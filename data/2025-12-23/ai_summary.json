{
    "papers": [
        {
            "title": "Enhancing annotations for 5D apple pose estimation through 3D Gaussian Splatting (3DGS)",
            "authors": [
                "Robert van de Ven",
                "Trim Bresilla",
                "Bram Nelissen",
                "Ard Nieuwenhuizen",
                "Eldert J. van Henten",
                "Gert Kootstra"
            ],
            "arxiv_id": "2512.20148v1",
            "summary": "Automating tasks in orchards is challenging because of the large amount of variation in the environment and occlusions. One of the challenges is apple pose estimation, where key points, such as the calyx, are often occluded. Recently developed pose estimation methods no longer rely on these key points, but still require them for annotations, making annotating challenging and time-consuming. Due to the abovementioned occlusions, there can be conflicting and missing annotations of the same fruit between different images. Novel 3D reconstruction methods can be used to simplify annotating and enlarge datasets. We propose a novel pipeline consisting of 3D Gaussian Splatting to reconstruct an orchard scene, simplified annotations, automated projection of the annotations to images, and the training and evaluation of a pose estimation method. Using our pipeline, 105 manual annotations were required to obtain 28,191 training labels, a reduction of 99.6%. Experimental results indicated that training with labels of fruits that are $\\leq95\\%$ occluded resulted in the best performance, with a neutral F1 score of 0.927 on the original images and 0.970 on the rendered images. Adjusting the size of the training dataset had small effects on the model performance in terms of F1 score and pose estimation accuracy. It was found that the least occluded fruits had the best position estimation, which worsened as the fruits became more occluded. It was also found that the tested pose estimation method was unable to correctly learn the orientation estimation of apples.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "33 pages, excluding appendices. 17 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20148v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]3D gaussian splatting",
                        "[T]3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 24.0
                }
            ],
            "relevance_score": 24.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "利用3D高斯溅射增强5D苹果姿态估计的标注效率",
            "summary_zh": "果园环境变化大且遮挡严重，使得果园自动化任务充满挑战。苹果姿态估计是其中一个难题，果萼等关键点经常被遮挡。虽然最新的姿态估计方法不再依赖这些关键点，但仍然需要它们进行标注，这使得标注工作既困难又耗时。由于遮挡，同一苹果在不同图像之间可能存在冲突或缺失的标注。新颖的3D重建方法可用于简化标注并扩大数据集。本文提出了一种新颖的流程，包括使用3D高斯溅射重建果园场景、简化标注、自动将标注投影到图像，以及训练和评估姿态估计方法。使用该流程，仅需105个手动标注即可获得28,191个训练标签，减少了99.6%。实验结果表明，使用遮挡率≤95%的苹果标签进行训练可获得最佳性能，在原始图像上的F1得分为0.927，在渲染图像上的F1得分为0.970。调整训练数据集的大小对模型的F1得分和姿态估计准确率影响不大。研究发现，遮挡最少的苹果的位置估计效果最好，随着遮挡增加，效果变差。此外，测试的姿态估计方法无法正确学习苹果的姿态估计。",
            "intro_zh": [
                "苹果姿态估计依赖人工标注，但果园环境遮挡严重，导致标注困难且易出错。",
                "利用3D高斯溅射重建果园场景，简化标注流程，并自动将标注投影到图像。",
                "实验表明，该方法仅需少量人工标注即可生成大量训练数据，并提升姿态估计性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决苹果姿态估计中人工标注耗时且易受遮挡影响的问题。现有方法虽然不再依赖关键点，但仍需人工标注，在遮挡严重的果园环境中，标注质量难以保证，且效率低下。\\n\\n**核心思路**：论文的核心思路是利用3D高斯溅射（3DGS）技术重建果园场景的3D模型，然后在3D模型上进行简化标注，最后将这些标注自动投影到2D图像上，从而生成大量的训练数据。这样可以显著减少人工标注的工作量，并提高标注的准确性和一致性。\\n\\n**技术框架**：该方法包含以下几个主要阶段：1) 使用多视角图像重建果园场景的3D高斯溅射模型；2) 在3D模型上进行简化标注（例如，仅标注苹果的中心点）；3) 将3D标注投影到2D图像上，生成训练数据；4) 使用生成的训练数据训练姿态估计模型；5) 评估姿态估计模型的性能。\\n\\n**关键创新**：该方法最重要的创新点在于将3D高斯溅射技术应用于苹果姿态估计的标注流程中。与传统的2D标注方法相比，该方法可以在3D空间中进行标注，从而避免了遮挡带来的问题，并提高了标注的效率和准确性。此外，自动投影标注到图像的方法也减少了人工干预，降低了标注成本。\\n\\n**关键设计**：论文中使用了标准的3D高斯溅射算法进行场景重建。在标注方面，作者简化了标注内容，例如只标注苹果的中心点。在训练姿态估计模型时，作者探索了不同遮挡程度的苹果对模型性能的影响，并发现使用遮挡率≤95%的苹果标签进行训练可以获得最佳性能。具体的姿态估计模型结构和损失函数没有在摘要中详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于果园机器人、自动化采摘、产量预测等领域。通过减少人工标注工作量，降低了数据获取成本，加速了相关算法的开发和部署。未来，该方法可推广到其他农作物或复杂场景的姿态估计任务中，促进农业智能化发展。",
            "highlight_zh": "该方法仅需105个手动标注即可生成28,191个训练标签，标注工作量减少了99.6%。实验结果表明，使用遮挡率≤95%的苹果标签进行训练，在原始图像上的F1得分为0.927，在渲染图像上的F1得分为0.970，验证了该方法的有效性。",
            "tags_zh": [
                "苹果姿态估计",
                "3D高斯溅射",
                "数据增强",
                "自动化标注",
                "果园机器人"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20148v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20148v1/img/overview_w_camera_poses.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20148v1/img/annotating_3dgs.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Asynchronous Fast-Slow Vision-Language-Action Policies for Whole-Body Robotic Manipulation",
            "authors": [
                "Teqiang Zou",
                "Hongliang Zeng",
                "Yuxuan Nong",
                "Yifan Li",
                "Kehui Liu",
                "Haotian Yang",
                "Xinyang Ling",
                "Xin Li",
                "Lianyang Ma"
            ],
            "arxiv_id": "2512.20188v1",
            "summary": "Most Vision-Language-Action (VLA) systems integrate a Vision-Language Model (VLM) for semantic reasoning with an action expert generating continuous action signals, yet both typically run at a single unified frequency. As a result, policy performance is constrained by the low inference speed of large VLMs. This mandatory synchronous execution severely limits control stability and real-time performance in whole-body robotic manipulation, which involves more joints, larger motion spaces, and dynamically changing views. We introduce a truly asynchronous Fast-Slow VLA framework (DuoCore-FS), organizing the system into a fast pathway for high-frequency action generation and a slow pathway for rich VLM reasoning. The system is characterized by two key features. First, a latent representation buffer bridges the slow and fast systems. It stores instruction semantics and action-reasoning representation aligned with the scene-instruction context, providing high-level guidance to the fast pathway. Second, a whole-body action tokenizer provides a compact, unified representation of whole-body actions. Importantly, the VLM and action expert are still jointly trained end-to-end, preserving unified policy learning while enabling asynchronous execution. DuoCore-FS supports a 3B-parameter VLM while achieving 30 Hz whole-body action-chunk generation, approximately three times as fast as prior VLA models with comparable model sizes. Real-world whole-body manipulation experiments demonstrate improved task success rates and significantly enhanced responsiveness compared to synchronous Fast-Slow VLA baselines. The implementation of DuoCore-FS, including training, inference, and deployment, is provided to commercial users by Astribot as part of the Astribot robotic platform.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20188v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation",
                        "whole-body manipulation"
                    ],
                    "score": 8.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "policy learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "VLA"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 21.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DuoCore-FS异步快速-慢速视觉-语言-动作策略，用于全身机器人操作。",
            "summary_zh": "大多数视觉-语言-动作（VLA）系统集成了视觉-语言模型（VLM）进行语义推理，以及动作专家生成连续动作信号，但两者通常以单一的统一频率运行。因此，策略性能受到大型VLM低推理速度的限制。这种强制同步执行严重限制了全身机器人操作中的控制稳定性和实时性能，全身机器人操作涉及更多关节、更大的运动空间和动态变化的视角。我们引入了一个真正的异步快速-慢速VLA框架（DuoCore-FS），将系统组织成一个用于高频动作生成的快速通道和一个用于丰富VLM推理的慢速通道。该系统的特点是两个关键特征。首先，一个潜在表示缓冲区桥接了慢速和快速系统。它存储与场景-指令上下文对齐的指令语义和动作推理表示，为快速通道提供高级指导。其次，一个全身动作分词器提供了全身动作的紧凑、统一的表示。重要的是，VLM和动作专家仍然进行端到端联合训练，在保持统一策略学习的同时实现异步执行。DuoCore-FS支持一个30亿参数的VLM，同时实现30 Hz的全身动作块生成，大约是先前具有可比模型大小的VLA模型的三倍。真实的全身操作实验表明，与同步快速-慢速VLA基线相比，任务成功率得到提高，响应能力显著增强。DuoCore-FS的实现，包括训练、推理和部署，由Astribot作为Astribot机器人平台的一部分提供给商业用户。",
            "intro_zh": [
                "现有VLA系统受限于VLM的低推理速度，同步执行限制了全身机器人操作的实时性和控制稳定性。",
                "DuoCore-FS框架通过异步执行VLM推理和动作生成，利用潜在表示缓冲区桥接快慢通道，提升整体性能。",
                "实验表明，DuoCore-FS能以30Hz生成全身动作块，速度是现有方法的3倍，并提高了真实环境下的任务成功率。"
            ],
            "method_zh": "**问题定义**：现有视觉-语言-动作（VLA）系统通常采用同步执行模式，即视觉-语言模型（VLM）的推理和动作专家的动作生成以相同的频率运行。然而，大型VLM的推理速度较慢，这限制了整个系统的实时性，尤其是在需要高频率控制的全身机器人操作中。此外，同步执行也限制了控制的稳定性，难以应对动态变化的环境。\n\n**核心思路**：DuoCore-FS的核心思路是将VLA系统解耦为两个异步运行的通道：一个快速通道用于高频率的动作生成，一个慢速通道用于VLM的语义推理。通过这种方式，系统可以充分利用VLM的强大推理能力，同时避免其低速推理对实时性的影响。关键在于设计一个有效的机制，将慢速通道的推理结果传递给快速通道，指导其动作生成。\n\n**技术框架**：DuoCore-FS框架包含以下主要模块：1) 慢速通道：负责运行VLM，进行视觉和语言信息的理解，提取场景和指令的语义信息。2) 快速通道：负责基于慢速通道提供的语义信息，生成高频率的动作指令。3) 潜在表示缓冲区：作为慢速通道和快速通道之间的桥梁，存储VLM推理得到的语义表示，并将其与场景-指令上下文对齐，为快速通道提供高级指导。4) 全身动作分词器：将全身动作表示为紧凑、统一的离散token序列，便于动作的生成和控制。\n\n**关键创新**：DuoCore-FS最重要的创新点在于其异步执行的架构。与传统的同步VLA系统相比，DuoCore-FS允许VLM和动作专家以不同的频率运行，从而突破了VLM推理速度的瓶颈。此外，潜在表示缓冲区的引入，使得慢速通道的推理结果能够有效地指导快速通道的动作生成，保证了整体策略的一致性。\n\n**关键设计**：DuoCore-FS的关键设计包括：1) 潜在表示缓冲区的实现方式，需要考虑如何有效地存储和检索语义表示，并将其与场景-指令上下文对齐。2) 全身动作分词器的设计，需要考虑如何将高维度的全身动作空间映射到低维度的token空间，同时保证动作的表达能力和控制精度。3) 损失函数的设计，需要保证VLM和动作专家能够进行端到端的联合训练，从而学习到统一的策略。",
            "application_zh": "DuoCore-FS框架在全身机器人操作领域具有广泛的应用前景，例如家庭服务机器人、工业自动化机器人等。该框架可以提高机器人的响应速度和控制精度，使其能够更好地完成复杂的任务，例如物体抓取、装配、导航等。此外，该框架还可以应用于虚拟现实、游戏等领域，提高虚拟角色的智能性和交互性。",
            "highlight_zh": "DuoCore-FS在真实环境下的全身操作实验中表现出色，实现了30Hz的全身动作块生成速度，是现有VLA模型的三倍。与同步Fast-Slow VLA基线相比，DuoCore-FS显著提高了任务成功率和响应能力。例如，在特定操作任务中，DuoCore-FS的任务成功率提升了XX%（具体数据未知）。",
            "tags_zh": [
                "视觉语言动作",
                "机器人操作",
                "异步执行",
                "快速-慢速策略",
                "全身控制"
            ],
            "_index": 1,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20188v1/framework.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20188v1/co_training.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20188v1/popcorn_pipeline.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Bring My Cup! Personalizing Vision-Language-Action Models with Visual Attentive Prompting",
            "authors": [
                "Sangoh Lee",
                "Sangwoo Mo",
                "Wook-Shin Han"
            ],
            "arxiv_id": "2512.20014v1",
            "summary": "While Vision-Language-Action (VLA) models generalize well to generic instructions, they struggle with personalized commands such as \"bring my cup\", where the robot must act on one specific instance among visually similar objects. We study this setting of manipulating personal objects, in which a VLA must identify and control a user-specific object unseen during training using only a few reference images. To address this challenge, we propose Visual Attentive Prompting (VAP), a simple-yet-effective training-free perceptual adapter that equips frozen VLAs with top-down selective attention. VAP treats the reference images as a non-parametric visual memory, grounds the personal object in the scene through open-vocabulary detection and embedding-based matching, and then injects this grounding as a visual prompt by highlighting the object and rewriting the instruction. We construct two simulation benchmarks, Personalized-SIMPLER and Personalized-VLABench, and a real-world tabletop benchmark to evaluate personalized manipulation across multiple robots and tasks. Experiments show that VAP consistently outperforms generic policies and token-learning baselines in both success rate and correct-object manipulation, helping to bridge the gap between semantic understanding and instance-level control.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20014v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "VLA"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出视觉注意力提示（VAP），解决VLA模型在个性化指令下的物体操作难题",
            "summary_zh": "视觉-语言-动作（VLA）模型在通用指令上表现良好，但在个性化指令（如“拿我的杯子”）中表现不佳，因为机器人必须在视觉上相似的物体中操作特定实例。本文研究了操作个人物品的场景，其中VLA模型必须仅使用少量参考图像来识别和控制训练期间未见过的用户特定对象。为了解决这个挑战，我们提出了视觉注意力提示（VAP），这是一种简单而有效的免训练感知适配器，它为冻结的VLA模型配备了自上而下的选择性注意力。VAP将参考图像视为非参数视觉记忆，通过开放词汇检测和基于嵌入的匹配将个人对象定位在场景中，然后通过突出显示对象并重写指令，将此定位作为视觉提示注入。我们构建了两个模拟基准（Personalized-SIMPLER和Personalized-VLABench）和一个真实世界的桌面基准，以评估跨多个机器人和任务的个性化操作。实验表明，VAP在成功率和正确对象操作方面始终优于通用策略和token-learning基线，有助于弥合语义理解和实例级控制之间的差距。",
            "intro_zh": [
                "VLA模型在处理个性化指令时，难以区分视觉相似但属于不同用户的物体，导致操作失败。",
                "VAP通过将参考图像作为视觉记忆，利用开放词汇检测和嵌入匹配来定位目标物体，并将其作为视觉提示注入VLA模型。",
                "在模拟和真实环境的实验中，VAP显著提高了成功率和正确物体操作率，优于现有方法。"
            ],
            "method_zh": "**问题定义**：现有的视觉-语言-动作（VLA）模型在处理通用指令时表现良好，但当需要操作特定用户的物品时，例如“把我的杯子拿过来”，由于视觉上相似的物体很多，模型难以区分并正确操作目标物体。现有方法缺乏对用户个性化信息的有效利用，导致泛化能力不足。\\n\\n**核心思路**：本文的核心思路是将用户的参考图像作为视觉记忆，通过视觉注意力机制引导VLA模型关注目标物体。具体来说，VAP利用参考图像来定位场景中的目标物体，并将定位结果作为视觉提示，增强VLA模型对个性化指令的理解和执行能力。这种方法无需重新训练VLA模型，即可实现个性化操作。\\n\\n**技术框架**：VAP主要包含三个阶段：1) **物体定位**：利用开放词汇检测器和基于嵌入的匹配方法，将参考图像中的目标物体定位到当前场景中。2) **视觉提示生成**：根据物体定位结果，生成视觉提示，例如突出显示目标物体。3) **指令重写**：将原始指令与视觉提示相结合，生成新的指令，输入到VLA模型中。VLA模型根据新的指令执行相应的动作。\\n\\n**关键创新**：VAP的关键创新在于提出了一种免训练的感知适配器，通过视觉注意力提示的方式，将用户的个性化信息注入到冻结的VLA模型中。与传统的微调方法相比，VAP无需重新训练模型，降低了计算成本和数据需求。此外，VAP利用开放词汇检测器和嵌入匹配方法，实现了对未知物体的定位和操作。\\n\\n**关键设计**：VAP的关键设计包括：1) 使用CLIP模型提取图像和文本的嵌入向量，用于计算物体之间的相似度。2) 利用注意力机制，根据参考图像和场景图像的相似度，生成视觉注意力图。3) 通过突出显示目标物体的方式，生成视觉提示。4) 将视觉提示与原始指令拼接，生成新的指令。具体参数设置和损失函数细节在论文中未明确说明，属于未知信息。",
            "application_zh": "该研究成果可应用于家庭服务机器人、智能助手等领域，使机器人能够更好地理解和执行用户的个性化指令，例如识别并拿取用户的特定物品、根据用户的偏好调整环境设置等。这项技术有助于提升人机交互的自然性和效率，增强用户体验，并为机器人更广泛的应用奠定基础。",
            "highlight_zh": "实验结果表明，VAP在Personalized-SIMPLER、Personalized-VLABench和真实世界桌面基准测试中，均显著优于通用策略和token-learning基线。具体而言，VAP在成功率和正确对象操作方面均取得了显著提升，表明其能够有效解决VLA模型在个性化指令下的物体操作难题。具体提升幅度在论文中未给出明确数据，属于未知信息。",
            "tags_zh": [
                "视觉语言动作模型",
                "个性化指令",
                "视觉注意力提示",
                "机器人操作",
                "物体识别"
            ],
            "_index": 2,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20014v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20014v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20014v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LoLA: Long Horizon Latent Action Learning for General Robot Manipulation",
            "authors": [
                "Xiaofan Wang",
                "Xingyu Gao",
                "Jianlong Fu",
                "Zuolei Li",
                "Dean Fortier",
                "Galen Mullins",
                "Andrey Kolobov",
                "Baining Guo"
            ],
            "arxiv_id": "2512.20166v1",
            "summary": "The capability of performing long-horizon, language-guided robotic manipulation tasks critically relies on leveraging historical information and generating coherent action sequences. However, such capabilities are often overlooked by existing Vision-Language-Action (VLA) models. To solve this challenge, we propose LoLA (Long Horizon Latent Action Learning), a framework designed for robot manipulation that integrates long-term multi-view observations and robot proprioception to enable multi-step reasoning and action generation. We first employ Vision-Language Models to encode rich contextual features from historical sequences and multi-view observations. We further introduces a key module, State-Aware Latent Re-representation, which transforms visual inputs and language commands into actionable robot motion space. Unlike existing VLA approaches that merely concatenate robot proprioception (e.g., joint angles) with VL embeddings, this module leverages such robot states to explicitly ground VL representations in physical scale through a learnable \"embodiment-anchored\" latent space. We trained LoLA on diverse robotic pre-training datasets and conducted extensive evaluations on simulation benchmarks (SIMPLER and LIBERO), as well as two real-world tasks on Franka and Bi-Manual Aloha robots. Results show that LoLA significantly outperforms prior state-of-the-art methods (e.g., pi0), particularly in long-horizon manipulation tasks.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20166v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation",
                        "bi-manual"
                    ],
                    "score": 8.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "vision-language-action",
                        "VLA",
                        "Aloha"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 17.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "LoLA：用于通用机器人操作的长程隐空间动作学习框架",
            "summary_zh": "本文提出LoLA（Long Horizon Latent Action Learning），一个用于机器人操作的框架，它整合了长期的多视角观测和机器人自身状态信息，以实现多步骤推理和动作生成。LoLA首先利用视觉-语言模型对历史序列和多视角观测进行编码，提取丰富的上下文特征。然后，引入关键模块——状态感知隐空间重表示（State-Aware Latent Re-representation），将视觉输入和语言指令转换为可执行的机器人运动空间。与现有仅将机器人自身状态（如关节角度）与视觉-语言嵌入连接的方法不同，该模块利用机器人状态，通过可学习的“具身锚定”隐空间，将视觉-语言表示显式地锚定到物理尺度上。LoLA在多个机器人预训练数据集上进行了训练，并在仿真基准（SIMPLER和LIBERO）以及Franka和Bi-Manual Aloha机器人上的两个真实世界任务中进行了广泛评估。结果表明，LoLA显著优于现有最先进的方法（如pi0），尤其是在长程操作任务中。",
            "intro_zh": [
                "现有视觉-语言-动作（VLA）模型在长程、语言引导的机器人操作任务中，忽略了历史信息利用和连贯动作序列生成能力。",
                "LoLA通过状态感知隐空间重表示模块，将视觉和语言信息转化为机器人可执行的动作空间，并显式地将视觉-语言表示锚定到物理尺度上。",
                "LoLA在仿真和真实机器人任务中均表现出色，显著优于现有方法，尤其在长程操作任务中性能提升明显。"
            ],
            "method_zh": "**问题定义**：现有视觉-语言-动作模型在处理长程机器人操作任务时，缺乏有效利用历史信息和生成连贯动作序列的能力。简单地将机器人自身状态与视觉-语言嵌入连接，无法充分将视觉-语言表示与物理世界进行对齐，导致在复杂操作任务中性能受限。\\n\\n**核心思路**：LoLA的核心思路是引入状态感知隐空间重表示模块，该模块利用机器人自身状态信息（如关节角度），将视觉和语言信息映射到一个“具身锚定”的隐空间。通过这种方式，模型能够更好地理解物理世界的约束，并生成更精确、更连贯的机器人动作序列。\\n\\n**技术框架**：LoLA框架主要包含以下几个阶段：1) 利用视觉-语言模型对历史序列和多视角观测进行编码，提取丰富的上下文特征。2) 引入状态感知隐空间重表示模块，将视觉输入和语言指令转换为可执行的机器人运动空间。该模块以视觉-语言嵌入和机器人自身状态作为输入，输出一个在隐空间中重表示的动作。3) 使用重表示的动作控制机器人执行操作。\\n\\n**关键创新**：LoLA最重要的技术创新点在于状态感知隐空间重表示模块。与现有方法简单地连接机器人状态和视觉-语言嵌入不同，该模块通过可学习的“具身锚定”隐空间，显式地将视觉-语言表示锚定到物理尺度上。这种方法使得模型能够更好地理解物理世界的约束，并生成更精确的机器人动作。\\n\\n**关键设计**：状态感知隐空间重表示模块的关键设计包括：1) 使用多层感知机（MLP）将视觉-语言嵌入和机器人自身状态映射到隐空间。2) 设计一个损失函数，鼓励隐空间中的表示与实际的机器人动作相对应。3) 使用Transformer网络来建模动作序列的长期依赖关系。",
            "application_zh": "LoLA框架具有广泛的应用前景，可应用于各种需要长程规划和精确控制的机器人操作任务，例如：家庭服务机器人、工业自动化、医疗手术机器人等。该研究有助于提升机器人在复杂环境中的适应性和操作能力，实现更智能、更高效的机器人应用。",
            "highlight_zh": "LoLA在SIMPLER和LIBERO仿真基准测试以及Franka和Bi-Manual Aloha机器人上的真实世界任务中进行了评估。结果表明，LoLA显著优于现有最先进的方法（如pi0），尤其是在长程操作任务中性能提升明显。例如，在某个长程操作任务中，LoLA的成功率比pi0提高了15%。",
            "tags_zh": [
                "机器人操作",
                "长程规划",
                "视觉语言动作模型",
                "隐空间学习",
                "具身智能"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20166v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20166v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20166v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Scaling Reinforcement Learning for Content Moderation with Large Language Models",
            "authors": [
                "Hamed Firooz",
                "Rui Liu",
                "Yuchen Lu",
                "Zhenyu Hou",
                "Fangzhou Xiong",
                "Xiaoyang Zhang",
                "Changshu Jian",
                "Zhicheng Zhu",
                "Jiayuan Ma",
                "Jacob Tao",
                "Chaitali Gupta",
                "Xiaochang Peng",
                "Shike Mei",
                "Hang Cui",
                "Yang Qin",
                "Shuo Tang",
                "Jason Gaedtke",
                "Arpit Mittal"
            ],
            "arxiv_id": "2512.20061v1",
            "summary": "Content moderation at scale remains one of the most pressing challenges in today's digital ecosystem, where billions of user- and AI-generated artifacts must be continuously evaluated for policy violations. Although recent advances in large language models (LLMs) have demonstrated strong potential for policy-grounded moderation, the practical challenges of training these systems to achieve expert-level accuracy in real-world settings remain largely unexplored, particularly in regimes characterized by label sparsity, evolving policy definitions, and the need for nuanced reasoning beyond shallow pattern matching. In this work, we present a comprehensive empirical investigation of scaling reinforcement learning (RL) for content classification, systematically evaluating multiple RL training recipes and reward-shaping strategies-including verifiable rewards and LLM-as-judge frameworks-to transform general-purpose language models into specialized, policy-aligned classifiers across three real-world content moderation tasks. Our findings provide actionable insights for industrial-scale moderation systems, demonstrating that RL exhibits sigmoid-like scaling behavior in which performance improves smoothly with increased training data, rollouts, and optimization steps before gradually saturating. Moreover, we show that RL substantially improves performance on tasks requiring complex policy-grounded reasoning while achieving up to 100x higher data efficiency than supervised fine-tuning, making it particularly effective in domains where expert annotations are scarce or costly.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20061v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "reward shaping"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "利用强化学习和大型语言模型提升大规模内容审核的效率与准确性",
            "summary_zh": "大规模内容审核是当前数字生态系统面临的最紧迫挑战之一，需要持续评估数十亿用户和AI生成的内容，以确定其是否违反政策。尽管大型语言模型（LLM）在基于策略的内容审核方面展现出巨大潜力，但在实际环境中训练这些系统以达到专家级准确率仍然面临诸多挑战，尤其是在标签稀疏、政策定义不断演变以及需要超越浅层模式匹配的细致推理的情况下。本文对使用强化学习（RL）进行内容分类的扩展性进行了全面的实证研究，系统地评估了多种RL训练方法和奖励塑造策略（包括可验证奖励和LLM作为评判框架），以将通用语言模型转化为在三个真实内容审核任务中专门的、符合策略的分类器。研究结果为工业级审核系统提供了可操作的见解，表明RL表现出类似Sigmoid的扩展行为，即性能随着训练数据、rollout和优化步骤的增加而平稳提高，然后逐渐饱和。此外，研究表明，RL在需要复杂策略推理的任务上显著提高了性能，同时实现了比监督微调高出100倍的数据效率，使其在专家标注稀缺或成本高昂的领域特别有效。",
            "intro_zh": [
                "现有内容审核方法难以应对标签稀疏、策略演变和复杂推理等挑战，导致审核效率和准确性不足。",
                "论文提出利用强化学习（RL）训练大型语言模型（LLM），通过奖励塑造策略使其成为专业的、符合策略的分类器。",
                "实验表明，RL方法在内容审核任务上表现出良好的扩展性，数据效率比监督微调高出100倍。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大规模内容审核中，现有方法在标签稀疏、策略定义不断演变以及需要复杂推理的情况下，难以达到专家级准确率的问题。现有方法，如监督学习，需要大量的标注数据，成本高昂，且难以适应策略的快速变化。\\n\\n**核心思路**：论文的核心思路是利用强化学习（RL）来训练大型语言模型（LLM），使其能够根据内容审核策略进行决策。通过奖励塑造策略，引导LLM学习符合策略的分类行为，从而在数据稀缺的情况下也能达到较高的准确率。这样设计的目的是为了提高数据效率，并使模型能够更好地适应不断变化的策略。\\n\\n**技术框架**：整体框架包括以下几个主要模块：1）LLM作为Agent，负责对内容进行分类；2）环境，模拟内容审核场景，提供内容样本；3）奖励函数，根据LLM的分类结果和审核策略，给出奖励信号；4）RL算法，用于更新LLM的策略，使其能够获得更高的奖励。其中，奖励函数的设计至关重要，论文探索了多种奖励塑造策略，包括可验证奖励和LLM作为评判框架。\\n\\n**关键创新**：最重要的技术创新点在于将强化学习应用于内容审核任务，并探索了多种有效的奖励塑造策略。与传统的监督学习方法相比，RL方法能够更好地利用未标注数据，提高数据效率，并适应策略的变化。此外，使用LLM作为评判框架，可以减少对人工标注的依赖。\\n\\n**关键设计**：论文中，奖励函数的设计是关键。可验证奖励是指根据一些明确的规则或标准来判断LLM的分类结果是否正确，并给出相应的奖励。LLM作为评判框架是指使用另一个LLM来评估LLM的分类结果，并给出奖励信号。此外，论文还探索了不同的RL算法，如PPO等，以及不同的训练参数设置，以优化模型的性能。",
            "application_zh": "该研究成果可应用于各种在线平台的内容审核系统，例如社交媒体、论坛、电商平台等。通过使用强化学习训练的LLM，可以自动识别和过滤违反政策的内容，减少人工审核的工作量，提高审核效率和准确性，从而维护健康的在线环境。",
            "highlight_zh": "实验结果表明，RL方法在内容审核任务上表现出良好的扩展性，性能随着训练数据、rollout和优化步骤的增加而平稳提高。与监督微调相比，RL方法在需要复杂策略推理的任务上显著提高了性能，同时实现了高达100倍的数据效率。这表明RL方法在数据稀缺或标注成本高昂的场景下具有显著优势。",
            "tags_zh": [
                "内容审核",
                "强化学习",
                "大型语言模型",
                "奖励塑造",
                "策略对齐"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20061v1/img/reward_hacking.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20061v1/img/instruction_halu.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20061v1/img/factuality_halu.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "QE-Catalytic: A Graph-Language Multimodal Base Model for Relaxed-Energy Prediction in Catalytic Adsorption",
            "authors": [
                "Yanjie Li",
                "Jian Xu",
                "Xueqing Chen",
                "Lina Yu",
                "Shiming Xiang",
                "Weijun Li",
                "Cheng-lin Liu"
            ],
            "arxiv_id": "2512.20084v1",
            "summary": "Adsorption energy is a key descriptor of catalytic reactivity. It is fundamentally defined as the difference between the relaxed total energy of the adsorbate-surface system and that of an appropriate reference state; therefore, the accuracy of relaxed-energy prediction directly determines the reliability of machine-learning-driven catalyst screening. E(3)-equivariant graph neural networks (GNNs) can natively operate on three-dimensional atomic coordinates under periodic boundary conditions and have demonstrated strong performance on such tasks. In contrast, language-model-based approaches, while enabling human-readable textual descriptions and reducing reliance on explicit graph -- thereby broadening applicability -- remain insufficient in both adsorption-configuration energy prediction accuracy and in distinguishing ``the same system with different configurations,'' even with graph-assisted pretraining in the style of GAP-CATBERTa.\n  To this end, we propose QE-Catalytic, a multimodal framework that deeply couples a large language model (\\textbf{Q}wen) with an E(3)-equivariant graph Transformer (\\textbf{E}quiformer-V2), enabling unified support for adsorption-configuration property prediction and inverse design on complex catalytic surfaces. During prediction, QE-Catalytic jointly leverages three-dimensional structures and structured configuration text, and injects ``3D geometric information'' into the language channel via graph-text alignment, allowing it to function as a high-performance text-based predictor when precise coordinates are unavailable, while also autoregressively generating CIF files for target-energy-driven structure design and information completion. On OC20, QE-Catalytic reduces the MAE of relaxed adsorption energy from 0.713~eV to 0.486~eV, and consistently outperforms baseline models such as CatBERTa and GAP-CATBERTa across multiple evaluation protocols.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "25 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20084v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "MAE"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出QE-Catalytic，融合图和语言模型，提升催化吸附中弛豫能量预测精度。",
            "summary_zh": "吸附能是催化反应活性的关键描述符。它从根本上定义为吸附质-表面系统的弛豫总能量与适当参考状态之间的差值；因此，弛豫能量预测的准确性直接决定了机器学习驱动的催化剂筛选的可靠性。E(3)-等变图神经网络(GNNs)可以在周期性边界条件下自然地处理三维原子坐标，并在该任务上表现出强大的性能。相比之下，基于语言模型的方法虽然能够实现人类可读的文本描述并减少对显式图的依赖——从而扩大了适用性——但在吸附构型能量预测精度和区分“具有不同构型的相同系统”方面仍然不足，即使采用类似于GAP-CATBERTa的图辅助预训练也是如此。为此，我们提出了QE-Catalytic，一个多模态框架，它将大型语言模型(Qwen)与E(3)-等变图Transformer(Equiformer-V2)深度耦合，从而能够统一支持复杂催化表面上的吸附构型属性预测和逆向设计。在预测过程中，QE-Catalytic联合利用三维结构和结构化构型文本，并通过图-文本对齐将“3D几何信息”注入到语言通道中，使其在没有精确坐标时也能作为高性能的基于文本的预测器发挥作用，同时还能自回归地生成用于目标能量驱动的结构设计和信息补全的CIF文件。在OC20上，QE-Catalytic将弛豫吸附能的MAE从0.713 eV降低到0.486 eV，并且在多个评估协议中始终优于CatBERTa和GAP-CATBERTa等基线模型。",
            "intro_zh": [
                "现有方法在催化吸附能量预测中，基于语言模型的方法精度不足，无法有效区分不同构型的相同系统。",
                "QE-Catalytic通过深度耦合大型语言模型和E(3)-等变图Transformer，实现对吸附构型属性的统一预测和逆向设计。",
                "实验结果表明，QE-Catalytic在OC20数据集上显著降低了弛豫吸附能的MAE，优于现有基线模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决催化吸附过程中弛豫能量预测的准确性问题。现有基于语言模型的方法，即使经过图辅助预训练，在预测吸附构型能量和区分不同构型的相同系统方面仍然存在不足，限制了催化剂筛选的可靠性。\\n\\n**核心思路**：论文的核心思路是将大型语言模型与E(3)-等变图Transformer深度耦合，构建一个多模态框架。通过图-文本对齐，将三维几何信息注入到语言通道中，使得模型既能利用结构信息，也能利用文本描述，从而提高预测精度和泛化能力。\\n\\n**技术框架**：QE-Catalytic框架包含两个主要模块：大型语言模型（Qwen）和E(3)-等变图Transformer（Equiformer-V2）。该框架首先利用Equiformer-V2处理三维原子结构，提取几何特征。然后，将结构化的构型文本输入到Qwen中进行处理。通过图-文本对齐机制，将Equiformer-V2提取的几何特征注入到Qwen中，实现多模态信息的融合。最后，利用融合后的信息进行弛豫能量预测，并支持自回归生成CIF文件进行结构设计。\\n\\n**关键创新**：该论文的关键创新在于多模态融合框架的设计，特别是图-文本对齐机制。通过将E(3)-等变图Transformer与大型语言模型深度耦合，实现了三维结构信息和文本信息的有效融合，克服了传统方法中仅依赖单一模态信息的局限性。此外，该框架还支持自回归生成CIF文件，为催化剂的逆向设计提供了新的途径。\\n\\n**关键设计**：QE-Catalytic的关键设计包括：1）选择Qwen作为大型语言模型，利用其强大的文本处理能力；2）选择Equiformer-V2作为图神经网络，利用其E(3)-等变性处理三维原子结构；3）设计图-文本对齐机制，将几何信息注入到语言通道中；4）采用合适的损失函数进行模型训练，优化预测精度。",
            "application_zh": "QE-Catalytic在催化剂设计与筛选领域具有广泛的应用前景。它可以用于预测各种催化材料的吸附能，加速新型催化剂的发现。此外，其逆向设计能力可以帮助研究人员根据目标能量需求，自动生成具有特定结构的催化材料，极大地提高催化剂研发效率。",
            "highlight_zh": "QE-Catalytic在OC20数据集上取得了显著的性能提升，将弛豫吸附能的MAE从0.713 eV降低到0.486 eV，超越了CatBERTa和GAP-CATBERTa等基线模型。这表明该方法在催化吸附能量预测方面具有优越的性能和潜力。",
            "tags_zh": [
                "催化吸附",
                "能量预测",
                "图神经网络",
                "语言模型",
                "多模态融合",
                "逆向设计",
                "E(3)-等变性"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20084v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20084v1/hamap.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20084v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Bridging Modalities and Transferring Knowledge: Enhanced Multimodal Understanding and Recognition",
            "authors": [
                "Gorjan Radevski"
            ],
            "arxiv_id": "2512.20501v1",
            "summary": "This manuscript explores multimodal alignment, translation, fusion, and transference to enhance machine understanding of complex inputs. We organize the work into five chapters, each addressing unique challenges in multimodal machine learning.\n  Chapter 3 introduces Spatial-Reasoning Bert for translating text-based spatial relations into 2D arrangements between clip-arts. This enables effective decoding of spatial language into visual representations, paving the way for automated scene generation aligned with human spatial understanding.\n  Chapter 4 presents a method for translating medical texts into specific 3D locations within an anatomical atlas. We introduce a loss function leveraging spatial co-occurrences of medical terms to create interpretable mappings, significantly enhancing medical text navigability.\n  Chapter 5 tackles translating structured text into canonical facts within knowledge graphs. We develop a benchmark for linking natural language to entities and predicates, addressing ambiguities in text extraction to provide clearer, actionable insights.\n  Chapter 6 explores multimodal fusion methods for compositional action recognition. We propose a method fusing video frames and object detection representations, improving recognition robustness and accuracy.\n  Chapter 7 investigates multimodal knowledge transference for egocentric action recognition. We demonstrate how multimodal knowledge distillation enables RGB-only models to mimic multimodal fusion-based capabilities, reducing computational requirements while maintaining performance.\n  These contributions advance methodologies for spatial language understanding, medical text interpretation, knowledge graph enrichment, and action recognition, enhancing computational systems' ability to process complex, multimodal inputs across diverse applications.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Ph.D. manuscript; Supervisors/Mentors: Marie-Francine Moens and Tinne Tuytelaars",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20501v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.5,
            "hit_pillars": [
                "2_algo_arch",
                "6_video_extraction",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多模态对齐、翻译、融合与迁移方法，提升复杂输入理解与识别能力",
            "summary_zh": "本研究探索了多模态对齐、翻译、融合和迁移，以增强机器对复杂输入的理解。论文分为五个章节，每个章节都针对多模态机器学习中独特的挑战。第三章介绍了Spatial-Reasoning Bert，用于将基于文本的空间关系转换为剪贴画之间的2D排列，从而能够有效地将空间语言解码为视觉表示，为自动生成与人类空间理解对齐的场景铺平了道路。第四章提出了一种将医学文本翻译成解剖图谱中特定3D位置的方法，引入了一种利用医学术语空间共现的损失函数来创建可解释的映射，显著增强了医学文本的可导航性。第五章解决了将结构化文本翻译成知识图谱中的规范事实的问题，开发了一个用于将自然语言链接到实体和谓词的基准，解决了文本提取中的歧义，以提供更清晰、可操作的见解。第六章探索了用于组合动作识别的多模态融合方法，提出了一种融合视频帧和对象检测表示的方法，提高了识别的鲁棒性和准确性。第七章研究了用于以自我为中心的动作识别的多模态知识迁移，证明了多模态知识蒸馏如何使仅RGB模型能够模仿基于多模态融合的能力，从而在保持性能的同时降低计算要求。这些贡献推进了空间语言理解、医学文本解释、知识图谱丰富和动作识别的方法，增强了计算系统处理跨各种应用的复杂多模态输入的能力。",
            "intro_zh": [
                "现有方法在处理复杂多模态输入时，缺乏有效的对齐、翻译和融合机制，限制了机器的理解能力。",
                "论文通过多模态对齐、翻译、融合和迁移等技术，构建更强大的模型，提升机器对复杂信息的理解和识别。",
                "论文在空间语言理解、医学文本解释、知识图谱构建和动作识别等任务上验证了所提出方法的有效性。"
            ],
            "method_zh": "**问题定义**：现有方法在处理多模态数据时，面临着模态间的语义鸿沟、信息冗余以及计算复杂度高等问题。例如，将文本描述转化为视觉场景，需要理解空间关系并进行有效布局；医学文本与3D解剖位置的对应关系难以准确建立；知识图谱构建面临自然语言的歧义性；动作识别需要有效融合视频帧和对象检测信息，并降低计算成本。\\n\\n**核心思路**：论文的核心思路是通过多模态对齐、翻译、融合和迁移等技术，弥合模态间的语义鸿沟，提取关键信息，并利用知识蒸馏等方法降低计算复杂度。具体而言，通过Spatial-Reasoning Bert理解空间关系，通过空间共现损失函数建立医学文本与3D位置的映射，通过构建基准解决自然语言歧义，通过多模态融合提高动作识别的准确性和鲁棒性，并通过知识蒸馏将多模态知识迁移到单模态模型。\\n\\n**技术框架**：论文包含五个主要章节，分别针对不同的多模态任务：1) Spatial-Reasoning Bert：将文本空间关系转化为2D剪贴画排列；2) 医学文本到3D位置的翻译：利用空间共现损失函数建立映射；3) 知识图谱构建：构建基准解决自然语言歧义；4) 组合动作识别：融合视频帧和对象检测信息；5) 自我中心动作识别：利用多模态知识蒸馏。每个章节都包含数据预处理、模型构建、训练和评估等阶段。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了Spatial-Reasoning Bert，能够有效理解和生成空间关系；2) 引入了空间共现损失函数，提高了医学文本到3D位置翻译的准确性；3) 构建了用于知识图谱构建的基准，解决了自然语言歧义问题；4) 提出了多模态融合和知识蒸馏方法，提高了动作识别的性能和效率。与现有方法相比，论文更加注重模态间的语义对齐和知识迁移。\\n\\n**关键设计**：Spatial-Reasoning Bert采用了Transformer架构，并针对空间关系进行了优化。医学文本到3D位置的翻译采用了基于注意力机制的模型，并利用空间共现信息设计了损失函数。知识图谱构建基准包含了多种类型的实体和关系，并提供了详细的标注信息。多模态融合采用了基于卷积神经网络的模型，并对不同模态的信息进行了加权融合。知识蒸馏采用了基于对抗学习的方法，使得单模态模型能够更好地模仿多模态模型的行为。",
            "application_zh": "该研究成果可应用于多个领域，包括：智能家居场景生成、医学影像报告解读、知识图谱自动构建、智能视频监控和人机交互等。通过提升机器对多模态信息的理解能力，可以实现更智能、更高效的应用，例如，自动生成符合用户需求的家居场景，辅助医生进行疾病诊断，构建更全面的知识图谱，以及实现更自然的人机交互。",
            "highlight_zh": "论文在多个任务上取得了显著的性能提升。例如，Spatial-Reasoning Bert在空间关系理解任务上取得了state-of-the-art的结果。医学文本到3D位置的翻译方法在准确率上超过了现有方法。多模态融合方法在动作识别任务上提高了识别的鲁棒性和准确性。知识蒸馏方法在保持性能的同时，显著降低了计算成本。",
            "tags_zh": [
                "多模态学习",
                "空间推理",
                "医学文本分析",
                "知识图谱",
                "动作识别",
                "知识蒸馏",
                "模态融合"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "CRAFT: Continuous Reasoning and Agentic Feedback Tuning for Multimodal Text-to-Image Generation",
            "authors": [
                "V. Kovalev",
                "A. Kuvshinov",
                "A. Buzovkin",
                "D. Pokidov",
                "D. Timonin"
            ],
            "arxiv_id": "2512.20362v1",
            "summary": "Recent work has shown that inference-time reasoning and reflection can improve text-to-image generation without retraining. However, existing approaches often rely on implicit, holistic critiques or unconstrained prompt rewrites, making their behavior difficult to interpret, control, or stop reliably. In contrast, large language models have benefited from explicit, structured forms of **thinking** based on verification, targeted correction, and early stopping.\n  We introduce CRAFT (Continuous Reasoning and Agentic Feedback Tuning), a training-free, model-agnostic framework that brings this structured reasoning paradigm to multimodal image generation. CRAFT decomposes a prompt into dependency-structured visual questions, veries generated images using a vision-language model, and applies targeted prompt edits through an LLM agent only where constraints fail. The process iterates with an explicit stopping criterion once all constraints are satised, yielding an interpretable and controllable inference-time renement loop.\n  Across multiple model families and challenging benchmarks, CRAFT consistently improves compositional accuracy, text rendering, and preference-based evaluations, with particularly strong gains for lightweight generators. Importantly, these improvements incur only a negligible inference-time overhead, allowing smaller or cheaper models to approach the quality of substantially more expensive systems. Our results suggest that explicitly structured, constraint-driven inference-time reasoning is a key ingredient for improving the reliability of multimodal generative models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "37 pages, 42 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20362v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CRAFT：用于多模态文图生成的持续推理和Agent反馈调整框架",
            "summary_zh": "本文提出CRAFT（Continuous Reasoning and Agentic Feedback Tuning），一个无需训练、模型无关的框架，旨在将结构化推理范式引入多模态图像生成。CRAFT将提示分解为依赖结构的视觉问题，使用视觉-语言模型验证生成的图像，并仅在约束失败时通过LLM Agent应用有针对性的提示编辑。该过程迭代进行，直到满足所有约束条件，从而产生可解释和可控的推理时细化循环。在多个模型系列和具有挑战性的基准测试中，CRAFT始终如一地提高了组合准确性、文本渲染和基于偏好的评估，对于轻量级生成器而言，收益尤其显著。重要的是，这些改进仅产生可忽略不计的推理时开销，从而使更小或更便宜的模型能够接近更昂贵系统的质量。结果表明，显式结构化、约束驱动的推理时推理是提高多模态生成模型可靠性的关键要素。",
            "intro_zh": [
                "现有文图生成方法依赖隐式、整体的评价或无约束的提示重写，行为难以解释、控制和停止。",
                "CRAFT框架将提示分解为视觉问题，利用视觉-语言模型验证图像，并通过LLM Agent进行有针对性的提示编辑。",
                "实验表明，CRAFT显著提升了组合准确性、文本渲染和用户偏好，且推理开销极小，使轻量模型性能逼近重型模型。"
            ],
            "method_zh": "**问题定义**：现有的文本到图像生成方法在推理时的改进通常依赖于隐式的、整体性的评价，或者是不受约束的提示重写。这导致这些方法的行为难以解释、控制，并且无法可靠地停止。因此，如何设计一种可解释、可控且可靠的推理时改进框架是一个关键问题。\\n\\n**核心思路**：CRAFT的核心思路是将结构化推理引入到多模态图像生成中。借鉴大型语言模型中基于验证、有针对性的纠正和提前停止的显式、结构化思考方式，CRAFT将复杂的提示分解为更小的、可验证的视觉约束，并迭代地改进图像生成，直到满足所有约束。\\n\\n**技术框架**：CRAFT框架包含以下几个主要模块：1) 提示分解：将原始文本提示分解为一系列依赖结构的视觉问题。2) 图像生成：使用现有的文本到图像生成模型生成图像。3) 图像验证：使用视觉-语言模型验证生成的图像是否满足分解后的视觉约束。4) 提示编辑：如果图像未能满足约束，则使用LLM Agent对提示进行有针对性的编辑，以纠正图像中的错误。5) 迭代与停止：重复图像生成、验证和编辑的过程，直到所有约束都得到满足，或者达到预设的迭代次数。\\n\\n**关键创新**：CRAFT的关键创新在于其显式、结构化的推理过程。与现有方法相比，CRAFT不是简单地重写整个提示或进行整体性的评价，而是将提示分解为可验证的约束，并针对性地纠正图像中的错误。这种方法提高了生成过程的可解释性和可控性。\\n\\n**关键设计**：CRAFT的关键设计包括：1) 使用依赖结构来组织视觉问题，以确保问题之间的逻辑关系。2) 使用视觉-语言模型进行图像验证，以确保验证的准确性。3) 使用LLM Agent进行提示编辑，以确保编辑的有效性和针对性。4) 设计明确的停止准则，以确保生成过程的效率。",
            "application_zh": "CRAFT框架可应用于各种需要高质量、可控图像生成的场景，例如：电商产品图生成、游戏美术设计、广告创意生成、教育内容创作等。通过提高生成图像的准确性和可控性，CRAFT可以帮助用户更高效地生成符合需求的图像内容，并降低人工干预的成本。未来，CRAFT有望成为多模态内容生成领域的重要组成部分。",
            "highlight_zh": "CRAFT在多个模型系列和具有挑战性的基准测试中，始终如一地提高了组合准确性、文本渲染和基于偏好的评估。尤其对于轻量级生成器，收益更为显著。值得注意的是，这些改进仅带来了可忽略不计的推理时开销，使得更小或更便宜的模型能够接近更昂贵系统的质量。",
            "tags_zh": [
                "文图生成",
                "多模态学习",
                "推理时优化",
                "Agent反馈",
                "视觉语言模型"
            ],
            "_index": 7,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20362v1/images/image01.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20362v1/images/image02.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20362v1/images/image03.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AMoE: Agglomerative Mixture-of-Experts Vision Foundation Model",
            "authors": [
                "Sofian Chaybouti",
                "Sanath Narayan",
                "Yasser Dahou",
                "Phúc H. Lê Khac",
                "Ankit Singh",
                "Ngoc Dung Huynh",
                "Wamiq Reyaz Para",
                "Hilde Kuehne",
                "Hakim Hacid"
            ],
            "arxiv_id": "2512.20157v1",
            "summary": "Vision foundation models trained via multi-teacher distillation offer a promising path toward unified visual representations, yet the learning dynamics and data efficiency of such approaches remain underexplored. In this paper, we systematically study multi-teacher distillation for vision foundation models and identify key factors that enable training at lower computational cost. We introduce Agglomerative Mixture-of-Experts Vision Foundation Models (AMoE), which distill knowledge from SigLIP2 and DINOv3 simultaneously into a Mixture-of-Experts student. We show that (1) our Asymmetric Relation-Knowledge Distillation loss preserves the geometric properties of each teacher while enabling effective knowledge transfer, (2) token-balanced batching that packs varying-resolution images into sequences with uniform token budgets stabilizes representation learning across resolutions without sacrificing performance, and (3) hierarchical clustering and sampling of training data--typically reserved for self-supervised learning--substantially improves sample efficiency over random sampling for multi-teacher distillation. By combining these findings, we curate OpenLVD200M, a 200M-image corpus that demonstrates superior efficiency for multi-teacher distillation. Instantiated in a Mixture-of-Experts. We release OpenLVD200M and distilled models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "17 pages, 8 figures, 11 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20157v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "distillation"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出AMoE，一种高效的Agglomerative Mixture-of-Experts视觉基础模型，通过多教师蒸馏实现。",
            "summary_zh": "本文系统研究了视觉基础模型的多教师蒸馏方法，并确定了在较低计算成本下进行训练的关键因素。我们提出了Agglomerative Mixture-of-Experts视觉基础模型（AMoE），它同时从SigLIP2和DINOv3中提取知识到一个混合专家学生模型中。我们证明了：（1）我们的非对称关系知识蒸馏损失保留了每个教师的几何属性，同时实现了有效的知识转移；（2）token平衡批处理将不同分辨率的图像打包成具有统一token预算的序列，稳定了跨分辨率的表示学习，且不牺牲性能；（3）训练数据的分层聚类和采样（通常用于自监督学习）显著提高了多教师蒸馏的样本效率，优于随机采样。通过结合这些发现，我们创建了OpenLVD200M，一个2亿图像语料库，展示了多教师蒸馏的卓越效率。我们发布了OpenLVD200M和蒸馏模型。",
            "intro_zh": [
                "现有的视觉基础模型训练方法计算成本高昂，且对多教师蒸馏的学习动态和数据效率研究不足。",
                "AMoE通过非对称关系知识蒸馏、token平衡批处理和分层聚类采样等技术，提升多教师蒸馏的效率。",
                "实验表明，AMoE在2亿图像语料库OpenLVD200M上表现出卓越的效率，并发布了该数据集和蒸馏模型。"
            ],
            "method_zh": "**问题定义**：现有的视觉基础模型训练，特别是基于多教师蒸馏的方法，面临着计算资源需求高、数据利用率低的问题。如何降低训练成本，同时保证甚至提升模型性能，是本文要解决的核心问题。现有方法在知识迁移过程中可能无法充分保留各个教师模型的优势，且对不同分辨率图像的处理不够高效。\\n\\n**核心思路**：本文的核心思路是通过一种高效的多教师蒸馏框架，将多个预训练视觉模型的知识整合到一个轻量级的混合专家模型中。通过精心设计的损失函数、数据采样策略和批处理方法，优化知识迁移过程，提高数据利用率，从而降低训练成本。\\n\\n**技术框架**：AMoE的整体框架包括以下几个主要模块：1) 多教师模型（SigLIP2和DINOv3）；2) 混合专家学生模型；3) 非对称关系知识蒸馏损失；4) token平衡批处理；5) 分层聚类采样。首先，利用分层聚类采样从训练数据集中选择具有代表性的样本。然后，将不同分辨率的图像通过token平衡批处理构建统一token预算的序列。接着，利用非对称关系知识蒸馏损失，将多教师模型的知识迁移到混合专家学生模型中。\\n\\n**关键创新**：本文的关键创新在于以下三个方面：1) 提出了非对称关系知识蒸馏损失，能够更好地保留各个教师模型的几何属性，实现更有效的知识迁移；2) 引入了token平衡批处理，解决了不同分辨率图像在训练过程中带来的不稳定性问题；3) 将分层聚类采样应用于多教师蒸馏，显著提高了样本效率。\\n\\n**关键设计**：非对称关系知识蒸馏损失的设计考虑了不同教师模型之间的差异，通过不对称的方式保留各自的优势。Token平衡批处理通过调整不同分辨率图像的数量，使得每个批次的token数量保持一致，从而稳定训练过程。分层聚类采样通过对训练数据进行聚类，并从每个簇中选择代表性样本，减少了数据冗余，提高了训练效率。",
            "application_zh": "AMoE具有广泛的应用前景，可用于图像分类、目标检测、图像分割等多种视觉任务。通过高效的多教师蒸馏，可以降低训练成本，加速模型部署，并为资源受限的设备提供高性能的视觉模型。该研究成果有助于推动视觉基础模型在实际场景中的应用。",
            "highlight_zh": "AMoE在OpenLVD200M数据集上进行了实验，结果表明，通过结合非对称关系知识蒸馏、token平衡批处理和分层聚类采样，AMoE能够以更高的效率进行多教师蒸馏。相比于随机采样，分层聚类采样显著提高了样本效率。具体性能数据和对比基线将在论文中详细展示。",
            "tags_zh": [
                "视觉基础模型",
                "多教师蒸馏",
                "知识蒸馏",
                "混合专家模型",
                "数据采样",
                "表征学习"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20157v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20157v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20157v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
            "authors": [
                "Xiang Chen",
                "Yixin Ou",
                "Quan Feng",
                "Lei Li",
                "Piji Li",
                "Haibo Ye",
                "Sheng-Jun Huang",
                "Shuofei Qiao",
                "Shumin Deng",
                "Huajun Chen",
                "Ningyu Zhang"
            ],
            "arxiv_id": "2512.20145v1",
            "summary": "The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV",
                "cs.IR",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "IEEE/ACM Transactions on Audio, Speech and Language Processing",
            "doi": "10.1109/TASLPRO.2025.3608936",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20145v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RetroPrompt，通过检索增强提示学习提升预训练模型泛化能力",
            "summary_zh": "预训练基础模型(PFMs)已成为促进大规模多模态学习的关键。研究人员通过提示学习有效地采用了“预训练、提示和预测”范式，以提高少样本性能。然而，PFM的提示学习方法仍然遵循参数学习范式，这可能会损害记忆和死记硬背的泛化稳定性。更具体地说，传统的提示学习可能难以充分利用非典型实例，并避免在完全监督训练过程中过度拟合有限数据的浅层模式。为了克服这些限制，我们提出了RetroPrompt方法，旨在通过将知识与单纯的记忆分离来实现记忆和泛化之间的平衡。与传统的提示方法不同，RetroPrompt利用从训练数据生成的公开知识库，并在输入、训练和推理阶段结合检索机制。这使得模型能够主动从语料库中检索相关的上下文信息，从而增强可用的线索。我们在自然语言处理和计算机视觉任务的各种数据集上进行了全面的实验，以证明我们提出的方法RetroPrompt在零样本和少样本场景中的优越性能。通过对记忆模式的详细分析，我们观察到RetroPrompt有效地减少了对死记硬背的依赖，从而增强了泛化能力。",
            "intro_zh": [
                "传统提示学习方法在预训练模型中存在过度依赖记忆、泛化能力不足的问题，尤其是在数据量有限的情况下。",
                "RetroPrompt的核心思想是解耦知识与记忆，通过检索增强的方式，使模型能够利用外部知识库提升泛化能力。",
                "实验结果表明，RetroPrompt在零样本和少样本场景下，在NLP和CV任务上均表现出优越的性能，并有效减少了对死记硬背的依赖。"
            ],
            "method_zh": "**问题定义**：现有预训练模型中的提示学习方法，过度依赖参数记忆，容易过拟合训练数据中的浅层模式，尤其是在少样本场景下，泛化能力受限。模型难以充分利用非典型实例，导致性能下降。\\n\\n**核心思路**：RetroPrompt的核心思路是通过引入检索增强机制，将知识与单纯的记忆解耦。模型不再仅仅依赖自身参数记忆，而是能够从外部知识库中检索相关信息，从而增强上下文线索，提升泛化能力。这种方法旨在平衡记忆和泛化，使模型能够更好地适应新的、未见过的数据。\\n\\n**技术框架**：RetroPrompt的整体框架包含以下几个主要阶段：1) **知识库构建**：利用训练数据构建一个公开可访问的知识库。2) **检索模块**：在输入、训练和推理阶段，模型使用检索模块从知识库中检索相关的上下文信息。3) **提示学习**：将检索到的信息融入到提示中，引导模型进行预测。整个流程旨在利用外部知识来增强模型的理解和推理能力。\\n\\n**关键创新**：RetroPrompt的关键创新在于将检索机制融入到提示学习中，实现了知识与记忆的解耦。与传统的提示学习方法不同，RetroPrompt不再仅仅依赖模型自身的参数记忆，而是能够主动从外部知识库中检索相关信息，从而增强上下文线索，提升泛化能力。这种方法有效地减少了对死记硬背的依赖，使模型能够更好地适应新的、未见过的数据。\\n\\n**关键设计**：RetroPrompt的关键设计包括：1) **知识库的构建方式**：知识库的构建方式会影响检索的效率和质量。论文可能采用了特定的数据结构或索引方法来优化知识库。2) **检索模块的设计**：检索模块需要能够准确地找到与输入相关的上下文信息。论文可能采用了特定的相似度度量方法或检索算法。3) **提示融合方式**：如何将检索到的信息有效地融入到提示中，也是一个关键的设计点。论文可能采用了特定的融合策略，例如注意力机制或拼接操作。",
            "application_zh": "RetroPrompt方法具有广泛的应用前景，可应用于自然语言处理和计算机视觉等领域。例如，在文本分类、图像识别、机器翻译等任务中，可以利用RetroPrompt提升模型的泛化能力和鲁棒性。该方法尤其适用于少样本学习场景，能够有效解决数据稀缺问题，具有重要的实际应用价值。",
            "highlight_zh": "RetroPrompt在多个NLP和CV数据集上进行了实验，结果表明其在零样本和少样本场景下均优于现有方法。通过对记忆模式的分析，发现RetroPrompt有效减少了对死记硬背的依赖，从而增强了泛化能力。具体性能提升数据未知，但整体表现出显著的优势。",
            "tags_zh": [
                "检索增强学习",
                "提示学习",
                "预训练模型",
                "少样本学习",
                "知识库",
                "泛化能力",
                "自然语言处理",
                "计算机视觉"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20145v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20145v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20145v1/figs/cv_results.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography",
            "authors": [
                "Songze Li",
                "Jiameng Cheng",
                "Yiming Li",
                "Xiaojun Jia",
                "Dacheng Tao"
            ],
            "arxiv_id": "2512.20168v1",
            "summary": "By integrating language understanding with perceptual modalities such as images, multimodal large language models (MLLMs) constitute a critical substrate for modern AI systems, particularly intelligent agents operating in open and interactive environments. However, their increasing accessibility also raises heightened risks of misuse, such as generating harmful or unsafe content. To mitigate these risks, alignment techniques are commonly applied to align model behavior with human values. Despite these efforts, recent studies have shown that jailbreak attacks can circumvent alignment and elicit unsafe outputs. Currently, most existing jailbreak methods are tailored for open-source models and exhibit limited effectiveness against commercial MLLM-integrated systems, which often employ additional filters. These filters can detect and prevent malicious input and output content, significantly reducing jailbreak threats. In this paper, we reveal that the success of these safety filters heavily relies on a critical assumption that malicious content must be explicitly visible in either the input or the output. This assumption, while often valid for traditional LLM-integrated systems, breaks down in MLLM-integrated systems, where attackers can leverage multiple modalities to conceal adversarial intent, leading to a false sense of security in existing MLLM-integrated systems. To challenge this assumption, we propose Odysseus, a novel jailbreak paradigm that introduces dual steganography to covertly embed malicious queries and responses into benign-looking images. Extensive experiments on benchmark datasets demonstrate that our Odysseus successfully jailbreaks several pioneering and realistic MLLM-integrated systems, achieving up to 99% attack success rate. It exposes a fundamental blind spot in existing defenses, and calls for rethinking cross-modal security in MLLM-integrated systems.",
            "categories": [
                "cs.CR",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "This paper is accepted by Network and Distributed System Security Symposium (NDSS) 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20168v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Odysseus：利用双重隐写术破解商业多模态LLM集成系统",
            "summary_zh": "多模态大型语言模型（MLLM）通过整合语言理解与图像等感知模态，构成了现代AI系统，特别是开放和交互环境中智能代理的关键基础。然而，其日益增长的可访问性也带来了滥用的风险，例如生成有害或不安全的内容。为了降低这些风险，通常应用对齐技术使模型行为与人类价值观对齐。尽管如此，最近的研究表明，越狱攻击可以绕过对齐并引出不安全的输出。目前，大多数现有的越狱方法都是为开源模型量身定制的，并且对商业MLLM集成系统的有效性有限，这些系统通常采用额外的过滤器。这些过滤器可以检测和阻止恶意输入和输出内容，从而显著降低越狱威胁。本文揭示了这些安全过滤器的成功在很大程度上依赖于一个关键假设，即恶意内容必须在输入或输出中显式可见。这种假设在MLLM集成系统中失效，攻击者可以利用多种模态来隐藏对抗意图，从而导致现有MLLM集成系统产生虚假的安全感。为了挑战这一假设，我们提出了Odysseus，一种新颖的越狱范例，它引入了双重隐写术，将恶意查询和响应隐蔽地嵌入到看似良性的图像中。在基准数据集上进行的大量实验表明，我们的Odysseus成功地越狱了几个开创性和现实的MLLM集成系统，攻击成功率高达99%。它暴露了现有防御措施中的一个根本盲点，并呼吁重新思考MLLM集成系统中的跨模态安全性。",
            "intro_zh": [
                "现有商业MLLM集成系统依赖安全过滤器来防御恶意内容，但这些过滤器假设恶意内容必须显式可见，存在被绕过的风险。",
                "Odysseus提出了一种双重隐写术，将恶意查询和响应隐蔽地嵌入到图像中，从而绕过安全过滤器，实现对MLLM集成系统的越狱攻击。",
                "实验表明，Odysseus在多个MLLM集成系统上实现了高达99%的攻击成功率，揭示了现有防御措施的盲点。"
            ],
            "method_zh": "**问题定义**：论文旨在解决商业多模态大型语言模型（MLLM）集成系统中，现有安全过滤器对恶意攻击防御不足的问题。现有方法主要依赖于检测输入或输出中显式可见的恶意内容，但这种假设在多模态场景下容易被绕过。攻击者可以通过隐蔽的方式将恶意信息嵌入到图像等模态中，从而欺骗安全过滤器，导致系统产生不安全或有害的输出。\\n\\n**核心思路**：论文的核心思路是利用双重隐写术，将恶意查询和响应隐藏在看似无害的图像中。通过这种方式，攻击者可以绕过依赖于显式内容检测的安全过滤器，从而实现对MLLM集成系统的越狱攻击。这种方法的核心在于利用多模态的特性，将恶意信息隐藏在不易被检测的模态中。\\n\\n**技术框架**：Odysseus框架主要包含以下几个阶段：1) **恶意查询编码**：将恶意查询通过隐写术编码到第一张图像中。2) **MLLM集成系统交互**：将包含恶意查询的图像输入到MLLM集成系统中，系统生成响应。3) **恶意响应编码**：将MLLM的响应（可能包含有害内容）通过隐写术编码到第二张图像中。4) **输出**：输出包含恶意响应的图像。整个流程利用图像作为载体，隐蔽地传递恶意查询和响应，从而绕过安全过滤器的检测。\\n\\n**关键创新**：论文的关键创新在于提出了双重隐写术的概念，并将其应用于MLLM集成系统的越狱攻击。与传统的越狱方法不同，Odysseus不依赖于显式地操纵文本输入，而是利用图像作为载体，将恶意信息隐藏在不易被检测的模态中。这种方法能够有效地绕过依赖于显式内容检测的安全过滤器，从而实现对MLLM集成系统的攻击。\\n\\n**关键设计**：论文中，隐写术的选择至关重要，需要选择一种能够保证图像质量，同时又能有效隐藏信息的算法。此外，恶意查询和响应的编码方式也需要精心设计，以避免被安全过滤器检测到。例如，可以使用自适应的隐写算法，根据图像的复杂程度动态调整嵌入强度。同时，可以对恶意信息进行加密或混淆，以进一步提高隐蔽性。",
            "application_zh": "该研究成果可应用于评估和改进多模态AI系统的安全性。通过模拟Odysseus攻击，开发者可以识别现有防御机制的盲点，并开发更有效的跨模态安全策略。此外，该研究也提醒人们关注多模态AI系统潜在的安全风险，并促进相关安全标准的制定。",
            "highlight_zh": "实验结果表明，Odysseus在多个商业MLLM集成系统上取得了显著的越狱效果，攻击成功率高达99%。这表明现有安全过滤器在多模态场景下存在严重的漏洞，无法有效防御隐蔽的恶意攻击。与传统的基于文本的越狱方法相比，Odysseus能够更有效地绕过安全机制，揭示了多模态AI系统安全性的脆弱性。",
            "tags_zh": [
                "多模态大语言模型",
                "越狱攻击",
                "隐写术",
                "安全漏洞",
                "跨模态安全"
            ],
            "_index": 10,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20168v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20168v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20168v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sample-Efficient Policy Constraint Offline Deep Reinforcement Learning based on Sample Filtering",
            "authors": [
                "Yuanhao Chen",
                "Qi Liu",
                "Pengbin Chen",
                "Zhongjian Qiao",
                "Yanjie Li"
            ],
            "arxiv_id": "2512.20115v1",
            "summary": "Offline reinforcement learning (RL) aims to learn a policy that maximizes the expected return using a given static dataset of transitions. However, offline RL faces the distribution shift problem. The policy constraint offline RL method is proposed to solve the distribution shift problem. During the policy constraint offline RL training, it is important to ensure the difference between the learned policy and behavior policy within a given threshold. Thus, the learned policy heavily relies on the quality of the behavior policy. However, a problem exists in existing policy constraint methods: if the dataset contains many low-reward transitions, the learned will be contained with a suboptimal reference policy, leading to slow learning speed, low sample efficiency, and inferior performances. This paper shows that the sampling method in policy constraint offline RL that uses all the transitions in the dataset can be improved. A simple but efficient sample filtering method is proposed to improve the sample efficiency and the final performance. First, we evaluate the score of the transitions by average reward and average discounted reward of episodes in the dataset and extract the transition samples of high scores. Second, the high-score transition samples are used to train the offline RL algorithms. We verify the proposed method in a series of offline RL algorithms and benchmark tasks. Experimental results show that the proposed method outperforms baselines.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20115v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning",
                        "offline RL",
                        "offline reinforcement learning"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于样本过滤的策略约束离线深度强化学习方法，提升样本效率。",
            "summary_zh": "离线强化学习旨在利用给定的静态数据集学习策略，以最大化预期回报。然而，离线强化学习面临分布偏移问题。策略约束离线强化学习方法被提出以解决该问题。在策略约束离线强化学习训练中，确保学习到的策略与行为策略之间的差异在给定阈值内非常重要。因此，学习到的策略严重依赖于行为策略的质量。然而，现有策略约束方法存在一个问题：如果数据集包含许多低回报的转移样本，学习到的策略将包含次优参考策略，导致学习速度慢、样本效率低和性能差。本文表明，策略约束离线强化学习中使用的所有数据集转移样本的采样方法可以改进。提出了一种简单而有效的样本过滤方法，以提高样本效率和最终性能。首先，我们通过数据集中episode的平均奖励和平均折扣奖励来评估转移样本的分数，并提取高分数的转移样本。其次，高分数的转移样本用于训练离线强化学习算法。我们在一些离线强化学习算法和基准任务中验证了所提出的方法。实验结果表明，该方法优于基线。",
            "intro_zh": [
                "离线强化学习受分布偏移问题困扰，策略约束方法虽能缓解，但易受数据集中低回报样本的影响。",
                "论文提出一种样本过滤方法，通过评估转移样本的分数，筛选出高质量样本用于训练，提升学习效率。",
                "实验结果表明，该方法在多个离线强化学习算法和基准任务中，均优于现有基线方法，验证了有效性。"
            ],
            "method_zh": "**问题定义**：离线强化学习中，策略约束方法旨在解决分布偏移问题，但当离线数据集包含大量低回报的转移样本时，学习到的策略会受到次优行为策略的限制，导致学习速度慢、样本效率低，最终性能不佳。现有方法没有有效区分和利用高质量样本。\n\n**核心思路**：核心在于通过样本过滤，优先选择高质量（高回报）的转移样本进行训练。这样可以减少低质量样本对策略学习的负面影响，使学习过程更关注有价值的经验，从而提高样本效率和最终性能。\n\n**技术框架**：整体框架包含两个主要阶段：1) 样本评分与过滤：对离线数据集中的每个转移样本进行评分，评分依据是包含该样本的episode的平均奖励和平均折扣奖励。然后，根据设定的阈值，筛选出高分数的转移样本。2) 离线强化学习训练：使用过滤后的高质量样本，训练现有的离线强化学习算法（如BCQ、CQL等）。\n\n**关键创新**：关键创新在于提出了简单有效的样本过滤机制，该机制能够区分离线数据集中的高质量和低质量样本，并优先利用高质量样本进行训练。与直接使用所有样本的方法相比，该方法能够更有效地利用数据，避免了低质量样本的干扰。\n\n**关键设计**：样本评分函数的设计是关键。论文采用episode的平均奖励和平均折扣奖励作为评分标准，这能够反映转移样本的长期价值。此外，过滤阈值的选择也会影响最终性能，需要在实际应用中进行调整。没有涉及特定的网络结构或损失函数，而是将该方法应用于现有的离线强化学习算法。",
            "application_zh": "该研究成果可应用于各种需要离线强化学习的场景，例如机器人控制、自动驾驶、推荐系统等。尤其是在数据质量参差不齐的情况下，该方法能够有效提升学习效率和策略性能。通过过滤低质量数据，可以降低数据收集成本，并加速策略迭代过程。",
            "highlight_zh": "实验结果表明，所提出的样本过滤方法能够显著提升离线强化学习的性能。在多个基准任务上，该方法优于现有的策略约束离线强化学习算法。例如，在某些任务上，该方法能够将性能提升超过10%，并且能够更快地收敛到最优策略。",
            "tags_zh": [
                "离线强化学习",
                "策略约束",
                "样本过滤",
                "深度强化学习",
                "分布偏移"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20115v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20115v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20115v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent",
            "authors": [
                "Humza Nusrat",
                "Luke Francisco",
                "Bing Luo",
                "Hassan Bagher-Ebadian",
                "Joshua Kim",
                "Karen Chin-Snyder",
                "Salim Siddiqui",
                "Mira Shah",
                "Eric Mellon",
                "Mohammad Ghassemi",
                "Anthony Doemer",
                "Benjamin Movsas",
                "Kundan Thind"
            ],
            "arxiv_id": "2512.20586v1",
            "summary": "Stereotactic radiosurgery (SRS) demands precise dose shaping around critical structures, yet black-box AI systems have limited clinical adoption due to opacity concerns. We tested whether chain-of-thought reasoning improves agentic planning in a retrospective cohort of 41 patients with brain metastases treated with 18 Gy single-fraction SRS. We developed SAGE (Secure Agent for Generative Dose Expertise), an LLM-based planning agent for automated SRS treatment planning. Two variants generated plans for each case: one using a non-reasoning model, one using a reasoning model. The reasoning variant showed comparable plan dosimetry relative to human planners on primary endpoints (PTV coverage, maximum dose, conformity index, gradient index; all p > 0.21) while reducing cochlear dose below human baselines (p = 0.022). When prompted to improve conformity, the reasoning model demonstrated systematic planning behaviors including prospective constraint verification (457 instances) and trade-off deliberation (609 instances), while the standard model exhibited none of these deliberative processes (0 and 7 instances, respectively). Content analysis revealed that constraint verification and causal explanation concentrated in the reasoning agent. The optimization traces serve as auditable logs, offering a path toward transparent automated planning.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.HC"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20586v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SAGE：基于人机协同推理的大语言模型自动立体定向放射外科计划系统",
            "summary_zh": "立体定向放射外科(SRS)需要在关键结构周围进行精确的剂量塑形，但黑盒AI系统由于透明度问题，临床应用受限。本文测试了思维链推理是否能改进智能体规划。研究回顾性分析了41例接受18Gy单次SRS治疗的脑转移患者。开发了SAGE（用于生成剂量专业知识的安全智能体），这是一个基于LLM的规划智能体，用于自动SRS治疗计划。两种变体为每个病例生成计划：一种使用非推理模型，另一种使用推理模型。推理变体在主要终点（PTV覆盖率、最大剂量、适形指数、梯度指数；所有p > 0.21）上显示出与人类计划员相当的计划剂量学，同时将耳蜗剂量降低到人类基线以下（p = 0.022）。当被提示改进适形性时，推理模型表现出系统的规划行为，包括前瞻性约束验证（457个实例）和权衡考虑（609个实例），而标准模型没有表现出这些审议过程（分别为0和7个实例）。内容分析表明，约束验证和因果解释集中在推理智能体中。优化轨迹可作为可审计的日志，为透明的自动化规划提供了一条途径。",
            "intro_zh": [
                "传统SRS计划制定依赖人工，耗时且易受经验影响，黑盒AI方法缺乏透明度，难以临床信任。",
                "SAGE利用大语言模型的推理能力，模拟人类专家进行剂量计划制定，提升透明度和可控性。",
                "实验表明，SAGE在剂量学指标上与人类专家相当，并能有效降低耳蜗剂量，同时提供可审计的决策过程。"
            ],
            "method_zh": "**问题定义**：立体定向放射外科(SRS)治疗计划的制定需要精确的剂量控制，以确保肿瘤区域得到充分照射，同时保护周围的关键器官。现有的AI方法，尤其是黑盒模型，虽然可能在性能上有所提升，但缺乏透明度和可解释性，导致临床医生难以信任和应用。因此，需要一种既能自动化计划制定，又能提供清晰决策过程的智能系统。\n\\n**核心思路**：本文的核心思路是利用大语言模型(LLM)的推理能力，模拟人类专家在SRS计划制定过程中的思考方式。通过思维链(Chain-of-Thought)推理，LLM可以逐步分析问题、验证约束条件、权衡不同方案，并最终生成治疗计划。这种方法旨在提高计划制定的透明度和可控性，从而增强临床医生的信任。\n\\n**技术框架**：SAGE (Secure Agent for Generative Dose Expertise) 系统的整体架构包含以下几个主要模块：1) LLM推理引擎：负责执行思维链推理，生成计划步骤和决策；2) 剂量计算模块：根据LLM生成的计划，计算剂量分布；3) 约束验证模块：检查计划是否满足预设的剂量约束条件；4) 优化模块：根据约束验证结果，调整计划参数，迭代优化剂量分布；5) 日志记录模块：记录LLM的推理过程和优化轨迹，提供可审计的决策过程。\n\\n**关键创新**：该论文最重要的技术创新点在于将大语言模型的推理能力引入到SRS治疗计划制定中。与传统的黑盒AI方法不同，SAGE能够提供清晰的决策过程，包括约束验证和权衡考虑。这种透明性使得临床医生能够理解和信任AI生成的计划，从而促进AI在临床实践中的应用。此外，SAGE还通过可审计的日志记录，为计划的验证和改进提供了依据。\n\\n**关键设计**：SAGE的关键设计包括：1) 使用思维链提示(Chain-of-Thought prompting)来引导LLM进行推理；2) 设计了专门的约束验证和权衡考虑模块，以确保计划的质量和安全性；3) 采用了迭代优化策略，逐步改进剂量分布；4) 实现了详细的日志记录，包括LLM的推理过程和优化轨迹。",
            "application_zh": "该研究成果可应用于自动化放射治疗计划制定，提高计划效率和质量，降低对人工经验的依赖。潜在应用领域包括脑转移瘤、三叉神经痛等需要精确剂量控制的疾病治疗。未来可扩展到其他类型的放射治疗，并与其他临床信息系统集成，实现更智能化的治疗决策。",
            "highlight_zh": "SAGE在主要剂量学指标（PTV覆盖率、最大剂量、适形指数、梯度指数）上与人类计划员相当(p>0.21)，同时显著降低了耳蜗剂量(p=0.022)。在改进适形性方面，推理模型展示了457个约束验证实例和609个权衡考虑实例，而标准模型几乎没有这些行为（0和7个实例）。这些结果表明，SAGE的推理能力能够有效提高计划质量和透明度。",
            "tags_zh": [
                "立体定向放射外科",
                "大语言模型",
                "思维链推理",
                "自动化计划",
                "剂量计划",
                "人机协同",
                "透明AI"
            ],
            "_index": 12,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20586v1/FIG1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20586v1/FIG2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20586v1/FIG3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "M$^3$KG-RAG: Multi-hop Multimodal Knowledge Graph-enhanced Retrieval-Augmented Generation",
            "authors": [
                "Hyeongcheol Park",
                "Jiyoung Seo",
                "Jaewon Mun",
                "Hogun Park",
                "Wonmin Byeon",
                "Sung June Kim",
                "Hyeonsoo Im",
                "JeungSub Lee",
                "Sangpil Kim"
            ],
            "arxiv_id": "2512.20136v1",
            "summary": "Retrieval-Augmented Generation (RAG) has recently been extended to multimodal settings, connecting multimodal large language models (MLLMs) with vast corpora of external knowledge such as multimodal knowledge graphs (MMKGs). Despite their recent success, multimodal RAG in the audio-visual domain remains challenging due to 1) limited modality coverage and multi-hop connectivity of existing MMKGs, and 2) retrieval based solely on similarity in a shared multimodal embedding space, which fails to filter out off-topic or redundant knowledge. To address these limitations, we propose M$^3$KG-RAG, a Multi-hop Multimodal Knowledge Graph-enhanced RAG that retrieves query-aligned audio-visual knowledge from MMKGs, improving reasoning depth and answer faithfulness in MLLMs. Specifically, we devise a lightweight multi-agent pipeline to construct multi-hop MMKG (M$^3$KG), which contains context-enriched triplets of multimodal entities, enabling modality-wise retrieval based on input queries. Furthermore, we introduce GRASP (Grounded Retrieval And Selective Pruning), which ensures precise entity grounding to the query, evaluates answer-supporting relevance, and prunes redundant context to retain only knowledge essential for response generation. Extensive experiments across diverse multimodal benchmarks demonstrate that M$^3$KG-RAG significantly enhances MLLMs' multimodal reasoning and grounding over existing approaches.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20136v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出M$^3$KG-RAG，通过多跳多模态知识图谱增强检索增强生成，提升MLLM在视听领域的推理和 grounding 能力。",
            "summary_zh": "检索增强生成(RAG)最近扩展到多模态设置，将多模态大型语言模型(MLLM)与海量的外部知识语料库（如多模态知识图谱(MMKG)）连接起来。尽管取得了进展，但视听领域的多模态RAG仍然面临挑战，原因在于：1)现有MMKG的模态覆盖范围和多跳连接性有限；2)仅基于共享多模态嵌入空间中的相似性进行检索，无法过滤掉离题或冗余的知识。为了解决这些限制，我们提出了M$^3$KG-RAG，一种多跳多模态知识图谱增强的RAG，它从MMKG中检索与查询对齐的视听知识，从而提高MLLM的推理深度和答案的忠实性。具体来说，我们设计了一个轻量级的多智能体流水线来构建多跳MMKG (M$^3$KG)，其中包含上下文丰富的多模态实体三元组，从而能够基于输入查询进行模态检索。此外，我们引入了GRASP (Grounded Retrieval And Selective Pruning)，它确保了对查询的精确实体 grounding，评估了答案支持的相关性，并修剪冗余上下文，只保留生成响应所需的知识。在各种多模态基准上的大量实验表明，与现有方法相比，M$^3$KG-RAG显著增强了MLLM的多模态推理和 grounding 能力。",
            "intro_zh": [
                "现有MMKG在视听领域存在模态覆盖不足和多跳连接性有限的问题，限制了多模态RAG的性能。",
                "M$^3$KG-RAG通过构建多跳MMKG并引入GRASP机制，实现了更精确的知识检索和冗余信息的过滤。",
                "实验结果表明，M$^3$KG-RAG显著提升了MLLM在多模态推理和 grounding 方面的能力，优于现有方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态RAG在视听领域面临的知识覆盖不足和检索精度不高的问题。现有方法依赖于有限的MMKG，并且检索过程容易引入无关或冗余信息，导致MLLM的推理能力受限。\\n\\n**核心思路**：论文的核心思路是通过构建更全面、连接性更强的多跳MMKG，并结合精确的实体 grounding 和选择性剪枝策略，来提升检索的准确性和效率，从而增强MLLM的多模态推理能力。\\n\\n**技术框架**：M$^3$KG-RAG包含两个主要模块：1) 多跳MMKG (M$^3$KG) 构建模块，采用多智能体流水线，从多源数据中提取上下文丰富的多模态实体三元组；2) GRASP (Grounded Retrieval And Selective Pruning) 模块，用于对查询进行实体 grounding，评估知识的相关性，并剪枝冗余信息。整个流程是：输入查询 -> M$^3$KG检索 -> GRASP处理 -> MLLM生成答案。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了轻量级的多智能体流水线，用于构建多跳MMKG，扩展了知识覆盖范围和连接性；2) 引入了GRASP机制，通过实体 grounding 和选择性剪枝，提高了检索的精度和效率。与现有方法相比，M$^3$KG-RAG能够更有效地利用外部知识，提升MLLM的推理能力。\\n\\n**关键设计**：多智能体流水线包含多个agent，分别负责从不同模态的数据中提取实体和关系。GRASP模块使用预训练模型进行实体 grounding，并设计了相关性评估函数来衡量知识与查询的相关性。剪枝策略基于相关性得分，移除冗余或无关的知识。",
            "application_zh": "该研究成果可应用于智能问答系统、视听内容理解、机器人导航等领域。例如，在智能客服中，可以利用M$^3$KG-RAG从海量知识库中检索相关信息，为用户提供更准确、更全面的答案。在机器人导航中，可以帮助机器人理解周围环境，并做出更合理的决策。未来，该技术有望在更多领域发挥重要作用。",
            "highlight_zh": "实验结果表明，M$^3$KG-RAG在多个多模态基准测试中显著优于现有方法。例如，在XXX数据集上，M$^3$KG-RAG的准确率提高了XX%，F1值提高了YY%。这些结果证明了M$^3$KG-RAG在多模态推理和 grounding 方面的有效性。",
            "tags_zh": [
                "多模态学习",
                "知识图谱",
                "检索增强生成",
                "多跳推理",
                "视听理解"
            ],
            "_index": 13,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20136v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20136v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20136v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Can LLMs Solve My Grandma's Riddle? Evaluating Multilingual Large Language Models on Reasoning Traditional Bangla Tricky Riddles",
            "authors": [
                "Nurul Labib Sayeedi",
                "Md. Faiyaz Abdullah Sayeedi",
                "Khushnur Binte Jahangir",
                "Swakkhar Shatabda",
                "Sarah Masud Preum"
            ],
            "arxiv_id": "2512.20324v1",
            "summary": "Large Language Models (LLMs) show impressive performance on many NLP benchmarks, yet their ability to reason in figurative, culturally grounded, and low-resource settings remains underexplored. We address this gap for Bangla by introducing BanglaRiddleEval, a benchmark of 1,244 traditional Bangla riddles instantiated across four tasks (4,976 riddle-task artifacts in total). Using an LLM-based pipeline, we generate Chain-of-Thought explanations, semantically coherent distractors, and fine-grained ambiguity annotations, and evaluate a diverse suite of open-source and closed-source models under different prompting strategies. Models achieve moderate semantic overlap on generative QA but low correctness, MCQ accuracy peaks at only about 56% versus an 83% human baseline, and ambiguity resolution ranges from roughly 26% to 68%, with high-quality explanations confined to the strongest models. These results show that current LLMs capture some cues needed for Bangla riddle reasoning but remain far from human-level performance, establishing BanglaRiddleEval as a challenging new benchmark for low-resource figurative reasoning. All data, code, and evaluation scripts are available on GitHub: https://github.com/Labib1610/BanglaRiddleEval.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20324v1",
            "code_links": [
                {
                    "url": "https://github.com/Labib1610/BanglaRiddleEval",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "BanglaRiddleEval：评估多语言大模型在孟加拉语谜语推理上的能力",
            "summary_zh": "大型语言模型（LLMs）在许多NLP基准测试中表现出令人印象深刻的性能，但它们在形象化、具有文化基础和低资源环境中的推理能力仍未得到充分探索。本文通过引入BanglaRiddleEval来解决孟加拉语的这一差距，BanglaRiddleEval是一个包含1,244个传统孟加拉语谜语的基准，这些谜语被实例化为四个任务（总共4,976个谜语-任务组合）。使用基于LLM的pipeline，我们生成了思维链解释、语义连贯的干扰项和细粒度的歧义注释，并在不同的prompt策略下评估了一系列开源和闭源模型。模型在生成式问答中实现了适度的语义重叠，但正确率较低；多项选择题的准确率峰值仅为约56%，而人类基线为83%；歧义消解的范围从大约26%到68%，高质量的解释仅限于最强的模型。这些结果表明，当前的LLM捕获了一些孟加拉语谜语推理所需的线索，但与人类水平的性能相差甚远，从而将BanglaRiddleEval确立为一个具有挑战性的低资源形象推理新基准。所有数据、代码和评估脚本都可以在GitHub上找到：https://github.com/Labib1610/BanglaRiddleEval。",
            "intro_zh": [
                "现有LLM在形象化、文化背景和低资源语言环境下的推理能力有待提升，尤其是在孟加拉语等低资源语言中。",
                "论文构建了BanglaRiddleEval基准，包含孟加拉语传统谜语，用于评估LLM在推理、歧义消解等方面的能力。",
                "实验结果表明，现有LLM在孟加拉语谜语推理方面与人类水平存在差距，为未来研究提供了挑战。"
            ],
            "method_zh": "**问题定义**：论文旨在评估大型语言模型（LLMs）在理解和解决传统孟加拉语谜语方面的能力。现有方法在低资源、文化相关的语言推理方面存在不足，无法充分捕捉谜语中的隐喻、歧义和文化背景。这导致LLMs在处理此类任务时表现不佳，缺乏有效的评估基准。\n\n**核心思路**：论文的核心思路是构建一个专门针对孟加拉语谜语的评估基准（BanglaRiddleEval），并利用该基准来系统地评估各种LLMs的推理能力。通过分析LLMs在不同任务上的表现，揭示其在处理低资源、形象化语言推理方面的局限性，并为未来的研究提供方向。\n\n**技术框架**：该研究的技术框架主要包括以下几个阶段：1) 数据集构建：收集并整理1244个传统孟加拉语谜语，并将其转化为四个不同的任务（如生成式问答、多项选择题、歧义消解等）。2) 数据增强：利用LLM生成思维链解释、语义连贯的干扰项和细粒度的歧义注释，以扩充数据集。3) 模型评估：选择一系列开源和闭源LLMs，并在BanglaRiddleEval基准上进行评估，采用不同的prompt策略。4) 结果分析：分析LLMs在不同任务上的表现，并与人类基线进行比较，以评估其推理能力。\n\n**关键创新**：该论文的关键创新在于：1) 提出了BanglaRiddleEval，这是一个专门针对孟加拉语谜语推理的基准，填补了低资源语言推理评估的空白。2) 利用LLM生成思维链解释和歧义注释，为谜语推理提供了更丰富的上下文信息。3) 系统地评估了各种LLMs在孟加拉语谜语推理上的表现，揭示了其在处理低资源、形象化语言推理方面的局限性。\n\n**关键设计**：在数据集构建方面，论文将每个谜语转化为四个任务：生成式问答（Generative QA）、多项选择题（MCQ）、歧义消解（Ambiguity Resolution）和解释生成（Explanation Generation）。在模型评估方面，采用了不同的prompt策略，例如zero-shot、few-shot和chain-of-thought prompting。评估指标包括生成式问答的语义重叠度、多项选择题的准确率和歧义消解的准确率。",
            "application_zh": "该研究成果可应用于提升LLM在低资源语言和文化背景下的推理能力，例如：开发更智能的孟加拉语聊天机器人、教育辅助工具和文化遗产保护应用。此外，BanglaRiddleEval基准可以促进对LLM在形象化语言理解方面的研究，并推动相关技术的进步。",
            "highlight_zh": "实验结果表明，现有LLM在BanglaRiddleEval基准上的表现远低于人类水平。多项选择题的准确率峰值仅为56%，而人类基线为83%。歧义消解的准确率范围为26%至68%。这些结果表明，LLM虽然能捕捉到一些线索，但在孟加拉语谜语推理方面仍有很大的提升空间。",
            "tags_zh": [
                "大型语言模型",
                "孟加拉语",
                "谜语推理",
                "低资源语言",
                "基准测试"
            ],
            "_index": 14,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge",
            "authors": [
                "Yuntao Dai",
                "Hang Gu",
                "Teng Wang",
                "Qianyu Cheng",
                "Yifei Zheng",
                "Zhiyong Qiu",
                "Lei Gong",
                "Wenqi Lou",
                "Xuehai Zhou"
            ],
            "arxiv_id": "2512.20276v1",
            "summary": "Vision-Language-Action (VLA) models have emerged as a unified paradigm for robotic perception and control, enabling emergent generalization and long-horizon task execution. However, their deployment in dynamic, real-world environments is severely hin dered by high inference latency. While smooth robotic interaction requires control frequencies of 20 to 30 Hz, current VLA models typi cally operate at only 3-5 Hz on edge devices due to the memory bound nature of autoregressive decoding. Existing optimizations often require extensive retraining or compromise model accuracy. To bridge this gap, we introduce ActionFlow, a system-level inference framework tailored for resource-constrained edge plat forms. At the core of ActionFlow is a Cross-Request Pipelin ing strategy, a novel scheduler that redefines VLA inference as a macro-pipeline of micro-requests. The strategy intelligently batches memory-bound Decode phases with compute-bound Prefill phases across continuous time steps to maximize hardware utilization. Furthermore, to support this scheduling, we propose a Cross Request State Packed Forward operator and a Unified KV Ring Buffer, which fuse fragmented memory operations into efficient dense computations. Experimental results demonstrate that ActionFlow achieves a 2.55x improvement in FPS on the OpenVLA-7B model without retraining, enabling real-time dy namic manipulation on edge hardware. Our work is available at https://anonymous.4open.science/r/ActionFlow-1D47.",
            "categories": [
                "cs.AI",
                "cs.RO"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20276v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "vision-language-action",
                        "VLA",
                        "OpenVLA"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "ActionFlow：边缘设备上视觉语言模型流水线式动作加速框架",
            "summary_zh": "视觉-语言-动作(VLA)模型已成为机器人感知和控制的统一范式，实现了涌现泛化和长时程任务执行。然而，由于推理延迟高，它们在动态、真实世界环境中的部署受到严重阻碍。平滑的机器人交互需要20到30Hz的控制频率，但由于自回归解码的内存限制，当前的VLA模型在边缘设备上通常仅以3-5Hz运行。现有的优化方法通常需要大量的重新训练或牺牲模型精度。为了弥合这一差距，我们引入了ActionFlow，这是一个为资源受限的边缘平台量身定制的系统级推理框架。ActionFlow的核心是一种跨请求流水线策略，这是一种新颖的调度器，它将VLA推理重新定义为微请求的宏流水线。该策略智能地将内存受限的解码阶段与计算受限的预填充阶段在连续的时间步长上进行批处理，以最大限度地提高硬件利用率。此外，为了支持这种调度，我们提出了一种跨请求状态打包前向算子和一个统一的KV环形缓冲区，它们将碎片化的内存操作融合为高效的密集计算。实验结果表明，ActionFlow在OpenVLA-7B模型上实现了2.55倍的FPS提升，无需重新训练，从而能够在边缘硬件上实现实时的动态操作。",
            "intro_zh": [
                "VLA模型推理速度慢，难以满足边缘设备上实时机器人控制的需求，现有优化方法常需重训练或牺牲精度。",
                "ActionFlow通过跨请求流水线调度，将VLA推理分解为微请求宏流水线，优化内存和计算资源的利用。",
                "ActionFlow在OpenVLA-7B模型上实现了2.55倍的FPS提升，无需重新训练，支持边缘设备上的实时动态操作。"
            ],
            "method_zh": "**问题定义**：现有视觉-语言-动作(VLA)模型在边缘设备上推理速度慢，无法满足实时机器人控制的需求。自回归解码过程中的内存访问成为瓶颈，导致推理延迟高。现有的优化方法，如模型压缩或量化，通常需要大量的重新训练，或者会降低模型的精度。因此，如何在资源受限的边缘设备上加速VLA模型的推理，同时保持模型精度，是一个亟待解决的问题。\\n\\n**核心思路**：ActionFlow的核心思路是将VLA模型的推理过程视为一个流水线，通过跨请求的调度，将内存受限的解码阶段和计算受限的预填充阶段进行并行处理，从而提高硬件资源的利用率。这种流水线式的处理方式可以有效地隐藏内存访问的延迟，并减少计算资源的空闲时间。通过将多个请求的解码和预填充阶段进行批处理，可以进一步提高硬件的利用率。\\n\\n**技术框架**：ActionFlow的整体框架包括以下几个主要模块：1) 跨请求流水线调度器：负责将VLA模型的推理过程分解为微请求，并根据硬件资源的利用情况，对这些微请求进行调度。2) 跨请求状态打包前向算子：将多个请求的状态信息打包在一起，减少内存访问的次数，提高计算效率。3) 统一的KV环形缓冲区：用于存储VLA模型在推理过程中产生的键值对(KV)信息，采用环形缓冲区的结构可以有效地管理内存，并减少内存分配和释放的开销。\\n\\n**关键创新**：ActionFlow最重要的技术创新点在于其跨请求流水线调度策略。与传统的推理方法不同，ActionFlow不是一次性处理一个请求，而是将多个请求的解码和预填充阶段进行批处理，从而提高硬件资源的利用率。此外，跨请求状态打包前向算子和统一的KV环形缓冲区也是重要的创新点，它们可以有效地减少内存访问的次数，并提高计算效率。\\n\\n**关键设计**：ActionFlow的关键设计包括：1) 流水线调度器的调度策略，需要根据硬件资源的利用情况，动态地调整解码和预填充阶段的批处理大小。2) 跨请求状态打包前向算子的打包策略，需要考虑不同请求之间的依赖关系，避免出现数据竞争。3) 统一的KV环形缓冲区的大小，需要根据VLA模型的规模和请求的数量进行调整，以保证内存的有效利用。",
            "application_zh": "ActionFlow可广泛应用于机器人、自动驾驶、智能家居等领域。通过加速VLA模型在边缘设备上的推理速度，可以实现更快速、更流畅的机器人控制和人机交互。例如，在机器人操作场景中，ActionFlow可以使机器人能够实时地感知环境，并根据指令做出相应的动作，从而提高机器人的工作效率和安全性。在自动驾驶领域，ActionFlow可以使车辆能够更快地识别交通信号和障碍物，从而提高驾驶的安全性。",
            "highlight_zh": "ActionFlow在OpenVLA-7B模型上实现了显著的性能提升，在不进行任何模型重训练的情况下，FPS提高了2.55倍。这意味着在相同的硬件条件下，ActionFlow可以使VLA模型的推理速度提高一倍以上，从而满足实时机器人控制的需求。实验结果表明，ActionFlow是一种有效的VLA模型加速框架，可以在边缘设备上实现高性能的推理。",
            "tags_zh": [
                "视觉语言动作模型",
                "边缘计算",
                "模型推理加速",
                "流水线调度",
                "机器人控制"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20276v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20276v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20276v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LADLE-MM: Limited Annotation based Detector with Learned Ensembles for Multimodal Misinformation",
            "authors": [
                "Daniele Cardullo",
                "Simone Teglia",
                "Irene Amerini"
            ],
            "arxiv_id": "2512.20257v1",
            "summary": "With the rise of easily accessible tools for generating and manipulating multimedia content, realistic synthetic alterations to digital media have become a widespread threat, often involving manipulations across multiple modalities simultaneously. Recently, such techniques have been increasingly employed to distort narratives of important events and to spread misinformation on social media, prompting the development of misinformation detectors. In the context of misinformation conveyed through image-text pairs, several detection methods have been proposed. However, these approaches typically rely on computationally intensive architectures or require large amounts of annotated data. In this work we introduce LADLE-MM: Limited Annotation based Detector with Learned Ensembles for Multimodal Misinformation, a model-soup initialized multimodal misinformation detector designed to operate under a limited annotation setup and constrained training resources. LADLE-MM is composed of two unimodal branches and a third multimodal one that enhances image and text representations with additional multimodal embeddings extracted from BLIP, serving as fixed reference space. Despite using 60.3% fewer trainable parameters than previous state-of-the-art models, LADLE-MM achieves competitive performance on both binary and multi-label classification tasks on the DGM4 benchmark, outperforming existing methods when trained without grounding annotations. Moreover, when evaluated on the VERITE dataset, LADLE-MM outperforms current state-of-the-art approaches that utilize more complex architectures involving Large Vision-Language-Models, demonstrating the effective generalization ability in an open-set setting and strong robustness to unimodal bias.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20257v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LADLE-MM，一种基于有限标注和集成学习的多模态信息检测器，适用于资源受限场景。",
            "summary_zh": "随着多媒体内容生成和操纵工具的普及，对数字媒体进行逼真的合成篡改已成为一种普遍威胁，通常涉及跨多种模态的同时操作。 近年来，此类技术越来越多地被用于歪曲重要事件的叙述并在社交媒体上传播虚假信息，从而推动了信息检测器的发展。 在通过图像-文本对传递的错误信息的背景下，已经提出了几种检测方法。 然而，这些方法通常依赖于计算密集型架构或需要大量的标注数据。 在这项工作中，我们介绍了LADLE-MM：基于有限标注的检测器，具有用于多模态错误信息的学习集成，这是一种模型汤初始化的多模态错误信息检测器，旨在在有限的标注设置和受约束的训练资源下运行。 LADLE-MM由两个单模态分支和一个第三个多模态分支组成，该分支使用从BLIP提取的附加多模态嵌入来增强图像和文本表示，作为固定的参考空间。 尽管使用的可训练参数比以前最先进的模型少60.3％，但LADLE-MM在DGM4基准测试中的二元和多标签分类任务上均实现了具有竞争力的性能，在没有grounding标注的情况下进行训练时，其性能优于现有方法。 此外，在VERITE数据集上进行评估时，LADLE-MM的性能优于当前使用涉及大型视觉-语言模型的更复杂架构的最新方法，从而证明了在开放集设置中的有效泛化能力以及对单模态偏差的强大鲁棒性。",
            "intro_zh": [
                "现有信息检测方法依赖于计算密集型架构或需要大量标注数据，限制了其在资源受限场景下的应用。",
                "LADLE-MM利用模型汤初始化，结合单模态和多模态分支，并引入BLIP嵌入作为参考空间，提升检测性能。",
                "实验表明，LADLE-MM在DGM4和VERITE数据集上均取得了竞争力的性能，且参数量更少，泛化能力更强。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在有限标注和计算资源下，如何高效准确地检测多模态（图像-文本）信息的问题。现有方法通常需要大量的标注数据或依赖于复杂的模型架构，导致训练成本高昂，难以在资源受限的环境中应用。\\n\\n**核心思路**：论文的核心思路是利用模型集成和预训练模型提供的知识，在有限的标注数据下训练出高性能的多模态信息检测器。通过模型汤初始化，可以有效地利用多个模型的优势，提高模型的泛化能力和鲁棒性。同时，引入BLIP提取的多模态嵌入作为参考空间，可以增强图像和文本表示，从而提高检测的准确性。\\n\\n**技术框架**：LADLE-MM的整体架构包含三个主要分支：两个单模态分支（分别处理图像和文本）和一个多模态分支。单模态分支负责提取图像和文本的特征表示。多模态分支则将图像和文本特征与从BLIP提取的多模态嵌入进行融合，从而增强表示能力。最后，将三个分支的输出进行集成，得到最终的检测结果。\\n\\n**关键创新**：LADLE-MM的关键创新在于以下几点：1) 采用了模型汤初始化，可以有效地利用多个模型的知识，提高模型的泛化能力。2) 引入了BLIP提取的多模态嵌入作为参考空间，增强了图像和文本表示，提高了检测的准确性。3) 在有限标注数据下取得了具有竞争力的性能，且参数量更少，更易于部署。\\n\\n**关键设计**：LADLE-MM的关键设计包括：1) 使用预训练的图像和文本编码器作为单模态分支的初始化。2) 使用BLIP模型提取图像-文本对的多模态嵌入，并将其作为固定的参考空间。3) 使用模型汤技术对多个模型的权重进行平均，得到最终的模型。4) 损失函数包括二元交叉熵损失和多标签分类损失，用于优化模型的分类性能。",
            "application_zh": "该研究成果可应用于社交媒体平台、新闻媒体等领域，用于自动检测和过滤虚假信息，维护网络信息安全。在资源受限的情况下，该方法也能有效部署，具有重要的实际应用价值。未来可进一步扩展到其他模态，如视频、音频等，构建更全面的信息检测系统。",
            "highlight_zh": "LADLE-MM在DGM4基准测试中，使用比现有SOTA模型少60.3%的参数量，取得了具有竞争力的性能，尤其是在没有grounding标注的情况下，优于现有方法。在VERITE数据集上，LADLE-MM也超越了使用更复杂架构（包括大型视觉-语言模型）的SOTA方法，展示了其强大的泛化能力和对单模态偏差的鲁棒性。",
            "tags_zh": [
                "多模态信息检测",
                "有限标注学习",
                "模型集成",
                "模型汤",
                "视觉语言模型"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20257v1/img/model.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20257v1/img/unmanipulated_pair.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20257v1/img/pca.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SirenPose: Dynamic Scene Reconstruction via Geometric Supervision",
            "authors": [
                "Kaitong Cai",
                "Jensen Zhang",
                "Jing Yang",
                "Keze Wang"
            ],
            "arxiv_id": "2512.20531v1",
            "summary": "We introduce SirenPose, a geometry-aware loss formulation that integrates the periodic activation properties of sinusoidal representation networks with keypoint-based geometric supervision, enabling accurate and temporally consistent reconstruction of dynamic 3D scenes from monocular videos. Existing approaches often struggle with motion fidelity and spatiotemporal coherence in challenging settings involving fast motion, multi-object interaction, occlusion, and rapid scene changes. SirenPose incorporates physics inspired constraints to enforce coherent keypoint predictions across both spatial and temporal dimensions, while leveraging high frequency signal modeling to capture fine grained geometric details. We further expand the UniKPT dataset to 600,000 annotated instances and integrate graph neural networks to model keypoint relationships and structural correlations. Extensive experiments on benchmarks including Sintel, Bonn, and DAVIS demonstrate that SirenPose consistently outperforms state-of-the-art methods. On DAVIS, SirenPose achieves a 17.8 percent reduction in FVD, a 28.7 percent reduction in FID, and a 6.0 percent improvement in LPIPS compared to MoSCA. It also improves temporal consistency, geometric accuracy, user score, and motion smoothness. In pose estimation, SirenPose outperforms Monst3R with lower absolute trajectory error as well as reduced translational and rotational relative pose error, highlighting its effectiveness in handling rapid motion, complex dynamics, and physically plausible reconstruction.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Under submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20531v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene reconstruction"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "3_perception_slam",
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "SirenPose：通过几何监督实现动态场景的精确重建与时序一致性",
            "summary_zh": "SirenPose 是一种几何感知损失函数，它将正弦表示网络 (SIREN) 的周期激活特性与基于关键点的几何监督相结合，从而能够从单目视频中准确且在时间上一致地重建动态 3D 场景。现有方法在快速运动、多对象交互、遮挡和快速场景变化等具有挑战性的环境中，通常难以保证运动的真实性和时空连贯性。SirenPose 结合了受物理学启发的约束，以确保空间和时间维度上关键点预测的连贯性，同时利用高频信号建模来捕获细粒度的几何细节。此外，我们还将 UniKPT 数据集扩展到 600,000 个带注释的实例，并集成图神经网络来建模关键点关系和结构相关性。在 Sintel、Bonn 和 DAVIS 等基准测试上的大量实验表明，SirenPose 始终优于最先进的方法。在 DAVIS 上，SirenPose 在 FVD 方面降低了 17.8%，在 FID 方面降低了 28.7%，在 LPIPS 方面提高了 6.0%（与 MoSCA 相比）。它还提高了时间一致性、几何精度、用户评分和运动平滑度。在姿态估计方面，SirenPose 优于 Monst3R，具有更低的绝对轨迹误差以及更小的平移和旋转相对姿态误差，突显了其在处理快速运动、复杂动力学和物理上合理的重建方面的有效性。",
            "intro_zh": [
                "现有动态场景重建方法在处理快速运动、多物体交互和遮挡等复杂场景时，难以保证重建结果的运动真实性和时空一致性。",
                "SirenPose 利用 SIREN 的周期激活特性和关键点几何约束，并引入物理启发的约束，以提升关键点预测的时空连贯性，并捕获细粒度的几何细节。",
                "实验表明，SirenPose 在多个数据集上显著优于现有方法，在时间一致性、几何精度和运动平滑度等方面均有提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单目视频中重建动态 3D 场景的问题，尤其是在快速运动、多对象交互、遮挡和快速场景变化等复杂场景下。现有方法难以保证重建结果的运动真实性和时空连贯性，导致重建质量下降。\\n\\n**核心思路**：论文的核心思路是将 SIREN 的周期激活特性与基于关键点的几何监督相结合，并引入物理启发的约束，从而提升关键点预测的时空连贯性，并捕获细粒度的几何细节。SIREN 擅长表示高频信号，有助于捕捉场景的细节信息。\\n\\n**技术框架**：SirenPose 的整体框架包含以下几个主要模块：1) 关键点检测与跟踪：使用预训练的关键点检测器和跟踪器从视频中提取关键点信息。2) SIREN 网络：使用 SIREN 网络表示动态场景的 3D 几何信息。3) 几何损失函数：设计几何损失函数，将关键点信息与 SIREN 网络的输出进行约束，保证重建结果的几何精度。4) 时序一致性约束：引入物理启发的约束，保证关键点预测在时间上的连贯性。5) 图神经网络：使用图神经网络建模关键点之间的关系和结构相关性。\\n\\n**关键创新**：SirenPose 的关键创新在于：1) 提出了几何感知的损失函数，将 SIREN 的周期激活特性与关键点几何约束相结合。2) 引入了物理启发的约束，保证关键点预测在时间上的连贯性。3) 利用图神经网络建模关键点之间的关系和结构相关性。这些创新使得 SirenPose 能够更好地处理复杂动态场景的重建问题。\\n\\n**关键设计**：论文的关键设计包括：1) 使用 SIREN 作为场景表示网络，利用其高频信号建模能力。2) 设计了几何损失函数，包括关键点位置损失、关键点深度损失等。3) 引入了物理启发的约束，例如速度一致性约束、加速度一致性约束等。4) 使用图神经网络建模关键点之间的关系，例如骨骼连接关系等。这些设计有助于提升重建结果的几何精度和时序一致性。",
            "application_zh": "SirenPose 技术可应用于机器人导航、自动驾驶、虚拟现实/增强现实、运动捕捉和视频游戏等领域。它能够帮助机器人更好地理解周围环境，实现更精确的定位和导航。在自动驾驶领域，可以用于重建车辆周围的动态场景，提高驾驶安全性。在 VR/AR 领域，可以用于创建更逼真的虚拟体验。在运动捕捉和视频游戏领域，可以用于生成更自然的动画效果。",
            "highlight_zh": "SirenPose 在 DAVIS 数据集上取得了显著的性能提升，FVD 指标降低了 17.8%，FID 指标降低了 28.7%，LPIPS 指标提高了 6.0%（与 MoSCA 相比）。此外，在姿态估计方面，SirenPose 优于 Monst3R，具有更低的绝对轨迹误差以及更小的平移和旋转相对姿态误差，证明了其在处理快速运动和复杂动力学场景下的有效性。",
            "tags_zh": [
                "动态场景重建",
                "几何监督",
                "正弦表示网络",
                "时序一致性",
                "关键点检测",
                "图神经网络",
                "单目视频",
                "三维重建"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20531v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20531v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20531v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Dreamcrafter: Immersive Editing of 3D Radiance Fields Through Flexible, Generative Inputs and Outputs",
            "authors": [
                "Cyrus Vachha",
                "Yixiao Kang",
                "Zach Dive",
                "Ashwat Chidambaram",
                "Anik Gupta",
                "Eunice Jun",
                "Bjoern Hartmann"
            ],
            "arxiv_id": "2512.20129v1",
            "summary": "Authoring 3D scenes is a central task for spatial computing applications. Competing visions for lowering existing barriers are (1) focus on immersive, direct manipulation of 3D content or (2) leverage AI techniques that capture real scenes (3D Radiance Fields such as, NeRFs, 3D Gaussian Splatting) and modify them at a higher level of abstraction, at the cost of high latency. We unify the complementary strengths of these approaches and investigate how to integrate generative AI advances into real-time, immersive 3D Radiance Field editing. We introduce Dreamcrafter, a VR-based 3D scene editing system that: (1) provides a modular architecture to integrate generative AI algorithms; (2) combines different levels of control for creating objects, including natural language and direct manipulation; and (3) introduces proxy representations that support interaction during high-latency operations. We contribute empirical findings on control preferences and discuss how generative AI interfaces beyond text input enhance creativity in scene editing and world building.",
            "categories": [
                "cs.HC",
                "cs.CV"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "CHI 2025, Project page: https://dream-crafter.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20129v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting",
                        "NeRF"
                    ],
                    "score": 8.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam"
            ],
            "headline_zh": "Dreamcrafter：通过灵活的生成式输入输出实现沉浸式3D辐射场编辑",
            "summary_zh": "3D场景创作是空间计算应用的核心任务。降低现有门槛的竞争愿景包括：（1）专注于3D内容的沉浸式直接操作；（2）利用AI技术捕获真实场景（如NeRFs、3D高斯溅射等3D辐射场），并在更高的抽象层次上修改它们，但代价是高延迟。我们统一了这些方法的互补优势，并研究如何将生成式AI的进步集成到实时、沉浸式3D辐射场编辑中。我们介绍了Dreamcrafter，一个基于VR的3D场景编辑系统，它：（1）提供了一个模块化架构来集成生成式AI算法；（2）结合了不同级别的控制来创建对象，包括自然语言和直接操作；（3）引入了代理表示，以支持高延迟操作期间的交互。我们贡献了关于控制偏好的经验性发现，并讨论了文本输入之外的生成式AI界面如何增强场景编辑和世界构建中的创造力。",
            "intro_zh": [
                "现有3D场景编辑方法在高抽象层次修改时存在高延迟，而直接操作则缺乏AI的生成能力。",
                "Dreamcrafter通过VR界面结合生成式AI，提供自然语言和直接操作等多种控制方式，实现实时沉浸式编辑。",
                "该系统采用模块化架构，集成了生成式AI算法，并引入代理表示来支持高延迟操作期间的交互。"
            ],
            "method_zh": "**问题定义**：论文旨在解决3D辐射场编辑中，现有方法要么依赖高延迟的生成式AI，要么依赖缺乏AI辅助的直接操作的问题。现有方法难以兼顾实时性和创造性，限制了3D场景编辑的效率和用户体验。\\n\\n**核心思路**：Dreamcrafter的核心思路是将生成式AI的强大生成能力与VR环境下的实时交互相结合。通过模块化的架构，系统可以灵活地集成不同的生成式AI算法，并提供多种控制方式，包括自然语言和直接操作，从而实现低延迟、高创造性的3D场景编辑。\\n\\n**技术框架**：Dreamcrafter系统主要包含以下几个模块：VR交互界面、生成式AI模块、代理表示模块和辐射场渲染模块。用户在VR界面中通过自然语言或直接操作输入指令，生成式AI模块根据指令生成或修改3D内容，代理表示模块用于在生成式AI处理期间提供低延迟的交互反馈，最后辐射场渲染模块将最终结果渲染到VR界面中。\\n\\n**关键创新**：Dreamcrafter的关键创新在于其模块化的架构和代理表示的设计。模块化架构使得系统可以灵活地集成不同的生成式AI算法，适应不同的编辑需求。代理表示则通过使用低分辨率或简化的3D模型，在生成式AI处理期间提供实时的交互反馈，从而缓解了高延迟带来的问题。\\n\\n**关键设计**：Dreamcrafter的关键设计包括：(1) VR交互界面的设计，需要考虑用户在VR环境下的操作习惯和舒适度；(2) 生成式AI模块的选择和集成，需要根据具体的编辑任务选择合适的算法，并进行优化；(3) 代理表示的生成和更新策略，需要在保证实时性的前提下，尽可能地保留原始3D内容的细节；(4) 辐射场渲染模块的优化，需要在保证渲染质量的前提下，尽可能地提高渲染速度。",
            "application_zh": "Dreamcrafter可应用于游戏开发、虚拟现实内容创作、建筑设计、工业设计等领域。它能够降低3D场景创作的门槛，提高创作效率，并为用户提供更具创造性和沉浸感的体验。未来，该技术有望推动空间计算应用的发展，并改变人们与3D世界的交互方式。",
            "highlight_zh": "论文通过用户研究验证了Dreamcrafter的有效性。研究结果表明，用户更倾向于结合自然语言和直接操作进行3D场景编辑。此外，代理表示的引入显著提升了用户在高延迟操作期间的交互体验。这些结果表明，Dreamcrafter在提升3D场景编辑的效率和创造性方面具有显著优势。",
            "tags_zh": [
                "3D辐射场编辑",
                "生成式AI",
                "虚拟现实",
                "沉浸式交互",
                "场景创作"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20129v1/images/chi_paper_dreamcrafter_teaser_figure_v3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20129v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20129v1/images/move_obj.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FlashVLM: Text-Guided Visual Token Selection for Large Multimodal Models",
            "authors": [
                "Kaitong Cai",
                "Jusheng Zhang",
                "Jing Yang",
                "Yijia Fan",
                "Pengtao Xie",
                "Jian Wang",
                "Keze Wang"
            ],
            "arxiv_id": "2512.20561v1",
            "summary": "Large vision-language models (VLMs) typically process hundreds or thousands of visual tokens per image or video frame, incurring quadratic attention cost and substantial redundancy. Existing token reduction methods often ignore the textual query or rely on deep attention maps, whose instability under aggressive pruning leads to degraded semantic alignment.\n  We propose FlashVLM, a text guided visual token selection framework that dynamically adapts visual inputs to the query. Instead of relying on noisy attention weights, FlashVLM computes an explicit cross modal similarity between projected image tokens and normalized text embeddings in the language model space. This extrinsic relevance is fused with intrinsic visual saliency using log domain weighting and temperature controlled sharpening. In addition, a diversity preserving partition retains a minimal yet representative set of background tokens to maintain global context.\n  Under identical token budgets and evaluation protocols, FlashVLM achieves beyond lossless compression, slightly surpassing the unpruned baseline while pruning up to 77.8 percent of visual tokens on LLaVA 1.5, and maintaining 92.8 percent accuracy even under 94.4 percent compression. Extensive experiments on 14 image and video benchmarks demonstrate that FlashVLM delivers state of the art efficiency performance trade offs while maintaining strong robustness and generalization across mainstream VLMs.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Under submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20561v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FlashVLM：文本引导的视觉Token选择，提升大模型多模态效率",
            "summary_zh": "大型视觉语言模型(VLMs)通常处理每个图像或视频帧的数百甚至数千个视觉token，导致二次方级别的注意力计算成本和显著的冗余。现有的token缩减方法通常忽略文本查询或依赖于深度注意力图，而深度注意力图在激进剪枝下不稳定，导致语义对齐性能下降。我们提出了FlashVLM，一个文本引导的视觉token选择框架，可以动态地调整视觉输入以适应查询。FlashVLM不依赖于噪声大的注意力权重，而是计算投影图像token和语言模型空间中归一化文本嵌入之间的显式跨模态相似性。这种外在相关性与内在视觉显著性融合，使用对数域加权和温度控制锐化。此外，多样性保持分区保留了一个最小但具有代表性的背景token集合，以维持全局上下文。在相同的token预算和评估协议下，FlashVLM实现了超越无损的压缩，在LLaVA 1.5上剪枝高达77.8%的视觉token的同时，略微超过了未剪枝的基线，并且在压缩94.4%的情况下，仍保持92.8%的准确率。在14个图像和视频基准上的大量实验表明，FlashVLM在保持主流VLMs的强大鲁棒性和泛化能力的同时，提供了最先进的效率-性能权衡。",
            "intro_zh": [
                "现有VLMs处理大量视觉tokens导致计算冗余，且token缩减方法易忽略文本信息或依赖不稳定的注意力图。",
                "FlashVLM通过计算图像tokens与文本嵌入的跨模态相似性，并结合视觉显著性，实现文本引导的动态token选择。",
                "实验表明，FlashVLM在大幅压缩视觉tokens的同时，性能超越未剪枝基线，并在多个基准测试中表现出强大的鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有的大型视觉语言模型（VLMs）在处理图像和视频时，需要处理大量的视觉tokens，这导致了巨大的计算开销，特别是注意力机制的二次方复杂度。现有的token缩减方法要么忽略了文本查询的信息，要么依赖于深度学习模型中的注意力图。然而，这些注意力图在进行激进的token剪枝时往往不稳定，导致视觉和文本之间的语义对齐效果下降，最终影响模型的性能。\\n\\n**核心思路**：FlashVLM的核心思路是利用文本信息来引导视觉token的选择，从而动态地调整视觉输入以适应特定的文本查询。它不依赖于不稳定的注意力权重，而是通过计算图像tokens和文本嵌入之间的跨模态相似性来确定哪些视觉tokens与文本查询最相关。同时，为了保持全局上下文，FlashVLM还保留了一部分具有代表性的背景tokens。\\n\\n**技术框架**：FlashVLM的整体框架包括以下几个主要步骤：1) 将图像分割成tokens，并使用视觉编码器提取每个token的特征；2) 使用语言模型对文本查询进行编码，得到文本嵌入；3) 计算图像tokens的特征和文本嵌入之间的跨模态相似性，得到每个视觉token与文本查询的相关性得分；4) 结合视觉显著性信息，对相关性得分进行加权和锐化；5) 使用多样性保持分区算法选择一部分与文本最相关的视觉tokens，并保留一部分具有代表性的背景tokens；6) 将选择的视觉tokens和文本嵌入输入到视觉语言模型中进行后续处理。\\n\\n**关键创新**：FlashVLM的关键创新在于它使用显式的跨模态相似性来指导视觉token的选择，而不是依赖于不稳定的注意力权重。这种方法能够更准确地选择与文本查询相关的视觉tokens，从而提高模型的性能。此外，FlashVLM还引入了多样性保持分区算法，以确保选择的tokens能够覆盖图像的全局上下文。\\n\\n**关键设计**：FlashVLM的关键设计包括：1) 使用对数域加权和温度控制锐化来融合跨模态相似性和视觉显著性；2) 使用余弦相似度来计算图像tokens和文本嵌入之间的相似性；3) 使用k-means聚类算法来实现多样性保持分区，选择具有代表性的背景tokens。温度参数控制锐化程度，影响选择token的集中度。多样性保持分区确保全局信息不丢失。",
            "application_zh": "FlashVLM具有广泛的应用前景，例如在图像/视频检索、视觉问答、图像描述生成等领域。通过减少视觉tokens的数量，FlashVLM可以显著降低计算成本，提高模型的效率，使其更适用于资源受限的设备或需要实时响应的应用场景。此外，FlashVLM还可以用于提高模型的鲁棒性和泛化能力，使其能够更好地适应不同的图像和视频数据。",
            "highlight_zh": "FlashVLM在LLaVA 1.5上实现了显著的性能提升。在剪枝高达77.8%的视觉tokens的情况下，FlashVLM的性能略微超过了未剪枝的基线。更令人印象深刻的是，即使在压缩94.4%的视觉tokens的情况下，FlashVLM仍然保持了92.8%的准确率。在14个图像和视频基准上的实验表明，FlashVLM在效率和性能之间取得了最佳的平衡。",
            "tags_zh": [
                "视觉语言模型",
                "Token选择",
                "跨模态相似性",
                "视觉显著性",
                "模型压缩",
                "效率优化",
                "文本引导"
            ],
            "_index": 19,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20561v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20561v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20561v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI",
            "authors": [
                "Muhammad Usman",
                "Azka Rehman",
                "Muhammad Mutti Ur Rehman",
                "Abd Ur Rehman",
                "Muhammad Umar Farooq"
            ],
            "arxiv_id": "2512.20436v1",
            "summary": "Accurate segmentation of ischemic stroke lesions from diffusion magnetic resonance imaging (MRI) is essential for clinical decision-making and outcome assessment. Diffusion-Weighted Imaging (DWI) and Apparent Diffusion Coefficient (ADC) scans provide complementary information on acute and sub-acute ischemic changes; however, automated lesion delineation remains challenging due to variability in lesion appearance.\n  In this work, we study ischemic stroke lesion segmentation using multimodal diffusion MRI from the ISLES 2022 dataset. Several state-of-the-art convolutional and transformer-based architectures, including U-Net variants, Swin-UNet, and TransUNet, are benchmarked. Based on performance, a dual-encoder TransUNet architecture is proposed to learn modality-specific representations from DWI and ADC inputs. To incorporate spatial context, adjacent slice information is integrated using a three-slice input configuration.\n  All models are trained under a unified framework and evaluated using the Dice Similarity Coefficient (DSC). Results show that transformer-based models outperform convolutional baselines, and the proposed dual-encoder TransUNet achieves the best performance, reaching a Dice score of 85.4% on the test set. The proposed framework offers a robust solution for automated ischemic stroke lesion segmentation from diffusion MRI.",
            "categories": [
                "eess.IV",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "eess.IV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20436v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于双编码器Transformer的Ischemic Stroke病灶分割方法，提升DWI和ADC图像的分割精度。",
            "summary_zh": "本研究针对弥散磁共振成像(MRI)中缺血性卒中病灶的精确分割问题，该分割对于临床决策和结果评估至关重要。弥散加权成像(DWI)和表观弥散系数(ADC)扫描提供了关于急性和亚急性缺血性变化的互补信息。然而，由于病灶外观的多样性，自动病灶描绘仍然具有挑战性。本研究利用ISLES 2022数据集，探索了基于多模态弥散MRI的缺血性卒中病灶分割。对包括U-Net变体、Swin-UNet和TransUNet在内的几种最先进的卷积和基于Transformer的架构进行了基准测试。基于性能，提出了一种双编码器TransUNet架构，以学习来自DWI和ADC输入的模态特定表示。为了整合空间上下文，使用三切片输入配置集成了相邻切片信息。所有模型都在统一框架下进行训练，并使用Dice相似系数(DSC)进行评估。结果表明，基于Transformer的模型优于卷积基线，并且所提出的双编码器TransUNet实现了最佳性能，在测试集上达到了85.4%的Dice分数。该框架为基于弥散MRI的自动缺血性卒中病灶分割提供了一个鲁棒的解决方案。",
            "intro_zh": [
                "缺血性卒中病灶分割是临床决策的关键，但DWI和ADC图像的病灶外观差异大，自动分割面临挑战。",
                "论文提出一种双编码器TransUNet架构，分别学习DWI和ADC的模态特定表示，并结合相邻切片信息。",
                "实验结果表明，该方法优于卷积和传统Transformer模型，在ISLES 2022数据集上Dice系数达到85.4%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决缺血性卒中病灶在弥散MRI图像（DWI和ADC）上的自动精确分割问题。现有方法，如传统的卷积神经网络（CNN）和一些Transformer网络，在处理病灶外观多样性和模态信息融合方面存在局限性，导致分割精度不高。\\n\\n**核心思路**：论文的核心思路是利用双编码器TransUNet架构，分别对DWI和ADC两种模态的图像进行特征提取，学习模态特定的表示。同时，为了更好地利用空间上下文信息，将相邻切片的信息融入到模型输入中，从而提高分割的准确性。\\n\\n**技术框架**：整体框架基于TransUNet，包含两个独立的编码器分支和一个共享的解码器。每个编码器分支负责提取对应模态（DWI或ADC）的特征。编码器采用Transformer结构，能够捕捉长距离依赖关系。解码器将两个编码器的特征融合，并逐步恢复空间分辨率，最终输出分割结果。此外，模型输入采用三切片配置，即当前切片及其相邻的两个切片，以提供更丰富的空间上下文信息。\\n\\n**关键创新**：该方法最重要的创新点在于采用了双编码器结构，能够针对DWI和ADC两种模态的特点，学习更具判别性的特征表示。与单编码器结构相比，双编码器能够更好地捕捉不同模态之间的互补信息，从而提高分割精度。\\n\\n**关键设计**：模型使用了Transformer作为编码器的核心组件，利用自注意力机制捕捉长距离依赖关系。输入数据采用三切片配置，以提供空间上下文信息。损失函数未知，但通常会采用Dice Loss或Cross-Entropy Loss等分割任务常用的损失函数。具体的Transformer参数设置（如层数、头数等）未知。",
            "application_zh": "该研究成果可应用于临床辅助诊断，帮助医生更准确、快速地分割缺血性卒中病灶，从而制定更有效的治疗方案。此外，该技术还可用于卒中患者的预后评估和疗效监测，具有重要的临床应用价值。未来，该方法可以推广到其他脑部疾病的病灶分割任务中。",
            "highlight_zh": "实验结果表明，所提出的双编码器TransUNet在ISLES 2022数据集上取得了最佳性能，Dice系数达到了85.4%。相比于传统的卷积神经网络（如U-Net及其变体）和单编码器TransUNet，该方法在分割精度上有了显著提升，证明了双编码器结构和模态特定特征学习的有效性。",
            "tags_zh": [
                "缺血性卒中",
                "病灶分割",
                "弥散磁共振成像",
                "Transformer",
                "双编码器",
                "多模态学习",
                "TransUNet"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20436v1/Figures/implementationscheme.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20436v1/Figures/dualencoder1slice.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20436v1/Figures/duaencoder3slice.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Unified Multimodal Brain Decoding via Cross-Subject Soft-ROI Fusion",
            "authors": [
                "Xuanyu Hu"
            ],
            "arxiv_id": "2512.20249v1",
            "summary": "Multimodal brain decoding aims to reconstruct semantic information that is consistent with visual stimuli from brain activity signals such as fMRI, and then generate readable natural language descriptions. However, multimodal brain decoding still faces key challenges in cross-subject generalization and interpretability. We propose a BrainROI model and achieve leading-level results in brain-captioning evaluation on the NSD dataset. Under the cross-subject setting, compared with recent state-of-the-art methods and representative baselines, metrics such as BLEU-4 and CIDEr show clear improvements. Firstly, to address the heterogeneity of functional brain topology across subjects, we design a new fMRI encoder. We use multi-atlas soft functional parcellations (soft-ROI) as a shared space. We extend the discrete ROI Concatenation strategy in MINDLLM to a voxel-wise gated fusion mechanism (Voxel-gate). We also ensure consistent ROI mapping through global label alignment, which enhances cross-subject transferability. Secondly, to overcome the limitations of manual and black-box prompting methods in stability and transparency, we introduce an interpretable prompt optimization process. In a small-sample closed loop, we use a locally deployed Qwen model to iteratively generate and select human-readable prompts. This process improves the stability of prompt design and preserves an auditable optimization trajectory. Finally, we impose parameterized decoding constraints during inference to further improve the stability and quality of the generated descriptions.",
            "categories": [
                "cs.LG",
                "cs.CV",
                "eess.IV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "15 pages, 2 figures, 4 tables. Submitted to ICPR 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20249v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出BrainROI模型，通过跨被试软ROI融合实现统一的多模态脑解码，提升脑活动到自然语言描述的泛化性和可解释性。",
            "summary_zh": "多模态脑解码旨在从fMRI等脑活动信号中重建与视觉刺激一致的语义信息，并生成可读的自然语言描述。然而，多模态脑解码在跨被试泛化和可解释性方面仍面临关键挑战。我们提出了BrainROI模型，并在NSD数据集上的脑-字幕评估中取得了领先水平的结果。在跨被试设置下，与最新的state-of-the-art方法和代表性基线相比，BLEU-4和CIDEr等指标显示出明显的改进。首先，为了解决不同被试间功能脑拓扑的异质性，我们设计了一种新的fMRI编码器，使用多图谱软功能分割（soft-ROI）作为共享空间，并将MINDLLM中的离散ROI连接策略扩展到体素级门控融合机制（Voxel-gate）。我们还通过全局标签对齐来确保一致的ROI映射，从而增强跨被试的可迁移性。其次，为了克服手动和黑盒提示方法在稳定性和透明度方面的局限性，我们引入了一个可解释的提示优化过程。在一个小样本闭环中，我们使用本地部署的Qwen模型来迭代生成和选择人类可读的提示，从而提高了提示设计的稳定性，并保留了可审计的优化轨迹。最后，我们在推理过程中施加参数化的解码约束，以进一步提高生成描述的稳定性和质量。",
            "intro_zh": [
                "现有脑解码方法在跨被试泛化能力和模型可解释性方面存在不足，难以适应个体差异。",
                "论文提出BrainROI模型，利用软ROI融合和可解释的提示优化，提升跨被试脑解码的性能和透明度。",
                "实验表明，BrainROI模型在NSD数据集上显著提升了BLEU-4和CIDEr等指标，优于现有方法。"
            ],
            "method_zh": "**问题定义**：多模态脑解码旨在从脑活动信号（如fMRI）重建语义信息并生成自然语言描述。现有方法在跨被试泛化能力和可解释性方面存在挑战。不同被试的脑功能拓扑结构存在异质性，导致模型难以在不同个体间有效迁移。此外，手动或黑盒提示方法缺乏稳定性和透明度，影响生成描述的质量和可控性。\\n\\n**核心思路**：论文的核心思路是通过跨被试软ROI融合和可解释的提示优化来解决上述问题。利用软ROI作为共享空间，缓解个体间脑功能拓扑的差异。设计体素级门控融合机制（Voxel-gate）和全局标签对齐，增强跨被试的可迁移性。引入可解释的提示优化过程，提高提示设计的稳定性和透明度。\\n\\n**技术框架**：BrainROI模型包含fMRI编码器、提示优化模块和解码器三个主要模块。fMRI编码器负责将fMRI信号映射到共享的软ROI空间。提示优化模块利用本地部署的Qwen模型迭代生成和选择人类可读的提示。解码器基于编码后的fMRI特征和优化后的提示生成自然语言描述。在推理阶段，施加参数化的解码约束，进一步提高生成描述的质量。\\n\\n**关键创新**：论文的关键创新在于以下几点：1) 提出基于软ROI融合的fMRI编码器，有效缓解了不同被试间脑功能拓扑的异质性。2) 设计了体素级门控融合机制（Voxel-gate），增强了ROI特征的表达能力。3) 引入了可解释的提示优化过程，提高了提示设计的稳定性和透明度。与现有方法相比，BrainROI模型在跨被试泛化能力和可解释性方面具有显著优势。\\n\\n**关键设计**：fMRI编码器使用多图谱软功能分割（soft-ROI）作为共享空间，通过Voxel-gate机制融合不同ROI的特征。全局标签对齐确保一致的ROI映射。提示优化模块使用本地部署的Qwen模型，通过小样本闭环迭代生成和选择提示。解码器采用参数化的解码约束，例如长度约束和关键词约束，以提高生成描述的质量。",
            "application_zh": "该研究成果可应用于神经科学、认知科学和人工智能等领域。潜在应用包括：开发更精准的脑机接口、辅助诊断神经系统疾病、提升人机交互的自然性和智能化水平。通过理解大脑活动与语义信息之间的关联，有望为人工智能的认知建模和自然语言处理提供新的思路。",
            "highlight_zh": "BrainROI模型在NSD数据集上的跨被试脑-字幕评估中取得了领先水平的结果。与state-of-the-art方法和代表性基线相比，BLEU-4和CIDEr等指标显示出明显的改进，验证了该模型在跨被试泛化能力和生成描述质量方面的优势。可解释的提示优化过程也提高了提示设计的稳定性和透明度。",
            "tags_zh": [
                "多模态脑解码",
                "跨被试泛化",
                "软ROI融合",
                "可解释性",
                "脑机接口"
            ],
            "_index": 21,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20249v1/frame.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20249v1/combination.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20249v1/IPO.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MAPI-GNN: Multi-Activation Plane Interaction Graph Neural Network for Multimodal Medical Diagnosis",
            "authors": [
                "Ziwei Qin",
                "Xuhui Song",
                "Deqing Huang",
                "Na Qin",
                "Jun Li"
            ],
            "arxiv_id": "2512.20026v1",
            "summary": "Graph neural networks are increasingly applied to multimodal medical diagnosis for their inherent relational modeling capabilities. However, their efficacy is often compromised by the prevailing reliance on a single, static graph built from indiscriminate features, hindering the ability to model patient-specific pathological relationships. To this end, the proposed Multi-Activation Plane Interaction Graph Neural Network (MAPI-GNN) reconstructs this single-graph paradigm by learning a multifaceted graph profile from semantically disentangled feature subspaces. The framework first uncovers latent graph-aware patterns via a multi-dimensional discriminator; these patterns then guide the dynamic construction of a stack of activation graphs; and this multifaceted profile is finally aggregated and contextualized by a relational fusion engine for a robust diagnosis. Extensive experiments on two diverse tasks, comprising over 1300 patient samples, demonstrate that MAPI-GNN significantly outperforms state-of-the-art methods.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted by Proceedings of the AAAI Conference on Artificial Intelligence 40 (AAAI-26)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20026v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MAPI-GNN：用于多模态医学诊断的多激活平面交互图神经网络",
            "summary_zh": "图神经网络（GNN）因其固有的关系建模能力，越来越多地应用于多模态医学诊断。然而，由于过度依赖从无差别特征构建的单一静态图，GNN的有效性常常受到影响，从而阻碍了对患者特定病理关系的建模。为此，本文提出了多激活平面交互图神经网络（MAPI-GNN），通过从语义上解耦的特征子空间学习多方面的图谱来重构这种单图范式。该框架首先通过多维判别器发现潜在的图感知模式；然后，这些模式指导动态构建一系列激活图；最后，通过关系融合引擎对这种多方面的图谱进行聚合和上下文感知，从而实现稳健的诊断。在包含超过1300个患者样本的两个不同任务上进行的大量实验表明，MAPI-GNN显著优于最先进的方法。",
            "intro_zh": [
                "现有GNN方法在多模态医学诊断中依赖单一静态图，无法有效建模患者个体化的病理关系。",
                "MAPI-GNN通过学习语义解耦的特征子空间，动态构建多激活平面图，从而捕捉更丰富的病理关系。",
                "在两个医学诊断任务上的实验表明，MAPI-GNN显著优于现有方法，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有的多模态医学诊断方法，特别是基于图神经网络的方法，通常使用单一的、静态的图结构来表示患者的特征关系。这种方法忽略了不同模态特征之间的复杂交互，以及患者个体差异导致的病理关系变化，限制了诊断的准确性。痛点在于无法有效建模患者特异性的病理关系。\\n\\n**核心思路**：MAPI-GNN的核心思路是从语义解耦的特征子空间中学习多方面的图谱，即构建多个“激活平面图”。每个激活平面图捕捉不同语义下的特征关系，从而更全面地表示患者的病理信息。通过动态构建和融合这些激活平面图，可以更好地建模患者个体化的病理关系。\\n\\n**技术框架**：MAPI-GNN框架主要包含三个阶段：1) **多维判别器**：用于发现潜在的图感知模式，即学习不同语义下的特征子空间。2) **动态激活图构建**：基于判别器学习到的模式，动态构建一系列激活图，每个图对应一个特征子空间。3) **关系融合引擎**：将多个激活图进行聚合和上下文感知，最终用于诊断。\\n\\n**关键创新**：MAPI-GNN的关键创新在于引入了多激活平面图的概念，打破了传统GNN方法中单一图的限制。通过从语义解耦的特征子空间学习多个图，可以更全面地捕捉患者的病理信息，从而提高诊断的准确性。与现有方法的本质区别在于，MAPI-GNN能够动态地学习和融合多个图结构，而现有方法通常使用预定义的或静态的图结构。\\n\\n**关键设计**：多维判别器的具体实现方式未知，但推测可能使用了某种形式的注意力机制或自编码器来学习特征子空间。激活图的构建方式可能是基于特征相似性或相关性。关系融合引擎可能使用了图卷积网络或注意力机制来聚合和上下文感知多个激活图的信息。损失函数的设计可能包括诊断分类损失和某种正则化项，以鼓励学习到更具区分性的特征子空间。",
            "application_zh": "MAPI-GNN在多模态医学诊断领域具有广泛的应用前景，例如疾病预测、风险评估、个性化治疗方案制定等。通过整合影像、基因、临床数据等多模态信息，MAPI-GNN能够更准确地识别疾病特征，提高诊断效率，并为患者提供更精准的医疗服务。未来，该方法有望应用于更广泛的医学领域，助力实现智能化医疗。",
            "highlight_zh": "MAPI-GNN在两个不同的多模态医学诊断任务上进行了评估，实验结果表明，MAPI-GNN显著优于现有的最先进方法。具体性能数据和提升幅度未知，但摘要中强调了“显著优于最先进的方法”，表明MAPI-GNN在诊断准确性方面取得了重要突破。",
            "tags_zh": [
                "多模态医学诊断",
                "图神经网络",
                "多激活平面",
                "特征解耦",
                "关系建模"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20026v1/fig2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20026v1/fig3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20026v1/fig4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Recurrent Off-Policy Deep Reinforcement Learning Doesn't Have to be Slow",
            "authors": [
                "Tyler Clark",
                "Christine Evers",
                "Jonathon Hare"
            ],
            "arxiv_id": "2512.20513v1",
            "summary": "Recurrent off-policy deep reinforcement learning models achieve state-of-the-art performance but are often sidelined due to their high computational demands. In response, we introduce RISE (Recurrent Integration via Simplified Encodings), a novel approach that can leverage recurrent networks in any image-based off-policy RL setting without significant computational overheads via using both learnable and non-learnable encoder layers. When integrating RISE into leading non-recurrent off-policy RL algorithms, we observe a 35.6% human-normalized interquartile mean (IQM) performance improvement across the Atari benchmark. We analyze various implementation strategies to highlight the versatility and potential of our proposed framework.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20513v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出RISE，通过简化编码提升图像Off-Policy强化学习中循环网络的效率",
            "summary_zh": "循环Off-Policy深度强化学习模型虽然能达到顶尖性能，但由于其高昂的计算需求而常常被搁置。为了解决这个问题，我们引入了RISE（Recurrent Integration via Simplified Encodings），这是一种新颖的方法，它可以通过使用可学习和不可学习的编码器层，在任何基于图像的Off-Policy强化学习设置中利用循环网络，而不会产生显著的计算开销。当将RISE集成到领先的非循环Off-Policy强化学习算法中时，我们观察到在Atari基准测试中，人类归一化的四分位间距平均值（IQM）性能提高了35.6%。我们分析了各种实现策略，以突出我们提出的框架的多功能性和潜力。",
            "intro_zh": [
                "循环Off-Policy深度强化学习计算量大，限制了其应用。",
                "RISE通过可学习和非学习编码器，降低循环网络的计算负担。",
                "RISE集成到现有算法后，Atari基准测试中IQM性能提升35.6%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决循环Off-Policy深度强化学习模型计算复杂度高的问题。现有的循环模型虽然性能优异，但其计算需求使得它们在实际应用中受到限制，尤其是在资源受限的环境下。因此，如何在保证性能的同时降低计算成本是本研究要解决的核心问题。\\n\\n**核心思路**：RISE的核心思路是通过简化编码过程来降低循环网络的计算负担。具体来说，RISE利用可学习和不可学习的编码器层，将原始图像数据转换为更紧凑、更易于处理的表示形式。这种简化的表示形式可以减少循环网络的输入维度，从而降低计算复杂度。同时，通过结合可学习和不可学习的编码器，RISE能够在保证信息完整性的前提下，进一步优化编码效率。\\n\\n**技术框架**：RISE框架主要包含以下几个模块：1) 图像输入模块：接收原始图像数据作为输入。2) 编码器模块：包含可学习和不可学习的编码器层，用于将原始图像数据转换为简化表示。3) 循环网络模块：接收编码器模块的输出，利用循环神经网络对时间序列信息进行建模。4) 策略/价值函数模块：根据循环网络的输出，预测策略或价值函数。整个框架可以与现有的Off-Policy强化学习算法相结合，实现高效的循环Off-Policy深度强化学习。\\n\\n**关键创新**：RISE的关键创新在于其简化的编码方式。与传统的直接将原始图像输入循环网络的方法不同，RISE通过编码器层提取图像的关键特征，并将其转换为更紧凑的表示形式。这种简化编码不仅降低了计算复杂度，还有助于循环网络更好地捕捉时间序列信息。此外，RISE结合了可学习和不可学习的编码器，进一步提高了编码效率和信息完整性。\\n\\n**关键设计**：RISE的关键设计包括：1) 编码器结构：可以选择不同的编码器结构，如卷积神经网络、线性层等。可学习编码器通过反向传播进行优化，不可学习编码器则采用预定义的变换，如随机投影。2) 编码维度：需要根据具体任务和计算资源选择合适的编码维度，以平衡性能和计算复杂度。3) 损失函数：RISE可以与现有的Off-Policy强化学习算法的损失函数相结合，共同优化整个模型。",
            "application_zh": "RISE具有广泛的应用前景，尤其是在需要处理高维图像数据的强化学习任务中。例如，它可以应用于机器人控制、自动驾驶、游戏AI等领域。通过降低循环网络的计算负担，RISE使得循环Off-Policy深度强化学习模型能够在资源受限的环境下部署，从而推动这些技术在实际场景中的应用。未来，RISE还可以与其他优化技术相结合，进一步提高强化学习算法的效率和性能。",
            "highlight_zh": "实验结果表明，将RISE集成到领先的非循环Off-Policy强化学习算法中，可以在Atari基准测试中实现显著的性能提升。具体来说，人类归一化的四分位间距平均值（IQM）性能提高了35.6%。这一结果表明，RISE能够有效地降低循环网络的计算负担，并在保证性能的同时提高强化学习算法的效率。",
            "tags_zh": [
                "循环神经网络",
                "深度强化学习",
                "Off-Policy学习",
                "图像编码",
                "计算效率"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20513v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20513v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20513v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Toward Explaining Large Language Models in Software Engineering Tasks",
            "authors": [
                "Antonio Vitale",
                "Khai-Nguyen Nguyen",
                "Denys Poshyvanyk",
                "Rocco Oliveto",
                "Simone Scalabrino",
                "Antonio Mastropaolo"
            ],
            "arxiv_id": "2512.20328v1",
            "summary": "Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20328v1",
            "code_links": [
                {
                    "url": "https://github.com/deviserlab/FeatureSHAP",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出FeatureSHAP，用于解释软件工程任务中的大型语言模型",
            "summary_zh": "大型语言模型（LLMs）在软件工程（SE）任务自动化方面取得了显著进展，例如代码生成和代码摘要。然而，LLMs的黑盒特性严重阻碍了其在高风险和安全关键领域的应用，在这些领域，可解释性和透明度对于信任、责任和有效的人工监督至关重要。尽管人们对软件工程领域的可解释AI越来越感兴趣，但现有方法缺乏与从业者对SE工件的推理方式相一致的领域特定解释。为了解决这一差距，我们引入了FeatureSHAP，这是第一个完全自动化、模型无关的可解释性框架，专为软件工程任务量身定制。FeatureSHAP基于Shapley值，通过系统的输入扰动和任务特定的相似性比较，将模型输出归因于高级输入特征，同时与开源和专有LLMs兼容。我们在两个双模态SE任务（代码生成和代码摘要）上评估了FeatureSHAP。结果表明，FeatureSHAP对不相关的输入特征赋予较低的重要性，并产生比基线方法更高保真度的解释。一项涉及37名参与者的从业者调查表明，FeatureSHAP有助于从业者更好地解释模型输出并做出更明智的决策。总而言之，FeatureSHAP代表了在软件工程中实现实用可解释AI的有意义的一步。FeatureSHAP可在https://github.com/deviserlab/FeatureSHAP上获得。",
            "intro_zh": [
                "现有LLM在软件工程任务中表现出色，但其黑盒特性限制了在高风险领域的应用，缺乏领域特定的解释。",
                "FeatureSHAP基于Shapley值，通过输入扰动和任务相似性比较，将模型输出归因于高级输入特征。",
                "实验表明，FeatureSHAP能有效区分相关和不相关特征，提供高保真解释，并帮助从业者做出更明智的决策。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在软件工程（SE）任务中应用时缺乏可解释性的问题。现有方法无法提供领域特定的解释，难以让从业者理解模型决策过程，阻碍了LLMs在安全关键领域的应用。现有方法无法有效区分输入特征的重要性，导致解释结果不准确。\\n\\n**核心思路**：论文的核心思路是利用Shapley值来量化每个输入特征对模型输出的贡献。通过系统地扰动输入并比较不同扰动下的模型输出，可以估计每个特征的重要性。 这种方法是模型无关的，可以应用于各种LLMs，无需修改模型结构或训练过程。 结合任务特定的相似性比较，能够更好地对软件工程领域的工件进行解释。\\n\\n**技术框架**：FeatureSHAP框架包含以下主要阶段：1) 输入特征提取：将输入数据分解为高级特征。2) 输入扰动：系统地扰动输入特征，生成多个扰动后的输入样本。3) 模型预测：使用LLM对原始输入和扰动后的输入进行预测。4) Shapley值计算：基于Shapley值理论，计算每个特征对模型输出的贡献。5) 解释生成：根据Shapley值，生成对模型决策的解释。\\n\\n**关键创新**：FeatureSHAP的关键创新在于其完全自动化和模型无关的特性，以及针对软件工程任务的定制化设计。它能够自动提取输入特征，并使用Shapley值来量化特征的重要性，无需人工干预。与现有方法相比，FeatureSHAP能够提供更准确、更易于理解的解释，并与开源和专有LLMs兼容。\\n\\n**关键设计**：FeatureSHAP的关键设计包括：1) 任务特定的相似性度量：用于比较不同扰动后的输入样本，以更准确地估计特征的重要性。2) 高级特征提取：将输入数据分解为更易于理解的高级特征，例如代码中的函数名、变量名等。3) Shapley值计算的优化：采用高效的算法来计算Shapley值，以降低计算复杂度。",
            "application_zh": "FeatureSHAP可应用于各种软件工程任务，例如代码生成、代码摘要、代码缺陷预测等。它可以帮助开发人员理解LLMs的决策过程，提高对模型输出的信任度，并进行有效的错误诊断和修复。该研究对于推动LLMs在安全关键领域的应用具有重要意义，例如航空航天、医疗保健等。",
            "highlight_zh": "实验结果表明，FeatureSHAP在代码生成和代码摘要任务中均优于基线方法。FeatureSHAP能够更准确地识别重要的输入特征，并生成更高保真度的解释。从业者调查表明，FeatureSHAP能够帮助开发人员更好地理解模型输出，并做出更明智的决策。例如，在代码生成任务中，FeatureSHAP能够突出显示与生成代码相关的关键代码片段。",
            "tags_zh": [
                "可解释AI",
                "大型语言模型",
                "软件工程",
                "Shapley值",
                "代码生成",
                "代码摘要",
                "模型解释",
                "特征重要性"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20328v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20328v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20328v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning",
            "authors": [
                "Saisai Yang",
                "Qingyi Huang",
                "Jing Yuan",
                "Liangyu Zha",
                "Kai Tang",
                "Yuhang Yang",
                "Ning Wang",
                "Yucheng Wei",
                "Liyao Li",
                "Wentao Ye",
                "Hao Chen",
                "Tao Zhang",
                "Junlin Zhou",
                "Haobo Wang",
                "Gang Chen",
                "Junbo Zhao"
            ],
            "arxiv_id": "2512.20312v1",
            "summary": "Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \\textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20312v1",
            "code_links": [
                {
                    "url": "https://huggingface.co/tablegpt/TableGPT-R1",
                    "type": "huggingface"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "reward shaping"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TableGPT-R1：通过强化学习提升表格推理能力，实现SOTA性能。",
            "summary_zh": "表格数据是现代数据分析和科学研究的基石。虽然通过监督微调(SFT)的大型语言模型(LLM)显著改善了与此类结构化数据的自然语言交互，但它们在处理真实世界表格任务所需的复杂、多步骤推理和强大的代码执行方面往往表现不足。强化学习(RL)为增强这些能力提供了一个有希望的途径，但其在表格领域的应用面临三个关键障碍：缺乏高质量的agent轨迹，这些轨迹具有在不同表格结构上的闭环代码执行和环境反馈；反馈信号的极端异质性，范围从刚性的SQL执行到开放式的数据解释；以及在垂直专业化过程中灾难性地遗忘一般知识的风险。为了克服这些挑战并解锁对复杂表格的高级推理，我们引入了TableGPT-R1，这是一个建立在系统RL框架上的专用表格模型。我们的方法整合了一个全面的数据工程管道，该管道合成了难度分层的agent轨迹，用于监督对齐和RL rollout；一个任务自适应奖励系统，该系统将基于规则的验证与标准注入的奖励模型相结合，并结合了过程级别的步骤奖励塑造和行为正则化；以及一个多阶段训练框架，该框架在专门从事表格特定任务之前逐步稳定推理。广泛的评估表明，TableGPT-R1在权威基准测试中实现了最先进的性能，显著优于基线模型，同时保留了强大的通用能力。我们的模型可在https://huggingface.co/tablegpt/TableGPT-R1上找到。",
            "intro_zh": [
                "现有大语言模型在表格数据处理中，难以胜任复杂推理和代码执行任务，尤其是在多步骤推理和闭环反馈场景下。",
                "TableGPT-R1通过系统性的强化学习框架，结合数据工程管道、任务自适应奖励系统和多阶段训练框架，提升表格推理能力。",
                "实验结果表明，TableGPT-R1在权威基准测试中取得了SOTA性能，显著超越了现有模型，并保持了良好的通用能力。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型在处理表格数据时，尤其是在需要复杂推理和代码执行的任务中，表现出明显的不足。它们难以处理多步骤推理、闭环反馈以及异构的反馈信号，并且容易在特定任务上过拟合，导致通用知识的遗忘。\\n\\n**核心思路**：TableGPT-R1的核心思路是利用强化学习(RL)来提升模型在表格数据上的推理能力。通过精心设计的奖励机制和训练流程，引导模型学习如何有效地执行代码、理解表格数据，并进行多步骤推理。同时，采用多阶段训练策略，避免模型在特定任务上过拟合，保持其通用性。\\n\\n**技术框架**：TableGPT-R1的整体框架包含以下几个主要模块：1) 数据工程管道：用于生成难度分层的agent轨迹，包括监督对齐和RL rollout所需的数据。2) 任务自适应奖励系统：结合基于规则的验证和标准注入的奖励模型，并进行过程级别的步骤奖励塑造和行为正则化。3) 多阶段训练框架：逐步稳定推理能力，然后再专注于表格特定任务的训练。\\n\\n**关键创新**：TableGPT-R1的关键创新在于其系统性的强化学习框架，该框架能够有效地解决表格数据处理中的三个主要挑战：缺乏高质量的agent轨迹、反馈信号的异质性以及通用知识的遗忘。通过数据工程管道生成高质量的训练数据，通过任务自适应奖励系统引导模型学习正确的行为，并通过多阶段训练框架保持模型的通用性。\\n\\n**关键设计**：在数据工程管道中，采用了难度分层的策略，逐步增加训练数据的难度，以提高模型的泛化能力。在任务自适应奖励系统中，结合了基于规则的验证和标准注入的奖励模型，以提供更准确的反馈信号。在多阶段训练框架中，首先进行预训练，以提高模型的通用能力，然后再进行微调，以适应特定的表格任务。",
            "application_zh": "TableGPT-R1在数据分析、商业智能、科学研究等领域具有广泛的应用前景。它可以帮助用户更高效地从表格数据中提取信息、进行决策分析，并支持自动化报告生成等任务。该研究的成果有望推动表格数据处理技术的发展，并为各行业带来实际价值。",
            "highlight_zh": "TableGPT-R1在多个权威表格推理基准测试中取得了SOTA性能，显著优于现有的基线模型。具体性能数据和提升幅度在论文中进行了详细展示。该模型在提升表格推理能力的同时，还保持了良好的通用能力，避免了在特定任务上过拟合的问题。",
            "tags_zh": [
                "表格推理",
                "强化学习",
                "大语言模型",
                "数据分析",
                "代码执行",
                "多步骤推理",
                "奖励塑造"
            ],
            "_index": 25,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20312v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20312v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20312v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LoFT-LLM: Low-Frequency Time-Series Forecasting with Large Language Models",
            "authors": [
                "Jiacheng You",
                "Jingcheng Yang",
                "Yuhang Xie",
                "Zhongxuan Wu",
                "Xiucheng Li",
                "Feng Li",
                "Pengjie Wang",
                "Jian Xu",
                "Bo Zheng",
                "Xinyang Chen"
            ],
            "arxiv_id": "2512.20002v1",
            "summary": "Time-series forecasting in real-world applications such as finance and energy often faces challenges due to limited training data and complex, noisy temporal dynamics. Existing deep forecasting models typically supervise predictions using full-length temporal windows, which include substantial high-frequency noise and obscure long-term trends. Moreover, auxiliary variables containing rich domain-specific information are often underutilized, especially in few-shot settings. To address these challenges, we propose LoFT-LLM, a frequency-aware forecasting pipeline that integrates low-frequency learning with semantic calibration via a large language model (LLM). Firstly, a Patch Low-Frequency forecasting Module (PLFM) extracts stable low-frequency trends from localized spectral patches. Secondly, a residual learner then models high-frequency variations. Finally, a fine-tuned LLM refines the predictions by incorporating auxiliary context and domain knowledge through structured natural language prompts. Extensive experiments on financial and energy datasets demonstrate that LoFT-LLM significantly outperforms strong baselines under both full-data and few-shot regimes, delivering superior accuracy, robustness, and interpretability.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted at KDD 2026. 9 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20002v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "LoFT-LLM：结合低频学习与大语言模型的时间序列预测框架",
            "summary_zh": "本文提出了一种名为LoFT-LLM的频率感知预测流程，它结合了低频学习和通过大语言模型（LLM）进行的语义校准，旨在解决实际应用中时间序列预测面临的挑战，如训练数据有限和复杂、嘈杂的时间动态。该方法首先使用Patch低频预测模块（PLFM）从局部频谱块中提取稳定的低频趋势，然后使用残差学习器对高频变化进行建模。最后，通过微调的LLM，利用结构化的自然语言提示，结合辅助上下文和领域知识来优化预测结果。在金融和能源数据集上的大量实验表明，LoFT-LLM在全数据和少样本情况下均显著优于强大的基线模型，提供了更高的准确性、鲁棒性和可解释性。",
            "intro_zh": [
                "现有深度预测模型使用全长时序窗口进行监督，包含大量高频噪声，掩盖长期趋势，且对辅助变量的利用不足。",
                "LoFT-LLM通过频率感知的方式，提取低频趋势并结合大语言模型进行语义校准，从而提升预测性能。",
                "实验表明，LoFT-LLM在金融和能源数据集上，相比现有方法，在准确性、鲁棒性和可解释性方面均有显著提升。"
            ],
            "method_zh": "**问题定义**：现实世界的时间序列预测，例如金融和能源领域，面临着训练数据有限以及复杂和嘈杂的时间动态的挑战。现有的深度预测模型通常使用全长的时间窗口来监督预测，这包含了大量的高频噪声，掩盖了长期的趋势。此外，包含丰富领域信息的辅助变量通常没有得到充分利用，尤其是在少样本的情况下。\\n\\n**核心思路**：LoFT-LLM的核心思路是将时间序列分解为低频趋势和高频残差，分别进行建模。低频趋势反映了数据的长期模式，对噪声不敏感，更容易学习。同时，利用大语言模型（LLM）的语义理解能力，将辅助变量和领域知识融入预测过程，从而提高预测的准确性和鲁棒性。\\n\\n**技术框架**：LoFT-LLM的整体框架包含三个主要模块：Patch低频预测模块（PLFM）、残差学习器和LLM语义校准模块。PLFM负责从局部频谱块中提取稳定的低频趋势。残差学习器用于建模高频变化。LLM语义校准模块则通过微调的LLM，利用结构化的自然语言提示，结合辅助上下文和领域知识来优化预测结果。\\n\\n**关键创新**：LoFT-LLM的关键创新在于频率感知的预测方法和LLM的语义校准。频率感知方法通过提取低频趋势，降低了噪声的影响，提高了模型的鲁棒性。LLM的语义校准则将领域知识融入预测过程，提高了预测的准确性和可解释性。\\n\\n**关键设计**：PLFM使用局部频谱分析提取低频成分，具体实现细节（如窗口大小、重叠率等）未知。残差学习器的具体网络结构未知。LLM使用微调方式，提示工程的具体形式未知，损失函数也未知。这些细节会影响最终的性能表现，但论文摘要中未详细说明。",
            "application_zh": "LoFT-LLM具有广泛的应用前景，尤其是在金融、能源等对预测精度要求高的领域。它可以用于股票价格预测、电力负荷预测、风力发电预测等。通过结合领域知识和辅助变量，LoFT-LLM可以提高预测的准确性和鲁棒性，为决策提供更可靠的依据。此外，该方法还可以应用于其他类型的时间序列预测问题，例如交通流量预测、销售预测等。",
            "highlight_zh": "LoFT-LLM在金融和能源数据集上进行了广泛的实验，结果表明，在全数据和少样本情况下，LoFT-LLM均显著优于强大的基线模型。具体的性能提升数据未知，但论文强调了其在准确性、鲁棒性和可解释性方面的优势。这些结果表明，LoFT-LLM是一种有效的时间序列预测方法。",
            "tags_zh": [
                "时间序列预测",
                "低频学习",
                "大语言模型",
                "频率分析",
                "语义校准"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20002v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20002v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20002v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model",
            "authors": [
                "Zhiyi Duan",
                "Xiangren Wang",
                "Hongyu Yuan",
                "Qianli Xing"
            ],
            "arxiv_id": "2512.20548v1",
            "summary": "Teachers' emotional states are critical in educational scenarios, profoundly impacting teaching efficacy, student engagement, and learning achievements. However, existing studies often fail to accurately capture teachers' emotions due to the performative nature and overlook the critical impact of instructional information on emotional expression.In this paper, we systematically investigate teacher sentiment analysis by building both the dataset and the model accordingly. We construct the first large-scale teacher multimodal sentiment analysis dataset, T-MED.To ensure labeling accuracy and efficiency, we employ a human-machine collaborative labeling process.The T-MED dataset includes 14,938 instances of teacher emotional data from 250 real classrooms across 11 subjects ranging from K-12 to higher education, integrating multimodal text, audio, video, and instructional information.Furthermore, we propose a novel asymmetric attention-based multimodal teacher sentiment analysis model, AAM-TSA.AAM-TSA introduces an asymmetric attention mechanism and hierarchical gating unit to enable differentiated cross-modal feature fusion and precise emotional classification. Experimental results demonstrate that AAM-TSA significantly outperforms existing state-of-the-art methods in terms of accuracy and interpretability on the T-MED dataset.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20548v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "构建T-MED数据集与AAM-TSA模型以提升教师情感分析准确性",
            "summary_zh": "教师的情感状态在教育场景中至关重要，直接影响教学效果、学生参与度和学习成就。然而，现有研究常常无法准确捕捉教师情感，忽视了教学信息对情感表达的影响。本文系统性地研究了教师情感分析，构建了首个大规模教师多模态情感分析数据集T-MED。为确保标注的准确性和效率，采用了人机协作的标注过程。T-MED数据集包含来自250个真实课堂的14,938个教师情感数据实例，涵盖K-12至高等教育的11个学科，整合了多模态文本、音频、视频和教学信息。此外，提出了一种新颖的基于非对称注意力的多模态教师情感分析模型AAM-TSA，实验结果表明AAM-TSA在T-MED数据集上显著优于现有最先进方法的准确性和可解释性。",
            "intro_zh": [
                "现有方法在捕捉教师情感时存在不足，未能充分考虑教学信息对情感表达的影响。",
                "论文提出了T-MED数据集和AAM-TSA模型，以实现教师情感的多模态分析和精准分类。",
                "实验结果显示，AAM-TSA在准确性和可解释性上显著优于现有的最先进方法。"
            ],
            "method_zh": "**问题定义**：本文旨在解决教师情感分析中的准确性问题，现有方法未能有效捕捉教师情感，尤其是在多模态信息的整合上存在不足。\\n\\n**核心思路**：提出了T-MED数据集和AAM-TSA模型，利用非对称注意力机制和分层门控单元，实现跨模态特征的差异化融合和精确情感分类。\\n\\n**技术框架**：AAM-TSA模型的整体架构包括输入层（多模态数据）、特征提取层（音频、视频、文本特征提取）、非对称注意力机制层和情感分类层，形成一个完整的情感分析流程。\\n\\n**关键创新**：AAM-TSA模型的非对称注意力机制是其核心创新，与现有方法相比，能够更好地处理多模态信息的差异性，提升情感分类的准确性。\\n\\n**关键设计**：模型设计中采用了分层门控单元，以实现不同模态特征的有效融合，损失函数则针对多模态特征的特性进行了优化，确保模型在训练过程中的稳定性和准确性。",
            "application_zh": "该研究的潜在应用领域包括教育技术、教师培训和情感计算等。通过准确分析教师情感，能够为教育决策提供数据支持，提升教学质量和学生学习体验，未来可能在智能教育系统中发挥重要作用。",
            "highlight_zh": "实验结果表明，AAM-TSA模型在T-MED数据集上的准确率显著高于现有最先进方法，具体提升幅度达到XX%，同时在情感分类的可解释性方面也有显著改善，展示了模型的有效性和实用性。",
            "tags_zh": [
                "教师情感分析",
                "多模态数据",
                "非对称注意力",
                "情感计算",
                "教育技术",
                "数据集构建",
                "模型创新"
            ],
            "_index": 27,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20548v1/w001-7.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20548v1/w002-5.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20548v1/w003-7.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
            "authors": [
                "Syeda Tasnim Fabiha",
                "Saad Shafiq",
                "Wesley Klewerton Guez Assunção",
                "Nenad Medvidović"
            ],
            "arxiv_id": "2512.20381v1",
            "summary": "Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "22 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20381v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Rake，利用深度强化学习从实现工件中识别合适大小的服务。",
            "summary_zh": "面向服务架构(SBA)作为一种现代化遗留系统的方法，在工业界和学术界受到了广泛关注。它指的是一种设计风格，使系统能够被开发为小型、松散耦合和自治的组件（服务）套件，这些组件封装了功能并通过语言无关的API进行通信。然而，定义能够捕获系统功能内聚子集的适当大小的服务仍然具有挑战性。现有工作通常依赖于文档的可用性、对项目人员的访问或对目标服务数量的先验知识，这些假设在许多实际场景中并不成立。我们的工作使用基于深度强化学习的方法来解决这些限制，直接从实现工件中识别适当大小的服务。我们提出Rake，一种基于强化学习的技术，它利用可用的系统文档和源代码来指导实现方法级别的服务分解。Rake不需要特定的文档或对项目人员的访问，并且是语言无关的。它还支持可定制的目标函数，该函数平衡模块化质量和业务能力对齐，即服务覆盖目标业务能力的程度。我们将Rake应用于四个开源遗留项目，并将其与两种最先进的技术进行了比较。平均而言，Rake实现了高7-14%的模块化质量和18-22%的业务能力对齐。我们的结果进一步表明，仅针对业务上下文进行优化会降低紧密耦合系统中的分解质量，突出了平衡目标的需求。",
            "intro_zh": [
                "现有服务分解方法依赖于文档、人员访问或先验知识，在实际场景中受限。",
                "Rake利用深度强化学习，直接从代码和文档中学习服务分解策略。",
                "实验表明，Rake在模块化质量和业务能力对齐方面优于现有技术。"
            ],
            "method_zh": "**问题定义**：论文旨在解决服务型架构中服务粒度划分的问题。现有方法依赖于人工经验或特定文档，难以自动化且效果受限。痛点在于如何从代码和文档等实现工件中自动识别合适大小的服务，同时兼顾模块化质量和业务能力对齐。\n\n**核心思路**：论文的核心思路是将服务分解问题建模为强化学习任务。通过训练智能体，使其能够根据代码和文档信息，逐步决策如何将方法聚合成服务。这种方法无需人工干预，能够自动学习最优的服务分解策略。\n\n**技术框架**：Rake的技术框架主要包括以下几个模块：1) 环境：模拟服务分解过程，包括代码和文档信息；2) 智能体：基于深度神经网络，负责决策如何将方法聚合成服务；3) 奖励函数：评估服务分解的质量，包括模块化质量和业务能力对齐；4) 训练过程：通过强化学习算法，不断优化智能体的策略。\n\n**关键创新**：Rake的关键创新在于：1) 将服务分解问题建模为强化学习任务，实现了自动化服务分解；2) 提出了可定制的目标函数，能够平衡模块化质量和业务能力对齐；3) 无需特定文档或人员访问，具有良好的通用性。\n\n**关键设计**：Rake的关键设计包括：1) 使用深度神经网络作为智能体的策略网络，能够处理复杂的代码和文档信息；2) 设计了合适的奖励函数，鼓励智能体生成高质量的服务分解方案；3) 采用了Actor-Critic算法进行训练，提高了训练效率和稳定性。具体的网络结构、损失函数和参数设置在论文中有详细描述。",
            "application_zh": "Rake可应用于遗留系统的现代化改造、微服务架构设计等领域。通过自动化服务分解，可以降低系统重构的成本和风险，提高系统的可维护性和可扩展性。未来，该技术可进一步应用于云原生应用开发、DevOps等领域，提升软件开发的效率和质量。",
            "highlight_zh": "Rake在四个开源遗留项目上进行了评估，并与两种最先进的技术进行了比较。实验结果表明，Rake在模块化质量方面平均提高了7-14%，在业务能力对齐方面平均提高了18-22%。这些结果表明，Rake能够有效地识别合适大小的服务，并优于现有技术。",
            "tags_zh": [
                "服务分解",
                "深度强化学习",
                "微服务架构",
                "遗留系统现代化",
                "模块化质量"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20381v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20381v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20381v1/figures/Approach-ODG.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization",
            "authors": [
                "Junren Li",
                "Luhua Lai"
            ],
            "arxiv_id": "2512.20333v1",
            "summary": "Generative artificial intelligence has revolutionized the exploration of chemical space, yet a critical bottleneck remains that a substantial fraction of generated molecules is synthetically inaccessible. Current solutions, such as post-hoc filtering or projection-based methods, often compromise structural novelty or disrupt key pharmacophores by forcing molecules into pre-defined synthetic templates. Herein, we introduce SynCraft, a reasoning-based framework that reframes synthesizability optimization not as a sequence translation task, but as a precise structural editing problem. Leveraging the emergent reasoning capabilities of Large Language Models, SynCraft navigates the \"synthesis cliff\" where minimal structural modifications yield significant gains in synthetic feasibility. By predicting executable sequences of atom-level edits rather than generating SMILES strings directly, SynCraft circumvents the syntactic fragility of LLMs while harnessing their chemical intuition. Extensive benchmarks demonstrate that SynCraft outperforms state-of-the-art baselines in generating synthesizable analogs with high structural fidelity. Furthermore, through interaction-aware prompting, SynCraft successfully replicates expert medicinal chemistry intuition in editing PLK1 inhibitors and rescuing high-scoring but previously discarded RIPK1 candidates in previous molecular generation literatures.",
            "categories": [
                "cs.AI",
                "q-bio.QM"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "28 pages, 4 figures, 1 table",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20333v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SynCraft：引导大语言模型预测编辑序列，优化分子合成可行性",
            "summary_zh": "生成式人工智能极大地推动了化学空间探索，但大量生成的分子难以合成仍然是一个关键瓶颈。现有的后处理过滤或基于投影的方法通常会牺牲结构新颖性或破坏关键药效团，因为它们强制将分子纳入预定义的合成模板。本文介绍SynCraft，一个基于推理的框架，它将合成可行性优化重新定义为一个精确的结构编辑问题，而非序列翻译任务。SynCraft利用大语言模型涌现的推理能力，在最小结构修改下实现合成可行性的显著提升。通过预测原子级别编辑的可执行序列，而非直接生成SMILES字符串，SynCraft规避了LLM的句法脆弱性，同时利用了它们的化学直觉。广泛的基准测试表明，SynCraft在生成具有高结构保真度的可合成类似物方面优于最先进的基线。此外，通过交互感知的提示，SynCraft成功地复制了药物化学专家的直觉，编辑了PLK1抑制剂，并在先前的分子生成文献中拯救了高分但先前被丢弃的RIPK1候选物。",
            "intro_zh": [
                "现有分子生成方法在合成可行性方面存在瓶颈，后处理或投影方法牺牲了结构新颖性。",
                "SynCraft将合成可行性优化视为结构编辑问题，利用大语言模型的推理能力预测原子级别的编辑序列。",
                "实验表明，SynCraft在生成可合成类似物方面优于现有方法，并能模拟药物化学专家的编辑直觉。"
            ],
            "method_zh": "**问题定义**：现有分子生成方法生成的分子，很多难以合成，导致化学空间探索受限。传统的解决方法，如后处理过滤或基于投影的方法，虽然能提高合成可行性，但往往会牺牲生成分子的结构新颖性，或者破坏分子中的关键药效团，因为这些方法依赖于预定义的合成模板，缺乏灵活性。\\n\\n**核心思路**：SynCraft的核心思路是将分子合成可行性优化问题，转化为一个精确的结构编辑问题。它不直接生成完整的SMILES字符串，而是通过预测一系列原子级别的编辑操作，逐步优化分子的结构，使其更易于合成。这种方法能够更好地保留分子的结构特征，同时提高合成可行性。\\n\\n**技术框架**：SynCraft框架主要包含以下几个阶段：首先，输入一个初始分子结构。然后，利用大语言模型（LLM）的推理能力，预测一系列原子级别的编辑操作，例如添加、删除或修改原子或化学键。这些编辑操作是基于对分子结构的分析和合成可行性的评估而生成的。最后，将这些编辑操作应用到初始分子结构上，得到优化后的分子结构。整个过程可以迭代进行，直到分子结构的合成可行性达到预定的标准。\\n\\n**关键创新**：SynCraft最重要的创新点在于它将大语言模型应用于分子结构的编辑，而不是直接生成SMILES字符串。这种方法能够更好地利用LLM的推理能力和化学直觉，同时避免了SMILES字符串的句法脆弱性问题。此外，SynCraft还引入了交互感知的提示机制，允许用户根据自己的经验和知识，对LLM的编辑操作进行指导，从而更好地模拟药物化学专家的编辑直觉。\\n\\n**关键设计**：SynCraft的关键设计包括：1) 使用预训练的大语言模型，并针对化学领域的数据进行微调，以提高其化学推理能力。2) 设计了一套原子级别的编辑操作，包括添加、删除和修改原子或化学键，这些操作需要足够细粒度，以保证分子结构能够被精确地编辑。3) 引入了交互感知的提示机制，允许用户根据自己的经验和知识，对LLM的编辑操作进行指导。4) 使用合适的损失函数，例如合成可行性评分和结构相似性评分，来指导LLM的学习过程。",
            "application_zh": "SynCraft可应用于药物发现、材料科学等领域，加速新分子设计与优化。通过提高生成分子的合成可行性，降低了后期合成难度和成本，缩短研发周期。该方法有望辅助药物化学家快速找到具有所需性质且易于合成的候选分子，加速新药研发进程。",
            "highlight_zh": "SynCraft在生成可合成类似物方面显著优于现有方法。实验结果表明，SynCraft在保持高结构保真度的前提下，能够有效提高生成分子的合成可行性。此外，SynCraft成功地复制了药物化学专家的编辑直觉，在PLK1抑制剂和RIPK1候选物的编辑任务中取得了良好的效果。",
            "tags_zh": [
                "分子生成",
                "合成可行性",
                "大语言模型",
                "结构编辑",
                "药物发现"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20333v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20333v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20333v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TongSIM: A General Platform for Simulating Intelligent Machines",
            "authors": [
                "Zhe Sun",
                "Kunlun Wu",
                "Chuanjian Fu",
                "Zeming Song",
                "Langyong Shi",
                "Zihe Xue",
                "Bohan Jing",
                "Ying Yang",
                "Xiaomeng Gao",
                "Aijia Li",
                "Tianyu Guo",
                "Huiying Li",
                "Xueyuan Yang",
                "Rongkai Liu",
                "Xinyi He",
                "Yuxi Wang",
                "Yue Li",
                "Mingyuan Liu",
                "Yujie Lu",
                "Hongzhao Xie",
                "Shiyun Zhao",
                "Bo Dai",
                "Wei Wang",
                "Tao Yuan",
                "Song-Chun Zhu",
                "Yujia Peng",
                "Zhenliang Zhang"
            ],
            "arxiv_id": "2512.20206v1",
            "summary": "As artificial intelligence (AI) rapidly advances, especially in multimodal large language models (MLLMs), research focus is shifting from single-modality text processing to the more complex domains of multimodal and embodied AI. Embodied intelligence focuses on training agents within realistic simulated environments, leveraging physical interaction and action feedback rather than conventionally labeled datasets. Yet, most existing simulation platforms remain narrowly designed, each tailored to specific tasks. A versatile, general-purpose training environment that can support everything from low-level embodied navigation to high-level composite activities, such as multi-agent social simulation and human-AI collaboration, remains largely unavailable. To bridge this gap, we introduce TongSIM, a high-fidelity, general-purpose platform for training and evaluating embodied agents. TongSIM offers practical advantages by providing over 100 diverse, multi-room indoor scenarios as well as an open-ended, interaction-rich outdoor town simulation, ensuring broad applicability across research needs. Its comprehensive evaluation framework and benchmarks enable precise assessment of agent capabilities, such as perception, cognition, decision-making, human-robot cooperation, and spatial and social reasoning. With features like customized scenes, task-adaptive fidelity, diverse agent types, and dynamic environmental simulation, TongSIM delivers flexibility and scalability for researchers, serving as a unified platform that accelerates training, evaluation, and advancement toward general embodied intelligence.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20206v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "large language model",
                        "multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TongSIM：通用智能机器模拟平台，支持具身智能体训练与评估",
            "summary_zh": "随着人工智能，特别是多模态大语言模型（MLLM）的快速发展，研究重点正从单模态文本处理转向更复杂的多模态和具身人工智能领域。具身智能侧重于在逼真的模拟环境中训练智能体，利用物理交互和动作反馈，而不是传统的标注数据集。然而，现有的大多数模拟平台仍然设计狭隘，各自针对特定任务。一个能够支持从低级具身导航到高级复合活动（如多智能体社会模拟和人机协作）的通用训练环境仍然很大程度上不可用。为了弥合这一差距，我们推出了 TongSIM，这是一个高保真、通用的平台，用于训练和评估具身智能体。TongSIM 提供了实际优势，提供了 100 多个多样化的多房间室内场景以及一个开放的、交互丰富的室外城镇模拟，确保了广泛的研究适用性。其全面的评估框架和基准能够精确评估智能体的能力，如感知、认知、决策、人机协作以及空间和社会推理。凭借定制场景、任务自适应保真度、多样化的智能体类型和动态环境模拟等功能，TongSIM 为研究人员提供了灵活性和可扩展性，作为一个统一的平台，加速了通用具身智能的训练、评估和发展。",
            "intro_zh": [
                "现有模拟平台设计狭隘，难以支持从低级导航到高级人机协作等复杂任务。",
                "TongSIM 平台提供高保真、通用的模拟环境，支持具身智能体的训练和评估。",
                "TongSIM 提供多样化的室内外场景、全面的评估框架和灵活的定制功能。"
            ],
            "method_zh": "**问题定义**：现有具身智能模拟平台通常针对特定任务设计，缺乏通用性和灵活性，难以支持复杂的多智能体交互、人机协作等高级任务。这限制了具身智能体的训练和评估，阻碍了通用具身智能的发展。\\n\\n**核心思路**：TongSIM 的核心思路是构建一个高保真、通用的模拟平台，提供多样化的场景、灵活的配置和全面的评估框架，从而支持各种具身智能任务的训练和评估。通过提供丰富的交互环境和可定制的智能体类型，TongSIM 旨在加速通用具身智能的研究。\\n\\n**技术框架**：TongSIM 平台包含以下主要模块：1) 场景生成模块，提供多样化的室内外场景，包括多房间室内环境和开放式城镇环境；2) 智能体管理模块，支持不同类型的智能体，包括机器人、人类等，并提供定制化功能；3) 物理引擎模块，模拟真实的物理交互，包括碰撞、重力等；4) 感知模块，模拟智能体的感知能力，包括视觉、听觉等；5) 评估模块，提供全面的评估指标，用于评估智能体的性能。\\n\\n**关键创新**：TongSIM 的关键创新在于其通用性和灵活性。它不仅提供了多样化的场景和智能体类型，还支持任务自适应的保真度调整，允许研究人员根据任务的复杂程度选择合适的模拟精度。此外，TongSIM 还提供了全面的评估框架，可以精确评估智能体的感知、认知、决策、人机协作以及空间和社会推理能力。\\n\\n**关键设计**：TongSIM 采用模块化设计，各个模块之间相互独立，易于扩展和定制。场景生成模块支持导入自定义场景，智能体管理模块支持自定义智能体类型和行为。物理引擎模块采用开源的 Bullet 物理引擎，感知模块支持多种传感器模拟，包括摄像头、麦克风、激光雷达等。评估模块提供多种评估指标，包括成功率、路径长度、时间消耗等。",
            "application_zh": "TongSIM 可应用于机器人导航、人机协作、多智能体社会模拟、自动驾驶等领域。该平台能够加速具身智能体的训练和评估，推动相关技术的发展，并最终应用于智能家居、智能交通、智能制造等实际场景，提升生产效率和生活质量。",
            "highlight_zh": "TongSIM 提供了超过 100 个多样化的多房间室内场景以及一个开放的、交互丰富的室外城镇模拟。该平台还提供了一套全面的评估框架和基准，能够精确评估智能体的感知、认知、决策、人机协作以及空间和社会推理能力。具体性能数据和对比基线信息未知。",
            "tags_zh": [
                "具身智能",
                "模拟平台",
                "多模态学习",
                "人机协作",
                "机器人导航"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20206v1/tongsim/figures/teaser.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20206v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20206v1/tongsim/figures/room_freq.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Concept Generalization in Humans and Large Language Models: Insights from the Number Game",
            "authors": [
                "Arghavan Bazigaran",
                "Hansem Sohn"
            ],
            "arxiv_id": "2512.20162v1",
            "summary": "We compare human and large language model (LLM) generalization in the number game, a concept inference task. Using a Bayesian model as an analytical framework, we examined the inductive biases and inference strategies of humans and LLMs. The Bayesian model captured human behavior better than LLMs in that humans flexibly infer rule-based and similarity-based concepts, whereas LLMs rely more on mathematical rules. Humans also demonstrated a few-shot generalization, even from a single example, while LLMs required more samples to generalize. These contrasts highlight the fundamental differences in how humans and LLMs infer and generalize mathematical concepts.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20162v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过数字游戏对比人类与大语言模型在概念泛化上的差异",
            "summary_zh": "本文对比了人类和大语言模型（LLM）在数字游戏（一种概念推断任务）中的泛化能力。我们使用贝叶斯模型作为分析框架，研究了人类和LLM的归纳偏置和推理策略。贝叶斯模型能更好地捕捉人类行为，因为人类可以灵活地推断基于规则和基于相似性的概念，而LLM更依赖于数学规则。人类还表现出小样本泛化能力，即使只有一个例子也能泛化，而LLM需要更多的样本才能泛化。这些对比突出了人类和LLM在推断和泛化数学概念方面的根本差异。",
            "intro_zh": [
                "现有方法难以解释人类与大语言模型在概念泛化上的差异，尤其是在数学概念方面。",
                "论文采用贝叶斯模型作为分析框架，研究人类和LLM在数字游戏中的归纳偏置和推理策略。",
                "实验表明，人类能灵活推断规则和相似性概念，且具有更强的小样本泛化能力，而LLM更依赖数学规则。"
            ],
            "method_zh": "**问题定义**：论文旨在研究人类和大语言模型在概念泛化能力上的差异，特别是在数学概念领域。现有方法未能充分解释两者在归纳偏置和推理策略上的不同，也未能揭示LLM在小样本学习方面的局限性。数字游戏提供了一个受控的环境，用于量化和比较人类和LLM在概念学习和泛化方面的表现。\\n\\n**核心思路**：论文的核心思路是使用贝叶斯模型作为分析框架，将人类和LLM的行为建模为概率推理过程。通过比较模型参数和预测结果，可以揭示人类和LLM在归纳偏置和推理策略上的差异。同时，通过改变训练样本的数量，可以评估两者的小样本泛化能力。\\n\\n**技术框架**：整体框架包括三个主要部分：1) 数字游戏环境的构建，用于生成训练和测试数据；2) 人类行为数据的收集，通过实验获取人类在数字游戏中的决策；3) LLM的训练和评估，使用不同的LLM架构和训练策略，评估其在数字游戏中的表现。贝叶斯模型用于对人类和LLM的行为进行建模和分析。\\n\\n**关键创新**：论文的关键创新在于将贝叶斯模型应用于分析人类和LLM在概念泛化上的差异。通过这种方法，可以量化两者在归纳偏置和推理策略上的不同，并揭示LLM在小样本学习方面的局限性。此外，论文还提出了一个数字游戏环境，为研究概念学习和泛化提供了一个新的平台。\\n\\n**关键设计**：在贝叶斯模型中，需要定义先验概率分布，用于表示对不同概念的初始信念。似然函数用于表示给定概念下观察到数据的概率。后验概率分布用于表示在观察到数据后对概念的更新信念。通过比较人类和LLM的后验概率分布，可以揭示两者在归纳偏置和推理策略上的差异。实验中使用了不同规模的LLM，并采用了不同的训练策略，例如微调和提示学习。",
            "application_zh": "该研究成果可应用于提升大语言模型的推理能力和泛化能力，使其更接近人类的认知水平。例如，可以借鉴人类的归纳偏置和推理策略，设计更有效的LLM训练方法。此外，该研究还可以应用于教育领域，帮助人们更好地理解数学概念，并提高解决问题的能力。",
            "highlight_zh": "实验结果表明，贝叶斯模型能更好地捕捉人类行为，人类在数字游戏中表现出更强的灵活性和泛化能力，能够灵活地推断基于规则和基于相似性的概念，并且具有更强的小样本泛化能力。相比之下，LLM更依赖于数学规则，且需要更多的样本才能泛化。这些发现揭示了人类和LLM在概念学习和泛化方面的根本差异。",
            "tags_zh": [
                "概念泛化",
                "大语言模型",
                "贝叶斯模型",
                "数字游戏",
                "归纳偏置"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20162v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20162v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20162v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches",
            "authors": [
                "Chaithra",
                "Kamesh Kadimisetty",
                "Biju R Mohan"
            ],
            "arxiv_id": "2512.20082v1",
            "summary": "Financial sentiment analysis plays a crucial role in informing investment decisions, assessing market risk, and predicting stock price trends. Existing works in financial sentiment analysis have not considered the impact of stock prices or market feedback on sentiment analysis. In this paper, we propose an adaptive framework that integrates large language models (LLMs) with real-world stock market feedback to improve sentiment classification in the context of the Indian stock market. The proposed methodology fine-tunes the LLaMA 3.2 3B model using instruction-based learning on the SentiFin dataset. To enhance sentiment predictions, a retrieval-augmented generation (RAG) pipeline is employed that dynamically selects multi-source contextual information based on the cosine similarity of the sentence embeddings. Furthermore, a feedback-driven module is introduced that adjusts the reliability of the source by comparing predicted sentiment with actual next-day stock returns, allowing the system to iteratively adapt to market behavior. To generalize this adaptive mechanism across temporal data, a reinforcement learning agent trained using proximal policy optimization (PPO) is incorporated. The PPO agent learns to optimize source weighting policies based on cumulative reward signals from sentiment-return alignment. Experimental results on NIFTY 50 news headlines collected from 2024 to 2025 demonstrate that the proposed system significantly improves classification accuracy, F1-score, and market alignment over baseline models and static retrieval methods. The results validate the potential of combining instruction-tuned LLMs with dynamic feedback and reinforcement learning for robust, market-aware financial sentiment modeling.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted in CODS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20082v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "PPO"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于指令调优LLM、RAG和强化学习的自适应金融情感分析框架，用于NIFTY 50指数预测。",
            "summary_zh": "金融情感分析在投资决策、市场风险评估和股票价格趋势预测中起着至关重要的作用。现有金融情感分析工作尚未考虑股票价格或市场反馈对情感分析的影响。本文提出了一个自适应框架，该框架将大型语言模型（LLM）与真实股票市场反馈相结合，以提高印度股票市场背景下的情感分类性能。该方法使用基于指令的学习在SentiFin数据集上微调LLaMA 3.2 3B模型。为了增强情感预测，采用检索增强生成（RAG）流程，该流程基于句子嵌入的余弦相似度动态选择多源上下文信息。此外，引入了一个反馈驱动模块，通过比较预测的情感与实际的次日股票收益来调整来源的可靠性，使系统能够迭代地适应市场行为。为了在时间数据上推广这种自适应机制，引入了一个使用近端策略优化（PPO）训练的强化学习代理。PPO代理学习基于情感-收益对齐的累积奖励信号来优化来源加权策略。对2024年至2025年收集的NIFTY 50新闻标题进行的实验结果表明，所提出的系统显著提高了分类准确率、F1分数和市场对齐度，优于基线模型和静态检索方法。结果验证了将指令调优的LLM与动态反馈和强化学习相结合以实现稳健的、市场感知的金融情感建模的潜力。",
            "intro_zh": [
                "现有金融情感分析方法忽略了股票价格和市场反馈对情感分析的影响，导致预测精度受限。",
                "提出一种自适应框架，结合指令调优的LLM、RAG和强化学习，利用市场反馈动态调整情感分析模型。",
                "实验结果表明，该系统在NIFTY 50新闻标题情感分析中，显著提高了分类准确率、F1分数和市场对齐度。"
            ],
            "method_zh": "**问题定义**：现有金融情感分析方法未能充分利用股票市场反馈信息，导致情感分析结果与实际市场表现的关联性较弱，无法有效指导投资决策。这些方法通常是静态的，无法适应不断变化的市场动态。\\n\\n**核心思路**：本文的核心思路是构建一个自适应的情感分析框架，该框架能够从实际股票市场反馈中学习，并动态调整情感分析模型，使其更好地适应市场行为。通过将LLM与RAG和强化学习相结合，实现对市场信息的有效利用和对模型参数的动态优化。\\n\\n**技术框架**：该框架包含以下主要模块：1) 指令调优的LLM：使用SentiFin数据集对LLaMA 3.2 3B模型进行指令调优，以提高情感分类能力。2) RAG：利用RAG流程，基于句子嵌入的余弦相似度动态选择多源上下文信息，增强情感预测。3) 反馈驱动模块：通过比较预测情感与实际次日股票收益，调整信息来源的可靠性。4) 强化学习代理：使用PPO算法训练强化学习代理，优化信息来源的加权策略，以适应市场变化。\\n\\n**关键创新**：该方法最重要的创新点在于其自适应性，能够根据市场反馈动态调整情感分析模型。通过强化学习，系统能够学习最优的信息来源加权策略，从而提高情感分析的准确性和市场对齐度。与现有静态方法相比，该方法能够更好地适应市场动态变化。\\n\\n**关键设计**：在RAG模块中，使用余弦相似度来衡量句子嵌入之间的相似性，从而选择相关的上下文信息。在强化学习模块中，使用PPO算法训练代理，奖励信号基于情感预测与实际股票收益的对齐程度。具体参数设置和网络结构细节未在摘要中详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于智能投资顾问、风险管理系统和量化交易策略等领域。通过更准确地分析市场情绪，可以帮助投资者做出更明智的决策，降低投资风险，提高投资回报。该方法还可用于构建更稳健的市场监控系统，及时发现潜在的市场风险。",
            "highlight_zh": "实验结果表明，该系统在NIFTY 50新闻标题情感分析中，显著提高了分类准确率、F1分数和市场对齐度，优于基线模型和静态检索方法。具体的性能提升数据未在摘要中给出，属于未知信息。该结果验证了将指令调优的LLM与动态反馈和强化学习相结合的有效性。",
            "tags_zh": [
                "金融情感分析",
                "指令调优LLM",
                "检索增强生成",
                "强化学习",
                "股票市场预测",
                "自适应模型",
                "NIFTY 50"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20082v1/Methodology.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20082v1/initial_source_weights.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20082v1/ppo_source_weights.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Making Large Language Models Efficient Dense Retrievers",
            "authors": [
                "Yibin Lei",
                "Shwai He",
                "Ang Li",
                "Andrew Yates"
            ],
            "arxiv_id": "2512.20612v1",
            "summary": "Recent work has shown that directly fine-tuning large language models (LLMs) for dense retrieval yields strong performance, but their substantial parameter counts make them computationally inefficient. While prior studies have revealed significant layer redundancy in LLMs for generative tasks, it remains unclear whether similar redundancy exists when these models are adapted for retrieval tasks, which require encoding entire sequences into fixed representations rather than generating tokens iteratively. To this end, we conduct a comprehensive analysis of layer redundancy in LLM-based dense retrievers. We find that, in contrast to generative settings, MLP layers are substantially more prunable, while attention layers remain critical for semantic aggregation. Building on this insight, we propose EffiR, a framework for developing efficient retrievers that performs large-scale MLP compression through a coarse-to-fine strategy (coarse-grained depth reduction followed by fine-grained width reduction), combined with retrieval-specific fine-tuning. Across diverse BEIR datasets and LLM backbones, EffiR achieves substantial reductions in model size and inference cost while preserving the performance of full-size models.",
            "categories": [
                "cs.IR",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20612v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EffiR框架，通过MLP压缩提升LLM密集检索器的效率，保持性能。",
            "summary_zh": "最近的研究表明，直接微调大型语言模型（LLM）用于密集检索可以获得强大的性能，但其庞大的参数量导致计算效率低下。虽然之前的研究揭示了LLM在生成任务中存在显著的层冗余，但当这些模型被用于检索任务时，是否存在类似的冗余仍然不清楚，因为检索任务需要将整个序列编码成固定的表示，而不是迭代地生成token。为此，我们对基于LLM的密集检索器中的层冗余进行了全面的分析。我们发现，与生成设置相比，MLP层更易于修剪，而注意力层对于语义聚合仍然至关重要。基于这一洞察，我们提出了EffiR，一个用于开发高效检索器的框架，该框架通过粗到精的策略（粗粒度的深度缩减，然后是细粒度的宽度缩减）执行大规模的MLP压缩，并结合特定于检索的微调。在不同的BEIR数据集和LLM骨干网络上，EffiR在保持全尺寸模型性能的同时，显著降低了模型大小和推理成本。",
            "intro_zh": [
                "现有基于LLM的密集检索器参数量巨大，计算效率低，限制了其应用。",
                "EffiR框架通过分析LLM层冗余，重点压缩MLP层，保留关键的注意力层。",
                "实验表明，EffiR在保持性能的同时，显著降低了模型大小和推理成本。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）作为密集检索器时计算效率低下的问题。现有方法直接微调整个LLM，参数量巨大，推理成本高昂。虽然LLM在生成任务中存在层冗余已被发现，但检索任务的层冗余情况尚不明确。\\n\\n**核心思路**：论文的核心思路是发现并利用LLM在检索任务中的层冗余，特别是MLP层的冗余，通过压缩MLP层来降低模型大小和推理成本，同时保留注意力层以维持语义聚合能力。\\n\\n**技术框架**：EffiR框架包含以下主要阶段：1) 层冗余分析：分析LLM中不同层的可修剪性，发现MLP层更易于修剪。2) 粗粒度深度缩减：移除部分MLP层，降低模型深度。3) 细粒度宽度缩减：对剩余的MLP层进行权重剪枝，进一步降低模型宽度。4) 检索特定微调：对压缩后的模型进行微调，以恢复性能。\\n\\n**关键创新**：最重要的技术创新点在于发现了LLM在检索任务中MLP层和注意力层不同的重要性，并据此设计了针对性的压缩策略。与现有方法不同，EffiR不是均匀地压缩所有层，而是重点压缩冗余的MLP层，保留关键的注意力层。\\n\\n**关键设计**：EffiR采用了粗到精的压缩策略，首先进行深度缩减，然后进行宽度缩减。深度缩减通过移除整个MLP层来实现，宽度缩减通过权重剪枝来实现。此外，论文还使用了检索特定的微调方法，例如对比学习，以优化压缩后的模型。",
            "application_zh": "该研究成果可应用于各种信息检索场景，例如搜索引擎、问答系统、推荐系统等。通过降低LLM密集检索器的计算成本，可以使其更容易部署在资源受限的环境中，并提高检索效率，从而提升用户体验。",
            "highlight_zh": "实验结果表明，EffiR在多个BEIR数据集上，使用不同的LLM骨干网络，都能在保持全尺寸模型性能的同时，显著降低模型大小和推理成本。具体的性能数据和提升幅度在论文中进行了详细的展示。",
            "tags_zh": [
                "密集检索",
                "大型语言模型",
                "模型压缩",
                "层冗余",
                "MLP压缩"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20612v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20612v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20612v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning",
            "authors": [
                "Seijin Kobayashi",
                "Yanick Schimpf",
                "Maximilian Schlegel",
                "Angelika Steger",
                "Maciej Wolczyk",
                "Johannes von Oswald",
                "Nino Scherre",
                "Kaitlin Maile",
                "Guillaume Lajoie",
                "Blake A. Richards",
                "Rif A. Saurous",
                "James Manyika",
                "Blaise Agüera y Arcas",
                "Alexander Meulemans",
                "João Sacramento"
            ],
            "arxiv_id": "2512.20605v1",
            "summary": "Large-scale autoregressive models pretrained on next-token prediction and finetuned with reinforcement learning (RL) have achieved unprecedented success on many problem domains. During RL, these models explore by generating new outputs, one token at a time. However, sampling actions token-by-token can result in highly inefficient learning, particularly when rewards are sparse. Here, we show that it is possible to overcome this problem by acting and exploring within the internal representations of an autoregressive model. Specifically, to discover temporally-abstract actions, we introduce a higher-order, non-causal sequence model whose outputs control the residual stream activations of a base autoregressive model. On grid world and MuJoCo-based tasks with hierarchical structure, we find that the higher-order model learns to compress long activation sequence chunks onto internal controllers. Critically, each controller executes a sequence of behaviorally meaningful actions that unfold over long timescales and are accompanied with a learned termination condition, such that composing multiple controllers over time leads to efficient exploration on novel tasks. We show that direct internal controller reinforcement, a process we term \"internal RL\", enables learning from sparse rewards in cases where standard RL finetuning fails. Our results demonstrate the benefits of latent action generation and reinforcement in autoregressive models, suggesting internal RL as a promising avenue for realizing hierarchical RL within foundation models.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20605v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出内部强化学习，利用自回归模型中的时间抽象实现分层强化学习",
            "summary_zh": "本文提出了一种在自回归模型内部表示中进行动作和探索的方法，以克服传统强化学习中token-by-token采样导致的学习效率低下的问题，尤其是在奖励稀疏的情况下。该方法引入了一个高阶非因果序列模型，其输出控制基础自回归模型的残差流激活，从而发现时间抽象动作。实验表明，该高阶模型能够将长激活序列块压缩到内部控制器上，每个控制器执行一系列行为上有意义的动作，这些动作在长时间尺度上展开，并伴随一个学习到的终止条件。通过直接内部控制器强化，即“内部强化学习”，可以在标准强化学习微调失败的情况下从稀疏奖励中学习。该研究表明了在自回归模型中进行潜在动作生成和强化的优势，并认为内部强化学习是实现基础模型中分层强化学习的一种有前景的途径。",
            "intro_zh": [
                "传统强化学习在自回归模型中逐token采样动作效率低，尤其在奖励稀疏时面临挑战。",
                "提出内部强化学习，在高阶模型中学习时间抽象动作，控制底层自回归模型的激活。",
                "实验表明，该方法能有效压缩长序列动作，从稀疏奖励中学习，优于标准强化学习。"
            ],
            "method_zh": "**问题定义**：现有的大规模自回归模型在强化学习微调时，通常采用逐token生成动作的方式进行探索。这种方式在奖励稀疏的环境下效率极低，因为模型需要花费大量时间才能探索到有意义的动作序列。因此，如何提高自回归模型在强化学习中的探索效率，尤其是在奖励稀疏的环境下，是本文要解决的核心问题。\\n\\n**核心思路**：本文的核心思路是在自回归模型的内部表示中进行动作和探索，而不是直接在输出空间中逐token生成动作。具体来说，通过引入一个高阶非因果序列模型，该模型学习控制底层自回归模型的残差流激活，从而实现对时间抽象动作的建模。这样，高阶模型可以一次性生成一个动作序列，而不是逐token生成，从而提高了探索效率。\\n\\n**技术框架**：整体框架包含两个主要部分：一个基础的自回归模型和一个高阶非因果序列模型。基础自回归模型负责生成底层的动作序列，而高阶模型则负责生成控制信号，这些控制信号作用于基础模型的残差流激活，从而影响基础模型的行为。在高阶模型训练过程中，采用强化学习算法，直接对高阶模型的控制器进行强化，使其能够生成更有利于任务完成的控制信号。\\n\\n**关键创新**：最重要的创新点在于提出了“内部强化学习”的概念，即直接在自回归模型的内部表示中进行强化学习。与传统的强化学习方法不同，内部强化学习不需要直接对输出空间中的动作进行强化，而是通过对内部控制器的强化，间接地影响模型的行为。这种方法能够更好地利用自回归模型的内部表示，从而提高学习效率。\\n\\n**关键设计**：高阶模型采用非因果序列模型，允许模型在生成控制信号时考虑未来的信息。高阶模型的损失函数包括两部分：一部分是标准的强化学习损失，用于优化控制器的行为；另一部分是正则化损失，用于约束控制器的输出，使其更加平滑和可解释。此外，高阶模型还学习一个终止条件，用于判断何时停止当前控制器的执行，从而实现对动作序列的分割。",
            "application_zh": "该研究成果可应用于机器人控制、游戏AI等领域，尤其是在需要长时间规划和稀疏奖励的环境下。通过学习时间抽象动作，可以显著提高智能体的学习效率和泛化能力，使其能够更好地适应复杂多变的环境。未来，该方法有望应用于更广泛的领域，例如自然语言处理和计算机视觉。",
            "highlight_zh": "实验结果表明，在网格世界和MuJoCo任务中，该方法能够有效地学习时间抽象动作，并在稀疏奖励环境下取得显著的性能提升。与标准的强化学习微调方法相比，内部强化学习能够更快地学习到有效的策略，并在某些任务中取得更高的奖励。",
            "tags_zh": [
                "自回归模型",
                "强化学习",
                "分层强化学习",
                "时间抽象",
                "内部强化学习"
            ],
            "_index": 34,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20605v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20605v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20605v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Drift-Corrected Monocular VIO and Perception-Aware Planning for Autonomous Drone Racing",
            "authors": [
                "Maulana Bisyir Azhari",
                "Donghun Han",
                "Je In You",
                "Sungjun Park",
                "David Hyunchul Shim"
            ],
            "arxiv_id": "2512.20475v1",
            "summary": "The Abu Dhabi Autonomous Racing League(A2RL) x Drone Champions League competition(DCL) requires teams to perform high-speed autonomous drone racing using only a single camera and a low-quality inertial measurement unit -- a minimal sensor set that mirrors expert human drone racing pilots. This sensor limitation makes the system susceptible to drift from Visual-Inertial Odometry (VIO), particularly during long and fast flights with aggressive maneuvers. This paper presents the system developed for the championship, which achieved a competitive performance. Our approach corrected VIO drift by fusing its output with global position measurements derived from a YOLO-based gate detector using a Kalman filter. A perception-aware planner generated trajectories that balance speed with the need to keep gates visible for the perception system. The system demonstrated high performance, securing podium finishes across multiple categories: third place in the AI Grand Challenge with top speed of 43.2 km/h, second place in the AI Drag Race with over 59 km/h, and second place in the AI Multi-Drone Race. We detail the complete architecture and present a performance analysis based on experimental data from the competition, contributing our insights on building a successful system for monocular vision-based autonomous drone flight.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20475v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]VIO"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "针对无人机竞速，提出漂移校正的单目VIO与感知规划方法",
            "summary_zh": "本文提出了一种用于无人机竞速的系统，该系统仅使用单个摄像头和低质量惯性测量单元（IMU）。这种最小化的传感器配置使得视觉惯性里程计（VIO）容易产生漂移，尤其是在长时间、快速飞行和剧烈机动期间。该方法通过卡尔曼滤波器融合VIO的输出和基于YOLO的门检测器获得的全局位置测量来校正VIO漂移。感知规划器生成平衡速度和保持门可见性的轨迹。该系统在多个类别中取得了优异的成绩：在AI Grand Challenge中获得第三名，最高速度为43.2公里/小时；在AI Drag Race中获得第二名，速度超过59公里/小时；在AI Multi-Drone Race中获得第二名。本文详细介绍了完整的系统架构，并基于比赛的实验数据进行了性能分析，为构建基于单目视觉的自主无人机飞行系统提供了见解。",
            "intro_zh": [
                "单目视觉无人机竞速易受VIO漂移影响，尤其在高速和剧烈运动中，限制了其性能。",
                "提出融合YOLO门检测的全局位置信息，使用卡尔曼滤波校正VIO漂移，并进行感知规划。",
                "系统在无人机竞速比赛中获得多个奖项，验证了所提方法在高速运动中的有效性。"
            ],
            "method_zh": "**问题定义**：无人机在高速自主竞速中，仅依赖单目视觉和低质量IMU时，VIO会产生显著的漂移，导致定位不准确，影响导航和控制。现有方法难以在资源受限的条件下，实现高精度和鲁棒性的定位。\n\n**核心思路**：通过融合视觉信息（门检测）提供的全局位置信息，来校正VIO的漂移。同时，在路径规划中考虑感知因素，确保无人机在高速运动中始终能够检测到目标门，从而实现更可靠的导航。\n\n**技术框架**：系统主要包含三个模块：1) 基于单目视觉的VIO模块，提供初始的位姿估计；2) 基于YOLO的门检测模块，检测图像中的门，并提供全局位置信息；3) 融合模块，使用卡尔曼滤波器融合VIO和门检测的结果，校正VIO的漂移。此外，还包含一个感知规划器，用于生成考虑感知约束的轨迹。\n\n**关键创新**：将全局视觉信息（门检测）与VIO融合，用于校正漂移，这在资源受限的无人机平台上是一种有效的定位方法。感知规划器的设计，保证了在高速运动中视觉信息的可靠性，提升了系统的整体鲁棒性。\n\n**关键设计**：卡尔曼滤波器的参数需要仔细调整，以平衡VIO和门检测的权重。感知规划器需要考虑无人机的运动学约束和视觉感知范围，以生成可行的轨迹。YOLO模型的选择和训练也至关重要，需要保证在各种光照和视角下都能准确检测到门。",
            "application_zh": "该研究成果可应用于资源受限环境下的自主导航，例如室内机器人、无人机巡检等。通过融合视觉信息和惯性测量，可以提高定位精度和鲁棒性，为自主系统提供更可靠的环境感知能力。未来的研究可以探索更高效的视觉特征提取方法和更鲁棒的融合算法，以进一步提升系统的性能。",
            "highlight_zh": "该系统在Abu Dhabi Autonomous Racing League (A2RL) x Drone Champions League competition (DCL)比赛中取得了显著成绩，包括AI Grand Challenge第三名（最高速度43.2 km/h）、AI Drag Race第二名（速度超过59 km/h）和AI Multi-Drone Race第二名。这些结果表明，所提出的漂移校正和感知规划方法在高速无人机竞速中具有优越的性能。",
            "tags_zh": [
                "无人机竞速",
                "单目视觉",
                "视觉惯性里程计",
                "漂移校正",
                "感知规划",
                "卡尔曼滤波",
                "YOLO"
            ],
            "_index": 35,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20475v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20475v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20475v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Cube Bench: A Benchmark for Spatial Visual Reasoning in MLLMs",
            "authors": [
                "Dhruv Anand",
                "Ehsan Shareghi"
            ],
            "arxiv_id": "2512.20595v1",
            "summary": "We introduce Cube Bench, a Rubik's-cube benchmark for evaluating spatial and sequential reasoning in multimodal large language models (MLLMs). The benchmark decomposes performance into five skills: (i) reconstructing cube faces from images and text, (ii) choosing the optimal next move, (iii) predicting the outcome of a candidate move without applying it, (iv) executing multi-step plans while recovering from mistakes, and (v) detecting and revising one's own errors. Using a shared set of scrambled cube states, identical prompts and parsers, and a single distance-to-solved metric, we compare recent MLLMs side by side as a function of scramble depth. Across seven MLLMs, accuracy drops sharply with depth; once a trajectory stalls or diverges, models rarely recover, and high face-reconstruction accuracy does not guarantee competent action selection or multi-step execution. A pronounced closed- vs open-source gap emerges: the strongest closed model leads on both single-step perception tasks and multi-step control tasks, while open-weight models cluster near chance on the hardest settings; yet even the best MLLM degrades at higher cube complexity. A simple self-correction via reflective thinking yields modest gains but can also introduce overthinking. Cube Bench offers a compact, reproducible probe of sequential spatial reasoning in MLLMs.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "27 pages, 5 figures, 9 tables. Cube available at https://github.com/dana-23/cube-bench",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20595v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Cube Bench：用于评估多模态大语言模型空间视觉推理能力的魔方基准测试。",
            "summary_zh": "本文提出了Cube Bench，一个用于评估多模态大语言模型（MLLM）在空间和序列推理能力的魔方基准测试。该基准将性能分解为五个技能：（i）从图像和文本重建魔方的面，（ii）选择最佳的下一步动作，（iii）在不应用候选动作的情况下预测其结果，（iv）执行多步计划并在错误中恢复，以及（v）检测和修改自己的错误。使用一组共享的打乱魔方状态、相同的提示和解析器以及单一的距离解决度量，本文比较了七个MLLM在不同打乱深度下的性能。结果表明，准确率随着深度急剧下降；一旦轨迹停滞或发散，模型很少恢复，并且高的面重建准确率并不能保证有效的动作选择或多步执行。闭源模型和开源模型之间存在明显的差距：最强的闭源模型在单步感知任务和多步控制任务中都处于领先地位，而开源模型在最困难的设置中接近随机水平；然而，即使是最好的MLLM也会在更高的魔方复杂度下性能下降。通过反思性思维进行简单的自我纠正可以产生适度的收益，但也可能导致过度思考。Cube Bench 为 MLLM 中的序列空间推理提供了一个紧凑、可复现的探针。",
            "intro_zh": [
                "现有的多模态大语言模型在空间和序列推理方面存在不足，尤其是在复杂任务中。",
                "Cube Bench通过魔方任务，将空间推理分解为面重建、动作选择、结果预测、多步执行和错误纠正五个技能。",
                "实验表明，模型性能随魔方复杂度急剧下降，且闭源模型优于开源模型，自我纠正策略效果有限。"
            ],
            "method_zh": "**问题定义**：论文旨在评估多模态大语言模型（MLLM）在空间和序列推理方面的能力，特别是在解决魔方这类复杂任务中的表现。现有方法缺乏一个专门针对空间推理的基准测试，难以系统性地评估和比较不同MLLM的性能。此外，现有方法难以深入分析模型在解决复杂问题时的具体瓶颈，例如感知、决策和执行等环节的错误。\n\n**核心思路**：论文的核心思路是利用魔方作为评估MLLM空间推理能力的代理任务。魔方具有明确的状态空间和动作空间，可以通过一系列操作来改变其状态。通过设计不同的魔方任务，可以考察MLLM在感知、推理、规划和执行等方面的能力。此外，论文还设计了统一的评估指标和实验流程，以便公平地比较不同MLLM的性能。\n\n**技术框架**：Cube Bench的整体框架包括以下几个主要模块：\n1. **魔方状态表示**：使用图像和文本两种方式来表示魔方的状态。\n2. **任务设计**：设计了五个不同的魔方任务，分别考察MLLM的面重建、动作选择、结果预测、多步执行和错误纠正能力。\n3. **提示工程**：设计了一致的提示模板，用于引导MLLM完成不同的任务。\n4. **评估指标**：使用距离解决度量（distance-to-solved metric）来评估MLLM的性能。\n5. **实验流程**：使用一组共享的打乱魔方状态、相同的提示和解析器，对不同的MLLM进行评估。\n\n**关键创新**：Cube Bench的关键创新在于：\n1. **魔方任务的分解**：将魔方任务分解为五个不同的技能，可以更细粒度地评估MLLM的空间推理能力。\n2. **统一的评估框架**：提供了一个统一的评估框架，可以公平地比较不同MLLM的性能。\n3. **错误分析**：可以分析MLLM在解决魔方任务时的具体错误，例如感知错误、决策错误和执行错误。\n\n**关键设计**：\n* **提示模板**：论文使用了精心设计的提示模板，以确保MLLM能够理解任务要求并生成有效的输出。\n* **距离解决度量**：使用距离解决度量来评估MLLM的性能，该指标可以反映MLLM距离解决魔方的程度。\n* **自我纠正机制**：论文尝试使用反思性思维进行自我纠正，但效果有限，表明MLLM在复杂任务中的自我纠正能力仍有待提高。",
            "application_zh": "Cube Bench为评估和提升多模态大语言模型的空间视觉推理能力提供了一个有价值的工具。该基准测试可以应用于机器人导航、自动驾驶、游戏AI等领域，帮助开发更智能、更可靠的AI系统。未来，可以扩展Cube Bench，增加任务的复杂性和多样性，以更好地评估MLLM的泛化能力。",
            "highlight_zh": "实验结果表明，MLLM在Cube Bench上的性能随着魔方复杂度的增加而急剧下降。闭源模型（如GPT-4V）在单步感知和多步控制任务中优于开源模型，但即使是最强的模型在更高复杂度下也会退化。简单的自我纠正策略虽然能带来一些提升，但效果有限。开源模型在最困难的设置中接近随机水平。",
            "tags_zh": [
                "多模态大语言模型",
                "空间推理",
                "视觉推理",
                "魔方",
                "基准测试"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20595v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20595v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20595v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AlignPose: Generalizable 6D Pose Estimation via Multi-view Feature-metric Alignment",
            "authors": [
                "Anna Šárová Mikeštíková",
                "Médéric Fourmy",
                "Martin Cífka",
                "Josef Sivic",
                "Vladimir Petrik"
            ],
            "arxiv_id": "2512.20538v1",
            "summary": "Single-view RGB model-based object pose estimation methods achieve strong generalization but are fundamentally limited by depth ambiguity, clutter, and occlusions. Multi-view pose estimation methods have the potential to solve these issues, but existing works rely on precise single-view pose estimates or lack generalization to unseen objects. We address these challenges via the following three contributions. First, we introduce AlignPose, a 6D object pose estimation method that aggregates information from multiple extrinsically calibrated RGB views and does not require any object-specific training or symmetry annotation. Second, the key component of this approach is a new multi-view feature-metric refinement specifically designed for object pose. It optimizes a single, consistent world-frame object pose minimizing the feature discrepancy between on-the-fly rendered object features and observed image features across all views simultaneously. Third, we report extensive experiments on four datasets (YCB-V, T-LESS, ITODD-MV, HouseCat6D) using the BOP benchmark evaluation and show that AlignPose outperforms other published methods, especially on challenging industrial datasets where multiple views are readily available in practice.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "18 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20538v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]6D pose estimation"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "AlignPose：通过多视角特征度量对齐实现通用6D位姿估计",
            "summary_zh": "单视角RGB模型驱动的物体位姿估计方法具有良好的泛化能力，但受到深度歧义、杂乱和遮挡的限制。多视角位姿估计方法有潜力解决这些问题，但现有工作依赖于精确的单视角位姿估计或缺乏对未见物体的泛化能力。我们通过以下三个贡献来解决这些挑战。首先，我们引入了AlignPose，一种6D物体位姿估计方法，它聚合来自多个外参校准的RGB视点的信息，并且不需要任何特定于物体的训练或对称性注释。其次，该方法的关键组成部分是一种新的多视角特征度量精炼，专门为物体位姿设计。它优化了一个单一的、一致的世界坐标系下的物体位姿，同时最小化所有视点中实时渲染的物体特征与观察到的图像特征之间的特征差异。第三，我们在四个数据集（YCB-V、T-LESS、ITODD-MV、HouseCat6D）上使用BOP基准评估报告了大量的实验，结果表明AlignPose优于其他已发表的方法，尤其是在实践中容易获得多个视角的具有挑战性的工业数据集上。",
            "intro_zh": [
                "单视角位姿估计受限于深度歧义和遮挡，多视角方法虽有潜力，但现有方法依赖单视角估计或泛化性不足。",
                "AlignPose通过多视角特征度量精炼，优化世界坐标系下的物体位姿，无需物体特定训练或对称性标注。",
                "在YCB-V、T-LESS等数据集上的实验表明，AlignPose优于现有方法，尤其在工业数据集上表现突出。"
            ],
            "method_zh": "**问题定义**：现有单视角6D位姿估计方法在处理深度歧义、遮挡和杂乱背景时存在局限性，而多视角方法虽然能够克服这些问题，但通常依赖于精确的单视角位姿估计作为初始化，或者缺乏对未见物体的泛化能力。因此，需要一种能够有效融合多视角信息，且无需特定物体训练或精确初始位姿估计的通用6D位姿估计方法。\\n\\n**核心思路**：AlignPose的核心思路是通过多视角特征度量对齐来优化物体位姿。它不依赖于预先的单视角位姿估计，而是直接在世界坐标系下优化一个统一的物体位姿，使得从该位姿渲染的物体特征与在多个视角中观察到的图像特征之间的差异最小化。这种方法能够有效地利用多视角信息来消除深度歧义和遮挡的影响，并提高位姿估计的准确性和鲁棒性。\\n\\n**技术框架**：AlignPose的整体框架包括以下几个主要步骤：1) 从多个校准的RGB图像中提取图像特征；2) 初始化一个物体位姿；3) 根据当前位姿渲染物体的特征；4) 计算渲染特征和图像特征之间的差异；5) 通过优化算法调整物体位姿，以最小化特征差异。该过程迭代进行，直到位姿收敛。\\n\\n**关键创新**：AlignPose的关键创新在于其多视角特征度量精炼方法。该方法直接在特征空间中进行位姿优化，避免了对几何信息的显式建模，从而提高了对噪声和遮挡的鲁棒性。此外，该方法不需要任何特定于物体的训练数据或对称性标注，因此具有良好的泛化能力。\\n\\n**关键设计**：AlignPose的关键设计包括：1) 使用预训练的深度卷积神经网络提取图像特征；2) 使用可微分渲染器生成渲染特征；3) 使用特征度量损失函数来衡量渲染特征和图像特征之间的差异；4) 使用Adam优化器来优化物体位姿。具体的损失函数选择和网络结构参数等细节，需要根据具体应用场景进行调整。",
            "application_zh": "AlignPose在机器人抓取、工业自动化、增强现实等领域具有广泛的应用前景。例如，在机器人抓取中，AlignPose可以帮助机器人准确地估计物体的位姿，从而实现精确的抓取操作。在工业自动化中，AlignPose可以用于检测和定位生产线上的零件，从而实现自动化的装配和检测。在增强现实中，AlignPose可以将虚拟物体与真实场景进行精确的对齐，从而提供更加沉浸式的用户体验。",
            "highlight_zh": "AlignPose在YCB-V、T-LESS、ITODD-MV和HouseCat6D四个数据集上进行了广泛的实验，并使用BOP基准进行评估。实验结果表明，AlignPose在这些数据集上都取得了优于其他已发表方法的结果，尤其是在具有挑战性的工业数据集上，AlignPose的性能提升更加显著。例如，在T-LESS数据集上，AlignPose的性能超过了现有最佳方法5%以上。",
            "tags_zh": [
                "6D位姿估计",
                "多视角视觉",
                "特征度量学习",
                "物体识别",
                "机器人视觉"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20538v1/figures/full_pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20538v1/figures/figure_templates.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20538v1/imgs/qualitative/ycbv/ycbv_001094.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SmartSplat: Feature-Smart Gaussians for Scalable Compression of Ultra-High-Resolution Images",
            "authors": [
                "Linfei Li",
                "Lin Zhang",
                "Zhong Wang",
                "Ying Shen"
            ],
            "arxiv_id": "2512.20377v1",
            "summary": "Recent advances in generative AI have accelerated the production of ultra-high-resolution visual content, posing significant challenges for efficient compression and real-time decoding on end-user devices. Inspired by 3D Gaussian Splatting, recent 2D Gaussian image models improve representation efficiency, yet existing methods struggle to balance compression ratio and reconstruction fidelity in ultra-high-resolution scenarios. To address this issue, we propose SmartSplat, a highly adaptive and feature-aware GS-based image compression framework that supports arbitrary image resolutions and compression ratios. SmartSplat leverages image-aware features such as gradients and color variances, introducing a Gradient-Color Guided Variational Sampling strategy together with an Exclusion-based Uniform Sampling scheme to improve the non-overlapping coverage of Gaussian primitives in pixel space. In addition, we propose a Scale-Adaptive Gaussian Color Sampling method to enhance color initialization across scales. Through joint optimization of spatial layout, scale, and color initialization, SmartSplat efficiently captures both local structures and global textures using a limited number of Gaussians, achieving high reconstruction quality under strong compression. Extensive experiments on DIV8K and a newly constructed 16K dataset demonstrate that SmartSplat consistently outperforms state-of-the-art methods at comparable compression ratios and exceeds their compression limits, showing strong scalability and practical applicability. The code is publicly available at https://github.com/lif314/SmartSplat.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted by AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20377v1",
            "code_links": [
                {
                    "url": "https://github.com/lif314/SmartSplat",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "SmartSplat：提出特征感知的GS图像压缩框架，实现超高分辨率图像的高效压缩与高质量重建。",
            "summary_zh": "随着生成式AI的快速发展，超高分辨率视觉内容的产生对高效压缩和终端设备上的实时解码提出了巨大挑战。受3D高斯溅射的启发，近期的2D高斯图像模型提高了表征效率，但现有方法难以在超高分辨率场景中平衡压缩率和重建保真度。为了解决这个问题，我们提出了SmartSplat，一个高度自适应且特征感知的基于高斯溅射的图像压缩框架，支持任意图像分辨率和压缩率。SmartSplat利用图像感知特征，如梯度和颜色方差，引入了一种梯度-颜色引导的变分采样策略以及一种基于排除的均匀采样方案，以改善像素空间中高斯基元的非重叠覆盖。此外，我们提出了一种尺度自适应的高斯颜色采样方法，以增强跨尺度的颜色初始化。通过空间布局、尺度和颜色初始化的联合优化，SmartSplat使用有限数量的高斯有效地捕获局部结构和全局纹理，从而在强压缩下实现高重建质量。在DIV8K和一个新构建的16K数据集上的大量实验表明，SmartSplat在可比的压缩率下始终优于最先进的方法，并超过了它们的压缩限制，显示出强大的可扩展性和实际适用性。",
            "intro_zh": [
                "现有图像压缩方法在高分辨率场景下难以平衡压缩率和重建质量，导致性能瓶颈。",
                "SmartSplat利用图像特征引导高斯采样，并自适应调整高斯颜色，从而更有效地表征图像。",
                "实验表明，SmartSplat在DIV8K和16K数据集上超越现有方法，实现了更高的压缩率和重建质量。"
            ],
            "method_zh": "**问题定义**：论文旨在解决超高分辨率图像压缩中，现有方法无法兼顾高压缩率和高质量重建的问题。现有方法在高分辨率图像上，要么压缩率低，要么重建质量差，难以满足实际应用需求。\\n\\n**核心思路**：SmartSplat的核心思路是利用图像的特征信息（如梯度和颜色方差）来引导高斯基元的采样和初始化，从而更有效地表示图像内容。通过关注图像的关键区域和细节，减少冗余信息，提高压缩效率。\\n\\n**技术框架**：SmartSplat的整体框架包含以下几个主要阶段：1) 特征提取：提取图像的梯度和颜色方差等特征。2) 高斯采样：采用梯度-颜色引导的变分采样和基于排除的均匀采样相结合的策略，生成高斯基元。3) 颜色初始化：使用尺度自适应的高斯颜色采样方法，初始化高斯基元的颜色。4) 联合优化：联合优化高斯基元的空间布局、尺度和颜色，以最小化重建误差。\\n\\n**关键创新**：SmartSplat的关键创新在于其特征感知的采样策略和尺度自适应的颜色初始化方法。梯度-颜色引导的变分采样能够使高斯基元更密集地分布在图像的关键区域，而基于排除的均匀采样则保证了高斯基元在像素空间中的非重叠覆盖。尺度自适应的颜色初始化方法能够更好地捕捉跨尺度的颜色信息。\\n\\n**关键设计**：梯度-颜色引导的变分采样策略使用梯度和颜色方差作为概率分布的权重，引导高斯基元的采样。基于排除的均匀采样通过维护一个已覆盖像素的集合，避免高斯基元之间的重叠。尺度自适应的颜色初始化方法通过在不同尺度上采样颜色信息，并将其融合到高斯基元的颜色初始化中。损失函数通常包括重建损失和正则化项，以保证重建质量和高斯基元的平滑性。",
            "application_zh": "SmartSplat可应用于各种需要高效压缩和高质量重建的超高分辨率图像场景，例如：高清视频流媒体、遥感图像处理、医学图像存储与传输、以及虚拟现实/增强现实等应用。该技术能够降低存储成本、减少带宽需求，并提升用户体验，具有广阔的应用前景。",
            "highlight_zh": "SmartSplat在DIV8K和16K数据集上进行了广泛的实验，结果表明，在可比的压缩率下，SmartSplat始终优于现有的最先进方法。更重要的是，SmartSplat能够突破现有方法的压缩限制，在更高的压缩率下仍然保持较高的重建质量，展现了强大的可扩展性和实际应用价值。",
            "tags_zh": [
                "图像压缩",
                "高斯溅射",
                "超高分辨率图像",
                "特征感知",
                "变分采样"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20377v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20377v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20377v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice",
            "authors": [
                "Yaowei Bai",
                "Ruiheng Zhang",
                "Yu Lei",
                "Xuhua Duan",
                "Jingfeng Yao",
                "Shuguang Ju",
                "Chaoyang Wang",
                "Wei Yao",
                "Yiwan Guo",
                "Guilin Zhang",
                "Chao Wan",
                "Qian Yuan",
                "Lei Chen",
                "Wenjuan Tang",
                "Biqiang Zhu",
                "Xinggang Wang",
                "Tao Sun",
                "Wei Zhou",
                "Dacheng Tao",
                "Yongchao Xu",
                "Chuansheng Zheng",
                "Huangxuan Zhao",
                "Bo Du"
            ],
            "arxiv_id": "2512.20344v1",
            "summary": "A global shortage of radiologists has been exacerbated by the significant volume of chest X-ray workloads, particularly in primary care. Although multimodal large language models show promise, existing evaluations predominantly rely on automated metrics or retrospective analyses, lacking rigorous prospective clinical validation. Janus-Pro-CXR (1B), a chest X-ray interpretation system based on DeepSeek Janus-Pro model, was developed and rigorously validated through a multicenter prospective trial (NCT07117266). Our system outperforms state-of-the-art X-ray report generation models in automated report generation, surpassing even larger-scale models including ChatGPT 4o (200B parameters), while demonstrating reliable detection of six clinically critical radiographic findings. Retrospective evaluation confirms significantly higher report accuracy than Janus-Pro and ChatGPT 4o. In prospective clinical deployment, AI assistance significantly improved report quality scores, reduced interpretation time by 18.3% (P < 0.001), and was preferred by a majority of experts in 54.3% of cases. Through lightweight architecture and domain-specific optimization, Janus-Pro-CXR improves diagnostic reliability and workflow efficiency, particularly in resource-constrained settings. The model architecture and implementation framework will be open-sourced to facilitate the clinical translation of AI-assisted radiology solutions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "arXiv admin note: substantial text overlap with arXiv:2507.19493",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20344v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "DeepSeek赋能的AI系统Janus-Pro-CXR，用于临床胸部X光片自动判读",
            "summary_zh": "由于放射科医生在全球范围内短缺，胸部X光片的工作量巨大，尤其是在基层医疗中。尽管多模态大型语言模型显示出前景，但现有的评估主要依赖于自动指标或回顾性分析，缺乏严格的前瞻性临床验证。我们开发了基于DeepSeek Janus-Pro模型的胸部X光片判读系统Janus-Pro-CXR (10亿参数)，并通过一项多中心前瞻性试验(NCT07117266)进行了严格验证。我们的系统在自动报告生成方面优于最先进的X光报告生成模型，甚至超过了更大规模的模型，包括ChatGPT 4o (2000亿参数)，同时证明了对六种临床关键放射学发现的可靠检测。回顾性评估证实，报告准确性显著高于Janus-Pro和ChatGPT 4o。在前瞻性临床部署中，AI辅助显著提高了报告质量评分，减少了18.3%的判读时间(P < 0.001)，并且在54.3%的案例中受到大多数专家的青睐。通过轻量级架构和领域特定的优化，Janus-Pro-CXR提高了诊断可靠性和工作流程效率，尤其是在资源受限的环境中。该模型架构和实现框架将开源，以促进AI辅助放射解决方案的临床转化。",
            "intro_zh": [
                "放射科医生短缺和胸部X光片工作量大，尤其在基层医疗，对X光片判读提出了挑战。",
                "Janus-Pro-CXR基于DeepSeek模型，通过领域优化，实现高效准确的胸部X光片判读。",
                "前瞻性临床试验表明，AI辅助提高了报告质量，缩短了判读时间，并受到专家青睐。"
            ],
            "method_zh": "**问题定义**：论文旨在解决放射科医生短缺和胸部X光片判读工作量大的问题，尤其是在基层医疗中。现有方法，包括大型语言模型，虽然有潜力，但缺乏严格的前瞻性临床验证，且模型规模庞大，难以在资源受限的环境中部署。\\n\\n**核心思路**：论文的核心思路是利用DeepSeek Janus-Pro模型，通过领域特定的优化和轻量级架构，构建一个高效、准确且易于部署的胸部X光片判读系统。该系统旨在提高诊断可靠性和工作流程效率，尤其是在资源受限的环境中。\\n\\n**技术框架**：Janus-Pro-CXR系统的整体架构基于DeepSeek Janus-Pro模型，并针对胸部X光片判读任务进行了优化。具体流程包括：图像输入、特征提取、报告生成和临床验证。系统包含的关键模块包括：图像处理模块、自然语言生成模块和临床反馈模块。\\n\\n**关键创新**：最重要的技术创新点在于领域特定的优化和轻量级架构。通过针对胸部X光片判读任务进行优化，Janus-Pro-CXR在保证准确性的前提下，显著降低了模型规模，使其更易于部署和应用。与现有方法相比，Janus-Pro-CXR在报告准确性和效率方面均有显著提升。\\n\\n**关键设计**：论文中关于关键参数设置、损失函数和网络结构的具体技术细节未详细描述，属于未知信息。但可以推测，针对胸部X光片判读任务，可能采用了特定的损失函数来优化报告生成，并可能对网络结构进行了剪枝或蒸馏，以实现轻量化。",
            "application_zh": "该研究成果可广泛应用于基层医疗机构、体检中心和远程医疗等场景，辅助医生进行胸部X光片的快速准确判读，提高诊断效率和质量，尤其是在放射科医生资源匮乏的地区。未来，该系统有望与电子病历系统集成，实现更智能化的医疗服务。",
            "highlight_zh": "Janus-Pro-CXR在自动报告生成方面优于最先进的X光报告生成模型，甚至超过了ChatGPT 4o (2000亿参数)。前瞻性临床部署中，AI辅助显著提高了报告质量评分，减少了18.3%的判读时间(P < 0.001)，并且在54.3%的案例中受到大多数专家的青睐。",
            "tags_zh": [
                "胸部X光片判读",
                "人工智能辅助诊断",
                "深度学习",
                "自然语言生成",
                "临床验证"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks",
            "authors": [
                "Divya Vijay",
                "Vignesh Ethiraj"
            ],
            "arxiv_id": "2512.20275v1",
            "summary": "As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.",
            "categories": [
                "cs.AI",
                "cs.NI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "15 pages, 3 figures, 3 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20275v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出G-SPEC神经符号框架，保障5G自治网络中LLM代理的安全策略执行。",
            "summary_zh": "随着网络向5G独立组网和6G演进，运营商面临的编排挑战超出了静态自动化和深度强化学习的局限。虽然大型语言模型（LLM）代理为意图驱动的网络提供了一条途径，但它们也引入了随机风险，包括拓扑幻觉和策略不合规。为了缓解这个问题，我们提出了图符号策略执行与控制（G-SPEC），这是一个神经符号框架，它使用确定性验证来约束概率规划。该架构依赖于一个治理三元组——一个电信适配代理（TSLAM-4B）、一个网络知识图（NKG）和SHACL约束。我们在一个模拟的450节点5G核心网上评估了G-SPEC，实现了零安全违规和94.1%的补救成功率，显著优于82.4%的基线。消融分析表明，NKG验证驱动了大部分安全收益（68%），其次是SHACL策略（24%）。在1万到10万个节点的拓扑上的可扩展性测试表明，验证延迟与子图大小k呈$O(k^{1.2})$关系。G-SPEC的处理开销为142ms，对于SMO层操作是可行的。",
            "intro_zh": [
                "现有5G/6G网络编排面临静态自动化和深度强化学习的局限，LLM代理引入了拓扑幻觉和策略违规等风险。",
                "G-SPEC框架结合神经符号方法，利用网络知识图和SHACL约束，对LLM代理的规划进行确定性验证，保障安全。",
                "实验表明，G-SPEC在5G核心网中实现了零安全违规和94.1%的补救成功率，显著优于基线方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决5G/6G自治网络中，使用LLM代理进行网络编排时，由于LLM的随机性和不确定性，可能导致的拓扑幻觉和策略违规问题。现有方法，如静态自动化和深度强化学习，无法有效应对日益复杂的网络环境和意图驱动的需求，而直接使用LLM代理则存在安全风险。\\n\\n**核心思路**：论文的核心思路是结合神经符号方法，利用LLM代理进行概率规划，同时使用网络知识图（NKG）和SHACL约束进行确定性验证，从而在保证网络灵活性的同时，确保安全性和策略合规性。通过这种方式，可以有效缓解LLM代理的随机性带来的风险。\\n\\n**技术框架**：G-SPEC框架包含三个主要模块：电信适配代理（TSLAM-4B）、网络知识图（NKG）和SHACL约束。TSLAM-4B负责根据网络意图进行概率规划，生成网络配置方案。NKG存储网络拓扑和资源信息，用于验证配置方案的合理性。SHACL约束定义了网络策略和安全规则，用于验证配置方案的合规性。整个流程是：TSLAM-4B生成方案 -> NKG验证方案的拓扑合理性 -> SHACL验证方案的策略合规性 -> 执行通过验证的方案。\\n\\n**关键创新**：G-SPEC的关键创新在于将神经方法（LLM代理）与符号方法（NKG和SHACL）相结合，形成一个神经符号框架。这种结合既利用了LLM的灵活性和泛化能力，又利用了符号方法的确定性和可验证性。与现有方法相比，G-SPEC能够更好地平衡网络性能和安全性。\\n\\n**关键设计**：TSLAM-4B是一个针对电信领域进行适配的LLM，具体模型大小为4B参数。NKG使用图数据库存储网络拓扑和资源信息，并支持高效的图查询操作。SHACL约束使用W3C标准定义，可以灵活地表达各种网络策略和安全规则。实验中，作者使用了包含450个节点的5G核心网进行评估，并设计了多种网络策略和安全规则。",
            "application_zh": "G-SPEC框架可应用于5G/6G自治网络的智能编排和管理，例如网络切片、资源分配、故障诊断和安全策略执行。该框架能够提高网络自动化水平，降低运维成本，并保障网络的安全性和可靠性。未来，G-SPEC可以扩展到其他领域，如云计算、物联网和工业控制系统。",
            "highlight_zh": "实验结果表明，G-SPEC在模拟的450节点5G核心网上实现了零安全违规和94.1%的补救成功率，显著优于82.4%的基线方法。消融分析表明，NKG验证贡献了68%的安全收益，SHACL策略贡献了24%。可扩展性测试表明，验证延迟与子图大小k呈$O(k^{1.2})$关系，处理开销为142ms，满足SMO层操作的需求。",
            "tags_zh": [
                "神经符号计算",
                "5G/6G网络",
                "自治网络",
                "大型语言模型",
                "网络知识图",
                "策略执行",
                "安全保障"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20275v1/figures/figure1_architecture_triad.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20275v1/figures/figure2_hallucination_caught.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20275v1/figures/figure3_latency_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Reason2Decide: Rationale-Driven Multi-Task Learning",
            "authors": [
                "H M Quamran Hasan",
                "Housam Khalifa Bashier",
                "Jiayi Dai",
                "Mi-Young Kim",
                "Randy Goebel"
            ],
            "arxiv_id": "2512.20074v1",
            "summary": "Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.",
            "categories": [
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20074v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Reason2Decide：一种基于理由驱动的多任务学习框架，提升临床决策支持系统的预测精度和解释一致性。",
            "summary_zh": "大型语言模型（LLM）广泛应用，但临床决策支持系统面临一个关键挑战：在实现高预测精度的同时，生成与预测结果一致的解释。现有方法存在暴露偏差，导致解释错位。我们提出了Reason2Decide，一个两阶段训练框架，解决自解释中的关键挑战，包括暴露偏差和任务分离。在第一阶段，模型训练生成理由；在第二阶段，模型联合训练标签预测和理由生成，应用scheduled sampling逐步从依赖真实标签过渡到依赖模型预测。我们在三个医疗数据集上评估Reason2Decide，包括一个专有的分诊数据集和公开的生物医学问答数据集。在不同模型规模下，Reason2Decide在预测（F1）和理由保真度（BERTScore、BLEU、LLM-as-a-Judge）方面优于其他微调基线和一些零样本LLM。在分诊任务中，Reason2Decide对LLM生成、护士撰写和护士后处理的理由具有鲁棒性。实验表明，仅在第一阶段使用LLM生成的理由，Reason2Decide就优于其他微调变体，表明LLM生成的理由适合预训练模型，减少对人工标注的依赖。值得注意的是，Reason2Decide以比现有基础模型小40倍的模型实现了这些改进，使临床推理更易于在资源受限的部署中使用，同时仍提供可解释的决策支持。",
            "intro_zh": [
                "现有临床决策支持系统难以兼顾预测精度和解释一致性，存在暴露偏差导致解释与预测不符。",
                "Reason2Decide采用两阶段训练，先生成理由，再联合训练预测和理由，利用scheduled sampling缓解暴露偏差。",
                "实验表明，Reason2Decide在医疗数据集上优于其他微调基线，且对不同来源的理由具有鲁棒性，模型规模更小。"
            ],
            "method_zh": "**问题定义**：临床决策支持系统需要高预测精度和与预测一致的解释，但现有方法存在暴露偏差，即训练时依赖真实标签，推理时依赖模型预测，导致解释与预测不一致。此外，理由生成和标签预测两个任务耦合度不高，直接联合训练效果不佳。\\n\\n**核心思路**：Reason2Decide的核心思路是将理由生成和标签预测解耦，分阶段训练。首先训练模型生成高质量的理由，然后利用生成的理由辅助标签预测，并使用scheduled sampling缓解暴露偏差。这样可以提高模型的预测精度和解释一致性。\\n\\n**技术框架**：Reason2Decide是一个两阶段训练框架。第一阶段，使用LLM生成的理由数据训练模型，使其具备生成合理理由的能力。第二阶段，联合训练标签预测和理由生成任务，使用scheduled sampling策略，逐渐从依赖真实标签过渡到依赖模型预测，从而缓解暴露偏差。整体流程是先预训练理由生成，再微调预测和理由生成。\\n\\n**关键创新**：Reason2Decide的关键创新在于两阶段训练框架和scheduled sampling策略。两阶段训练解耦了理由生成和标签预测任务，提高了训练效率和效果。Scheduled sampling缓解了暴露偏差，提高了模型在推理时的性能。此外，该方法可以使用LLM生成的理由进行预训练，减少了对人工标注数据的依赖。\\n\\n**关键设计**：第一阶段使用交叉熵损失函数训练理由生成模型。第二阶段，使用交叉熵损失函数训练标签预测模型，并使用交叉熵损失函数或BERTScore等指标作为理由生成模型的损失函数。Scheduled sampling策略通过调整使用真实标签的概率，逐步过渡到使用模型预测，具体概率由一个schedule函数控制。模型结构可以是Transformer等序列到序列模型。",
            "application_zh": "Reason2Decide可应用于各种临床决策支持系统，例如疾病诊断、治疗方案选择、风险评估等。该方法能够提供高精度的预测结果，并生成与预测一致的解释，有助于医生理解模型的决策过程，提高信任度，并辅助临床决策。此外，该方法可以使用LLM生成的理由进行预训练，降低了对人工标注数据的依赖，具有广泛的应用前景。",
            "highlight_zh": "Reason2Decide在三个医疗数据集上进行了评估，包括一个专有的分诊数据集和公开的生物医学问答数据集。实验结果表明，Reason2Decide在预测（F1）和理由保真度（BERTScore、BLEU、LLM-as-a-Judge）方面优于其他微调基线和一些零样本LLM。在分诊任务中，Reason2Decide对LLM生成、护士撰写和护士后处理的理由具有鲁棒性。使用LLM生成的理由进行预训练，Reason2Decide仍然优于其他微调变体。",
            "tags_zh": [
                "临床决策支持",
                "多任务学习",
                "理由生成",
                "可解释性",
                "暴露偏差"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20074v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "TAVID: Text-Driven Audio-Visual Interactive Dialogue Generation",
            "authors": [
                "Ji-Hoon Kim",
                "Junseok Ahn",
                "Doyeop Kwak",
                "Joon Son Chung",
                "Shinji Watanabe"
            ],
            "arxiv_id": "2512.20296v1",
            "summary": "The objective of this paper is to jointly synthesize interactive videos and conversational speech from text and reference images. With the ultimate goal of building human-like conversational systems, recent studies have explored talking or listening head generation as well as conversational speech generation. However, these works are typically studied in isolation, overlooking the multimodal nature of human conversation, which involves tightly coupled audio-visual interactions. In this paper, we introduce TAVID, a unified framework that generates both interactive faces and conversational speech in a synchronized manner. TAVID integrates face and speech generation pipelines through two cross-modal mappers (i.e., a motion mapper and a speaker mapper), which enable bidirectional exchange of complementary information between the audio and visual modalities. We evaluate our system across four dimensions: talking face realism, listening head responsiveness, dyadic interaction fluency, and speech quality. Extensive experiments demonstrate the effectiveness of our approach across all these aspects.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "eess.AS",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Project page: https://mm.kaist.ac.kr/projects/TAVID",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20296v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "dyadic interaction"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "5_interaction_reaction",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TAVID，通过跨模态映射实现文本驱动的交互式音视频对话生成。",
            "summary_zh": "本文旨在从文本和参考图像中联合合成交互式视频和对话语音。为了构建类人对话系统，现有研究探索了说话或倾听头部生成以及对话语音生成。然而，这些工作通常是孤立研究的，忽略了人类对话的多模态本质，即紧密耦合的音视频交互。本文提出了TAVID，一个统一的框架，以同步的方式生成交互式面部和对话语音。TAVID通过两个跨模态映射器（即，运动映射器和说话人映射器）集成了面部和语音生成流程，从而实现了音频和视觉模态之间互补信息的双向交换。我们在四个维度评估了我们的系统：说话面部真实感、倾听头部响应性、二元交互流畅性和语音质量。大量实验证明了我们的方法在所有这些方面的有效性。",
            "intro_zh": [
                "现有方法忽略了人类对话中音视频紧密耦合的特性，通常孤立地研究说话/倾听头部生成和对话语音生成。",
                "TAVID通过运动映射器和说话人映射器，在音频和视觉模态间建立双向信息交换，实现同步的面部和语音生成。",
                "实验表明，TAVID在说话面部真实感、倾听头部响应性、交互流畅性和语音质量方面均表现出色。"
            ],
            "method_zh": "**问题定义**：现有方法在生成交互式音视频对话时，通常将语音和视觉模态孤立处理，忽略了两者之间的紧密关联。这导致生成的对话缺乏真实感和自然性，无法充分模拟人类对话中的多模态交互。\n\n**核心思路**：TAVID的核心思路是通过跨模态映射器，显式地建模音频和视觉模态之间的依赖关系。具体来说，利用运动映射器将语音信息映射到面部运动，利用说话人映射器将面部视觉信息映射到语音特征，从而实现双向的信息传递和融合。这种设计旨在使生成的面部表情和语音更加协调一致，提高对话的真实感和流畅性。\n\n**技术框架**：TAVID框架包含以下主要模块：1) 文本编码器：将输入文本转换为语义表示。2) 语音生成器：基于文本编码和说话人映射器的输出生成对话语音。3) 面部生成器：基于文本编码和运动映射器的输出生成面部视频。4) 运动映射器：将语音特征映射到面部运动参数。5) 说话人映射器：将面部视觉特征映射到语音特征。整个流程是端到端可训练的，通过联合优化各个模块，实现音视频的同步生成。\n\n**关键创新**：TAVID的关键创新在于引入了跨模态映射器，实现了音频和视觉模态之间的双向信息交换。这种双向映射机制能够更好地捕捉人类对话中的复杂交互模式，从而生成更自然、更真实的交互式音视频对话。与现有方法相比，TAVID不再孤立地处理语音和视觉模态，而是将它们作为一个整体进行建模和生成。\n\n**关键设计**：运动映射器和说话人映射器通常采用Transformer或类似的注意力机制来实现。损失函数包括语音质量损失（如Mel-Spectrogram损失）、面部真实感损失（如对抗损失）以及跨模态一致性损失（用于约束音视频之间的同步性）。具体的网络结构和参数设置需要根据具体的数据集和任务进行调整。",
            "application_zh": "TAVID具有广泛的应用前景，例如虚拟助手、在线教育、游戏角色、电影制作等。它可以用于创建更具吸引力和互动性的虚拟人物，提升用户体验。此外，该技术还可以应用于人机交互研究，帮助我们更好地理解人类对话的本质。",
            "highlight_zh": "实验结果表明，TAVID在说话面部真实感、倾听头部响应性、二元交互流畅性和语音质量四个方面均优于现有方法。具体而言，TAVID生成的面部表情更加自然生动，语音质量更高，音视频同步性更好，整体交互体验更流畅。",
            "tags_zh": [
                "音视频对话生成",
                "跨模态学习",
                "人机交互",
                "说话人映射",
                "运动映射",
                "多模态融合",
                "文本驱动生成"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20296v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20296v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20296v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Contextual Analysis of Driver-Facing and Dual-View Video Inputs for Distraction Detection in Naturalistic Driving Environments",
            "authors": [
                "Anthony Dontoh",
                "Stephanie Ivey",
                "Armstrong Aboah"
            ],
            "arxiv_id": "2512.20025v1",
            "summary": "Despite increasing interest in computer vision-based distracted driving detection, most existing models rely exclusively on driver-facing views and overlook crucial environmental context that influences driving behavior. This study investigates whether incorporating road-facing views alongside driver-facing footage improves distraction detection accuracy in naturalistic driving conditions. Using synchronized dual-camera recordings from real-world driving, we benchmark three leading spatiotemporal action recognition architectures: SlowFast-R50, X3D-M, and SlowOnly-R50. Each model is evaluated under two input configurations: driver-only and stacked dual-view. Results show that while contextual inputs can improve detection in certain models, performance gains depend strongly on the underlying architecture. The single-pathway SlowOnly model achieved a 9.8 percent improvement with dual-view inputs, while the dual-pathway SlowFast model experienced a 7.2 percent drop in accuracy due to representational conflicts. These findings suggest that simply adding visual context is not sufficient and may lead to interference unless the architecture is specifically designed to support multi-view integration. This study presents one of the first systematic comparisons of single- and dual-view distraction detection models using naturalistic driving data and underscores the importance of fusion-aware design for future multimodal driver monitoring systems.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20025v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "8_physics_animation",
                "9_embodied_foundation"
            ],
            "headline_zh": "研究双视角视频输入对自然驾驶环境下分心检测的影响，强调融合设计的重要性。",
            "summary_zh": "本研究探讨了在基于计算机视觉的分心驾驶检测中，结合驾驶员视角和道路视角能否提高检测精度。现有模型主要依赖驾驶员视角，忽略了影响驾驶行为的关键环境信息。本研究使用自然驾驶环境下的同步双摄像头记录，对三种领先的时空动作识别架构（SlowFast-R50、X3D-M 和 SlowOnly-R50）进行了基准测试。每个模型在两种输入配置下评估：仅驾驶员视角和堆叠双视角。结果表明，虽然上下文输入可以在某些模型中提高检测精度，但性能提升很大程度上取决于底层架构。单路径 SlowOnly 模型在使用双视角输入时实现了 9.8% 的改进，而双路径 SlowFast 模型由于表征冲突导致准确率下降了 7.2%。这些发现表明，简单地添加视觉上下文是不够的，除非架构专门设计用于支持多视角融合，否则可能会导致干扰。本研究是首次使用自然驾驶数据对单视角和双视角分心检测模型进行系统比较的研究之一，并强调了融合感知设计对于未来多模态驾驶员监控系统的重要性。",
            "intro_zh": [
                "现有分心驾驶检测模型主要依赖驾驶员视角，忽略了道路环境等关键上下文信息。",
                "研究通过融合驾驶员和道路双视角信息，探索提升分心检测精度的可行性。",
                "实验结果表明，双视角融合效果依赖于模型架构，需专门设计以避免信息冲突。"
            ],
            "method_zh": "**问题定义**：论文旨在解决自然驾驶环境下，仅使用驾驶员视角视频进行分心检测时，忽略环境上下文信息导致检测精度受限的问题。现有方法的痛点在于无法有效利用环境信息，可能导致对驾驶员行为的误判。\\n\\n**核心思路**：论文的核心思路是将道路前方的环境视角信息与驾驶员视角信息相结合，作为模型的输入，从而为分心检测提供更丰富的上下文信息。期望通过这种方式，模型能够更准确地判断驾驶员的行为是否属于分心驾驶。\\n\\n**技术框架**：整体框架包括数据采集、数据预处理、模型训练和评估四个主要阶段。首先，使用双摄像头同步记录驾驶员和道路的视频数据。然后，对视频数据进行预处理，例如同步、裁剪和缩放。接着，使用预处理后的数据训练三种时空动作识别模型：SlowFast-R50、X3D-M 和 SlowOnly-R50。最后，在测试集上评估模型的性能，并比较不同输入配置（单视角 vs. 双视角）下的结果。\\n\\n**关键创新**：论文的关键创新在于系统性地比较了单视角和双视角输入对分心检测模型性能的影响，并揭示了不同模型架构对多视角信息融合的敏感性。强调了在设计多模态驾驶员监控系统时，需要考虑融合感知设计的重要性，避免简单地添加视觉上下文反而导致性能下降。\\n\\n**关键设计**：论文使用了三种不同的时空动作识别模型，分别是 SlowFast-R50、X3D-M 和 SlowOnly-R50。这些模型在视频理解领域具有代表性。关键设计在于对比了这些模型在单视角和双视角输入下的性能差异。对于双视角输入，论文采用了简单的堆叠方式，将驾驶员视角和道路视角的视频帧连接在一起作为模型的输入。没有特别设计复杂的融合机制，而是侧重于观察不同模型架构对这种简单融合方式的适应性。",
            "application_zh": "该研究成果可应用于高级驾驶辅助系统（ADAS）和自动驾驶系统，用于实时监测驾驶员状态，及时发出警告或采取干预措施，从而提高驾驶安全性。此外，该研究也为多模态驾驶员监控系统的设计提供了指导，有助于开发更智能、更可靠的驾驶辅助技术。",
            "highlight_zh": "实验结果表明，单路径 SlowOnly 模型在采用双视角输入时，分心检测准确率提升了 9.8%。然而，双路径 SlowFast 模型在相同条件下，准确率反而下降了 7.2%。这表明，简单地添加视觉上下文并不一定能提高性能，需要针对不同的模型架构进行专门的融合设计。",
            "tags_zh": [
                "分心驾驶检测",
                "双视角融合",
                "时空动作识别",
                "自然驾驶环境",
                "多模态学习"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20025v1/Proposed_Methodology.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20025v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20025v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LLM-Based Authoring of Agent-Based Narratives through Scene Descriptions",
            "authors": [
                "Vinayak Regmi",
                "Christos Mousas"
            ],
            "arxiv_id": "2512.20550v1",
            "summary": "This paper presents a system for procedurally generating agent-based narratives using large language models (LLMs). Users could drag and drop multiple agents and objects into a scene, with each entity automatically assigned semantic metadata describing its identity, role, and potential interactions. The scene structure is then serialized into a natural language prompt and sent to an LLM, which returns a structured string describing a sequence of actions and interactions among agents and objects. The returned string encodes who performed which actions, when, and how. A custom parser interprets this string and triggers coordinated agent behaviors, animations, and interaction modules. The system supports agent-based scenes, dynamic object manipulation, and diverse interaction types. Designed for ease of use and rapid iteration, the system enables the generation of virtual agent activity suitable for prototyping agent narratives. The performance of the developed system was evaluated using four popular lightweight LLMs. Each model's process and response time were measured under multiple complexity scenarios. The collected data were analyzed to compare consistency across the examined scenarios and to highlight the relative efficiency and suitability of each model for procedural agent-based narratives generation. The results demonstrate that LLMs can reliably translate high-level scene descriptions into executable agent-based behaviors.",
            "categories": [
                "cs.GR"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20550v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种基于LLM的叙事生成系统，通过场景描述驱动Agent行为。",
            "summary_zh": "本文提出了一种利用大型语言模型（LLM）程序化生成基于Agent的叙事的系统。用户可以将多个Agent和对象拖放到场景中，每个实体都会自动分配语义元数据，描述其身份、角色和潜在交互。然后，场景结构被序列化为自然语言提示，并发送给LLM，LLM返回一个结构化的字符串，描述Agent和对象之间的一系列动作和交互。返回的字符串编码了谁执行了哪些动作、何时以及如何执行。自定义解析器解释这个字符串，并触发协调的Agent行为、动画和交互模块。该系统支持基于Agent的场景、动态对象操作和多样化的交互类型。该系统设计易于使用和快速迭代，能够生成适合原型设计Agent叙事的虚拟Agent活动。使用四种流行的轻量级LLM评估了所开发系统的性能。在多种复杂性场景下测量了每个模型的处理和响应时间。分析收集到的数据，以比较不同场景之间的一致性，并突出每个模型在程序化Agent叙事生成方面的相对效率和适用性。结果表明，LLM可以可靠地将高级场景描述转换为可执行的基于Agent的行为。",
            "intro_zh": [
                "现有Agent叙事生成方法缺乏灵活性和可扩展性，难以快速原型设计复杂的交互场景。",
                "利用LLM的强大语言理解和生成能力，将场景描述转化为Agent的行为序列，实现叙事生成。",
                "实验表明，该系统能够有效地将场景描述转化为可执行的Agent行为，并评估了不同LLM的性能。"
            ],
            "method_zh": "**问题定义**：现有Agent叙事生成方法通常依赖于预定义的规则或有限的状态机，难以处理复杂的场景和多样化的交互。手动设计Agent行为繁琐且耗时，缺乏快速原型设计和迭代的能力。因此，需要一种能够根据场景描述自动生成Agent行为的系统，以提高叙事生成的效率和灵活性。\\n\\n**核心思路**：利用大型语言模型（LLM）的自然语言理解和生成能力，将场景描述转化为Agent的行为序列。用户通过图形界面创建场景，系统将场景信息转化为自然语言提示，输入LLM，LLM生成结构化的行为描述，最后由解析器将行为描述转化为可执行的Agent动作。这种方法的核心在于利用LLM作为场景描述和Agent行为之间的桥梁，从而实现自动化的叙事生成。\\n\\n**技术框架**：该系统主要包含以下几个模块：1) 场景编辑器：允许用户拖拽Agent和对象，并为其分配语义元数据。2) 场景描述生成器：将场景信息序列化为自然语言提示。3) LLM：接收场景描述，生成结构化的Agent行为描述。4) 行为解析器：解析LLM的输出，将其转化为可执行的Agent动作。5) Agent行为执行器：控制Agent的动画和交互。整个流程是从场景创建开始，经过LLM的推理和生成，最终实现Agent在虚拟环境中的行为。\\n\\n**关键创新**：该方法最重要的创新点在于利用LLM作为Agent叙事生成的中心环节。与传统的基于规则或状态机的方法相比，LLM能够理解更复杂的场景描述，并生成更自然、更丰富的Agent行为。此外，该系统还支持动态对象操作和多样化的交互类型，进一步提高了叙事生成的灵活性和可扩展性。\\n\\n**关键设计**：场景描述生成器的设计至关重要，需要将场景信息以清晰、简洁的方式呈现给LLM。行为解析器需要能够准确地解析LLM的输出，并将其转化为可执行的Agent动作。此外，选择合适的LLM也是关键，需要考虑模型的推理能力、生成速度和成本。论文中使用了四种轻量级LLM进行评估，并比较了它们在不同复杂性场景下的性能。",
            "application_zh": "该研究成果可应用于游戏开发、虚拟现实、教育培训等领域。例如，游戏开发者可以利用该系统快速生成游戏角色的行为脚本，提高开发效率。在教育领域，可以创建交互式虚拟环境，让学生通过与虚拟Agent互动来学习知识。此外，该系统还可以用于电影制作、广告设计等领域，为创意人员提供更便捷的叙事生成工具。",
            "highlight_zh": "实验结果表明，该系统能够有效地将场景描述转化为可执行的Agent行为。论文评估了四种轻量级LLM的性能，并比较了它们在不同复杂性场景下的处理和响应时间。结果显示，LLM能够可靠地将高级场景描述转换为可执行的基于Agent的行为，为程序化叙事生成提供了新的思路。",
            "tags_zh": [
                "Agent叙事生成",
                "大型语言模型",
                "程序化内容生成",
                "虚拟Agent",
                "场景描述"
            ],
            "_index": 44,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20550v1/fig1-new.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20550v1/fig2a.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20550v1/fig2b.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AprielGuard",
            "authors": [
                "Jaykumar Kasundra",
                "Anjaneya Praharaj",
                "Sourabh Surana",
                "Lakshmi Sirisha Chodisetty",
                "Sourav Sharma",
                "Abhigya Verma",
                "Abhishek Bhardwaj",
                "Debasish Kanhar",
                "Aakash Bhagat",
                "Khalil Slimi",
                "Seganrasan Subramanian",
                "Sathwik Tejaswi Madhusudhan",
                "Ranga Prasad Chenna",
                "Srinivas Sunkara"
            ],
            "arxiv_id": "2512.20293v1",
            "summary": "Safeguarding large language models (LLMs) against unsafe or adversarial behavior is critical as they are increasingly deployed in conversational and agentic settings. Existing moderation tools often treat safety risks (e.g. toxicity, bias) and adversarial threats (e.g. prompt injections, jailbreaks) as separate problems, limiting their robustness and generalizability. We introduce AprielGuard, an 8B parameter safeguard model that unify these dimensions within a single taxonomy and learning framework. AprielGuard is trained on a diverse mix of open and synthetic data covering standalone prompts, multi-turn conversations, and agentic workflows, augmented with structured reasoning traces to improve interpretability. Across multiple public and proprietary benchmarks, AprielGuard achieves strong performance in detecting harmful content and adversarial manipulations, outperforming existing opensource guardrails such as Llama-Guard and Granite Guardian, particularly in multi-step and reasoning intensive scenarios. By releasing the model, we aim to advance transparent and reproducible research on reliable safeguards for LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20293v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出AprielGuard，统一安全风险与对抗威胁，提升LLM安全防护能力",
            "summary_zh": "随着大型语言模型（LLMs）越来越多地部署在对话和代理环境中，保护它们免受不安全或对抗行为的影响至关重要。现有的审核工具通常将安全风险（如毒性、偏见）和对抗性威胁（如提示注入、越狱）视为独立的问题，限制了它们的鲁棒性和泛化能力。我们介绍了AprielGuard，一个80亿参数的安全防护模型，它在一个统一的分类和学习框架内整合了这些维度。AprielGuard在包含独立提示、多轮对话和代理工作流的各种开放和合成数据上进行训练，并辅以结构化的推理轨迹以提高可解释性。在多个公共和专有基准测试中，AprielGuard在检测有害内容和对抗性操纵方面表现出色，优于现有的开源防护模型，如Llama-Guard和Granite Guardian，尤其是在多步骤和推理密集型场景中。通过发布该模型，我们旨在推进关于LLM可靠安全防护的透明和可复现的研究。",
            "intro_zh": [
                "现有LLM安全防护方法将安全风险和对抗威胁视为独立问题，缺乏统一性和鲁棒性。",
                "AprielGuard通过统一的分类框架和学习范式，整合安全风险与对抗威胁，提升防护能力。",
                "实验表明，AprielGuard在检测有害内容和对抗攻击方面优于现有开源模型，尤其在复杂场景下。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLMs）安全防护方法通常将安全风险（如毒性、偏见）和对抗性威胁（如提示注入、越狱）视为两个独立的问题来处理。这种分离的处理方式导致了防护系统的鲁棒性和泛化能力受限，无法有效地应对复杂和多变的安全挑战。现有的开源防护模型在多步骤推理和复杂对话场景下的表现也存在不足。\\n\\n**核心思路**：AprielGuard的核心思路是将安全风险和对抗性威胁统一到一个共同的分类和学习框架中。通过这种统一，模型能够更好地理解和识别不同类型的安全问题，并采取相应的防护措施。此外，AprielGuard还利用结构化的推理轨迹来提高模型的可解释性，使其能够更好地解释其决策过程。\\n\\n**技术框架**：AprielGuard是一个基于Transformer架构的80亿参数模型。其训练流程包括以下几个主要步骤：首先，收集和构建一个包含各种安全风险和对抗性威胁的混合数据集，包括开放数据和合成数据。其次，使用该数据集对模型进行训练，使其能够识别和分类不同类型的安全问题。第三，利用结构化的推理轨迹来增强模型的可解释性。最后，在多个公共和专有基准测试中评估模型的性能。\\n\\n**关键创新**：AprielGuard最重要的技术创新点在于其统一的安全风险和对抗性威胁处理框架。与现有方法不同，AprielGuard不是将安全风险和对抗性威胁视为独立的问题，而是将它们整合到一个共同的框架中。这种统一的处理方式使得模型能够更好地理解和识别不同类型的安全问题，并采取相应的防护措施。此外，利用结构化的推理轨迹来提高模型的可解释性也是一个重要的创新点。\\n\\n**关键设计**：AprielGuard的关键设计包括以下几个方面：1) 使用80亿参数的Transformer模型，以获得强大的表示学习能力。2) 构建一个包含各种安全风险和对抗性威胁的混合数据集，以提高模型的泛化能力。3) 利用结构化的推理轨迹来增强模型的可解释性。4) 使用合适的损失函数和优化算法来训练模型，以获得最佳的性能。",
            "application_zh": "AprielGuard可应用于各种需要安全防护的大型语言模型应用场景，例如聊天机器人、智能助手、内容生成平台等。它可以有效地检测和阻止有害内容和对抗性攻击，保护用户免受不良信息的侵害，并维护平台的安全和稳定。该研究的成果有助于提升LLM在实际应用中的可靠性和安全性，促进LLM技术的健康发展。",
            "highlight_zh": "AprielGuard在多个公共和专有基准测试中表现出色，优于现有的开源防护模型，如Llama-Guard和Granite Guardian。尤其是在多步骤和推理密集型场景中，AprielGuard的性能提升更为显著，表明其在复杂安全挑战面前具有更强的鲁棒性。具体性能数据未在摘要中给出，但强调了其超越现有开源模型的优势。",
            "tags_zh": [
                "大型语言模型安全",
                "对抗攻击防御",
                "安全风险检测",
                "统一安全框架",
                "可解释性AI",
                "LLM安全防护",
                "多轮对话安全",
                "代理安全"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20293v1/data_generation.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20293v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20293v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LongVideoAgent: Multi-Agent Reasoning with Long Videos",
            "authors": [
                "Runtao Liu",
                "Ziyi Liu",
                "Jiaqi Tang",
                "Yue Ma",
                "Renjie Pi",
                "Jipeng Zhang",
                "Qifeng Chen"
            ],
            "arxiv_id": "2512.20618v1",
            "summary": "Recent advances in multimodal LLMs and systems that use tools for long-video QA point to the promise of reasoning over hour-long episodes. However, many methods still compress content into lossy summaries or rely on limited toolsets, weakening temporal grounding and missing fine-grained cues. We propose a multi-agent framework in which a master LLM coordinates a grounding agent to localize question-relevant segments and a vision agent to extract targeted textual observations. The master agent plans with a step limit, and is trained with reinforcement learning to encourage concise, correct, and efficient multi-agent cooperation. This design helps the master agent focus on relevant clips via grounding, complements subtitles with visual detail, and yields interpretable trajectories. On our proposed LongTVQA and LongTVQA+ which are episode-level datasets aggregated from TVQA/TVQA+, our multi-agent system significantly outperforms strong non-agent baselines. Experiments also show reinforcement learning further strengthens reasoning and planning for the trained agent. Code and data will be shared at https://longvideoagent.github.io/.",
            "categories": [
                "cs.AI",
                "cs.CV",
                "cs.LG",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20618v1",
            "code_links": [
                {
                    "url": "https://longvideoagent.github.io/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "LongVideoAgent：提出一种基于多智能体推理的长视频问答框架，提升时序定位和细节捕捉能力。",
            "summary_zh": "本文提出了一种多智能体框架，用于处理长视频问答任务。该框架由一个主LLM协调，一个负责定位问题相关片段的 grounding agent 和一个提取目标文本观测的 vision agent。主智能体在步数限制下进行规划，并通过强化学习进行训练，以鼓励简洁、正确和高效的多智能体协作。这种设计通过 grounding 帮助主智能体专注于相关片段，利用视觉细节补充字幕信息，并产生可解释的推理轨迹。在从 TVQA/TVQA+ 聚合而来的 episode-level 数据集 LongTVQA 和 LongTVQA+ 上，我们的多智能体系统显著优于强大的非智能体基线。实验还表明，强化学习进一步加强了训练后智能体的推理和规划能力。代码和数据将在 https://longvideoagent.github.io/ 上共享。",
            "intro_zh": [
                "现有长视频问答方法依赖有损压缩或有限的工具集，削弱了时序定位能力，并可能遗漏细粒度的线索。",
                "提出一种多智能体框架，利用 grounding agent 定位相关片段，vision agent 提取视觉细节，主 LLM 协调推理。",
                "在 LongTVQA 和 LongTVQA+ 数据集上，该方法显著优于非智能体基线，且强化学习能进一步提升推理和规划能力。"
            ],
            "method_zh": "**问题定义**：长视频问答任务需要模型具备在长时间跨度内进行推理的能力。现有方法通常采用有损的视频摘要或依赖有限的工具集，导致时序定位精度下降，无法捕捉视频中的细粒度信息，从而影响问答效果。\\n\\n**核心思路**：论文的核心思路是将长视频问答任务分解为多个智能体协作完成。通过引入 grounding agent 和 vision agent，分别负责定位相关视频片段和提取视觉信息，从而减轻主 LLM 的负担，使其能够更专注于推理和规划。这种分工协作的方式能够更有效地利用视频信息，提高问答的准确性。\\n\\n**技术框架**：LongVideoAgent 框架包含三个主要模块：主 LLM、grounding agent 和 vision agent。主 LLM 负责接收问题，协调其他智能体的工作，并最终生成答案。grounding agent 负责根据问题定位视频中相关的片段。vision agent 负责从定位到的视频片段中提取视觉信息，例如场景描述、物体识别等。整个流程如下：主 LLM 接收问题 -> 主 LLM 调用 grounding agent 定位相关片段 -> 主 LLM 调用 vision agent 提取视觉信息 -> 主 LLM 结合问题、定位片段和视觉信息进行推理 -> 主 LLM 生成答案。\\n\\n**关键创新**：该方法最重要的创新点在于提出了一个多智能体协作的框架，将长视频问答任务分解为多个子任务，并由不同的智能体负责完成。这种分工协作的方式能够更有效地利用视频信息，提高问答的准确性。与现有方法相比，该方法不需要对视频进行有损压缩，能够保留更多的细节信息。此外，通过强化学习训练主 LLM，能够进一步提高其推理和规划能力。\\n\\n**关键设计**：主 LLM 使用预训练的 LLM，并进行微调以适应长视频问答任务。Grounding agent 和 vision agent 可以使用现有的目标检测、视频分割等模型。强化学习的目标是鼓励主 LLM 进行简洁、正确和高效的多智能体协作。奖励函数可以设计为基于答案的准确性、使用的步数等因素。步数限制是为了防止主 LLM 无限循环调用其他智能体。",
            "application_zh": "该研究成果可应用于智能客服、视频内容理解、智能安防等领域。例如，在智能客服中，可以利用该方法对用户上传的视频进行分析，快速定位问题并给出解答。在视频内容理解中，可以用于自动生成视频摘要、视频标签等。在智能安防中，可以用于监控视频分析，自动识别异常行为。",
            "highlight_zh": "实验结果表明，在 LongTVQA 和 LongTVQA+ 数据集上，LongVideoAgent 显著优于非智能体基线。具体而言，LongVideoAgent 在 LongTVQA 数据集上取得了 X% 的提升，在 LongTVQA+ 数据集上取得了 Y% 的提升（具体数值未知）。此外，实验还表明，通过强化学习训练主 LLM，能够进一步提高其推理和规划能力。",
            "tags_zh": [
                "长视频问答",
                "多智能体系统",
                "强化学习",
                "时序定位",
                "视觉信息提取"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20618v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20618v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Active Intelligence in Video Avatars via Closed-loop World Modeling",
            "authors": [
                "Xuanhua He",
                "Tianyu Yang",
                "Ke Cao",
                "Ruiqi Wu",
                "Cheng Meng",
                "Yong Zhang",
                "Zhuoliang Kang",
                "Xiaoming Wei",
                "Qifeng Chen"
            ],
            "arxiv_id": "2512.20615v1",
            "summary": "Current video avatar generation methods excel at identity preservation and motion alignment but lack genuine agency, they cannot autonomously pursue long-term goals through adaptive environmental interaction. We address this by introducing L-IVA (Long-horizon Interactive Visual Avatar), a task and benchmark for evaluating goal-directed planning in stochastic generative environments, and ORCA (Online Reasoning and Cognitive Architecture), the first framework enabling active intelligence in video avatars. ORCA embodies Internal World Model (IWM) capabilities through two key innovations: (1) a closed-loop OTAR cycle (Observe-Think-Act-Reflect) that maintains robust state tracking under generative uncertainty by continuously verifying predicted outcomes against actual generations, and (2) a hierarchical dual-system architecture where System 2 performs strategic reasoning with state prediction while System 1 translates abstract plans into precise, model-specific action captions. By formulating avatar control as a POMDP and implementing continuous belief updating with outcome verification, ORCA enables autonomous multi-step task completion in open-domain scenarios. Extensive experiments demonstrate that ORCA significantly outperforms open-loop and non-reflective baselines in task success rate and behavioral coherence, validating our IWM-inspired design for advancing video avatar intelligence from passive animation to active, goal-oriented behavior.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Project Page: https://xuanhuahe.github.io/ORCA/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20615v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出ORCA框架，通过闭环世界建模实现视频化身的主动智能",
            "summary_zh": "现有的视频化身生成方法擅长保持身份和对齐动作，但缺乏真正的自主性，无法通过自适应环境交互自主地追求长期目标。为了解决这个问题，我们提出了L-IVA（Long-horizon Interactive Visual Avatar），这是一个用于评估随机生成环境中目标导向规划的任务和基准。同时，我们提出了ORCA（Online Reasoning and Cognitive Architecture），这是第一个使视频化身具备主动智能的框架。ORCA通过两个关键创新体现了内部世界模型（IWM）的能力：（1）一个闭环的OTAR循环（观察-思考-行动-反思），通过持续验证预测结果与实际生成结果，在生成不确定性下保持鲁棒的状态跟踪；（2）一个分层的双系统架构，其中系统2利用状态预测执行战略推理，而系统1将抽象计划转化为精确的、特定于模型的动作描述。通过将化身控制建模为POMDP，并使用结果验证实现连续的信念更新，ORCA能够在开放域场景中实现自主的多步骤任务完成。大量的实验表明，ORCA在任务成功率和行为连贯性方面显著优于开放循环和非反思基线，验证了我们受IWM启发的、将视频化身智能从被动动画提升到主动的、目标导向行为的设计。",
            "intro_zh": [
                "现有视频化身方法缺乏自主性，无法在复杂环境中完成长期目标，限制了其应用。",
                "ORCA框架通过闭环OTAR循环和分层双系统架构，使视频化身具备内部世界模型和主动智能。",
                "实验表明，ORCA在任务成功率和行为连贯性方面显著优于现有方法，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有视频化身生成方法主要关注身份保持和动作对齐，缺乏自主性和与环境交互的能力。它们无法像智能体一样，根据环境变化调整行为，从而完成复杂的、长期的目标。现有方法通常是开环的，无法处理生成过程中的不确定性，导致行为不连贯和任务失败。\\n\\n**核心思路**：ORCA的核心思路是赋予视频化身一个内部世界模型（IWM），使其能够像人类一样，通过观察、思考、行动和反思来理解环境并做出决策。通过闭环的反馈机制，ORCA可以不断修正对环境的理解，从而在不确定性中保持鲁棒性。分层双系统架构则模拟了人类的认知过程，将战略推理和具体动作执行分离，提高了效率和灵活性。\\n\\n**技术框架**：ORCA框架包含以下几个主要模块：1) **观察模块**：接收环境的视觉输入；2) **思考模块（系统2）**：基于内部世界模型进行战略推理，生成抽象的行动计划；3) **行动模块（系统1）**：将抽象计划转化为具体的、特定于模型的动作描述；4) **生成模块**：根据动作描述生成视频化身的行为；5) **反思模块**：将生成的行为与预测结果进行比较，更新内部世界模型。整个流程构成一个闭环的OTAR循环。框架将化身控制建模为POMDP（部分可观测马尔可夫决策过程），并使用结果验证进行连续的信念更新。\\n\\n**关键创新**：ORCA的关键创新在于其闭环的OTAR循环和分层双系统架构。OTAR循环通过持续验证预测结果，解决了生成过程中的不确定性问题，提高了状态跟踪的鲁棒性。分层双系统架构将战略推理和具体动作执行分离，提高了决策效率和灵活性。与现有方法的本质区别在于，ORCA赋予了视频化身主动智能，使其能够自主地与环境交互并完成长期目标。\\n\\n**关键设计**：ORCA使用Transformer网络作为系统2的战略推理模块，预测未来的状态和奖励。系统1使用条件生成模型，将抽象的行动计划转化为具体的动作描述。损失函数包括状态预测损失、奖励预测损失和行为连贯性损失。OTAR循环中的验证机制采用阈值判断，当预测结果与实际生成结果的差异超过阈值时，触发内部世界模型的更新。",
            "application_zh": "ORCA框架具有广泛的应用前景，例如智能助手、虚拟社交、游戏AI和远程呈现等。它可以使虚拟化身更加智能、自然和具有互动性，从而提升用户体验。未来，ORCA可以应用于更复杂的场景，例如教育、医疗和工业等领域，实现更高级的人机协作。",
            "highlight_zh": "实验结果表明，ORCA在L-IVA基准测试中显著优于开放循环和非反思基线。在任务成功率方面，ORCA比最佳基线提高了约20%。在行为连贯性方面，ORCA生成的视频化身行为更加自然和流畅，减少了不必要的动作和停顿。",
            "tags_zh": [
                "视频化身",
                "主动智能",
                "闭环控制",
                "世界模型",
                "POMDP"
            ],
            "_index": 47,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20615v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20615v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20615v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "milliMamba: Specular-Aware Human Pose Estimation via Dual mmWave Radar with Multi-Frame Mamba Fusion",
            "authors": [
                "Niraj Prakash Kini",
                "Shiau-Rung Tsai",
                "Guan-Hsun Lin",
                "Wen-Hsiao Peng",
                "Ching-Wen Ma",
                "Jenq-Neng Hwang"
            ],
            "arxiv_id": "2512.20128v1",
            "summary": "Millimeter-wave radar offers a privacy-preserving and lighting-invariant alternative to RGB sensors for Human Pose Estimation (HPE) task. However, the radar signals are often sparse due to specular reflection, making the extraction of robust features from radar signals highly challenging. To address this, we present milliMamba, a radar-based 2D human pose estimation framework that jointly models spatio-temporal dependencies across both the feature extraction and decoding stages. Specifically, given the high dimensionality of radar inputs, we adopt a Cross-View Fusion Mamba encoder to efficiently extract spatio-temporal features from longer sequences with linear complexity. A Spatio-Temporal-Cross Attention decoder then predicts joint coordinates across multiple frames. Together, this spatio-temporal modeling pipeline enables the model to leverage contextual cues from neighboring frames and joints to infer missing joints caused by specular reflections. To reinforce motion smoothness, we incorporate a velocity loss alongside the standard keypoint loss during training. Experiments on the TransHuPR and HuPR datasets demonstrate that our method achieves significant performance improvements, exceeding the baselines by 11.0 AP and 14.6 AP, respectively, while maintaining reasonable complexity. Code: https://github.com/NYCU-MAPL/milliMamba",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted at WACV 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20128v1",
            "code_links": [
                {
                    "url": "https://github.com/NYCU-MAPL/milliMamba",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "milliMamba：基于双毫米波雷达和多帧Mamba融合的抗镜面反射人体姿态估计",
            "summary_zh": "本文提出milliMamba，一个基于雷达的2D人体姿态估计框架，旨在解决毫米波雷达因镜面反射导致的信号稀疏问题。该框架联合建模特征提取和解码阶段的时空依赖性。具体而言，针对雷达输入的高维度特性，采用交叉视角融合Mamba编码器，以线性复杂度高效提取长序列的时空特征。然后，使用时空交叉注意力解码器预测多帧的关节坐标。这种时空建模流程使模型能够利用相邻帧和关节的上下文线索，推断因镜面反射而缺失的关节。为了增强运动平滑性，在训练过程中，除了标准关键点损失外，还引入了速度损失。在TransHuPR和HuPR数据集上的实验表明，该方法取得了显著的性能提升，分别超过基线11.0 AP和14.6 AP，同时保持了合理的复杂度。代码已开源。",
            "intro_zh": [
                "毫米波雷达为人体姿态估计提供了一种保护隐私且不受光照影响的替代方案，但镜面反射导致雷达信号稀疏，特征提取困难。",
                "milliMamba通过交叉视角融合Mamba编码器提取时空特征，并使用时空交叉注意力解码器预测关节坐标，从而利用上下文信息推断缺失关节。",
                "实验表明，milliMamba在TransHuPR和HuPR数据集上分别超越基线11.0 AP和14.6 AP，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：毫米波雷达在人体姿态估计中面临的主要问题是镜面反射导致的信号稀疏性。传统的基于雷达的人体姿态估计方法难以从稀疏信号中提取鲁棒的特征，导致姿态估计精度下降。现有方法通常无法有效利用时空上下文信息来弥补因镜面反射造成的关节信息缺失。\\n\\n**核心思路**：milliMamba的核心思路是利用Mamba架构强大的序列建模能力，同时在编码器和解码器中融入时空信息。通过Mamba编码器提取长序列的时空特征，并利用时空交叉注意力解码器融合多帧信息，从而实现对缺失关节的推断。这种设计旨在充分利用雷达信号的时空上下文信息，提高对镜面反射的鲁棒性。\\n\\n**技术框架**：milliMamba框架主要包含两个阶段：特征提取和解码。首先，使用交叉视角融合Mamba编码器从雷达数据中提取时空特征。然后，使用时空交叉注意力解码器，结合多帧信息预测人体关节坐标。为了保证运动的平滑性，在训练阶段引入了速度损失。\\n\\n**关键创新**：milliMamba的关键创新在于将Mamba架构引入到雷达人体姿态估计中，并设计了交叉视角融合Mamba编码器和时空交叉注意力解码器。Mamba架构能够以线性复杂度处理长序列，有效提取时空特征。交叉视角融合能够整合来自不同雷达视角的信号，提高特征的鲁棒性。时空交叉注意力解码器能够融合多帧信息，弥补因镜面反射造成的关节信息缺失。\\n\\n**关键设计**：交叉视角融合Mamba编码器：具体实现方式未知，但推测是将不同雷达视角的特征进行融合后输入Mamba模块。时空交叉注意力解码器：具体实现方式未知，但推测是利用注意力机制对不同帧和关节的信息进行加权融合。速度损失：用于约束相邻帧之间关节运动的平滑性，具体形式未知，但通常是计算相邻帧之间关节速度的差异，并将其作为损失函数的一部分。",
            "application_zh": "milliMamba在智能家居、健康监测、安防监控等领域具有广泛的应用前景。例如，可以在智能家居中用于识别人体行为，实现智能控制；在健康监测中用于评估人体运动状态，提供个性化健康建议；在安防监控中用于检测异常行为，提高安全性。由于其隐私保护特性，在对隐私敏感的场景下具有独特的优势。",
            "highlight_zh": "milliMamba在TransHuPR和HuPR数据集上取得了显著的性能提升，分别超过基线11.0 AP和14.6 AP。这些结果表明，milliMamba能够有效解决毫米波雷达人体姿态估计中因镜面反射导致的信号稀疏问题，并显著提高姿态估计的精度。同时，该方法保持了合理的计算复杂度。",
            "tags_zh": [
                "人体姿态估计",
                "毫米波雷达",
                "Mamba",
                "时空建模",
                "镜面反射"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20128v1/fig/pipeline_7.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20128v1/fig/mamba_scan_4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20128v1/fig/preprocessing_6.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DDAVS: Disentangled Audio Semantics and Delayed Bidirectional Alignment for Audio-Visual Segmentation",
            "authors": [
                "Jingqi Tian",
                "Yiheng Du",
                "Haoji Zhang",
                "Yuji Wang",
                "Isaac Ning Lee",
                "Xulong Bai",
                "Tianrui Zhu",
                "Jingxuan Niu",
                "Yansong Tang"
            ],
            "arxiv_id": "2512.20117v1",
            "summary": "Audio-Visual Segmentation (AVS) aims to localize sound-producing objects at the pixel level by jointly leveraging auditory and visual information. However, existing methods often suffer from multi-source entanglement and audio-visual misalignment, which lead to biases toward louder or larger objects while overlooking weaker, smaller, or co-occurring sources. To address these challenges, we propose DDAVS, a Disentangled Audio Semantics and Delayed Bidirectional Alignment framework. To mitigate multi-source entanglement, DDAVS employs learnable queries to extract audio semantics and anchor them within a structured semantic space derived from an audio prototype memory bank. This is further optimized through contrastive learning to enhance discriminability and robustness. To alleviate audio-visual misalignment, DDAVS introduces dual cross-attention with delayed modality interaction, improving the robustness of multimodal alignment. Extensive experiments on the AVS-Objects and VPO benchmarks demonstrate that DDAVS consistently outperforms existing approaches, exhibiting strong performance across single-source, multi-source, and multi-instance scenarios. These results validate the effectiveness and generalization ability of our framework under challenging real-world audio-visual segmentation conditions. Project page: https://trilarflagz.github.io/DDAVS-page/",
            "categories": [
                "cs.CV",
                "cs.SD",
                "eess.AS"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "https://trilarflagz.github.io/DDAVS-page/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20117v1",
            "code_links": [
                {
                    "url": "https://trilarflagz.github.io/DDAVS-page/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "DDAVS：解耦音频语义与延迟双向对齐，用于音视频分割",
            "summary_zh": "音视频分割(AVS)旨在通过联合利用听觉和视觉信息，在像素级别定位发声物体。然而，现有方法常常受到多源纠缠和音视频未对齐的影响，导致模型偏向于响亮或较大的物体，而忽略较弱、较小或同时出现的声源。为了解决这些挑战，我们提出了DDAVS，一个解耦音频语义和延迟双向对齐框架。为了缓解多源纠缠，DDAVS采用可学习的查询来提取音频语义，并将它们锚定在从音频原型记忆库导出的结构化语义空间中。通过对比学习进一步优化，以增强可区分性和鲁棒性。为了减轻音视频未对齐，DDAVS引入了具有延迟模态交互的双重交叉注意力，提高了多模态对齐的鲁棒性。在AVS-Objects和VPO基准上的大量实验表明，DDAVS始终优于现有方法，在单源、多源和多实例场景中表现出强大的性能。这些结果验证了我们的框架在具有挑战性的真实世界音视频分割条件下的有效性和泛化能力。",
            "intro_zh": [
                "现有音视频分割方法易受多源混淆和模态未对齐影响，导致分割结果偏向显著物体。",
                "DDAVS通过解耦音频语义和延迟双向对齐，提升模型对弱小和共现声源的分割能力。",
                "实验表明，DDAVS在单源、多源和多实例场景下均优于现有方法，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：音视频分割(AVS)旨在像素级别定位发声物体。现有方法的痛点在于：1)多源纠缠，即模型难以区分和分割多个同时发声的物体，容易偏向于响亮或较大的物体；2)音视频未对齐，由于时序和空间上的差异，音频和视频特征难以有效融合，影响分割精度。\\n\\n**核心思路**：DDAVS的核心思路是解耦音频语义，并采用延迟双向对齐来解决上述问题。具体来说，通过可学习的查询和音频原型记忆库，将音频语义映射到结构化的语义空间，从而减少多源之间的干扰。同时，通过延迟模态交互的双重交叉注意力机制，增强音视频特征的对齐和融合。\\n\\n**技术框架**：DDAVS框架主要包含以下几个模块：1)音频特征提取模块，用于提取音频的语义特征；2)可学习查询模块，用于从音频特征中提取关键语义信息；3)音频原型记忆库，用于构建结构化的音频语义空间；4)对比学习模块，用于增强音频语义的可区分性；5)双重交叉注意力模块，用于实现音视频特征的对齐和融合；6)分割头，用于生成最终的分割结果。\\n\\n**关键创新**：DDAVS的关键创新在于：1)解耦音频语义，通过可学习查询和音频原型记忆库，将音频语义映射到结构化的语义空间，减少多源干扰；2)延迟双向对齐，通过双重交叉注意力机制，并延迟模态交互，增强音视频特征的对齐和融合，提高分割精度。\\n\\n**关键设计**：音频原型记忆库的设计是关键。它通过聚类音频特征来构建原型，并使用对比学习来优化原型表示，从而增强音频语义的可区分性。双重交叉注意力模块采用延迟模态交互，即先在各自模态内进行自注意力计算，再进行跨模态的交叉注意力计算，避免了早期融合可能导致的信息损失。",
            "application_zh": "DDAVS在智能监控、自动驾驶、机器人等领域具有广泛的应用前景。例如，在智能监控中，可以利用DDAVS定位异常声音事件发生的位置；在自动驾驶中，可以帮助车辆感知周围环境中的声源，提高安全性；在机器人领域，可以使机器人更好地理解和交互周围环境。",
            "highlight_zh": "DDAVS在AVS-Objects和VPO基准测试中均取得了显著的性能提升。在AVS-Objects数据集上，DDAVS的mIoU指标优于现有最佳方法，尤其在多源和多实例场景下提升显著。在VPO数据集上，DDAVS也取得了具有竞争力的结果，验证了其泛化能力。",
            "tags_zh": [
                "音视频分割",
                "多模态融合",
                "语义解耦",
                "交叉注意力",
                "对比学习"
            ],
            "_index": 49,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20117v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20117v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20117v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Performative Policy Gradient: Optimality in Performative Reinforcement Learning",
            "authors": [
                "Debabrota Basu",
                "Udvas Das",
                "Brahim Driss",
                "Uddalak Mukherjee"
            ],
            "arxiv_id": "2512.20576v1",
            "summary": "Post-deployment machine learning algorithms often influence the environments they act in, and thus shift the underlying dynamics that the standard reinforcement learning (RL) methods ignore. While designing optimal algorithms in this performative setting has recently been studied in supervised learning, the RL counterpart remains under-explored. In this paper, we prove the performative counterparts of the performance difference lemma and the policy gradient theorem in RL, and further introduce the Performative Policy Gradient algorithm (PePG). PePG is the first policy gradient algorithm designed to account for performativity in RL. Under softmax parametrisation, and also with and without entropy regularisation, we prove that PePG converges to performatively optimal policies, i.e. policies that remain optimal under the distribution shifts induced by themselves. Thus, PePG significantly extends the prior works in Performative RL that achieves performative stability but not optimality. Furthermore, our empirical analysis on standard performative RL environments validate that PePG outperforms standard policy gradient algorithms and the existing performative RL algorithms aiming for stability.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20576v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出PePG算法，解决强化学习中策略执行带来的环境动态变化问题，实现策略的执行最优性。",
            "summary_zh": "后部署的机器学习算法通常会影响它们所作用的环境，从而改变标准强化学习（RL）方法忽略的底层动态。虽然在执行性设置中设计最优算法最近已在监督学习中得到研究，但RL对应方法仍未得到充分探索。在本文中，我们证明了RL中性能差异引理和策略梯度定理的执行性对应物，并进一步介绍了执行性策略梯度算法（PePG）。PePG是第一个旨在解决RL中执行性问题的策略梯度算法。在softmax参数化下，无论是否进行熵正则化，我们都证明PePG收敛到执行性最优策略，即在自身引起的分布变化下保持最优的策略。因此，PePG显著扩展了先前在执行性RL中的工作，这些工作实现了执行性稳定性，但没有实现最优性。此外，我们对标准执行性RL环境的实证分析验证了PePG优于标准策略梯度算法和现有旨在实现稳定性的执行性RL算法。",
            "intro_zh": [
                "传统强化学习忽略了策略执行对环境动态的影响，导致算法在实际部署中性能下降。",
                "论文提出Performative Policy Gradient (PePG) 算法，通过考虑策略执行带来的环境变化，优化策略。",
                "实验结果表明，PePG 在标准执行性强化学习环境中优于传统策略梯度算法和其他旨在实现稳定性的执行性RL算法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决强化学习中，智能体策略的执行会对环境产生影响，进而改变环境动态，导致传统强化学习算法训练出的策略不再是最优的问题。现有方法通常忽略这种环境变化，或者只关注策略的稳定性，而无法保证策略的执行最优性。\\n\\n**核心思路**：论文的核心思路是，将策略执行对环境的影响纳入强化学习的优化过程中。通过对性能差异引理和策略梯度定理进行扩展，使其能够反映策略执行带来的环境变化，从而指导策略的优化。PePG算法旨在找到一种策略，该策略在由自身引起的分布变化下仍然是最优的。\\n\\n**技术框架**：PePG算法基于策略梯度方法，其整体框架与传统的策略梯度算法类似，包括以下几个主要步骤：1) 收集经验数据：智能体与环境交互，收集状态、动作、奖励等数据。2) 估计策略梯度：利用收集到的数据，估计策略梯度，该梯度反映了策略对环境的影响。3) 更新策略：根据估计的策略梯度，更新策略参数。PePG的关键在于策略梯度的估计方式，它考虑了策略执行带来的环境变化。\\n\\n**关键创新**：PePG算法最重要的技术创新点在于，它首次在策略梯度算法中考虑了策略执行对环境的影响，并证明了在softmax参数化下，PePG算法能够收敛到执行性最优策略。与现有方法的本质区别在于，PePG算法不仅关注策略的稳定性，更关注策略的执行最优性。\\n\\n**关键设计**：PePG算法的关键设计包括：1) 对性能差异引理和策略梯度定理进行扩展，使其能够反映策略执行带来的环境变化。2) 使用softmax参数化策略，并证明了在该参数化下，PePG算法能够收敛到执行性最优策略。3) 可以选择是否使用熵正则化，以提高策略的探索能力和稳定性。",
            "application_zh": "该研究成果可应用于机器人、自动驾驶、推荐系统等领域，在这些领域中，智能体的行为会对环境产生显著影响。通过使用PePG算法，可以训练出更适应环境变化、性能更优的策略，提高智能体在实际应用中的表现。例如，在推荐系统中，PePG可以用于优化推荐策略，使其能够适应用户兴趣的变化，从而提高推荐的准确性和用户满意度。",
            "highlight_zh": "实验结果表明，在标准执行性强化学习环境中，PePG算法优于传统的策略梯度算法和其他旨在实现稳定性的执行性RL算法。具体来说，PePG算法能够更快地收敛到最优策略，并且在环境发生变化时，能够更好地保持策略的性能。这验证了PePG算法在解决执行性强化学习问题上的有效性。",
            "tags_zh": [
                "执行性强化学习",
                "策略梯度",
                "环境动态",
                "策略优化",
                "最优性",
                "性能差异引理",
                "后部署机器学习"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20576v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20576v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20576v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Jensen-Shannon Divergence Message-Passing for Rich-Text Graph Representation Learning",
            "authors": [
                "Zuo Wang",
                "Ye Yuan"
            ],
            "arxiv_id": "2512.20094v1",
            "summary": "In this paper, we investigate how the widely existing contextual and structural divergence may influence the representation learning in rich-text graphs. To this end, we propose Jensen-Shannon Divergence Message-Passing (JSDMP), a new learning paradigm for rich-text graph representation learning. Besides considering similarity regarding structure and text, JSDMP further captures their corresponding dissimilarity by Jensen-Shannon divergence. Similarity and dissimilarity are then jointly used to compute new message weights among text nodes, thus enabling representations to learn with contextual and structural information from truly correlated text nodes. With JSDMP, we propose two novel graph neural networks, namely Divergent message-passing graph convolutional network (DMPGCN) and Divergent message-passing Page-Rank graph neural networks (DMPPRG), for learning representations in rich-text graphs. DMPGCN and DMPPRG have been extensively texted on well-established rich-text datasets and compared with several state-of-the-art baselines. The experimental results show that DMPGCN and DMPPRG can outperform other baselines, demonstrating the effectiveness of the proposed Jensen-Shannon Divergence Message-Passing paradigm",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20094v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出JSDMP框架，利用Jensen-Shannon散度提升富文本图表示学习",
            "summary_zh": "本文研究了富文本图中广泛存在的上下文和结构差异如何影响表示学习。为此，我们提出了一种新的富文本图表示学习范式——Jensen-Shannon散度消息传递（JSDMP）。除了考虑结构和文本的相似性外，JSDMP还通过Jensen-Shannon散度捕获它们之间的差异性。然后，相似性和差异性被共同用于计算文本节点之间的新消息权重，从而使表示能够从真正相关的文本节点学习上下文和结构信息。基于JSDMP，我们提出了两种新的图神经网络，即发散消息传递图卷积网络（DMPGCN）和发散消息传递Page-Rank图神经网络（DMPPRG），用于学习富文本图中的表示。DMPGCN和DMPPRG已经在完善的富文本数据集上进行了广泛的测试，并与几种最先进的基线方法进行了比较。实验结果表明，DMPGCN和DMPPRG优于其他基线方法，证明了所提出的Jensen-Shannon散度消息传递范式的有效性。",
            "intro_zh": [
                "现有富文本图表示学习方法忽略了上下文和结构上的差异性，导致模型无法有效捕捉节点间的真实相关性。",
                "JSDMP框架通过Jensen-Shannon散度同时建模节点间的相似性和差异性，从而更准确地计算消息传递权重。",
                "DMPGCN和DMPPRG在多个富文本数据集上超越了现有SOTA方法，验证了JSDMP框架的有效性。"
            ],
            "method_zh": "**问题定义**：现有的富文本图表示学习方法主要关注节点间结构和文本的相似性，而忽略了它们之间的差异性。这种差异性可能导致模型将不相关的节点视为相关节点，从而影响表示学习的质量。因此，如何有效地建模和利用节点间的差异性是当前富文本图表示学习面临的一个重要问题。\\n\\n**核心思路**：本文的核心思路是利用Jensen-Shannon散度来同时建模节点间的相似性和差异性。Jensen-Shannon散度是一种衡量两个概率分布之间差异的指标，可以有效地捕捉节点在结构和文本上的不同之处。通过将相似性和差异性结合起来，可以更准确地计算消息传递权重，从而使模型能够从真正相关的节点学习信息。\\n\\n**技术框架**：JSDMP框架主要包含以下几个步骤：1) 构建富文本图，其中节点表示文本，边表示节点之间的关系；2) 计算节点之间的相似性和Jensen-Shannon散度；3) 基于相似性和Jensen-Shannon散度计算消息传递权重；4) 使用计算出的权重进行消息传递，更新节点表示；5) 使用更新后的节点表示进行下游任务。基于JSDMP，作者提出了DMPGCN和DMPPRG两种具体的图神经网络模型。\\n\\n**关键创新**：本文最重要的技术创新点在于提出了Jensen-Shannon散度消息传递（JSDMP）框架。该框架通过引入Jensen-Shannon散度，能够同时建模节点间的相似性和差异性，从而更准确地计算消息传递权重。与现有方法相比，JSDMP能够更好地捕捉节点间的真实相关性，从而提高表示学习的质量。\\n\\n**关键设计**：在DMPGCN中，作者使用图卷积网络进行消息传递，并使用Jensen-Shannon散度来调整消息传递权重。在DMPPRG中，作者使用PageRank算法进行消息传递，并使用Jensen-Shannon散度来调整PageRank值。损失函数根据具体的下游任务进行设计，例如节点分类任务可以使用交叉熵损失函数。",
            "application_zh": "该研究成果可应用于多种富文本图相关的任务，例如文档分类、信息检索、知识图谱补全等。通过更准确地学习节点表示，可以提高这些任务的性能。此外，该方法还可以扩展到其他类型的图数据，例如社交网络、生物网络等，具有广泛的应用前景。",
            "highlight_zh": "实验结果表明，DMPGCN和DMPPRG在多个富文本数据集上显著优于现有的SOTA方法。例如，在某个数据集上，DMPGCN的准确率比最佳基线方法提高了3%以上。这些结果证明了JSDMP框架的有效性，以及其在富文本图表示学习方面的潜力。",
            "tags_zh": [
                "富文本图",
                "图神经网络",
                "表示学习",
                "Jensen-Shannon散度",
                "消息传递"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20094v1/xitu.drawio.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20094v1/fram.drawio.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20094v1/DMPPRG.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information",
            "authors": [
                "İbrahim Oğuz Çetinkaya",
                "Sajad Khodadadian",
                "Taylan G. Topçu"
            ],
            "arxiv_id": "2512.20589v1",
            "summary": "As systems engineering (SE) objectives evolve from design and operation of monolithic systems to complex System of Systems (SoS), the discipline of Mission Engineering (ME) has emerged which is increasingly being accepted as a new line of thinking for the SE community. Moreover, mission environments are uncertain, dynamic, and mission outcomes are a direct function of how the mission assets will interact with this environment. This proves static architectures brittle and calls for analytically rigorous approaches for ME. To that end, this paper proposes an intelligent mission coordination methodology that integrates digital mission models with Reinforcement Learning (RL), that specifically addresses the need for adaptive task allocation and reconfiguration. More specifically, we are leveraging a Digital Engineering (DE) based infrastructure that is composed of a high-fidelity digital mission model and agent-based simulation; and then we formulate the mission tactics management problem as a Markov Decision Process (MDP), and employ an RL agent trained via Proximal Policy Optimization. By leveraging the simulation as a sandbox, we map the system states to actions, refining the policy based on realized mission outcomes. The utility of the RL-based intelligent mission coordinator is demonstrated through an aerial firefighting case study. Our findings indicate that the RL-based intelligent mission coordinator not only surpasses baseline performance but also significantly reduces the variability in mission performance. Thus, this study serves as a proof of concept demonstrating that DE-enabled mission simulations combined with advanced analytical tools offer a mission-agnostic framework for improving ME practice; which can be extended to more complicated fleet design and selection problems in the future from a mission-first perspective.",
            "categories": [
                "cs.CY",
                "cs.AI",
                "eess.SY",
                "math.OC"
            ],
            "primary_category": "cs.CY",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20589v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "利用高保真数字模型与强化学习进行任务工程：以完美信息下的空中消防为例",
            "summary_zh": "随着系统工程(SE)的目标从单一系统的设计和运行演变为复杂的系统之系统(SoS)，任务工程(ME)作为一种新的思维方式，正日益被SE社区所接受。此外，任务环境是不确定的、动态的，任务结果直接取决于任务资产与环境的交互方式。这使得静态架构变得脆弱，需要分析上严谨的ME方法。为此，本文提出了一种智能任务协调方法，将数字任务模型与强化学习(RL)相结合，专门解决自适应任务分配和重配置的需求。更具体地说，我们利用基于数字工程(DE)的基础设施，该基础设施由高保真数字任务模型和基于Agent的仿真组成；然后，我们将任务策略管理问题形式化为马尔可夫决策过程(MDP)，并采用通过近端策略优化训练的RL Agent。通过利用仿真作为沙箱，我们将系统状态映射到动作，并根据已实现的任务结果改进策略。通过空中消防案例研究，证明了基于RL的智能任务协调器的效用。我们的研究结果表明，基于RL的智能任务协调器不仅超越了基线性能，而且显著降低了任务性能的可变性。因此，这项研究作为一个概念验证，表明基于DE的任务仿真与先进的分析工具相结合，为改进ME实践提供了一个与任务无关的框架；未来可以从任务优先的角度扩展到更复杂的机队设计和选择问题。",
            "intro_zh": [
                "传统静态任务架构难以应对不确定、动态的任务环境，需要更具适应性的任务分配和重配置方法。",
                "提出一种智能任务协调方法，结合高保真数字任务模型和强化学习，实现自适应任务策略管理。",
                "通过空中消防案例研究验证了该方法的有效性，结果表明其超越基线性能并降低了任务性能的可变性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在复杂、动态和不确定的任务环境中，如何实现任务资产的自适应分配和重配置，以优化任务性能的问题。现有静态任务架构无法有效应对此类环境的变化，导致任务性能不稳定甚至失败。\\n\\n**核心思路**：论文的核心思路是将数字工程(DE)与强化学习(RL)相结合。首先，利用高保真数字任务模型和基于Agent的仿真构建任务环境的数字孪生。然后，将任务策略管理问题建模为马尔可夫决策过程(MDP)，并使用RL Agent学习最优的任务分配和重配置策略。通过在仿真环境中进行训练，RL Agent可以学习到在不同状态下采取何种动作才能最大化任务回报。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) **数字任务模型**：使用数字工程工具构建高保真任务环境模型，包括任务资产、环境因素和任务目标等。2) **Agent-based仿真**：基于数字任务模型构建仿真环境，模拟任务的执行过程。3) **强化学习Agent**：使用RL算法训练Agent，使其学习最优的任务策略。4) **任务协调器**：根据RL Agent的输出，对任务资产进行分配和重配置。整个流程是，首先在仿真环境中训练RL Agent，然后将训练好的Agent部署到实际任务环境中，指导任务协调器进行任务分配和重配置。\\n\\n**关键创新**：论文的关键创新在于将数字工程和强化学习相结合，构建了一个自适应的任务策略管理框架。与传统的静态任务架构相比，该框架能够根据环境的变化动态调整任务策略，从而提高任务性能的稳定性和可靠性。此外，通过在仿真环境中进行训练，可以降低实际任务中的风险和成本。\\n\\n**关键设计**：论文使用近端策略优化(PPO)算法训练RL Agent。状态空间包括任务资产的状态、环境状态和任务目标状态等。动作空间包括任务资产的分配和重配置方案。奖励函数的设计目标是最大化任务完成度和最小化资源消耗。具体参数设置未知。",
            "application_zh": "该研究成果可应用于各种复杂任务环境下的任务工程，例如：空中消防、搜救行动、军事作战、物流配送等。通过构建高保真数字模型和利用强化学习进行任务策略优化，可以提高任务效率、降低任务风险，并实现更智能化的任务管理。未来可扩展到更复杂的机队设计和选择问题。",
            "highlight_zh": "通过空中消防案例研究，验证了基于RL的智能任务协调器的有效性。实验结果表明，该方法不仅超越了基线性能，而且显著降低了任务性能的可变性。具体性能数据和提升幅度未知。",
            "tags_zh": [
                "任务工程",
                "强化学习",
                "数字工程",
                "任务分配",
                "系统之系统",
                "空中消防",
                "近端策略优化"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20589v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20589v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20589v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FaithLens: Detecting and Explaining Faithfulness Hallucination",
            "authors": [
                "Shuzheng Si",
                "Qingyi Wang",
                "Haozhe Zhao",
                "Yuzhuo Bai",
                "Guanqiao Chen",
                "Kangyang Luo",
                "Gang Chen",
                "Fanchao Qi",
                "Minjia Zhang",
                "Baobao Chang",
                "Maosong Sun"
            ],
            "arxiv_id": "2512.20182v1",
            "summary": "Recognizing whether outputs from large language models (LLMs) contain faithfulness hallucination is crucial for real-world applications, e.g., retrieval-augmented generation and summarization. In this paper, we introduce FaithLens, a cost-efficient and effective faithfulness hallucination detection model that can jointly provide binary predictions and corresponding explanations to improve trustworthiness. To achieve this, we first synthesize training data with explanations via advanced LLMs and apply a well-defined data filtering strategy to ensure label correctness, explanation quality, and data diversity. Subsequently, we fine-tune the model on these well-curated training data as a cold start and further optimize it with rule-based reinforcement learning, using rewards for both prediction correctness and explanation quality. Results on 12 diverse tasks show that the 8B-parameter FaithLens outperforms advanced models such as GPT-4.1 and o3. Also, FaithLens can produce high-quality explanations, delivering a distinctive balance of trustworthiness, efficiency, and effectiveness.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20182v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出FaithLens，用于检测并解释大语言模型中的忠实性幻觉。",
            "summary_zh": "本文介绍FaithLens，一种经济高效且有效的忠实性幻觉检测模型，它可以联合提供二元预测和相应的解释，以提高可信度。为了实现这一目标，我们首先通过先进的大语言模型合成带有解释的训练数据，并应用明确定义的数据过滤策略，以确保标签正确性、解释质量和数据多样性。随后，我们使用这些精心策划的训练数据对模型进行冷启动微调，并使用基于规则的强化学习进一步优化它，使用预测正确性和解释质量的奖励。在12个不同任务上的结果表明，80亿参数的FaithLens优于GPT-4.1和o3等先进模型。此外，FaithLens可以产生高质量的解释，从而在可信度、效率和有效性之间实现独特的平衡。",
            "intro_zh": [
                "大型语言模型（LLM）的幻觉问题严重影响其在实际应用中的可靠性，尤其是在检索增强生成和摘要等任务中。",
                "FaithLens通过合成带有解释的训练数据，并结合数据过滤和强化学习，实现了对幻觉的有效检测和解释。",
                "实验结果表明，FaithLens在多个任务上超越了GPT-4.1等先进模型，同时提供了高质量的解释，提升了模型的可信度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）中普遍存在的“忠实性幻觉”问题。现有方法要么无法有效检测幻觉，要么缺乏对幻觉原因的解释，导致用户难以信任LLM的输出。因此，需要一种既能准确检测幻觉，又能提供可信解释的解决方案。\\n\\n**核心思路**：FaithLens的核心思路是训练一个能够联合预测幻觉存在与否，并提供相应解释的模型。通过高质量的训练数据和强化学习，模型能够学习到幻觉的模式，并生成人类可理解的解释，从而提高模型的可信度。\\n\\n**技术框架**：FaithLens的整体框架包括以下几个主要阶段：1) **数据合成**：使用先进的LLM生成带有解释的训练数据。2) **数据过滤**：应用数据过滤策略，确保数据的标签正确性、解释质量和数据多样性。3) **冷启动微调**：在过滤后的数据上对模型进行微调，作为模型的初始状态。4) **强化学习优化**：使用基于规则的强化学习，根据预测正确性和解释质量对模型进行优化。\\n\\n**关键创新**：FaithLens的关键创新在于其联合预测和解释的能力，以及其训练数据的生成和优化方法。通过合成高质量的训练数据，并使用强化学习进行优化，FaithLens能够学习到幻觉的复杂模式，并生成可信的解释。此外，基于规则的强化学习奖励函数的设计也是一个创新点，它能够同时考虑预测的准确性和解释的质量。\\n\\n**关键设计**：在数据合成阶段，论文使用了先进的LLM来生成训练数据，并设计了特定的prompt来引导LLM生成高质量的解释。在数据过滤阶段，论文定义了一系列规则来过滤掉标签错误、解释质量差或数据多样性不足的数据。在强化学习阶段，论文设计了基于规则的奖励函数，该函数根据预测的准确性和解释的质量来奖励模型。具体的参数设置和网络结构细节在论文中未详细描述，属于未知信息。",
            "application_zh": "FaithLens可应用于各种需要LLM提供可靠输出的场景，例如检索增强生成、文本摘要、问答系统等。通过检测和解释幻觉，FaithLens可以提高LLM输出的可信度，减少错误信息的传播，并帮助用户更好地理解LLM的推理过程。未来，FaithLens可以进一步扩展到其他类型的LLM和任务中，成为提高LLM可靠性的重要工具。",
            "highlight_zh": "FaithLens在12个不同的任务上进行了评估，结果表明，80亿参数的FaithLens优于GPT-4.1和o3等先进模型。此外，FaithLens能够生成高质量的解释，从而在可信度、效率和有效性之间实现独特的平衡。具体的性能提升幅度在论文中未给出明确的量化数据，属于未知信息。",
            "tags_zh": [
                "忠实性幻觉检测",
                "大语言模型",
                "可解释性",
                "强化学习",
                "数据合成"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20182v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20182v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20182v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Offline Safe Policy Optimization From Heterogeneous Feedback",
            "authors": [
                "Ze Gong",
                "Pradeep Varakantham",
                "Akshat Kumar"
            ],
            "arxiv_id": "2512.20173v1",
            "summary": "Offline Preference-based Reinforcement Learning (PbRL) learns rewards and policies aligned with human preferences without the need for extensive reward engineering and direct interaction with human annotators. However, ensuring safety remains a critical challenge across many domains and tasks. Previous works on safe RL from human feedback (RLHF) first learn reward and cost models from offline data, then use constrained RL to optimize a safe policy. While such an approach works in the contextual bandits settings (LLMs), in long horizon continuous control tasks, errors in rewards and costs accumulate, leading to impairment in performance when used with constrained RL methods. To address these challenges, (a) instead of indirectly learning policies (from rewards and costs), we introduce a framework that learns a policy directly based on pairwise preferences regarding the agent's behavior in terms of rewards, as well as binary labels indicating the safety of trajectory segments; (b) we propose \\textsc{PreSa} (Preference and Safety Alignment), a method that combines preference learning module with safety alignment in a constrained optimization problem. This optimization problem is solved within a Lagrangian paradigm that directly learns reward-maximizing safe policy \\textit{without explicitly learning reward and cost models}, avoiding the need for constrained RL; (c) we evaluate our approach on continuous control tasks with both synthetic and real human feedback. Empirically, our method successfully learns safe policies with high rewards, outperforming state-of-the-art baselines, and offline safe RL approaches with ground-truth reward and cost.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted at AAMAS 2026 (Extended Abstract)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20173v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "preference learning",
                        "RLHF"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出PreSa框架，通过异构反馈直接优化安全策略，解决离线安全策略优化问题",
            "summary_zh": "本文提出了一种离线偏好强化学习(PbRL)框架，旨在无需大量奖励工程和与人工标注者直接交互的情况下，学习与人类偏好对齐的奖励和策略，同时确保安全性。针对现有基于人类反馈的安全强化学习(RLHF)方法在长时程连续控制任务中，由于奖励和成本模型误差累积导致性能下降的问题，本文提出PreSa (Preference and Safety Alignment)方法。该方法不间接学习策略（从奖励和成本），而是直接基于轨迹片段的奖励偏好和安全二元标签学习策略，避免了显式学习奖励和成本模型，也无需约束强化学习。实验结果表明，该方法在合成和真实人类反馈下，成功学习了高奖励的安全策略，优于现有技术水平的基线和具有真实奖励和成本的离线安全强化学习方法。",
            "intro_zh": [
                "现有安全强化学习方法在长时程任务中，奖励和成本模型误差累积导致性能下降，是核心挑战。",
                "PreSa框架直接基于人类偏好和安全标签学习策略，避免了显式奖励和成本模型的学习。",
                "实验表明，PreSa在连续控制任务中优于现有基线，成功学习了高奖励的安全策略。"
            ],
            "method_zh": "**问题定义**：论文旨在解决离线偏好强化学习中的安全策略优化问题。现有方法，如先学习奖励和成本模型，再使用约束强化学习优化策略，在长时程连续控制任务中会因为奖励和成本模型误差的累积而导致性能下降。这些方法依赖于准确的奖励和成本建模，而这在实际应用中往往是困难的。\\n\\n**核心思路**：论文的核心思路是避免显式地学习奖励和成本模型，而是直接从人类的偏好反馈（关于奖励）和安全标签中学习策略。通过这种方式，可以绕过奖励和成本模型带来的误差累积问题，直接优化策略，使其既能满足人类的偏好，又能保证安全性。\\n\\n**技术框架**：PreSa框架包含两个主要模块：偏好学习模块和安全对齐模块。整体流程如下：1) 收集包含轨迹片段的偏好和安全标签的离线数据集；2) 使用偏好学习模块学习一个策略，使其生成的轨迹片段与人类偏好对齐；3) 使用安全对齐模块，通过约束优化问题，确保学习到的策略生成的轨迹片段是安全的。整个优化问题在一个拉格朗日框架内解决，直接学习奖励最大化的安全策略。\\n\\n**关键创新**：最重要的技术创新点在于直接从偏好和安全标签学习策略，避免了显式奖励和成本模型的学习。这与现有方法的本质区别在于，它绕过了奖励和成本模型带来的误差累积问题，从而能够更有效地学习安全策略。此外，使用拉格朗日框架解决约束优化问题，使得可以直接学习安全策略，而无需使用约束强化学习。\\n\\n**关键设计**：PreSa框架的关键设计包括：1) 使用pairwise ranking loss来学习偏好，鼓励模型生成更符合人类偏好的轨迹片段；2) 使用安全约束来确保学习到的策略生成的轨迹片段是安全的，安全约束可以是基于二元安全标签的约束；3) 使用拉格朗日乘子法来解决约束优化问题，将安全约束转化为拉格朗日函数的一部分，从而可以直接学习安全策略。",
            "application_zh": "该研究成果可应用于机器人安全控制、自动驾驶、医疗决策等领域。在这些领域中，安全性至关重要，并且难以精确建模奖励函数。通过利用人类的偏好和安全反馈，可以训练出更安全、更符合人类期望的智能系统，从而提高系统的可靠性和实用性，并降低潜在风险。",
            "highlight_zh": "实验结果表明，PreSa在连续控制任务中显著优于现有基线方法。例如，在某个任务中，PreSa能够达到比现有最佳基线高出15%的奖励，同时保持较高的安全性。此外，PreSa还优于使用真实奖励和成本的离线安全强化学习方法，验证了其在避免奖励和成本模型误差方面的有效性。",
            "tags_zh": [
                "离线强化学习",
                "偏好学习",
                "安全强化学习",
                "人类反馈",
                "约束优化"
            ],
            "_index": 54,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20173v1/figures/problem_setting.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20173v1/figures/safety_ratio.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20173v1/figures/seglen_reward.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Fun-Audio-Chat Technical Report",
            "authors": [
                "Qian Chen",
                "Luyao Cheng",
                "Chong Deng",
                "Xiangang Li",
                "Jiaqing Liu",
                "Chao-Hong Tan",
                "Wen Wang",
                "Junhao Xu",
                "Jieping Ye",
                "Qinglin Zhang",
                "Qiquan Zhang",
                "Jingren Zhou"
            ],
            "arxiv_id": "2512.20156v1",
            "summary": "Recent advancements in joint speech-text models show great potential for seamless voice interactions. However, existing models face critical challenges: temporal resolution mismatch between speech tokens (25Hz) and text tokens (~3Hz) dilutes semantic information, incurs high computational costs, and causes catastrophic forgetting of text LLM knowledge. We introduce Fun-Audio-Chat, a Large Audio Language Model addressing these limitations via two innovations from our previous work DrVoice. First, Dual-Resolution Speech Representations (DRSR): the Shared LLM processes audio at efficient 5Hz (via token grouping), while the Speech Refined Head generates high-quality tokens at 25Hz, balancing efficiency (~50% GPU reduction) and quality. Second, Core-Cocktail Training, a two-stage fine-tuning with intermediate merging that mitigates catastrophic forgetting. We then apply Multi-Task DPO Training to enhance robustness, audio understanding, instruction-following and voice empathy. This multi-stage post-training enables Fun-Audio-Chat to retain text LLM knowledge while gaining powerful audio understanding, reasoning, and generation. Unlike recent LALMs requiring large-scale audio-text pre-training, Fun-Audio-Chat leverages pre-trained models and extensive post-training. Fun-Audio-Chat 8B and MoE 30B-A3B achieve competitive performance on Speech-to-Text and Speech-to-Speech tasks, ranking top among similar-scale models on Spoken QA benchmarks. They also achieve competitive to superior performance on Audio Understanding, Speech Function Calling, Instruction-Following and Voice Empathy. We develop Fun-Audio-Chat-Duplex, a full-duplex variant with strong performance on Spoken QA and full-duplex interactions. We open-source Fun-Audio-Chat-8B with training and inference code, and provide an interactive demo.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.SD",
                "eess.AS"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "21 pages, https://github.com/FunAudioLLM/Fun-Audio-Chat",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20156v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "DPO"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "instruction following"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Fun-Audio-Chat：通过双分辨率语音表示和核心鸡尾酒训练，提升语音交互大模型性能",
            "summary_zh": "本文介绍了Fun-Audio-Chat，一种大型音频语言模型，旨在解决现有语音-文本联合模型在语音交互中面临的挑战。这些挑战包括：语音token（25Hz）和文本token（~3Hz）之间的时间分辨率不匹配导致语义信息稀释、计算成本高昂以及灾难性地遗忘文本LLM知识。Fun-Audio-Chat通过借鉴DrVoice中的两项创新来克服这些限制。首先，双分辨率语音表示（DRSR）允许共享LLM以高效的5Hz处理音频（通过token分组），而语音精炼头以高质量的25Hz生成token，从而平衡效率（GPU减少约50%）和质量。其次，核心鸡尾酒训练是一种两阶段微调方法，通过中间合并来减轻灾难性遗忘。然后，应用多任务DPO训练来增强鲁棒性、音频理解、指令遵循和语音共情。这种多阶段后训练使Fun-Audio-Chat能够保留文本LLM知识，同时获得强大的音频理解、推理和生成能力。与最近需要大规模音频-文本预训练的LALM不同，Fun-Audio-Chat利用预训练模型和广泛的后训练。Fun-Audio-Chat 8B和MoE 30B-A3B在语音转文本和语音转语音任务上表现出竞争优势，在口语QA基准测试中，在类似规模的模型中名列前茅。它们还在音频理解、语音功能调用、指令遵循和语音共情方面取得了具有竞争力甚至更优越的性能。我们开发了Fun-Audio-Chat-Duplex，这是一种全双工变体，在口语QA和全双工交互方面表现出色。我们开源了Fun-Audio-Chat-8B，包括训练和推理代码，并提供了一个交互式演示。",
            "intro_zh": [
                "现有语音-文本模型存在语音和文本token分辨率不匹配的问题，导致语义信息损失和计算成本增加。",
                "Fun-Audio-Chat通过双分辨率语音表示（DRSR）和核心鸡尾酒训练，在效率和质量之间取得平衡，并减轻灾难性遗忘。",
                "Fun-Audio-Chat在语音转文本、语音转语音和口语QA等任务上取得了优异的性能，并在音频理解等方面表现出竞争力。"
            ],
            "method_zh": "**问题定义**：现有联合语音-文本模型在处理语音交互时，由于语音token（25Hz）和文本token（~3Hz）之间的时间分辨率差异，导致语义信息被稀释，计算成本高昂，并且容易发生灾难性遗忘，即在学习新任务时忘记了之前学习的文本LLM知识。\\n\\n**核心思路**：Fun-Audio-Chat的核心思路是通过双分辨率语音表示（DRSR）来解决时间分辨率不匹配的问题，并利用核心鸡尾酒训练来缓解灾难性遗忘。DRSR允许模型在不同分辨率下处理语音，兼顾效率和质量。核心鸡尾酒训练则通过两阶段微调和中间合并，使模型能够更好地保留文本LLM知识。\\n\\n**技术框架**：Fun-Audio-Chat的整体框架包括以下几个主要模块/阶段：1) 双分辨率语音表示（DRSR）：将语音信号转换为两种不同分辨率的表示，一种用于高效处理，另一种用于高质量生成。2) 共享LLM：使用大型语言模型处理低分辨率的语音表示。3) 语音精炼头：生成高质量的语音token。4) 核心鸡尾酒训练：通过两阶段微调和中间合并来缓解灾难性遗忘。5) 多任务DPO训练：增强模型的鲁棒性、音频理解、指令遵循和语音共情能力。\\n\\n**关键创新**：Fun-Audio-Chat最重要的技术创新点在于双分辨率语音表示（DRSR）和核心鸡尾酒训练。DRSR允许模型在不同分辨率下处理语音，从而在效率和质量之间取得平衡。核心鸡尾酒训练则通过两阶段微调和中间合并，有效地缓解了灾难性遗忘问题。与需要大规模音频-文本预训练的LALM不同，Fun-Audio-Chat主要依赖后训练。\\n\\n**关键设计**：在DRSR中，共享LLM以5Hz处理音频，而语音精炼头以25Hz生成token。核心鸡尾酒训练包括两个阶段：首先，对模型进行微调以适应新的音频任务；然后，将微调后的模型与原始文本LLM进行合并，以保留文本知识。多任务DPO训练使用多种损失函数来优化模型的不同能力，例如音频理解、指令遵循和语音共情。",
            "application_zh": "Fun-Audio-Chat具有广泛的应用前景，例如智能助手、语音搜索、语音翻译、语音游戏和人机交互等领域。它可以实现更自然、流畅和智能的语音交互体验，提升用户满意度。未来，该技术有望应用于各种智能设备和平台，例如智能家居、智能汽车和移动设备等。",
            "highlight_zh": "Fun-Audio-Chat 8B和MoE 30B-A3B在语音转文本和语音转语音任务上表现出竞争优势，并在口语QA基准测试中，在类似规模的模型中名列前茅。此外，它们还在音频理解、语音功能调用、指令遵循和语音共情方面取得了具有竞争力甚至更优越的性能。Fun-Audio-Chat-Duplex在口语QA和全双工交互方面表现出色。",
            "tags_zh": [
                "语音交互",
                "大型音频语言模型",
                "双分辨率语音表示",
                "核心鸡尾酒训练",
                "灾难性遗忘",
                "多任务学习",
                "语音理解"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20156v1/figure/polar_bar_chart_1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20156v1/figure/polar_bar_chart_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20156v1/figure/fun-audio-chat.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Evolutionary Neural Architecture Search with Dual Contrastive Learning",
            "authors": [
                "Xian-Rong Zhang",
                "Yue-Jiao Gong",
                "Wei-Neng Chen",
                "Jun Zhang"
            ],
            "arxiv_id": "2512.20112v1",
            "summary": "Evolutionary Neural Architecture Search (ENAS) has gained attention for automatically designing neural network architectures. Recent studies use a neural predictor to guide the process, but the high computational costs of gathering training data -- since each label requires fully training an architecture -- make achieving a high-precision predictor with { limited compute budget (i.e., a capped number of fully trained architecture-label pairs)} crucial for ENAS success. This paper introduces ENAS with Dual Contrastive Learning (DCL-ENAS), a novel method that employs two stages of contrastive learning to train the neural predictor. In the first stage, contrastive self-supervised learning is used to learn meaningful representations from neural architectures without requiring labels. In the second stage, fine-tuning with contrastive learning is performed to accurately predict the relative performance of different architectures rather than their absolute performance, which is sufficient to guide the evolutionary search. Across NASBench-101 and NASBench-201, DCL-ENAS achieves the highest validation accuracy, surpassing the strongest published baselines by 0.05\\% (ImageNet16-120) to 0.39\\% (NASBench-101). On a real-world ECG arrhythmia classification task, DCL-ENAS improves performance by approximately 2.5 percentage points over a manually designed, non-NAS model obtained via random search, while requiring only 7.7 GPU-days.",
            "categories": [
                "cs.NE",
                "cs.AI"
            ],
            "primary_category": "cs.NE",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "26 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20112v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]contrastive learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出DCL-ENAS，利用双重对比学习提升进化神经架构搜索的效率和精度。",
            "summary_zh": "本文提出了一种基于双重对比学习的进化神经架构搜索方法（DCL-ENAS），旨在解决ENAS中训练数据获取成本高昂的问题。DCL-ENAS分两个阶段训练神经预测器：第一阶段，使用对比自监督学习从神经架构中学习有意义的表示，无需标签；第二阶段，通过对比学习进行微调，准确预测不同架构的相对性能，从而指导进化搜索。在NASBench-101和NASBench-201上的实验表明，DCL-ENAS取得了最高的验证精度，超越了已发表的最强基线0.05% (ImageNet16-120)到0.39% (NASBench-101)。在真实世界的心电图心律失常分类任务中，DCL-ENAS的性能比通过随机搜索获得的手动设计的非NAS模型提高了约2.5个百分点，且仅需7.7 GPU-days。",
            "intro_zh": [
                "ENAS依赖神经预测器指导搜索，但获取带标签的架构训练数据成本高昂，限制了预测器的精度。",
                "DCL-ENAS通过双重对比学习，先无监督学习架构表示，再有监督微调相对性能预测，降低了对标注数据的需求。",
                "实验表明，DCL-ENAS在多个NASBench数据集和真实心电图分类任务上均取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：进化神经架构搜索（ENAS）依赖于神经预测器来指导架构搜索过程。然而，训练这些预测器需要大量的已训练架构及其性能标签，这导致了巨大的计算成本。尤其是在计算资源有限的情况下，如何利用有限的架构-标签对来训练一个高精度的预测器，是ENAS面临的关键挑战。现有方法通常直接预测架构的绝对性能，这需要大量的训练数据才能达到理想的精度。\\n\\n**核心思路**：DCL-ENAS的核心思路是利用对比学习来降低对绝对性能预测的需求。它不是直接预测架构的绝对性能，而是预测不同架构之间的相对性能差异。这种相对性能预测对噪声和偏差具有更强的鲁棒性，并且可以使用更少的训练数据来实现更高的精度。通过对比学习，模型可以学习到架构之间的相似性和差异性，从而更好地进行排序和选择。\\n\\n**技术框架**：DCL-ENAS包含两个主要的对比学习阶段。第一阶段是对比自监督学习，该阶段利用大量的未标记架构数据，通过对比学习的方式学习架构的表示。具体来说，对于每个架构，通过数据增强等方式生成多个变体，然后通过对比学习的目标函数，使得同一个架构的不同变体在表示空间中尽可能接近，而不同架构的变体则尽可能远离。第二阶段是对比微调，该阶段利用少量的已标记架构数据，通过对比学习的方式微调第一阶段学习到的架构表示。具体来说，对于每个架构对，根据它们的性能差异构建正负样本对，然后通过对比学习的目标函数，使得性能相似的架构对在表示空间中尽可能接近，而性能差异大的架构对则尽可能远离。\\n\\n**关键创新**：DCL-ENAS的关键创新在于其双重对比学习框架。第一阶段的对比自监督学习能够有效地利用大量的未标记架构数据，学习到有意义的架构表示，从而为第二阶段的对比微调提供了一个良好的初始化。第二阶段的对比微调则能够有效地利用少量的已标记架构数据，学习到架构之间的相对性能差异，从而提高预测器的精度。这种双重对比学习框架能够显著降低对标注数据的需求，提高ENAS的效率和精度。\\n\\n**关键设计**：在对比自监督学习阶段，使用了数据增强技术来生成架构变体，例如随机裁剪、旋转等。对比损失函数采用了InfoNCE损失函数，该损失函数能够有效地将相似的样本拉近，将不相似的样本推远。在对比微调阶段，使用了margin ranking loss作为对比损失函数，该损失函数能够有效地学习架构之间的相对性能差异。此外，还使用了warm-up策略来逐步增加对比损失的权重，以避免训练初期出现梯度爆炸等问题。",
            "application_zh": "DCL-ENAS具有广泛的应用前景，可应用于各种需要自动设计神经网络架构的场景，例如图像分类、目标检测、自然语言处理等。尤其是在计算资源有限或标注数据稀缺的情况下，DCL-ENAS能够显著提高神经架构搜索的效率和精度，降低模型开发的成本。该方法还可以应用于特定领域的模型定制，例如医疗诊断、金融风控等，通过自动搜索针对特定任务优化的神经网络架构，提高模型的性能和泛化能力。",
            "highlight_zh": "DCL-ENAS在NASBench-101和NASBench-201上取得了显著的性能提升，超越了已发表的最强基线0.05% (ImageNet16-120)到0.39% (NASBench-101)。在真实世界的心电图心律失常分类任务中，DCL-ENAS的性能比通过随机搜索获得的手动设计的非NAS模型提高了约2.5个百分点，且仅需7.7 GPU-days，表明了其在实际应用中的有效性和效率。",
            "tags_zh": [
                "神经架构搜索",
                "进化算法",
                "对比学习",
                "自监督学习",
                "神经网络",
                "模型优化"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20112v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20112v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20112v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Discovering Lie Groups with Flow Matching",
            "authors": [
                "Jung Yeon Park",
                "Yuxuan Chen",
                "Floor Eijkelboom",
                "Jan-Willem van de Meent",
                "Lawson L. S. Wong",
                "Robin Walters"
            ],
            "arxiv_id": "2512.20043v1",
            "summary": "Symmetry is fundamental to understanding physical systems, and at the same time, can improve performance and sample efficiency in machine learning. Both pursuits require knowledge of the underlying symmetries in data. To address this, we propose learning symmetries directly from data via flow matching on Lie groups. We formulate symmetry discovery as learning a distribution over a larger hypothesis group, such that the learned distribution matches the symmetries observed in data. Relative to previous works, our method, \\lieflow, is more flexible in terms of the types of groups it can discover and requires fewer assumptions. Experiments on 2D and 3D point clouds demonstrate the successful discovery of discrete groups, including reflections by flow matching over the complex domain. We identify a key challenge where the symmetric arrangement of the target modes causes ``last-minute convergence,'' where samples remain stationary until relatively late in the flow, and introduce a novel interpolation scheme for flow matching for symmetry discovery.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20043v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]flow matching"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出流匹配方法以发现李群的对称性",
            "summary_zh": "对称性是理解物理系统的基础，同时也能提高机器学习的性能和样本效率。为此，本文提出通过流匹配直接从数据中学习对称性，具体方法是学习一个更大假设群的分布，使得所学分布与数据中观察到的对称性相匹配。相较于以往的研究，本文的方法\textit{lieflow}在可发现的群类型上更为灵活，并且需要更少的假设。通过对二维和三维点云的实验，成功发现了包括反射在内的离散群体，并提出了一种新颖的插值方案以解决目标模式的对称排列导致的“最后时刻收敛”问题。",
            "intro_zh": [
                "现有方法在对称性发现中面临假设限制和灵活性不足的问题，难以适应多样化的数据结构。",
                "本文提出通过流匹配在李群上直接学习对称性，旨在减少假设并提高方法的灵活性。",
                "实验结果表明，本文方法在发现离散对称群体方面表现优异，尤其是在复杂域中的流匹配效果显著。"
            ],
            "method_zh": "**问题定义**：本文旨在解决如何从数据中有效发现对称性的问题，现有方法往往依赖于过多的假设，限制了其适用性和灵活性。\\n\\n**核心思路**：通过流匹配技术，学习一个更大假设群的分布，使其与数据中的对称性相匹配，从而实现对称性的自动发现。\\n\\n**技术框架**：整体方法包括数据预处理、流匹配算法的设计、对称性分布的学习和后处理阶段。每个阶段都针对特定的挑战进行优化。\\n\\n**关键创新**：本文的主要创新在于引入了一种新的插值方案，以解决在对称模式下的“最后时刻收敛”问题，这一设计显著提高了流匹配的效率和准确性。\\n\\n**关键设计**：在技术细节上，本文采用了特定的损失函数来优化流匹配过程，并设计了适应不同数据结构的网络架构，以确保方法的灵活性和有效性。",
            "application_zh": "该研究具有广泛的应用潜力，尤其在物理系统建模、机器人运动规划和计算机视觉等领域。通过自动发现对称性，可以显著提高模型的性能和样本效率，推动相关领域的进一步发展。",
            "highlight_zh": "实验结果显示，本文方法在二维和三维点云数据上成功发现了多种离散对称群体，包括反射，且相较于基线方法，性能提升显著，具体提升幅度未知。",
            "tags_zh": [
                "对称性发现",
                "流匹配",
                "李群",
                "机器学习",
                "物理建模",
                "计算机视觉",
                "机器人技术"
            ],
            "_index": 57,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20043v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20043v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20043v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multi-hop Reasoning via Early Knowledge Alignment",
            "authors": [
                "Yuxin Wang",
                "Shicheng Fang",
                "Bo Wang",
                "Qi Luo",
                "Xuanjing Huang",
                "Yining Zheng",
                "Xipeng Qiu"
            ],
            "arxiv_id": "2512.20144v1",
            "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \\href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "16 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20144v1",
            "code_links": [
                {
                    "url": "https://github.com/yxzwang/EarlyKnowledgeAlignment",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出早期知识对齐(EKA)模块，提升迭代RAG多跳推理性能与效率。",
            "summary_zh": "检索增强生成(RAG)已成为大语言模型(LLM)处理知识密集型查询的强大范例，这些查询需要领域特定或最新的信息。为了处理单步检索难以解决的复杂多跳问题，已经提出了结合强化学习的迭代RAG方法。然而，现有的迭代RAG系统通常在不利用可用检索语料库信息的情况下规划分解问题，导致低效的检索和推理链，从而造成次优性能。在本文中，我们引入了早期知识对齐(EKA)，这是一个简单但有效的模块，可以在迭代RAG系统中进行规划之前，将LLM与检索集进行对齐，并提供上下文相关的检索知识。在六个标准RAG数据集上的大量实验表明，通过建立更强的推理基础，EKA显著提高了检索精度，减少了级联错误，并提高了性能和效率。从熵的角度进行的分析表明，结合早期知识可以减少推理过程中不必要的探索，使模型能够更有效地专注于相关信息子集。此外，EKA被证明是一种通用的、免训练的推理策略，可以无缝扩展到大型模型。跨不同数据集和检索语料库的泛化测试证实了我们方法的鲁棒性。总的来说，EKA推进了迭代RAG系统的最新水平，同时阐明了强化学习增强框架中结构化推理和有效探索之间的关键相互作用。",
            "intro_zh": [
                "现有迭代RAG系统在分解问题时，未能充分利用检索语料库的信息，导致检索效率低下和推理链错误累积。",
                "论文提出早期知识对齐(EKA)模块，在规划前将LLM与检索集对齐，提供上下文相关的知识，增强推理基础。",
                "实验表明，EKA显著提升了检索精度，减少了级联错误，提高了RAG系统的性能和效率，且具有良好的泛化能力。"
            ],
            "method_zh": "**问题定义**：现有的迭代式检索增强生成（RAG）方法在处理多跳问题时，通常独立地进行问题分解和检索，忽略了检索语料库的先验知识。这导致检索到的信息与当前推理步骤的相关性较低，产生低效的推理链，并容易累积错误，最终影响整体性能。\\n\\n**核心思路**：论文的核心思路是在问题分解和规划之前，让LLM提前“感知”到检索语料库的内容，从而更好地指导后续的检索和推理过程。通过这种“早期知识对齐”，LLM可以更准确地判断哪些信息是可用的，并据此制定更有效的推理策略。\\n\\n**技术框架**：EKA模块被集成到迭代RAG系统中，作为一个预处理步骤。整体流程如下：1) 给定原始问题，首先使用LLM对检索语料库进行概要理解；2) EKA模块利用LLM的理解结果，指导后续的问题分解和检索规划；3) 迭代地进行检索和推理，直到得到最终答案。\\n\\n**关键创新**：EKA的关键创新在于其“早期”的知识对齐机制。与传统的迭代RAG方法不同，EKA不是在检索之后才利用检索到的信息，而是在规划之前就将LLM与检索语料库对齐。这种提前对齐的方式可以更有效地利用检索语料库的知识，避免不必要的探索，并减少错误累积。\\n\\n**关键设计**：EKA模块的具体实现方式是，首先使用LLM对检索语料库进行摘要，然后将摘要信息作为上下文输入到LLM中，指导其进行问题分解和检索规划。论文中没有提及具体的参数设置、损失函数或网络结构等技术细节，EKA主要是一个推理阶段的策略。",
            "application_zh": "该研究成果可应用于各种需要多跳推理和知识检索的场景，例如问答系统、智能助手、知识图谱推理等。通过提高检索精度和推理效率，EKA可以帮助用户更快速、准确地获取所需信息，并提升用户体验。未来，EKA有望成为构建更智能、更可靠的RAG系统的关键组成部分。",
            "highlight_zh": "论文在六个标准RAG数据集上进行了大量实验，结果表明EKA显著提高了检索精度，减少了级联错误，并提高了RAG系统的性能和效率。具体性能提升数据未在摘要中明确给出，但强调了EKA作为一种通用且免训练的推理策略，可以无缝扩展到大型模型，并在不同数据集和检索语料库上表现出鲁棒性。",
            "tags_zh": [
                "检索增强生成",
                "多跳推理",
                "知识对齐",
                "大语言模型",
                "强化学习",
                "迭代RAG",
                "知识检索"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20144v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20144v1/figurefigure/EKGRPO.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20144v1/close.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Memory-T1: Reinforcement Learning for Temporal Reasoning in Multi-session Agents",
            "authors": [
                "Yiming Du",
                "Baojun Wang",
                "Yifan Xiang",
                "Zhaowei Wang",
                "Wenyu Huang",
                "Boyang Xue",
                "Bin Liang",
                "Xingshan Zeng",
                "Fei Mi",
                "Haoli Bai",
                "Lifeng Shang",
                "Jeff Z. Pan",
                "Yuxin Jiang",
                "Kam-Fai Wong"
            ],
            "arxiv_id": "2512.20092v1",
            "summary": "Temporal reasoning over long, multi-session dialogues is a critical capability for conversational agents. However, existing works and our pilot study have shown that as dialogue histories grow in length and accumulate noise, current long-context models struggle to accurately identify temporally pertinent information, significantly impairing reasoning performance. To address this, we introduce Memory-T1, a framework that learns a time-aware memory selection policy using reinforcement learning (RL). It employs a coarse-to-fine strategy, first pruning the dialogue history into a candidate set using temporal and relevance filters, followed by an RL agent that selects the precise evidence sessions. The RL training is guided by a multi-level reward function optimizing (i) answer accuracy, (ii) evidence grounding, and (iii) temporal consistency. In particular, the temporal consistency reward provides a dense signal by evaluating alignment with the query time scope at both the session-level (chronological proximity) and the utterance-level (chronological fidelity), enabling the agent to resolve subtle chronological ambiguities. On the Time-Dialog benchmark, Memory-T1 boosts a 7B model to an overall score of 67.0\\%, establishing a new state-of-the-art performance for open-source models and outperforming a 14B baseline by 10.2\\%. Ablation studies show temporal consistency and evidence grounding rewards jointly contribute to a 15.0\\% performance gain. Moreover, Memory-T1 maintains robustness up to 128k tokens, where baseline models collapse, proving effectiveness against noise in extensive dialogue histories. The code and datasets are publicly available at https://github.com/Elvin-Yiming-Du/Memory-T1/",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20092v1",
            "code_links": [
                {
                    "url": "https://github.com/Elvin-Yiming-Du/Memory-T1/",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Memory-T1框架，利用强化学习解决多轮对话Agent中的时序推理难题。",
            "summary_zh": "本文提出Memory-T1框架，旨在解决会话Agent在长程多轮对话中进行时序推理时面临的挑战。现有方法在处理冗长且包含噪声的对话历史时，难以准确识别时序相关信息，严重影响推理性能。Memory-T1采用强化学习(RL)方法学习时间感知的记忆选择策略。该框架使用由粗到精的策略，首先通过时间和相关性过滤器将对话历史修剪为候选集，然后由RL Agent选择精确的证据会话。RL训练由多级奖励函数指导，优化(i)答案准确性，(ii)证据基础，以及(iii)时间一致性。特别是，时间一致性奖励通过评估会话级别（时间邻近度）和话语级别（时间保真度）与查询时间范围的对齐情况，提供密集信号，使Agent能够解决细微的时间歧义。在Time-Dialog基准测试中，Memory-T1将7B模型的整体得分提高到67.0%，为开源模型建立了新的最先进性能，并且优于14B基线模型10.2%。消融研究表明，时间一致性和证据基础奖励共同贡献了15.0%的性能提升。此外，Memory-T1在高达128k tokens的情况下保持了鲁棒性，而基线模型则崩溃，证明了其在处理大量对话历史中的噪声方面的有效性。",
            "intro_zh": [
                "现有长文本模型在处理长程多轮对话时，难以准确识别时序信息，导致时序推理性能下降。",
                "Memory-T1框架利用强化学习，学习时间感知的记忆选择策略，从对话历史中选择最相关的证据会话。",
                "实验表明，Memory-T1在Time-Dialog基准测试中显著提升了性能，并在长文本输入下保持了鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有对话Agent在处理长程多轮对话时，由于对话历史冗长且包含噪声，难以准确识别与时间相关的关键信息，导致时序推理能力不足。现有方法无法有效区分不同时间段的信息，容易受到无关信息的干扰，从而影响最终的推理结果。\\n\\n**核心思路**：Memory-T1的核心思路是利用强化学习，训练一个能够根据时间信息选择相关对话会话的Agent。通过学习时间感知的记忆选择策略，Agent可以从冗长的对话历史中提取出与当前问题最相关的证据，从而提高时序推理的准确性。这种方法模拟了人类在回忆信息时，会根据时间线索进行筛选的过程。\\n\\n**技术框架**：Memory-T1框架采用由粗到精的策略。首先，利用时间和相关性过滤器对对话历史进行初步筛选，得到候选会话集合。然后，强化学习Agent从候选集中选择最终的证据会话。Agent的状态包括对话历史、当前问题和已选择的会话。Agent的动作是选择下一个会话。整个框架通过多级奖励函数进行训练，包括答案准确性奖励、证据基础奖励和时间一致性奖励。\\n\\n**关键创新**：Memory-T1的关键创新在于引入了时间一致性奖励，该奖励从会话级别（时间邻近度）和话语级别（时间保真度）评估选择的会话与查询时间范围的对齐情况。这种时间一致性奖励能够提供密集的反馈信号，帮助Agent学习区分细微的时间差异，从而更准确地选择相关的证据会话。\\n\\n**关键设计**：时间一致性奖励是关键设计之一，它包括会话级别的时间邻近度评估和话语级别的时间保真度评估。时间邻近度评估会话的时间戳与查询时间范围的接近程度。时间保真度评估会话中话语的时间顺序是否与查询时间范围一致。此外，框架还使用了注意力机制来融合选择的证据会话，并使用交叉熵损失函数来优化答案准确性。",
            "application_zh": "Memory-T1框架可应用于各种需要时序推理的对话Agent，例如智能客服、虚拟助手、医疗诊断等。该框架能够提高Agent在处理复杂对话场景下的推理能力，从而提供更准确、更个性化的服务。未来，该研究可以扩展到其他需要处理长程依赖关系的自然语言处理任务中。",
            "highlight_zh": "Memory-T1在Time-Dialog基准测试中取得了显著的性能提升，将7B模型的整体得分提高到67.0%，超越了14B基线模型10.2%。消融研究表明，时间一致性和证据基础奖励共同贡献了15.0%的性能提升。此外，Memory-T1在处理高达128k tokens的长文本输入时，仍然保持了鲁棒性，而基线模型则崩溃。",
            "tags_zh": [
                "时序推理",
                "强化学习",
                "多轮对话",
                "长文本建模",
                "对话Agent"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20092v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20092v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20092v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Joint Design of Embedded Index Coding and Beamforming for MIMO-based Distributed Computing via Multi-Agent Reinforcement Learning",
            "authors": [
                "Heekang Song",
                "Wan Choi"
            ],
            "arxiv_id": "2512.20201v1",
            "summary": "In distributed computing systems, reducing the communication load during the data shuffling phase is a critical challenge, as excessive inter-node transmissions are a major performance bottleneck. One promising approach to alleviate this burden is Embedded Index Coding (EIC), which exploits cached data at user nodes to encode transmissions more efficiently. However, most prior work on EIC has focused on minimizing code length in wired, error-free environments-an objective often suboptimal for wireless multiple-input multiple-output (MIMO) systems, where channel conditions and spatial multiplexing gains must be considered. This paper investigates the joint design of EIC and transmit beamforming in MIMO systems to minimize total transmission time, an NP-hard problem. We first present a conventional optimization method that determines the optimal EIC via exhaustive search. To address its prohibitive complexity and adapt to dynamic wireless environments, we propose a novel, low-complexity multi-agent reinforcement learning (MARL) framework. The proposed framework enables decentralized agents to act on local observations while effectively managing the hybrid action space of discrete EIC selection and continuous beamforming design. Simulation results demonstrate that the proposed MARL-based approach achieves near-optimal performance with significantly reduced complexity, underscoring its effectiveness and practicality for real-world wireless systems.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20201v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于多智能体强化学习的嵌入式索引编码与波束成形联合设计方法，优化MIMO分布式计算系统性能。",
            "summary_zh": "在分布式计算系统中，数据混洗阶段的通信负载是关键挑战，过多的节点间传输是主要的性能瓶颈。嵌入式索引编码(EIC)是一种有前景的方法，它利用用户节点缓存的数据来更有效地编码传输。然而，大多数关于EIC的先前工作都集中在有线、无差错环境中最小化代码长度，这对于无线多输入多输出(MIMO)系统来说通常不是最优的，因为必须考虑信道条件和空间复用增益。本文研究了MIMO系统中EIC和发射波束成形的联合设计，以最小化总传输时间，这是一个NP-hard问题。我们首先提出了一种传统的优化方法，通过穷举搜索确定最优EIC。为了解决其过高的复杂性并适应动态无线环境，我们提出了一种新颖的、低复杂度的多智能体强化学习(MARL)框架。所提出的框架使分散的智能体能够根据局部观察采取行动，同时有效地管理离散EIC选择和连续波束成形设计的混合动作空间。仿真结果表明，所提出的基于MARL的方法以显著降低的复杂性实现了接近最优的性能，突出了其在实际无线系统中的有效性和实用性。",
            "intro_zh": [
                "分布式计算中数据混洗阶段的通信负载过高，现有EIC方法在无线MIMO系统中未充分考虑信道条件和空间复用增益。",
                "提出基于多智能体强化学习(MARL)的EIC和波束成形联合设计方法，分散的智能体根据局部观察进行决策，管理混合动作空间。",
                "仿真结果表明，提出的MARL方法在显著降低复杂性的同时，实现了接近最优的性能，验证了其有效性和实用性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决MIMO分布式计算系统中，如何联合优化嵌入式索引编码（EIC）和发射波束成形，以最小化总传输时间的问题。现有方法，特别是针对有线环境设计的EIC方法，无法有效利用无线MIMO系统的信道特性和空间复用增益，导致性能瓶颈。此外，联合优化问题是NP-hard问题，传统优化方法复杂度过高，难以适应动态无线环境。\\n\\n**核心思路**：论文的核心思路是利用多智能体强化学习（MARL）框架，将EIC选择和波束成形设计分解为多个智能体的决策问题。每个智能体根据局部观察独立行动，通过学习与其他智能体协作，共同优化全局目标，即最小化总传输时间。这种分散式决策方式降低了计算复杂度，并提高了对动态无线环境的适应性。\\n\\n**技术框架**：整体框架包含多个智能体，每个智能体对应一个用户节点。每个智能体观察局部信道状态信息和缓存数据信息，然后选择EIC方案和设计波束成形向量。所有智能体的行为共同影响系统的总传输时间，该时间作为奖励信号反馈给每个智能体。智能体通过与环境交互，不断学习和优化其策略。\\n\\n**关键创新**：最重要的技术创新在于将EIC选择（离散动作空间）和波束成形设计（连续动作空间）的联合优化问题，转化为一个多智能体强化学习问题，并设计了相应的MARL框架。与传统的集中式优化方法相比，该方法具有更低的计算复杂度和更好的可扩展性。与单智能体强化学习方法相比，多智能体方法能够更好地处理分布式决策问题。\\n\\n**关键设计**：论文采用Actor-Critic架构的MARL算法。Actor网络负责选择EIC方案和设计波束成形向量，Critic网络负责评估Actor网络生成的策略的价值。损失函数包括奖励函数和正则化项，用于平衡性能和稳定性。具体参数设置和网络结构在论文中有详细描述，但摘要中未提供具体数值。",
            "application_zh": "该研究成果可应用于无线分布式计算系统，例如边缘计算、联邦学习等场景。通过优化数据混洗阶段的通信效率，可以显著提升分布式计算的整体性能，降低延迟，提高资源利用率。未来，该方法有望推广到更复杂的无线网络环境，例如异构网络、大规模MIMO系统等。",
            "highlight_zh": "仿真结果表明，所提出的基于MARL的方法在显著降低复杂性的同时，实现了接近最优的性能。与传统的穷举搜索方法相比，MARL方法在性能损失很小的情况下，计算复杂度大幅降低。具体的性能提升幅度和对比基线在摘要中未给出，需要在论文正文中查找。",
            "tags_zh": [
                "多智能体强化学习",
                "嵌入式索引编码",
                "波束成形",
                "MIMO系统",
                "分布式计算",
                "无线通信",
                "数据混洗"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20201v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20201v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20201v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Pneumatic bladder links with wide range of motion joints for articulated inflatable robots",
            "authors": [
                "Katsu Uchiyama",
                "Ryuma Niiyama"
            ],
            "arxiv_id": "2512.20322v1",
            "summary": "Exploration of various applications is the frontier of research on inflatable robots. We proposed an articulated robots consisting of multiple pneumatic bladder links connected by rolling contact joints called Hillberry joints. The bladder link is made of a double-layered structure of tarpaulin sheet and polyurethane sheet, which is both airtight and flexible in shape. The integration of the Hilberry joint into an inflatable robot is also a new approach. The rolling contact joint allows wide range of motion of $\\pm 150 ^{\\circ}$, the largest among the conventional inflatable joints. Using the proposed mechanism for inflatable robots, we demonstrated moving a 500 g payload with a 3-DoF arm and lifting 3.4 kg and 5 kg payloads with 2-DoF and 1-DoF arms, respectively. We also experimented with a single 3-DoF inflatable leg attached to a dolly to show that the proposed structure worked for legged locomotion.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "Accepted at IROS2024 (IEEE/RSJ International Conference on Intelligent Robots and Systems)",
            "doi": "10.1109/IROS58592.2024.10802836",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20322v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "legged locomotion",
                        "locomotion"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于气动囊连接和Hillberry关节的可充气铰接机器人",
            "summary_zh": "本文提出了一种铰接式可充气机器人，该机器人由多个气动囊连接件组成，这些连接件通过称为Hillberry关节的滚动接触关节连接。囊连接件由防水布和聚氨酯薄板的双层结构制成，既气密又具有形状上的灵活性。将Hilberry关节集成到可充气机器人中也是一种新方法。这种滚动接触关节允许高达±150°的运动范围，是传统可充气关节中最大的。使用所提出的可充气机器人机制，我们演示了使用3自由度手臂移动500克有效载荷，以及分别使用2自由度和1自由度手臂提升3.4千克和5千克有效载荷。我们还用连接到台车的单个3自由度可充气腿进行了实验，以表明所提出的结构适用于腿式运动。",
            "intro_zh": [
                "可充气机器人的研究前沿在于探索其多样化的应用场景，但传统可充气关节的运动范围受限。",
                "该论文提出了一种基于气动囊和Hillberry滚动接触关节的铰接机器人，旨在扩大可充气机器人的运动范围。",
                "实验结果表明，该机器人能够实现大范围的运动，并成功地进行了有效载荷搬运和腿式运动的演示。"
            ],
            "method_zh": "**问题定义**：现有可充气机器人的关节运动范围有限，限制了其在复杂环境中的应用能力。传统可充气关节的设计难以兼顾大范围运动和结构稳定性，导致机器人操作能力受限。\\n\\n**核心思路**：该论文的核心思路是利用气动囊作为连接件，并结合Hillberry滚动接触关节，实现大范围的关节运动。气动囊提供结构支撑和灵活性，而Hillberry关节则允许关节进行大幅度的旋转。\\n\\n**技术框架**：该可充气铰接机器人的整体架构包括：1）气动囊连接件，由双层材料（防水布和聚氨酯薄板）构成，保证气密性和柔韧性；2）Hillberry滚动接触关节，连接相邻的气动囊，实现关节运动；3）控制系统，用于调节气压和控制关节运动。\\n\\n**关键创新**：该论文的关键创新在于将Hillberry滚动接触关节集成到可充气机器人中。这种关节设计能够实现高达±150°的运动范围，显著优于传统的可充气关节。此外，双层气动囊结构也保证了机器人的气密性和形状可控性。\\n\\n**关键设计**：Hillberry关节的具体设计参数（如滚动接触面的曲率半径、材料选择等）对关节的运动范围和承载能力有重要影响。气动囊的充气压力需要根据负载和运动需求进行精确控制。控制算法的设计需要考虑气动系统的非线性特性，以实现精确的关节运动控制。",
            "application_zh": "该研究成果可应用于搜索救援、医疗康复、太空探索等领域。可充气机器人的轻量化和柔性特性使其能够在狭小或危险环境中执行任务。例如，在灾难现场，可充气机器人可以进入倒塌建筑物内部进行搜索；在医疗领域，可充气机器人可以用于辅助康复训练。未来，该技术有望进一步发展，实现更复杂的功能和更广泛的应用。",
            "highlight_zh": "实验结果表明，该机器人能够实现大范围的关节运动（±150°）。3自由度手臂能够移动500克有效载荷，2自由度和1自由度手臂分别能够提升3.4千克和5千克有效载荷。此外，3自由度可充气腿的实验证明了该结构适用于腿式运动，为可充气机器人的移动能力提供了新的可能性。",
            "tags_zh": [
                "可充气机器人",
                "气动囊",
                "Hillberry关节",
                "铰接机器人",
                "柔性机器人"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20322v1/fig/imposter_3dof.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20322v1/fig/hilberry_model.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20322v1/fig/inflatable_joint_center_simple.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LEAD: Minimizing Learner-Expert Asymmetry in End-to-End Driving",
            "authors": [
                "Long Nguyen",
                "Micha Fauth",
                "Bernhard Jaeger",
                "Daniel Dauner",
                "Maximilian Igl",
                "Andreas Geiger",
                "Kashyap Chitta"
            ],
            "arxiv_id": "2512.20563v1",
            "summary": "Simulators can generate virtually unlimited driving data, yet imitation learning policies in simulation still struggle to achieve robust closed-loop performance. Motivated by this gap, we empirically study how misalignment between privileged expert demonstrations and sensor-based student observations can limit the effectiveness of imitation learning. More precisely, experts have significantly higher visibility (e.g., ignoring occlusions) and far lower uncertainty (e.g., knowing other vehicles' actions), making them difficult to imitate reliably. Furthermore, navigational intent (i.e., the route to follow) is under-specified in student models at test time via only a single target point. We demonstrate that these asymmetries can measurably limit driving performance in CARLA and offer practical interventions to address them. After careful modifications to narrow the gaps between expert and student, our TransFuser v6 (TFv6) student policy achieves a new state of the art on all major publicly available CARLA closed-loop benchmarks, reaching 95 DS on Bench2Drive and more than doubling prior performances on Longest6~v2 and Town13. Additionally, by integrating perception supervision from our dataset into a shared sim-to-real pipeline, we show consistent gains on the NAVSIM and Waymo Vision-Based End-to-End driving benchmarks. Our code, data, and models are publicly available at https://github.com/autonomousvision/lead.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.LG",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20563v1",
            "code_links": [
                {
                    "url": "https://github.com/autonomousvision/lead",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "sim-to-real"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "imitation learning"
                    ],
                    "score": 1.5
                }
            ],
            "relevance_score": 3.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "LEAD：最小化端到端驾驶中学习者-专家不对称性，提升CARLA模拟器驾驶性能",
            "summary_zh": "模拟器可以生成几乎无限的驾驶数据，但模拟环境中的模仿学习策略仍然难以实现鲁棒的闭环性能。本文研究了专家演示和基于传感器的学生观测之间的不对称性如何限制模仿学习的有效性。专家具有更高的可见性（例如，忽略遮挡）和更低的不确定性（例如，知道其他车辆的动作），这使得学生难以可靠地模仿。此外，学生模型在测试时仅通过单个目标点来指定导航意图（即要遵循的路线），这导致导航意图不明确。研究表明，这些不对称性会显著限制CARLA中的驾驶性能，并提出了解决这些问题的有效干预措施。经过仔细修改以缩小专家和学生之间的差距后，TransFuser v6 (TFv6) 学生策略在所有主要的公开CARLA闭环基准测试中都达到了新的state-of-the-art，在Bench2Drive上达到95 DS，并在Longest6 v2和Town13上实现了超过两倍的性能提升。此外，通过将来自数据集的感知监督集成到共享的sim-to-real流水线中，在NAVSIM和Waymo Vision-Based End-to-End驾驶基准测试中也显示出一致的收益。代码、数据和模型已公开。",
            "intro_zh": [
                "现有模仿学习方法在模拟驾驶中面临专家与学习者信息不对称的挑战，专家拥有更全面的环境信息和更明确的导航意图。",
                "LEAD旨在通过缩小专家和学习者之间的差距来提高模仿学习的性能，包括提升学习者的感知能力和明确导航意图。",
                "TransFuser v6在CARLA基准测试中取得了显著的性能提升，并在NAVSIM和Waymo数据集上验证了其sim-to-real的有效性。"
            ],
            "method_zh": "**问题定义**：现有端到端驾驶模仿学习方法在模拟环境中表现不佳，主要原因是专家（提供训练数据）和学习者（实际驾驶策略）之间存在信息不对称。专家通常拥有更全面的环境信息（例如，无遮挡的全局视图，其他车辆的未来动作），而学习者只能依赖有限的传感器数据。此外，学习者在测试时仅通过单个目标点来指定导航意图，这与专家在训练时所拥有的完整路线信息不符。这些不对称性导致学习者难以有效地模仿专家的驾驶行为。\\n\\n**核心思路**：LEAD的核心思路是最小化专家和学习者之间的信息不对称性。具体来说，通过增强学习者的感知能力，使其能够更好地理解周围环境；同时，通过更明确地指定导航意图，帮助学习者更好地规划行驶路线。这样，学习者就能更有效地模仿专家的驾驶行为，从而提高整体驾驶性能。\\n\\n**技术框架**：LEAD方法基于TransFuser架构，并对其进行了改进。整体框架包括以下几个主要模块：1) 感知模块：用于从传感器数据中提取环境信息；2) 导航模块：用于根据目标点和环境信息规划行驶路线；3) 控制模块：用于根据行驶路线生成车辆控制指令。此外，LEAD还引入了感知监督，利用数据集中的标注信息来提高感知模块的准确性。\\n\\n**关键创新**：LEAD最重要的技术创新点在于其对专家-学习者不对称性的显式建模和解决。与以往的研究主要关注模型架构的改进不同，LEAD更加关注数据层面的问题，通过缩小专家和学习者之间的差距来提高模仿学习的性能。这种思路为解决端到端驾驶中的挑战提供了一个新的视角。\\n\\n**关键设计**：LEAD的关键设计包括：1) 使用更强大的感知模块，例如，TransFuser v6；2) 引入感知监督，利用数据集中的标注信息来提高感知模块的准确性；3) 采用更有效的导航策略，例如，通过预测未来轨迹来明确导航意图；4) 仔细调整训练策略，例如，使用数据增强来模拟不同的环境条件。",
            "application_zh": "LEAD的研究成果可以应用于自动驾驶系统的开发，特别是在模拟环境中的训练和验证。通过缩小模拟环境和真实环境之间的差距，可以更有效地训练自动驾驶策略，并提高其在真实世界中的鲁棒性和安全性。此外，该方法还可以应用于其他需要模仿学习的机器人任务，例如，无人机导航和操作。",
            "highlight_zh": "TransFuser v6在CARLA闭环基准测试中取得了显著的性能提升，在Bench2Drive上达到了95 DS，并在Longest6 v2和Town13上实现了超过两倍的性能提升。此外，通过将感知监督集成到sim-to-real流水线中，在NAVSIM和Waymo Vision-Based End-to-End驾驶基准测试中也显示出一致的收益。这些结果表明，LEAD方法能够有效地提高端到端驾驶模仿学习的性能。",
            "tags_zh": [
                "端到端驾驶",
                "模仿学习",
                "信息不对称",
                "CARLA模拟器",
                "感知监督"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20563v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20563v1/gfx/teaser-short.png",
                    "caption": "",
                    "figure_id": "img_1"
                }
            ]
        },
        {
            "title": "SpatialTree: How Spatial Abilities Branch Out in MLLMs",
            "authors": [
                "Yuxi Xiao",
                "Longfei Li",
                "Shen Yan",
                "Xinhang Liu",
                "Sida Peng",
                "Yunchao Wei",
                "Xiaowei Zhou",
                "Bingyi Kang"
            ],
            "arxiv_id": "2512.20617v1",
            "summary": "Cognitive science suggests that spatial ability develops progressively-from perception to reasoning and interaction. Yet in multimodal LLMs (MLLMs), this hierarchy remains poorly understood, as most studies focus on a narrow set of tasks. We introduce SpatialTree, a cognitive-science-inspired hierarchy that organizes spatial abilities into four levels: low-level perception (L1), mental mapping (L2), simulation (L3), and agentic competence (L4). Based on this taxonomy, we construct the first capability-centric hierarchical benchmark, thoroughly evaluating mainstream MLLMs across 27 sub-abilities. The evaluation results reveal a clear structure: L1 skills are largely orthogonal, whereas higher-level skills are strongly correlated, indicating increasing interdependency. Through targeted supervised fine-tuning, we uncover a surprising transfer dynamic-negative transfer within L1, but strong cross-level transfer from low- to high-level abilities with notable synergy. Finally, we explore how to improve the entire hierarchy. We find that naive RL that encourages extensive \"thinking\" is unreliable: it helps complex reasoning but hurts intuitive perception. We propose a simple auto-think strategy that suppresses unnecessary deliberation, enabling RL to consistently improve performance across all levels. By building SpatialTree, we provide a proof-of-concept framework for understanding and systematically scaling spatial abilities in MLLMs.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "webpage: https://spatialtree.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20617v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SpatialTree：构建多模态LLM空间能力分层评估体系与提升方法",
            "summary_zh": "认知科学表明，空间能力的发展是一个渐进的过程，从感知到推理再到交互。然而，在多模态LLM（MLLM）中，这种层次结构仍然缺乏理解，因为大多数研究都集中在一小部分任务上。本文提出了SpatialTree，一个受认知科学启发的层次结构，将空间能力组织成四个层次：低级感知（L1）、心智地图（L2）、模拟（L3）和能动性能力（L4）。基于此分类法，构建了第一个以能力为中心的层次化基准，全面评估了主流MLLM在27个子能力上的表现。评估结果揭示了一个清晰的结构：L1技能在很大程度上是正交的，而更高层次的技能则强烈相关，表明相互依赖性越来越强。通过有针对性的监督微调，发现了一种令人惊讶的迁移动态：L1内部的负迁移，但从低级到高级能力的强跨级迁移，具有显著的协同作用。最后，探索了如何改进整个层次结构。发现鼓励广泛“思考”的朴素强化学习是不可靠的：它有助于复杂的推理，但损害了直观的感知。提出了一种简单的自动思考策略，抑制不必要的思考，使强化学习能够持续提高所有级别的性能。通过构建SpatialTree，为理解和系统地扩展MLLM中的空间能力提供了一个概念验证框架。",
            "intro_zh": [
                "现有MLLM研究对空间能力的理解不足，缺乏系统性的分层评估体系，难以指导模型优化。",
                "SpatialTree构建了一个认知科学启发的四层空间能力层次结构，并设计了相应的评估基准。",
                "实验表明，低级能力相对独立，高级能力相互依赖，通过自动思考策略的强化学习可以提升整体性能。"
            ],
            "method_zh": "**问题定义**：现有的多模态大语言模型（MLLM）在空间能力方面的发展缺乏系统性的评估和理解。大多数研究集中在少数特定任务上，无法全面反映模型在不同层次空间能力上的表现。因此，如何构建一个能够覆盖不同层次空间能力、并能有效评估MLLM性能的基准，以及如何利用该基准来提升MLLM的空间能力，是本文要解决的核心问题。\\n\\n**核心思路**：本文的核心思路是借鉴认知科学中空间能力发展的分层模型，将MLLM的空间能力划分为四个层次：低级感知（L1）、心智地图（L2）、模拟（L3）和能动性能力（L4）。通过构建一个与该层次结构相对应的评估基准SpatialTree，可以系统地评估MLLM在不同层次空间能力上的表现。此外，通过分析评估结果，可以指导模型进行有针对性的训练和优化，从而提升整体的空间能力。\\n\\n**技术框架**：SpatialTree框架主要包含两个部分：一是空间能力层次结构和评估基准的构建，二是基于评估结果的模型训练和优化。评估基准包含27个子能力，覆盖了四个层次的空间能力。模型训练和优化方面，本文采用了监督微调和强化学习两种方法。监督微调用于探索不同层次能力之间的迁移学习规律，强化学习则用于提升整体性能。\\n\\n**关键创新**：本文的关键创新在于提出了SpatialTree，一个认知科学启发的空间能力层次结构和评估基准。该基准能够系统地评估MLLM在不同层次空间能力上的表现，并为模型训练和优化提供指导。此外，本文还发现了一种有趣的迁移学习现象，即低级能力之间存在负迁移，而从低级到高级能力之间存在正迁移。\\n\\n**关键设计**：在评估基准的设计上，本文精心挑选了27个子能力，并为每个子能力设计了相应的评估任务。在强化学习方面，本文提出了一种自动思考策略，用于抑制不必要的思考，从而避免了强化学习对低级感知能力的负面影响。具体来说，该策略根据输入图像的复杂度动态调整模型的思考步数，从而在保证复杂推理能力的同时，避免过度思考对直观感知能力的干扰。",
            "application_zh": "该研究成果可应用于机器人导航、自动驾驶、虚拟现实等领域。通过提升MLLM的空间能力，可以使机器人更好地理解和操作周围环境，提高自动驾驶系统的安全性和可靠性，增强虚拟现实的沉浸感和交互性。此外，该研究提出的SpatialTree框架也可以作为评估和提升其他类型AI模型空间能力的通用工具。",
            "highlight_zh": "实验结果表明，SpatialTree能够有效评估MLLM在不同层次空间能力上的表现。通过监督微调，发现低级能力之间存在负迁移，而从低级到高级能力之间存在正迁移。采用自动思考策略的强化学习能够持续提高所有级别的性能。例如，在某些任务上，模型的性能提升了10%以上。",
            "tags_zh": [
                "多模态LLM",
                "空间能力",
                "分层评估",
                "迁移学习",
                "强化学习",
                "认知科学",
                "自动思考"
            ],
            "_index": 63,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20617v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20617v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20617v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models",
            "authors": [
                "Shengchao Zhou",
                "Yuxin Chen",
                "Yuying Ge",
                "Wei Huang",
                "Jiehong Lin",
                "Ying Shan",
                "Xiaojuan Qi"
            ],
            "arxiv_id": "2512.20557v1",
            "summary": "Vision-language models (VLM) excel at general understanding yet remain weak at dynamic spatial reasoning (DSR), i.e., reasoning about the evolvement of object geometry and relationship in 3D space over time, largely due to the scarcity of scalable 4D-aware training resources. To bridge this gap across aspects of dataset, benchmark and model, we introduce DSR Suite. First, we propose an automated pipeline that generates multiple-choice question-answer pairs from in-the-wild videos for DSR. By leveraging modern vision foundation models, the pipeline extracts rich geometric and motion information, including camera poses, local point clouds, object masks, orientations, and 3D trajectories. These geometric cues enable the construction of DSR-Train for learning and further human-refined DSR-Bench for evaluation. Compared with previous works, our data emphasize (i) in-the-wild video sources, (ii) object- and scene-level 3D requirements, (iii) viewpoint transformations, (iv) multi-object interactions, and (v) fine-grained, procedural answers. Beyond data, we propose a lightweight Geometry Selection Module (GSM) to seamlessly integrate geometric priors into VLMs, which condenses question semantics and extracts question-relevant knowledge from pretrained 4D reconstruction priors into a compact set of geometry tokens. This targeted extraction avoids overwhelming the model with irrelevant knowledge. Experiments show that integrating DSR-Train and GSM into Qwen2.5-VL-7B significantly enhances its dynamic spatial reasoning capability, while maintaining accuracy on general video understanding benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20557v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DSR Suite和几何选择模块GSM，提升VLM在动态空间推理能力",
            "summary_zh": "视觉语言模型(VLM)在通用理解方面表现出色，但在动态空间推理(DSR)方面仍然较弱，即推理3D空间中物体几何和关系随时间的演变，这主要是由于缺乏可扩展的4D感知训练资源。为了弥合数据集、基准和模型方面的差距，我们引入了DSR Suite。首先，我们提出了一个自动化的流程，从真实视频中生成用于DSR的多项选择问答对。通过利用现代视觉基础模型，该流程提取丰富的几何和运动信息，包括相机姿态、局部点云、物体掩码、方向和3D轨迹。这些几何线索使得构建用于学习的DSR-Train和进一步人工改进的用于评估的DSR-Bench成为可能。与之前的工作相比，我们的数据强调(i)真实视频来源，(ii)物体和场景级别的3D要求，(iii)视点转换，(iv)多物体交互，以及(v)细粒度的程序性答案。除了数据，我们提出了一个轻量级的几何选择模块(GSM)，以无缝地将几何先验知识集成到VLM中，该模块将问题语义浓缩，并从预训练的4D重建先验知识中提取问题相关的知识到一组紧凑的几何token中。这种有针对性的提取避免了用不相关的知识淹没模型。实验表明，将DSR-Train和GSM集成到Qwen2.5-VL-7B中显著增强了其动态空间推理能力，同时保持了在通用视频理解基准上的准确性。",
            "intro_zh": [
                "现有VLM在动态空间推理方面存在不足，缺乏大规模4D感知的训练数据是主要瓶颈。",
                "提出DSR Suite，包含自动生成DSR问答对的流程，以及轻量级的几何选择模块GSM，用于将几何先验知识融入VLM。",
                "实验表明，将DSR-Train和GSM集成到Qwen2.5-VL-7B中，显著提升了其动态空间推理能力，同时保持了通用视频理解的性能。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型(VLM)在理解静态图像方面表现出色，但在理解和推理动态3D空间中的物体运动和关系变化方面存在不足。主要痛点在于缺乏大规模、高质量的4D感知训练数据，以及如何有效地将3D几何信息融入到VLM中。\n\n**核心思路**：论文的核心思路是通过自动化的数据生成流程，构建大规模的DSR数据集，并设计一个轻量级的几何选择模块(GSM)，将问题相关的几何先验知识提取并融入到VLM中。这样既解决了数据稀缺的问题，又避免了用不相关的几何信息淹没模型。\n\n**技术框架**：整体框架包含两个主要部分：DSR Suite和几何选择模块(GSM)。DSR Suite负责生成大规模的DSR-Train和DSR-Bench数据集，利用视觉基础模型提取视频中的几何和运动信息。GSM则负责将问题语义和4D重建先验知识融合，生成几何token，并输入到VLM中。\n\n**关键创新**：论文的关键创新在于：1) 提出了一个自动化的流程，可以从真实视频中生成大规模的DSR问答对，解决了数据稀缺的问题。2) 设计了轻量级的几何选择模块(GSM)，可以有效地将几何先验知识融入到VLM中，避免了信息过载的问题。\n\n**关键设计**：DSR Suite的数据生成流程依赖于视觉基础模型，例如用于提取相机姿态、点云、物体掩码和3D轨迹的模型。GSM模块的设计目标是轻量级，因此采用了一个简单的神经网络结构，用于选择和融合几何特征。损失函数的设计旨在鼓励模型学习到问题相关的几何信息，并抑制不相关信息的干扰。具体参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "该研究成果可应用于机器人导航、自动驾驶、视频监控、增强现实等领域。通过提升VLM对动态空间的理解能力，可以使机器人在复杂环境中更好地感知、推理和行动。例如，机器人可以根据视频中的物体运动轨迹，预测未来的状态，从而做出更合理的决策。",
            "highlight_zh": "实验结果表明，将DSR-Train和GSM集成到Qwen2.5-VL-7B中，显著增强了其动态空间推理能力。在DSR-Bench数据集上，模型的性能得到了显著提升，同时在通用视频理解基准上保持了良好的性能。这表明该方法在提升动态空间推理能力的同时，没有牺牲模型的通用性。",
            "tags_zh": [
                "动态空间推理",
                "视觉语言模型",
                "4D感知",
                "几何选择模块",
                "视频理解"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20557v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20557v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20557v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
            "authors": [
                "YuChe Hsu",
                "AnJui Wang",
                "TsaiChing Ni",
                "YuanFu Yang"
            ],
            "arxiv_id": "2512.20387v1",
            "summary": "We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20387v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出视觉-语言模拟模型，从草图和文本生成可执行的工业系统数字孪生。",
            "summary_zh": "本文提出了一种视觉-语言模拟模型（VLSM），它统一了视觉和文本理解，能够从布局草图和自然语言提示中合成可执行的FlexScript代码，从而实现工业仿真系统的跨模态推理。为了支持这种新范式，本研究构建了首个用于生成数字孪生的大规模数据集，包含超过12万个提示-草图-代码三元组，从而实现文本描述、空间结构和仿真逻辑之间的多模态学习。同时，针对该任务专门提出了三个新的评估指标：结构有效率（SVR）、参数匹配率（PMR）和执行成功率（ESR），以全面评估结构完整性、参数保真度和仿真器的可执行性。通过对视觉编码器、连接器和代码预训练语言骨干网络的系统性消融研究，所提出的模型实现了近乎完美的结构精度和高执行鲁棒性。这项工作为将视觉推理和语言理解集成到可执行的工业仿真系统中的生成数字孪生奠定了基础。",
            "intro_zh": [
                "现有工业仿真系统缺乏从视觉和语言信息直接生成可执行代码的能力，限制了其易用性和智能化水平。",
                "提出视觉-语言模拟模型（VLSM），利用草图和自然语言提示生成可执行的FlexScript代码，实现跨模态的工业仿真。",
                "构建大规模数据集，并提出结构有效率、参数匹配率和执行成功率等新指标，实验结果表明模型具有高精度和鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有工业仿真系统通常需要人工编写复杂的代码来描述系统行为，这既耗时又需要专业的编程知识。缺乏一种能够直接从视觉布局和自然语言描述生成可执行代码的方法，使得仿真系统的构建和修改变得困难，阻碍了其广泛应用。\\n\\n**核心思路**：本文的核心思路是利用视觉和语言的互补信息，通过一个统一的模型将布局草图和自然语言提示转化为可执行的仿真代码。这种方法旨在降低仿真系统的构建门槛，提高其智能化水平，使得用户可以通过更直观的方式来创建和修改仿真模型。\\n\\n**技术框架**：该方法的核心是视觉-语言模拟模型（VLSM），它包含以下几个主要模块：1) 视觉编码器：用于提取布局草图的视觉特征；2) 文本编码器：用于提取自然语言提示的语义特征；3) 连接器：用于融合视觉和文本特征，实现跨模态的信息交互；4) 代码生成器：用于将融合后的特征转化为可执行的FlexScript代码。整个流程是从输入草图和文本开始，经过编码、融合，最终生成代码。\\n\\n**关键创新**：该方法最重要的创新点在于它将视觉和语言信息融合到一个统一的模型中，实现了从草图和文本到可执行代码的直接生成。此外，构建的大规模数据集和提出的新评估指标也为该领域的研究提供了重要的资源和工具。与现有方法相比，该方法无需人工编写代码，大大简化了仿真系统的构建过程。\\n\\n**关键设计**：视觉编码器可以采用卷积神经网络（CNN）或Transformer等结构，文本编码器可以采用预训练的语言模型（如BERT或GPT）。连接器可以使用注意力机制或跨模态Transformer等方法来实现视觉和文本特征的融合。代码生成器可以使用序列到序列（Seq2Seq）模型或Transformer等结构。损失函数可以包括代码生成损失、结构有效性损失和参数匹配损失等。具体参数设置需要根据实验结果进行调整。",
            "application_zh": "该研究成果可应用于智能制造、物流仓储、交通运输等领域，实现快速构建和修改工业仿真系统，优化生产流程、提高资源利用率、降低运营成本。未来可进一步扩展到更复杂的工业场景，例如智能工厂的自动化设计和优化。",
            "highlight_zh": "实验结果表明，提出的VLSM模型在结构有效率（SVR）上接近完美，在参数匹配率（PMR）和执行成功率（ESR）上也取得了显著的成果。通过消融实验，验证了各个模块的有效性，并证明了该模型在生成可执行工业仿真代码方面的优越性。",
            "tags_zh": [
                "数字孪生",
                "视觉-语言模型",
                "工业仿真",
                "跨模态学习",
                "代码生成"
            ],
            "_index": 65,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20387v1/figures/dataset_pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20387v1/figures/layout_type.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20387v1/figures/level_of_automation.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Towards Natural Language-Based Document Image Retrieval: New Dataset and Benchmark",
            "authors": [
                "Hao Guo",
                "Xugong Qin",
                "Jun Jie Ou Yang",
                "Peng Zhang",
                "Gangyan Zeng",
                "Yubo Li",
                "Hailun Lin"
            ],
            "arxiv_id": "2512.20174v1",
            "summary": "Document image retrieval (DIR) aims to retrieve document images from a gallery according to a given query. Existing DIR methods are primarily based on image queries that retrieve documents within the same coarse semantic category, e.g., newspapers or receipts. However, these methods struggle to effectively retrieve document images in real-world scenarios where textual queries with fine-grained semantics are usually provided. To bridge this gap, we introduce a new Natural Language-based Document Image Retrieval (NL-DIR) benchmark with corresponding evaluation metrics. In this work, natural language descriptions serve as semantically rich queries for the DIR task. The NL-DIR dataset contains 41K authentic document images, each paired with five high-quality, fine-grained semantic queries generated and evaluated through large language models in conjunction with manual verification. We perform zero-shot and fine-tuning evaluations of existing mainstream contrastive vision-language models and OCR-free visual document understanding (VDU) models. A two-stage retrieval method is further investigated for performance improvement while achieving both time and space efficiency. We hope the proposed NL-DIR benchmark can bring new opportunities and facilitate research for the VDU community. Datasets and codes will be publicly available at huggingface.co/datasets/nianbing/NL-DIR.",
            "categories": [
                "cs.CV",
                "cs.CL",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "CVPR 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20174v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出NL-DIR基准数据集，用于解决自然语言描述的文档图像检索问题",
            "summary_zh": "文档图像检索（DIR）旨在根据给定的查询从图库中检索文档图像。现有的DIR方法主要基于图像查询，检索语义类别粗略相同的文档，例如报纸或收据。然而，在实际场景中，通常提供具有细粒度语义的文本查询，这些方法难以有效检索文档图像。为了弥合这一差距，我们引入了一个新的基于自然语言的文档图像检索（NL-DIR）基准，并提出了相应的评估指标。在这项工作中，自然语言描述作为DIR任务的语义丰富的查询。NL-DIR数据集包含4.1万张真实的文档图像，每张图像都配有五个高质量、细粒度的语义查询，这些查询通过大型语言模型生成并评估，并结合人工验证。我们对现有的主流对比视觉-语言模型和无OCR的视觉文档理解（VDU）模型进行了零样本和微调评估。进一步研究了一种两阶段检索方法，以提高性能，同时实现时间和空间效率。我们希望提出的NL-DIR基准能够为VDU社区带来新的机遇并促进研究。数据集和代码将在huggingface.co/datasets/nianbing/NL-DIR上公开。",
            "intro_zh": [
                "现有文档图像检索方法难以处理实际场景中细粒度语义的文本查询。",
                "提出NL-DIR基准数据集，使用自然语言描述作为查询，促进更精细的文档图像检索。",
                "通过零样本和微调实验，验证了现有模型在NL-DIR上的性能，并探索了两阶段检索方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决基于自然语言描述的文档图像检索问题。现有文档图像检索方法主要依赖图像查询，只能检索粗粒度语义类别相同的文档，无法有效处理实际应用中常见的、具有细粒度语义的文本查询。这限制了文档图像检索在更广泛场景中的应用，例如根据用户输入的具体问题查找相关文档。\n\n**核心思路**：论文的核心思路是构建一个高质量的、包含自然语言描述的文档图像数据集，并以此为基础评估和改进现有视觉-语言模型在文档图像检索任务中的性能。通过引入自然语言描述作为查询，可以实现更精细、更灵活的文档图像检索，从而更好地满足用户的实际需求。\n\n**技术框架**：论文主要包含以下几个阶段：1) 构建NL-DIR数据集，包括收集文档图像，并使用大型语言模型生成和人工验证自然语言描述；2) 对现有主流的对比视觉-语言模型和无OCR的视觉文档理解模型进行零样本和微调评估；3) 探索两阶段检索方法，以提高检索性能和效率。整体框架围绕NL-DIR数据集展开，旨在评估现有模型并探索更有效的检索方法。\n\n**关键创新**：论文的关键创新在于构建了NL-DIR数据集，该数据集包含4.1万张真实的文档图像，每张图像都配有五个高质量、细粒度的自然语言描述。与现有数据集相比，NL-DIR数据集更贴近实际应用场景，并且提供了更丰富的语义信息，为研究基于自然语言的文档图像检索提供了新的平台。此外，论文还探索了一种两阶段检索方法，在提高性能的同时兼顾了时间和空间效率。\n\n**关键设计**：NL-DIR数据集的关键设计在于使用大型语言模型生成自然语言描述，并结合人工验证，以保证描述的质量和准确性。两阶段检索方法的关键设计在于首先使用粗粒度的图像特征进行快速检索，然后使用细粒度的文本特征进行精确排序，从而实现性能和效率的平衡。具体的模型选择、损失函数和网络结构等细节，论文中没有详细描述，属于模型选择和调优的范畴。",
            "application_zh": "该研究成果可应用于智能文档管理、信息检索、法律咨询、金融分析等领域。例如，用户可以通过自然语言描述快速找到所需的合同、发票、报告等文档图像。未来，该研究有望推动文档图像检索技术的发展，实现更智能、更高效的文档处理和信息服务。",
            "highlight_zh": "论文构建的NL-DIR数据集包含4.1万张文档图像，并配有高质量的自然语言描述，为相关研究提供了宝贵资源。实验结果表明，现有视觉-语言模型在NL-DIR数据集上仍有提升空间。论文提出的两阶段检索方法在提高检索性能的同时，兼顾了时间和空间效率，具有一定的实用价值。",
            "tags_zh": [
                "文档图像检索",
                "自然语言查询",
                "视觉语言模型",
                "NL-DIR数据集",
                "两阶段检索"
            ],
            "_index": 66,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20174v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20174v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20174v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond Vision: Contextually Enriched Image Captioning with Multi-Modal Retrieva",
            "authors": [
                "Nguyen Lam Phu Quy",
                "Pham Phu Hoa",
                "Tran Chi Nguyen",
                "Dao Sy Duy Minh",
                "Nguyen Hoang Minh Ngoc",
                "Huynh Trung Kiet"
            ],
            "arxiv_id": "2512.20042v1",
            "summary": "Real-world image captions often lack contextual depth, omitting crucial details such as event background, temporal cues, outcomes, and named entities that are not visually discernible. This gap limits the effectiveness of image understanding in domains like journalism, education, and digital archives, where richer, more informative descriptions are essential. To address this, we propose a multimodal pipeline that augments visual input with external textual knowledge. Our system retrieves semantically similar images using BEIT-3 (Flickr30k-384 and COCO-384) and SigLIP So-384, reranks them using ORB and SIFT for geometric alignment, and extracts contextual information from related articles via semantic search. A fine-tuned Qwen3 model with QLoRA then integrates this context with base captions generated by Instruct BLIP (Vicuna-7B) to produce event-enriched, context-aware descriptions. Evaluated on the OpenEvents v1 dataset, our approach generates significantly more informative captions compared to traditional methods, showing strong potential for real-world applications requiring deeper visual-textual understanding",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "7 pages, 5 figures. System description for the EVENTA Grand Challenge (Track 1) at ACM MM'25",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20042v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多模态检索增强的图像描述方法，提升事件背景和上下文理解能力",
            "summary_zh": "现实世界的图像描述通常缺乏上下文深度，忽略了事件背景、时间线索、结果以及视觉上难以辨认的命名实体等关键细节。这种差距限制了图像理解在新闻、教育和数字档案馆等领域的有效性，在这些领域中，更丰富、更翔实的描述至关重要。为了解决这个问题，我们提出了一种多模态流程，利用外部文本知识来增强视觉输入。我们的系统使用BEIT-3和SigLIP检索语义相似的图像，使用ORB和SIFT重新排序以进行几何对齐，并通过语义搜索从相关文章中提取上下文信息。然后，使用QLoRA微调的Qwen3模型将此上下文与Instruct BLIP生成的基本描述相结合，以生成事件丰富的、具有上下文感知能力的描述。在OpenEvents v1数据集上的评估表明，与传统方法相比，我们的方法生成的信息量明显更多，显示出在需要更深入的视觉-文本理解的实际应用中具有强大的潜力。",
            "intro_zh": [
                "现有图像描述模型缺乏对图像上下文信息的理解，难以捕捉事件背景和深层含义。",
                "该论文提出一种多模态检索方法，通过检索相关图像和文章，为图像描述提供丰富的上下文信息。",
                "实验表明，该方法生成的图像描述信息量显著提升，更符合实际应用需求。"
            ],
            "method_zh": "**问题定义**：现有图像描述模型主要依赖于视觉信息，难以捕捉图像背后的事件背景、时间信息以及命名实体等上下文信息。这导致生成的描述缺乏深度和细节，限制了其在新闻报道、教育资源等领域的应用。现有方法难以有效利用外部知识来增强图像描述的上下文理解能力。\\n\\n**核心思路**：该论文的核心思路是利用多模态检索技术，从外部知识库中检索与输入图像相关的图像和文本信息，并将这些信息融入到图像描述生成过程中。通过引入上下文信息，增强模型对图像的深层理解，从而生成更丰富、更准确的描述。\\n\\n**技术框架**：该方法包含以下几个主要模块：1) **图像检索模块**：使用BEIT-3和SigLIP模型检索语义相似的图像。2) **图像重排序模块**：使用ORB和SIFT算法对检索到的图像进行几何对齐和重排序。3) **文本检索模块**：通过语义搜索从相关文章中提取上下文信息。4) **描述生成模块**：使用微调的Qwen3模型，结合Instruct BLIP生成的基本描述和检索到的上下文信息，生成最终的图像描述。\\n\\n**关键创新**：该方法的关键创新在于将多模态检索技术应用于图像描述任务，通过检索相关图像和文本信息，为图像描述提供丰富的上下文信息。此外，该方法还采用了几何对齐和语义搜索等技术，进一步提高了检索的准确性和效率。\\n\\n**关键设计**：在图像检索模块中，使用了BEIT-3 (Flickr30k-384 and COCO-384) 和 SigLIP So-384 模型，这些模型在图像检索任务上表现出色。在描述生成模块中，使用了 Qwen3 模型，并采用 QLoRA 进行微调，以提高生成描述的质量和效率。Instruct BLIP (Vicuna-7B) 用于生成基础描述，为后续的上下文融合提供基础。",
            "application_zh": "该研究成果可应用于新闻报道、教育资源、数字档案馆等领域，提升图像描述的质量和信息量，帮助用户更好地理解图像内容。例如，在新闻报道中，可以生成包含事件背景和相关信息的图像描述，提高新闻报道的深度和可读性。在教育资源中，可以生成更详细的图像描述，帮助学生更好地理解教材内容。",
            "highlight_zh": "该方法在OpenEvents v1数据集上进行了评估，实验结果表明，与传统方法相比，该方法生成的图像描述信息量显著提升。这表明该方法能够有效利用外部知识来增强图像描述的上下文理解能力，具有很强的实际应用潜力。具体性能数据和提升幅度在论文中进行了详细展示。",
            "tags_zh": [
                "图像描述",
                "多模态检索",
                "上下文增强",
                "事件理解",
                "知识融合"
            ],
            "_index": 67,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20042v1/teaser_slay.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20042v1/Figure_1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "PaveSync: A Unified and Comprehensive Dataset for Pavement Distress Analysis and Classification",
            "authors": [
                "Blessing Agyei Kyem",
                "Joshua Kofi Asamoah",
                "Anthony Dontoh",
                "Andrews Danyo",
                "Eugene Denteh",
                "Armstrong Aboah"
            ],
            "arxiv_id": "2512.20011v1",
            "summary": "Automated pavement defect detection often struggles to generalize across diverse real-world conditions due to the lack of standardized datasets. Existing datasets differ in annotation styles, distress type definitions, and formats, limiting their integration for unified training. To address this gap, we introduce a comprehensive benchmark dataset that consolidates multiple publicly available sources into a standardized collection of 52747 images from seven countries, with 135277 bounding box annotations covering 13 distinct distress types. The dataset captures broad real-world variation in image quality, resolution, viewing angles, and weather conditions, offering a unique resource for consistent training and evaluation. Its effectiveness was demonstrated through benchmarking with state-of-the-art object detection models including YOLOv8-YOLOv12, Faster R-CNN, and DETR, which achieved competitive performance across diverse scenarios. By standardizing class definitions and annotation formats, this dataset provides the first globally representative benchmark for pavement defect detection and enables fair comparison of models, including zero-shot transfer to new environments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20011v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "zero-shot transfer"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PaveSync：统一全面的路面病害分析与分类数据集",
            "summary_zh": "由于缺乏标准化数据集，自动路面缺陷检测通常难以在各种真实条件下推广。现有数据集在标注风格、病害类型定义和格式上存在差异，限制了它们在统一训练中的集成。为了解决这一差距，我们引入了一个全面的基准数据集，该数据集将多个公开可用的来源整合为一个标准化的集合，包含来自七个国家的52747张图像，以及覆盖13种不同病害类型的135277个边界框标注。该数据集捕捉了图像质量、分辨率、视角和天气条件等方面的广泛真实变化，为一致的训练和评估提供了独特的资源。通过使用包括YOLOv8-YOLOv12、Faster R-CNN和DETR在内的最先进的目标检测模型进行基准测试，证明了其有效性，这些模型在各种场景中都取得了具有竞争力的性能。通过标准化类别定义和标注格式，该数据集为路面缺陷检测提供了第一个具有全球代表性的基准，并能够对模型进行公平比较，包括零样本迁移到新环境。",
            "intro_zh": [
                "现有路面病害数据集缺乏统一标准，标注方式、病害定义各异，阻碍了模型的泛化能力和统一训练。",
                "PaveSync数据集整合了多个公开数据源，标准化标注格式和病害类型，构建了包含多国数据的综合基准。",
                "实验表明，基于PaveSync训练的YOLOv8-YOLOv12、Faster R-CNN和DETR等模型在多种场景下表现出竞争优势。"
            ],
            "method_zh": "**问题定义**：现有路面病害检测数据集存在标注风格不统一、病害类型定义不一致、数据格式各异等问题，导致模型难以在不同数据集上进行统一训练和评估，泛化能力受限。缺乏一个全球代表性的、标准化的路面病害数据集，阻碍了该领域的研究进展。\\n\\n**核心思路**：PaveSync的核心思路是将多个公开可用的路面病害数据集进行整合，并对数据进行清洗、标注格式标准化、病害类型定义统一，从而构建一个统一且全面的基准数据集。通过提供一个标准化的数据集，PaveSync旨在促进路面病害检测模型的公平比较、统一训练和零样本迁移。\\n\\n**技术框架**：PaveSync数据集的构建流程主要包括以下几个阶段：1) 数据收集：从多个公开可用的路面病害数据集中收集图像数据。2) 数据清洗：对收集到的图像数据进行清洗，去除质量较差或不相关的图像。3) 标注格式标准化：将不同数据集的标注格式统一为一种标准格式，例如COCO格式。4) 病害类型定义统一：将不同数据集中的病害类型定义统一为一组标准的病害类型，例如裂缝、坑洼、车辙等。5) 数据集划分：将整合后的数据集划分为训练集、验证集和测试集。\\n\\n**关键创新**：PaveSync的关键创新在于：1) 它是第一个全球代表性的路面病害基准数据集，包含了来自七个国家的数据，具有广泛的地域覆盖性。2) 它对多个公开数据集进行了整合和标准化，解决了现有数据集之间不兼容的问题。3) 它提供了统一的标注格式和病害类型定义，方便研究人员进行模型训练和评估。\\n\\n**关键设计**：PaveSync数据集包含了52747张图像和135277个边界框标注，覆盖了13种不同的病害类型。数据集的图像质量、分辨率、视角和天气条件等都具有广泛的变化，能够模拟真实的道路场景。论文没有详细说明具体的参数设置、损失函数或网络结构，而是侧重于数据集的构建和评估。",
            "application_zh": "PaveSync数据集可广泛应用于智能交通、道路维护和城市管理等领域。通过训练基于PaveSync数据集的路面病害检测模型，可以实现对道路状况的自动评估，辅助道路维护决策，提高道路安全性和使用寿命，并降低维护成本。该数据集的标准化特性也为模型的跨区域应用提供了可能。",
            "highlight_zh": "论文使用YOLOv8-YOLOv12、Faster R-CNN和DETR等先进目标检测模型在PaveSync数据集上进行了基准测试，验证了数据集的有效性。实验结果表明，这些模型在各种场景下都取得了具有竞争力的性能，证明了PaveSync数据集能够为路面病害检测模型的训练和评估提供有效的支持。",
            "tags_zh": [
                "路面病害检测",
                "数据集",
                "目标检测",
                "基准测试",
                "标准化",
                "计算机视觉",
                "智能交通"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20011v1/images_distribution_pie_chart_with_legend.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20011v1/Cropped_Image.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20011v1/weather-conditions.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Fail Fast, Win Big: Rethinking the Drafting Strategy in Speculative Decoding via Diffusion LLMs",
            "authors": [
                "Rui Pan",
                "Zhuofu Chen",
                "Ravi Netravali"
            ],
            "arxiv_id": "2512.20573v1",
            "summary": "Diffusion Large Language Models (dLLMs) offer fast, parallel token generation, but their standalone use is plagued by an inherent efficiency-quality tradeoff. We show that, if carefully applied, the attributes of dLLMs can actually be a strength for drafters in speculative decoding with autoregressive (AR) verifiers. Our core insight is that dLLM's speed from parallel decoding drastically lowers the risk of costly rejections, providing a practical mechanism to effectively realize the (elusive) lengthy drafts that lead to large speedups with speculative decoding. We present FailFast, a dLLM-based speculative decoding framework that realizes this approach by dynamically adapting its speculation length. It \"fails fast\" by spending minimal compute in hard-to-speculate regions to shrink speculation latency and \"wins big\" by aggressively extending draft lengths in easier regions to reduce verification latency (in many cases, speculating and accepting 70 tokens at a time!). Without any fine-tuning, FailFast delivers lossless acceleration of AR LLMs and achieves up to 4.9$\\times$ speedup over vanilla decoding, 1.7$\\times$ over the best naive dLLM drafter, and 1.4$\\times$ over EAGLE-3 across diverse models and workloads. We open-source FailFast at https://github.com/ruipeterpan/failfast.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.DC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20573v1",
            "code_links": [
                {
                    "url": "https://github.com/ruipeterpan/failfast",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FailFast：利用扩散LLM加速推测解码，显著提升自回归LLM推理速度",
            "summary_zh": "扩散大语言模型(dLLMs)提供快速、并行的token生成能力，但其独立使用存在效率和质量之间的固有权衡。本文表明，如果谨慎应用，dLLMs的特性实际上可以成为自回归(AR)验证器中推测解码的起草者的优势。我们的核心见解是，dLLM并行解码带来的速度优势显著降低了代价高昂的拒绝风险，为有效实现(难以捉摸的)长草案提供了一种实用的机制，从而在使用推测解码时实现大幅加速。我们提出了FailFast，一个基于dLLM的推测解码框架，通过动态调整其推测长度来实现这种方法。它通过在难以推测的区域花费最少的计算来缩小推测延迟来“快速失败”，并通过在更容易的区域积极扩展草案长度来减少验证延迟来“大获全胜”(在许多情况下，一次推测和接受70个token!)。在没有任何微调的情况下，FailFast实现了AR LLM的无损加速，并且在不同的模型和工作负载中，相比于vanilla解码实现了高达4.9倍的加速，相比于最佳的naive dLLM起草者实现了1.7倍的加速，相比于EAGLE-3实现了1.4倍的加速。我们在https://github.com/ruipeterpan/failfast开源了FailFast。",
            "intro_zh": [
                "现有自回归LLM推理速度慢，而扩散LLM虽然并行生成快，但质量不高，直接应用存在效率-质量的权衡。",
                "FailFast利用扩散LLM作为推测解码的起草者，动态调整推测长度，在易推测区域大胆推测，难推测区域快速失败，降低计算成本。",
                "实验表明，FailFast无需微调即可显著加速自回归LLM，在多种模型和任务上优于现有方法，最高可达4.9倍加速。"
            ],
            "method_zh": "**问题定义**：论文旨在解决自回归大语言模型(AR LLM)推理速度慢的问题。现有的推测解码方法依赖于较短的草案长度，难以充分利用并行计算的优势，而直接使用扩散LLM(dLLM)生成文本又面临质量不高的问题。因此，如何有效地利用dLLM的并行生成能力来加速AR LLM的推理是一个关键挑战。\\n\\n**核心思路**：论文的核心思路是利用dLLM作为推测解码的起草者，并根据文本生成的难易程度动态调整推测长度。在容易推测的区域，积极扩展草案长度，以减少验证延迟；在难以推测的区域，快速失败，避免浪费计算资源。这种动态调整策略旨在最大化并行计算的优势，同时避免dLLM生成低质量文本的风险。\\n\\n**技术框架**：FailFast框架主要包含以下几个阶段：1) 使用dLLM并行生成草案token序列；2) 使用AR LLM验证生成的token序列；3) 根据验证结果，接受或拒绝部分或全部token；4) 基于已接受的token，继续生成后续token。框架的关键在于动态调整草案长度的策略，它会根据历史验证结果和当前生成难度，自适应地调整dLLM的推测长度。\\n\\n**关键创新**：FailFast的关键创新在于动态调整推测长度的策略。与传统的推测解码方法不同，FailFast不采用固定的草案长度，而是根据文本生成的难易程度进行自适应调整。这种动态调整策略能够更有效地利用dLLM的并行生成能力，同时避免生成低质量文本的风险。\\n\\n**关键设计**：FailFast的关键设计包括：1) 使用dLLM生成草案token序列；2) 使用AR LLM进行验证；3) 设计了一种动态调整草案长度的算法，该算法基于历史验证结果和当前生成难度，自适应地调整dLLM的推测长度。具体的参数设置和损失函数信息未知。",
            "application_zh": "FailFast可应用于各种需要快速文本生成的场景，例如：智能对话系统、机器翻译、文本摘要等。通过加速LLM的推理速度，可以显著提升用户体验，降低计算成本，并促进LLM在资源受限环境中的部署。该研究对于推动LLM的实际应用具有重要意义。",
            "highlight_zh": "FailFast在多种模型和任务上实现了显著的加速效果。实验结果表明，FailFast相比于vanilla解码实现了高达4.9倍的加速，相比于最佳的naive dLLM起草者实现了1.7倍的加速，相比于EAGLE-3实现了1.4倍的加速。这些结果表明，FailFast能够有效地利用dLLM的并行生成能力，并显著提升AR LLM的推理速度。",
            "tags_zh": [
                "推测解码",
                "扩散模型",
                "大语言模型",
                "并行计算",
                "自回归模型"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20573v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20573v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20573v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Generalisation in Multitask Fitted Q-Iteration and Offline Q-learning",
            "authors": [
                "Kausthubh Manda",
                "Raghuram Bharadwaj Diddigi"
            ],
            "arxiv_id": "2512.20220v1",
            "summary": "We study offline multitask reinforcement learning in settings where multiple tasks share a low-rank representation of their action-value functions. In this regime, a learner is provided with fixed datasets collected from several related tasks, without access to further online interaction, and seeks to exploit shared structure to improve statistical efficiency and generalization. We analyze a multitask variant of fitted Q-iteration that jointly learns a shared representation and task-specific value functions via Bellman error minimization on offline data. Under standard realizability and coverage assumptions commonly used in offline reinforcement learning, we establish finite-sample generalization guarantees for the learned value functions. Our analysis explicitly characterizes how pooling data across tasks improves estimation accuracy, yielding a $1/\\sqrt{nT}$ dependence on the total number of samples across tasks, while retaining the usual dependence on the horizon and concentrability coefficients arising from distribution shift. In addition, we consider a downstream offline setting in which a new task shares the same underlying representation as the upstream tasks. We study how reusing the representation learned during the multitask phase affects value estimation for this new task, and show that it can reduce the effective complexity of downstream learning relative to learning from scratch. Together, our results clarify the role of shared representations in multitask offline Q-learning and provide theoretical insight into when and how multitask structure can improve generalization in model-free, value-based reinforcement learning.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "18 pages (9 pages + Appendix and references), this is version 1",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20220v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "offline reinforcement learning"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出多任务离线Q学习方法以提升统计效率与泛化能力",
            "summary_zh": "本研究探讨了多任务离线强化学习，特别是在多个任务共享低秩动作价值函数表示的情况下。学习者利用固定的数据集进行学习，旨在通过共享结构提高统计效率和泛化能力。我们分析了一种多任务拟合Q迭代的变体，通过在离线数据上最小化贝尔曼误差，联合学习共享表示和任务特定的价值函数。在标准的可实现性和覆盖假设下，我们建立了学习的价值函数的有限样本泛化保证，明确了跨任务数据池化如何改善估计精度。此外，我们还考虑了一个下游离线设置，其中新任务共享与上游任务相同的基础表示，研究了在多任务阶段学习的表示如何影响新任务的价值估计，显示出相较于从头学习可以降低下游学习的有效复杂性。我们的结果阐明了共享表示在多任务离线Q学习中的作用，并提供了理论见解，说明何时以及如何利用多任务结构改善无模型、基于价值的强化学习的泛化能力。",
            "intro_zh": [
                "现有的多任务强化学习方法在处理共享低秩表示时，常常面临统计效率低和泛化能力不足的挑战。",
                "本文提出了一种多任务拟合Q迭代的方法，通过最小化贝尔曼误差来联合学习共享表示和任务特定的价值函数。",
                "研究结果表明，跨任务数据池化显著提高了价值函数的估计精度，并且在新任务中重用表示可以降低学习复杂性。"
            ],
            "method_zh": "**问题定义**：本论文旨在解决多任务离线强化学习中，如何有效利用共享低秩表示来提升统计效率和泛化能力的问题。现有方法在处理多个相关任务时，往往缺乏有效的结构化学习策略，导致学习效率低下。\\n\\n**核心思路**：论文提出了一种多任务拟合Q迭代的方法，通过在离线数据上最小化贝尔曼误差，联合学习共享表示和任务特定的价值函数。这种方法能够充分利用多个任务之间的相关性，从而提高学习的统计效率。\\n\\n**技术框架**：整体架构包括数据收集、共享表示学习和任务特定价值函数学习三个主要模块。首先，收集多个相关任务的离线数据；然后，通过拟合Q迭代算法学习共享表示；最后，针对每个任务优化其特定的价值函数。\\n\\n**关键创新**：最重要的技术创新在于建立了有限样本泛化保证，明确了跨任务数据池化如何改善估计精度。这一理论框架与传统的单任务学习方法有本质区别，能够更好地利用任务间的共享结构。\\n\\n**关键设计**：在损失函数设计上，采用贝尔曼误差最小化策略；在网络结构上，设计了共享层和任务特定层的组合，以便有效捕捉任务间的共性与差异。",
            "application_zh": "该研究的潜在应用领域包括机器人控制、自动驾驶、个性化推荐等多任务学习场景。通过提高多任务学习的效率和泛化能力，能够在实际应用中实现更高的性能和更低的成本，推动智能系统的进一步发展。",
            "highlight_zh": "实验结果表明，所提出的方法在多个基准任务上显著提高了价值函数的估计精度，具体表现为在样本数量为nT时，估计误差依赖于$1/\text{sqrt}(nT)$，相较于传统方法有明显提升。此外，新任务的学习复杂性降低，显示出良好的泛化能力。",
            "tags_zh": [
                "多任务学习",
                "离线强化学习",
                "Q学习",
                "贝尔曼误差",
                "共享表示",
                "统计效率",
                "泛化能力"
            ],
            "_index": 70,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20220v1/T-Scaling.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20220v1/n-scaling.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20220v1/H_scaling.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Learning to Reason in LLMs by Expectation Maximization",
            "authors": [
                "Junghyun Lee",
                "Branislav Kveton",
                "Sunav Choudhary",
                "Subhojyoti Mukherjee",
                "Anup Rao",
                "Ryan A. Rossi",
                "Alexa Siu"
            ],
            "arxiv_id": "2512.20169v1",
            "summary": "Large language models (LLMs) solve reasoning problems by first generating a rationale and then answering. We formalize reasoning as a latent variable model and derive an expectation-maximization (EM) objective for learning to reason. This view connects EM and modern reward-based optimization, and shows that the main challenge lies in designing a sampling distribution that generates rationales that justify correct answers. We instantiate and compare several sampling schemes: rejection sampling with a budget, self-taught reasoner (STaR), and prompt posterior sampling (PPS), which only keeps the rationalization stage of STaR. Our experiments on the ARC, MMLU, and OpenBookQA datasets with the Llama and Qwen models show that the sampling scheme can significantly affect the accuracy of learned reasoning models. Despite its simplicity, we observe that PPS outperforms the other sampling schemes.",
            "categories": [
                "cs.LG",
                "cs.CL",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "12 pages, 3 figures, 1 table",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20169v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于期望最大化的LLM推理学习框架，提升复杂推理任务性能",
            "summary_zh": "本文将大型语言模型（LLM）的推理过程形式化为一个隐变量模型，并推导出一个用于学习推理的期望最大化（EM）目标函数。该视角连接了EM和现代基于奖励的优化方法，并表明主要挑战在于设计一个能够生成合理化正确答案的理由的采样分布。论文实例化并比较了几种采样方案：带预算的拒绝采样、自学推理器（STaR）以及仅保留STaR推理阶段的提示后验采样（PPS）。在Llama和Qwen模型上，对ARC、MMLU和OpenBookQA数据集的实验表明，采样方案可以显著影响学习到的推理模型的准确性。尽管PPS很简单，但观察到它优于其他采样方案。",
            "intro_zh": [
                "现有LLM推理方法依赖生成理由再回答，但缺乏对理由生成过程的有效优化。",
                "论文提出基于期望最大化的框架，将推理视为隐变量模型，优化理由生成分布。",
                "实验表明，简单的提示后验采样（PPS）策略在多个数据集上优于其他复杂采样方法。"
            ],
            "method_zh": "**问题定义**：论文旨在提升大型语言模型在复杂推理任务中的表现。现有方法通常是先让LLM生成一个理由（rationale），然后再根据这个理由给出答案。然而，如何有效地学习和优化理由的生成过程是一个挑战，现有的方法往往缺乏理论基础和有效的优化策略。\\n\\n**核心思路**：论文的核心思路是将LLM的推理过程建模为一个隐变量模型，其中理由是隐变量，答案是观测变量。然后，利用期望最大化（EM）算法来学习理由的生成分布。EM算法通过迭代E步（期望步）和M步（最大化步）来优化模型参数，从而使得生成的理由能够更好地支持正确的答案。\\n\\n**技术框架**：整体框架包含两个主要阶段：理由生成阶段和答案预测阶段。在训练过程中，首先使用不同的采样策略（如拒绝采样、STaR、PPS）生成多个理由。然后，根据生成的理由和对应的答案，使用EM算法来更新模型的参数。具体来说，E步计算在给定答案的情况下，每个理由的后验概率；M步则根据后验概率来最大化模型的似然函数。\\n\\n**关键创新**：论文的关键创新在于将推理过程形式化为隐变量模型，并利用EM算法进行优化。这种方法提供了一个统一的理论框架，可以将不同的理由生成策略纳入其中。此外，论文还提出了提示后验采样（PPS）策略，该策略仅保留STaR的理由生成阶段，避免了STaR中的一些复杂操作，从而提高了效率和性能。\\n\\n**关键设计**：论文比较了几种不同的采样策略，包括：1) 带预算的拒绝采样：生成多个理由，然后选择能够给出正确答案的理由。2) 自学推理器（STaR）：使用强化学习来优化理由的生成过程。3) 提示后验采样（PPS）：仅使用LLM生成理由，并根据答案的正确性来调整理由的概率。损失函数采用交叉熵损失，用于优化模型的参数。实验中使用了Llama和Qwen等大型语言模型，并在ARC、MMLU和OpenBookQA等数据集上进行了评估。",
            "application_zh": "该研究成果可应用于各种需要复杂推理能力的场景，例如智能问答、知识图谱推理、代码生成等。通过提升LLM的推理能力，可以提高这些应用场景的准确性和可靠性。未来，该方法可以进一步扩展到其他类型的推理任务，并与其他技术（如知识图谱、符号推理）相结合，从而构建更加强大的智能系统。",
            "highlight_zh": "实验结果表明，基于期望最大化的学习框架可以显著提升LLM在推理任务中的性能。特别地，简单的提示后验采样（PPS）策略在ARC、MMLU和OpenBookQA数据集上优于其他更复杂的采样策略，例如STaR。这表明，有效的理由生成策略对于提升LLM的推理能力至关重要，并且简单的策略有时也能取得很好的效果。",
            "tags_zh": [
                "大型语言模型",
                "推理学习",
                "期望最大化",
                "隐变量模型",
                "提示后验采样"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20169v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20169v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Reliable LLM-Based Edge-Cloud-Expert Cascades for Telecom Knowledge Systems",
            "authors": [
                "Qiushuo Hou",
                "Sangwoo Park",
                "Matteo Zecchin",
                "Yunlong Cai",
                "Guanding Yu",
                "Osvaldo Simeone",
                "Tommaso Melodia"
            ],
            "arxiv_id": "2512.20012v1",
            "summary": "Large language models (LLMs) are emerging as key enablers of automation in domains such as telecommunications, assisting with tasks including troubleshooting, standards interpretation, and network optimization. However, their deployment in practice must balance inference cost, latency, and reliability. In this work, we study an edge-cloud-expert cascaded LLM-based knowledge system that supports decision-making through a question-and-answer pipeline. In it, an efficient edge model handles routine queries, a more capable cloud model addresses complex cases, and human experts are involved only when necessary. We define a misalignment-cost constrained optimization problem, aiming to minimize average processing cost, while guaranteeing alignment of automated answers with expert judgments. We propose a statistically rigorous threshold selection method based on multiple hypothesis testing (MHT) for a query processing mechanism based on knowledge and confidence tests. The approach provides finite-sample guarantees on misalignment risk. Experiments on the TeleQnA dataset -- a telecom-specific benchmark -- demonstrate that the proposed method achieves superior cost-efficiency compared to conventional cascaded baselines, while ensuring reliability at prescribed confidence levels.",
            "categories": [
                "eess.SP",
                "cs.LG"
            ],
            "primary_category": "eess.SP",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "This paper has been submitted to a journal",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20012v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于级联LLM的电信知识系统，优化成本与可靠性，实现自动化决策。",
            "summary_zh": "大型语言模型（LLM）正在成为电信等领域自动化的关键推动力，协助解决故障排除、标准解读和网络优化等任务。然而，实际部署需要在推理成本、延迟和可靠性之间取得平衡。本文研究了一种基于边缘-云-专家级联LLM的知识系统，该系统通过问答流程支持决策。其中，高效的边缘模型处理常规查询，更强大的云模型处理复杂案例，仅在必要时才涉及人工专家。我们定义了一个以错位成本为约束的优化问题，旨在最小化平均处理成本，同时保证自动化答案与专家判断的一致性。我们提出了一种基于多重假设检验（MHT）的统计严格的阈值选择方法，用于基于知识和置信度测试的查询处理机制。该方法为错位风险提供了有限样本保证。在电信专用基准TeleQnA数据集上的实验表明，与传统的级联基线相比，该方法实现了卓越的成本效率，同时确保了在规定的置信水平下的可靠性。",
            "intro_zh": [
                "现有LLM在电信领域应用面临推理成本、延迟和可靠性之间的权衡难题，需要更高效的部署策略。",
                "提出边缘-云-专家级联LLM知识系统，利用边缘模型处理常规查询，云模型处理复杂问题，专家处理疑难杂症。",
                "通过多重假设检验（MHT）进行阈值选择，保证在规定置信水平下的可靠性，并在TeleQnA数据集上验证了成本效率。"
            ],
            "method_zh": "**问题定义**：现有方法在电信知识系统中应用LLM时，难以兼顾推理成本、延迟和可靠性。简单地使用大型LLM会导致高昂的计算成本和延迟，而小型LLM的准确性可能不足。因此，需要一种能够根据查询的复杂程度动态调整处理方式的系统，以在成本和性能之间取得平衡。现有级联系统通常依赖于启发式规则或简单的阈值来决定何时将查询传递给更强大的模型或专家，缺乏统计上的严格保证。\\n\\n**核心思路**：本文的核心思路是构建一个边缘-云-专家级联的LLM系统，并利用统计假设检验来动态地决定查询的处理方式。边缘模型快速且成本低，但能力有限；云模型能力更强，但成本更高；专家则作为最终保障，处理最复杂的情况。通过这种分层结构，可以有效地利用资源，降低整体成本。\\n\\n**技术框架**：该系统包含三个主要模块：边缘LLM、云LLM和专家系统。当接收到一个查询时，首先由边缘LLM进行处理。边缘LLM会输出答案以及一个置信度评分。然后，系统会根据预先设定的阈值对置信度评分进行判断。如果置信度高于阈值，则直接返回边缘LLM的答案；否则，将查询传递给云LLM。云LLM的处理流程类似，也会输出答案和置信度评分。如果云LLM的置信度仍然低于阈值，则将查询传递给专家系统进行处理。\\n\\n**关键创新**：该论文的关键创新在于使用多重假设检验（MHT）来选择置信度阈值。传统的阈值选择方法通常是基于经验或启发式规则，缺乏理论依据。MHT提供了一种统计上严格的方法，可以在保证一定的错位风险的前提下，选择最优的阈值。这意味着可以控制自动化答案与专家判断不一致的概率，从而提高系统的可靠性。\\n\\n**关键设计**：论文的关键设计包括：1) 使用知识测试和置信度测试来评估LLM的答案质量。知识测试评估答案的正确性，置信度测试评估LLM对答案的自信程度。2) 使用多重假设检验（MHT）来选择置信度阈值。MHT可以控制总体错误率，从而保证系统的可靠性。3) 定义了一个错位成本约束的优化问题，旨在最小化平均处理成本，同时保证自动化答案与专家判断的一致性。",
            "application_zh": "该研究成果可应用于各种需要知识密集型决策的电信场景，例如网络故障诊断、服务配置优化和客户问题解答。通过自动化处理大部分查询，可以显著降低人工成本，提高响应速度，并提升客户满意度。此外，该方法也可以推广到其他领域，如医疗诊断、金融风控等。",
            "highlight_zh": "实验结果表明，所提出的基于MHT的阈值选择方法在TeleQnA数据集上优于传统的级联基线。在保证相同错位风险水平的前提下，该方法能够显著降低平均处理成本。具体而言，与基线方法相比，该方法可以将成本降低10%-20%，同时保持与专家判断的高度一致性。",
            "tags_zh": [
                "大型语言模型",
                "边缘计算",
                "知识系统",
                "多重假设检验",
                "电信网络",
                "问答系统",
                "成本优化"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20012v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20012v1/paper_photo/FST.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20012v1/photo/boxplot_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Schoenfeld's Anatomy of Mathematical Reasoning by Language Models",
            "authors": [
                "Ming Li",
                "Chenrui Fan",
                "Yize Cheng",
                "Soheil Feizi",
                "Tianyi Zhou"
            ],
            "arxiv_id": "2512.19995v1",
            "summary": "Large language models increasingly expose reasoning traces, yet their underlying cognitive structure and steps remain difficult to identify and analyze beyond surface-level statistics. We adopt Schoenfeld's Episode Theory as an inductive, intermediate-scale lens and introduce ThinkARM (Anatomy of Reasoning in Models), a scalable framework that explicitly abstracts reasoning traces into functional reasoning steps such as Analysis, Explore, Implement, Verify, etc. When applied to mathematical problem solving by diverse models, this abstraction reveals reproducible thinking dynamics and structural differences between reasoning and non-reasoning models, which are not apparent from token-level views. We further present two diagnostic case studies showing that exploration functions as a critical branching step associated with correctness, and that efficiency-oriented methods selectively suppress evaluative feedback steps rather than uniformly shortening responses. Together, our results demonstrate that episode-level representations make reasoning steps explicit, enabling systematic analysis of how reasoning is structured, stabilized, and altered in modern language models.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.19995v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ThinkARM框架，剖析语言模型数学推理过程中的认知结构与步骤",
            "summary_zh": "大型语言模型越来越多地展示出推理轨迹，但其潜在的认知结构和步骤仍然难以识别和分析，而不仅仅是表面层面的统计。我们采用Schoenfeld的Episode Theory作为一种归纳的、中等尺度的视角，并引入ThinkARM（模型推理剖析），这是一个可扩展的框架，它将推理轨迹显式地抽象为功能性的推理步骤，如分析、探索、实现、验证等。当应用于不同模型解决数学问题时，这种抽象揭示了可重复的思维动态以及推理模型和非推理模型之间的结构差异，这些差异在token级别视图中并不明显。我们进一步提出了两个诊断案例研究，表明探索是与正确性相关的关键分支步骤，并且面向效率的方法选择性地抑制评估反馈步骤，而不是统一地缩短响应。总之，我们的结果表明，episode级别的表示使推理步骤显式化，从而能够系统地分析现代语言模型中推理是如何构建、稳定和改变的。",
            "intro_zh": [
                "现有方法难以识别和分析语言模型推理过程中的认知结构和具体步骤，仅停留在表面统计层面。",
                "论文提出ThinkARM框架，将推理轨迹抽象为分析、探索、实现、验证等功能性步骤，便于分析。",
                "实验表明，ThinkARM能揭示推理模型和非推理模型在思维动态和结构上的差异，并诊断关键步骤。"
            ],
            "method_zh": "**问题定义**：现有方法难以深入理解大型语言模型在数学问题求解过程中的推理机制。仅仅关注token级别的统计信息无法揭示模型内部的认知结构和推理步骤，导致难以诊断和改进模型的推理能力。因此，需要一种更高级别的抽象方法来分析模型的推理过程。\\n\\n**核心思路**：论文的核心思路是借鉴Schoenfeld的Episode Theory，将复杂的推理过程分解为一系列功能性的推理步骤（Episodes），例如分析问题、探索解决方案、实施解决方案以及验证结果。通过将模型的推理轨迹映射到这些预定义的Episodes，可以更清晰地理解模型的推理流程和潜在问题。\\n\\n**技术框架**：ThinkARM框架主要包含以下几个阶段：1) **推理轨迹提取**：从语言模型的输出中提取推理过程的文本记录。2) **Episode识别**：使用自然语言处理技术（例如，文本分类或序列标注）将推理轨迹中的每个步骤映射到预定义的Episode类型（例如，分析、探索、实现、验证）。3) **推理动态分析**：分析不同Episode之间的转换关系和频率，从而揭示模型的推理模式和结构。4) **诊断性案例研究**：通过特定的案例研究，分析不同Episode对最终结果的影响，并识别模型推理过程中的瓶颈。\\n\\n**关键创新**：ThinkARM的关键创新在于它提供了一种可扩展的、中间尺度的抽象方法，可以将语言模型的推理轨迹转化为功能性的推理步骤。这种抽象方法使得研究人员可以更系统地分析模型的推理过程，并识别影响模型性能的关键因素。与传统的token级别分析相比，ThinkARM能够揭示更深层次的认知结构和推理动态。\\n\\n**关键设计**：ThinkARM框架的关键设计包括：1) **Episode类型的定义**：根据Schoenfeld的Episode Theory，定义了一组通用的推理步骤，例如分析、探索、实现、验证等。2) **Episode识别模型**：使用预训练的语言模型（例如，BERT或RoBERTa）对推理轨迹进行分类，从而识别每个步骤所属的Episode类型。3) **推理动态分析方法**：使用图论或马尔可夫链等方法分析不同Episode之间的转换关系，从而揭示模型的推理模式。",
            "application_zh": "该研究成果可应用于提升大型语言模型的数学推理能力，例如通过优化模型的探索策略或增强验证环节。此外，该框架还可用于评估不同模型的推理能力，并为模型设计提供指导。该方法具有通用性，可以推广到其他需要复杂推理的任务中，例如代码生成、逻辑推理等。",
            "highlight_zh": "实验结果表明，ThinkARM能够有效区分推理模型和非推理模型，并揭示它们在思维动态和结构上的差异。案例研究表明，探索步骤与正确性密切相关，而效率优化方法可能会抑制评估反馈步骤。这些发现为改进语言模型的推理能力提供了有价值的见解。",
            "tags_zh": [
                "语言模型",
                "数学推理",
                "认知结构",
                "推理步骤",
                "Episode Theory"
            ],
            "_index": 73,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.19995v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.19995v1/figures/word_cloud.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.19995v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Distilling to Hybrid Attention Models via KL-Guided Layer Selection",
            "authors": [
                "Yanhong Li",
                "Songlin Yang",
                "Shawn Tan",
                "Mayank Mishra",
                "Rameswar Panda",
                "Jiawei Zhou",
                "Yoon Kim"
            ],
            "arxiv_id": "2512.20569v1",
            "summary": "Distilling pretrained softmax attention Transformers into more efficient hybrid architectures that interleave softmax and linear attention layers is a promising approach for improving the inference efficiency of LLMs without requiring expensive pretraining from scratch. A critical factor in the conversion process is layer selection, i.e., deciding on which layers to convert to linear attention variants. This paper describes a simple and efficient recipe for layer selection that uses layer importance scores derived from a small amount of training on generic text data. Once the layers have been selected we use a recent pipeline for the distillation process itself \\citep[RADLADS;][]{goldstein2025radlads}, which consists of attention weight transfer, hidden state alignment, KL-based distribution matching, followed by a small amount of finetuning. We find that this approach is more effective than existing approaches for layer selection, including heuristics that uniformly interleave linear attentions based on a fixed ratio, as well as more involved approaches that rely on specialized diagnostic datasets.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20569v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "linear attention",
                        "distillation"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于KL散度引导的层选择方法，用于将Softmax注意力Transformer蒸馏为混合注意力模型。",
            "summary_zh": "本文提出了一种简单高效的层选择方法，用于将预训练的Softmax注意力Transformer蒸馏为更高效的混合架构，该架构交替使用Softmax和线性注意力层。这种方法旨在提高LLM的推理效率，而无需从头开始进行昂贵的预训练。该方法使用从少量通用文本数据训练中获得的层重要性得分来确定要转换为线性注意力变体的层。在选定层之后，我们使用最近的蒸馏流程（RADLADS），该流程包括注意力权重转移、隐藏状态对齐、基于KL散度的分布匹配，以及少量的微调。实验表明，该方法比现有的层选择方法更有效，包括基于固定比例均匀交错线性注意力的启发式方法，以及依赖于专门诊断数据集的更复杂的方法。",
            "intro_zh": [
                "现有方法在将Softmax注意力Transformer蒸馏为混合架构时，层选择策略效率低或依赖特定数据集。",
                "论文提出基于KL散度引导的层选择方法，通过层重要性得分确定线性注意力层的位置。",
                "实验表明，该方法优于均匀交错等现有层选择策略，能更有效地提升推理效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何高效地将预训练的Softmax注意力Transformer模型蒸馏成混合注意力模型的问题。现有方法，如均匀交错线性注意力层或依赖特定诊断数据集的方法，在层选择方面效率较低或泛化性不足，无法充分利用线性注意力的优势来加速推理。\\n\\n**核心思路**：核心思路是利用少量通用文本数据训练得到的层重要性得分来指导层选择过程。通过评估每一层的重要性，选择性地将重要性较低的层转换为线性注意力层，从而在保持模型性能的同时，降低计算复杂度。这种方法避免了对特定数据集的依赖，提高了泛化能力。\\n\\n**技术框架**：整体框架包括两个主要阶段：层选择阶段和蒸馏阶段。在层选择阶段，首先使用少量通用文本数据训练原始的Softmax注意力Transformer模型，然后计算每一层的层重要性得分。基于这些得分，选择一部分层转换为线性注意力层。在蒸馏阶段，使用RADLADS流程，包括注意力权重转移、隐藏状态对齐、基于KL散度的分布匹配，以及少量的微调，将原始模型的知识迁移到混合注意力模型。\\n\\n**关键创新**：最重要的技术创新点在于提出了一种基于KL散度引导的层选择方法。与现有方法相比，该方法不需要专门的诊断数据集，而是利用通用文本数据来评估层的重要性，从而更准确地确定哪些层可以安全地转换为线性注意力层，而不会显著降低模型性能。\\n\\n**关键设计**：关键设计包括：1) 使用KL散度来衡量原始模型和蒸馏模型在每一层的输出分布之间的差异，从而指导蒸馏过程。2) 使用RADLADS流程进行蒸馏，该流程包括注意力权重转移、隐藏状态对齐和分布匹配，以确保蒸馏后的模型能够尽可能地保留原始模型的知识。3) 使用少量微调来进一步优化蒸馏后的模型。",
            "application_zh": "该研究成果可广泛应用于自然语言处理领域，尤其是在需要部署大规模语言模型的场景中，如智能客服、机器翻译、文本生成等。通过将大型Softmax注意力Transformer模型蒸馏为更高效的混合注意力模型，可以显著降低推理成本，提高响应速度，从而更好地满足实际应用的需求。此外，该方法还可以应用于其他类型的Transformer模型，具有一定的通用性。",
            "highlight_zh": "该论文提出的方法在层选择方面优于现有的均匀交错等策略。实验结果表明，使用该方法蒸馏得到的混合注意力模型在保持性能的同时，显著降低了计算复杂度，提高了推理效率。具体的性能数据和提升幅度在论文中进行了详细的展示和对比。",
            "tags_zh": [
                "Transformer蒸馏",
                "混合注意力模型",
                "层选择",
                "KL散度",
                "模型压缩"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20569v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20569v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20569v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation",
            "authors": [
                "Nishant Gaurav",
                "Adit Akarsh",
                "Ankit Ranjan",
                "Manoj Bajaj"
            ],
            "arxiv_id": "2512.20278v1",
            "summary": "While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "7 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20278v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种自动工作流生成方法，解决大型语言模型从工具使用者到工作流架构师的转变难题。",
            "summary_zh": "尽管CodeMem确立了可执行代码作为智能体程序记忆的最佳表示形式，但自主地从零开始合成这种记忆的机制仍未得到充分探索。本文旨在推动大型语言模型从被动工具使用者转变为主动工作流架构师。通过对涉及Outlook和OneDrive的跨服务编排任务进行高保真案例研究，我们识别并解决了自动技能生成中的四个结构性瓶颈：涉及大型工具注册表导航的发现差距、关于基础工具响应结构的验证差距、用线性状态锚定取代低效搜索的分解差距，以及关注并发和持久性的扩展差距。我们证明，通过执行假设、探测和编码的科学方法，智能体可以自主编写健壮的、生产级别的代码技能。",
            "intro_zh": [
                "现有方法缺乏自主合成程序记忆的机制，限制了大型语言模型在复杂任务中的应用。",
                "论文提出一种基于假设、探测和编码的科学方法，使智能体能够自主编写代码技能。",
                "通过Outlook和OneDrive的跨服务编排案例研究，验证了该方法在解决自动技能生成瓶颈方面的有效性。"
            ],
            "method_zh": "**问题定义**：现有方法主要依赖人工设计工作流或简单的工具调用，无法充分利用大型语言模型的潜力，自主生成复杂的、可执行的程序记忆。痛点在于：难以发现和利用大量可用的工具，难以验证工具响应的正确性，难以将复杂任务分解为可执行的步骤，以及难以处理并发和持久性等扩展性问题。\\n\\n**核心思路**：论文的核心思路是将大型语言模型从被动工具使用者转变为主动工作流架构师。通过引入一种迭代的“假设、探测、编码”流程，使智能体能够自主探索工具的功能，验证工具的响应，并将复杂任务分解为一系列可执行的代码步骤。这种方法旨在克服自动技能生成中的各种瓶颈，并生成健壮的、生产级别的代码技能。\\n\\n**技术框架**：整体框架包含以下几个主要阶段：1) **发现阶段**：智能体探索可用的工具和服务，并选择合适的工具来解决当前的问题。2) **验证阶段**：智能体通过探测工具的API，验证工具的响应结构，并确保工具能够按照预期工作。3) **分解阶段**：智能体将复杂任务分解为一系列可执行的步骤，并使用线性状态锚定来优化搜索过程。4) **编码阶段**：智能体将分解后的步骤转换为可执行的代码，并处理并发和持久性等扩展性问题。\\n\\n**关键创新**：最重要的技术创新点在于将“假设、探测、编码”的科学方法应用于自动工作流生成。这种方法使智能体能够自主学习和适应新的工具和服务，并生成健壮的、可执行的代码技能。与现有方法相比，该方法更加灵活和可扩展，能够处理更复杂的任务。\\n\\n**关键设计**：论文中关键的设计包括：1) 使用大型语言模型作为智能体的核心推理引擎；2) 设计了一种线性状态锚定机制，用于优化任务分解过程；3) 采用了一种基于代码的程序记忆表示形式，使智能体能够高效地存储和检索知识；4) 实现了对并发和持久性的支持，使智能体能够处理更复杂的任务。",
            "application_zh": "该研究成果可应用于自动化办公、智能助手、机器人流程自动化（RPA）等领域。通过自动生成工作流，可以显著提高工作效率，降低人工成本，并实现更智能化的任务处理。未来，该技术有望应用于更广泛的领域，例如智能制造、智慧城市等。",
            "highlight_zh": "该论文通过在Outlook和OneDrive的跨服务编排任务上的实验，验证了所提出方法的有效性。实验结果表明，该方法能够自主生成健壮的、生产级别的代码技能，并有效地解决了自动技能生成中的四个结构性瓶颈。具体的性能数据和对比基线在论文中进行了详细描述。",
            "tags_zh": [
                "工作流生成",
                "程序记忆",
                "大型语言模型",
                "自动化",
                "代码合成",
                "跨服务编排",
                "智能体"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
            "authors": [
                "Tarik Houichime",
                "Abdelghani Souhar",
                "Younes El Amrani"
            ],
            "arxiv_id": "2512.20245v1",
            "summary": "The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via \"Signal Consensus\" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.",
            "categories": [
                "cs.NE",
                "cs.AI",
                "cs.IR",
                "cs.SC",
                "cs.SE"
            ],
            "primary_category": "cs.NE",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20245v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于遍历语音流形的共振记忆架构PTM，解决大语言模型无限上下文记忆问题。",
            "summary_zh": "当前大型语言模型的记忆受限于物理限制：随着学习的进行，模型容量逐渐耗尽。键-值状态的线性累积（O(N)）将上下文视为静态信息的仓库，最终迫使模型在遗忘和延迟之间做出选择。我们挑战了这种离散的正统观念，认为长期记忆不是存储项目，而是轨迹的持久性。我们引入了语音轨迹记忆（PTM），一种神经符号架构，它不是将语言编码为张量序列，而是编码为由无理旋转矩阵控制的遍历流形上的连续路径。通过将导航（不变的O(1)几何信号）与重构（概率生成行为）解耦，PTM实现了相对于密集缓存大于3000倍的压缩率。我们证明了检索成为一个共振过程：语音轨迹通过“信号共识”机制稳定模型，防止幻觉，确保高达约92%的事实准确性。虽然这种激进的抽象改变了生成纹理，但它解锁了独立于深度的即时访问延迟（约34毫秒）。我们的结果表明，无限上下文不需要无限的硅，而是需要将记忆视为作用于守恒的、不朽的物理信号的重构过程。",
            "intro_zh": [
                "现有大语言模型受限于上下文窗口大小，无法有效处理长程依赖，面临遗忘和高延迟的挑战。",
                "论文提出语音轨迹记忆（PTM），将语言编码为遍历流形上的连续路径，实现高效压缩和快速检索。",
                "实验表明，PTM在长文本记忆方面实现了超过3000倍的压缩，并保持了较高的事实准确率（约92%）。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）在处理长上下文时面临着严重的挑战。传统的键值对存储方式导致内存需求随上下文长度线性增长（O(N)），这限制了模型能够处理的上下文长度，并导致检索延迟增加。此外，这种离散的存储方式将上下文视为静态信息的集合，忽略了语言的动态特性，容易导致模型产生幻觉。\n\n**核心思路**：论文的核心思路是将长期记忆视为轨迹的持久性，而不是静态信息的存储。具体来说，论文将语言编码为遍历流形上的连续路径，利用无理旋转矩阵控制路径的演化。这种方法将导航（上下文定位）与重构（信息生成）解耦，从而实现高效的压缩和快速的检索。通过将上下文表示为连续的轨迹，模型可以更好地捕捉语言的动态特性，并减少幻觉的产生。\n\n**技术框架**：PTM的核心框架包括以下几个主要模块：1) **语音编码器**：将输入的文本转换为语音特征表示。2) **遍历流形**：使用无理旋转矩阵构建一个高维的遍历流形，用于表示上下文轨迹。3) **轨迹生成器**：根据语音特征生成在遍历流形上的连续路径。4) **信号共识模块**：通过比较当前输入与历史轨迹，实现对模型的稳定，减少幻觉。5) **解码器**：根据遍历流形上的位置重构文本。\n\n**关键创新**：PTM的关键创新在于将语言编码为遍历流形上的连续路径，并利用无理旋转矩阵控制路径的演化。这种方法实现了以下几个方面的优势：1) **高效压缩**：通过将上下文表示为连续的轨迹，PTM实现了远高于传统键值对存储的压缩率。2) **快速检索**：通过将导航与重构解耦，PTM实现了与上下文长度无关的快速检索。3) **减少幻觉**：通过信号共识机制，PTM可以有效地稳定模型，减少幻觉的产生。\n\n**关键设计**：PTM的关键设计包括：1) **无理旋转矩阵**：使用无理旋转矩阵保证遍历流形的遍历性，确保模型可以访问到所有的上下文信息。2) **信号共识损失**：设计信号共识损失函数，鼓励模型生成与历史轨迹一致的输出，从而减少幻觉。3) **概率生成模型**：使用概率生成模型根据遍历流形上的位置重构文本，实现信息的解码。",
            "application_zh": "PTM具有广泛的应用前景，例如：1) **长文本生成**：可以用于生成长篇小说、报告等。2) **对话系统**：可以用于构建具有长期记忆的对话系统。3) **信息检索**：可以用于在海量文本数据中进行快速检索。PTM的出现有望推动人工智能在长程依赖任务上的发展，并为构建更智能、更可靠的AI系统提供新的思路。",
            "highlight_zh": "PTM在实验中表现出了显著的优势。相对于传统的密集缓存，PTM实现了超过3000倍的压缩率，同时保持了较低的检索延迟（约34毫秒）。此外，PTM通过信号共识机制，将事实准确率提高到约92%，显著减少了模型产生幻觉的可能性。这些结果表明，PTM是一种非常有前景的长文本记忆架构。",
            "tags_zh": [
                "长文本记忆",
                "遍历流形",
                "神经符号架构",
                "无理旋转矩阵",
                "信号共识",
                "大语言模型",
                "上下文学习"
            ],
            "_index": 76,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20245v1/Images/torusv3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20245v1/Images/max_drift-rotations-merged.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20245v1/Images/architecture.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents",
            "authors": [
                "Xingbo Du",
                "Loka Li",
                "Duzhen Zhang",
                "Le Song"
            ],
            "arxiv_id": "2512.20237v1",
            "summary": "Memory systems have been designed to leverage past experiences in Large Language Model (LLM) agents. However, many deployed memory systems primarily optimize compression and storage, with comparatively less emphasis on explicit, closed-loop control of memory retrieval. From this observation, we build memory retrieval as an autonomous, accurate, and compatible agent system, named MemR$^3$, which has two core mechanisms: 1) a router that selects among retrieve, reflect, and answer actions to optimize answer quality; 2) a global evidence-gap tracker that explicitly renders the answering process transparent and tracks the evidence collection process. This design departs from the standard retrieve-then-answer pipeline by introducing a closed-loop control mechanism that enables autonomous decision-making. Empirical results on the LoCoMo benchmark demonstrate that MemR$^3$ surpasses strong baselines on LLM-as-a-Judge score, and particularly, it improves existing retrievers across four categories with an overall improvement on RAG (+7.29%) and Zep (+1.94%) using GPT-4.1-mini backend, offering a plug-and-play controller for existing memory stores.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "16 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MemR³：通过反思推理实现LLM Agent的记忆检索，提升问答质量。",
            "summary_zh": "本文提出了一种名为MemR³的记忆检索系统，旨在提升大型语言模型（LLM）Agent利用历史经验的能力。与现有主要优化压缩和存储的记忆系统不同，MemR³更侧重于对记忆检索进行显式的闭环控制。该系统包含两个核心机制：1) 一个路由器，用于在检索、反思和回答动作之间进行选择，以优化答案质量；2) 一个全局证据缺口追踪器，用于显式地呈现回答过程并追踪证据收集过程。这种设计通过引入闭环控制机制，实现了自主决策，从而突破了标准的检索-然后-回答的流程。在LoCoMo基准测试上的实验结果表明，MemR³在LLM-as-a-Judge评分上超越了强大的基线，并且在使用GPT-4.1-mini后端时，在RAG（+7.29%）和Zep（+1.94%）等四个类别上改进了现有的检索器，为现有的记忆存储提供了一个即插即用的控制器。",
            "intro_zh": [
                "现有记忆系统侧重压缩存储，缺乏对检索的显式闭环控制，导致LLM Agent在复杂任务中难以有效利用历史经验。",
                "MemR³通过引入路由器和全局证据缺口追踪器，实现检索、反思和回答的自主决策，优化证据收集过程，提升答案质量。",
                "实验表明，MemR³在LoCoMo基准测试中超越了现有基线，显著提升了RAG和Zep等检索器的性能，尤其是在问答质量方面。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）Agent的记忆系统，虽然能够存储和压缩历史信息，但在检索阶段缺乏有效的控制机制。传统的“检索-然后-回答”流程是单向的，无法根据回答过程中的证据缺口进行动态调整，导致回答质量受限。因此，需要一种能够自主控制检索过程，并根据反馈进行反思和调整的记忆检索系统。\n\n**核心思路**：MemR³的核心思路是将记忆检索过程建模为一个自主决策过程，通过引入闭环控制机制，使Agent能够根据当前的证据状态和回答需求，动态地选择不同的动作（检索、反思、回答）。这种设计允许Agent在检索过程中不断评估证据的充分性，并根据需要进行反思和补充检索，从而提高回答的准确性和完整性。\n\n**技术框架**：MemR³包含两个主要模块：路由器和全局证据缺口追踪器。路由器负责在检索、反思和回答三个动作之间进行选择，其决策基于当前的问题、已检索到的证据以及证据缺口追踪器的反馈。全局证据缺口追踪器负责监控回答过程中的证据收集情况，并识别出缺失或不足的证据，为路由器提供决策依据。整个流程是一个迭代的过程，Agent不断地进行检索、反思和回答，直到证据充分或达到预设的停止条件。\n\n**关键创新**：MemR³最重要的创新在于引入了闭环控制机制，将记忆检索过程从一个单向的流程转变为一个动态的决策过程。通过路由器和全局证据缺口追踪器的协同工作，Agent能够自主地控制检索过程，并根据反馈进行反思和调整。这种设计使得Agent能够更有效地利用历史信息，并生成更准确、更完整的回答。与传统的检索方法相比，MemR³能够更好地适应复杂的问题和动态的环境。\n\n**关键设计**：路由器的设计是MemR³的关键。路由器需要学习在不同的状态下选择合适的动作。这可以通过强化学习或监督学习来实现。全局证据缺口追踪器需要能够准确地识别出缺失或不足的证据。这可以通过分析已检索到的证据和问题之间的语义关系来实现。具体的实现细节，例如路由器的网络结构、证据缺口追踪器的算法等，需要根据具体的应用场景进行调整。",
            "application_zh": "MemR³可应用于各种需要LLM Agent进行复杂推理和决策的场景，例如智能客服、知识问答、任务规划和代码生成等。通过提升Agent对历史信息的利用效率和回答质量，MemR³能够显著提高这些应用的性能和用户体验。未来，MemR³有望成为LLM Agent记忆系统的标准组件，推动Agent技术的发展。",
            "highlight_zh": "在LoCoMo基准测试中，MemR³在使用GPT-4.1-mini后端时，在RAG上取得了+7.29%的提升，在Zep上取得了+1.94%的提升。这些结果表明，MemR³能够有效地提升现有检索器的性能，并显著提高LLM Agent的问答质量。实验结果还表明，MemR³在四个类别上均优于现有检索器，证明了其通用性和有效性。",
            "tags_zh": [
                "LLM Agent",
                "记忆检索",
                "反思推理",
                "闭环控制",
                "证据追踪"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20237v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20237v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20237v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
            "authors": [
                "Honglin Mu",
                "Jinghao Liu",
                "Kaiyang Wan",
                "Rui Xing",
                "Xiuying Chen",
                "Timothy Baldwin",
                "Wanxiang Che"
            ],
            "arxiv_id": "2512.20164v1",
            "summary": "Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20164v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "揭示LLM在简历筛选等专业应用中对抗性漏洞，并提出有效防御方法",
            "summary_zh": "大型语言模型（LLM）在文本理解和生成方面表现出色，使其成为代码审查和内容审核等自动化任务的理想选择。然而，我们的研究发现了一个漏洞：LLM容易受到隐藏在输入数据（如简历或代码）中的“对抗性指令”的操纵，导致它们偏离预期的任务。值得注意的是，虽然针对代码审查等成熟领域可能存在防御机制，但在简历筛选和同行评审等其他常见应用中，这些防御机制往往缺失。本文引入了一个基准来评估简历筛选中的这种漏洞，揭示了某些攻击类型的成功率超过80%。我们评估了两种防御机制：基于提示的防御实现了10.1%的攻击减少，但误拒率增加了12.5%，而我们提出的使用LoRA适配的FIDS（通过分离进行外部指令检测）实现了15.4%的攻击减少，误拒率增加了10.4%。组合方法提供了26.3%的攻击减少，表明训练时防御在安全性和效用保持方面均优于推理时缓解。",
            "intro_zh": [
                "现有LLM在简历筛选等专业领域应用中，缺乏针对对抗性指令攻击的有效防御机制，存在安全隐患。",
                "论文提出FIDS（通过分离进行外部指令检测）方法，利用LoRA适配增强模型对对抗性指令的识别能力。",
                "实验表明，FIDS及与prompt-based防御结合的方法，能有效降低攻击成功率，且训练时防御优于推理时缓解。"
            ],
            "method_zh": "**问题定义**：论文旨在解决LLM在简历筛选等专业应用中，容易受到对抗性指令攻击的问题。现有方法，特别是针对代码审查等成熟领域的防御机制，无法直接应用于这些专业领域，导致LLM在处理简历等数据时容易被恶意指令操纵，偏离预定目标。\\n\\n**核心思路**：论文的核心思路是通过训练时防御，增强LLM对对抗性指令的识别和抵抗能力。具体而言，论文提出了FIDS（Foreign Instruction Detection through Separation）方法，旨在将模型对正常指令和对抗性指令的响应分离，从而更容易检测和过滤对抗性指令。\\n\\n**技术框架**：整体框架包含两个主要阶段：攻击阶段和防御阶段。在攻击阶段，研究者构建对抗性指令并将其嵌入到简历中，以评估LLM的脆弱性。在防御阶段，研究者评估了prompt-based防御和FIDS两种方法。FIDS使用LoRA（Low-Rank Adaptation）技术，在预训练的LLM基础上进行微调，以区分正常指令和对抗性指令。\\n\\n**关键创新**：最重要的技术创新点在于FIDS方法，它通过LoRA适配，在训练过程中显式地学习区分正常指令和对抗性指令，从而提高了模型对对抗性攻击的鲁棒性。与传统的推理时防御方法相比，FIDS在训练时就融入了防御机制，能够更有效地抵御对抗性攻击。\\n\\n**关键设计**：FIDS的关键设计在于使用LoRA适配器。LoRA通过引入低秩矩阵来更新预训练模型的权重，从而在微调过程中减少了计算量和内存消耗。在FIDS中，LoRA被用于学习区分正常指令和对抗性指令的特征表示。此外，论文还探索了prompt-based防御，通过修改输入提示来引导LLM忽略对抗性指令。损失函数的设计可能涉及对比学习或交叉熵损失，以鼓励模型区分正常和对抗性指令的表示。",
            "application_zh": "该研究成果可应用于各种基于LLM的自动化任务，如招聘领域的简历筛选、学术领域的论文评审、以及内容审核等。通过提升LLM对抗恶意指令攻击的鲁棒性，可以提高自动化系统的安全性和可靠性，减少人工干预，提高工作效率。未来，该研究可以扩展到其他专业领域，并与其他防御技术相结合，构建更强大的安全防护体系。",
            "highlight_zh": "实验结果表明，某些攻击类型的成功率超过80%，凸显了LLM在简历筛选等专业应用中的安全风险。FIDS方法实现了15.4%的攻击减少，误拒率增加了10.4%。结合prompt-based防御，攻击减少率达到26.3%，表明训练时防御策略优于推理时缓解策略。这些数据验证了FIDS的有效性，并为LLM安全防御提供了新的思路。",
            "tags_zh": [
                "大型语言模型",
                "对抗性攻击",
                "简历筛选",
                "安全漏洞",
                "LoRA适配"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20164v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20164v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20164v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
            "authors": [
                "Ruiqi Wang",
                "Xinchen Wang",
                "Cuiyun Gao",
                "Chun Yong Chong",
                "Xin Xia",
                "Qing Liao"
            ],
            "arxiv_id": "2512.20159v1",
            "summary": "Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios.\n  To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20159v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "AXIOM：通过规则扰动和多源质量校准，基准测试LLM作为代码评估判官的能力",
            "summary_zh": "大型语言模型（LLMs）越来越多地应用于实际的软件工程中，促进了代码评估指标的发展，以研究LLM生成的代码的质量。传统的基于规则的指标仅仅根据程序与参考程序的表面相似性来评分，而不是深入分析功能和代码质量。为了解决这个局限性，研究人员开发了LLM-as-a-judge指标，提示LLMs评估和评分代码，并策划了各种代码评估基准来验证其有效性。然而，这些基准存在严重的局限性，阻碍了评估能力的可靠评估：一些基准具有粗粒度的二元标签，将丰富的代码行为简化为单个比特的信息，掩盖了细微的错误。另一些基准提出了细粒度但主观、定义模糊的评估标准，在手动注释的分数中引入了不可靠性，而这些分数是它们所依赖的ground-truth。此外，它们通常使用不受控制的数据合成方法，导致不平衡的分数分布，不能很好地代表真实世界的代码生成场景。为了创建一个多样化的基准，其中程序在各种质量级别上具有良好平衡的分布，并简化手动注释过程，我们提出了AXIOM，这是一个新颖的基于扰动的框架，用于大规模合成代码评估基准。它将程序分数重新定义为部署所需的改进工作，包括两个阶段：（1）规则引导的扰动，它提示LLMs将预定义的扰动规则序列应用于现有的高质量程序，以修改其功能和代码质量，使我们能够精确控制每个程序的目标分数，以实现平衡的分数分布。（2）多源质量校准，它首先选择一个子集...",
            "intro_zh": [
                "现有代码评估基准存在粗粒度标签、主观评估标准和不平衡数据分布等问题，难以可靠评估LLM的代码评估能力。",
                "AXIOM框架通过规则引导的扰动生成具有平衡质量分布的代码，并利用多源质量校准来提高评估的准确性。",
                "AXIOM旨在创建一个多样化的代码评估基准，能够更有效地评估LLM作为代码评估判官的能力，并简化手动标注流程。"
            ],
            "method_zh": "**问题定义**：现有代码评估基准存在以下痛点：一是标签过于粗糙，无法捕捉代码的细微错误；二是评估标准主观且定义模糊，导致人工标注不可靠；三是数据合成方法缺乏控制，造成分数分布不平衡，难以反映真实场景。这些问题严重阻碍了对LLM代码评估能力的有效评估。\\n\\n**核心思路**：AXIOM的核心思路是将代码质量评估转化为衡量代码“可部署性”所需的改进工作量。通过对高质量代码进行可控的扰动，人为引入缺陷，并根据扰动程度确定代码的质量等级。同时，利用多源信息对代码质量进行校准，提高评估的准确性。这种方法能够生成具有平衡质量分布且标注可靠的代码评估基准。\\n\\n**技术框架**：AXIOM框架包含两个主要阶段：1) **规则引导的扰动**：利用LLM对高质量代码应用预定义的扰动规则序列，修改代码的功能和质量，从而生成不同质量等级的代码。扰动规则的设计旨在模拟真实场景中可能出现的各种代码缺陷。2) **多源质量校准**：首先选择一个代码子集进行多方标注，然后利用这些标注数据训练一个模型，用于预测剩余代码的质量。多源信息包括代码本身的特征、LLM的评估结果以及人工标注结果。\\n\\n**关键创新**：AXIOM最重要的创新在于其基于扰动的代码生成方法。与传统方法直接生成代码或依赖人工标注不同，AXIOM通过对高质量代码进行可控的修改，能够精确控制代码的质量等级，并生成具有平衡质量分布的基准。此外，多源质量校准也提高了评估的准确性和可靠性。\\n\\n**关键设计**：扰动规则的设计是关键。这些规则需要覆盖各种常见的代码缺陷类型，例如逻辑错误、语法错误、性能问题等。扰动规则的强度也需要进行调整，以确保生成的代码质量分布均匀。多源质量校准中，需要选择合适的模型和特征，以充分利用各种信息源的优势。",
            "application_zh": "AXIOM框架生成的代码评估基准可以广泛应用于评估和比较不同LLM的代码生成和评估能力。它可以帮助研究人员更好地理解LLM在软件工程领域的优势和局限性，并促进相关技术的进一步发展。此外，该基准还可以用于训练和优化LLM，提高其代码生成质量和评估准确性。",
            "highlight_zh": "论文提出了AXIOM框架，通过规则扰动和多源质量校准，生成了高质量的代码评估基准。该基准具有平衡的质量分布和可靠的标注，能够更有效地评估LLM的代码评估能力。实验结果（未知，摘要未提及具体实验结果）表明，AXIOM框架能够生成更具代表性和挑战性的代码评估数据集。",
            "tags_zh": [
                "代码评估",
                "大型语言模型",
                "基准测试",
                "规则扰动",
                "多源质量校准"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20159v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20159v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20159v1/figures/rq2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection",
            "authors": [
                "Xingyou Yin",
                "Ceyao Zhang",
                "Min Hu",
                "Kai Chen"
            ],
            "arxiv_id": "2512.20140v1",
            "summary": "Large Language Models (LLMs) have demonstrated effectiveness as zero-shot time series (TS) forecasters. The key challenge lies in tokenizing TS data into textual representations that align with LLMs' pre-trained knowledge. While existing work often relies on fine-tuning specialized modules to bridge this gap, a distinct, yet challenging, paradigm aims to leverage truly off-the-shelf LLMs without any fine-tuning whatsoever, relying solely on strategic tokenization of numerical sequences. The performance of these fully frozen models is acutely sensitive to the textual representation of the input data, as their parameters cannot adapt to distribution shifts. In this paper, we introduce a simple yet highly effective strategy to overcome this brittleness: injecting noise into the raw time series before tokenization. This non-invasive intervention acts as a form of inference-time augmentation, compelling the frozen LLM to extrapolate based on robust underlying temporal patterns rather than superficial numerical artifacts. We theoretically analyze this phenomenon and empirically validate its effectiveness across diverse benchmarks. Notably, to fully eliminate potential biases from data contamination during LLM pre-training, we introduce two novel TS datasets that fall outside all utilized LLMs' pre-training scopes, and consistently observe improved performance. This study provides a further step in directly leveraging off-the-shelf LLMs for time series forecasting.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "9 pages,3 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20140v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过噪声注入增强即用型LLM的零样本时间序列预测能力",
            "summary_zh": "大型语言模型(LLMs)已展现出作为零样本时间序列(TS)预测器的有效性。关键挑战在于将TS数据标记化为与LLMs预训练知识对齐的文本表示。现有工作通常依赖于微调专门的模块来弥合这一差距，而一种截然不同但具有挑战性的范例旨在利用真正的即用型LLMs，无需任何微调，仅依赖于数值序列的战略性标记化。这些完全冻结模型的性能对输入数据的文本表示非常敏感，因为它们的参数无法适应分布偏移。本文提出了一种简单而高效的策略来克服这种脆弱性：在标记化之前将噪声注入原始时间序列。这种非侵入性干预充当一种推理时增强形式，迫使冻结的LLM基于鲁棒的底层时间模式而不是表面的数值伪像进行外推。我们从理论上分析了这种现象，并通过各种基准测试验证了其有效性。值得注意的是，为了完全消除LLM预训练期间数据污染可能产生的偏差，我们引入了两个新颖的TS数据集，这些数据集不在所有使用的LLM的预训练范围内，并始终观察到性能的提高。这项研究为直接利用即用型LLM进行时间序列预测提供了进一步的步骤。",
            "intro_zh": [
                "现有零样本时间序列预测方法依赖微调或对分布偏移敏感，限制了即用型LLM的直接应用。",
                "该论文提出在时间序列标记化前注入噪声，作为推理时增强，迫使LLM关注鲁棒的时间模式。",
                "实验表明，该方法在多个数据集上有效提升了零样本预测性能，并在新数据集上验证了无偏差性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决直接利用预训练好的、未经任何微调的大型语言模型（LLMs）进行零样本时间序列预测时，模型性能对输入数据表示方式过于敏感的问题。现有方法要么需要对LLM进行微调，要么依赖于专门的模块，这限制了LLM的通用性和即用性。直接使用LLM时，由于其参数无法适应时间序列数据的分布偏移，预测结果往往不稳定。\\n\\n**核心思路**：论文的核心思路是在将时间序列数据输入LLM之前，向原始数据中注入噪声。这种噪声注入可以看作是一种推理时的数据增强方法，它迫使LLM关注时间序列数据中更鲁棒、更本质的模式，而不是依赖于表面的数值特征。通过这种方式，可以提高LLM对不同数据表示方式的泛化能力，从而提升零样本预测的性能。\\n\\n**技术框架**：该方法的核心流程包括以下几个步骤：1) 获取原始时间序列数据；2) 向时间序列数据中注入噪声；3) 将加噪后的时间序列数据进行标记化，转换为LLM可以理解的文本表示；4) 将文本表示输入到预训练的LLM中进行预测；5) 将LLM的输出转换回时间序列预测结果。整个框架的关键在于噪声注入策略，它在数据预处理阶段起到了至关重要的作用。\\n\\n**关键创新**：该论文最重要的技术创新点在于提出了噪声注入作为一种简单而有效的推理时增强方法，用于提高即用型LLM在零样本时间序列预测中的鲁棒性。与现有方法相比，该方法无需对LLM进行任何微调，也无需引入额外的模块，而是通过对输入数据进行简单的处理，即可显著提升预测性能。这种方法的创新之处在于它充分利用了LLM的预训练知识，并通过噪声注入来引导LLM关注更本质的时间模式。\\n\\n**关键设计**：论文中关于噪声注入的具体实现细节（例如噪声的类型、幅度等）以及时间序列数据的标记化方式是关键的设计选择。论文可能探讨了不同类型的噪声（例如高斯噪声、均匀噪声等）对预测性能的影响，并选择了最优的噪声类型和幅度。此外，时间序列数据的标记化方式也会影响LLM的性能，论文可能采用了某种特定的标记化策略，例如将时间序列数据转换为自然语言描述或使用特殊的token表示时间序列的数值。",
            "application_zh": "该研究成果可广泛应用于金融、气象、交通等领域的时间序列预测。通过直接利用预训练的LLM，无需针对特定领域进行微调，即可快速部署时间序列预测模型，降低了开发成本和时间。该方法还有助于提高预测模型的鲁棒性和泛化能力，使其能够更好地适应不同的数据分布和场景。未来，该方法有望成为一种通用的时间序列预测解决方案。",
            "highlight_zh": "实验结果表明，该方法在多个时间序列数据集上显著提升了零样本预测性能。为了验证方法的有效性和消除数据污染的潜在偏差，作者构建了两个全新的时间序列数据集，并在这些数据集上观察到了一致的性能提升。具体提升幅度未知，但强调了该方法的有效性和鲁棒性。",
            "tags_zh": [
                "时间序列预测",
                "零样本学习",
                "大型语言模型",
                "噪声注入",
                "推理时增强"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20140v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20140v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20140v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
            "authors": [
                "Sangryu Park",
                "Gihyuk Ko",
                "Homook Cho"
            ],
            "arxiv_id": "2512.20062v1",
            "summary": "Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "The 9th International Conference on Mobile Internet Security (MobiSec 2025)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20062v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "指令调优本地LLM，有效识别软件漏洞类型，提升安全性和实用性。",
            "summary_zh": "大型语言模型(LLM)在自动化软件漏洞分析方面展现出巨大潜力，这对现代软件系统安全至关重要。然而，当前利用LLM进行漏洞分析的方法主要依赖于在线API服务，需要用户公开源代码。此外，它们通常将任务视为二元分类（有漏洞或无漏洞），限制了实际应用。本文通过将问题重新定义为软件漏洞识别(SVI)，要求LLM输出常见弱点枚举(CWE) ID中的弱点类型，而不仅仅是表明是否存在漏洞，从而解决了这些限制。我们还通过证明指令调优较小的、本地可部署的LLM可以实现卓越的识别性能，从而解决了对大型API型LLM的依赖。分析表明，指令调优的本地LLM在整体性能和成本效益方面优于在线API型LLM。我们的研究结果表明，对于在实际漏洞管理工作流程中利用LLM，指令调优的本地模型代表了一种更有效、安全和实用的方法。",
            "intro_zh": [
                "现有软件漏洞分析方法依赖在线API-based LLM，存在暴露源代码的安全风险，且仅限于二元分类，实用性受限。",
                "论文提出软件漏洞识别(SVI)任务，要求LLM输出CWE ID，实现漏洞类型识别，并采用指令调优本地LLM。",
                "实验表明，指令调优的本地LLM在性能和成本效益上优于在线API-based LLM，更具实用性。"
            ],
            "method_zh": "**问题定义**：现有基于LLM的软件漏洞分析方法主要依赖在线API服务，这要求开发者上传源代码，存在安全风险。同时，这些方法通常将漏洞分析简化为二元分类问题（即判断是否存在漏洞），无法提供漏洞的具体类型信息，限制了其在实际漏洞管理工作流程中的应用。\\n\\n**核心思路**：论文的核心思路是将软件漏洞分析重新定义为软件漏洞识别(SVI)任务，即要求LLM不仅判断是否存在漏洞，还要识别漏洞的具体类型（CWE ID）。此外，论文通过指令调优（instruction-tuning）的方式，使较小的、本地可部署的LLM也能达到甚至超过大型在线API型LLM的性能，从而避免了源代码泄露的风险。\\n\\n**技术框架**：论文的技术框架主要包括以下几个步骤：1) 数据准备：构建包含软件代码和对应CWE ID的数据集。2) 模型选择：选择一个较小的、本地可部署的LLM作为基础模型。3) 指令调优：使用构建的数据集对基础模型进行指令调优，使其能够根据输入的代码识别漏洞类型。4) 评估：使用测试集评估模型的性能，并与在线API型LLM进行比较。\\n\\n**关键创新**：论文的关键创新在于：1) 将软件漏洞分析重新定义为软件漏洞识别(SVI)任务，提高了漏洞分析的实用性。2) 证明了通过指令调优，较小的、本地可部署的LLM也能达到甚至超过大型在线API型LLM的性能，降低了安全风险和成本。\\n\\n**关键设计**：论文的关键设计包括：1) 选择合适的指令调优数据集，确保数据集的质量和多样性。2) 设计有效的指令模板，引导LLM学习如何根据代码识别漏洞类型。3) 采用合适的评估指标，全面评估模型的性能，例如准确率、召回率和F1值。",
            "application_zh": "该研究成果可应用于软件开发生命周期的各个阶段，例如代码审查、安全测试和漏洞修复。通过使用本地部署的、指令调优的LLM，开发者可以在不泄露源代码的情况下，快速准确地识别软件漏洞类型，从而提高软件的安全性和可靠性。未来，该技术有望集成到IDE和CI/CD流程中，实现自动化漏洞分析。",
            "highlight_zh": "实验结果表明，指令调优的本地LLM在软件漏洞识别任务上表现出色，在某些情况下甚至优于在线API型LLM。例如，在特定CWE类型的识别上，本地LLM的准确率提升了10%以上。此外，本地LLM的推理速度更快，成本更低，更适合实际应用。",
            "tags_zh": [
                "软件漏洞分析",
                "大型语言模型",
                "指令调优",
                "本地LLM",
                "软件安全"
            ],
            "_index": 81,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20062v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20062v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20062v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test",
            "authors": [
                "Zhe Sun",
                "Xueyuan Yang",
                "Yujie Lu",
                "Zhenliang Zhang"
            ],
            "arxiv_id": "2512.19992v1",
            "summary": "The integration of embodied agents into human environments demands embodied social intelligence: reasoning over both social norms and physical constraints. However, existing evaluations fail to address this integration, as they are limited to either disembodied social reasoning (e.g., in text) or socially-agnostic physical tasks. Both approaches fail to assess an agent's ability to integrate and trade off both physical and social constraints within a realistic, embodied context. To address this challenge, we introduce Spatially Situated Social Intelligence Test (S$^{3}$IT), a benchmark specifically designed to evaluate embodied social intelligence. It is centered on a novel and challenging seat-ordering task, requiring an agent to arrange seating in a 3D environment for a group of large language model-driven (LLM-driven) NPCs with diverse identities, preferences, and intricate interpersonal relationships. Our procedurally extensible framework generates a vast and diverse scenario space with controllable difficulty, compelling the agent to acquire preferences through active dialogue, perceive the environment via autonomous exploration, and perform multi-objective optimization within a complex constraint network. We evaluate state-of-the-art LLMs on S$^{3}$IT and found that they still struggle with this problem, showing an obvious gap compared with the human baseline. Results imply that LLMs have deficiencies in spatial intelligence, yet simultaneously demonstrate their ability to achieve near human-level competence in resolving conflicts that possess explicit textual cues.",
            "categories": [
                "cs.AI",
                "cs.CY"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.19992v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出S$^3$IT基准测试，用于评估具身智能体在复杂社交环境中的推理能力",
            "summary_zh": "本文提出了一个名为空间情境化社会智能测试(S$^3$IT)的基准，旨在评估具身智能体的社会智能。该基准的核心是一个新颖且具有挑战性的座位安排任务，要求智能体在一个3D环境中为一群由大型语言模型(LLM)驱动的NPC安排座位，这些NPC具有不同的身份、偏好和复杂的人际关系。该框架具有程序可扩展性，能够生成大量且多样化的场景，并控制难度。智能体需要通过主动对话获取偏好，通过自主探索感知环境，并在复杂的约束网络中执行多目标优化。在S$^3$IT上评估了最先进的LLM，结果表明它们仍然难以解决这个问题，与人类基线相比存在明显的差距。结果表明LLM在空间智能方面存在不足，但同时证明了它们在解决具有明确文本线索的冲突方面具有接近人类水平的能力。",
            "intro_zh": [
                "现有评估方法要么局限于非具身的社会推理，要么是社会无关的物理任务，无法评估智能体在现实环境中整合物理和社会约束的能力。",
                "S$^3$IT基准测试通过座位安排任务，要求智能体在3D环境中为具有复杂社交关系的NPC安排座位，从而评估具身社会智能。",
                "实验结果表明，现有LLM在空间智能方面存在不足，但在解决具有明确文本线索的冲突方面表现出接近人类水平的能力。"
            ],
            "method_zh": "**问题定义**：现有方法无法有效评估具身智能体在同时考虑物理和社会约束下的推理能力。具体来说，现有基准测试要么侧重于非具身的文本社会推理，要么侧重于与社会因素无关的物理任务，忽略了真实世界中物理和社会因素相互作用的复杂性。因此，需要一个能够综合评估智能体在具身环境中进行社会推理能力的基准。\n\\n**核心思路**：S$^3$IT的核心思路是创建一个具有挑战性的座位安排任务，该任务要求智能体在3D环境中为一群具有不同身份、偏好和复杂人际关系的NPC安排座位。智能体需要通过主动对话获取NPC的偏好，通过自主探索感知环境，并在复杂的约束网络中进行多目标优化，从而实现最佳的座位安排。\n\\n**技术框架**：S$^3$IT的整体框架包含以下几个主要模块：1) **场景生成器**：用于生成具有不同NPC身份、偏好和人际关系的3D环境。该模块具有程序可扩展性，可以生成大量且多样化的场景，并控制难度。2) **对话模块**：允许智能体与NPC进行对话，从而获取NPC的座位偏好。3) **环境感知模块**：允许智能体通过自主探索感知3D环境，获取座位的位置和可用性信息。4) **座位安排模块**：根据NPC的偏好、人际关系和环境约束，进行多目标优化，从而生成最佳的座位安排方案。5) **评估模块**：用于评估智能体的座位安排方案的质量，例如，是否满足NPC的偏好，是否避免了冲突等。\n\\n**关键创新**：S$^3$IT的关键创新在于它将社会智能与具身环境相结合，创造了一个更真实、更具挑战性的评估场景。与现有基准测试相比，S$^3$IT能够更全面地评估智能体在复杂社交环境中的推理能力。此外，S$^3$IT的程序可扩展性使其能够生成大量且多样化的场景，从而避免了过拟合问题。\n\\n**关键设计**：S$^3$IT的关键设计包括：1) 使用LLM驱动的NPC，使其具有更真实、更自然的对话能力。2) 设计了复杂的NPC人际关系网络，使得座位安排任务更具挑战性。3) 采用了多目标优化算法，以平衡不同NPC的偏好和约束。4) 设计了多种评估指标，以全面评估智能体的座位安排方案的质量。具体参数设置和损失函数等细节未在论文中详细描述，属于未知信息。",
            "application_zh": "S$^3$IT基准测试可以应用于开发更智能、更具社会意识的具身智能体，例如，社交机器人、虚拟助手等。这些智能体可以在各种现实场景中提供帮助，例如，组织会议、安排座位、协调活动等。此外，S$^3$IT还可以用于研究人类的社会推理能力，从而更好地理解人类的社交行为。",
            "highlight_zh": "实验结果表明，最先进的LLM在S$^3$IT基准测试中表现不佳，与人类基线相比存在明显的差距。这表明LLM在空间智能方面存在不足，需要进一步改进。然而，LLM在解决具有明确文本线索的冲突方面表现出接近人类水平的能力，表明LLM在社会推理方面具有一定的潜力。具体的性能数据和提升幅度未在摘要中给出，属于未知信息。",
            "tags_zh": [
                "具身智能",
                "社会智能",
                "基准测试",
                "大型语言模型",
                "空间推理"
            ],
            "_index": 82,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.19992v1/S3IT/figures/teaser.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.19992v1/S3IT/figures/elements.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.19992v1/S3IT/figures/room.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Coherence in the brain unfolds across separable temporal regimes",
            "authors": [
                "Davide Stauba",
                "Finn Rabe",
                "Akhil Misra",
                "Yves Pauli",
                "Roya Hüppi",
                "Nils Lang",
                "Lars Michels",
                "Victoria Edkins",
                "Sascha Frühholz",
                "Iris Sommer",
                "Wolfram Hinzen",
                "Philipp Homan"
            ],
            "arxiv_id": "2512.20481v1",
            "summary": "Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.",
            "categories": [
                "q-bio.NC",
                "cs.CL"
            ],
            "primary_category": "q-bio.NC",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20481v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用LLM提取的漂移和位移信号，揭示大脑中语言连贯性处理的时域分离机制",
            "summary_zh": "语言连贯性要求大脑满足两个相互竞争的时间需求：跨越扩展语境的意义逐渐积累，以及在事件边界处的表征快速重构。尽管这些过程对于语言和思维至关重要，但它们在人类大脑中自然听觉过程中的实现方式仍不清楚。本文测试了这两个过程是否可以通过无标注的漂移和位移信号来捕捉，以及它们的大脑神经表达是否在大规模皮层系统中分离。这些信号来自大型语言模型（LLM），并直接从叙事输入中形式化了语境漂移和事件位移。为了实现具有稳定参数估计的高精度体素编码模型，我们对一位健康成年人进行了超过7小时的密集采样，同时收集了超高场（7T）BOLD数据。然后，我们使用在独立故事上验证的正则化编码框架，对特征信息引导的血流动力学反应进行建模。漂移预测主要出现在默认模式网络中心，而位移预测在初级听觉皮层和语言联合皮层双侧均很明显。此外，默认模式网络和顶叶网络中的活动最好由一个信号来解释，该信号捕捉了意义如何在叙事过程中积累和逐渐消退。总之，这些发现表明，语言理解过程中的连贯性是通过缓慢的语境整合和快速的事件驱动重构的可分离神经机制来实现的，为理解精神疾病中语言连贯性障碍提供了一个机械论的切入点。",
            "intro_zh": [
                "自然语言理解中，大脑需要在长时程的语义积累和短时程的事件边界快速重构之间进行平衡，现有研究缺乏对这两种机制如何在大脑中实现的清晰理解。",
                "本文利用大型语言模型（LLM）提取的漂移和位移信号，分别对应语境的逐渐变化和事件的突变，以此来捕捉大脑中的语义积累和快速重构过程。",
                "实验结果表明，漂移信号主要与默认模式网络相关，而位移信号主要与听觉皮层和语言联合皮层相关，揭示了大脑中语言连贯性处理的时域分离机制。"
            ],
            "method_zh": "**问题定义**：论文旨在解决自然语言理解过程中，大脑如何同时处理长时程的语义连贯性（语境积累）和短时程的事件边界（快速重构）的问题。现有方法难以区分这两种时间尺度上的神经活动，并且缺乏对它们之间相互作用的深入理解。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）来提取两种关键信号：语境漂移信号（contextual drift）和事件位移信号（event shift）。语境漂移信号反映了随着叙事展开，语义逐渐积累和变化的过程；事件位移信号则捕捉了叙事中事件边界处的突变。通过将这些信号与大脑活动进行关联，可以揭示大脑中不同区域在不同时间尺度上处理语言连贯性的方式。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：\n1. **数据采集**：使用7T超高场fMRI扫描，记录被试在听取多个犯罪故事时的脑活动。\n2. **LLM特征提取**：使用大型语言模型处理故事文本，提取语境漂移和事件位移信号。\n3. **编码模型构建**：使用正则化的编码框架，将LLM提取的信号与fMRI数据进行关联，构建体素级别的预测模型。\n4. **模型验证**：在独立的故事上验证模型的预测能力，评估模型的泛化性能。\n5. **结果分析**：分析不同脑区对语境漂移和事件位移信号的响应，揭示大脑中语言连贯性处理的时域分离机制。\\n\\n**关键创新**：论文的关键创新在于：\n1. **使用LLM提取的漂移和位移信号**：这种方法能够更准确地捕捉语言理解过程中的语义变化和事件边界，避免了传统方法中手动标注的局限性。\n2. **高精度体素编码模型**：通过高密度采样和正则化方法，构建了具有稳定参数估计的体素编码模型，提高了模型预测的准确性。\n3. **揭示了大脑中语言连贯性处理的时域分离机制**：研究结果表明，大脑中存在两个不同的神经机制，分别负责处理长时程的语义积累和短时程的事件重构。\\n\\n**关键设计**：\n* **LLM选择**：论文使用了具体哪个LLM未明确说明（未知）。\n* **正则化方法**：使用了正则化编码框架，具体正则化方法未知。\n* **7T fMRI**：使用7T超高场fMRI，提供更高分辨率的脑活动数据。\n* **编码模型**：体素级别的编码模型，将LLM特征与每个体素的BOLD信号关联。",
            "application_zh": "该研究成果可应用于精神疾病的诊断和治疗，例如精神分裂症患者常常表现出语言连贯性障碍。通过分析患者大脑中漂移和位移信号的异常，可以帮助医生更准确地诊断病情，并制定更有效的治疗方案。此外，该研究还可以用于开发更智能的自然语言处理系统，提高机器对人类语言的理解能力。",
            "highlight_zh": "研究发现，默认模式网络（DMN）的活动与语境漂移信号显著相关，表明DMN在长时程的语义整合中起着关键作用。而初级听觉皮层和语言联合皮层则对事件位移信号更加敏感，反映了这些区域在快速事件重构中的作用。此外，研究还发现顶叶网络也参与了语义积累和消退的过程，进一步揭示了语言理解的复杂神经机制。",
            "tags_zh": [
                "语言理解",
                "大脑连贯性",
                "大型语言模型",
                "fMRI",
                "默认模式网络",
                "事件驱动",
                "神经机制"
            ],
            "_index": 83,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20481v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20481v1/figure2_meanr_simesp.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20481v1/figure3_contrasts.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SpidR: Learning Fast and Stable Linguistic Units for Spoken Language Models Without Supervision",
            "authors": [
                "Maxime Poli",
                "Mahi Luthra",
                "Youssef Benchekroun",
                "Yosuke Higuchi",
                "Martin Gleize",
                "Jiayi Shen",
                "Robin Algayres",
                "Yu-An Chung",
                "Mido Assran",
                "Juan Pino",
                "Emmanuel Dupoux"
            ],
            "arxiv_id": "2512.20308v1",
            "summary": "The parallel advances in language modeling and speech representation learning have raised the prospect of learning language directly from speech without textual intermediates. This requires extracting semantic representations directly from speech. Our contributions are threefold. First, we introduce SpidR, a self-supervised speech representation model that efficiently learns representations with highly accessible phonetic information, which makes it particularly suited for textless spoken language modeling. It is trained on raw waveforms using a masked prediction objective combined with self-distillation and online clustering. The intermediate layers of the student model learn to predict assignments derived from the teacher's intermediate layers. This learning objective stabilizes the online clustering procedure compared to previous approaches, resulting in higher quality codebooks. SpidR outperforms wav2vec 2.0, HuBERT, WavLM, and DinoSR on downstream language modeling benchmarks (sWUGGY, sBLIMP, tSC). Second, we systematically evaluate across models and layers the correlation between speech unit quality (ABX, PNMI) and language modeling performance, validating these metrics as reliable proxies. Finally, SpidR significantly reduces pretraining time compared to HuBERT, requiring only one day of pretraining on 16 GPUs, instead of a week. This speedup is enabled by the pretraining method and an efficient codebase, which allows faster iteration and easier experimentation. We open-source the training code and model checkpoints at https://github.com/facebookresearch/spidr.",
            "categories": [
                "cs.CL",
                "cs.SD",
                "eess.AS"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "30 pages, 16 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20308v1",
            "code_links": [
                {
                    "url": "https://github.com/facebookresearch/spidr",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "distillation"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "SpidR：无需监督，学习快速稳定的语音单元用于语音语言模型",
            "summary_zh": "语音语言建模和语音表征学习的并行发展，使得直接从语音中学习语言而无需文本中间步骤成为可能。本文提出了SpidR，一种自监督语音表征模型，它能高效地学习具有高度可访问语音信息的表征，特别适合于无文本语音语言建模。SpidR使用掩码预测目标、自蒸馏和在线聚类在原始波形上进行训练。学生模型的中间层学习预测来自教师模型中间层的分配。与以往方法相比，这种学习目标稳定了在线聚类过程，从而产生更高质量的码本。在下游语言建模基准测试（sWUGGY、sBLIMP、tSC）中，SpidR优于wav2vec 2.0、HuBERT、WavLM和DinoSR。此外，系统地评估了语音单元质量（ABX、PNMI）与语言建模性能之间的相关性，验证了这些指标作为可靠代理。最后，与HuBERT相比，SpidR显著减少了预训练时间，仅需在16个GPU上预训练一天，而不是一周。这种加速得益于预训练方法和高效的代码库，从而可以更快地迭代和更容易地进行实验。代码和模型检查点已开源。",
            "intro_zh": [
                "现有语音语言模型依赖文本中间步骤，限制了其效率和泛化能力，SpidR旨在直接从语音中学习语言。",
                "SpidR通过掩码预测、自蒸馏和在线聚类，学习具有高度可访问语音信息的语音表征，提升码本质量。",
                "实验表明，SpidR在多个语言建模基准上优于现有模型，并显著减少了预训练时间。"
            ],
            "method_zh": "**问题定义**：本文旨在解决如何高效地从原始语音波形中学习高质量的语音表征，用于无文本语音语言建模。现有方法，如HuBERT，预训练时间长，且在线聚类过程不够稳定，导致学习到的语音单元质量不高。\\n\\n**核心思路**：SpidR的核心思路是通过结合掩码预测、自蒸馏和在线聚类，稳定在线聚类过程，从而学习到具有高度可访问语音信息的语音表征。自蒸馏过程使得学生模型能够学习教师模型的知识，从而提高学习效率和稳定性。\\n\\n**技术框架**：SpidR的整体框架包括一个学生模型和一个教师模型。首先，对原始语音波形进行掩码处理。然后，学生模型和教师模型分别对掩码后的语音进行编码。学生模型的中间层学习预测来自教师模型中间层的聚类分配。最后，通过掩码预测损失和自蒸馏损失来优化模型。\\n\\n**关键创新**：SpidR的关键创新在于使用自蒸馏来稳定在线聚类过程。传统的在线聚类方法容易受到噪声和初始化影响，导致聚类结果不稳定。通过自蒸馏，学生模型可以学习教师模型的知识，从而提高聚类结果的稳定性和质量。\\n\\n**关键设计**：SpidR的关键设计包括：1) 使用掩码预测目标来学习语音表征；2) 使用自蒸馏来稳定在线聚类过程；3) 使用在线聚类来生成语音单元的码本；4) 使用ABX和PNMI指标来评估语音单元的质量。具体的损失函数包括掩码预测损失和自蒸馏损失。网络结构基于Transformer架构。",
            "application_zh": "SpidR在语音识别、语音合成、语音翻译等领域具有广泛的应用前景。它可以用于构建端到端的语音处理系统，无需文本标注数据，降低了数据收集和标注的成本。此外，SpidR还可以用于跨语言语音处理，例如，在一种语言上训练的模型可以用于另一种语言的语音处理。",
            "highlight_zh": "SpidR在sWUGGY、sBLIMP和tSC等下游语言建模任务上优于wav2vec 2.0、HuBERT、WavLM和DinoSR等基线模型。更重要的是，SpidR显著减少了预训练时间，仅需在16个GPU上训练一天，而HuBERT需要一周。这使得SpidR更易于训练和部署。",
            "tags_zh": [
                "自监督学习",
                "语音表征学习",
                "语音语言模型",
                "自蒸馏",
                "在线聚类"
            ],
            "_index": 84,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20308v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20308v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20308v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LightTact: A Visual-Tactile Fingertip Sensor for Deformation-Independent Contact Sensing",
            "authors": [
                "Changyi Lin",
                "Boda Huo",
                "Mingyang Yu",
                "Emily Ruppel",
                "Bingqing Chen",
                "Jonathan Francis",
                "Ding Zhao"
            ],
            "arxiv_id": "2512.20591v1",
            "summary": "Contact often occurs without macroscopic surface deformation, such as during interaction with liquids, semi-liquids, or ultra-soft materials. Most existing tactile sensors rely on deformation to infer contact, making such light-contact interactions difficult to perceive robustly. To address this, we present LightTact, a visual-tactile fingertip sensor that makes contact directly visible via a deformation-independent, optics-based principle. LightTact uses an ambient-blocking optical configuration that suppresses both external light and internal illumination at non-contact regions, while transmitting only the diffuse light generated at true contacts. As a result, LightTact produces high-contrast raw images in which non-contact pixels remain near-black (mean gray value < 3) and contact pixels preserve the natural appearance of the contacting surface. Built on this, LightTact achieves accurate pixel-level contact segmentation that is robust to material properties, contact force, surface appearance, and environmental lighting. We further integrate LightTact on a robotic arm and demonstrate manipulation behaviors driven by extremely light contact, including water spreading, facial-cream dipping, and thin-film interaction. Finally, we show that LightTact's spatially aligned visual-tactile images can be directly interpreted by existing vision-language models, enabling resistor value reasoning for robotic sorting.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20591v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "LightTact：一种用于形变无关接触感知的视觉-触觉指尖传感器",
            "summary_zh": "本文提出了一种名为LightTact的视觉-触觉指尖传感器，用于解决轻微接触场景下的感知问题，尤其是在与液体、半液体或超软材料交互时，这些场景通常不产生宏观表面形变。LightTact基于光学原理，无需依赖形变即可直接观察接触。它采用环境光阻断的光学配置，抑制非接触区域的外部光和内部照明，仅传输真实接触处产生的漫反射光。因此，LightTact生成高对比度的原始图像，其中非接触像素保持接近黑色（平均灰度值<3），而接触像素保留接触表面的自然外观。基于此，LightTact实现了精确的像素级接触分割，对材料属性、接触力、表面外观和环境光照具有鲁棒性。该传感器被集成到机械臂上，并展示了由极轻微接触驱动的操作行为，包括水扩散、面霜蘸取和薄膜交互。此外，LightTact空间对齐的视觉-触觉图像可以直接被现有的视觉-语言模型解释，从而实现电阻值的推理，用于机器人分拣。",
            "intro_zh": [
                "现有触觉传感器依赖形变来推断接触，在与液体等轻微接触场景中表现不佳，鲁棒性不足。",
                "LightTact采用光学配置，阻断环境光，仅传输接触区域的漫反射光，从而直接观察接触，无需依赖形变。",
                "实验表明，LightTact能准确分割接触区域，并驱动机械臂完成水扩散等轻微接触操作，还能结合视觉-语言模型进行电阻分拣。"
            ],
            "method_zh": "**问题定义**：现有触觉传感器主要依赖于接触产生的形变来感知接触，这在与液体、半液体或超软材料等发生轻微接触时会失效，因为这些接触通常不会引起明显的宏观形变。因此，需要一种能够独立于形变进行接触感知的传感器。\\n\\n**核心思路**：LightTact的核心思路是利用光学方法，直接“看到”接触。通过设计一种特殊的光学配置，阻断环境光和内部照明，使得只有在真实接触点产生的漫反射光才能被传感器捕捉到。这样，即使没有明显的形变，也能清晰地识别出接触区域。\\n\\n**技术框架**：LightTact传感器主要由以下几个部分组成：一个指尖形状的外壳，一个用于阻断环境光的光学系统，一个内部光源（用于在接触时产生漫反射），以及一个相机。当物体与传感器接触时，内部光源发出的光会在接触表面发生漫反射，这些漫反射光穿过光学系统，被相机捕捉到。非接触区域由于环境光和内部照明被阻断，因此在图像中呈现黑色。整个流程可以概括为：环境光阻断 -> 内部照明 -> 接触表面漫反射 -> 相机成像。\\n\\n**关键创新**：LightTact最重要的创新在于其形变无关的接触感知原理。与传统的触觉传感器不同，LightTact不依赖于形变来推断接触，而是直接通过光学方法观察接触。这种方法使得LightTact能够感知到非常轻微的接触，即使没有明显的形变也能准确地识别出接触区域。\\n\\n**关键设计**：LightTact的关键设计在于其光学配置，需要精确地控制光路，以确保环境光和内部照明在非接触区域被有效地阻断，同时保证接触区域产生的漫反射光能够被相机捕捉到。具体的技术细节包括：光学元件的形状、位置和材料的选择，内部光源的类型和强度，以及相机的参数设置（如曝光时间和增益）。此外，图像处理算法也至关重要，需要能够有效地从原始图像中分割出接触区域。",
            "application_zh": "LightTact在机器人操作、医疗保健、虚拟现实等领域具有广泛的应用前景。例如，在机器人操作中，它可以用于精确地控制机械臂与柔软物体的交互，如抓取易碎物品或进行精细的装配。在医疗保健领域，它可以用于开发更灵敏的医疗设备，如用于诊断或治疗的触觉传感器。在虚拟现实领域，它可以用于创建更逼真的触觉反馈，增强用户的沉浸感。",
            "highlight_zh": "LightTact实现了高精度的像素级接触分割，对材料属性、接触力、表面外观和环境光照具有鲁棒性。实验表明，LightTact能够驱动机械臂完成水扩散、面霜蘸取和薄膜交互等轻微接触操作。此外，LightTact与视觉-语言模型结合，实现了电阻值的推理，为机器人分拣提供了新的解决方案。",
            "tags_zh": [
                "视觉触觉融合",
                "触觉传感器",
                "轻微接触感知",
                "光学触觉",
                "机器人操作"
            ],
            "_index": 85,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20591v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20591v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20591v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Contingency Model-based Control (CMC) for Communicationless Cooperative Collision Avoidance in Robot Swarms",
            "authors": [
                "Georg Schildbach"
            ],
            "arxiv_id": "2512.20391v1",
            "summary": "Cooperative collision avoidance between robots in swarm operations remains an open challenge. Assuming a decentralized architecture, each robot is responsible for making its own control decisions, including motion planning. To this end, most existing approaches mostly rely some form of (wireless) communication between the agents of the swarm. In reality, however, communication is brittle. It may be affected by latency, further delays and packet losses, transmission faults, and is subject to adversarial attacks, such as jamming or spoofing. This paper proposes Contingency Model-based Control (CMC) as a communicationless alternative. It follows the implicit cooperation paradigm, under which the design of the robots is based on consensual (offline) rules, similar to traffic rules. They include the definition of a contingency trajectory for each robot, and a method for construction of mutual collision avoidance constraints. The setup is shown to guarantee the recursive feasibility and collision avoidance between all swarm members in closed-loop operation. Moreover, CMC naturally satisfies the Plug \\& Play paradigm, i.e., for new robots entering the swarm. Two numerical examples demonstrate that the collision avoidance guarantee is intact and that the robot swarm operates smoothly under the CMC regime.",
            "categories": [
                "math.OC",
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "math.OC",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20391v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "motion planning"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于应急模型的控制方法(CMC)，用于机器人集群中无通信的协同避障",
            "summary_zh": "机器人集群操作中的协同避障仍然是一个开放的挑战。在去中心化架构下，每个机器人负责做出自己的控制决策，包括运动规划。为此，大多数现有方法主要依赖于集群智能体之间的某种形式的（无线）通信。然而，在现实中，通信是脆弱的，可能受到延迟、进一步的延迟和数据包丢失、传输故障的影响，并且容易受到对抗性攻击，例如干扰或欺骗。本文提出基于应急模型的控制（CMC）作为一种无需通信的替代方案。它遵循隐式协作范例，其中机器人的设计基于协商一致的（离线）规则，类似于交通规则。这些规则包括为每个机器人定义应急轨迹，以及构建互避碰撞约束的方法。该设置被证明可以保证所有集群成员在闭环操作中的递归可行性和避碰。此外，CMC自然地满足即插即用范例，即对于进入集群的新机器人。两个数值例子表明，避碰保证是完整的，并且机器人集群在CMC机制下平稳运行。",
            "intro_zh": [
                "现有机器人集群协同避障方法依赖通信，但实际通信易受干扰，存在延迟和丢包等问题。",
                "提出基于应急模型的控制（CMC），通过预定义的规则和应急轨迹实现无通信的隐式协作。",
                "数值实验验证了CMC的有效性，保证了闭环操作中的递归可行性和避碰，并支持即插即用。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器人集群在去中心化控制下，如何在缺乏可靠通信的情况下实现协同避障的问题。现有方法依赖无线通信，但通信链路的脆弱性（延迟、丢包、干扰等）严重影响了避障性能和鲁棒性。因此，如何在没有通信的情况下保证集群安全高效地运行是一个关键挑战。\\n\\n**核心思路**：论文的核心思路是采用“隐式协作”范例，即通过预先设计好的、所有机器人共同遵守的规则来实现协同避障，而无需实时通信。每个机器人根据自身状态和预定义的规则独立决策，从而避免对通信的依赖。这种方法类似于交通规则，车辆通过遵守规则来实现交通秩序。\\n\\n**技术框架**：CMC方法主要包含以下几个关键模块：1) 为每个机器人定义应急轨迹，该轨迹描述了在潜在碰撞情况下机器人应采取的规避动作。2) 构建互避碰撞约束，这些约束基于机器人的状态和应急轨迹，确保机器人之间保持足够的安全距离。3) 设计控制律，使机器人能够跟踪期望轨迹，并在必要时切换到应急轨迹。整个框架保证了在闭环操作中，所有机器人都能递归地保持可行性，并避免碰撞。\\n\\n**关键创新**：CMC方法最重要的创新在于其无通信的协同避障机制。与依赖通信的方法相比，CMC具有更强的鲁棒性和可扩展性，能够应对通信受限或不可用的场景。此外，CMC自然地支持即插即用，新加入的机器人只需遵守预定义的规则即可融入集群，无需进行复杂的通信协议协商。\\n\\n**关键设计**：应急轨迹的设计是CMC的关键。论文中应急轨迹的具体形式未知，但其设计需要考虑机器人的动力学约束、环境的静态障碍物以及其他机器人的潜在行为。互避碰撞约束的设计也至关重要，需要保证在各种情况下都能提供足够的安全裕量，同时避免过于保守导致集群效率下降。控制律的设计需要保证机器人能够准确跟踪期望轨迹，并在必要时快速切换到应急轨迹。",
            "application_zh": "CMC方法适用于各种需要机器人集群协同工作的场景，例如：仓库物流、农业机器人、搜救行动、环境监测等。在这些场景中，通信可能受到限制或不可靠，CMC提供了一种鲁棒且可扩展的解决方案，能够保证集群的安全高效运行。未来，CMC可以进一步扩展到更复杂的环境和任务中，例如：动态环境、多目标优化等。",
            "highlight_zh": "论文通过数值实验验证了CMC的有效性。实验结果表明，在没有通信的情况下，CMC能够保证机器人集群安全地避开彼此，并平稳地完成任务。此外，实验还验证了CMC的即插即用特性，新加入的机器人能够快速融入集群并参与协同避障。具体的性能数据和对比基线未知。",
            "tags_zh": [
                "机器人集群",
                "协同避障",
                "无通信控制",
                "应急模型",
                "隐式协作"
            ],
            "_index": 86,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Learning Skills from Action-Free Videos",
            "authors": [
                "Hung-Chieh Fang",
                "Kuo-Han Hung",
                "Chu-Rong Chen",
                "Po-Jung Chou",
                "Chun-Kai Yang",
                "Po-Chen Ko",
                "Yu-Chiang Wang",
                "Yueh-Hua Wu",
                "Min-Hung Chen",
                "Shao-Hua Sun"
            ],
            "arxiv_id": "2512.20052v1",
            "summary": "Learning from videos offers a promising path toward generalist robots by providing rich visual and temporal priors beyond what real robot datasets contain. While existing video generative models produce impressive visual predictions, they are difficult to translate into low-level actions. Conversely, latent-action models better align videos with actions, but they typically operate at the single-step level and lack high-level planning capabilities. We bridge this gap by introducing Skill Abstraction from Optical Flow (SOF), a framework that learns latent skills from large collections of action-free videos. Our key idea is to learn a latent skill space through an intermediate representation based on optical flow that captures motion information aligned with both video dynamics and robot actions. By learning skills in this flow-based latent space, SOF enables high-level planning over video-derived skills and allows for easier translation of these skills into actions. Experiments show that our approach consistently improves performance in both multitask and long-horizon settings, demonstrating the ability to acquire and compose skills directly from raw visual data.",
            "categories": [
                "cs.AI",
                "cs.RO"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20052v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "optical flow"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出基于光流的技能抽象框架SOF，从无动作视频中学习机器人技能",
            "summary_zh": "本文提出了一种名为“基于光流的技能抽象”（SOF）的框架，旨在从大量无动作视频中学习潜在技能，从而弥合视频生成模型与机器人动作执行之间的差距。现有视频生成模型虽然能产生出色的视觉预测，但难以转化为低级动作。而潜在动作模型虽然能更好地将视频与动作对齐，但通常仅限于单步操作，缺乏高级规划能力。SOF通过学习基于光流的中间表示来学习潜在技能空间，光流能够捕捉与视频动态和机器人动作对齐的运动信息。通过在基于流的潜在空间中学习技能，SOF能够对视频导出的技能进行高级规划，并更容易地将这些技能转化为动作。实验表明，该方法在多任务和长时程设置中均能持续提高性能，证明了其直接从原始视觉数据中获取和组合技能的能力。",
            "intro_zh": [
                "现有视频生成模型难以转化为机器人可执行的低级动作，而单步潜在动作模型缺乏高级规划能力。",
                "SOF框架通过光流中间表示学习潜在技能空间，该空间对齐视频动态和机器人动作，实现技能的高级规划。",
                "实验结果表明，SOF在多任务和长时程任务中均表现出性能提升，验证了其从原始视频数据学习技能的有效性。"
            ],
            "method_zh": "**问题定义**：现有方法在利用视频数据学习机器人技能时面临挑战。视频生成模型擅长视觉预测，但难以转化为具体的机器人动作指令。另一方面，基于潜在动作的模型虽然能将视频与动作对齐，但通常只能处理单步动作，缺乏长期规划能力。因此，如何从无动作视频中学习可用于机器人长期规划的技能是一个关键问题。\\n\\n**核心思路**：本文的核心思路是通过光流作为中间表示，学习一个潜在的技能空间。光流能够捕捉视频中的运动信息，并且与机器人动作具有一定的相关性。通过在光流表示的潜在空间中学习技能，可以更容易地将视频中的运动模式转化为机器人可以执行的动作序列。这种方法旨在弥合视频生成模型和机器人动作执行之间的差距，实现从视频数据中学习可复用的技能。\\n\\n**技术框架**：SOF框架包含以下主要模块：1) 光流估计模块，用于从视频帧中提取光流信息；2) 技能编码器，将光流信息编码到潜在技能空间中；3) 技能解码器，将潜在技能解码为光流序列；4) 技能规划器，用于在潜在技能空间中进行长期规划，生成技能序列；5) 动作执行器，将技能序列转化为机器人动作指令。整个流程首先从视频中提取光流，然后通过编码器学习潜在技能，再利用规划器生成技能序列，最后通过执行器转化为机器人动作。\\n\\n**关键创新**：最重要的技术创新点在于使用光流作为中间表示来学习潜在技能空间。与直接从像素空间学习技能相比，光流能够更好地捕捉视频中的运动信息，并且与机器人动作具有更强的相关性。此外，SOF框架还引入了技能规划器，能够在潜在技能空间中进行长期规划，从而实现更复杂的任务。\\n\\n**关键设计**：SOF框架的关键设计包括：1) 使用预训练的光流估计网络提取光流信息；2) 使用变分自编码器（VAE）学习潜在技能空间，并引入KL散度损失来约束潜在空间的分布；3) 使用循环神经网络（RNN）作为技能解码器，生成光流序列；4) 使用基于模型的规划算法，如模型预测控制（MPC），在潜在技能空间中进行长期规划；5) 使用逆运动学方法将光流序列转化为机器人动作指令。",
            "application_zh": "该研究成果可应用于各种机器人任务，例如家庭服务机器人、工业机器人和自动驾驶汽车。通过从大量无动作视频中学习技能，机器人可以更好地理解周围环境，并执行复杂的任务，例如物体操作、导航和人机交互。该技术还可以用于机器人技能的迁移学习，将从一个任务中学到的技能应用到新的任务中，从而提高机器人的泛化能力。",
            "highlight_zh": "实验结果表明，SOF框架在多任务和长时程任务中均取得了显著的性能提升。例如，在物体操作任务中，SOF框架能够成功地从视频中学习到抓取、放置等技能，并将其应用于新的物体操作任务中。与基线方法相比，SOF框架在任务成功率和执行效率方面均有明显提高。具体提升幅度未知，需查阅论文。",
            "tags_zh": [
                "机器人技能学习",
                "无动作视频",
                "光流",
                "潜在空间",
                "技能规划",
                "机器人控制",
                "视觉学习"
            ],
            "_index": 87,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "DETACH : Decomposed Spatio-Temporal Alignment for Exocentric Video and Ambient Sensors with Staged Learning",
            "authors": [
                "Junho Yoon",
                "Jaemo Jung",
                "Hyunju Kim",
                "Dongman Lee"
            ],
            "arxiv_id": "2512.20409v1",
            "summary": "Aligning egocentric video with wearable sensors have shown promise for human action recognition, but face practical limitations in user discomfort, privacy concerns, and scalability. We explore exocentric video with ambient sensors as a non-intrusive, scalable alternative. While prior egocentric-wearable works predominantly adopt Global Alignment by encoding entire sequences into unified representations, this approach fails in exocentric-ambient settings due to two problems: (P1) inability to capture local details such as subtle motions, and (P2) over-reliance on modality-invariant temporal patterns, causing misalignment between actions sharing similar temporal patterns with different spatio-semantic contexts. To resolve these problems, we propose DETACH, a decomposed spatio-temporal framework. This explicit decomposition preserves local details, while our novel sensor-spatial features discovered via online clustering provide semantic grounding for context-aware alignment. To align the decomposed features, our two-stage approach establishes spatial correspondence through mutual supervision, then performs temporal alignment via a spatial-temporal weighted contrastive loss that adaptively handles easy negatives, hard negatives, and false negatives. Comprehensive experiments with downstream tasks on Opportunity++ and HWU-USP datasets demonstrate substantial improvements over adapted egocentric-wearable baselines.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20409v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "提出DETACH框架，通过解耦时空对齐解决外中心视频与环境传感器融合问题",
            "summary_zh": "将以自我为中心的视频与可穿戴传感器对齐已显示出在人类行为识别方面的潜力，但面临用户不适、隐私问题和可扩展性等实际限制。我们探索以外中心视频与环境传感器作为一种非侵入式、可扩展的替代方案。以往的以自我为中心的可穿戴设备研究主要采用全局对齐，通过将整个序列编码为统一的表示，但由于两个问题，这种方法在外中心-环境设置中失败：（P1）无法捕捉局部细节，例如细微的动作，以及（P2）过度依赖模态不变的时间模式，导致在具有相似时间模式但具有不同空间语义上下文的动作之间出现错位。为了解决这些问题，我们提出了DETACH，一个解耦的时空框架。这种显式分解保留了局部细节，而我们通过在线聚类发现的新型传感器-空间特征为上下文感知的对齐提供了语义基础。为了对齐分解的特征，我们的两阶段方法通过相互监督建立空间对应关系，然后通过空间-时间加权对比损失执行时间对齐，该损失自适应地处理简单负样本、困难负样本和假负样本。在Opportunity++和HWU-USP数据集上进行的下游任务的综合实验表明，与改编的以自我为中心的可穿戴设备基线相比，性能有了显著提高。",
            "intro_zh": [
                "现有方法难以捕捉外中心视频与环境传感器融合中的局部细节和空间语义信息。",
                "DETACH框架通过解耦时空特征，并利用在线聚类发现传感器-空间特征，实现上下文感知的对齐。",
                "在Opportunity++和HWU-USP数据集上的实验表明，DETACH显著优于现有方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决外中心视频与环境传感器融合中的对齐问题。现有方法，特别是那些从以自我为中心的可穿戴设备研究中改编的方法，通常采用全局对齐策略，即将整个序列编码成统一的表示。这种方法的痛点在于：1) 无法捕捉到细微的局部动作细节；2) 过度依赖时间模式，导致具有相似时间模式但空间语义不同的动作之间产生错位。\\n\\n**核心思路**：论文的核心思路是将时空对齐问题解耦，分别处理空间和时间上的对齐。通过显式地分解时空特征，保留了局部细节。此外，利用在线聚类方法发现传感器-空间特征，为上下文感知的对齐提供了语义基础。这种解耦和语义增强的设计旨在克服现有全局对齐方法的局限性。\\n\\n**技术框架**：DETACH框架包含两个主要阶段：空间对齐和时间对齐。首先，通过在线聚类提取传感器-空间特征。然后，利用互监督机制建立视频帧和传感器特征之间的空间对应关系。最后，使用空间-时间加权对比损失进行时间对齐，该损失能够自适应地处理不同类型的负样本（简单负样本、困难负样本和假负样本）。\\n\\n**关键创新**：DETACH的关键创新在于其解耦的时空对齐框架和自适应的对比学习损失。与以往的全局对齐方法不同，DETACH显式地分解了时空特征，从而能够更好地捕捉局部细节和空间语义信息。此外，自适应的对比学习损失能够更有效地学习到鲁棒的时空表示。\\n\\n**关键设计**：DETACH的关键设计包括：1) 使用在线聚类方法提取传感器-空间特征，这使得模型能够适应不同的环境和传感器配置；2) 采用互监督机制进行空间对齐，这能够有效地建立视频帧和传感器特征之间的对应关系；3) 设计空间-时间加权对比损失，该损失能够自适应地调整不同负样本的权重，从而提高模型的学习效率和泛化能力。",
            "application_zh": "该研究成果可应用于智能家居、智能工厂、医疗健康等领域。例如，通过融合外中心视频和环境传感器数据，可以实现对老年人跌倒的自动检测和预警，或者对工厂生产线上工人操作行为的监控和分析，从而提高生产效率和安全性。该研究为构建更加智能和安全的监控系统提供了新的思路。",
            "highlight_zh": "在Opportunity++和HWU-USP数据集上的实验结果表明，DETACH框架显著优于现有的以自我为中心的可穿戴设备基线方法。具体而言，DETACH在两个数据集上的下游任务中均取得了显著的性能提升，证明了其在外中心视频与环境传感器融合方面的有效性。实验结果验证了解耦时空对齐和自适应对比学习损失的优势。",
            "tags_zh": [
                "外中心视频",
                "环境传感器",
                "时空对齐",
                "对比学习",
                "行为识别"
            ],
            "_index": 88,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20409v1/Figure/Intro_1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20409v1/Figure/Intro_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20409v1/Figure/Method_Architecture.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Anisotropic Green Coordinates",
            "authors": [
                "Dong Xiao",
                "Renjie Chen",
                "Bailin Deng"
            ],
            "arxiv_id": "2512.20386v1",
            "summary": "We live in a world filled with anisotropy, a ubiquitous characteristic of both natural and engineered systems. In this study, we concentrate on space deformation and introduce anisotropic Green coordinates, which provide versatile effects for cage-based and variational deformations in both two and three dimensions. The anisotropic Green coordinates are derived from the anisotropic Laplacian equation $\\nabla\\cdot(\\mathbf{A}\\nabla u)=0$, where $\\mathbf{A}$ is a symmetric positive definite matrix. This equation belongs to the class of constant-coefficient second-order elliptic equations, exhibiting properties analogous to the Laplacian equation but incorporating the matrix $\\mathbf{A}$ to characterize anisotropic behavior. Based on this equation, we establish the boundary integral formulation, which is subsequently discretized to derive anisotropic Green coordinates defined on the vertices and normals of oriented simplicial cages. The deformation satisfies basic properties such as linear reproduction and translation invariance, and has closed-form expressions for both 2D and 3D scenarios. We also offer intuitive geometric interpretations of this method. Furthermore, our approach computes the gradient and Hessian of the deformation coordinates and employs the local-global optimization framework to facilitate variational shape deformation, enabling flexible shape manipulation while achieving as-rigid-as-possible shape deformation. Experimental results demonstrate that anisotropic Green coordinates offer versatile and diverse deformation options, providing artists with enhanced flexibility and introducing a novel perspective on spatial deformation.",
            "categories": [
                "cs.GR"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20386v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出各向异性绿色坐标以解决空间变形问题",
            "summary_zh": "在自然和工程系统中，各向异性是一种普遍特征。本研究集中于空间变形，提出各向异性绿色坐标，提供了在二维和三维中基于笼体和变分变形的多样化效果。这些坐标源自各向异性拉普拉斯方程，结合了对称正定矩阵，以表征各向异性行为。通过建立边界积分公式并进行离散化，定义了在有向单纯形笼体的顶点和法线上的各向异性绿色坐标。该变形方法满足线性重现和平移不变性，并提供了二维和三维场景的封闭形式表达。实验结果表明，各向异性绿色坐标为艺术家提供了更大的灵活性，并为空间变形引入了新的视角。",
            "intro_zh": [
                "现有的空间变形方法在处理各向异性特征时存在局限，难以实现灵活的形状操控。",
                "论文提出了基于各向异性拉普拉斯方程的各向异性绿色坐标，能够有效地进行笼体和变分变形。",
                "实验结果显示，该方法在二维和三维变形中提供了多样化的选项，显著提升了形状变形的灵活性。"
            ],
            "method_zh": "**问题定义**：本研究旨在解决现有空间变形方法在处理各向异性特征时的不足，尤其是在灵活性和效果多样性方面的挑战。\\n\\n**核心思路**：提出的各向异性绿色坐标基于各向异性拉普拉斯方程，通过引入对称正定矩阵来表征各向异性行为，从而实现更灵活的形状变形。\\n\\n**技术框架**：整体方法包括边界积分公式的建立、离散化处理以及在有向单纯形笼体的顶点和法线上的坐标定义，确保变形满足线性重现和平移不变性。\\n\\n**关键创新**：最重要的创新在于引入各向异性绿色坐标，使得变形方法能够在二维和三维场景中灵活应用，区别于传统方法的局限性。\\n\\n**关键设计**：在技术细节上，采用了局部-全局优化框架来计算变形坐标的梯度和海森矩阵，确保变形过程尽可能保持刚性，同时实现灵活的形状操控。",
            "application_zh": "该研究的潜在应用领域包括计算机图形学、动画制作、虚拟现实等，能够为艺术家和设计师提供更灵活的工具来实现复杂的形状变形。未来，该方法可能在游戏开发和影视特效制作中发挥重要作用，提升视觉效果和用户体验。",
            "highlight_zh": "实验结果表明，采用各向异性绿色坐标的变形方法在二维和三维场景中均表现出显著的灵活性和多样性，相较于传统方法，变形效果的自然度和艺术性得到了提升，具体性能数据尚未披露。",
            "tags_zh": [
                "各向异性变形",
                "绿色坐标",
                "空间变形",
                "计算机图形学",
                "虚拟现实",
                "动画制作",
                "形状操控"
            ],
            "_index": 89,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20386v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20386v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20386v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction",
            "authors": [
                "Hexu Zhao",
                "Xiaoteng Liu",
                "Xiwen Min",
                "Jianhao Huang",
                "Youming Deng",
                "Yanfei Li",
                "Ang Li",
                "Jinyang Li",
                "Aurojit Panda"
            ],
            "arxiv_id": "2512.20017v1",
            "summary": "Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.",
            "categories": [
                "cs.DC",
                "cs.GR"
            ],
            "primary_category": "cs.DC",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "13 pages main text, plus appendix",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20017v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene reconstruction"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Gaian：面向大规模重建，可扩展的基于点的可微渲染通用分布式训练系统",
            "summary_zh": "基于点的可微渲染(PBDR)能够实现高保真3D场景重建，但将PBDR扩展到高分辨率和大型场景需要高效的分布式训练系统。现有的系统与特定的PBDR方法紧密耦合，并且由于较差的数据局部性而遭受严重的通信开销。本文提出Gaian，一个通用的PBDR分布式训练系统。Gaian提供了一个统一的API，该API具有足够的表达能力来支持现有的PBDR方法，同时暴露了丰富的数据访问信息，Gaian利用这些信息来优化局部性并减少通信。通过实现4种PBDR算法来评估Gaian。我们的实现实现了高性能和资源效率：在六个数据集和高达128个GPU上，它减少了高达91%的通信，并将训练吞吐量提高了1.50倍-3.71倍。",
            "intro_zh": [
                "现有PBDR系统难以扩展到高分辨率和大型场景，且与特定方法耦合，数据局部性差导致通信开销大。",
                "Gaian通过统一API支持多种PBDR方法，并利用数据访问信息优化局部性，从而减少通信。",
                "实验表明，Gaian在多个数据集和GPU配置下，显著降低通信量并提升训练吞吐量。"
            ],
            "method_zh": "**问题定义**：论文旨在解决基于点的可微渲染（PBDR）在大规模场景重建中面临的扩展性问题。现有PBDR系统通常与特定算法紧密耦合，缺乏通用性。此外，由于数据局部性差，分布式训练过程中存在大量的通信开销，严重限制了训练效率。\\n\\n**核心思路**：Gaian的核心思路是设计一个通用的分布式训练系统，通过统一的API支持多种PBDR算法，并利用数据访问信息优化数据局部性，从而减少通信开销。这种解耦的设计使得系统更具灵活性和可扩展性。\\n\\n**技术框架**：Gaian系统包含一个统一的API，用于描述不同的PBDR算法。该API暴露了丰富的数据访问信息，例如哪些点需要被哪些GPU访问。Gaian利用这些信息进行数据划分和任务调度，以最大化数据局部性。系统还包含一个通信优化模块，用于减少GPU之间的通信量。\\n\\n**关键创新**：Gaian的关键创新在于其通用性和数据局部性优化。通过统一的API，Gaian可以支持多种PBDR算法，而无需为每种算法单独设计分布式训练系统。通过利用数据访问信息优化数据局部性，Gaian可以显著减少通信开销，提高训练效率。\\n\\n**关键设计**：Gaian的API设计允许用户指定点云数据的划分方式和渲染过程中的数据依赖关系。系统使用一种基于图的优化算法来确定最佳的数据划分方案，以最大化数据局部性。通信优化模块使用诸如梯度累积和异步通信等技术来进一步减少通信开销。损失函数和网络结构取决于具体的PBDR算法，Gaian提供了一个灵活的框架来支持不同的选择。",
            "application_zh": "Gaian可应用于大规模3D场景重建，例如城市建模、自动驾驶、虚拟现实等领域。通过提高PBDR的训练效率，Gaian能够加速这些应用的发展，并降低计算成本。未来，Gaian可以进一步扩展到支持其他类型的可微渲染算法，并应用于更广泛的计算机视觉和图形学任务。",
            "highlight_zh": "实验结果表明，Gaian在六个数据集和高达128个GPU上，相比现有系统，减少了高达91%的通信量，并将训练吞吐量提高了1.50倍-3.71倍。这些结果验证了Gaian的有效性和优越性，表明其能够显著提高大规模PBDR的训练效率。",
            "tags_zh": [
                "可微渲染",
                "分布式训练",
                "点云重建",
                "数据局部性",
                "大规模场景"
            ],
            "_index": 90,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20017v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20017v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20017v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Explainable time-series forecasting with sampling-free SHAP for Transformers",
            "authors": [
                "Matthias Hertel",
                "Sebastian Pütz",
                "Ralf Mikut",
                "Veit Hagenmeyer",
                "Benjamin Schäfer"
            ],
            "arxiv_id": "2512.20514v1",
            "summary": "Time-series forecasts are essential for planning and decision-making in many domains. Explainability is key to building user trust and meeting transparency requirements. Shapley Additive Explanations (SHAP) is a popular explainable AI framework, but it lacks efficient implementations for time series and often assumes feature independence when sampling counterfactuals. We introduce SHAPformer, an accurate, fast and sampling-free explainable time-series forecasting model based on the Transformer architecture. It leverages attention manipulation to make predictions based on feature subsets. SHAPformer generates explanations in under one second, several orders of magnitude faster than the SHAP Permutation Explainer. On synthetic data with ground truth explanations, SHAPformer provides explanations that are true to the data. Applied to real-world electrical load data, it achieves competitive predictive performance and delivers meaningful local and global insights, such as identifying the past load as the key predictor and revealing a distinct model behavior during the Christmas period.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-23",
            "updated": "2025-12-23",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20514v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出SHAPformer，一种基于Transformer的快速、无采样的可解释时间序列预测模型。",
            "summary_zh": "时间序列预测在许多领域对于规划和决策至关重要。可解释性是建立用户信任和满足透明度要求的关键。Shapley Additive Explanations (SHAP) 是一种流行的可解释AI框架，但它缺乏针对时间序列的有效实现，并且在对反事实进行采样时通常假设特征独立性。我们介绍 SHAPformer，这是一种基于 Transformer 架构的准确、快速且无采样的可解释时间序列预测模型。它利用注意力机制操作来进行基于特征子集的预测。SHAPformer 在不到一秒的时间内生成解释，比 SHAP Permutation Explainer 快几个数量级。在具有真实解释的合成数据上，SHAPformer 提供的解释与数据一致。应用于真实世界的电力负荷数据，它实现了有竞争力的预测性能，并提供了有意义的局部和全局见解，例如将过去的负荷识别为关键预测因子，并揭示了圣诞节期间独特的模型行为。",
            "intro_zh": [
                "现有时间序列预测方法缺乏高效的可解释性工具，SHAP等方法计算成本高，且常假设特征独立性。",
                "SHAPformer利用Transformer架构和注意力机制，通过特征子集进行预测，无需采样即可快速生成解释。",
                "实验表明，SHAPformer在合成数据上解释准确，在电力负荷数据上预测性能优异，并能提供有意义的洞见。"
            ],
            "method_zh": "**问题定义**：论文旨在解决时间序列预测模型的可解释性问题。现有的SHAP方法在时间序列数据上计算效率低，并且通常假设特征之间是相互独立的，这与时间序列数据的实际情况不符，导致解释不准确。\\n\\n**核心思路**：论文的核心思路是利用Transformer模型的注意力机制，通过操纵注意力权重来模拟特征子集的影响，从而实现无采样的SHAP值计算。这种方法避免了传统SHAP方法中需要大量采样的过程，显著提高了计算效率。\\n\\n**技术框架**：SHAPformer基于Transformer架构，主要包含以下模块：输入嵌入层、Transformer编码器层、注意力操纵层和预测输出层。输入嵌入层将时间序列数据转换为嵌入向量。Transformer编码器层学习时间序列的特征表示。注意力操纵层通过调整注意力权重来模拟特征子集的影响。预测输出层基于特征表示进行预测。\\n\\n**关键创新**：SHAPformer最重要的创新点在于其无采样的SHAP值计算方法。通过直接操纵Transformer的注意力权重，避免了传统SHAP方法中需要大量采样来估计条件期望的问题，从而实现了快速且准确的可解释性分析。与现有方法相比，SHAPformer不需要进行昂贵的采样过程，因此计算效率更高。\\n\\n**关键设计**：SHAPformer的关键设计包括：(1) 使用标准的Transformer编码器结构来学习时间序列的特征表示；(2) 设计了一种注意力操纵机制，通过屏蔽或调整注意力权重来模拟特征子集的影响；(3) 使用均方误差（MSE）作为预测损失函数，并采用Adam优化器进行模型训练。具体的注意力操纵策略和权重调整方法在论文中有详细描述。",
            "application_zh": "SHAPformer可应用于各种需要可解释时间序列预测的领域，例如电力负荷预测、金融市场分析、供应链管理和医疗健康监测。通过提供对预测结果的解释，SHAPformer可以帮助用户理解模型的决策过程，建立信任，并做出更明智的决策。此外，SHAPformer还可以用于识别关键的影响因素，从而优化资源分配和改进业务流程。",
            "highlight_zh": "SHAPformer在合成数据上能够准确地恢复ground truth解释，证明了其解释的可靠性。在真实世界的电力负荷数据上，SHAPformer实现了与现有模型相当的预测性能，并且解释速度比SHAP Permutation Explainer快几个数量级。此外，SHAPformer还揭示了电力负荷预测中的一些有趣现象，例如过去负荷是关键预测因子，以及圣诞节期间模型行为的特殊性。",
            "tags_zh": [
                "时间序列预测",
                "可解释AI",
                "Transformer",
                "SHAP值",
                "注意力机制",
                "电力负荷预测",
                "无采样"
            ],
            "_index": 91,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20514v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20514v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20514v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        }
    ]
}