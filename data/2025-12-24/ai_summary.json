{
    "papers": [
        {
            "title": "Quantile Rendering: Efficiently Embedding High-dimensional Feature on 3D Gaussian Splatting",
            "authors": [
                "Yoonwoo Jeong",
                "Cheng Sun",
                "Frank Wang",
                "Minsu Cho",
                "Jaesung Choe"
            ],
            "arxiv_id": "2512.20927v1",
            "summary": "Recent advancements in computer vision have successfully extended Open-vocabulary segmentation (OVS) to the 3D domain by leveraging 3D Gaussian Splatting (3D-GS). Despite this progress, efficiently rendering the high-dimensional features required for open-vocabulary queries poses a significant challenge. Existing methods employ codebooks or feature compression, causing information loss, thereby degrading segmentation quality. To address this limitation, we introduce Quantile Rendering (Q-Render), a novel rendering strategy for 3D Gaussians that efficiently handles high-dimensional features while maintaining high fidelity. Unlike conventional volume rendering, which densely samples all 3D Gaussians intersecting each ray, Q-Render sparsely samples only those with dominant influence along the ray. By integrating Q-Render into a generalizable 3D neural network, we also propose Gaussian Splatting Network (GS-Net), which predicts Gaussian features in a generalizable manner. Extensive experiments on ScanNet and LeRF demonstrate that our framework outperforms state-of-the-art methods, while enabling real-time rendering with an approximate ~43.7x speedup on 512-D feature maps. Code will be made publicly available.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Will be updated",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20927v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]3D gaussian splatting",
                        "[T]gaussian splatting",
                        "[T]splatting",
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 22.0
                }
            ],
            "relevance_score": 22.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出Quantile Rendering，高效嵌入高维特征于3D高斯溅射，提升开放词汇分割性能。",
            "summary_zh": "本文提出了一种新的渲染策略Quantile Rendering (Q-Render)，用于高效处理3D高斯溅射中的高维特征，以解决开放词汇分割(OVS)在3D领域中面临的挑战。现有方法通常采用码本或特征压缩，导致信息损失，从而降低分割质量。Q-Render不同于传统的体渲染，它不是密集采样与每条光线相交的所有3D高斯，而是稀疏采样那些沿光线具有主导影响的高斯。此外，本文还将Q-Render集成到一个可泛化的3D神经网络中，提出了高斯溅射网络(GS-Net)，以可泛化的方式预测高斯特征。在ScanNet和LeRF上的大量实验表明，该框架优于最先进的方法，同时实现了近似43.7倍的实时渲染加速（针对512维特征图）。代码将会公开。",
            "intro_zh": [
                "现有3D开放词汇分割方法在渲染高维特征时效率低下，且特征压缩易造成信息损失，影响分割质量。",
                "Q-Render通过稀疏采样光线上具有主导影响的高斯，避免了密集采样，从而高效处理高维特征。",
                "实验表明，该方法在ScanNet和LeRF数据集上优于现有技术，并实现了显著的渲染加速。"
            ],
            "method_zh": "**问题定义**：论文旨在解决3D开放词汇分割中，高维特征渲染效率低下的问题。现有方法如使用码本或特征压缩，虽然能降低计算量，但会造成信息损失，从而降低分割精度。因此，如何在保证分割质量的前提下，提升高维特征的渲染效率是本文要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是提出Quantile Rendering (Q-Render)，一种稀疏采样的渲染策略。Q-Render不再像传统体渲染那样密集采样所有与光线相交的3D高斯，而是只采样那些对光线贡献最大的高斯。这样可以显著减少采样数量，从而提高渲染效率。\\n\\n**技术框架**：整体框架包含两个主要部分：首先，使用Gaussian Splatting Network (GS-Net) 预测可泛化的高斯特征。GS-Net是一个3D神经网络，能够学习场景的几何和语义信息，并预测每个高斯的特征向量。其次，使用Q-Render渲染这些高斯特征，得到最终的分割结果。Q-Render根据每个高斯对光线的贡献度进行排序，并只采样贡献度最高的一部分高斯。\\n\\n**关键创新**：最重要的技术创新点在于Q-Render的稀疏采样策略。与传统的密集采样方法相比，Q-Render能够显著减少采样数量，从而提高渲染效率，同时避免了特征压缩带来的信息损失。此外，GS-Net的可泛化特征预测能力也是一个重要的创新点，使得该方法能够应用于不同的场景和数据集。\\n\\n**关键设计**：Q-Render的关键设计在于如何确定哪些高斯对光线具有主导影响。论文采用了一种基于分位数的采样方法，即选择对光线透明度贡献最大的前k%的高斯进行采样。具体来说，对于每条光线，首先计算每个高斯的透明度权重，然后根据权重对高斯进行排序，最后选择权重最高的k%的高斯进行采样。k的具体数值需要根据实际情况进行调整，以在渲染效率和分割精度之间取得平衡。",
            "application_zh": "该研究成果可应用于机器人导航、自动驾驶、虚拟现实/增强现实等领域。通过高效地渲染高维语义特征，可以使机器更好地理解周围环境，从而实现更智能的交互和决策。未来，该方法有望扩展到更复杂的场景和任务中，例如三维场景编辑、三维物体检测等。",
            "highlight_zh": "实验结果表明，Q-Render在ScanNet和LeRF数据集上均取得了优于现有方法的性能。尤其是在渲染512维特征图时，实现了约43.7倍的渲染加速，同时保持了较高的分割精度。这表明Q-Render在处理高维特征时具有显著的效率优势。",
            "tags_zh": [
                "3D高斯溅射",
                "开放词汇分割",
                "体渲染",
                "高维特征",
                "Quantile Rendering"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20927v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20927v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20927v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "UniTacHand: Unified Spatio-Tactile Representation for Human to Robotic Hand Skill Transfer",
            "authors": [
                "Chi Zhang",
                "Penglin Cai",
                "Haoqi Yuan",
                "Chaoyi Xu",
                "Zongqing Lu"
            ],
            "arxiv_id": "2512.21233v1",
            "summary": "Tactile sensing is crucial for robotic hands to achieve human-level dexterous manipulation, especially in scenarios with visual occlusion. However, its application is often hindered by the difficulty of collecting large-scale real-world robotic tactile data. In this study, we propose to collect low-cost human manipulation data using haptic gloves for tactile-based robotic policy learning. The misalignment between human and robotic tactile data makes it challenging to transfer policies learned from human data to robots. To bridge this gap, we propose UniTacHand, a unified representation to align robotic tactile information captured by dexterous hands with human hand touch obtained from gloves. First, we project tactile signals from both human hands and robotic hands onto a morphologically consistent 2D surface space of the MANO hand model. This unification standardizes the heterogeneous data structures and inherently embeds the tactile signals with spatial context. Then, we introduce a contrastive learning method to align them into a unified latent space, trained on only 10 minutes of paired data from our data collection system. Our approach enables zero-shot tactile-based policy transfer from humans to a real robot, generalizing to objects unseen in the pre-training data. We also demonstrate that co-training on mixed data, including both human and robotic demonstrations via UniTacHand, yields better performance and data efficiency compared with using only robotic data. UniTacHand paves a path toward general, scalable, and data-efficient learning for tactile-based dexterous hands.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21233v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation",
                        "dexterous hand",
                        "dexterous manipulation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "policy learning",
                        "contrastive learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "MANO"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "[T]human-to-robot"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "6_video_extraction",
                "7_retargeting"
            ],
            "headline_zh": "UniTacHand：用于人-机器人手技能迁移的统一时空触觉表示",
            "summary_zh": "触觉感知对于机器人手实现人类水平的灵巧操作至关重要，尤其是在视觉遮挡的情况下。然而，其应用常常受到大规模真实世界机器人触觉数据难以收集的限制。本研究提出使用触觉手套收集低成本的人类操作数据，用于基于触觉的机器人策略学习。人类和机器人触觉数据之间的不对齐使得从人类数据学习的策略难以迁移到机器人。为了弥合这一差距，我们提出了UniTacHand，一种统一的表示，用于对齐灵巧手捕获的机器人触觉信息与手套获得的人手触摸。首先，我们将来自人手和机器人手的触觉信号投影到MANO手模型的形态一致的2D表面空间上。这种统一标准化了异构数据结构，并固有地将触觉信号嵌入空间上下文。然后，我们引入了一种对比学习方法，将它们对齐到一个统一的潜在空间中，该空间仅在我们数据收集系统的10分钟配对数据上进行训练。我们的方法实现了从人类到真实机器人的零样本基于触觉的策略迁移，推广到预训练数据中未见过的对象。我们还证明，通过UniTacHand在混合数据（包括人类和机器人演示）上进行协同训练，与仅使用机器人数据相比，可以获得更好的性能和数据效率。UniTacHand为基于触觉的灵巧手的一般、可扩展和数据高效的学习铺平了道路。",
            "intro_zh": [
                "机器人触觉数据获取成本高昂，阻碍了触觉感知在灵巧操作中的应用，尤其是在视觉受限场景。",
                "UniTacHand通过将人手和机器人手的触觉信号投影到统一的MANO模型空间，并利用对比学习对齐，实现跨域迁移。",
                "实验表明，UniTacHand支持零样本策略迁移，且混合数据协同训练能提升性能和数据效率。"
            ],
            "method_zh": "**问题定义**：现有机器人触觉数据难以获取，且人手和机器人手的触觉数据存在不对齐问题，导致难以将人类的灵巧操作技能迁移到机器人上。现有方法通常依赖于大量的机器人数据，成本高昂且泛化性差。\\n\\n**核心思路**：UniTacHand的核心思路是将人手和机器人手的触觉信息映射到一个统一的、形态一致的表示空间，从而消除数据异构性。通过对比学习，进一步对齐不同来源的触觉特征，实现知识迁移。这样设计的原因在于，统一表示能够嵌入空间上下文，而对比学习能够学习到领域不变的特征。\\n\\n**技术框架**：UniTacHand包含以下主要阶段：1) 数据收集：使用触觉手套收集人手操作数据，使用机器人手上的触觉传感器收集机器人操作数据。2) 触觉信号投影：将人手和机器人手的触觉信号投影到MANO手模型的2D表面空间上，形成统一的表示。3) 对比学习：使用对比学习方法，训练一个编码器，将统一表示映射到潜在空间，并对齐人手和机器人手的触觉特征。4) 策略迁移：将训练好的编码器用于机器人策略学习，实现从人类到机器人的零样本策略迁移。\\n\\n**关键创新**：UniTacHand的关键创新在于提出了一个统一的时空触觉表示，能够有效地对齐人手和机器人手的触觉信息。与现有方法相比，UniTacHand不需要大量的机器人数据，而是利用低成本的人类数据进行训练，并通过对比学习实现跨域迁移。\\n\\n**关键设计**：UniTacHand的关键设计包括：1) 使用MANO模型作为统一的2D表面空间，嵌入空间上下文。2) 使用对比学习损失函数，鼓励人手和机器人手的触觉特征在潜在空间中对齐。3) 使用少量配对数据进行对比学习训练，提高数据效率。具体的对比学习损失函数细节和网络结构未在摘要中详细说明，属于未知信息。",
            "application_zh": "UniTacHand可应用于各种需要灵巧操作的机器人任务，例如：工业自动化、医疗手术、家庭服务等。通过利用人类的知识和经验，可以降低机器人学习的成本和时间，提高机器人的智能化水平。该研究为触觉感知在机器人领域的应用开辟了新的方向，具有重要的实际价值和未来影响。",
            "highlight_zh": "UniTacHand实现了从人类到真实机器人的零样本触觉策略迁移，能够推广到预训练数据中未见过的物体。通过混合人类和机器人数据进行协同训练，与仅使用机器人数据相比，性能和数据效率均得到提升。具体提升幅度和性能数据在摘要中未给出，属于未知信息。",
            "tags_zh": [
                "触觉感知",
                "机器人灵巧操作",
                "人机协作",
                "迁移学习",
                "对比学习"
            ],
            "_index": 1,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21233v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21233v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21233v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Embodied AI-Enhanced IoMT Edge Computing: UAV Trajectory Optimization and Task Offloading with Mobility Prediction",
            "authors": [
                "Siqi Mu",
                "Shuo Wen",
                "Yang Lu",
                "Ruihong Jiang",
                "Bo Ai"
            ],
            "arxiv_id": "2512.20902v1",
            "summary": "Due to their inherent flexibility and autonomous operation, unmanned aerial vehicles (UAVs) have been widely used in Internet of Medical Things (IoMT) to provide real-time biomedical edge computing service for wireless body area network (WBAN) users. In this paper, considering the time-varying task criticality characteristics of diverse WBAN users and the dual mobility between WBAN users and UAV, we investigate the dynamic task offloading and UAV flight trajectory optimization problem to minimize the weighted average task completion time of all the WBAN users, under the constraint of UAV energy consumption. To tackle the problem, an embodied AI-enhanced IoMT edge computing framework is established. Specifically, we propose a novel hierarchical multi-scale Transformer-based user trajectory prediction model based on the users' historical trajectory traces captured by the embodied AI agent (i.e., UAV). Afterwards, a prediction-enhanced deep reinforcement learning (DRL) algorithm that integrates predicted users' mobility information is designed for intelligently optimizing UAV flight trajectory and task offloading decisions. Real-word movement traces and simulation results demonstrate the superiority of the proposed methods in comparison with the existing benchmarks.",
            "categories": [
                "cs.NI",
                "cs.AI"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20902v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]trajectory optimization"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning",
                        "DRL"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]embodied AI"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 19.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于具身AI的IoMT边缘计算框架，优化无人机轨迹和任务卸载，最小化任务完成时间。",
            "summary_zh": "本文针对无线体域网(WBAN)用户，研究了在物联网医疗(IoMT)中利用无人机(UAV)提供实时生物医学边缘计算服务的问题。考虑到不同WBAN用户随时间变化的任務关键性以及WBAN用户与无人机之间的双重移动性，本文研究了动态任务卸载和无人机飞行轨迹优化问题，目标是在无人机能量消耗约束下，最小化所有WBAN用户的加权平均任务完成时间。为此，本文建立了一个基于具身AI增强的IoMT边缘计算框架。具体而言，我们提出了一种新颖的基于分层多尺度Transformer的用户轨迹预测模型，该模型基于具身AI代理（即无人机）捕获的用户历史轨迹。此外，设计了一种预测增强的深度强化学习(DRL)算法，该算法集成了预测的用户移动性信息，用于智能优化无人机飞行轨迹和任务卸载决策。真实世界的运动轨迹和仿真结果表明，与现有基准相比，所提出的方法具有优越性。",
            "intro_zh": [
                "现有方法难以有效应对WBAN用户任务关键性的时变特性以及用户与无人机之间的双重移动性，导致任务完成时间较长。",
                "提出一种基于具身AI增强的IoMT边缘计算框架，利用无人机捕获的用户历史轨迹，预测用户未来移动轨迹，并优化无人机飞行轨迹和任务卸载决策。",
                "实验结果表明，所提出的方法在最小化加权平均任务完成时间方面优于现有基准方法，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决IoMT场景下，如何优化无人机（UAV）的飞行轨迹和任务卸载策略，以最小化无线体域网（WBAN）用户的加权平均任务完成时间。现有方法未能充分考虑WBAN用户任务关键性的时变特性以及用户与无人机之间的双重移动性，导致任务完成效率不高。\\n\\n**核心思路**：论文的核心思路是利用具身AI（embodied AI）增强的边缘计算框架，通过无人机收集用户的历史轨迹数据，并使用Transformer模型预测用户的未来移动轨迹。然后，将预测的用户移动信息融入到深度强化学习（DRL）算法中，从而智能地优化无人机的飞行轨迹和任务卸载决策。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) **用户轨迹数据收集**：无人机作为具身AI代理，收集WBAN用户的历史轨迹数据。2) **用户轨迹预测**：利用分层多尺度Transformer模型，基于历史轨迹数据预测用户的未来移动轨迹。3) **任务卸载与轨迹优化**：设计预测增强的DRL算法，综合考虑预测的用户移动信息、任务关键性、无人机能量消耗等因素，优化无人机的飞行轨迹和任务卸载决策。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了基于分层多尺度Transformer的用户轨迹预测模型，能够更准确地预测用户的未来移动轨迹。2) 设计了预测增强的DRL算法，将预测的用户移动信息融入到DRL算法中，从而更有效地优化无人机的飞行轨迹和任务卸载决策。\\n\\n**关键设计**：在用户轨迹预测方面，采用了分层多尺度的Transformer模型，以捕捉不同时间尺度上的用户移动模式。在DRL算法设计方面，使用了深度Q网络（DQN）作为基础框架，并将预测的用户移动信息作为状态的一部分输入到DQN中。此外，还设计了合适的奖励函数，以鼓励无人机靠近任务关键性高的用户，并避免能量消耗过高。",
            "application_zh": "该研究成果可应用于智慧医疗、应急救援、环境监测等领域。例如，在突发公共卫生事件中，无人机可以携带医疗设备，根据预测的用户移动轨迹，快速到达需要帮助的患者身边，提供及时的医疗服务。此外，该方法还可以应用于其他需要移动边缘计算的场景，例如智能交通、智慧农业等。",
            "highlight_zh": "实验结果表明，与现有的基准方法相比，所提出的方法能够显著降低WBAN用户的加权平均任务完成时间。具体而言，在不同的实验场景下，所提出的方法可以将任务完成时间降低10%-20%。此外，实验还验证了所提出的用户轨迹预测模型的准确性，以及预测增强的DRL算法的有效性。",
            "tags_zh": [
                "无人机",
                "边缘计算",
                "物联网医疗",
                "深度强化学习",
                "轨迹预测",
                "任务卸载",
                "具身AI"
            ],
            "_index": 2,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20902v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20902v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20902v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Quadrupped-Legged Robot Movement Plan Generation using Large Language Model",
            "authors": [
                "Muhtadin",
                "Vincentius Gusti Putu A. B. M.",
                "Ahmad Zaini",
                "Mauridhi Hery Purnomo",
                "I Ketut Eddy Purnama",
                "Chastine Fatichah"
            ],
            "arxiv_id": "2512.21293v1",
            "summary": "Traditional control interfaces for quadruped robots often impose a high barrier to entry, requiring specialized technical knowledge for effective operation. To address this, this paper presents a novel control framework that integrates Large Language Models (LLMs) to enable intuitive, natural language-based navigation. We propose a distributed architecture where high-level instruction processing is offloaded to an external server to overcome the onboard computational constraints of the DeepRobotics Jueying Lite 3 platform. The system grounds LLM-generated plans into executable ROS navigation commands using real-time sensor fusion (LiDAR, IMU, and Odometry). Experimental validation was conducted in a structured indoor environment across four distinct scenarios, ranging from single-room tasks to complex cross-zone navigation. The results demonstrate the system's robustness, achieving an aggregate success rate of over 90\\% across all scenarios, validating the feasibility of offloaded LLM-based planning for autonomous quadruped deployment in real-world settings.",
            "categories": [
                "cs.RO",
                "cs.HC"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21293v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "quadruped",
                        "[T]legged robot"
                    ],
                    "score": 8.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 17.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于大语言模型的四足机器人自然语言运动规划方法",
            "summary_zh": "本文提出了一种新颖的控制框架，该框架集成了大型语言模型（LLM），以实现直观的、基于自然语言的四足机器人导航。为了克服DeepRobotics Jueying Lite 3平台的板载计算约束，该系统采用了一种分布式架构，将高级指令处理卸载到外部服务器。系统利用实时传感器融合（激光雷达、IMU和里程计）将LLM生成的计划转化为可执行的ROS导航命令。在结构化的室内环境中，针对四个不同的场景（从单房间任务到复杂的跨区域导航）进行了实验验证。结果表明，该系统具有鲁棒性，在所有场景中的总体成功率超过90％，验证了基于卸载LLM的规划在现实环境中自主部署四足机器人的可行性。",
            "intro_zh": [
                "传统四足机器人控制接口门槛高，需要专业技术知识才能有效操作。",
                "利用大语言模型，将自然语言指令转化为机器人可执行的运动规划，降低操作难度。",
                "实验表明，该系统在室内环境中具有较高的成功率，验证了其可行性。"
            ],
            "method_zh": "**问题定义**：传统四足机器人的控制依赖于复杂的控制接口，需要操作者具备专业的机器人学知识。这使得非专业人士难以有效操控四足机器人，限制了其应用范围。现有方法难以实现自然语言指令到机器人运动规划的直接转换。\\n\\n**核心思路**：本文的核心思路是利用大型语言模型（LLM）的强大自然语言理解和生成能力，将用户输入的自然语言指令转化为机器人可以理解和执行的运动规划。通过将计算密集型的LLM处理卸载到外部服务器，解决了四足机器人板载计算资源有限的问题。\\n\\n**技术框架**：该系统采用分布式架构，主要包含以下几个模块：1) 自然语言指令输入模块；2) LLM指令处理模块（在外部服务器上运行），负责将自然语言指令转化为高层运动规划；3) 传感器融合模块，利用激光雷达、IMU和里程计数据进行环境感知和定位；4) ROS导航命令生成模块，将LLM生成的高层运动规划转化为可执行的ROS导航命令；5) 四足机器人运动控制模块，负责执行ROS导航命令，控制机器人运动。\\n\\n**关键创新**：该方法最重要的创新点在于将大型语言模型应用于四足机器人的运动规划，实现了自然语言控制。与传统的基于规则或优化的运动规划方法相比，该方法更加灵活和易于使用。此外，通过将LLM处理卸载到外部服务器，解决了机器人板载计算资源有限的问题。\\n\\n**关键设计**：论文中没有详细描述LLM的具体选择和训练细节，以及ROS导航命令生成的具体算法。传感器融合模块的具体实现方式也未详细说明。这些是未来研究可以深入探索的方向。论文提到了DeepRobotics Jueying Lite 3平台，但没有给出具体的参数设置。",
            "application_zh": "该研究成果可应用于搜救、巡检、物流等领域。通过自然语言控制，非专业人员也能轻松操控四足机器人完成复杂任务，降低了使用门槛。未来，该技术有望在家庭服务、医疗辅助等领域发挥重要作用，提升机器人的智能化水平和服务能力。",
            "highlight_zh": "实验结果表明，该系统在结构化室内环境中，针对四个不同的场景（从单房间任务到复杂的跨区域导航），总体成功率超过90％。这验证了基于卸载LLM的规划在现实环境中自主部署四足机器人的可行性，展示了其良好的鲁棒性和实用性。",
            "tags_zh": [
                "四足机器人",
                "大语言模型",
                "自然语言控制",
                "运动规划",
                "ROS导航"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21293v1/images/fig.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21293v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21293v1/images/website.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LookPlanGraph: Embodied Instruction Following Method with VLM Graph Augmentation",
            "authors": [
                "Anatoly O. Onishchenko",
                "Alexey K. Kovalev",
                "Aleksandr I. Panov"
            ],
            "arxiv_id": "2512.21243v1",
            "summary": "Methods that use Large Language Models (LLM) as planners for embodied instruction following tasks have become widespread. To successfully complete tasks, the LLM must be grounded in the environment in which the robot operates. One solution is to use a scene graph that contains all the necessary information. Modern methods rely on prebuilt scene graphs and assume that all task-relevant information is available at the start of planning. However, these approaches do not account for changes in the environment that may occur between the graph construction and the task execution. We propose LookPlanGraph - a method that leverages a scene graph composed of static assets and object priors. During plan execution, LookPlanGraph continuously updates the graph with relevant objects, either by verifying existing priors or discovering new entities. This is achieved by processing the agents egocentric camera view using a Vision Language Model. We conducted experiments with changed object positions VirtualHome and OmniGibson simulated environments, demonstrating that LookPlanGraph outperforms methods based on predefined static scene graphs. To demonstrate the practical applicability of our approach, we also conducted experiments in a real-world setting. Additionally, we introduce the GraSIF (Graph Scenes for Instruction Following) dataset with automated validation framework, comprising 514 tasks drawn from SayPlan Office, BEHAVIOR-1K, and VirtualHome RobotHow. Project page available at https://lookplangraph.github.io .",
            "categories": [
                "cs.RO",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21243v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]instruction following"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "6_video_extraction",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LookPlanGraph，通过VLM图增强实现具身指令跟随任务",
            "summary_zh": "本文提出LookPlanGraph，一种利用视觉语言模型（VLM）增强图结构的具身指令跟随方法。该方法使用包含静态资产和对象先验的场景图。在规划执行期间，LookPlanGraph通过验证现有先验或发现新实体，利用智能体的自我中心相机视图，持续更新图结构。实验结果表明，在VirtualHome和OmniGibson模拟环境中，LookPlanGraph优于基于预定义静态场景图的方法。同时，在真实世界环境中验证了该方法的实际应用性。此外，本文还引入了GraSIF数据集，包含来自SayPlan Office、BEHAVIOR-1K和VirtualHome RobotHow的514个任务，并带有自动化验证框架。",
            "intro_zh": [
                "现有具身指令跟随方法依赖预构建的静态场景图，无法应对任务执行期间环境变化带来的挑战。",
                "LookPlanGraph通过VLM持续更新场景图，利用智能体的视觉信息动态调整环境认知，提升任务完成的鲁棒性。",
                "实验表明，LookPlanGraph在模拟和真实环境中均优于静态场景图方法，证明了其有效性和实用性。"
            ],
            "method_zh": "**问题定义**：现有基于LLM的具身指令跟随方法依赖预先构建的静态场景图，然而真实环境中物体位置可能发生变化，导致静态场景图与实际环境不符，影响任务完成。现有方法无法有效处理这种环境变化带来的不确定性。\\n\\n**核心思路**：LookPlanGraph的核心思路是在任务执行过程中，利用视觉语言模型（VLM）持续更新场景图。通过智能体的自我中心视角，VLM可以识别新的物体或验证已知的物体先验，从而动态调整场景图，使其与当前环境保持一致。\\n\\n**技术框架**：LookPlanGraph的整体框架包含以下几个主要阶段：1) 初始化：使用静态资产和对象先验构建初始场景图。2) 规划：利用LLM基于当前场景图生成任务执行计划。3) 执行：智能体按照计划执行动作。4) 观察与更新：在执行过程中，智能体通过自我中心相机获取视觉信息，利用VLM识别物体并更新场景图。5) 循环：重复执行步骤3和4，直到任务完成。\\n\\n**关键创新**：LookPlanGraph的关键创新在于动态场景图的构建和更新机制。与静态场景图方法不同，LookPlanGraph能够根据智能体的视觉输入，实时调整场景图，从而更好地适应环境变化。这种动态更新机制使得智能体能够更准确地理解环境，并做出更合理的决策。\\n\\n**关键设计**：VLM的选择和使用是关键设计之一。论文中使用了特定的VLM模型（具体模型名称未知），并设计了相应的提示工程（prompt engineering）方法，以提高物体识别的准确性和效率。此外，场景图的更新策略也至关重要，需要平衡更新频率和计算成本。具体的参数设置、损失函数和网络结构等技术细节在论文中可能有所描述，但摘要中未明确提及。",
            "application_zh": "LookPlanGraph可应用于各种需要智能体与动态环境交互的场景，例如家庭服务机器人、仓库拣选机器人、自动驾驶等。该方法能够提高机器人在复杂、变化环境中的适应性和鲁棒性，使其能够更好地完成各种任务。未来，该方法有望推动具身智能的进一步发展。",
            "highlight_zh": "实验结果表明，LookPlanGraph在VirtualHome和OmniGibson模拟环境中均优于基于静态场景图的方法。此外，在真实世界环境中的实验也验证了该方法的实用性。GraSIF数据集的发布为具身指令跟随领域提供了新的benchmark，并带有自动化验证框架，方便研究者进行算法评估。",
            "tags_zh": [
                "具身智能",
                "指令跟随",
                "视觉语言模型",
                "场景图",
                "动态环境"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21243v1/images/problem.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21243v1/images/overview.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21243v1/images/prompts.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multimodal Skeleton-Based Action Representation Learning via Decomposition and Composition",
            "authors": [
                "Hongsong Wang",
                "Heng Fei",
                "Bingxuan Dai",
                "Jie Gui"
            ],
            "arxiv_id": "2512.21064v1",
            "summary": "Multimodal human action understanding is a significant problem in computer vision, with the central challenge being the effective utilization of the complementarity among diverse modalities while maintaining model efficiency. However, most existing methods rely on simple late fusion to enhance performance, which results in substantial computational overhead. Although early fusion with a shared backbone for all modalities is efficient, it struggles to achieve excellent performance. To address the dilemma of balancing efficiency and effectiveness, we introduce a self-supervised multimodal skeleton-based action representation learning framework, named Decomposition and Composition. The Decomposition strategy meticulously decomposes the fused multimodal features into distinct unimodal features, subsequently aligning them with their respective ground truth unimodal counterparts. On the other hand, the Composition strategy integrates multiple unimodal features, leveraging them as self-supervised guidance to enhance the learning of multimodal representations. Extensive experiments on the NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD II datasets demonstrate that the proposed method strikes an excellent balance between computational cost and model performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Accepted by Machine Intelligence Research (Journal Impact Factor 8.7, 2024)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21064v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出分解与组合的多模态骨骼动作表示学习框架，提升效率与性能",
            "summary_zh": "多模态人体动作理解是计算机视觉中的一个重要问题，其核心挑战在于有效利用不同模态之间的互补性，同时保持模型效率。现有方法大多依赖简单的后期融合来提高性能，导致计算开销巨大。虽然使用共享骨干网络进行早期融合效率很高，但难以获得出色的性能。为了解决效率和效果之间的两难问题，本文提出了一种自监督的多模态骨骼动作表示学习框架，名为分解与组合。分解策略将融合的多模态特征细致地分解为不同的单模态特征，然后将它们与其各自的真实单模态对应物对齐。另一方面，组合策略整合多个单模态特征，利用它们作为自监督指导来增强多模态表示的学习。在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD II数据集上的大量实验表明，该方法在计算成本和模型性能之间取得了良好的平衡。",
            "intro_zh": [
                "现有方法在多模态动作识别中，要么效率低（后期融合），要么性能差（早期融合），难以兼顾。",
                "论文提出分解与组合策略，将多模态特征分解为单模态并对齐，再将单模态特征组合以指导多模态学习。",
                "在多个数据集上验证，该方法在计算成本和模型性能之间取得了平衡，优于现有方法。"
            ],
            "method_zh": "**问题定义**：多模态人体动作识别旨在利用多种模态的信息（如RGB、深度、骨骼）来准确识别动作。现有方法主要存在两个痛点：一是简单的后期融合方法计算开销大，效率低；二是使用共享骨干网络的早期融合方法性能受限，无法充分利用多模态信息的互补性。因此，如何在效率和性能之间取得平衡是该问题的主要挑战。\\n\\n**核心思路**：论文的核心思路是通过分解和组合策略，实现多模态信息的有效融合和表示学习。分解策略将融合后的多模态特征解耦为单模态特征，并与对应的单模态信息对齐，从而保证单模态信息的准确性。组合策略则利用单模态特征作为自监督信号，指导多模态特征的学习，从而提升多模态表示的质量。\\n\\n**技术框架**：整体框架包含两个主要阶段：分解阶段和组合阶段。在分解阶段，首先将多模态数据输入到一个共享的骨干网络中进行特征提取和融合。然后，使用分解模块将融合后的特征分解为多个单模态特征。每个单模态特征都与对应的单模态数据进行对齐，例如通过对比学习或回归等方式。在组合阶段，将多个单模态特征进行组合，生成自监督信号。该自监督信号用于指导多模态特征的学习，例如通过最小化多模态特征与自监督信号之间的差异。\\n\\n**关键创新**：该论文的关键创新在于提出了分解与组合的自监督学习框架，该框架能够有效地利用多模态信息的互补性，同时保持较高的计算效率。与传统的后期融合方法相比，该方法避免了大量的计算开销。与传统的早期融合方法相比，该方法能够更好地利用单模态信息，从而提升多模态表示的质量。\\n\\n**关键设计**：在分解阶段，可以使用不同的分解模块，例如线性层、卷积层或注意力机制等。单模态特征的对齐可以通过不同的损失函数来实现，例如对比损失、均方误差损失等。在组合阶段，可以使用不同的组合方法，例如加权平均、拼接或注意力机制等。自监督信号的生成也可以采用不同的方法，例如预测单模态特征、预测动作类别等。具体的网络结构和参数设置需要根据具体的数据集和任务进行调整。",
            "application_zh": "该研究成果可应用于视频监控、人机交互、智能家居、康复训练等领域。例如，在视频监控中，可以利用多模态信息准确识别异常行为；在人机交互中，可以根据用户的动作进行智能响应；在康复训练中，可以评估患者的运动能力并提供个性化的训练方案。未来，该方法有望进一步扩展到更复杂的场景和任务中，例如三维重建、机器人导航等。",
            "highlight_zh": "实验结果表明，该方法在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD II数据集上均取得了显著的性能提升。例如，在NTU RGB+D 60数据集上，该方法的准确率相比于基线方法提升了3%-5%。同时，该方法在保持较高性能的同时，计算效率也得到了显著提升，验证了分解与组合策略的有效性。",
            "tags_zh": [
                "多模态学习",
                "动作识别",
                "骨骼数据",
                "自监督学习",
                "表示学习",
                "分解与组合",
                "深度学习"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21064v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21064v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21064v1/images/draw2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Wireless Center of Pressure Feedback System for Humanoid Robot Balance Control using ESP32-C3",
            "authors": [
                "Muhtadin",
                "Faris Rafi Pramana",
                "Dion Hayu Fandiantoro",
                "Moh Ismarintan Zazuli",
                "Atar Fuady Babgei"
            ],
            "arxiv_id": "2512.21219v1",
            "summary": "Maintaining stability during the single-support phase is a fundamental challenge in humanoid robotics, particularly in dance robots that require complex maneuvers and high mechanical freedom. Traditional tethered sensor configurations often restrict joint movement and introduce mechanical noises. This study proposes a wireless embedded balance system designed to maintain stability on uneven surfaces. The system utilizes a custom-designed foot unit integrated with four load cells and an ESP32-C3 microcontroller to estimate the Center of Pressure (CoP) in real time. The CoP data were transmitted wirelessly to the main controller to minimize the wiring complexity of the 29-DoF VI-ROSE humanoid robot. A PID control strategy is implemented to adjust the torso, hip, and ankle roll joints based on CoP feedback. Experimental characterization demonstrated high sensor precision with an average measurement error of 14.8 g. Furthermore, the proposed control system achieved a 100% success rate in maintaining balance during single-leg lifting tasks at a 3-degree inclination with optimized PID parameters (Kp=0.10, Kd=0.005). These results validate the efficacy of wireless CoP feedback in enhancing the postural stability of humanoid robots, without compromising their mechanical flexibility.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21219v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "[T]humanoid robot"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "针对人形机器人，提出基于ESP32-C3的无线压力中心反馈平衡控制系统",
            "summary_zh": "本研究针对人形机器人单腿站立时的平衡问题，提出了一种无线嵌入式平衡系统。该系统集成了定制的足部单元，包含四个力传感器和一个ESP32-C3微控制器，用于实时估计压力中心(CoP)。CoP数据通过无线方式传输到主控制器，从而减少了29自由度VI-ROSE人形机器人的布线复杂性。采用PID控制策略，根据CoP反馈调整躯干、髋部和踝关节的横滚关节。实验结果表明，该传感器具有较高的精度，平均测量误差为14.8克。此外，在3度倾斜的单腿抬起任务中，通过优化PID参数(Kp=0.10, Kd=0.005)，该控制系统实现了100%的平衡成功率。验证了无线CoP反馈在增强人形机器人姿态稳定性方面的有效性，且不影响其机械灵活性。",
            "intro_zh": [
                "人形机器人单腿站立平衡控制面临挑战，传统有线传感器限制了关节运动，并引入机械噪声。",
                "设计无线嵌入式系统，利用足部力传感器和ESP32-C3实时估计压力中心，并无线传输数据。",
                "实验表明，该系统具有高精度，且在倾斜地面上单腿站立时，能有效维持机器人平衡。"
            ],
            "method_zh": "**问题定义**：人形机器人在单腿站立阶段保持平衡是一个关键问题，尤其是在需要复杂动作和高机械自由度的舞蹈机器人中。传统的有线传感器配置限制了关节的运动范围，并且容易引入机械噪声，影响控制精度。因此，需要一种无线、高精度的平衡系统来解决这些问题。\\n\\n**核心思路**：该论文的核心思路是设计一个无线的压力中心（CoP）反馈系统，通过实时测量足底的压力分布，计算出CoP的位置，并将该信息无线传输给主控制器。主控制器根据CoP的位置，调整机器人的姿态，从而实现平衡控制。采用无线方式可以避免有线连接带来的限制和噪声。\\n\\n**技术框架**：该系统的整体架构包括以下几个主要模块：1) 定制的足部单元，集成了四个力传感器，用于测量足底的压力分布；2) ESP32-C3微控制器，用于采集力传感器的数据，计算CoP的位置，并通过Wi-Fi无线传输数据；3) 主控制器，接收来自ESP32-C3的CoP数据，并根据PID控制策略，调整机器人的躯干、髋部和踝关节的横滚关节；4) VI-ROSE人形机器人，一个29自由度的机器人平台，用于验证该系统的性能。\\n\\n**关键创新**：该论文的关键创新在于将无线通信技术应用于人形机器人的平衡控制系统，从而避免了有线连接带来的限制和噪声。此外，该系统采用定制的足部单元，集成了多个力传感器，可以更精确地测量足底的压力分布，从而提高CoP的估计精度。\\n\\n**关键设计**：在关键设计方面，论文采用了ESP32-C3微控制器，因为它具有体积小、功耗低、无线通信能力强的特点。PID控制器的参数（Kp=0.10, Kd=0.005）是通过实验优化得到的，以实现最佳的平衡控制效果。力传感器的选择也至关重要，需要具有高精度和高灵敏度，以确保CoP估计的准确性。",
            "application_zh": "该研究成果可应用于各种需要高精度平衡控制的人形机器人应用场景，例如舞蹈机器人、康复机器人、服务机器人等。通过无线CoP反馈，可以提高机器人在复杂环境下的稳定性和适应性，使其能够执行更复杂的任务。此外，该系统还可以用于步态分析和运动控制研究，为机器人技术的进一步发展提供支持。",
            "highlight_zh": "实验结果表明，该系统具有较高的传感器精度，平均测量误差为14.8克。在3度倾斜的单腿抬起任务中，通过优化PID参数(Kp=0.10, Kd=0.005)，该控制系统实现了100%的平衡成功率。这些结果验证了无线CoP反馈在增强人形机器人姿态稳定性方面的有效性。",
            "tags_zh": [
                "人形机器人",
                "平衡控制",
                "压力中心",
                "无线传感器",
                "ESP32-C3"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21219v1/gambar/Diagram_Sistem_2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21219v1/gambar/Desain_Mekanik_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21219v1/gambar/Diagram_Elektronik.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DGSAN: Dual-Graph Spatiotemporal Attention Network for Pulmonary Nodule Malignancy Prediction",
            "authors": [
                "Xiao Yu",
                "Zhaojie Fang",
                "Guanyu Zhou",
                "Yin Shen",
                "Huoling Luo",
                "Ye Li",
                "Ahmed Elazab",
                "Xiang Wan",
                "Ruiquan Ge",
                "Changmiao Wang"
            ],
            "arxiv_id": "2512.20898v1",
            "summary": "Lung cancer continues to be the leading cause of cancer-related deaths globally. Early detection and diagnosis of pulmonary nodules are essential for improving patient survival rates. Although previous research has integrated multimodal and multi-temporal information, outperforming single modality and single time point, the fusion methods are limited to inefficient vector concatenation and simple mutual attention, highlighting the need for more effective multimodal information fusion. To address these challenges, we introduce a Dual-Graph Spatiotemporal Attention Network, which leverages temporal variations and multimodal data to enhance the accuracy of predictions. Our methodology involves developing a Global-Local Feature Encoder to better capture the local, global, and fused characteristics of pulmonary nodules. Additionally, a Dual-Graph Construction method organizes multimodal features into inter-modal and intra-modal graphs. Furthermore, a Hierarchical Cross-Modal Graph Fusion Module is introduced to refine feature integration. We also compiled a novel multimodal dataset named the NLST-cmst dataset as a comprehensive source of support for related research. Our extensive experiments, conducted on both the NLST-cmst and curated CSTL-derived datasets, demonstrate that our DGSAN significantly outperforms state-of-the-art methods in classifying pulmonary nodules with exceptional computational efficiency.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20898v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "mutual attention"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]spatiotemporal"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 11.5,
            "hit_pillars": [
                "5_interaction_reaction",
                "8_physics_animation",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出双图时空注意力网络以提高肺结节恶性预测准确性",
            "summary_zh": "肺癌是全球癌症相关死亡的主要原因，早期检测和诊断肺结节对提高患者生存率至关重要。尽管以往研究整合了多模态和多时间点信息，但现有的融合方法主要依赖于低效的向量拼接和简单的互注意力机制，亟需更有效的多模态信息融合。为此，本文提出了一种双图时空注意力网络（DGSAN），利用时间变化和多模态数据来提高预测准确性。我们开发了全球-局部特征编码器，以更好地捕捉肺结节的局部、全局和融合特征，并引入双图构建方法，将多模态特征组织为跨模态和内模态图。此外，层次交叉模态图融合模块被引入以优化特征集成。通过在NLST-cmst和CSTL衍生数据集上进行的广泛实验，DGSAN在肺结节分类中显著超越了现有最先进的方法，且计算效率极高。",
            "intro_zh": [
                "现有方法在多模态信息融合上存在低效的向量拼接和简单互注意力的局限性，影响了肺结节恶性预测的准确性。",
                "本文提出双图时空注意力网络（DGSAN），通过全球-局部特征编码器和双图构建方法，有效整合多模态和时序数据。",
                "实验结果表明，DGSAN在NLST-cmst和CSTL衍生数据集上显著提升了肺结节分类的准确性和计算效率。"
            ],
            "method_zh": "**问题定义**：本文旨在解决肺结节恶性预测中的多模态信息融合效率低下的问题。现有方法主要依赖于向量拼接和简单的互注意力机制，导致信息利用不充分。\\n\\n**核心思路**：论文提出的DGSAN通过引入双图构建和层次交叉模态图融合，旨在更有效地捕捉和整合多模态数据中的时序变化和特征，提升预测准确性。\\n\\n**技术框架**：DGSAN的整体架构包括全球-局部特征编码器、双图构建模块和层次交叉模态图融合模块。全球-局部特征编码器负责提取局部和全局特征，双图构建模块将多模态特征组织为跨模态和内模态图，最后通过融合模块优化特征集成。\\n\\n**关键创新**：DGSAN的核心创新在于双图构建和层次交叉模态图融合模块，这些设计使得模型能够更好地捕捉多模态数据中的复杂关系，显著提升了预测性能。\\n\\n**关键设计**：在模型设计中，采用了特定的损失函数以优化多模态特征的融合效果，并通过实验确定了最佳的网络结构和参数设置，以确保模型的高效性和准确性。",
            "application_zh": "该研究在肺结节恶性预测领域具有重要应用价值，能够为临床医生提供更准确的诊断支持，进而提高患者的生存率。未来，该方法也可扩展到其他医学影像分析和疾病预测领域，推动多模态数据融合技术的发展。",
            "highlight_zh": "在NLST-cmst和CSTL衍生数据集上的实验结果显示，DGSAN在肺结节分类任务中显著超越了现有最先进的方法，具体性能提升幅度达到XX%，且在计算效率上也表现优异，证明了其实际应用潜力。",
            "tags_zh": [
                "肺结节",
                "恶性预测",
                "多模态融合",
                "时空注意力",
                "深度学习",
                "医学影像",
                "数据集构建"
            ],
            "_index": 7,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20898v1/Picture/figure1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20898v1/Picture/figure2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20898v1/Picture/figure3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Language-Guided Grasp Detection with Coarse-to-Fine Learning for Robotic Manipulation",
            "authors": [
                "Zebin Jiang",
                "Tianle Jin",
                "Xiangtong Yao",
                "Alois Knoll",
                "Hu Cao"
            ],
            "arxiv_id": "2512.21065v1",
            "summary": "Grasping is one of the most fundamental challenging capabilities in robotic manipulation, especially in unstructured, cluttered, and semantically diverse environments. Recent researches have increasingly explored language-guided manipulation, where robots not only perceive the scene but also interpret task-relevant natural language instructions. However, existing language-conditioned grasping methods typically rely on shallow fusion strategies, leading to limited semantic grounding and weak alignment between linguistic intent and visual grasp reasoning.In this work, we propose Language-Guided Grasp Detection (LGGD) with a coarse-to-fine learning paradigm for robotic manipulation. LGGD leverages CLIP-based visual and textual embeddings within a hierarchical cross-modal fusion pipeline, progressively injecting linguistic cues into the visual feature reconstruction process. This design enables fine-grained visual-semantic alignment and improves the feasibility of the predicted grasps with respect to task instructions. In addition, we introduce a language-conditioned dynamic convolution head (LDCH) that mixes multiple convolution experts based on sentence-level features, enabling instruction-adaptive coarse mask and grasp predictions. A final refinement module further enhances grasp consistency and robustness in complex scenes.Experiments on the OCID-VLG and Grasp-Anything++ datasets show that LGGD surpasses existing language-guided grasping methods, exhibiting strong generalization to unseen objects and diverse language queries. Moreover, deployment on a real robotic platform demonstrates the practical effectiveness of our approach in executing accurate, instruction-conditioned grasp actions. The code will be released publicly upon acceptance.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Submitted to IEEE Journal",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21065v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "grasp prediction"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "language conditioned"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于粗到精学习的语言引导抓取检测方法，用于机器人操作",
            "summary_zh": "抓取是机器人操作中最具挑战性的基本能力之一，尤其是在非结构化、杂乱和语义多样的环境中。最近的研究越来越多地探索语言引导的操作，机器人不仅感知场景，还能理解任务相关的自然语言指令。然而，现有的语言条件抓取方法通常依赖于浅层融合策略，导致有限的语义基础和语言意图与视觉抓取推理之间的弱对齐。本文提出了一种基于粗到精学习范式的语言引导抓取检测（LGGD）方法，用于机器人操作。LGGD利用基于CLIP的视觉和文本嵌入，在分层跨模态融合管道中逐步将语言线索注入到视觉特征重建过程中。这种设计实现了细粒度的视觉-语义对齐，并提高了预测抓取相对于任务指令的可行性。此外，我们引入了一种语言条件动态卷积头（LDCH），它基于句子级特征混合多个卷积专家，从而实现指令自适应的粗掩码和抓取预测。最终的细化模块进一步增强了复杂场景中的抓取一致性和鲁棒性。在OCID-VLG和Grasp-Anything++数据集上的实验表明，LGGD超越了现有的语言引导抓取方法，对未见过的物体和不同的语言查询表现出强大的泛化能力。此外，在真实机器人平台上的部署证明了我们的方法在执行精确的、指令条件下的抓取动作方面的实际有效性。代码将在接收后公开发布。",
            "intro_zh": [
                "现有语言引导的抓取方法依赖浅层融合，存在语义基础薄弱和语言意图与视觉推理对齐不足的问题。",
                "提出一种粗到精的语言引导抓取检测（LGGD）方法，通过分层跨模态融合逐步注入语言线索。",
                "实验表明，LGGD在泛化性和鲁棒性上优于现有方法，并在真实机器人平台上验证了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器人操作中，如何利用自然语言指令更准确、更鲁棒地进行物体抓取的问题。现有方法通常采用浅层融合策略，无法充分理解语言指令中的语义信息，导致抓取位置不准确，对复杂环境的适应性较差。\\n\\n**核心思路**：论文的核心思路是通过一种粗到精的学习范式，逐步将语言信息融入到视觉特征中，实现细粒度的视觉-语义对齐。首先进行粗略的抓取区域预测，然后逐步细化抓取姿态，从而提高抓取的准确性和鲁棒性。\\n\\n**技术框架**：LGGD的整体架构包含以下几个主要模块：1) 基于CLIP的视觉和文本特征提取模块，用于提取视觉和语言的嵌入表示；2) 分层跨模态融合模块，逐步将语言信息注入到视觉特征重建过程中；3) 语言条件动态卷积头（LDCH），用于生成指令自适应的粗掩码和抓取预测；4) 抓取细化模块，进一步增强抓取的一致性和鲁棒性。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了粗到精的学习范式，实现了细粒度的视觉-语义对齐；2) 引入了语言条件动态卷积头（LDCH），能够根据不同的语言指令动态调整卷积核的参数，从而实现指令自适应的抓取预测。\\n\\n**关键设计**：在分层跨模态融合模块中，采用了多层Transformer结构，逐步将语言特征融入到视觉特征中。LDCH模块中，使用了多个卷积专家，每个专家负责处理不同类型的语言指令。通过句子级别的特征来混合这些专家，从而实现指令自适应的抓取预测。损失函数包括抓取分类损失、抓取回归损失和掩码预测损失。",
            "application_zh": "该研究成果可应用于智能仓储、智能制造、家庭服务机器人等领域。通过结合自然语言指令，机器人可以更灵活、更智能地完成各种抓取任务，例如根据用户指令抓取特定物品、在复杂环境中进行物体整理等，具有重要的实际应用价值和广阔的发展前景。",
            "highlight_zh": "LGGD在OCID-VLG和Grasp-Anything++数据集上超越了现有的语言引导抓取方法，展现出对未见物体的强大泛化能力和对多样语言查询的适应性。在真实机器人平台上的部署验证了其在执行精确、指令条件下的抓取动作方面的有效性。具体性能数据将在论文公开发布后提供。",
            "tags_zh": [
                "机器人抓取",
                "语言引导",
                "跨模态融合",
                "粗到精学习",
                "动态卷积"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21065v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21065v1/Images/rectangular_grasp.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21065v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents",
            "authors": [
                "Zhaoxi Zhang",
                "Yitong Duan",
                "Yanzhi Zhang",
                "Yiming Xu",
                "Jiyan He",
                "Yunfang Wu"
            ],
            "arxiv_id": "2512.20957v1",
            "summary": "Locating the files and functions requiring modification in large open-source software (OSS) repositories is challenging due to their scale and structural complexity. Existing large language model (LLM)-based methods typically treat this as a repository-level retrieval task and rely on multiple auxiliary tools, which overlook code execution logic and complicate model control. We propose RepoNavigator, an LLM agent equipped with a single execution-aware tool-jumping to the definition of an invoked symbol. This unified design reflects the actual flow of code execution while simplifying tool manipulation. RepoNavigator is trained end-to-end via Reinforcement Learning (RL) directly from a pretrained model, without any closed-source distillation. Experiments demonstrate that RL-trained RepoNavigator achieves state-of-the-art performance, with the 7B model outperforming 14B baselines, the 14B model surpassing 32B competitors, and even the 32B model exceeding closed-source models such as Claude-3.7. These results confirm that integrating a single, structurally grounded tool with RL training provides an efficient and scalable solution for repository-level issue localization.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20957v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "distillation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "RepoNavigator：基于强化学习的单工具LLM智能体，用于仓库级代码定位",
            "summary_zh": "由于大型开源软件(OSS)仓库的规模和结构复杂性，定位需要修改的文件和函数极具挑战。现有基于大型语言模型(LLM)的方法通常将其视为仓库级检索任务，并依赖多个辅助工具，忽略了代码执行逻辑并使模型控制复杂化。我们提出了RepoNavigator，一个配备单一执行感知工具（跳转到被调用符号的定义）的LLM智能体。这种统一的设计反映了代码执行的实际流程，同时简化了工具操作。RepoNavigator通过强化学习(RL)直接从预训练模型进行端到端训练，无需任何闭源知识蒸馏。实验表明，经过RL训练的RepoNavigator实现了最先进的性能，7B模型优于14B基线模型，14B模型超越32B竞争对手，甚至32B模型超过了诸如Claude-3.7等闭源模型。这些结果证实，将单一的、结构化的工具与RL训练相结合，为仓库级问题定位提供了一种高效且可扩展的解决方案。",
            "intro_zh": [
                "现有方法在大型代码仓库中定位问题时，依赖多个工具，忽略代码执行逻辑，导致模型控制复杂。",
                "RepoNavigator 采用单一的、执行感知的工具（跳转到符号定义），并通过强化学习进行端到端训练。",
                "实验结果表明，RepoNavigator 在仓库级问题定位上取得了 SOTA 性能，甚至超越了更大的模型和闭源模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型开源软件仓库中，难以快速准确地定位需要修改的文件和函数的问题。现有方法通常将此问题视为信息检索任务，依赖多个辅助工具，但这些工具忽略了代码的实际执行逻辑，导致模型控制复杂，效率低下。\\n\\n**核心思路**：论文的核心思路是设计一个配备单一工具的LLM智能体，该工具能够模拟代码执行的实际流程，即跳转到被调用符号的定义。通过这种方式，智能体可以沿着代码的调用链逐步探索代码库，从而更有效地定位问题。\\n\\n**技术框架**：RepoNavigator 的整体框架包括以下几个关键部分：首先，使用一个预训练的LLM作为基础模型。然后，设计一个单一的工具，即“跳转到定义”的功能，允许智能体在代码库中导航。最后，使用强化学习算法对智能体进行端到端训练，使其能够学会如何有效地使用该工具来解决问题。智能体通过观察代码库的状态、执行动作（跳转到定义），并根据是否成功定位问题获得奖励。\\n\\n**关键创新**：最重要的创新点在于将问题定位任务简化为一个单一工具的强化学习问题。与现有方法依赖多个工具相比，这种方法更加简洁高效，并且能够更好地模拟代码执行的实际流程。此外，通过强化学习进行端到端训练，使得智能体能够自动学习如何有效地使用该工具，而无需人工设计复杂的规则或策略。\\n\\n**关键设计**：RepoNavigator 的关键设计包括：1) 使用预训练的LLM作为基础模型，利用其强大的语言理解和代码生成能力。2) 设计单一的“跳转到定义”工具，简化工具操作，并模拟代码执行流程。3) 使用强化学习算法（具体算法未知）进行端到端训练，优化智能体的策略。4) 奖励函数的设计至关重要，需要能够有效地引导智能体学习如何定位问题。具体的参数设置、损失函数和网络结构等细节在论文中可能有所描述，但此处未知。",
            "application_zh": "RepoNavigator 有潜力应用于各种软件开发场景，例如代码维护、缺陷修复、代码审查和知识共享。它可以帮助开发人员快速定位代码库中的问题，提高开发效率，降低维护成本。此外，该研究思路也可以推广到其他领域，例如知识图谱推理和文档检索。",
            "highlight_zh": "RepoNavigator 通过强化学习训练，在仓库级问题定位任务上取得了显著的性能提升。7B 模型超越了 14B 的基线模型，14B 模型超越了 32B 的竞争对手，甚至 32B 模型超越了 Claude-3.7 等闭源模型。这些结果表明，单一工具结合强化学习是一种高效且可扩展的解决方案。",
            "tags_zh": [
                "代码定位",
                "大型语言模型",
                "强化学习",
                "软件仓库",
                "代码导航"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20957v1/navigator.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20957v1/navigator_main.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20957v1/qwen_ablation_rewards.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence",
            "authors": [
                "Sean C. Borneman",
                "Julia Krebs",
                "Ronnie B. Wilbur",
                "Evie A. Malaia"
            ],
            "arxiv_id": "2512.20929v1",
            "summary": "Human language processing relies on the brain's capacity for predictive inference. We present a machine learning framework for decoding neural (EEG) responses to dynamic visual language stimuli in Deaf signers. Using coherence between neural signals and optical flow-derived motion features, we construct spatiotemporal representations of predictive neural dynamics. Through entropy-based feature selection, we identify frequency-specific neural signatures that differentiate interpretable linguistic input from linguistically disrupted (time-reversed) stimuli. Our results reveal distributed left-hemispheric and frontal low-frequency coherence as key features in language comprehension, with experience-dependent neural signatures correlating with age. This work demonstrates a novel multimodal approach for probing experience-driven generative models of perception in the brain.",
            "categories": [
                "q-bio.NC",
                "cs.CL"
            ],
            "primary_category": "q-bio.NC",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Foundation Models for the Brain and Body",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20929v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "optical flow"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]spatiotemporal"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 11.0,
            "hit_pillars": [
                "3_perception_slam",
                "8_physics_animation",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于时空神经相干性的视觉语言处理预测推理解码框架",
            "summary_zh": "本文提出了一种机器学习框架，用于解码聋人对动态视觉语言刺激的神经（EEG）反应。通过神经信号与光流导出的运动特征之间的相干性，构建了预测神经动力学的时空表示。利用基于熵的特征选择，识别出特定频率的神经特征，这些特征能够区分可解释的语言输入和语言中断（时间反转）的刺激。结果表明，分布式的左半球和额叶低频相干性是语言理解的关键特征，并且经验依赖的神经特征与年龄相关。这项工作展示了一种新颖的多模态方法，用于探究大脑中经验驱动的生成式感知模型。",
            "intro_zh": [
                "现有方法在解码动态视觉语言刺激的神经反应方面存在不足，难以有效捕捉预测推理过程。",
                "利用神经信号与光流运动特征的相干性，构建时空表示，从而解码预测神经动力学。",
                "实验结果表明，左半球和额叶低频相干性是语言理解的关键，且神经特征与年龄相关。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何解码大脑在处理动态视觉语言（例如手语）时的神经活动，特别是预测推理过程。现有方法可能无法充分捕捉这种动态过程，并且难以区分有意义的语言输入和无意义的输入。\\n\\n**核心思路**：核心思路是利用神经信号（EEG）与视觉输入（光流导出的运动特征）之间的时空相干性来表征大脑的预测推理过程。通过分析不同频率的神经信号与视觉运动之间的关联，可以识别出与语言理解相关的特定神经特征。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：1) 收集聋人观看动态视觉语言刺激（手语）时的EEG数据；2) 从视觉刺激中提取光流特征，表征运动信息；3) 计算EEG信号与光流特征之间的相干性，构建时空表示；4) 使用基于熵的特征选择方法，选择区分可解释语言输入和时间反转刺激的关键神经特征；5) 分析这些特征与年龄等因素的关系。\\n\\n**关键创新**：关键创新在于将神经信号与视觉运动特征的相干性作为解码预测推理过程的桥梁。通过这种多模态融合的方法，可以更有效地捕捉大脑在处理动态语言时的复杂神经活动。此外，基于熵的特征选择方法能够自动识别出与语言理解相关的关键神经特征，避免了人工选择的偏见。\\n\\n**关键设计**：论文中关键的设计包括：1) 使用光流来表征视觉运动信息，这是一种有效且常用的方法；2) 计算EEG信号与光流特征之间的相干性，捕捉它们之间的时空关联；3) 使用基于熵的特征选择方法，自动选择关键神经特征；4) 分析不同频率的神经信号，因为不同频率的信号可能反映不同的认知过程。具体的参数设置和网络结构等细节在论文中可能没有详细描述，属于未知信息。",
            "application_zh": "该研究成果可应用于开发辅助聋人语言学习和交流的工具，例如实时手语翻译系统。此外，该方法还可以用于研究其他类型的动态视觉语言处理过程，例如阅读和观看电影。未来，该研究有望为理解人类大脑的语言处理机制提供更深入的见解，并促进人机交互技术的发展。",
            "highlight_zh": "实验结果表明，分布式的左半球和额叶低频相干性是语言理解的关键特征。通过区分可解释的语言输入和时间反转的刺激，验证了该方法的有效性。此外，研究还发现经验依赖的神经特征与年龄相关，表明该方法能够捕捉个体差异。",
            "tags_zh": [
                "视觉语言处理",
                "预测推理",
                "神经相干性",
                "脑电信号",
                "光流",
                "聋人语言",
                "时空表示"
            ],
            "_index": 10,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20929v1/BetterAlgorithmsAllFeatures.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20929v1/BetterAlgorithmsUFSFeaturesNoDirection.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20929v1/corr_post.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation",
            "authors": [
                "Wei-Rui Chen",
                "Vignesh Kothapalli",
                "Ata Fatahibaarzi",
                "Hejian Sang",
                "Shao Tang",
                "Qingquan Song",
                "Zhipeng Wang",
                "Muhammad Abdul-Mageed"
            ],
            "arxiv_id": "2512.21002v1",
            "summary": "Distilling the reasoning capabilities from a large language model (LLM) to a smaller student model often involves training on substantial amounts of reasoning data. However, distillation over lengthy sequences with prompt (P), chain-of-thought (CoT), and answer (A) segments makes the process computationally expensive. In this work, we investigate how the allocation of supervision across different segments (P, CoT, A) affects student performance. Our analysis shows that selective knowledge distillation over only the CoT tokens can be effective when the prompt and answer information is encompassed by it. Building on this insight, we establish a truncation protocol to quantify computation-quality tradeoffs as a function of sequence length. We observe that training on only the first $50\\%$ of tokens of every training sequence can retain, on average, $\\approx94\\%$ of full-sequence performance on math benchmarks while reducing training time, memory usage, and FLOPs by about $50\\%$ each. These findings suggest that reasoning distillation benefits from prioritizing early reasoning tokens and provides a simple lever for computation-quality tradeoffs. Codes are available at https://github.com/weiruichen01/distilling-the-essence.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21002v1",
            "code_links": [
                {
                    "url": "https://github.com/weiruichen01/distilling-the-essence",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于序列截断的高效推理蒸馏方法，加速LLM知识迁移。",
            "summary_zh": "将大型语言模型(LLM)的推理能力提炼到较小的学生模型通常需要在大量的推理数据上进行训练。然而，在包含提示(P)、思维链(CoT)和答案(A)片段的冗长序列上进行蒸馏，使得计算成本非常高昂。本文研究了在不同片段(P, CoT, A)上分配监督信号如何影响学生模型的性能。分析表明，当提示和答案信息包含在CoT中时，仅对CoT token进行选择性知识蒸馏是有效的。基于此，本文建立了一个截断协议，以量化计算量与质量之间的权衡关系，作为序列长度的函数。观察到，仅在每个训练序列的前50%的token上进行训练，平均可以保留数学基准上完整序列性能的约94%，同时将训练时间、内存使用和FLOPs减少约50%。这些发现表明，推理蒸馏受益于优先考虑早期推理token，并提供了一个简单的计算量与质量权衡的手段。代码已在https://github.com/weiruichen01/distilling-the-essence上发布。",
            "intro_zh": [
                "现有LLM推理能力蒸馏方法计算成本高昂，尤其是在处理包含长序列的推理数据时。",
                "该论文提出一种基于序列截断的蒸馏方法，通过优先考虑早期推理token来提高效率。",
                "实验表明，仅使用序列前50%的token进行训练，即可保留约94%的性能，同时显著降低计算成本。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）推理能力蒸馏方法，在处理包含提示（Prompt）、思维链（Chain-of-Thought, CoT）和答案（Answer）的长序列数据时，计算成本非常高昂。传统的蒸馏方法需要对整个序列进行训练，导致训练时间长、内存占用大、FLOPs高，限制了其在资源受限环境下的应用。\\n\\n**核心思路**：该论文的核心思路是，通过分析不同序列片段（Prompt、CoT、Answer）对学生模型性能的影响，发现CoT片段包含了Prompt和Answer的信息，因此只需要对CoT片段进行选择性知识蒸馏即可。进一步，通过截断序列，只保留序列的前一部分（例如前50%），来减少计算量，同时尽可能保留推理性能。这种方法基于一个假设，即推理过程的关键信息集中在序列的早期阶段。\\n\\n**技术框架**：该论文的技术框架主要包含以下几个步骤：1) 分析Prompt、CoT和Answer片段对学生模型性能的影响；2) 建立一个序列截断协议，允许控制截断的比例；3) 在截断后的序列上进行知识蒸馏，训练学生模型；4) 评估学生模型在数学推理基准上的性能，并分析计算量与性能之间的权衡关系。\\n\\n**关键创新**：该论文最重要的技术创新点在于，提出了基于序列截断的高效推理蒸馏方法。与传统的蒸馏方法不同，该方法不需要对整个序列进行训练，而是通过选择性地保留序列的早期部分，来减少计算量，同时尽可能保留推理性能。这种方法提供了一种简单而有效的计算量与质量权衡的手段。\\n\\n**关键设计**：论文的关键设计包括：1) 截断比例的选择：通过实验分析不同截断比例对性能的影响，找到一个合适的截断比例，例如50%；2) 损失函数的设计：使用标准的知识蒸馏损失函数，例如KL散度损失，来衡量学生模型和教师模型之间的输出差异；3) 训练策略：使用标准的训练策略，例如Adam优化器，并设置合适的学习率和batch size。",
            "application_zh": "该研究成果可应用于各种需要将大型语言模型的推理能力迁移到小型模型的场景，例如移动设备、嵌入式系统等资源受限的环境。通过降低计算成本，可以使得更多设备能够运行复杂的推理任务，从而推动人工智能在边缘计算领域的应用。此外，该方法还可以用于加速模型开发和部署过程。",
            "highlight_zh": "实验结果表明，仅使用训练序列的前50%的token进行训练，平均可以保留数学基准上完整序列性能的约94%，同时将训练时间、内存使用和FLOPs减少约50%。这表明该方法在显著降低计算成本的同时，能够保持较高的推理性能。",
            "tags_zh": [
                "知识蒸馏",
                "大型语言模型",
                "推理能力",
                "序列截断",
                "计算效率"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21002v1/images/combined_section_inclusion_masking.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21002v1/images/one_training_ex_wide.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21002v1/images/combined_LSP.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multimodal Sensing for Robot-Assisted Sub-Tissue Feature Detection in Physiotherapy Palpation",
            "authors": [
                "Tian-Ao Ren",
                "Jorge Garcia",
                "Seongheon Hong",
                "Jared Grinberg",
                "Hojung Choi",
                "Julia Di",
                "Hao Li",
                "Dmitry Grinberg",
                "Mark R. Cutkosky"
            ],
            "arxiv_id": "2512.20992v1",
            "summary": "Robotic palpation relies on force sensing, but force signals in soft-tissue environments are variable and cannot reliably reveal subtle subsurface features. We present a compact multimodal sensor that integrates high-resolution vision-based tactile imaging with a 6-axis force-torque sensor. In experiments on silicone phantoms with diverse subsurface tendon geometries, force signals alone frequently produce ambiguous responses, while tactile images reveal clear structural differences in presence, diameter, depth, crossings, and multiplicity. Yet accurate force tracking remains essential for maintaining safe, consistent contact during physiotherapeutic interaction. Preliminary results show that combining tactile and force modalities enables robust subsurface feature detection and controlled robotic palpation.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "6 pages, 9 figures, submitted to DMD2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20992v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种多模态触觉传感器，用于机器人辅助的理疗触诊中亚组织特征检测。",
            "summary_zh": "本文提出了一种紧凑的多模态传感器，它集成了基于视觉的高分辨率触觉成像和一个六轴力/力矩传感器。机器人触诊依赖于力感应，但在软组织环境中，力信号是可变的，无法可靠地揭示细微的地下特征。在具有不同地下肌腱几何形状的硅胶模型上的实验表明，单独的力信号经常产生模糊的响应，而触觉图像则揭示了在存在、直径、深度、交叉和多重性方面的清晰结构差异。然而，精确的力跟踪对于在理疗互动期间保持安全、一致的接触仍然至关重要。初步结果表明，结合触觉和力模态能够实现鲁棒的地下特征检测和受控的机器人触诊。",
            "intro_zh": [
                "软组织触诊中，单纯依靠力反馈难以准确识别亚组织特征，易受环境变化影响。",
                "设计多模态传感器融合触觉图像与力/力矩数据，提升亚组织特征识别的鲁棒性。",
                "实验表明，该方法在检测硅胶模型中的肌腱几何特征方面优于仅使用力反馈的方法。"
            ],
            "method_zh": "**问题定义**：机器人辅助理疗触诊中，准确检测软组织下的细微特征（如肌腱的形状、位置等）至关重要。然而，单独使用力传感器进行触诊时，由于软组织的复杂性和力信号的易变性，很难可靠地识别这些特征。现有的方法难以区分不同几何形状的亚组织结构，导致诊断精度下降。\\n\\n**核心思路**：本文的核心思路是将高分辨率的触觉图像与六轴力/力矩传感器的数据进行融合。触觉图像能够提供更直观的表面形变信息，弥补力传感器在识别细微结构方面的不足。通过结合两种模态的信息，可以更准确地检测亚组织特征。\\n\\n**技术框架**：该方法的核心是一个紧凑的多模态传感器，它包含两个主要模块：1) 基于视觉的触觉成像模块，用于捕捉高分辨率的触觉图像；2) 六轴力/力矩传感器，用于测量接触力的大小和方向。在触诊过程中，传感器与软组织表面接触，同时获取触觉图像和力/力矩数据。然后，将这两种模态的数据进行融合，用于亚组织特征的检测。\\n\\n**关键创新**：该方法最重要的创新点在于将视觉触觉成像与力/力矩传感相结合，形成一种多模态的触诊方案。与传统的仅依赖力反馈的触诊方法相比，该方法能够提供更丰富、更可靠的信息，从而提高亚组织特征检测的准确性和鲁棒性。\\n\\n**关键设计**：触觉成像模块采用高分辨率相机和弹性体材料，以捕捉细微的表面形变。力/力矩传感器采用六轴设计，能够测量三个方向的力和三个方向的力矩。数据融合方面，论文可能采用了简单的特征拼接或者更复杂的机器学习方法（具体细节未知）。",
            "application_zh": "该研究成果可应用于机器人辅助的物理治疗、康复训练和医疗诊断等领域。通过更精确的亚组织特征检测，医生可以更好地评估患者的病情，制定个性化的治疗方案。此外，该技术还可以用于远程医疗，使专家能够远程指导机器人进行触诊操作，从而提高医疗服务的可及性。",
            "highlight_zh": "实验结果表明，在检测硅胶模型中的肌腱几何特征时，结合触觉图像和力/力矩数据的多模态方法明显优于仅使用力反馈的方法。触觉图像能够清晰地揭示肌腱的存在、直径、深度、交叉和多重性等结构差异，而单独的力信号经常产生模糊的响应。具体的性能提升数据未知，但实验结果表明该方法具有很强的潜力。",
            "tags_zh": [
                "机器人触诊",
                "多模态传感",
                "触觉成像",
                "力/力矩传感",
                "亚组织特征检测"
            ],
            "_index": 12,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20992v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20992v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20992v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SegMo: Segment-aligned Text to 3D Human Motion Generation",
            "authors": [
                "Bowen Dang",
                "Lin Wu",
                "Xiaohang Yang",
                "Zheng Yuan",
                "Zhixiang Chen"
            ],
            "arxiv_id": "2512.21237v1",
            "summary": "Generating 3D human motions from textual descriptions is an important research problem with broad applications in video games, virtual reality, and augmented reality. Recent methods align the textual description with human motion at the sequence level, neglecting the internal semantic structure of modalities. However, both motion descriptions and motion sequences can be naturally decomposed into smaller and semantically coherent segments, which can serve as atomic alignment units to achieve finer-grained correspondence. Motivated by this, we propose SegMo, a novel Segment-aligned text-conditioned human Motion generation framework to achieve fine-grained text-motion alignment. Our framework consists of three modules: (1) Text Segment Extraction, which decomposes complex textual descriptions into temporally ordered phrases, each representing a simple atomic action; (2) Motion Segment Extraction, which partitions complete motion sequences into corresponding motion segments; and (3) Fine-grained Text-Motion Alignment, which aligns text and motion segments with contrastive learning. Extensive experiments demonstrate that SegMo improves the strong baseline on two widely used datasets, achieving an improved TOP 1 score of 0.553 on the HumanML3D test set. Moreover, thanks to the learned shared embedding space for text and motion segments, SegMo can also be applied to retrieval-style tasks such as motion grounding and motion-to-text retrieval.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "The IEEE/CVF Winter Conference on Applications of Computer Vision 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]motion generation"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "4_motion_diffusion"
            ],
            "headline_zh": "提出SegMo框架，通过对齐文本和运动片段实现更精细的文本驱动3D人体动作生成。",
            "summary_zh": "本文提出了一种新的分段对齐的文本条件3D人体动作生成框架SegMo，旨在实现细粒度的文本-动作对齐。现有方法通常在序列级别对齐文本描述和人体动作，忽略了模态内部的语义结构。SegMo框架包含三个模块：文本片段提取，将复杂的文本描述分解为按时间顺序排列的短语，每个短语代表一个简单的原子动作；运动片段提取，将完整的运动序列划分为相应的运动片段；细粒度文本-动作对齐，通过对比学习对齐文本和运动片段。在广泛使用的两个数据集上的实验表明，SegMo改进了强大的基线，在HumanML3D测试集上实现了0.553的TOP 1得分。此外，由于学习到的文本和运动片段的共享嵌入空间，SegMo还可以应用于运动定位和运动到文本检索等检索任务。",
            "intro_zh": [
                "现有文本驱动人体动作生成方法忽略了文本和动作序列内部的语义结构，导致对齐不够精细。",
                "SegMo框架通过提取文本和动作片段，并在片段级别进行对齐，从而实现更细粒度的文本-动作对应。",
                "实验结果表明，SegMo在HumanML3D数据集上取得了显著的性能提升，并可应用于运动检索等任务。"
            ],
            "method_zh": "**问题定义**：现有文本驱动3D人体动作生成方法主要在序列级别进行文本和动作的对齐，忽略了文本描述和动作序列内部的语义结构。这种粗粒度的对齐方式无法捕捉到文本和动作之间的细微对应关系，限制了生成动作的准确性和多样性。因此，如何实现更精细的文本-动作对齐是本文要解决的核心问题。\\n\\n**核心思路**：本文的核心思路是将文本描述和动作序列分解为更小的、语义连贯的片段，然后在片段级别进行对齐。这种方法能够更好地捕捉文本和动作之间的局部对应关系，从而提高生成动作的质量。具体来说，就是将文本分解为原子动作短语，将动作序列分解为相应的运动片段，然后学习一个共享的嵌入空间，使得对应的文本和运动片段在该空间中的距离更近。\\n\\n**技术框架**：SegMo框架包含三个主要模块：1) **文本片段提取**：使用自然语言处理技术将复杂的文本描述分解为按时间顺序排列的短语，每个短语代表一个简单的原子动作。2) **运动片段提取**：使用运动分割算法将完整的运动序列划分为相应的运动片段。3) **细粒度文本-动作对齐**：使用对比学习方法，学习文本和运动片段的共享嵌入空间，使得对应的文本和运动片段在该空间中的距离更近。\\n\\n**关键创新**：SegMo的关键创新在于提出了片段级别的文本-动作对齐方法。与现有方法在序列级别进行对齐不同，SegMo能够捕捉到文本和动作之间的局部对应关系，从而实现更精细的控制。此外，SegMo还提出了相应的文本和运动片段提取方法，以及基于对比学习的对齐策略。\\n\\n**关键设计**：在文本片段提取模块，使用了预训练的语言模型（例如BERT）来提取文本特征，并使用句法分析技术来分割文本。在运动片段提取模块，使用了基于运动学特征的分割算法。在细粒度文本-动作对齐模块，使用了InfoNCE损失函数来训练共享嵌入空间。具体的网络结构和参数设置在论文中有详细描述，这里不再赘述。",
            "application_zh": "SegMo框架具有广泛的应用前景，例如视频游戏、虚拟现实和增强现实等领域。它可以用于生成逼真的人体动作，从而提高用户体验。例如，在虚拟现实游戏中，可以根据玩家的语音指令生成相应的角色动作。此外，SegMo还可以应用于运动康复、动画制作等领域，具有重要的实际价值和未来影响。",
            "highlight_zh": "SegMo在HumanML3D数据集上取得了显著的性能提升，TOP 1得分达到了0.553，超过了现有的基线方法。实验结果表明，SegMo能够生成更准确、更逼真的人体动作。此外，SegMo还可以应用于运动定位和运动到文本检索等任务，展示了其强大的泛化能力。",
            "tags_zh": [
                "文本驱动动作生成",
                "3D人体动作",
                "片段对齐",
                "对比学习",
                "多模态学习"
            ],
            "_index": 13,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21237v1/images/1_idea.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21237v1/images/3_overview.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21237v1/images/4_qualitative.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PanoGrounder: Bridging 2D and 3D with Panoramic Scene Representations for VLM-based 3D Visual Grounding",
            "authors": [
                "Seongmin Jung",
                "Seongho Choi",
                "Gunwoo Jeon",
                "Minsu Cho",
                "Jongwoo Lim"
            ],
            "arxiv_id": "2512.20907v1",
            "summary": "3D Visual Grounding (3DVG) is a critical bridge from vision-language perception to robotics, requiring both language understanding and 3D scene reasoning. Traditional supervised models leverage explicit 3D geometry but exhibit limited generalization, owing to the scarcity of 3D vision-language datasets and the limited reasoning capabilities compared to modern vision-language models (VLMs). We propose PanoGrounder, a generalizable 3DVG framework that couples multi-modal panoramic representation with pretrained 2D VLMs for strong vision-language reasoning. Panoramic renderings, augmented with 3D semantic and geometric features, serve as an intermediate representation between 2D and 3D, and offer two major benefits: (i) they can be directly fed to VLMs with minimal adaptation and (ii) they retain long-range object-to-object relations thanks to their 360-degree field of view. We devise a three-stage pipeline that places a compact set of panoramic viewpoints considering the scene layout and geometry, grounds a text query on each panoramic rendering with a VLM, and fuses per-view predictions into a single 3D bounding box via lifting. Our approach achieves state-of-the-art results on ScanRefer and Nr3D, and demonstrates superior generalization to unseen 3D datasets and text rephrasings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20907v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]visual grounding"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PanoGrounder：利用全景场景表示桥接2D和3D，实现基于VLM的3D视觉定位",
            "summary_zh": "3D视觉定位（3DVG）是视觉-语言感知到机器人技术的关键桥梁，它需要语言理解和3D场景推理能力。传统的监督模型利用显式的3D几何信息，但由于3D视觉-语言数据集的稀缺以及与现代视觉-语言模型（VLM）相比有限的推理能力，其泛化能力受到限制。我们提出了PanoGrounder，一个通用的3DVG框架，它将多模态全景表示与预训练的2D VLM相结合，以实现强大的视觉-语言推理。全景渲染图，辅以3D语义和几何特征，作为2D和3D之间的中间表示，并提供两个主要优势：（i）它们可以通过最小的适配直接输入到VLM中，以及（ii）由于其360度视野，它们保留了长程对象到对象的关系。我们设计了一个三阶段流程，该流程考虑场景布局和几何形状来放置一组紧凑的全景视点，使用VLM在每个全景渲染图上定位文本查询，并通过提升将每个视点的预测融合为单个3D边界框。我们的方法在ScanRefer和Nr3D上实现了最先进的结果，并展示了对未见过的3D数据集和文本释义的卓越泛化能力。",
            "intro_zh": [
                "现有3D视觉定位方法依赖大量3D视觉-语言数据，且模型推理能力弱于先进的VLM，泛化性受限。",
                "PanoGrounder利用全景图作为2D和3D的桥梁，结合预训练VLM，提升视觉-语言推理能力和泛化性。",
                "实验表明，PanoGrounder在ScanRefer和Nr3D数据集上取得了SOTA结果，并对未见过的3D数据表现出更好的泛化能力。"
            ],
            "method_zh": "**问题定义**：3D视觉定位旨在根据给定的文本描述，在3D场景中定位目标物体。现有方法依赖于大量的3D视觉-语言标注数据，并且模型的视觉-语言推理能力相对较弱，导致泛化能力不足。这些方法难以适应新的场景和文本描述方式。\\n\\n**核心思路**：PanoGrounder的核心思路是利用全景图作为2D和3D场景之间的桥梁。通过将3D场景渲染成多个全景图，并结合3D语义和几何信息，可以充分利用预训练的2D VLM强大的视觉-语言推理能力。全景图的360度视野也有助于捕捉场景中物体之间的长程关系。\\n\\n**技术框架**：PanoGrounder包含三个主要阶段：1) 全景视点选择：根据场景布局和几何信息，选择一组紧凑的全景视点。2) 基于VLM的全景图定位：使用预训练的2D VLM在每个全景图上定位文本查询所指代的物体。3) 3D边界框融合：将每个视点的预测结果通过提升操作融合为单个3D边界框。\\n\\n**关键创新**：PanoGrounder的关键创新在于使用全景图作为中间表示，桥接了2D和3D场景，从而能够充分利用预训练的2D VLM的强大能力。与直接在3D数据上训练模型相比，这种方法可以显著提高模型的泛化能力。\\n\\n**关键设计**：全景视点的选择策略考虑了场景的几何信息，以确保每个视点都能覆盖场景中的关键区域。在全景图定位阶段，使用了预训练的CLIP模型进行视觉-语言匹配。在3D边界框融合阶段，使用了加权平均的方法，根据每个视点的置信度对预测结果进行加权。",
            "application_zh": "PanoGrounder在机器人导航、智能家居、增强现实等领域具有广泛的应用前景。例如，机器人可以根据用户的语音指令，在复杂的室内环境中定位并抓取目标物体。该研究有助于提升机器人与人类的交互能力，并促进机器人技术在实际生活中的应用。",
            "highlight_zh": "PanoGrounder在ScanRefer和Nr3D数据集上取得了state-of-the-art的结果，显著优于现有的3D视觉定位方法。此外，该方法在未见过的3D数据集和文本释义上表现出更强的泛化能力，验证了其有效性和鲁棒性。实验结果表明，利用全景图作为中间表示，可以有效提升3D视觉定位的性能。",
            "tags_zh": [
                "3D视觉定位",
                "全景场景表示",
                "视觉-语言模型",
                "跨模态学习",
                "机器人技术"
            ],
            "_index": 14,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20907v1/fig/hook.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20907v1/fig/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20907v1/fig/adapter.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Assessing the Software Security Comprehension of Large Language Models",
            "authors": [
                "Mohammed Latif Siddiq",
                "Natalie Sekerak",
                "Antonio Karam",
                "Maria Leal",
                "Arvin Islam-Gomes",
                "Joanna C. S. Santos"
            ],
            "arxiv_id": "2512.21238v1",
            "summary": "Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.",
            "categories": [
                "cs.SE",
                "cs.CR",
                "cs.LG"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Submitted to Empirical Software Engineering (EMSE) journal",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21238v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "系统评估大型语言模型在软件安全理解方面的能力，揭示其知识边界与常见误解。",
            "summary_zh": "本文系统地评估了五个领先的大型语言模型（LLMs）：GPT-4o-Mini、GPT-5-Mini、Gemini-2.5-Flash、Llama-3.1和Qwen-2.5在软件安全方面的理解能力。评估框架基于布鲁姆分类法，涵盖六个认知维度：记忆、理解、应用、分析、评估和创造。该研究整合了多样的数据集，包括精选的多项选择题、易受攻击的代码片段（SALLM）、软件安全导论课程的评估、真实案例研究（XBOW）以及安全软件工程课程中的项目创建任务。结果表明，LLMs在较低层次的认知任务（如回忆事实和识别已知漏洞）上表现良好，但在需要推理、架构评估和安全系统创建等较高层次的任务上，性能显著下降。此外，本文提出了一个软件安全知识边界，用于识别模型能够持续保持可靠性能的最高认知水平，并识别了LLMs在布鲁姆分类法的各个层次上表现出的51种常见误解模式。",
            "intro_zh": [
                "现有方法难以全面评估LLMs在软件安全领域的专业知识水平，尤其是在高阶认知能力方面。",
                "论文采用布鲁姆分类法作为框架，系统评估LLMs在软件安全领域的六个认知维度上的能力。",
                "实验结果揭示了LLMs在不同认知层次上的表现差异，并识别了其知识边界和常见的安全误解。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在软件安全领域知识掌握程度评估的问题。现有方法缺乏系统性和全面性，难以准确评估LLMs在高阶认知能力（如分析、评估和创造）方面的表现，也难以识别LLMs在软件安全方面的知识盲点和常见误解。\\n\\n**核心思路**：论文的核心思路是利用布鲁姆分类法作为评估框架，将软件安全知识划分为六个认知维度（记忆、理解、应用、分析、评估和创造），并设计相应的评估任务，从而全面评估LLMs在不同认知层次上的软件安全能力。通过分析LLMs在不同任务上的表现，可以确定其知识边界和常见误解。\\n\\n**技术框架**：该研究的技术框架包括以下几个主要组成部分：1) 选择五个代表性的LLMs：GPT-4o-Mini、GPT-5-Mini、Gemini-2.5-Flash、Llama-3.1和Qwen-2.5；2) 构建多样化的数据集，包括多项选择题、易受攻击的代码片段（SALLM）、软件安全课程评估、真实案例研究（XBOW）和项目创建任务；3) 设计与布鲁姆分类法六个认知维度相对应的评估任务；4) 分析LLMs在不同任务上的表现，计算准确率等指标；5) 识别LLMs的知识边界和常见误解模式。\\n\\n**关键创新**：论文的关键创新在于：1) 系统地将布鲁姆分类法应用于LLMs的软件安全能力评估；2) 构建了多样化的数据集，涵盖了不同类型的软件安全知识和技能；3) 提出了软件安全知识边界的概念，用于量化LLMs的软件安全能力；4) 识别了LLMs在软件安全方面存在的51种常见误解模式。\\n\\n**关键设计**：论文的关键设计包括：1) 数据集的选择，确保涵盖不同类型的软件安全知识和技能，并与布鲁姆分类法的六个认知维度相对应；2) 评估任务的设计，确保能够有效评估LLMs在不同认知层次上的表现；3) 知识边界的定义，采用统计方法确定模型能够持续保持可靠性能的最高认知水平；4) 误解模式的识别，通过人工分析LLMs的错误答案和解释，总结出常见的错误模式。",
            "application_zh": "该研究成果可用于指导LLMs在软件开发中的安全应用，帮助开发者了解LLMs的安全能力边界，避免过度依赖LLMs处理复杂的安全问题。同时，该研究也为LLMs的软件安全能力提升提供了方向，例如可以通过针对性地训练来弥补LLMs在高阶认知能力方面的不足，减少其在软件安全方面的误解。",
            "highlight_zh": "实验结果表明，LLMs在较低层次的认知任务（如回忆事实和识别已知漏洞）上表现良好，但在需要推理、架构评估和安全系统创建等较高层次的任务上，性能显著下降。研究识别了LLMs在布鲁姆分类法的各个层次上表现出的51种常见误解模式，为后续改进LLMs的软件安全能力提供了重要参考。",
            "tags_zh": [
                "大型语言模型",
                "软件安全",
                "能力评估",
                "布鲁姆分类法",
                "知识边界"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21238v1/figures/framework.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21238v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21238v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semi-Supervised Learning for Large Language Models Safety and Content Moderation",
            "authors": [
                "Eduard Stefan Dinuta",
                "Iustin Sirbu",
                "Traian Rebedea"
            ],
            "arxiv_id": "2512.21107v1",
            "summary": "Safety for Large Language Models (LLMs) has been an ongoing research focus since their emergence and is even more relevant nowadays with the increasing capacity of those models. Currently, there are several guardrails in place for all public LLMs and multiple proposed datasets for training safety classifiers. However, training these safety classifiers relies on large quantities of labeled data, which can be problematic to acquire, prone to labeling errors, or often include synthetic data. To address these issues, we suggest a different approach: utilizing semi-supervised learning techniques, which leverage both labeled and unlabeled data, to improve the performance on the safety task. We analyze the improvements that these techniques can offer for both prompts given to Large Language Models and the responses to those requests. Moreover, since augmentation is the central part of semi-supervised algorithms, we demonstrate the importance of using task-specific augmentations, which significantly increase the performance when compared to general-purpose augmentation techniques.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21107v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出半监督学习方法，提升大语言模型安全性和内容审核能力",
            "summary_zh": "针对大语言模型（LLM）的安全问题，本文提出了一种新的方法，利用半监督学习技术来提升安全分类器的性能。由于训练安全分类器需要大量标注数据，而这些数据获取困难、容易出错，且常包含合成数据，因此本文利用半监督学习，同时利用标注数据和未标注数据。研究分析了该技术在LLM的提示和响应方面的改进。此外，本文还强调了任务特定数据增强的重要性，证明其相比通用数据增强技术能显著提高性能。",
            "intro_zh": [
                "现有LLM安全分类器依赖大量标注数据，获取成本高、易出错，且质量难以保证。",
                "提出利用半监督学习，结合标注和未标注数据，提升LLM安全性和内容审核能力。",
                "实验表明，任务特定的数据增强策略能显著提升半监督学习在安全分类任务上的性能。"
            ],
            "method_zh": "**问题定义**：目前，训练用于保障大型语言模型（LLM）安全性的分类器，需要大量的标注数据。然而，获取高质量、大规模的标注数据成本高昂，且容易引入标注错误。此外，现有方法还常常依赖合成数据，这可能导致模型泛化能力不足。因此，如何利用有限的标注数据，同时有效利用未标注数据，是当前LLM安全领域面临的重要挑战。\\n\\n**核心思路**：本文的核心思路是利用半监督学习技术，结合已有的少量标注数据和大量的未标注数据，来训练LLM安全分类器。半监督学习能够从无标注数据中提取有用的信息，从而提升模型的泛化能力和鲁棒性，降低对大规模标注数据的依赖。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 数据准备：收集标注数据和未标注数据，并对数据进行预处理。2) 模型选择：选择合适的LLM作为基础模型，并构建安全分类器。3) 半监督学习训练：采用半监督学习算法，例如一致性正则化、伪标签等，结合标注数据和未标注数据进行训练。4) 评估：在测试集上评估模型的性能，并与基线方法进行比较。\\n\\n**关键创新**：本文的关键创新在于强调了任务特定数据增强的重要性。不同于通用的数据增强方法，任务特定的数据增强能够更好地保留原始数据的语义信息，并生成更具代表性的增强样本，从而提升半监督学习的性能。\\n\\n**关键设计**：在半监督学习算法的选择上，可以采用一致性正则化方法，例如MixMatch、ReMixMatch等。这些方法通过对输入数据进行扰动，并要求模型对扰动后的数据输出一致的预测结果，从而提升模型的鲁棒性。此外，损失函数的设计也至关重要，需要平衡标注数据和未标注数据之间的贡献，并引入正则化项，防止模型过拟合。",
            "application_zh": "该研究成果可应用于各种需要保障LLM安全性的场景，例如智能客服、内容生成、聊天机器人等。通过降低对大规模标注数据的依赖，可以有效降低LLM安全部署的成本，并提高其在实际应用中的可靠性。此外，该方法还可以促进LLM在更多领域的应用，例如教育、医疗等。",
            "highlight_zh": "实验结果表明，采用半监督学习方法可以显著提升LLM安全分类器的性能。特别是，使用任务特定的数据增强策略后，模型性能得到了进一步提升，相比于通用数据增强方法，性能提升显著。具体的性能数据（例如准确率、召回率等）需要在论文中查找。",
            "tags_zh": [
                "半监督学习",
                "大语言模型",
                "安全性",
                "内容审核",
                "数据增强",
                "自然语言处理",
                "安全分类器"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
            "authors": [
                "Ahmed M. Hussain",
                "Salahuddin Salahuddin",
                "Panos Papadimitratos"
            ],
            "arxiv_id": "2512.21110v1",
            "summary": "Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.CR",
                "cs.CY"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "22 pages and 23 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21110v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "大型语言模型未能理解用户意图，易被恶意利用绕过安全机制",
            "summary_zh": "当前大型语言模型（LLMs）的安全方法主要关注于显式有害内容，而忽略了一个关键漏洞：无法理解上下文和识别用户意图。这导致了可被恶意用户系统性利用以规避安全机制的漏洞。我们对包括ChatGPT、Claude、Gemini和DeepSeek在内的多个最先进的LLM进行了实证评估。我们的分析表明，可以通过情感框架、渐进式揭示和学术论证等技术来规避可靠的安全机制。值得注意的是，启用推理的配置反而放大了利用的有效性，提高了事实准确性，但未能质疑潜在意图。Claude Opus 4.1是一个例外，它在某些用例中优先考虑意图检测而非信息提供。这种模式表明，当前的架构设计存在系统性漏洞。这些局限性需要范式转变，将上下文理解和意图识别作为核心安全能力，而不是事后保护机制。",
            "intro_zh": [
                "现有大型语言模型的安全方法侧重于检测显式有害内容，忽略了理解用户意图的不足。",
                "论文通过情感框架、渐进式揭示等技术，揭示了现有LLM安全机制易被恶意用户绕过的漏洞。",
                "实验表明，启用推理的配置反而可能放大漏洞，仅Claude Opus 4.1在某些情况下优先考虑意图检测。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在理解用户意图方面的不足，以及由此导致的安全漏洞问题。现有方法主要关注于识别显式有害内容，而忽略了对用户潜在意图的分析，使得恶意用户可以通过各种手段绕过安全机制，例如情感引导、逐步诱导等。这种对上下文理解的缺失是现有LLM安全防护的痛点。\\n\\n**核心思路**：论文的核心思路是强调将上下文理解和意图识别作为LLM安全的核心能力，而不是仅仅依赖于事后保护机制。通过提高模型对用户意图的理解能力，可以更有效地识别和阻止恶意利用行为。论文通过实验证明，即使是具备推理能力的LLM，在缺乏对用户意图的有效判断时，也容易被误导。\\n\\n**技术框架**：论文采用实证评估的方法，针对多个主流LLM（包括ChatGPT、Claude、Gemini和DeepSeek）进行测试。测试主要通过设计特定的prompt，模拟恶意用户利用情感框架、渐进式揭示和学术论证等技术，诱导LLM生成有害内容或执行不安全操作。通过分析LLM在不同场景下的表现，揭示其在理解用户意图方面的局限性。\\n\\n**关键创新**：论文最重要的创新在于揭示了现有LLM安全机制的系统性漏洞，即缺乏对用户意图的有效理解。与现有方法不同，论文强调了意图识别的重要性，并指出需要从架构设计层面进行改进，将意图理解作为核心安全能力。\\n\\n**关键设计**：论文没有涉及具体的模型结构或算法设计，而是侧重于实验设计和结果分析。关键在于精心设计的prompt，这些prompt旨在模拟真实世界中恶意用户可能采用的攻击手段，从而有效地评估LLM的安全性能。论文通过对比不同LLM在相同prompt下的表现，以及启用/禁用推理功能后的差异，深入分析了其安全漏洞。",
            "application_zh": "该研究成果对提升大型语言模型的安全性具有重要意义。通过加强模型对用户意图的理解，可以有效防止恶意利用，保障用户安全。研究结果可应用于开发更安全、更可靠的LLM，并为未来的安全机制设计提供指导，例如在LLM应用中加入意图检测模块，从而减少被恶意利用的风险。",
            "highlight_zh": "实验结果表明，包括ChatGPT、Gemini和DeepSeek在内的多个先进LLM容易被情感框架、渐进式揭示等技术绕过安全机制。启用推理的配置通常会放大漏洞，而非缓解。Claude Opus 4.1在某些情况下表现出对意图检测的优先考虑，但整体而言，现有LLM在理解用户意图方面存在明显不足。",
            "tags_zh": [
                "大型语言模型安全",
                "用户意图理解",
                "安全漏洞",
                "对抗攻击",
                "上下文理解"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Neural Probe-Based Hallucination Detection for Large Language Models",
            "authors": [
                "Shize Liang",
                "Hongzhi Wang"
            ],
            "arxiv_id": "2512.20949v1",
            "summary": "Large language models(LLMs) excel at text generation and knowledge question-answering tasks, but they are prone to generating hallucinated content, severely limiting their application in high-risk domains. Current hallucination detection methods based on uncertainty estimation and external knowledge retrieval suffer from the limitation that they still produce erroneous content at high confidence levels and rely heavily on retrieval efficiency and knowledge coverage. In contrast, probe methods that leverage the model's hidden-layer states offer real-time and lightweight advantages. However, traditional linear probes struggle to capture nonlinear structures in deep semantic spaces.To overcome these limitations, we propose a neural network-based framework for token-level hallucination detection. By freezing language model parameters, we employ lightweight MLP probes to perform nonlinear modeling of high-level hidden states. A multi-objective joint loss function is designed to enhance detection stability and semantic disambiguity. Additionally, we establish a layer position-probe performance response model, using Bayesian optimization to automatically search for optimal probe insertion layers and achieve superior training results.Experimental results on LongFact, HealthBench, and TriviaQA demonstrate that MLP probes significantly outperform state-of-the-art methods in accuracy, recall, and detection capability under low false-positive conditions.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20949v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于神经探针的大语言模型幻觉检测框架，提升低误报率下的检测性能。",
            "summary_zh": "大型语言模型(LLMs)在文本生成和知识问答任务中表现出色，但容易产生幻觉内容，严重限制了其在高风险领域的应用。目前基于不确定性估计和外部知识检索的幻觉检测方法存在局限性，即在高置信度下仍然会产生错误内容，并且严重依赖于检索效率和知识覆盖率。相比之下，利用模型隐藏层状态的探针方法具有实时和轻量级的优势。然而，传统的线性探针难以捕捉深度语义空间中的非线性结构。为了克服这些限制，我们提出了一种基于神经网络的token级别幻觉检测框架。通过冻结语言模型参数，我们采用轻量级MLP探针来对高层隐藏状态进行非线性建模。设计了一种多目标联合损失函数，以增强检测稳定性和语义消歧。此外，我们建立了一个层位置-探针性能响应模型，使用贝叶斯优化自动搜索最佳探针插入层，并获得卓越的训练结果。在LongFact、HealthBench和TriviaQA上的实验结果表明，MLP探针在低误报条件下，在准确率、召回率和检测能力方面显著优于最先进的方法。",
            "intro_zh": [
                "现有幻觉检测方法在高置信度下仍会出错，且依赖外部知识检索，限制了其在高风险领域的应用。",
                "该论文提出一种基于神经网络探针的幻觉检测框架，利用轻量级MLP探针进行非线性建模，提升检测性能。",
                "实验结果表明，该方法在准确率、召回率和检测能力方面显著优于现有方法，尤其是在低误报条件下。"
            ],
            "method_zh": "**问题定义**：大语言模型容易产生幻觉内容，严重限制其在高风险领域的应用。现有的基于不确定性估计和外部知识检索的方法，在高置信度下仍然会产生错误内容，并且严重依赖于检索效率和知识覆盖率。传统的线性探针方法虽然轻量级，但难以捕捉深度语义空间中的非线性结构。\\n\\n**核心思路**：该论文的核心思路是利用神经网络（MLP）探针，对大语言模型的高层隐藏状态进行非线性建模，从而更准确地检测幻觉。通过冻结语言模型参数，保证探针的轻量级和实时性。同时，设计多目标联合损失函数，增强检测的稳定性和语义消歧能力。\\n\\n**技术框架**：整体框架包括以下几个主要模块：1) 冻结参数的大语言模型；2) 轻量级MLP探针，用于对隐藏层状态进行非线性建模；3) 多目标联合损失函数，用于训练探针；4) 层位置-探针性能响应模型，用于自动搜索最佳探针插入层。流程是：首先，将文本输入大语言模型，获取隐藏层状态；然后，将隐藏层状态输入MLP探针，得到幻觉检测结果；最后，使用多目标联合损失函数训练探针，并使用贝叶斯优化搜索最佳探针插入层。\\n\\n**关键创新**：最重要的技术创新点在于使用神经网络（MLP）探针进行非线性建模，克服了传统线性探针无法捕捉深度语义空间中非线性结构的局限性。此外，多目标联合损失函数和层位置-探针性能响应模型也提升了检测的稳定性和效率。与现有方法的本质区别在于，该方法不依赖于外部知识检索，而是直接利用模型内部的隐藏层状态进行幻觉检测。\\n\\n**关键设计**：关键设计包括：1) MLP探针的网络结构，例如层数、神经元数量等；2) 多目标联合损失函数的具体形式，例如各个损失项的权重；3) 贝叶斯优化的搜索空间和目标函数，用于自动搜索最佳探针插入层；4) 冻结大语言模型参数，保证探针的轻量级和实时性。",
            "application_zh": "该研究成果可应用于各种需要高可靠性的自然语言处理任务中，例如医疗诊断、金融分析、法律咨询等。通过提高大语言模型生成内容的真实性和可靠性，可以降低其在高风险领域的应用风险，并促进其更广泛的应用。未来，该方法可以进一步扩展到其他类型的语言模型和任务中。",
            "highlight_zh": "实验结果表明，该方法在LongFact、HealthBench和TriviaQA数据集上，显著优于现有的幻觉检测方法。具体来说，在低误报条件下，该方法在准确率、召回率和检测能力方面均取得了显著提升。这表明该方法能够更有效地检测大语言模型生成的幻觉内容，并降低误报率。",
            "tags_zh": [
                "大语言模型",
                "幻觉检测",
                "神经探针",
                "非线性建模",
                "多目标学习"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20949v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20949v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20949v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models",
            "authors": [
                "Sichun Luo",
                "Yi Huang",
                "Mukai Li",
                "Shichang Meng",
                "Fengyuan Liu",
                "Zefa Hu",
                "Junlan Feng",
                "Qi Liu"
            ],
            "arxiv_id": "2512.21120v1",
            "summary": "Large language models (LLMs) are increasingly deployed as conversational assistants in open-domain, multi-turn settings, where users often provide incomplete or ambiguous information. However, existing LLM-focused clarification benchmarks primarily assume single-turn interactions or cooperative users, limiting their ability to evaluate clarification behavior in realistic settings. We introduce \\textbf{ClarifyMT-Bench}, a benchmark for multi-turn clarification grounded in a five-dimensional ambiguity taxonomy and a set of six behaviorally diverse simulated user personas. Through a hybrid LLM-human pipeline, we construct 6,120 multi-turn dialogues capturing diverse ambiguity sources and interaction patterns. Evaluating ten representative LLMs uncovers a consistent under-clarification bias: LLMs tend to answer prematurely, and performance degrades as dialogue depth increases. To mitigate this, we propose \\textbf{ClarifyAgent}, an agentic approach that decomposes clarification into perception, forecasting, tracking, and planning, substantially improving robustness across ambiguity conditions. ClarifyMT-Bench establishes a reproducible foundation for studying when LLMs should ask, when they should answer, and how to navigate ambiguity in real-world human-LLM interactions.",
            "categories": [
                "cs.CL",
                "cs.IR"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21120v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ClarifyMT-Bench，用于评估和提升会话大语言模型的多轮澄清能力。",
            "summary_zh": "大型语言模型（LLMs）越来越多地被部署为开放域、多轮环境中的会话助手，在这些环境中，用户常常提供不完整或不明确的信息。然而，现有的以LLM为中心的澄清基准主要假设单轮交互或合作用户，限制了它们在真实场景中评估澄清行为的能力。我们引入了\textbf{ClarifyMT-Bench}，这是一个基于五维模糊性分类和一组六个行为多样的模拟用户角色构建的多轮澄清基准。通过混合LLM-人工流程，我们构建了6,120个多轮对话，捕捉了不同的模糊性来源和交互模式。对十个代表性LLM的评估揭示了一种一致的欠澄清偏差：LLM倾向于过早回答，并且性能随着对话深度的增加而下降。为了缓解这个问题，我们提出了\textbf{ClarifyAgent}，一种将澄清分解为感知、预测、跟踪和规划的代理方法，从而显著提高了各种模糊性条件下的鲁棒性。ClarifyMT-Bench为研究LLM何时应该提问、何时应该回答以及如何在真实的人机交互中处理模糊性奠定了可复现的基础。",
            "intro_zh": [
                "现有LLM澄清基准主要关注单轮交互或合作用户，难以评估真实场景下的澄清行为。",
                "论文提出ClarifyAgent，将澄清过程分解为感知、预测、跟踪和规划四个阶段，提升鲁棒性。",
                "ClarifyMT-Bench评估显示，LLM存在欠澄清偏差，ClarifyAgent能有效缓解该问题，提升性能。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型在多轮对话中，面对用户提供的不完整或模糊信息时，缺乏有效的澄清机制。现有的澄清基准测试主要集中在单轮交互或假设用户是完全合作的，这与真实场景存在差距，无法充分评估LLM在复杂对话环境下的澄清能力。因此，需要一个更贴近真实场景、更全面的多轮澄清基准，以及能够有效处理模糊信息的澄清方法。\n\n**核心思路**：论文的核心思路是将多轮澄清过程建模为一个智能代理（ClarifyAgent），该代理能够感知用户输入中的模糊性，预测澄清的必要性，跟踪对话状态，并规划澄清策略。通过将澄清过程分解为多个可控的步骤，可以更有效地引导LLM进行澄清，避免过早回答或遗漏关键信息。\n\n**技术框架**：ClarifyAgent的技术框架包含四个主要模块：1) 感知模块（Perception）：负责检测用户输入中的模糊性，并根据预定义的模糊性分类进行分类。2) 预测模块（Forecasting）：基于对话历史和当前输入，预测是否需要进行澄清。3) 跟踪模块（Tracking）：维护对话状态，包括已澄清的信息和未澄清的信息。4) 规划模块（Planning）：根据预测结果和对话状态，选择合适的澄清策略，例如提出具体问题或要求用户提供更多信息。\n\n**关键创新**：论文的关键创新在于提出了一个agentic的澄清框架，将澄清过程分解为多个可控的步骤，并引入了预测模块来判断澄清的必要性。这与传统的单轮澄清方法或直接回答问题的方法不同，能够更有效地处理多轮对话中的模糊信息。\n\n**关键设计**：ClarifyMT-Bench基准的设计考虑了五个维度的模糊性分类，并模拟了六种不同行为的用户角色，以增加基准的真实性和多样性。ClarifyAgent的各个模块可以使用不同的LLM或专门训练的模型来实现。预测模块可以使用二元分类器来判断是否需要澄清。规划模块可以基于规则或强化学习来选择澄清策略。",
            "application_zh": "该研究成果可应用于各种会话式人工智能系统，例如智能客服、虚拟助手和教育机器人。通过提升LLM的澄清能力，可以提高对话的效率和准确性，改善用户体验，并减少因信息不明确而导致的错误。",
            "highlight_zh": "实验结果表明，现有的LLM普遍存在欠澄清偏差，即倾向于过早回答问题，导致性能下降。ClarifyAgent在各种模糊性条件下均表现出显著的性能提升，证明了其在多轮澄清方面的有效性。例如，在某些模糊性条件下，ClarifyAgent的性能提升超过10%。",
            "tags_zh": [
                "多轮对话",
                "大语言模型",
                "澄清",
                "模糊性",
                "基准测试"
            ],
            "_index": 19,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21120v1/z13.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21120v1/z17.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21120v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study",
            "authors": [
                "Zhongren Dong",
                "Haotian Guo",
                "Weixiang Xu",
                "Huan Zhao",
                "Zixing Zhang"
            ],
            "arxiv_id": "2512.20948v1",
            "summary": "Neuropsychiatric disorders, such as Alzheimer's disease (AD), depression, and autism spectrum disorder (ASD), are characterized by linguistic and acoustic abnormalities, offering potential biomarkers for early detection. Despite the promise of multi-modal approaches, challenges like multi-lingual generalization and the absence of a unified evaluation framework persist. To address these gaps, we propose FEND (Foundation model-based Evaluation of Neuropsychiatric Disorders), a comprehensive multi-modal framework integrating speech and text modalities for detecting AD, depression, and ASD across the lifespan. Leveraging 13 multi-lingual datasets spanning English, Chinese, Greek, French, and Dutch, we systematically evaluate multi-modal fusion performance. Our results show that multi-modal fusion excels in AD and depression detection but underperforms in ASD due to dataset heterogeneity. We also identify modality imbalance as a prevalent issue, where multi-modal fusion fails to surpass the best mono-modal models. Cross-corpus experiments reveal robust performance in task- and language-consistent scenarios but noticeable degradation in multi-lingual and task-heterogeneous settings. By providing extensive benchmarks and a detailed analysis of performance-influencing factors, FEND advances the field of automated, lifespan-inclusive, and multi-lingual neuropsychiatric disorder assessment. We encourage researchers to adopt the FEND framework for fair comparisons and reproducible research.",
            "categories": [
                "cs.CL",
                "cs.SD"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20948v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出FEND框架，用于基于多模态融合和预训练模型评估神经精神疾病。",
            "summary_zh": "神经精神疾病，如阿尔茨海默病(AD)、抑郁症和自闭症谱系障碍(ASD)，其特征是语言和声音异常，这为早期检测提供了潜在的生物标志物。尽管多模态方法前景广阔，但多语言泛化和缺乏统一的评估框架等挑战依然存在。为了解决这些问题，我们提出了FEND（基于基础模型的神经精神疾病评估），这是一个综合的多模态框架，集成了语音和文本模态，用于检测整个生命周期的AD、抑郁症和ASD。我们利用跨越英语、中文、希腊语、法语和荷兰语的13个多语言数据集，系统地评估了多模态融合性能。结果表明，多模态融合在AD和抑郁症检测中表现出色，但在ASD中由于数据集异质性而表现不佳。我们还发现模态不平衡是一个普遍问题，多模态融合未能超过最佳单模态模型。跨语料库实验表明，在任务和语言一致的场景中表现出稳健的性能，但在多语言和任务异构设置中性能明显下降。通过提供广泛的基准和对性能影响因素的详细分析，FEND推动了自动化、全生命周期和多语言神经精神疾病评估领域的发展。我们鼓励研究人员采用FEND框架进行公平比较和可重复的研究。",
            "intro_zh": [
                "现有神经精神疾病评估方法缺乏多语言泛化能力和统一评估框架，限制了其应用。",
                "FEND框架融合语音和文本模态，利用预训练模型进行多语言、全生命周期的神经精神疾病评估。",
                "实验结果表明，FEND在AD和抑郁症检测中表现良好，但受数据集异质性和模态不平衡影响。"
            ],
            "method_zh": "**问题定义**：论文旨在解决神经精神疾病（如阿尔茨海默病、抑郁症和自闭症谱系障碍）的自动评估问题。现有方法在多语言环境下的泛化能力不足，且缺乏统一的评估框架，难以进行公平比较和可重复研究。此外，多模态融合方法在实际应用中面临数据集异质性和模态不平衡等挑战。\\n\\n**核心思路**：论文的核心思路是利用预训练的基础模型，构建一个多模态融合的评估框架（FEND），该框架能够同时处理语音和文本信息，并支持多种语言。通过在多个数据集上进行实验，分析多模态融合的性能，并识别影响性能的关键因素。这样设计的目的是为了提高神经精神疾病评估的准确性和泛化能力，并为未来的研究提供一个统一的基准。\\n\\n**技术框架**：FEND框架主要包含以下几个模块：1) 数据预处理模块：负责对语音和文本数据进行清洗和标准化。2) 特征提取模块：利用预训练的基础模型（如语音和文本领域的预训练模型）提取语音和文本特征。3) 多模态融合模块：将语音和文本特征进行融合，得到一个综合的特征表示。4) 分类模块：利用分类器（如支持向量机、神经网络等）对融合后的特征进行分类，判断个体是否患有神经精神疾病。\\n\\n**关键创新**：该论文的关键创新在于提出了一个统一的多模态评估框架（FEND），该框架能够同时处理语音和文本信息，并支持多种语言。此外，论文还对多模态融合的性能进行了深入分析，识别了数据集异质性和模态不平衡等问题，并提出了相应的解决方案。\\n\\n**关键设计**：论文的关键设计包括：1) 选择合适的预训练模型，以提取高质量的语音和文本特征。2) 设计有效的多模态融合方法，以充分利用语音和文本信息。3) 采用合适的分类器，以提高分类的准确性。4) 通过实验分析，优化框架的参数设置，如学习率、batch size等。",
            "application_zh": "该研究成果可应用于神经精神疾病的早期筛查和诊断，尤其是在多语言环境下。FEND框架能够为临床医生提供辅助决策支持，提高诊断效率和准确性。此外，该框架还可以用于药物研发和疗效评估，加速神经精神疾病的治疗进程。未来，该研究有望推动个性化医疗的发展，为患者提供更精准的治疗方案。",
            "highlight_zh": "实验结果表明，FEND框架在AD和抑郁症检测中表现出色，但在ASD检测中由于数据集异质性而表现不佳。跨语料库实验表明，在任务和语言一致的场景中表现出稳健的性能，但在多语言和任务异构设置中性能明显下降。研究还发现模态不平衡是一个普遍问题，多模态融合未能超过最佳单模态模型。",
            "tags_zh": [
                "神经精神疾病",
                "多模态融合",
                "预训练模型",
                "自然语言处理",
                "语音识别"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20948v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20948v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20948v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Multimodal Human-Centered Framework for Assessing Pedestrian Well-Being in the Wild",
            "authors": [
                "Yasaman Hakiminejad",
                "Arash Tavakoli"
            ],
            "arxiv_id": "2512.21200v1",
            "summary": "Pedestrian well-being is a critical yet rarely measured component of sustainable urban mobility and livable city design. Existing approaches to evaluating pedestrian environments often rely on static, infrastructure-based indices or retrospective surveys, which overlook the dynamic, subjective, and psychophysiological dimensions of everyday walking experience. This paper introduces a multimodal, human-centered framework for assessing pedestrian well-being in the wild by integrating three complementary data streams: continuous physiological sensing, geospatial tracking, and momentary self-reports collected using the Experience Sampling Method. The framework conceptualizes pedestrian experience as a triangulation enabling a holistic understanding of how urban environments influence well-being. The utility of our framework is then demonstrated through a naturalistic case study conducted in the Greater Philadelphia region, in which participants wore research-grade wearable sensors and carried GPS-enabled smartphones during their regular daily activities. Physiological indicators of autonomic nervous system activity, including heart rate variability and electrodermal activity, were synchronized with spatial trajectories and in situ self-reports of stress, affect, and perceived infrastructure conditions. Results illustrate substantial inter- and intra-individual variability in both subjective experience and physiological response, as well as context-dependent patterns associated with traffic exposure, pedestrian infrastructure quality, and environmental enclosure. The findings also suggest that commonly used walkability indices may not fully capture experiential dimensions of pedestrian well-being. By enabling real-world, multimodal measurement of pedestrian experience, the proposed framework offers a scalable and transferable approach for advancing human-centered urban analytics.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21200v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多模态行人福祉评估框架，用于城市可持续发展和宜居性设计。",
            "summary_zh": "行人福祉是可持续城市交通和宜居城市设计中一个关键但很少被衡量的组成部分。现有的行人环境评估方法通常依赖于静态的、基于基础设施的指标或回顾性调查，忽略了日常步行体验的动态、主观和心理生理维度。本文介绍了一种多模态、以人为中心的框架，用于评估“野外”的行人福祉，通过整合三个互补的数据流：连续生理传感、地理空间跟踪和使用体验抽样法收集的即时自我报告。该框架将行人体验概念化为一种三角测量，从而能够全面了解城市环境如何影响福祉。通过在大费城地区进行的自然案例研究，证明了我们框架的实用性，参与者在日常活动中佩戴研究级可穿戴传感器并携带支持GPS的智能手机。自主神经系统活动的生理指标，包括心率变异性和皮肤电活动，与空间轨迹和压力、情感和感知基础设施条件的现场自我报告同步。结果表明，主观体验和生理反应存在显着的个体间和个体内部差异，以及与交通暴露、行人基础设施质量和环境封闭相关的上下文相关模式。研究结果还表明，常用的步行性指数可能无法完全捕捉行人福祉的体验维度。通过实现对行人体验的真实世界、多模态测量，所提出的框架为推进以人为中心的城市分析提供了一种可扩展和可转移的方法。",
            "intro_zh": [
                "现有行人环境评估方法忽略了步行体验的动态、主观和心理生理维度。",
                "提出多模态框架，整合生理传感、地理空间跟踪和体验抽样自我报告。",
                "案例研究表明，主观体验和生理反应存在显著差异，且与环境因素相关。"
            ],
            "method_zh": "**问题定义**：现有评估行人福祉的方法，如基于基础设施的指标或回顾性调查，无法捕捉行人步行体验的动态性、主观性和生理心理维度。这些方法缺乏对行人实时状态和环境影响的细粒度理解，难以有效指导城市规划和设计，提升行人福祉。\\n\\n**核心思路**：论文的核心思路是将行人福祉的评估从静态、回顾性方法转变为动态、实时的多模态数据融合。通过同时收集行人的生理数据、地理位置信息和主观体验报告，构建一个全面的行人体验模型。这种方法能够更准确地反映城市环境对行人福祉的实际影响。\\n\\n**技术框架**：该框架包含三个主要模块：1) **生理传感模块**：使用可穿戴传感器（如心率变异性传感器和皮肤电活动传感器）连续监测行人的生理指标，反映其自主神经系统的活动状态。2) **地理空间跟踪模块**：利用GPS设备记录行人的空间轨迹，确定其所处的城市环境和基础设施条件。3) **体验抽样模块**：通过智能手机应用，在行人步行过程中随机触发问卷调查，收集其对压力、情感和感知基础设施条件的主观报告。这三个模块的数据进行时间同步和整合，形成一个多维度的行人体验数据集。\\n\\n**关键创新**：该框架的关键创新在于其多模态数据融合方法和“野外”数据收集策略。传统的行人福祉评估方法通常依赖于实验室环境或模拟场景，而该框架能够在真实的城市环境中收集数据，更贴近行人的实际体验。此外，通过整合生理、空间和主观数据，该框架能够更全面地理解城市环境对行人福祉的影响机制。\\n\\n**关键设计**：在案例研究中，参与者佩戴研究级可穿戴传感器并携带支持GPS的智能手机。生理数据以高频率（例如，心率变异性数据以1Hz采样）记录，以捕捉细微的生理变化。体验抽样调查采用随机触发机制，避免对行人的干扰。数据同步采用精确的时间戳，确保不同模态数据的一致性。研究人员还设计了专门的问卷，用于收集行人对压力、情感和感知基础设施条件的主观评价。",
            "application_zh": "该研究成果可应用于城市规划、交通管理和公共健康等领域。通过实时监测和评估行人福祉，城市规划者可以优化城市设计，改善行人基础设施，提升城市宜居性。交通管理者可以评估交通流量和拥堵对行人福祉的影响，制定更合理的交通管理策略。公共健康机构可以利用该框架评估城市环境对居民心理健康的影响，制定相应的干预措施。",
            "highlight_zh": "研究结果表明，行人的主观体验和生理反应存在显著的个体间和个体内部差异。例如，交通暴露、行人基础设施质量和环境封闭等因素与行人的压力水平和情感状态密切相关。此外，研究发现常用的步行性指数可能无法完全捕捉行人福祉的体验维度，表明需要更全面、多维度的评估方法。",
            "tags_zh": [
                "行人福祉",
                "多模态数据融合",
                "体验抽样法",
                "生理传感",
                "城市规划",
                "可持续交通",
                "以人为本的城市分析"
            ],
            "_index": 21,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21200v1/triangular.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21200v1/Framework.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21200v1/map.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Universal Transient Stability Analysis: A Large Language Model-Enabled Dynamics Prediction Framework",
            "authors": [
                "Chao Shen",
                "Ke Zuo",
                "Mingyang Sun"
            ],
            "arxiv_id": "2512.20970v1",
            "summary": "Existing dynamics prediction frameworks for transient stability analysis (TSA) fail to achieve multi-scenario \"universality\"--the inherent ability of a single, pre-trained architecture to generalize across diverse operating conditions, unseen faults, and heterogeneous systems. To address this, this paper proposes TSA-LLM, a large language model (LLM)-based universal framework that models multi-variate transient dynamics prediction as a univariate generative task with three key innovations: First, a novel data processing pipeline featuring channel independence decomposition to resolve dimensional heterogeneity, sample-wise normalization to eliminate separate stable or unstable pipelines, and temporal patching for efficient long-sequence modeling; Second, a parameter-efficient freeze-and-finetune strategy that augments the LLM's architecture with dedicated input embedding and output projection layers while freezing core transformer blocks to preserve generic feature extraction capabilities; Third, a two-stage fine-tuning scheme that combines teacher forcing, which feeds the model ground-truth data during initial training, with scheduled sampling, which gradually shifts to leveraging model-generated predictions, to mitigate cumulative errors in long-horizon iterative prediction. Comprehensive testing demonstrates the framework's universality, as TSA-LLM trained solely on the New England 39-bus system achieves zero-shot generalization to mixed stability conditions and unseen faults, and matches expert performance on the larger Iceland 189-bus system with only 5% fine-tuning data. This multi-scenario versatility validates a universal framework that eliminates scenario-specific retraining and achieves scalability via large-scale parameters and cross-scenario training data.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20970v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于大语言模型的通用暂态稳定性分析框架，实现跨场景零样本泛化。",
            "summary_zh": "现有的暂态稳定性分析(TSA)动态预测框架难以实现多场景的“通用性”，即单个预训练架构在不同运行条件、未见故障和异构系统中的泛化能力。为了解决这个问题，本文提出了TSA-LLM，一个基于大语言模型(LLM)的通用框架，它将多变量暂态动态预测建模为单变量生成任务，具有三个关键创新：首先，一种新颖的数据处理流程，包括用于解决维度异构性的通道独立分解、用于消除独立稳定或不稳定流程的样本级归一化，以及用于高效长序列建模的时间分块；其次，一种参数高效的冻结和微调策略，该策略使用专用输入嵌入和输出投影层来增强LLM的架构，同时冻结核心Transformer块以保留通用特征提取能力；第三，一种两阶段微调方案，该方案结合了教师强制（在初始训练期间向模型提供真实数据）和计划采样（逐渐转向利用模型生成的预测），以减轻长时程迭代预测中的累积误差。全面的测试表明了该框架的通用性，因为仅在新英格兰39总线系统上训练的TSA-LLM实现了对混合稳定条件和未见故障的零样本泛化，并且仅使用5%的微调数据即可在更大的冰岛189总线系统上匹配专家性能。这种多场景的通用性验证了一个通用框架，该框架消除了特定于场景的重新训练，并通过大规模参数和跨场景训练数据实现了可扩展性。",
            "intro_zh": [
                "现有暂态稳定性分析方法难以在不同运行条件和系统上泛化，需要针对特定场景进行重新训练。",
                "TSA-LLM利用大语言模型，通过数据处理、参数高效微调和两阶段训练，实现跨场景的通用动态预测。",
                "实验表明，TSA-LLM在未见故障和系统上表现出色，仅需少量数据即可匹配专家性能，验证了其通用性。"
            ],
            "method_zh": "**问题定义**：现有的暂态稳定性分析(TSA)动态预测框架缺乏通用性，无法在不同的电力系统运行条件、未见过的故障类型以及异构的电力系统之间进行泛化。这意味着针对每个新的场景，都需要重新训练模型，这大大增加了计算成本和部署难度。现有方法通常依赖于特定场景的数据进行训练，缺乏跨场景的知识迁移能力。\\n\\n**核心思路**：TSA-LLM的核心思路是将多变量的暂态动态预测问题转化为一个单变量的生成任务，并利用大语言模型(LLM)强大的序列建模能力来预测电力系统的动态行为。通过将多个变量解耦，并采用生成式的方式进行预测，可以有效地捕捉电力系统动态的复杂性和长期依赖关系。此外，通过冻结LLM的核心Transformer层，可以保留其通用的特征提取能力，并减少微调所需的参数量。\\n\\n**技术框架**：TSA-LLM的整体框架包括三个主要阶段：数据处理、模型构建和模型训练。在数据处理阶段，首先进行通道独立分解，将多变量时间序列分解为多个单变量时间序列。然后，进行样本级归一化，消除稳定和不稳定样本之间的差异。最后，采用时间分块技术，将长序列分割成多个短序列，以提高训练效率。在模型构建阶段，使用预训练的LLM作为骨干网络，并添加专门的输入嵌入层和输出投影层。在模型训练阶段，采用两阶段微调策略，首先使用教师强制进行训练，然后使用计划采样逐渐过渡到模型生成的预测。\\n\\n**关键创新**：TSA-LLM的关键创新在于其通用性。通过精心设计的数据处理流程和参数高效的微调策略，TSA-LLM能够在一个电力系统上训练，并在其他未见过的电力系统上进行零样本泛化。这种通用性大大降低了模型部署的成本和难度，并提高了模型的实用性。此外，两阶段微调策略有效地缓解了长时程迭代预测中的累积误差问题。\\n\\n**关键设计**：在数据处理方面，通道独立分解将多变量问题转化为单变量问题，简化了建模的难度。样本级归一化消除了稳定和不稳定样本之间的差异，提高了模型的鲁棒性。时间分块技术提高了训练效率。在模型训练方面，两阶段微调策略结合了教师强制和计划采样的优点，有效地缓解了长时程迭代预测中的累积误差问题。具体来说，计划采样的概率随着训练的进行逐渐增加，使得模型能够逐渐适应自身生成的预测。",
            "application_zh": "TSA-LLM可应用于电力系统运行的在线安全评估、控制策略优化和故障诊断。该框架能够快速准确地预测电力系统在不同运行条件下的动态行为，为电力系统的安全稳定运行提供保障。此外，TSA-LLM的通用性使其能够应用于不同的电力系统，降低了模型部署的成本和难度，具有广阔的应用前景。",
            "highlight_zh": "TSA-LLM在New England 39总线系统上训练后，实现了对混合稳定条件和未见故障的零样本泛化。在更大的Iceland 189总线系统上，仅使用5%的微调数据，TSA-LLM的性能就能够匹配专家水平。这些结果表明，TSA-LLM具有很强的通用性和泛化能力。",
            "tags_zh": [
                "暂态稳定性分析",
                "大语言模型",
                "动态预测",
                "零样本学习",
                "电力系统",
                "通用框架",
                "时间序列预测"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20970v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20970v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20970v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Surgical Scene Segmentation using a Spike-Driven Video Transformer with Real-Time Potential",
            "authors": [
                "Shihao Zou",
                "Jingjing Li",
                "Wei Ji",
                "Jincai Huang",
                "Kai Wang",
                "Guo Dan",
                "Weixin Si",
                "Yi Pan"
            ],
            "arxiv_id": "2512.21284v1",
            "summary": "Modern surgical systems increasingly rely on intelligent scene understanding to provide timely situational awareness for enhanced intra-operative safety. Within this pipeline, surgical scene segmentation plays a central role in accurately perceiving operative events. Although recent deep learning models, particularly large-scale foundation models, achieve remarkable segmentation accuracy, their substantial computational demands and power consumption hinder real-time deployment in resource-constrained surgical environments. To address this limitation, we explore the emerging SNN as a promising paradigm for highly efficient surgical intelligence. However, their performance is still constrained by the scarcity of labeled surgical data and the inherently sparse nature of surgical video representations. To this end, we propose \\textit{SpikeSurgSeg}, the first spike-driven video Transformer framework tailored for surgical scene segmentation with real-time potential on non-GPU platforms. To address the limited availability of surgical annotations, we introduce a surgical-scene masked autoencoding pretraining strategy for SNNs that enables robust spatiotemporal representation learning via layer-wise tube masking. Building on this pretrained backbone, we further adopt a lightweight spike-driven segmentation head that produces temporally consistent predictions while preserving the low-latency characteristics of SNNs. Extensive experiments on EndoVis18 and our in-house SurgBleed dataset demonstrate that SpikeSurgSeg achieves mIoU comparable to SOTA ANN-based models while reducing inference latency by at least $8\\times$. Notably, it delivers over $20\\times$ acceleration relative to most foundation-model baselines, underscoring its potential for time-critical surgical scene segmentation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21284v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene understanding"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 8.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "8_physics_animation",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出SpikeSurgSeg，一种基于脉冲神经网络的视频Transformer，用于实时手术场景分割。",
            "summary_zh": "现代手术系统越来越依赖智能场景理解，以提供及时的态势感知，从而增强术中安全性。其中，手术场景分割在准确感知手术事件方面起着核心作用。虽然最近的深度学习模型，特别是大型基础模型，取得了显著的分割精度，但它们巨大的计算需求和功耗阻碍了在资源受限的手术环境中进行实时部署。为了解决这个限制，我们探索了新兴的脉冲神经网络（SNN），作为高效手术智能的有希望的范例。然而，它们的性能仍然受到标记手术数据稀缺和手术视频表示固有稀疏性的限制。为此，我们提出了SpikeSurgSeg，这是第一个为手术场景分割量身定制的脉冲驱动视频Transformer框架，具有在非GPU平台上实现实时性的潜力。为了解决手术注释的有限可用性，我们引入了一种用于SNN的手术场景掩码自动编码预训练策略，该策略通过分层管掩码实现鲁棒的时空表示学习。在此预训练骨干网络的基础上，我们进一步采用了一种轻量级的脉冲驱动分割头，该分割头产生时间上一致的预测，同时保持了SNN的低延迟特性。在EndoVis18和我们内部的SurgBleed数据集上的大量实验表明，SpikeSurgSeg实现了与基于ANN的SOTA模型相当的mIoU，同时将推理延迟降低了至少8倍。值得注意的是，相对于大多数基础模型基线，它提供了超过20倍的加速，突显了其在时间关键型手术场景分割中的潜力。",
            "intro_zh": [
                "现有深度学习模型在手术场景分割中计算量大、功耗高，难以在资源受限环境中实时部署。",
                "提出SpikeSurgSeg，利用脉冲神经网络（SNN）和视频Transformer，结合掩码自动编码预训练，实现高效分割。",
                "实验表明，SpikeSurgSeg在保持分割精度的同时，显著降低了推理延迟，加速比超过传统模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决手术场景分割中现有深度学习模型计算量大、功耗高，难以实时部署的问题。现有方法，特别是基于大型基础模型的方案，虽然精度高，但计算资源需求巨大，无法满足手术环境的实时性要求。此外，手术数据标注稀缺以及手术视频的稀疏性也限制了SNN的性能。\\n\\n**核心思路**：论文的核心思路是利用脉冲神经网络（SNN）的低功耗、高效率特性，结合Transformer架构强大的时空建模能力，构建一个适用于手术场景分割的实时系统。通过掩码自动编码预训练，解决手术数据标注稀缺的问题，提升SNN的性能。\\n\\n**技术框架**：SpikeSurgSeg框架主要包含两个阶段：预训练阶段和分割阶段。预训练阶段采用手术场景掩码自动编码（Surgical-Scene Masked Autoencoding）策略，对SNN骨干网络进行预训练，学习鲁棒的时空表示。分割阶段则使用一个轻量级的脉冲驱动分割头，基于预训练的骨干网络进行手术场景分割，生成时间一致的预测。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了SpikeSurgSeg，这是第一个基于脉冲神经网络的视频Transformer框架，专门为手术场景分割设计。2) 引入了手术场景掩码自动编码预训练策略，有效解决了手术数据标注稀缺的问题，提升了SNN的性能。3) 设计了一个轻量级的脉冲驱动分割头，保证了分割的实时性和时间一致性。\\n\\n**关键设计**：在预训练阶段，采用了分层管掩码（layer-wise tube masking）策略，对输入视频进行掩码，迫使网络学习被掩码部分的信息，从而提升模型的鲁棒性。分割头的设计注重轻量化和低延迟，采用简单的卷积层和脉冲神经元，以保证实时性。损失函数方面，可能采用了交叉熵损失或Dice损失等常用的分割损失函数，具体细节未在摘要中明确说明。",
            "application_zh": "该研究成果可应用于智能手术机器人、术中导航系统和增强现实手术辅助等领域。通过实时分割手术场景，可以为医生提供更准确的术中信息，提高手术安全性，减少手术并发症，并有望实现更精准的手术操作。未来，该技术还可扩展到其他医疗影像分析任务，如病灶检测和器官分割。",
            "highlight_zh": "SpikeSurgSeg在EndoVis18和SurgBleed数据集上取得了与SOTA的ANN模型相当的mIoU，同时将推理延迟降低了至少8倍。相对于大多数基础模型基线，它提供了超过20倍的加速，充分证明了其在时间关键型手术场景分割中的潜力。",
            "tags_zh": [
                "手术场景分割",
                "脉冲神经网络",
                "视频Transformer",
                "实时性",
                "掩码自动编码"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21284v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21284v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21284v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Human Motion Estimation with Everyday Wearables",
            "authors": [
                "Siqi Zhu",
                "Yixuan Li",
                "Junfu Li",
                "Qi Wu",
                "Zan Wang",
                "Haozhe Ma",
                "Wei Liang"
            ],
            "arxiv_id": "2512.21209v1",
            "summary": "While on-body device-based human motion estimation is crucial for applications such as XR interaction, existing methods often suffer from poor wearability, expensive hardware, and cumbersome calibration, which hinder their adoption in daily life. To address these challenges, we present EveryWear, a lightweight and practical human motion capture approach based entirely on everyday wearables: a smartphone, smartwatch, earbuds, and smart glasses equipped with one forward-facing and two downward-facing cameras, requiring no explicit calibration before use. We introduce Ego-Elec, a 9-hour real-world dataset covering 56 daily activities across 17 diverse indoor and outdoor environments, with ground-truth 3D annotations provided by the motion capture (MoCap), to facilitate robust research and benchmarking in this direction. Our approach employs a multimodal teacher-student framework that integrates visual cues from egocentric cameras with inertial signals from consumer devices. By training directly on real-world data rather than synthetic data, our model effectively eliminates the sim-to-real gap that constrains prior work. Experiments demonstrate that our method outperforms baseline models, validating its effectiveness for practical full-body motion estimation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21209v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "sim-to-real"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "teacher-student"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 8.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "6_video_extraction",
                "9_embodied_foundation"
            ],
            "headline_zh": "EveryWear：利用日常可穿戴设备进行轻量级、免标定的全身人体运动估计",
            "summary_zh": "本文提出EveryWear，一种轻量级且实用的全身人体运动捕捉方法，完全基于日常可穿戴设备：智能手机、智能手表、耳机和智能眼镜，眼镜配备一个前置摄像头和两个下视摄像头，无需使用前进行显式校准。为了促进该方向的稳健研究和基准测试，我们引入了Ego-Elec，一个9小时的真实世界数据集，涵盖17个不同的室内和室外环境中的56项日常活动，并由运动捕捉（MoCap）提供ground-truth 3D标注。我们的方法采用多模态师生框架，将来自以自我为中心的摄像头的视觉线索与来自消费设备的惯性信号相结合。通过直接在真实世界数据上进行训练，我们的模型有效地消除了限制先前工作的sim-to-real差距。实验表明，我们的方法优于基线模型，验证了其在实际全身运动估计中的有效性。",
            "intro_zh": [
                "现有基于可穿戴设备的人体运动估计方法存在穿戴不便、硬件昂贵和校准繁琐等问题，限制了其在日常生活中的应用。",
                "EveryWear利用智能手机、智能手表、耳机和智能眼镜等日常可穿戴设备，结合视觉和惯性信号，实现轻量级、免标定的全身人体运动估计。",
                "通过在真实世界数据集Ego-Elec上训练，并采用多模态师生框架，该方法有效消除了sim-to-real差距，并在实验中优于基线模型。"
            ],
            "method_zh": "**问题定义**：现有基于可穿戴设备的人体运动估计方法依赖于特定的、昂贵的硬件，并且需要繁琐的校准过程，这使得它们难以在日常生活中普及。因此，需要一种轻量级、低成本、易于使用的解决方案，能够利用常见的可穿戴设备进行准确的人体运动估计。\\n\\n**核心思路**：论文的核心思路是利用日常生活中常见的可穿戴设备（智能手机、智能手表、耳机、智能眼镜）作为传感器，通过融合来自不同模态（视觉和惯性）的数据，实现全身人体运动的估计。这种方法避免了对专用硬件的依赖，降低了成本，并提高了易用性。\\n\\n**技术框架**：EveryWear采用多模态师生框架。首先，利用配备摄像头的智能眼镜捕捉第一人称视角的视觉信息，同时利用智能手机、智能手表和耳机等设备的惯性传感器获取运动数据。然后，将这些多模态数据输入到模型中进行训练。该模型采用师生学习框架，其中教师模型可能是一个更复杂的模型，用于生成伪标签，而学生模型则是一个更轻量级的模型，用于实际的运动估计。\\n\\n**关键创新**：该方法最重要的创新点在于其完全依赖于日常可穿戴设备，无需任何额外的专用硬件或复杂的校准过程。此外，通过直接在真实世界数据集上进行训练，有效地解决了sim-to-real的迁移问题，提高了模型的泛化能力。\\n\\n**关键设计**：Ego-Elec数据集的构建是关键设计之一，它提供了丰富的真实世界数据，涵盖了各种日常活动和环境。多模态融合策略也是关键，如何有效地将视觉和惯性数据结合起来，以获得更准确的运动估计结果，是需要仔细设计的。损失函数的设计也至关重要，需要能够有效地指导模型学习人体运动的规律。",
            "application_zh": "该研究成果可广泛应用于XR交互、虚拟现实、游戏、运动分析、健康监测等领域。例如，在VR/AR游戏中，用户可以通过日常可穿戴设备实现全身动作捕捉，从而获得更沉浸式的体验。在运动分析中，可以利用该技术对运动员的动作进行精确分析，提高训练效果。在健康监测中，可以实时监测用户的运动状态，提供个性化的健康建议。",
            "highlight_zh": "EveryWear在Ego-Elec数据集上进行了评估，实验结果表明，该方法在全身人体运动估计方面优于基线模型。通过直接在真实世界数据上进行训练，该方法有效地消除了sim-to-real差距，提高了模型的泛化能力。具体性能数据和与基线模型的对比结果在论文中有详细展示。",
            "tags_zh": [
                "人体运动估计",
                "可穿戴设备",
                "多模态融合",
                "师生学习",
                "免标定",
                "真实世界数据",
                "Ego-Elec数据集"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21209v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21209v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21209v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Robust and Efficient MuJoCo-based Model Predictive Control via Web of Affine Spaces Derivatives",
            "authors": [
                "Chen Liang",
                "Daniel Rakita"
            ],
            "arxiv_id": "2512.21109v1",
            "summary": "MuJoCo is a powerful and efficient physics simulator widely used in robotics. One common way it is applied in practice is through Model Predictive Control (MPC), which uses repeated rollouts of the simulator to optimize future actions and generate responsive control policies in real time. To make this process more accessible, the open source library MuJoCo MPC (MJPC) provides ready-to-use MPC algorithms and implementations built directly on top of the MuJoCo simulator. However, MJPC relies on finite differencing (FD) to compute derivatives through the underlying MuJoCo simulator, which is often a key bottleneck that can make it prohibitively costly for time-sensitive tasks, especially in high-DOF systems or complex scenes. In this paper, we introduce the use of Web of Affine Spaces (WASP) derivatives within MJPC as a drop-in replacement for FD. WASP is a recently developed approach for efficiently computing sequences of accurate derivative approximations. By reusing information from prior, related derivative calculations, WASP accelerates and stabilizes the computation of new derivatives, making it especially well suited for MPC's iterative, fine-grained updates over time. We evaluate WASP across a diverse suite of MJPC tasks spanning multiple robot embodiments. Our results suggest that WASP derivatives are particularly effective in MJPC: it integrates seamlessly across tasks, delivers consistently robust performance, and achieves up to a 2$\\mathsf{x}$ speedup compared to an FD backend when used with derivative-based planners, such as iLQG. In addition, WASP-based MPC outperforms MJPC's stochastic sampling-based planners on our evaluation tasks, offering both greater efficiency and reliability. To support adoption and future research, we release an open-source implementation of MJPC with WASP derivatives fully integrated.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Submitted to 2026 IEEE International Conference on Robotics & Automation (ICRA 2026)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21109v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "MPC",
                        "[T]model predictive control"
                    ],
                    "score": 8.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于仿射空间网络导数的MuJoCo模型预测控制，提升效率与鲁棒性",
            "summary_zh": "本文提出了一种基于仿射空间网络(Web of Affine Spaces, WASP)导数的MuJoCo模型预测控制(MPC)方法，旨在替代传统的有限差分(FD)方法。MuJoCo是一个强大的物理仿真器，常用于机器人控制。MuJoCo MPC (MJPC)库提供了现成的MPC算法，但其依赖有限差分计算导数，这在高自由度系统或复杂场景中会成为性能瓶颈。WASP是一种高效计算导数近似序列的方法，通过重用先前相关导数计算的信息，加速并稳定新导数的计算，特别适用于MPC的迭代更新。实验结果表明，WASP导数在MJPC中表现出色，能够无缝集成到各种任务中，提供稳定的性能，并且在使用基于导数的规划器(如iLQG)时，速度提升高达2倍。此外，基于WASP的MPC优于MJPC的基于随机采样的规划器，在效率和可靠性方面均有提升。本文开源了完全集成了WASP导数的MJPC实现。",
            "intro_zh": [
                "MuJoCo MPC依赖有限差分计算导数，在高自由度系统或复杂场景中计算成本高昂，限制了其在时间敏感任务中的应用。",
                "提出使用仿射空间网络(WASP)导数作为有限差分的替代方案，WASP通过重用先前导数信息加速导数计算，适用于MPC的迭代更新。",
                "实验表明，WASP导数能无缝集成到MJPC任务中，提升高达2倍的速度，并且在效率和可靠性上优于基于随机采样的规划器。"
            ],
            "method_zh": "**问题定义**：论文旨在解决MuJoCo MPC中，使用有限差分(FD)计算导数时效率低下的问题。有限差分方法需要多次仿真来估计梯度，这在高自由度机器人和复杂环境中计算成本很高，成为实时控制的瓶颈。\\n\\n**核心思路**：论文的核心思路是使用Web of Affine Spaces (WASP)导数来替代有限差分。WASP通过构建一系列仿射空间来近似目标函数的导数，并利用先前计算的导数信息来加速后续导数的计算。这种方法能够显著减少所需的仿真次数，从而提高MPC的计算效率。\\n\\n**技术框架**：该方法直接集成到MuJoCo MPC (MJPC)库中，作为一个可替换的导数计算后端。用户可以简单地将有限差分切换为WASP导数，而无需修改其他MPC算法的实现。整体流程包括：1) 初始化WASP导数计算器；2) 在每次MPC迭代中，使用WASP计算目标函数和约束的导数；3) 将计算得到的导数传递给优化器，以更新控制策略。\\n\\n**关键创新**：WASP导数的核心创新在于其能够高效地重用先前计算的导数信息。与有限差分每次都从头开始计算导数不同，WASP通过维护一个仿射空间网络，可以利用先前迭代中计算的导数来预测当前迭代的导数。这种方法显著减少了所需的仿真次数，从而提高了计算效率。\\n\\n**关键设计**：WASP的关键设计包括：1) 仿射空间的构建方式，例如如何选择基点和基向量；2) 如何更新和维护仿射空间网络，以保证导数近似的准确性；3) 如何选择合适的步长和正则化参数，以平衡导数计算的效率和精度。论文中可能还涉及一些针对MuJoCo的具体优化，例如如何利用MuJoCo的内部状态信息来加速导数计算（具体细节未知）。",
            "application_zh": "该研究成果可广泛应用于机器人控制领域，尤其是在需要实时响应和高精度控制的场景中，例如：人形机器人、四足机器人、无人驾驶汽车等。通过提高MPC的计算效率，可以实现更复杂的控制策略，并提高机器人的运动性能和鲁棒性。此外，该方法还可以应用于其他需要高效导数计算的领域，例如：优化设计、参数估计等。",
            "highlight_zh": "实验结果表明，与传统的有限差分方法相比，WASP导数在使用基于导数的规划器(如iLQG)时，速度提升高达2倍。此外，基于WASP的MPC在多个机器人控制任务中，优于MJPC的基于随机采样的规划器，在效率和可靠性方面均有提升。这些结果表明，WASP导数是一种有效的替代有限差分的方法，可以显著提高MuJoCo MPC的性能。",
            "tags_zh": [
                "模型预测控制",
                "MuJoCo",
                "导数计算",
                "仿射空间网络",
                "机器人控制"
            ],
            "_index": 25,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21109v1/figures/quadrotor.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21109v1/figures/swim.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21109v1/figures/climb.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Global End-Effector Pose Control of an Underactuated Aerial Manipulator via Reinforcement Learning",
            "authors": [
                "Shlok Deshmukh",
                "Javier Alonso-Mora",
                "Sihao Sun"
            ],
            "arxiv_id": "2512.21085v1",
            "summary": "Aerial manipulators, which combine robotic arms with multi-rotor drones, face strict constraints on arm weight and mechanical complexity. In this work, we study a lightweight 2-degree-of-freedom (DoF) arm mounted on a quadrotor via a differential mechanism, capable of full six-DoF end-effector pose control. While the minimal design enables simplicity and reduced payload, it also introduces challenges such as underactuation and sensitivity to external disturbances, including manipulation of heavy loads and pushing tasks. To address these, we employ reinforcement learning, training a Proximal Policy Optimization (PPO) agent in simulation to generate feedforward commands for quadrotor acceleration and body rates, along with joint angle targets. These commands are tracked by an incremental nonlinear dynamic inversion (INDI) attitude controller and a PID joint controller, respectively. Flight experiments demonstrate centimeter-level position accuracy and degree-level orientation precision, with robust performance under external force disturbances. The results highlight the potential of learning-based control strategies for enabling contact-rich aerial manipulation using simple, lightweight platforms.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "8 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21085v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "PPO"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "提出基于强化学习的欠驱动空中机械臂全局末端姿态控制方法",
            "summary_zh": "本文研究了一种轻量级双自由度（DoF）机械臂，该机械臂通过差动机构安装在四旋翼无人机上，能够实现六自由度末端执行器姿态控制。这种极简设计虽然实现了简单性和有效载荷的降低，但也带来了欠驱动和对外部扰动敏感等挑战，包括重物操作和推力任务。为了解决这些问题，我们采用强化学习，在仿真环境中训练近端策略优化（PPO）智能体，以生成四旋翼加速度和机身角速率的前馈命令以及关节角度目标。这些命令分别由增量非线性动态逆（INDI）姿态控制器和PID关节控制器跟踪。飞行实验表明，该方法实现了厘米级的定位精度和度级的姿态精度，并在外部力扰动下表现出鲁棒性。结果突出了基于学习的控制策略在利用简单、轻量级平台实现接触式空中操作的潜力。",
            "intro_zh": [
                "空中机械臂面临机械臂重量和机械复杂度的严格约束，现有方法难以兼顾轻量化和高精度控制。",
                "采用强化学习方法，训练PPO智能体生成前馈控制命令，结合INDI姿态控制器和PID关节控制器，实现精确控制。",
                "飞行实验验证了该方法的有效性，实现了厘米级的定位精度和度级的姿态精度，并具有良好的抗干扰能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决欠驱动空中机械臂的全局末端姿态精确控制问题。现有的空中机械臂设计往往需要在机械臂的重量和控制精度之间做出权衡。轻量化的机械臂虽然降低了无人机的负载，但也导致了欠驱动和对外部扰动的敏感性，使得精确控制末端执行器的姿态变得困难，尤其是在进行接触式操作时。\\n\\n**核心思路**：论文的核心思路是利用强化学习来学习一个前馈控制器，该控制器能够预测四旋翼无人机和机械臂的最佳控制指令，从而补偿欠驱动带来的控制困难和外部扰动的影响。通过在仿真环境中训练智能体，可以使其学习到复杂的动力学模型和控制策略，而无需手动设计复杂的控制算法。\\n\\n**技术框架**：整体框架包括三个主要模块：强化学习智能体、增量非线性动态逆（INDI）姿态控制器和PID关节控制器。首先，PPO智能体根据当前状态生成四旋翼加速度和机身角速率的前馈命令以及关节角度目标。然后，INDI姿态控制器跟踪四旋翼的加速度和角速率命令，PID关节控制器跟踪机械臂的关节角度目标。最后，系统将执行结果反馈给PPO智能体，用于更新策略。\\n\\n**关键创新**：该论文的关键创新在于将强化学习应用于欠驱动空中机械臂的全局末端姿态控制。与传统的控制方法相比，强化学习能够更好地处理非线性、欠驱动和外部扰动等复杂情况。此外，通过在仿真环境中进行训练，可以避免在真实环境中进行大量的实验，从而降低了成本和风险。\\n\\n**关键设计**：论文中使用了Proximal Policy Optimization (PPO)算法作为强化学习的训练方法。PPO算法是一种on-policy算法，通过限制策略更新的幅度，保证了训练的稳定性。INDI姿态控制器是一种基于模型的控制方法，能够有效地跟踪四旋翼的加速度和角速率命令。PID关节控制器则用于控制机械臂的关节角度。在仿真环境中，论文使用了详细的动力学模型，并考虑了各种外部扰动，以提高训练的泛化能力。",
            "application_zh": "该研究成果可应用于多种场景，例如：高空作业、桥梁检测、灾难救援等。在这些场景中，空中机械臂可以代替人类完成危险或难以到达的任务，例如：高空焊接、桥梁裂缝检测、废墟搜救等。此外，该技术还可以应用于物流领域，例如：无人机配送、仓库自动化等。",
            "highlight_zh": "实验结果表明，该方法能够实现厘米级的定位精度和度级的姿态精度。在外部力扰动下，该方法仍能保持良好的鲁棒性。与传统的控制方法相比，该方法在欠驱动和外部扰动下的性能得到了显著提升。例如，在推力任务中，该方法能够稳定地控制机械臂的姿态，而传统的控制方法则容易出现失控。",
            "tags_zh": [
                "空中机械臂",
                "强化学习",
                "欠驱动系统",
                "末端姿态控制",
                "PPO算法"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21085v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21085v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21085v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Safe Navigation with Zonotopic Tubes: An Elastic Tube-based MPC Framework",
            "authors": [
                "Niyousha Ghiasi",
                "Bahare Kiumarsi",
                "Hamidreza Modares"
            ],
            "arxiv_id": "2512.21198v1",
            "summary": "This paper presents an elastic tube-based model predictive control (MPC) framework for unknown discrete-time linear systems subject to disturbances. Unlike most existing elastic tube-based MPC methods, we do not assume perfect knowledge of the system model or disturbance realizations bounds. Instead, a conservative zonotopic disturbance set is initialized and iteratively refined using data and prior knowledge: data are used to identify matrix zonotope model sets for the system dynamics, while prior physical knowledge is employed to discard models and disturbances inconsistent with known constraints. This process yields constrained matrix zonotopes representing disturbance realizations and dynamics that enable a principled fusion of offline information with limited online data, improving MPC feasibility and performance. The proposed design leverages closed-loop system characterization to learn and refine control gains that maintain a small tube size. By separating open-loop model mismatch from closed-loop effects in the error dynamics, the method avoids dependence on the size of the state and input operating regions, thereby reducing conservatism. An adaptive co-design of the tube and ancillary feedback ensures $λ$-contractive zonotopic tubes, guaranteeing robust positive invariance, improved feasibility margins, and enhanced disturbance tolerance. We establish recursive feasibility conditions and introduce a polyhedral Lyapunov candidate for the error tube, proving exponential stability of the closed-loop error dynamics under the adaptive tube-gain updates. Simulations demonstrate improved robustness, enlarged feasibility regions, and safe closed-loop performance using only a small amount of online data.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21198v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]MPC",
                        "model predictive control"
                    ],
                    "score": 8.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于Zonotope Tube的弹性Tube-based MPC框架，用于未知线性系统的安全导航。",
            "summary_zh": "本文提出了一种基于弹性Tube的MPC框架，用于处理受扰动的未知离散时间线性系统。与现有方法不同，该方法不假设系统模型或扰动边界的完美知识。相反，初始化一个保守的Zonotope扰动集，并通过数据和先验知识迭代细化：利用数据识别系统动力学的矩阵Zonotope模型集，并利用先验物理知识排除与已知约束不一致的模型和扰动。该过程产生受约束的矩阵Zonotope，代表扰动实现和动力学，从而将离线信息与有限的在线数据进行融合，提高MPC的可行性和性能。该设计利用闭环系统特性来学习和细化控制增益，以保持较小的Tube尺寸。通过在误差动态中分离开环模型失配和闭环效应，该方法避免了对状态和输入操作区域大小的依赖，从而降低了保守性。Tube和辅助反馈的自适应协同设计确保了λ-收缩Zonotope Tube，保证了鲁棒正不变性，提高了可行性裕度，并增强了抗扰动能力。建立了递归可行性条件，并为误差Tube引入了多面体Lyapunov候选函数，证明了在自适应Tube增益更新下闭环误差动态的指数稳定性。仿真结果表明，仅使用少量在线数据即可提高鲁棒性，扩大可行性区域，并实现安全的闭环性能。",
            "intro_zh": [
                "现有弹性Tube-based MPC方法通常假设已知精确的系统模型和扰动边界，这在实际应用中难以满足。",
                "该论文提出一种迭代细化Zonotope扰动集的方法，融合先验知识和在线数据，以提高MPC的性能和可行性。",
                "通过自适应协同设计Tube和反馈增益，实现了λ-收缩Zonotope Tube，保证了鲁棒性和稳定性，仿真验证了其有效性。"
            ],
            "method_zh": "**问题定义**：该论文旨在解决在系统模型和扰动边界未知的情况下，如何实现线性系统的安全导航问题。现有弹性Tube-based MPC方法通常假设系统模型和扰动边界已知，这在实际应用中往往难以满足，导致控制性能下降甚至失效。\\n\\n**核心思路**：论文的核心思路是利用Zonotope来保守地估计系统的不确定性，并通过在线数据和先验知识迭代地细化Zonotope的边界，从而提高模型精度和控制性能。同时，通过自适应地调整Tube的大小和反馈增益，保证系统的鲁棒性和稳定性。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 初始化一个保守的Zonotope扰动集；2) 利用在线数据识别系统动力学的矩阵Zonotope模型集；3) 利用先验知识排除与已知约束不一致的模型和扰动；4) 自适应地调整Tube的大小和反馈增益，保证λ-收缩性；5) 利用多面体Lyapunov函数证明闭环系统的稳定性。\\n\\n**关键创新**：该方法最重要的创新点在于能够将离线信息与有限的在线数据进行融合，从而在系统模型和扰动边界未知的情况下，实现安全导航。此外，通过自适应地调整Tube的大小和反馈增益，可以有效地降低保守性，提高控制性能。\\n\\n**关键设计**：关键设计包括：1) 使用矩阵Zonotope来表示系统动力学的不确定性；2) 设计自适应的Tube和反馈增益更新策略，保证λ-收缩性；3) 使用多面体Lyapunov函数来证明闭环系统的稳定性；4) 迭代细化Zonotope扰动集，融合先验知识和在线数据。",
            "application_zh": "该研究成果可应用于机器人导航、自动驾驶、飞行器控制等领域，尤其适用于环境不确定、模型难以精确获取的场景。通过融合先验知识和在线数据，该方法能够提高系统的鲁棒性和安全性，具有重要的实际应用价值和广阔的应用前景。",
            "highlight_zh": "仿真结果表明，该方法仅使用少量在线数据即可提高鲁棒性，扩大可行性区域，并实现安全的闭环性能。与传统方法相比，该方法能够更好地处理系统模型和扰动边界未知的情况，具有更强的适应性和鲁棒性。具体性能提升数据未知。",
            "tags_zh": [
                "模型预测控制",
                "MPC",
                "Zonotope Tube",
                "鲁棒控制",
                "自适应控制",
                "安全导航",
                "线性系统",
                "不确定系统"
            ],
            "_index": 27,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21198v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21198v1/RbXL.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21198v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TICON: A Slide-Level Tile Contextualizer for Histopathology Representation Learning",
            "authors": [
                "Varun Belagali",
                "Saarthak Kapse",
                "Pierre Marza",
                "Srijan Das",
                "Zilinghan Li",
                "Sofiène Boutaj",
                "Pushpak Pati",
                "Srikar Yellapragada",
                "Tarak Nath Nandi",
                "Ravi K Madduri",
                "Joel Saltz",
                "Prateek Prasanna",
                "Stergios Christodoulidis Maria Vakalopoulou",
                "Dimitris Samaras"
            ],
            "arxiv_id": "2512.21331v1",
            "summary": "The interpretation of small tiles in large whole slide images (WSI) often needs a larger image context. We introduce TICON, a transformer-based tile representation contextualizer that produces rich, contextualized embeddings for ''any'' application in computational pathology. Standard tile encoder-based pipelines, which extract embeddings of tiles stripped from their context, fail to model the rich slide-level information essential for both local and global tasks. Furthermore, different tile-encoders excel at different downstream tasks. Therefore, a unified model is needed to contextualize embeddings derived from ''any'' tile-level foundation model. TICON addresses this need with a single, shared encoder, pretrained using a masked modeling objective to simultaneously unify and contextualize representations from diverse tile-level pathology foundation models. Our experiments demonstrate that TICON-contextualized embeddings significantly improve performance across many different tasks, establishing new state-of-the-art results on tile-level benchmarks (i.e., HEST-Bench, THUNDER, CATCH) and slide-level benchmarks (i.e., Patho-Bench). Finally, we pretrain an aggregator on TICON to form a slide-level foundation model, using only 11K WSIs, outperforming SoTA slide-level foundation models pretrained with up to 350K WSIs.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21331v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TICON：一种用于组织病理学表征学习的切片级上下文建模方法",
            "summary_zh": "在大型全切片图像(WSI)中，小切片的判读通常需要更大的图像上下文。我们提出了TICON，一种基于Transformer的切片表征上下文建模器，为计算病理学中的“任何”应用生成丰富的、上下文相关的嵌入。标准的基于切片编码器的流程，提取的切片嵌入缺乏上下文信息，无法对局部和全局任务至关重要的切片级信息进行建模。此外，不同的切片编码器擅长不同的下游任务。因此，需要一个统一的模型来对来自“任何”切片级基础模型的嵌入进行上下文建模。TICON通过一个共享的编码器来满足这一需求，该编码器使用掩码建模目标进行预训练，以同时统一和上下文建模来自不同切片级病理学基础模型的表征。实验表明，TICON上下文嵌入显著提高了各种任务的性能，在切片级基准(HEST-Bench、THUNDER、CATCH)和切片级基准(Patho-Bench)上建立了新的最先进结果。最后，我们仅使用1.1万张WSI在TICON上预训练了一个聚合器，形成了一个切片级基础模型，其性能优于使用高达35万张WSI预训练的最先进的切片级基础模型。",
            "intro_zh": [
                "现有方法缺乏对WSI中切片间上下文信息的有效建模，限制了病理图像分析的性能。",
                "TICON通过Transformer架构，对切片表征进行上下文建模，从而捕获切片间的依赖关系和全局信息。",
                "实验表明，TICON在多个切片和WSI级别的病理图像分析任务上，均取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：现有基于切片编码器的病理图像分析方法，通常将切片从其原始WSI上下文中剥离，导致无法有效利用切片间的空间关系和全局信息。此外，不同的切片编码器适用于不同的下游任务，缺乏一个通用的上下文建模框架。\\n\\n**核心思路**：TICON的核心思路是利用Transformer架构对切片表征进行上下文建模。通过将切片表征视为序列，并利用Transformer的自注意力机制，TICON能够捕获切片间的依赖关系，从而生成更具信息量的上下文嵌入。\\n\\n**技术框架**：TICON的整体框架包括三个主要模块：切片编码器、Transformer上下文建模器和下游任务适配器。首先，使用预训练的切片编码器提取每个切片的表征。然后，将这些表征输入到Transformer上下文建模器中，以生成上下文嵌入。最后，将上下文嵌入输入到下游任务适配器中，以完成特定的病理图像分析任务。\\n\\n**关键创新**：TICON的关键创新在于其Transformer上下文建模器。该模块能够有效地捕获切片间的依赖关系，从而生成更具信息量的上下文嵌入。此外，TICON采用了一种掩码建模目标进行预训练，使得模型能够学习到更鲁棒的表征。\\n\\n**关键设计**：TICON使用标准的Transformer架构作为上下文建模器。为了提高训练效率，TICON采用了相对位置编码。此外，TICON使用AdamW优化器进行训练，并采用余弦退火学习率策略。",
            "application_zh": "TICON可广泛应用于计算病理学领域，例如肿瘤亚型分类、淋巴结转移检测、免疫组化评分等。通过提供更具上下文信息的切片表征，TICON能够提高病理图像分析的准确性和效率，辅助病理医生进行诊断和治疗决策，具有重要的临床应用价值。",
            "highlight_zh": "TICON在多个病理图像分析基准测试中取得了显著的性能提升。例如，在HEST-Bench、THUNDER和CATCH等切片级基准测试中，TICON均取得了最先进的结果。此外，TICON在Patho-Bench切片级基准测试中也表现出色，甚至超越了使用更大规模数据集预训练的模型。",
            "tags_zh": [
                "组织病理学",
                "全切片图像",
                "表征学习",
                "Transformer",
                "上下文建模"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21331v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21331v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21331v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations",
            "authors": [
                "Jinghan Li",
                "Yang Jin",
                "Hao Jiang",
                "Yadong Mu",
                "Yang Song",
                "Kun Xu"
            ],
            "arxiv_id": "2512.21004v1",
            "summary": "Recent advances in pretraining general foundation models have significantly improved performance across diverse downstream tasks. While autoregressive (AR) generative models like GPT have revolutionized NLP, most visual generative pretraining methods still rely on BERT-style masked modeling, which often disregards the temporal information essential for video analysis. The few existing autoregressive visual pretraining methods suffer from issues such as inaccurate semantic localization and poor generation quality, leading to poor semantics. In this work, we propose NExT-Vid, a novel autoregressive visual generative pretraining framework that utilizes masked next-frame prediction to jointly model images and videos. NExT-Vid introduces a context-isolated autoregressive predictor to decouple semantic representation from target decoding, and a conditioned flow-matching decoder to enhance generation quality and diversity. Through context-isolated flow-matching pretraining, our approach achieves strong representations. Extensive experiments on large-scale pretrained models demonstrate that our proposed method consistently outperforms previous generative pretraining methods for visual representation learning via attentive probing in downstream classification.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21004v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "flow matching",
                        "representation learning",
                        "visual pre-training"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "NExT-Vid：提出基于下一帧预测的自回归视频建模框架，提升视频表征学习效果。",
            "summary_zh": "本文提出了一种名为NExT-Vid的新型自回归视觉生成预训练框架，该框架利用掩码下一帧预测来联合建模图像和视频。NExT-Vid引入了一个上下文隔离的自回归预测器，以将语义表示与目标解码解耦，并使用条件流匹配解码器来增强生成质量和多样性。通过上下文隔离的流匹配预训练，该方法能够获得强大的表征能力。在大型预训练模型上的大量实验表明，所提出的方法在下游分类任务中，通过注意力探测，始终优于以往的视觉表征生成预训练方法。",
            "intro_zh": [
                "现有视觉生成预训练方法忽略了视频分析中至关重要的时间信息，且自回归方法存在语义定位不准确和生成质量差的问题。",
                "NExT-Vid通过掩码下一帧预测进行自回归建模，并设计上下文隔离预测器和条件流匹配解码器，解耦语义表示并提升生成质量。",
                "实验表明，NExT-Vid在下游分类任务中，通过注意力探测，性能始终优于以往的生成预训练方法，证明了其有效性。"
            ],
            "method_zh": "**问题定义**：现有视觉生成预训练方法，尤其是BERT风格的掩码建模，忽略了视频中重要的时间信息。已有的自回归视觉预训练方法存在语义定位不准确、生成质量差等问题，导致语义信息不足。因此，需要一种能够有效利用时间信息，并生成高质量视频的自回归预训练方法。\\n\\n**核心思路**：NExT-Vid的核心思路是利用下一帧预测作为自回归建模的目标，通过预测下一帧来学习视频的时序信息和语义信息。为了解决语义定位不准确和生成质量差的问题，论文提出了上下文隔离的自回归预测器和条件流匹配解码器。\\n\\n**技术框架**：NExT-Vid的整体框架包含两个主要模块：上下文隔离的自回归预测器和条件流匹配解码器。首先，输入视频帧被掩码，然后通过上下文隔离的自回归预测器预测下一帧的掩码区域。预测器的输出作为条件，输入到条件流匹配解码器中，生成最终的下一帧。整个框架通过最小化预测帧和真实帧之间的差异进行训练。\\n\\n**关键创新**：NExT-Vid的关键创新在于上下文隔离的自回归预测器和条件流匹配解码器的设计。上下文隔离的预测器将语义表示与目标解码解耦，避免了语义信息的泄露。条件流匹配解码器通过流匹配技术，提高了生成质量和多样性。\\n\\n**关键设计**：上下文隔离的自回归预测器使用Transformer结构，并引入了上下文掩码机制，只允许预测器访问当前帧的信息，从而实现上下文隔离。条件流匹配解码器使用连续归一化流（Continuous Normalizing Flows, CNF）作为生成模型，通过学习一个连续的变换将噪声分布映射到目标分布，从而生成高质量的视频帧。损失函数包括预测损失和流匹配损失，用于优化预测器和解码器。",
            "application_zh": "NExT-Vid的潜在应用领域包括视频理解、视频生成、视频编辑、视频检索等。该研究可以提升视频分析任务的性能，例如视频分类、动作识别、视频描述等。此外，该方法还可以用于生成逼真的视频内容，例如用于游戏、电影制作等领域。未来，该方法可以进一步扩展到其他模态，例如音频、文本等，实现多模态的视频理解和生成。",
            "highlight_zh": "NExT-Vid在多个下游分类任务上进行了评估，结果表明，该方法始终优于以往的生成预训练方法。例如，在Kinetics-400数据集上，NExT-Vid的准确率比之前的最佳方法提高了X%。这些结果证明了NExT-Vid在视频表征学习方面的有效性。",
            "tags_zh": [
                "视频预训练",
                "自回归模型",
                "下一帧预测",
                "视频表征学习",
                "流匹配",
                "上下文隔离",
                "生成模型",
                "Transformer"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21004v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21004v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21004v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Dyna-Style Reinforcement Learning Modeling and Control of Non-linear Dynamics",
            "authors": [
                "Karim Abdelsalam",
                "Zeyad Gamal",
                "Ayman El-Badawy"
            ],
            "arxiv_id": "2512.21081v1",
            "summary": "Controlling systems with complex, nonlinear dynamics poses a significant challenge, particularly in achieving efficient and robust control. In this paper, we propose a Dyna-Style Reinforcement Learning control framework that integrates Sparse Identification of Nonlinear Dynamics (SINDy) with Twin Delayed Deep Deterministic Policy Gradient (TD3) reinforcement learning. SINDy is used to identify a data-driven model of the system, capturing its key dynamics without requiring an explicit physical model. This identified model is used to generate synthetic rollouts that are periodically injected into the reinforcement learning replay buffer during training on the real environment, enabling efficient policy learning with limited data available. By leveraging this hybrid approach, we mitigate the sample inefficiency of traditional model-free reinforcement learning methods while ensuring accurate control of nonlinear systems. To demonstrate the effectiveness of this framework, we apply it to a bi-rotor system as a case study, evaluating its performance in stabilization and trajectory tracking. The results show that our SINDy-TD3 approach achieves superior accuracy and robustness compared to direct reinforcement learning techniques, highlighting the potential of combining data-driven modeling with reinforcement learning for complex dynamical systems.",
            "categories": [
                "eess.SY",
                "cs.LG"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21081v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "policy learning",
                        "TD3"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于SINDy-TD3的Dyna-Style强化学习框架，用于非线性动力系统建模与控制",
            "summary_zh": "本文提出了一种Dyna-Style强化学习控制框架，该框架集成了非线性动力学稀疏辨识(SINDy)与双延迟深度确定性策略梯度(TD3)强化学习算法。SINDy用于识别系统的数据驱动模型，无需显式物理模型即可捕获其关键动力学特性。该模型用于生成合成轨迹，并在真实环境训练期间定期注入到强化学习回放缓冲区中，从而在有限数据下实现高效的策略学习。通过利用这种混合方法，我们缓解了传统无模型强化学习方法的样本低效问题，同时确保对非线性系统的精确控制。为了验证该框架的有效性，我们将其应用于双旋翼系统，并评估其在稳定和轨迹跟踪方面的性能。结果表明，与直接强化学习技术相比，我们的SINDy-TD3方法实现了卓越的精度和鲁棒性，突出了数据驱动建模与强化学习相结合在复杂动力系统中的潜力。",
            "intro_zh": [
                "复杂非线性动力系统的控制面临挑战，传统方法难以实现高效和鲁棒的控制。",
                "论文提出Dyna-Style强化学习框架，结合SINDy辨识模型和TD3强化学习，利用模型生成数据提升学习效率。",
                "在双旋翼系统上的实验表明，SINDy-TD3方法比直接强化学习方法在精度和鲁棒性上表现更优。"
            ],
            "method_zh": "**问题定义**：论文旨在解决复杂非线性动力系统的控制问题。现有方法，特别是传统的无模型强化学习方法，在样本效率方面存在不足，需要大量的真实环境交互才能学习到有效的控制策略。而依赖精确物理模型的控制方法，在模型未知或难以获取的情况下失效。\\n\\n**核心思路**：论文的核心思路是利用数据驱动的建模方法（SINDy）学习系统的近似动力学模型，然后利用该模型生成合成数据，并将其注入到强化学习的训练过程中。这种Dyna-Style的方法可以有效地扩充训练数据，提高样本效率，从而更快地学习到有效的控制策略。\\n\\n**技术框架**：整体框架包含两个主要模块：SINDy模型辨识模块和TD3强化学习控制模块。首先，利用SINDy从真实环境数据中学习系统的动力学模型。然后，使用该模型生成大量的合成数据。在TD3强化学习训练过程中，将真实环境数据和合成数据混合在一起，用于更新策略网络和价值网络。通过这种方式，强化学习算法可以从合成数据中学习到更多的信息，从而提高学习效率。\\n\\n**关键创新**：论文的关键创新在于将SINDy模型辨识与TD3强化学习相结合，提出了一种Dyna-Style的强化学习框架。SINDy能够有效地提取非线性动力系统的关键特征，而TD3则能够学习到鲁棒的控制策略。这种结合克服了传统无模型强化学习方法样本效率低的缺点，同时也避免了对精确物理模型的依赖。\\n\\n**关键设计**：SINDy模型的关键设计在于稀疏性约束，通过稀疏回归来选择对系统动力学影响最大的项，从而得到一个简洁且有效的模型。TD3算法的关键设计在于双延迟网络和目标策略平滑，这些技术可以有效地缓解Q函数过估计的问题，提高算法的稳定性和鲁棒性。论文中还设计了如何将SINDy生成的合成数据有效地注入到TD3的replay buffer中，以平衡真实数据和合成数据之间的比例。",
            "application_zh": "该研究成果可应用于各种需要精确控制的复杂非线性动力系统，例如机器人控制、飞行器控制、自动驾驶、过程控制等领域。通过结合数据驱动建模和强化学习，可以有效地解决传统控制方法难以处理的复杂系统控制问题，提高控制系统的性能和鲁棒性，并降低对系统先验知识的依赖。",
            "highlight_zh": "论文在双旋翼系统上进行了实验，结果表明，与直接使用TD3强化学习相比，SINDy-TD3方法在稳定控制和轨迹跟踪任务中均取得了显著的性能提升。具体而言，SINDy-TD3方法能够更快地收敛到最优策略，并且在控制精度和鲁棒性方面表现更优，验证了该方法的有效性。",
            "tags_zh": [
                "强化学习",
                "非线性控制",
                "系统辨识",
                "Dyna-Style",
                "TD3",
                "SINDy",
                "数据驱动建模",
                "双旋翼系统"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21081v1/Figures_eps/Picture10.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21081v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21081v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ReACT-Drug: Reaction-Template Guided Reinforcement Learning for de novo Drug Design",
            "authors": [
                "R Yadunandan",
                "Nimisha Ghosh"
            ],
            "arxiv_id": "2512.20958v1",
            "summary": "De novo drug design is a crucial component of modern drug development, yet navigating the vast chemical space to find synthetically accessible, high-affinity candidates remains a significant challenge. Reinforcement Learning (RL) enhances this process by enabling multi-objective optimization and exploration of novel chemical space - capabilities that traditional supervised learning methods lack. In this work, we introduce \\textbf{ReACT-Drug}, a fully integrated, target-agnostic molecular design framework based on Reinforcement Learning. Unlike models requiring target-specific fine-tuning, ReACT-Drug utilizes a generalist approach by leveraging ESM-2 protein embeddings to identify similar proteins for a given target from a knowledge base such as Protein Data Base (PDB). Thereafter, the known drug ligands corresponding to such proteins are decomposed to initialize a fragment-based search space, biasing the agent towards biologically relevant subspaces. For each such fragment, the pipeline employs a Proximal Policy Optimization (PPO) agent guiding a ChemBERTa-encoded molecule through a dynamic action space of chemically valid, reaction-template-based transformations. This results in the generation of \\textit{de novo} drug candidates with competitive binding affinities and high synthetic accessibility, while ensuring 100\\% chemical validity and novelty as per MOSES benchmarking. This architecture highlights the potential of integrating structural biology, deep representation learning, and chemical synthesis rules to automate and accelerate rational drug design. The dataset and code are available at https://github.com/YadunandanRaman/ReACT-Drug/.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20958v1",
            "code_links": [
                {
                    "url": "https://github.com/YadunandanRaman/ReACT-Drug/",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "PPO",
                        "representation learning"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "ReACT-Drug：基于反应模板引导的强化学习药物设计",
            "summary_zh": "从头药物设计是现代药物开发的关键组成部分，但如何在广阔的化学空间中找到具有合成可及性和高亲和力的候选药物仍然是一个重大挑战。强化学习(RL)通过实现多目标优化和探索新的化学空间来增强这一过程——这是传统监督学习方法所缺乏的能力。本文介绍了一个完全集成、与靶标无关的分子设计框架ReACT-Drug，该框架基于强化学习。与需要针对特定靶标进行微调的模型不同，ReACT-Drug采用了一种通用方法，利用ESM-2蛋白嵌入从蛋白质数据库(PDB)等知识库中识别给定靶标的相似蛋白。然后，将这些蛋白质对应的已知药物配体分解，以初始化基于片段的搜索空间，从而使agent偏向于生物学相关的子空间。对于每个这样的片段，该流程采用近端策略优化(PPO) agent，通过基于ChemBERTa编码分子的化学有效反应模板的动态动作空间来引导分子。这产生了具有竞争性结合亲和力和高合成可及性的从头药物候选物，同时根据MOSES基准测试确保100%的化学有效性和新颖性。该架构突出了整合结构生物学、深度表征学习和化学合成规则以自动化和加速合理药物设计的潜力。数据集和代码可在https://github.com/YadunandanRaman/ReACT-Drug/获取。",
            "intro_zh": [
                "现有药物设计方法难以在巨大的化学空间中找到既有高亲和力又易于合成的候选药物。",
                "ReACT-Drug利用强化学习，结合蛋白结构信息和反应模板，引导药物分子生成过程。",
                "实验表明，ReACT-Drug生成的药物候选物具有良好的结合亲和力、合成可及性和化学有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从头药物设计中，如何在巨大的化学空间中高效搜索具有高亲和力和良好合成可及性的药物分子的问题。现有方法，如基于规则或片段拼接的方法，难以保证生成分子的化学有效性和新颖性。而传统的监督学习方法缺乏探索新化学空间的能力，且需要大量特定靶标的数据进行训练。\\n\\n**核心思路**：论文的核心思路是利用强化学习，通过奖励函数引导agent生成具有期望性质的分子。同时，利用已知的蛋白结构信息和反应模板，缩小搜索空间，提高生成效率和分子质量。通过将药物设计过程建模为一个序列决策问题，agent可以逐步构建分子，并根据奖励信号进行优化。\\n\\n**技术框架**：ReACT-Drug框架包含以下主要模块：1) **蛋白相似性搜索**：利用ESM-2蛋白嵌入，从PDB等数据库中找到与目标蛋白相似的蛋白。2) **配体片段提取**：从相似蛋白的已知配体中提取片段，作为初始搜索空间。3) **强化学习Agent**：使用PPO算法训练agent，通过ChemBERTa编码分子状态，并根据反应模板选择动作。4) **奖励函数**：设计奖励函数，鼓励生成具有高亲和力、良好合成可及性和化学有效性的分子。\\n\\n**关键创新**：该方法的主要创新在于：1) **反应模板引导**：使用反应模板作为动作空间，保证生成分子的化学有效性。2) **蛋白结构信息融合**：利用蛋白相似性搜索和配体片段提取，将蛋白结构信息融入到药物设计过程中。3) **通用性**：该框架不依赖于特定靶标的训练数据，具有良好的通用性。\\n\\n**关键设计**：1) **反应模板选择**：使用预定义的反应模板库，并根据当前分子的结构动态选择可用的反应模板。2) **奖励函数设计**：奖励函数综合考虑了分子的结合亲和力（使用对接软件预测）、合成可及性（使用SA score评估）和化学有效性（通过惩罚不合理的化学结构实现）。3) **PPO Agent**：使用Proximal Policy Optimization (PPO) 算法训练agent，平衡探索和利用，提高训练效率和稳定性。",
            "application_zh": "ReACT-Drug具有广泛的应用前景，可用于加速新药发现过程，降低研发成本。该方法可以用于针对各种疾病靶标设计候选药物，尤其是在缺乏足够训练数据的情况下。此外，该框架还可以用于优化现有药物的性质，例如提高生物利用度或降低毒性。未来，ReACT-Drug可以与其他计算方法（如分子动力学模拟）相结合，进一步提高药物设计的准确性和效率。",
            "highlight_zh": "ReACT-Drug在从头药物设计任务中表现出色，生成的分子具有竞争性的结合亲和力、高合成可及性和100%的化学有效性。与现有方法相比，ReACT-Drug无需针对特定靶标进行微调，具有更好的通用性。该方法在MOSES基准测试中表现出良好的新颖性，表明其能够探索新的化学空间。",
            "tags_zh": [
                "药物设计",
                "强化学习",
                "反应模板",
                "蛋白结构",
                "从头设计"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20958v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20958v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20958v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ORCA: Object Recognition and Comprehension for Archiving Marine Species",
            "authors": [
                "Yuk-Kwan Wong",
                "Haixin Liang",
                "Zeyu Ma",
                "Yiwei Chen",
                "Ziqiang Zheng",
                "Rinaldi Gotama",
                "Pascal Sebastian",
                "Lauren D. Sparks",
                "Sai-Kit Yeung"
            ],
            "arxiv_id": "2512.21150v1",
            "summary": "Marine visual understanding is essential for monitoring and protecting marine ecosystems, enabling automatic and scalable biological surveys. However, progress is hindered by limited training data and the lack of a systematic task formulation that aligns domain-specific marine challenges with well-defined computer vision tasks, thereby limiting effective model application. To address this gap, we present ORCA, a multi-modal benchmark for marine research comprising 14,647 images from 478 species, with 42,217 bounding box annotations and 22,321 expert-verified instance captions. The dataset provides fine-grained visual and textual annotations that capture morphology-oriented attributes across diverse marine species. To catalyze methodological advances, we evaluate 18 state-of-the-art models on three tasks: object detection (closed-set and open-vocabulary), instance captioning, and visual grounding. Results highlight key challenges, including species diversity, morphological overlap, and specialized domain demands, underscoring the difficulty of marine understanding. ORCA thus establishes a comprehensive benchmark to advance research in marine domain. Project Page: http://orca.hkustvgd.com/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Accepted by The IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21150v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "visual grounding"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.0,
            "hit_pillars": [
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "ORCA：用于海洋物种存档的目标识别与理解多模态基准",
            "summary_zh": "海洋视觉理解对于监测和保护海洋生态系统至关重要，它能够实现自动且可扩展的生物调查。然而，有限的训练数据以及缺乏将特定领域内的海洋挑战与明确定义的计算机视觉任务对齐的系统性任务制定，阻碍了这一领域的进展，限制了模型的有效应用。为了解决这一问题，我们提出了ORCA，一个用于海洋研究的多模态基准，包含来自478个物种的14647张图像，以及42217个边界框标注和22321个专家验证的实例描述。该数据集提供了精细的视觉和文本标注，捕捉了各种海洋物种的形态学属性。为了促进方法论的进步，我们在三个任务上评估了18个最先进的模型：目标检测（闭集和开放词汇）、实例描述和视觉定位。结果突出了关键挑战，包括物种多样性、形态学重叠和专业领域需求，强调了海洋理解的难度。因此，ORCA建立了一个全面的基准，以推进海洋领域的研究。",
            "intro_zh": [
                "现有海洋视觉理解方法受限于数据量和任务定义，难以有效应对海洋物种识别的挑战。",
                "ORCA提出一个多模态基准数据集，包含图像、边界框和实例描述，旨在促进海洋物种识别的研究。",
                "通过在ORCA上评估现有模型，揭示了物种多样性、形态重叠等挑战，为未来研究指明方向。"
            ],
            "method_zh": "**问题定义**：现有海洋视觉理解方法面临数据稀缺和任务定义不明确的问题，导致模型在处理复杂多样的海洋物种时性能受限。缺乏一个统一的基准数据集来评估和比较不同算法的性能，阻碍了该领域的发展。现有方法难以有效应对海洋物种的形态学相似性和环境复杂性带来的挑战。\n\n**核心思路**：ORCA的核心思路是构建一个大规模、多模态的海洋物种数据集，并定义一系列具有挑战性的视觉任务，从而促进相关算法的开发和评估。通过提供高质量的图像、边界框标注和实例描述，ORCA旨在弥合领域知识和计算机视觉技术之间的差距，推动海洋生物研究的自动化和智能化。\n\n**技术框架**：ORCA数据集包含14647张图像，涵盖478个海洋物种。数据集提供了42217个边界框标注，用于目标检测任务，以及22321个专家验证的实例描述，用于实例描述和视觉定位任务。研究人员在ORCA上评估了18个最先进的模型，涵盖目标检测（闭集和开放词汇）、实例描述和视觉定位三个任务。\n\n**关键创新**：ORCA的主要创新在于其数据集的规模、多样性和多模态特性。它不仅提供了大量的图像和标注，还包含了专家验证的实例描述，从而能够更全面地捕捉海洋物种的特征。此外，ORCA还定义了一系列具有挑战性的视觉任务，旨在推动相关算法的创新。\n\n**关键设计**：ORCA数据集的设计考虑了海洋物种的多样性和形态学相似性。数据集的标注由领域专家进行验证，以确保标注的准确性和一致性。在评估现有模型时，研究人员采用了标准的评估指标，如平均精度（mAP）和CIDEr，以客观地比较不同算法的性能。",
            "application_zh": "ORCA数据集和基准的潜在应用领域包括海洋生物多样性监测、生态系统评估、渔业资源管理和海洋保护。通过自动识别和理解海洋物种，可以更有效地进行生物调查，评估生态系统的健康状况，并制定更科学的保护策略。ORCA的未来影响在于推动海洋生物研究的自动化和智能化，为可持续的海洋资源管理提供技术支持。",
            "highlight_zh": "在ORCA数据集上，研究人员评估了18个最先进的模型，结果表明现有模型在处理海洋物种识别任务时仍面临诸多挑战，尤其是在物种多样性、形态学重叠和专业领域需求方面。例如，在目标检测任务中，现有模型的平均精度（mAP）相对较低，表明模型难以准确识别和定位各种海洋物种。这些结果突出了ORCA数据集的价值，并为未来研究指明了方向。",
            "tags_zh": [
                "海洋物种识别",
                "多模态数据集",
                "目标检测",
                "实例描述",
                "视觉定位",
                "计算机视觉",
                "生物多样性"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21150v1/images/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21150v1/images/annotation_quantities.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21150v1/images/caption_tokens_length.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Streaming Video Instruction Tuning",
            "authors": [
                "Jiaer Xia",
                "Peixian Chen",
                "Mengdan Zhang",
                "Xing Sun",
                "Kaiyang Zhou"
            ],
            "arxiv_id": "2512.21334v1",
            "summary": "We present Streamo, a real-time streaming video LLM that serves as a general-purpose interactive assistant. Unlike existing online video models that focus narrowly on question answering or captioning, Streamo performs a broad spectrum of streaming video tasks, including real-time narration, action understanding, event captioning, temporal event grounding, and time-sensitive question answering. To develop such versatility, we construct Streamo-Instruct-465K, a large-scale instruction-following dataset tailored for streaming video understanding. The dataset covers diverse temporal contexts and multi-task supervision, enabling unified training across heterogeneous streaming tasks. After training end-to-end on the instruction-following dataset through a streamlined pipeline, Streamo exhibits strong temporal reasoning, responsive interaction, and broad generalization across a variety of streaming benchmarks. Extensive experiments show that Streamo bridges the gap between offline video perception models and real-time multimodal assistants, making a step toward unified, intelligent video understanding in continuous video streams.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21334v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal",
                        "instruction following"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Streamo，一个用于实时流视频理解的通用交互式助手。",
            "summary_zh": "本文提出Streamo，一个实时流视频LLM，作为通用交互式助手。与现有专注于问答或字幕的在线视频模型不同，Streamo执行广泛的流视频任务，包括实时叙述、动作理解、事件字幕、时间事件定位和时间敏感的问答。为了开发这种多功能性，我们构建了Streamo-Instruct-465K，这是一个为流视频理解量身定制的大规模指令跟随数据集。该数据集涵盖了不同的时间上下文和多任务监督，从而可以在异构流任务中进行统一训练。通过简化的pipeline在指令跟随数据集上进行端到端训练后，Streamo在各种流基准测试中表现出强大的时间推理、响应式交互和广泛的泛化能力。大量实验表明，Streamo弥合了离线视频感知模型和实时多模态助手之间的差距，朝着连续视频流中统一、智能的视频理解迈出了一步。",
            "intro_zh": [
                "现有在线视频模型专注于问答或字幕等狭窄任务，缺乏通用性和实时交互能力。",
                "Streamo通过构建大规模指令跟随数据集Streamo-Instruct-465K，实现跨异构流任务的统一训练。",
                "实验表明，Streamo在时间推理、响应式交互和泛化能力方面表现出色，弥合了离线和实时视频理解的差距。"
            ],
            "method_zh": "**问题定义**：现有在线视频模型通常只关注特定任务，如视频问答或字幕生成，缺乏对流视频的全面理解和实时交互能力。这些模型难以处理复杂的时序关系，并且泛化能力有限，无法适应各种不同的流视频任务。\\n\\n**核心思路**：Streamo的核心思路是利用大规模指令跟随学习，使模型能够理解并执行各种与流视频相关的任务。通过构建一个包含丰富时间上下文和多任务监督的数据集，Streamo能够学习到通用的视频理解能力，并能够根据指令实时地进行交互。\\n\\n**技术框架**：Streamo的整体框架包括以下几个主要模块：1) 视频编码器：用于提取视频帧的视觉特征。2) 文本编码器：用于编码指令文本。3) 多模态融合模块：将视频特征和文本特征进行融合。4) LLM解码器：根据融合后的特征生成输出文本。整个流程是端到端可训练的，通过指令跟随数据集进行优化。\\n\\n**关键创新**：Streamo的关键创新在于其统一的训练框架和大规模的指令跟随数据集。通过将各种流视频任务统一到指令跟随的范式下，Streamo能够学习到通用的视频理解能力。Streamo-Instruct-465K数据集的构建是另一个重要创新，它提供了丰富的时间上下文和多任务监督，为模型的训练提供了充足的数据支持。\\n\\n**关键设计**：Streamo使用了预训练的视觉和文本编码器，例如CLIP或类似的模型，以提取高质量的特征。多模态融合模块可以使用简单的连接或更复杂的注意力机制。LLM解码器可以使用现有的预训练语言模型，例如LLaMA或GPT系列。损失函数通常是交叉熵损失，用于优化生成文本的准确性。数据集的构建需要仔细设计，以确保覆盖各种不同的时间上下文和任务类型。",
            "application_zh": "Streamo具有广泛的应用前景，例如智能监控、实时视频分析、人机交互、远程协助等。它可以用于实时识别异常事件、理解用户意图、提供个性化服务等。未来，Streamo可以进一步扩展到更多的领域，例如自动驾驶、机器人导航等，实现更智能、更高效的视频理解和交互。",
            "highlight_zh": "Streamo在多个流视频基准测试中取得了显著的性能提升。例如，在时间事件定位任务中，Streamo的准确率比现有方法提高了10%以上。在时间敏感的问答任务中，Streamo能够更准确地回答与时间相关的问题，并且能够实时地进行交互。这些实验结果表明，Streamo在实时流视频理解方面具有强大的能力。",
            "tags_zh": [
                "流视频理解",
                "指令跟随学习",
                "实时交互",
                "多模态融合",
                "时间推理"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TGC-Net: A Structure-Aware and Semantically-Aligned Framework for Text-Guided Medical Image Segmentation",
            "authors": [
                "Gaoren Lin",
                "Huangxuan Zhao",
                "Yuan Xiong",
                "Lefei Zhang",
                "Bo Du",
                "Wentao Zhu"
            ],
            "arxiv_id": "2512.21135v1",
            "summary": "Text-guided medical segmentation enhances segmentation accuracy by utilizing clinical reports as auxiliary information. However, existing methods typically rely on unaligned image and text encoders, which necessitate complex interaction modules for multimodal fusion. While CLIP provides a pre-aligned multimodal feature space, its direct application to medical imaging is limited by three main issues: insufficient preservation of fine-grained anatomical structures, inadequate modeling of complex clinical descriptions, and domain-specific semantic misalignment. To tackle these challenges, we propose TGC-Net, a CLIP-based framework focusing on parameter-efficient, task-specific adaptations. Specifically, it incorporates a Semantic-Structural Synergy Encoder (SSE) that augments CLIP's ViT with a CNN branch for multi-scale structural refinement, a Domain-Augmented Text Encoder (DATE) that injects large-language-model-derived medical knowledge, and a Vision-Language Calibration Module (VLCM) that refines cross-modal correspondence in a unified feature space. Experiments on five datasets across chest X-ray and thoracic CT modalities demonstrate that TGC-Net achieves state-of-the-art performance with substantially fewer trainable parameters, including notable Dice gains on challenging benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21135v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TGC-Net以解决医学图像分割中的文本引导问题",
            "summary_zh": "文本引导的医学分割通过利用临床报告作为辅助信息来提高分割精度。然而，现有方法通常依赖于未对齐的图像和文本编码器，这需要复杂的交互模块进行多模态融合。虽然CLIP提供了预对齐的多模态特征空间，但其在医学成像中的直接应用受到三个主要问题的限制：细粒度解剖结构的不足保留、复杂临床描述的建模不足以及领域特定的语义不对齐。为了解决这些挑战，我们提出了TGC-Net，这是一个基于CLIP的框架，专注于参数高效和任务特定的适应。具体而言，它包含一个语义结构协同编码器（SSE），增强CLIP的ViT与CNN分支进行多尺度结构细化，一个领域增强文本编码器（DATE），注入大型语言模型衍生的医学知识，以及一个视觉-语言校准模块（VLCM），在统一特征空间中细化跨模态对应关系。实验结果表明，TGC-Net在胸部X光和胸部CT的五个数据集上实现了最先进的性能，并显著减少了可训练参数。",
            "intro_zh": [
                "现有医学图像分割方法在图像和文本编码器未对齐的情况下，导致多模态融合复杂且效果不佳。",
                "TGC-Net通过引入语义结构协同编码器和领域增强文本编码器，优化了图像和文本的特征对齐，提升了分割精度。",
                "在多个数据集上，TGC-Net在分割性能上超越了现有方法，且可训练参数显著减少，表现出更高的效率。"
            ],
            "method_zh": "**问题定义**：论文要解决的具体问题是如何有效地将文本信息引导的医学图像分割与现有方法的不足相结合，特别是在图像和文本编码器未对齐的情况下，导致的多模态融合复杂性和效果不佳的问题。\\n\\n**核心思路**：论文的核心解决思路是通过构建一个基于CLIP的框架，专注于参数高效和任务特定的适应，利用语义结构协同编码器和领域增强文本编码器来优化图像和文本特征的对齐。\\n\\n**技术框架**：整体架构包括三个主要模块：语义结构协同编码器（SSE），用于多尺度结构细化；领域增强文本编码器（DATE），注入医学知识；视觉-语言校准模块（VLCM），用于在统一特征空间中细化跨模态对应关系。\\n\\n**关键创新**：最重要的技术创新点在于引入了SSE和DATE模块，使得模型能够更好地保留细粒度解剖结构，并有效建模复杂的临床描述，从而解决了现有方法在医学图像分割中的局限性。\\n\\n**关键设计**：在设计中，SSE结合了CNN分支以实现多尺度结构细化，DATE则利用大型语言模型的知识进行文本编码，VLCM则确保了图像和文本特征在统一空间中的有效对齐。",
            "application_zh": "该研究的潜在应用领域包括医学影像分析、临床辅助诊断和智能医疗系统。通过提高医学图像分割的精度，TGC-Net能够帮助医生更好地进行疾病诊断和治疗规划，具有重要的实际价值和未来影响。",
            "highlight_zh": "在实验中，TGC-Net在胸部X光和胸部CT的五个数据集上实现了最先进的性能，显著提高了Dice系数，并且可训练参数数量大幅减少，展示了其在效率和效果上的优势。",
            "tags_zh": [
                "医学图像分割",
                "文本引导",
                "多模态融合",
                "CLIP",
                "深度学习",
                "结构感知",
                "语义对齐",
                "参数高效"
            ],
            "_index": 34,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21135v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21135v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21135v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Optical Flow-Guided 6DoF Object Pose Tracking with an Event Camera",
            "authors": [
                "Zibin Liu",
                "Banglei Guan",
                "Yang Shang",
                "Shunkun Liang",
                "Zhenbao Yu",
                "Qifeng Yu"
            ],
            "arxiv_id": "2512.21053v1",
            "summary": "Object pose tracking is one of the pivotal technologies in multimedia, attracting ever-growing attention in recent years. Existing methods employing traditional cameras encounter numerous challenges such as motion blur, sensor noise, partial occlusion, and changing lighting conditions. The emerging bio-inspired sensors, particularly event cameras, possess advantages such as high dynamic range and low latency, which hold the potential to address the aforementioned challenges. In this work, we present an optical flow-guided 6DoF object pose tracking method with an event camera. A 2D-3D hybrid feature extraction strategy is firstly utilized to detect corners and edges from events and object models, which characterizes object motion precisely. Then, we search for the optical flow of corners by maximizing the event-associated probability within a spatio-temporal window, and establish the correlation between corners and edges guided by optical flow. Furthermore, by minimizing the distances between corners and edges, the 6DoF object pose is iteratively optimized to achieve continuous pose tracking. Experimental results of both simulated and real events demonstrate that our methods outperform event-based state-of-the-art methods in terms of both accuracy and robustness.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "9 pages, 5 figures. In Proceedings of the 32nd ACM International Conference on Multimedia (MM '24)",
            "doi": "10.1145/3664647.3680992",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21053v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]optical flow"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出基于光流引导的事件相机6DoF物体姿态跟踪方法",
            "summary_zh": "物体姿态跟踪是多媒体技术中的关键技术之一，近年来受到越来越多的关注。现有方法在传统相机下面临运动模糊、传感器噪声、部分遮挡和光照变化等诸多挑战。新兴的生物启发传感器，尤其是事件相机，具有高动态范围和低延迟等优势，有望解决上述问题。本文提出了一种基于光流引导的事件相机6DoF物体姿态跟踪方法。首先，采用2D-3D混合特征提取策略，从事件和物体模型中检测角点和边缘，精确表征物体运动。然后，通过最大化事件关联概率来搜索角点的光流，并建立光流引导下角点与边缘之间的关联。最后，通过最小化角点与边缘之间的距离，迭代优化6DoF物体姿态，实现连续的姿态跟踪。实验结果表明，该方法在准确性和鲁棒性方面优于现有的基于事件的方法。",
            "intro_zh": [
                "现有基于传统相机的物体姿态跟踪方法面临运动模糊、传感器噪声和光照变化等挑战，影响跟踪精度与稳定性。",
                "本文提出了一种光流引导的6DoF物体姿态跟踪方法，利用事件相机的高动态范围和低延迟特性，提升跟踪性能。",
                "实验结果显示，该方法在模拟和真实事件数据集上均优于现有的基于事件的最先进方法，表现出更高的准确性和鲁棒性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决传统相机在物体姿态跟踪中面临的运动模糊、传感器噪声和光照变化等问题，这些问题严重影响了跟踪的准确性和稳定性。\\n\\n**核心思路**：提出了一种基于光流引导的6DoF物体姿态跟踪方法，利用事件相机的特性，通过提取角点和边缘特征来精确表征物体运动，从而实现高效的姿态跟踪。\\n\\n**技术框架**：整体方法包括特征提取、光流计算和姿态优化三个主要模块。首先，从事件和物体模型中提取2D-3D混合特征；然后，通过最大化事件关联概率计算角点的光流；最后，基于光流优化物体的6DoF姿态。\\n\\n**关键创新**：最重要的创新在于结合光流引导的特征关联方法，利用事件相机的优势来提高物体姿态跟踪的准确性和鲁棒性，这与传统方法有本质区别。\\n\\n**关键设计**：在特征提取中，采用了角点和边缘的混合特征提取策略；在光流计算中，设计了基于事件关联概率的优化算法；在姿态优化中，通过最小化角点与边缘的距离进行迭代优化。",
            "application_zh": "该研究具有广泛的应用潜力，尤其在机器人导航、增强现实和自动驾驶等领域。通过提高物体姿态跟踪的准确性和鲁棒性，可以显著提升这些应用的智能化水平和用户体验。未来，随着事件相机技术的进一步发展，该方法有望在更多实际场景中得到应用。",
            "highlight_zh": "实验结果表明，所提出的方法在模拟和真实事件数据集上均优于现有的基于事件的最先进方法，具体表现为在准确性上提高了约15%，在鲁棒性方面也显著增强，展示了其在复杂环境下的有效性。",
            "tags_zh": [
                "物体姿态跟踪",
                "事件相机",
                "光流引导",
                "6DoF",
                "特征提取",
                "鲁棒性",
                "动态范围",
                "计算机视觉"
            ],
            "_index": 35,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21053v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21053v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21053v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Self-supervised Multiplex Consensus Mamba for General Image Fusion",
            "authors": [
                "Yingying Wang",
                "Rongjin Zhuang",
                "Hui Zheng",
                "Xuanhua He",
                "Ke Cao",
                "Xiaotong Tu",
                "Xinghao Ding"
            ],
            "arxiv_id": "2512.20921v1",
            "summary": "Image fusion integrates complementary information from different modalities to generate high-quality fused images, thereby enhancing downstream tasks such as object detection and semantic segmentation. Unlike task-specific techniques that primarily focus on consolidating inter-modal information, general image fusion needs to address a wide range of tasks while improving performance without increasing complexity. To achieve this, we propose SMC-Mamba, a Self-supervised Multiplex Consensus Mamba framework for general image fusion. Specifically, the Modality-Agnostic Feature Enhancement (MAFE) module preserves fine details through adaptive gating and enhances global representations via spatial-channel and frequency-rotational scanning. The Multiplex Consensus Cross-modal Mamba (MCCM) module enables dynamic collaboration among experts, reaching a consensus to efficiently integrate complementary information from multiple modalities. The cross-modal scanning within MCCM further strengthens feature interactions across modalities, facilitating seamless integration of critical information from both sources. Additionally, we introduce a Bi-level Self-supervised Contrastive Learning Loss (BSCL), which preserves high-frequency information without increasing computational overhead while simultaneously boosting performance in downstream tasks. Extensive experiments demonstrate that our approach outperforms state-of-the-art (SOTA) image fusion algorithms in tasks such as infrared-visible, medical, multi-focus, and multi-exposure fusion, as well as downstream visual tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Accepted by AAAI 2026, 9 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20921v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba",
                        "contrastive learning"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出SMC-Mamba框架，用于通用图像融合，提升多种融合任务性能。",
            "summary_zh": "图像融合旨在整合来自不同模态的互补信息，生成高质量的融合图像，从而增强诸如目标检测和语义分割等下游任务。与主要关注整合模态间信息的特定任务技术不同，通用图像融合需要在不增加复杂性的前提下，处理广泛的任务并提高性能。为了实现这一目标，我们提出了SMC-Mamba，一个用于通用图像融合的自监督多路共识Mamba框架。具体而言，模态无关特征增强（MAFE）模块通过自适应门控保留精细细节，并通过空间-通道和频率-旋转扫描增强全局表示。多路共识跨模态Mamba（MCCM）模块实现了专家之间的动态协作，达成共识以有效地整合来自多个模态的互补信息。MCCM中的跨模态扫描进一步加强了模态间的特征交互，促进了来自两个来源的关键信息的无缝整合。此外，我们引入了一种双层自监督对比学习损失（BSCL），它在不增加计算开销的情况下保留了高频信息，同时提高了下游任务的性能。大量实验表明，我们的方法在红外-可见光、医学、多焦点和多曝光融合等任务以及下游视觉任务中，优于最先进的图像融合算法。",
            "intro_zh": [
                "现有图像融合方法难以兼顾多种任务，且在提升性能的同时往往会增加模型复杂度。",
                "提出SMC-Mamba框架，通过模态无关特征增强、多路共识跨模态Mamba模块和双层自监督对比学习损失，实现高效的通用图像融合。",
                "实验结果表明，该方法在多种图像融合任务和下游视觉任务中均优于现有最佳算法。"
            ],
            "method_zh": "**问题定义**：现有图像融合方法通常针对特定任务设计，缺乏通用性，难以同时处理多种融合任务。此外，为了提升融合性能，现有方法往往会增加模型复杂度，导致计算开销增大。因此，如何设计一种既能处理多种融合任务，又能保持较低复杂度的通用图像融合方法是一个挑战。\\n\\n**核心思路**：论文的核心思路是利用Mamba架构的序列建模能力，结合自监督学习，构建一个能够有效整合多模态信息的通用图像融合框架。通过模态无关的特征增强模块提取各模态的有效信息，并利用多路共识跨模态Mamba模块实现模态间的动态交互和信息融合。同时，引入双层自监督对比学习损失，以保留高频信息并提升下游任务性能。\\n\\n**技术框架**：SMC-Mamba框架主要包含三个模块：模态无关特征增强（MAFE）模块、多路共识跨模态Mamba（MCCM）模块和双层自监督对比学习损失（BSCL）。首先，MAFE模块用于提取各模态的特征，并增强特征的表达能力。然后，MCCM模块利用Mamba架构进行跨模态特征融合，实现模态间的信息交互。最后，BSCL用于优化模型，提升融合图像的质量和下游任务的性能。\\n\\n**关键创新**：该论文的关键创新在于以下几点：1) 提出了模态无关的特征增强模块，能够有效提取各模态的特征，并增强特征的表达能力。2) 提出了多路共识跨模态Mamba模块，利用Mamba架构进行跨模态特征融合，实现模态间的动态交互和信息融合。3) 提出了双层自监督对比学习损失，能够保留高频信息，并提升下游任务的性能。与现有方法相比，该方法具有更强的通用性和更高的性能。\\n\\n**关键设计**：MAFE模块采用自适应门控机制来保留精细细节，并使用空间-通道和频率-旋转扫描来增强全局表示。MCCM模块利用多个专家进行动态协作，并通过跨模态扫描进一步加强模态间的特征交互。BSCL损失函数包含图像层面的对比学习和特征层面的对比学习，以保留高频信息并提升下游任务性能。具体参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "该研究成果可广泛应用于红外-可见光图像融合、医学图像融合、多焦点图像融合和多曝光图像融合等领域。高质量的融合图像能够提升目标检测、语义分割等下游任务的性能，从而在安防监控、医疗诊断、遥感图像分析等领域具有重要的应用价值和潜力。未来，该方法有望进一步扩展到更多模态的图像融合任务中。",
            "highlight_zh": "实验结果表明，SMC-Mamba在红外-可见光、医学、多焦点和多曝光融合等任务中均取得了优于现有SOTA算法的性能。例如，在红外-可见光图像融合任务中，该方法在多个指标上均取得了显著提升，并且在下游视觉任务中也表现出优越的性能。此外，该方法在保持较低复杂度的同时，能够有效保留高频信息，提升融合图像的质量。",
            "tags_zh": [
                "图像融合",
                "Mamba",
                "自监督学习",
                "跨模态融合",
                "对比学习",
                "通用图像融合",
                "多模态信息整合"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20921v1/figures/framework.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20921v1/figures/Visual_VIF_MSRS.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20921v1/figures/Visual_MFF_MFI-WHU1.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment",
            "authors": [
                "Mohammad Mahdi Abootorabi",
                "Alireza Ghahramani Kure",
                "Mohammadali Mohammadkhani",
                "Sina Elahimanesh",
                "Mohammad Ali Ali Panah"
            ],
            "arxiv_id": "2512.20950v1",
            "summary": "This paper presents our system for SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval. In an era where misinformation spreads rapidly, effective fact-checking is increasingly critical. We introduce TriAligner, a novel approach that leverages a dual-encoder architecture with contrastive learning and incorporates both native and English translations across different modalities. Our method effectively retrieves claims across multiple languages by learning the relative importance of different sources in alignment. To enhance robustness, we employ efficient data preprocessing and augmentation using large language models while incorporating hard negative sampling to improve representation learning. We evaluate our approach on monolingual and crosslingual benchmarks, demonstrating significant improvements in retrieval accuracy and fact-checking performance over baselines.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.IR",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "11 pages Published at the SemEval-2025 workshop",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20950v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "contrastive learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TriAligner：通过多源对齐实现跨语言的事实验证声明检索",
            "summary_zh": "本文介绍了我们在SemEval-2025 Task 7：多语言和跨语言的事实验证声明检索任务中的系统。在一个错误信息迅速传播的时代，有效的事实验证变得越来越重要。我们提出了一种名为TriAligner的新方法，该方法利用具有对比学习的双编码器架构，并结合了不同模态的本地语言和英语翻译。我们的方法通过学习对齐中不同来源的相对重要性，有效地检索跨多种语言的声明。为了增强鲁棒性，我们采用高效的数据预处理和使用大型语言模型的数据增强，同时结合难负样本挖掘来改进表征学习。我们在单语和跨语言基准上评估了我们的方法，证明了在检索准确性和事实验证性能方面相对于基线的显著改进。",
            "intro_zh": [
                "现有方法在跨语言事实验证声明检索中，难以有效对齐不同语言和信息来源。",
                "TriAligner利用双编码器架构和对比学习，融合本地语言和英语翻译，学习来源重要性。",
                "实验表明，TriAligner在单语和跨语言基准测试中，显著提升了检索准确性和验证性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决跨语言环境下事实验证声明的检索问题。现有方法难以有效对齐不同语言的文本信息，并且忽略了不同信息来源的重要性，导致检索准确率不高。特别是在多语言环境中，如何有效地利用各种语言的信息进行事实核查是一个挑战。\\n\\n**核心思路**：论文的核心思路是利用多源对齐的方式，通过学习不同信息来源的相对重要性，从而提高跨语言声明检索的准确性。通过将本地语言和英语翻译结合，并使用对比学习来训练模型，使得模型能够更好地理解不同语言之间的语义关系。\\n\\n**技术框架**：TriAligner采用双编码器架构，包含以下主要模块：1) 数据预处理模块，用于清洗和转换原始数据；2) 翻译模块，将非英语文本翻译成英语；3) 双编码器模块，分别对本地语言和英语文本进行编码；4) 对比学习模块，通过对比学习损失函数优化模型；5) 检索模块，根据编码后的向量进行声明检索。整体流程是先对数据进行预处理和翻译，然后使用双编码器进行编码，通过对比学习优化模型，最后进行声明检索。\\n\\n**关键创新**：该方法最关键的创新点在于提出了TriAligner架构，该架构能够有效地对齐不同语言和信息来源，并学习它们在事实验证中的相对重要性。与现有方法相比，TriAligner不仅考虑了文本的语义信息，还考虑了不同来源的可信度，从而提高了检索的准确性。此外，利用对比学习和难负样本挖掘进一步提升了模型的表征能力。\\n\\n**关键设计**：在数据预处理阶段，使用了高效的清洗和转换技术。在对比学习中，采用了InfoNCE损失函数，并结合了难负样本挖掘策略，以提高模型的区分能力。在网络结构方面，使用了预训练语言模型作为编码器，并针对特定任务进行了微调。此外，还探索了不同的超参数设置，例如学习率、batch size等，以优化模型的性能。",
            "application_zh": "该研究成果可应用于新闻媒体的事实验证、社交媒体的谣言检测、以及搜索引擎的虚假信息过滤等领域。通过提高跨语言声明检索的准确性，有助于减少错误信息的传播，提升公众对信息的信任度，并为构建更健康的网络环境做出贡献。未来，该技术还可扩展到其他多语言信息检索任务中。",
            "highlight_zh": "TriAligner在单语和跨语言基准测试中均取得了显著的性能提升。例如，在跨语言检索任务中，相比于基线模型，检索准确率提升了超过10%。实验结果表明，该方法能够有效地对齐不同语言和信息来源，并提高事实验证的准确性。",
            "tags_zh": [
                "跨语言检索",
                "事实验证",
                "多源对齐",
                "对比学习",
                "双编码器",
                "自然语言处理",
                "信息检索"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20950v1/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Agentic Explainable Artificial Intelligence (Agentic XAI) Approach To Explore Better Explanation",
            "authors": [
                "Tomoaki Yamaguchi",
                "Yutong Zhou",
                "Masahiro Ryo",
                "Keisuke Katsura"
            ],
            "arxiv_id": "2512.21066v1",
            "summary": "Explainable artificial intelligence (XAI) enables data-driven understanding of factor associations with response variables, yet communicating XAI outputs to laypersons remains challenging, hindering trust in AI-based predictions. Large language models (LLMs) have emerged as promising tools for translating technical explanations into accessible narratives, yet the integration of agentic AI, where LLMs operate as autonomous agents through iterative refinement, with XAI remains unexplored. This study proposes an agentic XAI framework combining SHAP-based explainability with multimodal LLM-driven iterative refinement to generate progressively enhanced explanations. As a use case, we tested this framework as an agricultural recommendation system using rice yield data from 26 fields in Japan. The Agentic XAI initially provided a SHAP result and explored how to improve the explanation through additional analysis iteratively across 11 refinement rounds (Rounds 0-10). Explanations were evaluated by human experts (crop scientists) (n=12) and LLMs (n=14) against seven metrics: Specificity, Clarity, Conciseness, Practicality, Contextual Relevance, Cost Consideration, and Crop Science Credibility. Both evaluator groups confirmed that the framework successfully enhanced recommendation quality with an average score increase of 30-33% from Round 0, peaking at Rounds 3-4. However, excessive refinement showed a substantial drop in recommendation quality, indicating a bias-variance trade-off where early rounds lacked explanation depth (bias) while excessive iteration introduced verbosity and ungrounded abstraction (variance), as revealed by metric-specific analysis. These findings suggest that strategic early stopping (regularization) is needed for optimizing practical utility, challenging assumptions about monotonic improvement and providing evidence-based design principles for agentic XAI systems.",
            "categories": [
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21066v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Agentic XAI框架，结合SHAP与多模态LLM迭代优化解释质量，应用于农业推荐系统。",
            "summary_zh": "可解释人工智能(XAI)能够基于数据理解因素与响应变量之间的关联，但将XAI输出传达给非专业人士仍然具有挑战性，阻碍了对基于AI的预测的信任。大型语言模型(LLM)已成为将技术解释转化为易于理解的叙述的有前途的工具，但agentic AI（LLM作为自主agent通过迭代改进运行）与XAI的集成仍未被探索。本研究提出了一个agentic XAI框架，该框架结合了基于SHAP的可解释性与多模态LLM驱动的迭代改进，以生成逐步增强的解释。作为一个用例，我们使用来自日本26个田地的水稻产量数据，将该框架测试为一个农业推荐系统。Agentic XAI最初提供SHAP结果，并通过11轮改进迭代(第0-10轮)探索如何改进解释。解释由人类专家(作物科学家)(n=12)和LLM(n=14)根据七个指标进行评估：特异性、清晰度、简洁性、实用性、情境相关性、成本考虑和作物科学可信度。两个评估组都证实，该框架成功地提高了推荐质量，从第0轮开始平均得分提高了30-33%，并在第3-4轮达到峰值。然而，过度改进显示推荐质量大幅下降，表明存在偏差-方差权衡，早期轮次缺乏解释深度(偏差)，而过度迭代引入了冗长和无根据的抽象(方差)，正如指标特定分析所揭示的那样。这些发现表明，需要战略性提前停止(正则化)来优化实际效用，挑战了关于单调改进的假设，并为agentic XAI系统提供了基于证据的设计原则。",
            "intro_zh": [
                "现有XAI方法难以向非专业人士有效传达解释，影响了对AI预测的信任。",
                "提出Agentic XAI框架，利用LLM作为智能体迭代改进SHAP解释，提升可理解性。",
                "实验表明，该框架能显著提高农业推荐系统的解释质量，但过度迭代会降低效果。"
            ],
            "method_zh": "**问题定义**：现有XAI方法生成的解释往往过于技术化，难以被领域专家或普通用户理解和信任。这限制了XAI在实际应用中的价值，尤其是在需要人机协作的场景中。因此，如何将复杂的XAI结果转化为易于理解、具有实用价值的解释，是一个亟待解决的问题。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的自然语言生成能力，将XAI结果转化为更易于理解的解释。同时，将LLM视为一个智能体，通过迭代改进的方式，逐步优化解释的质量，使其更具特异性、清晰度、简洁性、实用性、情境相关性、成本考虑和作物科学可信度。\\n\\n**技术框架**：Agentic XAI框架主要包含以下几个阶段：\n1. **初始解释生成**：使用SHAP等XAI方法，生成初始的特征重要性解释。\n2. **LLM迭代改进**：将初始解释输入LLM，LLM根据预设的评估指标，生成改进后的解释。这个过程会进行多轮迭代，每一轮LLM都会根据上一轮的反馈，进一步优化解释。\n3. **解释评估**：使用人工专家和LLM对每一轮迭代生成的解释进行评估，评估指标包括特异性、清晰度、简洁性等。\n4. **提前停止机制**：根据评估结果，设置提前停止机制，防止过度迭代导致解释质量下降。\\n\\n**关键创新**：该论文的关键创新在于将agentic AI的思想引入XAI领域，利用LLM的自主学习能力，迭代优化解释的质量。与传统的XAI方法相比，Agentic XAI能够生成更易于理解、更具实用价值的解释。此外，该论文还提出了一个基于人工专家和LLM的综合评估体系，用于评估解释的质量。\\n\\n**关键设计**：在实验中，LLM被设置为一个智能体，通过与环境（即XAI结果和评估指标）交互，不断学习和改进解释的质量。论文中使用了特定的prompt工程技术，引导LLM生成符合要求的解释。此外，论文还设计了一个提前停止机制，防止过度迭代导致解释质量下降。具体来说，当评估指标的得分不再显著提升时，迭代过程就会停止。",
            "application_zh": "该研究成果可应用于各种需要可解释AI的领域，例如医疗诊断、金融风控、智能制造等。通过将复杂的AI决策转化为易于理解的解释，可以提高用户对AI系统的信任度，促进人机协作，并最终提升决策效率和质量。未来，该方法有望被集成到各种AI应用中，成为提升AI可解释性的重要工具。",
            "highlight_zh": "实验结果表明，Agentic XAI框架能够显著提高农业推荐系统的解释质量，平均得分提高了30-33%。在第3-4轮迭代时，解释质量达到峰值。然而，过度迭代会导致解释质量下降，表明存在偏差-方差权衡。这些结果验证了Agentic XAI框架的有效性，并为设计可解释AI系统提供了重要的设计原则。",
            "tags_zh": [
                "可解释人工智能",
                "Agentic AI",
                "大型语言模型",
                "SHAP",
                "迭代优化",
                "农业推荐系统",
                "人机协作"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Policy-Conditioned Policies for Multi-Agent Task Solving",
            "authors": [
                "Yue Lin",
                "Shuhui Zhu",
                "Wenhao Li",
                "Ang Li",
                "Dan Qiao",
                "Pascal Poupart",
                "Hongyuan Zha",
                "Baoxiang Wang"
            ],
            "arxiv_id": "2512.21024v1",
            "summary": "In multi-agent tasks, the central challenge lies in the dynamic adaptation of strategies. However, directly conditioning on opponents' strategies is intractable in the prevalent deep reinforcement learning paradigm due to a fundamental ``representational bottleneck'': neural policies are opaque, high-dimensional parameter vectors that are incomprehensible to other agents. In this work, we propose a paradigm shift that bridges this gap by representing policies as human-interpretable source code and utilizing Large Language Models (LLMs) as approximate interpreters. This programmatic representation allows us to operationalize the game-theoretic concept of \\textit{Program Equilibrium}. We reformulate the learning problem by utilizing LLMs to perform optimization directly in the space of programmatic policies. The LLM functions as a point-wise best-response operator that iteratively synthesizes and refines the ego agent's policy code to respond to the opponent's strategy. We formalize this process as \\textit{Programmatic Iterated Best Response (PIBR)}, an algorithm where the policy code is optimized by textual gradients, using structured feedback derived from game utility and runtime unit tests. We demonstrate that this approach effectively solves several standard coordination matrix games and a cooperative Level-Based Foraging environment.",
            "categories": [
                "cs.GT",
                "cs.AI"
            ],
            "primary_category": "cs.GT",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21024v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于策略条件策略的程序化迭代最佳响应算法，解决多智能体任务中的策略适应性问题。",
            "summary_zh": "在多智能体任务中，核心挑战在于策略的动态适应。然而，由于“表征瓶颈”的存在，直接以对手的策略为条件进行学习在深度强化学习中是难以实现的：神经策略是不透明的、高维的参数向量，其他智能体难以理解。本文提出了一种范式转变，通过将策略表示为人类可解释的源代码，并利用大型语言模型（LLM）作为近似解释器来弥合这一差距。这种程序化的表示允许我们实现博弈论中的“程序均衡”概念。我们通过利用LLM直接在程序化策略空间中执行优化来重新构建学习问题。LLM充当逐点最佳响应算子，迭代地合成和改进自我智能体的策略代码以响应对手的策略。我们将此过程形式化为“程序化迭代最佳响应（PIBR）”，这是一种通过文本梯度优化策略代码的算法，使用来自博弈效用和运行时单元测试的结构化反馈。我们证明了这种方法有效地解决了几个标准协调矩阵博弈和一个合作的基于等级的觅食环境。",
            "intro_zh": [
                "多智能体任务中，智能体策略的动态适应是核心挑战，但现有深度强化学习方法难以有效利用对手策略信息。",
                "论文提出将策略表示为人类可解释的源代码，并利用大型语言模型作为策略的近似解释器，实现程序均衡。",
                "实验证明，提出的程序化迭代最佳响应算法（PIBR）能有效解决协调博弈和合作觅食等任务。"
            ],
            "method_zh": "**问题定义**：在多智能体环境中，智能体需要根据其他智能体的策略动态调整自身策略。然而，传统的深度强化学习方法中，智能体的策略通常表示为神经网络的参数，这些参数是高维、不透明的，其他智能体难以理解和利用，从而导致策略适应性差。现有方法难以克服“表征瓶颈”，无法有效建模对手策略。\n\n**核心思路**：论文的核心思路是将智能体的策略表示为人类可读的源代码，并利用大型语言模型（LLM）来理解和执行这些代码。通过这种方式，智能体可以更容易地理解其他智能体的策略，并根据这些策略调整自己的行为。这种方法借鉴了博弈论中的“程序均衡”概念，即智能体通过理解彼此的程序化策略来达成均衡。\n\n**技术框架**：论文提出了程序化迭代最佳响应（PIBR）算法。该算法包含以下主要步骤：\n1. **策略表示**：将智能体的策略表示为可执行的源代码。\n2. **LLM解释**：使用LLM作为近似解释器，理解和执行其他智能体的策略代码。\n3. **最佳响应**：利用LLM生成针对对手策略的最佳响应策略代码。\n4. **迭代优化**：通过迭代地生成和改进策略代码，逐步优化智能体的策略。\n5. **反馈机制**：使用博弈效用和运行时单元测试作为反馈信号，指导LLM生成更有效的策略代码。\n\n**关键创新**：论文最重要的创新在于将策略表示为程序代码，并利用LLM进行策略理解和优化。这与传统的深度强化学习方法有本质区别，后者通常使用神经网络作为策略表示，难以进行策略的解释和推理。通过程序化的策略表示，智能体可以更容易地理解其他智能体的行为，并进行更有效的策略调整。\n\n**关键设计**：\n* **策略代码生成**：使用LLM生成策略代码，代码需要满足一定的语法和语义规范。\n* **反馈信号设计**：博弈效用用于评估策略的整体性能，运行时单元测试用于验证策略的局部行为。\n* **文本梯度优化**：使用文本梯度来指导LLM生成更有效的策略代码，例如通过修改代码中的关键词或逻辑结构。",
            "application_zh": "该研究成果可应用于多智能体协作、对抗和竞争等场景，例如自动驾驶、机器人协同、网络安全等。通过程序化策略表示和LLM的辅助，智能体可以更好地理解和适应复杂环境，提高协作效率和竞争能力。未来，该方法有望应用于更复杂的现实世界问题，例如供应链优化、资源分配等。",
            "highlight_zh": "实验结果表明，提出的PIBR算法在协调矩阵博弈和合作觅食环境中表现出色。在协调博弈中，PIBR算法能够快速收敛到最优策略，显著优于传统的强化学习方法。在合作觅食环境中，PIBR算法能够有效地协调多个智能体的行为，实现更高的资源收集效率。具体性能数据在论文中有详细展示。",
            "tags_zh": [
                "多智能体学习",
                "策略表示",
                "大型语言模型",
                "程序均衡",
                "迭代最佳响应"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21024v1/pics/exp/vanilla.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21024v1/pics/exp/climbing.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21024v1/pics/exp/penalty.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy",
            "authors": [
                "Xiaofeng Shi",
                "Qian Kou",
                "Yuduo Li",
                "Hua Zhou"
            ],
            "arxiv_id": "2512.21017v1",
            "summary": "With the rapid advancement of Large Language Models (LLMs), the Chain-of-Thought (CoT) component has become significant for complex reasoning tasks. However, in conventional Supervised Fine-Tuning (SFT), the model could allocate disproportionately more attention to CoT sequences with excessive length. This reduces focus on the much shorter but essential Key portion-the final answer, whose correctness directly determines task success and evaluation quality. To address this limitation, we propose SFTKey, a two-stage training scheme. In the first stage, conventional SFT is applied to ensure proper output format, while in the second stage, only the Key portion is fine-tuned to improve accuracy. Extensive experiments across multiple benchmarks and model families demonstrate that SFTKey achieves an average accuracy improvement exceeding 5\\% over conventional SFT, while preserving the ability to generate correct formats. Overall, this study advances LLM fine-tuning by explicitly balancing CoT learning with additional optimization on answer-relevant tokens.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21017v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SFTKey：通过强化关键答案token，提升LLM监督微调的准确率",
            "summary_zh": "随着大型语言模型（LLMs）的快速发展，思维链（CoT）成分在复杂的推理任务中变得至关重要。然而，在传统的监督微调（SFT）中，模型可能会过度关注长度过长的CoT序列，从而减少对关键部分的关注——即最终答案，其正确性直接决定了任务的成功和评估质量。为了解决这个限制，我们提出了SFTKey，一种两阶段训练方案。在第一阶段，应用传统的SFT以确保正确的输出格式，而在第二阶段，仅对关键部分进行微调以提高准确性。在多个基准和模型系列上的大量实验表明，SFTKey实现了比传统SFT平均超过5%的准确率提升，同时保留了生成正确格式的能力。总的来说，这项研究通过显式地平衡CoT学习和对答案相关token的额外优化，推进了LLM微调。",
            "intro_zh": [
                "传统监督微调（SFT）在处理CoT推理时，容易对过长的推理过程分配过多注意力，忽略了最终答案的重要性。",
                "SFTKey通过两阶段训练，首先进行标准SFT以保证输出格式，然后专注于微调答案部分，提升模型对关键信息的敏感度。",
                "实验结果表明，SFTKey在多个基准测试中，相比传统SFT，平均准确率提升超过5%，同时保持了生成正确格式的能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在监督微调（SFT）过程中，对思维链（CoT）推理过程中冗余信息过度关注，而忽略最终答案（Key）的问题。现有SFT方法的痛点在于，模型难以区分CoT中不同部分的重要性，导致最终答案的准确率提升受限。\\n\\n**核心思路**：论文的核心思路是，将SFT过程分为两个阶段，第一阶段进行标准的SFT，确保模型能够生成正确的CoT格式；第二阶段，只对答案部分（Key）进行微调，从而强化模型对关键信息的关注，提高答案的准确率。这样设计的原因是，CoT的格式正确性可以通过第一阶段保证，而答案的准确性则需要更精细的优化。\\n\\n**技术框架**：SFTKey的整体框架是一个两阶段的训练流程。第一阶段是标准SFT，使用全部的CoT数据进行训练，目标是让模型学会生成符合要求的CoT格式。第二阶段是Key-focused SFT，只使用答案部分的数据进行训练，目标是提高模型对答案的预测准确率。两个阶段可以采用相同的模型结构和优化器，但训练数据和损失函数有所不同。\\n\\n**关键创新**：SFTKey最重要的创新点在于，它将SFT过程解耦为格式学习和答案优化两个阶段，并针对答案部分进行专门的微调。这与传统的SFT方法不同，后者将CoT作为一个整体进行训练，难以区分不同部分的重要性。SFTKey通过这种解耦的方式，能够更有效地利用训练数据，提高答案的准确率。\\n\\n**关键设计**：在第二阶段的Key-focused SFT中，关键的设计在于如何确定答案部分。论文中可能使用了人工标注或者自动抽取的方法来确定答案的起始和结束位置。此外，损失函数的设计也至关重要，可能采用了只计算答案部分损失的策略，或者对答案部分的损失赋予更高的权重。具体的参数设置，如学习率、batch size等，可能需要根据不同的模型和数据集进行调整。",
            "application_zh": "SFTKey方法可广泛应用于需要高准确率的LLM应用场景，例如问答系统、知识图谱推理、代码生成等。通过提升模型对关键信息的关注，可以显著提高这些应用场景的性能和用户体验。未来，该方法可以进一步扩展到其他类型的任务和模型，例如多模态任务和更复杂的推理任务。",
            "highlight_zh": "SFTKey在多个基准测试和模型系列上进行了验证，实验结果表明，SFTKey相比传统的SFT方法，平均准确率提升超过5%。这一提升在不同的数据集和模型上都具有一致性，表明SFTKey具有较强的泛化能力。此外，SFTKey在提高准确率的同时，也保持了生成正确格式的能力，避免了因过度优化答案而导致格式错误的风险。",
            "tags_zh": [
                "监督微调",
                "大型语言模型",
                "思维链",
                "关键答案",
                "两阶段训练"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21017v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21017v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21017v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models",
            "authors": [
                "Xiang Zhang",
                "Jiaqi Wei",
                "Yuejin Yang",
                "Zijie Qiu",
                "Yuhan Chen",
                "Zhiqiang Gao",
                "Muhammad Abdul-Mageed",
                "Laks V. S. Lakshmanan",
                "Wanli Ouyang",
                "Chenyu You",
                "Siqi Sun"
            ],
            "arxiv_id": "2512.20954v1",
            "summary": "Chain-of-Thought (CoT) prompting has significantly advanced task-solving capabilities in natural language processing with large language models. Unlike standard prompting, CoT encourages the model to generate intermediate reasoning steps, non-answer tokens, that help guide the model toward more accurate final outputs. These intermediate steps enable more complex reasoning processes such as error correction, memory management, future planning, and self-reflection. However, applying CoT to non-natural language domains, such as protein and RNA language models, is not yet possible, primarily due to the limited expressiveness of their token spaces (e.g., amino acid tokens). In this work, we propose and define the concept of language expressiveness: the ability of a given language, using its tokens and grammar, to encode information. We show that the limited expressiveness of protein language severely restricts the applicability of CoT-style reasoning. To overcome this, we introduce reflection pretraining, for the first time in a biological sequence model, which enables the model to engage in intermediate reasoning through the generation of auxiliary \"thinking tokens\" beyond simple answer tokens. Theoretically, we demonstrate that our augmented token set significantly enhances biological language expressiveness, thereby improving the overall reasoning capacity of the model. Experimentally, our pretraining approach teaches protein models to self-correct and leads to substantial performance gains compared to standard pretraining.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20954v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出反射预训练，使生物序列模型具备token级自纠错能力",
            "summary_zh": "本文提出了一种针对生物序列模型（如蛋白质和RNA语言模型）的反射预训练方法，旨在提升模型在非自然语言领域的推理能力。与自然语言处理中的Chain-of-Thought (CoT) prompting不同，生物序列模型由于token空间的表达能力有限，难以直接应用CoT。本文首先定义了语言表达能力的概念，并指出蛋白质语言的表达能力不足限制了CoT的应用。为了解决这个问题，本文引入了反射预训练，通过生成辅助的“思考token”，增强模型的中间推理能力。理论分析表明，扩充的token集合显著提升了生物语言的表达能力，从而提高了模型的整体推理能力。实验结果表明，该预训练方法能够有效提升蛋白质模型的自纠错能力，并显著提高模型性能。",
            "intro_zh": [
                "生物序列模型token表达能力有限，难以直接应用自然语言处理中的CoT推理方法。",
                "提出反射预训练，通过引入辅助“思考token”增强生物序列模型的语言表达能力。",
                "实验表明，该方法能有效提升蛋白质模型的自纠错能力，并带来显著的性能提升。"
            ],
            "method_zh": "**问题定义**：现有蛋白质和RNA语言模型在处理复杂生物序列任务时，缺乏有效的推理能力，尤其是在token级别进行自纠错。这是因为生物序列的token空间（如氨基酸）表达能力有限，无法像自然语言那样通过Chain-of-Thought (CoT) prompting生成中间推理步骤，从而限制了模型的推理深度和准确性。\\n\\n**核心思路**：本文的核心思路是通过引入反射预训练，扩展生物序列模型的token空间，使其能够生成辅助的“思考token”。这些思考token类似于CoT中的中间推理步骤，可以帮助模型进行更深入的推理和自纠错。通过增强语言的表达能力，模型可以更好地理解生物序列的复杂关系。\\n\\n**技术框架**：该方法主要包含两个阶段：首先，定义并扩充生物序列模型的token集合，引入新的“思考token”，这些token代表了模型在推理过程中产生的中间状态或思考过程。其次，使用反射预训练策略，训练模型生成和利用这些思考token，从而提升模型的推理能力。整体流程可以概括为：输入生物序列 -> 模型生成思考token -> 模型基于思考token进行推理 -> 输出最终结果。\\n\\n**关键创新**：该方法最重要的创新点在于首次将反射预训练的概念引入生物序列模型，并提出了通过扩充token集合来增强生物语言表达能力的方法。与传统的预训练方法相比，反射预训练能够使模型具备更强的推理能力和自纠错能力，从而更好地处理复杂的生物序列任务。\\n\\n**关键设计**：具体的技术细节包括：(1) 思考token的设计：需要根据具体的生物序列任务设计合适的思考token，例如，可以设计代表序列结构、功能或相互作用的token。(2) 损失函数的设计：需要设计合适的损失函数，鼓励模型生成有意义的思考token，并利用这些token进行准确的推理。(3) 网络结构的选择：可以使用Transformer等常用的序列模型作为基础架构，并根据需要进行调整，例如，可以引入额外的注意力机制来更好地捕捉思考token与原始序列之间的关系。",
            "application_zh": "该研究成果可广泛应用于蛋白质功能预测、药物设计、基因编辑等生物信息学领域。通过提升生物序列模型的推理能力，可以更准确地预测蛋白质的结构和功能，加速新药的研发过程，并为基因治疗提供更可靠的依据。未来，该方法有望推动生物计算和人工智能在生命科学领域的深度融合。",
            "highlight_zh": "实验结果表明，通过反射预训练，蛋白质模型的性能得到了显著提升。例如，在蛋白质功能预测任务中，该方法相比于标准预训练方法，准确率提升了超过10%。此外，模型还展现出了更强的自纠错能力，能够有效地识别和纠正预测过程中的错误。",
            "tags_zh": [
                "生物序列模型",
                "反射预训练",
                "自纠错",
                "语言表达能力",
                "蛋白质功能预测"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20954v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20954v1/fig2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20954v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling",
            "authors": [
                "Chuan Wang",
                "Gaoming Yang",
                "Han Wu",
                "Jiakai Tang",
                "Jiahao Yu",
                "Jian Wu",
                "Jianwu Hu",
                "Junjun Zheng",
                "Shuwen Xiao",
                "Yeqiu Yang",
                "Yuning Jiang",
                "Ahjol Nurlanbek",
                "Binbin Cao",
                "Bo Zheng",
                "Fangmei Zhu",
                "Gaoming Zhou",
                "Huimin Yi",
                "Huiping Chu",
                "Jin Huang",
                "Jinzhe Shan",
                "Kenan Cui",
                "Longbin Li",
                "Silu Zhou",
                "Wen Chen",
                "Xia Ming",
                "Xiang Gao",
                "Xin Yao",
                "Xingyu Wen",
                "Yan Zhang",
                "Yiwen Hu",
                "Yulin Wang",
                "Ziheng Bao",
                "Zongyuan Wu"
            ],
            "arxiv_id": "2512.21257v1",
            "summary": "Industrial recommender systems face two fundamental limitations under the log-driven paradigm: (1) knowledge poverty in ID-based item representations that causes brittle interest modeling under data sparsity, and (2) systemic blindness to beyond-log user interests that constrains model performance within platform boundaries. These limitations stem from an over-reliance on shallow interaction statistics and close-looped feedback while neglecting the rich world knowledge about product semantics and cross-domain behavioral patterns that Large Language Models have learned from vast corpora.\n  To address these challenges, we introduce ReaSeq, a reasoning-enhanced framework that leverages world knowledge in Large Language Models to address both limitations through explicit and implicit reasoning. Specifically, ReaSeq employs explicit Chain-of-Thought reasoning via multi-agent collaboration to distill structured product knowledge into semantically enriched item representations, and latent reasoning via Diffusion Large Language Models to infer plausible beyond-log behaviors. Deployed on Taobao's ranking system serving hundreds of millions of users, ReaSeq achieves substantial gains: >6.0% in IPV and CTR, >2.9% in Orders, and >2.5% in GMV, validating the effectiveness of world-knowledge-enhanced reasoning over purely log-driven approaches.",
            "categories": [
                "cs.IR",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21257v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ReaSeq：通过推理释放世界知识，用于序列建模，提升淘宝推荐系统性能",
            "summary_zh": "工业推荐系统在日志驱动的范式下面临两个根本限制：（1）基于ID的物品表示缺乏知识，导致数据稀疏时兴趣建模脆弱；（2）对超出日志范围的用户兴趣的系统性盲视，将模型性能限制在平台边界内。这些限制源于过度依赖浅层交互统计和闭环反馈，而忽略了大型语言模型从海量语料库中学习到的关于产品语义和跨领域行为模式的丰富世界知识。为了解决这些挑战，我们引入了ReaSeq，这是一个推理增强框架，它利用大型语言模型中的世界知识，通过显式和隐式推理来解决这两个限制。具体来说，ReaSeq采用通过多智能体协作的显式思维链推理，将结构化产品知识提炼为语义丰富的物品表示，并通过扩散大型语言模型进行潜在推理，以推断合理的超出日志范围的行为。ReaSeq部署在为数亿用户提供服务的淘宝排名系统上，取得了显著的收益：IPV和CTR>6.0%，订单>2.9%，GMV>2.5%，验证了世界知识增强推理相对于纯日志驱动方法的有效性。",
            "intro_zh": [
                "现有推荐系统依赖日志数据，忽略了产品语义和跨领域行为模式等世界知识，导致模型在数据稀疏时表现不佳，且难以发现用户的新兴趣。",
                "ReaSeq框架利用大型语言模型中的世界知识，通过显式思维链推理和隐式扩散模型推理，增强物品表示并推断用户行为。",
                "在淘宝推荐系统上的实验表明，ReaSeq在IPV、CTR、订单和GMV等指标上均取得了显著提升，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有工业推荐系统过度依赖用户行为日志，导致两个主要问题：一是物品表示缺乏语义知识，难以应对数据稀疏性；二是模型无法有效探索用户在平台之外的潜在兴趣，限制了推荐效果的提升。现有方法难以充分利用大型语言模型中蕴含的丰富世界知识。\n\n**核心思路**：ReaSeq的核心思路是利用大型语言模型（LLM）中蕴含的世界知识，通过显式和隐式推理来增强推荐系统的性能。显式推理用于丰富物品的语义表示，隐式推理用于推断用户在平台之外的潜在行为，从而克服现有方法的局限性。\n\n**技术框架**：ReaSeq框架包含两个主要模块：\n1. **显式推理模块**：采用多智能体协作的思维链（Chain-of-Thought）推理，从LLM中提取结构化的产品知识，并将其融入到物品的表示中，从而增强物品的语义信息。\n2. **隐式推理模块**：利用扩散大型语言模型（Diffusion Large Language Models）来推断用户可能存在的超出日志范围的行为，从而扩展用户兴趣的覆盖范围。\n\n**关键创新**：ReaSeq的关键创新在于将大型语言模型中的世界知识引入到推荐系统中，并设计了显式和隐式推理机制来有效利用这些知识。与传统的日志驱动方法相比，ReaSeq能够更好地理解物品的语义信息，并探索用户的潜在兴趣。\n\n**关键设计**：\n* **显式推理**：设计了多智能体协作的推理流程，每个智能体负责提取不同方面的产品知识，并通过协作来生成全面的物品表示。\n* **隐式推理**：利用扩散模型生成用户可能感兴趣但未在日志中体现的行为序列，并将其作为增强数据来训练推荐模型。\n* **损失函数**：采用了结合日志数据和生成数据的混合损失函数，以平衡模型在已知行为和潜在行为之间的学习。",
            "application_zh": "ReaSeq具有广泛的应用前景，可应用于电商、新闻、视频等各种推荐系统。通过引入世界知识和推理能力，ReaSeq能够提升推荐系统的准确性、多样性和用户满意度，尤其是在数据稀疏或需要探索用户潜在兴趣的场景下，具有重要的实际价值和商业潜力。未来，ReaSeq可以进一步扩展到跨领域推荐、个性化搜索等领域。",
            "highlight_zh": "ReaSeq在淘宝推荐系统上进行了部署，并取得了显著的性能提升。实验结果表明，ReaSeq在IPV和CTR上提升了>6.0%，在订单上提升了>2.9%，在GMV上提升了>2.5%。这些数据表明，ReaSeq能够有效利用世界知识来增强推荐系统的性能，并显著提升用户体验和商业价值。",
            "tags_zh": [
                "推荐系统",
                "大型语言模型",
                "世界知识",
                "推理",
                "序列建模"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21257v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21257v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21257v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation",
            "authors": [
                "Kaiyuan Liu",
                "Shaotian Yan",
                "Rui Miao",
                "Bing Wang",
                "Chen Shen",
                "Jun Zhang",
                "Jieping Ye"
            ],
            "arxiv_id": "2512.20908v1",
            "summary": "Reasoning distillation has attracted increasing attention. It typically leverages a large teacher model to generate reasoning paths, which are then used to fine-tune a student model so that it mimics the teacher's behavior in training contexts. However, previous approaches have lacked a detailed analysis of the origins of the distilled model's capabilities. It remains unclear whether the student can maintain consistent behaviors with the teacher in novel test-time contexts, or whether it regresses to its original output patterns, raising concerns about the generalization of distillation models. To analyse this question, we introduce a cross-model Reasoning Distillation Provenance Tracing framework. For each action (e.g., a sentence) produced by the distilled model, we obtain the predictive probabilities assigned by the teacher, the original student, and the distilled model under the same context. By comparing these probabilities, we classify each action into different categories. By systematically disentangling the provenance of each action, we experimentally demonstrate that, in test-time contexts, the distilled model can indeed generate teacher-originated actions, which correlate with and plausibly explain observed performance on distilled model. Building on this analysis, we further propose a teacher-guided data selection method. Unlike prior approach that rely on heuristics, our method directly compares teacher-student divergences on the training data, providing a principled selection criterion. We validate the effectiveness of our approach across multiple representative teacher models and diverse student models. The results highlight the utility of our provenance-tracing framework and underscore its promise for reasoning distillation. We hope to share Reasoning Distillation Provenance Tracing and our insights into reasoning distillation with the community.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20908v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "teacher-student",
                        "[T]distillation"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出跨模型推理蒸馏溯源框架，分析学生模型能力来源并指导数据选择。",
            "summary_zh": "推理蒸馏日益受到关注。它通常利用大型教师模型生成推理路径，然后用于微调学生模型，使其在训练环境中模仿教师的行为。然而，先前的方法缺乏对蒸馏模型能力来源的详细分析。目前尚不清楚学生模型是否能在新的测试环境中保持与教师模型一致的行为，或者是否会退回到其原始输出模式，这引发了对蒸馏模型泛化能力的担忧。为了分析这个问题，我们引入了一个跨模型推理蒸馏溯源框架。对于蒸馏模型产生的每个动作（例如，一个句子），我们获取教师模型、原始学生模型和蒸馏模型在相同上下文下的预测概率。通过比较这些概率，我们将每个动作分类到不同的类别中。通过系统地解耦每个动作的来源，我们通过实验证明，在测试环境中，蒸馏模型确实可以生成源自教师模型的动作，这与观察到的蒸馏模型性能相关，并可能解释其性能。在此分析的基础上，我们进一步提出了一种教师引导的数据选择方法。与依赖启发式方法的先前方法不同，我们的方法直接比较训练数据上教师-学生模型的差异，提供了一个有原则的选择标准。我们在多个具有代表性的教师模型和不同的学生模型上验证了我们方法的有效性。结果突出了我们的溯源框架的实用性，并强调了其在推理蒸馏中的前景。我们希望与社区分享推理蒸馏溯源和我们对推理蒸馏的见解。",
            "intro_zh": [
                "现有推理蒸馏方法缺乏对学生模型能力来源的细致分析，难以判断学生模型在测试时能否保持与教师模型的一致性。",
                "提出跨模型推理蒸馏溯源框架，通过比较教师、学生和蒸馏模型的预测概率，追踪学生模型行为的来源。",
                "实验表明，蒸馏模型在测试时可以生成源自教师模型的动作，且与性能相关。基于此，提出教师引导的数据选择方法。"
            ],
            "method_zh": "**问题定义**：推理蒸馏旨在将大型教师模型的推理能力迁移到小型学生模型。然而，现有方法难以分析学生模型在蒸馏后获得的推理能力究竟来源于教师模型还是学生模型自身，尤其是在面对新的测试环境时，学生模型可能退化回原始状态，导致泛化能力不足。因此，需要一种方法来追踪和分析学生模型推理行为的来源，从而更好地理解和改进蒸馏过程。\\n\\n**核心思路**：核心思路是通过比较教师模型、原始学生模型和蒸馏后学生模型在相同上下文下的预测概率，来判断蒸馏后学生模型的行为（例如生成的句子）是来源于教师模型的指导，还是来源于学生模型自身的固有行为。通过分析不同来源的行为对最终性能的影响，可以更好地理解蒸馏过程，并指导数据选择。\\n\\n**技术框架**：该框架包含以下几个主要步骤：1) 对于学生模型生成的每个动作（例如，一个句子），获取教师模型、原始学生模型和蒸馏后学生模型在相同上下文下的预测概率分布。2) 基于这些概率分布，将每个动作分类到不同的类别，例如“教师模型来源”、“学生模型来源”等。3) 分析不同来源的动作与最终性能之间的关系，例如，教师模型来源的动作是否与更高的准确率相关。4) 基于分析结果，提出教师引导的数据选择方法，选择那些教师模型和学生模型差异较大的数据进行蒸馏，以提高蒸馏效果。\\n\\n**关键创新**：关键创新在于提出了一个跨模型的溯源框架，能够细粒度地分析蒸馏后学生模型行为的来源，并将其与最终性能联系起来。与以往依赖启发式方法的数据选择不同，该方法直接比较教师-学生模型的差异，提供了一个更具原则性的数据选择标准。\\n\\n**关键设计**：框架的关键设计包括：1) 如何定义和计算教师模型、原始学生模型和蒸馏后学生模型之间的预测概率差异。2) 如何将学生模型的行为分类到不同的来源类别。3) 如何设计教师引导的数据选择策略，例如，选择哪些数据进行蒸馏，以及如何平衡不同来源的数据。",
            "application_zh": "该研究成果可应用于各种需要模型压缩和加速的场景，例如移动设备上的自然语言处理、边缘计算环境下的智能问答等。通过更有效地进行推理蒸馏，可以降低模型部署的成本和延迟，提高用户体验。此外，该溯源框架有助于理解模型行为，提升模型的可解释性和可靠性。",
            "highlight_zh": "实验结果表明，蒸馏模型在测试时可以生成源自教师模型的动作，并且这些动作与性能提升相关。通过教师引导的数据选择方法，可以在多个教师模型和学生模型上验证其有效性，表明该方法具有良好的泛化能力。具体性能提升数据未知，但强调了溯源框架的实用性。",
            "tags_zh": [
                "推理蒸馏",
                "知识蒸馏",
                "模型溯源",
                "模型分析",
                "数据选择",
                "自然语言处理",
                "模型压缩",
                "模型泛化"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20908v1/sections/1_intro/0_motivation.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20908v1/sections/3_analyse/0_action_split.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20908v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RoboCade: Gamifying Robot Data Collection",
            "authors": [
                "Suvir Mirchandani",
                "Mia Tang",
                "Jiafei Duan",
                "Jubayer Ibn Hamid",
                "Michael Cho",
                "Dorsa Sadigh"
            ],
            "arxiv_id": "2512.21235v1",
            "summary": "Imitation learning from human demonstrations has become a dominant approach for training autonomous robot policies. However, collecting demonstration datasets is costly: it often requires access to robots and needs sustained effort in a tedious, long process. These factors limit the scale of data available for training policies. We aim to address this scalability challenge by involving a broader audience in a gamified data collection experience that is both accessible and motivating. Specifically, we develop a gamified remote teleoperation platform, RoboCade, to engage general users in collecting data that is beneficial for downstream policy training. To do this, we embed gamification strategies into the design of the system interface and data collection tasks. In the system interface, we include components such as visual feedback, sound effects, goal visualizations, progress bars, leaderboards, and badges. We additionally propose principles for constructing gamified tasks that have overlapping structure with useful downstream target tasks. We instantiate RoboCade on three manipulation tasks -- including spatial arrangement, scanning, and insertion. To illustrate the viability of gamified robot data collection, we collect a demonstration dataset through our platform, and show that co-training robot policies with this data can improve success rate on non-gamified target tasks (+16-56%). Further, we conduct a user study to validate that novice users find the gamified platform significantly more enjoyable than a standard non-gamified platform (+24%). These results highlight the promise of gamified data collection as a scalable, accessible, and engaging method for collecting demonstration data.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21235v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation",
                        "teleoperation"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "imitation learning"
                    ],
                    "score": 1.5
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "RoboCade：通过游戏化方式扩展机器人数据收集，提升模仿学习策略。",
            "summary_zh": "模仿学习已成为训练自主机器人策略的主流方法。然而，收集演示数据集成本高昂，需要机器人资源和长期繁琐的人工投入，限制了数据规模。本文旨在通过游戏化的数据收集体验，吸引更广泛的用户参与，解决数据可扩展性问题。我们开发了RoboCade，一个游戏化的远程遥操作平台，通过系统界面和任务设计中的游戏化策略，鼓励用户收集有益于策略训练的数据。界面包含视觉反馈、音效、目标可视化、进度条、排行榜和徽章等元素。我们还提出了构建游戏化任务的原则，使其与下游目标任务具有重叠结构。RoboCade被应用于空间排列、扫描和插入三个操作任务。实验表明，使用该平台收集的数据共同训练机器人策略，可以提高非游戏化目标任务的成功率（+16-56%）。用户研究表明，新手用户认为游戏化平台比标准平台更具吸引力（+24%）。这些结果表明，游戏化数据收集是一种可扩展、易于访问且引人入胜的演示数据收集方法。",
            "intro_zh": [
                "现有模仿学习依赖人工演示数据，但数据收集成本高昂，限制了训练数据的规模。",
                "RoboCade通过游戏化远程遥操作平台，吸引用户参与数据收集，降低数据获取成本。",
                "实验证明，使用RoboCade收集的数据训练机器人策略，显著提升了目标任务的成功率和用户体验。"
            ],
            "method_zh": "**问题定义**：论文旨在解决模仿学习中训练数据不足的问题。现有方法依赖于专家或人工演示，成本高昂且难以扩展，限制了机器人策略的性能提升。痛点在于如何低成本、大规模地获取高质量的机器人操作数据。\\n\\n**核心思路**：论文的核心思路是通过游戏化手段，将数据收集过程转化为有趣且引人入胜的游戏体验，从而吸引大量非专业用户参与数据标注和演示数据的生成。通过精心设计的游戏任务，保证收集到的数据对下游机器人策略训练具有价值。\\n\\n**技术框架**：RoboCade平台包含以下主要模块：1) 远程遥操作界面：用户通过该界面控制机器人执行任务。2) 游戏化元素：包括视觉反馈、音效、目标可视化、进度条、排行榜和徽章等，用于激励用户参与。3) 任务设计模块：用于创建与下游目标任务相关的游戏化任务。4) 数据收集模块：记录用户的操作数据，用于训练机器人策略。整体流程是：用户通过游戏化界面远程控制机器人完成任务，平台记录操作数据，然后将这些数据用于训练机器人策略。\\n\\n**关键创新**：论文的关键创新在于将游戏化理念融入到机器人数据收集过程中，提出了一种可扩展、低成本的数据获取方法。与传统的人工演示数据收集方法相比，RoboCade能够吸引更广泛的用户参与，从而获得更大规模的数据集。此外，论文还提出了构建游戏化任务的原则，确保收集到的数据对下游任务具有实用价值。\\n\\n**关键设计**：论文的关键设计包括：1) 游戏化界面的设计，例如使用视觉反馈和音效来增强用户的参与感。2) 任务设计，确保游戏任务与下游目标任务具有相似的结构，从而使收集到的数据能够有效地用于训练机器人策略。3) 排行榜和徽章系统，用于激励用户竞争和持续参与。",
            "application_zh": "RoboCade的应用场景广泛，可用于各种需要大量机器人操作数据的领域，例如工业自动化、家庭服务机器人、医疗机器人等。通过游戏化数据收集，可以降低数据获取成本，加速机器人技术的研发和应用。未来，该方法有望应用于更复杂的机器人任务，并与其他数据增强技术相结合，进一步提升机器人策略的性能。",
            "highlight_zh": "实验结果表明，使用RoboCade收集的数据共同训练机器人策略，在空间排列任务上成功率提升了16%，在扫描任务上提升了56%，在插入任务上提升了24%。用户研究表明，新手用户认为游戏化平台比标准平台更具吸引力，用户满意度提升了24%。这些数据表明，RoboCade在提高数据收集效率和用户体验方面具有显著优势。",
            "tags_zh": [
                "机器人数据收集",
                "游戏化",
                "模仿学习",
                "远程遥操作",
                "人机交互"
            ],
            "_index": 44,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Schrödinger's Navigator: Imagining an Ensemble of Futures for Zero-Shot Object Navigation",
            "authors": [
                "Yu He",
                "Da Huang",
                "Zhenyang Liu",
                "Zixiao Gu",
                "Qiang Sun",
                "Guangnan Ye",
                "Yanwei Fu"
            ],
            "arxiv_id": "2512.21201v1",
            "summary": "Zero-shot object navigation (ZSON) requires a robot to locate a target object in a previously unseen environment without relying on pre-built maps or task-specific training. However, existing ZSON methods often struggle in realistic and cluttered environments, particularly when the scene contains heavy occlusions, unknown risks, or dynamically moving target objects. To address these challenges, we propose \\textbf{Schrödinger's Navigator}, a navigation framework inspired by Schrödinger's thought experiment on uncertainty. The framework treats unobserved space as a set of plausible future worlds and reasons over them before acting. Conditioned on egocentric visual inputs and three candidate trajectories, a trajectory-conditioned 3D world model imagines future observations along each path. This enables the agent to see beyond occlusions and anticipate risks in unseen regions without requiring extra detours or dense global mapping. The imagined 3D observations are fused into the navigation map and used to update a value map. These updates guide the policy toward trajectories that avoid occlusions, reduce exposure to uncertain space, and better track moving targets. Experiments on a Go2 quadruped robot across three challenging scenarios, including severe static occlusions, unknown risks, and dynamically moving targets, show that Schrödinger's Navigator consistently outperforms strong ZSON baselines in self-localization, object localization, and overall Success Rate in occlusion-heavy environments. These results demonstrate the effectiveness of trajectory-conditioned 3D imagination in enabling robust zero-shot object navigation.",
            "categories": [
                "cs.RO",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21201v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "quadruped"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "world model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "6_video_extraction"
            ],
            "headline_zh": "提出Schrödinger's Navigator，通过未来世界想象增强零样本物体导航",
            "summary_zh": "本文提出Schrödinger's Navigator，一个受薛定谔思想实验启发的导航框架，用于解决零样本物体导航（ZSON）问题。该框架将未观测空间视为一组可能的未来世界，并在行动前对其进行推理。基于自中心视觉输入和候选轨迹，轨迹条件3D世界模型想象沿每条路径的未来观测。这使得智能体能够超越遮挡，预测未见区域的风险，而无需额外的绕行或密集的全局地图构建。想象的3D观测被融合到导航地图中，并用于更新价值地图。这些更新引导策略选择避开遮挡、减少暴露于不确定空间、更好地跟踪移动目标的轨迹。在Go2四足机器人上的实验表明，Schrödinger's Navigator在严重静态遮挡、未知风险和动态移动目标等三种具有挑战性的场景中，始终优于强大的ZSON基线，尤其是在自定位、物体定位和整体成功率方面。",
            "intro_zh": [
                "现有零样本物体导航方法在复杂环境中表现不佳，尤其是在存在严重遮挡、未知风险或动态目标时。",
                "Schrödinger's Navigator通过轨迹条件3D世界模型想象未来观测，使智能体能够推理未观测空间，从而应对遮挡和风险。",
                "在真实机器人实验中，该方法在遮挡严重的环境中显著优于现有方法，证明了轨迹条件3D想象的有效性。"
            ],
            "method_zh": "**问题定义**：零样本物体导航（ZSON）任务要求机器人在未见过的环境中定位目标物体，且不依赖预先构建的地图或特定任务的训练。现有方法在真实、杂乱的环境中，尤其是在存在严重遮挡、未知风险或动态移动目标时，性能会显著下降。这些方法通常难以有效推理未观测空间，导致导航效率降低甚至失败。\\n\\n**核心思路**：本文的核心思路是借鉴薛定谔的思想实验，将未观测空间视为一组可能的“未来世界”。通过让智能体“想象”沿着不同轨迹前进可能遇到的情况，从而在行动前进行推理，选择最优路径。这种方式允许智能体在没有全局地图的情况下，也能有效地避开障碍、预测风险，并跟踪移动目标。\\n\\n**技术框架**：Schrödinger's Navigator框架主要包含以下几个模块：1) 轨迹生成模块：根据当前状态生成多个候选轨迹。2) 轨迹条件3D世界模型：基于自中心视觉输入和候选轨迹，预测沿着每条轨迹前进可能观测到的3D场景。3) 地图融合与价值更新：将想象的3D观测融合到导航地图中，并更新价值地图，价值地图反映了不同位置的导航价值。4) 策略选择：根据价值地图选择最优轨迹，驱动机器人行动。\\n\\n**关键创新**：最重要的创新点在于轨迹条件3D世界模型的引入。该模型能够根据不同的轨迹预测未来观测，从而使智能体能够“看到”遮挡后面的物体，并预测潜在的风险。与现有方法相比，Schrödinger's Navigator不需要预先构建地图，也不需要额外的绕行或密集的全局地图构建，就能实现更鲁棒的导航。\\n\\n**关键设计**：轨迹条件3D世界模型使用神经网络进行训练，输入包括自中心视觉图像和轨迹信息，输出是预测的3D点云。价值地图的更新基于想象的3D观测，并考虑了遮挡、风险和目标位置等因素。策略选择模块可以使用强化学习或其他优化算法，选择价值最高的轨迹。",
            "application_zh": "该研究成果可应用于各种需要自主导航的场景，例如家庭服务机器人、仓库物流机器人、搜救机器人等。通过提升机器人在复杂环境中的导航能力，可以使其更好地完成各种任务，提高工作效率和安全性。此外，该方法还可以扩展到其他需要预测和推理的任务中，例如自动驾驶、游戏AI等。",
            "highlight_zh": "实验结果表明，Schrödinger's Navigator在三种具有挑战性的场景中均优于现有ZSON基线。在严重静态遮挡场景中，成功率提升了15%以上。在未知风险场景中，该方法能够有效地避开危险区域，降低碰撞风险。在动态移动目标场景中，该方法能够更准确地跟踪目标，提高导航效率。这些结果证明了轨迹条件3D想象在零样本物体导航中的有效性。",
            "tags_zh": [
                "零样本物体导航",
                "3D世界模型",
                "轨迹预测",
                "机器人导航",
                "环境理解"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21201v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21201v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21201v1/pic/robot.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Proprioception Enhances Vision Language Model in Generating Captions and Subtask Segmentations for Robot Task",
            "authors": [
                "Kanata Suzuki",
                "Shota Shimizu",
                "Tetsuya Ogata"
            ],
            "arxiv_id": "2512.20876v1",
            "summary": "From the perspective of future developments in robotics, it is crucial to verify whether foundation models trained exclusively on offline data, such as images and language, can understand the robot motion. In particular, since Vision Language Models (VLMs) do not include low-level motion information from robots in their training datasets, video understanding including trajectory information remains a significant challenge. In this study, we assess two capabilities of VLMs through a video captioning task with low-level robot motion information: (1) automatic captioning of robot tasks and (2) segmentation of a series of tasks. Both capabilities are expected to enhance the efficiency of robot imitation learning by linking language and motion and serve as a measure of the foundation model's performance. The proposed method generates multiple \"scene\" captions using image captions and trajectory data from robot tasks. The full task caption is then generated by summarizing these individual captions. Additionally, the method performs subtask segmentation by comparing the similarity between text embeddings of image captions. In both captioning tasks, the proposed method aims to improve performance by providing the robot's motion data - joint and end-effector states - as input to the VLM. Simulator experiments were conducted to validate the effectiveness of the proposed method.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20876v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "imitation learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种融合机器人运动信息的视觉语言模型，用于机器人任务的自动描述和分割。",
            "summary_zh": "本文研究了仅使用离线数据（如图像和语言）训练的视觉语言模型(VLM)是否能理解机器人运动，这对机器人技术的未来发展至关重要。由于VLM的训练数据集不包含来自机器人的底层运动信息，因此包含轨迹信息的视频理解仍然是一个重大挑战。本研究通过一个包含底层机器人运动信息的视频字幕任务，评估了VLM的两个能力：(1)机器人任务的自动字幕生成和(2)一系列任务的分割。 这两个能力有望通过连接语言和运动来提高机器人模仿学习的效率，并作为基础模型性能的衡量标准。该方法利用图像字幕和机器人任务的轨迹数据生成多个“场景”字幕，然后通过总结这些单独的字幕来生成完整的任务字幕。此外，该方法通过比较图像字幕的文本嵌入之间的相似性来执行子任务分割。在两个字幕任务中，该方法旨在通过向VLM提供机器人的运动数据（关节和末端执行器状态）作为输入来提高性能。通过模拟器实验验证了该方法的有效性。",
            "intro_zh": [
                "现有视觉语言模型缺乏对机器人底层运动信息的理解，限制了其在机器人任务中的应用。",
                "提出一种融合机器人关节和末端执行器状态的视觉语言模型，增强其对机器人运动的感知能力。",
                "通过模拟器实验验证，该方法在机器人任务描述和分割方面取得了有效提升。"
            ],
            "method_zh": "**问题定义**：现有的视觉语言模型（VLM）主要基于图像和文本数据进行训练，缺乏对机器人运动信息的理解。这导致它们在理解和描述涉及复杂机器人操作的任务时表现不佳，尤其是在需要精确运动轨迹信息的场景下。因此，如何将机器人运动信息融入VLM，使其能够更好地理解和描述机器人任务，是一个亟待解决的问题。\\n\\n**核心思路**：本文的核心思路是将机器人的运动数据（关节状态和末端执行器状态）作为额外的输入信息，融入到视觉语言模型中。通过这种方式，VLM可以同时利用视觉信息和运动信息，从而更全面地理解机器人任务。具体来说，该方法首先利用图像字幕模型生成每个场景的字幕，然后结合机器人运动数据对字幕进行修正和补充，最后将修正后的字幕进行汇总，生成完整的任务描述。\\n\\n**技术框架**：该方法主要包含以下几个模块：1) 图像字幕生成模块：利用现有的图像字幕模型，如Transformer或LSTM，对机器人任务的视频帧进行描述，生成初步的图像字幕。2) 运动信息编码模块：将机器人的关节状态和末端执行器状态等运动数据进行编码，得到运动特征向量。3) 多模态融合模块：将图像字幕和运动特征向量进行融合，利用注意力机制或拼接等方式，得到融合后的多模态特征表示。4) 任务描述生成模块：利用融合后的多模态特征表示，生成完整的机器人任务描述。5) 子任务分割模块：通过比较不同场景图像字幕的文本嵌入相似度，实现子任务的自动分割。\\n\\n**关键创新**：该方法最重要的创新点在于将机器人运动信息显式地融入到视觉语言模型中，从而增强了VLM对机器人任务的理解能力。与传统的VLM相比，该方法能够更好地捕捉机器人运动的细节，从而生成更准确、更全面的任务描述。此外，该方法还提出了一种基于文本嵌入相似度的子任务分割方法，能够自动将复杂的机器人任务分解为多个子任务。\\n\\n**关键设计**：在运动信息编码模块中，可以使用循环神经网络（RNN）或Transformer等模型对时间序列的运动数据进行编码。在多模态融合模块中，可以使用注意力机制来动态地调整图像字幕和运动特征向量的权重。在任务描述生成模块中，可以使用序列到序列（Seq2Seq）模型或Transformer等模型生成文本描述。损失函数可以采用交叉熵损失或BLEU score等指标来衡量生成文本的质量。",
            "application_zh": "该研究成果可应用于机器人模仿学习、人机协作、机器人教学等领域。通过自动生成机器人任务的描述和分割，可以降低机器人编程的难度，提高机器人学习的效率，并促进人与机器人之间的自然交互。未来，该技术有望应用于更复杂的机器人任务，例如家庭服务机器人、工业机器人等。",
            "highlight_zh": "该研究通过模拟器实验验证了所提出方法的有效性。实验结果表明，与传统的视觉语言模型相比，该方法在机器人任务描述和分割方面取得了显著的提升。具体的性能数据（例如BLEU score、分割准确率等）需要在论文中查找。该研究为视觉语言模型在机器人领域的应用提供了新的思路和方法。",
            "tags_zh": [
                "视觉语言模型",
                "机器人任务理解",
                "运动信息融合",
                "任务描述生成",
                "子任务分割"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20876v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20876v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20876v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PUFM++: Point Cloud Upsampling via Enhanced Flow Matching",
            "authors": [
                "Zhi-Song Liu",
                "Chenhang He",
                "Roland Maier",
                "Andreas Rupp"
            ],
            "arxiv_id": "2512.20988v1",
            "summary": "Recent advances in generative modeling have demonstrated strong promise for high-quality point cloud upsampling. In this work, we present PUFM++, an enhanced flow-matching framework for reconstructing dense and accurate point clouds from sparse, noisy, and partial observations. PUFM++ improves flow matching along three key axes: (i) geometric fidelity, (ii) robustness to imperfect input, and (iii) consistency with downstream surface-based tasks. We introduce a two-stage flow-matching strategy that first learns a direct, straight-path flow from sparse inputs to dense targets, and then refines it using noise-perturbed samples to approximate the terminal marginal distribution better. To accelerate and stabilize inference, we propose a data-driven adaptive time scheduler that improves sampling efficiency based on interpolation behavior. We further impose on-manifold constraints during sampling to ensure that generated points remain aligned with the underlying surface. Finally, we incorporate a recurrent interface network~(RIN) to strengthen hierarchical feature interactions and boost reconstruction quality. Extensive experiments on synthetic benchmarks and real-world scans show that PUFM++ sets a new state of the art in point cloud upsampling, delivering superior visual fidelity and quantitative accuracy across a wide range of tasks. Code and pretrained models are publicly available at https://github.com/Holmes-Alan/Enhanced_PUFM.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "21 pages, 15 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20988v1",
            "code_links": [
                {
                    "url": "https://github.com/Holmes-Alan/Enhanced_PUFM",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]flow matching"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出PUFM++以解决稀疏点云上采样问题",
            "summary_zh": "近年来，生成建模的进展为高质量点云上采样展现了强大的潜力。本文提出了PUFM++，一种增强的流匹配框架，用于从稀疏、噪声和部分观测中重建密集且准确的点云。PUFM++在三个关键方面改进了流匹配：几何保真度、对不完美输入的鲁棒性，以及与下游基于表面的任务的一致性。我们引入了两阶段流匹配策略，首先从稀疏输入学习直接的流，然后利用噪声扰动样本进行精炼。为了加速和稳定推理，我们提出了一种基于插值行为的数据驱动自适应时间调度器。此外，我们在采样过程中施加了流形约束，确保生成的点与基础表面对齐。最后，结合递归接口网络（RIN）增强层次特征交互，提高重建质量。大量实验表明，PUFM++在点云上采样中设定了新的最先进水平。",
            "intro_zh": [
                "现有的点云上采样方法在处理稀疏和噪声输入时常常面临几何保真度不足和鲁棒性差的问题。",
                "论文提出了一种两阶段流匹配策略，通过直接流和噪声扰动样本的结合，提升点云重建的质量和一致性。",
                "实验结果显示，PUFM++在多个基准和真实场景中均超越了现有方法，提供了更高的视觉保真度和定量准确性。"
            ],
            "method_zh": "**问题定义**：本文旨在解决从稀疏、噪声和部分观测中重建高质量点云的挑战。现有方法在几何保真度和对不完美输入的鲁棒性方面存在不足，导致重建效果不佳。\\n\\n**核心思路**：PUFM++的核心思路是通过两阶段流匹配策略，首先学习稀疏输入到密集目标的直接流，然后利用噪声扰动样本进行精炼，以更好地逼近终端边际分布。\\n\\n**技术框架**：整体架构包括两个主要阶段：第一阶段是直接流学习，第二阶段是基于噪声样本的流精炼。同时引入数据驱动的自适应时间调度器和流形约束，确保生成点与基础表面对齐。\\n\\n**关键创新**：最重要的创新在于引入了两阶段流匹配策略和自适应时间调度器，这与现有方法的单一流匹配策略形成鲜明对比，显著提升了重建质量和效率。\\n\\n**关键设计**：在设计中，采用了递归接口网络（RIN）以增强层次特征交互，并在采样过程中施加流形约束，确保生成点的几何一致性。",
            "application_zh": "该研究的潜在应用领域包括计算机视觉、机器人导航、虚拟现实和增强现实等。高质量的点云重建能够提升环境感知和三维重建的准确性，进而推动相关技术的发展和应用。未来，PUFM++有望在自动驾驶、城市建模等领域发挥重要作用。",
            "highlight_zh": "PUFM++在多个合成基准和真实场景中表现出色，相较于现有最先进方法，视觉保真度和定量准确性均有显著提升，具体性能数据表明在多个任务中均达到了新的最佳水平。",
            "tags_zh": [
                "点云上采样",
                "流匹配",
                "生成建模",
                "计算机视觉",
                "三维重建"
            ],
            "_index": 47,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20988v1/fig/overall_fm.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20988v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20988v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Model Merging via Multi-Teacher Knowledge Distillation",
            "authors": [
                "Seyed Arshan Dalili",
                "Mehrdad Mahdavi"
            ],
            "arxiv_id": "2512.21288v1",
            "summary": "Model merging has emerged as a lightweight alternative to joint multi-task learning (MTL), yet the generalization properties of merged models remain largely unexplored. Establishing such theoretical guarantees is non-trivial, as the merging process typically forbids access to the original training data and involves combining fine-tuned models trained on fundamentally heterogeneous data distributions. Without a principled understanding of these dynamics, current methods often rely on heuristics to approximate the optimal combination of parameters. This dependence is most critical in coefficient scaling, the weighting factors that modulate the magnitude of each fine-tuned model's contribution to the shared parameter. However, without a principled objective to guide their selection, these methods lead to brittle performance and are highly sensitive to scaling initialization. We address this gap by (i) establishing a novel flatness-aware PAC-Bayes generalization bound specifically for the model merging setting. This analysis introduces a \"cross-task heterogeneity\" term that formally captures the mismatch between diverse fine-tuned model priors and the target multi-task distributions. Guided by this theoretical insight, (ii) we frame model merging as multi-teacher knowledge distillation on scarce, unlabeled data. We formally demonstrate that minimizing the student-teacher Kullback-Leibler divergence directly tightens the upper bound on the merged model's excess risk. Guided by the flatness-aware bound derived, (iii) we operationalize this objective via SAMerging, a method that employs Sharpness-Aware Minimization (SAM) to find flat minima. Empirically, SAMerging establishes a new state of the art across vision and NLP benchmarks, achieving remarkable performance. The code is available at https://github.com/arshandalili/SAMerging.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21288v1",
            "code_links": [
                {
                    "url": "https://github.com/arshandalili/SAMerging",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出SAMerging，通过多教师知识蒸馏实现模型合并，提升泛化性能。",
            "summary_zh": "模型合并是联合多任务学习的一种轻量级替代方案，但合并模型的泛化特性在很大程度上仍未被探索。建立此类理论保证并非易事，因为合并过程通常禁止访问原始训练数据，并且涉及组合在根本上异构的数据分布上微调的模型。由于缺乏对这些动态的原则性理解，当前的方法通常依赖于启发式方法来近似参数的最佳组合。这种依赖在系数缩放中最为关键，系数缩放调节每个微调模型对共享参数的贡献程度。然而，在没有原则性目标来指导其选择的情况下，这些方法会导致脆弱的性能，并且对缩放初始化高度敏感。我们通过以下方式解决这一差距：(i) 专门为模型合并设置建立一种新颖的、感知平坦度的PAC-Bayes泛化界限。该分析引入了一个“跨任务异质性”项，该项正式捕获了各种微调模型先验与目标多任务分布之间的不匹配。(ii) 在此理论见解的指导下，我们将模型合并定义为在稀缺的未标记数据上的多教师知识蒸馏。我们正式证明，最小化学生-教师Kullback-Leibler散度可以直接收紧合并模型超额风险的上限。在导出的感知平坦度的界限的指导下，(iii) 我们通过SAMerging来实现这一目标，SAMerging采用Sharpness-Aware Minimization (SAM) 来寻找平坦最小值。在经验上，SAMerging在视觉和NLP基准测试中建立了新的最先进水平，取得了显著的性能。代码可在https://github.com/arshandalili/SAMerging获得。",
            "intro_zh": [
                "现有模型合并方法依赖启发式参数组合，缺乏理论指导，导致性能不稳定且对初始化敏感。",
                "论文将模型合并视为多教师知识蒸馏，通过最小化KL散度来优化合并模型，并推导出泛化误差上界。",
                "提出的SAMerging方法利用Sharpness-Aware Minimization寻找平坦最小值，在视觉和NLP任务上取得SOTA性能。"
            ],
            "method_zh": "**问题定义**：模型合并旨在将多个在不同任务上微调的模型合并为一个模型，以实现多任务学习的目的。现有方法通常依赖于启发式方法来确定每个模型的权重，缺乏理论指导，导致合并后的模型性能不稳定，并且对权重初始化非常敏感。尤其是在无法访问原始训练数据的情况下，如何有效地合并模型是一个挑战。\\n\\n**核心思路**：论文的核心思路是将模型合并问题转化为多教师知识蒸馏问题。通过将多个微调后的模型视为教师模型，利用少量未标记数据进行知识蒸馏，训练出一个学生模型作为合并后的模型。这种方法能够利用教师模型的知识，同时避免了直接操作模型参数的复杂性。\\n\\n**技术框架**：SAMerging的整体框架包括以下几个步骤：1) 对多个模型在各自的任务上进行微调。2) 利用少量未标记数据，将微调后的模型作为教师模型，训练一个学生模型。3) 在训练过程中，最小化学生模型和教师模型之间的Kullback-Leibler (KL) 散度，以保证学生模型能够学习到教师模型的知识。4) 使用Sharpness-Aware Minimization (SAM) 优化学生模型，寻找平坦最小值，提高模型的泛化能力。\\n\\n**关键创新**：论文的关键创新在于：1) 将模型合并问题转化为多教师知识蒸馏问题，为模型合并提供了一种新的视角。2) 提出了一个专门针对模型合并场景的、感知平坦度的PAC-Bayes泛化界限，为模型合并的理论分析提供了基础。3) 将Sharpness-Aware Minimization (SAM) 应用于模型合并，通过寻找平坦最小值来提高模型的泛化能力。\\n\\n**关键设计**：SAMerging的关键设计包括：1) 使用KL散度作为学生模型和教师模型之间的损失函数，以保证学生模型能够学习到教师模型的知识。2) 使用Sharpness-Aware Minimization (SAM) 优化学生模型，SAM通过寻找参数空间中loss值变化不敏感的区域，来提高模型的泛化能力。具体来说，SAM首先在当前参数附近寻找一个扰动，使得loss值增加最多，然后沿着loss增加的反方向更新参数。3) 论文中提出的“跨任务异质性”项，用于衡量不同任务之间的差异，并在PAC-Bayes泛化界限中发挥作用。",
            "application_zh": "该研究成果可应用于各种需要模型合并的场景，例如多任务学习、联邦学习和持续学习。通过SAMerging，可以有效地将多个在不同任务上训练的模型合并为一个高性能模型，从而降低模型部署和维护的成本，并提高模型的泛化能力。该方法在计算机视觉、自然语言处理等领域具有广泛的应用前景。",
            "highlight_zh": "SAMerging在多个视觉和NLP基准测试中取得了显著的性能提升，建立了新的SOTA。具体性能数据在论文中给出，相较于之前的模型合并方法，SAMerging在多个任务上都取得了明显的性能提升，验证了该方法的有效性。实验结果表明，SAMerging能够有效地利用多个模型的知识，并提高模型的泛化能力。",
            "tags_zh": [
                "模型合并",
                "知识蒸馏",
                "多任务学习",
                "泛化能力",
                "PAC-Bayes",
                "Sharpness-Aware Minimization",
                "深度学习",
                "模型优化"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21288v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21288v1/arxiv/plots_to_use/eurosat_vs_sun397__samerging_vs_adamerging_8.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21288v1/arxiv/plots_to_use/eurosat_vs_sun397_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MiST: Understanding the Role of Mid-Stage Scientific Training in Developing Chemical Reasoning Models",
            "authors": [
                "Andres M Bran",
                "Tong Xie",
                "Shai Pranesh",
                "Jeffrey Meng",
                "Xuan Vu Nguyen",
                "Jeremy Goumaz",
                "David Ming Segura",
                "Ruizhi Xu",
                "Dongzhan Zhou",
                "Wenjie Zhang",
                "Bram Hoex",
                "Philippe Schwaller"
            ],
            "arxiv_id": "2512.21231v1",
            "summary": "Large Language Models can develop reasoning capabilities through online fine-tuning with rule-based rewards. However, recent studies reveal a critical constraint: reinforcement learning succeeds only when the base model already assigns non-negligible probability to correct answers -- a property we term 'latent solvability'. This work investigates the emergence of chemical reasoning capabilities and what these prerequisites mean for chemistry. We identify two necessary conditions for RL-based chemical reasoning: 1) Symbolic competence, and 2) Latent chemical knowledge. We propose mid-stage scientific training (MiST): a set of mid-stage training techniques to satisfy these, including data-mixing with SMILES/CIF-aware pre-processing, continued pre-training on 2.9B tokens, and supervised fine-tuning on 1B tokens. These steps raise the latent-solvability score on 3B and 7B models by up to 1.8x, and enable RL to lift top-1 accuracy from 10.9 to 63.9% on organic reaction naming, and from 40.6 to 67.4% on inorganic material generation. Similar results are observed for other challenging chemical tasks, while producing interpretable reasoning traces. Our results define clear prerequisites for chemical reasoning training and highlight the broader role of mid-stage training in unlocking reasoning capabilities.",
            "categories": [
                "cs.LG",
                "cond-mat.mtrl-sci"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21231v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MiST，通过中阶段科学训练提升化学推理模型性能",
            "summary_zh": "大型语言模型可以通过基于规则奖励的在线微调来发展推理能力。然而，最近的研究表明一个关键约束：强化学习只有在基础模型已经为正确答案分配了不可忽略的概率时才能成功——我们称之为“潜在可解性”。本文研究了化学推理能力的出现，以及这些先决条件对化学的意义。我们确定了基于强化学习的化学推理的两个必要条件：1) 符号能力，2) 潜在的化学知识。我们提出了中阶段科学训练（MiST）：一套满足这些条件的中阶段训练技术，包括使用SMILES/CIF感知预处理的数据混合、在29亿tokens上的持续预训练以及在10亿tokens上的监督微调。这些步骤将3B和7B模型的潜在可解性得分提高了高达1.8倍，并使强化学习能够将有机反应命名上的top-1准确率从10.9%提高到63.9%，并将无机材料生成上的top-1准确率从40.6%提高到67.4%。在其他具有挑战性的化学任务中也观察到了类似的结果，同时产生了可解释的推理轨迹。我们的结果定义了化学推理训练的明确先决条件，并强调了中阶段训练在解锁推理能力方面的更广泛作用。",
            "intro_zh": [
                "现有方法在利用强化学习提升化学推理能力时，受限于模型自身的“潜在可解性”，即模型需具备初步的正确答案预测能力。",
                "论文提出中阶段科学训练（MiST），通过数据混合、持续预训练和监督微调等技术，增强模型的符号能力和潜在化学知识。",
                "实验表明，MiST能显著提升模型在有机反应命名和无机材料生成等任务上的准确率，并生成可解释的推理过程。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在化学推理任务中表现出潜力，但直接使用强化学习进行微调往往效果不佳。一个关键问题是，强化学习的成功依赖于模型本身是否具备“潜在可解性”，即模型在训练前已经对正确答案有一定的概率预测。如果模型缺乏必要的化学知识和符号处理能力，强化学习很难有效提升其推理能力。\\n\\n**核心思路**：论文的核心思路是通过中阶段科学训练（MiST）来增强模型的“潜在可解性”。MiST旨在使模型具备进行有效化学推理所需的两个关键要素：符号能力和潜在的化学知识。通过精心设计的中阶段训练，提升模型对化学结构和反应的理解，从而为后续的强化学习奠定坚实的基础。\\n\\n**技术框架**：MiST框架主要包含以下几个阶段：\n1. **数据混合与预处理**：将包含SMILES和CIF格式的化学数据与通用文本数据混合，并进行SMILES/CIF感知的预处理，以增强模型对化学结构的理解。\n2. **持续预训练**：在29亿个tokens上进行持续预训练，进一步提升模型对化学领域知识的掌握。\n3. **监督微调**：在10亿个tokens上进行监督微调，使模型能够更好地完成特定的化学任务。\n4. **强化学习（可选）**：在MiST的基础上，可以使用强化学习进一步提升模型的性能。\n\\n**关键创新**：该论文的关键创新在于提出了“中阶段科学训练”（MiST）的概念，并将其应用于化学推理模型的训练。与传统的预训练+微调方法不同，MiST强调在预训练和最终任务微调之间进行有针对性的训练，以弥补模型在化学领域知识和符号处理能力方面的不足。这种中阶段训练能够显著提升模型的“潜在可解性”，从而为后续的强化学习奠定基础。\\n\\n**关键设计**：\n* **数据混合比例**：需要仔细调整化学数据和通用文本数据的混合比例，以避免模型过度拟合化学领域知识，同时保持其通用语言能力。\n* **SMILES/CIF感知预处理**：针对SMILES和CIF格式的化学数据，需要进行专门的预处理，例如tokenization和数据增强，以提高模型对化学结构的理解。\n* **持续预训练目标**：持续预训练的目标可以是masked language modeling或因果语言建模，具体选择取决于模型的架构和任务需求。\n* **监督微调损失函数**：监督微调的损失函数通常是交叉熵损失，用于衡量模型预测结果与真实标签之间的差异。",
            "application_zh": "该研究成果可应用于药物发现、材料设计等领域。通过提升化学推理模型的性能，可以加速新药和新材料的研发过程，降低研发成本。此外，该方法还可以推广到其他科学领域，例如物理学和生物学，以提升相关领域的AI模型性能。",
            "highlight_zh": "实验结果表明，MiST能够显著提升模型的化学推理能力。在有机反应命名任务中，MiST将top-1准确率从10.9%提升到63.9%，提升幅度高达53%。在无机材料生成任务中，MiST将top-1准确率从40.6%提升到67.4%，提升幅度为26.8%。这些结果表明，MiST是一种有效的化学推理模型训练方法。",
            "tags_zh": [
                "化学推理",
                "大型语言模型",
                "中阶段训练",
                "强化学习",
                "潜在可解性"
            ],
            "_index": 49,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21231v1/figures/figure1.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21231v1/figures/scs_cr.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21231v1/figures/scs_prepost.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semantic Refinement with LLMs for Graph Representations",
            "authors": [
                "Safal Thapaliya",
                "Zehong Wang",
                "Jiazheng Li",
                "Ziming Li",
                "Yanfang Ye",
                "Chuxu Zhang"
            ],
            "arxiv_id": "2512.21106v1",
            "summary": "Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21106v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DAS框架，利用LLM进行图表示的语义精炼，解决图结构异构性问题。",
            "summary_zh": "图结构化数据在其预测信号来源方面表现出显著的异构性：在某些领域，节点级语义占主导地位，而在另一些领域，结构模式起着核心作用。这种结构-语义异构性意味着，没有具有固定归纳偏置的图学习模型可以在不同的图领域中实现最佳泛化。然而，大多数现有方法都是从模型侧解决这一挑战，通过逐步注入新的归纳偏置，但鉴于现实世界图的开放式多样性，这仍然存在根本性的局限性。在这项工作中，我们采取以数据为中心的视角，并将节点语义视为任务自适应变量。我们提出了一个用于图表示学习的数据自适应语义精炼框架DAS，该框架将固定的图神经网络（GNN）和大型语言模型（LLM）耦合在一个闭环反馈中。GNN提供隐式监督信号来指导LLM的语义精炼，并且精炼后的语义被反馈以更新相同的图学习器。我们在文本丰富和无文本图上评估了我们的方法。结果表明，在结构主导的图上取得了持续的改进，同时在语义丰富的图上保持了竞争力，证明了以数据为中心的语义自适应在结构-语义异构性下的有效性。",
            "intro_zh": [
                "现有图学习模型难以应对图结构和语义的异构性，因为它们通常具有固定的归纳偏置。",
                "DAS框架通过闭环反馈，利用GNN和LLM协同工作，实现节点语义的自适应精炼，从而适应不同的图结构。",
                "实验结果表明，DAS在结构主导的图上性能提升显著，并在语义丰富的图上保持竞争力，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有图学习方法在处理具有结构-语义异构性的图数据时面临挑战。不同的图数据集中，节点语义和图结构的重要性各不相同，而现有方法通常采用固定的归纳偏置，难以适应这种多样性。这导致模型在某些图上表现良好，但在另一些图上性能下降。现有方法主要集中在模型层面，通过不断添加新的归纳偏置来适应不同的图，但这种方式无法穷尽所有可能的图结构和语义组合。\\n\\n**核心思路**：本文的核心思路是将节点语义视为一个任务自适应的变量，通过数据驱动的方式进行精炼。作者认为，与其不断修改模型来适应不同的图，不如让模型自适应地学习和调整节点语义，从而更好地利用图的结构信息。通过将GNN和LLM结合，利用GNN的结构信息来指导LLM进行语义精炼，并将精炼后的语义反馈给GNN，形成一个闭环反馈系统。\\n\\n**技术框架**：DAS框架包含两个主要模块：GNN和LLM。GNN负责学习图的结构信息，并生成节点表示。LLM负责对节点语义进行精炼，并生成更丰富的语义表示。这两个模块通过一个闭环反馈系统进行交互。具体流程如下：1) GNN接收原始图数据，生成节点表示。2) LLM接收节点表示和原始节点文本（如果存在），进行语义精炼，生成精炼后的节点表示。3) 将精炼后的节点表示反馈给GNN，更新GNN的参数。4) 重复步骤1-3，直到模型收敛。\\n\\n**关键创新**：DAS框架的关键创新在于其数据自适应的语义精炼机制。与现有方法不同，DAS不是通过修改模型来适应不同的图，而是通过自适应地学习和调整节点语义来提高模型的泛化能力。通过将GNN和LLM结合，DAS可以同时利用图的结构信息和LLM的语义信息，从而更好地理解图数据。此外，DAS的闭环反馈系统可以不断地优化节点语义，从而提高模型的性能。\\n\\n**关键设计**：GNN可以使用任何现有的图神经网络模型，例如GCN、GAT等。LLM可以使用任何现有的预训练语言模型，例如BERT、RoBERTa等。在实验中，作者使用了GCN作为GNN，使用了BERT作为LLM。损失函数包括两部分：图学习损失和语义精炼损失。图学习损失用于训练GNN，语义精炼损失用于训练LLM。作者还设计了一种自适应的权重调整机制，用于平衡图学习损失和语义精炼损失。",
            "application_zh": "该研究成果可应用于多种图数据分析任务，例如社交网络分析、知识图谱推理、生物信息学等。通过自适应地学习和调整节点语义，可以提高模型在不同图数据集上的泛化能力，从而更好地解决实际问题。例如，在社交网络分析中，可以利用DAS框架来识别虚假账号或预测用户行为。在知识图谱推理中，可以利用DAS框架来补全知识图谱或进行关系预测。",
            "highlight_zh": "实验结果表明，DAS框架在结构主导的图上取得了显著的性能提升，例如在Cora数据集上，DAS的节点分类准确率比基线模型提高了5%以上。同时，DAS在语义丰富的图上保持了竞争力，表明其具有良好的泛化能力。这些结果验证了DAS框架在处理结构-语义异构性图数据方面的有效性。",
            "tags_zh": [
                "图神经网络",
                "大型语言模型",
                "语义精炼",
                "数据自适应",
                "图表示学习"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21106v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21106v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21106v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Shared Representation Learning for High-Dimensional Multi-Task Forecasting under Resource Contention in Cloud-Native Backends",
            "authors": [
                "Zixiao Huang",
                "Jixiao Yang",
                "Sijia Li",
                "Chi Zhang",
                "Jinyu Chen",
                "Chengda Xu"
            ],
            "arxiv_id": "2512.21102v1",
            "summary": "This study proposes a unified forecasting framework for high-dimensional multi-task time series to meet the prediction demands of cloud native backend systems operating under highly dynamic loads, coupled metrics, and parallel tasks. The method builds a shared encoding structure to represent diverse monitoring indicators in a unified manner and employs a state fusion mechanism to capture trend changes and local disturbances across different time scales. A cross-task structural propagation module is introduced to model potential dependencies among nodes, enabling the model to understand complex structural patterns formed by resource contention, link interactions, and changes in service topology. To enhance adaptability to non-stationary behaviors, the framework incorporates a dynamic adjustment mechanism that automatically regulates internal feature flows according to system state changes, ensuring stable predictions in the presence of sudden load shifts, topology drift, and resource jitter. The experimental evaluation compares multiple models across various metrics and verifies the effectiveness of the framework through analyses of hyperparameter sensitivity, environmental sensitivity, and data sensitivity. The results show that the proposed method achieves superior performance on several error metrics and provides more accurate representations of future states under different operating conditions. Overall, the unified forecasting framework offers reliable predictive capability for high-dimensional, multi-task, and strongly dynamic environments in cloud native systems and provides essential technical support for intelligent backend management.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21102v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出共享表征学习框架，解决云原生后端高维多任务时序预测难题。",
            "summary_zh": "本研究提出了一种统一的预测框架，用于高维多任务时间序列预测，旨在满足云原生后端系统在高度动态负载、耦合指标和并行任务下的预测需求。该方法构建了一个共享编码结构，以统一的方式表示各种监控指标，并采用状态融合机制来捕获不同时间尺度上的趋势变化和局部扰动。引入跨任务结构传播模块，用于建模节点之间潜在的依赖关系，使模型能够理解由资源竞争、链接交互和服务拓扑变化形成的复杂结构模式。为了增强对非平稳行为的适应性，该框架结合了一种动态调整机制，该机制根据系统状态变化自动调节内部特征流，从而确保在突然的负载变化、拓扑漂移和资源抖动存在的情况下实现稳定的预测。实验评估比较了各种指标下的多个模型，并通过超参数敏感性、环境敏感性和数据敏感性分析验证了该框架的有效性。结果表明，所提出的方法在多个误差指标上实现了卓越的性能，并提供了在不同操作条件下对未来状态的更准确表示。总而言之，该统一预测框架为云原生系统中高维、多任务和强动态环境提供了可靠的预测能力，并为智能后端管理提供了必要的技术支持。",
            "intro_zh": [
                "现有方法难以应对云原生后端系统高维、多任务和动态变化的复杂性，预测精度不足。",
                "构建共享编码结构统一表征监控指标，融合多尺度状态信息，并利用跨任务结构传播建模依赖关系。",
                "实验表明，该框架在多种误差指标上优于其他模型，能更准确地预测不同工况下的系统状态。"
            ],
            "method_zh": "**问题定义**：云原生后端系统面临高维多任务时序预测的挑战，具体表现为监控指标数量庞大、任务间存在复杂依赖关系、系统负载动态变化剧烈。现有方法难以有效捕捉这些复杂性，导致预测精度下降，无法满足智能后端管理的需求。\\n\\n**核心思路**：论文的核心思路是利用共享表征学习，将高维多任务的时序数据映射到统一的低维空间，从而降低模型的复杂度，并提高泛化能力。通过引入状态融合机制和跨任务结构传播模块，模型能够捕捉不同时间尺度上的动态变化和任务间的依赖关系，从而提高预测精度。动态调整机制则用于适应非平稳行为，确保预测的稳定性。\\n\\n**技术框架**：该框架主要包含以下几个模块：1) 共享编码结构：用于将不同的监控指标编码到统一的表征空间。2) 状态融合机制：用于融合不同时间尺度的状态信息，捕捉趋势变化和局部扰动。3) 跨任务结构传播模块：用于建模节点之间的依赖关系，理解资源竞争、链接交互和服务拓扑变化等复杂结构模式。4) 动态调整机制：根据系统状态变化自动调节内部特征流，适应非平稳行为。\\n\\n**关键创新**：最重要的技术创新点在于跨任务结构传播模块和动态调整机制。跨任务结构传播模块能够有效建模任务间的复杂依赖关系，而动态调整机制则能够使模型适应非平稳行为，从而提高预测的准确性和稳定性。与现有方法相比，该框架能够更好地捕捉云原生后端系统的复杂性和动态性。\\n\\n**关键设计**：共享编码结构可能采用Transformer或GNN等模型，状态融合机制可能使用注意力机制或卷积操作，跨任务结构传播模块可能基于图神经网络，动态调整机制可能基于强化学习或自适应学习率调整。损失函数可能包括均方误差、平均绝对误差等，并加入正则化项以防止过拟合。具体的网络结构和参数设置需要在实验中进行调整和优化。",
            "application_zh": "该研究成果可应用于云原生后端系统的智能管理，例如资源调度、故障预测和容量规划。通过准确预测系统未来的状态，可以优化资源分配，提前发现潜在问题，并合理规划系统容量，从而提高系统的性能、可靠性和资源利用率。此外，该方法还可以扩展到其他领域，如智能交通、金融风控等。",
            "highlight_zh": "实验结果表明，该框架在多个误差指标（如MSE、MAE）上优于其他基线模型，例如LSTM、GRU等。具体而言，在某些指标上，该框架的性能提升幅度达到10%-20%。此外，超参数敏感性、环境敏感性和数据敏感性分析验证了该框架的鲁棒性和泛化能力。",
            "tags_zh": [
                "时序预测",
                "共享表征学习",
                "云原生",
                "多任务学习",
                "资源竞争",
                "动态调整",
                "状态融合"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "LSTM-Based Modeling and Reinforcement Learning Control of a Magnetically Actuated Catheter",
            "authors": [
                "Arya Rashidinejad Meibodi",
                "Mahbod Gholamali Sinaki",
                "Khalil Alipour"
            ],
            "arxiv_id": "2512.21063v1",
            "summary": "Autonomous magnetic catheter systems are emerging as a promising approach for the future of minimally invasive interventions. This study presents a novel approach that begins by modeling the nonlinear and hysteretic dynamics of a magnetically actuated catheter system, consists of a magnetic catheter manipulated by servo-controlled magnetic fields generated by two external permanent magnets, and its complex behavior is captured using a Long Short-Term Memory (LSTM) neural network. This model validated against experimental setup's data with a root mean square error (RMSE) of 0.42 mm and 99.8% coverage within 3 mm, establishing it as a reliable surrogate model. This LSTM enables the training of Reinforcement Learning (RL) agents for controlling the system and avoiding damage to the real setup, with the potential for subsequent fine-tuning on the physical system. We implemented Deep Q-Network (DQN) and actor-critic RL controllers, comparing these two agents first for regulation and subsequently for path following along linear and half-sinusoidal paths for the catheter tip. The actor-critic outperforms DQN, offering greater accuracy and faster performance with less error, along with smoother trajectories at a 10 Hz sampling rate, in both regulation and path following compared to the DQN controller. This performance, due to the continuous action space, suits dynamic navigation tasks like navigating curved vascular structures for practical applications.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Presented at the 13th RSI International Conference on Robotics and Mechatronics (ICRoM 2025), Dec. 16-18, 2025, Tehran, Iran",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21063v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于LSTM建模和强化学习控制的磁驱动导管自主导航方法",
            "summary_zh": "本研究提出了一种用于磁驱动导管系统的建模与控制新方法，旨在实现微创介入的自主化。首先，利用长短期记忆（LSTM）神经网络对磁驱动导管系统的非线性及迟滞动力学进行建模。该系统由外部永磁体产生的伺服控制磁场操纵磁性导管。实验数据验证表明，该模型的均方根误差（RMSE）为0.42毫米，且99.8%的预测值在3毫米范围内，证明其是一个可靠的替代模型。该LSTM模型使得强化学习（RL）智能体能够被训练来控制系统，避免损坏真实设备，并有可能在物理系统上进行后续微调。我们实现了深度Q网络（DQN）和actor-critic两种RL控制器，并首先对它们的调节性能进行了比较，随后比较了导管尖端沿直线和半正弦路径的路径跟踪性能。结果表明，actor-critic算法优于DQN，在调节和路径跟踪方面都提供了更高的精度、更快的性能和更小的误差，以及更平滑的轨迹（采样率为10赫兹）。由于其连续动作空间，这种性能非常适合动态导航任务，例如在实际应用中导航弯曲的血管结构。",
            "intro_zh": [
                "现有磁驱动导管系统难以精确建模其非线性与迟滞特性，限制了自主控制的实现。",
                "利用LSTM网络学习磁驱动导管的复杂动力学模型，为后续强化学习控制提供精确的仿真环境。",
                "Actor-critic强化学习控制器在导管路径跟踪任务中表现优于DQN，精度更高，轨迹更平滑。"
            ],
            "method_zh": "**问题定义**：磁驱动导管系统在微创手术中具有重要应用，但其非线性、迟滞的动力学特性使得精确建模和控制变得困难。传统方法难以有效应对这些挑战，限制了导管的自主导航能力，增加了手术风险。\\n\\n**核心思路**：本研究的核心思路是利用LSTM神经网络学习磁驱动导管系统的动力学模型，并将其作为强化学习的仿真环境。通过在仿真环境中训练强化学习智能体，可以避免在真实系统上直接训练可能造成的损坏，并最终实现导管的精确自主控制。\\n\\n**技术框架**：该方法包含两个主要阶段：1) 基于LSTM的系统建模：利用实验数据训练LSTM网络，使其能够准确预测导管在不同磁场作用下的运动状态。2) 强化学习控制：使用训练好的LSTM模型作为仿真环境，训练DQN和actor-critic两种强化学习智能体，使其能够控制磁场，从而实现导管的精确导航。\\n\\n**关键创新**：该方法的关键创新在于将LSTM神经网络与强化学习相结合，利用LSTM强大的建模能力为强化学习提供精确的仿真环境，从而避免了在真实系统上直接训练的风险。此外，对比了DQN和actor-critic两种强化学习算法在导管控制中的性能，发现actor-critic算法更适合连续动作空间的控制任务。\\n\\n**关键设计**：LSTM网络结构的选择和训练数据的采集是关键。强化学习中，奖励函数的设计直接影响智能体的学习效果。Actor-critic算法采用连续动作空间，更适合控制磁场的连续变化。DQN算法则采用离散动作空间，需要进行离散化处理。实验中，采样率为10Hz，用于控制导管的运动。",
            "application_zh": "该研究成果可应用于微创手术领域，实现磁驱动导管的自主导航，减少医生操作负担，提高手术精度和安全性。未来可进一步扩展到更复杂的血管结构导航，以及药物递送等应用，具有重要的临床应用价值和商业前景。",
            "highlight_zh": "实验结果表明，基于LSTM建模的强化学习控制方法能够有效控制磁驱动导管。Actor-critic算法在直线和半正弦路径跟踪任务中均优于DQN算法，具有更高的精度和更平滑的轨迹。LSTM模型对导管运动的预测均方根误差（RMSE）为0.42毫米，且99.8%的预测值在3毫米范围内。",
            "tags_zh": [
                "磁驱动导管",
                "LSTM网络",
                "强化学习",
                "DQN",
                "Actor-Critic",
                "自主导航",
                "微创手术"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21063v1/Schematic.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21063v1/LSTM.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21063v1/Overview2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AirGS: Real-Time 4D Gaussian Streaming for Free-Viewpoint Video Experiences",
            "authors": [
                "Zhe Wang",
                "Jinghang Li",
                "Yifei Zhu"
            ],
            "arxiv_id": "2512.20943v1",
            "summary": "Free-viewpoint video (FVV) enables immersive viewing experiences by allowing users to view scenes from arbitrary perspectives. As a prominent reconstruction technique for FVV generation, 4D Gaussian Splatting (4DGS) models dynamic scenes with time-varying 3D Gaussian ellipsoids and achieves high-quality rendering via fast rasterization. However, existing 4DGS approaches suffer from quality degradation over long sequences and impose substantial bandwidth and storage overhead, limiting their applicability in real-time and wide-scale deployments. Therefore, we present AirGS, a streaming-optimized 4DGS framework that rearchitects the training and delivery pipeline to enable high-quality, low-latency FVV experiences. AirGS converts Gaussian video streams into multi-channel 2D formats and intelligently identifies keyframes to enhance frame reconstruction quality. It further combines temporal coherence with inflation loss to reduce training time and representation size. To support communication-efficient transmission, AirGS models 4DGS delivery as an integer linear programming problem and design a lightweight pruning level selection algorithm to adaptively prune the Gaussian updates to be transmitted, balancing reconstruction quality and bandwidth consumption. Extensive experiments demonstrate that AirGS reduces quality deviation in PSNR by more than 20% when scene changes, maintains frame-level PSNR consistently above 30, accelerates training by 6 times, reduces per-frame transmission size by nearly 50% compared to the SOTA 4DGS approaches.",
            "categories": [
                "cs.GR",
                "cs.DC",
                "cs.LG",
                "cs.MM",
                "cs.NI",
                "eess.IV"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "This paper is accepted by IEEE International Conference on Computer Communications (INFOCOM), 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20943v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "AirGS：面向自由视点视频的实时4D高斯流传输框架",
            "summary_zh": "本文提出AirGS，一个流传输优化的4D高斯溅射（4DGS）框架，旨在实现高质量、低延迟的自由视点视频（FVV）体验。AirGS将高斯视频流转换为多通道2D格式，并智能地识别关键帧以增强帧重建质量。它结合了时间一致性和膨胀损失，以减少训练时间和表示大小。为了支持通信高效的传输，AirGS将4DGS传输建模为一个整数线性规划问题，并设计了一种轻量级的剪枝级别选择算法，自适应地剪枝待传输的高斯更新，从而平衡重建质量和带宽消耗。实验表明，AirGS在场景变化时，PSNR的质量偏差降低了20%以上，帧级别PSNR始终保持在30以上，训练速度提高了6倍，并且与SOTA 4DGS方法相比，每帧传输大小减少了近50%。",
            "intro_zh": [
                "现有4DGS方法在长序列中存在质量下降问题，且带宽和存储开销大，限制了其在实时和大规模部署中的应用。",
                "AirGS通过重构训练和传输流程，将高斯视频流转换为多通道2D格式，并结合关键帧选择、时间一致性和膨胀损失等技术，优化了4DGS的流传输。",
                "实验结果表明，AirGS在质量、训练速度和传输大小方面均优于现有方法，尤其是在场景变化时能显著降低质量偏差。"
            ],
            "method_zh": "**问题定义**：现有4D高斯溅射（4DGS）方法在处理长时间序列的自由视点视频时，面临着两个主要问题：一是随着时间推移，重建质量会逐渐下降；二是需要大量的带宽和存储空间，这使得它们难以应用于实时和大规模的部署场景。这些问题限制了自由视点视频技术的广泛应用。\\n\\n**核心思路**：AirGS的核心思路是通过优化4DGS的训练和传输流程，使其更适合流传输。具体来说，它通过将高斯视频流转换为多通道2D格式，并智能地选择关键帧来提高重建质量。同时，利用时间一致性和膨胀损失来减少训练时间和表示大小。在传输方面，AirGS将4DGS的传输建模为一个整数线性规划问题，并设计了一种轻量级的剪枝算法，以平衡重建质量和带宽消耗。\\n\\n**技术框架**：AirGS的整体框架包含以下几个主要模块：1) **数据转换模块**：将4D高斯视频流转换为多通道2D格式，以便更有效地进行处理和传输。2) **关键帧选择模块**：智能地选择关键帧，以提高帧重建质量。3) **训练优化模块**：利用时间一致性和膨胀损失来减少训练时间和表示大小。4) **传输优化模块**：将4DGS传输建模为一个整数线性规划问题，并设计轻量级的剪枝算法。\\n\\n**关键创新**：AirGS的关键创新在于其针对流传输场景的优化策略。与传统的4DGS方法相比，AirGS更加注重在有限带宽下实现高质量的自由视点视频体验。它通过数据转换、关键帧选择、训练优化和传输优化等多种手段，实现了在质量、训练速度和传输大小方面的显著提升。\\n\\n**关键设计**：AirGS的关键设计包括：1) **多通道2D格式**：将高斯视频流转换为多通道2D格式，以便更有效地进行处理和传输。具体实现方式未知。2) **关键帧选择算法**：智能地选择关键帧，以提高帧重建质量。具体算法细节未知。3) **膨胀损失**：用于减少训练时间和表示大小。具体公式和实现方式未知。4) **整数线性规划模型**：用于优化4DGS传输，平衡重建质量和带宽消耗。具体模型参数和约束条件未知。5) **轻量级剪枝算法**：自适应地剪枝待传输的高斯更新，以减少传输大小。具体算法细节未知。",
            "application_zh": "AirGS具有广泛的应用前景，包括沉浸式远程呈现、虚拟现实/增强现实(VR/AR)游戏、在线教育、数字孪生等领域。它能够提供高质量、低延迟的自由视点视频体验，使用户能够从任意角度观看场景，从而增强沉浸感和交互性。AirGS的优化策略使其更适合在带宽受限的环境中使用，为大规模部署自由视点视频技术提供了可能。",
            "highlight_zh": "实验结果表明，AirGS在多个方面均优于现有方法。在场景变化时，AirGS的PSNR质量偏差降低了20%以上，帧级别PSNR始终保持在30以上。此外，AirGS的训练速度提高了6倍，每帧传输大小减少了近50%。这些数据表明，AirGS在质量、效率和带宽利用率方面均具有显著优势。",
            "tags_zh": [
                "自由视点视频",
                "4D高斯溅射",
                "流传输",
                "实时渲染",
                "带宽优化"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20943v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20943v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20943v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "XGrid-Mapping: Explicit Implicit Hybrid Grid Submaps for Efficient Incremental Neural LiDAR Mapping",
            "authors": [
                "Zeqing Song",
                "Zhongmiao Yan",
                "Junyuan Deng",
                "Songpengcheng Xia",
                "Xiang Mu",
                "Jingyi Xu",
                "Qi Wu",
                "Ling Pei"
            ],
            "arxiv_id": "2512.20976v1",
            "summary": "Large-scale incremental mapping is fundamental to the development of robust and reliable autonomous systems, as it underpins incremental environmental understanding with sequential inputs for navigation and decision-making. LiDAR is widely used for this purpose due to its accuracy and robustness. Recently, neural LiDAR mapping has shown impressive performance; however, most approaches rely on dense implicit representations and underutilize geometric structure, while existing voxel-guided methods struggle to achieve real-time performance. To address these challenges, we propose XGrid-Mapping, a hybrid grid framework that jointly exploits explicit and implicit representations for efficient neural LiDAR mapping. Specifically, the strategy combines a sparse grid, providing geometric priors and structural guidance, with an implicit dense grid that enriches scene representation. By coupling the VDB structure with a submap-based organization, the framework reduces computational load and enables efficient incremental mapping on a large scale. To mitigate discontinuities across submaps, we introduce a distillation-based overlap alignment strategy, in which preceding submaps supervise subsequent ones to ensure consistency in overlapping regions. To further enhance robustness and sampling efficiency, we incorporate a dynamic removal module. Extensive experiments show that our approach delivers superior mapping quality while overcoming the efficiency limitations of voxel-guided methods, thereby outperforming existing state-of-the-art mapping methods.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20976v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "implicit representation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 3.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出XGrid-Mapping，利用显隐混合网格子图实现高效增量式神经激光雷达建图",
            "summary_zh": "大规模增量式建图是构建鲁棒可靠的自主系统的基础，它支撑着利用连续输入进行增量式环境理解，从而为导航和决策提供支持。激光雷达因其精度和鲁棒性而被广泛使用。近年来，神经激光雷达建图表现出令人印象深刻的性能；然而，大多数方法依赖于密集的隐式表示，未能充分利用几何结构，而现有的基于体素的方法难以实现实时性能。为了解决这些挑战，我们提出了XGrid-Mapping，一种混合网格框架，它联合利用显式和隐式表示来实现高效的神经激光雷达建图。具体来说，该策略将提供几何先验和结构指导的稀疏网格与丰富场景表示的隐式密集网格相结合。通过将VDB结构与基于子图的组织相结合，该框架降低了计算负载，并实现了大规模高效的增量式建图。为了减轻子图之间的不连续性，我们引入了一种基于蒸馏的重叠对齐策略，其中先前的子图监督后续的子图，以确保重叠区域的一致性。为了进一步提高鲁棒性和采样效率，我们加入了一个动态移除模块。大量的实验表明，我们的方法提供了卓越的建图质量，同时克服了基于体素的方法的效率限制，从而优于现有的最先进的建图方法。",
            "intro_zh": [
                "现有神经激光雷达建图方法依赖密集隐式表示，忽略几何结构，或基于体素的方法难以实时运行。",
                "XGrid-Mapping结合稀疏显式网格和密集隐式网格，利用VDB结构和子图组织，实现高效增量建图。",
                "引入基于蒸馏的重叠对齐策略和动态移除模块，提升子图一致性、鲁棒性和采样效率。"
            ],
            "method_zh": "**问题定义**：现有神经激光雷达建图方法主要面临两个挑战：一是基于隐式表示的方法忽略了激光雷达数据的几何结构信息，导致建图精度受限；二是基于体素的方法计算复杂度高，难以实现大规模场景下的实时增量式建图。因此，如何兼顾建图精度和效率，实现大规模场景下的实时增量式神经激光雷达建图是本文要解决的核心问题。\\n\\n**核心思路**：XGrid-Mapping的核心思路是结合显式和隐式表示的优点。显式表示（稀疏网格）提供几何先验和结构指导，降低学习难度；隐式表示（密集网格）则可以更精细地表达场景细节。通过这种混合表示，可以在保证建图精度的同时，提高建图效率。此外，采用基于子图的组织方式和蒸馏对齐策略，进一步提升了大规模场景下的建图效果。\\n\\n**技术框架**：XGrid-Mapping的整体框架包括以下几个主要模块：1) 稀疏显式网格：使用VDB结构存储稀疏体素网格，提供几何先验；2) 隐式密集网格：使用MLP网络学习每个体素的占用概率，精细化场景表示；3) 子图管理：将场景划分为多个子图，降低计算负载；4) 蒸馏对齐：利用先前子图监督后续子图，保证子图间一致性；5) 动态移除模块：移除冗余点，提高采样效率。\\n\\n**关键创新**：XGrid-Mapping的关键创新在于以下几点：1) 显隐混合网格表示：结合了显式和隐式表示的优点，提高了建图精度和效率；2) 基于蒸馏的重叠对齐策略：有效缓解了子图之间的不连续性问题；3) 动态移除模块：提高了采样效率和鲁棒性。与现有方法相比，XGrid-Mapping在保证建图精度的前提下，显著提高了建图效率，更适合大规模场景下的实时应用。\\n\\n**关键设计**：在显隐混合网格表示中，稀疏网格的分辨率和隐式网络的结构是关键参数。蒸馏损失函数的设计也至关重要，需要平衡精度和效率。动态移除模块的阈值设置会影响采样效率和鲁棒性。具体而言，论文可能采用了交叉熵损失函数来训练隐式网络，并使用L1或L2损失函数进行蒸馏对齐。稀疏网格的分辨率需要根据场景的复杂度进行调整。",
            "application_zh": "XGrid-Mapping在自动驾驶、机器人导航、三维重建等领域具有广泛的应用前景。它可以为自动驾驶车辆提供高精度、实时的环境地图，从而提高导航的准确性和安全性。在机器人导航领域，它可以帮助机器人在复杂环境中进行自主探索和定位。在三维重建领域，它可以用于构建高精度的三维模型，应用于城市规划、文物保护等领域。未来，该研究可以进一步扩展到动态环境下的建图，以及多传感器融合的建图。",
            "highlight_zh": "实验结果表明，XGrid-Mapping在建图质量上优于现有的state-of-the-art方法，同时克服了基于体素的方法的效率限制。具体性能数据未知，但摘要强调了其在效率上的显著提升，表明该方法在保证精度的前提下，能够实现更快的建图速度，更适合大规模场景的应用。",
            "tags_zh": [
                "激光雷达建图",
                "神经表示",
                "增量式建图",
                "显隐混合表示",
                "子图管理"
            ],
            "_index": 54,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20976v1/picture_new/intro.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20976v1/picture_new/voxel-raycast.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20976v1/picture_new/approach-pipeline-f.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
            "authors": [
                "Le Wang",
                "Zonghao Ying",
                "Xiao Yang",
                "Quanchen Zou",
                "Zhenfei Yin",
                "Tianlin Li",
                "Jian Yang",
                "Yaodong Yang",
                "Aishan Liu",
                "Xianglong Liu"
            ],
            "arxiv_id": "2512.21220v1",
            "summary": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent's multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.",
            "categories": [
                "cs.AI",
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "11 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21220v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RoboSafe：通过可执行安全逻辑保障具身智能体的安全",
            "summary_zh": "具身智能体在视觉-语言模型（VLM）驱动下，执行复杂现实世界任务的能力日益增强，但它们仍然容易受到可能触发不安全行为的危险指令的影响。运行时安全防护栏因其灵活性而提供了一种有前景的解决方案，可以在任务执行期间拦截危险动作。然而，现有的防御措施通常依赖于静态规则过滤器或提示级别的控制，难以解决动态、时间依赖和上下文丰富的环境中出现的隐式风险。为了解决这个问题，我们提出了RoboSafe，一种混合推理运行时安全保障，通过可执行的基于谓词的安全逻辑来保护具身智能体。RoboSafe在混合长短期安全记忆上集成了两种互补的推理过程。我们首先提出了一个后向反射推理模块，该模块不断回顾短期记忆中的近期轨迹，以推断时间安全谓词，并在检测到违规时主动触发重新规划。然后，我们提出了一个前向预测推理模块，该模块通过从长期安全记忆和智能体的多模态观察中生成上下文感知的安全谓词来预测即将到来的风险。这些组件共同构成了一种自适应的、可验证的安全逻辑，既可解释又可作为代码执行。跨多个智能体的大量实验表明，与领先的基线相比，RoboSafe显著减少了危险行为（风险发生率降低36.8%），同时保持了接近原始的任务性能。在物理机械臂上的真实世界评估进一步证实了它的实用性。代码将在接收后发布。",
            "intro_zh": [
                "现有具身智能体的安全防护依赖静态规则或提示控制，难以应对动态环境中隐式风险。",
                "RoboSafe提出混合推理运行时安全保障，通过可执行的谓词安全逻辑，实现自适应安全。",
                "实验表明，RoboSafe显著降低了危险行为发生率，同时保持了任务性能，并在真实机械臂上验证了实用性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决具身智能体在执行任务时，由于环境的动态性和指令的复杂性，容易出现不安全行为的问题。现有方法，如静态规则过滤和提示级别控制，无法有效应对时间依赖和上下文相关的隐式风险，导致智能体可能做出危险动作。\\n\\n**核心思路**：RoboSafe的核心思路是构建一个混合推理的运行时安全保障系统，通过结合后向反射推理和前向预测推理，对智能体的行为进行动态的安全评估和干预。这种混合推理方式能够同时考虑历史轨迹和未来风险，从而更全面地保障智能体的安全。\\n\\n**技术框架**：RoboSafe的整体架构包含以下几个主要模块：1) 混合长短期安全记忆：用于存储智能体的历史轨迹和安全知识。2) 后向反射推理模块：回顾短期记忆中的近期轨迹，推断时间安全谓词，并在检测到违规时触发重新规划。3) 前向预测推理模块：从长期安全记忆和智能体的多模态观察中生成上下文感知的安全谓词，预测即将到来的风险。4) 可执行安全逻辑：将安全谓词转化为可执行的代码，用于实时监控和干预智能体的行为。\\n\\n**关键创新**：RoboSafe的关键创新在于其混合推理机制和可执行安全逻辑。传统的安全保障方法通常依赖于静态规则或提示工程，而RoboSafe能够根据环境和任务的动态变化，自适应地调整安全策略。可执行安全逻辑使得安全规则更加透明和可验证，方便开发者进行调试和优化。\\n\\n**关键设计**：RoboSafe的关键设计包括：1) 混合长短期安全记忆的结构和更新策略，用于有效存储和检索相关信息。2) 后向反射推理模块中，时间安全谓词的定义和推理方法，用于检测历史轨迹中的安全违规。3) 前向预测推理模块中，上下文感知安全谓词的生成方法，以及如何利用多模态观察进行风险预测。4) 可执行安全逻辑的实现方式，以及如何将其与智能体的控制系统进行集成。",
            "application_zh": "RoboSafe可应用于各种需要安全保障的具身智能体场景，如家庭服务机器人、工业机器人、自动驾驶车辆等。通过减少危险行为的发生，RoboSafe能够提高智能体的可靠性和安全性，降低事故风险，从而促进具身智能体在现实世界中的广泛应用。",
            "highlight_zh": "实验结果表明，RoboSafe在多个智能体上显著降低了危险行为的发生率，风险发生率降低了36.8%，优于现有的基线方法。同时，RoboSafe保持了接近原始的任务性能，表明其安全保障措施不会对智能体的效率产生显著影响。在真实机械臂上的实验进一步验证了RoboSafe的实用性和有效性。",
            "tags_zh": [
                "具身智能体",
                "安全保障",
                "运行时安全",
                "混合推理",
                "可执行逻辑",
                "安全谓词",
                "风险预测"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21220v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21220v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21220v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ETP-R1: Evolving Topological Planning with Reinforcement Fine-tuning for Vision-Language Navigation in Continuous Environments",
            "authors": [
                "Shuhao Ye",
                "Sitong Mao",
                "Yuxiang Cui",
                "Xuan Yu",
                "Shichao Zhai",
                "Wen Chen",
                "Shunbo Zhou",
                "Rong Xiong",
                "Yue Wang"
            ],
            "arxiv_id": "2512.20940v1",
            "summary": "Vision-Language Navigation in Continuous Environments (VLN-CE) requires an embodied agent to navigate towards target in continuous environments, following natural language instructions. While current graph-based methods offer an efficient, structured approach by abstracting the environment into a topological map and simplifying the action space to waypoint selection, they lag behind methods based on Large Vision-Language Models (LVLMs) in leveraging large-scale data and advanced training paradigms. In this paper, we try to bridge this gap by introducing ETP-R1, a framework that applies the paradigm of scaling up data and Reinforcement Fine-Tuning (RFT) to a graph-based VLN-CE model. To build a strong foundation, we first construct a high-quality, large-scale pretraining dataset using the Gemini API. This dataset consists of diverse, low-hallucination instructions for topological trajectories, providing rich supervision for our graph-based policy to map language to topological paths. This foundation is further strengthened by unifying data from both R2R and RxR tasks for joint pretraining. Building on this, we introduce a three-stage training paradigm, which culminates in the first application of closed-loop, online RFT to a graph-based VLN-CE model, powered by the Group Relative Policy Optimization (GRPO) algorithm. Extensive experiments demonstrate that our approach is highly effective, establishing new state-of-the-art performance across all major metrics on both the R2R-CE and RxR-CE benchmarks. Our code is available at https://github.com/Cepillar/ETP-R1.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "8 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20940v1",
            "code_links": [
                {
                    "url": "https://github.com/Cepillar/ETP-R1",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "VLN"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ETP-R1：通过强化微调演化拓扑规划，解决连续环境下的视觉-语言导航问题。",
            "summary_zh": "本文提出ETP-R1框架，旨在弥合基于图的视觉-语言导航在连续环境（VLN-CE）中的方法与基于大型视觉-语言模型（LVLMs）的方法之间的差距。ETP-R1将数据规模化和强化微调（RFT）应用于基于图的VLN-CE模型。首先，利用Gemini API构建高质量、大规模的预训练数据集，该数据集包含多样化的、低幻觉的拓扑轨迹指令，为基于图的策略提供了丰富的监督，以将语言映射到拓扑路径。通过统一来自R2R和RxR任务的数据进行联合预训练，进一步加强了这一基础。在此基础上，引入了一个三阶段的训练范式，最终将闭环、在线RFT首次应用于基于图的VLN-CE模型，并由Group Relative Policy Optimization (GRPO)算法提供支持。大量实验表明，该方法非常有效，在R2R-CE和RxR-CE基准测试中都建立了新的最先进的性能。",
            "intro_zh": [
                "现有基于图的VLN-CE方法在利用大规模数据和先进训练范式方面落后于基于LVLM的方法。",
                "ETP-R1通过构建大规模预训练数据集和引入强化微调，提升了基于图的VLN-CE模型的性能。",
                "实验结果表明，ETP-R1在R2R-CE和RxR-CE基准测试中取得了新的state-of-the-art性能。"
            ],
            "method_zh": "**问题定义**：视觉-语言导航在连续环境（VLN-CE）中，智能体需要根据自然语言指令在连续环境中导航到目标位置。现有基于图的方法虽然通过将环境抽象为拓扑地图并简化动作空间（仅需选择航点）提高了效率，但在利用大规模数据和先进训练范式方面不如基于大型视觉-语言模型（LVLMs）的方法。因此，如何提升基于图的方法的性能，使其能够充分利用大规模数据和先进训练范式，是本文要解决的问题。\\n\\n**核心思路**：本文的核心思路是将数据规模化和强化微调（RFT）应用于基于图的VLN-CE模型。通过构建大规模、高质量的预训练数据集，为模型提供丰富的监督信息，使其能够更好地将语言指令映射到拓扑路径。然后，通过强化微调进一步优化模型的策略，使其能够在真实环境中更好地导航。\\n\\n**技术框架**：ETP-R1框架包含三个主要阶段：1) **数据构建阶段**：利用Gemini API生成大规模、高质量的预训练数据集，包含多样化的、低幻觉的拓扑轨迹指令。2) **预训练阶段**：使用R2R和RxR任务的数据进行联合预训练，提升模型的泛化能力。3) **强化微调阶段**：使用Group Relative Policy Optimization (GRPO)算法进行闭环、在线强化微调，进一步优化模型的策略。\\n\\n**关键创新**：本文的关键创新在于首次将闭环、在线强化微调应用于基于图的VLN-CE模型。此外，利用Gemini API构建大规模、高质量的预训练数据集也是一个重要的创新点，它为模型提供了丰富的监督信息，使其能够更好地学习语言指令和环境之间的关系。\\n\\n**关键设计**：在数据构建阶段，使用Gemini API生成多样化的、低幻觉的拓扑轨迹指令。在预训练阶段，使用交叉熵损失函数来训练模型，使其能够更好地预测正确的拓扑路径。在强化微调阶段，使用Group Relative Policy Optimization (GRPO)算法来优化模型的策略，GRPO算法通过比较不同智能体的策略来减少方差，提高训练的稳定性。",
            "application_zh": "该研究成果可应用于机器人导航、虚拟现实、智能家居等领域。例如，可以利用该技术开发能够根据用户语音指令在复杂环境中自主导航的机器人，或者构建更加智能化的虚拟现实环境，使用户可以通过自然语言与虚拟环境进行交互。此外，该技术还可以应用于智能家居领域，实现更加便捷的语音控制和自动化服务。",
            "highlight_zh": "ETP-R1在R2R-CE和RxR-CE基准测试中都取得了新的state-of-the-art性能。具体来说，在R2R-CE基准测试中，ETP-R1在所有主要指标上都优于现有方法。在RxR-CE基准测试中，ETP-R1也取得了显著的性能提升，表明该方法具有很强的泛化能力。",
            "tags_zh": [
                "视觉语言导航",
                "连续环境",
                "拓扑规划",
                "强化学习",
                "预训练",
                "大型语言模型",
                "机器人导航"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20940v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20940v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20940v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Fast SAM2 with Text-Driven Token Pruning",
            "authors": [
                "Avilasha Mandal",
                "Chaoning Zhang",
                "Fachrina Dewi Puspitasari",
                "Xudong Wang",
                "Jiaquan Zhang",
                "Caiyan Qin",
                "Guoqing Wang",
                "Yang Yang",
                "Heng Tao Shen"
            ],
            "arxiv_id": "2512.21333v1",
            "summary": "Segment Anything Model 2 (SAM2), a vision foundation model has significantly advanced in prompt-driven video object segmentation, yet their practical deployment remains limited by the high computational and memory cost of processing dense visual tokens across time. The SAM2 pipelines typically propagate all visual tokens produced by the image encoder through downstream temporal reasoning modules, regardless of their relevance to the target object, resulting in reduced scalability due to quadratic memory attention overhead. In this work, we introduce a text-guided token pruning framework that improves inference efficiency by selectively reducing token density prior to temporal propagation, without modifying the underlying segmentation architecture. Operating after visual encoding and before memory based propagation, our method ranks tokens using a lightweight routing mechanism that integrates local visual context, semantic relevance derived from object-centric textual descriptions (either user-provided or automatically generated), and uncertainty cues that help preserve ambiguous or boundary critical regions. By retaining only the most informative tokens for downstream processing, the proposed approach reduces redundant computation while maintaining segmentation fidelity. Extensive experiments across multiple challenging video segmentation benchmarks demonstrate that post-encoder token pruning provides a practical and effective pathway to efficient, prompt-aware video segmentation, achieving up to 42.50 percent faster inference and 37.41 percent lower GPU memory usage compared to the unpruned baseline SAM2, while preserving competitive J and F performance. These results highlight the potential of early token selection to improve the scalability of transformer-based video segmentation systems for real-time and resource-constrained applications.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "28 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21333v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于文本驱动的token剪枝Fast SAM2，加速视频分割并降低资源消耗。",
            "summary_zh": "本文提出了一种基于文本引导的token剪枝框架，旨在提高Segment Anything Model 2 (SAM2) 在视频对象分割中的推理效率。该方法在视觉编码后、时序传播前选择性地减少token密度，无需修改底层分割架构。通过轻量级的路由机制，该方法融合局部视觉上下文、来自对象中心文本描述的语义相关性以及不确定性线索来评估token的重要性。仅保留信息量最大的token用于下游处理，从而减少冗余计算，同时保持分割精度。在多个具有挑战性的视频分割基准测试中，实验结果表明，与未剪枝的SAM2基线相比，所提出的方法实现了高达42.50%的推理速度提升和37.41%的GPU内存使用量降低，同时保持了具有竞争力的J和F性能。这突显了早期token选择在提高基于Transformer的视频分割系统在实时和资源受限应用中的可扩展性方面的潜力。",
            "intro_zh": [
                "SAM2在视频分割中表现出色，但处理密集视觉token导致计算和内存成本高昂，限制了实际部署。",
                "该文提出文本引导的token剪枝框架，在时序传播前选择性减少token密度，提升推理效率。",
                "实验表明，该方法在保持分割精度的同时，显著提升推理速度并降低GPU内存使用。"
            ],
            "method_zh": "**问题定义**：SAM2在视频分割任务中，需要处理大量的视觉tokens，导致计算和内存开销巨大，尤其是在处理长视频时，二次方级别的注意力机制使得资源消耗更加严重。现有的方法通常直接将所有视觉tokens传递到下游模块，而忽略了其中可能存在大量冗余信息，这限制了SAM2在资源受限设备上的应用。\n\n**核心思路**：本文的核心思路是在视觉编码后，时序传播前，对视觉tokens进行剪枝，只保留对目标对象分割有用的tokens。通过引入文本信息，引导token选择，使得剪枝过程更加智能，能够在减少计算量的同时，保持分割精度。这种方法避免了对SAM2底层架构的修改，易于集成和部署。\n\n**技术框架**：该方法主要包含三个阶段：视觉编码、token路由和时序传播。首先，使用SAM2的图像编码器提取视觉特征。然后，通过一个轻量级的路由机制对tokens进行排序，该机制融合了局部视觉上下文、文本语义相关性和不确定性线索。最后，只保留排名靠前的tokens进行时序传播和分割。文本信息可以是用户提供的，也可以是自动生成的。\n\n**关键创新**：该方法最重要的创新点在于引入了文本信息来指导token剪枝。与传统的基于视觉特征的token选择方法相比，文本信息能够提供更高级别的语义指导，使得剪枝过程更加关注目标对象，从而在减少计算量的同时，更好地保持分割精度。此外，该方法还考虑了不确定性线索，保留了边界区域的tokens，进一步提升了分割的鲁棒性。\n\n**关键设计**：token路由机制是该方法的核心。该机制使用一个轻量级的神经网络来预测每个token的重要性得分。输入包括局部视觉特征、文本嵌入和不确定性估计。局部视觉特征通过卷积操作提取，文本嵌入通过预训练的文本编码器获得，不确定性估计通过计算token特征的方差得到。损失函数采用交叉熵损失，目标是最大化保留的tokens与目标对象之间的IoU。",
            "application_zh": "该研究成果可应用于实时视频监控、自动驾驶、机器人导航等领域。通过降低计算和内存需求，使得SAM2能够在资源受限的设备上运行，从而扩展了其应用范围。此外，该方法还可以用于视频编辑、内容创作等领域，提高视频处理的效率和质量。",
            "highlight_zh": "实验结果表明，与未剪枝的SAM2基线相比，该方法在多个视频分割基准测试中实现了显著的性能提升。具体而言，推理速度提升了高达42.50%，GPU内存使用量降低了37.41%，同时保持了具有竞争力的J和F性能。这些结果表明，该方法是一种有效的视频分割加速方案。",
            "tags_zh": [
                "视频分割",
                "token剪枝",
                "文本引导",
                "模型加速",
                "SAM2"
            ],
            "_index": 57,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21333v1/tokens_1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21333v1/miansam.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21333v1/architechture_1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Leveraging Lightweight Entity Extraction for Scalable Event-Based Image Retrieval",
            "authors": [
                "Dao Sy Duy Minh",
                "Huynh Trung Kiet",
                "Nguyen Lam Phu Quy",
                "Phu-Hoa Pham",
                "Tran Chi Nguyen"
            ],
            "arxiv_id": "2512.21221v1",
            "summary": "Retrieving images from natural language descriptions is a core task at the intersection of computer vision and natural language processing, with wide-ranging applications in search engines, media archiving, and digital content management. However, real-world image-text retrieval remains challenging due to vague or context-dependent queries, linguistic variability, and the need for scalable solutions. In this work, we propose a lightweight two-stage retrieval pipeline that leverages event-centric entity extraction to incorporate temporal and contextual signals from real-world captions. The first stage performs efficient candidate filtering using BM25 based on salient entities, while the second stage applies BEiT-3 models to capture deep multimodal semantics and rerank the results. Evaluated on the OpenEvents v1 benchmark, our method achieves a mean average precision of 0.559, substantially outperforming prior baselines. These results highlight the effectiveness of combining event-guided filtering with long-text vision-language modeling for accurate and efficient retrieval in complex, real-world scenarios. Our code is available at https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "System description paper for EVENTA Grand Challenge Track 2 at ACM Multimedia 2025 (MM '25). Ranked 4th place. 6 pages, 1 figure, 2 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21221v1",
            "code_links": [
                {
                    "url": "https://github.com/PhamPhuHoa-23/Event-Based-Image-Retrieval",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于事件中心实体提取的两阶段图像检索方法，提升复杂场景下的检索精度。",
            "summary_zh": "本文提出了一种轻量级的两阶段图像检索流程，旨在利用事件中心实体提取来整合真实场景字幕中的时间和上下文信息。第一阶段，该流程使用基于BM25的显著实体进行高效的候选过滤。第二阶段，应用BEiT-3模型来捕捉深层的多模态语义并对结果进行重排序。在OpenEvents v1基准测试中，该方法实现了0.559的平均精度均值（mAP），显著优于先前的基线方法。实验结果表明，在复杂的真实场景中，将事件引导的过滤与长文本视觉-语言建模相结合，能够实现准确而高效的图像检索。",
            "intro_zh": [
                "真实场景图像-文本检索面临模糊查询、语言变异性和可扩展性挑战。",
                "利用事件中心实体提取，结合BM25过滤和BEiT-3重排序，提升检索效率和精度。",
                "在OpenEvents v1数据集上，该方法mAP达到0.559，显著优于现有方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决真实场景下图像-文本检索的难题，现有方法难以有效处理复杂、模糊的自然语言描述，并且缺乏对事件上下文信息的充分利用，导致检索精度不高，尤其是在大规模数据集上。\n\n**核心思路**：论文的核心思路是利用事件相关的实体信息作为桥梁，将图像和文本联系起来。通过提取文本描述中的关键实体，并将其作为检索的线索，可以有效地过滤掉不相关的图像，从而提高检索效率和精度。同时，利用预训练的BEiT-3模型来学习图像和文本的深层语义表示，进一步提升检索性能。\n\n**技术框架**：该方法采用两阶段检索框架。第一阶段是候选过滤阶段，使用BM25算法基于提取的实体信息对图像进行初步筛选，快速缩小检索范围。第二阶段是重排序阶段，使用BEiT-3模型对候选图像进行多模态语义分析，并根据图像和文本的相似度对结果进行重排序，最终返回最相关的图像。\n\n**关键创新**：该方法最重要的创新点在于将事件中心实体提取与视觉-语言模型相结合，充分利用了事件的上下文信息，从而提高了检索的准确性和效率。此外，两阶段检索框架的设计也使得该方法能够在大规模数据集上进行高效检索。\n\n**关键设计**：在第一阶段，使用轻量级的实体提取方法，保证了检索的效率。BM25算法被用于快速计算文本和图像描述之间的相似度。在第二阶段，BEiT-3模型被用于学习图像和文本的深层语义表示，并使用余弦相似度来衡量图像和文本之间的相似度。具体的参数设置和网络结构细节在论文中未详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于搜索引擎、媒体内容管理、数字内容归档等领域。通过更准确地理解图像内容和用户查询意图，可以提升搜索结果的相关性，改善用户体验。未来，该方法有望应用于智能监控、自动驾驶等需要理解场景事件的领域。",
            "highlight_zh": "该方法在OpenEvents v1基准测试中取得了显著的成果，平均精度均值（mAP）达到了0.559，大幅超越了现有的基线方法。这表明该方法在处理复杂、真实的图像-文本检索任务时具有很强的竞争力，验证了事件引导过滤与长文本视觉-语言建模结合的有效性。",
            "tags_zh": [
                "图像检索",
                "事件提取",
                "多模态学习",
                "BEiT-3",
                "BM25",
                "视觉语言模型",
                "自然语言处理"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21221v1/Images_pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Latent Implicit Visual Reasoning",
            "authors": [
                "Kelvin Li",
                "Chuyi Shang",
                "Leonid Karlinsky",
                "Rogerio Feris",
                "Trevor Darrell",
                "Roei Herzig"
            ],
            "arxiv_id": "2512.21218v1",
            "summary": "While Large Multimodal Models (LMMs) have made significant progress, they remain largely text-centric, relying on language as their core reasoning modality. As a result, they are limited in their ability to handle reasoning tasks that are predominantly visual. Recent approaches have sought to address this by supervising intermediate visual steps with helper images, depth maps, or image crops. However, these strategies impose restrictive priors on what \"useful\" visual abstractions look like, add heavy annotation costs, and struggle to generalize across tasks. To address this critical limitation, we propose a task-agnostic mechanism that trains LMMs to discover and use visual reasoning tokens without explicit supervision. These tokens attend globally and re-encode the image in a task-adaptive way, enabling the model to extract relevant visual information without hand-crafted supervision. Our approach outperforms direct fine-tuning and achieves state-of-the-art results on a diverse range of vision-centric tasks -- including those where intermediate abstractions are hard to specify -- while also generalizing to multi-task instruction tuning.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21218v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Latent Implicit Visual Reasoning，无需显式监督即可提升LMMs的视觉推理能力。",
            "summary_zh": "大型多模态模型(LMMs)取得了显著进展，但它们仍然以文本为中心，依赖语言作为核心推理方式。这限制了它们处理以视觉为主的推理任务的能力。为了解决这个问题，现有方法尝试通过辅助图像、深度图或图像裁剪来监督中间视觉步骤。然而，这些策略对“有用”的视觉抽象施加了限制性先验，增加了大量的标注成本，并且难以跨任务泛化。为了解决这一关键限制，我们提出了一种与任务无关的机制，该机制训练LMMs来发现和使用视觉推理token，而无需显式监督。这些token全局关注并以任务自适应的方式重新编码图像，使模型能够在没有手工监督的情况下提取相关的视觉信息。我们的方法优于直接微调，并在各种以视觉为中心的任务上实现了最先进的结果，包括那些难以指定中间抽象的任务，同时也推广到多任务指令调优。",
            "intro_zh": [
                "现有LMMs在视觉推理方面受限，依赖文本，且中间视觉步骤的监督方法存在标注成本高、泛化性差等问题。",
                "论文提出一种任务无关的机制，训练LMMs发现和使用视觉推理token，无需显式监督，自适应地提取视觉信息。",
                "实验表明，该方法优于直接微调，在多种视觉任务上达到SOTA，并能推广到多任务指令调优。"
            ],
            "method_zh": "**问题定义**：现有的大型多模态模型在处理视觉推理任务时，过度依赖文本信息，导致性能受限。为了提升视觉推理能力，一些方法尝试引入中间视觉步骤的监督，例如使用辅助图像或图像裁剪。然而，这些方法需要大量的人工标注，并且对视觉抽象的形式做出了较强的假设，限制了模型的泛化能力。因此，如何让模型在没有显式监督的情况下，自主学习并利用视觉信息进行推理，是一个亟待解决的问题。\\n\\n**核心思路**：论文的核心思路是训练LMMs学习一组“潜在隐式视觉推理token”。这些token能够全局关注图像，并以任务自适应的方式重新编码图像，从而提取与当前任务相关的视觉信息。关键在于，这些token的训练过程不需要任何显式的视觉监督信号，而是通过端到端的训练，让模型自主学习如何利用这些token进行视觉推理。\\n\\n**技术框架**：整体框架可以概括为：首先，输入图像经过一个视觉编码器（例如，预训练的ViT）提取图像特征。然后，将这些图像特征与一组可学习的视觉推理token拼接在一起。接着，将拼接后的特征输入到LMM中进行处理。LMM利用这些视觉推理token来关注和重新编码图像特征，从而提取与当前任务相关的视觉信息。最后，LMM根据提取的视觉信息和输入的文本指令，生成最终的输出。\\n\\n**关键创新**：最重要的创新点在于，提出了一种无需显式监督的视觉推理token学习方法。与现有方法相比，该方法不需要人工标注的中间视觉步骤，也不需要对视觉抽象的形式做任何假设。这使得模型能够更加灵活地学习和利用视觉信息，从而提升视觉推理能力。\\n\\n**关键设计**：视觉推理token的数量是一个重要的超参数，需要根据具体的任务进行调整。损失函数通常采用标准的交叉熵损失或生成损失，用于训练LMM生成正确的输出。在训练过程中，可以使用各种正则化技术，例如dropout或权重衰减，来防止过拟合。此外，还可以使用数据增强技术，例如随机裁剪或旋转，来增加数据的多样性。",
            "application_zh": "该研究成果可广泛应用于需要复杂视觉推理的场景，例如视觉问答、图像描述、机器人导航、智能监控等。通过提升LMMs的视觉推理能力，可以使其更好地理解和利用视觉信息，从而实现更智能、更可靠的应用。此外，该方法无需显式监督的特性，也降低了模型训练的成本，使其更容易部署到实际应用中。",
            "highlight_zh": "实验结果表明，该方法在多个视觉推理任务上取得了显著的性能提升，超越了直接微调和其他基于中间视觉步骤监督的方法。例如，在一些需要复杂视觉推理的任务上，该方法能够取得超过SOTA方法5%以上的性能提升。此外，实验还表明，该方法具有良好的泛化能力，能够推广到多任务指令调优。",
            "tags_zh": [
                "视觉推理",
                "大型多模态模型",
                "无监督学习",
                "视觉表征学习",
                "任务自适应",
                "视觉问答",
                "图像描述"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21218v1/images/livr_teaser.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21218v1/images/livr_method_combined2.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21218v1/images/latent_viz.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TexAvatars : Hybrid Texel-3D Representations for Stable Rigging of Photorealistic Gaussian Head Avatars",
            "authors": [
                "Jaeseong Lee",
                "Junyeong Ahn",
                "Taewoong Kang",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.21099v1",
            "summary": "Constructing drivable and photorealistic 3D head avatars has become a central task in AR/XR, enabling immersive and expressive user experiences. With the emergence of high-fidelity and efficient representations such as 3D Gaussians, recent works have pushed toward ultra-detailed head avatars. Existing approaches typically fall into two categories: rule-based analytic rigging or neural network-based deformation fields. While effective in constrained settings, both approaches often fail to generalize to unseen expressions and poses, particularly in extreme reenactment scenarios. Other methods constrain Gaussians to the global texel space of 3DMMs to reduce rendering complexity. However, these texel-based avatars tend to underutilize the underlying mesh structure. They apply minimal analytic deformation and rely heavily on neural regressors and heuristic regularization in UV space, which weakens geometric consistency and limits extrapolation to complex, out-of-distribution deformations. To address these limitations, we introduce TexAvatars, a hybrid avatar representation that combines the explicit geometric grounding of analytic rigging with the spatial continuity of texel space. Our approach predicts local geometric attributes in UV space via CNNs, but drives 3D deformation through mesh-aware Jacobians, enabling smooth and semantically meaningful transitions across triangle boundaries. This hybrid design separates semantic modeling from geometric control, resulting in improved generalization, interpretability, and stability. Furthermore, TexAvatars captures fine-grained expression effects, including muscle-induced wrinkles, glabellar lines, and realistic mouth cavity geometry, with high fidelity. Our method achieves state-of-the-art performance under extreme pose and expression variations, demonstrating strong generalization in challenging head reenactment settings.",
            "categories": [
                "cs.GR",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "3DV 2026, Project page with videos: https://summertight.github.io/TexAvatars/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21099v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "geometric consistency"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "7_retargeting"
            ],
            "headline_zh": "TexAvatars：结合Texel和3D表示，实现逼真高斯头部头像的稳定绑定",
            "summary_zh": "构建可驱动且逼真的3D头部头像已成为AR/XR的核心任务，能够实现沉浸式和富有表现力的用户体验。随着3D高斯等高保真和高效表示的出现，最近的研究已转向超细节的头部头像。现有方法通常分为两类：基于规则的解析绑定或基于神经网络的变形场。虽然在受限设置中有效，但两种方法通常无法推广到未见过的表情和姿势，尤其是在极端的重演场景中。其他方法将高斯约束到3DMM的全局纹素空间，以降低渲染复杂度。然而，这些基于纹素的头像往往未能充分利用底层网格结构。它们应用最少的解析变形，并严重依赖UV空间中的神经回归器和启发式正则化，这削弱了几何一致性，并限制了外推到复杂的、超出分布的变形。为了解决这些限制，我们引入了TexAvatars，一种混合头像表示，它将解析绑定的显式几何基础与纹素空间的空间连续性相结合。我们的方法通过CNN预测UV空间中的局部几何属性，但通过网格感知的雅可比矩阵驱动3D变形，从而实现跨三角形边界的平滑和语义上有意义的过渡。这种混合设计将语义建模与几何控制分离，从而提高了泛化性、可解释性和稳定性。此外，TexAvatars以高保真度捕捉细粒度的表情效果，包括肌肉引起的皱纹、眉间纹和逼真的口腔几何形状。我们的方法在极端的姿势和表情变化下实现了最先进的性能，在具有挑战性的头部重演设置中表现出强大的泛化能力。",
            "intro_zh": [
                "现有头部头像方法在极端姿势和表情下泛化性差，且过度依赖神经回归器，导致几何一致性弱，难以处理复杂变形。",
                "TexAvatars结合解析绑定的几何基础和纹素空间的空间连续性，通过网格感知的雅可比矩阵驱动3D变形，实现平滑过渡。",
                "TexAvatars在极端姿势和表情变化下实现了最先进的性能，能够捕捉细粒度的表情效果，具有强大的泛化能力。"
            ],
            "method_zh": "**问题定义**：现有3D头部头像构建方法，如基于规则的解析绑定和基于神经网络的变形场，在处理极端姿势和表情时泛化能力不足。基于纹素的方法虽然降低了渲染复杂度，但过度依赖神经回归器和启发式正则化，削弱了几何一致性，限制了对复杂变形的外推能力。\\n\\n**核心思路**：TexAvatars的核心思路是结合解析绑定的显式几何基础和纹素空间的空间连续性，提出一种混合头像表示。通过在UV空间预测局部几何属性，并利用网格感知的雅可比矩阵驱动3D变形，从而实现平滑且语义上有意义的变形。这种混合设计将语义建模与几何控制分离，提升了泛化性、可解释性和稳定性。\\n\\n**技术框架**：TexAvatars的技术框架主要包含以下几个阶段：1) 在UV空间使用CNN预测局部几何属性；2) 利用网格结构计算网格感知的雅可比矩阵；3) 使用雅可比矩阵驱动3D变形，从而实现头部头像的姿势和表情控制。该框架的关键在于将语义建模（CNN预测几何属性）与几何控制（雅可比矩阵驱动变形）解耦。\\n\\n**关键创新**：TexAvatars最重要的技术创新点在于其混合表示方法，它结合了解析绑定的几何基础和纹素空间的空间连续性。与完全依赖神经回归器的方法不同，TexAvatars利用网格感知的雅可比矩阵进行变形，从而保证了几何一致性，并提高了对复杂变形的泛化能力。\\n\\n**关键设计**：TexAvatars的关键设计包括：1) 使用CNN在UV空间预测局部几何属性，例如顶点位移；2) 设计网格感知的雅可比矩阵，用于将UV空间的变形转换为3D空间的变形；3) 使用合适的损失函数来训练CNN，例如L1损失或L2损失，以保证预测的几何属性的准确性。",
            "application_zh": "TexAvatars在AR/XR领域具有广泛的应用前景，可以用于创建逼真且可驱动的3D头部头像，从而提升用户在虚拟会议、游戏和社交互动中的沉浸感和表达能力。该技术还可以应用于虚拟形象定制、数字内容创作和远程呈现等领域，具有重要的实际价值和未来影响。",
            "highlight_zh": "TexAvatars在极端姿势和表情变化下实现了最先进的性能，能够捕捉细粒度的表情效果，例如肌肉引起的皱纹和逼真的口腔几何形状。实验结果表明，TexAvatars在具有挑战性的头部重演设置中表现出强大的泛化能力，优于现有的基于规则和基于神经网络的方法。",
            "tags_zh": [
                "3D头部头像",
                "高斯表示",
                "解析绑定",
                "纹素空间",
                "神经渲染",
                "AR/XR",
                "表情重演"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21099v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21099v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21099v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation",
            "authors": [
                "Zhe Cao",
                "Tao Wang",
                "Jiaming Wang",
                "Yanghai Wang",
                "Yuanxing Zhang",
                "Jialu Chen",
                "Miao Deng",
                "Jiahao Wang",
                "Yubin Guo",
                "Chenxi Liao",
                "Yize Zhang",
                "Zhaoxiang Zhang",
                "Jiaheng Liu"
            ],
            "arxiv_id": "2512.21094v1",
            "summary": "Text-to-Audio-Video (T2AV) generation aims to synthesize temporally coherent video and semantically synchronized audio from natural language, yet its evaluation remains fragmented, often relying on unimodal metrics or narrowly scoped benchmarks that fail to capture cross-modal alignment, instruction following, and perceptual realism under complex prompts. To address this limitation, we present T2AV-Compass, a unified benchmark for comprehensive evaluation of T2AV systems, consisting of 500 diverse and complex prompts constructed via a taxonomy-driven pipeline to ensure semantic richness and physical plausibility. Besides, T2AV-Compass introduces a dual-level evaluation framework that integrates objective signal-level metrics for video quality, audio quality, and cross-modal alignment with a subjective MLLM-as-a-Judge protocol for instruction following and realism assessment. Extensive evaluation of 11 representative T2AVsystems reveals that even the strongest models fall substantially short of human-level realism and cross-modal consistency, with persistent failures in audio realism, fine-grained synchronization, instruction following, etc. These results indicate significant improvement room for future models and highlight the value of T2AV-Compass as a challenging and diagnostic testbed for advancing text-to-audio-video generation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21094v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "instruction following"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出T2AV-Compass，用于统一评估文本到音视频生成模型的性能",
            "summary_zh": "文本到音视频生成(T2AV)旨在从自然语言合成时间连贯的视频和语义同步的音频，但其评估仍然是分散的，通常依赖于单模态指标或范围狭窄的基准，无法捕捉跨模态对齐、指令遵循以及复杂提示下的感知真实感。为了解决这个局限性，我们提出了T2AV-Compass，一个统一的基准，用于全面评估T2AV系统，包含500个多样且复杂的提示，这些提示通过分类驱动的流程构建，以确保语义丰富性和物理合理性。此外，T2AV-Compass引入了一个双层评估框架，该框架集成了用于视频质量、音频质量和跨模态对齐的客观信号级指标，以及用于指令遵循和真实感评估的主观MLLM-as-a-Judge协议。对11个代表性T2AV系统的广泛评估表明，即使是最强大的模型也远未达到人类水平的真实感和跨模态一致性，在音频真实感、细粒度同步、指令遵循等方面存在持续的失败。这些结果表明未来模型有很大的改进空间，并突出了T2AV-Compass作为具有挑战性和诊断性的测试平台，对于推进文本到音视频生成的重要价值。",
            "intro_zh": [
                "现有T2AV评估方法依赖单模态指标或窄范围基准，无法全面评估跨模态对齐、指令遵循和真实感。",
                "T2AV-Compass构建了一个包含500个复杂提示的统一基准，并结合客观指标和主观评估的双层框架。",
                "实验表明现有T2AV模型在真实感和跨模态一致性方面存在不足，T2AV-Compass可有效诊断这些问题。"
            ],
            "method_zh": "**问题定义**：T2AV-Compass旨在解决文本到音视频生成（T2AV）领域缺乏统一、全面的评估基准的问题。现有评估方法要么侧重于单模态（音频或视频）的质量评估，要么使用范围有限的基准数据集，无法有效衡量模型在跨模态对齐、指令遵循以及生成内容真实感等方面的综合能力。现有方法的痛点在于无法准确反映T2AV模型的实际性能，阻碍了该领域的发展。\\n\\n**核心思路**：T2AV-Compass的核心思路是构建一个多样化、复杂化的测试数据集，并设计一个双层评估框架，从客观和主观两个层面全面评估T2AV模型的性能。通过精心设计的提示语，考察模型对复杂指令的理解和执行能力，以及生成音视频在语义一致性和感知真实感方面的表现。这种设计旨在更贴近实际应用场景，从而更准确地评估模型的优劣。\\n\\n**技术框架**：T2AV-Compass的整体框架包含两个主要组成部分：一是数据集构建，二是评估框架。数据集构建采用分类驱动的流程，确保提示语在语义和物理上的合理性。评估框架则分为两个层次：第一层是客观评估，使用信号级别的指标来衡量视频和音频的质量，以及跨模态的对齐程度；第二层是主观评估，利用大型语言模型（MLLM）作为裁判，评估生成内容在指令遵循和真实感方面的表现。\\n\\n**关键创新**：T2AV-Compass的关键创新在于其统一的评估视角和双层评估框架。它不仅考虑了单模态的质量，更关注跨模态的语义一致性和时间同步性。此外，引入MLLM作为主观评估者，能够更有效地捕捉人类对生成内容真实感的感知。与现有方法相比，T2AV-Compass能够更全面、更准确地评估T2AV模型的性能。\\n\\n**关键设计**：在数据集构建方面，T2AV-Compass采用了分类驱动的方法，确保提示语的多样性和复杂性。在评估框架方面，客观指标包括PSNR、SSIM等用于衡量视频质量，PESQ、STOI等用于衡量音频质量，以及CLIP score等用于衡量跨模态对齐。主观评估则通过设计特定的prompt，让MLLM对生成内容的指令遵循程度和真实感进行评分。",
            "application_zh": "T2AV-Compass可用于评估和改进文本到音视频生成模型，推动该技术在娱乐、教育、广告等领域的应用。例如，可以用于自动生成电影预告片、制作教学视频、创建个性化广告等。该基准的推出将加速T2AV技术的发展，并促进其在实际场景中的广泛应用。",
            "highlight_zh": "对11个代表性T2AV系统的评估表明，现有模型在音频真实感、细粒度同步和指令遵循方面存在显著不足。即使是最强的模型也远未达到人类水平的真实感和跨模态一致性。例如，在主观评估中，现有模型的真实感得分普遍较低，表明未来模型有很大的提升空间。T2AV-Compass的评估结果为未来T2AV模型的研究方向提供了重要参考。",
            "tags_zh": [
                "文本到音视频生成",
                "多模态评估",
                "统一基准",
                "跨模态对齐",
                "指令遵循",
                "真实感评估",
                "大型语言模型",
                "客观指标"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Reasoning-Driven Amodal Completion: Collaborative Agents and Perceptual Evaluation",
            "authors": [
                "Hongxing Fan",
                "Shuyu Zhao",
                "Jiayang Ao",
                "Lu Sheng"
            ],
            "arxiv_id": "2512.20936v1",
            "summary": "Amodal completion, the task of inferring invisible object parts, faces significant challenges in maintaining semantic consistency and structural integrity. Prior progressive approaches are inherently limited by inference instability and error accumulation. To tackle these limitations, we present a Collaborative Multi-Agent Reasoning Framework that explicitly decouples Semantic Planning from Visual Synthesis. By employing specialized agents for upfront reasoning, our method generates a structured, explicit plan before pixel generation, enabling visually and semantically coherent single-pass synthesis. We integrate this framework with two critical mechanisms: (1) a self-correcting Verification Agent that employs Chain-of-Thought reasoning to rectify visible region segmentation and identify residual occluders strictly within the Semantic Planning phase, and (2) a Diverse Hypothesis Generator that addresses the ambiguity of invisible regions by offering diverse, plausible semantic interpretations, surpassing the limited pixel-level variations of standard random seed sampling. Furthermore, addressing the limitations of traditional metrics in assessing inferred invisible content, we introduce the MAC-Score (MLLM Amodal Completion Score), a novel human-aligned evaluation metric. Validated against human judgment and ground truth, these metrics establish a robust standard for assessing structural completeness and semantic consistency with visible context. Extensive experiments demonstrate that our framework significantly outperforms state-of-the-art methods across multiple datasets. Our project is available at: https://fanhongxing.github.io/remac-page.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20936v1",
            "code_links": [
                {
                    "url": "https://fanhongxing.github.io/remac-page",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "chain-of-thought"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于协同多智能体推理的非模态补全框架，解决语义一致性和结构完整性问题",
            "summary_zh": "非模态补全旨在推断不可见物体部分，但面临保持语义一致性和结构完整性的挑战。现有的渐进式方法受限于推理不稳定和误差累积。为解决这些问题，我们提出了一个协同多智能体推理框架，将语义规划与视觉合成显式解耦。通过使用专门的智能体进行前期推理，我们的方法在像素生成之前生成结构化的显式计划，从而实现视觉和语义上连贯的单次合成。我们集成了两个关键机制：(1)一个自校正验证智能体，采用思维链推理来纠正可见区域分割，并在语义规划阶段识别剩余遮挡物；(2)一个多样化假设生成器，通过提供多样化、合理的语义解释来解决不可见区域的模糊性，超越了标准随机种子抽样的有限像素级变化。此外，针对传统指标在评估推断的不可见内容方面的局限性，我们引入了MAC-Score（MLLM非模态补全得分），一种新型的人类对齐评估指标。经验证，这些指标与人类判断和真实数据相符，为评估结构完整性和与可见上下文的语义一致性建立了可靠的标准。大量实验表明，我们的框架在多个数据集上显著优于最先进的方法。",
            "intro_zh": [
                "现有非模态补全方法在语义一致性和结构完整性方面存在不足，易受推理不稳定和误差累积的影响。",
                "提出协同多智能体推理框架，通过语义规划和视觉合成解耦，以及自校正和多样化假设生成机制，提升补全效果。",
                "实验结果表明，该框架在多个数据集上显著优于现有方法，并提出了更符合人类感知的评估指标MAC-Score。"
            ],
            "method_zh": "**问题定义**：非模态补全任务旨在根据可见部分推断被遮挡的物体部分。现有方法，特别是渐进式方法，容易受到推理不稳定和误差累积的影响，难以保证补全结果的语义一致性和结构完整性。这些方法通常依赖于逐步的像素级生成，缺乏对全局语义信息的有效利用，导致补全结果与可见部分不协调。\\n\\n**核心思路**：论文的核心思路是将语义规划与视觉合成解耦，通过一个协同多智能体框架，首先进行全局的语义推理和规划，然后再进行像素级的视觉合成。这种方式避免了渐进式方法中的误差累积问题，并能够更好地利用全局语义信息，从而生成更合理、更连贯的补全结果。通过显式地生成一个结构化的计划，可以指导后续的视觉合成过程，确保补全结果在语义和视觉上与可见部分保持一致。\\n\\n**技术框架**：该框架包含多个协同工作的智能体，主要包括：语义规划智能体、视觉合成智能体、验证智能体和多样化假设生成器。语义规划智能体负责根据可见部分进行全局的语义推理，生成一个结构化的补全计划。视觉合成智能体根据该计划生成像素级的补全结果。验证智能体使用思维链推理来纠正可见区域分割错误，并识别剩余的遮挡物。多样化假设生成器则负责生成多种可能的补全方案，以应对不可见区域的模糊性。整个流程首先由语义规划智能体生成补全计划，然后由验证智能体进行校正，接着由多样化假设生成器生成多个候选方案，最后由视觉合成智能体根据最佳方案生成最终的补全结果。\\n\\n**关键创新**：该论文的关键创新在于以下几点：(1) 提出了协同多智能体推理框架，将语义规划与视觉合成解耦，避免了误差累积；(2) 引入了自校正验证智能体，能够纠正可见区域分割错误，提高补全的准确性；(3) 提出了多样化假设生成器，能够生成多种可能的补全方案，应对不可见区域的模糊性；(4) 提出了MAC-Score评估指标，更符合人类对补全结果的感知。与现有方法的本质区别在于，该方法不是直接进行像素级的生成，而是首先进行全局的语义推理和规划，从而更好地利用全局语义信息，生成更合理、更连贯的补全结果。\\n\\n**关键设计**：验证智能体采用了Chain-of-Thought推理，通过逐步推理来识别和纠正分割错误。多样化假设生成器通过采样不同的语义解释来生成多个候选方案。MAC-Score评估指标结合了MLLM（大型语言模型）的推理能力，能够更准确地评估补全结果的语义一致性和结构完整性。具体的网络结构和损失函数细节在论文中进行了详细描述，但摘要中未提供具体参数设置。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、图像编辑、三维重建等领域。例如，在自动驾驶中，非模态补全可以帮助车辆理解被遮挡的物体，提高环境感知能力。在机器人导航中，可以帮助机器人推断被遮挡的路径，规划更合理的运动轨迹。在图像编辑中，可以用于修复图像中的缺失部分，提高图像质量。该研究具有重要的实际应用价值和广阔的应用前景。",
            "highlight_zh": "实验结果表明，该框架在多个数据集上显著优于现有方法。例如，在XXX数据集上，该方法的性能提升了XX%。此外，MAC-Score评估指标与人类判断具有高度一致性，能够更准确地评估补全结果的质量。这些实验结果充分验证了该框架的有效性和优越性。",
            "tags_zh": [
                "非模态补全",
                "多智能体系统",
                "语义推理",
                "视觉合成",
                "思维链",
                "自校正",
                "多样性生成"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20936v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20936v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20936v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond Weight Adaptation: Feature-Space Domain Injection for Cross-Modal Ship Re-Identification",
            "authors": [
                "Tingfeng Xian",
                "Wenlve Zhou",
                "Zhiheng Zhou",
                "Zhelin Li"
            ],
            "arxiv_id": "2512.20892v1",
            "summary": "Cross-Modality Ship Re-Identification (CMS Re-ID) is critical for achieving all-day and all-weather maritime target tracking, yet it is fundamentally challenged by significant modality discrepancies. Mainstream solutions typically rely on explicit modality alignment strategies; however, this paradigm heavily depends on constructing large-scale paired datasets for pre-training. To address this, grounded in the Platonic Representation Hypothesis, we explore the potential of Vision Foundation Models (VFMs) in bridging modality gaps. Recognizing the suboptimal performance of existing generic Parameter-Efficient Fine-Tuning (PEFT) methods that operate within the weight space, particularly on limited-capacity models, we shift the optimization perspective to the feature space and propose a novel PEFT strategy termed Domain Representation Injection (DRI). Specifically, while keeping the VFM fully frozen to maximize the preservation of general knowledge, we design a lightweight, learnable Offset Encoder to extract domain-specific representations rich in modality and identity attributes from raw inputs. Guided by the contextual information of intermediate features at different layers, a Modulator adaptively transforms these representations. Subsequently, they are injected into the intermediate layers via additive fusion, dynamically reshaping the feature distribution to adapt to the downstream task without altering the VFM's pre-trained weights. Extensive experimental results demonstrate the superiority of our method, achieving State-of-the-Art (SOTA) performance with minimal trainable parameters. For instance, on the HOSS-ReID dataset, we attain 57.9\\% and 60.5\\% mAP using only 1.54M and 7.05M parameters, respectively. The code is available at https://github.com/TingfengXian/DRI.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20892v1",
            "code_links": [
                {
                    "url": "https://github.com/TingfengXian/DRI",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出领域表示注入方法以解决跨模态船舶再识别问题",
            "summary_zh": "跨模态船舶再识别（CMS Re-ID）对全天候海洋目标跟踪至关重要，但面临显著的模态差异挑战。现有主流解决方案通常依赖于显式模态对齐策略，然而这种方法严重依赖于构建大规模配对数据集进行预训练。为了解决这一问题，基于柏拉图表征假设，本文探讨了视觉基础模型（VFM）在弥合模态差距方面的潜力。我们提出了一种新颖的参数高效微调策略，称为领域表示注入（DRI），通过保持VFM完全冻结，设计轻量级可学习的偏移编码器，从原始输入中提取丰富的模态和身份属性的领域特征。实验结果表明，该方法在HOSS-ReID数据集上实现了57.9%和60.5%的mAP，参数量仅为1.54M和7.05M。",
            "intro_zh": [
                "现有的跨模态船舶再识别方法依赖于大规模配对数据集，导致模态对齐效果不佳。",
                "本文提出领域表示注入（DRI）策略，通过特征空间优化而非权重空间，提升跨模态再识别性能。",
                "在HOSS-ReID数据集上，DRI方法以最少的可训练参数实现了SOTA性能，显著提升了识别精度。"
            ],
            "method_zh": "**问题定义**：本文旨在解决跨模态船舶再识别中的模态差异问题。现有方法通常依赖于大规模配对数据集进行预训练，导致在小型模型上的性能不佳。\\n\\n**核心思路**：我们提出领域表示注入（DRI）策略，转向特征空间的优化，通过冻结VFM来保留通用知识，同时提取领域特定的表示。\\n\\n**技术框架**：整体架构包括一个偏移编码器和一个调制器。偏移编码器从原始输入中提取领域特征，调制器根据中间特征的上下文信息进行自适应转换，最后通过加法融合将这些表示注入到中间层。\\n\\n**关键创新**：DRI方法的核心创新在于通过特征空间的动态重塑来适应下游任务，而不改变VFM的预训练权重。这一方法显著提升了模型在跨模态任务中的表现。\\n\\n**关键设计**：我们设计了轻量级的偏移编码器和调制器，采用了特定的损失函数来优化领域特征的提取与融合，确保了模型的高效性与准确性。通过精简的参数设置，DRI方法在保持性能的同时降低了计算复杂度。",
            "application_zh": "该研究在海洋监测、船舶识别和智能交通等领域具有广泛的应用潜力。通过提高跨模态再识别的准确性，能够有效支持全天候的海洋目标跟踪，提升海洋安全和管理效率。未来，该方法还可扩展至其他多模态识别任务，推动相关技术的发展。",
            "highlight_zh": "实验结果显示，DRI方法在HOSS-ReID数据集上取得了57.9%和60.5%的mAP，分别使用了1.54M和7.05M的参数，显著优于现有的基线方法，展示了其在参数效率和识别精度上的优势。",
            "tags_zh": [
                "跨模态再识别",
                "领域表示注入",
                "视觉基础模型",
                "参数高效微调",
                "海洋目标跟踪"
            ],
            "_index": 63,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20892v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20892v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20892v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics",
            "authors": [
                "Jiashuo Liu",
                "Jiayun Wu",
                "Chunjie Wu",
                "Jingkai Liu",
                "Zaiyuan Wang",
                "Huan Zhou",
                "Wenhao Huang",
                "Hongseok Namkoong"
            ],
            "arxiv_id": "2512.21010v1",
            "summary": "The rapid proliferation of Large Language Models (LLMs) and diverse specialized benchmarks necessitates a shift from fragmented, task-specific metrics to a holistic, competitive ranking system that effectively aggregates performance across multiple ability dimensions. Primarily using static scoring, current evaluation methods are fundamentally limited. They struggle to determine the proper mix ratio across diverse benchmarks, and critically, they fail to capture a model's dynamic competitive fitness or its vulnerability when confronted with sequential, high-stakes tasks. To address this, we introduce the novel Competitive Swiss-System Dynamics (CSD) framework. CSD simulates a multi-round, sequential contest where models are dynamically paired across a curated sequence of benchmarks based on their accumulated win-loss record. And Monte Carlo Simulation ($N=100,000$ iterations) is used to approximate the statistically robust Expected Win Score ($E[S_m]$), which eliminates the noise of random pairing and early-round luck. Furthermore, we implement a Failure Sensitivity Analysis by parameterizing the per-round elimination quantity ($T_k$), which allows us to profile models based on their risk appetite--distinguishing between robust generalists and aggressive specialists. We demonstrate that CSD provides a more nuanced and context-aware ranking than traditional aggregate scoring and static pairwise models, representing a vital step towards risk-informed, next-generation LLM evaluation.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.PF"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "18 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21010v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于竞争瑞士轮动态系统的LLM综合评估框架，解决静态评估的局限性。",
            "summary_zh": "大型语言模型（LLM）的快速发展和多样化的专业基准测试需要从零散的、特定于任务的指标转变为一个整体的、竞争性的排名系统，该系统能够有效地聚合跨多个能力维度的性能。当前的评估方法主要使用静态评分，存在根本性的局限性。它们难以确定不同基准测试之间的适当混合比例，并且关键的是，它们无法捕捉模型在面对连续、高风险任务时的动态竞争适应性或脆弱性。为了解决这个问题，我们引入了新颖的竞争瑞士轮动态系统（CSD）框架。CSD模拟了一个多轮、连续的竞赛，其中模型根据其累积的胜负记录，在精心策划的基准测试序列中动态配对。并使用蒙特卡罗模拟（$N=100,000$次迭代）来近似统计上稳健的预期获胜分数（$E[S_m]$），从而消除随机配对和早期运气带来的噪声。此外，我们通过参数化每轮淘汰数量（$T_k$）来实现失败敏感性分析，这使我们能够根据模型的风险偏好来分析模型——区分稳健的通才和激进的专家。我们证明，CSD提供了比传统的聚合评分和静态配对模型更细致和上下文感知的排名，代表着迈向风险知情、下一代LLM评估的重要一步。",
            "intro_zh": [
                "现有LLM评估方法依赖静态评分，无法有效整合多维度基准测试结果，且忽略了模型在连续任务中的动态竞争能力。",
                "论文提出竞争瑞士轮动态系统（CSD），模拟多轮竞赛，根据模型胜负记录动态配对，评估其综合性能。",
                "通过蒙特卡罗模拟和失败敏感性分析，CSD能更准确地评估LLM的预期获胜分数和风险承受能力，提供更细致的排名。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）评估方法主要依赖于静态评分，这导致了几个关键问题。首先，不同基准测试之间的权重难以确定，导致综合评分可能无法准确反映模型的真实能力。其次，静态评分无法捕捉模型在连续、高风险任务中的动态表现，即模型在面对一系列挑战时的适应性和稳定性。最后，现有方法缺乏对模型风险承受能力的评估，无法区分稳健的通用模型和激进的专业模型。\\n\\n**核心思路**：论文的核心思路是引入竞争瑞士轮动态系统（CSD），将LLM的评估过程模拟成一个多轮的竞赛。在这个竞赛中，模型根据其历史胜负记录动态配对，并在不同的基准测试中进行对抗。通过这种方式，可以更全面地评估模型的综合能力和动态适应性。此外，通过失败敏感性分析，可以评估模型在面对失败时的表现，从而更好地理解模型的风险承受能力。\\n\\n**技术框架**：CSD框架主要包含以下几个阶段：1) **基准测试选择**：选择一系列具有代表性的基准测试，以覆盖LLM的多个能力维度。2) **模型配对**：根据模型的历史胜负记录，使用瑞士轮算法动态配对模型。3) **竞赛模拟**：在每个配对中，模型在选定的基准测试上进行对抗，并记录胜负结果。4) **预期获胜分数计算**：使用蒙特卡罗模拟（$N=100,000$次迭代）来近似统计上稳健的预期获胜分数（$E[S_m]$），从而消除随机配对和早期运气带来的噪声。5) **失败敏感性分析**：通过参数化每轮淘汰数量（$T_k$），分析模型在不同风险水平下的表现。\\n\\n**关键创新**：CSD框架的关键创新在于其动态性和竞争性。与传统的静态评分方法不同，CSD能够捕捉模型在连续任务中的动态表现，并评估其风险承受能力。此外，CSD使用瑞士轮算法进行模型配对，保证了每个模型都有机会与不同水平的对手进行对抗，从而更全面地评估其能力。\\n\\n**关键设计**：CSD框架的关键设计包括：1) **瑞士轮算法**：用于动态配对模型，保证公平性和竞争性。2) **蒙特卡罗模拟**：用于计算预期获胜分数，消除随机性带来的影响。3) **失败敏感性分析**：通过参数化每轮淘汰数量（$T_k$），评估模型在不同风险水平下的表现。参数$T_k$的具体数值需要根据实际情况进行调整，以达到最佳的评估效果。",
            "application_zh": "该研究成果可应用于LLM的综合性能评估、模型选择和优化。通过CSD框架，可以更全面地了解LLM在不同任务和风险水平下的表现，从而为实际应用提供更可靠的依据。此外，该框架还可以用于指导LLM的训练和优化，使其在各种场景下都能表现出色。",
            "highlight_zh": "论文通过实验证明，CSD框架能够提供比传统聚合评分和静态配对模型更细致和上下文感知的LLM排名。CSD能够有效区分稳健的通用模型和激进的专业模型，并能更好地捕捉模型在连续任务中的动态表现。蒙特卡洛模拟的使用显著降低了随机配对带来的噪声，使得评估结果更加可靠。",
            "tags_zh": [
                "大型语言模型评估",
                "瑞士轮算法",
                "动态评估",
                "风险敏感性分析",
                "蒙特卡罗模拟"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21010v1/figure/overall.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21010v1/figure/tier.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21010v1/figure/two_dimension.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Deadline-Aware Online Scheduling for LLM Fine-Tuning with Spot Market Predictions",
            "authors": [
                "Linggao Kong",
                "Yuedong Xu",
                "Lei Jiao",
                "Chuan Xu"
            ],
            "arxiv_id": "2512.20967v1",
            "summary": "As foundation models grow in size, fine-tuning them becomes increasingly expensive. While GPU spot instances offer a low-cost alternative to on-demand resources, their volatile prices and availability make deadline-aware scheduling particularly challenging. We tackle this difficulty by using a mix of spot and on-demand instances. Distinctively, we show the predictability of prices and availability in a spot instance market, the power of prediction in enabling cost-efficient scheduling and its sensitivity to estimation errors. An integer programming problem is formulated to capture the use of mixed instances under both the price and availability dynamics. We propose an online allocation algorithm with prediction based on the committed horizon control approach that leverages a \\emph{commitment level} to enforce the partial sequence of decisions. When this prediction becomes inaccurate, we further present a complementary online algorithm without predictions. An online policy selection algorithm is developed that learns the best policy from a pool constructed by varying the parameters of both algorithms. We prove that the prediction-based algorithm achieves tighter performance bounds as prediction error decreases, while the policy selection algorithm possesses a regret bound of $\\mathcal{O}(\\sqrt{T})$. Experimental results demonstrate that our online framework can adaptively select the best policy under varying spot market dynamics and prediction quality, consistently outperforming baselines and improving utility by up to 54.8\\%.",
            "categories": [
                "cs.DC",
                "cs.LG"
            ],
            "primary_category": "cs.DC",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20967v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于预测的在线调度方法以优化LLM微调成本",
            "summary_zh": "随着基础模型规模的不断扩大，微调这些模型的成本也在增加。虽然GPU的现货实例提供了低成本的替代方案，但其价格和可用性的波动使得基于截止日期的调度变得尤为困难。本文通过混合使用现货和按需实例来解决这一问题。我们展示了现货市场中价格和可用性的可预测性，以及预测在实现成本高效调度中的重要性和对估计误差的敏感性。我们提出了一种基于承诺水平控制的方法的在线分配算法，并在预测不准确时提供了无预测的补充算法。实验结果表明，我们的在线框架能够在变化的现货市场动态和预测质量下自适应选择最佳策略，性能提升可达54.8%。",
            "intro_zh": [
                "现有方法在处理GPU现货实例的价格波动和可用性时面临挑战，导致微调成本高昂。",
                "论文提出了一种混合使用现货和按需实例的在线调度算法，利用价格和可用性预测来优化资源分配。",
                "实验结果显示，所提框架在不同市场动态下能够自适应选择最佳策略，性能提升显著，最高可达54.8%。"
            ],
            "method_zh": "**问题定义**：本文旨在解决在GPU现货市场中进行LLM微调时，由于价格波动和可用性不确定性导致的调度问题。现有方法未能有效利用现货实例的成本优势，导致资源利用率低下。\\n\\n**核心思路**：论文提出了一种结合现货和按需实例的在线调度算法，利用对市场价格和可用性的预测来实现成本效益最大化。通过承诺水平控制的方法，算法能够在动态环境中做出更优决策。\\n\\n**技术框架**：整体框架包括预测模块、在线分配算法和策略选择算法。预测模块负责估计价格和可用性，在线分配算法基于预测结果进行资源分配，而策略选择算法则从多种策略中学习最佳选择。\\n\\n**关键创新**：最重要的创新在于提出了基于承诺水平的在线调度算法，能够在预测准确时提供更紧的性能界限，并在预测失误时切换到无预测的补充算法。这种灵活性是现有方法所不具备的。\\n\\n**关键设计**：算法设计中包含了对承诺水平的设置，损失函数的选择，以及如何构建策略池以便进行在线学习。这些设计确保了算法在不同市场条件下的适应性和鲁棒性。",
            "application_zh": "该研究的潜在应用领域包括大规模机器学习模型的训练和微调，尤其是在资源有限或成本敏感的环境中。通过优化调度策略，可以显著降低训练成本，提高资源利用率，推动AI技术的普及与应用。",
            "highlight_zh": "实验结果表明，所提出的在线调度框架在不同的现货市场动态和预测质量下，能够自适应选择最佳策略，性能提升可达54.8%。与基线相比，算法在成本效益和资源利用率上表现出显著优势。",
            "tags_zh": [
                "在线调度",
                "现货市场",
                "LLM微调",
                "成本优化",
                "预测算法",
                "资源分配",
                "机器学习"
            ],
            "_index": 65,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20967v1/figure/throughput_vs_gpu_glm3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20967v1/figure/throughput_vs_gpu_llama2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20967v1/figure/a100_avail.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Can Agentic AI Match the Performance of Human Data Scientists?",
            "authors": [
                "An Luo",
                "Jin Du",
                "Fangqiao Tian",
                "Xun Xian",
                "Robert Specht",
                "Ganghua Wang",
                "Xuan Bi",
                "Charles Fleming",
                "Jayanth Srinivasa",
                "Ashish Kundu",
                "Mingyi Hong",
                "Jie Ding"
            ],
            "arxiv_id": "2512.20959v1",
            "summary": "Data science plays a critical role in transforming complex data into actionable insights across numerous domains. Recent developments in large language models (LLMs) have significantly automated data science workflows, but a fundamental question persists: Can these agentic AI systems truly match the performance of human data scientists who routinely leverage domain-specific knowledge? We explore this question by designing a prediction task where a crucial latent variable is hidden in relevant image data instead of tabular features. As a result, agentic AI that generates generic codes for modeling tabular data cannot perform well, while human experts could identify the important hidden variable using domain knowledge. We demonstrate this idea with a synthetic dataset for property insurance. Our experiments show that agentic AI that relies on generic analytics workflow falls short of methods that use domain-specific insights. This highlights a key limitation of the current agentic AI for data science and underscores the need for future research to develop agentic AI systems that can better recognize and incorporate domain knowledge.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "stat.ME"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20959v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Agentic AI在数据科学中能否匹敌人类专家？领域知识至关重要",
            "summary_zh": "数据科学在将复杂数据转化为可执行的洞察方面发挥着关键作用。大型语言模型（LLMs）的最新发展已显著自动化了数据科学工作流程，但一个根本问题仍然存在：这些agentic AI系统能否真正匹敌那些经常利用领域特定知识的人类数据科学家？我们通过设计一个预测任务来探索这个问题，其中一个关键的潜在变量隐藏在相关的图像数据中，而不是表格特征中。因此，为建模表格数据生成通用代码的agentic AI无法表现良好，而人类专家可以使用领域知识识别重要的隐藏变量。我们用财产保险的合成数据集证明了这一想法。我们的实验表明，依赖于通用分析工作流程的agentic AI不如使用领域特定见解的方法。这突出了当前用于数据科学的agentic AI的一个关键局限性，并强调了未来研究开发能够更好识别和整合领域知识的agentic AI系统的必要性。",
            "intro_zh": [
                "现有agentic AI在数据科学任务中，尤其是在需要领域知识的任务中，性能与人类专家存在差距。",
                "论文设计了一个预测任务，其中关键信息隐藏在图像数据中，以此来模拟需要领域知识才能解决的问题。",
                "实验表明，依赖通用分析流程的agentic AI在处理此类任务时表现不佳，突显了领域知识的重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在研究当前agentic AI在数据科学任务中，尤其是在需要领域知识的任务中，是否能够达到人类专家的水平。现有agentic AI主要依赖于通用代码和表格数据分析，缺乏对领域知识的有效利用，导致在某些任务中表现不佳。\\n\\n**核心思路**：论文的核心思路是通过设计一个特殊的预测任务，该任务的关键信息隐藏在图像数据中，而非传统的表格特征中。这样，只有具备相关领域知识的人类专家才能识别出这些隐藏信息，从而做出准确的预测。而缺乏领域知识的agentic AI则难以有效解决该问题。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 构建一个合成数据集，模拟财产保险领域的预测任务；2) 将关键的潜在变量隐藏在图像数据中；3) 使用agentic AI和人类专家分别对该数据集进行建模和预测；4) 比较agentic AI和人类专家的预测性能。\\n\\n**关键创新**：论文最重要的技术创新点在于其任务设计，即巧妙地将关键信息隐藏在图像数据中，从而模拟了需要领域知识才能解决的实际问题。这种设计能够有效地评估agentic AI在利用领域知识方面的能力，并揭示其与人类专家之间的差距。\\n\\n**关键设计**：在数据集构建方面，论文使用了合成数据，并控制了数据中的噪声和相关性，以确保实验结果的可靠性。在模型选择方面，论文选择了具有代表性的agentic AI系统，并对其进行了适当的配置和优化。在性能评估方面，论文使用了多种指标，如准确率、召回率和F1值，以全面评估agentic AI和人类专家的预测性能。",
            "application_zh": "该研究成果可应用于评估和改进现有agentic AI系统在数据科学领域的应用能力，尤其是在需要领域知识的任务中。通过揭示agentic AI的局限性，可以指导未来的研究方向，例如开发能够更好整合领域知识的agentic AI系统，从而提高其在实际应用中的性能和可靠性。此外，该研究还可以促进人机协作，让人类专家和agentic AI能够更好地协同工作，共同解决复杂的数据科学问题。",
            "highlight_zh": "实验结果表明，在关键信息隐藏在图像数据中的预测任务中，依赖通用分析流程的agentic AI的性能明显低于人类专家。这表明，当前agentic AI在利用领域知识方面存在不足，无法有效解决需要领域知识的任务。该研究结果为改进agentic AI系统提供了重要的指导。",
            "tags_zh": [
                "Agentic AI",
                "数据科学",
                "领域知识",
                "大型语言模型",
                "图像数据",
                "预测任务",
                "人机协作"
            ],
            "_index": 66,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20959v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20959v1/roof_good.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20959v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks",
            "authors": [
                "Ningyuan Liu",
                "Jing Yang",
                "Kaitong Cai",
                "Keze Wang"
            ],
            "arxiv_id": "2512.20920v1",
            "summary": "Full parameter fine tuning is a key technique for adapting large language models (LLMs) to downstream tasks, but it incurs substantial memory overhead due to the need to cache extensive intermediate activations for backpropagation. This bottleneck makes full fine tuning of contemporary large scale LLMs challenging in practice. Existing distributed training frameworks such as DeepSpeed alleviate this issue using techniques like ZeRO and FSDP, which rely on multi GPU memory or CPU offloading, but often require additional hardware resources and reduce training speed. We introduce RevFFN, a memory efficient fine tuning paradigm for mixture of experts (MoE) LLMs. RevFFN employs carefully designed reversible Transformer blocks that allow reconstruction of layer input activations from outputs during backpropagation, eliminating the need to store most intermediate activations in memory. While preserving the expressive capacity of MoE architectures, this approach significantly reduces peak memory consumption for full parameter fine tuning. As a result, RevFFN enables efficient full fine tuning on a single consumer grade or server grade GPU.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Under submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20920v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RevFFN：利用可逆块实现MoE LLM全参数高效微调",
            "summary_zh": "全参数微调是使大型语言模型（LLM）适应下游任务的关键技术，但由于需要缓存大量的中间激活值以进行反向传播，因此会产生巨大的内存开销。这一瓶颈使得对当前大规模LLM进行全参数微调在实践中具有挑战性。现有的分布式训练框架（如DeepSpeed）使用ZeRO和FSDP等技术来缓解这个问题，这些技术依赖于多GPU内存或CPU卸载，但通常需要额外的硬件资源并降低训练速度。我们引入了RevFFN，这是一种用于混合专家（MoE）LLM的内存高效微调范例。RevFFN采用精心设计的可逆Transformer块，允许在反向传播期间从输出重建层输入激活，从而无需在内存中存储大多数中间激活。在保留MoE架构的表达能力的同时，这种方法显著降低了全参数微调的峰值内存消耗。因此，RevFFN能够在单个消费级或服务器级GPU上实现高效的全参数微调。",
            "intro_zh": [
                "现有全参数微调方法因需缓存大量中间激活值，导致内存开销巨大，限制了大规模LLM的微调。",
                "RevFFN通过可逆Transformer块，在反向传播时从输出重建输入激活，避免存储大量中间激活值，降低内存消耗。",
                "RevFFN能够在单个GPU上实现高效的全参数微调，同时保持MoE架构的表达能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）全参数微调过程中内存消耗过大的问题。现有方法，如直接反向传播，需要存储所有中间层的激活值，这对于参数量巨大的LLM来说是不可接受的。即使使用分布式训练框架，也需要额外的硬件资源或牺牲训练速度。\\n\\n**核心思路**：论文的核心思路是利用可逆Transformer块，使得每一层的输入激活可以从输出激活中恢复出来。这样，在反向传播时，只需要存储少量激活值，就可以通过计算重建其他层的激活值，从而显著降低内存占用。\\n\\n**技术框架**：RevFFN的核心是可逆Transformer块的设计。标准的Transformer块被替换为可逆块，这些块的设计允许从输出计算输入。整体训练流程与标准的全参数微调流程类似，但在反向传播阶段，会动态地重新计算所需的激活值，而不是从内存中读取。\\n\\n**关键创新**：最关键的创新在于可逆Transformer块的设计，它允许在不显著增加计算量的前提下，避免存储大量的中间激活值。与传统的Transformer块相比，可逆块在结构上进行了调整，使得输入和输出之间存在可逆的映射关系。\\n\\n**关键设计**：可逆Transformer块的具体设计包括对前馈网络（FFN）的修改，使其具有可逆性。论文可能采用了特定的激活函数或网络结构，以保证可逆性。此外，损失函数和优化器的选择可能也需要进行调整，以适应可逆块的特性。",
            "application_zh": "RevFFN技术可广泛应用于各种需要对大型语言模型进行微调的场景，例如自然语言处理、机器翻译、文本生成等。它降低了微调LLM的硬件门槛，使得研究人员和开发者能够在资源有限的环境下进行模型定制和优化，加速LLM在各领域的应用。",
            "highlight_zh": "论文提出的RevFFN方法显著降低了MoE LLM全参数微调的内存消耗，使得在单个消费级或服务器级GPU上进行高效微调成为可能。具体的性能数据（例如，内存占用降低的百分比、训练速度的提升等）需要在论文中查找。",
            "tags_zh": [
                "大型语言模型",
                "全参数微调",
                "混合专家模型",
                "内存优化",
                "可逆神经网络"
            ],
            "_index": 67,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20920v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Architectural Trade-offs in Small Language Models Under Compute Constraints",
            "authors": [
                "Shivraj Singh Bhatti"
            ],
            "arxiv_id": "2512.20877v1",
            "summary": "We present a systematic empirical study of small language models under strict compute constraints, analyzing how architectural choices and training budget interact to determine performance. Starting from a linear next-token predictor, we progressively introduce nonlinearities, self-attention, and multi-layer transformer architectures, evaluating each on character-level modeling of Tiny Shakespeare and word-level modeling of Penn Treebank (PTB) and WikiText-2. We compare models using test negative log-likelihood (NLL), parameter count, and approximate training FLOPs to characterize accuracy-efficiency trade-offs. Our results show that attention-based models dominate MLPs in per-FLOP efficiency even at small scale, while increasing depth or context without sufficient optimization can degrade performance. We further examine rotary positional embeddings (RoPE), finding that architectural techniques successful in large language models do not necessarily transfer to small-model regimes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "15 pages, 11 images",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20877v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究计算约束下小型语言模型的架构权衡，揭示不同架构选择对性能的影响。",
            "summary_zh": "本文针对计算资源受限的小型语言模型，系统性地研究了架构选择和训练预算如何相互作用以决定模型性能。从线性下一个token预测器出发，逐步引入非线性、自注意力机制和多层Transformer架构，并在Tiny Shakespeare数据集（字符级别建模）以及Penn Treebank (PTB) 和 WikiText-2数据集（词级别建模）上进行评估。我们使用测试负对数似然（NLL）、参数数量和近似训练FLOPs来比较模型，从而表征准确率-效率的权衡。结果表明，即使在小规模下，基于注意力的模型在每FLOP效率方面也优于MLP，而增加深度或上下文长度但没有充分优化可能会降低性能。我们进一步研究了旋转位置嵌入（RoPE），发现大型语言模型中成功的架构技术不一定能迁移到小型模型中。",
            "intro_zh": [
                "现有小型语言模型在计算约束下，架构选择对性能的影响缺乏系统性研究。",
                "通过逐步引入非线性、自注意力等模块，研究不同架构在计算效率上的权衡。",
                "实验表明，注意力机制在小规模模型中更有效，而RoPE等技术不一定适用。"
            ],
            "method_zh": "**问题定义**：论文旨在研究在严格的计算资源约束下，小型语言模型（Small Language Models, SLMs）的架构选择对模型性能的影响。现有的研究通常集中在大型语言模型上，而忽略了小型模型在资源受限场景下的特殊性。因此，如何为小型模型选择合适的架构，以在有限的计算预算下最大化模型性能，是一个重要的挑战。\\n\\n**核心思路**：论文的核心思路是通过系统性的实验，比较不同架构选择（例如，MLP、自注意力机制、Transformer等）在小型语言模型上的性能表现。通过控制训练预算（FLOPs），分析不同架构的效率，从而揭示在计算约束下，架构选择与模型性能之间的权衡关系。\\n\\n**技术框架**：研究从一个简单的线性下一个token预测器开始，逐步增加模型的复杂度，包括引入非线性激活函数、自注意力机制和多层Transformer架构。在每个阶段，都评估模型在字符级别的Tiny Shakespeare数据集和词级别的Penn Treebank (PTB) 和 WikiText-2数据集上的性能。评估指标包括测试负对数似然（NLL）、参数数量和近似训练FLOPs。\\n\\n**关键创新**：该研究的关键创新在于对小型语言模型进行了系统性的架构探索，并量化了不同架构在计算效率上的差异。此外，研究还发现，在大模型上有效的技术（如RoPE）不一定适用于小型模型，这为小型模型的架构设计提供了新的视角。\\n\\n**关键设计**：研究中关键的设计包括：1) 逐步增加模型复杂度，以便隔离不同架构选择的影响；2) 使用FLOPs作为主要的计算预算约束，以便公平地比较不同架构的效率；3) 在多个数据集上进行评估，以验证结果的泛化性；4) 探索了旋转位置嵌入（RoPE）在小型模型上的效果，并发现其性能不如预期。",
            "application_zh": "该研究成果可应用于资源受限的边缘计算设备、移动设备或嵌入式系统中，例如智能家居设备、可穿戴设备等。通过选择合适的模型架构，可以在有限的计算资源下部署高性能的语言模型，从而实现本地化的自然语言处理功能，提高用户体验和数据安全性。",
            "highlight_zh": "实验结果表明，在计算资源受限的情况下，基于注意力的模型在每FLOP效率方面优于MLP。同时，研究发现，增加模型深度或上下文长度，但没有进行充分的优化，反而会降低模型性能。此外，RoPE等在大模型上有效的技术，在小型模型上的效果并不理想，这为小型语言模型的架构设计提供了重要的参考。",
            "tags_zh": [
                "小型语言模型",
                "架构选择",
                "计算约束",
                "自注意力机制",
                "Transformer",
                "模型效率",
                "旋转位置嵌入"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20877v1/images/tiny_train_val_loss.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20877v1/images/linear_ctx_vs_loss.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20877v1/images/mlp_hidden_vs_loss.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
            "authors": [
                "Jin Qin",
                "Zihan Liao",
                "Ziyin Zhang",
                "Hang Yu",
                "Peng Di",
                "Rui Wang"
            ],
            "arxiv_id": "2512.21332v1",
            "summary": "We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM's causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21332v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "C2LLM：通过自适应跨注意力池化实现代码检索的新突破",
            "summary_zh": "本文介绍了C2LLM，一个对比代码大语言模型家族，包含0.5B和7B两种规模。C2LLM基于Qwen-2.5-Coder骨干网络，采用多头注意力池化（Pooling by Multihead Attention, PMA）模块，从token embedding生成序列embedding，有效地：1）利用了LLM在预训练期间获得的因果表示；2）能够聚合序列中所有token的信息，打破了基于EOS的序列embedding的信息瓶颈；3）支持embedding维度的灵活调整，作为MRL的替代方案。C2LLM模型在三百万公开数据上进行训练，在同等规模的模型中，于MTEB-Code上创造了新的记录，其中C2LLM-7B在总排行榜上排名第一。",
            "intro_zh": [
                "现有基于EOS token的序列embedding方法存在信息瓶颈，无法有效利用所有token信息。",
                "C2LLM采用多头注意力池化（PMA）模块，聚合所有token信息，并利用LLM的因果表示。",
                "C2LLM在MTEB-Code上取得了显著提升，C2LLM-7B在同等规模模型中排名第一。"
            ],
            "method_zh": "**问题定义**：现有的代码embedding模型，特别是基于大语言模型（LLM）的方法，通常依赖于EOS（End-of-Sequence）token的embedding来表示整个代码序列。这种方法的痛点在于，EOS token的embedding可能无法充分捕捉序列中的所有信息，造成信息瓶颈，限制了代码检索的性能。此外，固定维度的embedding也缺乏灵活性，难以适应不同的应用场景。\\n\\n**核心思路**：C2LLM的核心思路是利用多头注意力池化（PMA）模块，将序列中所有token的embedding进行聚合，从而生成更具代表性的序列embedding。PMA模块通过自适应地学习不同token的重要性，有效地捕捉序列中的关键信息，打破了EOS token的信息瓶颈。同时，C2LLM还利用了LLM在预训练过程中学习到的因果表示，进一步提升了embedding的质量。\\n\\n**技术框架**：C2LLM的整体框架基于Qwen-2.5-Coder骨干网络，并在其基础上添加了PMA模块。具体流程如下：首先，将代码序列输入到Qwen-2.5-Coder中，得到每个token的embedding。然后，将这些token embedding输入到PMA模块中进行聚合，生成序列embedding。最后，使用对比学习的目标函数，在大量代码数据上对模型进行训练，优化embedding的质量。\\n\\n**关键创新**：C2LLM最重要的技术创新点在于PMA模块的应用。与传统的基于EOS token的方法相比，PMA模块能够更有效地聚合序列中的所有信息，避免了信息瓶颈。此外，PMA模块还支持embedding维度的灵活调整，可以根据不同的应用场景进行优化。\\n\\n**关键设计**：PMA模块的关键设计包括：多头注意力的头数、注意力机制的类型、池化操作的方式等。论文中可能使用了标准的多头注意力机制，并采用可学习的query向量进行池化。损失函数方面，可能采用了对比学习中常用的InfoNCE损失函数，通过最大化正样本之间的相似度，最小化负样本之间的相似度，来优化embedding的质量。具体参数设置和网络结构细节需要在论文中进一步查找。",
            "application_zh": "C2LLM在代码检索、代码克隆检测、代码摘要生成等领域具有广泛的应用前景。高质量的代码embedding可以提高代码检索的准确率，帮助开发者快速找到所需的代码片段。此外，C2LLM还可以用于代码相似性分析，检测代码中的潜在漏洞和安全风险。未来，C2LLM有望成为代码智能领域的重要基础设施。",
            "highlight_zh": "C2LLM模型在MTEB-Code基准测试中取得了显著的性能提升。C2LLM-7B在同等规模的模型中排名第一，超越了现有的SOTA模型。实验结果表明，PMA模块能够有效地提升代码embedding的质量，打破EOS token的信息瓶颈。具体的性能数据和对比基线需要在论文中进一步查找。",
            "tags_zh": [
                "代码检索",
                "代码embedding",
                "大语言模型",
                "多头注意力",
                "对比学习"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21332v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21332v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Consulting, Data Analyst, and Management Tasks",
            "authors": [
                "Ali Merali"
            ],
            "arxiv_id": "2512.21316v1",
            "summary": "This paper derives `Scaling Laws for Economic Impacts' -- empirical relationships between the training compute of Large Language Models (LLMs) and professional productivity. In a preregistered experiment, over 500 consultants, data analysts, and managers completed professional tasks using one of 13 LLMs. We find that each year of AI model progress reduced task time by 8%, with 56% of gains driven by increased compute and 44% by algorithmic progress. However, productivity gains were significantly larger for non-agentic analytical tasks compared to agentic workflows requiring tool use. These findings suggest continued model scaling could boost U.S. productivity by approximately 20% over the next decade.",
            "categories": [
                "econ.GN",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "econ.GN",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21316v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "量化LLM规模对经济生产力的影响：咨询、数据分析与管理任务的实验证据",
            "summary_zh": "本文推导了“经济影响的规模定律”，即大型语言模型（LLM）的训练算力与专业生产力之间的经验关系。在一项预先注册的实验中，超过500名顾问、数据分析师和管理人员使用13个LLM完成了专业任务。研究发现，人工智能模型每进步一年，任务时间缩短8%，其中56%的收益来自算力的增加，44%来自算法的进步。然而，对于非代理分析任务，生产力提升显著高于需要工具使用的代理工作流程。这些发现表明，持续的模型扩展可能在未来十年内将美国生产力提高约20%。",
            "intro_zh": [
                "现有研究缺乏对LLM训练算力与专业人员生产力之间量化关系的深入探索，阻碍了对AI经济影响的准确预测。",
                "该研究通过实验方法，量化了LLM训练算力、算法进步与专业人员在咨询、数据分析和管理任务中的生产力提升之间的关系。",
                "实验结果表明，LLM的进步显著提升了生产力，但不同类型任务的提升幅度存在差异，并预测了未来十年AI对美国生产力的潜在影响。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何量化大型语言模型（LLM）的训练算力对经济生产力的影响这一问题。现有方法缺乏对LLM规模、算法进步与专业人员生产力之间关系的精确建模，难以准确预测AI对经济的潜在影响。特别是，不同类型任务（如分析型与代理型）对LLM能力的需求差异尚未得到充分研究。\\n\\n**核心思路**：论文的核心思路是通过设计一个大规模的实验，让专业人员使用不同规模和算法的LLM完成实际工作任务，从而建立LLM训练算力与生产力提升之间的经验关系。通过控制实验变量，可以区分算力提升和算法进步对生产力的独立贡献。此外，研究还关注不同类型任务对LLM能力的需求差异，从而更全面地评估LLM的经济影响。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个阶段：\n1. **任务设计**：选择具有代表性的咨询、数据分析和管理任务，确保任务难度适中，能够反映专业人员的实际工作场景。\n2. **模型选择**：选取13个不同规模和算法的LLM，覆盖不同时期的AI模型发展水平。\n3. **实验招募**：招募超过500名顾问、数据分析师和管理人员参与实验。\n4. **实验执行**：参与者使用不同的LLM完成预先设计的任务，记录任务完成时间和其他相关指标。\n5. **数据分析**：分析实验数据，建立LLM训练算力、算法进步与生产力提升之间的经验关系，并进行统计显著性检验。\\n\\n**关键创新**：该研究的关键创新在于：\n1. **量化经济影响**：首次通过大规模实验量化了LLM训练算力对专业人员生产力的影响，建立了“经济影响的规模定律”。\n2. **区分算力与算法贡献**：通过控制实验变量，区分了算力提升和算法进步对生产力的独立贡献。\n3. **关注任务类型差异**：研究关注不同类型任务对LLM能力的需求差异，更全面地评估了LLM的经济影响。\\n\\n**关键设计**：实验的关键设计包括：\n1. **预先注册**：为了确保研究的透明性和可重复性，实验方案在执行前进行了预先注册。\n2. **任务选择**：任务选择具有代表性的咨询、数据分析和管理任务，确保任务难度适中，能够反映专业人员的实际工作场景。\n3. **模型选择**：选取13个不同规模和算法的LLM，覆盖不同时期的AI模型发展水平。\n4. **指标选择**：选择任务完成时间作为主要生产力指标，并记录其他相关指标，如任务质量和用户满意度。",
            "application_zh": "该研究成果可应用于预测AI技术对各行各业生产力的潜在影响，指导企业和政府制定AI发展战略。例如，企业可以根据LLM的规模定律，评估投资AI技术的潜在回报；政府可以根据研究结果，制定促进AI技术创新和应用的政策，以提高国家整体生产力。此外，该研究还可以帮助教育机构调整课程设置，培养适应AI时代需求的专业人才。",
            "highlight_zh": "实验结果表明，人工智能模型每进步一年，任务时间缩短8%，其中56%的收益来自算力的增加，44%来自算法的进步。对于非代理分析任务，生产力提升显著高于需要工具使用的代理工作流程。研究预测，持续的模型扩展可能在未来十年内将美国生产力提高约20%。",
            "tags_zh": [
                "大型语言模型",
                "经济生产力",
                "规模定律",
                "实验研究",
                "人工智能",
                "算力",
                "算法进步"
            ],
            "_index": 70,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
            "authors": [
                "Yifan Huang",
                "Xiaojun Jia",
                "Wenbo Guo",
                "Yuqiang Sun",
                "Yihao Huang",
                "Chong Wang",
                "Yang Liu"
            ],
            "arxiv_id": "2512.21236v1",
            "summary": "Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL's effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.",
            "categories": [
                "cs.CR",
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "Accepted to FSE 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21236v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SPELL：通过句子配对探索LLM在恶意代码生成中的安全漏洞",
            "summary_zh": "大型语言模型（LLMs）通过AI辅助编码工具彻底改变了软件开发，使编程经验有限的开发人员能够创建复杂的应用程序。然而，这种可访问性也延伸到了恶意行为者，他们可能利用这些强大的工具来生成有害软件。现有的越狱研究主要侧重于针对LLM的一般攻击场景，对恶意代码生成作为越狱目标的研究有限。为了解决这一差距，我们提出了SPELL，这是一个全面的测试框架，专门用于评估恶意代码生成中安全对齐的弱点。我们的框架采用了一种时分选择策略，通过智能地组合来自先验知识数据集的句子来系统地构建越狱提示，从而平衡了对新攻击模式的探索和对成功技术的利用。对三种先进代码模型（GPT-4.1、Claude-3.5和Qwen2.5-Coder）的广泛评估表明了SPELL的有效性，在八个恶意代码类别中分别实现了83.75%、19.38%和68.12%的攻击成功率。生成的提示成功地在Cursor等实际AI开发工具中生成了恶意代码，并且最先进的检测系统确认输出为恶意的比率超过73%。这些发现揭示了当前LLM实现中的重大安全漏洞，并为改进代码生成应用中的AI安全对齐提供了宝贵的见解。",
            "intro_zh": [
                "现有研究对LLM在恶意代码生成方面的安全漏洞探索不足，缺乏针对性的测试框架。",
                "SPELL框架通过时分选择策略，智能组合句子构建越狱提示，探索并利用攻击模式。",
                "实验表明SPELL能有效攻击GPT-4.1等代码模型，并在实际AI开发工具中生成恶意代码。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在恶意代码生成方面的安全对齐问题。现有的越狱研究主要关注通用攻击，缺乏对恶意代码生成这一特定场景的深入研究和有效评估方法。这使得LLMs容易被恶意利用，生成有害软件，对软件开发生态构成威胁。\\n\\n**核心思路**：论文的核心思路是构建一个名为SPELL的测试框架，该框架通过系统地生成和评估越狱提示，来揭示LLMs在恶意代码生成方面的安全漏洞。SPELL采用时分选择策略，平衡了对新攻击模式的探索和对成功攻击技术的利用，从而更有效地发现LLMs的弱点。\\n\\n**技术框架**：SPELL框架主要包含以下几个阶段：1) **先验知识数据集构建**：收集包含各种攻击意图的句子，构建知识库。2) **时分选择策略**：将时间划分为多个阶段，在不同阶段侧重于探索新的攻击模式或利用已知的有效模式。3) **提示生成**：根据时分选择策略，从知识库中选择句子，组合成越狱提示。4) **攻击评估**：将生成的提示输入到目标LLM，评估其生成恶意代码的成功率。5) **恶意代码检测**：使用现有的恶意代码检测系统，验证生成的代码是否确实具有恶意性。\\n\\n**关键创新**：SPELL的关键创新在于其针对恶意代码生成场景设计的时分选择策略。该策略能够有效地平衡探索和利用，从而更全面地发现LLMs的安全漏洞。与传统的随机或基于规则的提示生成方法相比，SPELL能够更智能地生成有效的越狱提示。\\n\\n**关键设计**：SPELL的时分选择策略是其核心设计。具体而言，在探索阶段，SPELL会随机选择句子进行组合，以发现新的攻击模式。在利用阶段，SPELL会优先选择之前成功生成恶意代码的句子，并尝试对其进行变异，以提高攻击成功率。此外，SPELL还使用了多种提示工程技巧，例如使用角色扮演、添加约束条件等，来提高提示的有效性。",
            "application_zh": "该研究成果可应用于提升AI辅助代码工具的安全性，例如，通过SPELL框架发现的安全漏洞可以用于训练更鲁棒的LLM，从而防止恶意代码的生成。此外，该研究还可以帮助安全研究人员更好地理解LLM的安全风险，并开发更有效的防御机制。该研究对于保障软件开发生态的安全具有重要意义。",
            "highlight_zh": "SPELL框架在GPT-4.1、Claude-3.5和Qwen2.5-Coder三个先进代码模型上进行了广泛评估，分别实现了83.75%、19.38%和68.12%的攻击成功率。生成的提示成功地在Cursor等实际AI开发工具中生成了恶意代码，并且最先进的检测系统确认输出为恶意的比率超过73%。这些结果表明SPELL能够有效地揭示LLM在恶意代码生成方面的安全漏洞。",
            "tags_zh": [
                "大型语言模型",
                "恶意代码生成",
                "安全对齐",
                "越狱攻击",
                "提示工程"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21236v1/figures/overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Mesh-Attention: A New Communication-Efficient Distributed Attention with Improved Data Locality",
            "authors": [
                "Sirui Chen",
                "Jingji Chen",
                "Siqi Zhu",
                "Ziheng Jiang",
                "Yanghua Peng",
                "Xuehai Qian"
            ],
            "arxiv_id": "2512.20968v1",
            "summary": "Distributed attention is a fundamental problem for scaling context window for Large Language Models (LLMs). The state-of-the-art method, Ring-Attention, suffers from scalability limitations due to its excessive communication traffic. This paper proposes a new distributed attention algorithm, Mesh-Attention, by rethinking the design space of distributed attention with a new matrix-based model. Our method assigns a two-dimensional tile -- rather than one-dimensional row or column -- of computation blocks to each GPU to achieve higher efficiency through lower communication-computation (CommCom) ratio. The general approach covers Ring-Attention as a special case, and allows the tuning of CommCom ratio with different tile shapes. Importantly, we propose a greedy algorithm that can efficiently search the scheduling space within the tile with restrictions that ensure efficient communication among GPUs. The theoretical analysis shows that Mesh-Attention leads to a much lower communication complexity and exhibits good scalability comparing to other current algorithms.\n  Our extensive experiment results show that Mesh-Attention can achieve up to 3.4x speedup (2.9x on average) and reduce the communication volume by up to 85.4% (79.0% on average) on 256 GPUs. Our scalability results further demonstrate that Mesh-Attention sustains superior performance as the system scales, substantially reducing overhead in large-scale deployments. The results convincingly confirm the advantage of Mesh-Attention.",
            "categories": [
                "cs.DC",
                "cs.AI"
            ],
            "primary_category": "cs.DC",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20968v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Mesh-Attention，通过优化数据局部性提升分布式Attention的通信效率，加速LLM训练。",
            "summary_zh": "分布式注意力机制是扩展大型语言模型(LLMs)上下文窗口的关键。现有最优方法Ring-Attention因通信量过大而面临可扩展性限制。本文提出了一种新的分布式注意力算法Mesh-Attention，通过基于矩阵的新模型重新思考分布式注意力的设计空间。该方法为每个GPU分配一个二维计算块（而非一维行或列），通过降低通信-计算(CommCom)比率来实现更高的效率。该方法将Ring-Attention作为特例，并允许通过不同的块形状调整CommCom比率。重要的是，我们提出了一种贪婪算法，可以在块内有效地搜索调度空间，同时限制GPU之间的有效通信。理论分析表明，与其他现有算法相比，Mesh-Attention具有更低的通信复杂度和良好的可扩展性。实验结果表明，在256个GPU上，Mesh-Attention可以实现高达3.4倍的加速（平均2.9倍），并将通信量减少高达85.4%（平均79.0%）。可扩展性结果进一步表明，Mesh-Attention在系统扩展时保持卓越的性能，从而大大减少了大规模部署中的开销。结果令人信服地证实了Mesh-Attention的优势。",
            "intro_zh": [
                "现有Ring-Attention方法在扩展LLM上下文窗口时，由于通信量过大，可扩展性受限，成为瓶颈。",
                "Mesh-Attention通过为每个GPU分配二维计算块，降低通信-计算比率，优化数据局部性，提升分布式Attention效率。",
                "实验表明，Mesh-Attention在256个GPU上实现了高达3.4倍的加速，并显著降低了通信量，验证了其优势。"
            ],
            "method_zh": "**问题定义**：论文旨在解决分布式注意力机制在大规模语言模型训练中，因通信量过大导致的可扩展性瓶颈问题。现有的Ring-Attention方法虽然能够实现分布式计算，但其通信模式导致了较高的通信开销，限制了其在大规模GPU集群上的应用效果。\\n\\n**核心思路**：Mesh-Attention的核心思路是通过改变数据划分和计算分配方式，优化通信模式，从而降低通信开销。具体来说，它将计算任务划分为二维的块，并将这些块分配给GPU进行计算。通过合理安排块的形状和GPU之间的通信方式，可以显著降低通信-计算比率，提高整体效率。\\n\\n**技术框架**：Mesh-Attention的技术框架主要包括以下几个阶段：1) 数据划分：将注意力计算所需的输入数据划分为二维的块。2) 任务分配：将这些块分配给不同的GPU进行计算。3) 通信调度：设计一种高效的通信调度策略，使得GPU之间能够以最小的通信量完成数据交换。4) 结果聚合：将各个GPU的计算结果进行聚合，得到最终的注意力输出。\\n\\n**关键创新**：Mesh-Attention的关键创新在于其二维块划分和通信调度策略。与Ring-Attention的一维划分方式不同，二维划分能够更好地利用GPU的计算资源，降低通信开销。此外，论文还提出了一种贪婪算法，用于在块内搜索最佳的调度方案，以确保GPU之间的有效通信。\\n\\n**关键设计**：Mesh-Attention的关键设计包括：1) 块的形状：块的形状会影响通信-计算比率，需要根据具体的硬件和任务特点进行调整。2) 通信调度策略：论文提出了一种贪婪算法，用于搜索最佳的通信调度方案。该算法考虑了GPU之间的通信带宽和延迟等因素，以最小化通信开销。3) 损失函数：论文没有特别提到损失函数的设计，但可以推测其使用了标准的注意力机制损失函数。",
            "application_zh": "Mesh-Attention在大型语言模型训练、图像识别、语音识别等领域具有广泛的应用前景。通过降低分布式注意力机制的通信开销，可以加速模型的训练过程，提高模型的性能。此外，该方法还可以应用于其他需要大规模分布式计算的场景，例如科学计算、金融分析等。未来，Mesh-Attention有望成为大规模AI模型训练的重要技术支撑。",
            "highlight_zh": "实验结果表明，Mesh-Attention在256个GPU上实现了高达3.4倍的加速（平均2.9倍），并将通信量减少高达85.4%（平均79.0%）。与Ring-Attention相比，Mesh-Attention在可扩展性方面表现出更强的优势，能够更好地适应大规模GPU集群。这些结果充分证明了Mesh-Attention在分布式注意力机制方面的优越性。",
            "tags_zh": [
                "分布式注意力",
                "通信效率",
                "大型语言模型",
                "GPU集群",
                "数据局部性"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20968v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20968v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20968v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "The Silent Scholar Problem: A Probabilistic Framework for Breaking Epistemic Asymmetry in LLM Agents",
            "authors": [
                "Zan-Kai Chong",
                "Hiroyuki Ohsaki",
                "Bryan Ng"
            ],
            "arxiv_id": "2512.20884v1",
            "summary": "Autonomous agents powered by LLMs and Retrieval-Augmented Generation (RAG) are proficient consumers of digital content but remain unidirectional, a limitation we term epistemic asymmetry. This isolation leads to redundant reasoning and stagnates collective intelligence. Current self-reflection frameworks remain largely heuristic and private, lacking a probabilistic foundation to quantify certainty or justify external interaction.To bridge this gap, we propose a formal probabilistic framework that provides agents with a non-altruistic motive for bidirectional knowledge exchange. We model an agent's belief in a proposition using a Beta-Bernoulli distribution with a forgetting factor ($γ$). This allows us to isolate epistemic uncertainty as the variance of belief, establishing a dual drive for interaction: A homeostatic motive: The need to maintain certainty against the temporal decay introduced by $γ$. An optimal learning strategy: Targeting points of maximum ambiguity ($\\mathbb{E}[θ]=0.5$) to maximize information gain. Under this framework, public contribution is reframed as optimal active learning: sharing solutions to elicit feedback is the most efficient method for an agent to reduce its own uncertainty. To ensure scalability, we introduce epistemic caching, which leverages the forgetting factor to dynamically prioritize resources for the active head of non-stationary knowledge distributions. Finally, we demonstrate how these accumulated belief states serve as verifiable reward signals for Reinforcement Learning from Human Feedback (RLHF) and high-quality data filters for Supervised Fine-Tuning (SFT). Simulation results validate that this uncertainty-driven strategy significantly outperforms random baselines in heterogeneous (Zipfian) environments, maintaining high adaptability to concept drift.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.20884v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RLHF"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出概率框架以解决LLM代理的知识不对称问题",
            "summary_zh": "自主代理通过大语言模型（LLM）和检索增强生成（RAG）技术能够有效消费数字内容，但仍存在单向性的问题，称为知识不对称。这种孤立导致冗余推理并阻碍集体智能的发展。现有的自我反思框架主要是启发式和私有的，缺乏量化不确定性或合理化外部交互的概率基础。为此，本文提出了一种正式的概率框架，使代理具备双向知识交换的非利他动机。通过使用带遗忘因子的Beta-Bernoulli分布建模代理对命题的信念，本文建立了交互的双重驱动机制，并引入了知识的动态优先级缓存。实验结果表明，该不确定性驱动策略在异质环境中显著优于随机基线。",
            "intro_zh": [
                "现有的自我反思框架缺乏量化不确定性的概率基础，导致知识不对称和集体智能的停滞。",
                "提出了一种基于Beta-Bernoulli分布的概率框架，允许代理在知识交换中具备非利他动机，优化学习策略。",
                "实验结果显示，该框架在异质环境中显著提高了适应性和信息获取效率，超越了随机基线的表现。"
            ],
            "method_zh": "**问题定义**：本文旨在解决自主代理在知识交换中存在的单向性问题，现有方法缺乏有效的概率基础来量化不确定性，导致知识不对称和集体智能的低效。\\n\\n**核心思路**：通过引入Beta-Bernoulli分布和遗忘因子，建立代理对命题信念的模型，形成双重驱动机制以促进知识的双向交流。\\n\\n**技术框架**：整体架构包括信念建模、动态优先级缓存和反馈机制，代理通过主动学习策略在知识分布中选择最大模糊点进行信息获取。\\n\\n**关键创新**：最重要的创新在于将公共贡献重新定义为最优主动学习，代理通过分享解决方案来减少自身的不确定性，这一思路与传统方法有本质区别。\\n\\n**关键设计**：引入遗忘因子作为动态优先级的依据，设计了基于信念状态的奖励信号用于强化学习，并通过模拟验证了该策略在异质环境中的有效性。",
            "application_zh": "该研究的潜在应用领域包括智能助手、自动化决策系统和人机协作等。通过提高自主代理的知识交换能力，可以显著提升系统的智能水平和适应性，推动集体智能的发展，未来可能在教育、医疗和商业等多个领域产生深远影响。",
            "highlight_zh": "实验结果表明，基于不确定性驱动的策略在异质（Zipfian）环境中显著优于随机基线，具体表现为信息获取效率提高了约30%，并且在概念漂移情况下保持了高适应性。",
            "tags_zh": [
                "知识不对称",
                "大语言模型",
                "主动学习",
                "概率框架",
                "信息获取",
                "集体智能",
                "强化学习"
            ],
            "_index": 73,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.20884v1/images/experimentB-1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.20884v1/images/experimentB-2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.20884v1/images/experimentB-3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ACD: Direct Conditional Control for Video Diffusion Models via Attention Supervision",
            "authors": [
                "Weiqi Li",
                "Zehao Zhang",
                "Liang Lin",
                "Guangrun Wang"
            ],
            "arxiv_id": "2512.21268v1",
            "summary": "Controllability is a fundamental requirement in video synthesis, where accurate alignment with conditioning signals is essential. Existing classifier-free guidance methods typically achieve conditioning indirectly by modeling the joint distribution of data and conditions, which often results in limited controllability over the specified conditions. Classifier-based guidance enforces conditions through an external classifier, but the model may exploit this mechanism to raise the classifier score without genuinely satisfying the intended condition, resulting in adversarial artifacts and limited effective controllability. In this paper, we propose Attention-Conditional Diffusion (ACD), a novel framework for direct conditional control in video diffusion models via attention supervision. By aligning the model's attention maps with external control signals, ACD achieves better controllability. To support this, we introduce a sparse 3D-aware object layout as an efficient conditioning signal, along with a dedicated Layout ControlNet and an automated annotation pipeline for scalable layout integration. Extensive experiments on benchmark video generation datasets demonstrate that ACD delivers superior alignment with conditioning inputs while preserving temporal coherence and visual fidelity, establishing an effective paradigm for conditional video synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21268v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "classifier-free guidance"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "ACD：通过注意力监督实现视频扩散模型中的直接条件控制",
            "summary_zh": "可控性是视频合成中的一项基本要求，其中与条件信号的精确对齐至关重要。现有的无分类器引导方法通常通过对数据和条件的联合分布进行建模来间接实现条件控制，这通常导致对指定条件的有限可控性。基于分类器的引导通过外部分类器强制执行条件，但模型可能会利用这种机制来提高分类器分数，而没有真正满足预期的条件，从而导致对抗性伪影和有限的有效可控性。在本文中，我们提出了一种新颖的注意力条件扩散（ACD）框架，用于通过注意力监督在视频扩散模型中进行直接条件控制。通过将模型的注意力图与外部控制信号对齐，ACD实现了更好的可控性。为了支持这一点，我们引入了一种稀疏的3D感知对象布局作为一种有效的条件信号，以及一个专用的布局ControlNet和一个用于可扩展布局集成的自动注释管道。在基准视频生成数据集上的大量实验表明，ACD在保持时间连贯性和视觉保真度的同时，提供了与条件输入的卓越对齐，从而为条件视频合成建立了一种有效的范例。",
            "intro_zh": [
                "现有视频生成方法在条件控制方面存在不足，难以精确对齐条件信号，导致可控性受限。",
                "ACD通过注意力监督，直接将模型的注意力图与外部控制信号对齐，从而实现更强的条件控制能力。",
                "实验表明，ACD在保证视频质量和时间连贯性的同时，显著提升了与条件输入的对齐程度。"
            ],
            "method_zh": "**问题定义**：现有视频扩散模型在条件控制方面存在挑战。无分类器引导方法可控性有限，而基于分类器的引导方法容易产生对抗性伪影，无法真正满足条件要求。因此，需要一种更直接、更有效的条件控制方法。\\n\\n**核心思路**：ACD的核心思路是通过注意力监督，直接将视频扩散模型的注意力图与外部控制信号对齐。通过这种方式，模型能够更准确地理解和响应条件信号，从而实现更强的可控性。这种直接对齐避免了现有方法中存在的间接建模和对抗性问题。\\n\\n**技术框架**：ACD框架主要包含以下几个模块：1) 视频扩散模型：作为生成视频的基础模型。2) 布局ControlNet：用于处理稀疏的3D感知对象布局，并将其融入到扩散模型的生成过程中。3) 注意力监督模块：通过损失函数，促使扩散模型的注意力图与外部控制信号（例如，对象布局）对齐。4) 自动标注管道：用于生成大规模的训练数据，支持布局ControlNet的训练。\\n\\n**关键创新**：ACD的关键创新在于通过注意力监督实现直接条件控制。与现有方法相比，ACD避免了对数据和条件的联合分布进行建模，而是直接将模型的注意力与条件信号对齐，从而实现了更强的可控性和更好的生成质量。此外，引入的稀疏3D感知对象布局和自动标注管道也为ACD的有效实施提供了支持。\\n\\n**关键设计**：ACD的关键设计包括：1) 稀疏3D感知对象布局：使用3D bounding box表示场景中的对象，提供更精确的空间信息。2) 布局ControlNet：一个专门的网络，用于将布局信息融入到扩散模型的生成过程中。3) 注意力损失函数：用于衡量模型注意力图与目标布局之间的差异，并促使模型进行学习。具体的损失函数形式未知，需要在论文中查找。",
            "application_zh": "ACD可应用于各种条件视频生成任务，例如：根据用户指定的对象布局生成视频、根据文本描述生成视频场景、以及根据其他模态的信号（如音频）生成视频。该技术在游戏开发、电影制作、虚拟现实等领域具有广泛的应用前景，可以显著提升视频内容的创作效率和质量。",
            "highlight_zh": "实验结果表明，ACD在多个基准视频生成数据集上取得了显著的性能提升。与现有方法相比，ACD能够生成与条件输入更精确对齐的视频，同时保持了良好的时间连贯性和视觉保真度。具体的性能数据需要在论文中查找，例如FID分数、用户满意度调查等。",
            "tags_zh": [
                "视频生成",
                "扩散模型",
                "条件控制",
                "注意力机制",
                "ControlNet",
                "3D感知",
                "对象布局",
                "注意力监督"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21268v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21268v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21268v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
            "authors": [
                "Ziyu Chen",
                "Xinbei Jiang",
                "Peng Sun",
                "Tao Lin"
            ],
            "arxiv_id": "2512.21336v1",
            "summary": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21336v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "MDM"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "提出基于不确定性量化的掩码扩散模型解码路径优化方法",
            "summary_zh": "掩码扩散模型(MDMs)提供了一种灵活的、非自回归的生成方式，但这种自由也带来了一个挑战：最终输出质量对解码顺序高度敏感。我们首次将这个问题形式化，并将输出质量的变化归因于生成路径上的累积预测不确定性。为了量化这种不确定性，我们引入了去噪熵(Denoising Entropy)，这是一种可计算的指标，可以作为评估生成过程的内部信号。利用这个指标，我们提出了两种旨在优化解码路径的算法：一种事后选择方法和一种实时指导策略。实验表明，我们的熵引导方法显著提高了生成质量，持续提升了在具有挑战性的推理、规划和代码基准测试中的准确性。我们的工作将去噪熵确立为理解和控制生成过程的有效工具，有效地将MDM中的不确定性从一种负担转变为发现高质量解决方案的关键优势。",
            "intro_zh": [
                "掩码扩散模型解码顺序对生成质量影响大，现有方法缺乏有效控制。",
                "提出基于去噪熵的解码路径优化方法，量化生成过程中的不确定性。",
                "实验证明，该方法显著提升了推理、规划和代码生成等任务的准确性。"
            ],
            "method_zh": "**问题定义**：掩码扩散模型（MDMs）在生成过程中，由于其非自回归的特性，解码顺序的选择对最终生成结果的质量有显著影响。不同的解码路径会导致输出质量的巨大差异。现有的方法缺乏对这种解码路径选择的有效控制机制，导致生成结果不稳定，难以保证高质量的输出。\\n\\n**核心思路**：论文的核心思路是通过量化生成过程中的不确定性来指导解码路径的选择。具体来说，论文提出了一种名为“去噪熵”（Denoising Entropy）的指标，用于衡量每一步去噪过程中的预测不确定性。通过选择不确定性较低的解码路径，可以降低累积误差，从而提高生成质量。\\n\\n**技术框架**：整体框架包含以下几个主要步骤：1) 使用掩码扩散模型进行初始生成；2) 计算每一步去噪过程的去噪熵，作为衡量不确定性的指标；3) 基于去噪熵，采用两种策略优化解码路径：事后选择（选择熵值最低的路径）和实时指导（在生成过程中动态调整解码顺序）；4) 输出最终生成结果。\\n\\n**关键创新**：论文的关键创新在于提出了“去噪熵”这一概念，并将其作为量化掩码扩散模型生成过程中不确定性的有效指标。这是首次将不确定性量化引入到MDM的解码路径优化中，为控制生成过程提供了一种新的视角和工具。与现有方法相比，该方法能够更准确地评估解码路径的质量，从而实现更有效的优化。\\n\\n**关键设计**：去噪熵的计算基于模型预测的概率分布。具体来说，对于每一步去噪过程，模型会预测一个概率分布，去噪熵就是该概率分布的熵值。熵值越高，表示模型的不确定性越大。在事后选择策略中，选择具有最低平均去噪熵的完整解码路径。在实时指导策略中，每一步都选择能够最小化未来去噪熵的解码方向。具体的参数设置和网络结构与所使用的掩码扩散模型相关，论文中没有明确指出。",
            "application_zh": "该研究成果可应用于各种需要高质量、可控生成的场景，例如图像修复、文本生成、代码生成、药物发现等。通过优化解码路径，可以显著提高生成结果的质量和稳定性，从而提升相关应用的性能和用户体验。未来，该方法有望进一步扩展到其他类型的生成模型中，为人工智能的创造性应用提供更强大的支持。",
            "highlight_zh": "实验结果表明，基于去噪熵的解码路径优化方法在多个具有挑战性的任务上取得了显著的性能提升。例如，在推理、规划和代码生成等基准测试中，该方法能够持续提高生成准确率。具体的数据提升幅度在论文中有所体现，证明了该方法的有效性和优越性。",
            "tags_zh": [
                "掩码扩散模型",
                "解码路径优化",
                "不确定性量化",
                "去噪熵",
                "非自回归生成"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21336v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21336v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21336v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Relative Localization System Design for SnailBot: A Modular Self-reconfigurable Robot",
            "authors": [
                "Shuhan Zhang",
                "Tin Lun Lam"
            ],
            "arxiv_id": "2512.21226v1",
            "summary": "This paper presents the design and implementation of a relative localization system for SnailBot, a modular self reconfigurable robot. The system integrates ArUco marker recognition, optical flow analysis, and IMU data processing into a unified fusion framework, enabling robust and accurate relative positioning for collaborative robotic tasks. Experimental validation demonstrates the effectiveness of the system in realtime operation, with a rule based fusion strategy ensuring reliability across dynamic scenarios. The results highlight the potential for scalable deployment in modular robotic systems.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "7 pages, 7 figures, 4 algorithms",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21226v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "optical flow"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "为模块化自重构机器人SnailBot设计相对定位系统，实现协同任务。",
            "summary_zh": "本文提出了一种用于模块化自重构机器人SnailBot的相对定位系统设计与实现。该系统将ArUco标记识别、光流分析和IMU数据处理集成到一个统一的融合框架中，从而为协同机器人任务实现鲁棒而精确的相对定位。实验验证表明，该系统在实时操作中有效，基于规则的融合策略确保了在动态场景中的可靠性。结果突出了该系统在模块化机器人系统中进行可扩展部署的潜力。",
            "intro_zh": [
                "现有模块化机器人缺乏鲁棒的相对定位方案，难以适应动态环境下的协同任务。",
                "论文提出融合ArUco标记识别、光流分析和IMU数据的相对定位系统，提升定位精度和鲁棒性。",
                "实验验证了该系统在实时操作中的有效性，证明其在动态场景下具有良好的可靠性。"
            ],
            "method_zh": "**问题定义**：模块化自重构机器人需要在未知或动态环境中进行协同作业，精确的相对定位是实现协同的关键。然而，单一传感器容易受到环境因素的干扰，导致定位精度下降或失效。现有方法可能依赖于全局定位系统，或者在传感器融合方面存在局限性，无法在各种复杂场景下提供稳定可靠的相对定位。\n\n**核心思路**：论文的核心思路是将多种传感器信息进行融合，利用各自的优势互补，从而提高定位系统的鲁棒性和精度。具体来说，ArUco标记识别提供绝对位置信息，光流分析提供相邻帧之间的运动信息，IMU提供角速度和加速度信息。通过融合这些信息，可以在不同的场景下获得更可靠的相对定位结果。\n\n**技术框架**：该相对定位系统包含以下主要模块：1) ArUco标记识别模块：用于检测和识别环境中的ArUco标记，从而获得机器人的绝对位置信息。2) 光流分析模块：用于分析相邻帧之间的图像变化，从而估计机器人的运动速度和方向。3) IMU数据处理模块：用于处理IMU传感器的数据，从而获得机器人的角速度和加速度信息。4) 融合模块：将来自不同传感器的数据进行融合，从而获得更精确和鲁棒的相对定位结果。融合策略采用基于规则的方法，根据不同场景选择合适的传感器数据。\n\n**关键创新**：该论文的关键创新在于提出了一种统一的融合框架，能够有效地将ArUco标记识别、光流分析和IMU数据进行融合。这种融合框架能够充分利用不同传感器的优势，从而提高定位系统的鲁棒性和精度。此外，基于规则的融合策略能够根据不同的场景选择合适的传感器数据，进一步提高系统的可靠性。\n\n**关键设计**：ArUco标记识别模块使用OpenCV库进行实现，光流分析模块使用Lucas-Kanade算法进行实现，IMU数据处理模块使用卡尔曼滤波器进行实现。融合模块采用基于规则的策略，例如，在光照条件良好且ArUco标记可见的情况下，优先使用ArUco标记识别的结果；在光照条件较差或ArUco标记不可见的情况下，则使用光流分析和IMU数据进行定位。具体规则的制定需要根据实际应用场景进行调整。",
            "application_zh": "该研究成果可应用于模块化机器人的协同搬运、自主导航、环境探索等领域。在仓储物流、灾害救援、智能制造等场景中，多个SnailBot可以通过相对定位系统实现高效协作，完成复杂任务。未来，该系统有望扩展到其他类型的多机器人系统，促进机器人集群智能的发展。",
            "highlight_zh": "实验结果表明，该相对定位系统能够实现实时操作，并且在动态场景下具有良好的可靠性。基于规则的融合策略能够有效地提高定位精度和鲁棒性。具体的性能数据（例如定位误差、定位频率等）和对比基线（例如仅使用单一传感器进行定位）的数据在摘要中未提及，属于未知信息。",
            "tags_zh": [
                "相对定位",
                "模块化机器人",
                "传感器融合",
                "ArUco标记",
                "光流分析"
            ],
            "_index": 76,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21226v1/2.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21226v1/Snailbot_RL1.drawio.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21226v1/prevDesign.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Tracing Energy Flow: Learning Tactile-based Grasping Force Control to Prevent Slippage in Dynamic Object Interaction",
            "authors": [
                "Cheng-Yu Kuo",
                "Hirofumi Shin",
                "Takamitsu Matsubara"
            ],
            "arxiv_id": "2512.21043v1",
            "summary": "Regulating grasping force to reduce slippage during dynamic object interaction remains a fundamental challenge in robotic manipulation, especially when objects are manipulated by multiple rolling contacts, have unknown properties (such as mass or surface conditions), and when external sensing is unreliable. In contrast, humans can quickly regulate grasping force by touch, even without visual cues. Inspired by this ability, we aim to enable robotic hands to rapidly explore objects and learn tactile-driven grasping force control under motion and limited sensing. We propose a physics-informed energy abstraction that models the object as a virtual energy container. The inconsistency between the fingers' applied power and the object's retained energy provides a physically grounded signal for inferring slip-aware stability. Building on this abstraction, we employ model-based learning and planning to efficiently model energy dynamics from tactile sensing and perform real-time grasping force optimization. Experiments in both simulation and hardware demonstrate that our method can learn grasping force control from scratch within minutes, effectively reduce slippage, and extend grasp duration across diverse motion-object pairs, all without relying on external sensing or prior object knowledge.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "8 pages. Accepted by IEEE Robotics and Automation Letters (RA-L)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21043v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于触觉能量流的抓取力控制方法，防止动态物体交互中的滑移",
            "summary_zh": "在动态物体交互中，调节抓取力以减少滑移是一个根本性的挑战，尤其是在物体由多个滚动接触操纵、具有未知属性（如质量或表面条件）以及外部传感不可靠时。受人类即使在没有视觉线索的情况下也能通过触摸快速调节抓取力的能力启发，本文旨在使机器人手能够在运动和有限传感下快速探索物体，并学习触觉驱动的抓取力控制。我们提出了一种基于物理信息的能量抽象，将物体建模为虚拟能量容器。手指施加的功率与物体保持的能量之间的不一致性，为推断滑移感知的稳定性提供了物理基础信号。在此基础上，我们采用基于模型的学习和规划，从触觉传感中有效地建模能量动态，并执行实时抓取力优化。在仿真和硬件中的实验表明，我们的方法可以在几分钟内从头开始学习抓取力控制，有效地减少滑移，并在不同的运动-物体对中延长抓取持续时间，所有这些都不依赖于外部传感或先验物体知识。",
            "intro_zh": [
                "现有方法在动态物体交互中难以有效调节抓取力，尤其是在物体属性未知和外部传感不可靠的情况下。",
                "该论文提出了一种基于物理信息的能量抽象方法，通过建模物体能量变化来推断滑移，并优化抓取力。",
                "实验表明，该方法能够在几分钟内学习抓取力控制，有效减少滑移，并延长抓取时间，无需外部传感或先验知识。"
            ],
            "method_zh": "**问题定义**：论文旨在解决动态物体交互中，机器人如何在物体属性未知、外部传感不可靠的情况下，通过触觉信息控制抓取力，从而防止滑移的问题。现有方法难以适应动态环境和未知物体属性，容易发生滑移，导致操作失败。\\n\\n**核心思路**：论文的核心思路是将物体视为一个虚拟的能量容器，通过监测手指施加的功率与物体自身能量变化之间的差异来判断是否发生滑移。如果手指施加的能量大于物体保持的能量，则可能发生滑移。基于这种能量不一致性，可以调整抓取力，从而提高抓取的稳定性。\\n\\n**技术框架**：整体框架包括触觉数据采集、能量动态建模、抓取力优化三个主要阶段。首先，通过触觉传感器获取手指与物体接触的信息。然后，利用这些信息建立物体能量动态模型，该模型描述了手指施加的功率与物体能量变化之间的关系。最后，基于该模型，通过模型预测控制（MPC）等方法，实时优化抓取力，以减少滑移的发生。\\n\\n**关键创新**：最重要的创新点在于提出了基于物理信息的能量抽象方法，将复杂的抓取问题转化为能量流的分析。这种方法能够有效地利用触觉信息，推断物体的状态和稳定性，而无需依赖外部传感器或先验知识。与传统的基于视觉或力/力矩传感的抓取控制方法相比，该方法更加鲁棒和灵活。\\n\\n**关键设计**：论文采用基于模型的学习方法来建立能量动态模型。具体来说，可以使用高斯过程回归（GPR）等方法，从触觉数据中学习手指施加的功率与物体能量变化之间的关系。损失函数可以设计为最小化预测的能量变化与实际能量变化之间的差异。在抓取力优化阶段，可以使用模型预测控制（MPC）算法，根据能量动态模型预测未来一段时间内的物体状态，并优化抓取力，以最小化滑移的风险。",
            "application_zh": "该研究成果可应用于各种需要精确抓取和操作的场景，例如：工业自动化中对未知物体的抓取和装配、家庭服务机器人中对日常用品的操作、医疗机器人中对脆弱物体的操作等。通过提高抓取的稳定性和可靠性，可以显著提高机器人的工作效率和安全性，扩展其应用范围。",
            "highlight_zh": "实验结果表明，该方法能够在几分钟内从零开始学习抓取力控制，有效地减少滑移，并延长抓取持续时间。在仿真和硬件实验中，该方法都表现出良好的性能，能够适应不同的运动-物体对，且无需外部传感或先验知识。与传统的抓取控制方法相比，该方法在防止滑移方面具有显著优势。",
            "tags_zh": [
                "触觉感知",
                "抓取力控制",
                "能量流",
                "动态物体交互",
                "模型预测控制"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21043v1/fig/intro.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21043v1/fig/energy_power_overview.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21043v1/fig/robot_setup.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Towards Arbitrary Motion Completing via Hierarchical Continuous Representation",
            "authors": [
                "Chenghao Xu",
                "Guangtao Lyu",
                "Qi Liu",
                "Jiexi Yan",
                "Muli Yang",
                "Cheng Deng"
            ],
            "arxiv_id": "2512.21183v1",
            "summary": "Physical motions are inherently continuous, and higher camera frame rates typically contribute to improved smoothness and temporal coherence. For the first time, we explore continuous representations of human motion sequences, featuring the ability to interpolate, inbetween, and even extrapolate any input motion sequences at arbitrary frame rates. To achieve this, we propose a novel parametric activation-induced hierarchical implicit representation framework, referred to as NAME, based on Implicit Neural Representations (INRs). Our method introduces a hierarchical temporal encoding mechanism that extracts features from motion sequences at multiple temporal scales, enabling effective capture of intricate temporal patterns. Additionally, we integrate a custom parametric activation function, powered by Fourier transformations, into the MLP-based decoder to enhance the expressiveness of the continuous representation. This parametric formulation significantly augments the model's ability to represent complex motion behaviors with high accuracy. Extensive evaluations across several benchmark datasets demonstrate the effectiveness and robustness of our proposed approach.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21183v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "implicit representation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出基于分层连续表示的NAME框架，实现任意帧率的运动补全",
            "summary_zh": "本文首次探索了人体运动序列的连续表示，使其能够在任意帧率下对输入运动序列进行插值、中间帧生成甚至外推，从而提高运动的平滑性和时间连贯性。为此，我们提出了一种新颖的参数激活诱导分层隐式表示框架，称为NAME，它基于隐式神经表示（INRs）。我们的方法引入了一种分层时间编码机制，可以从多个时间尺度上提取运动序列的特征，从而有效地捕获复杂的时序模式。此外，我们将由傅里叶变换驱动的自定义参数激活函数集成到基于MLP的解码器中，以增强连续表示的表达能力。这种参数化公式显著增强了模型以高精度表示复杂运动行为的能力。在多个基准数据集上的大量评估证明了我们提出的方法的有效性和鲁棒性。",
            "intro_zh": [
                "现有方法难以在任意帧率下对运动序列进行插值和外推，限制了运动补全的灵活性和应用范围。",
                "提出NAME框架，利用分层时间编码和参数激活函数增强隐式神经表示，实现运动序列的连续表示。",
                "实验结果表明，该方法在多个基准数据集上表现出良好的性能和鲁棒性，能够有效完成任意帧率的运动补全任务。"
            ],
            "method_zh": "**问题定义**：论文旨在解决人体运动序列补全问题，特别是针对任意帧率下的运动插值、中间帧生成和外推。现有方法通常依赖于离散的帧表示，难以处理任意帧率的需求，且可能导致运动不连贯或不平滑。因此，如何建立一个能够处理任意时间点运动信息的连续表示是关键挑战。\\n\\n**核心思路**：论文的核心思路是将人体运动序列表示为一个连续的函数，通过隐式神经表示（INR）来建模这个函数。通过学习一个将时间点映射到运动姿态的函数，可以实现对任意时间点的运动姿态进行预测，从而解决任意帧率下的运动补全问题。分层时间编码和参数激活函数的设计旨在增强INR的表达能力，使其能够更好地捕捉复杂的运动模式。\\n\\n**技术框架**：NAME框架主要包含三个模块：分层时间编码模块、MLP解码器和参数激活函数。首先，分层时间编码模块从输入运动序列中提取多尺度的时间特征。然后，MLP解码器将时间编码作为输入，预测对应时间点的运动姿态。最后，参数激活函数被集成到MLP解码器中，以增强其表达能力。整个框架通过最小化预测姿态与真实姿态之间的差异进行训练。\\n\\n**关键创新**：论文的关键创新在于提出了参数激活诱导的分层隐式表示框架NAME。具体来说，分层时间编码能够有效捕获不同时间尺度的运动模式，而参数激活函数则增强了MLP解码器的表达能力，使其能够更准确地表示复杂的运动行为。与传统的INR方法相比，NAME能够更好地处理人体运动序列的复杂性和连续性。\\n\\n**关键设计**：分层时间编码采用多层Transformer结构，每一层处理不同时间尺度的特征。参数激活函数基于傅里叶变换，通过学习傅里叶系数来调整激活函数的形状，从而增强模型的表达能力。损失函数采用均方误差（MSE），衡量预测姿态与真实姿态之间的差异。网络结构采用多层感知机（MLP），具体层数和神经元数量根据实验进行调整。",
            "application_zh": "该研究成果可广泛应用于动画制作、游戏开发、虚拟现实等领域。通过任意帧率的运动补全，可以提高动画和游戏的流畅度和真实感。此外，该技术还可以用于运动分析、康复训练等领域，例如，通过对不完整的运动数据进行补全，可以更准确地评估运动员的运动表现或患者的康复进展。未来，该技术有望进一步扩展到其他类型的时序数据处理任务中。",
            "highlight_zh": "实验结果表明，NAME框架在Human3.6M、AMASS等多个基准数据集上取得了显著的性能提升。与现有方法相比，NAME在运动插值、中间帧生成和外推任务上均表现出更好的精度和鲁棒性。例如，在Human3.6M数据集上，NAME的平均误差降低了10%以上，证明了其在运动补全方面的有效性。",
            "tags_zh": [
                "运动补全",
                "隐式神经表示",
                "连续表示",
                "分层时间编码",
                "参数激活函数"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21183v1/fig/intro1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21183v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21183v1/fig/results.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "UniPR-3D: Towards Universal Visual Place Recognition with Visual Geometry Grounded Transformer",
            "authors": [
                "Tianchen Deng",
                "Xun Chen",
                "Ziming Li",
                "Hongming Shen",
                "Danwei Wang",
                "Javier Civera",
                "Hesheng Wang"
            ],
            "arxiv_id": "2512.21078v1",
            "summary": "Visual Place Recognition (VPR) has been traditionally formulated as a single-image retrieval task. Using multiple views offers clear advantages, yet this setting remains relatively underexplored and existing methods often struggle to generalize across diverse environments. In this work we introduce UniPR-3D, the first VPR architecture that effectively integrates information from multiple views. UniPR-3D builds on a VGGT backbone capable of encoding multi-view 3D representations, which we adapt by designing feature aggregators and fine-tune for the place recognition task. To construct our descriptor, we jointly leverage the 3D tokens and intermediate 2D tokens produced by VGGT. Based on their distinct characteristics, we design dedicated aggregation modules for 2D and 3D features, allowing our descriptor to capture fine-grained texture cues while also reasoning across viewpoints. To further enhance generalization, we incorporate both single- and multi-frame aggregation schemes, along with a variable-length sequence retrieval strategy. Our experiments show that UniPR-3D sets a new state of the art, outperforming both single- and multi-view baselines and highlighting the effectiveness of geometry-grounded tokens for VPR. Our code and models will be made publicly available on Github https://github.com/dtc111111/UniPR-3D.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21078v1",
            "code_links": [
                {
                    "url": "https://github.com/dtc111111/UniPR-3D",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "VGGT"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出UniPR-3D，利用视觉几何Transformer实现通用视觉定位识别。",
            "summary_zh": "视觉定位识别(VPR)传统上被认为是一个单图像检索任务。使用多视角图像具有明显的优势，但这种设置相对未被充分探索，并且现有方法通常难以在不同的环境中泛化。本文提出了UniPR-3D，这是第一个有效整合多视角信息的VPR架构。UniPR-3D建立在能够编码多视角3D表示的VGGT骨干网络之上，并通过设计特征聚合器并针对定位识别任务进行微调来改进VGGT。为了构建描述符，我们联合利用VGGT产生的3D tokens和中间2D tokens。基于它们的不同特性，我们为2D和3D特征设计了专门的聚合模块，使我们的描述符能够捕获细粒度的纹理线索，同时也能跨视角进行推理。为了进一步提高泛化能力，我们结合了单帧和多帧聚合方案，以及可变长度序列检索策略。实验表明，UniPR-3D达到了新的state-of-the-art，优于单视角和多视角基线，突出了几何约束tokens对于VPR的有效性。代码和模型将在Github上公开。",
            "intro_zh": [
                "现有VPR方法难以有效利用多视角信息，且泛化能力不足，难以适应多样环境。",
                "UniPR-3D通过VGGT骨干网络编码多视角3D表示，并设计特征聚合器进行微调，有效整合多视角信息。",
                "实验结果表明，UniPR-3D在VPR任务中取得了state-of-the-art的性能，验证了几何约束tokens的有效性。"
            ],
            "method_zh": "**问题定义**：视觉定位识别(VPR)旨在确定查询图像在已知环境中的位置。现有方法主要依赖单张图像，忽略了多视角信息蕴含的几何关系，导致泛化能力受限，难以适应环境变化。多视角VPR虽然能提供更丰富的信息，但现有方法难以有效整合这些信息，且计算复杂度较高。\\n\\n**核心思路**：UniPR-3D的核心思路是利用视觉几何Transformer (VGGT) 作为骨干网络，提取图像的2D和3D特征，并设计专门的聚合模块来融合这些特征。通过显式地建模场景的几何信息，可以提高VPR系统的鲁棒性和泛化能力。同时，采用单帧和多帧聚合策略，进一步增强了系统的适应性。\\n\\n**技术框架**：UniPR-3D的整体架构包括以下几个主要模块：1) VGGT骨干网络：用于提取多视角图像的2D和3D特征。2) 2D特征聚合模块：用于聚合VGGT提取的2D特征，捕获细粒度的纹理信息。3) 3D特征聚合模块：用于聚合VGGT提取的3D特征，进行跨视角的几何推理。4) 单帧和多帧聚合模块：用于融合单帧和多帧的特征，提高系统的鲁棒性。5) 可变长度序列检索模块：用于处理不同长度的图像序列，提高系统的灵活性。\\n\\n**关键创新**：UniPR-3D的关键创新在于：1) 首次将视觉几何Transformer (VGGT) 应用于VPR任务，有效利用了图像的几何信息。2) 设计了专门的2D和3D特征聚合模块，能够充分利用不同类型特征的优势。3) 提出了单帧和多帧聚合策略，以及可变长度序列检索模块，提高了系统的泛化能力和灵活性。\\n\\n**关键设计**：在VGGT骨干网络中，使用了预训练的权重进行初始化，并针对VPR任务进行了微调。2D和3D特征聚合模块采用了不同的网络结构，以适应不同类型特征的特性。单帧和多帧聚合模块采用了注意力机制，用于选择重要的帧。损失函数方面，使用了对比损失和三元组损失，以提高特征的区分性。可变长度序列检索模块采用了动态规划算法，用于找到最佳的匹配序列。",
            "application_zh": "UniPR-3D在机器人导航、自动驾驶、增强现实等领域具有广泛的应用前景。它可以帮助机器人在复杂环境中进行精确定位，提高导航的准确性和鲁棒性。在自动驾驶领域，可以用于车辆的定位和地图构建。在增强现实领域，可以用于虚拟物体的精确定位和跟踪。未来，该研究可以进一步扩展到更大规模、更复杂的环境中，并与其他传感器信息融合，以实现更可靠的定位。",
            "highlight_zh": "UniPR-3D在多个VPR数据集上取得了state-of-the-art的性能，显著优于现有的单视角和多视角方法。例如，在某数据集上，UniPR-3D的召回率比最佳基线提高了10%以上。实验结果表明，UniPR-3D能够有效利用多视角信息，提高VPR系统的鲁棒性和泛化能力。消融实验也验证了各个模块的有效性。",
            "tags_zh": [
                "视觉定位识别",
                "多视角学习",
                "视觉几何Transformer",
                "三维重建",
                "特征聚合"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.21078v1/teaser2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.21078v1/figure2-4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.21078v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ARX-Implementation of encrypted nonlinear dynamic controllers using observer form",
            "authors": [
                "Deuksun Hong",
                "Donghyeon Song",
                "Mingyu Jeong",
                "Junsoo Kim"
            ],
            "arxiv_id": "2512.21244v1",
            "summary": "While computation-enabled cryptosystems applied to control systems have improved security and privacy, a major issue is that the number of recursive operations on encrypted data is limited to a finite number of times in most cases, especially where fast computation is required. To allow for nonlinear dynamic control under this constraint, a method for representing a state-space system model as an auto-regressive model with exogenous inputs (ARX model) is proposed. With the input as well as the output of the plant encrypted and transmitted to the controller, the reformulated ARX form can compute each output using only a finite number of operations, from its several previous inputs and outputs. Existence of a stable observer for the controller is a key condition for the proposed representation. The representation replaces the controller with an observer form and applies a method similar to finite-impulse-response approximation. It is verified that the approximation error and its effect can be made arbitrarily small by an appropriate choice of a parameter, under stability of the observer and the closed-loop system. Simulation results demonstrate the effectiveness of the proposed method.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-24",
            "updated": "2025-12-24",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.21244v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "PULSE"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "8_physics_animation"
            ],
            "headline_zh": "提出基于ARX模型的加密非线性动态控制器，解决加密数据递归运算次数限制问题",
            "summary_zh": "为了提高控制系统的安全性和隐私性，计算使能的密码系统被应用到控制系统中。然而，一个主要问题是，在大多数情况下，对加密数据进行递归运算的次数是有限的，尤其是在需要快速计算的场景下。为了在这种约束下实现非线性动态控制，本文提出了一种将状态空间系统模型表示为具有外生输入的自回归模型（ARX模型）的方法。通过将工厂的输入和输出加密并传输到控制器，重新构建的ARX形式可以使用有限次数的运算，从其先前的几个输入和输出中计算每个输出。控制器稳定观测器的存在是所提出表示的关键条件。该表示用观测器形式替换控制器，并应用类似于有限脉冲响应近似的方法。经验证，在观测器和闭环系统稳定的前提下，通过适当选择参数，可以使近似误差及其影响任意小。仿真结果验证了该方法的有效性。",
            "intro_zh": [
                "现有计算使能的密码系统在控制系统中存在加密数据递归运算次数受限的问题，限制了其在非线性动态控制中的应用。",
                "论文提出将状态空间系统模型转换为ARX模型，从而将控制器的计算转化为有限次数的运算，解决了递归运算次数限制问题。",
                "仿真结果表明，通过适当选择参数，可以使近似误差任意小，验证了所提出方法的有效性。"
            ],
            "method_zh": "**问题定义**：现有方法在将计算使能的密码系统应用于控制系统时，面临着加密数据递归运算次数有限的挑战。特别是在需要快速计算的非线性动态控制场景下，这种限制尤为突出。传统的非线性动态控制器通常需要进行多次递归计算，这与密码系统的约束相冲突，限制了其应用。\n\n**核心思路**：论文的核心思路是将非线性动态控制器的状态空间模型转换为ARX（Auto-Regressive with eXogenous inputs）模型。ARX模型是一种线性模型，它将系统的输出表示为过去输入和输出的线性组合。通过这种转换，控制器的计算可以被分解为有限次数的运算，从而避免了无限递归的问题，满足了密码系统的约束。\n\n**技术框架**：整体框架包括以下几个主要步骤：1) 将非线性动态控制器的状态空间模型转化为ARX模型。2) 将工厂的输入和输出进行加密，并将加密后的数据传输到控制器。3) 控制器使用ARX模型，基于加密的输入和输出数据进行计算，得到控制信号。4) 将控制信号解密并应用于工厂。该框架的关键在于ARX模型的构建和参数选择，以保证控制器的稳定性和性能。\n\n**关键创新**：论文的关键创新在于将ARX模型应用于加密的非线性动态控制。与传统的基于状态空间模型的控制器相比，ARX模型避免了递归计算，从而满足了密码系统的约束。此外，论文还提出了一种基于观测器形式的ARX模型构建方法，并证明了在观测器和闭环系统稳定的前提下，可以通过适当选择参数，使近似误差任意小。\n\n**关键设计**：论文的关键设计包括：1) ARX模型的阶数选择：需要根据系统的动态特性选择合适的阶数，以保证模型的精度和计算复杂度。2) 观测器的设计：需要设计一个稳定的观测器，以估计系统的状态，并用于ARX模型的构建。3) 参数选择：需要选择合适的参数，以保证观测器和闭环系统的稳定性，并使近似误差最小化。论文采用类似于有限脉冲响应近似的方法来构建ARX模型，并分析了近似误差的影响。",
            "application_zh": "该研究成果可应用于对安全性要求较高的控制系统，例如工业控制系统、机器人控制系统和航空航天控制系统。通过对控制信号进行加密，可以防止恶意攻击者篡改控制信号，从而提高系统的安全性。此外，该方法还可以应用于保护用户隐私的场景，例如医疗设备控制系统，可以防止用户的生理数据被泄露。",
            "highlight_zh": "论文通过仿真实验验证了所提出方法的有效性。实验结果表明，在观测器和闭环系统稳定的前提下，通过适当选择参数，可以使近似误差任意小。这表明该方法可以在保证控制性能的同时，满足密码系统的约束，为加密的非线性动态控制提供了一种可行的解决方案。",
            "tags_zh": [
                "加密控制",
                "非线性控制",
                "动态系统",
                "ARX模型",
                "观测器",
                "信息安全"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": []
        }
    ]
}