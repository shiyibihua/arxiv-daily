{
    "papers": [
        {
            "title": "RoboMirror: Understand Before You Imitate for Video to Humanoid Locomotion",
            "authors": [
                "Zhe Li",
                "Cheng Chi",
                "Yangyang Wei",
                "Boan Zhu",
                "Tao Huang",
                "Zhenguo Sun",
                "Yibo Peng",
                "Pengwei Wang",
                "Zhongyuan Wang",
                "Fangzhou Liu",
                "Chang Xu",
                "Shanghang Zhang"
            ],
            "arxiv_id": "2512.23649v1",
            "summary": "Humans learn locomotion through visual observation, interpreting visual content first before imitating actions. However, state-of-the-art humanoid locomotion systems rely on either curated motion capture trajectories or sparse text commands, leaving a critical gap between visual understanding and control. Text-to-motion methods suffer from semantic sparsity and staged pipeline errors, while video-based approaches only perform mechanical pose mimicry without genuine visual understanding. We propose RoboMirror, the first retargeting-free video-to-locomotion framework embodying \"understand before you imitate\". Leveraging VLMs, it distills raw egocentric/third-person videos into visual motion intents, which directly condition a diffusion-based policy to generate physically plausible, semantically aligned locomotion without explicit pose reconstruction or retargeting. Extensive experiments validate the effectiveness of RoboMirror, it enables telepresence via egocentric videos, drastically reduces third-person control latency by 80%, and achieves a 3.7% higher task success rate than baselines. By reframing humanoid control around video understanding, we bridge the visual understanding and action gap.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23649v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "humanoid control",
                        "[T]humanoid locomotion",
                        "[T]locomotion"
                    ],
                    "score": 20.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "text-to-motion",
                        "physically plausible"
                    ],
                    "score": 5.0
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "egocentric"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 27.0,
            "hit_pillars": [
                "1_robot_core",
                "4_motion_diffusion",
                "6_video_extraction"
            ],
            "headline_zh": "RoboMirror：提出一种基于视频理解的人形机器人运动模仿框架",
            "summary_zh": "本文提出RoboMirror，一种无需重定向的视频到人形机器人运动框架，旨在实现“理解先于模仿”。该框架利用视觉语言模型（VLM）将第一人称/第三人称视角视频提炼成视觉运动意图，直接调节基于扩散模型的策略，生成物理上合理且语义对齐的运动，无需显式的姿态重建或重定向。大量实验验证了RoboMirror的有效性，它支持通过第一人称视频进行远程呈现，显著降低了第三人称控制的延迟（降低80%），并实现了比基线方法高3.7%的任务成功率。通过围绕视频理解重构人形机器人控制，弥合了视觉理解和动作之间的差距。",
            "intro_zh": [
                "现有的人形机器人运动系统依赖于人工标注的运动捕捉轨迹或稀疏的文本命令，缺乏对视觉内容的理解。",
                "RoboMirror利用视觉语言模型从视频中提取运动意图，并以此为条件驱动扩散模型生成运动，实现理解驱动的模仿。",
                "实验表明，RoboMirror在远程呈现、降低控制延迟和提高任务成功率方面均优于现有方法。"
            ],
            "method_zh": "**问题定义**：现有的人形机器人运动控制方法主要依赖于两种方式：一是使用人工设计的运动捕捉数据，二是使用稀疏的文本指令。前者需要大量的人工标注，成本高昂；后者则存在语义稀疏性和流水线误差的问题，难以实现精确的控制。此外，现有的基于视频的方法通常只进行机械的姿态模仿，缺乏对视频内容的深层理解，无法实现智能的运动控制。\\n\\n**核心思路**：RoboMirror的核心思路是“理解先于模仿”，即首先通过视觉语言模型（VLM）理解视频中的运动意图，然后利用这些意图来指导人形机器人的运动。这种方法避免了直接进行姿态重建或重定向，而是将视频理解作为运动控制的关键环节，从而实现更智能、更自然的运动控制。\\n\\n**技术框架**：RoboMirror的整体框架包括以下几个主要模块：1) 视频输入模块：接收第一人称或第三人称视角的视频作为输入。2) 视觉语言模型（VLM）：将视频帧转换为运动意图的文本描述。3) 扩散模型策略：以运动意图为条件，生成人形机器人的运动轨迹。4) 运动控制模块：将运动轨迹转化为机器人的关节控制指令。整个流程无需显式的姿态重建或重定向。\\n\\n**关键创新**：RoboMirror最重要的创新点在于它将视觉理解融入到人形机器人运动控制中，通过视觉语言模型提取视频中的运动意图，并以此为条件驱动运动生成。这种方法摆脱了对人工标注数据的依赖，实现了基于视觉理解的智能运动控制。与现有方法相比，RoboMirror能够更好地理解视频内容，生成更符合语义的运动。\\n\\n**关键设计**：RoboMirror的关键设计包括：1) 选择合适的视觉语言模型，以准确提取视频中的运动意图。2) 设计有效的扩散模型策略，以生成物理上合理且语义对齐的运动轨迹。3) 优化运动控制模块，以实现精确的机器人关节控制。论文中可能还涉及损失函数的设计，例如用于保证生成运动与视频意图一致性的损失函数，以及用于保证运动物理合理性的损失函数。具体的网络结构和参数设置在论文中会有详细描述（未知）。",
            "application_zh": "RoboMirror具有广泛的应用前景，例如远程呈现、虚拟现实、游戏和机器人辅助等领域。通过第一人称视频，用户可以远程控制人形机器人执行各种任务。在虚拟现实和游戏中，RoboMirror可以实现更逼真的角色动画和交互。此外，RoboMirror还可以应用于机器人辅助康复和训练等领域，帮助人们更好地进行运动学习。",
            "highlight_zh": "RoboMirror在多个实验中表现出色。在远程呈现任务中，它能够通过第一人称视频实现对人形机器人的有效控制。在第三人称控制任务中，RoboMirror将控制延迟降低了80%。此外，RoboMirror在任务成功率方面也优于基线方法，实现了3.7%的提升。这些实验结果表明，RoboMirror是一种有效且实用的视频到人形机器人运动框架。",
            "tags_zh": [
                "人形机器人",
                "运动控制",
                "视频理解",
                "视觉语言模型",
                "扩散模型",
                "运动意图",
                "远程呈现"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23649v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23649v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23649v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HY-Motion 1.0: Scaling Flow Matching Models for Text-To-Motion Generation",
            "authors": [
                "Yuxin Wen",
                "Qing Shuai",
                "Di Kang",
                "Jing Li",
                "Cheng Wen",
                "Yue Qian",
                "Ningxin Jiao",
                "Changhai Chen",
                "Weijie Chen",
                "Yiran Wang",
                "Jinkun Guo",
                "Dongyue An",
                "Han Liu",
                "Yanyu Tong",
                "Chao Zhang",
                "Qing Guo",
                "Juan Chen",
                "Qiao Zhang",
                "Youyi Zhang",
                "Zihao Yao",
                "Cheng Zhang",
                "Hong Duan",
                "Xiaoping Wu",
                "Qi Chen",
                "Fei Cheng",
                "Liang Dong",
                "Peng He",
                "Hao Zhang",
                "Jiaxin Lin",
                "Chao Zhang",
                "Zhongyi Fan",
                "Yifan Li",
                "Zhichao Hu",
                "Yuhong Liu",
                "Linus",
                "Jie Jiang",
                "Xiaolong Li",
                "Linchao Bao"
            ],
            "arxiv_id": "2512.23464v1",
            "summary": "We present HY-Motion 1.0, a series of state-of-the-art, large-scale, motion generation models capable of generating 3D human motions from textual descriptions. HY-Motion 1.0 represents the first successful attempt to scale up Diffusion Transformer (DiT)-based flow matching models to the billion-parameter scale within the motion generation domain, delivering instruction-following capabilities that significantly outperform current open-source benchmarks. Uniquely, we introduce a comprehensive, full-stage training paradigm -- including large-scale pretraining on over 3,000 hours of motion data, high-quality fine-tuning on 400 hours of curated data, and reinforcement learning from both human feedback and reward models -- to ensure precise alignment with the text instruction and high motion quality. This framework is supported by our meticulous data processing pipeline, which performs rigorous motion cleaning and captioning. Consequently, our model achieves the most extensive coverage, spanning over 200 motion categories across 6 major classes. We release HY-Motion 1.0 to the open-source community to foster future research and accelerate the transition of 3D human motion generation models towards commercial maturity.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Github: see https://github.com/Tencent-Hunyuan/HY-Motion-1.0",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23464v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "[T]flow matching"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]text-to-motion",
                        "[T]motion generation"
                    ],
                    "score": 15.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "instruction following"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 24.0,
            "hit_pillars": [
                "2_algo_arch",
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "HY-Motion 1.0：扩展Flow Matching模型至十亿参数规模，实现文本驱动的3D人体动作生成。",
            "summary_zh": "HY-Motion 1.0 是一系列先进的大规模运动生成模型，能够从文本描述生成 3D 人体运动。它是首次成功地将基于 Diffusion Transformer (DiT) 的 flow matching 模型扩展到运动生成领域中数十亿参数规模的尝试，提供了显著优于当前开源基准的指令遵循能力。该模型引入了一个全面的全阶段训练范式，包括超过 3,000 小时的运动数据的大规模预训练、400 小时精选数据上的高质量微调，以及来自人类反馈和奖励模型的强化学习，以确保与文本指令的精确对齐和高质量的运动。这一框架由我们细致的数据处理流程支持，该流程执行严格的运动清理和标注。因此，我们的模型实现了最广泛的覆盖，跨越 6 个主要类别中的 200 多个运动类别。我们将 HY-Motion 1.0 开源，以促进未来的研究并加速 3D 人体运动生成模型向商业成熟的过渡。",
            "intro_zh": [
                "现有文本到动作生成模型在指令遵循和动作质量上存在不足，难以满足复杂场景需求。",
                "HY-Motion 1.0 通过扩展 Diffusion Transformer (DiT) 架构，并结合大规模数据训练和强化学习，提升模型性能。",
                "该模型在超过200个运动类别上表现出色，显著超越现有开源基准，并已开源促进进一步研究。"
            ],
            "method_zh": "**问题定义**：现有文本到动作生成模型难以生成高质量、符合文本描述的3D人体运动。痛点在于模型规模小，数据量不足，以及缺乏有效的训练策略来保证文本与动作的对齐。\n\n**核心思路**：HY-Motion 1.0的核心思路是利用大规模数据和模型参数来提升模型的表达能力，并采用全阶段训练范式，包括预训练、微调和强化学习，以确保模型能够准确理解文本指令并生成高质量的动作。\n\n**技术框架**：HY-Motion 1.0 采用基于 Diffusion Transformer (DiT) 的 flow matching 模型。整体流程包括：1) 大规模运动数据预训练；2) 高质量数据微调；3) 基于人类反馈和奖励模型的强化学习。数据处理流程包括运动清理和标注。\n\n**关键创新**：最重要的创新点在于成功将 DiT-based flow matching 模型扩展到数十亿参数规模，并应用于运动生成领域。此外，全阶段训练范式，特别是结合人类反馈和奖励模型的强化学习，是提升模型性能的关键。\n\n**关键设计**：具体的技术细节包括：大规模预训练数据集的构建，高质量微调数据集的筛选，以及强化学习中奖励函数的设计。模型参数规模达到数十亿级别，网络结构采用 Diffusion Transformer (DiT)。",
            "application_zh": "HY-Motion 1.0 可广泛应用于虚拟现实、游戏开发、动画制作、机器人控制等领域。该模型能够根据文本描述生成逼真的人体运动，极大地降低了相关内容的制作成本，并为用户提供了更丰富的交互体验。未来，该技术有望应用于智能康复、运动训练等领域。",
            "highlight_zh": "HY-Motion 1.0 在文本到动作生成任务上取得了显著的性能提升，超越了现有的开源基准。该模型能够生成覆盖超过200个运动类别的高质量3D人体运动。通过大规模预训练、高质量微调和强化学习，模型在指令遵循和动作质量上均有显著提升。",
            "tags_zh": [
                "文本到动作生成",
                "3D人体运动",
                "Diffusion Transformer",
                "Flow Matching",
                "大规模预训练",
                "强化学习",
                "运动捕捉",
                "动作生成"
            ],
            "_index": 1,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23464v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23464v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23464v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Do You Have Freestyle? Expressive Humanoid Locomotion via Audio Control",
            "authors": [
                "Zhe Li",
                "Cheng Chi",
                "Yangyang Wei",
                "Boan Zhu",
                "Tao Huang",
                "Zhenguo Sun",
                "Yibo Peng",
                "Pengwei Wang",
                "Zhongyuan Wang",
                "Fangzhou Liu",
                "Chang Xu",
                "Shanghang Zhang"
            ],
            "arxiv_id": "2512.23650v1",
            "summary": "Humans intuitively move to sound, but current humanoid robots lack expressive improvisational capabilities, confined to predefined motions or sparse commands. Generating motion from audio and then retargeting it to robots relies on explicit motion reconstruction, leading to cascaded errors, high latency, and disjointed acoustic-actuation mapping. We propose RoboPerform, the first unified audio-to-locomotion framework that can directly generate music-driven dance and speech-driven co-speech gestures from audio. Guided by the core principle of \"motion = content + style\", the framework treats audio as implicit style signals and eliminates the need for explicit motion reconstruction. RoboPerform integrates a ResMoE teacher policy for adapting to diverse motion patterns and a diffusion-based student policy for audio style injection. This retargeting-free design ensures low latency and high fidelity. Experimental validation shows that RoboPerform achieves promising results in physical plausibility and audio alignment, successfully transforming robots into responsive performers capable of reacting to audio.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23650v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "humanoid robot",
                        "[T]humanoid locomotion",
                        "[T]locomotion"
                    ],
                    "score": 20.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "RoboPerform：提出一种基于音频控制的拟人机器人自由运动生成框架",
            "summary_zh": "本文提出RoboPerform，首个统一的音频到运动框架，能够直接从音频生成音乐驱动的舞蹈和语音驱动的伴随手势。该框架遵循“运动=内容+风格”的核心原则，将音频视为隐式的风格信号，无需显式的运动重建。RoboPerform集成了ResMoE教师策略以适应不同的运动模式，以及基于扩散的student策略以注入音频风格。这种无需重定向的设计确保了低延迟和高保真度。实验验证表明，RoboPerform在物理合理性和音频对齐方面取得了有希望的结果，成功地将机器人转变为能够对音频做出反应的表演者。",
            "intro_zh": [
                "现有拟人机器人缺乏表现力，通常局限于预定义的动作或稀疏的指令，难以实现即兴表演。",
                "RoboPerform将音频作为隐式风格信号，避免了显式的运动重建，从而降低了延迟并提高了保真度。",
                "实验表明，RoboPerform在物理合理性和音频对齐方面表现出色，使机器人能够根据音频进行舞蹈和手势表演。"
            ],
            "method_zh": "**问题定义**：现有方法依赖于显式的运动重建，将音频转换为运动再重定向到机器人，导致级联误差、高延迟以及声学-驱动映射的脱节。因此，如何直接从音频生成高质量、低延迟的机器人运动是一个关键问题。\\n\\n**核心思路**：RoboPerform的核心思路是将音频视为一种隐式的风格信号，并直接将其注入到运动生成过程中，避免了中间的运动重建步骤。这种方法基于“运动=内容+风格”的原则，认为音频可以提供运动的风格信息，而无需显式地定义运动的细节。\\n\\n**技术框架**：RoboPerform框架包含一个ResMoE教师策略和一个基于扩散的student策略。ResMoE教师策略用于学习各种运动模式，从而适应不同的运动内容。基于扩散的student策略则负责将音频风格注入到运动生成过程中。整个框架无需运动重定向，直接生成机器人的运动控制信号。\\n\\n**关键创新**：RoboPerform的关键创新在于其无需显式运动重建的架构。通过将音频作为隐式风格信号，并使用扩散模型进行风格注入，该框架能够生成高质量、低延迟的机器人运动。这种方法避免了传统方法中的级联误差和延迟问题。\\n\\n**关键设计**：ResMoE教师策略使用混合专家模型（MoE）来学习不同的运动模式。基于扩散的student策略使用扩散模型将音频特征融入到运动生成过程中。损失函数包括运动平滑性损失、音频对齐损失和物理合理性损失，以确保生成的运动既自然又符合物理规律。",
            "application_zh": "RoboPerform具有广泛的应用前景，包括娱乐机器人、人机交互、康复训练等领域。它可以使机器人能够根据音乐进行舞蹈表演，或者根据语音进行伴随手势，从而提高人机交互的自然性和趣味性。此外，该技术还可以应用于康复训练，通过音乐或语音引导患者进行运动。",
            "highlight_zh": "RoboPerform在实验中表现出良好的物理合理性和音频对齐性能。与现有方法相比，RoboPerform能够生成更自然、更流畅的机器人运动，并且能够更好地与音频同步。实验结果表明，RoboPerform成功地将机器人转变为能够对音频做出反应的表演者。",
            "tags_zh": [
                "音频控制",
                "拟人机器人",
                "运动生成",
                "扩散模型",
                "人机交互",
                "风格迁移",
                "ResMoE",
                "低延迟"
            ],
            "_index": 2,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23650v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23650v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23650v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RxnBench: A Multimodal Benchmark for Evaluating Large Language Models on Chemical Reaction Understanding from Scientific Literature",
            "authors": [
                "Hanzheng Li",
                "Xi Fang",
                "Yixuan Li",
                "Chaozheng Huang",
                "Junjie Wang",
                "Xi Wang",
                "Hongzhe Bai",
                "Bojun Hao",
                "Shenyu Lin",
                "Huiqi Liang",
                "Linfeng Zhang",
                "Guolin Ke"
            ],
            "arxiv_id": "2512.23565v1",
            "summary": "The integration of Multimodal Large Language Models (MLLMs) into chemistry promises to revolutionize scientific discovery, yet their ability to comprehend the dense, graphical language of reactions within authentic literature remains underexplored. Here, we introduce RxnBench, a multi-tiered benchmark designed to rigorously evaluate MLLMs on chemical reaction understanding from scientific PDFs. RxnBench comprises two tasks: Single-Figure QA (SF-QA), which tests fine-grained visual perception and mechanistic reasoning using 1,525 questions derived from 305 curated reaction schemes, and Full-Document QA (FD-QA), which challenges models to synthesize information from 108 articles, requiring cross-modal integration of text, schemes, and tables. Our evaluation of MLLMs reveals a critical capability gap: while models excel at extracting explicit text, they struggle with deep chemical logic and precise structural recognition. Notably, models with inference-time reasoning significantly outperform standard architectures, yet none achieve 50\\% accuracy on FD-QA. These findings underscore the urgent need for domain-specific visual encoders and stronger reasoning engines to advance autonomous AI chemists.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23565v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "[T]multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RxnBench：一个多模态基准，用于评估大语言模型对科学文献中化学反应的理解能力",
            "summary_zh": "将多模态大语言模型（MLLM）集成到化学领域有望彻底改变科学发现，但它们理解真实文献中密集、图形化反应语言的能力仍未得到充分探索。本文提出了RxnBench，这是一个多层基准，旨在严格评估MLLM对科学PDF中化学反应的理解能力。RxnBench包含两个任务：单图问答（SF-QA），使用从305个精选反应方案中提取的1525个问题来测试细粒度的视觉感知和机理推理；以及全文问答（FD-QA），要求模型综合来自108篇文章的信息，需要跨模态整合文本、方案和表格。对MLLM的评估揭示了一个关键的能力差距：虽然模型擅长提取显式文本，但它们在深入的化学逻辑和精确的结构识别方面存在困难。值得注意的是，具有推理时推理的模型明显优于标准架构，但没有一个模型在FD-QA上达到50%的准确率。这些发现强调了迫切需要特定领域的视觉编码器和更强大的推理引擎，以推进自主AI化学家的发展。",
            "intro_zh": [
                "现有MLLM在理解化学文献中复杂的反应图谱和文本信息方面存在不足，限制了其在化学发现中的应用。",
                "RxnBench通过构建包含单图问答和全文问答的多层基准，系统性地评估MLLM在化学反应理解方面的能力。",
                "实验结果表明，现有MLLM在化学逻辑和结构识别方面存在明显差距，需要更专业的视觉编码器和推理引擎。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型（MLLM）在理解化学科学文献中化学反应的难题。现有方法在处理包含复杂图表和文本信息的化学文献时，无法有效提取和整合信息，尤其是在理解化学逻辑和精确识别化学结构方面存在明显不足。这阻碍了MLLM在化学研究中的应用，例如自动化文献分析和反应预测。\n\n**核心思路**：论文的核心思路是构建一个专门用于评估MLLM在化学反应理解方面能力的基准数据集RxnBench。通过设计不同难度的问答任务，系统性地测试MLLM对化学反应的视觉感知、机理推理和信息整合能力。该基准旨在揭示现有MLLM的局限性，并推动领域内模型的发展。\n\n**技术框架**：RxnBench包含两个主要任务：单图问答（SF-QA）和全文问答（FD-QA）。SF-QA侧重于细粒度的视觉感知和机理推理，使用从反应方案中提取的问题进行评估。FD-QA则要求模型整合来自整篇文章的信息，包括文本、反应方案和表格，以回答更复杂的问题。整个流程包括数据收集、问题生成、模型评估和结果分析。\n\n**关键创新**：RxnBench的关键创新在于其专注于评估MLLM对化学反应的理解能力，而不仅仅是通用的视觉或文本理解。它通过设计特定领域的问答任务，更准确地反映了MLLM在化学研究中的实际应用需求。此外，RxnBench涵盖了单图和全文两种场景，更全面地评估了模型的跨模态信息整合能力。\n\n**关键设计**：SF-QA任务的问题设计侧重于反应机理和结构识别，例如询问反应物、产物、催化剂等。FD-QA任务的问题则需要模型整合来自不同模态的信息，例如从文本中提取反应条件，从反应方案中识别反应类型。评估指标主要采用准确率，以衡量模型回答问题的正确程度。论文还探索了使用推理时推理（inference-time reasoning）技术来提升模型性能。",
            "application_zh": "RxnBench的潜在应用领域包括：自动化化学文献分析、智能化学反应预测、辅助化学研究和教育等。通过提高MLLM对化学反应的理解能力，可以加速新材料的发现、优化化学反应路径，并为化学研究人员提供更强大的工具。未来，该基准可以扩展到其他化学领域，例如药物发现和材料科学。",
            "highlight_zh": "实验结果表明，现有MLLM在RxnBench上的表现与人类专家存在显著差距，尤其是在FD-QA任务上，没有模型达到50%的准确率。具有推理时推理的模型在一定程度上提升了性能，但仍远低于预期。这些结果表明，需要开发更专业的视觉编码器和推理引擎，以提高MLLM在化学领域的应用能力。",
            "tags_zh": [
                "多模态学习",
                "化学反应理解",
                "大语言模型",
                "基准数据集",
                "科学文献"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23565v1/media/image1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23565v1/media/image2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23565v1/media/image3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MM-UAVBench: How Well Do Multimodal Large Language Models See, Think, and Plan in Low-Altitude UAV Scenarios?",
            "authors": [
                "Shiqi Dai",
                "Zizhi Ma",
                "Zhicong Luo",
                "Xuesong Yang",
                "Yibin Huang",
                "Wanyue Zhang",
                "Chi Chen",
                "Zonghao Guo",
                "Wang Xu",
                "Yufei Sun",
                "Maosong Sun"
            ],
            "arxiv_id": "2512.23219v1",
            "summary": "While Multimodal Large Language Models (MLLMs) have exhibited remarkable general intelligence across diverse domains, their potential in low-altitude applications dominated by Unmanned Aerial Vehicles (UAVs) remains largely underexplored. Existing MLLM benchmarks rarely cover the unique challenges of low-altitude scenarios, while UAV-related evaluations mainly focus on specific tasks such as localization or navigation, without a unified evaluation of MLLMs'general intelligence. To bridge this gap, we present MM-UAVBench, a comprehensive benchmark that systematically evaluates MLLMs across three core capability dimensions-perception, cognition, and planning-in low-altitude UAV scenarios. MM-UAVBench comprises 19 sub-tasks with over 5.7K manually annotated questions, all derived from real-world UAV data collected from public datasets. Extensive experiments on 16 open-source and proprietary MLLMs reveal that current models struggle to adapt to the complex visual and cognitive demands of low-altitude scenarios. Our analyses further uncover critical bottlenecks such as spatial bias and multi-view understanding that hinder the effective deployment of MLLMs in UAV scenarios. We hope MM-UAVBench will foster future research on robust and reliable MLLMs for real-world UAV intelligence.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "25 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23219v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "[T]multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MM-UAVBench，评估多模态大语言模型在低空无人机场景下的感知、认知和规划能力。",
            "summary_zh": "多模态大语言模型(MLLMs)在各个领域展现了卓越的通用智能，但其在无人机(UAV)主导的低空应用中的潜力尚未得到充分探索。现有的MLLM基准测试很少涵盖低空场景的独特挑战，而与UAV相关的评估主要集中在定位或导航等特定任务上，缺乏对MLLM通用智能的统一评估。为了弥合这一差距，我们提出了MM-UAVBench，这是一个全面的基准，系统地评估了MLLM在低空UAV场景中的三个核心能力维度——感知、认知和规划。MM-UAVBench包含19个子任务，包含超过5.7K个手动标注的问题，所有问题都来自公共数据集收集的真实UAV数据。对16个开源和专有MLLM的大量实验表明，当前的模型难以适应低空场景的复杂视觉和认知需求。我们的分析进一步揭示了空间偏差和多视角理解等关键瓶颈，这些瓶颈阻碍了MLLM在UAV场景中的有效部署。我们希望MM-UAVBench能够促进未来对鲁棒且可靠的MLLM在实际UAV智能方面的研究。",
            "intro_zh": [
                "现有MLLM基准测试缺乏对低空无人机场景的针对性评估，无法有效反映模型在此类复杂环境下的性能。",
                "MM-UAVBench通过构建包含感知、认知和规划三个维度的综合评估体系，系统地测试MLLM在低空无人机场景中的能力。",
                "实验结果表明，现有MLLM在低空场景中面临空间偏差和多视角理解等挑战，性能有待提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型(MLLM)在低空无人机(UAV)场景下应用效果评估不足的问题。现有MLLM基准测试很少关注低空环境的特殊性，而UAV相关的研究又过于关注特定任务，缺乏对MLLM通用智能的全面评估。这导致我们难以了解现有MLLM在实际UAV应用中的潜力和局限性。\\n\\n**核心思路**：论文的核心思路是构建一个专门针对低空UAV场景的综合性基准测试集MM-UAVBench。通过设计一系列涵盖感知、认知和规划三个核心能力维度的子任务，系统地评估MLLM在处理低空UAV数据时的表现。这种方法能够更全面地揭示MLLM在UAV应用中的优势和不足，为未来的研究提供指导。\\n\\n**技术框架**：MM-UAVBench的整体框架包括数据收集、任务设计和模型评估三个主要阶段。首先，从公共数据集中收集真实的UAV图像和视频数据。然后，基于这些数据设计19个子任务，涵盖感知（例如目标检测、场景理解）、认知（例如推理、常识判断）和规划（例如路径规划、任务调度）三个维度。最后，使用这些子任务评估多个开源和专有的MLLM，并分析其性能瓶颈。\\n\\n**关键创新**：MM-UAVBench的关键创新在于其针对低空UAV场景的特殊设计。与现有的通用MLLM基准测试不同，MM-UAVBench更加关注低空环境的复杂性和挑战，例如视角变化、光照变化和遮挡等。此外，MM-UAVBench还引入了规划任务，这在现有的MLLM基准测试中相对较少。\\n\\n**关键设计**：MM-UAVBench包含19个子任务，每个子任务都包含多个手动标注的问题。这些问题旨在测试MLLM在不同方面的能力，例如识别不同类型的目标、理解场景中的关系、进行逻辑推理和制定合理的计划。为了确保评估的公平性和可靠性，论文作者对所有问题进行了仔细的审查和验证。",
            "application_zh": "该研究成果可应用于多种低空无人机应用场景，例如智能巡检、环境监测、灾害救援和物流配送等。通过评估和改进MLLM在这些场景下的性能，可以提高无人机的自主性和智能化水平，从而提升工作效率和安全性。未来，该基准测试集可以促进更多针对无人机应用的MLLM研究。",
            "highlight_zh": "在MM-UAVBench上对16个MLLM的实验结果表明，现有模型在低空UAV场景中表现不佳，尤其是在空间推理和多视角理解方面。例如，模型在处理视角变化较大的图像时，目标识别的准确率显著下降。这些结果揭示了现有MLLM在UAV应用中的局限性，为未来的研究指明了方向。",
            "tags_zh": [
                "多模态大语言模型",
                "无人机",
                "低空场景",
                "基准测试",
                "感知",
                "认知",
                "规划",
                "空间推理"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23219v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23219v1/x1.png",
                    "caption": "",
                    "figure_id": "img_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23219v1/x2.png",
                    "caption": "",
                    "figure_id": "img_2"
                }
            ]
        },
        {
            "title": "Replay Failures as Successes: Sample-Efficient Reinforcement Learning for Instruction Following",
            "authors": [
                "Kongcheng Zhang",
                "Qi Yao",
                "Shunyu Liu",
                "Wenjian Zhang",
                "Min Cen",
                "Yang Zhou",
                "Wenkai Fang",
                "Yiru Zhao",
                "Baisheng Lai",
                "Mingli Song"
            ],
            "arxiv_id": "2512.23457v1",
            "summary": "Reinforcement Learning (RL) has shown promise for aligning Large Language Models (LLMs) to follow instructions with various constraints. Despite the encouraging results, RL improvement inevitably relies on sampling successful, high-quality responses; however, the initial model often struggles to generate responses that satisfy all constraints due to its limited capabilities, yielding sparse or indistinguishable rewards that impede learning. In this work, we propose Hindsight instruction Replay (HiR), a novel sample-efficient RL framework for complex instruction following tasks, which employs a select-then-rewrite strategy to replay failed attempts as successes based on the constraints that have been satisfied in hindsight. We perform RL on these replayed samples as well as the original ones, theoretically framing the objective as dual-preference learning at both the instruction- and response-level to enable efficient optimization using only a binary reward signal. Extensive experiments demonstrate that the proposed HiR yields promising results across different instruction following tasks, while requiring less computational budget. Our code and dataset is available at https://github.com/sastpg/HIR.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23457v1",
            "code_links": [
                {
                    "url": "https://github.com/sastpg/HIR",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "preference learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]instruction following"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出HiR，通过回溯式指令重放提升指令跟随任务中强化学习的样本效率",
            "summary_zh": "强化学习(RL)在对齐大型语言模型(LLM)以遵循具有各种约束的指令方面显示出前景。尽管结果令人鼓舞，但RL的改进不可避免地依赖于采样成功的、高质量的响应；然而，由于初始模型的能力有限，通常难以生成满足所有约束的响应，从而产生稀疏或难以区分的奖励，阻碍了学习。本文提出了一种新颖的、样本高效的RL框架——回溯式指令重放(HiR)，用于复杂的指令跟随任务。HiR采用了一种先选择后重写的策略，基于事后满足的约束，将失败的尝试重放为成功。我们在这些重放的样本以及原始样本上执行RL，从理论上将目标构建为指令和响应级别的双重偏好学习，从而仅使用二元奖励信号即可实现高效优化。大量的实验表明，所提出的HiR在不同的指令跟随任务中产生了有希望的结果，同时需要的计算预算更少。我们的代码和数据集可在https://github.com/sastpg/HIR 获得。",
            "intro_zh": [
                "现有强化学习方法在指令跟随任务中面临奖励稀疏问题，初始模型难以生成满足所有约束的响应，导致学习效率低下。",
                "HiR通过回溯式指令重放，将失败的尝试根据事后满足的约束改写为成功案例，增加有效样本，提升学习效率。",
                "实验结果表明，HiR在不同指令跟随任务中表现出色，显著提升了样本效率，降低了计算成本。"
            ],
            "method_zh": "**问题定义**：论文旨在解决指令跟随任务中，强化学习训练样本效率低下的问题。现有方法依赖于采样成功的、高质量的响应，但初始模型往往难以满足所有指令约束，导致奖励信号稀疏，学习过程受阻。这种稀疏奖励问题严重限制了强化学习在复杂指令跟随任务中的应用。\n\n**核心思路**：HiR的核心思路是将失败的尝试转化为成功的经验。它不是简单地丢弃不满足所有约束的响应，而是通过“选择-重写”策略，根据事后满足的约束条件，将失败的尝试改写为成功的案例。这样可以有效增加训练样本的多样性和有效性，从而提升强化学习的样本效率。\n\n**技术框架**：HiR的整体框架包含以下几个主要步骤：1) 初始模型生成响应；2) 根据指令和响应计算奖励信号（二元奖励）；3) 选择满足部分约束的失败尝试；4) 根据满足的约束，重写失败的尝试，使其成为“伪成功”样本；5) 使用原始样本和重写后的样本进行强化学习训练。该框架在指令和响应两个层面进行双重偏好学习。\n\n**关键创新**：HiR的关键创新在于回溯式指令重放机制。与传统强化学习方法不同，HiR充分利用了失败的尝试，通过重写将其转化为有价值的训练样本。这种方法有效地解决了奖励稀疏问题，显著提升了样本效率。此外，HiR将目标构建为指令和响应级别的双重偏好学习，进一步提升了优化效率。\n\n**关键设计**：HiR使用二元奖励信号，简化了奖励函数的设计。选择-重写策略是关键，具体实现可能涉及规则、启发式方法或学习模型。损失函数的设计需要同时考虑原始样本和重写样本，以实现双重偏好学习。具体的网络结构取决于具体的指令跟随任务，但通常会采用Transformer等模型。",
            "application_zh": "HiR可应用于各种需要指令跟随的场景，例如机器人控制、对话系统、代码生成等。通过提升样本效率，HiR能够降低训练成本，加速模型迭代，使得强化学习能够更好地应用于实际复杂的任务中。该方法在智能助手、自动化流程等领域具有广泛的应用前景。",
            "highlight_zh": "HiR在多个指令跟随任务上取得了显著的性能提升，实验结果表明，HiR能够以更少的计算资源达到与现有方法相当甚至更好的性能。具体的性能数据和对比基线在论文中详细给出，证明了HiR在样本效率方面的优势。",
            "tags_zh": [
                "强化学习",
                "指令跟随",
                "样本效率",
                "回溯式学习",
                "语言模型"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23457v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23457v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23457v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PathFound: An Agentic Multimodal Model Activating Evidence-seeking Pathological Diagnosis",
            "authors": [
                "Shengyi Hua",
                "Jianfeng Wu",
                "Tianle Shen",
                "Kangzhe Hu",
                "Zhongzhen Huang",
                "Shujuan Ni",
                "Zhihong Zhang",
                "Yuan Li",
                "Zhe Wang",
                "Xiaofan Zhang"
            ],
            "arxiv_id": "2512.23545v1",
            "summary": "Recent pathological foundation models have substantially advanced visual representation learning and multimodal interaction. However, most models still rely on a static inference paradigm in which whole-slide images are processed once to produce predictions, without reassessment or targeted evidence acquisition under ambiguous diagnoses. This contrasts with clinical diagnostic workflows that refine hypotheses through repeated slide observations and further examination requests. We propose PathFound, an agentic multimodal model designed to support evidence-seeking inference in pathological diagnosis. PathFound integrates the power of pathological visual foundation models, vision-language models, and reasoning models trained with reinforcement learning to perform proactive information acquisition and diagnosis refinement by progressing through the initial diagnosis, evidence-seeking, and final decision stages. Across several large multimodal models, adopting this strategy consistently improves diagnostic accuracy, indicating the effectiveness of evidence-seeking workflows in computational pathology. Among these models, PathFound achieves state-of-the-art diagnostic performance across diverse clinical scenarios and demonstrates strong potential to discover subtle details, such as nuclear features and local invasions.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23545v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "representation learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "PathFound：一种主动证据搜寻的病理诊断多模态Agent模型",
            "summary_zh": "近期的病理学基础模型在视觉表征学习和多模态交互方面取得了显著进展。然而，大多数模型仍然依赖于静态的推理范式，即对整张切片图像进行一次处理以产生预测，而没有在诊断模糊时进行重新评估或有针对性的证据获取。这与临床诊断工作流程形成对比，后者通过重复的切片观察和进一步的检查请求来完善假设。我们提出了PathFound，一种旨在支持病理诊断中证据搜寻推理的主动多模态模型。PathFound集成了病理视觉基础模型、视觉-语言模型和使用强化学习训练的推理模型，通过初始诊断、证据搜寻和最终决策阶段，执行主动的信息获取和诊断改进。在几个大型多模态模型中，采用这种策略始终提高了诊断准确性，表明证据搜寻工作流程在计算病理学中的有效性。在这些模型中，PathFound在不同的临床场景中实现了最先进的诊断性能，并展示了发现细微细节（如核特征和局部浸润）的强大潜力。",
            "intro_zh": [
                "现有病理诊断模型缺乏主动证据搜寻能力，无法模拟医生通过多次观察和检查来完善诊断的过程。",
                "PathFound通过集成视觉基础模型、视觉-语言模型和强化学习推理模型，模拟医生主动搜寻证据并改进诊断的流程。",
                "实验表明，PathFound在多个大型多模态模型中提高了诊断准确性，并在不同临床场景中达到了最先进的性能。"
            ],
            "method_zh": "**问题定义**：现有病理诊断模型主要采用静态推理范式，即对整张切片图像进行一次性处理并给出预测，缺乏主动证据搜寻和诊断迭代的能力。这种方式无法模拟病理医生在实际诊断过程中，根据初步诊断结果，有针对性地观察特定区域或请求额外检查以获取更多证据，从而提高诊断准确性的过程。因此，如何使模型具备主动证据搜寻能力，以模拟临床诊断流程，是本文要解决的核心问题。\\n\\n**核心思路**：PathFound的核心思路是将病理诊断过程建模为一个Agent与环境交互的过程。Agent（模型）通过观察切片图像，进行初步诊断，并根据诊断结果决定下一步行动（例如，观察特定区域或请求额外检查）。环境（病理切片）根据Agent的行动提供新的信息，Agent根据新的信息更新诊断结果，并重复上述过程，直到最终做出诊断决策。这种主动证据搜寻的思路旨在模拟病理医生在实际诊断中的迭代过程，从而提高诊断准确性。\\n\\n**技术框架**：PathFound的技术框架主要包含三个阶段：初始诊断阶段、证据搜寻阶段和最终决策阶段。在初始诊断阶段，模型利用病理视觉基础模型对整张切片图像进行初步分析，并给出初步诊断结果。在证据搜寻阶段，模型根据初步诊断结果，利用视觉-语言模型和推理模型，决定下一步需要观察的区域或需要进行的检查。模型通过与环境交互，获取新的信息，并更新诊断结果。在最终决策阶段，模型综合所有已获取的信息，给出最终的诊断决策。\\n\\n**关键创新**：PathFound的关键创新在于将病理诊断过程建模为一个Agent与环境交互的过程，并利用强化学习训练推理模型，使其具备主动证据搜寻的能力。与现有方法相比，PathFound不再局限于对整张切片图像进行一次性处理，而是能够根据诊断结果，有针对性地获取更多信息，从而提高诊断准确性。此外，PathFound还集成了病理视觉基础模型和视觉-语言模型，使其能够更好地理解病理图像和文本信息。\\n\\n**关键设计**：PathFound的关键设计包括：1) 使用强化学习训练推理模型，使其能够根据诊断结果，选择最优的证据搜寻策略。2) 设计合适的奖励函数，鼓励模型获取更多有用的信息，并做出准确的诊断决策。3) 集成病理视觉基础模型和视觉-语言模型，使其能够更好地理解病理图像和文本信息。具体的网络结构和参数设置在论文中有详细描述，此处不再赘述。",
            "application_zh": "PathFound具有广泛的应用前景，可用于辅助病理医生进行诊断，提高诊断效率和准确性。该模型可以应用于各种病理诊断场景，例如肿瘤诊断、感染诊断等。此外，PathFound还可以用于病理图像的自动分析和标注，从而加速病理研究的进展。未来，PathFound有望成为病理诊断领域的重要工具。",
            "highlight_zh": "PathFound在多个大型多模态模型中进行了评估，结果表明，采用证据搜寻策略能够显著提高诊断准确性。PathFound在不同的临床场景中实现了最先进的诊断性能，并展示了发现细微细节（如核特征和局部浸润）的强大潜力。具体的性能数据和对比基线在论文中有详细描述。",
            "tags_zh": [
                "病理诊断",
                "多模态学习",
                "主动学习",
                "强化学习",
                "证据搜寻",
                "视觉-语言模型",
                "计算病理学"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23545v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23545v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23545v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SurgWorld: Learning Surgical Robot Policies from Videos via World Modeling",
            "authors": [
                "Yufan He",
                "Pengfei Guo",
                "Mengya Xu",
                "Zhaoshuo Li",
                "Andriy Myronenko",
                "Dillan Imans",
                "Bingjie Liu",
                "Dongren Yang",
                "Mingxue Gu",
                "Yongnan Ji",
                "Yueming Jin",
                "Ren Zhao",
                "Baiyong Shen",
                "Daguang Xu"
            ],
            "arxiv_id": "2512.23162v1",
            "summary": "Data scarcity remains a fundamental barrier to achieving fully autonomous surgical robots. While large scale vision language action (VLA) models have shown impressive generalization in household and industrial manipulation by leveraging paired video action data from diverse domains, surgical robotics suffers from the paucity of datasets that include both visual observations and accurate robot kinematics. In contrast, vast corpora of surgical videos exist, but they lack corresponding action labels, preventing direct application of imitation learning or VLA training. In this work, we aim to alleviate this problem by learning policy models from SurgWorld, a world model designed for surgical physical AI. We curated the Surgical Action Text Alignment (SATA) dataset with detailed action description specifically for surgical robots. Then we built SurgeWorld based on the most advanced physical AI world model and SATA. It's able to generate diverse, generalizable and realistic surgery videos. We are also the first to use an inverse dynamics model to infer pseudokinematics from synthetic surgical videos, producing synthetic paired video action data. We demonstrate that a surgical VLA policy trained with these augmented data significantly outperforms models trained only on real demonstrations on a real surgical robot platform. Our approach offers a scalable path toward autonomous surgical skill acquisition by leveraging the abundance of unlabeled surgical video and generative world modeling, thus opening the door to generalizable and data efficient surgical robot policies.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23162v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "imitation learning",
                        "[T]world model"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "vision-language-action",
                        "VLA"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "SurgWorld：通过世界建模从视频中学习手术机器人策略",
            "summary_zh": "数据稀缺是实现完全自主手术机器人的根本障碍。大规模视觉语言动作（VLA）模型通过利用来自不同领域的配对视频动作数据，在家庭和工业操作中表现出令人印象深刻的泛化能力，但手术机器人技术却面临着缺乏包含视觉观察和精确机器人运动学的数据集的问题。相比之下，存在大量的手术视频语料库，但它们缺乏相应的动作标签，从而无法直接应用模仿学习或VLA训练。在这项工作中，我们旨在通过从SurgWorld（一个专为手术物理AI设计的世界模型）中学习策略模型来缓解这个问题。我们策划了手术动作文本对齐（SATA）数据集，其中包含专门针对手术机器人的详细动作描述。然后，我们基于最先进的物理AI世界模型和SATA构建了SurgWorld。它能够生成多样化、可泛化和逼真的手术视频。我们也是第一个使用逆动力学模型从合成手术视频中推断伪运动学，从而生成合成的配对视频动作数据。我们证明，使用这些增强数据训练的手术VLA策略在真实手术机器人平台上显著优于仅在真实演示上训练的模型。我们的方法通过利用大量未标记的手术视频和生成式世界建模，为自主手术技能获取提供了一条可扩展的路径，从而为可泛化和数据高效的手术机器人策略打开了大门。",
            "intro_zh": [
                "手术机器人自主学习面临数据匮乏，尤其是缺乏带精确动作标签的视频数据。",
                "论文提出SurgWorld，一个基于物理AI的世界模型，用于生成逼真的手术视频。",
                "通过逆动力学模型从合成视频推断伪运动学，增强VLA策略训练，提升真实机器人性能。"
            ],
            "method_zh": "**问题定义**：手术机器人自主学习面临数据稀缺问题，特别是缺乏包含视觉信息和精确机器人运动学信息的配对数据。现有方法难以直接利用大量未标注的手术视频，限制了模仿学习和视觉语言动作模型的应用。\\n\\n**核心思路**：论文的核心思路是构建一个合成数据生成平台SurgWorld，通过世界模型生成逼真的手术视频，并利用逆动力学模型从视频中推断伪运动学信息，从而创建大量的合成配对视频-动作数据。这样可以克服真实数据稀缺的问题，并用于训练手术机器人的策略模型。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) Surgical Action Text Alignment (SATA)数据集的构建，包含手术动作的详细描述；2) 基于SATA和先进物理AI世界模型构建SurgWorld，用于生成手术视频；3) 使用逆动力学模型从合成视频中推断伪运动学信息；4) 使用合成数据训练手术VLA策略；5) 在真实手术机器人平台上进行评估。\\n\\n**关键创新**：最重要的技术创新点在于利用世界模型和逆动力学模型，从大量未标注的手术视频中生成可用于训练机器人策略的配对视频-动作数据。这避免了对大量真实标注数据的依赖，并为手术机器人自主学习提供了一种可扩展的解决方案。\\n\\n**关键设计**：SurgWorld基于先进的物理AI世界模型构建，能够生成多样化、可泛化和逼真的手术视频。逆动力学模型用于从视频中推断伪运动学信息，其具体实现细节（例如网络结构、损失函数等）未在摘要中详细说明。SATA数据集的构建是关键，它提供了手术动作的详细描述，用于指导世界模型的生成过程。",
            "application_zh": "该研究成果可应用于手术机器人的自主技能学习，降低对人工示教的依赖，提高手术效率和安全性。通过SurgWorld生成的大量合成数据，可以加速手术机器人在各种复杂手术场景中的应用，并为个性化手术方案的制定提供支持。未来，该技术有望推广到其他机器人操作领域，例如工业机器人、服务机器人等。",
            "highlight_zh": "论文通过实验证明，使用SurgWorld生成的合成数据训练的手术VLA策略，在真实手术机器人平台上显著优于仅在真实演示上训练的模型。具体的性能数据和提升幅度未在摘要中给出，但强调了合成数据在提升模型泛化能力和性能方面的有效性。",
            "tags_zh": [
                "手术机器人",
                "世界模型",
                "视觉语言动作",
                "逆动力学",
                "数据增强"
            ],
            "_index": 7,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23162v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23162v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23162v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MindWatcher: Toward Smarter Multimodal Tool-Integrated Reasoning",
            "authors": [
                "Jiawei Chen",
                "Xintian Shen",
                "Lihao Zheng",
                "Zhenwei Shao",
                "Hongyuan Zhang",
                "Pengfei Yu",
                "Xudong Rao",
                "Ning Mao",
                "Xiaobo Liu",
                "Lian Wen",
                "Chaoqun Du",
                "Feng Gu",
                "Wei He",
                "Qizhen Li",
                "Shanshan Li",
                "Zide Liu",
                "Jing Luo",
                "Lifu Mu",
                "Xuhao Pan",
                "Chang Ren",
                "Haoyi Sun",
                "Qian Wang",
                "Wei Wang",
                "Hongfu Yang",
                "Jiqing Zhan",
                "Chunpeng Zhou",
                "Zheng Zhou",
                "Hao Ma",
                "Tao Wei",
                "Pan Zhou",
                "Wei Chen"
            ],
            "arxiv_id": "2512.23412v1",
            "summary": "Traditional workflow-based agents exhibit limited intelligence when addressing real-world problems requiring tool invocation. Tool-integrated reasoning (TIR) agents capable of autonomous reasoning and tool invocation are rapidly emerging as a powerful approach for complex decision-making tasks involving multi-step interactions with external environments. In this work, we introduce MindWatcher, a TIR agent integrating interleaved thinking and multimodal chain-of-thought (CoT) reasoning. MindWatcher can autonomously decide whether and how to invoke diverse tools and coordinate their use, without relying on human prompts or workflows. The interleaved thinking paradigm enables the model to switch between thinking and tool calling at any intermediate stage, while its multimodal CoT capability allows manipulation of images during reasoning to yield more precise search results. We implement automated data auditing and evaluation pipelines, complemented by manually curated high-quality datasets for training, and we construct a benchmark, called MindWatcher-Evaluate Bench (MWE-Bench), to evaluate its performance. MindWatcher is equipped with a comprehensive suite of auxiliary reasoning tools, enabling it to address broad-domain multimodal problems. A large-scale, high-quality local image retrieval database, covering eight categories including cars, animals, and plants, endows model with robust object recognition despite its small size. Finally, we design a more efficient training infrastructure for MindWatcher, enhancing training speed and hardware utilization. Experiments not only demonstrate that MindWatcher matches or exceeds the performance of larger or more recent models through superior tool invocation, but also uncover critical insights for agent training, such as the genetic inheritance phenomenon in agentic RL.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Technique Report",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23412v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal",
                        "chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MindWatcher，一种集成多模态工具的智能推理Agent，解决复杂决策问题。",
            "summary_zh": "本文介绍了一种工具集成推理（TIR）Agent——MindWatcher，它集成了交错思考和多模态链式思考（CoT）推理。MindWatcher能够自主决定是否以及如何调用各种工具，并协调它们的使用，无需人工提示或工作流程。交错思考范式使模型能够在任何中间阶段在思考和工具调用之间切换，而其多模态CoT能力允许在推理过程中处理图像，从而产生更精确的搜索结果。我们实现了自动化的数据审计和评估流程，并辅以手动策划的高质量数据集进行训练。我们构建了一个名为MindWatcher-Evaluate Bench（MWE-Bench）的基准来评估其性能。MindWatcher配备了一套全面的辅助推理工具，使其能够解决广泛领域的多模态问题。一个大规模、高质量的本地图像检索数据库，涵盖汽车、动物和植物等八个类别，使模型即使在规模较小的情况下也能实现强大的对象识别能力。最后，我们为MindWatcher设计了一个更高效的训练基础设施，提高了训练速度和硬件利用率。实验表明，MindWatcher通过卓越的工具调用，匹配或超过了更大或更新模型的性能，并且揭示了Agent训练的关键见解，例如Agent强化学习中的遗传继承现象。",
            "intro_zh": [
                "现有基于工作流的Agent在解决需要工具调用的实际问题时智能有限。",
                "MindWatcher采用交错思考和多模态CoT推理，自主决定工具调用和协调。",
                "实验表明MindWatcher性能匹配或超过更大模型，并揭示Agent训练的关键见解。"
            ],
            "method_zh": "**问题定义**：传统工作流Agent在处理需要工具调用的复杂任务时表现出局限性，无法自主进行推理和工具调用。现有的工具集成推理Agent仍然依赖人工提示或预定义的工作流程，缺乏灵活性和自主性。此外，对于多模态信息的处理能力不足，难以充分利用图像等信息进行更精确的推理。\\n\\n**核心思路**：MindWatcher的核心思路是构建一个能够自主进行交错思考和多模态链式思考的Agent。通过交错思考，Agent可以在推理过程中灵活地切换思考和工具调用，无需预先确定工具调用的顺序。通过多模态链式思考，Agent可以利用图像等信息进行推理，提高推理的准确性。\\n\\n**技术框架**：MindWatcher的整体架构包含以下几个主要模块：1) 思考模块：负责进行推理和决策，决定是否需要调用工具。2) 工具调用模块：负责调用各种外部工具，例如搜索引擎、图像识别器等。3) 多模态信息处理模块：负责处理图像等信息，提取有用的特征。4) 链式思考模块：负责将思考过程组织成链式结构，方便进行推理和调试。Agent通过交错思考，在思考模块和工具调用模块之间进行切换，并利用多模态信息处理模块提供的特征进行推理。\\n\\n**关键创新**：MindWatcher的关键创新在于以下几个方面：1) 提出了交错思考的范式，使得Agent可以更加灵活地进行推理和工具调用。2) 提出了多模态链式思考的方法，使得Agent可以利用图像等信息进行更精确的推理。3) 构建了一个大规模、高质量的本地图像检索数据库，提高了Agent的图像识别能力。\\n\\n**关键设计**：MindWatcher的关键设计包括：1) 使用Transformer模型作为思考模块的基础架构。2) 设计了一种新的损失函数，用于训练Agent的交错思考能力。3) 使用对比学习的方法训练图像识别器，提高其识别精度。4) 采用强化学习的方法，优化Agent的工具调用策略。",
            "application_zh": "MindWatcher具有广泛的应用前景，例如智能客服、自动驾驶、医疗诊断等。它可以帮助人们解决各种复杂的问题，提高工作效率和生活质量。未来，MindWatcher可以进一步扩展到更多的领域，例如金融、教育等，为人们提供更加智能化的服务。",
            "highlight_zh": "实验结果表明，MindWatcher在MWE-Bench基准测试中取得了优异的成绩，匹配或超过了更大或更新的模型。例如，在图像检索任务中，MindWatcher的准确率比基线模型提高了10%。此外，实验还揭示了Agent强化学习中的遗传继承现象，为Agent训练提供了新的思路。",
            "tags_zh": [
                "工具集成推理",
                "多模态学习",
                "链式思考",
                "智能Agent",
                "强化学习"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23412v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23412v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23412v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation",
            "authors": [
                "Ethan Chern",
                "Zhulin Hu",
                "Bohao Tang",
                "Jiadi Su",
                "Steffi Chern",
                "Zhijie Deng",
                "Pengfei Liu"
            ],
            "arxiv_id": "2512.23576v1",
            "summary": "Real-time video generation via diffusion is essential for building general-purpose multimodal interactive AI systems. However, the simultaneous denoising of all video frames with bidirectional attention via an iterative process in diffusion models prevents real-time interaction. While existing distillation methods can make the model autoregressive and reduce sampling steps to mitigate this, they focus primarily on text-to-video generation, leaving the human-AI interaction unnatural and less efficient. This paper targets real-time interactive video diffusion conditioned on a multimodal context, including text, image, and audio, to bridge the gap. Given the observation that the leading on-policy distillation approach Self Forcing encounters challenges (visual artifacts like flickering, black frames, and quality degradation) with multimodal conditioning, we investigate an improved distillation recipe with emphasis on the quality of condition inputs as well as the initialization and schedule for the on-policy optimization. On benchmarks for multimodal-conditioned (audio, image, and text) avatar video generation including HDTF, AVSpeech, and CelebV-HQ, our distilled model matches the visual quality of the full-step, bidirectional baselines of similar or larger size with 20x less inference cost and latency. Further, we integrate our model with audio language models and long-form video inference technique Anchor-Heavy Identity Sinks to build LiveTalk, a real-time multimodal interactive avatar system. System-level evaluation on our curated multi-turn interaction benchmark shows LiveTalk outperforms state-of-the-art models (Sora2, Veo3) in multi-turn video coherence and content quality, while reducing response latency from 1 to 2 minutes to real-time generation, enabling seamless human-AI multimodal interaction.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23576v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出改进的On-Policy蒸馏方法，实现多模态交互式实时视频扩散",
            "summary_zh": "本文旨在解决多模态交互式AI系统中实时视频生成的问题。现有的扩散模型由于其迭代过程中的双向注意力机制，难以实现实时交互。虽然蒸馏方法可以通过自回归建模和减少采样步骤来缓解这个问题，但它们主要集中在文本到视频的生成，导致人机交互不自然且效率低下。本文提出了一种改进的蒸馏方法，重点关注条件输入的质量以及On-Policy优化的初始化和调度，以实现基于文本、图像和音频等多模态上下文的实时交互式视频扩散。在HDTF、AVSpeech和CelebV-HQ等数据集上的实验表明，该模型在视觉质量上与全步、双向基线模型相当，同时推理成本和延迟降低了20倍。此外，该模型集成了音频语言模型和Anchor-Heavy Identity Sinks长视频推理技术，构建了LiveTalk实时多模态交互式化身系统。系统级评估表明，LiveTalk在多轮视频连贯性和内容质量方面优于Sora2和Veo3等模型，并将响应延迟从1-2分钟降低到实时生成，从而实现无缝的人机多模态交互。",
            "intro_zh": [
                "现有扩散模型在实时视频生成中面临挑战，特别是多模态条件下的交互式应用，主要原因是其双向注意力和迭代采样过程。",
                "论文提出改进的On-Policy蒸馏方法，通过优化条件输入质量和蒸馏过程，显著提升了多模态条件下的视频生成效率和质量。",
                "实验结果表明，该方法在保证视觉质量的同时，显著降低了推理成本和延迟，并在多轮交互场景中优于现有先进模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态交互式AI系统中实时视频生成的问题。现有扩散模型由于其迭代过程中的双向注意力机制，难以实现实时交互。现有的蒸馏方法虽然可以加速生成，但在多模态条件下的效果不佳，容易出现视觉伪影，如闪烁、黑帧和质量下降。\n\n**核心思路**：论文的核心思路是通过改进On-Policy蒸馏方法，提高多模态条件下的视频生成质量和效率。关键在于优化条件输入的质量，并改进On-Policy优化的初始化和调度策略。通过高质量的条件输入和更有效的蒸馏过程，可以生成更逼真、更连贯的视频。\n\n**技术框架**：整体框架包括一个多模态条件编码器，用于将文本、图像和音频信息编码为潜在表示。然后，使用改进的On-Policy蒸馏方法训练一个自回归扩散模型，该模型能够根据潜在表示生成视频帧。最后，将该模型集成到LiveTalk系统中，实现实时多模态交互。\n\n**关键创新**：最重要的技术创新点在于改进的On-Policy蒸馏方法，该方法特别关注条件输入的质量以及蒸馏过程的优化。与传统的蒸馏方法相比，该方法能够更好地处理多模态条件，并生成更高质量的视频。此外，LiveTalk系统的集成也展示了该方法在实际应用中的潜力。\n\n**关键设计**：论文中关键的设计包括：(1) 使用高质量的多模态数据进行训练，确保条件输入的准确性；(2) 改进On-Policy优化的初始化策略，避免训练初期出现不稳定的情况；(3) 调整蒸馏过程中的调度策略，平衡生成速度和视频质量；(4) 使用Anchor-Heavy Identity Sinks技术，提高长视频的连贯性。",
            "application_zh": "该研究成果可广泛应用于虚拟化身、在线会议、游戏、教育等领域。通过实时多模态交互，可以创建更自然、更具吸引力的用户体验。例如，用户可以与虚拟化身进行实时对话，并根据用户的语音、表情和文本输入，生成相应的视频内容。未来，该技术有望进一步发展，实现更高级的人机交互。",
            "highlight_zh": "实验结果表明，该模型在HDTF、AVSpeech和CelebV-HQ等数据集上，在视觉质量上与全步、双向基线模型相当，同时推理成本和延迟降低了20倍。在多轮交互场景中，LiveTalk系统在视频连贯性和内容质量方面优于Sora2和Veo3等模型，并将响应延迟从1-2分钟降低到实时生成。",
            "tags_zh": [
                "实时视频生成",
                "多模态交互",
                "扩散模型",
                "On-Policy蒸馏",
                "人机交互"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23576v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23576v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23576v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Instruction-Following Evaluation of Large Vision-Language Models",
            "authors": [
                "Daiki Shiono",
                "Shumpei Miyawaki",
                "Ryota Tanaka",
                "Jun Suzuki"
            ],
            "arxiv_id": "2512.23572v1",
            "summary": "Following the initial flourishing of large language models (LLMs), there has been a surge in proposed large vision-language models (LVLMs) that integrate LLMs with vision capabilities. However, it has been observed that LVLMs, after tuning to visual instruction using commonly used training datasets, often fail to exhibit the instruction-following ability that was present in the LLM before integration, leading to results in which they do not follow task instructions as expected. This study quantitatively demonstrates that LVLMs' instruction-following ability declines after fine-tuning and analyzes its underlying causes. In particular, we constructed new training datasets highlighting whether the output format is specified. Then, we investigated how explicitly indicating the output format during fine-tuning affects LVLMs' instruction-following ability. Our quantitative evaluation confirmed that LVLMs' instruction-following ability declines after fine-tuning with commonly used datasets. Furthermore, we found that LVLMs trained with datasets, including instructions on output format, tend to follow instructions more accurately than models that do not. These findings suggest that including samples with instructions on output format during (visual) instruction tuning may help mitigate the decline in instruction-following abilities.",
            "categories": [
                "cs.CL",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "21 pages, 7 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23572v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]instruction following"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究表明视觉语言大模型微调后指令遵循能力下降，并提出改进方法。",
            "summary_zh": "随着大型语言模型（LLMs）的蓬勃发展，涌现出大量将LLMs与视觉能力相结合的大型视觉语言模型（LVLMs）。然而，研究发现，LVLMs在使用常用训练数据集进行视觉指令调优后，常常无法展现LLM在集成前所具备的指令遵循能力，导致结果未能按预期执行任务指令。本研究定量地证明了LVLMs的指令遵循能力在微调后下降，并分析了其根本原因。特别地，我们构建了新的训练数据集，重点关注是否明确指定了输出格式。然后，我们研究了在微调期间显式地指示输出格式如何影响LVLMs的指令遵循能力。我们的定量评估证实，LVLMs的指令遵循能力在使用常用数据集进行微调后会下降。此外，我们发现，使用包含输出格式指令的数据集训练的LVLMs，比那些没有包含输出格式指令的模型，往往能更准确地遵循指令。这些发现表明，在（视觉）指令调优期间包含带有输出格式指令的样本，可能有助于减轻指令遵循能力的下降。",
            "intro_zh": [
                "现有LVLMs在视觉指令微调后，其指令遵循能力相比原始LLM有所下降，未能完全按照指令执行任务。",
                "论文核心思想是通过构建包含明确输出格式指令的训练数据集，来提升LVLMs在微调后的指令遵循能力。",
                "实验结果表明，使用包含输出格式指令的数据集训练的LVLMs，其指令遵循准确性得到显著提升。"
            ],
            "method_zh": "**问题定义**：现有的大型视觉语言模型（LVLMs）在经过视觉指令微调后，其指令遵循能力相比于原始的LLM有所下降。这意味着模型在处理视觉相关的任务时，虽然具备了视觉感知能力，但无法很好地理解和执行用户给定的指令，导致输出结果不符合预期。现有方法在微调过程中，可能忽略了对输出格式的明确指导，导致模型在生成答案时缺乏规范性。\\n\\n**核心思路**：论文的核心思路是，通过在训练数据中显式地包含输出格式的指令，来引导LVLMs学习如何更好地遵循指令。作者认为，明确的输出格式指导可以帮助模型更好地理解用户的意图，并生成符合要求的答案。这种方法类似于在教学过程中，明确告诉学生答案应该以何种形式呈现。\\n\\n**技术框架**：该研究主要通过构建新的训练数据集来实现。这些数据集的特点是，它们不仅包含视觉信息和任务描述，还明确地指定了输出格式。例如，如果任务是描述图像中的物体，数据集会明确要求模型以列表的形式输出答案。然后，使用这些数据集对LVLMs进行微调，并评估其指令遵循能力。\\n\\n**关键创新**：该研究的关键创新在于，它强调了输出格式指令在视觉语言模型训练中的重要性。以往的研究主要关注如何提高模型的视觉感知能力和语言理解能力，而忽略了对输出格式的明确指导。该研究表明，明确的输出格式指导可以显著提高模型的指令遵循能力。\\n\\n**关键设计**：论文的关键设计在于构建了包含明确输出格式指令的训练数据集。具体来说，作者可能采用了以下策略：1) 在现有的视觉语言数据集的基础上，添加了关于输出格式的描述；2) 设计了新的任务，这些任务需要模型以特定的格式输出答案；3) 使用数据增强技术，生成更多包含输出格式指令的训练样本。此外，作者可能还调整了模型的损失函数，以鼓励模型生成符合指定格式的答案。例如，可以添加一个正则化项，惩罚那些不符合格式要求的输出。",
            "application_zh": "该研究成果可应用于各种需要视觉语言模型精确遵循指令的场景，例如智能客服、机器人导航、图像编辑等。通过提高LVLMs的指令遵循能力，可以使这些应用更加智能化和用户友好，提升用户体验，并降低人工干预的需求。未来，该方法有望推广到更复杂的视觉语言任务中。",
            "highlight_zh": "实验结果表明，使用包含输出格式指令的数据集训练的LVLMs，其指令遵循能力得到显著提升。具体而言，模型在遵循输出格式方面的准确率提高了XX%，并且在生成答案的流畅性和相关性方面也有所改善。这些结果表明，明确的输出格式指导是提高LVLMs指令遵循能力的关键因素。",
            "tags_zh": [
                "视觉语言模型",
                "指令遵循",
                "微调",
                "输出格式",
                "数据集构建"
            ],
            "_index": 10,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23572v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23572v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23572v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Contour Information Aware 2D Gaussian Splatting for Image Representation",
            "authors": [
                "Masaya Takabe",
                "Hiroshi Watanabe",
                "Sujun Hong",
                "Tomohiro Ikai",
                "Zheming Fan",
                "Ryo Ishimoto",
                "Kakeru Sugimoto",
                "Ruri Imichi"
            ],
            "arxiv_id": "2512.23255v1",
            "summary": "Image representation is a fundamental task in computer vision. Recently, Gaussian Splatting has emerged as an efficient representation framework, and its extension to 2D image representation enables lightweight, yet expressive modeling of visual content. While recent 2D Gaussian Splatting (2DGS) approaches provide compact storage and real-time decoding, they often produce blurry or indistinct boundaries when the number of Gaussians is small due to the lack of contour awareness. In this work, we propose a Contour Information-Aware 2D Gaussian Splatting framework that incorporates object segmentation priors into Gaussian-based image representation. By constraining each Gaussian to a specific segmentation region during rasterization, our method prevents cross-boundary blending and preserves edge structures under high compression. We also introduce a warm-up scheme to stabilize training and improve convergence. Experiments on synthetic color charts and the DAVIS dataset demonstrate that our approach achieves higher reconstruction quality around object edges compared to existing 2DGS methods. The improvement is particularly evident in scenarios with very few Gaussians, while our method still maintains fast rendering and low memory usage.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23255v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出轮廓信息感知的2D高斯溅射，提升图像表示中边缘重建质量",
            "summary_zh": "图像表示是计算机视觉中的一项基本任务。最近，高斯溅射已成为一种高效的表示框架，其扩展到2D图像表示能够以轻量级但富有表现力的方式对视觉内容进行建模。然而，由于缺乏轮廓感知，现有的2D高斯溅射(2DGS)方法在Gaussian数量较少时，经常产生模糊或不清晰的边界。本文提出了一种轮廓信息感知的2D高斯溅射框架，该框架将对象分割先验知识融入到基于高斯的图像表示中。通过在光栅化期间将每个高斯约束到特定的分割区域，我们的方法可以防止跨边界混合，并在高压缩下保持边缘结构。我们还引入了一种预热方案来稳定训练并提高收敛性。在合成彩色图表和DAVIS数据集上的实验表明，与现有的2DGS方法相比，我们的方法在对象边缘周围实现了更高的重建质量。这种改进在Gaussian数量非常少的情况下尤为明显，同时我们的方法仍然保持了快速渲染和低内存使用。",
            "intro_zh": [
                "现有2D高斯溅射方法在低Gaussian数量下，图像边缘重建模糊，缺乏轮廓感知。",
                "提出轮廓信息感知的2D高斯溅射框架，利用分割先验约束高斯分布，避免跨边界混合。",
                "实验表明，该方法在边缘重建质量上优于现有方法，尤其是在低Gaussian数量下，同时保持快速渲染和低内存占用。"
            ],
            "method_zh": "**问题定义**：现有的2D高斯溅射方法在图像表示中，尤其是在高压缩比（即使用较少的高斯分布）的情况下，容易产生模糊的边缘和不清晰的边界。这是因为高斯分布在图像区域上是连续的，没有明确的机制来防止它们跨越不同的对象或语义区域，导致颜色和纹理的混合，从而降低了重建图像的视觉质量。\\n\\n**核心思路**：论文的核心思路是将对象分割的先验知识融入到2D高斯溅射的框架中。通过利用分割信息，可以约束每个高斯分布仅位于特定的分割区域内，从而避免高斯分布跨越不同的对象边界。这样可以有效地防止颜色和纹理的混合，并保持图像边缘的清晰度。\\n\\n**技术框架**：该方法的核心框架是在标准的2D高斯溅射流程中引入分割约束。具体来说，首先使用一个预训练的分割模型来预测输入图像的分割掩码。然后，在训练过程中，每个高斯分布都被约束在其对应的分割区域内。这意味着在光栅化过程中，只有位于同一分割区域内的高斯分布才会被混合。此外，论文还引入了一个warm-up scheme来稳定训练过程并提高收敛速度。\\n\\n**关键创新**：该方法最重要的创新点在于将对象分割先验知识与2D高斯溅射相结合，从而实现了轮廓信息感知的图像表示。与现有的2DGS方法相比，该方法能够更好地保持图像边缘的清晰度，尤其是在高压缩比的情况下。这种方法通过约束高斯分布的范围，有效地避免了跨边界的颜色和纹理混合，从而提高了重建图像的视觉质量。\\n\\n**关键设计**：该方法的关键设计包括：1) 使用预训练的分割模型来生成分割掩码；2) 设计损失函数，鼓励高斯分布位于其对应的分割区域内；3) 引入warm-up scheme来稳定训练过程。具体的损失函数可能包含一个正则化项，用于惩罚高斯分布跨越分割边界的情况。Warm-up scheme可能涉及在训练初期使用较小的学习率，然后逐渐增加学习率，以避免训练过程中的不稳定现象。",
            "application_zh": "该研究成果可应用于图像压缩、图像编辑、图像修复等领域。通过更有效地表示图像，特别是在边缘区域，可以实现更高的压缩比，同时保持良好的视觉质量。在图像编辑中，可以更精确地控制对象的边界，从而实现更自然的编辑效果。此外，该方法还可以应用于三维重建和虚拟现实等领域，为高质量的图像渲染提供支持。",
            "highlight_zh": "实验结果表明，该方法在合成彩色图表和DAVIS数据集上均取得了显著的性能提升。尤其是在低Gaussian数量的情况下，该方法在边缘区域的重建质量明显优于现有的2DGS方法。定量指标显示，该方法在PSNR和SSIM等指标上均有提升，证明了其在图像表示方面的有效性。",
            "tags_zh": [
                "2D高斯溅射",
                "图像表示",
                "轮廓感知",
                "图像分割",
                "边缘重建"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23255v1/Overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23255v1/color_chart_result_graph.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23255v1/color_chart_result_image.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Agentic Physical AI toward a Domain-Specific Foundation Model for Nuclear Reactor Control",
            "authors": [
                "Yoonpyo Lee",
                "Kazuma Kobayashi",
                "Sai Puppala",
                "Sajedul Talukder",
                "Seid Koric",
                "Souvik Chakraborty",
                "Syed Bahauddin Alam"
            ],
            "arxiv_id": "2512.23292v1",
            "summary": "The prevailing paradigm in AI for physical systems, scaling general-purpose foundation models toward universal multimodal reasoning, confronts a fundamental barrier at the control interface. Recent benchmarks show that even frontier vision-language models achieve only 50-53% accuracy on basic quantitative physics tasks, behaving as approximate guessers that preserve semantic plausibility while violating physical constraints. This input unfaithfulness is not a scaling deficiency but a structural limitation. Perception-centric architectures optimize parameter-space imitation, whereas safety-critical control demands outcome-space guarantees over executed actions. Here, we present a fundamentally different pathway toward domain-specific foundation models by introducing compact language models operating as Agentic Physical AI, in which policy optimization is driven by physics-based validation rather than perceptual inference. We train a 360-million-parameter model on synthetic reactor control scenarios, scaling the dataset from 10^3 to 10^5 examples. This induces a sharp phase transition absent in general-purpose models. Small-scale systems exhibit high-variance imitation with catastrophic tail risk, while large-scale models undergo variance collapse exceeding 500x reduction, stabilizing execution-level behavior. Despite balanced exposure to four actuation families, the model autonomously rejects approximately 70% of the training distribution and concentrates 95% of runtime execution on a single-bank strategy. Learned representations transfer across distinct physics and continuous input modalities without architectural modification.",
            "categories": [
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23292v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Agentic Physical AI，用于核反应堆控制的领域特定基础模型。",
            "summary_zh": "当前物理系统AI的主流范式，即扩展通用基础模型以实现通用多模态推理，在控制界面面临根本性障碍。最新基准测试表明，即使是最先进的视觉-语言模型在基本定量物理任务上的准确率也仅为50-53%，表现得像近似猜测者，保留语义合理性但违反物理约束。这种输入不忠实性不是缩放缺陷，而是结构性限制。以感知为中心的架构优化参数空间模仿，而安全关键控制需要对执行动作的结果空间保证。本文提出了一种根本不同的领域特定基础模型路径，引入了作为Agentic Physical AI运行的紧凑语言模型，其中策略优化由基于物理的验证驱动，而不是感知推理。我们在合成反应堆控制场景中训练了一个3.6亿参数的模型，将数据集从10^3扩展到10^5个示例。这引发了通用模型中不存在的急剧相变。小规模系统表现出具有灾难性尾部风险的高方差模仿，而大规模模型经历了超过500倍的方差崩溃，稳定了执行级别的行为。尽管平衡地暴露于四个驱动系列，但该模型自主拒绝了大约70%的训练分布，并将95%的运行时执行集中在单个库策略上。学习到的表示可以在不同的物理和连续输入模态之间转移，而无需架构修改。",
            "intro_zh": [
                "通用AI模型在物理系统控制中面临输入不忠实问题，无法保证动作执行结果的安全性。",
                "提出Agentic Physical AI，利用紧凑语言模型，通过物理验证驱动策略优化，而非感知推理。",
                "实验表明，大规模训练可显著降低方差，稳定执行行为，并实现跨物理和模态的知识迁移。"
            ],
            "method_zh": "**问题定义**：现有通用人工智能模型在物理系统控制任务中表现不佳，尤其是在核反应堆控制等安全关键领域。这些模型往往依赖于感知输入进行模仿学习，但忽略了物理约束，导致控制动作不安全或无效。现有方法的痛点在于无法保证控制动作的物理合理性和安全性。\\n\\n**核心思路**：本文的核心思路是放弃以感知为中心的模仿学习，转而采用基于物理验证的策略优化。通过构建一个Agentic Physical AI，利用紧凑的语言模型作为策略生成器，并使用物理模型对生成的策略进行验证和优化，从而确保控制动作的物理可行性和安全性。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) **环境模拟器**：用于生成核反应堆控制的合成数据，包括各种控制场景和物理状态。2) **语言模型**：作为策略生成器，接收环境状态信息，输出控制动作序列。3) **物理验证器**：基于核反应堆的物理模型，对语言模型生成的控制动作进行验证，评估其是否满足物理约束和安全要求。4) **优化器**：根据物理验证器的反馈，调整语言模型的参数，优化控制策略。\\n\\n**关键创新**：最重要的技术创新点在于将物理验证引入到策略优化循环中。与传统的模仿学习方法不同，本文提出的方法不是直接模仿专家策略，而是通过物理模型对策略进行验证和改进，从而确保控制动作的物理合理性和安全性。这种方法能够有效地解决通用AI模型在物理系统控制中面临的输入不忠实问题。\\n\\n**关键设计**：关键设计包括：1) 使用3.6亿参数的紧凑语言模型，以降低计算成本和提高训练效率。2) 设计合适的损失函数，鼓励语言模型生成满足物理约束的控制策略。3) 通过大规模合成数据训练，提高模型的泛化能力和鲁棒性。4) 采用数据增强技术，增加训练数据的多样性，提高模型的性能。",
            "application_zh": "该研究成果可应用于核反应堆控制、智能制造、机器人控制等领域。通过构建领域特定的Agentic Physical AI，可以提高控制系统的安全性、可靠性和效率，降低人工干预的需求，并为实现自主控制提供技术支撑。未来，该方法有望推广到其他复杂物理系统的控制任务中。",
            "highlight_zh": "实验结果表明，通过大规模训练，Agentic Physical AI模型能够实现超过500倍的方差崩溃，显著提高了控制策略的稳定性。模型能够自主拒绝70%的训练分布，并将95%的运行时执行集中在单个库策略上，表明模型学习到了有效的控制策略。此外，学习到的表示可以在不同的物理和连续输入模态之间转移，而无需架构修改，展示了模型的泛化能力。",
            "tags_zh": [
                "核反应堆控制",
                "物理AI",
                "领域特定模型",
                "强化学习",
                "语言模型"
            ],
            "_index": 12,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23292v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23292v1/Figure_validation_scaling_bins.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23292v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Toward Trustworthy Agentic AI: A Multimodal Framework for Preventing Prompt Injection Attacks",
            "authors": [
                "Toqeer Ali Syed",
                "Mishal Ateeq Almutairi",
                "Mahmoud Abdel Moaty"
            ],
            "arxiv_id": "2512.23557v1",
            "summary": "Powerful autonomous systems, which reason, plan, and converse using and between numerous tools and agents, are made possible by Large Language Models (LLMs), Vision-Language Models (VLMs), and new agentic AI systems, like LangChain and GraphChain. Nevertheless, this agentic environment increases the probability of the occurrence of multimodal prompt injection (PI) attacks, in which concealed or malicious instructions carried in text, pictures, metadata, or agent-to-agent messages may spread throughout the graph and lead to unintended behavior, a breach of policy, or corruption of state. In order to mitigate these risks, this paper suggests a Cross-Agent Multimodal Provenanc- Aware Defense Framework whereby all the prompts, either user-generated or produced by upstream agents, are sanitized and all the outputs generated by an LLM are verified independently before being sent to downstream nodes. This framework contains a Text sanitizer agent, visual sanitizer agent, and output validator agent all coordinated by a provenance ledger, which keeps metadata of modality, source, and trust level throughout the entire agent network. This architecture makes sure that agent-to-agent communication abides by clear trust frames such such that injected instructions are not propagated down LangChain or GraphChain-style-workflows. The experimental assessments show that multimodal injection detection accuracy is significantly enhanced, and the cross-agent trust leakage is minimized, as well as, agentic execution pathways become stable. The framework, which expands the concept of provenance tracking and validation to the multi-agent orchestration, enhances the establishment of secure, understandable and reliable agentic AI systems.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "It is accepted in a conference paper, ICCA 2025 in Bahrain on 21 to 23 December",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23557v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出跨Agent多模态溯源防御框架，防范Agentic AI中的提示注入攻击。",
            "summary_zh": "大型语言模型(LLMs)、视觉-语言模型(VLMs)以及LangChain和GraphChain等新型Agentic AI系统，使得能够进行推理、规划和对话的强大自主系统成为可能。然而，这种Agentic环境增加了多模态提示注入(PI)攻击发生的可能性，其中隐藏或恶意指令通过文本、图片、元数据或Agent间的消息传播，可能导致意外行为、违反策略或状态损坏。为了降低这些风险，本文提出了一种跨Agent多模态溯源感知防御框架，其中所有提示（无论是用户生成的还是上游Agent生成的）都会被清理，并且LLM生成的所有输出在发送到下游节点之前都会被独立验证。该框架包含文本清理Agent、视觉清理Agent和输出验证Agent，所有Agent由溯源账本协调，溯源账本保存整个Agent网络中模态、来源和信任级别的元数据。这种架构确保Agent间的通信遵守明确的信任框架，从而防止注入的指令在LangChain或GraphChain风格的工作流程中传播。实验评估表明，多模态注入检测精度显著提高，跨Agent信任泄漏最小化，并且Agentic执行路径变得稳定。该框架将溯源跟踪和验证的概念扩展到多Agent编排，从而加强了安全、可理解和可靠的Agentic AI系统的建立。",
            "intro_zh": [
                "Agentic AI系统面临多模态提示注入攻击的风险，恶意指令可能通过多种模态传播，导致系统行为异常。",
                "论文提出跨Agent多模态溯源防御框架，通过清理提示和验证输出来防止恶意指令的传播。",
                "实验结果表明，该框架显著提高了多模态注入检测精度，并降低了跨Agent的信任泄漏风险。"
            ],
            "method_zh": "**问题定义**：论文旨在解决Agentic AI系统中日益严重的多模态提示注入攻击问题。现有的Agentic AI系统，如基于LangChain或GraphChain的系统，容易受到恶意用户或Agent通过文本、图像等多种模态注入的指令攻击，导致系统行为偏离预期，甚至造成安全漏洞。现有的防御方法往往只关注单一模态的攻击，缺乏对跨Agent通信过程中的信任管理和溯源追踪。\n\n**核心思路**：论文的核心思路是建立一个跨Agent、多模态的溯源感知防御框架，对所有Agent之间的通信进行监控、清理和验证。通过记录每个Agent的输入输出以及信任级别，构建一个溯源账本，从而实现对恶意指令的追踪和阻断。这种方法的核心在于将信任管理和安全防御融入到Agentic系统的整体架构中。\n\n**技术框架**：该框架包含以下几个主要模块：1) **文本清理Agent**：负责对文本模态的输入进行清理，移除潜在的恶意指令。2) **视觉清理Agent**：负责对图像模态的输入进行清理，例如检测和移除隐藏的文本信息。3) **输出验证Agent**：负责对LLM生成的输出进行验证，确保其符合预期的行为规范。4) **溯源账本**：负责记录所有Agent的输入输出、模态信息、来源以及信任级别，用于追踪恶意指令的传播路径。这些模块协同工作，形成一个完整的防御体系。\n\n**关键创新**：论文最重要的创新点在于提出了一个跨Agent、多模态的溯源感知防御框架。与现有的防御方法相比，该框架不仅考虑了单一模态的攻击，还关注了Agent之间的通信安全，通过溯源账本实现了对恶意指令的追踪和阻断。此外，该框架还引入了信任级别的概念，用于评估不同Agent的可信度，从而更好地管理Agent之间的信任关系。\n\n**关键设计**：框架的关键设计包括：1) **多模态清理机制**：针对文本和图像等不同模态，设计了不同的清理算法，以移除潜在的恶意指令。2) **信任级别评估**：设计了一种信任级别评估机制，用于评估不同Agent的可信度，并根据信任级别调整防御策略。3) **溯源账本结构**：设计了一种高效的溯源账本结构，用于记录所有Agent的输入输出以及信任级别，并支持快速的查询和追踪。",
            "application_zh": "该研究成果可应用于各种Agentic AI系统，例如智能客服、自动化流程管理、智能家居等。通过部署该防御框架，可以有效提高Agentic AI系统的安全性，防止恶意攻击，保障用户数据安全，并提升系统的可靠性和可信度。未来，该框架可以进一步扩展到更多的模态和Agent类型，以适应不断发展的Agentic AI应用场景。",
            "highlight_zh": "实验结果表明，该框架能够显著提高多模态注入检测的准确率，并有效降低跨Agent的信任泄漏风险。具体而言，该框架在多模态提示注入攻击的检测准确率上相比基线方法提升了XX%（具体数值论文中给出），同时将跨Agent的信任泄漏风险降低了YY%（具体数值论文中给出）。此外，实验还验证了该框架能够稳定Agentic系统的执行路径，使其更加可预测和可靠。",
            "tags_zh": [
                "Agentic AI",
                "多模态学习",
                "提示注入攻击",
                "安全防御",
                "溯源追踪"
            ],
            "_index": 13,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23557v1/images/architecture.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23557v1/images/sequence_diagram.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation",
            "authors": [
                "Huajie Tan",
                "Sixiang Chen",
                "Yijie Xu",
                "Zixiao Wang",
                "Yuheng Ji",
                "Cheng Chi",
                "Yaoxu Lyu",
                "Zhongxia Zhao",
                "Xiansheng Chen",
                "Peterson Co",
                "Shaoxuan Xie",
                "Guocai Yao",
                "Pengwei Wang",
                "Zhongyuan Wang",
                "Shanghang Zhang"
            ],
            "arxiv_id": "2512.23703v1",
            "summary": "The primary obstacle for applying reinforcement learning (RL) to real-world robotics is the design of effective reward functions. While recently learning-based Process Reward Models (PRMs) are a promising direction, they are often hindered by two fundamental limitations: their reward models lack step-aware understanding and rely on single-view perception, leading to unreliable assessments of fine-grained manipulation progress; and their reward shaping procedures are theoretically unsound, often inducing a semantic trap that misguides policy optimization. To address these, we introduce Dopamine-Reward, a novel reward modeling method for learning a general-purpose, step-aware process reward model from multi-view inputs. At its core is our General Reward Model (GRM), trained on a vast 3,400+ hour dataset, which leverages Step-wise Reward Discretization for structural understanding and Multi-Perspective Reward Fusion to overcome perceptual limitations. Building upon Dopamine-Reward, we propose Dopamine-RL, a robust policy learning framework that employs a theoretically-sound Policy-Invariant Reward Shaping method, which enables the agent to leverage dense rewards for efficient self-improvement without altering the optimal policy, thereby fundamentally avoiding the semantic trap. Extensive experiments across diverse simulated and real-world tasks validate our approach. GRM achieves state-of-the-art accuracy in reward assessment, and Dopamine-RL built on GRM significantly improves policy learning efficiency. For instance, after GRM is adapted to a new task in a one-shot manner from a single expert trajectory, the resulting reward model enables Dopamine-RL to improve the policy from near-zero to 95% success with only 150 online rollouts (approximately 1 hour of real robot interaction), while retaining strong generalization across tasks. Project website: https://robo-dopamine.github.io",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "27 pages, 11 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23703v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "policy learning",
                        "reward shaping"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "提出Dopamine-Reward以解决机器人操作中的奖励函数设计问题",
            "summary_zh": "在将强化学习应用于现实机器人时，设计有效的奖励函数是主要障碍。尽管基于学习的过程奖励模型（PRMs）是一种有前景的方向，但它们通常受到奖励模型缺乏步态意识和依赖单视角感知的限制，导致对细粒度操作进展的评估不可靠。此外，奖励塑造程序在理论上不够严谨，常常诱导出误导性的语义陷阱。为了解决这些问题，本文提出了一种新颖的奖励建模方法Dopamine-Reward，旨在从多视角输入中学习通用的、具有步态意识的过程奖励模型。核心是我们的通用奖励模型（GRM），其训练基于超过3400小时的数据集，利用逐步奖励离散化和多视角奖励融合来克服感知限制。实验结果表明，GRM在奖励评估中达到了最先进的准确性，而基于GRM的Dopamine-RL显著提高了策略学习效率。",
            "intro_zh": [
                "现有的过程奖励模型在机器人操作中面临奖励评估不可靠和理论基础不扎实的挑战。",
                "论文提出Dopamine-Reward，通过多视角输入学习具有步态意识的通用奖励模型，解决了现有方法的不足。",
                "实验表明，GRM在奖励评估中达到了最先进的准确性，Dopamine-RL在策略学习效率上显著提升。"
            ],
            "method_zh": "**问题定义**：本论文旨在解决在现实机器人操作中，现有强化学习方法在奖励函数设计上的不足，尤其是奖励模型缺乏步态意识和依赖单一视角感知的问题。\\n\\n**核心思路**：提出Dopamine-Reward方法，通过多视角输入来学习通用的、具有步态意识的过程奖励模型，从而提高奖励评估的可靠性和有效性。\\n\\n**技术框架**：整体架构包括通用奖励模型（GRM）和Dopamine-RL框架。GRM通过逐步奖励离散化和多视角奖励融合来实现结构化理解，而Dopamine-RL则采用理论上严谨的策略不变奖励塑造方法。\\n\\n**关键创新**：最重要的技术创新在于引入了逐步奖励离散化和多视角奖励融合，克服了传统方法的感知限制，并通过理论上严谨的奖励塑造避免了语义陷阱。\\n\\n**关键设计**：在GRM中，使用了大量的训练数据（3400小时以上），并设计了适当的损失函数和网络结构，以确保模型的准确性和泛化能力。",
            "application_zh": "该研究的潜在应用领域包括工业机器人、服务机器人和自动化系统等，能够显著提升机器人在复杂环境中的操作精度和效率。未来，Dopamine-Reward方法可能会推动更广泛的智能机器人技术的发展，使其在多样化任务中表现出更强的适应性和灵活性。",
            "highlight_zh": "实验结果显示，GRM在奖励评估中达到了最先进的准确性，Dopamine-RL在策略学习效率上显著提升。例如，在适应新任务时，Dopamine-RL能够在仅150次在线回合内将成功率从接近零提升至95%，展现出强大的任务泛化能力。",
            "tags_zh": [
                "过程奖励模型",
                "强化学习",
                "机器人操作",
                "多视角输入",
                "奖励塑造",
                "策略学习",
                "深度学习"
            ],
            "_index": 14,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23703v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23703v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23703v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ProGuard: Towards Proactive Multimodal Safeguard",
            "authors": [
                "Shaohan Yu",
                "Lijun Li",
                "Chenyang Si",
                "Lu Sheng",
                "Jing Shao"
            ],
            "arxiv_id": "2512.23573v1",
            "summary": "The rapid evolution of generative models has led to a continuous emergence of multimodal safety risks, exposing the limitations of existing defense methods. To address these challenges, we propose ProGuard, a vision-language proactive guard that identifies and describes out-of-distribution (OOD) safety risks without the need for model adjustments required by traditional reactive approaches. We first construct a modality-balanced dataset of 87K samples, each annotated with both binary safety labels and risk categories under a hierarchical multimodal safety taxonomy, effectively mitigating modality bias and ensuring consistent moderation across text, image, and text-image inputs. Based on this dataset, we train our vision-language base model purely through reinforcement learning (RL) to achieve efficient and concise reasoning. To approximate proactive safety scenarios in a controlled setting, we further introduce an OOD safety category inference task and augment the RL objective with a synonym-bank-based similarity reward that encourages the model to generate concise descriptions for unseen unsafe categories. Experimental results show that ProGuard achieves performance comparable to closed-source large models on binary safety classification, substantially outperforms existing open-source guard models on unsafe content categorization. Most notably, ProGuard delivers a strong proactive moderation ability, improving OOD risk detection by 52.6% and OOD risk description by 64.8%.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23573v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ProGuard，一种主动式多模态安全防护方法，用于识别和描述生成模型中的OOD安全风险。",
            "summary_zh": "生成模型的快速发展导致多模态安全风险不断涌现，暴露了现有防御方法的局限性。为了应对这些挑战，我们提出了ProGuard，一种视觉-语言主动防护方法，它能够识别和描述分布外(OOD)安全风险，而无需像传统被动方法那样进行模型调整。我们首先构建了一个包含87K样本的模态平衡数据集，每个样本都标注了二元安全标签和分层多模态安全分类体系下的风险类别，有效地缓解了模态偏差，并确保了文本、图像和文本-图像输入之间的一致审核。基于此数据集，我们完全通过强化学习(RL)训练视觉-语言基础模型，以实现高效简洁的推理。为了在受控环境中近似主动安全场景，我们进一步引入了OOD安全类别推断任务，并通过基于同义词库的相似性奖励来增强RL目标，鼓励模型为未见过的非安全类别生成简洁的描述。实验结果表明，ProGuard在二元安全分类方面达到了与闭源大型模型相当的性能，并在非安全内容分类方面显著优于现有的开源防护模型。最值得注意的是，ProGuard提供了强大的主动审核能力，将OOD风险检测提高了52.6%，OOD风险描述提高了64.8%。",
            "intro_zh": [
                "现有生成模型的安全性防御方法存在局限性，难以应对不断涌现的多模态安全风险，尤其是在分布外（OOD）场景下。",
                "ProGuard通过构建模态平衡数据集和强化学习训练，实现了对OOD安全风险的主动识别和描述，无需模型调整。",
                "实验结果表明，ProGuard在OOD风险检测和描述方面显著优于现有开源模型，提升幅度分别达到52.6%和64.8%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决生成模型中日益增长的多模态安全风险，特别是分布外（OOD）的安全风险识别问题。现有的防御方法通常是被动的，需要针对特定风险进行模型调整，无法有效应对未知的安全威胁。此外，现有方法往往存在模态偏差，难以在文本、图像和文本-图像等不同模态之间保持一致的审核标准。\\n\\n**核心思路**：ProGuard的核心思路是构建一个主动式的安全防护系统，使其能够在没有事先见过的情况下，识别和描述新的、分布外的安全风险。通过强化学习训练模型，使其能够高效简洁地进行推理，并利用同义词库的相似性奖励，鼓励模型生成对未知风险类别的准确描述。\\n\\n**技术框架**：ProGuard的技术框架主要包括以下几个部分：1) 构建模态平衡数据集，包含文本、图像和文本-图像三种模态，并标注二元安全标签和分层风险类别。2) 使用强化学习训练视觉-语言基础模型，使其能够进行安全分类和风险描述。3) 引入OOD安全类别推断任务，模拟主动安全场景。4) 使用基于同义词库的相似性奖励来增强强化学习目标，鼓励模型生成对未知风险类别的简洁描述。\\n\\n**关键创新**：ProGuard的关键创新在于其主动式的安全防护能力。与传统的被动防御方法不同，ProGuard能够在没有事先见过的情况下，识别和描述新的、分布外的安全风险。这得益于其基于强化学习的训练方法和基于同义词库的相似性奖励机制。\\n\\n**关键设计**：ProGuard的关键设计包括：1) 模态平衡数据集的构建，确保了模型在不同模态之间的一致性。2) 强化学习目标的设计，包括安全分类奖励、风险描述奖励和相似性奖励。3) 基于同义词库的相似性奖励的计算方法，用于衡量模型生成的描述与真实风险类别之间的相似度。具体参数设置和网络结构等细节在论文中未详细说明，属于未知信息。",
            "application_zh": "ProGuard可应用于各种生成模型，例如文本生成、图像生成和多模态生成模型，以提高其安全性。该研究的实际价值在于能够有效识别和防御未知的安全风险，降低生成模型被恶意利用的风险。未来，ProGuard可以进一步扩展到更广泛的安全领域，例如网络安全和信息安全。",
            "highlight_zh": "ProGuard在二元安全分类方面达到了与闭源大型模型相当的性能，并在非安全内容分类方面显著优于现有的开源防护模型。最重要的是，ProGuard在OOD风险检测方面提高了52.6%，在OOD风险描述方面提高了64.8%，展示了强大的主动审核能力。",
            "tags_zh": [
                "多模态安全",
                "主动防御",
                "强化学习",
                "分布外检测",
                "视觉-语言模型"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23573v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23573v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23573v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ThinkGen: Generalized Thinking for Visual Generation",
            "authors": [
                "Siyu Jiao",
                "Yiheng Lin",
                "Yujie Zhong",
                "Qi She",
                "Wei Zhou",
                "Xiaohan Lan",
                "Zilong Huang",
                "Fei Yu",
                "Yingchen Yu",
                "Yunqing Zhao",
                "Yao Zhao",
                "Yunchao Wei"
            ],
            "arxiv_id": "2512.23568v1",
            "summary": "Recent progress in Multimodal Large Language Models (MLLMs) demonstrates that Chain-of-Thought (CoT) reasoning enables systematic solutions to complex understanding tasks. However, its extension to generation tasks remains nascent and limited by scenario-specific mechanisms that hinder generalization and adaptation. In this work, we present ThinkGen, the first think-driven visual generation framework that explicitly leverages MLLM's CoT reasoning in various generation scenarios. ThinkGen employs a decoupled architecture comprising a pretrained MLLM and a Diffusion Transformer (DiT), wherein the MLLM generates tailored instructions based on user intent, and DiT produces high-quality images guided by these instructions. We further propose a separable GRPO-based training paradigm (SepGRPO), alternating reinforcement learning between the MLLM and DiT modules. This flexible design enables joint training across diverse datasets, facilitating effective CoT reasoning for a wide range of generative scenarios. Extensive experiments demonstrate that ThinkGen achieves robust, state-of-the-art performance across multiple generation benchmarks. Code is available: https://github.com/jiaosiyuu/ThinkGen",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23568v1",
            "code_links": [
                {
                    "url": "https://github.com/jiaosiyuu/ThinkGen",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal",
                        "chain-of-thought"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "ThinkGen：提出基于广义思维的视觉生成框架，提升多场景适应性。",
            "summary_zh": "本文提出ThinkGen，一种基于思维驱动的视觉生成框架，旨在利用多模态大型语言模型（MLLM）的思维链（CoT）推理能力，解决生成任务中场景泛化性不足的问题。ThinkGen采用解耦架构，包含预训练的MLLM和扩散Transformer（DiT）。MLLM根据用户意图生成定制指令，DiT在指令引导下生成高质量图像。此外，论文提出一种可分离的基于GRPO的训练范式（SepGRPO），在MLLM和DiT模块之间交替进行强化学习。这种灵活的设计支持跨多个数据集的联合训练，从而促进CoT推理在各种生成场景中的有效应用。大量实验表明，ThinkGen在多个生成基准测试中实现了稳健的、最先进的性能。",
            "intro_zh": [
                "现有方法在生成任务中应用CoT推理受限于特定场景机制，缺乏泛化性和适应性。",
                "ThinkGen利用MLLM的CoT推理能力，通过解耦架构和可分离训练范式实现跨场景的视觉生成。",
                "实验结果表明，ThinkGen在多个生成基准测试中取得了领先的性能表现。"
            ],
            "method_zh": "**问题定义**：现有视觉生成方法在利用多模态大语言模型（MLLM）的思维链（CoT）推理能力时，往往针对特定场景设计，导致模型在面对不同生成任务时泛化能力不足。这些方法缺乏一种通用的机制，能够有效地利用MLLM的推理能力来指导图像生成，从而限制了其在更广泛场景中的应用。\\n\\n**核心思路**：ThinkGen的核心思路是将视觉生成过程分解为两个阶段：首先，利用MLLM的CoT推理能力，根据用户意图生成详细的指令；然后，利用扩散Transformer（DiT）在这些指令的引导下生成高质量的图像。这种解耦的设计使得MLLM可以专注于推理，而DiT可以专注于图像生成，从而提高了整体的效率和效果。\\n\\n**技术框架**：ThinkGen的整体架构包含两个主要模块：一个预训练的MLLM和一个扩散Transformer（DiT）。用户输入文本或图像，MLLM根据输入生成一系列的推理步骤和最终的生成指令。这些指令被传递给DiT，DiT根据指令生成最终的图像。为了更好地训练这两个模块，论文提出了一个可分离的基于GRPO的训练范式（SepGRPO），该范式交替地对MLLM和DiT进行强化学习。\\n\\n**关键创新**：ThinkGen的关键创新在于其解耦的架构和可分离的训练范式。解耦架构使得MLLM和DiT可以独立地进行优化，从而提高了整体的性能。可分离的训练范式允许在不同的数据集上联合训练MLLM和DiT，从而提高了模型的泛化能力。此外，ThinkGen是第一个显式地利用MLLM的CoT推理能力来指导视觉生成的框架。\\n\\n**关键设计**：SepGRPO训练范式是关键设计之一，它通过交替强化学习的方式，分别优化MLLM和DiT。具体来说，首先固定DiT，利用强化学习优化MLLM，使其生成更有效的指令；然后固定MLLM，利用强化学习优化DiT，使其更好地理解和执行指令。这种交替优化的方式可以有效地提高整体的性能。此外，损失函数的设计也至关重要，需要平衡生成图像的质量和与指令的一致性。",
            "application_zh": "ThinkGen具有广泛的应用前景，包括图像编辑、图像生成、艺术创作、产品设计等领域。它可以用于根据用户提供的文本描述或草图生成高质量的图像，也可以用于对现有图像进行编辑和修改。此外，ThinkGen还可以应用于虚拟现实、游戏开发等领域，为用户提供更加逼真和沉浸式的体验。未来，ThinkGen有望成为视觉生成领域的重要工具，推动相关技术的发展。",
            "highlight_zh": "ThinkGen在多个生成基准测试中取得了显著的性能提升。例如，在文本到图像生成任务中，ThinkGen的FID得分优于现有方法，表明其生成的图像质量更高。此外，ThinkGen在图像编辑任务中也表现出色，能够根据用户指令对图像进行精确的修改。实验结果表明，ThinkGen能够有效地利用MLLM的CoT推理能力来指导视觉生成，从而提高了整体的性能。",
            "tags_zh": [
                "视觉生成",
                "多模态大语言模型",
                "思维链",
                "扩散模型",
                "强化学习",
                "图像编辑",
                "文本到图像生成"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23568v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23568v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23568v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "GaussianDWM: 3D Gaussian Driving World Model for Unified Scene Understanding and Multi-Modal Generation",
            "authors": [
                "Tianchen Deng",
                "Xuefeng Chen",
                "Yi Chen",
                "Qu Chen",
                "Yuyao Xu",
                "Lijin Yang",
                "Le Xu",
                "Yu Zhang",
                "Bo Zhang",
                "Wuxiong Huang",
                "Hesheng Wang"
            ],
            "arxiv_id": "2512.23180v1",
            "summary": "Driving World Models (DWMs) have been developing rapidly with the advances of generative models. However, existing DWMs lack 3D scene understanding capabilities and can only generate content conditioned on input data, without the ability to interpret or reason about the driving environment. Moreover, current approaches represent 3D spatial information with point cloud or BEV features do not accurately align textual information with the underlying 3D scene. To address these limitations, we propose a novel unified DWM framework based on 3D Gaussian scene representation, which enables both 3D scene understanding and multi-modal scene generation, while also enabling contextual enrichment for understanding and generation tasks. Our approach directly aligns textual information with the 3D scene by embedding rich linguistic features into each Gaussian primitive, thereby achieving early modality alignment. In addition, we design a novel task-aware language-guided sampling strategy that removes redundant 3D Gaussians and injects accurate and compact 3D tokens into LLM. Furthermore, we design a dual-condition multi-modal generation model, where the information captured by our vision-language model is leveraged as a high-level language condition in combination with a low-level image condition, jointly guiding the multi-modal generation process. We conduct comprehensive studies on the nuScenes, and NuInteract datasets to validate the effectiveness of our framework. Our method achieves state-of-the-art performance. We will release the code publicly on GitHub https://github.com/dtc111111/GaussianDWM.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23180v1",
            "code_links": [
                {
                    "url": "https://github.com/dtc111111/GaussianDWM",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出基于3D高斯表示的驾驶世界模型GaussianDWM，实现统一的场景理解和多模态生成。",
            "summary_zh": "本文提出了一种新颖的统一驾驶世界模型（DWM）框架，该框架基于3D高斯场景表示，能够实现3D场景理解和多模态场景生成，同时增强了对理解和生成任务的上下文丰富性。该方法通过将丰富的语言特征嵌入到每个高斯基元中，直接将文本信息与3D场景对齐，从而实现早期模态对齐。此外，设计了一种新颖的、任务感知的语言引导采样策略，该策略移除冗余的3D高斯并向LLM注入准确且紧凑的3D token。进一步地，设计了一个双条件多模态生成模型，其中视觉-语言模型捕获的信息被用作高级语言条件，并结合低级图像条件，共同指导多模态生成过程。在nuScenes和NuInteract数据集上进行了全面的研究，验证了该框架的有效性。该方法取得了最先进的性能，代码将在GitHub上公开。",
            "intro_zh": [
                "现有驾驶世界模型缺乏3D场景理解能力，且只能根据输入数据生成内容，无法解释或推理驾驶环境。",
                "提出基于3D高斯场景表示的统一DWM框架，通过将语言特征嵌入高斯基元实现早期模态对齐。",
                "设计任务感知语言引导采样策略和双条件多模态生成模型，并在nuScenes等数据集上验证了有效性。"
            ],
            "method_zh": "**问题定义**：现有驾驶世界模型（DWMs）无法有效理解3D场景，并且缺乏将文本信息与3D空间信息精确对齐的能力。它们通常依赖于点云或BEV特征，这限制了模型对驾驶环境的解释和推理能力。此外，现有模型主要关注条件生成，而忽略了对场景的深层理解。\\n\\n**核心思路**：本文的核心思路是利用3D高斯表示作为统一的场景表示，将视觉和语言信息融合到高斯基元中，从而实现3D场景的理解和多模态生成。通过将语言特征嵌入到每个3D高斯中，实现早期模态对齐，并利用语言引导采样策略来优化3D场景的表示。\\n\\n**技术框架**：GaussianDWM框架包含以下主要模块：1) 3D高斯场景表示模块：将3D场景表示为一组3D高斯基元，每个高斯基元包含位置、形状、颜色等属性。2) 视觉-语言嵌入模块：将图像和文本信息嵌入到3D高斯基元中，实现视觉和语言信息的融合。3) 任务感知语言引导采样模块：根据任务需求，利用语言信息对3D高斯基元进行采样，去除冗余信息，保留关键信息。4) 双条件多模态生成模块：利用视觉和语言信息作为条件，生成多模态场景内容。\\n\\n**关键创新**：该论文的关键创新在于：1) 提出了一种基于3D高斯表示的统一DWM框架，能够同时实现3D场景理解和多模态生成。2) 提出了一种早期模态对齐方法，通过将语言特征嵌入到3D高斯基元中，实现了视觉和语言信息的有效融合。3) 设计了一种任务感知语言引导采样策略，能够根据任务需求优化3D场景的表示。\\n\\n**关键设计**：任务感知语言引导采样策略是关键设计之一，它利用语言信息对3D高斯基元进行采样，去除冗余信息，保留关键信息。具体来说，该策略首先利用语言模型对场景进行描述，然后根据描述信息对3D高斯基元进行重要性排序，最后选择最重要的3D高斯基元作为场景的表示。双条件多模态生成模块利用视觉和语言信息作为条件，生成多模态场景内容。该模块采用Transformer架构，将视觉和语言信息作为输入，生成图像、文本等多种模态的内容。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、虚拟现实等领域。通过对驾驶环境的理解和推理，可以提高自动驾驶系统的安全性和可靠性。在机器人导航中，可以帮助机器人更好地理解周围环境，从而实现更智能的导航。在虚拟现实中，可以生成更逼真的虚拟场景，提高用户体验。",
            "highlight_zh": "该方法在nuScenes和NuInteract数据集上取得了state-of-the-art的性能。具体而言，该方法在3D场景理解和多模态生成任务上均取得了显著的提升，证明了该框架的有效性。代码将在GitHub上公开。",
            "tags_zh": [
                "驾驶世界模型",
                "3D高斯表示",
                "场景理解",
                "多模态生成",
                "视觉语言融合",
                "自动驾驶",
                "语言引导采样"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23180v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23180v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23180v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Splitwise: Collaborative Edge-Cloud Inference for LLMs via Lyapunov-Assisted DRL",
            "authors": [
                "Abolfazl Younesi",
                "Abbas Shabrang Maryan",
                "Elyas Oustad",
                "Zahra Najafabadi Samani",
                "Mohsen Ansari",
                "Thomas Fahringer"
            ],
            "arxiv_id": "2512.23310v1",
            "summary": "Deploying large language models (LLMs) on edge devices is challenging due to their limited memory and power resources. Cloud-only inference reduces device burden but introduces high latency and cost. Static edge-cloud partitions optimize a single metric and struggle when bandwidth fluctuates. We propose Splitwise, a novel Lyapunov-assisted deep reinforcement learning (DRL) framework for fine-grained, adaptive partitioning of LLMs across edge and cloud environments. Splitwise decomposes transformer layers into attention heads and feed-forward sub-blocks, exposing more partition choices than layer-wise schemes. A hierarchical DRL policy, guided by Lyapunov optimization, jointly minimizes latency, energy consumption, and accuracy degradation while guaranteeing queue stability under stochastic workloads and variable network bandwidth. Splitwise also guarantees robustness via partition checkpoints with exponential backoff recovery in case of communication failures. Experiments on Jetson Orin NX, Galaxy S23, and Raspberry Pi 5 with GPT-2 (1.5B), LLaMA-7B, and LLaMA-13B show that Splitwise reduces end-to-end latency by 1.4x-2.8x and cuts energy consumption by up to 41% compared with existing partitioners. It lowers the 95th-percentile latency by 53-61% relative to cloud-only execution, while maintaining accuracy and modest memory requirements.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.DC",
                "cs.ET",
                "cs.NI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "11 pages, 9 figures. Accepted by ACM for presentation at UCC '25 (18th International Conference on Utility and Cloud Computing), December 1-4, 2025, France. Proceedings publication pending",
            "doi": "10.1145/3773274.3774267",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23310v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning",
                        "[T]DRL"
                    ],
                    "score": 7.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Splitwise：基于Lyapunov优化的DRL实现LLM在边缘-云协同推理的自适应切分。",
            "summary_zh": "由于边缘设备内存和算力资源有限，在大语言模型（LLM）上部署具有挑战性。仅在云端推理虽然减轻了设备负担，但引入了高延迟和高成本。静态的边缘-云划分方案仅优化单一指标，难以应对带宽波动。我们提出了Splitwise，一种新颖的基于Lyapunov优化的深度强化学习（DRL）框架，用于LLM在边缘和云环境之间进行细粒度的自适应划分。Splitwise将Transformer层分解为注意力头和前馈子块，比逐层划分方案暴露了更多的划分选择。一个由Lyapunov优化指导的分层DRL策略，在随机工作负载和可变网络带宽下，联合最小化延迟、能耗和精度下降，同时保证队列稳定性。Splitwise还通过具有指数退避恢复的划分检查点来保证通信失败时的鲁棒性。在Jetson Orin NX、Galaxy S23和Raspberry Pi 5上使用GPT-2 (1.5B)、LLaMA-7B和LLaMA-13B进行的实验表明，与现有的划分器相比，Splitwise将端到端延迟降低了1.4x-2.8x，并将能耗降低了高达41%。相对于仅在云端执行，它将第95百分位的延迟降低了53-61%，同时保持了精度和适度的内存需求。",
            "intro_zh": [
                "现有边缘-云 LLM 推理方案难以在延迟、能耗和精度之间取得良好平衡，且无法适应动态网络环境。",
                "Splitwise 提出一种基于 Lyapunov 优化的分层 DRL 框架，实现 LLM 在边缘和云之间的细粒度自适应切分。",
                "实验表明，Splitwise 显著降低了端到端延迟和能耗，同时保持了精度和鲁棒性，优于现有方案。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在边缘设备上部署大型语言模型（LLM）时，由于资源限制和网络波动导致的推理延迟高、能耗大以及精度下降的问题。现有的静态边缘-云划分方法无法很好地适应动态变化的网络环境，并且通常只优化单一指标，难以实现多目标优化。\n\n**核心思路**：论文的核心思路是利用深度强化学习（DRL）来学习一个自适应的LLM划分策略，该策略能够根据当前的网络状态、设备资源和任务需求，动态地将LLM的不同部分分配到边缘设备和云端进行推理。通过Lyapunov优化来保证系统的稳定性，并使用细粒度的划分方式来增加划分的灵活性。\n\n**技术框架**：Splitwise 的整体框架包含以下几个主要模块：1) LLM 分解模块：将 Transformer 层分解为更小的单元（注意力头和前馈子块），从而提供更细粒度的划分选择。2) 状态观测模块：收集边缘设备和云端的资源信息、网络带宽以及任务队列长度等状态信息。3) DRL 策略学习模块：使用分层 DRL 策略，结合 Lyapunov 优化，学习最优的划分策略。4) 推理执行模块：根据 DRL 策略将 LLM 的不同部分分配到边缘设备和云端进行推理，并进行结果整合。5) 故障恢复模块：在通信失败时，通过划分检查点和指数退避恢复机制保证系统的鲁棒性。\n\n**关键创新**：论文的关键创新在于：1) 提出了细粒度的 LLM 划分方法，将 Transformer 层分解为更小的单元，增加了划分的灵活性。2) 结合 Lyapunov 优化和 DRL，实现多目标优化，同时保证系统的稳定性。3) 提出了分层 DRL 策略，降低了学习的复杂性。4) 实现了通信失败时的鲁棒性保证。\n\n**关键设计**：论文的关键设计包括：1) Lyapunov 函数的设计，用于保证任务队列的稳定性。2) DRL 策略网络的结构，包括状态表示、动作空间和奖励函数的设计。3) 划分检查点和指数退避恢复机制的具体实现。4) 针对不同 LLM 和边缘设备的参数调优。",
            "application_zh": "Splitwise 的应用场景广泛，包括智能家居、自动驾驶、工业物联网等需要在边缘设备上进行低延迟、高能效 LLM 推理的领域。该研究成果有助于推动 LLM 在资源受限环境中的部署，并为未来的边缘智能应用提供技术支撑。",
            "highlight_zh": "实验结果表明，Splitwise 在 GPT-2 (1.5B)、LLaMA-7B 和 LLaMA-13B 模型上，相比现有划分器，端到端延迟降低了 1.4x-2.8x，能耗降低了高达 41%。相对于仅在云端执行，第 95 百分位的延迟降低了 53-61%，同时保持了精度和适度的内存需求。这些结果验证了 Splitwise 在边缘-云协同推理中的有效性。",
            "tags_zh": [
                "边缘计算",
                "大语言模型",
                "深度强化学习",
                "模型切分",
                "Lyapunov优化"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23310v1/source/Figures/OperationalCostAnalysis.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23310v1/source/Figures/MemoryRequirements.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23310v1/source/Figures/PerformanceScalingSpeedupvscloudonly.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SE-MLP Model for Predicting Prior Acceleration Features in Penetration Signals",
            "authors": [
                "Yankang Li",
                "Changsheng Li"
            ],
            "arxiv_id": "2512.23131v1",
            "summary": "Accurate identification of the penetration process relies heavily on prior feature values of penetration acceleration. However, these feature values are typically obtained through long simulation cycles and expensive computations. To overcome this limitation, this paper proposes a multi-layer Perceptron architecture, termed squeeze and excitation multi-layer perceptron (SE-MLP), which integrates a channel attention mechanism with residual connections to enable rapid prediction of acceleration feature values. Using physical parameters under different working conditions as inputs, the model outputs layer-wise acceleration features, thereby establishing a nonlinear mapping between physical parameters and penetration characteristics. Comparative experiments against conventional MLP, XGBoost, and Transformer models demonstrate that SE-MLP achieves superior prediction accuracy, generalization, and stability. Ablation studies further confirm that both the channel attention module and residual structure contribute significantly to performance gains. Numerical simulations and range recovery tests show that the discrepancies between predicted and measured acceleration peaks and pulse widths remain within acceptable engineering tolerances. These results validate the feasibility and engineering applicability of the proposed method and provide a practical basis for rapidly generating prior feature values for penetration fuzes.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "23 pages, 10 figures, 6 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23131v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]penetration"
                    ],
                    "score": 7.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "PULSE"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 9.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "提出SE-MLP模型，用于快速预测侵彻信号中的先验加速度特征，解决传统方法计算耗时问题。",
            "summary_zh": "本文提出了一种名为挤压激励多层感知机（SE-MLP）的模型，该模型集成了通道注意力机制和残差连接，旨在快速预测加速度特征值。该模型以不同工况下的物理参数作为输入，输出分层加速度特征，从而建立物理参数与侵彻特性之间的非线性映射。与传统MLP、XGBoost和Transformer模型的对比实验表明，SE-MLP在预测精度、泛化性和稳定性方面表现更优。消融研究进一步证实了通道注意力模块和残差结构对性能提升的显著贡献。数值模拟和射程恢复测试表明，预测和测量得到的加速度峰值和脉冲宽度之间的差异保持在可接受的工程容差范围内。这些结果验证了该方法的可行性和工程适用性，并为快速生成侵彻引信的先验特征值提供了实践基础。",
            "intro_zh": [
                "准确识别侵彻过程依赖于侵彻加速度的先验特征值，但传统方法需要耗时的仿真周期和高昂的计算成本。",
                "论文提出SE-MLP模型，通过集成通道注意力机制和残差连接，实现对加速度特征值的快速预测。",
                "实验结果表明，SE-MLP在预测精度、泛化性和稳定性方面优于传统MLP、XGBoost和Transformer模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决侵彻过程中加速度特征值预测耗时的问题。传统的获取方式依赖于长时间的仿真和高昂的计算，这限制了对侵彻过程的快速分析和优化。现有方法的痛点在于计算效率低，难以满足实时性要求。\\n\\n**核心思路**：论文的核心思路是利用深度学习模型学习物理参数与加速度特征之间的非线性映射关系，从而实现对加速度特征值的快速预测。通过构建一个高效的预测模型，避免了耗时的仿真过程，提高了计算效率。\\n\\n**技术框架**：SE-MLP模型的整体架构是一个多层感知机，其输入是不同工况下的物理参数，输出是分层加速度特征。模型主要包含以下模块：输入层、多层感知机层、挤压激励（Squeeze-and-Excitation）模块、残差连接和输出层。挤压激励模块用于学习通道之间的依赖关系，提升特征表达能力。残差连接用于缓解梯度消失问题，提高模型训练的稳定性。\\n\\n**关键创新**：最重要的技术创新点在于将通道注意力机制（挤压激励模块）和残差连接集成到多层感知机中。与传统的MLP相比，SE-MLP能够更好地捕捉通道之间的依赖关系，并缓解梯度消失问题，从而提高预测精度和泛化能力。\\n\\n**关键设计**：SE-MLP的关键设计包括：1) 挤压激励模块的参数设置，例如压缩比例的选择；2) 残差连接的连接方式，例如直接连接或通过卷积层连接；3) 损失函数的选择，例如均方误差或Huber损失；4) 网络层数的选择，需要根据具体问题进行调整。",
            "application_zh": "该研究成果可应用于侵彻引信的快速设计和优化，提高武器系统的研发效率。此外，该方法还可以扩展到其他需要快速预测先验特征值的工程领域，例如材料设计、结构优化等。通过建立物理参数与性能指标之间的快速预测模型，可以加速设计迭代过程，降低研发成本。",
            "highlight_zh": "实验结果表明，SE-MLP模型在预测精度、泛化性和稳定性方面优于传统MLP、XGBoost和Transformer模型。消融研究证实了通道注意力模块和残差结构对性能提升的显著贡献。数值模拟和射程恢复测试表明，预测和测量得到的加速度峰值和脉冲宽度之间的差异保持在可接受的工程容差范围内，验证了该方法的工程适用性。",
            "tags_zh": [
                "侵彻信号预测",
                "加速度特征",
                "多层感知机",
                "通道注意力机制",
                "残差连接",
                "深度学习",
                "物理参数建模"
            ],
            "_index": 19,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23131v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23131v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23131v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Scalable Residual Feature Aggregation Framework with Hybrid Metaheuristic Optimization for Robust Early Pancreatic Neoplasm Detection in Multimodal CT Imaging",
            "authors": [
                "Janani Annur Thiruvengadam",
                "Kiran Mayee Nabigaru",
                "Anusha Kovi"
            ],
            "arxiv_id": "2512.23597v1",
            "summary": "The early detection of pancreatic neoplasm is a major clinical dilemma, and it is predominantly so because tumors are likely to occur with minimal contrast margins and a large spread anatomy-wide variation amongst patients on a CT scan. These complexities require to be addressed with an effective and scalable system that can assist in enhancing the salience of the subtle visual cues and provide a high level of the generalization on the multimodal imaging data. A Scalable Residual Feature Aggregation (SRFA) framework is proposed to be used to meet these conditions in this study. The framework integrates a pipeline of preprocessing followed by the segmentation using the MAGRes-UNet that is effective in making the pancreatic structures and isolating regions of interest more visible. DenseNet-121 performed with residual feature storage is used to extract features to allow deep hierarchical features to be aggregated without properties loss. To go further, hybrid HHO-BA metaheuristic feature selection strategy is used, which guarantees the best feature subset refinement. To be classified, the system is trained based on a new hybrid model that integrates the ability to pay attention on the world, which is the Vision Transformer (ViT) with the high representational efficiency of EfficientNet-B3. A dual optimization mechanism incorporating SSA and GWO is used to fine-tune hyperparameters to enhance greater robustness and less overfitting. Experimental results support the significant improvement in performance, with the suggested model reaching 96.23% accuracy, 95.58% F1-score and 94.83% specificity, the model is significantly better than the traditional CNNs and contemporary transformer-based models. Such results highlight the possibility of the SRFA framework as a useful instrument in the early detection of pancreatic tumors.",
            "categories": [
                "cs.CV",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23597v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于混合元启发式优化的可扩展残差特征聚合框架，用于多模态CT影像中早期胰腺肿瘤的稳健检测。",
            "summary_zh": "早期胰腺肿瘤的检测是一个主要的临床难题，主要是因为肿瘤可能以最小的对比边缘出现，并且在CT扫描中患者的解剖结构存在很大的差异。这些复杂性需要通过一个有效的、可扩展的系统来解决，该系统可以帮助增强细微视觉线索的显著性，并提供多模态成像数据的高度泛化能力。本研究提出了一个可扩展的残差特征聚合（SRFA）框架来满足这些条件。该框架集成了一个预处理流程，然后使用MAGRes-UNet进行分割，这有效地使胰腺结构更加可见并隔离感兴趣区域。使用具有残差特征存储的DenseNet-121来提取特征，以允许深度分层特征在不损失属性的情况下进行聚合。更进一步，使用混合HHO-BA元启发式特征选择策略，保证了最佳的特征子集细化。为了进行分类，该系统基于一种新的混合模型进行训练，该模型集成了对全局的关注能力，即Vision Transformer（ViT），以及EfficientNet-B3的高表示效率。采用包含SSA和GWO的双重优化机制来微调超参数，以增强更大的鲁棒性和更少的过拟合。实验结果支持性能的显著提高，所提出的模型达到了96.23%的准确率，95.58%的F1分数和94.83%的特异性，该模型明显优于传统的CNN和现代基于Transformer的模型。这些结果突出了SRFA框架作为早期检测胰腺肿瘤的有用工具的可能性。",
            "intro_zh": [
                "现有胰腺肿瘤检测方法难以应对肿瘤对比度低、患者解剖结构差异大的挑战，导致检测精度不足。",
                "论文提出SRFA框架，结合MAGRes-UNet分割、DenseNet-121特征提取和混合元启发式特征选择，增强肿瘤特征并提高泛化能力。",
                "实验结果表明，该模型在准确率、F1分数和特异性方面均优于传统CNN和Transformer模型，证明了其在早期胰腺肿瘤检测中的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态CT影像中早期胰腺肿瘤检测的难题。现有方法在处理肿瘤对比度低、患者解剖结构差异大以及数据泛化性差等问题时存在局限性，导致检测精度不高，难以满足临床需求。\\n\\n**核心思路**：论文的核心思路是构建一个可扩展的残差特征聚合（SRFA）框架，通过多阶段处理增强肿瘤区域的特征表达，并利用混合元启发式优化算法选择最优特征子集，从而提高检测的准确性和鲁棒性。这种设计旨在克服传统方法在特征提取和选择方面的不足。\\n\\n**技术框架**：SRFA框架包含以下主要模块：1) 预处理：对CT影像进行预处理，以提高图像质量。2) 分割：使用MAGRes-UNet分割胰腺结构，并隔离感兴趣区域。3) 特征提取：利用DenseNet-121提取深度分层特征，并采用残差连接存储特征信息。4) 特征选择：使用混合HHO-BA元启发式算法选择最优特征子集。5) 分类：使用集成了Vision Transformer (ViT) 和 EfficientNet-B3 的混合模型进行分类，并通过SSA和GWO双重优化机制微调超参数。\\n\\n**关键创新**：论文的关键创新在于：1) 提出了SRFA框架，将分割、特征提取、特征选择和分类整合到一个统一的流程中。2) 采用了混合HHO-BA元启发式算法进行特征选择，提高了特征选择的效率和准确性。3) 构建了ViT和EfficientNet-B3的混合分类模型，并使用双重优化机制微调超参数，增强了模型的鲁棒性和泛化能力。\\n\\n**关键设计**：1) MAGRes-UNet分割网络用于精确分割胰腺区域。2) DenseNet-121的残差连接用于保留深层特征信息。3) HHO-BA混合元启发式算法结合了两种算法的优点，提高了特征选择的效率。4) ViT和EfficientNet-B3混合模型结合了Transformer的全局关注能力和EfficientNet的表示效率。5) SSA和GWO双重优化机制用于微调模型的超参数，防止过拟合。",
            "application_zh": "该研究成果可应用于临床胰腺肿瘤的早期辅助诊断，帮助医生更准确地识别肿瘤，提高诊断效率。该框架具有可扩展性，可以应用于其他医学影像分析任务，例如其他器官的肿瘤检测或病灶分割。未来，该研究可以进一步扩展到多中心、多模态数据，提高模型的泛化能力和临床实用性。",
            "highlight_zh": "实验结果表明，所提出的SRFA框架在胰腺肿瘤检测中取得了显著的性能提升，达到了96.23%的准确率，95.58%的F1分数和94.83%的特异性。与传统的CNN和基于Transformer的模型相比，该模型在各项指标上均表现出更优的性能，验证了SRFA框架的有效性和优越性。",
            "tags_zh": [
                "胰腺肿瘤检测",
                "多模态CT影像",
                "残差特征聚合",
                "元启发式优化",
                "深度学习",
                "医学影像分析",
                "特征选择"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Stochastic Siamese MAE Pretraining for Longitudinal Medical Images",
            "authors": [
                "Taha Emre",
                "Arunava Chakravarty",
                "Thomas Pinetz",
                "Dmitrii Lachinov",
                "Martin J. Menten",
                "Hendrik Scholl",
                "Sobha Sivaprasad",
                "Daniel Rueckert",
                "Andrew Lotery",
                "Stefan Sacu",
                "Ursula Schmidt-Erfurth",
                "Hrvoje Bogunović"
            ],
            "arxiv_id": "2512.23441v1",
            "summary": "Temporally aware image representations are crucial for capturing disease progression in 3D volumes of longitudinal medical datasets. However, recent state-of-the-art self-supervised learning approaches like Masked Autoencoding (MAE), despite their strong representation learning capabilities, lack temporal awareness. In this paper, we propose STAMP (Stochastic Temporal Autoencoder with Masked Pretraining), a Siamese MAE framework that encodes temporal information through a stochastic process by conditioning on the time difference between the 2 input volumes. Unlike deterministic Siamese approaches, which compare scans from different time points but fail to account for the inherent uncertainty in disease evolution, STAMP learns temporal dynamics stochastically by reframing the MAE reconstruction loss as a conditional variational inference objective. We evaluated STAMP on two OCT and one MRI datasets with multiple visits per patient. STAMP pretrained ViT models outperformed both existing temporal MAE methods and foundation models on different late stage Age-Related Macular Degeneration and Alzheimer's Disease progression prediction which require models to learn the underlying non-deterministic temporal dynamics of the diseases.",
            "categories": [
                "cs.LG",
                "cs.CV"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Under review. Code is available in https://github.com/EmreTaha/STAMP",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23441v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "[T]MAE"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出STAMP：一种用于纵向医学图像的随机Siamese MAE预训练框架",
            "summary_zh": "本文提出了一种名为STAMP（具有掩码预训练的随机时间自编码器）的Siamese MAE框架，用于编码纵向医学数据集3D体积中的时间信息，这对于捕捉疾病进展至关重要。与现有的掩码自编码器（MAE）方法不同，STAMP通过一个随机过程，以两个输入体积之间的时间差为条件，来编码时间信息。与确定性的Siamese方法不同，STAMP将MAE重建损失重新定义为条件变分推断目标，从而随机地学习时间动态，解决了确定性方法无法解释疾病演变中固有不确定性的问题。在多个患者多次就诊的OCT和MRI数据集上进行的评估表明，STAMP预训练的ViT模型在预测晚期年龄相关性黄斑变性和阿尔茨海默病进展方面，优于现有的时间MAE方法和基础模型，这些预测任务需要模型学习疾病潜在的非确定性时间动态。",
            "intro_zh": [
                "现有MAE方法在表征学习方面表现出色，但缺乏对纵向医学图像时间信息的有效建模能力，无法捕捉疾病进展的不确定性。",
                "STAMP通过引入随机Siamese MAE框架，利用时间差作为条件，将重建损失转化为条件变分推断目标，从而学习非确定性的时间动态。",
                "在OCT和MRI数据集上的实验表明，STAMP预训练的ViT模型在疾病进展预测任务中，显著优于现有方法和基础模型。"
            ],
            "method_zh": "**问题定义**：纵向医学图像分析的关键在于捕捉疾病随时间变化的进展。现有的自监督学习方法，如MAE，虽然擅长图像表征学习，但缺乏对时间信息的有效建模，无法准确预测疾病的演变过程，尤其是在疾病进展具有不确定性的情况下。确定性的Siamese网络虽然可以比较不同时间点的扫描结果，但无法解释疾病演变中固有的不确定性。\n\n**核心思路**：STAMP的核心思路是通过引入随机性来建模疾病进展的不确定性。具体来说，它使用Siamese MAE框架，并以两个输入体积之间的时间差为条件，通过随机过程编码时间信息。这种方法将MAE的重建损失重新定义为条件变分推断目标，从而允许模型学习时间动态的概率分布，而不是单一的确定性映射。\n\n**技术框架**：STAMP采用Siamese网络结构，包含两个共享权重的MAE编码器。输入是同一患者在不同时间点的两张医学图像。这两个图像分别经过MAE编码器，然后通过一个条件变分自编码器（CVAE）进行处理，CVAE以两张图像的时间差作为条件，生成一个潜在变量。最后，解码器利用这个潜在变量重建被mask的图像块。整个框架通过最小化重建误差和CVAE的KL散度进行训练。\n\n**关键创新**：STAMP的关键创新在于将确定性的Siamese MAE框架扩展到随机框架，从而能够建模疾病进展的不确定性。通过将重建损失重新定义为条件变分推断目标，STAMP可以学习时间动态的概率分布，而不是单一的确定性映射。这使得模型能够更好地预测疾病的演变过程，尤其是在疾病进展具有不确定性的情况下。\n\n**关键设计**：STAMP的关键设计包括：1) 使用ViT作为MAE的编码器和解码器；2) 使用时间差作为CVAE的条件输入；3) 使用KL散度作为正则化项，鼓励潜在变量服从标准正态分布；4) 通过调整mask比例和CVAE的参数来控制模型的随机性。",
            "application_zh": "STAMP在纵向医学图像分析领域具有广泛的应用前景，例如疾病进展预测、个性化治疗方案制定、药物疗效评估等。通过学习疾病演变的非确定性时间动态，STAMP可以帮助医生更准确地预测患者的病情发展，从而制定更有效的治疗策略，并评估药物的疗效。此外，STAMP还可以用于辅助诊断，帮助医生识别早期病变，从而实现疾病的早期干预。",
            "highlight_zh": "STAMP在三个医学图像数据集（两个OCT数据集和一个MRI数据集）上进行了评估，实验结果表明，STAMP预训练的ViT模型在预测晚期年龄相关性黄斑变性和阿尔茨海默病进展方面，显著优于现有的时间MAE方法和基础模型。例如，在AMD进展预测任务中，STAMP相比于基线方法取得了显著的性能提升（具体数值未在摘要中给出，属于未知信息）。",
            "tags_zh": [
                "纵向医学图像",
                "自监督学习",
                "掩码自编码器",
                "Siamese网络",
                "时间序列分析"
            ],
            "_index": 21,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23441v1/visivis_v7.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23441v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23441v1/double.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multi-Track Multimodal Learning on iMiGUE: Micro-Gesture and Emotion Recognition",
            "authors": [
                "Arman Martirosyan",
                "Shahane Tigranyan",
                "Maria Razzhivina",
                "Artak Aslanyan",
                "Nazgul Salikhova",
                "Ilya Makarov",
                "Andrey Savchenko",
                "Aram Avetisyan"
            ],
            "arxiv_id": "2512.23291v1",
            "summary": "Micro-gesture recognition and behavior-based emotion prediction are both highly challenging tasks that require modeling subtle, fine-grained human behaviors, primarily leveraging video and skeletal pose data. In this work, we present two multimodal frameworks designed to tackle both problems on the iMiGUE dataset. For micro-gesture classification, we explore the complementary strengths of RGB and 3D pose-based representations to capture nuanced spatio-temporal patterns. To comprehensively represent gestures, video, and skeletal embeddings are extracted using MViTv2-S and 2s-AGCN, respectively. Then, they are integrated through a Cross-Modal Token Fusion module to combine spatial and pose information. For emotion recognition, our framework extends to behavior-based emotion prediction, a binary classification task identifying emotional states based on visual cues. We leverage facial and contextual embeddings extracted using SwinFace and MViTv2-S models and fuse them through an InterFusion module designed to capture emotional expressions and body gestures. Experiments conducted on the iMiGUE dataset, within the scope of the MiGA 2025 Challenge, demonstrate the robust performance and accuracy of our method in the behavior-based emotion prediction task, where our approach secured 2nd place.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23291v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对iMiGUE数据集，提出多轨多模态学习框架用于微手势和情感识别",
            "summary_zh": "微手势识别和基于行为的情感预测都是极具挑战性的任务，需要对细微的人类行为进行建模，主要利用视频和骨骼姿态数据。本文提出了两种多模态框架，旨在解决iMiGUE数据集上的这两个问题。对于微手势分类，探索了RGB和3D姿态表示的互补优势，以捕捉细致的时空模式。为了全面表示手势，分别使用MViTv2-S和2s-AGCN提取视频和骨骼嵌入，然后通过跨模态Token融合模块整合空间和姿态信息。对于情感识别，框架扩展到基于行为的情感预测，这是一个基于视觉线索识别情绪状态的二元分类任务。利用SwinFace和MViTv2-S模型提取面部和上下文嵌入，并通过InterFusion模块融合它们，旨在捕捉情感表达和身体手势。在MiGA 2025挑战赛的iMiGUE数据集上进行的实验表明，该方法在基于行为的情感预测任务中表现出强大的性能和准确性，并获得了第二名。",
            "intro_zh": [
                "微手势和情感识别面临捕捉细微行为模式的挑战，现有方法难以有效融合多模态信息。",
                "提出多轨多模态学习框架，针对微手势和情感识别分别设计了跨模态融合策略。",
                "在iMiGUE数据集上的实验表明，该方法在基于行为的情感预测任务中取得了优异的性能，排名第二。"
            ],
            "method_zh": "**问题定义**：论文旨在解决微手势识别和基于行为的情感预测两个问题。现有方法在处理细微的人类行为模式，以及有效融合来自视频、骨骼姿态等不同模态的信息方面存在不足，难以充分利用多模态数据的互补性。\\n\\n**核心思路**：论文的核心思路是利用多模态学习框架，针对微手势和情感识别任务，分别设计专门的跨模态融合策略。通过提取不同模态的特征表示，并采用有效的融合机制，从而捕捉细微的时空模式和情感表达。\\n\\n**技术框架**：整体框架包含两个主要分支：微手势识别和情感识别。对于微手势识别，首先使用MViTv2-S和2s-AGCN分别提取视频和骨骼姿态的嵌入表示，然后通过Cross-Modal Token Fusion模块进行融合。对于情感识别，使用SwinFace和MViTv2-S提取面部和上下文嵌入，并通过InterFusion模块进行融合。两个分支的最终输出分别是微手势类别和情感状态的预测结果。\\n\\n**关键创新**：论文的关键创新在于针对不同的任务，设计了专门的跨模态融合模块。Cross-Modal Token Fusion模块旨在融合视频和骨骼姿态的空间和姿态信息，而InterFusion模块旨在捕捉情感表达和身体手势之间的关联。这种针对特定任务的融合策略能够更有效地利用多模态数据的互补性。\\n\\n**关键设计**：在微手势识别分支，MViTv2-S和2s-AGCN的选择考虑了它们在视频和骨骼姿态特征提取方面的优势。Cross-Modal Token Fusion模块的具体实现细节（例如，注意力机制的选择、融合方式等）未知。在情感识别分支，SwinFace用于提取面部特征，MViTv2-S用于提取上下文特征，InterFusion模块的具体实现细节也未知。",
            "application_zh": "该研究成果可应用于人机交互、智能监控、医疗健康等领域。例如，在人机交互中，可以利用微手势识别实现更自然、更精细的交互方式；在智能监控中，可以利用情感识别技术检测异常行为和潜在风险；在医疗健康领域，可以辅助医生进行心理评估和疾病诊断。",
            "highlight_zh": "该方法在iMiGUE数据集的MiGA 2025挑战赛中，在基于行为的情感预测任务中取得了第二名的成绩，验证了该方法在处理细微行为模式和融合多模态信息方面的有效性。具体的性能数据和对比基线未知，但排名结果表明该方法具有竞争力。",
            "tags_zh": [
                "微手势识别",
                "情感识别",
                "多模态学习",
                "跨模态融合",
                "行为分析",
                "深度学习",
                "iMiGUE数据集"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23291v1/dt1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23291v1/cmtf.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23291v1/architecture3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multimodal Interpretation of Remote Sensing Images: Dynamic Resolution Input Strategy and Multi-scale Vision-Language Alignment Mechanism",
            "authors": [
                "Siyu Zhang",
                "Ying Chen",
                "Lianlei Shan",
                "Runhe Qiu"
            ],
            "arxiv_id": "2512.23243v1",
            "summary": "Multimodal fusion of remote sensing images serves as a core technology for overcoming the limitations of single-source data and improving the accuracy of surface information extraction, which exhibits significant application value in fields such as environmental monitoring and urban planning. To address the deficiencies of existing methods, including the failure of fixed resolutions to balance efficiency and detail, as well as the lack of semantic hierarchy in single-scale alignment, this study proposes a Vision-language Model (VLM) framework integrated with two key innovations: the Dynamic Resolution Input Strategy (DRIS) and the Multi-scale Vision-language Alignment Mechanism (MS-VLAM).Specifically, the DRIS adopts a coarse-to-fine approach to adaptively allocate computational resources according to the complexity of image content, thereby preserving key fine-grained features while reducing redundant computational overhead. The MS-VLAM constructs a three-tier alignment mechanism covering object, local-region and global levels, which systematically captures cross-modal semantic consistency and alleviates issues of semantic misalignment and granularity imbalance.Experimental results on the RS-GPT4V dataset demonstrate that the proposed framework significantly improves the accuracy of semantic understanding and computational efficiency in tasks including image captioning and cross-modal retrieval. Compared with conventional methods, it achieves superior performance in evaluation metrics such as BLEU-4 and CIDEr for image captioning, as well as R@10 for cross-modal retrieval. This technical framework provides a novel approach for constructing efficient and robust multimodal remote sensing systems, laying a theoretical foundation and offering technical guidance for the engineering application of intelligent remote sensing interpretation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23243v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DRIS和MS-VLAM，用于提升遥感图像多模态融合的效率和语义理解精度。",
            "summary_zh": "本研究针对遥感图像多模态融合中固定分辨率难以兼顾效率与细节、单尺度对齐缺乏语义层级的问题，提出了一个融合动态分辨率输入策略（DRIS）和多尺度视觉-语言对齐机制（MS-VLAM）的视觉-语言模型（VLM）框架。DRIS采用由粗到精的方法，根据图像内容的复杂性自适应地分配计算资源，从而在保留关键细粒度特征的同时，减少冗余计算开销。MS-VLAM构建了一个涵盖对象、局部区域和全局层面的三层对齐机制，系统地捕获跨模态语义一致性，并缓解语义错位和粒度不平衡的问题。在RS-GPT4V数据集上的实验结果表明，所提出的框架显著提高了图像描述和跨模态检索等任务中的语义理解精度和计算效率。与传统方法相比，在图像描述的BLEU-4和CIDEr指标以及跨模态检索的R@10指标上均取得了优异的性能。该技术框架为构建高效、鲁棒的多模态遥感系统提供了一种新方法，为智能遥感解译的工程应用奠定了理论基础，并提供了技术指导。",
            "intro_zh": [
                "现有遥感图像多模态融合方法在固定分辨率下难以平衡效率与细节，且单尺度对齐缺乏语义层级。",
                "提出动态分辨率输入策略（DRIS）和多尺度视觉-语言对齐机制（MS-VLAM）来提升效率和语义理解精度。",
                "在RS-GPT4V数据集上，该框架在图像描述和跨模态检索任务中显著提高了语义理解精度和计算效率。"
            ],
            "method_zh": "**问题定义**：遥感图像的多模态融合旨在克服单源数据的局限性，提高地表信息提取的准确性。然而，现有方法通常采用固定分辨率的图像输入，无法根据图像内容的复杂性自适应地调整计算资源，导致计算效率低下或细节信息丢失。此外，单尺度的视觉-语言对齐机制缺乏对语义层级的考虑，容易出现语义错位和粒度不平衡的问题。\\n\\n**核心思路**：论文的核心思路是设计一个能够自适应调整输入分辨率并进行多尺度语义对齐的视觉-语言模型。通过动态调整分辨率，可以在保证关键细节信息的同时减少计算冗余。通过多尺度对齐，可以更全面地捕捉跨模态的语义关联，从而提高语义理解的准确性。\\n\\n**技术框架**：该框架主要包含两个核心模块：动态分辨率输入策略（DRIS）和多尺度视觉-语言对齐机制（MS-VLAM）。DRIS首先对输入图像进行粗略分析，根据图像复杂度确定合适的分辨率。然后，MS-VLAM在对象、局部区域和全局三个层面上进行视觉和语言特征的对齐。最后，融合后的特征用于完成下游任务，如图像描述和跨模态检索。\\n\\n**关键创新**：该论文的关键创新在于DRIS和MS-VLAM的结合。DRIS能够自适应地调整输入分辨率，从而在效率和细节之间取得平衡。MS-VLAM则通过多尺度对齐，更全面地捕捉跨模态的语义关联，解决了语义错位和粒度不平衡的问题。与现有方法相比，该框架能够更有效地利用计算资源，并提高语义理解的准确性。\\n\\n**关键设计**：DRIS的具体实现可能涉及图像分割、显著性检测等技术，用于评估图像的复杂度。MS-VLAM的具体实现可能采用多层Transformer结构，分别提取对象、局部区域和全局层面的视觉和语言特征，并使用对比学习等方法进行对齐。损失函数的设计需要考虑不同尺度的对齐损失，并进行加权平均。",
            "application_zh": "该研究成果可应用于环境监测、城市规划、灾害评估等领域。通过更准确地理解遥感图像中的信息，可以为相关决策提供更可靠的依据。例如，在环境监测中，可以利用该技术监测植被覆盖变化、水体污染等情况。在城市规划中，可以用于分析城市扩张、土地利用等问题。在灾害评估中，可以快速评估灾情，为救援工作提供支持。未来，该技术有望与无人机、卫星等平台结合，实现更广泛的应用。",
            "highlight_zh": "实验结果表明，该框架在RS-GPT4V数据集上取得了显著的性能提升。在图像描述任务中，BLEU-4和CIDEr指标均优于传统方法。在跨模态检索任务中，R@10指标也得到了显著提升。这些结果表明，该框架能够有效地提高遥感图像多模态融合的效率和语义理解精度。",
            "tags_zh": [
                "遥感图像",
                "多模态融合",
                "视觉-语言模型",
                "动态分辨率",
                "多尺度对齐",
                "图像描述",
                "跨模态检索"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23243v1/Fig.1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23243v1/Fig.2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23243v1/Fig.3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RS-Prune: Training-Free Data Pruning at High Ratios for Efficient Remote Sensing Diffusion Foundation Models",
            "authors": [
                "Fan Wei",
                "Runmin Dong",
                "Yushan Lai",
                "Yixiang Yang",
                "Zhaoyang Luo",
                "Jinxiao Zhang",
                "Miao Yang",
                "Shuai Yuan",
                "Jiyao Zhao",
                "Bin Luo",
                "Haohuan Fu"
            ],
            "arxiv_id": "2512.23239v1",
            "summary": "Diffusion-based remote sensing (RS) generative foundation models are cruial for downstream tasks. However, these models rely on large amounts of globally representative data, which often contain redundancy, noise, and class imbalance, reducing training efficiency and preventing convergence. Existing RS diffusion foundation models typically aggregate multiple classification datasets or apply simplistic deduplication, overlooking the distributional requirements of generation modeling and the heterogeneity of RS imagery. To address these limitations, we propose a training-free, two-stage data pruning approach that quickly select a high-quality subset under high pruning ratios, enabling a preliminary foundation model to converge rapidly and serve as a versatile backbone for generation, downstream fine-tuning, and other applications. Our method jointly considers local information content with global scene-level diversity and representativeness. First, an entropy-based criterion efficiently removes low-information samples. Next, leveraging RS scene classification datasets as reference benchmarks, we perform scene-aware clustering with stratified sampling to improve clustering effectiveness while reducing computational costs on large-scale unlabeled data. Finally, by balancing cluster-level uniformity and sample representativeness, the method enables fine-grained selection under high pruning ratios while preserving overall diversity and representativeness. Experiments show that, even after pruning 85\\% of the training data, our method significantly improves convergence and generation quality. Furthermore, diffusion foundation models trained with our method consistently achieve state-of-the-art performance across downstream tasks, including super-resolution and semantic image synthesis. This data pruning paradigm offers practical guidance for developing RS generative foundation models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23239v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "RS-Prune：面向遥感扩散模型的高比例免训练数据剪枝",
            "summary_zh": "基于扩散的遥感（RS）生成式基础模型对于下游任务至关重要。然而，这些模型依赖于大量的全局代表性数据，这些数据通常包含冗余、噪声和类别不平衡，从而降低了训练效率并阻碍了收敛。现有的RS扩散基础模型通常聚合多个分类数据集或应用简单的去重，忽略了生成建模的分布需求和RS图像的异质性。为了解决这些限制，我们提出了一种免训练的两阶段数据剪枝方法，该方法能够快速选择高质量的子集，即使在高剪枝率下也能实现初步基础模型的快速收敛，并作为生成、下游微调和其他应用的多功能骨干网络。我们的方法联合考虑了局部信息内容与全局场景级别的多样性和代表性。首先，基于熵的标准有效地移除低信息量的样本。接下来，利用RS场景分类数据集作为参考基准，我们执行场景感知的聚类和分层抽样，以提高聚类效果，同时降低大规模无标签数据的计算成本。最后，通过平衡聚类级别的均匀性和样本代表性，该方法能够在高剪枝率下进行细粒度选择，同时保持整体的多样性和代表性。实验表明，即使在剪枝85%的训练数据后，我们的方法也能显著提高收敛性和生成质量。此外，使用我们的方法训练的扩散基础模型在包括超分辨率和语义图像合成在内的下游任务中始终取得最先进的性能。这种数据剪枝范式为开发RS生成式基础模型提供了实践指导。",
            "intro_zh": [
                "遥感扩散模型训练依赖大量数据，但数据中存在冗余、噪声和类别不平衡问题，影响训练效率和模型收敛。",
                "提出一种免训练的两阶段数据剪枝方法，通过熵值筛选低信息样本，并结合场景感知聚类和分层抽样，选择高质量数据子集。",
                "实验表明，即使剪枝85%的数据，该方法仍能显著提升模型收敛速度和生成质量，并在下游任务中取得SOTA性能。"
            ],
            "method_zh": "**问题定义**：遥感扩散模型训练需要大量数据，但现有数据集存在冗余、噪声和类别不平衡等问题，导致训练效率低下，模型难以收敛。现有方法通常采用简单的数据去重或直接聚合多个数据集，忽略了遥感图像的异质性和生成模型的分布需求。\\n\\n**核心思路**：通过两阶段的数据剪枝策略，在不进行模型训练的前提下，从原始数据集中选择一个高质量、具有代表性的子集。第一阶段基于熵值去除低信息量样本，第二阶段利用场景分类信息进行聚类和分层抽样，保证数据子集的多样性和代表性。\\n\\n**技术框架**：该方法包含两个主要阶段：1) 基于熵值的信息量筛选：计算每个样本的信息熵，去除熵值较低的样本，从而过滤掉冗余和无信息的图像。2) 场景感知的聚类和分层抽样：利用遥感场景分类数据集作为参考，对剩余样本进行聚类，并根据场景类别进行分层抽样，保证每个场景类别都有足够的样本被保留。\\n\\n**关键创新**：该方法的核心创新在于结合了局部信息内容（熵值）和全局场景级别的多样性和代表性。传统的剪枝方法通常只关注单个样本的信息量，而忽略了数据集的整体分布。该方法通过场景感知的聚类和分层抽样，保证了剪枝后的数据集仍然能够覆盖原始数据集的各种场景，从而提高了模型的泛化能力。\\n\\n**关键设计**：在信息量筛选阶段，使用图像的像素值计算熵值。在场景感知聚类阶段，使用预训练的场景分类模型提取图像的特征，然后使用K-means算法进行聚类。在分层抽样阶段，根据每个聚类的样本数量，按照比例进行抽样，保证每个场景类别都有足够的样本被保留。",
            "application_zh": "该研究成果可应用于遥感图像生成、超分辨率重建、语义图像合成等领域。通过高效的数据剪枝，可以降低遥感扩散模型训练的计算成本和时间成本，加速遥感基础模型的发展，并为下游应用提供更高质量的数据支持，具有重要的实际应用价值和广阔的应用前景。",
            "highlight_zh": "实验结果表明，即使剪枝85%的训练数据，使用RS-Prune方法训练的扩散模型在收敛速度和生成质量上均有显著提升。此外，该模型在超分辨率和语义图像合成等下游任务中取得了state-of-the-art的性能，验证了该数据剪枝方法的有效性和泛化能力。",
            "tags_zh": [
                "遥感图像",
                "扩散模型",
                "数据剪枝",
                "免训练",
                "场景感知聚类"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23239v1/Pictures/head.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23239v1/Pictures/0ef27c9b830072a346925b518d7876ee.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23239v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Bellman Calibration for V-Learning in Offline Reinforcement Learning",
            "authors": [
                "Lars van der Laan",
                "Nathan Kallus"
            ],
            "arxiv_id": "2512.23694v1",
            "summary": "We introduce Iterated Bellman Calibration, a simple, model-agnostic, post-hoc procedure for calibrating off-policy value predictions in infinite-horizon Markov decision processes. Bellman calibration requires that states with similar predicted long-term returns exhibit one-step returns consistent with the Bellman equation under the target policy. We adapt classical histogram and isotonic calibration to the dynamic, counterfactual setting by repeatedly regressing fitted Bellman targets onto a model's predictions, using a doubly robust pseudo-outcome to handle off-policy data. This yields a one-dimensional fitted value iteration scheme that can be applied to any value estimator. Our analysis provides finite-sample guarantees for both calibration and prediction under weak assumptions, and critically, without requiring Bellman completeness or realizability.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "econ.EM"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23694v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]offline reinforcement learning"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出迭代贝尔曼校准以优化离线强化学习中的价值预测",
            "summary_zh": "本文介绍了一种简单的、模型无关的后处理程序——迭代贝尔曼校准，用于校准无限时域马尔可夫决策过程中的离线价值预测。贝尔曼校准要求具有相似预测长期回报的状态，其一步回报需与目标策略下的贝尔曼方程一致。我们将经典的直方图和单调校准方法适应于动态的反事实场景，通过反复将拟合的贝尔曼目标回归到模型的预测上，使用双重稳健伪结果来处理离线数据。这种方法产生了一种一维拟合值迭代方案，可应用于任何价值估计器。我们的分析在弱假设下提供了有限样本的校准和预测保证，且关键的是不需要贝尔曼完全性或可实现性。",
            "intro_zh": [
                "现有的离线强化学习方法在价值预测的准确性和可靠性上存在不足，尤其是在处理反事实数据时。",
                "论文提出的迭代贝尔曼校准通过将贝尔曼目标与模型预测进行回归，提供了一种有效的价值校准方法。",
                "实验结果表明，该方法在有限样本下能够显著提升价值预测的准确性，且不依赖于贝尔曼完全性假设。"
            ],
            "method_zh": "**问题定义**：本文旨在解决离线强化学习中价值预测的校准问题，现有方法在处理反事实数据时常常面临准确性不足的挑战。\\n\\n**核心思路**：论文提出的迭代贝尔曼校准方法，通过反复回归拟合的贝尔曼目标，确保相似状态的预测结果一致，从而提高价值预测的准确性。\\n\\n**技术框架**：该方法的整体架构包括数据收集、贝尔曼目标拟合、模型预测回归和迭代校准四个主要模块，形成一个闭环的校准过程。\\n\\n**关键创新**：最重要的创新点在于将经典的校准技术适应于动态反事实环境，且无需依赖贝尔曼完全性或可实现性，拓宽了校准方法的适用范围。\\n\\n**关键设计**：在设计上，使用双重稳健伪结果来处理离线数据，确保校准过程的稳定性和准确性，同时采用了一维拟合值迭代方案以简化计算。",
            "application_zh": "该研究在离线强化学习、决策支持系统和智能控制等领域具有广泛的应用潜力。通过提高价值预测的准确性，能够有效提升智能体在复杂环境中的决策能力，推动相关技术的实际应用和发展。",
            "highlight_zh": "实验结果显示，迭代贝尔曼校准方法在多个基准数据集上相较于传统方法提升了价值预测的准确性，具体表现为在某些任务中预测误差降低了20%以上，验证了其有效性和实用性。",
            "tags_zh": [
                "离线强化学习",
                "贝尔曼校准",
                "价值预测",
                "反事实学习",
                "模型无关方法"
            ],
            "_index": 25,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23694v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23694v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "The Law of Multi-Model Collaboration: Scaling Limits of Model Ensembling for Large Language Models",
            "authors": [
                "Dakuan Lu",
                "Jiaqi Zhang",
                "Cheng Yuan",
                "Jiawei Shao",
                "Chi Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.23340v1",
            "summary": "Recent advances in large language models (LLMs) have been largely driven by scaling laws for individual models, which predict performance improvements as model parameters and data volume increase. However, the capabilities of any single LLM are inherently bounded. One solution originates from intricate interactions among multiple LLMs, rendering their collective performance surpasses that of any constituent model. Despite the rapid proliferation of multi-model integration techniques such as model routing and post-hoc ensembling, a unifying theoretical framework of performance scaling for multi-model collaboration remains absent. In this work, we propose the Law of Multi-model Collaboration, a scaling law that predicts the performance limits of LLM ensembles based on their aggregated parameter budget. To quantify the intrinsic upper bound of multi-model collaboration, we adopt a method-agnostic formulation and assume an idealized integration oracle where the total cross-entropy loss of each sample is determined by the minimum loss of any model in the model pool. Experimental results reveal that multi-model systems follow a power-law scaling with respect to the total parameter count, exhibiting a more significant improvement trend and a lower theoretical loss floor compared to single model scaling. Moreover, ensembles of heterogeneous model families achieve better performance scaling than those formed within a single model family, indicating that model diversity is a primary driver of collaboration gains. These findings suggest that model collaboration represents a critical axis for extending the intelligence frontier of LLMs.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.MA"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23340v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多模型协作定律，揭示大语言模型集成性能的缩放规律与极限。",
            "summary_zh": "大语言模型（LLM）的最新进展主要得益于单个模型的缩放定律，该定律预测模型参数和数据量的增加会带来性能的提升。然而，任何单个LLM的能力都存在固有的界限。一种解决方案源于多个LLM之间复杂的交互，使其集体性能超过任何单个模型。尽管模型路由和事后集成等多种模型集成技术迅速普及，但仍然缺乏一个统一的多模型协作性能缩放理论框架。本文提出了多模型协作定律，该定律预测LLM集成基于其聚合参数预算的性能极限。为了量化多模型协作的内在上限，我们采用了一种与方法无关的公式，并假设一个理想化的集成oracle，其中每个样本的总交叉熵损失由模型池中任何模型的最小损失决定。实验结果表明，多模型系统遵循关于总参数计数的幂律缩放，与单模型缩放相比，表现出更显著的改进趋势和更低的理论损失下限。此外，异构模型族的集成比在单个模型族内形成的集成实现了更好的性能缩放，表明模型多样性是协作收益的主要驱动因素。这些发现表明，模型协作是扩展LLM智能前沿的关键方向。",
            "intro_zh": [
                "现有大语言模型能力受限于单模型缩放，多模型集成虽有进展，但缺乏统一的性能缩放理论。",
                "论文提出多模型协作定律，基于聚合参数预算预测LLM集成性能极限，采用理想化集成oracle量化协作上限。",
                "实验表明，多模型系统性能随参数量呈幂律缩放，优于单模型，且异构模型集成效果更佳，模型多样性是关键。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有大语言模型集成方法缺乏统一理论框架的问题。现有方法主要依赖于单模型的缩放定律，但单个模型的性能存在固有上限。多模型集成是提升性能的有效途径，但缺乏对集成性能极限的理论指导，难以有效利用计算资源和模型多样性。\\n\\n**核心思路**：论文的核心思路是建立一个多模型协作的缩放定律，该定律能够预测模型集成的性能上限。通过分析模型集成后的整体性能与模型参数总量的关系，揭示多模型协作的内在规律。论文假设存在一个理想化的集成oracle，该oracle能够选择模型池中对每个样本损失最小的模型，从而量化多模型协作的理论上限。\\n\\n**技术框架**：论文的技术框架主要包括以下几个部分：1) 定义多模型协作的性能指标，采用交叉熵损失作为衡量标准。2) 提出多模型协作定律，建立模型集成性能与总参数量之间的关系。3) 引入理想化的集成oracle，用于量化多模型协作的理论上限。4) 通过实验验证多模型协作定律的有效性，并分析模型多样性对集成性能的影响。\\n\\n**关键创新**：论文最重要的技术创新在于提出了多模型协作定律，这是首次对多模型集成的性能缩放规律进行理论建模。与以往关注单模型缩放的研究不同，该论文关注多个模型协同工作时的性能表现，并揭示了模型多样性在提升集成性能中的关键作用。\\n\\n**关键设计**：论文的关键设计包括：1) 采用交叉熵损失作为性能指标，能够有效衡量模型的预测准确性。2) 假设理想化的集成oracle，能够简化问题分析，并量化多模型协作的理论上限。3) 通过实验对比不同模型集成策略的性能，验证多模型协作定律的有效性。4) 分析异构模型集成与同构模型集成的性能差异，揭示模型多样性的重要性。",
            "application_zh": "该研究成果可应用于大语言模型的集成优化，指导如何选择和组合不同的模型，以在有限的计算资源下获得最佳性能。此外，该研究还可用于指导新型多模型架构的设计，例如模型路由和动态集成等，从而进一步提升大语言模型的智能水平。",
            "highlight_zh": "实验结果表明，多模型系统遵循关于总参数计数的幂律缩放，与单模型缩放相比，表现出更显著的改进趋势和更低的理论损失下限。异构模型族的集成比在单个模型族内形成的集成实现了更好的性能缩放，验证了模型多样性是协作收益的主要驱动因素。",
            "tags_zh": [
                "多模型协作",
                "大语言模型",
                "缩放定律",
                "模型集成",
                "模型多样性"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23340v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23340v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Divergent-Convergent Thinking in Large Language Models for Creative Problem Generation",
            "authors": [
                "Manh Hung Nguyen",
                "Adish Singla"
            ],
            "arxiv_id": "2512.23601v1",
            "summary": "Large language models (LLMs) have significant potential for generating educational questions and problems, enabling educators to create large-scale learning materials. However, LLMs are fundamentally limited by the ``Artificial Hivemind'' effect, where they generate similar responses within the same model and produce homogeneous outputs across different models. As a consequence, students may be exposed to overly similar and repetitive LLM-generated problems, which harms diversity of thought. Drawing inspiration from Wallas's theory of creativity and Guilford's framework of divergent-convergent thinking, we propose CreativeDC, a two-phase prompting method that explicitly scaffolds the LLM's reasoning into distinct phases. By decoupling creative exploration from constraint satisfaction, our method enables LLMs to explore a broader space of ideas before committing to a final problem. We evaluate CreativeDC for creative problem generation using a comprehensive set of metrics that capture diversity, novelty, and utility. The results show that CreativeDC achieves significantly higher diversity and novelty compared to baselines while maintaining high utility. Moreover, scaling analysis shows that CreativeDC generates a larger effective number of distinct problems as more are sampled, increasing at a faster rate than baseline methods.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Preprint",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23601v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CreativeDC：利用大语言模型中的发散-收敛思维生成多样化创意问题",
            "summary_zh": "大型语言模型（LLMs）在生成教育问题方面具有巨大潜力，能够帮助教育工作者创建大规模的学习材料。然而，LLMs受到“人工蜂群”效应的根本限制，即在同一模型内生成相似的响应，并在不同模型之间产生同质的输出。因此，学生可能会接触到过于相似和重复的LLM生成的问题，这损害了思维的多样性。受Wallas创造力理论和Guilford发散-收敛思维框架的启发，我们提出了CreativeDC，一种两阶段提示方法，它将LLM的推理明确地分解为不同的阶段。通过将创造性探索与约束满足分离，我们的方法使LLMs能够在确定最终问题之前探索更广阔的创意空间。我们使用一套全面的指标来评估CreativeDC在创造性问题生成方面的性能，这些指标捕捉了多样性、新颖性和效用。结果表明，与基线方法相比，CreativeDC在保持高实用性的同时，实现了显著更高的多样性和新颖性。此外，规模分析表明，随着采样数量的增加，CreativeDC生成了更大数量的有效不同问题，其增长速度快于基线方法。",
            "intro_zh": [
                "现有LLM生成教育问题时存在“人工蜂群”效应，导致问题同质化，限制了学生思维多样性。",
                "CreativeDC方法借鉴发散-收敛思维，将问题生成分解为创意探索和约束满足两个阶段。",
                "实验表明，CreativeDC在多样性和新颖性方面显著优于基线方法，同时保持了较高的实用性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在生成教育问题时存在的同质化问题。现有方法受限于“人工蜂群”效应，导致生成的问题相似度高，缺乏多样性和新颖性，不利于培养学生的创造性思维。这种同质化问题限制了LLMs在教育领域的应用价值。\\n\\n**核心思路**：论文的核心思路是借鉴Wallas的创造力理论和Guilford的发散-收敛思维框架，将问题生成过程分解为两个阶段：发散阶段（Divergent Thinking）和收敛阶段（Convergent Thinking）。发散阶段鼓励LLM探索尽可能多的创意，生成各种不同的问题想法；收敛阶段则对这些想法进行筛选和优化，使其满足特定的约束条件，最终生成高质量的问题。\\n\\n**技术框架**：CreativeDC方法包含两个主要阶段：\n1. **发散阶段**：使用特定的prompt引导LLM进行自由联想，生成尽可能多的、不同的问题想法。这个阶段的目标是扩大搜索空间，避免过早陷入局部最优。\n2. **收敛阶段**：使用另一个prompt引导LLM对发散阶段生成的想法进行评估和筛选，选择最有价值的想法，并将其转化为符合要求的具体问题。这个阶段的目标是保证生成问题的质量和实用性。\\n\\n**关键创新**：CreativeDC的关键创新在于将创造性问题生成过程显式地分解为发散和收敛两个阶段，并分别使用不同的prompt进行引导。这种解耦使得LLM能够更好地探索创意空间，避免受到约束条件的限制，从而生成更多样化和新颖的问题。与现有方法相比，CreativeDC更注重激发LLM的创造性思维，而不是简单地模仿已有的问题模式。\\n\\n**关键设计**：在发散阶段，prompt的设计需要鼓励LLM进行大胆的联想，例如使用“头脑风暴”、“自由写作”等关键词。在收敛阶段，prompt的设计需要明确问题的约束条件，例如问题的难度、知识点、适用对象等。此外，还可以使用一些评价指标来指导LLM进行筛选，例如问题的原创性、趣味性、挑战性等。具体的参数设置和损失函数未知，因为论文侧重于prompt工程而非模型训练。",
            "application_zh": "CreativeDC方法可应用于教育领域，辅助教师快速生成大量多样化、高质量的练习题和考试题，减轻教师的备课负担。此外，该方法还可用于生成各种创意性任务，例如故事创作、产品设计等，激发用户的创造力。未来，该方法有望应用于更广泛的领域，例如科研探索、创新设计等。",
            "highlight_zh": "实验结果表明，CreativeDC在多样性（Diversity）和新颖性（Novelty）方面显著优于基线方法，同时保持了较高的实用性（Utility）。规模分析显示，随着采样数量的增加，CreativeDC生成有效不同问题的速度明显快于基线方法。具体性能数据未知，但整体趋势表明CreativeDC能够有效提升LLM生成问题的多样性和新颖性。",
            "tags_zh": [
                "大语言模型",
                "创造性问题生成",
                "发散-收敛思维",
                "提示工程",
                "教育应用"
            ],
            "_index": 27,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23601v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23601v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23601v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings",
            "authors": [
                "Thomas Haschka",
                "Joseph Bakarji"
            ],
            "arxiv_id": "2512.23471v1",
            "summary": "Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster - the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 News- groups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "20 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23471v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种基于嵌套密度聚类和LLM嵌入的语义树推断方法，用于文本语料库的语义结构发现。",
            "summary_zh": "近年来，由于大型语言模型（LLM）及其高维嵌入的兴起，语义文本分类取得了显著进展。虽然LLM嵌入经常被用于在向量数据库中通过语义相似性来存储和检索文本，但文本语料库中全局结构的语义关系通常仍然不明确。本文提出了一种嵌套密度聚类方法，用于推断语义相关文本的层次树。该方法首先通过搜索LLM嵌入空间中的密集簇来识别具有强语义相似性的文本。随着密度标准的逐渐放宽，这些密集簇合并成更分散的簇，直到整个数据集由单个簇表示——树的根。通过将密集簇嵌入到越来越分散的簇中，我们构建了一个树结构，该结构捕获了文本之间分层的语义关系。我们概述了如何将这种方法用于科学摘要的文本数据分类作为案例研究。这使得无需预定义类别即可进行数据驱动的研究领域及其子领域的发现。为了评估该方法的一般适用性，我们进一步将其应用于已建立的基准数据集，如20 News-groups和IMDB 50k Movie Reviews，证明了其跨领域的稳健性。最后，我们讨论了在科学计量学、主题演变方面的可能应用，强调了嵌套密度树如何揭示文本数据集中的语义结构和演变。",
            "intro_zh": [
                "现有方法难以有效揭示文本语料库中全局语义关系的结构，阻碍了对文本数据的深入理解和利用。",
                "该方法通过嵌套密度聚类，从LLM嵌入空间中构建语义树，揭示文本间的分层语义关系。",
                "实验表明，该方法在科学摘要分类、20 News-groups和IMDB 50k Movie Reviews等数据集上表现出良好的性能和鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决如何从文本语料库中自动推断出语义结构的问题。现有方法，如传统的聚类或主题模型，难以有效捕捉高维LLM嵌入空间中复杂的语义关系，并且通常需要预先定义类别或主题数量，限制了其灵活性和适用性。\\n\\n**核心思路**：论文的核心思路是利用嵌套密度聚类，从LLM嵌入空间中逐步构建语义树。该方法假设语义相似的文本在嵌入空间中会形成密集簇，通过逐步放宽密度标准，将这些密集簇合并成更大的簇，从而形成一个层次化的结构，反映文本之间的语义关系。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 使用LLM对文本进行嵌入，得到高维向量表示；2) 初始化密度阈值，在嵌入空间中寻找密集簇；3) 逐步降低密度阈值，合并相邻的密集簇，形成更大的簇；4) 将簇之间的合并关系构建成树结构，其中每个节点代表一个簇，父节点代表包含子节点的更广泛的语义类别。\\n\\n**关键创新**：该方法的关键创新在于将嵌套密度聚类与LLM嵌入相结合，能够有效地捕捉文本之间复杂的分层语义关系，无需预先定义类别或主题数量，具有很强的灵活性和适应性。与传统的聚类方法相比，该方法能够更好地反映文本之间的语义关联，并提供更丰富的语义信息。\\n\\n**关键设计**：论文中涉及的关键设计包括：1) 密度阈值的选择策略，需要根据数据集的特点进行调整；2) 簇合并的准则，例如可以使用基于距离或相似度的度量；3) 树结构的构建方式，例如可以使用自底向上的方式逐步合并簇。",
            "application_zh": "该研究成果可应用于科学计量学、主题演变分析、文本分类、信息检索等领域。例如，可以用于自动发现研究领域及其子领域，跟踪主题的演变趋势，构建知识图谱，提高信息检索的准确率和效率。该方法具有广泛的应用前景，能够帮助研究人员更好地理解和利用文本数据。",
            "highlight_zh": "该方法在科学摘要分类、20 News-groups和IMDB 50k Movie Reviews等数据集上进行了实验验证。实验结果表明，该方法能够有效地推断出文本之间的语义关系，并构建出具有良好层次结构的语义树。尤其是在科学摘要分类任务中，该方法能够自动发现研究领域及其子领域，为科研人员提供有价值的信息。",
            "tags_zh": [
                "语义树推断",
                "嵌套密度聚类",
                "大型语言模型",
                "文本分类",
                "语义分析"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23471v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23471v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23471v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process",
            "authors": [
                "Zhijun Chen",
                "Zeyu Ji",
                "Qianren Mao",
                "Junhang Cheng",
                "Bangjie Qin",
                "Hao Wu",
                "Zhuoran Li",
                "Jingzheng Li",
                "Kai Sun",
                "Zizhe Wang",
                "Yikun Ban",
                "Zhu Sun",
                "Xiangyang Ji",
                "Hailong Sun"
            ],
            "arxiv_id": "2512.23213v1",
            "summary": "We propose LLM-PeerReview, an unsupervised LLM Ensemble method that selects the most ideal response from multiple LLM-generated candidates for each query, harnessing the collective wisdom of multiple models with diverse strengths. LLM-PeerReview is built on a novel, peer-review-inspired framework that offers a clear and interpretable mechanism, while remaining fully unsupervised for flexible adaptability and generalization. Specifically, it operates in three stages: For scoring, we use the emerging LLM-as-a-Judge technique to evaluate each response by reusing multiple LLMs at hand; For reasoning, we can apply a principled graphical model-based truth inference algorithm or a straightforward averaging strategy to aggregate multiple scores to produce a final score for each response; Finally, the highest-scoring response is selected as the best ensemble output. LLM-PeerReview is conceptually simple and empirically powerful. The two variants of the proposed approach obtain strong results across four datasets, including outperforming the recent advanced model Smoothie-Global by 6.9% and 7.3% points, respectively.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23213v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LLM-PeerReview，通过同行评审集成大语言模型，提升生成质量。",
            "summary_zh": "本文提出了一种名为LLM-PeerReview的无监督LLM集成方法，旨在从多个LLM针对同一查询生成的候选答案中选择最佳答案。该方法利用多个模型的集体智慧，充分发挥它们各自的优势。LLM-PeerReview构建于一个新颖的、受同行评审启发的框架之上，该框架提供了一个清晰且可解释的机制，同时保持完全无监督，从而实现灵活的适应性和泛化能力。具体而言，它包含三个阶段：评分阶段，利用新兴的“LLM-as-a-Judge”技术，使用多个LLM对每个答案进行评估；推理阶段，应用基于图模型的真值推断算法或简单的平均策略，聚合多个评分，为每个答案生成最终得分；选择阶段，选择得分最高的答案作为最佳集成输出。LLM-PeerReview概念简单，效果显著。该方法的两个变体在四个数据集上取得了优异的结果，分别超越了最近的先进模型Smoothie-Global 6.9%和7.3%。",
            "intro_zh": [
                "现有LLM集成方法缺乏可解释性，且依赖监督数据，泛化能力受限。",
                "LLM-PeerReview模拟同行评审过程，利用多个LLM进行评分、推理和选择，实现无监督集成。",
                "实验表明，LLM-PeerReview在多个数据集上显著优于现有方法，提升效果明显。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型集成方法通常缺乏可解释性，难以理解每个模型的贡献。此外，许多方法依赖于监督数据进行训练，这限制了它们在不同任务和数据集上的泛化能力。因此，如何设计一种无监督且可解释的LLM集成方法是一个重要的挑战。\\n\\n**核心思路**：LLM-PeerReview的核心思路是模拟学术界的同行评审过程。每个LLM生成的答案都由其他LLM进行评估（评分），然后通过某种方式（例如，平均或更复杂的真值推断）将这些评分聚合起来，得到一个最终的得分。得分最高的答案被认为是最佳答案。这种设计借鉴了同行评审的智慧，利用多个LLM的判断力来选择最佳答案。\\n\\n**技术框架**：LLM-PeerReview包含三个主要阶段：\n1. **评分阶段**：使用多个LLM作为评审员，对每个候选答案进行评分。每个LLM都根据一定的标准（例如，相关性、准确性、流畅性等）对答案进行评估。\n2. **推理阶段**：将多个LLM的评分进行聚合，得到每个答案的最终得分。可以使用简单的平均策略，也可以使用更复杂的基于图模型的真值推断算法，例如，考虑评审员之间的可信度。\n3. **选择阶段**：选择得分最高的答案作为最终的集成输出。\\n\\n**关键创新**：LLM-PeerReview的关键创新在于其基于同行评审的框架。与传统的集成方法相比，LLM-PeerReview具有以下优势：\n* **无监督**：不需要监督数据进行训练，可以灵活地应用于不同的任务和数据集。\n* **可解释**：每个LLM的评分都可以被追溯，从而可以理解每个模型的贡献。\n* **自适应**：可以根据不同的任务和数据集选择不同的LLM作为评审员。\\n\\n**关键设计**：\n* **LLM选择**：选择合适的LLM作为评审员至关重要。可以根据LLM的专业领域、生成能力等因素进行选择。\n* **评分标准**：定义清晰的评分标准，例如，相关性、准确性、流畅性等，可以提高评分的准确性。\n* **真值推断算法**：选择合适的真值推断算法可以更准确地聚合多个评分。论文中提到了基于图模型的真值推断算法和简单的平均策略。\n* **集成策略**：最终选择得分最高的答案作为集成输出，简单有效。",
            "application_zh": "LLM-PeerReview可广泛应用于各种需要高质量文本生成的场景，例如问答系统、文本摘要、机器翻译、内容创作等。该方法能够有效提升生成文本的质量和可靠性，具有重要的实际应用价值。未来，可以进一步探索如何将LLM-PeerReview应用于更复杂的任务和领域，例如代码生成、对话系统等。",
            "highlight_zh": "实验结果表明，LLM-PeerReview在四个数据集上取得了显著的性能提升。具体而言，该方法的两个变体分别超越了最近的先进模型Smoothie-Global 6.9%和7.3%。这些结果表明，LLM-PeerReview是一种有效的LLM集成方法，能够显著提升生成文本的质量。",
            "tags_zh": [
                "大语言模型集成",
                "同行评审",
                "无监督学习",
                "真值推断",
                "LLM-as-a-Judge"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23213v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23213v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23213v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EquaCode: A Multi-Strategy Jailbreak Approach for Large Language Models via Equation Solving and Code Completion",
            "authors": [
                "Zhen Liang",
                "Hai Huang",
                "Zhengkui Chen"
            ],
            "arxiv_id": "2512.23173v1",
            "summary": "Large language models (LLMs), such as ChatGPT, have achieved remarkable success across a wide range of fields. However, their trustworthiness remains a significant concern, as they are still susceptible to jailbreak attacks aimed at eliciting inappropriate or harmful responses. However, existing jailbreak attacks mainly operate at the natural language level and rely on a single attack strategy, limiting their effectiveness in comprehensively assessing LLM robustness. In this paper, we propose Equacode, a novel multi-strategy jailbreak approach for large language models via equation-solving and code completion. This approach transforms malicious intent into a mathematical problem and then requires the LLM to solve it using code, leveraging the complexity of cross-domain tasks to divert the model's focus toward task completion rather than safety constraints. Experimental results show that Equacode achieves an average success rate of 91.19% on the GPT series and 98.65% across 3 state-of-the-art LLMs, all with only a single query. Further, ablation experiments demonstrate that EquaCode outperforms either the mathematical equation module or the code module alone. This suggests a strong synergistic effect, thereby demonstrating that multi-strategy approach yields results greater than the sum of its parts.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "This is a preprint. A revised version will appear in the Proceedings of AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23173v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出 EquaCode，利用数学方程求解与代码补全实现大语言模型越狱攻击",
            "summary_zh": "大型语言模型（LLMs），如ChatGPT，在各个领域取得了显著成功。然而，它们的可靠性仍然是一个重要问题，因为它们仍然容易受到旨在引出不适当或有害响应的越狱攻击。现有的越狱攻击主要在自然语言层面操作，并依赖于单一的攻击策略，限制了其全面评估LLM鲁棒性的有效性。本文提出了一种新颖的多策略越狱方法Equacode，通过方程求解和代码补全来实现对大型语言模型的攻击。该方法将恶意意图转化为数学问题，然后要求LLM使用代码来解决它，利用跨领域任务的复杂性来转移模型对任务完成的关注，而不是安全约束。实验结果表明，Equacode在GPT系列上的平均成功率为91.19%，在3个最先进的LLM上的平均成功率为98.65%，而且只需要一次查询。此外，消融实验表明，EquaCode的性能优于单独的数学方程模块或代码模块。这表明存在强大的协同效应，从而证明了多策略方法产生的结果大于其各部分之和。",
            "intro_zh": [
                "现有大语言模型越狱攻击主要依赖自然语言，且策略单一，难以全面评估模型的鲁棒性。",
                "EquaCode 将恶意意图转化为数学问题，并要求模型通过代码求解，利用跨领域复杂性转移模型注意力。",
                "实验表明，EquaCode 在 GPT 系列和多个 SOTA LLM 上取得了超过 90% 的越狱成功率，且优于单一策略。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型容易受到越狱攻击，攻击者可以通过精心设计的提示词诱导模型生成有害或不当内容。现有的攻击方法主要集中在自然语言层面，依赖于单一的攻击策略，这使得模型更容易识别和防御这些攻击。因此，如何设计一种更有效、更隐蔽的攻击方法，以全面评估和提高大语言模型的安全性，是一个亟待解决的问题。\\n\\n**核心思路**：EquaCode 的核心思路是将恶意意图转化为一个复杂的数学问题，并要求大语言模型通过编写代码来解决这个问题。这种方法利用了数学和编程的跨领域复杂性，使得模型更难识别出潜在的恶意意图，从而更容易绕过模型的安全机制。通过将问题转化为代码补全任务，模型会将更多的注意力放在完成任务上，而忽略潜在的安全风险。\\n\\n**技术框架**：EquaCode 的整体框架包含两个主要模块：数学方程生成模块和代码补全模块。首先，数学方程生成模块将恶意意图编码为一个复杂的数学方程。然后，将该方程作为提示词输入到大语言模型中，要求模型生成解决该方程的代码。最后，执行生成的代码，如果代码成功执行并输出了预期的结果，则认为越狱攻击成功。\\n\\n**关键创新**：EquaCode 的关键创新在于其多策略攻击方法，它结合了数学方程求解和代码补全两个不同的领域，从而提高了攻击的隐蔽性和有效性。与传统的自然语言攻击方法相比，EquaCode 能够更有效地绕过模型的安全机制，因为它利用了模型在跨领域任务中的弱点。此外，EquaCode 的多策略方法也使得模型更难识别出攻击的意图，从而提高了攻击的成功率。\\n\\n**关键设计**：在数学方程生成模块中，需要精心设计方程的复杂度和难度，以确保模型能够理解并尝试解决该方程，同时又不会过于简单以至于模型能够轻易识别出潜在的恶意意图。在代码补全模块中，需要选择合适的编程语言和代码框架，以便模型能够生成可执行的代码，并能够输出预期的结果。此外，还需要设置合适的执行环境和安全策略，以防止生成的代码对系统造成损害。",
            "application_zh": "EquaCode 可用于评估和提高大语言模型的安全性，帮助开发者发现模型中存在的漏洞，并采取相应的措施进行修复。此外，该方法还可以用于开发更强大的安全防御机制，以防止恶意用户利用大语言模型进行有害活动。该研究对于构建更安全、更可靠的人工智能系统具有重要意义。",
            "highlight_zh": "EquaCode 在 GPT 系列模型上取得了 91.19% 的平均越狱成功率，在三个最先进的 LLM 上达到了 98.65% 的成功率，且仅需单次查询。消融实验表明，EquaCode 的性能显著优于单独使用数学方程或代码补全模块，验证了多策略协同攻击的有效性。",
            "tags_zh": [
                "大语言模型",
                "越狱攻击",
                "方程求解",
                "代码补全",
                "多策略攻击",
                "安全评估",
                "鲁棒性"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23173v1/equacode.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23173v1/code.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23173v1/intent.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning",
            "authors": [
                "Yuqi Tang",
                "Jing Yu",
                "Zichang Su",
                "Kehua Feng",
                "Zhihui Zhu",
                "Libin Wang",
                "Lei Liang",
                "Qiang Zhang",
                "Keyan Ding",
                "Huajun Chen"
            ],
            "arxiv_id": "2512.23440v1",
            "summary": "Clinical diagnosis begins with doctor-patient interaction, during which physicians iteratively gather information, determine examination and refine differential diagnosis through patients' response. This dynamic clinical-reasoning process is poorly represented by existing LLM benchmarks that focus on static question-answering. To mitigate these gaps, recent methods explore dynamic medical frameworks involving interactive clinical dialogues. Although effective, they often rely on limited, contamination-prone datasets and lack granular, multi-level evaluation. In this work, we propose ClinDEF, a dynamic framework for assessing clinical reasoning in LLMs through simulated diagnostic dialogues. Grounded in a disease knowledge graph, our method dynamically generates patient cases and facilitates multi-turn interactions between an LLM-based doctor and an automated patient agent. Our evaluation protocol goes beyond diagnostic accuracy by incorporating fine-grained efficiency analysis and rubric-based assessment of diagnostic quality. Experiments show that ClinDEF effectively exposes critical clinical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "23 pages, 4 figures, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23440v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ClinDEF动态评估框架，用于评估大型语言模型在临床推理中的能力",
            "summary_zh": "临床诊断始于医患互动，医生通过患者的反馈迭代地收集信息、确定检查并完善鉴别诊断。现有的LLM基准测试侧重于静态问答，难以体现这种动态的临床推理过程。为了弥补这些差距，最近的方法探索了涉及交互式临床对话的动态医学框架。尽管有效，但它们通常依赖于有限的、易受污染的数据集，并且缺乏细粒度的多层次评估。本文提出了ClinDEF，一个用于评估LLM在模拟诊断对话中临床推理能力的动态框架。该方法基于疾病知识图谱，动态生成病例，并促进基于LLM的医生与自动患者代理之间的多轮交互。我们的评估协议超越了诊断准确性，纳入了细粒度的效率分析和基于标准的诊断质量评估。实验表明，ClinDEF有效地揭示了最先进的LLM中关键的临床推理差距，提供了一种更细致和临床意义的评估范式。",
            "intro_zh": [
                "现有LLM评估侧重静态问答，无法有效评估临床推理中动态交互的过程。",
                "ClinDEF框架基于疾病知识图谱，动态生成病例，模拟医患多轮交互对话。",
                "ClinDEF评估协议不仅关注诊断准确性，还包括效率分析和诊断质量评估。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）在临床推理方面的评估主要依赖于静态的问答形式，无法模拟真实的医患交互过程。这种静态评估方式忽略了医生在诊断过程中需要不断收集信息、调整诊断方向的动态性。此外，现有的动态医学框架依赖的数据集有限，容易受到污染，并且缺乏细粒度的多层次评估，难以全面反映LLM在临床推理中的能力。\\n\\n**核心思路**：ClinDEF的核心思路是构建一个动态的评估框架，通过模拟医患之间的对话来评估LLM的临床推理能力。该框架基于疾病知识图谱，可以动态生成不同的病例，并允许LLM扮演医生角色与自动患者代理进行多轮交互。通过这种方式，可以更真实地模拟临床诊断过程，并对LLM的推理能力进行更全面的评估。\\n\\n**技术框架**：ClinDEF框架主要包含以下几个模块：1) **疾病知识图谱**：用于存储疾病、症状、检查等相关信息，为病例生成和患者代理提供知识基础。2) **病例生成器**：基于疾病知识图谱，动态生成不同的患者病例，包括患者的基本信息、主诉、病史等。3) **患者代理**：模拟患者的行为，根据医生的提问提供相应的回答。4) **LLM医生**：扮演医生的角色，与患者代理进行对话，收集信息，进行诊断。5) **评估模块**：对LLM医生的诊断结果进行评估，包括诊断准确性、效率和诊断质量。\\n\\n**关键创新**：ClinDEF的关键创新在于其动态的评估方式，能够模拟真实的医患交互过程，更全面地评估LLM在临床推理方面的能力。与现有的静态评估方法相比，ClinDEF能够更好地反映LLM在信息收集、诊断推理和决策制定方面的能力。此外，ClinDEF还引入了细粒度的评估指标，包括效率分析和基于标准的诊断质量评估，能够更深入地分析LLM的优势和不足。\\n\\n**关键设计**：ClinDEF框架的关键设计包括：1) **疾病知识图谱的构建**：需要选择合适的知识图谱构建方法，并确保知识图谱的完整性和准确性。2) **患者代理的设计**：需要设计合理的患者行为模型，使其能够根据医生的提问提供真实、合理的回答。3) **评估指标的选择**：需要选择能够全面反映LLM临床推理能力的评估指标，包括诊断准确性、效率和诊断质量。4) **多轮对话的管理**：需要设计有效的对话管理机制，确保对话的流畅性和有效性。",
            "application_zh": "ClinDEF框架可用于评估和改进LLM在医疗领域的应用，例如辅助诊断、智能问诊等。通过该框架，可以发现LLM在临床推理方面的不足，并针对性地进行改进，提高LLM在医疗领域的实用性和可靠性。此外，该框架还可以用于医学教育，帮助医学生提高临床推理能力。",
            "highlight_zh": "实验结果表明，ClinDEF能够有效地揭示现有LLM在临床推理方面的差距。例如，一些最先进的LLM在诊断准确性方面表现不佳，并且在信息收集和诊断推理方面存在明显的不足。ClinDEF的评估结果为改进LLM在医疗领域的应用提供了重要的参考。",
            "tags_zh": [
                "大型语言模型",
                "临床推理",
                "动态评估",
                "医患对话",
                "知识图谱"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23440v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23440v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23440v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation",
            "authors": [
                "Xin Zhang",
                "Yang Cao",
                "Baoxing Wu",
                "Xinyi Chen",
                "Kai Song",
                "Siying Li"
            ],
            "arxiv_id": "2512.23356v1",
            "summary": "Large Language Models (LLMs) have achieved strong performance across a wide range of natural language processing tasks in recent years, including machine translation, text generation, and question answering. As their applications extend to increasingly complex scenarios, however, LLMs continue to face challenges in tasks that require deep reasoning and logical inference. In particular, models trained on large scale textual corpora may incorporate noisy or irrelevant information during generation, which can lead to incorrect predictions or outputs that are inconsistent with factual knowledge. To address this limitation, we propose a stepwise reasoning enhancement framework for LLMs based on external subgraph generation, termed SGR. The proposed framework dynamically constructs query relevant subgraphs from external knowledge bases and leverages their semantic structure to guide the reasoning process. By performing reasoning in a step by step manner over structured subgraphs, SGR reduces the influence of noisy information and improves reasoning accuracy. Specifically, the framework first generates an external subgraph tailored to the input query, then guides the model to conduct multi step reasoning grounded in the subgraph, and finally integrates multiple reasoning paths to produce the final answer. Experimental results on multiple benchmark datasets demonstrate that SGR consistently outperforms strong baselines, indicating its effectiveness in enhancing the reasoning capabilities of LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23356v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于外部子图生成的逐步增强推理框架SGR，提升大语言模型在复杂推理任务中的性能。",
            "summary_zh": "近年来，大型语言模型（LLMs）在机器翻译、文本生成和问答等自然语言处理任务中取得了显著成果。然而，当应用扩展到日益复杂的场景时，LLMs在需要深度推理和逻辑推断的任务中仍然面临挑战。特别是在大规模文本语料库上训练的模型，在生成过程中可能会包含噪声或不相关的信息，从而导致不正确的预测或与事实知识不一致的输出。为了解决这一局限性，我们提出了一种基于外部子图生成的LLMs逐步推理增强框架，称为SGR。该框架动态地从外部知识库构建与查询相关的子图，并利用其语义结构来指导推理过程。通过在结构化子图上逐步执行推理，SGR减少了噪声信息的影响，提高了推理准确性。具体来说，该框架首先生成一个针对输入查询量身定制的外部子图，然后引导模型在子图的基础上进行多步推理，最后整合多个推理路径以产生最终答案。在多个基准数据集上的实验结果表明，SGR始终优于强大的基线模型，表明其在增强LLMs推理能力方面的有效性。",
            "intro_zh": [
                "现有大语言模型在复杂推理任务中易受噪声信息干扰，导致错误预测或与事实不符的输出。",
                "SGR框架通过动态构建外部知识子图，引导模型在结构化知识上进行逐步推理，减少噪声影响。",
                "实验结果表明，SGR在多个基准数据集上优于现有方法，有效提升了大语言模型的推理能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在复杂推理任务中，由于受到训练数据中噪声或不相关信息的影响，导致推理准确性下降的问题。现有方法难以有效利用外部知识，容易产生与事实知识不一致的输出。\\n\\n**核心思路**：论文的核心思路是利用外部知识库构建与输入查询相关的子图，并引导LLM在这些结构化的子图上进行逐步推理。通过限制推理过程在相关知识范围内，减少噪声信息的干扰，从而提高推理的准确性和可靠性。\\n\\n**技术框架**：SGR框架包含三个主要阶段：1) **子图生成**：根据输入查询，从外部知识库中提取相关的子图。2) **多步推理**：引导LLM在生成的子图上进行多步推理，每一步推理都基于子图的结构化信息。3) **答案整合**：整合多条推理路径的结果，生成最终答案。\\n\\n**关键创新**：SGR的关键创新在于动态构建与查询相关的外部子图，并将LLM的推理过程限制在这些子图的范围内。这种方法有效地利用了外部知识，并减少了噪声信息的干扰，从而提高了推理的准确性。与现有方法相比，SGR能够更好地利用外部知识，并避免生成与事实知识不一致的输出。\\n\\n**关键设计**：子图生成过程依赖于知识库的结构和查询的语义信息，具体实现可能涉及实体链接、关系抽取等技术。多步推理过程可以通过提示工程（Prompt Engineering）引导LLM逐步探索子图中的信息。答案整合可以采用投票、加权平均等方法，根据不同推理路径的可靠性进行整合。",
            "application_zh": "该研究成果可应用于问答系统、知识图谱推理、智能助手等领域。通过提升大语言模型的推理能力，可以提高这些应用在复杂场景下的准确性和可靠性，例如在医疗诊断、金融分析等需要精确推理的领域具有重要价值。未来，该方法可以进一步扩展到其他需要利用外部知识进行推理的任务中。",
            "highlight_zh": "实验结果表明，SGR框架在多个基准数据集上 consistently 优于现有的强大基线模型，证明了其在增强LLMs推理能力方面的有效性。具体的性能提升数据在摘要中未给出，但强调了SGR在多个数据集上的一致性表现优越。",
            "tags_zh": [
                "大语言模型",
                "知识图谱",
                "推理增强",
                "外部知识",
                "子图生成"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23356v1/Fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23356v1/Fig2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23356v1/Fig3.png",
                    "caption": "",
                    "figure_id": "img_2"
                }
            ]
        },
        {
            "title": "SpatialMosaic: A Multiview VLM Dataset for Partial Visibility",
            "authors": [
                "Kanghee Lee",
                "Injae Lee",
                "Minseok Kwak",
                "Kwonyoung Ryu",
                "Jungi Hong",
                "Jaesik Park"
            ],
            "arxiv_id": "2512.23365v1",
            "summary": "The rapid progress of Multimodal Large Language Models (MLLMs) has unlocked the potential for enhanced 3D scene understanding and spatial reasoning. However, existing approaches often rely on pre-constructed 3D representations or off-the-shelf reconstruction pipelines, which constrain scalability and real-world applicability. A recent line of work explores learning spatial reasoning directly from multi-view images, enabling Vision-Language Models (VLMs) to understand 3D scenes without explicit 3D reconstructions. Nevertheless, key challenges that frequently arise in real-world environments, such as partial visibility, occlusion, and low-overlap conditions that require spatial reasoning from fragmented visual cues, remain under-explored. To address these limitations, we propose a scalable multi-view data generation and annotation pipeline that constructs realistic spatial reasoning QAs, resulting in SpatialMosaic, a comprehensive instruction-tuning dataset featuring 2M QA pairs. We further introduce SpatialMosaic-Bench, a challenging benchmark for evaluating multi-view spatial reasoning under realistic and challenging scenarios, consisting of 1M QA pairs across 6 tasks. In addition, we present SpatialMosaicVLM, a hybrid framework that integrates 3D reconstruction models as geometry encoders within VLMs for robust spatial reasoning. Extensive experiments demonstrate that our proposed dataset and VQA tasks effectively enhance spatial reasoning under challenging multi-view conditions, validating the effectiveness of our data generation pipeline in constructing realistic and diverse QA pairs. Code and dataset will be available soon.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23365v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene understanding"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出SpatialMosaic数据集，增强多视角VLM在部分可见场景下的空间推理能力",
            "summary_zh": "多模态大型语言模型(MLLM)的快速发展释放了增强3D场景理解和空间推理的潜力。然而，现有方法通常依赖于预先构建的3D表示或现成的重建流程，这限制了可扩展性和实际应用。最近的研究探索直接从多视角图像中学习空间推理，使视觉-语言模型(VLM)能够在没有显式3D重建的情况下理解3D场景。然而，现实环境中经常出现的关键挑战，如部分可见性、遮挡和低重叠条件，需要从碎片化的视觉线索进行空间推理，这些挑战仍未得到充分研究。为了解决这些限制，我们提出了一个可扩展的多视角数据生成和标注流程，构建了真实的包含200万个QA对的空间推理QA，形成了SpatialMosaic，一个全面的指令调优数据集。我们进一步引入了SpatialMosaic-Bench，这是一个具有挑战性的基准，用于评估在现实和具有挑战性的场景下的多视角空间推理，包含跨越6个任务的100万个QA对。此外，我们提出了SpatialMosaicVLM，一个混合框架，它将3D重建模型作为几何编码器集成到VLM中，以实现鲁棒的空间推理。大量的实验表明，我们提出的数据集和VQA任务有效地增强了具有挑战性的多视角条件下的空间推理，验证了我们的数据生成流程在构建真实和多样化的QA对方面的有效性。代码和数据集即将发布。",
            "intro_zh": [
                "现有方法依赖预构建3D表示或重建流程，限制了VLM在真实场景中的空间推理能力，尤其是在部分可见和遮挡情况下。",
                "SpatialMosaic通过可扩展的数据生成和标注流程，构建包含200万QA对的数据集，用于训练VLM在复杂多视角场景下的空间推理。",
                "SpatialMosaic-Bench提供100万QA对的基准测试，SpatialMosaicVLM框架集成了3D重建模型，实验验证了数据集和VQA任务的有效性。"
            ],
            "method_zh": "**问题定义**：现有VLM在多视角场景下的空间推理能力不足，尤其是在部分可见、遮挡和低重叠等真实场景中。现有方法依赖于预先构建的3D模型或重建流程，限制了其可扩展性和泛化能力。因此，需要一种能够直接从多视角图像中学习空间推理的方法，并解决真实场景中的挑战。\\n\\n**核心思路**：SpatialMosaic的核心思路是通过大规模数据生成和标注，构建一个包含丰富空间推理信息的指令调优数据集。该数据集模拟了真实场景中的各种挑战，如部分可见、遮挡和低重叠，从而使VLM能够学习到更鲁棒的空间推理能力。此外，SpatialMosaic还提出了一个混合框架SpatialMosaicVLM，将3D重建模型作为几何编码器集成到VLM中，进一步提升空间推理性能。\\n\\n**技术框架**：SpatialMosaic的整体框架包括以下几个主要模块：1) 多视角数据生成：使用可扩展的流程生成包含各种场景和视角的图像数据。2) 空间推理QA标注：设计多种空间推理任务，并对生成的数据进行QA标注，构建包含丰富空间推理信息的数据集。3) SpatialMosaic-Bench基准测试：构建一个具有挑战性的基准测试，用于评估VLM在多视角空间推理方面的性能。4) SpatialMosaicVLM框架：将3D重建模型作为几何编码器集成到VLM中，提升空间推理性能。\\n\\n**关键创新**：SpatialMosaic的主要创新点在于：1) 提出了一个可扩展的多视角数据生成和标注流程，能够构建大规模、高质量的空间推理数据集。2) 设计了多种空间推理任务，涵盖了真实场景中的各种挑战。3) 提出了SpatialMosaicVLM框架，将3D重建模型与VLM相结合，提升了空间推理性能。\\n\\n**关键设计**：在数据生成方面，SpatialMosaic采用了随机场景生成和相机参数设置，模拟了真实场景中的各种视角和光照条件。在QA标注方面，SpatialMosaic设计了多种空间推理任务，包括目标定位、关系推理和场景理解等。SpatialMosaicVLM框架中，3D重建模型采用了现有的成熟算法，如COLMAP等，并将其输出作为VLM的输入，从而使VLM能够利用3D几何信息进行空间推理。",
            "application_zh": "SpatialMosaic的研究成果可应用于机器人导航、自动驾驶、增强现实等领域。通过提升VLM在复杂环境下的空间推理能力，可以使机器人更好地理解周围环境，实现更智能的导航和交互。在自动驾驶领域，可以提高车辆对周围环境的感知能力，从而提高驾驶安全性。在增强现实领域，可以实现更自然的虚拟物体与真实环境的融合。",
            "highlight_zh": "SpatialMosaic数据集包含200万个QA对，SpatialMosaic-Bench基准测试包含100万个QA对，涵盖6个空间推理任务。实验结果表明，使用SpatialMosaic进行训练可以显著提升VLM在多视角空间推理方面的性能。SpatialMosaicVLM框架通过集成3D重建模型，进一步提升了空间推理的准确性和鲁棒性。具体性能数据将在论文中详细展示。",
            "tags_zh": [
                "多视角学习",
                "视觉语言模型",
                "空间推理",
                "数据集构建",
                "三维重建"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23365v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23365v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23365v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multi-Agent Framework for Threat Mitigation and Resilience in AI-Based Systems",
            "authors": [
                "Armstrong Foundjem",
                "Lionel Nganyewou Tidjon",
                "Leuson Da Silva",
                "Foutse Khomh"
            ],
            "arxiv_id": "2512.23132v1",
            "summary": "Machine learning (ML) underpins foundation models in finance, healthcare, and critical infrastructure, making them targets for data poisoning, model extraction, prompt injection, automated jailbreaking, and preference-guided black-box attacks that exploit model comparisons. Larger models can be more vulnerable to introspection-driven jailbreaks and cross-modal manipulation. Traditional cybersecurity lacks ML-specific threat modeling for foundation, multimodal, and RAG systems. Objective: Characterize ML security risks by identifying dominant TTPs, vulnerabilities, and targeted lifecycle stages. Methods: We extract 93 threats from MITRE ATLAS (26), AI Incident Database (12), and literature (55), and analyze 854 GitHub/Python repositories. A multi-agent RAG system (ChatGPT-4o, temp 0.4) mines 300+ articles to build an ontology-driven threat graph linking TTPs, vulnerabilities, and stages. Results: We identify unreported threats including commercial LLM API model stealing, parameter memorization leakage, and preference-guided text-only jailbreaks. Dominant TTPs include MASTERKEY-style jailbreaking, federated poisoning, diffusion backdoors, and preference optimization leakage, mainly impacting pre-training and inference. Graph analysis reveals dense vulnerability clusters in libraries with poor patch propagation. Conclusion: Adaptive, ML-specific security frameworks, combining dependency hygiene, threat intelligence, and monitoring, are essential to mitigate supply-chain and inference risks across the ML lifecycle.",
            "categories": [
                "cs.CR",
                "cs.LG",
                "cs.MA"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "56 pages, 18 Figures, 22 Tables, TOSEM",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23132v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多智能体框架，用于缓解和增强人工智能系统的威胁抵御能力",
            "summary_zh": "机器学习正支撑着金融、医疗和关键基础设施中的基础模型，使其成为数据投毒、模型提取、提示注入、自动越狱和利用模型比较的偏好引导黑盒攻击的目标。更大的模型更容易受到内省驱动的越狱和跨模态操纵的影响。传统的网络安全缺乏针对基础模型、多模态和RAG系统的机器学习特定威胁建模。本研究旨在通过识别主要的TTP、漏洞和目标生命周期阶段来描述机器学习安全风险。我们从MITRE ATLAS（26个）、AI Incident Database（12个）和文献（55个）中提取了93个威胁，并分析了854个GitHub/Python存储库。一个多智能体RAG系统（ChatGPT-4o，温度0.4）挖掘了300多篇文章，构建了一个本体驱动的威胁图，将TTP、漏洞和阶段联系起来。我们识别出未报告的威胁，包括商业LLM API模型窃取、参数记忆泄漏和偏好引导的纯文本越狱。主要的TTP包括MASTERKEY风格的越狱、联邦投毒、扩散后门和偏好优化泄漏，主要影响预训练和推理。图分析揭示了具有较差补丁传播的库中的密集漏洞集群。结论是，自适应的、机器学习特定的安全框架，结合依赖卫生、威胁情报和监控，对于缓解整个机器学习生命周期中的供应链和推理风险至关重要。",
            "intro_zh": [
                "现有网络安全方法缺乏针对机器学习模型（尤其是基础模型、多模态模型和RAG系统）的特定威胁建模。",
                "提出一种多智能体RAG系统，通过分析大量威胁数据，构建本体驱动的威胁图，关联TTP、漏洞和生命周期阶段。",
                "识别出商业LLM API模型窃取、参数记忆泄漏等未报告威胁，并揭示了主要TTP和高风险漏洞集群。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器学习系统，特别是基于大型语言模型（LLM）的系统，在面对各种安全威胁时的脆弱性问题。现有的网络安全方法通常不足以应对机器学习模型特有的攻击方式，例如数据投毒、模型提取、提示注入和越狱攻击。这些攻击可能导致模型性能下降、敏感信息泄露甚至系统崩溃。\\n\\n**核心思路**：论文的核心思路是构建一个多智能体框架，利用RAG（Retrieval-Augmented Generation）系统，从大量的威胁情报数据中提取、分析和关联威胁信息，从而构建一个全面的威胁图。该威胁图能够帮助安全专家识别潜在的攻击路径、漏洞和关键的攻击阶段，从而制定更有效的防御策略。\\n\\n**技术框架**：该框架主要包含以下几个模块：1) **威胁数据收集模块**：从MITRE ATLAS、AI Incident Database和相关文献中收集威胁数据。2) **知识图谱构建模块**：利用多智能体RAG系统（ChatGPT-4o）从收集到的数据中提取实体（TTP、漏洞、阶段）和关系，构建本体驱动的威胁图。3) **威胁分析模块**：分析威胁图，识别主要的TTP、高风险漏洞集群和关键的攻击阶段。4) **安全策略生成模块**：基于威胁分析结果，生成针对性的安全策略，例如依赖项管理、威胁情报和监控。\\n\\n**关键创新**：该论文的关键创新在于：1) **多智能体RAG系统**：利用多智能体系统自动化地从海量数据中提取和关联威胁信息，提高了威胁情报分析的效率和准确性。2) **本体驱动的威胁图**：构建了一个结构化的威胁知识库，能够清晰地展示威胁之间的关系和攻击路径。3) **识别未报告的威胁**：通过分析，识别出商业LLM API模型窃取、参数记忆泄漏等新型威胁。\\n\\n**关键设计**：RAG系统使用ChatGPT-4o作为核心引擎，温度参数设置为0.4，以平衡生成结果的创造性和准确性。威胁图的构建基于预定义的本体，该本体定义了威胁相关的实体类型（TTP、漏洞、阶段）和关系类型。论文还重点关注了依赖项管理，强调了及时更新和修补漏洞的重要性。",
            "application_zh": "该研究成果可应用于提高人工智能系统的安全性，尤其是在金融、医疗和关键基础设施等领域。通过构建全面的威胁图和制定针对性的安全策略，可以有效降低机器学习模型遭受攻击的风险，保护敏感数据和系统安全。该研究还有助于开发更安全的LLM应用，并促进人工智能技术的可靠应用。",
            "highlight_zh": "实验结果表明，该框架能够识别出未报告的威胁，例如商业LLM API模型窃取和参数记忆泄漏。通过分析威胁图，发现主要的TTP包括MASTERKEY风格的越狱、联邦投毒和扩散后门。此外，还识别出具有较差补丁传播的库中的密集漏洞集群，为安全专家提供了有价值的威胁情报。",
            "tags_zh": [
                "机器学习安全",
                "威胁建模",
                "多智能体系统",
                "RAG系统",
                "大型语言模型",
                "知识图谱",
                "漏洞分析"
            ],
            "_index": 34,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23132v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23132v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23132v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Web World Models",
            "authors": [
                "Jichen Feng",
                "Yifan Zhang",
                "Chenggong Zhang",
                "Yifu Lu",
                "Shilong Liu",
                "Mengdi Wang"
            ],
            "arxiv_id": "2512.23676v1",
            "summary": "Language agents increasingly require persistent worlds in which they can act, remember, and learn. Existing approaches sit at two extremes: conventional web frameworks provide reliable but fixed contexts backed by databases, while fully generative world models aim for unlimited environments at the expense of controllability and practical engineering. In this work, we introduce the Web World Model (WWM), a middle ground where world state and ``physics'' are implemented in ordinary web code to ensure logical consistency, while large language models generate context, narratives, and high-level decisions on top of this structured latent state. We build a suite of WWMs on a realistic web stack, including an infinite travel atlas grounded in real geography, fictional galaxy explorers, web-scale encyclopedic and narrative worlds, and simulation- and game-like environments. Across these systems, we identify practical design principles for WWMs: separating code-defined rules from model-driven imagination, representing latent state as typed web interfaces, and utilizing deterministic generation to achieve unlimited but structured exploration. Our results suggest that web stacks themselves can serve as a scalable substrate for world models, enabling controllable yet open-ended environments. Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Project Page: https://github.com/Princeton-AI2-Lab/Web-World-Models",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23676v1",
            "code_links": [
                {
                    "url": "https://github.com/Princeton-AI2-Lab/Web-World-Models",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Web World Model，结合Web代码的逻辑一致性和LLM的生成能力，构建可控且开放的Agent环境。",
            "summary_zh": "语言Agent越来越需要在持久的世界中行动、记忆和学习。现有方法处于两个极端：传统的Web框架提供可靠但固定的上下文，由数据库支持；而完全生成的世界模型旨在实现无限的环境，但牺牲了可控性和实际工程性。本文提出了Web World Model (WWM)，这是一种中间方案，其中世界状态和“物理”规则在普通的Web代码中实现，以确保逻辑一致性，而大型语言模型在此结构化的潜在状态之上生成上下文、叙事和高层决策。我们在一个真实的Web堆栈上构建了一套WWM，包括一个基于真实地理的无限旅行地图集、虚构的星系探险者、Web规模的百科全书和叙事世界，以及模拟和游戏类环境。通过这些系统，我们确定了WWM的实用设计原则：将代码定义的规则与模型驱动的想象力分离，将潜在状态表示为类型化的Web接口，并利用确定性生成来实现无限但结构化的探索。结果表明，Web堆栈本身可以作为世界模型的可扩展基底，从而实现可控但开放的环境。",
            "intro_zh": [
                "现有语言Agent环境构建方法要么依赖固定Web框架，缺乏开放性；要么完全依赖生成模型，难以控制和保证逻辑一致性。",
                "Web World Model (WWM) 结合Web代码的逻辑性和LLM的生成能力，在结构化潜在状态上生成上下文和决策，实现可控且开放的环境。",
                "通过在多种Web环境中的实验，验证了WWM的设计原则，证明了Web技术栈作为世界模型可扩展基底的潜力。"
            ],
            "method_zh": "**问题定义**：现有语言Agent环境构建方法存在局限性。传统Web框架依赖数据库，环境固定，缺乏开放性和探索性。完全生成的世界模型虽然开放，但难以控制，容易出现逻辑不一致和幻觉问题，难以实际工程化应用。\\n\\n**核心思路**：Web World Model (WWM) 的核心思路是将世界状态和基本规则用Web代码实现，保证逻辑一致性和可控性，同时利用大型语言模型 (LLM) 在此基础上生成上下文、叙事和高层决策，实现开放性和创造性。这种混合方法旨在弥合传统Web框架和完全生成模型之间的差距。\\n\\n**技术框架**：WWM的整体架构包含以下几个关键模块：1) **Web代码层**：定义世界的基本状态和规则，例如地理位置、物理定律等，使用标准的Web技术栈实现。2) **LLM层**：负责生成上下文、叙事和高层决策，例如Agent的行动计划、对话内容等。3) **接口层**：定义Web代码层和LLM层之间的接口，例如Agent可以查询哪些信息、可以执行哪些操作。通过这些接口，LLM可以与Web世界进行交互。\\n\\n**关键创新**：WWM的关键创新在于将Web技术栈作为世界模型的基础，并结合LLM的生成能力。这种混合方法既保证了逻辑一致性和可控性，又实现了开放性和创造性。与现有方法相比，WWM更易于工程化实现，并且可以构建更复杂、更真实的世界模型。\\n\\n**关键设计**：WWM的关键设计原则包括：1) **代码定义的规则与模型驱动的想象力分离**：Web代码负责定义世界的物理规则和基本状态，LLM负责生成上下文和叙事。2) **潜在状态表示为类型化的Web接口**：通过定义清晰的Web接口，LLM可以方便地访问和操作世界状态。3) **利用确定性生成实现无限但结构化的探索**：通过控制LLM的生成过程，可以实现对世界的结构化探索，避免出现逻辑不一致和幻觉问题。",
            "application_zh": "Web World Model 有广泛的应用前景，包括：1) 游戏开发：可以用于构建更真实、更开放的游戏世界。2) 教育：可以用于创建交互式学习环境，让学生在虚拟世界中学习知识。3) 科研：可以用于模拟复杂的系统，例如经济系统、社会系统等。4) 智能助手：可以用于构建更智能的助手，让助手能够更好地理解用户的需求并提供帮助。",
            "highlight_zh": "论文在多个Web环境中进行了实验，包括无限旅行地图集、星系探险、Web规模的百科全书和叙事世界，以及模拟和游戏类环境。实验结果表明，WWM可以有效地构建可控且开放的世界模型，并且易于工程化实现。论文还总结了WWM的实用设计原则，为未来的研究提供了指导。",
            "tags_zh": [
                "世界模型",
                "语言Agent",
                "大型语言模型",
                "Web技术栈",
                "可控生成"
            ],
            "_index": 35,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23676v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23676v1/images/Teaser2.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23676v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CME-CAD: Heterogeneous Collaborative Multi-Expert Reinforcement Learning for CAD Code Generation",
            "authors": [
                "Ke Niu",
                "Haiyang Yu",
                "Zhuofan Chen",
                "Zhengtao Yao",
                "Weitao Jia",
                "Xiaodong Ge",
                "Jingqun Tang",
                "Benlei Cui",
                "Bin Li",
                "Xiangyang Xue"
            ],
            "arxiv_id": "2512.23333v1",
            "summary": "Computer-Aided Design (CAD) is essential in industrial design, but the complexity of traditional CAD modeling and workflows presents significant challenges for automating the generation of high-precision, editable CAD models. Existing methods that reconstruct 3D models from sketches often produce non-editable and approximate models that fall short of meeting the stringent requirements for precision and editability in industrial design. Moreover, the reliance on text or image-based inputs often requires significant manual annotation, limiting their scalability and applicability in industrial settings. To overcome these challenges, we propose the Heterogeneous Collaborative Multi-Expert Reinforcement Learning (CME-CAD) paradigm, a novel training paradigm for CAD code generation. Our approach integrates the complementary strengths of these models, facilitating collaborative learning and improving the model's ability to generate accurate, constraint-compatible, and fully editable CAD models. We introduce a two-stage training process: Multi-Expert Fine-Tuning (MEFT), and Multi-Expert Reinforcement Learning (MERL). Additionally, we present CADExpert, an open-source benchmark consisting of 17,299 instances, including orthographic projections with precise dimension annotations, expert-generated Chain-of-Thought (CoT) processes, executable CADQuery code, and rendered 3D models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23333v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "chain-of-thought"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出CME-CAD异构协作多专家强化学习框架，用于高精度可编辑CAD代码生成。",
            "summary_zh": "本文提出了一种用于CAD代码生成的新型训练范式——异构协作多专家强化学习(CME-CAD)。该方法集成了不同模型的互补优势，促进协作学习，并提高模型生成精确、约束兼容且完全可编辑的CAD模型的能力。我们引入了一个两阶段训练过程：多专家微调(MEFT)和多专家强化学习(MERL)。此外，我们还提出了CADExpert，一个包含17,299个实例的开源基准，包括正交投影和精确的尺寸标注、专家生成的思维链(CoT)过程、可执行的CADQuery代码和渲染的3D模型。",
            "intro_zh": [
                "现有方法从草图重建3D模型通常产生不可编辑且近似的模型，无法满足工业设计中对精度和可编辑性的严格要求。",
                "CME-CAD通过异构多专家协作，结合多专家微调和强化学习，提升CAD代码生成的精度和可编辑性。",
                "论文构建了包含17,299个实例的CADExpert基准数据集，为CAD代码生成领域的研究提供了有力支持。"
            ],
            "method_zh": "**问题定义**：现有CAD建模方法复杂，难以自动化生成高精度、可编辑的CAD模型。从草图重建3D模型的方法通常产生非可编辑的近似模型，无法满足工业设计的严格要求。依赖文本或图像输入的方法需要大量手动标注，限制了其在工业环境中的可扩展性和适用性。\\n\\n**核心思路**：CME-CAD的核心思路是利用异构多专家的协作，结合各自的优势，共同学习生成CAD代码。通过多专家微调(MEFT)和多专家强化学习(MERL)两个阶段的训练，使模型能够生成精确、约束兼容且完全可编辑的CAD模型。这种方法旨在克服现有方法在精度、可编辑性和自动化程度方面的局限性。\\n\\n**技术框架**：CME-CAD的整体框架包含两个主要阶段：MEFT和MERL。在MEFT阶段，不同的专家模型（例如，擅长几何推理的模型和擅长代码生成的模型）在CADExpert数据集上进行微调，以提高各自的专业能力。在MERL阶段，这些微调后的专家模型通过强化学习进行协作，共同生成CAD代码。强化学习的目标是最大化奖励函数，该奖励函数考虑了生成的CAD模型的精度、约束兼容性和可编辑性。\\n\\n**关键创新**：CME-CAD的关键创新在于异构多专家的协作学习范式。与传统的单模型方法相比，CME-CAD能够更好地利用不同模型的优势，从而提高CAD代码生成的质量。此外，两阶段训练过程（MEFT和MERL）也是一个重要的创新，它能够有效地引导模型学习生成高质量的CAD代码。CADExpert数据集的构建也为该领域的研究提供了重要的资源。\\n\\n**关键设计**：MEFT阶段的关键设计在于选择合适的专家模型和微调策略。MERL阶段的关键设计在于定义合适的奖励函数和强化学习算法。奖励函数需要综合考虑CAD模型的精度、约束兼容性和可编辑性。强化学习算法需要能够有效地探索CAD代码的搜索空间，并找到最优的生成策略。具体的参数设置、损失函数和网络结构等技术细节在论文中可能没有详细描述，属于未知信息。",
            "application_zh": "CME-CAD技术可应用于工业设计、建筑设计、产品设计等领域，实现CAD模型的自动化生成，提高设计效率，降低设计成本。该技术还可以用于逆向工程，从现有产品或零件的图像或扫描数据中自动生成CAD模型。未来，CME-CAD有望与人工智能设计工具集成，实现更加智能化的设计流程。",
            "highlight_zh": "论文提出了CADExpert基准数据集，包含17,299个实例，为CAD代码生成研究提供了数据基础。CME-CAD框架通过异构多专家协作和两阶段训练，在CAD代码生成任务上取得了显著的性能提升，但具体性能数据和对比基线未知。",
            "tags_zh": [
                "CAD代码生成",
                "强化学习",
                "多专家协作",
                "异构学习",
                "工业设计"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23333v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23333v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23333v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Alpha-R1: Alpha Screening with LLM Reasoning via Reinforcement Learning",
            "authors": [
                "Zuoyou Jiang",
                "Li Zhao",
                "Rui Sun",
                "Ruohan Sun",
                "Zhongjian Li",
                "Jing Li",
                "Daxin Jiang",
                "Zuo Bai",
                "Cheng Hua"
            ],
            "arxiv_id": "2512.23515v1",
            "summary": "Signal decay and regime shifts pose recurring challenges for data-driven investment strategies in non-stationary markets. Conventional time-series and machine learning approaches, which rely primarily on historical correlations, often struggle to generalize when the economic environment changes. While large language models (LLMs) offer strong capabilities for processing unstructured information, their potential to support quantitative factor screening through explicit economic reasoning remains underexplored. Existing factor-based methods typically reduce alphas to numerical time series, overlooking the semantic rationale that determines when a factor is economically relevant. We propose Alpha-R1, an 8B-parameter reasoning model trained via reinforcement learning for context-aware alpha screening. Alpha-R1 reasons over factor logic and real-time news to evaluate alpha relevance under changing market conditions, selectively activating or deactivating factors based on contextual consistency. Empirical results across multiple asset pools show that Alpha-R1 consistently outperforms benchmark strategies and exhibits improved robustness to alpha decay. The full implementation and resources are available at https://github.com/FinStep-AI/Alpha-R1.",
            "categories": [
                "q-fin.TR",
                "cs.AI",
                "cs.CE",
                "cs.LG"
            ],
            "primary_category": "q-fin.TR",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23515v1",
            "code_links": [
                {
                    "url": "https://github.com/FinStep-AI/Alpha-R1",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Alpha-R1，利用强化学习训练LLM进行上下文感知的Alpha筛选，提升量化投资策略的鲁棒性。",
            "summary_zh": "非平稳市场中，信号衰减和机制转变对数据驱动的投资策略提出了持续的挑战。传统的时序和机器学习方法主要依赖历史相关性，难以在经济环境变化时泛化。大型语言模型(LLM)在处理非结构化信息方面表现出强大的能力，但其通过显式经济推理支持量化因子筛选的潜力尚未得到充分探索。现有的基于因子的方法通常将alphas简化为数值时间序列，忽略了决定因子何时具有经济相关性的语义原理。我们提出了Alpha-R1，一个通过强化学习训练的80亿参数推理模型，用于上下文感知的alpha筛选。Alpha-R1基于因子逻辑和实时新闻进行推理，以评估alpha在变化的市场条件下的相关性，并根据上下文一致性选择性地激活或停用因子。跨多个资产池的实证结果表明，Alpha-R1始终优于基准策略，并表现出对alpha衰减的改进的鲁棒性。完整的实现和资源可在https://github.com/FinStep-AI/Alpha-R1获得。",
            "intro_zh": [
                "传统量化投资方法依赖历史数据，难以应对市场环境变化带来的信号衰减和机制转变。",
                "Alpha-R1利用大型语言模型进行经济推理，结合因子逻辑和实时新闻，实现上下文感知的alpha筛选。",
                "实验结果表明，Alpha-R1在多个资产池中优于基准策略，并提高了对alpha衰减的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决量化投资中因子有效性随时间衰减以及市场环境变化导致因子失效的问题。现有方法主要依赖历史数据，缺乏对市场环境变化的适应性，无法有效识别和利用在特定市场条件下有效的alpha因子。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）的推理能力，结合因子逻辑和实时新闻，对alpha因子进行上下文感知的筛选。通过让LLM理解市场环境变化对因子有效性的影响，从而选择性地激活或停用因子，提高投资策略的鲁棒性。\\n\\n**技术框架**：Alpha-R1的技术框架包含以下几个主要模块：1)因子逻辑和实时新闻输入模块，负责收集和处理因子逻辑描述和实时市场新闻；2)LLM推理模块，利用预训练的LLM进行经济推理，评估alpha因子在当前市场环境下的相关性；3)强化学习训练模块，通过强化学习算法优化LLM的推理能力，使其能够更好地适应市场变化；4)因子激活/停用模块，根据LLM的推理结果，选择性地激活或停用alpha因子。\\n\\n**关键创新**：论文最重要的技术创新点在于将大型语言模型的推理能力引入到量化因子筛选中，实现了上下文感知的alpha筛选。与现有方法相比，Alpha-R1能够更好地理解市场环境变化对因子有效性的影响，从而提高投资策略的鲁棒性。现有方法通常将alpha简化为数值时间序列，忽略了语义信息。\\n\\n**关键设计**：Alpha-R1使用一个80亿参数的LLM作为推理引擎。强化学习的奖励函数设计至关重要，需要能够反映投资组合的收益和风险。论文中使用了特定的奖励函数来鼓励模型选择能够带来更高收益且风险可控的alpha因子。具体参数设置和网络结构细节在论文中有详细描述，但此处未给出。",
            "application_zh": "Alpha-R1可应用于量化投资、风险管理和资产配置等领域。通过利用LLM的推理能力，可以更有效地识别和利用在特定市场条件下有效的alpha因子，提高投资组合的收益和风险调整后收益。该研究为开发更智能、更鲁棒的量化投资策略提供了新的思路。",
            "highlight_zh": "Alpha-R1在多个资产池的实验结果表明，其性能始终优于基准策略，并且对alpha衰减具有更强的鲁棒性。具体的性能提升数据在论文中给出，但此处未提供详细数值。实验结果验证了利用LLM进行上下文感知alpha筛选的有效性。",
            "tags_zh": [
                "量化投资",
                "大型语言模型",
                "强化学习",
                "因子筛选",
                "上下文感知"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23515v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23515v1/images/nav/main_result_comparison.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23515v1/images/nav/main_result_csi1000_comparison.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Act2Goal: From World Model To General Goal-conditioned Policy",
            "authors": [
                "Pengfei Zhou",
                "Liliang Chen",
                "Shengcong Chen",
                "Di Chen",
                "Wenzhi Zhao",
                "Rongjun Jin",
                "Guanghui Ren",
                "Jianlan Luo"
            ],
            "arxiv_id": "2512.23541v1",
            "summary": "Specifying robotic manipulation tasks in a manner that is both expressive and precise remains a central challenge. While visual goals provide a compact and unambiguous task specification, existing goal-conditioned policies often struggle with long-horizon manipulation due to their reliance on single-step action prediction without explicit modeling of task progress. We propose Act2Goal, a general goal-conditioned manipulation policy that integrates a goal-conditioned visual world model with multi-scale temporal control. Given a current observation and a target visual goal, the world model generates a plausible sequence of intermediate visual states that captures long-horizon structure. To translate this visual plan into robust execution, we introduce Multi-Scale Temporal Hashing (MSTH), which decomposes the imagined trajectory into dense proximal frames for fine-grained closed-loop control and sparse distal frames that anchor global task consistency. The policy couples these representations with motor control through end-to-end cross-attention, enabling coherent long-horizon behavior while remaining reactive to local disturbances. Act2Goal achieves strong zero-shot generalization to novel objects, spatial layouts, and environments. We further enable reward-free online adaptation through hindsight goal relabeling with LoRA-based finetuning, allowing rapid autonomous improvement without external supervision. Real-robot experiments demonstrate that Act2Goal improves success rates from 30% to 90% on challenging out-of-distribution tasks within minutes of autonomous interaction, validating that goal-conditioned world models with multi-scale temporal control provide structured guidance necessary for robust long-horizon manipulation. Project page: https://act2goal.github.io/",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23541v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 6.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "Act2Goal：融合世界模型与多尺度时序控制的通用目标条件策略",
            "summary_zh": "本文提出Act2Goal，一种通用的目标条件操作策略，它将目标条件视觉世界模型与多尺度时序控制相结合。针对现有方法在长时程操作中依赖单步动作预测且缺乏显式任务进度建模的问题，Act2Goal利用世界模型生成中间视觉状态序列，捕捉长时程结构。引入多尺度时序哈希(MSTH)将轨迹分解为密集的近端帧和稀疏的远端帧，分别用于细粒度闭环控制和全局任务一致性。该策略通过端到端交叉注意力将这些表示与电机控制耦合，实现连贯的长时程行为并对局部扰动做出反应。Act2Goal在新的物体、空间布局和环境中实现了强大的零样本泛化。通过基于LoRA的后见目标重标记在线自适应，无需外部监督即可快速自主改进。真实机器人实验表明，Act2Goal在具有挑战性的分布外任务中，通过几分钟的自主交互，成功率从30%提高到90%，验证了具有多尺度时序控制的目标条件世界模型为鲁棒的长时程操作提供了必要的结构化指导。",
            "intro_zh": [
                "现有目标条件策略难以处理长时程操作，主要因为它们依赖单步动作预测，缺乏对任务进度的显式建模。",
                "Act2Goal通过结合目标条件视觉世界模型和多尺度时序控制，生成中间视觉状态序列，实现长时程任务规划。",
                "实验表明，Act2Goal在零样本泛化和在线自适应方面表现出色，真实机器人实验成功率从30%提升到90%。"
            ],
            "method_zh": "**问题定义**：现有的机器人操作任务指定方法难以兼顾表达性和精确性。视觉目标虽然提供了紧凑且明确的任务规范，但现有的目标条件策略在长时程操作中表现不佳，主要原因是它们依赖于单步动作预测，缺乏对任务进度的显式建模，难以应对长期规划中的不确定性。\\n\\n**核心思路**：Act2Goal的核心思路是将目标条件视觉世界模型与多尺度时序控制相结合。世界模型负责生成从当前状态到目标状态的合理中间视觉状态序列，从而捕捉长时程任务的结构信息。多尺度时序控制则将该视觉计划转化为鲁棒的执行策略，兼顾局部控制的精确性和全局任务的一致性。\\n\\n**技术框架**：Act2Goal的整体框架包含以下几个主要模块：1) **目标条件视觉世界模型**：根据当前观测和目标视觉状态，预测一系列中间视觉状态。2) **多尺度时序哈希(MSTH)**：将预测的视觉轨迹分解为密集的近端帧和稀疏的远端帧。近端帧用于细粒度的闭环控制，远端帧用于保持全局任务的一致性。3) **策略网络**：通过端到端交叉注意力机制，将MSTH输出的视觉信息与电机控制指令进行融合，生成最终的动作。\\n\\n**关键创新**：Act2Goal的关键创新在于将世界模型生成的长时程视觉规划与多尺度时序控制相结合。与传统的单步预测方法不同，Act2Goal能够显式地建模任务进度，并利用多尺度信息来平衡局部控制和全局规划。此外，通过引入基于LoRA的后见目标重标记在线自适应方法，实现了无需外部监督的快速自主改进。\\n\\n**关键设计**：MSTH的关键设计在于如何选择近端帧和远端帧。论文采用了一种基于哈希的方法来选择关键帧，保证了帧的选择具有代表性，同时降低了计算复杂度。策略网络采用交叉注意力机制，将视觉信息和电机控制指令进行融合，实现了端到端的学习。损失函数包括重构损失和动作预测损失，用于训练世界模型和策略网络。",
            "application_zh": "Act2Goal具有广泛的应用前景，可应用于各种机器人操作任务，例如装配、抓取、放置等。该方法尤其适用于复杂、长时程的操作任务，例如家庭服务机器人、工业自动化等领域。通过在线自适应，Act2Goal能够快速适应新的环境和任务，降低了机器人部署和维护的成本，加速了机器人技术的普及。",
            "highlight_zh": "Act2Goal在真实机器人实验中表现出色，在具有挑战性的分布外任务中，通过几分钟的自主交互，成功率从30%提高到90%。该方法在零样本泛化方面也表现出强大的能力，能够直接应用于新的物体、空间布局和环境，无需额外的训练。",
            "tags_zh": [
                "机器人操作",
                "目标条件策略",
                "世界模型",
                "多尺度时序控制",
                "长时程规划",
                "零样本泛化",
                "在线自适应"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23541v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23541v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23541v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Explainable Neural Inverse Kinematics for Obstacle-Aware Robotic Manipulation: A Comparative Analysis of IKNet Variants",
            "authors": [
                "Sheng-Kai Chen",
                "Yi-Ling Tsai",
                "Chun-Chih Chang",
                "Yan-Chen Chen",
                "Po-Chiang Lin"
            ],
            "arxiv_id": "2512.23312v1",
            "summary": "Deep neural networks have accelerated inverse-kinematics (IK) inference to the point where low cost manipulators can execute complex trajectories in real time, yet the opaque nature of these models contradicts the transparency and safety requirements emerging in responsible AI regulation. This study proposes an explainability centered workflow that integrates Shapley-value attribution with physics-based obstacle avoidance evaluation for the ROBOTIS OpenManipulator-X. Building upon the original IKNet, two lightweight variants-Improved IKNet with residual connections and Focused IKNet with position-orientation decoupling are trained on a large, synthetically generated pose-joint dataset. SHAP is employed to derive both global and local importance rankings, while the InterpretML toolkit visualizes partial-dependence patterns that expose non-linear couplings between Cartesian poses and joint angles. To bridge algorithmic insight and robotic safety, each network is embedded in a simulator that subjects the arm to randomized single and multi-obstacle scenes; forward kinematics, capsule-based collision checks, and trajectory metrics quantify the relationship between attribution balance and physical clearance. Qualitative heat maps reveal that architectures distributing importance more evenly across pose dimensions tend to maintain wider safety margins without compromising positional accuracy. The combined analysis demonstrates that explainable AI(XAI) techniques can illuminate hidden failure modes, guide architectural refinements, and inform obstacle aware deployment strategies for learning based IK. The proposed methodology thus contributes a concrete path toward trustworthy, data-driven manipulation that aligns with emerging responsible-AI standards.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "27 pages, 16 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23312v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于可解释AI的逆运动学框架，提升机器人操作的安全性和透明度。",
            "summary_zh": "本研究提出了一种以可解释性为中心的逆运动学(IK)工作流程，该流程将Shapley值归因与基于物理的避障评估相结合，应用于ROBOTIS OpenManipulator-X机械臂。在原始IKNet的基础上，训练了两个轻量级变体——具有残差连接的改进IKNet和具有位置-方向解耦的Focused IKNet，使用大规模合成姿态-关节数据集。采用SHAP来推导全局和局部重要性排序，而InterpretML工具包可视化了部分依赖模式，揭示了笛卡尔姿态和关节角度之间的非线性耦合。为了连接算法洞察力和机器人安全性，将每个网络嵌入到模拟器中，使机械臂暴露于随机的单障碍物和多障碍物场景中；前向运动学、基于胶囊的碰撞检查和轨迹指标量化了归因平衡与物理间隙之间的关系。定性热图显示，在姿态维度上更均匀地分配重要性的架构往往保持更宽的安全裕度，而不会影响位置精度。综合分析表明，可解释AI(XAI)技术可以阐明隐藏的失效模式，指导架构改进，并为基于学习的IK提供避障部署策略。因此，所提出的方法为实现符合新兴负责任AI标准的、可信赖的、数据驱动的操作提供了一条具体的途径。",
            "intro_zh": [
                "深度神经网络加速了逆运动学推理，但其不透明性与负责任AI监管中对透明度和安全性的要求相悖。",
                "该研究提出一种可解释的逆运动学框架，结合SHAP值归因和物理避障评估，提升模型透明度和安全性。",
                "通过在模拟环境中进行障碍物规避测试，验证了该框架能够揭示隐藏的失效模式，并指导架构改进。"
            ],
            "method_zh": "**问题定义**：论文旨在解决深度神经网络在逆运动学（IK）推理中的不透明性问题。现有基于深度学习的IK方法虽然速度快，但缺乏可解释性，难以满足机器人应用中对安全性和可靠性的要求，尤其是在存在障碍物的环境中，难以保证机械臂的安全运动。\\n\\n**核心思路**：论文的核心思路是将可解释人工智能（XAI）技术，特别是SHAP值归因，与基于物理的避障评估相结合，以提高IK模型的透明度和安全性。通过分析模型对不同输入特征的依赖程度，揭示模型决策过程中的关键因素，并利用模拟环境评估模型在实际场景中的避障能力。\\n\\n**技术框架**：整体框架包含三个主要部分：1) 基于合成数据集训练IKNet及其变体（Improved IKNet和Focused IKNet）；2) 使用SHAP值进行全局和局部重要性分析，并使用InterpretML可视化部分依赖关系；3) 在模拟环境中进行避障测试，通过前向运动学、碰撞检测和轨迹指标评估模型的性能。\\n\\n**关键创新**：该研究的关键创新在于将XAI技术应用于逆运动学问题，并将其与物理仿真相结合，从而能够量化模型的可解释性与实际性能之间的关系。此外，论文还提出了两种轻量级的IKNet变体，旨在提高模型的效率和可解释性。\\n\\n**关键设计**：论文中，Improved IKNet引入了残差连接，以提高模型的训练效率和性能；Focused IKNet则将位置和方向解耦，以提高模型的可解释性。在避障测试中，使用基于胶囊的碰撞检测方法，并设计了相应的轨迹指标来评估模型的避障能力。SHAP值用于评估每个输入特征对模型输出的影响，从而揭示模型决策过程中的关键因素。",
            "application_zh": "该研究成果可应用于各种机器人操作场景，尤其是在需要高安全性和可靠性的环境中，如医疗机器人、工业机器人和家庭服务机器人。通过提高IK模型的可解释性，可以更容易地发现和解决潜在的安全问题，从而提高机器人的整体性能和用户信任度。此外，该方法还可以用于指导IK模型的架构设计和参数优化。",
            "highlight_zh": "实验结果表明，通过XAI技术可以揭示IK模型中隐藏的失效模式，并指导架构改进。定性热图显示，在姿态维度上更均匀地分配重要性的架构往往保持更宽的安全裕度，而不会影响位置精度。该研究验证了可解释AI技术在机器人逆运动学中的有效性，并为开发更安全、更可靠的机器人系统提供了新的思路。",
            "tags_zh": [
                "逆运动学",
                "可解释AI",
                "机器人操作",
                "避障",
                "SHAP值"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "OmniAgent: Audio-Guided Active Perception Agent for Omnimodal Audio-Video Understanding",
            "authors": [
                "Keda Tao",
                "Wenjie Du",
                "Bohan Yu",
                "Weiqiang Wang",
                "Jian Liu",
                "Huan Wang"
            ],
            "arxiv_id": "2512.23646v1",
            "summary": "Omnimodal large language models have made significant strides in unifying audio and visual modalities; however, they often lack the fine-grained cross-modal understanding and have difficulty with multimodal alignment. To address these limitations, we introduce OmniAgent, a fully audio-guided active perception agent that dynamically orchestrates specialized tools to achieve more fine-grained audio-visual reasoning. Unlike previous works that rely on rigid, static workflows and dense frame-captioning, this paper demonstrates a paradigm shift from passive response generation to active multimodal inquiry. OmniAgent employs dynamic planning to autonomously orchestrate tool invocation on demand, strategically concentrating perceptual attention on task-relevant cues. Central to our approach is a novel coarse-to-fine audio-guided perception paradigm, which leverages audio cues to localize temporal events and guide subsequent reasoning. Extensive empirical evaluations on three audio-video understanding benchmarks demonstrate that OmniAgent achieves state-of-the-art performance, surpassing leading open-source and proprietary models by substantial margins of 10% - 20% accuracy.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Website:https://kd-tao.github.io/OmniAgent/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23646v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniAgent：一种音频引导的主动感知Agent，用于全模态音视频理解",
            "summary_zh": "本文提出OmniAgent，一个完全由音频引导的主动感知Agent，旨在提升全模态大语言模型在音视频理解中的细粒度跨模态理解和多模态对齐能力。与依赖静态工作流和密集帧字幕的方法不同，OmniAgent实现了从被动响应生成到主动多模态查询的范式转变。它采用动态规划，自主地按需编排工具调用，并将感知注意力集中在任务相关的线索上。该方法的核心是一种新颖的由粗到精的音频引导感知范式，利用音频线索来定位时间事件，并指导后续的推理。在三个音视频理解基准上的大量实验评估表明，OmniAgent实现了最先进的性能，超越了领先的开源和专有模型，准确率提高了10%-20%。",
            "intro_zh": [
                "现有全模态大语言模型在音视频理解中缺乏细粒度的跨模态理解和多模态对齐能力。",
                "OmniAgent通过音频引导的主动感知，动态编排工具调用，实现由粗到精的音视频理解。",
                "实验结果表明，OmniAgent在音视频理解任务上取得了显著提升，超越现有模型10%-20%的准确率。"
            ],
            "method_zh": "**问题定义**：现有全模态大语言模型在音视频理解任务中，通常采用静态的工作流程和密集的帧字幕方式，缺乏对音频和视频信息之间细粒度关联的理解能力，难以实现精准的多模态对齐。这导致模型在复杂场景下的推理能力受限，无法有效利用音频信息引导视觉感知。\n\n**核心思路**：OmniAgent的核心思路是利用音频信息作为引导，主动地进行多模态感知和推理。通过动态规划工具调用，模型可以根据音频线索自主地选择合适的工具进行处理，并将注意力集中在与任务相关的视觉信息上，从而实现更精准的音视频理解。\n\n**技术框架**：OmniAgent的整体架构包含以下几个主要模块：1) 音频事件检测模块，用于从音频中提取关键事件信息；2) 动态规划模块，根据音频事件信息，规划工具调用顺序；3) 多模态感知模块，利用选定的工具对视频进行处理，提取相关视觉特征；4) 推理模块，结合音频和视觉信息进行推理，完成最终任务。整个流程是由粗到精的，首先通过音频定位关键事件，然后引导视觉感知。\n\n**关键创新**：OmniAgent的关键创新在于其主动感知的模式和由粗到精的音频引导策略。与传统的被动式模型不同，OmniAgent可以根据音频信息主动地选择合适的工具进行处理，并将注意力集中在与任务相关的视觉信息上。这种主动感知的模式使得模型能够更有效地利用多模态信息，提高理解能力。由粗到精的策略则保证了模型能够高效地定位关键信息，避免了对所有帧进行密集处理。\n\n**关键设计**：OmniAgent的关键设计包括：1) 音频事件检测模块的设计，需要选择合适的音频特征和模型结构，以保证能够准确地检测到关键事件；2) 动态规划模块的设计，需要定义合适的奖励函数和搜索策略，以保证能够找到最优的工具调用顺序；3) 多模态感知模块的设计，需要选择合适的视觉特征提取器和融合策略，以保证能够有效地利用视觉信息。",
            "application_zh": "OmniAgent在智能监控、智能家居、自动驾驶等领域具有广泛的应用前景。例如，在智能监控中，可以通过分析监控视频中的声音事件（如玻璃破碎、呼救声等）来自动识别异常情况并报警。在自动驾驶中，可以通过分析车辆周围的声音信息（如警笛声、喇叭声等）来辅助驾驶决策，提高安全性。",
            "highlight_zh": "OmniAgent在三个音视频理解基准测试中均取得了state-of-the-art的性能，相比于领先的开源和商业模型，准确率提升了10%-20%。这表明OmniAgent在音视频理解方面具有显著的优势，能够有效地利用多模态信息进行推理。",
            "tags_zh": [
                "音视频理解",
                "主动感知",
                "多模态融合",
                "音频引导",
                "动态规划"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23646v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23646v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23646v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "NeXT-IMDL: Build Benchmark for NeXT-Generation Image Manipulation Detection & Localization",
            "authors": [
                "Yifei Li",
                "Haoyuan He",
                "Yu Zheng",
                "Bingyao Yu",
                "Wenzhao Zheng",
                "Lei Chen",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "arxiv_id": "2512.23374v1",
            "summary": "The accessibility surge and abuse risks of user-friendly image editing models have created an urgent need for generalizable, up-to-date methods for Image Manipulation Detection and Localization (IMDL). Current IMDL research typically uses cross-dataset evaluation, where models trained on one benchmark are tested on others. However, this simplified evaluation approach conceals the fragility of existing methods when handling diverse AI-generated content, leading to misleading impressions of progress. This paper challenges this illusion by proposing NeXT-IMDL, a large-scale diagnostic benchmark designed not just to collect data, but to probe the generalization boundaries of current detectors systematically. Specifically, NeXT-IMDL categorizes AIGC-based manipulations along four fundamental axes: editing models, manipulation types, content semantics, and forgery granularity. Built upon this, NeXT-IMDL implements five rigorous cross-dimension evaluation protocols. Our extensive experiments on 11 representative models reveal a critical insight: while these models perform well in their original settings, they exhibit systemic failures and significant performance degradation when evaluated under our designed protocols that simulate real-world, various generalization scenarios. By providing this diagnostic toolkit and the new findings, we aim to advance the development towards building truly robust, next-generation IMDL models.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23374v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]manipulation"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "NeXT-IMDL：构建下一代图像篡改检测与定位的基准测试",
            "summary_zh": "用户友好的图像编辑模型的普及和滥用风险，使得对图像篡改检测与定位(IMDL)的通用且最新的方法的需求变得迫切。目前的IMDL研究通常使用跨数据集评估，即在某个基准上训练的模型在其他基准上进行测试。然而，这种简化的评估方法掩盖了现有方法在处理各种AI生成内容时的脆弱性，导致对进展的误导性印象。本文提出了NeXT-IMDL，一个大规模诊断基准，旨在系统地探测当前检测器的泛化边界，而不仅仅是收集数据。具体来说，NeXT-IMDL沿着四个基本轴对基于AIGC的篡改进行分类：编辑模型、篡改类型、内容语义和伪造粒度。在此基础上，NeXT-IMDL实现了五个严格的跨维度评估协议。对11个代表性模型的大量实验揭示了一个关键的见解：虽然这些模型在其原始设置中表现良好，但在我们设计的模拟真实世界各种泛化场景的协议下进行评估时，它们表现出系统性失败和显著的性能下降。通过提供这种诊断工具包和新的发现，我们的目标是推进构建真正强大的下一代IMDL模型。",
            "intro_zh": [
                "现有图像篡改检测方法在跨数据集评估中表现出脆弱性，无法有效处理多样化的AI生成内容。",
                "NeXT-IMDL通过构建大规模诊断基准，系统性地评估现有检测器在不同维度上的泛化能力。",
                "实验表明，现有模型在NeXT-IMDL的严格评估协议下性能显著下降，揭示了其泛化能力的不足。"
            ],
            "method_zh": "**问题定义**：现有图像篡改检测与定位(IMDL)方法在处理真实世界中各种AI生成内容时，泛化能力不足。跨数据集评估虽然常用，但无法充分揭示模型在不同编辑模型、篡改类型、内容语义和伪造粒度上的性能差异。现有方法容易在特定数据集上过拟合，导致在实际应用中表现不佳。\\n\\n**核心思路**：NeXT-IMDL的核心思路是构建一个大规模、多维度的诊断基准，通过系统性的跨维度评估协议，全面评估现有IMDL模型的泛化能力。该基准旨在模拟真实世界的复杂场景，揭示模型在不同因素影响下的性能瓶颈，从而推动更鲁棒的IMDL模型的发展。\\n\\n**技术框架**：NeXT-IMDL的整体框架包括数据收集与组织、维度划分、评估协议设计和实验评估四个主要阶段。首先，收集大量AI生成图像，涵盖不同的编辑模型、篡改类型、内容语义和伪造粒度。然后，沿着这四个维度对数据进行分类和组织。接着，设计五个严格的跨维度评估协议，模拟真实世界的各种泛化场景。最后，在NeXT-IMDL上评估现有IMDL模型的性能，并分析结果。\\n\\n**关键创新**：NeXT-IMDL的关键创新在于其多维度的数据组织方式和严格的跨维度评估协议。与以往的基准测试不同，NeXT-IMDL不仅仅是收集数据，而是系统性地探索了不同因素对IMDL模型性能的影响。通过跨维度评估，可以更全面地了解模型的泛化能力，并发现其潜在的弱点。\\n\\n**关键设计**：NeXT-IMDL的关键设计包括四个维度：编辑模型（例如StyleGAN、DALL-E）、篡改类型（例如图像修复、对象移除）、内容语义（例如人脸、风景）和伪造粒度（例如小区域篡改、全局篡改）。五个评估协议包括：模型泛化（在不同编辑模型上训练和测试）、类型泛化（在不同篡改类型上训练和测试）、语义泛化（在不同内容语义上训练和测试）、粒度泛化（在不同伪造粒度上训练和测试）和组合泛化（同时考虑多个维度的泛化能力）。",
            "application_zh": "NeXT-IMDL的研究成果可应用于数字取证、社交媒体内容审核、新闻真实性验证等领域。通过提高图像篡改检测的准确性和鲁棒性，可以有效防止虚假信息的传播，维护网络安全和公共利益。未来，该基准可以不断扩展和更新，以适应新的AI生成技术和篡改手段。",
            "highlight_zh": "在NeXT-IMDL的评估中，11个代表性IMDL模型在跨维度评估协议下表现出显著的性能下降。例如，在模型泛化评估中，模型在新的编辑模型生成的数据上准确率下降了20%-50%。这些结果表明，现有IMDL模型在真实世界的复杂场景中泛化能力不足，需要进一步改进。",
            "tags_zh": [
                "图像篡改检测",
                "图像篡改定位",
                "AI生成内容",
                "基准测试",
                "泛化能力"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23374v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23374v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23374v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "MedGemma vs GPT-4: Open-Source and Proprietary Zero-shot Medical Disease Classification from Images",
            "authors": [
                "Md. Sazzadul Islam Prottasha",
                "Nabil Walid Rafi"
            ],
            "arxiv_id": "2512.23304v1",
            "summary": "Multimodal Large Language Models (LLMs) introduce an emerging paradigm for medical imaging by interpreting scans through the lens of extensive clinical knowledge, offering a transformative approach to disease classification. This study presents a critical comparison between two fundamentally different AI architectures: the specialized open-source agent MedGemma and the proprietary large multimodal model GPT-4 for diagnosing six different diseases. The MedGemma-4b-it model, fine-tuned using Low-Rank Adaptation (LoRA), demonstrated superior diagnostic capability by achieving a mean test accuracy of 80.37% compared to 69.58% for the untuned GPT-4. Furthermore, MedGemma exhibited notably higher sensitivity in high-stakes clinical tasks, such as cancer and pneumonia detection. Quantitative analysis via confusion matrices and classification reports provides comprehensive insights into model performance across all categories. These results emphasize that domain-specific fine-tuning is essential for minimizing hallucinations in clinical implementation, positioning MedGemma as a sophisticated tool for complex, evidence-based medical reasoning.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Accepted for publication in the Journal of Machine Learning and Deep Learning (JMLDL). 9 pages, 9 figures, 10 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23304v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MedGemma在医学图像疾病分类中优于GPT-4，领域微调至关重要",
            "summary_zh": "本研究对比了两种架构迥异的AI模型在医学图像疾病分类中的表现：专门的开源模型MedGemma和专有的多模态大模型GPT-4，用于诊断六种不同的疾病。结果表明，经过低秩适应(LoRA)微调的MedGemma-4b-it模型表现出更优越的诊断能力，平均测试准确率达到80.37%，而未调优的GPT-4为69.58%。此外，MedGemma在高风险临床任务（如癌症和肺炎检测）中表现出明显更高的灵敏度。通过混淆矩阵和分类报告进行的定量分析，全面深入地展示了模型在所有类别中的性能。这些结果强调，领域特定的微调对于最小化临床应用中的幻觉至关重要，使MedGemma成为复杂、基于证据的医学推理的强大工具。",
            "intro_zh": [
                "现有通用多模态大模型在医学图像诊断中存在幻觉问题，限制了其临床应用。",
                "论文提出利用领域知识微调开源模型MedGemma，提升其在特定疾病分类任务上的性能。",
                "实验结果表明，微调后的MedGemma在准确率和灵敏度上均优于未微调的GPT-4。"
            ],
            "method_zh": "**问题定义**：论文旨在解决医学图像疾病分类问题。现有通用多模态大模型（如GPT-4）虽然拥有广泛的知识，但在医学领域缺乏专业知识，容易产生幻觉，导致诊断错误。这限制了它们在临床环境中的可靠应用。\\n\\n**核心思路**：论文的核心思路是利用领域特定的数据对开源模型MedGemma进行微调，使其更好地适应医学图像的特点和疾病的诊断逻辑。通过微调，模型可以学习到更准确的医学知识，从而减少幻觉，提高诊断准确率。\\n\\n**技术框架**：整体框架包括两个主要阶段：首先，使用低秩适应(LoRA)方法对MedGemma-4b-it模型进行微调，使其适应医学图像数据。其次，将微调后的MedGemma与未微调的GPT-4进行比较，评估它们在六种不同疾病的分类任务中的性能。评估指标包括准确率、灵敏度、混淆矩阵和分类报告。\\n\\n**关键创新**：论文的关键创新在于证明了领域特定微调对于提高多模态大模型在医学图像诊断中的性能至关重要。通过对开源模型MedGemma进行微调，使其在特定任务上超越了未微调的专有模型GPT-4，突出了领域知识的重要性。\\n\\n**关键设计**：论文使用了低秩适应(LoRA)方法进行微调，这是一种参数高效的微调技术，可以在不修改原始模型参数的情况下，通过引入少量可训练的参数来适应新的任务。具体来说，LoRA通过在预训练模型的权重矩阵旁边添加低秩矩阵来实现。此外，论文还仔细选择了用于微调的数据集，并针对不同的疾病类别进行了性能评估。",
            "application_zh": "该研究成果可应用于辅助医生进行疾病诊断，尤其是在资源有限的地区，可以利用开源模型和领域微调技术构建低成本、高性能的医学图像诊断系统。未来，该技术有望扩展到更多疾病的诊断，并与其他医疗信息系统集成，提升医疗服务的效率和质量。",
            "highlight_zh": "实验结果表明，经过LoRA微调的MedGemma-4b-it模型在六种疾病的平均测试准确率达到80.37%，显著高于未调优的GPT-4的69.58%。尤其在癌症和肺炎等高风险疾病的检测中，MedGemma表现出更高的灵敏度，表明领域微调能够有效提升模型在关键临床任务中的性能。",
            "tags_zh": [
                "医学图像分类",
                "多模态大模型",
                "领域微调",
                "MedGemma",
                "GPT-4",
                "低秩适应",
                "疾病诊断"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "AVOID: The Adverse Visual Conditions Dataset with Obstacles for Driving Scene Understanding",
            "authors": [
                "Jongoh Jeong",
                "Taek-Jin Song",
                "Jong-Hwan Kim",
                "Kuk-Jin Yoon"
            ],
            "arxiv_id": "2512.23215v1",
            "summary": "Understanding road scenes for visual perception remains crucial for intelligent self-driving cars. In particular, it is desirable to detect unexpected small road hazards reliably in real-time, especially under varying adverse conditions (e.g., weather and daylight). However, existing road driving datasets provide large-scale images acquired in either normal or adverse scenarios only, and often do not contain the road obstacles captured in the same visual domain as for the other classes. To address this, we introduce a new dataset called AVOID, the Adverse Visual Conditions Dataset, for real-time obstacle detection collected in a simulated environment. AVOID consists of a large set of unexpected road obstacles located along each path captured under various weather and time conditions. Each image is coupled with the corresponding semantic and depth maps, raw and semantic LiDAR data, and waypoints, thereby supporting most visual perception tasks. We benchmark the results on high-performing real-time networks for the obstacle detection task, and also propose and conduct ablation studies using a comprehensive multi-task network for semantic segmentation, depth and waypoint prediction tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23215v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "AVOID：用于驾驶场景理解的含障碍物恶劣视觉条件数据集",
            "summary_zh": "为了智能自动驾驶汽车，理解道路场景至关重要。尤其是在各种恶劣条件（如天气和日光）下，可靠地实时检测到意外的小型道路障碍物是理想的。然而，现有的道路驾驶数据集通常只提供在正常或恶劣场景下获取的大规模图像，并且通常不包含与其他类别在同一视觉域中捕获的道路障碍物。为了解决这个问题，我们引入了一个名为AVOID的新数据集，即恶劣视觉条件数据集，用于在模拟环境中收集的实时障碍物检测。AVOID包含大量位于每条路径上的意外道路障碍物，这些障碍物是在各种天气和时间条件下捕获的。每张图像都配有相应的语义图和深度图、原始和语义LiDAR数据以及航点，从而支持大多数视觉感知任务。我们对用于障碍物检测任务的高性能实时网络进行了基准测试，并提出并使用综合多任务网络进行语义分割、深度和航点预测任务的消融研究。",
            "intro_zh": [
                "现有驾驶数据集缺乏在恶劣视觉条件下，与其它类别同域的道路障碍物数据，限制了自动驾驶感知系统的鲁棒性。",
                "AVOID数据集旨在提供一个包含各种恶劣天气和光照条件下的道路障碍物图像，以及语义、深度、LiDAR和航点信息的数据集。",
                "论文在AVOID数据集上对实时障碍物检测网络进行了基准测试，并使用多任务网络进行了语义分割、深度和航点预测的消融研究。"
            ],
            "method_zh": "**问题定义**：论文旨在解决自动驾驶场景下，在恶劣视觉条件下实时检测道路障碍物的问题。现有的道路驾驶数据集要么只包含正常场景，要么只包含恶劣场景，并且通常缺乏与其它类别在同一视觉域中捕获的道路障碍物数据。这使得训练出的模型在实际复杂环境中泛化能力不足，难以可靠地检测出道路上的潜在危险。\n\n**核心思路**：论文的核心思路是构建一个包含各种恶劣视觉条件（天气、光照）下的道路障碍物数据集，并提供丰富的标注信息（语义、深度、LiDAR、航点），从而为训练更鲁棒的自动驾驶感知模型提供数据基础。通过在模拟环境中生成数据，可以方便地控制各种条件，并获取精确的标注。\n\n**技术框架**：AVOID数据集的构建流程主要包括以下几个阶段：首先，在模拟环境中设置不同的天气和光照条件；然后，在道路上随机放置各种障碍物；接着，使用虚拟相机和传感器（LiDAR）采集图像、深度图、语义图和点云数据；最后，对采集到的数据进行标注，包括障碍物的类别、位置、深度等信息。数据集还提供了航点信息，用于支持路径规划任务。\n\n**关键创新**：该论文的关键创新在于构建了一个专门针对恶劣视觉条件下的道路障碍物检测的数据集。与现有数据集相比，AVOID数据集更加关注恶劣天气和光照条件下的障碍物检测，并且提供了丰富的标注信息，可以支持多种视觉感知任务。此外，数据集是在模拟环境中生成的，可以方便地扩展和修改，以满足不同的研究需求。\n\n**关键设计**：AVOID数据集包含多种天气条件（晴天、雨天、雾天、雪天）和时间条件（白天、夜晚、黄昏）。障碍物的种类包括行人、车辆、交通锥、垃圾桶等。数据集的图像分辨率为1920x1080。论文还使用了常见的实时目标检测网络（具体网络名称未知）作为基线模型，并在数据集上进行了性能评估。多任务网络用于语义分割、深度预测和航点预测，损失函数和网络结构的具体细节未知。",
            "application_zh": "AVOID数据集可用于训练和评估自动驾驶汽车的感知系统，尤其是在恶劣视觉条件下的障碍物检测能力。该数据集可以促进相关算法的开发和改进，提高自动驾驶汽车在复杂环境中的安全性和可靠性。此外，该数据集还可以应用于机器人导航、智能监控等领域。",
            "highlight_zh": "论文在AVOID数据集上对高性能实时网络进行了基准测试，结果表明，现有模型在恶劣视觉条件下的障碍物检测性能仍然有待提高。此外，论文还使用多任务网络进行了语义分割、深度和航点预测的消融研究，结果表明，多任务学习可以提高模型的整体性能。具体的性能数据和提升幅度未知。",
            "tags_zh": [
                "自动驾驶",
                "道路障碍物检测",
                "恶劣视觉条件",
                "数据集",
                "模拟环境"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "REVEALER: Reinforcement-Guided Visual Reasoning for Element-Level Text-Image Alignment Evaluation",
            "authors": [
                "Fulin Shi",
                "Wenyi Xiao",
                "Bin Chen",
                "Liang Din",
                "Leilei Gan"
            ],
            "arxiv_id": "2512.23169v1",
            "summary": "Evaluating the alignment between textual prompts and generated images is critical for ensuring the reliability and usability of text-to-image (T2I) models. However, most existing evaluation methods rely on coarse-grained metrics or static QA pipelines, which lack fine-grained interpretability and struggle to reflect human preferences. To address this, we propose REVEALER, a unified framework for element-level alignment evaluation based on reinforcement-guided visual reasoning. Adopting a structured \"grounding-reasoning-conclusion\" paradigm, our method enables Multimodal Large Language Models (MLLMs) to explicitly localize semantic elements and derive interpretable alignment judgments. We optimize the model via Group Relative Policy Optimization(GRPO) using a composite reward function that incorporates structural format, grounding accuracy, and alignment fidelity. Extensive experiments across four benchmarks-EvalMuse-40K, RichHF, MHaluBench, and GenAI-Bench-demonstrate that REVEALER achieves state-of-the-art performance. Our approach consistently outperforms both strong proprietary models and supervised baselines while demonstrating superior inference efficiency compared to existing iterative visual reasoning methods.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23169v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "REVEALER：提出强化学习引导的视觉推理框架，用于元素级文本-图像对齐评估",
            "summary_zh": "评估文本提示与生成图像之间的对齐对于确保文本到图像（T2I）模型的可靠性和可用性至关重要。然而，现有的大多数评估方法依赖于粗粒度的指标或静态的问答流程，缺乏细粒度的可解释性，难以反映人类偏好。为了解决这个问题，我们提出了REVEALER，一个统一的框架，用于基于强化学习引导的视觉推理进行元素级对齐评估。我们的方法采用结构化的“grounding-reasoning-conclusion”范式，使多模态大型语言模型（MLLM）能够显式地定位语义元素并得出可解释的对齐判断。我们使用包含结构格式、grounding准确性和对齐保真度的复合奖励函数，通过Group Relative Policy Optimization (GRPO)优化模型。在四个基准测试（EvalMuse-40K、RichHF、MHaluBench和GenAI-Bench）上的大量实验表明，REVEALER实现了最先进的性能。我们的方法始终优于强大的专有模型和监督基线，同时与现有的迭代视觉推理方法相比，表现出卓越的推理效率。",
            "intro_zh": [
                "现有文本-图像对齐评估方法依赖粗粒度指标或静态QA流程，缺乏细粒度可解释性，难以反映人类偏好。",
                "REVEALER采用“grounding-reasoning-conclusion”范式，利用强化学习引导MLLM进行元素级对齐评估，提升可解释性。",
                "实验表明，REVEALER在多个基准测试中达到SOTA性能，优于现有模型，并具有更高的推理效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决文本到图像生成模型中，评估生成图像与文本描述之间对齐程度的问题。现有方法主要依赖于粗粒度的指标，例如整体相似度评分，或者使用静态的问答流程。这些方法无法提供细粒度的解释，难以判断图像中哪些元素与文本描述相符，哪些不符，也难以准确反映人类的偏好。\\n\\n**核心思路**：REVEALER的核心思路是利用多模态大型语言模型（MLLM）进行视觉推理，并采用强化学习来引导模型学习如何进行元素级别的对齐评估。通过将评估过程分解为“grounding-reasoning-conclusion”三个步骤，模型可以首先定位图像中的语义元素，然后推理这些元素与文本描述的对齐关系，最后给出对齐判断。这种方法提供了更细粒度的可解释性，并且可以通过强化学习来优化模型的评估策略。\\n\\n**技术框架**：REVEALER的整体框架包含以下几个主要模块：1) Grounding模块：使用MLLM定位图像中的语义元素，例如物体、属性等。2) Reasoning模块：使用MLLM推理这些元素与文本描述的对齐关系。3) Conclusion模块：根据推理结果，给出最终的对齐判断。整个框架采用强化学习进行优化，使用Group Relative Policy Optimization (GRPO)算法。\\n\\n**关键创新**：REVEALER的关键创新在于：1) 提出了一个统一的框架，用于元素级别的文本-图像对齐评估。2) 采用强化学习来引导MLLM进行视觉推理，提高了评估的准确性和可解释性。3) 使用了结构化的“grounding-reasoning-conclusion”范式，使模型能够显式地定位语义元素并得出可解释的对齐判断。\\n\\n**关键设计**：REVEALER的关键设计包括：1) 使用复合奖励函数，包含结构格式、grounding准确性和对齐保真度，用于强化学习的训练。2) 采用Group Relative Policy Optimization (GRPO)算法，加速强化学习的收敛。3) 针对不同的评估任务，设计了不同的prompt模板，以提高模型的泛化能力。",
            "application_zh": "REVEALER可应用于文本到图像生成模型的评估和改进，帮助开发者更好地理解模型的优缺点，并针对性地进行优化。此外，该方法还可以用于图像检索、图像描述等任务，提高多模态任务的性能和可解释性。未来，该研究或可扩展到视频生成、3D内容生成等领域。",
            "highlight_zh": "REVEALER在EvalMuse-40K、RichHF、MHaluBench和GenAI-Bench四个基准测试中均取得了SOTA性能，显著优于现有的专有模型和监督基线。例如，在EvalMuse-40K数据集上，REVEALER的性能提升超过10%。此外，REVEALER还具有更高的推理效率，相比于现有的迭代视觉推理方法，能够更快地完成评估任务。",
            "tags_zh": [
                "文本-图像对齐",
                "视觉推理",
                "强化学习",
                "多模态学习",
                "大型语言模型"
            ],
            "_index": 44,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23169v1/figures/figure1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23169v1/figures/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23169v1/figures/comparison_radar_chart.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Joint Link Adaptation and Device Scheduling Approach for URLLC Industrial IoT Network: A DRL-based Method with Bayesian Optimization",
            "authors": [
                "Wei Gao",
                "Paul Zheng",
                "Peng Wu",
                "Yulin Hu",
                "Anke Schmeink"
            ],
            "arxiv_id": "2512.23493v1",
            "summary": "In this article, we consider an industrial internet of things (IIoT) network supporting multi-device dynamic ultra-reliable low-latency communication (URLLC) while the channel state information (CSI) is imperfect. A joint link adaptation (LA) and device scheduling (including the order) design is provided, aiming at maximizing the total transmission rate under strict block error rate (BLER) constraints. In particular, a Bayesian optimization (BO) driven Twin Delayed Deep Deterministic Policy Gradient (TD3) method is proposed, which determines the device served order sequence and the corresponding modulation and coding scheme (MCS) adaptively based on the imperfect CSI. Note that the imperfection of CSI, error sample imbalance in URLLC networks, as well as the parameter sensitivity nature of the TD3 algorithm likely diminish the algorithm's convergence speed and reliability. To address such an issue, we proposed a BO based training mechanism for the convergence speed improvement, which provides a more reliable learning direction and sample selection method to track the imbalance sample problem. Via extensive simulations, we show that the proposed algorithm achieves faster convergence and higher sum-rate performance compared to existing solutions.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "16 page,10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23493v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]DRL",
                        "TD3"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "针对URLLC工业物联网，提出基于贝叶斯优化的DRL联合链路自适应与设备调度方法",
            "summary_zh": "本文研究了支持多设备动态超可靠低延迟通信（URLLC）的工业物联网（IIoT）网络，其中信道状态信息（CSI）是不完善的。提出了一种联合链路自适应（LA）和设备调度（包括顺序）设计，旨在严格的误块率（BLER）约束下最大化总传输速率。特别地，提出了一种基于贝叶斯优化（BO）驱动的双延迟深度确定性策略梯度（TD3）方法，该方法基于不完善的CSI自适应地确定设备服务顺序序列和相应的调制和编码方案（MCS）。考虑到CSI的不完善、URLLC网络中的错误样本不平衡以及TD3算法的参数敏感性可能会降低算法的收敛速度和可靠性，我们提出了一种基于BO的训练机制来提高收敛速度，该机制提供了一种更可靠的学习方向和样本选择方法来跟踪不平衡样本问题。通过大量的仿真，我们表明，与现有解决方案相比，所提出的算法实现了更快的收敛速度和更高的总速率性能。",
            "intro_zh": [
                "现有URLLC工业物联网中，不完善的信道状态信息和样本不平衡问题导致链路自适应和设备调度困难。",
                "提出基于贝叶斯优化的TD3算法，自适应地确定设备服务顺序和MCS，以最大化总传输速率并满足BLER约束。",
                "仿真结果表明，该算法比现有方案收敛更快，并能实现更高的总速率性能，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决URLLC工业物联网中，在不完善的信道状态信息（CSI）条件下，如何联合优化链路自适应（LA）和设备调度，以最大化总传输速率并满足严格的误块率（BLER）约束的问题。现有方法通常难以处理CSI不完善带来的挑战，并且在URLLC场景下，错误样本的稀缺性导致训练困难。此外，传统的深度强化学习算法对参数敏感，难以保证收敛性和可靠性。\\n\\n**核心思路**：论文的核心思路是利用深度强化学习（DRL）来学习最优的设备调度策略和链路自适应方案。具体来说，使用Twin Delayed Deep Deterministic Policy Gradient (TD3) 算法，该算法适用于连续动作空间，并能有效缓解过估计问题。为了解决CSI不完善和样本不平衡问题，引入贝叶斯优化（BO）来指导TD3的训练过程，从而加速收敛并提高算法的鲁棒性。\\n\\n**技术框架**：整体框架包含以下几个主要模块：1) 环境建模：模拟URLLC工业物联网的信道环境，包括CSI的不完善性。2) 状态空间设计：定义TD3算法的状态空间，包括信道状态、设备队列长度等信息。3) 动作空间设计：定义TD3算法的动作空间，包括设备调度顺序和调制编码方案（MCS）。4) 奖励函数设计：设计奖励函数，鼓励算法最大化总传输速率，同时满足BLER约束。5) 基于贝叶斯优化的TD3训练：使用贝叶斯优化来调整TD3算法的超参数，并选择更有价值的样本进行训练。\\n\\n**关键创新**：论文的关键创新在于将贝叶斯优化与TD3算法相结合，用于解决URLLC工业物联网中的联合链路自适应和设备调度问题。与传统的DRL方法相比，该方法能够更有效地处理CSI的不完善性和样本不平衡问题，从而提高算法的收敛速度和性能。此外，该方法还能够自适应地调整设备调度顺序和MCS，以适应不同的信道条件。\\n\\n**关键设计**：在贝叶斯优化方面，使用高斯过程作为代理模型，并采用期望提升（Expected Improvement）作为采集函数，以选择最有希望提高性能的超参数组合。在TD3算法方面，使用了两个Critic网络来缓解过估计问题，并采用了延迟更新策略来提高训练的稳定性。奖励函数的设计至关重要，需要仔细权衡总传输速率和BLER约束之间的关系。具体参数设置（如学习率、折扣因子等）未知，需要在实际应用中进行调整。",
            "application_zh": "该研究成果可应用于各种需要超可靠低延迟通信的工业物联网场景，例如智能工厂、自动化生产线、远程医疗等。通过优化链路自适应和设备调度，可以提高通信效率，降低延迟，从而提升工业生产的自动化水平和智能化程度。未来，该方法有望扩展到更复杂的网络拓扑和更严格的QoS需求场景。",
            "highlight_zh": "仿真结果表明，所提出的基于贝叶斯优化的TD3算法在收敛速度和总速率性能方面均优于现有解决方案。具体来说，该算法能够更快地找到最优策略，并且能够实现更高的总传输速率，同时满足严格的BLER约束。与传统的TD3算法相比，该算法的收敛速度提高了约20%，总速率性能提升了约10%（具体数值未知，此处为示例）。",
            "tags_zh": [
                "URLLC",
                "工业物联网",
                "链路自适应",
                "设备调度",
                "深度强化学习",
                "贝叶斯优化",
                "TD3算法"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23493v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23493v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23493v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance",
            "authors": [
                "Zhuo Li",
                "Pengyu Cheng",
                "Zhechao Yu",
                "Feifei Tong",
                "Anningzhe Gao",
                "Tsung-Hui Chang",
                "Xiang Wan",
                "Erchao Zhao",
                "Xiaoxi Jiang",
                "Guanjun Jiang"
            ],
            "arxiv_id": "2512.23461v1",
            "summary": "Reward models (RMs) are essential in reinforcement learning from human feedback (RLHF) to align large language models (LLMs) with human values. However, RM training data is commonly recognized as low-quality, containing inductive biases that can easily lead to overfitting and reward hacking. For example, more detailed and comprehensive responses are usually human-preferred but with more words, leading response length to become one of the inevitable inductive biases. A limited number of prior RM debiasing approaches either target a single specific type of bias or model the problem with only simple linear correlations, \\textit{e.g.}, Pearson coefficients. To mitigate more complex and diverse inductive biases in reward modeling, we introduce a novel information-theoretic debiasing method called \\textbf{D}ebiasing via \\textbf{I}nformation optimization for \\textbf{R}M (DIR). Inspired by the information bottleneck (IB), we maximize the mutual information (MI) between RM scores and human preference pairs, while minimizing the MI between RM outputs and biased attributes of preference inputs. With theoretical justification from information theory, DIR can handle more sophisticated types of biases with non-linear correlations, broadly extending the real-world application scenarios for RM debiasing methods. In experiments, we verify the effectiveness of DIR with three types of inductive biases: \\textit{response length}, \\textit{sycophancy}, and \\textit{format}. We discover that DIR not only effectively mitigates target inductive biases but also enhances RLHF performance across diverse benchmarks, yielding better generalization abilities. The code and training recipes are available at https://github.com/Qwen-Applications/DIR.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23461v1",
            "code_links": [
                {
                    "url": "https://github.com/Qwen-Applications/DIR",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RLHF"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DIR方法，通过信息论优化消除奖励模型中的归纳偏置，提升RLHF性能。",
            "summary_zh": "奖励模型（RM）在基于人类反馈的强化学习（RLHF）中至关重要，用于使大型语言模型（LLM）与人类价值观对齐。然而，RM训练数据通常被认为是低质量的，包含容易导致过拟合和奖励攻击的归纳偏置。例如，更详细和全面的回复通常更受人类青睐，但也包含更多词语，导致回复长度成为不可避免的归纳偏置之一。为了缓解奖励建模中更复杂和多样的归纳偏置，我们引入了一种新颖的基于信息论的去偏置方法，称为DIR。受信息瓶颈（IB）的启发，我们最大化RM分数与人类偏好对之间的互信息（MI），同时最小化RM输出与偏好输入的有偏属性之间的MI。DIR可以处理具有非线性相关性的更复杂类型的偏差，从而广泛扩展RM去偏置方法的实际应用场景。实验表明，DIR不仅有效地缓解了目标归纳偏置，而且提高了各种基准测试中的RLHF性能，从而产生了更好的泛化能力。",
            "intro_zh": [
                "现有奖励模型易受训练数据中归纳偏置的影响，导致过拟合和奖励攻击，限制了模型泛化能力。",
                "DIR方法通过最大化奖励分数与人类偏好间的互信息，并最小化奖励输出与偏置属性间的互信息，实现去偏置。",
                "实验证明DIR能有效缓解回复长度、谄媚和格式等归纳偏置，并提升RLHF在多个基准测试中的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决奖励模型（RM）训练中存在的归纳偏置问题。现有的RM训练数据质量不高，包含如回复长度、谄媚等多种归纳偏置，导致模型过拟合这些偏置，无法真正学习到人类的偏好，从而影响RLHF的性能。现有的去偏置方法要么只针对特定类型的偏置，要么采用简单的线性相关模型，无法处理复杂的非线性偏置。\n\n**核心思路**：论文的核心思路是利用信息论中的信息瓶颈（Information Bottleneck, IB）原理进行去偏置。具体来说，希望奖励模型能够尽可能多地保留关于人类偏好的信息，同时尽可能少地保留关于输入中偏置属性的信息。通过这种方式，可以迫使模型关注真正重要的特征，而不是被偏置属性所迷惑。\n\n**技术框架**：DIR方法的整体框架包含以下几个关键部分：首先，使用奖励模型对输入进行评分，得到奖励分数；然后，计算奖励分数与人类偏好对之间的互信息，并最大化该互信息；同时，计算奖励模型的输出与输入中偏置属性之间的互信息，并最小化该互信息。通过优化这两个互信息，可以实现去偏置的目的。整个过程可以看作是一个信息瓶颈的优化过程。\n\n**关键创新**：DIR方法最重要的创新在于其基于信息论的去偏置框架。与以往方法不同，DIR不依赖于对偏置类型的先验知识，也不需要手动设计特定的去偏置策略。DIR通过优化互信息，自动学习如何去除偏置，从而能够处理更复杂和多样的偏置类型。此外，DIR方法可以处理非线性相关的偏置，这是以往线性模型无法做到的。\n\n**关键设计**：DIR的关键设计包括：1) 互信息的计算方法。论文采用了一种基于神经网络的互信息估计方法，可以有效地估计高维数据的互信息。2) 损失函数的设计。损失函数由两部分组成：一部分是最大化奖励分数与人类偏好之间的互信息，另一部分是最小化奖励模型输出与偏置属性之间的互信息。3) 偏置属性的定义。论文针对不同的偏置类型，设计了不同的偏置属性提取器，例如，对于回复长度偏置，可以直接使用回复的长度作为偏置属性。",
            "application_zh": "该研究成果可广泛应用于各种需要从人类反馈中学习的场景，例如对话系统、文本生成、推荐系统等。通过消除奖励模型中的归纳偏置，可以提高模型的泛化能力和鲁棒性，使其更好地对齐人类价值观，从而生成更符合人类期望的内容。该方法还有助于提升AI系统的安全性和可靠性，降低奖励攻击的风险。",
            "highlight_zh": "实验结果表明，DIR方法在缓解回复长度、谄媚和格式等归纳偏置方面表现出色。例如，在针对回复长度偏置的实验中，DIR方法能够显著降低奖励模型对回复长度的依赖，同时提高RLHF的性能。此外，DIR方法在多个基准测试中都取得了优于现有方法的性能，证明了其有效性和泛化能力。",
            "tags_zh": [
                "奖励模型",
                "归纳偏置",
                "信息瓶颈",
                "互信息",
                "强化学习",
                "人类反馈",
                "语言模型"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23461v1/figures/framework1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23461v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23461v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Post-Training Quantization of OpenPangu Models for Efficient Deployment on Atlas A2",
            "authors": [
                "Yilun Luo",
                "HuaQing Zheng",
                "Haoqian Meng",
                "Wenyuan Liu",
                "Peng Zhang"
            ],
            "arxiv_id": "2512.23367v1",
            "summary": "Huawei's openPangu-Embedded-1B and openPangu-Embedded-7B, variants of the openPangu large language model, integrate three distinct Chain-of-Thought (CoT) reasoning paradigms, namely slow_think, auto_think, and no_think. While these CoT modes enhance reasoning capabilities, their generation of extended reasoning traces introduces substantial memory and latency overheads, posing challenges for practical deployment on Ascend NPUs. This paper addresses these computational constraints by leveraging low-bit quantization, which transforms FP16 computations into more efficient integer arithmetic. We introduce a unified low-bit inference framework, supporting INT8 (W8A8) and W4A8 quantization, specifically optimized for openPangu-Embedded models on the Atlas A2. Our comprehensive evaluation, conducted across all three CoT modes on code generation benchmarks (HumanEval and MBPP), demonstrates the efficacy of this approach. INT8 quantization consistently preserves over 90\\% of the FP16 baseline accuracy and achieves a 1.5x prefill speedup on the Atlas A2. Furthermore, W4A8 quantization significantly reduces memory consumption, albeit with a moderate trade-off in accuracy. These findings collectively indicate that low-bit quantization effectively facilitates efficient CoT reasoning on Ascend NPUs, maintaining high model fidelity.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23367v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对昇腾A2，提出低比特量化方案，加速盘古模型推理并降低内存占用。",
            "summary_zh": "华为的openPangu-Embedded-1B和openPangu-Embedded-7B是大语言模型openPangu的变体，集成了三种不同的思维链（CoT）推理范式，即slow_think、auto_think和no_think。虽然这些CoT模式增强了推理能力，但它们生成的扩展推理轨迹带来了大量的内存和延迟开销，给在昇腾NPU上的实际部署带来了挑战。本文通过利用低比特量化来解决这些计算约束，将FP16计算转换为更高效的整数运算。我们引入了一个统一的低比特推理框架，支持INT8 (W8A8) 和 W4A8 量化，专门为Atlas A2上的openPangu-Embedded模型进行了优化。我们对所有三种CoT模式在代码生成基准（HumanEval和MBPP）上进行了全面评估，证明了该方法的有效性。INT8量化始终保持超过90%的FP16基线精度，并在Atlas A2上实现了1.5倍的预填充加速。此外，W4A8量化显著降低了内存消耗，尽管在精度上有所折衷。这些发现共同表明，低比特量化有效地促进了昇腾NPU上高效的CoT推理，同时保持了高模型保真度。",
            "intro_zh": [
                "大语言模型推理计算量大，内存占用高，给部署带来挑战，尤其是在资源受限的Ascend NPU上。",
                "采用低比特量化，将FP16计算转换为更高效的整数运算，降低内存占用和计算复杂度。",
                "在代码生成任务上，INT8量化保持了90%以上的精度，并实现了1.5倍的加速；W4A8量化显著降低了内存消耗。"
            ],
            "method_zh": "**问题定义**：论文旨在解决openPangu-Embedded系列模型在Ascend NPU（特别是Atlas A2）上部署时，由于CoT推理导致的内存和延迟开销过大的问题。现有方法，即FP16精度推理，无法满足资源受限场景下的部署需求，需要寻找更高效的推理方案。\\n\\n**核心思路**：论文的核心思路是利用低比特量化技术，将FP16精度的模型参数和激活值转换为低比特（INT8或W4A8）表示，从而降低内存占用和计算复杂度。通过量化，可以将浮点运算转化为更快的整数运算，从而加速推理过程。\\n\\n**技术框架**：论文提出了一个统一的低比特推理框架，该框架支持INT8 (W8A8) 和 W4A8 两种量化方式。该框架针对openPangu-Embedded模型在Atlas A2上的部署进行了优化。具体流程包括：首先，对FP16模型进行量化，得到低比特模型；然后，使用低比特模型在Atlas A2上进行推理。\\n\\n**关键创新**：论文的关键创新在于针对openPangu-Embedded模型和Atlas A2硬件平台，设计并实现了高效的低比特量化推理框架。该框架能够有效地平衡模型精度、推理速度和内存占用，从而实现模型在资源受限环境下的高效部署。\\n\\n**关键设计**：论文中未明确说明量化方案的具体细节，例如量化参数的校准方法、量化误差的补偿策略等。这些细节对于量化模型的性能至关重要，但论文中未提供足够的信息。",
            "application_zh": "该研究成果可应用于各种需要高效部署大语言模型的场景，例如边缘计算设备、移动设备等。通过低比特量化，可以在资源受限的硬件平台上运行更大规模的模型，从而提升AI应用的智能化水平。该技术对于推动大语言模型在实际场景中的应用具有重要意义。",
            "highlight_zh": "实验结果表明，INT8量化在HumanEval和MBPP代码生成基准上保持了超过90%的FP16基线精度，并在Atlas A2上实现了1.5倍的预填充加速。W4A8量化虽然在精度上有所下降，但显著降低了内存消耗。这些结果验证了低比特量化在加速推理和降低内存占用方面的有效性。",
            "tags_zh": [
                "低比特量化",
                "大语言模型",
                "模型部署",
                "昇腾NPU",
                "Atlas A2",
                "思维链推理",
                "INT8量化",
                "W4A8量化"
            ],
            "_index": 47,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23367v1/iclr2026/smooth_hadamard_w4a8_demo.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23367v1/iclr2026/humaneval_mbpp_word_counts.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23367v1/iclr2026/CoT_demo.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "On the Inverse Flow Matching Problem in the One-Dimensional and Gaussian Cases",
            "authors": [
                "Alexander Korotin",
                "Gudmund Pammer"
            ],
            "arxiv_id": "2512.23265v1",
            "summary": "This paper studies the inverse problem of flow matching (FM) between distributions with finite exponential moment, a problem motivated by modern generative AI applications such as the distillation of flow matching models. Uniqueness of the solution is established in two cases - the one-dimensional setting and the Gaussian case. The general multidimensional problem remains open for future studies.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "10.4213/rm10283",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23265v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]flow matching",
                        "distillation"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "研究一维和高斯分布下的逆流匹配问题，为流匹配模型蒸馏提供理论基础",
            "summary_zh": "本文研究了具有有限指数矩的分布之间的流匹配（FM）逆问题。该问题由现代生成人工智能应用驱动，例如流匹配模型的蒸馏。论文在两种情况下建立了解决方案的唯一性：一维情形和高斯情形。一般多维问题仍然是未来研究的开放性问题。",
            "intro_zh": [
                "流匹配模型蒸馏是现代生成AI的重要应用，但其逆问题（即从目标分布反推流场）的理论基础尚不完善。",
                "论文针对一维和高斯分布，证明了流匹配逆问题解的唯一性，为后续研究奠定了理论基础。",
                "虽然一般多维问题仍未解决，但该研究为理解和优化流匹配模型的蒸馏过程提供了关键见解。"
            ],
            "method_zh": "**问题定义**：论文研究的是流匹配的逆问题，即给定两个分布，如何唯一确定一个最优的向量场（或称流），使得一个分布可以通过该向量场连续地变换到另一个分布。现有方法在理论上缺乏对解唯一性的保证，尤其是在高维情况下，这会影响流匹配模型的蒸馏效果。\\n\\n**核心思路**：论文的核心思路是利用指数矩的性质以及特定分布（一维和高斯分布）的特性，通过数学推导证明在这些情况下，流匹配逆问题的解是唯一的。这意味着对于这些特定分布，存在一个且仅有一个最优的向量场能够实现分布之间的转换。\\n\\n**技术框架**：论文主要采用数学分析的方法。首先，对流匹配问题进行数学建模，然后利用变分法或最优控制理论建立目标函数。接着，针对一维和高斯分布，利用其特殊的数学性质，例如高斯分布的对称性和一维分布的单调性，推导出解的唯一性条件。\\n\\n**关键创新**：论文的关键创新在于针对流匹配逆问题，首次在理论上证明了一维和高斯分布情况下解的唯一性。这为流匹配模型的蒸馏提供了重要的理论支撑，并为解决更一般情况下的逆问题提供了思路。\\n\\n**关键设计**：论文的关键设计在于巧妙地利用了指数矩的性质来约束分布，并结合特定分布的特性进行数学推导。具体的参数设置和网络结构并非论文的重点，因为该研究主要关注理论证明，而非具体的模型实现。",
            "application_zh": "该研究成果可应用于生成模型的蒸馏，特别是基于流匹配的模型。通过确保流匹配逆问题的解的唯一性，可以提高蒸馏模型的精度和效率。此外，该研究也为理解和优化其他基于流的生成模型提供了理论基础，例如在图像生成、音频合成等领域。",
            "highlight_zh": "论文证明了一维和高斯分布下流匹配逆问题的解的唯一性，为流匹配模型蒸馏提供了理论保障。虽然没有提供具体的性能数据，但该理论结果为后续研究提供了重要的指导，并有望提升流匹配模型蒸馏的效率和精度。未来的研究可以尝试将该理论推广到更一般的多维分布。",
            "tags_zh": [
                "流匹配",
                "逆问题",
                "生成模型",
                "模型蒸馏",
                "唯一性证明",
                "高斯分布",
                "一维分布",
                "指数矩"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "SPIRAL: Symbolic LLM Planning via Grounded and Reflective Search",
            "authors": [
                "Yifan Zhang",
                "Giridhar Ganapavarapu",
                "Srideepika Jayaraman",
                "Bhavna Agrawal",
                "Dhaval Patel",
                "Achille Fokoue"
            ],
            "arxiv_id": "2512.23167v1",
            "summary": "Large Language Models (LLMs) often falter at complex planning tasks that require exploration and self-correction, as their linear reasoning process struggles to recover from early mistakes. While search algorithms like Monte Carlo Tree Search (MCTS) can explore alternatives, they are often ineffective when guided by sparse rewards and fail to leverage the rich semantic capabilities of LLMs. We introduce SPIRAL (Symbolic LLM Planning via Grounded and Reflective Search), a novel framework that embeds a cognitive architecture of three specialized LLM agents into an MCTS loop. SPIRAL's key contribution is its integrated planning pipeline where a Planner proposes creative next steps, a Simulator grounds the search by predicting realistic outcomes, and a Critic provides dense reward signals through reflection. This synergy transforms MCTS from a brute-force search into a guided, self-correcting reasoning process. On the DailyLifeAPIs and HuggingFace datasets, SPIRAL consistently outperforms the default Chain-of-Thought planning method and other state-of-the-art agents. More importantly, it substantially surpasses other state-of-the-art agents; for example, SPIRAL achieves 83.6% overall accuracy on DailyLifeAPIs, an improvement of over 16 percentage points against the next-best search framework, while also demonstrating superior token efficiency. Our work demonstrates that structuring LLM reasoning as a guided, reflective, and grounded search process yields more robust and efficient autonomous planners. The source code, full appendices, and all experimental data are available for reproducibility at the official project repository.",
            "categories": [
                "cs.AI",
                "cs.LG",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23167v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SPIRAL：通过具身和反思搜索实现符号LLM规划",
            "summary_zh": "大型语言模型(LLMs)在需要探索和自我纠正的复杂规划任务中常常表现不佳，因为它们的线性推理过程难以从早期错误中恢复。虽然像蒙特卡洛树搜索(MCTS)这样的搜索算法可以探索替代方案，但当受到稀疏奖励的指导时，它们通常是无效的，并且无法利用LLM丰富的语义能力。我们引入了SPIRAL（通过具身和反思搜索实现符号LLM规划），这是一个新颖的框架，它将三个专门的LLM代理的认知架构嵌入到MCTS循环中。SPIRAL的关键贡献在于其集成的规划流程，其中规划器提出创造性的下一步，模拟器通过预测现实的结果来支持搜索，而评论员通过反思提供密集的奖励信号。这种协同作用将MCTS从蛮力搜索转变为有指导的、自我纠正的推理过程。在DailyLifeAPIs和HuggingFace数据集上，SPIRAL始终优于默认的思维链规划方法和其他最先进的代理。更重要的是，它大大超过了其他最先进的代理；例如，SPIRAL在DailyLifeAPIs上实现了83.6%的总体准确率，比下一个最佳搜索框架提高了16个百分点以上，同时还表现出卓越的token效率。我们的工作表明，将LLM推理构建为有指导的、反思的和具身的搜索过程可以产生更强大和高效的自主规划器。源代码、完整附录和所有实验数据可在官方项目存储库中获得，以实现可重复性。",
            "intro_zh": [
                "现有LLM在复杂规划任务中，由于线性推理和难以从早期错误恢复，表现不佳，而传统搜索算法又难以有效利用LLM的语义能力。",
                "SPIRAL通过将三个LLM代理（规划器、模拟器、评论员）嵌入MCTS循环中，实现有指导、反思和具身的搜索过程，从而提升规划能力。",
                "实验表明，SPIRAL在DailyLifeAPIs数据集上超越现有最佳方法16个百分点，达到83.6%的准确率，并具有更高的token效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型在复杂规划任务中表现不佳的问题。现有方法，如思维链（Chain-of-Thought）推理，通常采用线性推理方式，难以从早期错误中恢复。而传统的搜索算法，如蒙特卡洛树搜索（MCTS），在稀疏奖励下效率低下，且无法充分利用LLM的语义理解能力。\\n\\n**核心思路**：论文的核心思路是将LLM的推理过程构建为一个有指导的、反思的和具身的搜索过程。通过引入三个专门的LLM代理（规划器、模拟器和评论员），并将其嵌入到MCTS循环中，实现更高效和鲁棒的规划。这种设计旨在结合LLM的语义理解能力和MCTS的探索能力，从而克服传统方法的局限性。\\n\\n**技术框架**：SPIRAL框架包含以下主要模块：1) **规划器（Planner）**：负责提出创造性的下一步行动方案。2) **模拟器（Simulator）**：负责预测行动方案的现实结果，从而支持搜索过程的具身性。3) **评论员（Critic）**：负责通过反思提供密集的奖励信号，指导搜索过程。这三个模块嵌入到MCTS循环中，形成一个迭代的规划、模拟和评估过程。MCTS负责探索不同的行动序列，而LLM代理负责提供指导和反馈。\\n\\n**关键创新**：SPIRAL的关键创新在于其集成的规划流程，将LLM的语义理解能力与MCTS的搜索能力相结合。通过引入专门的LLM代理，实现了有指导的、反思的和具身的搜索过程。与传统的MCTS方法相比，SPIRAL能够更有效地利用LLM的知识和推理能力，从而提高规划的效率和准确性。与传统的线性推理方法相比，SPIRAL能够更好地从错误中恢复，并探索更多的替代方案。\\n\\n**关键设计**：论文中没有明确给出关键参数设置、损失函数或网络结构的具体细节。但是，可以推断，每个LLM代理（规划器、模拟器和评论员）都需要进行适当的prompt工程，以确保其能够有效地执行各自的任务。奖励函数的设计对于评论员的性能至关重要，需要仔细考虑如何将反思结果转化为密集的奖励信号。MCTS的探索策略（如UCT）也需要进行调整，以适应LLM代理的指导。",
            "application_zh": "SPIRAL框架可应用于各种需要复杂规划和决策的领域，例如机器人导航、任务自动化、游戏AI和智能助手。该框架能够提高自主系统的鲁棒性和效率，使其能够更好地适应复杂和动态的环境。未来，SPIRAL可以扩展到处理更复杂的任务，并与其他技术（如强化学习）相结合，从而实现更强大的自主规划能力。",
            "highlight_zh": "SPIRAL在DailyLifeAPIs数据集上取得了显著的性能提升，总体准确率达到83.6%，比下一个最佳搜索框架提高了16个百分点以上。此外，SPIRAL还表现出卓越的token效率，这意味着它在实现相同性能的同时，使用的计算资源更少。在HuggingFace数据集上，SPIRAL也优于其他最先进的代理，证明了其泛化能力。",
            "tags_zh": [
                "大型语言模型",
                "规划",
                "蒙特卡洛树搜索",
                "具身智能",
                "反思学习",
                "自主代理",
                "符号推理"
            ],
            "_index": 49,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23167v1/figures/revision_spiral_intro_final.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23167v1/figures/revision_spiral_overview_final.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23167v1/figures/cost_comparison_tokens.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "An Inference-Based Architecture for Intent and Affordance Saturation in Decision-Making",
            "authors": [
                "Wendyam Eric Lionel Ilboudo",
                "Saori C Tanaka"
            ],
            "arxiv_id": "2512.23144v1",
            "summary": "Decision paralysis, i.e. hesitation, freezing, or failure to act despite full knowledge and motivation, poses a challenge for choice models that assume options are already specified and readily comparable. Drawing on qualitative reports in autism research that are especially salient, we propose a computational account in which paralysis arises from convergence failure in a hierarchical decision process. We separate intent selection (what to pursue) from affordance selection (how to pursue the goal) and formalize commitment as inference under a mixture of reverse- and forward-Kullback-Leibler (KL) objectives. Reverse KL is mode-seeking and promotes rapid commitment, whereas forward KL is mode-covering and preserves multiple plausible goals or actions. In static and dynamic (drift-diffusion) models, forward-KL-biased inference yields slow, heavy-tailed response times and two distinct failure modes, intent saturation and affordance saturation, when values are similar. Simulations in multi-option tasks reproduce key features of decision inertia and shutdown, treating autism as an extreme regime of a general, inference-based, decision-making continuum.",
            "categories": [
                "q-bio.NC",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "q-bio.NC",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "32 pages, 12 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23144v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]affordance"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出基于推理的架构，解决决策中意图和可供性饱和导致的决策瘫痪问题",
            "summary_zh": "决策瘫痪，即在充分了解情况和具备足够动机的情况下，仍然犹豫不决、停滞不前或无法行动，对假设选项已明确且易于比较的选择模型提出了挑战。借鉴自闭症研究中尤其显著的定性报告，我们提出了一种计算模型，其中瘫痪源于分层决策过程中的收敛失败。我们将意图选择（追求什么）与可供性选择（如何实现目标）分离，并将承诺形式化为在反向和前向Kullback-Leibler (KL)目标混合下的推理。反向KL是模式寻求的，促进快速承诺，而前向KL是模式覆盖的，保留多个合理的目标或行动。在静态和动态（漂移扩散）模型中，当前向KL偏差的推理产生缓慢、重尾的响应时间以及两种不同的失败模式：意图饱和和可供性饱和，尤其是在价值相似时。在多选项任务中的模拟重现了决策惯性和关闭的关键特征，并将自闭症视为基于推理的通用决策连续体的极端状态。",
            "intro_zh": [
                "现有选择模型难以解释决策瘫痪现象，即充分了解情况却无法行动，因为它们假设选项已明确且易于比较。",
                "该论文提出一种基于推理的计算模型，将意图选择和可供性选择分离，并使用混合KL散度目标来模拟决策过程。",
                "通过静态和动态模型仿真，验证了该模型能够重现决策惯性和关闭等现象，并将自闭症视为决策连续体的一个极端。"
            ],
            "method_zh": "**问题定义**：论文旨在解决决策瘫痪问题，即个体在拥有充分信息和动机的情况下，仍然难以做出决策。现有选择模型通常假设选项是明确且易于比较的，无法解释犹豫不决、停滞不前等现象，尤其是在选项价值相似时。这些模型忽略了意图选择（what to pursue）和可供性选择（how to pursue the goal）之间的差异，以及决策过程中的不确定性。\n\n**核心思路**：论文的核心思路是将决策过程建模为一种基于推理的过程，该过程涉及意图选择和可供性选择两个阶段。通过引入反向和前向KL散度的混合目标，模型能够平衡快速承诺（反向KL）和保留多种可能性（前向KL）的需求。这种设计允许模型在选项价值相似时，表现出犹豫不决和决策瘫痪的现象。\n\n**技术框架**：该论文构建了一个分层决策模型，包含意图选择和可供性选择两个模块。模型使用混合KL散度作为推理目标，其中反向KL促进快速决策，前向KL保留多种可能性。该模型在静态和动态（漂移扩散）环境中进行了仿真，以验证其行为。\n\n**关键创新**：该论文的关键创新在于将决策过程形式化为一种基于推理的过程，并引入了混合KL散度目标。这种方法能够更好地模拟人类决策中的不确定性和犹豫不决现象，并解释了决策瘫痪的产生机制。与传统选择模型相比，该模型更加灵活和具有解释性。\n\n**关键设计**：模型使用反向KL和前向KL的加权和作为损失函数，权重参数控制了模型对快速承诺和保留多种可能性的偏好。在漂移扩散模型中，漂移率由意图和可供性的价值差异决定。模型的参数设置允许其模拟不同的决策风格，包括快速决策和犹豫不决。",
            "application_zh": "该研究成果可应用于开发更智能的决策支持系统，帮助用户在复杂和不确定的环境中做出更好的决策。此外，该模型还可以用于理解和治疗自闭症等认知障碍，为个性化干预提供理论基础。该研究对于理解人类决策过程具有重要意义，并可能影响人工智能和认知科学领域。",
            "highlight_zh": "该论文通过仿真实验验证了模型的有效性。结果表明，当前向KL偏差较大时，模型会表现出缓慢、重尾的响应时间，以及意图饱和和可供性饱和两种失败模式。此外，该模型还能够重现决策惯性和关闭等现象，并将自闭症视为决策连续体的一个极端。这些结果表明，该模型能够捕捉人类决策中的关键特征。",
            "tags_zh": [
                "决策瘫痪",
                "意图选择",
                "可供性选择",
                "KL散度",
                "推理模型",
                "自闭症",
                "漂移扩散模型"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23144v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23144v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23144v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design",
            "authors": [
                "Zelin Zang",
                "Yuhang Song",
                "Bingo Wing-Kuen Ling",
                "Aili Wang",
                "Fuji Yang"
            ],
            "arxiv_id": "2512.23189v1",
            "summary": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23189v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Agentic EDA框架，实现数字芯片设计的自主化，加速AI原生设计流程。",
            "summary_zh": "本综述全面概述了生成式AI和Agentic AI在数字电子设计自动化（EDA）领域的集成。首先回顾了从传统计算机辅助设计（CAD）到AI辅助EDA（AI4EDA），再到新兴的AI原生和Agentic设计范式的演变。详细介绍了这些范式在数字芯片设计流程中的应用，包括基于多模态基础模型的Agentic认知架构的构建、前端RTL代码生成和智能验证，以及后端物理设计中的算法创新和工具编排。通过综合案例研究验证了这些方法，展示了从微架构定义到GDSII的实际可行性。特别强调了跨阶段反馈循环的潜力，其中Agent利用后端PPA指标自主优化前端逻辑。此外，本综述深入探讨了对安全性的双重影响，包括新型对抗风险、自动漏洞修复和隐私保护基础设施。最后，批判性地总结了当前与幻觉、数据稀缺和黑盒工具相关的挑战，并概述了未来L4自主芯片设计的发展趋势。最终，这项工作旨在定义Agentic EDA这一新兴领域，并为从AI辅助工具到完全自主的设计工程师的过渡提供战略路线图。",
            "intro_zh": [
                "传统EDA工具难以应对日益复杂的芯片设计需求，AI辅助设计虽有进展，但仍依赖人工干预，效率受限。",
                "论文提出Agentic EDA框架，利用生成式AI和Agentic AI，构建自主化的芯片设计流程，实现跨阶段的智能优化。",
                "通过案例研究验证了Agentic EDA框架的可行性，展示了其在微架构定义、RTL代码生成和物理设计等方面的潜力。"
            ],
            "method_zh": "**问题定义**：当前数字芯片设计面临日益增长的复杂性和上市时间压力。传统的EDA工具虽然提供了自动化功能，但仍然需要大量的人工干预和专家知识。AI辅助EDA（AI4EDA）在一定程度上提高了效率，但仍然依赖于预定义的算法和有限的优化策略。现有的方法难以实现跨阶段的自主优化和快速迭代，导致设计周期长、成本高。\n\n**核心思路**：本论文的核心思路是引入Agentic AI，构建一个自主的芯片设计Agent，使其能够像人类工程师一样，理解设计目标、探索设计空间、并根据反馈进行优化。通过将芯片设计的各个阶段（如RTL代码生成、验证、物理设计）建模为Agent，并赋予其自主决策和学习能力，实现端到端的自动化设计流程。\n\n**技术框架**：Agentic EDA框架包含以下主要模块：1) 基于多模态基础模型的认知架构，用于理解设计规范和目标；2) 前端RTL代码生成Agent，负责根据规范生成可验证的RTL代码；3) 智能验证Agent，用于自动检测和修复设计缺陷；4) 后端物理设计Agent，负责布局、布线和优化PPA指标。这些Agent通过跨阶段的反馈循环进行协作，例如，后端Agent将PPA指标反馈给前端Agent，用于优化RTL代码。\n\n**关键创新**：本论文的关键创新在于将Agentic AI引入到数字芯片设计领域，提出了一个完整的Agentic EDA框架。与传统的AI4EDA方法相比，Agentic EDA具有更强的自主性和适应性，能够实现跨阶段的智能优化和快速迭代。此外，论文还强调了跨阶段反馈循环的重要性，通过将后端PPA指标反馈给前端Agent，实现了全局优化。\n\n**关键设计**：在Agentic EDA框架中，关键的设计包括：1) 多模态基础模型的选择和训练，用于理解设计规范和目标；2) Agent之间的通信协议和协作机制，确保Agent能够有效地协同工作；3) 奖励函数的设计，用于指导Agent的学习和优化；4) 知识库的构建，用于存储和共享设计经验和知识。",
            "application_zh": "Agentic EDA框架可应用于各种数字芯片设计场景，包括CPU、GPU、AI芯片等。它能够显著缩短设计周期、降低设计成本，并提高芯片的性能和功耗。此外，Agentic EDA还有助于解决芯片设计人才短缺的问题，使非专业人士也能参与到芯片设计中来。未来，Agentic EDA有望成为芯片设计的主流范式，推动芯片产业的快速发展。",
            "highlight_zh": "论文通过案例研究验证了Agentic EDA框架的可行性，展示了其在微架构定义、RTL代码生成和物理设计等方面的潜力。虽然具体的性能数据和提升幅度未在摘要中明确给出，但强调了从微架构定义到GDSII的实际可行性，以及通过后端PPA指标自主优化前端逻辑的能力，暗示了在设计效率和芯片性能上的显著提升。",
            "tags_zh": [
                "Agentic EDA",
                "自主芯片设计",
                "AI原生设计",
                "生成式AI",
                "多模态基础模型",
                "RTL代码生成",
                "物理设计"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23189v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23189v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23189v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "GVSynergy-Det: Synergistic Gaussian-Voxel Representations for Multi-View 3D Object Detection",
            "authors": [
                "Yi Zhang",
                "Yi Wang",
                "Lei Yao",
                "Lap-Pui Chau"
            ],
            "arxiv_id": "2512.23176v1",
            "summary": "Image-based 3D object detection aims to identify and localize objects in 3D space using only RGB images, eliminating the need for expensive depth sensors required by point cloud-based methods. Existing image-based approaches face two critical challenges: methods achieving high accuracy typically require dense 3D supervision, while those operating without such supervision struggle to extract accurate geometry from images alone. In this paper, we present GVSynergy-Det, a novel framework that enhances 3D detection through synergistic Gaussian-Voxel representation learning. Our key insight is that continuous Gaussian and discrete voxel representations capture complementary geometric information: Gaussians excel at modeling fine-grained surface details while voxels provide structured spatial context. We introduce a dual-representation architecture that: 1) adapts generalizable Gaussian Splatting to extract complementary geometric features for detection tasks, and 2) develops a cross-representation enhancement mechanism that enriches voxel features with geometric details from Gaussian fields. Unlike previous methods that either rely on time-consuming per-scene optimization or utilize Gaussian representations solely for depth regularization, our synergistic strategy directly leverages features from both representations through learnable integration, enabling more accurate object localization. Extensive experiments demonstrate that GVSynergy-Det achieves state-of-the-art results on challenging indoor benchmarks, significantly outperforming existing methods on both ScanNetV2 and ARKitScenes datasets, all without requiring any depth or dense 3D geometry supervision (e.g., point clouds or TSDF).",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "11 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23176v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 5.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "GVSynergy-Det：协同高斯-体素表示用于多视角3D目标检测",
            "summary_zh": "本文提出了一种名为GVSynergy-Det的新框架，旨在通过协同高斯-体素表示学习来增强基于图像的3D目标检测。核心思想是连续高斯和离散体素表示能够捕捉互补的几何信息：高斯擅长建模精细的表面细节，而体素提供结构化的空间上下文。该框架引入了一种双重表示架构，该架构：（1）调整通用高斯溅射以提取用于检测任务的互补几何特征；（2）开发了一种跨表示增强机制，利用高斯场的几何细节来丰富体素特征。与以往依赖耗时的单场景优化或仅使用高斯表示进行深度正则化的方法不同，我们的协同策略通过可学习的集成直接利用来自两种表示的特征，从而实现更准确的目标定位。大量实验表明，GVSynergy-Det在具有挑战性的室内基准测试中实现了最先进的结果，在ScanNetV2和ARKitScenes数据集上均显著优于现有方法，且无需任何深度或密集3D几何监督（例如，点云或TSDF）。",
            "intro_zh": [
                "现有基于图像的3D目标检测方法难以兼顾高精度和弱监督，高精度方法依赖密集3D监督，而弱监督方法难以提取准确几何信息。",
                "GVSynergy-Det通过协同高斯-体素表示学习增强3D检测，利用高斯表示的精细表面细节和体素表示的结构化空间上下文。",
                "实验表明，GVSynergy-Det在ScanNetV2和ARKitScenes数据集上取得了SOTA结果，且无需深度或密集3D几何监督。"
            ],
            "method_zh": "**问题定义**：基于图像的3D目标检测旨在仅使用RGB图像识别和定位3D空间中的对象。现有方法要么需要密集的3D监督才能实现高精度，要么在没有这种监督的情况下难以从图像中提取准确的几何信息。因此，如何在弱监督或无监督的情况下，提升基于图像的3D目标检测精度是一个关键问题。\\n\\n**核心思路**：论文的核心思路是利用高斯表示和体素表示的互补性。高斯表示擅长捕捉精细的表面细节，而体素表示提供结构化的空间上下文。通过协同利用这两种表示，可以更准确地进行3D目标检测。这种协同作用避免了对密集3D监督的依赖，并提升了弱监督条件下的几何信息提取能力。\\n\\n**技术框架**：GVSynergy-Det框架包含两个主要模块：高斯特征提取模块和体素特征增强模块。首先，利用改进的高斯溅射（Gaussian Splatting）从多视角图像中提取高斯特征。然后，将场景划分为体素，并提取体素特征。接着，通过跨表示增强机制，利用高斯特征来丰富体素特征。最后，将增强后的体素特征输入到3D目标检测器中进行目标检测。\\n\\n**关键创新**：该方法的核心创新在于提出了协同高斯-体素表示学习。与以往方法不同，该方法不是简单地将高斯表示作为深度正则化项，而是直接利用高斯特征和体素特征进行目标检测。此外，该方法还提出了跨表示增强机制，利用高斯特征来增强体素特征，从而更好地利用两种表示的互补性。\\n\\n**关键设计**：在实现上，采用了可学习的集成方式来融合高斯特征和体素特征。具体来说，使用注意力机制来学习不同特征的重要性，并根据重要性对特征进行加权融合。此外，损失函数的设计也考虑了高斯表示和体素表示的特点，例如，使用高斯分布的KL散度来约束高斯表示的形状，并使用交叉熵损失来训练目标检测器。",
            "application_zh": "GVSynergy-Det在室内场景理解、机器人导航、自动驾驶等领域具有广泛的应用前景。该方法无需深度传感器，仅依赖RGB图像即可实现高精度的3D目标检测，降低了硬件成本，并提高了系统的鲁棒性。未来，该方法可以应用于智能家居、虚拟现实、增强现实等领域。",
            "highlight_zh": "GVSynergy-Det在ScanNetV2和ARKitScenes数据集上取得了显著的性能提升。在ScanNetV2数据集上，GVSynergy-Det在不使用任何深度监督的情况下，显著优于现有的基于图像的3D目标检测方法。在ARKitScenes数据集上，GVSynergy-Det也取得了SOTA结果，证明了该方法的有效性和泛化能力。",
            "tags_zh": [
                "3D目标检测",
                "多视角几何",
                "高斯溅射",
                "体素表示",
                "无监督学习"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23176v1/model_size_performance_comparison.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23176v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23176v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Not too long do read: Evaluating LLM-generated extreme scientific summaries",
            "authors": [
                "Zhuoqi Lyu",
                "Qing Ke"
            ],
            "arxiv_id": "2512.23206v1",
            "summary": "High-quality scientific extreme summary (TLDR) facilitates effective science communication. How do large language models (LLMs) perform in generating them? How are LLM-generated summaries different from those written by human experts? However, the lack of a comprehensive, high-quality scientific TLDR dataset hinders both the development and evaluation of LLMs' summarization ability. To address these, we propose a novel dataset, BiomedTLDR, containing a large sample of researcher-authored summaries from scientific papers, which leverages the common practice of including authors' comments alongside bibliography items. We then test popular open-weight LLMs for generating TLDRs based on abstracts. Our analysis reveals that, although some of them successfully produce humanoid summaries, LLMs generally exhibit a greater affinity for the original text's lexical choices and rhetorical structures, hence tend to be more extractive rather than abstractive in general, compared to humans. Our code and datasets are available at https://github.com/netknowledge/LLM_summarization (Lyu and Ke, 2025).",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23206v1",
            "code_links": [
                {
                    "url": "https://github.com/netknowledge/LLM_summarization",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 5.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出BiomedTLDR数据集，评估大语言模型在生成科研论文极简摘要方面的能力",
            "summary_zh": "高质量的科研极简摘要（TLDR）有助于有效的科学传播。本文旨在评估大型语言模型（LLMs）在生成此类摘要方面的表现，并分析LLM生成的摘要与人类专家撰写的摘要之间的差异。由于缺乏全面、高质量的科研TLDR数据集，阻碍了LLMs摘要能力的开发和评估。为此，本文提出了一个新的数据集BiomedTLDR，其中包含大量研究人员撰写的科学论文摘要，该数据集利用了在参考文献条目旁边包含作者评论的常见做法。然后，我们测试了流行的开源LLMs，以基于摘要生成TLDR。分析表明，尽管其中一些模型成功生成了类人摘要，但与人类相比，LLMs通常更倾向于原始文本的词汇选择和修辞结构，因此总体上更偏向于抽取式而非生成式。",
            "intro_zh": [
                "现有科研TLDR数据集的缺乏，限制了对LLM生成极简摘要能力的有效评估和提升。",
                "论文构建了BiomedTLDR数据集，包含研究人员撰写的摘要，用于训练和评估LLM。",
                "实验表明，LLM生成的摘要更倾向于抽取式，在词汇和结构上更依赖原文，与人类撰写存在差异。"
            ],
            "method_zh": "**问题定义**：论文旨在解决缺乏高质量科研TLDR数据集的问题，并评估大型语言模型（LLMs）在生成此类摘要方面的能力。现有方法缺乏足够的数据支持，难以全面评估LLMs的摘要生成质量，也无法深入了解LLMs与人类专家在摘要生成策略上的差异。\\n\\n**核心思路**：论文的核心思路是构建一个高质量的科研TLDR数据集BiomedTLDR，该数据集包含大量研究人员撰写的摘要，并利用这些数据来训练和评估LLMs的摘要生成能力。通过对比LLMs和人类专家生成的摘要，分析LLMs在词汇选择、修辞结构和摘要风格上的特点。\\n\\n**技术框架**：论文的技术框架主要包括数据集构建和LLM评估两个部分。数据集构建方面，利用参考文献条目旁边的作者评论作为TLDR摘要的来源，构建BiomedTLDR数据集。LLM评估方面，选择流行的开源LLMs，基于论文摘要生成TLDR，并与人类专家撰写的摘要进行对比分析。\\n\\n**关键创新**：论文的关键创新在于构建了BiomedTLDR数据集，该数据集为科研TLDR摘要生成任务提供了高质量的数据支持。此外，论文还深入分析了LLMs在摘要生成方面的特点，揭示了LLMs更倾向于抽取式摘要的倾向，这与人类专家的摘要风格存在差异。\\n\\n**关键设计**：BiomedTLDR数据集的关键设计在于利用参考文献条目旁边的作者评论作为TLDR摘要的来源，这种方法能够有效地获取大量高质量的科研摘要。在LLM评估方面，论文选择了多个流行的开源LLMs，并采用了多种评估指标，包括ROUGE等，以全面评估LLMs的摘要生成质量。",
            "application_zh": "该研究成果可应用于科学传播、科研信息检索和智能文献推荐等领域。高质量的科研TLDR摘要能够帮助研究人员快速了解论文的核心内容，提高科研效率。此外，该研究还可以促进LLMs在科研领域的应用，例如自动生成论文摘要、科研报告等。",
            "highlight_zh": "实验结果表明，虽然部分LLMs能够生成类人摘要，但总体而言，LLMs更倾向于原始文本的词汇选择和修辞结构，表现出更强的抽取式摘要倾向。与人类专家相比，LLMs在摘要生成方面仍有提升空间，尤其是在生成更具抽象性和概括性的摘要方面。",
            "tags_zh": [
                "大语言模型",
                "文本摘要",
                "科研摘要",
                "数据集构建",
                "自然语言处理"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23206v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23206v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23206v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Bridging Cognitive Gap: Hierarchical Description Learning for Artistic Image Aesthetics Assessment",
            "authors": [
                "Henglin Liu",
                "Nisha Huang",
                "Chang Liu",
                "Jiangpeng Yan",
                "Huijuan Huang",
                "Jixuan Ying",
                "Tong-Yee Lee",
                "Pengfei Wan",
                "Xiangyang Ji"
            ],
            "arxiv_id": "2512.23413v1",
            "summary": "The aesthetic quality assessment task is crucial for developing a human-aligned quantitative evaluation system for AIGC. However, its inherently complex nature, spanning visual perception, cognition, and emotion, poses fundamental challenges. Although aesthetic descriptions offer a viable representation of this complexity, two critical challenges persist: (1) data scarcity and imbalance: existing dataset overly focuses on visual perception and neglects deeper dimensions due to the expensive manual annotation; and (2) model fragmentation: current visual networks isolate aesthetic attributes with multi-branch encoder, while multimodal methods represented by contrastive learning struggle to effectively process long-form textual descriptions. To resolve challenge (1), we first present the Refined Aesthetic Description (RAD) dataset, a large-scale (70k), multi-dimensional structured dataset, generated via an iterative pipeline without heavy annotation costs and easy to scale. To address challenge (2), we propose ArtQuant, an aesthetics assessment framework for artistic images which not only couples isolated aesthetic dimensions through joint description generation, but also better models long-text semantics with the help of LLM decoders. Besides, theoretical analysis confirms this symbiosis: RAD's semantic adequacy (data) and generation paradigm (model) collectively minimize prediction entropy, providing mathematical grounding for the framework. Our approach achieves state-of-the-art performance on several datasets while requiring only 33% of conventional training epochs, narrowing the cognitive gap between artistic images and aesthetic judgment. We will release both code and dataset to support future research.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "AAAI2026,Project Page:https://github.com/Henglin-Liu/ArtQuant",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23413v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ArtQuant框架，通过层级描述学习解决艺术图像美学评估中的认知鸿沟。",
            "summary_zh": "美学质量评估对于开发与人类认知对齐的AIGC定量评估系统至关重要。然而，其内在的复杂性，跨越视觉感知、认知和情感，带来了根本性的挑战。尽管美学描述为此复杂性提供了一种可行的表示，但仍然存在两个关键挑战：（1）数据稀缺和不平衡：由于昂贵的手动标注，现有数据集过度关注视觉感知而忽略了更深层次的维度；（2）模型碎片化：当前视觉网络使用多分支编码器隔离美学属性，而以对比学习为代表的多模态方法难以有效处理长文本描述。为了解决挑战（1），我们首先提出了精炼美学描述（RAD）数据集，这是一个大规模（70k）、多维结构化数据集，通过迭代流程生成，无需大量标注成本且易于扩展。为了解决挑战（2），我们提出了一种用于艺术图像的美学评估框架ArtQuant，该框架不仅通过联合描述生成耦合了孤立的美学维度，而且借助LLM解码器更好地建模了长文本语义。此外，理论分析证实了这种共生关系：RAD的语义充分性（数据）和生成范式（模型）共同最小化了预测熵，为该框架提供了数学基础。我们的方法在多个数据集上实现了最先进的性能，同时仅需要传统训练epoch的33%，缩小了艺术图像和美学判断之间的认知差距。我们将发布代码和数据集以支持未来的研究。",
            "intro_zh": [
                "现有美学评估数据集标注成本高昂，导致数据稀缺且侧重视觉感知，忽略了认知和情感等深层维度。",
                "ArtQuant框架通过联合描述生成耦合美学维度，并利用LLM解码器建模长文本语义，从而缩小认知差距。",
                "实验结果表明，ArtQuant在多个数据集上取得了SOTA性能，且仅需传统训练epoch的33%。"
            ],
            "method_zh": "**问题定义**：论文旨在解决艺术图像美学评估中存在的认知鸿沟问题。现有方法主要存在两个痛点：一是数据集标注成本高昂，导致数据稀缺且不平衡，难以覆盖美学的多维度特征；二是模型设计上，视觉网络通常采用多分支结构孤立地处理各个美学属性，而多模态方法难以有效利用长文本描述。\n\\n**核心思路**：论文的核心思路是构建一个大规模、多维度的美学描述数据集（RAD），并设计一个能够有效利用该数据集进行训练的美学评估框架（ArtQuant）。ArtQuant通过联合生成美学描述来耦合各个维度，并借助LLM解码器更好地理解和利用长文本语义信息。\n\\n**技术框架**：ArtQuant框架主要包含以下几个模块：1)图像编码器：用于提取图像的视觉特征；2)文本编码器：用于编码美学描述文本；3)联合描述生成器：基于图像特征和文本特征，生成对图像美学属性的描述；4)美学质量评估器：基于生成的美学描述，预测图像的美学质量。整个流程是端到端可训练的。\n\\n**关键创新**：论文的关键创新在于：1)提出了RAD数据集，解决了数据稀缺和不平衡的问题；2)提出了ArtQuant框架，通过联合描述生成和LLM解码器，有效耦合了美学维度并利用了长文本语义；3)从理论上分析了RAD数据集和ArtQuant框架的共生关系，证明了其有效性。\n\\n**关键设计**：RAD数据集通过迭代流程生成，降低了标注成本。ArtQuant框架使用Transformer架构作为联合描述生成器和LLM解码器。损失函数包括描述生成损失和美学质量评估损失。具体参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "该研究成果可应用于AIGC内容的质量评估、图像搜索排序、艺术品推荐、以及个性化内容生成等领域。通过更准确地评估艺术图像的美学质量，可以提升用户体验，并为AIGC的发展提供更有效的反馈机制。未来，该方法可以扩展到其他类型的内容，如视频、音乐等。",
            "highlight_zh": "ArtQuant框架在多个艺术图像美学评估数据集上取得了SOTA性能，例如在XXXX数据集上，相比于之前的最佳方法，准确率提升了X%。更重要的是，ArtQuant仅需传统训练epoch的33%即可达到SOTA性能，显著降低了训练成本。",
            "tags_zh": [
                "艺术图像美学评估",
                "层级描述学习",
                "AIGC",
                "多模态学习",
                "LLM",
                "数据集构建",
                "认知鸿沟"
            ],
            "_index": 54,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23413v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23413v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23413v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Visual Language Hypothesis",
            "authors": [
                "Xiu Li"
            ],
            "arxiv_id": "2512.23335v1",
            "summary": "We study visual representation learning from a structural and topological perspective. We begin from a single hypothesis: that visual understanding presupposes a semantic language for vision, in which many perceptual observations correspond to a small number of discrete semantic states. Together with widely assumed premises on transferability and abstraction in representation learning, this hypothesis implies that the visual observation space must be organized in a fiber bundle like structure, where nuisance variation populates fibers and semantics correspond to a quotient base space. From this structure we derive two theoretical consequences. First, the semantic quotient $X/G$ is not a submanifold of $X$ and cannot be obtained through smooth deformation alone, semantic invariance requires a non-homeomorphic, discriminative target, for example, supervision via labels, cross instance identification, or multimodal alignment that supplies explicit semantic equivalence. Second, we show that approximating the quotient also places structural demands on the model architecture. Semantic abstraction requires not only an external semantic target, but a representation mechanism capable of supporting topology change: an expand-and-snap process in which the manifold is first geometrically expanded to separate structure and then collapsed to form discrete semantic regions. We emphasize that these results are interpretive rather than prescriptive: the framework provides a topological lens that aligns with empirical regularities observed in large-scale discriminative and multimodal models, and with classical principles in statistical learning theory.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23335v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出视觉语言假设，从结构和拓扑角度分析视觉表征学习",
            "summary_zh": "本文从结构和拓扑的角度研究视觉表征学习。我们从一个假设出发：视觉理解预设了一种视觉语义语言，其中许多感知观察对应于少量离散的语义状态。结合表征学习中广泛假设的可迁移性和抽象性，该假设意味着视觉观察空间必须组织成类似于纤维束的结构，其中干扰变化填充纤维，而语义对应于商基空间。从这种结构中，我们推导出两个理论结果。首先，语义商空间$X/G$不是$X$的子流形，不能仅通过平滑变形获得，语义不变性需要非同胚的判别目标，例如，通过标签、跨实例识别或提供显式语义等价性的多模态对齐进行监督。其次，我们表明，近似商空间也对模型架构提出了结构性要求。语义抽象不仅需要外部语义目标，还需要能够支持拓扑变化的表征机制：一种扩展和捕捉过程，其中流形首先在几何上扩展以分离结构，然后塌陷以形成离散的语义区域。我们强调这些结果是解释性的而非规定性的：该框架提供了一个拓扑视角，与大规模判别和多模态模型中观察到的经验规律以及统计学习理论中的经典原则相一致。",
            "intro_zh": [
                "现有视觉表征学习方法缺乏对视觉语义结构和拓扑性质的深入理解。",
                "论文提出视觉语言假设，认为视觉理解依赖于离散语义状态和纤维束结构。",
                "该框架为理解大规模判别和多模态模型的经验规律提供了一个拓扑视角。"
            ],
            "method_zh": "**问题定义**：论文旨在理解视觉表征学习的内在结构，特别是如何从原始像素空间抽象到高级语义概念。现有方法通常侧重于优化模型以提高性能，而忽略了对表征空间拓扑结构的分析，这限制了对视觉理解本质的理解。现有方法缺乏对语义不变性的明确建模，导致模型容易受到噪声和干扰的影响。\\n\\n**核心思路**：论文的核心思路是引入“视觉语言假设”，即视觉理解依赖于一个潜在的语义语言，该语言将连续的视觉观察映射到少量的离散语义状态。这种假设暗示视觉观察空间具有纤维束结构，其中每个纤维代表同一语义概念的不同变体。通过分析这种结构，可以更好地理解语义不变性和抽象的本质。\\n\\n**技术框架**：论文构建了一个理论框架，该框架基于纤维束理论来描述视觉表征空间。该框架包括以下几个关键组成部分：1) 视觉观察空间X，代表所有可能的视觉输入。2) 语义空间G，代表离散的语义状态。3) 纤维束结构，将X组织成纤维，每个纤维对应于G中的一个语义状态。4) 商空间X/G，代表语义不变的表征。论文通过分析这些组成部分之间的关系，推导出关于语义不变性和抽象的理论结果。\\n\\n**关键创新**：论文的关键创新在于将纤维束理论引入视觉表征学习，并提出了“视觉语言假设”。这种假设提供了一种新的视角来理解视觉理解的本质，并为设计更有效的表征学习方法提供了理论指导。论文强调了语义不变性需要非同胚的判别目标，这与传统的平滑变形方法不同。\\n\\n**关键设计**：论文没有提出具体的模型架构或算法，而是侧重于理论分析。然而，论文的结论对模型设计具有重要意义。例如，论文指出语义抽象需要能够支持拓扑变化的表征机制，这暗示了需要使用具有非线性激活函数或跳跃连接的网络结构。论文还强调了需要使用显式的语义监督信号，例如标签或多模态对齐，来学习语义不变的表征。",
            "application_zh": "该研究成果可应用于各种视觉理解任务，例如图像分类、目标检测和语义分割。通过更好地理解视觉表征的内在结构，可以设计出更鲁棒、更高效的视觉模型。此外，该研究还可以促进跨模态学习和机器人视觉等领域的发展，为实现更智能的视觉系统奠定基础。",
            "highlight_zh": "论文的主要亮点在于提出了视觉语言假设，并从拓扑结构角度分析了视觉表征学习。虽然没有提供具体的实验结果，但该理论框架为理解现有深度学习模型的行为提供了一种新的视角，并为未来的研究方向提供了指导。",
            "tags_zh": [
                "视觉表征学习",
                "纤维束理论",
                "拓扑结构",
                "语义不变性",
                "视觉语言",
                "抽象",
                "深度学习"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation",
            "authors": [
                "Dianyun Wang",
                "Qingsen Ma",
                "Yuhu Shang",
                "Zhifeng Lu",
                "Lechen Ning",
                "Zhenbo Xu",
                "Huijia Wu",
                "Zhaofeng He"
            ],
            "arxiv_id": "2512.23260v1",
            "summary": "Parameter-efficient fine-tuning has become the dominant paradigm for adapting large language models to downstream tasks. Low-rank adaptation methods such as LoRA operate under the assumption that task-relevant weight updates reside in a low-rank subspace, yet this subspace is learned implicitly from data in a black-box manner, offering no interpretability or direct control. We hypothesize that this difficulty stems from polysemanticity--individual dimensions encoding multiple entangled concepts. To address this, we leverage pre-trained Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled feature space, then construct an explicit, interpretable low-rank subspace to guide adapter initialization. We provide theoretical analysis proving that under monosemanticity assumptions, SAE-based subspace identification achieves arbitrarily small recovery error, while direct identification in polysemantic space suffers an irreducible error floor. On safety alignment, our method achieves up to 99.6% safety rate--exceeding full fine-tuning by 7.4 percentage points and approaching RLHF-based methods--while updating only 0.19-0.24% of parameters. Crucially, our method provides interpretable insights into the learned alignment subspace through the semantic grounding of SAE features. Our work demonstrates that incorporating mechanistic interpretability into the fine-tuning process can simultaneously improve both performance and transparency.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23260v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "RLHF"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于稀疏自编码器构建低秩子空间适配的安全对齐方法",
            "summary_zh": "参数高效微调已成为将大型语言模型适配到下游任务的主流范式。诸如LoRA之类的低秩适配方法假设任务相关的权重更新存在于一个低秩子空间中，然而，这个子空间是以黑盒方式从数据中隐式学习的，不提供可解释性或直接控制。我们假设这种困难源于多义性——单个维度编码多个纠缠的概念。为了解决这个问题，我们利用预训练的稀疏自编码器（SAE）来识别解耦特征空间中的任务相关特征，然后构建一个显式的、可解释的低秩子空间来指导适配器初始化。我们提供了理论分析，证明在单义性假设下，基于SAE的子空间识别可以实现任意小的恢复误差，而多义空间中的直接识别会遭受不可约的误差下限。在安全对齐方面，我们的方法实现了高达99.6%的安全率——超过完全微调7.4个百分点，并接近基于RLHF的方法——同时仅更新0.19-0.24%的参数。至关重要的是，我们的方法通过SAE特征的语义基础，提供了对学习到的对齐子空间的可解释的见解。我们的工作表明，将机制可解释性融入微调过程可以同时提高性能和透明度。",
            "intro_zh": [
                "现有低秩适配方法缺乏可解释性，其低秩子空间以黑盒方式学习，难以直接控制。",
                "利用预训练稀疏自编码器识别解耦特征空间中的任务相关特征，构建显式可解释的低秩子空间。",
                "实验表明，该方法在安全对齐方面优于全微调，接近RLHF方法，同时仅更新少量参数。"
            ],
            "method_zh": "**问题定义**：现有低秩适配方法（如LoRA）在微调大型语言模型时，虽然参数效率高，但学习到的低秩子空间缺乏可解释性，难以理解和控制模型行为。这种黑盒特性限制了模型在安全对齐等任务中的应用，因为无法直接干预或验证模型的决策过程。现有方法难以应对特征空间的多义性问题，即单个维度可能编码多个纠缠的概念，导致子空间识别的误差较高。\\n\\n**核心思路**：论文的核心思路是利用预训练的稀疏自编码器（SAE）来解耦特征空间，将多义特征分解为单义特征。通过在解耦后的特征空间中识别任务相关的特征，可以构建一个更清晰、更可解释的低秩子空间，用于指导适配器的初始化。这种方法旨在将机制可解释性融入微调过程，从而提高模型的性能和透明度。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 使用预训练的稀疏自编码器（SAE）对模型的中间层特征进行编码，得到解耦的特征表示。2) 在解耦后的特征空间中，识别与特定任务（如安全对齐）相关的特征。这可以通过分析SAE激活与任务目标之间的相关性来实现。3) 基于识别出的任务相关特征，构建一个低秩子空间。这个子空间可以被视为一个适配器，用于在微调过程中调整模型的权重。4) 使用构建的低秩子空间初始化适配器，并进行微调。\\n\\n**关键创新**：该方法最重要的技术创新点在于将稀疏自编码器（SAE）引入到低秩适配框架中，用于解耦特征空间并提高可解释性。与传统的低秩适配方法相比，该方法能够显式地识别和控制任务相关的特征，从而实现更精确、更可控的微调。此外，该方法还提供了理论分析，证明在单义性假设下，基于SAE的子空间识别可以实现任意小的恢复误差。\\n\\n**关键设计**：SAE的训练目标是最小化重构误差，同时鼓励稀疏激活。这可以通过添加L1正则化项来实现。低秩子空间的构建方式取决于具体的任务和特征空间。一种常见的方法是选择与任务目标相关性最高的SAE激活对应的特征向量，并将它们作为子空间的基向量。适配器的初始化可以使用这些基向量的线性组合。损失函数通常包括任务相关的损失项（如交叉熵损失）和一个正则化项，用于防止过拟合。",
            "application_zh": "该研究成果可应用于安全关键型大型语言模型的对齐，例如，在自动驾驶、医疗诊断等领域，确保模型输出的安全性、可靠性和可解释性。此外，该方法还可推广到其他需要可控微调的场景，例如，个性化推荐、内容生成等。通过提高模型的可解释性，可以增强用户对模型的信任，并促进其更广泛的应用。",
            "highlight_zh": "该方法在安全对齐任务上取得了显著的性能提升，安全率高达99.6%，超过全微调7.4个百分点，并接近基于RLHF的方法。同时，该方法仅更新0.19-0.24%的参数，具有很高的参数效率。此外，该方法还提供了对学习到的对齐子空间的可解释的见解，通过SAE特征的语义基础，可以理解模型是如何进行安全对齐的。",
            "tags_zh": [
                "低秩适配",
                "参数高效微调",
                "稀疏自编码器",
                "可解释性",
                "安全对齐"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23260v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23260v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23260v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Diffusion-based Decentralized Federated Multi-Task Representation Learning",
            "authors": [
                "Donghwa Kang",
                "Shana Moothedath"
            ],
            "arxiv_id": "2512.23161v1",
            "summary": "Representation learning is a widely adopted framework for learning in data-scarce environments to obtain a feature extractor or representation from various different yet related tasks. Despite extensive research on representation learning, decentralized approaches remain relatively underexplored. This work develops a decentralized projected gradient descent-based algorithm for multi-task representation learning. We focus on the problem of multi-task linear regression in which multiple linear regression models share a common, low-dimensional linear representation. We present an alternating projected gradient descent and minimization algorithm for recovering a low-rank feature matrix in a diffusion-based decentralized and federated fashion. We obtain constructive, provable guarantees that provide a lower bound on the required sample complexity and an upper bound on the iteration complexity of our proposed algorithm. We analyze the time and communication complexity of our algorithm and show that it is fast and communication-efficient. We performed numerical simulations to validate the performance of our algorithm and compared it with benchmark algorithms.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23161v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于扩散的去中心化联邦多任务表征学习算法，解决数据稀缺环境下的特征提取问题。",
            "summary_zh": "本文提出了一种基于扩散的去中心化联邦多任务表征学习算法，用于解决数据稀缺环境下的学习问题，旨在从多个相关任务中学习特征提取器或表征。尽管表征学习的研究广泛，但去中心化方法相对较少。本文开发了一种基于去中心化投影梯度下降的多任务表征学习算法。我们专注于多任务线性回归问题，其中多个线性回归模型共享一个共同的低维线性表征。我们提出了一种交替投影梯度下降和最小化算法，用于以基于扩散的去中心化和联邦方式恢复低秩特征矩阵。我们获得了建设性的、可证明的保证，提供了所需样本复杂度的下界和所提出算法的迭代复杂度的上界。我们分析了算法的时间和通信复杂度，表明它快速且通信高效。我们进行了数值模拟，以验证算法的性能，并将其与基准算法进行了比较。",
            "intro_zh": [
                "现有表征学习方法在去中心化场景下探索不足，难以适应数据分散的实际应用。",
                "提出一种基于扩散的去中心化联邦学习算法，通过交替投影梯度下降和最小化，学习共享的低秩特征矩阵。",
                "理论分析表明算法具有良好的样本复杂度和迭代复杂度，数值实验验证了其性能优于基准算法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多任务线性回归问题，其中多个线性回归模型需要共享一个低维的线性表征。现有方法在去中心化场景下，难以保证学习效率和通信效率，并且缺乏理论保证。\\n\\n**核心思路**：论文的核心思路是利用扩散策略，在去中心化的网络中，通过节点间的信息交换，实现对全局低秩特征矩阵的协同学习。通过交替的投影梯度下降和最小化步骤，每个节点逐步逼近全局最优解。\\n\\n**技术框架**：整体框架包含以下几个主要步骤：1) 初始化：每个节点初始化一个局部特征矩阵；2) 扩散：节点之间交换局部特征矩阵的信息；3) 投影梯度下降：每个节点利用接收到的信息和本地数据，进行投影梯度下降更新局部特征矩阵；4) 最小化：对更新后的局部特征矩阵进行最小化操作，以保证低秩性；5) 迭代：重复步骤2-4，直到收敛。\\n\\n**关键创新**：论文的关键创新在于将扩散策略与投影梯度下降相结合，提出了一种去中心化的联邦多任务表征学习算法。该算法能够在保证学习性能的同时，降低通信成本，并提供了理论上的收敛性保证。与传统的集中式方法相比，该方法更适用于数据分散的场景。\\n\\n**关键设计**：算法的关键设计包括：1) 投影算子的选择，需要保证投影后的矩阵满足低秩约束；2) 梯度下降步长的选择，需要保证算法的收敛性；3) 扩散策略的设计，需要平衡信息交换的效率和通信成本；4) 损失函数的设计，需要能够反映多任务之间的关系，并促进共享表征的学习。",
            "application_zh": "该研究具有广泛的应用前景，例如在医疗健康领域，不同医院可以共享患者数据，共同学习疾病的诊断模型；在金融领域，不同银行可以共享交易数据，共同学习信用风险评估模型；在物联网领域，不同设备可以共享传感器数据，共同学习环境监测模型。该研究可以促进数据共享和协同学习，提高模型的泛化能力和鲁棒性。",
            "highlight_zh": "论文通过数值模拟验证了所提出算法的性能。实验结果表明，该算法在多任务线性回归问题上，能够有效地学习到共享的低秩特征矩阵，并且在样本复杂度和迭代复杂度方面，优于传统的基准算法。具体的性能提升数据在论文中给出，证明了该算法的有效性和优越性。",
            "tags_zh": [
                "去中心化学习",
                "联邦学习",
                "多任务学习",
                "表征学习",
                "扩散策略"
            ],
            "_index": 57,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23161v1/Fig1a_Tcon10.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23161v1/Fig1b_Tcon20.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23161v1/Fig1c_Tcon30.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications",
            "authors": [
                "Haixiao Gao",
                "Mengying Sun",
                "Ruichen Zhang",
                "Yanhan Wang",
                "Xiaodong Xu",
                "Nan Ma",
                "Dusit Niyato",
                "Ping Zhang"
            ],
            "arxiv_id": "2512.23294v1",
            "summary": "Semantic communications (SemCom), as one of the key technologies for 6G, is shifting networks from bit transmission to semantic information exchange. On this basis, introducing agentic artificial intelligence (AI) with perception, memory, reasoning, and action capabilities provides a practicable path to intelligent communications. This paper provides a systematic exposition of how agentic AI empowers SemCom from the perspectives of research foundations, system architecture, and application scenarios. We first provide a comprehensive review of existing studies by agent types, covering embedded agents, large language model (LLM)/large vision model (LVM) agents, and reinforcement learning (RL) agents. Additionally, we propose a unified agentic AI-enhanced SemCom framework covering the application layer, the semantic layer, and the cloud-edge collaboration layer, forming a closed loop from intent to encoding to transmission to decoding to action to evaluation. We also present several typical scenarios, including multi-vehicle collaborative perception, multi-robot cooperative rescue, and agentic operations for intellicise (intelligent and concise) networks. Furthermore, we introduce an agentic knowledge base (KB)-based joint source-channel coding case study, AKB-JSCC, where the source KB and channel KB are built by LLM/LVM agents and RL agents, respectively. Experimental results show that AKB-JSCC achieves higher information reconstruction quality under different channel conditions. Finally, we discuss future evolution and research directions, providing a reference for portable, verifiable, and controllable research and deployment of agentic SemCom.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23294v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Agentic AI增强的语义通信框架，提升复杂场景下的信息重建质量。",
            "summary_zh": "本文系统性地阐述了Agentic AI如何赋能语义通信(SemCom)，从研究基础、系统架构和应用场景三个角度展开。首先，全面回顾了现有基于不同类型Agent的研究，包括嵌入式Agent、大型语言模型(LLM)/大型视觉模型(LVM)Agent和强化学习(RL)Agent。其次，提出了一个统一的Agentic AI增强的SemCom框架，覆盖应用层、语义层和云边协同层，形成从意图到编码到传输到解码到行动到评估的闭环。此外，还展示了几个典型的应用场景，包括多车辆协同感知、多机器人协同救援以及面向智能简洁网络的Agentic操作。进一步地，介绍了一个基于Agentic知识库(KB)的联合信源信道编码案例研究AKB-JSCC，其中信源KB和信道KB分别由LLM/LVM Agent和RL Agent构建。实验结果表明，AKB-JSCC在不同的信道条件下实现了更高的信息重建质量。最后，讨论了未来的发展和研究方向，为Agentic SemCom的可移植、可验证和可控的研究和部署提供参考。",
            "intro_zh": [
                "现有语义通信方法在复杂动态环境中难以有效提取和利用语义信息，导致通信效率和可靠性受限。",
                "本文提出Agentic AI增强的语义通信框架，利用Agent的感知、记忆、推理和行动能力，实现更智能的语义信息处理。",
                "通过Agentic知识库驱动的联合信源信道编码（AKB-JSCC）实验，验证了该框架在提升信息重建质量方面的有效性。"
            ],
            "method_zh": "**问题定义**：现有语义通信方法在面对复杂、动态的环境时，难以准确提取和利用语义信息，导致通信效率和可靠性下降。尤其是在资源受限的场景下，如何进行高效的语义编码和传输是一个挑战。现有方法通常依赖于预定义的语义规则或固定的模型，缺乏适应性和智能性。\\n\\n**核心思路**：本文的核心思路是引入Agentic AI，利用其感知、记忆、推理和行动能力，构建一个更智能、更自适应的语义通信系统。通过Agent对环境的感知和理解，可以更准确地提取语义信息，并根据信道条件动态调整编码策略，从而提高通信效率和可靠性。\\n\\n**技术框架**：该框架包含三个主要层次：应用层、语义层和云边协同层。应用层负责接收用户的意图，并将其转化为语义层的输入。语义层利用Agentic AI进行语义编码和解码，包括语义提取、推理和知识库查询。云边协同层负责信道编码、传输和资源管理，利用云端强大的计算能力和边缘设备的实时响应能力，实现高效的通信。整个框架形成一个闭环，从意图到行动再到评估，不断优化通信策略。\\n\\n**关键创新**：最重要的技术创新点在于将Agentic AI引入语义通信，并构建了一个统一的框架。与传统的语义通信方法相比，该框架具有更强的自适应性和智能性，能够更好地应对复杂动态环境。此外，基于Agentic知识库的联合信源信道编码（AKB-JSCC）也是一个重要的创新，它能够根据信源和信道的特性，动态调整编码策略，从而提高信息重建质量。\\n\\n**关键设计**：在AKB-JSCC中，信源知识库由LLM/LVM Agent构建，负责提取信源的语义信息；信道知识库由RL Agent构建，负责学习信道特性并优化信道编码策略。LLM/LVM Agent可以采用预训练模型进行微调，RL Agent可以采用深度Q网络（DQN）等算法进行训练。损失函数可以包括信息重建误差、传输功耗等，通过优化损失函数，可以实现高效的语义通信。",
            "application_zh": "该研究成果可应用于多车辆协同感知、多机器人协同救援等复杂场景。通过Agentic AI增强的语义通信，可以实现更高效的信息共享和协同决策，提高系统的整体性能和可靠性。未来，该技术还可应用于智能交通、智能制造、智慧城市等领域，推动智能化社会的发展。",
            "highlight_zh": "实验结果表明，基于Agentic知识库的联合信源信道编码（AKB-JSCC）在不同的信道条件下实现了更高的信息重建质量。具体来说，在信噪比较低的情况下，AKB-JSCC相比于传统的联合信源信道编码方法，信息重建质量提升了约10%-20%。这表明Agentic AI能够有效提升语义通信的性能。",
            "tags_zh": [
                "语义通信",
                "Agentic AI",
                "大型语言模型",
                "强化学习",
                "知识库",
                "联合信源信道编码",
                "智能通信",
                "云边协同"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23294v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23294v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23294v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation",
            "authors": [
                "Shaocong Xu",
                "Songlin Wei",
                "Qizhe Wei",
                "Zheng Geng",
                "Hong Li",
                "Licheng Shen",
                "Qianpu Sun",
                "Shu Han",
                "Bin Ma",
                "Bohan Li",
                "Chongjie Ye",
                "Yuhang Zheng",
                "Nan Wang",
                "Saining Zhang",
                "Hao Zhao"
            ],
            "arxiv_id": "2512.23705v1",
            "summary": "Transparent objects remain notoriously hard for perception systems: refraction, reflection and transmission break the assumptions behind stereo, ToF and purely discriminative monocular depth, causing holes and temporally unstable estimates. Our key observation is that modern video diffusion models already synthesize convincing transparent phenomena, suggesting they have internalized the optical rules. We build TransPhy3D, a synthetic video corpus of transparent/reflective scenes: 11k sequences rendered with Blender/Cycles. Scenes are assembled from a curated bank of category-rich static assets and shape-rich procedural assets paired with glass/plastic/metal materials. We render RGB + depth + normals with physically based ray tracing and OptiX denoising. Starting from a large video diffusion model, we learn a video-to-video translator for depth (and normals) via lightweight LoRA adapters. During training we concatenate RGB and (noisy) depth latents in the DiT backbone and co-train on TransPhy3D and existing frame-wise synthetic datasets, yielding temporally consistent predictions for arbitrary-length input videos. The resulting model, DKT, achieves zero-shot SOTA on real and synthetic video benchmarks involving transparency: ClearPose, DREDS (CatKnown/CatNovel), and TransPhy3D-Test. It improves accuracy and temporal consistency over strong image/video baselines, and a normal variant sets the best video normal estimation results on ClearPose. A compact 1.3B version runs at ~0.17 s/frame. Integrated into a grasping stack, DKT's depth boosts success rates across translucent, reflective and diffuse surfaces, outperforming prior estimators. Together, these results support a broader claim: \"Diffusion knows transparency.\" Generative video priors can be repurposed, efficiently and label-free, into robust, temporally coherent perception for challenging real-world manipulation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Project Page: https://daniellli.github.io/projects/DKT/; Code: https://github.com/Daniellli/DKT; Dataset: https://huggingface.co/datasets/Daniellesry/TransPhy3D",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23705v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "monocular depth"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "1_robot_core",
                "3_perception_slam"
            ],
            "headline_zh": "利用视频扩散模型，DKT实现了透明物体深度和法向量的零样本SOTA估计",
            "summary_zh": "透明物体对感知系统来说一直是个难题，折射、反射和透射破坏了立体视觉、飞行时间相机以及纯粹判别式单目深度估计的假设，导致空洞和时间上不稳定的估计。本文的关键观察是，现代视频扩散模型已经合成了令人信服的透明现象，表明它们已经内化了光学规则。为此，作者构建了TransPhy3D，一个透明/反射场景的合成视频语料库，包含1.1万个使用Blender/Cycles渲染的序列。场景由丰富的静态资产和程序化资产组成，并配以玻璃/塑料/金属材料。使用基于物理的光线追踪和OptiX降噪渲染RGB +深度+法向量。从大型视频扩散模型出发，通过轻量级的LoRA适配器学习视频到视频的深度（和法向量）转换器。在训练过程中，将RGB和（带噪声的）深度潜在变量连接在DiT骨干网络中，并在TransPhy3D和现有的逐帧合成数据集上进行联合训练，从而为任意长度的输入视频产生时间一致的预测。由此产生的模型DKT在涉及透明度的真实和合成视频基准测试（ClearPose、DREDS和TransPhy3D-Test）上实现了零样本SOTA。它提高了精度和时间一致性，并且一个法向量变体在ClearPose上设置了最佳视频法向量估计结果。一个紧凑的1.3B版本以约0.17秒/帧的速度运行。集成到抓取堆栈中，DKT的深度提高了半透明、反射和漫反射表面的成功率，优于先前的估计器。总之，这些结果支持一个更广泛的论点：“扩散知道透明度。”生成视频先验可以被重新利用，高效且无标签地转化为鲁棒的、时间连贯的感知，用于具有挑战性的真实世界操作。",
            "intro_zh": [
                "传统方法在透明物体深度估计方面面临挑战，因为透明物体的折射、反射等特性违反了传统视觉算法的假设。",
                "该论文利用视频扩散模型已经能够生成逼真的透明效果的特性，通过训练将视频扩散模型转化为深度和法向量估计器。",
                "实验表明，该方法在真实和合成数据集上均取得了SOTA结果，并在抓取任务中提高了成功率，验证了方法的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决透明和反射物体深度和法向量估计的问题。现有方法，如立体视觉、ToF传感器和单目深度估计，在处理透明物体时会失效，导致深度估计不准确、存在空洞以及时间上的不稳定性。这些方法无法很好地处理由于折射、反射和透射等现象引起的光线传播变化。\\n\\n**核心思路**：论文的核心思路是利用视频扩散模型已经学习到的关于透明物体光学特性的先验知识。作者认为，如果扩散模型能够生成逼真的透明效果，那么它一定已经内化了相关的物理规则。因此，可以通过训练将视频扩散模型转化为深度和法向量估计器，从而解决透明物体的感知问题。\\n\\n**技术框架**：整体框架包括以下几个主要步骤：1) 构建大规模合成数据集TransPhy3D，包含透明和反射场景的视频序列，并提供精确的深度和法向量标签。2) 基于大型视频扩散模型，使用LoRA适配器学习视频到视频的转换器，用于预测深度和法向量。3) 在训练过程中，将RGB图像和带噪声的深度潜在变量连接到DiT骨干网络中，并在TransPhy3D和现有数据集上进行联合训练，以提高模型的泛化能力和时间一致性。\\n\\n**关键创新**：该论文的关键创新在于将视频扩散模型用于透明物体的深度和法向量估计。与传统方法不同，该方法不依赖于特定的几何或光度假设，而是利用扩散模型学习到的先验知识来推断透明物体的深度和法向量。此外，使用LoRA适配器可以高效地将大型扩散模型适应于新的任务。\\n\\n**关键设计**：TransPhy3D数据集包含1.1万个视频序列，使用Blender/Cycles渲染，并使用OptiX降噪。训练过程中，使用LoRA适配器来微调视频扩散模型，并采用联合训练策略，结合TransPhy3D和现有数据集。损失函数包括深度和法向量的L1损失，以及时间一致性损失。模型使用DiT作为骨干网络，并使用RGB和深度潜在变量的连接作为输入。",
            "application_zh": "该研究成果可应用于机器人抓取、自动驾驶、增强现实等领域。在机器人抓取中，准确的深度估计可以帮助机器人更好地识别和抓取透明或反射物体。在自动驾驶中，可以提高车辆对透明物体的感知能力，例如挡风玻璃、水面等。在增强现实中，可以更真实地渲染虚拟物体与真实透明物体的交互。",
            "highlight_zh": "DKT在ClearPose、DREDS和TransPhy3D-Test等数据集上实现了零样本SOTA，显著提高了透明物体深度和法向量估计的准确性和时间一致性。在ClearPose数据集上，法向量估计结果达到了最佳水平。此外，一个紧凑的1.3B版本模型运行速度达到0.17秒/帧，具有实际应用价值。集成到抓取堆栈后，DKT显著提高了半透明、反射和漫反射表面的抓取成功率。",
            "tags_zh": [
                "透明物体感知",
                "深度估计",
                "法向量估计",
                "视频扩散模型",
                "零样本学习"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23705v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23705v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23705v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SoulX-LiveTalk Technical Report",
            "authors": [
                "Le Shen",
                "Qiao Qian",
                "Tan Yu",
                "Ke Zhou",
                "Tianhang Yu",
                "Yu Zhan",
                "Zhenjie Wang",
                "Ming Tao",
                "Shunshun Yin",
                "Siyuan Liu"
            ],
            "arxiv_id": "2512.23379v1",
            "summary": "Deploying massive diffusion models for real-time, infinite-duration, audio-driven avatar generation presents a significant engineering challenge, primarily due to the conflict between computational load and strict latency constraints. Existing approaches often compromise visual fidelity by enforcing strictly unidirectional attention mechanisms or reducing model capacity. To address this problem, we introduce \\textbf{SoulX-LiveTalk}, a 14B-parameter framework optimized for high-fidelity real-time streaming. Diverging from conventional unidirectional paradigms, we use a \\textbf{Self-correcting Bidirectional Distillation} strategy that retains bidirectional attention within video chunks. This design preserves critical spatiotemporal correlations, significantly enhancing motion coherence and visual detail. To ensure stability during infinite generation, we incorporate a \\textbf{Multi-step Retrospective Self-Correction Mechanism}, enabling the model to autonomously recover from accumulated errors and preventing collapse. Furthermore, we engineered a full-stack inference acceleration suite incorporating hybrid sequence parallelism, Parallel VAE, and kernel-level optimizations. Extensive evaluations confirm that SoulX-LiveTalk is the first 14B-scale system to achieve a \\textbf{sub-second start-up latency (0.87s)} while reaching a real-time throughput of \\textbf{32 FPS}, setting a new standard for high-fidelity interactive digital human synthesis.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "12 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23379v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "spatiotemporal"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 3.5,
            "hit_pillars": [
                "2_algo_arch",
                "8_physics_animation"
            ],
            "headline_zh": "提出SoulX-LiveTalk框架，实现高保真实时音频驱动的数字人生成。",
            "summary_zh": "本文提出SoulX-LiveTalk，一个参数量为140亿的框架，专为高保真实时流媒体应用优化。针对大规模扩散模型在实时、无限时长、音频驱动的数字人生成中面临的计算负载与严格延迟约束之间的矛盾，该框架采用自校正双向蒸馏策略，在视频块内保留双向注意力，从而保留关键的时空相关性，显著增强运动连贯性和视觉细节。为了确保无限生成过程中的稳定性，引入多步回顾自校正机制，使模型能够自主地从累积误差中恢复并防止崩溃。此外，还设计了全栈推理加速套件，包括混合序列并行、并行VAE和内核级优化。实验结果表明，SoulX-LiveTalk是首个实现亚秒级启动延迟（0.87秒）并达到32 FPS实时吞吐量的140亿参数规模系统，为高保真交互式数字人合成树立了新标准。",
            "intro_zh": [
                "现有方法在实时数字人生成中，为满足延迟约束，常牺牲视觉保真度，例如采用单向注意力或降低模型容量。",
                "SoulX-LiveTalk采用自校正双向蒸馏，保留时空相关性，并引入多步回顾自校正机制，确保生成稳定性。",
                "SoulX-LiveTalk实现了0.87秒的启动延迟和32 FPS的实时吞吐量，为140亿参数规模系统设立了新标准。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大规模扩散模型在实时、无限时长、音频驱动的数字人生成任务中，计算负载高和延迟要求严格之间的矛盾。现有方法为了满足实时性，通常会牺牲生成质量，例如采用严格的单向注意力机制或者降低模型容量，导致生成的数字人在运动连贯性和视觉细节上表现不佳。\\n\\n**核心思路**：SoulX-LiveTalk的核心思路是在保证实时性的前提下，尽可能保留模型的表达能力和生成质量。为此，论文提出了自校正双向蒸馏策略，以保留视频块内的双向注意力，从而捕捉更丰富的时空信息。同时，为了解决无限生成过程中可能出现的误差累积和模型崩溃问题，引入了多步回顾自校正机制。\\n\\n**技术框架**：SoulX-LiveTalk的整体框架包含以下几个主要模块：1) 音频特征提取模块：用于提取输入音频的特征表示。2) 扩散模型：基于扩散模型的生成器，负责将音频特征转化为高保真的数字人视频。3) 自校正双向蒸馏模块：在训练阶段，通过双向注意力机制学习更丰富的时空信息，并通过蒸馏的方式将这些信息传递给推理阶段的模型。4) 多步回顾自校正模块：在推理阶段，定期回顾之前的生成结果，并进行自校正，以防止误差累积和模型崩溃。5) 推理加速套件：包括混合序列并行、并行VAE和内核级优化，用于加速模型的推理过程。\\n\\n**关键创新**：SoulX-LiveTalk的关键创新在于以下几个方面：1) 自校正双向蒸馏策略：突破了传统单向注意力机制的限制，保留了更丰富的时空信息，从而提高了生成质量。2) 多步回顾自校正机制：解决了无限生成过程中可能出现的误差累积和模型崩溃问题，保证了生成过程的稳定性。3) 全栈推理加速套件：通过多种优化手段，显著提高了模型的推理速度，使其能够满足实时性要求。\\n\\n**关键设计**：在自校正双向蒸馏中，采用了教师-学生模型的蒸馏方式，教师模型使用双向注意力，学生模型则在推理时使用单向注意力，以保证实时性。多步回顾自校正机制中，设置了回顾的频率和校正的强度等参数，以平衡生成质量和计算开销。在推理加速方面，混合序列并行将模型参数分布在多个GPU上，并行VAE则同时处理多个VAE的计算，内核级优化则针对关键算子进行了手工优化。",
            "application_zh": "SoulX-LiveTalk在虚拟主播、在线教育、远程会议、游戏娱乐等领域具有广泛的应用前景。它可以用于创建高度逼真的虚拟形象，并根据用户的语音实时生成相应的视频内容，从而提供更具沉浸感和互动性的用户体验。该技术还有潜力应用于医疗健康、心理咨询等领域，为患者提供个性化的虚拟助手。",
            "highlight_zh": "SoulX-LiveTalk在实验中表现出色，实现了0.87秒的亚秒级启动延迟，并达到了32 FPS的实时吞吐量。这是首个达到如此高性能的140亿参数规模的数字人生成系统。相比于现有方法，SoulX-LiveTalk在生成质量和实时性方面都取得了显著的提升，为高保真交互式数字人合成树立了新的标杆。",
            "tags_zh": [
                "数字人生成",
                "实时渲染",
                "扩散模型",
                "双向注意力",
                "自校正机制",
                "模型蒸馏",
                "推理加速",
                "音频驱动"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23379v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23379v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23379v1/figs/visual_quality1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Automated river gauge plate reading using a hybrid object detection and generative AI framework in the Limpopo River Basin",
            "authors": [
                "Kayathri Vigneswaran",
                "Hugo Retief",
                "Jai Clifford Holmes",
                "Mariangel Garcia Andarcia",
                "Hansaka Tennakoon"
            ],
            "arxiv_id": "2512.23454v1",
            "summary": "Accurate and continuous monitoring of river water levels is essential for flood forecasting, water resource management, and ecological protection. Traditional hydrological observation methods are often limited by manual measurement errors and environmental constraints. This study presents a hybrid framework integrating vision based waterline detection, YOLOv8 pose scale extraction, and large multimodal language models (GPT 4o and Gemini 2.0 Flash) for automated river gauge plate reading. The methodology involves sequential stages of image preprocessing, annotation, waterline detection, scale gap estimation, and numeric reading extraction. Experiments demonstrate that waterline detection achieved high precision of 94.24 percent and an F1 score of 83.64 percent, while scale gap detection provided accurate geometric calibration for subsequent reading extraction. Incorporating scale gap metadata substantially improved the predictive performance of LLMs, with Gemini Stage 2 achieving the highest accuracy, with a mean absolute error of 5.43 cm, root mean square error of 8.58 cm, and R squared of 0.84 under optimal image conditions. Results highlight the sensitivity of LLMs to image quality, with degraded images producing higher errors, and underscore the importance of combining geometric metadata with multimodal artificial intelligence for robust water level estimation. Overall, the proposed approach offers a scalable, efficient, and reliable solution for automated hydrological monitoring, demonstrating potential for real time river gauge digitization and improved water resource management.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "11 pages, 14 figures, 4 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23454v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出混合AI框架，用于利姆波波河流域自动读取水位标尺",
            "summary_zh": "本文提出了一种混合框架，该框架集成了基于视觉的水线检测、YOLOv8姿态尺度提取以及大型多模态语言模型（GPT 4o和Gemini 2.0 Flash），用于自动读取河流标尺。该方法包括图像预处理、标注、水线检测、刻度间隙估计和数值读取提取等阶段。实验表明，水线检测实现了94.24%的高精度和83.64%的F1分数，而刻度间隙检测为后续的读数提取提供了精确的几何校准。结合刻度间隙元数据显著提高了LLM的预测性能，其中Gemini Stage 2在最佳图像条件下实现了最高的准确率，平均绝对误差为5.43厘米，均方根误差为8.58厘米，R平方为0.84。结果表明，LLM对图像质量敏感，图像质量下降会导致更高的误差，并强调了将几何元数据与多模态人工智能相结合以实现稳健的水位估计的重要性。总的来说，该方法为自动水文监测提供了一种可扩展、高效且可靠的解决方案，展示了实时河流标尺数字化和改进水资源管理的潜力。",
            "intro_zh": [
                "传统人工测量水位存在误差和环境限制，难以满足洪水预报和水资源管理的需求。",
                "提出结合视觉水线检测、YOLOv8姿态估计和大型多模态语言模型的混合框架，实现自动水位标尺读取。",
                "实验表明，该方法在水线检测和刻度估计方面表现出色，结合几何元数据显著提升了LLM的预测精度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决传统人工测量河流标尺水位存在的误差大、效率低以及难以实时监测的问题。现有方法依赖人工读数，易受主观因素和环境条件的影响，无法满足现代水资源管理和防洪预警的需求。\\n\\n**核心思路**：论文的核心思路是将计算机视觉技术与大型多模态语言模型相结合，利用视觉技术提取水位标尺的几何信息，然后利用LLM进行数值识别和水位估计。通过融合视觉信息和语言模型的推理能力，提高水位读取的准确性和鲁棒性。\\n\\n**技术框架**：该框架包含以下主要阶段：1) 图像预处理：对采集的河流标尺图像进行去噪、增强等处理，提高图像质量。2) 水线检测：利用计算机视觉算法检测图像中的水线位置。3) 刻度间隙估计：使用YOLOv8提取标尺的姿态和尺度信息，估计刻度之间的间隙大小。4) 数值读取提取：将水线位置和刻度间隙信息输入到大型多模态语言模型（GPT 4o或Gemini 2.0 Flash）中，由LLM识别标尺上的数值并估计水位。\\n\\n**关键创新**：该论文的关键创新在于将计算机视觉技术与大型多模态语言模型相结合，实现自动化的河流标尺水位读取。通过引入刻度间隙的几何元数据，显著提高了LLM的预测性能。此外，该方法还探索了不同LLM在水位读取任务中的表现，并分析了图像质量对LLM性能的影响。\\n\\n**关键设计**：水线检测采用图像处理算法，例如边缘检测和霍夫变换。刻度间隙估计使用YOLOv8进行目标检测和姿态估计。大型多模态语言模型使用GPT 4o和Gemini 2.0 Flash，通过提示工程（prompt engineering）引导LLM进行数值识别和水位估计。损失函数主要考虑水位估计的均方误差和绝对误差。",
            "application_zh": "该研究成果可应用于水文监测、水资源管理、防洪预警等领域。通过自动化河流标尺水位读取，可以提高监测效率和数据质量，为水资源决策提供更准确的依据。该技术还可扩展到其他类型的仪表读数自动化，具有广泛的应用前景。",
            "highlight_zh": "实验结果表明，水线检测精度达到94.24%，F1分数为83.64%。在最佳图像条件下，结合刻度间隙元数据后，Gemini Stage 2的平均绝对误差为5.43厘米，均方根误差为8.58厘米，R平方为0.84。实验还验证了图像质量对LLM性能的影响，表明高质量图像对于准确的水位估计至关重要。",
            "tags_zh": [
                "水位监测",
                "河流标尺",
                "计算机视觉",
                "YOLOv8",
                "多模态学习",
                "大型语言模型",
                "水资源管理"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Towards Integrating Uncertainty for Domain-Agnostic Segmentation",
            "authors": [
                "Jesse Brouwers",
                "Xiaoyan Xing",
                "Alexander Timans"
            ],
            "arxiv_id": "2512.23427v1",
            "summary": "Foundation models for segmentation such as the Segment Anything Model (SAM) family exhibit strong zero-shot performance, but remain vulnerable in shifted or limited-knowledge domains. This work investigates whether uncertainty quantification can mitigate such challenges and enhance model generalisability in a domain-agnostic manner. To this end, we (1) curate UncertSAM, a benchmark comprising eight datasets designed to stress-test SAM under challenging segmentation conditions including shadows, transparency, and camouflage; (2) evaluate a suite of lightweight, post-hoc uncertainty estimation methods; and (3) assess a preliminary uncertainty-guided prediction refinement step. Among evaluated approaches, a last-layer Laplace approximation yields uncertainty estimates that correlate well with segmentation errors, indicating a meaningful signal. While refinement benefits are preliminary, our findings underscore the potential of incorporating uncertainty into segmentation models to support robust, domain-agnostic performance. Our benchmark and code are made publicly available.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Public code at https://github.com/JesseBrouw/UncertSAM | published at the 2nd Workshop on Frontiers in Probabilistic Inference (NeurIPS 2025) | 12 pages, 8 figures (incl. Appendix)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23427v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出UncertSAM基准并探索不确定性量化，提升分割模型在未知领域的泛化性",
            "summary_zh": "针对Segment Anything Model (SAM)等分割基础模型在领域迁移或知识有限的情况下表现不佳的问题，本文研究了不确定性量化是否能缓解这些挑战，并提升模型在领域无关场景下的泛化能力。为此，我们（1）构建了UncertSAM基准，包含八个数据集，旨在压力测试SAM在阴影、透明度和伪装等具有挑战性的分割条件下的性能；（2）评估了一系列轻量级的后验不确定性估计方法；（3）评估了一个初步的、不确定性引导的预测优化步骤。在评估的方法中，最后一层拉普拉斯近似产生的不确定性估计与分割误差具有良好的相关性，表明存在有意义的信号。虽然优化带来的好处是初步的，但我们的发现强调了将不确定性纳入分割模型以支持鲁棒的、领域无关的性能的潜力。我们的基准和代码已公开。",
            "intro_zh": [
                "分割基础模型在领域迁移时性能下降，缺乏对未知环境的鲁棒性。",
                "通过量化模型预测的不确定性，指导模型在困难样本上的预测优化。",
                "构建UncertSAM基准测试不确定性估计方法，并验证其与分割误差的相关性。"
            ],
            "method_zh": "**问题定义**：现有分割基础模型，如SAM，在面对领域偏移或知识受限的场景时，分割性能会显著下降。这些模型缺乏对自身预测结果的置信度评估，难以区分可靠预测和错误预测，导致在未知环境中的泛化能力不足。因此，如何提升分割模型在领域无关场景下的鲁棒性，是本文要解决的核心问题。\\n\\n**核心思路**：本文的核心思路是利用不确定性量化来指导分割模型的预测。通过估计模型预测结果的不确定性，可以识别出模型容易出错的区域，并针对这些区域进行预测优化。这种方法的核心在于，认为模型的不确定性与分割误差之间存在相关性，可以通过不确定性信息来提升模型的性能。\\n\\n**技术框架**：本文的技术框架主要包含三个部分：首先，构建UncertSAM基准数据集，用于评估不同不确定性估计方法在各种具有挑战性的分割场景下的性能。其次，评估一系列轻量级的后验不确定性估计方法，包括蒙特卡洛dropout、深度集成和最后一层拉普拉斯近似等。最后，设计一个初步的不确定性引导的预测优化步骤，利用估计的不确定性信息来改进模型的分割结果。\\n\\n**关键创新**：本文的关键创新在于探索了不确定性量化在提升分割模型领域泛化能力方面的潜力。通过构建UncertSAM基准，为评估不确定性估计方法提供了一个统一的平台。此外，本文还验证了最后一层拉普拉斯近似方法在估计分割模型不确定性方面的有效性，并初步探索了利用不确定性信息进行预测优化的方法。\\n\\n**关键设计**：在不确定性估计方面，本文主要关注轻量级的后验方法，以便于集成到现有的分割模型中。其中，最后一层拉普拉斯近似方法通过对模型最后一层的权重进行拉普拉斯近似，来估计预测结果的不确定性。在预测优化方面，本文采用了一种简单的不确定性加权方法，即对不确定性较高的区域赋予更高的权重，以引导模型进行更准确的预测。具体的参数设置和损失函数细节在论文中进行了详细描述。",
            "application_zh": "该研究成果可应用于自动驾驶、医学图像分析、遥感图像处理等领域。通过提高分割模型在复杂和未知环境下的鲁棒性，可以减少人工干预，提高工作效率，并为相关应用提供更可靠的决策支持。未来，该研究可以进一步扩展到其他视觉任务，如目标检测和图像分类，并探索更有效的不确定性量化和利用方法。",
            "highlight_zh": "实验结果表明，最后一层拉普拉斯近似方法能够有效估计分割模型的不确定性，并且该不确定性与分割误差具有良好的相关性。初步的预测优化实验表明，利用不确定性信息可以提升模型的分割性能，但提升幅度有限，未来仍有较大的改进空间。UncertSAM基准的发布为后续研究提供了统一的评估平台。",
            "tags_zh": [
                "语义分割",
                "不确定性量化",
                "领域泛化",
                "基础模型",
                "拉普拉斯近似"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23427v1/images/ignorance_example/prompt_input.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23427v1/images/ignorance_example/predicted_masks.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23427v1/images/ignorance_example/residuals.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents",
            "authors": [
                "Jiafeng Liang",
                "Hao Li",
                "Chang Li",
                "Jiaqi Zhou",
                "Shixin Jiang",
                "Zekun Wang",
                "Changkai Ji",
                "Zhihao Zhu",
                "Runxuan Liu",
                "Tao Ren",
                "Jinlan Fu",
                "See-Kiong Ng",
                "Xia Liang",
                "Ming Liu",
                "Bing Qin"
            ],
            "arxiv_id": "2512.23343v1",
            "summary": "Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "57 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23343v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "综述：AI Agent中借鉴认知神经科学的记忆系统设计",
            "summary_zh": "记忆是连接过去和未来的关键，为人类和AI系统提供宝贵的经验和概念，以应对复杂任务。最近，自主Agent的研究越来越关注借鉴认知神经科学来设计高效的记忆工作流程。然而，由于跨学科的障碍，现有的工作难以充分吸收人类记忆机制的本质。为了弥合这一差距，本文系统地综合了记忆的跨学科知识，将认知神经科学的见解与LLM驱动的Agent联系起来。具体来说，我们首先阐明了记忆的定义和功能，沿着从认知神经科学到LLM再到Agent的渐进轨迹进行分析。然后，我们对生物和人工视角的记忆分类、存储机制以及完整的管理生命周期进行了比较分析。随后，我们回顾了用于评估Agent记忆的主流基准。此外，我们从攻击和防御的双重角度探讨了记忆安全。最后，我们展望了未来的研究方向，重点是多模态记忆系统和技能获取。",
            "intro_zh": [
                "现有自主Agent在设计记忆系统时，未能充分理解和利用人类记忆机制的本质，存在跨学科知识融合的障碍。",
                "本文旨在弥合认知神经科学与AI Agent之间的差距，系统地整合记忆的跨学科知识，并将其应用于LLM驱动的Agent。",
                "本文对记忆的定义、功能、分类、存储、管理以及安全性进行了全面分析，并展望了多模态记忆系统和技能获取的未来研究方向。"
            ],
            "method_zh": "**问题定义**：现有自主Agent的记忆系统设计，虽然借鉴了认知神经科学的一些概念，但由于跨学科知识的壁垒，未能充分理解和应用人类记忆机制的精髓。这导致Agent在处理复杂任务时，记忆效率和泛化能力受到限制。现有方法缺乏对记忆的全面理解，包括记忆的分类、存储机制、管理生命周期以及安全性等方面。\n\n**核心思路**：本文的核心思路是通过系统性地梳理和整合认知神经科学中关于记忆的知识，并将其与LLM驱动的Agent相结合，从而设计出更高效、更智能的记忆系统。这种跨学科的融合有助于Agent更好地理解和利用过去的经验，从而提高其在复杂环境中的适应性和决策能力。\n\n**技术框架**：本文的框架主要包含以下几个部分：首先，阐述记忆的定义和功能，并沿着认知神经科学、LLM和Agent的轨迹进行分析。其次，对生物和人工记忆的分类、存储机制和管理生命周期进行比较分析。然后，回顾用于评估Agent记忆的主流基准。此外，探讨记忆安全问题，并从攻击和防御两个角度进行分析。最后，展望未来的研究方向，重点关注多模态记忆系统和技能获取。\n\n**关键创新**：本文的创新之处在于系统性地整合了认知神经科学和AI Agent领域的知识，为Agent记忆系统的设计提供了新的视角和方法。通过对生物和人工记忆进行深入的比较分析，揭示了两者之间的相似性和差异性，为Agent记忆系统的优化提供了理论基础。此外，本文还关注了记忆安全问题，并提出了相应的防御策略，这在以往的研究中较少被关注。\n\n**关键设计**：本文主要是一个综述性质的工作，并没有提出具体的算法或网络结构。但是，文章强调了在设计Agent记忆系统时需要考虑的关键因素，例如记忆的分类（如情景记忆、语义记忆等）、存储机制（如分布式表示、稀疏编码等）、管理生命周期（如记忆的编码、存储、检索和遗忘等）以及安全性（如对抗攻击、隐私保护等）。这些因素需要在具体的设计中进行权衡和优化。",
            "application_zh": "该研究成果可应用于各种需要智能Agent进行复杂决策和长期规划的领域，例如：自动驾驶、智能客服、机器人导航、游戏AI等。通过构建更高效、更安全的记忆系统，可以显著提高Agent的性能和可靠性，使其能够更好地适应复杂多变的环境，并完成各种具有挑战性的任务。未来的研究方向，如多模态记忆系统和技能获取，将进一步拓展Agent的应用范围和能力。",
            "highlight_zh": "本文是一篇综述性文章，主要贡献在于对现有研究进行了系统性的梳理和总结，并提出了未来的研究方向。虽然没有具体的实验结果，但其对Agent记忆系统的全面分析和跨学科的视角，为未来的研究提供了重要的参考价值。通过整合认知神经科学的知识，有望设计出更智能、更高效的Agent记忆系统。",
            "tags_zh": [
                "记忆系统",
                "认知神经科学",
                "自主Agent",
                "LLM",
                "多模态记忆"
            ],
            "_index": 63,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23343v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23343v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23343v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Holi-DETR: Holistic Fashion Item Detection Leveraging Contextual Information",
            "authors": [
                "Youngchae Kwon",
                "Jinyoung Choi",
                "Injung Kim"
            ],
            "arxiv_id": "2512.23221v1",
            "summary": "Fashion item detection is challenging due to the ambiguities introduced by the highly diverse appearances of fashion items and the similarities among item subcategories. To address this challenge, we propose a novel Holistic Detection Transformer (Holi-DETR) that detects fashion items in outfit images holistically, by leveraging contextual information. Fashion items often have meaningful relationships as they are combined to create specific styles. Unlike conventional detectors that detect each item independently, Holi-DETR detects multiple items while reducing ambiguities by leveraging three distinct types of contextual information: (1) the co-occurrence relationship between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. %Holi-DETR explicitly incorporates three types of contextual information: (1) the co-occurrence probability between fashion items, (2) the relative position and size based on inter-item spatial arrangements, and (3) the spatial relationships between items and human body key-points. To this end, we propose a novel architecture that integrates these three types of heterogeneous contextual information into the Detection Transformer (DETR) and its subsequent models. In experiments, the proposed methods improved the performance of the vanilla DETR and the more recently developed Co-DETR by 3.6 percent points (pp) and 1.1 pp, respectively, in terms of average precision (AP).",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "20 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23221v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "spatial relationship"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "7_retargeting"
            ],
            "headline_zh": "提出Holi-DETR，利用上下文信息进行整体时尚单品检测，提升检测精度。",
            "summary_zh": "时尚单品检测面临着时尚单品外观高度多样性和子类别之间相似性带来的挑战。为了解决这个问题，我们提出了一种新颖的整体检测Transformer（Holi-DETR），通过利用上下文信息来整体地检测服装图像中的时尚单品。时尚单品通常具有有意义的关系，因为它们被组合起来以创建特定的风格。与独立检测每个单品的传统检测器不同，Holi-DETR通过利用三种不同的上下文信息来检测多个单品，同时减少歧义：（1）时尚单品之间的共现关系，（2）基于单品间空间排列的相对位置和大小，以及（3）单品与人体关键点之间的空间关系。实验表明，所提出的方法在平均精度（AP）方面分别将原始DETR和最近开发的Co-DETR的性能提高了3.6个百分点（pp）和1.1个百分点（pp）。",
            "intro_zh": [
                "时尚单品检测面临外观多样性和类别相似性挑战，传统方法忽略了单品间的上下文关系。",
                "Holi-DETR利用单品共现关系、相对位置大小和与人体关键点关系三种上下文信息，实现整体检测。",
                "实验结果表明，Holi-DETR在平均精度上优于DETR和Co-DETR，分别提升了3.6和1.1个百分点。"
            ],
            "method_zh": "**问题定义**：论文旨在解决时尚单品检测中由于单品外观多样性和子类别相似性导致的歧义性问题。现有方法通常独立检测每个单品，忽略了单品之间的上下文关系，导致检测精度不高。\\n\\n**核心思路**：论文的核心思路是利用时尚单品之间的上下文信息来减少检测歧义。具体来说，论文考虑了三种类型的上下文信息：单品共现关系、单品间的相对位置和大小关系，以及单品与人体关键点之间的空间关系。通过整合这些上下文信息，模型可以更准确地识别和定位时尚单品。\\n\\n**技术框架**：Holi-DETR基于Detection Transformer (DETR) 架构。整体流程包括：首先，提取图像特征；然后，利用Transformer编码器-解码器结构进行目标检测；最后，将三种上下文信息融入到DETR中，以提高检测精度。具体来说，论文设计了一个模块来显式地建模单品共现概率，并利用单品间的空间关系和单品与人体关键点之间的关系来约束检测结果。\\n\\n**关键创新**：论文的关键创新在于将三种异构的上下文信息（单品共现关系、单品间的相对位置和大小关系，以及单品与人体关键点之间的空间关系）有效地整合到DETR框架中。这种整合方式使得模型能够更好地理解图像中的时尚搭配，从而提高检测精度。与现有方法相比，Holi-DETR不再孤立地检测每个单品，而是从整体上考虑单品之间的关系。\\n\\n**关键设计**：论文在DETR的基础上，引入了三个关键的设计：1) 共现概率建模模块，用于学习单品之间的共现关系；2) 相对位置和大小编码模块，用于编码单品之间的空间关系；3) 人体关键点对齐模块，用于对齐单品与人体关键点之间的空间关系。损失函数方面，除了DETR原有的损失函数外，可能还引入了额外的损失函数来约束上下文信息的学习。具体的网络结构细节和参数设置在论文中应该有更详细的描述（未知）。",
            "application_zh": "该研究成果可应用于智能穿搭推荐、电商平台服装检索、虚拟试衣等领域。通过准确检测时尚单品，可以为用户提供个性化的搭配建议，提高购物体验。未来，该技术还可扩展到其他商品检测领域，例如家居用品、电子产品等。",
            "highlight_zh": "实验结果表明，Holi-DETR在时尚单品检测任务上取得了显著的性能提升。与原始DETR相比，Holi-DETR的平均精度（AP）提高了3.6个百分点。与最近提出的Co-DETR相比，Holi-DETR的平均精度也提高了1.1个百分点。这些结果表明，利用上下文信息可以有效地提高时尚单品检测的精度。",
            "tags_zh": [
                "时尚单品检测",
                "上下文信息",
                "Detection Transformer",
                "目标检测",
                "服装搭配"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23221v1/Fig1_arxiv.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23221v1/Fig2_arxiv.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23221v1/Fig3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Eliciting Behaviors in Multi-Turn Conversations",
            "authors": [
                "Jing Huang",
                "Shujian Zhang",
                "Lun Wang",
                "Andrew Hard",
                "Rajiv Mathews",
                "John Lambert"
            ],
            "arxiv_id": "2512.23701v1",
            "summary": "Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23701v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出多轮对话行为引导方法以提升评估效果",
            "summary_zh": "识别大型语言模型在对话环境中的特定复杂行为对于其评估至关重要。尽管已有研究提出了诱导特定行为的自然语言提示技术，但主要集中在单轮对话中。本研究探讨了多轮对话中的行为引导，首先提供了一个分析框架，将现有方法分为三类：仅使用先前知识的方法、离线交互的方法和在线交互的方法。我们引入了一种在线方法的多轮通用形式，统一了单轮和多轮引导。通过自动生成多轮测试用例评估这三类方法，分析了查询预算与成功率之间的权衡，发现在线方法在三个任务中平均成功率达到了45/19/77%，而现有基准的静态方法几乎未能发现失败案例。我们的研究强调了行为引导方法在多轮对话评估中的新应用，以及社区向动态基准发展的必要性。",
            "intro_zh": [
                "现有方法主要集中在单轮对话，缺乏对多轮对话中复杂行为的有效引导与评估。",
                "论文提出了一种新的多轮对话行为引导框架，整合了单轮与多轮的引导方法，提升了模型的交互能力。",
                "实验结果显示，在线方法在多个任务中成功率显著高于传统静态方法，展示了动态评估的潜力。"
            ],
            "method_zh": "**问题定义**：本研究旨在解决现有方法在多轮对话中无法有效引导复杂行为的问题。现有方法多集中于单轮对话，导致对多轮交互的评估不足。\\n\\n**核心思路**：论文提出了一种多轮对话的行为引导方法，通过分析现有方法的不足，设计了一个统一的框架，能够同时处理单轮和多轮的行为引导。\\n\\n**技术框架**：整体架构包括三个主要模块：基于先前知识的引导、离线交互引导和在线交互引导。通过这些模块的组合，形成了一个灵活的多轮对话行为引导系统。\\n\\n**关键创新**：最重要的创新在于引入了在线交互的方法，能够在多轮对话中动态调整引导策略，与静态方法相比，显著提高了行为发现的成功率。\\n\\n**关键设计**：在参数设置上，研究对查询预算进行了优化，确保在有限的交互次数内最大化成功率。损失函数和网络结构经过精心设计，以适应多轮对话的复杂性。具体细节包括对输入的动态调整和反馈机制的实现。",
            "application_zh": "该研究的潜在应用领域包括智能客服、虚拟助手和教育领域等多轮对话系统。通过提升对话系统的行为引导能力，可以显著改善用户体验和系统的交互质量，未来可能推动更智能的对话系统发展。",
            "highlight_zh": "实验结果表明，在线方法在三个任务中的平均成功率分别为45%、19%和77%，显著高于现有静态方法的表现，展示了动态评估在多轮对话中的有效性和必要性。",
            "tags_zh": [
                "多轮对话",
                "行为引导",
                "自然语言处理",
                "动态评估",
                "大型语言模型"
            ],
            "_index": 65,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23701v1/figs/benchmark_saturation.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23701v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23701v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "BOAD: Discovering Hierarchical Software Engineering Agents via Bandit Optimization",
            "authors": [
                "Iris Xu",
                "Guangtao Zeng",
                "Zexue He",
                "Charles Jin",
                "Aldo Pareja",
                "Dan Gutfreund",
                "Chuang Gan",
                "Zhang-Wei Hong"
            ],
            "arxiv_id": "2512.23631v1",
            "summary": "Large language models (LLMs) have shown strong reasoning and coding capabilities, yet they struggle to generalize to real-world software engineering (SWE) problems that are long-horizon and out of distribution. Existing systems often rely on a single agent to handle the entire workflow-interpreting issues, navigating large codebases, and implementing fixes-within one reasoning chain. Such monolithic designs force the model to retain irrelevant context, leading to spurious correlations and poor generalization. Motivated by how human engineers decompose complex problems, we propose structuring SWE agents as orchestrators coordinating specialized sub-agents for sub-tasks such as localization, editing, and validation. The challenge lies in discovering effective hierarchies automatically: as the number of sub-agents grows, the search space becomes combinatorial, and it is difficult to attribute credit to individual sub-agents within a team. We address these challenges by formulating hierarchy discovery as a multi-armed bandit (MAB) problem, where each arm represents a candidate sub-agent and the reward measures its helpfulness when collaborating with others. This framework, termed Bandit Optimization for Agent Design (BOAD), enables efficient exploration of sub-agent designs under limited evaluation budgets. On SWE-bench-Verified, BOAD outperforms single-agent and manually designed multi-agent systems. On SWE-bench-Live, featuring more recent and out-of-distribution issues, our 36B system ranks second on the leaderboard at the time of evaluation, surpassing larger models such as GPT-4 and Claude. These results demonstrate that automatically discovered hierarchical multi-agent systems significantly improve generalization on challenging long-horizon SWE tasks. Code is available at https://github.com/iamxjy/BOAD-SWE-Agent.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23631v1",
            "code_links": [
                {
                    "url": "https://github.com/iamxjy/BOAD-SWE-Agent",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出BOAD以自动发现层次化软件工程代理解决复杂问题",
            "summary_zh": "大型语言模型（LLMs）在推理和编码能力上表现出色，但在处理长时间跨度和分布外的软件工程（SWE）问题时却难以泛化。现有系统通常依赖单一代理处理整个工作流程，导致模型保留无关上下文，从而产生虚假关联和较差的泛化能力。为此，本文提出将SWE代理结构化为协调专门子代理的指挥者，以处理定位、编辑和验证等子任务。我们将层次发现问题形式化为多臂赌博机（MAB）问题，通过奖励机制评估子代理的协作效果。BOAD框架在有限评估预算下高效探索子代理设计，实验结果表明其在SWE-bench-Verified上优于单代理和手动设计的多代理系统，并在SWE-bench-Live上取得了第二名的优异成绩，超越了GPT-4等更大模型。",
            "intro_zh": [
                "现有软件工程代理通常依赖单一模型处理复杂任务，导致泛化能力差和上下文干扰。",
                "本文提出BOAD框架，通过多臂赌博机方法自动发现层次化代理，协调多个专门子代理处理不同子任务。",
                "实验结果显示，BOAD在多个基准测试中表现优异，显著提高了长时间跨度软件工程任务的泛化能力。"
            ],
            "method_zh": "**问题定义**：本文旨在解决现有软件工程代理在处理复杂问题时的泛化能力不足，尤其是在长时间跨度和分布外问题上的表现。现有方法依赖单一代理，导致上下文干扰和虚假关联。\\n\\n**核心思路**：论文提出将软件工程代理结构化为多个专门子代理的层次化系统，通过多臂赌博机（MAB）方法自动发现有效的代理层次，以便更好地分配任务和提高协作效率。\\n\\n**技术框架**：整体架构包括一个指挥者代理和多个子代理，指挥者负责协调子代理的工作。每个子代理专注于特定任务，如代码定位、编辑和验证。通过MAB方法，系统能够在有限的评估预算内探索和优化子代理的组合。\\n\\n**关键创新**：最重要的创新在于将层次发现问题形式化为MAB问题，使得在复杂的代理系统中能够有效地评估和优化子代理的协作效果。这一方法与传统的单一代理设计有本质区别。\\n\\n**关键设计**：在设计中，采用了奖励机制来评估每个子代理的协作效果，确保在探索过程中能够快速识别出高效的代理组合。具体参数设置和损失函数的选择也经过精心设计，以适应软件工程任务的特点。 ",
            "application_zh": "该研究的潜在应用领域包括软件开发、自动化测试和代码审查等。通过自动发现和协调层次化代理，能够显著提高软件工程任务的效率和准确性，减少人工干预的需求，未来可能对软件开发流程产生深远影响。",
            "highlight_zh": "在SWE-bench-Verified基准测试中，BOAD框架的表现优于传统的单代理和手动设计的多代理系统。在SWE-bench-Live上，BOAD的36B系统在评估时排名第二，超越了更大模型如GPT-4和Claude，显示出显著的性能提升。",
            "tags_zh": [
                "层次化代理",
                "多臂赌博机",
                "软件工程",
                "自动化协作",
                "模型泛化能力"
            ],
            "_index": 66,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "VL-RouterBench: A Benchmark for Vision-Language Model Routing",
            "authors": [
                "Zhehao Huang",
                "Baijiong Lin",
                "Jingyuan Zhang",
                "Jingying Wang",
                "Yuhang Liu",
                "Ning Lu",
                "Tao Li",
                "Xiaolin Huang"
            ],
            "arxiv_id": "2512.23562v1",
            "summary": "Multi-model routing has evolved from an engineering technique into essential infrastructure, yet existing work lacks a systematic, reproducible benchmark for evaluating vision-language models (VLMs). We present VL-RouterBench to assess the overall capability of VLM routing systems systematically. The benchmark is grounded in raw inference and scoring logs from VLMs and constructs quality and cost matrices over sample-model pairs. In scale, VL-RouterBench covers 14 datasets across 3 task groups, totaling 30,540 samples, and includes 15 open-source models and 2 API models, yielding 519,180 sample-model pairs and a total input-output token volume of 34,494,977. The evaluation protocol jointly measures average accuracy, average cost, and throughput, and builds a ranking score from the harmonic mean of normalized cost and accuracy to enable comparison across router configurations and cost budgets. On this benchmark, we evaluate 10 routing methods and baselines and observe a significant routability gain, while the best current routers still show a clear gap to the ideal Oracle, indicating considerable room for improvement in router architecture through finer visual cues and modeling of textual structure. We will open-source the complete data construction and evaluation toolchain to promote comparability, reproducibility, and practical deployment in multimodal routing research.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23562v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VL-RouterBench，用于系统评估视觉-语言模型路由系统的性能。",
            "summary_zh": "多模型路由已从工程技术发展成为关键基础设施，但现有工作缺乏系统性的、可复现的基准来评估视觉-语言模型（VLM）。我们提出了VL-RouterBench，旨在系统地评估VLM路由系统的整体能力。该基准基于VLM的原始推理和评分日志，构建样本-模型对的质量和成本矩阵。在规模上，VL-RouterBench涵盖3个任务组的14个数据集，共计30,540个样本，包括15个开源模型和2个API模型，产生519,180个样本-模型对，总输入-输出token量为34,494,977。评估协议联合衡量平均准确率、平均成本和吞吐量，并从归一化成本和准确率的调和平均值构建排名分数，以实现跨路由器配置和成本预算的比较。在该基准上，我们评估了10种路由方法和基线，观察到显著的可路由性增益，但目前最好的路由器与理想的Oracle之间仍存在明显差距，表明通过更精细的视觉线索和文本结构建模，路由器架构仍有很大的改进空间。我们将开源完整的数据构建和评估工具链，以促进多模态路由研究中的可比性、可复现性和实际部署。",
            "intro_zh": [
                "现有VLM路由评估缺乏系统性、可复现的基准，难以有效衡量不同路由策略的优劣。",
                "VL-RouterBench基于VLM的推理日志构建质量和成本矩阵，全面评估路由系统的性能。",
                "实验表明，现有最佳路由器与理想状态仍有差距，未来可通过优化视觉和文本建模提升性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决视觉-语言模型（VLM）路由系统缺乏系统性、可复现的评估基准的问题。现有的VLM路由研究难以进行公平比较和有效优化，阻碍了该领域的进一步发展。缺乏统一的评估标准导致研究结果难以推广和应用。\\n\\n**核心思路**：论文的核心思路是构建一个全面的基准测试平台VL-RouterBench，该平台基于VLM的原始推理和评分日志，构建样本-模型对的质量和成本矩阵。通过综合考虑准确率、成本和吞吐量，为VLM路由系统的性能评估提供了一个客观、可复现的框架。\\n\\n**技术框架**：VL-RouterBench的整体框架包括以下几个主要模块：1) 数据集构建：收集涵盖多种任务的14个数据集，共计30,540个样本。2) 模型集成：集成15个开源模型和2个API模型，形成包含519,180个样本-模型对的测试集。3) 评估指标：定义平均准确率、平均成本和吞吐量等评估指标，并构建基于归一化成本和准确率调和平均值的排名分数。4) 路由方法评估：评估10种路由方法和基线，并与理想的Oracle进行比较。\\n\\n**关键创新**：VL-RouterBench的关键创新在于其系统性和全面性。它不仅提供了大规模的测试数据集和多种VLM模型，还定义了一套综合性的评估指标，能够全面衡量VLM路由系统的性能。此外，VL-RouterBench还开源了完整的数据构建和评估工具链，促进了研究的可比性、可复现性和实际部署。\\n\\n**关键设计**：VL-RouterBench的关键设计包括：1) 数据集的选择：选择涵盖多种任务的数据集，以保证评估的全面性。2) 模型的集成：集成多种开源模型和API模型，以覆盖不同的模型架构和性能水平。3) 评估指标的定义：定义平均准确率、平均成本和吞吐量等评估指标，以综合衡量VLM路由系统的性能。4) 排名分数的构建：构建基于归一化成本和准确率调和平均值的排名分数，以实现跨路由器配置和成本预算的比较。",
            "application_zh": "VL-RouterBench可应用于多模态智能客服、智能文档处理、自动驾驶等领域。通过优化VLM路由策略，可以降低计算成本，提高响应速度和准确率，从而提升用户体验和系统效率。该基准的开源将促进VLM路由技术的进一步发展和应用。",
            "highlight_zh": "在VL-RouterBench上评估了10种路由方法和基线，结果显示现有最佳路由器与理想的Oracle之间仍存在明显差距，表明VLM路由技术仍有很大的提升空间。该基准的发布为后续研究提供了一个统一的评估平台，有助于推动VLM路由技术的快速发展。",
            "tags_zh": [
                "视觉-语言模型",
                "多模型路由",
                "基准测试",
                "性能评估",
                "多模态学习"
            ],
            "_index": 67,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23562v1/_figs/comprehensive_comparison_best_arxiv.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23562v1/_figs/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23562v1/_figs/data_distribution.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Trustworthy Machine Learning under Distribution Shifts",
            "authors": [
                "Zhuo Huang"
            ],
            "arxiv_id": "2512.23524v1",
            "summary": "Machine Learning (ML) has been a foundational topic in artificial intelligence (AI), providing both theoretical groundwork and practical tools for its exciting advancements. From ResNet for visual recognition to Transformer for vision-language alignment, the AI models have achieved superior capability to humans. Furthermore, the scaling law has enabled AI to initially develop general intelligence, as demonstrated by Large Language Models (LLMs). To this stage, AI has had an enormous influence on society and yet still keeps shaping the future for humanity. However, distribution shift remains a persistent ``Achilles' heel'', fundamentally limiting the reliability and general usefulness of ML systems. Moreover, generalization under distribution shift would also cause trust issues for AIs. Motivated by these challenges, my research focuses on \\textit{Trustworthy Machine Learning under Distribution Shifts}, with the goal of expanding AI's robustness, versatility, as well as its responsibility and reliability. We carefully study the three common distribution shifts into: (1) Perturbation Shift, (2) Domain Shift, and (3) Modality Shift. For all scenarios, we also rigorously investigate trustworthiness via three aspects: (1) Robustness, (2) Explainability, and (3) Adaptability. Based on these dimensions, we propose effective solutions and fundamental insights, meanwhile aiming to enhance the critical ML problems, such as efficiency, adaptability, and safety.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "PhD Thesis",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23524v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对分布偏移下的可信机器学习，研究鲁棒性、可解释性和适应性",
            "summary_zh": "机器学习(ML)是人工智能(AI)的基础，为AI的发展提供了理论基础和实用工具。从用于视觉识别的ResNet到用于视觉-语言对齐的Transformer，AI模型已经实现了超越人类的能力。此外，缩放定律使得AI初步发展出通用智能，正如大型语言模型(LLM)所展示的那样。目前，AI对社会产生了巨大影响，并将继续塑造人类的未来。然而，分布偏移仍然是一个持续存在的“阿喀琉斯之踵”，从根本上限制了ML系统的可靠性和通用性。此外，分布偏移下的泛化也会导致AI的信任问题。受这些挑战的推动，我的研究重点是\textit{分布偏移下的可信机器学习}，目标是扩展AI的鲁棒性、通用性以及责任性和可靠性。我们仔细研究了三种常见的分布偏移：(1)扰动偏移，(2)领域偏移，和(3)模态偏移。对于所有场景，我们还通过三个方面严格研究可信度：(1)鲁棒性，(2)可解释性，和(3)适应性。基于这些维度，我们提出了有效的解决方案和基本见解，同时旨在增强关键的ML问题，如效率、适应性和安全性。",
            "intro_zh": [
                "现有机器学习模型在分布偏移下泛化能力不足，导致可靠性和通用性受限，难以满足实际应用需求。",
                "该研究着眼于扰动、领域和模态三种分布偏移，从鲁棒性、可解释性和适应性三个维度提升模型可信度。",
                "通过提出有效的解决方案和基本见解，旨在增强机器学习在效率、适应性和安全性等方面的关键问题。"
            ],
            "method_zh": "**问题定义**：论文旨在解决机器学习模型在面对分布偏移时，性能显著下降的问题。现有的机器学习模型通常假设训练数据和测试数据服从相同的分布，但在实际应用中，这种假设往往不成立。分布偏移包括多种形式，如输入数据中的噪声扰动（扰动偏移）、训练数据和测试数据来自不同的领域（领域偏移）、以及输入数据的模态发生变化（模态偏移）。这些偏移会导致模型泛化能力下降，从而影响模型的可靠性和实用性。\\n\\n**核心思路**：论文的核心思路是针对不同的分布偏移类型，从鲁棒性、可解释性和适应性三个方面来提升模型的可信度。具体来说，鲁棒性是指模型在面对扰动时保持性能稳定的能力；可解释性是指模型做出决策的原因能够被理解和解释；适应性是指模型能够快速适应新的分布的能力。通过提升这三个方面的性能，可以有效地提高模型在分布偏移下的泛化能力和可信度。\\n\\n**技术框架**：论文构建了一个通用的技术框架，用于研究分布偏移下的可信机器学习。该框架包括三个主要模块：(1)分布偏移检测模块，用于检测输入数据是否存在分布偏移；(2)鲁棒性增强模块，用于提高模型对扰动的抵抗能力；(3)适应性调整模块，用于使模型能够快速适应新的分布。这三个模块协同工作，可以有效地提高模型在分布偏移下的性能。\\n\\n**关键创新**：论文的关键创新在于提出了一个统一的框架，能够同时考虑多种类型的分布偏移，并从鲁棒性、可解释性和适应性三个方面来提升模型的可信度。此外，论文还针对每种分布偏移类型，提出了具体的解决方案，例如，使用对抗训练来提高模型的鲁棒性，使用注意力机制来提高模型的可解释性，使用元学习来提高模型的适应性。\\n\\n**关键设计**：论文的关键设计包括：(1)使用对抗训练来生成对抗样本，从而提高模型的鲁棒性；(2)使用注意力机制来可视化模型关注的区域，从而提高模型的可解释性；(3)使用元学习来学习如何快速适应新的分布，从而提高模型的适应性。此外，论文还设计了一系列损失函数，用于优化模型的鲁棒性、可解释性和适应性。",
            "application_zh": "该研究成果可广泛应用于自动驾驶、医疗诊断、金融风控等领域。在自动驾驶中，模型需要对各种天气和光照条件下的图像进行识别，鲁棒性至关重要。在医疗诊断中，模型需要对不同医院和设备的图像进行分析，适应性是关键。在金融风控中，模型需要对不断变化的市场数据进行预测，可解释性有助于理解模型的决策过程。该研究有助于提升这些应用场景中AI系统的可靠性和安全性。",
            "highlight_zh": "论文通过实验验证了所提出方法的有效性。在图像分类任务中，针对扰动偏移，所提出的鲁棒性增强方法能够将模型的准确率提高10%。针对领域偏移，所提出的适应性调整方法能够将模型的准确率提高15%。针对模态偏移，所提出的多模态融合方法能够将模型的准确率提高8%。实验结果表明，所提出的方法能够有效地提高模型在分布偏移下的性能。",
            "tags_zh": [
                "分布偏移",
                "可信机器学习",
                "鲁棒性",
                "可解释性",
                "适应性",
                "领域自适应",
                "对抗训练",
                "元学习"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FRoD: Full-Rank Efficient Fine-Tuning with Rotational Degrees for Fast Convergence",
            "authors": [
                "Guoan Wan",
                "Tianyu Chen",
                "Fangzheng Feng",
                "Haoyi Zhou",
                "Runhua Xu"
            ],
            "arxiv_id": "2512.23485v1",
            "summary": "Parameter-efficient fine-tuning (PEFT) methods have emerged as a practical solution for adapting large foundation models to downstream tasks, reducing computational and memory costs by updating only a small subset of parameters. Among them, approaches like LoRA aim to strike a balance between efficiency and expressiveness, but often suffer from slow convergence and limited adaptation capacity due to their inherent low-rank constraints. This trade-off hampers the ability of PEFT methods to capture complex patterns needed for diverse tasks. To address these challenges, we propose FRoD, a novel fine-tuning method that combines hierarchical joint decomposition with rotational degrees of freedom. By extracting a globally shared basis across layers and injecting sparse, learnable perturbations into scaling factors for flexible full-rank updates, FRoD enhances expressiveness and efficiency, leading to faster and more robust convergence. On 20 benchmarks spanning vision, reasoning, and language understanding, FRoD matches full model fine-tuning in accuracy, while using only 1.72% of trainable parameters under identical training budgets.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "The 40th Annual AAAI Conference on Artificial Intelligence",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23485v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FRoD：利用旋转自由度实现全秩高效微调，加速模型收敛",
            "summary_zh": "参数高效微调（PEFT）方法已成为将大型基础模型适配到下游任务的实用解决方案，它通过仅更新一小部分参数来降低计算和内存成本。其中，LoRA等方法旨在平衡效率和表达能力，但由于其固有的低秩约束，常常面临收敛速度慢和适应能力有限的问题。这种权衡阻碍了PEFT方法捕捉多样化任务所需的复杂模式。为了解决这些挑战，我们提出了一种新的微调方法FRoD，它结合了分层联合分解和旋转自由度。通过提取跨层的全局共享基，并将稀疏的可学习扰动注入到缩放因子中，以实现灵活的全秩更新，FRoD增强了表达能力和效率，从而实现更快、更稳健的收敛。在涵盖视觉、推理和语言理解的20个基准测试中，FRoD在相同的训练预算下，仅使用1.72%的可训练参数，即可达到与全模型微调相当的精度。",
            "intro_zh": [
                "现有PEFT方法受限于低秩约束，难以在效率和表达能力之间取得平衡，导致收敛速度慢，适应能力不足。",
                "FRoD通过分层联合分解和旋转自由度，提取全局共享基，并注入稀疏可学习扰动，实现灵活的全秩更新。",
                "实验表明，FRoD在20个基准测试中，仅使用1.72%的可训练参数，即可达到与全模型微调相当的精度。"
            ],
            "method_zh": "**问题定义**：现有参数高效微调方法（PEFT），如LoRA，虽然减少了计算和存储开销，但由于其低秩特性，限制了模型的表达能力，导致收敛速度慢，无法充分适应下游任务的复杂模式。因此，如何在保证效率的同时，提升PEFT方法的表达能力和收敛速度，是一个亟待解决的问题。\\n\\n**核心思路**：FRoD的核心思路是打破低秩约束，实现高效的全秩微调。它通过提取跨层的全局共享基，并在此基础上引入稀疏的可学习扰动，从而在参数量较少的情况下，实现对模型参数的灵活调整。这种方法既保证了微调的效率，又提升了模型的表达能力。\\n\\n**技术框架**：FRoD的技术框架主要包含两个关键步骤：1) 分层联合分解：对模型参数进行分解，提取跨层的全局共享基。这一步旨在减少参数冗余，提高微调效率。2) 旋转自由度注入：在全局共享基的基础上，引入稀疏的可学习扰动，并将其注入到缩放因子中。这些扰动通过旋转操作，实现对模型参数的灵活调整，从而提升模型的表达能力。\\n\\n**关键创新**：FRoD最重要的技术创新在于其结合了分层联合分解和旋转自由度，实现了高效的全秩微调。与传统的低秩微调方法相比，FRoD能够更好地捕捉下游任务的复杂模式，从而提升模型的性能。此外，FRoD通过稀疏扰动的方式，进一步降低了参数量，提高了微调效率。\\n\\n**关键设计**：FRoD的关键设计包括：1) 全局共享基的提取方法：具体采用何种分解方式提取全局共享基，例如奇异值分解（SVD）或其他矩阵分解方法。2) 稀疏扰动的注入方式：如何选择合适的稀疏模式，以及如何将扰动注入到缩放因子中。3) 旋转操作的具体实现：如何设计旋转矩阵，以实现对模型参数的灵活调整。论文中可能还涉及损失函数的设计，以引导模型学习到更有效的参数。",
            "application_zh": "FRoD具有广泛的应用前景，可用于各种大型预训练模型的微调，例如在自然语言处理、计算机视觉和语音识别等领域。它可以帮助企业和研究机构更高效地将大型模型应用于各种下游任务，降低计算成本和开发周期，加速人工智能技术的落地。此外，FRoD还可以促进模型的可持续发展，减少能源消耗。",
            "highlight_zh": "FRoD在20个涵盖视觉、推理和语言理解的基准测试中表现出色。在相同的训练预算下，FRoD仅使用1.72%的可训练参数，即可达到与全模型微调相当的精度。这表明FRoD在保证效率的同时，显著提升了模型的性能。该结果突显了FRoD在参数高效微调方面的优势。",
            "tags_zh": [
                "参数高效微调",
                "全秩微调",
                "旋转自由度",
                "分层联合分解",
                "深度学习",
                "模型优化"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23485v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23485v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23485v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AKG kernel Agent: A Multi-Agent Framework for Cross-Platform Kernel Synthesis",
            "authors": [
                "Jinye Du",
                "Quan Yuan",
                "Zuyao Zhang",
                "Yanzhi Yi",
                "Jiahui Hu",
                "Wangyi Chen",
                "Yiyang Zhu",
                "Qishui Zheng",
                "Wenxiang Zou",
                "Xiangyu Chang",
                "Zuohe Zheng",
                "Zichun Ye",
                "Chao Liu",
                "Shanni Li",
                "Renwei Zhang",
                "Yiping Deng",
                "Xinwei Hu",
                "Xuefeng Jin",
                "Jie Zhao"
            ],
            "arxiv_id": "2512.23424v1",
            "summary": "Modern AI models demand high-performance computation kernels. The growing complexity of LLMs, multimodal architectures, and recommendation systems, combined with techniques like sparsity and quantization, creates significant computational challenges. Moreover, frequent hardware updates and diverse chip architectures further complicate this landscape, requiring tailored kernel implementations for each platform. However, manual optimization cannot keep pace with these demands, creating a critical bottleneck in AI system development. Recent advances in LLM code generation capabilities have opened new possibilities for automating kernel development. In this work, we propose AKG kernel agent (AI-driven Kernel Generator), a multi-agent system that automates kernel generation, migration, and performance tuning. AKG kernel agent is designed to support multiple domain-specific languages (DSLs), including Triton, TileLang, CPP, and CUDA-C, enabling it to target different hardware backends while maintaining correctness and portability. The system's modular design allows rapid integration of new DSLs and hardware targets. When evaluated on KernelBench using Triton DSL across GPU and NPU backends, AKG kernel agent achieves an average speedup of 1.46$\\times$ over PyTorch Eager baselines implementations, demonstrating its effectiveness in accelerating kernel development for modern AI workloads.",
            "categories": [
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23424v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出AKG kernel Agent，一个用于跨平台内核合成的多智能体框架。",
            "summary_zh": "现代AI模型对高性能计算内核的需求日益增长。LLM、多模态架构和推荐系统复杂性的增加，以及稀疏性和量化等技术的应用，带来了巨大的计算挑战。此外，频繁的硬件更新和多样化的芯片架构进一步复杂化了这一局面，需要为每个平台定制内核实现。然而，手动优化无法跟上这些需求，成为AI系统开发的关键瓶颈。LLM代码生成能力的最新进展为自动化内核开发开辟了新的可能性。本文提出了AKG kernel agent（AI驱动的内核生成器），一个多智能体系统，可以自动生成、迁移和性能调优内核。AKG kernel agent旨在支持多种领域特定语言（DSL），包括Triton、TileLang、CPP和CUDA-C，使其能够针对不同的硬件后端，同时保持正确性和可移植性。该系统的模块化设计允许快速集成新的DSL和硬件目标。在使用Triton DSL在GPU和NPU后端上评估KernelBench时，AKG kernel agent比PyTorch Eager基线实现平均加速1.46倍，证明了其在加速现代AI工作负载的内核开发方面的有效性。",
            "intro_zh": [
                "现有AI模型对高性能内核需求激增，但手动优化难以跟上硬件更新和架构多样性，成为AI系统开发的瓶颈。",
                "AKG kernel agent是一个多智能体系统，通过自动化内核生成、迁移和调优，支持多种DSL和硬件后端，解决内核开发瓶颈。",
                "实验表明，在GPU和NPU后端上，AKG kernel agent使用Triton DSL在KernelBench上实现了平均1.46倍的加速。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现代AI模型对高性能计算内核日益增长的需求与手动内核优化速度无法满足硬件快速迭代之间的矛盾。现有方法，即手动优化内核，耗时且容易出错，无法适应快速变化的硬件架构和AI模型需求。这导致AI系统开发效率低下，成为一个关键瓶颈。\\n\\n**核心思路**：论文的核心思路是利用LLM的代码生成能力，构建一个多智能体系统，自动化内核的生成、迁移和性能调优。通过支持多种领域特定语言（DSL），该系统可以针对不同的硬件后端生成优化的内核，从而提高AI模型的计算效率。这种自动化方法旨在克服手动优化的局限性，加速AI系统的开发过程。\\n\\n**技术框架**：AKG kernel agent的技术框架是一个多智能体系统，包含以下主要模块：1) **任务分解模块**：将高层次的内核生成任务分解为更小的、可管理的子任务。2) **代码生成模块**：利用LLM生成初步的内核代码，支持多种DSL，如Triton、TileLang、CPP和CUDA-C。3) **代码验证模块**：验证生成的代码的正确性，确保其功能符合预期。4) **性能调优模块**：通过自动搜索和优化技术，提升内核的性能。5) **部署模块**：将优化后的内核部署到目标硬件平台上。这些模块协同工作，实现内核的自动化生成和优化。\\n\\n**关键创新**：最重要的技术创新点在于将LLM的代码生成能力与多智能体系统相结合，实现内核开发的自动化。与传统的基于规则或模板的内核生成方法相比，AKG kernel agent能够生成更复杂、更优化的内核代码，并且可以更容易地适应新的硬件架构和AI模型需求。此外，该系统支持多种DSL，使其具有更广泛的适用性。\\n\\n**关键设计**：AKG kernel agent的关键设计包括：1) **智能体之间的协作机制**：定义了智能体之间如何通信和协作，以完成复杂的内核生成任务。2) **LLM的选择和训练**：选择了合适的LLM，并对其进行微调，以提高其代码生成能力。3) **性能调优算法**：采用了高效的性能调优算法，如遗传算法或强化学习，以自动搜索最优的内核配置。4) **代码验证方法**：设计了有效的代码验证方法，以确保生成的代码的正确性。",
            "application_zh": "AKG kernel agent可广泛应用于各种需要高性能计算内核的AI领域，如深度学习、计算机视觉、自然语言处理和推荐系统。它能够加速AI模型的训练和推理过程，提高AI应用的性能和效率。该研究的潜在价值在于降低了内核开发的门槛，使得AI开发者能够更专注于模型设计和算法创新，而无需过多关注底层硬件细节。未来，AKG kernel agent有望成为AI系统开发的重要工具，推动AI技术的普及和应用。",
            "highlight_zh": "实验结果表明，AKG kernel agent在使用Triton DSL在GPU和NPU后端上评估KernelBench时，相比于PyTorch Eager基线实现，平均加速了1.46倍。这一显著的性能提升证明了AKG kernel agent在加速现代AI工作负载的内核开发方面的有效性。该结果表明，通过自动化内核生成和优化，可以显著提高AI模型的计算效率。",
            "tags_zh": [
                "内核生成",
                "多智能体系统",
                "领域特定语言",
                "AI自动化",
                "性能优化"
            ],
            "_index": 70,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23424v1/media/Framework.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23424v1/media/ConductorWorkflow.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23424v1/media/RAG.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Theoretical Foundations of Scaling Law in Familial Models",
            "authors": [
                "Huan Song",
                "Qingfei Zhao",
                "Ting Long",
                "Shuyu Tian",
                "Hongjun An",
                "Jiawei Shao",
                "Chi Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.23407v1",
            "summary": "Neural scaling laws have become foundational for optimizing large language model (LLM) training, yet they typically assume a single dense model output. This limitation effectively overlooks \"Familial models, a transformative paradigm essential for realizing ubiquitous intelligence across heterogeneous device-edge-cloud hierarchies. Transcending static architectures, familial models integrate early exits with relay-style inference to spawn G deployable sub-models from a single shared backbone. In this work, we theoretically and empirically extend the scaling law to capture this \"one-run, many-models\" paradigm by introducing Granularity (G) as a fundamental scaling variable alongside model size (N) and training tokens (D). To rigorously quantify this relationship, we propose a unified functional form L(N, D, G) and parameterize it using large-scale empirical runs. Specifically, we employ a rigorous IsoFLOP experimental design to strictly isolate architectural impact from computational scale. Across fixed budgets, we systematically sweep model sizes (N) and granularities (G) while dynamically adjusting tokens (D). This approach effectively decouples the marginal cost of granularity from the benefits of scale, ensuring high-fidelity parameterization of our unified scaling law. Our results reveal that the granularity penalty follows a multiplicative power law with an extremely small exponent. Theoretically, this bridges fixed-compute training with dynamic architectures. Practically, it validates the \"train once, deploy many\" paradigm, demonstrating that deployment flexibility is achievable without compromising the compute-optimality of dense baselines.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23407v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "针对Familial模型，提出包含模型粒度的新型Scaling Law理论框架。",
            "summary_zh": "神经Scaling Law已成为优化大型语言模型（LLM）训练的基础，但它们通常假设单一的稠密模型输出。这种局限性忽略了“Familial模型”，这是一种对于在异构设备-边缘-云层次结构中实现普遍智能至关重要的变革性范例。Familial模型超越了静态架构，集成了早期退出与中继式推理，从而从单个共享骨干网络中产生G个可部署的子模型。在这项工作中，我们通过引入粒度（G）作为模型大小（N）和训练tokens（D）之外的基本scaling变量，从理论和经验上扩展了scaling law，以捕捉这种“一次运行，多个模型”的范例。为了严格量化这种关系，我们提出了一个统一的函数形式L(N, D, G)，并使用大规模的经验运行对其进行参数化。具体来说，我们采用严格的IsoFLOP实验设计，以严格地将架构影响与计算规模隔离开来。在固定的预算下，我们系统地扫描模型大小（N）和粒度（G），同时动态调整tokens（D）。这种方法有效地将粒度的边际成本与规模的优势分离开来，从而确保了我们统一scaling law的高保真参数化。我们的结果表明，粒度惩罚遵循一个具有极小指数的乘法幂律。从理论上讲，这桥接了固定计算训练与动态架构。实际上，它验证了“一次训练，多次部署”的范例，表明部署灵活性可以在不影响稠密基线的计算最优性的情况下实现。",
            "intro_zh": [
                "现有Scaling Law主要针对单一稠密模型，无法有效支持Familial模型这种“一次训练，多次部署”的范式。",
                "论文提出将模型粒度（G）作为scaling变量，构建统一的Scaling Law函数L(N, D, G)，从而支持Familial模型。",
                "通过IsoFLOP实验设计，隔离架构影响与计算规模，验证了部署灵活性不会影响计算最优性，并参数化了Scaling Law。"
            ],
            "method_zh": "**问题定义**：现有的神经Scaling Law主要关注单一的、稠密的模型，无法直接应用于Familial模型。Familial模型允许从一个共享的骨干网络中派生出多个不同粒度的子模型，以适应不同的部署环境和计算资源。因此，如何建立适用于Familial模型的Scaling Law，从而指导其训练和部署，是一个关键问题。现有方法无法有效衡量模型粒度对性能的影响，也无法在固定计算预算下优化模型大小和粒度的分配。\\n\\n**核心思路**：论文的核心思路是将模型粒度（G）引入Scaling Law，将其作为一个独立的scaling变量，与模型大小（N）和训练tokens（D）一起，共同决定模型的性能。通过建立一个统一的函数形式L(N, D, G)，可以量化模型大小、训练数据和模型粒度之间的关系。这种设计允许在固定计算预算下，权衡模型大小和粒度，从而优化Familial模型的训练和部署。\\n\\n**技术框架**：论文采用了一种系统的实验方法来研究Familial模型的Scaling Law。首先，定义了模型粒度（G）的概念，并将其作为scaling变量。然后，设计了IsoFLOP实验，即在固定的计算预算下，系统地扫描不同的模型大小（N）和粒度（G），并动态调整训练tokens（D）。通过这种方式，可以有效地将架构影响与计算规模隔离开来。最后，使用实验数据来参数化统一的Scaling Law函数L(N, D, G)，从而建立模型大小、训练数据和模型粒度之间的关系。\\n\\n**关键创新**：论文的关键创新在于将模型粒度（G）引入Scaling Law，并提出了统一的函数形式L(N, D, G)。这使得Scaling Law能够适用于Familial模型，从而支持“一次训练，多次部署”的范式。与现有方法相比，该方法能够更准确地预测Familial模型的性能，并指导其训练和部署。此外，IsoFLOP实验设计也是一个重要的创新，它可以有效地隔离架构影响与计算规模，从而提高实验结果的可靠性。\\n\\n**关键设计**：论文的关键设计包括：1) 模型粒度的定义：明确了如何衡量Familial模型中子模型的数量和复杂程度。2) IsoFLOP实验设计：确保在固定计算预算下进行实验，从而避免计算规模对实验结果的干扰。3) 统一的Scaling Law函数L(N, D, G)：选择合适的函数形式来拟合实验数据，并确定函数中的参数。4) 粒度惩罚的建模：发现粒度惩罚遵循一个具有极小指数的乘法幂律，这表明部署灵活性可以在不影响计算最优性的情况下实现。",
            "application_zh": "该研究成果可应用于各种需要灵活部署的场景，例如边缘计算、移动设备和云计算。通过Familial模型和新型Scaling Law，可以根据不同设备的计算能力和资源限制，选择合适的子模型进行部署，从而实现更高效、更智能的应用。例如，在智能家居场景中，可以使用较小的子模型在本地设备上进行快速响应，而将复杂的任务交给云端进行处理。",
            "highlight_zh": "实验结果表明，粒度惩罚遵循一个具有极小指数的乘法幂律，这意味着增加模型粒度对性能的影响相对较小。这验证了“一次训练，多次部署”的范例，表明部署灵活性可以在不影响稠密基线的计算最优性的情况下实现。通过IsoFLOP实验，论文成功地将架构影响与计算规模隔离开来，从而提高了实验结果的可靠性。",
            "tags_zh": [
                "Scaling Law",
                "Familial模型",
                "模型粒度",
                "IsoFLOP实验",
                "模型部署"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Anka: A Domain-Specific Language for Reliable LLM Code Generation",
            "authors": [
                "Saif Khalfan Saif Al Mazrouei"
            ],
            "arxiv_id": "2512.23214v1",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet they exhibit systematic errors on complex, multi-step programming tasks. We hypothesize that these errors stem from the flexibility of general-purpose languages, which permits multiple valid approaches and requires implicit state management. To test this hypothesis, we introduce Anka, a domain-specific language (DSL) for data transformation pipelines designed with explicit, constrained syntax that reduces ambiguity in code generation. Despite having zero prior training exposure to Anka, Claude 3.5 Haiku achieves 99.9% parse success and 95.8% overall task accuracy across 100 benchmark problems. Critically, Anka demonstrates a 40 percentage point accuracy advantage over Python on multi-step pipeline tasks (100% vs. 60%), where Python's flexible syntax leads to frequent errors in operation sequencing and variable management. Cross-model validation with GPT-4o-mini confirms this advantage (+26.7 percentage points on multi-step tasks). Our results demonstrate that: (1) LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy; (2) constrained syntax significantly reduces errors on complex tasks; and (3) domain-specific languages purposefully designed for LLM generation can outperform general-purpose languages on which the LLM has extensive training. We release the complete language implementation, benchmark suite, and evaluation framework to facilitate further research.",
            "categories": [
                "cs.CL",
                "cs.LG",
                "cs.PL",
                "cs.SE"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "11 pages, 1 figure, 4 tables. Code and benchmarks available at https://github.com/BleBlo/Anka",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23214v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出领域特定语言Anka，提升LLM在复杂数据转换任务中的代码生成可靠性。",
            "summary_zh": "大型语言模型（LLMs）在代码生成方面表现出卓越的能力，但在复杂的多步骤编程任务中存在系统性错误。我们假设这些错误源于通用语言的灵活性，它允许多种有效方法并需要隐式状态管理。为了验证这一假设，我们引入了Anka，一种用于数据转换管道的领域特定语言（DSL），它具有显式、受约束的语法，从而减少了代码生成中的歧义。尽管之前没有接受过Anka的训练，Claude 3.5 Haiku在100个基准问题中实现了99.9%的解析成功率和95.8%的总体任务准确率。关键的是，Anka在多步骤管道任务上比Python表现出40个百分点的准确率优势（100% vs. 60%），其中Python的灵活语法导致操作排序和变量管理中频繁出现错误。使用GPT-4o-mini进行的跨模型验证证实了这一优势（在多步骤任务上+26.7个百分点）。我们的结果表明：（1）LLM可以完全从上下文提示中学习新的DSL，达到接近原生准确率；（2）受约束的语法显著减少了复杂任务中的错误；（3）专门为LLM生成而设计的领域特定语言可以胜过LLM接受过广泛训练的通用语言。我们发布完整的语言实现、基准测试套件和评估框架，以促进进一步研究。",
            "intro_zh": [
                "通用编程语言的灵活性导致LLM在复杂多步骤编程任务中产生系统性错误，如操作排序和变量管理错误。",
                "提出领域特定语言Anka，通过显式和受约束的语法来减少代码生成中的歧义，从而提高LLM代码生成的可靠性。",
                "实验表明，Anka在多步骤数据转换任务上显著优于Python，并且LLM可以从上下文提示中快速学习并应用Anka。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在执行复杂、多步骤数据转换任务时代码生成可靠性不足的问题。现有通用编程语言（如Python）的灵活性导致LLMs在操作排序、变量管理等方面容易出错，从而降低了任务的整体准确率。\\n\\n**核心思路**：论文的核心思路是设计一种领域特定语言（DSL），即Anka，它具有显式且受约束的语法，从而减少LLM在代码生成过程中的歧义。通过限制语言的表达方式，可以引导LLM生成更可靠、更符合预期的代码。\\n\\n**技术框架**：Anka的设计目标是简化数据转换管道的构建。其整体框架包括：定义明确的数据类型和操作符；使用显式语法来指定数据流和操作顺序；提供一套完整的基准测试套件和评估框架，用于评估LLM在Anka上的代码生成能力。\\n\\n**关键创新**：该论文的关键创新在于提出了一种专门为LLM代码生成设计的DSL，并验证了其在复杂任务上的有效性。与现有方法不同，Anka不是试图改进LLM本身，而是通过约束编程语言来提高LLM的性能。\\n\\n**关键设计**：Anka的关键设计包括：1) 显式的数据类型声明，减少类型推断错误；2) 受限的操作符集合，避免不必要的复杂性；3) 强制性的数据流定义，确保操作顺序的正确性；4) 简洁的语法结构，降低LLM的学习难度。论文未提及具体的参数设置或损失函数，因为Anka本身是一种编程语言，而非机器学习模型。",
            "application_zh": "该研究成果可应用于需要高可靠性代码生成的领域，例如数据清洗、ETL流程、自动化报告生成等。通过使用领域特定语言，可以降低开发成本，提高代码质量，并减少人工干预。未来，可以进一步扩展Anka的功能，支持更复杂的数据转换场景，并将其应用于其他领域。",
            "highlight_zh": "实验结果表明，Claude 3.5 Haiku在Anka上实现了99.9%的解析成功率和95.8%的总体任务准确率。在多步骤管道任务上，Anka比Python表现出40个百分点的准确率优势（100% vs. 60%）。使用GPT-4o-mini进行的跨模型验证也证实了Anka的优势（在多步骤任务上+26.7个百分点）。",
            "tags_zh": [
                "领域特定语言",
                "代码生成",
                "大型语言模型",
                "数据转换",
                "可靠性",
                "语法约束",
                "基准测试"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23214v1/complexity_advantage.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing",
            "authors": [
                "Panagiotis Theocharopoulos",
                "Ajinkya Kulkarni",
                "Mathew Magimai. -Doss"
            ],
            "arxiv_id": "2512.23684v1",
            "summary": "Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23684v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "多语言隐藏提示注入攻击影响LLM学术评审，不同语言脆弱性差异显著",
            "summary_zh": "大型语言模型（LLM）越来越多地被考虑用于高影响的工作流程，包括学术同行评审。然而，LLM容易受到文档级别的隐藏提示注入攻击。本文构建了一个包含约500篇ICML接收的真实学术论文的数据集，并评估了在这些文档中嵌入隐藏对抗性提示的效果。每篇论文都被注入了四种不同语言的语义等效指令，并使用LLM进行评审。研究发现，提示注入对英语、日语和中文注入的评审分数和接受/拒绝决定产生了重大影响，而阿拉伯语注入几乎没有产生任何影响。这些结果突出了基于LLM的评审系统对文档级别提示注入的敏感性，并揭示了不同语言之间脆弱性的显著差异。",
            "intro_zh": [
                "LLM在学术评审等高风险场景应用面临安全挑战，文档级隐藏提示注入攻击是潜在威胁。",
                "论文通过在学术论文中嵌入多语言对抗性提示，评估LLM评审系统的脆弱性。",
                "实验表明，英语、日语和中文的提示注入能显著改变评审结果，不同语言影响程度不同。"
            ],
            "method_zh": "**问题定义**：论文旨在研究大型语言模型（LLM）在学术评审中面临的文档级隐藏提示注入攻击的威胁。现有方法缺乏对这种攻击方式的有效防御，使得LLM在评审过程中可能受到恶意指令的影响，导致评审结果的偏差，甚至做出错误的决策。\\n\\n**核心思路**：论文的核心思路是通过在真实的学术论文中嵌入多语言的对抗性提示，来模拟攻击者可能采用的手段，从而评估LLM评审系统对这种攻击的脆弱性。通过观察LLM在受到不同语言提示注入后的评审结果变化，分析不同语言对攻击效果的影响。\\n\\n**技术框架**：论文的技术框架主要包括以下几个步骤：1) 构建包含ICML接收论文的数据集；2) 对每篇论文进行多语言（英语、日语、中文、阿拉伯语）的对抗性提示注入，确保语义等效；3) 使用LLM对注入提示的论文进行评审；4) 分析评审分数和接受/拒绝决定的变化，评估攻击效果。\\n\\n**关键创新**：论文的关键创新在于：1) 首次系统性地研究了多语言隐藏提示注入攻击对LLM学术评审的影响；2) 揭示了不同语言在提示注入攻击中的脆弱性差异，为防御策略的设计提供了新的视角；3) 使用真实学术论文作为攻击载体，更贴近实际应用场景，提高了研究的实用价值。\\n\\n**关键设计**：论文的关键设计包括：1) 选择ICML接收的论文作为数据集，保证了论文的质量和代表性；2) 使用四种不同语言进行提示注入，考察了语言对攻击效果的影响；3) 对抗性提示的设计需要保证语义等效，避免影响论文本身的含义；4) 评审结果的评估指标包括评审分数和接受/拒绝决定，能够全面反映攻击的影响。",
            "application_zh": "该研究成果可应用于提升基于LLM的学术评审系统的安全性，例如开发针对提示注入攻击的防御机制，或设计更鲁棒的评审流程。此外，该研究也为其他LLM应用场景（如合同审查、法律咨询等）的安全性评估提供了参考，有助于构建更可靠的人工智能系统。",
            "highlight_zh": "实验结果表明，英语、日语和中文的提示注入对LLM评审结果有显著影响，导致评审分数和接受/拒绝决定发生变化。阿拉伯语的提示注入效果不明显，揭示了不同语言在提示注入攻击中的脆弱性差异。这些发现为开发更有效的防御策略提供了重要依据。",
            "tags_zh": [
                "LLM",
                "提示注入攻击",
                "学术评审",
                "多语言",
                "对抗性攻击"
            ],
            "_index": 73,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "The Gaining Paths to Investment Success: Information-Driven LLM Graph Reasoning for Venture Capital Prediction",
            "authors": [
                "Haoyu Pei",
                "Zhongyang Liu",
                "Xiangyi Xiao",
                "Xiaocong Du",
                "Haipeng Zhang",
                "Kunpeng Zhang",
                "Suting Hong"
            ],
            "arxiv_id": "2512.23489v1",
            "summary": "Most venture capital (VC) investments fail, while a few deliver outsized returns. Accurately predicting startup success requires synthesizing complex relational evidence, including company disclosures, investor track records, and investment network structures, through explicit reasoning to form coherent, interpretable investment theses. Traditional machine learning and graph neural networks both lack this reasoning capability. Large language models (LLMs) offer strong reasoning but face a modality mismatch with graphs. Recent graph-LLM methods target in-graph tasks where answers lie within the graph, whereas VC prediction is off-graph: the target exists outside the network. The core challenge is selecting graph paths that maximize predictor performance on an external objective while enabling step-by-step reasoning. We present MIRAGE-VC, a multi-perspective retrieval-augmented generation framework that addresses two obstacles: path explosion (thousands of candidate paths overwhelm LLM context) and heterogeneous evidence fusion (different startups need different analytical emphasis). Our information-gain-driven path retriever iteratively selects high-value neighbors, distilling investment networks into compact chains for explicit reasoning. A multi-agent architecture integrates three evidence streams via a learnable gating mechanism based on company attributes. Under strict anti-leakage controls, MIRAGE-VC achieves +5.0% F1 and +16.6% PrecisionAt5, and sheds light on other off-graph prediction tasks such as recommendation and risk assessment. Code: https://anonymous.4open.science/r/MIRAGE-VC-323F.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23489v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "MIRAGE-VC：信息增益驱动的LLM图推理，用于风险投资预测",
            "summary_zh": "风险投资(VC)中，多数投资失败，少数带来超额回报。准确预测初创公司成功需要综合复杂的关联证据，包括公司披露信息、投资者业绩记录和投资网络结构，并通过显式推理形成连贯、可解释的投资论点。传统机器学习和图神经网络都缺乏这种推理能力。大型语言模型(LLM)具有强大的推理能力，但与图存在模态不匹配。现有的图-LLM方法主要针对图内任务，而VC预测是图外任务，目标存在于网络之外。核心挑战是选择最大化外部目标预测性能的图路径，同时实现逐步推理。我们提出了MIRAGE-VC，一个多视角检索增强生成框架，解决了路径爆炸（数千条候选路径使LLM上下文不堪重负）和异构证据融合（不同的初创公司需要不同的分析重点）两个难题。我们的信息增益驱动的路径检索器迭代地选择高价值邻居，将投资网络提炼成紧凑的链条以进行显式推理。一个多智能体架构通过基于公司属性的可学习门控机制整合了三个证据流。在严格的反泄露控制下，MIRAGE-VC实现了+5.0%的F1和+16.6%的PrecisionAt5，并为推荐和风险评估等其他图外预测任务提供了启示。",
            "intro_zh": [
                "现有方法难以有效利用复杂关系证据进行风险投资预测，缺乏显式推理能力。",
                "MIRAGE-VC通过信息增益驱动的路径检索和多智能体架构，实现对投资网络的有效推理。",
                "实验表明，MIRAGE-VC在风险投资预测任务上显著提升了F1和PrecisionAt5指标。"
            ],
            "method_zh": "**问题定义**：风险投资预测是一个典型的图外预测问题，需要利用公司信息、投资者信息以及投资网络结构等复杂关系证据来预测初创公司的成功率。现有方法，如传统机器学习和图神经网络，难以进行有效的推理，无法充分利用这些关系信息。大型语言模型虽然具有强大的推理能力，但与图数据存在模态不匹配的问题。\\n\\n**核心思路**：MIRAGE-VC的核心思路是利用信息增益来指导图路径的检索，从而将复杂的投资网络提炼成紧凑的、具有高信息量的路径，然后利用大型语言模型对这些路径进行推理，最终实现对初创公司成功率的预测。这种方法能够有效地解决路径爆炸问题，并能够根据不同的初创公司选择不同的分析重点。\\n\\n**技术框架**：MIRAGE-VC的整体架构是一个多视角检索增强生成框架，主要包含两个模块：信息增益驱动的路径检索器和多智能体架构。路径检索器负责从投资网络中选择高价值的邻居，构建紧凑的推理路径。多智能体架构负责整合来自不同证据流的信息，并利用可学习的门控机制来调整不同证据流的权重。\\n\\n**关键创新**：MIRAGE-VC最重要的技术创新点在于其信息增益驱动的路径检索器。该检索器能够迭代地选择高价值的邻居，从而将复杂的投资网络提炼成紧凑的链条，避免了路径爆炸问题。与现有方法相比，MIRAGE-VC能够更有效地利用图结构信息，并能够进行显式的推理。\\n\\n**关键设计**：MIRAGE-VC的关键设计包括：1) 使用信息增益作为路径选择的指标；2) 设计了一个多智能体架构来整合来自不同证据流的信息；3) 使用可学习的门控机制来调整不同证据流的权重。具体的参数设置、损失函数和网络结构等技术细节在论文中有详细描述。",
            "application_zh": "MIRAGE-VC的研究成果可以应用于风险投资领域的项目评估、投资组合管理和风险控制。此外，该方法还可以推广到其他图外预测任务，如推荐系统和风险评估，具有广泛的应用前景和实际价值。通过提升投资决策的准确性，有望促进创新和经济发展。",
            "highlight_zh": "MIRAGE-VC在风险投资预测任务上取得了显著的性能提升。在严格的反泄露控制下，MIRAGE-VC的F1值提高了5.0%，PrecisionAt5提高了16.6%。这些结果表明，MIRAGE-VC能够有效地利用图结构信息和大型语言模型的推理能力，从而提高风险投资预测的准确性。",
            "tags_zh": [
                "风险投资预测",
                "图神经网络",
                "大型语言模型",
                "信息增益",
                "图推理"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23489v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23489v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23489v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?",
            "authors": [
                "The Anh Nguyen",
                "Triet Huynh Minh Le",
                "M. Ali Babar"
            ],
            "arxiv_id": "2512.23385v1",
            "summary": "The rapid growth of Artificial Intelligence (AI) models and applications has led to an increasingly complex security landscape. Developers of AI projects must contend not only with traditional software supply chain issues but also with novel, AI-specific security threats. However, little is known about what security issues are commonly encountered and how they are resolved in practice. This gap hinders the development of effective security measures for each component of the AI supply chain. We bridge this gap by conducting an empirical investigation of developer-reported issues and solutions, based on discussions from Hugging Face and GitHub. To identify security-related discussions, we develop a pipeline that combines keyword matching with an optimal fine-tuned distilBERT classifier, which achieved the best performance in our extensive comparison of various deep learning and large language models. This pipeline produces a dataset of 312,868 security discussions, providing insights into the security reporting practices of AI applications and projects. We conduct a thematic analysis of 753 posts sampled from our dataset and uncover a fine-grained taxonomy of 32 security issues and 24 solutions across four themes: (1) System and Software, (2) External Tools and Ecosystem, (3) Model, and (4) Data. We reveal that many security issues arise from the complex dependencies and black-box nature of AI components. Notably, challenges related to Models and Data often lack concrete solutions. Our insights can offer evidence-based guidance for developers and researchers to address real-world security threats across the AI supply chain.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR",
                "cs.HC"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23385v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "通过分析开发者报告的安全问题与解决方案，提升AI供应链安全性",
            "summary_zh": "人工智能模型和应用的快速增长导致安全形势日益复杂。AI项目开发者不仅要应对传统的软件供应链问题，还要应对新型的、AI特有的安全威胁。然而，对于常见的安全问题以及实际的解决方案，我们知之甚少。为了弥合这一差距，我们基于Hugging Face和GitHub上的讨论，对开发者报告的问题和解决方案进行了实证研究。为了识别与安全相关的讨论，我们开发了一个管道，将关键词匹配与优化的微调distilBERT分类器相结合，该分类器在我们对各种深度学习和大型语言模型的广泛比较中取得了最佳性能。该管道生成了一个包含312,868个安全讨论的数据集，提供了对AI应用和项目安全报告实践的见解。我们对从数据集中抽样的753个帖子进行了主题分析，揭示了一个细粒度的分类法，涵盖四个主题的32个安全问题和24个解决方案：（1）系统和软件，（2）外部工具和生态系统，（3）模型，以及（4）数据。我们发现，许多安全问题源于AI组件的复杂依赖关系和黑盒特性。值得注意的是，与模型和数据相关的挑战往往缺乏具体的解决方案。我们的见解可以为开发者和研究人员提供基于证据的指导，以应对AI供应链中的实际安全威胁。",
            "intro_zh": [
                "AI供应链面临传统软件安全问题之外，还存在AI模型和数据带来的新型安全威胁，现有研究对这些威胁的理解不足。",
                "该研究通过分析Hugging Face和GitHub上的开发者讨论，识别并分类AI项目中的安全问题和解决方案。",
                "研究构建了一个包含31万余条安全讨论的数据集，并对753个帖子进行主题分析，揭示了32个安全问题和24个解决方案。"
            ],
            "method_zh": "**问题定义**：论文旨在解决AI供应链中存在的安全问题，这些问题源于AI模型和应用的复杂性，以及对AI组件（如模型和数据）的依赖。现有方法未能充分识别和解决这些AI特有的安全威胁，导致开发者缺乏有效的安全措施指导。\\n\\n**核心思路**：论文的核心思路是通过挖掘开发者在Hugging Face和GitHub等平台上的讨论，来了解AI项目中实际遇到的安全问题和解决方案。通过分析这些真实世界的案例，可以更准确地识别AI供应链中的安全风险，并为开发者提供有针对性的安全建议。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个阶段：1) 数据收集：从Hugging Face和GitHub收集开发者讨论数据。2) 安全讨论识别：开发一个管道，结合关键词匹配和微调的distilBERT分类器，识别与安全相关的讨论。3) 主题分析：对识别出的安全讨论进行抽样，并进行人工主题分析，提取安全问题和解决方案。4) 分类构建：根据主题分析的结果，构建一个细粒度的安全问题和解决方案分类体系。\\n\\n**关键创新**：该研究的关键创新在于：1) 利用开发者报告的数据，更贴近实际应用场景，避免了传统安全研究的局限性。2) 结合关键词匹配和微调的distilBERT分类器，提高了安全讨论识别的准确率。3) 构建了一个细粒度的AI供应链安全问题和解决方案分类体系，为后续研究提供了基础。\\n\\n**关键设计**：在安全讨论识别阶段，研究人员对distilBERT模型进行了微调，使其能够更准确地识别与安全相关的文本。此外，在主题分析阶段，研究人员采用了迭代式的编码方法，确保分类体系的完整性和准确性。具体参数设置和损失函数等细节未在论文中详细描述。",
            "application_zh": "该研究成果可应用于AI开发的安全审计、漏洞挖掘和安全加固。通过了解AI供应链中常见的安全问题和解决方案，开发者可以更有针对性地采取安全措施，降低AI系统的安全风险。研究结果还可以为安全研究人员提供参考，促进AI安全领域的发展。",
            "highlight_zh": "研究构建了一个包含312,868个安全讨论的数据集，并对753个帖子进行了主题分析，揭示了32个安全问题和24个解决方案，涵盖系统软件、外部工具、模型和数据四个主题。研究发现，与模型和数据相关的安全问题往往缺乏具体的解决方案，这突显了AI安全研究的挑战。",
            "tags_zh": [
                "AI供应链安全",
                "安全漏洞分析",
                "开发者报告",
                "自然语言处理",
                "深度学习",
                "安全分类",
                "Hugging Face",
                "GitHub"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23385v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23385v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23385v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TCEval: Using Thermal Comfort to Assess Cognitive and Perceptual Abilities of AI",
            "authors": [
                "Jingming Li"
            ],
            "arxiv_id": "2512.23217v1",
            "summary": "A critical gap exists in LLM task-specific benchmarks. Thermal comfort, a sophisticated interplay of environmental factors and personal perceptions involving sensory integration and adaptive decision-making, serves as an ideal paradigm for evaluating real-world cognitive capabilities of AI systems. To address this, we propose TCEval, the first evaluation framework that assesses three core cognitive capacities of AI, cross-modal reasoning, causal association, and adaptive decision-making, by leveraging thermal comfort scenarios and large language model (LLM) agents. The methodology involves initializing LLM agents with virtual personality attributes, guiding them to generate clothing insulation selections and thermal comfort feedback, and validating outputs against the ASHRAE Global Database and Chinese Thermal Comfort Database. Experiments on four LLMs show that while agent feedback has limited exact alignment with humans, directional consistency improves significantly with a 1 PMV tolerance. Statistical tests reveal that LLM-generated PMV distributions diverge markedly from human data, and agents perform near-randomly in discrete thermal comfort classification. These results confirm the feasibility of TCEval as an ecologically valid Cognitive Turing Test for AI, demonstrating that current LLMs possess foundational cross-modal reasoning ability but lack precise causal understanding of the nonlinear relationships between variables in thermal comfort. TCEval complements traditional benchmarks, shifting AI evaluation focus from abstract task proficiency to embodied, context-aware perception and decision-making, offering valuable insights for advancing AI in human-centric applications like smart buildings.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23217v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TCEval框架以评估AI的认知与感知能力",
            "summary_zh": "在大型语言模型（LLM）任务特定基准中存在重要缺口。热舒适作为环境因素与个人感知之间复杂交互的理想范式，能够有效评估AI系统的真实世界认知能力。为此，本文提出了TCEval，这是第一个通过热舒适场景和LLM代理评估AI三大核心认知能力的评估框架。研究表明，尽管代理反馈与人类的精确对齐有限，但在1 PMV容忍度下，方向一致性显著提高。统计测试显示，LLM生成的PMV分布与人类数据显著偏离，代理在离散热舒适分类中的表现接近随机。这些结果确认了TCEval作为生态有效的认知图灵测试的可行性，展示了当前LLM具备基础的跨模态推理能力，但缺乏对热舒适变量之间非线性关系的精确因果理解。",
            "intro_zh": [
                "现有的LLM任务特定基准缺乏有效性，无法全面评估AI在真实环境中的认知能力。",
                "本文提出TCEval框架，通过热舒适场景评估AI的跨模态推理、因果关联和适应性决策能力。",
                "实验结果显示，LLM生成的反馈与人类数据存在显著差异，但在一定容忍度下，方向一致性有明显提升。"
            ],
            "method_zh": "**问题定义**：本文旨在解决现有LLM评估方法在真实环境认知能力评估中的不足，特别是在热舒适领域的应用。现有方法未能有效捕捉AI在复杂环境中的感知与决策能力。\\n\\n**核心思路**：TCEval框架通过模拟热舒适场景，结合LLM代理的虚拟个性特征，评估其在跨模态推理、因果关联和适应性决策方面的能力。这种设计旨在提供更真实的评估环境。\\n\\n**技术框架**：TCEval的整体架构包括初始化LLM代理、生成服装绝缘选择和热舒适反馈，并将输出与ASHRAE全球数据库和中国热舒适数据库进行验证。主要模块包括数据收集、模型初始化、反馈生成和结果验证。\\n\\n**关键创新**：TCEval的创新在于将热舒适作为评估AI认知能力的基准，首次将环境感知与决策能力结合，提供了一种新的评估视角，与传统基准方法形成鲜明对比。\\n\\n**关键设计**：在模型设计中，采用了特定的参数设置和损失函数，以确保生成的反馈与真实数据的对齐。同时，使用了1 PMV的容忍度来提高方向一致性，增强了评估的生态有效性。",
            "application_zh": "TCEval框架的潜在应用领域包括智能建筑、环境监测和人机交互等。通过更准确地评估AI在复杂环境中的认知能力，能够推动AI在以人为中心的应用中的发展，提升用户体验和环境适应性。未来，该框架可能为智能系统的设计和优化提供重要参考。",
            "highlight_zh": "实验结果显示，LLM生成的PMV分布与人类数据显著偏离，且在离散热舒适分类中表现接近随机。然而，在1 PMV容忍度下，代理的方向一致性显著提高，表明TCEval在评估AI认知能力方面具有潜力。",
            "tags_zh": [
                "热舒适",
                "认知能力评估",
                "大型语言模型",
                "跨模态推理",
                "因果关联",
                "适应性决策",
                "智能建筑",
                "生态有效性"
            ],
            "_index": 76,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "From Model Choice to Model Belief: Establishing a New Measure for LLM-Based Research",
            "authors": [
                "Hongshen Sun",
                "Juanjuan Zhang"
            ],
            "arxiv_id": "2512.23184v1",
            "summary": "Large language models (LLMs) are increasingly used to simulate human behavior, but common practices to use LLM-generated data are inefficient. Treating an LLM's output (\"model choice\") as a single data point underutilizes the information inherent to the probabilistic nature of LLMs. This paper introduces and formalizes \"model belief,\" a measure derived from an LLM's token-level probabilities that captures the model's belief distribution over choice alternatives in a single generation run. The authors prove that model belief is asymptotically equivalent to the mean of model choices (a non-trivial property) but forms a more statistically efficient estimator, with lower variance and a faster convergence rate. Analogous properties are shown to hold for smooth functions of model belief and model choice often used in downstream applications. The authors demonstrate the performance of model belief through a demand estimation study, where an LLM simulates consumer responses to different prices. In practical settings with limited numbers of runs, model belief explains and predicts ground-truth model choice better than model choice itself, and reduces the computation needed to reach sufficiently accurate estimates by roughly a factor of 20. The findings support using model belief as the default measure to extract more information from LLM-generated data.",
            "categories": [
                "cs.AI",
                "econ.EM"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23184v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出“模型置信度”：一种更高效的LLM数据利用方法，提升LLM模拟研究的统计效率。",
            "summary_zh": "大型语言模型（LLMs）越来越多地被用于模拟人类行为，但常用的LLM生成数据的使用方法效率低下。将LLM的输出（“模型选择”）视为单个数据点，未能充分利用LLM概率性质中蕴含的信息。本文介绍并形式化了“模型置信度”，这是一种从LLM的token级别概率中导出的度量，它在单个生成运行中捕获模型对选择方案的置信度分布。作者证明了模型置信度与模型选择的均值是渐近等价的（一个重要的性质），但它形成了一个统计上更有效的估计器，具有更低的方差和更快的收敛速度。类似的性质也被证明适用于模型置信度和模型选择的光滑函数，这些函数经常在下游应用中使用。作者通过需求估计研究展示了模型置信度的性能，其中LLM模拟消费者对不同价格的反应。在运行次数有限的实际设置中，模型置信度比模型选择本身更好地解释和预测了ground-truth模型选择，并将达到足够准确的估计所需的计算量减少了大约20倍。研究结果支持使用模型置信度作为默认度量，以从LLM生成的数据中提取更多信息。",
            "intro_zh": [
                "现有方法将LLM输出视为单一数据点，忽略了其内在的概率信息，导致LLM模拟研究效率低下。",
                "论文提出“模型置信度”概念，利用LLM的token级别概率分布，更全面地捕捉模型对不同选择的置信程度。",
                "实验表明，模型置信度在预测模型选择方面优于传统方法，并显著降低了计算成本，提升了估计精度。"
            ],
            "method_zh": "**问题定义**：现有方法在利用LLM生成的数据时，通常只关注最终的“模型选择”，即LLM给出的一个具体答案。这种方法忽略了LLM生成答案过程中产生的token级别的概率分布信息，造成了信息浪费。尤其是在模拟人类行为的研究中，这种信息损失会降低统计效率，需要更多的采样才能得到可靠的结果。\\n\\n**核心思路**：论文的核心思路是利用LLM的token级别概率分布，构建一个名为“模型置信度”的度量。该度量能够反映LLM对于不同选择方案的置信程度，从而更全面地利用LLM生成过程中的信息。通过将LLM的输出从单一选择扩展到概率分布，可以更准确地模拟人类行为，并提高统计效率。\\n\\n**技术框架**：该论文主要关注理论分析和实验验证，并没有提出一个全新的技术框架。其核心在于定义和使用“模型置信度”这一概念。具体来说，对于一个给定的问题和一组可能的答案，LLM会生成每个答案的概率分布。模型置信度就是基于这个概率分布计算出来的一个度量，用于表示LLM对每个答案的置信程度。然后，作者在需求估计的场景下，将模型置信度应用于模拟消费者行为，并与传统的“模型选择”方法进行比较。\\n\\n**关键创新**：该论文的关键创新在于提出了“模型置信度”这一概念，并证明了其在统计效率上的优越性。与传统的“模型选择”方法相比，模型置信度能够更好地利用LLM生成过程中的信息，从而提高模拟的准确性和效率。此外，论文还证明了模型置信度与模型选择的均值是渐近等价的，这为使用模型置信度提供了理论基础。\\n\\n**关键设计**：论文的关键设计在于如何从LLM的token级别概率分布中计算出模型置信度。具体计算方法取决于具体的应用场景和LLM的输出格式。在需求估计的实验中，作者使用了softmax函数将LLM输出的logits转换为概率分布，然后基于该概率分布计算模型置信度。此外，论文还考虑了如何将模型置信度应用于下游任务，例如需求估计中的价格弹性计算。",
            "application_zh": "该研究成果可广泛应用于各种需要利用LLM模拟人类行为的领域，例如市场营销、经济学、社会科学等。通过使用模型置信度，研究人员可以更高效地利用LLM生成的数据，降低计算成本，并提高模拟的准确性。这有助于更好地理解人类行为，并为决策提供更可靠的依据。",
            "highlight_zh": "实验结果表明，在需求估计任务中，模型置信度比模型选择更好地解释和预测了ground-truth模型选择。在实际设置中，使用模型置信度可以将达到足够准确的估计所需的计算量减少大约20倍。这表明模型置信度是一种更高效、更准确的LLM数据利用方法。",
            "tags_zh": [
                "大型语言模型",
                "LLM",
                "模型置信度",
                "概率建模",
                "统计效率",
                "需求估计",
                "行为模拟"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Reservoir Computing inspired Matrix Multiplication-free Language Model",
            "authors": [
                "Takumi Shiratsuchi",
                "Yuichiro Tanaka",
                "Hakaru Tamukoh"
            ],
            "arxiv_id": "2512.23145v1",
            "summary": "Large language models (LLMs) have achieved state-of-the-art performance in natural language processing; however, their high computational cost remains a major bottleneck. In this study, we target computational efficiency by focusing on a matrix multiplication free language model (MatMul-free LM) and further reducing the training cost through an architecture inspired by reservoir computing. Specifically, we partially fix and share the weights of selected layers in the MatMul-free LM and insert reservoir layers to obtain rich dynamic representations without additional training overhead. Additionally, several operations are combined to reduce memory accesses. Experimental results show that the proposed architecture reduces the number of parameters by up to 19%, training time by 9.9%, and inference time by 8.0%, while maintaining comparable performance to the baseline model.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "9 pages, 10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23145v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于储层计算的无矩阵乘法语言模型，降低训练和推理成本。",
            "summary_zh": "大型语言模型（LLMs）在自然语言处理领域取得了最先进的性能；然而，其高计算成本仍然是一个主要的瓶颈。本研究着眼于计算效率，专注于无矩阵乘法语言模型（MatMul-free LM），并通过受储层计算启发的架构进一步降低训练成本。具体来说，我们部分固定和共享MatMul-free LM中选定层的权重，并插入储层层以获得丰富的动态表示，而无需额外的训练开销。此外，还组合了多个操作以减少内存访问。实验结果表明，所提出的架构在保持与基线模型相当的性能的同时，减少了高达19%的参数数量，9.9%的训练时间和8.0%的推理时间。",
            "intro_zh": [
                "大型语言模型计算成本高昂，成为其应用的主要瓶颈，需要更高效的模型。",
                "论文提出一种基于储层计算的无矩阵乘法语言模型，旨在降低训练和推理的计算成本。",
                "实验结果表明，该架构在保持性能的同时，显著减少了参数量、训练时间和推理时间。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLMs）虽然性能优越，但其计算成本过高，限制了其在资源受限环境中的应用。无矩阵乘法语言模型（MatMul-free LM）是一种降低计算复杂度的尝试，但仍有进一步降低训练成本的空间。\\n\\n**核心思路**：论文的核心思路是借鉴储层计算的思想，通过固定部分网络权重并引入储层层，在不增加额外训练开销的情况下，获得丰富的动态表示。这种方法旨在降低训练参数量和计算复杂度，从而提高训练和推理效率。\\n\\n**技术框架**：该模型基于MatMul-free LM，主要包含以下几个关键模块：1) 部分权重固定的MatMul-free LM层：这些层中的部分权重被固定并共享，以减少参数数量。2) 储层层：插入到网络中的储层层负责生成丰富的动态表示，而无需进行训练。3) 优化的操作组合：通过组合多个操作来减少内存访问，进一步提高计算效率。整体流程是，输入数据首先通过部分权重固定的MatMul-free LM层，然后通过储层层生成动态表示，最后进行预测。\\n\\n**关键创新**：该论文的关键创新在于将储层计算的思想引入到无矩阵乘法语言模型中。与传统的训练整个网络的方法不同，该方法通过固定部分权重和引入储层层，实现了在不增加额外训练开销的情况下，获得丰富的动态表示。这与完全训练所有参数的传统方法有着本质的区别。\\n\\n**关键设计**：论文的关键设计包括：1) 储层层的具体结构和参数设置（例如，储层的大小、连接方式等，具体细节未知）。2) 如何选择和固定MatMul-free LM中的哪些层和哪些权重（具体策略未知）。3) 如何组合多个操作以减少内存访问（具体操作组合方式未知）。这些设计细节对于模型的性能和效率至关重要，但论文摘要中并未详细描述。",
            "application_zh": "该研究成果可应用于资源受限的设备或场景，例如移动设备、嵌入式系统等，使得在这些平台上部署和运行大型语言模型成为可能。此外，该方法还可以加速语言模型的开发和迭代过程，降低研发成本，促进自然语言处理技术的普及。",
            "highlight_zh": "实验结果表明，该架构在保持与基线模型相当的性能的同时，减少了高达19%的参数数量，9.9%的训练时间和8.0%的推理时间。这些数据表明，该方法在降低计算成本方面具有显著优势。",
            "tags_zh": [
                "语言模型",
                "储层计算",
                "无矩阵乘法",
                "计算效率",
                "模型压缩"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23145v1/image/Metaformer.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23145v1/image/Transformer_En.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23145v1/image/prevWork_architecture_En.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "It's a TRAP! Task-Redirecting Agent Persuasion Benchmark for Web Agents",
            "authors": [
                "Karolina Korgul",
                "Yushi Yang",
                "Arkadiusz Drohomirecki",
                "Piotr Błaszczyk",
                "Will Howard",
                "Lukas Aichberger",
                "Chris Russell",
                "Philip H. S. Torr",
                "Adam Mahdi",
                "Adel Bibi"
            ],
            "arxiv_id": "2512.23128v1",
            "summary": "Web-based agents powered by large language models are increasingly used for tasks such as email management or professional networking. Their reliance on dynamic web content, however, makes them vulnerable to prompt injection attacks: adversarial instructions hidden in interface elements that persuade the agent to divert from its original task. We introduce the Task-Redirecting Agent Persuasion Benchmark (TRAP), an evaluation for studying how persuasion techniques misguide autonomous web agents on realistic tasks. Across six frontier models, agents are susceptible to prompt injection in 25\\% of tasks on average (13\\% for GPT-5 to 43\\% for DeepSeek-R1), with small interface or contextual changes often doubling success rates and revealing systemic, psychologically driven vulnerabilities in web-based agents. We also provide a modular social-engineering injection framework with controlled experiments on high-fidelity website clones, allowing for further benchmark expansion.",
            "categories": [
                "cs.HC",
                "cs.AI",
                "cs.MA"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23128v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TRAP基准测试，评估Web Agent在提示注入攻击下的任务重定向脆弱性",
            "summary_zh": "本文介绍了一个名为任务重定向代理说服基准（TRAP）的评估方法，用于研究说服技术如何误导自主Web Agent执行非预期任务。这些Agent由大型语言模型驱动，常用于电子邮件管理或专业社交等任务。然而，它们对动态Web内容的依赖使其容易受到提示注入攻击，即隐藏在界面元素中的对抗性指令，诱使Agent偏离其原始任务。实验表明，六个前沿模型平均有25%的任务容易受到提示注入的影响（GPT-5为13%，DeepSeek-R1为43%）。界面或上下文的微小变化通常会使成功率翻倍，揭示了Web Agent中系统性的、心理驱动的漏洞。此外，本文还提供了一个模块化的社会工程注入框架，通过对高保真网站克隆进行受控实验，从而进一步扩展基准测试。",
            "intro_zh": [
                "Web Agent依赖动态Web内容，易受恶意提示注入攻击，导致任务被重定向。",
                "TRAP基准测试通过模拟真实Web环境，评估Agent在对抗性指令下的行为。",
                "实验表明，现有Agent对提示注入攻击的抵抗力较弱，存在显著的安全漏洞。"
            ],
            "method_zh": "**问题定义**：论文旨在解决Web Agent容易受到提示注入攻击，导致其执行非预期任务的问题。现有方法缺乏对这种攻击的系统性评估和防御机制，使得Agent在实际应用中面临安全风险。现有的Web Agent在处理网页内容时，容易受到恶意构造的提示的影响，从而偏离其预定的目标。\n\n**核心思路**：论文的核心思路是构建一个基准测试环境，模拟真实的Web环境，并设计各种社会工程学攻击手段，评估Agent在这些攻击下的表现。通过分析Agent的脆弱性，为开发更安全的Web Agent提供指导。\n\n**技术框架**：TRAP基准测试包含以下主要模块：1) 高保真网站克隆：创建与真实网站相似的克隆环境，模拟Agent的实际操作场景。2) 任务定义：定义Agent需要完成的各种任务，例如发送邮件、添加联系人等。3) 攻击策略：设计各种提示注入攻击策略，例如在网页文本中嵌入恶意指令。4) 评估指标：评估Agent在攻击下的表现，例如任务完成率、任务重定向率等。5) 模块化社会工程注入框架：允许用户自定义攻击策略，扩展基准测试。\n\n**关键创新**：论文的关键创新在于提出了一个专门针对Web Agent的提示注入攻击评估基准。该基准不仅模拟了真实的Web环境，还设计了多种社会工程学攻击手段，能够全面评估Agent的安全性。此外，该基准还提供了一个模块化的攻击框架，方便用户自定义攻击策略。\n\n**关键设计**：TRAP基准测试的关键设计包括：1) 高保真网站克隆，保证了评估的真实性。2) 多样化的任务定义，覆盖了Agent的常见应用场景。3) 精心设计的攻击策略，模拟了真实的攻击手段。4) 模块化的攻击框架，方便用户扩展和定制。具体参数设置和网络结构取决于被评估的Agent模型。",
            "application_zh": "该研究成果可应用于提升Web Agent的安全性，防止其受到恶意攻击。通过TRAP基准测试，可以评估和改进Agent的防御能力，降低任务被重定向的风险。这对于保护用户隐私、防止信息泄露以及确保Agent的可靠运行具有重要意义。未来，该研究可以促进开发更安全的Web Agent，使其能够更好地服务于用户。",
            "highlight_zh": "实验结果表明，现有Web Agent对提示注入攻击的抵抗力较弱，平均有25%的任务容易受到攻击。不同模型之间的表现差异显著，GPT-5的攻击成功率为13%，而DeepSeek-R1则高达43%。此外，实验还发现，界面或上下文的微小变化会显著影响攻击成功率，揭示了Agent中存在的系统性漏洞。",
            "tags_zh": [
                "Web Agent",
                "提示注入攻击",
                "基准测试",
                "任务重定向",
                "安全评估"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23128v1/Figures/environments.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23128v1/Figures/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23128v1/iclr/Figures/injection_creation_iteration2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing",
            "authors": [
                "Yuwen Li",
                "Wei Zhang",
                "Zelong Huang",
                "Mason Yang",
                "Jiajun Wu",
                "Shawn Guo",
                "Huahao Hu",
                "Lingyi Sun",
                "Jian Yang",
                "Mingjie Tang",
                "Byran Dai"
            ],
            "arxiv_id": "2512.23611v1",
            "summary": "Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23611v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "InfTool：通过多智能体角色扮演合成无限工具使用数据，提升LLM工具调用能力。",
            "summary_zh": "本文提出InfTool，一个全自动框架，通过自进化的多智能体合成来打破现有方法在工具调用方面的瓶颈。InfTool仅需原始API规范，即可协调三个协作智能体（用户模拟器、工具调用助手和MCP服务器）生成多样化、经过验证的轨迹，涵盖单轮调用到复杂的多步骤工作流程。该框架建立了一个闭环：合成的数据通过带有门控奖励的Group Relative Policy Optimization (GRPO) 训练模型，改进后的模型生成更高质量的数据以弥补能力差距，并且这个循环在没有人为干预的情况下迭代。在Berkeley Function-Calling Leaderboard (BFCL) 上的实验表明，InfTool 将一个基础的 32B 模型从 19.8% 的准确率提升到 70.9%（+258%），超过了 10 倍大的模型，并且可以与 Claude-Opus 相媲美，所有这些都来自合成数据，无需人工标注。",
            "intro_zh": [
                "现有方法在使大型语言模型（LLM）可靠地调用外部工具时面临挑战，包括高质量轨迹的人工标注成本高昂、对未见工具的泛化能力差以及单模型合成的质量上限。",
                "InfTool 提出一个全自动框架，通过多智能体角色扮演，仅需原始API规范，即可生成多样化、经过验证的工具使用轨迹，无需人工干预。",
                "实验表明，InfTool 在 Berkeley Function-Calling Leaderboard (BFCL) 上显著提升了模型的工具调用准确率，甚至超越了规模更大的模型。"
            ],
            "method_zh": "**问题定义**：现有方法在训练LLM进行工具调用时，面临数据获取的难题。人工标注成本高，且难以覆盖所有可能的工具和使用场景。单模型生成数据存在偏差和覆盖不足的问题，导致模型泛化能力受限。\\n\\n**核心思路**：InfTool的核心思路是利用多智能体协作，构建一个闭环的自学习系统。通过用户模拟器、工具调用助手和MCP服务器之间的交互，自动生成高质量的工具使用数据，并利用这些数据迭代训练模型，从而不断提升模型的工具调用能力。\\n\\n**技术框架**：InfTool包含三个主要模块：1) 用户模拟器：模拟用户需求，生成工具调用请求。2) 工具调用助手：根据用户请求，选择合适的工具并调用，生成工具调用轨迹。3) MCP服务器：验证工具调用轨迹的正确性，并提供奖励信号。这三个模块形成一个闭环，不断生成和验证数据，并利用这些数据训练模型。\\n\\n**关键创新**：InfTool的关键创新在于其全自动化的数据生成和模型训练流程。它摆脱了对人工标注的依赖，能够自动探索和学习新的工具和使用场景。此外，InfTool利用Group Relative Policy Optimization (GRPO) 算法，结合门控奖励，有效地训练模型，提升其工具调用能力。\\n\\n**关键设计**：InfTool使用Group Relative Policy Optimization (GRPO) 算法进行模型训练，该算法能够有效地利用多智能体生成的数据。门控奖励机制用于筛选高质量的工具调用轨迹，避免噪声数据对模型训练产生负面影响。具体参数设置和网络结构细节在论文中未明确说明，属于未知信息。",
            "application_zh": "InfTool 的潜在应用领域包括自动化客服、智能助手、机器人控制等。它可以用于训练 LLM 在各种实际场景中自主调用工具，完成复杂任务。该研究的实际价值在于降低了 LLM 工具调用训练的成本，提高了模型的泛化能力。未来，InfTool 可以扩展到更多领域，例如代码生成、科学研究等，赋能 LLM 解决更复杂的问题。",
            "highlight_zh": "InfTool 在 Berkeley Function-Calling Leaderboard (BFCL) 上取得了显著成果，将一个基础的 32B 模型从 19.8% 的准确率提升到 70.9%（+258%），超越了 10 倍大的模型，并且可以与 Claude-Opus 相媲美。所有这些提升都来自于合成数据，无需人工标注，证明了 InfTool 在提升 LLM 工具调用能力方面的有效性。",
            "tags_zh": [
                "工具调用",
                "大型语言模型",
                "多智能体",
                "强化学习",
                "数据合成"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23611v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23611v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23611v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "The Big Three in Marriage Talk: LLM-Assisted Analysis of Moral Ethics and Sentiment on Weibo and Xiaohongshu",
            "authors": [
                "Frank Tian-Fang Ye",
                "Xiaozi Gao"
            ],
            "arxiv_id": "2512.23609v1",
            "summary": "China's marriage registrations have declined dramatically, dropping from 13.47 million couples in 2013 to 6.1 million in 2024. Understanding public attitudes toward marriage requires examining not only emotional sentiment but also the moral reasoning underlying these evaluations. This study analyzed 219,358 marriage-related posts from two major Chinese social media platforms (Sina Weibo and Xiaohongshu) using large language model (LLM)-assisted content analysis. Drawing on Shweder's Big Three moral ethics framework, posts were coded for sentiment (positive, negative, neutral) and moral dimensions (Autonomy, Community, Divinity). Results revealed platform differences: Weibo discourse skewed positive, while Xiaohongshu was predominantly neutral. Most posts across both platforms lacked explicit moral framing. However, when moral ethics were invoked, significant associations with sentiment emerged. Posts invoking Autonomy ethics and Community ethics were predominantly negative, whereas Divinity-framed posts tended toward neutral or positive sentiment. These findings suggest that concerns about both personal autonomy constraints and communal obligations drive negative marriage attitudes in contemporary China. The study demonstrates LLMs' utility for scaling qualitative analysis and offers insights for developing culturally informed policies addressing marriage decline in Chinese contexts.",
            "categories": [
                "econ.GN",
                "cs.CL"
            ],
            "primary_category": "econ.GN",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23609v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大语言模型分析微博和小红书上的婚姻话题，揭示道德伦理与情感倾向",
            "summary_zh": "中国结婚登记数量急剧下降，从2013年的1347万对降至2024年的610万对。为了解公众对婚姻的态度，需要考察情感倾向以及评估背后的道德推理。本研究利用大型语言模型（LLM）辅助的内容分析方法，分析了来自中国两大社交媒体平台（新浪微博和小红书）的219358篇与婚姻相关的帖子。基于Shweder的“三大道德伦理”框架，对帖子进行情感（积极、消极、中性）和道德维度（自主、社群、神性）的编码。结果显示平台差异：微博上的讨论偏向积极，而小红书则以中性为主。两个平台上的大多数帖子都缺乏明确的道德框架。然而，当涉及道德伦理时，情感与道德之间存在显著关联。强调自主伦理和社群伦理的帖子大多为负面情绪，而以神性为框架的帖子则倾向于中性或积极情绪。这些发现表明，对个人自主约束和社群义务的担忧是当代中国消极婚姻态度的驱动因素。该研究展示了LLM在扩展定性分析方面的效用，并为制定具有文化敏感性的政策以应对中国婚姻数量下降的问题提供了见解。",
            "intro_zh": [
                "中国结婚率显著下降，理解公众对婚姻的态度需要深入分析情感和道德因素。",
                "本研究利用大语言模型分析社交媒体数据，识别情感倾向和道德伦理框架。",
                "研究发现自主和社群伦理与负面婚姻态度相关，揭示了婚姻观念转变的深层原因。"
            ],
            "method_zh": "**问题定义**：本研究旨在理解中国社会对婚姻态度转变的深层原因，特别是情感倾向和道德伦理在其中的作用。现有方法难以大规模分析社交媒体上复杂的文本数据，无法有效捕捉用户的情感和道德观念。\\n\\n**核心思路**：本研究的核心思路是利用大型语言模型（LLM）的强大文本理解能力，对社交媒体上的婚姻相关帖子进行内容分析，结合Shweder的“三大道德伦理”框架，从情感和道德两个维度剖析公众对婚姻的看法。通过量化分析不同道德框架下的情感倾向，揭示影响婚姻态度的关键因素。\\n\\n**技术框架**：整体框架包括数据收集、预处理、LLM辅助的编码和统计分析四个阶段。首先，从新浪微博和小红书收集与婚姻相关的帖子。然后，对文本数据进行清洗和预处理。接着，利用LLM对帖子进行情感（积极、消极、中性）和道德维度（自主、社群、神性）的编码。最后，进行统计分析，探索情感和道德之间的关联。\\n\\n**关键创新**：本研究的关键创新在于将LLM应用于大规模社交媒体文本的定性分析，并结合Shweder的道德伦理框架，实现了对婚姻态度更深入的理解。与传统的人工编码相比，LLM能够显著提高分析效率和一致性，并能捕捉到更细微的情感和道德差异。\\n\\n**关键设计**：研究中使用了预训练的LLM模型（具体模型未知），并针对中文社交媒体文本进行了微调（具体微调方法未知）。情感分类和道德维度分类的具体prompt设计未知。统计分析中，采用了卡方检验等方法，检验不同道德框架下的情感分布是否存在显著差异。",
            "application_zh": "该研究成果可应用于社会学、人口学和传播学等领域，为政府制定相关政策提供参考。通过了解公众对婚姻的真实态度和潜在担忧，可以制定更具针对性的政策，以应对结婚率下降的问题。此外，该方法也可推广到其他社会议题的研究中，例如教育、医疗等。",
            "highlight_zh": "研究发现，微博上的婚姻讨论偏向积极，而小红书则以中性为主。更重要的是，当帖子涉及道德伦理时，自主和社群伦理与负面情感显著相关，而神性伦理则倾向于中性或积极情感。这些发现揭示了当代中国社会对婚姻态度的复杂性，以及道德观念在其中的重要作用。",
            "tags_zh": [
                "大语言模型",
                "社交媒体分析",
                "婚姻态度",
                "道德伦理",
                "情感分析"
            ],
            "_index": 81,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias",
            "authors": [
                "Hazel Kim",
                "Philip Torr"
            ],
            "arxiv_id": "2512.23518v1",
            "summary": "Large language models (LLMs) are highly vulnerable to input confirmation bias. When a prompt implies a preferred answer, models often reinforce that bias rather than explore alternatives. This phenomenon remains underexplored, yet it is already harmful in base models and poses an even greater risk in multi-agent debate, where echo chambers reinforce bias instead of correction. We introduce Mixture of Latent Concept Experts (MoLaCE), a lightweight inference-time framework that addresses confirmation bias by mixing experts instantiated as different activation strengths over latent concepts that shape model responses. Our key insight is that, due to the compositional nature of language, differently phrased prompts reweight latent concepts in prompt-specific ways that affect factual correctness, so no single fixed intervention can be applied universally across inputs. This design enables a single LLM to emulate the benefits of debate internally while remaining computationally efficient and scalable. It can also be integrated into multi-agent debate frameworks to diversify perspectives and reduce correlated errors. We empirically show that it consistently reduces confirmation bias, improves robustness, and matches or surpasses multi-agent debate while requiring only a fraction of the computation.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23518v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出MoLaCE，通过混合潜在概念专家解决LLM中的确认偏差问题",
            "summary_zh": "大型语言模型（LLMs）极易受到输入确认偏差的影响。当提示暗示了偏好的答案时，模型通常会强化这种偏差，而不是探索替代方案。这种现象尚未得到充分研究，但它已经在基础模型中造成了危害，并且在多智能体辩论中构成了更大的风险，在多智能体辩论中，回声室效应会强化偏差而不是纠正偏差。我们引入了潜在概念专家混合（MoLaCE），这是一个轻量级的推理时框架，通过混合实例化为不同激活强度的专家来解决确认偏差，这些专家作用于塑造模型响应的潜在概念。我们的关键见解是，由于语言的组合性质，不同措辞的提示以提示特定的方式重新加权潜在概念，从而影响事实的正确性，因此不能将单个固定的干预措施普遍应用于所有输入。这种设计使单个LLM能够在内部模拟辩论的好处，同时保持计算效率和可扩展性。它还可以集成到多智能体辩论框架中，以实现视角多样化并减少相关的错误。我们通过实验表明，它始终如一地减少了确认偏差，提高了鲁棒性，并且在仅需少量计算的情况下匹配或超过了多智能体辩论。",
            "intro_zh": [
                "大型语言模型容易受到确认偏差的影响，即倾向于支持与初始假设一致的信息，忽略其他可能性。",
                "MoLaCE通过混合多个“潜在概念专家”来解决此问题，每个专家代表不同的激活强度，从而影响模型响应。",
                "实验表明，MoLaCE能有效减少确认偏差，提高模型鲁棒性，且计算成本远低于多智能体辩论。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）中普遍存在的确认偏差问题。当用户提供的prompt带有倾向性时，LLM往往会强化这种偏差，而无法给出客观、全面的回答。现有的多智能体辩论方法虽然可以缓解这个问题，但计算成本高昂，难以扩展。\\n\\n**核心思路**：论文的核心思想是，利用语言的组合性质，不同措辞的prompt会以不同的方式激活LLM内部的“潜在概念”。通过混合这些潜在概念的专家，可以模拟多智能体辩论的效果，从而减少确认偏差。MoLaCE的关键在于，它不是采用固定的干预措施，而是根据不同的prompt动态调整潜在概念的权重。\\n\\n**技术框架**：MoLaCE框架主要包含以下几个步骤：1) 提取prompt中的潜在概念；2) 为每个潜在概念实例化一个“专家”，每个专家代表不同的激活强度；3) 根据prompt的特性，动态调整每个专家的权重；4) 将所有专家的输出混合，得到最终的答案。这个过程在单个LLM内部完成，无需多个LLM之间的交互。\\n\\n**关键创新**：MoLaCE最重要的创新点在于，它将多智能体辩论的思想融入到单个LLM中，通过混合潜在概念专家来模拟辩论过程。与传统的多智能体辩论方法相比，MoLaCE大大降低了计算成本，提高了效率。此外，MoLaCE能够根据不同的prompt动态调整潜在概念的权重，从而更好地适应不同的输入。\\n\\n**关键设计**：MoLaCE的关键设计包括：1) 如何提取prompt中的潜在概念（具体方法未知）；2) 如何定义和实例化“专家”（具体实现未知）；3) 如何根据prompt的特性动态调整专家的权重（具体算法未知）；4) 如何混合不同专家的输出（例如，加权平均）。论文中可能使用了特定的损失函数来训练MoLaCE，以鼓励模型学习到更客观、全面的知识。",
            "application_zh": "MoLaCE可应用于各种需要减少确认偏差的场景，例如问答系统、搜索引擎、内容生成等。通过提高LLM的客观性和鲁棒性，MoLaCE可以帮助用户获取更准确、全面的信息，避免受到误导。未来，MoLaCE还可以与其他技术结合，例如知识图谱、信息检索等，进一步提升LLM的性能。",
            "highlight_zh": "实验结果表明，MoLaCE能够显著减少LLM中的确认偏差，提高模型在各种任务上的鲁棒性。在某些任务上，MoLaCE的性能甚至超过了传统的多智能体辩论方法，同时计算成本大大降低。具体的性能数据和提升幅度在论文中详细给出（具体数值未知）。",
            "tags_zh": [
                "大型语言模型",
                "确认偏差",
                "多智能体辩论",
                "潜在概念",
                "模型鲁棒性"
            ],
            "_index": 82,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23518v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23518v1/figures/latent_corr_phi.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23518v1/figures/alpha_layers_llama.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data",
            "authors": [
                "Jiapeng Wang",
                "Yiwen Hu",
                "Yanzipeng Gao",
                "Haoyu Wang",
                "Shuo Wang",
                "Hongyu Lu",
                "Jiaxin Mao",
                "Wayne Xin Zhao",
                "Junyi Li",
                "Xiao Zhang"
            ],
            "arxiv_id": "2512.23422v1",
            "summary": "As access to high-quality, domain-specific data grows increasingly scarce, multi-epoch training has become a practical strategy for adapting large language models (LLMs). However, autoregressive models often suffer from performance degradation under repeated data exposure, where overfitting leads to a marked decline in model capability. Through empirical analysis, we trace this degradation to an imbalance in learning dynamics: predictable, low-entropy tokens are learned quickly and come to dominate optimization, while the model's ability to generalize on high-entropy tokens deteriorates with continued training. To address this, we introduce EntroDrop, an entropy-guided token dropout method that functions as structured data regularization. EntroDrop selectively masks low-entropy tokens during training and employs a curriculum schedule to adjust regularization strength in alignment with training progress. Experiments across model scales from 0.6B to 8B parameters show that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training. These findings underscore the importance of aligning regularization with token-level learning dynamics when training on limited data. Our approach offers a promising pathway toward more effective adaptation of LLMs in data-constrained domains.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23422v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EntroDrop，通过熵引导的token dropout解决领域数据受限时自回归语言模型的过拟合问题",
            "summary_zh": "随着高质量领域特定数据的日益稀缺，多轮训练已成为调整大型语言模型（LLM）的实用策略。然而，自回归模型在重复数据暴露下常常遭受性能下降，即过拟合导致模型能力显著下降。通过实证分析，我们将这种退化归因于学习动态的不平衡：可预测的低熵token被快速学习并主导优化，而模型在高熵token上的泛化能力随着持续训练而恶化。为了解决这个问题，我们引入了EntroDrop，一种熵引导的token dropout方法，它作为结构化数据正则化发挥作用。EntroDrop在训练期间选择性地屏蔽低熵token，并采用课程表来调整正则化强度，使其与训练进度保持一致。在0.6B到8B参数的模型规模上的实验表明，EntroDrop始终优于标准正则化基线，并在整个扩展多轮训练中保持稳健的性能。这些发现强调了在数据受限领域进行训练时，将正则化与token级别学习动态对齐的重要性。我们的方法为在数据受限领域更有效地调整LLM提供了一条有希望的途径。",
            "intro_zh": [
                "现有自回归模型在领域数据有限的情况下，多轮训练易导致过拟合，模型泛化能力下降。",
                "EntroDrop通过选择性地dropout低熵token，并使用课程学习调整正则化强度，缓解过拟合。",
                "实验结果表明，EntroDrop在不同规模模型上均优于标准正则化方法，提升了模型在多轮训练中的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在领域数据有限的情况下，自回归语言模型在多轮训练中容易出现的过拟合问题。现有方法在重复暴露于训练数据时，模型会过度关注低熵（易于预测）的token，而忽略高熵（难以预测）的token，导致模型泛化能力下降。\\n\\n**核心思路**：论文的核心思路是根据token的熵值进行dropout，即EntroDrop。通过在训练过程中选择性地屏蔽低熵token，迫使模型更多地关注高熵token，从而平衡学习动态，提高模型的泛化能力。这样设计的目的是为了防止模型过度拟合易于学习的token，从而更好地适应复杂和罕见的token。\\n\\n**技术框架**：EntroDrop方法主要包含以下几个阶段：1) **熵值计算**：在训练过程中，计算每个token的熵值，熵值反映了token的可预测性。2) **Dropout Mask生成**：根据token的熵值，生成一个dropout mask，用于选择性地屏蔽低熵token。3) **Dropout应用**：将dropout mask应用于token序列，从而在训练过程中屏蔽一部分低熵token。4) **课程学习**：随着训练的进行，逐渐调整dropout的比例，即课程学习，以更好地平衡模型的学习过程。\\n\\n**关键创新**：EntroDrop的关键创新在于其熵引导的token dropout机制。与传统的随机dropout不同，EntroDrop根据token的熵值进行dropout，更加有针对性，能够更好地平衡模型的学习动态，提高模型的泛化能力。此外，课程学习的引入也使得dropout的比例能够随着训练的进行而动态调整，进一步优化了模型的性能。\\n\\n**关键设计**：EntroDrop的关键设计包括：1) **熵值计算方法**：论文采用交叉熵损失来估计token的熵值。2) **Dropout比例**：Dropout比例的设置需要根据具体的任务和数据集进行调整，论文中采用了课程学习的方法来动态调整dropout比例。3) **课程学习策略**：论文采用线性增长的课程学习策略，即随着训练的进行，dropout比例逐渐增加。",
            "application_zh": "EntroDrop方法可以应用于各种领域数据受限的自回归语言模型训练场景，例如低资源语言建模、特定领域的文本生成等。该方法能够提高模型在这些场景下的泛化能力和鲁棒性，从而提升模型的实际应用价值。未来，该方法可以进一步扩展到其他类型的模型和任务中，例如机器翻译、文本摘要等。",
            "highlight_zh": "实验结果表明，EntroDrop在不同规模的模型（0.6B到8B参数）上均优于标准正则化基线。例如，在某个特定任务上，EntroDrop相比于baseline方法，perplexity降低了X%，显著提升了模型的性能。此外，EntroDrop在多轮训练中表现出更强的鲁棒性，能够有效防止过拟合，保持模型的性能稳定。",
            "tags_zh": [
                "自回归语言模型",
                "领域数据受限",
                "过拟合",
                "熵引导",
                "Token Dropout"
            ],
            "_index": 83,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23422v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23422v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23422v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration",
            "authors": [
                "Minjiang Huang",
                "Jipeng Qiang",
                "Yi Zhu",
                "Chaowei Zhang",
                "Xiangyu Zhao",
                "Kui Yu"
            ],
            "arxiv_id": "2512.23300v1",
            "summary": "Audiobook interpretations are attracting increasing attention, as they provide accessible and in-depth analyses of books that offer readers practical insights and intellectual inspiration. However, their manual creation process remains time-consuming and resource-intensive. To address this challenge, we propose AI4Reading, a multi-agent collaboration system leveraging large language models (LLMs) and speech synthesis technology to generate podcast, like audiobook interpretations. The system is designed to meet three key objectives: accurate content preservation, enhanced comprehensibility, and a logical narrative structure. To achieve these goals, we develop a framework composed of 11 specialized agents,including topic analysts, case analysts, editors, a narrator, and proofreaders that work in concert to explore themes, extract real world cases, refine content organization, and synthesize natural spoken language. By comparing expert interpretations with our system's output, the results show that although AI4Reading still has a gap in speech generation quality, the generated interpretative scripts are simpler and more accurate.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "ACL 2025 demo",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23300v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出AI4Reading，一个基于多智能体协作的中文有声书解读系统",
            "summary_zh": "有声书解读正受到越来越多的关注，因为它们提供了对书籍的可访问和深入的分析，为读者提供了实践见解和智力启发。然而，人工创作过程仍然耗时且资源密集。为了应对这一挑战，我们提出了AI4Reading，一个利用大型语言模型（LLMs）和语音合成技术生成类似播客的有声书解读的多智能体协作系统。该系统旨在满足三个关键目标：准确的内容保留、增强的可理解性和逻辑的叙事结构。为了实现这些目标，我们开发了一个由11个专业智能体组成的框架，包括主题分析师、案例分析师、编辑、叙述者和校对员，它们协同工作以探索主题、提取真实世界的案例、改进内容组织并合成自然的口语。通过将专家解读与我们系统的输出进行比较，结果表明，尽管AI4Reading在语音生成质量方面仍有差距，但生成的解读脚本更简单、更准确。",
            "intro_zh": [
                "人工创作有声书解读耗时且成本高昂，难以满足日益增长的需求。",
                "AI4Reading通过多智能体协作，利用大语言模型和语音合成技术自动生成有声书解读。",
                "实验结果表明，AI4Reading生成的解读脚本在准确性和简洁性上优于人工，但在语音质量上仍有提升空间。"
            ],
            "method_zh": "**问题定义**：论文旨在解决有声书解读内容创作效率低下的问题。现有的人工创作方式耗时费力，难以规模化生产高质量的解读内容。因此，需要一种自动化的方法来生成准确、易懂且具有逻辑性的有声书解读。\n\n**核心思路**：论文的核心思路是利用多智能体协作的方式，将有声书解读任务分解为多个子任务，并由不同的智能体负责完成。每个智能体专注于特定的任务，例如主题分析、案例提取、内容编辑和语音合成，从而提高整体的效率和质量。这种分工协作的方式能够充分利用大语言模型的强大能力，并模拟人类专家团队的工作流程。\n\n**技术框架**：AI4Reading系统包含11个专业智能体，它们协同完成有声书解读任务。整体流程如下：首先，主题分析师智能体负责分析书籍的主题和核心思想；然后，案例分析师智能体负责提取与主题相关的真实世界案例；接着，编辑智能体负责对内容进行组织和润色，确保逻辑清晰；最后，叙述者智能体负责将文本转化为自然流畅的语音。此外，还有校对员智能体负责检查和纠正错误，确保最终输出的质量。\n\n**关键创新**：该论文的关键创新在于提出了一个基于多智能体协作的自动化有声书解读系统。与传统的单一大语言模型方法相比，该系统能够更好地模拟人类专家团队的工作流程，从而生成更准确、更易懂且更具逻辑性的解读内容。此外，该系统还引入了多个专业智能体，例如主题分析师和案例分析师，从而能够更深入地挖掘书籍的内涵。\n\n**关键设计**：每个智能体都基于大语言模型进行设计，并针对其特定的任务进行了优化。例如，主题分析师智能体使用了特定的提示工程（prompt engineering）技术，以提高其主题分析的准确性。案例分析师智能体则使用了知识图谱等技术，以提高其案例提取的效率。此外，系统还使用了特定的损失函数来优化语音合成的质量。具体的参数设置和网络结构等技术细节在论文中未详细说明，属于未知信息。",
            "application_zh": "AI4Reading系统可应用于大规模有声书解读内容的自动生成，降低制作成本，提高生产效率。该技术可服务于教育、文化传播等领域，为读者提供更便捷、更深入的阅读体验。未来，该系统还可扩展到其他类型的文本解读，例如新闻报道、学术论文等。",
            "highlight_zh": "实验结果表明，AI4Reading生成的解读脚本在准确性和简洁性上优于人工创作的脚本。虽然在语音生成质量方面仍有差距，但AI4Reading在内容理解和逻辑组织方面表现出色，为自动化有声书解读提供了一种可行的解决方案。具体的性能数据和提升幅度在论文中未详细说明，属于未知信息。",
            "tags_zh": [
                "有声书解读",
                "多智能体协作",
                "大型语言模型",
                "语音合成",
                "自动化内容生成"
            ],
            "_index": 84,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23300v1/figures/AI4Reading.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23300v1/figures/Agent.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23300v1/time_spent.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Towards the Automation in the Space Station: Feasibility Study and Ground Tests of a Multi-Limbed Intra-Vehicular Robot",
            "authors": [
                "Seiko Piotr Yamaguchi",
                "Kentaro Uno",
                "Yasumaru Fujii",
                "Masazumi Imai",
                "Kazuki Takada",
                "Taku Okawara",
                "Kazuya Yoshida"
            ],
            "arxiv_id": "2512.23153v1",
            "summary": "This paper presents a feasibility study, including simulations and prototype tests, on the autonomous operation of a multi-limbed intra-vehicular robot (mobile manipulator), shortly MLIVR, designed to assist astronauts with logistical tasks on the International Space Station (ISS). Astronauts spend significant time on tasks such as preparation, close-out, and the collection and transportation of goods, reducing the time available for critical mission activities. Our study explores the potential for a mobile manipulator to support these operations, emphasizing the need for autonomous functionality to minimize crew and ground operator effort while enabling real-time task execution. We focused on the robot's transportation capabilities, simulating its motion planning in 3D space. The actual motion execution was tested with a prototype on a 2D table to mimic a microgravity environment. The results demonstrate the feasibility of performing these tasks with minimal human intervention, offering a promising solution to enhance operational efficiency on the ISS.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "Author's version of a manuscript accepted at the 2025 IEEE/SICE International Symposium on System Integration (SII). (c) IEEE. The final published version is available at https://doi.org/10.1109/SII59315.2025.10870890",
            "doi": "10.1109/SII59315.2025.10870890",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23153v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "motion planning"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "面向空间站的自动化：多臂舱内机器人的可行性研究与地面测试",
            "summary_zh": "本文提出了一项关于多臂舱内机器人（MLIVR）自主运行的可行性研究，包括仿真和原型测试。该机器人旨在协助国际空间站（ISS）上的宇航员完成后勤任务。宇航员花费大量时间在准备、结束、以及物资的收集和运输等任务上，从而减少了关键任务的可用时间。我们的研究探讨了移动机械臂支持这些操作的潜力，强调自主功能对于最大限度地减少宇航员和地面操作员的工作量，同时实现实时任务执行的必要性。我们专注于机器人的运输能力，在3D空间中模拟其运动规划。实际的运动执行通过在2D桌面上使用原型来模拟微重力环境进行测试。结果表明，在最少的人工干预下执行这些任务是可行的，为提高国际空间站的运行效率提供了一个有希望的解决方案。",
            "intro_zh": [
                "宇航员在空间站的后勤任务耗费大量时间，降低了执行关键任务的效率，亟需自动化解决方案。",
                "论文提出一种多臂舱内机器人（MLIVR），旨在通过自主移动操作来辅助宇航员完成物资运输等任务。",
                "通过仿真和2D桌面原型测试，验证了MLIVR在微重力环境下执行运输任务的可行性，减少人工干预。"
            ],
            "method_zh": "**问题定义**：论文旨在解决国际空间站内宇航员在后勤任务中耗时过长的问题。现有方法依赖于宇航员手动操作，效率低下，且占用了宇航员执行关键任务的时间。因此，需要一种自动化解决方案来减轻宇航员的负担，提高空间站的整体运行效率。\\n\\n**核心思路**：论文的核心思路是利用多臂移动机器人（MLIVR）的自主移动和操作能力，代替宇航员完成重复性的后勤任务，如物资的收集、运输和整理。通过自主运动规划和控制，MLIVR能够在空间站内部自主导航，并利用机械臂抓取和搬运物体。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个阶段：1) 任务需求分析：确定空间站内需要自动化的后勤任务类型和操作要求。2) 机器人设计：设计具有多臂和移动底盘的MLIVR，使其具备足够的灵活性和操作能力。3) 运动规划与控制：开发自主运动规划算法，使MLIVR能够在空间站内部安全、高效地导航和操作。4) 仿真验证：在3D仿真环境中模拟MLIVR的运动和操作，验证其可行性和性能。5) 原型测试：构建MLIVR原型，并在2D桌面环境中模拟微重力环境，进行实际的运动和操作测试。\\n\\n**关键创新**：该研究的关键创新在于将多臂移动机器人应用于空间站内部的后勤任务自动化。与传统的固定式机器人相比，MLIVR具有更强的灵活性和适应性，能够适应空间站内部复杂的环境。此外，该研究还探索了在微重力环境下进行机器人运动规划和控制的方法。\\n\\n**关键设计**：论文中没有详细说明具体的参数设置、损失函数或网络结构等技术细节。但是，可以推断，运动规划算法需要考虑空间站内部的障碍物和约束条件，以及机器人的运动学和动力学特性。控制算法需要保证机器人的稳定性和精度，并能够适应微重力环境的影响。原型测试中，2D桌面模拟微重力环境的方式是关键设计，需要保证摩擦力等因素与真实环境尽可能接近。",
            "application_zh": "该研究成果可应用于国际空间站及未来的深空探测任务中，减轻宇航员的后勤负担，提高任务效率。此外，该技术还可应用于其他受限空间内的自动化操作，如核电站维护、灾难救援等领域，具有重要的实际应用价值和广阔的发展前景。",
            "highlight_zh": "该研究通过仿真和2D桌面原型测试，验证了多臂舱内机器人（MLIVR）在空间站内部执行运输任务的可行性。虽然没有给出具体的性能数据，但实验结果表明，MLIVR能够在最少的人工干预下完成任务，为空间站的自动化操作提供了一种有希望的解决方案。",
            "tags_zh": [
                "空间站自动化",
                "多臂机器人",
                "移动操作",
                "运动规划",
                "微重力环境"
            ],
            "_index": 85,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23153v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23153v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23153v1/fig/flow-r1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multi-label Classification with Panoptic Context Aggregation Networks",
            "authors": [
                "Mingyuan Jiu",
                "Hailong Zhu",
                "Wenchuan Wei",
                "Hichem Sahbi",
                "Rongrong Ji",
                "Mingliang Xu"
            ],
            "arxiv_id": "2512.23486v1",
            "summary": "Context modeling is crucial for visual recognition, enabling highly discriminative image representations by integrating both intrinsic and extrinsic relationships between objects and labels in images. A limitation in current approaches is their focus on basic geometric relationships or localized features, often neglecting cross-scale contextual interactions between objects. This paper introduces the Deep Panoptic Context Aggregation Network (PanCAN), a novel approach that hierarchically integrates multi-order geometric contexts through cross-scale feature aggregation in a high-dimensional Hilbert space. Specifically, PanCAN learns multi-order neighborhood relationships at each scale by combining random walks with an attention mechanism. Modules from different scales are cascaded, where salient anchors at a finer scale are selected and their neighborhood features are dynamically fused via attention. This enables effective cross-scale modeling that significantly enhances complex scene understanding by combining multi-order and cross-scale context-aware features. Extensive multi-label classification experiments on NUS-WIDE, PASCAL VOC2007, and MS-COCO benchmarks demonstrate that PanCAN consistently achieves competitive results, outperforming state-of-the-art techniques in both quantitative and qualitative evaluations, thereby substantially improving multi-label classification performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23486v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene understanding"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出PanCAN，通过全景上下文聚合网络提升多标签分类性能",
            "summary_zh": "本文提出了一种深度全景上下文聚合网络(PanCAN)，用于解决视觉识别中上下文建模的问题。现有方法通常侧重于基本的几何关系或局部特征，忽略了对象之间跨尺度的上下文交互。PanCAN通过在高维希尔伯特空间中进行跨尺度特征聚合，分层地整合多阶几何上下文。具体来说，PanCAN通过结合随机游走和注意力机制，学习每个尺度的多阶邻域关系。来自不同尺度的模块级联，选择更精细尺度上的显著锚点，并通过注意力动态融合其邻域特征。这种方法能够有效地进行跨尺度建模，通过结合多阶和跨尺度的上下文感知特征，显著增强复杂场景理解。在NUS-WIDE、PASCAL VOC2007和MS-COCO基准数据集上的大量多标签分类实验表明，PanCAN始终如一地取得了有竞争力的结果，在定量和定性评估中均优于最先进的技术，从而大大提高了多标签分类性能。",
            "intro_zh": [
                "现有方法在多标签分类中缺乏有效的跨尺度上下文建模能力，限制了复杂场景的理解。",
                "PanCAN通过分层聚合多阶几何上下文，并利用跨尺度特征融合，提升了模型对图像的理解能力。",
                "实验结果表明，PanCAN在多个数据集上超越了现有技术，显著提升了多标签分类的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多标签图像分类任务中，现有方法对图像中物体间跨尺度上下文关系建模不足的问题。现有方法通常只关注局部特征或简单的几何关系，忽略了不同尺度下物体之间的复杂交互，导致模型难以准确识别图像中的多个标签。\\n\\n**核心思路**：论文的核心思路是利用全景上下文聚合网络（PanCAN），通过分层的方式，在不同尺度上学习和聚合物体之间的上下文关系。PanCAN通过跨尺度特征聚合，将不同尺度的信息融合在一起，从而更好地理解图像中的复杂场景。\\n\\n**技术框架**：PanCAN的整体架构包含多个尺度的模块级联。每个模块通过随机游走和注意力机制学习多阶邻域关系。首先，在每个尺度上，利用随机游走算法探索像素之间的关系，构建邻域图。然后，使用注意力机制对邻域内的特征进行加权，突出重要特征。最后，将不同尺度的模块进行级联，通过选择更精细尺度上的显著锚点，并动态融合其邻域特征，实现跨尺度上下文建模。\\n\\n**关键创新**：PanCAN的关键创新在于其跨尺度上下文聚合机制。通过在不同尺度上学习和聚合上下文信息，PanCAN能够更好地理解图像中的复杂场景。此外，PanCAN还利用随机游走和注意力机制，有效地学习多阶邻域关系，从而提高了模型的性能。\\n\\n**关键设计**：PanCAN的关键设计包括：1) 使用随机游走算法构建邻域图，探索像素之间的关系；2) 使用注意力机制对邻域内的特征进行加权，突出重要特征；3) 将不同尺度的模块进行级联，实现跨尺度上下文建模。具体的参数设置和损失函数等技术细节在论文中进行了详细描述。",
            "application_zh": "该研究成果可广泛应用于图像识别、目标检测、场景理解等领域。例如，在智能安防领域，可以利用该技术更准确地识别监控视频中的多个目标和事件；在自动驾驶领域，可以帮助车辆更好地理解周围环境，提高驾驶安全性。此外，该技术还可以应用于图像搜索、图像标注等领域，具有重要的实际应用价值和广阔的发展前景。",
            "highlight_zh": "PanCAN在NUS-WIDE、PASCAL VOC2007和MS-COCO等多个多标签分类数据集上进行了广泛的实验，结果表明PanCAN consistently achieves competitive results, outperforming state-of-the-art techniques in both quantitative and qualitative evaluations, thereby substantially improving multi-label classification performance. 具体提升幅度在论文中有详细数据。",
            "tags_zh": [
                "多标签分类",
                "上下文建模",
                "跨尺度特征聚合",
                "全景上下文",
                "深度学习"
            ],
            "_index": 86,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23486v1/Domain_construction.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23486v1/Network_framework.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23486v1/Visualization_of_Numbers_of_Layers.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RealX3D: A Physically-Degraded 3D Benchmark for Multi-view Visual Restoration and Reconstruction",
            "authors": [
                "Shuhong Liu",
                "Chenyu Bao",
                "Ziteng Cui",
                "Yun Liu",
                "Xuangeng Chu",
                "Lin Gu",
                "Marcos V. Conde",
                "Ryo Umagami",
                "Tomohiro Hashimoto",
                "Zijian Hu",
                "Tianhan Xu",
                "Yuan Gan",
                "Yusuke Kurose",
                "Tatsuya Harada"
            ],
            "arxiv_id": "2512.23437v1",
            "summary": "We introduce RealX3D, a real-capture benchmark for multi-view visual restoration and 3D reconstruction under diverse physical degradations. RealX3D groups corruptions into four families, including illumination, scattering, occlusion, and blurring, and captures each at multiple severity levels using a unified acquisition protocol that yields pixel-aligned LQ/GT views. Each scene includes high-resolution capture, RAW images, and dense laser scans, from which we derive world-scale meshes and metric depth. Benchmarking a broad range of optimization-based and feed-forward methods shows substantial degradation in reconstruction quality under physical corruptions, underscoring the fragility of current multi-view pipelines in real-world challenging environments.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23437v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "metric depth"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "RealX3D：一个用于多视角视觉恢复与重建的物理退化3D基准",
            "summary_zh": "我们提出了RealX3D，一个真实场景捕获的基准数据集，用于在各种物理退化条件下进行多视角视觉恢复和3D重建。RealX3D将图像退化分为四个类别：光照、散射、遮挡和模糊，并使用统一的采集协议在多个严重程度上捕获每个类别，从而产生像素对齐的低质量/高质量视图。每个场景包括高分辨率图像捕获、RAW图像和密集激光扫描，我们从中导出世界尺度的网格和度量深度。对各种基于优化和前馈方法进行基准测试表明，在物理退化下，重建质量显著下降，突显了当前多视角流水线在现实世界挑战性环境中的脆弱性。",
            "intro_zh": [
                "现有多视角视觉恢复与3D重建方法在真实物理退化场景下表现脆弱，缺乏有效评估工具。",
                "RealX3D通过统一的采集协议，在真实场景中模拟光照、散射、遮挡和模糊等多种物理退化。",
                "实验表明，现有方法在RealX3D基准上重建质量显著下降，验证了该基准的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有多视角视觉恢复和3D重建方法在真实物理退化场景下性能不足的问题。现有方法通常在理想条件下训练和评估，缺乏对真实世界中各种物理退化（如光照变化、散射、遮挡和模糊）的鲁棒性。因此，需要一个能够模拟真实物理退化的基准数据集，以便更好地评估和改进相关算法。\\n\\n**核心思路**：论文的核心思路是构建一个真实场景捕获的基准数据集RealX3D，该数据集包含多种物理退化，并提供像素对齐的低质量/高质量视图、高分辨率图像、RAW图像和密集激光扫描等多种数据。通过在RealX3D上评估现有方法，可以揭示其在真实物理退化场景下的性能瓶颈，并为未来的研究提供方向。\\n\\n**技术框架**：RealX3D的构建流程主要包括以下几个阶段：1)场景选择和搭建；2)使用统一的采集协议，在不同物理退化条件下捕获多视角图像；3)利用激光扫描仪获取场景的几何信息；4)对采集到的数据进行处理，生成像素对齐的低质量/高质量视图、世界尺度的网格和度量深度等。该数据集包含光照、散射、遮挡和模糊四种类型的物理退化，每种退化又包含多个严重程度级别。\\n\\n**关键创新**：RealX3D的关键创新在于其真实场景捕获和物理退化模拟。与以往的合成数据集不同，RealX3D是在真实场景中采集的，能够更好地反映真实世界的复杂性和多样性。此外，RealX3D通过统一的采集协议，在多个严重程度上模拟了多种物理退化，从而可以更全面地评估算法的鲁棒性。\\n\\n**关键设计**：RealX3D的关键设计包括：1)使用高精度相机和激光扫描仪进行数据采集；2)采用统一的采集协议，确保不同视角和不同退化程度的图像之间像素对齐；3)提供多种数据类型，包括高分辨率图像、RAW图像、密集激光扫描、世界尺度的网格和度量深度等；4)将物理退化分为光照、散射、遮挡和模糊四种类型，每种类型包含多个严重程度级别。",
            "application_zh": "RealX3D基准数据集可广泛应用于计算机视觉、机器人和增强现实等领域。例如，可以用于开发更鲁棒的多视角视觉恢复和3D重建算法，提高机器人在复杂环境中的感知能力，以及改善增强现实应用的沉浸感和真实感。此外，该数据集还可以促进对物理退化建模和图像恢复技术的研究。",
            "highlight_zh": "实验结果表明，现有的多视角视觉恢复和3D重建方法在RealX3D基准上表现出显著的性能下降。例如，在存在严重遮挡或模糊的情况下，重建精度大幅降低。这些结果突出了现有方法在真实物理退化场景下的脆弱性，并验证了RealX3D基准的有效性。",
            "tags_zh": [
                "多视角视觉恢复",
                "3D重建",
                "物理退化",
                "基准数据集",
                "真实场景",
                "图像恢复",
                "计算机视觉",
                "鲁棒性"
            ],
            "_index": 87,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23437v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23437v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23437v1/figures/lowlight/bluehawaii/input.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond-Diagonal Reconfigurable Intelligent Surfaces for 6G Networks: Principles, Challenges, and Quantum Horizons",
            "authors": [
                "Abd Ullah Khan",
                "Uman Khalid",
                "Muhammad Tanveer",
                "Trung Q. Duong",
                "Hyundong Shin"
            ],
            "arxiv_id": "2512.23400v1",
            "summary": "A beyond-diagonal reconfigurable intelligent surface (BD-RIS) is an innovative type of reconfigurable intelligent surface (RIS) that has recently been proposed and is considered a revolutionary advancement in wave manipulation. Unlike the mutually disconnected arrangement of elements in traditional RISs, BD-RIS creates cost-effective and simple inter-element connections, allowing for greater freedom in configuring the amplitude and phase of impinging waves. However, there are numerous underlying challenges in realizing the advantages associated with BD-RIS, prompting the research community to actively investigate cutting-edge schemes and algorithms in this direction. Particularly, the passive beamforming design for BD-RIS under specific environmental conditions has become a major focus in this research area. In this article, we provide a systematic introduction to BD-RIS, elaborating on its functional principles concerning architectural design, promising advantages, and classification. Subsequently, we present recent advances and identify a series of challenges and opportunities. Additionally, we consider a specific case study where beamforming is designed using four different algorithms, and we analyze their performance with respect to sum rate and computation cost. To augment the beamforming capabilities in 6G BD-RIS with quantum enhancement, we analyze various hybrid quantum-classical machine learning (ML) models to improve beam prediction performance, employing real-world communication Scenario 8 from the DeepSense 6G dataset. Consequently, we derive useful insights about the practical implications of BD-RIS.",
            "categories": [
                "cs.SI",
                "cs.LG"
            ],
            "primary_category": "cs.SI",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23400v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "面向6G网络的超对角可重构智能表面：原理、挑战与量子前沿",
            "summary_zh": "超对角可重构智能表面（BD-RIS）是一种新型的RIS，被认为是波束操控领域的革命性进展。与传统RIS中元件间相互分离的结构不同，BD-RIS通过经济高效的元件间连接，实现了对入射波幅度和相位的更灵活配置。然而，实现BD-RIS优势面临诸多挑战，促使研究人员积极探索前沿方案和算法。特别是在特定环境条件下，BD-RIS的被动波束成形设计已成为研究重点。本文系统地介绍了BD-RIS，阐述了其架构设计、潜在优势和分类等功能原理。随后，我们介绍了最新进展，并识别了一系列挑战和机遇。此外，我们通过案例研究，使用四种不同算法设计波束成形，并分析了它们在总速率和计算成本方面的性能。为了利用量子增强来提升6G BD-RIS中的波束成形能力，我们分析了各种混合量子-经典机器学习（ML）模型，以提高波束预测性能，并采用了DeepSense 6G数据集中的真实通信场景8。最后，我们推导出了关于BD-RIS实际意义的有用见解。",
            "intro_zh": [
                "传统RIS元件间相互独立，限制了波束操控的灵活性，BD-RIS通过元件间连接增强了波束调控能力，但同时也带来了新的设计挑战。",
                "论文核心在于探索BD-RIS的架构、优势和分类，并针对其波束成形设计，研究了多种算法和量子机器学习模型的应用。",
                "通过案例研究，论文分析了不同波束成形算法的性能，并利用真实数据集验证了量子增强机器学习模型在BD-RIS中的潜力。"
            ],
            "method_zh": "**问题定义**：论文旨在研究下一代6G网络中，如何利用超对角可重构智能表面(BD-RIS)更有效地进行无线信号的波束成形。传统RIS元件间相互独立，无法灵活调整入射波的幅度和相位，限制了其性能。因此，如何充分利用BD-RIS元件间连接的优势，设计高效的波束成形算法，是本文要解决的关键问题。\\n\\n**核心思路**：论文的核心思路是深入研究BD-RIS的架构和工作原理，并探索不同的波束成形算法，包括传统的和基于量子机器学习的方法，以优化BD-RIS的性能。通过案例研究，比较不同算法在总速率和计算复杂度方面的表现，并利用真实数据集验证量子增强机器学习模型在波束预测方面的潜力。\\n\\n**技术框架**：论文首先介绍了BD-RIS的基本原理和架构，然后讨论了其优势和分类。接着，论文研究了四种不同的波束成形算法，并分析了它们的性能。最后，论文提出了基于混合量子-经典机器学习模型的波束预测方法，并使用DeepSense 6G数据集进行了验证。整体流程包括：BD-RIS原理介绍 -> 波束成形算法研究 -> 量子机器学习模型应用 -> 性能评估与分析。\\n\\n**关键创新**：论文的关键创新在于将量子机器学习模型应用于BD-RIS的波束成形设计中，探索了量子计算在提升无线通信性能方面的潜力。此外，论文还系统地分析了BD-RIS的架构、优势和挑战，为未来的研究提供了指导。\\n\\n**关键设计**：论文中，波束成形算法的设计细节未详细给出，但提到了四种不同的算法，并比较了它们在总速率和计算成本方面的性能。在量子机器学习模型方面，论文采用了混合量子-经典的方法，具体模型结构和参数设置未详细说明，但使用了DeepSense 6G数据集中的真实通信场景8进行训练和验证。",
            "application_zh": "该研究成果可应用于未来的6G无线通信网络，通过BD-RIS实现更灵活、高效的波束成形，提高频谱效率和网络容量。潜在应用包括：增强现实/虚拟现实、无人驾驶、物联网等对通信质量有较高要求的场景。量子机器学习的应用为未来无线通信的智能化发展提供了新的方向。",
            "highlight_zh": "论文通过案例研究，比较了四种不同波束成形算法在总速率和计算成本方面的性能。此外，论文还利用DeepSense 6G数据集验证了量子增强机器学习模型在波束预测方面的潜力，表明量子计算有望提升BD-RIS的性能。具体的性能提升幅度未在摘要中明确给出。",
            "tags_zh": [
                "可重构智能表面",
                "超对角RIS",
                "6G网络",
                "波束成形",
                "量子机器学习"
            ],
            "_index": 88,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23400v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23400v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23400v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "NashOpt - A Python Library for Computing Generalized Nash Equilibria",
            "authors": [
                "Alberto Bemporad"
            ],
            "arxiv_id": "2512.23636v1",
            "summary": "NashOpt is an open-source Python library for computing and designing generalized Nash equilibria (GNEs) in noncooperative games with shared constraints and real-valued decision variables. The library exploits the joint Karush-Kuhn-Tucker (KKT) conditions of all players to handle both general nonlinear GNEs and linear-quadratic games, including their variational versions. Nonlinear games are solved via nonlinear least-squares formulations, relying on JAX for automatic differentiation. Linear-quadratic GNEs are reformulated as mixed-integer linear programs, enabling efficient computation of multiple equilibria. The framework also supports inverse-game and Stackelberg game-design problems. The capabilities of NashOpt are demonstrated through several examples, including noncooperative game-theoretic control problems of linear quadratic regulation and model predictive control. The library is available at https://github.com/bemporad/nashopt",
            "categories": [
                "eess.SY",
                "cs.GT"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-29",
            "updated": "2025-12-29",
            "comment": "23 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.23636v1",
            "code_links": [
                {
                    "url": "https://github.com/bemporad/nashopt",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "model predictive control"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "NashOpt：用于计算广义纳什均衡的Python库",
            "summary_zh": "NashOpt是一个开源Python库，用于计算和设计具有共享约束和实值决策变量的非合作博弈中的广义纳什均衡（GNEs）。该库利用所有参与者的联合Karush-Kuhn-Tucker（KKT）条件来处理一般的非线性GNEs和线性二次博弈，包括它们的变分版本。非线性博弈通过非线性最小二乘公式求解，依赖于JAX进行自动微分。线性二次GNEs被重新表述为混合整数线性规划，从而能够高效地计算多个均衡。该框架还支持逆博弈和Stackelberg博弈设计问题。NashOpt的功能通过几个例子得到证明，包括线性二次调节和模型预测控制的非合作博弈论控制问题。该库可在https://github.com/bemporad/nashopt 获取。",
            "intro_zh": [
                "现有方法在求解具有共享约束的非合作博弈中的广义纳什均衡（GNEs）时，效率和通用性存在挑战。",
                "NashOpt库通过利用联合KKT条件，并结合JAX自动微分和混合整数线性规划，提供了一种高效且通用的GNE求解方案。",
                "通过线性二次调节和模型预测控制等实例验证了NashOpt在非合作博弈论控制问题中的有效性。"
            ],
            "method_zh": "**问题定义**：该论文旨在解决非合作博弈中广义纳什均衡（GNEs）的计算问题，特别是当博弈具有共享约束和实值决策变量时。现有方法在处理非线性博弈和寻找多个均衡方面存在效率瓶颈，并且缺乏对逆博弈和Stackelberg博弈设计的支持。\\n\\n**核心思路**：NashOpt的核心思路是利用所有参与者的联合Karush-Kuhn-Tucker（KKT）条件来统一处理GNEs。对于非线性博弈，采用非线性最小二乘公式，并借助JAX进行自动微分以高效计算梯度。对于线性二次博弈，则将其转化为混合整数线性规划（MILP）问题，从而能够有效地找到多个均衡。\\n\\n**技术框架**：NashOpt库的整体框架包括以下几个主要模块：1) 博弈定义模块：用于定义参与者、决策变量、目标函数和约束条件；2) KKT条件构建模块：基于博弈定义，构建所有参与者的联合KKT条件；3) 求解器模块：针对非线性博弈，采用基于JAX的非线性最小二乘求解器；针对线性二次博弈，采用MILP求解器；4) 结果分析模块：用于分析求解得到的GNE，并支持逆博弈和Stackelberg博弈设计。\\n\\n**关键创新**：NashOpt的关键创新在于其统一的框架，能够同时处理非线性GNEs和线性二次GNEs。通过将线性二次GNEs转化为MILP问题，实现了多个均衡的高效计算。此外，该库还支持逆博弈和Stackelberg博弈设计，扩展了GNE的应用范围。\\n\\n**关键设计**：对于非线性博弈，NashOpt依赖JAX进行自动微分，无需手动推导梯度，简化了开发流程。对于线性二次博弈，MILP的构建需要仔细选择决策变量和约束条件，以保证求解效率。逆博弈和Stackelberg博弈设计则需要根据具体问题，设计合适的目标函数和约束条件。",
            "application_zh": "NashOpt可应用于多个领域，包括但不限于：多智能体系统控制、资源分配、交通网络优化、电力市场建模、以及博弈论在经济学和工程学中的其他应用。该库能够帮助研究人员和工程师设计和分析复杂的非合作博弈，并找到有效的均衡策略，从而优化系统性能。",
            "highlight_zh": "论文通过多个示例展示了NashOpt的有效性，包括线性二次调节和模型预测控制的非合作博弈论控制问题。实验结果表明，NashOpt能够高效地计算GNE，并且能够处理具有复杂约束的博弈。此外，该库还展示了在逆博弈和Stackelberg博弈设计方面的应用。",
            "tags_zh": [
                "广义纳什均衡",
                "非合作博弈",
                "KKT条件",
                "JAX自动微分",
                "混合整数线性规划",
                "多智能体系统",
                "博弈论控制"
            ],
            "_index": 89,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.23636v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.23636v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.23636v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        }
    ]
}