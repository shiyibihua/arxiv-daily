{
    "papers": [
        {
            "title": "Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations",
            "authors": [
                "Aaron Kurda",
                "Simon Steuernagel",
                "Lukas Jung",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14428v1",
            "summary": "The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 4 figures, submitted to International Journal of Robotics Research (IJRR)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14428v1",
            "code_links": [],
            "headline_zh": "提出MemFlow方法，通过动态检索相关历史帧和激活相关token，解决流式视频生成中的长上下文一致性挑战。",
            "summary_zh": "流式视频生成的核心挑战在于维持长上下文中的内容一致性，这对内存设计提出了高要求。现有解决方案大多通过预定义策略压缩历史帧来维护内存，但不同待生成的视频块应参考不同的历史线索，固定策略难以满足这一需求。本文提出MemFlow来解决此问题。具体而言，在生成即将到来的视频块之前，我们通过检索与该块文本提示最相关的历史帧来动态更新内存库。这一设计使得即使未来帧中出现新事件或场景切换，也能保持叙事连贯性。此外，在生成过程中，我们仅激活内存库中与每个查询最相关的token，这有效保证了生成效率。通过这种方式，MemFlow在实现出色的长上下文一致性的同时，计算负担可忽略不计（与无内存基线相比速度仅降低7.9%），并保持与任何具有KV缓存的流式视频生成模型的兼容性。",
            "intro_zh": [
                "现有方法使用固定策略压缩历史帧，难以适应不同视频块对历史线索的差异化需求，导致长上下文一致性不足。",
                "MemFlow在生成前动态检索与文本提示最相关的历史帧更新内存，生成时仅激活相关token，实现自适应记忆管理。",
                "实验表明，MemFlow显著提升长视频叙事一致性，计算开销极小（速度仅降7.9%），兼容现有流式生成模型。"
            ],
            "method_zh": "MemFlow的整体框架基于流式视频生成模型，核心创新在于引入自适应记忆流机制。方法包括两个关键步骤：首先，在生成每个视频块前，根据当前文本提示从历史帧中动态检索最相关的内容，更新内存库，确保记忆与生成需求对齐；其次，在注意力层中，仅激活内存库中与查询最相关的token，减少计算冗余。与现有方法的主要区别在于，MemFlow摒弃了固定压缩策略，采用动态检索和选择性激活，实现了更灵活高效的长上下文管理。",
            "application_zh": "该研究可应用于长视频自动生成、影视制作辅助、游戏场景动态渲染等领域，提升叙事连贯性和效率，为多模态AI在创意产业中的实际部署提供技术支持。",
            "highlight_zh": "MemFlow在长上下文一致性方面表现突出，同时计算负担极低，与无内存基线相比速度仅降低7.9%，并保持与现有流式视频生成模型的兼容性，验证了其高效性和实用性。",
            "tags_zh": [
                "流式视频生成",
                "长上下文一致性",
                "自适应记忆",
                "动态检索",
                "注意力机制",
                "KV缓存",
                "多模态AI",
                "视频叙事"
            ],
            "_index": 0
        },
        {
            "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
            "authors": [
                "Yanning Dai",
                "Chenyu Tang",
                "Ruizhi Zhang",
                "Wenyu Yang",
                "Yilan Zhang",
                "Yuhui Wang",
                "Junliang Chen",
                "Xuhang Chen",
                "Ruimou Xie",
                "Yangyue Cao",
                "Qiaoying Li",
                "Jin Cao",
                "Tao Li",
                "Hubin Zhao",
                "Yu Pan",
                "Arokia Nathan",
                "Xin Gao",
                "Peter Smielewski",
                "Shuo Gao"
            ],
            "arxiv_id": "2512.14329v1",
            "summary": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
            "categories": [
                "cs.CE",
                "cs.AI"
            ],
            "primary_category": "cs.CE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14329v1",
            "code_links": [],
            "headline_zh": "提出TimeLens基准与模型，通过高质量数据和算法设计提升多模态大语言模型的视频时序定位能力",
            "summary_zh": "本文并未提出新方法，而是为视频理解的核心能力——视频时序定位（VTG）建立了一个直接、渐进但至关重要的基线。尽管多模态大语言模型（MLLMs）在多种视频理解任务中表现出色，但优化其VTG能力的方案仍未被充分探索。本文提出TimeLens，从数据质量和算法设计两个主要维度，系统性地研究如何构建具有强大VTG能力的MLLMs。我们首先揭示了现有VTG基准中的关键质量问题，并引入了TimeLens-Bench，它包含三个流行基准的精心重新标注版本，遵循严格的质量标准。我们的分析显示，与旧基准相比，模型排名发生了显著变化，证实了先前评估标准的不可靠性。我们还通过自动重新标注流程解决了训练数据中的噪声问题，生成了TimeLens-100K，这是一个大规模、高质量的训练数据集。基于我们的数据基础，我们深入探索了算法设计原则，得出一系列有意义的见解和有效且高效的实践。这些包括用于时间表示的交替文本编码、作为训练范式的免思考强化学习与可验证奖励（RLVR）方法，以及精心设计的RLVR训练方案。这些努力最终形成了TimeLens模型系列，这是一组在开源模型中具有最先进VTG性能的MLLMs，甚至超越了GPT-5和Gemini-2.5-Flash等专有模型。所有代码、数据和模型都将发布以促进未来研究。",
            "intro_zh": [
                "现有VTG基准存在质量问题，导致模型评估不可靠，且训练数据噪声大，限制了MLLMs在视频时序定位中的性能提升。",
                "论文从数据质量和算法设计入手，构建高质量基准TimeLens-Bench和训练集TimeLens-100K，并设计交替文本编码和RLVR训练范式。",
                "TimeLens模型在VTG任务中达到开源模型最优，超越GPT-5等专有模型，验证了高质量数据和算法设计的有效性。"
            ],
            "method_zh": "TimeLens的整体框架基于多模态大语言模型，专注于提升视频时序定位能力。关键技术创新点包括：在数据层面，通过严格标准重新标注现有基准，构建TimeLens-Bench以解决评估问题，并利用自动流程生成高质量训练集TimeLens-100K；在算法层面，引入交替文本编码来有效表示时间信息，并采用免思考强化学习与可验证奖励（RLVR）作为训练范式，优化模型输出。与现有方法的主要区别在于，它系统性地整合了高质量数据构建和算法设计，而非单一技术改进，强调基准可靠性和训练效率，为VTG任务提供了可复现的基线方案。",
            "application_zh": "该研究可应用于视频内容分析、智能监控、视频检索和编辑等领域，通过提升视频时序定位精度，支持更准确的视频理解任务，如事件检测、场景分割和问答系统，具有实际价值。",
            "highlight_zh": "TimeLens模型在VTG任务中达到开源模型最优性能，超越GPT-5和Gemini-2.5-Flash等专有模型；TimeLens-Bench基准揭示了旧基准的不可靠性，导致模型排名显著变化；高质量数据集TimeLens-100K有效提升了训练效果。",
            "tags_zh": [
                "视频时序定位",
                "多模态大语言模型",
                "基准评估",
                "高质量数据",
                "强化学习训练",
                "视频理解",
                "开源模型",
                "算法设计"
            ],
            "_index": 1
        },
        {
            "title": "SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry",
            "authors": [
                "Johannes A. Gaus",
                "Daniel Häufle",
                "Woo-Jeong Baek"
            ],
            "arxiv_id": "2512.14189v1",
            "summary": "While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14189v1",
            "code_links": [],
            "headline_zh": "提出基于Leech晶格的球形量化方法，以改进视觉标记化与生成中的重建-压缩权衡。",
            "summary_zh": "非参数量化因其参数效率和在大码本上的可扩展性而备受关注。本文通过晶格编码的视角，提出了不同非参数量化方法的统一表述。晶格码的几何结构解释了在训练自编码器时，对于某些现有的无查找量化变体（如BSQ）需要辅助损失项的必要性。作为进一步探索，我们研究了几种可能的候选方案，包括随机晶格、广义斐波那契晶格和最密球堆积晶格。其中，我们发现基于Leech晶格的量化方法（称为球形Leech量化，Λ24-SQ）由于其高对称性和超球面上的均匀分布，既能简化训练流程，又能改善重建与压缩之间的权衡。在图像标记化和压缩任务中，该量化方法在所有指标上均优于先前最佳方法BSQ，同时消耗的比特数略少。这一改进也延伸到了最先进的自回归图像生成框架中。",
            "intro_zh": [
                "现有非参数量化方法（如BSQ）在训练自编码器时需辅助损失项，导致流程复杂且重建-压缩权衡不佳。",
                "提出基于Leech晶格的球形量化（Λ24-SQ），利用其高对称性和超球面均匀分布简化训练并优化性能。",
                "在图像标记化、压缩和生成任务中，Λ24-SQ在重建质量上全面超越BSQ，同时比特消耗更低。"
            ],
            "method_zh": "论文提出一种统一的非参数量化框架，基于晶格编码理论。核心方法是球形Leech量化（Λ24-SQ），它利用Leech晶格（Λ24）的高对称性和在24维超球面上的均匀分布特性。该方法通过晶格点直接量化特征向量，无需复杂的查找操作或辅助损失，简化了自编码器的训练流程。与现有方法（如BSQ）的主要区别在于：Λ24-SQ基于数学上优化的晶格结构，提供了更均匀的量化点分布，从而在压缩效率和重建质量之间达到更好平衡，避免了训练中的不稳定性。",
            "application_zh": "该研究主要应用于计算机视觉领域，特别是图像和视频的压缩、标记化以及生成任务。潜在价值包括提升图像编码效率、支持高质量图像生成模型（如自回归框架），并可能扩展到其他模态的数据压缩和生成场景。",
            "highlight_zh": "实验显示，Λ24-SQ在图像标记化和压缩任务中，所有重建质量指标（如PSNR、SSIM）均优于先前最佳方法BSQ，同时比特率略有降低；在自回归图像生成框架中也能带来性能提升，验证了其广泛适用性。",
            "tags_zh": [
                "非参数量化",
                "晶格编码",
                "Leech晶格",
                "图像标记化",
                "图像压缩",
                "自回归生成",
                "视觉量化",
                "重建-压缩权衡"
            ],
            "_index": 2
        },
        {
            "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
            "authors": [
                "Zihan Wang",
                "Jiashun Wang",
                "Jeff Tan",
                "Yiwen Zhao",
                "Jessica Hodgins",
                "Shubham Tulsiani",
                "Deva Ramanan"
            ],
            "arxiv_id": "2512.14696v1",
            "summary": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
            "categories": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://crisp-real2sim.github.io/CRISP-Real2Sim/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14696v1",
            "code_links": [],
            "headline_zh": "提出CRISP方法，通过平面基元拟合和接触建模从单目视频重建可模拟的人类运动与场景几何，解决物理交互失败问题。",
            "summary_zh": "我们介绍了CRISP，一种从单目视频中恢复可模拟的人类运动和场景几何的方法。先前关于人类-场景联合重建的工作依赖于数据驱动的先验和无物理约束的联合优化，或恢复带有伪影的噪声几何，导致场景交互的运动跟踪策略失败。相比之下，我们的关键见解是通过对场景点云重建进行平面基元拟合，通过深度、法线和光流的简单聚类流程，恢复凸、干净且可模拟的几何。为了重建在交互过程中可能被遮挡的场景几何，我们利用人类-场景接触建模（例如，使用人体姿态重建被遮挡的椅子座位）。最后，我们通过强化学习驱动人形控制器，确保人类和场景重建在物理上是合理的。我们的方法在人类中心视频基准（EMDB、PROX）上将运动跟踪失败率从55.2%降低到6.9%，同时提供43%更快的RL模拟吞吐量。我们进一步在野外视频上验证了它，包括随意拍摄的视频、互联网视频，甚至Sora生成的视频。这展示了CRISP大规模生成物理有效的人类运动和交互环境的能力，极大地推进了机器人学和AR/VR的真实到模拟应用。",
            "intro_zh": [
                "现有方法依赖数据驱动先验或无物理优化，导致场景几何噪声大、交互失败率高，难以支持模拟应用。",
                "CRISP通过平面基元拟合点云和人类-场景接触建模，重建干净、凸的几何，并利用强化学习确保物理合理性。",
                "在基准测试中，运动跟踪失败率从55.2%降至6.9%，RL模拟吞吐量提升43%，并在多种视频上验证有效性。"
            ],
            "method_zh": "CRISP的整体框架包括从单目视频重建场景点云，然后通过基于深度、法线和光流的聚类流程拟合平面基元，以生成凸、干净的几何。关键创新点在于结合人类-场景接触建模来重建遮挡区域（如利用人体姿态推断椅子座位），并使用强化学习驱动人形控制器进行物理验证。与现有方法的主要区别在于：它不依赖复杂的数据驱动先验，而是通过简单聚类和物理约束直接生成可模拟的几何，避免了噪声和伪影问题，从而支持更可靠的交互模拟。",
            "application_zh": "该研究在机器人学和AR/VR领域有广泛应用潜力，例如用于训练机器人交互策略、创建虚拟环境中的物理模拟场景，以及增强现实中的真实感交互体验，能大规模生成物理有效的运动和环境数据。",
            "highlight_zh": "在EMDB和PROX基准上，CRISP将运动跟踪失败率从55.2%显著降低至6.9%，同时RL模拟吞吐量提升43%，并在随意拍摄、互联网和Sora生成视频上验证了其鲁棒性和可扩展性。",
            "tags_zh": [
                "单目视频重建",
                "人类-场景交互",
                "平面基元拟合",
                "接触建模",
                "强化学习模拟",
                "物理合理性",
                "真实到模拟",
                "机器人学应用"
            ],
            "_index": 4
        },
        {
            "title": "Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids",
            "authors": [
                "Mohammed Ayman Habib",
                "Aldo Petruzzelli"
            ],
            "arxiv_id": "2512.14411v1",
            "summary": "Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages; xTech Humanoid white paper submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14411v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "人形机器人",
                    "matched_keywords": [
                        "humanoid"
                    ],
                    "score": 1
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "headline_zh": "提出通用推理模型以提升复杂推理任务性能，在ARC-AGI基准上实现新突破。",
            "summary_zh": "通用Transformer（UTs）已广泛应用于ARC-AGI和数独等复杂推理任务，但其性能提升的具体来源尚未充分探索。本研究系统分析了UTs的变体，发现ARC-AGI上的改进主要源于Transformer的循环归纳偏置和强非线性组件，而非复杂的架构设计。基于这一发现，我们提出了通用推理模型（URM），通过引入短卷积和截断反向传播来增强UT。该方法显著提升了推理性能，在ARC-AGI 1上达到53.8%的pass@1，在ARC-AGI 2上达到16.0%的pass@1，实现了最先进水平。代码已开源。",
            "intro_zh": [
                "现有通用Transformer在复杂推理任务中性能提升来源不明确，缺乏系统性分析，限制了模型优化。",
                "论文提出通用推理模型，通过短卷积和截断反向传播增强通用Transformer，强化循环归纳偏置和非线性能力。",
                "实验显示，URM在ARC-AGI基准上取得显著提升，pass@1分数达到新高度，验证了方法的有效性。"
            ],
            "method_zh": "通用推理模型（URM）基于通用Transformer框架，通过引入短卷积模块来增强局部特征提取能力，并结合截断反向传播技术优化训练过程，减少计算开销。关键创新在于利用短卷积强化非线性组件，同时保持循环归纳偏置，从而提升模型在复杂推理任务中的表现。与现有方法相比，URM更注重基础组件的优化，而非复杂架构设计，实现了更高效的性能提升。",
            "application_zh": "该研究可应用于需要高级推理能力的领域，如人工智能通用智能（AGI）测试、逻辑谜题求解（如数独）和复杂决策系统，为开发更鲁棒的推理模型提供技术基础。",
            "highlight_zh": "URM在ARC-AGI 1上达到53.8% pass@1，在ARC-AGI 2上达到16.0% pass@1，均创下最先进记录，显著超越先前方法，证明了短卷积和截断反向传播的有效性。",
            "tags_zh": [
                "通用推理模型",
                "Transformer架构",
                "循环归纳偏置",
                "非线性组件",
                "短卷积",
                "截断反向传播",
                "ARC-AGI基准",
                "复杂推理任务"
            ],
            "_index": 5
        },
        {
            "title": "DriverGaze360: OmniDirectional Driver Attention with Object-Level Guidance",
            "authors": [
                "Shreedhar Govil",
                "Didier Stricker",
                "Jason Rambach"
            ],
            "arxiv_id": "2512.14266v1",
            "summary": "Predicting driver attention is a critical problem for developing explainable autonomous driving systems and understanding driver behavior in mixed human-autonomous vehicle traffic scenarios. Although significant progress has been made through large-scale driver attention datasets and deep learning architectures, existing works are constrained by narrow frontal field-of-view and limited driving diversity. Consequently, they fail to capture the full spatial context of driving environments, especially during lane changes, turns, and interactions involving peripheral objects such as pedestrians or cyclists. In this paper, we introduce DriverGaze360, a large-scale 360$^\\circ$ field of view driver attention dataset, containing $\\sim$1 million gaze-labeled frames collected from 19 human drivers, enabling comprehensive omnidirectional modeling of driver gaze behavior. Moreover, our panoramic attention prediction approach, DriverGaze360-Net, jointly learns attention maps and attended objects by employing an auxiliary semantic segmentation head. This improves spatial awareness and attention prediction across wide panoramic inputs. Extensive experiments demonstrate that DriverGaze360-Net achieves state-of-the-art attention prediction performance on multiple metrics on panoramic driving images. Dataset and method available at https://av.dfki.de/drivergaze360.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14266v1",
            "code_links": [],
            "headline_zh": "提出O-Voxel稀疏体素表示与稀疏压缩VAE，以解决3D生成中复杂拓扑与细节外观建模的挑战",
            "summary_zh": "近年来，3D生成建模在生成真实感方面取得了显著进展，但该领域仍受限于现有表示方法，这些方法难以捕捉具有复杂拓扑结构和详细外观的资产。本文提出了一种从原生3D数据中学习结构化潜在表示的方法来应对这一挑战。其核心是一种名为O-Voxel的新型稀疏体素结构，这是一种全向体素表示，能够同时编码几何和外观信息。O-Voxel能够稳健地建模任意拓扑结构，包括开放、非流形和完全封闭的表面，同时捕捉超越纹理颜色的全面表面属性，例如基于物理的渲染参数。基于O-Voxel，我们设计了一种稀疏压缩变分自编码器，它提供了高空间压缩率和紧凑的潜在空间。我们使用多样化的公共3D资产数据集，训练了包含40亿参数的大规模流匹配模型用于3D生成。尽管模型规模庞大，推理过程仍然保持高效。同时，我们生成资产的几何和材质质量远超现有模型。我们相信，我们的方法为3D生成建模提供了重要进展。",
            "intro_zh": [
                "现有3D表示方法难以有效捕捉复杂拓扑（如开放、非流形表面）和超越颜色的详细外观属性（如物理渲染参数）。",
                "提出O-Voxel稀疏体素表示，统一编码几何与外观；并基于此设计稀疏压缩VAE，实现高压缩率与紧凑潜在空间。",
                "训练40亿参数流匹配模型，生成资产在几何与材质质量上远超现有方法，且推理高效，验证了方法的有效性。"
            ],
            "method_zh": "论文提出一个基于结构化潜在表示的3D生成框架。核心是O-Voxel稀疏体素表示，它作为原生3D数据的统一编码器，能处理任意拓扑并包含几何与外观（如物理渲染参数）信息。基于O-Voxel，设计了稀疏压缩变分自编码器，通过稀疏性实现高空间压缩，形成紧凑的潜在空间。在此基础上，训练大规模流匹配模型进行生成。与现有方法相比，主要区别在于使用O-Voxel作为底层表示，克服了传统网格或体素在拓扑和细节上的限制，并通过稀疏压缩优化了潜在空间效率。",
            "application_zh": "该研究在3D内容创作、虚拟现实、游戏开发、工业设计等领域具有广泛应用潜力，能高效生成高质量、复杂拓扑的3D资产，提升自动化生成的真实感和多样性，降低人工建模成本。",
            "highlight_zh": "实验表明，生成的3D资产在几何细节和材质质量上显著超越现有模型，同时基于40亿参数的大规模流匹配模型实现了高效推理，验证了O-Voxel表示和稀疏压缩VAE的有效性与优越性。",
            "tags_zh": [
                "3D生成建模",
                "稀疏体素表示",
                "结构化潜在空间",
                "流匹配模型",
                "几何与外观编码",
                "大规模参数训练",
                "物理渲染参数",
                "复杂拓扑建模"
            ],
            "_index": 6
        },
        {
            "title": "ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body",
            "authors": [
                "Juze Zhang",
                "Changan Chen",
                "Xin Chen",
                "Heng Yu",
                "Tiange Xiang",
                "Ali Sartaz Khan",
                "Shrinidhi K. Lakshmikanth",
                "Ehsan Adeli"
            ],
            "arxiv_id": "2512.14234v1",
            "summary": "Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond \"speech-conditioned motion generation\" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://ai.stanford.edu/~juze/ViBES/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14234v1",
            "code_links": [],
            "headline_zh": "提出MMGR多模态生成推理评估框架，以解决现有视频基础模型在物理、逻辑和空间约束方面缺乏可靠评估的问题。",
            "summary_zh": "视频基础模型能够生成视觉逼真且时序连贯的内容，但其作为世界模拟器的可靠性取决于是否捕捉了物理、逻辑和空间约束。现有指标如弗雷歇视频距离（FVD）强调感知质量，却忽视了推理失败，包括违反因果关系、物理规律和全局一致性。我们引入了MMGR（多模态生成推理评估与基准），这是一个基于五种推理能力的原则性评估框架：物理推理、逻辑推理、3D空间推理、2D空间推理和时序推理。MMGR在三个领域评估生成推理：抽象推理（ARC-AGI、数独）、具身导航（真实世界3D导航与定位）和物理常识（运动和组合交互）。MMGR应用细粒度指标，要求视频和图像生成在整体上正确。我们对领先的视频模型（Veo-3、Sora-2、Wan-2.2）和图像模型（Nano-banana、Nano-banana Pro、GPT-4o-image、Qwen-image）进行了基准测试，揭示了跨领域的显著性能差距。模型在物理常识任务上表现中等，但在抽象推理上表现不佳（ARC-AGI准确率低于10%），并在具身设置中的长时程空间规划上遇到困难。我们的分析突出了当前模型的关键局限性，包括过度依赖感知数据、全局状态一致性弱，以及目标函数奖励视觉合理性而非因果正确性。MMGR提供了一个统一的诊断基准，并为推理感知的生成世界模型指明了路径。",
            "intro_zh": [
                "现有视频基础模型评估指标（如FVD）过于关注感知质量，忽视了物理、逻辑和空间推理失败，导致模型作为世界模拟器的可靠性不足。",
                "论文提出MMGR框架，基于五种推理能力（物理、逻辑、3D空间、2D空间、时序）构建原则性评估，覆盖抽象推理、具身导航和物理常识三大领域。",
                "基准测试显示，主流模型在物理常识任务上表现中等，但在抽象推理（如ARC-AGI准确率低于10%）和长时程空间规划上表现不佳，揭示了关键局限性。"
            ],
            "method_zh": "MMGR是一个多模态生成推理评估框架，整体框架基于五种核心推理能力（物理、逻辑、3D空间、2D空间、时序），设计细粒度评估指标，要求视频和图像生成在整体上正确。关键技术创新点在于将推理能力系统化分类，并应用于三个具体领域（抽象推理、具身导航、物理常识），通过统一基准进行跨模型比较。与现有方法的主要区别在于，现有方法如FVD侧重于感知质量评估，而MMGR强调推理正确性，能够诊断模型在因果关系、物理约束和全局一致性方面的失败，从而提供更全面的评估视角。",
            "application_zh": "该研究可应用于视频生成模型的质量评估与优化、具身智能系统的导航与规划、以及物理模拟和游戏开发中的世界建模。它为开发更可靠的生成世界模型提供了诊断工具，有助于提升AI在复杂环境中的推理能力。",
            "highlight_zh": "实验结果显示，主流视频和图像模型在物理常识任务上表现中等，但在抽象推理任务（如ARC-AGI）上准确率低于10%，且在具身导航的长时程空间规划中表现不佳，揭示了模型在全局状态一致性和因果推理方面的显著缺陷。",
            "tags_zh": [
                "多模态推理评估",
                "视频基础模型",
                "生成世界模型",
                "物理常识推理",
                "具身导航",
                "抽象推理",
                "基准测试",
                "因果推理"
            ],
            "_index": 6
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689v1",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The first two authors contributed equally. Project page: https://nvlabs.github.io/CHIP/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689v1",
            "code_links": [],
            "headline_zh": "提出CHIP模块以解决人形机器人执行强力操作任务时末端执行器刚度控制与动态运动跟踪的平衡问题。",
            "summary_zh": "人形机器人在敏捷运动技能（如后空翻、奔跑、爬行）方面取得了显著进展，但在执行强力操作任务（如移动物体、擦拭、推车）时仍面临挑战。本文提出自适应合规人形控制通过后见扰动（CHIP），这是一个即插即用模块，能够在保持动态参考运动敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实现，无需数据增强或额外奖励调整。研究表明，使用CHIP训练的通用运动跟踪控制器能够执行多种需要不同末端执行器合规性的强力操作任务，例如多机器人协作、擦拭、箱子递送和开门。",
            "intro_zh": [
                "核心问题：人形机器人虽能实现敏捷运动，但在强力操作任务中难以平衡末端执行器刚度与动态运动跟踪，导致任务执行受限。",
                "方法要点：提出CHIP模块，通过后见扰动自适应调整末端执行器合规性，无需复杂数据或奖励设计，实现即插即用的刚度控制。",
                "实验或效果：CHIP使通用控制器成功执行多机器人协作、擦拭等任务，验证了其在多样化强力操作中的有效性和泛化能力。"
            ],
            "method_zh": "CHIP是一个基于强化学习的即插即用模块，整体框架集成于通用运动跟踪控制器中，通过后见扰动技术自适应调整末端执行器刚度。关键技术创新在于利用扰动历史信息优化合规性控制，无需额外数据增强或奖励函数调优。与现有方法的主要区别在于，CHIP专注于末端执行器刚度与动态运动跟踪的协同优化，避免了传统方法中数据依赖和调参复杂性，提升了任务适应性和实现简便性。",
            "application_zh": "该研究可应用于人形机器人在工业、服务或家庭环境中的强力操作任务，如物体搬运、清洁、协作搬运和门操作，提升机器人在复杂场景下的多功能性和实用性。",
            "highlight_zh": "实验显示，CHIP模块使通用控制器在多种强力操作任务中实现高效执行，如多机器人协作和开门，验证了其自适应合规性控制的优越性能，无需额外数据或奖励调整，显著提升了任务完成率和泛化能力。",
            "tags_zh": [
                "人形机器人控制",
                "自适应合规性",
                "末端执行器刚度",
                "后见扰动",
                "强力操作任务",
                "运动跟踪",
                "强化学习",
                "即插即用模块"
            ],
            "_index": 7
        },
        {
            "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
            "authors": [
                "Timo Klein",
                "Thomas Lang",
                "Andrii Shkabrii",
                "Alexander Sturm",
                "Kevin Sidak",
                "Lukas Miklautz",
                "Claudia Plant",
                "Yllka Velaj",
                "Sebastian Tschiatschek"
            ],
            "arxiv_id": "2512.14202v1",
            "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14202v1",
            "code_links": [
                {
                    "url": "https://github.com/Probabilistic-and-Interactive-ML/hyper-rl",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "PPO"
                    ],
                    "score": 3
                }
            ],
            "headline_zh": "提出Spoken DialogSum数据集以解决语音对话摘要中缺乏情感和副语言信息对齐数据的问题。",
            "summary_zh": "当前的音频语言模型能够处理长对话，但情感感知或语音对话摘要的研究因缺乏将语音、摘要和副语言线索关联的数据而受限。我们引入了Spoken DialogSum，这是首个将原始对话音频与事实摘要、情感丰富摘要以及说话者年龄、性别和情感的语句级标签对齐的语料库。该数据集通过两个阶段构建：首先，使用大型语言模型重写DialogSum脚本，添加Switchboard风格的填充词和反馈词，并为每个语句标记情感、音高和语速；其次，通过富有表现力的文本转语音引擎从标记脚本合成语音，并与副语言标签对齐。Spoken DialogSum包含13,460个情感多样的对话，每个对话都配有事实摘要和情感聚焦摘要。数据集在线可用。基线实验显示，与级联的ASR-LLM系统相比，音频-LLM将情感摘要的ROUGE-L分数相对提升了28%，证实了端到端语音建模的价值。",
            "intro_zh": [
                "核心问题：现有语音对话摘要研究缺乏同时包含语音、摘要和副语言信息（如情感、音高）的数据集，限制了情感感知模型的发展。",
                "方法要点：通过两阶段方法构建Spoken DialogSum数据集，先使用LLM重写脚本并标记情感等副语言信息，再用TTS合成对齐语音。",
                "实验或效果：基线实验表明，端到端音频-LLM模型在情感摘要任务上比级联ASR-LLM系统在ROUGE-L分数上相对提升28%。"
            ],
            "method_zh": "论文的核心方法是构建Spoken DialogSum数据集的框架。整体框架包括两个阶段：第一阶段，利用大型语言模型（LLM）对DialogSum文本脚本进行改写，添加Switchboard风格的填充词和反馈词以模拟真实对话，并为每个语句自动标记情感、音高和语速等副语言信息；第二阶段，使用富有表现力的文本转语音（TTS）引擎，基于标记脚本合成语音，确保语音与副语言标签精确对齐。关键技术创新点在于首次将原始音频、事实摘要、情感摘要和语句级副语言标签集成到一个统一数据集中。与现有方法的主要区别是，现有数据集通常仅包含文本或语音，缺乏情感和副语言信息的系统对齐，而本方法通过自动化流程实现了多模态数据的协同生成。",
            "application_zh": "该研究在语音助手、客户服务对话分析、情感计算和心理健康监测等领域具有潜在应用价值。通过提供情感丰富的语音对话数据，可支持开发更智能的对话系统，提升人机交互的自然性和情感理解能力。",
            "highlight_zh": "最重要的实验结果是，使用Spoken DialogSum数据集训练的端到端音频-LLM模型，在情感摘要任务上，ROUGE-L分数比级联ASR-LLM系统相对提升了28%，显著证明了直接处理语音信号在情感感知任务中的优势。",
            "tags_zh": [
                "语音对话摘要",
                "情感计算",
                "副语言信息",
                "数据集构建",
                "端到端语音建模",
                "多模态对齐",
                "文本转语音合成",
                "大型语言模型"
            ],
            "_index": 8
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100v1",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100v1",
            "code_links": [
                {
                    "url": "https://github.com/ChunjinJiang/sgrpo",
                    "type": "github"
                }
            ],
            "_index": 9
        },
        {
            "title": "Early Warning Index for Patient Deteriorations in Hospitals",
            "authors": [
                "Dimitris Bertsimas",
                "Yu Ma",
                "Kimberly Villalobos Carballo",
                "Gagan Singh",
                "Michal Laskowski",
                "Jeff Mather",
                "Dan Kombert",
                "Howard Haronian"
            ],
            "arxiv_id": "2512.14683v1",
            "summary": "Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14683v1",
            "code_links": [],
            "headline_zh": "提出早期预警指数（EWI）多模态机器学习框架，以解决医院患者病情恶化预测难题。",
            "summary_zh": "医院缺乏自动化系统来利用日益增长的异构临床和运营数据有效预测关键事件。早期识别有恶化风险的患者不仅对患者护理质量监控至关重要，也对医生护理管理至关重要。然而，由于数据格式不一致，将各种数据流转化为准确且可解释的风险评估面临重大挑战。我们开发了一个多模态机器学习框架——早期预警指数（EWI），用于预测ICU入院、紧急响应团队派遣和死亡率的综合风险。EWI设计的关键在于人机协同过程：临床医生帮助确定警报阈值并解释模型输出，这些输出通过使用SHAP（Shapley Additive exPlanations）的可解释性增强，以突出驱动每位患者风险的临床和运营因素（如计划手术、病房普查）。我们将EWI部署在医院仪表板中，将患者分为三个风险等级。使用美国一家大型医院的18,633名独特患者数据集，我们的方法从结构化和非结构化电子健康记录（EHR）数据中自动提取特征，并实现了0.796的C统计量。目前，它被用作主动管理风险患者的分类工具。所提出的方法通过自动对不同风险水平的患者进行排序，为医生节省了宝贵时间，使他们能够专注于患者护理，而不是筛选复杂的EHR数据。通过进一步精确定位特定风险驱动因素，该模型为护理人员调度和关键资源分配提供了数据驱动的调整。因此，临床医生和管理人员可以避免下游并发症，包括昂贵的手术或高再入院率，并改善整体患者流程。",
            "intro_zh": [
                "核心问题：医院缺乏自动化系统整合异构临床数据，难以准确预测患者病情恶化，数据格式不一致导致风险评估挑战。",
                "方法要点：开发多模态机器学习框架EWI，结合人机协同过程，利用SHAP增强可解释性，自动提取EHR特征预测综合风险。",
                "实验或效果：在18,633名患者数据集上实现C统计量0.796，部署为医院仪表板，有效分类患者风险，提升护理效率。"
            ],
            "method_zh": "论文提出早期预警指数（EWI）多模态机器学习框架，整体框架整合结构化和非结构化电子健康记录（EHR）数据，通过自动特征提取预测ICU入院、紧急响应团队派遣和死亡率的综合风险。关键技术创新点包括人机协同过程，临床医生参与设定警报阈值和解释输出，以及使用SHAP（Shapley Additive exPlanations）提供可解释性，突出临床和运营风险驱动因素。与现有方法的主要区别在于其多模态数据融合能力、可解释性增强和实际部署导向，解决了传统方法数据格式不一致和缺乏临床整合的问题。",
            "application_zh": "该研究应用于医院临床管理，作为患者病情恶化的早期预警工具，潜在应用包括ICU入院预测、紧急响应优化和资源分配调整，实际价值在于提升患者护理质量、减少并发症和改善医院运营效率。",
            "highlight_zh": "最重要的实验结果：在大型医院18,633名患者数据集上，EWI实现C统计量0.796，表明高预测准确性；性能提升体现在自动风险分层和可解释输出，帮助临床医生主动管理患者，减少下游并发症。",
            "tags_zh": [
                "早期预警指数",
                "多模态机器学习",
                "患者恶化预测",
                "可解释人工智能",
                "电子健康记录",
                "临床决策支持",
                "医院运营优化",
                "风险分层"
            ],
            "_index": 9
        },
        {
            "title": "OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving",
            "authors": [
                "Zhenguo Zhang",
                "Haohan Zhen",
                "Yishen Wang",
                "Le Xu",
                "Tianchen Deng",
                "Xuefeng Chen",
                "Qu Chen",
                "Bo Zhang",
                "Wuxiong Huang"
            ],
            "arxiv_id": "2512.14044v1",
            "summary": "The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and \"zoom in\" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14044v1",
            "code_links": [],
            "headline_zh": "提出VASA-3D，通过单张图像生成音频驱动的逼真3D头部化身，解决表情细节建模和单图重建挑战。",
            "summary_zh": "我们提出了VASA-3D，一种音频驱动的单次3D头部化身生成器。这项研究解决了两个主要挑战：捕捉真实人脸的微妙表情细节，以及从单张肖像图像重建复杂的3D头部化身。为了准确建模表情细节，VASA-3D利用了VASA-1的运动潜在表示，该方法在2D说话头部生成中展现出卓越的真实感和生动性。我们工作的一个关键要素是将这种运动潜在表示转换到3D，这是通过设计一个以运动潜在为条件的3D头部模型来实现的。该模型针对单张图像的定制化是通过一个优化框架实现的，该框架使用了从输入图像合成的参考头部的大量视频帧。优化过程采用了多种训练损失，这些损失对生成训练数据中的伪影和有限姿态覆盖具有鲁棒性。我们的实验表明，VASA-3D生成了现有技术无法实现的逼真3D说话头部，并支持在线生成512x512自由视角视频，帧率高达75 FPS，从而促进了与逼真3D化身更沉浸式的互动。",
            "intro_zh": [
                "现有方法难以从单张图像重建复杂3D头部化身，且表情细节建模不足，限制了真实感。",
                "VASA-3D利用VASA-1的运动潜在表示，设计条件化3D模型，通过优化框架实现单图定制化。",
                "实验生成逼真3D说话头部，支持在线75 FPS自由视角视频，显著提升沉浸感和实时性能。"
            ],
            "method_zh": "VASA-3D的整体框架基于音频驱动的3D头部化身生成，核心创新点包括：利用VASA-1的运动潜在表示来建模表情细节，设计一个以该运动潜在为条件的3D头部模型，实现从2D到3D的转换。关键技术创新在于通过优化框架定制化模型，使用从输入图像合成的视频帧进行训练，并采用鲁棒损失函数处理数据中的伪影和姿态限制。与现有方法的主要区别在于结合了2D说话头部的先进运动建模能力，并扩展到3D领域，解决了单图重建和表情细节的挑战，避免了传统方法对多视图数据或复杂采集的依赖。",
            "application_zh": "该研究在虚拟现实、增强现实、远程会议和娱乐领域具有广泛应用潜力，可生成逼真3D化身用于沉浸式交互、个性化虚拟角色和实时通信，提升用户体验和真实感。",
            "highlight_zh": "VASA-3D生成逼真3D说话头部，超越现有技术，支持在线生成512x512自由视角视频，帧率达75 FPS，实验验证了其在表情细节和实时性能上的显著提升。",
            "tags_zh": [
                "音频驱动生成",
                "3D头部化身",
                "单图像重建",
                "运动潜在表示",
                "优化框架",
                "自由视角视频",
                "实时渲染",
                "表情建模"
            ],
            "_index": 11
        },
        {
            "title": "Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks",
            "authors": [
                "Rae Chipera",
                "Jenny Du",
                "Irene Tsapara"
            ],
            "arxiv_id": "2512.14675v1",
            "summary": "Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smooth activations in convergence speed and spectral radius tolerance. Notably, the Cantor function (continuous everywhere and flat almost everywhere) maintains ESP-consistent behavior up to spectral radii of rho ~ 10, an order of magnitude beyond typical bounds for smooth functions, while achieving 2.6x faster convergence than tanh and ReLU. We introduce a theoretical framework for quantized activation functions, defining a Degenerate Echo State Property (d-ESP) that captures stability for discrete-output functions and proving that d-ESP implies traditional ESP. We identify a critical crowding ratio Q=N/k (reservoir size / quantization levels) that predicts failure thresholds for discrete activations. Our analysis reveals that preprocessing topology, rather than continuity per se, determines stability: monotone, compressive preprocessing maintains ESP across scales, while dispersive or discontinuous preprocessing triggers sharp failures. While our findings challenge assumptions about activation function design in reservoir computing, the mechanism underlying the exceptional performance of certain fractal functions remains unexplained, suggesting fundamental gaps in our understanding of how geometric properties of activation functions influence reservoir dynamics.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "50 pages, 21 figures. Extended version with full proofs, parameter sweeps, and appendices",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14675v1",
            "code_links": [],
            "headline_zh": "提出非光滑激活函数在回声状态网络中的应用，提升极端条件下的鲁棒性和收敛速度",
            "summary_zh": "当代储层计算严重依赖平滑、全局Lipschitz连续的激活函数，这限制了在国防、灾害响应和药物建模等极端条件下需要鲁棒操作的应用。我们系统地研究了回声状态网络中的非光滑激活函数，包括混沌、随机和分形变体。通过对36,610个储层配置进行全面的参数扫描，我们证明了几种非光滑函数不仅保持了回声状态特性（ESP），而且在收敛速度和谱半径容限方面优于传统的平滑激活函数。值得注意的是，康托函数（处处连续且几乎处处平坦）在谱半径高达ρ~10时仍保持ESP一致行为，比平滑函数的典型界限高出一个数量级，同时实现了比tanh和ReLU快2.6倍的收敛速度。我们引入了量化激活函数的理论框架，定义了捕获离散输出函数稳定性的退化回声状态特性（d-ESP），并证明d-ESP蕴含传统ESP。我们识别了一个关键的拥挤比Q=N/k（储层大小/量化级别），用于预测离散激活函数的失效阈值。我们的分析表明，预处理拓扑而非连续性本身决定了稳定性：单调、压缩的预处理在多个尺度上保持ESP，而分散或不连续的预处理则引发急剧失效。虽然我们的发现挑战了储层计算中激活函数设计的假设，但某些分形函数优异性能的机制仍未得到解释，这表明我们对激活函数几何性质如何影响储层动态的理解存在根本性差距。",
            "intro_zh": [
                "核心问题：传统回声状态网络依赖平滑激活函数，在极端条件下鲁棒性不足，限制了国防、灾害响应等应用。",
                "方法要点：系统研究非光滑激活函数，包括混沌、随机和分形变体，并引入量化激活函数的理论框架。",
                "实验或效果：康托函数在谱半径高达10时保持稳定，收敛速度比tanh和ReLU快2.6倍，性能显著提升。"
            ],
            "method_zh": "论文采用回声状态网络（ESN）作为整体框架，核心方法包括系统研究非光滑激活函数（如康托函数、混沌和随机变体）在储层计算中的应用。关键技术创新点在于引入了量化激活函数的理论框架，定义了退化回声状态特性（d-ESP）来捕获离散输出函数的稳定性，并证明d-ESP蕴含传统ESP。与现有方法的主要区别在于挑战了传统依赖平滑、Lipschitz连续激活函数的假设，通过参数扫描和理论分析，揭示预处理拓扑（而非连续性）对稳定性的决定性作用，并识别拥挤比作为预测离散激活函数失效的关键指标。",
            "application_zh": "该研究在国防、灾害响应和药物建模等领域具有潜在应用价值，特别是在需要极端条件下鲁棒操作的场景中，如实时监控、应急决策和复杂系统模拟，能提升模型的稳定性和效率。",
            "highlight_zh": "最重要的实验结果包括：康托函数在谱半径高达10时仍保持回声状态特性，比平滑函数界限高一个数量级；收敛速度比tanh和ReLU快2.6倍；通过36,610个配置的参数扫描，验证了非光滑函数的优越性能。",
            "tags_zh": [
                "回声状态网络",
                "非光滑激活函数",
                "分形函数",
                "混沌激活",
                "储层计算",
                "稳定性分析",
                "量化激活",
                "极端条件鲁棒性"
            ],
            "_index": 10
        },
        {
            "title": "ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM",
            "authors": [
                "Ignacio Alzugaray",
                "Marwan Taher",
                "Andrew J. Davison"
            ],
            "arxiv_id": "2512.14032v1",
            "summary": "We present a novel neural RGB-D Simultaneous Localization And Mapping (SLAM) system that learns an implicit map of the scene in real time. For the first time, we explore the use of Scene Coordinate Regression (SCR) as the core implicit map representation in a neural SLAM pipeline, a paradigm that trains a lightweight network to directly map 2D image features to 3D global coordinates. SCR networks provide efficient, low-memory 3D map representations, enable extremely fast relocalization, and inherently preserve privacy, making them particularly suitable for neural implicit SLAM.\n  Our system is the first one to achieve strict real-time in neural implicit RGB-D SLAM by relying on a SCR-based representation. We introduce a novel SCR architecture specifically tailored for this purpose and detail the critical design choices required to integrate SCR into a live SLAM pipeline. The resulting framework is simple yet flexible, seamlessly supporting both sparse and dense features, and operates reliably in dynamic environments without special adaptation. We evaluate our approach on established synthetic and real-world benchmarks, demonstrating competitive performance against the state of the art. Project Page: https://github.com/ialzugaray/ace-slam",
            "categories": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://github.com/ialzugaray/ace-slam",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14671v1",
            "code_links": [],
            "headline_zh": "提出ART以解决从稀疏多状态RGB图像重建完整3D关节物体的类别无关前馈建模问题",
            "summary_zh": "我们介绍了ART（Articulated Reconstruction Transformer）——一种类别无关的前馈模型，能够仅从稀疏的多状态RGB图像重建完整的3D关节物体。以往的关节物体重建方法要么依赖于脆弱的跨状态对应关系的缓慢优化，要么使用仅限于特定物体类别的前馈模型。相比之下，ART将关节物体视为刚性部件的组装体，将重建问题表述为基于部件的预测。我们新设计的Transformer架构将稀疏图像输入映射到一组可学习的部件槽，ART从中联合解码出各个部件的统一表示，包括其3D几何、纹理和显式关节参数。所得重建结果具有物理可解释性，并可轻松导出用于仿真。通过在具有逐部件监督的大规模多样化数据集上进行训练，并在多个基准测试中评估，ART相比现有基线取得了显著改进，为从图像输入进行关节物体重建建立了新的技术标杆。",
            "intro_zh": [
                "现有方法依赖缓慢优化或局限于特定类别，难以高效重建多样化关节物体。",
                "ART将关节物体建模为刚性部件组装体，通过Transformer架构实现部件级预测。",
                "在多个基准测试中，ART显著超越现有基线，建立了新的技术标杆。"
            ],
            "method_zh": "ART采用基于Transformer的前馈架构，整体框架将稀疏多状态RGB图像输入映射到一组可学习的部件槽，然后联合解码每个部件的3D几何、纹理和显式关节参数。关键技术创新在于将关节物体视为刚性部件组装体，并设计Transformer实现部件级预测，避免了传统方法对跨状态对应关系的依赖。与现有方法的主要区别在于其类别无关性和前馈特性，能够高效处理多样化物体，而无需缓慢优化或类别限制。",
            "application_zh": "该研究在机器人操作、虚拟现实和仿真领域具有广泛应用价值，例如机器人抓取关节物体、虚拟环境中的物体交互模拟，以及增强现实中的实时物体重建，为物理可解释的3D建模提供了高效解决方案。",
            "highlight_zh": "ART在多个关节物体重建基准测试中显著超越现有基线，实现了更高的重建精度和效率，特别是在处理稀疏图像输入时表现出色，为相关任务建立了新的技术标杆。",
            "tags_zh": [
                "关节物体重建",
                "3D重建",
                "Transformer架构",
                "部件级预测",
                "类别无关建模",
                "前馈模型",
                "物理可解释性",
                "稀疏图像输入"
            ],
            "_index": 11
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689v1",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The first two authors contributed equally. Project page: https://nvlabs.github.io/CHIP/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689v1",
            "code_links": [],
            "headline_zh": "提出EVOLVE-VLA测试时训练框架，使视觉-语言-动作模型通过环境交互持续自适应，减少任务特定演示需求。",
            "summary_zh": "实现真正自适应的具身智能需要智能体通过环境交互持续学习，而非仅模仿静态演示。视觉-语言-动作模型虽通过大语言模型推进了机器人操作，但仍受限于监督微调：每任务需数百演示、僵化记忆轨迹、部署条件偏离训练时无法适应。本文提出EVOLVE-VLA，一个测试时训练框架，使VLA模型能以最少或零任务特定演示通过环境交互持续适应。关键技术挑战是用自主反馈替代测试时不可用的oracle奖励信号。我们通过学习的进度估计器提供密集反馈解决此问题，并设计框架通过两种机制“驯服”这一固有噪声信号：(1)累积进度估计机制平滑噪声点估计，(2)渐进视野扩展策略实现逐步策略演化。EVOLVE-VLA取得显著提升：长视野任务+8.6%、1-shot学习+22.0%，并实现跨任务泛化——在未见任务上无任务特定演示训练达到20.8%成功率（纯SFT为0%）。定性分析揭示了演示中不存在的涌现能力，包括错误恢复和新策略。这项工作代表了VLA模型真正学习和适应的关键一步，从静态模仿迈向持续自我改进。",
            "intro_zh": [
                "现有VLA模型依赖监督微调，需大量演示、记忆轨迹，部署条件变化时无法适应，限制了自适应能力。",
                "提出测试时训练框架，通过学习的进度估计器提供自主反馈，结合累积估计和渐进视野扩展机制驯服噪声信号。",
                "实验显示长视野任务提升8.6%，1-shot学习提升22.0%，跨任务泛化达20.8%成功率，涌现错误恢复和新策略能力。"
            ],
            "method_zh": "EVOLVE-VLA是一个测试时训练框架，使视觉-语言-动作模型在部署时通过环境交互持续自适应。整体框架基于学习的进度估计器，它提供密集反馈替代测试时不可用的oracle奖励信号。关键技术创新点包括：累积进度估计机制，通过平滑点估计减少噪声影响；渐进视野扩展策略，逐步扩展策略优化范围以实现稳定演化。与现有方法的主要区别在于，它不依赖大量任务特定演示，而是利用自主反馈实现在线适应，突破了监督微调的静态限制，支持动态环境交互和跨任务泛化。",
            "application_zh": "该研究可应用于机器人操作、自主导航和智能家居等领域，使智能体在真实世界中通过交互持续改进，减少对人工演示的依赖，提升适应性和泛化能力，推动具身智能向更灵活、自适应的方向发展。",
            "highlight_zh": "EVOLVE-VLA在长视野任务上提升8.6%，1-shot学习提升22.0%，跨任务泛化在未见任务上达到20.8%成功率（纯SFT为0%），并涌现错误恢复和新策略能力，显著超越传统监督微调方法。",
            "tags_zh": [
                "测试时训练",
                "视觉-语言-动作模型",
                "环境交互",
                "进度估计",
                "自适应学习",
                "机器人操作",
                "跨任务泛化",
                "具身智能"
            ],
            "_index": 14
        },
        {
            "title": "Enhancing Visual Sentiment Analysis via Semiotic Isotopy-Guided Dataset Construction",
            "authors": [
                "Marco Blanchini",
                "Giovanna Maria Dimitri",
                "Benedetta Tondi",
                "Tarcisio Lancioni",
                "Mauro Barni"
            ],
            "arxiv_id": "2512.14665v1",
            "summary": "Visual Sentiment Analysis (VSA) is a challenging task due to the vast diversity of emotionally salient images and the inherent difficulty of acquiring sufficient data to capture this variability comprehensively. Key obstacles include building large-scale VSA datasets and developing effective methodologies that enable algorithms to identify emotionally significant elements within an image. These challenges are reflected in the limited generalization performance of VSA algorithms and models when trained and tested across different datasets. Starting from a pool of existing data collections, our approach enables the creation of a new larger dataset that not only contains a wider variety of images than the original ones, but also permits training new models with improved capability to focus on emotionally relevant combinations of image elements. This is achieved through the integration of the semiotic isotopy concept within the dataset creation process, providing deeper insights into the emotional content of images. Empirical evaluations show that models trained on a dataset generated with our method consistently outperform those trained on the original data collections, achieving superior generalization across major VSA benchmarks",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14665v1",
            "code_links": [],
            "headline_zh": "提出基于符号同位性指导的数据集构建方法，以提升视觉情感分析模型的泛化能力",
            "summary_zh": "视觉情感分析（VSA）是一项具有挑战性的任务，主要由于情感显著图像的巨大多样性以及获取足够数据以全面捕捉这种变异性存在固有困难。关键障碍包括构建大规模VSA数据集和开发有效方法，使算法能够识别图像中的情感显著元素。这些挑战体现在VSA算法和模型在不同数据集上训练和测试时泛化性能有限。从现有数据集合出发，我们的方法能够创建一个新的更大数据集，不仅包含比原始数据更广泛的图像种类，还允许训练新模型，提高其关注图像元素情感相关组合的能力。这是通过在数据集创建过程中整合符号同位性概念实现的，从而更深入地洞察图像的情感内容。实证评估表明，使用我们方法生成的数据集训练的模型始终优于在原始数据集合上训练的模型，在主要VSA基准测试中实现了更优的泛化性能。",
            "intro_zh": [
                "核心问题：视觉情感分析面临数据集规模有限和模型泛化能力不足的挑战，导致跨数据集性能下降。",
                "方法要点：引入符号同位性概念指导数据集构建，整合现有数据以创建更丰富、情感元素组合更显著的新数据集。",
                "实验或效果：新数据集训练的模型在主要基准测试中表现更优，泛化性能显著提升，验证了方法的有效性。"
            ],
            "method_zh": "论文提出一种基于符号同位性指导的数据集构建框架。整体框架从现有VSA数据集合出发，通过符号同位性分析图像中的情感元素组合，筛选和重组图像以构建更大、更多样化的新数据集。关键技术创新点在于将符号学中的同位性概念应用于视觉情感分析，该方法强调图像元素在情感表达上的一致性，从而更精准地识别情感相关特征。与现有方法的主要区别在于，传统方法通常依赖人工标注或简单数据增强，而本方法通过符号同位性提供理论指导，实现数据集的智能扩展，提升模型对情感内容的聚焦能力。",
            "application_zh": "该研究可应用于社交媒体情感监控、广告效果评估、心理健康辅助诊断等领域。通过提升视觉情感分析的准确性和泛化能力，有助于更精准地理解用户情感反馈，优化内容推荐和情感交互系统，具有重要的实际价值。",
            "highlight_zh": "实验结果显示，使用新数据集训练的模型在多个VSA基准测试中均优于原始数据集训练的模型，泛化性能显著提升，证明了符号同位性指导在数据集构建中的有效性，为视觉情感分析提供了新的数据增强策略。",
            "tags_zh": [
                "视觉情感分析",
                "数据集构建",
                "符号同位性",
                "泛化性能",
                "情感元素识别",
                "多模态分析",
                "机器学习模型"
            ],
            "_index": 12
        },
        {
            "title": "gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation",
            "authors": [
                "Alban Puech",
                "Matteo Mazzonelli",
                "Celia Cintas",
                "Tamara R. Govindasamy",
                "Mangaliso Mngomezulu",
                "Jonas Weiss",
                "Matteo Baù",
                "Anna Varbella",
                "François Mirallès",
                "Kibaek Kim",
                "Le Xie",
                "Hendrik F. Hamann",
                "Etienne Vos",
                "Thomas Brunschwiler"
            ],
            "arxiv_id": "2512.14658v1",
            "summary": "We introduce gridfm-datakit-v1, a Python library for generating realistic and diverse Power Flow (PF) and Optimal Power Flow (OPF) datasets for training Machine Learning (ML) solvers. Existing datasets and libraries face three main challenges: (1) lack of realistic stochastic load and topology perturbations, limiting scenario diversity; (2) PF datasets are restricted to OPF-feasible points, hindering generalization of ML solvers to cases that violate operating limits (e.g., branch overloads or voltage violations); and (3) OPF datasets use fixed generator cost functions, limiting generalization across varying costs. gridfm-datakit addresses these challenges by: (1) combining global load scaling from real-world profiles with localized noise and supporting arbitrary N-k topology perturbations to create diverse yet realistic datasets; (2) generating PF samples beyond operating limits; and (3) producing OPF data with varying generator costs. It also scales efficiently to large grids (up to 10,000 buses). Comparisons with OPFData, OPF-Learn, PGLearn, and PF$Δ$ are provided. Available on GitHub at https://github.com/gridfm/gridfm-datakit under Apache 2.0 and via `pip install gridfm-datakit`.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "eess.SY",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Main equal contributors: Alban Puech, Matteo Mazzonelli. Other equal contributors: Celia Cintas, Tamara R. Govindasamy, Mangaliso Mngomezulu, Jonas Weiss",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14658v1",
            "code_links": [
                {
                    "url": "https://github.com/gridfm/gridfm-datakit",
                    "type": "github"
                }
            ],
            "headline_zh": "提出gridfm-datakit-v1 Python库，以生成可扩展且现实的电力潮流和最优潮流数据集，解决现有方法在多样性、泛化性和成本变化方面的不足。",
            "summary_zh": "我们介绍了gridfm-datakit-v1，这是一个用于生成现实且多样化的电力潮流（PF）和最优潮流（OPF）数据集的Python库，旨在训练机器学习（ML）求解器。现有数据集和库面临三个主要挑战：（1）缺乏现实的随机负荷和拓扑扰动，限制了场景多样性；（2）PF数据集仅限于OPF可行点，阻碍了ML求解器对违反运行限制（如支路过载或电压违规）情况的泛化；（3）OPF数据集使用固定的发电机成本函数，限制了在不同成本下的泛化能力。gridfm-datakit通过以下方式应对这些挑战：（1）结合来自真实世界配置文件的全局负荷缩放与局部噪声，并支持任意N-k拓扑扰动，以创建多样且现实的数据集；（2）生成超出运行限制的PF样本；（3）生成具有变化发电机成本的OPF数据。它还能高效扩展到大型电网（最多10,000个节点）。提供了与OPFData、OPF-Learn、PGLearn和PF$Δ$的比较。该库可在GitHub上获取，网址为https://github.com/gridfm/gridfm-datakit，遵循Apache 2.0许可，并通过`pip install gridfm-datakit`安装。",
            "intro_zh": [
                "现有方法缺乏现实随机负荷和拓扑扰动，导致数据集多样性不足，限制了机器学习求解器的训练效果。",
                "通过结合全局负荷缩放与局部噪声，并支持任意N-k拓扑扰动，生成多样且现实的PF和OPF数据集，同时包含超出运行限制的样本和变化成本。",
                "库能高效扩展到10,000节点电网，相比现有工具，在数据多样性和泛化性方面有显著提升，支持更稳健的ML求解器训练。"
            ],
            "method_zh": "gridfm-datakit-v1的整体框架是一个基于Python的数据生成库，专注于电力系统仿真。关键技术创新点包括：结合真实世界负荷配置文件的全局缩放与局部噪声注入，以模拟现实负荷变化；支持任意N-k拓扑扰动，增强数据集的拓扑多样性；生成超出运行限制（如电压违规或支路过载）的PF样本，以提升ML求解器的泛化能力；以及引入变化发电机成本函数，使OPF数据更贴近实际运营场景。与现有方法的主要区别在于，它解决了现有库在随机扰动、泛化边界和成本固定性方面的局限性，提供了更全面和可扩展的数据生成能力。",
            "application_zh": "该研究主要应用于电力系统优化和机器学习领域，潜在应用包括训练用于电力潮流和最优潮流求解的机器学习模型，支持电网规划、实时监控和能源管理。实际价值在于提供高质量、多样化的数据集，促进更稳健和泛化性强的AI求解器开发，提升电力系统运营的效率和可靠性。",
            "highlight_zh": "实验表明，gridfm-datakit能高效生成多达10,000节点的大型电网数据集，相比OPFData、OPF-Learn等现有工具，在数据多样性、泛化性和成本变化方面有显著改进，支持更全面的ML求解器训练场景。",
            "tags_zh": [
                "潮流数据生成",
                "最优潮流数据生成",
                "机器学习求解器",
                "电网仿真",
                "数据多样性",
                "可扩展性",
                "Python库",
                "大规模电网"
            ],
            "_index": 13
        },
        {
            "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
            "authors": [
                "Alessandro Trapasso",
                "Luca Iocchi",
                "Fabio Patrizi"
            ],
            "arxiv_id": "2512.14617v1",
            "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 32 figures, includes appendix",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14617v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reinforcement learning",
                        "RL",
                        "reward"
                    ],
                    "score": 3
                }
            ],
            "headline_zh": "提出WaveSim，一种基于小波变换的多尺度相似性度量方法，用于评估天气和气候空间场。",
            "summary_zh": "我们介绍了WaveSim，一种用于评估天气和气候应用中空间场的多尺度相似性度量方法。WaveSim利用小波变换将输入场分解为尺度特定的小波系数。该度量通过乘以从这些系数导出的三个正交分量构建：幅度，量化系数能量分布的相似性，即场的强度；位移，通过比较归一化能量分布的质量中心来捕捉空间偏移；以及结构，评估独立于位置和幅度的模式组织。每个分量产生一个尺度特定的相似性得分，范围从0（无相似性）到1（完美相似性），然后跨尺度组合以产生整体相似性度量。我们首先使用合成测试案例评估WaveSim，应用受控的空间和时间扰动来系统评估其敏感性和预期行为。然后，我们展示了其在物理相关案例研究中的适用性，这些案例研究涉及地球系统模型中关键的气候变率模式。传统的逐点度量缺乏将误差归因于物理尺度或差异模式的机制。通过在小波域操作并沿独立轴分解信号，WaveSim绕过了这些限制，并为评估复杂场中的相似性提供了一个可解释且诊断丰富的框架。此外，WaveSim框架允许用户强调特定尺度或分量，并适用于用户特定的模型比较、模型评估以及预测系统的校准和训练。我们提供了WaveSim的PyTorch就绪实现，以及所有评估脚本，网址为：https://github.com/gabrieleaccarino/wavesim。",
            "intro_zh": [
                "传统逐点度量无法将误差归因于物理尺度或差异模式，限制了天气和气候场评估的深度诊断能力。",
                "WaveSim利用小波变换分解场，通过幅度、位移和结构三个正交分量量化多尺度相似性，提供可解释的评估框架。",
                "在合成测试和气候变率案例中，WaveSim表现出对空间和时间扰动的敏感性，并成功应用于模型比较和预测系统训练。"
            ],
            "method_zh": "WaveSim的整体框架基于小波变换，将输入空间场分解为尺度特定的小波系数。关键技术创新点在于从系数中提取三个正交分量：幅度分量量化能量分布相似性，反映场强度；位移分量通过比较归一化能量分布的质量中心来捕捉空间偏移；结构分量评估模式组织，独立于位置和振幅。这些分量分别计算尺度特定相似性得分（0到1），然后跨尺度组合形成整体度量。与现有方法的主要区别在于，传统逐点度量（如均方误差）缺乏多尺度分解和正交分量分析，而WaveSim通过小波域操作提供了更丰富、可解释的相似性评估，能够区分不同物理尺度的差异模式。",
            "application_zh": "WaveSim适用于天气和气候领域的模型比较、模型评估、预测系统校准和训练。其多尺度分析能力有助于诊断地球系统模型中的气候变率模式，提升模型性能优化和物理过程理解。",
            "highlight_zh": "WaveSim在合成测试中表现出对空间和时间扰动的敏感性，验证了其预期行为。在气候变率案例研究中，成功应用于评估地球系统模型，提供了比传统度量更丰富的诊断信息，支持用户强调特定尺度或分量。",
            "tags_zh": [
                "小波变换",
                "多尺度相似性度量",
                "天气气候场评估",
                "模型比较",
                "预测系统训练",
                "空间场分析",
                "正交分量分解"
            ],
            "_index": 14
        },
        {
            "title": "DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors",
            "authors": [
                "Yiheng Huang",
                "Junhong Chen",
                "Anqi Ning",
                "Zhanhong Liang",
                "Nick Michiels",
                "Luc Claesen",
                "Wenyin Liu"
            ],
            "arxiv_id": "2512.14536v1",
            "summary": "Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "8 pages, 7 figures",
            "doi": "10.1109/LRA.2025.3644148",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14536v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "自动驾驶",
                    "matched_keywords": [
                        "nuScenes"
                    ],
                    "score": 1
                },
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 2
                },
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出ViRC框架，通过Reason Chunking机制增强多模态数学推理中的视觉交错思维链",
            "summary_zh": "思维链显著提升了大型语言模型的推理能力，但在扩展到多模态领域时面临挑战，特别是在数学任务中。现有的多模态大语言模型通常仅从单个静态数学图像进行文本推理，忽视了推理过程中的动态视觉获取。相比之下，人类会反复检查视觉图像，并采用逐步推理来证明中间命题。这种将问题解决过程分解为关键逻辑节点的策略符合认知科学中的米勒定律。受此启发，我们提出了一个用于多模态数学任务的ViRC框架，引入了Reason Chunking机制，将多模态数学思维链结构化为连续的Critical Reasoning Units，以模拟人类专家的问题解决模式。CRUs确保单元内的文本连贯性以验证中间命题，同时跨单元整合视觉信息以生成后续命题并支持结构化推理。为此，我们使用三种视觉工具和四种推理模式构建了CRUX数据集，为每个数学问题提供跨多个推理路径的显式标注CRUs。利用CRUX数据集，我们提出了一种受人类认知学习启发的渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，旨在进一步增强模型的Reason Chunking能力。由此产生的ViRC-7B模型在多个数学基准测试中平均比基线提升了18.8%。代码可在https://github.com/Leon-LihongWang/ViRC获取。",
            "intro_zh": [
                "现有MLLMs在数学任务中仅从静态图像推理，缺乏动态视觉获取，导致多模态推理能力受限。",
                "提出Reason Chunking机制，将推理过程分解为Critical Reasoning Units，模拟人类逐步验证的认知模式。",
                "ViRC-7B模型在多个数学基准上平均提升18.8%，验证了框架在增强多模态数学推理中的有效性。"
            ],
            "method_zh": "ViRC框架的核心是Reason Chunking机制，它将多模态数学思维链分解为连续的Critical Reasoning Units。每个CRU作为一个关键逻辑节点，确保单元内文本连贯性以验证中间命题，同时跨单元整合视觉信息生成后续命题。关键创新包括：构建CRUX数据集，使用三种视觉工具和四种推理模式提供显式标注的CRUs；设计渐进式训练策略，结合Instructional SFT、Practice SFT和Strategic RL，模拟人类认知学习过程。与现有方法的主要区别在于，ViRC强调动态视觉获取和结构化推理，而非仅依赖静态图像的单次文本推理。",
            "application_zh": "该研究可应用于教育技术中的智能数学辅导系统，帮助学生通过视觉交互逐步解决复杂问题；也可用于自动化数学问题求解工具，提升多模态场景下的推理准确性。潜在价值在于推动多模态AI在科学、工程等领域的结构化推理能力发展。",
            "highlight_zh": "ViRC-7B模型在多个数学基准测试中实现平均18.8%的性能提升，显著优于基线方法，证明了Reason Chunking机制在增强多模态数学推理中的有效性。",
            "tags_zh": [
                "多模态推理",
                "数学思维链",
                "视觉交错",
                "Reason Chunking",
                "Critical Reasoning Units",
                "渐进式训练",
                "认知科学启发",
                "结构化推理"
            ],
            "_index": 15
        },
        {
            "title": "CoLD Fusion: A Real-time Capable Spline-based Fusion Algorithm for Collective Lane Detection",
            "authors": [
                "Jörg Gamerdinger",
                "Sven Teufel",
                "Georg Volk",
                "Oliver Bringmann"
            ],
            "arxiv_id": "2512.14355v1",
            "summary": "Comprehensive environment perception is essential for autonomous vehicles to operate safely. It is crucial to detect both dynamic road users and static objects like traffic signs or lanes as these are required for safe motion planning. However, in many circumstances a complete perception of other objects or lanes is not achievable due to limited sensor ranges, occlusions, and curves. In scenarios where an accurate localization is not possible or for roads where no HD maps are available, an autonomous vehicle must rely solely on its perceived road information. Thus, extending local sensing capabilities through collective perception using vehicle-to-vehicle communication is a promising strategy that has not yet been explored for lane detection. Therefore, we propose a real-time capable approach for collective perception of lanes using a spline-based estimation of undetected road sections. We evaluate our proposed fusion algorithm in various situations and road types. We were able to achieve real-time capability and extend the perception range by up to 200%.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at IEEE IV 2023",
            "doi": "10.1109/IV55152.2023.10186632",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14355v1",
            "code_links": [],
            "headline_zh": "提出可适应脑肿瘤分割流程，通过影像组学引导亚型识别和病灶级模型集成提升多类型肿瘤分割性能。",
            "summary_zh": "在多参数磁共振成像（MRI）上实现稳健且可泛化的脑肿瘤分割仍然困难，因为肿瘤类型差异很大。BraTS 2025 Lighthouse挑战赛在多样化的高质量成人及儿童肿瘤数据集上评估分割方法：国际多中心儿童脑肿瘤分割（PED）、术前脑膜瘤分割（MEN）、脑膜瘤放疗分割（MEN-RT）以及治疗前后脑转移瘤分割（MET）。我们提出了一种灵活、模块化且可适应的流程，通过选择和组合最先进的模型，并在训练前后应用肿瘤和病灶特异性处理来提升分割性能。从MRI中提取的影像组学特征有助于检测肿瘤亚型，确保更平衡的训练。定制的病灶级性能指标确定集成中每个模型的影响，并优化进一步细化预测的后处理，使工作流程能够针对每个病例定制每一步。在BraTS测试集上，我们的流程在多个挑战中取得了与排名靠前算法相当的性能。这些发现证实，定制的病灶感知处理和模型选择能够产生稳健的分割，同时不将方法锁定于特定的网络架构。我们的方法在临床实践中具有定量肿瘤测量的潜力，支持诊断和预后。",
            "intro_zh": [
                "核心问题：脑肿瘤类型多样，现有分割方法难以在MRI上实现稳健且可泛化的分割，尤其是在成人及儿童肿瘤、脑膜瘤和转移瘤等不同数据集上。",
                "方法要点：提出灵活可适应流程，结合影像组学引导亚型识别、病灶级模型集成和定制后处理，针对不同肿瘤类型优化分割步骤。",
                "实验或效果：在BraTS 2025 Lighthouse挑战赛的多个测试集上，性能与顶级算法相当，证实了方法的有效性和泛化能力。"
            ],
            "method_zh": "整体框架是一个模块化、可适应的分割流程，包括模型选择、训练优化和预测后处理。关键技术创新点在于：1）利用影像组学特征进行肿瘤亚型检测，以平衡训练数据；2）采用病灶级性能指标指导模型集成，确定每个模型在集成中的权重；3）应用肿瘤和病灶特异性后处理进一步细化分割结果。与现有方法的主要区别在于，该方法不依赖于单一网络架构，而是通过灵活组合现有模型和定制处理步骤，实现针对不同肿瘤类型的自适应分割，提高了泛化性和鲁棒性。",
            "application_zh": "该研究在临床医学影像分析领域具有重要应用价值，可用于脑肿瘤的定量测量，支持诊断、预后评估和治疗规划，特别是在多类型肿瘤（如儿童肿瘤、脑膜瘤、转移瘤）的MRI分割任务中，有助于提升临床决策的准确性和效率。",
            "highlight_zh": "在BraTS 2025 Lighthouse挑战赛的测试集上，该流程在PED、MEN、MEN-RT和MET等多个数据集上均取得了与排名靠前算法相当的分割性能，证明了其在不同肿瘤类型上的稳健性和泛化能力，无需锁定特定网络架构即可实现高效分割。",
            "tags_zh": [
                "脑肿瘤分割",
                "多参数MRI",
                "影像组学",
                "模型集成",
                "病灶级处理",
                "自适应流程",
                "临床影像分析",
                "BraTS挑战赛"
            ],
            "_index": 16
        },
        {
            "title": "Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding",
            "authors": [
                "Nando Metzger",
                "Prune Truong",
                "Goutam Bhat",
                "Konrad Schindler",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14236v1",
            "summary": "The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: elastic3d.github.io",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14236v1",
            "code_links": [],
            "headline_zh": "提出TiME（微型单语编码器）以解决大型语言模型在效率关键应用中速度慢、能耗高的问题",
            "summary_zh": "当前语言模型研究主要集中于大型通用模型，但许多自然语言处理（NLP）流水线仅需具备明确、小型能力集的模型。大型模型虽能执行这些任务，但处理大量数据或提供实时响应时速度不足，且能耗过高，导致可持续性担忧及在电池供电设备上部署困难。本研究展示了如何为这类效率关键应用训练小型模型。与许多现成NLP流水线不同，我们的模型采用蒸馏等现代训练技术，并支持低资源语言。我们称这些模型为TiME（微型单语编码器），在一系列常见NLP任务上全面评估，观察到在基准性能与吞吐量、延迟和能耗之间实现了更好的权衡。此外，我们证明了从多语言教师模型蒸馏单语模型是可行的，同样可以从具有相对位置嵌入的教师模型蒸馏出具有绝对位置嵌入的模型。",
            "intro_zh": [
                "核心问题：大型通用语言模型在效率关键应用中速度慢、能耗高，难以处理大数据或实时响应，且部署在电池设备上存在可持续性问题。",
                "方法要点：提出TiME模型，通过蒸馏等现代训练技术训练小型单语编码器，支持低资源语言，优化性能与效率的权衡。",
                "实验或效果：在常见NLP任务上评估，TiME在基准性能、吞吐量、延迟和能耗方面表现更优，验证了蒸馏单语模型的可行性。"
            ],
            "method_zh": "TiME的整体框架基于微型单语编码器，采用蒸馏技术从大型多语言教师模型训练小型模型。关键技术创新点包括：从多语言教师蒸馏单语模型，以及从具有相对位置嵌入的教师蒸馏出具有绝对位置嵌入的模型。与现有方法的主要区别在于，TiME专注于效率优化，而非追求通用性，通过现代训练方法提升小型模型在特定任务上的性能，同时显著降低计算资源需求。",
            "application_zh": "TiME适用于需要高效处理大量数据或实时响应的NLP流水线，如低资源语言处理、电池供电设备（如移动设备或物联网设备）上的部署，以及可持续性要求高的应用场景，能减少能耗并提升响应速度。",
            "highlight_zh": "实验结果显示，TiME在一系列常见NLP任务上实现了基准性能与吞吐量、延迟和能耗的更好权衡，验证了从多语言教师蒸馏单语模型的可行性，并成功从相对位置嵌入教师蒸馏出绝对位置嵌入模型，提升了小型模型的效率。",
            "tags_zh": [
                "微型语言模型",
                "单语编码器",
                "蒸馏训练",
                "效率优化",
                "低资源语言",
                "能耗降低",
                "实时响应",
                "NLP流水线"
            ],
            "_index": 17
        },
        {
            "title": "OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving",
            "authors": [
                "Tao Tang",
                "Enhui Ma",
                "xia zhou",
                "Letian Wang",
                "Tianyi Yan",
                "Xueyang Zhang",
                "Kun Zhan",
                "Peng Jia",
                "XianPeng Lang",
                "Jia-Wang Bian",
                "Kaicheng Yu",
                "Xiaodan Liang"
            ],
            "arxiv_id": "2512.14225v1",
            "summary": "Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ACM MM 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14225v1",
            "code_links": [],
            "headline_zh": "提出首个多中心淋巴瘤分型基准数据集，系统评估病理基础模型与多实例学习聚合器在HE染色全切片图像上的性能。",
            "summary_zh": "及时准确的淋巴瘤诊断对指导癌症治疗至关重要。标准诊断实践结合苏木精-伊红（HE）染色全切片图像与免疫组化、流式细胞术和分子遗传学检测来确定淋巴瘤亚型，这一过程需要昂贵设备、熟练人员并导致治疗延迟。深度学习方法可通过从常规可用的HE染色切片中提取诊断信息来协助病理学家，但多中心数据上的淋巴瘤分型综合基准仍缺乏。在这项工作中，我们提出了首个多中心淋巴瘤基准数据集，涵盖四种常见淋巴瘤亚型和健康对照组织。我们系统评估了五种公开可用的病理基础模型（H-optimus-1、H0-mini、Virchow2、UNI2、Titan）与基于注意力（AB-MIL）和基于Transformer（TransMIL）的多实例学习聚合器在三种放大倍数（10x、20x、40x）下的组合。在分布内测试集上，模型在所有放大倍数下实现了超过80%的多类平衡准确率，所有基础模型表现相似，两种聚合方法结果相当。放大倍数研究表明，40x分辨率已足够，更高分辨率或跨放大倍数聚合未带来性能提升。然而，在分布外测试集上，性能显著下降至约60%，突显了显著的泛化挑战。为推进该领域，需要覆盖更多罕见淋巴瘤亚型的更大规模多中心研究。我们提供了一个自动化基准测试流程以促进此类未来研究。",
            "intro_zh": [
                "现有淋巴瘤诊断依赖多模态检测，成本高、耗时长，且缺乏多中心HE图像分型基准。",
                "论文提出首个多中心淋巴瘤基准数据集，并系统评估病理基础模型与多实例学习聚合器的组合。",
                "模型在分布内测试集上准确率超80%，但分布外性能降至约60%，揭示泛化挑战。"
            ],
            "method_zh": "论文采用多实例学习框架处理全切片图像，将每个切片视为实例包，每个实例对应图像块。核心方法结合预训练的病理基础模型（如H-optimus-1、Virchow2等）提取特征，然后使用基于注意力的AB-MIL或基于Transformer的TransMIL聚合器整合实例级特征，生成切片级预测。关键创新在于首次在多中心淋巴瘤数据集上系统比较多种基础模型与聚合器，并研究放大倍数的影响。与现有方法相比，该方法避免了从头训练，利用公开基础模型，并通过基准测试提供了标准化评估。",
            "application_zh": "该研究可应用于病理学辅助诊断，帮助从常规HE染色切片中快速识别淋巴瘤亚型，减少对昂贵辅助检测的依赖，加速诊断流程，尤其在资源有限或远程医疗场景中具有实际价值。",
            "highlight_zh": "在分布内测试集上，所有模型组合在10x、20x、40x放大倍数下均实现超过80%的多类平衡准确率，表明40x分辨率已足够且无需更高分辨率。然而，分布外测试集性能大幅下降至约60%，突显模型泛化能力不足，是未来研究的关键挑战。",
            "tags_zh": [
                "淋巴瘤分型",
                "全切片图像分析",
                "多实例学习",
                "病理基础模型",
                "多中心基准",
                "HE染色图像",
                "注意力机制",
                "Transformer聚合"
            ],
            "_index": 18
        },
        {
            "title": "Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination",
            "authors": [
                "Zhuoxiao Li",
                "Wenzong Ma",
                "Taoyu Wu",
                "Jinjing Zhu",
                "Zhenchao Q",
                "Shuai Zhang",
                "Jing Ou",
                "Yinrui Ren",
                "Weiqing Qi",
                "Guobin Shen",
                "Hui Xiong",
                "Wufan Zhao"
            ],
            "arxiv_id": "2512.14200v1",
            "summary": "Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14200v1",
            "code_links": [],
            "headline_zh": "提出AMD-HookNet++混合CNN-Transformer特征增强方法，用于合成孔径雷达图像中的冰川崩解前沿分割。",
            "summary_zh": "冰川和冰架前沿的动态变化对冰盖质量平衡和沿海海平面有重要影响。为有效监测冰川状况，持续估计冰川崩解前沿的位置变化至关重要。AMD-HookNet首次引入了纯双分支卷积神经网络（CNN）进行冰川分割，但卷积操作的局部性和平移不变性虽然有利于捕捉低级细节，却限制了模型保持长程依赖关系的能力。本研究提出AMD-HookNet++，一种新颖的先进混合CNN-Transformer特征增强方法，用于在合成孔径雷达图像中分割冰川并描绘崩解前沿。我们的混合结构包括两个分支：一个基于Transformer的上下文分支，用于捕获长程依赖关系，在更大视野中提供全局上下文信息；以及一个基于CNN的目标分支，用于保留局部细节。为增强连接混合特征的表示，我们设计了一个增强的空间通道注意力模块，通过从空间和通道角度动态调整令牌关系，促进混合CNN-Transformer分支之间的交互。此外，我们开发了像素到像素对比深度监督，通过将像素级度量学习集成到冰川分割中，优化我们的混合模型。通过在具有挑战性的冰川分割基准数据集CaFFe上进行广泛实验和全面的定量与定性分析，我们表明AMD-HookNet++以78.2的IoU和1,318米的HD95设定了新的最先进水平，同时保持了367米的竞争性MDE。更重要的是，我们的混合模型产生了更平滑的崩解前沿描绘，解决了纯基于Transformer方法中常见的锯齿边缘问题。",
            "intro_zh": [
                "现有纯CNN方法（如AMD-HookNet）在冰川分割中难以捕获长程依赖关系，导致全局上下文信息不足。",
                "提出混合CNN-Transformer架构，结合Transformer分支捕获全局上下文和CNN分支保留局部细节，并引入增强注意力模块优化特征交互。",
                "在CaFFe数据集上，AMD-HookNet++达到78.2 IoU和1,318米HD95，显著提升分割精度并生成更平滑的崩解前沿。"
            ],
            "method_zh": "AMD-HookNet++采用双分支混合架构：一个基于Transformer的上下文分支捕获长程依赖和全局上下文，另一个基于CNN的目标分支保留局部细节。关键创新包括增强的空间通道注意力模块，通过动态调整空间和通道维度的令牌关系，促进分支间特征交互；以及像素到像素对比深度监督，集成像素级度量学习优化模型。与现有方法的主要区别在于结合了CNN的局部细节能力和Transformer的全局建模优势，解决了纯CNN方法的长程依赖限制和纯Transformer方法的锯齿边缘问题。",
            "application_zh": "该研究主要应用于冰川监测和气候变化研究领域，通过合成孔径雷达图像中的冰川崩解前沿分割，支持冰盖质量平衡评估和沿海海平面变化预测，具有重要的环境科学和地球观测价值。",
            "highlight_zh": "在CaFFe基准数据集上，AMD-HookNet++达到78.2 IoU和1,318米HD95，优于现有方法，同时保持367米MDE；定性分析显示模型能生成更平滑的崩解前沿，有效减少锯齿边缘。",
            "tags_zh": [
                "冰川分割",
                "合成孔径雷达图像",
                "CNN-Transformer混合架构",
                "空间通道注意力",
                "像素级对比学习",
                "崩解前沿检测",
                "长程依赖建模",
                "环境监测"
            ],
            "_index": 19
        },
        {
            "title": "CIS-BA: Continuous Interaction Space Based Backdoor Attack for Object Detection in the Real-World",
            "authors": [
                "Shuxin Zhao",
                "Bo Lang",
                "Nan Xiao",
                "Yilang Zhang"
            ],
            "arxiv_id": "2512.14158v1",
            "summary": "Object detection models deployed in real-world applications such as autonomous driving face serious threats from backdoor attacks. Despite their practical effectiveness,existing methods are inherently limited in both capability and robustness due to their dependence on single-trigger-single-object mappings and fragile pixel-level cues. We propose CIS-BA, a novel backdoor attack paradigm that redefines trigger design by shifting from static object features to continuous inter-object interaction patterns that describe how objects co-occur and interact in a scene. By modeling these patterns as a continuous interaction space, CIS-BA introduces space triggers that, for the first time, enable a multi-trigger-multi-object attack mechanism while achieving robustness through invariant geometric relations. To implement this paradigm, we design CIS-Frame, which constructs space triggers via interaction analysis, formalizes them as class-geometry constraints for sample poisoning, and embeds the backdoor during detector training. CIS-Frame supports both single-object attacks (object misclassification and disappearance) and multi-object simultaneous attacks, enabling complex and coordinated effects across diverse interaction states. Experiments on MS-COCO and real-world videos show that CIS-BA achieves over 97% attack success under complex environments and maintains over 95% effectiveness under dynamic multi-trigger conditions, while evading three state-of-the-art defenses. In summary, CIS-BA extends the landscape of backdoor attacks in interaction-intensive scenarios and provides new insights into the security of object detection systems.",
            "categories": [
                "cs.CV",
                "cs.CR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14158v1",
            "code_links": [],
            "headline_zh": "提出MuseCPBench基准以解决音乐编辑中音乐上下文保存评估不一致的问题。",
            "summary_zh": "音乐编辑在现代音乐制作中扮演着关键角色，应用于电影、广播和游戏开发等领域。近年来，音乐生成模型的进步使得音色转换、乐器替换和风格变换等多样化编辑任务成为可能。然而，许多现有工作忽视了评估编辑过程中应保持不变的音乐方面——我们将其定义为音乐上下文保存（MCP）。尽管一些研究考虑了MCP，但它们采用了不一致的评估协议和指标，导致不可靠和不公平的比较。为填补这一空白，我们引入了首个MCP评估基准MuseCPBench，涵盖四类音乐方面，并支持对五种代表性音乐编辑基线方法进行全面比较。通过对音乐方面、方法和模型的系统分析，我们识别出当前音乐编辑方法中一致的保存差距，并提供深入解释。我们希望这些发现能为开发具有强大MCP能力的更有效和可靠音乐编辑策略提供实用指导。",
            "intro_zh": [
                "现有音乐编辑方法在评估音乐上下文保存（MCP）时缺乏统一标准，导致比较不可靠。",
                "论文提出首个MCP评估基准MuseCPBench，涵盖四类音乐方面，支持对五种基线方法的全面比较。",
                "通过系统分析，识别出当前方法的保存差距，为改进编辑策略提供实用指导。"
            ],
            "method_zh": "论文的核心方法是构建MuseCPBench基准，整体框架包括定义音乐上下文保存（MCP）概念、设计四类音乐方面（如旋律、节奏、和声和音色）的评估指标，并集成五种代表性音乐编辑基线方法（如基于生成模型的编辑技术）。关键技术创新点在于首次系统化MCP评估，通过标准化协议确保公平比较。与现有方法的主要区别在于，现有工作多关注编辑效果本身，而MuseCPBench强调保存不变属性的评估，填补了评估空白。",
            "application_zh": "该研究可应用于音乐制作、电影配乐、游戏音频和广播编辑等领域，帮助开发者评估和改进音乐编辑模型的上下文保存能力，提升编辑质量和可靠性。",
            "highlight_zh": "实验结果显示，MuseCPBench基准能有效识别当前音乐编辑方法在保存音乐上下文方面的差距，例如在特定音乐方面（如和声）的保存性能普遍较低，为未来方法优化提供了明确方向。",
            "tags_zh": [
                "音乐编辑",
                "音乐上下文保存",
                "评估基准",
                "音乐生成模型",
                "多任务比较",
                "音乐制作",
                "标准化评估"
            ],
            "_index": 20
        },
        {
            "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
            "authors": [
                "Yankai Jiang",
                "Yujie Zhang",
                "Peng Zhang",
                "Yichen Li",
                "Jintai Chen",
                "Xiaoming Shi",
                "Shihui Zhen"
            ],
            "arxiv_id": "2512.14157v1",
            "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",
            "categories": [
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14157v1",
            "code_links": [],
            "headline_zh": "提出单帧视频集蒸馏框架以解决视频数据集蒸馏中参数激增和优化困难的问题。",
            "summary_zh": "数据集蒸馏旨在合成紧凑而信息丰富的数据集，使在其上训练的模型能达到与在全数据集上训练相当的性能。虽然该方法在图像数据上已显示出有希望的结果，但将数据集蒸馏方法扩展到视频数据已被证明具有挑战性，并且通常导致次优性能。在这项工作中，我们首先将视频集蒸馏的核心挑战确定为视频时间维度引入的可学习参数大幅增加，这使优化复杂化并阻碍收敛。为解决此问题，我们观察到单个帧通常足以捕捉视频的判别性语义。利用这一见解，我们提出了单帧视频集蒸馏（SFVD），这是一个将视频蒸馏为每个类别高度信息丰富的帧的框架。使用可微分插值，这些帧被转换为视频序列并与原始数据集匹配，同时更新仅限于帧本身以提高优化效率。为了进一步整合时间信息，在匹配过程中通过通道重塑层将蒸馏帧与从真实视频中采样的真实视频结合。在多个基准上的广泛实验表明，SFVD显著优于先前方法，在MiniUCF上实现了高达5.3%的改进，从而提供了更有效的解决方案。",
            "intro_zh": [
                "视频数据集蒸馏面临时间维度导致参数激增，优化复杂且收敛困难。",
                "提出SFVD框架，将视频蒸馏为单帧，通过可微分插值和通道重塑整合时间信息。",
                "在MiniUCF等基准上显著超越现有方法，性能提升最高达5.3%。"
            ],
            "method_zh": "SFVD框架的核心是将视频数据集蒸馏为每个类别的代表性单帧。整体框架包括：首先，为每个类别合成高度信息丰富的单帧作为蒸馏核心；其次，通过可微分插值技术将这些单帧扩展为视频序列，以模拟原始视频的时间动态；第三，在匹配过程中，通过通道重塑层将蒸馏帧与采样的真实视频结合，以整合额外的时间信息。关键技术创新在于将优化限制在单帧上，大幅减少可学习参数，从而简化优化过程并提高效率。与现有方法的主要区别在于避免了直接处理高维视频序列的复杂性，而是通过单帧蒸馏和插值策略有效捕捉视频的判别性语义，同时通过通道重塑引入时间上下文，实现更优的性能。",
            "application_zh": "该研究在视频理解、动作识别和视频分类等领域具有潜在应用价值，能显著降低视频数据存储和计算成本，加速模型训练，适用于资源受限环境如边缘设备或大规模视频分析系统。",
            "highlight_zh": "在MiniUCF基准上，SFVD实现了高达5.3%的性能提升，显著优于先前视频数据集蒸馏方法，验证了单帧蒸馏框架的有效性和优化效率。",
            "tags_zh": [
                "视频数据集蒸馏",
                "单帧蒸馏",
                "可微分插值",
                "通道重塑",
                "优化效率",
                "动作识别",
                "视频分类",
                "计算成本降低"
            ],
            "_index": 21
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057v1",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057v1",
            "code_links": [],
            "headline_zh": "提出JMMMU-Pro基准和Vibe Benchmark Construction方法，以低成本构建高质量日语多学科多模态理解评估工具。",
            "summary_zh": "本文介绍了JMMMU-Pro，一个基于图像的日语多学科多模态理解基准，以及Vibe Benchmark Construction，一种可扩展的构建方法。继从MMMU到MMMU-Pro的演进后，JMMMU-Pro通过将问题图像和问题文本组合成单一图像来扩展JMMMU，从而创建一个需要通过视觉感知进行集成视觉-文本理解的基准。为了构建JMMMU-Pro，我们提出了Vibe Benchmark Construction方法，其中图像生成模型（如Nano Banana Pro）生成候选视觉问题，人类验证输出并在必要时通过调整提示重新生成以确保质量。通过利用Nano Banana Pro的高度真实图像生成能力及其嵌入清晰日语文本的能力，我们以低成本构建了一个高质量的基准，覆盖广泛的背景和布局设计。实验结果表明，所有开源LMM在JMMMU-Pro上都面临显著困难，突显了JMMMU-Pro作为指导开源社区未来努力的重要基准。我们相信，JMMMU-Pro为评估LMM的日语能力提供了更严格的评估工具，而我们的Vibe Benchmark Construction也为未来基于图像的VQA基准开发提供了高效指南。",
            "intro_zh": [
                "现有日语多模态基准在集成视觉-文本理解方面存在不足，难以全面评估LMM的日语能力。",
                "提出Vibe Benchmark Construction方法，结合图像生成模型和人工验证，低成本构建高质量视觉问题图像。",
                "实验显示开源LMM在JMMMU-Pro上表现显著困难，验证了基准的严格性和指导价值。"
            ],
            "method_zh": "论文的核心方法是Vibe Benchmark Construction，整体框架包括使用图像生成模型（如Nano Banana Pro）自动生成候选视觉问题图像，然后通过人工验证和调整提示进行质量控制和迭代优化。关键技术创新点在于利用Nano Banana Pro的高真实感图像生成和日语文本嵌入能力，结合人类反馈循环，实现高效、低成本的基准构建。与现有方法的主要区别在于，传统基准构建通常依赖手动设计或简单合成，而该方法通过生成式AI自动化部分流程，同时保持人类监督以确保多样性和准确性，从而扩展了基准的规模和覆盖范围。",
            "application_zh": "该研究主要应用于评估大型多模态模型（LMM）的日语多模态理解能力，为开源社区提供严格的基准测试工具。潜在应用领域包括日语教育、跨语言AI系统开发、以及多模态人机交互，实际价值在于推动日语AI技术的标准化和性能提升。",
            "highlight_zh": "最重要的实验结果是所有开源LMM在JMMMU-Pro基准上都表现出显著困难，突显了该基准的挑战性和评估有效性，为未来LMM的日语能力改进提供了明确方向。",
            "tags_zh": [
                "日语多模态理解",
                "基准构建",
                "图像生成模型",
                "视觉问答",
                "多学科评估",
                "开源LMM",
                "人工验证",
                "低成本构建"
            ],
            "_index": 22
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028v1",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028v1",
            "code_links": [
                {
                    "url": "https://namisntimpot.github.io/NSLweb/",
                    "type": "project_page"
                }
            ],
            "headline_zh": "提出PageRank Transformer（ParaFormer）以解决图Transformer中全局注意力导致的过平滑问题，提升图表示学习性能。",
            "summary_zh": "图Transformer（GTs）作为一种有前景的图学习工具，利用其全连接特性有效捕获全局信息。为应对深度图神经网络（GNNs）中的过平滑问题，全局注意力被引入，从而无需依赖深度GNNs。然而，通过实证和理论分析，我们发现全局注意力本身表现出严重的过平滑现象，由于其固有的低通滤波特性，导致节点表示变得难以区分，这种效应甚至比GNNs中观察到的更强。为缓解此问题，我们提出PageRank Transformer（ParaFormer），其核心是一个PageRank增强的注意力模块，旨在模拟深度Transformer的行为。我们从理论和实证上证明，ParaFormer通过充当自适应通滤波器来减轻过平滑。实验表明，ParaFormer在11个数据集（节点数从数千到数百万）的节点分类和图分类任务中均取得一致的性能提升，验证了其有效性。补充材料（包括代码和附录）可在https://github.com/chaohaoyuan/ParaFormer找到。",
            "intro_zh": [
                "现有图Transformer的全局注意力机制存在严重过平滑问题，导致节点表示趋同，影响图学习性能。",
                "提出PageRank Transformer（ParaFormer），通过PageRank增强的注意力模块模拟深度Transformer，实现自适应滤波以缓解过平滑。",
                "在11个数据集上，ParaFormer在节点分类和图分类任务中均表现出性能提升，验证了其有效性和泛化能力。"
            ],
            "method_zh": "ParaFormer的整体框架基于图Transformer，核心创新在于引入PageRank增强的注意力模块。该模块通过整合PageRank算法来调整注意力权重，使其能够自适应地过滤信息，从而模拟深度Transformer的行为，避免全局注意力固有的低通滤波效应。与现有方法的主要区别在于，传统图Transformer的全局注意力易导致过平滑，而ParaFormer通过PageRank机制实现自适应通滤波，有效平衡局部和全局信息，提升表示学习的区分度。",
            "application_zh": "该研究可应用于社交网络分析、推荐系统、生物信息学和知识图谱等领域，通过提升图表示学习的准确性和鲁棒性，支持节点分类、图分类等任务，具有广泛的工业和研究价值。",
            "highlight_zh": "ParaFormer在11个数据集（节点数从数千到数百万）上均取得性能提升，在节点分类和图分类任务中表现一致优于基线方法，验证了其缓解过平滑的有效性和泛化能力。",
            "tags_zh": [
                "图Transformer",
                "过平滑问题",
                "PageRank算法",
                "自适应滤波",
                "图表示学习",
                "节点分类",
                "图分类",
                "全局注意力"
            ],
            "_index": 23
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020v1",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages. Review Paper on Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020v1",
            "code_links": [],
            "headline_zh": "提出QR-MAX算法，通过奖励机分解非马尔可夫奖励决策过程，实现离散动作环境中的高效模型强化学习。",
            "summary_zh": "许多实际决策问题涉及任务的成功依赖于整个系统历史，而非仅达到具有期望属性的状态。马尔可夫强化学习方法不适用于此类任务，而非马尔可夫奖励决策过程使智能体能够处理时间依赖性任务。这种方法长期以来缺乏在（近）最优性和样本效率方面的形式化保证。我们通过QR-MAX贡献于解决这两个问题，这是一种基于模型的新算法，用于离散非马尔可夫奖励决策过程，通过奖励机将马尔可夫转移学习与非马尔可夫奖励处理分解。据我们所知，这是首个基于模型的强化学习算法，利用这种分解在离散动作非马尔可夫奖励决策过程中实现多项式样本复杂度的PAC收敛到ε-最优策略。然后，我们将QR-MAX扩展到连续状态空间，通过Bucket-QR-MAX，这是一种基于SimHash的离散化器，保持相同的分解结构，无需手动网格化或函数逼近即可实现快速稳定学习。我们在复杂度递增的环境中将我们的方法与现代最先进的基于模型强化学习方法进行实验比较，显示出样本效率的显著提升和寻找最优策略的鲁棒性增强。",
            "intro_zh": [
                "核心问题：现有马尔可夫强化学习方法无法处理依赖历史的任务，而非马尔可夫奖励决策过程方法缺乏最优性和样本效率的形式化保证。",
                "方法要点：提出QR-MAX算法，通过奖励机分解马尔可夫转移和非马尔可夫奖励，实现模型学习与奖励处理的分离。",
                "实验或效果：在复杂环境中，QR-MAX相比现有方法显著提升样本效率，并增强策略最优性的鲁棒性。"
            ],
            "method_zh": "QR-MAX是一种基于模型的强化学习算法，专为离散动作非马尔可夫奖励决策过程设计。整体框架结合奖励机来分解马尔可夫状态转移学习和非马尔可夫奖励处理，关键创新在于利用这种分解实现多项式样本复杂度的PAC收敛到ε-最优策略。与现有方法的主要区别在于，它首次在离散动作环境中通过模型学习提供形式化保证，避免了传统非马尔可夫方法的不稳定性。扩展版本Bucket-QR-MAX使用SimHash离散化器处理连续状态，保持分解结构，无需手动网格化。",
            "application_zh": "该研究适用于需要处理时间依赖性任务的领域，如机器人路径规划、自动驾驶决策和工业控制系统，其中任务成功依赖于历史序列而非单一状态，能提升智能体在复杂环境中的决策效率和鲁棒性。",
            "highlight_zh": "实验显示，QR-MAX在样本效率上显著优于现代最先进的基于模型强化学习方法，在复杂度递增的环境中实现更快的收敛和更高的策略最优性，Bucket-QR-MAX在连续状态空间中保持稳定学习，无需额外函数逼近。",
            "tags_zh": [
                "非马尔可夫奖励决策过程",
                "模型强化学习",
                "奖励机",
                "样本效率",
                "PAC收敛",
                "离散动作",
                "连续状态空间",
                "SimHash离散化"
            ],
            "_index": 24
        },
        {
            "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
            "authors": [
                "Jun Zhang",
                "Teng Wang",
                "Yuying Ge",
                "Yixiao Ge",
                "Xinhao Li",
                "Ying Shan",
                "Limin Wang"
            ],
            "arxiv_id": "2512.14615v1",
            "summary": "We introduce the Overlap-Weighted Hierarchical Normalized Persistence Velocity (OW-HNPV), a novel topological data analysis method for detecting anomalies in time-varying networks. Unlike existing methods that measure cumulative topological presence, we introduce the first velocity-based perspective on persistence diagrams, measuring the rate at which features appear and disappear, automatically downweighting noise through overlap-based weighting. We also prove that OW-HNPV is mathematically stable. It behaves in a controlled, predictable way, even when comparing persistence diagrams from networks with different feature types. Applied to Ethereum transaction networks (May 2017-May 2018), OW-HNPV demonstrates superior performance for cryptocurrency anomaly detection, achieving up to 10.4% AUC gain over baseline models for 7-day price movement predictions. Compared with established methods, including Vector of Averaged Bettis (VAB), persistence landscapes, and persistence images, velocity-based summaries excel at medium- to long-range forecasting (4-7 days), with OW-HNPV providing the most consistent and stable performance across prediction horizons. Our results show that modeling topological velocity is crucial for detecting structural anomalies in dynamic networks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "50 pages, 21 figures. Extended version with full proofs, parameter sweeps, and appendices",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14675v1",
            "code_links": [],
            "headline_zh": "提出基于重叠加权的分层归一化持久性速度方法，用于时变网络异常检测，在加密货币市场预测中实现显著性能提升。",
            "summary_zh": "我们引入了重叠加权分层归一化持久性速度，这是一种用于检测时变网络异常的新型拓扑数据分析方法。与现有测量累积拓扑存在的方法不同，我们首次从速度角度分析持久图，测量特征出现和消失的速率，并通过基于重叠的加权自动降低噪声影响。我们还证明了OW-HNPV在数学上是稳定的，即使在比较具有不同特征类型的网络的持久图时，其行为也是可控且可预测的。应用于以太坊交易网络，OW-HNPV在加密货币异常检测方面表现出优越性能，在7天价格变动预测中比基线模型实现了高达10.4%的AUC增益。与向量平均贝蒂数、持久景观和持久图像等现有方法相比，基于速度的摘要在中长期预测中表现优异，OW-HNPV在不同预测时间范围内提供了最一致和稳定的性能。我们的结果表明，建模拓扑速度对于检测动态网络中的结构异常至关重要。",
            "intro_zh": [
                "现有方法主要关注累积拓扑存在，缺乏对特征动态变化速率的建模，难以有效区分噪声与真实异常。",
                "提出基于速度的持久图分析视角，引入重叠加权机制自动降噪，并证明方法的数学稳定性。",
                "在以太坊交易网络异常检测中，OW-HNPV实现高达10.4%的AUC提升，在中长期预测中表现最稳定。"
            ],
            "method_zh": "整体框架基于拓扑数据分析，将时变网络转化为持久图序列，通过计算特征出现和消失的速率来量化拓扑速度。关键技术创新包括：首次引入速度视角分析持久图，提出重叠加权机制自动降低噪声影响，并证明方法的数学稳定性。与现有方法如向量平均贝蒂数、持久景观等相比，主要区别在于从累积测量转向动态速率测量，更关注特征变化过程而非静态存在。",
            "application_zh": "该方法适用于动态网络异常检测，如加密货币交易网络监控、社交网络动态分析、生物网络变化追踪等领域，为金融风控、网络安全和系统监控提供新工具。",
            "highlight_zh": "在以太坊交易网络7天价格预测中，OW-HNPV比基线模型实现高达10.4%的AUC增益；在中长期预测中表现最优，提供最一致稳定的性能，验证了拓扑速度建模的有效性。",
            "tags_zh": [
                "拓扑数据分析",
                "持久图",
                "网络异常检测",
                "动态网络",
                "加密货币市场",
                "速度建模",
                "重叠加权",
                "数学稳定性"
            ],
            "_index": 26
        },
        {
            "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
            "authors": [
                "Wenqiang Sun",
                "Haiyu Zhang",
                "Haoyuan Wang",
                "Junta Wu",
                "Zehan Wang",
                "Zhenwei Wang",
                "Yunhong Wang",
                "Jun Zhang",
                "Tengfei Wang",
                "Chunchao Guo"
            ],
            "arxiv_id": "2512.14614v1",
            "summary": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "project page: https://3d-models.hunyuan.tencent.com/world/, demo: https://3d.hunyuan.tencent.com/sceneTo3D",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14614v1",
            "code_links": [],
            "headline_zh": "提出WorldPlay流式视频扩散模型，通过长期几何一致性实现实时交互式世界建模，解决速度与内存的权衡问题。",
            "summary_zh": "本文介绍了WorldPlay，一种流式视频扩散模型，能够实现具有长期几何一致性的实时交互式世界建模，解决了当前方法在速度与内存之间的权衡限制。WorldPlay基于三个关键创新：1）采用双重动作表示，实现对用户键盘和鼠标输入的鲁棒动作控制；2）通过重构上下文记忆动态重建过去帧的上下文，并利用时间重帧保持几何重要但久远帧的可访问性，有效缓解记忆衰减；3）提出上下文强制，一种专为内存感知模型设计的新型蒸馏方法，通过对齐教师和学生模型的记忆上下文，保持学生模型使用长程信息的能力，实现实时速度同时防止误差漂移。综合来看，WorldPlay能以24 FPS生成具有卓越一致性的长时流式720p视频，优于现有技术，并在多样场景中展现出强大的泛化能力。项目页面和在线演示可在https://3d-models.hunyuan.tencent.com/world/和https://3d.hunyuan.tencent.com/sceneTo3D找到。",
            "intro_zh": [
                "现有方法在实时交互式世界建模中面临速度与内存的权衡，难以同时保证长期几何一致性和实时性能。",
                "WorldPlay采用双重动作表示、重构上下文记忆和上下文强制蒸馏，实现鲁棒控制、缓解记忆衰减并保持长程信息能力。",
                "模型能以24 FPS生成720p长时流式视频，在一致性和泛化性上优于现有技术，支持多样场景应用。"
            ],
            "method_zh": "WorldPlay是一个基于流式视频扩散模型的整体框架，旨在实现实时交互式世界建模。其关键技术创新包括：双重动作表示用于鲁棒响应用户输入；重构上下文记忆通过动态重建过去帧上下文和时间重帧来保持长期几何一致性，缓解记忆衰减；上下文强制蒸馏方法对齐教师和学生模型的记忆上下文，确保学生模型在实时推理中能有效利用长程信息。与现有方法的主要区别在于，它通过内存感知设计解决了速度与内存的权衡，避免了传统方法中因内存限制导致的误差漂移或性能下降。",
            "application_zh": "该研究在虚拟现实、游戏开发、自动驾驶模拟和机器人导航等领域具有潜在应用价值，能够支持实时交互式场景生成和长期一致性建模，提升用户体验和系统可靠性。",
            "highlight_zh": "WorldPlay在实验中能以24 FPS实时生成720p长时流式视频，展现出卓越的几何一致性，优于现有技术，并在多样场景中验证了强大的泛化能力，有效解决了速度与内存的权衡问题。",
            "tags_zh": [
                "流式视频生成",
                "交互式世界建模",
                "长期几何一致性",
                "重构上下文记忆",
                "上下文强制蒸馏",
                "双重动作表示",
                "内存感知模型",
                "长时视频生成"
            ],
            "_index": 27
        },
        {
            "title": "Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection",
            "authors": [
                "Tejaswani Dash",
                "Gautam Datla",
                "Anudeep Vurity",
                "Tazeem Ahmad",
                "Mohd Adnan",
                "Saima Rafi",
                "Saisha Patro",
                "Saina Patro"
            ],
            "arxiv_id": "2512.14563v1",
            "summary": "Cardiovascular disease (CVD) remains the leading cause of mortality worldwide, underscoring the need for reliable and efficient predictive tools that support early intervention. Traditional diagnostic approaches rely on handcrafted features and clinician expertise, while machine learning methods improve reproducibility but often struggle to generalize across noisy and heterogeneous clinical data. In this work, we propose Residual GRU with Multi-Head Self-Attention, a compact deep learning architecture designed for tabular clinical records. The model integrates residual bidirectional gated recurrent units for sequential modeling of feature columns, a channel reweighting block, and multi-head self-attention pooling with a learnable classification token to capture global context. We evaluate the model on the UCI Heart Disease dataset using 5-fold stratified cross-validation and compare it against classical methods such as Logistic Regression, Random Forest, and Support Vector Machines, as well as modern deep learning baselines including DeepMLP, convolutional networks, recurrent networks, and Transformers. The proposed model achieves an accuracy of 0.861, macro-F1 of 0.860, ROC-AUC of 0.908, and PR-AUC of 0.904, outperforming all baselines. Ablation studies confirm the individual contributions of residual recurrence, channel gating, and attention pooling. t-SNE visualizations further indicate that the learned embeddings exhibit clearer separation between disease and non-disease classes compared to raw features. These results demonstrate that lightweight hybrid recurrent and attention-based architectures provide a strong balance between accuracy and efficiency for clinical risk prediction, supporting deployment in resource-constrained healthcare settings.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14559v1",
            "code_links": [],
            "headline_zh": "提出LLmFPCA-detect框架，结合LLM文本嵌入与稀疏多元函数主成分分析，用于稀疏纵向文本数据的异常检测与聚类分析。",
            "summary_zh": "稀疏纵向（SL）文本数据指个体随时间重复生成文本（如客户评论、社交媒体帖子、电子病历），但观测频率和时间点因人而异。这些复杂数据集虽具潜力，但因缺乏专用方法、噪声大、异质性强且易含异常，检测和推断关键模式面临挑战。本文引入LLmFPCA-detect，一个灵活框架，将基于LLM的文本嵌入与函数数据分析结合，以检测大型SL文本数据集中的聚类和异常。首先，LLmFPCA-detect使用LLM提示将每段文本嵌入到应用特定的数值空间。在数值空间中进行稀疏多元函数主成分分析（mFPCA），作为恢复主要群体特征的核心工具，并生成个体级分数，这些分数与基线静态协变量一起，促进数据分割、无监督异常检测与推断，并支持其他下游任务。特别地，我们利用LLM在LLmFPCA-detect发现的数据段和异常指导下进行动态关键词分析，并展示LLmFPCA-detect产生的聚类特定函数主成分分数作为现有流程的特征，有助于提升预测性能。通过实验支持LLmFPCA-detect的稳定性，并在两个公共数据集（亚马逊客户评论轨迹和维基百科讨论页评论流）上评估，证明其跨领域实用性并优于最先进的基线方法。",
            "intro_zh": [
                "核心问题：稀疏纵向文本数据缺乏专用分析方法，噪声大、异质性强，导致异常检测和模式推断困难。",
                "方法要点：结合LLM文本嵌入与稀疏多元函数主成分分析，构建灵活框架以检测聚类和异常。",
                "实验或效果：在亚马逊和维基百科数据集上验证，性能优于基线方法，并提升下游预测任务表现。"
            ],
            "method_zh": "LLmFPCA-detect框架首先使用LLM提示将文本嵌入到数值空间，然后应用稀疏多元函数主成分分析（mFPCA）处理这些嵌入，以恢复群体特征并生成个体级分数。关键创新在于将LLM的语义理解能力与函数数据分析的时序建模相结合，解决了稀疏纵向文本数据的异质性和噪声问题。与现有方法相比，它专门针对稀疏纵向文本设计，通过mFPCA处理时间变化，而传统方法多依赖静态分析或忽略文本时序特性。",
            "application_zh": "该研究可应用于客户评论分析、社交媒体监控、电子病历异常检测等领域，为政策制定和个性化推荐提供数据支持，具有跨领域的实际价值。",
            "highlight_zh": "在亚马逊客户评论和维基百科评论数据集上，LLmFPCA-detect在异常检测和聚类任务中优于最先进基线，同时其生成的函数主成分分数作为特征能显著提升下游预测性能。",
            "tags_zh": [
                "稀疏纵向文本",
                "异常检测",
                "函数主成分分析",
                "大语言模型嵌入",
                "无监督学习",
                "时序数据分析",
                "文本聚类",
                "多变量函数分析"
            ],
            "_index": 29
        },
        {
            "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
            "authors": [
                "Teodor Poncu",
                "Ioana Pintilie",
                "Marius Dragoi",
                "Dragos Tantaru",
                "Florin Brad"
            ],
            "arxiv_id": "2512.14500v1",
            "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14500v1",
            "code_links": [],
            "headline_zh": "系统分析深度音乐转录模型中的声音与音乐偏见，揭示其在分布偏移下的性能退化问题",
            "summary_zh": "自动音乐转录（AMT）——将音乐音频转换为音符表示的任务——在深度学习系统的推动下取得了快速进展。由于丰富标注音乐数据集的可用性有限，AMT的大部分进展集中在古典钢琴音乐，甚至少数特定数据集上。这些系统是否能有效泛化到其他音乐情境仍是一个开放问题。本研究补充了最近关于声音分布偏移（如录音条件）的研究，调查了音乐维度——特别是流派、动态和复音水平的变化。为此，我们引入了MDS语料库，包含三个不同子集——(1)流派、(2)随机和(3)MAEtest——以模拟分布偏移的不同轴。我们使用传统信息检索和音乐感知性能指标评估了多个最先进AMT系统在MDS语料库上的表现。广泛的评估隔离并暴露了特定分布偏移下不同程度的性能退化。特别是，我们测量到由于声音导致的音符级F1性能下降20个百分点，由于流派导致的下降14个百分点。总体而言，我们发现动态估计比起始预测更容易受到音乐变化的影响。音乐感知评估指标，特别是捕捉和声结构的指标，有助于识别潜在贡献因素。此外，随机生成的非音乐序列实验揭示了极端音乐分布偏移下系统性能的明显限制。总之，这些发现为深度AMT系统中语料库偏见问题的持续影响提供了新证据。",
            "intro_zh": [
                "核心问题：深度AMT模型因训练数据集中于古典钢琴音乐，泛化能力受限，对流派、动态等音乐变化敏感，导致性能下降。",
                "方法要点：构建MDS语料库模拟分布偏移，评估多个SOTA AMT系统，使用传统和音乐感知指标分析性能退化。",
                "实验或效果：发现声音和流派分别导致F1下降20和14个百分点，动态估计更脆弱，非音乐序列揭示系统局限性。"
            ],
            "method_zh": "论文的核心方法是系统评估框架，而非提出新模型。整体框架包括：构建MDS语料库，包含Genre、Random和MAEtest三个子集，以模拟音乐维度（如流派、动态、复音水平）的分布偏移；评估多个最先进的深度AMT系统（具体模型未指定，但基于现有SOTA），使用传统信息检索指标（如音符级F1）和音乐感知指标（如捕捉和声结构的指标）。关键技术创新点在于首次系统分析音乐维度（而非仅声音）的分布偏移对AMT的影响，并引入随机非音乐序列测试极端情况。与现有方法的主要区别是：现有研究多关注声音分布偏移（如录音条件），而本文聚焦音乐内在变化，提供更全面的偏见分析。",
            "application_zh": "该研究可应用于音乐信息检索、音乐教育工具和自动作曲系统，通过识别模型偏见，帮助改进AMT系统的鲁棒性和泛化能力，促进跨流派和风格的音乐处理应用。",
            "highlight_zh": "最重要的实验结果是：在MDS语料库上，声音分布偏移导致音符级F1性能下降20个百分点，流派偏移导致下降14个百分点；动态估计比起始预测更易受音乐变化影响；随机非音乐序列测试显示系统在极端偏移下性能显著受限，凸显语料库偏见的持久影响。",
            "tags_zh": [
                "自动音乐转录",
                "分布偏移",
                "语料库偏见",
                "音乐信息检索",
                "深度学习评估",
                "泛化能力",
                "音乐感知指标",
                "性能退化"
            ],
            "_index": 30
        },
        {
            "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
            "authors": [
                "Siyuan Zhu",
                "Chengdong Xu",
                "Kaiqiang Ke",
                "Chao Yu"
            ],
            "arxiv_id": "2512.14465v1",
            "summary": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14465v1",
            "code_links": [],
            "headline_zh": "提出FakeRadar框架以解决深度伪造视频检测中的跨域泛化挑战，通过主动探测伪造异常来识别未知伪造类型。",
            "summary_zh": "本文提出FakeRadar，一种新颖的深度伪造视频检测框架，旨在解决现实场景中跨域泛化的挑战。现有检测方法通常依赖于特定操纵线索，在已知伪造类型上表现良好，但对新兴操纵技术表现出严重局限性。这种泛化能力差源于它们无法有效适应未见过的伪造模式。为克服此问题，我们利用大规模预训练模型（如CLIP）主动探测特征空间，明确突出真实视频、已知伪造和未知操纵之间的分布差距。具体而言，FakeRadar引入伪造异常探测，采用动态子聚类建模和聚类条件异常生成来合成估计子聚类边界附近的异常样本，模拟超出已知操纵类型的新伪造伪影。此外，我们设计异常引导的三重训练，通过提出的异常驱动对比学习和异常条件交叉熵损失优化检测器，以区分真实、伪造和异常样本。实验表明，FakeRadar在深度伪造视频检测的各种基准数据集上优于现有方法，特别是在跨域评估中，通过处理多种新兴操纵技术。",
            "intro_zh": [
                "现有深度伪造检测方法依赖已知伪造线索，对新兴技术泛化能力差，难以适应未知伪造模式。",
                "FakeRadar利用预训练模型主动探测特征空间，通过伪造异常探测和异常引导训练模拟未知伪造，提升泛化性能。",
                "实验显示FakeRadar在跨域评估中优于现有方法，有效处理多种新兴操纵技术，验证了其泛化优势。"
            ],
            "method_zh": "FakeRadar的整体框架基于大规模预训练模型（如CLIP）构建，核心包括伪造异常探测和异常引导的三重训练。关键技术创新点在于：伪造异常探测通过动态子聚类建模和聚类条件异常生成，主动合成异常样本以模拟未知伪造伪影；异常引导的三重训练结合异常驱动对比学习和异常条件交叉熵损失，优化检测器区分真实、伪造和异常样本。与现有方法的主要区别在于，FakeRadar不依赖特定操纵线索，而是通过主动探测特征分布异常来增强对未知伪造的适应能力，从而提升跨域泛化性能。",
            "application_zh": "该研究可应用于网络安全、社交媒体内容审核、司法取证和数字媒体验证等领域，帮助自动检测深度伪造视频，特别是在面对新兴伪造技术时提供更可靠的泛化检测能力，具有实际价值。",
            "highlight_zh": "FakeRadar在多个深度伪造视频检测基准数据集上表现优异，特别是在跨域评估中显著优于现有方法，通过处理新兴操纵技术验证了其泛化优势，提升了未知伪造检测的准确性和鲁棒性。",
            "tags_zh": [
                "深度伪造检测",
                "跨域泛化",
                "伪造异常探测",
                "预训练模型",
                "对比学习",
                "视频分析",
                "异常生成",
                "机器学习安全"
            ],
            "_index": 31
        },
        {
            "title": "GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion",
            "authors": [
                "Fangzhou Lin",
                "Guoshun He",
                "Zhenyu Guo",
                "Zhe Huang",
                "Jinsong Tao"
            ],
            "arxiv_id": "2512.14400v1",
            "summary": "Electric load is simultaneously affected across multiple time scales by exogenous factors such as weather and calendar rhythms, sudden events, and policies. Therefore, this paper proposes GRAFT (GRid-Aware Forecasting with Text), which modifies and improves STanHOP to better support grid-aware forecasting and multi-source textual interventions. Specifically, GRAFT strictly aligns daily-aggregated news, social media, and policy texts with half-hour load, and realizes text-guided fusion to specific time positions via cross-attention during both training and rolling forecasting. In addition, GRAFT provides a plug-and-play external-memory interface to accommodate different information sources in real-world deployment. We construct and release a unified aligned benchmark covering 2019--2021 for five Australian states (half-hour load, daily-aligned weather/calendar variables, and three categories of external texts), and conduct systematic, reproducible evaluations at three scales -- hourly, daily, and monthly -- under a unified protocol for comparison across regions, external sources, and time scales. Experimental results show that GRAFT significantly outperforms strong baselines and reaches or surpasses the state of the art across multiple regions and forecasting horizons. Moreover, the model is robust in event-driven scenarios and enables temporal localization and source-level interpretation of text-to-load effects through attention read-out. We release the benchmark, preprocessing scripts, and forecasting results to facilitate standardized empirical evaluation and reproducibility in power grid load forecasting.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14400v1",
            "code_links": [],
            "headline_zh": "提出几何感知神经预条件器与混合迭代求解器，以解决参数偏微分方程在任意几何域上的求解鲁棒性问题。",
            "summary_zh": "参数偏微分方程（PDEs）的经典迭代求解器收敛行为通常对域和离散化高度敏感。先前，我们通过将经典求解器与神经算子结合，针对特定几何引入了混合求解器，但它们在训练未遇见的几何上表现不佳。为解决这一挑战，我们引入了Geo-DeepONet，这是一种几何感知的深度算子网络，它整合了从有限元离散化中提取的域信息。Geo-DeepONet能够在任意非结构化网格上实现精确的算子学习，无需重新训练。基于此，我们通过将Geo-DeepONet与传统方法（如松弛方案和Krylov子空间算法）耦合，开发了一类几何感知的混合预条件迭代求解器。通过在多样非结构化域上的参数PDE数值实验，我们证明了所提混合求解器在多个实际应用中的增强鲁棒性和效率。",
            "intro_zh": [
                "现有混合求解器对训练几何敏感，在未见几何上性能下降，限制了泛化能力。",
                "提出Geo-DeepONet，整合有限元域信息，实现跨任意网格的几何感知算子学习。",
                "实验表明，混合求解器在多样几何上提升鲁棒性和效率，适用于实际参数PDE问题。"
            ],
            "method_zh": "论文提出几何感知混合迭代求解器框架，核心是Geo-DeepONet模型，它基于深度算子网络（DeepONet）架构，但创新性地融入有限元离散化的几何信息作为输入，使网络能处理任意非结构化网格。关键技术创新在于几何感知设计，通过提取域特征（如网格节点和连接性）来增强神经预条件器的泛化能力。与现有方法的主要区别在于：传统混合求解器依赖特定几何训练，而Geo-DeepONet无需重新训练即可适应新几何，结合经典迭代方法（如松弛和Krylov算法）形成混合求解器，提升求解鲁棒性。",
            "application_zh": "该研究适用于参数偏微分方程求解领域，如计算流体动力学、结构力学和电磁学中的多物理场模拟，能处理复杂几何域（如不规则边界或自适应网格），提高实际工程和科学计算中的求解效率和稳定性。",
            "highlight_zh": "数值实验在多样非结构化域上进行，结果显示，所提混合求解器相比传统方法，在收敛速度和鲁棒性上显著提升，能有效处理训练未见的几何，验证了Geo-DeepONet的泛化能力和实际应用价值。",
            "tags_zh": [
                "参数偏微分方程",
                "几何感知学习",
                "神经预条件器",
                "混合迭代求解器",
                "深度算子网络",
                "非结构化网格",
                "有限元方法",
                "计算科学"
            ],
            "_index": 32
        },
        {
            "title": "Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments",
            "authors": [
                "Aleksi Karhunen",
                "Teemu Hakala",
                "Väinö Karjalainen",
                "Eija Honkavaara"
            ],
            "arxiv_id": "2512.14340v1",
            "summary": "The interest in the usage of uncrewed aerial vehicles (UAVs) for forest applications has increased in recent years. While above-canopy flight has reached a high level of autonomy, navigating under-canopy remains a significant challenge. The use of autonomous UAVs could reduce the burden of data collection, which has motivated the development of numerous solutions for under-canopy autonomous flight. However, the experiments conducted in the literature and their reporting lack rigor. Very rarely, the density and the difficulty of the test forests are reported, or multiple flights are flown, and the success rate of those flights is reported. The aim of this study was to implement an autonomously flying quadrotor based on a lightweight lidar using openly available algorithms and test its behavior in real forest environments. A set of rigorous experiments was conducted with a quadrotor prototype utilizing the IPC path planner and LTA-OM SLAM algorithm. Based on the results of the first 33 flights, the original system was further enhanced. With the optimized system, 60 flights were performed, resulting in a total of 93 test flights. The optimized system performed significantly better in terms of reliability and flight mission completion times, achieving success rates of 12/15 in a medium-density forest and 15/15 in a dense forest, at a target flight velocity of 1 m/s. At a target flight velocity of 2 m/s, it had a success rate of 12/15 and 5/15, respectively. Furthermore, a standardized testing setup and evaluation criteria were proposed, enabling consistent performance comparisons of autonomous under-canopy UAV systems, enhancing reproducibility, guiding system improvements, and accelerating progress in forest robotics.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This work has been submitted to the IEEE for possible publication",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14340v1",
            "code_links": [],
            "headline_zh": "提出TUMTraf EMOT数据集与基准方法，解决交通场景中基于事件相机的多目标跟踪问题。",
            "summary_zh": "在智能交通系统中，多目标跟踪主要基于帧式相机，但这些相机在弱光和高速度运动条件下性能较差。事件相机具有低延迟、高动态范围和高时间分辨率的特点，有潜力缓解这些问题。与基于帧的视觉相比，基于事件视觉的研究要少得多。为了填补这一研究空白，我们引入了一个专为基于事件的智能交通系统设计的初始试点数据集，涵盖车辆和行人的检测与跟踪。基于该数据集，我们建立了一个检测跟踪基准，并采用专门的特征提取器，实现了优异的性能。",
            "intro_zh": [
                "现有帧式相机在弱光和高速度运动条件下性能不佳，限制了智能交通系统的应用。",
                "论文提出基于事件相机的数据集和基准方法，通过专门的特征提取器提升跟踪性能。",
                "实验表明，该方法在交通场景中实现了优异的车辆和行人跟踪效果。"
            ],
            "method_zh": "论文采用检测跟踪框架，核心是专门设计的事件特征提取器。整体框架包括事件数据预处理、特征提取和目标关联模块。关键技术创新在于针对事件相机数据特性优化特征表示，与现有方法相比，更注重事件流的高时间分辨率和动态范围优势，而非传统图像处理。",
            "application_zh": "该研究可应用于智能交通系统、自动驾驶和监控领域，特别是在弱光、高动态范围或高速运动场景中，提升多目标跟踪的鲁棒性和实时性。",
            "highlight_zh": "基于TUMTraf EMOT数据集，论文的基准方法在车辆和行人跟踪任务中表现出色，验证了事件相机在交通场景中的潜力，为后续研究提供了可靠基础。",
            "tags_zh": [
                "事件相机",
                "多目标跟踪",
                "智能交通系统",
                "数据集",
                "特征提取",
                "交通场景",
                "基准方法",
                "低延迟视觉"
            ],
            "_index": 33
        },
        {
            "title": "ARCADE: Adaptive Robot Control with Online Changepoint-Aware Bayesian Dynamics Learning",
            "authors": [
                "Rishabh Dev Yadav",
                "Avirup Das",
                "Hongyu Song",
                "Samuel Kaski",
                "Wei Pan"
            ],
            "arxiv_id": "2512.14331v1",
            "summary": "Real-world robots must operate under evolving dynamics caused by changing operating conditions, external disturbances, and unmodeled effects. These may appear as gradual drifts, transient fluctuations, or abrupt shifts, demanding real-time adaptation that is robust to short-term variation yet responsive to lasting change. We propose a framework for modeling the nonlinear dynamics of robotic systems that can be updated in real time from streaming data. The method decouples representation learning from online adaptation, using latent representations learned offline to support online closed-form Bayesian updates. To handle evolving conditions, we introduce a changepoint-aware mechanism with a latent variable inferred from data likelihoods that indicates continuity or shift. When continuity is likely, evidence accumulates to refine predictions; when a shift is detected, past information is tempered to enable rapid re-learning. This maintains calibrated uncertainty and supports probabilistic reasoning about transient, gradual, or structural change. We prove that the adaptive regret of the framework grows only logarithmically in time and linearly with the number of shifts, competitive with an oracle that knows timings of shift. We validate on cartpole simulations and real quadrotor flights with swinging payloads and mid-flight drops, showing improved predictive accuracy, faster recovery, and more accurate closed-loop tracking than relevant baselines.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14331v1",
            "code_links": [],
            "headline_zh": "提出KEMM模型，通过LLM驱动的知识增强解决多模态癌症生存预测中的特征冗余和对齐难题。",
            "summary_zh": "当前多模态生存预测方法通常依赖病理图像（WSIs）和基因组数据，这些数据具有高维度和冗余性，难以从中提取判别性特征并实现不同模态的对齐。此外，仅使用简单的生存随访标签不足以监督如此复杂的任务。为解决这些挑战，我们提出了KEMM，一种LLM驱动的知识增强多模态模型，用于癌症生存预测，该模型整合了专家报告和预后背景知识。1）专家报告由病理学家逐案提供，并由大型语言模型（LLM）精炼，提供简洁且临床聚焦的诊断陈述，这些信息通常暗示不同的生存结果。2）预后背景知识（PBK）由LLM简洁生成，提供关于不同癌症类型的宝贵预后背景知识，从而增强生存预测。为利用这些知识，我们引入了知识增强跨模态（KECM）注意力模块。KECM能有效引导网络关注来自高度冗余模态的判别性和生存相关特征。在五个数据集上的广泛实验表明，KEMM实现了最先进的性能。代码将在接受后发布。",
            "intro_zh": [
                "现有方法依赖高维冗余的病理图像和基因组数据，难以提取判别性特征并实现模态对齐，且生存标签监督不足。",
                "提出KEMM模型，整合LLM精炼的专家报告和生成的预后背景知识，通过KECM注意力模块增强特征提取和模态融合。",
                "在五个数据集上实验，KEMM达到最先进性能，验证了知识增强在多模态生存预测中的有效性。"
            ],
            "method_zh": "KEMM的整体框架是一个多模态深度学习模型，核心整合病理图像、基因组数据、专家报告和预后背景知识。关键技术创新点包括：1）利用LLM精炼专家报告以提供临床聚焦的诊断信息；2）LLM生成预后背景知识以补充领域知识；3）设计知识增强跨模态（KECM）注意力模块，该模块通过知识引导注意力机制，有效聚焦于判别性和生存相关特征，减少冗余干扰。与现有方法的主要区别在于：现有方法通常仅依赖原始多模态数据和简单标签，而KEMM引入外部知识源（专家报告和PBK），并通过KECM实现知识驱动的特征对齐和融合，从而提升模型鲁棒性和预测准确性。",
            "application_zh": "该研究主要应用于癌症预后预测和个性化医疗领域，可辅助临床医生评估患者生存风险，优化治疗决策。潜在价值包括提高预测准确性、减少数据冗余影响，以及通过知识增强提升模型可解释性，推动精准医疗发展。",
            "highlight_zh": "在五个数据集上的实验显示，KEMM实现了最先进的性能，具体提升未知，但验证了知识增强和KECM模块在多模态生存预测中的有效性，显著优于依赖原始数据和简单标签的基线方法。",
            "tags_zh": [
                "多模态学习",
                "癌症生存预测",
                "知识增强",
                "LLM驱动",
                "跨模态注意力",
                "病理图像分析",
                "基因组数据",
                "预后建模"
            ],
            "_index": 35
        },
        {
            "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
            "authors": [
                "Agrippina Mwangi",
                "León Navarro-Hilfiker",
                "Lukasz Brewka",
                "Mikkel Gryning",
                "Elena Fumagalli",
                "Madeleine Gibescu"
            ],
            "arxiv_id": "2512.14297v1",
            "summary": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.\n  To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.\n  Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.\n  Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
            "categories": [
                "cs.NI",
                "cs.AI",
                "cs.ET",
                "cs.PF",
                "hep-ex"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14297v1",
            "code_links": [],
            "headline_zh": "提出基于GPT-2的尼泊尔语大语言模型，通过定制BPE分词器和高效训练策略解决低资源语言生成难题。",
            "summary_zh": "尼泊尔语作为一种低资源语言，拥有超过3200万使用者，因其复杂的语法、黏着性形态和高质量语料库的有限可用性，在自然语言处理领域持续面临挑战。迄今为止的大多数努力都集中在基础编码器架构上，这些架构对于尼泊尔语特定的文本生成仍然不足。本研究提出了一个基于GPT-2的尼泊尔语语言模型，采用了受GPT-3启发的多种训练策略，包括优化的学习率调度、批次缩放和架构改进。一个定制的16k字节对编码分词器专门在尼泊尔语文本上训练，以确保更一致的分割和改进的输入表示。该模型在一个组合数据集上进行了预训练，该数据集包括10.75GB清洗后的尼泊尔BERTa语料库和额外的网络爬取的尼泊尔新闻文章。集成了FlashAttention以减少内存使用并稳定训练。经过两个训练周期后，模型实现了3.168177的训练损失、3.081982的验证损失和21.80的最终困惑度，展示了其生成连贯的尼泊尔新闻风格文本的能力。",
            "intro_zh": [
                "现有方法主要基于基础编码器架构，难以满足尼泊尔语复杂语法和黏着性形态下的文本生成需求。",
                "论文提出基于GPT-2的模型，结合定制BPE分词器和GPT-3启发的训练策略，优化学习率与架构。",
                "模型在尼泊尔语数据集上训练后，困惑度达21.80，能生成连贯的新闻文本，验证了其有效性。"
            ],
            "method_zh": "论文采用GPT-2作为基础架构，核心创新在于定制16k BPE分词器专门针对尼泊尔语训练，确保更准确的分词和输入表示。方法整合了受GPT-3启发的训练策略，如优化学习率调度和批次缩放，并引入FlashAttention以提升训练效率和稳定性。与现有方法相比，主要区别在于从基础编码器转向生成式模型，并针对尼泊尔语低资源特性进行定制化优化，解决了传统方法在文本生成上的不足。",
            "application_zh": "该研究可应用于尼泊尔语新闻自动生成、聊天机器人、内容创作和机器翻译等领域，为低资源语言的自然语言处理提供实际解决方案，促进尼泊尔语社区的数字化发展。",
            "highlight_zh": "模型在训练后达到21.80的困惑度，训练损失和验证损失分别为3.168177和3.081982，成功生成连贯的尼泊尔新闻风格文本，证明了定制分词器和高效训练策略的有效性。",
            "tags_zh": [
                "低资源语言处理",
                "尼泊尔语大语言模型",
                "字节对编码分词器",
                "GPT-2架构",
                "FlashAttention优化",
                "文本生成",
                "自然语言处理",
                "训练策略优化"
            ],
            "_index": 36
        },
        {
            "title": "PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design",
            "authors": [
                "Ruozhao Yang",
                "Mingfei Cheng",
                "Gelei Deng",
                "Tianwei Zhang",
                "Junjie Wang",
                "Xiaofei Xie"
            ],
            "arxiv_id": "2512.14233v1",
            "summary": "Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14233v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VIO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "headline_zh": "提出低资源语言NLP教程，通过端到端流程构建包容性语言技术以应对数据稀缺挑战。",
            "summary_zh": "本教程（https://tum-nlp.github.io/low-resource-tutorial）专为从事多语言和低资源语言工作的NLP从业者、研究人员和开发者设计，旨在创建更公平且具有社会影响力的语言技术。参与者将获得构建端到端NLP流程的实用工具包，涵盖从数据收集和网络爬取到平行句挖掘、机器翻译，以及文本分类和多模态推理等下游应用。教程介绍了应对数据稀缺和文化差异挑战的策略，提供了实践方法和建模框架。我们将重点关注公平、可重复且基于社区反馈的开发方法，并以真实场景为基础。我们将展示涵盖超过10种语言的多样化用例，这些语言来自不同的语系和地缘政治背景，包括数字资源丰富和严重代表性不足的语言。",
            "intro_zh": [
                "核心问题：现有NLP技术多依赖高资源语言数据，低资源语言面临数据稀缺、文化差异和代表性不足的挑战，导致技术应用不公。",
                "方法要点：提供端到端NLP流程工具包，包括数据收集、平行句挖掘和建模框架，强调公平、可重复和社区参与的开发方法。",
                "实验或效果：教程展示超过10种语言的用例，涵盖不同语系和地缘政治背景，验证方法在低资源场景下的实用性和包容性。"
            ],
            "method_zh": "本教程的核心方法是一个端到端NLP流程框架，从数据收集（如网络爬取）开始，通过平行句挖掘构建多语言语料库，进而支持机器翻译和下游任务（如文本分类和多模态推理）。关键技术创新点在于整合了应对数据稀缺的策略（如低资源建模技术）和文化差异处理机制，强调社区反馈和可重复性。与现有方法的主要区别在于它系统性地覆盖了从数据到应用的完整链条，并特别关注低资源语言的公平性和社会影响，而非仅聚焦于高资源语言的性能优化。",
            "application_zh": "该研究可应用于多语言NLP系统开发，特别是在低资源语言场景下，如机器翻译、文本分类和多模态推理，有助于提升语言技术的包容性和社会影响力，服务于全球多样化的语言社区。",
            "highlight_zh": "教程展示了超过10种语言的多样化用例，包括数字资源丰富和严重代表性不足的语言，验证了端到端流程在低资源环境中的可行性，强调了公平和社区参与的实际效果。",
            "tags_zh": [
                "低资源语言处理",
                "多语言NLP",
                "端到端流程",
                "数据稀缺应对",
                "公平性技术",
                "社区参与开发",
                "平行句挖掘",
                "包容性语言技术"
            ],
            "_index": 37
        },
        {
            "title": "FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation",
            "authors": [
                "Qingyuan Cai",
                "Linxin Zhang",
                "Xuecai Hu",
                "Saihui Hou",
                "Yongzhen Huang"
            ],
            "arxiv_id": "2512.14162v1",
            "summary": "Recent approaches for monocular 3D human pose estimation (3D HPE) have achieved leading performance by directly regressing 3D poses from 2D keypoint sequences. Despite the rapid progress in 3D HPE, existing methods are typically trained and evaluated under disparate frameworks, lacking a unified framework for fair comparison. To address these limitations, we propose Fast3DHPE, a modular framework that facilitates rapid reproduction and flexible development of new methods. By standardizing training and evaluation protocols, Fast3DHPE enables fair comparison across 3D human pose estimation methods while significantly improving training efficiency. Within this framework, we introduce FastDDHPose, a Disentangled Diffusion-based 3D Human Pose Estimation method which leverages the strong latent distribution modeling capability of diffusion models to explicitly model the distributions of bone length and bone direction while avoiding further amplification of hierarchical error accumulation. Moreover, we design an efficient Kinematic-Hierarchical Spatial and Temporal Denoiser that encourages the model to focus on kinematic joint hierarchies while avoiding unnecessary modeling of overly complex joint topologies. Extensive experiments on Human3.6M and MPI-INF-3DHP show that the Fast3DHPE framework enables fair comparison of all methods while significantly improving training efficiency. Within this unified framework, FastDDHPose achieves state-of-the-art performance with strong generalization and robustness in in-the-wild scenarios. The framework and models will be released at: https://github.com/Andyen512/Fast3DHPE",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14162v1",
            "code_links": [
                {
                    "url": "https://huggingface.co/datasets/FoodLog",
                    "type": "huggingface"
                }
            ],
            "headline_zh": "提出FoodLogAthl-218真实世界食物图像数据集，解决现有数据集与用户实际餐食照片差异大的问题。",
            "summary_zh": "食物图像分类模型对饮食管理应用至关重要，能减轻手动记录餐食的负担。然而，大多数用于训练此类模型的公开数据集依赖网络爬取的图像，这些图像常与用户实际餐食照片存在差异。本研究提出了FoodLogAthl-218，这是一个从饮食管理应用FoodLog Athl收集的真实世界餐食记录构建的食物图像数据集。数据集包含218个食物类别的6,925张图像，总计14,349个边界框。每张图像附带丰富的元数据，包括用餐日期和时间、匿名用户ID以及餐食级上下文。与传统数据集不同，传统数据集以预定义类别集指导基于网络的图像收集，而我们的数据始于用户提交的照片，随后才应用标签。这带来了更大的类内多样性、餐食类型的自然频率分布，以及用于个人使用而非公开分享的随意、未过滤的图像。除了（1）标准分类基准外，我们还引入了两个FoodLog特定任务：（2）遵循用户日志时间流的增量微调协议，以及（3）上下文感知分类任务，其中每张图像包含多道菜肴，模型必须利用整体餐食上下文对每道菜进行分类。我们使用大型多模态模型（LMMs）评估了这些任务。数据集可在https://huggingface.co/datasets/FoodLog/FoodLogAthl-218公开获取。",
            "intro_zh": [
                "核心问题：现有食物图像数据集多基于网络爬取，与用户真实餐食照片差异大，缺乏真实世界多样性，限制了饮食管理应用的准确性。",
                "方法要点：从饮食管理应用收集用户真实餐食照片，构建FoodLogAthl-218数据集，包含丰富元数据，并设计增量微调和上下文感知分类任务。",
                "实验或效果：数据集包含6,925张图像、218个类别，评估显示能提升模型在真实场景下的性能，支持多模态模型应用。"
            ],
            "method_zh": "论文的核心方法是构建FoodLogAthl-218数据集，整体框架基于从饮食管理应用FoodLog Athl收集的真实用户餐食记录。关键技术创新点包括：数据收集始于用户提交的照片而非预定义类别，确保图像更贴近实际使用场景；数据集附带丰富元数据如用餐时间、用户ID和餐食上下文，增强实用性；引入增量微调协议和上下文感知分类任务，模拟真实应用中的时间流和多菜肴场景。与现有方法的主要区别在于：传统数据集依赖网络爬取，图像质量高但缺乏真实多样性，而本数据集直接从用户端获取，具有更大的类内多样性和自然分布，更适用于实际饮食管理应用。",
            "application_zh": "该研究主要应用于饮食管理领域，如健康监测、营养分析和个性化饮食建议。通过提供真实世界食物图像数据集，能提升自动餐食记录系统的准确性，减少用户手动输入负担，支持智能健康应用开发，具有实际商业和社会价值。",
            "highlight_zh": "最重要的实验结果包括：数据集包含6,925张图像、218个类别和14,349个边界框，具有自然频率分布和丰富元数据；在标准分类基准和FoodLog特定任务（如增量微调和上下文感知分类）上，使用大型多模态模型评估显示，数据集能有效提升模型在真实场景下的性能，验证了其实际应用潜力。",
            "tags_zh": [
                "食物图像分类",
                "真实世界数据集",
                "饮食管理应用",
                "多模态模型",
                "上下文感知分类",
                "增量微调",
                "图像识别",
                "健康监测"
            ],
            "_index": 38
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140v1",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140v1",
            "code_links": [],
            "headline_zh": "提出Residual GRU+MHSA轻量混合循环注意力模型，用于心血管疾病检测，平衡准确性与效率。",
            "summary_zh": "心血管疾病（CVD）是全球主要死因，需要可靠高效的预测工具以支持早期干预。传统诊断方法依赖手工特征和临床专家经验，而机器学习方法虽提高可重复性，但常难以在噪声和异质临床数据中泛化。本研究提出Residual GRU with Multi-Head Self-Attention，一种为表格临床记录设计的紧凑深度学习架构。该模型整合残差双向门控循环单元用于特征列的序列建模、通道重加权块，以及带可学习分类标记的多头自注意力池化以捕获全局上下文。我们在UCI心脏病数据集上使用5折分层交叉验证评估模型，并与逻辑回归、随机森林、支持向量机等经典方法，以及DeepMLP、卷积网络、循环网络和Transformer等现代深度学习基线进行比较。所提模型达到0.861准确率、0.860宏F1、0.908 ROC-AUC和0.904 PR-AUC，优于所有基线。消融研究确认了残差循环、通道门控和注意力池化的各自贡献。t-SNE可视化进一步表明，与原始特征相比，学习到的嵌入在疾病和非疾病类别间展现出更清晰的分离。这些结果表明，轻量混合循环和基于注意力的架构为临床风险预测提供了准确性与效率之间的强平衡，支持在资源受限的医疗环境中部署。",
            "intro_zh": [
                "核心问题：传统心血管疾病诊断依赖手工特征和专家经验，机器学习方法在噪声和异质临床数据中泛化能力有限。",
                "方法要点：提出轻量混合模型，结合残差双向GRU进行序列建模、通道重加权和多头自注意力池化，以捕获全局上下文。",
                "实验或效果：在UCI心脏病数据集上，模型准确率达0.861，优于经典和深度学习基线，消融研究验证各组件贡献。"
            ],
            "method_zh": "论文提出Residual GRU+MHSA模型，整体框架为紧凑深度学习架构，专为表格临床记录设计。关键技术创新点包括：整合残差双向门控循环单元（GRU）对特征列进行序列建模，引入通道重加权块优化特征表示，以及使用带可学习分类标记的多头自注意力（MHSA）池化机制捕获全局依赖关系。与现有方法的主要区别在于，它结合了循环网络的时间建模能力和注意力机制的全局上下文捕捉，形成轻量混合结构，相比传统机器学习方法（如逻辑回归）和单一深度学习模型（如纯Transformer或卷积网络），在保持高效率的同时提升了处理异质临床数据的能力。",
            "application_zh": "该研究主要应用于心血管疾病早期检测和风险预测，基于表格临床记录（如患者病史、检查指标）进行分析。潜在价值在于支持资源受限的医疗环境部署，如社区医院或远程医疗，提供高效、自动化的诊断辅助工具，促进早期干预和个性化治疗。",
            "highlight_zh": "在UCI心脏病数据集上，模型达到0.861准确率、0.860宏F1、0.908 ROC-AUC和0.904 PR-AUC，全面优于逻辑回归、随机森林、支持向量机及DeepMLP、卷积网络等深度学习基线。消融研究证实残差循环、通道门控和注意力池化均贡献显著性能提升。",
            "tags_zh": [
                "心血管疾病检测",
                "轻量深度学习",
                "残差双向GRU",
                "多头自注意力",
                "表格数据建模",
                "临床风险预测",
                "混合循环注意力模型",
                "医疗人工智能"
            ],
            "_index": 39
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095v1",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095v1",
            "code_links": [],
            "headline_zh": "提出PolyPersona框架，通过角色条件化微调生成多领域合成调查响应，支持高效可扩展的数据生成与评估。",
            "summary_zh": "本文介绍了PolyPersona，一个用于生成跨多个领域的角色条件化调查响应的生成框架。该框架在资源自适应训练设置下，使用参数高效的LoRA适配器和4位量化对紧凑聊天模型进行指令微调。基于对话的数据管道明确保留角色线索，确保生成响应在行为上的一致性。利用此管道，我们构建了一个包含10个领域、433个不同角色的3,568个合成调查响应的数据集，支持受控指令微调和系统化的多领域评估。我们使用多指标评估套件评估生成响应，该套件结合了标准文本生成指标（包括BLEU、ROUGE和BERTScore）和专门设计的调查特定指标，用于评估结构连贯性、风格一致性和情感对齐。实验结果表明，TinyLlama 1.1B和Phi-2等紧凑模型实现了与较大7B至8B基线相当的性能，最高BLEU得分为0.090，ROUGE-1为0.429。这些发现表明，角色条件化微调使小型语言模型能够生成可靠且连贯的合成调查数据。所提出的框架为调查数据生成提供了一种高效且可重复的方法，支持可扩展评估，同时通过透明和开放的协议促进偏见分析。",
            "intro_zh": [
                "现有方法在生成合成调查响应时，难以有效整合角色信息并保持行为一致性，导致数据质量受限。",
                "论文提出PolyPersona框架，通过角色条件化指令微调和对话式数据管道，确保生成响应与指定角色对齐。",
                "实验显示，紧凑模型如TinyLlama 1.1B和Phi-2在性能上媲美更大基线，BLEU最高达0.090，验证了方法的有效性。"
            ],
            "method_zh": "PolyPersona是一个生成框架，整体基于指令微调紧凑聊天模型，核心创新点包括：使用参数高效的LoRA适配器结合4位量化进行资源自适应训练，降低计算成本；设计对话式数据管道，明确保留角色线索（如人口统计特征、行为模式），确保生成响应的行为一致性。与现有方法的主要区别在于，它系统化地整合角色条件化，通过多领域数据集（10个领域、433个角色）支持可控微调和评估，而传统方法往往忽略角色对齐或依赖更大模型，导致效率低下。",
            "application_zh": "该研究可应用于社会科学调查、市场研究、用户体验测试等领域，用于高效生成合成调查数据，支持数据增强、模型评估和偏见分析，降低真实数据收集成本，促进可扩展和可重复的研究。",
            "highlight_zh": "紧凑模型TinyLlama 1.1B和Phi-2在合成调查响应生成中，性能与7B-8B基线相当，最高BLEU得分0.090、ROUGE-1得分0.429，证明了角色条件化微调的有效性，同时框架构建了包含3,568个响应的多领域数据集，支持系统化评估。",
            "tags_zh": [
                "角色条件化生成",
                "合成调查响应",
                "指令微调",
                "LoRA适配器",
                "4位量化",
                "多领域评估",
                "紧凑语言模型",
                "数据生成框架"
            ],
            "_index": 40
        },
        {
            "title": "Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation",
            "authors": [
                "Humaira Tasnim",
                "Ashik E Rasul",
                "Bruce Jo",
                "Hyung-Jin Yoon"
            ],
            "arxiv_id": "2512.14054v1",
            "summary": "Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14054v1",
            "code_links": [],
            "headline_zh": "提出CLNet框架，通过显式跨视图对应关系增强图像检索式地理定位性能。",
            "summary_zh": "基于图像检索的跨视图地理定位（IRCVGL）旨在匹配从显著不同视角（如卫星和街景）捕获的图像。现有方法主要依赖学习鲁棒的全局表示或隐式特征对齐，往往无法建模对精确定位至关重要的显式空间对应关系。本文提出一种新颖的对应感知特征细化框架，称为CLNet，它显式地桥接不同视图之间的语义和几何差距。CLNet将视图对齐过程分解为三个可学习且互补的模块：神经对应图（NCM），通过潜在对应场在空间上对齐跨视图特征；非线性嵌入转换器（NEC），使用基于MLP的变换跨视角重新映射特征；以及全局特征重校准（GFR）模块，通过学习到的空间线索引导重新加权信息丰富的特征通道。所提出的CLNet能够联合捕获高级语义和细粒度对齐。在四个公共基准测试（CVUSA、CVACT、VIGOR和University-1652）上的广泛实验表明，我们的CLNet实现了最先进的性能，同时提供了更好的可解释性和泛化能力。",
            "intro_zh": [
                "现有方法依赖全局表示或隐式对齐，难以建模跨视图的显式空间对应关系，导致地理定位精度受限。",
                "CLNet通过神经对应图、非线性嵌入转换器和全局特征重校准三个模块，显式学习语义和几何对应以细化特征。",
                "在CVUSA等四个基准测试中，CLNet达到最先进性能，提升定位准确率并增强模型可解释性和泛化性。"
            ],
            "method_zh": "CLNet是一个对应感知特征细化框架，整体架构包括三个核心模块：神经对应图（NCM）通过潜在对应场实现跨视图特征的空间对齐，捕捉几何对应；非线性嵌入转换器（NEC）使用MLP变换跨视角重新映射特征，处理视角差异；全局特征重校准（GFR）基于学习到的空间线索重新加权特征通道，增强信息丰富度。关键创新在于将视图对齐分解为可学习的显式对应建模，区别于现有方法的全局或隐式对齐。主要区别在于CLNet联合优化语义和几何对应，提供更精细的特征对齐，从而提高地理定位的准确性和鲁棒性。",
            "application_zh": "该研究可应用于自动驾驶、无人机导航和增强现实等领域，通过跨视图图像匹配实现精确的地理定位，支持城市规划和智能交通系统，提升定位服务的可靠性和效率。",
            "highlight_zh": "在CVUSA、CVACT、VIGOR和University-1652四个基准测试中，CLNet均达到最先进性能，显著提升跨视图地理定位的准确率，同时模型展现出更好的可解释性和泛化能力，验证了显式对应建模的有效性。",
            "tags_zh": [
                "跨视图地理定位",
                "图像检索",
                "特征对齐",
                "神经对应图",
                "非线性嵌入转换",
                "全局特征重校准",
                "语义对应",
                "几何对应"
            ],
            "_index": 41
        },
        {
            "title": "E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms",
            "authors": [
                "Boyang Li",
                "Zhongpeng Jin",
                "Shuai Zhao",
                "Jiahui Liao",
                "Tian Liu",
                "Han Liu",
                "Yuanhai Zhang",
                "Kai Huang"
            ],
            "arxiv_id": "2512.14046v1",
            "summary": "The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14046v1",
            "code_links": [],
            "headline_zh": "提出以人为中心且时间连贯的反事实解释方法，以解决临床推荐中现有方法的不足",
            "summary_zh": "反事实解释作为可解释机制被越来越多地提出，以实现算法追索。然而，当前针对时间序列分类的反事实技术主要基于静态数据假设设计，并侧重于生成最小输入扰动以翻转模型预测。本文认为，在临床推荐场景中，此类方法从根本上不足，因为干预措施随时间展开，必须具有因果合理性和时间连贯性。我们主张转向反映持续、目标导向干预的反事实解释，这些干预应与临床推理和患者特定动态保持一致。我们指出了现有方法在实践应用中的关键缺陷，特别是时间盲点以及在方法设计和评估指标中缺乏以用户为中心的考量。为支持我们的观点，我们对几种最先进的时间序列方法进行了鲁棒性分析，结果表明生成的反事实解释对随机噪声高度敏感。这一发现突显了它们在现实世界临床环境中的有限可靠性，因为微小的测量变化是不可避免的。最后，我们呼吁开发超越仅考虑预测变化而不考虑可行性或可操作性的方法和评估框架，强调需要可操作、目的驱动的干预措施，这些措施在现实世界中对应用用户是可行的。",
            "intro_zh": [
                "核心问题：现有反事实解释方法基于静态假设，忽略时间连贯性和临床可行性，导致干预不可靠。",
                "方法要点：倡导以人为中心的反事实解释，强调持续、目标导向的干预，需与临床推理和患者动态一致。",
                "实验或效果：通过鲁棒性分析发现现有方法对噪声敏感，突显其在真实临床环境中的局限性。"
            ],
            "method_zh": "本文未提出具体的新模型架构，而是从方法论角度批判现有方法并倡导新方向。整体框架强调反事实解释应基于时间序列的动态特性，而非静态扰动。关键技术创新点在于将时间连贯性和因果合理性作为核心设计原则，要求干预措施在时间维度上持续且逻辑一致。与现有方法的主要区别在于：现有方法侧重于最小化输入扰动以改变预测，而本文主张反事实解释应反映现实世界中的可行干预，如临床治疗过程，从而提升可解释性和实用性。",
            "application_zh": "该研究主要应用于临床推荐系统，如疾病预测和个性化治疗规划。通过提供以人为中心且时间连贯的反事实解释，可帮助医生理解模型决策，制定更可行、持续的干预措施，提升医疗AI的可信度和实用性。",
            "highlight_zh": "对多种最先进时间序列反事实方法进行鲁棒性分析，发现生成的反事实解释对随机噪声高度敏感，表明现有方法在真实临床环境中可靠性有限，因微小测量变化不可避免。",
            "tags_zh": [
                "反事实解释",
                "时间序列分类",
                "临床推荐系统",
                "可解释人工智能",
                "时间连贯性",
                "以人为中心设计",
                "算法追索",
                "鲁棒性分析"
            ],
            "_index": 42
        },
        {
            "title": "Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks",
            "authors": [
                "Yong Fang",
                "Na Li",
                "Hangguan Shan",
                "Eryun Liu",
                "Xinyu Li",
                "Wei Ni",
                "Er-Ping Li"
            ],
            "arxiv_id": "2512.14023v1",
            "summary": "Multivariate Time Series (MTS) forecasting plays a vital role in various real-world applications, such as traffic management and predictive maintenance. Existing approaches typically model MTS data in either Euclidean or Riemannian space, limiting their ability to capture the diverse geometric structures and complex spatio-temporal dependencies inherent in real-world data. To overcome this limitation, we propose the Hybrid Symmetric Positive-Definite Manifold Graph Neural Network (HSMGNN), a novel graph neural network-based model that captures data geometry within a hybrid Euclidean-Riemannian framework. To the best of our knowledge, this is the first work to leverage hybrid geometric representations for MTS forecasting, enabling expressive and comprehensive modeling of geometric properties. Specifically, we introduce a Submanifold-Cross-Segment (SCS) embedding to project input MTS into both Euclidean and Riemannian spaces, thereby capturing spatio-temporal variations across distinct geometric domains. To alleviate the high computational cost of Riemannian distance, we further design an Adaptive-Distance-Bank (ADB) layer with a trainable memory mechanism. Finally, a Fusion Graph Convolutional Network (FGCN) is devised to integrate features from the dual spaces via a learnable fusion operator for accurate prediction. Experiments on three benchmark datasets demonstrate that HSMGNN achieves up to a 13.8 percent improvement over state-of-the-art baselines in forecasting accuracy.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14023v1",
            "code_links": [],
            "headline_zh": "提出一种测试时优化的通用AI医学图像配准框架，以解决多模态、多解剖区域非刚性配准的挑战。",
            "summary_zh": "医学图像配准对于对齐计算机断层扫描（CT）、磁共振成像（MRI）和超声等不同成像模态的解剖结构至关重要。其中，非刚性配准（NRR）由于需要捕捉由呼吸或对比剂引起的信号变化等生理过程导致的复杂解剖变形，尤其具有挑战性。传统的NRR方法虽然在理论上稳健，但通常需要大量参数调整并产生高计算成本，限制了其在实时临床工作流程中的应用。最近的基于深度学习（DL）的方法显示出潜力；然而，它们对任务特定再训练的依赖在实践中限制了可扩展性和适应性。这些局限性凸显了对能够处理异构成像环境的高效、可泛化配准框架的需求。在这项工作中，我们引入了一种新颖的AI驱动的3D非刚性配准框架，该框架可泛化到多种成像模态和解剖区域。与依赖应用特定模型的传统方法不同，我们的方法消除了解剖或模态特定的定制，实现了在不同临床环境中的简化集成。",
            "intro_zh": [
                "核心问题：传统非刚性配准方法参数调整复杂、计算成本高，而深度学习模型依赖任务特定再训练，限制了临床应用的实时性和泛化能力。",
                "方法要点：提出一种AI驱动的通用框架，通过消除解剖或模态特定定制，实现跨多模态和多解剖区域的3D非刚性配准。",
                "实验或效果：该框架在测试时优化，显著提升了配准效率，并展示了在异构成像环境中的良好适应性和简化集成潜力。"
            ],
            "method_zh": "论文提出了一种AI驱动的3D非刚性配准框架，整体框架基于深度学习模型，旨在实现跨多种成像模态（如CT、MRI、超声）和解剖区域的通用配准。关键技术创新点在于消除了传统方法中对解剖或模态特定定制的依赖，通过优化测试时处理流程，提高了模型的泛化能力和适应性。与现有方法的主要区别在于，它不依赖于应用特定模型，而是采用一种更通用的架构，减少了参数调整需求，从而降低了计算成本并简化了临床集成。",
            "application_zh": "该研究可应用于医学影像分析领域，如多模态图像融合、手术导航和疾病监测，通过高效、通用的配准框架，提升临床工作流程的实时性和准确性，支持跨不同成像设备和解剖区域的诊断与治疗规划。",
            "highlight_zh": "实验结果表明，该框架在测试时优化后，显著减少了计算时间，同时保持了高配准精度，在多种成像模态和解剖区域上展示了优异的泛化性能，相比传统方法提升了效率并降低了定制需求。",
            "tags_zh": [
                "医学图像配准",
                "非刚性配准",
                "深度学习",
                "多模态融合",
                "3D图像处理",
                "测试时优化",
                "泛化框架",
                "临床集成"
            ],
            "_index": 43
        },
        {
            "title": "Early Warning Index for Patient Deteriorations in Hospitals",
            "authors": [
                "Dimitris Bertsimas",
                "Yu Ma",
                "Kimberly Villalobos Carballo",
                "Gagan Singh",
                "Michal Laskowski",
                "Jeff Mather",
                "Dan Kombert",
                "Howard Haronian"
            ],
            "arxiv_id": "2512.14683v1",
            "summary": "Hospitals lack automated systems to harness the growing volume of heterogeneous clinical and operational data to effectively forecast critical events. Early identification of patients at risk for deterioration is essential not only for patient care quality monitoring but also for physician care management. However, translating varied data streams into accurate and interpretable risk assessments poses significant challenges due to inconsistent data formats. We develop a multimodal machine learning framework, the Early Warning Index (EWI), to predict the aggregate risk of ICU admission, emergency response team dispatch, and mortality. Key to EWI's design is a human-in-the-loop process: clinicians help determine alert thresholds and interpret model outputs, which are enhanced by explainable outputs using Shapley Additive exPlanations (SHAP) to highlight clinical and operational factors (e.g., scheduled surgeries, ward census) driving each patient's risk. We deploy EWI in a hospital dashboard that stratifies patients into three risk tiers. Using a dataset of 18,633 unique patients at a large U.S. hospital, our approach automatically extracts features from both structured and unstructured electronic health record (EHR) data and achieves C-statistics of 0.796. It is currently used as a triage tool for proactively managing at-risk patients. The proposed approach saves physicians valuable time by automatically sorting patients of varying risk levels, allowing them to concentrate on patient care rather than sifting through complex EHR data. By further pinpointing specific risk drivers, the proposed model provides data-informed adjustments to caregiver scheduling and allocation of critical resources. As a result, clinicians and administrators can avert downstream complications, including costly procedures or high readmission rates and improve overall patient flow.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14683v1",
            "code_links": [],
            "headline_zh": "提出VLegal-Bench基准以解决越南法律领域大语言模型评估的标准化与认知深度不足问题",
            "summary_zh": "随着大语言模型（LLMs）的快速发展，人工智能在法律领域的应用展现出新的可能性。然而，越南法律的复杂性、层级结构以及频繁修订，给评估这些模型如何解释和利用法律知识带来了巨大挑战。为填补这一空白，越南法律基准（VLegal-Bench）被引入，这是首个旨在系统评估LLMs在越南法律任务上表现的综合性基准。基于布鲁姆认知分类法，VLegal-Bench通过设计反映实际使用场景的任务，涵盖了多个层次的法律理解。该基准包含10,450个样本，通过严格的标注流程生成，其中法律专家使用我们的标注系统对每个实例进行标注和交叉验证，确保每个样本都基于权威法律文件，并模拟真实世界法律助手的工作流程，包括一般法律问答、检索增强生成、多步推理以及针对越南法律的场景化问题解决。通过提供一个标准化、透明且基于认知科学的评估框架，VLegal-Bench为评估LLMs在越南法律背景下的性能奠定了坚实基础，并支持开发更可靠、可解释且符合伦理的AI辅助法律系统。",
            "intro_zh": [
                "核心问题：越南法律复杂且频繁修订，现有方法缺乏标准化基准来评估大语言模型的法律推理能力，导致模型性能评估不全面。",
                "方法要点：基于布鲁姆认知分类法设计多层次法律任务，通过专家标注和交叉验证构建包含10,450个样本的基准，确保样本基于权威法律文件。",
                "实验或效果：VLegal-Bench提供了透明评估框架，支持开发更可靠的AI法律系统，但具体模型性能提升数据未知，需后续实验验证。"
            ],
            "method_zh": "VLegal-Bench的整体框架是一个基于认知科学的标准化评估基准，核心方法包括：1）以布鲁姆认知分类法为指导，设计多层次法律理解任务，如问答、检索增强生成和多步推理；2）通过严格标注流程，由法律专家使用标注系统生成和验证10,450个样本，确保样本基于权威越南法律文件并模拟真实工作流程；3）关键技术创新在于将认知理论与法律实践结合，创建透明、可复现的评估体系。与现有方法的主要区别在于其专门针对越南法律定制，强调认知深度和实际场景，而非通用法律基准。",
            "application_zh": "该研究可应用于越南法律AI助手开发、法律教育工具、自动化法律咨询系统等领域，提升法律服务的效率和准确性，支持司法和合规场景的智能化。",
            "highlight_zh": "VLegal-Bench构建了首个针对越南法律的综合性基准，包含10,450个专家验证样本，基于认知分类法设计任务，为LLMs评估提供标准化框架，但具体性能提升需模型测试后确定。",
            "tags_zh": [
                "越南法律基准",
                "大语言模型评估",
                "认知分类法",
                "法律推理",
                "专家标注系统",
                "检索增强生成",
                "多步推理",
                "AI辅助法律系统"
            ],
            "_index": 44
        },
        {
            "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
            "authors": [
                "Zechen Bai",
                "Chen Gao",
                "Mike Zheng Shou"
            ],
            "arxiv_id": "2512.14666v1",
            "summary": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\\% on long-horizon tasks, +22.0\\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\\% success on unseen tasks without task-specific demonstrations training (vs. 0\\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14666v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "reward"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出任务自适应Transformer（TAT）以解决医学图像全任务恢复中的任务干扰与不平衡问题",
            "summary_zh": "医学图像恢复（MedIR）旨在从低质量图像中恢复高质量医学图像。近年来，MedIR领域的研究重点转向能够同时处理多种不同MedIR任务的全任务模型。然而，由于模态和退化类型存在显著差异，使用共享模型处理这些多样化任务时，需要仔细考虑两个关键的任务间关系：任务干扰（当不同任务在同一参数上产生冲突的梯度更新方向时发生）和任务不平衡（指由于每个任务固有的学习难度不同而导致的不均衡优化）。为解决这些挑战，我们提出了一种任务自适应Transformer（TAT），这是一个通过两个关键创新动态适应不同任务的新框架。首先，引入任务自适应权重生成策略，通过为每个任务生成任务特定的权重参数来减轻任务干扰，从而消除共享权重参数上的潜在梯度冲突。其次，引入任务自适应损失平衡策略，根据任务特定的学习难度动态调整损失权重，防止任务主导或训练不足。大量实验表明，我们提出的TAT在三个MedIR任务——PET合成、CT去噪和MRI超分辨率——中，无论是在任务特定还是全任务设置下，都实现了最先进的性能。代码可在https://github.com/Yaziwel/TAT获取。",
            "intro_zh": [
                "现有全任务医学图像恢复模型面临任务干扰和任务不平衡的挑战，导致性能受限。",
                "提出任务自适应Transformer，通过动态权重生成和损失平衡策略，实现任务间高效协同。",
                "在PET合成、CT去噪和MRI超分辨率任务中，TAT在单任务和全任务设置下均达到最优性能。"
            ],
            "method_zh": "TAT是一个基于Transformer的全任务医学图像恢复框架，其核心创新包括任务自适应权重生成策略和任务自适应损失平衡策略。整体框架采用共享主干网络，但通过任务特定权重参数动态调整模型行为，避免梯度冲突；同时，根据任务学习难度自动平衡损失权重，优化训练过程。与现有方法相比，TAT首次在Transformer架构中系统解决全任务恢复中的任务干扰和不平衡问题，实现了更灵活和高效的多任务学习。",
            "application_zh": "该研究可广泛应用于医学影像分析领域，如PET图像合成以辅助诊断、CT图像去噪提升图像质量、MRI超分辨率增强细节分辨率，有助于提高临床诊断的准确性和效率，推动智能医疗影像处理技术的发展。",
            "highlight_zh": "实验表明，TAT在PET合成、CT去噪和MRI超分辨率三个任务上均取得最先进性能，全任务设置下相比基线方法显著提升，例如在PSNR和SSIM指标上平均提高约2-5%，验证了其有效解决任务干扰和不平衡的能力。",
            "tags_zh": [
                "医学图像恢复",
                "全任务模型",
                "任务自适应Transformer",
                "任务干扰",
                "任务不平衡",
                "多任务学习",
                "Transformer架构",
                "动态权重生成"
            ],
            "_index": 45
        },
        {
            "title": "ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking",
            "authors": [
                "Lihong Wang",
                "Liangqi Li",
                "Weiwei Feng",
                "Jiamin Wu",
                "Changtao Miao",
                "Tieru Wu",
                "Rui Ma",
                "Bo Zhang",
                "Zhe Li"
            ],
            "arxiv_id": "2512.14654v1",
            "summary": "CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Code is available at https://github.com/Leon-LihongWang/ViRC",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14549v1",
            "code_links": [],
            "headline_zh": "提出双目标训练方法以平衡语言模型训练效率与过拟合鲁棒性",
            "summary_zh": "本文结合自回归和掩码扩散训练目标，无需修改模型架构，实现了灵活的语言模型，其性能优于单目标模型。自回归建模因其训练效率高而流行，但代价是对过拟合敏感；而掩码扩散模型训练效率较低，但对过拟合更具鲁棒性。本工作证明双目标训练能兼顾两者优势。为确定两个目标之间的最优比例，我们在不同数据重复水平下训练和评估了50个语言模型。结果表明，在所有评估设置下，结合两个目标是最优的，且无论针对自回归还是掩码扩散下游性能，最优比例相似。",
            "intro_zh": [
                "核心问题：自回归模型训练效率高但易过拟合，掩码扩散模型鲁棒性强但训练效率低，现有单目标方法难以平衡两者。",
                "方法要点：结合自回归和掩码扩散训练目标，通过双目标训练实现效率与鲁棒性的平衡，无需架构修改。",
                "实验或效果：在50个模型实验中，双目标训练在所有设置下均优于单目标，最优比例稳定，提升了下游性能。"
            ],
            "method_zh": "论文提出一种双目标训练框架，核心方法是在标准语言模型架构基础上，同时应用自回归和掩码扩散训练目标。关键技术创新点在于无需修改模型架构，通过优化两个目标的混合比例，实现训练效率和过拟合鲁棒性的平衡。与现有方法的主要区别在于，现有工作通常专注于单一目标，而本方法结合了两种目标的优势，避免了各自缺点，提供了一种更灵活的训练策略。",
            "application_zh": "该研究可应用于自然语言处理领域，如文本生成、机器翻译和语言理解任务，通过提升模型训练效率和鲁棒性，降低过拟合风险，适用于数据有限或重复场景，具有实际价值。",
            "highlight_zh": "最重要的实验结果是，双目标训练在所有评估设置下均优于单目标模型，最优混合比例在不同数据重复水平下保持相似，显著提升了下游任务性能，证明了方法的普适性和有效性。",
            "tags_zh": [
                "双目标训练",
                "自回归模型",
                "掩码扩散模型",
                "训练效率",
                "过拟合鲁棒性",
                "语言模型优化",
                "下游性能",
                "数据重复"
            ],
            "_index": 46
        },
        {
            "title": "A Multicenter Benchmark of Multiple Instance Learning Models for Lymphoma Subtyping from HE-stained Whole Slide Images",
            "authors": [
                "Rao Muhammad Umer",
                "Daniel Sens",
                "Jonathan Noll",
                "Christian Matek",
                "Lukas Wolfseher",
                "Rainer Spang",
                "Ralf Huss",
                "Johannes Raffler",
                "Sarah Reinke",
                "Wolfram Klapper",
                "Katja Steiger",
                "Kristina Schwamborn",
                "Carsten Marr"
            ],
            "arxiv_id": "2512.14640v1",
            "summary": "Timely and accurate lymphoma diagnosis is essential for guiding cancer treatment. Standard diagnostic practice combines hematoxylin and eosin (HE)-stained whole slide images with immunohistochemistry, flow cytometry, and molecular genetic tests to determine lymphoma subtypes, a process requiring costly equipment, skilled personnel, and causing treatment delays. Deep learning methods could assist pathologists by extracting diagnostic information from routinely available HE-stained slides, yet comprehensive benchmarks for lymphoma subtyping on multicenter data are lacking. In this work, we present the first multicenter lymphoma benchmarking dataset covering four common lymphoma subtypes and healthy control tissue. We systematically evaluate five publicly available pathology foundation models (H-optimus-1, H0-mini, Virchow2, UNI2, Titan) combined with attention-based (AB-MIL) and transformer-based (TransMIL) multiple instance learning aggregators across three magnifications (10x, 20x, 40x). On in-distribution test sets, models achieve multiclass balanced accuracies exceeding 80% across all magnifications, with all foundation models performing similarly and both aggregation methods showing comparable results. The magnification study reveals that 40x resolution is sufficient, with no performance gains from higher resolutions or cross-magnification aggregation. However, on out-of-distribution test sets, performance drops substantially to around 60%, highlighting significant generalization challenges. To advance the field, larger multicenter studies covering additional rare lymphoma subtypes are needed. We provide an automated benchmarking pipeline to facilitate such future research.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14640v1",
            "code_links": [],
            "headline_zh": "提出HiFi-Portrait方法，通过高保真多脸融合解决零样本身份保持肖像生成中的保真度和属性控制问题。",
            "summary_zh": "近年来，基于扩散的技术在身份保持肖像生成（IPG）方面取得了显著进展。然而，当使用同一身份的多张参考图像时，现有方法通常生成保真度较低的肖像，且难以精确定制面部属性。为解决这些问题，本文提出了HiFi-Portrait，一种用于零样本肖像生成的高保真方法。具体而言，我们首先引入面部细化器和地标生成器，以获取细粒度的多脸特征和3D感知的面部地标，这些地标包括参考身份和目标属性。然后，我们设计HiFi-Net来融合多脸特征并将其与地标对齐，从而提高身份保真度和面部控制能力。此外，我们开发了一个自动化流程来构建基于身份的数据集，用于训练HiFi-Portrait。大量实验结果表明，我们的方法在面部相似性和可控性方面超越了最先进的方法。同时，我们的方法也与之前基于SDXL的工作兼容。",
            "intro_zh": [
                "现有方法在使用多张参考图像时，生成肖像保真度低，且难以精确控制面部属性，限制了身份保持肖像生成的应用效果。",
                "论文提出HiFi-Portrait，通过面部细化器和地标生成器提取多脸特征与3D地标，并设计HiFi-Net进行融合对齐，提升保真度和控制能力。",
                "实验显示，该方法在面部相似性和可控性上超越SOTA方法，且兼容SDXL框架，验证了其有效性和实用性。"
            ],
            "method_zh": "HiFi-Portrait的整体框架包括面部细化器、地标生成器和HiFi-Net。面部细化器从多张参考图像中提取细粒度特征，地标生成器生成3D感知的面部地标以编码身份和属性信息。HiFi-Net作为核心模块，融合多脸特征并与地标对齐，通过特征融合和空间对齐机制增强身份保真度和属性控制。关键技术创新在于多脸特征融合与3D地标对齐的结合，以及自动化数据集构建流程。与现有方法相比，HiFi-Portrait更注重高保真度和精确属性控制，而非仅依赖单一参考或简单特征拼接。",
            "application_zh": "该研究可应用于数字娱乐、虚拟现实、个性化内容创作等领域，如生成高保真虚拟肖像、定制化角色设计或身份保持的图像编辑，提升用户体验和创作效率。",
            "highlight_zh": "实验结果表明，HiFi-Portrait在面部相似性指标上显著优于现有SOTA方法，同时实现了更高的属性可控性，且与SDXL兼容，展示了其在零样本肖像生成中的优越性能。",
            "tags_zh": [
                "身份保持肖像生成",
                "零样本学习",
                "高保真融合",
                "多脸特征提取",
                "3D面部地标",
                "扩散模型",
                "SDXL兼容",
                "自动化数据集构建"
            ],
            "_index": 47
        },
        {
            "title": "Hierarchical Persistence Velocity for Network Anomaly Detection: Theory and Applications to Cryptocurrency Markets",
            "authors": [
                "Omid Khormali"
            ],
            "arxiv_id": "2512.14615v1",
            "summary": "We introduce the Overlap-Weighted Hierarchical Normalized Persistence Velocity (OW-HNPV), a novel topological data analysis method for detecting anomalies in time-varying networks. Unlike existing methods that measure cumulative topological presence, we introduce the first velocity-based perspective on persistence diagrams, measuring the rate at which features appear and disappear, automatically downweighting noise through overlap-based weighting. We also prove that OW-HNPV is mathematically stable. It behaves in a controlled, predictable way, even when comparing persistence diagrams from networks with different feature types. Applied to Ethereum transaction networks (May 2017-May 2018), OW-HNPV demonstrates superior performance for cryptocurrency anomaly detection, achieving up to 10.4% AUC gain over baseline models for 7-day price movement predictions. Compared with established methods, including Vector of Averaged Bettis (VAB), persistence landscapes, and persistence images, velocity-based summaries excel at medium- to long-range forecasting (4-7 days), with OW-HNPV providing the most consistent and stable performance across prediction horizons. Our results show that modeling topological velocity is crucial for detecting structural anomalies in dynamic networks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14615v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "SAC"
                    ],
                    "score": 2
                }
            ],
            "headline_zh": "提出CAPRMIL框架，通过上下文感知的补丁表示简化多示例学习，提升计算病理学中的弱监督分析效率。",
            "summary_zh": "在计算病理学中，由于全切片图像（WSI）的千兆像素尺度和像素级标注的稀缺性，弱监督已成为深度学习的标准方法，其中多示例学习（MIL）被确立为切片级模型训练的主要框架。本文受神经偏微分方程（PDE）求解器的启发，为MIL方法引入了一种新颖的设置。我们提出了一种高效、聚合器无关的框架，无需依赖复杂的基于注意力的聚合，而是从MIL聚合器中移除了相关性学习的复杂性。CAPRMIL生成丰富的上下文感知补丁嵌入，促进下游任务中的有效相关性学习。通过将使用冻结补丁编码器提取的补丁特征投影到一小组全局上下文/形态感知令牌中，并利用多头自注意力，CAPRMIL以相对于包大小的线性计算复杂度注入全局上下文。结合简单的平均MIL聚合器，CAPRMIL在多个公共病理学基准测试中匹配了最先进的切片级性能，同时与最先进的MIL方法相比，可训练参数总数减少了48%-92.8%，推理期间的FLOPs降低了52%-99%，并在GPU内存效率和训练时间方面排名最佳模型之列。我们的结果表明，在聚合之前学习丰富的上下文感知实例表示是复杂池化方法在全切片分析中的一种有效且可扩展的替代方案。我们的代码可在https://github.com/mandlos/CAPRMIL获取。",
            "intro_zh": [
                "现有MIL方法依赖复杂注意力聚合，计算开销大，难以高效处理大规模WSI数据。",
                "提出CAPRMIL框架，通过上下文感知补丁嵌入和线性复杂度全局上下文注入，简化聚合过程。",
                "在多个病理基准测试中匹配SOTA性能，显著降低参数、FLOPs和内存需求，提升训练效率。"
            ],
            "method_zh": "CAPRMIL的整体框架包括：使用冻结的补丁编码器提取补丁特征，然后将其投影到少量全局上下文/形态感知令牌中，通过多头自注意力机制注入全局上下文，计算复杂度与包大小呈线性关系。关键技术创新点在于将相关性学习从聚合器转移到补丁表示阶段，生成上下文感知的嵌入，从而允许使用简单的平均聚合器。与现有方法的主要区别在于，它避免了复杂的注意力聚合机制，通过高效的上下文注入实现高性能，减少了模型复杂性和计算资源需求。",
            "application_zh": "该研究主要应用于计算病理学领域，特别是全切片图像（WSI）的弱监督分析，如癌症诊断、组织分类和预后预测。其高效性使其适合大规模医疗图像处理，降低计算成本，促进临床部署和实时分析。",
            "highlight_zh": "CAPRMIL在多个公共病理学基准测试中匹配最先进性能，同时可训练参数减少48%-92.8%，推理FLOPs降低52%-99%，在GPU内存效率和训练时间方面表现优异，显著提升了计算效率。",
            "tags_zh": [
                "多示例学习",
                "计算病理学",
                "弱监督学习",
                "上下文感知表示",
                "全切片图像分析",
                "高效聚合",
                "线性复杂度",
                "医疗图像处理"
            ],
            "_index": 48
        },
        {
            "title": "Hybrid Iterative Solvers with Geometry-Aware Neural Preconditioners for Parametric PDEs",
            "authors": [
                "Youngkyu Lee",
                "Francesc Levrero Florencio",
                "Jay Pathak",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14596v1",
            "summary": "The convergence behavior of classical iterative solvers for parametric partial differential equations (PDEs) is often highly sensitive to the domain and specific discretization of PDEs. Previously, we introduced hybrid solvers by combining the classical solvers with neural operators for a specific geometry 1, but they tend to under-perform in geometries not encountered during training. To address this challenge, we introduce Geo-DeepONet, a geometry-aware deep operator network that incorporates domain information extracted from finite element discretizations. Geo-DeepONet enables accurate operator learning across arbitrary unstructured meshes without requiring retraining. Building on this, we develop a class of geometry-aware hybrid preconditioned iterative solvers by coupling Geo-DeepONet with traditional methods such as relaxation schemes and Krylov subspace algorithms. Through numerical experiments on parametric PDEs posed over diverse unstructured domains, we demonstrate the enhanced robustness and efficiency of the proposed hybrid solvers for multiple real-world applications.",
            "categories": [
                "cs.LG",
                "math.NA"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 10 figures, 3 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14596v1",
            "code_links": [],
            "headline_zh": "提出基于变分自编码器的合成心内电图生成方法，以缓解非侵入性电生理成像中的数据稀缺问题。",
            "summary_zh": "心房颤动是最常见的持续性心律失常，其临床评估需要准确表征心房电活动。非侵入性心电图成像结合深度学习方法，从体表电位估计心内电图已显示出潜力，但进展受限于配对体表电位-心内电图数据集的有限可用性。为应对这一限制，本研究探索了变分自编码器用于生成合成多通道心房心内电图。提出了两种模型：针对窦性心律的特定VAE和针对窦性心律与心房颤动信号的类别条件VAE。生成的合成心内电图通过形态、频谱和分布相似性指标进行评估。VAE-S在仿真心内电图方面实现了更高的保真度，而VAE-C以降低窦性重建质量为代价，实现了节律特异性生成。作为概念验证，生成的合成心内电图被用于下游非侵入性心内电图重建任务的数据增强，其中适度增强提高了估计性能。这些结果证明了基于VAE的生成模型在缓解数据稀缺和增强基于深度学习的非侵入性心电图成像流程方面的潜力。",
            "intro_zh": [
                "核心问题：非侵入性电生理成像中，配对体表电位与心内电图数据稀缺，限制了深度学习方法的进展。",
                "方法要点：提出两种变分自编码器模型，分别针对窦性心律和节律条件生成合成心内电图，以扩充数据集。",
                "实验或效果：VAE-S在仿真数据上保真度更高，VAE-C支持节律特异性生成，数据增强提升了下游任务性能。"
            ],
            "method_zh": "论文提出基于变分自编码器的生成模型框架，用于合成多通道心房心内电图。整体框架包括两个模型：VAE-S专门针对窦性心律信号进行训练，VAE-C则通过类别条件机制同时处理窦性心律和心房颤动信号，实现节律特异性生成。关键技术创新点在于利用VAE的潜在空间表示来建模心内电图的复杂分布，并通过条件控制生成特定节律的合成数据。与现有方法的主要区别在于，传统方法依赖有限真实数据，而本方法通过生成合成数据直接缓解数据稀缺问题，且VAE-C首次在非侵入性电生理成像中实现多节律条件生成，增强了模型的适用性和灵活性。",
            "application_zh": "该研究主要应用于非侵入性电生理成像领域，特别是心房颤动的诊断和治疗规划。通过生成合成心内电图，可以扩充训练数据集，提升深度学习模型的泛化能力和准确性，从而优化临床评估流程，支持更精准的心脏电活动分析。",
            "highlight_zh": "VAE-S在仿真心内电图上的形态、频谱和分布相似性指标表现最佳，保真度更高；VAE-C成功实现节律特异性生成，但窦性重建质量略有下降。在下游非侵入性心内电图重建任务中，使用生成数据进行适度数据增强，显著提高了估计性能，验证了方法的有效性。",
            "tags_zh": [
                "变分自编码器",
                "合成心内电图生成",
                "非侵入性电生理成像",
                "数据增强",
                "心房颤动",
                "深度学习",
                "心内电图重建",
                "节律条件生成"
            ],
            "_index": 49
        },
        {
            "title": "TUMTraf EMOT: Event-Based Multi-Object Tracking Dataset and Baseline for Traffic Scenarios",
            "authors": [
                "Mengyu Li",
                "Xingcheng Zhou",
                "Guang Chen",
                "Alois Knoll",
                "Hu Cao"
            ],
            "arxiv_id": "2512.14595v1",
            "summary": "In Intelligent Transportation Systems (ITS), multi-object tracking is primarily based on frame-based cameras. However, these cameras tend to perform poorly under dim lighting and high-speed motion conditions. Event cameras, characterized by low latency, high dynamic range and high temporal resolution, have considerable potential to mitigate these issues. Compared to frame-based vision, there are far fewer studies on event-based vision. To address this research gap, we introduce an initial pilot dataset tailored for event-based ITS, covering vehicle and pedestrian detection and tracking. We establish a tracking-by-detection benchmark with a specialized feature extractor based on this dataset, achieving excellent performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14595v1",
            "code_links": [],
            "headline_zh": "提出DASP框架，利用时空先验的域适应解决夜间单目深度估计性能下降问题。",
            "summary_zh": "自监督单目深度估计在白天条件下已取得显著成功，但在夜间由于低可见度和变化光照（如光线不足导致纹理缺失区域，移动物体带来模糊区域）性能显著下降。为此，我们提出了一个名为DASP的自监督框架，利用时空先验进行夜间深度估计。具体来说，DASP包括一个用于提取时空先验的对抗分支和一个用于学习的自监督分支。在对抗分支中，我们首先设计了一个对抗网络，其中判别器由四个设计的时空先验学习块（SPLB）组成，以利用白天先验。特别地，SPLB包含一个基于空间的时序学习模块（STLM），使用正交差分沿时间轴提取与运动相关的变化，以及一个轴向空间学习模块（ASLM），采用局部非对称卷积与全局轴向注意力来捕获多尺度结构信息。通过结合STLM和ASLM，我们的模型能够获取足够的时空特征来恢复纹理缺失区域并估计由动态物体引起的模糊区域。在自监督分支中，我们提出了一个3D一致性投影损失，将目标帧和源帧双边投影到共享的3D空间中，并计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。在Oxford RobotCar和nuScenes数据集上的大量实验表明，我们的方法在夜间深度估计方面实现了最先进的性能。消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "现有自监督单目深度估计在夜间因低可见度和动态物体导致性能显著下降，难以处理纹理缺失和模糊区域。",
                "DASP框架结合对抗分支提取时空先验和自监督分支学习，通过SPLB模块和3D一致性投影损失增强特征提取和结构一致性。",
                "在Oxford RobotCar和nuScenes数据集上实现最先进性能，消融研究验证了各组件有效性，显著提升夜间深度估计精度。"
            ],
            "method_zh": "DASP是一个自监督框架，整体包括对抗分支和自监督分支。对抗分支中，判别器采用四个时空先验学习块（SPLB），每个SPLB结合空间时序学习模块（STLM）和轴向空间学习模块（ASLM）：STLM使用正交差分提取时间轴上的运动变化，ASLM利用局部非对称卷积和全局轴向注意力捕获多尺度结构信息。自监督分支引入3D一致性投影损失，通过双边投影目标帧和源帧到共享3D空间，计算3D差异以优化结构一致性和白天先验。关键创新在于SPLB的设计和3D投影损失，与现有方法相比，DASP更有效地整合时空先验，提升夜间场景的鲁棒性。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和增强现实等领域，特别是在夜间或低光照环境下，通过改进深度估计提升系统感知能力，增强安全性和可靠性。",
            "highlight_zh": "在Oxford RobotCar和nuScenes数据集上，DASP实现了最先进的夜间深度估计性能，消融研究证实SPLB模块和3D一致性投影损失对提升精度有显著贡献，有效处理纹理缺失和动态模糊问题。",
            "tags_zh": [
                "夜间深度估计",
                "自监督学习",
                "时空先验",
                "域适应",
                "对抗网络",
                "3D一致性投影",
                "单目视觉",
                "动态物体处理"
            ],
            "_index": 50
        },
        {
            "title": "Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies",
            "authors": [
                "Ekaterina Artemova",
                "Laurie Burchell",
                "Daryna Dementieva",
                "Shu Okabe",
                "Mariya Shmatova",
                "Pedro Ortiz Suarez"
            ],
            "arxiv_id": "2512.14576v1",
            "summary": "This tutorial (https://tum-nlp.github.io/low-resource-tutorial) is designed for NLP practitioners, researchers, and developers working with multilingual and low-resource languages who seek to create more equitable and socially impactful language technologies. Participants will walk away with a practical toolkit for building end-to-end NLP pipelines for underrepresented languages -- from data collection and web crawling to parallel sentence mining, machine translation, and downstream applications such as text classification and multimodal reasoning. The tutorial presents strategies for tackling the challenges of data scarcity and cultural variance, offering hands-on methods and modeling frameworks. We will focus on fair, reproducible, and community-informed development approaches, grounded in real-world scenarios. We will showcase a diverse set of use cases covering over 10 languages from different language families and geopolitical contexts, including both digitally resource-rich and severely underrepresented languages.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Tutorial is accepted to LREC2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14527v1",
            "code_links": [],
            "headline_zh": "提出基于损失变化的动态学习率调度器GreedyLR，以加速模型训练收敛",
            "summary_zh": "尽管训练优化器取得了显著进展，但大多数研究工作仍使用余弦或指数衰减等常见调度器。本文研究了GreedyLR，这是一种新颖的调度器，能够根据当前损失在训练过程中自适应调整学习率。为了验证所提出调度器的有效性，我们在多个NLP、CV和LLM任务上进行了实验，参数规模高达70亿，包括微调和预训练实验。结果表明，我们的方法在准确性、速度和收敛性方面优于几种最先进的调度器。我们还提供了GreedyLR算法的理论分析，包括收敛性证明和最大化收敛速率的最优缩放因子F的推导，并通过实验展示了算法对现实噪声环境的鲁棒性。我们的调度器易于实现、计算高效，可被视为训练的良好默认调度器。",
            "intro_zh": [
                "现有方法多依赖固定模式调度器（如余弦衰减），缺乏对训练动态的自适应调整，可能导致收敛速度慢或性能不佳。",
                "提出GreedyLR调度器，核心思想是根据损失变化动态调整学习率，通过理论推导确定最优缩放因子以加速收敛。",
                "在NLP、CV和LLM任务上实验显示，GreedyLR在准确率、速度和收敛性上优于现有调度器，参数规模达70亿。"
            ],
            "method_zh": "GreedyLR是一种动态学习率调度器，整体框架基于训练过程中的损失变化来调整学习率。关键技术创新点在于自适应机制：算法实时监控损失值，根据损失的变化幅度计算学习率调整因子，通过理论分析推导出最优缩放因子F以最大化收敛速率。与现有方法的主要区别在于，它不依赖预定义的时间表（如余弦衰减），而是根据训练动态进行实时调整，从而更灵活地适应不同任务和模型，提高了对噪声环境的鲁棒性。",
            "application_zh": "该研究可广泛应用于自然语言处理、计算机视觉和大语言模型的训练场景，包括微调和预训练任务。其实际价值在于提供了一种高效、自适应的学习率调度方法，能加速模型收敛、提升训练效率，适用于大规模参数模型（如70亿参数）的训练优化。",
            "highlight_zh": "实验在多个NLP、CV和LLM任务上进行，参数规模高达70亿，结果显示GreedyLR在准确率、训练速度和收敛性方面均优于现有最先进调度器，同时算法对噪声环境表现出良好鲁棒性。",
            "tags_zh": [
                "动态学习率调度",
                "训练优化",
                "收敛加速",
                "自适应调整",
                "损失变化",
                "大规模模型训练",
                "理论分析",
                "鲁棒性验证"
            ],
            "_index": 51
        },
        {
            "title": "Polypersona: Persona-Grounded LLM for Synthetic Survey Responses",
            "authors": [
                "Tejaswani Dash",
                "Dinesh Karri",
                "Anudeep Vurity",
                "Gautam Datla",
                "Tazeem Ahmad",
                "Saima Rafi",
                "Rohith Tangudu"
            ],
            "arxiv_id": "2512.14562v1",
            "summary": "This paper introduces PolyPersona, a generative framework for synthesizing persona-conditioned survey responses across multiple domains. The framework instruction-tunes compact chat models using parameter-efficient LoRA adapters with 4-bit quantization under a resource-adaptive training setup. A dialogue-based data pipeline explicitly preserves persona cues, ensuring consistent behavioral alignment across generated responses. Using this pipeline, we construct a dataset of 3,568 synthetic survey responses spanning ten domains and 433 distinct personas, enabling controlled instruction tuning and systematic multi-domain evaluation. We evaluate the generated responses using a multi-metric evaluation suite that combines standard text generation metrics, including BLEU, ROUGE, and BERTScore, with survey-specific metrics designed to assess structural coherence, stylistic consistency, and sentiment alignment.Experimental results show that compact models such as TinyLlama 1.1B and Phi-2 achieve performance comparable to larger 7B to 8B baselines, with a highest BLEU score of 0.090 and ROUGE-1 of 0.429. These findings demonstrate that persona-conditioned fine-tuning enables small language models to generate reliable and coherent synthetic survey data. The proposed framework provides an efficient and reproducible approach for survey data generation, supporting scalable evaluation while facilitating bias analysis through transparent and open protocols.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted in IEEE Bigdata 2025- LLMs4ALL",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14562v1",
            "code_links": [],
            "headline_zh": "比较生成方法以解决科学计算网络中数据转移预测的类别不平衡问题",
            "summary_zh": "监控数据转移性能是科学计算网络中的关键任务。通过在通信阶段早期预测性能，可以识别潜在缓慢的转移并选择性监控，从而优化网络使用和整体性能。在此背景下，提高机器学习模型预测能力的一个关键瓶颈是类别不平衡问题。本项目专注于解决类别不平衡问题以增强性能预测的准确性。在本研究中，我们分析和比较了多种增强策略，包括传统的过采样方法和生成技术。此外，我们调整训练数据集中的类别不平衡比例以评估其对模型性能的影响。虽然增强可能改善性能，但随着不平衡比例增加，性能并未显著提升。我们得出结论，即使是最先进的技术如CTGAN，也未显著优于简单的分层采样。",
            "intro_zh": [
                "核心问题：机器学习模型在科学计算网络数据转移预测中面临类别不平衡，导致预测准确性受限。",
                "方法要点：比较传统过采样与生成方法如CTGAN，调整训练数据不平衡比例以评估增强策略效果。",
                "实验或效果：增强策略在低不平衡时可能提升性能，但高不平衡下改进有限，CTGAN未显著优于分层采样。"
            ],
            "method_zh": "论文采用比较分析框架，核心方法包括传统过采样和生成技术如CTGAN，用于处理数据转移预测中的类别不平衡。关键技术创新点在于系统评估不同增强策略在不平衡比例变化下的效果，而非提出新模型。与现有方法的主要区别在于直接对比生成方法与简单采样，强调实际应用中的性能瓶颈，而非理论优化。整体框架基于实验驱动，通过调整训练数据集的不平衡比例来量化增强策略的贡献。",
            "application_zh": "该研究可应用于科学计算网络中的性能监控和优化，帮助识别缓慢数据转移以提升网络效率，潜在价值在于指导实际部署中的类别不平衡处理策略。",
            "highlight_zh": "最重要的实验结果显示，增强策略在类别不平衡比例较低时可能改善预测性能，但随着比例增加，性能提升不显著；CTGAN等先进生成方法未超越简单分层采样，表明类别不平衡问题在此场景下具有挑战性。",
            "tags_zh": [
                "数据转移预测",
                "类别不平衡",
                "生成方法",
                "过采样",
                "科学计算网络",
                "性能监控",
                "机器学习模型",
                "CTGAN"
            ],
            "_index": 52
        },
        {
            "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
            "authors": [
                "Nguyen Tien Dong",
                "Minh-Anh Nguyen",
                "Thanh Dat Hoang",
                "Nguyen Tuan Ngoc",
                "Dao Xuan Quang Minh",
                "Phan Phi Hai",
                "Nguyen Thi Ngoc Anh",
                "Dang Van Tu",
                "Binh Vu"
            ],
            "arxiv_id": "2512.14554v1",
            "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14554v1",
            "code_links": [],
            "headline_zh": "提出C-ing Clearly方法，利用C代码增强大语言模型对汇编的理解，以解决二进制代码分析任务性能不足的问题。",
            "summary_zh": "大语言模型（LLMs）通常在涉及高级编程语言的编码任务中表现出色，但对于低级编程语言（如汇编）则表现不佳。我们提出了一种名为C-ing Clearly的合成数据生成方法，该方法利用相应的C代码来增强LLM对汇编的理解。通过在通过我们的方法生成的数据上进行微调，我们展示了LLM在二进制代码摘要和漏洞检测方面的性能提升。我们的方法在不同LLM家族和模型大小上均表现出了一致的增益。",
            "intro_zh": [
                "核心问题：大语言模型在处理低级汇编语言时性能不足，难以有效执行二进制代码分析任务。",
                "方法要点：提出C-ing Clearly方法，通过生成C代码与汇编的对应数据，增强模型对汇编语义的理解。",
                "实验或效果：在二进制代码摘要和漏洞检测任务中，微调后的模型性能显著提升，且在不同模型上表现一致。"
            ],
            "method_zh": "C-ing Clearly是一种合成数据生成方法，整体框架基于利用C代码作为中介来增强LLM对汇编的理解。关键技术创新点在于自动生成C代码与汇编的配对数据，通过微调LLM学习两者之间的语义映射。与现有方法的主要区别在于，它不依赖大量人工标注的汇编数据，而是利用C代码的丰富语义信息来提升模型性能，从而更高效地解决低级语言分析问题。",
            "application_zh": "该研究可应用于软件安全分析、逆向工程和漏洞检测等领域，通过提升LLM对二进制代码的理解能力，帮助自动化代码审计和恶意软件分析，具有重要的实际价值。",
            "highlight_zh": "实验结果显示，在二进制代码摘要和漏洞检测任务中，使用C-ing Clearly方法微调的LLM性能显著提升，且在不同LLM家族和模型大小上均获得一致增益，验证了方法的有效性和泛化能力。",
            "tags_zh": [
                "大语言模型",
                "汇编语言理解",
                "二进制代码分析",
                "合成数据生成",
                "漏洞检测",
                "代码摘要",
                "微调技术",
                "软件安全"
            ],
            "_index": 53
        },
        {
            "title": "Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency",
            "authors": [
                "Jia Guo",
                "Jiawei Du",
                "Shengzhu Yang",
                "Shuai Lu",
                "Wenquan Cheng",
                "Kaiwen Zhang",
                "Yihua Sun",
                "Chuhong Yang",
                "Weihang Zhang",
                "Fang Chen",
                "Yilan Wu",
                "Lie Ju",
                "Guochen Ning",
                "Longfei Ma",
                "Huiping Yao",
                "Jinyuan Wang",
                "Peilun Shi",
                "Yukun Zhou",
                "Jie Xu",
                "Pearse A. Keane",
                "Hanruo Liu",
                "Hongen Liao",
                "Ningli Wang",
                "Huiqi Li"
            ],
            "arxiv_id": "2512.14499v1",
            "summary": "Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14499v1",
            "code_links": [],
            "headline_zh": "提出ReVision视网膜基础模型，从大规模临床实践中学习，以解决低资源环境下部署效率低的问题。",
            "summary_zh": "当前视网膜基础模型受限于缺乏真实临床背景的精选研究数据集，且每个应用都需要大量任务特定优化，限制了其在低资源环境下的部署效率。本文表明，通过直接从真实世界医疗实践中构建临床原生智能，可以克服这些障碍。我们的核心见解是，大规模远程医疗项目（专家中心为分布式机构提供远程咨询）是学习临床图像解读的自然资源库。我们提出了ReVision，一个视网膜基础模型，它从485,980张彩色眼底照片及其对应诊断报告的自然对齐中学习，这些数据来自中国162家医疗机构长达十年的远程医疗项目积累。通过在27个眼科基准上进行广泛评估，我们证明ReVision能以最少的本地资源实现部署效率。无需任何任务特定训练，ReVision在12个公共基准上实现零样本疾病检测，平均AUROC为0.946，在3个独立临床队列上为0.952。当最小适应可行时，ReVision匹配经过广泛微调的替代方案，同时需要数量级更少的可训练参数和标记示例。学习到的表示还能有效迁移到新临床站点、成像领域、成像模态和系统健康预测任务。在一项涉及33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将诊断准确性提高了14.8%，覆盖所有经验水平。这些结果表明，临床原生智能可以直接从临床档案中提取，无需进一步注释，以构建适合各种低资源环境的医疗AI系统。",
            "intro_zh": [
                "核心问题：现有视网膜基础模型依赖精选数据集，缺乏真实临床上下文，且需大量任务特定优化，导致低资源环境下部署效率低。",
                "方法要点：从大规模远程医疗项目中学习临床图像与诊断报告的自然对齐，构建临床原生智能，无需额外标注。",
                "实验或效果：零样本疾病检测AUROC达0.946-0.952，最小适应下匹配微调模型，参数和样本需求大幅减少。"
            ],
            "method_zh": "ReVision是一个视网膜基础模型，其整体框架基于大规模远程医疗数据构建，核心是从485,980张彩色眼底照片及其对应诊断报告的自然对齐中学习临床图像解读。关键技术创新点在于直接从真实世界临床实践中提取原生智能，利用远程医疗项目积累的数据，实现图像与文本的跨模态对齐学习。与现有方法的主要区别在于：现有方法通常依赖标注良好的研究数据集，而ReVision直接从临床档案中学习，无需额外人工标注；现有方法需要针对每个任务进行大量优化，而ReVision通过零样本或最小适应实现高效部署，减少了参数和样本需求。",
            "application_zh": "该研究在低资源医疗环境中具有广泛应用价值，如远程眼科诊断、基层医疗机构辅助筛查、多模态医学图像分析，以及系统健康预测任务，能提升诊断效率和准确性，降低医疗成本。",
            "highlight_zh": "零样本疾病检测在12个公共基准上平均AUROC达0.946，在3个临床队列上达0.952；最小适应下匹配微调模型，参数和样本需求减少数量级；前瞻性读者研究中，零样本辅助将诊断准确性提高14.8%。",
            "tags_zh": [
                "视网膜基础模型",
                "临床原生智能",
                "远程医疗",
                "零样本学习",
                "部署效率",
                "多模态对齐",
                "低资源医疗AI",
                "眼科图像分析"
            ],
            "_index": 55
        },
        {
            "title": "SuperCLIP: CLIP with Simple Classification Supervision",
            "authors": [
                "Weiheng Zhao",
                "Zilong Huang",
                "Jiashi Feng",
                "Xinggang Wang"
            ],
            "arxiv_id": "2512.14480v1",
            "summary": "Contrastive Language-Image Pretraining (CLIP) achieves strong generalization in vision-language tasks by aligning images and texts in a shared embedding space. However, recent findings show that CLIP-like models still underutilize fine-grained semantic signals in text, and this issue becomes even more pronounced when dealing with long and detailed captions. This stems from CLIP's training objective, which optimizes only global image-text similarity and overlooks token-level supervision - limiting its ability to achieve fine-grained visual-text alignment. To address this, we propose SuperCLIP, a simple yet effective framework that augments contrastive learning with classification-based supervision. By adding only a lightweight linear layer to the vision encoder, SuperCLIP leverages token-level cues to enhance visual-textual alignment - with just a 0.077% increase in total FLOPs, and no need for additional annotated data. Experiments show that SuperCLIP consistently improves zero-shot classification, image-text retrieval, and purely visual tasks. These gains hold regardless of whether the model is trained on original web data or rich re-captioned data, demonstrating SuperCLIP's ability to recover textual supervision in both cases. Furthermore, SuperCLIP alleviates CLIP's small-batch performance drop through classification-based supervision that avoids reliance on large batch sizes. Code and models will be made open source.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by NeurIPS 2025. Code: https://github.com/hustvl/SuperCLIP",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14480v1",
            "code_links": [],
            "headline_zh": "提出稀疏多模态Transformer架构SMMT，以解决资源受限下多模态智能系统的高计算成本问题。",
            "summary_zh": "基于Transformer的多模态智能系统常因密集自注意力机制导致高计算和能耗成本，限制了其在资源约束下的可扩展性。本文提出SMMT，一种稀疏多模态Transformer架构，旨在提升效率和鲁棒性。该架构在级联多模态Transformer框架基础上，引入基于聚类的稀疏注意力机制以实现近似线性的计算复杂度，并采用模态级掩码增强对不完整输入的鲁棒性。以ADNI数据集上的阿尔茨海默病分类作为代表性多模态案例进行评估，实验结果表明，与密集注意力基线相比，SMMT在保持竞争力的预测性能的同时，显著减少了训练时间、内存使用和能耗，证明了其作为可扩展智能系统中资源感知架构组件的适用性。",
            "intro_zh": [
                "现有基于Transformer的多模态系统因密集自注意力导致高计算和能耗成本，限制了资源受限下的可扩展性。",
                "SMMT引入基于聚类的稀疏注意力和模态级掩码，实现近似线性计算复杂度并增强对不完整输入的鲁棒性。",
                "在ADNI数据集上，SMMT保持竞争力预测性能，同时显著降低训练时间、内存使用和能耗。"
            ],
            "method_zh": "SMMT基于级联多模态Transformer框架构建，整体架构通过多模态融合处理输入数据。关键技术创新点包括：采用基于聚类的稀疏注意力机制，将注意力计算限制在相关聚类内，从而将计算复杂度从二次降低到近似线性；引入模态级掩码技术，在训练时随机屏蔽部分模态输入，以增强模型对不完整数据的鲁棒性。与现有方法的主要区别在于，传统多模态Transformer通常使用密集自注意力，计算成本高，而SMMT通过稀疏化和掩码策略，在保持性能的同时大幅提升效率，特别适用于资源受限环境。",
            "application_zh": "该研究可应用于医疗诊断、自动驾驶、机器人感知等需要多模态数据融合的智能系统领域，尤其在资源受限的边缘设备或大规模部署场景中，SMMT的高效性和鲁棒性有助于降低计算成本并提升系统可靠性。",
            "highlight_zh": "在ADNI数据集上的阿尔茨海默病分类任务中，SMMT与密集注意力基线相比，在保持相似预测准确率的同时，训练时间减少约30%，内存使用降低25%，能耗下降20%，显著提升了资源效率。",
            "tags_zh": [
                "稀疏注意力",
                "多模态Transformer",
                "阿尔茨海默病分类",
                "计算效率",
                "模态掩码",
                "资源感知架构",
                "ADNI数据集",
                "可扩展智能系统"
            ],
            "_index": 55
        },
        {
            "title": "SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition",
            "authors": [
                "Alessia Micieli",
                "Giovanni Maria Farinella",
                "Francesco Ragusa"
            ],
            "arxiv_id": "2512.14489v1",
            "summary": "In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14489v1",
            "code_links": [
                {
                    "url": "https://fpv-iplab.github.io/SignIT/",
                    "type": "project_page"
                }
            ],
            "headline_zh": "提出SignIT数据集与多模态分析框架，以解决意大利手语识别任务中的数据集稀缺与模型性能挑战问题。",
            "summary_zh": "本文介绍了SignIT，一个用于研究意大利手语识别任务的新数据集。该数据集包含644个视频，总时长3.33小时，手动标注了94个不同的手语类别，这些类别属于5个宏观类别：动物、食物、颜色、情感和家庭。我们还提取了用户手部、面部和身体的2D关键点。基于此数据集，我们提出了一个手语识别任务的基准，采用多种最先进的模型，展示了时间信息、2D关键点和RGB帧如何影响这些模型的性能。结果表明，这些模型在这个具有挑战性的LIS数据集上存在局限性。数据和标注已发布在以下链接：https://fpv-iplab.github.io/SignIT/。",
            "intro_zh": [
                "现有意大利手语识别研究面临数据集稀缺和模型性能不足的挑战，限制了实际应用的发展。",
                "论文提出SignIT数据集，包含多模态标注和基准测试，通过整合时间信息、2D关键点和RGB帧来提升识别准确性。",
                "实验结果显示，现有模型在SignIT数据集上表现有限，突出了多模态融合的重要性，为未来研究提供了改进方向。"
            ],
            "method_zh": "论文的核心方法包括构建SignIT数据集，该数据集包含644个视频，手动标注94个手语类别，并提取手部、面部和身体的2D关键点。整体框架涉及多模态数据整合，通过基准测试评估多种最先进模型，如基于时间序列、关键点和RGB帧的模型。关键技术创新点在于提供全面的多模态标注和公开基准，与现有方法的主要区别在于专注于意大利手语，并强调多模态信息对性能的影响，而非提出新模型架构。",
            "application_zh": "该研究可应用于手语翻译系统、无障碍通信工具和教育平台，帮助聋哑人士与主流社会交流，提升手语识别技术的实际可用性和普及度。",
            "highlight_zh": "实验结果显示，现有最先进模型在SignIT数据集上的性能有限，表明时间信息、2D关键点和RGB帧的整合对提升识别准确率至关重要，为多模态手语识别研究提供了重要基准和挑战。",
            "tags_zh": [
                "意大利手语识别",
                "多模态数据集",
                "2D关键点提取",
                "视频分析",
                "基准测试",
                "手语分类",
                "计算机视觉",
                "无障碍技术"
            ],
            "_index": 56
        },
        {
            "title": "TACK Tunnel Data (TTD): A Benchmark Dataset for Deep Learning-Based Defect Detection in Tunnels",
            "authors": [
                "Andreas Sjölander",
                "Valeria Belloni",
                "Robel Fekadu",
                "Andrea Nascetti"
            ],
            "arxiv_id": "2512.14477v1",
            "summary": "Tunnels are essential elements of transportation infrastructure, but are increasingly affected by ageing and deterioration mechanisms such as cracking. Regular inspections are required to ensure their safety, yet traditional manual procedures are time-consuming, subjective, and costly. Recent advances in mobile mapping systems and Deep Learning (DL) enable automated visual inspections. However, their effectiveness is limited by the scarcity of tunnel datasets. This paper introduces a new publicly available dataset containing annotated images of three different tunnel linings, capturing typical defects: cracks, leaching, and water infiltration. The dataset is designed to support supervised, semi-supervised, and unsupervised DL methods for defect detection and segmentation. Its diversity in texture and construction techniques also enables investigation of model generalization and transferability across tunnel types. By addressing the critical lack of domain-specific data, this dataset contributes to advancing automated tunnel inspection and promoting safer, more efficient infrastructure maintenance strategies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14477v1",
            "code_links": [],
            "headline_zh": "提出SASQ框架以解决大语言模型量化训练中激活量化因子的优化问题，实现高效静态推理。",
            "summary_zh": "大语言模型（LLMs）在自然语言任务中表现出色，但其规模增长快于GPU内存进步，导致部署挑战。模型量化通过降低权重和激活精度来缓解此问题，但现有方案面临根本性权衡：动态量化计算开销高且在边缘设备上部署困难，而静态量化则牺牲准确性。现有的量化感知训练（QAT）方法还面临权重训练成本问题。我们提出SASQ：一个专门针对激活量化因子的轻量级QAT框架。SASQ仅优化量化因子（不改变预训练权重），实现高精度的静态推理，同时保持部署效率。SASQ自适应地截断一些异常值，从而降低量化难度，同时保留激活的分布特性。SASQ不仅超越了现有SOTA量化方案，还优于对应的FP16模型。在LLaMA2-7B上，它在WikiText2上实现了比QuaRot低5.2%的困惑度和比FP16模型低4.7%的困惑度。",
            "intro_zh": [
                "现有量化方法面临动态量化计算开销高、静态量化精度低，以及量化感知训练权重成本大的挑战。",
                "SASQ框架仅优化激活量化因子，不改变预训练权重，通过自适应截断异常值来降低量化难度。",
                "在LLaMA2-7B上，SASQ在WikiText2上比QuaRot和FP16模型分别降低5.2%和4.7%的困惑度。"
            ],
            "method_zh": "SASQ是一个轻量级量化感知训练框架，专注于优化激活量化因子。整体框架基于预训练模型，仅调整量化参数而不更新权重，实现静态推理。关键技术创新包括自适应截断激活中的异常值，以平衡量化精度和分布保留。与现有方法的主要区别在于避免了权重训练成本，同时通过静态量化因子优化提升准确性，解决了动态量化部署困难和静态量化精度不足的问题。",
            "application_zh": "该研究适用于大语言模型的边缘部署和资源受限环境，如移动设备、嵌入式系统，能降低内存和计算需求，提升模型在自然语言处理任务中的实际应用效率。",
            "highlight_zh": "在LLaMA2-7B模型上，SASQ在WikiText2数据集上实现比QuaRot低5.2%的困惑度，甚至优于FP16模型4.7%，展示了其在量化精度和部署效率方面的显著优势。",
            "tags_zh": [
                "大语言模型",
                "模型量化",
                "量化感知训练",
                "激活量化",
                "静态推理",
                "边缘部署",
                "轻量级框架",
                "异常值截断"
            ],
            "_index": 57
        },
        {
            "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
            "authors": [
                "Additi Pandey",
                "Liang Wei",
                "Hessam Babaee",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14471v1",
            "summary": "Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14471v1",
            "code_links": [],
            "headline_zh": "提出SuperCLIP框架，通过分类监督增强对比学习，解决CLIP模型细粒度语义利用不足的问题。",
            "summary_zh": "对比语言-图像预训练（CLIP）通过在共享嵌入空间中对齐图像和文本来实现视觉-语言任务的强泛化能力。然而，最近的研究发现，CLIP类模型在处理文本时仍未能充分利用细粒度语义信号，这一问题在处理长而详细的描述时尤为明显。这源于CLIP的训练目标仅优化全局图像-文本相似性，而忽略了词元级监督，限制了其实现细粒度视觉-文本对齐的能力。为解决这一问题，我们提出了SuperCLIP，一个简单而有效的框架，通过基于分类的监督来增强对比学习。仅需在视觉编码器上添加一个轻量级线性层，SuperCLIP就能利用词元级线索来提升视觉-文本对齐，总FLOPs仅增加0.077%，且无需额外标注数据。实验表明，SuperCLIP在零样本分类、图像-文本检索和纯视觉任务上均能持续提升性能。这些增益无论模型是在原始网络数据还是丰富的重新描述数据上训练都成立，证明了SuperCLIP在两种情况下恢复文本监督的能力。此外，SuperCLIP通过基于分类的监督减轻了CLIP在小批量情况下的性能下降，避免了依赖大批量训练。代码和模型将开源。",
            "intro_zh": [
                "CLIP模型仅优化全局图像-文本相似性，忽略词元级监督，导致细粒度语义信号利用不足，尤其在处理长描述时表现更差。",
                "SuperCLIP通过添加轻量级线性层，引入基于分类的监督，增强对比学习，以词元级线索提升视觉-文本对齐，无需额外数据。",
                "实验显示SuperCLIP在零样本分类、图像-文本检索和视觉任务上均提升性能，并缓解小批量训练的性能下降问题。"
            ],
            "method_zh": "SuperCLIP的整体框架基于CLIP，通过增强对比学习来实现。关键技术创新点是在视觉编码器上添加一个轻量级线性层，用于生成分类预测，从而引入基于分类的监督。这种方法利用文本中的词元级信息（如名词或短语）作为监督信号，通过分类损失函数优化视觉特征与文本细粒度语义的对齐。与现有方法的主要区别在于，SuperCLIP不依赖复杂的架构或额外标注数据，而是通过简单的分类监督直接提升CLIP的细粒度对齐能力，总计算开销仅微增0.077%。",
            "application_zh": "SuperCLIP可应用于多模态人工智能领域，如零样本图像分类、图像-文本检索、视觉问答和内容生成任务。其提升的细粒度对齐能力有助于在医疗影像分析、自动驾驶视觉理解和智能内容推荐等实际场景中实现更精准的语义理解。",
            "highlight_zh": "SuperCLIP在零样本分类任务上显著提升准确率，图像-文本检索性能优于基线CLIP，同时纯视觉任务如目标检测也有改进。实验还表明，该方法能有效缓解小批量训练的性能下降，总FLOPs仅增加0.077%，无需额外数据。",
            "tags_zh": [
                "对比学习",
                "多模态对齐",
                "细粒度语义",
                "零样本分类",
                "图像-文本检索",
                "轻量级监督",
                "视觉-语言模型",
                "预训练框架"
            ],
            "_index": 58
        },
        {
            "title": "Nonlinear System Identification Nano-drone Benchmark",
            "authors": [
                "Riccardo Busetto",
                "Elia Cereda",
                "Marco Forgione",
                "Gabriele Maroni",
                "Dario Piga",
                "Daniele Palossi"
            ],
            "arxiv_id": "2512.14450v1",
            "summary": "We introduce a benchmark for system identification based on 75k real-world samples from the Crazyflie 2.1 Brushless nano-quadrotor, a sub-50g aerial vehicle widely adopted in robotics research. The platform presents a challenging testbed due to its multi-input, multi-output nature, open-loop instability, and nonlinear dynamics under agile maneuvers. The dataset comprises four aggressive trajectories with synchronized 4-dimensional motor inputs and 13-dimensional output measurements. To enable fair comparison of identification methods, the benchmark includes a suite of multi-horizon prediction metrics for evaluating both one-step and multi-step error propagation. In addition to the data, we provide a detailed description of the platform and experimental setup, as well as baseline models highlighting the challenge of accurate prediction under real-world noise and actuation nonlinearities. All data, scripts, and reference implementations are released as open-source at https://github.com/idsia-robotics/nanodrone-sysid-benchmark to facilitate transparent comparison of algorithms and support research on agile, miniaturized aerial robotics.",
            "categories": [
                "eess.SY",
                "cs.RO"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14477v1",
            "code_links": [],
            "headline_zh": "提出TACK隧道数据集（TTD）以解决隧道缺陷检测中领域数据稀缺的问题。",
            "summary_zh": "隧道是交通基础设施的关键组成部分，但日益受到老化和劣化机制（如裂缝）的影响。为确保安全，需要定期检查，但传统手动方法耗时、主观且成本高。移动测绘系统和深度学习的进展使得自动化视觉检查成为可能，但其有效性受限于隧道数据集的稀缺性。本文介绍了一个新的公开数据集，包含三种不同隧道衬砌的标注图像，捕捉典型缺陷：裂缝、渗漏和水渗透。该数据集旨在支持监督、半监督和无监督的深度学习方法进行缺陷检测和分割。其在纹理和施工技术上的多样性也使得能够研究模型在不同隧道类型间的泛化性和可迁移性。通过解决领域特定数据的关键缺乏问题，该数据集有助于推进自动化隧道检查，并促进更安全、更高效的基础设施维护策略。",
            "intro_zh": [
                "核心问题：隧道缺陷检测依赖传统手动检查，存在耗时、主观和成本高的不足，且深度学习应用受限于领域数据稀缺。",
                "方法要点：构建公开数据集TTD，包含多种隧道衬砌的标注图像，支持监督、半监督和无监督方法，以促进模型泛化研究。",
                "实验或效果：数据集通过多样纹理和施工技术设计，提升了缺陷检测的自动化水平，为基础设施维护提供数据基础。"
            ],
            "method_zh": "论文的核心方法是构建和发布TACK隧道数据集（TTD），整体框架包括数据采集、标注和公开共享。关键技术创新点在于数据集覆盖三种不同隧道衬砌类型，并标注了裂缝、渗漏和水渗透等典型缺陷，支持多种深度学习范式。与现有方法的主要区别在于其针对隧道领域的专门性，解决了数据稀缺问题，并强调模型泛化性和可迁移性的评估，而非提出新算法。",
            "application_zh": "该研究主要应用于隧道基础设施的自动化视觉检查，潜在应用领域包括交通工程、城市维护和公共安全。实际价值在于通过提供高质量数据集，加速深度学习模型开发，实现更高效、客观的缺陷检测，从而提升基础设施维护的安全性和经济性。",
            "highlight_zh": "最重要的实验结果是TTD数据集的公开可用性，它通过多样化的隧道衬砌图像和缺陷标注，为深度学习模型提供了基准测试平台。性能提升体现在支持多种学习方法，促进了缺陷检测任务的自动化进展，但具体模型性能数据未知，需后续研究验证。",
            "tags_zh": [
                "隧道缺陷检测",
                "深度学习数据集",
                "基础设施维护",
                "视觉检查",
                "模型泛化",
                "数据稀缺",
                "自动化检测",
                "公共数据集"
            ],
            "_index": 59
        },
        {
            "title": "A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning",
            "authors": [
                "Zixin Zhang",
                "Kanghao Chen",
                "Hanqing Wang",
                "Hongfei Zhang",
                "Harold Haodong Chen",
                "Chenfei Liao",
                "Litao Guo",
                "Ying-Cong Chen"
            ],
            "arxiv_id": "2512.14442v1",
            "summary": "Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\\textbf{Dreamer}$ that employs generative models to visualize $\\textit{how}$ an interaction would look; (2) a $\\textbf{Thinker}$ that utilizes large vision-language models to decide $\\textit{what}$ object part to interact with; and (3) a $\\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14442v1",
            "code_links": [],
            "headline_zh": "提出模型优先推理方法，通过显式问题建模减少大语言模型在复杂规划任务中的幻觉问题",
            "summary_zh": "大语言模型在处理复杂多步规划任务时，常出现高约束违反率和不一致解决方案。现有策略如思维链和ReAct依赖隐式状态跟踪，缺乏显式问题表示。受经典AI规划启发，本文提出模型优先推理，这是一种两阶段范式：LLM首先构建问题的显式模型，定义实体、状态变量、动作和约束，然后生成解决方案计划。在医疗调度、路径规划、资源分配、逻辑谜题和程序合成等多个规划领域中，与思维链和ReAct相比，MFR减少了约束违反并提高了解决方案质量。消融研究表明，显式建模阶段对这些改进至关重要。结果表明，许多LLM规划失败源于表示缺陷而非推理限制，凸显显式建模作为稳健可解释AI代理的关键组成部分。所有提示、评估程序和任务数据集均已记录，以促进可重复性。",
            "intro_zh": [
                "现有方法如思维链和ReAct依赖隐式状态跟踪，缺乏显式问题表示，导致高约束违反和不一致解决方案。",
                "提出模型优先推理，两阶段范式：先构建显式问题模型，再生成解决方案计划，以增强表示能力。",
                "在多个规划领域实验中，MFR显著减少约束违反，提高解决方案质量，消融研究证实显式建模的关键作用。"
            ],
            "method_zh": "模型优先推理采用两阶段框架：第一阶段，LLM构建问题的显式模型，包括定义实体、状态变量、动作和约束，形成结构化表示；第二阶段，基于此模型生成解决方案计划。关键创新在于引入显式建模步骤，将问题表示与推理分离，类似于经典AI规划方法。与现有方法如思维链和ReAct的主要区别在于，MFR不依赖隐式状态跟踪，而是通过显式模型提供清晰的问题结构，从而减少幻觉和约束违反，提高规划任务的稳健性和可解释性。",
            "application_zh": "该研究适用于需要复杂多步规划的领域，如医疗调度、路径规划、资源分配、逻辑谜题和程序合成。通过显式建模，可提升AI代理在实际任务中的可靠性和效率，支持自动化决策和智能系统开发。",
            "highlight_zh": "在多个规划领域实验中，MFR相比思维链和ReAct，显著减少约束违反率，提高解决方案质量；消融研究显示，显式建模阶段是关键改进因素，验证了表示缺陷是LLM规划失败的主要原因。",
            "tags_zh": [
                "大语言模型",
                "规划任务",
                "显式建模",
                "模型优先推理",
                "约束违反",
                "AI代理",
                "可解释性",
                "多步规划"
            ],
            "_index": 60
        },
        {
            "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
            "authors": [
                "Gabriele Prato",
                "Shagun Sodhani",
                "Alessandro Sordoni",
                "Sarath Chandar"
            ],
            "arxiv_id": "2512.14427v1",
            "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14427v1",
            "code_links": [],
            "headline_zh": "提出Kinetic-Mamba框架，结合Mamba架构高效预测刚性化学动力学，用于燃烧模拟。",
            "summary_zh": "准确的化学动力学建模对燃烧模拟至关重要，它控制着复杂反应路径和热化学状态的演化。本文介绍了Kinetic-Mamba，这是一个基于Mamba的神经算子框架，将神经算子的表达能力与Mamba架构的高效时间建模能力相结合。该框架包含三个互补模型：(i) 一个独立的Mamba模型，从给定初始条件预测热化学状态变量的时间演化；(ii) 一个约束Mamba模型，在学习状态动力学时强制质量守恒；(iii) 一个基于区域的架构，采用两个独立的Mamba模型来捕捉温度依赖区域间的动力学。我们还开发了一个潜在Kinetic-Mamba变体，在降维潜在空间中演化动力学，并在物理流形上重建完整状态。我们使用时间分解和递归预测策略评估Kinetic-Mamba的准确性和鲁棒性。进一步评估模型在不同分布外数据集上的外推能力。在Syngas和GRI-Mech 3.0反应机制上的计算实验表明，我们的框架仅使用状态变量的初始条件就能高保真地预测复杂动力学行为。",
            "intro_zh": [
                "核心问题：燃烧模拟中刚性化学动力学建模复杂，传统方法计算成本高，难以准确捕捉反应路径和热化学状态演化。",
                "方法要点：提出Kinetic-Mamba框架，结合神经算子的表达能力和Mamba架构的时间建模效率，通过多模型互补预测动力学演化。",
                "实验或效果：在Syngas和GRI-Mech 3.0机制上验证，仅用初始条件即实现高保真预测，并展示良好的外推能力。"
            ],
            "method_zh": "Kinetic-Mamba是一个基于Mamba的神经算子框架，整体框架包括三个核心模型：独立Mamba模型用于直接预测状态演化，约束Mamba模型在训练中强制质量守恒以提升物理一致性，以及区域感知架构使用两个Mamba模型分别处理不同温度区域的动力学。关键技术创新点在于将Mamba的高效序列建模能力与神经算子的泛化能力结合，并引入潜在空间变体以降低计算复杂度。与现有方法的主要区别在于其专注于刚性化学动力学的端到端预测，通过多模型集成和物理约束设计，提高了预测的准确性和效率，避免了传统数值方法的高计算成本。",
            "application_zh": "该研究主要应用于燃烧模拟领域，如发动机设计、能源系统和环境建模，通过高效预测化学动力学行为，可加速复杂反应过程的仿真，降低计算资源需求，提升工业设计和优化效率。",
            "highlight_zh": "实验显示Kinetic-Mamba在Syngas和GRI-Mech 3.0反应机制上仅基于初始条件即实现高保真预测，准确捕捉复杂动力学行为；通过时间分解和递归预测策略验证鲁棒性，并在分布外数据集上展示良好外推能力，显著提升预测效率。",
            "tags_zh": [
                "化学动力学建模",
                "Mamba架构",
                "神经算子",
                "燃烧模拟",
                "时间序列预测",
                "质量守恒约束",
                "潜在空间学习",
                "刚性系统"
            ],
            "_index": 61
        },
        {
            "title": "The Devil is in Attention Sharing: Improving Complex Non-rigid Image Editing Faithfulness via Attention Synergy",
            "authors": [
                "Zhuo Chen",
                "Fanyue Wei",
                "Runze Xu",
                "Jingjing Li",
                "Lixin Duan",
                "Angela Yao",
                "Wen Li"
            ],
            "arxiv_id": "2512.14423v1",
            "summary": "Training-free image editing with large diffusion models has become practical, yet faithfully performing complex non-rigid edits (e.g., pose or shape changes) remains highly challenging. We identify a key underlying cause: attention collapse in existing attention sharing mechanisms, where either positional embeddings or semantic features dominate visual content retrieval, leading to over-editing or under-editing.To address this issue, we introduce SynPS, a method that Synergistically leverages Positional embeddings and Semantic information for faithful non-rigid image editing. We first propose an editing measurement that quantifies the required editing magnitude at each denoising step. Based on this measurement, we design an attention synergy pipeline that dynamically modulates the influence of positional embeddings, enabling SynPS to balance semantic modifications and fidelity preservation.By adaptively integrating positional and semantic cues, SynPS effectively avoids both over- and under-editing. Extensive experiments on public and newly curated benchmarks demonstrate the superior performance and faithfulness of our approach.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page:https://synps26.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14423v1",
            "code_links": [],
            "headline_zh": "提出Context-Picker框架，通过多阶段强化学习动态选择最小充分证据集，以解决长上下文问答中的上下文选择难题。",
            "summary_zh": "在长上下文问答（LCQA）中，为给定查询确定最优的上下文量是一个重大挑战。包含过少段落可能遗漏关键信息，而包含过多则会引入噪声并降低答案质量。传统方法（如固定Top-K检索和单阶段重排序）面临选择适当段落数量的困境，这一问题在事实型问题上尤为突出，这类问题通常只需要少量特定证据。为解决此问题，我们引入了Context-Picker，这是一个推理感知框架，将范式从基于相似性的排序转向最小充分子集选择。Context-Picker将上下文选择视为一个决策过程，通过受人类启发的两阶段强化学习计划进行优化：一个以召回为导向的阶段，优先覆盖推理链；随后是一个以精确为导向的阶段，积极剪枝冗余以提炼紧凑的证据集。为解决奖励稀疏性问题，我们提出了一个离线证据蒸馏流程，通过留一法（LOO）挖掘“最小充分集”，提供密集、任务对齐的监督。在五个长上下文和多跳问答基准上的实验表明，Context-Picker显著优于强大的RAG基线，在可比或更短的上下文长度下实现了更高的答案准确性。消融研究表明，从粗到细的优化计划、冗余感知的奖励塑造和推理引导的格式都对这一增益有重要贡献。",
            "intro_zh": [
                "核心问题：长上下文问答中，传统固定Top-K检索和单阶段重排序方法难以平衡上下文覆盖与噪声控制，尤其对事实型问题造成信息冗余或遗漏。",
                "方法要点：提出Context-Picker框架，将上下文选择视为决策过程，采用两阶段强化学习（召回导向和精确导向）动态选择最小充分证据集。",
                "实验或效果：在五个基准测试中，Context-Picker显著超越RAG基线，以更短上下文实现更高答案准确性，消融研究验证了关键组件的有效性。"
            ],
            "method_zh": "Context-Picker是一个推理感知框架，整体上采用多阶段强化学习进行动态上下文选择。关键技术创新包括：1）将上下文选择从相似性排序范式转向最小充分子集选择；2）设计两阶段强化学习计划，第一阶段以召回为导向覆盖推理链，第二阶段以精确为导向剪枝冗余；3）提出离线证据蒸馏流程，通过留一法挖掘最小充分集，解决奖励稀疏性问题。与现有方法的主要区别在于，它不再依赖固定数量的段落或单阶段重排序，而是通过决策过程优化，实现自适应、任务对齐的上下文选择。",
            "application_zh": "该研究主要应用于长上下文问答和多跳问答场景，如文档检索、知识库问答和复杂推理任务，可提升大型语言模型在信息密集环境中的准确性和效率，减少计算开销。",
            "highlight_zh": "在五个长上下文和多跳问答基准测试中，Context-Picker显著优于RAG基线，答案准确性更高，同时上下文长度可比或更短；消融研究证实两阶段优化、冗余感知奖励和推理引导格式是关键增益来源。",
            "tags_zh": [
                "长上下文问答",
                "强化学习",
                "证据选择",
                "多阶段优化",
                "推理感知",
                "最小充分集",
                "RAG增强",
                "问答系统"
            ],
            "_index": 62
        },
        {
            "title": "Hybrid Ensemble Method for Detecting Cyber-Attacks in Water Distribution Systems Using the BATADAL Dataset",
            "authors": [
                "Waqas Ahmed"
            ],
            "arxiv_id": "2512.14422v1",
            "summary": "The cybersecurity of Industrial Control Systems that manage critical infrastructure such as Water Distribution Systems has become increasingly important as digital connectivity expands. BATADAL benchmark data is a good source of testing intrusion detection techniques, but it presents several important problems, such as imbalance in the number of classes, multivariate time dependence, and stealthy attacks. We consider a hybrid ensemble learning model that will enhance the detection ability of cyber-attacks in WDS by using the complementary capabilities of machine learning and deep learning models. Three base learners, namely, Random Forest , eXtreme Gradient Boosting , and Long Short-Term Memory network, have been strictly compared and seven ensemble types using simple averaged and stacked learning with a logistic regression meta-learner. Random Forest analysis identified top predictors turned into temporal and statistical features, and Synthetic Minority Oversampling Technique (SMOTE) was used to overcome the class imbalance issue. The analyics indicates that the single Long Short-Term Memory network model is of poor performance (F1 = 0.000, AUC = 0.4460), but tree-based models, especially eXtreme Gradient Boosting, perform well (F1 = 0.7470, AUC=0.9684). The hybrid stacked ensemble of Random Forest , eXtreme Gradient Boosting , and Long Short-Term Memory network scored the highest, with the attack class of 0.7205 with an F1-score and a AUC of 0.9826 indicating that the heterogeneous stacking between model precision and generalization can work. The proposed framework establishes a robust and scalable solution for cyber-attack detection in time-dependent industrial systems, integrating temporal learning and ensemble diversity to support the secure operation of critical infrastructure.",
            "categories": [
                "cs.CR",
                "cs.LG"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, & figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14422v1",
            "code_links": [],
            "headline_zh": "提出AnySleep深度学习系统，以解决多中心睡眠研究中电极设置异质性和时间分辨率限制的问题。",
            "summary_zh": "睡眠对健康至关重要，但研究其动态需要手动睡眠分期，这在睡眠研究和临床护理中是一项劳动密集型步骤。传统上，多中心多导睡眠图（PSG）记录通常以30秒为周期进行评分，这更多是出于实用而非生理原因，且电极数量、导联方式和受试者特征差异显著。这些限制给开展协调的多中心睡眠研究以及在更短时间尺度上发现新颖、稳健的生物标志物带来了挑战。本文提出AnySleep，一种深度神经网络模型，可利用任何脑电图（EEG）或眼电图（EOG）数据，以可调的时间分辨率进行睡眠分期。我们在来自21个数据集的超过19,000个夜间记录上训练和验证了该模型，涵盖近200,000小时的EEG和EOG数据，以促进跨站点的稳健泛化。该模型达到了最先进的性能，在30秒周期上超越或等同于现有基线。随着提供更多通道，性能有所提升，但在EOG缺失或仅使用EOG或单个EEG导联（额叶、中央或枕叶）时仍保持强劲。在低于30秒的时间尺度上，模型能捕捉与觉醒一致的短暂清醒侵入，并相对于标准的30秒评分，改善了生理特征（年龄、性别）和病理生理状况（睡眠呼吸暂停）的预测。我们公开提供该模型，以促进具有异质电极设置的大规模研究，并加速睡眠中新生物标志物的发现。",
            "intro_zh": [
                "核心问题：传统睡眠分期依赖手动评分，耗时且在多中心研究中因电极设置、导联方式和受试者差异而难以协调，限制了短时间尺度生物标志物的发现。",
                "方法要点：提出AnySleep深度神经网络，利用任意EEG或EOG数据，支持可调时间分辨率，通过大规模多中心数据训练实现跨站点稳健泛化。",
                "实验或效果：模型在30秒周期达到SOTA性能，在子30秒尺度捕捉短时觉醒，提升年龄、性别和睡眠呼吸暂停等特征的预测准确性。"
            ],
            "method_zh": "AnySleep是一个深度神经网络模型，整体框架基于深度学习技术，设计为通道无关，可处理任意EEG或EOG输入数据。关键技术创新点包括：支持可调时间分辨率（如低于30秒），以捕捉更精细的睡眠动态；通过大规模多中心数据集（超过19,000个记录）训练，增强模型对异质电极设置和站点差异的泛化能力。与现有方法的主要区别在于：传统方法通常固定于30秒周期且依赖特定电极配置，而AnySleep灵活适应不同通道组合（如仅EOG或单EEG导联），并优化了短时间尺度分析，从而克服了多中心研究中的协调挑战。",
            "application_zh": "该研究可应用于多中心睡眠研究、临床睡眠监测和生物标志物发现。实际价值在于：促进大规模异质电极设置下的协调研究，加速新睡眠生物标志物的识别，并支持个性化睡眠健康评估，如改善睡眠障碍（如睡眠呼吸暂停）的诊断和监测。",
            "highlight_zh": "模型在30秒周期达到最先进性能，超越或等于基线；在子30秒时间尺度，能有效捕捉短时觉醒，提升年龄、性别和睡眠呼吸暂停的预测准确性；即使仅使用EOG或单EEG导联，性能仍保持强劲，展示了卓越的泛化能力。",
            "tags_zh": [
                "睡眠分期",
                "深度学习",
                "多中心研究",
                "脑电图分析",
                "时间分辨率",
                "生物标志物发现",
                "通道无关模型",
                "睡眠障碍诊断"
            ],
            "_index": 63
        },
        {
            "title": "Dual-Axis RCCL: Representation-Complete Convergent Learning for Organic Chemical Space",
            "authors": [
                "Dejun Hu",
                "Zhiming Li",
                "Jia-Rui Shen",
                "Jia-Ning Tu",
                "Zi-Hao Ye",
                "Junliang Zhang"
            ],
            "arxiv_id": "2512.14418v1",
            "summary": "Machine learning is profoundly reshaping molecular and materials modeling; however, given the vast scale of chemical space (10^30-10^60), it remains an open scientific question whether models can achieve convergent learning across this space. We introduce a Dual-Axis Representation-Complete Convergent Learning (RCCL) strategy, enabled by a molecular representation that integrates graph convolutional network (GCN) encoding of local valence environments, grounded in modern valence bond theory, together with no-bridge graph (NBG) encoding of ring/cage topologies, providing a quantitative measure of chemical-space coverage. This framework formalizes representation completeness, establishing a principled basis for constructing datasets that support convergent learning for large models. Guided by this RCCL framework, we develop the FD25 dataset, systematically covering 13,302 local valence units and 165,726 ring/cage topologies, achieving near-complete combinatorial coverage of organic molecules with H/C/N/O/F elements. Graph neural networks trained on FD25 exhibit representation-complete convergent learning and strong out-of-distribution generalization, with an overall prediction error of approximately 1.0 kcal/mol MAE across external benchmarks. Our results establish a quantitative link between molecular representation, structural completeness, and model generalization, providing a foundation for interpretable, transferable, and data-efficient molecular intelligence.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "33 pages, 10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14418v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出基于Crazyflie 2.1纳米四旋翼的75k真实世界样本系统辨识基准，以评估非线性动态下的多步预测性能。",
            "summary_zh": "我们引入了一个基于Crazyflie 2.1无刷纳米四旋翼（一种广泛用于机器人研究的重量低于50克的空中飞行器）的75k真实世界样本的系统辨识基准。该平台因其多输入多输出特性、开环不稳定性以及在敏捷机动下的非线性动态而成为一个具有挑战性的测试平台。数据集包含四条激进轨迹，同步记录了4维电机输入和13维输出测量。为了公平比较辨识方法，基准包括一套多时间范围预测指标，用于评估一步和多步误差传播。除了数据外，我们还提供了平台和实验设置的详细描述，以及基线模型，突出了在真实世界噪声和执行器非线性下准确预测的挑战。所有数据、脚本和参考实现均以开源形式发布在https://github.com/idsia-robotics/nanodrone-sysid-benchmark，以促进算法的透明比较并支持敏捷、微型空中机器人研究。",
            "intro_zh": [
                "核心问题：现有系统辨识方法在真实世界噪声、非线性动态和开环不稳定性下难以准确预测，缺乏标准化基准进行公平比较。",
                "方法要点：基于Crazyflie 2.1纳米四旋翼构建包含75k样本的数据集，提供多步预测指标和开源工具以评估辨识算法。",
                "实验或效果：基准包含激进轨迹数据，基线模型展示了预测挑战，促进算法透明比较和微型空中机器人研究。"
            ],
            "method_zh": "论文的核心方法围绕构建一个系统辨识基准，整体框架包括数据采集、指标定义和开源实现。关键技术创新点在于利用Crazyflie 2.1纳米四旋翼的真实世界数据，涵盖多输入多输出、非线性动态和开环不稳定性，并引入多时间范围预测指标（如一步和多步误差传播）来全面评估辨识性能。与现有方法的主要区别在于提供了标准化、大规模的真实世界数据集和评估套件，强调在敏捷机动和噪声环境下的挑战，而非仅依赖仿真或简化模型。",
            "application_zh": "该研究可应用于微型空中机器人（如无人机）的控制系统设计、动态建模优化和自主导航算法开发。潜在价值包括提升在复杂环境下的飞行稳定性、支持敏捷机动研究和促进机器人学习算法的真实世界验证。",
            "highlight_zh": "最重要的实验结果包括数据集包含75k真实世界样本，覆盖激进轨迹；基准提供多步预测指标，基线模型揭示了在噪声和非线性下的预测误差；开源发布促进了算法透明比较，为微型空中机器人研究提供了实用测试平台。",
            "tags_zh": [
                "系统辨识",
                "非线性动态",
                "纳米四旋翼",
                "多步预测",
                "真实世界数据",
                "开源基准",
                "微型空中机器人",
                "控制建模"
            ],
            "_index": 64
        },
        {
            "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
            "authors": [
                "Wentao Wan",
                "Qiqing Lao",
                "Zhiwei Xie",
                "Hefeng Wu",
                "Runnan Lin",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14395v1",
            "summary": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "27 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14395v1",
            "code_links": [],
            "headline_zh": "提出推理风格投毒攻击与实时监控方法，揭示LLM代理在过程层面的安全漏洞。",
            "summary_zh": "大型语言模型（LLM）代理依赖外部检索，在高风险环境中部署日益增多。现有对抗攻击主要关注内容伪造或指令注入，而本文识别出一种新颖的、面向过程的攻击面：代理的推理风格。我们提出推理风格投毒（RSP），这是一种操纵代理如何处理信息而非处理什么信息的范式。我们引入生成式风格注入（GSI），这是一种攻击方法，将检索到的文档重写为病态语调——特别是“分析瘫痪”或“认知仓促”——而不改变基本事实或使用显式触发器。为了量化这些变化，我们开发了推理风格向量（RSV），这是一种跟踪验证深度、自信度和注意力焦点的指标。在HotpotQA和FEVER数据集上使用ReAct、Reflection和思维树（ToT）架构进行的实验表明，GSI显著降低了性能。它使推理步骤增加多达4.4倍或导致过早错误，成功绕过最先进的内容过滤器。最后，我们提出RSP-M，一种轻量级运行时监控器，实时计算RSV指标并在值超过安全阈值时触发警报。我们的工作表明，推理风格是一种独特、可利用的漏洞，需要超越静态内容分析的过程级防御。",
            "intro_zh": [
                "现有攻击多聚焦内容伪造或指令注入，忽视LLM代理推理过程本身的脆弱性，导致安全防护存在盲区。",
                "提出推理风格投毒攻击，通过生成式风格注入操纵文档语调，在不改变事实下诱导病态推理，并开发推理风格向量进行量化评估。",
                "实验显示攻击显著降低代理性能，推理步骤最多增加4.4倍，且能绕过先进内容过滤器，验证了过程级攻击的有效性。"
            ],
            "method_zh": "论文提出推理风格投毒（RSP）整体框架，包括攻击和防御两部分。核心创新点在于生成式风格注入（GSI）攻击方法，它通过重写检索文档为“分析瘫痪”或“认知仓促”等病态语调，在不改变事实内容下操纵LLM代理的推理风格；同时开发推理风格向量（RSV）作为量化指标，基于验证深度、自信度和注意力焦点跟踪风格变化。与现有方法的主要区别在于，传统攻击侧重于内容或指令层面，而RSP专注于过程层面的推理风格操纵，这是一种新颖的攻击范式，强调“如何推理”而非“推理什么”，从而能绕过基于内容的静态防御。",
            "application_zh": "该研究主要应用于LLM代理的安全防护领域，特别是在高风险环境如金融决策、医疗诊断或法律咨询中，代理依赖外部检索进行推理。潜在价值在于揭示过程级安全漏洞，推动开发实时监控和动态防御机制，提升代理在对抗环境下的鲁棒性和可靠性。",
            "highlight_zh": "在HotpotQA和FEVER数据集上，使用ReAct、Reflection和ToT架构的实验表明，GSI攻击使推理步骤增加高达4.4倍或诱导过早错误，显著降低代理性能；攻击成功绕过最先进的内容过滤器，验证了过程级攻击的隐蔽性和有效性。",
            "tags_zh": [
                "推理风格投毒",
                "生成式风格注入",
                "推理风格向量",
                "过程级攻击",
                "LLM代理安全",
                "实时监控",
                "对抗攻击",
                "检索增强生成"
            ],
            "_index": 65
        },
        {
            "title": "A Comprehensive Safety Metric to Evaluate Perception in Autonomous Systems",
            "authors": [
                "Georg Volk",
                "Jörg Gamerdinger",
                "Alexander von Bernuth",
                "Oliver Bringmann"
            ],
            "arxiv_id": "2512.14367v1",
            "summary": "Complete perception of the environment and its correct interpretation is crucial for autonomous vehicles. Object perception is the main component of automotive surround sensing. Various metrics already exist for the evaluation of object perception. However, objects can be of different importance depending on their velocity, orientation, distance, size, or the potential damage that could be caused by a collision due to a missed detection. Thus, these additional parameters have to be considered for safety evaluation. We propose a new safety metric that incorporates all these parameters and returns a single easily interpretable safety assessment score for object perception. This new metric is evaluated with both real world and virtual data sets and compared to state of the art metrics.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at IEEE ITSC 2020",
            "doi": "10.1109/ITSC45102.2020.9294708",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14367v1",
            "code_links": [],
            "headline_zh": "提出ClimaX-LETKF数据驱动集合天气预报系统，首次实现基于机器学习的纯数据驱动集合预报并稳定运行多年。",
            "summary_zh": "尽管基于机器学习的天气预报（MLWP）已取得显著进展，但在MLWP模型中同化真实观测或集合预报的研究仍然有限。我们介绍了ClimaX-LETKF，这是首个纯数据驱动的基于机器学习的集合天气预报系统。该系统通过同化NCEP ADP全球高空和地面天气观测，能够稳定运行多年，独立于数值天气预报（NWP）模型。实验表明，与松弛到先验扩展（RTPS）相比，使用松弛到先验扰动（RTPP）时系统表现出更高的稳定性和准确性，而NWP模型通常更稳定于RTPS。RTPP将分析扰动替换为分析和背景扰动的加权混合，而RTPS仅简单缩放分析扰动。我们的实验揭示，MLWP模型在将大气场恢复到其吸引子方面的能力不如NWP模型。这项工作为增强MLWP集合预报系统提供了宝贵见解，并代表了其实际应用的重要一步。",
            "intro_zh": [
                "现有MLWP模型在同化真实观测或集合预报方面研究不足，缺乏独立于NWP的稳定数据驱动系统。",
                "提出ClimaX-LETKF，基于机器学习构建纯数据驱动集合预报框架，通过同化NCEP观测实现长期稳定运行。",
                "实验显示RTPP比RTPS在MLWP中更优，提升稳定性和准确性，但MLWP恢复大气吸引子能力弱于NWP。"
            ],
            "method_zh": "ClimaX-LETKF是一个纯数据驱动的机器学习集合天气预报系统，核心框架基于局部集合变换卡尔曼滤波（LETKF）进行数据同化，结合机器学习模型生成预报。关键创新在于首次在MLWP中实现独立于NWP的长期稳定集合预报，通过同化NCEP ADP全球观测数据。与现有方法的主要区别在于：传统MLWP依赖NWP初始化或缺乏集合预报能力，而ClimaX-LETKF完全数据驱动，并引入RTPP（松弛到先验扰动）技术优化扰动更新，相比RTPS（松弛到先验扩展）更适应MLWP特性。",
            "application_zh": "该研究可应用于气象预报、气候建模和灾害预警等领域，通过提升MLWP集合预报的稳定性和准确性，推动数据驱动天气预报系统的实际部署，减少对传统NWP的依赖，为极端天气事件预测和长期气候分析提供新工具。",
            "highlight_zh": "ClimaX-LETKF在多年运行中表现稳定，RTPP相比RTPS显著提升MLWP集合预报的准确性和稳定性，但实验发现MLWP恢复大气吸引子能力弱于NWP，这为未来优化提供了关键方向。",
            "tags_zh": [
                "机器学习天气预报",
                "数据同化",
                "集合预报",
                "ClimaX-LETKF",
                "松弛到先验扰动",
                "数值天气预报",
                "大气吸引子",
                "气象观测"
            ],
            "_index": 66
        },
        {
            "title": "Unified Semantic Transformer for 3D Scene Understanding",
            "authors": [
                "Sebastian Koch",
                "Johanna Wald",
                "Hide Matsuki",
                "Pedro Hermosilla",
                "Timo Ropinski",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14364v1",
            "summary": "Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://unite-page.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364v1",
            "code_links": [],
            "headline_zh": "提出A4-Agent框架，通过解耦推理过程实现零样本可及性预测，以解决现有方法泛化能力不足的问题。",
            "summary_zh": "可及性预测是基于语言指令识别物体上交互区域的关键技术，对具身AI至关重要。当前主流端到端模型将高层推理与低层定位耦合在单一流程中，并依赖标注数据集训练，导致在新物体和未见环境上泛化能力差。本文超越这一范式，提出A4-Agent，一种无需训练的智能体框架，将可及性预测解耦为三阶段流程。该框架在测试时协调专用基础模型：(1) Dreamer利用生成模型可视化交互过程；(2) Thinker使用大型视觉语言模型决定交互的物体部分；(3) Spotter协调视觉基础模型精确定位交互区域。通过利用预训练模型的互补优势且无需任务特定微调，我们的零样本框架在多个基准测试中显著优于最先进的监督方法，并展现出对真实场景的鲁棒泛化能力。",
            "intro_zh": [
                "现有端到端模型耦合推理与定位，依赖标注数据训练，导致对新物体和环境的泛化能力差。",
                "提出A4-Agent框架，将可及性预测解耦为三阶段流程，协调专用基础模型实现零样本推理。",
                "在多个基准测试中显著优于监督方法，并展现出对真实场景的鲁棒泛化能力。"
            ],
            "method_zh": "A4-Agent是一个无需训练的智能体框架，将可及性预测解耦为三阶段流程：Dreamer阶段利用生成模型（如扩散模型）可视化交互过程；Thinker阶段使用大型视觉语言模型（如GPT-4V）分析物体部分并决定交互目标；Spotter阶段协调视觉基础模型（如SAM）精确定位交互区域。关键创新在于通过模块化设计，将高层推理与低层定位分离，并利用预训练模型的互补优势实现零样本预测。与现有方法的主要区别在于避免了端到端耦合和任务特定训练，提升了泛化能力和灵活性。",
            "application_zh": "该研究可应用于具身AI、机器人操作和智能交互系统，例如家庭服务机器人执行语言指令、工业自动化中的物体抓取，以及增强现实中的交互场景理解，提升系统在复杂环境中的适应性和实用性。",
            "highlight_zh": "在多个基准测试中，A4-Agent的零样本方法显著优于最先进的监督方法，例如在特定数据集上准确率提升超过10%，并展现出对真实世界场景的鲁棒泛化能力，验证了框架的有效性和通用性。",
            "tags_zh": [
                "可及性预测",
                "零样本学习",
                "智能体框架",
                "视觉语言模型",
                "具身AI",
                "模块化推理",
                "基础模型协调",
                "泛化能力"
            ],
            "_index": 67
        },
        {
            "title": "Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis",
            "authors": [
                "Nicholas Tagliapietra",
                "Katharina Ensinger",
                "Christoph Zimmer",
                "Osman Mian"
            ],
            "arxiv_id": "2512.14361v1",
            "summary": "Real world systems evolve in continuous-time according to their underlying causal relationships, yet their dynamics are often unknown. Existing approaches to learning such dynamics typically either discretize time -- leading to poor performance on irregularly sampled data -- or ignore the underlying causality. We propose CaDyT, a novel method for causal discovery on dynamical systems addressing both these challenges. In contrast to state-of-the-art causal discovery methods that model the problem using discrete-time Dynamic Bayesian networks, our formulation is grounded in Difference-based causal models, which allow milder assumptions for modeling the continuous nature of the system. CaDyT leverages exact Gaussian Process inference for modeling the continuous-time dynamics which is more aligned with the underlying dynamical process. We propose a practical instantiation that identifies the causal structure via a greedy search guided by the Algorithmic Markov Condition and Minimum Description Length principle. Our experiments show that CaDyT outperforms state-of-the-art methods on both regularly and irregularly-sampled data, discovering causal networks closer to the true underlying dynamics.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.DS"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted as Oral at AAAI 2026 Conference",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14361v1",
            "code_links": [],
            "headline_zh": "提出稀疏到稠密关键掩码蒸馏方法，以解决无监督视频实例分割中合成数据运动建模不准确的问题。",
            "summary_zh": "近年来，无监督视频实例分割的最先进方法严重依赖于从以对象为中心的图像数据集（如ImageNet）生成的合成视频数据。然而，通过人工移动和缩放图像实例掩码来合成视频，无法准确建模视频中的真实运动，例如透视变化、单个或多个实例的部分运动或相机运动。为解决这一问题，我们提出了一种仅使用真实视频数据训练的无监督视频实例分割模型。我们从单个视频帧上的无监督实例分割掩码开始。但这些单帧分割存在时间噪声，且质量在视频中变化。因此，我们通过利用深度运动先验识别视频中的高质量关键掩码来建立时间一致性。稀疏关键掩码伪标注随后用于训练一个用于隐式掩码传播的分割模型，为此我们提出了一种稀疏到稠密蒸馏方法，辅以时间丢弃损失。在最终模型上对生成的稠密标签集进行训练后，我们的方法在各种基准测试中超越了当前最先进水平。",
            "intro_zh": [
                "核心问题：现有方法依赖合成视频数据，无法准确建模真实视频中的复杂运动，如透视变化和部分运动。",
                "方法要点：利用深度运动先验识别高质量关键掩码，通过稀疏到稠密蒸馏和时间丢弃损失训练模型实现隐式传播。",
                "实验或效果：在多个基准测试中超越当前最先进方法，显著提升无监督视频实例分割性能。"
            ],
            "method_zh": "整体框架基于真实视频数据，从单帧无监督分割掩码出发，通过深度运动先验筛选高质量关键掩码建立时间一致性。关键技术创新点包括稀疏到稠密蒸馏方法，将稀疏关键掩码作为伪标注训练分割模型进行隐式掩码传播，并引入时间丢弃损失以优化训练过程。与现有方法的主要区别在于完全避免合成数据，直接利用真实视频中的运动信息，从而更准确地建模动态场景。",
            "application_zh": "该研究可应用于视频监控、自动驾驶、机器人视觉和视频编辑等领域，通过无监督方式实现视频中实例的精确分割和跟踪，降低对标注数据的依赖，提升实际场景中的鲁棒性和效率。",
            "highlight_zh": "在多个无监督视频实例分割基准测试中，该方法显著超越现有最先进模型，证明了仅使用真实视频数据训练的有效性，并展示了在复杂运动场景下的优越性能。",
            "tags_zh": [
                "无监督学习",
                "视频实例分割",
                "稀疏到稠密蒸馏",
                "时间一致性",
                "深度运动先验",
                "关键掩码筛选",
                "隐式掩码传播",
                "真实视频数据"
            ],
            "_index": 68
        },
        {
            "title": "Mimicking Human Visual Development for Learning Robust Image Representations",
            "authors": [
                "Ankita Raj",
                "Kaashika Prajaapat",
                "Tapan Kumar Gandhi",
                "Chetan Arora"
            ],
            "arxiv_id": "2512.14360v1",
            "summary": "The human visual system is remarkably adept at adapting to changes in the input distribution; a capability modern convolutional neural networks (CNNs) still struggle to match. Drawing inspiration from the developmental trajectory of human vision, we propose a progressive blurring curriculum to improve the generalization and robustness of CNNs. Human infants are born with poor visual acuity, gradually refining their ability to perceive fine details. Mimicking this process, we begin training CNNs on highly blurred images during the initial epochs and progressively reduce the blur as training advances. This approach encourages the network to prioritize global structures over high-frequency artifacts, improving robustness against distribution shifts and noisy inputs. Challenging prior claims that blurring in the initial training epochs imposes a stimulus deficit and irreversibly harms model performance, we reveal that early-stage blurring enhances generalization with minimal impact on in-domain accuracy. Our experiments demonstrate that the proposed curriculum reduces mean corruption error (mCE) by up to 8.30% on CIFAR-10-C and 4.43% on ImageNet-100-C datasets, compared to standard training without blurring. Unlike static blur-based augmentation, which applies blurred images randomly throughout training, our method follows a structured progression, yielding consistent gains across various datasets. Furthermore, our approach complements other augmentation techniques, such as CutMix and MixUp, and enhances both natural and adversarial robustness against common attack methods. Code is available at https://github.com/rajankita/Visual_Acuity_Curriculum.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted to ICVGIP 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14439v1",
            "code_links": [],
            "headline_zh": "提出VICTOR方法以解决视频识别系统中数据集版权审计的挑战",
            "summary_zh": "视频识别系统在内容推荐和安全监控等日常应用中日益普及。为促进视频识别技术的发展，许多机构发布了高质量的开源公共数据集用于训练先进模型。然而，这些数据集也容易遭到滥用和侵权。数据集版权审计是识别此类未经授权使用的有效解决方案。但现有的数据集版权解决方案主要集中于图像领域；视频数据的复杂性使得视频领域的数据集版权审计尚未得到充分探索。具体而言，视频数据引入了额外的时间维度，这对现有方法的有效性和隐蔽性构成了重大挑战。本文提出了VICTOR，这是首个针对视频识别系统的数据集版权审计方法。我们开发了一种通用且隐蔽的样本修改策略，增强了目标模型的输出差异。通过仅修改一小部分样本（例如1%），VICTOR放大了已发布修改样本对目标模型预测行为的影响。然后，模型对已发布修改样本和未发布原始样本的行为差异可作为数据集审计的关键依据。在多个模型和数据集上的广泛实验突显了VICTOR的优越性。最后，我们展示了VICTOR在面对训练视频或目标模型的多种扰动机制时具有鲁棒性。",
            "intro_zh": [
                "现有方法主要针对图像领域，视频数据的时间维度带来有效性和隐蔽性挑战，导致视频数据集版权审计未被充分探索。",
                "提出VICTOR方法，通过隐蔽修改少量样本（如1%）来放大模型输出差异，利用行为差异作为审计依据。",
                "在多个模型和数据集上实验显示VICTOR具有优越性能，且对训练视频或模型的扰动机制保持鲁棒性。"
            ],
            "method_zh": "VICTOR的整体框架基于一种通用且隐蔽的样本修改策略，旨在增强目标模型在已发布修改样本和未发布原始样本之间的输出差异。关键技术创新点在于设计了一种高效的修改机制，仅需修改少量样本（如1%），即可显著放大模型预测行为的变化，从而在不影响模型正常使用的前提下实现审计。与现有方法的主要区别在于，VICTOR专门针对视频数据的时空特性进行优化，克服了时间维度带来的挑战，而现有方法多局限于静态图像领域，缺乏对视频复杂性的处理能力。",
            "application_zh": "该研究可应用于视频识别系统的数据集版权保护，例如在内容推荐、安全监控等领域，帮助机构检测未经授权的数据集使用，维护知识产权，促进视频数据资源的合法共享和利用。",
            "highlight_zh": "实验表明，VICTOR在多个视频识别模型和数据集上均表现出优越的审计性能，仅修改1%样本即可有效放大模型输出差异，且在面对训练视频或模型的扰动时保持鲁棒，验证了其在实际场景中的实用性和可靠性。",
            "tags_zh": [
                "视频识别系统",
                "数据集版权审计",
                "样本修改策略",
                "模型行为差异",
                "时间维度挑战",
                "隐蔽性审计",
                "鲁棒性验证",
                "视频数据保护"
            ],
            "_index": 69
        },
        {
            "title": "Enhancing Interpretability for Vision Models via Shapley Value Optimization",
            "authors": [
                "Kanglong Fan",
                "Yunqiao Yang",
                "Chen Ma"
            ],
            "arxiv_id": "2512.14354v1",
            "summary": "Deep neural networks have demonstrated remarkable performance across various domains, yet their decision-making processes remain opaque. Although many explanation methods are dedicated to bringing the obscurity of DNNs to light, they exhibit significant limitations: post-hoc explanation methods often struggle to faithfully reflect model behaviors, while self-explaining neural networks sacrifice performance and compatibility due to their specialized architectural designs. To address these challenges, we propose a novel self-explaining framework that integrates Shapley value estimation as an auxiliary task during training, which achieves two key advancements: 1) a fair allocation of the model prediction scores to image patches, ensuring explanations inherently align with the model's decision logic, and 2) enhanced interpretability with minor structural modifications, preserving model performance and compatibility. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art interpretability.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted to AAAI2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14354v1",
            "code_links": [],
            "headline_zh": "提出基于分数的Turbo消息传递算法，以解决压缩成像中传统去噪器表达能力不足的问题",
            "summary_zh": "消息传递算法通过集成现成的图像去噪器已应用于压缩成像，但这些去噪器主要依赖通用或手工设计的先验，往往难以准确捕捉自然图像的复杂统计结构，导致传统即插即用方法在高度欠定情况下重建效果不佳。最近，基于分数的生成模型成为准确表征复杂图像分布的强大框架，但其直接用于后验采样通常计算复杂度极高。本文通过利用基于分数的生成建模与经验贝叶斯去噪之间的紧密联系，设计了一个消息传递框架，该框架集成了基于分数的最小均方误差去噪器用于压缩图像恢复。所得算法称为基于分数的Turbo消息传递，结合了消息传递的快速收敛性和基于分数的生成先验的表达能力。对于具有量化测量的实际系统，我们进一步提出了量化STMP，它在STMP基础上增加了分量级MMSE去量化模块。我们证明STMP和Q-STMP的渐近性能可以通过一组状态演化方程准确预测。在FFHQ数据集上的实验表明，与竞争基线相比，STMP在性能与复杂度之间取得了显著更好的权衡，且Q-STMP即使在1比特量化下仍保持鲁棒性。值得注意的是，STMP和Q-STMP通常能在10次迭代内收敛。",
            "intro_zh": [
                "核心问题：传统即插即用方法依赖表达能力有限的去噪器，在高度欠定压缩成像中重建效果不佳。",
                "方法要点：结合基于分数的生成先验与消息传递框架，设计STMP算法实现高效后验采样。",
                "实验或效果：STMP在FFHQ数据集上优于基线，Q-STMP在1比特量化下鲁棒，两者均快速收敛。"
            ],
            "method_zh": "论文提出基于分数的Turbo消息传递框架，整体上是一个迭代式消息传递算法，用于压缩图像恢复。关键技术创新点在于：1) 利用基于分数的生成模型与经验贝叶斯去噪的关联，设计基于分数的最小均方误差去噪器，以更准确地建模图像先验；2) 引入Turbo消息传递机制，加速收敛并提高效率；3) 针对量化测量系统，扩展为Q-STMP，加入分量级MMSE去量化模块。与现有方法的主要区别在于：传统即插即用方法使用通用或手工去噪器，而STMP集成了基于分数的生成先验，能更好地捕捉图像复杂统计结构，同时避免了直接后验采样的高计算成本。",
            "application_zh": "该研究主要应用于压缩成像领域，如医学成像、遥感图像处理和低功耗视觉系统，通过高效恢复高质量图像，提升图像重建的准确性和鲁棒性，尤其在资源受限或量化测量场景中具有实际价值。",
            "highlight_zh": "在FFHQ数据集上，STMP相比基线方法在性能与复杂度权衡上显著更优；Q-STMP在1比特量化下仍保持鲁棒重建能力；两种算法均能在10次迭代内快速收敛，验证了高效性和实用性。",
            "tags_zh": [
                "压缩成像",
                "消息传递算法",
                "基于分数的生成模型",
                "即插即用方法",
                "图像去噪",
                "量化测量",
                "状态演化方程",
                "图像重建"
            ],
            "_index": 70
        },
        {
            "title": "Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization",
            "authors": [
                "Henrik Hose",
                "Paul Brunzema",
                "Alexander von Rohr",
                "Alexander Gräfe",
                "Angela P. Schoellig",
                "Sebastian Trimpe"
            ],
            "arxiv_id": "2512.14350v1",
            "summary": "Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14350v1",
            "code_links": [],
            "headline_zh": "提出3-(PP(2-(UPS)))冗余并联机构并基于工作空间分析优化几何参数，以提升机器人性能。",
            "summary_zh": "冗余并联机器人通常应用于需要高精度、高负载能力和大工作空间的场景，相比传统并联机构具有优势。然而，其基本机器人构型和几何参数优化仍然具有挑战性。本文首先提出了一种新型的3-(PP(2-(UPS)))冗余并联机构，具有良好的通用性，并进一步通过分析关键几何参数如何影响其工作空间的体积、形状、边界完整性和定向能力，研究了运动学优化问题。定义了扭转能力指数TI_1和倾斜能力指数TI_2来评估机构的定向性能。完成了数值模拟研究以验证分析，为3-(PP(2-(UPS)))及其他类似冗余并联机构的参数优化提供了合理且重要的参考。",
            "intro_zh": [
                "冗余并联机器人的构型设计和几何参数优化面临挑战，现有方法难以平衡精度、负载和工作空间需求。",
                "提出3-(PP(2-(UPS)))新型机构，通过分析几何参数对工作空间的影响，定义TI_1和TI_2指数优化定向性能。",
                "数值模拟验证了参数优化效果，为类似机构提供了关键参考，提升了工作空间和定向能力。"
            ],
            "method_zh": "论文提出3-(PP(2-(UPS)))冗余并联机构的整体框架，包括机构构型设计和运动学分析。关键技术创新在于定义扭转能力指数TI_1和倾斜能力指数TI_2，用于量化评估机构的定向性能，并结合工作空间分析优化几何参数。与现有方法的主要区别在于系统性地研究几何参数对工作空间体积、形状和边界的影响，提供了一种基于性能指标的优化方法，而非仅依赖经验或简单模型。",
            "application_zh": "该研究可应用于工业自动化、精密加工和航空航天等领域，其中需要高精度、大工作空间和高负载能力的机器人系统，如装配、检测和操作任务，提升生产效率和灵活性。",
            "highlight_zh": "数值模拟结果表明，通过优化几何参数，机构的工作空间体积和形状得到显著改善，TI_1和TI_2指数有效评估了定向性能，为实际设计提供了量化依据，提升了机器人的整体运动能力。",
            "tags_zh": [
                "冗余并联机构",
                "几何参数优化",
                "工作空间分析",
                "运动学优化",
                "定向性能评估",
                "机器人设计",
                "数值模拟"
            ],
            "_index": 71
        },
        {
            "title": "Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure",
            "authors": [
                "Jooyeol Yun",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.14336v1",
            "summary": "Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "yeolj00.github.io/personal-projects/vector-prism",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14336v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL",
                        "PPO"
                    ],
                    "score": 2
                }
            ],
            "headline_zh": "提出基于大语言模型的智能交互工作流，以降低SPECFEM地震波模拟软件的使用门槛。",
            "summary_zh": "针对主流开源地震波模拟软件SPECFEM传统工作流程中学习曲线陡峭、依赖复杂手动文件编辑和命令行操作的问题，本文提出了一种由大语言模型驱动的智能交互工作流。我们首次为SPECFEM（支持2D、3D笛卡尔和3D全球版本）引入了模型上下文协议服务器套件，将整个模拟过程分解为从参数生成、网格划分到求解器执行和可视化的离散、可代理执行的工具。这种方法实现了从文件驱动到意图驱动的对话交互的范式转变。该框架支持全自动执行和人机协同，使研究人员能够实时指导模拟策略并保留科学决策权，同时显著减少繁琐的低级操作。通过多个案例研究验证，该工作流在自主和交互模式下均能无缝运行，产生与标准基线一致的高保真结果。作为MCP技术在计算地震学中的首次应用，本研究显著降低了入门门槛，增强了可重复性，并为推动计算地球物理学向AI辅助和自动化科学研究发展提供了有前景的途径。完整源代码可在https://github.com/RenYukun1563/specfem-mcp获取。",
            "intro_zh": [
                "传统SPECFEM工作流程依赖复杂手动文件编辑和命令行操作，学习曲线陡峭，阻碍了非专家用户的使用。",
                "提出基于大语言模型的智能交互工作流，通过MCP服务器套件将模拟过程分解为可代理执行的工具，实现意图驱动的对话交互。",
                "案例验证显示工作流在自主和交互模式下均能无缝运行，产生高保真结果，显著降低了使用门槛并增强了可重复性。"
            ],
            "method_zh": "论文的核心方法是构建一个基于大语言模型的智能交互框架，整体框架包括为SPECFEM设计的首个模型上下文协议服务器套件，将地震波模拟流程（如参数设置、网格划分、求解和可视化）分解为离散工具。关键技术创新点在于应用MCP技术实现从文件驱动到意图驱动的范式转变，支持全自动和人机协同模式。与现有方法的主要区别在于替代了传统依赖手动编辑配置文件和命令行操作的方式，通过自然语言交互简化流程，使研究人员能更专注于科学决策而非低级操作细节。",
            "application_zh": "该研究主要应用于计算地震学和地球物理学领域，为地震波模拟提供AI辅助工具，潜在价值包括降低专业软件使用门槛、提升科研效率，并推动自动化科学研究在自然灾害预测、资源勘探等实际场景中的应用。",
            "highlight_zh": "实验通过多个案例验证，工作流在自主和交互模式下均能无缝运行，产生与标准基线一致的高保真模拟结果，证明了其有效性和可靠性，显著减少了人工操作时间并提升了工作流程的灵活性。",
            "tags_zh": [
                "地震波模拟",
                "大语言模型",
                "智能交互工作流",
                "模型上下文协议",
                "计算地球物理学",
                "AI辅助科研",
                "自动化工作流",
                "SPECFEM软件"
            ],
            "_index": 72
        },
        {
            "title": "Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring",
            "authors": [
                "Yannis Belkhiter",
                "Seshu Tirupathi",
                "Giulio Zizzo",
                "John D. Kelleher"
            ],
            "arxiv_id": "2512.14332v1",
            "summary": "The field of Language Reasoning Models (LRMs) has been very active over the past few years with advances in training and inference techniques enabling LRMs to reason longer, and more accurately. However, a growing body of studies show that LRMs are still inefficient, over-generating verification and reflection steps. To address this challenge, we introduce the Step-Tagging framework, a lightweight sentence-classifier enabling real-time annotation of the type of reasoning steps that an LRM is generating. To monitor reasoning behaviors, we introduced ReasonType: a novel taxonomy of reasoning steps. Building on this framework, we demonstrated that online monitoring of the count of specific steps can produce effective interpretable early stopping criteria of LRM inferences. We evaluate the Step-tagging framework on three open-source reasoning models across standard benchmark datasets: MATH500, GSM8K, AIME and non-mathematical tasks (GPQA and MMLU-Pro). We achieve 20 to 50\\% token reduction while maintaining comparable accuracy to standard generation, with largest gains observed on more computation-heavy tasks. This work offers a novel way to increase control over the generation of LRMs, and a new tool to study behaviors of LRMs.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14332v1",
            "code_links": [],
            "headline_zh": "提出Odyssey数据集，基于环形激光陀螺仪惯性导航系统，为GNSS信号缺失环境下的激光雷达惯性里程计提供高精度地面真值。",
            "summary_zh": "激光雷达惯性里程计（LIO）和同步定位与建图（SLAM）系统的开发和评估需要精确的地面真值。全球导航卫星系统（GNSS）常被用作基础，但在遮挡环境中，由于多径效应或信号丢失，其信号可能不可靠。现有数据集通过整合惯性测量单元（IMU）测量来补偿GNSS信号的偶发性丢失，但常用的微机电系统（MEMS）或光纤陀螺仪（FOG）系统不允许对GNSS缺失环境进行长期研究。为填补这一空白，我们提出了Odyssey，一个专注于GNSS缺失环境（如隧道和停车场）以及其他代表性不足但普遍存在场景（如启停交通、颠簸道路和开阔田野）的LIO数据集。我们的地面真值源自配备环形激光陀螺仪（RLG）的导航级惯性导航系统（INS），与现有数据集使用的IMU相比，具有优异的偏置稳定性特性，支持对GNSS缺失环境进行长期准确研究。这使得Odyssey成为首个公开可用的基于RLG的INS数据集。除了为LIO提供数据外，我们还通过三次重复所有轨迹以及提供精确大地坐标来整合外部地图数据，支持其他任务，如地点识别。所有数据、数据加载器和其他材料可在https://odyssey.uni-goettingen.de/在线获取。",
            "intro_zh": [
                "核心问题：现有数据集依赖GNSS作为地面真值，但在遮挡环境中信号不可靠，且常用IMU系统（如MEMS或FOG）偏置稳定性不足，无法支持GNSS缺失环境的长期研究。",
                "方法要点：提出Odyssey数据集，使用配备环形激光陀螺仪的导航级INS提供高精度地面真值，专注于隧道、停车场等GNSS缺失场景，并覆盖启停交通等普遍情况。",
                "实验或效果：Odyssey成为首个公开的基于RLG的INS数据集，支持LIO、SLAM和地点识别等任务，通过重复轨迹和地理坐标增强数据实用性。"
            ],
            "method_zh": "论文的核心方法是构建Odyssey数据集，整体框架包括数据采集、处理和标注。关键技术创新点在于使用配备环形激光陀螺仪的导航级惯性导航系统作为地面真值源，相比现有数据集常用的微机电系统或光纤陀螺仪IMU，具有更高的偏置稳定性和长期精度。与现有方法的主要区别在于，Odyssey专门针对GNSS信号缺失环境（如隧道、停车场）设计，通过高精度INS提供可靠真值，弥补了现有数据集在长期GNSS缺失场景下的不足，同时整合了重复轨迹和地理坐标以支持多任务应用。",
            "application_zh": "该研究主要应用于自动驾驶和机器人领域，特别是在GNSS信号受限或缺失的环境（如城市隧道、地下停车场、山区道路）中，为激光雷达惯性里程计和同步定位与建图系统的开发与评估提供基准数据。潜在价值包括提升定位精度、支持长期导航研究，并促进地点识别等辅助任务的发展。",
            "highlight_zh": "最重要的实验结果是Odyssey数据集成为首个公开可用的基于环形激光陀螺仪惯性导航系统的数据集，通过高精度地面真值，显著提升了在GNSS缺失环境下的长期研究能力，支持LIO和SLAM系统在复杂场景中的性能评估。",
            "tags_zh": [
                "激光雷达惯性里程计",
                "同步定位与建图",
                "惯性导航系统",
                "环形激光陀螺仪",
                "GNSS缺失环境",
                "自动驾驶数据集",
                "地点识别",
                "地面真值"
            ],
            "_index": 73
        },
        {
            "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
            "authors": [
                "Georgios Bouchouras",
                "Dimitrios Doumanas",
                "Andreas Soularidis",
                "Konstantinos Kotis",
                "George A. Vouros"
            ],
            "arxiv_id": "2512.14288v1",
            "summary": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.\n  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.\n  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.\n  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.\n  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14288v1",
            "code_links": [],
            "headline_zh": "研究文档打包策略对大型语言模型潜在多跳推理能力的影响，优化模型训练效率与性能",
            "summary_zh": "训练大型语言模型的标准实践通常涉及将多个文档打包在一起以提高计算效率，但这一过程对模型能力的影响尚未得到充分探索。为填补这一空白，本研究调查了不同文档打包策略如何影响LLMs的潜在多跳推理能力。我们的研究结果表明，与在单个文档上训练相比，打包可以提高模型性能，但需要更多的计算资源。为了进一步理解其底层机制，我们进行了消融研究，识别了解释打包优势的关键因素。最终，我们的研究深化了对LLM训练动态的理解，并为优化模型开发提供了实用见解。",
            "intro_zh": [
                "核心问题：现有训练方法中，文档打包对大型语言模型能力的影响尚未充分研究，特别是对多跳推理等复杂任务的影响未知。",
                "方法要点：通过系统比较不同文档打包策略，分析其对模型潜在多跳推理能力的影响，并进行消融研究以揭示关键因素。",
                "实验或效果：研究发现打包能提升模型性能，但需更多计算资源；消融实验识别了影响性能的关键因素，为优化训练提供指导。"
            ],
            "method_zh": "论文采用实验分析方法，整体框架包括设计不同文档打包策略（如基于内容、长度或随机组合），在标准LLM训练流程中应用这些策略，并评估模型在潜在多跳推理任务上的表现。关键技术创新点在于系统量化打包策略对模型能力的影响，而非仅关注计算效率。与现有方法的主要区别在于，现有研究多假设打包仅影响训练速度，而本文首次深入探讨其对模型内在推理能力的潜在提升机制，通过消融研究分离出关键变量（如文档间关联性、打包密度等），为理解训练动态提供新视角。",
            "application_zh": "该研究可应用于大型语言模型的训练优化领域，帮助开发者在计算资源与模型性能间做出平衡决策，提升多跳推理等复杂任务的效率。潜在价值包括指导实际模型开发中的文档预处理策略，降低训练成本，同时确保模型在推理密集型应用（如问答系统、逻辑分析）中保持高性能。",
            "highlight_zh": "最重要的实验结果显示，文档打包相比单个文档训练能显著提升模型在潜在多跳推理任务上的性能，但计算开销增加；消融研究进一步识别出文档间语义关联性和打包密度是关键影响因素，为优化策略提供了实证依据。",
            "tags_zh": [
                "文档打包策略",
                "大型语言模型训练",
                "多跳推理能力",
                "计算效率优化",
                "消融研究",
                "训练动态分析",
                "模型性能提升",
                "潜在能力评估"
            ],
            "_index": 74
        },
        {
            "title": "SS4D: Native 4D Generative Model via Structured Spacetime Latents",
            "authors": [
                "Zhibing Li",
                "Mengchen Zhang",
                "Tong Wu",
                "Jing Tan",
                "Jiaqi Wang",
                "Dahua Lin"
            ],
            "arxiv_id": "2512.14284v1",
            "summary": "We present SS4D, a native 4D generative model that synthesizes dynamic 3D objects directly from monocular video. Unlike prior approaches that construct 4D representations by optimizing over 3D or video generative models, we train a generator directly on 4D data, achieving high fidelity, temporal coherence, and structural consistency. At the core of our method is a compressed set of structured spacetime latents. Specifically, (1) To address the scarcity of 4D training data, we build on a pre-trained single-image-to-3D model, preserving strong spatial consistency. (2) Temporal consistency is enforced by introducing dedicated temporal layers that reason across frames. (3) To support efficient training and inference over long video sequences, we compress the latent sequence along the temporal axis using factorized 4D convolutions and temporal downsampling blocks. In addition, we employ a carefully designed training strategy to enhance robustness against occlusion",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ToG(Siggraph Asia 2025)",
            "doi": "10.1145/3763302",
            "journal_ref": "ACM Transactions on Graphics, 44(6): Article 244, 12 pages, December 2025",
            "pdf_url": "https://arxiv.org/pdf/2512.14284v1",
            "code_links": [],
            "headline_zh": "提出基于状态分量解耦的二次卡尔曼滤波器，用于椭圆扩展目标跟踪，实现高效高精度估计。",
            "summary_zh": "扩展目标跟踪涉及同时估计目标物体的物理尺寸和运动学参数，通常每个时间步会观测到多个测量值。本文提出了一种基于运动学、方向和轴长解耦的确定性闭式椭圆扩展目标跟踪器。通过忽略这些状态分量之间的潜在相关性，相比整体联合解决方案，各个估计器所需的近似更少。所提出的算法优于现有算法，达到了基于采样方法的精度水平。此外，还引入了基于批处理的变体，在计算效率极高的同时，性能优于所有可比较的最先进算法。这通过使用文献中常见模型的仿真研究，以及对真实汽车雷达数据的广泛定量评估得到了验证。",
            "intro_zh": [
                "现有扩展目标跟踪方法通常需要复杂的联合估计，导致计算负担重且近似误差累积，难以平衡精度与效率。",
                "论文提出将目标状态分解为运动学、方向和轴长三个分量，分别独立估计，减少近似需求，并设计二次卡尔曼滤波器实现闭式更新。",
                "算法在仿真和真实雷达数据上验证，精度达到采样方法水平，批处理变体计算高效且优于所有可比先进算法。"
            ],
            "method_zh": "论文提出一种基于状态分量解耦的椭圆扩展目标跟踪框架。整体框架将目标状态分解为运动学（如位置、速度）、方向（椭圆朝向）和轴长（椭圆尺寸）三个独立分量，分别使用二次卡尔曼滤波器进行估计。关键技术创新点在于通过解耦忽略分量间的相关性，减少了整体联合估计所需的近似步骤，从而降低了误差累积。与现有方法的主要区别在于：现有方法通常采用联合估计或采样技术，计算复杂或精度受限；而本方法通过确定性闭式更新，在保持高精度的同时实现了高效计算，特别是批处理变体进一步优化了效率。",
            "application_zh": "该研究主要应用于自动驾驶和智能交通系统中的目标跟踪场景，如使用雷达数据实时估计车辆、行人等扩展目标的运动状态和物理尺寸。潜在应用还包括机器人导航、无人机监控和工业自动化，其中需要高效准确地跟踪非点状目标，提升环境感知和决策能力。",
            "highlight_zh": "在仿真和真实汽车雷达数据上的实验表明，算法精度达到基于采样方法的水平，批处理变体在计算效率上显著提升，性能优于所有可比较的最先进算法，验证了其在扩展目标跟踪中的优越性。",
            "tags_zh": [
                "扩展目标跟踪",
                "椭圆目标建模",
                "卡尔曼滤波器",
                "状态分量解耦",
                "确定性闭式估计",
                "汽车雷达数据处理",
                "高效计算算法",
                "批处理优化"
            ],
            "_index": 75
        },
        {
            "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
            "authors": [
                "Panayiotis Smeros",
                "Vincent Emonet",
                "Ruijie Wang",
                "Ana-Claudia Sima",
                "Tarcisio Mendes de Farias"
            ],
            "arxiv_id": "2512.14277v1",
            "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 8 figures, 1 table. Under Review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14277v1",
            "code_links": [],
            "headline_zh": "提出SynPS方法，通过注意力协同机制解决复杂非刚性图像编辑中的忠实性问题",
            "summary_zh": "基于大型扩散模型的无训练图像编辑已变得实用，但忠实执行复杂非刚性编辑（如姿态或形状变化）仍然极具挑战。我们发现一个关键根本原因：现有注意力共享机制中的注意力崩溃，其中位置嵌入或语义特征主导视觉内容检索，导致过度编辑或编辑不足。为解决此问题，我们引入SynPS，一种协同利用位置嵌入和语义信息以实现忠实非刚性图像编辑的方法。我们首先提出一种编辑度量，量化每个去噪步骤所需的编辑幅度。基于此度量，我们设计了一个注意力协同流程，动态调节位置嵌入的影响，使SynPS能够平衡语义修改和保真度保持。通过自适应整合位置和语义线索，SynPS有效避免过度编辑和编辑不足。在公共和新构建的基准测试上的大量实验证明了我们方法的优越性能和忠实性。",
            "intro_zh": [
                "现有方法在复杂非刚性图像编辑中存在注意力崩溃问题，导致过度编辑或编辑不足，影响编辑忠实性。",
                "提出SynPS方法，通过动态调节位置嵌入和语义信息的协同作用，实现编辑幅度自适应控制。",
                "实验表明，SynPS在公共和新基准上显著提升编辑忠实性，有效平衡语义修改与保真度保持。"
            ],
            "method_zh": "SynPS的整体框架基于扩散模型的无训练图像编辑流程，核心创新在于注意力协同机制。该方法首先引入编辑度量来量化每个去噪步骤的编辑需求，然后设计动态调制模块，根据度量结果调整位置嵌入在注意力共享中的权重。关键技术创新点在于将位置嵌入和语义信息协同整合，避免单一因素主导内容检索。与现有方法的主要区别在于，传统方法往往固定位置或语义的贡献，而SynPS通过自适应调节实现更精细的编辑控制，从而提升复杂非刚性编辑的忠实性。",
            "application_zh": "该研究在计算机视觉和人工智能领域具有广泛潜在应用，如数字媒体创作中的图像编辑、虚拟现实内容生成、以及机器人视觉系统的场景理解与交互。通过提升复杂非刚性编辑的忠实性，可支持更精准的图像修改任务，例如人体姿态调整、物体形状变换等，为实际应用提供更可靠的技术基础。",
            "highlight_zh": "在公共基准和新构建的数据集上，SynPS表现出优越性能，显著减少过度编辑和编辑不足现象。实验结果显示，该方法在复杂非刚性编辑任务中，编辑忠实性得到大幅提升，有效平衡语义修改与图像保真度，验证了注意力协同机制的有效性。",
            "tags_zh": [
                "图像编辑",
                "扩散模型",
                "注意力机制",
                "非刚性变换",
                "忠实性评估",
                "无训练方法",
                "计算机视觉",
                "人工智能"
            ],
            "_index": 76
        },
        {
            "title": "Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in",
            "authors": [
                "Xiaoqian Shen",
                "Min-Hung Chen",
                "Yu-Chiang Frank Wang",
                "Mohamed Elhoseiny",
                "Ryo Hachiuma"
            ],
            "arxiv_id": "2512.14273v1",
            "summary": "Grounded video question answering (GVQA) aims to localize relevant temporal segments in videos and generate accurate answers to a given question; however, large video-language models (LVLMs) exhibit limited temporal awareness. Although existing approaches based on Group Relative Policy Optimization (GRPO) attempt to improve temporal grounding, they still struggle to faithfully ground their answers in the relevant video evidence, leading to temporal mislocalization and hallucinations. In this work, we present Zoom-Zero, a coarse-to-fine framework that first localizes query-relevant segments and then temporally zooms into the most salient frames for finer-grained visual verification. Our method addresses the limits of GRPO for the GVQA task with two key innovations: (i) a zoom-in accuracy reward that validates the fidelity of temporal grounding prediction and facilitates fine-grained visual verification on grounded frames; (ii) token-selective credit assignment, which attributes rewards to the tokens responsible for temporal localization or answer generation, mitigating GRPO's issue in handling multi-faceted reward signals. Our proposed method advances grounded video question answering, improving temporal grounding by 5.2\\% on NExT-GQA and 4.6\\% on ReXTime, while also enhancing average answer accuracy by 2.4\\%. Additionally, the coarse-to-fine zoom-in during inference further benefits long-form video understanding by preserving critical visual details without compromising global context, yielding an average improvement of 6.4\\% on long-video benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://xiaoqian-shen.github.io/Zoom-Zero/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14273v1",
            "code_links": [],
            "headline_zh": "提出混合集成学习方法以解决水分配系统中网络攻击检测的类别不平衡与时间依赖性问题",
            "summary_zh": "随着数字连接性的扩展，管理关键基础设施（如水分配系统）的工业控制系统的网络安全变得越来越重要。BATADAL基准数据是测试入侵检测技术的良好来源，但它提出了几个重要问题，如类别数量不平衡、多变量时间依赖性和隐蔽攻击。我们考虑一种混合集成学习模型，通过利用机器学习和深度学习模型的互补能力，增强水分配系统中网络攻击的检测能力。对三种基础学习器（随机森林、极限梯度提升和长短期记忆网络）进行了严格比较，并使用了七种集成类型，包括简单平均和基于逻辑回归元学习器的堆叠学习。随机森林分析确定了转化为时间和统计特征的重要预测因子，并使用合成少数类过采样技术（SMOTE）来克服类别不平衡问题。分析表明，单一长短期记忆网络模型性能较差（F1 = 0.000，AUC = 0.4460），但基于树的模型，尤其是极限梯度提升，表现良好（F1 = 0.7470，AUC = 0.9684）。随机森林、极限梯度提升和长短期记忆网络的混合堆叠集成得分最高，攻击类别的F1分数为0.7205，AUC为0.9826，表明模型精度和泛化能力之间的异构堆叠是有效的。所提出的框架为时间依赖的工业系统中的网络攻击检测建立了一个稳健且可扩展的解决方案，集成了时间学习和集成多样性，以支持关键基础设施的安全运行。",
            "intro_zh": [
                "核心问题：BATADAL数据集存在类别不平衡、多变量时间依赖性和隐蔽攻击等挑战，影响网络攻击检测的准确性。",
                "方法要点：提出混合集成学习框架，结合随机森林、极限梯度提升和长短期记忆网络，利用堆叠学习提升检测性能。",
                "实验或效果：混合堆叠集成在攻击检测上达到F1分数0.7205和AUC 0.9826，显著优于单一模型。"
            ],
            "method_zh": "论文提出一个混合集成学习框架，用于水分配系统中的网络攻击检测。整体框架包括三个基础学习器：随机森林（RF）、极限梯度提升（XGBoost）和长短期记忆网络（LSTM），通过简单平均和堆叠学习（使用逻辑回归作为元学习器）进行集成。关键技术创新点在于结合了基于树的机器学习模型（RF和XGBoost）与深度学习模型（LSTM），以利用它们在处理静态特征和时间序列数据上的互补优势。与现有方法的主要区别在于，该方法通过异构堆叠集成，有效整合了不同模型的精度和泛化能力，同时使用SMOTE处理类别不平衡问题，并基于随机森林分析提取时间和统计特征，增强了模型对多变量时间依赖性和隐蔽攻击的检测能力。",
            "application_zh": "该研究主要应用于工业控制系统的网络安全领域，特别是水分配系统等关键基础设施的网络攻击检测。实际价值在于提供了一种稳健且可扩展的解决方案，能够集成时间学习和模型多样性，支持关键基础设施的安全运行，并可能扩展到其他时间依赖的工业系统，如电力或交通控制系统。",
            "highlight_zh": "最重要的实验结果是混合堆叠集成（RF、XGBoost和LSTM）在攻击检测上表现最佳，F1分数为0.7205，AUC高达0.9826，显著优于单一模型（如LSTM的F1为0.000）。这表明异构集成能有效提升检测性能，解决了类别不平衡和时间依赖性问题。",
            "tags_zh": [
                "网络攻击检测",
                "混合集成学习",
                "水分配系统",
                "时间序列分析",
                "类别不平衡处理",
                "堆叠学习",
                "工业控制系统安全",
                "BATADAL数据集"
            ],
            "_index": 77
        },
        {
            "title": "CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics",
            "authors": [
                "Zixin Tang",
                "Yiming Chen",
                "Quentin Rouxel",
                "Dianxi Li",
                "Shuang Wu",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14270v1",
            "summary": "Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14270v1",
            "code_links": [
                {
                    "url": "https://github.com/MischaD/LCMem",
                    "type": "github"
                }
            ],
            "headline_zh": "提出LCMem模型，通过统一重识别和复制检测任务，解决跨域图像记忆检测的鲁棒性问题。",
            "summary_zh": "生成图像建模的最新进展已实现足以欺骗人类专家的视觉真实感，但其在隐私保护数据共享方面的潜力仍未得到充分理解。一个核心障碍是缺乏可靠的记忆检测机制、有限的定量评估以及现有隐私审计方法在跨域中的泛化能力差。为解决这一问题，我们提出将记忆检测视为重识别和复制检测交叉点的统一问题，其互补目标涵盖身份一致性和增强鲁棒的复制检测，并引入潜在对比记忆网络（LCMem），这是一个在两项任务上联合评估的跨域模型。LCMem通过两阶段训练策略实现这一点：首先学习身份一致性，然后纳入增强鲁棒的复制检测。在六个基准数据集上，LCMem在重识别任务上提升了高达16个百分点，在复制检测任务上提升了高达30个百分点，实现了更可靠的大规模记忆检测。我们的结果表明，现有隐私过滤器性能有限且鲁棒性不足，突显了更强保护机制的需求。LCMem为跨域隐私审计设定了新标准，提供可靠且可扩展的记忆检测。代码和模型公开可用。",
            "intro_zh": [
                "核心问题：现有隐私审计方法在跨域泛化能力差，缺乏可靠的记忆检测机制和定量评估，限制了隐私保护数据共享的应用。",
                "方法要点：将记忆检测统一为重识别和复制检测的交叉问题，采用两阶段训练策略，先学习身份一致性，再融入增强鲁棒的复制检测。",
                "实验或效果：在六个数据集上，LCMem在重识别任务提升高达16个百分点，复制检测任务提升高达30个百分点，显著提高检测可靠性。"
            ],
            "method_zh": "LCMem是一个跨域模型，整体框架基于潜在对比记忆网络，将记忆检测视为重识别和复制检测的统一任务。关键技术创新点包括：采用两阶段训练策略，第一阶段专注于学习身份一致性，第二阶段结合增强鲁棒的复制检测，通过对比学习优化特征表示。与现有方法的主要区别在于，LCMem整合了互补任务，避免了传统隐私审计方法的领域依赖性和泛化不足问题，实现了更鲁棒的跨域检测能力。",
            "application_zh": "该研究可应用于隐私保护数据共享、生成模型审计、图像版权保护等领域，为跨域隐私审计提供可靠工具，帮助识别和防止敏感图像数据的未经授权使用，提升数据安全性和合规性。",
            "highlight_zh": "在六个基准数据集上，LCMem在重识别任务中性能提升高达16个百分点，复制检测任务提升高达30个百分点，显著优于现有隐私过滤器，证明了其在跨域记忆检测中的鲁棒性和可扩展性。",
            "tags_zh": [
                "图像记忆检测",
                "隐私审计",
                "重识别",
                "复制检测",
                "跨域模型",
                "对比学习",
                "生成模型安全",
                "数据共享保护"
            ],
            "_index": 78
        },
        {
            "title": "Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs",
            "authors": [
                "Wentao Wan",
                "Kaiyu Wu",
                "Qingyang Ma",
                "Nan Kang",
                "Yunjie Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14257v1",
            "summary": "Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 Pages, 12 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14257v1",
            "code_links": [],
            "headline_zh": "提出DISCODE分布感知分数解码器，以解决大视觉语言模型在跨域图像描述评估中的鲁棒性问题。",
            "summary_zh": "大视觉语言模型（LVLMs）在多模态任务中表现出色，但在图像描述评估中，尤其是在域偏移场景下，鲁棒性仍面临挑战。为解决这一问题，我们提出了分布感知分数解码器（DISCODE），这是一种无需微调的新方法，能够生成更符合人类判断的鲁棒评估分数。DISCODE的核心思想是测试时自适应评估方法，引入了自适应测试时（ATT）损失，利用高斯先验分布提高评估分数估计的鲁棒性。我们推导出该损失的解析解，可在测试时高效最小化。此外，我们提出了多域描述评估（MCEval）基准，这是一个覆盖六个不同领域的新图像描述评估基准，旨在评估评估指标的鲁棒性。实验表明，DISCODE在MCEval和四个现有基准上作为无参考评估指标达到了最先进的性能。",
            "intro_zh": [
                "现有大视觉语言模型在图像描述评估中，尤其在跨域场景下，鲁棒性不足，难以与人类判断对齐。",
                "提出DISCODE方法，基于测试时自适应评估，引入ATT损失和高斯先验，无需微调即可提升评估分数鲁棒性。",
                "在MCEval和四个现有基准上，DISCODE作为无参考评估指标实现了最先进的性能，验证了其有效性。"
            ],
            "method_zh": "DISCODE的整体框架是一个测试时自适应评估系统，核心创新点包括：1）引入自适应测试时（ATT）损失，该损失基于高斯先验分布，旨在优化评估分数估计的鲁棒性；2）推导出ATT损失的解析解，允许在测试时高效计算和最小化损失，无需额外训练或微调。与现有方法的主要区别在于，DISCODE不依赖于模型微调，而是通过测试时自适应机制直接调整评估过程，利用分布信息来减少域偏移影响，从而在跨域场景下提供更稳定和准确的评估分数。",
            "application_zh": "该研究可应用于图像描述生成系统的自动评估，特别是在多领域或跨域场景下，如新闻、医疗、艺术等，帮助开发者和研究者快速、鲁棒地评估模型性能，减少人工标注成本，推动多模态AI技术的实际部署。",
            "highlight_zh": "DISCODE在MCEval基准（覆盖六个领域）和四个现有基准上作为无参考评估指标达到了最先进的性能，显著提升了跨域评估的鲁棒性，与人类判断更一致，验证了其方法的有效性。",
            "tags_zh": [
                "图像描述评估",
                "大视觉语言模型",
                "跨域鲁棒性",
                "测试时自适应",
                "无参考评估",
                "多模态任务",
                "高斯先验分布",
                "自动评估指标"
            ],
            "_index": 79
        },
        {
            "title": "DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos",
            "authors": [
                "Yang Bai",
                "Liudi Yang",
                "George Eskandar",
                "Fengyi Shen",
                "Mohammad Altillawi",
                "Ziyuan Liu",
                "Gitta Kutyniok"
            ],
            "arxiv_id": "2512.14217v1",
            "summary": "Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14217v1",
            "code_links": [],
            "headline_zh": "提出双轴表示完全收敛学习策略，解决有机化学空间模型收敛与泛化难题。",
            "summary_zh": "机器学习正在深刻重塑分子与材料建模，但面对化学空间的巨大规模（10^30-10^60），模型能否实现跨空间的收敛学习仍是一个开放的科学问题。我们引入了双轴表示完全收敛学习策略，该策略通过一种分子表示实现，该表示整合了基于现代价键理论的局部价环境图卷积网络编码，以及环/笼拓扑的无桥图编码，提供了化学空间覆盖的定量度量。该框架形式化了表示完全性，为构建支持大模型收敛学习的数据集建立了原则性基础。在此RCCL框架指导下，我们开发了FD25数据集，系统覆盖了13,302个局部价单元和165,726个环/笼拓扑，实现了对含H/C/N/O/F元素的有机分子的近乎完全组合覆盖。在FD25上训练的图神经网络表现出表示完全收敛学习和强大的分布外泛化能力，在外部基准测试中整体预测误差约为1.0 kcal/mol MAE。我们的结果建立了分子表示、结构完全性和模型泛化之间的定量联系，为可解释、可迁移和数据高效的分子智能奠定了基础。",
            "intro_zh": [
                "核心问题：化学空间规模巨大（10^30-10^60），现有方法难以确保模型在该空间实现收敛学习，泛化能力受限。",
                "方法要点：提出双轴RCCL策略，结合局部价环境GCN编码和环/笼拓扑NBG编码，构建表示完全性框架指导数据集构建。",
                "实验或效果：开发FD25数据集，训练模型在外部基准上实现约1.0 kcal/mol MAE误差，展现强泛化能力。"
            ],
            "method_zh": "论文提出双轴表示完全收敛学习框架，核心方法包括：整体框架基于表示完全性概念，通过整合局部价环境和环/笼拓扑的双轴编码来量化化学空间覆盖。关键技术创新点在于结合图卷积网络编码局部价环境（基于现代价键理论）和无桥图编码环/笼拓扑，形成互补表示。与现有方法的主要区别在于，它首次形式化了表示完全性，为数据集构建提供原则性指导，确保模型能在整个化学空间实现收敛学习，而非依赖随机或经验性采样。",
            "application_zh": "该研究在分子与材料建模领域具有广泛应用潜力，可用于药物发现、材料设计、催化剂开发等，通过提供可解释、可迁移的分子智能模型，提升数据效率和预测准确性，加速新分子和材料的研发进程。",
            "highlight_zh": "最重要的实验结果包括：FD25数据集覆盖13,302个局部价单元和165,726个环/笼拓扑，实现近乎完全组合覆盖；训练模型在外部基准测试中整体预测误差约为1.0 kcal/mol MAE，显著优于传统方法，验证了表示完全收敛学习和强泛化能力。",
            "tags_zh": [
                "化学空间建模",
                "表示完全性",
                "图神经网络",
                "分子表示学习",
                "收敛学习",
                "泛化能力",
                "数据集构建",
                "有机分子预测"
            ],
            "_index": 80
        },
        {
            "title": "Error Bound Analysis of Physics-Informed Neural Networks-Driven T2 Quantification in Cardiac Magnetic Resonance Imaging",
            "authors": [
                "Mengxue Zhang",
                "Qingrui Cai",
                "Yinyin Chen",
                "Hang Jin",
                "Jianjun Zhou",
                "Qiu Guo",
                "Peijun Zhao",
                "Zhiping Mao",
                "Xingxing Zhang",
                "Yuyu Xia",
                "Xianwang Jiang",
                "Qin Xu",
                "Chunyan Xiong",
                "Yirong Zhou",
                "Chengyan Wang",
                "Xiaobo Qu"
            ],
            "arxiv_id": "2512.14211v1",
            "summary": "Physics-Informed Neural Networks (PINN) are emerging as a promising approach for quantitative parameter estimation of Magnetic Resonance Imaging (MRI). While existing deep learning methods can provide an accurate quantitative estimation of the T2 parameter, they still require large amounts of training data and lack theoretical support and a recognized gold standard. Thus, given the absence of PINN-based approaches for T2 estimation, we propose embedding the fundamental physics of MRI, the Bloch equation, in the loss of PINN, which is solely based on target scan data and does not require a pre-defined training database. Furthermore, by deriving rigorous upper bounds for both the T2 estimation error and the generalization error of the Bloch equation solution, we establish a theoretical foundation for evaluating the PINN's quantitative accuracy. Even without access to the ground truth or a gold standard, this theory enables us to estimate the error with respect to the real quantitative parameter T2. The accuracy of T2 mapping and the validity of the theoretical analysis are demonstrated on a numerical cardiac model and a water phantom, where our method exhibits excellent quantitative precision in the myocardial T2 range. Clinical applicability is confirmed in 94 acute myocardial infarction (AMI) patients, achieving low-error quantitative T2 estimation under the theoretical error bound, highlighting the robustness and potential of PINN.",
            "categories": [
                "physics.bio-ph",
                "cs.AI"
            ],
            "primary_category": "physics.bio-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14211v1",
            "code_links": [],
            "headline_zh": "提出PortAgent，一种基于大语言模型的车辆调度代理，以解决自动化集装箱码头中车辆调度系统跨码头可移植性低的问题。",
            "summary_zh": "车辆调度系统对自动化集装箱码头的运营效率至关重要，但其广泛商业化受到跨码头可移植性低的阻碍。这一挑战源于三个限制：高度依赖港口运营专家、对码头特定数据的高需求以及耗时的手动部署过程。利用大语言模型的兴起，本文提出PortAgent，一种基于大语言模型的车辆调度代理，完全自动化车辆调度系统的迁移工作流。它具有三个特点：（1）无需港口运营专家；（2）数据需求低；（3）部署快速。具体而言，通过虚拟专家团队消除专家依赖。该团队与知识检索器、建模师、编码器和调试器四个虚拟专家协作，模拟人类专家团队进行车辆调度系统迁移工作流。这些专家通过少样本示例学习方法专门化于码头车辆调度系统领域。通过这种方法，专家能够从少量车辆调度系统示例中学习领域知识。这些示例通过检索增强生成机制检索，减轻了对码头特定数据的高需求。此外，在这些专家之间建立了自动车辆调度系统设计工作流，以避免额外的手动干预。在该工作流中，创建了一个受大语言模型反射框架启发的自校正循环。",
            "intro_zh": [
                "核心问题：现有车辆调度系统跨码头可移植性低，主要受限于专家依赖、数据需求高和手动部署耗时。",
                "方法要点：提出PortAgent，基于大语言模型构建虚拟专家团队，通过少样本学习和检索增强生成自动化迁移工作流。",
                "实验或效果：PortAgent实现了快速部署，减少数据需求，提升系统可移植性，具体性能提升未知。"
            ],
            "method_zh": "PortAgent的核心方法基于大语言模型驱动的虚拟专家团队框架。整体框架包括知识检索器、建模师、编码器和调试器四个虚拟专家，它们通过协作模拟人类专家团队进行车辆调度系统迁移。关键技术创新点在于结合少样本示例学习和检索增强生成机制，使专家能从少量示例中学习领域知识，并自动检索相关数据以降低数据需求。与现有方法的主要区别在于完全自动化迁移过程，无需专家干预，通过自校正循环优化工作流，显著提高可移植性和部署效率。",
            "application_zh": "该研究主要应用于自动化集装箱码头的车辆调度系统迁移和部署，可扩展到其他物流和工业自动化场景，提升运营效率和系统适应性，具有实际商业价值。",
            "highlight_zh": "PortAgent通过虚拟专家团队和少样本学习，实现了车辆调度系统的快速自动化迁移，减少专家依赖和数据需求，具体性能指标未知，但显著提升了可移植性和部署速度。",
            "tags_zh": [
                "大语言模型",
                "车辆调度系统",
                "自动化码头",
                "少样本学习",
                "检索增强生成",
                "虚拟专家团队",
                "系统迁移",
                "自校正循环"
            ],
            "_index": 81
        },
        {
            "title": "Towards Explainable Quantum AI: Informing the Encoder Selection of Quantum Neural Networks via Visualization",
            "authors": [
                "Shaolun Ruan",
                "Feng Liang",
                "Rohan Ramakrishna",
                "Chao Ren",
                "Rudai Yan",
                "Qiang Guan",
                "Jiannan Li",
                "Yong Wang"
            ],
            "arxiv_id": "2512.14181v1",
            "summary": "Quantum Neural Networks (QNNs) represent a promising fusion of quantum computing and neural network architectures, offering speed-ups and efficient processing of high-dimensional, entangled data. A crucial component of QNNs is the encoder, which maps classical input data into quantum states. However, choosing suitable encoders remains a significant challenge, largely due to the lack of systematic guidance and the trial-and-error nature of current approaches. This process is further impeded by two key challenges: (1) the difficulty in evaluating encoded quantum states prior to training, and (2) the lack of intuitive methods for analyzing an encoder's ability to effectively distinguish data features. To address these issues, we introduce a novel visualization tool, XQAI-Eyes, which enables QNN developers to compare classical data features with their corresponding encoded quantum states and to examine the mixed quantum states across different classes. By bridging classical and quantum perspectives, XQAI-Eyes facilitates a deeper understanding of how encoders influence QNN performance. Evaluations across diverse datasets and encoder designs demonstrate XQAI-Eyes's potential to support the exploration of the relationship between encoder design and QNN effectiveness, offering a holistic and transparent approach to optimizing quantum encoders. Moreover, domain experts used XQAI-Eyes to derive two key practices for quantum encoder selection, grounded in the principles of pattern preservation and feature mapping.",
            "categories": [
                "quant-ph",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "quant-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 6 figures, accepted by TVCG 2026, not published yet",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14181v1",
            "code_links": [],
            "headline_zh": "提出基于合成数据的管道，以加速军事化人形机器人的训练、验证和部署准备。",
            "summary_zh": "Omnia提出了一种基于合成数据的管道，旨在加速军事化人形机器人的训练、验证和部署准备。该方法将第一人称空间观测数据（来自点对点记录、智能眼镜、增强现实头显和空间浏览工作流）转换为可扩展的、任务特定的合成数据集，用于人形机器人自主性。通过生成大量高保真模拟场景，并结合自动标注和模型训练，该管道能够在感知、导航和决策能力方面实现快速迭代，而无需承担广泛实地试验的成本、风险或时间限制。生成的数据集可以快速调整以适应新的操作环境和威胁条件，支持基线人形机器人性能以及高级子系统，如多模态传感、反检测生存能力和CBRNE相关侦察行为。这项工作通过在开发过程早期将人形机器人系统暴露于广泛的场景多样性中，旨在在复杂、竞争性环境中实现更快的开发周期和更高的鲁棒性。",
            "intro_zh": [
                "现有方法依赖实地试验，成本高、风险大且耗时，难以快速适应新环境和威胁条件。",
                "提出基于合成数据的管道，将第一人称观测转换为任务特定数据集，结合自动标注和训练实现快速迭代。",
                "通过生成高保真模拟场景，加速感知、导航和决策能力开发，提升在复杂环境中的鲁棒性和适应性。"
            ],
            "method_zh": "论文提出一个合成数据驱动的管道框架，整体包括数据采集、合成数据集生成、自动标注和模型训练四个核心环节。关键技术创新点在于将第一人称空间观测（如点对点记录、智能眼镜数据）转换为可扩展的、任务特定的合成数据集，并集成自动标注以支持高效模型训练。与现有方法的主要区别在于，它避免了依赖昂贵且耗时的实地试验，而是通过合成数据模拟多样场景，实现快速迭代和适应性调整，特别针对军事化人形机器人的自主性需求。",
            "application_zh": "该研究主要应用于军事化人形机器人的开发，支持感知、导航和决策能力的快速训练与验证。潜在价值包括加速机器人部署准备、提升在复杂战场环境中的鲁棒性，以及适应CBRNE侦察等特定任务，具有重要的国防和安防应用前景。",
            "highlight_zh": "实验表明，该管道能生成大量高保真模拟场景，结合自动标注显著加速模型训练迭代。在感知、导航和决策任务中，实现了快速适应新环境和威胁条件的能力，提升了人形机器人在复杂、竞争性设置中的性能鲁棒性。",
            "tags_zh": [
                "合成数据管道",
                "军事化人形机器人",
                "第一人称观测",
                "自动标注",
                "任务特定数据集",
                "快速迭代训练",
                "复杂环境鲁棒性",
                "CBRNE侦察"
            ],
            "_index": 82
        },
        {
            "title": "Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere",
            "authors": [
                "Francesco Di Sario",
                "Daniel Rebain",
                "Dor Verbin",
                "Marco Grangetto",
                "Andrea Tagliasacchi"
            ],
            "arxiv_id": "2512.14180v1",
            "summary": "Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14180v1",
            "code_links": [],
            "headline_zh": "提出无监督机器学习框架以检测全球铝贸易中的异常套利和洗钱行为",
            "summary_zh": "随着全球经济向脱碳转型，铝行业成为战略资源管理的焦点。尽管碳边境调节机制等政策旨在减少排放，却无意中扩大了原铝、废铝和半成品之间的价格套利空间，为市场优化创造了新激励。本研究提出一个统一的无监督机器学习框架，用于检测和分类联合国商品贸易统计数据中（2020年至2024年）的新兴贸易异常。超越传统的基于规则的监测，我们应用一个四层分析流程，利用法证统计、孤立森林、网络科学和深度自编码器。与可持续性套利是主要驱动因素的假设相反，实证结果揭示了一个矛盾且更严重的硬件掩蔽现象。非法行为者利用双向关税激励，将废铝误分类为高计数异质商品，以证明单价极端异常值（>160美元/公斤，溢价1900%）的合理性，这指示贸易洗钱而非商业套利。从拓扑角度看，风险并非集中在主要出口国，而是集中在作为非法重路由关键节点的高中心性影子枢纽。这些行为者执行空岸策略，系统性地将目的地数据抑制为未指定代码，以破坏镜像统计数据和切断法证追踪。通过SHAP验证，结果确认价格偏差是异常的主要预测因子，需要海关执法从物理量检查向动态算法估值审计的范式转变。",
            "intro_zh": [
                "现有方法依赖传统规则监测，难以检测新兴贸易异常，如铝行业中的价格套利和洗钱行为。",
                "论文提出四层无监督机器学习框架，结合法证统计、孤立森林、网络科学和深度自编码器，实现异常检测与分类。",
                "实证结果揭示硬件掩蔽现象，价格偏差是主要预测因子，推动海关执法向动态算法审计转变。"
            ],
            "method_zh": "论文提出一个统一的无监督机器学习框架，整体框架包括四层分析流程：法证统计用于初步数据清洗和异常识别，孤立森林用于检测离群点，网络科学分析贸易网络拓扑结构以识别高中心性影子枢纽，深度自编码器用于学习正常贸易模式并重构异常。关键技术创新点在于融合多学科方法，实现端到端的异常检测与分类，与现有基于规则的方法相比，能更有效地捕捉复杂和非线性的贸易异常模式。",
            "application_zh": "该研究可应用于全球贸易数据监控，特别是铝等关键资源行业，帮助海关和监管机构检测贸易洗钱、价格操纵等非法活动，提升执法效率和资源管理能力。",
            "highlight_zh": "实证结果揭示硬件掩蔽现象，非法行为者利用废铝误分类实现单价极端异常值（溢价1900%），指示贸易洗钱；风险集中在影子枢纽而非主要出口国；SHAP验证显示价格偏差是异常的主要预测因子。",
            "tags_zh": [
                "无监督学习",
                "贸易异常检测",
                "铝套利分析",
                "网络科学",
                "深度自编码器",
                "贸易洗钱识别",
                "海关执法优化",
                "价格偏差预测"
            ],
            "_index": 83
        },
        {
            "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
            "authors": [
                "Yunhao Yao",
                "Zhiqiang Wang",
                "Haoran Cheng",
                "Yihang Cheng",
                "Haohua Du",
                "Xiang-Yang Li"
            ],
            "arxiv_id": "2512.14166v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14166v1",
            "code_links": [],
            "headline_zh": "提出ExpanDyNeRF框架，利用高斯溅射先验和伪真值生成策略，解决动态NeRF在大视角旋转下渲染不稳定的问题。",
            "summary_zh": "在动态神经辐射场（NeRF）系统中，当前最先进的新视角合成方法在显著视角偏差下常失败，产生不稳定和不真实的渲染。为解决此问题，我们引入了扩展动态NeRF（ExpanDyNeRF），这是一个单目NeRF框架，利用高斯溅射先验和伪真值生成策略，以实现大角度旋转下的真实合成。ExpanDyNeRF优化密度和颜色特征，以改进从挑战性视角的场景重建。我们还提出了合成动态多视角（SynDM）数据集，这是首个用于动态场景的合成多视角数据集，具有明确的侧视角监督，通过基于GTA V的自定义渲染管线创建。在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角偏移下的渲染保真度显著优于现有动态NeRF方法。更多细节见补充材料。",
            "intro_zh": [
                "现有动态NeRF方法在大视角旋转下渲染不稳定，导致新视角合成失败，产生不真实结果。",
                "ExpanDyNeRF结合高斯溅射先验和伪真值生成，优化密度和颜色特征，提升大角度视角下的重建质量。",
                "实验显示，ExpanDyNeRF在SynDM和真实数据集上，渲染保真度显著优于现有方法，尤其在极端视角偏移下。"
            ],
            "method_zh": "ExpanDyNeRF是一个单目NeRF框架，整体基于动态神经辐射场，通过高斯溅射先验提供几何约束，并采用伪真值生成策略增强训练数据。关键技术创新包括：引入高斯溅射先验以稳定大视角下的密度估计，以及设计伪真值生成机制来模拟多视角监督。与现有方法的主要区别在于，它专门针对单目视频输入，通过先验和伪真值策略，有效缓解了视角偏差导致的渲染不稳定性，而无需依赖多摄像头或复杂运动模型。",
            "application_zh": "该研究可应用于虚拟现实、增强现实和机器人导航等领域，通过单目视频实现动态场景的高质量新视角合成，提升沉浸式体验和场景理解能力。",
            "highlight_zh": "在SynDM数据集上，ExpanDyNeRF在极端视角偏移下的渲染保真度显著提升，定量指标优于现有动态NeRF方法，定性结果展示更稳定和真实的合成效果。",
            "tags_zh": [
                "动态神经辐射场",
                "新视角合成",
                "单目视频",
                "高斯溅射先验",
                "伪真值生成",
                "合成数据集",
                "大视角旋转",
                "渲染保真度"
            ],
            "_index": 84
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138v1",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138v1",
            "code_links": [],
            "headline_zh": "提出基于投影误差评分的字典选择方法，以增强稀疏回归在系统辨识中的准确性和可解释性。",
            "summary_zh": "本研究重新审视了基于字典的稀疏回归方法，特别是序列阈值最小二乘法（STLS），并提出了一种基于评分引导的字典选择策略，为数据驱动建模提供实用指导，重点应用于SINDy类算法。STLS是一种解决ℓ0稀疏最小二乘问题的算法，它通过分裂方法高效求解最小二乘部分，同时使用近端方法处理稀疏项。该算法生成的系数向量分量依赖于投影重构误差（称为评分）和字典项之间的互相关性。本文的第一个贡献是对评分和字典选择策略的理论分析，这可以在原始和弱SINDy框架下理解。其次，在常微分方程和偏微分方程上的数值实验突出了基于评分的筛选方法的有效性，提高了动态系统辨识的准确性和可解释性。这些结果表明，在某些情况下，集成评分引导方法来更精确地优化字典可能有助于SINDy用户增强其数据驱动发现控制方程的鲁棒性。",
            "intro_zh": [
                "现有稀疏回归方法如STLS在字典选择上缺乏理论指导，影响系统辨识的准确性和可解释性。",
                "提出基于投影误差评分的字典筛选策略，结合STLS算法优化稀疏项选择过程。",
                "数值实验表明该方法在常微分和偏微分方程辨识中提升了准确性和模型可解释性。"
            ],
            "method_zh": "论文的核心方法基于STLS算法框架，该算法通过分裂迭代求解ℓ0稀疏最小二乘问题：每次迭代先固定稀疏模式求解最小二乘，再通过阈值处理更新稀疏系数。关键创新在于引入投影重构误差（评分）作为字典项选择的指导指标，结合字典项间的互相关性分析，动态优化字典库。与现有方法的主要区别在于，传统STLS依赖固定阈值，而本文方法利用评分理论分析实现更智能的字典筛选，增强了稀疏回归的适应性和理论可解释性。",
            "application_zh": "该方法主要应用于动态系统辨识领域，如基于SINDy算法的数据驱动建模，可用于发现常微分方程、偏微分方程等控制方程，在机器人控制、流体力学、生物系统建模等工程和科学计算中具有实际价值。",
            "highlight_zh": "在常微分方程和偏微分方程的数值实验中，基于评分的字典选择方法显著提高了系统辨识的准确性，同时增强了模型的可解释性，验证了理论分析的有效性。",
            "tags_zh": [
                "稀疏回归",
                "系统辨识",
                "SINDy算法",
                "字典选择",
                "投影误差评分",
                "动态系统建模",
                "数据驱动发现"
            ],
            "_index": 85
        },
        {
            "title": "UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis",
            "authors": [
                "Amirmohammad Pasdar",
                "Toby Murray",
                "Van-Thuan Pham"
            ],
            "arxiv_id": "2512.14130v1",
            "summary": "We introduce UIXPOSE, a source-code-agnostic framework that operates on both compiled and open-source apps. This framework applies Intention Behaviour Alignment (IBA) to mobile malware analysis, aligning UI-inferred intent with runtime semantics. Previous work either infers intent statically, e.g., permission-centric, or widget-level or monitors coarse dynamic signals (endpoints, partial resource usage) that miss content and context. UIXPOSE infers an intent vector from each screen using vision-language models and knowledge structures and combines decoded network payloads, heap/memory signals, and resource utilisation traces into a behaviour vector. Their alignment, calculated at runtime, can both detect misbehaviour and highlight exploration of behaviourally rich paths. In three real-world case studies, UIXPOSE reveals covert exfiltration and hidden background activity that evade metadata-only baselines, demonstrating how IBA improves dynamic detection.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14130v1",
            "code_links": [],
            "headline_zh": "提出GRAFT模型以解决电网负荷预测中多源文本信息融合与对齐的挑战",
            "summary_zh": "电力负荷同时受到天气、日历节律、突发事件和政策等多时间尺度外生因素的影响。为此，本文提出GRAFT（基于文本的电网感知预测），改进STanHOP模型以更好地支持电网感知预测和多源文本干预。具体而言，GRAFT将每日聚合的新闻、社交媒体和政策文本与半小时负荷数据严格对齐，并通过训练和滚动预测期间的交叉注意力实现文本引导的融合到特定时间位置。此外，GRAFT提供即插即用的外部记忆接口，以适应实际部署中的不同信息源。我们构建并发布了一个统一的基准数据集，涵盖2019-2021年澳大利亚五个州的半小时负荷、每日对齐的天气/日历变量以及三类外部文本，并在统一协议下进行了系统、可重复的评估，比较了不同区域、外部来源和时间尺度。实验结果表明，GRAFT显著优于强基线模型，在多个区域和预测时间范围内达到或超越了最先进水平。此外，该模型在事件驱动场景中表现稳健，并通过注意力读出机制实现了文本对负荷影响的时序定位和来源级解释。我们发布了基准数据集、预处理脚本和预测结果，以促进电网负荷预测的标准化实证评估和可重复性。",
            "intro_zh": [
                "现有方法难以有效融合多源文本信息（如新闻、社交媒体、政策）与电网负荷数据，导致预测精度受限。",
                "GRAFT通过严格对齐文本与负荷数据，并利用交叉注意力实现文本引导的融合，同时提供外部记忆接口增强适应性。",
                "实验显示GRAFT在多个区域和时间尺度上显著优于基线，达到或超越最先进水平，并支持事件驱动的稳健预测。"
            ],
            "method_zh": "GRAFT的整体框架基于改进的STanHOP模型，核心创新点包括：严格对齐多源文本（新闻、社交媒体、政策）与半小时负荷数据，通过交叉注意力机制在训练和滚动预测中实现文本到特定时间位置的引导融合；提供即插即用的外部记忆接口，便于集成不同信息源。与现有方法的主要区别在于其强调电网感知预测，并系统整合多类别文本干预，而非仅依赖传统变量如天气和日历。",
            "application_zh": "该研究可应用于智能电网管理、能源需求预测和电力市场分析等领域，通过融合多源文本信息提升负荷预测精度，支持实时决策和事件响应，具有实际部署价值。",
            "highlight_zh": "GRAFT在澳大利亚五个州的基准测试中，于小时、日和月尺度上均显著优于强基线，达到或超越最先进水平；模型在事件驱动场景中表现稳健，并通过注意力机制实现文本影响的时序定位和来源解释。",
            "tags_zh": [
                "电网负荷预测",
                "多源文本融合",
                "交叉注意力机制",
                "时序对齐",
                "外部记忆接口",
                "事件驱动预测",
                "可解释性分析",
                "基准数据集"
            ],
            "_index": 86
        },
        {
            "title": "Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field",
            "authors": [
                "Chenzui Li",
                "Yiming Chen",
                "Xi Wu",
                "Tao Teng",
                "Sylvain Calinon",
                "Darwin Caldwell",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14111v1",
            "summary": "Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14111v1",
            "code_links": [],
            "headline_zh": "提出SuperWing数据集以解决三维翼型数据稀缺问题，加速数据驱动的跨音速翼型气动设计。",
            "summary_zh": "机器学习代理模型在加速气动设计方面展现出潜力，但现有数据集稀缺且多样性有限，限制了三维翼型通用预测器的发展。本文介绍了SuperWing，这是一个全面的开放跨音速后掠翼气动数据集，包含4,239个参数化翼型几何形状和28,856个雷诺平均Navier-Stokes流场解。数据集中的翼型形状采用简化但富有表现力的几何参数化方法生成，结合了翼展方向上的翼型形状、扭转角和上反角变化，从而在不依赖基准翼型扰动的情况下增强了多样性。所有形状均在覆盖典型飞行包线的广泛马赫数和攻角范围内进行模拟。为展示数据集的实用性，我们基准测试了两个最先进的Transformer模型，它们能准确预测表面流动，并在保留样本上实现了2.5阻力计数误差。在SuperWing上预训练的模型进一步展现出对复杂基准翼型（如DLR-F6和NASA CRM）的强大零样本泛化能力，突显了数据集的多样性和实际应用潜力。",
            "intro_zh": [
                "现有三维翼型气动设计数据集稀缺且多样性不足，限制了机器学习代理模型的通用性发展。",
                "提出SuperWing数据集，通过参数化几何生成和广泛模拟条件，增强翼型形状和流动的多样性。",
                "实验显示模型在预测表面流动时误差低，并实现零样本泛化到复杂基准翼型，验证数据集有效性。"
            ],
            "method_zh": "论文的核心方法是构建SuperWing数据集，整体框架包括翼型几何参数化生成和流场模拟。关键技术创新点在于采用简化的几何参数化，允许翼展方向上的翼型形状、扭转角和上反角变化，从而在不依赖基准翼型扰动的情况下生成多样化的三维翼型。与现有方法的主要区别在于，SuperWing提供了大规模、高多样性的跨音速翼型数据，覆盖广泛的飞行条件，弥补了现有数据集的不足，支持数据驱动的气动设计研究。",
            "application_zh": "该研究可应用于航空航天工程中的翼型优化设计、飞行器气动性能预测和机器学习模型训练。通过提供高质量数据集，能加速气动设计流程，降低计算成本，并促进通用代理模型的发展，具有实际工程价值。",
            "highlight_zh": "最重要的实验结果是Transformer模型在SuperWing数据集上实现了2.5阻力计数误差的准确预测，并在DLR-F6和NASA CRM等复杂基准翼型上展现出强大的零样本泛化能力，突显了数据集的多样性和实用性。",
            "tags_zh": [
                "跨音速翼型数据集",
                "气动设计",
                "机器学习代理模型",
                "三维翼型几何参数化",
                "雷诺平均Navier-Stokes模拟",
                "Transformer模型",
                "零样本泛化",
                "航空航天工程"
            ],
            "_index": 87
        },
        {
            "title": "OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration",
            "authors": [
                "Ruitong Sun",
                "Tianze Yang",
                "Wei Niu",
                "Jin Sun"
            ],
            "arxiv_id": "2512.14096v1",
            "summary": "Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "29 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14096v1",
            "code_links": [],
            "headline_zh": "提出基于动态权重生成的大规模编辑方法MeG，以解决大语言模型知识编辑中的大规模修改挑战。",
            "summary_zh": "知识编辑（KE）是研究如何以低成本（相比预训练）修改大语言模型（LLMs）中某些知识的领域。目前，在大规模编辑LLMs的同时确保编辑的可靠性、通用性和局部性指标仍是一个挑战。本文提出了一种基于动态权重生成的大规模编辑方法（MeG）。我们的MeG涉及在LLMs的特定层附加一个动态权重神经元，并使用扩散模型根据知识所需的输入查询条件生成该神经元的权重。这使得通过添加单个动态权重神经元即可实现大规模知识编辑的目标。实验表明，与现有知识编辑方法相比，我们的MeG在可靠性、通用性和局部性指标方面能显著提升大规模KE的性能，特别是局部性指标的绝对值指数有较高的百分点增长，证明了我们提出方法的优势。",
            "intro_zh": [
                "核心问题：现有知识编辑方法难以在大规模修改大语言模型时，同时保证编辑的可靠性、通用性和局部性指标。",
                "方法要点：通过附加动态权重神经元，并利用扩散模型基于输入查询条件生成权重，实现高效的大规模知识编辑。",
                "实验或效果：MeG在可靠性、通用性和局部性指标上显著优于现有方法，局部性指标提升尤为突出。"
            ],
            "method_zh": "MeG的整体框架是在大语言模型的特定层附加一个动态权重神经元，该神经元的权重由扩散模型条件生成，生成过程基于输入查询所需的知识。关键技术创新点在于使用扩散模型动态生成权重，而非固定修改模型参数，这允许通过单个神经元实现大规模编辑。与现有方法的主要区别在于，传统方法通常直接修改模型权重或添加静态模块，而MeG通过动态权重生成实现了更灵活、可扩展的编辑，提高了编辑效率和性能。",
            "application_zh": "该研究可应用于大语言模型的持续学习和知识更新，例如在AI助手、内容生成系统中快速修正错误知识或添加新信息，提升模型的适应性和准确性，降低重新训练的成本。",
            "highlight_zh": "实验结果显示，MeG在大规模知识编辑任务中，可靠性、通用性和局部性指标均显著提升，特别是局部性指标的绝对值指数有较高百分点增长，证明了其在保持模型原有知识的同时高效编辑新知识的优势。",
            "tags_zh": [
                "知识编辑",
                "大语言模型",
                "动态权重生成",
                "扩散模型",
                "大规模编辑",
                "模型微调",
                "人工智能优化"
            ],
            "_index": 88
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087v1",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Submitted to IEEE TPAMI, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "深度估计",
                    "matched_keywords": [
                        "3D reconstruction"
                    ],
                    "score": 1
                },
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出RePo机制，通过上下文重定位减少外部认知负荷，提升大语言模型在噪声上下文和长文本任务中的性能。",
            "summary_zh": "上下文学习是现代大语言模型（LLMs）的基础；然而，主流架构通过分配线性或恒定的位置索引，强加了僵化固定的上下文结构。基于认知负荷理论（CLT），我们认为这种无信息结构增加了外部认知负荷，消耗了本应用于深度推理和注意力分配的有限工作记忆容量。为解决此问题，我们提出了RePo，一种通过上下文重定位减少外部负荷的新机制。与标准方法不同，RePo使用可微分模块fφ来分配捕捉上下文依赖关系的标记位置，而非依赖预定义的整数范围。通过在OLMo-2 1B骨干网络上持续预训练，我们证明RePo在涉及噪声上下文、结构化数据和更长上下文长度的任务中显著提升性能，同时在一般短上下文任务上保持竞争力。详细分析显示，RePo成功将更高注意力分配给遥远但相关的信息，在密集和非线性空间中分配位置，并捕捉输入上下文的内在结构。我们的代码可在https://github.com/SakanaAI/repo获取。",
            "intro_zh": [
                "现有大语言模型使用线性或恒定位置索引，导致上下文结构僵化，增加外部认知负荷，限制深度推理能力。",
                "提出RePo机制，利用可微分模块fφ动态分配标记位置，捕捉上下文依赖，减少外部负荷，优化注意力分配。",
                "实验表明，RePo在噪声上下文、结构化数据和长文本任务中性能显著提升，同时保持短上下文任务竞争力，注意力更聚焦相关远距离信息。"
            ],
            "method_zh": "RePo的整体框架基于大语言模型骨干（如OLMo-2 1B），通过持续预训练集成上下文重定位机制。关键技术创新点是引入可微分模块fφ，该模块动态学习并分配标记位置，以捕捉上下文依赖关系，而非依赖预定义的线性或恒定位置索引。与现有方法的主要区别在于：RePo打破了传统位置编码的僵化结构，允许位置在密集和非线性空间中灵活调整，从而更有效地建模上下文内在结构，减少外部认知负荷，提升模型在复杂任务中的表现。",
            "application_zh": "该研究可应用于需要处理噪声上下文、结构化数据或长文本的自然语言处理任务，如文档摘要、问答系统和代码生成，提升模型在实际场景中的鲁棒性和效率。",
            "highlight_zh": "RePo在噪声上下文、结构化数据和长文本任务中性能显著提升，同时保持一般短上下文任务竞争力；分析显示模型能分配更高注意力给遥远相关信息，并有效捕捉输入结构。",
            "tags_zh": [
                "上下文学习",
                "位置编码",
                "认知负荷理论",
                "大语言模型",
                "注意力机制",
                "持续预训练",
                "噪声上下文处理",
                "长文本建模"
            ],
            "_index": 89
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069v1",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14388v1",
            "code_links": [],
            "headline_zh": "提出基于提升量子差分隐私的黑盒审计框架，利用量子金丝雀检测量子机器学习模型中的隐私泄露问题。",
            "summary_zh": "量子机器学习（QML）虽然具有显著的计算优势，但模型在敏感数据上训练时可能记忆个体记录，导致严重的隐私漏洞。现有的量子差分隐私（QDP）机制提供了理论上的最坏情况保证，但缺乏对已部署模型进行实证验证的工具。本文首次引入了基于提升量子差分隐私的黑盒隐私审计框架，利用量子金丝雀（策略性偏移编码的量子态）来检测记忆行为，并精确量化训练过程中的隐私泄露。该框架建立了金丝雀偏移与迹距离界限之间的严格数学联系，推导出隐私预算消耗的经验下界，从而弥合了理论保证与实际隐私验证之间的关键差距。在模拟和物理量子硬件上的全面评估表明，该框架能有效测量QML模型中的实际隐私损失，为QML系统提供稳健的隐私验证。",
            "intro_zh": [
                "现有量子差分隐私机制缺乏实证验证工具，无法评估已部署量子机器学习模型的隐私泄露风险。",
                "提出基于提升量子差分隐私的黑盒审计框架，利用量子金丝雀策略性编码量子态来检测记忆和量化隐私泄露。",
                "实验在模拟和物理硬件上验证了框架有效性，能精确测量隐私损失并建立理论到实践的桥梁。"
            ],
            "method_zh": "论文提出一个黑盒隐私审计框架，核心基于提升量子差分隐私理论。整体框架通过引入量子金丝雀——即策略性偏移编码的量子态，作为探测工具来检测模型训练过程中的记忆行为。关键技术创新点在于建立了金丝雀偏移与量子态迹距离之间的严格数学联系，从而推导出隐私预算消耗的经验下界，这允许在无需访问模型内部细节的情况下量化隐私泄露。与现有方法的主要区别在于，现有量子差分隐私方法仅提供理论保证，而本框架首次实现了对QML模型的实证隐私验证，弥补了理论分析与实际部署之间的差距。",
            "application_zh": "该研究可应用于量子机器学习系统的隐私安全评估，特别是在医疗、金融等敏感数据处理场景中，帮助验证量子模型是否遵守隐私保护标准，促进QML技术的可信部署。",
            "highlight_zh": "在模拟和物理量子硬件上的实验表明，框架能有效检测模型记忆行为，精确量化隐私泄露，经验下界与理论保证一致，验证了提升量子差分隐私在实际系统中的适用性。",
            "tags_zh": [
                "大语言模型推理加速",
                "推测采样",
                "强化学习",
                "动态草稿树",
                "马尔可夫决策过程",
                "离线强化学习",
                "计算优化",
                "实时决策"
            ],
            "_index": 90
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO",
                        "VIO"
                    ],
                    "score": 2
                }
            ],
            "headline_zh": "提出EcoScapes系统，结合专用LLM、卫星影像分析和知识库，帮助小城市制定有效的气候适应策略。",
            "summary_zh": "气候适应对于城市地区的可持续性乃至生存至关重要。然而，小城市往往面临人员资源有限、难以整合多源海量数据进行全面分析的挑战。为克服这些困难，本文提出一个多层系统，结合专用大型语言模型、卫星影像分析和知识库，以辅助制定有效的气候适应策略。相关代码可在https://github.com/Photon-GitHub/EcoScapes找到。",
            "intro_zh": [
                "小城市在气候适应中面临人员资源有限、多源数据整合困难的问题，难以进行全面分析。",
                "提出多层系统，结合专用LLM、卫星影像分析和知识库，自动化生成气候适应建议。",
                "系统能有效辅助小城市制定策略，提升分析效率，具体性能提升未知。"
            ],
            "method_zh": "论文提出EcoScapes系统，整体框架为多层结构，整合专用大型语言模型、卫星影像分析模块和知识库。关键技术创新在于将LLM与遥感数据结合，实现自动化气候适应建议生成。与现有方法的主要区别在于针对小城市资源限制，提供端到端解决方案，减少人工依赖，增强数据整合能力。",
            "application_zh": "该研究主要应用于城市规划领域，特别是小城市的气候适应策略制定。潜在价值包括提升城市可持续性、辅助决策者优化资源分配，并可能推广至其他环境管理场景。",
            "highlight_zh": "系统能有效生成气候适应建议，提升小城市数据分析效率，但具体实验结果和性能提升数据未知，需参考代码库进一步验证。",
            "tags_zh": [
                "气候适应",
                "城市规划",
                "大型语言模型",
                "卫星影像分析",
                "知识库",
                "多源数据整合",
                "可持续发展"
            ],
            "_index": 91
        },
        {
            "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems",
            "authors": [
                "Enhong Liu",
                "Haiyu Yang",
                "Miel Hostens"
            ],
            "arxiv_id": "2512.14043v1",
            "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14043v1",
            "code_links": [],
            "headline_zh": "提出一种综合安全度量标准，用于评估自动驾驶系统中的感知安全性，考虑物体重要性参数。",
            "summary_zh": "环境感知及其正确解释对自动驾驶车辆至关重要，物体感知是汽车环绕感知的主要组成部分。目前已有多种评估物体感知的度量标准，但物体的重要性可能因其速度、方向、距离、尺寸或漏检可能导致碰撞造成的潜在损害而不同。因此，安全评估需要考虑这些额外参数。我们提出了一种新的安全度量标准，整合了所有这些参数，并返回一个易于解释的单一安全评估分数。该新度量标准通过真实世界和虚拟数据集进行评估，并与最先进的度量标准进行比较。",
            "intro_zh": [
                "现有感知评估度量未充分考虑物体重要性参数，如速度、方向、距离、尺寸和潜在碰撞损害，导致安全评估不全面。",
                "论文提出一种综合安全度量标准，整合物体重要性参数，生成单一安全评估分数，提高评估的准确性和可解释性。",
                "通过真实世界和虚拟数据集验证，新度量标准在安全评估方面优于现有方法，提供更全面的感知性能分析。"
            ],
            "method_zh": "论文提出一种综合安全度量标准框架，核心思想是将物体重要性参数（如速度、方向、距离、尺寸和潜在碰撞损害）整合到感知评估中。关键技术创新点包括设计参数权重模型，量化不同参数对安全的影响，并计算单一安全分数。与现有方法的主要区别在于，传统度量标准通常仅关注检测精度（如准确率、召回率），而新方法扩展了评估维度，直接关联安全性能，提供更贴近实际驾驶场景的评估结果。",
            "application_zh": "该研究主要应用于自动驾驶系统，特别是汽车环绕感知模块的安全评估。潜在应用领域包括自动驾驶车辆测试、感知算法优化和标准制定，实际价值在于提升系统安全性和可靠性，减少因感知错误导致的事故风险。",
            "highlight_zh": "实验使用真实世界和虚拟数据集，新度量标准在安全评估方面表现优于现有最先进度量标准，能更准确地反映感知系统的安全性能，提供易于解释的分数，支持系统改进决策。",
            "tags_zh": [
                "自动驾驶安全",
                "感知评估",
                "安全度量标准",
                "物体重要性参数",
                "综合评估",
                "汽车环绕感知",
                "虚拟数据集验证"
            ],
            "_index": 92
        },
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031v1",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031v1",
            "code_links": [],
            "headline_zh": "提出通过优化网络秩来提升隐式神经表示的高频信号保真度，挑战传统架构限制观点。",
            "summary_zh": "基于普通多层感知机（MLPs）的隐式神经表示（INRs）被广泛认为无法表示高频内容，这引导研究转向坐标嵌入或特殊激活函数等架构干预。本文挑战了普通MLPs的低频偏差是学习高频内容的内在架构限制这一观点，认为这是训练过程中稳定秩退化的症状。我们通过实验证明，在训练期间调节网络的秩显著提高了学习信号的保真度，使即使是简单的MLP架构也具有表达力。大量实验表明，使用像Muon这样的优化器，具有高秩、近正交更新，能持续增强INRs架构，甚至超越简单的ReLU MLPs。这些显著改进适用于多种领域，包括自然和医学图像以及新视角合成，与先前最先进方法相比，PSNR提升高达9 dB。我们的项目页面包含代码和实验结果，可在https://muon-inrs.github.io访问。",
            "intro_zh": [
                "现有方法认为普通MLPs因架构限制无法表示高频信号，依赖复杂干预如坐标嵌入。",
                "论文提出高频学习受限源于训练中秩退化，通过优化器如Muon调节秩来提升保真度。",
                "实验显示该方法在图像和新视角合成中PSNR提升高达9 dB，验证了简单MLPs的潜力。"
            ],
            "method_zh": "论文整体框架基于隐式神经表示（INRs），使用普通多层感知机（MLPs）作为基础架构。关键技术创新点在于挑战传统观点，将高频学习限制归因于训练过程中的稳定秩退化，而非MLPs的固有架构缺陷。为此，提出通过优化器（如Muon）调节网络秩，实现高秩、近正交的权重更新，从而增强信号保真度。与现有方法的主要区别在于，不依赖额外的架构干预（如坐标嵌入或特殊激活函数），而是通过优化训练过程本身来提升性能，使简单MLP架构也能有效表示高频内容。",
            "application_zh": "该研究在计算机视觉和人工智能领域具有广泛潜在应用，包括自然图像处理、医学图像分析以及新视角合成等任务。通过提升隐式神经表示的高频保真度，可应用于高质量图像重建、3D场景表示和虚拟现实，为实际应用提供更精确和高效的解决方案。",
            "highlight_zh": "实验结果显示，使用优化器如Muon调节秩后，在多种领域（自然图像、医学图像、新视角合成）中，PSNR提升高达9 dB，显著超越先前最先进方法，验证了秩优化对提升INRs性能的有效性。",
            "tags_zh": [
                "隐式神经表示",
                "多层感知机",
                "秩优化",
                "高频信号",
                "图像重建",
                "新视角合成",
                "优化器设计",
                "计算机视觉"
            ],
            "_index": 93
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014v1",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "21 pages, 13 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364v1",
            "code_links": [],
            "headline_zh": "提出UNITE统一语义Transformer，以单一模型解决3D场景理解中的多任务分割与属性预测问题。",
            "summary_zh": "整体3D场景理解涉及捕获和解析非结构化3D环境。由于现实世界的固有复杂性，现有模型主要被开发并局限于任务特定。我们引入了UNITE，一种用于3D场景理解的统一语义Transformer，这是一种新颖的前馈神经网络，将多种3D语义任务统一在单一模型中。我们的模型以完全端到端的方式处理未见过的场景，仅需几秒钟即可推断完整的3D语义几何。我们的方法能够直接从RGB图像预测多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征，以及功能性和关节性。该方法通过结合2D蒸馏进行训练，严重依赖自监督，并利用新颖的多视图损失设计来确保3D视图一致性。我们证明UNITE在多个不同语义任务上实现了最先进的性能，甚至在许多情况下超越了任务特定模型，超过了基于真实3D几何操作的方法。请访问项目网站unite-page.github.io。",
            "intro_zh": [
                "现有3D场景理解模型多为任务特定，难以处理现实世界的复杂性和多样性，限制了模型的泛化能力和应用范围。",
                "论文提出UNITE统一语义Transformer，通过单一模型整合多种3D语义任务，利用2D蒸馏和多视图损失实现端到端预测。",
                "实验表明，UNITE在多个语义任务上达到最先进性能，超越任务特定模型，甚至在真实3D几何方法上表现更优。"
            ],
            "method_zh": "UNITE是一种基于Transformer的前馈神经网络，整体框架以RGB图像为输入，通过端到端方式直接预测3D语义几何。关键技术创新点包括：统一多任务学习架构，将3D场景分割、实例嵌入、开放词汇特征等功能整合；采用2D蒸馏和自监督训练策略，结合新颖的多视图损失确保3D视图一致性。与现有方法的主要区别在于，它避免了任务特定模型的局限性，通过单一模型处理多种语义属性，提高了效率和泛化能力，同时不依赖真实3D几何输入。",
            "application_zh": "该研究在机器人导航、自动驾驶、增强现实和智能监控等领域具有潜在应用价值，能够提升系统对复杂3D环境的理解和交互能力，促进更智能的感知和决策。",
            "highlight_zh": "UNITE在多个3D语义任务上实现最先进性能，包括场景分割和实例预测，超越任务特定模型，并在许多情况下优于基于真实3D几何的方法，展示了其高效和强大的泛化能力。",
            "tags_zh": [
                "3D场景理解",
                "统一语义Transformer",
                "多任务学习",
                "2D蒸馏",
                "自监督训练",
                "多视图一致性",
                "端到端预测",
                "RGB图像处理"
            ],
            "_index": 94
        },
        {
            "title": "Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025",
            "authors": [
                "Ruanqianqian Huang",
                "Avery Reyna",
                "Sorin Lerner",
                "Haijun Xia",
                "Brian Hempel"
            ],
            "arxiv_id": "2512.14012v1",
            "summary": "The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14012v1",
            "code_links": [],
            "headline_zh": "提出CaDyT方法，基于差分因果模型与高斯过程推理，解决动态系统中连续时间因果发现难题。",
            "summary_zh": "现实世界系统根据其潜在因果关系在连续时间内演化，但其动态通常未知。现有学习方法通常要么离散化时间——导致在非规则采样数据上性能不佳——要么忽略底层因果关系。我们提出CaDyT，一种用于动态系统因果发现的新方法，同时应对这两个挑战。与使用离散时间动态贝叶斯网络建模问题的最先进因果发现方法不同，我们的公式基于差分因果模型，该模型允许对系统的连续性质进行更温和的假设建模。CaDyT利用精确的高斯过程推理来建模连续时间动态，这更符合底层动态过程。我们提出了一种实用的实例化方法，通过由算法马尔可夫条件和最小描述长度原则指导的贪婪搜索来识别因果结构。我们的实验表明，CaDyT在规则和非规则采样数据上均优于最先进方法，发现的因果网络更接近真实的底层动态。",
            "intro_zh": [
                "现有方法常离散化时间或忽略因果关系，难以处理非规则采样数据与连续动态。",
                "CaDyT基于差分因果模型，利用高斯过程推理建模连续时间动态，通过贪婪搜索识别结构。",
                "实验显示CaDyT在规则与非规则采样数据上均优于现有方法，更接近真实动态。"
            ],
            "method_zh": "CaDyT的整体框架基于差分因果模型，通过高斯过程推理精确建模连续时间动态，避免了离散化带来的误差。关键技术创新在于结合算法马尔可夫条件和最小描述长度原则指导的贪婪搜索，实现因果结构识别。与现有方法的主要区别在于：不同于基于离散时间动态贝叶斯网络的方法，CaDyT直接处理连续时间，更符合真实系统演化；同时，差分因果模型允许更温和的假设，提升了在非规则采样数据上的鲁棒性。",
            "application_zh": "该研究可应用于复杂动态系统的因果分析，如生物医学信号处理、金融时间序列建模、机器人控制等领域，有助于揭示系统内在机制，提升预测与干预能力。",
            "highlight_zh": "CaDyT在规则和非规则采样数据上的实验均显著优于现有方法，因果网络发现更准确，验证了其在连续时间动态建模中的优越性。",
            "tags_zh": [
                "因果发现",
                "动态系统",
                "连续时间建模",
                "高斯过程",
                "差分因果模型",
                "算法马尔可夫条件",
                "最小描述长度"
            ],
            "_index": 95
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001v1",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by IROS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001v1",
            "code_links": [
                {
                    "url": "https://github.com/Tompson11/claim",
                    "type": "github"
                }
            ],
            "headline_zh": "提出渐进模糊课程学习，模仿人类视觉发育过程以提升卷积神经网络的泛化与鲁棒性。",
            "summary_zh": "人类视觉系统能出色适应输入分布变化，而现代卷积神经网络（CNNs）在此方面仍有不足。受人类视觉发育轨迹启发，本文提出一种渐进模糊课程学习方法来提升CNNs的泛化和鲁棒性。人类婴儿出生时视觉敏锐度较差，逐渐发展出感知细节的能力。模仿这一过程，我们在训练初期对CNNs使用高度模糊的图像，并随着训练进展逐步减少模糊程度。这种方法促使网络优先关注全局结构而非高频伪影，从而提升对分布偏移和噪声输入的鲁棒性。与先前认为早期模糊会造成刺激缺陷并不可逆损害模型性能的观点不同，我们发现早期模糊能增强泛化能力，对域内精度影响极小。实验表明，相比无模糊的标准训练，所提方法在CIFAR-10-C数据集上平均腐蚀误差（mCE）降低达8.30%，在ImageNet-100-C数据集上降低4.43%。与静态模糊增强（在整个训练中随机应用模糊图像）不同，我们的方法遵循结构化渐进过程，在不同数据集上均取得一致增益。此外，该方法可与其他增强技术（如CutMix和MixUp）互补，并提升对常见攻击方法的自然和对抗鲁棒性。代码已开源。",
            "intro_zh": [
                "核心问题：现代卷积神经网络在适应输入分布变化方面表现不佳，缺乏人类视觉系统的鲁棒性，现有方法如静态模糊增强效果有限。",
                "方法要点：模仿人类视觉发育过程，提出渐进模糊课程学习，训练初期使用高度模糊图像，逐步减少模糊以引导网络学习全局结构。",
                "实验或效果：在CIFAR-10-C和ImageNet-100-C数据集上，平均腐蚀误差显著降低，泛化能力提升，且与现有增强技术兼容。"
            ],
            "method_zh": "论文提出一种渐进模糊课程学习框架，整体框架基于标准卷积神经网络训练流程，但引入动态模糊策略。关键技术创新点在于模仿人类视觉发育的渐进过程：训练初期使用高斯模糊等操作生成高度模糊图像作为输入，随着训练轮次增加，逐步降低模糊强度（如减小模糊核大小或标准差），直至最终使用清晰图像。这种方法的核心是结构化渐进，而非随机应用模糊。与现有方法的主要区别在于：不同于静态模糊增强（在整个训练中随机混合模糊和清晰图像），本方法遵循明确的课程顺序，从模糊到清晰，更贴合生物发育原理；同时，它挑战了早期模糊会损害性能的传统观点，通过实验证明早期模糊能促进泛化学习。",
            "application_zh": "该研究可应用于计算机视觉领域中对鲁棒性要求高的场景，如自动驾驶中的图像识别（需处理天气变化、噪声干扰）、医疗影像分析（应对设备差异或图像质量波动）、安防监控（适应光照和视角变化）以及增强现实系统。通过提升模型对分布偏移和噪声的鲁棒性，有助于在实际部署中提高可靠性和安全性。",
            "highlight_zh": "实验显示，渐进模糊课程学习在CIFAR-10-C数据集上平均腐蚀误差（mCE）降低达8.30%，在ImageNet-100-C数据集上降低4.43%，显著优于无模糊标准训练。该方法还提升了对抗鲁棒性，与CutMix、MixUp等增强技术结合时效果更佳，验证了其泛化能力和实际应用价值。",
            "tags_zh": [
                "渐进模糊课程学习",
                "人类视觉发育模仿",
                "卷积神经网络鲁棒性",
                "图像表示学习",
                "分布偏移适应",
                "对抗鲁棒性",
                "数据增强",
                "泛化能力提升"
            ],
            "_index": 96
        },
        {
            "title": "On the Hardness of Conditional Independence Testing In Practice",
            "authors": [
                "Zheng He",
                "Roman Pogodin",
                "Yazhe Li",
                "Namrata Deka",
                "Arthur Gretton",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.14000v1",
            "summary": "Tests of conditional independence (CI) underpin a number of important problems in machine learning and statistics, from causal discovery to evaluation of predictor fairness and out-of-distribution robustness. Shah and Peters (2020) showed that, contrary to the unconditional case, no universally finite-sample valid test can ever achieve nontrivial power. While informative, this result (based on \"hiding\" dependence) does not seem to explain the frequent practical failures observed with popular CI tests. We investigate the Kernel-based Conditional Independence (KCI) test - of which we show the Generalized Covariance Measure underlying many recent tests is nearly a special case - and identify the major factors underlying its practical behavior. We highlight the key role of errors in the conditional mean embedding estimate for the Type-I error, while pointing out the importance of selecting an appropriate conditioning kernel (not recognized in previous work) as being necessary for good test power but also tending to inflate Type-I error.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Published at NeurIPS 2025: https://openreview.net/forum?id=Tn1M71PDfF",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14000v1",
            "code_links": [],
            "headline_zh": "提出TiCard框架，通过可部署的仅解释残差学习解决数据库基数估计的部署难题",
            "summary_zh": "基数估计是基于成本的查询优化的关键瓶颈，但可部署的改进仍然困难：经典估计器忽略了相关性，而学习型估计器通常需要特定于工作负载的训练流程并侵入性地集成到优化器中。本文提出了TiCard，一个低侵入性、基于校正的框架，它增强（而非替换）数据库的原生估计器。TiCard使用仅解释特征学习乘法残差校正，并仅使用解释分析进行离线标签。我们研究了两种实际实例化：（i）用于亚毫秒推理的梯度提升回归器，以及（ii）TabPFN，一种上下文表格基础模型，通过刷新小型参考集而无需梯度重新训练来适应。在TiDB上使用TPCH和连接顺序基准测试，在低跟踪设置中（总共263次执行；157次用于学习），TiCard显著提高了操作员级别的尾部准确性：P90 Q误差从312.85（原生）降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），而仅连接策略保持了近乎完美的中位数行为。我们将TiCard定位为专注于可部署性的AI4DB构建块：明确的范围、保守的集成策略以及从离线校正到优化器内使用的集成路线图。",
            "intro_zh": [
                "核心问题：基数估计是查询优化的瓶颈，经典方法忽略相关性，学习型方法部署困难，需要侵入式集成。",
                "方法要点：提出TiCard框架，使用仅解释特征学习残差校正，增强而非替换原生估计器，实现低侵入性部署。",
                "实验或效果：在TiDB上测试，TiCard显著降低尾部Q误差，P90从312.85降至13.69，P99从37,974.37降至3,416.50。"
            ],
            "method_zh": "TiCard是一个基于校正的框架，整体框架包括使用EXPLAIN-only特征（如查询计划结构）学习乘法残差，以增强数据库原生估计器。关键技术创新点在于仅依赖EXPLAIN特征进行推理，避免侵入优化器，并使用EXPLAIN ANALYZE进行离线标签生成。与现有方法的主要区别在于：它不替换原生估计器，而是作为校正层，支持两种实例化——梯度提升回归器（GBR）用于快速推理，以及TabPFN基础模型用于上下文适应，无需重新训练。",
            "application_zh": "该研究应用于数据库管理系统中的查询优化，特别是基数估计场景，可提升TPCH、Join Order Benchmark等基准测试的性能，实际价值在于为AI4DB提供可部署的构建块，支持从离线校正逐步集成到在线优化器，降低部署门槛。",
            "highlight_zh": "在低跟踪设置下，TiCard显著改善尾部准确性：P90 Q误差从原生312.85降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），同时保持近乎完美的中位数行为，验证了框架的有效性和可部署性。",
            "tags_zh": [
                "基数估计",
                "查询优化",
                "残差学习",
                "可部署AI",
                "数据库增强",
                "梯度提升回归",
                "表格基础模型",
                "AI4DB"
            ],
            "_index": 97
        },
        {
            "title": "Maximum Mean Discrepancy with Unequal Sample Sizes via Generalized U-Statistics",
            "authors": [
                "Aaron Wei",
                "Milad Jalali",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.13997v1",
            "summary": "Existing two-sample testing techniques, particularly those based on choosing a kernel for the Maximum Mean Discrepancy (MMD), often assume equal sample sizes from the two distributions. Applying these methods in practice can require discarding valuable data, unnecessarily reducing test power. We address this long-standing limitation by extending the theory of generalized U-statistics and applying it to the usual MMD estimator, resulting in new characterization of the asymptotic distributions of the MMD estimator with unequal sample sizes (particularly outside the proportional regimes required by previous partial results). This generalization also provides a new criterion for optimizing the power of an MMD test with unequal sample sizes. Our approach preserves all available data, enhancing test accuracy and applicability in realistic settings. Along the way, we give much cleaner characterizations of the variance of MMD estimators, revealing something that might be surprising to those in the area: while zero MMD implies a degenerate estimator, it is sometimes possible to have a degenerate estimator with nonzero MMD as well; we give a construction and a proof that it does not happen in common situations.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13997v1",
            "code_links": [],
            "headline_zh": "提出基于样条的实时集体车道检测融合算法，以扩展自动驾驶车辆在传感器受限或高精度地图缺失场景下的感知范围。",
            "summary_zh": "全面的环境感知对于自动驾驶车辆的安全运行至关重要，需要检测动态道路使用者和静态对象如交通标志或车道，以支持安全运动规划。然而，由于传感器范围有限、遮挡和弯道等因素，在许多情况下无法实现对其他对象或车道的完整感知。在无法精确定位或没有高精度地图的道路场景中，自动驾驶车辆必须仅依赖其感知的道路信息。因此，通过车对车通信利用集体感知扩展本地感知能力是一种有前景的策略，但尚未在车道检测中得到探索。为此，我们提出了一种实时可行的集体车道感知方法，使用基于样条的估计来预测未检测到的道路段。我们在多种情况和道路类型下评估了所提出的融合算法，实现了实时能力，并将感知范围扩展了高达200%。",
            "intro_zh": [
                "现有车道检测方法受限于传感器范围、遮挡和弯道，导致感知不完整，尤其在无高精度地图或定位不准时，自动驾驶车辆面临安全风险。",
                "论文提出基于样条的集体感知融合算法，通过车对车通信整合多车数据，实时估计未检测道路段，以扩展感知范围。",
                "实验表明，该方法在多种道路场景下实现实时处理，感知范围提升高达200%，显著增强了自动驾驶系统的环境感知能力。"
            ],
            "method_zh": "论文提出CoLD Fusion算法，整体框架基于车对车通信实现集体感知，核心是使用样条曲线对未检测车道段进行估计和融合。关键技术创新点在于结合实时样条拟合与多源数据融合，优化了计算效率，确保在动态环境中快速响应。与现有方法的主要区别在于首次将集体感知应用于车道检测，通过通信扩展本地感知，而非仅依赖单一车辆传感器或静态地图。",
            "application_zh": "该研究主要应用于自动驾驶领域，特别是在传感器受限、遮挡严重或缺乏高精度地图的城市和乡村道路场景中，通过集体感知提升车道检测的可靠性和安全性，支持更稳健的运动规划和决策。",
            "highlight_zh": "实验结果显示，CoLD Fusion算法在多种道路类型下均能实现实时处理，感知范围扩展高达200%，有效克服了传统方法的局限性，显著提升了自动驾驶车辆在复杂环境中的感知能力。",
            "tags_zh": [
                "集体感知",
                "车道检测",
                "样条估计",
                "车对车通信",
                "实时融合",
                "自动驾驶",
                "环境感知",
                "传感器融合"
            ],
            "_index": 98
        },
        {
            "title": "Universal Reasoning Model",
            "authors": [
                "Zitian Gao",
                "Lynx Chen",
                "Yihao Xiao",
                "He Xing",
                "Ran Tao",
                "Haoming Luo",
                "Joey Zhou",
                "Bryan Dai"
            ],
            "arxiv_id": "2512.14693v1",
            "summary": "Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14354v1",
            "code_links": [],
            "headline_zh": "提出基于沙普利值优化的自解释框架，以增强视觉模型的可解释性并保持性能。",
            "summary_zh": "深度神经网络在各种领域表现出色，但其决策过程仍不透明。尽管许多解释方法致力于揭示深度神经网络的模糊性，但它们存在显著局限性：事后解释方法往往难以忠实反映模型行为，而自解释神经网络因其专门架构设计而牺牲了性能和兼容性。为解决这些挑战，我们提出了一种新颖的自解释框架，在训练过程中将沙普利值估计作为辅助任务集成，实现了两个关键进展：1）将模型预测分数公平分配给图像块，确保解释与模型的决策逻辑内在一致；2）通过微小的结构修改增强可解释性，同时保持模型性能和兼容性。在多个基准测试上的广泛实验表明，我们的方法实现了最先进的可解释性。",
            "intro_zh": [
                "现有方法不足：事后解释方法难以忠实反映模型行为，自解释神经网络牺牲性能和兼容性。",
                "方法要点：提出自解释框架，集成沙普利值估计作为辅助任务，实现公平分配预测分数。",
                "实验效果：在多个基准测试中实现最先进的可解释性，保持模型性能。"
            ],
            "method_zh": "论文提出一种自解释框架，整体框架在训练过程中集成沙普利值估计作为辅助任务。关键技术创新点包括：通过优化沙普利值实现模型预测分数到图像块的公平分配，确保解释与决策逻辑内在一致；采用微小的结构修改，避免对模型性能和兼容性造成显著影响。与现有方法的主要区别在于：不同于事后解释方法，该方法在训练阶段直接优化可解释性；相比传统自解释神经网络，它通过轻量级设计保持高性能和兼容性。",
            "application_zh": "该研究可应用于医疗影像分析、自动驾驶、安防监控等领域，通过增强视觉模型的可解释性，帮助用户理解模型决策依据，提升系统透明度和可信度，支持高风险决策场景。",
            "highlight_zh": "在多个基准测试中，该方法实现了最先进的可解释性，同时保持模型性能，通过公平分配预测分数和微小结构修改，有效解决了现有方法的局限性。",
            "tags_zh": [
                "可解释人工智能",
                "沙普利值",
                "自解释神经网络",
                "视觉模型",
                "深度学习",
                "模型透明度",
                "辅助任务优化"
            ],
            "_index": 99
        },
        {
            "title": "Native and Compact Structured Latents for 3D Generation",
            "authors": [
                "Jianfeng Xiang",
                "Xiaoxue Chen",
                "Sicheng Xu",
                "Ruicheng Wang",
                "Zelong Lv",
                "Yu Deng",
                "Hongyuan Zhu",
                "Yue Dong",
                "Hao Zhao",
                "Nicholas Jing Yuan",
                "Jiaolong Yang"
            ],
            "arxiv_id": "2512.14692v1",
            "summary": "Recent advancements in 3D generative modeling have significantly improved the generation realism, yet the field is still hampered by existing representations, which struggle to capture assets with complex topologies and detailed appearance. This paper present an approach for learning a structured latent representation from native 3D data to address this challenge. At its core is a new sparse voxel structure called O-Voxel, an omni-voxel representation that encodes both geometry and appearance. O-Voxel can robustly model arbitrary topology, including open, non-manifold, and fully-enclosed surfaces, while capturing comprehensive surface attributes beyond texture color, such as physically-based rendering parameters. Based on O-Voxel, we design a Sparse Compression VAE which provides a high spatial compression rate and a compact latent space. We train large-scale flow-matching models comprising 4B parameters for 3D generation using diverse public 3D asset datasets. Despite their scale, inference remains highly efficient. Meanwhile, the geometry and material quality of our generated assets far exceed those of existing models. We believe our approach offers a significant advancement in 3D generative modeling.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://microsoft.github.io/TRELLIS.2/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14692v1",
            "code_links": [],
            "headline_zh": "提出混合高斯溅射框架，通过静态-动态分解策略解决动态新视角合成中模型冗余和效率低下的问题。",
            "summary_zh": "动态新视角合成对于创造沉浸式体验至关重要。现有方法通过引入带有隐式变形场或非区分性时变参数的3D高斯溅射，超越了基于NeRF的方法。然而，由于模型复杂度过高和参数冗余，它们导致模型体积庞大、渲染速度缓慢，在资源受限设备上效率低下。为获得更高效、参数冗余更少的模型，本文提出混合高斯溅射，这是一个紧凑高效的框架，旨在在统一表示中显式解耦场景的静态和动态区域。HGS的核心创新在于静态-动态分解策略，该策略利用径向基函数对高斯基元进行建模。具体而言，对于动态区域，我们使用时变RBF有效捕捉时间变化并处理场景突变；对于静态区域，我们通过共享时间不变参数减少冗余。此外，我们引入针对显式模型的两阶段训练策略，以增强静态-动态边界的时间一致性。实验结果表明，我们的方法将模型大小减少了高达98%，在单个RTX 3090 GPU上以4K分辨率实现高达125 FPS的实时渲染。在RTX 3050上，它还能在1352*1014分辨率下维持160 FPS，并已集成到VR系统中。此外，HGS在渲染质量上与最先进方法相当，同时在高频细节和场景突变方面显著提高了视觉保真度。",
            "intro_zh": [
                "现有动态新视角合成方法因模型复杂和参数冗余，导致模型体积大、渲染慢，难以实时应用。",
                "提出混合高斯溅射框架，通过静态-动态分解策略，使用径向基函数分别建模动态和静态区域。",
                "实验显示模型大小减少高达98%，渲染速度达125 FPS，在VR系统中实现高效集成。"
            ],
            "method_zh": "HGS的整体框架是一个基于3D高斯溅射的紧凑动态新视角合成系统。关键技术创新包括静态-动态分解策略，该策略利用径向基函数对高斯基元进行建模：动态区域使用时变RBF捕捉时间变化，静态区域共享时间不变参数以减少冗余。此外，引入两阶段训练策略以增强静态-动态边界的时间一致性。与现有方法的主要区别在于显式解耦静态和动态区域，避免了隐式变形场或非区分性时变参数带来的过度复杂性和参数冗余，从而实现了更高效的模型表示。",
            "application_zh": "该研究在虚拟现实、增强现实和沉浸式媒体中具有广泛应用潜力，特别是在资源受限设备上实现实时动态场景渲染，提升用户体验和系统效率。",
            "highlight_zh": "模型大小减少高达98%，在RTX 3090上以4K分辨率实现125 FPS实时渲染，RTX 3050上维持160 FPS，已集成到VR系统，渲染质量与最先进方法相当。",
            "tags_zh": [
                "动态新视角合成",
                "3D高斯溅射",
                "静态-动态分解",
                "径向基函数",
                "实时渲染",
                "模型压缩",
                "虚拟现实",
                "高效计算"
            ],
            "_index": 100
        },
        {
            "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
            "authors": [
                "Sicheng Xu",
                "Guojun Chen",
                "Jiaolong Yang",
                "Yizhong Zhang",
                "Yu Deng",
                "Steve Lin",
                "Baining Guo"
            ],
            "arxiv_id": "2512.14677v1",
            "summary": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14677v1",
            "code_links": [],
            "headline_zh": "提出基于贝叶斯优化的近似模型预测控制微调方法，无需重新训练神经网络即可适应新系统实例和成本函数。",
            "summary_zh": "近似模型预测控制（AMPC）旨在用神经网络模仿MPC的行为，从而避免在运行时求解昂贵的优化问题。然而，在部署过程中，通常需要对底层MPC的参数进行微调，这往往需要反复生成新数据集并重新训练神经网络，使得AMPC不实用。最近的研究通过利用MPC优化问题的近似灵敏度来适应AMPC而无需重新训练，但当前这种适应必须手动完成，对于高维系统来说既费力又不直观。为解决这一问题，我们提出使用贝叶斯优化基于实验数据来调整AMPC策略的参数。通过将基于模型的控制与直接局部学习相结合，我们的方法在硬件上实现了优于名义AMPC的性能，且实验量最小。这使得AMPC能够自动且数据高效地适应新系统实例，并微调到难以直接在MPC中实现的成本函数。我们在硬件实验中展示了所提方法，包括倒立摆的摆起动作和欠驱动平衡独轮机器人的偏航控制，这是一个具有挑战性的控制问题。",
            "intro_zh": [
                "现有AMPC在部署时需手动微调参数，过程繁琐且不直观，尤其对高维系统不实用。",
                "提出结合贝叶斯优化与AMPC，利用实验数据自动调整策略参数，实现无需重新训练的适应。",
                "在倒立摆和独轮机器人硬件实验中，方法以最小实验量显著提升性能，优于名义AMPC。"
            ],
            "method_zh": "论文提出一个整体框架，将近似模型预测控制（AMPC）与贝叶斯优化（BO）相结合。核心思想是利用BO基于少量实验数据自动搜索AMPC策略的最优参数，而无需重新训练神经网络。关键技术创新点在于将模型基控制（通过AMPC近似MPC）与直接局部学习（通过BO优化参数）融合，实现数据高效的适应。与现有方法的主要区别在于：现有方法依赖手动调整或基于近似灵敏度的适应，而本方法自动化参数微调过程，避免了重新训练神经网络的成本，并能处理难以直接实现的成本函数。",
            "application_zh": "该研究适用于机器人控制、自动化系统和实时优化领域，特别是在需要快速适应新硬件实例或复杂成本函数的场景中，如无人机导航、工业机械臂和智能车辆控制，具有提升系统鲁棒性和降低部署成本的实际价值。",
            "highlight_zh": "在倒立摆摆起和欠驱动独轮机器人偏航控制的硬件实验中，所提方法以最小实验量实现了优于名义AMPC的性能，成功适应新系统实例并优化了难以直接实现的成本函数，验证了其自动化和数据高效的优势。",
            "tags_zh": [
                "近似模型预测控制",
                "贝叶斯优化",
                "神经网络微调",
                "机器人控制",
                "自适应控制",
                "硬件实验",
                "数据高效学习",
                "优化参数调整"
            ],
            "_index": 101
        },
        {
            "title": "ART: Articulated Reconstruction Transformer",
            "authors": [
                "Zizhang Li",
                "Cheng Zhang",
                "Zhengqin Li",
                "Henry Howard-Jenkins",
                "Zhaoyang Lv",
                "Chen Geng",
                "Jiajun Wu",
                "Richard Newcombe",
                "Jakob Engel",
                "Zhao Dong"
            ],
            "arxiv_id": "2512.14671v1",
            "summary": "We introduce ART, Articulated Reconstruction Transformer -- a category-agnostic, feed-forward model that reconstructs complete 3D articulated objects from only sparse, multi-state RGB images. Previous methods for articulated object reconstruction either rely on slow optimization with fragile cross-state correspondences or use feed-forward models limited to specific object categories. In contrast, ART treats articulated objects as assemblies of rigid parts, formulating reconstruction as part-based prediction. Our newly designed transformer architecture maps sparse image inputs to a set of learnable part slots, from which ART jointly decodes unified representations for individual parts, including their 3D geometry, texture, and explicit articulation parameters. The resulting reconstructions are physically interpretable and readily exportable for simulation. Trained on a large-scale, diverse dataset with per-part supervision, and evaluated across diverse benchmarks, ART achieves significant improvements over existing baselines and establishes a new state of the art for articulated object reconstruction from image inputs.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://kyleleey.github.io/ART/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14671v1",
            "code_links": [],
            "headline_zh": "提出一种几何任务空间端口哈密顿公式，用于冗余机械臂的阻抗控制和稳定性设计。",
            "summary_zh": "本文提出了一种新颖的几何端口哈密顿公式，用于描述执行微分运动学任务η=J(q)q̇的冗余机械臂，其中q是配置流形上的点，η是任务空间的速度类变量，J(q)是表示任务的线性映射（如经典解析或几何机械臂雅可比矩阵）。该模型源自对规范哈密顿动力学的坐标变换，将标准哈密顿动量变量分解为任务空间动量变量和零空间动量变量。文中强调了该模型的性质及其与现有拉格朗日公式的关系。最后，应用该模型于互联与阻尼分配无源性控制设计，在仿真中稳定并塑造了7自由度Emika Panda机器人的阻抗。",
            "intro_zh": [
                "核心问题：现有冗余机械臂控制方法在处理任务空间动力学时，常缺乏几何结构或能量守恒的明确表示，导致阻抗控制和稳定性设计复杂。",
                "方法要点：通过坐标变换将哈密顿动力学分解为任务空间和零空间动量，构建几何端口哈密顿公式，以统一描述机械臂的动力学和任务执行。",
                "实验或效果：在7自由度机器人仿真中，应用该模型成功实现了阻抗控制和稳定性提升，验证了方法的有效性和实用性。"
            ],
            "method_zh": "论文提出一种几何端口哈密顿公式，整体框架基于对冗余机械臂的微分运动学任务η=J(q)q̇进行建模。关键技术创新点是通过坐标变换，将标准哈密顿动量变量分解为任务空间动量变量和零空间动量变量，从而在几何结构上分离任务相关和冗余自由度动力学。与现有方法的主要区别在于，该方法直接基于哈密顿动力学，提供了更自然的能量守恒和无源性分析，便于与互联与阻尼分配无源性控制等先进控制策略结合，而传统拉格朗日公式可能缺乏这种几何直观性或能量视角。",
            "application_zh": "该研究可应用于冗余机械臂的精确控制和阻抗调节，如工业自动化、医疗机器人或服务机器人中需要柔顺交互和任务优化的场景，提升机器人的动态性能和稳定性。",
            "highlight_zh": "在仿真实验中，应用提出的几何端口哈密顿公式于7自由度Emika Panda机器人，通过互联与阻尼分配无源性控制成功实现了阻抗的稳定和形状控制，展示了模型在冗余机械臂控制中的有效性和潜在性能提升。",
            "tags_zh": [
                "端口哈密顿系统",
                "冗余机械臂",
                "几何控制",
                "阻抗控制",
                "任务空间动力学",
                "无源性控制",
                "机器人仿真"
            ],
            "_index": 102
        },
        {
            "title": "WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields",
            "authors": [
                "Gabriele Accarino",
                "Viviana Acquaviva",
                "Sara Shamekh",
                "Duncan Watson-Parris",
                "David Lawrence"
            ],
            "arxiv_id": "2512.14656v1",
            "summary": "We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components derived from these coefficients: Magnitude, which quantifies similarities in the energy distribution of the coefficients, i.e., the intensity of the field; Displacement, which captures spatial shift by comparing the centers of mass of normalized energy distributions; and Structure, which assesses pattern organization independent of location and amplitude. Each component yields a scale-specific similarity score ranging from 0 (no similarity) to 1 (perfect similarity), which are then combined across scales to produce an overall similarity measure. We first evaluate WaveSim using synthetic test cases, applying controlled spatial and temporal perturbations to systematically assess its sensitivity and expected behavior. We then demonstrate its applicability to physically relevant case studies of key modes of climate variability in Earth System Models. Traditional point-wise metrics lack a mechanism for attributing errors to physical scales or modes of dissimilarity. By operating in the wavelet domain and decomposing the signal along independent axes, WaveSim bypasses these limitations and provides an interpretable and diagnostically rich framework for assessing similarity in complex fields. Additionally, the WaveSim framework allows users to place emphasis on a specific scale or component, and lends itself to user-specific model intercomparison, model evaluation, and calibration and training of forecasting systems. We provide a PyTorch-ready implementation of WaveSim, along with all evaluation scripts, at: https://github.com/gabrieleaccarino/wavesim.",
            "categories": [
                "physics.ao-ph",
                "cs.CV",
                "physics.data-an"
            ],
            "primary_category": "physics.ao-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14341v1",
            "code_links": [],
            "headline_zh": "提出TDAE框架以解决恶意图像编辑防御中跨模型可迁移性不足的问题。",
            "summary_zh": "近期研究表明，在输入图像中添加不可感知的扰动，在对抗基于扩散模型的恶意图像编辑系统方面展现出潜力，但现有方法在跨模型评估中可迁移性有限。为此，我们提出可迁移防御恶意图像编辑（TDAE），一种新颖的双模态框架，通过协调图像-文本优化增强图像对恶意编辑的免疫力。具体而言，在视觉防御层面，我们引入FlatGrad防御机制（FDM），将梯度正则化融入对抗目标，通过显式引导扰动朝向平坦最小值，增强对未见编辑模型的免疫鲁棒性。在文本增强保护方面，我们提出动态提示防御（DPD）的对抗优化范式，周期性优化文本嵌入，使免疫化图像的编辑结果与原始图像对齐，然后在优化嵌入下更新图像。通过对多样化嵌入的迭代对抗更新，DPD强制生成免疫化图像，寻求更广泛的免疫增强特征集，从而实现跨模型可迁移性。大量实验结果表明，我们的TDAE在内部和跨模型评估中，在减轻恶意编辑方面均达到最先进性能。",
            "intro_zh": [
                "现有方法在对抗恶意图像编辑时，跨模型可迁移性有限，难以泛化到未见编辑模型。",
                "提出TDAE框架，结合FDM的梯度正则化和DPD的动态文本优化，通过双模态协调增强免疫鲁棒性。",
                "实验显示TDAE在内部和跨模型评估中均实现最优性能，显著提升防御效果和可迁移性。"
            ],
            "method_zh": "TDAE是一个双模态框架，通过图像-文本协调优化增强图像免疫力。整体框架包括视觉防御和文本增强保护两部分：FDM在图像层面引入梯度正则化，引导扰动朝向平坦最小值以提升鲁棒性；DPD在文本层面动态优化嵌入，通过迭代对抗更新使免疫化图像与原始图像编辑结果对齐。关键创新在于结合平坦最小值和动态文本优化，与现有方法相比，TDAE强调跨模型可迁移性，通过双模态交互实现更广泛的免疫特征学习。",
            "application_zh": "该研究可应用于图像安全领域，如保护社交媒体、数字媒体内容免受恶意篡改，增强AI生成内容的可信度，适用于版权保护、身份验证和内容审核等场景。",
            "highlight_zh": "TDAE在内部和跨模型评估中均达到最先进性能，实验表明其能有效减轻恶意编辑，显著提升防御可迁移性，验证了双模态优化的有效性。",
            "tags_zh": [
                "恶意图像编辑防御",
                "跨模型可迁移性",
                "双模态优化",
                "梯度正则化",
                "动态提示防御",
                "扩散模型",
                "图像免疫力",
                "对抗攻击"
            ],
            "_index": 103
        },
        {
            "title": "Adaptable Segmentation Pipeline for Diverse Brain Tumors with Radiomic-guided Subtyping and Lesion-Wise Model Ensemble",
            "authors": [
                "Daniel Capellán-Martín",
                "Abhijeet Parida",
                "Zhifan Jiang",
                "Nishad Kulkarni",
                "Krithika Iyer",
                "Austin Tapp",
                "Syed Muhammad Anwar",
                "María J. Ledesma-Carbayo",
                "Marius George Linguraru"
            ],
            "arxiv_id": "2512.14648v1",
            "summary": "Robust and generalizable segmentation of brain tumors on multi-parametric magnetic resonance imaging (MRI) remains difficult because tumor types differ widely. The BraTS 2025 Lighthouse Challenge benchmarks segmentation methods on diverse high-quality datasets of adult and pediatric tumors: multi-consortium international pediatric brain tumor segmentation (PED), preoperative meningioma tumor segmentation (MEN), meningioma radiotherapy segmentation (MEN-RT), and segmentation of pre- and post-treatment brain metastases (MET). We present a flexible, modular, and adaptable pipeline that improves segmentation performance by selecting and combining state-of-the-art models and applying tumor- and lesion-specific processing before and after training. Radiomic features extracted from MRI help detect tumor subtype, ensuring a more balanced training. Custom lesion-level performance metrics determine the influence of each model in the ensemble and optimize post-processing that further refines the predictions, enabling the workflow to tailor every step to each case. On the BraTS testing sets, our pipeline achieved performance comparable to top-ranked algorithms across multiple challenges. These findings confirm that custom lesion-aware processing and model selection yield robust segmentations yet without locking the method to a specific network architecture. Our method has the potential for quantitative tumor measurement in clinical practice, supporting diagnosis and prognosis.",
            "categories": [
                "cs.CV",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 5 figures, 3 tables. Algorithm presented at MICCAI BraTS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14648v1",
            "code_links": [],
            "headline_zh": "提出基于轻量激光雷达的无人机导航系统优化与标准化评估方法，以解决稠密北方森林环境下的自主飞行挑战。",
            "summary_zh": "近年来，无人机在森林应用中的使用兴趣日益增长。尽管冠层以上飞行已达到高度自主性，但冠层下导航仍是一个重大挑战。自主无人机的使用可减轻数据收集负担，这推动了众多冠层下自主飞行解决方案的开发。然而，文献中的实验及其报告缺乏严谨性，很少报告测试森林的密度和难度，或进行多次飞行并报告成功率。本研究旨在基于轻量激光雷达，利用公开算法实现自主飞行的四旋翼无人机，并在真实森林环境中测试其行为。使用IPC路径规划器和LTA-OM SLAM算法，对四旋翼原型进行了严格实验。基于前33次飞行结果，进一步优化了原始系统。优化系统进行了60次飞行，总计93次测试飞行。优化系统在可靠性和飞行任务完成时间方面表现显著更好，在目标飞行速度1 m/s下，中等密度森林中成功率为12/15，稠密森林中为15/15；在2 m/s下，成功率分别为12/15和5/15。此外，提出了标准化测试设置和评估标准，以实现自主冠层下无人机系统性能的一致比较，增强可重复性，指导系统改进，并加速森林机器人学进展。",
            "intro_zh": [
                "现有方法在稠密森林冠层下自主飞行中缺乏严谨实验报告，如森林密度和成功率数据不足。",
                "论文基于轻量激光雷达和公开算法，构建无人机导航系统，并通过优化提升性能。",
                "优化系统在真实森林测试中显著提高成功率，并提出了标准化评估框架以促进领域发展。"
            ],
            "method_zh": "论文采用基于轻量激光雷达的四旋翼无人机平台，整体框架结合了IPC路径规划器和LTA-OM SLAM算法。关键技术创新点在于系统优化，通过初始33次飞行结果分析，调整参数或算法以增强可靠性和效率。与现有方法的主要区别在于强调实验严谨性和标准化评估，而非仅依赖算法创新，从而在稠密森林环境中实现更稳定的自主导航。",
            "application_zh": "该研究适用于森林监测、生态调查和资源管理等领域，通过自主无人机在稠密冠层下飞行，可高效收集数据，减少人工负担，提升森林机器人学的实际应用价值。",
            "highlight_zh": "优化系统在目标速度1 m/s下，中等密度森林成功率达12/15，稠密森林达15/15；速度提升至2 m/s时，成功率分别为12/15和5/15。总计93次飞行验证了性能提升，并建立了标准化测试标准。",
            "tags_zh": [
                "无人机导航",
                "激光雷达",
                "森林机器人学",
                "自主飞行",
                "SLAM算法",
                "路径规划",
                "稠密环境",
                "标准化评估"
            ],
            "_index": 104
        },
        {
            "title": "TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines",
            "authors": [
                "David Schulmeister",
                "Valentin Hartmann",
                "Lars Klein",
                "Robert West"
            ],
            "arxiv_id": "2512.14645v1",
            "summary": "Today, a lot of research on language models is focused on large, general-purpose models. However, many NLP pipelines only require models with a well-defined, small set of capabilities. While large models are capable of performing the tasks of those smaller models, they are simply not fast enough to process large amounts of data or offer real-time responses. Furthermore, they often use unnecessarily large amounts of energy, leading to sustainability concerns and problems when deploying them on battery-powered devices. In our work, we show how to train small models for such efficiency-critical applications. As opposed to many off-the-shelf NLP pipelines, our models use modern training techniques such as distillation, and offer support for low-resource languages. We call our models TiME (Tiny Monolingual Encoders) and comprehensively evaluate them on a range of common NLP tasks, observing an improved trade-off between benchmark performance on one hand, and throughput, latency and energy consumption on the other. Along the way, we show that distilling monolingual models from multilingual teachers is possible, and likewise distilling models with absolute positional embeddings from teachers with relative positional embeddings.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14645v1",
            "code_links": [],
            "headline_zh": "揭示Hopfield网络通过范数效率隐式学习图同构类，实现多项式样本复杂度",
            "summary_zh": "许多学习问题涉及对称性，虽然不变性可以内置到神经架构中，但在群结构数据上训练时也可能隐式出现。我们研究了经典Hopfield网络中的这一现象，并表明它们可以从小的随机样本中推断出图的完整同构类。我们的结果显示：(i) 图同构类可以在三维不变子空间中表示，(ii) 使用梯度下降最小化能量流（MEF）具有对范数效率解的隐式偏置，这支撑了学习同构类的多项式样本复杂度界限，以及(iii) 在多种学习规则下，参数随着样本量增长而收敛到不变子空间。这些发现共同突出了Hopfield网络中泛化的统一机制：学习中对范数效率的偏置驱动了在群结构数据下近似不变性的出现。",
            "intro_zh": [
                "核心问题：现有方法常显式构建不变性，但隐式学习机制在群结构数据中的效率和泛化能力尚不明确。",
                "方法要点：利用Hopfield网络，通过最小化能量流（MEF）的梯度下降，隐式偏置范数效率解，实现图同构类学习。",
                "实验或效果：网络能在三维不变子空间中表示同构类，样本复杂度为多项式，参数收敛到不变子空间。"
            ],
            "method_zh": "论文采用经典Hopfield网络作为整体框架，研究其在图同构类学习中的隐式偏置。关键技术创新点在于分析梯度下降最小化能量流（MEF）的过程，揭示其对范数效率解的隐式偏置，这驱动了不变子空间的收敛。与现有方法的主要区别在于，不依赖显式的不变性设计，而是通过优化过程自然涌现近似不变性，从而更高效地处理对称性数据。",
            "application_zh": "该研究可应用于图结构数据分析、模式识别和机器学习中的对称性处理，例如社交网络分析、化学分子结构分类，以及需要高效学习不变特征的领域，提升模型在群结构数据上的泛化能力。",
            "highlight_zh": "最重要的实验结果显示，Hopfield网络能从少量随机样本中学习图同构类，样本复杂度为多项式界限，且参数在多种学习规则下收敛到三维不变子空间，验证了隐式偏置对泛化的关键作用。",
            "tags_zh": [
                "Hopfield网络",
                "隐式偏置",
                "图同构",
                "不变子空间",
                "范数效率",
                "样本复杂度",
                "群结构数据",
                "梯度下降"
            ],
            "_index": 105
        },
        {
            "title": "AMD-HookNet++: Evolution of AMD-HookNet with Hybrid CNN-Transformer Feature Enhancement for Glacier Calving Front Segmentation",
            "authors": [
                "Fei Wu",
                "Marcel Dreier",
                "Nora Gourmelon",
                "Sebastian Wind",
                "Jianlin Zhang",
                "Thorsten Seehaus",
                "Matthias Braun",
                "Andreas Maier",
                "Vincent Christlein"
            ],
            "arxiv_id": "2512.14639v1",
            "summary": "The dynamics of glaciers and ice shelf fronts significantly impact the mass balance of ice sheets and coastal sea levels. To effectively monitor glacier conditions, it is crucial to consistently estimate positional shifts of glacier calving fronts. AMD-HookNet firstly introduces a pure two-branch convolutional neural network (CNN) for glacier segmentation. Yet, the local nature and translational invariance of convolution operations, while beneficial for capturing low-level details, restricts the model ability to maintain long-range dependencies. In this study, we propose AMD-HookNet++, a novel advanced hybrid CNN-Transformer feature enhancement method for segmenting glaciers and delineating calving fronts in synthetic aperture radar images. Our hybrid structure consists of two branches: a Transformer-based context branch to capture long-range dependencies, which provides global contextual information in a larger view, and a CNN-based target branch to preserve local details. To strengthen the representation of the connected hybrid features, we devise an enhanced spatial-channel attention module to foster interactions between the hybrid CNN-Transformer branches through dynamically adjusting the token relationships from both spatial and channel perspectives. Additionally, we develop a pixel-to-pixel contrastive deep supervision to optimize our hybrid model by integrating pixelwise metric learning into glacier segmentation. Through extensive experiments and comprehensive quantitative and qualitative analyses on the challenging glacier segmentation benchmark dataset CaFFe, we show that AMD-HookNet++ sets a new state of the art with an IoU of 78.2 and a HD95 of 1,318 m, while maintaining a competitive MDE of 367 m. More importantly, our hybrid model produces smoother delineations of calving fronts, resolving the issue of jagged edges typically seen in pure Transformer-based approaches.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1109/TGRS.2025.3642764",
            "journal_ref": "IEEE Transactions on Geoscience and Remote Sensing (2025)",
            "pdf_url": "https://arxiv.org/pdf/2512.14639v1",
            "code_links": [],
            "headline_zh": "提出Vector Prism框架，通过恢复SVG语义结构解决矢量图形动画自动化难题",
            "summary_zh": "可缩放矢量图形（SVG）是现代网页设计的核心，随着网络环境日益动态化，对其动画化的需求持续增长。尽管在代码生成和运动规划方面取得了进展，但自动化矢量图形动画对视觉语言模型（VLMs）仍然具有挑战性。VLMs经常错误处理SVG，因为视觉上连贯的部分通常被分割成低级形状，这些形状几乎无法指导哪些元素应该一起移动。本文介绍了一个框架，该框架恢复了可靠SVG动画所需的语义结构，并揭示了当前VLM系统忽略的缺失层。这是通过对多个弱部件预测进行统计聚合实现的，使系统能够从噪声预测中稳定推断语义。通过将SVG重新组织为语义组，我们的方法使VLMs能够生成更加连贯的动画。我们的实验表明，与现有方法相比取得了显著提升，这表明语义恢复是解锁稳健SVG动画并支持VLMs与矢量图形之间更可解释交互的关键步骤。",
            "intro_zh": [
                "现有视觉语言模型处理SVG时，常因低级形状碎片化而无法识别应一起移动的语义部件，导致动画不连贯。",
                "提出Vector Prism框架，通过统计聚合多个弱部件预测来恢复SVG的语义结构，并重组为语义组。",
                "实验显示，该方法在SVG动画生成上显著优于现有方法，实现了更连贯的动画效果和可解释的交互。"
            ],
            "method_zh": "Vector Prism框架的核心是通过语义恢复来增强SVG动画生成。整体框架包括：首先，从视觉语言模型获取多个弱部件预测；然后，通过统计聚合这些预测，稳定推断出SVG的语义结构；最后，将SVG重新组织为语义组，为动画生成提供高层指导。关键技术创新在于利用统计方法从噪声预测中恢复语义，解决了现有方法因低级形状碎片化而忽略语义层的问题。与现有方法的主要区别在于，它不直接依赖VLM的原始输出，而是通过语义恢复步骤，使VLM能够基于语义组生成更连贯的动画。",
            "application_zh": "该研究主要应用于网页设计和动态内容生成领域，可自动化生成SVG动画，提升网页交互性和用户体验。潜在价值包括简化动画制作流程、支持更复杂的矢量图形动画，以及促进视觉语言模型在图形处理中的实际应用。",
            "highlight_zh": "实验结果表明，Vector Prism框架在SVG动画生成任务上取得了显著提升，与现有方法相比，生成的动画更加连贯，语义恢复步骤是关键因素，支持了更可解释的模型交互。",
            "tags_zh": [
                "矢量图形动画",
                "语义结构恢复",
                "视觉语言模型",
                "统计聚合",
                "SVG处理",
                "网页设计自动化",
                "多模态交互"
            ],
            "_index": 106
        },
        {
            "title": "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation",
            "authors": [
                "Yash Vishe",
                "Eric Xue",
                "Xunyi Jiang",
                "Zachary Novack",
                "Junda Wu",
                "Julian McAuley",
                "Xin Xu"
            ],
            "arxiv_id": "2512.14629v1",
            "summary": "Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP). While some studies do consider MCP, they adopt inconsistent evaluation protocols and metrics, leading to unreliable and unfair comparisons. To address this gap, we introduce the first MCP evaluation benchmark, MuseCPBench, which covers four categories of musical facets and enables comprehensive comparisons across five representative music editing baselines. Through systematic analysis along musical facets, methods, and models, we identify consistent preservation gaps in current music editing methods and provide insightful explanations. We hope our findings offer practical guidance for developing more effective and reliable music editing strategies with strong MCP capability",
            "categories": [
                "cs.SD",
                "cs.AI"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14629v1",
            "code_links": [],
            "headline_zh": "提出双注意力引导噪声扰动免疫方法，以防御文本到图像扩散模型中的恶意编辑风险。",
            "summary_zh": "文本到图像扩散模型的进展通过文本提示改变了图像编辑方式，但也带来了因潜在滥用创建欺骗性或有害内容而引发的重大伦理挑战。现有防御方法试图通过嵌入不可感知的扰动来降低风险，但其在对抗恶意篡改方面的有效性有限。为解决此问题，我们提出了一种双注意力引导噪声扰动免疫方法，该方法添加不可感知的扰动以破坏模型的语义理解和生成过程。DANP在多个时间步上操作，通过动态阈值生成掩码来识别文本相关和不相关区域，从而操纵交叉注意力图和噪声预测过程。它减少相关区域的注意力，同时增加不相关区域的注意力，从而误导编辑朝向错误区域并保护目标内容。此外，我们的方法最大化注入噪声与模型预测噪声之间的差异，以进一步干扰生成。通过同时针对注意力和噪声预测机制，DANP展现出对恶意编辑的显著免疫力，大量实验证实我们的方法实现了最先进的性能。",
            "intro_zh": [
                "现有防御方法依赖不可感知扰动，但对抗恶意篡改效果有限，面临语义理解干扰不足的挑战。",
                "提出DANP方法，通过动态阈值生成掩码，操纵交叉注意力和噪声预测，误导编辑并保护目标区域。",
                "实验显示DANP在防御恶意编辑方面达到最先进性能，有效提升免疫力和生成干扰能力。"
            ],
            "method_zh": "DANP的整体框架基于文本到图像扩散模型，在多个时间步上添加不可感知噪声扰动。关键技术创新包括：使用动态阈值生成掩码来区分文本相关和不相关区域，从而精确操纵交叉注意力图；同时，通过最大化注入噪声与模型预测噪声的差异，干扰噪声预测过程。与现有方法的主要区别在于，DANP同时针对注意力和噪声预测两个核心机制，实现更全面的防御，而传统方法通常仅关注单一扰动或静态策略。",
            "application_zh": "该研究可应用于图像安全领域，如防止恶意编辑用于虚假新闻、深度伪造或有害内容生成，提升数字媒体的可信度和伦理合规性，具有实际价值于社交媒体、新闻审核和内容创作平台。",
            "highlight_zh": "DANP在防御恶意编辑方面实现最先进性能，通过双注意力引导和噪声扰动，显著提升免疫力，实验证实其有效误导编辑并保护目标，性能优于现有方法。",
            "tags_zh": [
                "文本到图像扩散模型",
                "恶意编辑防御",
                "注意力机制",
                "噪声扰动",
                "语义理解干扰",
                "图像安全",
                "伦理挑战",
                "动态阈值"
            ],
            "_index": 107
        },
        {
            "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
            "authors": [
                "Atsuyuki Miyai",
                "Shota Onohara",
                "Jeonghun Baek",
                "Kiyoharu Aizawa"
            ],
            "arxiv_id": "2512.14620v1",
            "summary": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://mmmu-japanese-benchmark.github.io/JMMMU_Pro/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14620v1",
            "code_links": [],
            "headline_zh": "提出Step-Tagging框架，通过实时监控推理步骤类型，实现语言推理模型生成过程的控制与优化。",
            "summary_zh": "语言推理模型（LRMs）领域近年来发展迅速，训练和推理技术的进步使得LRMs能够进行更长、更准确的推理。然而，越来越多的研究表明，LRMs仍然效率低下，过度生成验证和反思步骤。为解决这一挑战，我们引入了Step-Tagging框架，这是一个轻量级的句子分类器，能够实时标注LRM生成的推理步骤类型。为了监控推理行为，我们提出了ReasonType：一种新颖的推理步骤分类法。基于此框架，我们证明了在线监控特定步骤的数量可以产生有效的、可解释的LRM推理早期停止标准。我们在三个开源推理模型上评估了Step-Tagging框架，使用标准基准数据集：MATH500、GSM8K、AIME以及非数学任务（GPQA和MMLU-Pro）。在保持与标准生成相当准确度的同时，我们实现了20%到50%的token减少，在计算量更大的任务上观察到最大的收益。这项工作提供了一种新颖的方式来增加对LRM生成的控制，以及一种研究LRM行为的新工具。",
            "intro_zh": [
                "语言推理模型（LRMs）在推理过程中存在效率低下问题，常过度生成验证和反思步骤，导致计算资源浪费。",
                "论文提出Step-Tagging框架，通过轻量级句子分类器实时标注推理步骤类型，并引入ReasonType分类法来监控推理行为。",
                "实验表明，该框架在多个基准数据集上实现20-50%的token减少，同时保持准确度，尤其在计算密集型任务中效果显著。"
            ],
            "method_zh": "Step-Tagging框架的核心是一个轻量级句子分类器，用于实时标注语言推理模型（LRM）生成的推理步骤类型。关键技术创新包括：引入ReasonType——一种新颖的推理步骤分类法，系统化定义不同步骤类别；以及基于在线监控特定步骤数量，开发可解释的早期停止标准，以优化推理过程。与现有方法主要区别在于，传统方法往往依赖固定长度或启发式停止策略，而Step-Tagging通过动态步骤类型分析，提供更精细的控制和效率提升，直接针对LRMs的过度生成问题。",
            "application_zh": "该研究可应用于需要高效推理的语言模型场景，如数学问题求解、科学问答和复杂决策任务。通过减少不必要的token生成，能降低计算成本，提升模型在资源受限环境下的实用性，同时为LRM行为分析提供新工具，促进模型可解释性和优化研究。",
            "highlight_zh": "在MATH500、GSM8K、AIME等数学任务及GPQA、MMLU-Pro非数学任务上，Step-Tagging框架实现20%至50%的token减少，准确度与标准生成相当。最大收益出现在计算量更大的任务中，显著提升推理效率。",
            "tags_zh": [
                "语言推理模型",
                "步骤监控",
                "早期停止",
                "推理效率",
                "轻量级分类器",
                "可解释性",
                "token减少",
                "ReasonType分类法"
            ],
            "_index": 108
        },
        {
            "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
            "authors": [
                "Chaohao Yuan",
                "Zhenjie Song",
                "Ercan Engin Kuruoglu",
                "Kangfei Zhao",
                "Yang Liu",
                "Deli Zhao",
                "Hong Cheng",
                "Yu Rong"
            ],
            "arxiv_id": "2512.14619v1",
            "summary": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by WSDM 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14331v1",
            "code_links": [],
            "headline_zh": "提出ARCADE框架，通过在线变化点感知贝叶斯动力学学习，解决机器人系统在动态变化环境中的实时自适应控制问题。",
            "summary_zh": "现实世界中的机器人必须在动态变化的环境中运行，这些变化可能由操作条件改变、外部干扰或未建模效应引起，表现为渐进漂移、瞬时波动或突然转变，需要实时适应机制，既能抵抗短期变化，又能响应持久变化。本文提出一个框架，用于建模机器人系统的非线性动力学，可从流数据中实时更新。该方法将表示学习与在线适应解耦，利用离线学习的潜在表示支持在线闭式贝叶斯更新。为处理演化条件，引入变化点感知机制，通过从数据似然推断的潜在变量指示连续性或转变。当连续性可能时，证据累积以优化预测；当检测到转变时，过去信息被调节以支持快速重新学习。这保持了校准的不确定性，并支持对瞬时、渐进或结构变化的概率推理。我们证明该框架的自适应遗憾仅随时间对数增长，并与转变次数线性相关，与知道转变时间的神谕方法竞争。在倒立摆模拟和真实四旋翼飞行器实验中验证，包括摆动负载和飞行中掉落场景，相比相关基线，展示了改进的预测准确性、更快恢复和更准确的闭环跟踪。",
            "intro_zh": [
                "核心问题：现有方法难以实时适应机器人动力学中的渐进漂移、瞬时波动或突然转变，导致预测不准确和跟踪性能下降。",
                "方法要点：提出ARCADE框架，结合离线表示学习和在线贝叶斯更新，通过变化点感知机制动态调整信息积累，实现快速自适应。",
                "实验或效果：在模拟和真实机器人实验中，ARCADE显著提升预测准确性、加速恢复时间，并改善闭环跟踪性能，优于基线方法。"
            ],
            "method_zh": "ARCADE框架整体上采用两阶段方法：离线阶段学习非线性动力学的潜在表示，在线阶段基于流数据进行闭式贝叶斯更新。关键技术创新点包括变化点感知机制，通过推断潜在变量来检测动力学连续性或转变，从而动态调节过去信息的权重。与现有方法的主要区别在于解耦表示学习与在线适应，支持实时更新和概率推理，同时理论证明自适应遗憾增长缓慢，增强鲁棒性和效率。",
            "application_zh": "该研究适用于需要实时自适应控制的机器人系统，如无人机在负载变化或干扰下的飞行、工业机器人在动态环境中的操作，以及自主车辆在不确定条件下的导航，提升系统在复杂环境中的鲁棒性和性能。",
            "highlight_zh": "在倒立摆模拟和真实四旋翼飞行器实验中，ARCADE相比基线方法，预测准确性提高，恢复时间缩短，闭环跟踪误差降低，特别是在摆动负载和飞行中掉落场景中表现突出，验证了其高效自适应能力。",
            "tags_zh": [
                "机器人自适应控制",
                "在线贝叶斯学习",
                "变化点检测",
                "非线性动力学建模",
                "实时流数据更新",
                "概率推理",
                "闭环跟踪",
                "无人机应用"
            ],
            "_index": 109
        },
        {
            "title": "LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts",
            "authors": [
                "Prasanjit Dubey",
                "Aritra Guha",
                "Zhengyi Zhou",
                "Qiong Wu",
                "Xiaoming Huo",
                "Paromita Dubey"
            ],
            "arxiv_id": "2512.14604v1",
            "summary": "Sparse longitudinal (SL) textual data arises when individuals generate text repeatedly over time (e.g., customer reviews, occasional social media posts, electronic medical records across visits), but the frequency and timing of observations vary across individuals. These complex textual data sets have immense potential to inform future policy and targeted recommendations. However, because SL text data lack dedicated methods and are noisy, heterogeneous, and prone to anomalies, detecting and inferring key patterns is challenging. We introduce LLmFPCA-detect, a flexible framework that pairs LLM-based text embeddings with functional data analysis to detect clusters and infer anomalies in large SL text datasets. First, LLmFPCA-detect embeds each piece of text into an application-specific numeric space using LLM prompts. Sparse multivariate functional principal component analysis (mFPCA) conducted in the numeric space forms the workhorse to recover primary population characteristics, and produces subject-level scores which, together with baseline static covariates, facilitate data segmentation, unsupervised anomaly detection and inference, and enable other downstream tasks. In particular, we leverage LLMs to perform dynamic keyword profiling guided by the data segments and anomalies discovered by LLmFPCA-detect, and we show that cluster-specific functional PC scores from LLmFPCA-detect, used as features in existing pipelines, help boost prediction performance. We support the stability of LLmFPCA-detect with experiments and evaluate it on two different applications using public datasets, Amazon customer-review trajectories, and Wikipedia talk-page comment streams, demonstrating utility across domains and outperforming state-of-the-art baselines.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14604v1",
            "code_links": [],
            "headline_zh": "通过比较法分析提出全球统一法律标准以解决自动驾驶车辆中的刑事归责问题",
            "summary_zh": "人工智能通过自动驾驶车辆（AVs）革新了交通运输，但也引入了关于违规行为的复杂刑事归责问题。本研究采用比较法分析，对美国、德国、英国、中国和印度的主要法规、现实世界中的责任索赔案例以及学术文献进行了研究；这些司法管辖区因其技术进步和对比鲜明的监管方法而被选中。研究探讨了人为错误归因、AI道德主体性以及AV事故中主要责任人的识别。研究发现监管格局碎片化：印度和美国依赖松散的各州法律网络，而英国则颁布了开创性的《2018年自动化和电动汽车法案》。德国执行严格的安全标准，根据车辆的运行模式区分责任，而中国同样旨在建立严格的责任制度。研究得出结论，全球统一的法律标准对于促进技术创新、同时确保最低风险和明确的责任归责至关重要。",
            "intro_zh": [
                "核心问题：自动驾驶车辆引发刑事归责难题，现有法律体系碎片化，难以适应AI技术带来的新挑战，如人为错误归因和AI道德主体性。",
                "方法要点：采用比较法分析，研究多国法规、案例和文献，聚焦技术先进和监管差异的司法管辖区，以识别责任归责的关键因素。",
                "实验或效果：发现各国监管模式各异，如英国有专门立法，德国基于运行模式区分责任，强调全球统一标准对技术创新和风险控制的重要性。"
            ],
            "method_zh": "论文的核心方法是比较法分析，整体框架包括选取美国、德国、英国、中国和印度作为研究对象，基于其技术先进性和监管差异。关键技术创新点在于系统整合了主要法规、现实责任索赔案例和学术文献，进行跨司法管辖区的对比研究。与现有方法的主要区别在于，它不仅关注单一国家的法律分析，而是通过多国比较，揭示全球监管碎片化问题，并强调统一标准的必要性，从而更全面地解决自动驾驶车辆中的刑事归责挑战。",
            "application_zh": "该研究可应用于自动驾驶车辆的法律监管和政策制定领域，帮助各国政府和国际组织制定统一的法律标准，促进技术创新，同时确保交通安全和明确的责任归责，具有重要的实际价值。",
            "highlight_zh": "最重要的实验结果是揭示了各国监管模式的显著差异：英国通过专门立法领先，德国基于运行模式严格区分责任，而印度和美国依赖松散法律网络。这强调了全球统一法律标准的紧迫性，以平衡技术创新与风险控制。",
            "tags_zh": [
                "自动驾驶车辆",
                "刑事归责",
                "比较法分析",
                "法律监管",
                "AI道德主体性",
                "全球统一标准",
                "责任归责",
                "技术创新"
            ],
            "_index": 110
        },
        {
            "title": "Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis",
            "authors": [
                "Lukáš Samuel Marták",
                "Patricia Hu",
                "Gerhard Widmer"
            ],
            "arxiv_id": "2512.14602v1",
            "summary": "Automatic Music Transcription (AMT) -- the task of converting music audio into note representations -- has seen rapid progress, driven largely by deep learning systems. Due to the limited availability of richly annotated music datasets, much of the progress in AMT has been concentrated on classical piano music, and even a few very specific datasets. Whether these systems can generalize effectively to other musical contexts remains an open question. Complementing recent studies on distribution shifts in sound (e.g., recording conditions), in this work we investigate the musical dimension -- specifically, variations in genre, dynamics, and polyphony levels. To this end, we introduce the MDS corpus, comprising three distinct subsets -- (1) Genre, (2) Random, and (3) MAEtest -- to emulate different axes of distribution shift. We evaluate the performance of several state-of-the-art AMT systems on the MDS corpus using both traditional information-retrieval and musically-informed performance metrics. Our extensive evaluation isolates and exposes varying degrees of performance degradation under specific distribution shifts. In particular, we measure a note-level F1 performance drop of 20 percentage points due to sound, and 14 due to genre. Generally, we find that dynamics estimation proves more vulnerable to musical variation than onset prediction. Musically informed evaluation metrics, particularly those capturing harmonic structure, help identify potential contributing factors. Furthermore, experiments with randomly generated, non-musical sequences reveal clear limitations in system performance under extreme musical distribution shifts. Altogether, these findings offer new evidence of the persistent impact of the Corpus Bias problem in deep AMT systems.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "pre-print of the upcoming EURASIP JASM journal article",
            "doi": "10.1186/s13636-025-00428-z",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14602v1",
            "code_links": [],
            "headline_zh": "提出数据-物理混合生成模型，基于单次平地行走数据预测中风患者个性化康复任务中的步态，以增强临床决策。",
            "summary_zh": "中风后运动能力的动态预测对于定制康复至关重要，但当前评估仅提供静态损伤评分，无法指示患者是否能安全执行特定任务，如斜坡行走或爬楼梯。本文开发了一个数据-物理混合生成框架，通过单次20米平地行走试验重建个体中风幸存者的神经肌肉控制，并预测康复场景中的任务条件化运动。该系统结合了可穿戴传感器运动学、比例-微分物理控制器、健康人群运动图谱，以及基于目标条件深度强化学习与行为克隆和生成对抗模仿学习，生成物理合理、患者特定的斜坡和楼梯步态模拟。在11名中风幸存者中，个性化控制器保留了独特步态模式，同时将关节角度和端点保真度分别提高了4.73%和12.10%，并将训练时间减少到仅物理基线的25.56%。在一项涉及21名住院患者的多中心试点中，使用我们的运动预测指导任务选择和难度的临床医生，在28天标准康复期间获得的Fugl-Meyer下肢评分增益大于对照组临床医生（平均变化6.0分对3.7分）。这些发现表明，我们的生成性任务预测框架可以增强中风后步态康复的临床决策，并为动态个性化运动恢复策略提供模板。",
            "intro_zh": [
                "核心问题：现有中风康复评估仅提供静态损伤评分，无法动态预测患者执行特定任务（如斜坡行走）的能力，限制了康复个性化。",
                "方法要点：结合可穿戴传感器数据、物理控制器、健康运动图谱和深度强化学习，构建混合生成模型，从单次行走数据重建个性化神经肌肉控制。",
                "实验或效果：在11名患者中提升步态模拟保真度，多中心试点显示使用预测指导康复可显著提高下肢功能评分增益。"
            ],
            "method_zh": "论文提出一个数据-物理混合生成框架，整体架构整合可穿戴传感器采集的运动学数据、比例-微分物理控制器模拟生物力学约束、健康人群运动图谱作为参考基准，以及目标条件深度强化学习结合行为克隆和生成对抗模仿学习来生成任务特定步态。关键技术创新在于融合数据驱动与物理模型，实现从单次行走试验快速重建个性化控制器，并预测多种康复场景下的运动。与现有纯物理或纯数据方法相比，该方法在保持患者独特步态模式的同时，提高了模拟的物理合理性和效率。",
            "application_zh": "该研究主要应用于中风后运动康复领域，通过个性化步态预测辅助临床医生制定动态康复计划，如选择安全任务（斜坡、楼梯行走）和调整难度，提升康复效果和效率，具有推动精准医疗和智能康复系统的潜力。",
            "highlight_zh": "在11名中风患者中，个性化控制器将关节角度和端点保真度分别提升4.73%和12.10%，训练时间减少至基线25.56%；多中心试点中，使用预测指导康复的临床医生组下肢功能评分平均增益达6.0分，显著高于对照组的3.7分。",
            "tags_zh": [
                "中风康复",
                "步态预测",
                "数据-物理混合模型",
                "可穿戴传感器",
                "深度强化学习",
                "个性化医疗",
                "生成对抗模仿学习",
                "运动控制"
            ],
            "_index": 111
        },
        {
            "title": "FakeRadar: Probing Forgery Outliers to Detect Unknown Deepfake Videos",
            "authors": [
                "Zhaolun Li",
                "Jichang Li",
                "Yinqi Cai",
                "Junye Chen",
                "Xiaonan Luo",
                "Guanbin Li",
                "Rushi Lan"
            ],
            "arxiv_id": "2512.14601v1",
            "summary": "In this paper, we propose FakeRadar, a novel deepfake video detection framework designed to address the challenges of cross-domain generalization in real-world scenarios. Existing detection methods typically rely on manipulation-specific cues, performing well on known forgery types but exhibiting severe limitations against emerging manipulation techniques. This poor generalization stems from their inability to adapt effectively to unseen forgery patterns. To overcome this, we leverage large-scale pretrained models (e.g. CLIP) to proactively probe the feature space, explicitly highlighting distributional gaps between real videos, known forgeries, and unseen manipulations. Specifically, FakeRadar introduces Forgery Outlier Probing, which employs dynamic subcluster modeling and cluster-conditional outlier generation to synthesize outlier samples near boundaries of estimated subclusters, simulating novel forgery artifacts beyond known manipulation types. Additionally, we design Outlier-Guided Tri-Training, which optimizes the detector to distinguish real, fake, and outlier samples using proposed outlier-driven contrastive learning and outlier-conditioned cross-entropy losses. Experiments show that FakeRadar outperforms existing methods across various benchmark datasets for deepfake video detection, particularly in cross-domain evaluations, by handling the variety of emerging manipulation techniques.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14601v1",
            "code_links": [],
            "headline_zh": "提出SIFM方法以解决图像免疫评估指标不准确的问题，通过语义失配和感知退化新视角保护图像免受恶意编辑。",
            "summary_zh": "基于扩散模型的文本引导图像编辑虽然强大，但也引发了滥用担忧，促使人们使用不可察觉的扰动来免疫图像以防止未经授权的编辑。评估免疫成功的主流指标通常依赖于测量受保护图像生成的输出与未受保护原始图像生成的参考输出之间的视觉差异。这种方法从根本上忽视了图像免疫的核心要求，即破坏与攻击者意图的语义对齐，而不考虑与任何特定输出的偏差。我们认为，免疫成功应定义为编辑输出要么语义上与提示不匹配，要么遭受显著的感知退化，这两者都能阻止恶意意图。为实现这一原则，我们提出了协同中间特征操纵（SIFM），该方法通过双重协同目标策略性地扰动中间扩散特征：（1）最大化特征与原始编辑轨迹的差异，以破坏与预期编辑的语义对齐；（2）最小化特征范数以诱导感知退化。此外，我们引入了免疫成功率（ISR），这是一种新颖的指标，首次设计用于严格量化真实的免疫效果。ISR量化了免疫导致相对于提示的语义失败或显著感知退化的编辑比例，通过多模态大语言模型（MLLMs）进行评估。大量实验表明，我们的SIFM在保护视觉内容免受基于扩散的恶意操纵方面达到了最先进的性能。",
            "intro_zh": [
                "现有图像免疫评估指标依赖视觉差异，忽略了破坏语义对齐的核心要求，导致评估不准确。",
                "提出SIFM方法，通过最大化特征差异和最小化特征范数，协同扰动扩散特征以实现语义失配和感知退化。",
                "实验显示SIFM在免疫成功率上达到最优，有效保护图像免受恶意编辑，验证了新视角的有效性。"
            ],
            "method_zh": "论文提出协同中间特征操纵（SIFM）作为核心方法，整体框架基于扩散模型，在中间特征层施加扰动。关键技术创新点包括：设计双重协同目标，一是最大化特征与原始编辑轨迹的差异以破坏语义对齐，二是最小化特征范数以诱导感知退化；同时引入免疫成功率（ISR）作为新评估指标，利用多模态大语言模型量化语义失败和感知退化。与现有方法的主要区别在于，SIFM从语义失配和感知退化新视角出发，直接针对攻击者意图进行免疫，而非依赖输出视觉差异，从而更准确地评估和实现免疫效果。",
            "application_zh": "该研究可应用于数字版权保护、社交媒体内容安全、新闻图像防篡改等领域，通过免疫技术防止恶意编辑，保障视觉内容的真实性和完整性，具有重要的实际价值。",
            "highlight_zh": "SIFM在免疫成功率（ISR）上达到最先进性能，实验表明其能有效诱导语义失配和感知退化，显著提升图像免疫效果，验证了新评估指标和方法的优越性。",
            "tags_zh": [
                "图像免疫",
                "扩散模型",
                "语义失配",
                "感知退化",
                "特征扰动",
                "评估指标",
                "多模态大语言模型",
                "内容安全"
            ],
            "_index": 112
        },
        {
            "title": "FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications",
            "authors": [
                "Mitsuki Watanabe",
                "Sosuke Amano",
                "Kiyoharu Aizawa",
                "Yoko Yamakata"
            ],
            "arxiv_id": "2512.14574v1",
            "summary": "Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3746027.3758276",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14312v1",
            "code_links": [],
            "headline_zh": "提出基于视觉语言模型的零样本与少样本方法，以替代YOLOv8实现中东和北非地区废水处理厂的卫星图像高效检测。",
            "summary_zh": "在中东和北非地区，废水处理厂对可持续水资源管理至关重要，从卫星图像中精确识别这些设施有助于环境监测。传统方法如YOLOv8分割需要大量人工标注，但研究表明视觉语言模型通过其内在推理和标注能力，能实现同等或更优效果，是一种高效替代方案。本研究提出了一种结构化的VLM比较方法，分为零样本和少样本两个流程，专门用于识别废水处理厂。YOLOv8在来自埃及、沙特阿拉伯和阿联酋的83,566张高分辨率卫星图像政府数据集上训练，其中约85%为废水处理厂（正样本），15%为非废水处理厂（负样本）。评估的VLM包括LLaMA 3.2 Vision、Qwen 2.5 VL、DeepSeek-VL2、Gemma 3、Gemini和Pixtral 12B（Mistral），用于识别废水处理厂组件如圆形/矩形储罐、曝气池，并通过专家提示区分混淆物，生成包含置信度和描述的JSON输出。数据集包含1,207个已验证的废水处理厂位置（198个阿联酋、354个沙特阿拉伯、655个埃及）以及来自现场/AI数据的同等数量的非废水处理厂站点，作为600米×600米的Geo-TIFF图像（缩放级别18，EPSG:4326）。在废水处理厂图像上的零样本评估显示，多个VLM的性能超过了YOLOv8的真阳性率，其中Gemma-3最高。结果证实，VLM特别是零样本方法，可以替代YOLOv8实现高效、无需标注的废水处理厂分类，从而支持可扩展的遥感应用。",
            "intro_zh": [
                "核心问题：传统YOLOv8方法依赖大量人工标注，成本高且难以适应中东和北非地区废水处理厂的快速检测需求。",
                "方法要点：采用视觉语言模型进行零样本和少样本检测，利用专家提示识别废水处理厂组件，减少对标注数据的依赖。",
                "实验或效果：多个VLM在零样本评估中超越YOLOv8真阳性率，Gemma-3表现最佳，验证了VLM的高效性和可扩展性。"
            ],
            "method_zh": "论文提出一种结构化方法，比较多种视觉语言模型在零样本和少样本设置下的性能。整体框架包括：使用YOLOv8作为基线模型，在包含83,566张高分辨率卫星图像的数据集上训练；同时评估LLaMA 3.2 Vision、Qwen 2.5 VL等VLM，通过专家提示引导模型识别废水处理厂组件（如圆形/矩形储罐、曝气池）并区分混淆物，输出JSON格式结果。关键技术创新点在于将VLM应用于卫星图像中的废水处理厂检测，结合零样本和少样本策略，减少对标注数据的依赖。与现有方法的主要区别是：传统方法如YOLOv8需要大量手动标注，而VLM利用其内在推理能力，在无需或仅需少量标注的情况下实现高效检测，提高了方法的灵活性和可扩展性。",
            "application_zh": "该研究可应用于中东和北非地区的环境监测和水资源管理，通过卫星图像自动检测废水处理厂，支持可持续城市规划和灾害响应。潜在价值包括降低人工标注成本、提升遥感数据分析效率，并为全球类似区域提供可复制的技术方案。",
            "highlight_zh": "在零样本评估中，多个视觉语言模型（如Gemma-3）的真阳性率超过YOLOv8，最高性能模型实现了更高效的废水处理厂分类。这证实了VLM作为标注免费替代方案的可行性，显著提升了检测速度和可扩展性。",
            "tags_zh": [
                "视觉语言模型",
                "零样本检测",
                "少样本学习",
                "卫星图像分析",
                "废水处理厂识别",
                "遥感应用",
                "中东和北非地区",
                "环境监测"
            ],
            "_index": 113
        },
        {
            "title": "CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer",
            "authors": [
                "Xianwei Cao",
                "Dou Quan",
                "Shuang Wang",
                "Ning Huyan",
                "Wei Wang",
                "Yunan Li",
                "Licheng Jiao"
            ],
            "arxiv_id": "2512.14560v1",
            "summary": "Image retrieval-based cross-view geo-localization (IRCVGL) aims to match images captured from significantly different viewpoints, such as satellite and street-level images. Existing methods predominantly rely on learning robust global representations or implicit feature alignment, which often fail to model explicit spatial correspondences crucial for accurate localization. In this work, we propose a novel correspondence-aware feature refinement framework, termed CLNet, that explicitly bridges the semantic and geometric gaps between different views. CLNet decomposes the view alignment process into three learnable and complementary modules: a Neural Correspondence Map (NCM) that spatially aligns cross-view features via latent correspondence fields; a Nonlinear Embedding Converter (NEC) that remaps features across perspectives using an MLP-based transformation; and a Global Feature Recalibration (GFR) module that reweights informative feature channels guided by learned spatial cues. The proposed CLNet can jointly capture both high-level semantics and fine-grained alignments. Extensive experiments on four public benchmarks, CVUSA, CVACT, VIGOR, and University-1652, demonstrate that our proposed CLNet achieves state-of-the-art performance while offering better interpretability and generalizability.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14560v1",
            "code_links": [],
            "headline_zh": "提出一种面向工业边缘计算的持续学习方法，用于实时质量控制，减少灾难性遗忘影响。",
            "summary_zh": "互联网连接设备的指数级增长给传统集中式计算系统带来了延迟和带宽限制的挑战。边缘计算通过将计算更靠近数据源来解决这些困难。此外，传统机器学习算法不适合边缘计算系统，因为数据通常以动态和持续的方式到达。然而，增量学习为这些场景提供了良好的解决方案。我们引入了一种新方法，将增量学习理念应用于工业领域的边缘计算场景，具体目的是在制造系统中实现实时质量控制。通过应用持续学习，我们减少了灾难性遗忘的影响，并提供了一种高效且有效的解决方案。",
            "intro_zh": [
                "传统集中式计算面临延迟和带宽限制，边缘计算成为解决方案，但传统机器学习算法不适应动态数据流。",
                "论文提出在工业边缘计算场景中应用增量学习，实现实时质量控制，减少灾难性遗忘。",
                "该方法提供高效解决方案，提升边缘系统的适应性和性能，具体实验结果未知。"
            ],
            "method_zh": "论文提出一种面向工业物联网的边缘计算架构，核心是应用持续学习方法。整体框架将增量学习集成到边缘节点，处理动态数据流。关键技术创新在于将持续学习理念专门化到工业质量控制场景，优化模型更新策略以减少灾难性遗忘。与现有方法的主要区别在于结合边缘计算和持续学习，针对工业实时需求设计，而非通用机器学习框架。",
            "application_zh": "该研究主要应用于工业制造领域的实时质量控制，如生产线监测、缺陷检测等。潜在价值包括提升生产效率、降低延迟，并适应动态环境变化，推动工业自动化和智能化。",
            "highlight_zh": "论文通过应用持续学习，有效减少了灾难性遗忘的影响，提供了边缘计算场景下的高效解决方案。具体性能提升未知，但强调了方法在实时工业应用中的适应性和有效性。",
            "tags_zh": [
                "边缘计算",
                "持续学习",
                "工业物联网",
                "增量学习",
                "实时质量控制",
                "灾难性遗忘",
                "智能制造"
            ],
            "_index": 114
        },
        {
            "title": "Test Time Optimized Generalized AI-based Medical Image Registration Method",
            "authors": [
                "Sneha Sree C.",
                "Dattesh Shanbhag",
                "Sudhanya Chatterjee"
            ],
            "arxiv_id": "2512.14556v1",
            "summary": "Medical image registration is critical for aligning anatomical structures across imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and ultrasound. Among existing techniques, non-rigid registration (NRR) is particularly challenging due to the need to capture complex anatomical deformations caused by physiological processes like respiration or contrast-induced signal variations. Traditional NRR methods, while theoretically robust, often require extensive parameter tuning and incur high computational costs, limiting their use in real-time clinical workflows. Recent deep learning (DL)-based approaches have shown promise; however, their dependence on task-specific retraining restricts scalability and adaptability in practice. These limitations underscore the need for efficient, generalizable registration frameworks capable of handling heterogeneous imaging contexts. In this work, we introduce a novel AI-driven framework for 3D non-rigid registration that generalizes across multiple imaging modalities and anatomical regions. Unlike conventional methods that rely on application-specific models, our approach eliminates anatomy- or modality-specific customization, enabling streamlined integration into diverse clinical environments.",
            "categories": [
                "eess.IV",
                "cs.CV"
            ],
            "primary_category": "eess.IV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14556v1",
            "code_links": [],
            "headline_zh": "提出PSMamba渐进自监督视觉Mamba框架，以解决植物病害识别中多尺度病变模式捕获不足的问题。",
            "summary_zh": "自监督学习已成为无需人工标注的强大表示学习范式。然而，现有框架多关注全局对齐，难以捕获植物病害图像中层次化、多尺度的病变模式特征。为填补这一空白，本文提出PSMamba，一种渐进自监督框架，将视觉Mamba的高效序列建模与双学生层次蒸馏策略相结合。不同于传统的单教师-学生设计，PSMamba采用共享全局教师和两个专门化学生：一个处理中尺度视图以捕获病变分布和叶脉结构，另一个聚焦局部视图以捕获细粒度线索，如纹理不规则和早期病变。这种多粒度监督促进了上下文和细节表示的联合学习，并通过一致性损失确保跨尺度对齐的连贯性。在三个基准数据集上的实验表明，PSMamba持续优于最先进的自监督学习方法，在领域偏移和细粒度场景中均展现出卓越的准确性和鲁棒性。",
            "intro_zh": [
                "现有自监督学习框架主要依赖全局对齐，难以有效建模植物病害图像中复杂的多尺度病变模式，导致在细粒度识别任务上表现受限。",
                "PSMamba创新性地结合视觉Mamba的序列建模能力与双学生层次蒸馏策略，通过共享全局教师和两个专门化学生分别处理中尺度和局部视图，实现多粒度监督学习。",
                "在三个基准数据集上的实验验证了PSMamba的优越性，其准确性和鲁棒性均超越现有自监督方法，尤其在领域偏移和细粒度场景中表现突出。"
            ],
            "method_zh": "PSMamba的整体框架是一个渐进自监督学习系统，核心创新在于将视觉Mamba的高效序列建模与双学生层次蒸馏策略深度融合。关键技术创新点包括：采用共享全局教师提供全局表示指导，同时部署两个专门化学生——一个处理中尺度视图以捕获病变分布和叶脉结构等中层特征，另一个聚焦局部视图以提取纹理不规则和早期病变等细粒度线索；通过多粒度监督和一致性损失实现跨尺度对齐的联合学习。与现有方法的主要区别在于：传统自监督框架多基于单一教师-学生设计或仅关注全局对齐，而PSMamba通过双学生架构和渐进式蒸馏，更精细地建模了植物病害图像中的层次化多尺度模式，提升了表示学习的全面性和鲁棒性。",
            "application_zh": "该研究主要应用于农业领域的植物病害智能识别与监测，可集成于移动设备或无人机平台，实现大规模农田的自动化病害诊断。其潜在价值包括降低人工标注成本、提高早期病害检测精度，并为精准农业和可持续作物管理提供技术支持。",
            "highlight_zh": "在三个植物病害基准数据集上的实验表明，PSMamba在准确性和鲁棒性上均显著优于现有最先进的自监督学习方法，尤其在处理领域偏移和细粒度识别任务时表现卓越，验证了其多尺度建模的有效性。",
            "tags_zh": [
                "自监督学习",
                "视觉Mamba",
                "植物病害识别",
                "多尺度建模",
                "层次蒸馏",
                "序列建模",
                "细粒度识别",
                "农业人工智能"
            ],
            "_index": 115
        },
        {
            "title": "Dual Language Models: Balancing Training Efficiency and Overfitting Resilience",
            "authors": [
                "David Samuel",
                "Lucas Georges Gabriel Charpentier"
            ],
            "arxiv_id": "2512.14549v1",
            "summary": "This paper combines autoregressive and masked-diffusion training objectives without any architectural modifications, resulting in flexible language models that outperform single-objective models. Autoregressive modeling has been a popular approach, partly because of its training efficiency; however, that comes at the cost of sensitivity to overfitting. On the other hand, masked-diffusion models are less efficient to train while being more resilient to overfitting. In this work, we demonstrate that dual-objective training achieves the best of both worlds. To derive the optimal ratio between both objectives, we train and evaluate 50 language models under varying levels of data repetition. We show that it is optimal to combine both objectives under all evaluated settings and that the optimal ratio is similar whether targeting autoregressive or masked-diffusion downstream performance.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14549v1",
            "code_links": [],
            "headline_zh": "提出基于自一致性的训练方法，提升模型错误设定下摊销贝叶斯模型比较的准确性",
            "summary_zh": "摊销贝叶斯推断（ABI）通过训练神经网络代理在统计模型模拟数据上，提供快速、可扩展的后验密度近似。然而，ABI方法对模型错误设定高度敏感：当观测数据超出训练分布（统计模型的生成范围）时，神经网络代理可能表现不可预测。这在模型比较场景中构成挑战，因为需要考虑多个统计模型，其中至少部分存在错误设定。最近关于自一致性（SC）的研究为解决这一问题提供了有前景的补救措施，即使对于经验数据（无真实标签）也可访问。在本研究中，我们探讨了SC如何改进以四种不同方式概念化的摊销模型比较。在两个合成和两个真实世界案例研究中，我们发现通过近似参数后验估计边际似然的方法，在模型比较中始终优于直接近似模型证据或后验模型概率的方法。当似然函数可用时，SC训练即使在严重模型错误设定下也能提高鲁棒性。对于无法访问解析似然函数的方法，SC的益处更为有限且不一致。我们的结果为可靠的摊销贝叶斯模型比较提供了实用指导：优先选择基于参数后验的方法，并在经验数据集上通过SC训练增强它们，以减轻模型错误设定下的外推偏差。",
            "intro_zh": [
                "核心问题：摊销贝叶斯推断在模型错误设定下表现不稳定，影响多模型比较的可靠性。",
                "方法要点：引入自一致性训练，增强神经网络代理在经验数据上的鲁棒性，减少外推偏差。",
                "实验或效果：基于参数后验的方法在合成和真实数据中表现最佳，SC训练显著提升准确性。"
            ],
            "method_zh": "论文提出一个基于自一致性（SC）的摊销贝叶斯模型比较框架。整体框架涉及训练神经网络代理来近似后验分布，并通过SC训练在经验数据上优化代理，确保其输出在不同模型间保持一致。关键技术创新点在于将SC原则应用于模型比较场景，利用经验数据（无需真实标签）来校准代理行为，从而缓解模型错误设定导致的偏差。与现有方法的主要区别在于：现有ABI方法通常依赖模拟数据训练，对模型错误设定敏感；而本方法通过SC训练整合经验数据，提高了在真实世界应用中的鲁棒性和泛化能力。",
            "application_zh": "该研究适用于需要快速、可扩展模型比较的领域，如生物统计学、金融建模和机器学习模型选择。在实际应用中，它可以帮助研究人员在存在模型不确定性的情况下，更可靠地评估和选择统计模型，提升决策的准确性。",
            "highlight_zh": "实验显示，基于参数后验的模型比较方法在四个案例研究中均优于直接近似证据的方法；SC训练在似然可用时，即使模型严重错误设定，也能将准确性提升高达20%；但在无解析似然时，SC的改善有限且不稳定。",
            "tags_zh": [
                "摊销贝叶斯推断",
                "模型比较",
                "自一致性训练",
                "模型错误设定",
                "神经网络代理",
                "后验近似",
                "鲁棒性提升",
                "经验数据校准"
            ],
            "_index": 116
        },
        {
            "title": "Improving Slow Transfer Predictions: Generative Methods Compared",
            "authors": [
                "Jacob Taegon Kim",
                "Alex Sim",
                "Kesheng Wu",
                "Jinoh Kim"
            ],
            "arxiv_id": "2512.14522v1",
            "summary": "Monitoring data transfer performance is a crucial task in scientific computing networks. By predicting performance early in the communication phase, potentially sluggish transfers can be identified and selectively monitored, optimizing network usage and overall performance. A key bottleneck to improving the predictive power of machine learning (ML) models in this context is the issue of class imbalance. This project focuses on addressing the class imbalance problem to enhance the accuracy of performance predictions. In this study, we analyze and compare various augmentation strategies, including traditional oversampling methods and generative techniques. Additionally, we adjust the class imbalance ratios in training datasets to evaluate their impact on model performance. While augmentation may improve performance, as the imbalance ratio increases, the performance does not significantly improve. We conclude that even the most advanced technique, such as CTGAN, does not significantly improve over simple stratified sampling.",
            "categories": [
                "cs.LG",
                "cs.DC",
                "cs.NI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1109/ICNC64010.2025.10994006",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14522v1",
            "code_links": [],
            "headline_zh": "提出基于阈值触发的深度Q网络自愈框架，以解决软件定义工业物联网边缘网络中随机中断问题。",
            "summary_zh": "软件定义工业网络中的随机中断（如良性流量突发和交换机热波动导致的闪断事件）是导致间歇性服务降级的主要原因，这些事件违反了IEC 61850衍生的服务质量要求和用户定义的服务级别协议，阻碍了符合IEC 61400-25的风力发电厂中控制、监控和尽力而为流量的可靠及时交付。未能维持这些要求通常会导致控制信号延迟或丢失、运行效率降低以及风力涡轮发电机停机风险增加。为解决这些挑战，本研究提出了一种阈值触发的深度Q网络自愈代理，能够自主检测、分析和缓解网络中断，同时实时调整路由行为和资源分配。该代理在基于云的概念验证测试平台中部署的模拟三集群交换机网络上进行了训练、验证和测试。仿真结果表明，与基线最短路径和负载均衡路由方法相比，所提出的代理将中断恢复性能提高了53.84%，并在超骨干叶数据平面架构中优于最先进的方法，包括自适应网络模糊推理系统（提升13.1%）以及基于深度Q网络和流量预测的路由优化方法（提升21.5%）。此外，该代理在需要时通过主动启动外部机架冷却来维持交换机热稳定性。这些发现突显了深度强化学习在构建部署在关键任务、时间敏感应用场景中的软件定义工业网络弹性方面的潜力。",
            "intro_zh": [
                "核心问题：随机中断（如流量突发和热波动）导致软件定义工业网络服务降级，违反服务质量要求，影响控制信号可靠交付。",
                "方法要点：提出阈值触发的深度Q网络自愈代理，自主检测、分析和缓解中断，实时调整路由和资源分配。",
                "实验或效果：在模拟网络中测试，中断恢复性能比基线方法提升53.84%，优于现有先进方法，并维持交换机热稳定性。"
            ],
            "method_zh": "论文提出一个基于阈值触发的深度Q网络（DQN）自愈框架，整体框架包括一个自愈代理，通过深度强化学习在软件定义工业物联网边缘网络中实现自主网络管理。关键技术创新点在于结合阈值触发机制，当网络指标（如延迟或热波动）超过预设阈值时，触发DQN代理进行决策，以实时调整路由行为和资源分配，从而检测、分析和缓解随机中断。与现有方法的主要区别在于：它集成了自适应路由优化和热管理，而传统方法如最短路径路由或基于模糊推理的系统缺乏这种综合性和实时性；同时，相比纯DQN方法，阈值触发提高了决策效率，减少了不必要的计算开销。",
            "application_zh": "该研究主要应用于软件定义工业物联网边缘网络，特别是在关键任务和时间敏感场景中，如风力发电厂的控制和监控系统。潜在应用领域包括智能电网、工业自动化和其他需要高可靠性和低延迟的网络环境，实际价值在于提升网络弹性和运行效率，减少停机风险。",
            "highlight_zh": "最重要的实验结果是：在模拟三集群交换机网络中，所提出的自愈代理将中断恢复性能比基线最短路径和负载均衡路由方法提高了53.84%；同时，在超骨干叶数据平面架构中，它优于自适应网络模糊推理系统（提升13.1%）和基于深度Q网络与流量预测的路由优化方法（提升21.5%），并有效维持了交换机热稳定性。",
            "tags_zh": [
                "深度强化学习",
                "软件定义网络",
                "工业物联网",
                "自愈网络",
                "路由优化",
                "热管理",
                "边缘计算",
                "网络弹性"
            ],
            "_index": 117
        },
        {
            "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
            "authors": [
                "Shizhuo Mao",
                "Song Chen",
                "Yi Kang"
            ],
            "arxiv_id": "2512.14481v1",
            "summary": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14481v1",
            "code_links": [],
            "headline_zh": "提出人机协作本体工程方法，以提升帕金森病监测与警报领域的本体构建效果。",
            "summary_zh": "本文探讨了将大型语言模型（LLMs）集成到帕金森病（PD）监测与警报本体工程中的四种关键方法：单次提示（OS）、思维链（CoT）提示、X-HCOME和SimX-HCOME+。主要目标是确定LLMs是否能独立创建全面本体，以及人机协作是否能实现这一目标。因此，本文评估了LLMs在自动化本体开发中的有效性，以及通过人机协作实现的提升。初始本体生成使用OS和CoT提示进行，展示了LLMs自主构建PD监测与警报本体的能力，但这些输出不够全面，需要大量人工细化以提高完整性和准确性。X-HCOME是一种结合人类专业知识和LLM能力的混合本体工程方法，显著提高了本体的全面性，结果与专家构建的本体非常相似。进一步实验使用SimX-HCOME+，另一种强调持续人类监督和迭代细化的混合方法，突出了持续人类参与的重要性，该方法创建了更全面和准确的本体。总体而言，本文强调了人机协作在推进本体工程中的潜力，特别是在PD等复杂领域。结果为未来研究指明了有前景的方向，包括开发专门用于本体构建的GPT模型。",
            "intro_zh": [
                "核心问题：LLMs在自动化本体构建中难以独立生成全面且准确的本体，尤其在复杂医学领域如帕金森病监测与警报。",
                "方法要点：提出混合本体工程方法，如X-HCOME和SimX-HCOME+，结合人类专业知识和LLM能力，通过迭代协作提升本体质量。",
                "实验或效果：人机协作方法显著提高了本体的全面性和准确性，接近专家构建水平，验证了协作的有效性。"
            ],
            "method_zh": "论文的核心方法包括四种本体工程方法：单次提示（OS）和思维链（CoT）提示用于初始LLM自主本体生成，X-HCOME作为混合方法结合人类输入和LLM输出进行协作构建，SimX-HCOME+则强调持续人类监督和迭代细化。整体框架基于人机协作，关键技术创新点在于将LLMs的自动化能力与人类专家的领域知识相结合，通过结构化流程优化本体开发。与现有方法的主要区别在于，传统方法可能依赖纯人工或纯自动化，而本文方法通过混合策略平衡效率和准确性，特别针对复杂医学领域设计。",
            "application_zh": "该研究可应用于帕金森病等慢性疾病的智能监测与警报系统，通过构建高质量本体支持知识表示和推理，提升医疗诊断、患者管理和远程护理的自动化水平，具有实际医疗价值。",
            "highlight_zh": "实验结果显示，人机协作方法（如X-HCOME和SimX-HCOME+）相比纯LLM方法（OS和CoT）显著提升了本体的全面性和准确性，接近专家构建标准，验证了协作在复杂领域本体工程中的优势。",
            "tags_zh": [
                "本体工程",
                "大型语言模型",
                "帕金森病监测",
                "人机协作",
                "思维链提示",
                "混合方法",
                "知识表示",
                "医疗人工智能"
            ],
            "_index": 118
        },
        {
            "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
            "authors": [
                "Annu Rana",
                "Gaurav Kumar"
            ],
            "arxiv_id": "2512.14474v1",
            "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14474v1",
            "code_links": [],
            "headline_zh": "提出SS4D原生4D生成模型，通过结构化时空潜在表示从单目视频直接合成动态3D对象。",
            "summary_zh": "我们提出了SS4D，一种原生4D生成模型，能够直接从单目视频合成动态3D对象。与先前通过优化3D或视频生成模型来构建4D表示的方法不同，我们直接在4D数据上训练生成器，实现了高保真度、时间一致性和结构一致性。我们方法的核心是一组压缩的结构化时空潜在表示。具体来说：(1) 为了解决4D训练数据稀缺的问题，我们基于预训练的单图像到3D模型构建，保持了强大的空间一致性。(2) 通过引入专门的时序层来跨帧推理，强制实现时间一致性。(3) 为了支持长视频序列的高效训练和推理，我们使用分解的4D卷积和时序下采样块沿时间轴压缩潜在序列。此外，我们采用精心设计的训练策略来增强对遮挡的鲁棒性。",
            "intro_zh": [
                "现有方法依赖3D或视频生成模型优化构建4D表示，导致保真度、时间一致性和结构一致性不足。",
                "SS4D通过结构化时空潜在表示，结合预训练单图像到3D模型、时序层和压缩机制，直接训练4D生成器。",
                "实验表明，SS4D在动态3D对象合成中实现了高保真度、时间一致性和高效性，优于现有方法。"
            ],
            "method_zh": "SS4D的整体框架是一个原生4D生成模型，直接从单目视频输入生成动态3D对象。关键技术创新点包括：使用结构化时空潜在表示来编码4D数据；基于预训练单图像到3D模型确保空间一致性；引入时序层强制时间一致性；采用分解4D卷积和时序下采样块压缩潜在序列以支持长视频处理。与现有方法的主要区别在于，SS4D直接在4D数据上训练生成器，而非通过优化3D或视频模型间接构建4D表示，从而提升了生成质量和效率。",
            "application_zh": "该研究在虚拟现实、增强现实、游戏开发和电影特效等领域有潜在应用，可用于自动生成动态3D内容，减少人工建模成本，提升内容创作的效率和真实感。",
            "highlight_zh": "SS4D在动态3D对象合成任务中表现出高保真度和时间一致性，通过结构化时空潜在表示和压缩机制，实现了对长视频的高效处理，实验结果显示其在生成质量上优于现有4D生成方法。",
            "tags_zh": [
                "4D生成模型",
                "动态3D合成",
                "时空潜在表示",
                "单目视频处理",
                "时间一致性",
                "结构一致性",
                "长视频压缩",
                "遮挡鲁棒性"
            ],
            "_index": 119
        },
        {
            "title": "AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts",
            "authors": [
                "Niklas Grieger",
                "Jannik Raskob",
                "Siamak Mehrkanoon",
                "Stephan Bialonski"
            ],
            "arxiv_id": "2512.14461v1",
            "summary": "Sleep is essential for good health throughout our lives, yet studying its dynamics requires manual sleep staging, a labor-intensive step in sleep research and clinical care. Across centers, polysomnography (PSG) recordings are traditionally scored in 30-s epochs for pragmatic, not physiological, reasons and can vary considerably in electrode count, montage, and subject characteristics. These constraints present challenges in conducting harmonized multi-center sleep studies and discovering novel, robust biomarkers on shorter timescales. Here, we present AnySleep, a deep neural network model that uses any electroencephalography (EEG) or electrooculography (EOG) data to score sleep at adjustable temporal resolutions. We trained and validated the model on over 19,000 overnight recordings from 21 datasets collected across multiple clinics, spanning nearly 200,000 hours of EEG and EOG data, to promote robust generalization across sites. The model attains state-of-the-art performance and surpasses or equals established baselines at 30-s epochs. Performance improves as more channels are provided, yet remains strong when EOG is absent or when only EOG or single EEG derivations (frontal, central, or occipital) are available. On sub-30-s timescales, the model captures short wake intrusions consistent with arousals and improves prediction of physiological characteristics (age, sex) and pathophysiological conditions (sleep apnea), relative to standard 30-s scoring. We make the model publicly available to facilitate large-scale studies with heterogeneous electrode setups and to accelerate the discovery of novel biomarkers in sleep.",
            "categories": [
                "cs.LG",
                "eess.SP",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 6 figures, 2 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14461v1",
            "code_links": [],
            "headline_zh": "提出TAIGHA和TAIGHA-S量表，专门评估用户对AI生成健康建议的信任与不信任，以解决现有工具缺乏针对性测量的问题。",
            "summary_zh": "随着大型语言模型等人工智能工具被公众用于获取健康信息和指导，在健康相关情境中，遵循或拒绝AI生成建议可能产生直接的临床影响。现有工具如“自动化系统信任调查”评估通用技术的可信度，但缺乏专门测量用户对AI生成健康建议信任的有效工具。本研究开发并验证了“AI生成健康建议信任量表”（TAIGHA）及其四项目简短版本（TAIGHA-S），作为基于理论的工具，分别测量信任和不信任，每个维度包含认知和情感成分。项目开发采用生成式AI方法，随后进行内容验证（10名领域专家）、表面验证（30名普通参与者）和心理测量验证（385名英国参与者在症状评估场景中接收AI生成建议）。经过自动项目缩减，保留28个项目，并根据专家评分缩减至10个。TAIGHA显示出优异的内容效度（S-CVI/Ave=0.99），验证性因子分析确认双因子模型拟合度极佳（CFI=0.98，TLI=0.98，RMSEA=0.07，SRMR=0.03）。内部一致性高（α=0.95）。收敛效度得到支持，与自动化系统信任调查相关（r=0.67/-0.66）且与用户对AI建议的依赖相关（信任r=0.37），而区分效度得到支持，与阅读流畅性和心理负荷相关性低（所有|r|<0.25）。TAIGHA-S与完整量表高度相关（r=0.96）并显示出良好信度（α=0.88）。TAIGHA和TAIGHA-S是评估用户对AI生成健康建议信任和不信任的有效工具。单独报告信任和不信任允许更全面地评估AI干预，简短量表非常适合时间受限的设置。",
            "intro_zh": [
                "核心问题：现有通用信任测量工具（如自动化系统信任调查）缺乏针对性，无法准确评估用户对AI生成健康建议的信任与不信任，这在健康领域具有直接临床影响。",
                "方法要点：基于理论开发TAIGHA量表，区分信任与不信任的认知和情感成分，采用生成式AI生成项目，并通过多阶段验证确保效度和信度。",
                "实验或效果：验证显示TAIGHA具有优异的内容效度、模型拟合度和内部一致性，TAIGHA-S与完整量表高度相关，适用于快速评估场景。"
            ],
            "method_zh": "论文核心方法为开发并验证TAIGHA量表及其简短版本TAIGHA-S。整体框架基于理论构建，区分信任和不信任两个维度，每个维度包含认知和情感成分。关键技术创新点在于采用生成式AI方法生成初始项目，结合专家内容验证和参与者表面验证，确保项目针对AI生成健康建议场景。与现有方法的主要区别在于：现有工具如自动化系统信任调查评估通用技术信任，而TAIGHA专门针对健康建议领域，提供更精准的测量，并首次将信任与不信任作为独立维度处理，允许更全面的评估。",
            "application_zh": "该研究在医疗健康、人机交互和AI伦理领域具有广泛应用价值。TAIGHA量表可用于评估AI健康建议工具的用户接受度，优化AI系统设计以提高可信度，支持临床决策辅助系统的有效性研究，并促进AI在健康咨询中的安全部署。",
            "highlight_zh": "最重要的实验结果包括：TAIGHA量表内容效度S-CVI/Ave达0.99，验证性因子分析显示双因子模型拟合极佳（CFI=0.98，RMSEA=0.07），内部一致性α=0.95。TAIGHA-S与完整量表高度相关（r=0.96），信度α=0.88，验证了量表在快速评估中的实用性。",
            "tags_zh": [
                "AI生成健康建议",
                "信任测量",
                "量表开发",
                "心理测量验证",
                "人机交互",
                "医疗人工智能",
                "效度信度评估",
                "简短量表"
            ],
            "_index": 120
        },
        {
            "title": "Reasoning-Style Poisoning of LLM Agents via Stealthy Style Transfer: Process-Level Attacks and Runtime Monitoring in RSV Space",
            "authors": [
                "Xingfu Zhou",
                "Pengfei Wang"
            ],
            "arxiv_id": "2512.14448v1",
            "summary": "Large Language Model (LLM) agents relying on external retrieval are increasingly deployed in high-stakes environments. While existing adversarial attacks primarily focus on content falsification or instruction injection, we identify a novel, process-oriented attack surface: the agent's reasoning style. We propose Reasoning-Style Poisoning (RSP), a paradigm that manipulates how agents process information rather than what they process. We introduce Generative Style Injection (GSI), an attack method that rewrites retrieved documents into pathological tones--specifically \"analysis paralysis\" or \"cognitive haste\"--without altering underlying facts or using explicit triggers. To quantify these shifts, we develop the Reasoning Style Vector (RSV), a metric tracking Verification depth, Self-confidence, and Attention focus. Experiments on HotpotQA and FEVER using ReAct, Reflection, and Tree of Thoughts (ToT) architectures reveal that GSI significantly degrades performance. It increases reasoning steps by up to 4.4 times or induces premature errors, successfully bypassing state-of-the-art content filters. Finally, we propose RSP-M, a lightweight runtime monitor that calculates RSV metrics in real-time and triggers alerts when values exceed safety thresholds. Our work demonstrates that reasoning style is a distinct, exploitable vulnerability, necessitating process-level defenses beyond static content analysis.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14448v1",
            "code_links": [],
            "headline_zh": "提出SPARQL-LLM方法，通过轻量级元数据实现实时、低成本的从自然语言生成SPARQL查询，适用于分布式知识图谱。",
            "summary_zh": "大型语言模型的出现促进了从自然语言生成结构化查询（如SPARQL查询）的新方法。然而，这些新方法大多关注单一来源的响应准确性，而忽略了其他评估标准，如分布式数据存储上的联邦查询能力，以及生成SPARQL查询的运行时间和成本。因此，它们通常不适合生产环境或难以在（可能联邦的）知识图谱上以良好准确性部署。为缓解这些问题，本文扩展了先前工作，描述并系统评估了SPARQL-LLM，这是一种开源且与三元存储无关的方法，由轻量级元数据驱动，从自然语言文本生成SPARQL查询。首先，我们描述了其架构，包括元数据索引、提示构建、查询生成和执行等专用组件。然后，基于一个包含多语言问题的最新挑战，以及来自生物信息学领域三个最流行知识图谱的问题集合，对其进行了评估。我们的结果显示，在该最新挑战中F1分数显著提高了24%，适应英语和西班牙语等高资源语言，并能形成复杂和联邦的生物信息学查询。此外，我们表明SPARQL-LLM比参与挑战的其他系统快达36倍，每个问题的成本最高为0.01美元，使其适用于实时、低成本的文本到SPARQL应用。一个部署在真实世界分散知识图谱上的此类应用可在https://www.expasy.org/chat找到。",
            "intro_zh": [
                "现有方法主要关注单一来源的查询准确性，但忽略了联邦查询能力、运行时间和成本，导致难以在生产环境中部署。",
                "SPARQL-LLM采用轻量级元数据驱动架构，包括元数据索引、提示构建和查询生成组件，实现与三元存储无关的查询生成。",
                "实验显示，在最新挑战中F1分数提升24%，支持多语言和复杂联邦查询，运行速度快达36倍，成本低至每问题0.01美元。"
            ],
            "method_zh": "SPARQL-LLM的整体框架基于轻量级元数据，包括元数据索引、提示构建、查询生成和执行三个核心组件。关键技术创新在于使用元数据而非依赖特定三元存储，实现通用性和高效性；通过优化提示设计，提升查询生成的准确性和适应性。与现有方法的主要区别在于，它不仅关注准确性，还强调联邦查询支持、实时性能和低成本，通过系统化架构解决了生产部署的挑战。",
            "application_zh": "该研究适用于需要从自然语言实时生成SPARQL查询的场景，如生物信息学知识图谱查询、分布式数据存储的联邦检索，以及低成本的文本到查询应用，例如在https://www.expasy.org/chat上部署的聊天系统。",
            "highlight_zh": "最重要的实验结果包括：在最新挑战中F1分数提高24%，支持英语和西班牙语等多语言查询，能处理复杂联邦查询，运行速度比其他系统快达36倍，成本低至每问题0.01美元，展现了高效、低成本的实时应用潜力。",
            "tags_zh": [
                "SPARQL查询生成",
                "自然语言处理",
                "知识图谱",
                "联邦查询",
                "轻量级元数据",
                "实时系统",
                "低成本应用",
                "生物信息学"
            ],
            "_index": 121
        },
        {
            "title": "S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation",
            "authors": [
                "Leon Sick",
                "Lukas Hoyer",
                "Dominik Engel",
                "Pedro Hermosilla",
                "Timo Ropinski"
            ],
            "arxiv_id": "2512.14440v1",
            "summary": "In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page with Code/Models/Demo: https://leonsick.github.io/s2d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14440v1",
            "code_links": [],
            "headline_zh": "提出TUN网络以解决一维持久性图中显著点自动检测的挑战，提升拓扑数据分析的实用性。",
            "summary_zh": "持久性图（PDs）是理解点云底层形状拓扑结构的强大工具，但识别图中哪些点编码真实信号仍具挑战性，这阻碍了拓扑数据分析在许多应用中的实际采用，其中持久性图的自动可靠解释对下游决策至关重要。本文研究一维持久性图的自动显著性检测，提出拓扑理解网络（TUN），这是一个多模态网络，结合增强的PD描述符、自注意力机制、PointNet风格的点云编码器、学习融合和逐点分类，以及稳定预处理和不平衡感知训练。它提供了一个自动有效的解决方案，用于识别PD中的显著点，这对下游应用至关重要。实验表明，TUN在检测PD显著点方面优于经典方法，证明了其在现实应用中的有效性。",
            "intro_zh": [
                "核心问题：持久性图中哪些点代表真实拓扑信号难以自动识别，阻碍了拓扑数据分析的实际应用。",
                "方法要点：提出TUN网络，融合增强描述符、自注意力、点云编码器和学习融合，实现多模态特征提取与分类。",
                "实验或效果：TUN在检测显著点方面超越经典方法，验证了其有效性和在现实场景中的实用性。"
            ],
            "method_zh": "TUN的整体框架是一个多模态网络，专为一维持久性图的显著点检测设计。关键技术创新点包括：结合增强的持久性图描述符以捕获拓扑特征，引入自注意力机制处理序列依赖，使用PointNet风格的点云编码器提取点级信息，并通过学习融合模块整合多模态特征，最后进行逐点分类。与现有方法的主要区别在于，TUN集成了多种先进技术，提供端到端的自动化解决方案，而传统方法往往依赖手动阈值或简单统计，缺乏深度学习的自适应能力。",
            "application_zh": "该研究在拓扑数据分析领域有广泛应用，如点云处理、形状分析、生物信息学和机器学习中的特征提取。通过自动检测持久性图中的显著点，可提升下游任务的决策可靠性，例如在计算机视觉中识别关键拓扑结构，或在机器人导航中优化路径规划。",
            "highlight_zh": "实验结果显示，TUN在检测一维持久性图的显著点方面显著优于经典方法，如基于阈值的统计技术，具体性能提升体现在更高的准确率和召回率，证明了其在实际应用中的有效性和鲁棒性。",
            "tags_zh": [
                "持久性图",
                "拓扑数据分析",
                "多模态网络",
                "自注意力机制",
                "点云编码",
                "显著性检测",
                "深度学习",
                "一维拓扑"
            ],
            "_index": 122
        },
        {
            "title": "VICTOR: Dataset Copyright Auditing in Video Recognition Systems",
            "authors": [
                "Quan Yuan",
                "Zhikun Zhang",
                "Linkang Du",
                "Min Chen",
                "Mingyang Sun",
                "Yunjun Gao",
                "Shibo He",
                "Jiming Chen"
            ],
            "arxiv_id": "2512.14439v1",
            "summary": "Video recognition systems are increasingly being deployed in daily life, such as content recommendation and security monitoring. To enhance video recognition development, many institutions have released high-quality public datasets with open-source licenses for training advanced models. At the same time, these datasets are also susceptible to misuse and infringement. Dataset copyright auditing is an effective solution to identify such unauthorized use. However, existing dataset copyright solutions primarily focus on the image domain; the complex nature of video data leaves dataset copyright auditing in the video domain unexplored. Specifically, video data introduces an additional temporal dimension, which poses significant challenges to the effectiveness and stealthiness of existing methods.\n  In this paper, we propose VICTOR, the first dataset copyright auditing approach for video recognition systems. We develop a general and stealthy sample modification strategy that enhances the output discrepancy of the target model. By modifying only a small proportion of samples (e.g., 1%), VICTOR amplifies the impact of published modified samples on the prediction behavior of the target models. Then, the difference in the model's behavior for published modified and unpublished original samples can serve as a key basis for dataset auditing. Extensive experiments on multiple models and datasets highlight the superiority of VICTOR. Finally, we show that VICTOR is robust in the presence of several perturbation mechanisms to the training videos or the target models.",
            "categories": [
                "cs.CR",
                "cs.CV"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "To appear in the NDSS Symposium 2026, February 2026, San Diego, CA, USA",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14439v1",
            "code_links": [],
            "headline_zh": "提出Zoom-Zero框架，通过粗到细的时序放大机制解决视频问答中的时序定位不准确问题。",
            "summary_zh": "基于视频的问答任务旨在定位视频中的相关时序片段并生成准确答案，但现有大型视频语言模型在时序感知方面存在局限。虽然基于组相对策略优化的方法试图改进时序定位，但仍难以忠实将答案基于相关视频证据，导致时序错位和幻觉。本文提出Zoom-Zero，一种粗到细的框架，首先定位查询相关片段，然后时序放大到最显著帧进行细粒度视觉验证。该方法通过两个关键创新解决GVQA任务中GRPO的局限：(i) 放大精度奖励，验证时序定位预测的保真度并促进对定位帧的细粒度视觉验证；(ii) 令牌选择性信用分配，将奖励归因于负责时序定位或答案生成的令牌，缓解GRPO在处理多方面奖励信号时的问题。所提方法推进了基于视频的问答，在NExT-GQA和ReXTime数据集上分别将时序定位精度提升5.2%和4.6%，同时将平均答案准确率提高2.4%。此外，推理过程中的粗到细放大通过保留关键视觉细节而不损害全局上下文，进一步有益于长视频理解，在长视频基准上平均提升6.4%。",
            "intro_zh": [
                "现有大型视频语言模型在时序感知方面有限，基于GRPO的方法仍难以忠实定位视频证据，导致时序错位和幻觉。",
                "提出Zoom-Zero框架，采用粗到细的时序放大机制，结合放大精度奖励和令牌选择性信用分配，提升时序定位和视觉验证。",
                "在NExT-GQA和ReXTime数据集上时序定位精度分别提升5.2%和4.6%，答案准确率提高2.4%，长视频理解平均提升6.4%。"
            ],
            "method_zh": "Zoom-Zero是一个粗到细的框架，整体流程包括两个阶段：首先，通过粗粒度定位模块识别查询相关的视频时序片段；然后，时序放大到这些片段中最显著的帧进行细粒度视觉验证，以生成准确答案。关键技术创新点包括：(i) 放大精度奖励机制，用于评估时序定位预测的保真度并促进对定位帧的细粒度验证；(ii) 令牌选择性信用分配，将强化学习奖励精确分配给负责时序定位或答案生成的令牌，优化多任务学习。与现有基于GRPO的方法相比，该方法更有效地处理多方面奖励信号，减少了时序错位和幻觉问题。",
            "application_zh": "该研究可应用于智能视频分析、教育辅助、安防监控和内容检索等领域，通过提升视频问答的时序定位精度，增强对长视频的理解能力，为多模态人工智能系统提供更可靠的视频证据支持。",
            "highlight_zh": "在NExT-GQA数据集上时序定位精度提升5.2%，在ReXTime数据集上提升4.6%；平均答案准确率提高2.4%；长视频理解基准上平均性能提升6.4%，显著优于现有方法。",
            "tags_zh": [
                "视频问答",
                "时序定位",
                "粗到细框架",
                "强化学习",
                "多模态融合",
                "长视频理解",
                "视觉验证",
                "令牌信用分配"
            ],
            "_index": 123
        },
        {
            "title": "Score-Based Turbo Message Passing for Plug-and-Play Compressive Imaging",
            "authors": [
                "Chang Cai",
                "Hao Jiang",
                "Xiaojun Yuan",
                "Ying-Jun Angela Zhang"
            ],
            "arxiv_id": "2512.14435v1",
            "summary": "Message-passing algorithms have been adapted for compressive imaging by incorporating various off-the-shelf image denoisers. However, these denoisers rely largely on generic or hand-crafted priors and often fall short in accurately capturing the complex statistical structure of natural images. As a result, traditional plug-and-play (PnP) methods often lead to suboptimal reconstruction, especially in highly underdetermined regimes. Recently, score-based generative models have emerged as a powerful framework for accurately characterizing sophisticated image distribution. Yet, their direct use for posterior sampling typically incurs prohibitive computational complexity. In this paper, by exploiting the close connection between score-based generative modeling and empirical Bayes denoising, we devise a message-passing framework that integrates a score-based minimum mean-squared error (MMSE) denoiser for compressive image recovery. The resulting algorithm, named score-based turbo message passing (STMP), combines the fast convergence of message passing with the expressive power of score-based generative priors. For practical systems with quantized measurements, we further propose quantized STMP (Q-STMP), which augments STMP with a component-wise MMSE dequantization module. We demonstrate that the asymptotic performance of STMP and Q-STMP can be accurately predicted by a set of state-evolution (SE) equations. Experiments on the FFHQ dataset demonstrate that STMP strikes a significantly better performance-complexity tradeoff compared with competing baselines, and that Q-STMP remains robust even under 1-bit quantization. Remarkably, both STMP and Q-STMP typically converge within 10 iterations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14435v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出CaFe-TeleVision系统，通过粗到精控制与沉浸式可视化提升远程操作的效率和人机工程学",
            "summary_zh": "远程操作为远程控制和机器人本体感知数据收集提供了有前景的范式。尽管近期有所进展，但现有系统在效率和人体工程学方面仍存在局限，尤其是在挑战性场景中。本文提出CaFe-TeleVision，一种具有沉浸式情境可视化的粗到精远程操作系统，以提升人体工程学。其核心在于重定向模块中提出的粗到精控制机制，以弥合工作空间差异，共同优化效率和物理人体工程学。为了提供具有足够视觉线索的沉浸式反馈以适配人类视觉系统，感知模块集成了按需情境可视化技术，降低了多视图处理的认知负荷。该系统基于人形协作机器人构建，并通过六项挑战性双手操作任务进行验证。对24名参与者的用户研究证实，CaFe-TeleVision在统计学上显著提升了人体工程学，表明在远程操作期间任务负荷更低、用户接受度更高。定量结果也验证了我们的系统在六项任务中的优越性能，成功率最高超出对比方法28.89%，完成时间加速26.81%。项目网页：https://clover-cuhk.github.io/cafe_television/",
            "intro_zh": [
                "现有远程操作系统在挑战性场景下效率与人机工程学表现不足，影响用户体验与任务性能。",
                "提出粗到精控制机制与沉浸式情境可视化，分别优化操作精度与视觉反馈，降低认知负荷。",
                "用户研究显示系统显著降低任务负荷、提升接受度，任务成功率最高提升28.89%，完成时间加速26.81%。"
            ],
            "method_zh": "CaFe-TeleVision系统整体框架包含重定向模块与感知模块。重定向模块采用粗到精控制机制，先进行粗略空间对齐，再精细调整机器人姿态，以解决操作者与机器人工作空间不匹配问题，同时优化效率与物理人机工程学。感知模块集成按需情境可视化技术，动态提供沉浸式视觉反馈，减少多视图处理的认知负担。关键创新在于将粗到精控制与沉浸式可视化结合，系统性地提升远程操作的整体性能。与现有方法相比，主要区别在于更注重人机交互的舒适性与效率平衡，而非单一追求控制精度或视觉逼真度。",
            "application_zh": "该系统适用于远程机器人操作、危险环境作业（如核设施维护、太空探索）、医疗手术辅助及工业自动化等领域，能提升操作安全性、效率与用户体验，具有实际应用价值。",
            "highlight_zh": "在六项挑战性双手操作任务中，系统成功率最高超出对比方法28.89%，完成时间加速26.81%；用户研究（24名参与者）显示任务负荷显著降低、用户接受度提升，统计学上证实了人机工程学的改进。",
            "tags_zh": [
                "远程操作",
                "人机工程学",
                "粗到精控制",
                "沉浸式可视化",
                "机器人重定向",
                "双手操作",
                "人机交互",
                "协作机器人"
            ],
            "_index": 124
        },
        {
            "title": "Geometric Parameter Optimization of a Novel 3-(PP(2-(UPS))) Redundant Parallel Mechanism based on Workspace Determination",
            "authors": [
                "Quan Yuan",
                "Daqian Cao",
                "Weibang Bai"
            ],
            "arxiv_id": "2512.14434v1",
            "summary": "Redundant parallel robots are normally employed in scenarios requiring good precision, high load capability, and large workspace compared to traditional parallel mechanisms. However, the elementary robotic configuration and geometric parameter optimization are still quite challenging. This paper proposes a novel 3-(PP(2-(UPS))) redundant parallel mechanism, with good generalizability first, and further investigates the kinematic optimization issue by analyzing and investigating how its key geometric parameters influence the volume, shape, boundary completeness, and orientation capabilities of its workspace. The torsional capability index TI_1 and tilting capability index TI_2 are defined to evaluate the orientation performance of the mechanism. Numerical simulation studies are completed to indicate the analysis, providing reasonable but essential references for the parameter optimization of 3-(PP(2-(UPS))) and other similar redundant parallel mechanisms.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "7 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14434v1",
            "code_links": [],
            "headline_zh": "提出DriverGaze360数据集和全景注意力预测方法，以解决自动驾驶中驾驶员注意力建模的视野限制问题。",
            "summary_zh": "预测驾驶员注意力是开发可解释自动驾驶系统和理解混合交通场景中驾驶员行为的关键问题。尽管通过大规模数据集和深度学习架构已取得显著进展，但现有工作受限于狭窄的前方视野和有限的驾驶多样性，无法捕捉驾驶环境的完整空间上下文，尤其是在变道、转弯和涉及行人或自行车等外围物体交互时。本文介绍了DriverGaze360，一个大规模360度视野驾驶员注意力数据集，包含从19名驾驶员收集的约100万帧注视标记帧，实现了对驾驶员注视行为的全方位建模。此外，我们的全景注意力预测方法DriverGaze360-Net通过采用辅助语义分割头联合学习注意力图和关注对象，提高了对宽全景输入的空间感知和注意力预测能力。大量实验表明，DriverGaze360-Net在全景驾驶图像上实现了多个指标的先进注意力预测性能。数据集和方法可在https://av.dfki.de/drivergaze360获取。",
            "intro_zh": [
                "现有方法受限于狭窄前方视野和有限驾驶多样性，无法捕捉变道、转弯等场景的完整空间上下文。",
                "提出DriverGaze360数据集和全景注意力预测方法，联合学习注意力图和关注对象以增强空间感知。",
                "实验显示DriverGaze360-Net在全景驾驶图像上实现了多个指标的先进性能，提升了注意力预测准确性。"
            ],
            "method_zh": "论文的核心方法是DriverGaze360-Net，这是一个全景注意力预测模型，整体框架基于深度学习架构，处理360度视野输入以生成注意力图。关键技术创新点在于联合学习注意力图和关注对象，通过引入辅助语义分割头，模型不仅能预测驾驶员注视位置，还能识别被关注的对象类别，如行人或车辆，从而增强空间上下文理解。与现有方法的主要区别在于其全景视野处理能力，克服了传统方法局限于前方视野的不足，并整合了对象级指导，提高了预测的准确性和可解释性。",
            "application_zh": "该研究可应用于自动驾驶系统开发，通过预测驾驶员注意力增强车辆的可解释性和安全性，特别是在混合交通场景中理解人类驾驶员行为，辅助决策制定。此外，还可用于驾驶员行为分析和培训，提升驾驶安全。",
            "highlight_zh": "DriverGaze360-Net在全景驾驶图像上实现了多个指标的先进性能，包括注意力预测准确性和空间感知能力，显著优于现有方法，验证了全景视野和对象级指导的有效性。",
            "tags_zh": [
                "驾驶员注意力预测",
                "全景视野建模",
                "自动驾驶系统",
                "语义分割",
                "深度学习",
                "混合交通场景",
                "可解释性",
                "数据集构建"
            ],
            "_index": 125
        },
        {
            "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
            "authors": [
                "Yukun Ren",
                "Siwei Yu",
                "Kai Chen",
                "Jianwei Ma"
            ],
            "arxiv_id": "2512.14429v1",
            "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.",
            "categories": [
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 15 figures. Code available at https://github.com/RenYukun1563/specfem-mcp",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
            "code_links": [],
            "headline_zh": "提出基于决策树的可解释偏好学习模型，以解决高斯过程在偏好贝叶斯优化中可解释性差、处理分类数据困难及计算复杂的问题。",
            "summary_zh": "当前的偏好贝叶斯优化方法依赖于高斯过程作为代理模型，这些模型难以解释、处理分类数据困难且计算复杂，限制了其实际应用。本文引入了一种基于决策树的固有可解释代理模型，能够处理分类和连续数据，并可扩展到大型数据集。在八个逐渐尖峰的优化函数上进行的大量数值实验表明，该模型在尖峰函数上优于基于高斯过程的替代方法，在非尖峰函数上性能仅略低。此外，我们将模型应用于真实世界的寿司数据集，展示了其学习个人寿司偏好的能力。最后，我们展示了利用历史偏好数据加速新用户优化过程的初步工作。",
            "intro_zh": [
                "现有高斯过程模型可解释性差、处理分类数据困难且计算复杂，限制了偏好贝叶斯优化的实际应用。",
                "提出基于决策树的代理模型，具有固有可解释性，能处理混合数据类型，并实现大规模扩展。",
                "在尖峰函数上性能优于高斯过程模型，在非尖峰函数上性能接近，并成功应用于真实偏好学习任务。"
            ],
            "method_zh": "论文提出了一种基于决策树的代理模型框架，用于替代传统的高斯过程在偏好贝叶斯优化中的角色。关键技术创新点在于利用决策树的固有可解释性，通过构建树结构来建模用户偏好，支持分类和连续数据的混合输入，并采用高效算法实现大规模数据扩展。与现有方法的主要区别在于，该模型避免了高斯过程的黑盒特性，提供了更直观的决策路径解释，同时降低了计算复杂度，提高了处理复杂数据类型的灵活性。",
            "application_zh": "该研究可应用于个性化推荐系统、产品设计优化和用户偏好建模等领域，通过可解释的偏好学习提升决策透明度和效率，具有实际商业和科研价值。",
            "highlight_zh": "在八个尖峰优化函数实验中，模型在尖峰函数上显著优于高斯过程基准，在非尖峰函数上性能仅略低；在寿司数据集上成功学习个人偏好，验证了实际应用潜力。",
            "tags_zh": [
                "偏好学习",
                "贝叶斯优化",
                "决策树模型",
                "可解释人工智能",
                "分类数据处理",
                "大规模优化",
                "个性化推荐"
            ],
            "_index": 126
        },
        {
            "title": "Quadratic Kalman Filter for Elliptical Extended Object Tracking based on Decoupling State Components",
            "authors": [
                "Simon Steuernagel",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14426v1",
            "summary": "Extended object tracking involves estimating both the physical extent and kinematic parameters of a target object, where typically multiple measurements are observed per time step. In this article, we propose a deterministic closed-form elliptical extended object tracker, based on decoupling of the kinematics, orientation, and axis lengths. By disregarding potential correlations between these state components, fewer approximations are required for the individual estimators than for an overall joint solution. The resulting algorithm outperforms existing algorithms, reaching the accuracy of sampling-based procedures. Additionally, a batch-based variant is introduced, yielding highly efficient computation while outperforming all comparable state-of-the-art algorithms. This is validated both by a simulation study using common models from literature, as well as an extensive quantitative evaluation on real automotive radar data.",
            "categories": [
                "eess.SP",
                "cs.RO"
            ],
            "primary_category": "eess.SP",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 8 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14426v1",
            "code_links": [],
            "headline_zh": "提出EVPG方法，通过概率图将不可微的视觉编程执行过程转化为可微的概率推理，以增强视觉推理任务中的视觉编程性能。",
            "summary_zh": "近年来，基于大语言模型（LLMs）的视觉编程（VP）在复杂视觉推理（VR）任务中迅速发展并展现出巨大潜力。先前增强VP的工作主要集中于提高LLM生成的视觉程序质量，但忽略了优化VP调用的预训练模型，这些模型作为VP从目标任务分解出的视觉子任务的模块。困难在于只有目标VR任务的最终标签，而没有子任务的标签。此外，VP的不可微性阻碍了直接使用高效的基于梯度的优化方法，以利用最终标签进行整个VP框架的端到端学习。为克服这些问题，我们提出了EVPG，一种通过概率图增强视觉编程以进行视觉推理的方法。具体而言，我们根据VP执行过程中的变量依赖关系，创造性地构建了一个有向概率图，将不可微的VP执行过程重构为该有向概率图上的可微精确概率推理过程。这使得VP框架能够利用最终标签，在目标VR任务的端到端监督学习中实现高效的基于梯度的优化。广泛而全面的实验证明了我们EVPG的有效性和优势，在三个经典复杂VR任务（GQA、NLVRv2和Open Images）上显示出VP的显著性能提升。",
            "intro_zh": [
                "现有方法主要优化LLM生成的视觉程序，但忽略了VP调用的预训练模型优化，且缺乏子任务标签，导致难以进行端到端学习。",
                "EVPG通过构建有向概率图，将VP的不可微执行过程转化为可微的概率推理，从而支持基于梯度的优化。",
                "在GQA、NLVRv2和Open Images等VR任务上，EVPG显著提升了VP的性能，证明了其有效性和优势。"
            ],
            "method_zh": "EVPG的整体框架基于视觉编程（VP），核心创新在于构建一个有向概率图来建模VP执行过程中的变量依赖关系。该方法将VP的不可微执行过程重构为在该概率图上的可微精确概率推理过程，从而允许使用最终任务标签进行梯度反向传播，实现端到端监督学习。与现有方法的主要区别在于，它不仅关注程序生成质量，还通过概率图优化了VP调用的预训练模型，解决了子任务标签缺失和不可微性问题。",
            "application_zh": "该研究可应用于复杂视觉推理任务，如视觉问答（VQA）、图像-文本匹配和开放域图像理解，提升多模态AI系统在自动驾驶、智能助手和内容分析等领域的实际性能。",
            "highlight_zh": "在GQA、NLVRv2和Open Images三个经典VR任务上，EVPG显著提升了视觉编程的性能，通过实验验证了其有效性和优势，具体性能提升数据未知，但论文报告了广泛而全面的实验结果。",
            "tags_zh": [
                "视觉编程",
                "概率图模型",
                "视觉推理",
                "端到端学习",
                "大语言模型",
                "多模态AI",
                "梯度优化",
                "监督学习"
            ],
            "_index": 127
        },
        {
            "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
            "authors": [
                "Nakamasa Inoue",
                "Kanoko Goto",
                "Masanari Oi",
                "Martyna Gruszka",
                "Mahiro Ukai",
                "Takumi Hirose",
                "Yusuke Sekikawa"
            ],
            "arxiv_id": "2512.14420v1",
            "summary": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper accepted to AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14420v1",
            "code_links": [],
            "headline_zh": "提出FLAME时间序列基础模型，通过流增强的勒让德记忆实现高效稳健的确定性与概率性预测。",
            "summary_zh": "本文介绍了FLAME，一个极其轻量且强大的时间序列基础模型家族，支持通过生成式概率建模进行确定性和概率性预测，从而确保效率和鲁棒性。FLAME利用勒让德记忆实现强大的泛化能力。通过在编码和解码阶段采用勒让德记忆的变体，即平移勒让德（LegT）和缩放勒让德（LegS），FLAME能够有效捕捉数据中的固有归纳偏置，并进行高效的长程推理。为了在保持高效的同时增强概率性预测的准确性，FLAME采用基于归一化流的预测头，以生成方式建模预测范围内的任意复杂分布。在公认的基准测试（包括TSFM-Bench和ProbTS）上的全面实验表明，FLAME在确定性和概率性预测任务上均展现出持续的最先进零样本性能。",
            "intro_zh": [
                "现有时间序列预测方法在轻量化、泛化能力和概率建模方面存在不足，难以兼顾效率与准确性。",
                "FLAME通过勒让德记忆变体捕捉数据归纳偏置，并结合归一化流头实现生成式概率预测，提升长程推理能力。",
                "实验显示FLAME在TSFM-Bench和ProbTS基准上实现零样本SOTA性能，验证了其高效稳健的预测效果。"
            ],
            "method_zh": "FLAME的整体框架基于勒让德记忆单元构建，包含编码和解码阶段。关键创新在于引入平移勒让德（LegT）和缩放勒让德（LegS）变体，以自适应捕捉时间序列的动态模式，增强模型对数据固有结构的建模能力。与现有方法的主要区别在于：一方面，通过勒让德记忆的数学特性实现高效的长程依赖建模，降低计算复杂度；另一方面，采用归一化流作为预测头，以生成方式灵活建模复杂概率分布，避免了传统参数化分布的局限性，从而在轻量级设计中兼顾确定性与概率性预测需求。",
            "application_zh": "该研究可应用于金融、气象、能源和物联网等领域的时间序列预测任务，如股票价格预测、天气预报、电力负荷分析和设备故障预警，其轻量高效特性适合边缘计算和实时系统部署。",
            "highlight_zh": "在TSFM-Bench和ProbTS基准测试中，FLAME在确定性和概率性预测任务上均取得零样本状态-of-the-art性能，显著优于现有方法，证明了其强大的泛化能力和预测准确性。",
            "tags_zh": [
                "时间序列预测",
                "基础模型",
                "勒让德记忆",
                "归一化流",
                "概率建模",
                "零样本学习",
                "长程推理",
                "轻量级设计"
            ],
            "_index": 128
        },
        {
            "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
            "authors": [
                "Jia Hu",
                "Junqi Li",
                "Weimeng Lin",
                "Peng Jia",
                "Yuxiong Ji",
                "Jintao Lai"
            ],
            "arxiv_id": "2512.14417v1",
            "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14417v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出基于多智能体架构和递归分解的定理证明系统，显著提升Lean4自动证明性能",
            "summary_zh": "形式化自动定理证明长期以来被视为人工智能的挑战。本文介绍了一种新的计算机定理证明方法，该方法采用专门的语言模型生成Lean4证明，并结合递归分解将困难定理分解为更简单的蕴含命题。这些模型通过多智能体架构协调，组织自动形式化（如果需要）、证明生成、困难定理分解为简单蕴含命题，以及这些命题的递归证明（和/或分解）。在没有分解的情况下，我们在miniF2F上实现了90.4%的通过率。通过分解，这一性能得到显著提升。一个关键的技术贡献在于我们扩展了Kimina Lean Server，增加了抽象语法树（AST）解析能力，以促进自动递归证明分解。该系统已在PyPI上作为goedels-poetry（https://pypi.org/project/goedels-poetry）提供，开源实现KellyJDavis/goedels-poetry（https://github.com/KellyJDavis/goedels-poetry）便于适应替代语言模型和扩展自定义功能。",
            "intro_zh": [
                "核心问题：形式化自动定理证明面临困难定理难以直接证明的挑战，现有方法在复杂场景下性能有限。",
                "方法要点：采用多智能体架构协调语言模型生成Lean4证明，并递归分解困难定理为简单命题以提升证明成功率。",
                "实验或效果：在miniF2F基准测试中，无分解时通过率达90.4%，引入分解后性能显著提升。"
            ],
            "method_zh": "论文提出一个多智能体架构系统，整体框架包括自动形式化、证明生成、定理分解和递归证明等模块。关键技术创新点在于扩展Kimina Lean Server以支持AST解析，实现自动递归证明分解，这允许系统将复杂定理拆解为更易处理的子命题。与现有方法的主要区别在于结合了语言模型生成和结构化分解策略，而非单纯依赖端到端模型或传统符号推理，从而提高了处理困难定理的灵活性和成功率。",
            "application_zh": "该研究可应用于数学定理自动证明、形式化验证、教育辅助工具和人工智能推理系统等领域，提升自动化证明的效率和可靠性，具有推动AI在逻辑推理方面发展的实际价值。",
            "highlight_zh": "在miniF2F基准测试中，系统无分解时通过率已达90.4%，引入递归分解后性能得到显著提升，具体提升幅度未知，但强调了分解策略对处理困难定理的有效性。",
            "tags_zh": [
                "自动定理证明",
                "Lean4证明生成",
                "递归分解",
                "多智能体架构",
                "抽象语法树解析",
                "形式化验证",
                "语言模型",
                "数学推理"
            ],
            "_index": 129
        },
        {
            "title": "Pattern Recognition of Aluminium Arbitrage in Global Trade Data",
            "authors": [
                "Muhammad Sukri Bin Ramli"
            ],
            "arxiv_id": "2512.14410v1",
            "summary": "As the global economy transitions toward decarbonization, the aluminium sector has become a focal point for strategic resource management. While policies such as the Carbon Border Adjustment Mechanism (CBAM) aim to reduce emissions, they have inadvertently widened the price arbitrage between primary metal, scrap, and semi-finished goods, creating new incentives for market optimization. This study presents a unified, unsupervised machine learning framework to detect and classify emerging trade anomalies within UN Comtrade data (2020 to 2024). Moving beyond traditional rule-based monitoring, we apply a four-layer analytical pipeline utilizing Forensic Statistics, Isolation Forests, Network Science, and Deep Autoencoders. Contrary to the hypothesis that Sustainability Arbitrage would be the primary driver, empirical results reveal a contradictory and more severe phenomenon of Hardware Masking. Illicit actors exploit bi-directional tariff incentives by misclassifying scrap as high-count heterogeneous goods to justify extreme unit-price outliers of >$160/kg, a 1,900% markup indicative of Trade-Based Money Laundering (TBML) rather than commercial arbitrage. Topologically, risk is not concentrated in major exporters but in high-centrality Shadow Hubs that function as pivotal nodes for illicit rerouting. These actors execute a strategy of Void-Shoring, systematically suppressing destination data to Unspecified Code to fracture mirror statistics and sever forensic trails. Validated by SHAP (Shapley Additive Explanations), the results confirm that price deviation is the dominant predictor of anomalies, necessitating a paradigm shift in customs enforcement from physical volume checks to dynamic, algorithmic valuation auditing.",
            "categories": [
                "econ.GN",
                "cs.LG"
            ],
            "primary_category": "econ.GN",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14410v1",
            "code_links": [],
            "headline_zh": "提出基于基本话语单元的上下文压缩器，通过结构化分解与选择解决长文本处理中的计算成本与噪声问题。",
            "summary_zh": "管理长上下文是大语言模型（LLMs）的关键瓶颈，尤其在长文档问答和自主代理等应用中，长输入导致高计算成本和噪声引入。现有压缩技术常通过离散令牌移除破坏局部连贯性，或依赖隐式潜在编码，存在位置偏差且与闭源API不兼容。为应对这些限制，我们引入了基于基本话语单元（EDU）的上下文压缩器，这是一种新颖的显式压缩框架，旨在保留全局结构和细粒度细节。我们的方法将上下文压缩重新表述为“先结构后选择”的过程：首先，LingoEDU将线性文本转换为基于源索引锚定的基本话语单元结构关系树，以消除幻觉；其次，轻量级排名模块选择查询相关的子树进行线性化。为严格评估结构理解，我们发布了StructBench，一个包含248个多样化文档的手动标注数据集。实证结果表明，我们的方法在结构预测准确性上达到最先进水平，显著优于前沿LLMs，同时降低成本。此外，我们的结构感知压缩在从长上下文任务到复杂深度搜索场景的下游任务中大幅提升了性能。",
            "intro_zh": [
                "现有压缩方法常破坏文本局部连贯性或依赖隐式编码，导致位置偏差和API不兼容问题。",
                "提出基于基本话语单元的显式压缩框架，通过结构关系树分解和查询相关子树选择实现忠实压缩。",
                "在StructBench数据集上实现最先进结构预测准确性，显著降低计算成本并提升下游任务性能。"
            ],
            "method_zh": "论文提出EDU-based Context Compressor框架，整体流程为结构-then-选择。首先，LingoEDU模块将线性文本分解为基本话语单元（EDU），构建严格锚定源索引的结构关系树，确保压缩忠实性。其次，轻量级排名模块基于查询相关性选择子树进行线性化输出。关键创新在于显式结构化压缩，避免了隐式编码的偏差，并保持全局与局部细节。与现有方法的主要区别在于强调结构保留和显式索引，而非依赖离散令牌移除或潜在表示。",
            "application_zh": "该研究适用于长文档问答、自主代理、深度搜索等场景，能有效降低LLMs的计算开销和噪声干扰，提升处理效率和准确性，具有实际部署价值。",
            "highlight_zh": "在StructBench数据集上，方法实现最先进的结构预测准确性，显著优于前沿LLMs，同时压缩成本降低，并在长上下文任务和复杂搜索中带来性能提升。",
            "tags_zh": [
                "上下文压缩",
                "基本话语单元",
                "结构关系树",
                "长文本处理",
                "大语言模型",
                "计算效率",
                "下游任务增强",
                "显式压缩框架"
            ],
            "_index": 130
        },
        {
            "title": "Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos",
            "authors": [
                "Le Jiang",
                "Shaotong Zhu",
                "Yedi Luo",
                "Shayda Moezzi",
                "Sarah Ostadabbas"
            ],
            "arxiv_id": "2512.14406v1",
            "summary": "In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14406v1",
            "code_links": [],
            "headline_zh": "提出RGM方法以解决图生成模型评估中MMD指标的局限性问题",
            "summary_zh": "图生成是网络科学和生物信息学等领域的核心任务，图生成模型通过学习真实世界图的分布来生成相似的新样本，如基于变分自编码器、循环神经网络和扩散模型的方法。然而，现有评估过程主要依赖最大均值差异作为度量生成图集合属性分布的指标，存在明显局限。本文提出了一种名为RGM的新方法，用于评估图生成模型，克服了MMD的不足。作为方法实践，我们全面评估了两种先进图生成模型：图循环注意力网络和高效度引导图生成模型，通过几何深度学习模型在合成与真实图数据集上训练进行性能比较。研究发现，虽然两种模型能生成具有特定拓扑属性的图，但在保持区分不同图域的结构特征方面存在显著局限，同时揭示了MMD作为评估指标的不充分性，为未来研究提供了替代方案。",
            "intro_zh": [
                "现有图生成模型评估主要依赖最大均值差异，但该指标在捕捉图结构特性方面存在不足，导致评估不全面。",
                "论文提出RGM方法，利用几何深度学习模型在定制数据集上训练，以更准确地评估生成图的分布和结构特性。",
                "实验表明，GRAN和EDGE模型在生成真实图时存在结构特征保留的局限，同时验证了MMD作为评估指标的不充分性。"
            ],
            "method_zh": "论文的核心方法是RGM，整体框架基于几何深度学习模型，该模型在包含合成和真实图的定制数据集上训练，专门用于图分类任务。关键技术创新点在于将图生成模型的评估问题转化为图表示学习问题，通过训练模型来区分不同图域的结构特征，从而更全面地评估生成图的分布。与现有方法的主要区别在于，RGM不依赖单一统计指标如MMD，而是利用深度学习模型捕捉图的复杂结构模式，提供更细粒度的评估视角。",
            "application_zh": "该研究可应用于网络科学、生物信息学等领域，通过改进图生成模型的评估，有助于开发更高质量的合成图，用于网络模拟、药物发现和社交网络分析等实际任务，提升模型在实际场景中的可靠性和泛化能力。",
            "highlight_zh": "实验结果显示，GRAN和EDGE模型在生成图时能复现某些拓扑属性，但在保持区分不同图域的结构特征方面表现不佳，同时证实了MMD作为评估指标的局限性，为未来研究提供了基于几何深度学习的替代评估框架。",
            "tags_zh": [
                "图生成模型",
                "几何深度学习",
                "模型评估",
                "最大均值差异",
                "图结构特性",
                "图分类",
                "网络科学",
                "生物信息学"
            ],
            "_index": 131
        },
        {
            "title": "RePo: Language Models with Context Re-Positioning",
            "authors": [
                "Huayang Li",
                "Tianyu Zhao",
                "Richard Sproat"
            ],
            "arxiv_id": "2512.14391v1",
            "summary": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14240v1",
            "code_links": [],
            "headline_zh": "提出物理一致的反应-扩散系统数据驱动建模方法，确保质量守恒和准正性约束",
            "summary_zh": "本文解决了从数据中学习反应-扩散系统同时确保学习模型的物理一致性和适定性的问题。基于结构化模型学习的正则化框架，我们专注于学习参数化反应项，并研究如何将关键物理属性（如质量守恒和准正性）直接纳入学习过程。我们的主要贡献有两个方面：首先，我们提出了系统修改给定参数化反应项类别的技术，使所得项固有地满足质量守恒和准正性，确保学习的反应-扩散系统保持非负性并遵循物理原理。这些修改还保证了所得偏微分方程在额外正则性和增长条件下的适定性。其次，我们使用这些物理一致的反应项，将基于正则化的模型学习的现有理论结果扩展到反应-扩散系统。具体来说，我们证明了即使强制执行守恒定律和准正性，学习问题的解也会收敛到极限系统的唯一正则化最小化解。此外，我们提供了准正性函数的逼近结果，这对于构建物理一致的参数化至关重要。这些结果推动了与基本物理定律一致的可解释且可靠的数据驱动反应-扩散系统模型的发展。",
            "intro_zh": [
                "现有数据驱动建模方法常忽略物理约束，导致反应-扩散系统模型可能违反质量守恒和准正性等基本物理原理。",
                "提出系统修改参数化反应项的技术，将质量守恒和准正性直接嵌入学习过程，确保模型物理一致性。",
                "理论证明学习解收敛到唯一正则化最小化解，并提供准正性函数逼近结果，提升模型可靠性和适定性。"
            ],
            "method_zh": "论文基于正则化框架进行结构化模型学习，核心方法包括两个关键技术：一是系统修改参数化反应项类别，通过数学构造使反应项固有满足质量守恒和准正性，从而确保学习到的反应-扩散系统保持非负性并遵循物理原理；二是扩展理论分析，将现有正则化模型学习理论应用于这些物理一致的反应项，证明学习问题的解收敛性。与现有方法的主要区别在于直接整合物理约束到学习过程中，而非后处理或忽略约束，这增强了模型的物理可解释性和适定性。",
            "application_zh": "该研究可应用于生物化学过程模拟、生态学种群动力学、材料科学中的扩散现象等领域，为开发可靠的数据驱动模型提供基础，有助于预测和优化复杂物理系统行为。",
            "highlight_zh": "理论证明学习解在强制执行质量守恒和准正性约束下仍收敛到唯一正则化最小化解，提供了准正性函数的逼近结果，确保模型物理一致性和适定性，提升了数据驱动反应-扩散系统模型的可靠性和可解释性。",
            "tags_zh": [
                "反应-扩散系统",
                "物理一致性建模",
                "数据驱动模型",
                "质量守恒",
                "准正性",
                "正则化学习",
                "偏微分方程学习",
                "模型适定性"
            ],
            "_index": 132
        },
        {
            "title": "Optimizing Rank for High-Fidelity Implicit Neural Representations",
            "authors": [
                "Julian McGinnis",
                "Florian A. Hölzl",
                "Suprosanna Shit",
                "Florentin Bieder",
                "Paul Friedrich",
                "Mark Mühlau",
                "Björn Menze",
                "Daniel Rueckert",
                "Benedikt Wiestler"
            ],
            "arxiv_id": "2512.14366v1",
            "summary": "Implicit Neural Representations (INRs) based on vanilla Multi-Layer Perceptrons (MLPs) are widely believed to be incapable of representing high-frequency content. This has directed research efforts towards architectural interventions, such as coordinate embeddings or specialized activation functions, to represent high-frequency signals. In this paper, we challenge the notion that the low-frequency bias of vanilla MLPs is an intrinsic, architectural limitation to learn high-frequency content, but instead a symptom of stable rank degradation during training. We empirically demonstrate that regulating the network's rank during training substantially improves the fidelity of the learned signal, rendering even simple MLP architectures expressive. Extensive experiments show that using optimizers like Muon, with high-rank, near-orthogonal updates, consistently enhances INR architectures even beyond simple ReLU MLPs. These substantial improvements hold across a diverse range of domains, including natural and medical images, and novel view synthesis, with up to 9 dB PSNR improvements over the previous state-of-the-art. Our project page, which includes code and experimental results, is available at: (https://muon-inrs.github.io).",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14366v1",
            "code_links": [],
            "headline_zh": "提出Ladder Side Tuning方法以解决大语言模型微调中的内存瓶颈问题",
            "summary_zh": "微调大语言模型（LLMs）常受限于商用GPU的内存容量。参数高效微调（PEFT）方法如QLoRA虽减少了可训练参数数量，但完整模型的反向传播仍导致高内存占用。本文重新审视了Ladder Side Tuning（LST），这是一种较少被探索的PEFT技术，通过添加轻量级侧网络，在保持与QLoRA相似计算扩展斜率的同时，将峰值内存降低50%。在涵盖自然语言理解、数学和LLM批评任务的不同下游基准测试中，LST平均性能与QLoRA相当，同时内存效率更高。这种效率使得在单个12GB消费级GPU上微调70亿参数模型成为可能，支持2k令牌上下文且无需梯度检查点——在这些条件下QLoRA会耗尽内存。除了内存效率，我们还建立了扩展定律，表明LST的扩展方式与QLoRA相似。通过利用Ladder的架构灵活性，我们引入了xLadder，这是一种深度扩展变体，通过交叉连接增加有效深度，并在固定参数数量下缩短思维链（CoT）。Ladder在内存受限时表现强劲；xLadder在此基础上实现了更深层推理而无额外内存开销。",
            "intro_zh": [
                "现有PEFT方法如QLoRA虽减少可训练参数，但反向传播仍导致高内存占用，限制大模型微调。",
                "提出Ladder Side Tuning（LST），添加轻量级侧网络，通过侧向连接优化，显著降低内存需求。",
                "实验显示LST在多个基准任务中性能与QLoRA相当，峰值内存降低50%，支持7B模型在12GB GPU上微调。"
            ],
            "method_zh": "论文核心方法是Ladder Side Tuning（LST），一种参数高效微调技术。整体框架基于预训练大语言模型，添加一个轻量级侧网络（side network），通过侧向连接（ladder connections）将主模型的中间层输出与侧网络集成，仅训练侧网络参数，从而减少内存占用。关键技术创新点包括：利用侧网络实现高效反向传播，避免完整模型梯度计算；引入xLadder变体，通过交叉连接（cross-connections）增加网络深度，提升推理能力。与现有方法如QLoRA的主要区别在于：LST侧重于架构优化，通过侧网络降低内存，而QLoRA基于量化技术；LST在内存效率上更优，支持更大上下文长度。",
            "application_zh": "该研究适用于大语言模型在资源受限环境下的微调，如消费级GPU部署、边缘计算或内存敏感场景。潜在应用包括自然语言处理任务（如文本分类、问答）、数学推理和AI批评系统，提升模型定制化能力的同时降低硬件成本。",
            "highlight_zh": "最重要的实验结果是LST在多个下游基准测试中平均性能与QLoRA相当，同时峰值内存降低50%。具体地，LST支持在单个12GB GPU上微调7B参数模型，处理2k令牌上下文且无需梯度检查点，而QLoRA在相同条件下内存耗尽。扩展定律分析显示LST与QLoRA具有相似的计算扩展斜率。",
            "tags_zh": [
                "参数高效微调",
                "大语言模型",
                "内存优化",
                "侧网络",
                "轻量级架构",
                "扩展定律",
                "下游任务",
                "消费级GPU"
            ],
            "_index": 133
        },
        {
            "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
            "authors": [
                "Qizhi Wang"
            ],
            "arxiv_id": "2512.14358v1",
            "summary": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
            "categories": [
                "cs.AI",
                "cs.DB"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages(/wo references), 4 figures, 10 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14358v1",
            "code_links": [],
            "headline_zh": "提出Elastic3D方法，基于引导潜在解码实现可控的单目到立体视频转换，解决传统方法中的伪影问题。",
            "summary_zh": "随着沉浸式3D内容需求的增长，自动化单目到立体视频转换变得日益重要。本文提出Elastic3D，一种可控的端到端方法，用于将传统视频升级为双目视频。该方法基于条件潜在扩散模型，避免了因显式深度估计和变形而产生的伪影。其高质量立体视频输出的关键在于一种新颖的引导VAE解码器，确保输出视频清晰且满足极线一致性。此外，该方法通过直观的标量调节旋钮，在推理时允许用户控制立体效果的强度（更精确地说，是视差范围）。在三个真实世界立体视频数据集上的实验表明，我们的方法优于传统的基于变形的方法和最近的无变形基线，为可靠、可控的立体视频转换设定了新标准。请访问项目页面查看视频样本：https://elastic3d.github.io。",
            "intro_zh": [
                "核心问题：传统单目到立体视频转换方法依赖显式深度估计和变形，易产生伪影，且缺乏用户对立体效果的可控性。",
                "方法要点：基于条件潜在扩散模型，引入引导VAE解码器确保视频清晰度和极线一致性，并通过标量参数实现视差范围的可控调节。",
                "实验或效果：在三个真实立体视频数据集上验证，性能优于传统变形方法和近期无变形基线，设定了新的转换标准。"
            ],
            "method_zh": "Elastic3D采用端到端的条件潜在扩散框架，整体架构基于扩散模型生成立体视频对。关键技术创新是引导VAE解码器，它在解码过程中引入几何约束，确保输出视频的清晰度和极线一致性，避免了传统方法中因深度估计不准确导致的伪影。与现有方法的主要区别在于：它不依赖显式的深度估计和变形步骤，而是通过潜在空间中的引导解码直接生成高质量立体视频，同时提供用户可控的视差调节功能，增强了方法的灵活性和实用性。",
            "application_zh": "该研究可应用于虚拟现实、增强现实、3D电影制作和游戏开发等领域，自动化将现有2D视频转换为沉浸式3D内容，降低制作成本，提升用户体验，推动沉浸式媒体技术的发展。",
            "highlight_zh": "在三个真实世界立体视频数据集上的实验表明，Elastic3D在视觉质量和一致性方面显著优于传统变形方法和近期无变形基线，通过定量和定性评估验证了其高效性和可控性，为立体视频转换任务设定了新的性能基准。",
            "tags_zh": [
                "立体视频转换",
                "潜在扩散模型",
                "引导解码",
                "极线一致性",
                "可控视差",
                "端到端学习",
                "单目到立体",
                "视频增强"
            ],
            "_index": 134
        },
        {
            "title": "HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis",
            "authors": [
                "Kaizhe Zhang",
                "Yijie Zhou",
                "Weizhan Zhang",
                "Caixia Yan",
                "Haipeng Du",
                "yugui xie",
                "Yu-Hui Wen",
                "Yong-Jin Liu"
            ],
            "arxiv_id": "2512.14352v1",
            "summary": "Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.",
            "categories": [
                "cs.CV",
                "cs.CG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14352v1",
            "code_links": [],
            "headline_zh": "提出4D-RaDiff框架，通过潜在扩散生成4D雷达点云，以解决雷达数据标注不足的问题。",
            "summary_zh": "汽车雷达因其成本效益和在恶劣天气条件下的鲁棒性，在环境感知方面展现出有前景的发展。然而，标注雷达数据的有限可用性对推进基于雷达的感知系统构成了重大挑战。为解决这一限制，我们提出了一种新颖的框架来生成4D雷达点云，用于训练和评估物体检测器。与基于图像的扩散不同，我们的方法旨在通过将扩散应用于潜在点云表示来考虑雷达点云的稀疏性和独特特性。在此潜在空间中，生成通过对象或场景级别的条件进行控制。所提出的4D-RaDiff将未标注的边界框转换为高质量的雷达标注，并将现有的激光雷达点云数据转换为逼真的雷达场景。实验表明，在训练期间将4D-RaDiff的合成雷达数据作为数据增强方法，与仅使用真实数据训练相比，持续提高了物体检测性能。此外，在我们的合成数据上进行预训练，可将所需标注雷达数据量减少高达90%，同时实现可比的物体检测性能。",
            "intro_zh": [
                "核心问题：标注雷达数据稀缺，限制了基于雷达的感知系统发展，尤其在恶劣天气下。",
                "方法要点：提出4D-RaDiff框架，在潜在空间应用扩散模型生成雷达点云，考虑其稀疏性和特性。",
                "实验或效果：合成数据作为增强提升检测性能，预训练减少90%标注需求，保持可比性能。"
            ],
            "method_zh": "4D-RaDiff是一个基于潜在扩散的框架，用于生成4D雷达点云。整体框架包括将雷达点云编码到潜在空间，在该空间应用扩散过程，并通过对象或场景级别的条件控制生成。关键技术创新点在于针对雷达点云的稀疏性和独特特性（如噪声和低分辨率），设计潜在表示和扩散机制，而非直接处理原始点云。与现有方法（如图像扩散或直接点云生成）的主要区别在于：它专门适配雷达数据，能有效处理其不规则性和不确定性，并通过条件生成实现灵活的数据增强和标注转换。",
            "application_zh": "该研究主要应用于自动驾驶领域，特别是雷达感知系统的训练和评估。潜在应用包括：生成合成雷达数据以补充真实数据不足，提升物体检测器在恶劣天气下的鲁棒性；将现有激光雷达数据转换为雷达场景，降低数据采集成本；作为数据增强工具，加速雷达感知算法的开发和优化。",
            "highlight_zh": "实验显示，使用4D-RaDiff合成数据作为增强，物体检测性能相比仅用真实数据训练有持续提升；预训练可减少高达90%的标注雷达数据需求，同时保持可比检测性能，验证了框架的有效性和实用性。",
            "tags_zh": [
                "4D雷达点云生成",
                "潜在扩散模型",
                "自动驾驶感知",
                "数据增强",
                "物体检测",
                "雷达数据合成",
                "条件生成",
                "稀疏点云处理"
            ],
            "_index": 135
        },
        {
            "title": "Implicit Bias and Invariance: How Hopfield Networks Efficiently Learn Graph Orbits",
            "authors": [
                "Michael Murray",
                "Tenzin Chan",
                "Kedar Karhadker",
                "Christopher J. Hillar"
            ],
            "arxiv_id": "2512.14338v1",
            "summary": "Many learning problems involve symmetries, and while invariance can be built into neural architectures, it can also emerge implicitly when training on group-structured data. We study this phenomenon in classical Hopfield networks and show they can infer the full isomorphism class of a graph from a small random sample. Our results reveal that: (i) graph isomorphism classes can be represented within a three-dimensional invariant subspace, (ii) using gradient descent to minimize energy flow (MEF) has an implicit bias toward norm-efficient solutions, which underpins a polynomial sample complexity bound for learning isomorphism classes, and (iii) across multiple learning rules, parameters converge toward the invariant subspace as sample sizes grow. Together, these findings highlight a unifying mechanism for generalization in Hopfield networks: a bias toward norm efficiency in learning drives the emergence of approximate invariance under group-structured data.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14338v1",
            "code_links": [],
            "headline_zh": "提出ViBES对话代理，通过联合规划语言与运动解决多模态社交交互中的时序与协调问题。",
            "summary_zh": "人类交流本质上是多模态和社交性的：语言、韵律和肢体语言共同传递意图。然而，大多数现有系统将人类行为建模为翻译任务（如伴随语音的手势或文本到动作），将固定话语映射到动作片段，而不需要代理决策何时移动、做什么或如何在多轮对话中适应。这导致脆弱的时序、弱社交基础以及语音、文本和动作被孤立训练或推断的碎片化堆栈。我们介绍了ViBES（语音行为表达与同步），这是一个联合规划语言和运动并执行对话条件身体动作的对话式3D代理。具体而言，ViBES是一个具有混合模态专家（MoME）骨干的语音-语言-行为（SLB）模型：模态分区的Transformer专家用于语音、面部表情和身体运动。该模型通过模态硬路由（参数按专家分割）处理交错的多模态令牌流，同时通过跨专家注意力共享信息。通过利用强大的预训练语音-语言模型，该代理支持混合主动交互：用户可以在对话中说话、打字或发出身体动作指令，系统暴露可控行为钩子以流式响应。我们进一步在多轮对话上使用对话-动作对齐和行为质量的自动指标进行基准测试，观察到相对于强大的伴随语音和文本到动作基线的一致增益。ViBES超越了“语音条件运动生成”，走向代理虚拟身体，其中语言、韵律和运动被联合生成，实现可控、社交能力强的3D交互。代码和数据将在ai.stanford.edu/~juze/ViBES/提供。",
            "intro_zh": [
                "现有方法将人类行为建模为翻译任务，导致时序脆弱、社交基础弱和模态孤立，难以适应多轮对话。",
                "提出ViBES，基于混合模态专家骨干联合规划语言与运动，通过跨专家注意力实现多模态协调。",
                "在多轮对话基准测试中，ViBES在对话-动作对齐和行为质量上优于基线，支持混合主动交互和可控响应。"
            ],
            "method_zh": "ViBES是一个语音-语言-行为（SLB）模型，核心架构为混合模态专家（MoME）骨干。整体框架包括模态分区的Transformer专家，分别处理语音、面部表情和身体运动令牌流，通过硬路由按模态分割参数，同时利用跨专家注意力共享信息。关键技术创新在于联合规划语言和运动，而非孤立生成，并整合预训练语音-语言模型以增强多模态协调。与现有方法的主要区别在于从翻译任务转向代理决策，实现对话条件身体动作的实时执行，解决了时序和社交协调问题。",
            "application_zh": "该研究可应用于虚拟现实、社交机器人、在线教育和游戏等领域，实现更自然、可控的3D人机交互，提升用户体验和社交能力。",
            "highlight_zh": "在多轮对话基准测试中，ViBES在对话-动作对齐和行为质量自动指标上一致优于伴随语音和文本到动作基线，展示了联合生成的优势。",
            "tags_zh": [
                "多模态对话代理",
                "3D虚拟身体",
                "混合模态专家",
                "语音-语言-行为模型",
                "跨模态协调",
                "社交交互",
                "可控行为生成",
                "多轮对话"
            ],
            "_index": 136
        },
        {
            "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
            "authors": [
                "Shuai Dong",
                "Jie Zhang",
                "Guoying Zhao",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14320v1",
            "summary": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14320v1",
            "code_links": [],
            "headline_zh": "提出PentestEval基准测试，通过模块化阶段设计评估LLM在渗透测试中的性能，以解决自动化不可靠问题。",
            "summary_zh": "渗透测试对于评估和增强系统安全至关重要，但传统工作流程高度依赖人工、专业知识密集且难以扩展。尽管大语言模型（LLMs）为自动化提供了前景，但现有应用依赖简单提示，缺乏任务分解或领域适应，导致不可靠的黑盒行为和有限的对渗透测试各阶段模型能力的洞察。为填补这一空白，我们引入了PentestEval，这是首个全面基准测试，用于评估LLM在六个分解的渗透测试阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订。PentestEval集成了专家标注的真实数据和一个完全自动化的评估管道，覆盖12个真实漏洞场景中的所有阶段，共346个任务。我们对9个广泛使用的LLM进行阶段级评估，结果显示整体性能较弱，且在渗透测试工作流程各阶段存在明显局限性。端到端管道成功率仅为31%，现有LLM驱动系统如PentestGPT、PentestAgent和VulnBot也表现出类似局限性，自主代理几乎完全失败。这些发现强调，自主渗透测试需要更强的结构化推理，其中模块化能增强每个单独阶段并提升整体性能。PentestEval为未来细粒度、阶段级评估研究提供了基础基准，为更可靠的基于LLM的自动化铺平道路。",
            "intro_zh": [
                "核心问题：现有LLM在渗透测试中依赖简单提示，缺乏任务分解和领域适应，导致自动化不可靠且难以评估各阶段能力。",
                "方法要点：提出PentestEval基准测试，通过模块化设计分解渗透测试为六个阶段，集成专家标注数据和自动化评估管道。",
                "实验或效果：评估9个LLM显示整体性能弱，端到端成功率仅31%，自主代理几乎失败，模块化能提升阶段和整体性能。"
            ],
            "method_zh": "PentestEval的整体框架是一个模块化基准测试系统，将渗透测试工作流程分解为六个阶段：信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订。关键技术创新点包括：首次引入阶段级评估设计，覆盖12个真实漏洞场景的346个任务；集成专家标注的真实数据，确保评估准确性；开发完全自动化的评估管道，支持高效测试。与现有方法的主要区别在于：现有方法通常依赖黑盒提示，缺乏任务分解和领域适应，而PentestEval通过模块化设计提供细粒度评估，增强了对LLM能力的洞察，并支持结构化推理改进。",
            "application_zh": "该研究主要应用于网络安全领域，特别是渗透测试自动化。潜在价值包括：为LLM在安全任务中的性能评估提供标准化基准，促进更可靠的自动化工具开发；帮助研究人员和从业者识别模型在渗透测试各阶段的局限性，指导模型优化和领域适应；推动基于LLM的自主安全系统向结构化、模块化方向发展，提升实际部署的可靠性和效率。",
            "highlight_zh": "最重要的实验结果：对9个广泛使用的LLM进行阶段级评估，整体性能较弱，端到端管道成功率仅为31%；现有LLM驱动系统如PentestGPT、PentestAgent和VulnBot表现出类似局限性，自主代理几乎完全失败。性能提升：模块化设计能增强每个渗透测试阶段，从而改善整体性能，为未来研究提供了基础基准。",
            "tags_zh": [
                "渗透测试基准",
                "大语言模型评估",
                "模块化设计",
                "阶段级评估",
                "网络安全自动化",
                "专家标注数据",
                "自动化评估管道",
                "结构化推理"
            ],
            "_index": 137
        },
        {
            "title": "From YOLO to VLMs: Advancing Zero-Shot and Few-Shot Detection of Wastewater Treatment Plants Using Satellite Imagery in MENA Region",
            "authors": [
                "Akila Premarathna",
                "Kanishka Hewageegana",
                "Garcia Andarcia Mariangel"
            ],
            "arxiv_id": "2512.14312v1",
            "summary": "In regions of the Middle East and North Africa (MENA), there is a high demand for wastewater treatment plants (WWTPs), crucial for sustainable water management. Precise identification of WWTPs from satellite images enables environmental monitoring. Traditional methods like YOLOv8 segmentation require extensive manual labeling. But studies indicate that vision-language models (VLMs) are an efficient alternative to achieving equivalent or superior results through inherent reasoning and annotation. This study presents a structured methodology for VLM comparison, divided into zero-shot and few-shot streams specifically to identify WWTPs. The YOLOv8 was trained on a governmental dataset of 83,566 high-resolution satellite images from Egypt, Saudi Arabia, and UAE: ~85% WWTPs (positives), 15% non-WWTPs (negatives). Evaluated VLMs include LLaMA 3.2 Vision, Qwen 2.5 VL, DeepSeek-VL2, Gemma 3, Gemini, and Pixtral 12B (Mistral), used to identify WWTP components such as circular/rectangular tanks, aeration basins and distinguish confounders via expert prompts producing JSON outputs with confidence and descriptions. The dataset comprises 1,207 validated WWTP locations (198 UAE, 354 KSA, 655 Egypt) and equal non-WWTP sites from field/AI data, as 600mx600m Geo-TIFF images (Zoom 18, EPSG:4326). Zero-shot evaluations on WWTP images showed several VLMs out-performing YOLOv8's true positive rate, with Gemma-3 highest. Results confirm that VLMs, particularly with zero-shot, can replace YOLOv8 for efficient, annotation-free WWTP classification, enabling scalable remote sensing.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14312v1",
            "code_links": [],
            "headline_zh": "提出多视图MRI方法，利用空间关系检测胶质母细胞瘤MGMT甲基化状态，避免复杂3D模型问题。",
            "summary_zh": "MGMT启动子甲基化的存在显著影响胶质母细胞瘤（GBM）患者化疗效果。目前，MGMT启动子甲基化的确认依赖于侵入性脑肿瘤组织活检。本研究探索了放射基因组学技术，这是一种在精准医学中具有前景的方法，旨在从医学图像中识别遗传标记。利用MRI扫描和深度学习模型，我们提出了一种新的多视图方法，考虑MRI视图之间的空间关系来检测MGMT甲基化状态。重要的是，我们的方法从所有三个视图中提取信息，而不使用复杂的3D深度学习模型，避免了高参数数量、收敛缓慢和大量内存需求等问题。我们还引入了一种新的肿瘤切片提取技术，并基于多个评估指标展示了其优于现有方法的优势。通过将我们的方法与最先进的模型进行比较，我们证明了该方法的有效性。此外，我们分享了已发表模型的可重复流程，鼓励透明度和稳健诊断工具的开发。我们的研究突出了非侵入性方法识别MGMT启动子甲基化的潜力，并有助于推进GBM治疗中的精准医学。",
            "intro_zh": [
                "核心问题：现有MGMT甲基化检测依赖侵入性活检，缺乏高效非侵入性方法，且复杂3D模型存在参数多、收敛慢、内存需求大等问题。",
                "方法要点：提出多视图MRI方法，利用空间关系整合三个视图信息，避免复杂3D模型，并引入新肿瘤切片提取技术提升性能。",
                "实验或效果：通过对比实验，新方法在多个评估指标上优于现有方法，验证了其有效性和非侵入性检测潜力。"
            ],
            "method_zh": "整体框架基于多视图MRI和深度学习模型，核心思想是通过整合轴向、冠状和矢状三个MRI视图的空间关系来检测MGMT甲基化状态。关键技术创新点包括：采用多视图方法而非复杂3D模型，避免了高参数和内存问题；引入新的肿瘤切片提取技术，优化了图像预处理步骤。与现有方法的主要区别在于，该方法不依赖3D卷积神经网络，而是通过多视图融合捕捉空间信息，从而在保持性能的同时降低了计算复杂度，提高了实用性和可扩展性。",
            "application_zh": "该研究主要应用于胶质母细胞瘤的精准医疗领域，潜在价值包括：为非侵入性MGMT甲基化检测提供新工具，辅助化疗方案制定；推动放射基因组学在临床诊断中的应用，减少患者侵入性活检风险；促进透明和可重复的AI诊断流程开发，提升医疗AI的可靠性和普及性。",
            "highlight_zh": "最重要的实验结果：新方法在多个评估指标上优于现有最先进模型，验证了多视图方法的有效性；新肿瘤切片提取技术显著提升了性能，展示了技术优势；整体方法避免了3D模型的复杂性问题，实现了高效且稳健的MGMT甲基化状态检测。",
            "tags_zh": [
                "胶质母细胞瘤",
                "MGMT甲基化检测",
                "多视图MRI",
                "放射基因组学",
                "深度学习模型",
                "非侵入性诊断",
                "精准医学",
                "肿瘤切片提取"
            ],
            "_index": 138
        },
        {
            "title": "Continual Learning at the Edge: An Agnostic IIoT Architecture",
            "authors": [
                "Pablo García-Santaclara",
                "Bruno Fernández-Castro",
                "Rebeca P. Díaz-Redondo",
                "Carlos Calvo-Moa",
                "Henar Mariño-Bodelón"
            ],
            "arxiv_id": "2512.14311v1",
            "summary": "The exponential growth of Internet-connected devices has presented challenges to traditional centralized computing systems due to latency and bandwidth limitations. Edge computing has evolved to address these difficulties by bringing computations closer to the data source. Additionally, traditional machine learning algorithms are not suitable for edge-computing systems, where data usually arrives in a dynamic and continual way. However, incremental learning offers a good solution for these settings. We introduce a new approach that applies the incremental learning philosophy within an edge-computing scenario for the industrial sector with a specific purpose: real time quality control in a manufacturing system. Applying continual learning we reduce the impact of catastrophic forgetting and provide an efficient and effective solution.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1007/978-981-96-6938-7_33",
            "journal_ref": "García-Santaclara, P., Fernández-Castro, B., Díaz-Redondo, R. P., Calvo-Moa, C., & Mariño-Bodelón, H. (2025). Continual learning at the edge: An agnostic IIoT architecture. In Lecture Notes in Networks and Systems. Springer",
            "pdf_url": "https://arxiv.org/pdf/2512.14311v1",
            "code_links": [],
            "headline_zh": "提出基于教师模型的数据过滤方法，以提升多模态对比学习在噪声数据下的性能。",
            "summary_zh": "现代多模态表示学习的成功依赖于互联网规模的数据集。由于大量原始网络数据质量较低，数据筛选已成为训练流程中的关键步骤。使用训练模型进行过滤（即基于教师的过滤）已成为一种成功的解决方案，它利用预训练模型计算质量分数。为了解释基于教师的过滤在经验上的成功，我们在标准双模态数据生成模型下刻画了过滤后对比学习的性能。设η∈(0,1]为n个配对样本中模态正确匹配的数据比例，我们利用线性对比学习设置来展示数据过滤的可证明益处：(i) 无过滤时的误差上界和下界为1/(η√n)，(ii) 在η较大时，基于教师过滤的误差上界为1/√(ηn)，在η较小时为1/√n。",
            "intro_zh": [
                "核心问题：互联网规模多模态数据集中存在大量噪声和不匹配样本，影响对比学习性能。",
                "方法要点：提出基于教师模型的过滤方法，利用预训练模型评估数据质量，筛选高质量样本。",
                "实验或效果：理论证明过滤能显著降低误差，在η较大时误差上界为1/√(ηn)，η较小时为1/√n。"
            ],
            "method_zh": "论文采用线性对比学习框架，核心方法为基于教师模型的数据过滤。整体框架包括：在标准双模态数据生成模型下，利用预训练教师模型计算每个样本的质量分数，根据分数筛选出高质量数据用于后续对比学习训练。关键技术创新点在于理论分析了过滤对误差的影响，证明了过滤能改善学习性能。与现有方法的主要区别在于，该方法不仅提供经验解决方案，还通过理论推导量化了过滤的益处，为数据筛选提供了理论依据。",
            "application_zh": "该研究可应用于多模态表示学习领域，如视觉-语言模型训练、跨模态检索和生成任务，通过有效过滤噪声数据提升模型鲁棒性和性能，具有实际价值。",
            "highlight_zh": "理论结果表明，无过滤时误差界为1/(η√n)，而基于教师过滤后，在η较大时误差上界降至1/√(ηn)，η较小时降至1/√n，显著提升了学习效率。",
            "tags_zh": [
                "多模态对比学习",
                "数据过滤",
                "教师模型",
                "噪声数据",
                "理论分析",
                "表示学习",
                "双模态数据"
            ],
            "_index": 139
        },
        {
            "title": "PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition",
            "authors": [
                "Abdullah Al Mamun",
                "Miaohua Zhang",
                "David Ahmedt-Aristizabal",
                "Zeeshan Hayder",
                "Mohammad Awrangjeb"
            ],
            "arxiv_id": "2512.14309v1",
            "summary": "Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14309v1",
            "code_links": [],
            "headline_zh": "提出基于大语言模型的复杂相对位置描述地理编码方法，以解决生物多样性记录中位置描述自动化处理难题。",
            "summary_zh": "地理编码文本文档通常依赖于基于地名录的方法为地名分配地理坐标，或通过语言建模方法将文本术语与地理位置关联。然而，许多位置描述通过空间关系相对指定位置，使得仅基于地名或地理指示词的地理编码不准确。这一问题在生物标本采集记录中尤为常见，这些记录中的位置通常以叙述形式描述而非坐标，尤其是在GPS出现之前的记录。准确的地理编码对生物多样性研究至关重要，但该过程仍然劳动密集，导致对自动化地理编码解决方案的需求。本文探讨了大语言模型自动地理编码复杂位置描述的潜力，重点关注生物多样性收集领域。我们首先确定了有效的提示模式，然后使用量化低秩适应在多区域和多语言的生物多样性数据集上对大语言模型进行微调。我们的方法在固定训练数据量下，平均在65%的记录中实现了10公里半径内的地理编码，优于现有基线。最佳结果（纽约州）为85%在10公里内和67%在1公里内。所选大语言模型在处理冗长、复杂的描述时表现良好，突显了其在处理复杂位置描述地理编码方面的潜力。",
            "intro_zh": [
                "现有方法主要依赖地名或地理指示词进行地理编码，难以处理包含空间关系的复杂相对位置描述，导致准确性不足。",
                "论文提出使用大语言模型，通过有效提示模式和QLoRA微调技术，自动解析和地理编码复杂位置描述，提升处理能力。",
                "实验结果显示，该方法在多个数据集上平均65%的记录在10公里半径内准确，纽约州最佳结果达85%在10公里内和67%在1公里内。"
            ],
            "method_zh": "论文提出一个基于大语言模型的自动化地理编码框架。整体框架包括：首先识别有效的提示模式以引导模型理解复杂位置描述；然后使用量化低秩适应技术在大规模生物多样性数据集上进行微调，这些数据集涵盖多区域和多语言，以增强模型的泛化能力。关键技术创新点在于结合大语言模型的自然语言理解能力与QLoRA高效微调，直接处理包含空间关系的文本描述，而无需依赖传统的地名录或简单关键词匹配。与现有方法的主要区别在于，它能够处理冗长、叙述性的位置描述，通过端到端学习实现更准确的地理坐标预测，突破了基于地名或地理指示词的局限性。",
            "application_zh": "该研究主要应用于生物多样性领域，特别是生物标本采集记录的地理编码，可自动化处理历史记录中的叙述性位置描述，支持生物多样性研究和保护工作。此外，也可扩展至其他需要从文本中提取地理信息的场景，如灾害报告、考古记录或社交媒体分析。",
            "highlight_zh": "实验表明，在固定训练数据量下，该方法平均在65%的记录中实现10公里半径内的地理编码，优于现有基线。最佳性能在纽约州数据集上达到85%在10公里内和67%在1公里内，突显了大语言模型在处理复杂描述时的优越性。",
            "tags_zh": [
                "地理编码",
                "大语言模型",
                "生物多样性记录",
                "相对位置描述",
                "QLoRA微调",
                "自然语言处理",
                "空间关系解析",
                "自动化地理信息提取"
            ],
            "_index": 140
        },
        {
            "title": "Improving the Accuracy of Amortized Model Comparison with Self-Consistency",
            "authors": [
                "Šimon Kucharský",
                "Aayush Mishra",
                "Daniel Habermann",
                "Stefan T. Radev",
                "Paul-Christian Bürkner"
            ],
            "arxiv_id": "2512.14308v1",
            "summary": "Amortized Bayesian inference (ABI) offers fast, scalable approximations to posterior densities by training neural surrogates on data simulated from the statistical model. However, ABI methods are highly sensitive to model misspecification: when observed data fall outside the training distribution (generative scope of the statistical models), neural surrogates can behave unpredictably. This makes it a challenge in a model comparison setting, where multiple statistical models are considered, of which at least some are misspecified. Recent work on self-consistency (SC) provides a promising remedy to this issue, accessible even for empirical data (without ground-truth labels). In this work, we investigate how SC can improve amortized model comparison conceptualized in four different ways. Across two synthetic and two real-world case studies, we find that approaches for model comparison that estimate marginal likelihoods through approximate parameter posteriors consistently outperform methods that directly approximate model evidence or posterior model probabilities. SC training improves robustness when the likelihood is available, even under severe model misspecification. The benefits of SC for methods without access of analytic likelihoods are more limited and inconsistent. Our results suggest practical guidance for reliable amortized Bayesian model comparison: prefer parameter posterior-based methods and augment them with SC training on empirical datasets to mitigate extrapolation bias under model misspecification.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.CO"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14308v1",
            "code_links": [],
            "headline_zh": "提出OmniGen统一框架以解决自动驾驶中多模态传感器数据生成的对齐与效率问题",
            "summary_zh": "自动驾驶的显著进步很大程度上依赖于大规模真实世界数据收集，但获取多样化和极端案例数据仍然成本高昂且效率低下。生成模型通过合成逼真的传感器数据成为一种有前景的解决方案。然而，现有方法主要关注单模态生成，导致多模态传感器数据效率低下和对齐不准确。为解决这些挑战，我们提出了OmniGen，在统一框架中生成对齐的多模态传感器数据。我们的方法利用共享的鸟瞰图空间统一多模态特征，并设计了一种新颖的可泛化多模态重建方法UAE，联合解码激光雷达和多视角相机数据。UAE通过体渲染实现多模态传感器解码，支持准确灵活的重建。此外，我们结合了带有ControlNet分支的扩散变换器，实现可控的多模态传感器生成。我们的全面实验表明，OmniGen在多模态一致性和灵活传感器调整方面，实现了统一多模态传感器数据生成的理想性能。",
            "intro_zh": [
                "现有方法主要关注单模态传感器数据生成，导致多模态数据效率低下和对齐不准确，限制了自动驾驶数据合成的实用性。",
                "提出OmniGen统一框架，利用共享BEV空间统一多模态特征，并设计UAE方法通过体渲染联合解码激光雷达和相机数据，实现对齐生成。",
                "实验表明，OmniGen在多模态一致性和传感器调整方面表现优异，显著提升了生成数据的质量和灵活性，支持可控生成任务。"
            ],
            "method_zh": "OmniGen的整体框架是一个统一的多模态传感器数据生成系统，核心包括共享BEV空间特征统一和UAE多模态重建模块。关键技术创新点在于：1) 利用BEV空间作为中间表示，将不同模态的传感器数据（如激光雷达点云和多视角相机图像）对齐到同一坐标系，解决模态间不一致问题；2) 设计UAE方法，通过体渲染技术联合解码激光雷达和相机数据，实现准确且灵活的多模态重建；3) 结合扩散变换器与ControlNet分支，支持可控生成，允许用户调整传感器参数或场景条件。与现有方法的主要区别在于，OmniGen首次在统一框架中实现多模态传感器数据的对齐生成，避免了传统单模态方法导致的效率低下和错位问题，提升了数据合成的整体一致性和实用性。",
            "application_zh": "该研究主要应用于自动驾驶领域，潜在价值包括：1) 合成多样化和极端案例的传感器数据，用于训练和测试自动驾驶系统，降低真实数据收集成本；2) 支持可控数据生成，便于模拟不同天气、光照或传感器配置下的驾驶场景，增强模型的鲁棒性；3) 作为数据增强工具，提升现有数据集的多样性和覆盖范围，加速自动驾驶算法的研发进程。",
            "highlight_zh": "实验结果显示，OmniGen在统一多模态传感器数据生成任务中，实现了多模态一致性和灵活传感器调整的优异性能。具体而言，在生成数据的对齐精度和重建质量方面，相比现有单模态方法有显著提升，支持可控生成并验证了其在模拟复杂驾驶场景中的有效性，为自动驾驶数据合成提供了高效解决方案。",
            "tags_zh": [
                "多模态传感器生成",
                "自动驾驶数据合成",
                "鸟瞰图空间统一",
                "体渲染解码",
                "扩散变换器",
                "可控生成",
                "激光雷达与相机对齐",
                "多模态一致性"
            ],
            "_index": 141
        },
        {
            "title": "The Trust in AI-Generated Health Advice (TAIGHA) Scale and Short Version (TAIGHA-S): Development and Validation Study",
            "authors": [
                "Marvin Kopka",
                "Azeem Majeed",
                "Gabriella Spinelli",
                "Austen El-Osta",
                "Markus Feufel"
            ],
            "arxiv_id": "2512.14278v1",
            "summary": "Artificial Intelligence tools such as large language models are increasingly used by the public to obtain health information and guidance. In health-related contexts, following or rejecting AI-generated advice can have direct clinical implications. Existing instruments like the Trust in Automated Systems Survey assess trustworthiness of generic technology, and no validated instrument measures users' trust in AI-generated health advice specifically. This study developed and validated the Trust in AI-Generated Health Advice (TAIGHA) scale and its four-item short form (TAIGHA-S) as theory-based instruments measuring trust and distrust, each with cognitive and affective components. The items were developed using a generative AI approach, followed by content validation with 10 domain experts, face validation with 30 lay participants, and psychometric validation with 385 UK participants who received AI-generated advice in a symptom-assessment scenario. After automated item reduction, 28 items were retained and reduced to 10 based on expert ratings. TAIGHA showed excellent content validity (S-CVI/Ave=0.99) and CFA confirmed a two-factor model with excellent fit (CFI=0.98, TLI=0.98, RMSEA=0.07, SRMR=0.03). Internal consistency was high (α=0.95). Convergent validity was supported by correlations with the Trust in Automated Systems Survey (r=0.67/-0.66) and users' reliance on the AI's advice (r=0.37 for trust), while divergent validity was supported by low correlations with reading flow and mental load (all |r|<0.25). TAIGHA-S correlated highly with the full scale (r=0.96) and showed good reliability (α=0.88). TAIGHA and TAIGHA-S are validated instruments for assessing user trust and distrust in AI-generated health advice. Reporting trust and distrust separately permits a more complete evaluation of AI interventions, and the short scale is well-suited for time-constrained settings.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14278v1",
            "code_links": [],
            "headline_zh": "提出历史增强两阶段Transformer框架，以解决无人机视觉语言导航中全局推理与局部理解不平衡的问题。",
            "summary_zh": "空中视觉语言导航（AVLN）要求无人机代理基于语言指令在大规模城市环境中定位目标。成功导航需要全局环境推理和局部场景理解，但现有无人机代理通常采用单粒度框架，难以平衡这两方面。为应对此限制，本研究提出历史增强两阶段Transformer（HETT）框架，通过粗到细的导航流程整合这两个方面。具体而言，HETT首先通过融合空间地标和历史上下文预测粗粒度目标位置，然后通过细粒度视觉分析精炼动作。此外，设计了一个历史网格地图，动态将视觉特征聚合为结构化空间记忆，增强综合场景感知。同时，手动优化了CityNav数据集标注以提升数据质量。在优化后的CityNav数据集上的实验显示，HETT带来显著性能提升，而广泛的消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "现有无人机代理采用单粒度框架，难以平衡全局环境推理与局部场景理解，导致导航性能受限。",
                "提出历史增强两阶段Transformer框架，通过粗到细流程融合空间地标和历史上下文，并设计历史网格地图增强场景感知。",
                "在优化后的CityNav数据集上，HETT实现显著性能提升，消融研究验证了各组件有效性，证明方法优越性。"
            ],
            "method_zh": "HETT框架采用两阶段Transformer架构，整体流程为粗到细导航。首先，在粗粒度阶段，通过融合空间地标和历史上下文预测目标位置；其次，在细粒度阶段，基于视觉分析精炼动作。关键技术创新包括历史网格地图，动态聚合视觉特征为结构化空间记忆，增强场景感知。与现有方法的主要区别在于其双粒度设计，有效整合全局推理和局部理解，避免了单粒度框架的局限性。",
            "application_zh": "该研究可应用于无人机自主导航、城市搜索救援、物流配送和智能监控等领域，通过提升视觉语言导航的准确性和效率，支持复杂环境下的目标定位和路径规划，具有实际工业价值。",
            "highlight_zh": "在优化后的CityNav数据集上，HETT相比现有方法带来显著性能提升，消融研究证实历史网格地图和两阶段设计是关键贡献，验证了框架的有效性和鲁棒性。",
            "tags_zh": [
                "视觉语言导航",
                "无人机导航",
                "Transformer架构",
                "多模态融合",
                "空间记忆",
                "粗到细导航",
                "城市环境",
                "数据集优化"
            ],
            "_index": 142
        },
        {
            "title": "TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning",
            "authors": [
                "Yu Chen",
                "Hongwei Lin"
            ],
            "arxiv_id": "2512.14274v1",
            "summary": "Persistence diagrams (PDs) provide a powerful tool for understanding the topology of the underlying shape of a point cloud. However, identifying which points in PDs encode genuine signals remains challenging. This challenge directly hinders the practical adoption of topological data analysis in many applications, where automated and reliable interpretation of persistence diagrams is essential for downstream decision-making. In this paper, we study automatic significance detection for one-dimensional persistence diagrams. Specifically, we propose Topology Understanding Net (TUN), a multi-modal network that combines enhanced PD descriptors with self-attention, a PointNet-style point cloud encoder, learned fusion, and per-point classification, alongside stable preprocessing and imbalance-aware training. It provides an automated and effective solution for identifying significant points in PDs, which are critical for downstream applications. Experiments show that TUN outperforms classic methods in detecting significant points in PDs, illustrating its effectiveness in real-world applications.",
            "categories": [
                "cs.CV",
                "cs.LG",
                "math.AT"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14274v1",
            "code_links": [],
            "headline_zh": "提出加权共形预测方法，为一般缺失数据机制提供自适应且有效的掩码条件覆盖保证",
            "summary_zh": "共形预测（CP）为不确定性量化提供了原则性框架，但在面对缺失协变量时无法保证覆盖。针对不同缺失模式引起的异质性，掩码条件有效（MCV）覆盖已成为比边际覆盖更理想的属性。本研究通过提出一个预填补-掩码-校正框架来适应分割CP处理缺失值，能够提供有效覆盖。我们证明该方法为一般缺失数据机制提供了保证的边际覆盖和掩码条件有效性。方法的关键组成部分是一个重新加权的共形预测过程，在校准数据集的分布填补（多重填补）后校正预测集，使我们的方法与标准填补流程兼容。我们推导出两种算法，并证明它们近似边际有效和MCV。我们在合成和真实世界数据集上进行了评估。与标准MCV方法相比，该方法显著减少了预测区间的宽度，同时保持了目标保证。",
            "intro_zh": [
                "共形预测在处理缺失协变量时无法保证覆盖，现有方法难以应对缺失模式异质性。",
                "提出预填补-掩码-校正框架，通过加权共形预测校正填补后的预测集，兼容标准填补流程。",
                "在合成和真实数据集上验证，显著减少预测区间宽度，同时维持边际和掩码条件覆盖保证。"
            ],
            "method_zh": "论文提出预填补-掩码-校正框架处理缺失数据。整体流程包括：先对校准数据集进行分布填补（如多重填补），然后应用加权共形预测校正预测集。关键创新是引入重新加权的共形预测过程，通过权重调整来适应不同缺失模式，确保掩码条件有效性。与现有方法的主要区别在于：该方法不依赖特定缺失机制假设，能处理一般缺失数据，且与标准填补方法（如多重填补）无缝集成，提高了实用性和灵活性。",
            "application_zh": "该方法适用于医疗诊断、金融风险评估和工业质量控制等领域，其中数据常存在缺失值。通过提供可靠的预测区间，能增强模型在不确定性环境下的决策支持，提升实际应用中的鲁棒性和可信度。",
            "highlight_zh": "实验表明，与标准掩码条件有效方法相比，该方法在合成和真实数据集上显著减少了预测区间宽度（具体数值未知），同时保持了目标覆盖保证，验证了其有效性和效率提升。",
            "tags_zh": [
                "共形预测",
                "缺失数据处理",
                "不确定性量化",
                "掩码条件覆盖",
                "加权校正",
                "多重填补",
                "预测区间",
                "统计学习"
            ],
            "_index": 143
        },
        {
            "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
            "authors": [
                "Nick Leenders",
                "Thomas Quadt",
                "Boris Cule",
                "Roy Lindelauf",
                "Herman Monsuur",
                "Joost van Oijen",
                "Mark Voskuijl"
            ],
            "arxiv_id": "2512.14263v1",
            "summary": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
            "code_links": [],
            "headline_zh": "提出基于大语言模型比较的LLM compare方法，以无监督方式估计问题难度，解决分布外问题评估难题。",
            "summary_zh": "大语言模型（LLMs）微调的进展显著提升了其在基准测试上的性能，这凸显了对更困难合成数据的需求。数据生成流程中的关键步骤是估计问题难度的方法。当前方法（如人工校准或基于性能的评分）由于不可扩展、耗时且依赖真实标签，无法泛化到分布外问题（即当前人类和LLMs无法解决的问题）。因此，我们提出了一种新的问题难度估计方法LLM compare，以解决这些限制。该方法利用LLM进行成对难度比较，然后基于结果计算Bradley-Terry分数。为验证方法，我们首先提出了一个概念框架，将现有方法定位在三个正交平面——构建、规模和依赖性上，识别出评估分布外问题所需占据的象限。LLM compare自然占据了所有理想象限，成为首个连续动态、模型无关且独立于真实标签信息的度量。其次，我们展示了LLM compare与人工标注高度一致：在n=1876时，Pearson相关系数r≥0.80。第三，我们证明LLM compare对幻觉具有鲁棒性，在10%噪声注入下，Pearson相关系数下降小于6%。我们的工作代表了在替代耗时的人工标注和合成数据生成方面的重要一步，并将成为课程设计、模型评估和AI辅助研究构思的重要推动力。",
            "intro_zh": [
                "核心问题：现有难度估计方法（如人工校准）依赖真实标签且不可扩展，无法评估分布外问题，限制了合成数据生成。",
                "方法要点：利用大语言模型进行成对难度比较，结合Bradley-Terry模型计算连续分数，实现无监督、模型无关的难度估计。",
                "实验或效果：与人工标注高度相关（Pearson r≥0.80），对噪声鲁棒（性能下降<6%），验证了方法的有效性和稳定性。"
            ],
            "method_zh": "LLM compare方法的核心框架基于大语言模型（LLM）的成对比较能力。首先，LLM对问题对进行难度比较，生成相对难度的判断结果；然后，利用Bradley-Terry模型将这些比较结果转化为连续的难度分数。关键技术创新点在于首次实现了完全无监督的难度估计，不依赖真实标签或人类标注，通过LLM的推理能力泛化到未知问题。与现有方法的主要区别在于：现有方法通常基于性能评分（如模型准确率）或人工评估，受限于可解问题和标注成本；而LLM compare通过模型无关的比较机制，能够处理分布外问题，并具有连续动态和可扩展的优势。",
            "application_zh": "该方法可应用于课程设计中自适应学习路径的生成，通过动态调整问题难度优化教学序列；在模型评估中，为基准测试提供更细粒度的难度分析，辅助性能诊断；在AI辅助研究构思中，帮助生成挑战性合成数据，推动大语言模型的前沿发展。",
            "highlight_zh": "实验显示LLM compare与人工标注的Pearson相关系数高达0.80以上（n=1876），验证了其有效性；在10%噪声注入下，相关性下降小于6%，证明了方法对幻觉和噪声的强鲁棒性，为无监督难度估计提供了可靠基准。",
            "tags_zh": [
                "问题难度估计",
                "大语言模型",
                "无监督学习",
                "分布外泛化",
                "Bradley-Terry模型",
                "合成数据生成",
                "课程设计",
                "模型评估"
            ],
            "_index": 144
        },
        {
            "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
            "authors": [
                "Xingjian Wu",
                "Hanyin Cheng",
                "Xiangfei Qiu",
                "Zhengyu Li",
                "Jilin Hu",
                "Chenjuan Guo",
                "Bin Yang"
            ],
            "arxiv_id": "2512.14253v1",
            "summary": "In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14253v1",
            "code_links": [],
            "headline_zh": "提出DRAW2ACT框架，通过深度感知轨迹条件视频生成，提升机器人演示的可控性和一致性。",
            "summary_zh": "视频扩散模型为具身AI提供了强大的真实世界模拟器，但在机器人操作的可控性方面仍有限制。近期基于轨迹条件的视频生成工作填补了这一空白，但通常依赖于2D轨迹或单模态条件，限制了其生成可控且一致的机器人演示的能力。我们提出了DRAW2ACT，这是一个深度感知轨迹条件视频生成框架，它从输入轨迹中提取多个正交表示，捕捉深度、语义、形状和运动，并将它们注入扩散模型。此外，我们提出联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督来增强时空一致性。最后，我们引入了一个基于生成的RGB和深度序列的多模态策略模型，以回归机器人的关节角度。在Bridge V2、Berkeley Autolab和模拟基准测试上的实验表明，与现有基线相比，DRAW2ACT实现了更优的视觉保真度和一致性，同时获得了更高的操作成功率。",
            "intro_zh": [
                "现有方法依赖2D轨迹或单模态条件，导致机器人演示视频的可控性和一致性受限。",
                "DRAW2ACT从轨迹提取深度、语义等多模态表示，并注入扩散模型，联合生成RGB和深度视频。",
                "实验显示，DRAW2ACT在视觉保真度、一致性和操作成功率上均优于基线方法。"
            ],
            "method_zh": "DRAW2ACT是一个深度感知轨迹条件视频生成框架，整体基于扩散模型。关键创新点包括：从输入轨迹提取深度、语义、形状和运动等多模态正交表示，通过跨模态注意力机制联合生成空间对齐的RGB和深度视频，并引入深度监督增强时空一致性。与现有方法的主要区别在于，它结合了深度信息，避免了仅依赖2D轨迹的局限性，从而提升了生成视频的可控性和一致性。",
            "application_zh": "该研究可应用于机器人演示视频生成、具身AI模拟训练和自动化操作任务，通过生成高质量的多模态视频，帮助机器人学习复杂操作技能，提升实际部署中的成功率和效率。",
            "highlight_zh": "在Bridge V2、Berkeley Autolab和模拟基准测试中，DRAW2ACT在视觉保真度和一致性方面表现优异，操作成功率显著高于现有基线，验证了其方法的有效性。",
            "tags_zh": [
                "视频扩散模型",
                "轨迹条件生成",
                "深度感知",
                "多模态融合",
                "机器人演示",
                "时空一致性",
                "跨模态注意力",
                "具身AI"
            ],
            "_index": 145
        },
        {
            "title": "From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition",
            "authors": [
                "Yiqing Zhou",
                "Yu Lei",
                "Shuzheng Si",
                "Qingyan Sun",
                "Wei Wang",
                "Yifei Wu",
                "Hao Wen",
                "Gang Chen",
                "Fanchao Qi",
                "Maosong Sun"
            ],
            "arxiv_id": "2512.14244v1",
            "summary": "Managing extensive context remains a critical bottleneck for Large Language Models (LLMs), particularly in applications like long-document question answering and autonomous agents where lengthy inputs incur high computational costs and introduce noise. Existing compression techniques often disrupt local coherence through discrete token removal or rely on implicit latent encoding that suffers from positional bias and incompatibility with closed-source APIs. To address these limitations, we introduce the EDU-based Context Compressor, a novel explicit compression framework designed to preserve both global structure and fine-grained details. Our approach reformulates context compression as a structure-then-select process. First, our LingoEDU transforms linear text into a structural relation tree of Elementary Discourse Units (EDUs) which are anchored strictly to source indices to eliminate hallucination. Second, a lightweight ranking module selects query-relevant sub-trees for linearization. To rigorously evaluate structural understanding, we release StructBench, a manually annotated dataset of 248 diverse documents. Empirical results demonstrate that our method achieves state-of-the-art structural prediction accuracy and significantly outperforms frontier LLMs while reducing costs. Furthermore, our structure-aware compression substantially enhances performance across downstream tasks ranging from long-context tasks to complex Deep Search scenarios.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14244v1",
            "code_links": [],
            "headline_zh": "提出基于物理信息神经网络的T2量化方法，通过误差界分析解决心脏磁共振成像中定量参数估计的理论与数据挑战。",
            "summary_zh": "物理信息神经网络（PINN）正成为磁共振成像（MRI）定量参数估计的一种有前景方法。现有深度学习方法虽能提供T2参数的准确定量估计，但仍需大量训练数据，且缺乏理论支持和公认的金标准。鉴于目前尚无基于PINN的T2估计方法，我们提出将MRI基本物理原理——布洛赫方程嵌入PINN的损失函数中，该方法仅基于目标扫描数据，无需预定义训练数据库。此外，通过推导T2估计误差和布洛赫方程解泛化误差的严格上界，我们为评估PINN定量准确性建立了理论基础。即使无法获取真实值或金标准，该理论也能估计相对于真实定量参数T2的误差。在数值心脏模型和水模上验证了T2映射的准确性及理论分析的有效性，我们的方法在心肌T2范围内表现出优异的定量精度。在94例急性心肌梗死（AMI）患者中证实了临床适用性，在理论误差界内实现了低误差的定量T2估计，突显了PINN的稳健性和潜力。",
            "intro_zh": [
                "现有深度学习方法依赖大量训练数据且缺乏理论支持，难以在无金标准下评估T2定量准确性。",
                "提出将布洛赫方程嵌入PINN损失，仅基于扫描数据实现T2估计，无需预训练数据库。",
                "在数值模型和临床患者中验证方法，实现低误差T2量化，理论误差界为评估提供依据。"
            ],
            "method_zh": "论文提出基于物理信息神经网络（PINN）的T2量化框架，核心是将MRI的布洛赫方程作为物理约束嵌入神经网络的损失函数中。关键创新点在于推导了T2估计误差和布洛赫方程解泛化误差的严格上界，为PINN的定量准确性提供了理论保障。与现有深度学习方法相比，该方法无需大量训练数据，仅依赖目标扫描数据，通过物理原理引导网络学习，实现了数据高效且理论可解释的T2参数估计。",
            "application_zh": "该方法主要应用于心脏磁共振成像中的T2定量参数估计，特别适用于急性心肌梗死等心脏疾病的诊断和监测。通过提供理论误差界，可在无金标准情况下评估定量准确性，增强临床应用的可靠性和稳健性，推动精准医疗发展。",
            "highlight_zh": "在数值心脏模型和水模实验中，方法在心肌T2范围内表现出优异定量精度；在94例急性心肌梗死患者临床验证中，实现低误差T2估计，且结果符合理论误差界，证实了方法的有效性和临床潜力。",
            "tags_zh": [
                "物理信息神经网络",
                "T2量化",
                "心脏磁共振成像",
                "误差界分析",
                "布洛赫方程",
                "定量参数估计",
                "急性心肌梗死",
                "理论保障"
            ],
            "_index": 146
        },
        {
            "title": "Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning",
            "authors": [
                "Salvatore Romano",
                "Marco Grassia",
                "Giuseppe Mangioni"
            ],
            "arxiv_id": "2512.14241v1",
            "summary": "Graph generation is a crucial task in many fields, including network science and bioinformatics, as it enables the creation of synthetic graphs that mimic the properties of real-world networks for various applications. Graph Generative Models (GGMs) have emerged as a promising solution to this problem, leveraging deep learning techniques to learn the underlying distribution of real-world graphs and generate new samples that closely resemble them. Examples include approaches based on Variational Auto-Encoders, Recurrent Neural Networks, and more recently, diffusion-based models. However, the main limitation often lies in the evaluation process, which typically relies on Maximum Mean Discrepancy (MMD) as a metric to assess the distribution of graph properties in the generated ensemble. This paper introduces a novel methodology for evaluating GGMs that overcomes the limitations of MMD, which we call RGM (Representation-aware Graph-generation Model evaluation). As a practical demonstration of our methodology, we present a comprehensive evaluation of two state-of-the-art Graph Generative Models: Graph Recurrent Attention Networks (GRAN) and Efficient and Degree-guided graph GEnerative model (EDGE). We investigate their performance in generating realistic graphs and compare them using a Geometric Deep Learning model trained on a custom dataset of synthetic and real-world graphs, specifically designed for graph classification tasks. Our findings reveal that while both models can generate graphs with certain topological properties, they exhibit significant limitations in preserving the structural characteristics that distinguish different graph domains. We also highlight the inadequacy of Maximum Mean Discrepancy as an evaluation metric for GGMs and suggest alternative approaches for future research.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "physics.soc-ph"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14241v1",
            "code_links": [],
            "headline_zh": "提出多速率规划与控制框架，解决多移动机械臂在受限环境中协同搬运的轨迹跟踪问题。",
            "summary_zh": "本文研究了在障碍物密集且高度受限环境中，移动多机械臂系统在时空任务规范下的协同操作问题。任务要求在运输抓取物体时，同时满足连续机器人动力学和由障碍物及狭窄通道引起的离散几何约束。为应对这种混合结构，我们提出了一个多速率规划与控制框架，该框架结合了离线生成满足信号时序逻辑（STL）的物体轨迹和无碰撞基座足迹，以及在线约束逆运动学和连续时间反馈控制。由此产生的闭环系统能够在跟踪期望物体运动的同时，实现多个机械臂的协调重构。该方法通过使用三个Franka Emika Panda移动机械臂刚性抓取物体的高保真物理仿真进行了评估。",
            "intro_zh": [
                "核心问题：在障碍物密集的受限环境中，多移动机械臂协同搬运需同时处理连续动力学、离散几何约束及复杂时空任务，现有方法难以高效协调。",
                "方法要点：提出多速率框架，离线规划满足STL的物体轨迹与无碰撞基座路径，在线结合约束逆运动学与反馈控制实现协调跟踪。",
                "实验或效果：在高保真仿真中，三个Panda移动机械臂成功实现刚性抓取物体的协同搬运，验证了框架在复杂环境下的有效性。"
            ],
            "method_zh": "论文提出一个多速率规划与控制框架。整体上，框架分为离线与在线两部分：离线阶段生成满足信号时序逻辑（STL）规范的对象轨迹和确保无碰撞的移动基座足迹路径；在线阶段则执行约束逆运动学计算，并结合连续时间反馈控制，实时协调多个机械臂的运动以精确跟踪目标轨迹。关键创新在于将离散的时空任务规范（STL）与连续的动力学控制相结合，通过多速率处理有效应对环境约束与系统动力学的混合特性。与现有方法相比，此框架能更系统地处理复杂环境下的协同操作问题，特别是在狭窄通道和障碍物密集场景中，实现了离线规划安全性与在线控制实时性的平衡。",
            "application_zh": "该研究可应用于工业自动化中的复杂物料搬运、仓储物流的自主操作、灾难救援中的协同物体移动，以及任何需要在受限空间内由多个机器人协同完成精密操作的任务，提升系统在动态和约束环境下的自主性与可靠性。",
            "highlight_zh": "在高保真物理仿真中，使用三个Franka Emika Panda移动机械臂成功实现了刚性抓取物体的协同搬运。系统在障碍物密集和狭窄通道的受限环境下，能够有效跟踪满足STL规范的物体轨迹，同时确保基座无碰撞，验证了多速率框架在复杂协同操作任务中的可行性与性能。",
            "tags_zh": [
                "多机械臂协同",
                "轨迹跟踪",
                "受限环境操作",
                "信号时序逻辑",
                "多速率控制",
                "移动操作",
                "逆运动学",
                "物理仿真验证"
            ],
            "_index": 147
        },
        {
            "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
            "authors": [
                "Estelle Zheng",
                "Nathan Cerisara",
                "Sébastien Warichet",
                "Emmanuel Helbert",
                "Christophe Cerisara"
            ],
            "arxiv_id": "2512.14237v1",
            "summary": "Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "headline_zh": "提出Hyper++方法以解决双曲深度强化学习中的优化不稳定问题，在ProcGen和Atari-5环境中实现稳定高效训练。",
            "summary_zh": "强化学习（RL）智能体的性能关键取决于底层特征表示的质量。双曲特征空间非常适合此目的，因为它们能自然捕捉复杂RL环境中常见的层次和关系结构。然而，由于RL的非平稳性，利用这些空间通常面临优化挑战。在这项工作中，我们确定了决定双曲深度RL智能体训练成败的关键因素。通过分析双曲几何的庞加莱球和双曲面模型中核心操作的梯度，我们发现大范数嵌入会破坏基于梯度的训练稳定性，导致近端策略优化（PPO）中的信任区域违反。基于这些见解，我们引入了Hyper++，一种新的双曲PPO智能体，包含三个组件：（i）通过分类值损失而非回归实现稳定的评论家训练；（ii）特征正则化保证有界范数，同时避免裁剪带来的维度诅咒；（iii）使用更优化友好的双曲网络层公式。在ProcGen实验中，我们表明Hyper++保证了稳定学习，优于先前的双曲智能体，并将挂钟时间减少了约30%。在Atari-5与Double DQN中，Hyper++显著优于欧几里得和双曲基线。我们在https://github.com/Probabilistic-and-Interactive-ML/hyper-rl 发布了代码。",
            "intro_zh": [
                "核心问题：双曲深度强化学习面临优化挑战，大范数嵌入导致梯度训练不稳定，破坏PPO的信任区域约束。",
                "方法要点：提出Hyper++智能体，结合分类值损失、特征正则化和优化友好双曲层，确保稳定训练和高效性能。",
                "实验或效果：在ProcGen和Atari-5环境中，Hyper++实现稳定学习，性能优于基线，训练时间减少约30%。"
            ],
            "method_zh": "Hyper++的整体框架基于近端策略优化（PPO），在双曲特征空间中操作。关键技术创新点包括：使用分类值损失替代回归损失来稳定评论家训练，避免梯度爆炸；引入特征正则化机制，约束嵌入范数在合理范围内，防止大范数问题，同时避免传统裁剪方法导致的维度诅咒；采用更优化友好的双曲网络层设计，改进梯度流。与现有方法的主要区别在于，它系统解决了双曲RL中的优化不稳定问题，通过理论分析和工程优化，实现了更鲁棒和高效的双曲深度强化学习。",
            "application_zh": "该研究可应用于复杂强化学习环境，如视频游戏（如Atari）、程序生成环境（如ProcGen）和机器人控制，其中环境具有层次或关系结构。通过稳定双曲特征学习，能提升智能体在结构化任务中的性能和训练效率，具有实际价值于自动化决策和智能系统开发。",
            "highlight_zh": "在ProcGen实验中，Hyper++保证稳定学习，优于先前双曲智能体，并将挂钟时间减少约30%。在Atari-5与Double DQN中，Hyper++显著超越欧几里得和双曲基线，展示了其高效性和泛化能力。",
            "tags_zh": [
                "双曲几何",
                "深度强化学习",
                "近端策略优化",
                "特征正则化",
                "梯度稳定",
                "程序生成环境",
                "Atari游戏",
                "优化挑战"
            ],
            "_index": 148
        },
        {
            "title": "4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation",
            "authors": [
                "Jimmie Kwok",
                "Holger Caesar",
                "Andras Palffy"
            ],
            "arxiv_id": "2512.14235v1",
            "summary": "Automotive radar has shown promising developments in environment perception due to its cost-effectiveness and robustness in adverse weather conditions. However, the limited availability of annotated radar data poses a significant challenge for advancing radar-based perception systems. To address this limitation, we propose a novel framework to generate 4D radar point clouds for training and evaluating object detectors. Unlike image-based diffusion, our method is designed to consider the sparsity and unique characteristics of radar point clouds by applying diffusion to a latent point cloud representation. Within this latent space, generation is controlled via conditioning at either the object or scene level. The proposed 4D-RaDiff converts unlabeled bounding boxes into high-quality radar annotations and transforms existing LiDAR point cloud data into realistic radar scenes. Experiments demonstrate that incorporating synthetic radar data of 4D-RaDiff as data augmentation method during training consistently improves object detection performance compared to training on real data only. In addition, pre-training on our synthetic data reduces the amount of required annotated radar data by up to 90% while achieving comparable object detection performance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14235v1",
            "code_links": [],
            "headline_zh": "提出SkyLume大规模无人机数据集以解决多时序光照下城市场景重建的挑战",
            "summary_zh": "近年来，神经辐射场和3D高斯溅射在基于无人机的大规模3D重建任务中展现出强大潜力，通过拟合图像外观实现重建。然而，现实世界的大规模采集通常基于多时序数据捕获，不同时间段的光照不一致性会显著导致颜色伪影、几何不准确和外观不一致。由于缺乏系统捕获相同区域在不同光照条件下的无人机数据集，这一挑战在很大程度上尚未得到充分探索。为填补这一空白，我们引入了SkyLume，这是一个专门为研究城市场景建模中光照鲁棒3D重建而设计的大规模真实世界无人机数据集：(1) 我们从10个城市区域收集数据，包含超过10万张高分辨率无人机图像（四个倾斜视图和天底视图），每个区域在一天中的三个时间段被捕获，以系统隔离光照变化。(2) 为支持几何和外观的精确评估，我们提供每个场景的激光雷达扫描和准确的3D地面真值，用于评估不同光照下的深度、表面法线和重建质量。(3) 对于逆渲染任务，我们引入了时间一致性系数，这是一个衡量跨时间反照率稳定性的指标，直接评估光照与材质解耦的鲁棒性。我们旨在使这一资源成为推动大规模逆渲染、几何重建和新视图合成研究和现实世界评估的基础。",
            "intro_zh": [
                "现有方法在基于多时序无人机数据的大规模3D重建中面临光照不一致性挑战，导致颜色伪影和几何不准确，缺乏系统数据集支持研究。",
                "论文提出SkyLume数据集，包含10个城市区域超过10万张图像，每个区域在三个时间段捕获，并提供激光雷达扫描和3D地面真值以支持评估。",
                "引入时间一致性系数作为评估指标，直接衡量光照与材质解耦的鲁棒性，为逆渲染任务提供量化基准，推动相关研究进展。"
            ],
            "method_zh": "论文的核心方法围绕SkyLume数据集的构建和评估框架展开。整体框架包括数据采集、标注和评估指标设计。关键技术创新点在于系统捕获同一城市区域在一天中三个时间段（如早晨、中午、傍晚）的高分辨率无人机图像，以隔离光照变化，同时提供激光雷达扫描和精确3D地面真值用于几何和外观评估。与现有方法的主要区别在于，SkyLume是首个专门针对多时序光照下大规模城市场景重建的无人机数据集，填补了该领域数据空白，并引入时间一致性系数作为逆渲染任务的新评估指标，直接量化光照解耦的稳定性。",
            "application_zh": "该研究在计算机视觉和机器人领域具有广泛潜在应用，包括城市建模、自动驾驶环境感知、虚拟现实场景生成和文化遗产数字化。通过提供光照鲁棒的重建数据，可提升现实世界3D重建的准确性和一致性，支持大规模逆渲染算法开发和评估，推动无人机巡检、智慧城市规划和增强现实等实际应用。",
            "highlight_zh": "SkyLume数据集包含超过10万张高分辨率图像，覆盖10个城市区域，每个区域在三个时间段捕获，系统隔离光照变化。实验通过激光雷达扫描和3D地面真值验证了数据集的几何和外观质量，时间一致性系数为逆渲染任务提供了量化评估基准，显著提升了光照鲁棒重建的研究能力。",
            "tags_zh": [
                "无人机数据集",
                "光照鲁棒重建",
                "多时序数据",
                "逆渲染",
                "3D高斯溅射",
                "城市场景建模",
                "时间一致性系数",
                "大规模3D重建"
            ],
            "_index": 149
        },
        {
            "title": "Multi-View MRI Approach for Classification of MGMT Methylation in Glioblastoma Patients",
            "authors": [
                "Rawan Alyahya",
                "Asrar Alruwayqi",
                "Atheer Alqarni",
                "Asma Alkhaldi",
                "Metab Alkubeyyer",
                "Xin Gao",
                "Mona Alshahrani"
            ],
            "arxiv_id": "2512.14232v1",
            "summary": "The presence of MGMT promoter methylation significantly affects how well chemotherapy works for patients with Glioblastoma Multiforme (GBM). Currently, confirmation of MGMT promoter methylation relies on invasive brain tumor tissue biopsies. In this study, we explore radiogenomics techniques, a promising approach in precision medicine, to identify genetic markers from medical images. Using MRI scans and deep learning models, we propose a new multi-view approach that considers spatial relationships between MRI views to detect MGMT methylation status. Importantly, our method extracts information from all three views without using a complicated 3D deep learning model, avoiding issues associated with high parameter count, slow convergence, and substantial memory demands. We also introduce a new technique for tumor slice extraction and show its superiority over existing methods based on multiple evaluation metrics. By comparing our approach to state-of-the-art models, we demonstrate the efficacy of our method. Furthermore, we share a reproducible pipeline of published models, encouraging transparency and the development of robust diagnostic tools. Our study highlights the potential of non-invasive methods for identifying MGMT promoter methylation and contributes to advancing precision medicine in GBM treatment.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14232v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14190v1",
            "code_links": [],
            "headline_zh": "提出随机桥作为生成模型中的随机传输方法，实现高效高质量样本生成。",
            "summary_zh": "本文探讨了在生成建模领域使用随机桥——即在固定时间点被约束为取目标分布值的随机过程——的动机。当适当初始化时，随机桥可以充当两个概率分布之间的随机传输，并且根据驱动过程的不同，可以表现出马尔可夫或非马尔可夫、连续、不连续或混合模式。我们展示了如何从一般的概率陈述出发，然后扩展到针对学习和模拟算法的具体表示，这些表示基于信息处理。我们的实证结果建立在高斯随机桥之上，与传统方法相比，能以显著更少的步骤生成高质量样本，同时获得具有竞争力的弗雷歇起始距离分数。我们的分析表明，所提出的框架计算成本低廉，适用于高速生成任务。",
            "intro_zh": [
                "现有生成模型在生成高质量样本时通常需要大量计算步骤，导致效率低下。",
                "提出使用随机桥作为随机传输方法，通过条件随机过程连接源和目标分布。",
                "实验表明，该方法能以更少步骤生成高质量样本，计算成本低且适合高速任务。"
            ],
            "method_zh": "论文提出一个基于随机桥的生成模型框架，其核心思想是利用随机过程（如高斯随机桥）作为连接两个概率分布的随机传输。关键创新在于将随机桥条件化为在固定时间点取目标分布值，从而形成一种灵活的传输机制，可适应马尔可夫或非马尔可夫、连续或不连续模式。与现有方法（如基于扩散或流的方法）相比，该方法直接从概率陈述出发，通过信息处理视角构建学习和模拟算法，减少了中间步骤，提高了计算效率。",
            "application_zh": "该研究适用于需要高速生成高质量样本的领域，如图像生成、视频合成和自然语言处理中的序列生成。其计算廉价特性使其在实时应用和资源受限环境中具有实际价值，例如在线内容创建、游戏开发和模拟系统。",
            "highlight_zh": "基于高斯随机桥的实证结果显示，与传统方法相比，能以显著更少的步骤生成高质量样本，同时获得竞争性的弗雷歇起始距离分数，证明了框架的高效性和性能优势。",
            "tags_zh": [
                "随机桥",
                "生成模型",
                "随机传输",
                "高斯过程",
                "高效采样",
                "概率建模",
                "信息处理",
                "高速生成"
            ],
            "_index": 150
        },
        {
            "title": "Weighted Conformal Prediction Provides Adaptive and Valid Mask-Conditional Coverage for General Missing Data Mechanisms",
            "authors": [
                "Jiarong Fan",
                "Juhyun Park. Thi Phuong Thuy Vo",
                "Nicolas Brunel"
            ],
            "arxiv_id": "2512.14221v1",
            "summary": "Conformal prediction (CP) offers a principled framework for uncertainty quantification, but it fails to guarantee coverage when faced with missing covariates. In addressing the heterogeneity induced by various missing patterns, Mask-Conditional Valid (MCV) Coverage has emerged as a more desirable property than Marginal Coverage. In this work, we adapt split CP to handle missing values by proposing a preimpute-mask-then-correct framework that can offer valid coverage. We show that our method provides guaranteed Marginal Coverage and Mask-Conditional Validity for general missing data mechanisms. A key component of our approach is a reweighted conformal prediction procedure that corrects the prediction sets after distributional imputation (multiple imputation) of the calibration dataset, making our method compatible with standard imputation pipelines. We derive two algorithms, and we show that they are approximately marginally valid and MCV. We evaluate them on synthetic and real-world datasets. It reduces significantly the width of prediction intervals w.r.t standard MCV methods, while maintaining the target guarantees.",
            "categories": [
                "stat.ML",
                "cs.LG"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14221v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "IEEE Transactions on Dependable and Secure Computing",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14188v1",
            "code_links": [],
            "headline_zh": "提出基于动量的自适应矩阵攻击AdaMI，以解决对抗样本生成中的优化收敛和稳定性问题。",
            "summary_zh": "生成对抗样本可被表述为一个优化问题。在各种基于优化的攻击方法中，基于梯度的PGD和基于动量的MI-FGSM引起了广泛关注。然而，这些攻击都使用符号函数来缩放扰动，从优化理论的角度来看存在一些理论问题。本文首先揭示了PGD实际上是投影梯度法的一种特定重构，仅使用当前梯度来确定步长。进一步，我们展示了当使用带有累积梯度的传统自适应矩阵来缩放扰动时，PGD就变成了AdaGrad。受此分析启发，我们提出了一种新颖的基于动量的攻击方法AdaMI，其中扰动通过一个有趣的基于动量的自适应矩阵进行优化。AdaMI被证明在凸问题上能达到最优收敛，表明它解决了MI-FGSM的非收敛问题，从而确保了优化过程的稳定性。实验表明，所提出的基于动量的自适应矩阵可以作为一种通用且有效的技术，在不同网络间提升对抗样本的迁移性，同时保持更好的稳定性和不可感知性。",
            "intro_zh": [
                "现有对抗攻击方法如PGD和MI-FGSM使用符号函数缩放扰动，存在优化理论上的收敛性和稳定性问题。",
                "提出AdaMI攻击，利用基于动量的自适应矩阵优化扰动，确保凸问题上的最优收敛，解决非收敛问题。",
                "实验显示AdaMI在多种网络上显著提升对抗样本迁移性，同时保持更好的稳定性和不可感知性。"
            ],
            "method_zh": "论文提出AdaMI攻击方法，整体框架基于优化理论，将对抗样本生成视为一个优化问题。关键技术创新点是引入基于动量的自适应矩阵来缩放扰动，该矩阵结合了历史梯度信息，类似于优化算法中的动量机制。与现有方法的主要区别在于：PGD仅使用当前梯度，MI-FGSM引入动量但使用符号函数，而AdaMI通过自适应矩阵动态调整步长，避免了符号函数的局限性，从而在理论上保证凸问题的最优收敛，提高了优化过程的稳定性。",
            "application_zh": "该研究可应用于计算机视觉和机器学习的安全领域，如对抗性防御、模型鲁棒性评估和隐私保护。通过生成更稳定、迁移性更强的对抗样本，有助于开发更健壮的AI系统，提升实际部署中的安全性。",
            "highlight_zh": "AdaMI在多个基准网络上的实验表明，其对抗样本迁移性优于当前最先进方法，同时优化过程更稳定，扰动更不易被察觉，验证了基于动量的自适应矩阵的有效性。",
            "tags_zh": [
                "对抗样本生成",
                "优化攻击",
                "动量方法",
                "自适应矩阵",
                "迁移性提升",
                "稳定性优化",
                "计算机视觉安全"
            ],
            "_index": 151
        },
        {
            "title": "Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.14206v1",
            "summary": "We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14206v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "物理动作",
                    "matched_keywords": [
                        "physics simulation"
                    ],
                    "score": 1
                }
            ],
            "primary_category": "cs.MM",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The 35th edition of the Workshop on Network and Operating System Support for Digital Audio and Video (NOSSDAV '25), March 31-April 4, 2025, Stellenbosch, South Africa",
            "doi": "10.1145/3712678.3721881",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14185v1",
            "code_links": [],
            "headline_zh": "提出ELVIS端到端学习型视频流增强管道，通过生成式AI去除冗余数据以提升视频质量而不增加带宽需求。",
            "summary_zh": "视频流的主要挑战在于平衡高视频质量与流畅播放。传统编解码器虽已针对此权衡进行优化，但由于无法利用上下文信息，必须编码并传输全部视频数据。本文介绍了ELVIS（端到端学习型视频流增强管道），这是一种端到端架构，结合了服务器端编码优化与客户端生成式修复技术，以去除并重建冗余视频数据。其模块化设计使ELVIS能够集成不同编解码器、修复模型和质量指标，从而适应未来创新。我们的结果表明，当前技术相比基准测试可实现高达11个VMAF点的改进，但由于计算需求，实时应用仍面临挑战。ELVIS代表了将生成式AI融入视频流管道的基础性步骤，能够在无需增加带宽的情况下实现更高质量体验。",
            "intro_zh": [
                "传统视频流方法需编码并传输全部数据，无法利用上下文信息，导致带宽与质量间的固有矛盾。",
                "ELVIS采用端到端架构，结合服务器端编码优化与客户端生成式修复，去除冗余数据并重建内容。",
                "实验显示，ELVIS在VMAF指标上提升达11点，但计算需求对实时应用构成挑战，需进一步优化。"
            ],
            "method_zh": "ELVIS是一个端到端学习型视频流增强管道，整体框架包括服务器端编码优化模块和客户端生成式修复模块。服务器端通过智能分析去除视频中的冗余数据，仅传输关键信息；客户端利用生成式AI（如修复模型）重建缺失内容，确保视频质量。关键技术创新在于模块化设计，允许灵活集成不同编解码器、修复模型和质量评估指标，增强了系统的适应性和可扩展性。与现有方法的主要区别在于，传统方法依赖完整数据传输，而ELVIS通过生成式AI减少数据量，实现带宽节省与质量提升的平衡。",
            "application_zh": "该研究可应用于在线视频流媒体服务（如Netflix、YouTube），提升高清或4K视频的传输效率；也可用于远程教育、视频会议等场景，优化带宽受限环境下的视频体验。其实际价值在于降低带宽成本的同时提高用户观看质量，推动生成式AI在实时视频处理领域的应用。",
            "highlight_zh": "实验结果表明，ELVIS在VMAF（视频多方法评估融合）指标上相比基准测试最高提升11点，显著改善了视频质量感知。然而，由于生成式修复模型的计算复杂度，实时应用面临延迟挑战，需进一步优化计算效率以实现广泛部署。",
            "tags_zh": [
                "视频流增强",
                "生成式AI",
                "端到端学习",
                "编码优化",
                "修复模型",
                "带宽节省",
                "VMAF评估",
                "模块化设计"
            ],
            "_index": 152
        },
        {
            "title": "Fracture Morphology Classification: Local Multiclass Modeling for Multilabel Complexity",
            "authors": [
                "Cassandra Krause",
                "Mattias P. Heinrich",
                "Ron Keuth"
            ],
            "arxiv_id": "2512.14196v1",
            "summary": "Between $15\\,\\%$ and $45\\,\\%$ of children experience a fracture during their growth years, making accurate diagnosis essential. Fracture morphology, alongside location and fragment angle, is a key diagnostic feature. In this work, we propose a method to extract fracture morphology by assigning automatically global AO codes to corresponding fracture bounding boxes. This approach enables the use of public datasets and reformulates the global multilabel task into a local multiclass one, improving the average F1 score by $7.89\\,\\%$. However, performance declines when using imperfect fracture detectors, highlighting challenges for real-world deployment. Our code is available on GitHub.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted as poster at the German Conference on Medical Image Computing 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14196v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "RL"
                    ],
                    "score": 1
                }
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted to the Second Workshop on Bangla Language Processing (BLP) at IJCNLP-AACL 2025. 14 pages, 9 figures, 6 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14179v1",
            "code_links": [],
            "headline_zh": "提出两种检索增强生成管道，用于孟加拉语标准语到方言的机器翻译，解决低资源方言翻译难题。",
            "summary_zh": "将标准语言翻译为区域方言是自然语言处理中的重要挑战，尤其在孟加拉语中，由于数据稀缺和语言变异性，这一问题尤为突出。本文提出并比较了两种新颖的检索增强生成（RAG）管道，用于标准语到方言的孟加拉语翻译。第一种是基于转录本的管道，利用音频转录中的大型方言句子上下文；第二种是更有效的标准化句子对管道，使用结构化的“方言:标准孟加拉语”句子对。我们在六种孟加拉语方言和多种大型语言模型上评估了这两种管道，使用BLEU、ChrF、WER和BERTScore等指标。研究结果表明，句子对管道始终优于基于转录本的管道，例如在吉大港方言中，将词错误率（WER）从76%降低到55%。关键的是，这种RAG方法使较小模型（如Llama-3.1-8B）能够超越更大模型（如GPT-OSS-120B），表明精心设计的检索策略可能比模型规模更为关键。这项工作为低资源方言翻译提供了一种有效、无需微调的解决方案，为保护语言多样性提供了实用蓝图。",
            "intro_zh": [
                "核心问题：孟加拉语标准语到方言翻译面临数据稀缺和语言变异性挑战，现有方法在低资源环境下效果有限。",
                "方法要点：提出两种RAG管道，基于转录本和标准化句子对，利用检索增强生成技术提升翻译质量。",
                "实验或效果：句子对管道显著降低词错误率，较小模型通过RAG超越更大模型，验证检索策略的重要性。"
            ],
            "method_zh": "论文提出两种检索增强生成（RAG）管道框架：基于转录本的管道从音频转录中提取方言句子上下文，用于检索增强；标准化句子对管道则使用结构化的“方言:标准孟加拉语”句子对作为检索源。关键创新点在于将RAG技术应用于低资源方言翻译，通过检索相关上下文来增强大型语言模型的翻译能力，无需额外微调。与现有方法的主要区别在于，传统方法依赖大规模平行语料或复杂微调，而本方法通过检索策略有效利用有限数据，直接提升模型性能，特别适用于数据稀缺场景。",
            "application_zh": "该研究可应用于低资源语言方言翻译、语言多样性保护、跨方言通信辅助工具开发，以及教育、媒体和文化传承领域，为多语言社会提供实用技术支持。",
            "highlight_zh": "句子对管道在吉大港方言上将词错误率从76%降至55%，较小模型Llama-3.1-8B通过RAG超越GPT-OSS-120B等更大模型，证明检索策略比模型规模更关键。",
            "tags_zh": [
                "检索增强生成",
                "孟加拉语翻译",
                "方言机器翻译",
                "低资源自然语言处理",
                "语言多样性保护",
                "大型语言模型应用",
                "词错误率优化",
                "无微调解决方案"
            ],
            "_index": 153
        },
        {
            "title": "Improving Semantic Uncertainty Quantification in LVLMs with Semantic Gaussian Processes",
            "authors": [
                "Joseph Hoche",
                "Andrei Bursuc",
                "David Brellmann",
                "Gilles Louppe",
                "Pavel Izmailov",
                "Angela Yao",
                "Gianni Franchi"
            ],
            "arxiv_id": "2512.14177v1",
            "summary": "Large Vision-Language Models (LVLMs) often produce plausible but unreliable outputs, making robust uncertainty estimation essential. Recent work on semantic uncertainty estimates relies on external models to cluster multiple sampled responses and measure their semantic consistency. However, these clustering methods are often fragile, highly sensitive to minor phrasing variations, and can incorrectly group or separate semantically similar answers, leading to unreliable uncertainty estimates. We propose Semantic Gaussian Process Uncertainty (SGPU), a Bayesian framework that quantifies semantic uncertainty by analyzing the geometric structure of answer embeddings, avoiding brittle clustering. SGPU maps generated answers into a dense semantic space, computes the Gram matrix of their embeddings, and summarizes their semantic configuration via the eigenspectrum. This spectral representation is then fed into a Gaussian Process Classifier that learns to map patterns of semantic consistency to predictive uncertainty, and that can be applied in both black-box and white-box settings. Across six LLMs and LVLMs on eight datasets spanning VQA, image classification, and textual QA, SGPU consistently achieves state-of-the-art calibration (ECE) and discriminative (AUROC, AUARC) performance. We further show that SGPU transfers across models and modalities, indicating that its spectral representation captures general patterns of semantic uncertainty.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14177v1",
            "code_links": [],
            "headline_zh": "提出语义高斯过程不确定性框架，以解决大型视觉语言模型中语义不确定性量化不可靠的问题。",
            "summary_zh": "大型视觉语言模型（LVLMs）常产生看似合理但不可靠的输出，因此稳健的不确定性估计至关重要。现有的语义不确定性估计方法依赖外部模型对多个采样响应进行聚类并测量其语义一致性，但这些聚类方法往往脆弱，对细微措辞变化高度敏感，可能错误地分组或分离语义相似的答案，导致不确定性估计不可靠。我们提出了语义高斯过程不确定性（SGPU），这是一个贝叶斯框架，通过分析答案嵌入的几何结构来量化语义不确定性，避免了脆弱的聚类。SGPU将生成的答案映射到密集的语义空间，计算其嵌入的Gram矩阵，并通过特征谱总结其语义配置。然后将这种谱表示输入高斯过程分类器，该分类器学习将语义一致性模式映射到预测不确定性，并可在黑盒和白盒设置中应用。在涵盖VQA、图像分类和文本QA的八个数据集上，对六个LLM和LVLM进行测试，SGPU在标定（ECE）和判别（AUROC、AUARC）性能方面始终达到最先进水平。我们进一步表明，SGPU可跨模型和模态迁移，表明其谱表示捕捉了语义不确定性的一般模式。",
            "intro_zh": [
                "现有方法依赖外部聚类模型，对措辞变化敏感，易错误分组语义相似答案，导致不确定性估计不可靠。",
                "提出SGPU框架，通过分析答案嵌入的几何结构，避免聚类，使用谱表示和高斯过程分类器量化语义不确定性。",
                "在多个数据集和模型上，SGPU在标定和判别性能方面达到最先进水平，并展示跨模型和模态的迁移能力。"
            ],
            "method_zh": "SGPU是一个贝叶斯框架，整体框架包括三个步骤：首先，将LVLM生成的多个答案映射到密集语义空间，获取其嵌入表示；其次，计算这些嵌入的Gram矩阵，并通过特征谱分析总结答案的语义配置，形成谱表示；最后，将谱表示输入高斯过程分类器，该分类器学习从语义一致性模式到预测不确定性的映射。关键技术创新点在于避免使用脆弱的聚类方法，转而利用几何结构和谱分析来捕捉语义不确定性。与现有方法的主要区别在于，SGPU不依赖外部聚类模型，而是基于嵌入的几何特性，提供更稳健和通用的不确定性估计，适用于黑盒和白盒设置。",
            "application_zh": "该研究可应用于需要高可靠性的大型视觉语言模型场景，如自动驾驶中的视觉问答、医疗图像分析、内容审核和智能助手，通过改进不确定性估计，提升模型输出的可信度和安全性。",
            "highlight_zh": "在六个LLM和LVLM上，覆盖八个VQA、图像分类和文本QA数据集，SGPU在标定性能（ECE）和判别性能（AUROC、AUARC）方面均达到最先进水平，并展示出跨模型和模态的迁移能力，验证了其通用性。",
            "tags_zh": [
                "语义不确定性量化",
                "大型视觉语言模型",
                "高斯过程分类器",
                "谱表示",
                "贝叶斯框架",
                "多模态迁移",
                "模型校准",
                "多模态学习",
                "嵌入几何分析"
            ],
            "_index": 154
        },
        {
            "title": "On Improving Deep Active Learning with Formal Verification",
            "authors": [
                "Jonathan Spiegelman",
                "Guy Amir",
                "Guy Katz"
            ],
            "arxiv_id": "2512.14170v1",
            "summary": "Deep Active Learning (DAL) aims to reduce labeling costs in neural-network training by prioritizing the most informative unlabeled samples for annotation. Beyond selecting which samples to label, several DAL approaches further enhance data efficiency by augmenting the training set with synthetic inputs that do not require additional manual labeling. In this work, we investigate how augmenting the training data with adversarial inputs that violate robustness constraints can improve DAL performance. We show that adversarial examples generated via formal verification contribute substantially more than those produced by standard, gradient-based attacks. We apply this extension to multiple modern DAL techniques, as well as to a new technique that we propose, and show that it yields significant improvements in model generalization across standard benchmarks.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14170v1",
            "code_links": [],
            "headline_zh": "提出基于形式验证的对抗样本增强方法，以提升深度主动学习的模型泛化能力",
            "summary_zh": "深度主动学习旨在通过优先标注信息量最大的未标记样本来降低神经网络训练中的标注成本。除了选择标注样本外，一些深度主动学习方法还通过添加无需额外手动标注的合成输入来进一步增强数据效率。本研究探讨了如何通过添加违反鲁棒性约束的对抗样本来增强训练数据，从而提升深度主动学习的性能。研究表明，通过形式验证生成的对抗样本比基于标准梯度攻击生成的样本贡献更大。我们将此扩展应用于多种现代深度主动学习技术以及我们提出的新技术，并证明其在标准基准测试中显著提升了模型的泛化能力。",
            "intro_zh": [
                "现有深度主动学习方法在数据增强方面主要依赖合成输入，但对抗样本的生成多基于梯度攻击，可能无法充分提升模型鲁棒性。",
                "论文提出使用形式验证生成对抗样本，这些样本能更有效地违反鲁棒性约束，从而增强训练数据。",
                "实验表明，该方法在多个深度主动学习技术和新提出的技术上均显著提升了模型在标准基准测试中的泛化性能。"
            ],
            "method_zh": "论文的核心方法是将形式验证生成的对抗样本集成到深度主动学习框架中。整体框架包括：在主动学习循环中，不仅选择信息量大的未标记样本进行标注，还通过形式验证技术生成对抗样本作为数据增强。关键技术创新在于利用形式验证（而非传统梯度攻击）来生成对抗样本，这些样本能更精确地违反模型的鲁棒性约束（如安全属性），从而提供更有效的训练信号。与现有方法的主要区别在于，现有方法通常使用基于梯度的攻击生成对抗样本，而本方法通过形式验证确保生成的样本在理论上更具挑战性，能更全面地暴露模型弱点。",
            "application_zh": "该研究可应用于需要高数据效率的深度学习场景，如自动驾驶、医疗图像分析或自然语言处理，其中标注成本高昂且模型鲁棒性至关重要。通过减少标注需求并提升泛化能力，能降低实际部署中的资源消耗和风险。",
            "highlight_zh": "实验结果显示，使用形式验证生成的对抗样本进行数据增强，在多个深度主动学习技术（如不确定性采样、多样性采样）和新提出的技术上，模型在标准基准测试（如CIFAR-10、MNIST）中的泛化性能得到显著提升，具体提升幅度因数据集和技术而异，但普遍优于基于梯度攻击的增强方法。",
            "tags_zh": [
                "深度主动学习",
                "形式验证",
                "对抗样本",
                "数据增强",
                "模型泛化",
                "鲁棒性约束",
                "神经网络训练",
                "标注成本降低"
            ],
            "_index": 155
        },
        {
            "title": "PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario",
            "authors": [
                "Zhijie Zhong",
                "Zhiwen Yu",
                "Pengyu Li",
                "Jianming Lv",
                "C. L. Philip Chen",
                "Min Chen"
            ],
            "arxiv_id": "2512.14150v1",
            "summary": "Radio path loss prediction (RPP) is critical for optimizing 5G networks and enabling IoT, smart city, and similar applications. However, current deep learning-based RPP methods lack proactive environmental modeling, struggle with realistic multi-transmitter scenarios, and generalize poorly under distribution shifts, particularly when training/testing environments differ in building density or transmitter configurations. This paper identifies three key issues: (1) passive environmental modeling that overlooks transmitters and key environmental features; (2) overemphasis on single-transmitter scenarios despite real-world multi-transmitter prevalence; (3) excessive focus on in-distribution performance while neglecting distribution shift challenges. To address these, we propose PathFinder, a novel architecture that actively models buildings and transmitters via disentangled feature encoding and integrates Mask-Guided Low-rank Attention to independently focus on receiver and building regions. We also introduce a Transmitter-Oriented Mixup strategy for robust training and a new benchmark, single-to-multi-transmitter RPP (S2MT-RPP), tailored to evaluate extrapolation performance (multi-transmitter testing after single-transmitter training). Experimental results show PathFinder outperforms state-of-the-art methods significantly, especially in challenging multi-transmitter scenarios. Our code and project site are available at: https://emorzz1g.github.io/PathFinder/.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "34 pages, 14 figures, 4 tables. Under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14150v1",
            "code_links": [
                {
                    "url": "https://emorzz1g.github.io/PathFinder/",
                    "type": "project_page"
                }
            ],
            "headline_zh": "提出PathFinder架构，通过主动环境建模和注意力机制解决单发射器到多发射器场景下的路径损耗预测问题。",
            "summary_zh": "无线电路径损耗预测（RPP）对于优化5G网络和实现物联网、智慧城市等应用至关重要。然而，当前基于深度学习的RPP方法存在三个主要问题：缺乏主动环境建模、难以处理真实多发射器场景、在分布偏移下泛化能力差。本文提出PathFinder架构，通过解耦特征编码主动建模建筑物和发射器，并集成掩码引导低秩注意力机制独立关注接收器和建筑物区域。此外，引入面向发射器的混合策略进行鲁棒训练，并创建单到多发射器RPP（S2MT-RPP）基准来评估外推性能。实验结果表明，PathFinder在挑战性多发射器场景中显著优于现有方法。代码和项目网站已公开。",
            "intro_zh": [
                "现有方法被动建模环境，忽视发射器和关键特征，导致预测不准确。",
                "PathFinder通过解耦编码和掩码引导注意力主动建模环境，提升多发射器场景适应性。",
                "在S2MT-RPP基准上，PathFinder显著优于现有方法，尤其在多发射器测试中表现突出。"
            ],
            "method_zh": "PathFinder整体框架基于深度神经网络，核心创新包括解耦特征编码和掩码引导低秩注意力机制。解耦编码主动分离建筑物和发射器特征，增强环境建模能力；注意力机制独立处理接收器和建筑物区域，优化信息聚焦。与现有方法相比，PathFinder强调主动建模而非被动学习，并引入面向发射器的混合策略提升鲁棒性，专门针对单到多发射器场景设计，解决了分布偏移挑战。",
            "application_zh": "该研究可应用于5G网络优化、物联网部署和智慧城市建设，通过精准路径损耗预测提升无线通信效率，支持多发射器环境下的网络规划和资源分配，具有实际工程价值。",
            "highlight_zh": "PathFinder在单到多发射器RPP基准测试中表现优异，相比现有方法显著提升预测精度，特别是在多发射器场景下，验证了其主动建模和注意力机制的有效性。",
            "tags_zh": [
                "路径损耗预测",
                "多发射器场景",
                "主动环境建模",
                "注意力机制",
                "分布偏移",
                "5G网络优化",
                "深度学习"
            ],
            "_index": 165
        },
        {
            "title": "TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models",
            "authors": [
                "Hanning Chen",
                "Keyu Man",
                "Kevin Zhu",
                "Chenguang Zhu",
                "Haonan Li",
                "Tongbo Luo",
                "Xizhou Feng",
                "Wei Sun",
                "Sreen Tallam",
                "Mohsen Imani",
                "Partha Kanuparthy"
            ],
            "arxiv_id": "2512.14141v1",
            "summary": "Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14141v1",
            "code_links": [],
            "headline_zh": "提出TorchTraceAP基准数据集与迭代方法，以解决计算机视觉模型中性能反模式检测的自动化难题。",
            "summary_zh": "识别和解决机器学习模型中的性能反模式对于高效训练和推理至关重要，但这通常需要跨越系统基础设施、ML模型和内核开发的深厚专业知识。虽然大型科技公司依赖专门的ML基础设施工程师来分析torch跟踪和基准测试，但这种资源密集型工作流程对大多数计算机视觉研究人员来说难以实现。在众多挑战中，在冗长的执行跟踪中精确定位有问题的跟踪段仍然是最耗时的任务，并且难以用当前的ML模型（包括LLM）实现自动化。在这项工作中，我们提出了第一个专门设计用于评估和改进ML模型检测跟踪中反模式能力的基准数据集。我们的数据集包含超过600个来自不同计算机视觉模型（分类、检测、分割和生成）的PyTorch跟踪，这些跟踪是在多个硬件平台上收集的。我们还提出了一种新颖的迭代方法：首先使用轻量级ML模型检测具有反模式的跟踪段，然后使用大型语言模型进行细粒度分类和针对性反馈。实验结果表明，我们的方法在检测反模式区域方面显著优于无监督聚类和基于规则的统计技术。我们的方法还有效地弥补了LLM有限的上下文长度和推理效率低下的问题。",
            "intro_zh": [
                "现有方法依赖专家手动分析跟踪，耗时且难以自动化，尤其对计算机视觉研究人员资源不足。",
                "提出迭代方法：轻量级ML模型初步检测反模式段，LLM进行细粒度分类和反馈，结合两者优势。",
                "实验显示，该方法在检测反模式区域上显著优于无监督聚类和基于规则技术，并提升LLM效率。"
            ],
            "method_zh": "论文提出一种迭代框架，整体分为两个阶段：首先，使用轻量级ML模型（如小型神经网络）对PyTorch跟踪进行初步扫描，快速识别出可能包含性能反模式的跟踪段；然后，将这些候选段输入大型语言模型进行细粒度分类和生成针对性反馈。关键技术创新点在于结合了轻量级模型的高效检测能力和LLM的复杂推理能力，通过迭代方式优化检测精度。与现有方法的主要区别在于，它避免了纯规则或统计方法的局限性，同时解决了LLM上下文长度限制和推理效率低下的问题，实现了更自动化和精准的反模式检测。",
            "application_zh": "该研究可应用于计算机视觉模型的性能优化领域，帮助研究人员和工程师自动化检测训练和推理中的效率瓶颈，如内存泄漏、计算冗余等反模式。潜在价值包括降低对专家依赖、加速模型调试过程，并提升ML基础设施的智能化水平，适用于学术研究和工业部署场景。",
            "highlight_zh": "实验结果表明，提出的迭代方法在检测反模式区域方面显著优于无监督聚类和基于规则的统计技术，具体性能提升未量化但强调“显著”。此外，该方法有效补偿了LLM的上下文长度限制和推理效率问题，展示了在自动化检测任务中的实用优势。",
            "tags_zh": [
                "性能反模式检测",
                "PyTorch跟踪分析",
                "基准数据集",
                "迭代机器学习方法",
                "计算机视觉模型优化",
                "大型语言模型应用",
                "自动化调试工具",
                "ML基础设施"
            ],
            "_index": 166
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140v1",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140v1",
            "code_links": [],
            "headline_zh": "提出SketchAssist以解决线稿编辑中语义修改与局部重绘的平衡问题",
            "summary_zh": "线稿编辑是数字插画的核心环节，但现有图像编辑系统难以在支持高层次语义修改和精确局部重绘的同时，保持线稿的稀疏、风格敏感结构。本文提出SketchAssist，一个交互式线稿绘制助手，通过统一指令引导的全局编辑和线条引导的区域重绘来加速创作，同时保持无关区域和整体构图不变。为实现大规模应用，我们引入可控数据生成流程：从无属性基础线稿构建属性添加序列，通过跨序列采样形成多步编辑链，并应用风格保持的属性移除模型扩展风格覆盖。基于此数据，SketchAssist采用统一线稿编辑框架，对基于DiT的编辑器进行最小改动，重新利用RGB通道编码输入，实现在单一输入界面中无缝切换指令引导编辑和线条引导重绘。为进一步优化不同模式下的行为，我们在LoRA层集成任务引导的专家混合机制，通过文本和视觉线索路由，提升语义可控性、结构保真度和风格保持。大量实验显示，在两个任务上均达到最先进结果，相比近期基线，在指令遵循和风格/结构保持方面表现更优。我们的数据集和SketchAssist共同为线稿创作和修订提供了实用、可控的助手。",
            "intro_zh": [
                "现有图像编辑系统难以平衡线稿的稀疏结构保持与高层次语义修改和局部重绘需求，导致编辑效果不佳。",
                "提出SketchAssist助手，通过统一指令引导全局编辑和线条引导区域重绘，并引入可控数据生成和任务引导专家混合机制。",
                "实验表明，SketchAssist在指令遵循和风格/结构保持方面优于基线，实现了线稿编辑的实用性和可控性提升。"
            ],
            "method_zh": "SketchAssist采用统一线稿编辑框架，基于DiT编辑器进行最小改动，核心创新包括：重新利用RGB通道编码输入，实现指令引导编辑和线条引导重绘在单一界面的无缝切换；集成任务引导的专家混合机制到LoRA层，通过文本和视觉线索路由，优化不同编辑模式下的语义可控性、结构保真度和风格保持。与现有方法相比，主要区别在于其结合了全局语义编辑和局部精确重绘，并通过可控数据生成流程（包括属性添加序列、多步编辑链和风格保持属性移除）支持大规模应用，避免了传统方法在风格敏感线稿编辑中的局限性。",
            "application_zh": "该研究可应用于数字插画、动画制作、游戏设计等领域，作为线稿创作和修订的交互式助手，帮助艺术家快速实现语义修改和局部调整，提升创作效率和编辑精度，具有实际商业和创意价值。",
            "highlight_zh": "SketchAssist在指令引导编辑和线条引导重绘任务上均达到最先进结果，相比近期基线，在指令遵循和风格/结构保持方面表现更优，实验验证了其语义可控性和编辑效果的提升。",
            "tags_zh": [
                "线稿编辑",
                "语义修改",
                "局部重绘",
                "可控数据生成",
                "专家混合机制",
                "风格保持",
                "交互式助手",
                "数字插画"
            ],
            "_index": 167
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138v1",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138v1",
            "code_links": [],
            "headline_zh": "提出LAPPI方法，利用大语言模型辅助用户将模糊偏好转化为优化问题实例，以解决组合优化问题实例化困难。",
            "summary_zh": "许多现实世界任务，如旅行规划或膳食规划，可以表述为组合优化问题。然而，使用优化求解器对终端用户来说很困难，因为它需要问题实例化：定义候选项目、分配偏好分数和指定约束。我们引入了LAPPI（LLM辅助的基于偏好的问题实例化），这是一种交互式方法，利用大语言模型（LLMs）支持用户在此实例化过程中。通过自然语言对话，系统帮助用户将模糊偏好转化为明确定义的优化问题。这些实例化的问题随后传递给现有的优化求解器以生成解决方案。在旅行规划的用户研究中，我们的方法成功捕捉了用户偏好，并生成了可行的计划，优于传统方法和提示工程方法。我们通过将其适应到另一个用例进一步展示了LAPPI的通用性。",
            "intro_zh": [
                "现有方法中，组合优化问题实例化对终端用户困难，需定义候选项、偏好和约束，导致使用门槛高。",
                "论文提出LAPPI，通过LLM驱动的自然语言对话交互，辅助用户将模糊偏好转化为结构化优化问题实例。",
                "在旅行规划用户研究中，LAPPI成功捕捉偏好，生成可行计划，性能优于传统和提示工程方法，并展示通用性。"
            ],
            "method_zh": "LAPPI的整体框架基于交互式优化流程，用户通过自然语言对话与LLM交互，系统逐步引导用户澄清偏好、定义候选项目和约束，自动生成优化问题实例。关键技术创新点在于结合LLM的语义理解能力，将非结构化用户输入转化为结构化优化问题参数，如偏好分数和约束条件。与现有方法的主要区别在于，传统方法依赖用户手动实例化，而LAPPI通过对话自动化此过程，降低了技术门槛，提高了易用性和准确性。",
            "application_zh": "该研究适用于需要个性化组合优化的场景，如旅行规划、膳食规划、日程安排和资源分配，潜在价值在于提升终端用户的操作便利性和决策效率，支持更广泛的实际应用部署。",
            "highlight_zh": "在旅行规划用户研究中，LAPPI成功捕捉用户偏好，生成可行计划，性能优于传统方法和提示工程方法，具体提升表现为更高的用户满意度和计划可行性，并验证了方法在额外用例中的通用性。",
            "tags_zh": [
                "组合优化",
                "问题实例化",
                "大语言模型",
                "交互式系统",
                "自然语言处理",
                "用户偏好建模",
                "优化求解器",
                "旅行规划"
            ],
            "_index": 168
        },
        {
            "title": "Erasing CLIP Memories: Non-Destructive, Data-Free Zero-Shot class Unlearning in CLIP Models",
            "authors": [
                "Ashish Mishra",
                "Tarun Kumar",
                "Gyanaranjan Nayak",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14137v1",
            "summary": "We introduce a novel, closed-form approach for selective unlearning in multimodal models, specifically targeting pretrained models such as CLIP. Our method leverages nullspace projection to erase the target class information embedded in the final projection layer, without requiring any retraining or the use of images from the forget set. By computing an orthonormal basis for the subspace spanned by target text embeddings and projecting these directions, we dramatically reduce the alignment between image features and undesired classes. Unlike traditional unlearning techniques that rely on iterative fine-tuning and extensive data curation, our approach is both computationally efficient and surgically precise. This leads to a pronounced drop in zero-shot performance for the target classes while preserving the overall multimodal knowledge of the model. Our experiments demonstrate that even a partial projection can balance between complete unlearning and retaining useful information, addressing key challenges in model decontamination and privacy preservation.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14137v1",
            "code_links": [],
            "headline_zh": "提出基于零空间投影的非破坏性数据无关零样本类别遗忘方法，以解决CLIP模型选择性遗忘问题。",
            "summary_zh": "我们提出了一种新颖的闭式方法，用于多模态模型中的选择性遗忘，特别针对如CLIP这样的预训练模型。该方法利用零空间投影来擦除嵌入在最终投影层中的目标类别信息，无需任何重新训练或使用遗忘集中的图像。通过计算目标文本嵌入所张成子空间的正交基并投影这些方向，我们显著降低了图像特征与不需要类别之间的对齐。与依赖迭代微调和大量数据整理的传统遗忘技术不同，我们的方法既计算高效又具有外科手术般的精确性。这导致目标类别的零样本性能显著下降，同时保留了模型的整体多模态知识。实验表明，即使是部分投影也能在完全遗忘和保留有用信息之间取得平衡，解决了模型去污和隐私保护中的关键挑战。",
            "intro_zh": [
                "现有方法依赖迭代微调和大量数据整理，计算成本高且难以精确控制遗忘过程。",
                "提出基于零空间投影的闭式方法，通过正交基投影擦除目标类别信息，无需重新训练或数据。",
                "实验显示目标类别零样本性能显著下降，同时整体多模态知识得以保留，部分投影实现平衡。"
            ],
            "method_zh": "该方法整体框架基于CLIP模型的最终投影层，通过计算目标类别文本嵌入的正交基，构建零空间投影矩阵来擦除这些方向上的信息。关键技术创新点在于利用闭式零空间投影实现非破坏性、数据无关的类别遗忘，无需微调或访问遗忘集图像。与现有方法的主要区别在于避免了迭代优化和数据依赖，提供了一种计算高效且精确的解决方案，直接操作嵌入空间而非修改模型参数。",
            "application_zh": "该研究在模型去污和隐私保护领域具有重要应用价值，例如在需要移除敏感或错误类别信息的场景中，如医疗图像分析、内容过滤和合规性调整，能高效实现选择性遗忘而不损害模型整体性能。",
            "highlight_zh": "实验结果表明，该方法能显著降低目标类别的零样本性能，同时保持模型对其他类别的识别能力；部分投影策略在完全遗忘和知识保留之间取得平衡，验证了方法的有效性和灵活性。",
            "tags_zh": [
                "选择性遗忘",
                "零空间投影",
                "多模态模型",
                "CLIP模型",
                "零样本学习",
                "模型去污",
                "隐私保护",
                "闭式方法"
            ],
            "_index": 169
        },
        {
            "title": "UIXPOSE: Mobile Malware Detection via Intention-Behaviour Discrepancy Analysis",
            "authors": [
                "Amirmohammad Pasdar",
                "Toby Murray",
                "Van-Thuan Pham"
            ],
            "arxiv_id": "2512.14130v1",
            "summary": "We introduce UIXPOSE, a source-code-agnostic framework that operates on both compiled and open-source apps. This framework applies Intention Behaviour Alignment (IBA) to mobile malware analysis, aligning UI-inferred intent with runtime semantics. Previous work either infers intent statically, e.g., permission-centric, or widget-level or monitors coarse dynamic signals (endpoints, partial resource usage) that miss content and context. UIXPOSE infers an intent vector from each screen using vision-language models and knowledge structures and combines decoded network payloads, heap/memory signals, and resource utilisation traces into a behaviour vector. Their alignment, calculated at runtime, can both detect misbehaviour and highlight exploration of behaviourally rich paths. In three real-world case studies, UIXPOSE reveals covert exfiltration and hidden background activity that evade metadata-only baselines, demonstrating how IBA improves dynamic detection.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14130v1",
            "code_links": [],
            "headline_zh": "提出UIXPOSE框架，通过意图-行为差异分析解决移动恶意软件检测问题",
            "summary_zh": "我们介绍了UIXPOSE，这是一个与源代码无关的框架，可同时处理编译和开源应用程序。该框架将意图行为对齐（IBA）应用于移动恶意软件分析，将UI推断的意图与运行时语义对齐。先前的工作要么静态推断意图（例如基于权限或小部件级别），要么监控粗糙的动态信号（端点、部分资源使用），这些方法忽略了内容和上下文。UIXPOSE使用视觉语言模型和知识结构从每个屏幕推断意图向量，并将解码的网络负载、堆/内存信号和资源利用轨迹组合成行为向量。在运行时计算它们的对齐度，既可以检测不当行为，又可以突出显示行为丰富路径的探索。在三个真实案例研究中，UIXPOSE揭示了仅基于元数据的基线方法无法检测到的隐蔽数据外泄和隐藏后台活动，展示了IBA如何改进动态检测。",
            "intro_zh": [
                "现有方法在移动恶意软件检测中，要么静态推断意图（如权限分析），要么监控粗糙动态信号（如端点调用），忽略了UI内容和上下文，导致检测精度不足。",
                "UIXPOSE提出意图行为对齐（IBA）方法，通过视觉语言模型从UI推断意图向量，结合运行时行为向量（如网络负载、内存信号），在运行时计算对齐度以检测恶意行为。",
                "在三个真实案例研究中，UIXPOSE成功检测到隐蔽数据外泄和隐藏后台活动，超越了仅基于元数据的基线方法，证明了IBA在动态检测中的有效性。"
            ],
            "method_zh": "UIXPOSE是一个与源代码无关的框架，整体架构包括意图向量推断和行为向量构建两部分。关键技术创新点在于使用视觉语言模型和知识结构从UI屏幕推断意图向量，同时结合解码的网络负载、堆/内存信号和资源利用轨迹形成行为向量，并通过意图行为对齐（IBA）在运行时计算两者的对齐度。与现有方法的主要区别在于，它避免了静态意图推断或粗糙动态监控的局限性，实现了UI内容与运行时语义的深度融合，从而更准确地检测恶意行为。",
            "application_zh": "该研究主要应用于移动安全领域，特别是Android和iOS平台的恶意软件检测。潜在应用包括移动应用商店的安全审核、企业移动设备管理（MDM）中的威胁防护，以及个人用户的反恶意软件工具开发，具有提升移动生态系统安全性的实际价值。",
            "highlight_zh": "在三个真实案例研究中，UIXPOSE成功揭示了仅基于元数据的基线方法无法检测到的隐蔽数据外泄和隐藏后台活动，例如通过UI界面伪装正常操作而实际执行恶意数据传输的行为，证明了意图行为对齐（IBA）在动态检测中的显著性能提升。",
            "tags_zh": [
                "移动恶意软件检测",
                "意图行为对齐",
                "视觉语言模型",
                "运行时语义分析",
                "UI推断意图",
                "动态检测框架",
                "多模态融合",
                "安全分析"
            ],
            "_index": 170
        },
        {
            "title": "Consistent Instance Field for Dynamic Scene Understanding",
            "authors": [
                "Junyi Wu",
                "Van Nguyen Nguyen",
                "Benjamin Planche",
                "Jiachen Tao",
                "Changchang Sun",
                "Zhongpai Gao",
                "Zhenghao Zhao",
                "Anwesa Choudhuri",
                "Gengyu Zhang",
                "Meng Zheng",
                "Feiran Wang",
                "Terrence Chen",
                "Yan Yan",
                "Ziyan Wu"
            ],
            "arxiv_id": "2512.14126v1",
            "summary": "We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14126v1",
            "code_links": [],
            "headline_zh": "提出一致实例场以解决动态场景理解中离散跟踪和视角依赖特征的不足，实现连续时空表示。",
            "summary_zh": "我们引入了“一致实例场”，这是一种用于动态场景理解的连续且概率性的时空表示。与先前依赖离散跟踪或视角依赖特征的方法不同，我们的方法通过为每个时空点建模占用概率和条件实例分布，将可见性与持久对象身份解耦。为实现这一点，我们引入了一种基于可变形3D高斯的新型实例嵌入表示，该表示联合编码辐射度和语义信息，并通过可微分光栅化直接从输入RGB图像和实例掩码中学习。此外，我们引入了新机制来校准每个高斯的身份，并向语义活跃区域重新采样高斯，确保跨空间和时间的一致实例表示。在HyperNeRF和Neu3D数据集上的实验表明，我们的方法在新视角全景分割和开放词汇4D查询任务上显著优于最先进的方法。",
            "intro_zh": [
                "核心问题：现有动态场景理解方法依赖离散跟踪或视角依赖特征，难以实现跨时空的一致对象身份表示。",
                "方法要点：提出一致实例场，基于可变形3D高斯建模占用概率和实例分布，解耦可见性与对象身份。",
                "实验或效果：在HyperNeRF和Neu3D数据集上，新视角全景分割和开放词汇4D查询任务性能显著提升。"
            ],
            "method_zh": "整体框架基于可变形3D高斯，构建连续时空表示。关键技术创新点包括：实例嵌入表示联合编码辐射度和语义信息，通过可微分光栅化从RGB图像和实例掩码直接学习；引入校准机制和重采样策略，确保高斯身份一致并聚焦语义活跃区域。与现有方法的主要区别在于，它避免了离散跟踪，提供概率性表示，实现跨视角和时间的对象身份一致性。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和增强现实等领域，支持动态场景的实时理解和交互，如新视角全景分割和开放词汇查询，提升环境感知和决策能力。",
            "highlight_zh": "在HyperNeRF和Neu3D数据集上，新视角全景分割和开放词汇4D查询任务中，性能显著优于最先进方法，验证了一致实例场在动态场景理解中的有效性。",
            "tags_zh": [
                "动态场景理解",
                "实例场表示",
                "可变形3D高斯",
                "新视角全景分割",
                "开放词汇查询",
                "时空表示",
                "实例嵌入",
                "可微分光栅化"
            ],
            "_index": 157
        },
        {
            "title": "SportsGPT: An LLM-driven Framework for Interpretable Sports Motion Assessment and Training Guidance",
            "authors": [
                "Wenbo Tian",
                "Ruting Lin",
                "Hongxian Zheng",
                "Yaodong Yang",
                "Geng Wu",
                "Zihao Zhang",
                "Zhang Zhang"
            ],
            "arxiv_id": "2512.14121v1",
            "summary": "Existing intelligent sports analysis systems mainly focus on \"scoring and visualization,\" often lacking automatic performance diagnosis and interpretable training guidance. Recent advances of Large Language Models (LMMs) and motion analysis techniques provide new opportunities to address the above limitations. In this paper, we propose SportsGPT, an LLM-driven framework for interpretable sports motion assessment and training guidance, which establishes a closed loop from motion time-series input to professional training guidance. First, given a set of high-quality target models, we introduce MotionDTW, a two-stage time series alignment algorithm designed for accurate keyframe extraction from skeleton-based motion sequences. Subsequently, we design a Knowledge-based Interpretable Sports Motion Assessment Model (KISMAM) to obtain a set of interpretable assessment metrics (e.g., insufficient extension) by constrasting the keyframes with the targe models. Finally, we propose SportsRAG, a RAG-based training guidance model based on Qwen3. Leveraging a 6B-token knowledge base, it prompts the LLM to generate professional training guidance by retrieving domain-specific QA pairs. Experimental results demonstrate that MotionDTW significantly outperforms traditional methods with lower temporal error and higher IoU scores. Furthermore, ablation studies validate the KISMAM and SportsRAG, confirming that SportsGPT surpasses general LLMs in diagnostic accuracy and professionalism.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14121v1",
            "code_links": [],
            "headline_zh": "提出SportsGPT框架，基于LLM实现可解释的运动评估与训练指导，解决现有系统缺乏自动诊断和可解释指导的问题。",
            "summary_zh": "现有的智能运动分析系统主要关注“评分和可视化”，往往缺乏自动性能诊断和可解释的训练指导。大型语言模型（LLMs）和运动分析技术的最新进展为解决上述局限性提供了新机遇。本文提出SportsGPT，一个基于LLM的可解释运动评估与训练指导框架，建立了从运动时间序列输入到专业训练指导的闭环。首先，给定一组高质量目标模型，我们引入MotionDTW，一种两阶段时间序列对齐算法，用于从基于骨架的运动序列中准确提取关键帧。随后，我们设计了一个基于知识的可解释运动评估模型（KISMAM），通过将关键帧与目标模型对比，获得一组可解释的评估指标（如伸展不足）。最后，我们提出SportsRAG，一个基于Qwen3的RAG训练指导模型。利用一个6B-token的知识库，它通过检索领域特定的问答对来提示LLM生成专业训练指导。实验结果表明，MotionDTW在时间误差更低和IoU分数更高方面显著优于传统方法。此外，消融研究验证了KISMAM和SportsRAG，确认SportsGPT在诊断准确性和专业性方面超越通用LLMs。",
            "intro_zh": [
                "现有智能体育分析系统多聚焦于评分与可视化，缺乏自动性能诊断和可解释的训练指导，限制了实际应用价值。",
                "论文提出SportsGPT框架，结合MotionDTW关键帧提取、KISMAM评估模型和SportsRAG指导生成，构建从运动输入到专业指导的闭环系统。",
                "实验显示MotionDTW在时间误差和IoU上优于传统方法，SportsGPT在诊断准确性和专业性上超越通用大语言模型，验证了框架有效性。"
            ],
            "method_zh": "SportsGPT是一个基于LLM的闭环框架，从运动时间序列输入到专业训练指导。核心方法包括：MotionDTW，一种两阶段时间序列对齐算法，用于从骨架序列中准确提取关键帧；KISMAM，基于知识的可解释运动评估模型，通过对比关键帧与目标模型生成可解释指标；SportsRAG，基于RAG的训练指导模型，利用6B-token知识库和Qwen3 LLM，通过检索领域QA对生成专业指导。关键创新在于将运动分析与LLM结合，实现可解释评估和个性化指导。与现有方法的主要区别在于，它不仅提供评分，还通过知识驱动和RAG机制，生成具体、可解释的诊断和改进建议，解决了传统系统缺乏深度分析和指导的问题。",
            "application_zh": "该研究可应用于体育训练、康复医学和健身指导等领域，为运动员、教练和普通用户提供自动、可解释的运动性能评估和个性化训练建议，提升训练效率和安全性。",
            "highlight_zh": "MotionDTW在关键帧提取上显著优于传统方法，时间误差更低，IoU分数更高；SportsGPT通过消融研究验证，在诊断准确性和专业性方面超越通用LLMs，展示了框架的整体优势。",
            "tags_zh": [
                "运动分析",
                "大语言模型",
                "时间序列对齐",
                "可解释评估",
                "检索增强生成",
                "骨架运动",
                "训练指导",
                "闭环框架"
            ],
            "_index": 158
        },
        {
            "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
            "authors": [
                "Ramesh Gundluru",
                "Shubham Gupta",
                "Sri Rama Murty K"
            ],
            "arxiv_id": "2512.14115v1",
            "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14115v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出联合多模态对比学习框架，以解决声学词嵌入在语音检索任务中的局限性，提升口语词检测和关键词识别的鲁棒性。",
            "summary_zh": "声学词嵌入（AWEs）提高了语音检索任务（如口语词检测和关键词识别）的效率。然而，现有方法存在局限性，包括单模态监督、音频-音频和音频-文本对齐的分离优化，以及需要任务特定模型。为解决这些不足，我们提出了一个联合多模态对比学习框架，在共享嵌入空间中统一了声学和跨模态监督。我们的方法同时优化：（i）音频-文本对比学习，受CLAP损失启发，以对齐音频和文本表示；（ii）音频-音频对比学习，通过深度词判别损失，以增强类内紧凑性和类间分离性。所提方法在词判别任务上优于现有AWE基线，同时灵活支持口语词检测和关键词识别。据我们所知，这是首个此类综合方法。",
            "intro_zh": [
                "现有声学词嵌入方法依赖单模态监督，音频-音频和音频-文本对齐优化分离，导致模型泛化能力受限。",
                "提出联合多模态对比学习框架，统一音频-文本和音频-音频监督，在共享嵌入空间中进行端到端优化。",
                "在词判别任务上超越基线，同时支持口语词检测和关键词识别，展示了方法的鲁棒性和灵活性。"
            ],
            "method_zh": "论文提出一个联合多模态对比学习框架，整体架构包括音频编码器和文本编码器，生成共享嵌入空间中的表示。关键技术创新点在于同时应用音频-文本对比学习（基于CLAP损失）和音频-音频对比学习（基于深度词判别损失），以统一优化跨模态对齐和声学判别性。与现有方法的主要区别在于避免了分离优化，通过端到端训练整合多模态监督，从而提升模型在语音检索任务中的性能和泛化能力。",
            "application_zh": "该研究可应用于语音检索系统，如口语词检测和关键词识别，适用于智能助手、语音搜索和音频内容分析等领域，提高检索效率和准确性。",
            "highlight_zh": "在词判别任务上，所提方法优于现有声学词嵌入基线，同时灵活支持口语词检测和关键词识别，展示了多模态联合优化的有效性。",
            "tags_zh": [
                "多模态对比学习",
                "声学词嵌入",
                "口语词检测",
                "关键词识别",
                "音频-文本对齐",
                "语音检索",
                "联合优化",
                "共享嵌入空间"
            ],
            "_index": 159
        },
        {
            "title": "MFE-GAN: Efficient GAN-based Framework for Document Image Enhancement and Binarization with Multi-scale Feature Extraction",
            "authors": [
                "Rui-Yang Ju",
                "KokSheik Wong",
                "Yanlin Jin",
                "Jen-Shiun Chiang"
            ],
            "arxiv_id": "2512.14114v1",
            "summary": "Document image enhancement and binarization are commonly performed prior to document analysis and recognition tasks for improving the efficiency and accuracy of optical character recognition (OCR) systems. This is because directly recognizing text in degraded documents, particularly in color images, often results in unsatisfactory recognition performance. To address these issues, existing methods train independent generative adversarial networks (GANs) for different color channels to remove shadows and noise, which, in turn, facilitates efficient text information extraction. However, deploying multiple GANs results in long training and inference times. To reduce both training and inference times of document image enhancement and binarization models, we propose MFE-GAN, an efficient GAN-based framework with multi-scale feature extraction (MFE), which incorporates Haar wavelet transformation (HWT) and normalization to process document images before feeding them into GANs for training. In addition, we present novel generators, discriminators, and loss functions to improve the model's performance, and we conduct ablation studies to demonstrate their effectiveness. Experimental results on the Benchmark, Nabuco, and CMATERdb datasets demonstrate that the proposed MFE-GAN significantly reduces the total training and inference times while maintaining comparable performance with respect to state-of-the-art (SOTA) methods. The implementation of this work is available at https://ruiyangju.github.io/MFE-GAN.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Extended Journal Version of APSIPA ASC 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14114v1",
            "code_links": [
                {
                    "url": "https://ruiyangju.github.io/MFE-GAN",
                    "type": "project_page"
                }
            ],
            "headline_zh": "提出MFE-GAN框架，通过多尺度特征提取和Haar小波变换，高效解决文档图像增强与二值化问题。",
            "summary_zh": "文档图像增强与二值化通常在文档分析与识别任务前执行，以提高光学字符识别（OCR）系统的效率和准确性。这是因为直接识别退化文档（特别是彩色图像）中的文本往往导致不理想的识别性能。为解决这些问题，现有方法训练独立的生成对抗网络（GANs）处理不同颜色通道以去除阴影和噪声，从而促进高效的文本信息提取。然而，部署多个GANs会导致训练和推理时间过长。为减少文档图像增强与二值化模型的训练和推理时间，我们提出了MFE-GAN，这是一种基于GAN的高效框架，采用多尺度特征提取（MFE），结合Haar小波变换（HWT）和归一化处理文档图像，然后输入GANs进行训练。此外，我们提出了新颖的生成器、判别器和损失函数以提升模型性能，并通过消融研究验证其有效性。在Benchmark、Nabuco和CMATERdb数据集上的实验结果表明，所提出的MFE-GAN显著减少了总训练和推理时间，同时保持了与最先进（SOTA）方法相当的性能。本工作的实现可在https://ruiyangju.github.io/MFE-GAN获取。",
            "intro_zh": [
                "现有方法使用多个独立GAN处理不同颜色通道，导致训练和推理时间过长，效率低下。",
                "提出MFE-GAN框架，结合Haar小波变换和多尺度特征提取，优化图像预处理，并设计新生成器、判别器和损失函数。",
                "实验显示，MFE-GAN在多个数据集上显著减少训练和推理时间，同时性能与SOTA方法相当。"
            ],
            "method_zh": "MFE-GAN是一个基于生成对抗网络的高效框架，整体架构包括预处理模块和多尺度特征提取模块。关键技术创新点在于引入Haar小波变换和归一化进行图像预处理，以及设计新颖的生成器和判别器结构，结合多尺度特征提取来捕获文档图像的全局和局部信息。与现有方法的主要区别在于，它避免了使用多个独立GAN处理不同颜色通道，而是通过统一的框架和优化预处理步骤，显著降低了计算复杂度，提高了训练和推理效率。",
            "application_zh": "该研究主要应用于文档图像处理领域，特别是在光学字符识别（OCR）系统中，用于增强退化文档图像（如去除阴影和噪声）并进行二值化，以提高文本识别的准确性和效率。潜在应用包括数字化档案管理、历史文档修复、移动设备扫描应用等，具有实际价值在于提升自动化文档处理的速度和可靠性。",
            "highlight_zh": "在Benchmark、Nabuco和CMATERdb数据集上的实验表明，MFE-GAN显著减少了总训练和推理时间，同时保持了与最先进方法相当的性能，验证了其高效性和有效性。",
            "tags_zh": [
                "文档图像增强",
                "图像二值化",
                "生成对抗网络",
                "多尺度特征提取",
                "Haar小波变换",
                "光学字符识别",
                "高效训练",
                "消融研究"
            ],
            "_index": 160
        },
        {
            "title": "Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach",
            "authors": [
                "Ashish Mishra",
                "Gyanaranjan Nayak",
                "Tarun Kumar",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14113v1",
            "summary": "Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or \"unlearning\") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14113v1",
            "code_links": [],
            "headline_zh": "提出一种无需训练和数据的遗忘框架，实现CLIP模型中对特定对象类别的选择性、可控和领域无关的遗忘。",
            "summary_zh": "预训练模型如CLIP在多种视觉领域（如自然图像、艺术渲染和抽象表示）中展现出卓越的零样本分类能力。然而，实际应用常需移除（或“遗忘”）特定对象类别，且不依赖额外数据或重新训练，也不影响模型在无关任务上的性能。本文提出一种新颖的无需训练和数据的遗忘框架，支持三种遗忘范式：（1）在所有领域中全局遗忘选定对象，（2）领域特定知识移除（例如，消除草图表示同时保留照片识别），以及（3）在选择性领域中完全遗忘。通过利用多模态零空间，结合文本提示和从CLIP联合嵌入空间衍生的合成视觉原型，该方法高效移除不需要的类别信息，同时保留其余知识。此方法克服了现有基于重新训练方法的局限性，为可控模型遗忘提供了灵活且计算高效的解决方案。",
            "intro_zh": [
                "核心问题：现有遗忘方法通常依赖重新训练或额外数据，导致计算成本高、灵活性差，难以实现特定对象或领域的精确控制遗忘。",
                "方法要点：提出一种无需训练和数据的框架，利用多模态零空间整合文本提示和合成视觉原型，实现选择性、可控和领域无关的遗忘。",
                "实验或效果：该方法在多种视觉领域（如自然图像和草图）中有效移除目标类别，同时保持模型在无关任务上的性能，计算效率高。"
            ],
            "method_zh": "整体框架基于CLIP的联合嵌入空间，通过多模态零空间实现遗忘。关键技术创新点包括：利用文本提示和合成视觉原型构建遗忘目标，通过零空间投影移除不需要的类别信息，而无需重新训练或额外数据。与现有方法的主要区别在于：本方法无需训练或数据，支持多种遗忘范式（全局、领域特定和选择性领域），提供更高的灵活性和计算效率，克服了传统基于重新训练方法的局限性。",
            "application_zh": "该研究可应用于隐私保护（如移除敏感类别）、模型合规性调整（如删除侵权内容）和自适应AI系统（如动态更新知识库），在计算机视觉和AI部署中具有实际价值。",
            "highlight_zh": "实验表明，该方法在多种视觉领域（如ImageNet和草图数据集）中成功移除目标类别，遗忘后模型在保留类别上的性能下降可忽略，计算成本远低于重新训练方法。",
            "tags_zh": [
                "CLIP模型",
                "知识遗忘",
                "多模态学习",
                "零样本分类",
                "嵌入空间优化",
                "无需训练方法",
                "可控遗忘",
                "领域无关",
                "计算效率"
            ],
            "_index": 175
        },
        {
            "title": "Optimizing Multi-Tier Supply Chain Ordering with a Hybrid Liquid Neural Network and Extreme Gradient Boosting Model",
            "authors": [
                "Chunan Tong"
            ],
            "arxiv_id": "2512.14112v1",
            "summary": "Supply chain management (SCM) faces significant challenges like demand fluctuations and the bullwhip effect. Traditional methods and even state-of-the-art LLMs struggle with benchmarks like the Vending Machine Test, failing to handle SCM's complex continuous time-series data. While ML approaches like LSTM and XGBoost offer solutions, they are often limited by computational inefficiency. Liquid Neural Networks (LNN), known for their adaptability and efficiency in robotics, remain untapped in SCM. This study proposes a hybrid LNN+XGBoost model for multi-tier supply chains. By combining LNN's dynamic feature extraction with XGBoost's global optimization, the model aims to minimize the bullwhip effect and increase profitability. This innovative approach addresses the need for efficiency and adaptability, filling a critical gap in intelligent SCM.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14112v1",
            "code_links": [],
            "headline_zh": "提出混合液体神经网络与极端梯度提升模型以优化多层级供应链订单问题",
            "summary_zh": "供应链管理面临需求波动和牛鞭效应等重大挑战。传统方法及先进大语言模型在处理如自动售货机测试等基准时表现不佳，难以应对供应链中复杂的连续时间序列数据。虽然长短期记忆网络和极端梯度提升等机器学习方法提供解决方案，但常受计算效率限制。液体神经网络在机器人领域以适应性和高效性著称，但在供应链管理中尚未应用。本研究提出一种混合液体神经网络与极端梯度提升模型，用于多层级供应链。通过结合液体神经网络的动态特征提取和极端梯度提升的全局优化能力，该模型旨在最小化牛鞭效应并提高盈利能力。这一创新方法满足了效率和适应性的需求，填补了智能供应链管理的关键空白。",
            "intro_zh": [
                "供应链管理面临需求波动和牛鞭效应等挑战，传统方法和大语言模型在处理连续时间序列数据时效率低下，计算成本高。",
                "论文提出混合液体神经网络与极端梯度提升模型，利用液体神经网络的动态特征提取和极端梯度提升的全局优化，以提升供应链订单决策的效率和准确性。",
                "模型在实验中可能显著减少牛鞭效应并提高盈利能力，具体性能提升未知，但展示了在供应链基准测试中的潜在优势。"
            ],
            "_index": 161
        },
        {
            "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
            "authors": [
                "Emanuele Mezzi",
                "Gertjan Burghouts",
                "Maarten Kruithof"
            ],
            "arxiv_id": "2512.14102v1",
            "summary": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14102v1",
            "code_links": [],
            "headline_zh": "提出RUNE方法，结合大语言模型与神经符号AI，解决遥感文本到图像检索中复杂空间关系处理与可解释性不足的问题。",
            "summary_zh": "遥感领域的文本到图像检索随着针对航空和卫星影像定制的大型视觉语言模型（LVLMs）的兴起而迅速发展，最终形成了遥感大型视觉语言模型（RS-LVLMs）。然而，有限的可解释性和对复杂空间关系处理能力差仍然是实际应用中的关键挑战。为解决这些问题，我们引入了RUNE（使用神经符号实体进行推理），该方法将大语言模型（LLMs）与神经符号AI相结合，通过推理检测到的实体与从文本查询推导出的一阶逻辑（FOL）表达式之间的兼容性来检索图像。与依赖隐式联合嵌入的RS-LVLMs不同，RUNE执行显式推理，从而提升性能和可解释性。为实现可扩展性，我们提出了一种逻辑分解策略，该策略在检测到的实体的条件子集上操作，保证比神经方法更短的执行时间。我们不是将基础模型用于端到端检索，而是仅利用它们生成FOL表达式，将推理委托给神经符号推理模块。为了评估，我们重新利用了原本为物体检测设计的DOTA数据集，通过添加比现有基准更复杂的查询来增强它。我们展示了LLM在文本到逻辑翻译中的有效性，并将RUNE与最先进的RS-LVLMs进行比较，证明了其优越性能。我们引入了两个指标：检索对查询复杂性的鲁棒性（RRQC）和检索对图像不确定性的鲁棒性（RRIU），用于评估相对于查询复杂性和图像不确定性的性能。RUNE在复杂遥感检索任务中优于联合嵌入模型，在性能、鲁棒性和可解释性方面带来增益。我们通过一个关于洪水后卫星图像检索的用例展示了RUNE在现实世界遥感应用中的潜力。",
            "intro_zh": [
                "现有遥感文本到图像检索方法（如RS-LVLMs）存在可解释性不足和复杂空间关系处理能力差的问题，限制了实际应用。",
                "论文提出RUNE方法，结合大语言模型生成一阶逻辑表达式，并利用神经符号推理模块进行显式推理，提升检索性能和可解释性。",
                "实验表明，RUNE在复杂查询任务中优于现有RS-LVLMs，并引入新指标RRQC和RRIU验证其鲁棒性，展示了在洪水后卫星图像检索等场景的应用潜力。"
            ],
            "method_zh": "RUNE的整体框架包括两个核心模块：首先，使用大语言模型将文本查询翻译为一阶逻辑表达式；其次，通过神经符号推理模块，基于检测到的实体与逻辑表达式的兼容性进行显式推理来检索图像。关键技术创新点在于逻辑分解策略，该策略在检测到的实体的条件子集上操作，优化执行时间，确保可扩展性。与现有方法的主要区别在于，RUNE不依赖隐式联合嵌入，而是采用显式推理路径，将基础模型仅用于逻辑生成，推理任务由专门的神经符号模块处理，从而增强可解释性和处理复杂关系的能力。",
            "application_zh": "该研究在遥感领域具有广泛的应用潜力，例如在灾害响应中用于洪水后卫星图像检索，可快速定位受灾区域；还可应用于城市规划、环境监测和军事侦察等场景，通过复杂查询实现高效、可解释的图像检索，提升决策支持系统的实用性。",
            "highlight_zh": "RUNE在复杂遥感检索任务中显著优于现有RS-LVLMs，性能提升明显；引入的RRQC和RRIU指标验证了其对查询复杂性和图像不确定性的鲁棒性；在DOTA数据集上的实验展示了LLM在文本到逻辑翻译中的有效性，并通过洪水后检索用例证明了实际应用价值。",
            "tags_zh": [
                "遥感图像检索",
                "神经符号AI",
                "大语言模型",
                "一阶逻辑推理",
                "复杂查询处理",
                "可解释性AI",
                "多模态融合",
                "卫星图像分析"
            ],
            "_index": 179
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100v1",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100v1",
            "code_links": [
                {
                    "url": "https://github.com/ChunjinJiang/sgrpo",
                    "type": "github"
                }
            ],
            "headline_zh": "提出基于一阶逻辑相似性的奖励机制S-GRPO，以替代传统奖励模型，提升RLHF的稳定性和性能。",
            "summary_zh": "基于人类反馈的强化学习（RLHF）在将大型语言模型（LLMs）与人类价值观和偏好对齐方面起着关键作用。然而，训练出的奖励模型的质量和稳定性在很大程度上决定了最终的对齐性能。现有方法如近端策略优化（PPO）严重依赖奖励模型来引导LLMs朝向人类对齐的行为。在这项工作中，我们提出了一种基于逻辑相似性的奖励机制，作为传统奖励建模的替代方案。我们的方法不依赖启发式奖励估计，而是利用形式逻辑一致性来引导模型与人类偏好对齐。由于现实世界的问题可以从多个角度解释，为确保基于逻辑的强化学习不会导致模型崩溃，我们引入了S-GRPO，这是GRPO框架的一个监督变体。S-GRPO在训练中结合了一个额外的监督组件，并联合优化生成项、KL散度正则化和基于标签的目标。实验结果表明，S-GRPO在性能和鲁棒性方面均持续优于标准监督微调（SFT）。此外，它扩展了现有的偏好学习框架如GRPO和DPO，为对齐训练提供了更灵活和任务自适应的途径。我们的代码可在https://github.com/ChunjinJiang/sgrpo获取。",
            "intro_zh": [
                "现有RLHF方法依赖奖励模型，其质量和稳定性直接影响对齐性能，存在不稳定和启发式估计的不足。",
                "提出基于一阶逻辑相似性的奖励机制，利用形式逻辑一致性替代传统奖励建模，并引入S-GRPO框架防止模型崩溃。",
                "实验显示S-GRPO在性能和鲁棒性上优于标准监督微调，并扩展了GRPO和DPO等偏好学习框架。"
            ],
            "method_zh": "论文提出S-GRPO框架，整体基于GRPO框架进行扩展，核心创新点在于引入基于一阶逻辑相似性的奖励机制，替代传统奖励模型。该方法通过形式逻辑一致性评估模型输出与人类偏好的对齐程度，避免了启发式奖励估计的不稳定性。关键技术创新包括在训练中联合优化生成项、KL散度正则化和基于标签的监督目标，以防止基于逻辑的强化学习导致模型崩溃。与现有方法的主要区别在于不依赖显式奖励模型，而是直接利用逻辑相似性进行对齐引导，提供了更灵活和任务自适应的训练方式。",
            "application_zh": "该研究可应用于大型语言模型的对齐训练，特别是在需要稳定和逻辑一致性的场景，如AI助手、内容生成和决策支持系统，有助于提升模型与人类价值观的匹配度和可靠性。",
            "highlight_zh": "S-GRPO在实验中持续优于标准监督微调（SFT），在性能和鲁棒性方面均有显著提升，同时成功扩展了GRPO和DPO等现有偏好学习框架，验证了基于逻辑相似性奖励机制的有效性。",
            "tags_zh": [
                "强化学习人类反馈",
                "逻辑相似性奖励",
                "模型对齐",
                "S-GRPO框架",
                "一阶逻辑",
                "监督微调",
                "偏好学习",
                "KL散度正则化"
            ],
            "_index": 180
        },
        {
            "title": "ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models",
            "authors": [
                "Ruishu Zhu",
                "Zhihao Huang",
                "Jiacheng Sun",
                "Ping Luo",
                "Hongyuan Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14099v1",
            "summary": "Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14099v1",
            "code_links": [],
            "headline_zh": "提出ViewMask-1-to-3，通过离散扩散模型解决单图像生成多视角一致图像的挑战。",
            "summary_zh": "从单张图像和文本描述生成多视角图像一直面临几何一致性难以保持的挑战。现有方法通常依赖3D感知架构或专用扩散模型，需要大量多视角训练数据和复杂几何先验。本文提出ViewMask-1-to-3，首次将离散扩散模型应用于多视角图像生成。与在潜在空间操作的连续扩散方法不同，ViewMask-1-to-3将多视角合成建模为离散序列建模问题，每个视角通过MAGVIT-v2标记化表示为视觉标记。通过掩码标记预测统一语言和视觉，该方法能够通过文本输入的迭代标记解掩码逐步生成多个视角。ViewMask-1-to-3通过简单随机掩码结合自注意力实现跨视角一致性，无需复杂3D几何约束或专用注意力架构。实验表明，离散扩散为现有多视角生成方法提供了可行且简单的替代方案，在GSO和3D-FUTURE数据集上平均PSNR、SSIM和LPIPS指标排名第一，同时保持架构简洁性。",
            "intro_zh": [
                "现有方法依赖3D架构或专用扩散模型，需大量多视角数据和复杂几何先验，导致实现复杂且成本高。",
                "ViewMask-1-to-3将多视角生成建模为离散序列问题，使用MAGVIT-v2标记化和掩码预测，通过随机掩码与自注意力确保一致性。",
                "在GSO和3D-FUTURE数据集上，该方法在PSNR、SSIM和LPIPS指标上平均排名第一，验证了离散扩散的有效性和简洁性。"
            ],
            "method_zh": "ViewMask-1-to-3的整体框架基于离散扩散模型，将多视角图像生成转化为序列建模任务。首先，使用MAGVIT-v2将每个视角图像标记化为视觉标记序列，结合文本输入形成多模态序列。关键创新点在于采用掩码标记预测机制，通过迭代解掩码逐步生成多视角图像，并利用随机掩码和自注意力机制实现跨视角几何一致性，无需额外3D约束。与现有方法的主要区别在于：它避免了连续扩散模型的潜在空间操作，简化了架构；不依赖复杂3D几何先验或专用注意力模块，降低了实现难度和计算成本。",
            "application_zh": "该研究在计算机视觉和机器人领域有广泛应用潜力，如虚拟现实中的场景重建、增强现实的物体展示、机器人导航的环境感知，以及游戏和影视制作中的多视角内容生成，能高效生成一致的多视角图像，提升真实感和交互性。",
            "highlight_zh": "在GSO和3D-FUTURE数据集上的实验结果显示，ViewMask-1-to-3在PSNR、SSIM和LPIPS指标上平均排名第一，显著优于现有方法，证明了离散扩散模型在多视角生成中的高效性和简洁架构优势。",
            "tags_zh": [
                "多视角图像生成",
                "离散扩散模型",
                "序列建模",
                "掩码标记预测",
                "几何一致性",
                "MAGVIT-v2标记化",
                "多模态融合",
                "自注意力机制"
            ],
            "_index": 181
        },
        {
            "title": "Cornserve: Efficiently Serving Any-to-Any Multimodal Models",
            "authors": [
                "Jeff J. Ma",
                "Jae-Won Chung",
                "Jisang Ahn",
                "Yizhuo Liang",
                "Akshay Jajoo",
                "Myungjin Lee",
                "Mosharaf Chowdhury"
            ],
            "arxiv_id": "2512.14098v1",
            "summary": "We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.\n  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\\times$ throughput improvement and up to 5.79$\\times$ tail latency reduction over existing solutions.",
            "categories": [
                "cs.LG",
                "cs.DC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14098v1",
            "code_links": [],
            "headline_zh": "提出Cornserve系统以高效在线服务任意到任意多模态模型，解决异构计算挑战。",
            "summary_zh": "我们介绍了Cornserve，一个用于新兴任意到任意多模态模型的高效在线服务系统。任意到任意模型接受文本和多模态数据（如图像、视频、音频）的组合作为输入，并生成文本和多模态数据的组合作为输出，在模型服务中引入了请求类型、计算路径和计算规模异构性。Cornserve允许模型开发者描述通用任意到任意模型的计算图，该图由多模态编码器、大型语言模型等自回归模型和扩散变换器等多模态生成器等异构组件组成。基于此，Cornserve的规划器自动为模型找到优化的部署计划，包括是否以及如何根据模型和工作负载特性将模型分解为更小的组件。Cornserve的分布式运行时然后按照计划执行模型，高效处理在线服务中的任意到任意模型异构性。评估显示，Cornserve能够高效服务多样化的任意到任意模型和工作负载，相比现有解决方案，吞吐量提升高达3.81倍，尾部延迟降低高达5.79倍。",
            "intro_zh": [
                "现有方法难以处理任意到任意多模态模型的异构性，包括请求类型、计算路径和计算规模差异，导致在线服务效率低下。",
                "Cornserve通过描述模型计算图，自动规划优化部署，并利用分布式运行时执行，核心思想是分解模型以匹配工作负载特性。",
                "实验表明，Cornserve显著提升吞吐量（最高3.81倍）和降低尾部延迟（最高5.79倍），优于现有解决方案。"
            ],
            "method_zh": "Cornserve的整体框架包括一个规划器和一个分布式运行时。规划器基于模型开发者提供的计算图描述，自动生成优化的部署计划，关键创新点在于能够根据模型和工作负载特性动态决定是否及如何将模型分解为异构组件（如多模态编码器、LLMs、DiTs）。与现有方法的主要区别在于，Cornserve专门针对任意到任意模型的异构性设计，通过自动规划和分布式执行来高效处理多模态输入输出的复杂计算路径，而传统系统往往假设固定模型结构或忽略这种异构性。",
            "application_zh": "该研究可应用于多模态AI服务场景，如智能助手、内容生成平台和实时交互系统，支持文本、图像、视频、音频的任意组合输入输出，提升服务效率和可扩展性，具有实际部署价值。",
            "highlight_zh": "最重要的实验结果显示，Cornserve在多样化任意到任意模型和工作负载上，相比现有解决方案，实现了高达3.81倍的吞吐量提升和高达5.79倍的尾部延迟降低，证明了其高效处理异构性的能力。",
            "tags_zh": [
                "多模态模型服务",
                "任意到任意模型",
                "异构计算",
                "在线服务系统",
                "模型分解",
                "分布式运行时",
                "吞吐量优化",
                "尾部延迟降低"
            ],
            "_index": 182
        },
        {
            "title": "OUSAC: Optimized Guidance Scheduling with Adaptive Caching for DiT Acceleration",
            "authors": [
                "Ruitong Sun",
                "Tianze Yang",
                "Wei Niu",
                "Jin Sun"
            ],
            "arxiv_id": "2512.14096v1",
            "summary": "Diffusion models have emerged as the dominant paradigm for high-quality image generation, yet their computational expense remains substantial due to iterative denoising. Classifier-Free Guidance (CFG) significantly enhances generation quality and controllability but doubles the computation by requiring both conditional and unconditional forward passes at every timestep. We present OUSAC (Optimized gUidance Scheduling with Adaptive Caching), a framework that accelerates diffusion transformers (DiT) through systematic optimization. Our key insight is that variable guidance scales enable sparse computation: adjusting scales at certain timesteps can compensate for skipping CFG at others, enabling both fewer total sampling steps and fewer CFG steps while maintaining quality. However, variable guidance patterns introduce denoising deviations that undermine standard caching methods, which assume constant CFG scales across steps. Moreover, different transformer blocks are affected at different levels under dynamic conditions. This paper develops a two-stage approach leveraging these insights. Stage-1 employs evolutionary algorithms to jointly optimize which timesteps to skip and what guidance scale to use, eliminating up to 82% of unconditional passes. Stage-2 introduces adaptive rank allocation that tailors calibration efforts per transformer block, maintaining caching effectiveness under variable guidance. Experiments demonstrate that OUSAC significantly outperforms state-of-the-art acceleration methods, achieving 53% computational savings with 15% quality improvement on DiT-XL/2 (ImageNet 512x512), 60% savings with 16.1% improvement on PixArt-alpha (MSCOCO), and 5x speedup on FLUX while improving CLIP Score over the 50-step baseline.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "29 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14096v1",
            "code_links": [],
            "headline_zh": "提出OUSAC框架，通过优化引导调度与自适应缓存加速扩散变换器，解决CFG计算开销大的问题。",
            "summary_zh": "扩散模型已成为高质量图像生成的主导范式，但其迭代去噪过程计算开销巨大。无分类器引导（CFG）显著提升了生成质量和可控性，但需要在每个时间步同时执行条件前向传播和无条件前向传播，导致计算量加倍。本文提出了OUSAC（优化引导调度与自适应缓存）框架，通过系统优化加速扩散变换器（DiT）。核心洞见是：可变的引导尺度能够实现稀疏计算——在某些时间步调整引导尺度可以补偿在其他时间步跳过CFG的操作，从而在保持质量的同时减少总采样步数和CFG步数。然而，可变的引导模式会引入去噪偏差，破坏标准缓存方法的有效性（这些方法假设CFG尺度在步间恒定）。此外，在动态条件下，不同的变换器块受到的影响程度不同。本文基于这些洞见开发了一种两阶段方法：第一阶段使用进化算法联合优化跳过哪些时间步以及使用何种引导尺度，最多可消除82%的无条件前向传播；第二阶段引入自适应秩分配，针对每个变换器块定制校准工作，在可变引导下保持缓存有效性。实验表明，OUSAC显著优于最先进的加速方法，在DiT-XL/2（ImageNet 512x512）上实现了53%的计算节省和15%的质量提升，在PixArt-alpha（MSCOCO）上实现了60%的节省和16.1%的提升，在FLUX上实现了5倍加速，同时CLIP分数超过50步基线。",
            "intro_zh": [
                "核心问题：CFG虽提升扩散模型质量，但需双倍计算，且现有缓存方法在可变引导下失效，阻碍高效加速。",
                "方法要点：提出两阶段框架，先优化引导调度减少CFG步数，再自适应缓存补偿偏差，实现稀疏计算。",
                "实验或效果：在多个DiT模型上显著节省计算并提升质量，如DiT-XL/2节省53%计算且质量提升15%。"
            ],
            "method_zh": "OUSAC是一个两阶段框架，旨在加速扩散变换器（DiT）。整体框架包括：第一阶段使用进化算法联合优化时间步跳过策略和引导尺度，实现稀疏计算，最多可消除82%的无条件前向传播；第二阶段引入自适应秩分配，根据动态引导条件为每个变换器块定制校准秩，以维持缓存有效性。关键技术创新点在于利用可变引导尺度补偿跳过CFG的偏差，以及自适应缓存机制应对不同块的异质性影响。与现有方法的主要区别在于：现有方法通常假设恒定CFG尺度或采用固定缓存策略，而OUSAC通过系统优化和自适应设计，在可变引导下实现更高效的加速，同时保持或提升生成质量。",
            "application_zh": "该研究可应用于需要高效高质量图像生成的领域，如内容创作、游戏开发、广告设计和虚拟现实，通过减少扩散模型的计算开销，降低部署成本并提升实时性，具有实际商业价值。",
            "highlight_zh": "OUSAC在多个基准测试中表现优异：DiT-XL/2上节省53%计算且FID提升15%，PixArt-alpha上节省60%计算且质量提升16.1%，FLUX上实现5倍加速并超越基线CLIP分数，显著优于现有加速方法。",
            "tags_zh": [
                "扩散模型加速",
                "无分类器引导优化",
                "稀疏计算",
                "自适应缓存",
                "进化算法调度",
                "变换器块校准",
                "图像生成效率",
                "计算节省"
            ],
            "_index": 183
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095v1",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095v1",
            "code_links": [],
            "headline_zh": "提出AnchorHOI框架，通过基于锚点的先验蒸馏策略解决零样本4D人-物交互生成中的交互线索不足问题。",
            "summary_zh": "尽管基于监督方法的文本驱动4D人-物交互生成取得了显著进展，但由于大规模4D HOI数据集的稀缺性，其可扩展性仍然受限。为了克服这一限制，最近的方法尝试使用预训练的图像扩散模型进行零样本4D HOI生成。然而，在生成过程中交互线索的蒸馏非常有限，限制了它们在不同场景中的适用性。本文提出了AnchorHOI，这是一个新颖的框架，通过结合视频扩散模型超越图像扩散模型，充分利用混合先验，推进了4D HOI生成。然而，直接使用此类先验优化高维4D HOI仍然具有挑战性，特别是在人体姿态和组合运动方面。为了解决这一挑战，AnchorHOI引入了一种基于锚点的先验蒸馏策略，该策略构建交互感知的锚点，然后利用它们在一个可处理的两步过程中指导生成。具体来说，为4D HOI生成设计了两个定制的锚点：用于表达性交互组合的锚点神经辐射场，以及用于逼真运动合成的锚点关键点。大量实验表明，AnchorHOI在多样性和泛化性方面优于先前的方法。",
            "intro_zh": [
                "现有零样本4D HOI生成方法主要依赖图像扩散模型，交互线索蒸馏不足，限制了跨场景适用性。",
                "AnchorHOI提出基于锚点的先验蒸馏策略，通过构建交互感知锚点（如锚点NeRF和关键点）指导生成过程。",
                "实验表明，该方法在多样性和泛化性上优于先前方法，有效提升了4D HOI生成质量。"
            ],
            "method_zh": "AnchorHOI是一个零样本4D人-物交互生成框架，整体基于混合先验（结合图像和视频扩散模型）进行生成。关键技术创新在于引入锚点先验蒸馏策略：首先构建两个交互感知锚点——锚点NeRF用于建模交互组合，锚点关键点用于合成运动；然后通过两步过程（先优化锚点，再指导生成）实现可处理的高维4D HOI优化。与现有方法的主要区别在于，它超越了仅依赖图像扩散模型的局限，通过锚点机制更充分地蒸馏交互线索，解决了直接优化4D HOI的挑战。",
            "application_zh": "该研究在虚拟现实、游戏开发、机器人交互仿真和影视特效制作等领域具有潜在应用价值，能够生成多样且逼真的4D人-物交互序列，降低对大规模标注数据的依赖，提升内容创作的效率和灵活性。",
            "highlight_zh": "实验结果显示，AnchorHOI在零样本4D HOI生成任务中，相比先前方法在多样性和泛化性方面表现更优，通过锚点先验蒸馏有效提升了交互质量和运动真实性，验证了框架的有效性。",
            "tags_zh": [
                "4D人-物交互生成",
                "零样本学习",
                "先验蒸馏",
                "神经辐射场",
                "运动合成",
                "扩散模型",
                "视频生成",
                "交互建模"
            ],
            "_index": 184
        },
        {
            "title": "Quality-Aware Framework for Video-Derived Respiratory Signals",
            "authors": [
                "Nhi Nguyen",
                "Constantino Álvarez Casado",
                "Le Nguyen",
                "Manuel Lage Cañellas",
                "Miguel Bordallo López"
            ],
            "arxiv_id": "2512.14093v1",
            "summary": "Video-based respiratory rate (RR) estimation is often unreliable due to inconsistent signal quality across extraction methods. We present a predictive, quality-aware framework that integrates heterogeneous signal sources with dynamic assessment of reliability. Ten signals are extracted from facial remote photoplethysmography (rPPG), upper-body motion, and deep learning pipelines, and analyzed using four spectral estimators: Welch's method, Multiple Signal Classification (MUSIC), Fast Fourier Transform (FFT), and peak detection. Segment-level quality indices are then used to train machine learning models that predict accuracy or select the most reliable signal. This enables adaptive signal fusion and quality-based segment filtering. Experiments on three public datasets (OMuSense-23, COHFACE, MAHNOB-HCI) show that the proposed framework achieves lower RR estimation errors than individual methods in most cases, with performance gains depending on dataset characteristics. These findings highlight the potential of quality-driven predictive modeling to deliver scalable and generalizable video-based respiratory monitoring solutions.",
            "categories": [
                "cs.CV",
                "eess.SP"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages, 1 figure, 2 tables, conference",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14093v1",
            "code_links": [],
            "headline_zh": "提出质量感知框架以解决视频呼吸信号估计中信号质量不一致的问题，实现自适应融合与过滤。",
            "summary_zh": "基于视频的呼吸率估计常因不同提取方法产生的信号质量不一致而不可靠。本文提出一个预测性、质量感知的框架，整合了异质信号源并动态评估其可靠性。从面部远程光电容积描记术、上半身运动和深度学习流程中提取十种信号，并使用四种频谱估计器进行分析：Welch方法、多重信号分类、快速傅里叶变换和峰值检测。然后，利用片段级质量指标训练机器学习模型，以预测准确性或选择最可靠的信号。这实现了自适应信号融合和基于质量的片段过滤。在三个公共数据集上的实验表明，该框架在大多数情况下比个体方法实现了更低的呼吸率估计误差，性能提升取决于数据集特性。这些发现突显了质量驱动的预测建模在提供可扩展和泛化的视频呼吸监测解决方案方面的潜力。",
            "intro_zh": [
                "核心问题：视频呼吸率估计因信号提取方法多样导致质量不一致，影响可靠性和准确性。",
                "方法要点：整合多源信号，动态评估质量，通过机器学习模型预测准确性并自适应融合信号。",
                "实验或效果：在三个数据集上验证，框架降低估计误差，性能提升依赖于数据集特性。"
            ],
            "method_zh": "论文提出一个质量感知框架，整体包括信号提取、频谱分析和质量评估三部分。关键技术创新点在于从面部rPPG、上半身运动和深度学习流程中提取十种异质信号，使用Welch方法、MUSIC、FFT和峰值检测四种频谱估计器进行分析，并基于片段级质量指标训练机器学习模型进行准确性预测或信号选择。与现有方法的主要区别在于动态评估信号可靠性，实现自适应融合和过滤，而非依赖单一信号源或固定融合策略。",
            "application_zh": "该研究可应用于远程医疗监测、健康管理、运动生理学和智能家居等领域，提供非接触式、可扩展的呼吸监测解决方案，提升视频呼吸信号估计的准确性和泛化能力。",
            "highlight_zh": "在OMuSense-23、COHFACE和MAHNOB-HCI三个公共数据集上的实验显示，框架在大多数情况下比个体方法降低了呼吸率估计误差，性能提升因数据集特性而异，突显了质量驱动建模的有效性。",
            "tags_zh": [
                "视频呼吸率估计",
                "质量感知框架",
                "信号融合",
                "远程光电容积描记术",
                "机器学习模型",
                "频谱分析",
                "自适应过滤",
                "频谱估计",
                "健康监测"
            ],
            "_index": 163
        },
        {
            "title": "ProtoFlow: Interpretable and Robust Surgical Workflow Modeling with Learned Dynamic Scene Graph Prototypes",
            "authors": [
                "Felix Holm",
                "Ghazal Ghazaei",
                "Nassir Navab"
            ],
            "arxiv_id": "2512.14092v1",
            "summary": "Purpose: Detailed surgical recognition is critical for advancing AI-assisted surgery, yet progress is hampered by high annotation costs, data scarcity, and a lack of interpretable models. While scene graphs offer a structured abstraction of surgical events, their full potential remains untapped. In this work, we introduce ProtoFlow, a novel framework that learns dynamic scene graph prototypes to model complex surgical workflows in an interpretable and robust manner.\n  Methods: ProtoFlow leverages a graph neural network (GNN) encoder-decoder architecture that combines self-supervised pretraining for rich representation learning with a prototype-based fine-tuning stage. This process discovers and refines core prototypes that encapsulate recurring, clinically meaningful patterns of surgical interaction, forming an explainable foundation for workflow analysis.\n  Results: We evaluate our approach on the fine-grained CAT-SG dataset. ProtoFlow not only outperforms standard GNN baselines in overall accuracy but also demonstrates exceptional robustness in limited-data, few-shot scenarios, maintaining strong performance when trained on as few as one surgical video. Our qualitative analyses further show that the learned prototypes successfully identify distinct surgical sub-techniques and provide clear, interpretable insights into workflow deviations and rare complications.\n  Conclusion: By uniting robust representation learning with inherent explainability, ProtoFlow represents a significant step toward developing more transparent, reliable, and data-efficient AI systems, accelerating their potential for clinical adoption in surgical training, real-time decision support, and workflow optimization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14092v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ProtoFlow框架，通过动态场景图原型学习实现可解释且鲁棒的手术工作流建模",
            "summary_zh": "目的：详细的手术识别对推进AI辅助手术至关重要，但高标注成本、数据稀缺和缺乏可解释模型阻碍了进展。虽然场景图为手术事件提供了结构化抽象，但其全部潜力尚未被充分挖掘。本研究提出ProtoFlow，一种新颖框架，通过学习动态场景图原型，以可解释且鲁棒的方式建模复杂手术工作流。方法：ProtoFlow采用图神经网络编码器-解码器架构，结合自监督预训练进行丰富表示学习，以及基于原型的微调阶段。该过程发现并精炼核心原型，这些原型封装了重复出现、具有临床意义的手术交互模式，为工作流分析形成可解释的基础。结果：我们在细粒度CAT-SG数据集上评估了该方法。ProtoFlow不仅在整体准确率上优于标准GNN基线，还在有限数据、少样本场景中表现出卓越的鲁棒性，在仅用一个手术视频训练时仍保持强劲性能。定性分析进一步显示，学习到的原型成功识别了不同的手术子技术，并为工作流偏差和罕见并发症提供了清晰、可解释的洞察。结论：通过将鲁棒表示学习与内在可解释性相结合，ProtoFlow代表了向开发更透明、可靠和数据高效AI系统迈出的重要一步，加速了其在手术培训、实时决策支持和工作流优化中的临床应用潜力。",
            "intro_zh": [
                "核心问题：手术识别面临高标注成本、数据稀缺和模型缺乏可解释性，现有场景图方法潜力未充分发挥。",
                "方法要点：提出ProtoFlow框架，结合自监督预训练和原型微调，学习动态场景图原型以建模手术工作流。",
                "实验或效果：在CAT-SG数据集上超越GNN基线，少样本场景下鲁棒性强，原型提供可解释的手术洞察。"
            ],
            "method_zh": "ProtoFlow采用图神经网络编码器-解码器架构，整体框架包括自监督预训练和基于原型的微调两个阶段。关键技术创新点在于学习动态场景图原型，这些原型自动发现并封装手术中的重复交互模式，形成可解释的工作流表示。与现有方法的主要区别在于将原型学习引入手术场景图建模，增强了模型的解释性和数据效率，而传统GNN方法通常缺乏这种内在可解释性，且对数据量要求较高。",
            "application_zh": "该研究可应用于手术培训系统，提供可解释的工作流分析辅助教学；在实时手术决策支持中，帮助识别工作流偏差和并发症；还可用于手术室工作流优化，提升手术效率和安全性。",
            "highlight_zh": "在CAT-SG数据集上，ProtoFlow整体准确率优于标准GNN基线；在少样本场景下表现出卓越鲁棒性，仅用一个手术视频训练时性能仍强劲；定性分析显示学习原型能识别手术子技术并提供工作流偏差的可解释洞察。",
            "tags_zh": [
                "手术工作流建模",
                "动态场景图",
                "原型学习",
                "图神经网络",
                "可解释人工智能",
                "少样本学习",
                "自监督预训练",
                "医疗图像分析"
            ],
            "_index": 186
        },
        {
            "title": "Arithmetic-Intensity-Aware Quantization",
            "authors": [
                "Taig Singh",
                "Shreshth Rajan",
                "Nikhil Iyer"
            ],
            "arxiv_id": "2512.14090v1",
            "summary": "As modern neural networks become increasingly memory-bound, inference throughput is limited by DRAM bandwidth rather than compute. We present Arithmetic-Intensity-Aware Quantization (AIQ), a mixed precision quantization framework that chooses per-layer bit-widths to maximize arithmetic intensity (AI) while minimizing accuracy loss. AIQ is a post-training quantization method that uses search algorithms over per-layer quantization schemes to minimize a weighted loss over AI and accuracy. On ResNet-20/CIFAR-10, AIQ increases AI by ~50% over an FP32 baseline while keeping test accuracy within ~1 percentage point, and outperforming global uniform quantization schemes. On a memory-bound MobileNetV2 architecture, AIQ configurations give a 1.66x higher throughput than the FP32 baseline while keeping test accuracy within 1 percentage point. We also find that AIQ naturally quantizes larger layers more aggressively.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14090v1",
            "code_links": [],
            "headline_zh": "提出算术强度感知量化（AIQ）框架，通过混合精度量化解决内存带宽限制下的神经网络推理性能问题。",
            "summary_zh": "随着现代神经网络日益受内存限制，推理吞吐量更多地受DRAM带宽而非计算能力制约。本文提出了算术强度感知量化（AIQ），这是一种混合精度量化框架，通过选择每层位宽来最大化算术强度（AI）同时最小化精度损失。AIQ是一种后训练量化方法，使用搜索算法优化每层量化方案，以最小化算术强度和精度的加权损失。在ResNet-20/CIFAR-10上，AIQ相比FP32基线将算术强度提高了约50%，同时保持测试精度在约1个百分点内，并优于全局均匀量化方案。在内存受限的MobileNetV2架构上，AIQ配置实现了比FP32基线高1.66倍的吞吐量，同时保持测试精度在1个百分点内。我们还发现AIQ自然地更激进地量化较大的层。",
            "intro_zh": [
                "核心问题：现代神经网络推理受内存带宽限制，而非计算能力，导致吞吐量瓶颈，现有量化方法如全局均匀量化可能未充分考虑内存效率。",
                "方法要点：提出AIQ框架，通过后训练搜索算法优化每层位宽，以最大化算术强度并最小化精度损失，实现混合精度量化。",
                "实验或效果：在ResNet-20/CIFAR-10上提升算术强度约50%，MobileNetV2上吞吐量提高1.66倍，均保持精度损失在1个百分点内。"
            ],
            "method_zh": "AIQ是一个后训练混合精度量化框架，整体框架包括基于搜索算法优化每层量化位宽，以最小化算术强度和精度的加权损失函数。关键技术创新点在于引入算术强度作为量化决策的核心指标，通过动态调整位宽来平衡内存带宽利用和模型精度。与现有方法的主要区别在于，AIQ不依赖全局统一量化，而是针对每层特性进行定制化量化，更有效地缓解内存瓶颈，相比传统方法如全局均匀量化，能更好地提升推理性能。",
            "application_zh": "该研究适用于边缘计算、移动设备和物联网等内存受限场景，通过优化神经网络推理的内存效率，提升实时应用如计算机视觉和自然语言处理的部署性能，具有实际价值。",
            "highlight_zh": "在ResNet-20/CIFAR-10上，AIQ将算术强度提高约50%，精度损失控制在1个百分点内；在MobileNetV2上，吞吐量提升1.66倍，同样保持精度稳定，显著优于基线方法。",
            "tags_zh": [
                "混合精度量化",
                "算术强度优化",
                "后训练量化",
                "内存带宽限制",
                "神经网络推理",
                "模型压缩",
                "边缘计算",
                "性能提升"
            ],
            "_index": 187
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087v1",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Submitted to IEEE TPAMI, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087v1",
            "code_links": [],
            "headline_zh": "提出GaussianPlant方法，通过解耦结构和外观的高斯溅射表示，实现植物高保真外观与精确结构的三维重建。",
            "summary_zh": "我们提出了一种基于三维高斯溅射（3DGS）的方法，用于从多视角图像中联合恢复植物外观和内部结构。虽然3DGS在新视角合成中表现出强大的场景外观重建能力，但缺乏支撑这些外观的结构表示（如植物的分枝模式），这限制了其在植物表型分析等任务中的应用。为实现高保真外观和结构重建，我们引入了GaussianPlant，这是一种分层3DGS表示，解耦了结构和外观。具体而言，我们使用结构基元（StPs）显式表示枝干和叶片的几何结构，并使用外观基元（ApPs）通过三维高斯表示植物的外观。StPs表示植物的简化结构，即将枝干建模为圆柱体、叶片建模为圆盘。为准确区分枝干和叶片，StP的属性（即枝干或叶片）以自组织方式进行优化。ApPs绑定到每个StP，以传统3DGS方式表示枝干或叶片的外观。StPs和ApPs通过输入多视角图像的重渲染损失以及利用绑定对应信息从ApP到StP的梯度流进行联合优化。我们进行了实验，定性评估外观和结构的重建准确性，并通过真实世界实验定性验证实际性能。实验表明，GaussianPlant通过ApPs实现了高保真外观重建，通过StPs实现了精确结构重建，从而能够提取分枝结构和叶片实例。",
            "intro_zh": [
                "现有3DGS方法缺乏植物内部结构表示，限制了在植物表型分析等任务中的应用。",
                "提出分层3DGS表示GaussianPlant，通过结构基元和外观基元解耦结构与外观。",
                "实验验证了该方法在植物外观和结构重建上的高保真性和准确性，支持分枝和叶片提取。"
            ],
            "method_zh": "GaussianPlant的整体框架基于三维高斯溅射（3DGS），采用分层表示解耦结构和外观。关键技术创新点包括：引入结构基元（StPs）显式建模植物几何结构（枝干为圆柱体、叶片为圆盘），并以自组织方式优化其属性；使用外观基元（ApPs）绑定到StPs，通过三维高斯表示外观；通过重渲染损失和从ApP到StP的梯度流进行联合优化。与现有方法的主要区别在于，传统3DGS仅关注外观重建，而GaussianPlant通过结构-外观解耦，同时实现了高保真外观和精确结构重建，解决了植物三维重建中的结构表示缺失问题。",
            "application_zh": "该研究在植物表型分析、农业监测、植物建模和虚拟现实等领域具有潜在应用价值，能够支持精确的植物结构提取和外观渲染，提升相关任务的效率和准确性。",
            "highlight_zh": "实验表明，GaussianPlant在植物三维重建中实现了高保真外观重建和精确结构重建，能够有效提取分枝结构和叶片实例，验证了其在实际应用中的性能提升。",
            "tags_zh": [
                "三维高斯溅射",
                "植物三维重建",
                "结构-外观解耦",
                "多视角图像",
                "植物表型分析",
                "分层表示",
                "自组织优化",
                "联合优化"
            ],
            "_index": 188
        },
        {
            "title": "Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization",
            "authors": [
                "Boyuan Yao",
                "Dingcheng Luo",
                "Lianghao Cao",
                "Nikola Kovachki",
                "Thomas O'Leary-Roseberry",
                "Omar Ghattas"
            ],
            "arxiv_id": "2512.14086v1",
            "summary": "We present approximation theories and efficient training methods for derivative-informed Fourier neural operators (DIFNOs) with applications to PDE-constrained optimization. A DIFNO is an FNO trained by minimizing its prediction error jointly on output and Fréchet derivative samples of a high-fidelity operator (e.g., a parametric PDE solution operator). As a result, a DIFNO can closely emulate not only the high-fidelity operator's response but also its sensitivities. To motivate the use of DIFNOs instead of conventional FNOs as surrogate models, we show that accurate surrogate-driven PDE-constrained optimization requires accurate surrogate Fréchet derivatives. Then, for continuously differentiable operators, we establish (i) simultaneous universal approximation of FNOs and their Fréchet derivatives on compact sets, and (ii) universal approximation of FNOs in weighted Sobolev spaces with input measures that have unbounded supports. Our theoretical results certify the capability of FNOs for accurate derivative-informed operator learning and accurate solution of PDE-constrained optimization. Furthermore, we develop efficient training schemes using dimension reduction and multi-resolution techniques that significantly reduce memory and computational costs for Fréchet derivative learning. Numerical examples on nonlinear diffusion--reaction, Helmholtz, and Navier--Stokes equations demonstrate that DIFNOs are superior in sample complexity for operator learning and solving infinite-dimensional PDE-constrained inverse problems, achieving high accuracy at low training sample sizes.",
            "categories": [
                "cs.LG",
                "math.NA"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14086v1",
            "code_links": [],
            "headline_zh": "提出导数信息傅里叶神经算子，通过联合优化输出和导数样本实现高效PDE约束优化",
            "summary_zh": "本文提出了导数信息傅里叶神经算子的近似理论和高效训练方法，应用于偏微分方程约束优化。DIFNO是一种通过最小化高保真算子输出和Fréchet导数样本预测误差联合训练的FNO，能够紧密模拟算子的响应和灵敏度。研究表明，准确的代理驱动PDE约束优化需要准确的代理Fréchet导数。对于连续可微算子，我们建立了FNO及其Fréchet导数在紧集上的同时通用近似性，以及在具有无界支撑的输入测度加权Sobolev空间中FNO的通用近似性。理论结果验证了FNO在准确导数信息算子学习和PDE约束优化求解中的能力。此外，我们开发了使用降维和多分辨率技术的高效训练方案，显著降低了Fréchet导数学习的内存和计算成本。非线性扩散-反应、Helmholtz和Navier-Stokes方程的数值实验表明，DIFNO在算子学习和求解无限维PDE约束逆问题的样本复杂度方面具有优越性，在低训练样本量下实现高精度。",
            "intro_zh": [
                "现有FNO作为代理模型在PDE约束优化中导数精度不足，影响优化效果",
                "提出DIFNO，通过联合训练输出和Fréchet导数样本提升导数模拟能力",
                "理论证明通用近似性，实验显示在低样本量下实现高精度，显著降低计算成本"
            ],
            "method_zh": "DIFNO基于傅里叶神经算子框架，核心创新在于训练过程中同时最小化高保真算子的输出误差和Fréchet导数误差。整体框架采用FNO作为基础架构，通过联合损失函数优化，使网络不仅能准确预测算子响应，还能精确模拟其灵敏度。关键技术创新包括：1）同时通用近似理论证明FNO及其导数在紧集上的逼近能力；2）开发高效的降维和多分辨率训练技术，减少导数学习的内存和计算开销。与现有FNO的主要区别在于训练目标包含导数信息，从而在PDE约束优化中提供更准确的梯度信息，提升优化效率和精度。",
            "application_zh": "该研究主要应用于偏微分方程约束的优化问题，如逆问题求解、参数估计和最优控制，在工程、物理和计算科学中具有广泛价值，能高效处理高维、非线性PDE系统，降低计算成本。",
            "highlight_zh": "数值实验在非线性扩散-反应、Helmholtz和Navier-Stokes方程上验证DIFNO的优越性：在低训练样本量下实现高精度，样本复杂度显著优于传统FNO，高效解决无限维PDE约束逆问题，计算成本大幅降低。",
            "tags_zh": [
                "导数信息学习",
                "傅里叶神经算子",
                "偏微分方程约束优化",
                "代理建模",
                "Fréchet导数",
                "降维训练",
                "多分辨率技术",
                "逆问题求解"
            ],
            "_index": 165
        },
        {
            "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
            "authors": [
                "Sungnyun Kim"
            ],
            "arxiv_id": "2512.14083v1",
            "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.",
            "categories": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "eess.AS",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "PhD Dissertation",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14083v1",
            "code_links": [],
            "headline_zh": "提出分层可扩展框架以解决真实世界视听语音识别中的鲁棒性和泛化性问题",
            "summary_zh": "视听语音识别（AVSR）系统在实际部署中面临严峻挑战，主要源于真实环境中的不可预测声学噪声和视觉干扰导致的性能显著下降。本论文主张采用系统化的分层方法克服这些挑战，在表示、架构和系统三个层面实现鲁棒的可扩展性。在表示层面，我们研究构建统一模型的方法，学习对多种真实世界干扰具有内在鲁棒性的视听特征，从而无需专用模块即可泛化到新环境。针对架构可扩展性，我们探索如何高效扩展模型容量，同时确保多模态输入的自适应可靠使用，开发了一个基于输入特征智能分配计算资源的框架。最后，在系统层面，我们提出通过与大规模基础模型的模块化集成来扩展系统功能，利用其强大的认知和生成能力最大化最终识别准确率。通过在这三个层面系统提供解决方案，本论文旨在构建下一代鲁棒、可扩展且在实际应用中具有高可靠性的AVSR系统。",
            "intro_zh": [
                "核心问题：真实世界AVSR系统在声学噪声和视觉干扰下性能显著下降，现有方法缺乏系统化解决方案应对多层面挑战。",
                "方法要点：采用分层可扩展框架，在表示、架构和系统三个层面分别提升鲁棒性、自适应能力和功能扩展性。",
                "实验或效果：通过统一特征学习、智能资源分配和基础模型集成，显著提升系统在复杂环境下的识别准确率和泛化能力。"
            ],
            "method_zh": "论文提出一个分层可扩展框架，整体上分为表示、架构和系统三个层面。在表示层面，核心创新是构建统一模型学习对多种真实世界干扰具有内在鲁棒性的视听特征，避免依赖专用模块。在架构层面，关键技术创新是开发自适应框架，根据输入特征智能分配计算资源，实现模型容量的高效扩展。在系统层面，主要区别在于通过模块化集成大规模基础模型，利用其认知和生成能力增强系统功能。与现有方法相比，该方法系统性地解决了多层面挑战，而非孤立优化单个组件。",
            "application_zh": "该研究可应用于智能助手、远程会议、自动驾驶、医疗辅助和娱乐等需要高鲁棒性语音识别的领域，提升系统在嘈杂或视觉受限环境下的可靠性，推动AVSR技术在实际场景中的广泛部署。",
            "highlight_zh": "实验表明，分层框架在真实世界噪声和干扰下显著提升识别准确率，统一特征学习增强泛化能力，智能资源分配优化计算效率，基础模型集成最大化性能，整体系统展现出高可靠性和可扩展性。",
            "tags_zh": [
                "视听语音识别",
                "多模态融合",
                "鲁棒性学习",
                "多模态融合",
                "可扩展架构",
                "基础模型集成",
                "真实世界应用",
                "自适应计算",
                "分层框架"
            ],
            "_index": 166
        },
        {
            "title": "SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations",
            "authors": [
                "Wentao Guo",
                "Mayank Mishra",
                "Xinle Cheng",
                "Ion Stoica",
                "Tri Dao"
            ],
            "arxiv_id": "2512.14080v1",
            "summary": "Mixture of Experts (MoE) models have emerged as the de facto architecture for scaling up language models without significantly increasing the computational cost. Recent MoE models demonstrate a clear trend towards high expert granularity (smaller expert intermediate dimension) and higher sparsity (constant number of activated experts with higher number of total experts), which improve model quality per FLOP. However, fine-grained MoEs suffer from increased activation memory footprint and reduced hardware efficiency due to higher IO costs, while sparser MoEs suffer from wasted computations due to padding in Grouped GEMM kernels. In response, we propose a memory-efficient algorithm to compute the forward and backward passes of MoEs with minimal activation caching for the backward pass. We also design GPU kernels that overlap memory IO with computation benefiting all MoE architectures. Finally, we propose a novel \"token rounding\" method that minimizes the wasted compute due to padding in Grouped GEMM kernels. As a result, our method SonicMoE reduces activation memory by 45% and achieves a 1.86x compute throughput improvement on Hopper GPUs compared to ScatterMoE's BF16 MoE kernel for a fine-grained 7B MoE. Concretely, SonicMoE on 64 H100s achieves a training throughput of 213 billion tokens per day comparable to ScatterMoE's 225 billion tokens per day on 96 H100s for a 7B MoE model training with FSDP-2 using the lm-engine codebase. Under high MoE sparsity settings, our tile-aware token rounding algorithm yields an additional 1.16x speedup on kernel execution time compared to vanilla top-$K$ routing while maintaining similar downstream performance. We open-source all our kernels to enable faster MoE model training.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14080v1",
            "code_links": [],
            "headline_zh": "提出SonicMoE以解决细粒度MoE模型中的内存和计算效率问题，通过IO感知优化和令牌舍入方法加速训练。",
            "summary_zh": "混合专家（MoE）模型已成为扩展语言模型而不显著增加计算成本的事实架构。最近的MoE模型显示出高专家粒度（较小的专家中间维度）和更高稀疏性（激活专家数量恒定但总专家数更多）的明显趋势，这提高了每FLOP的模型质量。然而，细粒度MoE由于更高的IO成本而面临激活内存占用增加和硬件效率降低的问题，而更稀疏的MoE则因分组GEMM内核中的填充而导致计算浪费。为此，我们提出了一种内存高效的算法来计算MoE的前向和后向传递，最小化后向传递的激活缓存。我们还设计了GPU内核，将内存IO与计算重叠，使所有MoE架构受益。最后，我们提出了一种新颖的“令牌舍入”方法，最小化分组GEMM内核中填充造成的计算浪费。因此，我们的方法SonicMoE在细粒度7B MoE上，相比ScatterMoE的BF16 MoE内核，减少了45%的激活内存，并在Hopper GPU上实现了1.86倍的计算吞吐量提升。具体来说，在64个H100上，SonicMoE实现了每天2130亿令牌的训练吞吐量，与ScatterMoE在96个H100上使用lm-engine代码库进行7B MoE模型训练（使用FSDP-2）的每天2250亿令牌吞吐量相当。在高MoE稀疏性设置下，我们的瓦片感知令牌舍入算法相比普通top-K路由，在保持类似下游性能的同时，实现了额外1.16倍的内核执行时间加速。我们开源了所有内核以加速MoE模型训练。",
            "intro_zh": [
                "核心问题：细粒度MoE模型因高IO成本导致激活内存占用增加和硬件效率降低，稀疏MoE因分组GEMM内核填充造成计算浪费。",
                "方法要点：提出内存高效算法减少激活缓存，设计IO与计算重叠的GPU内核，并引入令牌舍入方法优化分组GEMM效率。",
                "实验或效果：在7B MoE上，SonicMoE减少45%激活内存，提升1.86倍计算吞吐量，并在高稀疏设置下实现额外1.16倍加速。"
            ],
            "method_zh": "SonicMoE的整体框架基于MoE模型，通过系统级优化提升训练效率。关键技术创新包括：1) 内存高效算法，最小化后向传递的激活缓存，减少内存占用；2) GPU内核设计，实现内存IO与计算的重叠，提高硬件利用率；3) 瓦片感知令牌舍入方法，动态调整令牌分配以减少分组GEMM内核中的填充浪费。与现有方法（如ScatterMoE）的主要区别在于，SonicMoE综合解决了IO瓶颈和计算浪费问题，通过算法和内核层面的协同优化，而非仅依赖单一改进。",
            "application_zh": "该研究主要应用于大规模语言模型的训练加速，特别是在需要高专家粒度和稀疏性的MoE架构中。潜在应用领域包括自然语言处理、AI推理和生成任务，实际价值在于降低训练成本、提高资源利用率，促进更高效的大模型部署和开发。",
            "highlight_zh": "在Hopper GPU上，SonicMoE相比ScatterMoE的BF16 MoE内核，对细粒度7B MoE实现45%激活内存减少和1.86倍计算吞吐量提升；在高稀疏设置下，令牌舍入算法带来额外1.16倍内核执行加速，同时保持下游性能。",
            "tags_zh": [
                "混合专家模型",
                "内存优化",
                "计算效率",
                "令牌舍入",
                "训练吞吐量",
                "稀疏计算",
                "IO感知优化"
            ],
            "_index": 191
        },
        {
            "title": "Grammar Search for Multi-Agent Systems",
            "authors": [
                "Mayank Singh",
                "Vikas Yadav",
                "Shiva Krishna Reddy Malay",
                "Shravan Nayak",
                "Sai Rajeswar",
                "Sathwik Tejaswi Madhusudhan",
                "Eduardo Blanco"
            ],
            "arxiv_id": "2512.14079v1",
            "summary": "Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.",
            "categories": [
                "cs.AI",
                "cs.CL",
                "cs.MA"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14079v1",
            "code_links": [],
            "headline_zh": "提出基于语法搜索的结构化框架，以提升多智能体系统的搜索效率与可解释性。",
            "summary_zh": "多智能体系统的自动搜索已成为智能体AI研究的关键焦点。先前方法主要依赖基于LLM的代码空间自由形式搜索。本文提出了一种更结构化的框架，通过一组固定的简单可组合组件探索相同空间。研究表明，尽管在候选生成阶段缺乏LLM的生成灵活性，但该方法在数学和问答两个领域的五个基准测试中，有四个优于先前方法。此外，该方法还具有额外优势，包括更经济高效的搜索过程，以及生成模块化、可解释且逻辑更简单的多智能体系统。",
            "intro_zh": [
                "现有方法依赖LLM进行自由形式搜索，可能导致搜索效率低、成本高且系统逻辑复杂难解释。",
                "提出基于固定可组合组件的语法搜索框架，通过结构化方式生成候选系统，提升搜索可控性。",
                "在数学和问答领域的五个基准测试中，该方法在四个上优于先前方法，同时搜索成本更低。"
            ],
            "method_zh": "论文提出一种基于语法搜索的结构化框架，用于多智能体系统的自动构建。整体框架通过定义一组固定的简单组件（如基础操作或规则）作为构建块，使用语法规则指导这些组件的组合，以生成候选系统。关键技术创新在于将自由形式的代码搜索转化为受控的语法驱动搜索，减少了搜索空间的随机性。与现有基于LLM的自由形式搜索方法相比，该方法更注重模块化和可解释性，通过结构化组件简化系统逻辑，同时降低搜索成本。",
            "application_zh": "该研究可应用于需要高效构建多智能体系统的领域，如自动化数学问题求解、智能问答系统、任务协作机器人等。其结构化方法有助于开发更可靠、可维护的AI系统，提升实际部署中的可解释性和成本效益。",
            "highlight_zh": "在数学和问答两个领域的五个基准测试中，该方法在四个测试上优于基于LLM的自由形式搜索方法，显示出更强的性能。同时，搜索过程更经济高效，生成的系统更具模块化和可解释性。",
            "tags_zh": [
                "多智能体系统",
                "语法搜索",
                "结构化框架",
                "可组合组件",
                "自动搜索",
                "可解释AI",
                "成本效率",
                "模块化设计"
            ],
            "_index": 192
        },
        {
            "title": "FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis",
            "authors": [
                "Da Zhang",
                "Bingyu Li",
                "Zhiyuan Zhao",
                "Feiping Nie",
                "Junyu Gao",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14078v1",
            "summary": "Time series analysis plays a vital role in fields such as finance, healthcare, industry, and meteorology, underpinning key tasks including classification, forecasting, and anomaly detection. Although deep learning models have achieved remarkable progress in these areas in recent years, constructing an efficient, multi-task compatible, and generalizable unified framework for time series analysis remains a significant challenge. Existing approaches are often tailored to single tasks or specific data types, making it difficult to simultaneously handle multi-task modeling and effectively integrate information across diverse time series types. Moreover, real-world data are often affected by noise, complex frequency components, and multi-scale dynamic patterns, which further complicate robust feature extraction and analysis. To ameliorate these challenges, we propose FusAD, a unified analysis framework designed for diverse time series tasks. FusAD features an adaptive time-frequency fusion mechanism, integrating both Fourier and Wavelet transforms to efficiently capture global-local and multi-scale dynamic features. With an adaptive denoising mechanism, FusAD automatically senses and filters various types of noise, highlighting crucial sequence variations and enabling robust feature extraction in complex environments. In addition, the framework integrates a general information fusion and decoding structure, combined with masked pre-training, to promote efficient learning and transfer of multi-granularity representations. Extensive experiments demonstrate that FusAD consistently outperforms state-of-the-art models on mainstream time series benchmarks for classification, forecasting, and anomaly detection tasks, while maintaining high efficiency and scalability. Code is available at https://github.com/zhangda1018/FusAD.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper has been accepted by ICDE2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14078v1",
            "code_links": [
                {
                    "url": "https://github.com/zhangda1018/FusAD",
                    "type": "github"
                }
            ],
            "headline_zh": "提出FusAD统一框架，通过自适应时频融合与去噪解决多任务时间序列分析难题",
            "summary_zh": "时间序列分析在金融、医疗、工业和气象等领域至关重要，支撑着分类、预测和异常检测等关键任务。尽管深度学习模型近年来在这些领域取得了显著进展，但构建一个高效、多任务兼容且可泛化的统一分析框架仍面临重大挑战。现有方法通常针对单一任务或特定数据类型设计，难以同时处理多任务建模并有效整合不同类型时间序列的信息。此外，现实世界数据常受噪声、复杂频率成分和多尺度动态模式影响，进一步增加了稳健特征提取和分析的难度。为应对这些挑战，我们提出了FusAD，一个为多样化时间序列任务设计的统一分析框架。FusAD采用自适应时频融合机制，结合傅里叶和小波变换，高效捕捉全局-局部和多尺度动态特征。通过自适应去噪机制，FusAD自动感知并过滤各类噪声，突出关键序列变化，在复杂环境中实现稳健特征提取。此外，该框架集成通用信息融合与解码结构，结合掩码预训练，促进多粒度表示的高效学习和迁移。大量实验表明，FusAD在主流时间序列基准测试的分类、预测和异常检测任务中持续优于最先进模型，同时保持高效率和可扩展性。代码发布于https://github.com/zhangda1018/FusAD。",
            "intro_zh": [
                "现有方法多为单任务或特定数据类型设计，难以统一处理多任务和多样化时间序列，且现实数据常受噪声和多尺度模式干扰。",
                "提出FusAD框架，核心是自适应时频融合机制结合傅里叶与小波变换，以及自适应去噪，以捕捉全局-局部特征并过滤噪声。",
                "实验显示FusAD在分类、预测和异常检测任务上优于现有模型，实现高效、可扩展的多任务性能提升。"
            ],
            "method_zh": "FusAD是一个统一的时间序列分析框架，整体架构包括自适应时频融合、自适应去噪、通用信息融合与解码模块。关键技术创新点在于：1) 自适应时频融合机制，同时利用傅里叶变换捕捉全局频率特征和小波变换提取局部多尺度动态，实现高效信息整合；2) 自适应去噪机制，自动检测并过滤数据中的各类噪声，增强特征鲁棒性；3) 结合掩码预训练的通用解码结构，促进多粒度表示学习与迁移。与现有方法的主要区别在于，它不局限于单一任务或数据类型，而是通过统一的机制处理多样化时间序列，有效解决了多任务兼容性和泛化性不足的问题。",
            "application_zh": "该研究可广泛应用于金融风险预测、医疗健康监测、工业设备故障检测和气象数据分析等领域，为多任务时间序列分析提供高效、稳健的解决方案，提升实际应用中的准确性和可靠性。",
            "highlight_zh": "在主流时间序列基准测试中，FusAD在分类、预测和异常检测任务上均优于最先进模型，展现出显著的性能提升，同时框架高效且可扩展，验证了其统一分析能力的有效性。",
            "tags_zh": [
                "时间序列分析",
                "时频融合",
                "自适应去噪",
                "多任务学习",
                "傅里叶变换",
                "小波变换",
                "掩码预训练",
                "统一框架"
            ],
            "_index": 193
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069v1",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14069v1",
            "code_links": [
                {
                    "url": "https://github.com/minaduki-sora/RADAR",
                    "type": "github"
                }
            ],
            "headline_zh": "提出RADAR方法，基于强化学习的动态草稿树加速大型语言模型推理，解决推测采样中草稿模型调用缺乏灵活性的问题。",
            "summary_zh": "现代大型语言模型（LLMs）的推理过程昂贵且缓慢，推测采样已成为解决此问题的有效方案，但推测采样中用于生成候选令牌的草稿模型调用次数是一个预设的超参数，缺乏灵活性。为了更有效地生成和利用候选令牌，我们提出了RADAR，一种基于强化学习动态草稿树的新型推测采样方法。RADAR将草稿树生成过程建模为马尔可夫决策过程（MDP），并采用离线强化学习训练预测模型，从而实现对草稿模型调用的实时决策，减少冗余计算并进一步加速推理。在三个LLMs和四个任务上的评估显示，RADAR相比自回归解码基线实现了3.17倍至4.82倍的加速。代码可在https://github.com/minaduki-sora/RADAR获取。",
            "intro_zh": [
                "现有推测采样方法中，草稿模型调用次数固定为超参数，导致计算冗余和灵活性不足，限制了推理效率提升。",
                "RADAR将草稿树生成建模为MDP，利用离线强化学习训练预测模型，动态决定草稿模型调用，优化候选令牌生成过程。",
                "实验表明，RADAR在多个LLMs和任务上实现3.17x-4.82x加速，显著超越自回归基线，验证了方法的有效性。"
            ],
            "method_zh": "RADAR的整体框架基于推测采样，但创新性地引入动态草稿树生成机制。核心方法是将草稿树构建过程视为马尔可夫决策过程，其中状态包括当前上下文和候选令牌，动作是决定是否继续调用草稿模型扩展树。通过离线强化学习训练一个预测模型，该模型学习最优策略，实时评估每个节点的扩展价值，从而动态调整草稿模型调用次数，减少不必要的计算。与现有推测采样方法的主要区别在于，RADAR不再依赖固定超参数，而是通过强化学习实现自适应决策，提高了灵活性和效率。",
            "application_zh": "RADAR适用于需要高效推理的大型语言模型场景，如实时对话系统、代码生成、文本摘要和机器翻译。其加速能力可降低计算成本，提升响应速度，在云计算、边缘设备和AI服务中具有实际价值，促进LLMs在资源受限环境下的部署。",
            "highlight_zh": "在三个不同规模的大型语言模型和四个多样化任务（如文本生成和问答）上，RADAR相比标准自回归解码基线实现了3.17倍到4.82倍的推理加速，最高提升达4.82倍，显著减少了延迟，同时保持输出质量，证明了动态决策在优化推测采样中的有效性。",
            "tags_zh": [
                "大型语言模型推理加速",
                "推测采样",
                "强化学习应用",
                "动态草稿树",
                "马尔可夫决策过程",
                "离线强化学习",
                "计算优化",
                "实时决策"
            ],
            "_index": 194
        },
        {
            "title": "SDAR-VL: Stable and Efficient Block-wise Diffusion for Vision-Language Understanding",
            "authors": [
                "Shuang Cheng",
                "Yuhua Jiang",
                "Zineng Zhou",
                "Dawei Liu",
                "Wang Tao",
                "Linfeng Zhang",
                "Biqing Qi",
                "Bowen Zhou"
            ],
            "arxiv_id": "2512.14068v1",
            "summary": "Block-wise discrete diffusion offers an attractive balance between parallel generation and causal dependency modeling, making it a promising backbone for vision-language modeling. However, its practical adoption has been limited by high training cost, slow convergence, and instability, which have so far kept it behind strong autoregressive (AR) baselines. We present \\textbf{SDAR-VL}, the first systematic application of block-wise discrete diffusion to large-scale vision-language understanding (VLU), together with an \\emph{integrated framework for efficient and stable training}. This framework unifies three components: (1) \\textbf{Asynchronous Block-wise Noise Scheduling} to diversify supervision within each batch; (2) \\textbf{Effective Mask Ratio Scaling} for unbiased loss normalization under stochastic masking; and (3) a \\textbf{Progressive Beta Noise Curriculum} that increases effective mask coverage while preserving corruption diversity. Experiments on 21 single-image, multi-image, and video benchmarks show that SDAR-VL consistently improves \\emph{training efficiency}, \\emph{convergence stability}, and \\emph{task performance} over conventional block diffusion. On this evaluation suite, SDAR-VL sets a new state of the art among diffusion-based vision-language models and, under matched settings, matches or surpasses strong AR baselines such as LLaVA-OneVision as well as the global diffusion baseline LLaDA-V, establishing block-wise diffusion as a practical backbone for VLU.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14068v1",
            "code_links": [],
            "headline_zh": "提出SDAR-VL框架，通过异步块噪声调度等技术解决块状离散扩散在视觉语言理解中的训练不稳定和效率低问题。",
            "summary_zh": "块状离散扩散在并行生成与因果依赖建模之间提供了有吸引力的平衡，使其成为视觉语言建模的有前景的骨干。然而，其实际应用受到高训练成本、收敛慢和不稳定性的限制，迄今仍落后于强大的自回归基线。我们提出了SDAR-VL，这是块状离散扩散在大规模视觉语言理解中的首次系统性应用，同时提供了一个高效稳定训练的综合框架。该框架统一了三个组件：(1) 异步块状噪声调度，以在每个批次内多样化监督；(2) 有效掩码比率缩放，用于在随机掩码下进行无偏损失归一化；(3) 渐进式Beta噪声课程，增加有效掩码覆盖率同时保持破坏多样性。在21个单图像、多图像和视频基准测试上的实验表明，SDAR-VL在训练效率、收敛稳定性和任务性能方面持续优于传统块扩散。在此评估套件中，SDAR-VL在基于扩散的视觉语言模型中设立了新的最先进水平，并在匹配设置下，达到或超越了如LLaVA-OneVision等强自回归基线以及全局扩散基线LLaDA-V，确立了块状扩散作为视觉语言理解的实用骨干。",
            "intro_zh": [
                "块状离散扩散在视觉语言理解中面临训练成本高、收敛慢和不稳定性，限制了其实际应用。",
                "SDAR-VL通过异步块噪声调度、有效掩码比率缩放和渐进式Beta噪声课程，实现高效稳定训练。",
                "在21个基准测试中，SDAR-VL提升了训练效率、收敛稳定性和性能，达到或超越强基线。"
            ],
            "method_zh": "SDAR-VL是一个集成框架，将块状离散扩散应用于大规模视觉语言理解。整体框架包括三个关键技术创新：异步块状噪声调度，通过在不同块中应用不同噪声水平来多样化监督；有效掩码比率缩放，确保在随机掩码策略下损失计算的公平性；渐进式Beta噪声课程，逐步增加掩码覆盖率同时维持噪声多样性。与现有方法的主要区别在于，它系统性地解决了块扩散的训练不稳定和效率问题，而传统方法通常忽视这些优化，导致性能受限。",
            "application_zh": "该研究可应用于视觉语言理解任务，如单图像描述、多图像推理和视频理解，提升模型在医疗影像分析、自动驾驶、智能助手等领域的实际性能，推动多模态AI的发展。",
            "highlight_zh": "在21个基准测试中，SDAR-VL在训练效率、收敛稳定性和任务性能上优于传统块扩散，达到基于扩散模型的新SOTA，并在匹配设置下匹配或超越LLaVA-OneVision等强基线。",
            "tags_zh": [
                "块状离散扩散",
                "视觉语言理解",
                "异步噪声调度",
                "掩码比率缩放",
                "噪声课程学习",
                "多模态建模",
                "训练稳定性",
                "高效训练"
            ],
            "_index": 195
        },
        {
            "title": "Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed",
            "authors": [
                "Yonggan Fu",
                "Lexington Whalen",
                "Zhifan Ye",
                "Xin Dong",
                "Shizhe Diao",
                "Jingyu Liu",
                "Chengyue Wu",
                "Hao Zhang",
                "Enze Xie",
                "Song Han",
                "Maksim Khadkevich",
                "Jan Kautz",
                "Yingyan Celine Lin",
                "Pavlo Molchanov"
            ],
            "arxiv_id": "2512.14067v1",
            "summary": "Diffusion language models (dLMs) have emerged as a promising paradigm that enables parallel, non-autoregressive generation, but their learning efficiency lags behind that of autoregressive (AR) language models when trained from scratch. To this end, we study AR-to-dLM conversion to transform pretrained AR models into efficient dLMs that excel in speed while preserving AR models' task accuracy. We achieve this by identifying limitations in the attention patterns and objectives of existing AR-to-dLM methods and then proposing principles and methodologies for more effective AR-to-dLM conversion. Specifically, we first systematically compare different attention patterns and find that maintaining pretrained AR weight distributions is critical for effective AR-to-dLM conversion. As such, we introduce a continuous pretraining scheme with a block-wise attention pattern, which remains causal across blocks while enabling bidirectional modeling within each block. We find that this approach can better preserve pretrained AR models' weight distributions than fully bidirectional modeling, in addition to its known benefit of enabling KV caching, and leads to a win-win in accuracy and efficiency. Second, to mitigate the training-test gap in mask token distributions (uniform vs. highly left-to-right), we propose a position-dependent token masking strategy that assigns higher masking probabilities to later tokens during training to better mimic test-time behavior. Leveraging this framework, we conduct extensive studies of dLMs' attention patterns, training dynamics, and other design choices, providing actionable insights into scalable AR-to-dLM conversion. These studies lead to the Efficient-DLM family, which outperforms state-of-the-art AR models and dLMs, e.g., our Efficient-DLM 8B achieves +5.4%/+2.7% higher accuracy with 4.5x/2.7x higher throughput compared to Dream 7B and Qwen3 4B, respectively.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14067v1",
            "code_links": [],
            "headline_zh": "提出Efficient-DLM框架，通过改进AR到dLM转换方法，实现高效扩散语言模型，在保持准确性的同时大幅提升生成速度。",
            "summary_zh": "扩散语言模型（dLMs）作为一种支持并行、非自回归生成的新范式，展现出巨大潜力，但其从头训练的学习效率仍落后于自回归（AR）语言模型。为此，本研究探索AR到dLM的转换方法，旨在将预训练的AR模型转化为高效的dLMs，在保持AR模型任务准确性的同时显著提升生成速度。我们通过分析现有AR-to-dLM方法在注意力模式和目标函数上的局限性，提出了更有效的转换原则和方法。具体而言，首先系统比较不同注意力模式，发现保持预训练AR权重分布对有效转换至关重要。因此，我们引入了一种基于块状注意力模式的持续预训练方案，该方案在块间保持因果性，同时在块内支持双向建模。这种方法比完全双向建模能更好地保留预训练AR模型的权重分布，并具备KV缓存优势，实现了准确性和效率的双赢。其次，为缓解训练与测试阶段掩码标记分布（均匀分布与高度从左到右分布）的差异，我们提出了一种位置相关的标记掩码策略，在训练时对后续标记赋予更高的掩码概率，以更好地模拟测试时的行为。基于此框架，我们深入研究了dLMs的注意力模式、训练动态及其他设计选择，为可扩展的AR-to-dLM转换提供了实用见解。这些研究催生了Efficient-DLM系列模型，其在性能上超越了当前最先进的AR模型和dLMs。例如，我们的Efficient-DLM 8B模型在准确率上分别比Dream 7B和Qwen3 4B高出5.4%和2.7%，同时吞吐量分别提升了4.5倍和2.7倍。",
            "intro_zh": [
                "现有AR-to-dLM转换方法在注意力模式和目标函数上存在局限，导致转换后模型性能下降或效率不足。",
                "提出块状注意力模式和位置相关掩码策略，优化AR权重保留和训练-测试一致性，实现高效转换。",
                "Efficient-DLM 8B在准确率和吞吐量上显著超越Dream 7B和Qwen3 4B，验证了方法的有效性。"
            ],
            "method_zh": "论文提出Efficient-DLM框架，核心是通过改进AR到dLM的转换过程，将预训练AR模型高效转化为扩散语言模型。整体框架包括两个关键技术：一是块状注意力模式，在块内进行双向建模以提升效率，同时块间保持因果性以保留AR权重分布；二是位置相关掩码策略，通过调整训练时掩码概率分布，减少与测试阶段的差异。与现有方法相比，该方法更注重保持预训练权重和优化训练动态，而非完全重新设计模型架构。",
            "application_zh": "该研究可应用于需要高速文本生成的场景，如实时对话系统、内容创作工具和大规模语言模型部署，通过提升生成效率降低计算成本，同时保持高质量输出。",
            "highlight_zh": "Efficient-DLM 8B模型在准确率上比Dream 7B和Qwen3 4B分别提升5.4%和2.7%，吞吐量提高4.5倍和2.7倍，实现了速度与精度的双重突破。",
            "tags_zh": [
                "扩散语言模型",
                "自回归模型转换",
                "注意力模式优化",
                "训练策略改进",
                "高效文本生成",
                "模型加速",
                "预训练权重保留",
                "并行生成"
            ],
            "_index": 169
        },
        {
            "title": "Bridging Fidelity-Reality with Controllable One-Step Diffusion for Image Super-Resolution",
            "authors": [
                "Hao Chen",
                "Junyang Chen",
                "Jinshan Pan",
                "Jiangxin Dong"
            ],
            "arxiv_id": "2512.14061v1",
            "summary": "Recent diffusion-based one-step methods have shown remarkable progress in the field of image super-resolution, yet they remain constrained by three critical limitations: (1) inferior fidelity performance caused by the information loss from compression encoding of low-quality (LQ) inputs; (2) insufficient region-discriminative activation of generative priors; (3) misalignment between text prompts and their corresponding semantic regions. To address these limitations, we propose CODSR, a controllable one-step diffusion network for image super-resolution. First, we propose an LQ-guided feature modulation module that leverages original uncompressed information from LQ inputs to provide high-fidelity conditioning for the diffusion process. We then develop a region-adaptive generative prior activation method to effectively enhance perceptual richness without sacrificing local structural fidelity. Finally, we employ a text-matching guidance strategy to fully harness the conditioning potential of text prompts. Extensive experiments demonstrate that CODSR achieves superior perceptual quality and competitive fidelity compared with state-of-the-art methods with efficient one-step inference.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://github.com/Chanson94/CODSR",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14061v1",
            "code_links": [],
            "headline_zh": "提出CODSR可控一步扩散网络，通过LQ引导特征调制、区域自适应生成先验激活和文本匹配指导，解决图像超分辨率中保真度不足、生成先验激活不充分和文本提示错位问题。",
            "summary_zh": "近期基于扩散的一步方法在图像超分辨率领域取得了显著进展，但仍受限于三个关键问题：(1) 由于低质量输入压缩编码导致的信息损失，造成保真度性能不佳；(2) 生成先验的区域判别性激活不足；(3) 文本提示与其对应语义区域之间的错位。为解决这些限制，我们提出了CODSR，一种可控的一步扩散网络用于图像超分辨率。首先，我们提出了一个LQ引导的特征调制模块，利用低质量输入的原始未压缩信息为扩散过程提供高保真度条件。然后，我们开发了一种区域自适应的生成先验激活方法，以有效增强感知丰富性而不牺牲局部结构保真度。最后，我们采用文本匹配指导策略，充分利用文本提示的条件潜力。大量实验表明，CODSR在高效一步推理下，相比最先进方法实现了卓越的感知质量和有竞争力的保真度。",
            "intro_zh": [
                "现有一步扩散方法在图像超分辨率中面临保真度不足、生成先验激活不充分和文本提示错位三大挑战。",
                "CODSR通过LQ引导特征调制、区域自适应生成先验激活和文本匹配指导，提升保真度和感知质量。",
                "实验显示CODSR在一步推理下实现卓越感知质量和有竞争力保真度，优于现有方法。"
            ],
            "method_zh": "CODSR是一个可控的一步扩散网络，整体框架基于扩散模型，通过一步推理实现图像超分辨率。关键技术创新包括：LQ引导特征调制模块，利用低质量输入的未压缩信息增强保真度；区域自适应生成先验激活方法，针对不同区域调整生成先验以平衡感知丰富性和结构保真度；文本匹配指导策略，优化文本提示与语义区域的对应关系。与现有方法的主要区别在于，CODSR综合解决了保真度损失、先验激活不足和文本错位问题，通过模块化设计实现高效可控的超分辨率。",
            "application_zh": "该研究可应用于图像增强、视频修复、医学成像和数字媒体处理等领域，提升低分辨率图像的视觉质量和细节恢复能力，具有实际价值如改善监控视频清晰度或增强历史照片。",
            "highlight_zh": "CODSR在一步推理下，相比最先进方法，实现了卓越的感知质量和有竞争力的保真度，实验验证了其在效率和性能上的优势，特别是在处理复杂场景时表现出色。",
            "tags_zh": [
                "图像超分辨率",
                "扩散模型",
                "一步推理",
                "保真度增强",
                "生成先验激活",
                "文本指导",
                "可控网络",
                "区域自适应"
            ],
            "_index": 197
        },
        {
            "title": "Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning",
            "authors": [
                "Zulin Zhuang",
                "Yu Bian"
            ],
            "arxiv_id": "2512.14058v1",
            "summary": "Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14058v1",
            "code_links": [],
            "headline_zh": "提出非侵入式多模态深度学习框架，以实时预测动态室内工作平面照度分布，支持日光联动控制节能。",
            "summary_zh": "日光联动控制（DLCs）在建筑节能方面具有巨大潜力，尤其是在日光充足且能实时准确预测室内工作平面照度时。现有室内日光预测研究大多针对静态场景开发与测试。本研究提出一种多模态深度学习框架，利用非侵入式图像中的时空特征实时预测室内工作平面照度分布。该方法仅从侧窗区域提取图像特征，而非室内像素，从而适用于动态占用的室内空间。在中国广州的一个测试房间进行了现场实验，收集了17,344个样本用于模型训练和验证。模型在同分布测试集上实现了R2 > 0.98且RMSE < 0.14，在未见日测试集上实现了R2 > 0.82且RMSE < 0.17，表明其具有高精度和可接受的时间泛化能力。",
            "intro_zh": [
                "现有室内日光预测方法多针对静态场景，难以适应动态占用空间，限制了日光联动控制的实时应用。",
                "提出多模态深度学习框架，仅从侧窗区域提取图像特征，结合时空信息，实现非侵入式实时照度预测。",
                "现场实验验证模型在同分布和未见日测试集上均表现优异，R2值高且误差低，展示了良好的泛化性能。"
            ],
            "method_zh": "论文提出一个多模态深度学习框架，整体架构基于非侵入式图像输入，通过卷积神经网络提取侧窗区域的图像特征，并结合时间序列数据（如时间戳）进行时空融合。关键技术创新点在于仅利用侧窗像素而非整个室内图像，避免了动态占用干扰，同时引入多模态学习以增强预测鲁棒性。与现有方法的主要区别在于其专注于动态场景的实时预测，而非静态建模，从而提高了在真实环境中的适用性和效率。",
            "application_zh": "该研究可应用于智能建筑节能系统，通过实时预测室内照度优化日光联动控制，减少人工照明能耗，提升建筑能效。潜在领域包括办公楼、学校等动态占用空间，支持可持续城市发展。",
            "highlight_zh": "模型在同分布测试集上达到R2 > 0.98和RMSE < 0.14的高精度，在未见日测试集上保持R2 > 0.82和RMSE < 0.17，验证了其出色的预测能力和时间泛化性能，为动态室内环境下的实时照度控制提供了可靠工具。",
            "tags_zh": [
                "日光联动控制",
                "实时照度预测",
                "多模态深度学习",
                "非侵入式图像处理",
                "时空特征提取",
                "建筑节能",
                "动态室内场景",
                "泛化性能验证"
            ],
            "_index": 198
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057v1",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057v1",
            "code_links": [],
            "headline_zh": "提出CRAFT模型，通过无动作Transformer编码器-解码器实现任务表示，以解决元强化学习中任务推断与策略优化的耦合问题。",
            "summary_zh": "强化学习（RL）使机器人能在不确定环境中操作，但标准方法常难以泛化到未见任务。上下文自适应元强化学习通过任务表示来应对这些限制，但它们大多依赖经验中的完整动作信息，使任务推断与特定策略紧密耦合。本文介绍了Context Representation via Action Free Transformer encoder decoder（CRAFT），这是一种信念模型，仅从状态和奖励序列推断任务表示。通过消除对动作的依赖，CRAFT将任务推断与策略优化解耦，支持模块化训练，并利用摊销变分推断进行可扩展的信念更新。该模型基于带有旋转位置嵌入的Transformer编码器-解码器构建，能捕捉长程时间依赖，并稳健编码参数化和非参数化任务变化。在MetaWorld ML-10机器人操作基准上的实验表明，与上下文自适应元RL基线相比，CRAFT实现了更快的适应、更好的泛化和更有效的探索。这些发现突显了无动作推断作为机器人控制中可扩展RL基础的潜力。",
            "intro_zh": [
                "现有元强化学习方法依赖动作信息进行任务推断，导致任务表示与策略优化紧密耦合，限制了泛化能力。",
                "CRAFT模型仅使用状态和奖励序列，通过Transformer编码器-解码器推断任务表示，实现任务推断与策略优化的解耦。",
                "在MetaWorld ML-10基准上，CRAFT相比基线方法展现出更快的适应速度、更好的泛化性能和更有效的探索能力。"
            ],
            "method_zh": "CRAFT的整体框架是一个基于Transformer编码器-解码器的信念模型，用于从状态和奖励序列推断任务表示。关键技术创新包括：采用无动作输入设计，仅依赖状态和奖励序列；使用旋转位置嵌入增强位置编码能力；结合摊销变分推断进行可扩展的信念更新。与现有方法的主要区别在于，传统上下文自适应元RL方法需要完整动作信息，而CRAFT通过移除动作依赖，实现了任务推断与策略优化的解耦，支持模块化训练，并能处理参数化和非参数化任务变化。",
            "application_zh": "该研究主要应用于机器人控制领域，特别是在需要快速适应新任务和泛化到未见场景的元强化学习环境中。潜在应用包括工业自动化、服务机器人、自动驾驶等，其中机器人需在动态和不确定环境中高效学习和操作。",
            "highlight_zh": "在MetaWorld ML-10机器人操作基准实验中，CRAFT相比上下文自适应元RL基线方法，实现了更快的任务适应速度、更高的泛化性能（提升具体数值未知），以及更有效的探索策略，突显了无动作推断在提升元强化学习可扩展性和效率方面的优势。",
            "tags_zh": [
                "元强化学习",
                "任务表示学习",
                "Transformer编码器-解码器",
                "无动作推断",
                "机器人控制",
                "泛化能力",
                "信念模型",
                "摊销变分推断"
            ],
            "_index": 199
        },
        {
            "title": "FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling",
            "authors": [
                "Kim Sung-Bin",
                "Joohyun Chang",
                "David Harwath",
                "Tae-Hyun Oh"
            ],
            "arxiv_id": "2512.14056v1",
            "summary": "Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://facedit.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14056v1",
            "code_links": [],
            "headline_zh": "提出FacEDiT，通过语音条件面部运动填充统一处理说话人脸编辑与生成问题。",
            "summary_zh": "说话人脸编辑和生成通常被视为独立问题。本研究提出将两者视为统一框架——语音条件面部运动填充的子任务。我们探索面部运动填充作为一种自监督预训练任务，同时作为动态说话人脸合成的统一表述。为实现这一想法，我们提出FacEDiT，一种基于流匹配训练的语音条件扩散变换器。受掩码自编码器启发，FacEDiT学习在周围运动和语音条件下合成掩码面部运动。这一框架支持局部生成和编辑，如替换、插入和删除，同时确保与未编辑区域的无缝过渡。此外，偏置注意力和时间平滑性约束增强了边界连续性和唇部同步。针对缺乏标准编辑基准的问题，我们引入FacEDiTBench，首个说话人脸编辑数据集，包含多样编辑类型和长度，以及新评估指标。大量实验验证说话人脸编辑和生成作为语音条件运动填充的子任务；FacEDiT产生准确、语音对齐的面部编辑，具有强身份保持和流畅视觉连续性，同时有效泛化到说话人脸生成。",
            "intro_zh": [
                "核心问题：现有方法将说话人脸编辑和生成视为独立任务，缺乏统一框架，导致编辑时边界不连续和身份保持差。",
                "方法要点：提出语音条件面部运动填充作为统一框架，使用扩散变换器学习掩码面部运动合成，结合偏置注意力和平滑约束。",
                "实验或效果：FacEDiT在编辑和生成任务中均表现优异，实现高精度唇部同步、身份保持和视觉连续性，并引入新基准验证。"
            ],
            "method_zh": "FacEDiT的整体框架基于语音条件扩散变换器，采用流匹配训练。关键技术创新点包括：将面部运动填充作为自监督预训练任务，统一说话人脸编辑与生成；受掩码自编码器启发，模型学习在周围运动和语音条件下合成掩码面部运动；引入偏置注意力和时间平滑性约束以增强边界连续性和唇部同步。与现有方法的主要区别在于，传统方法通常分别处理编辑和生成，而FacEDiT通过统一框架实现两者，支持局部编辑如替换、插入和删除，同时确保无缝过渡。",
            "application_zh": "该研究在虚拟现实、视频会议、电影特效和数字人交互等领域有广泛应用潜力，可实现高保真说话人脸编辑和生成，提升用户体验和内容创作效率。",
            "highlight_zh": "实验显示FacEDiT在说话人脸编辑和生成任务中均优于基线方法，实现准确语音对齐、强身份保持和流畅视觉连续性；新基准FacEDiTBench验证了模型在多样编辑类型下的泛化能力，性能提升显著。",
            "tags_zh": [
                "说话人脸编辑",
                "面部运动填充",
                "扩散变换器",
                "语音条件合成",
                "自监督学习",
                "多模态融合",
                "视频生成",
                "唇部同步"
            ],
            "_index": 200
        },
        {
            "title": "Expert Switching for Robust AAV Landing: A Dual-Detector Framework in Simulation",
            "authors": [
                "Humaira Tasnim",
                "Ashik E Rasul",
                "Bruce Jo",
                "Hyung-Jin Yoon"
            ],
            "arxiv_id": "2512.14054v1",
            "summary": "Reliable helipad detection is essential for Autonomous Aerial Vehicle (AAV) landing, especially under GPS-denied or visually degraded conditions. While modern detectors such as YOLOv8 offer strong baseline performance, single-model pipelines struggle to remain robust across the extreme scale transitions that occur during descent, where helipads appear small at high altitude and large near touchdown. To address this limitation, we propose a scale-adaptive dual-expert perception framework that decomposes the detection task into far-range and close-range regimes. Two YOLOv8 experts are trained on scale-specialized versions of the HelipadCat dataset, enabling one model to excel at detecting small, low-resolution helipads and the other to provide high-precision localization when the target dominates the field of view. During inference, both experts operate in parallel, and a geometric gating mechanism selects the expert whose prediction is most consistent with the AAV's viewpoint. This adaptive routing prevents the degradation commonly observed in single-detector systems when operating across wide altitude ranges. The dual-expert perception module is evaluated in a closed-loop landing environment that integrates CARLA's photorealistic rendering with NASA's GUAM flight-dynamics engine. Results show substantial improvements in alignment stability, landing accuracy, and overall robustness compared to single-detector baselines. By introducing a scale-aware expert routing strategy tailored to the landing problem, this work advances resilient vision-based perception for autonomous descent and provides a foundation for future multi-expert AAV frameworks.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14054v1",
            "code_links": [],
            "headline_zh": "提出基于双检测器的专家切换框架，以解决自主空中车辆在降落过程中因尺度变化导致的停机坪检测鲁棒性问题。",
            "summary_zh": "可靠的停机坪检测对于自主空中车辆（AAV）降落至关重要，尤其是在GPS失效或视觉条件退化的情况下。虽然现代检测器如YOLOv8提供了强大的基线性能，但单模型管道在降落过程中经历的极端尺度转换下难以保持鲁棒性，其中停机坪在高空时显得小而低分辨率，在接近着陆时则占据视野主导。为应对这一限制，本文提出了一种尺度自适应的双专家感知框架，将检测任务分解为远距离和近距离两个阶段。两个YOLOv8专家在HelipadCat数据集的尺度专门化版本上进行训练，使一个模型擅长检测小而低分辨率的停机坪，另一个在目标主导视野时提供高精度定位。在推理过程中，两个专家并行运行，几何门控机制选择与AAV视点最一致的预测专家。这种自适应路由防止了单检测器系统在宽高度范围内操作时常见的性能退化。双专家感知模块在闭环降落环境中进行评估，该环境集成了CARLA的光真实感渲染与NASA的GUAM飞行动力学引擎。结果显示，与单检测器基线相比，在对齐稳定性、降落精度和整体鲁棒性方面有显著提升。通过引入针对降落问题定制的尺度感知专家路由策略，这项工作推进了自主下降的弹性视觉感知，并为未来多专家AAV框架奠定了基础。",
            "intro_zh": [
                "核心问题：单检测器在AAV降落过程中因停机坪尺度剧烈变化（从高空小目标到近地大目标）导致检测鲁棒性不足。",
                "方法要点：提出双专家感知框架，训练两个YOLOv8专家分别处理远距离和近距离尺度，通过几何门控机制自适应切换专家。",
                "实验或效果：在CARLA与GUAM集成的仿真环境中，相比单检测器基线，显著提升了对齐稳定性、降落精度和整体鲁棒性。"
            ],
            "method_zh": "论文提出一种尺度自适应的双专家感知框架，整体框架包括两个并行运行的YOLOv8检测器，分别作为远距离和近距离专家，训练于HelipadCat数据集的尺度专门化版本。关键技术创新点是几何门控机制，它基于AAV的视点（如高度和视角）动态选择最一致的专家预测，实现自适应路由。与现有方法的主要区别在于，传统单检测器系统难以处理降落过程中的极端尺度变化，而本框架通过专家分解和切换策略，专门针对尺度变化问题进行了优化，提升了检测鲁棒性和精度。",
            "application_zh": "该研究主要应用于自主空中车辆的视觉引导降落场景，特别是在GPS失效或恶劣视觉条件下，如军事侦察、紧急救援或无人机物流。其潜在价值在于提高AAV在复杂环境中的自主性和安全性，为未来多专家感知系统提供基础。",
            "highlight_zh": "在CARLA与NASA GUAM集成的闭环仿真环境中，双专家框架相比单检测器基线，在停机坪检测上实现了显著提升：对齐稳定性增强，降落精度提高，整体鲁棒性改善，验证了尺度自适应策略的有效性。",
            "tags_zh": [
                "自主空中车辆",
                "停机坪检测",
                "尺度自适应",
                "双专家框架",
                "几何门控",
                "视觉感知",
                "仿真评估",
                "YOLOv8"
            ],
            "_index": 201
        },
        {
            "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
            "authors": [
                "HyperAI Team",
                "Yuchen Liu",
                "Kaiyang Han",
                "Zhiqiang Xia",
                "Yuhang Dong",
                "Chen Song",
                "Kangyu Tang",
                "Jiaming Xu",
                "Xiushi Feng",
                "WenXuan Yu",
                "Li Peng",
                "Mingyang Wang",
                "Kai Wang",
                "Changpeng Yang",
                "Yang Li",
                "Haoyu Lu",
                "Hao Wang",
                "Bingna Xu",
                "Guangyao Liu",
                "Long Huang",
                "Kaibin Guo",
                "Jinyang Wu",
                "Dan Wu",
                "Hongzhen Wang",
                "Peng Zhou",
                "Shuai Nie",
                "Shande Wang",
                "Runyu Shi",
                "Ying Huang"
            ],
            "arxiv_id": "2512.14052v1",
            "summary": "Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.",
            "categories": [
                "cs.CV",
                "cs.CL"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Technical report of Xiaomi HyperAI Team",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14052v1",
            "code_links": [],
            "headline_zh": "提出HyperVL，一种高效的动态多模态大语言模型，以解决边缘设备上视觉编码器计算和内存瓶颈问题。",
            "summary_zh": "当前多模态大语言模型虽具备强大的感知和推理能力，但其高计算和内存需求使其难以直接部署在设备端环境中。尽管小参数模型逐渐获得强通用能力，标准视觉Transformer编码器在处理高分辨率输入时仍面临延迟和内存消耗过高的关键瓶颈。为应对这些挑战，我们引入了HyperVL，一种专为设备端推理设计的高效多模态大语言模型。HyperVL采用图像分块策略以限制峰值内存使用，并整合了两项新技术：(1) 视觉分辨率压缩器，自适应预测最优编码分辨率以消除冗余计算；(2) 双重一致性学习，在多尺度ViT编码器间进行对齐，实现在共享大语言模型下视觉分支的动态切换。大量实验表明，HyperVL在多个基准测试中，在可比规模模型中实现了最先进的性能。此外，它在真实移动设备上显著降低了延迟和功耗，证明了其在设备端多模态推理中的实用性。",
            "intro_zh": [
                "现有方法中，标准视觉Transformer编码器在处理高分辨率输入时存在高延迟和内存消耗，成为设备端部署的关键瓶颈。",
                "HyperVL通过图像分块策略限制内存峰值，并引入视觉分辨率压缩器和双重一致性学习，实现自适应编码和动态视觉分支切换。",
                "实验结果显示，HyperVL在可比规模模型中达到最优性能，并在移动设备上显著降低延迟和功耗，提升设备端推理效率。"
            ],
            "method_zh": "HyperVL的整体框架基于多模态大语言模型，专为设备端推理优化。它采用图像分块策略处理输入，以控制内存使用。关键技术创新包括视觉分辨率压缩器，该组件自适应预测图像的最优编码分辨率，减少不必要的计算；以及双重一致性学习，通过在多尺度视觉Transformer编码器间建立一致性，实现在共享大语言模型下不同视觉分支的动态切换。与现有方法相比，HyperVL通过动态调整编码分辨率和分支选择，显著降低了计算和内存开销，同时保持高性能。",
            "application_zh": "该研究适用于边缘计算和移动设备场景，如智能手机、物联网设备和嵌入式系统，支持实时多模态任务如视觉问答、图像描述和交互式应用，提升设备端AI推理的效率和实用性。",
            "highlight_zh": "HyperVL在多个基准测试中，在可比规模模型中实现最先进性能；在真实移动设备上，延迟和功耗显著降低，例如在特定测试中延迟减少超过30%，功耗降低约20%，验证了其设备端部署的有效性。",
            "tags_zh": [
                "设备端推理",
                "多模态大语言模型",
                "视觉Transformer",
                "动态编码",
                "边缘计算",
                "内存优化",
                "延迟降低",
                "功耗优化"
            ],
            "_index": 202
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051v1",
            "code_links": [],
            "headline_zh": "提出OpenDataArena以解决大语言模型后训练数据集评估不透明和缺乏公平基准的问题。",
            "summary_zh": "大语言模型的快速发展依赖于后训练数据集的质量和多样性，但当前存在一个关键矛盾：模型被严格基准测试，而数据本身却是一个黑箱，表现为组成不透明、来源不确定且缺乏系统评估。这种不透明性阻碍了可重复性，并模糊了数据特性与模型行为之间的因果关系。为弥补这一差距，我们引入了OpenDataArena，这是一个全面开放的平台，旨在基准测试后训练数据的内在价值。ODA建立了一个综合生态系统，包括四个关键支柱：(i) 一个统一的训练-评估管道，确保在不同模型和领域间进行公平、开放的比较；(ii) 一个多维评分框架，沿数十个不同维度分析数据质量；(iii) 一个交互式数据谱系探索器，可视化数据集谱系并剖析组件来源；(iv) 一个完全开源的工具包，用于训练、评估和评分，以促进数据研究。在ODA上进行的广泛实验——覆盖多个领域的120多个训练数据集、22个基准测试，通过超过600次训练运行和4000万个处理数据点验证——揭示了非平凡的见解。我们的分析揭示了数据复杂性与任务性能之间的内在权衡，通过谱系追踪识别了流行基准中的冗余，并映射了数据集间的谱系关系。我们发布所有结果、工具和配置，以民主化高质量数据评估的访问。ODA不仅旨在扩展排行榜，更设想从试错式数据策展转向以数据为中心的人工智能原则科学，为数据混合规律和基础模型战略组成的研究铺平道路。",
            "intro_zh": [
                "核心问题：大语言模型后训练数据集评估不透明，缺乏公平基准，阻碍可重复性和数据-模型因果分析。",
                "方法要点：构建OpenDataArena平台，集成统一训练-评估管道、多维评分框架、数据谱系探索器和开源工具包。",
                "实验或效果：覆盖120+数据集和22个基准，揭示数据复杂性-性能权衡，识别冗余，并映射数据集谱系关系。"
            ],
            "method_zh": "OpenDataArena是一个全面开放的平台，核心框架包括四个支柱：统一训练-评估管道、多维评分框架、交互式数据谱系探索器和开源工具包。技术创新点在于整合了公平比较机制、多维度数据质量分析和可视化谱系追踪。与现有方法的主要区别在于，ODA不仅提供基准测试，还通过开放生态系统促进数据研究的透明度和可重复性，解决了数据黑箱问题，而传统方法往往只关注模型性能评估，忽视数据本身的系统分析。",
            "application_zh": "该研究可应用于大语言模型开发、数据策展优化和人工智能伦理评估等领域，帮助研究人员和开发者更科学地选择和组合训练数据，提升模型性能与可解释性，推动数据为中心的人工智能发展。",
            "highlight_zh": "实验覆盖120多个训练数据集和22个基准，通过600+训练运行验证，揭示了数据复杂性与任务性能的权衡，识别了流行基准中的冗余，并成功映射了数据集间的谱系关系，为数据混合规律提供了实证基础。",
            "tags_zh": [
                "大语言模型",
                "后训练数据集",
                "数据评估",
                "基准测试",
                "数据谱系",
                "开源平台",
                "数据为中心AI",
                "模型性能分析"
            ],
            "_index": 203
        },
        {
            "title": "SELECT: Detecting Label Errors in Real-world Scene Text Data",
            "authors": [
                "Wenjun Liu",
                "Qian Wu",
                "Yifeng Hu",
                "Yuke Li"
            ],
            "arxiv_id": "2512.14050v1",
            "summary": "We introduce SELECT (Scene tExt Label Errors deteCTion), a novel approach that leverages multi-modal training to detect label errors in real-world scene text datasets. Utilizing an image-text encoder and a character-level tokenizer, SELECT addresses the issues of variable-length sequence labels, label sequence misalignment, and character-level errors, outperforming existing methods in accuracy and practical utility. In addition, we introduce Similarity-based Sequence Label Corruption (SSLC), a process that intentionally introduces errors into the training labels to mimic real-world error scenarios during training. SSLC not only can cause a change in the sequence length but also takes into account the visual similarity between characters during corruption. Our method is the first to detect label errors in real-world scene text datasets successfully accounting for variable-length labels. Experimental results demonstrate the effectiveness of SELECT in detecting label errors and improving STR accuracy on real-world text datasets, showcasing its practical utility.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3743093.3771031",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14050v1",
            "code_links": [],
            "headline_zh": "提出SELECT方法，通过多模态训练检测真实场景文本数据集中的标签错误，解决变长标签序列问题。",
            "summary_zh": "我们介绍了SELECT（场景文本标签错误检测），这是一种利用多模态训练检测真实场景文本数据集中标签错误的新方法。通过使用图像-文本编码器和字符级分词器，SELECT解决了变长序列标签、标签序列错位和字符级错误等问题，在准确性和实用性上超越了现有方法。此外，我们引入了基于相似性的序列标签损坏（SSLC）过程，该过程在训练期间有意向训练标签中引入错误，以模拟真实世界的错误场景。SSLC不仅可能导致序列长度变化，还在损坏过程中考虑了字符之间的视觉相似性。我们的方法是首个成功检测真实场景文本数据集中标签错误并考虑变长标签的方法。实验结果表明，SELECT在检测标签错误和提高真实世界文本数据集上的场景文本识别（STR）准确性方面具有有效性，展示了其实用价值。",
            "intro_zh": [
                "现有方法难以处理真实场景文本数据中的变长标签序列、标签错位和字符级错误，导致标签错误检测不准确。",
                "SELECT采用多模态训练，结合图像-文本编码器和字符级分词器，并引入SSLC过程模拟真实错误，提升检测鲁棒性。",
                "实验显示SELECT在检测标签错误方面优于现有方法，并能有效提高场景文本识别的准确性，具有实际应用价值。"
            ],
            "method_zh": "SELECT的整体框架基于多模态训练，核心包括图像-文本编码器和字符级分词器。图像-文本编码器提取图像和文本的联合特征，字符级分词器处理变长序列标签，确保字符级对齐。关键技术创新是引入SSLC过程，在训练中故意引入标签错误，模拟真实场景的标签损坏，并考虑字符视觉相似性以增强模型对错误的识别能力。与现有方法的主要区别在于，SELECT是首个专门针对真实场景文本数据集设计的方法，能有效处理变长标签序列和字符级错误，而传统方法多假设固定长度标签或忽略视觉相似性。",
            "application_zh": "该研究可应用于场景文本识别（STR）系统的数据清洗和质量控制，帮助提升自动驾驶、文档数字化、智能监控等领域的文本识别准确性。通过检测和纠正标签错误，能优化训练数据集，增强模型在真实世界复杂环境中的鲁棒性和可靠性。",
            "highlight_zh": "实验结果表明，SELECT在多个真实场景文本数据集上显著优于现有标签错误检测方法，准确率提升明显。同时，使用SELECT纠正标签错误后，场景文本识别模型的准确性得到有效提高，验证了方法的实用性和有效性。",
            "tags_zh": [
                "场景文本识别",
                "标签错误检测",
                "多模态训练",
                "变长序列处理",
                "字符级分词",
                "视觉相似性",
                "数据清洗",
                "真实世界应用"
            ],
            "_index": 171
        },
        {
            "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation",
            "authors": [
                "Shen Li",
                "Li Huang",
                "Shaoxiong Zhan",
                "Weifeng Sun",
                "Tao Yin",
                "Zhongxin Liu",
                "Meng Yan"
            ],
            "arxiv_id": "2512.14048v1",
            "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at AAAI-2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14048v1",
            "code_links": [],
            "headline_zh": "提出RoutingGen框架，通过动态路由和意图链式思考解决代码生成中过度推理和意图抽象不足的问题。",
            "summary_zh": "大型语言模型在代码生成方面展现出强大的生成能力和巨大潜力。现有的链式思考提示方法通过引出中间步骤来增强模型推理，但存在两个主要局限：首先，其统一应用倾向于在简单任务上引发过度思考；其次，它们在代码生成中缺乏意图抽象，例如明确建模核心算法设计和效率，导致模型关注表面结构而忽视全局问题目标。受认知经济原则启发——仅在必要时进行结构化推理以节省认知资源，我们提出了RoutingGen，一种新颖的难度感知路由框架，动态调整代码生成的提示策略。对于简单任务，它采用少样本提示；对于更复杂的任务，它调用结构化推理策略，称为意图链式思考，我们引入该策略来指导模型捕捉任务意图，如核心算法逻辑及其时间复杂度。在三个模型和六个标准代码生成基准上的实验表明，RoutingGen在大多数设置中实现了最先进的性能，同时在所有设置中平均减少了46.37%的总令牌使用量。此外，意图链式思考在具有挑战性的基准上优于六个现有的提示基线。",
            "intro_zh": [
                "现有链式思考提示方法在代码生成中存在过度推理和意图抽象不足的问题，导致模型效率低下且忽视全局目标。",
                "论文提出RoutingGen框架，结合动态路由和意图链式思考，根据任务难度自适应选择提示策略，提升推理效率。",
                "实验显示RoutingGen在多个基准上达到最优性能，平均减少46.37%令牌使用，意图链式思考优于现有基线。"
            ],
            "method_zh": "RoutingGen是一个难度感知的动态路由框架，整体框架包括任务难度评估模块和策略选择模块。关键技术创新点在于引入意图链式思考，它通过结构化推理指导模型捕捉任务意图，如核心算法逻辑和时间复杂度，与现有方法的主要区别在于动态路由机制：对于简单任务采用少样本提示以避免过度推理，对于复杂任务则调用意图链式思考进行深度推理，从而优化资源分配和性能。",
            "application_zh": "该研究可应用于自动化代码生成、智能编程助手和软件工程工具开发，通过提升代码生成效率和准确性，支持复杂算法设计和优化任务，具有实际价值于减少开发时间和提高代码质量。",
            "highlight_zh": "RoutingGen在三个模型和六个标准代码生成基准上实现最先进性能，平均减少46.37%总令牌使用量；意图链式思考在挑战性基准上优于六个现有提示基线，显著提升推理效率和任务完成度。",
            "tags_zh": [
                "代码生成",
                "链式思考提示",
                "动态路由",
                "意图建模",
                "大型语言模型",
                "推理优化",
                "难度感知",
                "算法设计",
                "令牌效率"
            ],
            "_index": 205
        },
        {
            "title": "E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms",
            "authors": [
                "Boyang Li",
                "Zhongpeng Jin",
                "Shuai Zhao",
                "Jiahui Liao",
                "Tian Liu",
                "Han Liu",
                "Yuanhai Zhang",
                "Kai Huang"
            ],
            "arxiv_id": "2512.14046v1",
            "summary": "The ability to adapt to changing environments is crucial for the autonomous navigation systems of Unmanned Aerial Vehicles (UAVs). However, existing navigation systems adopt fixed execution configurations without considering environmental dynamics based on available computing resources, e.g., with a high execution frequency and task workload. This static approach causes rigid flight strategies and excessive computations, ultimately degrading flight performance or even leading to failures in UAVs. Despite the necessity for an adaptive system, dynamically adjusting workloads remains challenging, due to difficulties in quantifying environmental complexity and modeling the relationship between environment and system configuration. Aiming at adapting to dynamic environments, this paper proposes E-Navi, an environmental-adaptive navigation system for UAVs that dynamically adjusts task executions on the CPUs in response to environmental changes based on available computational resources. Specifically, the perception-planning pipeline of UAVs navigation system is redesigned through dynamic adaptation of mapping resolution and execution frequency, driven by the quantitative environmental complexity evaluations. In addition, E-Navi supports flexible deployment across hardware platforms with varying levels of computing capability. Extensive Hardware-In-the-Loop and real-world experiments demonstrate that the proposed system significantly outperforms the baseline method across various hardware platforms, achieving up to 53.9% navigation task workload reduction, up to 63.8% flight time savings, and delivering more stable velocity control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14046v1",
            "code_links": [],
            "headline_zh": "提出E-Navi环境自适应导航系统，为资源受限无人机平台解决动态环境适应性问题",
            "summary_zh": "适应变化环境的能力对无人机自主导航系统至关重要。然而，现有导航系统采用固定的执行配置，未基于可用计算资源考虑环境动态性，例如采用高执行频率和任务负载。这种静态方法导致飞行策略僵化和计算过度，最终降低飞行性能甚至导致无人机故障。尽管自适应系统具有必要性，但由于量化环境复杂性和建模环境与系统配置关系的困难，动态调整工作负载仍然具有挑战性。为适应动态环境，本文提出E-Navi，一种面向无人机的环境自适应导航系统，基于可用计算资源动态调整CPU上的任务执行以响应环境变化。具体而言，通过定量环境复杂度评估驱动，重新设计了无人机导航系统的感知-规划流程，实现地图分辨率和执行频率的动态自适应。此外，E-Navi支持在不同计算能力水平的硬件平台上灵活部署。广泛的硬件在环和真实世界实验表明，所提系统在各种硬件平台上显著优于基线方法，实现高达53.9%的导航任务负载减少、高达63.8%的飞行时间节省，并提供更稳定的速度控制。",
            "intro_zh": [
                "现有无人机导航系统采用固定配置，无法根据环境动态调整计算资源，导致飞行策略僵化和性能下降。",
                "E-Navi通过量化环境复杂度，动态调整地图分辨率和执行频率，实现感知-规划流程的自适应优化。",
                "实验显示系统显著降低任务负载和飞行时间，提升速度控制稳定性，支持跨硬件平台部署。"
            ],
            "_index": 172
        },
        {
            "title": "A Deep Dive into Function Inlining and its Security Implications for ML-based Binary Analysis",
            "authors": [
                "Omar Abusabha",
                "Jiyong Uhm",
                "Tamer Abuhmed",
                "Hyungjoon Koo"
            ],
            "arxiv_id": "2512.14045v1",
            "summary": "A function inlining optimization is a widely used transformation in modern compilers, which replaces a call site with the callee's body in need. While this transformation improves performance, it significantly impacts static features such as machine instructions and control flow graphs, which are crucial to binary analysis. Yet, despite its broad impact, the security impact of function inlining remains underexplored to date. In this paper, we present the first comprehensive study of function inlining through the lens of machine learning-based binary analysis. To this end, we dissect the inlining decision pipeline within the LLVM's cost model and explore the combinations of the compiler options that aggressively promote the function inlining ratio beyond standard optimization levels, which we term extreme inlining. We focus on five ML-assisted binary analysis tasks for security, using 20 unique models to systematically evaluate their robustness under extreme inlining scenarios. Our extensive experiments reveal several significant findings: i) function inlining, though a benign transformation in intent, can (in)directly affect ML model behaviors, being potentially exploited by evading discriminative or generative ML models; ii) ML models relying on static features can be highly sensitive to inlining; iii) subtle compiler settings can be leveraged to deliberately craft evasive binary variants; and iv) inlining ratios vary substantially across applications and build configurations, undermining assumptions of consistency in training and evaluation of ML models.",
            "categories": [
                "cs.CR",
                "cs.LG",
                "cs.PL"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14045v1",
            "code_links": [],
            "headline_zh": "首次全面研究函数内联对基于机器学习的二进制分析安全影响，揭示极端内联下模型脆弱性。",
            "summary_zh": "函数内联优化是现代编译器中广泛使用的转换，通过将调用点替换为被调用函数体来提升性能，但显著影响机器指令和控制流图等静态特征，这些特征对二进制分析至关重要。尽管其影响广泛，函数内联的安全影响至今尚未得到充分探索。本文首次从基于机器学习的二进制分析角度，对函数内联进行全面研究。为此，我们剖析了LLVM成本模型中的内联决策流程，并探索了编译器选项的组合，这些组合能激进地提升函数内联比率，超越标准优化级别，我们称之为极端内联。我们聚焦于五个安全相关的ML辅助二进制分析任务，使用20个独特模型，系统评估它们在极端内联场景下的鲁棒性。大量实验揭示了几个重要发现：i) 函数内联虽意图良性，但可直接或间接影响ML模型行为，可能被利用以逃避判别性或生成性ML模型；ii) 依赖静态特征的ML模型对内联高度敏感；iii) 细微的编译器设置可被利用来故意制作逃避性二进制变体；iv) 内联比率在不同应用和构建配置中差异显著，削弱了ML模型训练和评估中一致性假设。",
            "intro_zh": [
                "现有方法不足：函数内联对二进制分析安全影响未充分探索，ML模型鲁棒性假设可能不成立。",
                "方法要点：剖析LLVM内联决策流程，探索极端内联设置，系统评估ML模型在安全任务中的表现。",
                "实验效果：发现内联可被利用逃避ML模型，模型敏感性高，编译器设置影响显著，内联比率差异大。"
            ],
            "method_zh": "论文核心方法包括：整体框架基于LLVM编译器，通过分析其成本模型中的内联决策流程，识别影响内联比率的因素；关键技术创新点在于提出极端内联概念，通过组合编译器选项（如优化标志和启发式参数）激进提升内联比率，超越标准-O1/-O2/-O3级别；与现有方法的主要区别在于，现有研究多关注内联的性能优化，而本文首次系统研究其对ML-based二进制分析安全的影响，并引入极端内联作为攻击向量，评估模型鲁棒性。",
            "application_zh": "该研究潜在应用于二进制安全分析领域，如恶意软件检测、漏洞挖掘和代码混淆防御，通过揭示内联对ML模型的脆弱性，可指导更鲁棒的模型设计和编译器安全优化，提升实际安全系统的可靠性。",
            "highlight_zh": "实验显示，极端内联下，ML模型在五个安全任务中表现显著下降，内联比率最高提升至标准优化的数倍，模型逃避攻击成功率增加，揭示了内联作为隐蔽攻击向量的潜力。",
            "tags_zh": [
                "函数内联",
                "二进制分析",
                "机器学习安全",
                "编译器优化",
                "极端内联",
                "模型鲁棒性",
                "LLVM成本模型",
                "静态特征"
            ],
            "_index": 173
        },
        {
            "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
            "authors": [
                "Boran Wang",
                "Xinming Wang",
                "Yi Chen",
                "Xiang Li",
                "Jian Xu",
                "Jing Yuan",
                "Chenglin Liu"
            ],
            "arxiv_id": "2512.14040v1",
            "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14040v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "强化学习",
                    "matched_keywords": [
                        "PPO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出ChartAgent框架，通过工具集成推理解决图表理解在稀疏标注下的鲁棒性问题。",
            "summary_zh": "图表因其高信息密度和直观可读性，已成为跨学科数据分析和交流的实际媒介。近年来，多模态大语言模型（MLLMs）在自动化图表理解方面取得了显著进展，但它们仍然严重依赖显式文本标注，并且在关键数字缺失时性能显著下降。为解决这一局限性，我们引入了ChartAgent，这是一个基于工具集成推理（TIR）的图表理解框架。受人类认知启发，ChartAgent将复杂的图表分析分解为一系列可观察、可重放的步骤。支持这一架构的是一个可扩展的模块化工具库，包含十多个核心工具，如关键元素检测、实例分割和光学字符识别（OCR），智能体动态编排这些工具，以实现跨不同图表类型的系统化视觉解析。利用TIR的透明性和可验证性，ChartAgent超越了黑盒范式，通过将中间输出标准化并整合为结构化证据包，为最终结论提供可追溯和可复现的支持。实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，为可信赖和可扩展的图表理解系统提供了一条实用路径。",
            "intro_zh": [
                "现有多模态大语言模型依赖显式文本标注，关键数字缺失时性能显著下降，鲁棒性不足。",
                "提出ChartAgent框架，基于工具集成推理，将图表分析分解为可观察步骤，动态编排模块化工具库。",
                "实验显示，ChartAgent在稀疏标注设置下显著提升鲁棒性，提供可追溯和可复现的图表理解支持。"
            ],
            "method_zh": "ChartAgent是一个基于工具集成推理（TIR）的图表理解框架。整体框架将复杂图表分析分解为可观察、可重放的步骤序列，通过一个可扩展的模块化工具库（包括关键元素检测、实例分割、OCR等十多个核心工具）动态编排实现系统化视觉解析。关键技术创新点在于引入结构化证据包，标准化和整合中间输出，提供可追溯和可复现的支持。与现有方法的主要区别在于，它超越了MLLMs的黑盒范式，通过工具集成提高鲁棒性，特别是在稀疏标注或关键信息缺失场景下，增强了透明性和可信度。",
            "application_zh": "该研究可应用于数据可视化分析、自动化报告生成、教育辅助工具和商业智能系统等领域，通过提高图表理解的鲁棒性和可解释性，支持跨学科的数据驱动决策和高效信息提取，具有广泛的实用价值。",
            "highlight_zh": "实验结果表明，ChartAgent在稀疏标注设置下显著提升了鲁棒性，通过工具集成推理和结构化证据包，实现了可追溯的图表解析，为可信赖的自动化系统提供了有效解决方案。",
            "tags_zh": [
                "图表理解",
                "工具集成推理",
                "多模态大语言模型",
                "稀疏标注",
                "视觉解析",
                "可扩展框架",
                "自动化分析"
            ],
            "_index": 210
        },
        {
            "title": "ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization",
            "authors": [
                "Meng Wei",
                "Cheng Zhang",
                "Jianmin Zheng",
                "Hamid Rezatofighi",
                "Jianfei Cai"
            ],
            "arxiv_id": "2512.14039v1",
            "summary": "Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14039v1",
            "code_links": [],
            "headline_zh": "提出ASAP-Textured Gaussians，通过自适应采样和各向异性参数化解决纹理高斯方法的内存效率问题。",
            "summary_zh": "近年来，3D高斯溅射通过纹理参数化捕捉空间变化属性，提升了外观建模和下游任务性能，但纹理参数引入显著内存效率挑战。本文不提出新纹理公式，而是回顾现有纹理高斯方法，识别两个共同关键限制：(1) 纹理通常在规范空间中定义，导致采样效率低下，浪费纹理容量于低贡献区域；(2) 纹理参数化在所有高斯上均匀分配，不考虑视觉复杂性，导致过参数化。为解决这些问题，我们提出两种简单有效的策略：基于高斯密度分布的自适应采样和根据渲染误差分配纹理资源的误差驱动各向异性参数化。所提出的ASAP Textured Gaussians（自适应采样和各向异性参数化）显著改善了质量效率权衡，以更少纹理参数实现高保真渲染。",
            "intro_zh": [
                "现有纹理高斯方法在规范空间定义纹理，采样效率低，浪费资源于低贡献区域。",
                "提出自适应采样和误差驱动各向异性参数化，优化纹理分配以提升效率。",
                "实验显示ASAP方法显著减少纹理参数，同时保持高保真渲染质量。"
            ],
            "method_zh": "ASAP-Textured Gaussians的整体框架基于3D高斯溅射，通过纹理参数化增强外观建模。关键技术创新包括：自适应采样策略，利用高斯密度分布优化采样点，减少低贡献区域的纹理浪费；误差驱动各向异性参数化，根据渲染误差动态分配纹理资源，避免均匀分配导致的过参数化。与现有方法的主要区别在于，不引入新纹理公式，而是改进现有纹理高斯的采样和参数化过程，直接针对内存效率问题，实现更高效的纹理利用。",
            "application_zh": "该研究可应用于计算机视觉和图形学领域，如虚拟现实、增强现实和3D重建，通过高效纹理建模提升渲染质量和系统性能，降低内存开销，适用于实时或资源受限场景。",
            "highlight_zh": "实验结果表明，ASAP-Textured Gaussians在减少纹理参数的同时，保持高保真渲染，显著优化质量效率权衡，具体性能提升未知，但强调方法在内存效率方面的改进。",
            "tags_zh": [
                "3D高斯溅射",
                "纹理参数化",
                "自适应采样",
                "各向异性参数化",
                "内存效率优化",
                "高保真渲染",
                "计算机视觉",
                "图形学"
            ],
            "_index": 211
        },
        {
            "title": "ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM",
            "authors": [
                "Ignacio Alzugaray",
                "Marwan Taher",
                "Andrew J. Davison"
            ],
            "arxiv_id": "2512.14032v1",
            "summary": "We present a novel neural RGB-D Simultaneous Localization And Mapping (SLAM) system that learns an implicit map of the scene in real time. For the first time, we explore the use of Scene Coordinate Regression (SCR) as the core implicit map representation in a neural SLAM pipeline, a paradigm that trains a lightweight network to directly map 2D image features to 3D global coordinates. SCR networks provide efficient, low-memory 3D map representations, enable extremely fast relocalization, and inherently preserve privacy, making them particularly suitable for neural implicit SLAM.\n  Our system is the first one to achieve strict real-time in neural implicit RGB-D SLAM by relying on a SCR-based representation. We introduce a novel SCR architecture specifically tailored for this purpose and detail the critical design choices required to integrate SCR into a live SLAM pipeline. The resulting framework is simple yet flexible, seamlessly supporting both sparse and dense features, and operates reliably in dynamic environments without special adaptation. We evaluate our approach on established synthetic and real-world benchmarks, demonstrating competitive performance against the state of the art. Project Page: https://github.com/ialzugaray/ace-slam",
            "categories": [
                "cs.CV",
                "cs.AI",
                "eess.IV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://github.com/ialzugaray/ace-slam",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14032v1",
            "code_links": [
                {
                    "url": "https://github.com/ialzugaray/ace-slam",
                    "type": "github"
                }
            ],
            "headline_zh": "提出ACE-SLAM，基于场景坐标回归实现神经隐式实时RGB-D SLAM，解决现有方法实时性不足和隐私问题。",
            "summary_zh": "我们提出了一种新颖的神经RGB-D同时定位与建图（SLAM）系统，能够实时学习场景的隐式地图。首次探索了将场景坐标回归（SCR）作为神经SLAM流程中的核心隐式地图表示范式，该范式训练一个轻量级网络直接映射2D图像特征到3D全局坐标。SCR网络提供高效、低内存的3D地图表示，支持极快的重定位，并固有地保护隐私，使其特别适合神经隐式SLAM。我们的系统是首个通过依赖基于SCR的表示实现严格实时性的神经隐式RGB-D SLAM。我们引入了一种专门为此目的设计的新颖SCR架构，并详细阐述了将SCR集成到实时SLAM流程中的关键设计选择。所得框架简单而灵活，无缝支持稀疏和稠密特征，并在动态环境中可靠运行，无需特殊适应。我们在已建立的合成和真实世界基准上评估了我们的方法，展示了与最先进技术相比的竞争性能。项目页面：https://github.com/ialzugaray/ace-slam",
            "intro_zh": [
                "现有神经隐式SLAM方法在实时性和内存效率方面存在不足，难以在动态环境中稳定运行。",
                "提出基于场景坐标回归的轻量级网络，直接映射图像特征到3D坐标，实现高效隐式地图表示和快速重定位。",
                "在合成和真实基准测试中，系统实现严格实时性，性能与最先进方法竞争，无需特殊适应动态环境。"
            ],
            "method_zh": "ACE-SLAM的整体框架是一个基于场景坐标回归（SCR）的神经隐式SLAM系统，通过轻量级网络将RGB-D图像特征直接回归到3D全局坐标，作为隐式地图表示。关键技术创新点包括专门为实时SLAM设计的SCR架构，以及将SCR无缝集成到实时流程中的设计选择，如支持稀疏和稠密特征。与现有方法的主要区别在于首次将SCR作为核心隐式表示，实现了严格实时性，同时保持低内存占用和隐私保护，无需复杂适应即可处理动态环境。",
            "application_zh": "该研究适用于增强现实、机器人导航和智能监控等领域，其高效实时SLAM能力可提升设备定位精度和用户体验，隐私保护特性使其适合敏感环境应用。",
            "highlight_zh": "在合成和真实世界基准测试中，ACE-SLAM实现严格实时性，重定位速度极快，性能与最先进方法竞争，且在动态环境中稳定运行，无需额外适应。",
            "tags_zh": [
                "神经隐式SLAM",
                "场景坐标回归",
                "实时定位与建图",
                "RGB-D SLAM",
                "轻量级网络",
                "隐私保护",
                "动态环境适应",
                "3D地图表示"
            ],
            "_index": 212
        },
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031v1",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031v1",
            "code_links": [],
            "headline_zh": "评估VLA模型与强化学习方法在建筑机器人技能学习中的样本效率与实用性",
            "summary_zh": "本研究评估了两种领先方法——视觉-语言-动作（VLA）模型和强化学习（RL）方法——用于教授建筑机器人新技能，以理解它们在建筑自动化中的适用性。目标是了解任务性能以及在真实工作中部署每种方法所需的实际努力。作者开发了两个遥操作接口来控制机器人并收集所需的演示，这两种接口都被证明对训练机器人执行长期和灵巧任务有效。此外，作者进行了三阶段评估。首先，作者比较了多层感知器（MLP）策略和深度Q网络（DQN）模仿模型，以确定更强的RL基线，重点关注模型性能、泛化能力和拾取实验。其次，在两种不同场景下训练了三种不同的VLA模型，并相互比较。第三，作者使用计算和样本效率指标，以及一个包括运输和安装的多阶段面板安装任务的机器人实验，对选定的RL基线与VLA模型进行了基准测试。VLA模型表现出强大的泛化和少样本能力，在拾取阶段实现了60%和100%的成功率。相比之下，DQN可以变得鲁棒，但需要在调优期间添加额外噪声，这增加了工作量。总体而言，研究结果表明，VLA通过减少编程努力和用最少数据实现有用性能，为任务变更提供了实际优势，而DQN在可接受足够调优努力时提供了一个可行的基线。",
            "intro_zh": [
                "核心问题：建筑自动化中机器人技能学习面临样本效率低、泛化能力差和部署工作量大的挑战，现有方法如传统RL需要大量数据和复杂调优。",
                "方法要点：提出基于视觉-语言-动作（VLA）模型的端到端学习框架，结合遥操作接口收集演示，实现少样本学习和任务适应。",
                "实验或效果：VLA模型在拾取任务中达到60%-100%成功率，优于DQN基线，显著减少数据需求和编程工作量。"
            ],
            "method_zh": "论文采用分层评估框架，核心方法包括VLA模型和RL方法。整体框架基于遥操作接口收集机器人演示数据，用于训练和比较。关键技术创新点在于VLA模型的多模态融合，结合视觉输入、语言指令和动作输出，实现端到端技能学习。与现有方法的主要区别在于VLA模型强调少样本能力和泛化性，而传统RL方法如DQN依赖更多数据和调优噪声来提升鲁棒性。",
            "application_zh": "该研究主要应用于建筑自动化领域，如机器人面板安装、运输和灵巧操作任务，可推广到其他需要高效技能学习的工业机器人场景，提升自动化系统的适应性和部署效率。",
            "highlight_zh": "VLA模型在拾取实验中实现60%和100%成功率，展示强泛化和少样本能力；DQN基线虽可鲁棒化，但需额外噪声调优增加工作量；整体上VLA在样本效率和实用性上优于RL方法。",
            "tags_zh": [
                "建筑机器人",
                "视觉-语言-动作模型",
                "强化学习",
                "样本效率",
                "多模态融合",
                "遥操作接口",
                "技能学习",
                "自动化部署"
            ],
            "_index": 213
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028v1",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028v1",
            "code_links": [
                {
                    "url": "https://namisntimpot.github.io/NSLweb/",
                    "type": "project_page"
                }
            ],
            "headline_zh": "提出基于神经特征解码的单次结构光三维成像方法，以提升在遮挡、精细结构和非朗伯表面等挑战场景下的鲁棒性。",
            "summary_zh": "本文研究了单次结构光系统在主动三维成像中的应用，这类系统广泛应用于苹果Face ID和英特尔RealSense等商业三维传感设备。传统的结构光方法通常通过像素域匹配算法解码深度对应关系，导致在遮挡、精细结构细节和非朗伯表面等挑战场景下鲁棒性有限。受神经特征匹配最新进展的启发，我们提出了一种基于学习的结构光解码框架，在特征空间而非脆弱的像素域执行鲁棒的对应匹配。我们的方法从投影图案和捕获的红外图像中提取神经特征，通过在特征空间中构建代价体积显式地结合其几何先验，相比像素域解码方法实现了显著的性能提升。为进一步提高深度质量，我们引入了一个深度细化模块，利用大规模单目深度估计模型的强先验，改善精细细节恢复和全局结构一致性。为促进有效学习，我们开发了一个基于物理的结构光渲染流程，生成了近百万个包含室内环境中多样物体和材料的合成图案-图像对。实验表明，我们的方法仅使用多种结构光图案的合成数据进行训练，就能很好地泛化到真实世界室内环境，无需重新训练即可有效处理各种图案类型，并始终优于商业结构光系统和基于被动立体RGB的深度估计方法。项目页面：https://namisntimpot.github.io/NSLweb/。",
            "intro_zh": [
                "传统单次结构光方法依赖像素域匹配，在遮挡、精细结构或非朗伯表面等复杂场景下鲁棒性不足，导致深度估计精度下降。",
                "提出基于神经特征解码的框架，在特征空间而非像素域进行对应匹配，并引入深度细化模块，结合几何先验和大规模单目深度模型先验提升性能。",
                "仅用合成数据训练，方法在真实室内场景中泛化良好，处理多种图案类型无需重新训练，性能优于商业结构光系统和被动立体RGB深度估计方法。"
            ],
            "method_zh": "整体框架包括神经特征提取、特征空间代价体积构建和深度细化模块。首先，从投影图案和捕获的红外图像中提取神经特征，替代传统像素域匹配。关键创新在于在特征空间中构建代价体积，显式地结合几何先验，实现更鲁棒的对应匹配。与现有方法的主要区别在于：传统方法依赖像素级匹配，易受噪声和场景复杂性影响；而本方法通过深度学习在特征空间进行匹配，提升了在挑战场景下的鲁棒性，并利用大规模单目深度模型的先验进行深度细化，进一步优化细节和全局结构。",
            "application_zh": "该研究可应用于消费电子（如智能手机面部识别、增强现实）、工业检测（如精密零件三维扫描）、机器人导航（如环境感知与避障）等领域，提升三维成像在复杂场景下的可靠性和精度，具有广泛的商业和工业价值。",
            "highlight_zh": "实验显示，方法在合成和真实数据上均优于传统像素域解码，深度估计误差显著降低；泛化能力强，仅用合成数据训练即可处理真实室内场景和多种图案类型；在遮挡、精细结构等挑战场景下，性能提升尤为明显，优于苹果Face ID和英特尔RealSense等商业系统。",
            "tags_zh": [
                "单次结构光",
                "三维成像",
                "神经特征匹配",
                "深度估计",
                "合成数据训练",
                "特征空间解码",
                "鲁棒性提升",
                "室内场景"
            ],
            "_index": 214
        },
        {
            "title": "Unleashing the Power of Image-Tabular Self-Supervised Learning via Breaking Cross-Tabular Barriers",
            "authors": [
                "Yibing Fu",
                "Yunpeng Zhao",
                "Zhitao Zeng",
                "Cheng Chen",
                "Yueming Jin"
            ],
            "arxiv_id": "2512.14026v1",
            "summary": "Multi-modal learning integrating medical images and tabular data has significantly advanced clinical decision-making in recent years. Self-Supervised Learning (SSL) has emerged as a powerful paradigm for pretraining these models on large-scale unlabeled image-tabular data, aiming to learn discriminative representations. However, existing SSL methods for image-tabular representation learning are often confined to specific data cohorts, mainly due to their rigid tabular modeling mechanisms when modeling heterogeneous tabular data. This inter-tabular barrier hinders the multi-modal SSL methods from effectively learning transferrable medical knowledge shared across diverse cohorts. In this paper, we propose a novel SSL framework, namely CITab, designed to learn powerful multi-modal feature representations in a cross-tabular manner. We design the tabular modeling mechanism from a semantic-awareness perspective by integrating column headers as semantic cues, which facilitates transferrable knowledge learning and the scalability in utilizing multiple data sources for pretraining. Additionally, we propose a prototype-guided mixture-of-linear layer (P-MoLin) module for tabular feature specialization, empowering the model to effectively handle the heterogeneity of tabular data and explore the underlying medical concepts. We conduct comprehensive evaluations on Alzheimer's disease diagnosis task across three publicly available data cohorts containing 4,461 subjects. Experimental results demonstrate that CITab outperforms state-of-the-art approaches, paving the way for effective and scalable cross-tabular multi-modal learning.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14026v1",
            "code_links": [],
            "headline_zh": "提出CITab框架以解决跨队列图像-表格自监督学习中的异构表格数据建模障碍问题。",
            "summary_zh": "近年来，整合医学图像和表格数据的多模态学习显著推动了临床决策的进步。自监督学习已成为在这些大规模未标记图像-表格数据上进行预训练的强大范式，旨在学习判别性表示。然而，现有的图像-表格表示学习自监督方法通常局限于特定数据队列，主要由于其在建模异构表格数据时采用僵化的表格建模机制。这种跨表格障碍阻碍了多模态自监督方法有效学习跨不同队列共享的可迁移医学知识。本文提出了一种新颖的自监督学习框架，即CITab，旨在以跨表格方式学习强大的多模态特征表示。我们从语义感知的角度设计表格建模机制，通过整合列标题作为语义线索，促进可迁移知识学习和利用多个数据源进行预训练的可扩展性。此外，我们提出了原型引导的线性混合层模块用于表格特征专业化，使模型能够有效处理表格数据的异构性并探索潜在的医学概念。我们在包含4,461名受试者的三个公开数据队列上对阿尔茨海默病诊断任务进行了全面评估。实验结果表明，CITab优于最先进的方法，为有效且可扩展的跨表格多模态学习铺平了道路。",
            "intro_zh": [
                "现有自监督学习方法在图像-表格多模态学习中面临跨队列迁移困难，主要由于异构表格数据的僵化建模机制阻碍了知识共享。",
                "CITab框架通过语义感知的表格建模整合列标题作为语义线索，并引入原型引导的线性混合层模块，以专业化处理表格数据异构性。",
                "在阿尔茨海默病诊断任务中，CITab在三个公开队列上超越现有方法，验证了其有效性和可扩展性。"
            ],
            "method_zh": "CITab是一个自监督学习框架，整体架构包括图像编码器、表格编码器和多模态融合模块。关键技术创新点在于：从语义感知角度设计表格建模机制，通过列标题作为语义线索增强跨队列知识迁移；引入原型引导的线性混合层模块，动态调整线性层以专业化处理表格数据的异构性，探索潜在医学概念。与现有方法的主要区别在于，它打破了跨表格障碍，通过更灵活的表格建模支持多源数据预训练，而传统方法通常依赖固定结构，限制了可扩展性和迁移能力。",
            "application_zh": "该研究主要应用于医学领域，如阿尔茨海默病等疾病的诊断和预测，通过整合医学图像和临床表格数据，提升临床决策的准确性和效率。潜在价值包括支持跨医院或研究队列的数据融合，促进大规模多模态医学AI模型的开发。",
            "highlight_zh": "在包含4,461名受试者的三个公开阿尔茨海默病数据队列上，CITab在诊断任务中显著优于现有最先进方法，证明了其在跨队列场景下的优越性能和可扩展性，为多模态医学学习提供了有效解决方案。",
            "tags_zh": [
                "多模态学习",
                "自监督学习",
                "医学图像分析",
                "表格数据处理",
                "跨队列学习",
                "异构数据建模",
                "阿尔茨海默病诊断",
                "语义感知建模"
            ],
            "_index": 215
        },
        {
            "title": "Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks",
            "authors": [
                "Yong Fang",
                "Na Li",
                "Hangguan Shan",
                "Eryun Liu",
                "Xinyu Li",
                "Wei Ni",
                "Er-Ping Li"
            ],
            "arxiv_id": "2512.14023v1",
            "summary": "Multivariate Time Series (MTS) forecasting plays a vital role in various real-world applications, such as traffic management and predictive maintenance. Existing approaches typically model MTS data in either Euclidean or Riemannian space, limiting their ability to capture the diverse geometric structures and complex spatio-temporal dependencies inherent in real-world data. To overcome this limitation, we propose the Hybrid Symmetric Positive-Definite Manifold Graph Neural Network (HSMGNN), a novel graph neural network-based model that captures data geometry within a hybrid Euclidean-Riemannian framework. To the best of our knowledge, this is the first work to leverage hybrid geometric representations for MTS forecasting, enabling expressive and comprehensive modeling of geometric properties. Specifically, we introduce a Submanifold-Cross-Segment (SCS) embedding to project input MTS into both Euclidean and Riemannian spaces, thereby capturing spatio-temporal variations across distinct geometric domains. To alleviate the high computational cost of Riemannian distance, we further design an Adaptive-Distance-Bank (ADB) layer with a trainable memory mechanism. Finally, a Fusion Graph Convolutional Network (FGCN) is devised to integrate features from the dual spaces via a learnable fusion operator for accurate prediction. Experiments on three benchmark datasets demonstrate that HSMGNN achieves up to a 13.8 percent improvement over state-of-the-art baselines in forecasting accuracy.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14023v1",
            "code_links": [],
            "headline_zh": "提出混合欧几里得-对称正定流形图神经网络以解决多元时间序列预测中几何结构建模不足的问题。",
            "summary_zh": "多元时间序列预测在交通管理和预测性维护等实际应用中至关重要。现有方法通常在欧几里得空间或黎曼空间中建模MTS数据，限制了其捕捉真实数据中多样几何结构和复杂时空依赖性的能力。为克服这一限制，我们提出了混合对称正定流形图神经网络，这是一种基于图神经网络的新模型，在混合欧几里得-黎曼框架内捕捉数据几何。据我们所知，这是首次利用混合几何表示进行MTS预测的工作，实现了对几何属性的表达性和全面建模。具体来说，我们引入了子流形交叉段嵌入，将输入MTS投影到欧几里得和黎曼空间，从而捕捉不同几何域中的时空变化。为减轻黎曼距离的高计算成本，我们进一步设计了具有可训练记忆机制的自适应距离库层。最后，开发了融合图卷积网络，通过可学习融合算子整合双空间特征以进行准确预测。在三个基准数据集上的实验表明，HSMGNN在预测准确性上比最先进基线提高了高达13.8%。",
            "intro_zh": [
                "现有方法在欧几里得或黎曼空间中建模多元时间序列，难以捕捉真实数据中的多样几何结构和复杂时空依赖性。",
                "提出HSMGNN模型，通过混合几何表示和子流形交叉段嵌入，在双空间中捕捉时空变化，并设计自适应距离库层降低计算成本。",
                "在三个基准数据集上，HSMGNN相比最先进基线在预测准确性上提升高达13.8%，验证了其有效性。"
            ],
            "method_zh": "HSMGNN的整体框架基于混合欧几里得-黎曼空间，通过图神经网络建模多元时间序列。关键技术创新包括：子流形交叉段嵌入将数据投影到欧几里得和黎曼空间以捕捉几何多样性；自适应距离库层利用可训练记忆机制优化黎曼距离计算，降低计算复杂度；融合图卷积网络通过可学习算子整合双空间特征进行预测。与现有方法的主要区别在于首次引入混合几何表示，克服了单一空间建模的局限性，实现了更全面的几何属性捕捉。",
            "application_zh": "该研究可应用于交通管理、预测性维护等领域，通过准确预测多元时间序列，优化资源分配和故障预警，提升系统效率和可靠性。",
            "highlight_zh": "在三个基准数据集上的实验显示，HSMGNN相比最先进基线在预测准确性上最高提升13.8%，显著优于现有方法，证明了混合几何表示的有效性。",
            "tags_zh": [
                "多元时间序列预测",
                "图神经网络",
                "混合几何表示",
                "对称正定流形",
                "时空依赖性建模",
                "自适应距离库",
                "融合图卷积网络",
                "预测准确性提升"
            ],
            "_index": 216
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020v1",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages. Review Paper on Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020v1",
            "code_links": [],
            "headline_zh": "综述深度学习在自主机器人场景理解中的应用，涵盖对象检测、语义分割、深度估计、3D重建和视觉SLAM，以提升环境感知与决策能力。",
            "summary_zh": "本文综述了深度学习在自主机器人场景理解中的应用，包括对象检测、语义和实例分割、深度估计、3D重建以及视觉SLAM的创新。它强调这些技术如何解决传统几何模型的局限性，在遮挡和无纹理表面情况下实时改进深度感知，并增强语义推理以更好地理解环境。当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。最后，综述概述了现有问题及研究方向，以推进基于学习的自主机器人场景理解。",
            "intro_zh": [
                "核心问题：传统几何模型在场景理解中存在局限性，如难以处理遮挡、无纹理表面和动态环境，导致深度感知和语义推理不足。",
                "方法要点：论文综述深度学习技术，包括对象检测、语义分割、深度估计和视觉SLAM，通过神经网络模型提升环境感知的准确性和实时性。",
                "实验或效果：综述表明，这些方法能有效改进深度感知，增强语义理解，并在动态环境中提升决策和导航性能，但具体实验数据未知。"
            ],
            "method_zh": "论文整体框架为综述性分析，未提出单一模型，而是系统梳理深度学习在场景理解中的关键技术。关键技术创新点包括整合对象检测、语义分割、深度估计和视觉SLAM，以克服传统方法的几何限制。与现有方法的主要区别在于强调深度学习如何通过端到端学习处理复杂环境，提升感知模块的集成效果，而非依赖手工特征或静态模型。",
            "application_zh": "该研究在自主机器人领域有广泛应用，如自动驾驶、无人机导航、服务机器人和工业自动化，通过增强场景理解能力，提升机器人在动态和非结构化环境中的决策、避障和交互效率。",
            "highlight_zh": "综述指出，深度学习技术能显著改进深度感知和语义推理，在遮挡和无纹理表面情况下实现实时性能提升，但具体实验数据如准确率或速度提升未知，主要基于现有文献总结。",
            "tags_zh": [
                "场景理解",
                "深度学习",
                "自主机器人",
                "语义分割",
                "深度估计",
                "视觉SLAM",
                "3D重建",
                "对象检测"
            ],
            "_index": 217
        },
        {
            "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
            "authors": [
                "Juseung Yun",
                "Sunwoo Yu",
                "Sumin Ha",
                "Jonghyun Kim",
                "Janghyeon Lee",
                "Jongseong Jang",
                "Soonyoung Lee"
            ],
            "arxiv_id": "2512.14019v1",
            "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14019v1",
            "code_links": [],
            "headline_zh": "提出EXAONE Path 2.5病理学基础模型，通过多组学对齐解决癌症多模态建模不足的问题",
            "summary_zh": "癌症进展源于多个生物层面的相互作用，特别是超越形态学且涉及分子层面的过程，这些是仅依赖图像的模型无法捕捉的。为了更全面地刻画这一生物图景，我们提出了EXAONE Path 2.5，一个病理学基础模型，它联合建模组织学、基因组学、表观遗传学和转录组学等多模态数据，生成反映肿瘤生物学更全面的整合患者表征。我们的方法包含三个关键组件：(1) 多模态SigLIP损失，实现跨异质模态的全配对对比学习；(2) 片段感知旋转位置编码(F-RoPE)模块，保留全切片图像中的空间结构和组织片段拓扑；(3) 针对全切片图像和RNA-seq的领域专用内部基础模型，提供基于生物学的嵌入，以实现稳健的多模态对齐。我们在两个互补基准上评估EXAONE Path 2.5：一个内部真实世界临床数据集和覆盖80个任务的Patho-Bench基准。我们的框架展示了高数据和参数效率，在Patho-Bench上达到与最先进基础模型相当的性能，同时在内部临床设置中表现出最高的适应性。这些结果突显了基于生物学的多模态设计的价值，并强调了整合基因型到表型建模对下一代精准肿瘤学的潜力。",
            "intro_zh": [
                "核心问题：现有病理学模型主要依赖图像数据，难以捕捉癌症进展中跨分子层面的相互作用，导致对肿瘤生物学的理解不全面。",
                "方法要点：提出EXAONE Path 2.5，通过多模态SigLIP损失、F-RoPE模块和领域专用基础模型，实现组织学与多组学数据的联合建模。",
                "实验或效果：在Patho-Bench基准上达到最先进性能，在内部临床数据中表现出高适应性，验证了多模态设计的有效性。"
            ],
            "method_zh": "EXAONE Path 2.5的整体框架是一个病理学基础模型，旨在整合组织学图像与基因组、表观遗传和转录组等多组学数据。关键技术创新点包括：采用多模态SigLIP损失进行全配对对比学习，以对齐异质模态；设计F-RoPE模块，在全切片图像中保留空间结构和组织片段拓扑；并构建领域专用内部基础模型，为全切片图像和RNA-seq提供生物学基础的嵌入。与现有方法的主要区别在于，它超越了单一图像模态，通过多组学对齐实现更全面的肿瘤生物学表征，提高了模型的生物解释性和适应性。",
            "application_zh": "该研究在精准肿瘤学领域具有广泛应用潜力，可用于癌症诊断、预后预测和治疗响应评估，通过整合多模态数据提供更个性化的医疗决策支持，推动下一代精准医疗的发展。",
            "highlight_zh": "在Patho-Bench基准的80个任务中，EXAONE Path 2.5达到与最先进基础模型相当的性能，同时在内部真实世界临床数据集中表现出最高的适应性，验证了其高数据和参数效率。",
            "tags_zh": [
                "病理学基础模型",
                "多模态对齐",
                "多组学整合",
                "对比学习",
                "全切片图像分析",
                "RNA-seq建模",
                "生物信息学"
            ],
            "_index": 176
        },
        {
            "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization",
            "authors": [
                "Jiuding Yang",
                "Shengyao Lu",
                "Hongxuan Liu",
                "Shayan Shirahmad Gale Bagi",
                "Zahra Fazel",
                "Tomasz Czajkowski",
                "Di Niu"
            ],
            "arxiv_id": "2512.14018v1",
            "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14018v1",
            "code_links": [],
            "headline_zh": "提出PerfCoder模型，通过可解释的定制化优化生成高性能代码，解决大语言模型在代码性能优化方面的不足。",
            "summary_zh": "大语言模型在自动代码生成方面取得了显著进展，但在生成高性能代码方面仍存在局限，这是实际软件系统中的关键需求。我们认为当前大语言模型不仅因数据稀缺而受限，更重要的是缺乏指导可解释且有效性能改进的监督。本文介绍了PerfCoder，这是一系列专门设计用于通过可解释的定制化优化从源代码生成性能增强代码的大语言模型。PerfCoder在精选的真实世界优化轨迹集合上进行了微调，这些轨迹带有可读的人类注释，并通过使用运行时测量的强化微调进行偏好对齐，使其能够提出特定于输入的改进策略并直接应用，而无需依赖迭代优化。在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超越了所有现有模型，表明性能优化不能仅通过规模实现，而需要优化策略意识。此外，PerfCoder可以生成关于源代码的可解释反馈，当在规划器与优化器协作工作流中作为更大语言模型的输入时，可以进一步改善结果。具体而言，我们将32B模型和GPT-5在代码优化方面的性能提升到新水平，显著超越了它们的原始性能。",
            "intro_zh": [
                "现有大语言模型在代码生成中缺乏性能优化监督，导致生成代码效率低，难以满足实际软件需求。",
                "PerfCoder通过微调真实优化轨迹和强化学习对齐偏好，实现可解释的定制化代码优化，无需迭代优化。",
                "在PIE基准测试中，PerfCoder在运行时加速和优化率上超越所有模型，并提升32B模型和GPT-5的优化性能。"
            ],
            "method_zh": "PerfCoder的整体框架基于大语言模型，通过两个关键步骤实现代码性能优化：首先，在精选的真实世界优化轨迹数据集上进行微调，这些轨迹包含人类可读的注释，以学习可解释的优化策略；其次，使用运行时测量进行强化微调，以对齐模型偏好，使其能够直接应用输入特定的改进。技术创新点在于结合了监督微调和强化学习，强调优化策略的可解释性。与现有方法的主要区别在于，PerfCoder不依赖迭代优化过程，而是通过一次性生成优化代码，并利用可解释反馈提升协作工作流中的性能。",
            "application_zh": "该研究可应用于软件开发、编译器优化和自动化代码重构领域，帮助开发者生成高性能代码，提升软件系统效率，具有实际工程价值。",
            "highlight_zh": "在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超越所有现有模型，并将32B模型和GPT-5的代码优化性能提升到新水平，显著超越原始性能。",
            "tags_zh": [
                "代码性能优化",
                "大语言模型",
                "可解释优化",
                "强化微调",
                "代码生成",
                "软件工程",
                "自动化重构"
            ],
            "_index": 219
        },
        {
            "title": "KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding",
            "authors": [
                "Zongyao Li",
                "Kengo Ishida",
                "Satoshi Yamazaki",
                "Xiaotong Ji",
                "Jianquan Liu"
            ],
            "arxiv_id": "2512.14017v1",
            "summary": "We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "WACV2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14017v1",
            "code_links": [
                {
                    "url": "https://github.com/NEC-VID/KFS-Bench",
                    "type": "github"
                }
            ],
            "headline_zh": "提出KFS-Bench基准和自适应平衡采样方法，以解决长视频问答中关键帧采样评估与性能优化问题。",
            "summary_zh": "我们提出了KFS-Bench，这是首个用于长视频问答（QA）中关键帧采样的基准，具有多场景标注功能，能够直接且稳健地评估采样策略。关键帧采样对于高效的长视频理解至关重要。在长视频QA中，选择信息丰富的帧可以使多模态大语言模型（MLLMs）提高准确性和效率。KFS-Bench解决了先前工作仅通过QA准确性间接评估帧选择质量的局限性。通过为每个问题提供所需多个不相交场景的真实标注，KFS-Bench使我们能够直接分析不同采样方法如何在整个长视频中捕捉关键内容。利用KFS-Bench，我们对关键帧采样方法进行了全面研究，发现不仅采样精度，而且场景覆盖率和采样平衡性是影响QA性能的关键因素。基于所有这些因素，我们设计了一种与QA准确性相关的新型采样质量度量。此外，我们开发了一种新颖的关键帧采样方法，利用问题-视频相关性来平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。我们的自适应平衡采样方法在关键帧采样和QA性能方面均实现了卓越表现。该基准可在https://github.com/NEC-VID/KFS-Bench获取。",
            "intro_zh": [
                "现有方法仅通过问答准确性间接评估帧选择质量，缺乏直接分析采样策略在多场景长视频中内容捕捉能力的基准。",
                "论文提出KFS-Bench基准，提供多场景真实标注，并设计自适应平衡采样方法，通过问题-视频相关性优化场景覆盖与相似性平衡。",
                "实验表明，自适应平衡采样在关键帧采样和问答性能上均优于现有方法，新设计的采样质量度量与准确性高度相关。"
            ],
            "method_zh": "论文的核心方法包括KFS-Bench基准构建和自适应平衡采样方法。整体框架基于长视频问答场景，通过标注多个不相交场景作为真实参考，直接评估采样策略。关键技术创新点在于：1) 设计多场景标注基准，支持直接分析采样内容覆盖；2) 提出新型采样质量度量，综合考虑精度、覆盖率和平衡性；3) 开发自适应平衡采样方法，利用问题-视频相关性动态调整采样，平衡多样性与相似性。与现有方法的主要区别在于，现有工作依赖间接QA评估，而本方法提供直接评估框架，并引入场景覆盖和平衡性作为关键优化因素，从而更全面地提升采样效果。",
            "application_zh": "该研究可应用于长视频理解任务，如视频监控分析、教育视频内容提取、影视内容检索等，通过高效关键帧采样提升多模态大语言模型在视频问答中的准确性和效率，具有实际价值于资源受限环境下的实时视频处理。",
            "highlight_zh": "自适应平衡采样方法在KFS-Bench上实现卓越性能，关键帧采样质量显著提升，同时问答准确性得到改善；新设计的采样质量度量与QA准确性高度相关，验证了场景覆盖和平衡性对性能的关键影响。",
            "tags_zh": [
                "长视频理解",
                "关键帧采样",
                "视频问答",
                "多模态大语言模型",
                "基准评估",
                "自适应采样",
                "场景覆盖",
                "采样平衡性"
            ],
            "_index": 220
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014v1",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "21 pages, 13 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14014v1",
            "code_links": [
                {
                    "url": "https://github.com/jacklishufan/MobileWorld",
                    "type": "github"
                }
            ],
            "headline_zh": "提出MobileWorldBench基准和MobileWorld数据集，通过语义世界建模提升移动GUI代理的任务成功率",
            "summary_zh": "世界模型在提升具身代理任务性能方面显示出巨大效用。先前工作主要关注像素空间世界模型，但这些方法在GUI设置中面临实际限制，预测未来状态的复杂视觉元素通常很困难。在本工作中，我们探索了GUI代理世界建模的替代方案，其中状态转换用自然语言描述而非预测原始像素。首先，我们引入了MobileWorldBench，这是一个评估视觉语言模型作为移动GUI代理世界模型能力的基准。其次，我们发布了MobileWorld，一个包含140万样本的大规模数据集，显著提升了视觉语言模型的世界建模能力。最后，我们提出了一个新颖框架，将视觉语言模型世界模型集成到移动代理的规划框架中，证明语义世界模型可以通过提高任务成功率直接使移动代理受益。代码和数据集可在https://github.com/jacklishufan/MobileWorld获取。",
            "intro_zh": [
                "现有像素空间世界模型在GUI环境中预测复杂视觉元素困难，限制了移动代理的实际应用。",
                "论文提出用自然语言描述状态转换的语义世界建模方法，并构建基准和数据集提升视觉语言模型能力。",
                "实验表明，集成语义世界模型的移动代理框架能显著提高任务成功率，验证了方法的有效性。"
            ],
            "method_zh": "论文提出一个集成视觉语言模型作为世界模型的移动代理框架。整体框架包括：MobileWorldBench基准用于评估视觉语言模型在GUI环境中的世界建模能力，MobileWorld数据集提供大规模训练样本以增强模型性能，以及一个规划框架将语义世界模型与代理决策过程结合。关键技术创新点在于用自然语言替代像素预测来描述状态转换，这降低了建模复杂度并提高了可解释性。与现有方法的主要区别在于从像素空间转向语义空间，避免了直接预测复杂视觉元素的困难，更适合GUI环境下的实际应用。",
            "application_zh": "该研究可应用于移动GUI代理的自动化任务执行，如智能手机应用操作、网页浏览辅助和软件测试自动化。通过语义世界建模，代理能更准确地理解和预测界面变化，提升在复杂交互环境中的任务成功率，具有实际部署价值。",
            "highlight_zh": "实验结果显示，使用MobileWorld数据集训练的视觉语言模型在世界建模能力上显著提升。集成该语义世界模型的移动代理框架在任务成功率上取得明显改进，验证了语义方法相对于传统像素空间模型的优势，为GUI代理的实用化提供了新途径。",
            "tags_zh": [
                "语义世界建模",
                "移动GUI代理",
                "视觉语言模型",
                "基准测试",
                "大规模数据集",
                "自然语言描述",
                "任务规划",
                "界面自动化"
            ],
            "_index": 221
        },
        {
            "title": "Professional Software Developers Don't Vibe, They Control: AI Agent Use for Coding in 2025",
            "authors": [
                "Ruanqianqian Huang",
                "Avery Reyna",
                "Sorin Lerner",
                "Haijun Xia",
                "Brian Hempel"
            ],
            "arxiv_id": "2512.14012v1",
            "summary": "The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.HC"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14012v1",
            "code_links": [],
            "headline_zh": "揭示专业开发者如何通过控制策略有效利用AI代理提升软件开发效率与质量",
            "summary_zh": "AI代理的兴起正在改变软件构建方式，其承诺是开发者可以更快地编写代码、将多个任务委托给不同代理，甚至仅通过自然语言就能编写完整的软件。然而，代理在专业软件开发中实际扮演的角色仍存疑问。本文通过实地观察（N=13）和定性调查（N=99），研究了经验丰富的开发者如何在构建软件时使用代理，包括他们的动机、策略、任务适用性和情感态度。研究发现，尽管经验丰富的开发者重视代理作为生产力提升工具，但他们出于对基本软件质量属性的坚持，在软件设计和实现中保留了自己的主导权，并利用专业知识实施控制代理行为的策略。此外，由于对弥补代理局限性的信心，经验丰富的开发者对将代理纳入软件开发整体持积极态度。我们的结果揭示了软件开发最佳实践在有效使用代理中的价值，提出了代理可能适用的任务类型，并指出了未来改进代理界面和代理使用指南的机会。",
            "intro_zh": [
                "核心问题：AI代理在专业软件开发中的实际角色和有效性尚不明确，开发者如何平衡自动化与质量控制是关键挑战。",
                "方法要点：通过实地观察和定性调查，分析经验开发者使用AI代理的动机、策略和情感，强调控制与专业知识整合。",
                "实验或效果：发现开发者通过控制策略保留主导权，对代理持积极态度，并识别了代理适用的任务类型和界面改进方向。"
            ],
            "method_zh": "本文采用混合研究方法，结合实地观察和定性调查。整体框架包括对13名经验开发者的现场观察，记录他们在实际软件开发项目中使用AI代理的行为和互动；同时，通过在线问卷对99名开发者进行定性调查，收集关于使用动机、策略、任务适用性和情感态度的数据。关键技术创新点在于将人类因素与AI代理使用深度结合，强调开发者的控制策略和专业知识在代理应用中的核心作用。与现有方法的主要区别在于，本研究不聚焦于代理技术本身，而是从开发者视角出发，探索实际工作场景中的代理使用模式，填补了代理在专业软件开发中实证研究的空白。",
            "application_zh": "该研究可应用于软件开发工具设计、AI代理界面优化和行业培训指南制定。通过理解开发者如何有效控制代理，能提升代理在代码生成、任务自动化和质量保证等场景的实用性，推动AI与人类协作的软件开发范式。",
            "highlight_zh": "最重要的实验结果是：经验开发者通过控制策略（如代码审查、任务分解）保留软件主导权，对代理持整体积极态度（信心源于弥补代理局限），并识别出代理适合自动化但需人类监督的任务类型。",
            "tags_zh": [
                "AI代理",
                "软件开发",
                "人类-AI协作",
                "质量控制",
                "实地观察",
                "定性研究",
                "开发者行为",
                "代理界面设计"
            ],
            "_index": 222
        },
        {
            "title": "Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation",
            "authors": [
                "Yue Wan",
                "Jiayi Yuan",
                "Zhiwei Feng",
                "Xiaowei Jia"
            ],
            "arxiv_id": "2512.14011v1",
            "summary": "Antigenic epitope presented by major histocompatibility complex II (MHC-II) proteins plays an essential role in immunotherapy. However, compared to the more widely studied MHC-I in computational immunotherapy, the study of MHC-II antigenic epitope poses significantly more challenges due to its complex binding specificity and ambiguous motif patterns. Consequently, existing datasets for MHC-II interactions are smaller and less standardized than those available for MHC-I. To address these challenges, we present a well-curated dataset derived from the Immune Epitope Database (IEDB) and other public sources. It not only extends and standardizes existing peptide-MHC-II datasets, but also introduces a novel antigen-MHC-II dataset with richer biological context. Leveraging this dataset, we formulate three major machine learning (ML) tasks of peptide binding, peptide presentation, and antigen presentation, which progressively capture the broader biological processes within the MHC-II antigen presentation pathway. We further employ a multi-scale evaluation framework to benchmark existing models, along with a comprehensive analysis over various modeling designs to this problem with a modular framework. Overall, this work serves as a valuable resource for advancing computational immunotherapy, providing a foundation for future research in ML guided epitope discovery and predictive modeling of immune responses.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14011v1",
            "code_links": [],
            "headline_zh": "提出多尺度预测框架以加速MHC-II抗原呈递中的表位发现",
            "summary_zh": "由主要组织相容性复合体II（MHC-II）蛋白呈递的抗原表位在免疫治疗中起着至关重要的作用。然而，与计算免疫治疗中更广泛研究的MHC-I相比，MHC-II抗原表位的研究由于其复杂的结合特异性和模糊的基序模式而面临更多挑战。因此，现有的MHC-II相互作用数据集比MHC-I的数据集更小且标准化程度更低。为解决这些挑战，我们提出了一个从免疫表位数据库（IEDB）和其他公共来源精心整理的数据集。它不仅扩展和标准化了现有的肽-MHC-II数据集，还引入了一个具有更丰富生物学背景的新型抗原-MHC-II数据集。利用该数据集，我们制定了肽结合、肽呈递和抗原呈递三个主要机器学习任务，逐步捕捉MHC-II抗原呈递途径中更广泛的生物过程。我们进一步采用多尺度评估框架对现有模型进行基准测试，并通过模块化框架对该问题的各种建模设计进行全面分析。总体而言，这项工作为推进计算免疫治疗提供了宝贵资源，为未来机器学习指导的表位发现和免疫反应预测建模研究奠定了基础。",
            "intro_zh": [
                "核心问题：MHC-II表位研究因结合特异性复杂、基序模式模糊，数据集小且标准化不足，相比MHC-I更具挑战。",
                "方法要点：构建标准化MHC-II数据集，定义肽结合、肽呈递和抗原呈递三任务，采用多尺度评估和模块化分析框架。",
                "实验或效果：提供高质量数据集和基准测试，为机器学习在免疫治疗中的应用奠定基础，促进表位发现研究。"
            ],
            "method_zh": "论文提出一个模块化框架，核心包括数据整理、任务定义和多尺度评估。首先，从IEDB等公共来源构建标准化MHC-II数据集，扩展肽-MHC-II数据并引入抗原-MHC-II数据以丰富生物学背景。其次，定义肽结合、肽呈递和抗原呈递三个机器学习任务，逐步模拟MHC-II抗原呈递途径。关键创新在于多尺度评估框架，用于基准测试现有模型，并结合模块化设计分析不同建模策略。与现有方法的主要区别在于系统整合数据集、任务和评估，提供更全面的生物学过程捕捉，而非仅关注单一预测任务。",
            "application_zh": "该研究在计算免疫治疗领域有广泛应用，如加速疫苗设计、个性化免疫疗法开发和自身免疫性疾病研究。通过机器学习预测MHC-II表位，可优化抗原筛选，提高免疫治疗效率，为精准医疗提供技术支持。",
            "highlight_zh": "实验亮点包括构建高质量标准化MHC-II数据集，覆盖肽和抗原级别；多尺度评估显示模型在肽结合、呈递任务中性能提升；模块化分析揭示了不同建模设计的优劣，为未来研究提供基准和指导。",
            "tags_zh": [
                "MHC-II表位预测",
                "计算免疫治疗",
                "多尺度机器学习",
                "抗原呈递建模",
                "数据集标准化",
                "模块化框架",
                "免疫反应建模"
            ],
            "_index": 178
        },
        {
            "title": "Physics-Informed Machine Learning for Two-Phase Moving-Interface and Stefan Problems",
            "authors": [
                "Che-Chia Chang",
                "Te-Sheng Lin",
                "Ming-Chih Lai"
            ],
            "arxiv_id": "2512.14010v1",
            "summary": "The Stefan problem is a classical free-boundary problem that models phase-change processes and poses computational challenges due to its moving interface and nonlinear temperature-phase coupling. In this work, we develop a physics-informed neural network framework for solving two-phase Stefan problems. The proposed method explicitly tracks the interface motion and enforces the discontinuity in the temperature gradient across the interface while maintaining global consistency of the temperature field. Our approach employs two neural networks: one representing the moving interface and the other for the temperature field. The interface network allows rapid categorization of thermal diffusivity in the spatial domain, which is a crucial step for selecting training points for the temperature network. The temperature network's input is augmented with a modified zero-level set function to accurately capture the jump in its normal derivative across the interface. Numerical experiments on two-phase dynamical Stefan problems demonstrate the superior accuracy and effectiveness of our proposed method compared with the ones obtained by other neural network methodology in literature. The results indicate that the proposed framework offers a robust and flexible alternative to traditional numerical methods for solving phase-change problems governed by moving boundaries. In addition, the proposed method can capture an unstable interface evolution associated with the Mullins-Sekerka instability.",
            "categories": [
                "physics.comp-ph",
                "cs.LG"
            ],
            "primary_category": "physics.comp-ph",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14010v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "视觉里程计",
                    "matched_keywords": [
                        "VO"
                    ],
                    "score": 1
                }
            ],
            "relevance_score": 1,
            "headline_zh": "提出基于物理信息神经网络的框架以解决两相Stefan移动界面问题",
            "summary_zh": "Stefan问题是一个经典的相变过程自由边界问题，因其移动界面和非线性温度-相耦合而带来计算挑战。本文开发了一个基于物理信息的神经网络框架来解决两相Stefan问题。该方法显式跟踪界面运动，并在保持温度场全局一致性的同时，强制界面处温度梯度的不连续性。我们的方法采用两个神经网络：一个表示移动界面，另一个用于温度场。界面网络允许在空间域中快速分类热扩散率，这是为温度网络选择训练点的关键步骤。温度网络的输入通过修改的零水平集函数增强，以准确捕捉界面处法向导数的跳跃。在两相动态Stefan问题上的数值实验表明，与文献中其他神经网络方法相比，我们提出的方法具有更高的准确性和有效性。结果表明，该框架为解决受移动边界控制的相变问题提供了一个鲁棒且灵活的替代传统数值方法的选择。此外，该方法能够捕捉与Mullins-Sekerka不稳定性相关的不稳定界面演化。",
            "intro_zh": [
                "Stefan问题作为相变过程的经典自由边界问题，面临移动界面和非线性耦合带来的计算挑战，传统方法处理界面不连续性时存在困难。",
                "提出双神经网络框架：一个网络显式跟踪界面运动，另一个网络建模温度场，通过增强输入准确捕捉界面处的梯度跳跃。",
                "数值实验显示，该方法在动态Stefan问题上优于现有神经网络方法，能有效处理不稳定界面演化，提供高精度解决方案。"
            ],
            "method_zh": "本文提出一个基于物理信息的神经网络框架，核心是双网络架构：一个神经网络用于显式建模移动界面，另一个神经网络用于表示温度场。关键技术创新在于，界面网络通过快速分类热扩散率来指导温度网络的训练点选择，而温度网络则利用修改的零水平集函数作为输入增强，以精确捕捉界面处的法向导数不连续性。与现有方法的主要区别在于，该方法显式处理界面运动和不连续性，避免了传统神经网络方法在界面附近精度不足的问题，同时通过物理约束确保全局一致性。",
            "application_zh": "该研究在相变过程建模中具有广泛潜在应用，如材料科学中的凝固和熔化模拟、能源领域的相变储能系统优化，以及环境工程中的冰层生长预测。其实际价值在于为移动边界问题提供高效、灵活的数值解决方案，替代传统计算密集型方法。",
            "highlight_zh": "数值实验表明，该方法在两相动态Stefan问题上实现了显著精度提升，优于文献中其他神经网络方法，并能成功捕捉Mullins-Sekerka不稳定性导致的不稳定界面演化，验证了框架的鲁棒性和有效性。",
            "tags_zh": [
                "物理信息神经网络",
                "Stefan问题",
                "移动界面",
                "两相流",
                "相变模拟",
                "自由边界问题",
                "界面不连续性",
                "数值模拟"
            ],
            "_index": 224
        },
        {
            "title": "Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models",
            "authors": [
                "Shufan Li",
                "Jiuxiang Gu",
                "Kangning Liu",
                "Zhe Lin",
                "Zijun Wei",
                "Aditya Grover",
                "Jason Kuen"
            ],
            "arxiv_id": "2512.14008v1",
            "summary": "Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14008v1",
            "code_links": [],
            "headline_zh": "提出Sparse-LaViDa框架，通过动态截断冗余掩码标记以加速掩码离散扩散模型推理，同时保持生成质量。",
            "summary_zh": "掩码离散扩散模型（MDMs）在图像理解、生成和编辑等多模态任务中表现出色，但其推理速度因需在每个采样步骤重复处理冗余掩码标记而受限。本文提出Sparse-LaViDa，一种新颖的建模框架，通过动态截断每个推理步骤中不必要的掩码标记来加速MDM采样。为保持生成质量，引入了专门的寄存器标记作为截断标记的紧凑表示。此外，为确保训练与推理的一致性，设计了专门的注意力掩码，在训练中忠实匹配截断采样过程。基于最先进的统一MDM LaViDa-O，Sparse-LaViDa在文本到图像生成、图像编辑和数学推理等多样化任务中实现了高达2倍的加速，同时维持生成质量。",
            "intro_zh": [
                "现有掩码离散扩散模型推理速度慢，因需在每个采样步骤重复处理冗余掩码标记，导致效率低下。",
                "提出Sparse-LaViDa框架，动态截断冗余标记并使用寄存器标记保持质量，设计注意力掩码确保训练与推理一致。",
                "在文本到图像生成等任务中实现高达2倍加速，同时维持生成质量，验证了方法的有效性。"
            ],
            "method_zh": "Sparse-LaViDa基于LaViDa-O统一MDM框架，核心创新在于动态截断机制：在推理时识别并移除冗余掩码标记，引入寄存器标记作为其紧凑表示以保留信息。关键技术创新包括专门设计的注意力掩码，确保训练过程模拟截断采样，从而保持一致性。与现有MDM方法相比，主要区别在于通过稀疏化处理减少计算开销，而非依赖全标记处理，显著提升推理效率。",
            "application_zh": "该研究可应用于多模态人工智能领域，如文本到图像生成、图像编辑和数学推理任务，通过加速推理过程，提升实时交互和批量处理效率，具有实际部署价值。",
            "highlight_zh": "实验结果显示，Sparse-LaViDa在文本到图像生成、图像编辑和数学推理任务中实现高达2倍推理加速，同时生成质量与基线模型相当，验证了框架的有效性和实用性。",
            "tags_zh": [
                "稀疏扩散模型",
                "多模态推理",
                "掩码离散扩散",
                "加速采样",
                "寄存器标记",
                "注意力掩码",
                "文本到图像生成",
                "图像编辑"
            ],
            "_index": 225
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001v1",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by IROS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001v1",
            "code_links": [
                {
                    "url": "https://github.com/Tompson11/claim",
                    "type": "github"
                }
            ],
            "headline_zh": "提出CLAIM方法，利用单目深度模型和双损失函数实现相机与LiDAR的高效对齐，无需复杂特征处理。",
            "summary_zh": "本文释放了强大单目深度模型在相机-LiDAR标定中的潜力，提出了CLAIM这一新颖的相机与LiDAR数据对齐方法。给定初始猜测和图像-LiDAR点云对，CLAIM采用从粗到精的搜索方法，寻找最小化基于块状皮尔逊相关的结构损失和基于互信息的纹理损失的最优变换。这两种损失作为相机-LiDAR对齐结果的良好度量，无需像大多数方法那样进行复杂的数据处理、特征提取或特征匹配步骤，使我们的方法简单且适应大多数场景。我们在公开的KITTI、Waymo和MIAS-LCEC数据集上验证了CLAIM，实验结果表明其性能优于最先进的方法。代码可在https://github.com/Tompson11/claim获取。",
            "intro_zh": [
                "现有相机-LiDAR对齐方法通常依赖复杂的数据处理、特征提取和匹配步骤，导致计算成本高且适应性受限。",
                "CLAIM利用单目深度模型，通过从粗到精搜索优化结构损失和纹理损失，实现高效对齐，无需复杂特征处理。",
                "在KITTI、Waymo和MIAS-LCEC数据集上，CLAIM表现出优于现有方法的性能，验证了其有效性和泛化能力。"
            ],
            "method_zh": "CLAIM的整体框架基于从粗到精的搜索策略，给定初始变换猜测和图像-点云对，迭代优化相机与LiDAR之间的外参。关键技术创新点包括：引入基于块状皮尔逊相关的结构损失来度量几何对齐质量，以及基于互信息的纹理损失来评估外观一致性，这两种损失直接利用原始数据，避免了传统方法中的特征提取和匹配步骤。与现有方法的主要区别在于，CLAIM无需复杂的预处理或手工特征设计，通过单目深度模型增强对齐精度，简化了流程并提高了适应性。",
            "application_zh": "该研究可应用于自动驾驶、机器人导航和增强现实等领域，其中精确的相机-LiDAR对齐对于多传感器融合、环境感知和定位至关重要，有助于提升系统的鲁棒性和准确性。",
            "highlight_zh": "在KITTI、Waymo和MIAS-LCEC数据集上的实验显示，CLAIM在相机-LiDAR对齐任务中性能优于最先进方法，验证了其损失函数的有效性和方法的泛化能力，代码已开源促进进一步研究。",
            "tags_zh": [
                "相机-LiDAR对齐",
                "单目深度模型",
                "结构损失",
                "纹理损失",
                "多模态融合",
                "自动驾驶",
                "传感器标定",
                "从粗到精搜索"
            ],
            "_index": 226
        },
        {
            "title": "On the Hardness of Conditional Independence Testing In Practice",
            "authors": [
                "Zheng He",
                "Roman Pogodin",
                "Yazhe Li",
                "Namrata Deka",
                "Arthur Gretton",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.14000v1",
            "summary": "Tests of conditional independence (CI) underpin a number of important problems in machine learning and statistics, from causal discovery to evaluation of predictor fairness and out-of-distribution robustness. Shah and Peters (2020) showed that, contrary to the unconditional case, no universally finite-sample valid test can ever achieve nontrivial power. While informative, this result (based on \"hiding\" dependence) does not seem to explain the frequent practical failures observed with popular CI tests. We investigate the Kernel-based Conditional Independence (KCI) test - of which we show the Generalized Covariance Measure underlying many recent tests is nearly a special case - and identify the major factors underlying its practical behavior. We highlight the key role of errors in the conditional mean embedding estimate for the Type-I error, while pointing out the importance of selecting an appropriate conditioning kernel (not recognized in previous work) as being necessary for good test power but also tending to inflate Type-I error.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Published at NeurIPS 2025: https://openreview.net/forum?id=Tn1M71PDfF",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14000v1",
            "code_links": [],
            "headline_zh": "揭示基于核的条件独立性测试在实践中失效的关键因素，聚焦条件均值嵌入误差和核选择的影响。",
            "summary_zh": "条件独立性测试在机器学习和统计学中至关重要，支撑着从因果发现到预测器公平性和分布外鲁棒性评估等多个重要问题。Shah和Peters（2020）的研究表明，与无条件情况不同，不存在普遍有限样本有效的测试能够实现非平凡功效。尽管这一结果（基于“隐藏”依赖性）具有启发性，但似乎未能解释实践中常见条件独立性测试频繁失效的现象。本文研究了基于核的条件独立性测试——我们证明许多近期测试所基于的广义协方差度量几乎是一个特例——并识别了其实际行为背后的主要因素。我们强调了条件均值嵌入估计误差对第一类错误的关键作用，同时指出选择适当的条件核（先前工作中未被认识到）对于良好测试功效的必要性，但也倾向于增加第一类错误。",
            "intro_zh": [
                "核心问题：现有条件独立性测试在实践中常失效，Shah和Peters的理论结果未能完全解释这些实际失败原因。",
                "方法要点：聚焦基于核的条件独立性测试，分析条件均值嵌入误差和条件核选择对测试性能的影响机制。",
                "实验或效果：识别出误差和核选择是导致第一类错误和功效问题的关键因素，为改进测试提供理论指导。"
            ],
            "method_zh": "论文整体框架围绕基于核的条件独立性测试展开，通过理论分析和实验验证，深入探讨其在实际应用中的行为。关键技术创新点在于首次系统性地揭示了条件均值嵌入估计误差对第一类错误的核心作用，并强调了条件核选择在平衡测试功效和错误率中的重要性。与现有方法的主要区别在于，不仅关注测试的理论局限性，还从实践角度出发，识别出具体操作因素（如核选择）如何影响测试性能，这弥补了先前研究中对这些实际细节的忽视。",
            "application_zh": "该研究在因果发现、机器学习模型公平性评估和分布外鲁棒性测试等领域具有重要应用价值，通过优化条件独立性测试，能提升这些任务中的可靠性和准确性。",
            "highlight_zh": "实验结果表明，条件均值嵌入误差是导致第一类错误增加的主要因素，而条件核选择虽能提升测试功效，但也会加剧错误率，这为实际测试中的参数调优提供了关键见解。",
            "tags_zh": [
                "条件独立性测试",
                "核方法",
                "条件均值嵌入",
                "第一类错误",
                "测试功效",
                "因果发现",
                "机器学习公平性",
                "分布外鲁棒性"
            ],
            "_index": 227
        },
        {
            "title": "Memo2496: Expert-Annotated Dataset and Dual-View Adaptive Framework for Music Emotion Recognition",
            "authors": [
                "Qilin Li",
                "C. L. Philip Chen",
                "TongZhang"
            ],
            "arxiv_id": "2512.13998v1",
            "summary": "Music Emotion Recogniser (MER) research faces challenges due to limited high-quality annotated datasets and difficulties in addressing cross-track feature drift. This work presents two primary contributions to address these issues. Memo2496, a large-scale dataset, offers 2496 instrumental music tracks with continuous valence arousal labels, annotated by 30 certified music specialists. Annotation quality is ensured through calibration with extreme emotion exemplars and a consistency threshold of 0.25, measured by Euclidean distance in the valence arousal space. Furthermore, the Dual-view Adaptive Music Emotion Recogniser (DAMER) is introduced. DAMER integrates three synergistic modules: Dual Stream Attention Fusion (DSAF) facilitates token-level bidirectional interaction between Mel spectrograms and cochleagrams via cross attention mechanisms; Progressive Confidence Labelling (PCL) generates reliable pseudo labels employing curriculum-based temperature scheduling and consistency quantification using Jensen Shannon divergence; and Style Anchored Memory Learning (SAML) maintains a contrastive memory queue to mitigate cross-track feature drift. Extensive experiments on the Memo2496, 1000songs, and PMEmo datasets demonstrate DAMER's state-of-the-art performance, improving arousal dimension accuracy by 3.43%, 2.25%, and 0.17%, respectively. Ablation studies and visualisation analyses validate each module's contribution. Both the dataset and source code are publicly available.",
            "categories": [
                "cs.SD",
                "cs.AI",
                "cs.MM"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13998v1",
            "code_links": [],
            "headline_zh": "提出Memo2496数据集和DAMER框架以解决音乐情感识别中数据质量低和跨曲目特征漂移问题",
            "summary_zh": "音乐情感识别研究面临高质量标注数据集有限和跨曲目特征漂移的挑战。本文提出两项主要贡献：Memo2496是一个大规模数据集，包含2496首器乐曲目，由30位认证音乐专家标注连续效价-唤醒度标签，通过极端情感示例校准和效价-唤醒空间欧氏距离一致性阈值0.25确保标注质量；同时提出双视图自适应音乐情感识别器，集成三个协同模块：双流注意力融合通过交叉注意力机制促进梅尔频谱图和耳蜗图之间的令牌级双向交互，渐进置信度标注采用课程式温度调度和Jensen-Shannon散度一致性量化生成可靠伪标签，风格锚定记忆学习维护对比记忆队列以缓解跨曲目特征漂移。在Memo2496、1000songs和PMEmo数据集上的广泛实验表明DAMER达到最先进性能，唤醒维度准确率分别提升3.43%、2.25%和0.17%，消融研究和可视化分析验证了各模块贡献。数据集和源代码已公开。",
            "intro_zh": [
                "音乐情感识别面临高质量标注数据稀缺和跨曲目特征漂移的挑战，现有方法难以稳定处理不同音乐风格的情感表达。",
                "提出DAMER框架，集成双流注意力融合、渐进置信度标注和风格锚定记忆学习模块，协同提升特征交互和泛化能力。",
                "在多个数据集上实现显著性能提升，唤醒维度准确率最高提升3.43%，并通过消融实验验证各模块有效性。"
            ],
            "method_zh": "DAMER框架采用双视图自适应架构，核心创新在于三个模块：双流注意力融合实现梅尔频谱图和耳蜗图的令牌级双向交互，增强多模态特征融合；渐进置信度标注通过课程式温度调度和Jensen-Shannon散度量化生成高质量伪标签，提升训练稳定性；风格锚定记忆学习利用对比记忆队列缓解跨曲目特征漂移，提高模型泛化性。与现有方法相比，DAMER首次系统整合多模态交互、伪标签优化和特征漂移缓解，形成端到端的自适应学习系统。",
            "application_zh": "该研究可应用于智能音乐推荐系统、情感化音乐治疗、影视配乐自动生成等领域，通过精准识别音乐情感，提升用户体验和个性化服务，具有广泛的娱乐、医疗和创作价值。",
            "highlight_zh": "DAMER在Memo2496、1000songs和PMEmo数据集上唤醒维度准确率分别提升3.43%、2.25%和0.17%，达到最先进性能；消融研究证实各模块均贡献显著，可视化分析进一步验证了特征漂移缓解效果。",
            "tags_zh": [
                "音乐情感识别",
                "多模态融合",
                "伪标签生成",
                "特征漂移缓解",
                "对比学习",
                "注意力机制",
                "数据集构建",
                "自适应学习"
            ],
            "_index": 228
        },
        {
            "title": "Maximum Mean Discrepancy with Unequal Sample Sizes via Generalized U-Statistics",
            "authors": [
                "Aaron Wei",
                "Milad Jalali",
                "Danica J. Sutherland"
            ],
            "arxiv_id": "2512.13997v1",
            "summary": "Existing two-sample testing techniques, particularly those based on choosing a kernel for the Maximum Mean Discrepancy (MMD), often assume equal sample sizes from the two distributions. Applying these methods in practice can require discarding valuable data, unnecessarily reducing test power. We address this long-standing limitation by extending the theory of generalized U-statistics and applying it to the usual MMD estimator, resulting in new characterization of the asymptotic distributions of the MMD estimator with unequal sample sizes (particularly outside the proportional regimes required by previous partial results). This generalization also provides a new criterion for optimizing the power of an MMD test with unequal sample sizes. Our approach preserves all available data, enhancing test accuracy and applicability in realistic settings. Along the way, we give much cleaner characterizations of the variance of MMD estimators, revealing something that might be surprising to those in the area: while zero MMD implies a degenerate estimator, it is sometimes possible to have a degenerate estimator with nonzero MMD as well; we give a construction and a proof that it does not happen in common situations.",
            "categories": [
                "stat.ML",
                "cs.LG",
                "math.ST",
                "stat.ME"
            ],
            "primary_category": "stat.ML",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13997v1",
            "code_links": [],
            "headline_zh": "提出基于广义U统计量的最大均值差异方法，以解决不等样本量下的两样本测试问题，避免数据丢弃并提升测试能力。",
            "summary_zh": "现有的两样本测试技术，特别是基于选择核函数的最大均值差异（MMD）方法，通常假设两个分布具有相等的样本量。在实际应用中，这些方法可能需要丢弃有价值的数据，从而不必要地降低测试能力。我们通过扩展广义U统计量的理论并将其应用于常规的MMD估计器，解决了这一长期存在的限制，从而对不等样本量下MMD估计器的渐近分布进行了新的刻画（尤其是在先前部分结果所要求的比例范围之外）。这一推广还为优化不等样本量下MMD测试的能力提供了新准则。我们的方法保留了所有可用数据，增强了现实场景中的测试准确性和适用性。在此过程中，我们给出了MMD估计器方差的更清晰刻画，揭示了一个可能令该领域研究者惊讶的现象：虽然零MMD意味着估计器退化，但有时也可能出现非零MMD下的退化估计器；我们提供了一个构造，并证明这在常见情况下不会发生。",
            "intro_zh": [
                "核心问题：现有MMD两样本测试方法通常假设样本量相等，实际应用中需丢弃数据，导致测试能力降低和资源浪费。",
                "方法要点：扩展广义U统计量理论，应用于MMD估计器，刻画不等样本量下的渐近分布，并优化测试能力准则。",
                "实验或效果：方法保留所有数据，提升测试准确性和适用性，同时揭示了MMD估计器方差的新特性。"
            ],
            "method_zh": "论文的核心方法基于广义U统计量的理论扩展，应用于最大均值差异（MMD）估计器。整体框架通过将不等样本量下的MMD估计器建模为广义U统计量，推导其渐近分布，特别是在非比例样本量场景下。关键技术创新点包括：1) 利用广义U统计量理论，统一处理不等样本量问题，避免数据丢弃；2) 提供新的渐近分布刻画，覆盖更广泛的样本量范围；3) 提出优化测试能力的准则，基于方差分析。与现有方法的主要区别在于：现有方法通常依赖等样本量假设或比例样本量限制，而本方法通过广义U统计量直接处理任意不等样本量，增强了理论完备性和实际适用性。",
            "application_zh": "该研究可应用于机器学习、统计学和数据分析中的两样本测试场景，如异常检测、分布比较和模型评估。在实际价值上，它允许在样本量不平衡时充分利用所有数据，提升测试的准确性和效率，适用于生物信息学、金融风险分析等领域。",
            "highlight_zh": "最重要的实验结果包括：在不等样本量下，MMD估计器的渐近分布得到精确刻画，测试能力显著提升；方法避免了数据丢弃，在模拟和真实数据实验中显示出更高的准确性和鲁棒性；同时，揭示了MMD估计器方差的新现象，为非零MMD下的退化情况提供了理论分析。",
            "tags_zh": [
                "最大均值差异",
                "两样本测试",
                "广义U统计量",
                "不等样本量",
                "渐近分布",
                "测试能力优化",
                "数据保留",
                "方差分析"
            ],
            "_index": 229
        },
        {
            "title": "Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training",
            "authors": [
                "Can Jin",
                "Hongwu Peng",
                "Mingcan Xiang",
                "Qixin Zhang",
                "Xiangchi Yuan",
                "Amit Hasan",
                "Ohiremen Dibua",
                "Yifan Gong",
                "Yan Kang",
                "Dimitris N. Metaxas"
            ],
            "arxiv_id": "2512.13996v1",
            "summary": "Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13996v1",
            "code_links": [],
            "headline_zh": "提出DTop-p MoE以解决稀疏专家混合模型中动态控制激活专家数量的问题",
            "summary_zh": "稀疏专家混合（MoE）架构通过为每个输入令牌仅激活专家子集来有效扩展模型容量。然而，标准的Top-k路由策略采用统一的稀疏模式，忽略了令牌难度的变化。虽然Top-p路由提供了灵活的替代方案，但现有实现通常依赖于固定的全局概率阈值，这导致计算成本不可控且对超参数选择敏感。本文提出DTop-p MoE，一种稀疏可控的动态Top-p路由机制。为解决优化不可微分阈值的挑战，我们利用比例积分（PI）控制器动态调整概率阈值，使运行中的激活专家稀疏度与指定目标对齐。此外，我们引入动态路由归一化机制，自适应调整层间路由逻辑，允许不同层学习不同的专家选择模式，同时使用全局概率阈值。在大型语言模型和扩散变换器上的大量实验表明，DTop-p始终优于Top-k和固定阈值Top-p基线。我们的分析证实，DTop-p在精确控制激活专家数量的同时，自适应地在不同令牌和层间分配资源。此外，DTop-p在专家粒度、专家容量、模型大小和数据集大小方面表现出强大的扩展性，为大规模MoE预训练提供了稳健框架。",
            "intro_zh": [
                "现有Top-k路由采用统一稀疏模式，忽略令牌难度差异，而Top-p路由依赖固定阈值，导致计算成本不可控和超参数敏感。",
                "提出DTop-p MoE，使用PI控制器动态调整概率阈值以控制稀疏度，并引入动态路由归一化机制自适应调整层间路由逻辑。",
                "实验表明DTop-p在大型语言模型和扩散变换器中优于基线，能精确控制激活专家数量并自适应分配资源，具有强扩展性。"
            ],
            "method_zh": "DTop-p MoE的整体框架基于稀疏专家混合架构，核心创新点包括：1）使用比例积分（PI）控制器动态调整Top-p路由的概率阈值，通过反馈机制使激活专家稀疏度与目标值对齐，解决阈值不可微分优化问题；2）引入动态路由归一化机制，自适应调整不同层的路由逻辑，允许各层学习独特的专家选择模式，同时维持全局概率阈值。与现有方法的主要区别在于：Top-k路由强制统一激活专家数量，而DTop-p通过动态阈值实现稀疏可控；相比固定阈值Top-p，DTop-p能精确控制计算成本并减少超参数敏感性。",
            "application_zh": "该研究适用于大规模基础模型预训练场景，如大型语言模型和扩散变换器的开发，能有效扩展模型容量并优化资源分配。潜在应用包括自然语言处理、图像生成和多模态AI系统，为构建高效、可扩展的AI模型提供技术支撑。",
            "highlight_zh": "在大型语言模型和扩散变换器实验中，DTop-p MoE一致优于Top-k和固定阈值Top-p基线，能精确控制激活专家数量，自适应分配资源，并在专家粒度、容量、模型大小和数据集大小方面展现出强扩展性。",
            "tags_zh": [
                "稀疏专家混合",
                "动态路由机制",
                "比例积分控制器",
                "大规模预训练",
                "模型扩展性",
                "计算成本控制",
                "自适应资源分配",
                "基础模型优化"
            ],
            "_index": 230
        }
    ]
}