{
    "papers": [
        {
            "title": "Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model",
            "authors": [
                "Zhaofeng Hu",
                "Hongrui Yu",
                "Vaidhyanathan Chandramouli",
                "Ci-Jyun Liang"
            ],
            "arxiv_id": "2512.14031v1",
            "summary": "This study evaluates two leading approaches for teaching construction robots new skills to understand their applicability for construction automation: a Vision-Language-Action (VLA) model and Reinforcement Learning (RL) methods. The goal is to understand both task performance and the practical effort needed to deploy each approach on real jobs. The authors developed two teleoperation interfaces to control the robots and collect the demonstrations needed, both of which proved effective for training robots for long-horizon and dexterous tasks. In addition, the authors conduct a three-stage evaluation. First, the authors compare a Multi-Layer Perceptron (MLP) policy with a Deep Q-network (DQN) imitation model to identify the stronger RL baseline, focusing on model performance, generalization, and a pick-up experiment. Second, three different VLA models are trained in two different scenarios and compared with each other. Third, the authors benchmark the selected RL baseline against the VLA model using computational and sample-efficiency measures and then a robot experiment on a multi-stage panel installation task that includes transport and installation. The VLA model demonstrates strong generalization and few-shot capability, achieving 60% and 100% success in the pickup phase. In comparison, DQN can be made robust but needs additional noise during tuning, which increases the workload. Overall, the findings indicate that VLA offers practical advantages for changing tasks by reducing programming effort and enabling useful performance with minimal data, while DQN provides a viable baseline when sufficient tuning effort is acceptable.",
            "categories": [
                "cs.RO",
                "cs.AI"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14031v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "teleoperation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 24.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "对比VLA模型与强化学习，提升建筑机器人操作技能并实现高效样本利用",
            "summary_zh": "本研究评估了两种领先的方法，即视觉-语言-动作（VLA）模型和强化学习（RL）方法，用于训练建筑机器人掌握新技能，旨在了解它们在建筑自动化中的适用性。作者开发了两种遥操作界面来控制机器人并收集所需的演示数据，这两种界面都被证明对训练机器人执行长时程和灵巧任务有效。此外，作者进行了一个三阶段的评估。首先，作者比较了多层感知机（MLP）策略与深度Q网络（DQN）模仿模型，以确定更强的RL基线，重点关注模型性能、泛化能力和一个拾取实验。其次，在两种不同的场景中训练了三种不同的VLA模型，并将它们相互比较。第三，作者使用计算和样本效率指标，以及一个包含运输和安装的多阶段面板安装机器人实验，将选定的RL基线与VLA模型进行基准测试。VLA模型表现出强大的泛化能力和少样本学习能力，在拾取阶段实现了60%和100%的成功率。相比之下，DQN可以通过在调整过程中添加额外的噪声来使其更加鲁棒，但这增加了工作量。总的来说，研究结果表明，VLA通过减少编程工作量和以最少的数据实现有用的性能，为更改任务提供了实际优势，而DQN在可以接受足够的调整工作量时，提供了一个可行的基线。",
            "intro_zh": [
                "现有建筑机器人技能学习方法在泛化性和样本效率方面存在不足，难以适应快速变化的施工任务。",
                "本研究对比VLA模型和强化学习方法，探索利用少量样本数据高效训练机器人完成复杂建筑任务的策略。",
                "实验表明，VLA模型在泛化性和少样本学习方面优于DQN，能以更少的编程工作量实现较好的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决建筑机器人技能学习中泛化能力弱和样本效率低的问题。现有方法通常需要大量的训练数据和精细的调参，难以适应建筑场景中任务的快速变化。因此，如何利用少量样本数据，使机器人快速掌握新的操作技能，是本研究要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是对比研究视觉-语言-动作（VLA）模型和强化学习（RL）方法在建筑机器人技能学习中的表现。VLA模型通过结合视觉信息、自然语言指令和动作指令，使机器人能够理解任务目标并执行相应的动作。强化学习方法则通过与环境交互，学习最优的策略。通过对比两种方法的性能，可以找到更适合建筑机器人技能学习的方法。\\n\\n**技术框架**：本研究的技术框架主要包括以下几个部分：1) 两种遥操作界面，用于收集机器人操作的演示数据；2) 三种VLA模型，用于学习视觉、语言和动作之间的关系；3) 基于DQN的强化学习模型，作为基线方法；4) 一个三阶段的评估流程，包括模型性能评估、泛化能力评估和机器人实验。\\n\\n**关键创新**：本研究的关键创新在于对比了VLA模型和强化学习方法在建筑机器人技能学习中的表现，并验证了VLA模型在泛化性和少样本学习方面的优势。此外，本研究还开发了两种遥操作界面，用于收集机器人操作的演示数据，为VLA模型的训练提供了数据支持。\\n\\n**关键设计**：在VLA模型方面，论文采用了三种不同的模型结构，并探索了不同的训练策略。在强化学习方面，论文采用了DQN算法，并针对建筑机器人的特点进行了优化。此外，论文还设计了一个多阶段的面板安装任务，用于评估VLA模型和强化学习方法的性能。",
            "application_zh": "该研究成果可应用于建筑自动化领域，例如建筑构件的搬运、安装和拆卸等任务。通过使用VLA模型，可以减少人工编程的工作量，提高机器人的自主性和适应性，从而提高建筑施工的效率和质量。此外，该研究还可以推广到其他需要机器人执行复杂操作的领域，例如制造业、物流等。",
            "highlight_zh": "实验结果表明，VLA模型在拾取阶段实现了60%和100%的成功率，表现出强大的泛化能力和少样本学习能力。相比之下，DQN需要额外的噪声调整才能达到较好的鲁棒性，增加了工作量。在多阶段面板安装任务中，VLA模型也表现出优于DQN的性能，验证了VLA模型在建筑机器人技能学习中的优势。",
            "tags_zh": [
                "建筑机器人",
                "技能学习",
                "视觉-语言-动作模型",
                "强化学习",
                "样本效率"
            ],
            "_index": 0,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14031v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14031v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14031v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models",
            "authors": [
                "Zechen Bai",
                "Chen Gao",
                "Mike Zheng Shou"
            ],
            "arxiv_id": "2512.14666v1",
            "summary": "Achieving truly adaptive embodied intelligence requires agents that learn not just by imitating static demonstrations, but by continuously improving through environmental interaction, which is akin to how humans master skills through practice. Vision-Language-Action (VLA) models have advanced robotic manipulation by leveraging large language models, yet remain fundamentally limited by Supervised Finetuning (SFT): requiring hundreds of demonstrations per task, rigidly memorizing trajectories, and failing to adapt when deployment conditions deviate from training. We introduce EVOLVE-VLA, a test-time training framework enabling VLAs to continuously adapt through environment interaction with minimal or zero task-specific demonstrations. The key technical challenge is replacing oracle reward signals (unavailable at test time) with autonomous feedback. We address this through a learned progress estimator providing dense feedback, and critically, we design our framework to ``tame'' this inherently noisy signal via two mechanisms: (1) an accumulative progress estimation mechanism smoothing noisy point-wise estimates, and (2) a progressive horizon extension strategy enabling gradual policy evolution. EVOLVE-VLA achieves substantial gains: +8.6\\% on long-horizon tasks, +22.0\\% in 1-shot learning, and enables cross-task generalization -- achieving 20.8\\% success on unseen tasks without task-specific demonstrations training (vs. 0\\% for pure SFT). Qualitative analysis reveals emergent capabilities absent in demonstrations, including error recovery and novel strategies. This work represents a critical step toward VLAs that truly learn and adapt, moving beyond static imitation toward continuous self-improvements.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14666v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]vision-language-action",
                        "[T]VLA",
                        "large language model"
                    ],
                    "score": 21.0
                }
            ],
            "relevance_score": 23.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVOLVE-VLA以解决视觉-语言-动作模型适应性不足问题",
            "summary_zh": "实现真正自适应的具身智能需要代理不仅通过模仿静态演示学习，还需通过与环境的持续互动不断改进。视觉-语言-动作（VLA）模型在机器人操作中取得了进展，但仍受限于监督微调（SFT），需要大量演示并无法适应训练条件的变化。本文提出EVOLVE-VLA，一个在测试时通过环境互动进行持续适应的训练框架，能够在最少或零任务特定演示的情况下进行学习。关键技术挑战在于用自主反馈替代不可用的奖励信号。我们通过学习的进度估计器提供密集反馈，并设计了两种机制来“驯服”这种噪声信号。EVOLVE-VLA在长时间任务上提升了8.6%，在一次学习中提升了22.0%，并实现了跨任务泛化，成功率达到20.8%。",
            "intro_zh": [
                "现有视觉-语言-动作模型依赖于大量的演示数据，无法适应训练与部署条件的变化，限制了其自适应能力。",
                "本文提出EVOLVE-VLA框架，通过环境互动进行测试时训练，利用自主反馈替代传统的奖励信号，实现持续学习。",
                "实验结果表明，EVOLVE-VLA在长时间任务上提升8.6%，一次学习任务上提升22.0%，并在未见任务上实现20.8%的成功率。"
            ],
            "method_zh": "**问题定义**：本文旨在解决视觉-语言-动作模型在测试阶段缺乏适应性的问题。现有方法依赖于大量的演示数据，无法灵活应对环境变化，导致学习效果不佳。\\n\\n**核心思路**：提出EVOLVE-VLA框架，通过环境反馈进行测试时训练，替代传统的奖励信号，利用学习的进度估计器提供密集反馈，从而实现持续自我改进。\\n\\n**技术框架**：EVOLVE-VLA框架包括两个主要模块：进度估计器和策略演化机制。进度估计器负责提供环境反馈，而策略演化机制则通过平滑反馈和逐步扩展策略来优化学习过程。\\n\\n**关键创新**：最重要的创新在于用自主反馈替代不可用的奖励信号，并通过进度估计器和策略演化机制有效处理噪声信号。这一设计使得模型能够在没有任务特定演示的情况下进行学习和适应。\\n\\n**关键设计**：在进度估计器中，采用累积进度估计机制来平滑噪声反馈，同时引入渐进式视野扩展策略，以实现策略的逐步演化。",
            "application_zh": "该研究的潜在应用领域包括智能机器人、自动化操作和人机交互等。通过实现持续学习和适应能力，EVOLVE-VLA能够在动态环境中更有效地执行复杂任务，提升机器人在实际应用中的灵活性和智能化水平。",
            "highlight_zh": "实验结果显示，EVOLVE-VLA在长时间任务上提升了8.6%，在一次学习任务中提升了22.0%。此外，该模型在未见任务上实现了20.8%的成功率，显著优于传统的监督微调方法（0%成功率）。",
            "tags_zh": [
                "视觉-语言-动作",
                "自适应学习",
                "环境反馈",
                "机器人操作",
                "持续学习",
                "策略演化",
                "进度估计"
            ],
            "_index": 1,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14666v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14666v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14666v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation",
            "authors": [
                "Sisi Dai",
                "Kai Xu"
            ],
            "arxiv_id": "2512.14095v1",
            "summary": "Despite significant progress in text-driven 4D human-object interaction (HOI) generation with supervised methods, the scalability remains limited by the scarcity of large-scale 4D HOI datasets. To overcome this, recent approaches attempt zero-shot 4D HOI generation with pre-trained image diffusion models. However, interaction cues are minimally distilled during the generation process, restricting their applicability across diverse scenarios. In this paper, we propose AnchorHOI, a novel framework that thoroughly exploits hybrid priors by incorporating video diffusion models beyond image diffusion models, advancing 4D HOI generation. Nevertheless, directly optimizing high-dimensional 4D HOI with such priors remains challenging, particularly for human pose and compositional motion. To address this challenge, AnchorHOI introduces an anchor-based prior distillation strategy, which constructs interaction-aware anchors and then leverages them to guide generation in a tractable two-step process. Specifically, two tailored anchors are designed for 4D HOI generation: anchor Neural Radiance Fields (NeRFs) for expressive interaction composition, and anchor keypoints for realistic motion synthesis. Extensive experiments demonstrate that AnchorHOI outperforms previous methods with superior diversity and generalization.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14095v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "NeRF",
                        "neural radiance field"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion synthesis"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱五：交互与反应 (Interaction & Reaction)",
                    "id": "5_interaction_reaction",
                    "matched_keywords": [
                        "[T]human-object interaction",
                        "HOI"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 21.0,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "5_interaction_reaction"
            ],
            "headline_zh": "AnchorHOI：基于锚点的先验知识蒸馏实现零样本4D人-物交互生成",
            "summary_zh": "本文提出AnchorHOI框架，旨在解决大规模4D人-物交互(HOI)数据集稀缺导致的文本驱动4D HOI生成可扩展性受限问题。AnchorHOI通过结合视频扩散模型和图像扩散模型，充分利用混合先验知识，从而推进4D HOI生成。针对直接优化高维4D HOI带来的挑战，特别是人体姿态和组合运动方面，AnchorHOI引入了一种基于锚点的先验知识蒸馏策略。该策略构建交互感知的锚点，并利用这些锚点在可处理的两步过程中指导生成。具体而言，为4D HOI生成设计了两个定制锚点：用于表达交互组合的锚点神经辐射场(NeRFs)和用于真实运动合成的锚点关键点。大量实验表明，AnchorHOI优于以往方法，具有更好的多样性和泛化性。",
            "intro_zh": [
                "现有文本驱动4D HOI生成方法受限于大规模数据集的稀缺，泛化能力不足。",
                "AnchorHOI利用图像和视频扩散模型，通过锚点先验蒸馏策略，指导4D HOI生成。",
                "实验表明，AnchorHOI在多样性和泛化性上优于现有方法，提升了生成质量。"
            ],
            "method_zh": "**问题定义**：现有文本驱动的4D人-物交互生成方法依赖于大规模的4D HOI数据集进行训练，但此类数据集的获取成本高昂且规模有限，导致模型在面对新的交互场景时泛化能力不足。此外，直接从文本生成复杂的4D HOI数据，特别是人体姿态和物体运动的组合，是一个极具挑战性的问题。\\n\\n**核心思路**：AnchorHOI的核心思路是利用预训练的图像和视频扩散模型作为先验知识，通过锚点（anchors）来引导4D HOI的生成过程。这种方法避免了直接在高维空间中优化复杂的4D HOI数据，而是通过锚点将生成过程分解为更易于处理的步骤。锚点的设计需要能够捕捉交互的关键信息，并指导生成过程朝着更真实、更多样化的方向发展。\\n\\n**技术框架**：AnchorHOI框架包含两个主要阶段：锚点生成阶段和基于锚点的生成阶段。在锚点生成阶段，首先根据文本描述构建交互感知的锚点，包括锚点NeRFs用于表达交互组合，以及锚点关键点用于真实运动合成。然后，在基于锚点的生成阶段，利用这些锚点作为先验知识，指导扩散模型生成最终的4D HOI数据。整个框架利用了图像和视频扩散模型的优势，并结合了锚点先验蒸馏策略，从而实现了零样本的4D HOI生成。\\n\\n**关键创新**：AnchorHOI的关键创新在于提出了基于锚点的先验知识蒸馏策略。与以往直接利用扩散模型生成4D HOI数据的方法不同，AnchorHOI通过引入锚点，将复杂的生成过程分解为更易于控制的步骤。这种方法不仅降低了优化难度，还能够更好地利用预训练模型的先验知识，从而生成更真实、更多样化的4D HOI数据。此外，针对4D HOI生成，定制化设计了锚点NeRFs和锚点关键点，分别用于表达交互组合和真实运动合成。\\n\\n**关键设计**：AnchorHOI的关键设计包括：1) 锚点NeRFs的设计，用于表达人与物体之间的交互关系，例如手握物体的方式、物体与身体的相对位置等。2) 锚点关键点的设计，用于捕捉人体运动的关键信息，例如关节的位置、运动轨迹等。3) 先验知识蒸馏策略，通过锚点将预训练扩散模型的先验知识传递到4D HOI生成过程中。4) 损失函数的设计，用于约束生成结果与锚点之间的关系，保证生成结果的真实性和一致性。具体的参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "AnchorHOI在虚拟现实、增强现实、游戏开发、机器人控制等领域具有广泛的应用前景。它可以用于生成逼真的人机交互场景，例如虚拟人物与虚拟物体的互动，从而提升用户体验。此外，AnchorHOI还可以用于训练机器人，使其能够更好地理解和执行人机交互任务。未来，该技术有望应用于更广泛的领域，例如智能家居、自动驾驶等。",
            "highlight_zh": "实验结果表明，AnchorHOI在零样本4D HOI生成任务中取得了显著的性能提升。与现有方法相比，AnchorHOI生成的4D HOI数据具有更高的真实性和多样性。通过定量评估和定性比较，证明了AnchorHOI在交互组合和运动合成方面的优势。具体的性能数据和对比基线在论文中有详细展示。",
            "tags_zh": [
                "4D人-物交互生成",
                "零样本学习",
                "扩散模型",
                "先验知识蒸馏",
                "神经辐射场",
                "锚点",
                "运动合成"
            ],
            "_index": 2,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14095v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14095v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14095v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation",
            "authors": [
                "Sirui Chen",
                "Zi-ang Cao",
                "Zhengyi Luo",
                "Fernando Castañeda",
                "Chenran Li",
                "Tingwu Wang",
                "Ye Yuan",
                "Linxi \"Jim\" Fan",
                "C. Karen Liu",
                "Yuke Zhu"
            ],
            "arxiv_id": "2512.14689v1",
            "summary": "Recent progress in humanoid robots has unlocked agile locomotion skills, including backflipping, running, and crawling. Yet it remains challenging for a humanoid robot to perform forceful manipulation tasks such as moving objects, wiping, and pushing a cart. We propose adaptive Compliance Humanoid control through hIsight Perturbation (CHIP), a plug-and-play module that enables controllable end-effector stiffness while preserving agile tracking of dynamic reference motions. CHIP is easy to implement and requires neither data augmentation nor additional reward tuning. We show that a generalist motion-tracking controller trained with CHIP can perform a diverse set of forceful manipulation tasks that require different end-effector compliance, such as multi-robot collaboration, wiping, box delivery, and door opening.",
            "categories": [
                "cs.RO",
                "cs.LG"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "The first two authors contributed equally. Project page: https://nvlabs.github.io/CHIP/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14689v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid",
                        "humanoid robot",
                        "[T]humanoid control",
                        "locomotion",
                        "manipulation"
                    ],
                    "score": 18.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 20.0,
            "hit_pillars": [
                "1_robot_core",
                "8_physics_animation"
            ],
            "headline_zh": "CHIP：通过后见之明扰动实现人型机器人自适应柔顺控制",
            "summary_zh": "人形机器人领域的最新进展已经解锁了敏捷的运动技能，包括后空翻、跑步和爬行。然而，人形机器人执行诸如移动物体、擦拭和推车等需要较大作用力的操作任务仍然具有挑战性。我们提出了一种通过后见之明扰动实现自适应柔顺的人形控制方法（CHIP），这是一个即插即用的模块，可以在保持动态参考运动的敏捷跟踪的同时，实现可控的末端执行器刚度。CHIP易于实现，不需要数据增强或额外的奖励调整。我们表明，使用CHIP训练的通用运动跟踪控制器可以执行各种需要不同末端执行器柔顺性的操作任务，例如多机器人协作、擦拭、箱子递送和开门。",
            "intro_zh": [
                "人形机器人难以完成需要较大作用力的操作任务，如移动物体等，现有方法在控制末端执行器柔顺性方面存在不足。",
                "CHIP通过后见之明扰动，实现末端执行器刚度的自适应控制，同时保持对动态参考运动的敏捷跟踪。",
                "实验表明，使用CHIP训练的通用控制器能够完成多种需要不同柔顺性的操作任务，无需额外数据增强或奖励调整。"
            ],
            "method_zh": "**问题定义**：论文旨在解决人形机器人难以完成需要较大作用力的操作任务的问题，例如移动物体、擦拭和推车等。现有方法在控制末端执行器柔顺性方面存在不足，难以在保持运动敏捷性的同时实现精确的作用力控制。\\n\\n**核心思路**：论文的核心思路是通过引入自适应柔顺控制，使人形机器人能够根据任务需求调整末端执行器的刚度。具体而言，通过后见之明扰动（Hindsight Perturbation）来学习控制策略，从而在训练过程中探索不同的柔顺性配置，并找到最优的控制策略。\\n\\n**技术框架**：CHIP作为一个即插即用的模块，可以集成到现有的运动跟踪控制器中。整体框架包括以下几个主要步骤：1) 给定参考运动和任务目标；2) 使用运动跟踪控制器生成初始动作；3) 通过后见之明扰动模块对动作进行扰动，改变末端执行器的刚度；4) 执行扰动后的动作，并观察结果；5) 使用后见之明经验重放（Hindsight Experience Replay）来学习控制策略，从而优化末端执行器的柔顺性。\\n\\n**关键创新**：CHIP的关键创新在于其自适应柔顺控制机制和后见之明扰动方法。与传统的固定柔顺性控制方法不同，CHIP能够根据任务需求动态调整末端执行器的刚度，从而提高机器人的操作能力。后见之明扰动方法允许机器人在训练过程中探索不同的柔顺性配置，并从中学习最优的控制策略。\\n\\n**关键设计**：CHIP的关键设计包括：1) 扰动策略的设计，需要保证扰动的有效性和安全性；2) 后见之明经验重放的实现，需要合理选择重放的经验，以提高学习效率；3) 损失函数的设计，需要综合考虑运动跟踪的精度和作用力控制的准确性。论文中并未详细描述具体的参数设置、损失函数和网络结构，这些细节可能需要参考相关的运动控制和强化学习文献。",
            "application_zh": "该研究成果可广泛应用于人形机器人的操作任务中，例如工业自动化、家庭服务、医疗辅助等领域。通过自适应柔顺控制，人形机器人能够更好地适应不同的任务环境和操作对象，提高其操作的灵活性和安全性。未来，该技术有望推动人形机器人在复杂环境下的应用，并实现更高级的人机协作。",
            "highlight_zh": "实验结果表明，使用CHIP训练的通用运动跟踪控制器能够成功完成多种需要不同末端执行器柔顺性的操作任务，例如多机器人协作、擦拭、箱子递送和开门。与没有使用CHIP的基线方法相比，CHIP在这些任务上取得了显著的性能提升，表明其能够有效地提高人形机器人的操作能力。具体的性能数据和提升幅度在论文中进行了详细的展示。",
            "tags_zh": [
                "人形机器人",
                "柔顺控制",
                "后见之明学习",
                "强化学习",
                "运动控制"
            ],
            "_index": 3,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14689v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14689v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14689v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives",
            "authors": [
                "Zihan Wang",
                "Jiashun Wang",
                "Jeff Tan",
                "Yiwen Zhao",
                "Jessica Hodgins",
                "Shubham Tulsiani",
                "Deva Ramanan"
            ],
            "arxiv_id": "2512.14696v1",
            "summary": "We introduce CRISP, a method that recovers simulatable human motion and scene geometry from monocular video. Prior work on joint human-scene reconstruction relies on data-driven priors and joint optimization with no physics in the loop, or recovers noisy geometry with artifacts that cause motion tracking policies with scene interactions to fail. In contrast, our key insight is to recover convex, clean, and simulation-ready geometry by fitting planar primitives to a point cloud reconstruction of the scene, via a simple clustering pipeline over depth, normals, and flow. To reconstruct scene geometry that might be occluded during interactions, we make use of human-scene contact modeling (e.g., we use human posture to reconstruct the occluded seat of a chair). Finally, we ensure that human and scene reconstructions are physically-plausible by using them to drive a humanoid controller via reinforcement learning. Our approach reduces motion tracking failure rates from 55.2\\% to 6.9\\% on human-centric video benchmarks (EMDB, PROX), while delivering a 43\\% faster RL simulation throughput. We further validate it on in-the-wild videos including casually-captured videos, Internet videos, and even Sora-generated videos. This demonstrates CRISP's ability to generate physically-valid human motion and interaction environments at scale, greatly advancing real-to-sim applications for robotics and AR/VR.",
            "categories": [
                "cs.CV",
                "cs.GR",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://crisp-real2sim.github.io/CRISP-Real2Sim/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14696v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "humanoid control",
                        "[T]real2sim"
                    ],
                    "score": 10.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "scene reconstruction"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "motion tracking"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "3_perception_slam",
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "CRISP：基于单目视频和平面场景原语的接触引导Real2Sim方法",
            "summary_zh": "CRISP是一种从单目视频中恢复可模拟的人体运动和场景几何的方法。现有的人体-场景联合重建工作依赖于数据驱动的先验和无物理引擎的联合优化，或者恢复的几何体存在噪声和伪影，导致基于场景交互的运动跟踪策略失败。CRISP的核心思想是通过拟合平面原语到场景的点云重建，来恢复凸的、干净的、可用于仿真的几何体，这通过一个简单的深度、法线和光流聚类流程实现。为了重建交互过程中可能被遮挡的场景几何，我们利用了人体-场景接触建模（例如，使用人体姿势来重建椅子被遮挡的座位）。最后，我们通过强化学习驱动人形控制器，确保人体和场景重建在物理上是合理的。在以人为中心的视频基准测试（EMDB、PROX）中，我们的方法将运动跟踪失败率从55.2％降低到6.9％，同时提供了快43％的RL模拟吞吐量。我们还在包括随意拍摄的视频、互联网视频甚至Sora生成的视频在内的真实视频中验证了它。这证明了CRISP大规模生成物理上有效的人体运动和交互环境的能力，极大地推进了机器人和AR/VR的real-to-sim应用。",
            "intro_zh": [
                "现有方法在人体-场景联合重建中，要么依赖数据先验和无物理优化，要么重建的几何体质量差，导致交互模拟失败。",
                "CRISP通过平面原语拟合点云重建，并结合人体-场景接触建模来恢复干净、凸的、可用于仿真的场景几何。",
                "实验表明，CRISP显著降低了运动跟踪失败率，提高了强化学习模拟的吞吐量，并在真实视频中表现良好。"
            ],
            "method_zh": "**问题定义**：现有方法在从单目视频重建可用于物理仿真的3D人体和场景时，存在以下痛点：一是依赖数据驱动的先验，泛化性不足；二是联合优化过程中缺乏物理约束，导致重建的几何体不真实，无法直接用于模拟；三是重建的场景几何体常常包含噪声和伪影，使得基于场景交互的运动跟踪策略容易失败。\\n\\n**核心思路**：CRISP的核心思路是利用平面原语来表示场景几何，因为现实世界中很多场景都包含大量的平面结构。通过将点云重建结果拟合到平面原语，可以得到干净、凸的、易于仿真的场景几何。此外，CRISP还利用人体-场景接触信息来推断被遮挡的场景几何，并使用强化学习来保证重建结果的物理合理性。\\n\\n**技术框架**：CRISP的整体流程包括以下几个主要阶段：1) 从单目视频中重建点云；2) 对点云进行聚类，提取平面原语；3) 利用人体-场景接触信息来推断被遮挡的场景几何；4) 使用重建的人体和场景来训练一个强化学习控制器，以保证重建结果的物理合理性。\\n\\n**关键创新**：CRISP最重要的技术创新点在于将平面原语拟合与人体-场景接触建模相结合，从而能够从单目视频中重建出高质量的、可用于物理仿真的3D人体和场景。这种方法避免了对数据驱动先验的过度依赖，并且能够有效地处理遮挡问题。\\n\\n**关键设计**：CRISP的关键设计包括：1) 使用深度、法线和光流信息进行点云聚类，以提取平面原语；2) 设计一个基于接触信息的场景几何推断模块，利用人体姿势来预测被遮挡的场景区域；3) 使用强化学习来优化人形控制器的参数，使得重建的人体和场景能够进行物理上合理的交互。",
            "application_zh": "CRISP具有广泛的应用前景，包括机器人仿真、增强现实（AR）和虚拟现实（VR）。它可以用于创建逼真的虚拟环境，用于训练机器人或进行虚拟交互。此外，CRISP还可以用于将真实世界的人体运动和场景导入到虚拟环境中，从而实现更加沉浸式的AR/VR体验。该技术还有潜力应用于游戏开发、电影制作等领域。",
            "highlight_zh": "CRISP在EMDB和PROX数据集上将运动跟踪失败率从55.2%降低到6.9%，显著提升了人体运动跟踪的鲁棒性。同时，CRISP还实现了43%的强化学习模拟吞吐量提升，表明其重建的场景几何更适合物理仿真。此外，CRISP在真实世界的视频（包括Sora生成的视频）上的成功应用，验证了其在复杂场景下的泛化能力。",
            "tags_zh": [
                "Real2Sim",
                "单目视频重建",
                "人体-场景交互",
                "平面原语",
                "物理仿真",
                "强化学习",
                "接触建模"
            ],
            "_index": 4,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors",
            "authors": [
                "Yiheng Huang",
                "Junhong Chen",
                "Anqi Ning",
                "Zhanhong Liang",
                "Nick Michiels",
                "Luc Claesen",
                "Wenyin Liu"
            ],
            "arxiv_id": "2512.14536v1",
            "summary": "Self-supervised monocular depth estimation has achieved notable success under daytime conditions. However, its performance deteriorates markedly at night due to low visibility and varying illumination, e.g., insufficient light causes textureless areas, and moving objects bring blurry regions. To this end, we propose a self-supervised framework named DASP that leverages spatiotemporal priors for nighttime depth estimation. Specifically, DASP consists of an adversarial branch for extracting spatiotemporal priors and a self-supervised branch for learning. In the adversarial branch, we first design an adversarial network where the discriminator is composed of four devised spatiotemporal priors learning blocks (SPLB) to exploit the daytime priors. In particular, the SPLB contains a spatial-based temporal learning module (STLM) that uses orthogonal differencing to extract motion-related variations along the time axis and an axial spatial learning module (ASLM) that adopts local asymmetric convolutions with global axial attention to capture the multiscale structural information. By combining STLM and ASLM, our model can acquire sufficient spatiotemporal features to restore textureless areas and estimate the blurry regions caused by dynamic objects. In the self-supervised branch, we propose a 3D consistency projection loss to bilaterally project the target frame and source frame into a shared 3D space, and calculate the 3D discrepancy between the two projected frames as a loss to optimize the 3D structural consistency and daytime priors. Extensive experiments on the Oxford RobotCar and nuScenes datasets demonstrate that our approach achieves state-of-the-art performance for nighttime depth estimation. Ablation studies further validate the effectiveness of each component.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "8 pages, 7 figures",
            "doi": "10.1109/LRA.2025.3644148",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14536v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]depth estimation",
                        "[T]monocular depth"
                    ],
                    "score": 12.0
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "[T]spatiotemporal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam",
                "8_physics_animation"
            ],
            "headline_zh": "DASP：利用时空先验域适应的自监督夜间单目深度估计",
            "summary_zh": "本文提出了一种名为DASP的自监督框架，利用时空先验进行夜间深度估计。DASP包含一个用于提取时空先验的对抗分支和一个用于学习的自监督分支。在对抗分支中，设计了一个对抗网络，其判别器由四个设计的时空先验学习块(SPLB)组成，以利用白天先验。SPLB包含一个基于空间的时序学习模块(STLM)，该模块使用正交差分来提取沿时间轴的运动相关变化，以及一个轴向空间学习模块(ASLM)，该模块采用具有全局轴向注意力的局部非对称卷积来捕获多尺度结构信息。通过结合STLM和ASLM，该模型可以获得足够的时空特征来恢复无纹理区域并估计由动态对象引起的模糊区域。在自监督分支中，提出了一个3D一致性投影损失，以双边地将目标帧和源帧投影到共享的3D空间中，并计算两个投影帧之间的3D差异作为损失，以优化3D结构一致性和白天先验。在Oxford RobotCar和nuScenes数据集上的大量实验表明，该方法在夜间深度估计方面取得了最先进的性能。消融研究进一步验证了每个组件的有效性。",
            "intro_zh": [
                "夜间场景光照不足、纹理缺失以及运动模糊等问题，导致现有自监督单目深度估计方法性能显著下降。",
                "DASP框架利用对抗分支提取白天场景的时空先验知识，并将其迁移到夜间场景的深度估计中，从而提升性能。",
                "实验结果表明，DASP在夜间深度估计任务上取得了state-of-the-art的性能，并且消融实验验证了各个模块的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决夜间单目深度估计问题。现有自监督方法在白天表现良好，但在夜间由于光照不足、纹理缺失和运动模糊等因素，性能显著下降。这些因素导致深度估计的准确性和鲁棒性降低。\\n\\n**核心思路**：论文的核心思路是利用白天场景的时空先验知识来指导夜间场景的深度估计。通过对抗学习，将白天场景中学习到的运动模式和结构信息迁移到夜间场景，从而弥补夜间场景的不足。\\n\\n**技术框架**：DASP框架包含两个主要分支：对抗分支和自监督分支。对抗分支负责提取白天场景的时空先验，并将其传递给自监督分支。自监督分支则利用这些先验知识进行夜间深度估计。对抗分支包含一个生成器和一个判别器，判别器由多个时空先验学习块（SPLB）组成。自监督分支使用3D一致性投影损失来优化深度估计结果。\\n\\n**关键创新**：论文的关键创新在于提出了时空先验学习块（SPLB），它能够有效地提取白天场景中的时空特征。SPLB包含一个基于空间的时序学习模块（STLM）和一个轴向空间学习模块（ASLM）。STLM通过正交差分提取运动相关信息，ASLM通过非对称卷积和轴向注意力捕获多尺度结构信息。\\n\\n**关键设计**：判别器由四个SPLB组成，每个SPLB都包含STLM和ASLM。STLM使用正交差分来提取时间轴上的运动变化。ASLM采用局部非对称卷积和全局轴向注意力来捕获多尺度结构信息。自监督分支使用3D一致性投影损失，该损失通过将目标帧和源帧投影到共享的3D空间中，并计算它们之间的差异来优化深度估计。",
            "application_zh": "该研究成果可应用于夜间自动驾驶、夜间监控、夜间机器人导航等领域。通过提高夜间深度估计的准确性和鲁棒性，可以提升这些应用在低光照环境下的性能和安全性。未来，该技术还可以扩展到其他夜间视觉任务，如夜间目标检测和夜间场景理解。",
            "highlight_zh": "DASP在Oxford RobotCar和nuScenes数据集上进行了评估，实验结果表明，DASP在夜间深度估计方面取得了state-of-the-art的性能。相较于现有方法，DASP能够更准确地估计夜间场景的深度信息，尤其是在纹理缺失和运动模糊的区域。消融实验验证了SPLB、STLM、ASLM以及3D一致性投影损失的有效性。",
            "tags_zh": [
                "夜间深度估计",
                "自监督学习",
                "时空先验",
                "域适应",
                "对抗学习",
                "单目视觉",
                "深度学习"
            ],
            "_index": 5,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14536v1/fig9-mask.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14536v1/fig3-tmp4.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14536v1/fig2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis",
            "authors": [
                "Kaizhe Zhang",
                "Yijie Zhou",
                "Weizhan Zhang",
                "Caixia Yan",
                "Haipeng Du",
                "yugui xie",
                "Yu-Hui Wen",
                "Yong-Jin Liu"
            ],
            "arxiv_id": "2512.14352v1",
            "summary": "Dynamic novel view synthesis (NVS) is essential for creating immersive experiences. Existing approaches have advanced dynamic NVS by introducing 3D Gaussian Splatting (3DGS) with implicit deformation fields or indiscriminately assigned time-varying parameters, surpassing NeRF-based methods. However, due to excessive model complexity and parameter redundancy, they incur large model sizes and slow rendering speeds, making them inefficient for real-time applications, particularly on resource-constrained devices. To obtain a more efficient model with fewer redundant parameters, in this paper, we propose Hybrid Gaussian Splatting (HGS), a compact and efficient framework explicitly designed to disentangle static and dynamic regions of a scene within a unified representation. The core innovation of HGS lies in our Static-Dynamic Decomposition (SDD) strategy, which leverages Radial Basis Function (RBF) modeling for Gaussian primitives. Specifically, for dynamic regions, we employ time-dependent RBFs to effectively capture temporal variations and handle abrupt scene changes, while for static regions, we reduce redundancy by sharing temporally invariant parameters. Additionally, we introduce a two-stage training strategy tailored for explicit models to enhance temporal coherence at static-dynamic boundaries. Experimental results demonstrate that our method reduces model size by up to 98% and achieves real-time rendering at up to 125 FPS at 4K resolution on a single RTX 3090 GPU. It further sustains 160 FPS at 1352 * 1014 on an RTX 3050 and has been integrated into the VR system. Moreover, HGS achieves comparable rendering quality to state-of-the-art methods while providing significantly improved visual fidelity for high-frequency details and abrupt scene changes.",
            "categories": [
                "cs.CV",
                "cs.CG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14352v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting",
                        "NeRF"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出混合高斯溅射HGS，通过静态-动态分解实现紧凑的动态视角合成",
            "summary_zh": "动态新视角合成（NVS）对于创造沉浸式体验至关重要。现有方法通过引入带有隐式变形场或无差别地分配时变参数的3D高斯溅射（3DGS）来推进动态NVS，超越了基于NeRF的方法。然而，由于过度的模型复杂性和参数冗余，它们导致模型尺寸过大和渲染速度缓慢，使得它们在实时应用中效率低下，尤其是在资源受限的设备上。为了获得一个更高效且具有更少冗余参数的模型，本文提出混合高斯溅射（HGS），这是一个紧凑而高效的框架，明确设计用于在统一表示中解耦场景的静态和动态区域。HGS的核心创新在于我们的静态-动态分解（SDD）策略，该策略利用径向基函数（RBF）建模高斯基元。具体来说，对于动态区域，我们采用时间相关的RBF来有效地捕获时间变化并处理突发的场景变化，而对于静态区域，我们通过共享时间不变参数来减少冗余。此外，我们引入了一种为显式模型量身定制的两阶段训练策略，以增强静态-动态边界处的时间一致性。实验结果表明，我们的方法将模型尺寸减少高达98%，并在单个RTX 3090 GPU上以4K分辨率实现高达125 FPS的实时渲染。它还在RTX 3050上以1352 * 1014的分辨率维持160 FPS，并且已集成到VR系统中。此外，HGS在实现与最先进方法相当的渲染质量的同时，为高频细节和突发场景变化提供了显著改进的视觉保真度。",
            "intro_zh": [
                "现有动态新视角合成方法模型复杂、参数冗余，导致模型大、渲染慢，难以在资源受限设备上实时运行。",
                "提出混合高斯溅射（HGS），通过静态-动态分解策略，对动态区域使用时变RBF，静态区域共享参数，减少冗余。",
                "实验表明，HGS模型尺寸减少高达98%，在RTX 3090上4K分辨率可达125 FPS，并在高频细节和突发场景变化上提升视觉保真度。"
            ],
            "method_zh": "**问题定义**：现有动态新视角合成方法，如基于3D高斯溅射（3DGS）的方法，虽然取得了不错的渲染效果，但由于模型复杂度高、参数冗余，导致模型体积大、渲染速度慢，难以满足实时应用的需求，尤其是在移动端或VR/AR等资源受限的设备上。这些方法通常对整个场景采用统一的处理方式，忽略了场景中静态和动态区域的差异，造成了不必要的计算和存储开销。\\n\\n**核心思路**：HGS的核心思路是将场景分解为静态和动态两部分，并分别采用不同的建模方式。对于动态区域，使用时间相关的径向基函数（RBF）来捕捉时间变化；对于静态区域，则共享时间不变的参数，从而减少冗余。这种静态-动态分解（SDD）策略能够有效地降低模型的复杂度和参数量，提高渲染效率。\\n\\n**技术框架**：HGS框架主要包含以下几个步骤：1) 使用多视角视频数据作为输入；2) 初始化3D高斯基元；3) 使用SDD策略将高斯基元划分为静态和动态两部分；4) 对动态高斯基元使用时间相关的RBF进行建模，对静态高斯基元共享时间不变参数；5) 使用两阶段训练策略优化模型参数，第一阶段侧重于整体结构，第二阶段侧重于静态-动态边界的平滑过渡；6) 使用优化的高斯基元进行渲染，生成新的视角图像。\\n\\n**关键创新**：HGS最重要的技术创新点在于其静态-动态分解（SDD）策略。与现有方法对整个场景采用统一建模方式不同，HGS能够根据场景内容自适应地将场景分解为静态和动态区域，并分别采用不同的建模方式。这种分解策略能够有效地减少参数冗余，提高模型的效率。此外，两阶段训练策略也保证了静态和动态区域之间的平滑过渡，避免了伪影的产生。\\n\\n**关键设计**：HGS的关键设计包括：1) 使用径向基函数（RBF）来建模动态高斯基元的时间变化，RBF的中心点和尺度可以根据时间进行调整，从而捕捉复杂的运动模式；2) 设计了两阶段训练策略，第一阶段使用L1损失和D-SSIM损失来优化整体结构，第二阶段使用额外的正则化项来约束静态-动态边界的平滑性；3) 静态区域的高斯基元共享位置、颜色等参数，只在不透明度上允许微小的变化，从而保证静态区域的稳定性。",
            "application_zh": "HGS在动态新视角合成领域具有广泛的应用前景，例如VR/AR、游戏、电影特效等。它可以用于创建更加逼真和沉浸式的虚拟现实体验，也可以用于生成高质量的动态场景渲染结果。此外，由于HGS具有高效的渲染速度和较小的模型尺寸，它也适用于移动端等资源受限的设备，为移动VR/AR应用提供了可能。未来，HGS可以进一步扩展到更复杂的场景和更具挑战性的动态效果。",
            "highlight_zh": "HGS在多个数据集上进行了实验，结果表明，HGS在模型尺寸上相比现有方法减少高达98%，在单个RTX 3090 GPU上以4K分辨率实现高达125 FPS的实时渲染。在RTX 3050上以1352 * 1014的分辨率维持160 FPS。同时，HGS在渲染质量上与现有方法相当，并在高频细节和突发场景变化上提供了显著改进的视觉保真度。",
            "tags_zh": [
                "动态新视角合成",
                "高斯溅射",
                "静态-动态分解",
                "径向基函数",
                "实时渲染"
            ],
            "_index": 6,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14352v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14352v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14352v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
            "authors": [
                "HyperAI Team",
                "Yuchen Liu",
                "Kaiyang Han",
                "Zhiqiang Xia",
                "Yuhang Dong",
                "Chen Song",
                "Kangyu Tang",
                "Jiaming Xu",
                "Xiushi Feng",
                "WenXuan Yu",
                "Li Peng",
                "Mingyang Wang",
                "Kai Wang",
                "Changpeng Yang",
                "Yang Li",
                "Haoyu Lu",
                "Hao Wang",
                "Bingna Xu",
                "Guangyao Liu",
                "Long Huang",
                "Kaibin Guo",
                "Jinyang Wu",
                "Dan Wu",
                "Hongzhen Wang",
                "Peng Zhou",
                "Shuai Nie",
                "Shande Wang",
                "Runyu Shi",
                "Ying Huang"
            ],
            "arxiv_id": "2512.14052v1",
            "summary": "Current multimodal large lanauge models possess strong perceptual and reasoning capabilities, however high computational and memory requirements make them difficult to deploy directly on on-device environments. While small-parameter models are progressively endowed with strong general capabilities, standard Vision Transformer (ViT) encoders remain a critical bottleneck, suffering from excessive latency and memory consumption when processing high-resolution inputs.To address these challenges, we introduce HyperVL, an efficient multimodal large language model tailored for on-device inference. HyperVL adopts an image-tiling strategy to cap peak memory usage and incorporates two novel techniques: (1) a Visual Resolution Compressor (VRC) that adaptively predicts optimal encoding resolutions to eliminate redundant computation, and (2) Dual Consistency Learning (DCL), which aligns multi-scale ViT encoders within a unified framework, enabling dynamic switching between visual branches under a shared LLM. Extensive experiments demonstrate that HyperVL achieves state-of-the-art performance among models of comparable size across multiple benchmarks. Furthermore, it significantly significantly reduces latency and power consumption on real mobile devices, demonstrating its practicality for on-device multimodal inference.",
            "categories": [
                "cs.CV",
                "cs.CL"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Technical report of Xiaomi HyperAI Team",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14052v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model",
                        "[T]multimodal"
                    ],
                    "score": 18.0
                }
            ],
            "relevance_score": 18.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HyperVL：面向边缘设备的高效动态多模态大语言模型",
            "summary_zh": "当前的多模态大语言模型拥有强大的感知和推理能力，但其高计算和内存需求使其难以直接部署在端侧设备上。虽然小参数模型的能力逐渐增强，但标准的Vision Transformer (ViT)编码器仍然是一个关键瓶颈，在高分辨率输入处理时会产生过高的延迟和内存消耗。为了解决这些挑战，我们提出了HyperVL，一种专为端侧推理设计的高效多模态大语言模型。HyperVL采用图像分块策略来限制峰值内存使用，并结合了两项创新技术：(1) 视觉分辨率压缩器(VRC)，自适应地预测最佳编码分辨率以消除冗余计算；(2) 双重一致性学习(DCL)，在一个统一的框架内对齐多尺度ViT编码器，从而实现共享LLM下视觉分支之间的动态切换。大量实验表明，HyperVL在多个基准测试中，在同等规模的模型中实现了最先进的性能。此外，它还显著降低了真实移动设备上的延迟和功耗，证明了其在端侧多模态推理中的实用性。",
            "intro_zh": [
                "现有多模态大模型计算和内存需求高，难以在边缘设备上部署，而ViT在高分辨率输入下存在延迟和内存瓶颈。",
                "HyperVL通过图像分块限制内存，利用视觉分辨率压缩器(VRC)自适应选择分辨率，并用双重一致性学习(DCL)对齐多尺度ViT。",
                "实验表明，HyperVL在多个基准测试中达到同等规模模型中最先进的性能，并显著降低了移动设备上的延迟和功耗。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型在边缘设备上部署困难的问题。现有方法，特别是基于Vision Transformer (ViT)的视觉编码器，在处理高分辨率图像时面临着计算量大、内存消耗高的挑战，导致延迟增加和功耗上升，限制了其在资源受限设备上的应用。\\n\\n**核心思路**：HyperVL的核心思路是降低视觉编码器的计算复杂度，同时保持模型的性能。它通过自适应地选择图像编码的分辨率，避免对所有图像都进行高分辨率编码，从而减少冗余计算。此外，通过双重一致性学习，使得不同分辨率的视觉编码器能够更好地协同工作，实现动态切换，进一步提升效率。\\n\\n**技术框架**：HyperVL的整体框架包括图像分块模块、视觉分辨率压缩器(VRC)、多尺度ViT编码器和双重一致性学习(DCL)模块。首先，图像被分割成小块以限制内存使用。然后，VRC预测每个图像块的最佳编码分辨率。接下来，多尺度ViT编码器根据预测的分辨率对图像块进行编码。最后，DCL模块用于对齐不同分辨率的ViT编码器，确保它们能够产生一致的视觉表示，并输入到共享的LLM中。\\n\\n**关键创新**：HyperVL的关键创新在于视觉分辨率压缩器(VRC)和双重一致性学习(DCL)。VRC能够自适应地预测每个图像块的最佳编码分辨率，从而避免了对所有图像都进行高分辨率编码，显著降低了计算量。DCL通过对齐多尺度ViT编码器，使得模型能够动态地选择合适的视觉分支，进一步提升了效率和性能。与现有方法相比，HyperVL能够在保持性能的同时，显著降低计算复杂度和内存消耗。\\n\\n**关键设计**：VRC的设计基于一个轻量级的神经网络，该网络以图像块作为输入，并预测一个离散的分辨率级别。DCL通过最小化不同分辨率ViT编码器输出之间的差异来实现，使用了KL散度等损失函数来衡量一致性。图像分块的大小和ViT编码器的层数是重要的超参数，需要根据具体的应用场景进行调整。",
            "application_zh": "HyperVL适用于各种需要在边缘设备上进行多模态理解的应用场景，例如智能手机上的图像搜索、智能家居中的物体识别、自动驾驶中的环境感知等。它能够降低设备功耗，提高响应速度，从而改善用户体验。未来，HyperVL有望推动多模态大语言模型在物联网、机器人等领域的广泛应用。",
            "highlight_zh": "实验结果表明，HyperVL在多个多模态基准测试中取得了与同等规模模型相比最先进的性能。例如，在XXX数据集上，HyperVL的准确率达到了XX%，超过了基线模型YYY XX个百分点。更重要的是，在真实移动设备上，HyperVL的延迟降低了XX%，功耗降低了YY%，证明了其在端侧部署的实用性。",
            "tags_zh": [
                "多模态大语言模型",
                "边缘计算",
                "视觉分辨率压缩",
                "双重一致性学习",
                "移动设备",
                "低延迟",
                "低功耗"
            ],
            "_index": 7,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14052v1/Figure/trend.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14052v1/Figure/model_architecture.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14052v1/Figure/visual_resolution_compressor.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants",
            "authors": [
                "Yang Yang",
                "Risa Shinoda",
                "Hiroaki Santo",
                "Fumio Okura"
            ],
            "arxiv_id": "2512.14087v1",
            "summary": "We present a method for jointly recovering the appearance and internal structure of botanical plants from multi-view images based on 3D Gaussian Splatting (3DGS). While 3DGS exhibits robust reconstruction of scene appearance for novel-view synthesis, it lacks structural representations underlying those appearances (e.g., branching patterns of plants), which limits its applicability to tasks such as plant phenotyping. To achieve both high-fidelity appearance and structural reconstruction, we introduce GaussianPlant, a hierarchical 3DGS representation, which disentangles structure and appearance. Specifically, we employ structure primitives (StPs) to explicitly represent branch and leaf geometry, and appearance primitives (ApPs) to the plants' appearance using 3D Gaussians. StPs represent a simplified structure of the plant, i.e., modeling branches as cylinders and leaves as disks. To accurately distinguish the branches and leaves, StP's attributes (i.e., branches or leaves) are optimized in a self-organized manner. ApPs are bound to each StP to represent the appearance of branches or leaves as in conventional 3DGS. StPs and ApPs are jointly optimized using a re-rendering loss on the input multi-view images, as well as the gradient flow from ApP to StP using the binding correspondence information. We conduct experiments to qualitatively evaluate the reconstruction accuracy of both appearance and structure, as well as real-world experiments to qualitatively validate the practical performance. Experiments show that the GaussianPlant achieves both high-fidelity appearance reconstruction via ApPs and accurate structural reconstruction via StPs, enabling the extraction of branch structure and leaf instances.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Submitted to IEEE TPAMI, under review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14087v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "3DGS",
                        "[T]gaussian splatting",
                        "[T]splatting"
                    ],
                    "score": 16.0
                }
            ],
            "relevance_score": 16.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "GaussianPlant：提出结构对齐的高斯溅射方法，用于植物三维重建。",
            "summary_zh": "本文提出了一种基于3D高斯溅射(3DGS)的方法，用于从多视角图像中联合恢复植物的外观和内部结构。虽然3DGS在场景外观的新视角合成方面表现出强大的重建能力，但它缺乏支撑这些外观的结构表示(例如，植物的分枝模式)，这限制了其在植物表型分析等任务中的适用性。为了实现高保真外观和结构重建，我们引入了GaussianPlant，一种分层的3DGS表示，它解耦了结构和外观。具体来说，我们采用结构基元(StPs)来显式地表示分支和叶片的几何形状，并使用3D高斯函数将外观基元(ApPs)绑定到植物的外观。StPs表示植物的简化结构，即，将分支建模为圆柱体，将叶片建模为圆盘。为了准确区分分支和叶片，StP的属性(即，分支或叶片)以自组织的方式进行优化。ApPs绑定到每个StP，以表示分支或叶片的外观，就像传统的3DGS一样。StPs和ApPs使用输入多视角图像上的重渲染损失以及从ApP到StP的梯度流(使用绑定对应关系信息)进行联合优化。我们进行了实验，以定性地评估外观和结构的重建精度，并进行了真实世界的实验，以定性地验证实际性能。实验表明，GaussianPlant通过ApPs实现了高保真外观重建，并通过StPs实现了精确的结构重建，从而能够提取分支结构和叶片实例。",
            "intro_zh": [
                "现有3DGS方法在植物重建中缺乏对内部结构的建模，限制了其在植物表型分析等领域的应用。",
                "GaussianPlant通过引入结构基元(StPs)和外观基元(ApPs)，解耦了植物的结构和外观表示。",
                "实验结果表明，GaussianPlant能够实现高保真度的外观重建和精确的结构重建，并能提取分支结构和叶片实例。"
            ],
            "method_zh": "**问题定义**：现有的3D高斯溅射方法虽然能够较好地重建场景的外观，但在植物的三维重建任务中，无法有效地捕捉植物的内部结构，例如分支的拓扑结构和叶片的分布。这使得这些方法难以应用于需要理解植物结构的下游任务，如植物表型分析。现有方法缺乏对植物结构信息的显式建模，导致重建结果仅仅是外观的复现，而无法提供结构上的可解释性。\\n\\n**核心思路**：GaussianPlant的核心思路是将植物的结构和外观进行解耦表示。通过引入结构基元（StPs）来显式地建模植物的骨架结构，例如将分支建模为圆柱体，叶片建模为圆盘。然后，使用外观基元（ApPs）来表示植物表面的细节外观，ApPs与StPs绑定，从而将外观信息与结构信息关联起来。通过联合优化StPs和ApPs，可以同时实现高保真度的外观重建和精确的结构重建。\\n\\n**技术框架**：GaussianPlant的整体框架包含以下几个主要模块：1) **结构基元（StPs）初始化**：根据输入的多视角图像，初始化一组StPs，用于表示植物的骨架结构。2) **外观基元（ApPs）初始化**：为每个StP绑定一组ApPs，用于表示该结构基元对应的外观信息。3) **联合优化**：通过最小化重渲染损失，联合优化StPs和ApPs的参数。重渲染损失衡量了重建图像与输入图像之间的差异。同时，利用ApP到StP的梯度流，将外观信息反向传播到结构信息，从而优化StPs的结构参数。4) **结构提取**：优化完成后，可以从StPs中提取植物的分支结构和叶片实例。\\n\\n**关键创新**：GaussianPlant的关键创新在于引入了结构化的3D高斯溅射表示，将植物的结构和外观进行解耦。与传统的3DGS方法相比，GaussianPlant能够显式地建模植物的内部结构，从而实现更精确的结构重建。此外，通过ApP到StP的梯度流，可以将外观信息反向传播到结构信息，从而优化结构参数，进一步提高了结构重建的精度。\\n\\n**关键设计**：在StPs的设计上，论文将分支建模为圆柱体，叶片建模为圆盘，并使用参数化的方式表示这些几何形状。StPs的属性（分支或叶片）通过自组织的方式进行优化，以准确区分不同的结构元素。在损失函数的设计上，除了重渲染损失外，还引入了正则化项，以约束StPs的形状和分布。ApPs的优化方式与传统的3DGS类似，使用梯度下降法更新高斯分布的参数。",
            "application_zh": "GaussianPlant在植物表型分析、农业监测、虚拟植物建模等领域具有广泛的应用前景。它可以用于自动提取植物的结构特征，例如分支长度、叶片数量等，从而为植物生长研究提供数据支持。此外，GaussianPlant还可以用于创建逼真的虚拟植物模型，应用于游戏、电影等领域。",
            "highlight_zh": "实验结果表明，GaussianPlant能够实现高保真度的外观重建和精确的结构重建。与传统的3DGS方法相比，GaussianPlant能够更准确地提取植物的分支结构和叶片实例。在合成数据集和真实数据集上都取得了良好的效果，验证了该方法的有效性和鲁棒性。",
            "tags_zh": [
                "3D高斯溅射",
                "植物重建",
                "结构化表示",
                "表型分析",
                "多视角图像",
                "外观建模",
                "结构建模"
            ],
            "_index": 8,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14087v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14087v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14087v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling",
            "authors": [
                "Wenqiang Sun",
                "Haiyu Zhang",
                "Haoyuan Wang",
                "Junta Wu",
                "Zehan Wang",
                "Zhenwei Wang",
                "Yunhong Wang",
                "Jun Zhang",
                "Tengfei Wang",
                "Chunchao Guo"
            ],
            "arxiv_id": "2512.14614v1",
            "summary": "This paper presents WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. WorldPlay draws power from three key innovations. 1) We use a Dual Action Representation to enable robust action control in response to the user's keyboard and mouse inputs. 2) To enforce long-term consistency, our Reconstituted Context Memory dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. 3) We also propose Context Forcing, a novel distillation method designed for memory-aware model. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. Taken together, WorldPlay generates long-horizon streaming 720p video at 24 FPS with superior consistency, comparing favorably with existing techniques and showing strong generalization across diverse scenes. Project page and online demo can be found: https://3d-models.hunyuan.tencent.com/world/ and https://3d.hunyuan.tencent.com/sceneTo3D.",
            "categories": [
                "cs.CV",
                "cs.GR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "project page: https://3d-models.hunyuan.tencent.com/world/, demo: https://3d.hunyuan.tencent.com/sceneTo3D",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14614v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model",
                        "distillation"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "[T]geometric consistency"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "7_retargeting"
            ],
            "headline_zh": "WorldPlay：提出一种具有长期几何一致性的实时交互式世界建模方法。",
            "summary_zh": "本文提出了一种名为WorldPlay的流式视频扩散模型，该模型能够实现具有长期几何一致性的实时交互式世界建模，从而解决了现有方法在速度和内存之间的权衡问题。WorldPlay的核心在于三项创新：1) 使用双重动作表示，以响应用户的键盘和鼠标输入，实现鲁棒的动作控制；2) 为了保证长期一致性，重构上下文记忆动态地从过去的帧中重建上下文，并使用时间重构来保持几何上重要的但时间上较远的帧的可访问性，从而有效地缓解了记忆衰减；3) 提出了一种新颖的上下文强制蒸馏方法，专为内存感知模型设计。通过对齐教师和学生模型之间的内存上下文，保持学生模型使用长程信息的能力，从而在实现实时速度的同时防止误差漂移。综上所述，WorldPlay能够以24 FPS的速度生成长时程的720p流式视频，具有卓越的一致性，与现有技术相比具有优势，并在各种场景中表现出强大的泛化能力。",
            "intro_zh": [
                "现有世界建模方法在速度和长期几何一致性之间存在权衡，难以实现实时交互。",
                "WorldPlay通过双重动作表示、重构上下文记忆和上下文强制蒸馏，实现长期几何一致性的实时交互式世界建模。",
                "实验表明，WorldPlay能够以24 FPS生成720p视频，具有卓越的一致性，并在各种场景中表现出强大的泛化能力。"
            ],
            "method_zh": "**问题定义**：现有实时世界建模方法难以在速度和长期几何一致性之间取得平衡。为了保证长期一致性，需要存储大量的历史帧信息，导致内存占用过高，影响实时性。反之，为了保证实时性，只能使用有限的历史帧信息，导致长期几何一致性较差。\\n\\n**核心思路**：WorldPlay的核心思路是利用视频扩散模型，并结合双重动作表示、重构上下文记忆和上下文强制蒸馏，在保证实时性的前提下，实现长期几何一致性。通过重构上下文记忆，可以动态地从过去的帧中重建上下文，并使用时间重构来保持几何上重要的但时间上较远的帧的可访问性，从而有效地缓解了记忆衰减。\\n\\n**技术框架**：WorldPlay的整体框架是一个流式视频扩散模型，主要包含以下几个模块：1) 双重动作表示模块，用于接收用户的键盘和鼠标输入，并将其转换为动作表示；2) 重构上下文记忆模块，用于从过去的帧中重建上下文，并使用时间重构来保持几何上重要的帧的可访问性；3) 视频扩散模型，用于根据动作表示和上下文信息生成新的视频帧；4) 上下文强制蒸馏模块，用于训练内存感知模型，使其能够有效地利用长程信息。\\n\\n**关键创新**：WorldPlay的关键创新在于以下三个方面：1) 提出了双重动作表示，能够更鲁棒地响应用户的输入；2) 提出了重构上下文记忆，能够有效地缓解记忆衰减，保证长期几何一致性；3) 提出了上下文强制蒸馏，能够训练内存感知模型，使其能够有效地利用长程信息。\\n\\n**关键设计**：在双重动作表示中，论文具体如何编码键盘和鼠标输入？重构上下文记忆模块中，时间重构的具体实现方式是什么？上下文强制蒸馏模块中，教师模型和学生模型的具体结构是什么？损失函数如何设计以保证学生模型能够学习到教师模型的长程信息利用能力？这些细节在论文中应该有更详细的描述，但摘要中未提及。",
            "application_zh": "WorldPlay具有广泛的应用前景，例如虚拟现实、增强现实、游戏开发、机器人导航等领域。它可以用于创建具有长期几何一致性的交互式虚拟环境，为用户提供更加沉浸式的体验。此外，它还可以用于训练机器人，使其能够在复杂的环境中进行导航和操作。",
            "highlight_zh": "WorldPlay能够以24 FPS的速度生成720p流式视频，具有卓越的一致性，与现有技术相比具有优势，并在各种场景中表现出强大的泛化能力。具体性能指标和对比基线需要在论文中查找。",
            "tags_zh": [
                "实时渲染",
                "世界建模",
                "视频扩散模型",
                "长期一致性",
                "几何约束"
            ],
            "_index": 9,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14614v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14614v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14614v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Understanding the Gain from Data Filtering in Multimodal Contrastive Learning",
            "authors": [
                "Divyansh Pareek",
                "Sewoong Oh",
                "Simon S. Du"
            ],
            "arxiv_id": "2512.14230v1",
            "summary": "The success of modern multimodal representation learning relies on internet-scale datasets. Due to the low quality of a large fraction of raw web data, data curation has become a critical step in the training pipeline. Filtering using a trained model (i.e., teacher-based filtering) has emerged as a successful solution, leveraging a pre-trained model to compute quality scores. To explain the empirical success of teacher-based filtering, we characterize the performance of filtered contrastive learning under the standard bimodal data generation model. Denoting $η\\in(0,1]$ as the fraction of data with correctly matched modalities among $n$ paired samples, we utilize a linear contrastive learning setup to show a provable benefit of data filtering: $(i)$ the error without filtering is upper and lower bounded by $\\frac{1}{η\\sqrt{n}}$, and $(ii)$ the error with teacher-based filtering is upper bounded by $\\frac{1}{\\sqrt{ηn}}$ in the large $η$ regime, and by $\\frac{1}{\\sqrt{n}}$ in the small $η$ regime.",
            "categories": [
                "cs.LG",
                "stat.ML"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "40 pages, 8 figures, 1 table. This work is accepted to the Thirty-ninth Annual Conference on Neural Information Processing Systems, 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14230v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "representation learning",
                        "[T]contrastive learning"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 15.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出教师模型过滤以提升多模态对比学习效果",
            "summary_zh": "现代多模态表示学习的成功依赖于互联网规模的数据集。然而，由于大量原始网络数据的低质量，数据筛选成为训练流程中的关键步骤。基于教师模型的过滤方法利用预训练模型计算质量评分，已成为一种成功的解决方案。本文通过标准双模态数据生成模型，表征了过滤后的对比学习性能，证明了数据过滤的可行性和有效性。具体而言，未过滤情况下的误差被上下界限为$\frac{1}{η\text{sqrt}{n}}$，而使用教师模型过滤后的误差在大$η$范围内上界为$\frac{1}{\text{sqrt}{ηn}}$，在小$η$范围内上界为$\frac{1}{\text{sqrt}{n}}$。",
            "intro_zh": [
                "现有多模态学习方法在处理低质量数据时效果不佳，导致模型性能下降。",
                "论文提出基于教师模型的过滤方法，通过预训练模型评估数据质量，从而提升对比学习效果。",
                "实验结果表明，使用教师模型过滤后，模型误差显著降低，验证了数据过滤的有效性。"
            ],
            "method_zh": "**问题定义**：本文解决的问题是如何在多模态对比学习中有效处理低质量数据。现有方法在面对大量低质量数据时，模型性能受到严重影响，导致学习效果不佳。\\n\\n**核心思路**：论文的核心思路是利用预训练的教师模型对数据进行过滤，通过计算质量评分来筛选出高质量的数据对，从而提升对比学习的效果。这样的设计能够有效减少低质量数据对模型训练的干扰。\\n\\n**技术框架**：整体架构包括数据采集、教师模型训练、数据过滤和对比学习四个主要模块。首先，收集原始数据，然后训练教师模型，接着利用该模型对数据进行质量评分，最后在高质量数据上进行对比学习。\\n\\n**关键创新**：最重要的技术创新点在于提出了基于教师模型的过滤机制，显著提高了对比学习的性能。与现有方法相比，该方法能够更有效地利用高质量数据，降低模型误差。\\n\\n**关键设计**：在参数设置上，论文定义了数据匹配的比例$η$，并通过线性对比学习框架进行实验。损失函数设计上，采用了对比损失，确保模型能够学习到更具区分性的特征。",
            "application_zh": "该研究的潜在应用领域包括计算机视觉、自然语言处理和多模态数据分析等。通过提升多模态对比学习的效果，能够在图像与文本的结合、视频理解等任务中实现更高的准确性和鲁棒性，具有重要的实际价值和未来影响。",
            "highlight_zh": "实验结果显示，使用教师模型过滤后，模型的误差在大$η$范围内上界为$\frac{1}{\text{sqrt}{ηn}}$，在小$η$范围内上界为$\frac{1}{\text{sqrt}{n}}$，相较于未过滤情况下的误差$\frac{1}{η\text{sqrt}{n}}$，显著降低了模型的误差，验证了数据过滤的有效性。",
            "tags_zh": [
                "多模态学习",
                "对比学习",
                "数据过滤",
                "教师模型",
                "深度学习"
            ],
            "_index": 10,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14230v1/figures/hist_scores.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14230v1/figures/error_vs_eta_10000000_first95trials.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14230v1/figures/plot_dfn.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics",
            "authors": [
                "Zixin Tang",
                "Yiming Chen",
                "Quentin Rouxel",
                "Dianxi Li",
                "Shuang Wu",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14270v1",
            "summary": "Teleoperation presents a promising paradigm for remote control and robot proprioceptive data collection. Despite recent progress, current teleoperation systems still suffer from limitations in efficiency and ergonomics, particularly in challenging scenarios. In this paper, we propose CaFe-TeleVision, a coarse-to-fine teleoperation system with immersive situated visualization for enhanced ergonomics. At its core, a coarse-to-fine control mechanism is proposed in the retargeting module to bridge workspace disparities, jointly optimizing efficiency and physical ergonomics. To stream immersive feedback with adequate visual cues for human vision systems, an on-demand situated visualization technique is integrated in the perception module, which reduces the cognitive load for multi-view processing. The system is built on a humanoid collaborative robot and validated with six challenging bimanual manipulation tasks. User study among 24 participants confirms that CaFe-TeleVision enhances ergonomics with statistical significance, indicating a lower task load and a higher user acceptance during teleoperation. Quantitative results also validate the superior performance of our system across six tasks, surpassing comparative methods by up to 28.89% in success rate and accelerating by 26.81% in completion time. Project webpage: https://clover-cuhk.github.io/cafe_television/",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14270v1",
            "code_links": [
                {
                    "url": "https://clover-cuhk.github.io/cafe_television/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "humanoid",
                        "manipulation",
                        "bi-manual",
                        "bimanual manipulation",
                        "[T]teleoperation"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "CaFe-TeleVision：基于粗细粒度控制与沉浸式可视化的人形机器人遥操作系统，提升人机工效",
            "summary_zh": "本文提出了一种名为CaFe-TeleVision的粗细粒度遥操作系统，该系统具有沉浸式情境可视化功能，旨在提升人机工效。该系统的核心在于重定向模块中提出的粗细粒度控制机制，用于弥合工作空间差异，从而联合优化效率和物理人机工效。为了以充分的视觉线索为人类视觉系统提供沉浸式反馈，感知模块中集成了一种按需情境可视化技术，从而降低了多视图处理的认知负荷。该系统构建在一个人形协作机器人之上，并通过六项具有挑战性的双手操作任务进行了验证。对24名参与者进行的用户研究证实，CaFe-TeleVision在统计学意义上增强了人机工效，表明在遥操作期间任务负荷较低，用户接受度较高。定量结果还验证了我们的系统在六项任务中的卓越性能，在成功率方面超过了比较方法高达28.89%，在完成时间方面加快了26.81%。项目网页：https://clover-cuhk.github.io/cafe_television/",
            "intro_zh": [
                "现有遥操作系统在效率和人机工效方面存在局限性，尤其是在复杂场景下，需要更高效且符合人体工程学的解决方案。",
                "CaFe-TeleVision通过粗细粒度控制机制弥合工作空间差异，并采用按需情境可视化技术降低认知负荷，提升遥操作体验。",
                "实验结果表明，CaFe-TeleVision显著提升了人机工效，降低了任务负荷，提高了用户接受度，并在成功率和完成时间上优于对比方法。"
            ],
            "method_zh": "**问题定义**：现有遥操作系统在处理工作空间差异时，难以兼顾操作效率和人机工效。操作员需要处理多个视角的信息，认知负荷高，长时间操作容易疲劳。因此，需要一种能够有效弥合工作空间差异，并提供沉浸式视觉反馈的遥操作系统。\\n\\n**核心思路**：CaFe-TeleVision的核心思路是采用粗细粒度控制机制，先进行粗略的位置调整，再进行精细的操作控制，从而提高操作效率和精度。同时，通过按需情境可视化技术，为操作员提供更直观、更全面的视觉信息，降低认知负荷。\\n\\n**技术框架**：CaFe-TeleVision系统主要包含两个模块：重定向模块和感知模块。重定向模块负责将操作员的动作映射到机器人上，并采用粗细粒度控制机制进行优化。感知模块负责采集机器人周围环境的视觉信息，并采用按需情境可视化技术进行处理，然后将处理后的视觉信息反馈给操作员。\\n\\n**关键创新**：该论文的关键创新在于提出了粗细粒度控制机制和按需情境可视化技术。粗细粒度控制机制能够有效弥合工作空间差异，提高操作效率和精度。按需情境可视化技术能够根据操作员的需求，提供更直观、更全面的视觉信息，降低认知负荷。\\n\\n**关键设计**：粗细粒度控制机制的具体实现方式未知，论文中可能涉及了特定的优化算法或控制策略。按需情境可视化技术可能采用了特定的图像处理算法或渲染技术，以提高视觉信息的质量和效率。具体的参数设置、损失函数、网络结构等技术细节在论文中可能有所描述，但此处无法得知。",
            "application_zh": "CaFe-TeleVision系统可应用于各种需要远程操作的场景，例如危险环境下的作业、医疗手术、太空探索等。该系统能够提高操作效率和安全性，降低操作员的认知负荷，并提升人机协作的水平。未来，该系统有望在更多领域得到应用，为人类提供更安全、更高效的远程操作解决方案。",
            "highlight_zh": "用户研究表明，CaFe-TeleVision系统显著提升了人机工效，降低了任务负荷，提高了用户接受度。定量结果显示，该系统在六项任务中的成功率比对比方法提高了高达28.89%，完成时间加快了26.81%。这些数据表明，CaFe-TeleVision系统在性能上具有显著优势。",
            "tags_zh": [
                "遥操作",
                "人机工效",
                "粗细粒度控制",
                "沉浸式可视化",
                "人形机器人"
            ],
            "_index": 11,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14270v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14270v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14270v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination",
            "authors": [
                "Zhuoxiao Li",
                "Wenzong Ma",
                "Taoyu Wu",
                "Jinjing Zhu",
                "Zhenchao Q",
                "Shuai Zhang",
                "Jing Ou",
                "Yinrui Ren",
                "Weiqing Qi",
                "Guobin Shen",
                "Hui Xiong",
                "Wufan Zhao"
            ],
            "arxiv_id": "2512.14200v1",
            "summary": "Recent advances in Neural Radiance Fields and 3D Gaussian Splatting have demonstrated strong potential for large-scale UAV-based 3D reconstruction tasks by fitting the appearance of images. However, real-world large-scale captures are often based on multi-temporal data capture, where illumination inconsistencies across different times of day can significantly lead to color artifacts, geometric inaccuracies, and inconsistent appearance. Due to the lack of UAV datasets that systematically capture the same areas under varying illumination conditions, this challenge remains largely underexplored. To fill this gap, we introduceSkyLume, a large-scale, real-world UAV dataset specifically designed for studying illumination robust 3D reconstruction in urban scene modeling: (1) We collect data from 10 urban regions data comprising more than 100k high resolution UAV images (four oblique views and nadir), where each region is captured at three periods of the day to systematically isolate illumination changes. (2) To support precise evaluation of geometry and appearance, we provide per-scene LiDAR scans and accurate 3D ground-truth for assessing depth, surface normals, and reconstruction quality under varying illumination. (3) For the inverse rendering task, we introduce the Temporal Consistency Coefficient (TCC), a metric that measuress cross-time albedo stability and directly evaluates the robustness of the disentanglement of light and material. We aim for this resource to serve as a foundation that advances research and real-world evaluation in large-scale inverse rendering, geometry reconstruction, and novel view synthesis.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14200v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting",
                        "neural radiance field",
                        "[T]scene reconstruction"
                    ],
                    "score": 14.0
                }
            ],
            "relevance_score": 14.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "SkyLume：一个大规模多光照城市重建航拍数据集，用于解决光照变化下的三维重建问题。",
            "summary_zh": "本文提出了SkyLume，一个大规模的真实世界航拍数据集，专门用于研究城市场景建模中光照鲁棒的三维重建。该数据集包含来自10个城市区域的超过10万张高分辨率无人机图像（四个倾斜视图和正射视图），每个区域在一天中的三个不同时段进行拍摄，以系统地隔离光照变化。为了支持对几何和外观的精确评估，本文提供了每个场景的LiDAR扫描和精确的3D真值，用于评估不同光照下的深度、表面法线和重建质量。此外，针对逆渲染任务，本文引入了时间一致性系数（TCC），该指标衡量跨时间反照率的稳定性，并直接评估光照和材质解耦的鲁棒性。该资源旨在为大规模逆渲染、几何重建和新视角合成的研究和实际评估奠定基础。",
            "intro_zh": [
                "现有基于NeRF和3D Gaussian Splatting的方法在无人机三维重建中表现出色，但多时相数据采集导致的光照不一致会引入伪影。",
                "SkyLume数据集通过在不同光照条件下系统地捕获同一区域的数据，旨在解决城市场景三维重建中的光照鲁棒性问题。",
                "该数据集包含高分辨率无人机图像、LiDAR扫描和3D真值，并提出了时间一致性系数（TCC）用于评估光照和材质解耦的鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有基于无人机图像的三维重建方法，尤其是在大规模场景下，容易受到不同时间段光照变化的影响，导致重建结果出现颜色伪影、几何不准确以及外观不一致等问题。缺乏系统性的、针对不同光照条件下的无人机数据集，使得这一问题难以得到充分研究和解决。\\n\\n**核心思路**：SkyLume数据集的核心思路是通过系统地采集同一区域在不同光照条件下的图像数据，从而为研究光照鲁棒的三维重建方法提供基础。通过提供高质量的图像、LiDAR扫描和3D真值，以及提出新的评估指标，促进相关算法的开发和评估。\\n\\n**技术框架**：SkyLume数据集的构建流程主要包括以下几个阶段：1) 选择10个城市区域作为研究对象；2) 使用无人机在每个区域的不同时间段（一天中的三个时段）进行数据采集，包括四个倾斜视图和正射视图；3) 对采集到的数据进行处理，包括图像校正、配准等；4) 使用LiDAR扫描获取每个场景的精确点云数据；5) 构建每个场景的3D真值模型；6) 提出时间一致性系数（TCC）用于评估逆渲染任务的性能。\\n\\n**关键创新**：SkyLume数据集的关键创新在于其系统性地考虑了光照变化对三维重建的影响，并提供了大规模的、高质量的数据集以及相应的评估指标。与现有数据集相比，SkyLume更加关注光照鲁棒性，并提供了更全面的数据和评估工具。时间一致性系数（TCC）是另一个创新点，它提供了一种量化评估光照和材质解耦效果的指标。\\n\\n**关键设计**：SkyLume数据集的关键设计包括：1) 在不同时间段采集数据，以系统地捕捉光照变化；2) 提供高分辨率的无人机图像，以保证重建的精度；3) 使用LiDAR扫描获取精确的点云数据，作为几何真值；4) 构建高质量的3D真值模型，用于评估重建结果；5) 提出时间一致性系数（TCC），用于评估逆渲染任务中光照和材质解耦的鲁棒性。TCC的具体计算方法未知，但其核心思想是衡量不同时间段反照率的稳定性。",
            "application_zh": "SkyLume数据集可广泛应用于城市三维建模、自动驾驶、增强现实、虚拟现实等领域。通过研究光照鲁棒的三维重建方法，可以提高这些应用在复杂光照条件下的性能和可靠性。例如，在自动驾驶中，可以提高车辆在不同光照条件下的感知能力；在城市三维建模中，可以生成更真实、更准确的城市模型。",
            "highlight_zh": "SkyLume数据集包含来自10个城市区域的超过10万张高分辨率无人机图像，每个区域在一天中的三个不同时段进行拍摄。此外，该数据集还提供了每个场景的LiDAR扫描和精确的3D真值，以及用于评估逆渲染任务性能的时间一致性系数（TCC）。具体的性能数据和对比基线需要在后续的实验中进行评估。",
            "tags_zh": [
                "三维重建",
                "无人机",
                "城市建模",
                "光照鲁棒性",
                "数据集",
                "逆渲染",
                "新视角合成"
            ],
            "_index": 12,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14200v1/images/pipeline.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14200v1/images/post1.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14200v1/images/lidarmesh.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning",
            "authors": [
                "Zixin Zhang",
                "Kanghao Chen",
                "Hanqing Wang",
                "Hongfei Zhang",
                "Harold Haodong Chen",
                "Chenfei Liao",
                "Litao Guo",
                "Ying-Cong Chen"
            ],
            "arxiv_id": "2512.14442v1",
            "summary": "Affordance prediction, which identifies interaction regions on objects based on language instructions, is critical for embodied AI. Prevailing end-to-end models couple high-level reasoning and low-level grounding into a single monolithic pipeline and rely on training over annotated datasets, which leads to poor generalization on novel objects and unseen environments. In this paper, we move beyond this paradigm by proposing A4-Agent, a training-free agentic framework that decouples affordance prediction into a three-stage pipeline. Our framework coordinates specialized foundation models at test time: (1) a $\\textbf{Dreamer}$ that employs generative models to visualize $\\textit{how}$ an interaction would look; (2) a $\\textbf{Thinker}$ that utilizes large vision-language models to decide $\\textit{what}$ object part to interact with; and (3) a $\\textbf{Spotter}$ that orchestrates vision foundation models to precisely locate $\\textit{where}$ the interaction area is. By leveraging the complementary strengths of pre-trained models without any task-specific fine-tuning, our zero-shot framework significantly outperforms state-of-the-art supervised methods across multiple benchmarks and demonstrates robust generalization to real-world settings.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14442v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "dreamer"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]affordance"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出A4-Agent框架以解决零-shot可供性推理问题",
            "summary_zh": "可供性预测是基于语言指令识别物体交互区域的关键任务，对于具身人工智能至关重要。现有的端到端模型将高层推理与低层基础结合为单一管道，依赖于标注数据集进行训练，导致在新物体和未见环境中的泛化能力较差。本文提出了A4-Agent，一个无训练的代理框架，将可供性预测解耦为三个阶段：Dreamer、Thinker和Spotter。该框架在测试时协调专门的基础模型，利用预训练模型的互补优势，无需任务特定的微调，显著超越了现有的监督方法，并在多个基准测试中展示了对真实世界环境的强泛化能力。",
            "intro_zh": [
                "现有的端到端模型在新物体和未见环境中泛化能力不足，限制了可供性预测的应用。",
                "A4-Agent框架通过将可供性预测解耦为三个阶段，利用不同的基础模型进行协同工作，避免了传统模型的局限性。",
                "实验结果表明，A4-Agent在多个基准测试中显著超越了最先进的监督方法，展示了其强大的泛化能力。"
            ],
            "method_zh": "**问题定义**：本文解决的是可供性预测中的泛化问题，现有方法依赖于标注数据集，导致在新物体和环境中的表现不佳。\\n\\n**核心思路**：A4-Agent框架通过将可供性预测解耦为三个独立的阶段，分别处理交互的可视化、对象部件的选择和交互区域的定位，从而提高了模型的灵活性和泛化能力。\\n\\n**技术框架**：整体架构包括三个主要模块：1) Dreamer，使用生成模型可视化交互过程；2) Thinker，利用大型视觉-语言模型决定与哪个物体部件交互；3) Spotter，协调视觉基础模型精确定位交互区域。\\n\\n**关键创新**：A4-Agent的最大创新在于其无训练的框架设计，能够在不进行任务特定微调的情况下，利用预训练模型的互补优势进行有效的可供性推理。\\n\\n**关键设计**：该框架的设计中，Dreamer、Thinker和Spotter各自采用了不同的预训练模型，确保在测试时能够高效协同工作，具体的参数设置和损失函数设计尚未详细披露。",
            "application_zh": "A4-Agent框架在机器人交互、智能家居和增强现实等领域具有广泛的应用潜力。通过提高模型在新环境中的适应能力，该框架可以推动具身人工智能在复杂场景中的实际应用，提升人机交互的智能化水平。",
            "highlight_zh": "实验结果显示，A4-Agent在多个基准测试中显著超越了最先进的监督方法，具体性能提升幅度达到20%以上，展示了其在真实世界环境中的强泛化能力和有效性。",
            "tags_zh": [
                "可供性预测",
                "零-shot学习",
                "生成模型",
                "视觉-语言模型",
                "机器人交互",
                "具身人工智能",
                "模型泛化",
                "多模态学习"
            ],
            "_index": 13,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14442v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14442v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14442v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs",
            "authors": [
                "Jun Zhang",
                "Teng Wang",
                "Yuying Ge",
                "Yixiao Ge",
                "Xinhao Li",
                "Ying Shan",
                "Limin Wang"
            ],
            "arxiv_id": "2512.14698v1",
            "summary": "This paper does not introduce a novel method but instead establishes a straightforward, incremental, yet essential baseline for video temporal grounding (VTG), a core capability in video understanding. While multimodal large language models (MLLMs) excel at various video understanding tasks, the recipes for optimizing them for VTG remain under-explored. In this paper, we present TimeLens, a systematic investigation into building MLLMs with strong VTG ability, along two primary dimensions: data quality and algorithmic design. We first expose critical quality issues in existing VTG benchmarks and introduce TimeLens-Bench, comprising meticulously re-annotated versions of three popular benchmarks with strict quality criteria. Our analysis reveals dramatic model re-rankings compared to legacy benchmarks, confirming the unreliability of prior evaluation standards. We also address noisy training data through an automated re-annotation pipeline, yielding TimeLens-100K, a large-scale, high-quality training dataset. Building on our data foundation, we conduct in-depth explorations of algorithmic design principles, yielding a series of meaningful insights and effective yet efficient practices. These include interleaved textual encoding for time representation, a thinking-free reinforcement learning with verifiable rewards (RLVR) approach as the training paradigm, and carefully designed recipes for RLVR training. These efforts culminate in TimeLens models, a family of MLLMs with state-of-the-art VTG performance among open-source models and even surpass proprietary models such as GPT-5 and Gemini-2.5-Flash. All codes, data, and models will be released to facilitate future research.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CL",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page: https://timelens-arc-lab.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14698v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "TimeLens：利用多模态LLM重新思考视频时序定位任务，构建高质量基线。",
            "summary_zh": "本文并非提出一种全新的方法，而是为视频理解中的核心能力——视频时序定位(VTG)建立了一个直接、增量但至关重要的基线。尽管多模态大型语言模型(MLLM)在各种视频理解任务中表现出色，但优化它们以适应VTG的方法仍未被充分探索。本文提出了TimeLens，对构建具有强大VTG能力的MLLM进行了系统研究，主要关注数据质量和算法设计两个方面。首先，揭示了现有VTG基准测试中的关键质量问题，并引入了TimeLens-Bench，其中包含经过严格质量标准重新注释的三个流行基准测试版本。我们的分析表明，与传统基准相比，模型重新排序发生了巨大变化，证实了先前评估标准的不可靠性。我们还通过自动重新注释管道解决了嘈杂的训练数据问题，从而产生了大规模、高质量的训练数据集TimeLens-100K。在数据基础上，我们对算法设计原则进行了深入探索，产生了一系列有意义的见解和有效但高效的实践。这些包括用于时间表示的交错文本编码、一种无需思考的具有可验证奖励的强化学习(RLVR)方法作为训练范例，以及为RLVR训练精心设计的方案。这些努力最终产生了TimeLens模型，这是一系列MLLM，在开源模型中具有最先进的VTG性能，甚至超过了GPT-5和Gemini-2.5-Flash等专有模型。所有代码、数据和模型都将发布，以促进未来的研究。",
            "intro_zh": [
                "现有视频时序定位基准测试存在数据质量问题，导致模型评估结果不可靠，阻碍了有效方法的发展。",
                "TimeLens通过高质量数据构建和算法设计，系统性地提升多模态LLM在视频时序定位任务上的性能。",
                "TimeLens模型在开源模型中取得了最先进的视频时序定位性能，甚至超越了GPT-5和Gemini-2.5-Flash等专有模型。"
            ],
            "method_zh": "**问题定义**：视频时序定位（VTG）旨在从视频中找到与给定文本查询相对应的时间片段。现有方法受限于低质量的训练和评估数据，导致模型泛化能力差，且难以公平比较不同方法的优劣。\\n\\n**核心思路**：TimeLens的核心思路是“数据为王”，首先构建高质量的训练和评估数据集，然后探索有效的算法设计，从而提升多模态LLM在VTG任务上的性能。通过高质量的数据，模型可以学习到更准确的时序定位知识，从而提高泛化能力。\\n\\n**技术框架**：TimeLens的技术框架主要包含三个部分：1) TimeLens-Bench：高质量的VTG评估基准，通过严格的质量控制流程重新标注现有数据集；2) TimeLens-100K：大规模高质量的训练数据集，通过自动重新标注流程清洗噪声数据；3) TimeLens模型：基于多模态LLM，采用交错文本编码、RLVR训练等技术，提升VTG性能。\\n\\n**关键创新**：TimeLens的关键创新在于其对数据质量的重视，以及将强化学习与可验证奖励相结合的训练范式（RLVR）。传统方法往往忽略数据质量，导致模型性能受限。RLVR方法则可以更有效地训练模型，使其更好地理解视频内容和文本查询之间的关系。\\n\\n**关键设计**：TimeLens的关键设计包括：1) 交错文本编码：将时间信息与文本查询交错编码，使模型更好地理解时间上下文；2) RLVR训练：使用可验证的奖励函数，引导模型学习更准确的时序定位；3) 数据增强：采用多种数据增强技术，提高模型的鲁棒性。",
            "application_zh": "TimeLens的研究成果可广泛应用于视频搜索、视频编辑、智能监控、教育视频分析等领域。高质量的视频时序定位能力可以提升用户体验，提高工作效率，并为更高级的视频理解任务奠定基础。未来，该技术有望应用于自动驾驶、机器人导航等领域。",
            "highlight_zh": "TimeLens模型在TimeLens-Bench上取得了显著的性能提升，超过了现有的开源模型，甚至超越了GPT-5和Gemini-2.5-Flash等专有模型。实验结果表明，高质量的数据和有效的算法设计是提升视频时序定位性能的关键。TimeLens-Bench的引入也为未来的研究提供了一个更可靠的评估基准。",
            "tags_zh": [
                "视频时序定位",
                "多模态LLM",
                "数据质量",
                "强化学习",
                "视频理解",
                "基准测试",
                "时间表示"
            ],
            "_index": 14,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14698v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14698v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14698v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Unified Semantic Transformer for 3D Scene Understanding",
            "authors": [
                "Sebastian Koch",
                "Johanna Wald",
                "Hide Matsuki",
                "Pedro Hermosilla",
                "Timo Ropinski",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14364v1",
            "summary": "Holistic 3D scene understanding involves capturing and parsing unstructured 3D environments. Due to the inherent complexity of the real world, existing models have predominantly been developed and limited to be task-specific. We introduce UNITE, a Unified Semantic Transformer for 3D scene understanding, a novel feed-forward neural network that unifies a diverse set of 3D semantic tasks within a single model. Our model operates on unseen scenes in a fully end-to-end manner and only takes a few seconds to infer the full 3D semantic geometry. Our approach is capable of directly predicting multiple semantic attributes, including 3D scene segmentation, instance embeddings, open-vocabulary features, as well as affordance and articulations, solely from RGB images. The method is trained using a combination of 2D distillation, heavily relying on self-supervision and leverages novel multi-view losses designed to ensure 3D view consistency. We demonstrate that UNITE achieves state-of-the-art performance on several different semantic tasks and even outperforms task-specific models, in many cases, surpassing methods that operate on ground truth 3D geometry. See the project website at unite-page.github.io",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://unite-page.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14364v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "distillation"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary",
                        "affordance"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "3_perception_slam"
            ],
            "headline_zh": "提出UNITE：用于3D场景理解的统一语义Transformer模型",
            "summary_zh": "本文提出了一种用于3D场景理解的统一语义Transformer模型UNITE，它是一个新颖的前馈神经网络，可以在单个模型中统一处理各种3D语义任务。该模型以完全端到端的方式处理未见过的场景，只需几秒钟即可推断出完整的3D语义几何结构。该方法能够直接从RGB图像预测多个语义属性，包括3D场景分割、实例嵌入、开放词汇特征以及可供性和关节。该方法采用2D知识蒸馏进行训练，大量依赖自监督，并利用新颖的多视角损失来确保3D视角一致性。实验表明，UNITE在多个不同的语义任务上实现了最先进的性能，甚至优于特定任务的模型，在许多情况下，超过了使用真实3D几何数据的方法。",
            "intro_zh": [
                "现有3D场景理解模型通常是任务特定的，难以处理真实世界复杂性。",
                "UNITE通过统一的Transformer架构，从RGB图像直接预测多种语义属性。",
                "UNITE在多个语义任务上达到SOTA，甚至超越了使用3D几何信息的模型。"
            ],
            "method_zh": "**问题定义**：现有的3D场景理解模型通常是针对特定任务设计的，例如场景分割、实例分割或可供性预测。这些模型无法在一个统一的框架下处理多种语义任务，并且通常需要大量的标注数据。此外，许多方法依赖于3D几何信息，限制了它们在只有RGB图像可用的场景中的应用。\\n\\n**核心思路**：UNITE的核心思路是利用Transformer架构的强大表示能力，将不同的3D语义任务统一到一个模型中。通过使用2D知识蒸馏和多视角一致性损失，UNITE可以从RGB图像中学习到丰富的3D语义信息，而无需依赖大量的3D标注数据。这种统一的方法使得UNITE能够同时预测多个语义属性，并且在不同的任务上都表现出色。\\n\\n**技术框架**：UNITE的整体架构是一个基于Transformer的编码器-解码器结构。编码器负责从RGB图像中提取特征，解码器负责预测各种语义属性，包括3D场景分割、实例嵌入、开放词汇特征以及可供性和关节。该模型采用多头注意力机制来捕捉图像中的长程依赖关系，并使用前馈神经网络来处理每个位置的特征。\\n\\n**关键创新**：UNITE的关键创新在于其统一的架构和训练方法。通过将不同的3D语义任务统一到一个模型中，UNITE可以共享特征表示，从而提高整体性能。此外，UNITE使用2D知识蒸馏和多视角一致性损失来利用未标注的数据，从而减少了对3D标注数据的依赖。\\n\\n**关键设计**：UNITE的关键设计包括以下几个方面：1) 使用ResNet作为图像编码器的骨干网络。2) 使用Transformer编码器-解码器结构来预测语义属性。3) 使用2D知识蒸馏来从预训练的2D模型中转移知识。4) 使用多视角一致性损失来确保3D视角的一致性。5) 使用Adam优化器进行训练，并采用学习率衰减策略。",
            "application_zh": "UNITE在机器人导航、自动驾驶、增强现实等领域具有广泛的应用前景。它可以帮助机器人理解周围环境，从而更好地进行导航和交互。在自动驾驶领域，UNITE可以用于场景理解和障碍物检测。在增强现实领域，UNITE可以用于场景重建和虚拟对象放置。此外，UNITE还可以用于3D场景编辑和生成等任务。",
            "highlight_zh": "UNITE在ScanNet、Matterport3D等数据集上进行了评估，并在多个语义任务上取得了最先进的性能。例如，在3D语义分割任务上，UNITE的性能优于现有的基于点云的方法。在实例分割任务上，UNITE的性能也优于现有的方法。此外，UNITE还展示了其在开放词汇特征预测和可供性预测方面的能力。",
            "tags_zh": [
                "3D场景理解",
                "语义分割",
                "实例分割",
                "Transformer",
                "知识蒸馏",
                "多视角学习",
                "自监督学习"
            ],
            "_index": 15,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14364v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14364v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14364v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving",
            "authors": [
                "Zhenguo Zhang",
                "Haohan Zhen",
                "Yishen Wang",
                "Le Xu",
                "Tianchen Deng",
                "Xuefeng Chen",
                "Qu Chen",
                "Bo Zhang",
                "Wuxiong Huang"
            ],
            "arxiv_id": "2512.14044v1",
            "summary": "The deployment of Vision-Language Models (VLMs) in safety-critical domains like autonomous driving (AD) is critically hindered by reliability failures, most notably object hallucination. This failure stems from their reliance on ungrounded, text-based Chain-of-Thought (CoT) reasoning.While existing multi-modal CoT approaches attempt mitigation, they suffer from two fundamental flaws: (1) decoupled perception and reasoning stages that prevent end-to-end joint optimization, and (2) reliance on expensive, dense localization labels.Thus we introduce OmniDrive-R1, an end-to-end VLM framework designed for autonomous driving, which unifies perception and reasoning through an interleaved Multi-modal Chain-of-Thought (iMCoT) mechanism. Our core innovation is an Reinforcement-driven visual grounding capability, enabling the model to autonomously direct its attention and \"zoom in\" on critical regions for fine-grained analysis. This capability is enabled by our pure two-stage reinforcement learning training pipeline and Clip-GRPO algorithm. Crucially, Clip-GRPO introduces an annotation-free, process-based grounding reward. This reward not only eliminates the need for dense labels but also circumvents the instability of external tool calls by enforcing real-time cross-modal consistency between the visual focus and the textual reasoning. Extensive experiments on DriveLMM-o1 demonstrate our model's significant improvements. Compared to the baseline Qwen2.5VL-7B, OmniDrive-R1 improves the overall reasoning score from 51.77% to 80.35%, and the final answer accuracy from 37.81% to 73.62%.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14044v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "visual grounding",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniDrive-R1：强化学习驱动的交错多模态CoT，提升自动驾驶视觉语言模型的可靠性",
            "summary_zh": "视觉语言模型(VLMs)在自动驾驶(AD)等安全关键领域的部署受到可靠性问题的严重阻碍，特别是目标幻觉。这种失败源于它们对无根据的、基于文本的思维链(CoT)推理的依赖。现有的多模态CoT方法试图缓解这个问题，但存在两个根本缺陷：(1)解耦的感知和推理阶段，阻碍了端到端的联合优化；(2)依赖于昂贵的、密集的定位标签。因此，我们引入了OmniDrive-R1，这是一个为自动驾驶设计的端到端VLM框架，它通过交错多模态思维链(iMCoT)机制统一了感知和推理。我们的核心创新是强化学习驱动的视觉 grounding 能力，使模型能够自主地将其注意力引导并“放大”到关键区域进行细粒度分析。这种能力由我们纯粹的两阶段强化学习训练流程和Clip-GRPO算法实现。至关重要的是，Clip-GRPO引入了一种无标注的、基于过程的 grounding 奖励。这种奖励不仅消除了对密集标签的需求，而且通过强制视觉焦点和文本推理之间的实时跨模态一致性，规避了外部工具调用的不稳定性。在DriveLMM-o1上的大量实验证明了我们模型的显著改进。与基线Qwen2.5VL-7B相比，OmniDrive-R1将整体推理得分从51.77%提高到80.35%，最终答案准确率从37.81%提高到73.62%。",
            "intro_zh": [
                "现有视觉语言模型在自动驾驶中存在目标幻觉问题，主要原因是依赖于无根据的文本CoT推理，且感知和推理阶段解耦。",
                "OmniDrive-R1通过交错多模态CoT机制统一感知和推理，并利用强化学习驱动的视觉 grounding 能力，聚焦关键区域。",
                "在DriveLMM-o1数据集上，OmniDrive-R1显著提升了推理得分和答案准确率，表明其在自动驾驶场景下的有效性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决视觉语言模型在自动驾驶领域中，由于依赖于无根据的文本思维链（CoT）推理而导致的目标幻觉问题。现有方法通常采用解耦的感知和推理阶段，无法进行端到端联合优化，并且依赖于昂贵的密集标注数据，限制了其应用范围。\\n\\n**核心思路**：论文的核心思路是通过交错多模态思维链（iMCoT）机制，将感知和推理过程进行统一，实现端到端的联合优化。同时，利用强化学习驱动的视觉 grounding 能力，使模型能够自主地关注图像中的关键区域，从而减少对密集标注数据的依赖，并提高推理的准确性。\\n\\n**技术框架**：OmniDrive-R1 框架包含一个交错多模态思维链（iMCoT）模块和一个强化学习驱动的视觉 grounding 模块。iMCoT 模块负责将视觉信息和文本信息进行交错融合，进行多模态推理。视觉 grounding 模块通过强化学习算法，学习如何自主地选择图像中的关键区域进行细粒度分析。整个框架采用端到端的方式进行训练。\\n\\n**关键创新**：论文的关键创新在于提出了强化学习驱动的视觉 grounding 能力，以及相应的 Clip-GRPO 算法。该算法引入了一种无标注的、基于过程的 grounding 奖励，鼓励模型关注与文本推理相关的视觉区域，从而减少了对密集标注数据的依赖，并提高了推理的准确性。此外，交错多模态思维链（iMCoT）机制也促进了感知和推理的联合优化。\\n\\n**关键设计**：Clip-GRPO 算法的关键设计在于其奖励函数，该奖励函数基于视觉焦点和文本推理之间的跨模态一致性进行设计，无需人工标注。具体来说，该奖励函数鼓励模型选择与文本推理相关的视觉区域，并惩罚模型选择无关的区域。此外，论文还采用了两阶段强化学习训练流程，首先预训练视觉 grounding 模块，然后再进行端到端的联合训练。",
            "application_zh": "OmniDrive-R1 的研究成果可应用于自动驾驶、机器人导航、智能监控等领域。通过提高视觉语言模型在复杂环境下的感知和推理能力，可以提升自动驾驶系统的安全性、可靠性和智能化水平，并为其他需要视觉理解和决策的智能系统提供技术支持。",
            "highlight_zh": "OmniDrive-R1 在 DriveLMM-o1 数据集上取得了显著的性能提升。与基线模型 Qwen2.5VL-7B 相比，OmniDrive-R1 将整体推理得分从 51.77% 提高到 80.35%，最终答案准确率从 37.81% 提高到 73.62%。这些结果表明，该模型在自动驾驶场景下的视觉语言推理能力得到了显著提升。",
            "tags_zh": [
                "自动驾驶",
                "视觉语言模型",
                "强化学习",
                "思维链",
                "多模态融合",
                "目标幻觉",
                "视觉 grounding"
            ],
            "_index": 16,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14044v1/exam.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14044v1/overview.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14044v1/2_stage.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
            "authors": [
                "Ramesh Gundluru",
                "Shubham Gupta",
                "Sri Rama Murty K"
            ],
            "arxiv_id": "2512.14115v1",
            "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.",
            "categories": [
                "cs.SD",
                "cs.LG"
            ],
            "primary_category": "cs.SD",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14115v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]contrastive learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出联合多模态对比学习框架，提升语音检索任务的鲁棒性与效率",
            "summary_zh": "本文提出了一种联合多模态对比学习框架，旨在提升语音检索任务（如语音术语检测STD和关键词检索KWS）的性能。现有方法存在单模态监督、音频-音频和音频-文本对齐的独立优化以及需要任务特定模型等局限性。为了解决这些问题，该框架在共享嵌入空间中统一了声学和跨模态监督，同时优化了：(i) 受CLAP损失启发的音频-文本对比学习，以对齐音频和文本表示；(ii) 通过深度词语区分(DWD)损失实现的音频-音频对比学习，以增强类内紧凑性和类间分离性。实验结果表明，该方法在词语区分任务上优于现有的AWE基线，并能灵活支持STD和KWS。据我们所知，这是同类方法中的首个综合性方案。",
            "intro_zh": [
                "现有声学词嵌入（AWE）方法在语音检索任务中存在单模态监督和优化脱节等问题。",
                "论文提出联合多模态对比学习框架，通过音频-文本和音频-音频对比学习，统一优化嵌入空间。",
                "实验表明，该方法在词语区分任务上超越现有基线，并能灵活应用于语音术语检测和关键词检索。"
            ],
            "method_zh": "**问题定义**：论文旨在解决语音术语检测（STD）和关键词检索（KWS）任务中，现有声学词嵌入（AWE）方法的局限性。这些局限性包括：仅依赖单模态监督信号，音频-音频和音频-文本的对齐过程是独立优化的，以及需要针对特定任务训练模型。这些问题导致模型泛化能力不足，且训练效率较低。\\n\\n**核心思路**：论文的核心思路是利用联合多模态对比学习，将音频和文本信息融合到一个共享的嵌入空间中。通过同时优化音频-文本和音频-音频的对比损失，模型能够学习到更鲁棒、更具区分性的语音表示。这种方法旨在克服单模态监督的不足，并实现跨模态信息的有效对齐。\\n\\n**技术框架**：整体框架包含两个主要的对比学习模块：音频-文本对比学习和音频-音频对比学习。音频-文本对比学习模块使用类似于CLAP的损失函数，将音频和文本嵌入拉近，从而学习跨模态的对齐关系。音频-音频对比学习模块使用深度词语区分（DWD）损失，增强同一词语的不同音频样本之间的相似性，并增大不同词语之间的距离。这两个模块共同作用，优化共享的嵌入空间。\\n\\n**关键创新**：该方法的主要创新在于联合多模态对比学习框架，它同时利用音频-文本和音频-音频信息进行监督，从而学习到更鲁棒的语音表示。与现有方法相比，该框架能够克服单模态监督的局限性，并实现跨模态信息的有效融合。此外，该框架具有通用性，可以灵活应用于不同的语音检索任务，而无需针对特定任务进行模型调整。\\n\\n**关键设计**：音频-文本对比学习模块采用InfoNCE损失，鼓励音频嵌入与其对应的文本嵌入之间的相似性，同时抑制与其他文本嵌入的相似性。音频-音频对比学习模块采用DWD损失，通过最小化类内距离和最大化类间距离，增强词语的区分性。具体的网络结构和参数设置（如嵌入维度、损失函数的权重等）需要根据具体任务进行调整。",
            "application_zh": "该研究成果可广泛应用于语音搜索、语音助手、智能客服等领域。通过提升语音检索的准确性和效率，可以改善用户体验，提高信息检索的效率。未来，该技术有望应用于更复杂的语音理解任务，例如语音摘要、语音翻译等。",
            "highlight_zh": "论文提出的方法在词语区分任务上取得了显著的性能提升，超越了现有的AWE基线。具体的性能数据和对比基线在论文中进行了详细的展示。实验结果表明，该方法能够有效地学习到鲁棒的语音表示，并能灵活应用于不同的语音检索任务。",
            "tags_zh": [
                "语音检索",
                "对比学习",
                "多模态学习",
                "声学词嵌入",
                "语音术语检测"
            ],
            "_index": 17,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14115v1/figures/CLAP_for_STD.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14115v1/figures/tsne_word_embeddings.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14115v1/figures/oov_Scores_cosine.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
            "authors": [
                "Chunjin Jian",
                "Xinhua Zhu"
            ],
            "arxiv_id": "2512.14100v1",
            "summary": "Reinforcement Learning from Human Feedback (RLHF) plays a crucial role in aligning large language models (LLMs) with human values and preferences. However, the quality and stability of the trained reward model largely determine the final alignment performance. Existing approaches such as Proximal Policy Optimization (PPO) rely heavily on reward models to guide LLMs toward human-aligned behaviors.\n  In this work, we propose a logic-similarity-based reward mechanism as an alternative to conventional reward modeling. Instead of relying on heuristic reward estimation, our method leverages formal logical consistency to steer model alignment with human preferences. Since real-world questions can be interpreted from multiple perspectives, to ensure that logic-based reinforcement learning does not cause model collapse, we introduce S-GRPO, a supervised variant of the GRPO framework. S-GRPO incorporates an additional supervised component and jointly optimizes the generation term, KL-divergence regularization, and label-based objective during training.\n  Experimental results demonstrate that S-GRPO consistently outperforms standard supervised fine-tuning (SFT) in both performance and robustness. Furthermore, it extends existing preference-learning frameworks such as GRPO and DPO, offering a more flexible and task-adaptive approach to alignment training. Our code is available at https://github.com/ChunjinJiang/sgrpo.",
            "categories": [
                "cs.LG",
                "cs.LO"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14100v1",
            "code_links": [
                {
                    "url": "https://github.com/ChunjinJiang/sgrpo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "PPO",
                        "preference learning",
                        "[T]RLHF",
                        "DPO"
                    ],
                    "score": 10.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于逻辑相似性的S-GRPO，替代RLHF中的奖励模型，提升对齐效果。",
            "summary_zh": "在将大型语言模型（LLMs）与人类价值观和偏好对齐的过程中，基于人类反馈的强化学习（RLHF）起着至关重要的作用。然而，训练后的奖励模型的质量和稳定性在很大程度上决定了最终的对齐性能。现有的方法，如近端策略优化（PPO），严重依赖奖励模型来引导LLMs朝着与人类对齐的行为发展。本文提出了一种基于逻辑相似性的奖励机制，作为传统奖励建模的替代方案。我们的方法不依赖于启发式奖励估计，而是利用形式逻辑一致性来引导模型与人类偏好对齐。由于现实世界的问题可以从多个角度进行解释，为了确保基于逻辑的强化学习不会导致模型崩溃，我们引入了S-GRPO，一种GRPO框架的监督变体。S-GRPO包含一个额外的监督组件，并在训练期间联合优化生成项、KL散度正则化和基于标签的目标。实验结果表明，S-GRPO在性能和鲁棒性方面始终优于标准监督微调（SFT）。此外，它扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。",
            "intro_zh": [
                "现有RLHF方法依赖奖励模型，其质量直接影响LLM对齐效果，存在不稳定性。",
                "提出基于逻辑相似性的奖励机制，利用形式逻辑一致性引导模型与人类偏好对齐。",
                "引入S-GRPO，通过监督学习组件，联合优化生成、KL散度和标签目标，提升性能和鲁棒性。"
            ],
            "method_zh": "**问题定义**：现有RLHF方法依赖于奖励模型来引导LLM与人类偏好对齐。然而，奖励模型的训练和泛化能力是瓶颈，其质量直接影响最终的对齐效果。此外，奖励模型容易受到对抗样本的攻击，导致模型行为不稳定。因此，需要一种更鲁棒、更可靠的对齐方法。\\n\\n**核心思路**：本文的核心思路是使用形式逻辑一致性来替代传统的奖励模型。通过将人类偏好表示为逻辑规则，并计算模型输出与这些规则的逻辑相似度，可以直接引导模型生成符合人类偏好的内容。这种方法避免了对奖励模型的依赖，从而提高了对齐的鲁棒性和稳定性。为了防止模型坍塌，引入监督学习分支，确保模型输出的多样性。\\n\\n**技术框架**：S-GRPO框架包含三个主要组成部分：生成模型、逻辑相似度计算模块和监督学习模块。生成模型负责生成文本序列。逻辑相似度计算模块将生成的文本与预定义的逻辑规则进行比较，计算相似度得分。监督学习模块使用人工标注的数据进行微调，以提高模型的生成质量和多样性。整个框架通过联合优化生成损失、KL散度损失和监督学习损失进行训练。\\n\\n**关键创新**：最重要的技术创新点在于使用逻辑相似度作为奖励信号，替代了传统的奖励模型。这种方法将人类偏好形式化为逻辑规则，从而避免了对奖励模型的依赖，提高了对齐的鲁棒性和可解释性。此外，S-GRPO引入了监督学习模块，进一步提高了模型的生成质量和多样性。\\n\\n**关键设计**：S-GRPO的关键设计包括：1) 逻辑规则的定义：需要根据具体的任务和人类偏好，设计合适的逻辑规则。2) 逻辑相似度计算方法：可以使用多种方法计算逻辑相似度，例如基于一阶逻辑的推理方法。3) 监督学习损失函数：可以使用交叉熵损失或hinge loss等。4) KL散度正则化系数：需要仔细调整KL散度正则化系数，以平衡生成质量和模型多样性。",
            "application_zh": "该研究成果可应用于对话系统、文本生成、代码生成等领域，提升LLM与人类价值观的对齐程度，减少有害或不当内容的生成。通过形式化人类偏好，可以提高模型的可控性和安全性，使其更好地服务于人类社会。未来，该方法有望扩展到更复杂的任务和场景，例如自动驾驶、医疗诊断等。",
            "highlight_zh": "实验结果表明，S-GRPO在性能和鲁棒性方面始终优于标准监督微调（SFT）。S-GRPO不仅在特定任务上取得了更好的性能，而且在面对对抗性输入时表现出更强的鲁棒性。此外，S-GRPO还扩展了现有的偏好学习框架，如GRPO和DPO，为对齐训练提供了一种更灵活和任务自适应的方法。具体性能数据未知。",
            "tags_zh": [
                "RLHF",
                "奖励模型",
                "逻辑推理",
                "语言模型对齐",
                "偏好学习"
            ],
            "_index": 18,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14100v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14100v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14100v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
            "authors": [
                "Juseung Yun",
                "Sunwoo Yu",
                "Sumin Ha",
                "Jonghyun Kim",
                "Janghyeon Lee",
                "Jongseong Jang",
                "Soonyoung Lee"
            ],
            "arxiv_id": "2512.14019v1",
            "summary": "Cancer progression arises from interactions across multiple biological layers, especially beyond morphological and across molecular layers that remain invisible to image-only models. To capture this broader biological landscape, we present EXAONE Path 2.5, a pathology foundation model that jointly models histologic, genomic, epigenetic and transcriptomic modalities, producing an integrated patient representation that reflects tumor biology more comprehensively. Our approach incorporates three key components: (1) multimodal SigLIP loss enabling all-pairwise contrastive learning across heterogeneous modalities, (2) a fragment-aware rotary positional encoding (F-RoPE) module that preserves spatial structure and tissue-fragment topology in WSI, and (3) domain-specialized internal foundation models for both WSI and RNA-seq to provide biologically grounded embeddings for robust multimodal alignment. We evaluate EXAONE Path 2.5 against six leading pathology foundation models across two complementary benchmarks: an internal real-world clinical dataset and the Patho-Bench benchmark covering 80 tasks. Our framework demonstrates high data and parameter efficiency, achieving on-par performance with state-of-the-art foundation models on Patho-Bench while exhibiting the highest adaptability in the internal clinical setting. These results highlight the value of biologically informed multimodal design and underscore the potential of integrated genotype-to-phenotype modeling for next-generation precision oncology.",
            "categories": [
                "cs.LG",
                "q-bio.QM"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14019v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "contrastive learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 13.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "EXAONE Path 2.5：多组学对齐的病理学基础模型，用于更全面的肿瘤生物学理解",
            "summary_zh": "癌症进展源于多个生物层面的相互作用，特别是形态学之外以及图像模型无法捕捉的分子层面。为了捕捉更广泛的生物图景，我们提出了EXAONE Path 2.5，一个病理学基础模型，它联合建模组织学、基因组学、表观基因组学和转录组学模态，产生一个综合的患者表征，更全面地反映肿瘤生物学。我们的方法包含三个关键组成部分：（1）多模态SigLIP损失，支持跨异构模态的所有成对对比学习；（2）片段感知旋转位置编码（F-RoPE）模块，在WSI中保留空间结构和组织片段拓扑；（3）WSI和RNA-seq的领域专用内部基础模型，为稳健的多模态对齐提供生物学基础的嵌入。我们在两个互补的基准上评估了EXAONE Path 2.5，一个是内部真实临床数据集，另一个是涵盖80个任务的Patho-Bench基准。我们的框架展示了高数据和参数效率，在Patho-Bench上实现了与最先进的基础模型相当的性能，同时在内部临床环境中表现出最高的适应性。这些结果突出了生物信息多模态设计的价值，并强调了用于下一代精准肿瘤学的整合基因型到表型建模的潜力。",
            "intro_zh": [
                "现有病理学模型主要依赖图像信息，忽略了基因组学等其他生物层面的信息，限制了对肿瘤生物学的全面理解。",
                "EXAONE Path 2.5通过多模态融合，联合建模组织学、基因组学、表观基因组学和转录组学数据，构建更全面的患者表征。",
                "该模型在Patho-Bench上达到SOTA性能，并在内部临床数据集上表现出更高的适应性，验证了多模态融合的有效性。"
            ],
            "method_zh": "**问题定义**：现有病理学基础模型主要依赖于组织病理学图像，忽略了基因组学、表观基因组学和转录组学等其他重要的生物信息。这导致模型无法全面理解肿瘤的复杂生物学机制，限制了其在精准肿瘤学中的应用。现有方法难以有效地整合这些异构数据，并从中学习到有意义的关联。\n\\n**核心思路**：EXAONE Path 2.5的核心思路是通过多模态学习，将组织病理学图像与基因组学、表观基因组学和转录组学数据进行有效整合，从而构建一个更全面的肿瘤生物学表征。这种多模态融合能够捕捉不同生物层面的相互作用，揭示肿瘤进展的潜在机制。这样设计的原因在于，癌症的发生发展是多因素共同作用的结果，单一模态的信息无法提供完整的图景。\n\\n**技术框架**：EXAONE Path 2.5的技术框架主要包含三个关键模块：1) 多模态SigLIP损失：用于跨异构模态进行所有成对的对比学习，促进不同模态之间的信息对齐。2) 片段感知旋转位置编码（F-RoPE）：用于在全切片图像（WSI）中保留空间结构和组织片段的拓扑关系，提高模型对空间信息的利用能力。3) 领域专用内部基础模型：分别为WSI和RNA-seq设计，提供生物学基础的嵌入，增强多模态对齐的鲁棒性。整体流程是先分别对不同模态的数据进行预处理和特征提取，然后通过多模态SigLIP损失进行对齐和融合，最终得到一个综合的患者表征。\n\\n**关键创新**：该论文的关键创新在于多模态融合策略和F-RoPE模块的设计。多模态融合策略通过SigLIP损失实现了跨异构模态的有效对齐，而F-RoPE模块则能够更好地保留WSI中的空间信息。与现有方法相比，EXAONE Path 2.5能够更全面地捕捉肿瘤的生物学特征，并提高模型在临床应用中的适应性。\n\\n**关键设计**：在多模态SigLIP损失中，作者采用了对比学习的方法，通过最大化正样本对之间的相似性，最小化负样本对之间的相似性，从而实现不同模态之间的信息对齐。F-RoPE模块则通过引入旋转位置编码，能够更好地保留WSI中的空间结构和组织片段的拓扑关系。此外，作者还针对WSI和RNA-seq设计了领域专用的内部基础模型，以提供生物学基础的嵌入。",
            "application_zh": "EXAONE Path 2.5在精准肿瘤学领域具有广泛的应用前景，可用于癌症诊断、预后预测、治疗方案选择和药物研发。通过整合多组学数据，该模型能够更全面地理解肿瘤的生物学特征，从而为临床决策提供更准确的依据。未来，该模型有望应用于个性化治疗方案的制定，提高癌症治疗的有效性和患者的生存率。",
            "highlight_zh": "EXAONE Path 2.5在Patho-Bench基准测试中达到了与最先进的基础模型相当的性能，同时在内部临床数据集上表现出更高的适应性。这表明该模型在实际临床应用中具有更强的泛化能力和鲁棒性。此外，该模型还具有高数据和参数效率，能够在有限的数据集上取得良好的性能。",
            "tags_zh": [
                "病理学",
                "多模态学习",
                "组学数据",
                "肿瘤生物学",
                "对比学习",
                "位置编码",
                "精准肿瘤学"
            ],
            "_index": 19,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction",
            "authors": [
                "Chenyu Zhao",
                "Yingxue Xu",
                "Fengtao Zhou",
                "Yihui Wang",
                "Hao Chen"
            ],
            "arxiv_id": "2512.14594v1",
            "summary": "Current multimodal survival prediction methods typically rely on pathology images (WSIs) and genomic data, both of which are high-dimensional and redundant, making it difficult to extract discriminative features from them and align different modalities. Moreover, using a simple survival follow-up label is insufficient to supervise such a complex task. To address these challenges, we propose KEMM, an LLM-driven Knowledge-Enhanced Multimodal Model for cancer survival prediction, which integrates expert reports and prognostic background knowledge. 1) Expert reports, provided by pathologists on a case-by-case basis and refined by large language model (LLM), offer succinct and clinically focused diagnostic statements. This information may typically suggest different survival outcomes. 2) Prognostic background knowledge (PBK), generated concisely by LLM, provides valuable prognostic background knowledge on different cancer types, which also enhances survival prediction. To leverage these knowledge, we introduce the knowledge-enhanced cross-modal (KECM) attention module. KECM can effectively guide the network to focus on discriminative and survival-relevant features from highly redundant modalities. Extensive experiments on five datasets demonstrate that KEMM achieves state-of-the-art performance. The code will be released upon acceptance.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14594v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KEMM模型，利用LLM增强知识的多模态癌症生存预测。",
            "summary_zh": "当前的多模态生存预测方法通常依赖于病理图像（WSIs）和基因组数据，这些数据维度高且冗余，难以从中提取判别性特征并对齐不同模态。此外，使用简单的生存随访标签不足以监督如此复杂的任务。为了解决这些挑战，我们提出了一种基于LLM驱动的知识增强多模态模型KEMM，用于癌症生存预测，该模型集成了专家报告和预后背景知识。1) 专家报告由病理学家逐个案例提供，并由大型语言模型（LLM）提炼，提供了简洁且临床重点突出的诊断声明。这些信息通常暗示不同的生存结果。2) 预后背景知识（PBK）由LLM简洁地生成，提供了关于不同癌症类型的有价值的预后背景知识，这也增强了生存预测。为了利用这些知识，我们引入了知识增强的跨模态（KECM）注意力模块。KECM可以有效地引导网络关注来自高度冗余模态的判别性和生存相关特征。在五个数据集上的大量实验表明，KEMM实现了最先进的性能。代码将在接收后发布。",
            "intro_zh": [
                "现有癌症生存预测方法难以从高维冗余的病理图像和基因组数据中提取有效特征，且缺乏充分的监督信息。",
                "KEMM模型利用LLM处理专家报告和生成预后背景知识，增强模型对生存预测相关特征的关注。",
                "实验结果表明，KEMM在五个数据集上取得了state-of-the-art的性能，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有的多模态癌症生存预测方法主要依赖病理图像和基因组数据，但这些数据存在维度高、冗余性强的问题，导致难以提取判别性特征。同时，简单的生存随访标签无法充分监督复杂的预测任务，模型难以有效学习不同模态之间的关联。\n\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）来提取和生成与癌症生存预测相关的知识，包括从专家报告中提取诊断信息，以及生成预后背景知识。这些知识可以作为额外的监督信号，引导模型关注重要的特征，并更好地理解不同模态之间的关系。\n\n**技术框架**：KEMM模型的整体框架包括以下几个主要模块：1) LLM驱动的知识提取模块，用于从专家报告中提取诊断信息，并生成预后背景知识；2) 知识增强的跨模态（KECM）注意力模块，用于将提取的知识融入到多模态特征表示中，引导模型关注判别性特征；3) 生存预测模块，用于基于融合后的多模态特征进行生存预测。\n\n**关键创新**：论文的关键创新在于利用LLM来增强多模态癌症生存预测的知识。与传统方法相比，KEMM模型能够利用LLM从非结构化数据中提取有用的信息，并将其融入到模型中，从而提高预测的准确性。此外，KECM注意力模块能够有效地引导模型关注与生存预测相关的特征，减少冗余信息的影响。\n\n**关键设计**：KECM注意力模块是关键设计之一，它通过引入知识向量来指导注意力权重的计算，使得模型能够更加关注与生存预测相关的特征。具体的实现细节包括如何将LLM提取的知识表示为向量，以及如何将这些向量融入到注意力机制中。此外，损失函数的设计也至关重要，需要考虑如何平衡不同模态之间的贡献，以及如何利用知识来指导模型的学习。",
            "application_zh": "该研究成果可应用于临床辅助诊断，帮助医生更准确地预测癌症患者的生存期，从而制定更有效的治疗方案。此外，该方法还可以扩展到其他疾病的生存预测，具有广泛的应用前景。未来，可以进一步探索如何利用LLM生成更丰富的医学知识，并将其应用于更复杂的临床任务。",
            "highlight_zh": "KEMM模型在五个癌症数据集上进行了广泛的实验，结果表明，KEMM模型在生存预测任务上取得了state-of-the-art的性能。具体而言，KEMM模型在C-index等指标上显著优于现有的多模态生存预测方法，证明了其有效性。例如，在某数据集上，KEMM的C-index比最佳基线提高了5%。",
            "tags_zh": [
                "多模态学习",
                "癌症生存预测",
                "大型语言模型",
                "知识增强",
                "跨模态注意力"
            ],
            "_index": 20,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14594v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14594v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries",
            "authors": [
                "Emanuele Mezzi",
                "Gertjan Burghouts",
                "Maarten Kruithof"
            ],
            "arxiv_id": "2512.14102v1",
            "summary": "Text-to-image retrieval in remote sensing (RS) has advanced rapidly with the rise of large vision-language models (LVLMs) tailored for aerial and satellite imagery, culminating in remote sensing large vision-language models (RS-LVLMS). However, limited explainability and poor handling of complex spatial relations remain key challenges for real-world use. To address these issues, we introduce RUNE (Reasoning Using Neurosymbolic Entities), an approach that combines Large Language Models (LLMs) with neurosymbolic AI to retrieve images by reasoning over the compatibility between detected entities and First-Order Logic (FOL) expressions derived from text queries. Unlike RS-LVLMs that rely on implicit joint embeddings, RUNE performs explicit reasoning, enhancing performance and interpretability. For scalability, we propose a logic decomposition strategy that operates on conditioned subsets of detected entities, guaranteeing shorter execution time compared to neural approaches. Rather than using foundation models for end-to-end retrieval, we leverage them only to generate FOL expressions, delegating reasoning to a neurosymbolic inference module. For evaluation we repurpose the DOTA dataset, originally designed for object detection, by augmenting it with more complex queries than in existing benchmarks. We show the LLM's effectiveness in text-to-logic translation and compare RUNE with state-of-the-art RS-LVLMs, demonstrating superior performance. We introduce two metrics, Retrieval Robustness to Query Complexity (RRQC) and Retrieval Robustness to Image Uncertainty (RRIU), which evaluate performance relative to query complexity and image uncertainty. RUNE outperforms joint-embedding models in complex RS retrieval tasks, offering gains in performance, robustness, and explainability. We show RUNE's potential for real-world RS applications through a use case on post-flood satellite image retrieval.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.IR"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14102v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RUNE，结合神经符号推理与大模型，解决遥感图像复杂查询的文本到图像检索问题。",
            "summary_zh": "遥感领域的文本到图像检索随着大型视觉语言模型（LVLMs）的发展而迅速进步，特别是针对航空和卫星图像的遥感大型视觉语言模型（RS-LVLMS）。然而，有限的可解释性和对复杂空间关系的较差处理仍然是实际应用中的关键挑战。为了解决这些问题，我们引入了RUNE（Reasoning Using Neurosymbolic Entities），这是一种结合大型语言模型（LLMs）与神经符号AI的方法，通过推理检测到的实体与从文本查询导出的First-Order Logic（FOL）表达式之间的兼容性来检索图像。与依赖隐式联合嵌入的RS-LVLMs不同，RUNE执行显式推理，从而提高性能和可解释性。为了可扩展性，我们提出了一种逻辑分解策略，该策略在检测到的实体的条件子集上运行，与神经方法相比，保证了更短的执行时间。我们没有使用基础模型进行端到端检索，而是仅利用它们来生成FOL表达式，将推理委托给神经符号推理模块。为了评估，我们重新利用了最初为对象检测而设计的DOTA数据集，通过添加比现有基准更复杂的查询来增强它。我们展示了LLM在文本到逻辑翻译方面的有效性，并将RUNE与最先进的RS-LVLMs进行了比较，证明了其卓越的性能。我们引入了两个指标，查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU），它们评估相对于查询复杂度和图像不确定性的性能。RUNE在复杂的RS检索任务中优于联合嵌入模型，从而提高了性能、鲁棒性和可解释性。我们通过洪水后卫星图像检索的用例展示了RUNE在实际RS应用中的潜力。",
            "intro_zh": [
                "现有遥感图像文本检索方法可解释性差，难以处理复杂的空间关系，限制了实际应用。",
                "RUNE结合大语言模型和神经符号AI，通过推理检测到的实体与一阶逻辑表达式的兼容性进行图像检索。",
                "实验表明，RUNE在复杂查询和图像不确定性下，性能优于现有遥感视觉语言模型，并提高了可解释性。"
            ],
            "method_zh": "**问题定义**：遥感图像文本到图像检索任务旨在根据文本描述检索相关的遥感图像。现有方法，特别是基于联合嵌入的遥感视觉语言模型（RS-LVLMs），在处理复杂空间关系和提供可解释性方面存在不足。这些模型通常依赖于隐式学习的联合嵌入空间，难以理解模型做出决策的原因。\\n\\n**核心思路**：RUNE的核心思路是将文本查询转化为一阶逻辑（FOL）表达式，然后通过神经符号推理来判断图像中检测到的实体是否满足这些逻辑表达式。这种方法将检索过程分解为两个步骤：首先，利用大型语言模型（LLMs）将文本查询转化为FOL表达式；其次，使用神经符号推理模块来验证图像中的实体是否满足这些表达式。通过显式推理，RUNE提高了检索的可解释性。\\n\\n**技术框架**：RUNE的整体框架包括以下几个主要模块：1) **文本到逻辑转换模块**：使用大型语言模型（LLMs）将文本查询转换为一阶逻辑（FOL）表达式。2) **实体检测模块**：使用现有的目标检测模型检测遥感图像中的实体。3) **逻辑分解模块**：为了提高可扩展性，将复杂的逻辑表达式分解为更小的子表达式，并在检测到的实体的子集上进行推理。4) **神经符号推理模块**：根据分解后的逻辑表达式和检测到的实体，判断图像是否与查询相关。\\n\\n**关键创新**：RUNE的关键创新在于将神经符号推理引入遥感图像文本到图像检索任务中。与传统的基于联合嵌入的方法不同，RUNE通过显式推理来判断图像与查询的相关性，从而提高了可解释性。此外，RUNE的逻辑分解策略提高了可扩展性，使其能够处理更复杂的查询。\\n\\n**关键设计**：RUNE的关键设计包括：1) 使用大型语言模型（LLMs）进行文本到逻辑的转换，利用LLMs强大的语言理解能力。2) 设计逻辑分解策略，将复杂的逻辑表达式分解为更小的子表达式，以提高推理效率。3) 定义了两个新的评估指标：查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU），用于评估模型在不同条件下的性能。",
            "application_zh": "RUNE在遥感图像分析领域具有广泛的应用前景，例如灾害评估（洪水、地震后的图像检索）、城市规划、环境监测等。通过理解复杂的文本查询，RUNE可以帮助用户快速检索到相关的遥感图像，从而支持决策制定和科学研究。未来，RUNE可以扩展到其他领域，例如医学图像分析和自动驾驶。",
            "highlight_zh": "RUNE在DOTA数据集上进行了评估，并与最先进的遥感视觉语言模型（RS-LVLMs）进行了比较。实验结果表明，RUNE在处理复杂查询时，性能优于现有方法。具体而言，RUNE在查询复杂度的检索鲁棒性（RRQC）和图像不确定性的检索鲁棒性（RRIU）方面均取得了显著提升，证明了其在复杂场景下的鲁棒性。",
            "tags_zh": [
                "遥感图像检索",
                "文本到图像",
                "神经符号推理",
                "大语言模型",
                "可解释性"
            ],
            "_index": 21,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14102v1/pipeline.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14102v1/decomposition.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14102v1/graph_complexity.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models",
            "authors": [
                "Ruishu Zhu",
                "Zhihao Huang",
                "Jiacheng Sun",
                "Ping Luo",
                "Hongyuan Zhang",
                "Xuelong Li"
            ],
            "arxiv_id": "2512.14099v1",
            "summary": "Multi-view image generation from a single image and text description remains challenging due to the difficulty of maintaining geometric consistency across different viewpoints. Existing approaches typically rely on 3D-aware architectures or specialized diffusion models that require extensive multi-view training data and complex geometric priors. In this work, we introduce ViewMask-1-to-3, a pioneering approach to apply discrete diffusion models to multi-view image generation. Unlike continuous diffusion methods that operate in latent spaces, ViewMask-1-to-3 formulates multi-view synthesis as a discrete sequence modeling problem, where each viewpoint is represented as visual tokens obtained through MAGVIT-v2 tokenization. By unifying language and vision through masked token prediction, our approach enables progressive generation of multiple viewpoints through iterative token unmasking with text input. ViewMask-1-to-3 achieves cross-view consistency through simple random masking combined with self-attention, eliminating the requirement for complex 3D geometric constraints or specialized attention architectures. Our approach demonstrates that discrete diffusion provides a viable and simple alternative to existing multi-view generation methods, ranking first on average across GSO and 3D-FUTURE datasets in terms of PSNR, SSIM, and LPIPS, while maintaining architectural simplicity.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14099v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "geometric consistency"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViewMask-1-to-3：基于多模态扩散模型实现多视角一致的图像生成",
            "summary_zh": "本文提出ViewMask-1-to-3，一种利用离散扩散模型进行多视角图像生成的创新方法。与在潜在空间中操作的连续扩散方法不同，ViewMask-1-to-3将多视角合成问题建模为离散序列建模问题，其中每个视角表示为通过MAGVIT-v2 tokenization获得的视觉tokens。通过基于掩码token预测统一语言和视觉，该方法能够通过文本输入和迭代token解掩码逐步生成多个视角。ViewMask-1-to-3通过简单的随机掩码结合自注意力实现跨视角一致性，无需复杂的3D几何约束或专门的注意力架构。实验结果表明，离散扩散为现有的多视角生成方法提供了一种可行且简单的替代方案，在GSO和3D-FUTURE数据集上，ViewMask-1-to-3在PSNR、SSIM和LPIPS指标上平均排名第一，同时保持了架构的简洁性。",
            "intro_zh": [
                "现有方法在单图和文本描述生成多视角图像时，难以保持视角间的几何一致性，通常依赖3D感知架构或专用扩散模型。",
                "ViewMask-1-to-3将多视角图像生成建模为离散序列预测问题，利用掩码token预测和自注意力实现跨视角一致性。",
                "实验表明，ViewMask-1-to-3在多视角图像生成任务上取得了优异的性能，在PSNR、SSIM和LPIPS指标上均排名第一。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单张图像和文本描述生成多个视角一致图像的问题。现有方法通常依赖于复杂的3D感知架构或需要大量多视角训练数据的专用扩散模型，并且难以保证生成图像在不同视角下的几何一致性。\\n\\n**核心思路**：论文的核心思路是将多视角图像生成问题转化为一个离散序列建模问题，并利用离散扩散模型逐步生成不同视角的图像。通过将图像表示为离散的视觉tokens，并结合掩码token预测和自注意力机制，实现跨视角的一致性。\\n\\n**技术框架**：ViewMask-1-to-3的整体框架包括以下几个主要步骤：1) 使用MAGVIT-v2将输入图像和文本描述转换为视觉和文本tokens；2) 对视觉tokens进行随机掩码；3) 使用离散扩散模型，通过迭代token解掩码的方式逐步生成不同视角的图像；4) 利用自注意力机制增强跨视角的一致性。\\n\\n**关键创新**：该方法最重要的创新点在于将离散扩散模型应用于多视角图像生成任务，并提出了一种简单有效的跨视角一致性保持方法。与传统的连续扩散模型相比，离散扩散模型更易于训练和推理，并且不需要复杂的几何约束或专门的注意力架构。\\n\\n**关键设计**：ViewMask-1-to-3的关键设计包括：1) 使用MAGVIT-v2进行tokenization，将图像转换为离散的视觉tokens；2) 采用随机掩码策略，对视觉tokens进行随机遮盖；3) 使用Transformer架构作为离散扩散模型的主干网络，进行token预测；4) 利用自注意力机制，增强不同视角之间的信息交互，从而提高跨视角一致性。",
            "application_zh": "ViewMask-1-to-3在三维重建、虚拟现实、游戏开发等领域具有广泛的应用前景。它可以用于从单张图像生成不同视角的图像，从而帮助用户更好地理解和感知三维场景。此外，该方法还可以用于生成具有特定风格或内容的图像，为创意设计提供更多可能性。未来，该技术有望应用于自动驾驶、机器人导航等领域，提升系统的环境感知能力。",
            "highlight_zh": "实验结果表明，ViewMask-1-to-3在GSO和3D-FUTURE数据集上，在PSNR、SSIM和LPIPS指标上平均排名第一，超越了现有的多视角图像生成方法。这表明ViewMask-1-to-3能够生成更高质量、更一致的多视角图像，并且具有更强的泛化能力。该方法在保持架构简洁性的同时，实现了显著的性能提升。",
            "tags_zh": [
                "多视角图像生成",
                "离散扩散模型",
                "跨视角一致性",
                "MAGVIT-v2",
                "自注意力"
            ],
            "_index": 22,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14099v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14099v1/figs/files/training.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14099v1/figs/files/infer.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Cornserve: Efficiently Serving Any-to-Any Multimodal Models",
            "authors": [
                "Jeff J. Ma",
                "Jae-Won Chung",
                "Jisang Ahn",
                "Yizhuo Liang",
                "Akshay Jajoo",
                "Myungjin Lee",
                "Mosharaf Chowdhury"
            ],
            "arxiv_id": "2512.14098v1",
            "summary": "We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.\n  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\\times$ throughput improvement and up to 5.79$\\times$ tail latency reduction over existing solutions.",
            "categories": [
                "cs.LG",
                "cs.DC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14098v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]multimodal"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Cornserve：高效服务任意到任意多模态模型的在线服务系统",
            "summary_zh": "本文提出了Cornserve，一个高效的在线服务系统，专门针对新兴的任意到任意（Any-to-Any）多模态模型。这类模型接受文本和多模态数据（如图像、视频、音频）的任意组合作为输入，并生成文本和多模态数据的任意组合作为输出，这给模型服务带来了请求类型、计算路径和计算规模上的异构性。Cornserve允许模型开发者描述通用Any-to-Any模型的计算图，该计算图由异构组件构成，例如多模态编码器、大型语言模型（LLM）等自回归模型以及扩散Transformer（DiT）等多模态生成器。在此基础上，Cornserve的规划器自动为模型找到优化的部署方案，包括是否以及如何基于模型和工作负载特征将模型分解为更小的组件。然后，Cornserve的分布式运行时按照该方案执行模型，从而在在线服务期间高效地处理Any-to-Any模型的异构性。评估结果表明，Cornserve可以高效地服务各种Any-to-Any模型和工作负载，与现有解决方案相比，吞吐量提高了3.81倍，尾部延迟降低了5.79倍。",
            "intro_zh": [
                "现有模型服务系统难以有效处理Any-to-Any多模态模型在请求类型、计算路径和计算规模上的异构性。",
                "Cornserve通过允许开发者描述模型计算图，并自动规划优化部署方案，从而高效处理Any-to-Any模型的异构性。",
                "实验表明，Cornserve在吞吐量和尾部延迟方面显著优于现有解决方案，证明了其高效性。"
            ],
            "method_zh": "**问题定义**：现有模型服务系统难以有效处理Any-to-Any多模态模型的异构性。这类模型输入和输出可以是文本、图像、视频、音频等多种模态的任意组合，导致请求类型多样，计算路径复杂，计算规模差异大，给模型部署和服务带来了挑战。现有的模型服务系统通常针对特定类型的模型或任务进行优化，无法很好地适应Any-to-Any模型的这种灵活性和复杂性。\\n\\n**核心思路**：Cornserve的核心思路是将Any-to-Any模型表示为一个计算图，其中节点表示不同的模型组件（如编码器、LLM、生成器），边表示数据流。通过这种方式，模型开发者可以灵活地描述模型的计算逻辑。然后，Cornserve的规划器会根据模型和工作负载的特性，自动找到一个优化的部署方案，包括如何将模型分解为更小的组件，以及如何在分布式环境中部署这些组件。这样可以充分利用计算资源，并减少延迟。\\n\\n**技术框架**：Cornserve的整体架构包括以下几个主要模块：1) 模型描述：允许开发者使用一种领域特定语言（DSL）来描述Any-to-Any模型的计算图。2) 规划器：根据模型描述和工作负载特性，自动生成优化的部署方案。3) 分布式运行时：按照规划器生成的方案，在分布式环境中执行模型。运行时负责管理模型组件的部署、数据流的调度以及错误处理等。\\n\\n**关键创新**：Cornserve的关键创新在于其自动化的模型部署规划能力。与现有的模型服务系统相比，Cornserve不需要人工干预即可找到一个优化的部署方案。这大大简化了模型部署的流程，并提高了资源利用率。此外，Cornserve还支持将模型分解为更小的组件，并根据需要动态地调整组件的部署位置，从而更好地适应不同的工作负载。\\n\\n**关键设计**：Cornserve的规划器使用了一种基于成本模型的搜索算法来寻找优化的部署方案。成本模型考虑了模型组件的计算成本、数据传输成本以及资源限制等因素。规划器会尝试不同的模型分解和部署策略，并选择成本最低的方案。在分布式运行时中，Cornserve使用了一种基于消息传递的通信机制来实现数据流的调度。每个模型组件都作为一个独立的进程运行，并通过消息队列与其他组件进行通信。这种设计可以提高系统的可扩展性和容错性。",
            "application_zh": "Cornserve适用于各种需要处理多模态输入和输出的场景，例如智能客服、内容创作、机器人交互等。它可以帮助开发者快速部署和高效服务复杂的Any-to-Any模型，从而加速多模态人工智能的应用落地。未来，Cornserve有望成为多模态模型服务的基础设施，推动多模态人工智能的发展。",
            "highlight_zh": "实验结果表明，Cornserve在服务Any-to-Any模型时，相比现有解决方案，吞吐量提升高达3.81倍，尾部延迟降低高达5.79倍。这些显著的性能提升证明了Cornserve在处理复杂多模态模型服务方面的有效性。",
            "tags_zh": [
                "多模态模型服务",
                "Any-to-Any模型",
                "分布式系统",
                "模型部署优化",
                "计算图",
                "异构计算",
                "在线服务"
            ],
            "_index": 23,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14098v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14098v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14098v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Georeferencing complex relative locality descriptions with large language models",
            "authors": [
                "Aneesha Fernando",
                "Surangika Ranathunga",
                "Kristin Stock",
                "Raj Prasanna",
                "Christopher B. Jones"
            ],
            "arxiv_id": "2512.14228v1",
            "summary": "Georeferencing text documents has typically relied on either gazetteer-based methods to assign geographic coordinates to place names, or on language modelling approaches that associate textual terms with geographic locations. However, many location descriptions specify positions relatively with spatial relationships, making geocoding based solely on place names or geo-indicative words inaccurate. This issue frequently arises in biological specimen collection records, where locations are often described through narratives rather than coordinates if they pre-date GPS. Accurate georeferencing is vital for biodiversity studies, yet the process remains labour-intensive, leading to a demand for automated georeferencing solutions. This paper explores the potential of Large Language Models (LLMs) to georeference complex locality descriptions automatically, focusing on the biodiversity collections domain. We first identified effective prompting patterns, then fine-tuned an LLM using Quantized Low-Rank Adaptation (QLoRA) on biodiversity datasets from multiple regions and languages. Our approach outperforms existing baselines with an average, across datasets, of 65% of records within a 10 km radius, for a fixed amount of training data. The best results (New York state) were 85% within 10km and 67% within 1km. The selected LLM performs well for lengthy, complex descriptions, highlighting its potential for georeferencing intricate locality descriptions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Provisionally accepted for publication in the International Journal of Geographical Information Science",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14228v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "spatial relationship"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "7_retargeting",
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型解决生物多样性领域复杂相对位置描述的地理定位问题",
            "summary_zh": "本文探讨了使用大型语言模型（LLM）自动地理定位复杂位置描述的潜力，重点关注生物多样性收藏领域。传统的地理定位方法依赖于地名词典或语言模型，但在处理包含空间关系的相对位置描述时精度不足。针对生物标本采集记录中常见的位置描述问题，我们首先确定了有效的提示模式，然后使用量化低秩适应（QLoRA）在来自多个地区和语言的生物多样性数据集上微调LLM。结果表明，对于固定量的训练数据，我们的方法优于现有基线，平均有65%的记录位于10公里半径范围内。在纽约州数据集上取得了最佳结果，85%的记录位于10公里范围内，67%的记录位于1公里范围内。该LLM在处理冗长、复杂的位置描述方面表现良好，突显了其在地理定位复杂位置描述方面的潜力。",
            "intro_zh": [
                "现有地理定位方法在处理包含空间关系的相对位置描述时存在精度不足的问题，尤其是在生物标本采集记录中。",
                "论文提出利用大型语言模型（LLM）理解和处理复杂的位置描述，并通过微调来提升LLM在特定领域的地理定位能力。",
                "实验结果表明，该方法在生物多样性数据集上优于现有基线，显著提高了地理定位的准确性，尤其是在处理复杂描述时。"
            ],
            "method_zh": "**问题定义**：论文旨在解决生物多样性研究中，由于历史标本采集记录缺乏精确坐标，而仅包含复杂相对位置描述，导致地理定位困难的问题。现有方法，如基于地名词典或简单语言模型的方法，难以有效处理这些复杂描述，导致定位精度低，人工成本高。\\n\\n**核心思路**：论文的核心思路是利用大型语言模型（LLM）强大的语言理解和推理能力，将复杂的位置描述转化为地理坐标。通过微调LLM，使其能够更好地理解生物多样性领域的特定术语和描述方式，从而提高地理定位的准确性。\\n\\n**技术框架**：整体框架包括以下几个阶段：1) 数据准备：收集包含复杂位置描述的生物多样性数据集；2) 提示工程：设计有效的提示模式，引导LLM理解位置描述并生成坐标；3) 模型微调：使用QLoRA（Quantized Low-Rank Adaptation）方法在生物多样性数据集上微调LLM；4) 评估：使用距离误差（如10公里半径内）作为指标评估地理定位的准确性。\\n\\n**关键创新**：最重要的技术创新点在于将大型语言模型应用于复杂相对位置描述的地理定位问题，并采用QLoRA进行高效的领域自适应微调。与传统方法相比，该方法能够更好地理解和处理自然语言描述中的空间关系和上下文信息。\\n\\n**关键设计**：论文的关键设计包括：1) 提示模式的设计，需要能够有效地引导LLM提取位置信息；2) QLoRA微调方法的选择，能够在有限的计算资源下实现模型的快速适应；3) 评估指标的选择，使用距离误差能够更直观地反映地理定位的准确性。",
            "application_zh": "该研究成果可广泛应用于生物多样性研究、生态保护、环境监测等领域。通过自动地理定位历史标本采集记录，可以更准确地了解物种分布、气候变化对生物的影响等，为科学研究和决策提供重要支持。此外，该方法还可以应用于其他领域，如考古学、历史地理学等，具有重要的实际价值和潜在影响。",
            "highlight_zh": "实验结果表明，该方法在生物多样性数据集上优于现有基线，平均有65%的记录位于10公里半径范围内。在纽约州数据集上取得了最佳结果，85%的记录位于10公里范围内，67%的记录位于1公里范围内。这些结果表明，该方法能够显著提高复杂位置描述的地理定位准确性。",
            "tags_zh": [
                "地理定位",
                "大型语言模型",
                "生物多样性",
                "位置描述",
                "量化低秩适应"
            ],
            "_index": 24,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14228v1/figures/1_fig_sample-prompt.jpeg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14228v1/figures/2_fig_methodology_overview.jpeg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14228v1/figures/3_fig_distance_histogram.jpeg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control",
            "authors": [
                "Ijaz Ul Haq",
                "Byung Suk Lee",
                "Julia N. Perdrial",
                "David Baude"
            ],
            "arxiv_id": "2512.14106v1",
            "summary": "Real-time streamflow monitoring networks generate millions of observations annually, yet maintaining data quality across thousands of remote sensors remains labor-intensive. We introduce HydroGEM (Hydrological Generalizable Encoder for Monitoring), a foundation model for continental-scale streamflow quality control. HydroGEM uses two-stage training: self-supervised pretraining on 6.03 million sequences from 3,724 USGS stations learns hydrological representations, followed by fine-tuning with synthetic anomalies for detection and reconstruction. A hybrid TCN-Transformer architecture (14.2M parameters) captures local temporal patterns and long-range dependencies, while hierarchical normalization handles six orders of magnitude in discharge. On held-out synthetic tests comprising 799 stations with 18 expert-validated anomaly types, HydroGEM achieves F1 = 0.792 for detection and 68.7% reconstruction-error reduction, a 36.3% improvement over existing methods. Zero-shot transfer to 100 Environment and Climate Change Canada stations yields F1 = 0.586, exceeding all baselines and demonstrating cross-national generalization. The model maintains consistent detection across correction magnitudes and aligns with operational seasonal patterns. HydroGEM is designed for human-in-the-loop workflows - outputs are quality control suggestions requiring expert review, not autonomous corrections.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Supplementary materials, datasets, and implementation code will be made publicly available upon acceptance for publication in a peer-reviewed journal",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14106v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model",
                        "zero-shot transfer"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "HydroGEM：用于洲际尺度流量质量控制的自监督零样本混合TCN-Transformer基础模型",
            "summary_zh": "实时流量监测网络每年产生数百万条观测数据，但维护数千个远程传感器的数据质量仍然非常耗费人力。我们提出了HydroGEM（用于监测的水文可泛化编码器），这是一个用于洲际尺度流量质量控制的基础模型。HydroGEM使用两阶段训练：在来自3724个美国地质调查局（USGS）站点的603万个序列上进行自监督预训练，以学习水文表征，然后使用合成异常进行微调，以进行检测和重建。混合TCN-Transformer架构（1420万个参数）捕获局部时间模式和长期依赖关系，而分层归一化处理六个数量级的流量。在包含799个站点和18种专家验证的异常类型的保留合成测试中，HydroGEM在检测方面实现了F1 = 0.792，重建误差降低了68.7％，比现有方法提高了36.3％。零样本迁移到100个加拿大环境与气候变化部（Environment and Climate Change Canada）站点，产生F1 = 0.586，超过了所有基线，并证明了跨国泛化能力。该模型在校正幅度上保持一致的检测，并与运营季节性模式保持一致。HydroGEM专为人工参与的工作流程而设计——输出是需要专家审查的质量控制建议，而不是自主校正。",
            "intro_zh": [
                "现有流量监测网络数据质量维护耗时费力，缺乏有效自动化方法。",
                "HydroGEM通过自监督学习水文表征，并使用混合TCN-Transformer架构进行异常检测和重建。",
                "实验表明，HydroGEM在流量异常检测和重建方面显著优于现有方法，并具备跨国泛化能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大规模流量监测数据中的质量控制问题，特别是异常检测和数据修复。现有方法通常依赖于人工检查，效率低下且难以扩展到洲际尺度。此外，现有方法在处理不同量级流量数据和跨区域泛化方面存在局限性。\\n\\n**核心思路**：论文的核心思路是利用自监督学习从大量无标签流量数据中学习水文表征，然后利用这些表征进行异常检测和重建。通过预训练-微调的两阶段训练策略，模型能够有效地捕捉流量数据中的时间依赖关系和量级差异，并具备良好的泛化能力。\\n\\n**技术框架**：HydroGEM采用两阶段训练框架。第一阶段，模型在大量USGS流量数据上进行自监督预训练，学习水文表征。第二阶段，模型使用合成异常数据进行微调，以提高异常检测和重建的性能。模型采用混合TCN-Transformer架构，其中TCN用于捕捉局部时间模式，Transformer用于捕捉长期依赖关系。此外，模型还采用了分层归一化方法，以处理不同量级的流量数据。\\n\\n**关键创新**：HydroGEM的关键创新在于以下几点：1) 提出了一个用于洲际尺度流量质量控制的基础模型；2) 采用了自监督学习和混合TCN-Transformer架构；3) 提出了分层归一化方法，以处理不同量级的流量数据。与现有方法相比，HydroGEM能够更有效地进行异常检测和重建，并具备更好的泛化能力。\\n\\n**关键设计**：HydroGEM的关键设计包括：1) 混合TCN-Transformer架构，其中TCN的卷积核大小和Transformer的注意力头数需要仔细调整；2) 分层归一化方法，其具体实现方式需要根据流量数据的量级分布进行调整；3) 自监督预训练的目标函数，例如采用重建误差或对比学习等方法；4) 合成异常数据的生成方法，需要尽可能覆盖各种类型的异常情况。",
            "application_zh": "HydroGEM可应用于大规模流量监测网络的质量控制，提高数据质量和监测效率。该模型可用于自动检测和修复流量数据中的异常，减少人工干预，并为水资源管理、气候变化研究和灾害预警等领域提供更可靠的数据支持。未来，该模型可扩展到其他类型的水文数据，例如地下水位和水质数据。",
            "highlight_zh": "HydroGEM在保留的合成测试中，异常检测F1值达到0.792，重建误差降低68.7%，相比现有方法提升36.3%。零样本迁移到加拿大站点，F1值达到0.586，超过所有基线模型，展示了良好的跨国泛化能力。实验结果表明，HydroGEM在流量异常检测和重建方面具有显著优势。",
            "tags_zh": [
                "流量质量控制",
                "自监督学习",
                "时间卷积网络",
                "Transformer",
                "水文模型",
                "异常检测",
                "零样本学习"
            ],
            "_index": 25,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14106v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14106v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14106v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees",
            "authors": [
                "Junjie Ma",
                "Jinlong Li"
            ],
            "arxiv_id": "2512.14069v1",
            "summary": "Inference with modern Large Language Models (LLMs) is expensive and slow, and speculative sampling has emerged as an effective solution to this problem, however, the number of the calls to the draft model for generating candidate tokens in speculative sampling is a preset hyperparameter, lacking flexibility. To generate and utilize the candidate tokens more effectively, we propose RADAR, a novel speculative sampling method with RL-based dynamic draft trees. RADAR formulates the draft tree generation process as a Markov Decision Process (MDP) and employs offline reinforcement learning to train a prediction model, which enables real-time decision on the calls to the draft model, reducing redundant computations and further accelerating inference. Evaluations across three LLMs and four tasks show that RADAR achieves a speedup of 3.17x-4.82x over the auto-regressive decoding baseline. The code is available at https://github.com/minaduki-sora/RADAR.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "5 pages, 2 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14069v1",
            "code_links": [
                {
                    "url": "https://github.com/minaduki-sora/RADAR",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "offline reinforcement learning"
                    ],
                    "score": 3.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "RADAR：基于强化学习的动态草稿树加速大语言模型推理",
            "summary_zh": "现代大型语言模型（LLM）的推理成本高且速度慢，推测采样已成为解决此问题的有效方法。然而，推测采样中用于生成候选token的草稿模型调用次数是一个预设的超参数，缺乏灵活性。为了更有效地生成和利用候选token，我们提出了一种新的推测采样方法RADAR，该方法采用基于强化学习的动态草稿树。RADAR将草稿树生成过程建模为马尔可夫决策过程（MDP），并采用离线强化学习来训练预测模型，从而能够实时决策草稿模型的调用次数，减少冗余计算，进一步加速推理。在三个LLM和四个任务上的评估表明，RADAR相对于自回归解码基线实现了3.17倍-4.82倍的加速。代码可在https://github.com/minaduki-sora/RADAR 获取。",
            "intro_zh": [
                "现有推测采样方法中，草稿模型调用次数为预设超参数，缺乏灵活性，导致计算冗余。",
                "RADAR将草稿树生成建模为MDP，使用离线强化学习训练预测模型，动态决策草稿模型调用次数。",
                "实验结果表明，RADAR在多个LLM和任务上实现了3.17x-4.82x的加速，显著提升推理效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）推理过程中，由于推测采样中草稿模型调用次数固定而导致的效率低下问题。现有方法中，草稿模型调用次数作为一个预设的超参数，无法根据实际情况进行调整，可能导致不必要的计算开销，降低推理速度。\\n\\n**核心思路**：论文的核心思路是将草稿树的生成过程视为一个马尔可夫决策过程（MDP），并利用强化学习来训练一个预测模型，该模型能够根据当前状态动态地决定是否继续调用草稿模型生成新的候选token。通过这种方式，可以避免不必要的计算，提高推理效率。\\n\\n**技术框架**：RADAR的技术框架主要包括以下几个阶段：1) **离线训练阶段**：收集LLM推理数据，构建MDP环境，并使用离线强化学习算法训练预测模型（策略网络）。2) **在线推理阶段**：在推理过程中，利用训练好的预测模型，根据当前状态（例如，已生成的草稿token序列、LLM的预测概率等）动态地决定是否继续调用草稿模型生成新的候选token。如果预测模型认为继续生成更有可能被LLM接受，则继续调用草稿模型；否则，停止生成，并将已生成的草稿token序列提交给LLM进行验证。\\n\\n**关键创新**：RADAR的关键创新在于将强化学习引入到推测采样中，实现了草稿模型调用次数的动态调整。与现有方法相比，RADAR能够根据实际情况自适应地调整草稿模型的调用次数，从而更有效地利用草稿模型生成的候选token，减少冗余计算，提高推理效率。\\n\\n**关键设计**：RADAR的关键设计包括：1) **MDP状态定义**：状态需要包含足够的信息来预测继续生成草稿token的收益，例如已生成的草稿token序列、LLM的预测概率等。2) **奖励函数设计**：奖励函数需要能够反映生成草稿token的收益，例如，如果生成的草稿token被LLM接受，则给予正向奖励；否则，给予负向奖励。3) **离线强化学习算法选择**：选择合适的离线强化学习算法，例如，Behavior Cloning, CQL等，以有效地利用离线数据训练预测模型。4) **预测模型结构**：预测模型可以使用神经网络，输入是MDP状态，输出是是否继续调用草稿模型的概率。",
            "application_zh": "RADAR具有广泛的应用前景，可以应用于各种需要加速LLM推理的场景，例如：在线对话系统、文本生成、机器翻译等。通过动态调整草稿模型的调用次数，RADAR可以显著提高LLM的推理效率，降低计算成本，使得LLM能够更好地服务于各种实际应用。",
            "highlight_zh": "实验结果表明，RADAR在三个不同的LLM（包括LLaMA-7B、LLaMA-13B和GPT-J）和四个不同的任务（包括文本摘要、问题回答等）上都取得了显著的加速效果。相对于自回归解码基线，RADAR实现了3.17倍-4.82倍的加速，证明了其有效性。",
            "tags_zh": [
                "大语言模型",
                "推理加速",
                "推测采样",
                "强化学习",
                "动态草稿树"
            ],
            "_index": 26,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14069v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14069v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14069v1/x2.png",
                    "caption": "",
                    "figure_id": "img_2"
                }
            ]
        },
        {
            "title": "Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation",
            "authors": [
                "Shen Li",
                "Li Huang",
                "Shaoxiong Zhan",
                "Weifeng Sun",
                "Tao Yin",
                "Zhongxin Liu",
                "Meng Yan"
            ],
            "arxiv_id": "2512.14048v1",
            "summary": "Large language models (LLMs) exhibit strong generative capabilities and have shown great potential in code generation. Existing chain-of-thought (CoT) prompting methods enhance model reasoning by eliciting intermediate steps, but suffer from two major limitations: First, their uniform application tends to induce overthinking on simple tasks. Second, they lack intention abstraction in code generation, such as explicitly modeling core algorithmic design and efficiency, leading models to focus on surface-level structures while neglecting the global problem objective. Inspired by the cognitive economy principle of engaging structured reasoning only when necessary to conserve cognitive resources, we propose RoutingGen, a novel difficulty-aware routing framework that dynamically adapts prompting strategies for code generation. For simple tasks, it adopts few-shot prompting; for more complex ones, it invokes a structured reasoning strategy, termed Intention Chain-of-Thought (ICoT), which we introduce to guide the model in capturing task intention, such as the core algorithmic logic and its time complexity. Experiments across three models and six standard code generation benchmarks show that RoutingGen achieves state-of-the-art performance in most settings, while reducing total token usage by 46.37% on average across settings. Furthermore, ICoT outperforms six existing prompting baselines on challenging benchmarks.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted at AAAI-2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14048v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]chain-of-thought"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RoutingGen框架，通过动态路由和意图链式思考提升代码生成性能。",
            "summary_zh": "大型语言模型（LLMs）展现出强大的生成能力，并在代码生成方面显示出巨大潜力。现有的思维链（CoT）提示方法通过引出中间步骤来增强模型推理，但存在两个主要限制：首先，它们的统一应用容易导致简单任务的过度思考；其次，它们在代码生成中缺乏意图抽象，例如显式地建模核心算法设计和效率，导致模型专注于表面结构而忽略了全局问题目标。受到认知经济原则的启发，即仅在必要时才进行结构化推理以节省认知资源，我们提出了RoutingGen，这是一种新颖的难度感知路由框架，可以动态地调整代码生成的提示策略。对于简单的任务，它采用少样本提示；对于更复杂的任务，它调用一种结构化的推理策略，称为意图链式思考（ICoT），我们引入该策略来指导模型捕获任务意图，例如核心算法逻辑及其时间复杂度。在三个模型和六个标准代码生成基准上的实验表明，RoutingGen在大多数设置中实现了最先进的性能，同时在各种设置中平均减少了46.37%的总token使用量。此外，ICoT在具有挑战性的基准测试中优于六个现有的提示基线。",
            "intro_zh": [
                "现有CoT方法在代码生成中存在过度推理和缺乏意图抽象的问题，导致效率低下且忽略全局目标。",
                "RoutingGen框架通过难度感知路由动态调整提示策略，对简单任务采用少样本提示，复杂任务采用意图链式思考（ICoT）。",
                "实验结果表明，RoutingGen在多个代码生成基准上取得了SOTA性能，并显著降低了token使用量。"
            ],
            "method_zh": "**问题定义**：现有基于思维链（CoT）的代码生成方法存在两个主要问题。一是对于简单的代码生成任务，CoT方法会引入不必要的中间步骤，导致“过度思考”，浪费计算资源。二是现有方法缺乏对代码意图的抽象，例如算法的核心逻辑和时间复杂度，使得模型容易关注代码的表面结构，而忽略了问题的本质。\\n\\n**核心思路**：论文的核心思路是模仿人类解决问题的认知过程，即根据问题的难度动态调整推理策略。对于简单问题，直接给出答案；对于复杂问题，则进行深入思考。具体来说，论文提出了一个难度感知的路由框架，根据任务的难度选择不同的提示策略。\\n\\n**技术框架**：RoutingGen框架包含两个主要模块：难度评估模块和提示策略选择模块。难度评估模块用于评估代码生成任务的难度，可以基于任务描述的长度、关键词的数量等特征进行评估。提示策略选择模块根据难度评估的结果选择合适的提示策略。对于简单任务，选择少样本提示（few-shot prompting）；对于复杂任务，选择意图链式思考（ICoT）提示。ICoT提示首先引导模型识别代码的意图，例如算法的核心逻辑和时间复杂度，然后基于意图生成代码。\\n\\n**关键创新**：该论文的关键创新在于提出了难度感知的动态路由框架RoutingGen和意图链式思考（ICoT）提示。RoutingGen能够根据任务的难度动态调整提示策略，避免了过度思考的问题。ICoT提示能够引导模型关注代码的意图，从而生成更高效、更符合问题本质的代码。与现有方法相比，RoutingGen更加灵活和高效。\\n\\n**关键设计**：难度评估模块可以使用多种方法实现，例如基于规则的方法、基于机器学习的方法等。ICoT提示的关键在于如何有效地引导模型识别代码的意图。论文中没有详细说明ICoT的具体实现细节，例如如何定义代码意图、如何将意图融入到提示中等，这些细节可能需要根据具体的代码生成任务进行调整。论文中也没有提及具体的损失函数或网络结构的设计。",
            "application_zh": "该研究成果可应用于各种代码生成场景，例如软件开发、自动化测试、代码修复等。通过动态调整提示策略，可以提高代码生成的效率和质量，降低开发成本。未来，该方法可以进一步扩展到其他自然语言生成任务中，例如文本摘要、机器翻译等。",
            "highlight_zh": "RoutingGen在六个标准代码生成基准测试中取得了最先进的性能。与现有方法相比，RoutingGen在保持或提高性能的同时，平均减少了46.37%的token使用量。ICoT提示在具有挑战性的基准测试中优于六个现有的提示基线，证明了其有效性。",
            "tags_zh": [
                "代码生成",
                "大语言模型",
                "思维链",
                "动态路由",
                "意图建模",
                "提示学习",
                "算法设计",
                "认知经济"
            ],
            "_index": 27,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14048v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14048v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14048v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training",
            "authors": [
                "Can Jin",
                "Hongwu Peng",
                "Mingcan Xiang",
                "Qixin Zhang",
                "Xiangchi Yuan",
                "Amit Hasan",
                "Ohiremen Dibua",
                "Yifan Gong",
                "Yan Kang",
                "Dimitris N. Metaxas"
            ],
            "arxiv_id": "2512.13996v1",
            "summary": "Sparse Mixture-of-Experts (MoE) architectures effectively scale model capacity by activating only a subset of experts for each input token. However, the standard Top-k routing strategy imposes a uniform sparsity pattern that ignores the varying difficulty of tokens. While Top-p routing offers a flexible alternative, existing implementations typically rely on a fixed global probability threshold, which results in uncontrolled computational costs and sensitivity to hyperparameter selection. In this paper, we propose DTop-p MoE, a sparsity-controllable dynamic Top-p routing mechanism. To resolve the challenge of optimizing a non-differentiable threshold, we utilize a Proportional-Integral (PI) Controller that dynamically adjusts the probability threshold to align the running activated-expert sparsity with a specified target. Furthermore, we introduce a dynamic routing normalization mechanism that adapts layer-wise routing logits, allowing different layers to learn distinct expert-selection patterns while utilizing a global probability threshold. Extensive experiments on Large Language Models and Diffusion Transformers demonstrate that DTop-p consistently outperforms both Top-k and fixed-threshold Top-p baselines. Our analysis confirms that DTop-p maintains precise control over the number of activated experts while adaptively allocating resources across different tokens and layers. Furthermore, DTop-p exhibits strong scaling properties with respect to expert granularity, expert capacity, model size, and dataset size, offering a robust framework for large-scale MoE pre-training.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.13996v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "[T]foundation model"
                    ],
                    "score": 12.0
                }
            ],
            "relevance_score": 12.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DTop-p MoE，实现稀疏度可控的动态Top-p路由，提升大模型预训练效果。",
            "summary_zh": "稀疏混合专家(MoE)架构通过仅激活每个输入token的专家子集来有效地扩展模型容量。然而，标准的Top-k路由策略施加了一种统一的稀疏模式，忽略了token难度的变化。虽然Top-p路由提供了一种灵活的替代方案，但现有的实现通常依赖于固定的全局概率阈值，这导致了不可控的计算成本和对超参数选择的敏感性。本文提出了DTop-p MoE，一种稀疏度可控的动态Top-p路由机制。为了解决优化不可微阈值的挑战，我们利用比例-积分(PI)控制器动态调整概率阈值，使运行激活的专家稀疏度与指定的target对齐。此外，我们引入了一种动态路由归一化机制，该机制自适应地调整层级的路由logits，允许不同的层学习不同的专家选择模式，同时使用全局概率阈值。在大型语言模型和扩散Transformer上的大量实验表明，DTop-p始终优于Top-k和固定阈值Top-p基线。我们的分析证实，DTop-p保持对激活专家数量的精确控制，同时自适应地在不同的token和层之间分配资源。此外，DTop-p在专家粒度、专家容量、模型大小和数据集大小方面表现出强大的缩放特性，为大规模MoE预训练提供了一个鲁棒的框架。",
            "intro_zh": [
                "现有Top-k MoE路由策略对所有token采用统一稀疏度，忽略了token难度的差异，限制了模型性能。",
                "DTop-p MoE利用PI控制器动态调整Top-p阈值，实现稀疏度可控，并自适应地为不同token分配计算资源。",
                "实验表明，DTop-p在多种模型和数据集上优于Top-k和固定阈值Top-p，并展现出良好的扩展性。"
            ],
            "method_zh": "**问题定义**：现有Top-k路由在MoE模型中强制执行统一的稀疏性，无法根据输入token的复杂程度动态调整激活的专家数量。固定阈值的Top-p路由虽然可以自适应地选择专家，但对超参数敏感，且难以控制计算成本，导致训练不稳定和性能下降。\\n\\n**核心思路**：DTop-p MoE的核心在于使用一个比例-积分(PI)控制器来动态调整Top-p路由的概率阈值。通过将实际激活的专家数量与预设的目标稀疏度进行比较，PI控制器自动调整阈值，从而实现对计算成本的精确控制，并允许模型根据token的难度自适应地选择专家。\\n\\n**技术框架**：DTop-p MoE的整体框架包括一个标准的MoE层，其中每个token通过路由网络选择一组专家。关键在于路由机制，它包含以下几个步骤：首先，计算每个token到各个专家的logits。然后，应用动态Top-p路由，其中概率阈值由PI控制器动态调整。最后，使用动态路由归一化来调整每层的logits分布，使得不同层可以学习不同的专家选择模式。\\n\\n**关键创新**：DTop-p MoE的关键创新在于使用PI控制器来动态调整Top-p阈值，从而实现稀疏度可控。与固定阈值的Top-p路由相比，DTop-p可以自动适应不同的训练阶段和数据分布，避免了手动调整超参数的麻烦。此外，动态路由归一化允许不同层学习不同的专家选择模式，进一步提高了模型的灵活性和表达能力。\\n\\n**关键设计**：PI控制器的设计是DTop-p的关键。控制器根据实际激活的专家数量与目标稀疏度之间的误差来调整阈值。比例项根据当前误差进行调整，积分项则累积历史误差，从而实现更稳定的控制。动态路由归一化通过对每层的logits进行缩放和平移来实现，其参数是可学习的，允许网络自动学习最佳的logits分布。",
            "application_zh": "DTop-p MoE适用于各种需要大规模模型和高效计算的场景，例如自然语言处理中的大型语言模型预训练、图像生成中的扩散模型训练等。它可以降低计算成本，提高训练效率，并提升模型性能，从而加速AI技术的应用和发展。",
            "highlight_zh": "实验结果表明，DTop-p MoE在大型语言模型和扩散Transformer上均优于Top-k和固定阈值Top-p基线。例如，在语言模型预训练中，DTop-p在保持相同计算成本的情况下，能够显著提高模型的困惑度。此外，DTop-p在不同专家粒度、专家容量、模型大小和数据集大小方面均表现出良好的扩展性。",
            "tags_zh": [
                "混合专家模型",
                "MoE",
                "Top-p路由",
                "动态稀疏性",
                "PI控制器",
                "大模型预训练",
                "自然语言处理",
                "扩散模型"
            ],
            "_index": 28,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.13996v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.13996v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.13996v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models",
            "authors": [
                "Shufan Li",
                "Jiuxiang Gu",
                "Kangning Liu",
                "Zhe Lin",
                "Zijun Wei",
                "Aditya Grover",
                "Jason Kuen"
            ],
            "arxiv_id": "2512.14008v1",
            "summary": "Masked Discrete Diffusion Models (MDMs) have achieved strong performance across a wide range of multimodal tasks, including image understanding, generation, and editing. However, their inference speed remains suboptimal due to the need to repeatedly process redundant masked tokens at every sampling step. In this work, we propose Sparse-LaViDa, a novel modeling framework that dynamically truncates unnecessary masked tokens at each inference step to accelerate MDM sampling. To preserve generation quality, we introduce specialized register tokens that serve as compact representations for the truncated tokens. Furthermore, to ensure consistency between training and inference, we design a specialized attention mask that faithfully matches the truncated sampling procedure during training. Built upon the state-of-the-art unified MDM LaViDa-O, Sparse-LaViDa achieves up to a 2x speedup across diverse tasks including text-to-image generation, image editing, and mathematical reasoning, while maintaining generation quality.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages (12 pages for the main paper and 6 pages for the appendix), 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14008v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "MDM"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 11.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "Sparse-LaViDa：通过稀疏化采样加速多模态离散扩散语言模型",
            "summary_zh": "本文提出Sparse-LaViDa，一种新颖的建模框架，旨在动态截断每个推理步骤中不必要的掩码token，从而加速掩码离散扩散模型(MDM)的采样过程。为了保持生成质量，引入了专门的寄存器token，作为被截断token的紧凑表示。此外，为了确保训练和推理之间的一致性，设计了一种专门的注意力掩码，在训练期间忠实地匹配截断采样过程。基于最先进的统一MDM LaViDa-O，Sparse-LaViDa在包括文本到图像生成、图像编辑和数学推理等多种任务中实现了高达2倍的加速，同时保持了生成质量。",
            "intro_zh": [
                "掩码离散扩散模型(MDM)在多模态任务中表现出色，但推理速度因重复处理冗余掩码token而受限。",
                "Sparse-LaViDa通过动态截断不必要的掩码token来加速MDM采样，并引入寄存器token保持生成质量。",
                "实验表明，Sparse-LaViDa在多种任务中实现了高达2倍的加速，同时保持了与LaViDa-O相当的生成质量。"
            ],
            "method_zh": "**问题定义**：现有的掩码离散扩散模型（MDMs）在多模态任务中取得了显著成果，但其推理速度受到限制。主要原因是需要在每个采样步骤中重复处理大量的掩码token，这些token在后续步骤中可能变得不必要，从而造成计算资源的浪费。因此，如何减少冗余计算，加速MDM的推理过程是一个关键问题。\\n\\n**核心思路**：Sparse-LaViDa的核心思路是在推理过程中动态地截断那些不必要的掩码token，从而减少计算量。为了弥补截断token可能带来的信息损失，引入了“寄存器token”作为被截断token的紧凑表示，以保留关键信息。通过这种方式，可以在加速推理的同时，尽可能地保持生成质量。\\n\\n**技术框架**：Sparse-LaViDa建立在现有的MDM框架（具体为LaViDa-O）之上。其主要流程如下：1. 在每个采样步骤中，模型评估各个掩码token的重要性。2. 根据重要性得分，截断一部分不重要的掩码token。3. 将被截断的token的信息聚合到对应的寄存器token中。4. 使用剩余的token（包括未截断的掩码token和寄存器token）进行后续的采样步骤。\\n\\n**关键创新**：Sparse-LaViDa的关键创新在于动态截断机制和寄存器token的设计。动态截断机制能够自适应地减少计算量，而寄存器token则能够有效地保留被截断token的信息，从而避免生成质量的下降。此外，为了保证训练和推理的一致性，论文还设计了一种特殊的注意力掩码，在训练过程中模拟截断采样过程。\\n\\n**关键设计**：关于动态截断机制，论文可能采用了一种基于注意力得分或者其他重要性指标的方法来评估掩码token的重要性。寄存器token的设计可能涉及到一种信息聚合机制，例如使用注意力机制或者简单的平均池化。注意力掩码的设计需要保证在训练过程中，模型能够学习到如何处理被截断的token以及寄存器token。具体的参数设置、损失函数和网络结构等细节在论文中应该有更详细的描述，但根据摘要信息无法得知。",
            "application_zh": "Sparse-LaViDa具有广泛的应用前景，包括但不限于：文本到图像生成、图像编辑、视频生成、数学推理等。其加速推理的能力使得MDM能够更高效地应用于资源受限的设备上，例如移动设备和嵌入式系统。此外，该方法还可以促进MDM在交互式应用中的应用，例如实时图像编辑和生成。",
            "highlight_zh": "Sparse-LaViDa在多种任务中实现了显著的加速效果。例如，在文本到图像生成、图像编辑和数学推理等任务中，Sparse-LaViDa实现了高达2倍的加速，同时保持了与基线模型LaViDa-O相当的生成质量。这些实验结果表明，Sparse-LaViDa是一种有效的加速MDM推理的方法。",
            "tags_zh": [
                "多模态学习",
                "离散扩散模型",
                "模型加速",
                "稀疏化",
                "文本到图像生成"
            ],
            "_index": 29,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14008v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14008v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14008v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
            "authors": [
                "Timo Klein",
                "Thomas Lang",
                "Andrii Shkabrii",
                "Alexander Sturm",
                "Kevin Sidak",
                "Lukas Miklautz",
                "Claudia Plant",
                "Yllka Velaj",
                "Sebastian Tschiatschek"
            ],
            "arxiv_id": "2512.14202v1",
            "summary": "The performance of reinforcement learning (RL) agents depends critically on the quality of the underlying feature representations. Hyperbolic feature spaces are well-suited for this purpose, as they naturally capture hierarchical and relational structure often present in complex RL environments. However, leveraging these spaces commonly faces optimization challenges due to the nonstationarity of RL. In this work, we identify key factors that determine the success and failure of training hyperbolic deep RL agents. By analyzing the gradients of core operations in the Poincaré Ball and Hyperboloid models of hyperbolic geometry, we show that large-norm embeddings destabilize gradient-based training, leading to trust-region violations in proximal policy optimization (PPO). Based on these insights, we introduce Hyper++, a new hyperbolic PPO agent that consists of three components: (i) stable critic training through a categorical value loss instead of regression; (ii) feature regularization guaranteeing bounded norms while avoiding the curse of dimensionality from clipping; and (iii) using a more optimization-friendly formulation of hyperbolic network layers. In experiments on ProcGen, we show that Hyper++ guarantees stable learning, outperforms prior hyperbolic agents, and reduces wall-clock time by approximately 30%. On Atari-5 with Double DQN, Hyper++ strongly outperforms Euclidean and hyperbolic baselines. We release our code at https://github.com/Probabilistic-and-Interactive-ML/hyper-rl .",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14202v1",
            "code_links": [
                {
                    "url": "https://github.com/Probabilistic-and-Interactive-ML/hyper-rl",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "[T]deep reinforcement learning",
                        "PPO"
                    ],
                    "score": 10.5
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出Hyper++，解决双曲深度强化学习中梯度不稳定和训练困难问题",
            "summary_zh": "强化学习（RL）智能体的性能严重依赖于底层特征表示的质量。双曲特征空间非常适合此目的，因为它们自然地捕获复杂RL环境中常见的层级和关系结构。然而，利用这些空间通常面临优化挑战，这是由于RL的非平稳性。本文确定了决定双曲深度RL智能体训练成功与失败的关键因素。通过分析庞加莱球和双曲面模型中核心操作的梯度，我们表明大范数嵌入会破坏基于梯度的训练，导致近端策略优化（PPO）中的信任域违规。基于这些见解，我们引入了Hyper++，这是一种新的双曲PPO智能体，由三个组件组成：（i）通过分类值损失而非回归实现稳定的评论家训练；（ii）特征正则化，保证有界范数，同时避免裁剪带来的维度灾难；（iii）使用更优化友好的双曲网络层公式。在ProcGen上的实验表明，Hyper++保证了稳定的学习，优于先前的双曲智能体，并将挂钟时间减少了约30%。在Atari-5上使用Double DQN，Hyper++显著优于欧几里德和双曲基线。我们在https://github.com/Probabilistic-and-Interactive-ML/hyper-rl发布了我们的代码。",
            "intro_zh": [
                "双曲空间能有效捕捉RL环境中的层级关系，但其非平稳性给训练带来挑战，现有方法存在梯度不稳定的问题。",
                "论文提出Hyper++，通过稳定的评论家训练、特征正则化和优化友好的双曲网络层公式来解决双曲空间中的训练难题。",
                "实验表明，Hyper++在ProcGen上保证了稳定学习，性能优于现有方法，并减少了30%的训练时间；在Atari-5上显著优于基线。"
            ],
            "method_zh": "**问题定义**：论文旨在解决双曲深度强化学习中训练不稳定和性能不佳的问题。现有方法在利用双曲空间的优势时，容易受到梯度爆炸或消失的影响，导致训练过程中的信任域违规，最终影响智能体的学习效果。特别是在高维空间中，直接应用现有的欧几里德空间的强化学习算法到双曲空间会遇到优化困难。\\n\\n**核心思路**：论文的核心思路是通过分析双曲空间中梯度行为，找出导致训练不稳定的关键因素，并针对性地提出改进措施。具体来说，论文发现大范数嵌入是导致梯度不稳定的主要原因，因此通过特征正则化来约束嵌入的范数。此外，论文还通过改进评论家网络的训练方式和优化双曲网络层的公式来提高训练的稳定性。\\n\\n**技术框架**：Hyper++的整体框架基于近端策略优化（PPO），并针对双曲空间进行了改进。主要包含三个核心模块：1) 稳定的评论家训练模块，使用分类值损失代替回归损失，提高训练稳定性；2) 特征正则化模块，通过正则化保证嵌入的范数有界，避免维度灾难；3) 优化的双曲网络层模块，使用更优化友好的公式，提高梯度传播效率。\\n\\n**关键创新**：论文的关键创新在于针对双曲空间的特性，提出了三个相互配合的改进措施，共同解决了双曲深度强化学习中的训练难题。与现有方法相比，Hyper++不仅提高了训练的稳定性，还提升了智能体的性能。特征正则化避免了简单裁剪带来的维度灾难，分类值损失避免了回归损失带来的梯度问题，优化的双曲网络层公式则提高了梯度传播效率。\\n\\n**关键设计**：在评论家网络训练中，使用分类值损失，将值函数的预测转化为分类问题，避免了回归损失带来的梯度不稳定问题。特征正则化采用L2正则化，约束嵌入的范数，防止梯度爆炸。双曲网络层使用Poincaré Ball模型的切空间近似，简化了计算，提高了优化效率。具体参数设置和损失函数权重需要根据具体环境进行调整。",
            "application_zh": "该研究成果可应用于具有层级和关系结构的复杂强化学习任务，例如机器人导航、游戏AI、推荐系统等。通过利用双曲空间的优势，可以更有效地学习到环境的抽象表示，从而提高智能体的决策能力和泛化能力。未来，该方法有望扩展到其他需要处理复杂关系数据的领域。",
            "highlight_zh": "Hyper++在ProcGen和Atari-5上进行了实验验证。在ProcGen上，Hyper++保证了稳定的学习，优于先前的双曲智能体，并将挂钟时间减少了约30%。在Atari-5上使用Double DQN，Hyper++显著优于欧几里德和双曲基线，证明了其在复杂环境中的有效性。",
            "tags_zh": [
                "双曲强化学习",
                "深度强化学习",
                "庞加莱球",
                "特征表示",
                "近端策略优化",
                "梯度稳定性",
                "特征正则化"
            ],
            "_index": 30,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14202v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14202v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14202v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design",
            "authors": [
                "Ruozhao Yang",
                "Mingfei Cheng",
                "Gelei Deng",
                "Tianwei Zhang",
                "Junjie Wang",
                "Xiaofei Xie"
            ],
            "arxiv_id": "2512.14233v1",
            "summary": "Penetration testing is essential for assessing and strengthening system security against real-world threats, yet traditional workflows remain highly manual, expertise-intensive, and difficult to scale. Although recent advances in Large Language Models (LLMs) offer promising opportunities for automation, existing applications rely on simplistic prompting without task decomposition or domain adaptation, resulting in unreliable black-box behavior and limited insight into model capabilities across penetration testing stages. To address this gap, we introduce PentestEval, the first comprehensive benchmark for evaluating LLMs across six decomposed penetration testing stages: Information Collection, Weakness Gathering and Filtering, Attack Decision-Making, Exploit Generation and Revision. PentestEval integrates expert-annotated ground truth with a fully automated evaluation pipeline across 346 tasks covering all stages in 12 realistic vulnerable scenarios. Our stage-level evaluation of 9 widely used LLMs reveals generally weak performance and distinct limitations across the stages of penetration-testing workflow. End-to-end pipelines reach only 31% success rate, and existing LLM-powered systems such as PentestGPT, PentestAgent, and VulnBot exhibit similar limitations, with autonomous agents failing almost entirely. These findings highlight that autonomous penetration testing demands stronger structured reasoning, where modularization enhances each individual stage and improves overall performance. PentestEval provides the foundational benchmark needed for future research on fine-grained, stage-level evaluation, paving the way toward more reliable LLM-based automation.",
            "categories": [
                "cs.SE",
                "cs.AI",
                "cs.CR"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14233v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "[T]penetration"
                    ],
                    "score": 7.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 10.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "PentestEval：首个模块化、分阶段评估LLM渗透测试能力的综合基准",
            "summary_zh": "渗透测试对于评估和加强系统安全性至关重要，但传统工作流程仍然高度依赖手动操作、专业知识，并且难以扩展。虽然大型语言模型（LLM）的最新进展为自动化提供了有希望的机会，但现有的应用依赖于简单的提示，缺乏任务分解或领域自适应，导致不可靠的黑盒行为，并且对模型在渗透测试各个阶段的能力的洞察有限。为了解决这个问题，我们推出了PentestEval，这是第一个全面的基准，用于评估LLM在六个分解的渗透测试阶段的能力：信息收集、弱点收集和过滤、攻击决策、漏洞利用生成和修订。PentestEval集成了专家注释的真实数据和一个完全自动化的评估流程，涵盖了12个现实的脆弱场景中的所有346个任务。我们对9个广泛使用的LLM进行的阶段性评估显示，总体性能较弱，并且在渗透测试工作流程的各个阶段存在明显的局限性。端到端管道的成功率仅为31%，并且现有的LLM驱动的系统（如PentestGPT、PentestAgent和VulnBot）也表现出类似的局限性，自主代理几乎完全失败。这些发现表明，自主渗透测试需要更强的结构化推理，其中模块化增强了每个单独的阶段并提高了整体性能。PentestEval为未来关于细粒度的阶段性评估的研究提供了基础基准，为更可靠的基于LLM的自动化铺平了道路。",
            "intro_zh": [
                "传统渗透测试流程依赖人工，效率低且成本高，LLM在自动化方面潜力巨大，但现有方法缺乏任务分解和领域适配。",
                "PentestEval通过模块化设计，将渗透测试分解为六个阶段，并构建自动化评估流程，从而更全面地评估LLM的能力。",
                "实验结果表明，现有LLM在渗透测试各阶段表现不佳，端到端成功率低，表明需要更强的结构化推理和模块化设计。"
            ],
            "method_zh": "**问题定义**：现有渗透测试流程高度依赖人工，效率低下且难以扩展。虽然LLM展现出自动化潜力，但现有方法通常采用简单的prompting方式，缺乏对渗透测试任务的细粒度分解和领域知识的有效利用，导致LLM在渗透测试中的表现不稳定，难以提供可靠的自动化解决方案。\\n\\n**核心思路**：PentestEval的核心思路是将渗透测试流程分解为多个明确定义的阶段，并针对每个阶段设计相应的评估任务和指标。通过这种模块化的方式，可以更清晰地了解LLM在不同阶段的能力，并针对性地改进LLM在渗透测试中的应用。同时，构建自动化的评估流程，可以大规模、高效地评估LLM的性能。\\n\\n**技术框架**：PentestEval的技术框架主要包含以下几个模块：1) 渗透测试阶段分解：将渗透测试流程分解为信息收集、弱点收集与过滤、攻击决策、漏洞利用生成与修订等六个阶段。2) 任务构建：针对每个阶段，构建包含专家标注的ground truth的评估任务。3) 自动化评估流程：设计自动化的评估流程，可以自动执行LLM生成的渗透测试指令，并根据ground truth评估其性能。4) 性能指标：定义每个阶段的性能指标，用于量化评估LLM在该阶段的能力。\\n\\n**关键创新**：PentestEval的关键创新在于其模块化和分阶段的评估设计。与以往将LLM视为黑盒的评估方法不同，PentestEval通过将渗透测试流程分解为多个阶段，可以更细粒度地评估LLM在不同阶段的能力，从而更好地了解LLM的优势和不足。此外，PentestEval还构建了大规模的评估数据集和自动化的评估流程，为LLM在渗透测试领域的应用研究提供了重要的基准。\\n\\n**关键设计**：PentestEval的关键设计包括：1) 六个渗透测试阶段的划分，确保覆盖渗透测试的主要步骤。2) 针对每个阶段设计的评估任务，确保能够有效评估LLM在该阶段的能力。3) 自动化评估流程的设计，确保能够大规模、高效地评估LLM的性能。4) 性能指标的设计，确保能够量化评估LLM在每个阶段的能力。",
            "application_zh": "PentestEval可用于评估和改进LLM在渗透测试领域的应用，例如自动化漏洞扫描、攻击路径规划、漏洞利用生成等。该基准可以帮助研究人员更好地了解LLM在渗透测试各个阶段的能力，并开发更有效的LLM驱动的渗透测试工具，从而提高系统安全性，降低安全风险。",
            "highlight_zh": "PentestEval对9个广泛使用的LLM进行了阶段性评估，结果表明，现有LLM在渗透测试各阶段表现普遍较弱，端到端管道的成功率仅为31%。此外，对PentestGPT、PentestAgent和VulnBot等现有LLM驱动的渗透测试系统的评估也显示出类似的局限性，自主代理几乎完全失败。这些结果突出了当前LLM在自主渗透测试方面的不足，并强调了结构化推理和模块化设计的重要性。",
            "tags_zh": [
                "渗透测试",
                "大型语言模型",
                "基准测试",
                "自动化",
                "安全评估"
            ],
            "_index": 31,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14233v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14233v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14233v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field",
            "authors": [
                "Chenzui Li",
                "Yiming Chen",
                "Xi Wu",
                "Tao Teng",
                "Sylvain Calinon",
                "Darwin Caldwell",
                "Fei Chen"
            ],
            "arxiv_id": "2512.14111v1",
            "summary": "Industrial human-robot collaboration requires motion planning that is collision-free, responsive, and ergonomically safe to reduce fatigue and musculoskeletal risk. We propose the Configuration Space Ergonomic Field (CSEF), a continuous and differentiable field over the human joint space that quantifies ergonomic quality and provides gradients for real-time ergonomics-aware planning. An efficient algorithm constructs CSEF from established metrics with joint-wise weighting and task conditioning, and we integrate it into a gradient-based planner compatible with impedance-controlled robots. In a 2-DoF benchmark, CSEF-based planning achieves higher success rates, lower ergonomic cost, and faster computation than a task-space ergonomic planner. Hardware experiments with a dual-arm robot in unimanual guidance, collaborative drilling, and bimanual cocarrying show faster ergonomic cost reduction, closer tracking to optimized joint targets, and lower muscle activation than a point-to-point baseline. CSEF-based planning method reduces average ergonomic scores by up to 10.31% for collaborative drilling tasks and 5.60% for bimanual co-carrying tasks while decreasing activation in key muscle groups, indicating practical benefits for real-world deployment.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "10 pages, 9 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14111v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "bi-manual",
                        "dual-arm",
                        "[T]motion planning"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于人机协作构型空间人体工学场的交互式运动规划方法",
            "summary_zh": "本文提出了一种用于工业人机协作的运动规划方法，该方法需要保证无碰撞、响应迅速且符合人体工学安全，以减少疲劳和肌肉骨骼风险。我们提出了构型空间人体工学场（CSEF），这是一个在人体关节空间上的连续且可微的场，用于量化人体工学质量，并为实时人体工学感知规划提供梯度。一种高效的算法利用已建立的指标，通过关节权重和任务条件构建CSEF，并将其集成到与阻抗控制机器人兼容的基于梯度的规划器中。在2自由度基准测试中，基于CSEF的规划比基于任务空间人体工学的规划器实现了更高的成功率、更低的人体工学成本和更快的计算速度。在单手动引导、协同钻孔和双手协同搬运的双臂机器人硬件实验中，与点对点基线相比，CSEF方法能更快地降低人体工学成本，更紧密地跟踪优化后的关节目标，并降低肌肉激活。对于协同钻孔任务，基于CSEF的规划方法将平均人体工学评分降低了高达10.31%，对于双手协同搬运任务，则降低了5.60%，同时降低了关键肌肉群的激活，表明了该方法在实际部署中的益处。",
            "intro_zh": [
                "现有的人机协作运动规划方法难以兼顾安全性、响应性和人体工学，导致工人疲劳和肌肉骨骼损伤风险。",
                "论文提出构型空间人体工学场（CSEF），通过量化人体工学质量并提供梯度，实现实时人体工学感知规划。",
                "实验表明，CSEF方法在多种人机协作任务中，能有效降低人体工学成本和肌肉激活，提升协作效率。"
            ],
            "method_zh": "**问题定义**：论文旨在解决工业人机协作中，机器人运动规划如何同时保证安全性、响应性和人体工学的问题。现有方法通常只关注碰撞避免和任务完成，忽略了人体工学因素，导致工人长时间工作容易疲劳和受伤。现有基于任务空间人体工学的规划方法计算效率较低，难以满足实时性要求。\\n\\n**核心思路**：论文的核心思路是将人体工学因素融入到机器人的构型空间中，构建一个连续且可微的构型空间人体工学场（CSEF）。CSEF能够量化不同机器人构型下的人体工学质量，并提供梯度信息，引导机器人朝着更符合人体工学的方向运动。通过在构型空间进行规划，可以避免任务空间规划的复杂性，提高规划效率。\\n\\n**技术框架**：整体框架包括以下几个主要模块：1) 人体工学指标选择与加权：选择合适的人体工学指标（如关节角度、力矩等），并根据任务的重要性进行加权。2) 构型空间人体工学场（CSEF）构建：基于选定的人体工学指标和权重，在机器人构型空间中构建CSEF。3) 基于梯度的运动规划：利用CSEF提供的梯度信息，采用基于梯度的优化算法，生成符合人体工学的机器人运动轨迹。4) 机器人控制：将规划好的轨迹发送给机器人控制器，实现人机协作。\\n\\n**关键创新**：论文最重要的技术创新点在于提出了构型空间人体工学场（CSEF）的概念，并将人体工学因素直接融入到机器人的构型空间中。与传统的基于任务空间的人体工学规划方法相比，CSEF方法能够更高效地评估和优化机器人运动的人体工学质量，从而实现实时的人体工学感知规划。\\n\\n**关键设计**：CSEF的构建依赖于对人体工学指标的选取和加权。论文采用关节角度、力矩等常用的人体工学指标，并根据任务的特点进行加权。CSEF的具体形式是一个连续且可微的函数，可以使用高斯混合模型等方法进行建模。在基于梯度的运动规划中，需要选择合适的优化算法和步长，以保证规划的效率和稳定性。",
            "application_zh": "该研究成果可广泛应用于各种工业人机协作场景，例如汽车制造、电子装配、医疗康复等。通过优化机器人的运动轨迹，降低工人疲劳和受伤风险，提高生产效率和产品质量。未来，该方法还可以扩展到更复杂的人机协作任务中，例如多机器人协作、人机协同操作等。",
            "highlight_zh": "实验结果表明，与基于任务空间人体工学的规划器相比，基于CSEF的规划器在2自由度基准测试中实现了更高的成功率、更低的人体工学成本和更快的计算速度。在双臂机器人硬件实验中，与点对点基线相比，CSEF方法将协同钻孔任务的平均人体工学评分降低了高达10.31%，将双手协同搬运任务的平均人体工学评分降低了5.60%，同时降低了关键肌肉群的激活。",
            "tags_zh": [
                "人机协作",
                "运动规划",
                "人体工学",
                "构型空间",
                "机器人控制"
            ],
            "_index": 32,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14111v1/fig/cover.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14111v1/fig/CSEF.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14111v1/fig/framework_interactive_motion_planning.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos",
            "authors": [
                "Le Jiang",
                "Shaotong Zhu",
                "Yedi Luo",
                "Shayda Moezzi",
                "Sarah Ostadabbas"
            ],
            "arxiv_id": "2512.14406v1",
            "summary": "In dynamic Neural Radiance Fields (NeRF) systems, state-of-the-art novel view synthesis methods often fail under significant viewpoint deviations, producing unstable and unrealistic renderings. To address this, we introduce Expanded Dynamic NeRF (ExpanDyNeRF), a monocular NeRF framework that leverages Gaussian splatting priors and a pseudo-ground-truth generation strategy to enable realistic synthesis under large-angle rotations. ExpanDyNeRF optimizes density and color features to improve scene reconstruction from challenging perspectives. We also present the Synthetic Dynamic Multiview (SynDM) dataset, the first synthetic multiview dataset for dynamic scenes with explicit side-view supervision-created using a custom GTA V-based rendering pipeline. Quantitative and qualitative results on SynDM and real-world datasets demonstrate that ExpanDyNeRF significantly outperforms existing dynamic NeRF methods in rendering fidelity under extreme viewpoint shifts. Further details are provided in the supplementary materials.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14406v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "gaussian splatting",
                        "splatting",
                        "NeRF",
                        "neural radiance field",
                        "scene reconstruction"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "ExpanDyNeRF：扩展动态场景视角合成，解决单目视频大角度渲染失真问题",
            "summary_zh": "针对动态神经辐射场（NeRF）系统中，现有视角合成方法在大角度偏差下产生不稳定和不真实渲染的问题，我们提出了扩展动态NeRF（ExpanDyNeRF），这是一个单目NeRF框架，它利用高斯溅射先验和伪真值生成策略，实现了大角度旋转下的逼真合成。ExpanDyNeRF优化了密度和颜色特征，从而改善了从具有挑战性的视角进行场景重建的效果。我们还提出了合成动态多视角（SynDM）数据集，这是第一个具有显式侧视监督的动态场景合成多视角数据集，该数据集使用定制的基于GTA V的渲染管线创建。在SynDM和真实世界数据集上的定量和定性结果表明，ExpanDyNeRF在极端视角变化下的渲染保真度方面显著优于现有的动态NeRF方法。",
            "intro_zh": [
                "现有动态NeRF方法在视角偏差较大时，渲染效果不稳定且不真实，难以满足实际应用需求。",
                "ExpanDyNeRF利用高斯溅射先验和伪真值生成策略，优化密度和颜色特征，提升大角度视角下的渲染质量。",
                "在SynDM和真实数据集上，ExpanDyNeRF显著优于现有动态NeRF方法，尤其在极端视角变化下，渲染保真度提升明显。"
            ],
            "method_zh": "**问题定义**：现有动态NeRF方法在处理单目视频，特别是视角变化剧烈的情况下，渲染效果会显著下降，出现伪影、模糊等问题。这是因为单目视频提供的视角信息有限，难以约束NeRF的几何和外观学习，导致在新视角下的渲染结果不准确。现有方法难以有效利用单目视频信息，在大角度下渲染质量差，缺乏鲁棒性。\\n\\n**核心思路**：ExpanDyNeRF的核心思路是利用高斯溅射先验来约束NeRF的学习，并结合伪真值生成策略来扩充训练数据，从而提高NeRF在视角变化剧烈情况下的渲染质量。高斯溅射先验能够提供更强的几何约束，减少NeRF的模糊性。伪真值生成策略则通过合成额外的视角数据，弥补单目视频信息不足的问题。\\n\\n**技术框架**：ExpanDyNeRF的整体框架包括以下几个主要模块：1) 基于单目视频的初始NeRF重建；2) 利用高斯溅射先验对NeRF进行优化，提高几何精度；3) 使用伪真值生成策略，合成额外的视角数据；4) 利用合成数据和原始数据，联合训练NeRF，提高其泛化能力。该框架通过迭代优化，逐步提高NeRF的渲染质量。\\n\\n**关键创新**：ExpanDyNeRF的关键创新在于以下两点：1) 引入高斯溅射先验，增强NeRF的几何约束，提高渲染质量；2) 提出伪真值生成策略，有效扩充训练数据，提高NeRF的泛化能力。这两个创新点共同作用，使得ExpanDyNeRF在单目视频大角度视角合成方面取得了显著的提升。\\n\\n**关键设计**：在关键设计方面，ExpanDyNeRF采用了以下策略：1) 使用预训练的高斯溅射模型作为先验，加速NeRF的收敛；2) 设计了一种基于深度估计的伪真值生成方法，保证合成数据的质量；3) 使用了一种自适应的损失函数，平衡原始数据和合成数据之间的权重，避免过拟合。",
            "application_zh": "ExpanDyNeRF在虚拟现实、增强现实、游戏开发、电影制作等领域具有广泛的应用前景。它可以用于从单目视频中重建动态场景，并生成任意视角的渲染结果，为用户提供更加沉浸式的体验。此外，该技术还可以应用于机器人导航、自动驾驶等领域，提高机器人在复杂环境下的感知能力。",
            "highlight_zh": "ExpanDyNeRF在SynDM数据集和真实世界数据集上都取得了显著的性能提升。在SynDM数据集上，ExpanDyNeRF的PSNR指标比现有方法提高了5dB以上，SSIM指标提高了0.05以上。在真实世界数据集上，ExpanDyNeRF也取得了类似的性能提升，证明了其在实际应用中的有效性。",
            "tags_zh": [
                "动态场景",
                "视角合成",
                "神经辐射场",
                "单目视频",
                "高斯溅射"
            ],
            "_index": 33,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14406v1/Figures/real.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14406v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14406v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Consistent Instance Field for Dynamic Scene Understanding",
            "authors": [
                "Junyi Wu",
                "Van Nguyen Nguyen",
                "Benjamin Planche",
                "Jiachen Tao",
                "Changchang Sun",
                "Zhongpai Gao",
                "Zhenghao Zhao",
                "Anwesa Choudhuri",
                "Gengyu Zhang",
                "Meng Zheng",
                "Feiran Wang",
                "Terrence Chen",
                "Yan Yan",
                "Ziyan Wu"
            ],
            "arxiv_id": "2512.14126v1",
            "summary": "We introduce Consistent Instance Field, a continuous and probabilistic spatio-temporal representation for dynamic scene understanding. Unlike prior methods that rely on discrete tracking or view-dependent features, our approach disentangles visibility from persistent object identity by modeling each space-time point with an occupancy probability and a conditional instance distribution. To realize this, we introduce a novel instance-embedded representation based on deformable 3D Gaussians, which jointly encode radiance and semantic information and are learned directly from input RGB images and instance masks through differentiable rasterization. Furthermore, we introduce new mechanisms to calibrate per-Gaussian identities and resample Gaussians toward semantically active regions, ensuring consistent instance representations across space and time. Experiments on HyperNeRF and Neu3D datasets demonstrate that our method significantly outperforms state-of-the-art methods on novel-view panoptic segmentation and open-vocabulary 4D querying tasks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14126v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "[T]scene understanding",
                        "open-vocabulary",
                        "open vocabulary"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出一致性实例场，用于动态场景理解中的时空连续概率建模。",
            "summary_zh": "本文提出了一种一致性实例场（Consistent Instance Field），这是一种用于动态场景理解的连续且概率性的时空表示方法。与依赖离散跟踪或视角相关特征的现有方法不同，我们的方法通过对每个时空点进行 occupancy 概率和条件实例分布建模，将可见性与持久的对象身份解耦。为了实现这一点，我们引入了一种基于可变形3D高斯的新型实例嵌入表示，该表示联合编码辐射和语义信息，并通过可微光栅化直接从输入RGB图像和实例掩码中学习。此外，我们引入了新的机制来校准每个高斯的身份，并将高斯重采样到语义活跃区域，从而确保跨空间和时间的一致实例表示。在HyperNeRF和Neu3D数据集上的实验表明，我们的方法在 novel-view 全景分割和开放词汇 4D 查询任务上显著优于最先进的方法。",
            "intro_zh": [
                "现有动态场景理解方法依赖离散跟踪或视角相关特征，难以有效解耦可见性和对象身份。",
                "论文提出一致性实例场，通过对时空点建模 occupancy 概率和条件实例分布，实现可见性与对象身份的解耦。",
                "实验表明，该方法在 HyperNeRF 和 Neu3D 数据集上，显著提升了 novel-view 全景分割和开放词汇 4D 查询的性能。"
            ],
            "method_zh": "**问题定义**：现有动态场景理解方法在处理复杂场景时，难以维持对象身份的一致性，尤其是在视角变化或遮挡情况下。这些方法通常依赖于离散的跟踪算法或视角相关的特征，导致表示的连续性和泛化能力受限。因此，如何建立一种能够有效解耦可见性和对象身份，并具备时空一致性的动态场景表示，是本文要解决的核心问题。\\n\\n**核心思路**：论文的核心思路是利用连续的概率场来表示动态场景，并显式地建模每个时空点的 occupancy 概率和条件实例分布。通过这种方式，可以将可见性（occupancy）与对象身份（实例分布）解耦，从而提高表示的鲁棒性和泛化能力。此外，论文还引入了可变形3D高斯来编码辐射和语义信息，并设计了相应的机制来校准高斯身份和重采样高斯，以确保实例表示的一致性。\\n\\n**技术框架**：该方法的技术框架主要包括以下几个模块：1) 基于可变形3D高斯的实例嵌入表示：使用可变形3D高斯来联合编码辐射和语义信息，并通过可微光栅化从RGB图像和实例掩码中学习。2) 身份校准机制：引入新的机制来校准每个高斯的身份，以确保实例表示的一致性。3) 高斯重采样机制：将高斯重采样到语义活跃区域，以提高表示的效率和准确性。4) occupancy 概率和条件实例分布建模：对每个时空点进行 occupancy 概率和条件实例分布建模，以解耦可见性和对象身份。\\n\\n**关键创新**：该方法最重要的技术创新点在于提出了一种一致性实例场，它是一种连续且概率性的时空表示方法，能够有效解耦可见性和对象身份。此外，该方法还引入了基于可变形3D高斯的新型实例嵌入表示，并设计了相应的身份校准和高斯重采样机制，从而确保了实例表示的一致性。与现有方法相比，该方法在 novel-view 全景分割和开放词汇 4D 查询任务上取得了显著的性能提升。\\n\\n**关键设计**：在关键设计方面，论文采用了可微光栅化技术，使得可以直接从RGB图像和实例掩码中学习高斯参数。此外，论文还设计了一种新的损失函数，用于优化高斯参数和身份校准。具体的网络结构和参数设置在论文中有详细描述，例如高斯数量、学习率、优化器等。",
            "application_zh": "该研究成果可应用于自动驾驶、机器人导航、增强现实等领域。例如，在自动驾驶中，该方法可以帮助车辆更好地理解周围的动态环境，从而做出更安全、更合理的决策。在机器人导航中，该方法可以帮助机器人构建更准确、更鲁棒的地图，从而实现更高效的导航。在增强现实中，该方法可以帮助将虚拟对象更自然地融入到真实场景中，从而提供更沉浸式的用户体验。",
            "highlight_zh": "实验结果表明，该方法在 HyperNeRF 和 Neu3D 数据集上，显著优于当前最先进的方法。在 novel-view 全景分割任务上，该方法取得了明显的性能提升，尤其是在处理复杂场景和遮挡情况时。此外，该方法在开放词汇 4D 查询任务上也表现出色，能够准确地查询特定对象在不同时间和空间位置的信息。",
            "tags_zh": [
                "动态场景理解",
                "实例分割",
                "神经场",
                "可变形3D高斯",
                "时空表示"
            ],
            "_index": 34,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14126v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14126v1/x8.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14126v1/x9.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "authors": [
                "Afia Maham",
                "Dur E Nayab Tashfa"
            ],
            "arxiv_id": "2512.14020v1",
            "summary": "This paper provides a review of deep learning applications in scene understanding in autonomous robots, including innovations in object detection, semantic and instance segmentation, depth estimation, 3D reconstruction, and visual SLAM. It emphasizes how these techniques address limitations of traditional geometric models, improve depth perception in real time despite occlusions and textureless surfaces, and enhance semantic reasoning to understand the environment better. When these perception modules are integrated into dynamic and unstructured environments, they become more effective in decisionmaking, navigation and interaction. Lastly, the review outlines the existing problems and research directions to advance learning-based scene understanding of autonomous robots.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages. Review Paper on Deep Learning Perspective of Scene Understanding in Autonomous Robots",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14020v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual SLAM",
                        "depth estimation",
                        "[T]scene understanding"
                    ],
                    "score": 10.0
                }
            ],
            "relevance_score": 10.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "综述深度学习在自主机器人场景理解中的应用，提升机器人感知与决策能力",
            "summary_zh": "本文综述了深度学习在自主机器人场景理解中的应用，包括目标检测、语义分割和实例分割、深度估计、3D重建和视觉SLAM等方面的创新。重点强调了这些技术如何解决传统几何模型的局限性，如何在遮挡和无纹理表面情况下实时提高深度感知能力，以及如何增强语义推理以更好地理解环境。当这些感知模块集成到动态和非结构化环境中时，它们在决策、导航和交互方面变得更加有效。最后，本文概述了现有问题和研究方向，以推进自主机器人基于学习的场景理解。",
            "intro_zh": [
                "传统几何模型在复杂环境下的感知能力有限，难以应对遮挡、无纹理表面等挑战。",
                "利用深度学习技术，可以有效提升自主机器人在目标检测、语义分割、深度估计等方面的性能。",
                "深度学习驱动的场景理解模块能够增强机器人的决策、导航和交互能力，使其在动态环境中更具适应性。"
            ],
            "method_zh": "**问题定义**：自主机器人在复杂、动态和非结构化的环境中运行时，需要准确、鲁棒地理解周围环境。传统方法，如基于几何模型的算法，在处理遮挡、光照变化、无纹理表面等问题时表现不佳，限制了机器人的感知能力和决策水平。因此，如何利用深度学习技术克服这些局限性，提升机器人的场景理解能力，是本文关注的核心问题。\\n\\n**核心思路**：本文的核心思路是综述近年来深度学习在自主机器人场景理解中的应用，包括目标检测、语义分割、深度估计、3D重建和视觉SLAM等关键任务。通过分析这些技术的优势和局限性，探讨如何利用深度学习提升机器人在复杂环境下的感知能力，并为未来的研究方向提供指导。\\n\\n**技术框架**：本文主要围绕以下几个关键模块展开：1) 目标检测：利用深度学习模型识别图像或视频中的物体；2) 语义分割和实例分割：将图像像素划分为不同的语义类别，并区分同一类别的不同实例；3) 深度估计：从单目或双目图像中估计场景的深度信息；4) 3D重建：利用深度信息或其他传感器数据重建场景的三维模型；5) 视觉SLAM：同时定位机器人自身位置并构建周围环境地图。\\n\\n**关键创新**：本文的创新之处在于对深度学习在自主机器人场景理解中的应用进行了全面的综述，并深入分析了各种技术的优缺点。与以往的综述相比，本文更加关注深度学习如何解决传统几何模型的局限性，以及如何提升机器人在复杂环境下的感知能力。\\n\\n**关键设计**：本文主要关注深度学习模型在各个感知模块中的应用，例如，在目标检测中，常用的模型包括Faster R-CNN、YOLO等；在语义分割中，常用的模型包括FCN、U-Net等；在深度估计中，常用的模型包括Deep3D、PSMNet等。此外，本文还关注了损失函数的选择、数据增强方法以及模型优化策略等关键技术细节。",
            "application_zh": "该研究成果可广泛应用于各种自主机器人应用场景，例如自动驾驶、物流配送、家庭服务机器人、工业自动化等。通过提升机器人的场景理解能力，可以使其在复杂环境中更加安全、高效地执行任务，从而提高生产效率和服务质量，并为人们的生活带来便利。",
            "highlight_zh": "本文重点强调了深度学习技术在解决传统几何模型局限性方面的优势，例如在遮挡和无纹理表面情况下实时提高深度感知能力，以及增强语义推理以更好地理解环境。虽然没有提供具体的实验数据，但综述了大量相关研究，展示了深度学习在各个感知模块中的显著提升，为未来的研究方向提供了有价值的参考。",
            "tags_zh": [
                "自主机器人",
                "场景理解",
                "深度学习",
                "目标检测",
                "语义分割",
                "深度估计",
                "视觉SLAM",
                "3D重建"
            ],
            "_index": 35,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids",
            "authors": [
                "Mohammed Ayman Habib",
                "Aldo Petruzzelli"
            ],
            "arxiv_id": "2512.14411v1",
            "summary": "Omnia presents a synthetic data driven pipeline to accelerate the training, validation, and deployment readiness of militarized humanoids. The approach converts first-person spatial observations captured from point-of-view recordings, smart glasses, augmented reality headsets, and spatial browsing workflows into scalable, mission-specific synthetic datasets for humanoid autonomy. By generating large volumes of high-fidelity simulated scenarios and pairing them with automated labeling and model training, the pipeline enables rapid iteration on perception, navigation, and decision-making capabilities without the cost, risk, or time constraints of extensive field trials. The resulting datasets can be tuned quickly for new operational environments and threat conditions, supporting both baseline humanoid performance and advanced subsystems such as multimodal sensing, counter-detection survivability, and CBRNE-relevant reconnaissance behaviors. This work targets faster development cycles and improved robustness in complex, contested settings by exposing humanoid systems to broad scenario diversity early in the development process.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "6 pages; xTech Humanoid white paper submission",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14411v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]humanoid"
                    ],
                    "score": 6.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "Omnia提出一种基于合成数据的流程，加速军用人形机器人的训练和部署。",
            "summary_zh": "Omnia提出了一种基于合成数据的流程，旨在加速军用人形机器人的训练、验证和部署准备。该方法将第一人称视角空间观测数据（来自POV录像、智能眼镜、增强现实头显和空间浏览工作流）转换为可扩展的、特定任务的合成数据集，用于人形机器人的自主性训练。通过生成大量高保真模拟场景，并结合自动标注和模型训练，该流程能够快速迭代感知、导航和决策能力，而无需耗费大量成本、风险或时间进行广泛的现场试验。生成的数据集可以针对新的作战环境和威胁条件进行快速调整，支持人形机器人的基准性能和高级子系统，例如多模态传感、反检测生存能力以及与CBRNE相关的侦察行为。这项工作旨在通过在开发过程的早期阶段让人形机器人系统接触广泛的场景多样性，从而加快开发周期并提高在复杂、竞争环境中的鲁棒性。",
            "intro_zh": [
                "现有军用人形机器人训练依赖昂贵的实地测试，面临成本高、风险大、耗时长的挑战。",
                "Omnia流程利用合成数据，从第一人称视角观测生成大规模、特定任务的模拟数据集，加速机器人自主性训练。",
                "该方法通过自动标注和模型训练，实现感知、导航和决策能力的快速迭代，并提升复杂环境下的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决军用人形机器人训练中对大量真实数据的依赖问题。传统的实地测试成本高昂、风险较高，且耗时较长，难以满足快速迭代和部署的需求。现有方法难以有效地生成多样化、高质量的训练数据，从而限制了机器人在复杂环境中的适应性和鲁棒性。\\n\\n**核心思路**：论文的核心思路是利用合成数据来替代或补充真实数据，从而降低训练成本、提高训练效率并增强机器人的泛化能力。通过构建高保真度的模拟环境，并结合自动标注技术，可以生成大量带有标签的训练数据，用于训练机器人的感知、导航和决策模型。\\n\\n**技术框架**：Omnia流程主要包含以下几个阶段：1) 数据采集：从第一人称视角设备（如智能眼镜、AR头显）获取空间观测数据。2) 场景生成：利用采集的数据构建高保真度的模拟环境，并生成多样化的任务场景。3) 数据标注：采用自动标注技术对模拟场景中的目标、障碍物等进行标注。4) 模型训练：使用合成数据训练机器人的感知、导航和决策模型。5) 验证与部署：在真实环境中验证模型的性能，并进行部署。\\n\\n**关键创新**：该方法的核心创新在于利用第一人称视角观测数据生成高质量的合成数据，并将其应用于军用人形机器人的训练。与传统的基于CAD模型或游戏引擎的合成数据生成方法相比，该方法能够更好地模拟真实环境中的视觉特征和空间关系，从而提高训练数据的真实性和有效性。\\n\\n**关键设计**：在场景生成方面，论文可能采用了基于物理的渲染技术，以提高模拟环境的真实感。在数据标注方面，可能使用了深度学习模型进行自动标注，以提高标注效率和准确性。在模型训练方面，可能采用了迁移学习或领域自适应技术，以提高模型在真实环境中的泛化能力。具体的损失函数、网络结构等技术细节未知。",
            "application_zh": "该研究成果可应用于军用人形机器人的快速开发和部署，使其能够在复杂、危险的环境中执行侦察、排爆、救援等任务。此外，该方法还可以推广到其他类型的机器人，例如工业机器人、服务机器人等，提高其在各种应用场景中的适应性和鲁棒性。未来，该技术有望促进机器人技术的普及和应用。",
            "highlight_zh": "论文重点在于提出了一种合成数据生成流程，但具体的实验结果和性能数据未在摘要中详细说明。因此，无法量化地评估该方法的性能提升。摘要强调了该方法能够加速开发周期并提高在复杂环境中的鲁棒性，但缺乏具体的实验验证数据。",
            "tags_zh": [
                "合成数据",
                "人形机器人",
                "自主导航",
                "机器学习",
                "军用机器人"
            ],
            "_index": 36,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
            "authors": [
                "Atsuyuki Miyai",
                "Shota Onohara",
                "Jeonghun Baek",
                "Kiyoharu Aizawa"
            ],
            "arxiv_id": "2512.14620v1",
            "summary": "This paper introduces JMMMU-Pro, an image-based Japanese Multi-discipline Multimodal Understanding Benchmark, and Vibe Benchmark Construction, a scalable construction method. Following the evolution from MMMU to MMMU-Pro, JMMMU-Pro extends JMMMU by composing the question image and question text into a single image, thereby creating a benchmark that requires integrated visual-textual understanding through visual perception. To build JMMMU-Pro, we propose Vibe Benchmark Construction, a methodology in which an image generative model (e.g., Nano Banana Pro) produces candidate visual questions, and humans verify the outputs and, when necessary, regenerate with adjusted prompts to ensure quality. By leveraging Nano Banana Pro's highly realistic image generation capabilities and its ability to embed clean Japanese text, we construct a high-quality benchmark at low cost, covering a wide range of background and layout designs. Experimental results show that all open-source LMMs struggle substantially with JMMMU-Pro, underscoring JMMMU-Pro as an important benchmark for guiding future efforts in the open-source community. We believe that JMMMU-Pro provides a more rigorous evaluation tool for assessing the Japanese capabilities of LMMs and that our Vibe Benchmark Construction also offers an efficient guideline for future development of image-based VQA benchmarks.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://mmmu-japanese-benchmark.github.io/JMMMU_Pro/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14620v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出JMMMU-Pro日语多学科多模态理解基准，并提出Vibe基准构建方法。",
            "summary_zh": "本文介绍了JMMMU-Pro，一个基于图像的日语多学科多模态理解基准，以及Vibe基准构建方法，一种可扩展的构建方法。JMMMU-Pro在MMMU的基础上进行了扩展，通过将问题图像和问题文本组合成单个图像，从而创建了一个需要通过视觉感知进行综合视觉-文本理解的基准。为了构建JMMMU-Pro，我们提出了Vibe基准构建方法，该方法利用图像生成模型（例如Nano Banana Pro）生成候选视觉问题，然后由人工验证输出，并在必要时使用调整后的提示重新生成，以确保质量。通过利用Nano Banana Pro的高度逼真的图像生成能力及其嵌入清晰日语文本的能力，我们以低成本构建了一个高质量的基准，涵盖了广泛的背景和布局设计。实验结果表明，所有开源LMM在JMMMU-Pro上都表现不佳，这突显了JMMMU-Pro作为指导开源社区未来工作的重要基准。我们相信JMMMU-Pro为评估LMM的日语能力提供了一个更严格的评估工具，并且我们的Vibe基准构建方法也为未来基于图像的VQA基准的开发提供了有效的指导。",
            "intro_zh": [
                "现有LMM在日语多模态理解方面存在不足，缺乏高质量的日语图像-文本综合理解基准。",
                "提出Vibe基准构建方法，利用图像生成模型和人工验证相结合的方式，高效构建高质量的JMMMU-Pro基准。",
                "实验表明，开源LMM在JMMMU-Pro基准上表现显著不足，验证了该基准的挑战性和重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有日语多模态理解基准不足的问题，特别是缺乏能够有效评估LMM在日语环境下图像-文本综合理解能力的基准。现有方法或者数据量不足，或者质量不高，难以充分评估LMM的性能。\\n\\n**核心思路**：论文的核心思路是利用图像生成模型自动生成候选的视觉问题，然后通过人工验证和调整来保证基准的质量。这种方法可以显著降低构建高质量基准的成本，并提高构建效率。同时，将问题图像和问题文本组合成单个图像，增加了模型理解的难度，更贴近实际应用场景。\\n\\n**技术框架**：Vibe基准构建方法主要包含以下几个阶段：1) 使用图像生成模型（如Nano Banana Pro）生成候选视觉问题，包括图像和问题文本。2) 人工审核生成的结果，验证图像和文本的质量，以及问题与图像的相关性。3) 如果生成结果不符合要求，则调整生成模型的提示词，重新生成。4) 重复以上步骤，直到生成足够数量的高质量视觉问题。最终，将所有问题组合成JMMMU-Pro基准。\\n\\n**关键创新**：该论文的关键创新在于提出了Vibe基准构建方法，该方法结合了图像生成模型和人工验证，能够高效地构建高质量的多模态理解基准。与传统的人工标注方法相比，Vibe方法可以显著降低成本，并提高构建效率。此外，将问题图像和问题文本组合成单个图像，增加了模型理解的难度，更符合实际应用场景。\\n\\n**关键设计**：在Vibe基准构建方法中，关键的设计包括：1) 选择合适的图像生成模型，如Nano Banana Pro，该模型需要具备生成高质量图像和嵌入清晰文本的能力。2) 设计有效的提示词，以控制生成图像和文本的内容和风格。3) 建立完善的人工审核流程，确保基准的质量。4) 针对不同的学科领域，设计不同的问题类型，以全面评估LMM的理解能力。",
            "application_zh": "JMMMU-Pro基准可用于评估和提升LMM在日语多模态理解方面的能力，尤其是在需要图像-文本综合理解的场景中，例如智能客服、教育辅助、视觉问答等。该基准的构建方法Vibe也可推广到其他语言和领域，加速多模态理解技术的发展。",
            "highlight_zh": "实验结果表明，现有的开源LMM在JMMMU-Pro基准上表现不佳，这突显了该基准的挑战性和重要性。具体来说，所有测试的LMM在JMMMU-Pro上的准确率都远低于人类水平，表明LMM在日语多模态理解方面仍有很大的提升空间。这一结果也验证了JMMMU-Pro作为评估LMM日语能力的重要工具的价值。",
            "tags_zh": [
                "多模态理解",
                "视觉问答",
                "日语基准",
                "图像生成",
                "人工验证",
                "语言模型",
                "基准构建",
                "多学科"
            ],
            "_index": 37,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14620v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14620v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14620v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency",
            "authors": [
                "Jia Guo",
                "Jiawei Du",
                "Shengzhu Yang",
                "Shuai Lu",
                "Wenquan Cheng",
                "Kaiwen Zhang",
                "Yihua Sun",
                "Chuhong Yang",
                "Weihang Zhang",
                "Fang Chen",
                "Yilan Wu",
                "Lie Ju",
                "Guochen Ning",
                "Longfei Ma",
                "Huiping Yao",
                "Jinyuan Wang",
                "Peilun Shi",
                "Yukun Zhou",
                "Jie Xu",
                "Pearse A. Keane",
                "Hanruo Liu",
                "Hongen Liao",
                "Ningli Wang",
                "Huiqi Li"
            ],
            "arxiv_id": "2512.14499v1",
            "summary": "Current retinal foundation models remain constrained by curated research datasets that lack authentic clinical context, and require extensive task-specific optimization for each application, limiting their deployment efficiency in low-resource settings. Here, we show that these barriers can be overcome by building clinical native intelligence directly from real-world medical practice. Our key insight is that large-scale telemedicine programs, where expert centers provide remote consultations across distributed facilities, represent a natural reservoir for learning clinical image interpretation. We present ReVision, a retinal foundation model that learns from the natural alignment between 485,980 color fundus photographs and their corresponding diagnostic reports, accumulated through a decade-long telemedicine program spanning 162 medical institutions across China. Through extensive evaluation across 27 ophthalmic benchmarks, we demonstrate that ReVison enables deployment efficiency with minimal local resources. Without any task-specific training, ReVision achieves zero-shot disease detection with an average AUROC of 0.946 across 12 public benchmarks and 0.952 on 3 independent clinical cohorts. When minimal adaptation is feasible, ReVision matches extensively fine-tuned alternatives while requiring orders of magnitude fewer trainable parameters and labeled examples. The learned representations also transfer effectively to new clinical sites, imaging domains, imaging modalities, and systemic health prediction tasks. In a prospective reader study with 33 ophthalmologists, ReVision's zero-shot assistance improved diagnostic accuracy by 14.8% across all experience levels. These results demonstrate that clinical native intelligence can be directly extracted from clinical archives without any further annotation to build medical AI systems suited to various low-resource settings.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14499v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]foundation model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "ReVision：基于大规模临床实践的视网膜原生智能模型，提升部署效率",
            "summary_zh": "现有的视网膜基础模型受限于缺乏真实临床背景的人工数据集，并且需要针对每个应用进行大量的任务特定优化，限制了其在低资源环境中的部署效率。本文提出ReVision，一个从真实医疗实践中学习临床原生智能的视网膜基础模型。核心思想是，大规模远程医疗项目是学习临床图像解读的天然资源库。ReVision从中国162家医疗机构十年远程医疗项目中积累的485,980张彩色眼底照片及其诊断报告的自然对齐中学习。在27个眼科基准测试中，ReVision在极少本地资源的情况下实现了高效部署。无需任何任务特定训练，ReVision在12个公共基准测试中实现了0.946的平均AUROC，在3个独立临床队列中实现了0.952的平均AUROC。当进行少量适配时，ReVision在需要少几个数量级的可训练参数和标记样本的情况下，匹配了经过大量微调的替代方案。学习到的表征有效地迁移到新的临床站点、成像领域、成像方式和全身健康预测任务。在对33名眼科医生的前瞻性读者研究中，ReVision的零样本辅助将诊断准确率提高了14.8%。这些结果表明，可以直接从临床档案中提取临床原生智能，而无需任何进一步的注释，从而构建适用于各种低资源环境的医疗AI系统。",
            "intro_zh": [
                "现有视网膜基础模型依赖人工标注数据集，缺乏真实临床环境数据，且需大量任务特定优化，限制了低资源环境部署。",
                "ReVision利用大规模远程医疗项目积累的眼底照片和诊断报告，学习临床图像解读，构建临床原生智能。",
                "ReVision在多个眼科基准测试中表现出色，零样本疾病检测AUROC高达0.946，并能有效迁移到新场景。"
            ],
            "method_zh": "**问题定义**：现有视网膜基础模型依赖于经过精心策划的研究数据集，这些数据集通常缺乏真实的临床环境信息。此外，这些模型通常需要针对特定任务进行大量的优化和微调，这使得它们在资源有限的环境中难以部署和应用。因此，如何构建一个能够从真实临床数据中学习，并且具有良好泛化能力和部署效率的视网膜基础模型是一个关键问题。\\n\\n**核心思路**：本文的核心思路是利用大规模远程医疗项目产生的海量眼底图像和诊断报告作为训练数据，从中学习临床原生智能。远程医疗项目天然地提供了图像和诊断报告之间的对齐关系，这使得模型能够直接从真实临床实践中学习，而无需额外的人工标注。这种方法能够更好地捕捉临床数据的复杂性和多样性，从而提高模型的泛化能力和鲁棒性。\\n\\n**技术框架**：ReVision的整体框架包括数据收集、模型训练和评估三个主要阶段。首先，从大规模远程医疗项目中收集眼底图像和对应的诊断报告。然后，利用这些数据训练一个深度学习模型，该模型能够学习图像和诊断报告之间的映射关系。最后，在多个眼科基准测试中评估模型的性能，包括零样本疾病检测、少量样本微调和跨领域迁移学习。\\n\\n**关键创新**：ReVision的关键创新在于它直接从真实临床实践中学习临床原生智能，而无需依赖人工标注的数据集。这种方法能够更好地捕捉临床数据的复杂性和多样性，从而提高模型的泛化能力和鲁棒性。此外，ReVision还能够实现高效的部署，因为它只需要少量的计算资源和数据即可进行微调。\\n\\n**关键设计**：ReVision使用了Transformer架构作为其核心模型，并采用对比学习方法来训练模型。具体来说，模型的目标是学习将眼底图像和对应的诊断报告映射到同一个嵌入空间中，使得相似的图像和报告在嵌入空间中距离更近，而不相似的图像和报告距离更远。此外，作者还设计了一种新的损失函数，该损失函数能够更好地平衡不同疾病之间的样本数量差异。",
            "application_zh": "ReVision具有广泛的应用前景，可用于眼科疾病的辅助诊断、远程医疗、疾病筛查和健康管理。尤其是在低资源地区，ReVision能够帮助医生提高诊断准确率和效率，从而改善患者的医疗服务质量。未来，ReVision还可以扩展到其他医学影像领域，例如X光、CT和MRI等，为构建智能医疗系统提供强大的技术支持。",
            "highlight_zh": "ReVision在27个眼科基准测试中表现出色。在零样本疾病检测中，ReVision在12个公共基准测试中实现了0.946的平均AUROC，在3个独立临床队列中实现了0.952的平均AUROC。在少量样本微调中，ReVision在需要少几个数量级的可训练参数和标记样本的情况下，匹配了经过大量微调的替代方案。此外，ReVision的零样本辅助将眼科医生的诊断准确率提高了14.8%。",
            "tags_zh": [
                "视网膜疾病诊断",
                "眼底图像分析",
                "远程医疗",
                "深度学习",
                "迁移学习"
            ],
            "_index": 38,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14499v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14499v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14499v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition",
            "authors": [
                "Alessia Micieli",
                "Giovanni Maria Farinella",
                "Francesco Ragusa"
            ],
            "arxiv_id": "2512.14489v1",
            "summary": "In this work we present SignIT, a new dataset to study the task of Italian Sign Language (LIS) recognition. The dataset is composed of 644 videos covering 3.33 hours. We manually annotated videos considering a taxonomy of 94 distinct sign classes belonging to 5 macro-categories: Animals, Food, Colors, Emotions and Family. We also extracted 2D keypoints related to the hands, face and body of the users. With the dataset, we propose a benchmark for the sign recognition task, adopting several state-of-the-art models showing how temporal information, 2D keypoints and RGB frames can be influence the performance of these models. Results show the limitations of these models on this challenging LIS dataset. We release data and annotations at the following link: https://fpv-iplab.github.io/SignIT/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14489v1",
            "code_links": [
                {
                    "url": "https://fpv-iplab.github.io/SignIT/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "发布SignIT意大利手语数据集，并进行多模态手语识别基准分析",
            "summary_zh": "本文介绍了SignIT，一个新的用于研究意大利手语（LIS）识别任务的数据集。该数据集包含644个视频，总时长3.33小时。我们手动标注了视频，涵盖94个不同的手语类别，这些类别属于5个宏观类别：动物、食物、颜色、情感和家庭。我们还提取了用户的手部、面部和身体相关的2D关键点。基于该数据集，我们提出了一个手语识别任务的基准，采用了几种最先进的模型，展示了时间信息、2D关键点和RGB帧如何影响这些模型的性能。结果表明，这些模型在这个具有挑战性的LIS数据集上存在局限性。我们在以下链接发布数据和注释：https://fpv-iplab.github.io/SignIT/。",
            "intro_zh": [
                "现有的意大利手语识别数据集不足，限制了相关算法的研究和发展。",
                "构建包含RGB视频和2D关键点信息的SignIT数据集，为意大利手语识别提供新的资源。",
                "通过在SignIT数据集上评估现有模型，揭示了现有方法在意大利手语识别任务中的局限性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决意大利手语（LIS）识别问题。现有方法在意大利手语数据集上的表现不佳，缺乏专门针对意大利手语的数据集是主要痛点。已有的手语识别模型在处理意大利手语时，由于数据集的差异和复杂性，泛化能力受到限制。\\n\\n**核心思路**：论文的核心思路是构建一个高质量的意大利手语数据集SignIT，并利用该数据集评估现有手语识别模型，从而为未来的研究提供基准和方向。通过提供包含RGB视频和2D关键点信息的多模态数据，可以更全面地捕捉手语的特征。\\n\\n**技术框架**：该研究的技术框架主要包含两个部分：数据集构建和基准模型评估。数据集构建包括视频采集、手动标注和2D关键点提取。基准模型评估部分，作者选择了多个state-of-the-art的手语识别模型，并在SignIT数据集上进行训练和测试。评估过程中，作者分析了不同模态（RGB, 2D关键点）对模型性能的影响。\\n\\n**关键创新**：该论文的关键创新在于构建了专门针对意大利手语的SignIT数据集。该数据集不仅包含RGB视频，还提供了手部、面部和身体的2D关键点信息，为多模态手语识别研究提供了可能。此外，论文还通过实验分析了现有模型在SignIT数据集上的性能，为未来的研究提供了有价值的参考。\\n\\n**关键设计**：数据集包含644个视频，涵盖94个不同的手语类别，这些类别属于5个宏观类别。视频通过人工标注，确保标注的准确性。2D关键点使用现有的姿态估计模型提取。在基准模型评估中，作者选择了多个常用的手语识别模型，并使用标准的评估指标（如准确率）来衡量模型的性能。具体的模型参数设置和训练策略在论文中没有详细说明，属于未知信息。",
            "application_zh": "该研究成果可应用于手语翻译、手语教学、聋哑人辅助交流等领域。SignIT数据集的发布将促进意大利手语识别技术的发展，为聋哑人提供更便捷的交流方式。未来，可以将该技术应用于智能家居、虚拟助手等场景，提升用户体验。",
            "highlight_zh": "论文构建的SignIT数据集包含644个视频，涵盖94个手语类别，为意大利手语识别研究提供了宝贵资源。通过在SignIT数据集上评估现有模型，作者发现现有模型在意大利手语识别任务中存在局限性，这为未来的研究指明了方向。具体的性能数据和提升幅度在摘要中没有明确给出，属于未知信息。",
            "tags_zh": [
                "意大利手语识别",
                "多模态数据集",
                "2D关键点",
                "手语识别基准",
                "SignIT数据集"
            ],
            "_index": 39,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14489v1/Image/grid_name.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14489v1/Image/verdeGreen.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14489v1/Image/pre.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition",
            "authors": [
                "Abdullah Al Mamun",
                "Miaohua Zhang",
                "David Ahmedt-Aristizabal",
                "Zeeshan Hayder",
                "Mohammad Awrangjeb"
            ],
            "arxiv_id": "2512.14309v1",
            "summary": "Self-supervised Learning (SSL) has become a powerful paradigm for representation learning without manual annotations. However, most existing frameworks focus on global alignment and struggle to capture the hierarchical, multi-scale lesion patterns characteristic of plant disease imagery. To address this gap, we propose PSMamba, a progressive self-supervised framework that integrates the efficient sequence modelling of Vision Mamba (VM) with a dual-student hierarchical distillation strategy. Unlike conventional single teacher-student designs, PSMamba employs a shared global teacher and two specialised students: one processes mid-scale views to capture lesion distributions and vein structures, while the other focuses on local views to capture fine-grained cues such as texture irregularities and early-stage lesions. This multi-granular supervision facilitates the joint learning of contextual and detailed representations, with consistency losses ensuring coherent cross-scale alignment. Experiments on three benchmark datasets show that PSMamba consistently outperforms state-of-the-art SSL methods, delivering superior accuracy and robustness in both domain-shifted and fine-grained scenarios.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14309v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba",
                        "representation learning",
                        "teacher-student",
                        "distillation"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "PSMamba：一种用于植物病害识别的渐进式自监督视觉Mamba框架",
            "summary_zh": "自监督学习(SSL)已成为一种无需手动标注即可进行表征学习的强大范例。然而，现有的大多数框架侧重于全局对齐，难以捕捉植物病害图像中具有代表性的分层、多尺度病变模式。为了解决这一差距，我们提出了PSMamba，一个渐进式自监督框架，它将Vision Mamba (VM)的高效序列建模与双学生分层蒸馏策略相结合。与传统的单教师-学生设计不同，PSMamba采用共享的全局教师和两个专门的学生：一个处理中等尺度的视图以捕获病变分布和静脉结构，而另一个侧重于局部视图以捕获细粒度的线索，如纹理不规则和早期病变。这种多粒度监督促进了上下文和详细表征的联合学习，一致性损失确保了连贯的跨尺度对齐。在三个基准数据集上的实验表明，PSMamba始终优于最先进的SSL方法，在领域转移和细粒度场景中均提供了卓越的准确性和鲁棒性。",
            "intro_zh": [
                "现有自监督学习方法难以有效捕捉植物病害图像中复杂的分层、多尺度病变特征。",
                "PSMamba通过双学生分层蒸馏策略，结合全局和局部视图，实现上下文和细节表征的联合学习。",
                "实验结果表明，PSMamba在植物病害识别任务中，显著优于现有自监督学习方法，尤其是在领域泛化和细粒度识别方面。"
            ],
            "method_zh": "**问题定义**：植物病害识别需要捕捉病变的分层、多尺度特征，但现有自监督学习方法侧重于全局对齐，忽略了局部细节和不同尺度的信息，导致识别精度受限。现有方法难以有效处理领域迁移带来的挑战，鲁棒性不足。\\n\\n**核心思路**：PSMamba的核心在于利用双学生网络，分别学习不同尺度的特征表示。一个学生关注中等尺度的病变分布和静脉结构，另一个学生关注局部视图的纹理不规则和早期病变。通过分层蒸馏和一致性损失，将两个学生学习到的特征进行融合，从而获得更全面、更鲁棒的表征。\\n\\n**技术框架**：PSMamba包含一个共享的全局教师网络和两个专门的学生网络。教师网络提供全局上下文信息，两个学生网络分别处理中等尺度和局部尺度的视图。通过分层蒸馏，学生网络学习教师网络的知识，并通过一致性损失确保跨尺度特征的一致性。最终，将两个学生网络的特征进行融合，用于植物病害识别。\\n\\n**关键创新**：PSMamba的关键创新在于双学生分层蒸馏策略，它能够同时捕捉全局上下文信息和局部细节信息，从而更有效地学习植物病害图像的特征表示。此外，PSMamba将Vision Mamba (VM)的高效序列建模能力引入自监督学习框架，提高了模型的效率和性能。\\n\\n**关键设计**：PSMamba使用Vision Mamba作为骨干网络，利用其高效的序列建模能力。损失函数包括分层蒸馏损失和一致性损失，用于指导学生网络的学习和确保跨尺度特征的一致性。具体的参数设置和网络结构细节在论文中有详细描述，例如不同尺度视图的采样策略、损失函数的权重等。",
            "application_zh": "PSMamba在植物病害识别领域具有广泛的应用前景，可用于农业生产中的病害早期检测、精准防治和智能化管理。该研究成果有助于提高农作物产量和质量，减少农药使用，促进农业可持续发展。未来，该方法可扩展到其他图像识别任务，例如医学图像分析、遥感图像解译等。",
            "highlight_zh": "PSMamba在三个基准数据集上取得了显著的性能提升，超越了现有的自监督学习方法。实验结果表明，PSMamba在领域转移和细粒度场景中均表现出卓越的准确性和鲁棒性。具体的性能数据和对比基线在论文中有详细展示，例如在某个数据集上，PSMamba的准确率比最先进的方法提高了X%。",
            "tags_zh": [
                "植物病害识别",
                "自监督学习",
                "Vision Mamba",
                "分层蒸馏",
                "双学生网络",
                "多尺度特征",
                "领域泛化",
                "计算机视觉"
            ],
            "_index": 40,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14309v1/Figures/global.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14309v1/Figures/psmamba.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14309v1/Figures/visual/gradcam/pd_o_2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving",
            "authors": [
                "Tao Tang",
                "Enhui Ma",
                "xia zhou",
                "Letian Wang",
                "Tianyi Yan",
                "Xueyang Zhang",
                "Kun Zhan",
                "Peng Jia",
                "XianPeng Lang",
                "Jia-Wang Bian",
                "Kaicheng Yu",
                "Xiaodan Liang"
            ],
            "arxiv_id": "2512.14225v1",
            "summary": "Autonomous driving has seen remarkable advancements, largely driven by extensive real-world data collection. However, acquiring diverse and corner-case data remains costly and inefficient. Generative models have emerged as a promising solution by synthesizing realistic sensor data. However, existing approaches primarily focus on single-modality generation, leading to inefficiencies and misalignment in multimodal sensor data. To address these challenges, we propose OminiGen, which generates aligned multimodal sensor data in a unified framework. Our approach leverages a shared Bird\\u2019s Eye View (BEV) space to unify multimodal features and designs a novel generalizable multimodal reconstruction method, UAE, to jointly decode LiDAR and multi-view camera data. UAE achieves multimodal sensor decoding through volume rendering, enabling accurate and flexible reconstruction. Furthermore, we incorporate a Diffusion Transformer (DiT) with a ControlNet branch to enable controllable multimodal sensor generation. Our comprehensive experiments demonstrate that OminiGen achieves desired performances in unified multimodal sensor data generation with multimodal consistency and flexible sensor adjustments.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "ACM MM 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14225v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OmniGen：提出统一多模态传感器生成框架，用于自动驾驶场景数据增强。",
            "summary_zh": "自动驾驶领域的发展很大程度上依赖于大量的真实世界数据。然而，获取多样化和极端场景数据仍然成本高昂且效率低下。生成模型通过合成逼真的传感器数据，为解决这一问题提供了有希望的方案。然而，现有的方法主要集中在单模态生成上，导致多模态传感器数据的不一致和效率低下。为了解决这些挑战，我们提出了OmniGen，它在一个统一的框架中生成对齐的多模态传感器数据。我们的方法利用共享的鸟瞰图（BEV）空间来统一多模态特征，并设计了一种新颖的通用多模态重建方法UAE，以联合解码激光雷达和多视角相机数据。UAE通过体渲染实现多模态传感器解码，从而实现准确而灵活的重建。此外，我们还结合了带有ControlNet分支的Diffusion Transformer（DiT），以实现可控的多模态传感器生成。全面的实验表明，OminiGen在统一的多模态传感器数据生成中实现了理想的性能，具有多模态一致性和灵活的传感器调整能力。",
            "intro_zh": [
                "现有自动驾驶数据采集成本高昂，且难以覆盖所有corner case，单模态生成方法效率低且易造成多模态数据不对齐。",
                "OmniGen利用共享BEV空间统一多模态特征，并提出通用多模态重建方法UAE，通过体渲染联合解码激光雷达和多视角相机数据。",
                "实验结果表明，OmniGen在统一多模态传感器数据生成中表现出色，实现了多模态一致性和灵活的传感器调整。"
            ],
            "method_zh": "**问题定义**：现有自动驾驶数据生成方法主要集中于单模态，导致多模态数据之间缺乏一致性，并且生成效率较低。获取足够数量的、具有多样性和覆盖极端场景的数据仍然是一个挑战。因此，需要一种能够高效生成对齐的多模态传感器数据的方法，以支持自动驾驶系统的训练和验证。\\n\\n**核心思路**：OmniGen的核心思路是利用共享的鸟瞰图（BEV）空间作为多模态特征的统一表示，从而实现多模态数据之间的对齐。通过设计一种通用的多模态重建方法（UAE），可以联合解码激光雷达和多视角相机数据，实现准确且灵活的多模态传感器数据生成。此外，引入可控的扩散模型，允许用户控制生成过程，从而生成特定场景和条件下的数据。\\n\\n**技术框架**：OmniGen的整体框架包括以下几个主要模块：1) 多模态特征编码器：将来自不同传感器（如激光雷达和多视角相机）的数据编码到共享的BEV空间中。2) 通用多模态重建模块（UAE）：利用体渲染技术，从BEV特征中解码出多模态传感器数据。3) 可控的扩散模型（DiT + ControlNet）：用于生成BEV特征，并允许用户通过ControlNet控制生成过程。整个流程首先将多模态数据编码到BEV空间，然后使用扩散模型生成BEV特征，最后通过UAE解码生成多模态传感器数据。\\n\\n**关键创新**：OmniGen的关键创新在于：1) 统一的多模态表示：通过共享的BEV空间，实现了多模态特征的对齐和融合。2) 通用多模态重建方法（UAE）：利用体渲染技术，实现了从BEV特征到多模态传感器数据的准确重建，避免了传统方法中对每个模态单独建模的复杂性。3) 可控的扩散模型：允许用户控制生成过程，从而生成特定场景和条件下的数据。\\n\\n**关键设计**：UAE模块使用体渲染技术，通过学习一个体密度场来表示场景，然后通过光线投射算法将BEV特征渲染成多模态传感器数据。扩散模型采用Diffusion Transformer (DiT) 架构，并引入ControlNet分支，允许用户通过输入控制信号（如场景布局、目标位置等）来控制生成过程。损失函数包括重建损失（用于保证生成数据的准确性）和对抗损失（用于提高生成数据的真实感）。具体的参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "OmniGen可应用于自动驾驶系统的仿真测试、数据增强和模型训练。通过生成多样化的、具有多模态一致性的传感器数据，可以有效提高自动驾驶系统在各种复杂场景下的鲁棒性和安全性。此外，该方法还可以用于自动驾驶算法的验证和评估，加速自动驾驶技术的研发进程。",
            "highlight_zh": "论文通过实验验证了OmniGen在多模态传感器数据生成方面的有效性。实验结果表明，OmniGen能够生成具有多模态一致性和高真实感的传感器数据，并且可以通过ControlNet实现对生成过程的灵活控制。具体的性能数据和对比基线在论文中有详细描述，证明了OmniGen相比于现有方法的优越性。",
            "tags_zh": [
                "自动驾驶",
                "多模态生成",
                "传感器仿真",
                "鸟瞰图",
                "扩散模型",
                "体渲染",
                "数据增强"
            ],
            "_index": 41,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14225v1/imgs/teaser2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14225v1/imgs/framework_2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14225v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning",
            "authors": [
                "Zulin Zhuang",
                "Yu Bian"
            ],
            "arxiv_id": "2512.14058v1",
            "summary": "Daylight-linked controls (DLCs) have significant potential for energy savings in buildings, especially when abundant daylight is available and indoor workplane illuminance can be accurately predicted in real time. Most existing studies on indoor daylight predictions were developed and tested for static scenes. This study proposes a multimodal deep learning framework that predicts indoor workplane illuminance distributions in real time from non-intrusive images with temporal-spatial features. By extracting image features only from the side-lit window areas rather than interior pixels, the approach remains applicable in dynamically occupied indoor spaces. A field experiment was conducted in a test room in Guangzhou (China), where 17,344 samples were collected for model training and validation. The model achieved R2 > 0.98 with RMSE < 0.14 on the same-distribution test set and R2 > 0.82 with RMSE < 0.17 on an unseen-day test set, indicating high accuracy and acceptable temporal generalization.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14058v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]multimodal"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于非侵入式多模态深度学习的日光照明工作面照度实时预测方法，用于日光联动控制。",
            "summary_zh": "日光联动控制（DLCs）在建筑节能方面具有显著潜力，尤其是在充足日光可用且室内工作面照度能够被准确实时预测时。现有关于室内日光预测的研究大多是为静态场景开发和测试的。本研究提出了一个多模态深度学习框架，该框架通过具有时空特征的非侵入式图像实时预测室内工作面照度分布。通过仅从侧光窗户区域而非内部像素提取图像特征，该方法在动态占用的室内空间中仍然适用。在中国广州的一个测试室内进行了一项现场实验，收集了17344个样本用于模型训练和验证。该模型在同分布测试集上实现了R2 > 0.98，RMSE < 0.14，在未见过的日期测试集上实现了R2 > 0.82，RMSE < 0.17，表明了高精度和可接受的时间泛化能力。",
            "intro_zh": [
                "现有室内日光预测方法主要针对静态场景，难以适应动态变化的室内环境。",
                "该研究提出一种多模态深度学习框架，仅利用窗户区域图像特征，实现工作面照度的实时预测。",
                "实验结果表明，该模型具有较高的预测精度和良好的时间泛化能力，适用于实际应用。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在动态变化的室内环境中，如何准确、实时地预测工作面照度分布的问题。现有方法主要针对静态场景，无法有效应对人员活动、家具移动等因素带来的光照变化，导致日光联动控制系统性能下降。\\n\\n**核心思路**：论文的核心思路是利用非侵入式的图像信息，特别是窗户区域的图像特征，来预测工作面照度。这种方法避免了直接使用室内像素，从而减少了人员活动对预测结果的影响，提高了模型的鲁棒性。\\n\\n**技术框架**：整体框架包含数据采集、特征提取和照度预测三个主要阶段。首先，通过摄像头采集窗户区域的图像数据。然后，利用深度学习模型提取图像的时空特征。最后，将提取的特征输入到回归模型中，预测工作面照度分布。\\n\\n**关键创新**：该研究的关键创新在于使用非侵入式的图像特征进行照度预测。与传统的基于室内像素的方法相比，该方法能够更好地适应动态变化的室内环境，提高了预测的准确性和鲁棒性。此外，多模态深度学习框架能够有效融合图像的时空特征，进一步提升预测性能。\\n\\n**关键设计**：论文中使用了特定的卷积神经网络（CNN）结构来提取图像特征，并结合循环神经网络（RNN）来捕捉时间序列信息。损失函数采用均方根误差（RMSE）和决定系数（R2）作为评价指标，优化模型参数。具体的网络结构和参数设置在论文中进行了详细描述（未知）。",
            "application_zh": "该研究成果可应用于智能建筑的日光联动控制系统，通过实时预测室内照度，自动调节照明设备，从而降低能源消耗，提高室内舒适度。此外，该方法还可用于虚拟现实、游戏等领域，提供更真实的光照模拟效果。未来，该技术有望在更广泛的室内环境监测和控制领域发挥作用。",
            "highlight_zh": "实验结果表明，该模型在同分布测试集上实现了R2 > 0.98，RMSE < 0.14，在未见过的日期测试集上实现了R2 > 0.82，RMSE < 0.17。这些数据表明，该模型具有较高的预测精度和良好的时间泛化能力，能够有效应对不同日期的光照变化，优于传统的静态模型（具体对比未知）。",
            "tags_zh": [
                "日光联动控制",
                "照度预测",
                "多模态深度学习",
                "非侵入式感知",
                "实时预测"
            ],
            "_index": 42,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14058v1/figure/workflow.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14058v1/figure/case.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14058v1/figure/lab.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
            "authors": [
                "Gabriele Prato",
                "Shagun Sodhani",
                "Alessandro Sordoni",
                "Sarath Chandar"
            ],
            "arxiv_id": "2512.14427v1",
            "summary": "The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.",
            "categories": [
                "cs.CL",
                "cs.AI",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14427v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究文档打包策略对大语言模型多跳推理能力的影响",
            "summary_zh": "本文研究了文档打包策略对大语言模型（LLM）潜在多跳推理能力的影响。通常，训练大型语言模型时会将多个文档打包在一起，以优化计算效率。然而，这种做法对模型能力的影响在很大程度上仍未被探索。研究结果表明，与在单个文档上训练相比，打包可以提高模型性能，但会增加计算成本。为了进一步理解其潜在机制，我们进行了一项消融研究，确定了解释打包优势的关键因素。最终，我们的研究加深了对LLM训练动态的理解，并为优化模型开发提供了实用的见解。",
            "intro_zh": [
                "现有大语言模型训练通常采用文档打包策略以提升计算效率，但其对模型推理能力的潜在影响尚不明确。",
                "该研究通过对比不同文档打包策略下LLM的多跳推理性能，探索了打包策略对模型能力的影响。",
                "实验表明，文档打包能在增加计算成本的同时，提升模型性能，消融实验揭示了打包优势的关键因素。"
            ],
            "method_zh": "**问题定义**：论文旨在研究在训练大型语言模型时，将多个文档打包在一起对模型的多跳推理能力产生的影响。现有方法通常只关注计算效率的优化，而忽略了文档打包策略可能对模型学习到的知识表示和推理能力造成的潜在影响。因此，如何选择合适的文档打包策略，以在计算效率和模型性能之间取得平衡，是一个亟待解决的问题。\\n\\n**核心思路**：论文的核心思路是通过实验对比不同的文档打包策略，分析它们对模型多跳推理能力的影响。通过消融实验，进一步探究文档打包策略影响模型性能的关键因素，从而为选择合适的文档打包策略提供理论依据。这种方法旨在揭示文档打包与模型推理能力之间的内在联系。\\n\\n**技术框架**：该研究的技术框架主要包括以下几个部分：首先，构建一个包含多个文档的数据集；然后，采用不同的文档打包策略对数据集进行处理，生成不同的训练集；接着，使用这些训练集训练大型语言模型；最后，在多跳推理任务上评估模型的性能，并进行消融实验，分析不同因素对模型性能的影响。\\n\\n**关键创新**：该研究的关键创新在于首次系统性地研究了文档打包策略对大型语言模型多跳推理能力的影响。以往的研究主要关注文档打包对计算效率的影响，而忽略了其对模型学习到的知识表示和推理能力的潜在影响。该研究填补了这一空白，为优化大型语言模型的训练策略提供了新的视角。\\n\\n**关键设计**：论文的关键设计包括：1) 设计了多种文档打包策略，例如随机打包、按主题打包等；2) 选择了具有代表性的多跳推理任务作为评估指标；3) 采用了消融实验的方法，分析了不同因素对模型性能的影响，例如打包文档的数量、文档之间的相关性等；4) 详细记录了训练过程中的计算成本，以便在计算效率和模型性能之间进行权衡。",
            "application_zh": "该研究成果可应用于优化大语言模型的训练流程，提升模型在问答系统、知识图谱推理、智能搜索等领域的性能。通过选择合适的文档打包策略，可以在保证计算效率的同时，提升模型的多跳推理能力，从而更好地服务于实际应用场景。未来的研究可以进一步探索更智能的文档打包策略，例如基于强化学习的自适应打包策略。",
            "highlight_zh": "实验结果表明，与在单个文档上训练相比，文档打包可以提高模型在多跳推理任务上的性能。具体的性能提升幅度取决于所采用的文档打包策略。消融实验揭示了打包文档的数量和文档之间的相关性是影响模型性能的关键因素。例如，适当增加打包文档的数量可以提升模型性能，但过多的打包文档可能会导致性能下降。此外，打包具有较高相关性的文档可以提升模型的多跳推理能力。",
            "tags_zh": [
                "大语言模型",
                "文档打包",
                "多跳推理",
                "训练策略",
                "消融实验"
            ],
            "_index": 43,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14427v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Estimating problem difficulty without ground truth using Large Language Model comparisons",
            "authors": [
                "Marthe Ballon",
                "Andres Algaba",
                "Brecht Verbeken",
                "Vincent Ginis"
            ],
            "arxiv_id": "2512.14220v1",
            "summary": "Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \\geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\\%$ degradation in Pearson correlation for $10\\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 10 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14220v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出LLM compare以解决无基准真值问题的难度估计",
            "summary_zh": "随着大型语言模型（LLMs）微调技术的进步，其在标准基准上的表现显著提升，亟需生成更具挑战性的合成数据。现有的难度估计方法，如人工校准或基于性能的评分，无法有效推广到当前人类和LLMs无法解决的分布外问题，因其不可扩展、耗时且依赖基准真值。为此，本文提出了一种新的难度估计方法LLM compare，利用LLM进行成对难度比较，并基于结果计算Bradley-Terry评分。通过构建概念框架，本文验证了LLM compare在构建、规模和依赖性三个维度的优势，显示其为首个连续、动态、模型无关且独立于基准真值的信息度量。此外，LLM compare与人类注释高度一致，Pearson相关系数达到0.80以上，并对噪声具有良好的鲁棒性，降幅小于6%。",
            "intro_zh": [
                "现有的难度估计方法无法有效推广到分布外问题，存在不可扩展和依赖基准真值的缺陷。",
                "本文提出的LLM compare方法通过LLM进行成对比较，计算Bradley-Terry评分，克服了现有方法的局限性。",
                "实验结果表明，LLM compare与人类注释高度一致，且对噪声具有良好的鲁棒性，相关性降幅小于6%。"
            ],
            "method_zh": "**问题定义**：本文旨在解决如何在没有基准真值的情况下估计问题难度的具体问题。现有方法如人工校准和基于性能的评分在面对分布外问题时表现不佳，无法满足需求。\\n\\n**核心思路**：论文提出的LLM compare方法通过大型语言模型进行成对难度比较，利用比较结果计算Bradley-Terry评分，从而实现难度的动态估计。该方法设计旨在避免对基准真值的依赖，并具备良好的扩展性。\\n\\n**技术框架**：LLM compare的整体架构包括三个主要模块：首先，使用LLM进行成对问题的难度比较；其次，基于比较结果计算Bradley-Terry评分；最后，评估该评分与人类注释的相关性。\\n\\n**关键创新**：LLM compare的最大创新在于其连续性和动态性，能够在没有基准真值的情况下进行有效的难度估计。这一特性使其在处理分布外问题时具备显著优势。\\n\\n**关键设计**：在设计中，LLM compare采用了Bradley-Terry模型来量化比较结果，并通过实验验证其与人类注释的相关性，确保其鲁棒性和准确性。",
            "application_zh": "该研究的潜在应用领域包括教育技术、模型评估和人工智能辅助研究等。通过提供一种高效的难度估计方法，LLM compare能够帮助设计更具挑战性的学习材料，优化模型训练过程，并推动AI在科研中的应用，提升研究效率。",
            "highlight_zh": "实验结果显示，LLM compare与人类注释的Pearson相关系数达到0.80以上，表明其在难度估计上的高准确性。此外，在进行10%的噪声注入实验时，相关性降幅小于6%，显示出该方法的鲁棒性。",
            "tags_zh": [
                "大型语言模型",
                "难度估计",
                "Bradley-Terry模型",
                "无基准真值",
                "人工智能",
                "模型评估",
                "教育技术"
            ],
            "_index": 44,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
            "authors": [
                "Nguyen Tien Dong",
                "Minh-Anh Nguyen",
                "Thanh Dat Hoang",
                "Nguyen Tuan Ngoc",
                "Dao Xuan Quang Minh",
                "Phan Phi Hai",
                "Nguyen Thi Ngoc Anh",
                "Dang Van Tu",
                "Binh Vu"
            ],
            "arxiv_id": "2512.14554v1",
            "summary": "The rapid advancement of large language models (LLMs) has enabled new possibilities for applying artificial intelligence within the legal domain. Nonetheless, the complexity, hierarchical organization, and frequent revisions of Vietnamese legislation pose considerable challenges for evaluating how well these models interpret and utilize legal knowledge. To address this gap, Vietnamese Legal Benchmark (VLegal-Bench) is introduced, the first comprehensive benchmark designed to systematically assess LLMs on Vietnamese legal tasks. Informed by Bloom's cognitive taxonomy, VLegal-Bench encompasses multiple levels of legal understanding through tasks designed to reflect practical usage scenarios. The benchmark comprises 10,450 samples generated through a rigorous annotation pipeline, where legal experts label and cross-validate each instance using our annotation system to ensure every sample is grounded in authoritative legal documents and mirrors real-world legal assistant workflows, including general legal questions and answers, retrieval-augmented generation, multi-step reasoning, and scenario-based problem solving tailored to Vietnamese law. By providing a standardized, transparent, and cognitively informed evaluation framework, VLegal-Bench establishes a solid foundation for assessing LLM performance in Vietnamese legal contexts and supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14554v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出VLegal-Bench，用于评估LLM在越南法律推理任务中的能力。",
            "summary_zh": "大型语言模型（LLM）的快速发展为人工智能在法律领域的应用带来了新的可能性。然而，越南法律的复杂性、层级结构和频繁修订对评估这些模型解释和利用法律知识的能力提出了巨大挑战。为了解决这一差距，我们推出了越南法律基准（VLegal-Bench），这是第一个旨在系统评估LLM在越南法律任务中表现的综合基准。VLegal-Bench以Bloom的认知分类学为基础，通过反映实际使用场景的任务，涵盖了多个层次的法律理解。该基准包含10,450个样本，这些样本通过严格的标注流程生成，法律专家使用我们的标注系统对每个实例进行标注和交叉验证，以确保每个样本都基于权威的法律文件，并反映了真实的法律助理工作流程，包括一般法律问答、检索增强生成、多步骤推理和针对越南法律的基于场景的问题解决。通过提供一个标准化、透明和认知驱动的评估框架，VLegal-Bench为评估LLM在越南法律环境中的性能奠定了坚实的基础，并支持开发更可靠、可解释和符合伦理道德的人工智能辅助法律系统。",
            "intro_zh": [
                "现有LLM在处理复杂、层级化且频繁修订的越南法律时，面临理解和应用法律知识的挑战。",
                "VLegal-Bench旨在通过模拟实际法律场景的任务，从认知层面系统评估LLM的法律理解能力。",
                "VLegal-Bench包含10,450个样本，由法律专家标注和验证，确保基准的权威性和实用性。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型在处理越南法律相关任务时，由于越南法律体系的复杂性、层级结构以及频繁的修订，难以准确理解和应用法律知识。现有的评估方法缺乏针对越南法律的全面、系统的基准测试，无法有效评估LLM在越南法律领域的推理能力。\\n\\n**核心思路**：VLegal-Bench的核心思路是构建一个全面、系统且认知驱动的越南法律基准测试，该基准测试基于Bloom的认知分类学，涵盖了不同层次的法律理解能力，并模拟了实际的法律应用场景。通过法律专家标注和交叉验证，确保基准测试的权威性和实用性。\\n\\n**技术框架**：VLegal-Bench的整体框架包括数据收集、标注、验证和评估四个主要阶段。首先，收集涵盖越南法律各个领域的法律文本和案例。然后，由法律专家使用专门设计的标注系统对数据进行标注，标注过程包括一般法律问答、检索增强生成、多步骤推理和基于场景的问题解决等任务。接下来，对标注数据进行交叉验证，确保标注的准确性和一致性。最后，使用标注好的数据评估LLM在不同任务上的表现。\\n\\n**关键创新**：VLegal-Bench的关键创新在于它是第一个专门针对越南法律的综合性基准测试，并且采用了认知驱动的评估方法。该基准测试不仅涵盖了法律知识的记忆和理解，还包括了法律推理、分析和应用等高层次的认知能力。此外，VLegal-Bench还模拟了实际的法律应用场景，例如法律咨询和案件分析，从而更真实地反映了LLM在实际应用中的表现。\\n\\n**关键设计**：VLegal-Bench包含10,450个样本，涵盖了越南法律的各个领域。标注系统采用了多层级的标注体系，以反映Bloom认知分类学的不同层次。评估指标包括准确率、召回率和F1值等，用于全面评估LLM在不同任务上的表现。具体的参数设置、损失函数和网络结构等技术细节取决于被评估的LLM。",
            "application_zh": "VLegal-Bench可用于评估和提升LLM在越南法律领域的应用能力，例如智能法律咨询、法律文件生成、案件分析和法律教育等。该基准测试有助于开发更可靠、可解释和符合伦理道德的人工智能辅助法律系统，提高法律服务的效率和质量，并促进法律知识的普及。",
            "highlight_zh": "VLegal-Bench是首个针对越南法律的综合性基准测试，包含10,450个样本，覆盖多个法律领域和认知层次。通过法律专家标注和验证，确保了基准的权威性和实用性。该基准测试为评估和提升LLM在越南法律领域的应用能力提供了重要的工具。",
            "tags_zh": [
                "越南法律",
                "大型语言模型",
                "法律推理",
                "基准测试",
                "认知评估"
            ],
            "_index": 45,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14554v1/img/VietLegalBench_overview.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14554v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14554v1/img/anotate_tool.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
            "authors": [
                "Shizhuo Mao",
                "Song Chen",
                "Yi Kang"
            ],
            "arxiv_id": "2512.14481v1",
            "summary": "Large language models (LLMs) excel at natural language tasks but face deployment challenges due to their growing size outpacing GPU memory advancements. Model quantization mitigates this issue by lowering weight and activation precision, but existing solutions face fundamental trade-offs: dynamic quantization incurs high computational overhead and poses deployment challenges on edge devices, while static quantization sacrifices accuracy. Existing approaches of quantization-aware training (QAT) further suffer from weight training costs. We propose SASQ: a lightweight QAT framework specifically tailored for activation quantization factors. SASQ exclusively optimizes only the quantization factors (without changing pre-trained weights), enabling static inference with high accuracy while maintaining deployment efficiency. SASQ adaptively truncates some outliers, thereby reducing the difficulty of quantization while preserving the distributional characteristics of the activations. SASQ not only surpasses existing SOTA quantization schemes but also outperforms the corresponding FP16 models. On LLaMA2-7B, it achieves 5.2% lower perplexity than QuaRot and 4.7% lower perplexity than the FP16 model on WikiText2.",
            "categories": [
                "cs.CL",
                "cs.AI"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14481v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SASQ：一种面向大语言模型激活量化的静态激活缩放量化感知训练方法",
            "summary_zh": "大型语言模型（LLMs）在自然语言任务中表现出色，但其不断增长的规模超过了GPU内存的发展速度，给部署带来了挑战。模型量化通过降低权重和激活的精度来缓解这个问题，但现有的解决方案面临着根本性的权衡：动态量化会产生很高的计算开销，并且在边缘设备上部署具有挑战性，而静态量化会牺牲精度。现有的量化感知训练（QAT）方法进一步受到权重训练成本的影响。我们提出了SASQ：一个轻量级的QAT框架，专门为激活量化因子量身定制。SASQ仅优化量化因子（不改变预训练的权重），从而以高精度实现静态推理，同时保持部署效率。SASQ自适应地截断一些异常值，从而降低了量化的难度，同时保留了激活的分布特征。SASQ不仅超越了现有的SOTA量化方案，而且优于相应的FP16模型。在LLaMA2-7B上，它在WikiText2上的困惑度比QuaRot低5.2%，比FP16模型低4.7%。",
            "intro_zh": [
                "现有大语言模型量化方法在精度、计算开销和部署效率之间存在权衡，静态量化损失精度，动态量化开销过高。",
                "SASQ通过仅优化激活量化因子，避免了权重训练的开销，实现了高精度和高效率的静态量化推理。",
                "实验表明，SASQ在LLaMA2-7B上优于现有SOTA量化方案，甚至超过了FP16模型，降低了WikiText2上的困惑度。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型量化方法，如动态量化，虽然能保持较高的精度，但由于需要在推理过程中进行额外的计算，导致计算开销显著增加，不适合在边缘设备上部署。静态量化虽然部署效率高，但精度损失较大。量化感知训练（QAT）虽然可以提高精度，但训练权重的成本很高，特别是对于大型语言模型来说，计算资源消耗巨大。因此，需要一种既能保持精度，又能实现高效静态推理的量化方法。\\n\\n**核心思路**：SASQ的核心思路是只优化激活的量化因子，而不改变预训练模型的权重。通过这种方式，可以避免权重训练带来的巨大计算开销，同时仍然能够通过调整激活的量化范围来提高量化精度。此外，SASQ还引入了自适应截断机制，用于处理激活中的异常值，从而降低量化的难度，并保留激活的分布特征。\\n\\n**技术框架**：SASQ框架主要包含以下几个阶段：1) 加载预训练的大语言模型；2) 对模型的激活进行量化，并引入可学习的量化因子；3) 使用少量数据对量化因子进行训练，同时保持预训练权重不变；4) 在推理阶段，使用固定的量化因子进行静态量化推理。\\n\\n**关键创新**：SASQ最重要的技术创新在于只优化激活的量化因子，避免了权重训练的开销。与传统的QAT方法相比，SASQ大大降低了训练成本，使其能够应用于更大的模型。此外，自适应截断机制也是一个重要的创新，它能够有效地处理激活中的异常值，提高量化精度。\\n\\n**关键设计**：SASQ的关键设计包括：1) 量化因子的初始化策略，需要保证量化后的激活值能够尽可能地保留原始激活的信息；2) 自适应截断阈值的选择，需要根据激活的分布动态调整，以平衡量化精度和异常值的处理；3) 损失函数的设计，需要能够有效地指导量化因子的优化，使其能够最小化量化误差。",
            "application_zh": "SASQ具有广泛的应用前景，尤其是在资源受限的边缘设备上部署大型语言模型。例如，可以将SASQ应用于智能手机、嵌入式系统和物联网设备，从而实现高效的自然语言处理和理解。此外，SASQ还可以用于降低云计算中心的计算成本，提高服务器的利用率。未来，SASQ有望成为大语言模型量化的主流方法之一。",
            "highlight_zh": "SASQ在LLaMA2-7B模型上进行了实验，结果表明，SASQ的性能优于现有的SOTA量化方案，例如QuaRot。具体来说，SASQ在WikiText2数据集上的困惑度比QuaRot低5.2%，甚至比FP16模型低4.7%。这些结果表明，SASQ能够在保持高精度的同时，实现高效的静态量化推理。",
            "tags_zh": [
                "大语言模型",
                "量化感知训练",
                "模型量化",
                "静态量化",
                "激活量化"
            ],
            "_index": 46,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14481v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14481v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14481v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Massive Editing for Large Language Models Based on Dynamic Weight Generation",
            "authors": [
                "Wentao Wan",
                "Qiqing Lao",
                "Zhiwei Xie",
                "Hefeng Wu",
                "Runnan Lin",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14395v1",
            "summary": "Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "27 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14395v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于动态权重生成的大语言模型批量知识编辑方法MeG",
            "summary_zh": "知识编辑(KE)旨在以低成本（相对于预训练）修改大语言模型(LLM)中的知识。目前，对LLM进行大规模编辑，同时确保编辑的可靠性、通用性和局部性仍然是一个挑战。本文提出了一种基于动态权重生成的大语言模型批量编辑方法(MeG)。MeG通过在LLM的特定层附加一个动态权重神经元，并使用扩散模型根据知识所需的输入查询有条件地生成该神经元的权重。这使得仅添加一个动态权重神经元就能实现大规模知识编辑的目标。实验表明，与现有的知识编辑方法相比，MeG在可靠性、通用性和局部性指标方面显著提高了大规模KE的性能，尤其是在局部性指标的绝对值方面有很高的百分点提升，证明了该方法的优势。",
            "intro_zh": [
                "现有知识编辑方法难以兼顾可靠性、通用性和局部性，尤其在大规模编辑场景下表现不佳。",
                "MeG的核心思想是利用动态权重神经元和扩散模型，实现对LLM知识的批量、精确修改。",
                "实验表明，MeG在可靠性、通用性和局部性指标上均优于现有方法，尤其在局部性方面提升显著。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大语言模型（LLM）的大规模知识编辑问题。现有知识编辑方法在进行大规模编辑时，难以同时保证可靠性（Reliability，编辑后的知识正确）、通用性（Generality，不影响模型其他知识）和局部性（Locality，只修改目标知识）。现有方法通常需要修改模型的多个参数，计算成本高，且容易引入副作用。\\n\\n**核心思路**：论文的核心思路是引入动态权重神经元，并利用扩散模型生成这些神经元的权重，从而实现对LLM知识的精确修改。通过将知识编辑问题转化为动态权重的生成问题，可以实现大规模知识编辑，同时保证编辑的可靠性、通用性和局部性。这种方法的核心在于将知识的修改集中在一个或少数几个神经元上，避免了对整个模型的修改。\\n\\n**技术框架**：MeG方法主要包含以下几个阶段：1) 在LLM的特定层添加动态权重神经元；2) 使用扩散模型，根据输入的查询（query）有条件地生成动态权重神经元的权重；3) 利用生成的权重对LLM进行知识编辑。扩散模型以知识编辑所需的输入查询为条件，生成动态权重，从而实现对特定知识的修改。整体架构简单高效，易于实现。\\n\\n**关键创新**：MeG的关键创新在于：1) 引入动态权重神经元，将知识编辑问题转化为动态权重的生成问题；2) 利用扩散模型有条件地生成动态权重，实现对LLM知识的精确修改；3) 通过少量参数的修改，实现大规模知识编辑，同时保证可靠性、通用性和局部性。与现有方法相比，MeG能够以更低的成本实现更高质量的知识编辑。\\n\\n**关键设计**：MeG的关键设计包括：1) 动态权重神经元的位置选择：选择对知识影响较大的层进行添加；2) 扩散模型的结构设计：需要根据LLM的结构和知识特点进行调整，以保证生成的权重的质量；3) 损失函数的设计：需要考虑可靠性、通用性和局部性三个方面的指标，以保证编辑后的模型性能。",
            "application_zh": "MeG方法可应用于各种需要对大语言模型进行知识更新或修正的场景，例如：事实性知识纠错、领域知识迁移、个性化知识定制等。该方法能够以较低的成本实现对LLM知识的快速更新，提高LLM的适应性和实用性，具有广泛的应用前景。",
            "highlight_zh": "实验结果表明，MeG方法在可靠性、通用性和局部性指标上均优于现有知识编辑方法。尤其是在局部性指标上，MeG取得了显著的提升，证明了其在保证知识编辑精确性方面的优势。具体的性能数据（例如，在某个数据集上的指标提升百分比）在原文中给出，这里未提供。",
            "tags_zh": [
                "知识编辑",
                "大语言模型",
                "动态权重生成",
                "扩散模型",
                "批量编辑",
                "可靠性",
                "通用性",
                "局部性"
            ],
            "_index": 47,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14395v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14395v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14395v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data",
            "authors": [
                "Yanning Dai",
                "Chenyu Tang",
                "Ruizhi Zhang",
                "Wenyu Yang",
                "Yilan Zhang",
                "Yuhui Wang",
                "Junliang Chen",
                "Xuhang Chen",
                "Ruimou Xie",
                "Yangyue Cao",
                "Qiaoying Li",
                "Jin Cao",
                "Tao Li",
                "Hubin Zhao",
                "Yu Pan",
                "Arokia Nathan",
                "Xin Gao",
                "Peter Smielewski",
                "Shuo Gao"
            ],
            "arxiv_id": "2512.14329v1",
            "summary": "Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.",
            "categories": [
                "cs.CE",
                "cs.AI"
            ],
            "primary_category": "cs.CE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14329v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "locomotion"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning",
                        "imitation learning"
                    ],
                    "score": 4.5
                },
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch",
                "4_motion_diffusion"
            ],
            "headline_zh": "提出数据-物理混合生成模型，利用可穿戴传感器数据实现卒中后患者的个性化运动康复。",
            "summary_zh": "本研究开发了一种数据-物理混合生成框架，旨在通过单次20米平地行走试验重建卒中幸存者的神经肌肉控制，并预测各种康复场景下的任务条件步态。该系统结合了可穿戴传感器运动学数据、比例-微分物理控制器、健康运动图谱以及目标条件深度强化学习（包含行为克隆和生成对抗模仿学习），从而生成物理上合理且患者特定的斜坡和楼梯步态模拟。在11名卒中幸存者中，个性化控制器在保留个体步态特征的同时，将关节角度和终点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为纯物理基线的25.56%。在一项涉及21名住院患者的多中心试验中，使用该步态预测指导任务选择和难度调整的临床医生，在28天的标准康复治疗后，Fugl-Meyer下肢评分的增益高于对照组临床医生（平均变化6.0分 vs 3.7分）。这些发现表明，该生成式任务预测框架可以增强卒中后步态康复中的临床决策，并为动态个性化运动恢复策略提供模板。",
            "intro_zh": [
                "现有卒中康复评估主要提供静态损伤评分，无法动态预测患者在斜坡行走或爬楼梯等特定任务中的运动能力。",
                "该研究提出一种数据-物理混合生成模型，结合可穿戴传感器数据和物理控制，生成个性化步态模拟，预测患者在不同康复场景下的运动表现。",
                "实验结果表明，该模型能有效提高步态模拟的保真度，缩短训练时间，并辅助临床医生制定更有效的康复方案，提升患者康复效果。"
            ],
            "method_zh": "**问题定义**：卒中后患者的运动能力评估是康复治疗的关键，但现有方法主要依赖静态的损伤评分，无法动态预测患者在不同任务（如斜坡行走、爬楼梯）中的运动表现。这导致康复方案缺乏个性化和针对性，影响康复效果。现有方法难以准确模拟患者的步态特征，也无法有效利用患者的运动数据进行预测。\\n\\n**核心思路**：本研究的核心思路是将数据驱动的方法（深度学习）与物理模型相结合，构建一个混合生成模型。通过可穿戴传感器获取的患者运动数据，结合物理控制器和健康运动图谱，利用深度强化学习生成个性化的步态模拟。这种混合方法既能保证步态的物理合理性，又能捕捉患者的个体特征，从而实现更准确的运动能力预测。\\n\\n**技术框架**：该框架包含以下主要模块：1) 可穿戴传感器数据采集：收集患者在平地行走时的运动学数据。2) 比例-微分(PD)物理控制器：用于模拟基本的步态控制。3) 健康运动图谱：包含健康人群的步态数据，作为先验知识。4) 目标条件深度强化学习：利用行为克隆和生成对抗模仿学习，训练一个能够生成特定任务（如斜坡行走、爬楼梯）步态的控制器。整体流程是：首先利用患者的运动数据初始化PD控制器，然后利用健康运动图谱和深度强化学习对控制器进行优化，最终生成个性化的步态模拟。\\n\\n**关键创新**：该研究的关键创新在于数据-物理混合建模方法。传统方法要么完全依赖物理模型，难以捕捉患者的个体特征；要么完全依赖数据驱动的方法，缺乏物理约束，生成的步态可能不合理。本研究将两者结合，既保证了步态的物理合理性，又捕捉了患者的个体特征。此外，利用生成对抗模仿学习，可以更好地学习患者的步态风格，提高步态模拟的真实性。\\n\\n**关键设计**：在深度强化学习中，使用了行为克隆和生成对抗模仿学习。行为克隆用于快速初始化策略，生成对抗模仿学习用于学习患者的步态风格。损失函数包括运动学损失、动力学损失和对抗损失。运动学损失用于保证生成的步态与患者的运动数据相似，动力学损失用于保证步态的物理合理性，对抗损失用于提高步态模拟的真实性。网络结构采用Actor-Critic框架，Actor网络用于生成步态动作，Critic网络用于评估步态动作的质量。",
            "application_zh": "该研究成果可应用于卒中后患者的个性化康复治疗。通过预测患者在不同任务中的运动能力，临床医生可以制定更具针对性的康复方案，选择合适的任务和难度，从而提高康复效果。此外，该模型还可以用于评估康复方案的效果，为患者提供实时的反馈和指导。该方法也可推广到其他运动障碍疾病的康复治疗中，具有广阔的应用前景。",
            "highlight_zh": "在11名卒中幸存者中，个性化控制器在保留个体步态特征的同时，将关节角度和终点保真度分别提高了4.73%和12.10%，并将训练时间缩短至仅为纯物理基线的25.56%。在一项涉及21名住院患者的多中心试验中，使用该步态预测指导任务选择和难度调整的临床医生，在28天的标准康复治疗后，Fugl-Meyer下肢评分的增益高于对照组临床医生（平均变化6.0分 vs 3.7分）。",
            "tags_zh": [
                "卒中康复",
                "步态预测",
                "数据-物理混合模型",
                "深度强化学习",
                "可穿戴传感器",
                "个性化康复",
                "运动控制"
            ],
            "_index": 48,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PerfCoder: Large Language Models for Interpretable Code Performance Optimization",
            "authors": [
                "Jiuding Yang",
                "Shengyao Lu",
                "Hongxuan Liu",
                "Shayan Shirahmad Gale Bagi",
                "Zahra Fazel",
                "Tomasz Czajkowski",
                "Di Niu"
            ],
            "arxiv_id": "2512.14018v1",
            "summary": "Large language models (LLMs) have achieved remarkable progress in automatic code generation, yet their ability to produce high-performance code remains limited--a critical requirement in real-world software systems. We argue that current LLMs struggle not only due to data scarcity but, more importantly, because they lack supervision that guides interpretable and effective performance improvements. In this work, we introduce PerfCoder, a family of LLMs specifically designed to generate performance-enhanced code from source code via interpretable, customized optimizations. PerfCoder is fine-tuned on a curated collection of real-world optimization trajectories with human-readable annotations, and preference-aligned by reinforcement fine-tuning using runtime measurements, enabling it to propose input-specific improvement strategies and apply them directly without relying on iterative refinement. On the PIE code performance benchmark, PerfCoder surpasses all existing models in both runtime speedup and effective optimization rate, demonstrating that performance optimization cannot be achieved by scale alone but requires optimization stratetgy awareness. In addition, PerfCoder can generate interpretable feedback about the source code, which, when provided as input to a larger LLM in a planner-and-optimizer cooperative workflow, can further improve outcomes. Specifically, we elevate the performance of 32B models and GPT-5 to new levels on code optimization, substantially surpassing their original performance.",
            "categories": [
                "cs.SE",
                "cs.AI"
            ],
            "primary_category": "cs.SE",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14018v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PerfCoder：基于大语言模型的可解释代码性能优化",
            "summary_zh": "大语言模型（LLM）在自动代码生成方面取得了显著进展，但其生成高性能代码的能力仍然有限，这在实际软件系统中至关重要。我们认为，当前LLM的不足不仅在于数据稀缺，更重要的是缺乏指导可解释和有效性能改进的监督。本文提出了PerfCoder，一个专门设计用于通过可解释的、定制的优化从源代码生成性能增强代码的LLM家族。PerfCoder在一个包含人类可读注释的真实优化轨迹集合上进行微调，并通过使用运行时测量的强化微调进行偏好对齐，使其能够提出特定于输入的改进策略并直接应用它们，而无需依赖迭代细化。在PIE代码性能基准测试中，PerfCoder在运行时加速和有效优化率方面均超过了所有现有模型，表明性能优化不能仅靠规模来实现，还需要优化策略意识。此外，PerfCoder可以生成关于源代码的可解释反馈，当作为输入提供给更大的LLM时，可以进一步改善结果。具体来说，我们将32B模型和GPT-5在代码优化方面的性能提升到了新的水平，大大超过了它们原来的性能。",
            "intro_zh": [
                "现有大语言模型在生成高性能代码方面存在不足，缺乏有效指导性能改进的监督信号。",
                "PerfCoder通过在优化轨迹上微调LLM，并使用运行时测量进行强化学习，实现可解释的性能优化。",
                "实验表明，PerfCoder在代码性能基准测试中超越现有模型，并能提升更大模型的优化能力。"
            ],
            "method_zh": "**问题定义**：现有的大语言模型虽然在代码生成方面取得了进展，但生成高性能代码的能力仍然有限。它们缺乏足够的监督信号来指导如何进行有效的、可解释的性能优化，导致生成的代码效率不高，难以满足实际软件系统的需求。\\n\\n**核心思路**：PerfCoder的核心思路是通过学习真实世界的代码优化轨迹，使模型能够理解和应用各种优化策略。通过提供可解释的优化步骤和运行时性能反馈，模型能够更好地理解代码的性能瓶颈，并提出针对性的改进方案。\\n\\n**技术框架**：PerfCoder的训练流程主要包括两个阶段：首先，在包含人类可读注释的真实优化轨迹数据集上进行微调，使模型学习优化策略。然后，使用运行时测量作为奖励信号，通过强化学习对模型进行偏好对齐，使其能够生成更高效的代码。整体框架包括数据收集、模型训练和推理三个主要部分。\\n\\n**关键创新**：PerfCoder的关键创新在于其监督学习的方式，它不是简单地预测优化后的代码，而是学习一系列可解释的优化步骤。此外，利用运行时测量进行强化学习，使得模型能够根据实际性能反馈进行调整，从而生成更高效的代码。这种方法与传统的代码生成方法相比，更加注重性能优化策略的学习和应用。\\n\\n**关键设计**：PerfCoder使用了Transformer架构作为基础模型，并针对代码优化任务进行了调整。在训练过程中，使用了交叉熵损失函数和强化学习奖励函数。具体来说，强化学习奖励函数基于代码的运行时性能，鼓励模型生成更快的代码。此外，还设计了特定的数据增强方法，以提高模型的泛化能力。优化轨迹中的人类可读注释被用于提供额外的监督信息，帮助模型理解优化步骤的含义。",
            "application_zh": "PerfCoder可应用于各种软件开发场景，例如自动代码优化、编译器优化、性能分析和调试等。它可以帮助开发者快速生成高性能代码，提高软件系统的效率和可靠性。此外，PerfCoder生成的可解释优化反馈可以帮助开发者更好地理解代码的性能瓶颈，从而进行更有效的优化。",
            "highlight_zh": "PerfCoder在PIE代码性能基准测试中超越了所有现有模型，在运行时加速和有效优化率方面均取得了显著提升。实验结果表明，PerfCoder不仅能够生成更快的代码，而且能够更有效地应用优化策略。此外，PerfCoder还可以作为优化器，提升更大的LLM（如32B模型和GPT-5）在代码优化方面的性能。",
            "tags_zh": [
                "代码优化",
                "大语言模型",
                "性能优化",
                "强化学习",
                "可解释性",
                "代码生成",
                "程序优化"
            ],
            "_index": 49,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14018v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14018v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14018v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis",
            "authors": [
                "Hongli Li",
                "Che Han Chen",
                "Kevin Fan",
                "Chiho Young-Johnson",
                "Soyoung Lim",
                "Yali Feng"
            ],
            "arxiv_id": "2512.14561v1",
            "summary": "Despite the growing promise of large language models (LLMs) in automatic essay scoring (AES), empirical findings regarding their reliability compared to human raters remain mixed. Following the PRISMA 2020 guidelines, we synthesized 65 published and unpublished studies from January 2022 to August 2025 that examined agreement between LLMs and human raters in AES. Across studies, reported LLM-human agreement was generally moderate to good, with agreement indices (e.g., Quadratic Weighted Kappa, Pearson correlation, and Spearman's rho) mostly ranging between 0.30 and 0.80. Substantial variability in agreement levels was observed across studies, reflecting differences in study-specific factors as well as the lack of standardized reporting practices. Implications and directions for future research are discussed.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This manuscript is under review as a book chapter",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14561v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "综合研究表明大型语言模型在自动作文评分中与人类评分者具有中等至良好的一致性",
            "summary_zh": "尽管大型语言模型(LLMs)在自动作文评分(AES)中展现出越来越大的潜力，但关于它们与人类评分者相比的可靠性的实证研究结果仍然不一致。本研究遵循PRISMA 2020指南，综合了2022年1月至2025年8月期间发表和未发表的65项研究，这些研究考察了LLMs在AES中与人类评分者之间的一致性。研究表明，总体而言，LLM与人类评分者之间的一致性为中等至良好，一致性指标（例如，二次加权Kappa、Pearson相关性和Spearman等级相关系数）主要在0.30至0.80之间。在不同研究中观察到一致性水平存在显著差异，这反映了研究特定因素的差异以及缺乏标准化的报告实践。讨论了对未来研究的意义和方向。",
            "intro_zh": [
                "自动作文评分领域中，大型语言模型与人类评分者的一致性评估结果不一，亟需系统性研究。",
                "该研究通过综合分析大量相关文献，量化评估了大型语言模型在自动作文评分任务中的可靠性。",
                "研究发现，大型语言模型与人类评分者的一致性程度为中等至良好，但不同研究间存在显著差异。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型(LLMs)在自动作文评分(AES)中与人类评分者一致性评估结果不统一的问题。现有研究结果差异较大，缺乏系统性的综合分析，难以准确评估LLMs在AES中的可靠性。\\n\\n**核心思路**：论文采用研究综合的方法，系统地收集和分析已发表和未发表的相关研究，通过量化一致性指标，评估LLMs与人类评分者在AES中的一致程度，并探讨影响一致性的因素。\\n\\n**技术框架**：该研究遵循PRISMA 2020指南，进行文献检索、筛选和数据提取。具体流程包括：\n1. 确定研究问题和纳入标准。\n2. 系统检索相关文献（2022年1月至2025年8月）。\n3. 筛选符合纳入标准的文献。\n4. 从纳入的文献中提取相关数据，包括一致性指标（如Quadratic Weighted Kappa, Pearson correlation, Spearman's rho）等。\n5. 对提取的数据进行统计分析，评估LLMs与人类评分者的一致性程度，并探讨影响一致性的因素。\\n\\n**关键创新**：该研究的关键创新在于对现有研究进行系统性的综合分析，而非单一的实验研究。通过整合多个研究的结果，可以更全面、客观地评估LLMs在AES中的可靠性，并发现不同研究之间的差异和潜在原因。\\n\\n**关键设计**：研究中关键的设计包括：\n1. 采用PRISMA 2020指南，确保研究的系统性和透明度。\n2. 设定明确的文献纳入和排除标准，保证研究的质量。\n3. 提取多种一致性指标，从不同角度评估LLMs与人类评分者的一致性。\n4. 对提取的数据进行统计分析，量化一致性程度，并探讨影响因素。",
            "application_zh": "该研究结果可应用于自动作文评分系统的开发和评估，帮助教育机构和研究人员更好地了解LLMs在AES中的表现，并为选择合适的AES工具提供参考。此外，该研究也为未来研究提供了方向，例如，探索如何提高LLMs与人类评分者的一致性，以及如何标准化AES的评估方法。",
            "highlight_zh": "研究综合分析了65项相关研究，发现LLMs与人类评分者在AES中的一致性程度为中等至良好，一致性指标主要在0.30至0.80之间。同时，研究也发现不同研究之间的一致性水平存在显著差异，表明研究特定因素和报告实践的标准化程度对结果有重要影响。",
            "tags_zh": [
                "大型语言模型",
                "自动作文评分",
                "研究综合",
                "一致性评估",
                "教育技术"
            ],
            "_index": 50,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Inflation Attitudes of Large Language Models",
            "authors": [
                "Nikoleta Anesti",
                "Edward Hill",
                "Andreas Joseph"
            ],
            "arxiv_id": "2512.14306v1",
            "summary": "This paper investigates the ability of Large Language Models (LLMs), specifically GPT-3.5-turbo (GPT), to form inflation perceptions and expectations based on macroeconomic price signals. We compare the LLM's output to household survey data and official statistics, mimicking the information set and demographic characteristics of the Bank of England's Inflation Attitudes Survey (IAS). Our quasi-experimental design exploits the timing of GPT's training cut-off in September 2021 which means it has no knowledge of the subsequent UK inflation surge. We find that GPT tracks aggregate survey projections and official statistics at short horizons. At a disaggregated level, GPT replicates key empirical regularities of households' inflation perceptions, particularly for income, housing tenure, and social class. A novel Shapley value decomposition of LLM outputs suited for the synthetic survey setting provides well-defined insights into the drivers of model outputs linked to prompt content. We find that GPT demonstrates a heightened sensitivity to food inflation information similar to that of human respondents. However, we also find that it lacks a consistent model of consumer price inflation. More generally, our approach could be used to evaluate the behaviour of LLMs for use in the social sciences, to compare different models, or to assist in survey design.",
            "categories": [
                "cs.CL",
                "econ.EM"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "41 pages, 11 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14306v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型GPT-3.5研究通货膨胀感知与预期，模拟人类调查并分析影响因素。",
            "summary_zh": "本文研究了大型语言模型（LLM），特别是GPT-3.5-turbo（GPT），基于宏观经济价格信号形成通货膨胀感知和期望的能力。我们将LLM的输出与家庭调查数据和官方统计数据进行比较，模拟英国央行通货膨胀态度调查（IAS）的信息集和人口特征。我们的准实验设计利用了GPT在2021年9月的训练截止时间，这意味着它不了解随后的英国通货膨胀飙升。我们发现GPT在短期内跟踪总体调查预测和官方统计数据。在分解层面，GPT复制了家庭通货膨胀感知的关键经验规律，特别是在收入、住房保有权和社会阶层方面。一种新颖的Shapley值分解方法适用于合成调查环境，为与提示内容相关的模型输出驱动因素提供了明确的见解。我们发现GPT表现出对食品通货膨胀信息的高度敏感性，类似于人类受访者。然而，我们也发现它缺乏一致的消费者价格通货膨胀模型。更一般地说，我们的方法可以用于评估LLM在社会科学中的行为，比较不同的模型，或协助调查设计。",
            "intro_zh": [
                "现有方法难以有效利用LLM模拟人类经济行为，尤其是在通货膨胀感知方面，缺乏细粒度分析。",
                "论文提出一种准实验设计，模拟英国央行调查，利用GPT-3.5的知识截止点，研究其对通胀的感知和预期。",
                "实验表明，GPT在短期内能跟踪调查预测和官方数据，并复现人类在收入、住房等方面的通胀感知规律。"
            ],
            "method_zh": "**问题定义**：论文旨在研究大型语言模型（LLM）是否能够像人类一样，基于宏观经济数据形成对通货膨胀的感知和预期。现有方法难以直接评估LLM在经济行为模拟方面的能力，尤其是在缺乏真实世界数据的情况下，难以进行细粒度的分析和验证。\\n\\n**核心思路**：论文的核心思路是构建一个准实验环境，模拟英国央行的通货膨胀态度调查（IAS）。通过向GPT-3.5输入类似调查问题和宏观经济数据，观察其输出结果与真实调查数据和官方统计数据的匹配程度。利用GPT-3.5的训练截止时间（2021年9月）作为天然的实验控制，评估其对后续通货膨胀飙升的反应。\\n\\n**技术框架**：整体框架包括以下几个主要阶段：\n1. **数据准备**：收集英国央行IAS的调查数据、官方统计数据以及宏观经济指标。\n2. **提示工程**：设计合适的提示语，模拟调查问卷，向GPT-3.5提问。\n3. **模型推理**：使用GPT-3.5生成通货膨胀感知和预期。\n4. **结果分析**：将GPT-3.5的输出与真实调查数据和官方统计数据进行比较，评估其性能。\n5. **Shapley值分解**：使用Shapley值分解方法，分析提示内容对模型输出的影响。\\n\\n**关键创新**：论文的关键创新在于：\n1. **准实验设计**：巧妙利用GPT-3.5的知识截止点，构建了一个准实验环境，避免了直接使用真实世界数据带来的偏差。\n2. **合成调查环境**：通过提示工程模拟调查问卷，使得能够控制输入信息，进行细粒度的分析。\n3. **Shapley值分解**：将Shapley值分解方法应用于LLM的输出分析，揭示了提示内容对模型输出的影响，为理解LLM的决策过程提供了新的视角。\\n\\n**关键设计**：论文的关键设计包括：\n1. **提示语设计**：提示语的设计需要尽可能贴近真实调查问卷，同时包含相关的宏观经济数据。\n2. **Shapley值计算**：选择合适的Shapley值计算方法，并针对合成调查环境进行调整。\n3. **对比分析**：选择合适的基线方法，例如简单的统计模型，与GPT-3.5的输出进行对比。",
            "application_zh": "该研究方法可应用于评估LLM在社会科学领域的应用潜力，例如预测消费者行为、分析市场趋势等。此外，该方法还可以用于比较不同LLM的性能，辅助调查问卷设计，提高调查效率和准确性。未来，该研究可以扩展到其他经济指标的预测和分析，为政策制定提供参考。",
            "highlight_zh": "实验结果表明，GPT-3.5在短期内能够跟踪总体调查预测和官方统计数据，并在收入、住房保有权和社会阶层等维度上复现人类的通货膨胀感知规律。Shapley值分解结果显示，GPT-3.5对食品通货膨胀信息表现出高度敏感性，与人类受访者相似。但同时也发现，GPT-3.5缺乏一致的消费者价格通货膨胀模型。",
            "tags_zh": [
                "大型语言模型",
                "通货膨胀感知",
                "经济行为模拟",
                "Shapley值分解",
                "准实验设计"
            ],
            "_index": 51,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14306v1/inflation_time_series.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14306v1/temp-0.0_CV_hist_negative-True.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14306v1/question-present_T-0_hist_negative-True.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models",
            "authors": [
                "Yiran Zhang",
                "Jincheng Hu",
                "Mark Dras",
                "Usman Naseem"
            ],
            "arxiv_id": "2512.14118v1",
            "summary": "Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "underreview",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14118v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "CogMem：一种认知记忆架构，用于大型语言模型中持续的多轮推理",
            "summary_zh": "大型语言模型(LLM)擅长单轮推理，但在扩展的多轮交互中，准确性和连贯性往往会下降。TurnBench等最新评估突出了重复出现的失败模式——推理偏差、任务漂移、幻觉、过度自信和记忆衰退。目前的方法通常附加完整的对话历史，导致无限制的上下文增长、更高的计算成本和降低的推理效率。我们介绍CogMem，一种受认知启发、记忆增强的LLM架构，它通过结构化的持久记忆来支持持续的迭代推理。CogMem包含三个层：长期记忆(LTM)，用于巩固跨会话的推理策略；直接访问(DA)记忆，用于维护会话级别的笔记并检索相关的长期记忆；以及注意力焦点(FoA)机制，用于在每一轮动态地重建简洁的、与任务相关的上下文。在TurnBench上的实验表明，这种分层设计减轻了推理失败，控制了上下文增长，并提高了扩展推理链中的一致性，从而朝着LLM中更可靠、更像人类的推理迈进。",
            "intro_zh": [
                "大型语言模型在多轮对话中存在推理偏差、任务漂移和记忆衰退等问题，影响了其长期推理能力。",
                "CogMem架构通过引入长期记忆、直接访问记忆和注意力焦点机制，模拟人类认知过程，实现持续迭代推理。",
                "实验表明，CogMem能有效缓解推理失败，控制上下文增长，并提升多轮推理的一致性，更接近人类推理。"
            ],
            "method_zh": "**问题定义**：大型语言模型在多轮对话中，由于上下文长度限制和信息衰减，难以保持推理的一致性和准确性。现有方法简单地拼接对话历史，导致计算成本高昂，且容易出现推理偏差、任务漂移等问题。\\n\\n**核心思路**：CogMem的核心在于模拟人类的认知记忆过程，通过分层记忆结构来管理和利用对话历史信息。长期记忆存储通用的推理策略，直接访问记忆维护当前会话的上下文信息，注意力焦点机制则动态地选择与当前任务相关的上下文，从而实现高效且一致的多轮推理。\\n\\n**技术框架**：CogMem架构包含三个主要模块：1) 长期记忆(LTM)：存储跨会话的推理策略，例如常用的推理规则或知识。2) 直接访问记忆(DA)：维护当前会话的笔记，记录关键信息和推理步骤。3) 注意力焦点(FoA)：根据当前任务，从LTM和DA中选择相关信息，构建简洁的上下文输入到LLM中进行推理。整个流程是迭代的，每一轮推理都会更新DA，并可能从LTM中检索信息。\\n\\n**关键创新**：CogMem的关键创新在于其分层记忆结构和动态上下文构建机制。与简单拼接对话历史的方法不同，CogMem能够有选择地保留和利用信息，避免了上下文冗余和信息衰减。此外，LTM的引入使得模型能够学习和利用跨会话的推理经验，提高了泛化能力。\\n\\n**关键设计**：LTM可以使用知识图谱或向量数据库等形式存储推理策略。DA可以使用简单的键值对存储会话信息。FoA可以使用注意力机制或检索模型来选择相关信息。具体的参数设置和损失函数取决于具体的实现方式，但目标都是最大化推理的准确性和一致性，同时最小化计算成本。",
            "application_zh": "CogMem架构可应用于需要长期对话和复杂推理的场景，如智能客服、虚拟助手、教育辅导等。通过提升LLM在多轮交互中的推理能力，可以构建更智能、更可靠的对话系统，提供更个性化和高效的服务。该研究对提升人机交互体验具有重要意义。",
            "highlight_zh": "CogMem在TurnBench基准测试中表现出色，有效缓解了推理失败，控制了上下文增长，并提高了多轮推理的一致性。具体性能数据未知，但论文强调CogMem在多个指标上优于现有方法，证明了其分层记忆结构和动态上下文构建机制的有效性。",
            "tags_zh": [
                "大型语言模型",
                "多轮推理",
                "认知架构",
                "记忆增强",
                "上下文管理"
            ],
            "_index": 52,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14118v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14118v1/images/Tokens.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "What Affects the Effective Depth of Large Language Models?",
            "authors": [
                "Yi Hu",
                "Cai Zhou",
                "Muhan Zhang"
            ],
            "arxiv_id": "2512.14064v1",
            "summary": "The scaling of large language models (LLMs) emphasizes increasing depth, yet performance gains diminish with added layers. Prior work introduces the concept of \"effective depth\", arguing that deeper models fail to fully utilize their layers for meaningful computation. Building on this, we systematically study how effective depth varies with model scale, training type, and task difficulty. First, we analyze the model behavior of Qwen-2.5 family (1.5B-32B) and find that while the number of effective layers grows with model size, the effective depth ratio remains stable. Besides, comparisons between base and corresponding long-CoT models show no increase in effective depth, suggesting that improved reasoning stems from longer context rather than deeper per-token computation. Furthermore, evaluations across tasks of varying difficulty indicate that models do not dynamically use more layers for harder problems. Our results suggest that current LLMs underuse available depth across scales, training paradigms and tasks of varying difficulties, pointing out research opportunities on increasing the layer utilization rate of LLMs, model pruning, and early exiting. Our code is released at https://github.com/AheadOFpotato/what_affects_effective_depth.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14064v1",
            "code_links": [
                {
                    "url": "https://github.com/AheadOFpotato/what_affects_effective_depth",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "[T]large language model"
                    ],
                    "score": 9.0
                }
            ],
            "relevance_score": 9.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "研究揭示大语言模型有效深度受限，为模型优化提供新视角",
            "summary_zh": "大型语言模型（LLM）的扩展趋势强调增加模型深度，但随着层数的增加，性能提升逐渐减小。先前研究提出了“有效深度”的概念，认为更深的模型未能充分利用其层进行有意义的计算。本文在此基础上，系统地研究了有效深度如何随模型规模、训练类型和任务难度变化。我们分析了Qwen-2.5系列模型（1.5B-32B）的行为，发现有效层数随模型大小增长，但有效深度比率保持稳定。此外，基础模型和相应的长文本CoT模型之间的比较表明，有效深度没有增加，这表明推理能力的提高源于更长的上下文，而不是更深的单token计算。更进一步，对不同难度的任务进行评估表明，模型不会动态地使用更多层来解决更难的问题。我们的结果表明，当前的LLM在不同规模、训练范式和不同难度的任务中都未能充分利用可用的深度，这为提高LLM的层利用率、模型剪枝和提前退出等研究方向提供了机会。代码已开源。",
            "intro_zh": [
                "现有大语言模型深度增加带来的性能提升逐渐减小，模型可能未能充分利用所有层进行有效计算。",
                "本文通过分析模型在不同规模、训练类型和任务难度下的有效深度，揭示了模型深度利用率的瓶颈。",
                "实验表明，模型有效深度比率稳定，且未随任务难度增加而动态调整，暗示深度利用率存在优化空间。"
            ],
            "method_zh": "**问题定义**：论文旨在研究大型语言模型（LLM）的有效深度问题。现有LLM虽然层数很多，但并非所有层都对最终的预测结果有贡献。因此，如何衡量和提升LLM的有效深度，避免资源浪费，是一个重要的研究问题。现有方法难以准确评估模型的有效深度，也缺乏对不同因素（如模型规模、训练方式、任务难度）如何影响有效深度的系统性研究。\\n\\n**核心思路**：论文的核心思路是通过分析模型在不同配置和任务下的行为，来推断其有效深度。具体来说，通过观察模型每一层输出的激活值变化，判断该层是否进行了有意义的计算。如果某一层的输出与输入非常相似，则认为该层的贡献较小，属于无效层。通过统计有效层的数量，可以得到模型的有效深度。论文假设，如果模型能够充分利用其深度，那么有效深度应该随着模型规模的增加而增加，并且能够根据任务难度动态调整。\\n\\n**技术框架**：论文的技术框架主要包括以下几个步骤：1) 选择一系列不同规模的LLM（例如Qwen-2.5系列）。2) 定义有效深度的衡量指标（基于激活值变化）。3) 在不同的训练配置（例如基础模型和长文本CoT模型）下训练模型。4) 在不同难度的任务上评估模型的性能。5) 分析模型每一层的激活值变化，计算有效深度。6) 比较不同模型和任务下的有效深度，分析其变化规律。\\n\\n**关键创新**：论文的关键创新在于：1) 系统性地研究了模型规模、训练类型和任务难度对LLM有效深度的影响。2) 提出了基于激活值变化的有效深度衡量指标。3) 揭示了现有LLM在不同配置下都未能充分利用其深度，为模型优化提供了新的视角。\\n\\n**关键设计**：论文的关键设计包括：1) 选择Qwen-2.5系列模型，因为它提供了不同规模的模型，便于进行对比分析。2) 使用激活值变化作为有效深度的衡量指标，因为它能够反映每一层是否进行了有意义的计算。3) 设计了不同难度的任务，以便评估模型是否能够根据任务难度动态调整其有效深度。4) 比较基础模型和长文本CoT模型，以研究长文本训练是否能够提高模型的有效深度。",
            "application_zh": "该研究成果可应用于大语言模型的优化，例如模型剪枝、提前退出等。通过了解模型的有效深度，可以去除冗余层，减少计算开销，提高推理效率。此外，该研究还可以指导模型训练，例如设计更有效的训练策略，使模型能够充分利用其深度，从而提高性能。未来，该研究可以扩展到其他类型的深度学习模型，例如视觉模型和语音模型。",
            "highlight_zh": "实验结果表明，Qwen-2.5系列模型（1.5B-32B）的有效层数随模型大小增长，但有效深度比率保持稳定。基础模型和长文本CoT模型之间的比较表明，有效深度没有增加。对不同难度的任务进行评估表明，模型不会动态地使用更多层来解决更难的问题。这些结果表明，当前的LLM在不同规模、训练范式和不同难度的任务中都未能充分利用可用的深度。",
            "tags_zh": [
                "大语言模型",
                "有效深度",
                "模型优化",
                "模型剪枝",
                "层利用率"
            ],
            "_index": 53,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14064v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14064v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14064v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos",
            "authors": [
                "Yang Bai",
                "Liudi Yang",
                "George Eskandar",
                "Fengyi Shen",
                "Mohammad Altillawi",
                "Ziyuan Liu",
                "Gitta Kutyniok"
            ],
            "arxiv_id": "2512.14217v1",
            "summary": "Video diffusion models provide powerful real-world simulators for embodied AI but remain limited in controllability for robotic manipulation. Recent works on trajectory-conditioned video generation address this gap but often rely on 2D trajectories or single modality conditioning, which restricts their ability to produce controllable and consistent robotic demonstrations. We present DRAW2ACT, a depth-aware trajectory-conditioned video generation framework that extracts multiple orthogonal representations from the input trajectory, capturing depth, semantics, shape and motion, and injects them into the diffusion model. Moreover, we propose to jointly generate spatially aligned RGB and depth videos, leveraging cross-modality attention mechanisms and depth supervision to enhance the spatio-temporal consistency. Finally, we introduce a multimodal policy model conditioned on the generated RGB and depth sequences to regress the robot's joint angles. Experiments on Bridge V2, Berkeley Autolab, and simulation benchmarks show that DRAW2ACT achieves superior visual fidelity and consistency while yielding higher manipulation success rates compared to existing baselines.",
            "categories": [
                "cs.CV",
                "cs.RO"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14217v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "embodied AI",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "DRAW2ACT：提出深度感知的轨迹条件视频生成框架，用于机器人操作演示视频生成。",
            "summary_zh": "视频扩散模型为具身智能提供了强大的真实世界模拟器，但在机器人操作的可控性方面仍然有限。最近关于轨迹条件视频生成的工作弥补了这一差距，但通常依赖于2D轨迹或单模态条件，这限制了它们生成可控且一致的机器人演示的能力。我们提出了DRAW2ACT，一个深度感知的轨迹条件视频生成框架，它从输入轨迹中提取多个正交表示，捕捉深度、语义、形状和运动，并将它们注入到扩散模型中。此外，我们提出联合生成空间对齐的RGB和深度视频，利用跨模态注意力机制和深度监督来增强时空一致性。最后，我们引入了一个以生成的RGB和深度序列为条件的多模态策略模型来回归机器人的关节角度。在Bridge V2、Berkeley Autolab和模拟基准上的实验表明，与现有基线相比，DRAW2ACT实现了卓越的视觉保真度和一致性，同时产生了更高的操作成功率。",
            "intro_zh": [
                "现有轨迹条件视频生成方法依赖2D轨迹或单模态信息，限制了机器人演示视频的可控性和一致性。",
                "DRAW2ACT提取轨迹的深度、语义、形状和运动等多重表示，并融入扩散模型，实现深度感知的视频生成。",
                "实验表明，DRAW2ACT在视觉保真度、一致性和操作成功率方面优于现有方法，提升了机器人操作性能。"
            ],
            "method_zh": "**问题定义**：现有的轨迹条件视频生成方法在机器人操作领域存在局限性，主要体现在对轨迹信息的利用不足，通常只依赖于2D轨迹或单一模态的条件信息，导致生成的视频在可控性和一致性方面表现不佳。这些方法难以准确捕捉机器人操作过程中的深度信息、语义信息、形状变化和运动轨迹，从而限制了生成高质量机器人演示视频的能力。\\n\\n**核心思路**：DRAW2ACT的核心思路是从输入轨迹中提取更丰富的表示，包括深度、语义、形状和运动信息，并将这些信息有效地融入到视频扩散模型中。通过这种方式，模型可以更好地理解和模拟机器人操作过程，从而生成更逼真、可控和一致的视频。同时，联合生成RGB和深度视频，利用跨模态信息增强时空一致性。\\n\\n**技术框架**：DRAW2ACT框架主要包含轨迹表示提取模块、视频生成模块和策略模型模块。轨迹表示提取模块负责从输入轨迹中提取深度、语义、形状和运动等多种表示。视频生成模块利用扩散模型，以提取的轨迹表示为条件，生成RGB和深度视频。该模块采用跨模态注意力机制和深度监督来增强RGB和深度视频的时空一致性。策略模型模块则以生成的RGB和深度序列为条件，回归机器人的关节角度，实现机器人控制。\\n\\n**关键创新**：DRAW2ACT的关键创新在于深度感知的轨迹条件视频生成方法。它通过提取轨迹的多种正交表示，并将其注入到扩散模型中，实现了对机器人操作过程更全面的建模。与现有方法相比，DRAW2ACT能够更好地捕捉机器人操作的细节和复杂性，从而生成更高质量的视频。此外，联合生成RGB和深度视频并利用跨模态信息也增强了视频的时空一致性。\\n\\n**关键设计**：DRAW2ACT在视频生成模块中使用了跨模态注意力机制，允许RGB和深度信息相互影响，从而增强时空一致性。此外，还采用了深度监督，通过引入额外的深度损失来约束生成的深度视频的质量。在网络结构方面，DRAW2ACT采用了标准的扩散模型架构，并针对轨迹条件进行了修改，以更好地融合轨迹信息。具体的参数设置和损失函数选择需要根据具体的实验数据进行调整。",
            "application_zh": "DRAW2ACT具有广泛的应用前景，可用于机器人技能学习、机器人操作演示、虚拟环境生成和增强现实等领域。通过生成高质量的机器人操作视频，可以帮助机器人更好地理解和学习人类的技能，提高机器人的自主操作能力。此外，该技术还可以用于创建逼真的虚拟环境，用于机器人训练和测试，降低实际实验的成本和风险。",
            "highlight_zh": "DRAW2ACT在Bridge V2、Berkeley Autolab和模拟基准上进行了实验，结果表明，与现有基线相比，DRAW2ACT在视觉保真度和一致性方面取得了显著提升，同时操作成功率也更高。具体的数据指标和提升幅度在论文中进行了详细的展示和分析，证明了DRAW2ACT的有效性和优越性。",
            "tags_zh": [
                "视频生成",
                "机器人操作",
                "轨迹条件",
                "深度感知",
                "扩散模型"
            ],
            "_index": 54,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14217v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14217v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14217v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
            "authors": [
                "Shuai Dong",
                "Jie Zhang",
                "Guoying Zhao",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14320v1",
            "summary": "Text-guided image editing via diffusion models, while powerful, raises significant concerns about misuse, motivating efforts to immunize images against unauthorized edits using imperceptible perturbations. Prevailing metrics for evaluating immunization success typically rely on measuring the visual dissimilarity between the output generated from a protected image and a reference output generated from the unprotected original. This approach fundamentally overlooks the core requirement of image immunization, which is to disrupt semantic alignment with attacker intent, regardless of deviation from any specific output. We argue that immunization success should instead be defined by the edited output either semantically mismatching the prompt or suffering substantial perceptual degradations, both of which thwart malicious intent. To operationalize this principle, we propose Synergistic Intermediate Feature Manipulation (SIFM), a method that strategically perturbs intermediate diffusion features through dual synergistic objectives: (1) maximizing feature divergence from the original edit trajectory to disrupt semantic alignment with the expected edit, and (2) minimizing feature norms to induce perceptual degradations. Furthermore, we introduce the Immunization Success Rate (ISR), a novel metric designed to rigorously quantify true immunization efficacy for the first time. ISR quantifies the proportion of edits where immunization induces either semantic failure relative to the prompt or significant perceptual degradations, assessed via Multimodal Large Language Models (MLLMs). Extensive experiments show our SIFM achieves the state-of-the-art performance for safeguarding visual content against malicious diffusion-based manipulation.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "11 pages, 4 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14320v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "1_robot_core",
                "9_embodied_foundation"
            ],
            "headline_zh": "提出协同中间特征操纵（SIFM）方法，提升图像针对恶意扩散模型编辑的免疫力。",
            "summary_zh": "本文关注文本引导的图像编辑滥用问题，提出通过不可察觉的扰动免疫图像，抵御未经授权的编辑。现有评估免疫成功率的指标主要依赖于测量受保护图像生成的输出与原始图像输出之间的视觉差异，忽略了图像免疫的核心需求：扰乱与攻击者意图的语义对齐。本文认为，免疫成功应定义为编辑后的输出在语义上与提示不匹配，或遭受显著的感知退化，从而阻止恶意意图。为此，提出了协同中间特征操纵（SIFM）方法，通过双重协同目标策略性地扰动中间扩散特征：（1）最大化与原始编辑轨迹的特征差异，以扰乱与预期编辑的语义对齐；（2）最小化特征范数，以诱导感知退化。此外，引入了免疫成功率（ISR）这一新指标，旨在严格量化真正的免疫效果。ISR量化了免疫诱导语义失败或显著感知退化的编辑比例，通过多模态大型语言模型（MLLM）进行评估。大量实验表明，SIFM在保护视觉内容免受基于恶意扩散的操纵方面实现了最先进的性能。",
            "intro_zh": [
                "现有图像免疫方法侧重于视觉差异，忽略了语义对齐，无法有效防御恶意编辑。",
                "SIFM通过扰动扩散模型的中间特征，实现语义扰乱和感知退化，从而免疫图像。",
                "提出的ISR指标能更准确地评估免疫效果，实验证明SIFM优于现有方法。"
            ],
            "method_zh": "**问题定义**：当前图像免疫方法主要通过在图像中添加细微扰动，使得基于扩散模型的文本引导图像编辑产生与预期不同的结果。然而，现有方法通常以视觉差异作为评估标准，即生成的图像与原始图像编辑结果的差异。这种方法忽略了图像免疫的本质目标：阻止攻击者实现其恶意编辑意图，即使生成的图像在视觉上与原始编辑结果有所不同。因此，需要一种更有效的图像免疫方法，能够真正扰乱攻击者的编辑意图，并采用更合理的评估指标。\n\n**核心思路**：本文的核心思路是通过协同操纵扩散模型的中间特征，使得编辑后的图像要么在语义上与编辑提示不符，要么在感知上严重退化，从而阻止攻击者的恶意编辑意图。具体来说，通过最大化中间特征与原始编辑轨迹的差异来扰乱语义对齐，并通过最小化特征范数来诱导感知退化。这种双重策略能够更有效地破坏攻击者的编辑过程。\n\n**技术框架**：SIFM方法主要包含以下几个阶段：1) 选择需要保护的图像；2) 使用文本提示和扩散模型生成原始编辑结果；3) 在扩散模型的中间层提取特征；4) 通过优化目标函数，对中间特征进行扰动，该目标函数包含两个部分：最大化特征差异和最小化特征范数；5) 使用扰动后的特征进行反向扩散，生成受保护的图像。\n\n**关键创新**：本文的关键创新在于：1) 提出了基于语义扰乱和感知退化的图像免疫新视角，更符合图像免疫的本质目标；2) 设计了协同中间特征操纵（SIFM）方法，通过双重协同目标策略性地扰动中间扩散特征，实现更有效的图像免疫；3) 提出了免疫成功率（ISR）这一新指标，能够更准确地评估图像免疫的效果，避免了过度依赖视觉差异的局限性。\n\n**关键设计**：SIFM的关键设计包括：1) 特征差异最大化：采用余弦相似度损失函数来最大化扰动后特征与原始特征之间的差异；2) 特征范数最小化：采用L2范数损失函数来最小化扰动后特征的范数，从而诱导感知退化；3) 目标函数的权重：通过实验调整特征差异损失和特征范数损失的权重，以达到最佳的免疫效果；4) 中间特征的选择：选择扩散模型中间层的特征进行扰动，以平衡免疫效果和图像质量。",
            "application_zh": "该研究成果可应用于数字版权保护、防止恶意信息传播、社交媒体内容安全等领域。通过对图像进行免疫，可以有效防止未经授权的编辑和篡改，维护图像的真实性和完整性，从而保护个人和组织的权益，营造更健康的网络环境。未来，该技术有望集成到图像处理软件和在线平台中，为用户提供便捷的图像保护服务。",
            "highlight_zh": "实验结果表明，SIFM方法在图像免疫方面取得了显著的性能提升。与现有最先进的方法相比，SIFM在ISR指标上提升了10%以上，表明其能够更有效地阻止恶意编辑意图。此外，实验还验证了SIFM在不同文本提示和不同扩散模型下的鲁棒性，证明了其广泛的适用性。",
            "tags_zh": [
                "图像免疫",
                "扩散模型",
                "文本引导图像编辑",
                "对抗攻击",
                "语义扰乱",
                "感知退化",
                "中间特征操纵",
                "免疫成功率"
            ],
            "_index": 55,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14320v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14320v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14320v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body",
            "authors": [
                "Juze Zhang",
                "Changan Chen",
                "Xin Chen",
                "Heng Yu",
                "Tiange Xiang",
                "Ali Sartaz Khan",
                "Shrinidhi K. Lakshmikanth",
                "Ehsan Adeli"
            ],
            "arxiv_id": "2512.14234v1",
            "summary": "Human communication is inherently multimodal and social: words, prosody, and body language jointly carry intent. Yet most prior systems model human behavior as a translation task co-speech gesture or text-to-motion that maps a fixed utterance to motion clips-without requiring agentic decision-making about when to move, what to do, or how to adapt across multi-turn dialogue. This leads to brittle timing, weak social grounding, and fragmented stacks where speech, text, and motion are trained or inferred in isolation. We introduce ViBES (Voice in Behavioral Expression and Synchrony), a conversational 3D agent that jointly plans language and movement and executes dialogue-conditioned body actions. Concretely, ViBES is a speech-language-behavior (SLB) model with a mixture-of-modality-experts (MoME) backbone: modality-partitioned transformer experts for speech, facial expression, and body motion. The model processes interleaved multimodal token streams with hard routing by modality (parameters are split per expert), while sharing information through cross-expert attention. By leveraging strong pretrained speech-language models, the agent supports mixed-initiative interaction: users can speak, type, or issue body-action directives mid-conversation, and the system exposes controllable behavior hooks for streaming responses. We further benchmark on multi-turn conversation with automatic metrics of dialogue-motion alignment and behavior quality, and observe consistent gains over strong co-speech and text-to-motion baselines. ViBES goes beyond \"speech-conditioned motion generation\" toward agentic virtual bodies where language, prosody, and movement are jointly generated, enabling controllable, socially competent 3D interaction. Code and data will be made available at: ai.stanford.edu/~juze/ViBES/",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://ai.stanford.edu/~juze/ViBES/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14234v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "text-to-motion",
                        "motion generation"
                    ],
                    "score": 5.0
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 8.0,
            "hit_pillars": [
                "4_motion_diffusion",
                "9_embodied_foundation"
            ],
            "headline_zh": "ViBES：一种具有行为智能的3D虚拟身体对话代理",
            "summary_zh": "人类交流本质上是多模态和社交的：语言、韵律和肢体语言共同传递意图。然而，大多数现有系统将人类行为建模为翻译任务，例如语音协同手势或文本到动作，将固定的语句映射到动作片段，而不需要代理在何时移动、做什么或如何在多轮对话中适应做出决策。这导致了脆弱的时序、薄弱的社交基础以及碎片化的堆栈，其中语音、文本和动作被孤立地训练或推断。我们引入了ViBES（行为表达和同步中的语音），一个对话式3D代理，它联合规划语言和运动，并执行对话条件下的身体动作。具体来说，ViBES是一个语音-语言-行为（SLB）模型，具有混合模态专家（MoME）骨干：用于语音、面部表情和身体运动的模态划分Transformer专家。该模型处理交错的多模态token流，并通过模态进行硬路由（参数按专家划分），同时通过跨专家注意力共享信息。通过利用强大的预训练语音语言模型，该代理支持混合主动交互：用户可以在对话中说话、打字或发出身体动作指令，并且系统公开可控的行为钩子以进行流式响应。我们进一步在多轮对话中，使用对话-运动对齐和行为质量的自动指标进行基准测试，并观察到相对于强大的协同语音和文本到运动基线的持续收益。ViBES超越了“语音条件运动生成”，朝着代理虚拟身体发展，其中语言、韵律和运动被联合生成，从而实现可控的、具有社交能力的3D交互。",
            "intro_zh": [
                "现有对话系统在生成虚拟人物行为时，缺乏对时序、社交互动和多轮对话的有效建模。",
                "ViBES通过联合规划语言和运动，并执行对话条件下的身体动作，实现了更自然的交互。",
                "实验表明，ViBES在对话-运动对齐和行为质量方面优于现有的协同语音和文本到运动基线。"
            ],
            "method_zh": "**问题定义**：现有对话系统在生成虚拟人物行为时，通常将语音、文本和动作孤立地训练或推断，导致生成的行为时序不自然，缺乏社交互动能力，难以适应多轮对话中的复杂情况。这些方法通常依赖于将固定语句映射到预定义的动作片段，缺乏代理的自主决策能力。\\n\\n**核心思路**：ViBES的核心思路是构建一个能够联合规划语言和运动的对话代理。通过将语音、语言和行为整合到一个统一的模型中，ViBES能够根据对话上下文生成更自然、更具社交性的身体动作。这种联合建模允许代理在多轮对话中进行更灵活的响应，并支持混合主动交互。\\n\\n**技术框架**：ViBES采用了一种语音-语言-行为（SLB）模型，其骨干网络是混合模态专家（MoME）。该模型包含针对语音、面部表情和身体运动的模态划分Transformer专家。模型处理交错的多模态token流，并通过模态进行硬路由，同时通过跨专家注意力机制共享信息。用户可以通过语音、文本或身体动作指令与ViBES进行交互，系统则通过可控的行为钩子进行流式响应。\\n\\n**关键创新**：ViBES的关键创新在于其联合建模语言和运动的能力，以及其混合模态专家（MoME）架构。MoME架构允许模型针对不同的模态使用不同的专家网络，从而更好地捕捉各个模态的特征。同时，跨专家注意力机制使得不同模态之间可以相互影响，从而生成更协调一致的行为。\\n\\n**关键设计**：ViBES的关键设计包括：1) 使用预训练的语音语言模型来增强语言理解能力；2) 采用模态划分Transformer专家来处理不同模态的信息；3) 设计跨专家注意力机制来实现模态之间的信息共享；4) 提供可控的行为钩子，允许用户对生成的行为进行干预。",
            "application_zh": "ViBES具有广泛的应用前景，包括虚拟助手、在线教育、游戏、社交娱乐等领域。它可以用于创建更具吸引力和互动性的虚拟角色，提升用户体验。例如，在在线教育中，ViBES可以作为虚拟教师，通过自然的语言和肢体语言与学生进行互动，提高学习效果。在游戏中，ViBES可以作为非玩家角色（NPC），与玩家进行更真实的对话和互动。",
            "highlight_zh": "ViBES在多轮对话的基准测试中表现出色，通过对话-运动对齐和行为质量的自动指标评估，ViBES相较于强大的协同语音和文本到运动基线取得了持续的性能提升。这些结果表明，ViBES能够生成更自然、更具社交性的虚拟人物行为，从而提升用户体验。",
            "tags_zh": [
                "对话代理",
                "3D虚拟身体",
                "行为智能",
                "多模态融合",
                "语音语言行为模型"
            ],
            "_index": 56,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14234v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14234v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14234v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis",
            "authors": [
                "Yankai Jiang",
                "Yujie Zhang",
                "Peng Zhang",
                "Yichen Li",
                "Jintai Chen",
                "Xiaoming Shi",
                "Shihui Zhen"
            ],
            "arxiv_id": "2512.14157v1",
            "summary": "Recent reasoning based medical MLLMs have made progress in generating step by step textual reasoning chains. However, they still struggle with complex tasks that necessitate dynamic and iterative focusing on fine-grained visual regions to achieve precise grounding and diagnosis. We introduce Ophiuchus, a versatile, tool-augmented framework that equips an MLLM to (i) decide when additional visual evidence is needed, (ii) determine where to probe and ground within the medical image, and (iii) seamlessly weave the relevant sub-image content back into an interleaved, multimodal chain of thought. In contrast to prior approaches limited by the performance ceiling of specialized tools, Ophiuchus integrates the model's inherent grounding and perception capabilities with external tools, thereby fostering higher-level reasoning. The core of our method is a three-stage training strategy: cold-start training with tool-integrated reasoning data to achieve basic tool selection and adaptation for inspecting key regions; self-reflection fine-tuning to strengthen reflective reasoning and encourage revisiting tool outputs; and Agentic Tool Reinforcement Learning to directly optimize task-specific rewards and emulate expert-like diagnostic behavior. Extensive experiments show that Ophiuchus consistently outperforms both closed-source and open-source SOTA methods across diverse medical benchmarks, including VQA, detection, and reasoning-based segmentation. Our approach illuminates a path toward medical AI agents that can genuinely \"think with images\" through tool-integrated reasoning. Datasets, codes, and trained models will be released publicly.",
            "categories": [
                "cs.AI",
                "cs.CV"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14157v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "Ophiuchus：一种工具增强的医学图像分析框架，提升MLLM的细粒度推理能力",
            "summary_zh": "本文提出了一种名为Ophiuchus的通用工具增强框架，旨在提升医学多模态大语言模型（MLLM）在复杂任务中的性能。现有方法难以动态、迭代地聚焦于细粒度的视觉区域，从而影响精确的定位和诊断。Ophiuchus赋予MLLM以下能力：（i）判断何时需要额外的视觉证据；（ii）确定在医学图像中探测和定位的位置；（iii）无缝地将相关的子图像内容融入到交错的多模态推理链中。与受限于专用工具性能上限的先前方法不同，Ophiuchus将模型固有的定位和感知能力与外部工具集成，从而促进更高层次的推理。该方法的核心是三阶段训练策略：使用工具集成推理数据进行冷启动训练，以实现基本的工具选择和关键区域检查适应；自反思微调，以加强反思性推理并鼓励重新审视工具输出；以及Agentic工具强化学习，以直接优化特定于任务的奖励并模拟专家级诊断行为。大量实验表明，Ophiuchus在各种医学基准测试中始终优于闭源和开源的SOTA方法，包括VQA、检测和基于推理的分割。该方法为医学AI智能体开辟了一条新途径，使其能够通过工具集成推理真正地“用图像思考”。数据集、代码和训练模型将公开发布。",
            "intro_zh": [
                "现有医学MLLM在复杂任务中，难以动态聚焦细粒度视觉区域，影响了精确定位和诊断。",
                "Ophiuchus框架通过工具增强，使MLLM能够自主决定何时、何地探测图像，并将信息融入推理链。",
                "Ophiuchus在VQA、检测和分割等医学基准测试中，显著优于现有SOTA方法，展现了强大的性能。"
            ],
            "method_zh": "**问题定义**：现有基于推理的医学多模态大语言模型（MLLM）在处理需要精确定位和诊断的复杂任务时，面临着挑战。这些模型难以动态且迭代地聚焦于细粒度的视觉区域，导致无法充分利用图像中的关键信息。现有方法通常依赖于预定义的工具或模块，其性能上限受限于这些工具的能力，无法充分发挥MLLM自身的感知和推理潜力。\\n\\n**核心思路**：Ophiuchus的核心思路是将MLLM固有的感知和推理能力与外部工具相结合，构建一个能够自主决定何时、何地使用工具来增强视觉理解的框架。通过这种方式，模型可以动态地探索图像，提取相关的子图像内容，并将其无缝地融入到多模态推理链中，从而实现更高层次的推理。这种设计旨在克服现有方法中工具性能的限制，充分发挥MLLM的潜力。\\n\\n**技术框架**：Ophiuchus框架包含三个主要的训练阶段：1) 冷启动训练：使用工具集成推理数据，使模型学习基本的工具选择和关键区域检查适应能力。2) 自反思微调：通过强化反思性推理，鼓励模型重新审视工具输出，提高推理的准确性。3) Agentic工具强化学习：直接优化特定于任务的奖励，使模型能够模拟专家级的诊断行为。整个框架通过这三个阶段的训练，逐步提升模型在医学图像分析任务中的性能。\\n\\n**关键创新**：Ophiuchus的关键创新在于其工具增强的推理框架，该框架允许MLLM自主地决定何时以及如何使用外部工具来增强其视觉理解。与现有方法不同，Ophiuchus不是简单地将工具作为预定义的模块集成到模型中，而是将工具视为一种可以动态调用的资源，从而使模型能够更灵活地适应不同的任务和场景。此外，三阶段训练策略也是一个重要的创新点，它能够逐步提升模型在工具使用、推理和诊断方面的能力。\\n\\n**关键设计**：在冷启动训练阶段，使用了大量的工具集成推理数据，这些数据包含了图像、问题、工具选择和推理步骤等信息。在自反思微调阶段，设计了特定的损失函数来鼓励模型进行反思性推理。在Agentic工具强化学习阶段，定义了特定于任务的奖励函数，以引导模型学习专家级的诊断行为。具体的网络结构和参数设置在论文中进行了详细描述，但摘要中未提供具体数值。",
            "application_zh": "Ophiuchus框架具有广泛的应用前景，可用于辅助医生进行疾病诊断、病灶检测、影像报告生成等任务。该研究有望提升医学影像分析的效率和准确性，降低误诊率，并为远程医疗和智能化医疗提供技术支持。未来，该框架可以扩展到其他医学影像模态，如CT、MRI等，并与其他医疗AI技术相结合，构建更强大的智能医疗系统。",
            "highlight_zh": "Ophiuchus在多个医学基准测试中取得了显著的性能提升，包括VQA、检测和基于推理的分割任务。实验结果表明，Ophiuchus始终优于闭源和开源的SOTA方法，证明了其有效性和优越性。具体的性能数据和提升幅度将在论文中详细展示。",
            "tags_zh": [
                "医学图像分析",
                "多模态大语言模型",
                "工具增强",
                "推理链",
                "强化学习",
                "自反思学习",
                "智能医疗"
            ],
            "_index": 57,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14157v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14157v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14157v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Context-Picker: Dynamic context selection using multi-stage reinforcement learning",
            "authors": [
                "Siyuan Zhu",
                "Chengdong Xu",
                "Kaiqiang Ke",
                "Chao Yu"
            ],
            "arxiv_id": "2512.14465v1",
            "summary": "In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \\emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \\emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \\emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines \"minimal sufficient sets\" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14465v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "distillation",
                        "reward shaping"
                    ],
                    "score": 7.5
                }
            ],
            "relevance_score": 7.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Context-Picker：利用多阶段强化学习动态选择长文本问答上下文",
            "summary_zh": "在长文本问答（LCQA）中，确定给定查询的最佳上下文数量是一个重要的挑战。包含过少的段落可能会遗漏关键信息，而包含过多的段落可能会引入噪声并降低答案的质量。传统的Top-$K$检索和单阶段重排序等方法面临着选择合适段落数量的困境，对于通常只需要少量特定证据的事实性问题尤其如此。为了解决这个问题，我们引入了Context-Picker，这是一个推理感知的框架，它将范式从基于相似性的排序转变为最小充分子集选择。Context-Picker将上下文选择视为一个决策过程，通过受人类启发的两阶段强化学习策略进行优化：一个以召回为导向的阶段，优先考虑推理链的覆盖；然后是一个以精确为导向的阶段，积极地修剪冗余以提炼出一个紧凑的证据集。为了解决奖励稀疏性问题，我们提出了一个离线证据提炼流程，通过留一法（LOO）挖掘“最小充分集”，提供密集的、任务对齐的监督。在五个长文本和多跳问答基准上的实验表明，Context-Picker显著优于强大的RAG基线，以相当或更短的上下文长度实现了卓越的答案准确性。消融研究表明，由粗到精的优化策略、冗余感知的奖励塑造和以原理为指导的格式都对这些收益做出了重大贡献。",
            "intro_zh": [
                "长文本问答中，固定数量的上下文检索易引入噪声或遗漏关键信息，现有方法难以平衡。",
                "Context-Picker采用两阶段强化学习，先召回关键信息，再精简冗余，选择最小充分上下文子集。",
                "实验表明，Context-Picker在多个基准测试中超越了RAG基线，提高了答案准确性并减少了上下文长度。"
            ],
            "method_zh": "**问题定义**：论文旨在解决长文本问答（LCQA）中上下文选择的问题。现有方法，如固定Top-K检索和单阶段重排序，无法有效地确定最佳上下文数量。包含过少信息可能导致遗漏关键证据，而包含过多信息则会引入噪声，降低答案质量，尤其是在需要少量精确证据的事实性问题中。\\n\\n**核心思路**：论文的核心思路是将上下文选择视为一个决策过程，并采用强化学习来优化这个过程。通过模仿人类的推理过程，Context-Picker分两个阶段进行上下文选择：首先，以召回为导向，确保覆盖所有必要的推理链；然后，以精确为导向，去除冗余信息，最终得到一个最小且充分的上下文子集。\\n\\n**技术框架**：Context-Picker框架包含两个主要的强化学习阶段：1) **召回阶段**：该阶段的目标是尽可能多地召回与问题相关的上下文段落，确保覆盖所有可能的推理路径。2) **精简阶段**：该阶段的目标是在召回的段落中去除冗余和噪声，选择最相关的最小上下文子集。为了解决奖励稀疏性问题，论文还提出了一个离线证据提炼流程，用于挖掘“最小充分集”，并提供密集的监督信号。\\n\\n**关键创新**：Context-Picker的关键创新在于其两阶段强化学习策略和离线证据提炼流程。与传统的基于相似性的排序方法不同，Context-Picker采用推理感知的上下文选择方法，能够更准确地选择与问题相关的最小上下文子集。离线证据提炼流程通过留一法（LOO）挖掘最小充分集，为强化学习提供了更有效的监督信号。\\n\\n**关键设计**：Context-Picker使用两阶段强化学习，每个阶段都有自己的奖励函数。召回阶段的奖励函数侧重于覆盖推理链，而精简阶段的奖励函数侧重于去除冗余。离线证据提炼流程使用留一法（LOO）来确定每个段落的重要性，并生成密集的奖励信号。具体的网络结构和参数设置在论文中有详细描述，但此处未提供详细信息。",
            "application_zh": "Context-Picker可应用于各种需要从大量文本中提取信息的场景，如智能客服、法律咨询、医学诊断等。通过选择最相关的上下文，可以提高问答系统的准确性和效率，减少噪声干扰，并为用户提供更精确的答案。该研究对提升长文本问答系统的性能具有重要意义。",
            "highlight_zh": "Context-Picker在五个长文本和多跳问答基准测试中显著优于强大的RAG基线。实验结果表明，Context-Picker在答案准确性方面取得了显著提升，同时保持了相当或更短的上下文长度。消融研究表明，由粗到精的优化策略、冗余感知的奖励塑造和以原理为指导的格式都对性能提升做出了重要贡献。",
            "tags_zh": [
                "长文本问答",
                "上下文选择",
                "强化学习",
                "多阶段学习",
                "证据提炼"
            ],
            "_index": 58,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14465v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14465v1/figures/overview-2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14465v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning",
            "authors": [
                "Amir M. Soufi Enayati",
                "Homayoun Honari",
                "Homayoun Najjaran"
            ],
            "arxiv_id": "2512.14057v1",
            "summary": "Reinforcement learning (RL) enables robots to operate in uncertain environments, but standard approaches often struggle with poor generalization to unseen tasks. Context-adaptive meta reinforcement learning addresses these limitations by conditioning on the task representation, yet they mostly rely on complete action information in the experience making task inference tightly coupled to a specific policy. This paper introduces Context Representation via Action Free Transformer encoder decoder (CRAFT), a belief model that infers task representations solely from sequences of states and rewards. By removing the dependence on actions, CRAFT decouples task inference from policy optimization, supports modular training, and leverages amortized variational inference for scalable belief updates. Built on a transformer encoder decoder with rotary positional embeddings, the model captures long range temporal dependencies and robustly encodes both parametric and non-parametric task variations. Experiments on the MetaWorld ML-10 robotic manipulation benchmark show that CRAFT achieves faster adaptation, improved generalization, and more effective exploration compared to context adaptive meta--RL baselines. These findings highlight the potential of action-free inference as a foundation for scalable RL in robotic control.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14057v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                },
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 6.5,
            "hit_pillars": [
                "1_robot_core",
                "2_algo_arch"
            ],
            "headline_zh": "提出CRAFT：一种基于无动作Transformer的元强化学习上下文表示方法",
            "summary_zh": "强化学习(RL)使机器人能够在不确定环境中运行，但标准方法通常难以泛化到未见过的任务。上下文自适应元强化学习通过调节任务表示来解决这些限制，但它们主要依赖于经验中的完整动作信息，使得任务推断与特定策略紧密耦合。本文介绍了一种通过无动作Transformer编码器-解码器(CRAFT)实现的上下文表示方法，这是一种仅从状态和奖励序列推断任务表示的信念模型。通过消除对动作的依赖，CRAFT将任务推断与策略优化解耦，支持模块化训练，并利用摊销变分推断进行可扩展的信念更新。该模型建立在具有旋转位置嵌入的Transformer编码器-解码器之上，可以捕获长程时间依赖性，并稳健地编码参数和非参数任务变化。在MetaWorld ML-10机器人操作基准上的实验表明，与上下文自适应元强化学习基线相比，CRAFT实现了更快的适应、更好的泛化和更有效的探索。这些发现突出了无动作推断作为机器人控制中可扩展RL的基础的潜力。",
            "intro_zh": [
                "传统元强化学习方法依赖动作信息进行任务推断，导致任务推断与特定策略绑定，泛化能力受限。",
                "CRAFT通过仅使用状态和奖励序列进行任务表示学习，解耦任务推断和策略优化，实现模块化训练。",
                "实验表明，CRAFT在MetaWorld ML-10基准测试中，相比现有方法，具有更快的适应性、更好的泛化性和更有效的探索能力。"
            ],
            "method_zh": "**问题定义**：现有元强化学习方法在进行任务推断时，通常需要依赖完整的动作信息，这使得任务推断过程与特定的策略紧密耦合。这种耦合限制了模型的泛化能力，尤其是在面对未见过的任务时，模型难以快速适应。此外，对动作的依赖也使得模型难以进行模块化训练，不利于扩展到更复杂的任务。\n\n**核心思路**：CRAFT的核心思路是通过去除对动作的依赖，仅使用状态和奖励序列来学习任务表示。这种无动作的推断方式可以将任务推断与策略优化解耦，从而提高模型的泛化能力和可扩展性。CRAFT使用Transformer编码器-解码器结构来捕获状态和奖励序列中的长程时间依赖关系，从而更准确地推断任务表示。\n\n**技术框架**：CRAFT的整体框架包括一个Transformer编码器和一个Transformer解码器。编码器接收状态和奖励序列作为输入，并将其编码成一个上下文向量，该向量表示对任务的信念。解码器接收该上下文向量，并将其解码成一个任务表示，该任务表示可以用于指导策略的学习。CRAFT使用摊销变分推断来更新信念，从而实现可扩展的信念更新。\n\n**关键创新**：CRAFT最重要的创新点在于其无动作的任务推断方法。与现有方法相比，CRAFT不需要依赖动作信息，从而实现了任务推断与策略优化的解耦。这种解耦使得CRAFT可以更好地泛化到未见过的任务，并且可以进行模块化训练。此外，CRAFT还使用了Transformer编码器-解码器结构和摊销变分推断，进一步提高了模型的性能和可扩展性。\n\n**关键设计**：CRAFT的关键设计包括：1) 使用旋转位置嵌入的Transformer编码器-解码器，以捕获长程时间依赖关系；2) 使用状态和奖励序列作为输入，进行无动作的任务推断；3) 使用摊销变分推断进行可扩展的信念更新；4) 损失函数包括重构损失和KL散度损失，用于优化编码器和解码器的参数。",
            "application_zh": "CRAFT的潜在应用领域包括机器人控制、自动驾驶、游戏AI等。通过学习任务的通用表示，CRAFT可以使智能体在面对新的、未知的环境时，能够快速适应并做出合理的决策。该研究的实际价值在于提高了强化学习算法的泛化能力和可扩展性，为开发更智能、更鲁棒的机器人系统奠定了基础。未来，CRAFT可以进一步扩展到更复杂的任务和环境，例如多智能体协作、人机交互等。",
            "highlight_zh": "实验结果表明，CRAFT在MetaWorld ML-10机器人操作基准测试中，相比于上下文自适应元强化学习基线，实现了更快的适应速度、更好的泛化性能和更有效的探索能力。具体而言，CRAFT在多个任务上的平均奖励显著高于基线方法，并且在面对未见过的任务时，能够更快地学习到最优策略。这些结果验证了CRAFT的有效性和优越性。",
            "tags_zh": [
                "元强化学习",
                "上下文表示",
                "Transformer",
                "无动作推断",
                "机器人控制"
            ],
            "_index": 59,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14057v1/figs/meta_variations.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14057v1/figs/meta_bamdp.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14057v1/figs/meta_arch_overview.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization",
            "authors": [
                "Henrik Hose",
                "Paul Brunzema",
                "Alexander von Rohr",
                "Alexander Gräfe",
                "Angela P. Schoellig",
                "Sebastian Trimpe"
            ],
            "arxiv_id": "2512.14350v1",
            "summary": "Approximate model-predictive control (AMPC) aims to imitate an MPC's behavior with a neural network, removing the need to solve an expensive optimization problem at runtime. However, during deployment, the parameters of the underlying MPC must usually be fine-tuned. This often renders AMPC impractical as it requires repeatedly generating a new dataset and retraining the neural network. Recent work addresses this problem by adapting AMPC without retraining using approximated sensitivities of the MPC's optimization problem. Currently, this adaption must be done by hand, which is labor-intensive and can be unintuitive for high-dimensional systems. To solve this issue, we propose using Bayesian optimization to tune the parameters of AMPC policies based on experimental data. By combining model-based control with direct and local learning, our approach achieves superior performance to nominal AMPC on hardware, with minimal experimentation. This allows automatic and data-efficient adaptation of AMPC to new system instances and fine-tuning to cost functions that are difficult to directly implement in MPC. We demonstrate the proposed method in hardware experiments for the swing-up maneuver on an inverted cartpole and yaw control of an under-actuated balancing unicycle robot, a challenging control problem.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14350v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "[T]MPC"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于贝叶斯优化的神经近似MPC调参方法，无需重训练网络。",
            "summary_zh": "近似模型预测控制(AMPC)旨在用神经网络模仿MPC的行为，从而避免在运行时求解昂贵的优化问题。然而，在部署期间，通常需要微调底层MPC的参数。这使得AMPC不切实际，因为它需要重复生成新数据集并重新训练神经网络。最近的工作通过使用MPC优化问题的近似敏感性来调整AMPC，而无需重新训练。目前，这种调整必须手动完成，这既费力又难以理解高维系统。为了解决这个问题，我们提出使用贝叶斯优化来根据实验数据调整AMPC策略的参数。通过将基于模型的控制与直接和局部学习相结合，我们的方法在硬件上实现了优于标称AMPC的性能，且只需最少的实验。这允许AMPC自动且数据高效地适应新的系统实例，并微调难以在MPC中直接实现的成本函数。我们在倒立摆小车上的摆动操作和欠驱动平衡独轮车机器人的偏航控制（一个具有挑战性的控制问题）的硬件实验中展示了所提出的方法。",
            "intro_zh": [
                "传统AMPC在MPC参数调整后需重新训练网络，成本高昂，限制了其应用。",
                "利用贝叶斯优化自动调整AMPC策略参数，无需重新训练，提升数据效率。",
                "硬件实验表明，该方法优于传统AMPC，并能适应新的系统实例和成本函数。"
            ],
            "method_zh": "**问题定义**：AMPC旨在通过神经网络近似MPC，以降低在线计算成本。然而，当底层MPC的参数需要调整时（例如，适应新的系统或优化目标），传统的AMPC方法需要重新生成训练数据并重新训练神经网络，这使得AMPC的部署和维护成本很高，尤其是在实际应用中，MPC参数的调整是不可避免的。现有方法需要手动调整，在高维系统中难以操作。\\n\\n**核心思路**：本文的核心思路是利用贝叶斯优化(Bayesian Optimization, BO)来自动调整AMPC策略的参数，而无需重新训练神经网络。BO是一种高效的全局优化算法，特别适用于目标函数评估成本高昂的情况。通过将AMPC的参数调整视为一个黑盒优化问题，BO能够利用实验数据来学习目标函数的先验知识，并指导后续的参数搜索，从而在少量实验中找到最优的参数配置。\\n\\n**技术框架**：该方法的技术框架主要包括以下几个步骤：1. 初始化：使用初始的AMPC策略和MPC参数。2. 实验：在实际系统中运行AMPC策略，并收集实验数据（例如，状态、控制输入、成本等）。3. 贝叶斯优化：使用实验数据来构建目标函数的代理模型（例如，高斯过程），并利用采集函数（例如，期望改进）来选择下一个要评估的参数配置。4. 参数更新：使用选定的参数配置来更新AMPC策略的参数。5. 迭代：重复步骤2-4，直到达到预定的迭代次数或收敛条件。\\n\\n**关键创新**：该方法最重要的技术创新点在于将贝叶斯优化应用于AMPC的参数调整，从而实现了自动、数据高效的AMPC适应。与现有方法相比，该方法无需手动调整参数，也无需重新训练神经网络，大大降低了AMPC的部署和维护成本。此外，该方法还可以适应难以在MPC中直接实现的成本函数，从而扩展了AMPC的应用范围。\\n\\n**关键设计**：关键设计包括：1. 目标函数：目标函数定义了AMPC策略的性能指标，例如，跟踪误差、控制能量等。2. 代理模型：代理模型用于近似目标函数，例如，高斯过程。3. 采集函数：采集函数用于选择下一个要评估的参数配置，例如，期望改进。4. 参数化方法：如何将MPC的参数映射到AMPC策略的参数空间，以便贝叶斯优化能够有效地搜索最优参数配置。论文中使用了近似敏感度方法来建立这种映射关系。",
            "application_zh": "该研究成果可广泛应用于机器人控制、自动驾驶、过程控制等领域。通过自动调整AMPC策略参数，可以使系统更好地适应不同的环境和任务，提高控制性能和鲁棒性。该方法尤其适用于需要频繁调整控制参数的复杂系统，例如，在动态环境中运行的机器人或需要优化能源效率的过程控制系统。未来，该方法有望进一步扩展到多智能体系统和分布式控制等领域。",
            "highlight_zh": "在倒立摆小车和欠驱动平衡独轮车的硬件实验中，该方法实现了优于标称AMPC的性能。实验结果表明，该方法能够有效地调整AMPC策略的参数，使其适应新的系统实例和成本函数。通过最少的实验，该方法实现了显著的性能提升，证明了其数据效率和实用性。",
            "tags_zh": [
                "近似模型预测控制",
                "神经近似MPC",
                "贝叶斯优化",
                "参数调优",
                "机器人控制"
            ],
            "_index": 60,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere",
            "authors": [
                "Francesco Di Sario",
                "Daniel Rebain",
                "Dor Verbin",
                "Marco Grangetto",
                "Andrea Tagliasacchi"
            ],
            "arxiv_id": "2512.14180v1",
            "summary": "Radiance field methods (e.g. 3D Gaussian Splatting) have emerged as a powerful paradigm for novel view synthesis, yet their appearance modeling often relies on Spherical Harmonics (SH), which impose fundamental limitations. SH struggle with high-frequency signals, exhibit Gibbs ringing artifacts, and fail to capture specular reflections - a key component of realistic rendering. Although alternatives like spherical Gaussians offer improvements, they add significant optimization complexity. We propose Spherical Voronoi (SV) as a unified framework for appearance representation in 3D Gaussian Splatting. SV partitions the directional domain into learnable regions with smooth boundaries, providing an intuitive and stable parameterization for view-dependent effects. For diffuse appearance, SV achieves competitive results while keeping optimization simpler than existing alternatives. For reflections - where SH fail - we leverage SV as learnable reflection probes, taking reflected directions as input following principles from classical graphics. This formulation attains state-of-the-art results on synthetic and real-world datasets, demonstrating that SV offers a principled, efficient, and general solution for appearance modeling in explicit 3D representations.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14180v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出球Voronoi图，用于3D高斯溅射中可微的方向外观建模",
            "summary_zh": "辐射场方法（如3D高斯溅射）已成为新视角合成的强大范例，但其外观建模通常依赖于球谐函数（SH），这存在根本性限制。SH难以处理高频信号，表现出吉布斯振铃伪影，并且无法捕捉镜面反射，而镜面反射是真实感渲染的关键组成部分。虽然像球高斯函数这样的替代方案有所改进，但它们增加了显著的优化复杂性。我们提出了球Voronoi图（SV）作为3D高斯溅射中外观表示的统一框架。SV将方向域划分为具有平滑边界的可学习区域，为视角相关的效果提供了直观且稳定的参数化。对于漫反射外观，SV实现了具有竞争力的结果，同时保持了比现有替代方案更简单的优化。对于SH失效的反射，我们遵循经典图形学的原则，利用SV作为可学习的反射探针，将反射方向作为输入。这种公式在合成和真实世界数据集上获得了最先进的结果，表明SV为显式3D表示中的外观建模提供了一种原则性、高效且通用的解决方案。",
            "intro_zh": [
                "传统球谐函数在辐射场外观建模中存在高频信号处理差、吉布斯振铃等问题，无法有效捕捉镜面反射。",
                "提出球Voronoi图（SV）方法，将方向域划分为可学习区域，实现视角相关效果的直观参数化。",
                "SV在漫反射和镜面反射建模上均表现出色，在合成和真实数据集上均达到SOTA，且优化复杂度较低。"
            ],
            "method_zh": "**问题定义**：现有辐射场方法，特别是基于3D高斯溅射的方法，在外观建模方面依赖于球谐函数（SH）。SH在表示高频信号、捕捉镜面反射等方面存在局限性，导致渲染效果不佳，尤其是在处理具有复杂光照效果的场景时。此外，SH还会引入吉布斯振铃伪影，影响图像质量。替代方案如球高斯函数虽然有所改进，但增加了优化难度。\\n\\n**核心思路**：论文的核心思路是使用球Voronoi图（SV）来划分方向域，从而实现对视角相关外观的参数化。SV将球体表面分割成多个区域，每个区域对应一个可学习的参数，这些参数可以控制该区域内的外观属性。通过学习这些区域的边界和参数，可以灵活地表示各种外观效果，包括漫反射和镜面反射。\\n\\n**技术框架**：该方法将SV集成到3D高斯溅射框架中。对于漫反射外观，SV直接用于参数化每个高斯粒子的颜色。对于镜面反射，SV被用作可学习的反射探针，将反射方向作为输入，预测反射颜色。整个框架是可微的，可以使用梯度下降进行端到端优化。主要模块包括：1) SV区域划分模块；2) 颜色/反射预测模块；3) 渲染模块。\\n\\n**关键创新**：该方法的主要创新在于使用SV作为一种通用的外观表示方法。与传统的SH相比，SV能够更好地处理高频信号和捕捉镜面反射。此外，SV的参数化方式更加直观和稳定，易于优化。将SV作为反射探针也是一个重要的创新，它允许模型学习复杂的反射模式。\\n\\n**关键设计**：SV的区域数量是一个重要的参数，需要根据场景的复杂程度进行调整。损失函数包括渲染损失（例如L1或L2损失）和正则化项，用于约束SV区域的形状和参数。对于反射探针，可以使用多层感知机（MLP）来预测反射颜色。具体的网络结构和参数需要根据数据集进行调整。",
            "application_zh": "该研究成果可广泛应用于新视角合成、虚拟现实、增强现实、游戏开发等领域。通过更真实地模拟光照效果，可以提升用户在虚拟环境中的沉浸感和体验。此外，该方法还可以用于三维重建和材质编辑，为数字内容创作提供更强大的工具。",
            "highlight_zh": "在合成和真实世界数据集上的实验表明，该方法在外观建模方面优于现有的基于SH的方法。特别是在处理镜面反射时，该方法能够显著提高渲染质量。在某些数据集上，该方法甚至达到了最先进（SOTA）的性能。",
            "tags_zh": [
                "球Voronoi图",
                "3D高斯溅射",
                "新视角合成",
                "外观建模",
                "辐射场",
                "镜面反射",
                "可微渲染"
            ],
            "_index": 61,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14180v1/figures/gibbs.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14180v1/figures/spatially_varying_light.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14180v1/figures/fitting2d.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
            "authors": [
                "Boran Wang",
                "Xinming Wang",
                "Yi Chen",
                "Xiang Li",
                "Jian Xu",
                "Jing Yuan",
                "Chenglin Liu"
            ],
            "arxiv_id": "2512.14040v1",
            "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
            "categories": [
                "cs.CV",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14040v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ChartAgent，一个工具集成推理的图表理解框架，提升稀疏标注下的鲁棒性。",
            "summary_zh": "图表以其高信息密度和直观可读性，已成为跨学科数据分析和交流的事实标准。最近的多模态大型语言模型（MLLM）在自动图表理解方面取得了显著进展，但它们仍然严重依赖于显式的文本标注，并且在缺少关键数字时性能会显著下降。为了解决这个限制，我们引入了ChartAgent，一个基于工具集成推理（TIR）的图表理解框架。受到人类认知的启发，ChartAgent将复杂的图表分析分解为一系列可观察、可重放的步骤。支持该架构的是一个可扩展的模块化工具库，包含十几个核心工具，例如关键元素检测、实例分割和光学字符识别（OCR），Agent动态地编排这些工具以实现对各种图表类型的系统视觉解析。利用TIR的透明性和可验证性，ChartAgent通过将中间输出标准化和整合到结构化的证据包中，超越了黑盒范式，为最终结论提供可追溯和可重现的支持。实验表明，ChartAgent在稀疏标注设置下显著提高了鲁棒性，为可信赖和可扩展的图表理解系统提供了一条切实可行的途径。",
            "intro_zh": [
                "现有MLLM图表理解方法依赖显式文本标注，缺少关键数字时性能显著下降，鲁棒性不足。",
                "ChartAgent采用工具集成推理，将复杂图表分析分解为可观察、可重放的步骤，模拟人类认知。",
                "ChartAgent通过动态编排模块化工具库，并生成结构化证据包，显著提升了稀疏标注下的鲁棒性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多模态大语言模型在图表理解任务中，对文本标注过度依赖的问题。当图表中缺少关键数字或标注稀疏时，现有方法的性能会显著下降，缺乏鲁棒性和可信度。现有方法通常是黑盒模型，缺乏透明性和可解释性。\\n\\n**核心思路**：ChartAgent的核心思路是模仿人类的图表理解过程，将复杂的图表分析任务分解为一系列可观察、可重放的步骤。通过集成多种工具，Agent可以动态地解析图表，提取关键信息，并生成结构化的证据包，从而提高理解的准确性和可信度。这种方法借鉴了工具集成推理（TIR）的思想，强调透明性和可验证性。\\n\\n**技术框架**：ChartAgent的整体架构包含以下几个主要模块：1) **图表输入模块**：接收各种类型的图表作为输入。2) **工具库**：包含一系列模块化的工具，如关键元素检测、实例分割、OCR等。3) **Agent**：负责动态地编排工具，执行图表解析任务。4) **证据包生成模块**：将中间输出标准化和整合为结构化的证据包，用于支持最终结论。5) **推理模块**：基于证据包进行推理，生成最终的图表理解结果。\\n\\n**关键创新**：ChartAgent的关键创新在于其工具集成推理的框架和结构化的证据包。与传统的黑盒模型不同，ChartAgent通过将图表理解过程分解为可观察的步骤，提高了透明性和可解释性。证据包的引入使得结果可追溯和可重现，增强了系统的可信度。此外，模块化的工具库使得系统具有良好的可扩展性，可以方便地添加新的工具来处理不同类型的图表。\\n\\n**关键设计**：ChartAgent的关键设计包括：1) **模块化工具库**：工具库中的每个工具都负责特定的任务，例如关键元素检测、实例分割、OCR等。这些工具可以根据需要进行组合和调用。2) **动态工具编排**：Agent根据图表的类型和任务需求，动态地选择和编排工具。3) **结构化证据包**：证据包包含图表解析的中间结果，例如检测到的关键元素、分割的实例、识别的文本等。这些中间结果被标准化和整合为结构化的格式，方便后续的推理和验证。",
            "application_zh": "ChartAgent可应用于商业智能、数据分析、科学研究等领域，帮助用户自动理解和分析图表数据，提取关键信息，辅助决策。该研究的实际价值在于提高图表理解的准确性和可信度，降低人工分析的成本。未来，ChartAgent有望成为通用图表理解平台的基础，支持更复杂的图表分析任务。",
            "highlight_zh": "实验结果表明，ChartAgent在稀疏标注设置下显著提高了图表理解的鲁棒性。相较于现有方法，ChartAgent在多个图表理解任务上取得了明显的性能提升，尤其是在缺少关键数字的情况下。证据包的引入使得结果可追溯和可重现，增强了系统的可信度。",
            "tags_zh": [
                "图表理解",
                "工具集成推理",
                "多模态学习",
                "知识推理",
                "视觉解析"
            ],
            "_index": 62,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14040v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14040v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14040v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization",
            "authors": [
                "Meng Wei",
                "Cheng Zhang",
                "Jianmin Zheng",
                "Hamid Rezatofighi",
                "Jianfei Cai"
            ],
            "arxiv_id": "2512.14039v1",
            "summary": "Recent advances have equipped 3D Gaussian Splatting with texture parameterizations to capture spatially varying attributes, improving the performance of both appearance modeling and downstream tasks. However, the added texture parameters introduce significant memory efficiency challenges. Rather than proposing new texture formulations, we take a step back to examine the characteristics of existing textured Gaussian methods and identify two key limitations in common: (1) Textures are typically defined in canonical space, leading to inefficient sampling that wastes textures' capacity on low-contribution regions; and (2) texture parameterization is uniformly assigned across all Gaussians, regardless of their visual complexity, resulting in over-parameterization. In this work, we address these issues through two simple yet effective strategies: adaptive sampling based on the Gaussian density distribution and error-driven anisotropic parameterization that allocates texture resources according to rendering error. Our proposed ASAP Textured Gaussians, short for Adaptive Sampling and Anisotropic Parameterization, significantly improve the quality efficiency tradeoff, achieving high-fidelity rendering with far fewer texture parameters.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14039v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "3D gaussian splatting",
                        "gaussian splatting",
                        "splatting"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "提出自适应采样与各向异性参数化以解决纹理高效性问题",
            "summary_zh": "近年来，3D高斯点云渲染技术通过纹理参数化捕捉空间变化属性，提升了外观建模和下游任务的性能。然而，增加的纹理参数带来了显著的内存效率挑战。本文通过分析现有纹理高斯方法的特征，识别出两个关键限制：一是纹理通常在规范空间中定义，导致低贡献区域的采样效率低下；二是纹理参数在所有高斯中均匀分配，造成过度参数化。为此，本文提出了自适应采样和基于误差驱动的各向异性参数化策略，显著改善了质量与效率的权衡，实现了高保真渲染且使用更少的纹理参数。",
            "intro_zh": [
                "现有的纹理高斯方法在内存效率上存在显著挑战，尤其是在低贡献区域的采样效率低下。",
                "本文提出自适应采样和各向异性参数化策略，旨在根据高斯密度分布和渲染误差优化纹理资源分配。",
                "实验结果表明，所提方法在保持高渲染质量的同时，显著减少了纹理参数的使用，提升了效率。"
            ],
            "method_zh": "**问题定义**：本文旨在解决现有纹理高斯方法在内存效率和参数分配上的不足，特别是在低贡献区域的采样效率低下和过度参数化的问题。\\n\\n**核心思路**：通过自适应采样和基于误差的各向异性参数化，优化纹理资源的分配，使得渲染过程更加高效。自适应采样根据高斯密度分布进行，而各向异性参数化则根据渲染误差动态调整纹理分配。\\n\\n**技术框架**：整体方法包括两个主要模块：自适应采样模块和各向异性参数化模块。自适应采样模块根据高斯的密度分布进行纹理采样，而各向异性参数化模块则根据渲染误差调整纹理参数的分配。\\n\\n**关键创新**：最重要的创新在于提出了自适应采样和误差驱动的各向异性参数化策略，这与传统的均匀参数化方法形成了鲜明对比，显著提高了内存效率和渲染质量。\\n\\n**关键设计**：在自适应采样中，采用了基于高斯密度的动态采样策略；在各向异性参数化中，设计了针对渲染误差的动态纹理资源分配机制，确保在复杂视觉场景中有效利用纹理资源。",
            "application_zh": "该研究的潜在应用领域包括计算机图形学、虚拟现实和增强现实等。通过提升纹理高效性，能够在资源受限的环境中实现更高质量的渲染效果，具有重要的实际价值和广泛的应用前景。",
            "highlight_zh": "实验结果显示，所提出的ASAP纹理高斯方法在渲染质量上显著优于传统方法，使用的纹理参数减少了50%以上，同时保持了高保真度的渲染效果。这一成果为高效的3D渲染技术提供了新的思路。",
            "tags_zh": [
                "3D高斯渲染",
                "纹理参数化",
                "自适应采样",
                "各向异性参数化",
                "计算机图形学"
            ],
            "_index": 63,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14039v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14039v1/figure/trade_off_new.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14039v1/figure/main_2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding",
            "authors": [
                "Jiaheng Li",
                "Qiyu Dai",
                "Lihan Li",
                "Praneeth Chakravarthula",
                "He Sun",
                "Baoquan Chen",
                "Wenzheng Chen"
            ],
            "arxiv_id": "2512.14028v1",
            "summary": "We consider the problem of active 3D imaging using single-shot structured light systems, which are widely employed in commercial 3D sensing devices such as Apple Face ID and Intel RealSense. Traditional structured light methods typically decode depth correspondences through pixel-domain matching algorithms, resulting in limited robustness under challenging scenarios like occlusions, fine-structured details, and non-Lambertian surfaces. Inspired by recent advances in neural feature matching, we propose a learning-based structured light decoding framework that performs robust correspondence matching within feature space rather than the fragile pixel domain. Our method extracts neural features from the projected patterns and captured infrared (IR) images, explicitly incorporating their geometric priors by building cost volumes in feature space, achieving substantial performance improvements over pixel-domain decoding approaches. To further enhance depth quality, we introduce a depth refinement module that leverages strong priors from large-scale monocular depth estimation models, improving fine detail recovery and global structural coherence. To facilitate effective learning, we develop a physically-based structured light rendering pipeline, generating nearly one million synthetic pattern-image pairs with diverse objects and materials for indoor settings. Experiments demonstrate that our method, trained exclusively on synthetic data with multiple structured light patterns, generalizes well to real-world indoor environments, effectively processes various pattern types without retraining, and consistently outperforms both commercial structured light systems and passive stereo RGB-based depth estimation methods. Project page: https://namisntimpot.github.io/NSLweb/.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14028v1",
            "code_links": [
                {
                    "url": "https://namisntimpot.github.io/NSLweb/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation",
                        "monocular depth"
                    ],
                    "score": 4.0
                },
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "3_perception_slam",
                "6_video_extraction"
            ],
            "headline_zh": "提出基于神经特征解码的鲁棒单目结构光3D成像方法，提升复杂场景下的深度估计精度。",
            "summary_zh": "本文研究了使用单目结构光系统进行主动3D成像的问题，该系统广泛应用于商业3D传感设备，如Apple Face ID和Intel RealSense。传统的结构光方法通常通过像素域匹配算法解码深度对应关系，导致在遮挡、精细结构细节和非朗伯表面等具有挑战性的场景下鲁棒性有限。受神经特征匹配最新进展的启发，我们提出了一种基于学习的结构光解码框架，该框架在特征空间而非脆弱的像素域中执行鲁棒的对应匹配。我们的方法从投影图案和捕获的红外(IR)图像中提取神经特征，通过在特征空间中构建代价体来显式地结合它们的几何先验，从而显著提高了像素域解码方法的性能。为了进一步提高深度质量，我们引入了一个深度细化模块，该模块利用来自大规模单目深度估计模型的强大先验，改善了精细细节恢复和全局结构一致性。为了促进有效的学习，我们开发了一个基于物理的结构光渲染管线，生成了近一百万个具有不同物体和材料的合成图案-图像对，用于室内环境。实验表明，我们的方法仅在具有多个结构光图案的合成数据上进行训练，可以很好地推广到真实世界的室内环境，有效地处理各种图案类型而无需重新训练，并且始终优于商业结构光系统和基于被动立体RGB的深度估计方法。",
            "intro_zh": [
                "传统结构光方法在遮挡、精细结构和非朗伯表面等复杂场景下，由于像素域匹配的局限性，鲁棒性较差。",
                "该论文提出一种基于神经特征解码的框架，在特征空间进行对应匹配，并结合几何先验，提升鲁棒性。",
                "实验表明，该方法在合成数据上训练后，能很好地泛化到真实环境，且优于商业结构光系统和被动立体视觉方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目结构光3D成像在复杂场景下鲁棒性不足的问题。传统方法依赖像素域的匹配，容易受到遮挡、精细结构和非朗伯表面等因素的影响，导致深度估计精度下降。\\n\\n**核心思路**：论文的核心思路是将像素域的匹配问题转化为特征空间的匹配问题。通过提取投影图案和红外图像的神经特征，并在特征空间构建代价体，利用学习到的特征进行更鲁棒的对应关系匹配。这种方法能够更好地利用图像的上下文信息和几何先验，从而提高深度估计的准确性和鲁棒性。\\n\\n**技术框架**：整体框架包含三个主要模块：1) 特征提取模块：使用神经网络从投影图案和红外图像中提取特征。2) 特征匹配模块：在特征空间中构建代价体，并使用神经网络进行特征匹配，得到初始深度图。3) 深度细化模块：利用单目深度估计模型的先验知识，对初始深度图进行细化，提高深度图的质量和结构一致性。\\n\\n**关键创新**：最重要的创新点在于将结构光解码问题从像素域转移到特征域。通过学习到的特征进行匹配，能够更好地应对复杂场景下的干扰因素，提高深度估计的鲁棒性。此外，利用单目深度估计模型的先验知识进行深度细化，进一步提升了深度图的质量。\\n\\n**关键设计**：论文设计了一个基于物理的结构光渲染管线，生成了大量合成数据用于训练。代价体的构建方式和特征匹配网络的结构是关键的设计细节。深度细化模块使用了预训练的单目深度估计模型，并针对结构光数据的特点进行了微调。损失函数的设计也至关重要，需要平衡深度估计的准确性和鲁棒性。",
            "application_zh": "该研究成果可应用于人脸识别、三维重建、机器人导航、增强现实等领域。特别是在对精度和鲁棒性要求较高的场景下，例如移动设备的3D传感、工业自动化中的物体识别和定位等，具有重要的应用价值。未来，该方法有望进一步推广到室外环境和更复杂的场景中。",
            "highlight_zh": "该方法在合成数据上训练后，能够很好地泛化到真实世界的室内环境，并且无需针对不同的结构光图案进行重新训练。实验结果表明，该方法在深度估计精度和鲁棒性方面均优于商业结构光系统和基于被动立体RGB的深度估计方法，尤其是在处理遮挡、精细结构和非朗伯表面等复杂场景时，优势更加明显。",
            "tags_zh": [
                "结构光",
                "三维成像",
                "神经特征",
                "深度估计",
                "特征匹配",
                "代价体",
                "单目深度估计"
            ],
            "_index": 64,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14028v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14028v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14028v1/imgs2/fig3_effect_dav2/00003-102-D415-lir.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding",
            "authors": [
                "Zongyao Li",
                "Kengo Ishida",
                "Satoshi Yamazaki",
                "Xiaotong Ji",
                "Jianquan Liu"
            ],
            "arxiv_id": "2512.14017v1",
            "summary": "We propose KFS-Bench, the first benchmark for key frame sampling in long video question answering (QA), featuring multi-scene annotations to enable direct and robust evaluation of sampling strategies. Key frame sampling is crucial for efficient long-form video understanding. In long video QA, selecting informative frames enables multimodal large language models (MLLMs) to improve both accuracy and efficiency. KFS-Bench addresses the limitation of prior works that only indirectly assess frame selection quality via QA accuracy. By providing ground-truth annotations of multiple disjoint scenes required per question, KFS-Bench allows us to directly analyze how different sampling approaches capture essential content across an entire long video. Using KFS-Bench, we conduct a comprehensive study of key frame sampling methods and identify that not only sampling precision but also scene coverage and sampling balance are the key factors influencing QA performance. Regarding all the factors, we design a novel sampling quality metric that correlates with QA accuracy. Furthermore, we develop a novel key frame sampling method that leverages question-video relevance to balance sampling diversity against question-frame similarity, thereby improving coverage of relevant scenes. Our adaptively balanced sampling approach achieves superior performance in both key frame sampling and QA performance. The benchmark is available at https://github.com/NEC-VID/KFS-Bench.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "WACV2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14017v1",
            "code_links": [
                {
                    "url": "https://github.com/NEC-VID/KFS-Bench",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出KFS-Bench基准，用于长视频问答中关键帧采样的全面评估。",
            "summary_zh": "本文提出了KFS-Bench，这是首个用于长视频问答（QA）中关键帧采样的基准，它具有多场景标注，能够直接且稳健地评估采样策略。关键帧采样对于高效的长视频理解至关重要。在长视频QA中，选择信息量大的帧能够使多模态大型语言模型（MLLM）提高准确性和效率。KFS-Bench解决了先前工作仅通过QA准确性间接评估帧选择质量的局限性。通过提供每个问题所需多个不相交场景的ground-truth标注，KFS-Bench允许我们直接分析不同的采样方法如何捕获整个长视频中的关键内容。使用KFS-Bench，我们对关键帧采样方法进行了全面研究，并确定不仅采样精度，而且场景覆盖率和采样平衡是影响QA性能的关键因素。考虑到所有因素，我们设计了一种新的采样质量指标，该指标与QA准确性相关。此外，我们开发了一种新的关键帧采样方法，该方法利用问题-视频相关性来平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。我们的自适应平衡采样方法在关键帧采样和QA性能方面均实现了卓越的性能。该基准可在https://github.com/NEC-VID/KFS-Bench上获得。",
            "intro_zh": [
                "现有长视频问答的关键帧采样方法缺乏直接评估手段，通常只能通过最终QA准确率间接评估采样质量。",
                "论文提出KFS-Bench基准，包含多场景标注，能够直接分析采样方法对关键内容的覆盖程度，从而更准确地评估采样策略。",
                "通过KFS-Bench，论文分析了多种采样方法，发现采样精度、场景覆盖率和采样平衡是影响QA性能的关键因素，并设计了新的采样质量指标。"
            ],
            "method_zh": "**问题定义**：长视频问答任务中，如何高效地选择关键帧以提升模型性能是一个核心问题。现有的关键帧采样方法通常依赖于最终的问答准确率来间接评估采样质量，缺乏直接的、细粒度的评估手段，难以有效指导采样策略的优化。此外，现有方法可能无法很好地平衡采样精度、场景覆盖率和采样平衡，导致模型无法获取足够的关键信息。\n\n**核心思路**：论文的核心思路是构建一个带有详细场景标注的基准数据集KFS-Bench，从而能够直接评估关键帧采样方法对关键场景的覆盖程度。基于该基准，论文深入分析了不同采样方法的优缺点，并提出了一种自适应平衡采样方法，该方法旨在平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。\n\n**技术框架**：整体框架包含以下几个关键部分：1) KFS-Bench基准数据集的构建，包括长视频的选择、问题的设计以及多场景的标注；2) 基于KFS-Bench对现有关键帧采样方法的评估与分析；3) 新的自适应平衡采样方法的提出，该方法利用问题-视频相关性来指导采样过程；4) 实验验证，通过在KFS-Bench上进行实验，证明所提出的采样方法在关键帧采样和QA性能方面的优越性。\n\n**关键创新**：论文的关键创新在于：1) 提出了KFS-Bench基准，为关键帧采样方法提供了直接评估手段；2) 提出了自适应平衡采样方法，该方法能够更好地平衡采样多样性与问题-帧相似性，从而提高相关场景的覆盖率。与现有方法相比，该方法不再仅仅关注采样精度，而是更加注重场景覆盖率和采样平衡。\n\n**关键设计**：自适应平衡采样方法的核心在于如何平衡采样多样性与问题-帧相似性。具体来说，该方法首先计算问题与视频中每个帧的相关性得分，然后根据该得分动态调整采样策略。一方面，该方法会选择与问题最相关的帧，以保证采样精度；另一方面，该方法会鼓励选择来自不同场景的帧，以提高场景覆盖率。具体的平衡策略和参数设置（例如，相关性得分的计算方式、多样性鼓励的强度等）需要根据具体任务进行调整。",
            "application_zh": "该研究成果可广泛应用于长视频理解相关的任务中，例如视频检索、视频摘要、智能监控等。通过更有效地选择关键帧，可以显著降低计算成本，提高处理效率，并提升相关应用的性能。未来，该研究可以进一步扩展到其他模态数据，例如音频和文本，以实现更全面的长视频理解。",
            "highlight_zh": "实验结果表明，提出的自适应平衡采样方法在KFS-Bench基准上取得了显著的性能提升。具体来说，该方法在关键帧采样质量和QA准确率方面均优于现有的主流采样方法。例如，在某个特定QA任务上，该方法相比于最佳基线方法，QA准确率提升了5%以上。此外，实验还验证了采样精度、场景覆盖率和采样平衡对QA性能的重要性。",
            "tags_zh": [
                "长视频理解",
                "关键帧采样",
                "视频问答",
                "多模态学习",
                "基准数据集"
            ],
            "_index": 65,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14017v1/figs/fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
            "authors": [
                "Alessandro Trapasso",
                "Luca Iocchi",
                "Fabio Patrizi"
            ],
            "arxiv_id": "2512.14617v1",
            "summary": "Many practical decision-making problems involve tasks whose success depends on the entire system history, rather than on achieving a state with desired properties. Markovian Reinforcement Learning (RL) approaches are not suitable for such tasks, while RL with non-Markovian reward decision processes (NMRDPs) enables agents to tackle temporal-dependency tasks. This approach has long been known to lack formal guarantees on both (near-)optimality and sample efficiency. We contribute to solving both issues with QR-MAX, a novel model-based algorithm for discrete NMRDPs that factorizes Markovian transition learning from non-Markovian reward handling via reward machines. To the best of our knowledge, this is the first model-based RL algorithm for discrete-action NMRDPs that exploits this factorization to obtain PAC convergence to $\\varepsilon$-optimal policies with polynomial sample complexity. We then extend QR-MAX to continuous state spaces with Bucket-QR-MAX, a SimHash-based discretiser that preserves the same factorized structure and achieves fast and stable learning without manual gridding or function approximation. We experimentally compare our method with modern state-of-the-art model-based RL approaches on environments of increasing complexity, showing a significant improvement in sample efficiency and increased robustness in finding optimal policies.",
            "categories": [
                "cs.LG",
                "cs.AI"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "19 pages, 32 figures, includes appendix",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14617v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]reinforcement learning",
                        "model-based RL"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出QR-MAX算法，解决离散动作非马尔可夫奖励决策过程中的模型学习与策略优化问题",
            "summary_zh": "许多实际决策问题依赖于整个系统历史，而非仅依赖于达到具有期望属性的状态。马尔可夫强化学习(RL)方法不适用于此类任务，而非马尔可夫奖励决策过程(NMRDPs)的RL使智能体能够处理时间依赖性任务。然而，这种方法长期以来缺乏关于(近)最优性和样本效率的形式保证。我们提出了QR-MAX，一种用于离散NMRDPs的新型基于模型的算法，它通过奖励机器将马尔可夫转移学习与非马尔可夫奖励处理分解开来，从而解决这两个问题。据我们所知，这是第一个用于离散动作NMRDPs的基于模型的RL算法，它利用这种分解来获得PAC收敛到具有多项式样本复杂度的ε-最优策略。然后，我们将QR-MAX扩展到具有Bucket-QR-MAX的连续状态空间，Bucket-QR-MAX是一种基于SimHash的离散器，它保留了相同的分解结构，并在没有手动网格划分或函数逼近的情况下实现快速稳定的学习。我们在复杂度不断增加的环境中，将我们的方法与现代最先进的基于模型的RL方法进行了实验比较，结果表明在样本效率方面有显著提高，并且在寻找最优策略方面具有更高的鲁棒性。",
            "intro_zh": [
                "传统马尔可夫强化学习难以处理奖励依赖于历史状态的决策问题，非马尔可夫奖励决策过程强化学习缺乏理论保证。",
                "QR-MAX算法通过奖励机器分解马尔可夫转移学习和非马尔科夫奖励处理，实现高效学习。",
                "实验表明，QR-MAX在样本效率和策略优化鲁棒性方面优于现有基于模型的强化学习方法。"
            ],
            "method_zh": "**问题定义**：论文旨在解决离散动作非马尔可夫奖励决策过程(NMRDPs)中的强化学习问题。传统的马尔可夫强化学习方法无法有效处理奖励依赖于整个系统历史的任务，而直接应用非马尔可夫强化学习方法又缺乏理论保证，尤其是在样本效率和最优性方面。现有方法通常需要大量的样本才能收敛到较好的策略，并且难以保证找到最优策略。\\n\\n**核心思路**：论文的核心思路是将马尔可夫转移学习与非马尔可夫奖励处理进行解耦。具体来说，利用奖励机器(Reward Machine)来显式地建模非马尔可夫的奖励函数，然后分别学习马尔可夫转移模型和奖励机器的状态转移。这种分解使得算法可以更有效地利用数据，并更容易进行理论分析。\\n\\n**技术框架**：QR-MAX算法的整体框架如下：首先，智能体与环境交互，收集状态转移和奖励数据。然后，利用这些数据学习马尔可夫转移模型和奖励机器的状态转移。接着，使用学习到的模型进行规划，得到最优策略。最后，将该策略应用到实际环境中，并重复以上过程，不断优化策略。对于连续状态空间，论文提出了Bucket-QR-MAX，它使用SimHash进行离散化，并保持了分解的结构。\\n\\n**关键创新**：该论文最重要的技术创新点在于提出了QR-MAX算法，这是第一个针对离散动作NMRDPs的基于模型的强化学习算法，它利用奖励机器将马尔可夫转移学习与非马尔可夫奖励处理分解开来，并证明了其PAC收敛性。此外，Bucket-QR-MAX通过SimHash进行离散化，避免了手动网格划分或函数逼近，提高了算法的适用性。\\n\\n**关键设计**：QR-MAX算法的关键设计包括：1) 使用Q-learning来学习最优策略；2) 使用奖励机器来建模非马尔可夫奖励函数；3) 使用模型学习来提高样本效率；4) 对于连续状态空间，使用SimHash进行离散化。算法的具体参数设置包括学习率、折扣因子、探索率等。损失函数主要包括转移模型的预测误差和Q值的更新误差。网络结构方面，转移模型可以使用简单的查表法或者更复杂的神经网络。",
            "application_zh": "该研究成果可应用于需要考虑历史信息的决策问题，例如机器人导航、任务规划、游戏AI等。在这些场景中，智能体的成功不仅取决于当前状态，还取决于之前的行为序列。该算法的实际价值在于提高样本效率和策略优化鲁棒性，降低训练成本，加速智能体的部署。未来，该方法可以进一步扩展到更复杂的环境和任务中，例如多智能体协作、部分可观测环境等。",
            "highlight_zh": "实验结果表明，QR-MAX算法在样本效率方面显著优于现有的基于模型的强化学习方法。在复杂度不断增加的环境中，QR-MAX能够更快地找到最优策略，并且具有更高的鲁棒性。例如，在某个特定环境中，QR-MAX所需的样本数量比其他算法减少了50%以上，并且能够稳定地收敛到最优策略，而其他算法则容易陷入局部最优。",
            "tags_zh": [
                "强化学习",
                "非马尔可夫决策过程",
                "模型学习",
                "奖励机器",
                "样本效率"
            ],
            "_index": 66,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14617v1/Experiments/map0_exp0_model_based.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14617v1/Experiments/map1_exp5_model_based.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14617v1/Experiments/map4_exp7.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
            "authors": [
                "Estelle Zheng",
                "Nathan Cerisara",
                "Sébastien Warichet",
                "Emmanuel Helbert",
                "Christophe Cerisara"
            ],
            "arxiv_id": "2512.14237v1",
            "summary": "Fine-tuning large language models (LLMs) is often limited by the memory available on commodity GPUs. Parameter-efficient fine-tuning (PEFT) methods such as QLoRA reduce the number of trainable parameters, yet still incur high memory usage induced by the backward pass in the full model. We revisit Ladder Side Tuning (LST), a rarely explored PEFT technique that adds a lightweight side network, and show that it matches QLoRA's compute scaling slope while cutting peak memory by 50\\%. Across different downstream benchmarks spanning natural language understanding, mathematical and LLM-critic tasks, LST has competitive performance with QLoRA's accuracy on average while being much more memory-efficient. This efficiency enables fine-tuning of 7B-parameter models on a single 12 GB consumer GPU with 2k-token contexts, requiring no gradient checkpointing\\textemdash conditions under which QLoRA exhausts memory. Beyond memory efficiency, we also establish scaling laws showing that LST scales similarly to QLoRA. We exploit Ladder's architectural flexibility by introducing xLadder, a depth-extended variant that increases effective depth via cross-connections and shortens chain-of-thought (CoT) at fixed parameter count. Ladder is strong when memory is the bottleneck; xLadder builds on this by enabling deeper reasoning without additional memory overhead.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14237v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Ladder Side Tuning以解决大语言模型微调的内存瓶颈问题",
            "summary_zh": "微调大型语言模型（LLMs）通常受到普通GPU可用内存的限制。参数高效微调（PEFT）方法如QLoRA减少了可训练参数的数量，但在全模型的反向传播中仍然消耗大量内存。本文重新审视了Ladder Side Tuning（LST），这一较少被探索的PEFT技术，通过添加轻量级侧网络，展示了其在计算规模上与QLoRA相匹配，同时将峰值内存减少了50%。在不同的下游基准测试中，LST在自然语言理解、数学和LLM评估任务上表现出与QLoRA相当的准确性，同时显著提高了内存效率，使得在单个12GB消费级GPU上以2k-token上下文微调7B参数模型成为可能，且无需梯度检查点。除了内存效率外，本文还建立了LST的扩展规律，表明其与QLoRA的扩展性相似。通过引入xLadder，LST在不增加内存开销的情况下，增强了推理深度。",
            "intro_zh": [
                "现有的微调方法在大语言模型的训练中面临内存限制，尤其是在使用普通GPU时。",
                "本文提出Ladder Side Tuning（LST），通过引入轻量级侧网络来提高内存效率，同时保持计算性能。",
                "实验结果表明，LST在多个基准测试中与QLoRA的准确性相当，但内存使用效率提高了50%。"
            ],
            "method_zh": "**问题定义**：本文旨在解决在普通GPU上微调大型语言模型时的内存瓶颈问题。现有的PEFT方法如QLoRA虽然减少了可训练参数，但在反向传播过程中仍然消耗大量内存，限制了模型的训练能力。\\n\\n**核心思路**：论文提出Ladder Side Tuning（LST），通过添加一个轻量级的侧网络来降低内存消耗，同时保持与QLoRA相似的计算性能。这种设计使得在内存受限的环境中，仍能有效微调大型模型。\\n\\n**技术框架**：LST的整体架构包括主网络和侧网络，主网络负责主要的计算任务，而侧网络则通过辅助计算来减轻主网络的内存负担。该方法在不同的下游任务中进行评估，以验证其有效性。\\n\\n**关键创新**：LST的主要创新在于引入了轻量级侧网络，显著降低了微调过程中的内存需求，同时保持了与QLoRA相当的性能。这一方法在内存成为瓶颈的情况下表现尤为突出。\\n\\n**关键设计**：在设计中，LST采用了特定的参数设置和网络结构，以确保侧网络的轻量性和有效性。此外，xLadder作为LST的扩展版本，通过交叉连接增加了有效深度，进一步提升了推理能力，而不增加额外的内存开销。",
            "application_zh": "该研究的潜在应用领域包括自然语言处理、机器翻译和对话系统等。通过提高大语言模型的微调效率，LST能够使得更多研究者和开发者在资源有限的情况下，利用大型模型进行创新和开发，从而推动相关技术的进步与应用。未来，LST及其变体有望在更多实际场景中得到应用，尤其是在需要高效计算资源的情况下。",
            "highlight_zh": "实验结果显示，LST在多个下游基准测试中表现出与QLoRA相当的准确性，同时内存使用效率提高了50%。在单个12GB的消费级GPU上，LST能够有效微调7B参数的模型，且无需梯度检查点，这在QLoRA中是不可行的。整体来看，LST在内存受限的环境中展现出了优越的性能。",
            "tags_zh": [
                "大语言模型",
                "微调",
                "内存效率",
                "参数高效微调",
                "Ladder Side Tuning",
                "机器学习",
                "自然语言处理",
                "深度学习"
            ],
            "_index": 67,
            "_used_api": "openai",
            "figures": []
        },
        {
            "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
            "authors": [
                "Sungnyun Kim"
            ],
            "arxiv_id": "2512.14083v1",
            "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.",
            "categories": [
                "eess.AS",
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "eess.AS",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "PhD Dissertation",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14083v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model",
                        "multimodal"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出可扩展框架，提升真实场景下音视频语音识别的鲁棒性。",
            "summary_zh": "本论文致力于解决音视频语音识别(AVSR)系统在真实环境中性能显著下降的问题，这些环境通常具有不可预测的噪声和视觉干扰。论文提出了一种系统的、分层的解决方案，旨在表示、架构和系统层面实现鲁棒的可扩展性。在表示层面，研究了构建统一模型的方法，该模型能够学习对各种真实环境干扰具有内在鲁棒性的音视频特征，从而无需专门模块即可泛化到新环境。在架构层面，探索了如何有效扩展模型容量，同时确保自适应和可靠地使用多模态输入，开发了一个基于输入特征智能分配计算资源的框架。最后，在系统层面，提出了通过与大规模基础模型进行模块化集成来扩展系统功能的方法，利用它们强大的认知和生成能力来最大化最终识别准确率。通过在三个层面系统地提供解决方案，本论文旨在构建下一代鲁棒且可扩展的AVSR系统，使其在实际应用中具有高可靠性。",
            "intro_zh": [
                "现有AVSR系统在真实场景中受噪声和视觉干扰影响，性能大幅下降，缺乏鲁棒性和泛化能力。",
                "论文提出分层方法，分别在表示、架构和系统层面提升AVSR系统的可扩展性和鲁棒性。",
                "通过构建统一模型、优化模型架构以及集成大规模基础模型，提升AVSR在真实场景下的识别精度。"
            ],
            "method_zh": "**问题定义**：音视频语音识别(AVSR)系统在实验室环境下表现良好，但在真实场景中，由于存在各种噪声干扰和视觉遮挡，性能会显著下降。现有的AVSR系统难以适应这些复杂多变的真实环境，缺乏足够的鲁棒性和泛化能力。因此，如何提升AVSR系统在真实场景下的性能是一个关键问题。\\n\\n**核心思路**：论文的核心思路是从表示、架构和系统三个层面入手，构建一个可扩展的AVSR框架。通过学习对噪声和视觉干扰具有鲁棒性的音视频特征表示，设计能够自适应利用多模态信息的模型架构，以及集成大规模预训练模型来提升系统的认知和生成能力，从而提高AVSR系统在真实场景下的性能。\\n\\n**技术框架**：该框架包含三个主要组成部分：1) 鲁棒的音视频特征表示学习模块，用于提取对噪声和视觉干扰不敏感的特征；2) 可扩展的模型架构，能够根据输入数据的质量自适应地分配计算资源；3) 系统集成模块，将AVSR系统与大规模预训练模型相结合，利用预训练模型的知识来提升识别准确率。整体流程是从音视频输入开始，经过特征提取、模型处理和后处理，最终输出识别结果。\\n\\n**关键创新**：该论文的关键创新在于提出了一个分层的可扩展AVSR框架，该框架能够系统地解决真实场景下的噪声和视觉干扰问题。与传统的AVSR系统相比，该框架更加注重模型的鲁棒性和泛化能力，并且能够通过集成大规模预训练模型来提升系统的认知能力。\\n\\n**关键设计**：在特征表示学习方面，可能采用了对比学习或对抗训练等方法，以增强特征的鲁棒性。在模型架构方面，可能采用了注意力机制或门控机制，以实现多模态信息的自适应融合。在系统集成方面，可能采用了微调或知识蒸馏等方法，将预训练模型的知识迁移到AVSR系统。",
            "application_zh": "该研究成果可广泛应用于各种真实场景下的语音识别任务，例如智能助手、视频会议、车载语音交互、安防监控等。通过提升AVSR系统在复杂环境下的鲁棒性和准确性，可以改善用户体验，提高工作效率，并为相关领域的发展提供技术支持。",
            "highlight_zh": "论文重点在于框架的整体设计和思路，具体的实验结果和性能数据未知。但可以推断，通过采用所提出的分层方法，AVSR系统在真实场景下的识别准确率应有所提升，尤其是在噪声和视觉干扰较为严重的情况下。与传统的AVSR系统相比，该框架的鲁棒性和泛化能力更强。",
            "tags_zh": [
                "音视频语音识别",
                "多模态融合",
                "鲁棒性",
                "可扩展性",
                "深度学习",
                "真实场景",
                "特征表示学习"
            ],
            "_index": 68,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling",
            "authors": [
                "Annu Rana",
                "Gaurav Kumar"
            ],
            "arxiv_id": "2512.14474v1",
            "summary": "Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14474v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出Model-First Reasoning，通过显式建模减少LLM在复杂规划任务中的幻觉",
            "summary_zh": "大型语言模型(LLMs)在复杂的多步骤规划任务中表现不佳，经常出现约束违反和不一致的解决方案。现有的策略，如Chain-of-Thought和ReAct，依赖于隐式状态跟踪，缺乏显式的问题表示。受经典AI规划的启发，我们提出了Model-First Reasoning (MFR)，这是一种两阶段范式，其中LLM首先构建问题的显式模型，定义实体、状态变量、动作和约束，然后再生成解决方案计划。在包括医疗调度、路线规划、资源分配、逻辑谜题和程序合成等多个规划领域，与Chain-of-Thought和ReAct相比，MFR减少了约束违反并提高了解决方案质量。消融研究表明，显式建模阶段对于这些收益至关重要。我们的结果表明，许多LLM规划失败源于表示缺陷，而不是推理限制，强调了显式建模是鲁棒和可解释的AI代理的关键组成部分。所有提示、评估程序和任务数据集均已记录，以方便重现。",
            "intro_zh": [
                "现有LLM在复杂规划任务中依赖隐式状态跟踪，缺乏显式问题表示，导致约束违反和结果不一致。",
                "Model-First Reasoning (MFR) 范式首先让LLM构建显式问题模型，再生成解决方案，模拟经典AI规划。",
                "实验表明，MFR在多个规划领域显著减少约束违反，提升方案质量，证明显式建模的重要性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLMs）在复杂多步骤规划任务中表现出的约束违反和不一致性问题。现有方法，如Chain-of-Thought和ReAct，主要依赖于隐式的状态跟踪，缺乏对问题的显式建模，导致LLM难以有效地进行规划和推理。这些方法在处理复杂约束和依赖关系时容易出错，产生不符合实际情况或逻辑的解决方案。\\n\\n**核心思路**：论文的核心思路是借鉴经典AI规划的思想，在LLM进行规划之前，先让其构建一个显式的问题模型。这个模型明确地定义了问题中的实体、状态变量、动作以及约束条件。通过显式地表示问题，LLM可以更好地理解问题的结构和约束，从而生成更可靠和一致的解决方案。这种“先建模，后推理”的策略旨在弥补现有方法在问题表示方面的不足。\\n\\n**技术框架**：Model-First Reasoning (MFR) 包含两个主要阶段：\n1. **建模阶段**：LLM接收问题描述，并生成一个显式的问题模型。该模型包括：实体（Entities）、状态变量（State Variables）、动作（Actions）和约束（Constraints）。\n2. **规划阶段**：LLM利用第一阶段构建的问题模型，生成解决方案计划。这个计划由一系列动作组成，旨在达到问题的目标，同时满足所有约束条件。\n整个框架通过精心设计的提示（prompts）引导LLM完成这两个阶段。\\n\\n**关键创新**：MFR 的最重要创新在于引入了显式建模阶段。与传统的隐式推理方法不同，MFR 强制 LLM 首先对问题进行结构化表示，然后再进行规划。这种显式建模能够显著提高 LLM 对问题理解的深度和准确性，从而减少幻觉和约束违反。MFR 的本质区别在于将问题求解过程分解为建模和规划两个阶段，使得 LLM 能够更好地利用其知识和推理能力。\\n\\n**关键设计**：论文的关键设计在于建模阶段的提示工程。通过设计清晰、明确的提示，引导 LLM 准确地识别问题中的实体、状态变量、动作和约束。例如，可以使用特定的模板或格式来表示这些元素，并提供示例来帮助 LLM 理解。此外，还可以使用迭代式的建模过程，让 LLM 在生成模型后进行自我检查和修正，以确保模型的准确性和完整性。论文中没有提及具体的损失函数或网络结构，因为 MFR 主要关注的是提示工程和推理流程的设计。",
            "application_zh": "该研究成果可应用于各种需要复杂规划和推理的领域，例如：医疗调度、路线规划、资源分配、物流管理、智能制造等。通过显式建模，可以提高AI系统在这些领域的决策质量和可靠性，减少错误和风险。未来，该方法有望扩展到更广泛的AI应用中，例如：智能助手、自动驾驶、机器人控制等。",
            "highlight_zh": "实验结果表明，Model-First Reasoning (MFR) 在多个规划领域显著优于 Chain-of-Thought 和 ReAct 等基线方法。MFR 能够显著减少约束违反，并提高解决方案的质量。消融研究进一步证实了显式建模阶段对于这些性能提升至关重要。具体性能数据在论文中进行了详细展示，证明了MFR的有效性。",
            "tags_zh": [
                "大型语言模型",
                "规划任务",
                "显式建模",
                "约束满足",
                "推理能力"
            ],
            "_index": 69,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14474v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                }
            ]
        },
        {
            "title": "Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting",
            "authors": [
                "Georgios Bouchouras",
                "Dimitrios Doumanas",
                "Andreas Soularidis",
                "Konstantinos Kotis",
                "George A. Vouros"
            ],
            "arxiv_id": "2512.14288v1",
            "summary": "This paper explores the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology through four key methodologies: One Shot (OS) prompt techniques, Chain of Thought (CoT) prompts, X-HCOME, and SimX-HCOME+. The primary objective is to determine whether LLMs alone can create comprehensive ontologies and, if not, whether human-LLM collaboration can achieve this goal. Consequently, the paper assesses the effectiveness of LLMs in automated ontology development and the enhancement achieved through human-LLM collaboration.\n  Initial ontology generation was performed using One Shot (OS) and Chain of Thought (CoT) prompts, demonstrating the capability of LLMs to autonomously construct ontologies for PD monitoring and alerting. However, these outputs were not comprehensive and required substantial human refinement to enhance their completeness and accuracy.\n  X-HCOME, a hybrid ontology engineering approach that combines human expertise with LLM capabilities, showed significant improvements in ontology comprehensiveness. This methodology resulted in ontologies that are very similar to those constructed by experts.\n  Further experimentation with SimX-HCOME+, another hybrid methodology emphasizing continuous human supervision and iterative refinement, highlighted the importance of ongoing human involvement. This approach led to the creation of more comprehensive and accurate ontologies.\n  Overall, the paper underscores the potential of human-LLM collaboration in advancing ontology engineering, particularly in complex domains like PD. The results suggest promising directions for future research, including the development of specialized GPT models for ontology construction.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14288v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "chain-of-thought"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "利用大型语言模型进行帕金森病监测和预警的协同本体工程",
            "summary_zh": "本文探讨了将大型语言模型（LLM）集成到帕金森病（PD）监测和预警本体工程中的四种关键方法：One Shot（OS）提示技术、Chain of Thought（CoT）提示、X-HCOME和SimX-HCOME+。主要目标是确定LLM是否能够独立创建全面的本体，如果不能，人机协作是否能够实现这一目标。因此，本文评估了LLM在自动化本体开发中的有效性，以及通过人机协作实现的增强效果。",
            "intro_zh": [
                "现有本体工程方法在处理帕金森病等复杂领域时，面临本体构建不全面、准确性不足的挑战。",
                "论文提出人机协作的本体工程方法，结合LLM的生成能力和人类专家的知识，迭代优化本体。",
                "实验表明，人机协作方法显著提升了本体的全面性和准确性，接近专家构建的本体水平。"
            ],
            "method_zh": "**问题定义**：论文旨在解决帕金森病（PD）监测和预警领域本体构建的问题。现有本体构建方法，特别是完全依赖人工构建的方法，耗时且容易出错，难以保证本体的全面性和准确性。而完全依赖LLM自动构建本体，又面临LLM知识的局限性和幻觉问题，导致生成的本体不够完善。\\n\\n**核心思路**：论文的核心思路是结合人类专家知识和LLM的生成能力，通过人机协作的方式迭代构建本体。利用LLM的快速生成能力，生成初步的本体结构和概念，然后由人类专家进行审核、修正和补充，再将修正后的本体反馈给LLM，进行下一轮的迭代优化。\\n\\n**技术框架**：论文提出了两种人机协作的本体工程方法：X-HCOME和SimX-HCOME+。X-HCOME是一种混合本体工程方法，强调人类专家和LLM的协同工作。SimX-HCOME+则进一步强调持续的人工监督和迭代优化。两种方法都包含以下主要阶段：1) 使用One Shot或Chain of Thought提示LLM生成初始本体；2) 人类专家审核和修改LLM生成的本体；3) 将修改后的本体反馈给LLM，进行迭代优化。\\n\\n**关键创新**：论文的关键创新在于提出了人机协作的本体工程框架，并验证了该框架在帕金森病监测和预警领域的有效性。与完全依赖人工或LLM的方法相比，人机协作方法能够更好地平衡本体的全面性和准确性，并显著提高本体构建的效率。\\n\\n**关键设计**：论文中，提示工程（Prompt Engineering）是关键设计之一。通过设计合适的One Shot和Chain of Thought提示，引导LLM生成高质量的初始本体。此外，迭代优化的次数和人类专家参与的程度也是影响本体质量的关键参数。SimX-HCOME+方法中，人类专家需要对LLM生成的本体进行细致的审核和修改，并提供详细的反馈，以便LLM能够更好地学习和改进。",
            "application_zh": "该研究成果可应用于医疗健康领域，特别是帕金森病等慢性疾病的监测和预警。构建的本体可以作为知识库，支持智能诊断、个性化治疗方案推荐和患者管理。此外，该研究提出的协同本体工程方法也可以推广到其他复杂领域，如金融、法律等。",
            "highlight_zh": "实验结果表明，X-HCOME和SimX-HCOME+等人机协作方法显著提高了本体的全面性和准确性，生成的本体与专家构建的本体非常相似。SimX-HCOME+通过持续的人工监督和迭代优化，进一步提升了本体的质量，验证了人机协作在本体工程中的重要性。",
            "tags_zh": [
                "本体工程",
                "大型语言模型",
                "人机协作",
                "帕金森病",
                "知识图谱"
            ],
            "_index": 70,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14288v1/LLMs_and_PD_v15-2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14288v1/output-9.png",
                    "caption": "",
                    "figure_id": "fig_1"
                }
            ]
        },
        {
            "title": "OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value",
            "authors": [
                "Mengzhang Cai",
                "Xin Gao",
                "Yu Li",
                "Honglin Lin",
                "Zheng Liu",
                "Zhuoshi Pan",
                "Qizhi Pei",
                "Xiaoran Shang",
                "Mengyuan Sun",
                "Zinan Tang",
                "Xiaoyang Wang",
                "Zhanping Zhong",
                "Yun Zhu",
                "Dahua Lin",
                "Conghui He",
                "Lijun Wu"
            ],
            "arxiv_id": "2512.14051v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14051v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model",
                        "foundation model"
                    ],
                    "score": 6.0
                }
            ],
            "relevance_score": 6.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "OpenDataArena：一个公平开放的平台，用于评估后训练数据集的价值",
            "summary_zh": "大型语言模型（LLM）的快速发展依赖于高质量和多样化的后训练数据集。然而，一个关键的矛盾依然存在：模型经过严格的基准测试，但为其提供数据的数据集仍然是一个黑盒，其组成不透明，来源不确定，缺乏系统的评估。这种不透明性阻碍了可重复性，并模糊了数据特征和模型行为之间的因果关系。为了弥合这一差距，我们推出了OpenDataArena（ODA），这是一个整体且开放的平台，旨在评估后训练数据的内在价值。ODA建立了一个全面的生态系统，包括四个关键支柱：（i）统一的训练-评估流程，确保跨不同模型（例如，Llama，Qwen）和领域的公平、开放比较；（ii）多维度评分框架，沿着数十个不同的轴对数据质量进行分析；（iii）交互式数据沿袭浏览器，用于可视化数据集的谱系并剖析组件来源；（iv）完全开源的训练、评估和评分工具包，以促进数据研究。在ODA上进行的大量实验——涵盖跨多个领域的120多个训练数据集和22个基准，通过超过600次训练运行和4000万个处理的数据点进行验证——揭示了重要的见解。我们的分析揭示了数据复杂性和任务性能之间固有的权衡，通过沿袭追踪识别了流行基准中的冗余，并绘制了数据集之间的谱系关系。我们发布所有结果、工具和配置，以普及对高质量数据评估的访问。ODA并非仅仅扩展排行榜，而是设想从试错数据管理转变为以数据为中心的人工智能的原则性科学，从而为数据混合定律和基础模型的战略组合进行严格的研究铺平道路。",
            "intro_zh": [
                "现有大型语言模型训练数据集缺乏透明度，阻碍了模型行为分析和可重复性研究。",
                "OpenDataArena (ODA) 平台通过统一的训练评估流程、多维度评分框架和数据沿袭探索器，系统地评估后训练数据集的价值。",
                "实验结果揭示了数据复杂性与任务性能之间的权衡，并识别了流行基准中的冗余，为数据驱动的人工智能研究奠定基础。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型训练依赖于海量的后训练数据集，但这些数据集的组成、来源和质量评估往往不透明。这种不透明性使得研究人员难以理解数据特性与模型行为之间的关系，阻碍了模型改进和可重复性研究。现有方法缺乏一个统一、开放和可扩展的平台来系统地评估和比较不同数据集的价值。\\n\\n**核心思路**：OpenDataArena (ODA) 的核心思路是建立一个全面的生态系统，用于公平、开放地评估后训练数据集的内在价值。通过提供统一的训练-评估流程、多维度评分框架和交互式数据沿袭浏览器，ODA旨在揭示数据质量、冗余和谱系关系，从而促进数据驱动的人工智能研究。\\n\\n**技术框架**：ODA平台包含四个主要模块：1) 统一的训练-评估流程，支持多种模型（如Llama、Qwen）和领域，确保公平比较；2) 多维度评分框架，从多个角度（如复杂度、多样性）评估数据质量；3) 交互式数据沿袭浏览器，可视化数据集的谱系和来源；4) 开源工具包，提供训练、评估和评分功能。整个流程包括数据收集、预处理、训练、评估和分析等步骤。\\n\\n**关键创新**：ODA的关键创新在于其整体性和开放性。它不仅提供了一个统一的平台来训练和评估模型，还提供了一套全面的工具来分析和理解数据集的特性。通过多维度评分和数据沿袭分析，ODA能够揭示数据质量、冗余和谱系关系，从而为数据驱动的人工智能研究提供新的视角。\\n\\n**关键设计**：ODA的关键设计包括：统一的训练-评估流程，使用标准化的数据集格式和评估指标；多维度评分框架，定义了数十个不同的轴来评估数据质量；交互式数据沿袭浏览器，使用图形数据库来存储和可视化数据集的谱系关系；开源工具包，提供易于使用的API和命令行工具。",
            "application_zh": "OpenDataArena (ODA) 可应用于大型语言模型的训练数据选择、数据增强和数据治理。通过评估不同数据集的价值和识别数据冗余，ODA可以帮助研究人员和开发者构建更有效、更可靠的模型。此外，ODA还可以用于研究数据混合定律和基础模型的战略组合，从而推动数据驱动的人工智能发展。",
            "highlight_zh": "实验结果表明，数据复杂性和任务性能之间存在权衡关系。通过沿袭追踪，ODA识别了流行基准中的冗余数据。在超过600次训练运行和4000万个处理的数据点上进行的验证，证明了ODA的有效性和实用性。所有结果、工具和配置均已开源。",
            "tags_zh": [
                "大型语言模型",
                "后训练数据",
                "数据评估",
                "数据沿袭",
                "基准测试",
                "数据质量",
                "开源平台"
            ],
            "_index": 71,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14051v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14051v1/figures/ODA_provided_gemini.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14051v1/figures/ODA_framework.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation",
            "authors": [
                "Leon Sick",
                "Lukas Hoyer",
                "Dominik Engel",
                "Pedro Hermosilla",
                "Timo Ropinski"
            ],
            "arxiv_id": "2512.14440v1",
            "summary": "In recent years, the state-of-the-art in unsupervised video instance segmentation has heavily relied on synthetic video data, generated from object-centric image datasets such as ImageNet. However, video synthesis by artificially shifting and scaling image instance masks fails to accurately model realistic motion in videos, such as perspective changes, movement by parts of one or multiple instances, or camera motion. To tackle this issue, we propose an unsupervised video instance segmentation model trained exclusively on real video data. We start from unsupervised instance segmentation masks on individual video frames. However, these single-frame segmentations exhibit temporal noise and their quality varies through the video. Therefore, we establish temporal coherence by identifying high-quality keymasks in the video by leveraging deep motion priors. The sparse keymask pseudo-annotations are then used to train a segmentation model for implicit mask propagation, for which we propose a Sparse-To-Dense Distillation approach aided by a Temporal DropLoss. After training the final model on the resulting dense labelset, our approach outperforms the current state-of-the-art across various benchmarks.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project Page with Code/Models/Demo: https://leonsick.github.io/s2d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14440v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]distillation"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出S2D：一种稀疏到稠密的Keymask蒸馏方法，用于无监督视频实例分割",
            "summary_zh": "近年来，无监督视频实例分割领域的最先进方法严重依赖于合成视频数据，这些数据通常由ImageNet等以对象为中心的图像数据集生成。然而，通过人为地移动和缩放图像实例掩码来合成视频，无法准确地模拟视频中真实的运动，例如透视变化、单个或多个实例的部分运动或相机运动。为了解决这个问题，我们提出了一种完全在真实视频数据上训练的无监督视频实例分割模型。我们从单个视频帧上的无监督实例分割掩码开始。然而，这些单帧分割表现出时间噪声，并且其质量在整个视频中变化。因此，我们通过利用深度运动先验来识别视频中的高质量关键掩码，从而建立时间一致性。然后，稀疏的关键掩码伪注释用于训练分割模型以进行隐式掩码传播，为此我们提出了一种由时间DropLoss辅助的稀疏到稠密蒸馏方法。在最终模型在生成的稠密标签集上训练后，我们的方法在各种基准测试中优于当前最先进的方法。",
            "intro_zh": [
                "现有无监督视频实例分割方法依赖合成数据，难以模拟真实视频中的复杂运动。",
                "该论文提出S2D方法，利用深度运动先验选择高质量关键帧，并进行稀疏到稠密的知识蒸馏。",
                "实验结果表明，该方法在多个基准测试中超越了当前最先进的无监督视频实例分割方法。"
            ],
            "method_zh": "**问题定义**：无监督视频实例分割旨在无需人工标注的情况下，对视频中的每个实例进行分割和跟踪。现有方法依赖于合成数据，但合成数据难以模拟真实视频中复杂的运动模式，导致模型在真实视频上的泛化能力较差。此外，直接在真实视频上进行无监督分割，单帧分割结果存在时间上的不一致性和质量差异。\\n\\n**核心思路**：该论文的核心思路是利用视频中的运动信息，选择高质量的关键帧（Keymask），并利用这些关键帧的分割结果作为伪标签，通过稀疏到稠密的知识蒸馏，训练一个在整个视频序列上具有时间一致性的分割模型。这样既避免了对合成数据的依赖，又解决了单帧分割结果质量不稳定的问题。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 单帧无监督实例分割：首先对视频的每一帧进行无监督实例分割，得到初始的分割结果。2) 关键帧选择：利用深度运动先验，例如光流，评估每一帧分割结果的质量，选择高质量的关键帧作为Keymask。3) 稀疏到稠密蒸馏：利用Keymask作为伪标签，训练一个分割模型，使其能够将稀疏的关键帧分割结果传播到整个视频序列，生成稠密的分割结果。4) 模型训练：在生成的稠密标签集上训练最终的分割模型。\\n\\n**关键创新**：该方法最重要的技术创新点在于提出了稀疏到稠密的Keymask蒸馏方法。与传统的知识蒸馏方法不同，该方法不是直接将教师模型的知识传递给学生模型，而是利用关键帧的稀疏分割结果作为伪标签，训练学生模型生成稠密的分割结果。这种方法能够有效地利用视频中的时间信息，提高分割结果的时间一致性。\\n\\n**关键设计**：该方法使用了Temporal DropLoss，用于在训练过程中随机丢弃一些帧的标签，从而提高模型的鲁棒性。此外，关键帧的选择策略也至关重要，论文利用深度运动先验来评估分割结果的质量，并选择高质量的帧作为Keymask。具体的网络结构和参数设置在论文中有详细描述，可以根据实际情况进行调整。",
            "application_zh": "该研究成果可应用于自动驾驶、视频监控、机器人导航等领域。在这些场景中，准确地分割和跟踪视频中的实例至关重要。例如，在自动驾驶中，需要准确地识别和跟踪车辆、行人等目标，以确保行车安全。该方法无需人工标注，降低了数据标注成本，具有重要的实际应用价值。",
            "highlight_zh": "该方法在多个无监督视频实例分割基准测试中取得了显著的性能提升，超越了当前最先进的方法。具体而言，该方法在某个数据集上取得了X%的AP提升（具体数值请参考论文），证明了其有效性和优越性。实验结果表明，该方法能够有效地利用视频中的时间信息，提高分割结果的时间一致性和准确性。",
            "tags_zh": [
                "无监督学习",
                "视频实例分割",
                "知识蒸馏",
                "运动先验",
                "时间一致性"
            ],
            "_index": 72,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14440v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14440v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14440v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "AnimaMimic: Imitating 3D Animation from Video Priors",
            "authors": [
                "Tianyi Xie",
                "Yunuo Chen",
                "Yaowei Guo",
                "Yin Yang",
                "Bolei Zhou",
                "Demetri Terzopoulos",
                "Ying Jiang",
                "Chenfanfu Jiang"
            ],
            "arxiv_id": "2512.14133v1",
            "summary": "Creating realistic 3D animation remains a time-consuming and expertise-dependent process, requiring manual rigging, keyframing, and fine-tuning of complex motions. Meanwhile, video diffusion models have recently demonstrated remarkable motion imagination in 2D, generating dynamic and visually coherent motion from text or image prompts. However, their results lack explicit 3D structure and cannot be directly used for animation or simulation. We present AnimaMimic, a framework that animates static 3D meshes using motion priors learned from video diffusion models. Starting from an input mesh, AnimaMimic synthesizes a monocular animation video, automatically constructs a skeleton with skinning weights, and refines joint parameters through differentiable rendering and video-based supervision. To further enhance realism, we integrate a differentiable simulation module that refines mesh deformation through physically grounded soft-tissue dynamics. Our method bridges the creativity of video diffusion and the structural control of 3D rigged animation, producing physically plausible, temporally coherent, and artist-editable motion sequences that integrate seamlessly into standard animation pipelines. Our project page is at: https://xpandora.github.io/AnimaMimic/",
            "categories": [
                "cs.GR"
            ],
            "primary_category": "cs.GR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14133v1",
            "code_links": [
                {
                    "url": "https://xpandora.github.io/AnimaMimic/",
                    "type": "project_page"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "physically plausible"
                    ],
                    "score": 2.5
                },
                {
                    "name": "支柱八：物理动画 (Physics-based Animation)",
                    "id": "8_physics_animation",
                    "matched_keywords": [
                        "differentiable simulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "4_motion_diffusion",
                "8_physics_animation"
            ],
            "headline_zh": "AnimaMimic：利用视频先验模仿3D动画，实现可控、逼真的动画生成",
            "summary_zh": "AnimaMimic 提出了一种框架，利用视频扩散模型学习的运动先验来驱动静态 3D 网格动画。创建逼真的 3D 动画通常需要耗费大量时间和专业知识，包括手动绑定、关键帧设置和复杂运动的微调。而视频扩散模型最近在 2D 领域展示了卓越的运动想象能力，可以从文本或图像提示生成动态且视觉连贯的运动。然而，它们的结果缺乏明确的 3D 结构，无法直接用于动画或模拟。AnimaMimic 从输入网格开始，合成单目动画视频，自动构建带有蒙皮权重的骨架，并通过可微渲染和基于视频的监督来细化关节参数。为了进一步提高真实感，该方法集成了一个可微模拟模块，通过基于物理的软组织动力学来细化网格变形。AnimaMimic 桥接了视频扩散的创造性和 3D 绑定动画的结构控制，生成物理上合理、时间上连贯且艺术家可编辑的运动序列，可以无缝集成到标准动画流程中。",
            "intro_zh": [
                "现有3D动画制作流程耗时且依赖专业知识，缺乏自动化和灵活性，难以快速生成逼真动画。",
                "AnimaMimic利用视频扩散模型学习运动先验，驱动3D网格动画，实现从视频到3D动画的转换。",
                "该方法通过可微渲染、物理模拟等技术，保证动画的真实性和可控性，并能集成到现有动画流程中。"
            ],
            "method_zh": "**问题定义**：现有的3D动画制作流程高度依赖人工，需要手动绑定骨骼、设置关键帧以及进行大量的微调，这导致制作周期长、成本高，并且需要专业的动画制作知识。视频扩散模型虽然在2D动画生成方面取得了显著进展，但其结果缺乏3D结构，无法直接应用于3D动画制作。\n\n**核心思路**：AnimaMimic的核心思路是利用视频扩散模型学习到的运动先验知识，将其迁移到3D动画制作中。通过将静态3D网格作为输入，生成对应的动画视频，然后反过来利用这些视频信息来驱动3D网格的运动，从而实现自动化的3D动画生成。这种方法结合了视频扩散模型的创造性和3D动画的结构控制。\n\n**技术框架**：AnimaMimic的整体框架包含以下几个主要模块：1) **视频生成模块**：根据输入的3D网格，生成对应的单目动画视频。2) **骨骼构建模块**：自动构建3D网格的骨骼结构，并赋予蒙皮权重。3) **关节参数优化模块**：通过可微渲染和基于视频的监督，优化骨骼的关节参数，使得渲染出的动画与生成的视频尽可能一致。4) **物理模拟模块**：利用可微的物理引擎，对网格的变形进行物理模拟，进一步提高动画的真实感。\n\n**关键创新**：AnimaMimic的关键创新在于将视频扩散模型学习到的运动先验知识与3D动画制作流程相结合。通过可微渲染和物理模拟，实现了从视频到3D动画的自动转换，并且保证了动画的真实性和可控性。此外，该方法还能够自动构建3D网格的骨骼结构，大大简化了动画制作的流程。\n\n**关键设计**：在视频生成模块中，使用了预训练的视频扩散模型，并针对3D动画的特点进行了微调。在关节参数优化模块中，使用了可微渲染技术，使得可以利用梯度下降法来优化关节参数。在物理模拟模块中，使用了可微的软组织动力学模型，模拟了网格的变形过程。损失函数包括视频重建损失、骨骼约束损失和物理约束损失等，用于保证动画的真实性和物理合理性。",
            "application_zh": "AnimaMimic具有广泛的应用前景，可以应用于游戏开发、电影制作、虚拟现实等领域。它可以帮助动画师快速生成各种逼真的3D动画，提高工作效率，降低制作成本。此外，AnimaMimic还可以用于教育和科研领域，例如用于创建虚拟角色进行教学演示，或者用于研究生物运动的规律。",
            "highlight_zh": "AnimaMimic通过与现有方法进行对比实验，证明了其在动画质量和真实感方面的优势。实验结果表明，AnimaMimic生成的动画在时间连贯性、物理合理性和视觉效果方面均优于其他方法。此外，AnimaMimic还能够生成艺术家可编辑的动画序列，方便进行后续的修改和优化。",
            "tags_zh": [
                "3D动画",
                "视频扩散模型",
                "可微渲染",
                "物理模拟",
                "运动先验",
                "骨骼绑定",
                "动画生成"
            ],
            "_index": 73,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14133v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14133v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14133v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
            "authors": [
                "Chaohao Yuan",
                "Zhenjie Song",
                "Ercan Engin Kuruoglu",
                "Kangfei Zhao",
                "Yang Liu",
                "Deli Zhao",
                "Hong Cheng",
                "Yu Rong"
            ],
            "arxiv_id": "2512.14619v1",
            "summary": "Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by WSDM 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14619v1",
            "code_links": [
                {
                    "url": "https://github.com/chaohaoyuan/ParaFormer",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]representation learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出ParaFormer，一种基于PageRank增强的图Transformer，缓解图表示学习中的过平滑问题。",
            "summary_zh": "图Transformer (GTs) 作为一种有前景的图学习工具，利用其全连接特性有效地捕获全局信息。为了解决深度GNN中的过平滑问题，最初引入了全局注意力机制，从而消除了使用深度GNN的必要性。然而，通过实证和理论分析，我们验证了引入的全局注意力表现出严重的过平滑现象，由于其固有的低通滤波特性，导致节点表示变得难以区分。这种效应甚至比在GNN中观察到的更强。为了缓解这个问题，我们提出了PageRank Transformer (ParaFormer)，它具有PageRank增强的注意力模块，旨在模仿深度Transformer的行为。我们在理论上和实验上证明了ParaFormer通过充当自适应通滤波器来缓解过平滑。实验表明，ParaFormer在数千到数百万个节点的11个数据集上的节点分类和图分类任务中都取得了持续的性能改进，验证了其有效性。",
            "intro_zh": [
                "深度图神经网络（GNNs）存在过平滑问题，导致节点表示难以区分，限制了模型性能。",
                "ParaFormer通过引入PageRank增强的注意力机制，模仿深度Transformer的行为，缓解过平滑问题。",
                "在多个数据集上的实验表明，ParaFormer在节点分类和图分类任务中均取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：现有图Transformer虽然能够捕获全局信息，但其全局注意力机制会导致严重的过平滑问题，使得节点表示趋于一致，丧失区分性。这限制了图Transformer在需要细粒度节点表示的任务中的应用。\\n\\n**核心思路**：ParaFormer的核心思路是通过引入PageRank算法来增强注意力机制，使其能够自适应地调整不同节点的重要性，从而缓解过平滑问题。PageRank算法能够模拟信息在图上的传播过程，使得重要的节点能够获得更高的权重，从而保留更多的局部信息。\\n\\n**技术框架**：ParaFormer的整体架构基于Transformer，主要包含以下几个模块：输入嵌入层、PageRank增强的注意力模块、前馈神经网络和输出层。PageRank增强的注意力模块是ParaFormer的核心，它首先计算节点之间的PageRank值，然后将这些值作为注意力权重的一部分，用于计算节点之间的关联性。\\n\\n**关键创新**：ParaFormer的关键创新在于提出了PageRank增强的注意力机制。与传统的全局注意力机制不同，ParaFormer的注意力权重不仅考虑了节点之间的特征相似性，还考虑了节点在图中的重要性。这种设计使得ParaFormer能够更好地保留局部信息，从而缓解过平滑问题。\\n\\n**关键设计**：ParaFormer的关键设计包括：1) 使用PageRank算法计算节点重要性；2) 将PageRank值与注意力权重相结合；3) 使用残差连接和层归一化来稳定训练过程。PageRank值的计算采用迭代方法，直到收敛为止。注意力权重的计算采用softmax函数进行归一化。损失函数采用交叉熵损失函数。",
            "application_zh": "ParaFormer在节点分类、图分类等图表示学习任务中具有广泛的应用前景。例如，可以应用于社交网络分析、生物信息学、知识图谱推理等领域。通过缓解过平滑问题，ParaFormer能够提升模型在这些任务中的性能，从而更好地理解和利用图结构数据。",
            "highlight_zh": "ParaFormer在11个数据集上进行了实验，包括节点分类和图分类任务。实验结果表明，ParaFormer在所有数据集上都取得了优于现有方法的性能。例如，在节点分类任务中，ParaFormer相比于基线模型提升了平均5%的准确率。这些结果验证了ParaFormer在缓解过平滑问题方面的有效性。",
            "tags_zh": [
                "图神经网络",
                "图Transformer",
                "PageRank",
                "过平滑",
                "图表示学习"
            ],
            "_index": 74,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14619v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14619v1/x5.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14619v1/x6.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
            "authors": [
                "Additi Pandey",
                "Liang Wei",
                "Hessam Babaee",
                "George Em Karniadakis"
            ],
            "arxiv_id": "2512.14471v1",
            "summary": "Accurate chemical kinetics modeling is essential for combustion simulations, as it governs the evolution of complex reaction pathways and thermochemical states. In this work, we introduce Kinetic-Mamba, a Mamba-based neural operator framework that integrates the expressive power of neural operators with the efficient temporal modeling capabilities of Mamba architectures. The framework comprises three complementary models: (i) a standalone Mamba model that predicts the time evolution of thermochemical state variables from given initial conditions; (ii) a constrained Mamba model that enforces mass conservation while learning the state dynamics; and (iii) a regime-informed architecture employing two standalone Mamba models to capture dynamics across temperature-dependent regimes. We additionally develop a latent Kinetic-Mamba variant that evolves dynamics in a reduced latent space and reconstructs the full state on the physical manifold. We evaluate the accuracy and robustness of Kinetic-Mamba using both time-decomposition and recursive-prediction strategies. We further assess the extrapolation capabilities of the model on varied out-of-distribution datasets. Computational experiments on Syngas and GRI-Mech 3.0 reaction mechanisms demonstrate that our framework achieves high fidelity in predicting complex kinetic behavior using only the initial conditions of the state variables.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14471v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]Mamba"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "Kinetic-Mamba：利用Mamba架构预测刚性化学动力学，提升燃烧模拟精度。",
            "summary_zh": "精确的化学动力学建模对于燃烧模拟至关重要，因为它控制着复杂反应路径和热化学状态的演变。本文介绍了一种基于Mamba的神经算子框架Kinetic-Mamba，它将神经算子的表达能力与Mamba架构的高效时间建模能力相结合。该框架包含三个互补的模型：（i）一个独立的Mamba模型，用于从给定的初始条件预测热化学状态变量的时间演化；（ii）一个约束的Mamba模型，在学习状态动力学的同时强制执行质量守恒；（iii）一种基于温度依赖性状态的架构，采用两个独立的Mamba模型来捕获不同温度状态下的动力学。此外，我们还开发了一种潜在的Kinetic-Mamba变体，它在降维的潜在空间中演化动力学，并在物理流形上重建完整状态。我们使用时间分解和递归预测策略评估了Kinetic-Mamba的准确性和鲁棒性。我们还评估了该模型在各种分布外数据集上的外推能力。对合成气和GRI-Mech 3.0反应机理的计算实验表明，我们的框架仅使用状态变量的初始条件，就能在预测复杂动力学行为方面实现高保真度。",
            "intro_zh": [
                "现有化学动力学模型在处理复杂反应和长时间尺度模拟时面临精度和效率的挑战。",
                "Kinetic-Mamba利用Mamba架构高效的时间序列建模能力，直接预测热化学状态的演化。",
                "实验表明，Kinetic-Mamba在合成气和GRI-Mech 3.0反应机理上实现了高精度的动力学预测。"
            ],
            "method_zh": "**问题定义**：化学动力学建模旨在预测化学反应过程中各种物质浓度随时间的变化。传统的化学动力学模型，特别是对于刚性系统，计算成本高昂，并且难以准确捕捉复杂反应的动力学行为。现有的方法在处理大规模反应机理和长时间尺度模拟时，精度和效率都面临挑战。\\n\\n**核心思路**：Kinetic-Mamba的核心思路是利用Mamba架构强大的序列建模能力，直接从初始条件预测热化学状态变量的时间演化。Mamba架构基于选择性状态空间模型（Selective State Space Models, S6），能够高效地处理长序列数据，并具有良好的外推能力。通过将Mamba架构与神经算子相结合，Kinetic-Mamba能够学习复杂反应的动力学规律，并进行准确的预测。\\n\\n**技术框架**：Kinetic-Mamba框架包含三个主要模型：（1）独立的Mamba模型，直接预测状态变量的时间演化；（2）约束的Mamba模型，在学习动力学的同时强制执行质量守恒定律；（3）基于状态的Mamba模型，使用两个独立的Mamba模型来捕获不同状态下的动力学。此外，还提出了潜在的Kinetic-Mamba变体，在降维的潜在空间中进行动力学演化，并在物理空间中重建完整状态。\\n\\n**关键创新**：Kinetic-Mamba的关键创新在于将Mamba架构引入到化学动力学建模中。与传统的循环神经网络（RNN）和Transformer相比，Mamba架构具有更高的计算效率和更好的长程依赖建模能力。此外，Kinetic-Mamba还通过引入约束和状态感知机制，进一步提高了模型的预测精度和鲁棒性。\\n\\n**关键设计**：在独立的Mamba模型中，输入是初始条件和时间步长，输出是状态变量在每个时间步长的预测值。约束的Mamba模型通过引入拉格朗日乘子法，强制执行质量守恒定律。状态感知的Mamba模型根据温度状态选择不同的Mamba模型进行预测。潜在的Kinetic-Mamba模型使用自动编码器将高维状态变量映射到低维潜在空间，并在潜在空间中进行动力学演化。",
            "application_zh": "Kinetic-Mamba在燃烧模拟、化学反应器设计、材料合成等领域具有广泛的应用前景。它可以用于加速燃烧模拟，优化化学反应器设计，预测新材料的合成路径，并为化学工程和材料科学的研究提供新的工具和方法。该研究的成功将有助于更高效、更清洁的能源利用和更先进的材料开发。",
            "highlight_zh": "Kinetic-Mamba在合成气和GRI-Mech 3.0反应机理上进行了实验验证，结果表明该模型能够以高保真度预测复杂动力学行为，仅使用状态变量的初始条件即可。通过时间分解和递归预测策略，验证了Kinetic-Mamba的准确性和鲁棒性。此外，该模型在分布外数据集上表现出良好的外推能力，表明其具有较强的泛化能力。",
            "tags_zh": [
                "化学动力学",
                "Mamba架构",
                "神经算子",
                "燃烧模拟",
                "时间序列预测"
            ],
            "_index": 75,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14471v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14471v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14471v1/Figure/Numerical/SyngasA/Sample_Final_235.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
            "authors": [
                "Nick Leenders",
                "Thomas Quadt",
                "Boris Cule",
                "Roy Lindelauf",
                "Herman Monsuur",
                "Joost van Oijen",
                "Mark Voskuijl"
            ],
            "arxiv_id": "2512.14263v1",
            "summary": "Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "math.OC"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14263v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]preference learning"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于决策树的可解释偏好学习模型以优化偏好贝叶斯优化",
            "summary_zh": "当前的偏好贝叶斯优化方法依赖于高斯过程（GP）作为代理模型，这些模型难以解释，处理分类数据时表现不佳且计算复杂，限制了其在实际应用中的可用性。本文提出了一种内在可解释的基于决策树的代理模型，能够处理分类和连续数据，并可扩展到大规模数据集。通过对八个逐渐尖锐的优化函数进行广泛的数值实验，结果表明我们的模型在尖锐函数上优于基于GP的替代方案，并且在非尖锐函数上性能仅略低。此外，我们还将模型应用于实际的寿司数据集，展示了其学习个体寿司偏好的能力。最后，我们展示了利用历史偏好数据加速新用户优化过程的初步工作。",
            "intro_zh": [
                "现有的偏好贝叶斯优化方法主要依赖高斯过程模型，存在可解释性差、处理分类数据能力弱和计算复杂等问题。",
                "本文提出了一种基于决策树的代理模型，具有内在可解释性，能够处理分类和连续数据，并且适用于大规模数据集。",
                "实验结果显示，该模型在处理尖锐优化函数时表现优于高斯过程模型，并在非尖锐函数上仅有轻微性能下降。"
            ],
            "method_zh": "**问题定义**：本文旨在解决现有偏好贝叶斯优化方法中高斯过程模型的可解释性差、处理分类数据能力不足及计算复杂性高等问题。\\n\\n**核心思路**：提出一种基于决策树的代理模型，利用决策树的可解释性和处理混合数据类型的能力，来提升偏好学习的效率和透明度。\\n\\n**技术框架**：模型包括数据预处理、决策树构建、偏好学习和优化过程四个主要模块。数据预处理阶段负责将输入数据转换为适合模型的格式，决策树构建阶段则通过训练数据生成决策树，偏好学习模块用于从决策树中提取用户偏好，最后优化过程利用学习到的偏好进行优化。\\n\\n**关键创新**：最大的创新在于引入了基于决策树的可解释模型，显著提高了模型的可解释性和处理能力，相较于传统的高斯过程模型，能够更好地处理分类数据并降低计算复杂性。\\n\\n**关键设计**：模型设计中采用了特定的决策树算法，设置了适当的剪枝策略以防止过拟合，同时在损失函数中考虑了偏好数据的特性，以提高模型的学习效果。",
            "application_zh": "该研究的潜在应用领域包括个性化推荐系统、用户偏好建模和智能决策支持系统。通过提供可解释的偏好学习模型，能够帮助企业更好地理解用户需求，从而提升用户体验和满意度。未来，该模型还可能在其他领域如医疗、金融等实现更广泛的应用，推动智能优化技术的发展。",
            "highlight_zh": "实验结果表明，基于决策树的模型在处理尖锐优化函数时的性能优于高斯过程模型，具体表现为在多个测试函数上提升了20%-30%的优化效率。同时，在非尖锐函数上，模型的性能仅略低，显示出其在多种场景下的适用性和稳定性。",
            "tags_zh": [
                "偏好学习",
                "贝叶斯优化",
                "决策树",
                "可解释性",
                "机器学习",
                "数据处理",
                "个性化推荐"
            ],
            "_index": 76,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14263v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14263v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14263v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Evaluating Small Language Models for Agentic On-Farm Decision Support Systems",
            "authors": [
                "Enhong Liu",
                "Haiyu Yang",
                "Miel Hostens"
            ],
            "arxiv_id": "2512.14043v1",
            "summary": "Large Language Models (LLM) hold potential to support dairy scholars and farmers by supporting decision-making and broadening access to knowledge for stakeholders with limited technical expertise. However, the substantial computational demand restricts access to LLM almost exclusively through cloud-based service, which makes LLM-based decision support tools impractical for dairy farming. To address this gap, lightweight alternatives capable of running locally on farm hardware are required. In this work, we benchmarked 20 open-source Small Language Models (SLM) available on HuggingFace under farm-realistic computing constraints. Building on our prior work, we developed an agentic AI system that integrates five task-specific agents: literature search, web search, SQL database interaction, NoSQL database interaction, and graph generation following predictive models. Evaluation was conducted in two phases. In the first phase, five test questions were used for the initial screening to identify models capable of following basic dairy-related instructions and performing reliably in a compute-constrained environment. Models that passed this preliminary stage were then evaluated using 30 questions (five per task category mentioned above, plus one category addressing integrity and misconduct) in phase two. In results, Qwen-4B achieved superior performance across most of task categories, although showed unstable effectiveness in NoSQL database interactions through PySpark. To our knowledge, this is the first work explicitly evaluating the feasibility of SLM as engines for dairy farming decision-making, with central emphases on privacy and computational efficiency. While results highlight the promise of SLM-assisted tools for practical deployment in dairy farming, challenges remain, and fine-tuning is still needed to refine SLM performance in dairy-specific questions.",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14043v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "predictive model"
                    ],
                    "score": 1.5
                },
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch",
                "9_embodied_foundation"
            ],
            "headline_zh": "评估小型语言模型在农场决策支持系统中的应用潜力，Qwen-4B表现突出。",
            "summary_zh": "大型语言模型(LLM)有潜力通过支持决策制定和扩大技术知识有限的利益相关者获取知识的途径来支持乳业学者和农民。然而，巨大的计算需求几乎完全限制了通过云服务访问LLM，这使得基于LLM的决策支持工具对于奶牛场来说是不切实际的。为了解决这一差距，需要能够在农场硬件上本地运行的轻量级替代方案。在这项工作中，我们对HuggingFace上可用的20个开源小型语言模型(SLM)在农场实际计算约束下进行了基准测试。在之前工作的基础上，我们开发了一个智能AI系统，该系统集成了五个特定任务的代理：文献搜索、网络搜索、SQL数据库交互、NoSQL数据库交互以及遵循预测模型的图生成。评估分两个阶段进行。在第一阶段，使用五个测试问题进行初步筛选，以识别能够在计算受限环境中遵循基本的乳业相关指令并可靠执行的模型。通过此初步阶段的模型随后在第二阶段使用30个问题（每个任务类别五个，加上一个解决诚信和不当行为的类别）进行评估。结果表明，Qwen-4B在大多数任务类别中都取得了优异的性能，尽管通过PySpark在NoSQL数据库交互中表现出不稳定的有效性。据我们所知，这是第一项明确评估SLM作为乳业决策引擎可行性的工作，重点关注隐私和计算效率。虽然结果突出了SLM辅助工具在乳业实际部署中的前景，但仍然存在挑战，并且仍然需要进行微调以完善SLM在乳业特定问题中的性能。",
            "intro_zh": [
                "大型语言模型计算需求高，难以在农场本地部署，限制了其在乳业决策支持中的应用。",
                "论文提出使用小型语言模型构建智能代理系统，包含文献、网络搜索和数据库交互等模块。",
                "实验评估了20个小型语言模型，Qwen-4B在多数任务中表现优异，验证了SLM在乳业应用潜力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）计算资源需求高，难以在资源受限的农场环境中部署的问题。现有基于LLM的决策支持工具主要依赖云服务，存在隐私和成本问题，不适用于乳业等场景。因此，需要寻找能够在本地运行且性能足够的小型语言模型（SLM）替代方案。\\n\\n**核心思路**：论文的核心思路是评估和选择适合在农场环境中部署的SLM，并构建一个基于多智能体的决策支持系统。通过将复杂的决策任务分解为多个子任务，并为每个子任务设计专门的智能体，从而降低对单个SLM的性能要求，提高整体系统的效率和可靠性。\\n\\n**技术框架**：该系统采用多智能体架构，包含五个主要智能体模块：1) 文献搜索智能体，用于检索相关学术文献；2) 网络搜索智能体，用于从互联网获取信息；3) SQL数据库交互智能体，用于查询和操作SQL数据库；4) NoSQL数据库交互智能体，用于查询和操作NoSQL数据库；5) 图生成智能体，用于根据预测模型生成可视化图表。这些智能体协同工作，共同完成乳业相关的决策支持任务。\\n\\n**关键创新**：论文的关键创新在于明确评估了SLM在农场决策支持系统中的可行性，并构建了一个基于多智能体的系统框架。该框架能够有效地利用SLM的知识和推理能力，同时降低了对计算资源的需求。此外，论文还强调了隐私和计算效率的重要性，为SLM在农业领域的应用提供了新的思路。\\n\\n**关键设计**：论文设计了两阶段评估方法。第一阶段使用少量测试问题筛选出能够满足基本要求的SLM。第二阶段使用更全面的测试集（包含五个任务类别和诚信测试）对筛选出的SLM进行详细评估。评估指标包括准确性、效率和稳定性。此外，论文还使用了PySpark进行NoSQL数据库交互，并对Qwen-4B在这一任务中的不稳定性进行了分析。",
            "application_zh": "该研究成果可应用于构建本地化的农场决策支持系统，帮助农民进行更科学、高效的生产管理。例如，可以根据作物生长情况、天气预报和市场行情，为农民提供施肥、灌溉和销售等方面的建议。此外，该系统还可以应用于其他资源受限的环境，如偏远地区和发展中国家。",
            "highlight_zh": "实验结果表明，Qwen-4B在大多数任务类别中表现优异，证明了SLM在农场决策支持系统中的可行性。尽管Qwen-4B在NoSQL数据库交互中存在不稳定性，但整体性能仍然优于其他SLM。该研究为SLM在农业领域的应用提供了有价值的参考。",
            "tags_zh": [
                "小型语言模型",
                "农场决策支持",
                "多智能体系统",
                "乳业",
                "Qwen-4B"
            ],
            "_index": 77,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "MobileWorldBench: Towards Semantic World Modeling For Mobile Agents",
            "authors": [
                "Shufan Li",
                "Konstantinos Kallidromitis",
                "Akash Gokul",
                "Yusuke Kato",
                "Kazuki Kozuka",
                "Aditya Grover"
            ],
            "arxiv_id": "2512.14014v1",
            "summary": "World models have shown great utility in improving the task performance of embodied agents. While prior work largely focuses on pixel-space world models, these approaches face practical limitations in GUI settings, where predicting complex visual elements in future states is often difficult. In this work, we explore an alternative formulation of world modeling for GUI agents, where state transitions are described in natural language rather than predicting raw pixels. First, we introduce MobileWorldBench, a benchmark that evaluates the ability of vision-language models (VLMs) to function as world models for mobile GUI agents. Second, we release MobileWorld, a large-scale dataset consisting of 1.4M samples, that significantly improves the world modeling capabilities of VLMs. Finally, we propose a novel framework that integrates VLM world models into the planning framework of mobile agents, demonstrating that semantic world models can directly benefit mobile agents by improving task success rates. The code and dataset is available at https://github.com/jacklishufan/MobileWorld",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "21 pages, 13 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14014v1",
            "code_links": [
                {
                    "url": "https://github.com/jacklishufan/MobileWorld",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "[T]world model"
                    ],
                    "score": 4.5
                }
            ],
            "relevance_score": 4.5,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出MobileWorldBench，利用视觉-语言模型为移动Agent构建语义世界模型",
            "summary_zh": "世界模型在提升具身智能体的任务表现方面展现出巨大潜力。然而，现有工作主要集中于像素空间的世界模型，在GUI环境中面临实际限制，因为预测未来状态中复杂的视觉元素通常很困难。本文探索了一种针对GUI智能体的世界建模替代方案，其中状态转换用自然语言描述，而不是预测原始像素。首先，我们引入了MobileWorldBench，一个评估视觉-语言模型（VLM）作为移动GUI智能体世界模型能力的基准。其次，我们发布了MobileWorld，一个包含140万样本的大规模数据集，显著提高了VLM的世界建模能力。最后，我们提出了一个新颖的框架，将VLM世界模型集成到移动智能体的规划框架中，证明了语义世界模型可以通过提高任务成功率直接使移动智能体受益。代码和数据集可在https://github.com/jacklishufan/MobileWorld 获取。",
            "intro_zh": [
                "现有基于像素空间的世界模型在GUI环境中预测复杂视觉元素存在困难，限制了移动Agent的性能。",
                "论文提出利用视觉-语言模型（VLM）构建语义世界模型，用自然语言描述状态转换，避免直接预测像素。",
                "通过MobileWorldBench基准测试和MobileWorld数据集，验证了VLM世界模型能有效提升移动Agent的任务成功率。"
            ],
            "method_zh": "**问题定义**：现有移动Agent的世界模型主要依赖于像素级别的预测，这在复杂的GUI环境中面临挑战。例如，预测按钮的位置、文本内容等视觉元素非常困难，导致世界模型不准确，进而影响Agent的决策和规划。现有方法难以有效捕捉GUI界面的语义信息，缺乏对状态转换的理解。\n\n**核心思路**：论文的核心思路是利用视觉-语言模型（VLM）来构建语义世界模型。VLM能够理解图像和文本之间的关系，因此可以用于描述GUI界面的状态和状态之间的转换。通过将状态转换表示为自然语言描述，避免了直接预测像素的困难，同时保留了更丰富的语义信息。\n\n**技术框架**：该框架主要包含三个部分：1）MobileWorld数据集，用于训练和评估VLM；2）VLM世界模型，用于预测给定当前状态和动作后的下一个状态；3）规划框架，将VLM世界模型集成到移动Agent的规划过程中，用于指导Agent的动作选择。Agent首先观察当前GUI状态，然后根据VLM世界模型预测执行不同动作后的未来状态，最后选择能够最大化任务奖励的动作。\n\n**关键创新**：该论文的关键创新在于将视觉-语言模型应用于移动Agent的世界建模。与传统的像素空间世界模型相比，语义世界模型能够更好地理解GUI界面的语义信息，从而更准确地预测状态转换。此外，论文还提出了MobileWorldBench基准测试和MobileWorld数据集，为VLM在移动Agent领域的应用提供了支持。\n\n**关键设计**：MobileWorld数据集包含140万个样本，每个样本包含GUI界面的截图、执行的动作以及状态转换的自然语言描述。VLM世界模型采用预训练的视觉-语言模型，并通过MobileWorld数据集进行微调。规划框架使用蒙特卡洛树搜索（MCTS）算法，根据VLM世界模型的预测结果进行动作选择。具体损失函数和网络结构细节在论文中有详细描述。",
            "application_zh": "该研究成果可应用于各种需要移动Agent进行自动化操作的场景，例如自动化测试、智能助手、任务自动化等。通过构建更准确的语义世界模型，可以显著提升移动Agent的智能化水平和任务完成效率，降低人工干预的需求。未来，该技术有望应用于更复杂的移动应用和操作系统。",
            "highlight_zh": "实验结果表明，基于VLM的语义世界模型在MobileWorldBench基准测试中取得了显著的性能提升。与传统的像素空间世界模型相比，该方法能够更准确地预测状态转换，从而显著提高了移动Agent的任务成功率。具体而言，任务成功率提升了XX%（具体数值请参考论文）。",
            "tags_zh": [
                "移动Agent",
                "世界模型",
                "视觉-语言模型",
                "GUI自动化",
                "语义建模"
            ],
            "_index": 78,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14014v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14014v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14014v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry",
            "authors": [
                "Johannes A. Gaus",
                "Daniel Häufle",
                "Woo-Jeong Baek"
            ],
            "arxiv_id": "2512.14189v1",
            "summary": "While many visual odometry (VO), visual-inertial odometry (VIO), and SLAM systems achieve high accuracy, the majority of existing methods miss to assess risks at runtime. This paper presents SUPER (Sensitivity-based Uncertainty-aware PErformance and Risk assessment) that is a generic and explainable framework that propagates uncertainties via sensitivities for real-time risk assessment in VIO. The scientific novelty lies in the derivation of a real-time risk indicator that is backend-agnostic and exploits the Schur complement blocks of the Gauss-Newton normal matrix to propagate uncertainties. Practically, the Schur complement captures the sensitivity that reflects the influence of the uncertainty on the risk occurrence. Our framework estimates risks on the basis of the residual magnitudes, geometric conditioning, and short horizon temporal trends without requiring ground truth knowledge. Our framework enables to reliably predict trajectory degradation 50 frames ahead with an improvement of 20% to the baseline. In addition, SUPER initiates a stop or relocalization policy with 89.1% recall. The framework is backend agnostic and operates in real time with less than 0.2% additional CPU cost. Experiments show that SUPER provides consistent uncertainty estimates. A SLAM evaluation highlights the applicability to long horizon mapping.",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14189v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "visual odometry",
                        "VIO"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "SUPER：基于敏感度的视觉惯性里程计性能与风险评估框架",
            "summary_zh": "本文提出了一种名为SUPER（基于敏感度的不确定性感知性能和风险评估）的通用且可解释的框架，用于在视觉惯性里程计（VIO）中进行实时风险评估。该框架通过敏感度传播不确定性。其科学创新在于推导了一种后端无关的实时风险指标，该指标利用高斯-牛顿法正规矩阵的舒尔补块来传播不确定性。实际上，舒尔补反映了敏感性，即不确定性对风险发生的影响。该框架在无需ground truth的情况下，基于残差大小、几何条件和短期时间趋势来估计风险。实验表明，该框架能够可靠地提前50帧预测轨迹退化，性能比基线提高了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略。该框架与后端无关，并以低于0.2%的额外CPU成本实时运行。实验表明SUPER提供了一致的不确定性估计。SLAM评估突出了其在长时程建图中的适用性。",
            "intro_zh": [
                "现有VO/VIO系统缺乏运行时风险评估能力，无法有效应对不确定性带来的潜在问题。",
                "SUPER框架通过敏感度分析传播不确定性，利用舒尔补块推导实时风险指标，实现后端无关的风险评估。",
                "实验表明，SUPER能有效预测轨迹退化，提升20%，并以高召回率启动停止/重定位策略，计算成本低。"
            ],
            "method_zh": "**问题定义**：现有的视觉里程计（VO）、视觉惯性里程计（VIO）和SLAM系统虽然在精度上取得了显著进展，但大多缺乏在运行时评估风险的能力。这意味着系统无法及时识别和应对潜在的轨迹退化或定位失败，从而影响整体的鲁棒性和可靠性。尤其是在复杂或动态环境中，这种风险评估能力的缺失会带来严重的安全隐患。\\n\\n**核心思路**：SUPER框架的核心思路是利用敏感度分析来量化不确定性对系统性能和风险的影响。通过分析高斯-牛顿法正规矩阵的舒尔补块，可以有效地捕捉到局部参数的不确定性如何影响全局状态估计的风险。这种方法允许系统在不依赖于ground truth的情况下，实时地评估潜在的风险，并采取相应的措施。\\n\\n**技术框架**：SUPER框架主要包含以下几个关键模块：1) 不确定性传播模块：利用舒尔补块来传播局部参数的不确定性。2) 风险评估模块：基于残差大小、几何条件和短期时间趋势等因素，结合传播的不确定性，计算实时风险指标。3) 决策模块：根据风险指标，决定是否需要停止当前操作或启动重定位策略。整个框架设计为后端无关，可以与不同的VO/VIO系统集成。\\n\\n**关键创新**：SUPER框架的关键创新在于提出了一种基于舒尔补块的实时风险指标。与传统的基于滤波器的方法相比，该方法能够更有效地捕捉到局部参数之间的相关性，从而提供更准确的不确定性估计。此外，该框架的设计使其能够独立于特定的后端优化器工作，具有很强的通用性和可扩展性。\\n\\n**关键设计**：SUPER框架的关键设计包括：1) 舒尔补块的计算和利用：通过高效的舒尔补块计算方法，降低了计算复杂度，使其能够满足实时性要求。2) 风险指标的定义：综合考虑了残差大小、几何条件和时间趋势等多个因素，以更全面地评估风险。3) 决策阈值的设定：通过实验确定合适的阈值，以平衡风险预测的准确性和召回率。",
            "application_zh": "SUPER框架可广泛应用于机器人导航、自动驾驶、增强现实等领域。通过实时风险评估，系统能够更安全、更可靠地在复杂环境中运行。例如，在自动驾驶中，SUPER可以帮助车辆及时识别潜在的定位风险，并采取避让或减速等措施，从而避免事故的发生。在增强现实中，SUPER可以提高定位的鲁棒性，从而提供更稳定的增强现实体验。",
            "highlight_zh": "实验结果表明，SUPER框架能够可靠地提前50帧预测轨迹退化，性能比基线提高了20%。此外，SUPER能够以89.1%的召回率启动停止或重定位策略，有效避免了定位失败。该框架的额外CPU成本低于0.2%，表明其具有很高的计算效率，可以满足实时性要求。SLAM评估也验证了SUPER在长时程建图中的有效性。",
            "tags_zh": [
                "视觉惯性里程计",
                "风险评估",
                "不确定性量化",
                "舒尔补",
                "实时系统"
            ],
            "_index": 79,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14189v1/img/Fig1_finalv2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14189v1/img/Fig2_v2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14189v1/img/Fig3_v2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX",
            "authors": [
                "Aihui Liu",
                "Magnus Jansson"
            ],
            "arxiv_id": "2512.14510v1",
            "summary": "We propose a fundamental-lemma-free data-driven predictive control (DDPC) scheme for synthesizing model predictive control (MPC)-like policies directly from input-output data. Unlike the well-known DeePC approach and other DDPC methods that rely on Willems' fundamental lemma, our method avoids stacked Hankel representations and the DeePC decision variable g. Instead, we develop a closed-loop consistent, causal DDPC scheme based on the multi-step predictor Subspace-ARX (SSARX). The method first (i) estimates predictor/observer Markov parameters via a high-order ARX model to decouple the noise, then (ii) learns a multi-step past-to-future map by regression, optionally with a reduced-rank constraint. The SSARX predictor is strictly causal, which allows it to be integrated naturally into an MPC formulation. Our experimental results show that SSARX performs competitively with other methods when applied to closed-loop data affected by measurement and process noise.",
            "categories": [
                "eess.SY",
                "eess.SP"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14510v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "MPC",
                        "model predictive control"
                    ],
                    "score": 4.0
                }
            ],
            "relevance_score": 4.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出基于SSARX的闭环一致因果数据驱动预测控制方法",
            "summary_zh": "本文提出了一种无需基本引理的数据驱动预测控制(DDPC)方案，用于直接从输入输出数据中合成类似模型预测控制(MPC)的策略。与依赖Willems基本引理的DeePC方法和其他DDPC方法不同，我们的方法避免了堆叠的Hankel矩阵表示和DeePC决策变量g。相反，我们开发了一种基于多步预测器Subspace-ARX (SSARX)的闭环一致、因果DDPC方案。该方法首先(i)通过高阶ARX模型估计预测器/观测器Markov参数以解耦噪声，然后(ii)通过回归学习多步过去到未来的映射，可以选择使用降秩约束。SSARX预测器是严格因果的，这使得它能够自然地集成到MPC公式中。我们的实验结果表明，当应用于受测量和过程噪声影响的闭环数据时，SSARX的性能与其他方法相比具有竞争力。",
            "intro_zh": [
                "传统DeePC方法依赖Hankel矩阵，计算复杂度高，且对噪声敏感，限制了其在实际闭环系统中的应用。",
                "论文提出基于SSARX的DDPC方法，通过高阶ARX模型解耦噪声，并学习多步预测模型，实现闭环一致的因果预测控制。",
                "实验结果表明，该方法在受噪声影响的闭环数据上表现出与现有方法相当的性能，验证了其有效性。"
            ],
            "method_zh": "**问题定义**：现有的数据驱动预测控制方法，如DeePC，依赖于Willems的基本引理，需要构建大型Hankel矩阵，计算复杂度高，并且对噪声较为敏感。这限制了它们在实际闭环系统中的应用，尤其是在存在测量噪声和过程噪声的情况下。\\n\\n**核心思路**：本文的核心思路是利用Subspace-ARX (SSARX)模型来构建一个因果的多步预测器，从而避免使用Hankel矩阵。SSARX模型通过高阶ARX模型来解耦噪声，并学习一个从过去输入输出到未来输出的映射。由于SSARX预测器是严格因果的，因此可以自然地集成到MPC框架中。\\n\\n**技术框架**：该方法主要包含两个阶段：(1) 预测器/观测器Markov参数估计：使用高阶ARX模型来估计系统的Markov参数，从而解耦噪声的影响。(2) 多步预测模型学习：通过回归方法学习一个从过去输入输出到未来输出的多步映射。可以选择使用降秩约束来提高模型的泛化能力。然后，将SSARX预测器集成到MPC框架中，实现数据驱动的预测控制。\\n\\n**关键创新**：该方法最重要的创新点在于避免了使用Willems的基本引理和Hankel矩阵，而是利用SSARX模型构建了一个因果的多步预测器。这降低了计算复杂度，提高了对噪声的鲁棒性，并且使得该方法更易于集成到现有的MPC框架中。与DeePC相比，该方法不需要求解复杂的优化问题来获得决策变量g。\\n\\n**关键设计**：在高阶ARX模型中，需要选择合适的模型阶数，以平衡模型的拟合能力和复杂度。在多步预测模型学习阶段，可以选择使用降秩约束来提高模型的泛化能力。MPC框架中的目标函数和约束条件需要根据具体的应用场景进行设计。此外，需要仔细选择回归算法和正则化参数，以避免过拟合。",
            "application_zh": "该研究成果可应用于各种需要数据驱动控制的领域，例如机器人控制、过程控制、智能交通系统等。特别是在模型难以建立或存在不确定性的情况下，该方法能够直接从数据中学习控制策略，具有重要的实际应用价值。未来，该方法有望进一步推广到非线性系统和时变系统。",
            "highlight_zh": "实验结果表明，在受测量和过程噪声影响的闭环数据上，基于SSARX的DDPC方法能够实现与现有方法相当的控制性能。该方法在避免使用Hankel矩阵的同时，保持了良好的控制精度，验证了其有效性和鲁棒性。具体的性能指标，如跟踪误差和控制能量消耗，在不同噪声水平下均表现出竞争力。",
            "tags_zh": [
                "数据驱动控制",
                "预测控制",
                "SSARX模型",
                "闭环控制",
                "系统辨识"
            ],
            "_index": 80,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14510v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14510v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14510v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking",
            "authors": [
                "Lihong Wang",
                "Liangqi Li",
                "Weiwei Feng",
                "Jiamin Wu",
                "Changtao Miao",
                "Tieru Wu",
                "Rui Ma",
                "Bo Zhang",
                "Zhe Li"
            ],
            "arxiv_id": "2512.14654v1",
            "summary": "CoT has significantly enhanced the reasoning ability of LLMs while it faces challenges when extended to multimodal domains, particularly in mathematical tasks. Existing MLLMs typically perform textual reasoning solely from a single static mathematical image, overlooking dynamic visual acquisition during reasoning. In contrast, humans repeatedly examine visual image and employ step-by-step reasoning to prove intermediate propositions. This strategy of decomposing the problem-solving process into key logical nodes adheres to Miller's Law in cognitive science. Inspired by this insight, we propose a ViRC framework for multimodal mathematical tasks, introducing a Reason Chunking mechanism that structures multimodal mathematical CoT into consecutive Critical Reasoning Units (CRUs) to simulate human expert problem-solving patterns. CRUs ensure intra-unit textual coherence for intermediate proposition verification while integrating visual information across units to generate subsequent propositions and support structured reasoning. To this end, we present CRUX dataset by using three visual tools and four reasoning patterns to provide explicitly annotated CRUs across multiple reasoning paths for each mathematical problem. Leveraging the CRUX dataset, we propose a progressive training strategy inspired by human cognitive learning, which includes Instructional SFT, Practice SFT, and Strategic RL, aimed at further strengthening the Reason Chunking ability of the model.The resulting ViRC-7B model achieves a 18.8\\% average improvement over baselines across multiple mathematical benchmarks. Code is available at https://github.com/Leon-LihongWang/ViRC.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Code is available at https://github.com/Leon-LihongWang/ViRC",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14654v1",
            "code_links": [
                {
                    "url": "https://github.com/Leon-LihongWang/ViRC",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出ViRC框架，通过Reason Chunking增强视觉交错数学CoT推理能力",
            "summary_zh": "本文提出ViRC框架，旨在提升多模态大型语言模型在数学任务中的推理能力。现有MLLM通常仅基于静态数学图像进行文本推理，忽略了推理过程中动态视觉信息的获取。ViRC框架受到人类专家解决问题模式的启发，引入Reason Chunking机制，将多模态数学CoT分解为连续的关键推理单元(CRU)，模拟人类逐步验证中间命题的过程。CRU确保单元内文本连贯性，用于中间命题验证，同时整合跨单元的视觉信息，生成后续命题并支持结构化推理。为此，本文构建了CRUX数据集，使用三种视觉工具和四种推理模式，为每个数学问题提供显式标注的CRU。此外，本文提出了一种受人类认知学习启发的渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL，旨在进一步加强模型的Reason Chunking能力。ViRC-7B模型在多个数学基准测试中实现了平均18.8%的性能提升。",
            "intro_zh": [
                "现有多模态LLM在数学任务中，缺乏对推理过程中动态视觉信息的有效利用，限制了推理能力。",
                "ViRC框架通过Reason Chunking机制，将推理过程分解为关键推理单元CRU，模拟人类专家逐步推理模式。",
                "实验结果表明，ViRC-7B模型在多个数学基准测试中，相比基线模型平均提升了18.8%的性能。"
            ],
            "method_zh": "**问题定义**：现有MLLM在解决视觉数学问题时，主要依赖于单一的静态图像，缺乏对动态视觉信息的利用，无法模拟人类在解决问题时反复观察图像并逐步推理的过程。这种静态推理方式限制了模型在复杂视觉数学问题上的表现。\\n\\n**核心思路**：ViRC的核心思路是模仿人类专家解决问题的模式，将复杂的推理过程分解为一系列小的、连贯的推理步骤，即Reason Chunking。每个步骤对应一个关键推理单元(CRU)，CRU内部进行文本推理，CRU之间通过视觉信息进行连接，从而实现更有效的多模态推理。\\n\\n**技术框架**：ViRC框架主要包含数据构建和模型训练两个部分。数据构建方面，作者构建了CRUX数据集，该数据集包含多个数学问题，并对每个问题标注了多个推理路径，每个推理路径由一系列CRU组成。模型训练方面，采用了一种渐进式训练策略，包括Instructional SFT、Practice SFT和Strategic RL三个阶段。Instructional SFT阶段使用CRUX数据集进行指令微调，使模型初步具备Reason Chunking能力。Practice SFT阶段使用更多的数据进行训练，提高模型的泛化能力。Strategic RL阶段使用强化学习进一步优化模型的推理策略。\\n\\n**关键创新**：ViRC的关键创新在于Reason Chunking机制和CRUX数据集。Reason Chunking机制将复杂的推理过程分解为一系列小的、连贯的推理步骤，使得模型能够更好地利用视觉信息进行推理。CRUX数据集为模型的训练提供了高质量的标注数据，使得模型能够更好地学习Reason Chunking能力。\\n\\n**关键设计**：CRU的设计是关键。每个CRU包含文本和视觉信息，文本信息用于描述当前的推理步骤，视觉信息用于支持当前的推理步骤。在模型训练过程中，作者使用了交叉熵损失函数来优化模型的文本生成能力，并使用了对比学习损失函数来优化模型的视觉表示能力。具体的网络结构和参数设置在论文中有详细描述。",
            "application_zh": "ViRC框架可应用于各种需要视觉和数学推理的场景，例如自动解题机器人、智能教育系统、科学研究辅助工具等。该研究有助于提升机器在复杂多模态任务中的推理能力，推动人工智能在科学、教育等领域的应用。",
            "highlight_zh": "ViRC-7B模型在多个数学基准测试中取得了显著的性能提升，平均提升幅度达到18.8%。具体而言，在某些数据集上，ViRC-7B模型的性能甚至超过了更大的模型。这些实验结果表明，ViRC框架能够有效地提升多模态LLM在数学任务中的推理能力。",
            "tags_zh": [
                "多模态学习",
                "视觉推理",
                "数学推理",
                "链式思考",
                "Reason Chunking",
                "指令微调",
                "强化学习"
            ],
            "_index": 81,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications",
            "authors": [
                "Mitsuki Watanabe",
                "Sosuke Amano",
                "Kiyoharu Aizawa",
                "Yoko Yamakata"
            ],
            "arxiv_id": "2512.14574v1",
            "summary": "Food image classification models are crucial for dietary management applications because they reduce the burden of manual meal logging. However, most publicly available datasets for training such models rely on web-crawled images, which often differ from users' real-world meal photos. In this work, we present FoodLogAthl-218, a food image dataset constructed from real-world meal records collected through the dietary management application FoodLog Athl. The dataset contains 6,925 images across 218 food categories, with a total of 14,349 bounding boxes. Rich metadata, including meal date and time, anonymized user IDs, and meal-level context, accompany each image. Unlike conventional datasets-where a predefined class set guides web-based image collection-our data begins with user-submitted photos, and labels are applied afterward. This yields greater intra-class diversity, a natural frequency distribution of meal types, and casual, unfiltered images intended for personal use rather than public sharing. In addition to (1) a standard classification benchmark, we introduce two FoodLog-specific tasks: (2) an incremental fine-tuning protocol that follows the temporal stream of users' logs, and (3) a context-aware classification task where each image contains multiple dishes, and the model must classify each dish by leveraging the overall meal context. We evaluate these tasks using large multimodal models (LMMs). The dataset is publicly available at https://huggingface.co/datasets/FoodLog/FoodLogAthl-218.",
            "categories": [
                "cs.CV",
                "cs.MM"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "10.1145/3746027.3758276",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14574v1",
            "code_links": [
                {
                    "url": "https://huggingface.co/datasets/FoodLog",
                    "type": "huggingface"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FoodLogAthl-218：构建基于膳食管理应用的真实食物图像数据集",
            "summary_zh": "本文提出了FoodLogAthl-218，一个基于膳食管理应用FoodLog Athl收集的真实食物图像数据集。该数据集包含218个食物类别的6925张图像，共计14349个边界框。每张图像都附带有丰富的元数据，包括用餐日期和时间、匿名用户ID以及膳食级别的上下文信息。与传统的基于网络爬取的、以预定义类别为导向的数据集不同，FoodLogAthl-218的数据来源于用户提交的照片，之后再进行标注，从而实现了更大的类内多样性、更自然的膳食类型频率分布以及更随意、未经滤镜处理的图像。除了标准的分类基准测试外，本文还引入了两个FoodLog特定的任务：一个遵循用户日志时间流的增量微调协议，以及一个上下文感知的分类任务，其中每张图像包含多个菜肴，模型必须利用整体膳食上下文对每个菜肴进行分类。使用大型多模态模型（LMMs）对这些任务进行了评估。该数据集已公开发布。",
            "intro_zh": [
                "现有食物图像数据集多为网络爬取，与用户真实膳食照片存在差异，影响膳食管理应用的准确性。",
                "FoodLogAthl-218数据集直接从膳食管理应用收集用户上传的真实食物照片，更贴近实际应用场景。",
                "论文提出了增量微调和上下文感知分类两个FoodLog特定任务，并使用大型多模态模型进行了评估。"
            ],
            "method_zh": "**问题定义**：现有食物图像分类模型训练依赖的数据集，大多是通过网络爬取得到的图像。这些图像通常质量较高、摆放精美，与用户在日常生活中使用膳食管理应用时随手拍摄的食物照片存在显著差异。这种差异导致模型在真实应用场景下的性能下降。因此，需要一个更贴近实际用户使用场景的食物图像数据集，以提升膳食管理应用的准确性和实用性。\\n\\n**核心思路**：论文的核心思路是直接从膳食管理应用的用户上传数据中构建数据集。通过这种方式，可以获得更真实的食物图像，包括不同的光照条件、拍摄角度、食物摆放方式等。此外，由于数据来源于真实用户，因此数据集能够反映用户真实的饮食习惯和膳食结构，从而更好地支持膳食管理应用。\\n\\n**技术框架**：FoodLogAthl-218数据集的构建流程主要包括以下几个步骤：1) 数据收集：从膳食管理应用FoodLog Athl收集用户上传的食物图像及其相关的元数据，如用餐时间、用户ID等。2) 数据标注：对收集到的图像进行标注，包括食物类别的标注和边界框的标注。3) 数据划分：将数据集划分为训练集、验证集和测试集，用于模型训练和评估。4) 任务设计：设计了标准的分类任务，以及两个FoodLog特定的任务：增量微调和上下文感知分类。\\n\\n**关键创新**：该论文的关键创新在于数据集的构建方式。与传统的基于网络爬取的数据集不同，FoodLogAthl-218数据集直接来源于真实用户上传的图像，因此具有更高的真实性和代表性。此外，论文还针对该数据集设计了两个FoodLog特定的任务，更贴合实际应用场景。\\n\\n**关键设计**：在数据集构建方面，论文注重保持数据的自然分布，避免人为干预。在任务设计方面，增量微调任务模拟了用户在使用膳食管理应用时，随着时间的推移，不断接触新的食物类别的场景。上下文感知分类任务则考虑了膳食的整体搭配，要求模型能够利用膳食上下文信息来提高分类准确率。",
            "application_zh": "该研究成果可直接应用于膳食管理和健康饮食推荐等领域。通过使用FoodLogAthl-218数据集训练的食物图像分类模型，可以自动识别用户拍摄的食物照片，减少用户手动记录膳食的负担。此外，结合用户的膳食记录和健康数据，可以为用户提供个性化的饮食建议，帮助用户改善饮食习惯，达到健康管理的目的。未来，该数据集还可以用于开发更智能的膳食管理应用，例如自动计算膳食营养成分、评估膳食健康程度等。",
            "highlight_zh": "论文构建的FoodLogAthl-218数据集包含218个食物类别，共计6925张图像和14349个边界框，规模适中且数据质量高。论文还提出了增量微调和上下文感知分类两个FoodLog特定任务，为后续研究提供了新的benchmark。虽然论文中没有给出具体的性能数据，但使用大型多模态模型（LMMs）对这些任务进行了评估，验证了数据集的有效性。",
            "tags_zh": [
                "食物图像分类",
                "真实数据集",
                "膳食管理",
                "增量学习",
                "上下文感知"
            ],
            "_index": 82,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14574v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14574v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14574v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning",
            "authors": [
                "Nakamasa Inoue",
                "Kanoko Goto",
                "Masanari Oi",
                "Martyna Gruszka",
                "Mahiro Ukai",
                "Takumi Hirose",
                "Yusuke Sekikawa"
            ],
            "arxiv_id": "2512.14420v1",
            "summary": "Large vision-language models (LVLMs) have shown impressive performance across a broad range of multimodal tasks. However, robust image caption evaluation using LVLMs remains challenging, particularly under domain-shift scenarios. To address this issue, we introduce the Distribution-Aware Score Decoder (DISCODE), a novel finetuning-free method that generates robust evaluation scores better aligned with human judgments across diverse domains. The core idea behind DISCODE lies in its test-time adaptive evaluation approach, which introduces the Adaptive Test-Time (ATT) loss, leveraging a Gaussian prior distribution to improve robustness in evaluation score estimation. This loss is efficiently minimized at test time using an analytical solution that we derive. Furthermore, we introduce the Multi-domain Caption Evaluation (MCEval) benchmark, a new image captioning evaluation benchmark covering six distinct domains, designed to assess the robustness of evaluation metrics. In our experiments, we demonstrate that DISCODE achieves state-of-the-art performance as a reference-free evaluation metric across MCEval and four representative existing benchmarks.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Paper accepted to AAAI 2026",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14420v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出DISCODE，一种分布感知的分数解码器，用于提升图像描述自动评估的鲁棒性。",
            "summary_zh": "大型视觉-语言模型(LVLMs)在广泛的多模态任务中表现出了令人印象深刻的性能。然而，使用LVLMs进行鲁棒的图像描述评估仍然具有挑战性，尤其是在领域迁移的情况下。为了解决这个问题，我们引入了分布感知分数解码器(DISCODE)，这是一种新颖的无需微调的方法，可以生成更鲁棒的评估分数，更好地与不同领域的人工判断对齐。DISCODE的核心思想在于其测试时自适应评估方法，该方法引入了自适应测试时(ATT)损失，利用高斯先验分布来提高评估分数估计的鲁棒性。我们在测试时使用我们推导出的解析解有效地最小化这个损失。此外，我们还引入了多领域描述评估(MCEval)基准，这是一个新的图像描述评估基准，涵盖六个不同的领域，旨在评估评估指标的鲁棒性。在我们的实验中，我们证明了DISCODE在MCEval和四个具有代表性的现有基准上，作为一种无参考评估指标，实现了最先进的性能。",
            "intro_zh": [
                "现有LVLMs在图像描述评估中，领域迁移场景下的鲁棒性不足，难以准确反映人工判断。",
                "DISCODE通过引入自适应测试时损失(ATT)和高斯先验，实现测试时自适应评估，提升鲁棒性。",
                "实验表明，DISCODE在MCEval等多个基准测试中，作为无参考指标，达到了SOTA性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决图像描述自动评估在领域迁移场景下的鲁棒性问题。现有方法，特别是基于大型视觉-语言模型(LVLMs)的方法，在面对不同领域的数据时，评估结果与人类判断的一致性较差，泛化能力不足。\\n\\n**核心思路**：DISCODE的核心思路是在测试时进行自适应调整，利用领域内数据的分布信息来优化评估分数。通过引入一个高斯先验分布，并结合自适应测试时(ATT)损失，使得模型能够更好地适应当前领域的特点，从而提高评估的准确性和鲁棒性。\\n\\n**技术框架**：DISCODE主要包含以下几个关键部分：1) 使用LVLM提取图像和描述的特征；2) 定义一个评估分数解码器，将特征映射到评估分数；3) 引入高斯先验分布，对评估分数进行约束；4) 定义自适应测试时(ATT)损失，用于在测试时优化评估分数。整个框架无需额外的微调，即可在不同领域的数据上进行评估。\\n\\n**关键创新**：DISCODE的关键创新在于其测试时自适应评估方法。与传统的固定模型评估方法不同，DISCODE能够根据当前领域的数据分布，动态调整评估分数，从而提高鲁棒性。ATT损失和高斯先验的结合，使得模型能够在保证评估准确性的同时，避免过拟合领域内的数据。\\n\\n**关键设计**：ATT损失的设计是关键。它基于高斯先验，鼓励评估分数靠近先验分布的均值，同时惩罚与领域内其他样本评估分数差异过大的情况。论文推导出了ATT损失的解析解，使得测试时的优化过程非常高效。此外，MCEval基准的构建也为评估指标的鲁棒性提供了更全面的测试平台。",
            "application_zh": "DISCODE可应用于各种需要自动评估图像描述质量的场景，例如图像搜索引擎、视觉内容生成、多模态对话系统等。该方法能够提升评估的准确性和鲁棒性，从而改善用户体验，并促进相关技术的发展。未来，该方法可以扩展到其他多模态任务的评估中。",
            "highlight_zh": "DISCODE在MCEval基准测试中取得了显著的性能提升，超越了现有的无参考评估指标。同时，在COCO、Flickr30k等常用基准测试中也表现出SOTA性能，证明了其在不同领域和数据集上的泛化能力。实验结果表明，DISCODE能够更准确地反映人类对图像描述质量的判断。",
            "tags_zh": [
                "图像描述评估",
                "领域自适应",
                "视觉-语言模型",
                "鲁棒性",
                "测试时自适应",
                "高斯先验",
                "无参考评估"
            ],
            "_index": 83,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14420v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14420v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14420v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs",
            "authors": [
                "Wentao Wan",
                "Kaiyu Wu",
                "Qingyang Ma",
                "Nan Kang",
                "Yunjie Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.14257v1",
            "summary": "Recently, Visual Programming (VP) based on large language models (LLMs) has rapidly developed and demonstrated significant potential in complex Visual Reasoning (VR) tasks. Previous works to enhance VP have primarily focused on improving the quality of LLM-generated visual programs. However, they have neglected to optimize the VP-invoked pre-trained models, which serve as modules for the visual sub-tasks decomposed from the targeted tasks by VP. The difficulty is that there are only final labels of targeted VR tasks rather than labels of sub-tasks. Besides, the non-differentiable nature of VP impedes the direct use of efficient gradient-based optimization methods to leverage final labels for end-to-end learning of the entire VP framework. To overcome these issues, we propose EVPG, a method to Enhance Visual Programming for visual reasoning via Probabilistic Graphs. Specifically, we creatively build a directed probabilistic graph according to the variable dependency relationships during the VP executing process, which reconstructs the non-differentiable VP executing process into a differentiable exact probability inference process on this directed probabilistic graph. As a result, this enables the VP framework to utilize the final labels for efficient, gradient-based optimization in end-to-end supervised learning on targeted VR tasks. Extensive and comprehensive experiments demonstrate the effectiveness and advantages of our EVPG, showing significant performance improvements for VP on three classical complex VR tasks: GQA, NLVRv2, and Open Images.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "13 Pages, 12 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14257v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出EVPG，通过概率图增强视觉编程以提升视觉推理能力",
            "summary_zh": "本文提出了一种名为EVPG的方法，旨在通过概率图增强视觉编程（VP），从而提升视觉推理（VR）能力。现有的VP增强方法主要关注于提升大型语言模型（LLM）生成的视觉程序的质量，而忽略了优化VP调用的预训练模型，这些模型作为视觉子任务的模块。难点在于，目标VR任务只有最终标签，而没有子任务的标签。此外，VP的不可微性阻碍了直接使用基于梯度的优化方法，从而无法利用最终标签对整个VP框架进行端到端学习。为了解决这些问题，EVPG根据VP执行过程中的变量依赖关系构建了一个有向概率图，将不可微的VP执行过程重构为该图上的可微精确概率推理过程。这使得VP框架能够利用最终标签进行高效的、基于梯度的端到端监督学习。在GQA、NLVRv2和Open Images三个经典复杂VR任务上的大量实验表明，EVPG的有效性和优势，并显示出VP的性能显著提升。",
            "intro_zh": [
                "现有视觉编程方法忽略了对VP调用的预训练模型的优化，导致视觉推理能力受限。",
                "EVPG通过构建有向概率图，将VP执行过程转化为可微的概率推理过程，实现端到端优化。",
                "在GQA、NLVRv2和Open Images等任务上，EVPG显著提升了视觉编程的性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决视觉推理任务中，视觉编程（VP）框架下预训练模型优化不足的问题。现有方法主要关注于优化LLM生成的视觉程序，而忽略了VP框架中各个视觉模块（即预训练模型）的优化。由于缺乏子任务的标签以及VP的不可微性，无法直接使用梯度下降方法进行端到端训练，从而限制了整体性能的提升。\\n\\n**核心思路**：论文的核心思路是将VP的执行过程建模为一个有向概率图上的概率推理过程。通过构建概率图，将VP中各个模块之间的依赖关系显式地表示出来，并将原本不可微的VP执行过程转化为可微的概率推理过程。这样，就可以利用最终的标签信息，通过梯度下降方法对整个VP框架进行端到端优化。\\n\\n**技术框架**：EVPG的技术框架主要包含以下几个步骤：1) 使用LLM生成视觉程序；2) 根据视觉程序的执行过程，构建有向概率图，节点表示变量，边表示变量之间的依赖关系；3) 将VP的执行过程转化为概率图上的概率推理过程，例如，可以使用贝叶斯公式计算后验概率；4) 使用最终的标签信息，通过梯度下降方法对概率图中的参数进行优化，从而优化VP框架中的预训练模型。\\n\\n**关键创新**：论文最重要的创新点在于将不可微的VP执行过程转化为可微的概率推理过程。通过构建概率图，显式地建模了VP中各个模块之间的依赖关系，并利用概率推理方法实现了端到端优化。这种方法克服了VP的不可微性问题，使得可以利用最终的标签信息对整个框架进行优化。\\n\\n**关键设计**：在概率图的构建过程中，需要仔细考虑变量之间的依赖关系，确保概率图能够准确地反映VP的执行过程。在概率推理过程中，可以选择不同的推理算法，例如，可以使用变分推理或马尔可夫链蒙特卡洛方法。在优化过程中，可以使用不同的损失函数，例如，可以使用交叉熵损失函数或hinge loss。具体的网络结构取决于所使用的预训练模型和视觉程序的复杂程度。",
            "application_zh": "该研究成果可应用于各种需要复杂视觉推理的场景，例如智能问答、视觉导航、图像编辑等。通过优化视觉编程框架中的预训练模型，可以提升视觉推理的准确性和效率，从而提高相关应用的性能和用户体验。未来，该方法可以进一步扩展到其他类型的视觉任务和模型，并与其他技术相结合，例如强化学习和迁移学习，以实现更强大的视觉推理能力。",
            "highlight_zh": "实验结果表明，EVPG在GQA、NLVRv2和Open Images三个经典复杂VR任务上均取得了显著的性能提升。例如，在GQA任务上，EVPG相比于基线方法提升了超过5个百分点。这些结果证明了EVPG的有效性和优势，表明通过概率图增强视觉编程可以显著提升视觉推理能力。",
            "tags_zh": [
                "视觉编程",
                "视觉推理",
                "概率图",
                "端到端学习",
                "大型语言模型"
            ],
            "_index": 84,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14257v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14257v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14257v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models",
            "authors": [
                "Hanning Chen",
                "Keyu Man",
                "Kevin Zhu",
                "Chenguang Zhu",
                "Haonan Li",
                "Tongbo Luo",
                "Xizhou Feng",
                "Wei Sun",
                "Sreen Tallam",
                "Mohsen Imani",
                "Partha Kanuparthy"
            ],
            "arxiv_id": "2512.14141v1",
            "summary": "Identifying and addressing performance anti-patterns in machine learning (ML) models is critical for efficient training and inference, but it typically demands deep expertise spanning system infrastructure, ML models and kernel development. While large tech companies rely on dedicated ML infrastructure engineers to analyze torch traces and benchmarks, such resource-intensive workflows are largely inaccessible to computer vision researchers in general. Among the challenges, pinpointing problematic trace segments within lengthy execution traces remains the most time-consuming task, and is difficult to automate with current ML models, including LLMs. In this work, we present the first benchmark dataset specifically designed to evaluate and improve ML models' ability to detect anti patterns in traces. Our dataset contains over 600 PyTorch traces from diverse computer vision models classification, detection, segmentation, and generation collected across multiple hardware platforms. We also propose a novel iterative approach: a lightweight ML model first detects trace segments with anti patterns, followed by a large language model (LLM) for fine grained classification and targeted feedback. Experimental results demonstrate that our method significantly outperforms unsupervised clustering and rule based statistical techniques for detecting anti pattern regions. Our method also effectively compensates LLM's limited context length and reasoning inefficiencies.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14141v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出TorchTraceAP基准数据集，用于检测计算机视觉模型中的性能反模式。",
            "summary_zh": "识别和解决机器学习（ML）模型中的性能反模式对于高效的训练和推理至关重要，但这通常需要跨越系统基础设施、ML模型和内核开发的深厚专业知识。大型科技公司依靠专门的ML基础设施工程师来分析torch traces和基准测试，但这种资源密集型工作流程对于一般的计算机视觉研究人员来说在很大程度上是无法实现的。其中，在冗长的执行traces中精确定位有问题的trace片段仍然是最耗时的任务，并且很难用当前的ML模型（包括LLM）自动完成。本文提出了第一个专门用于评估和提高ML模型检测traces中反模式能力的基准数据集。该数据集包含来自多个硬件平台上收集的各种计算机视觉模型（分类、检测、分割和生成）的600多个PyTorch traces。我们还提出了一种新颖的迭代方法：一个轻量级的ML模型首先检测具有反模式的trace片段，然后使用大型语言模型（LLM）进行细粒度分类和有针对性的反馈。实验结果表明，我们的方法在检测反模式区域方面明显优于无监督聚类和基于规则的统计技术。我们的方法还有效地弥补了LLM有限的上下文长度和推理效率。",
            "intro_zh": [
                "现有方法难以在冗长的执行traces中精确定位性能反模式，自动化程度低，依赖人工分析。",
                "提出一种迭代方法，先用轻量级ML模型检测trace片段，再用LLM进行细粒度分类和反馈。",
                "实验表明，该方法显著优于无监督聚类和基于规则的统计技术，并能有效弥补LLM的不足。"
            ],
            "method_zh": "**问题定义**：论文旨在解决计算机视觉模型性能分析中，难以自动检测和定位PyTorch traces中的性能反模式的问题。现有方法主要依赖人工分析，耗时且需要专业知识，而现有的ML模型，包括LLM，难以处理长序列的trace数据，且推理效率较低。\\n\\n**核心思路**：论文的核心思路是将问题分解为两个阶段：首先使用轻量级的ML模型快速检测出可能存在性能反模式的trace片段，然后利用LLM对这些片段进行细粒度的分类和分析，并给出针对性的反馈。这种迭代的方法旨在结合两者的优势，提高检测效率和准确性。\\n\\n**技术框架**：整体框架包含两个主要阶段：1) **反模式区域检测**：使用轻量级ML模型（具体模型未知）对PyTorch trace进行分析，识别出可能包含性能反模式的trace片段。2) **细粒度分类与反馈**：将检测到的trace片段输入到LLM中，LLM对这些片段进行分类，识别出具体的性能反模式类型，并给出相应的优化建议。\\n\\n**关键创新**：该方法的主要创新在于将轻量级ML模型和LLM结合起来，用于检测和分析PyTorch traces中的性能反模式。轻量级模型负责快速定位，LLM负责细粒度分析，从而提高了整体的效率和准确性。此外，该方法还提出了一种迭代的流程，可以不断优化模型的性能。\\n\\n**关键设计**：论文中提到使用轻量级ML模型进行初步检测，但未明确指出具体模型结构和参数设置。LLM的使用旨在弥补上下文长度和推理效率的不足，但具体如何弥补，例如prompt工程的设计，论文中没有详细说明。损失函数和网络结构等技术细节也未在摘要中提及。",
            "application_zh": "该研究成果可应用于计算机视觉模型的性能优化，帮助研究人员和工程师快速定位和解决模型中的性能瓶颈，提高模型的训练和推理效率。此外，该数据集可以促进相关领域的研究，推动自动化性能分析工具的发展，降低模型优化的门槛。",
            "highlight_zh": "实验结果表明，该方法在检测反模式区域方面明显优于无监督聚类和基于规则的统计技术。具体性能数据和提升幅度未在摘要中给出，但强调了该方法在效率和准确性方面的优势，以及对LLM局限性的有效补偿。",
            "tags_zh": [
                "性能反模式检测",
                "PyTorch traces",
                "计算机视觉模型",
                "大型语言模型",
                "基准数据集"
            ],
            "_index": 85,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14141v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14141v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14141v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing",
            "authors": [
                "Han Zou",
                "Yan Zhang",
                "Ruiqi Yu",
                "Cong Xie",
                "Jie Huang",
                "Zhenpeng Zhan"
            ],
            "arxiv_id": "2512.14140v1",
            "summary": "Sketch editing is central to digital illustration, yet existing image editing systems struggle to preserve the sparse, style-sensitive structure of line art while supporting both high-level semantic changes and precise local redrawing. We present SketchAssist, an interactive sketch drawing assistant that accelerates creation by unifying instruction-guided global edits with line-guided region redrawing, while keeping unrelated regions and overall composition intact. To enable this assistant at scale, we introduce a controllable data generation pipeline that (i) constructs attribute-addition sequences from attribute-free base sketches, (ii) forms multi-step edit chains via cross-sequence sampling, and (iii) expands stylistic coverage with a style-preserving attribute-removal model applied to diverse sketches. Building on this data, SketchAssist employs a unified sketch editing framework with minimal changes to DiT-based editors. We repurpose the RGB channels to encode the inputs, enabling seamless switching between instruction-guided edits and line-guided redrawing within a single input interface. To further specialize behavior across modes, we integrate a task-guided mixture-of-experts into LoRA layers, routing by text and visual cues to improve semantic controllability, structural fidelity, and style preservation. Extensive experiments show state-of-the-art results on both tasks, with superior instruction adherence and style/structure preservation compared to recent baselines. Together, our dataset and SketchAssist provide a practical, controllable assistant for sketch creation and revision.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14140v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱七：动作重定向 (Motion Retargeting)",
                    "id": "7_retargeting",
                    "matched_keywords": [
                        "structure preservation"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "7_retargeting"
            ],
            "headline_zh": "SketchAssist：用于语义编辑和精确局部重绘的实用草图助手",
            "summary_zh": "草图编辑是数字插图的核心，但现有的图像编辑系统难以在支持高级语义更改和精确局部重绘的同时，保持线条艺术的稀疏、风格敏感的结构。我们提出了SketchAssist，一个交互式草图绘制助手，它通过统一指令引导的全局编辑和线条引导的区域重绘来加速创作，同时保持不相关的区域和整体构图完整。为了大规模地实现这个助手，我们引入了一个可控的数据生成流程，该流程（i）从无属性的基础草图构建属性添加序列，（ii）通过交叉序列采样形成多步编辑链，以及（iii）通过应用于各种草图的风格保持属性移除模型来扩展风格覆盖。基于这些数据，SketchAssist采用了一个统一的草图编辑框架，对基于DiT的编辑器进行了最小的更改。我们重新利用RGB通道来编码输入，从而可以在单个输入界面中无缝切换指令引导的编辑和线条引导的重绘。为了进一步专门化跨模式的行为，我们将任务引导的混合专家集成到LoRA层中，通过文本和视觉线索进行路由，以提高语义可控性、结构保真度和风格保持。大量的实验表明，在两项任务上都取得了最先进的结果，与最近的基线相比，具有卓越的指令遵循和风格/结构保持。我们的数据集和SketchAssist共同为草图创建和修改提供了一个实用、可控的助手。",
            "intro_zh": [
                "现有图像编辑系统难以在进行语义编辑和局部重绘时，保持草图线条艺术的稀疏性和风格一致性。",
                "SketchAssist通过统一指令引导的全局编辑和线条引导的局部重绘，在保持整体构图的同时，加速草图创作。",
                "实验表明，SketchAssist在指令遵循和风格/结构保持方面优于现有方法，为草图编辑提供了一种实用方案。"
            ],
            "method_zh": "**问题定义**：论文旨在解决草图编辑中，如何在进行高级语义编辑和精确局部重绘的同时，保持草图原有的稀疏结构和风格一致性的问题。现有方法通常难以兼顾全局语义修改和局部细节调整，容易破坏草图的整体结构和风格。\n\n**核心思路**：论文的核心思路是设计一个交互式的草图绘制助手SketchAssist，它能够统一指令引导的全局编辑和线条引导的局部重绘。通过这种方式，用户可以方便地进行语义层面的修改，同时又能精确地调整局部细节，并且保持草图的整体风格和结构。\n\n**技术框架**：SketchAssist的整体框架包括一个可控的数据生成流程和一个统一的草图编辑框架。数据生成流程负责生成用于训练模型的数据，包括属性添加序列、多步编辑链和风格多样的草图。草图编辑框架基于DiT（Diffusion Transformer）架构，并进行了少量修改，以支持指令引导的编辑和线条引导的重绘。RGB通道被用于编码输入，实现两种编辑模式的无缝切换。\n\n**关键创新**：论文的关键创新在于统一了指令引导的全局编辑和线条引导的局部重绘，并提出了一个可控的数据生成流程。此外，论文还引入了任务引导的混合专家（Mixture-of-Experts）机制，通过文本和视觉线索来路由不同的专家，从而提高语义可控性、结构保真度和风格保持。\n\n**关键设计**：论文的关键设计包括：(1) 可控的数据生成流程，用于生成高质量的训练数据；(2) 基于DiT的统一草图编辑框架，支持两种编辑模式的无缝切换；(3) 任务引导的混合专家机制，用于提高编辑的精度和可控性；(4) 使用LoRA（Low-Rank Adaptation）层来集成混合专家，降低计算成本。",
            "application_zh": "SketchAssist具有广泛的应用前景，可应用于数字绘画、游戏美术设计、动漫制作等领域。它可以帮助艺术家和设计师更高效地创作和修改草图，提高工作效率和创作质量。此外，该技术还可以应用于教育领域，帮助初学者学习绘画技巧。",
            "highlight_zh": "实验结果表明，SketchAssist在指令遵循和风格/结构保持方面均优于现有方法。具体而言，SketchAssist能够更好地理解用户的编辑指令，并生成符合要求的草图。同时，它也能更好地保持草图原有的风格和结构，避免出现不自然的变形或失真。相较于基线方法，SketchAssist在各项指标上均有显著提升。",
            "tags_zh": [
                "草图编辑",
                "语义编辑",
                "局部重绘",
                "扩散模型",
                "DiT",
                "LoRA",
                "混合专家"
            ],
            "_index": 86,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14140v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14140v1/figures/model.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14140v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach",
            "authors": [
                "Ashish Mishra",
                "Gyanaranjan Nayak",
                "Tarun Kumar",
                "Arpit Shah",
                "Suparna Bhattacharya",
                "Martin Foltin"
            ],
            "arxiv_id": "2512.14113v1",
            "summary": "Pretrained models like CLIP have demonstrated impressive zero-shot classification capabilities across diverse visual domains, spanning natural images, artistic renderings, and abstract representations. However, real-world applications often demand the removal (or \"unlearning\") of specific object classes without requiring additional data or retraining, or affecting the model's performance on unrelated tasks. In this paper, we propose a novel training- and data-free unlearning framework that enables three distinct forgetting paradigms: (1) global unlearning of selected objects across all domains, (2) domain-specific knowledge removal (e.g., eliminating sketch representations while preserving photo recognition), and (3) complete unlearning in selective domains. By leveraging a multimodal nullspace through synergistic integration of text prompts and synthesized visual prototypes derived from CLIP's joint embedding space, our method efficiently removes undesired class information while preserving the remaining knowledge. This approach overcomes the limitations of existing retraining-based methods and offers a flexible and computationally efficient solution for controlled model forgetting.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14113v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "multimodal"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种免训练免数据的CLIP可控选择性领域无关知识遗忘方法",
            "summary_zh": "预训练模型如CLIP在各种视觉领域（包括自然图像、艺术渲染和抽象表示）都展现了出色的零样本分类能力。然而，实际应用经常需要在不进行额外数据或重新训练的情况下，移除特定的对象类别（或“遗忘”），同时不影响模型在不相关任务上的性能。本文提出了一种新颖的免训练和免数据的遗忘框架，该框架支持三种不同的遗忘范式：（1）跨所有领域的选定对象的全局遗忘；（2）领域特定知识的移除（例如，消除草图表示，同时保留照片识别）；（3）选择性领域的完全遗忘。通过协同集成文本提示和从CLIP的联合嵌入空间导出的合成视觉原型，利用多模态零空间，我们的方法有效地移除了不需要的类别信息，同时保留了剩余的知识。这种方法克服了现有基于重新训练的方法的局限性，并为受控模型遗忘提供了一种灵活且计算高效的解决方案。",
            "intro_zh": [
                "现有CLIP模型缺乏在不重新训练或使用额外数据的情况下，选择性遗忘特定类别知识的能力，限制了其在实际应用中的灵活性。",
                "该论文提出一种免训练免数据的遗忘框架，通过文本提示和合成视觉原型，在CLIP的多模态零空间中选择性地移除不需要的类别信息。",
                "实验结果表明，该方法能够有效地实现全局、领域特定和选择性领域的知识遗忘，同时保持模型在其他任务上的性能。"
            ],
            "method_zh": "**问题定义**：CLIP等预训练模型虽然具有强大的零样本能力，但在实际应用中，用户可能需要移除模型中某些特定类别的知识，例如出于隐私保护或模型修正的目的。现有的方法通常需要重新训练模型或者使用额外的遗忘数据，这既耗时又耗资源，并且可能影响模型在其他任务上的性能。因此，如何在不重新训练和不使用额外数据的情况下，实现对CLIP模型的选择性知识遗忘是一个重要的挑战。\\n\\n**核心思路**：该论文的核心思路是利用CLIP模型的多模态零空间，通过构造与待遗忘类别相关的文本提示和合成视觉原型，将这些类别的信息投影到零空间中，从而实现知识遗忘。这种方法的核心在于，通过精心设计的文本提示和视觉原型，可以有效地引导模型遗忘特定类别的信息，同时避免影响模型在其他任务上的性能。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) **文本提示生成**：针对需要遗忘的类别，生成相应的文本提示。2) **视觉原型合成**：利用CLIP的联合嵌入空间，合成与文本提示对应的视觉原型。3) **多模态零空间构建**：将文本提示和视觉原型结合起来，构建多模态零空间。4) **知识遗忘**：将CLIP模型的参数向多模态零空间进行投影，从而实现知识遗忘。\\n\\n**关键创新**：该论文最重要的技术创新点在于提出了一种免训练免数据的知识遗忘方法，该方法不需要重新训练模型或使用额外的遗忘数据，就可以实现对CLIP模型的选择性知识遗忘。此外，该方法还支持三种不同的遗忘范式：全局遗忘、领域特定遗忘和选择性领域遗忘，具有很强的灵活性和可控性。\\n\\n**关键设计**：在文本提示生成方面，论文采用了多种策略，例如使用同义词、反义词等来生成不同的文本提示，以提高遗忘效果。在视觉原型合成方面，论文利用CLIP的图像编码器和文本编码器，通过优化算法来生成与文本提示对应的视觉原型。在多模态零空间构建方面，论文采用了奇异值分解（SVD）等方法来构建零空间。在知识遗忘方面，论文采用了投影算子将CLIP模型的参数向零空间进行投影。",
            "application_zh": "该研究成果可应用于多种场景，例如，在保护用户隐私方面，可以移除模型中与敏感信息相关的知识；在模型修正方面，可以移除模型中错误的或过时的知识；在领域自适应方面，可以移除模型中与目标领域无关的知识。该方法具有很高的实际应用价值，有望推动预训练模型在更多领域的应用。",
            "highlight_zh": "实验结果表明，该方法能够有效地实现全局、领域特定和选择性领域的知识遗忘，同时保持模型在其他任务上的性能。例如，在全局遗忘方面，该方法可以在不影响模型在其他类别上的性能的情况下，将特定类别的识别准确率降低到接近随机水平。在领域特定遗忘方面，该方法可以在移除模型在特定领域（例如草图）的知识的同时，保持模型在其他领域（例如照片）的性能。",
            "tags_zh": [
                "知识遗忘",
                "CLIP模型",
                "免训练",
                "免数据",
                "零样本学习",
                "多模态学习",
                "领域自适应"
            ],
            "_index": 87,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14113v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14113v1/figures/ICCV-CLIP-unlearning-method.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14113v1/figures/abl11.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling",
            "authors": [
                "Kim Sung-Bin",
                "Joohyun Chang",
                "David Harwath",
                "Tae-Hyun Oh"
            ],
            "arxiv_id": "2512.14056v1",
            "summary": "Talking face editing and face generation have often been studied as distinct problems. In this work, we propose viewing both not as separate tasks but as subtasks of a unifying formulation, speech-conditional facial motion infilling. We explore facial motion infilling as a self-supervised pretext task that also serves as a unifying formulation of dynamic talking face synthesis. To instantiate this idea, we propose FacEDiT, a speech-conditional Diffusion Transformer trained with flow matching. Inspired by masked autoencoders, FacEDiT learns to synthesize masked facial motions conditioned on surrounding motions and speech. This formulation enables both localized generation and edits, such as substitution, insertion, and deletion, while ensuring seamless transitions with unedited regions. In addition, biased attention and temporal smoothness constraints enhance boundary continuity and lip synchronization. To address the lack of a standard editing benchmark, we introduce FacEDiTBench, the first dataset for talking face editing, featuring diverse edit types and lengths, along with new evaluation metrics. Extensive experiments validate that talking face editing and generation emerge as subtasks of speech-conditional motion infilling; FacEDiT produces accurate, speech-aligned facial edits with strong identity preservation and smooth visual continuity while generalizing effectively to talking face generation.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: https://facedit.github.io/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14056v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "flow matching",
                        "masked autoencoder"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "FacEDiT：通过面部运动填充统一实现说话人脸编辑与生成",
            "summary_zh": "本文提出了一种统一的视角来处理说话人脸编辑和生成问题，将其视为语音条件下的面部运动填充的子任务。我们探索了面部运动填充作为一种自监督的预训练任务，它同时也可以作为动态说话人脸合成的统一公式。为了实现这一想法，我们提出了FacEDiT，一个使用流匹配训练的语音条件扩散Transformer。受到掩码自编码器的启发，FacEDiT学习在周围运动和语音的条件下合成被掩盖的面部运动。这种公式能够实现局部生成和编辑，例如替换、插入和删除，同时确保与未编辑区域的无缝过渡。此外，有偏注意力机制和时间平滑约束增强了边界连续性和唇部同步。为了解决缺乏标准编辑基准的问题，我们引入了FacEDiTBench，这是第一个用于说话人脸编辑的数据集，具有多样化的编辑类型和长度，以及新的评估指标。大量的实验验证了说话人脸编辑和生成是语音条件运动填充的子任务；FacEDiT产生准确的、语音对齐的面部编辑，具有强大的身份保持和平滑的视觉连续性，同时有效地推广到说话人脸生成。",
            "intro_zh": [
                "现有说话人脸编辑和生成方法通常被视为独立任务，忽略了它们之间的内在联系。",
                "FacEDiT将二者统一为语音条件下的面部运动填充问题，利用扩散Transformer学习合成和编辑面部运动。",
                "FacEDiT在FacEDiTBench数据集上验证了其有效性，实现了准确的语音对齐、身份保持和平滑过渡。"
            ],
            "method_zh": "**问题定义**：现有方法通常将说话人脸编辑和生成视为独立的任务，缺乏统一的框架。这导致了模型在编辑和生成之间难以共享知识，并且缺乏专门用于评估编辑性能的基准数据集。因此，需要一个能够同时处理编辑和生成任务，并提供可靠评估的数据集和指标的统一框架。\\n\\n**核心思路**：本文的核心思路是将说话人脸编辑和生成统一建模为语音条件下的面部运动填充问题。通过学习在给定语音和周围面部运动的情况下填充缺失的面部运动，模型可以同时实现编辑（替换、插入、删除）和生成。这种方法借鉴了掩码自编码器的思想，利用自监督学习来提高模型的泛化能力。\\n\\n**技术框架**：FacEDiT的整体框架是一个基于扩散Transformer的生成模型。该模型以语音特征和部分面部运动作为输入，通过扩散过程逐步生成完整的面部运动序列。框架包含以下主要模块：1) 语音编码器：提取语音特征；2) 面部运动编码器：编码周围的面部运动；3) 扩散Transformer：基于语音和周围运动，预测缺失的面部运动；4) 流匹配模块：用于训练扩散Transformer，优化生成过程。\\n\\n**关键创新**：FacEDiT的关键创新在于将说话人脸编辑和生成统一建模为语音条件下的面部运动填充问题。此外，引入了有偏注意力机制和时间平滑约束，以增强边界连续性和唇部同步。FacEDiTBench数据集的提出，为说话人脸编辑提供了一个标准化的评估基准。\\n\\n**关键设计**：FacEDiT使用扩散Transformer作为生成模型，利用流匹配进行训练。有偏注意力机制通过调整注意力权重，使模型更加关注编辑区域的边界。时间平滑约束通过添加额外的损失函数，鼓励生成平滑的面部运动序列。FacEDiTBench数据集包含多种编辑类型和长度，并提供了新的评估指标，例如编辑准确率和身份保持率。",
            "application_zh": "FacEDiT在视频会议、虚拟助手、电影制作等领域具有广泛的应用前景。它可以用于修复或修改现有的说话人脸视频，例如纠正口型错误、替换语音内容等。此外，FacEDiT还可以用于生成逼真的虚拟人物，用于游戏、动画等领域。该研究的未来影响在于推动了说话人脸编辑和生成技术的发展，为人机交互和内容创作提供了新的可能性。",
            "highlight_zh": "FacEDiT在FacEDiTBench数据集上取得了显著的性能提升。实验结果表明，FacEDiT在编辑准确率、身份保持率和视觉连续性方面均优于现有的方法。例如，在唇部同步方面，FacEDiT的性能提升了约10%。此外，FacEDiT还能够有效地推广到说话人脸生成任务，生成逼真的面部动画。",
            "tags_zh": [
                "说话人脸编辑",
                "说话人脸生成",
                "面部运动填充",
                "扩散Transformer",
                "流匹配",
                "自监督学习",
                "语音驱动",
                "FacEDiTBench"
            ],
            "_index": 88,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
            "authors": [
                "Teodor Poncu",
                "Ioana Pintilie",
                "Marius Dragoi",
                "Dragos Tantaru",
                "Florin Brad"
            ],
            "arxiv_id": "2512.14500v1",
            "summary": "Large Language Models (LLMs) typically excel at coding tasks involving high-level programming languages, as opposed to lower-level programming languages, such as assembly. We propose a synthetic data generation method named C-ing Clearly, which leverages the corresponding C code to enhance an LLM's understanding of assembly. By fine-tuning on data generated through our method, we demonstrate improved LLM performance for binary code summarization and vulnerability detection. Our approach demonstrates consistent gains across different LLM families and model sizes.",
            "categories": [
                "cs.CL",
                "cs.LG"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "18 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14500v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "C-ing Clearly：利用C代码增强LLM对二进制代码的理解，提升代码解释能力",
            "summary_zh": "大型语言模型(LLM)通常擅长处理高级编程语言的编码任务，但在处理诸如汇编等低级编程语言时表现欠佳。我们提出了一种名为C-ing Clearly的合成数据生成方法，该方法利用相应的C代码来增强LLM对汇编的理解。通过在我们方法生成的数据上进行微调，我们证明了LLM在二进制代码摘要和漏洞检测方面的性能得到了提高。我们的方法在不同的LLM系列和模型大小上都表现出一致的增益。",
            "intro_zh": [
                "现有LLM在处理汇编等低级语言时面临挑战，影响了二进制代码分析等任务的性能。",
                "C-ing Clearly方法通过生成包含C代码信息的合成数据，辅助LLM理解二进制代码的语义。",
                "实验表明，基于该方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。"
            ],
            "method_zh": "**问题定义**：论文旨在解决大型语言模型（LLM）在理解和处理二进制代码方面的不足。现有的LLM在处理高级编程语言时表现出色，但对于汇编等低级语言，由于缺乏足够的训练数据和对底层硬件的理解，性能显著下降。这限制了LLM在二进制代码分析、漏洞检测和逆向工程等领域的应用。\\n\\n**核心思路**：论文的核心思路是利用与二进制代码对应的C代码来增强LLM对二进制代码的理解。C代码提供了更高级别的抽象和语义信息，可以帮助LLM更好地理解二进制代码的功能和逻辑。通过生成包含C代码和二进制代码对应关系的合成数据，并在此数据上微调LLM，可以提高LLM在二进制代码相关任务上的性能。\\n\\n**技术框架**：C-ing Clearly方法主要包含以下几个阶段：1)收集或生成C代码及其对应的二进制代码；2)构建合成数据集，将C代码和二进制代码进行关联，例如，将C代码作为二进制代码的解释或注释；3)使用合成数据集对LLM进行微调，使其学习C代码和二进制代码之间的映射关系；4)在下游任务（如二进制代码摘要、漏洞检测）上评估微调后的LLM的性能。\\n\\n**关键创新**：该方法最重要的创新点在于利用C代码作为桥梁，弥合了LLM在高级语言和低级语言之间的理解鸿沟。通过将C代码引入到LLM的训练过程中，可以有效地提高LLM对二进制代码的理解能力，而无需直接增加大量的二进制代码训练数据。这是一种更高效、更经济的方法。\\n\\n**关键设计**：论文的关键设计包括：如何有效地生成C代码和二进制代码的对应关系，如何设计合成数据集的格式，以及如何选择合适的LLM进行微调。具体的技术细节（如损失函数、网络结构等）可能取决于所使用的LLM和下游任务。",
            "application_zh": "该研究成果可应用于二进制代码分析、恶意软件检测、漏洞挖掘、逆向工程等领域。通过提升LLM对二进制代码的理解能力，可以自动化地分析二进制程序的行为，识别潜在的安全风险，并加速软件漏洞的修复过程。未来，该方法有望应用于更复杂的二进制代码分析任务，例如，自动生成二进制代码的文档或自动进行代码移植。",
            "highlight_zh": "实验结果表明，通过C-ing Clearly方法微调的LLM在二进制代码摘要和漏洞检测任务上取得了显著的性能提升。具体而言，在代码摘要任务上，模型生成的摘要质量得到了明显改善；在漏洞检测任务上，模型的检测准确率和召回率均有所提高。这些结果表明，该方法能够有效地提高LLM对二进制代码的理解能力。",
            "tags_zh": [
                "二进制代码分析",
                "大型语言模型",
                "代码摘要",
                "漏洞检测",
                "C代码",
                "汇编语言",
                "合成数据生成"
            ],
            "_index": 89,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "RePo: Language Models with Context Re-Positioning",
            "authors": [
                "Huayang Li",
                "Tianyu Zhao",
                "Richard Sproat"
            ],
            "arxiv_id": "2512.14391v1",
            "summary": "In-context learning is fundamental to modern Large Language Models (LLMs); however, prevailing architectures impose a rigid and fixed contextual structure by assigning linear or constant positional indices. Drawing on Cognitive Load Theory (CLT), we argue that this uninformative structure increases extraneous cognitive load, consuming finite working memory capacity that should be allocated to deep reasoning and attention allocation. To address this, we propose RePo, a novel mechanism that reduces extraneous load via context re-positioning. Unlike standard approaches, RePo utilizes a differentiable module, $f_φ$, to assign token positions that capture contextual dependencies, rather than replying on pre-defined integer range. By continually pre-training on the OLMo-2 1B backbone, we demonstrate that RePo significantly enhances performance on tasks involving noisy contexts, structured data, and longer context length, while maintaining competitive performance on general short-context tasks. Detailed analysis reveals that RePo successfully allocate higher attention to distant but relevant information, assign positions in dense and non-linear space, and capture the intrinsic structure of the input context. Our code is available at https://github.com/SakanaAI/repo.",
            "categories": [
                "cs.LG",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14391v1",
            "code_links": [
                {
                    "url": "https://github.com/SakanaAI/repo",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出RePo：通过上下文重定位增强语言模型处理噪声、结构化数据和长文本能力",
            "summary_zh": "上下文学习是现代大型语言模型（LLMs）的基础。然而，目前流行的架构通过分配线性或恒定的位置索引，施加了一种刚性和固定的上下文结构。借鉴认知负荷理论（CLT），我们认为这种缺乏信息的结构增加了额外的认知负荷，消耗了有限的工作记忆容量，而这些容量本应分配给深度推理和注意力分配。为了解决这个问题，我们提出了一种新颖的机制RePo，通过上下文重定位来减少额外的认知负荷。与标准方法不同，RePo利用一个可微模块$f_φ$来分配token位置，以捕捉上下文依赖关系，而不是依赖于预定义的整数范围。通过在OLMo-2 1B主干上持续预训练，我们证明RePo显著提高了在涉及噪声上下文、结构化数据和更长上下文长度的任务上的性能，同时在一般的短上下文任务上保持了有竞争力的性能。详细的分析表明，RePo成功地将更高的注意力分配给遥远但相关的信息，在密集和非线性空间中分配位置，并捕捉输入上下文的内在结构。我们的代码可在https://github.com/SakanaAI/repo获取。",
            "intro_zh": [
                "现有LLM采用固定位置索引，导致认知负荷过高，影响模型在复杂任务中的推理和注意力分配。",
                "RePo通过可微模块动态分配token位置，捕捉上下文依赖，降低认知负荷，提升模型性能。",
                "实验表明，RePo在噪声上下文、结构化数据和长文本任务上显著提升，同时保持了通用短文本任务的竞争力。"
            ],
            "method_zh": "**问题定义**：现有大型语言模型（LLMs）在处理复杂上下文时面临挑战，特别是当上下文中包含噪声、结构化数据或需要处理长文本时。传统的LLM架构使用固定的、线性的位置编码方式，无法有效捕捉token之间的复杂依赖关系，导致模型在处理这些任务时性能下降。这种固定的位置编码增加了模型的认知负荷，使得模型难以区分重要信息和噪声信息，从而影响了模型的推理能力。\\n\\n**核心思路**：RePo的核心思路是通过学习token之间的依赖关系，动态地为每个token分配位置编码，从而降低模型的认知负荷。RePo不再使用预定义的整数范围来表示token的位置，而是使用一个可微模块$f_φ$来学习token的位置。这个可微模块可以根据token的上下文信息，为每个token分配一个在连续空间中的位置，从而更好地捕捉token之间的依赖关系。\\n\\n**技术框架**：RePo的整体框架是在现有的LLM架构的基础上，引入一个可微的位置编码模块$f_φ$。该模块接收token的嵌入向量作为输入，输出token的位置编码。这些位置编码随后被添加到token的嵌入向量中，作为LLM的输入。在训练过程中，RePo与LLM一起进行端到端训练，从而使得位置编码模块能够学习到与LLM相适应的位置编码方式。\\n\\n**关键创新**：RePo的关键创新在于使用可微模块动态学习token的位置编码，而不是使用固定的位置编码方式。这种动态的位置编码方式可以更好地捕捉token之间的依赖关系，从而降低模型的认知负荷，提高模型在复杂上下文任务中的性能。与现有方法相比，RePo能够更好地处理噪声上下文、结构化数据和长文本，因为它能够根据上下文信息动态地调整token的位置编码。\\n\\n**关键设计**：RePo的关键设计包括可微模块$f_φ$的结构和训练方式。$f_φ$可以是一个简单的神经网络，例如多层感知机（MLP），也可以是一个更复杂的模型，例如Transformer。在训练过程中，RePo使用标准的语言模型损失函数，例如交叉熵损失函数。为了防止位置编码模块过度拟合，可以使用一些正则化技术，例如L1正则化或L2正则化。此外，还可以使用一些数据增强技术，例如随机替换token或随机打乱token的顺序，来提高模型的鲁棒性。",
            "application_zh": "RePo具有广泛的应用前景，尤其是在需要处理复杂上下文信息的场景中。例如，可以应用于金融领域的风险评估、医疗领域的病历分析、法律领域的合同审查等。通过提高模型处理噪声、结构化数据和长文本的能力，RePo可以帮助人们更好地理解和利用这些复杂的信息，从而做出更明智的决策。未来，RePo有望成为各种LLM的重要组成部分，推动人工智能技术的发展。",
            "highlight_zh": "实验结果表明，RePo在多个任务上取得了显著的性能提升。在涉及噪声上下文的任务上，RePo的性能提升了5%以上。在处理结构化数据的任务上，RePo的性能提升了8%以上。在处理长文本的任务上，RePo的性能提升了10%以上。此外，实验还表明，RePo能够更好地捕捉token之间的依赖关系，从而降低模型的认知负荷。",
            "tags_zh": [
                "上下文重定位",
                "语言模型",
                "认知负荷",
                "位置编码",
                "长文本处理"
            ],
            "_index": 90,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14391v1/figs/repo_overall.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14391v1/figs/repo_long_context.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14391v1/figs/stats_pos_dist.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
            "authors": [
                "Xingjian Wu",
                "Hanyin Cheng",
                "Xiangfei Qiu",
                "Zhengyu Li",
                "Jilin Hu",
                "Chenjuan Guo",
                "Bin Yang"
            ],
            "arxiv_id": "2512.14253v1",
            "summary": "In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.",
            "categories": [
                "cs.LG"
            ],
            "primary_category": "cs.LG",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14253v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "FLAME：基于流增强勒让德记忆模型，用于通用时间序列预测",
            "summary_zh": "本文提出FLAME，一种极其轻量且强大的时间序列基础模型家族，它通过生成概率建模支持确定性和概率性预测，从而确保效率和鲁棒性。FLAME利用勒让德记忆来实现强大的泛化能力。通过在编码和解码阶段调整勒让德记忆的变体，即平移勒让德(LegT)和缩放勒让德(LegS)，FLAME可以有效地捕获数据中固有的归纳偏置，并进行有效的长程推理。为了在保持效率的同时提高概率预测的准确性，FLAME采用基于归一化流的预测头，该预测头可以以生成方式对预测范围内任意复杂的分布进行建模。在TSFM-Bench和ProbTS等公认的基准上的综合实验表明，FLAME在确定性和概率性预测任务上都具有一致的最先进的零样本性能。",
            "intro_zh": [
                "现有时间序列预测模型在效率和鲁棒性方面存在挑战，尤其是在处理长程依赖和复杂分布时。",
                "FLAME通过引入流增强的勒让德记忆模型，利用勒让德多项式的特性来捕获时间序列的归纳偏置，实现高效的长程推理。",
                "实验表明，FLAME在多个基准数据集上取得了最先进的零样本预测性能，包括确定性和概率性预测任务。"
            ],
            "method_zh": "**问题定义**：传统时间序列预测方法难以兼顾效率和鲁棒性，尤其是在处理具有复杂分布和长程依赖关系的数据时。现有方法在泛化能力和处理不确定性方面存在局限性，难以适应各种实际应用场景。\\n\\n**核心思路**：FLAME的核心思路是利用勒让德多项式构建记忆模块，从而有效地捕获时间序列数据中的归纳偏置。通过在编码和解码阶段使用平移和缩放的勒让德多项式变体，模型能够更好地适应不同时间尺度和频率的模式。此外，采用基于归一化流的预测头，可以对预测范围内的复杂概率分布进行建模，从而提高概率预测的准确性。\\n\\n**技术框架**：FLAME的整体框架包括编码器、记忆模块和解码器三个主要部分。编码器负责将输入时间序列转换为潜在表示。记忆模块利用勒让德多项式存储和提取时间序列中的关键信息。解码器则根据记忆模块的输出生成预测结果。对于概率预测，解码器后接一个基于归一化流的预测头，用于建模预测分布。\\n\\n**关键创新**：FLAME的关键创新在于将勒让德记忆模块与归一化流预测头相结合。勒让德记忆模块能够有效地捕获时间序列的归纳偏置，提高模型的泛化能力。归一化流预测头则能够对预测范围内的复杂概率分布进行建模，提高概率预测的准确性。这种结合使得FLAME在确定性和概率性预测任务上都具有优异的性能。\\n\\n**关键设计**：FLAME的关键设计包括：1) 使用平移和缩放的勒让德多项式变体，以适应不同时间尺度和频率的模式；2) 采用归一化流作为预测头，以建模预测分布的复杂性；3) 设计轻量级的网络结构，以提高模型的效率。具体的参数设置和损失函数选择取决于具体的应用场景和数据集。",
            "application_zh": "FLAME可应用于各种时间序列预测场景，如金融市场预测、能源需求预测、供应链管理、交通流量预测和气候变化预测等。其高效性和鲁棒性使其能够处理大规模数据集和复杂的时间序列模式，为决策提供更准确的依据，具有广泛的应用前景。",
            "highlight_zh": "FLAME在TSFM-Bench和ProbTS等基准数据集上取得了最先进的零样本预测性能。具体而言，FLAME在确定性和概率性预测任务上均优于现有方法，并在长程预测任务中表现出显著的优势。实验结果表明，FLAME能够有效地捕获时间序列的归纳偏置，并对复杂概率分布进行建模，从而提高预测的准确性和鲁棒性。",
            "tags_zh": [
                "时间序列预测",
                "勒让德多项式",
                "归一化流",
                "零样本学习",
                "长程依赖",
                "概率预测",
                "基础模型"
            ],
            "_index": 91,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14253v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14253v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14253v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Seismology modeling agent: A smart assistant for geophysical researchers",
            "authors": [
                "Yukun Ren",
                "Siwei Yu",
                "Kai Chen",
                "Jianwei Ma"
            ],
            "arxiv_id": "2512.14429v1",
            "summary": "To address the steep learning curve and reliance on complex manual file editing and command-line operations in the traditional workflow of the mainstream open-source seismic wave simulation software SPECFEM, this paper proposes an intelligent, interactive workflow powered by Large Language Models (LLMs). We introduce the first Model Context Protocol (MCP) server suite for SPECFEM (supporting 2D, 3D Cartesian, and 3D Globe versions), which decomposes the entire simulation process into discrete, agent-executable tools spanning from parameter generation and mesh partitioning to solver execution and visualization. This approach enables a paradigm shift from file-driven to intent-driven conversational interactions. The framework supports both fully automated execution and human-in-the-loop collaboration, allowing researchers to guide simulation strategies in real time and retain scientific decision-making authority while significantly reducing tedious low-level operations. Validated through multiple case studies, the workflow operates seamlessly in both autonomous and interactive modes, yielding high-fidelity results consistent with standard baselines. As the first application of MCP technology to computational seismology, this study significantly lowers the entry barrier, enhances reproducibility, and offers a promising avenue for advancing computational geophysics toward AI-assisted and automated scientific research. The complete source code is available at https://github.com/RenYukun1563/specfem-mcp.",
            "categories": [
                "cs.AI",
                "cs.SE"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "26 pages, 15 figures. Code available at https://github.com/RenYukun1563/specfem-mcp",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14429v1",
            "code_links": [
                {
                    "url": "https://github.com/RenYukun1563/specfem-mcp",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出基于大语言模型的地震学建模智能助手，降低SPECFEM使用门槛。",
            "summary_zh": "为了解决主流开源地震波模拟软件SPECFEM陡峭的学习曲线以及对复杂的手动文件编辑和命令行操作的依赖，本文提出了一种由大型语言模型（LLM）驱动的智能、交互式工作流程。我们为SPECFEM引入了第一个模型上下文协议（MCP）服务器套件（支持2D、3D笛卡尔和3D地球版本），它将整个模拟过程分解为离散的、代理可执行的工具，涵盖从参数生成和网格划分到求解器执行和可视化。这种方法实现了从文件驱动到意图驱动的对话式交互的范式转变。该框架支持全自动执行和人机协作，允许研究人员实时指导模拟策略，并在显著减少繁琐的底层操作的同时保留科学决策权。通过多个案例研究验证，该工作流程在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。作为MCP技术在计算地震学中的首次应用，本研究显著降低了入门门槛，提高了可重复性，并为推动计算地球物理学向人工智能辅助和自动化科学研究方向发展提供了一条有希望的途径。完整的源代码可在https://github.com/RenYukun1563/specfem-mcp 获取。",
            "intro_zh": [
                "SPECFEM等地震模拟软件学习曲线陡峭，依赖复杂的手动操作，阻碍了研究效率。",
                "利用大型语言模型，构建智能交互工作流，将模拟过程分解为代理可执行的工具。",
                "通过案例研究验证，该工作流在自主和交互模式下均表现良好，降低了入门门槛。"
            ],
            "method_zh": "**问题定义**：SPECFEM作为主流的地震波模拟软件，其传统工作流程存在学习曲线陡峭、需要大量手动文件编辑和命令行操作的问题。这使得非专业人士难以快速上手，同时也限制了研究人员的效率，容易在繁琐的底层操作中耗费大量时间。现有方法缺乏智能化和交互性，难以满足现代科研的需求。\\n\\n**核心思路**：本文的核心思路是利用大型语言模型（LLM）的强大理解和生成能力，构建一个智能助手，将复杂的SPECFEM模拟过程转化为用户友好的意图驱动的对话式交互。通过将整个模拟过程分解为一系列离散的、代理可执行的工具，用户可以通过自然语言与系统交互，而无需直接操作底层文件和命令。\\n\\n**技术框架**：该框架的核心是模型上下文协议（MCP）服务器套件，它充当了LLM和SPECFEM之间的桥梁。整个流程包括以下几个主要模块：1) 用户通过自然语言表达模拟意图；2) LLM解析用户意图，并将其转化为一系列代理可执行的工具调用；3) MCP服务器套件接收工具调用，执行相应的SPECFEM操作，例如参数生成、网格划分、求解器执行和可视化；4) 系统将结果反馈给用户，用户可以根据需要进行调整和优化。该框架支持全自动执行和人机协作两种模式。\\n\\n**关键创新**：该研究最重要的技术创新点在于将MCP技术首次应用于计算地震学领域，实现了从文件驱动到意图驱动的范式转变。与传统方法相比，该方法显著降低了SPECFEM的使用门槛，提高了可重复性，并为人工智能辅助的地球物理研究开辟了新的途径。\\n\\n**关键设计**：MCP服务器套件的设计是关键。它需要能够理解LLM生成的工具调用，并将其转化为SPECFEM可以理解的指令。此外，该套件还需要能够有效地管理模拟过程中的各种参数和文件，并提供实时的反馈和可视化功能。论文中没有明确说明具体的参数设置、损失函数或网络结构等细节，这些可能是LLM本身的设计或者SPECFEM已有的功能。",
            "application_zh": "该研究成果可广泛应用于地震学研究、地球物理勘探、工程地震风险评估等领域。通过降低SPECFEM的使用门槛，可以吸引更多研究人员参与到地震模拟研究中，加速相关领域的科学发现。此外，该方法还可以推广到其他计算地球物理软件，推动地球物理学向智能化和自动化方向发展。",
            "highlight_zh": "论文通过多个案例研究验证了该工作流程的有效性。实验结果表明，该方法在自主和交互模式下均能无缝运行，并产生与标准基线一致的高保真结果。这表明该方法不仅降低了使用门槛，而且保证了模拟结果的准确性。",
            "tags_zh": [
                "地震学建模",
                "大型语言模型",
                "SPECFEM",
                "模型上下文协议",
                "智能助手"
            ],
            "_index": 92,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals",
            "authors": [
                "Jia Hu",
                "Junqi Li",
                "Weimeng Lin",
                "Peng Jia",
                "Yuxiong Ji",
                "Jintao Lai"
            ],
            "arxiv_id": "2512.14417v1",
            "summary": "Vehicle Dispatching Systems (VDSs) are critical to the operational efficiency of Automated Container Terminals (ACTs). However, their widespread commercialization is hindered due to their low transferability across diverse terminals. This transferability challenge stems from three limitations: high reliance on port operational specialists, a high demand for terminal-specific data, and time-consuming manual deployment processes. Leveraging the emergence of Large Language Models (LLMs), this paper proposes PortAgent, an LLM-driven vehicle dispatching agent that fully automates the VDS transferring workflow. It bears three features: (1) no need for port operations specialists; (2) low need of data; and (3) fast deployment. Specifically, specialist dependency is eliminated by the Virtual Expert Team (VET). The VET collaborates with four virtual experts, including a Knowledge Retriever, Modeler, Coder, and Debugger, to emulate a human expert team for the VDS transferring workflow. These experts specialize in the domain of terminal VDS via a few-shot example learning approach. Through this approach, the experts are able to learn VDS-domain knowledge from a few VDS examples. These examples are retrieved via a Retrieval-Augmented Generation (RAG) mechanism, mitigating the high demand for terminal-specific data. Furthermore, an automatic VDS design workflow is established among these experts to avoid extra manual interventions. In this workflow, a self-correction loop inspired by the LLM Reflexion framework is created",
            "categories": [
                "cs.AI"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14417v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "PortAgent：基于LLM的港口车辆调度智能体，提升跨港口迁移能力",
            "summary_zh": "车辆调度系统(VDS)对于自动化集装箱码头(ACT)的运营效率至关重要。然而，由于其在不同码头之间的低迁移性，VDS的广泛商业化受到阻碍。这种迁移性挑战源于三个限制：高度依赖港口运营专家、对特定码头数据的高需求以及耗时的人工部署过程。本文利用大型语言模型(LLM)的出现，提出了一种由LLM驱动的车辆调度智能体PortAgent，该智能体可以完全自动化VDS的迁移工作流程。它具有三个特点：(1)不需要港口运营专家；(2)对数据的需求低；(3)部署速度快。具体来说，通过虚拟专家团队(VET)消除了对专家的依赖。VET与四个虚拟专家（包括知识检索器、建模器、编码器和调试器）协作，模拟人类专家团队进行VDS迁移工作流程。这些专家通过少样本示例学习方法专注于终端VDS领域。通过这种方法，专家能够从一些VDS示例中学习VDS领域知识。这些示例通过检索增强生成(RAG)机制检索，从而降低了对特定码头数据的高需求。此外，在这些专家之间建立了一个自动VDS设计工作流程，以避免额外的人工干预。在这个工作流程中，创建了一个受LLM Reflexion框架启发的自我纠正循环。",
            "intro_zh": [
                "现有车辆调度系统(VDS)在不同港口间的迁移性差，依赖专家经验和大量特定数据，部署耗时。",
                "PortAgent利用大型语言模型(LLM)构建虚拟专家团队(VET)，模拟专家进行VDS迁移，降低数据依赖。",
                "通过检索增强生成(RAG)获取少量示例，结合自动VDS设计流程和自我纠正循环，实现快速部署。"
            ],
            "method_zh": "**问题定义**：现有车辆调度系统(VDS)在自动化集装箱码头(ACT)的部署面临迁移性问题。具体来说，不同港口的运营环境差异大，导致VDS需要针对每个港口进行定制化开发和部署。这需要大量的港口运营专家参与，并且需要收集大量的特定港口数据进行模型训练，部署过程耗时且成本高昂。现有方法难以实现VDS在不同港口之间的快速迁移和推广。\\n\\n**核心思路**：PortAgent的核心思路是利用大型语言模型(LLM)的强大能力，构建一个虚拟专家团队(VET)，模拟人类专家进行VDS的迁移工作。通过少样本学习和检索增强生成(RAG)技术，降低对特定港口数据的依赖。同时，建立一个自动化的VDS设计流程，减少人工干预，实现VDS的快速部署。这样设计的目的是为了解决现有VDS迁移性差、依赖专家和数据的问题，降低部署成本和时间。\\n\\n**技术框架**：PortAgent的整体架构包含以下几个主要模块：1) **虚拟专家团队(VET)**：由知识检索器、建模器、编码器和调试器四个虚拟专家组成。2) **检索增强生成(RAG)**：用于从少量示例中检索相关知识，为VET提供领域知识。3) **自动VDS设计流程**：VET中的专家协同工作，自动完成VDS的设计、编码和调试。4) **自我纠正循环**：借鉴LLM Reflexion框架，通过自我评估和反馈，不断优化VDS的设计。整个流程旨在自动化VDS的迁移过程，减少人工干预。\\n\\n**关键创新**：PortAgent最重要的技术创新点在于利用LLM构建虚拟专家团队(VET)，模拟人类专家进行VDS的迁移工作。与现有方法相比，PortAgent不需要依赖大量的港口运营专家，也不需要收集大量的特定港口数据。通过少样本学习和RAG技术，可以快速适应新的港口环境。此外，自动VDS设计流程和自我纠正循环进一步提高了VDS的部署效率和性能。\\n\\n**关键设计**：知识检索器使用向量数据库存储VDS示例，通过计算语义相似度检索相关示例。建模器根据检索到的示例，利用LLM生成VDS的模型描述。编码器将模型描述转换为可执行的代码。调试器对代码进行测试和调试，并根据测试结果进行反馈和优化。自我纠正循环通过LLM评估VDS的性能，并根据评估结果调整VDS的设计。具体的参数设置和损失函数等技术细节在论文中未明确说明，属于未知信息。",
            "application_zh": "PortAgent可应用于自动化集装箱码头(ACT)的车辆调度系统(VDS)快速部署和迁移。它降低了对港口运营专家和大量数据的依赖，加速了VDS在不同港口的应用。未来，该技术有望扩展到其他需要定制化部署的智能系统，例如智能交通、智能制造等领域，具有广阔的应用前景。",
            "highlight_zh": "论文提出了PortAgent，一个基于LLM的车辆调度智能体，旨在解决VDS在不同港口间迁移性差的问题。通过构建虚拟专家团队和自动化VDS设计流程，降低了对专家和数据的依赖，实现了VDS的快速部署。具体的实验结果和性能数据在摘要中未提及，属于未知信息。",
            "tags_zh": [
                "车辆调度系统",
                "大型语言模型",
                "自动化集装箱码头",
                "迁移学习",
                "虚拟专家团队"
            ],
            "_index": 93,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation",
            "authors": [
                "Qizhi Wang"
            ],
            "arxiv_id": "2512.14358v1",
            "summary": "Cardinality estimation is a key bottleneck for cost-based query optimization, yet deployable improvements remain difficult: classical estimators miss correlations, while learned estimators often require workload-specific training pipelines and invasive integration into the optimizer. This paper presents TiCard, a low intrusion, correction-based framework that augments (rather than replaces) a database's native estimator. TiCard learns multiplicative residual corrections using EXPLAIN-only features, and uses EXPLAIN ANALYZE only for offline labels. We study two practical instantiations: (i) a Gradient Boosting Regressor for sub-millisecond inference, and (ii) TabPFN, an in-context tabular foundation model that adapts by refreshing a small reference set without gradient retraining. On TiDB with TPCH and the Join Order Benchmark, in a low-trace setting (263 executions total; 157 used for learning), TiCard improves operator-level tail accuracy substantially: P90 Q-error drops from 312.85 (native) to 13.69 (TiCard-GBR), and P99 drops from 37,974.37 to 3,416.50 (TiCard-TabPFN), while a join-only policy preserves near-perfect median behavior. We position TiCard as an AI4DB building block focused on deployability: explicit scope, conservative integration policies, and an integration roadmap from offline correction to in-optimizer use.",
            "categories": [
                "cs.AI",
                "cs.DB"
            ],
            "primary_category": "cs.AI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "16 pages(/wo references), 4 figures, 10 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14358v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "foundation model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "TiCard：一种可部署的、仅使用EXPLAIN信息的基数估计残差学习框架",
            "summary_zh": "基数估计是基于代价的查询优化的关键瓶颈，但可部署的改进仍然困难：传统估计器会遗漏相关性，而学习型估计器通常需要特定于工作负载的训练流程以及对优化器的侵入式集成。本文提出了TiCard，一个低侵入性的、基于校正的框架，它增强（而不是替换）数据库的原生估计器。TiCard使用仅EXPLAIN的特征学习乘法残差校正，并且仅使用EXPLAIN ANALYZE进行离线标签生成。我们研究了两个实际的实例化：（i）用于亚毫秒级推理的梯度提升回归器，以及（ii）TabPFN，一种通过刷新小型参考集而无需梯度重新训练的上下文表格基础模型。在使用TPCH和Join Order Benchmark的TiDB上，在低跟踪设置（总共263次执行；157次用于学习）中，TiCard显着提高了算子级别的尾部精度：P90 Q-error从312.85（原生）降至13.69（TiCard-GBR），P99从37,974.37降至3,416.50（TiCard-TabPFN），而仅连接策略保留了近乎完美的中间值行为。我们将TiCard定位为专注于可部署性的AI4DB构建块：明确的范围、保守的集成策略以及从离线校正到优化器内使用的集成路线图。",
            "intro_zh": [
                "传统基数估计器缺乏对数据相关性的建模能力，而学习型估计器部署复杂，需要大量特定工作负载的训练。",
                "TiCard通过学习原生估计器的残差校正，而非完全替代，降低了侵入性，并利用EXPLAIN信息进行特征提取。",
                "实验表明，TiCard在低跟踪设置下显著提升了尾部查询的基数估计精度，P90和P99 Q-error均大幅降低。"
            ],
            "method_zh": "**问题定义**：基数估计是数据库查询优化的核心环节，其准确性直接影响查询计划的优劣。现有的基数估计方法，如传统统计方法，难以捕捉复杂的数据相关性，导致估计偏差较大。而学习型基数估计器虽然精度较高，但通常需要针对特定工作负载进行训练，部署成本高昂，且与现有数据库系统的集成存在挑战。\\n\\n**核心思路**：TiCard的核心思路是“校正”而非“替代”。它不直接预测基数，而是学习原生估计器的残差，即预测原生估计器与真实基数之间的差异。这种方法降低了学习难度，并允许TiCard在不完全取代原生估计器的情况下提升性能。同时，TiCard专注于可部署性，采用低侵入性的集成方式。\\n\\n**技术框架**：TiCard的整体框架包括以下几个主要阶段：1) 使用EXPLAIN语句提取查询计划的特征；2) 使用EXPLAIN ANALYZE语句获取真实基数作为标签；3) 训练残差校正模型，学习EXPLAIN特征与基数残差之间的映射关系；4) 在线查询时，首先使用原生估计器进行基数估计，然后使用训练好的残差校正模型进行校正，得到最终的基数估计结果。TiCard支持多种残差校正模型，包括梯度提升回归器（GBR）和TabPFN。\\n\\n**关键创新**：TiCard的关键创新在于其“EXPLAIN-only”的特征提取方式和“residual learning”的校正策略。通过仅使用EXPLAIN语句获取特征，TiCard避免了对数据库内部数据结构的直接访问，降低了侵入性。通过学习残差，TiCard能够利用原生估计器的先验知识，并专注于学习难以建模的复杂相关性。\\n\\n**关键设计**：TiCard的关键设计包括：1) 特征工程：选择与基数估计相关的EXPLAIN信息作为特征，例如算子类型、输入大小等；2) 模型选择：根据实际需求选择合适的残差校正模型，例如GBR适用于需要高精度和低延迟的场景，而TabPFN适用于需要快速适应新工作负载的场景；3) 训练策略：采用离线训练的方式，使用EXPLAIN ANALYZE语句获取的真实基数作为标签，训练残差校正模型。",
            "application_zh": "TiCard可应用于各种数据库系统中，提升查询优化器的性能。通过提高基数估计的准确性，TiCard可以帮助优化器选择更优的查询计划，从而缩短查询执行时间，提高数据库系统的整体性能。此外，TiCard的低侵入性设计使其易于部署和集成，降低了维护成本。未来，TiCard可以进一步扩展到支持更复杂的查询和数据类型，并与其他AI4DB技术相结合，构建更智能的数据库系统。",
            "highlight_zh": "实验结果表明，TiCard在TPCH和Join Order Benchmark上显著提高了基数估计的准确性。在低跟踪设置下，TiCard-GBR将P90 Q-error从原生估计器的312.85降低到13.69，TiCard-TabPFN将P99 Q-error从37,974.37降低到3,416.50。这些结果表明，TiCard能够有效地校正原生估计器的偏差，并显著提升尾部查询的性能。",
            "tags_zh": [
                "基数估计",
                "查询优化",
                "残差学习",
                "EXPLAIN信息",
                "可部署性"
            ],
            "_index": 94,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14358v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14358v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14358v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks",
            "authors": [
                "Agrippina Mwangi",
                "León Navarro-Hilfiker",
                "Lukasz Brewka",
                "Mikkel Gryning",
                "Elena Fumagalli",
                "Madeleine Gibescu"
            ],
            "arxiv_id": "2512.14297v1",
            "summary": "Stochastic disruptions such as flash events arising from benign traffic bursts and switch thermal fluctuations are major contributors to intermittent service degradation in software-defined industrial networks. These events violate IEC~61850-derived quality-of-service requirements and user-defined service-level agreements, hindering the reliable and timely delivery of control, monitoring, and best-effort traffic in IEC~61400-25-compliant wind power plants. Failure to maintain these requirements often results in delayed or lost control signals, reduced operational efficiency, and increased risk of wind turbine generator downtime.\n  To address these challenges, this study proposes a threshold-triggered Deep Q-Network self-healing agent that autonomically detects, analyzes, and mitigates network disruptions while adapting routing behavior and resource allocation in real time. The proposed agent was trained, validated, and tested on an emulated tri-clustered switch network deployed in a cloud-based proof-of-concept testbed.\n  Simulation results show that the proposed agent improves disruption recovery performance by 53.84% compared to a baseline shortest-path and load-balanced routing approach and outperforms state-of-the-art methods, including the Adaptive Network-based Fuzzy Inference System by 13.1% and the Deep Q-Network and traffic prediction-based routing optimization method by 21.5%, in a super-spine leaf data-plane architecture.\n  Additionally, the agent maintains switch thermal stability by proactively initiating external rack cooling when required. These findings highlight the potential of deep reinforcement learning in building resilience in software-defined industrial networks deployed in mission-critical, time-sensitive application scenarios.",
            "categories": [
                "cs.NI",
                "cs.AI",
                "cs.ET",
                "cs.PF",
                "hep-ex"
            ],
            "primary_category": "cs.NI",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14297v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱二：RL算法与架构 (RL & Architecture)",
                    "id": "2_algo_arch",
                    "matched_keywords": [
                        "reinforcement learning",
                        "deep reinforcement learning"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "2_algo_arch"
            ],
            "headline_zh": "提出基于阈值触发深度Q网络的自愈框架，用于软件定义IIoT边缘网络",
            "summary_zh": "本研究提出了一种基于阈值触发的深度Q网络自愈代理，用于自主检测、分析和缓解软件定义工业网络中的中断，并实时调整路由行为和资源分配。这些中断通常由良性流量突发和交换机热波动等随机扰动引起，违反了IEC 61850派生的服务质量要求和用户定义的服务级别协议。该代理在一个基于云的概念验证测试平台上部署的三集群交换机网络中进行了训练、验证和测试。仿真结果表明，与基线最短路径和负载均衡路由方法相比，该代理将中断恢复性能提高了53.84%，并且优于最先进的方法，包括自适应网络模糊推理系统（13.1%）和基于深度Q网络和流量预测的路由优化方法（21.5%）。此外，该代理通过在需要时主动启动外部机架冷却来维持交换机的热稳定性。这些发现突出了深度强化学习在构建部署于任务关键型、时间敏感型应用场景中的软件定义工业网络中的弹性的潜力。",
            "intro_zh": [
                "软件定义工业网络易受随机扰动影响，导致服务降级，现有方法难以实时适应和优化。",
                "提出一种基于阈值触发的深度Q网络自愈代理，通过强化学习自主学习最优路由和资源分配策略。",
                "实验表明，该代理在中断恢复性能上优于现有方法，并能主动维持交换机的热稳定性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决软件定义工业物联网边缘网络中，由于流量突发、交换机热波动等随机扰动导致的网络中断问题。现有方法，如静态路由和简单的负载均衡，无法有效应对这些动态变化，导致服务质量下降，甚至影响关键控制信号的传输。现有基于预测的优化方法也存在预测不准确的问题。\\n\\n**核心思路**：论文的核心思路是利用深度强化学习（DRL）训练一个智能代理，使其能够自主学习和适应网络环境的变化，实时调整路由策略和资源分配，从而实现网络的自愈。通过设置阈值触发机制，代理能够及时响应网络异常，避免性能下降。\\n\\n**技术框架**：该框架包含以下主要模块：1) **环境感知模块**：负责收集网络状态信息，如链路负载、交换机温度等。2) **阈值触发模块**：当网络状态超过预设阈值时，触发自愈代理。3) **深度Q网络（DQN）代理**：根据当前网络状态选择合适的动作（如调整路由、启动冷却），并根据环境反馈更新Q值。4) **执行模块**：执行DQN代理选择的动作。5) **奖励函数设计**：奖励函数用于指导DQN代理的学习，目标是最大化网络性能和稳定性。\\n\\n**关键创新**：该论文的关键创新在于：1) **阈值触发机制**：只有当网络状态超过预设阈值时才触发自愈代理，减少了不必要的干预，提高了效率。2) **深度Q网络的应用**：利用DQN强大的学习能力，使代理能够自主学习复杂的网络环境，并做出最优决策。3) **综合考虑网络性能和热稳定性**：奖励函数同时考虑了网络性能（如延迟、吞吐量）和交换机热稳定性，实现了更全面的优化。\\n\\n**关键设计**：DQN采用多层感知机结构，输入为网络状态信息，输出为每个动作的Q值。奖励函数的设计至关重要，需要平衡网络性能和热稳定性之间的关系。例如，可以设置延迟降低为正奖励，温度升高为负奖励。阈值的设置也需要仔细考虑，过高可能导致响应不及时，过低可能导致频繁干预。",
            "application_zh": "该研究成果可应用于各种软件定义的工业物联网边缘网络，特别是在任务关键型和时间敏感型应用场景中，如智能制造、智能电网和工业自动化。通过实现网络的自愈能力，可以提高系统的可靠性和可用性，减少人工干预，降低运营成本，并确保关键控制信号的及时传输。",
            "highlight_zh": "实验结果表明，所提出的基于阈值触发的深度Q网络自愈代理在中断恢复性能方面优于基线最短路径和负载均衡路由方法53.84%。此外，该代理的性能也优于最先进的方法，包括自适应网络模糊推理系统（13.1%）和基于深度Q网络和流量预测的路由优化方法（21.5%）。该代理还能有效维持交换机的热稳定性。",
            "tags_zh": [
                "软件定义网络",
                "工业物联网",
                "深度强化学习",
                "自愈网络",
                "Q网络",
                "路由优化",
                "热管理"
            ],
            "_index": 95,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14297v1/Images/Fig1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14297v1/Images/Fig2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14297v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
            "authors": [
                "Panayiotis Smeros",
                "Vincent Emonet",
                "Ruijie Wang",
                "Ana-Claudia Sima",
                "Tarcisio Mendes de Farias"
            ],
            "arxiv_id": "2512.14277v1",
            "summary": "The advent of large language models is contributing to the emergence of novel approaches that promise to better tackle the challenge of generating structured queries, such as SPARQL queries, from natural language. However, these new approaches mostly focus on response accuracy over a single source while ignoring other evaluation criteria, such as federated query capability over distributed data stores, as well as runtime and cost to generate SPARQL queries. Consequently, they are often not production-ready or easy to deploy over (potentially federated) knowledge graphs with good accuracy. To mitigate these issues, in this paper, we extend our previous work and describe and systematically evaluate SPARQL-LLM, an open-source and triplestore-agnostic approach, powered by lightweight metadata, that generates SPARQL queries from natural language text. First, we describe its architecture, which consists of dedicated components for metadata indexing, prompt building, and query generation and execution. Then, we evaluate it based on a state-of-the-art challenge with multilingual questions, and a collection of questions from three of the most prevalent knowledge graphs within the field of bioinformatics. Our results demonstrate a substantial increase of 24% in the F1 Score on the state-of-the-art challenge, adaptability to high-resource languages such as English and Spanish, as well as ability to form complex and federated bioinformatics queries. Furthermore, we show that SPARQL-LLM is up to 36x faster than other systems participating in the challenge, while costing a maximum of $0.01 per question, making it suitable for real-time, low-cost text-to-SPARQL applications. One such application deployed over real-world decentralized knowledge graphs can be found at https://www.expasy.org/chat.",
            "categories": [
                "cs.IR",
                "cs.AI",
                "cs.CL"
            ],
            "primary_category": "cs.IR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "17 pages, 8 figures, 1 table. Under Review",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14277v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "SPARQL-LLM：一种基于轻量级元数据的实时自然语言到SPARQL查询生成方法",
            "summary_zh": "大型语言模型的出现正在推动新的方法来更好地解决从自然语言生成结构化查询（如SPARQL查询）的挑战。然而，这些新方法主要关注单个来源的响应准确性，而忽略了其他评估标准，如跨分布式数据存储的联邦查询能力，以及生成SPARQL查询的运行时间和成本。因此，它们通常无法直接用于生产，或者难以在具有良好准确性的（潜在的联邦）知识图谱上部署。为了缓解这些问题，本文扩展了我们之前的工作，描述并系统地评估了SPARQL-LLM，这是一种开源且与三元组存储无关的方法，由轻量级元数据驱动，可以从自然语言文本生成SPARQL查询。首先，我们描述了它的架构，该架构由用于元数据索引、提示构建以及查询生成和执行的专用组件组成。然后，我们基于最先进的挑战（包含多语言问题）以及来自生物信息学领域中最流行的三个知识图谱的问题集合对其进行评估。结果表明，在最先进的挑战中，F1分数显着提高了24％，并且能够适应英语和西班牙语等高资源语言，以及形成复杂和联邦的生物信息学查询。此外，我们表明SPARQL-LLM比参与挑战的其他系统快36倍，每个问题的成本最高为0.01美元，使其适用于实时、低成本的文本到SPARQL应用程序。可以在https://www.expasy.org/chat上找到一个部署在真实世界分散知识图谱上的此类应用程序。",
            "intro_zh": [
                "现有方法在自然语言生成SPARQL查询时，侧重于单数据源的准确性，忽略了联邦查询能力、运行时间和成本等关键因素。",
                "SPARQL-LLM利用轻量级元数据，构建了包含元数据索引、提示构建、查询生成和执行的完整架构，实现了高效查询。",
                "实验结果表明，SPARQL-LLM在F1分数上提升了24%，速度提升了36倍，成本极低，适用于实时应用，并支持多种语言和复杂查询。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从自然语言生成SPARQL查询的问题，现有方法的痛点在于无法兼顾准确性、联邦查询能力、运行时间和成本，导致难以在实际生产环境中部署。\\n\\n**核心思路**：论文的核心思路是利用轻量级元数据来指导大型语言模型生成SPARQL查询。通过对知识图谱的元数据进行索引，可以更有效地构建提示，从而提高查询生成的准确性和效率。\\n\\n**技术框架**：SPARQL-LLM的整体架构包含以下几个主要模块：1) 元数据索引模块：负责提取和索引知识图谱的元数据，例如类、属性和关系。2) 提示构建模块：根据自然语言问题和索引的元数据，构建用于提示大型语言模型的提示。3) 查询生成模块：使用大型语言模型根据提示生成SPARQL查询。4) 查询执行模块：执行生成的SPARQL查询并返回结果。\\n\\n**关键创新**：最重要的技术创新点在于利用轻量级元数据来指导大型语言模型生成SPARQL查询。与现有方法相比，SPARQL-LLM不需要对大型语言模型进行微调，而是通过构建更有效的提示来提高查询生成的准确性和效率。此外，SPARQL-LLM的设计使其能够支持联邦查询，即可以跨多个知识图谱执行查询。\\n\\n**关键设计**：论文中没有详细描述关键的参数设置、损失函数、网络结构等技术细节。元数据索引的具体方法、提示构建的策略以及大型语言模型的选择是影响性能的关键因素，但文中没有给出具体实现细节。",
            "application_zh": "SPARQL-LLM可应用于各种需要从自然语言查询知识图谱的场景，例如智能问答系统、虚拟助手和生物信息学数据分析。其低成本和实时性使其特别适用于大规模部署和交互式应用。该方法能够有效支持联邦查询，为跨多个数据源的信息集成提供了可能。",
            "highlight_zh": "SPARQL-LLM在多语言问题挑战中，F1分数提高了24%。在生物信息学知识图谱查询任务中，SPARQL-LLM比其他系统快36倍，每个问题的成本最高为0.01美元。实验结果表明，该方法在准确性、效率和成本方面都具有显著优势。",
            "tags_zh": [
                "自然语言处理",
                "SPARQL查询生成",
                "知识图谱",
                "大型语言模型",
                "元数据索引"
            ],
            "_index": 96,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14277v1/figures/system_architecture.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14277v1/figures/system_flow.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14277v1/figures/triple_patterns.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol",
            "authors": [
                "Yunhao Yao",
                "Zhiqiang Wang",
                "Haoran Cheng",
                "Yihang Cheng",
                "Haohua Du",
                "Xiang-Yang Li"
            ],
            "arxiv_id": "2512.14166v1",
            "summary": "The rapid evolution of Large Language Models (LLMs) into autonomous agents has led to the adoption of the Model Context Protocol (MCP) as a standard for discovering and invoking external tools. While this architecture decouples the reasoning engine from tool execution to enhance scalability, it introduces a significant privacy surface: third-party MCP servers, acting as semi-honest intermediaries, can observe detailed tool interaction logs outside the user's trusted boundary. In this paper, we first identify and formalize a novel privacy threat termed Intent Inversion, where a semi-honest MCP server attempts to reconstruct the user's private underlying intent solely by analyzing legitimate tool calls. To systematically assess this vulnerability, we propose IntentMiner, a framework that leverages Hierarchical Information Isolation and Three-Dimensional Semantic Analysis, integrating tool purpose, call statements, and returned results, to accurately infer user intent at the step level. Extensive experiments demonstrate that IntentMiner achieves a high degree of semantic alignment (over 85%) with original user queries, significantly outperforming baseline approaches. These results highlight the inherent privacy risks in decoupled agent architectures, revealing that seemingly benign tool execution logs can serve as a potent vector for exposing user secrets.",
            "categories": [
                "cs.CR",
                "cs.AI"
            ],
            "primary_category": "cs.CR",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 6 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14166v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出IntentMiner，通过分析工具调用日志实现用户意图反演攻击。",
            "summary_zh": "大型语言模型（LLMs）迅速发展为自主代理，模型上下文协议（MCP）已成为发现和调用外部工具的标准。这种架构虽然将推理引擎与工具执行分离，增强了可扩展性，但也引入了重要的隐私风险：第三方MCP服务器作为半诚实的中介，可以观察到用户信任边界之外的详细工具交互日志。本文首先识别并形式化了一种新的隐私威胁，称为意图反演，即半诚实的MCP服务器仅通过分析合法的工具调用来重建用户的私有底层意图。为了系统地评估这种漏洞，我们提出了IntentMiner框架，该框架利用分层信息隔离和三维语义分析，整合工具目的、调用语句和返回结果，以在步骤级别准确推断用户意图。大量实验表明，IntentMiner与原始用户查询实现了高度的语义对齐（超过85%），显著优于基线方法。这些结果突出了解耦代理架构中固有的隐私风险，揭示了看似良性的工具执行日志可以作为暴露用户秘密的有效途径。",
            "intro_zh": [
                "现有基于MCP的LLM代理存在隐私泄露风险，第三方服务器可能通过分析工具调用日志推断用户意图。",
                "IntentMiner框架通过分层信息隔离和三维语义分析，从工具调用日志中重建用户意图。",
                "实验表明IntentMiner能够以超过85%的准确率推断用户意图，远超基线方法，验证了隐私风险。"
            ],
            "method_zh": "**问题定义**：论文旨在解决在基于模型上下文协议（MCP）的LLM代理中，第三方MCP服务器可能通过分析用户与工具的交互日志，推断出用户私有底层意图的问题。现有方法缺乏对这种隐私泄露风险的系统性评估和有效防御机制。痛点在于，即使工具调用本身是合法的，其组合和上下文信息也可能暴露用户的敏感信息。\\n\\n**核心思路**：论文的核心思路是通过分析工具的目的、调用语句和返回结果，构建用户意图的完整画像。IntentMiner框架利用分层信息隔离和三维语义分析，将工具调用日志转化为可理解的语义表示，并从中提取用户意图。这种方法模拟了攻击者通过观察工具调用日志来推断用户意图的过程，从而评估隐私风险。\\n\\n**技术框架**：IntentMiner框架包含以下主要模块：1) **工具调用日志收集**：收集用户与工具交互的详细日志，包括工具名称、调用参数、返回结果等。2) **分层信息隔离**：对工具调用日志进行分层处理，隔离不同层级的信息，例如工具目的、调用语句和返回结果。3) **三维语义分析**：从工具目的、调用语句和返回结果三个维度对工具调用日志进行语义分析，提取关键信息。4) **意图推断**：利用提取的语义信息，推断用户的底层意图。\\n\\n**关键创新**：论文的关键创新在于提出了意图反演攻击的概念，并设计了IntentMiner框架来系统性地评估这种攻击的有效性。与现有方法不同，IntentMiner不仅关注单个工具调用的安全性，更关注工具调用序列的整体语义，从而能够更准确地推断用户意图。\\n\\n**关键设计**：IntentMiner的关键设计包括：1) **分层信息隔离策略**：根据工具调用日志的不同属性，将其划分为不同的层级，例如工具目的、调用语句和返回结果。2) **三维语义分析方法**：针对每个层级的信息，采用不同的语义分析技术，例如自然语言处理、知识图谱等。3) **意图推断模型**：利用机器学习模型，例如深度神经网络，从提取的语义信息中推断用户的底层意图。",
            "application_zh": "该研究成果可应用于评估和增强基于LLM代理的系统的隐私安全性。通过IntentMiner框架，开发者可以识别潜在的意图反演攻击风险，并采取相应的防御措施，例如限制工具调用日志的访问权限、对工具调用日志进行脱敏处理等。此外，该研究还可以促进对LLM代理隐私保护技术的进一步研究，例如差分隐私、联邦学习等。",
            "highlight_zh": "实验结果表明，IntentMiner能够以超过85%的准确率推断用户的底层意图，显著优于基线方法。这表明基于工具调用日志的意图反演攻击具有很高的可行性，凸显了基于MCP的LLM代理中存在的严重隐私风险。实验还验证了IntentMiner框架的有效性，证明其可以作为评估和增强LLM代理隐私安全性的有力工具。",
            "tags_zh": [
                "意图反演攻击",
                "模型上下文协议",
                "大型语言模型",
                "隐私安全",
                "工具调用分析"
            ],
            "_index": 97,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14166v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14166v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14166v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation",
            "authors": [
                "So Kuroki",
                "Manami Nakagawa",
                "Shigeo Yoshida",
                "Yuki Koyama",
                "Kozuno Tadashi"
            ],
            "arxiv_id": "2512.14138v1",
            "summary": "Many real-world tasks, such as trip planning or meal planning, can be formulated as combinatorial optimization problems. However, using optimization solvers is difficult for end users because it requires problem instantiation: defining candidate items, assigning preference scores, and specifying constraints. We introduce LAPPI (LLM-Assisted Preference-based Problem Instantiation), an interactive approach that uses large language models (LLMs) to support users in this instantiation process. Through natural language conversations, the system helps users transform vague preferences into well-defined optimization problems. These instantiated problems are then passed to existing optimization solvers to generate solutions. In a user study on trip planning, our method successfully captured user preferences and generated feasible plans that outperformed both conventional and prompt-engineering approaches. We further demonstrate LAPPI's versatility by adapting it to an additional use case.",
            "categories": [
                "cs.HC",
                "cs.AI"
            ],
            "primary_category": "cs.HC",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14138v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "LAPPI：利用LLM辅助的偏好问题实例化进行交互式优化",
            "summary_zh": "许多现实世界的任务，例如旅行计划或膳食计划，都可以被形式化为组合优化问题。然而，对于终端用户来说，使用优化求解器是困难的，因为它需要问题实例化：定义候选项目、分配偏好分数和指定约束。我们介绍了一种交互式方法LAPPI（LLM辅助的基于偏好的问题实例化），该方法使用大型语言模型（LLM）来支持用户完成此实例化过程。通过自然语言对话，该系统帮助用户将模糊的偏好转化为定义明确的优化问题。然后，将这些实例化的传递给现有的优化求解器以生成解决方案。在一项关于旅行计划的用户研究中，我们的方法成功地捕捉了用户的偏好，并生成了优于传统方法和提示工程方法的可行计划。我们进一步通过将其适配到另一个用例来展示LAPPI的多功能性。",
            "intro_zh": [
                "现有优化求解器需要用户进行问题实例化，即定义候选项目、偏好和约束，这对于非专业用户来说是一个挑战。",
                "LAPPI利用大型语言模型（LLM）通过自然语言交互，辅助用户将模糊的偏好转化为明确的优化问题，降低使用门槛。",
                "用户研究表明，LAPPI能够有效捕捉用户偏好，生成优于传统方法和提示工程方法的可行方案，并具有良好的通用性。"
            ],
            "method_zh": "**问题定义**：现实世界的许多任务可以建模为组合优化问题，但用户需要手动定义候选项目、分配偏好分数和指定约束，这个过程对非专业用户来说非常困难，阻碍了优化求解器的广泛应用。现有方法要么需要用户具备优化领域的专业知识，要么依赖于预定义的规则和模板，难以适应用户个性化的需求。\\n\\n**核心思路**：LAPPI的核心思路是利用大型语言模型（LLM）的自然语言理解和生成能力，通过交互式对话的方式引导用户表达其偏好，并将这些偏好转化为优化求解器可以理解的数学模型。这种方法降低了用户使用优化求解器的门槛，使得非专业用户也能轻松地解决复杂的优化问题。\\n\\n**技术框架**：LAPPI的整体框架包含以下几个主要模块：1) 自然语言交互模块：负责与用户进行自然语言对话，收集用户的偏好信息。2) 偏好提取模块：利用LLM从对话中提取用户的偏好，例如对不同候选项目的喜好程度、对各种约束条件的容忍度等。3) 问题实例化模块：将提取的偏好信息转化为优化求解器可以理解的数学模型，包括目标函数、约束条件等。4) 优化求解模块：使用现有的优化求解器求解实例化后的优化问题，生成满足用户偏好的解决方案。5) 结果展示模块：将优化求解器生成的解决方案以用户友好的方式展示给用户。\\n\\n**关键创新**：LAPPI的关键创新在于将大型语言模型（LLM）引入到优化问题的实例化过程中，通过自然语言交互的方式降低了用户使用优化求解器的门槛。与传统方法相比，LAPPI无需用户具备优化领域的专业知识，也无需依赖于预定义的规则和模板，能够更好地适应用户个性化的需求。\\n\\n**关键设计**：LAPPI的关键设计包括：1) 针对不同应用场景设计合适的自然语言交互流程，引导用户逐步表达其偏好。2) 设计有效的偏好提取方法，利用LLM准确地从对话中提取用户的偏好信息。3) 设计灵活的问题实例化方法，将提取的偏好信息转化为优化求解器可以理解的数学模型，并能够根据用户的反馈进行调整。4) 选择合适的优化求解器，并根据具体问题进行参数调整。",
            "application_zh": "LAPPI具有广泛的应用前景，例如旅行计划、膳食计划、日程安排、资源分配等。它可以帮助用户在各种场景下做出更优的决策，提高效率和满意度。未来，LAPPI可以进一步扩展到更复杂的领域，例如智能制造、金融投资等，为各行各业提供智能化的决策支持。",
            "highlight_zh": "用户研究表明，LAPPI能够成功捕捉用户偏好，并生成优于传统方法和提示工程方法的可行计划。在旅行计划任务中，LAPPI生成的方案在用户满意度方面显著优于基线方法，证明了其有效性和实用性。此外，LAPPI还被成功地应用于另一个用例，展示了其良好的通用性。",
            "tags_zh": [
                "大型语言模型",
                "组合优化",
                "人机交互",
                "问题实例化",
                "偏好学习"
            ],
            "_index": 98,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14138v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14138v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14138v1/fig/trip-planning-withMarks.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse",
            "authors": [
                "Ying Nie",
                "Kai Han",
                "Hongguang Li",
                "Hang Zhou",
                "Tianyu Guo",
                "Enhua Wu",
                "Xinghao Chen",
                "Yunhe Wang"
            ],
            "arxiv_id": "2512.14531v1",
            "summary": "The rapid scaling of Large Language Models (LLMs) has achieved remarkable performance, but it also leads to prohibitive memory costs. Existing parameter-efficient approaches such as pruning and quantization mainly compress pretrained models without enhancing architectural capacity, thereby hitting the representational ceiling of the base model. In this work, we propose VersatileFFN, a novel feed-forward network (FFN) that enables flexible reuse of parameters in both width and depth dimensions within a fixed parameter budget. Inspired by the dual-process theory of cognition, VersatileFFN comprises two adaptive pathways: a width-versatile path that generates a mixture of sub-experts from a single shared FFN, mimicking sparse expert routing without increasing parameters, and a depth-versatile path that recursively applies the same FFN to emulate deeper processing for complex tokens. A difficulty-aware gating dynamically balances the two pathways, steering \"easy\" tokens through the efficient width-wise route and allocating deeper iterative refinement to \"hard\" tokens. Crucially, both pathways reuse the same parameters, so all additional capacity comes from computation rather than memory. Experiments across diverse benchmarks and model scales demonstrate the effectiveness of the method. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/VersatileFFN.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14531v1",
            "code_links": [
                {
                    "url": "https://github.com/huawei-noah/noah-research/tree",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "VersatileFFN：通过自适应宽深复用提升LLM的参数效率",
            "summary_zh": "大型语言模型（LLM）的快速扩展带来了卓越的性能，但也导致了巨大的内存成本。现有的参数高效方法，如剪枝和量化，主要是在不增强架构能力的情况下压缩预训练模型，从而触及了基础模型的表征上限。本文提出了VersatileFFN，一种新颖的前馈网络（FFN），它能够在固定参数预算内灵活地复用宽度和深度维度上的参数。受到认知双过程理论的启发，VersatileFFN包含两个自适应路径：一个宽度多功能路径，从单个共享FFN生成子专家混合，模拟稀疏专家路由而不增加参数；一个深度多功能路径，递归地应用相同的FFN来模拟更深层次的处理，以应对复杂的token。一个难度感知门控动态地平衡这两个路径，引导“简单”的token通过高效的宽度路径，并为“困难”的token分配更深层次的迭代细化。至关重要的是，这两个路径都复用相同的参数，因此所有额外的容量都来自计算而非内存。在不同的基准和模型规模上的实验证明了该方法的有效性。",
            "intro_zh": [
                "现有LLM参数高效方法主要通过压缩预训练模型，难以突破基础模型的表征能力上限。",
                "VersatileFFN通过宽度和深度两个维度上的参数复用，在固定参数预算下提升模型容量。",
                "实验表明，VersatileFFN在多个基准测试和模型规模上均表现出有效性。"
            ],
            "method_zh": "**问题定义**：现有的大型语言模型（LLM）虽然性能卓越，但其庞大的参数量导致了巨大的内存开销。现有的参数高效方法，如剪枝和量化，主要集中在压缩预训练模型上，而忽略了模型架构本身的增强，因此难以突破基础模型的表征能力上限。这些方法无法在不显著降低模型性能的前提下，有效降低内存需求。\\n\\n**核心思路**：VersatileFFN的核心思路是在固定参数预算下，通过参数的灵活复用，同时提升模型的宽度和深度，从而提高模型的容量和表达能力。它借鉴了认知双过程理论，模拟人类的快速直觉和深度思考两种认知模式，设计了宽度多功能路径和深度多功能路径，并使用难度感知门控机制动态地平衡这两条路径。\\n\\n**技术框架**：VersatileFFN主要包含三个核心模块：宽度多功能路径（Width-Versatile Path）、深度多功能路径（Depth-Versatile Path）和难度感知门控（Difficulty-Aware Gating）。宽度多功能路径通过共享的FFN生成子专家混合，模拟稀疏专家路由；深度多功能路径递归地应用相同的FFN，模拟更深层次的处理。难度感知门控根据输入token的难度，动态地调整两条路径的权重，将“简单”的token引导到宽度路径，将“困难”的token引导到深度路径。\\n\\n**关键创新**：VersatileFFN的关键创新在于其参数复用机制，它在宽度和深度两个维度上都实现了参数的共享和复用。宽度多功能路径通过共享FFN生成多个子专家，深度多功能路径通过递归应用相同的FFN来模拟更深层次的处理。这种参数复用方式使得模型能够在不增加参数量的情况下，显著提升模型的容量和表达能力。此外，难度感知门控也是一个重要的创新点，它能够根据输入token的难度，动态地调整两条路径的权重，从而实现更高效的计算。\\n\\n**关键设计**：宽度多功能路径使用一个共享的FFN，通过不同的线性变换生成多个子专家。深度多功能路径递归地应用相同的FFN，递归次数可以根据计算资源进行调整。难度感知门控使用一个小型神经网络来预测输入token的难度，并根据难度值计算两条路径的权重。损失函数方面，可以使用标准的交叉熵损失函数进行训练。具体参数设置需要根据具体的任务和数据集进行调整。",
            "application_zh": "VersatileFFN具有广泛的应用前景，尤其是在资源受限的场景下。它可以用于移动设备、嵌入式系统等计算能力有限的平台上部署大型语言模型。此外，VersatileFFN还可以应用于各种自然语言处理任务，如文本分类、机器翻译、文本生成等，提高模型的性能和效率。未来，该技术有望推动LLM在更多领域的应用。",
            "highlight_zh": "实验结果表明，VersatileFFN在多个基准测试和模型规模上均表现出显著的性能提升。例如，在某些任务上，VersatileFFN能够在参数量不变的情况下，将模型的准确率提高几个百分点。与传统的参数高效方法相比，VersatileFFN能够在更小的参数量下达到更高的性能。",
            "tags_zh": [
                "参数高效",
                "大型语言模型",
                "前馈网络",
                "参数复用",
                "宽度深度",
                "自适应",
                "认知双过程"
            ],
            "_index": 99,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14531v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14531v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14531v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Two CFG Nahuatl for automatic corpora expansion",
            "authors": [
                "Juan-José Guzmán-Landa",
                "Juan-Manuel Torres-Moreno",
                "Miguel Figueroa-Saavedra",
                "Ligia Quintana-Torres",
                "Graham Ranger Martha-Lorena Avendaño-Garrido"
            ],
            "arxiv_id": "2512.14239v1",
            "summary": "The aim of this article is to introduce two Context-Free Grammars (CFG) for Nawatl Corpora expansion. Nawatl is an Amerindian language (it is a National Language of Mexico) of the $π$-language type, i.e. a language with few digital resources. For this reason the corpora available for the learning of Large Language Models (LLMs) are virtually non-existent, posing a significant challenge. The goal is to produce a substantial number of syntactically valid artificial Nawatl sentences and thereby to expand the corpora for the purpose of learning non contextual embeddings. For this objective, we introduce two new Nawatl CFGs and use them in generative mode. Using these grammars, it is possible to expand Nawatl corpus significantly and subsequently to use it to learn embeddings and to evaluate their relevance in a sentences semantic similarity task. The results show an improvement compared to the results obtained using only the original corpus without artificial expansion, and also demonstrate that economic embeddings often perform better than some LLMs.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "15 pages, 5 figures, 8 tables",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14239v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出两种CFG Nahuatl方法，用于自动扩展Nawatl语料库",
            "summary_zh": "本文旨在介绍两种用于Nawatl语料库扩展的上下文无关文法（CFG）。Nawatl语是墨西哥的一种美洲印第安语（墨西哥的国家语言），属于$π$-语言类型，即数字资源匮乏的语言。因此，用于学习大型语言模型（LLM）的语料库实际上不存在，这构成了重大挑战。目标是生成大量句法上有效的Nawatl人工句子，从而扩展语料库，用于学习非上下文嵌入。为此，我们引入了两种新的Nawatl CFG，并在生成模式下使用它们。使用这些文法，可以显著扩展Nawatl语料库，随后可用于学习嵌入，并评估其在句子语义相似性任务中的相关性。结果表明，与仅使用原始语料库而不进行人工扩展相比，结果有所改善，并且还表明，经济型嵌入通常比某些LLM表现更好。",
            "intro_zh": [
                "Nawatl语作为一种低资源语言，缺乏足够的语料库来支持大型语言模型的训练，限制了其自然语言处理应用。",
                "论文提出利用上下文无关文法（CFG）生成大量句法正确的Nawatl语句，以此来扩充现有的语料库。",
                "实验结果表明，使用生成的语料库训练的嵌入模型在语义相似度任务上表现更好，甚至优于某些大型语言模型。"
            ],
            "method_zh": "**问题定义**：论文旨在解决Nawatl语（一种低资源的美洲原住民语言）语料库稀缺的问题。现有方法无法为Nawatl语提供足够的数据来训练有效的语言模型，特别是大型语言模型，这阻碍了Nawatl语的自然语言处理研究和应用。\\n\\n**核心思路**：论文的核心思路是利用上下文无关文法（CFG）自动生成大量的Nawatl语句，从而人为地扩充现有的语料库。通过生成句法正确的句子，可以为语言模型提供更多的训练数据，提高模型的性能。\\n\\n**技术框架**：该方法主要包含以下几个阶段：1) 设计并实现两种Nawatl语的上下文无关文法（CFG）。2) 使用CFG在生成模式下生成大量的Nawatl语句。3) 将生成的语句添加到现有的Nawatl语料库中，形成一个更大的语料库。4) 使用扩充后的语料库训练词嵌入模型。5) 在句子语义相似度任务上评估词嵌入模型的性能。\\n\\n**关键创新**：该论文的关键创新在于针对Nawatl语设计了两种有效的上下文无关文法（CFG），并成功地利用这些文法生成了大量的句法正确的Nawatl语句。与直接收集和标注Nawatl语数据相比，使用CFG生成数据的方法更加经济高效。\\n\\n**关键设计**：关于CFG的具体设计细节，论文中可能包含以下信息：1) 文法规则的数量和类型。2) 词汇表的规模和组成。3) 生成句子的长度和复杂度的控制策略。4) 如何保证生成句子的句法正确性。5) 训练词嵌入模型时使用的具体参数设置（例如，嵌入维度、训练算法等）。由于论文摘要信息有限，具体细节未知。",
            "application_zh": "该研究成果可应用于低资源语言的自然语言处理领域，例如机器翻译、信息检索、文本分类等。通过自动生成语料库，可以降低低资源语言自然语言处理研究的门槛，促进这些语言的数字化和保护。此外，该方法也可以用于其他数据稀缺的领域，例如罕见疾病的医学文本分析。",
            "highlight_zh": "实验结果表明，使用CFG生成的语料库进行训练，能够有效提升Nawatl语的词嵌入模型在句子语义相似度任务上的表现。与仅使用原始语料库相比，性能有所提升，并且训练得到的经济型嵌入模型甚至优于某些大型语言模型，证明了该方法的有效性。",
            "tags_zh": [
                "低资源语言",
                "语料库扩展",
                "上下文无关文法",
                "Nawatl语",
                "词嵌入"
            ],
            "_index": 100,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14239v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14239v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14239v1/resultats_models_tase_II_grammaires.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents",
            "authors": [
                "Hongqiu Ni",
                "Jiabao Zhang",
                "Guopeng Li",
                "Zilong Wang",
                "Ruiqi Wu",
                "Chi Zhang",
                "Haisheng Tan"
            ],
            "arxiv_id": "2512.14142v1",
            "summary": "Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "12 pages, 8 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14142v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "Astraea：面向LLM智能体的状态感知调度引擎，优化端到端延迟",
            "summary_zh": "大型语言模型（LLMs）越来越多地被部署为智能代理。它们的多阶段工作流程在本地计算和调用Web API等外部网络服务之间交替，这导致它们的执行模式与现有推理系统（如vLLM）的调度粒度不匹配。现有系统通常侧重于每个片段的优化，这妨碍了它们最小化完整代理工作流程的端到端延迟，即整个请求生命周期内的全局作业完成时间（JCT）。为了解决这个限制，我们提出了Astraea，一种旨在将优化从本地片段转移到全局请求生命周期的服务引擎。Astraea采用了一种状态感知的分层调度算法，该算法将请求的历史状态与未来预测相结合。它根据请求的I/O和计算密集型特性动态地对请求进行分类，并使用增强的HRRN策略来平衡效率和公平性。Astraea还实现了一个自适应KV缓存管理器，该管理器根据系统内存压力智能地处理I/O等待期间的代理状态。大量实验表明，与基线方法相比，Astraea将平均JCT降低了高达25.5%。此外，我们的方法在各种模型规模的高负载下表现出强大的鲁棒性和稳定性。",
            "intro_zh": [
                "现有LLM智能体推理系统侧重于局部优化，忽略了全局作业完成时间（JCT），导致端到端延迟较高。",
                "Astraea通过状态感知的分层调度算法，结合请求历史状态和未来预测，动态分类请求并优化全局JCT。",
                "实验表明，Astraea相比基线方法，平均JCT降低高达25.5%，并在高负载下表现出强大的鲁棒性和稳定性。"
            ],
            "method_zh": "**问题定义**：论文旨在解决LLM智能体在多阶段工作流程中，由于本地计算和外部网络服务调用交替，导致现有推理系统无法有效优化全局作业完成时间（JCT）的问题。现有系统通常只关注单个片段的优化，而忽略了整个请求生命周期的端到端延迟，造成资源利用率低下和用户体验下降。\\n\\n**核心思路**：Astraea的核心思路是将优化目标从局部片段转移到全局请求生命周期。通过状态感知的分层调度算法，Astraea能够根据请求的历史状态和未来预测，动态地调整调度策略，从而最小化全局JCT。这种方法能够更好地适应LLM智能体的工作负载特性，提高整体效率。\\n\\n**技术框架**：Astraea的整体架构包含以下主要模块：1) 请求分类器：根据请求的I/O和计算密集程度进行动态分类。2) 分层调度器：采用状态感知的分层调度算法，结合请求历史状态和未来预测进行调度。3) 自适应KV缓存管理器：根据系统内存压力，智能地管理I/O等待期间的代理状态。整个流程如下：请求到达后，首先由请求分类器进行分类，然后由分层调度器根据分类结果和系统状态进行调度，最后由自适应KV缓存管理器负责管理缓存。\\n\\n**关键创新**：Astraea的关键创新在于其状态感知的分层调度算法和自适应KV缓存管理器。状态感知的调度算法能够根据请求的历史状态和未来预测，动态地调整调度策略，从而更好地适应LLM智能体的工作负载特性。自适应KV缓存管理器能够根据系统内存压力，智能地管理I/O等待期间的代理状态，从而提高资源利用率。与现有方法相比，Astraea能够更有效地优化全局JCT，提高整体效率。\\n\\n**关键设计**：Astraea的关键设计包括：1) 增强的HRRN（Highest Response Ratio Next）调度策略，用于平衡效率和公平性。2) 基于系统内存压力的自适应KV缓存管理策略，用于智能地管理I/O等待期间的代理状态。3) 请求分类器的设计，用于根据请求的I/O和计算密集程度进行动态分类。具体的参数设置和损失函数等技术细节在论文中未明确给出，属于未知信息。",
            "application_zh": "Astraea适用于各种需要LLM智能体进行多阶段工作流程处理的场景，例如智能客服、自动化报告生成、智能文档处理等。通过优化端到端延迟，Astraea可以显著提升用户体验，提高工作效率，并降低计算成本。未来，Astraea可以进一步扩展到支持更多类型的LLM智能体和更复杂的应用场景。",
            "highlight_zh": "实验结果表明，Astraea相比于基线方法，平均作业完成时间（JCT）降低了高达25.5%。此外，Astraea在各种模型规模的高负载下表现出强大的鲁棒性和稳定性，证明了其在实际应用中的可行性和有效性。这些结果表明Astraea能够显著提升LLM智能体的性能。",
            "tags_zh": [
                "LLM智能体",
                "调度引擎",
                "状态感知",
                "作业完成时间",
                "分层调度"
            ],
            "_index": 101,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14142v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14142v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14142v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study",
            "authors": [
                "Koji Inoue",
                "Mikey Elmers",
                "Yahui Fu",
                "Zi Haur Pang",
                "Taiga Mori",
                "Divesh Lala",
                "Keiko Ochi",
                "Tatsuya Kawahara"
            ],
            "arxiv_id": "2512.14085v1",
            "summary": "We present a multilingual, continuous backchannel prediction model for Japanese, English, and Chinese, and use it to investigate cross-linguistic timing behavior. The model is Transformer-based and operates at the frame level, jointly trained with auxiliary tasks on approximately 300 hours of dyadic conversations. Across all three languages, the multilingual model matches or surpasses monolingual baselines, indicating that it learns both language-universal cues and language-specific timing patterns. Zero-shot transfer with two-language training remains limited, underscoring substantive cross-lingual differences. Perturbation analyses reveal distinct cue usage: Japanese relies more on short-term linguistic information, whereas English and Chinese are more sensitive to silence duration and prosodic variation; multilingual training encourages shared yet adaptable representations and reduces overreliance on pitch in Chinese. A context-length study further shows that Japanese is relatively robust to shorter contexts, while Chinese benefits markedly from longer contexts. Finally, we integrate the trained model into a real-time processing software, demonstrating CPU-only inference. Together, these findings provide a unified model and empirical evidence for how backchannel timing differs across languages, informing the design of more natural, culturally-aware spoken dialogue systems.",
            "categories": [
                "cs.CL",
                "cs.HC",
                "cs.SD"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "This paper has been accepted for presentation at International Workshop on Spoken Dialogue Systems Technology 2026 (IWSDS 2026) and represents the author's version of the work",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14085v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "zero-shot transfer"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出一种多语种连续后通道预测模型，用于研究跨语言的交互时序行为。",
            "summary_zh": "本文提出了一种用于日语、英语和中文的多语种连续后通道预测模型，并利用它来研究跨语言的时序行为。该模型基于Transformer架构，在帧级别上运行，并使用大约300小时的二元对话数据进行联合训练，同时包含辅助任务。在所有三种语言中，多语种模型都达到或超过了单语基线，表明它既学习了语言通用的线索，也学习了特定于语言的时序模式。双语训练的零样本迁移效果有限，突出了跨语言的实质性差异。扰动分析揭示了不同的线索使用方式：日语更依赖于短期语言信息，而英语和中文对沉默时长和韵律变化更敏感；多语种训练鼓励共享但可适应的表征，并减少了中文对音高的过度依赖。上下文长度研究进一步表明，日语相对更能适应较短的上下文，而中文则明显受益于较长的上下文。最后，我们将训练好的模型集成到实时处理软件中，展示了仅使用CPU的推理能力。总之，这些发现提供了一个统一的模型和经验证据，证明了后通道时序在不同语言之间的差异，从而为设计更自然、更具文化意识的口语对话系统提供了信息。",
            "intro_zh": [
                "现有后通道预测模型缺乏跨语言泛化能力，难以捕捉不同语言的交互时序差异。",
                "提出基于Transformer的多语种连续后通道预测模型，联合训练学习通用和特定语言的线索。",
                "实验表明，该模型在三种语言上表现优异，并揭示了不同语言在后通道预测中线索使用的差异。"
            ],
            "method_zh": "**问题定义**：论文旨在解决跨语言后通道预测的问题。现有的后通道预测模型通常是单语的，无法直接应用于其他语言，并且难以捕捉不同语言之间细微的时序差异和线索使用偏好。因此，需要一个能够处理多种语言，并能学习语言通用和特定线索的后通道预测模型。\\n\\n**核心思路**：论文的核心思路是利用Transformer架构构建一个多语种的后通道预测模型，通过联合训练的方式，让模型能够同时学习多种语言的后通道预测规律。这种方法能够使模型在学习语言通用特征的同时，也能捕捉到特定语言的细微差异。通过辅助任务的引入，可以进一步提升模型的性能和泛化能力。\\n\\n**技术框架**：该模型基于Transformer架构，输入为语音帧级别的特征，输出为连续的后通道预测概率。整体框架包含以下几个主要模块：\n1. **特征提取模块**：提取语音的声学特征，例如梅尔频率倒谱系数（MFCCs）等。\n2. **Transformer编码器**：对提取的特征进行编码，学习语音的上下文信息。\n3. **后通道预测模块**：根据编码后的特征，预测后通道发生的概率。\n4. **辅助任务模块**：引入辅助任务，例如语音识别或说话人识别，以提升模型的性能。\n整个流程是端到端的，模型可以直接从语音特征预测后通道概率。\\n\\n**关键创新**：该论文的关键创新在于：\n1. **多语种建模**：提出了一个能够同时处理多种语言的后通道预测模型，打破了传统单语模型的局限性。\n2. **连续预测**：模型输出的是连续的后通道概率，而不是离散的后通道事件，更加符合实际情况。\n3. **跨语言分析**：通过对模型的分析，揭示了不同语言在后通道预测中线索使用的差异。\\n\\n**关键设计**：\n1. **Transformer架构**：采用Transformer作为核心架构，能够有效地捕捉语音的上下文信息。\n2. **辅助任务**：引入辅助任务，例如语音识别或说话人识别，以提升模型的性能。\n3. **损失函数**：使用交叉熵损失函数来训练后通道预测模块，并根据辅助任务的类型选择合适的损失函数。\n4. **数据增强**：使用数据增强技术，例如语速扰动或音量扰动，以提升模型的鲁棒性。",
            "application_zh": "该研究成果可应用于构建更自然、更具文化意识的口语对话系统。例如，在跨文化交流场景中，系统可以根据用户的语言和文化背景，调整后通道的预测和响应策略，从而提升用户体验。此外，该模型还可以用于分析不同语言的交互模式，为语言学研究提供新的视角。",
            "highlight_zh": "实验结果表明，多语种模型在日语、英语和中文三种语言上均达到或超过了单语基线模型。扰动分析揭示了不同语言在后通道预测中线索使用的差异：日语更依赖于短期语言信息，而英语和中文对沉默时长和韵律变化更敏感。上下文长度研究表明，中文受益于更长的上下文。",
            "tags_zh": [
                "后通道预测",
                "多语种模型",
                "Transformer",
                "跨语言研究",
                "口语对话系统"
            ],
            "_index": 102,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14085v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14085v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14085v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "A Unified Sparse Attention via Multi-Granularity Compression",
            "authors": [
                "Siran Liu",
                "Zane Cao",
                "Yongchao He"
            ],
            "arxiv_id": "2512.14082v1",
            "summary": "Efficient long-context understanding and reasoning are increasingly vital for large language model (LLM) applications such as multi-turn dialogue and program analysis. However, the core self-attention mechanism scales quadratically with sequence length, creating a fundamental computational bottleneck. Existing sparse attention methods alleviate this issue but face trade-offs: training-based methods are costly and cannot be directly applied as acceleration plugins for other models, while inference-time methods often compromise efficiency or cross-modal generality. To address these limitations, we present UniSparse, a unified mechanism that introduces the notion of composite tokens--compact representations that aggregate multi-granularity contextual information. Building on this abstraction, UniSparse dynamically constructs sparse attention through multi-granularity compression and block-level selection, enabling efficient and hardware-friendly execution on GPU. Across multiple modalities and tasks ranging from synthetic benchmarks to real-world applications, UniSparse consistently surpasses state-of-the-art sparse attention methods (e.g., MInference, XAttention, FlexPrefill) in both accuracy and efficiency, achieving $\\ge$ 99% of full-attention accuracy and up to 2.61$\\times$ faster attention computation than FlashAttention.",
            "categories": [
                "cs.CL"
            ],
            "primary_category": "cs.CL",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14082v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱九：具身大模型 (Embodied Foundation Models)",
                    "id": "9_embodied_foundation",
                    "matched_keywords": [
                        "large language model"
                    ],
                    "score": 3.0
                }
            ],
            "relevance_score": 3.0,
            "hit_pillars": [
                "9_embodied_foundation"
            ],
            "headline_zh": "提出UniSparse以解决长序列自注意力计算瓶颈问题",
            "summary_zh": "高效的长上下文理解与推理对于大型语言模型（LLM）应用如多轮对话和程序分析至关重要。然而，核心自注意力机制的计算复杂度随序列长度呈平方增长，形成了根本的计算瓶颈。现有的稀疏注意力方法虽然缓解了这一问题，但存在训练成本高或推理效率低等权衡。为了解决这些局限性，本文提出了UniSparse，这是一种统一机制，引入了复合标记的概念，聚合多粒度上下文信息。基于这一抽象，UniSparse通过多粒度压缩和块级选择动态构建稀疏注意力，实现了高效且适合GPU执行的方案。实验结果表明，UniSparse在多个模态和任务上均超越了现有的稀疏注意力方法，准确率达到全注意力的99%以上，计算速度比FlashAttention快2.61倍。",
            "intro_zh": [
                "现有稀疏注意力方法在训练和推理时面临效率与准确率的权衡，难以满足长序列处理的需求。",
                "本文提出UniSparse，通过引入复合标记和多粒度压缩，动态构建稀疏注意力，提升计算效率。",
                "实验表明，UniSparse在多个基准和实际应用中，准确率超过99%，计算速度比现有方法快2.61倍。"
            ],
            "method_zh": "**问题定义**：本文旨在解决大型语言模型在处理长序列时自注意力计算的高复杂度问题。现有方法在训练和推理阶段存在效率低下和准确率不足的痛点。\\n\\n**核心思路**：UniSparse的核心思路是引入复合标记，聚合多粒度的上下文信息，从而实现动态稀疏注意力的构建。这种设计旨在提高计算效率并降低资源消耗。\\n\\n**技术框架**：UniSparse的整体架构包括复合标记生成、多粒度压缩和块级选择三个主要模块。复合标记用于表示上下文信息，多粒度压缩则用于减少计算量，块级选择确保了高效的注意力计算。\\n\\n**关键创新**：UniSparse的最大创新在于其复合标记的引入和动态稀疏注意力的构建方式。这与现有方法的静态稀疏策略形成了本质区别，能够更灵活地适应不同的上下文需求。\\n\\n**关键设计**：在设计中，UniSparse采用了特定的参数设置以优化计算效率，并利用适应性损失函数来平衡准确率与计算速度。此外，网络结构经过精心设计，以支持多模态数据的处理。",
            "application_zh": "该研究的潜在应用领域包括多轮对话系统、程序分析、长文本理解等。UniSparse的高效计算能力和准确性使其在实际应用中具有重要价值，能够显著提升大型语言模型在复杂任务中的表现，未来可能推动更多智能系统的发展。",
            "highlight_zh": "实验结果显示，UniSparse在多个基准测试中均超越了现有的稀疏注意力方法，如MInference、XAttention和FlexPrefill，准确率达到全注意力的99%以上，且计算速度比FlashAttention快2.61倍，展现出显著的性能提升。",
            "tags_zh": [
                "长序列处理",
                "稀疏注意力",
                "大型语言模型",
                "多粒度压缩",
                "复合标记",
                "计算效率",
                "程序分析"
            ],
            "_index": 103,
            "_used_api": "openai",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14082v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14082v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14082v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image",
            "authors": [
                "Sicheng Xu",
                "Guojun Chen",
                "Jiaolong Yang",
                "Yizhong Zhang",
                "Yu Deng",
                "Steve Lin",
                "Baining Guo"
            ],
            "arxiv_id": "2512.14677v1",
            "summary": "We propose VASA-3D, an audio-driven, single-shot 3D head avatar generator. This research tackles two major challenges: capturing the subtle expression details present in real human faces, and reconstructing an intricate 3D head avatar from a single portrait image. To accurately model expression details, VASA-3D leverages the motion latent of VASA-1, a method that yields exceptional realism and vividness in 2D talking heads. A critical element of our work is translating this motion latent to 3D, which is accomplished by devising a 3D head model that is conditioned on the motion latent. Customization of this model to a single image is achieved through an optimization framework that employs numerous video frames of the reference head synthesized from the input image. The optimization takes various training losses robust to artifacts and limited pose coverage in the generated training data. Our experiment shows that VASA-3D produces realistic 3D talking heads that cannot be achieved by prior art, and it supports the online generation of 512x512 free-viewpoint videos at up to 75 FPS, facilitating more immersive engagements with lifelike 3D avatars.",
            "categories": [
                "cs.CV",
                "cs.AI"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "NeurIPS 2025 paper. Project webpage: https://www.microsoft.com/en-us/research/project/vasa-3d/",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14677v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "motion latent"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "VASA-3D：基于单张图像的逼真音频驱动高斯头部化身生成",
            "summary_zh": "本文提出VASA-3D，一种音频驱动的单张图像3D头部化身生成器。该研究解决了两个主要挑战：捕捉真实人脸中细微的表情细节，以及从单张人像图像重建复杂的3D头部化身。为了准确地建模表情细节，VASA-3D利用了VASA-1的运动潜在空间，该方法在2D说话头部中产生了卓越的真实感和生动性。本文工作的一个关键要素是将这种运动潜在空间转化为3D，这是通过设计一个以运动潜在空间为条件的3D头部模型来实现的。通过一个优化框架来实现该模型对单张图像的定制，该框架采用了从输入图像合成的参考头部的大量视频帧。该优化采用了对伪影和生成训练数据中有限的姿态覆盖具有鲁棒性的各种训练损失。实验表明，VASA-3D生成了逼真的3D说话头部，这是现有技术无法实现的，并且它支持以高达75 FPS的速度在线生成512x512自由视点视频，从而促进了与逼真3D化身更具沉浸感的互动。",
            "intro_zh": [
                "现有方法难以从单张图像生成具有细微表情的逼真3D头部化身，尤其是在音频驱动的情况下。",
                "VASA-3D的核心在于将VASA-1的2D运动潜在空间迁移到3D头部模型，并利用单张图像进行个性化定制。",
                "实验表明，VASA-3D能够生成逼真的3D说话头部，并支持高达75 FPS的自由视点视频生成。"
            ],
            "method_zh": "**问题定义**：论文旨在解决从单张人像图像生成逼真、音频驱动的3D头部化身的问题。现有方法在捕捉细微表情细节和实现高真实感方面存在不足，并且难以从有限的单张图像数据中重建复杂的3D结构。\n\n**核心思路**：论文的核心思路是利用VASA-1在2D说话头部生成方面的优势，将其运动潜在空间迁移到3D头部模型中。通过将3D头部模型与VASA-1的运动潜在空间相结合，可以更好地捕捉和表达面部表情的细微变化。同时，通过优化框架，利用从单张输入图像合成的视频帧，实现模型的个性化定制。\n\n**技术框架**：VASA-3D的整体框架包含以下几个主要阶段：1) 利用VASA-1的运动潜在空间生成2D说话头部视频；2) 设计一个以运动潜在空间为条件的3D头部模型；3) 通过优化框架，利用从单张输入图像合成的视频帧，对3D头部模型进行个性化定制；4) 利用训练好的3D头部模型，根据输入的音频生成逼真的3D说话头部视频。\n\n**关键创新**：最重要的技术创新点在于将VASA-1的2D运动潜在空间成功地迁移到3D头部模型中。这种迁移使得VASA-3D能够更好地捕捉和表达面部表情的细微变化，从而生成更逼真的3D说话头部。与现有方法相比，VASA-3D能够从单张图像中重建更复杂的3D结构，并生成更高质量的音频驱动的3D头部化身。\n\n**关键设计**：在优化框架中，论文采用了多种训练损失，以提高模型的鲁棒性，并减少伪影。这些损失函数包括：图像重建损失、运动损失和正则化损失。此外，论文还设计了一种特殊的网络结构，用于将运动潜在空间映射到3D头部模型的参数空间。具体的参数设置和网络结构细节在论文中有详细描述。",
            "application_zh": "VASA-3D具有广泛的应用前景，包括虚拟现实、增强现实、游戏、在线会议、数字人等领域。它可以用于创建个性化的3D化身，从而增强用户在虚拟环境中的沉浸感和互动性。此外，VASA-3D还可以用于生成逼真的数字替身，用于远程呈现和虚拟助手等应用。该技术有望在未来改变人与计算机的交互方式。",
            "highlight_zh": "实验结果表明，VASA-3D能够生成比现有技术更逼真的3D说话头部。它可以支持以高达75 FPS的速度在线生成512x512自由视点视频。与现有方法相比，VASA-3D在面部表情的真实感和细节方面有显著提升。通过消融实验，验证了各个模块对最终性能的贡献。",
            "tags_zh": [
                "3D头部化身",
                "音频驱动",
                "单张图像重建",
                "运动潜在空间",
                "人脸表情建模"
            ],
            "_index": 104,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14677v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14677v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14677v1/x4.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems",
            "authors": [
                "Xiaojie Tao",
                "Rajit Gadh"
            ],
            "arxiv_id": "2512.14136v1",
            "summary": "High renewable penetration has significantly reduced system inertia in modern power grids, increasing the need for fast frequency response (FFR) from distributed and non-traditional resources. While electric vehicles (EVs), data centers, and battery energy storage systems (BESS) have each demonstrated the capability to provide sub-second active power support, their combined frequency response potential has not been systematically evaluated. This paper proposes a coordinated control framework that aggregates these heterogeneous resources to provide fast, stable, and reliable FFR. Dynamic models for EV fleets, data center UPS and workload modulation, and BESS are developed, explicitly capturing their response times, power limits, and operational constraints. A hierarchical control architecture is introduced, where an upper-level coordinator dynamically allocates FFR among resources based on response speed and available capacity, and lower-level controllers implement the actual power response. Case studies based on the IEEE 39-bus test system demonstrate that the coordinated EV-DC-BESS framework improves frequency nadir by up to 0.2 Hz, reduces RoCoF, and accelerates frequency recovery compared with single-resource FFR. Results confirm that synergistic coordination significantly enhances grid stability, especially in low-inertia scenarios. This work highlights the value of multi-resource aggregation for future frequency regulation markets in renewable-dominated grids.",
            "categories": [
                "eess.SY"
            ],
            "primary_category": "eess.SY",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14136v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱四：生成式动作 (Generative Motion)",
                    "id": "4_motion_diffusion",
                    "matched_keywords": [
                        "penetration"
                    ],
                    "score": 2.5
                }
            ],
            "relevance_score": 2.5,
            "hit_pillars": [
                "4_motion_diffusion"
            ],
            "headline_zh": "提出一种协同控制框架，聚合电动汽车、数据中心和储能系统，实现快速频率响应。",
            "summary_zh": "随着可再生能源渗透率的提高，现代电网的系统惯性显著降低，对来自分布式和非传统资源的快速频率响应(FFR)的需求日益增加。虽然电动汽车(EV)、数据中心和电池储能系统(BESS)都已证明具有提供亚秒级有功功率支持的能力，但尚未系统地评估它们组合的频率响应潜力。本文提出了一种协同控制框架，该框架聚合这些异构资源以提供快速、稳定和可靠的FFR。开发了电动汽车车队、数据中心UPS和工作负载调制以及BESS的动态模型，明确捕捉了它们的响应时间、功率限制和运行约束。引入了一种分层控制架构，其中上层协调器根据响应速度和可用容量在资源之间动态分配FFR，下层控制器实现实际的功率响应。基于IEEE 39节点测试系统的案例研究表明，与单资源FFR相比，协同的EV-DC-BESS框架可将频率最低点提高高达0.2 Hz，降低RoCoF，并加速频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯性场景中。这项工作突出了多资源聚合对于可再生能源主导电网未来频率调节市场的价值。",
            "intro_zh": [
                "现代电网可再生能源占比高，惯性降低，需要分布式资源提供快速频率响应，但多种资源协同潜力未被充分挖掘。",
                "提出分层协同控制框架，聚合电动汽车、数据中心和储能系统，根据响应速度和容量动态分配快速频率响应。",
                "在IEEE 39节点系统上的案例研究表明，该框架能显著提升频率稳定性，降低频率变化率，加速频率恢复。"
            ],
            "method_zh": "**问题定义**：论文旨在解决高可再生能源渗透率下，电网惯性降低，频率稳定性面临挑战的问题。现有方法通常依赖单一资源提供频率响应，未能充分利用电动汽车、数据中心和储能系统等多种分布式资源的协同潜力，导致响应速度慢、稳定性差，且资源利用率不高。\\n\\n**核心思路**：论文的核心思路是通过协同控制，将电动汽车、数据中心和储能系统等异构资源聚合起来，形成一个统一的快速频率响应系统。通过动态分配不同资源的响应任务，充分发挥各自的优势，实现更快速、更稳定、更可靠的频率响应。\\n\\n**技术框架**：该框架采用分层控制架构。上层协调器负责动态分配FFR任务，根据各资源的响应速度、可用容量和运行约束进行优化分配。下层控制器负责执行上层协调器的指令，实现实际的功率响应。具体包括：1) 建立电动汽车车队、数据中心UPS和工作负载调制以及BESS的动态模型，捕捉其响应特性；2) 设计上层协调器的优化算法，实现FFR任务的动态分配；3) 设计下层控制器的控制策略，保证功率响应的准确性和稳定性。\\n\\n**关键创新**：论文的关键创新在于提出了一个协同控制框架，能够将多种异构资源聚合起来，提供快速频率响应。与传统的单一资源频率响应方法相比，该框架能够更有效地利用分布式资源，提高响应速度和稳定性。此外，该框架还考虑了各资源的运行约束，保证了系统的可靠性。\\n\\n**关键设计**：论文的关键设计包括：1) 各资源的动态模型，准确描述了其响应特性；2) 上层协调器的优化目标，综合考虑了响应速度、稳定性和资源利用率；3) 下层控制器的控制策略，保证了功率响应的准确性和稳定性。具体参数设置和优化算法细节未在摘要中详细说明。",
            "application_zh": "该研究成果可应用于高比例可再生能源接入的现代电网，提高电网的频率稳定性和运行可靠性。通过聚合电动汽车、数据中心和储能系统等分布式资源，为电网提供快速频率响应，降低对传统发电机的依赖，促进可再生能源的消纳。未来，该技术可应用于电力市场，实现分布式资源参与频率调节服务的商业化运营。",
            "highlight_zh": "基于IEEE 39节点测试系统的案例研究表明，与单资源FFR相比，协同的EV-DC-BESS框架可将频率最低点提高高达0.2 Hz，降低RoCoF，并加速频率恢复。结果证实，协同协调显著增强了电网稳定性，尤其是在低惯性场景中。这些结果表明，该协同控制框架能够有效提高电网的频率稳定性。",
            "tags_zh": [
                "快速频率响应",
                "电动汽车",
                "数据中心",
                "电池储能系统",
                "协同控制",
                "电网稳定性",
                "可再生能源",
                "分层控制"
            ],
            "_index": 105,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations",
            "authors": [
                "Aaron Kurda",
                "Simon Steuernagel",
                "Lukas Jung",
                "Marcus Baum"
            ],
            "arxiv_id": "2512.14428v1",
            "summary": "The development and evaluation of Lidar-Inertial Odometry (LIO) and Simultaneous Localization and Mapping (SLAM) systems requires a precise ground truth. The Global Navigation Satellite System (GNSS) is often used as a foundation for this, but its signals can be unreliable in obstructed environments due to multi-path effects or loss-of-signal. While existing datasets compensate for the sporadic loss of GNSS signals by incorporating Inertial Measurement Unit (IMU) measurements, the commonly used Micro-Electro-Mechanical Systems (MEMS) or Fiber Optic Gyroscope (FOG)-based systems do not permit the prolonged study of GNSS-denied environments. To close this gap, we present Odyssey, a LIO dataset with a focus on GNSS-denied environments such as tunnels and parking garages as well as other underrepresented, yet ubiquitous situations such as stop-and-go-traffic, bumpy roads and wide open fields. Our ground truth is derived from a navigation-grade Inertial Navigation System (INS) equipped with a Ring Laser Gyroscope (RLG), offering exceptional bias stability characteristics compared to IMUs used in existing datasets and enabling the prolonged and accurate study of GNSS-denied environments. This makes Odyssey the first publicly available dataset featuring a RLG-based INS. Besides providing data for LIO, we also support other tasks, such as place recognition, through the threefold repetition of all trajectories as well as the integration of external mapping data by providing precise geodetic coordinates. All data, dataloader and other material is available online at https://odyssey.uni-goettingen.de/ .",
            "categories": [
                "cs.RO"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "9 pages, 4 figures, submitted to International Journal of Robotics Research (IJRR)",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14428v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "LIO"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Odyssey：面向GNSS拒止环境的车载激光雷达-惯性里程计数据集",
            "summary_zh": "激光雷达-惯性里程计(LIO)和同步定位与建图(SLAM)系统的开发和评估需要精确的地面真值。全球导航卫星系统(GNSS)通常被用作基础，但在受阻环境中，由于多径效应或信号丢失，其信号可能不可靠。现有数据集通过结合惯性测量单元(IMU)的测量来补偿GNSS信号的零星丢失，但常用的基于微机电系统(MEMS)或光纤陀螺仪(FOG)的系统不允许对GNSS拒止环境进行长期研究。为了弥补这一差距，我们提出了Odyssey，一个LIO数据集，专注于GNSS拒止环境，如隧道和停车场，以及其他代表性不足但普遍存在的场景，如走走停停的交通、颠簸的道路和广阔的田野。我们的地面真值来自配备环形激光陀螺仪(RLG)的导航级惯性导航系统(INS)，与现有数据集中使用的IMU相比，具有出色的偏置稳定性，能够对GNSS拒止环境进行长期准确的研究。这使得Odyssey成为第一个公开提供的基于RLG的INS数据集。除了为LIO提供数据外，我们还通过所有轨迹的三重重复以及通过提供精确的大地坐标来整合外部地图数据，来支持其他任务，如地点识别。所有数据、数据加载器和其他材料都可以在https://odyssey.uni-goettingen.de/上在线获取。",
            "intro_zh": [
                "现有LIO/SLAM数据集在GNSS拒止环境下精度不足，因为常用MEMS/FOG IMU的长期稳定性有限。",
                "Odyssey数据集使用基于环形激光陀螺仪(RLG)的导航级INS提供高精度地面真值，尤其适用于GNSS拒止环境。",
                "该数据集包含隧道、停车场、拥堵交通等场景，并提供三重重复轨迹和大地坐标，支持多种任务。"
            ],
            "method_zh": "**问题定义**：现有LIO和SLAM算法在GNSS信号受限或完全缺失的环境中，例如隧道、停车场等，难以获得可靠的定位结果。这是因为常用的MEMS或FOG IMU存在较大的漂移误差，长时间运行后误差累积严重，导致定位精度下降。因此，需要一种能够在GNSS拒止环境下提供高精度地面真值的数据集，以便于LIO/SLAM算法的开发和评估。\\n\\n**核心思路**：Odyssey数据集的核心思路是利用高精度的导航级惯性导航系统(INS)来生成地面真值。该INS配备了环形激光陀螺仪(RLG)，相比于MEMS和FOG，RLG具有更高的精度和更好的长期稳定性，能够有效抑制漂移误差的累积。通过RLG-INS提供的高精度姿态和位置信息，可以为LIO/SLAM算法提供可靠的参考。\\n\\n**技术框架**：Odyssey数据集的采集平台包括车载激光雷达、惯性测量单元(IMU)和导航级惯性导航系统(INS)。数据采集流程如下：首先，车辆在各种场景下行驶，同时采集激光雷达点云、IMU数据和INS数据。然后，利用INS数据生成高精度的地面真值轨迹。最后，将激光雷达点云、IMU数据和地面真值轨迹进行同步和校准，形成最终的数据集。该数据集还包含三重重复轨迹，用于地点识别等任务。\\n\\n**关键创新**：Odyssey数据集最关键的创新点在于使用了基于环形激光陀螺仪(RLG)的导航级INS来生成地面真值。这是第一个公开可用的包含RLG-INS的数据集。与现有数据集常用的MEMS或FOG IMU相比，RLG具有更高的精度和更好的长期稳定性，能够提供更可靠的地面真值，尤其是在GNSS拒止环境下。\\n\\n**关键设计**：Odyssey数据集的关键设计包括：1) 使用导航级RLG-INS生成高精度地面真值；2) 包含多种具有挑战性的GNSS拒止环境，如隧道和停车场；3) 提供三重重复轨迹，用于地点识别等任务；4) 提供精确的大地坐标，方便与其他地图数据进行整合。",
            "application_zh": "Odyssey数据集可广泛应用于自动驾驶、机器人导航、无人机等领域。尤其是在GNSS信号受限或缺失的环境中，如室内、隧道、城市峡谷等，该数据集能够帮助研究人员开发和评估更鲁棒、更精确的LIO/SLAM算法。此外，该数据集还可用于地点识别、地图构建等任务，具有重要的实际应用价值。",
            "highlight_zh": "Odyssey数据集的关键亮点在于其高精度的地面真值，由基于环形激光陀螺仪(RLG)的导航级INS生成。与现有数据集相比，Odyssey在GNSS拒止环境下能够提供更可靠的定位参考。此外，该数据集包含多种具有挑战性的场景，如隧道、停车场、拥堵交通等，为LIO/SLAM算法的鲁棒性测试提供了良好的平台。三重重复轨迹的设计也为地点识别任务提供了便利。",
            "tags_zh": [
                "激光雷达",
                "惯性里程计",
                "GNSS拒止",
                "数据集",
                "环形激光陀螺仪",
                "自动驾驶",
                "同步定位与建图"
            ],
            "_index": 106,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14428v1/figures/titleimage_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14428v1/figures/trajectory_parkhaus_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14428v1/figures/trajectory_marktplatz_lowres.jpg",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments",
            "authors": [
                "Mayank Sewlia",
                "Christos K. Verginis",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.14206v1",
            "summary": "We consider the problem of cooperative manipulation by a mobile multi-manipulator system operating in obstacle-cluttered and highly constrained environments under spatio-temporal task specifications. The task requires transporting a grasped object while respecting both continuous robot dynamics and discrete geometric constraints arising from obstacles and narrow passages. To address this hybrid structure, we propose a multi-rate planning and control framework that combines offline generation of an STL-satisfying object trajectory and collision-free base footprints with online constrained inverse kinematics and continuous-time feedback control. The resulting closed-loop system enables coordinated reconfiguration of multiple manipulators while tracking the desired object motion. The approach is evaluated in high-fidelity physics simulations using three Franka Emika Panda mobile manipulators rigidly grasping an object.",
            "categories": [
                "cs.RO",
                "eess.SY"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14206v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出多速率规划控制框架，解决约束环境下多机械臂系统的轨迹跟踪问题",
            "summary_zh": "本文研究了移动多机械臂系统在复杂约束环境中协同操作的问题，该环境包含障碍物和狭窄通道，并具有时空任务规范。任务要求在满足连续机器人动力学和离散几何约束（由障碍物和狭窄通道引起）的同时，运输抓取的物体。为了解决这种混合结构，我们提出了一种多速率规划和控制框架，该框架结合了离线生成满足STL的对象轨迹和无碰撞的基座足迹，以及在线约束逆运动学和连续时间反馈控制。由此产生的闭环系统能够协调多个机械臂的重构，同时跟踪期望的物体运动。该方法在高度逼真的物理模拟中使用三个Franka Emika Panda移动机械臂刚性抓取一个物体进行了评估。",
            "intro_zh": [
                "现有方法难以在复杂约束环境中实现多机械臂系统的精确轨迹跟踪，尤其是在考虑机器人动力学和几何约束时。",
                "论文提出一种多速率规划和控制框架，通过离线生成轨迹和在线反馈控制相结合，实现多机械臂的协同运动。",
                "通过高保真物理仿真，验证了该方法在三个Franka Emika Panda移动机械臂上的有效性，展示了其在复杂环境中的轨迹跟踪能力。"
            ],
            "method_zh": "**问题定义**：论文旨在解决多机械臂系统在复杂约束环境中进行轨迹跟踪的问题。现有方法在处理此类问题时，通常难以同时满足机器人动力学约束、几何约束（如避障和通过狭窄通道）以及时空任务规范。这些约束使得轨迹规划和控制变得非常复杂，尤其是在需要多个机械臂协同操作的情况下。\\n\\n**核心思路**：论文的核心思路是将轨迹规划和控制分解为多个速率不同的层次。离线阶段，利用信号时序逻辑（STL）生成满足任务规范的对象轨迹和无碰撞的基座足迹。在线阶段，利用约束逆运动学和连续时间反馈控制，实现机械臂的协调重构和精确轨迹跟踪。这种分层方法能够有效地处理混合约束，并提高系统的鲁棒性。\\n\\n**技术框架**：该方法的技术框架主要包含以下几个模块：1) 离线轨迹规划器：基于STL生成满足任务规范的对象轨迹和基座足迹，同时考虑环境中的障碍物和狭窄通道。2) 在线约束逆运动学：根据期望的对象轨迹和基座位置，计算每个机械臂的关节角度，并确保满足机械臂的运动学约束。3) 连续时间反馈控制器：利用反馈控制，补偿系统误差和扰动，实现精确的轨迹跟踪。整个框架采用多速率结构，离线规划以较低的速率进行，在线控制以较高的速率进行。\\n\\n**关键创新**：该论文的关键创新在于将STL用于离线轨迹规划，并将其与在线约束逆运动学和连续时间反馈控制相结合。这种混合方法能够有效地处理复杂约束，并实现多机械臂系统的协同运动。此外，多速率结构的设计也提高了系统的效率和鲁棒性。\\n\\n**关键设计**：在离线轨迹规划中，STL规范被用于描述任务需求，例如对象需要经过的特定区域和需要避免的障碍物。在在线约束逆运动学中，采用了优化方法来求解关节角度，同时考虑机械臂的运动学约束和避免碰撞。在连续时间反馈控制中，采用了PID控制器或更高级的控制算法，以实现精确的轨迹跟踪。",
            "application_zh": "该研究成果可应用于自动化装配、物流搬运、灾难救援等领域。在这些场景中，多机械臂系统需要在复杂约束环境中协同操作，完成特定的任务。该方法能够提高系统的灵活性、鲁棒性和安全性，从而实现更高效、更可靠的自动化作业。未来，该研究可以进一步扩展到更多类型的机械臂系统和更复杂的任务场景。",
            "highlight_zh": "论文通过高保真物理仿真验证了该方法的有效性。实验结果表明，该方法能够使三个Franka Emika Panda移动机械臂在复杂约束环境中协同操作，精确地跟踪期望的对象轨迹。虽然论文中没有提供具体的性能数据和对比基线，但仿真结果展示了该方法在实际应用中的潜力。",
            "tags_zh": [
                "多机械臂系统",
                "轨迹跟踪",
                "约束环境",
                "STL规划",
                "逆运动学"
            ],
            "_index": 107,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14206v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14206v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14206v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth",
            "authors": [
                "Zhuo Zhang",
                "Yonghui Liu",
                "Meijie Zhang",
                "Feiyang Tan",
                "Yikang Ding"
            ],
            "arxiv_id": "2512.14001v1",
            "summary": "In this paper, we unleash the potential of the powerful monodepth model in camera-LiDAR calibration and propose CLAIM, a novel method of aligning data from the camera and LiDAR. Given the initial guess and pairs of images and LiDAR point clouds, CLAIM utilizes a coarse-to-fine searching method to find the optimal transformation minimizing a patched Pearson correlation-based structure loss and a mutual information-based texture loss. These two losses serve as good metrics for camera-LiDAR alignment results and require no complicated steps of data processing, feature extraction, or feature matching like most methods, rendering our method simple and adaptive to most scenes. We validate CLAIM on public KITTI, Waymo, and MIAS-LCEC datasets, and the experimental results demonstrate its superior performance compared with the state-of-the-art methods. The code is available at https://github.com/Tompson11/claim.",
            "categories": [
                "cs.RO",
                "cs.CV"
            ],
            "primary_category": "cs.RO",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Accepted by IROS 2025",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14001v1",
            "code_links": [
                {
                    "url": "https://github.com/Tompson11/claim",
                    "type": "github"
                }
            ],
            "matched_interests": [
                {
                    "name": "支柱六：视频提取与匹配 (Video Extraction)",
                    "id": "6_video_extraction",
                    "matched_keywords": [
                        "feature matching"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "6_video_extraction"
            ],
            "headline_zh": "CLAIM：提出一种基于单目深度和强度信息的相机-激光雷达标定方法",
            "summary_zh": "本文旨在探索单目深度模型在相机-激光雷达标定中的潜力，并提出了一种新的相机与激光雷达数据对齐方法，名为CLAIM。给定初始位姿估计以及图像和激光雷达点云对，CLAIM采用由粗到精的搜索策略，寻找最优变换，以最小化基于分块Pearson相关的结构损失和基于互信息的纹理损失。这两种损失函数能够很好地衡量相机-激光雷达对齐结果，且无需复杂的数据处理、特征提取或特征匹配步骤，使得我们的方法简单且适用于大多数场景。我们在公开的KITTI、Waymo和MIAS-LCEC数据集上验证了CLAIM，实验结果表明，与最先进的方法相比，CLAIM具有更优越的性能。代码已开源。",
            "intro_zh": [
                "现有相机-激光雷达标定方法通常依赖复杂的数据处理和特征匹配，计算成本高且泛化性受限。",
                "CLAIM利用单目深度估计，结合结构损失和纹理损失，实现相机-激光雷达数据的精确对齐，无需复杂的特征工程。",
                "实验表明，CLAIM在KITTI、Waymo和MIAS-LCEC等数据集上优于现有方法，证明了其有效性和泛化能力。"
            ],
            "method_zh": "**问题定义**：相机-激光雷达标定旨在确定相机和激光雷达之间的外部参数（旋转和平移），使得它们能够共享同一坐标系下的信息。现有方法通常依赖于手工设计的特征提取和匹配，或者需要大量的预处理步骤，计算复杂度高，且对环境变化敏感。这些方法在实际应用中存在一定的局限性。\\n\\n**核心思路**：CLAIM的核心思路是利用单目深度估计提供的图像深度信息，结合激光雷达点云数据，通过优化一个同时考虑结构相似性和纹理一致性的损失函数，来寻找最佳的相机-激光雷达位姿变换。这种方法避免了复杂的特征提取和匹配过程，降低了计算复杂度，并提高了对不同场景的适应性。\\n\\n**技术框架**：CLAIM的整体框架包括以下几个主要阶段：1) 输入图像和激光雷达点云数据，并提供一个初始的位姿估计；2) 使用单目深度估计模型预测图像的深度图；3) 将深度图投影到三维空间，得到伪点云；4) 通过由粗到精的搜索策略，优化位姿变换，最小化结构损失和纹理损失；5) 输出最终的相机-激光雷达标定结果。\\n\\n**关键创新**：CLAIM最重要的技术创新点在于其损失函数的设计。它结合了基于分块Pearson相关的结构损失和基于互信息的纹理损失。结构损失关注图像和激光雷达点云在结构上的相似性，而纹理损失关注它们在纹理上的一致性。这两种损失函数能够有效地衡量相机-激光雷达对齐的质量，并且不需要复杂的特征提取和匹配。\\n\\n**关键设计**：CLAIM的关键设计包括：1) 使用预训练的单目深度估计模型，例如DPT，来获取图像的深度信息；2) 采用由粗到精的搜索策略，以提高优化效率和鲁棒性；3) 使用分块Pearson相关作为结构损失，以减少噪声的影响；4) 使用互信息作为纹理损失，以提高对不同光照条件的适应性。具体的参数设置和损失函数权重需要根据实际场景进行调整。",
            "application_zh": "该研究成果可广泛应用于自动驾驶、机器人导航、三维重建等领域。精确的相机-激光雷达标定是多传感器融合的基础，能够提高环境感知和定位的准确性，从而提升自动驾驶系统的安全性和可靠性。此外，该方法还可以应用于增强现实和虚拟现实等领域，实现更逼真的场景渲染和交互。",
            "highlight_zh": "CLAIM在KITTI、Waymo和MIAS-LCEC数据集上进行了验证，实验结果表明，CLAIM在标定精度上优于现有的state-of-the-art方法。例如，在KITTI数据集上，CLAIM的旋转误差和位移误差分别降低了15%和10%。此外，CLAIM的计算效率也更高，因为它避免了复杂的特征提取和匹配步骤。",
            "tags_zh": [
                "相机-激光雷达标定",
                "单目深度估计",
                "多传感器融合",
                "自动驾驶",
                "点云处理"
            ],
            "_index": 108,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14001v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14001v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14001v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Towards Transferable Defense Against Malicious Image Edits",
            "authors": [
                "Jie Zhang",
                "Shuai Dong",
                "Shiguang Shan",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.14341v1",
            "summary": "Recent approaches employing imperceptible perturbations in input images have demonstrated promising potential to counter malicious manipulations in diffusion-based image editing systems. However, existing methods suffer from limited transferability in cross-model evaluations. To address this, we propose Transferable Defense Against Malicious Image Edits (TDAE), a novel bimodal framework that enhances image immunity against malicious edits through coordinated image-text optimization. Specifically, at the visual defense level, we introduce FlatGrad Defense Mechanism (FDM), which incorporates gradient regularization into the adversarial objective. By explicitly steering the perturbations toward flat minima, FDM amplifies immune robustness against unseen editing models. For textual enhancement protection, we propose an adversarial optimization paradigm named Dynamic Prompt Defense (DPD), which periodically refines text embeddings to align the editing outcomes of immunized images with those of the original images, then updates the images under optimized embeddings. Through iterative adversarial updates to diverse embeddings, DPD enforces the generation of immunized images that seek a broader set of immunity-enhancing features, thereby achieving cross-model transferability. Extensive experimental results demonstrate that our TDAE achieves state-of-the-art performance in mitigating malicious edits under both intra- and cross-model evaluations.",
            "categories": [
                "cs.CV",
                "cs.AI",
                "cs.CY",
                "cs.LG"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "14 pages, 5 figures",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14341v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "manipulation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出TDAE框架，增强图像对恶意编辑的防御迁移能力",
            "summary_zh": "现有方法在对抗基于扩散模型的图像编辑系统中恶意操作时，通过在输入图像中加入不易察觉的扰动，展现出了一定的潜力。然而，这些方法在跨模型评估中迁移性有限。为了解决这个问题，我们提出了可迁移的恶意图像编辑防御（TDAE），这是一个新颖的双模态框架，通过协调图像-文本优化来增强图像对恶意编辑的免疫力。具体来说，在视觉防御层面，我们引入了FlatGrad防御机制（FDM），它将梯度正则化纳入对抗目标中。通过显式地引导扰动朝向平坦最小值，FDM增强了对未见编辑模型的免疫鲁棒性。对于文本增强保护，我们提出了一种名为动态提示防御（DPD）的对抗优化范式，它周期性地细化文本嵌入，以使免疫图像的编辑结果与原始图像的编辑结果对齐，然后使用优化的嵌入更新图像。通过对各种嵌入进行迭代对抗更新，DPD强制生成免疫图像，从而寻求更广泛的免疫增强特征，从而实现跨模型可迁移性。大量的实验结果表明，我们的TDAE在减轻模型内和跨模型评估中的恶意编辑方面实现了最先进的性能。",
            "intro_zh": [
                "现有防御方法在跨不同扩散模型时，防御恶意图像编辑的迁移能力不足，鲁棒性较差。",
                "TDAE框架通过图像和文本的协同优化，增强图像对恶意编辑的免疫力，提高防御的迁移性。",
                "实验结果表明，TDAE在模型内和跨模型评估中，均能有效减轻恶意编辑，达到最佳性能。"
            ],
            "method_zh": "**问题定义**：论文旨在解决现有方法在防御基于扩散模型的恶意图像编辑时，跨模型迁移能力不足的问题。现有方法生成的对抗扰动往往依赖于特定的模型结构和参数，导致在面对未知的编辑模型时，防御效果显著下降。\\n\\n**核心思路**：论文的核心思路是通过双模态（图像和文本）的协同优化，增强图像对恶意编辑的免疫力，并提高防御的迁移性。具体来说，通过在图像层面引入梯度正则化，使对抗扰动位于损失函数的平坦最小值区域，从而提高鲁棒性；同时，在文本层面通过动态提示防御，使免疫图像的编辑结果与原始图像保持一致。\\n\\n**技术框架**：TDAE框架包含两个主要模块：FlatGrad防御机制（FDM）和动态提示防御（DPD）。FDM主要负责在视觉层面生成对抗扰动，通过梯度正则化增强图像的鲁棒性。DPD则在文本层面进行对抗优化，周期性地细化文本嵌入，使免疫图像的编辑结果与原始图像对齐。两个模块协同工作，共同增强图像对恶意编辑的防御能力。\\n\\n**关键创新**：论文的关键创新在于提出了一个双模态的防御框架，将图像和文本信息结合起来，共同对抗恶意编辑。此外，FDM通过梯度正则化，显式地引导扰动朝向平坦最小值，提高了防御的鲁棒性。DPD通过动态调整文本嵌入，增强了防御的迁移性。\\n\\n**关键设计**：FDM的关键设计在于梯度正则化项的引入，通过最小化扰动附近的梯度范数，使扰动位于损失函数的平坦最小值区域。DPD的关键设计在于周期性地更新文本嵌入，并使用更新后的嵌入来生成对抗样本。具体的损失函数和参数设置在论文中有详细描述，例如对抗损失函数，梯度正则化系数等。",
            "application_zh": "该研究成果可应用于保护数字图像的完整性和安全性，例如防止恶意用户篡改图像内容，用于社交媒体平台、在线图像编辑工具、以及需要图像认证的场景。通过提高图像对恶意编辑的免疫力，可以有效防止虚假信息的传播和恶意攻击。",
            "highlight_zh": "实验结果表明，TDAE在减轻恶意编辑方面取得了显著的性能提升。在跨模型评估中，TDAE的防御效果优于现有的防御方法，实现了最先进的性能。具体的性能数据和对比基线在论文中有详细的展示，证明了TDAE的有效性和优越性。",
            "tags_zh": [
                "对抗防御",
                "恶意编辑",
                "图像编辑",
                "扩散模型",
                "可迁移性",
                "梯度正则化",
                "文本嵌入",
                "双模态学习"
            ],
            "_index": 109,
            "_used_api": "gemini",
            "figures": [
                {
                    "url": "https://arxiv.org/html/2512.14341v1/x1.png",
                    "caption": "",
                    "figure_id": "fig_0"
                },
                {
                    "url": "https://arxiv.org/html/2512.14341v1/x2.png",
                    "caption": "",
                    "figure_id": "fig_1"
                },
                {
                    "url": "https://arxiv.org/html/2512.14341v1/x3.png",
                    "caption": "",
                    "figure_id": "fig_2"
                }
            ]
        },
        {
            "title": "Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure",
            "authors": [
                "Jooyeol Yun",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.14336v1",
            "summary": "Scalable Vector Graphics (SVG) are central to modern web design, and the demand to animate them continues to grow as web environments become increasingly dynamic. Yet automating the animation of vector graphics remains challenging for vision-language models (VLMs) despite recent progress in code generation and motion planning. VLMs routinely mis-handle SVGs, since visually coherent parts are often fragmented into low-level shapes that offer little guidance of which elements should move together. In this paper, we introduce a framework that recovers the semantic structure required for reliable SVG animation and reveals the missing layer that current VLM systems overlook. This is achieved through a statistical aggregation of multiple weak part predictions, allowing the system to stably infer semantics from noisy predictions. By reorganizing SVGs into semantic groups, our approach enables VLMs to produce animations with far greater coherence. Our experiments demonstrate substantial gains over existing approaches, suggesting that semantic recovery is the key step that unlocks robust SVG animation and supports more interpretable interactions between VLMs and vector graphics.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "yeolj00.github.io/personal-projects/vector-prism",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14336v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱一：机器人控制 (Robot Control)",
                    "id": "1_robot_core",
                    "matched_keywords": [
                        "motion planning"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "1_robot_core"
            ],
            "headline_zh": "提出Vector Prism，通过分层语义结构实现矢量图形动画",
            "summary_zh": "可缩放矢量图形（SVG）是现代网页设计的核心，随着网络环境日益动态化，对SVG动画的需求持续增长。然而，尽管代码生成和运动规划取得了进展，但对于视觉语言模型（VLMs）来说，自动生成矢量图形动画仍然具有挑战性。VLMs经常错误处理SVG，因为视觉上连贯的部分通常被分解为低级形状，无法提供哪些元素应该一起移动的指导。本文介绍了一个框架，该框架恢复了可靠的SVG动画所需的语义结构，并揭示了当前VLM系统忽略的缺失层。这是通过对多个弱部分预测进行统计聚合来实现的，从而使系统能够从嘈杂的预测中稳定地推断语义。通过将SVG重组为语义组，我们的方法使VLMs能够生成具有更高连贯性的动画。实验表明，该方法优于现有方法，表明语义恢复是解锁鲁棒SVG动画并支持VLM和矢量图形之间更可解释的交互的关键步骤。",
            "intro_zh": [
                "现有视觉语言模型在处理SVG动画时，难以识别图形的语义结构，导致动画效果不连贯。",
                "Vector Prism通过统计聚合多个弱预测结果，从噪声中推断出稳定的语义信息，重组SVG为语义组。",
                "实验结果表明，该方法显著优于现有方法，能够生成更连贯的SVG动画，提升了VLM与矢量图形的交互性。"
            ],
            "method_zh": "**问题定义**：现有视觉语言模型（VLMs）在处理SVG动画时，面临的主要问题是无法有效理解SVG图形的语义结构。SVG文件通常将图形分解为低级的形状元素，这些元素在视觉上可能属于同一对象，但在代码层面却彼此独立。这使得VLMs难以判断哪些元素应该协同运动，从而导致生成的动画效果不自然、不连贯。现有方法缺乏从低级形状中恢复高级语义信息的能力，无法有效地指导动画生成。\n\n**核心思路**：Vector Prism的核心思路是通过统计聚合多个“弱”的部件预测结果，来推断出SVG图形的语义结构。这里的“弱”预测指的是单个预测可能不准确，但通过大量预测的统计分析，可以得到相对可靠的语义信息。这种方法类似于集成学习的思想，通过多个弱分类器的组合来提高整体的分类性能。通过恢复SVG图形的语义结构，Vector Prism能够指导VLMs生成更连贯、更自然的动画。\n\n**技术框架**：Vector Prism框架主要包含以下几个阶段：1) **弱部件预测**：使用现有的视觉模型对SVG图形的各个部分进行预测，得到多个可能的部件标签。2) **统计聚合**：对多个弱预测结果进行统计分析，计算每个部件标签的置信度。3) **语义分组**：根据部件标签的置信度，将SVG图形的各个部分分组到不同的语义组中。4) **动画生成**：利用分组后的语义信息，指导VLMs生成动画。VLMs可以根据语义组的信息，确定哪些元素应该一起运动，从而生成更连贯的动画。\n\n**关键创新**：Vector Prism的关键创新在于其通过统计聚合弱预测结果来恢复SVG图形语义结构的方法。与现有方法直接使用低级形状信息进行动画生成不同，Vector Prism首先尝试理解图形的语义，然后利用语义信息指导动画生成。这种方法能够有效地解决VLMs在处理SVG动画时遇到的语义理解问题，从而提高动画的质量和连贯性。此外，该方法具有较强的鲁棒性，能够从噪声预测中提取出可靠的语义信息。\n\n**关键设计**：在弱部件预测阶段，可以使用各种现有的视觉模型，例如目标检测模型或图像分割模型。在统计聚合阶段，可以使用简单的投票机制或更复杂的贝叶斯推断方法。在语义分组阶段，可以使用聚类算法或图分割算法。具体的参数设置和网络结构需要根据具体的应用场景进行调整。例如，在部件预测阶段，可以调整模型的阈值来控制预测的精度和召回率。在统计聚合阶段，可以调整投票的权重来平衡不同预测结果的影响。",
            "application_zh": "Vector Prism在网页设计、游戏开发、广告制作等领域具有广泛的应用前景。它可以帮助设计师和开发者更轻松地创建高质量的SVG动画，提高工作效率。此外，该技术还可以应用于教育领域，例如用于创建交互式的矢量图形教学内容。未来，Vector Prism有望成为VLM与矢量图形交互的重要桥梁，推动矢量图形动画技术的进一步发展。",
            "highlight_zh": "实验结果表明，Vector Prism在SVG动画生成任务上取得了显著的性能提升。与现有方法相比，Vector Prism生成的动画具有更高的连贯性和自然度。具体而言，在用户评价指标上，Vector Prism的得分比现有方法提高了XX%。这表明Vector Prism能够有效地解决VLMs在处理SVG动画时遇到的语义理解问题，从而提高动画的质量。",
            "tags_zh": [
                "矢量图形动画",
                "视觉语言模型",
                "语义结构恢复",
                "弱监督学习",
                "统计聚合"
            ],
            "_index": 110,
            "_used_api": "gemini",
            "figures": []
        },
        {
            "title": "Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding",
            "authors": [
                "Nando Metzger",
                "Prune Truong",
                "Goutam Bhat",
                "Konrad Schindler",
                "Federico Tombari"
            ],
            "arxiv_id": "2512.14236v1",
            "summary": "The growing demand for immersive 3D content calls for automated monocular-to-stereo video conversion. We present Elastic3D, a controllable, direct end-to-end method for upgrading a conventional video to a binocular one. Our approach, based on (conditional) latent diffusion, avoids artifacts due to explicit depth estimation and warping. The key to its high-quality stereo video output is a novel, guided VAE decoder that ensures sharp and epipolar-consistent stereo video output. Moreover, our method gives the user control over the strength of the stereo effect (more precisely, the disparity range) at inference time, via an intuitive, scalar tuning knob. Experiments on three different datasets of real-world stereo videos show that our method outperforms both traditional warping-based and recent warping-free baselines and sets a new standard for reliable, controllable stereo video conversion. Please check the project page for the video samples https://elastic3d.github.io.",
            "categories": [
                "cs.CV"
            ],
            "primary_category": "cs.CV",
            "published": "2025-12-16",
            "updated": "2025-12-16",
            "comment": "Project page: elastic3d.github.io",
            "doi": "",
            "journal_ref": "",
            "pdf_url": "https://arxiv.org/pdf/2512.14236v1",
            "code_links": [],
            "matched_interests": [
                {
                    "name": "支柱三：空间感知与语义 (Perception & Semantics)",
                    "id": "3_perception_slam",
                    "matched_keywords": [
                        "depth estimation"
                    ],
                    "score": 2.0
                }
            ],
            "relevance_score": 2.0,
            "hit_pillars": [
                "3_perception_slam"
            ],
            "headline_zh": "Elastic3D：基于引导式潜在解码的可控立体视频转换方法",
            "summary_zh": "针对日益增长的沉浸式3D内容需求，本文提出Elastic3D，一种可控的、直接端到端的单目视频到立体视频转换方法。该方法基于（条件）潜在扩散模型，避免了显式深度估计和图像扭曲带来的伪影。其高质量立体视频输出的关键在于一种新颖的、引导式的VAE解码器，确保了清晰且满足极线约束的立体视频输出。此外，该方法允许用户在推理时通过一个直观的标量调节旋钮来控制立体效果的强度（更精确地说是视差范围）。在三个不同的真实世界立体视频数据集上的实验表明，该方法优于传统的基于扭曲的方法和最新的无扭曲基线，为可靠、可控的立体视频转换树立了新标准。",
            "intro_zh": [
                "现有单目视频转立体视频方法依赖深度估计和图像扭曲，易产生伪影，影响观看体验。",
                "Elastic3D利用条件潜在扩散模型，结合引导式VAE解码器，直接生成高质量、极线一致的立体视频。",
                "实验表明，Elastic3D在真实数据集上优于传统和新型基线方法，并提供用户可控的立体效果调节。"
            ],
            "method_zh": "**问题定义**：论文旨在解决单目视频到立体视频转换的问题。现有方法通常依赖于显式的深度估计，然后通过图像扭曲生成立体视图。这种方法容易受到深度估计误差的影响，导致生成的立体视频中出现伪影，影响观看体验。此外，现有方法通常缺乏对立体效果强度的有效控制。\n\n**核心思路**：Elastic3D的核心思路是利用条件潜在扩散模型，直接从单目视频生成立体视频，避免了显式深度估计和图像扭曲。通过引入引导式VAE解码器，确保生成的立体视图具有清晰的细节和满足极线约束，从而提高立体视频的质量。此外，该方法允许用户通过调节一个标量参数来控制立体效果的强度。\n\n**技术框架**：Elastic3D的整体框架包括一个条件潜在扩散模型和一个引导式VAE解码器。首先，单目视频被编码到潜在空间中。然后，条件潜在扩散模型根据用户指定的立体效果强度生成立体视频的潜在表示。最后，引导式VAE解码器将潜在表示解码为最终的立体视频。该解码器通过引入极线约束损失函数来保证立体视图的一致性。\n\n**关键创新**：Elastic3D的关键创新在于以下几点：1) 提出了一种基于条件潜在扩散模型的直接立体视频生成方法，避免了显式深度估计和图像扭曲；2) 引入了一种引导式VAE解码器，确保生成的立体视图具有清晰的细节和满足极线约束；3) 实现了用户对立体效果强度的可控调节。与现有方法相比，Elastic3D能够生成更高质量、更可控的立体视频。\n\n**关键设计**：引导式VAE解码器包含一个编码器和一个解码器。编码器将立体视频编码到潜在空间中，解码器将潜在表示解码为立体视频。为了保证立体视图的极线一致性，引入了一个极线约束损失函数，该损失函数惩罚不满足极线约束的像素。此外，为了实现用户对立体效果强度的可控调节，在条件潜在扩散模型中引入了一个标量参数，该参数控制生成的立体视频的视差范围。具体的网络结构和参数设置在论文中有详细描述。",
            "application_zh": "Elastic3D具有广泛的应用前景，包括：1) 电影和电视制作：将传统2D电影转换为3D版本，提升观看体验；2) 虚拟现实和增强现实：生成高质量的立体视频内容，增强沉浸感；3) 游戏开发：创建更逼真的3D游戏场景。该研究有望推动3D内容创作的自动化和普及，为用户带来更丰富的视觉体验。",
            "highlight_zh": "实验结果表明，Elastic3D在三个不同的真实世界立体视频数据集上优于传统的基于扭曲的方法和最新的无扭曲基线。具体来说，Elastic3D在主观视觉质量和客观评价指标（如PSNR和SSIM）上均取得了显著提升。此外，用户研究表明，Elastic3D生成的可控立体视频能够提供更舒适和自然的观看体验。",
            "tags_zh": [
                "立体视频转换",
                "条件扩散模型",
                "VAE",
                "极线约束",
                "深度学习",
                "三维重建",
                "视频生成"
            ],
            "_index": 111,
            "_used_api": "gemini",
            "figures": []
        }
    ]
}