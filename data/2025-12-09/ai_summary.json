{
    "papers": [
        {
            "title": "Astra: General Interactive World Model with Autoregressive Denoising",
            "authors": [
                "Yixuan Zhu",
                "Jiaqi Feng",
                "Wenzhao Zheng",
                "Yuan Gao",
                "Xin Tao",
                "Pengfei Wan",
                "Jie Zhou",
                "Jiwen Lu"
            ],
            "arxiv_id": "2512.08931v1",
            "summary": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an autoregressive denoising architecture and use temporal causal attention to aggregate past observations and support streaming outputs. We use a noise-augmented history memory to avoid over-reliance on past frames to balance responsiveness with temporal coherence. For precise action control, we introduce an action-aware adapter that directly injects action signals into the denoising process. We further develop a mixture of action experts that dynamically route heterogeneous action modalities, enhancing versatility across diverse real-world tasks such as exploration, manipulation, and camera control. Astra achieves interactive, consistent, and general long-term video prediction and supports various forms of interactions. Experiments across multiple datasets demonstrate the improvements of Astra in fidelity, long-range prediction, and action alignment over existing state-of-the-art world models.",
            "headline_zh": "提出Astra通用交互世界模型，通过自回归去噪架构实现多场景长时视频预测与精确动作控制。",
            "intro_zh": [
                "核心问题：现有世界模型在通用场景和多样化动作形式下的长时未来预测能力不足。",
                "方法要点：采用自回归去噪架构，结合时间因果注意力和噪声增强历史记忆，引入动作感知适配器和动作专家混合机制。",
                "实验或效果：在多个数据集上验证，Astra在保真度、长程预测和动作对齐方面优于现有先进模型。"
            ],
            "tags_zh": [
                "世界模型",
                "自回归去噪",
                "长时视频预测",
                "动作控制",
                "通用交互",
                "扩散变换器"
            ],
            "_index": 0
        },
        {
            "title": "Selfi: Self Improving Reconstruction Engine via 3D Geometric Feature Alignment",
            "authors": [
                "Youming Deng",
                "Songyou Peng",
                "Junyi Zhang",
                "Kathryn Heal",
                "Tiancheng Sun",
                "John Flynn",
                "Steve Marschner",
                "Lucy Chai"
            ],
            "arxiv_id": "2512.08930v1",
            "summary": "Novel View Synthesis (NVS) has traditionally relied on models with explicit 3D inductive biases combined with known camera parameters from Structure-from-Motion (SfM) beforehand. Recent vision foundation models like VGGT take an orthogonal approach -- 3D knowledge is gained implicitly through training data and loss objectives, enabling feed-forward prediction of both camera parameters and 3D representations directly from a set of uncalibrated images. While flexible, VGGT features lack explicit multi-view geometric consistency, and we find that improving such 3D feature consistency benefits both NVS and pose estimation tasks. We introduce Selfi, a self-improving 3D reconstruction pipeline via feature alignment, transforming a VGGT backbone into a high-fidelity 3D reconstruction engine by leveraging its own outputs as pseudo-ground-truth. Specifically, we train a lightweight feature adapter using a reprojection-based consistency loss, which distills VGGT outputs into a new geometrically-aligned feature space that captures spatial proximity in 3D. This enables state-of-the-art performance in both NVS and camera pose estimation, demonstrating that feature alignment is a highly beneficial step for downstream 3D reasoning.",
            "headline_zh": "提出Selfi通过特征对齐提升3D重建，改进VGGT的几何一致性以优化新视角合成和相机姿态估计。",
            "intro_zh": [
                "核心问题：VGGT等视觉基础模型缺乏显式多视角几何一致性，影响3D重建质量。",
                "方法要点：使用重投影一致性损失训练轻量特征适配器，将VGGT输出蒸馏到几何对齐特征空间。",
                "实验或效果：在NVS和相机姿态估计任务中实现最先进性能，验证特征对齐对下游3D推理的益处。"
            ],
            "tags_zh": [
                "新视角合成",
                "3D重建",
                "特征对齐",
                "相机姿态估计",
                "蒸馏训练",
                "几何一致性"
            ],
            "_index": 1
        },
        {
            "title": "Efficiently Reconstructing Dynamic Scenes One D4RT at a Time",
            "authors": [
                "Chuhan Zhang",
                "Guillaume Le Moing",
                "Skanda Koppula",
                "Ignacio Rocco",
                "Liliane Momeni",
                "Junyu Xie",
                "Shuyang Sun",
                "Rahul Sukthankar",
                "Joëlle K Barral",
                "Raia Hadsell",
                "Zoubin Ghahramani",
                "Andrew Zisserman",
                "Junlin Zhang",
                "Mehdi SM Sajjadi"
            ],
            "arxiv_id": "2512.08924v1",
            "summary": "Understanding and reconstructing the complex geometry and motion of dynamic scenes from video remains a formidable challenge in computer vision. This paper introduces D4RT, a simple yet powerful feedforward model designed to efficiently solve this task. D4RT utilizes a unified transformer architecture to jointly infer depth, spatio-temporal correspondence, and full camera parameters from a single video. Its core innovation is a novel querying mechanism that sidesteps the heavy computation of dense, per-frame decoding and the complexity of managing multiple, task-specific decoders. Our decoding interface allows the model to independently and flexibly probe the 3D position of any point in space and time. The result is a lightweight and highly scalable method that enables remarkably efficient training and inference. We demonstrate that our approach sets a new state of the art, outperforming previous methods across a wide spectrum of 4D reconstruction tasks. We refer to the project webpage for animated results: https://d4rt-paper.github.io/.",
            "headline_zh": "提出D4RT前馈模型，通过统一Transformer架构高效重建动态场景的4D几何与运动。",
            "intro_zh": [
                "核心问题：从视频中高效重建动态场景的复杂几何和运动仍具挑战。",
                "方法要点：采用统一Transformer架构，通过新颖查询机制联合推断深度、时空对应和相机参数。",
                "实验或效果：在多种4D重建任务中超越先前方法，实现轻量级、可扩展的高效训练与推理。"
            ],
            "tags_zh": [
                "动态场景重建",
                "4D重建",
                "Transformer架构",
                "深度估计",
                "相机参数估计",
                "时空对应"
            ],
            "_index": 2
        },
        {
            "title": "Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs",
            "authors": [
                "Angela van Sprang",
                "Laurens Samson",
                "Ana Lucic",
                "Erman Acar",
                "Sennay Ghebreab",
                "Yuki M. Asano"
            ],
            "arxiv_id": "2512.08923v1",
            "summary": "We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason over these different modalities. We evaluate 15 MLLMs and find that the degree of modality inconsistency varies substantially, even when accounting for problems with text recognition (OCR). Neither rendering text as image nor rendering an image as text solves the inconsistency. Even if OCR is correct, we find that visual characteristics (text colour and resolution, but not font) and the number of vision tokens have an impact on model performance. Finally, we find that our consistency score correlates with the modality gap between text and images, highlighting a mechanistic interpretation of cross-modal inconsistent MLLMs.",
            "headline_zh": "提出REST和REST+基准以评估多模态大语言模型的跨模态不一致性",
            "intro_zh": [
                "核心问题：MLLMs在图像、文本和混合模态中处理相同语义信息时存在推理不一致",
                "方法要点：构建包含三种模态的基准，评估15个MLLMs的跨模态一致性",
                "实验或效果：发现模态不一致程度差异大，视觉特征和视觉令牌数影响性能"
            ],
            "tags_zh": [
                "多模态大语言模型",
                "跨模态一致性",
                "基准评估",
                "模态间隙",
                "视觉特征影响",
                "文本识别"
            ],
            "_index": 3
        },
        {
            "title": "Unified Diffusion Transformer for High-fidelity Text-Aware Image Restoration",
            "authors": [
                "Jin Hyeon Kim",
                "Paul Hyunbin Cho",
                "Claire Kim",
                "Jaewon Min",
                "Jaeeun Lee",
                "Jihye Park",
                "Yeji Choi",
                "Seungryong Kim"
            ],
            "arxiv_id": "2512.08922v1",
            "summary": "Text-Aware Image Restoration (TAIR) aims to recover high- quality images from low-quality inputs containing degraded textual content. While diffusion models provide strong gen- erative priors for general image restoration, they often pro- duce text hallucinations in text-centric tasks due to the ab- sence of explicit linguistic knowledge. To address this, we propose UniT, a unified text restoration framework that in- tegrates a Diffusion Transformer (DiT), a Vision-Language Model (VLM), and a Text Spotting Module (TSM) in an it- erative fashion for high-fidelity text restoration. In UniT, the VLM extracts textual content from degraded images to provide explicit textual guidance. Simultaneously, the TSM, trained on diffusion features, generates intermedi- ate OCR predictions at each denoising step, enabling the VLM to iteratively refine its guidance during the denoising process. Finally, the DiT backbone, leveraging its strong representational power, exploit these cues to recover fine- grained textual content while effectively suppressing text hallucinations. Experiments on the SA-Text and Real-Text benchmarks demonstrate that UniT faithfully reconstructs degraded text, substantially reduces hallucinations, and achieves state-of-the-art end-to-end F1-score performance in TAIR task.",
            "headline_zh": "提出UniT统一框架，通过集成扩散Transformer、视觉语言模型和文本定位模块，解决文本感知图像恢复中的文本幻觉问题。",
            "intro_zh": [
                "核心问题：扩散模型在文本感知图像恢复中因缺乏显式语言知识，常产生文本幻觉。",
                "方法要点：结合VLM提取文本指导，TSM迭代优化OCR预测，DiT利用这些线索恢复精细文本并抑制幻觉。",
                "实验或效果：在SA-Text和Real-Text基准测试中，UniT显著减少幻觉，实现最先进的端到端F1分数性能。"
            ],
            "tags_zh": [
                "文本感知图像恢复",
                "扩散Transformer",
                "视觉语言模型",
                "文本定位模块",
                "文本幻觉抑制",
                "高保真文本恢复"
            ],
            "_index": 4
        },
        {
            "title": "OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer",
            "authors": [
                "Jessica Yin",
                "Haozhi Qi",
                "Youngsun Wi",
                "Sayantan Kundu",
                "Mike Lambeta",
                "William Yang",
                "Changhao Wang",
                "Tingfan Wu",
                "Jitendra Malik",
                "Tess Hellebrekers"
            ],
            "arxiv_id": "2512.08920v1",
            "summary": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, is capable of executing a challenging contact-rich manipulation task. By equipping both the human and the robot with the same glove, OSMO minimizes the visual and tactile embodiment gap, enabling the transfer of continuous shear and normal force feedback while avoiding the need for image inpainting or other vision-based force inference. On a real-world wiping task requiring sustained contact pressure, our tactile-aware policy achieves a 72% success rate, outperforming vision-only baselines by eliminating contact-related failure modes. We release complete hardware designs, firmware, and assembly instructions to support community adoption.",
            "headline_zh": "提出开源触觉手套OSMO，通过人类演示实现机器人接触丰富任务的技能迁移。",
            "intro_zh": [
                "问题：人类视频演示缺乏接触信号，限制机器人掌握接触丰富的操作任务。",
                "方法：OSMO手套配备12个三轴触觉传感器，兼容手部追踪，最小化视觉和触觉体现差距。",
                "效果：在真实擦拭任务中，仅基于人类演示训练的机器人策略成功率72%，优于纯视觉基线。"
            ],
            "tags_zh": [
                "触觉感知",
                "技能迁移",
                "开源硬件",
                "机器人操作",
                "人类演示"
            ],
            "_index": 5
        },
        {
            "title": "SAQ: Stabilizer-Aware Quantum Error Correction Decoder",
            "authors": [
                "David Zenati",
                "Eliya Nachmani"
            ],
            "arxiv_id": "2512.08914v1",
            "summary": "Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a unified framework combining transformer-based learning with constraint aware post-processing that achieves both near Maximum Likelihood (ML) accuracy and linear computational scalability with respect to the syndrome size. Our approach combines a dual-stream transformer architecture that processes syndromes and logical information with asymmetric attention patterns, and a novel differentiable logical loss that directly optimizes Logical Error Rates (LER) through smooth approximations over finite fields. SAQ-Decoder achieves near-optimal performance, with error thresholds of 10.99% (independent noise) and 18.6% (depolarizing noise) on toric codes that approach the ML bounds of 11.0% and 18.9% while outperforming existing neural and classical baselines in accuracy, complexity, and parameter efficiency. Our findings establish that learned decoders can simultaneously achieve competitive decoding accuracy and computational efficiency, addressing key requirements for practical fault-tolerant quantum computing systems.",
            "headline_zh": "提出SAQ-Decoder框架，结合Transformer学习与约束感知后处理，实现近最大似然精度和线性计算可扩展性，以解决量子纠错解码的精度-效率权衡问题。",
            "intro_zh": [
                "量子纠错解码面临精度与效率的权衡，现有方法如MWPM和神经网络解码器在性能或复杂度上存在不足。",
                "SAQ-Decoder采用双流Transformer架构处理综合征和逻辑信息，结合可微逻辑损失直接优化逻辑错误率。",
                "在toric码上实现近最优性能，独立噪声和去极化噪声下的错误阈值接近最大似然界限，优于现有基线。"
            ],
            "tags_zh": [
                "量子纠错解码",
                "Transformer架构",
                "可微逻辑损失",
                "线性计算可扩展性",
                "toric码",
                "最大似然精度"
            ],
            "_index": 6
        },
        {
            "title": "LiDAS: Lighting-driven Dynamic Active Sensing for Nighttime Perception",
            "authors": [
                "Simon de Moreau",
                "Andrei Bursuc",
                "Hafid El-Idrissi",
                "Fabien Moutarde"
            ],
            "arxiv_id": "2512.08912v1",
            "summary": "Nighttime environments pose significant challenges for camera-based perception, as existing methods passively rely on the scene lighting. We introduce Lighting-driven Dynamic Active Sensing (LiDAS), a closed-loop active illumination system that combines off-the-shelf visual perception models with high-definition headlights. Rather than uniformly brightening the scene, LiDAS dynamically predicts an optimal illumination field that maximizes downstream perception performance, i.e., decreasing light on empty areas to reallocate it on object regions. LiDAS enables zero-shot nighttime generalization of daytime-trained models through adaptive illumination control. Trained on synthetic data and deployed zero-shot in real-world closed-loop driving scenarios, LiDAS enables +18.7% mAP50 and +5.0% mIoU over standard low-beam at equal power. It maintains performances while reducing energy use by 40%. LiDAS complements domain-generalization methods, further strengthening robustness without retraining. By turning readily available headlights into active vision actuators, LiDAS offers a cost-effective solution to robust nighttime perception.",
            "headline_zh": "提出LiDAS系统，通过动态主动照明优化夜间感知性能",
            "intro_zh": [
                "核心问题：夜间环境光照不足，现有相机感知方法被动依赖场景照明，性能受限。",
                "方法要点：结合现成视觉模型与高清头灯，闭环预测最优照明场，动态重分配光线至目标区域。",
                "实验或效果：在真实闭环驾驶场景中零样本部署，相比标准近光灯提升mAP50 18.7%和mIoU 5.0%，节能40%。"
            ],
            "tags_zh": [
                "夜间感知",
                "主动照明",
                "闭环控制",
                "零样本泛化",
                "节能优化"
            ],
            "_index": 7
        },
        {
            "title": "Self-Evolving 3D Scene Generation from a Single Image",
            "authors": [
                "Kaizhi Zheng",
                "Yue Fan",
                "Jing Gu",
                "Zishuo Xu",
                "Xuehai He",
                "Xin Eric Wang"
            ],
            "arxiv_id": "2512.08905v1",
            "summary": "Generating high-quality, textured 3D scenes from a single image remains a fundamental challenge in vision and graphics. Recent image-to-3D generators recover reasonable geometry from single views, but their object-centric training limits generalization to complex, large-scale scenes with faithful structure and texture. We present EvoScene, a self-evolving, training-free framework that progressively reconstructs complete 3D scenes from single images. The key idea is combining the complementary strengths of existing models: geometric reasoning from 3D generation models and visual knowledge from video generation models. Through three iterative stages--Spatial Prior Initialization, Visual-guided 3D Scene Mesh Generation, and Spatial-guided Novel View Generation--EvoScene alternates between 2D and 3D domains, gradually improving both structure and appearance. Experiments on diverse scenes demonstrate that EvoScene achieves superior geometric stability, view-consistent textures, and unseen-region completion compared to strong baselines, producing ready-to-use 3D meshes for practical applications.",
            "headline_zh": "提出EvoScene框架，通过自演化方法从单图像生成高质量3D场景",
            "intro_zh": [
                "核心问题：单图像生成3D场景存在几何不稳定和纹理不一致的挑战",
                "方法要点：结合3D生成模型的几何推理和视频生成模型的视觉知识，迭代优化",
                "实验或效果：在多样场景中实现几何稳定、视图一致纹理和未见过区域补全"
            ],
            "tags_zh": [
                "单图像3D生成",
                "自演化框架",
                "几何推理",
                "视觉知识",
                "迭代优化",
                "3D场景重建"
            ],
            "_index": 8
        },
        {
            "title": "UniLayDiff: A Unified Diffusion Transformer for Content-Aware Layout Generation",
            "authors": [
                "Zeyang Liu",
                "Le Wang",
                "Sanping Zhou",
                "Yuxuan Wu",
                "Xiaolong Sun",
                "Gang Hua",
                "Haoxiang Li"
            ],
            "arxiv_id": "2512.08897v1",
            "summary": "Content-aware layout generation is a critical task in graphic design automation, focused on creating visually appealing arrangements of elements that seamlessly blend with a given background image. The variety of real-world applications makes it highly challenging to develop a single model capable of unifying the diverse range of input-constrained generation sub-tasks, such as those conditioned by element types, sizes, or their relationships. Current methods either address only a subset of these tasks or necessitate separate model parameters for different conditions, failing to offer a truly unified solution. In this paper, we propose UniLayDiff: a Unified Diffusion Transformer, that for the first time, addresses various content-aware layout generation tasks with a single, end-to-end trainable model. Specifically, we treat layout constraints as a distinct modality and employ Multi-Modal Diffusion Transformer framework to capture the complex interplay between the background image, layout elements, and diverse constraints. Moreover, we integrate relation constraints through fine-tuning the model with LoRA after pretraining the model on other tasks. Such a schema not only achieves unified conditional generation but also enhances overall layout quality. Extensive experiments demonstrate that UniLayDiff achieves state-of-the-art performance across from unconditional to various conditional generation tasks and, to the best of our knowledge, is the first model to unify the full range of content-aware layout generation tasks.",
            "headline_zh": "提出UniLayDiff统一扩散Transformer，以单模型解决内容感知布局生成的多任务挑战。",
            "intro_zh": [
                "核心问题：现有方法无法统一处理元素类型、尺寸或关系等多样约束的布局生成子任务。",
                "方法要点：将布局约束作为独立模态，采用多模态扩散Transformer框架捕获背景、元素与约束的交互。",
                "实验或效果：在无条件到多种条件生成任务中达到最先进性能，首次统一全范围内容感知布局生成。"
            ],
            "tags_zh": [
                "内容感知布局生成",
                "扩散Transformer",
                "多模态学习",
                "统一模型",
                "条件生成"
            ],
            "_index": 9
        },
        {
            "title": "Open Polymer Challenge: Post-Competition Report",
            "authors": [
                "Gang Liu",
                "Sobin Alosious",
                "Subhamoy Mahajan",
                "Eric Inae",
                "Yihan Zhu",
                "Yuhan Liu",
                "Renzheng Zhang",
                "Jiaxin Xu",
                "Addison Howard",
                "Ying Li",
                "Tengfei Luo",
                "Meng Jiang"
            ],
            "arxiv_id": "2512.08896v1",
            "summary": "Machine learning (ML) offers a powerful path toward discovering sustainable polymer materials, but progress has been limited by the lack of large, high-quality, and openly accessible polymer datasets. The Open Polymer Challenge (OPC) addresses this gap by releasing the first community-developed benchmark for polymer informatics, featuring a dataset with 10K polymers and 5 properties: thermal conductivity, radius of gyration, density, fractional free volume, and glass transition temperature. The challenge centers on multi-task polymer property prediction, a core step in virtual screening pipelines for materials discovery. Participants developed models under realistic constraints that include small data, label imbalance, and heterogeneous simulation sources, using techniques such as feature-based augmentation, transfer learning, self-supervised pretraining, and targeted ensemble strategies. The competition also revealed important lessons about data preparation, distribution shifts, and cross-group simulation consistency, informing best practices for future large-scale polymer datasets. The resulting models, analysis, and released data create a new foundation for molecular AI in polymer science and are expected to accelerate the development of sustainable and energy-efficient materials. Along with the competition, we release the test dataset at https://www.kaggle.com/datasets/alexliu99/neurips-open-polymer-prediction-2025-test-data. We also release the data generation pipeline at https://github.com/sobinalosious/ADEPT, which simulates more than 25 properties, including thermal conductivity, radius of gyration, and density.",
            "headline_zh": "发布首个社区基准Open Polymer Challenge，通过多任务预测加速可持续聚合物材料发现",
            "intro_zh": [
                "核心问题：聚合物信息学缺乏大规模高质量开放数据集，限制机器学习在材料发现中的应用",
                "方法要点：构建包含10K聚合物和5种属性的数据集，采用特征增强、迁移学习等技术应对小数据和标签不平衡",
                "实验或效果：竞赛揭示数据准备、分布偏移等教训，为未来大规模聚合物数据集提供最佳实践"
            ],
            "tags_zh": [
                "聚合物信息学",
                "多任务预测",
                "数据集基准",
                "材料发现",
                "机器学习应用"
            ],
            "_index": 10
        },
        {
            "title": "Unsupervised Learning of Density Estimates with Topological Optimization",
            "authors": [
                "Suina Tanweer",
                "Firas A. Khasawneh"
            ],
            "arxiv_id": "2512.08895v1",
            "summary": "Kernel density estimation is a key component of a wide variety of algorithms in machine learning, Bayesian inference, stochastic dynamics and signal processing. However, the unsupervised density estimation technique requires tuning a crucial hyperparameter: the kernel bandwidth. The choice of bandwidth is critical as it controls the bias-variance trade-off by over- or under-smoothing the topological features. Topological data analysis provides methods to mathematically quantify topological characteristics, such as connected components, loops, voids et cetera, even in high dimensions where visualization of density estimates is impossible. In this paper, we propose an unsupervised learning approach using a topology-based loss function for the automated and unsupervised selection of the optimal bandwidth and benchmark it against classical techniques -- demonstrating its potential across different dimensions.",
            "headline_zh": "提出基于拓扑优化的无监督核密度估计方法，用于自动选择最优带宽",
            "intro_zh": [
                "核心问题：核密度估计中带宽超参数的无监督选择，影响拓扑特征的平滑度",
                "方法要点：使用拓扑数据分析的损失函数，自动化优化带宽，无需人工调参",
                "实验或效果：在不同维度上基准测试，展示其优于经典技术的潜力"
            ],
            "tags_zh": [
                "无监督学习",
                "核密度估计",
                "拓扑数据优化",
                "带宽选择",
                "高维数据分析"
            ],
            "_index": 11
        },
        {
            "title": "Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training",
            "authors": [
                "Jakub Krajewski",
                "Amitis Shidani",
                "Dan Busbridge",
                "Sam Wiseman",
                "Jason Ramapuram"
            ],
            "arxiv_id": "2512.08894v1",
            "summary": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, which is prone to compounding errors. Furthermore, we introduce functional forms that predict accuracy across token-to-parameter ratios and account for inference compute under repeated sampling. We validate our findings on models with up to 17B parameters trained on up to 350B tokens across two dataset mixtures. To support reproducibility and encourage future research, we release the complete set of pretraining losses and downstream evaluation results.",
            "headline_zh": "提出直接框架以建模大语言模型训练预算与下游任务性能的缩放关系",
            "intro_zh": [
                "核心问题：传统缩放定律依赖预训练损失等代理指标，预测下游任务性能不可靠",
                "方法要点：基于固定token-参数比，用幂律直接建模下游任务准确率的对数缩放",
                "实验或效果：验证模型达17B参数和350B tokens，直接方法外推优于两阶段方法，减少误差"
            ],
            "tags_zh": [
                "大语言模型缩放定律",
                "下游任务性能预测",
                "幂律建模",
                "训练预算优化",
                "基准评估"
            ],
            "_index": 12
        },
        {
            "title": "Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders",
            "authors": [
                "Guangzhi Xiong",
                "Zhenghao He",
                "Bohan Liu",
                "Sanchit Sinha",
                "Aidong Zhang"
            ],
            "arxiv_id": "2512.08892v1",
            "summary": "Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.",
            "headline_zh": "提出RAGLens，基于稀疏自编码器检测检索增强生成中的不忠实输出。",
            "intro_zh": [
                "核心问题：检索增强生成存在不忠实输出，现有检测方法依赖大量标注数据或高推理成本。",
                "方法要点：利用稀疏自编码器解耦内部激活，通过信息特征选择和加性建模构建轻量级检测器。",
                "实验或效果：RAGLens检测性能优于现有方法，提供可解释理由，并揭示幻觉信号分布新见解。"
            ],
            "tags_zh": [
                "检索增强生成",
                "稀疏自编码器",
                "幻觉检测",
                "可解释性",
                "轻量级检测器"
            ],
            "_index": 13
        },
        {
            "title": "No Labels, No Problem: Training Visual Reasoners with Multimodal Verifiers",
            "authors": [
                "Damiano Marsili",
                "Georgia Gkioxari"
            ],
            "arxiv_id": "2512.08889v1",
            "summary": "Visual reasoning is challenging, requiring both precise object grounding and understanding complex spatial relationships. Existing methods fall into two camps: language-only chain-of-thought approaches, which demand large-scale (image, query, answer) supervision, and program-synthesis approaches which use pre-trained models and avoid training, but suffer from flawed logic and erroneous grounding. We propose an annotation-free training framework that improves both reasoning and grounding. Our framework uses AI-powered verifiers: an LLM verifier refines LLM reasoning via reinforcement learning, while a VLM verifier strengthens visual grounding through automated hard-negative mining, eliminating the need for ground truth labels. This design combines the strengths of modern AI systems: advanced language-only reasoning models for decomposing spatial queries into simpler subtasks, and strong vision specialist models improved via performant VLM critics. We evaluate our approach across diverse spatial reasoning tasks, and show that our method improves visual reasoning and surpasses open-source and proprietary models, while with our improved visual grounding model we further outperform recent text-only visual reasoning methods. Project webpage: https://glab-caltech.github.io/valor/",
            "headline_zh": "提出无标注训练框架，结合多模态验证器提升视觉推理与定位能力",
            "intro_zh": [
                "视觉推理需精确对象定位与复杂空间关系理解，现有方法依赖大规模标注或存在逻辑错误",
                "框架使用LLM验证器通过强化学习优化推理，VLM验证器通过自动硬负样本挖掘增强视觉定位",
                "在多样空间推理任务中评估，方法超越开源与专有模型，改进定位模型优于纯文本方法"
            ],
            "tags_zh": [
                "视觉推理",
                "无标注训练",
                "多模态验证器",
                "强化学习",
                "硬负样本挖掘",
                "空间关系理解"
            ],
            "_index": 14
        },
        {
            "title": "Accelerated Rotation-Invariant Convolution for UAV Image Segmentation",
            "authors": [
                "Manduhu Manduhu",
                "Alexander Dow",
                "Gerard Dooly",
                "James Riordan"
            ],
            "arxiv_id": "2512.08888v1",
            "summary": "Rotation invariance is essential for precise, object-level segmentation in UAV aerial imagery, where targets can have arbitrary orientations and exhibit fine-scale details. Conventional segmentation architectures like U-Net rely on convolution operators that are not rotation-invariant, leading to degraded segmentation accuracy across varying viewpoints. Rotation invariance can be achieved by expanding the filter bank across multiple orientations; however, this will significantly increase computational cost and memory traffic. In this paper, we introduce a GPU-optimized rotation-invariant convolution framework that eliminates the traditional data-lowering (im2col) step required for matrix-multiplication-based convolution. By exploiting structured data sharing among symmetrically rotated filters, our method achieves multi-orientation convolution with greatly reduced memory traffic and computational redundancy. We further generalize the approach to accelerate convolution with arbitrary (non-symmetric) rotation angles.\n  Across extensive benchmarks, the proposed convolution achieves 20--55% faster training and 15--45% lower energy consumption than CUDNN, while maintaining accuracy comparable to state-of-the-art rotation-invariant methods. In the eight-orientation setting, our approach achieves up to 45% speedup and 41% energy savings on 256\\(\\times\\)256 inputs, and 32% speedup and 23% lower energy usage on 1024\\(\\times\\)1024 inputs. Integrated into a U-Net segmentation model, the framework yields up to 6% improvement in accuracy over the non-rotation-aware baseline. These results demonstrate that the proposed method provides an effective and highly efficient alternative to existing rotation-invariant CNN frameworks.",
            "headline_zh": "提出GPU优化的旋转不变卷积框架，以高效处理无人机图像分割中的任意方向目标。",
            "intro_zh": [
                "核心问题：传统卷积在无人机图像分割中缺乏旋转不变性，导致精度下降且计算成本高。",
                "方法要点：通过结构化数据共享消除im2col步骤，减少内存流量和计算冗余，支持多方向和任意角度卷积。",
                "实验或效果：相比CUDNN，训练速度提升20-55%，能耗降低15-45%，在U-Net中精度提升达6%。"
            ],
            "tags_zh": [
                "旋转不变卷积",
                "无人机图像分割",
                "GPU优化",
                "计算效率",
                "内存优化"
            ],
            "_index": 15
        },
        {
            "title": "Explainable Anomaly Detection for Industrial IoT Data Streams",
            "authors": [
                "Ana Rita Paupério",
                "Diogo Risca",
                "Afonso Lourenço",
                "Goreti Marreiros",
                "Ricardo Martins"
            ],
            "arxiv_id": "2512.08885v1",
            "summary": "Industrial maintenance is being transformed by the Internet of Things and edge computing, generating continuous data streams that demand real-time, adaptive decision-making under limited computational resources. While data stream mining (DSM) addresses this challenge, most methods assume fully supervised settings, yet in practice, ground-truth labels are often delayed or unavailable. This paper presents a collaborative DSM framework that integrates unsupervised anomaly detection with interactive, human-in-the-loop learning to support maintenance decisions. We employ an online Isolation Forest and enhance interpretability using incremental Partial Dependence Plots and a feature importance score, derived from deviations of Individual Conditional Expectation curves from a fading average, enabling users to dynamically reassess feature relevance and adjust anomaly thresholds. We describe the real-time implementation and provide initial results for fault detection in a Jacquard loom unit. Ongoing work targets continuous monitoring to predict and explain imminent bearing failures.",
            "headline_zh": "提出协作数据流挖掘框架，集成无监督异常检测与交互式人机学习以支持工业物联网维护决策。",
            "intro_zh": [
                "核心问题：工业物联网数据流中，真实标签常延迟或缺失，需实时自适应决策。",
                "方法要点：使用在线隔离森林进行异常检测，增强可解释性通过增量部分依赖图和特征重要性评分。",
                "实验或效果：在提花织机单元进行故障检测，提供初步结果，目标持续监测预测轴承故障。"
            ],
            "tags_zh": [
                "工业物联网",
                "数据流挖掘",
                "异常检测",
                "可解释性",
                "人机交互学习",
                "在线隔离森林"
            ],
            "_index": 16
        },
        {
            "title": "Decentralized Trust for Space AI: Blockchain-Based Federated Learning Across Multi-Vendor LEO Satellite Networks",
            "authors": [
                "Mohamed Elmahallawy",
                "Asma Jodeiri Akbarfam"
            ],
            "arxiv_id": "2512.08882v1",
            "summary": "The rise of space AI is reshaping government and industry through applications such as disaster detection, border surveillance, and climate monitoring, powered by massive data from commercial and governmental low Earth orbit (LEO) satellites. Federated satellite learning (FSL) enables joint model training without sharing raw data, but suffers from slow convergence due to intermittent connectivity and introduces critical trust challenges--where biased or falsified updates can arise across satellite constellations, including those injected through cyberattacks on inter-satellite or satellite-ground communication links. We propose OrbitChain, a blockchain-backed framework that empowers trustworthy multi-vendor collaboration in LEO networks. OrbitChain (i) offloads consensus to high-altitude platforms (HAPs) with greater computational capacity, (ii) ensures transparent, auditable provenance of model updates from different orbits owned by different vendors, and (iii) prevents manipulated or incomplete contributions from affecting global FSL model aggregation. Extensive simulations show that OrbitChain reduces computational and communication overhead while improving privacy, security, and global model accuracy. Its permissioned proof-of-authority ledger finalizes over 1000 blocks with sub-second latency (0.16,s, 0.26,s, 0.35,s for 1-of-5, 3-of-5, and 5-of-5 quorums). Moreover, OrbitChain reduces convergence time by up to 30 hours on real satellite datasets compared to single-vendor, demonstrating its effectiveness for real-time, multi-vendor learning. Our code is available at https://github.com/wsu-cyber-security-lab-ai/OrbitChain.git",
            "headline_zh": "提出OrbitChain框架，通过区块链增强多供应商LEO卫星网络中的联邦学习信任与效率",
            "intro_zh": [
                "核心问题：联邦卫星学习面临间歇连接导致收敛慢，以及跨星座更新可能被篡改的信任挑战",
                "方法要点：利用高空平台卸载共识，确保模型更新可审计，防止恶意贡献影响聚合",
                "实验或效果：仿真显示降低开销，提升隐私安全与模型精度，收敛时间减少达30小时"
            ],
            "tags_zh": [
                "联邦学习",
                "区块链",
                "低地球轨道卫星",
                "信任机制",
                "多供应商协作",
                "高空平台"
            ],
            "_index": 17
        },
        {
            "title": "SATGround: A Spatially-Aware Approach for Visual Grounding in Remote Sensing",
            "authors": [
                "Aysim Toker",
                "Andreea-Maria Oncescu",
                "Roy Miles",
                "Ismail Elezi",
                "Jiankang Deng"
            ],
            "arxiv_id": "2512.08881v1",
            "summary": "Vision-language models (VLMs) are emerging as powerful generalist tools for remote sensing, capable of integrating information across diverse tasks and enabling flexible, instruction-based interactions via a chat interface. In this work, we enhance VLM-based visual grounding in satellite imagery by proposing a novel structured localization mechanism. Our approach involves finetuning a pretrained VLM on a diverse set of instruction-following tasks, while interfacing a dedicated grounding module through specialized control tokens for localization. This method facilitates joint reasoning over both language and spatial information, significantly enhancing the model's ability to precisely localize objects in complex satellite scenes. We evaluate our framework on several remote sensing benchmarks, consistently improving the state-of-the-art, including a 24.8% relative improvement over previous methods on visual grounding. Our results highlight the benefits of integrating structured spatial reasoning into VLMs, paving the way for more reliable real-world satellite data analysis.",
            "headline_zh": "提出SATGround方法，通过结构化定位机制增强遥感图像中的视觉定位能力。",
            "intro_zh": [
                "核心问题：遥感图像中视觉语言模型的视觉定位精度不足，需提升复杂场景下的对象定位能力。",
                "方法要点：微调预训练视觉语言模型，结合专用定位模块和特殊控制令牌，实现语言与空间信息的联合推理。",
                "实验或效果：在多个遥感基准测试中显著提升性能，视觉定位任务相对改进24.8%，优于现有方法。"
            ],
            "tags_zh": [
                "视觉语言模型",
                "遥感图像",
                "视觉定位",
                "结构化定位",
                "控制令牌",
                "联合推理"
            ],
            "_index": 18
        },
        {
            "title": "DAO-GP Drift Aware Online Non-Linear Regression Gaussian-Process",
            "authors": [
                "Mohammad Abu-Shaira",
                "Ajita Rattani",
                "Weishi Shi"
            ],
            "arxiv_id": "2512.08879v1",
            "summary": "Real-world datasets often exhibit temporal dynamics characterized by evolving data distributions. Disregarding this phenomenon, commonly referred to as concept drift, can significantly diminish a model's predictive accuracy. Furthermore, the presence of hyperparameters in online models exacerbates this issue. These parameters are typically fixed and cannot be dynamically adjusted by the user in response to the evolving data distribution. Gaussian Process (GP) models offer powerful non-parametric regression capabilities with uncertainty quantification, making them ideal for modeling complex data relationships in an online setting. However, conventional online GP methods face several critical limitations, including a lack of drift-awareness, reliance on fixed hyperparameters, vulnerability to data snooping, absence of a principled decay mechanism, and memory inefficiencies. In response, we propose DAO-GP (Drift-Aware Online Gaussian Process), a novel, fully adaptive, hyperparameter-free, decayed, and sparse non-linear regression model. DAO-GP features a built-in drift detection and adaptation mechanism that dynamically adjusts model behavior based on the severity of drift. Extensive empirical evaluations confirm DAO-GP's robustness across stationary conditions, diverse drift types (abrupt, incremental, gradual), and varied data characteristics. Analyses demonstrate its dynamic adaptation, efficient in-memory and decay-based management, and evolving inducing points. Compared with state-of-the-art parametric and non-parametric models, DAO-GP consistently achieves superior or competitive performance, establishing it as a drift-resilient solution for online non-linear regression.",
            "headline_zh": "提出DAO-GP以解决在线高斯过程回归中的概念漂移和超参数固定问题",
            "intro_zh": [
                "核心问题：在线高斯过程模型缺乏漂移感知、依赖固定超参数，导致预测精度下降",
                "方法要点：引入内置漂移检测与适应机制，动态调整模型行为，实现超参数自由和稀疏化",
                "实验或效果：在多种漂移类型和数据特性下表现稳健，性能优于或媲美现有先进模型"
            ],
            "tags_zh": [
                "在线学习",
                "高斯过程回归",
                "概念漂移检测",
                "非参数模型",
                "自适应算法"
            ],
            "_index": 19
        },
        {
            "title": "IPPO Learns the Game, Not the Team: A Study on Generalization in Heterogeneous Agent Teams",
            "authors": [
                "Ryan LeRoy",
                "Jack Kolb"
            ],
            "arxiv_id": "2512.08877v1",
            "summary": "Multi-Agent Reinforcement Learning (MARL) is commonly deployed in settings where agents are trained via self-play with homogeneous teammates, often using parameter sharing and a single policy architecture. This opens the question: to what extent do self-play PPO agents learn general coordination strategies grounded in the underlying game, compared to overfitting to their training partners' behaviors? This paper investigates the question using the Heterogeneous Multi-Agent Challenge (HeMAC) environment, which features distinct Observer and Drone agents with complementary capabilities. We introduce Rotating Policy Training (RPT), an approach that rotates heterogeneous teammate policies of different learning algorithms during training, to expose the agent to a broader range of partner strategies. When playing alongside a withheld teammate policy (DDQN), we find that RPT achieves similar performance to a standard self-play baseline, IPPO, where all agents were trained sharing a single PPO policy. This result indicates that in this heterogeneous multi-agent setting, the IPPO baseline generalizes to novel teammate algorithms despite not experiencing teammate diversity during training. This shows that a simple IPPO baseline may possess the level of generalization to novel teammates that a diverse training regimen was designed to achieve.",
            "headline_zh": "提出旋转策略训练以研究异构多智能体团队中自学习PPO的泛化能力",
            "intro_zh": [
                "核心问题：自学习PPO智能体是否学习基于游戏的通用协调策略，而非过拟合训练伙伴行为",
                "方法要点：引入旋转策略训练，在训练中轮换异构队友策略以暴露更广伙伴策略范围",
                "实验或效果：在HeMAC环境中，IPPO基线泛化至新队友算法，性能与RPT相似"
            ],
            "tags_zh": [
                "多智能体强化学习",
                "异构智能体",
                "泛化能力",
                "自学习",
                "旋转策略训练",
                "PPO算法"
            ],
            "_index": 20
        },
        {
            "title": "When Tables Leak: Attacking String Memorization in LLM-Based Tabular Data Generation",
            "authors": [
                "Joshua Ward",
                "Bochao Gu",
                "Chi-Hua Wang",
                "Guang Cheng"
            ],
            "arxiv_id": "2512.08875v1",
            "summary": "Large Language Models (LLMs) have recently demonstrated remarkable performance in generating high-quality tabular synthetic data. In practice, two primary approaches have emerged for adapting LLMs to tabular data generation: (i) fine-tuning smaller models directly on tabular datasets, and (ii) prompting larger models with examples provided in context. In this work, we show that popular implementations from both regimes exhibit a tendency to compromise privacy by reproducing memorized patterns of numeric digits from their training data. To systematically analyze this risk, we introduce a simple No-box Membership Inference Attack (MIA) called LevAtt that assumes adversarial access to only the generated synthetic data and targets the string sequences of numeric digits in synthetic observations. Using this approach, our attack exposes substantial privacy leakage across a wide range of models and datasets, and in some cases, is even a perfect membership classifier on state-of-the-art models. Our findings highlight a unique privacy vulnerability of LLM-based synthetic data generation and the need for effective defenses. To this end, we propose two methods, including a novel sampling strategy that strategically perturbs digits during generation. Our evaluation demonstrates that this approach can defeat these attacks with minimal loss of fidelity and utility of the synthetic data.",
            "headline_zh": "提出LevAtt攻击揭示LLM表格生成中数字字符串记忆泄露隐私风险，并提出防御方法。",
            "intro_zh": [
                "核心问题：LLM表格生成方法易泄露训练数据中数字字符串记忆，导致隐私风险。",
                "方法要点：设计LevAtt无盒成员推理攻击，仅基于生成数据分析数字序列泄露。",
                "实验或效果：攻击在多种模型和数据集上暴露显著泄露，并提出扰动采样防御降低风险。"
            ],
            "tags_zh": [
                "表格数据生成",
                "隐私泄露",
                "成员推理攻击",
                "大语言模型",
                "数字字符串记忆"
            ],
            "_index": 21
        },
        {
            "title": "Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning",
            "authors": [
                "Jing Jie Tan",
                "Anissa Mokraoui",
                "Ban-Hoe Kwan",
                "Danny Wee-Kiat Ng",
                "Yan-Chai Hum"
            ],
            "arxiv_id": "2512.08873v1",
            "summary": "Image captioning is essential in many fields including assisting visually impaired individuals, improving content management systems, and enhancing human-computer interaction. However, a recent challenge in this domain is dealing with low-resolution image (LRI). While performance can be improved by using larger models like transformers for encoding, these models are typically heavyweight, demanding significant computational resources and memory, leading to challenges in retraining. To address this, the proposed SOLI (Siamese-Driven Optimization for Low-Resolution Image Latent Embedding in Image Captioning) approach presents a solution specifically designed for lightweight, low-resolution images captioning. It employs a Siamese network architecture to optimize latent embeddings, enhancing the efficiency and accuracy of the image-to-text translation process. By focusing on a dual-pathway neural network structure, SOLI minimizes computational overhead without sacrificing performance, making it an ideal choice for training on resource-constrained scenarios.",
            "headline_zh": "提出SOLI方法以解决轻量级低分辨率图像描述中的计算效率问题",
            "intro_zh": [
                "核心问题：低分辨率图像描述任务中，大型模型计算资源需求高，重训练困难。",
                "方法要点：采用孪生网络架构优化潜在嵌入，通过双路径结构减少计算开销。",
                "实验或效果：在资源受限场景下，保持性能的同时提升效率和准确性。"
            ],
            "tags_zh": [
                "低分辨率图像描述",
                "孪生网络",
                "潜在嵌入优化",
                "轻量级模型",
                "计算效率"
            ],
            "_index": 22
        },
        {
            "title": "Fed-SE: Federated Self-Evolution for Privacy-Constrained Multi-Environment LLM Agents",
            "authors": [
                "Xiang Chen",
                "Yuling Shi",
                "Qizhen Lan",
                "Yuchao Qiu",
                "Xiaodong Gu"
            ],
            "arxiv_id": "2512.08870v1",
            "summary": "LLM agents are widely deployed in complex interactive tasks, yet privacy constraints often preclude centralized optimization and co-evolution across dynamic environments. While Federated Learning (FL) has proven effective on static datasets, its extension to the open-ended self-evolution of agents remains underexplored. Directly applying standard FL is challenging: heterogeneous tasks and sparse, trajectory-level rewards introduce severe gradient conflicts, destabilizing the global optimization process. To bridge this gap, we propose Fed-SE, a Federated Self-Evolution framework for LLM agents. Fed-SE establishes a local evolution-global aggregation paradigm. Locally, agents employ parameter-efficient fine-tuning on filtered, high-return trajectories to achieve stable gradient updates. Globally, Fed-SE aggregates updates within a low-rank subspace that disentangles environment-specific dynamics, effectively reducing negative transfer across clients. Experiments across five heterogeneous environments demonstrate that Fed-SE improves average task success rates by approximately 18% over federated baselines, validating its effectiveness in robust cross-environment knowledge transfer in privacy-constrained deployments.",
            "headline_zh": "提出Fed-SE联邦自进化框架，以解决隐私约束下多环境LLM代理的梯度冲突与负迁移问题。",
            "intro_zh": [
                "核心问题：隐私限制下，LLM代理在多环境中的异质任务和稀疏奖励导致梯度冲突，阻碍联邦优化。",
                "方法要点：本地基于高回报轨迹进行参数高效微调，全局在低秩子空间聚合更新以解耦环境动态。",
                "实验效果：在五个异质环境中，Fed-SE相比联邦基线平均任务成功率提升约18%。"
            ],
            "tags_zh": [
                "联邦学习",
                "大语言模型代理",
                "自进化",
                "隐私保护",
                "梯度冲突",
                "负迁移"
            ],
            "_index": 23
        },
        {
            "title": "Differentially Private Synthetic Data Generation Using Context-Aware GANs",
            "authors": [
                "Anantaa Kotal",
                "Anupam Joshi"
            ],
            "arxiv_id": "2512.08869v1",
            "summary": "The widespread use of big data across sectors has raised major privacy concerns, especially when sensitive information is shared or analyzed. Regulations such as GDPR and HIPAA impose strict controls on data handling, making it difficult to balance the need for insights with privacy requirements. Synthetic data offers a promising solution by creating artificial datasets that reflect real patterns without exposing sensitive information. However, traditional synthetic data methods often fail to capture complex, implicit rules that link different elements of the data and are essential in domains like healthcare. They may reproduce explicit patterns but overlook domain-specific constraints that are not directly stated yet crucial for realism and utility. For example, prescription guidelines that restrict certain medications for specific conditions or prevent harmful drug interactions may not appear explicitly in the original data. Synthetic data generated without these implicit rules can lead to medically inappropriate or unrealistic profiles. To address this gap, we propose ContextGAN, a Context-Aware Differentially Private Generative Adversarial Network that integrates domain-specific rules through a constraint matrix encoding both explicit and implicit knowledge. The constraint-aware discriminator evaluates synthetic data against these rules to ensure adherence to domain constraints, while differential privacy protects sensitive details from the original data. We validate ContextGAN across healthcare, security, and finance, showing that it produces high-quality synthetic data that respects domain rules and preserves privacy. Our results demonstrate that ContextGAN improves realism and utility by enforcing domain constraints, making it suitable for applications that require compliance with both explicit patterns and implicit rules under strict privacy guarantees.",
            "headline_zh": "提出ContextGAN以解决隐私保护下合成数据忽略领域隐式规则的问题",
            "intro_zh": [
                "核心问题：传统合成数据方法难以捕捉领域隐式规则，导致数据不现实或无效",
                "方法要点：集成约束矩阵编码领域知识，通过约束感知判别器确保数据遵循规则",
                "实验或效果：在医疗、安全、金融领域验证，生成高质量合成数据，提升真实性和实用性"
            ],
            "tags_zh": [
                "差分隐私",
                "生成对抗网络",
                "合成数据生成",
                "领域约束",
                "隐私保护",
                "数据效用"
            ],
            "_index": 24
        },
        {
            "title": "EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce",
            "authors": [
                "Rui Min",
                "Zile Qiao",
                "Ze Xu",
                "Jiawen Zhai",
                "Wenyu Gao",
                "Xuanzhong Chen",
                "Haozhen Sun",
                "Zhen Zhang",
                "Xinyu Wang",
                "Hong Zhou",
                "Wenbiao Yin",
                "Xuan Zhou",
                "Yong Jiang",
                "Haicheng Liu",
                "Liang Ding",
                "Ling Zou",
                "Yi R.",
                "Fung",
                "Yalong Li",
                "Pengjun Xie"
            ],
            "arxiv_id": "2512.08868v1",
            "summary": "Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.",
            "headline_zh": "提出EcomBench基准以评估电商场景中基础代理的实际能力",
            "intro_zh": [
                "核心问题：现有基准多关注学术或人工场景，忽略真实应用挑战，如电商领域动态交互。",
                "方法要点：基于真实电商用户需求构建基准，覆盖多任务类别和难度级别，评估信息检索和推理能力。",
                "实验或效果：通过专家标注确保准确性和领域相关性，为代理提供动态测试平台。"
            ],
            "tags_zh": [
                "电商基准",
                "基础代理评估",
                "多步推理",
                "信息检索",
                "真实场景测试"
            ],
            "_index": 25
        },
        {
            "title": "Secure and Privacy-Preserving Federated Learning for Next-Generation Underground Mine Safety",
            "authors": [
                "Mohamed Elmahallawy",
                "Sanjay Madria",
                "Samuel Frimpong"
            ],
            "arxiv_id": "2512.08862v1",
            "summary": "Underground mining operations depend on sensor networks to monitor critical parameters such as temperature, gas concentration, and miner movement, enabling timely hazard detection and safety decisions. However, transmitting raw sensor data to a centralized server for machine learning (ML) model training raises serious privacy and security concerns. Federated Learning (FL) offers a promising alternative by enabling decentralized model training without exposing sensitive local data. Yet, applying FL in underground mining presents unique challenges: (i) Adversaries may eavesdrop on shared model updates to launch model inversion or membership inference attacks, compromising data privacy and operational safety; (ii) Non-IID data distributions across mines and sensor noise can hinder model convergence. To address these issues, we propose FedMining--a privacy-preserving FL framework tailored for underground mining. FedMining introduces two core innovations: (1) a Decentralized Functional Encryption (DFE) scheme that keeps local models encrypted, thwarting unauthorized access and inference attacks; and (2) a balancing aggregation mechanism to mitigate data heterogeneity and enhance convergence. Evaluations on real-world mining datasets demonstrate FedMining's ability to safeguard privacy while maintaining high model accuracy and achieving rapid convergence with reduced communication and computation overhead. These advantages make FedMining both secure and practical for real-time underground safety monitoring.",
            "headline_zh": "提出FedMining框架，通过去中心化功能加密和平衡聚合机制，解决地下矿山联邦学习中的隐私安全与数据异构问题。",
            "intro_zh": [
                "核心问题：地下矿山传感器数据集中训练引发隐私安全风险，且非独立同分布数据与噪声阻碍模型收敛。",
                "方法要点：采用去中心化功能加密保护本地模型更新，结合平衡聚合机制缓解数据异构性。",
                "实验或效果：在真实数据集上验证了隐私保护能力，同时保持高模型精度和快速收敛，降低通信与计算开销。"
            ],
            "tags_zh": [
                "联邦学习",
                "隐私保护",
                "地下矿山安全",
                "去中心化功能加密",
                "数据异构性",
                "模型收敛"
            ],
            "_index": 26
        },
        {
            "title": "Tri-Bench: Stress-Testing VLM Reliability on Spatial Reasoning under Camera Tilt and Object Interference",
            "authors": [
                "Amit Bendkhale"
            ],
            "arxiv_id": "2512.08860v1",
            "summary": "Verifiable geometric reasoning is a critical component for trustworthy and controllable agentic AI. Despite impressive capabilities, Vision-Language Models (VLMs) often fail under realistic scene changes. We present Tri-Bench, a compact benchmark of planar triangle problems that isolates relative geometric reasoning while stressing two deployment-critical factors: camera pose (planar vs. tilted) and scene context via object interference (10 everyday objects). To test verifiability and control, we evaluate four recent VLMs using a single, fixed prompt whose guardrail explicitly describes a surrounding square border, enabling correct answers via homography. We evaluate six simple tasks over binary and continuous targets, and observe that the overall accuracy with respect to 3D ground truth is modest, ~69% on average (best ~75%, worst ~64%). The same responses align even more closely with 2D projections in the image plane, where mean accuracy is ~72%. All four VLMs consistently fail, with accuracy falling to ~0%, on recognizing minority shape classes (equilateral, isosceles, right-angled triangles). Additionally, overall VLM accuracy degrades by ~4.1% under camera tilt. This demonstrates that models fail to correctly utilize the explicit frame-of-reference hint provided in the prompt and default to 2D image plane cues. Finally, we find that object interference has no significant effect on VLM accuracy.",
            "headline_zh": "提出Tri-Bench基准，测试VLM在相机倾斜和物体干扰下的空间推理可靠性。",
            "intro_zh": [
                "核心问题：VLM在真实场景变化下几何推理失败，影响可信AI。",
                "方法要点：设计平面三角形问题，隔离相对几何推理，强调相机姿态和物体干扰因素。",
                "实验效果：VLM整体准确率约69%，相机倾斜降低4.1%，物体干扰无显著影响，模型依赖2D图像线索。"
            ],
            "tags_zh": [
                "视觉语言模型",
                "空间推理",
                "基准测试",
                "相机姿态",
                "几何验证",
                "物体干扰"
            ],
            "_index": 27
        },
        {
            "title": "Refining Diffusion Models for Motion Synthesis with an Acceleration Loss to Generate Realistic IMU Data",
            "authors": [
                "Lars Ole Häusler",
                "Lena Uhlenberg",
                "Göran Köber",
                "Diyora Salimova",
                "Oliver Amft"
            ],
            "arxiv_id": "2512.08859v1",
            "summary": "We propose a text-to-IMU (inertial measurement unit) motion-synthesis framework to obtain realistic IMU data by fine-tuning a pretrained diffusion model with an acceleration-based second-order loss (L_acc). L_acc enforces consistency in the discrete second-order temporal differences of the generated motion, thereby aligning the diffusion prior with IMU-specific acceleration patterns. We integrate L_acc into the training objective of an existing diffusion model, finetune the model to obtain an IMU-specific motion prior, and evaluate the model with an existing text-to-IMU framework that comprises surface modelling and virtual sensor simulation. We analysed acceleration signal fidelity and differences between synthetic motion representation and actual IMU recordings. As a downstream application, we evaluated Human Activity Recognition (HAR) and compared the classification performance using data of our method with the earlier diffusion model and two additional diffusion model baselines. When we augmented the earlier diffusion model objective with L_acc and continued training, L_acc decreased by 12.7% relative to the original model. The improvements were considerably larger in high-dynamic activities (i.e., running, jumping) compared to low-dynamic activities~(i.e., sitting, standing). In a low-dimensional embedding, the synthetic IMU data produced by our refined model shifts closer to the distribution of real IMU recordings. HAR classification trained exclusively on our refined synthetic IMU data improved performance by 8.7% compared to the earlier diffusion model and by 7.6% over the best-performing comparison diffusion model. We conclude that acceleration-aware diffusion refinement provides an effective approach to align motion generation and IMU synthesis and highlights how flexible deep learning pipelines are for specialising generic text-to-motion priors to sensor-specific tasks.",
            "headline_zh": "提出基于加速度损失的扩散模型微调方法，以生成更真实的IMU运动数据",
            "intro_zh": [
                "核心问题：现有文本到IMU运动合成框架生成的加速度信号不够真实，影响下游应用如人类活动识别。",
                "方法要点：通过引入加速度二阶损失（L_acc）微调预训练扩散模型，增强生成运动的时间一致性，对齐IMU加速度模式。",
                "实验或效果：L_acc降低12.7%，高动态活动改进显著；合成IMU数据分布更接近真实数据，HAR分类性能提升8.7%。"
            ],
            "tags_zh": [
                "扩散模型",
                "运动合成",
                "IMU数据生成",
                "加速度损失",
                "人类活动识别",
                "文本到运动"
            ],
            "_index": 28
        },
        {
            "title": "Reinforcement Learning From State and Temporal Differences",
            "authors": [
                "Lex Weaver",
                "Jonathan Baxter"
            ],
            "arxiv_id": "2512.08855v1",
            "summary": "TD($λ$) with function approximation has proved empirically successful for some complex reinforcement learning problems. For linear approximation, TD($λ$) has been shown to minimise the squared error between the approximate value of each state and the true value. However, as far as policy is concerned, it is error in the relative ordering of states that is critical, rather than error in the state values. We illustrate this point, both in simple two-state and three-state systems in which TD($λ$)--starting from an optimal policy--converges to a sub-optimal policy, and also in backgammon. We then present a modified form of TD($λ$), called STD($λ$), in which function approximators are trained with respect to relative state values on binary decision problems. A theoretical analysis, including a proof of monotonic policy improvement for STD($λ$) in the context of the two-state system, is presented, along with a comparison with Bertsekas' differential training method [1]. This is followed by successful demonstrations of STD($λ$) on the two-state system and a variation on the well known acrobot problem.",
            "headline_zh": "提出STD(λ)方法，通过优化状态相对值解决TD(λ)在策略改进中的次优问题。",
            "intro_zh": [
                "核心问题：TD(λ)在函数逼近中最小化状态值平方误差，但策略改进更依赖状态相对排序。",
                "方法要点：引入STD(λ)，在二元决策问题中基于状态相对值训练函数逼近器，理论证明单调策略改进。",
                "实验或效果：在双状态系统、三状态系统和西洋双陆棋中验证TD(λ)次优，STD(λ)在双状态系统和acrobot变体上成功演示。"
            ],
            "tags_zh": [
                "强化学习",
                "时序差分学习",
                "函数逼近",
                "策略改进",
                "状态相对值",
                "二元决策"
            ],
            "_index": 29
        },
        {
            "title": "Generation is Required for Data-Efficient Perception",
            "authors": [
                "Jack Brady",
                "Bernhard Schölkopf",
                "Thomas Kipf",
                "Simon Buchholz",
                "Wieland Brendel"
            ],
            "arxiv_id": "2512.08854v1",
            "summary": "It has been hypothesized that human-level visual perception requires a generative approach in which internal representations result from inverting a decoder. Yet today's most successful vision models are non-generative, relying on an encoder that maps images to representations without decoder inversion. This raises the question of whether generation is, in fact, necessary for machines to achieve human-level visual perception. To address this, we study whether generative and non-generative methods can achieve compositional generalization, a hallmark of human perception. Under a compositional data generating process, we formalize the inductive biases required to guarantee compositional generalization in decoder-based (generative) and encoder-based (non-generative) methods. We then show theoretically that enforcing these inductive biases on encoders is generally infeasible using regularization or architectural constraints. In contrast, for generative methods, the inductive biases can be enforced straightforwardly, thereby enabling compositional generalization by constraining a decoder and inverting it. We highlight how this inversion can be performed efficiently, either online through gradient-based search or offline through generative replay. We examine the empirical implications of our theory by training a range of generative and non-generative methods on photorealistic image datasets. We find that, without the necessary inductive biases, non-generative methods often fail to generalize compositionally and require large-scale pretraining or added supervision to improve generalization. By comparison, generative methods yield significant improvements in compositional generalization, without requiring additional data, by leveraging suitable inductive biases on a decoder along with search and replay.",
            "headline_zh": "提出生成方法通过解码器归纳偏置实现组合泛化，解决数据高效感知问题",
            "intro_zh": [
                "核心问题：生成与非生成方法在组合泛化能力上的差异，以评估人类级视觉感知的必要性",
                "方法要点：理论分析解码器与编码器的归纳偏置，生成方法通过解码器约束和反转实现组合泛化",
                "实验或效果：生成方法在真实图像数据集上显著提升组合泛化，无需额外数据或监督"
            ],
            "tags_zh": [
                "组合泛化",
                "生成模型",
                "视觉感知",
                "归纳偏置",
                "数据高效学习"
            ],
            "_index": 30
        },
        {
            "title": "Interpolation in Knowledge Representation",
            "authors": [
                "Jean Christoph Jung",
                "Patrick Koopmann",
                "Matthias Knorr"
            ],
            "arxiv_id": "2512.08833v1",
            "summary": "Craig interpolation and uniform interpolation have many applications in knowledge representation, including explainability, forgetting, modularization and reuse, and even learning. At the same time, many relevant knowledge representation formalisms do in general not have Craig or uniform interpolation, and computing interpolants in practice is challenging. We have a closer look at two prominent knowledge representation formalisms, description logics and logic programming, and discuss theoretical results and practical methods for computing interpolants.",
            "headline_zh": "探讨知识表示中插值法的理论结果与计算方法，应用于描述逻辑和逻辑编程",
            "intro_zh": [
                "核心问题：知识表示形式如描述逻辑和逻辑编程通常缺乏Craig或均匀插值，实际计算插值困难",
                "方法要点：分析插值在知识表示中的应用，包括可解释性、遗忘、模块化和学习，讨论计算插值的理论结果",
                "实验或效果：未知"
            ],
            "tags_zh": [
                "知识表示",
                "插值法",
                "描述逻辑",
                "逻辑编程",
                "可解释性",
                "模块化"
            ],
            "_index": 31
        },
        {
            "title": "Forecasting Fails: Unveiling Evasion Attacks in Weather Prediction Models",
            "authors": [
                "Huzaifa Arif",
                "Pin-Yu Chen",
                "Alex Gittens",
                "James Diffenderfer",
                "Bhavya Kailkhura"
            ],
            "arxiv_id": "2512.08832v1",
            "summary": "With the increasing reliance on AI models for weather forecasting, it is imperative to evaluate their vulnerability to adversarial perturbations. This work introduces Weather Adaptive Adversarial Perturbation Optimization (WAAPO), a novel framework for generating targeted adversarial perturbations that are both effective in manipulating forecasts and stealthy to avoid detection. WAAPO achieves this by incorporating constraints for channel sparsity, spatial localization, and smoothness, ensuring that perturbations remain physically realistic and imperceptible. Using the ERA5 dataset and FourCastNet (Pathak et al. 2022), we demonstrate WAAPO's ability to generate adversarial trajectories that align closely with predefined targets, even under constrained conditions. Our experiments highlight critical vulnerabilities in AI-driven forecasting models, where small perturbations to initial conditions can result in significant deviations in predicted weather patterns. These findings underscore the need for robust safeguards to protect against adversarial exploitation in operational forecasting systems.",
            "headline_zh": "提出WAAPO框架以生成针对天气预测模型的隐蔽对抗扰动",
            "intro_zh": [
                "核心问题：评估AI天气预测模型对对抗扰动的脆弱性，需生成物理真实且不易察觉的扰动。",
                "方法要点：WAAPO通过通道稀疏性、空间局部性和平滑性约束，优化生成目标对抗扰动。",
                "实验或效果：在ERA5数据集和FourCastNet上，WAAPO能生成与预设目标紧密对齐的对抗轨迹，揭示模型关键漏洞。"
            ],
            "tags_zh": [
                "天气预测模型",
                "对抗攻击",
                "扰动优化",
                "物理约束",
                "模型脆弱性"
            ],
            "_index": 32
        },
        {
            "title": "InfiniteVL: Synergizing Linear and Sparse Attention for Highly-Efficient, Unlimited-Input Vision-Language Models",
            "authors": [
                "Hongyuan Tao",
                "Bencheng Liao",
                "Shaoyu Chen",
                "Haoran Yin",
                "Qian Zhang",
                "Wenyu Liu",
                "Xinggang Wang"
            ],
            "arxiv_id": "2512.08829v1",
            "summary": "Window attention and linear attention represent two principal strategies for mitigating the quadratic complexity and ever-growing KV cache in Vision-Language Models (VLMs). However, we observe that window-based VLMs suffer performance degradation when sequence length exceeds the window size, while linear attention underperforms on information-intensive tasks such as OCR and document understanding. To overcome these limitations, we propose InfiniteVL, a linear-complexity VLM architecture that synergizes sliding window attention (SWA) with Gated DeltaNet. For achieving competitive multimodal performance under constrained resources, we design a three-stage training strategy comprising distillation pretraining, instruction tuning, and long-sequence SFT. Remarkably, using less than 2\\% of the training data required by leading VLMs, InfiniteVL not only substantially outperforms previous linear-complexity VLMs but also matches the performance of leading Transformer-based VLMs, while demonstrating effective long-term memory retention. Compared to similar-sized Transformer-based VLMs accelerated by FlashAttention-2, InfiniteVL achieves over 3.6\\times inference speedup while maintaining constant latency and memory footprint. In streaming video understanding scenarios, it sustains a stable 24 FPS real-time prefill speed while preserving long-term memory cache. Code and models are available at https://github.com/hustvl/InfiniteVL.",
            "headline_zh": "提出InfiniteVL，结合滑动窗口与线性注意力，实现高效无限输入视觉语言模型。",
            "intro_zh": [
                "问题：窗口注意力超窗性能下降，线性注意力信息密集型任务表现不足。",
                "方法：融合滑动窗口注意力与Gated DeltaNet，设计三阶段训练策略。",
                "效果：数据量少2%，性能匹配领先Transformer模型，推理加速3.6倍。"
            ],
            "tags_zh": [
                "无限输入视觉语言模型",
                "线性复杂度注意力",
                "滑动窗口注意力",
                "长序列训练",
                "实时视频理解",
                "蒸馏预训练"
            ],
            "_index": 33
        },
        {
            "title": "CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale",
            "authors": [
                "Shahar Sarfaty",
                "Adi Haviv",
                "Uri Hacohen",
                "Niva Elkin-Koren",
                "Roi Livni",
                "Amit H. Bermano"
            ],
            "arxiv_id": "2512.08826v1",
            "summary": "The rapid proliferation of generative components, such as LoRAs, has created a vast but unstructured ecosystem. Existing discovery methods depend on unreliable user descriptions or biased popularity metrics, hindering usability. We present CARLoS, a large-scale framework for characterizing LoRAs without requiring additional metadata. Analyzing over 650 LoRAs, we employ them in image generation over a variety of prompts and seeds, as a credible way to assess their behavior. Using CLIP embeddings and their difference to a base-model generation, we concisely define a three-part representation: Directions, defining semantic shift; Strength, quantifying the significance of the effect; and Consistency, quantifying how stable the effect is. Using these representations, we develop an efficient retrieval framework that semantically matches textual queries to relevant LoRAs while filtering overly strong or unstable ones, outperforming textual baselines in automated and human evaluations. While retrieval is our primary focus, the same representation also supports analyses linking Strength and Consistency to legal notions of substantiality and volition, key considerations in copyright, positioning CARLoS as a practical system with broader relevance for LoRA analysis.",
            "headline_zh": "提出CARLoS框架，通过简洁评估表示实现大规模LoRA检索，解决依赖不可靠元数据的问题。",
            "intro_zh": [
                "核心问题：LoRA生态系统庞大但无序，现有发现方法依赖不可靠用户描述或流行度指标，影响可用性。",
                "方法要点：分析650多个LoRA，基于CLIP嵌入差异定义三部分表示：方向、强度和一致性，用于语义检索。",
                "实验或效果：在自动和人工评估中优于文本基线，支持检索并链接到版权法律概念，提升LoRA分析实用性。"
            ],
            "tags_zh": [
                "LoRA检索",
                "生成组件评估",
                "CLIP嵌入",
                "语义匹配",
                "版权分析",
                "大规模框架"
            ],
            "_index": 34
        },
        {
            "title": "Training-Free Dual Hyperbolic Adapters for Better Cross-Modal Reasoning",
            "authors": [
                "Yi Zhang",
                "Chun-Wun Cheng",
                "Junyi He",
                "Ke Yu",
                "Yushun Tang",
                "Carola-Bibiane Schönlieb",
                "Zhihai He",
                "Angelica I. Aviles-Rivero"
            ],
            "arxiv_id": "2512.08820v1",
            "summary": "Recent research in Vision-Language Models (VLMs) has significantly advanced our capabilities in cross-modal reasoning. However, existing methods suffer from performance degradation with domain changes or require substantial computational resources for fine-tuning in new domains. To address this issue, we develop a new adaptation method for large vision-language models, called \\textit{Training-free Dual Hyperbolic Adapters} (T-DHA). We characterize the vision-language relationship between semantic concepts, which typically has a hierarchical tree structure, in the hyperbolic space instead of the traditional Euclidean space. Hyperbolic spaces exhibit exponential volume growth with radius, unlike the polynomial growth in Euclidean space. We find that this unique property is particularly effective for embedding hierarchical data structures using the Poincaré ball model, achieving significantly improved representation and discrimination power. Coupled with negative learning, it provides more accurate and robust classifications with fewer feature dimensions. Our extensive experimental results on various datasets demonstrate that the T-DHA method significantly outperforms existing state-of-the-art methods in few-shot image recognition and domain generalization tasks.",
            "headline_zh": "提出训练自由双曲适配器以提升跨模态推理的鲁棒性和效率",
            "intro_zh": [
                "现有视觉语言模型在领域变化时性能下降或需大量计算资源微调",
                "在双曲空间建模层次化语义关系，利用指数体积增长提升表示能力",
                "实验显示在少样本图像识别和领域泛化任务中优于现有方法"
            ],
            "tags_zh": [
                "视觉语言模型",
                "跨模态推理",
                "双曲空间",
                "训练自由适配",
                "领域泛化",
                "少样本学习"
            ],
            "_index": 35
        },
        {
            "title": "Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis",
            "authors": [
                "Ferdinand Kapl",
                "Emmanouil Angelis",
                "Tobias Höppe",
                "Kaitlin Maile",
                "Johannes von Oswald",
                "Nino Scherrer",
                "Stefan Bauer"
            ],
            "arxiv_id": "2512.08819v1",
            "summary": "Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.",
            "headline_zh": "分析深度增长模型如何通过中间堆叠克服深度诅咒，提升Transformer推理性能",
            "intro_zh": [
                "核心问题：标准Transformer后层贡献低，存在深度诅咒，影响模型深度利用效率",
                "方法要点：采用深度增长训练，通过中间堆叠优化残差流结构，形成可置换计算块",
                "实验或效果：深度增长模型提升深度利用，改进下游推理基准，提出轻量修改进一步优化"
            ],
            "tags_zh": [
                "深度增长模型",
                "Transformer",
                "深度诅咒",
                "中间堆叠",
                "推理性能",
                "残差流结构"
            ],
            "_index": 36
        },
        {
            "title": "Heterogeneity in Multi-Robot Environmental Monitoring for Resolving Time-Conflicting Tasks",
            "authors": [
                "Connor York",
                "Zachary R Madin",
                "Paul O'Dowd",
                "Edmund R Hunt"
            ],
            "arxiv_id": "2512.08813v1",
            "summary": "Multi-robot systems performing continuous tasks face a performance trade-off when interrupted by urgent, time-critical sub-tasks. We investigate this trade-off in a scenario where a team must balance area patrolling with locating an anomalous radio signal. To address this trade-off, we evaluate both behavioral heterogeneity through agent role specialization (\"patrollers\" and \"searchers\") and sensing heterogeneity (i.e., only the searchers can sense the radio signal). Through simulation, we identify the Pareto-optimal trade-offs under varying team compositions, with behaviorally heterogeneous teams demonstrating the most balanced trade-offs in the majority of cases. When sensing capability is restricted, heterogeneous teams with half of the sensing-capable agents perform comparably to homogeneous teams, providing cost-saving rationale for restricting sensor payload deployment. Our findings demonstrate that pre-deployment role and sensing specialization are powerful design considerations for multi-robot systems facing time-conflicting tasks, where varying the degree of behavioral heterogeneity can tune system performance toward either task.",
            "headline_zh": "评估异构多机器人系统在时间冲突任务中的性能权衡，以平衡区域巡逻与异常信号定位。",
            "intro_zh": [
                "核心问题：多机器人系统在持续任务中面临时间冲突子任务时的性能权衡。",
                "方法要点：通过行为异构（角色专业化）和感知异构（传感器限制）设计系统。",
                "实验或效果：模拟显示行为异构团队在多数情况下实现最平衡的权衡，感知限制可节省成本。"
            ],
            "tags_zh": [
                "多机器人系统",
                "时间冲突任务",
                "异构设计",
                "性能权衡",
                "模拟评估"
            ],
            "_index": 37
        },
        {
            "title": "Emovectors: assessing emotional content in jazz improvisations for creativity evaluation",
            "authors": [
                "Anna Jordanous"
            ],
            "arxiv_id": "2512.08812v1",
            "summary": "Music improvisation is fascinating to study, being essentially a live demonstration of a creative process. In jazz, musicians often improvise across predefined chord progressions (leadsheets). How do we assess the creativity of jazz improvisations? And can we capture this in automated metrics for creativity for current LLM-based generative systems? Demonstration of emotional involvement is closely linked with creativity in improvisation. Analysing musical audio, can we detect emotional involvement? This study hypothesises that if an improvisation contains more evidence of emotion-laden content, it is more likely to be recognised as creative. An embeddings-based method is proposed for capturing the emotional content in musical improvisations, using a psychologically-grounded classification of musical characteristics associated with emotions. Resulting 'emovectors' are analysed to test the above hypothesis, comparing across multiple improvisations. Capturing emotional content in this quantifiable way can contribute towards new metrics for creativity evaluation that can be applied at scale.",
            "headline_zh": "提出基于嵌入的emovectors方法，量化爵士即兴演奏中的情感内容以评估创造力。",
            "intro_zh": [
                "核心问题：如何自动评估爵士即兴演奏的创造力，并关联情感内容。",
                "方法要点：使用心理学基础的音乐特征分类，通过嵌入方法捕捉情感内容生成emovectors。",
                "实验或效果：分析emovectors测试假设，为大规模创造力评估提供新指标。"
            ],
            "tags_zh": [
                "爵士即兴演奏",
                "创造力评估",
                "情感内容分析",
                "嵌入方法",
                "音乐特征分类"
            ],
            "_index": 38
        },
        {
            "title": "Multicalibration for LLM-based Code Generation",
            "authors": [
                "Viola Campos",
                "Robin Kuschnereit",
                "Adrian Ulges"
            ],
            "arxiv_id": "2512.08810v1",
            "summary": "As AI-based code generation becomes widespread, researchers are investigating the calibration of code LLMs - ensuring their confidence scores faithfully represent the true likelihood of code correctness. To do so, we investigate multicalibration, which can capture additional factors about a coding problem, such as complexity, code length, or programming language used. We study four multicalibration approaches on three function synthesis benchmarks, using latest-generation code LLMs (Qwen3 Coder, GPT-OSS, DeepSeek-R1-Distill). Our results demonstrate that multicalibration can yield distinct improvements over both uncalibrated token likelihoods (+1.03 in skill score) and baseline calibrations (+0.37 in skill score). We study the influence of the aforementioned factors in ablations, and make our dataset (consisting of code generations, likelihoods, and correctness labels) available for future research on code LLM calibration.",
            "headline_zh": "提出多校准方法以提升代码大语言模型的置信度校准效果",
            "intro_zh": [
                "研究代码大语言模型置信度校准问题，确保置信分数准确反映代码正确性概率",
                "采用多校准方法，考虑编程语言、代码长度和复杂度等因素，提升校准性能",
                "在三个函数合成基准上测试四种多校准方法，相比基线校准提升0.37技能分数"
            ],
            "tags_zh": [
                "代码生成",
                "大语言模型校准",
                "多校准",
                "置信度评估",
                "函数合成基准"
            ],
            "_index": 39
        },
        {
            "title": "PrivTune: Efficient and Privacy-Preserving Fine-Tuning of Large Language Models via Device-Cloud Collaboration",
            "authors": [
                "Yi Liu",
                "Weixiang Han",
                "Chengjun Cai",
                "Xingliang Yuan",
                "Cong Wang"
            ],
            "arxiv_id": "2512.08809v1",
            "summary": "With the rise of large language models, service providers offer language models as a service, enabling users to fine-tune customized models via uploaded private datasets. However, this raises concerns about sensitive data leakage. Prior methods, relying on differential privacy within device-cloud collaboration frameworks, struggle to balance privacy and utility, exposing users to inference attacks or degrading fine-tuning performance. To address this, we propose PrivTune, an efficient and privacy-preserving fine-tuning framework via Split Learning (SL). The key idea of PrivTune is to inject crafted noise into token representations from the SL bottom model, making each token resemble the $n$-hop indirect neighbors. PrivTune formulates this as an optimization problem to compute the optimal noise vector, aligning with defense-utility goals. On this basis, it then adjusts the parameters (i.e., mean) of the $d_χ$-Privacy noise distribution to align with the optimization direction and scales the noise according to token importance to minimize distortion. Experiments on five datasets (covering both classification and generation tasks) against three embedding inversion and three attribute inference attacks show that, using RoBERTa on the Stanford Sentiment Treebank dataset, PrivTune reduces the attack success rate to 10% with only a 3.33% drop in utility performance, outperforming state-of-the-art baselines.",
            "headline_zh": "提出PrivTune框架，通过设备-云协作实现大语言模型高效隐私保护微调",
            "intro_zh": [
                "核心问题：现有差分隐私方法在设备-云协作中难以平衡隐私与效用，易导致敏感数据泄露或性能下降",
                "方法要点：基于Split Learning，向底层模型令牌表示注入优化噪声，使令牌类似间接邻居，并调整噪声分布参数以最小化失真",
                "实验或效果：在五个数据集上对抗六种攻击，PrivTune将攻击成功率降至10%，效用性能仅下降3.33%，优于基线方法"
            ],
            "tags_zh": [
                "隐私保护微调",
                "设备-云协作",
                "Split Learning",
                "令牌噪声注入",
                "大语言模型安全"
            ],
            "_index": 40
        },
        {
            "title": "Identifying counterfactual probabilities using bivariate distributions and uplift modeling",
            "authors": [
                "Théo Verhelst",
                "Gianluca Bontempi"
            ],
            "arxiv_id": "2512.08805v1",
            "summary": "Uplift modeling estimates the causal effect of an intervention as the difference between potential outcomes under treatment and control, whereas counterfactual identification aims to recover the joint distribution of these potential outcomes (e.g., \"Would this customer still have churned had we given them a marketing offer?\"). This joint counterfactual distribution provides richer information than the uplift but is harder to estimate. However, the two approaches are synergistic: uplift models can be leveraged for counterfactual estimation. We propose a counterfactual estimator that fits a bivariate beta distribution to predicted uplift scores, yielding posterior distributions over counterfactual outcomes. Our approach requires no causal assumptions beyond those of uplift modeling. Simulations show the efficacy of the approach, which can be applied, for example, to the problem of customer churn in telecom, where it reveals insights unavailable to standard ML or uplift models alone.",
            "headline_zh": "提出基于双变量Beta分布和提升建模的反事实概率估计方法，应用于电信客户流失分析。",
            "intro_zh": [
                "核心问题：反事实识别需估计干预下潜在结果的联合分布，比提升建模更复杂但信息更丰富。",
                "方法要点：利用提升模型预测分数拟合双变量Beta分布，生成反事实结果的后验分布，无需额外因果假设。",
                "实验或效果：模拟验证方法有效性，在电信客户流失问题中揭示标准机器学习或提升模型无法提供的洞察。"
            ],
            "tags_zh": [
                "反事实估计",
                "提升建模",
                "双变量分布",
                "因果推断",
                "客户流失分析"
            ],
            "_index": 41
        },
        {
            "title": "Democratizing ML for Enterprise Security: A Self-Sustained Attack Detection Framework",
            "authors": [
                "Sadegh Momeni",
                "Ge Zhang",
                "Birkett Huber",
                "Hamza Harkous",
                "Sam Lipton",
                "Benoit Seguin",
                "Yanis Pavlidis"
            ],
            "arxiv_id": "2512.08802v1",
            "summary": "Despite advancements in machine learning for security, rule-based detection remains prevalent in Security Operations Centers due to the resource intensiveness and skill gap associated with ML solutions. While traditional rule-based methods offer efficiency, their rigidity leads to high false positives or negatives and requires continuous manual maintenance. This paper proposes a novel, two-stage hybrid framework to democratize ML-based threat detection. The first stage employs intentionally loose YARA rules for coarse-grained filtering, optimized for high recall. The second stage utilizes an ML classifier to filter out false positives from the first stage's output. To overcome data scarcity, the system leverages Simula, a seedless synthetic data generation framework, enabling security analysts to create high-quality training datasets without extensive data science expertise or pre-labeled examples. A continuous feedback loop incorporates real-time investigation results to adaptively tune the ML model, preventing rule degradation.\n  This proposed model with active learning has been rigorously tested for a prolonged time in a production environment spanning tens of thousands of systems. The system handles initial raw log volumes often reaching 250 billion events per day, significantly reducing them through filtering and ML inference to a handful of daily tickets for human investigation. Live experiments over an extended timeline demonstrate a general improvement in the model's precision over time due to the active learning feature. This approach offers a self-sustained, low-overhead, and low-maintenance solution, allowing security professionals to guide model learning as expert ``teachers''.",
            "headline_zh": "提出两阶段混合框架以降低企业安全中基于机器学习的攻击检测门槛",
            "intro_zh": [
                "核心问题：规则检测僵化导致高误报/漏报，ML方案资源密集且技能门槛高",
                "方法要点：先松YARA规则粗筛，后ML分类器精筛，结合Simula生成合成数据克服数据稀缺",
                "实验或效果：生产环境长期测试，日处理2500亿事件，通过主动学习持续提升模型精度"
            ],
            "tags_zh": [
                "企业安全检测",
                "混合框架",
                "合成数据生成",
                "主动学习",
                "YARA规则",
                "ML分类器"
            ],
            "_index": 42
        },
        {
            "title": "Can TabPFN Compete with GNNs for Node Classification via Graph Tabularization?",
            "authors": [
                "Jeongwhan Choi",
                "Woosung Kang",
                "Minseo Kim",
                "Jongwoo Kim",
                "Noseong Park"
            ],
            "arxiv_id": "2512.08798v1",
            "summary": "Foundation models pretrained on large data have demonstrated remarkable zero-shot generalization capabilities across domains. Building on the success of TabPFN for tabular data and its recent extension to time series, we investigate whether graph node classification can be effectively reformulated as a tabular learning problem. We introduce TabPFN-GN, which transforms graph data into tabular features by extracting node attributes, structural properties, positional encodings, and optionally smoothed neighborhood features. This enables TabPFN to perform direct node classification without any graph-specific training or language model dependencies. Our experiments on 12 benchmark datasets reveal that TabPFN-GN achieves competitive performance with GNNs on homophilous graphs and consistently outperforms them on heterophilous graphs. These results demonstrate that principled feature engineering can bridge the gap between tabular and graph domains, providing a practical alternative to task-specific GNN training and LLM-dependent graph foundation models.",
            "headline_zh": "提出TabPFN-GN将图数据表格化，用于节点分类，无需图特定训练或语言模型依赖。",
            "intro_zh": [
                "研究图节点分类能否通过表格学习有效解决，利用TabPFN基础模型。",
                "方法提取节点属性、结构特征等，将图数据转换为表格形式进行直接分类。",
                "实验显示在异配图上性能优于GNN，同配图上竞争，提供图学习新替代方案。"
            ],
            "tags_zh": [
                "图节点分类",
                "表格化学习",
                "基础模型",
                "异配图",
                "特征工程",
                "零样本泛化"
            ],
            "_index": 43
        },
        {
            "title": "MatteViT: High-Frequency-Aware Document Shadow Removal with Shadow Matte Guidance",
            "authors": [
                "Chaewon Kim",
                "Seoyeon Lee",
                "Jonghyuk Park"
            ],
            "arxiv_id": "2512.08789v1",
            "summary": "Document shadow removal is essential for enhancing the clarity of digitized documents. Preserving high-frequency details (e.g., text edges and lines) is critical in this process because shadows often obscure or distort fine structures. This paper proposes a matte vision transformer (MatteViT), a novel shadow removal framework that applies spatial and frequency-domain information to eliminate shadows while preserving fine-grained structural details. To effectively retain these details, we employ two preservation strategies. First, our method introduces a lightweight high-frequency amplification module (HFAM) that decomposes and adaptively amplifies high-frequency components. Second, we present a continuous luminance-based shadow matte, generated using a custom-built matte dataset and shadow matte generator, which provides precise spatial guidance from the earliest processing stage. These strategies enable the model to accurately identify fine-grained regions and restore them with high fidelity. Extensive experiments on public benchmarks (RDD and Kligler) demonstrate that MatteViT achieves state-of-the-art performance, providing a robust and practical solution for real-world document shadow removal. Furthermore, the proposed method better preserves text-level details in downstream tasks, such as optical character recognition, improving recognition performance over prior methods.",
            "headline_zh": "提出MatteViT框架，利用高频感知和阴影遮罩指导解决文档阴影去除问题。",
            "intro_zh": [
                "核心问题：文档阴影去除需保留高频细节如文本边缘，阴影常模糊精细结构。",
                "方法要点：结合空间与频域信息，引入高频放大模块和连续亮度阴影遮罩指导。",
                "实验或效果：在公开基准测试中达到先进性能，提升下游任务如OCR的识别效果。"
            ],
            "tags_zh": [
                "文档阴影去除",
                "高频感知",
                "阴影遮罩指导",
                "视觉变换器",
                "光学字符识别"
            ],
            "_index": 44
        },
        {
            "title": "A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs",
            "authors": [
                "Mahmoud Srewa",
                "Tianyu Zhao",
                "Salma Elmalaki"
            ],
            "arxiv_id": "2512.08786v1",
            "summary": "This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.",
            "headline_zh": "提出自适应聚合策略以解决联邦RLHF中LLM与多元人类偏好对齐的公平性问题",
            "intro_zh": [
                "核心问题：联邦学习中标准方法难以充分代表多元人类偏好，导致对齐质量与公平性失衡",
                "方法要点：评估标准聚合技术并引入自适应方案，基于历史性能动态调整偏好权重",
                "实验或效果：在Q/A任务中，自适应方法在保持对齐得分的同时显著提升公平性"
            ],
            "tags_zh": [
                "联邦学习",
                "强化学习人类反馈",
                "偏好聚合",
                "公平性评估",
                "大语言模型对齐"
            ],
            "_index": 45
        },
        {
            "title": "LoFA: Learning to Predict Personalized Priors for Fast Adaptation of Visual Generative Models",
            "authors": [
                "Yiming Hao",
                "Mutian Xu",
                "Chongjie Ye",
                "Jie Qin",
                "Shunlin Lu",
                "Yipeng Qin",
                "Xiaoguang Han"
            ],
            "arxiv_id": "2512.08785v1",
            "summary": "Personalizing visual generative models to meet specific user needs has gained increasing attention, yet current methods like Low-Rank Adaptation (LoRA) remain impractical due to their demand for task-specific data and lengthy optimization. While a few hypernetwork-based approaches attempt to predict adaptation weights directly, they struggle to map fine-grained user prompts to complex LoRA distributions, limiting their practical applicability. To bridge this gap, we propose LoFA, a general framework that efficiently predicts personalized priors for fast model adaptation. We first identify a key property of LoRA: structured distribution patterns emerge in the relative changes between LoRA and base model parameters. Building on this, we design a two-stage hypernetwork: first predicting relative distribution patterns that capture key adaptation regions, then using these to guide final LoRA weight prediction. Extensive experiments demonstrate that our method consistently predicts high-quality personalized priors within seconds, across multiple tasks and user prompts, even outperforming conventional LoRA that requires hours of processing. Project page: https://jaeger416.github.io/lofa/.",
            "headline_zh": "提出LoFA框架以快速预测个性化先验，实现视觉生成模型的高效适配",
            "intro_zh": [
                "核心问题：现有方法如LoRA需任务特定数据和长时间优化，超网络方法难以映射细粒度提示到复杂LoRA分布",
                "方法要点：基于LoRA参数相对变化的结构化分布模式，设计两阶段超网络预测相对分布模式并指导最终权重预测",
                "实验或效果：在多个任务和用户提示下，秒级预测高质量个性化先验，性能优于需数小时处理的传统LoRA"
            ],
            "tags_zh": [
                "视觉生成模型",
                "个性化适配",
                "超网络",
                "快速优化",
                "LoRA分布预测"
            ],
            "_index": 46
        },
        {
            "title": "Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages",
            "authors": [
                "David Samuel",
                "Lilja Øvrelid",
                "Erik Velldal",
                "Andrey Kutuzov"
            ],
            "arxiv_id": "2512.08777v1",
            "summary": "We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.",
            "headline_zh": "提出后训练方法以在低资源语言中实现流畅偏好对齐，无需目标语言指令数据。",
            "intro_zh": [
                "核心问题：低资源语言缺乏母语数据集和流畅生成模型，偏好对齐易受不流畅奖励模型影响。",
                "方法要点：采用在线策略训练，避免依赖机器翻译或多语言微调，无需目标语言指令数据。",
                "实验或效果：以挪威语为例，通过母语者评估，在线策略方法优于替代方案，提升流畅性。"
            ],
            "tags_zh": [
                "低资源语言",
                "偏好对齐",
                "后训练",
                "在线策略训练",
                "流畅性评估",
                "语言模型"
            ],
            "_index": 47
        },
        {
            "title": "Refining Visual Artifacts in Diffusion Models via Explainable AI-based Flaw Activation Maps",
            "authors": [
                "Seoyeon Lee",
                "Gwangyeol Yu",
                "Chaewon Kim",
                "Jonghyuk Park"
            ],
            "arxiv_id": "2512.08774v1",
            "summary": "Diffusion models have achieved remarkable success in image synthesis. However, addressing artifacts and unrealistic regions remains a critical challenge. We propose self-refining diffusion, a novel framework that enhances image generation quality by detecting these flaws. The framework employs an explainable artificial intelligence (XAI)-based flaw highlighter to produce flaw activation maps (FAMs) that identify artifacts and unrealistic regions. These FAMs improve reconstruction quality by amplifying noise in flawed regions during the forward process and by focusing on these regions during the reverse process. The proposed approach achieves up to a 27.3% improvement in Fréchet inception distance across various diffusion-based models, demonstrating consistently strong performance on diverse datasets. It also shows robust effectiveness across different tasks, including image generation, text-to-image generation, and inpainting. These results demonstrate that explainable AI techniques can extend beyond interpretability to actively contribute to image refinement. The proposed framework offers a versatile and effective approach applicable to various diffusion models and tasks, significantly advancing the field of image synthesis.",
            "headline_zh": "提出基于可解释AI的自精炼扩散框架，以检测并修复扩散模型中的视觉伪影和不真实区域。",
            "intro_zh": [
                "扩散模型在图像合成中面临伪影和不真实区域的关键挑战。",
                "利用可解释AI生成缺陷激活图，在正向过程放大噪声，反向过程聚焦修复。",
                "在多种模型和任务上实现Fréchet inception距离提升，最高达27.3%。"
            ],
            "tags_zh": [
                "扩散模型",
                "图像合成",
                "可解释AI",
                "缺陷检测",
                "图像精炼"
            ],
            "_index": 48
        },
        {
            "title": "De novo generation of functional terpene synthases using TpsGPT",
            "authors": [
                "Hamsini Ramanathan",
                "Roman Bushuiev",
                "Matouš Soldát",
                "Jirí Kohout",
                "Téo Hebra",
                "Joshua David Smith",
                "Josef Sivic",
                "Tomáš Pluskal"
            ],
            "arxiv_id": "2512.08772v1",
            "summary": "Terpene synthases (TPS) are a key family of enzymes responsible for generating the diverse terpene scaffolds that underpin many natural products, including front-line anticancer drugs such as Taxol. However, de novo TPS design through directed evolution is costly and slow. We introduce TpsGPT, a generative model for scalable TPS protein design, built by fine-tuning the protein language model ProtGPT2 on 79k TPS sequences mined from UniProt. TpsGPT generated de novo enzyme candidates in silico and we evaluated them using multiple validation metrics, including EnzymeExplorer classification, ESMFold structural confidence (pLDDT), sequence diversity, CLEAN classification, InterPro domain detection, and Foldseek structure alignment. From an initial pool of 28k generated sequences, we identified seven putative TPS enzymes that satisfied all validation criteria. Experimental validation confirmed TPS enzymatic activity in at least two of these sequences. Our results show that fine-tuning of a protein language model on a carefully curated, enzyme-class-specific dataset, combined with rigorous filtering, can enable the de novo generation of functional, evolutionarily distant enzymes.",
            "headline_zh": "提出TpsGPT以解决萜烯合酶从头设计的成本与效率问题",
            "intro_zh": [
                "萜烯合酶设计依赖定向进化，过程昂贵且缓慢",
                "基于ProtGPT2微调，构建生成模型TpsGPT，用于从头设计酶序列",
                "通过多指标验证和实验，确认生成序列具有功能性活性"
            ],
            "tags_zh": [
                "蛋白质语言模型",
                "酶设计",
                "生成模型",
                "萜烯合酶",
                "从头设计",
                "实验验证"
            ],
            "_index": 49
        },
        {
            "title": "A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows",
            "authors": [
                "Eranga Bandara",
                "Ross Gore",
                "Peter Foytik",
                "Sachin Shetty",
                "Ravi Mukkamala",
                "Abdul Rahman",
                "Xueping Liang",
                "Safdar H. Bouk",
                "Amin Hass",
                "Sachini Rajapakse",
                "Ng Wee Keong",
                "Kasun De Zoysa",
                "Aruna Withanage",
                "Nilaan Loganathan"
            ],
            "arxiv_id": "2512.08769v1",
            "summary": "Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.",
            "headline_zh": "提出生产级智能体AI工作流设计与部署的端到端实践指南，以解决可靠性与可维护性挑战。",
            "intro_zh": [
                "核心问题：如何设计、工程化和运营可靠、可观测、可维护且符合安全治理要求的生产级智能体AI工作流。",
                "方法要点：引入结构化工程生命周期，涵盖工作流分解、多智能体设计模式、MCP协议、工具集成、确定性编排、负责任AI考虑和环境感知部署策略。",
                "实验或效果：通过多模态新闻分析与媒体生成工作流的案例研究，展示原则的实际应用与实现洞察。"
            ],
            "tags_zh": [
                "智能体AI工作流",
                "生产级部署",
                "多智能体设计",
                "模型上下文协议",
                "负责任AI",
                "容器化部署"
            ],
            "_index": 50
        },
        {
            "title": "Data-Driven Dynamic Parameter Learning of manipulator robots",
            "authors": [
                "Mohammed Elseiagy",
                "Tsige Tadesse Alemayoh",
                "Ranulfo Bezerra",
                "Shotaro Kojima",
                "Kazunori Ohno"
            ],
            "arxiv_id": "2512.08767v1",
            "summary": "Bridging the sim-to-real gap remains a fundamental challenge in robotics, as accurate dynamic parameter estimation is essential for reliable model-based control, realistic simulation, and safe deployment of manipulators. Traditional analytical approaches often fall short when faced with complex robot structures and interactions. Data-driven methods offer a promising alternative, yet conventional neural networks such as recurrent models struggle to capture long-range dependencies critical for accurate estimation. In this study, we propose a Transformer-based approach for dynamic parameter estimation, supported by an automated pipeline that generates diverse robot models and enriched trajectory data using Jacobian-derived features. The dataset consists of 8,192 robots with varied inertial and frictional properties. Leveraging attention mechanisms, our model effectively captures both temporal and spatial dependencies. Experimental results highlight the influence of sequence length, sampling rate, and architecture, with the best configuration (sequence length 64, 64 Hz, four layers, 32 heads) achieving a validation R2 of 0.8633. Mass and inertia are estimated with near-perfect accuracy, Coulomb friction with moderate-to-high accuracy, while viscous friction and distal link center-of-mass remain more challenging. These results demonstrate that combining Transformers with automated dataset generation and kinematic enrichment enables scalable, accurate dynamic parameter estimation, contributing to improved sim-to-real transfer in robotic systems",
            "headline_zh": "提出基于Transformer的动态参数估计方法，结合自动化数据生成，以提升机器人仿真到现实的迁移能力。",
            "intro_zh": [
                "核心问题：机器人动态参数估计对模型控制至关重要，但传统方法难以处理复杂结构，数据驱动方法面临长依赖捕获挑战。",
                "方法要点：采用Transformer模型，利用注意力机制捕捉时空依赖，并通过自动化管道生成多样化机器人模型和轨迹数据。",
                "实验或效果：最佳配置在验证集上R2达0.8633，质量和惯性估计准确，摩擦和质心估计更具挑战性，证明方法可扩展且准确。"
            ],
            "tags_zh": [
                "动态参数估计",
                "Transformer模型",
                "仿真到现实迁移",
                "自动化数据生成",
                "机器人控制"
            ],
            "_index": 51
        },
        {
            "title": "Wan-Move: Motion-controllable Video Generation via Latent Trajectory Guidance",
            "authors": [
                "Ruihang Chu",
                "Yefei He",
                "Zhekai Chen",
                "Shiwei Zhang",
                "Xiaogang Xu",
                "Bin Xia",
                "Dingdong Wang",
                "Hongwei Yi",
                "Xihui Liu",
                "Hengshuang Zhao",
                "Yu Liu",
                "Yingya Zhang",
                "Yujiu Yang"
            ],
            "arxiv_id": "2512.08765v1",
            "summary": "We present Wan-Move, a simple and scalable framework that brings motion control to video generative models. Existing motion-controllable methods typically suffer from coarse control granularity and limited scalability, leaving their outputs insufficient for practical use. We narrow this gap by achieving precise and high-quality motion control. Our core idea is to directly make the original condition features motion-aware for guiding video synthesis. To this end, we first represent object motions with dense point trajectories, allowing fine-grained control over the scene. We then project these trajectories into latent space and propagate the first frame's features along each trajectory, producing an aligned spatiotemporal feature map that tells how each scene element should move. This feature map serves as the updated latent condition, which is naturally integrated into the off-the-shelf image-to-video model, e.g., Wan-I2V-14B, as motion guidance without any architecture change. It removes the need for auxiliary motion encoders and makes fine-tuning base models easily scalable. Through scaled training, Wan-Move generates 5-second, 480p videos whose motion controllability rivals Kling 1.5 Pro's commercial Motion Brush, as indicated by user studies. To support comprehensive evaluation, we further design MoveBench, a rigorously curated benchmark featuring diverse content categories and hybrid-verified annotations. It is distinguished by larger data volume, longer video durations, and high-quality motion annotations. Extensive experiments on MoveBench and the public dataset consistently show Wan-Move's superior motion quality. Code, models, and benchmark data are made publicly available.",
            "headline_zh": "提出Wan-Move框架，通过潜在轨迹引导实现视频生成中的精确运动控制。",
            "intro_zh": [
                "现有方法运动控制粒度粗且可扩展性有限，难以满足实际应用需求。",
                "核心方法是将密集点轨迹投影到潜在空间，传播首帧特征以生成对齐的时空特征图作为运动指导。",
                "实验表明，Wan-Move在MoveBench基准上生成5秒480p视频，运动可控性媲美商业工具，并公开代码与数据。"
            ],
            "tags_zh": [
                "视频生成",
                "运动控制",
                "潜在轨迹",
                "时空特征",
                "基准评估",
                "可扩展框架"
            ],
            "_index": 52
        },
        {
            "title": "Learning and Editing Universal Graph Prompt Tuning via Reinforcement Learning",
            "authors": [
                "Jinfeng Xu",
                "Zheyu Chen",
                "Shuo Yang",
                "Jinze Li",
                "Hewei Wang",
                "Yijie Li",
                "Edith C. H. Ngai"
            ],
            "arxiv_id": "2512.08763v1",
            "summary": "Early graph prompt tuning approaches relied on task-specific designs for Graph Neural Networks (GNNs), limiting their adaptability across diverse pre-training strategies. In contrast, another promising line of research has investigated universal graph prompt tuning, which operates directly in the input graph's feature space and builds a theoretical foundation that universal graph prompt tuning can theoretically achieve an equivalent effect of any prompting function, eliminating dependence on specific pre-training strategies. Recent works propose selective node-based graph prompt tuning to pursue more ideal prompts. However, we argue that selective node-based graph prompt tuning inevitably compromises the theoretical foundation of universal graph prompt tuning. In this paper, we strengthen the theoretical foundation of universal graph prompt tuning by introducing stricter constraints, demonstrating that adding prompts to all nodes is a necessary condition for achieving the universality of graph prompts. To this end, we propose a novel model and paradigm, Learning and Editing Universal GrAph Prompt Tuning (LEAP), which preserves the theoretical foundation of universal graph prompt tuning while pursuing more ideal prompts. Specifically, we first build the basic universal graph prompts to preserve the theoretical foundation and then employ actor-critic reinforcement learning to select nodes and edit prompts. Extensive experiments on graph- and node-level tasks across various pre-training strategies in both full-shot and few-shot scenarios show that LEAP consistently outperforms fine-tuning and other prompt-based approaches.",
            "headline_zh": "提出LEAP模型以强化通用图提示调优的理论基础并提升性能",
            "intro_zh": [
                "早期图提示调优依赖任务特定设计，限制跨预训练策略的适应性",
                "LEAP通过全节点提示保持理论基础，并利用强化学习编辑提示",
                "实验表明LEAP在全样本和少样本场景下优于微调和其他提示方法"
            ],
            "tags_zh": [
                "图神经网络",
                "提示调优",
                "强化学习",
                "通用图提示",
                "节点选择",
                "少样本学习"
            ],
            "_index": 53
        },
        {
            "title": "Performance Comparison of Aerial RIS and STAR-RIS in 3D Wireless Environments",
            "authors": [
                "Dongdong Yang",
                "Bin Li",
                "Jiguang He"
            ],
            "arxiv_id": "2512.08755v1",
            "summary": "Reconfigurable intelligent surface (RIS) and simultaneously transmitting and reflecting RIS (STAR-RIS) have emerged as key enablers for enhancing wireless coverage and capacity in next-generation networks. When mounted on unmanned aerial vehicles (UAVs), they benefit from flexible deployment and improved line-of-sight conditions. Despite their promising potential, a comprehensive performance comparison between aerial RIS and STAR-RIS architectures has not been thoroughly investigated. This letter presents a detailed performance comparison between aerial RIS and STAR-RIS in three-dimensional wireless environments. Accurate channel models incorporating directional radiation patterns are established, and the influence of deployment altitude and orientation is thoroughly examined. To optimize the system sum-rate, we formulate joint optimization problems for both architectures and propose an efficient solution based on the weighted minimum mean square error and block coordinate descent algorithms. Simulation results reveal that STAR-RIS outperforms RIS in low-altitude scenarios due to its full-space coverage capability, whereas RIS delivers better performance near the base station at higher altitudes. The findings provide practical insights for the deployment of aerial intelligent surfaces in future 6G communication systems.",
            "headline_zh": "比较空中RIS与STAR-RIS在三维无线环境中的性能，优化部署策略以提升系统总速率。",
            "intro_zh": [
                "核心问题：空中RIS与STAR-RIS在三维无线环境中的性能对比尚未充分研究。",
                "方法要点：建立精确信道模型，基于WMMSE和块坐标下降算法优化系统总速率。",
                "实验或效果：STAR-RIS在低空场景表现更优，RIS在高空近基站处性能更好。"
            ],
            "tags_zh": [
                "可重构智能表面",
                "同时传输与反射RIS",
                "三维无线环境",
                "系统总速率优化",
                "无人机部署",
                "6G通信系统"
            ],
            "_index": 54
        },
        {
            "title": "A Multi-Robot Platform for Robotic Triage Combining Onboard Sensing and Foundation Models",
            "authors": [
                "Jason Hughes",
                "Marcel Hussing",
                "Edward Zhang",
                "Shenbagaraj Kannapiran",
                "Joshua Caswell",
                "Kenneth Chaney",
                "Ruichen Deng",
                "Michaela Feehery",
                "Agelos Kratimenos",
                "Yi Fan Li",
                "Britny Major",
                "Ethan Sanchez",
                "Sumukh Shrote",
                "Youkang Wang",
                "Jeremy Wang",
                "Daudi Zein",
                "Luying Zhang",
                "Ruijun Zhang",
                "Alex Zhou",
                "Tenzi Zhouga",
                "Jeremy Cannon",
                "Zaffir Qasim",
                "Jay Yelon",
                "Fernando Cladera",
                "Kostas Daniilidis",
                "Camillo J. Taylor",
                "Eric Eaton"
            ],
            "arxiv_id": "2512.08754v1",
            "summary": "This report presents a heterogeneous robotic system designed for remote primary triage in mass-casualty incidents (MCIs). The system employs a coordinated air-ground team of unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) to locate victims, assess their injuries, and prioritize medical assistance without risking the lives of first responders. The UAV identify and provide overhead views of casualties, while UGVs equipped with specialized sensors measure vital signs and detect and localize physical injuries. Unlike previous work that focused on exploration or limited medical evaluation, this system addresses the complete triage process: victim localization, vital sign measurement, injury severity classification, mental status assessment, and data consolidation for first responders. Developed as part of the DARPA Triage Challenge, this approach demonstrates how multi-robot systems can augment human capabilities in disaster response scenarios to maximize lives saved.",
            "headline_zh": "提出异构多机器人系统，结合机载传感与基础模型，用于大规模伤亡事件中的远程初级分诊。",
            "intro_zh": [
                "核心问题：大规模伤亡事件中，急救人员面临风险，需远程高效定位伤员并评估伤情以优先医疗援助。",
                "方法要点：采用无人机与地面车辆协同，无人机定位并提供俯视视图，地面车辆测量生命体征并检测物理损伤，整合基础模型完成完整分诊流程。",
                "实验或效果：作为DARPA分诊挑战赛的一部分，系统展示了多机器人系统在灾难响应中增强人类能力以最大化救援效果。"
            ],
            "tags_zh": [
                "多机器人系统",
                "远程分诊",
                "无人机-地面车辆协同",
                "机载传感",
                "基础模型",
                "灾难响应"
            ],
            "_index": 55
        },
        {
            "title": "Skewness-Guided Pruning of Multimodal Swin Transformers for Federated Skin Lesion Classification on Edge Devices",
            "authors": [
                "Kuniko Paxton",
                "Koorosh Aslansefat",
                "Dhavalkumar Thakker",
                "Yiannis Papadopoulos"
            ],
            "arxiv_id": "2512.08751v1",
            "summary": "In recent years, high-performance computer vision models have achieved remarkable success in medical imaging, with some skin lesion classification systems even surpassing dermatology specialists in diagnostic accuracy. However, such models are computationally intensive and large in size, making them unsuitable for deployment on edge devices. In addition, strict privacy constraints hinder centralized data management, motivating the adoption of Federated Learning (FL). To address these challenges, this study proposes a skewness-guided pruning method that selectively prunes the Multi-Head Self-Attention and Multi-Layer Perceptron layers of a multimodal Swin Transformer based on the statistical skewness of their output distributions. The proposed method was validated in a horizontal FL environment and shown to maintain performance while substantially reducing model complexity. Experiments on the compact Swin Transformer demonstrate approximately 36\\% model size reduction with no loss in accuracy. These findings highlight the feasibility of achieving efficient model compression and privacy-preserving distributed learning for multimodal medical AI on edge devices.",
            "headline_zh": "提出基于偏度引导的剪枝方法，用于联邦学习下边缘设备的多模态皮肤病变分类。",
            "intro_zh": [
                "核心问题：高精度医学视觉模型计算量大、隐私限制，难以部署于边缘设备。",
                "方法要点：基于输出分布偏度，选择性剪枝多模态Swin Transformer的自注意力和多层感知机层。",
                "实验或效果：在联邦学习环境中验证，模型大小减少约36%，准确率无损失。"
            ],
            "tags_zh": [
                "联邦学习",
                "模型剪枝",
                "多模态Swin Transformer",
                "皮肤病变分类",
                "边缘计算"
            ],
            "_index": 56
        },
        {
            "title": "A Scalable Pipeline Combining Procedural 3D Graphics and Guided Diffusion for Photorealistic Synthetic Training Data Generation in White Button Mushroom Segmentation",
            "authors": [
                "Artúr I. Károly",
                "Péter Galambos"
            ],
            "arxiv_id": "2512.08747v1",
            "summary": "Industrial mushroom cultivation increasingly relies on computer vision for monitoring and automated harvesting. However, developing accurate detection and segmentation models requires large, precisely annotated datasets that are costly to produce. Synthetic data provides a scalable alternative, yet often lacks sufficient realism to generalize to real-world scenarios. This paper presents a novel workflow that integrates 3D rendering in Blender with a constrained diffusion model to automatically generate high-quality annotated, photorealistic synthetic images of Agaricus Bisporus mushrooms. This approach preserves full control over 3D scene configuration and annotations while achieving photorealism without the need for specialized computer graphics expertise. We release two synthetic datasets (each containing 6,000 images depicting over 250k mushroom instances) and evaluate Mask R-CNN models trained on them in a zero-shot setting. When tested on two independent real-world datasets (including a newly collected benchmark), our method achieves state-of-the-art segmentation performance (F1 = 0.859 on M18K), despite using only synthetic training data. Although the approach is demonstrated on Agaricus Bisporus mushrooms, the proposed pipeline can be readily adapted to other mushroom species or to other agricultural domains, such as fruit and leaf detection.",
            "headline_zh": "提出结合3D渲染与约束扩散的流程，以生成逼真合成数据用于蘑菇分割。",
            "intro_zh": [
                "工业蘑菇种植需大量标注数据，但真实数据获取成本高且合成数据常缺乏真实感。",
                "方法集成Blender 3D渲染与约束扩散模型，自动生成高质量逼真合成图像，保留场景控制。",
                "在零样本设置下，基于合成数据训练的Mask R-CNN在真实数据集上达到先进分割性能。"
            ],
            "tags_zh": [
                "合成数据生成",
                "3D渲染",
                "扩散模型",
                "蘑菇分割",
                "农业计算机视觉"
            ],
            "_index": 57
        },
        {
            "title": "Towards Foundation Models with Native Multi-Agent Intelligence",
            "authors": [
                "Shuyue Hu",
                "Haoyang Yan",
                "Yiqun Zhang",
                "Yang Chen",
                "Dongzhan Zhou",
                "Lei Bai"
            ],
            "arxiv_id": "2512.08743v1",
            "summary": "Foundation models (FMs) are increasingly assuming the role of the \"brain\" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.",
            "headline_zh": "提出基础模型原生多智能体智能框架，以解决单智能体能力不足问题",
            "intro_zh": [
                "核心问题：单智能体性能强不自动转化为稳健多智能体智能，需专门研究",
                "方法要点：识别理解、规划、高效通信和适应作为核心能力，并规划数据集、评估、训练和安全研究方向",
                "实验或效果：基于41个大语言模型提供实证证据，显示能力差距"
            ],
            "tags_zh": [
                "基础模型",
                "多智能体智能",
                "大语言模型",
                "智能体交互",
                "评估框架"
            ],
            "_index": 58
        },
        {
            "title": "Deconstructing the Dual Black Box:A Plug-and-Play Cognitive Framework for Human-AI Collaborative Enhancement and Its Implications for AI Governance",
            "authors": [
                "Yiming Lu"
            ],
            "arxiv_id": "2512.08740v1",
            "summary": "Currently, there exists a fundamental divide between the \"cognitive black box\" (implicit intuition) of human experts and the \"computational black box\" (untrustworthy decision-making) of artificial intelligence (AI). This paper proposes a new paradigm of \"human-AI collaborative cognitive enhancement,\" aiming to transform the dual black boxes into a composable, auditable, and extensible \"functional white-box\" system through structured \"meta-interaction.\" The core breakthrough lies in the \"plug-and-play cognitive framework\"--a computable knowledge package that can be extracted from expert dialogues and loaded into the Recursive Adversarial Meta-Thinking Network (RAMTN). This enables expert thinking, such as medical diagnostic logic and teaching intuition, to be converted into reusable and scalable public assets, realizing a paradigm shift from \"AI as a tool\" to \"AI as a thinking partner.\" This work not only provides the first engineering proof for \"cognitive equity\" but also opens up a new path for AI governance: constructing a verifiable and intervenable governance paradigm through \"transparency of interaction protocols\" rather than prying into the internal mechanisms of models. The framework is open-sourced to promote technology for good and cognitive inclusion. This paper is an independent exploratory research conducted by the author. All content presented, including the theoretical framework (RAMTN), methodology (meta-interaction), system implementation, and case validation, constitutes the author's individual research achievements.",
            "headline_zh": "提出可插拔认知框架，通过元交互实现人机协作认知增强与AI治理新范式",
            "intro_zh": [
                "核心问题：人类专家认知黑盒与AI计算黑盒间的根本隔阂，阻碍可信人机协作。",
                "方法要点：基于RAMTN网络，从专家对话提取可计算知识包，构建可组合、可审计的功能白盒系统。",
                "实验或效果：框架开源，提供认知公平的工程证明，支持医疗诊断、教学直觉等案例验证。"
            ],
            "tags_zh": [
                "人机协作认知增强",
                "可插拔认知框架",
                "元交互",
                "递归对抗元思考网络",
                "AI治理",
                "认知公平"
            ],
            "_index": 59
        },
        {
            "title": "Pose-Based Sign Language Spotting via an End-to-End Encoder Architecture",
            "authors": [
                "Samuel Ebimobowei Johnny",
                "Blessed Guda",
                "Emmanuel Enejo Aaron",
                "Assane Gueye"
            ],
            "arxiv_id": "2512.08738v1",
            "summary": "Automatic Sign Language Recognition (ASLR) has emerged as a vital field for bridging the gap between deaf and hearing communities. However, the problem of sign-to-sign retrieval or detecting a specific sign within a sequence of continuous signs remains largely unexplored. We define this novel task as Sign Language Spotting. In this paper, we present a first step toward sign language retrieval by addressing the challenge of detecting the presence or absence of a query sign video within a sentence-level gloss or sign video. Unlike conventional approaches that rely on intermediate gloss recognition or text-based matching, we propose an end-to-end model that directly operates on pose keypoints extracted from sign videos. Our architecture employs an encoder-only backbone with a binary classification head to determine whether the query sign appears within the target sequence. By focusing on pose representations instead of raw RGB frames, our method significantly reduces computational cost and mitigates visual noise. We evaluate our approach on the Word Presence Prediction dataset from the WSLP 2025 shared task, achieving 61.88\\% accuracy and 60.00\\% F1-score. These results demonstrate the effectiveness of our pose-based framework for Sign Language Spotting, establishing a strong foundation for future research in automatic sign language retrieval and verification. Code is available at https://github.com/EbimoJohnny/Pose-Based-Sign-Language-Spotting",
            "headline_zh": "提出基于姿态的端到端编码器架构，用于手语检索中的特定手势检测任务。",
            "intro_zh": [
                "核心问题：解决连续手语序列中特定手势的检测与检索，定义为手语定位任务。",
                "方法要点：直接利用姿态关键点，采用编码器架构进行二分类，避免中间文本匹配。",
                "实验或效果：在WSLP 2025数据集上达到61.88%准确率和60.00% F1分数，验证了框架有效性。"
            ],
            "tags_zh": [
                "手语定位",
                "姿态关键点",
                "端到端模型",
                "编码器架构",
                "二分类",
                "手语检索"
            ],
            "_index": 60
        },
        {
            "title": "Mitigating Individual Skin Tone Bias in Skin Lesion Classification through Distribution-Aware Reweighting",
            "authors": [
                "Kuniko Paxton",
                "Zeinab Dehghani",
                "Koorosh Aslansefat",
                "Dhavalkumar Thakker",
                "Yiannis Papadopoulos"
            ],
            "arxiv_id": "2512.08733v1",
            "summary": "Skin color has historically been a focal point of discrimination, yet fairness research in machine learning for medical imaging often relies on coarse subgroup categories, overlooking individual-level variations. Such group-based approaches risk obscuring biases faced by outliers within subgroups. This study introduces a distribution-based framework for evaluating and mitigating individual fairness in skin lesion classification. We treat skin tone as a continuous attribute rather than a categorical label, and employ kernel density estimation (KDE) to model its distribution. We further compare twelve statistical distance metrics to quantify disparities between skin tone distributions and propose a distance-based reweighting (DRW) loss function to correct underrepresentation in minority tones. Experiments across CNN and Transformer models demonstrate: (i) the limitations of categorical reweighting in capturing individual-level disparities, and (ii) the superior performance of distribution-based reweighting, particularly with Fidelity Similarity (FS), Wasserstein Distance (WD), Hellinger Metric (HM), and Harmonic Mean Similarity (HS). These findings establish a robust methodology for advancing fairness at individual level in dermatological AI systems, and highlight broader implications for sensitive continuous attributes in medical image analysis.",
            "headline_zh": "提出基于分布感知重加权的框架，以缓解皮肤病变分类中的个体肤色偏差。",
            "intro_zh": [
                "核心问题：传统基于粗粒度子组的公平性方法忽视个体肤色连续变化，可能导致组内异常值偏差被掩盖。",
                "方法要点：将肤色视为连续属性，使用核密度估计建模分布，并基于统计距离度量设计重加权损失函数。",
                "实验或效果：在CNN和Transformer模型上验证，分布感知重加权优于分类方法，特定距离度量如Fidelity Similarity表现更优。"
            ],
            "tags_zh": [
                "皮肤病变分类",
                "个体公平性",
                "分布感知重加权",
                "统计距离度量",
                "核密度估计",
                "医学图像分析"
            ],
            "_index": 61
        },
        {
            "title": "Neural Ordinary Differential Equations for Simulating Metabolic Pathway Dynamics from Time-Series Multiomics Data",
            "authors": [
                "Udesh Habaraduwa",
                "Andrei Lixandru"
            ],
            "arxiv_id": "2512.08732v1",
            "summary": "The advancement of human healthspan and bioengineering relies heavily on predicting the behavior of complex biological systems. While high-throughput multiomics data is becoming increasingly abundant, converting this data into actionable predictive models remains a bottleneck. High-capacity, datadriven simulation systems are critical in this landscape; unlike classical mechanistic models restricted by prior knowledge, these architectures can infer latent interactions directly from observational data, allowing for the simulation of temporal trajectories and the anticipation of downstream intervention effects in personalized medicine and synthetic biology. To address this challenge, we introduce Neural Ordinary Differential Equations (NODEs) as a dynamic framework for learning the complex interplay between the proteome and metabolome. We applied this framework to time-series data derived from engineered Escherichia coli strains, modeling the continuous dynamics of metabolic pathways. The proposed NODE architecture demonstrates superior performance in capturing system dynamics compared to traditional machine learning pipelines. Our results show a greater than 90% improvement in root mean squared error over baselines across both Limonene (up to 94.38% improvement) and Isopentenol (up to 97.65% improvement) pathway datasets. Furthermore, the NODE models demonstrated a 1000x acceleration in inference time, establishing them as a scalable, high-fidelity tool for the next generation of metabolic engineering and biological discovery.",
            "headline_zh": "提出神经常微分方程框架，从时序多组学数据模拟代谢通路动态",
            "intro_zh": [
                "问题：多组学数据丰富，但转化为可预测模型存在瓶颈，需数据驱动模拟系统。",
                "方法：使用神经常微分方程学习蛋白质组与代谢组间的复杂相互作用，建模连续动态。",
                "效果：在柠檬烯和异戊烯醇通路数据集上，均方根误差提升超90%，推理时间加速1000倍。"
            ],
            "tags_zh": [
                "神经常微分方程",
                "代谢通路模拟",
                "时序多组学数据",
                "数据驱动建模",
                "生物系统预测"
            ],
            "_index": 62
        },
        {
            "title": "SegEarth-OV3: Exploring SAM 3 for Open-Vocabulary Semantic Segmentation in Remote Sensing Images",
            "authors": [
                "Kaiyu Li",
                "Shengqi Zhang",
                "Yupeng Deng",
                "Zhi Wang",
                "Deyu Meng",
                "Xiangyong Cao"
            ],
            "arxiv_id": "2512.08730v1",
            "summary": "Most existing methods for training-free Open-Vocabulary Semantic Segmentation (OVSS) are based on CLIP. While these approaches have made progress, they often face challenges in precise localization or require complex pipelines to combine separate modules, especially in remote sensing scenarios where numerous dense and small targets are present. Recently, Segment Anything Model 3 (SAM 3) was proposed, unifying segmentation and recognition in a promptable framework. In this paper, we present a preliminary exploration of applying SAM 3 to the remote sensing OVSS task without any training. First, we implement a mask fusion strategy that combines the outputs from SAM 3's semantic segmentation head and the Transformer decoder (instance head). This allows us to leverage the strengths of both heads for better land coverage. Second, we utilize the presence score from the presence head to filter out categories that do not exist in the scene, reducing false positives caused by the vast vocabulary sizes and patch-level processing in geospatial scenes. We evaluate our method on extensive remote sensing datasets. Experiments show that this simple adaptation achieves promising performance, demonstrating the potential of SAM 3 for remote sensing OVSS. Our code is released at https://github.com/earth-insights/SegEarth-OV-3.",
            "headline_zh": "提出SegEarth-OV3，探索SAM 3在遥感图像开放词汇语义分割中的应用，无需训练。",
            "intro_zh": [
                "核心问题：现有基于CLIP的开放词汇语义分割方法在遥感场景中定位不精确或流程复杂。",
                "方法要点：结合SAM 3的语义分割头和Transformer解码器输出，并利用存在分数过滤不存在的类别。",
                "实验或效果：在遥感数据集上评估，简单适应展现出有前景的性能，验证了SAM 3的潜力。"
            ],
            "tags_zh": [
                "开放词汇语义分割",
                "遥感图像",
                "SAM 3",
                "掩码融合",
                "存在分数过滤",
                "无训练方法"
            ],
            "_index": 63
        },
        {
            "title": "Exposing Hidden Biases in Text-to-Image Models via Automated Prompt Search",
            "authors": [
                "Manos Plitsis",
                "Giorgos Bouritsas",
                "Vassilis Katsouros",
                "Yannis Panagakis"
            ],
            "arxiv_id": "2512.08724v1",
            "summary": "Text-to-image (TTI) diffusion models have achieved remarkable visual quality, yet they have been repeatedly shown to exhibit social biases across sensitive attributes such as gender, race and age. To mitigate these biases, existing approaches frequently depend on curated prompt datasets - either manually constructed or generated with large language models (LLMs) - as part of their training and/or evaluation procedures. Beside the curation cost, this also risks overlooking unanticipated, less obvious prompts that trigger biased generation, even in models that have undergone debiasing. In this work, we introduce Bias-Guided Prompt Search (BGPS), a framework that automatically generates prompts that aim to maximize the presence of biases in the resulting images. BGPS comprises two components: (1) an LLM instructed to produce attribute-neutral prompts and (2) attribute classifiers acting on the TTI's internal representations that steer the decoding process of the LLM toward regions of the prompt space that amplify the image attributes of interest. We conduct extensive experiments on Stable Diffusion 1.5 and a state-of-the-art debiased model and discover an array of subtle and previously undocumented biases that severely deteriorate fairness metrics. Crucially, the discovered prompts are interpretable, i.e they may be entered by a typical user, quantitatively improving the perplexity metric compared to a prominent hard prompt optimization counterpart. Our findings uncover TTI vulnerabilities, while BGPS expands the bias search space and can act as a new evaluation tool for bias mitigation.",
            "headline_zh": "提出Bias-Guided Prompt Search框架，通过自动提示搜索暴露文本到图像模型的隐藏偏见",
            "intro_zh": [
                "问题：现有方法依赖人工或LLM构建提示数据集，可能忽略触发偏见的未预期提示，影响偏见缓解效果。",
                "方法：结合LLM生成属性中性提示和属性分类器引导解码，自动搜索放大图像偏见的提示。",
                "实验：在Stable Diffusion 1.5和去偏见模型上发现新偏见，提示可解释且提升困惑度指标。"
            ],
            "tags_zh": [
                "文本到图像模型",
                "偏见检测",
                "提示搜索",
                "公平性评估",
                "扩散模型"
            ],
            "_index": 64
        },
        {
            "title": "Multi-domain performance analysis with scores tailored to user preferences",
            "authors": [
                "Sébastien Piérard",
                "Adrien Deliège",
                "Marc Van Droogenbroeck"
            ],
            "arxiv_id": "2512.08715v1",
            "summary": "The performance of algorithms, methods, and models tends to depend heavily on the distribution of cases on which they are applied, this distribution being specific to the applicative domain. After performing an evaluation in several domains, it is highly informative to compute a (weighted) mean performance and, as shown in this paper, to scrutinize what happens during this averaging. To achieve this goal, we adopt a probabilistic framework and consider a performance as a probability measure (e.g., a normalized confusion matrix for a classification task). It appears that the corresponding weighted mean is known to be the summarization, and that only some remarkable scores assign to the summarized performance a value equal to a weighted arithmetic mean of the values assigned to the domain-specific performances. These scores include the family of ranking scores, a continuum parameterized by user preferences, and that the weights to consider in the arithmetic mean depend on the user preferences. Based on this, we rigorously define four domains, named easiest, most difficult, preponderant, and bottleneck domains, as functions of user preferences. After establishing the theory in a general setting, regardless of the task, we develop new visual tools for two-class classification.",
            "headline_zh": "提出基于用户偏好多域性能分析方法，定义关键域并开发可视化工具",
            "intro_zh": [
                "核心问题：算法性能依赖应用域分布，需多域评估与加权平均分析",
                "方法要点：采用概率框架，识别满足加权算术平均的评分族，定义四种关键域",
                "实验或效果：针对二分类任务开发新可视化工具，支持性能分析"
            ],
            "tags_zh": [
                "多域性能分析",
                "用户偏好评分",
                "加权平均",
                "概率框架",
                "二分类可视化"
            ],
            "_index": 65
        },
        {
            "title": "Automatic Essay Scoring and Feedback Generation in Basque Language Learning",
            "authors": [
                "Ekhi Azurmendi",
                "Xabier Arregi",
                "Oier Lopez de Lacalle"
            ],
            "arxiv_id": "2512.08713v1",
            "summary": "This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.",
            "headline_zh": "提出首个巴斯克语自动作文评分与反馈生成数据集及模型，提升低资源语言教育NLP研究基础。",
            "intro_zh": [
                "核心问题：巴斯克语等低资源语言缺乏公开的自动作文评分数据集与反馈生成基准。",
                "方法要点：构建包含3200篇C1水平作文的数据集，并微调RoBERTa-EusCrawl和Latxa模型进行评分与解释生成。",
                "实验或效果：微调Latxa模型在评分一致性和反馈质量上超越GPT-5等闭源系统，并建立新评估方法验证反馈有效性。"
            ],
            "tags_zh": [
                "自动作文评分",
                "反馈生成",
                "巴斯克语处理",
                "低资源语言NLP",
                "模型微调",
                "教育技术"
            ],
            "_index": 66
        },
        {
            "title": "Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design",
            "authors": [
                "Jannik Graebner",
                "Ryne Beeson"
            ],
            "arxiv_id": "2512.08705v1",
            "summary": "Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase.",
            "headline_zh": "提出梯度信息蒙特卡洛微调扩散模型以优化低推力轨迹设计",
            "intro_zh": [
                "核心问题：低推力轨迹设计在复杂目标景观中面临全局搜索困难，存在多个局部最优解。",
                "方法要点：扩展自监督扩散模型微调框架，结合梯度信息马尔可夫链蒙特卡洛算法（MALA和HMC）加速收敛。",
                "实验或效果：在土卫六系统多圈转移任务中，MALA将可行性率从17.34%提升至63.01，并生成更密集、多样化的帕累托前沿。"
            ],
            "tags_zh": [
                "低推力轨迹设计",
                "扩散模型",
                "马尔可夫链蒙特卡洛",
                "梯度信息采样",
                "帕累托优化",
                "自监督学习"
            ],
            "_index": 67
        },
        {
            "title": "Scale-invariant and View-relational Representation Learning for Full Surround Monocular Depth",
            "authors": [
                "Kyumin Hwang",
                "Wonhyeok Choi",
                "Kiljoon Han",
                "Wonjoon Choi",
                "Minwoo Choi",
                "Yongcheon Na",
                "Minwoo Park",
                "Sunghoon Im"
            ],
            "arxiv_id": "2512.08700v1",
            "summary": "Recent foundation models demonstrate strong generalization capabilities in monocular depth estimation. However, directly applying these models to Full Surround Monocular Depth Estimation (FSMDE) presents two major challenges: (1) high computational cost, which limits real-time performance, and (2) difficulty in estimating metric-scale depth, as these models are typically trained to predict only relative depth. To address these limitations, we propose a novel knowledge distillation strategy that transfers robust depth knowledge from a foundation model to a lightweight FSMDE network. Our approach leverages a hybrid regression framework combining the knowledge distillation scheme--traditionally used in classification--with a depth binning module to enhance scale consistency. Specifically, we introduce a cross-interaction knowledge distillation scheme that distills the scale-invariant depth bin probabilities of a foundation model into the student network while guiding it to infer metric-scale depth bin centers from ground-truth depth. Furthermore, we propose view-relational knowledge distillation, which encodes structural relationships among adjacent camera views and transfers them to enhance cross-view depth consistency. Experiments on DDAD and nuScenes demonstrate the effectiveness of our method compared to conventional supervised methods and existing knowledge distillation approaches. Moreover, our method achieves a favorable trade-off between performance and efficiency, meeting real-time requirements.",
            "headline_zh": "提出跨交互与视图关系知识蒸馏策略，以解决全环绕单目深度估计中的计算成本高和尺度估计难问题。",
            "intro_zh": [
                "核心问题：现有基础模型在全环绕单目深度估计中计算成本高且难以预测度量尺度深度。",
                "方法要点：采用混合回归框架，结合知识蒸馏和深度分箱模块，通过跨交互和视图关系蒸馏提升尺度一致性和跨视图深度一致性。",
                "实验或效果：在DDAD和nuScenes数据集上验证有效性，实现性能与效率的平衡，满足实时需求。"
            ],
            "tags_zh": [
                "全环绕单目深度估计",
                "知识蒸馏",
                "尺度不变表示",
                "视图关系学习",
                "实时性能优化"
            ],
            "_index": 68
        },
        {
            "title": "An Additive Manufacturing Part Qualification Framework: Transferring Knowledge of Stress-strain Behaviors from Additively Manufactured Polymers to Metals",
            "authors": [
                "Chenglong Duan",
                "Dazhong Wu"
            ],
            "arxiv_id": "2512.08699v1",
            "summary": "Part qualification is crucial in additive manufacturing (AM) because it ensures that additively manufactured parts can be consistently produced and reliably used in critical applications. Part qualification aims at verifying that an additively manufactured part meets performance requirements; therefore, predicting the complex stress-strain behaviors of additively manufactured parts is critical. We develop a dynamic time warping (DTW)-transfer learning (TL) framework for additive manufacturing part qualification by transferring knowledge of the stress-strain behaviors of additively manufactured low-cost polymers to metals. Specifically, the framework employs DTW to select a polymer dataset as the source domain that is the most relevant to the target metal dataset. Using a long short-term memory (LSTM) model, four source polymers (i.e., Nylon, PLA, CF-ABS, and Resin) and three target metals (i.e., AlSi10Mg, Ti6Al4V, and carbon steel) that are fabricated by different AM techniques are utilized to demonstrate the effectiveness of the DTW-TL framework. Experimental results show that the DTW-TL framework identifies the closest match between polymers and metals to select one single polymer dataset as the source domain. The DTW-TL model achieves the lowest mean absolute percentage error of 12.41% and highest coefficient of determination of 0.96 when three metals are used as the target domain, respectively, outperforming the vanilla LSTM model without TL as well as the TL model pre-trained on four polymer datasets as the source domain.",
            "headline_zh": "提出动态时间规整-迁移学习框架，通过聚合物知识迁移实现增材制造金属部件应力应变行为预测",
            "intro_zh": [
                "核心问题：增材制造部件认证需准确预测复杂应力应变行为，但金属数据稀缺。",
                "方法要点：使用DTW选择最相关聚合物源域，结合LSTM模型进行知识迁移。",
                "实验效果：在三种金属上，DTW-TL模型误差最低12.41%，决定系数最高0.96，优于基准模型。"
            ],
            "tags_zh": [
                "增材制造",
                "迁移学习",
                "动态时间规整",
                "长短期记忆网络",
                "应力应变预测",
                "部件认证"
            ],
            "_index": 69
        },
        {
            "title": "What really matters for person re-identification? A Mixture-of-Experts Framework for Semantic Attribute Importance",
            "authors": [
                "Athena Psalta",
                "Vasileios Tsironis",
                "Konstantinos Karantzalos"
            ],
            "arxiv_id": "2512.08697v1",
            "summary": "State-of-the-art person re-identification methods achieve impressive accuracy but remain largely opaque, leaving open the question: which high-level semantic attributes do these models actually rely on? We propose MoSAIC-ReID, a Mixture-of-Experts framework that systematically quantifies the importance of pedestrian attributes for re-identification. Our approach uses LoRA-based experts, each linked to a single attribute, and an oracle router that enables controlled attribution analysis. While MoSAIC-ReID achieves competitive performance on Market-1501 and DukeMTMC under the assumption that attribute annotations are available at test time, its primary value lies in providing a large-scale, quantitative study of attribute importance across intrinsic and extrinsic cues. Using generalized linear models, statistical tests, and feature-importance analyses, we reveal which attributes, such as clothing colors and intrinsic characteristics, contribute most strongly, while infrequent cues (e.g. accessories) have limited effect. This work offers a principled framework for interpretable ReID and highlights the requirements for integrating explicit semantic knowledge in practice. Code is available at https://github.com/psaltaath/MoSAIC-ReID",
            "headline_zh": "提出MoSAIC-ReID框架以量化行人重识别中语义属性的重要性",
            "intro_zh": [
                "核心问题：现有行人重识别模型依赖哪些高层语义属性不透明",
                "方法要点：基于LoRA的专家混合框架，每个专家关联单一属性，通过路由控制分析",
                "实验或效果：在Market-1501和DukeMTMC上实现竞争性能，量化分析属性重要性，揭示服装颜色等关键属性"
            ],
            "tags_zh": [
                "行人重识别",
                "属性重要性分析",
                "专家混合框架",
                "可解释性",
                "语义属性"
            ],
            "_index": 70
        },
        {
            "title": "Non Normalized Shared-Constraint Dynamic Games for Human-Robot Collaboration with Asymmetric Responsibility",
            "authors": [
                "Mark Pustilnik",
                "Francesco Borrelli"
            ],
            "arxiv_id": "2512.08688v1",
            "summary": "This paper proposes a dynamic game formulation for cooperative human-robot navigation in shared workspaces with obstacles, where the human and robot jointly satisfy shared safety constraints while pursuing a common task. A key contribution is the introduction of a non-normalized equilibrium structure for the shared constraints. This structure allows the two agents to contribute different levels of effort towards enforcing safety requirements such as collision avoidance and inter-players spacing. We embed this non-normalized equilibrium into a receding-horizon optimal control scheme.",
            "headline_zh": "提出非归一化共享约束动态博弈方法，用于人机协作导航中不对称责任的安全约束执行。",
            "intro_zh": [
                "核心问题：人机协作导航中，如何在共享工作空间内处理障碍物，并允许双方以不同努力水平满足安全约束。",
                "方法要点：引入非归一化均衡结构，嵌入滚动时域最优控制方案，实现不对称责任下的共享约束动态博弈。",
                "实验或效果：未知。"
            ],
            "tags_zh": [
                "人机协作",
                "动态博弈",
                "共享约束",
                "非归一化均衡",
                "滚动时域控制",
                "安全导航"
            ],
            "_index": 71
        },
        {
            "title": "Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology",
            "authors": [
                "Rongzhao Zhang",
                "Junqiao Wang",
                "Shuyun Yang",
                "Mouxiao Bian",
                "Chao Ding",
                "Yuwei Bai",
                "Chihao Zhang",
                "Yuguang Shen",
                "Lei Wang",
                "Lei Zheng",
                "Qiujuan Yan",
                "Yun Zhong",
                "Meiling Liu",
                "Jiwei Yu",
                "Zheng Wang",
                "Jie Xu",
                "Meng Luo"
            ],
            "arxiv_id": "2512.08674v1",
            "summary": "Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.",
            "headline_zh": "提出分层多智能体框架以解决胃肠道肿瘤学中多模态临床推理的上下文稀释和幻觉问题",
            "intro_zh": [
                "核心问题：多模态大语言模型在复杂异构医疗数据中面临上下文稀释和幻觉挑战",
                "方法要点：模拟多学科团队协作，采用分层多智能体框架集成内镜、放射学和生化数据",
                "实验或效果：系统获得4.60/5.00专家评分，在推理逻辑和医学准确性上显著优于基线"
            ],
            "tags_zh": [
                "多模态临床推理",
                "多智能体框架",
                "胃肠道肿瘤学",
                "决策支持系统",
                "医学人工智能"
            ],
            "_index": 72
        },
        {
            "title": "Dual-Branch Center-Surrounding Contrast: Rethinking Contrastive Learning for 3D Point Clouds",
            "authors": [
                "Shaofeng Zhang",
                "Xuanqi Chen",
                "Xiangdong Zhang",
                "Sitong Wu",
                "Junchi Yan"
            ],
            "arxiv_id": "2512.08673v1",
            "summary": "Most existing self-supervised learning (SSL) approaches for 3D point clouds are dominated by generative methods based on Masked Autoencoders (MAE). However, these generative methods have been proven to struggle to capture high-level discriminative features effectively, leading to poor performance on linear probing and other downstream tasks. In contrast, contrastive methods excel in discriminative feature representation and generalization ability on image data. Despite this, contrastive learning (CL) in 3D data remains scarce. Besides, simply applying CL methods designed for 2D data to 3D fails to effectively learn 3D local details. To address these challenges, we propose a novel Dual-Branch \\textbf{C}enter-\\textbf{S}urrounding \\textbf{Con}trast (CSCon) framework. Specifically, we apply masking to the center and surrounding parts separately, constructing dual-branch inputs with center-biased and surrounding-biased representations to better capture rich geometric information. Meanwhile, we introduce a patch-level contrastive loss to further enhance both high-level information and local sensitivity. Under the FULL and ALL protocols, CSCon achieves performance comparable to generative methods; under the MLP-LINEAR, MLP-3, and ONLY-NEW protocols, our method attains state-of-the-art results, even surpassing cross-modal approaches. In particular, under the MLP-LINEAR protocol, our method outperforms the baseline (Point-MAE) by \\textbf{7.9\\%}, \\textbf{6.7\\%}, and \\textbf{10.3\\%} on the three variants of ScanObjectNN, respectively. The code will be made publicly available.",
            "headline_zh": "提出双分支中心-周围对比框架以改进3D点云的自监督学习",
            "intro_zh": [
                "问题：现有3D点云自监督学习以生成方法为主，但难以捕获高层判别特征，对比方法在3D中应用不足且直接迁移2D方法效果不佳。",
                "方法：通过分别掩码中心和周围部分构建双分支输入，结合补丁级对比损失增强几何信息捕获和局部敏感性。",
                "效果：在多个协议下达到与生成方法相当或更优性能，尤其在MLP-LINEAR协议下显著超越基线方法。"
            ],
            "tags_zh": [
                "3D点云",
                "自监督学习",
                "对比学习",
                "双分支架构",
                "几何特征学习"
            ],
            "_index": 73
        },
        {
            "title": "DS FedProxGrad: Asymptotic Stationarity Without Noise Floor in Fair Federated Learning",
            "authors": [
                "Huzaifa Arif"
            ],
            "arxiv_id": "2512.08671v1",
            "summary": "Recent work \\cite{arifgroup} introduced Federated Proximal Gradient \\textbf{(\\texttt{FedProxGrad})} for solving non-convex composite optimization problems in group fair federated learning. However, the original analysis established convergence only to a \\textit{noise-dominated neighborhood of stationarity}, with explicit dependence on a variance-induced noise floor. In this work, we provide an improved asymptotic convergence analysis for a generalized \\texttt{FedProxGrad}-type analytical framework with inexact local proximal solutions and explicit fairness regularization. We call this extended analytical framework \\textbf{DS \\texttt{FedProxGrad}} (Decay Step Size \\texttt{FedProxGrad}). Under a Robbins-Monro step-size schedule \\cite{robbins1951stochastic} and a mild decay condition on local inexactness, we prove that $\\liminf_{r\\to\\infty} \\mathbb{E}[\\|\\nabla F(\\mathbf{x}^r)\\|^2] = 0$, i.e., the algorithm is asymptotically stationary and the convergence rate does not depend on a variance-induced noise floor.",
            "headline_zh": "提出DS FedProxGrad以在公平联邦学习中实现无噪声底限的渐近平稳性",
            "intro_zh": [
                "原FedProxGrad在公平联邦学习中收敛至噪声主导邻域，存在方差诱导的噪声底限问题",
                "扩展为DS FedProxGrad框架，结合衰减步长和不精确局部解，证明渐近平稳性",
                "在Robbins-Monro步长调度下，实现梯度范数平方期望的极限为零，消除噪声底限依赖"
            ],
            "tags_zh": [
                "公平联邦学习",
                "非凸优化",
                "渐近收敛",
                "衰减步长",
                "近端梯度方法"
            ],
            "_index": 74
        },
        {
            "title": "Direct transfer of optimized controllers to similar systems using dimensionless MPC",
            "authors": [
                "Josip Kir Hromatko",
                "Shambhuraj Sawant",
                "Šandor Ileš",
                "Sébastien Gros"
            ],
            "arxiv_id": "2512.08667v1",
            "summary": "Scaled model experiments are commonly used in various engineering fields to reduce experimentation costs and overcome constraints associated with full-scale systems. The relevance of such experiments relies on dimensional analysis and the principle of dynamic similarity. However, transferring controllers to full-scale systems often requires additional tuning. In this paper, we propose a method to enable a direct controller transfer using dimensionless model predictive control, tuned automatically for closed-loop performance. With this reformulation, the closed-loop behavior of an optimized controller transfers directly to a new, dynamically similar system. Additionally, the dimensionless formulation allows for the use of data from systems of different scales during parameter optimization. We demonstrate the method on a cartpole swing-up and a car racing problem, applying either reinforcement learning or Bayesian optimization for tuning the controller parameters. Software used to obtain the results in this paper is publicly available at https://github.com/josipkh/dimensionless-mpcrl.",
            "headline_zh": "提出基于无量纲模型预测控制的直接控制器迁移方法，以解决相似系统间控制器转移需额外调优的问题。",
            "intro_zh": [
                "核心问题：缩比模型实验中控制器迁移至全尺寸系统常需额外调优，增加成本与复杂性。",
                "方法要点：通过无量纲模型预测控制，实现优化控制器在动态相似系统间的直接迁移，并支持多尺度数据用于参数优化。",
                "实验或效果：在倒立摆起摆和赛车控制问题中，结合强化学习或贝叶斯优化调参，验证了方法的有效性。"
            ],
            "tags_zh": [
                "无量纲模型预测控制",
                "控制器迁移",
                "动态相似性",
                "参数优化",
                "缩比实验"
            ],
            "_index": 75
        },
        {
            "title": "Ergodic Trajectory Planning with Dynamic Sensor Footprints",
            "authors": [
                "Ziyue Zheng",
                "Yongce Liu",
                "Hesheng Wang",
                "Zhongqiang Ren"
            ],
            "arxiv_id": "2512.08661v1",
            "summary": "This paper addresses the problem of trajectory planning for information gathering with a dynamic and resolution-varying sensor footprint. Ergodic planning offers a principled framework that balances exploration (visiting all areas) and exploitation (focusing on high-information regions) by planning trajectories such that the time spent in a region is proportional to the amount of information in that region. Existing ergodic planning often oversimplifies the sensing model by assuming a point sensor or a footprint with constant shape and resolution. In practice, the sensor footprint can drastically change over time as the robot moves, such as aerial robots equipped with downward-facing cameras, whose field of view depends on the orientation and altitude. To overcome this limitation, we propose a new metric that accounts for dynamic sensor footprints, analyze the theoretic local optimality conditions, and propose numerical trajectory optimization algorithms. Experimental results show that the proposed approach can simultaneously optimize both the trajectories and sensor footprints, with up to an order of magnitude better ergodicity than conventional methods. We also deploy our approach in a multi-drone system to ergodically cover an object in 3D space.",
            "headline_zh": "提出动态传感器足迹的遍历轨迹规划方法，以优化信息采集任务",
            "intro_zh": [
                "核心问题：现有遍历规划假设传感器足迹固定，忽略动态变化如无人机相机视角随姿态和高度变化",
                "方法要点：引入新度量考虑动态足迹，分析局部最优条件，开发数值轨迹优化算法",
                "实验或效果：实验显示方法能同时优化轨迹和足迹，遍历性比传统方法提升一个数量级，并应用于多无人机3D物体覆盖"
            ],
            "tags_zh": [
                "遍历规划",
                "动态传感器足迹",
                "轨迹优化",
                "信息采集",
                "多无人机系统",
                "3D覆盖"
            ],
            "_index": 76
        },
        {
            "title": "An Agentic AI System for Multi-Framework Communication Coding",
            "authors": [
                "Bohao Yang",
                "Rui Yang",
                "Joshua M. Biro",
                "Haoyuan Wang",
                "Jessica L. Handley",
                "Brianna Richardson",
                "Sophia Bessias",
                "Nicoleta Economou-Zavlanos",
                "Armando D. Bedoya",
                "Monica Agrawal",
                "Michael M. Zavlanos",
                "Anand Chowdhury",
                "Raj M. Ratwani",
                "Kai Sun",
                "Kathryn I. Pollak",
                "Michael J. Pencina",
                "Chuan Hong"
            ],
            "arxiv_id": "2512.08659v1",
            "summary": "Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.",
            "headline_zh": "提出基于多智能体架构的MOSAIC系统，用于临床沟通编码以解决标注可扩展性问题。",
            "intro_zh": [
                "核心问题：临床沟通标注依赖人工，存在劳动密集、不一致和难以扩展的挑战。",
                "方法要点：采用LangGraph架构协调四个核心智能体，结合检索增强生成和动态少样本提示进行编码。",
                "实验或效果：在风湿病和妇产科领域测试，整体F1分数达0.928，优于基准方法。"
            ],
            "tags_zh": [
                "临床沟通编码",
                "多智能体系统",
                "检索增强生成",
                "动态少样本提示",
                "LangGraph架构"
            ],
            "_index": 77
        },
        {
            "title": "Reusability in MLOps: Leveraging Ports and Adapters to Build a Microservices Architecture for the Maritime Domain",
            "authors": [
                "Renato Cordeiro Ferreira",
                "Aditya Dhinavahi",
                "Rowanne Trapmann",
                "Willem-Jan van den Heuvel"
            ],
            "arxiv_id": "2512.08657v1",
            "summary": "ML-Enabled Systems (MLES) are inherently complex since they require multiple components to achieve their business goal. This experience report showcases the software architecture reusability techniques applied while building Ocean Guard, an MLES for anomaly detection in the maritime domain. In particular, it highlights the challenges and lessons learned to reuse the Ports and Adapters pattern to support building multiple microservices from a single codebase. This experience report hopes to inspire software engineers, machine learning engineers, and data scientists to apply the Hexagonal Architecture pattern to build their MLES.",
            "headline_zh": "应用端口与适配器模式构建可复用的MLOps微服务架构，以支持海事领域异常检测系统。",
            "intro_zh": [
                "核心问题：MLES组件复杂，难以复用，影响开发效率。",
                "方法要点：采用端口与适配器模式，从单一代码库构建多个微服务。",
                "实验或效果：经验报告展示架构实践，旨在启发工程师应用六边形架构。"
            ],
            "tags_zh": [
                "MLOps",
                "端口与适配器模式",
                "微服务架构",
                "海事异常检测",
                "软件架构复用",
                "六边形架构"
            ],
            "_index": 78
        },
        {
            "title": "Sim2Swim: Zero-Shot Velocity Control for Agile AUV Maneuvering in 3 Minutes",
            "authors": [
                "Lauritz Rismark Fosso",
                "Herman Biørn Amundsen",
                "Marios Xanthidis",
                "Sveinung Johan Ohrem"
            ],
            "arxiv_id": "2512.08656v1",
            "summary": "Holonomic autonomous underwater vehicles (AUVs) have the hardware ability for agile maneuvering in both translational and rotational degrees of freedom (DOFs). However, due to challenges inherent to underwater vehicles, such as complex hydrostatics and hydrodynamics, parametric uncertainties, and frequent changes in dynamics due to payload changes, control is challenging. Performance typically relies on carefully tuned controllers targeting unique platform configurations, and a need for re-tuning for deployment under varying payloads and hydrodynamic conditions. As a consequence, agile maneuvering with simultaneous tracking of time-varying references in both translational and rotational DOFs is rarely utilized in practice. To the best of our knowledge, this paper presents the first general zero-shot sim2real deep reinforcement learning-based (DRL) velocity controller enabling path following and agile 6DOF maneuvering with a training duration of just 3 minutes. Sim2Swim, the proposed approach, inspired by state-of-the-art DRL-based position control, leverages domain randomization and massively parallelized training to converge to field-deployable control policies for AUVs of variable characteristics without post-processing or tuning. Sim2Swim is extensively validated in pool trials for a variety of configurations, showcasing robust control for highly agile motions.",
            "headline_zh": "提出Sim2Swim零样本深度强化学习速度控制器，实现水下机器人敏捷6自由度操控",
            "intro_zh": [
                "水下机器人因复杂流体动力学和参数不确定性，敏捷操控面临挑战",
                "方法基于深度强化学习，利用域随机化和并行训练，无需调参即可部署",
                "实验在池中验证，展示了对多种配置的鲁棒控制和高度敏捷运动"
            ],
            "tags_zh": [
                "水下机器人控制",
                "深度强化学习",
                "零样本学习",
                "敏捷操控",
                "域随机化",
                "仿真到现实"
            ],
            "_index": 79
        },
        {
            "title": "A Sensor-Aware Phenomenological Framework for Lidar Degradation Simulation and SLAM Robustness Evaluation",
            "authors": [
                "Doumegna Mawuto Koudjo Felix",
                "Xianjia Yu",
                "Zhuo Zou",
                "Tomi Westerlund"
            ],
            "arxiv_id": "2512.08653v1",
            "summary": "Lidar-based SLAM systems are highly sensitive to adverse conditions such as occlusion, noise, and field-of-view (FoV) degradation, yet existing robustness evaluation methods either lack physical grounding or do not capture sensor-specific behavior. This paper presents a sensor-aware, phenomenological framework for simulating interpretable lidar degradations directly on real point clouds, enabling controlled and reproducible SLAM stress testing. Unlike image-derived corruption benchmarks (e.g., SemanticKITTI-C) or simulation-only approaches (e.g., lidarsim), the proposed system preserves per-point geometry, intensity, and temporal structure while applying structured dropout, FoV reduction, Gaussian noise, occlusion masking, sparsification, and motion distortion. The framework features autonomous topic and sensor detection, modular configuration with four severity tiers (light--extreme), and real-time performance (less than 20 ms per frame) compatible with ROS workflows. Experimental validation across three lidar architectures and five state-of-the-art SLAM systems reveals distinct robustness patterns shaped by sensor design and environmental context. The open-source implementation provides a practical foundation for benchmarking lidar-based SLAM under physically meaningful degradation scenarios.",
            "headline_zh": "提出传感器感知的激光雷达退化仿真框架，用于SLAM鲁棒性评估",
            "intro_zh": [
                "核心问题：现有激光雷达SLAM鲁棒性评估方法缺乏物理基础或传感器特异性",
                "方法要点：直接在真实点云上模拟可解释退化，保留几何、强度和时间结构",
                "实验或效果：在三种激光雷达架构和五种SLAM系统上验证，揭示鲁棒性模式"
            ],
            "tags_zh": [
                "激光雷达退化仿真",
                "SLAM鲁棒性评估",
                "传感器感知框架",
                "点云处理",
                "ROS兼容性"
            ],
            "_index": 80
        },
        {
            "title": "Repulsor: Accelerating Generative Modeling with a Contrastive Memory Bank",
            "authors": [
                "Shaofeng Zhang",
                "Xuanqi Chen",
                "Ning Liao",
                "Haoxiang Zhao",
                "Xiaoxing Wang",
                "Haoru Tan",
                "Sitong Wu",
                "Xiaosong Jia",
                "Qi Fan",
                "Junchi Yan"
            ],
            "arxiv_id": "2512.08648v1",
            "summary": "The dominance of denoising generative models (e.g., diffusion, flow-matching) in visual synthesis is tempered by their substantial training costs and inefficiencies in representation learning. While injecting discriminative representations via auxiliary alignment has proven effective, this approach still faces key limitations: the reliance on external, pre-trained encoders introduces overhead and domain shift. A dispersed-based strategy that encourages strong separation among in-batch latent representations alleviates this specific dependency. To assess the effect of the number of negative samples in generative modeling, we propose {\\mname}, a plug-and-play training framework that requires no external encoders. Our method integrates a memory bank mechanism that maintains a large, dynamically updated queue of negative samples across training iterations. This decouples the number of negatives from the mini-batch size, providing abundant and high-quality negatives for a contrastive objective without a multiplicative increase in computational cost. A low-dimensional projection head is used to further minimize memory and bandwidth overhead. {\\mname} offers three principal advantages: (1) it is self-contained, eliminating dependency on pretrained vision foundation models and their associated forward-pass overhead; (2) it introduces no additional parameters or computational cost during inference; and (3) it enables substantially faster convergence, achieving superior generative quality more efficiently. On ImageNet-256, {\\mname} achieves a state-of-the-art FID of \\textbf{2.40} within 400k steps, significantly outperforming comparable methods.",
            "headline_zh": "提出Repulsor框架，通过对比记忆库加速生成模型训练，无需外部编码器。",
            "intro_zh": [
                "核心问题：去噪生成模型训练成本高，依赖外部编码器引入开销和领域偏移。",
                "方法要点：集成动态更新的记忆库机制，解耦负样本数与批次大小，使用低维投影头减少开销。",
                "实验或效果：在ImageNet-256上，400k步内达到FID 2.40，收敛更快，推理无额外成本。"
            ],
            "tags_zh": [
                "生成模型",
                "对比学习",
                "记忆库机制",
                "训练加速",
                "图像合成"
            ],
            "_index": 81
        },
        {
            "title": "C-DIRA: Computationally Efficient Dynamic ROI Routing and Domain-Invariant Adversarial Learning for Lightweight Driver Behavior Recognition",
            "authors": [
                "Keito Inoshita"
            ],
            "arxiv_id": "2512.08647v1",
            "summary": "Driver distraction behavior recognition using in-vehicle cameras demands real-time inference on edge devices. However, lightweight models often fail to capture fine-grained behavioral cues, resulting in reduced performance on unseen drivers or under varying conditions. ROI-based methods also increase computational cost, making it difficult to balance efficiency and accuracy. This work addresses the need for a lightweight architecture that overcomes these constraints. We propose Computationally efficient Dynamic region of Interest Routing and domain-invariant Adversarial learning for lightweight driver behavior recognition (C-DIRA). The framework combines saliency-driven Top-K ROI pooling and fused classification for local feature extraction and integration. Dynamic ROI routing enables selective computation by applying ROI inference only to high difficulty data samples. Moreover, pseudo-domain labeling and adversarial learning are used to learn domain-invariant features robust to driver and background variation. Experiments on the State Farm Distracted Driver Detection Dataset show that C-DIRA maintains high accuracy with significantly fewer FLOPs and lower latency than prior lightweight models. It also demonstrates robustness under visual degradation such as blur and low-light, and stable performance across unseen domains. These results confirm C-DIRA's effectiveness in achieving compactness, efficiency, and generalization.",
            "headline_zh": "提出C-DIRA框架，通过动态ROI路由和域不变对抗学习，实现轻量级驾驶员行为识别的高效与泛化。",
            "intro_zh": [
                "核心问题：轻量模型在边缘设备上实时识别驾驶员分心行为时，难以平衡计算效率与细粒度特征提取，且泛化能力不足。",
                "方法要点：结合显著性驱动的Top-K ROI池化和融合分类进行局部特征提取，动态路由仅对高难度样本应用ROI推理，并利用伪域标注和对抗学习学习域不变特征。",
                "实验或效果：在State Farm数据集上，C-DIRA相比先前轻量模型，在保持高准确率的同时显著减少FLOPs和延迟，并在视觉退化及未见域中表现出鲁棒性。"
            ],
            "tags_zh": [
                "驾驶员行为识别",
                "轻量级模型",
                "动态ROI路由",
                "域不变学习",
                "对抗学习",
                "边缘计算"
            ],
            "_index": 82
        },
        {
            "title": "Chain-of-Image Generation: Toward Monitorable and Controllable Image Generation",
            "authors": [
                "Young Kyung Kim",
                "Oded Schlesinger",
                "Yuzhou Zhao",
                "J. Matias Di Martino",
                "Guillermo Sapiro"
            ],
            "arxiv_id": "2512.08645v1",
            "summary": "While state-of-the-art image generation models achieve remarkable visual quality, their internal generative processes remain a \"black box.\" This opacity limits human observation and intervention, and poses a barrier to ensuring model reliability, safety, and control. Furthermore, their non-human-like workflows make them difficult for human observers to interpret. To address this, we introduce the Chain-of-Image Generation (CoIG) framework, which reframes image generation as a sequential, semantic process analogous to how humans create art. Similar to the advantages in monitorability and performance that Chain-of-Thought (CoT) brought to large language models (LLMs), CoIG can produce equivalent benefits in text-to-image generation. CoIG utilizes an LLM to decompose a complex prompt into a sequence of simple, step-by-step instructions. The image generation model then executes this plan by progressively generating and editing the image. Each step focuses on a single semantic entity, enabling direct monitoring. We formally assess this property using two novel metrics: CoIG Readability, which evaluates the clarity of each intermediate step via its corresponding output; and Causal Relevance, which quantifies the impact of each procedural step on the final generated image. We further show that our framework mitigates entity collapse by decomposing the complex generation task into simple subproblems, analogous to the procedural reasoning employed by CoT. Our experimental results indicate that CoIG substantially enhances quantitative monitorability while achieving competitive compositional robustness compared to established baseline models. The framework is model-agnostic and can be integrated with any image generation model.",
            "headline_zh": "提出链式图像生成框架以增强图像生成的可监控性和可控性",
            "intro_zh": [
                "核心问题：现有图像生成模型内部过程不透明，限制监控、干预和可靠性。",
                "方法要点：利用大语言模型分解提示为逐步指令，实现语义序列化生成。",
                "实验或效果：通过新指标评估监控性，提升组合鲁棒性，框架模型无关。"
            ],
            "tags_zh": [
                "图像生成",
                "可监控性",
                "可控性",
                "链式推理",
                "语义分解",
                "模型无关框架"
            ],
            "_index": 83
        },
        {
            "title": "Aerial Vision-Language Navigation with a Unified Framework for Spatial, Temporal and Embodied Reasoning",
            "authors": [
                "Huilin Xu",
                "Zhuoyang Liu",
                "Yixiang Luomei",
                "Feng Xu"
            ],
            "arxiv_id": "2512.08639v1",
            "summary": "Aerial Vision-and-Language Navigation (VLN) aims to enable unmanned aerial vehicles (UAVs) to interpret natural language instructions and navigate complex urban environments using onboard visual observation. This task holds promise for real-world applications such as low-altitude inspection, search-and-rescue, and autonomous aerial delivery. Existing methods often rely on panoramic images, depth inputs, or odometry to support spatial reasoning and action planning. These requirements increase system cost and integration complexity, thus hindering practical deployment for lightweight UAVs. We present a unified aerial VLN framework that operates solely on egocentric monocular RGB observations and natural language instructions. The model formulates navigation as a next-token prediction problem, jointly optimizing spatial perception, trajectory reasoning, and action prediction through prompt-guided multi-task learning. Moreover, we propose a keyframe selection strategy to reduce visual redundancy by retaining semantically informative frames, along with an action merging and label reweighting mechanism that mitigates long-tailed supervision imbalance and facilitates stable multi-task co-training. Extensive experiments on the Aerial VLN benchmark validate the effectiveness of our method. Under the challenging monocular RGB-only setting, our model achieves strong results across both seen and unseen environments. It significantly outperforms existing RGB-only baselines and narrows the performance gap with state-of-the-art panoramic RGB-D counterparts. Comprehensive ablation studies further demonstrate the contribution of our task design and architectural choices.",
            "headline_zh": "提出统一框架，仅用单目RGB和语言指令实现无人机视觉语言导航，优化空间、时间和具身推理。",
            "intro_zh": [
                "核心问题：现有方法依赖全景、深度或里程计，增加成本和复杂性，阻碍轻量无人机部署。",
                "方法要点：将导航建模为下一个令牌预测，通过提示引导多任务学习联合优化感知、推理和动作预测。",
                "实验或效果：在Aerial VLN基准上验证，单目RGB设置下性能优于现有RGB基线，接近全景RGB-D方法。"
            ],
            "tags_zh": [
                "视觉语言导航",
                "无人机导航",
                "多任务学习",
                "单目视觉",
                "具身推理",
                "关键帧选择"
            ],
            "_index": 84
        },
        {
            "title": "Multi-Task Bayesian Optimization for Tuning Decentralized Trajectory Generation in Multi-UAV Systems",
            "authors": [
                "Marta Manzoni",
                "Alessandro Nazzari",
                "Roberto Rubinacci",
                "Marco Lovera"
            ],
            "arxiv_id": "2512.08630v1",
            "summary": "This paper investigates the use of Multi-Task Bayesian Optimization for tuning decentralized trajectory generation algorithms in multi-drone systems. We treat each task as a trajectory generation scenario defined by a specific number of drone-to-drone interactions. To model relationships across scenarios, we employ Multi-Task Gaussian Processes, which capture shared structure across tasks and enable efficient information transfer during optimization. We compare two strategies: optimizing the average mission time across all tasks and optimizing each task individually. Through a comprehensive simulation campaign, we show that single-task optimization leads to progressively shorter mission times as swarm size grows, but requires significantly more optimization time than the average-task approach.",
            "headline_zh": "提出多任务贝叶斯优化以调优多无人机系统中的分散轨迹生成算法",
            "intro_zh": [
                "核心问题：多无人机系统中分散轨迹生成算法的参数调优，涉及不同无人机交互场景。",
                "方法要点：采用多任务高斯过程建模任务间关系，实现优化过程中的信息共享。",
                "实验或效果：通过仿真比较，单任务优化随群规模增大任务时间缩短，但优化时间显著高于平均任务方法。"
            ],
            "tags_zh": [
                "多任务贝叶斯优化",
                "分散轨迹生成",
                "多无人机系统",
                "高斯过程",
                "参数调优",
                "仿真评估"
            ],
            "_index": 85
        },
        {
            "title": "See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm",
            "authors": [
                "Haoyu Zhao",
                "Weizhong Ding",
                "Yuhao Yang",
                "Zheng Tian",
                "Linyi Yang",
                "Kun Shao",
                "Jun Wang"
            ],
            "arxiv_id": "2512.08629v1",
            "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.",
            "headline_zh": "提出See-Control框架，通过低自由度机械臂直接物理交互实现智能手机操作，提供平台无关解决方案。",
            "intro_zh": [
                "核心问题：现有基于ADB的智能手机操作代理仅适用于Android设备，限制了应用范围。",
                "方法要点：构建包含基准、MLLM代理和标注数据集的框架，生成机械臂控制命令，无需ADB或系统后端访问。",
                "实验或效果：引入155个任务的ESO基准和丰富标注数据集，为未来研究提供资源，促进数字代理与物理世界融合。"
            ],
            "tags_zh": [
                "多模态大语言模型",
                "智能手机操作",
                "机械臂控制",
                "平台无关性",
                "物理交互",
                "基准数据集"
            ],
            "_index": 86
        },
        {
            "title": "Trajectory Densification and Depth from Perspective-based Blur",
            "authors": [
                "Tianchen Qiu",
                "Qirun Zhang",
                "Jiajian He",
                "Zhengyue Zhuge",
                "Jiahui Xu",
                "Yueting Chen"
            ],
            "arxiv_id": "2512.08627v1",
            "summary": "In the absence of a mechanical stabilizer, the camera undergoes inevitable rotational dynamics during capturing, which induces perspective-based blur especially under long-exposure scenarios. From an optical standpoint, perspective-based blur is depth-position-dependent: objects residing at distinct spatial locations incur different blur levels even under the same imaging settings. Inspired by this, we propose a novel method that estimate metric depth by examining the blur pattern of a video stream and dense trajectory via joint optical design algorithm. Specifically, we employ off-the-shelf vision encoder and point tracker to extract video information. Then, we estimate depth map via windowed embedding and multi-window aggregation, and densify the sparse trajectory from the optical algorithm using a vision-language model. Evaluations on multiple depth datasets demonstrate that our method attains strong performance over large depth range, while maintaining favorable generalization. Relative to the real trajectory in handheld shooting settings, our optical algorithm achieves superior precision and the dense reconstruction maintains strong accuracy.",
            "headline_zh": "提出基于透视模糊的深度估计与轨迹稠密化方法，用于手持长曝光视频场景。",
            "intro_zh": [
                "核心问题：手持相机旋转导致透视模糊，其程度依赖物体深度，影响视频质量与深度估计。",
                "方法要点：结合视觉编码器与点跟踪器提取信息，通过窗口嵌入和多窗口聚合估计深度图，并利用视觉语言模型稠密化稀疏轨迹。",
                "实验或效果：在多个深度数据集上表现优异，泛化能力强，轨迹重建精度高，优于真实手持拍摄轨迹。"
            ],
            "tags_zh": [
                "深度估计",
                "透视模糊",
                "轨迹稠密化",
                "手持视频",
                "视觉语言模型",
                "多窗口聚合"
            ],
            "_index": 87
        },
        {
            "title": "OpenMonoGS-SLAM: Monocular Gaussian Splatting SLAM with Open-set Semantics",
            "authors": [
                "Jisang Yoo",
                "Gyeongjin Kang",
                "Hyun-kyu Ko",
                "Hyeonwoo Yu",
                "Eunbyung Park"
            ],
            "arxiv_id": "2512.08625v1",
            "summary": "Simultaneous Localization and Mapping (SLAM) is a foundational component in robotics, AR/VR, and autonomous systems. With the rising focus on spatial AI in recent years, combining SLAM with semantic understanding has become increasingly important for enabling intelligent perception and interaction. Recent efforts have explored this integration, but they often rely on depth sensors or closed-set semantic models, limiting their scalability and adaptability in open-world environments. In this work, we present OpenMonoGS-SLAM, the first monocular SLAM framework that unifies 3D Gaussian Splatting (3DGS) with open-set semantic understanding. To achieve our goal, we leverage recent advances in Visual Foundation Models (VFMs), including MASt3R for visual geometry and SAM and CLIP for open-vocabulary semantics. These models provide robust generalization across diverse tasks, enabling accurate monocular camera tracking and mapping, as well as a rich understanding of semantics in open-world environments. Our method operates without any depth input or 3D semantic ground truth, relying solely on self-supervised learning objectives. Furthermore, we propose a memory mechanism specifically designed to manage high-dimensional semantic features, which effectively constructs Gaussian semantic feature maps, leading to strong overall performance. Experimental results demonstrate that our approach achieves performance comparable to or surpassing existing baselines in both closed-set and open-set segmentation tasks, all without relying on supplementary sensors such as depth maps or semantic annotations.",
            "headline_zh": "提出OpenMonoGS-SLAM，结合3D高斯溅射与开放集语义，实现单目SLAM在开放世界环境中的智能感知。",
            "intro_zh": [
                "核心问题：现有SLAM方法依赖深度传感器或封闭集语义模型，在开放世界环境中可扩展性和适应性受限。",
                "方法要点：利用视觉基础模型（如MASt3R、SAM、CLIP）进行自监督学习，无需深度输入或3D语义真值，并设计内存机制管理高维语义特征。",
                "实验或效果：在封闭集和开放集分割任务中性能达到或超越基线，不依赖额外传感器或语义标注。"
            ],
            "tags_zh": [
                "单目SLAM",
                "3D高斯溅射",
                "开放集语义",
                "视觉基础模型",
                "自监督学习",
                "语义特征映射"
            ],
            "_index": 88
        },
        {
            "title": "Protein Secondary Structure Prediction Using Transformers",
            "authors": [
                "Manzi Kevin Maxime"
            ],
            "arxiv_id": "2512.08613v1",
            "summary": "Predicting protein secondary structures such as alpha helices, beta sheets, and coils from amino acid sequences is essential for understanding protein function. This work presents a transformer-based model that applies attention mechanisms to protein sequence data to predict structural motifs. A sliding-window data augmentation technique is used on the CB513 dataset to expand the training samples. The transformer shows strong ability to generalize across variable-length sequences while effectively capturing both local and long-range residue interactions.",
            "headline_zh": "提出基于Transformer的模型，利用注意力机制预测蛋白质二级结构，以解决序列到结构映射问题。",
            "intro_zh": [
                "核心问题：从氨基酸序列预测蛋白质二级结构（如α螺旋、β折叠、卷曲），对理解蛋白质功能至关重要。",
                "方法要点：应用Transformer的注意力机制处理蛋白质序列数据，捕捉局部和长程残基相互作用，并采用滑动窗口数据增强技术扩展训练样本。",
                "实验或效果：在CB513数据集上，模型展现出对变长序列的强泛化能力，有效预测结构基序。"
            ],
            "tags_zh": [
                "蛋白质二级结构预测",
                "Transformer模型",
                "注意力机制",
                "滑动窗口数据增强",
                "CB513数据集",
                "序列泛化"
            ],
            "_index": 89
        },
        {
            "title": "CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models",
            "authors": [
                "Hui Wang",
                "Yang Liu",
                "Xiaoyu Zhang",
                "Chaoxu Mu"
            ],
            "arxiv_id": "2512.08609v1",
            "summary": "Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.",
            "headline_zh": "提出CogMCTS框架，结合认知引导与MCTS以优化基于LLM的自动启发式设计",
            "intro_zh": [
                "现有LLM进化方法易陷局部最优，MCTS集成中认知整合与搜索多样性受限",
                "CogMCTS通过多轮认知反馈、双轨节点扩展和策略突变，动态改进启发式生成",
                "实验表明CogMCTS在稳定性、效率和解决方案质量上优于现有方法"
            ],
            "tags_zh": [
                "自动启发式设计",
                "蒙特卡洛树搜索",
                "大语言模型",
                "认知引导",
                "启发式优化"
            ],
            "_index": 90
        },
        {
            "title": "Decoupled Design of Time-Varying Control Barrier Functions via Equivariances",
            "authors": [
                "Adrian Wiltz",
                "Dimos V. Dimarogonas"
            ],
            "arxiv_id": "2512.08607v1",
            "summary": "This article presents a systematic method for designing time-varying Control Barrier Functions (CBF) composed of a time-invariant component and multiple time-dependent components, leveraging structural properties of the system dynamics. The method involves the construction of a specific class of time-invariant CBFs that encode the system's dynamic capabilities with respect to a given constraint, and augments them subsequently with appropriately designed time-dependent transformations. While transformations uniformly varying the time-invariant CBF can be applied to arbitrary systems, transformations exploiting structural properties in the dynamics - equivariances in particular - enable the handling of a broader and more expressive class of time-varying constraints. The article shows how to leverage such properties in the design of time-varying CBFs. The proposed method decouples the design of time variations from the computationally expensive construction of the underlying CBFs, thereby providing a computationally attractive method to the design of time-varying CBFs. The method accounts for input constraints and under-actuation, and requires only qualitative knowledge on the time-variation of the constraints making it suitable to the application in uncertain environments.",
            "headline_zh": "提出基于等变性的时变控制屏障函数解耦设计方法，以处理不确定环境中的时变约束。",
            "intro_zh": [
                "核心问题：传统时变控制屏障函数设计计算成本高，难以处理动态系统中的时变约束。",
                "方法要点：利用系统动力学结构（如等变性），将时变部分与时不变部分解耦设计，降低计算复杂度。",
                "实验或效果：方法能处理输入约束和欠驱动系统，仅需约束时变的定性知识，适用于不确定环境。"
            ],
            "tags_zh": [
                "控制屏障函数",
                "时变约束",
                "等变性",
                "解耦设计",
                "不确定环境"
            ],
            "_index": 91
        },
        {
            "title": "Decoupling Template Bias in CLIP: Harnessing Empty Prompts for Enhanced Few-Shot Learning",
            "authors": [
                "Zhenyu Zhang",
                "Guangyao Chen",
                "Yixiong Zou",
                "Zhimeng Huang",
                "Yuhua Li"
            ],
            "arxiv_id": "2512.08606v1",
            "summary": "The Contrastive Language-Image Pre-Training (CLIP) model excels in few-shot learning by aligning visual and textual representations. Our study shows that template-sample similarity (TSS), defined as the resemblance between a text template and an image sample, introduces bias. This bias leads the model to rely on template proximity rather than true sample-to-category alignment, reducing both accuracy and robustness in classification. We present a framework that uses empty prompts, textual inputs that convey the idea of \"emptiness\" without category information. These prompts capture unbiased template features and offset TSS bias. The framework employs two stages. During pre-training, empty prompts reveal and reduce template-induced bias within the CLIP encoder. During few-shot fine-tuning, a bias calibration loss enforces correct alignment between images and their categories, ensuring the model focuses on relevant visual cues. Experiments across multiple benchmarks demonstrate that our template correction method significantly reduces performance fluctuations caused by TSS, yielding higher classification accuracy and stronger robustness. The repository of this project is available at https://github.com/zhenyuZ-HUST/Decoupling-Template-Bias-in-CLIP.",
            "headline_zh": "提出使用空提示框架以解决CLIP中模板-样本相似性偏差，提升少样本学习性能。",
            "intro_zh": [
                "核心问题：CLIP中模板-样本相似性导致模型依赖模板而非真实类别对齐，降低分类准确性和鲁棒性。",
                "方法要点：引入空提示捕获无偏模板特征，通过预训练和少样本微调两阶段框架校准偏差。",
                "实验或效果：在多个基准测试中显著减少性能波动，提高分类准确率和鲁棒性。"
            ],
            "tags_zh": [
                "CLIP模型",
                "少样本学习",
                "模板偏差",
                "空提示",
                "对比学习",
                "分类鲁棒性"
            ],
            "_index": 92
        },
        {
            "title": "Heuristics for Combinatorial Optimization via Value-based Reinforcement Learning: A Unified Framework and Analysis",
            "authors": [
                "Orit Davidovich",
                "Shimrit Shtern",
                "Segev Wasserkrug",
                "Nimrod Megiddo"
            ],
            "arxiv_id": "2512.08601v1",
            "summary": "Since the 1990s, considerable empirical work has been carried out to train statistical models, such as neural networks (NNs), as learned heuristics for combinatorial optimization (CO) problems. When successful, such an approach eliminates the need for experts to design heuristics per problem type. Due to their structure, many hard CO problems are amenable to treatment through reinforcement learning (RL). Indeed, we find a wealth of literature training NNs using value-based, policy gradient, or actor-critic approaches, with promising results, both in terms of empirical optimality gaps and inference runtimes. Nevertheless, there has been a paucity of theoretical work undergirding the use of RL for CO problems. To this end, we introduce a unified framework to model CO problems through Markov decision processes (MDPs) and solve them using RL techniques. We provide easy-to-test assumptions under which CO problems can be formulated as equivalent undiscounted MDPs that provide optimal solutions to the original CO problems. Moreover, we establish conditions under which value-based RL techniques converge to approximate solutions of the CO problem with a guarantee on the associated optimality gap. Our convergence analysis provides: (1) a sufficient rate of increase in batch size and projected gradient descent steps at each RL iteration; (2) the resulting optimality gap in terms of problem parameters and targeted RL accuracy; and (3) the importance of a choice of state-space embedding. Together, our analysis illuminates the success (and limitations) of the celebrated deep Q-learning algorithm in this problem context.",
            "headline_zh": "提出基于值强化学习的统一框架与分析，用于组合优化启发式学习",
            "intro_zh": [
                "核心问题：组合优化启发式学习缺乏理论支撑，需统一建模与分析",
                "方法要点：将组合优化问题建模为无折扣马尔可夫决策过程，提供收敛条件与最优性间隙保证",
                "实验或效果：分析深度Q学习算法的成功与局限，为实际应用提供理论指导"
            ],
            "tags_zh": [
                "组合优化",
                "强化学习",
                "马尔可夫决策过程",
                "值函数学习",
                "最优性间隙",
                "理论分析"
            ],
            "_index": 93
        },
        {
            "title": "Examining Student Interactions with a Pedagogical AI-Assistant for Essay Writing and their Impact on Students Writing Quality",
            "authors": [
                "Wicaksono Febriantoro",
                "Qi Zhou",
                "Wannapon Suraworachet",
                "Sahan Bulathwela",
                "Andrea Gauthier",
                "Eva Millan",
                "Mutlu Cukurova"
            ],
            "arxiv_id": "2512.08596v1",
            "summary": "The dynamic nature of interactions between students and GenAI, as well as their relationship to writing quality, remains underexplored. While most research has examined how general-purpose GenAI can support writing, fewer studies have investigated how students interact with pedagogically designed systems across different phases of the writing process. To address this gap, we evaluated a GenAI-driven essay-writing assistant (EWA) designed to support higher education students in argumentative writing. Drawing on 1,282 interaction logs from 32 undergraduates during a two-hour writing session, Sequential Pattern Mining and K-Means clustering were used to identify behavioral patterns. Two clusters emerged: Cluster 1 emphasized outline planning and essay structure, while Cluster 2 focused on content development. A Mann-Whitney U test revealed a moderate effect size (r = 0.36) in the essay Organization dimension, with Cluster 1 showing higher scores. Qualitative analysis indicated that students with better performance actively wrote and shared essay sections with EWA for feedback, rather than interacted passively by asking questions. These findings suggest implications for teaching and system design. Teachers can encourage active engagement, while future EWAs may integrate automatic labeling and monitoring to prompt students to move from questioning to writing, enabling fuller benefits from GenAI-supported learning.",
            "headline_zh": "分析学生与教学型AI写作助手的交互模式及其对议论文写作质量的影响",
            "intro_zh": [
                "核心问题：学生与教学型AI在写作各阶段的交互动态及其与写作质量的关系尚不明确",
                "方法要点：基于1282条交互日志，使用序列模式挖掘和K-Means聚类识别行为模式",
                "实验或效果：发现两个行为簇，强调大纲规划的簇在文章组织维度得分更高，效果量中等"
            ],
            "tags_zh": [
                "AI写作助手",
                "学生交互分析",
                "序列模式挖掘",
                "写作质量评估",
                "教学系统设计"
            ],
            "_index": 94
        },
        {
            "title": "The SMART+ Framework for AI Systems",
            "authors": [
                "Laxmiraju Kandikatla",
                "Branislav Radeljic"
            ],
            "arxiv_id": "2512.08592v1",
            "summary": "Artificial Intelligence (AI) systems are now an integral part of multiple industries. In clinical research, AI supports automated adverse event detection in clinical trials, patient eligibility screening for protocol enrollment, and data quality validation. Beyond healthcare, AI is transforming finance through real-time fraud detection, automated loan risk assessment, and algorithmic decision-making. Similarly, in manufacturing, AI enables predictive maintenance to reduce equipment downtime, enhances quality control through computer-vision inspection, and optimizes production workflows using real-time operational data. While these technologies enhance operational efficiency, they introduce new challenges regarding safety, accountability, and regulatory compliance. To address these concerns, we introduce the SMART+ Framework - a structured model built on the pillars of Safety, Monitoring, Accountability, Reliability, and Transparency, and further enhanced with Privacy & Security, Data Governance, Fairness & Bias, and Guardrails. SMART+ offers a practical, comprehensive approach to evaluating and governing AI systems across industries. This framework aligns with evolving mechanisms and regulatory guidance to integrate operational safeguards, oversight procedures, and strengthened privacy and governance controls. SMART+ demonstrates risk mitigation, trust-building, and compliance readiness. By enabling responsible AI adoption and ensuring auditability, SMART+ provides a robust foundation for effective AI governance in clinical research.",
            "headline_zh": "提出SMART+框架以解决AI系统在安全、问责和合规方面的挑战",
            "intro_zh": [
                "核心问题：AI系统在提升效率时，面临安全、问责和监管合规的新挑战",
                "方法要点：基于安全、监控、问责、可靠性和透明度支柱，增强隐私、数据治理、公平性和防护措施",
                "实验或效果：未知，但框架旨在实现风险缓解、信任建立和合规准备"
            ],
            "tags_zh": [
                "AI治理框架",
                "安全与问责",
                "监管合规",
                "数据治理",
                "公平性评估",
                "隐私保护"
            ],
            "_index": 95
        },
        {
            "title": "Long-Sequence LSTM Modeling for NBA Game Outcome Prediction Using a Novel Multi-Season Dataset",
            "authors": [
                "Charles Rios",
                "Longzhen Han",
                "Almas Baimagambetov",
                "Nikolaos Polatidis"
            ],
            "arxiv_id": "2512.08591v1",
            "summary": "Predicting the outcomes of professional basketball games, particularly in the National Basketball Association (NBA), has become increasingly important for coaching strategy, fan engagement, and sports betting. However, many existing prediction models struggle with concept drift, limited temporal context, and instability across seasons. To advance forecasting in this domain, we introduce a newly constructed longitudinal NBA dataset covering the 2004-05 to 2024-25 seasons and present a deep learning framework designed to model long-term performance trends. Our primary contribution is a Long Short-Term Memory (LSTM) architecture that leverages an extended sequence length of 9,840 games equivalent to eight full NBA seasons to capture evolving team dynamics and season-over-season dependencies. We compare this model against several traditional Machine Learning (ML) and Deep Learning (DL) baselines, including Logistic Regression, Random Forest, Multi-Layer Perceptron (MLP), and Convolutional Neural Network (CNN). The LSTM achieves the best performance across all metrics, with 72.35 accuracy, 73.15 precision and 76.13 AUC-ROC. These results demonstrate the importance of long-sequence temporal modeling in basketball outcome prediction and highlight the value of our new multi-season dataset for developing robust, generalizable NBA forecasting systems.",
            "headline_zh": "提出长序列LSTM模型，利用多赛季数据集预测NBA比赛结果，以应对概念漂移和时序依赖问题。",
            "intro_zh": [
                "核心问题：现有NBA比赛预测模型存在概念漂移、时序上下文有限和跨赛季不稳定性。",
                "方法要点：构建覆盖2004-05至2024-25赛季的新数据集，并设计LSTM模型，序列长度达9,840场比赛以捕获长期趋势。",
                "实验或效果：LSTM在准确率、精确度和AUC-ROC上均优于传统ML和DL基线，最高准确率达72.35%。"
            ],
            "tags_zh": [
                "长序列建模",
                "LSTM",
                "NBA比赛预测",
                "多赛季数据集",
                "时序依赖",
                "深度学习"
            ],
            "_index": 96
        },
        {
            "title": "Automated Pollen Recognition in Optical and Holographic Microscopy Images",
            "authors": [
                "Swarn Singh Warshaneyan",
                "Maksims Ivanovs",
                "Blaž Cugmas",
                "Inese Bērziņa",
                "Laura Goldberga",
                "Mindaugas Tamosiunas",
                "Roberts Kadiķis"
            ],
            "arxiv_id": "2512.08589v1",
            "summary": "This study explores the application of deep learning to improve and automate pollen grain detection and classification in both optical and holographic microscopy images, with a particular focus on veterinary cytology use cases. We used YOLOv8s for object detection and MobileNetV3L for the classification task, evaluating their performance across imaging modalities. The models achieved 91.3% mAP50 for detection and 97% overall accuracy for classification on optical images, whereas the initial performance on greyscale holographic images was substantially lower. We addressed the performance gap issue through dataset expansion using automated labeling and bounding box area enlargement. These techniques, applied to holographic images, improved detection performance from 2.49% to 13.3% mAP50 and classification performance from 42% to 54%. Our work demonstrates that, at least for image classification tasks, it is possible to pair deep learning techniques with cost-effective lensless digital holographic microscopy devices.",
            "headline_zh": "提出基于深度学习的自动化花粉识别方法，应用于光学与全息显微镜图像，提升兽医细胞学检测效率。",
            "intro_zh": [
                "核心问题：自动化花粉检测与分类在光学和全息显微镜图像中性能差异大，全息图像初始准确率低。",
                "方法要点：使用YOLOv8s进行目标检测和MobileNetV3L进行分类，通过自动标注和边界框扩大扩展数据集。",
                "实验或效果：光学图像检测mAP50达91.3%，分类准确率97%；全息图像经优化后检测mAP50从2.49%提升至13.3%，分类准确率从42%提升至54%。"
            ],
            "tags_zh": [
                "花粉识别",
                "深度学习",
                "光学显微镜",
                "全息显微镜",
                "目标检测",
                "图像分类"
            ],
            "_index": 97
        },
        {
            "title": "Mind to Hand: Purposeful Robotic Control via Embodied Reasoning",
            "authors": [
                "Peijun Tang",
                "Shangjin Xie",
                "Binyan Sun",
                "Baifu Huang",
                "Kuncheng Luo",
                "Haotian Yang",
                "Weiqi Jin",
                "Jianan Wang"
            ],
            "arxiv_id": "2512.08580v1",
            "summary": "Humans act with context and intention, with reasoning playing a central role. While internet-scale data has enabled broad reasoning capabilities in AI systems, grounding these abilities in physical action remains a major challenge. We introduce Lumo-1, a generalist vision-language-action (VLA) model that unifies robot reasoning (\"mind\") with robot action (\"hand\"). Our approach builds upon the general multi-modal reasoning capabilities of pre-trained vision-language models (VLMs), progressively extending them to embodied reasoning and action prediction, and ultimately towards structured reasoning and reasoning-action alignment. This results in a three-stage pre-training pipeline: (1) Continued VLM pre-training on curated vision-language data to enhance embodied reasoning skills such as planning, spatial understanding, and trajectory prediction; (2) Co-training on cross-embodiment robot data alongside vision-language data; and (3) Action training with reasoning process on trajectories collected on Astribot S1, a bimanual mobile manipulator with human-like dexterity and agility. Finally, we integrate reinforcement learning to further refine reasoning-action consistency and close the loop between semantic inference and motor control. Extensive experiments demonstrate that Lumo-1 achieves significant performance improvements in embodied vision-language reasoning, a critical component for generalist robotic control. Real-world evaluations further show that Lumo-1 surpasses strong baselines across a wide range of challenging robotic tasks, with strong generalization to novel objects and environments, excelling particularly in long-horizon tasks and responding to human-natural instructions that require reasoning over strategy, concepts and space.",
            "headline_zh": "提出Lumo-1模型，通过三阶段预训练统一机器人推理与动作，以解决AI系统在物理动作中的推理落地挑战。",
            "intro_zh": [
                "核心问题：AI系统虽具备广泛推理能力，但难以在物理动作中有效落地，机器人控制需结合上下文与意图。",
                "方法要点：基于预训练视觉语言模型，分三阶段扩展至具身推理与动作预测，包括增强推理技能、跨具身数据协同训练和动作训练。",
                "实验或效果：Lumo-1在具身视觉语言推理中表现显著提升，在真实世界机器人任务中超越基线，尤其在长时程任务和自然指令响应中表现出色。"
            ],
            "tags_zh": [
                "具身推理",
                "视觉语言动作模型",
                "机器人控制",
                "三阶段预训练",
                "长时程任务",
                "跨具身数据"
            ],
            "_index": 98
        },
        {
            "title": "Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery",
            "authors": [
                "Yuna Kato",
                "Shohei Mori",
                "Hideo Saito",
                "Yoshifumi Takatsume",
                "Hiroki Kajita",
                "Mariko Isogawa"
            ],
            "arxiv_id": "2512.08577v1",
            "summary": "Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post-processing since camera configurations change every time surgeons move the lamp for optimal lighting. This paper aims to fully automate this alignment task. The proposed method identifies frames in which the lighting system moves, realigns them, and selects the camera with the least occlusion to generate a video that consistently presents the surgical field from a fixed perspective. A user study involving surgeons demonstrated that videos generated by our method were superior to those produced by conventional methods in terms of the ease of confirming the surgical area and the comfort during video viewing. Additionally, our approach showed improvements in video quality over existing techniques. Furthermore, we implemented several synthesis options for the proposed view-synthesis method and conducted a user study to assess surgeons' preferences for each option.",
            "headline_zh": "提出自动化多相机对齐方法以生成无遮挡开放手术视频",
            "intro_zh": [
                "核心问题：手术视频录制中，医生遮挡相机视野，手动调整相机位置和角度耗时费力。",
                "方法要点：利用多相机无影灯系统，自动检测灯光移动帧、重新对齐并选择遮挡最少的相机，生成固定视角视频。",
                "实验或效果：用户研究表明，生成视频在确认手术区域和观看舒适度上优于传统方法，视频质量有所提升。"
            ],
            "tags_zh": [
                "手术视频生成",
                "多相机对齐",
                "无遮挡视图",
                "计算机视觉",
                "医疗影像处理"
            ],
            "_index": 99
        },
        {
            "title": "RVC-NMPC: Nonlinear Model Predictive Control with Reciprocal Velocity Constraints for Mutual Collision Avoidance in Agile UAV Flight",
            "authors": [
                "Vit Kratky",
                "Robert Penicka",
                "Parakh M. Gupta",
                "Ondrej Prochazka",
                "Martin Saska"
            ],
            "arxiv_id": "2512.08574v1",
            "summary": "This paper presents an approach to mutual collision avoidance based on Nonlinear Model Predictive Control (NMPC) with time-dependent Reciprocal Velocity Constraints (RVCs). Unlike most existing methods, the proposed approach relies solely on observable information about other robots, eliminating the necessity of excessive communication use. The computationally efficient algorithm for computing RVCs, together with the direct integration of these constraints into NMPC problem formulation on a controller level, allows the whole pipeline to run at 100 Hz. This high processing rate, combined with modeled nonlinear dynamics of the controlled Uncrewed Aerial Vehicles (UAVs), is a key feature that facilitates the use of the proposed approach for an agile UAV flight. The proposed approach was evaluated through extensive simulations emulating real-world conditions in scenarios involving up to 10 UAVs and velocities of up to 25 m/s, and in real-world experiments with accelerations up to 30 m/s$^2$. Comparison with state of the art shows 31% improvement in terms of flight time reduction in challenging scenarios, while maintaining a collision-free navigation in all trials.",
            "headline_zh": "提出基于非线性模型预测控制与互惠速度约束的无人机敏捷飞行互避方法",
            "intro_zh": [
                "核心问题：无人机敏捷飞行中的互避需高效、低通信依赖的实时控制。",
                "方法要点：集成互惠速度约束至非线性模型预测控制，仅依赖可观测信息，实现100Hz处理。",
                "实验或效果：仿真与实飞验证，在10架无人机、25m/s速度下，飞行时间减少31%，无碰撞。"
            ],
            "tags_zh": [
                "无人机互避",
                "非线性模型预测控制",
                "互惠速度约束",
                "实时控制",
                "敏捷飞行"
            ],
            "_index": 100
        },
        {
            "title": "From Cells to Survival: Hierarchical Analysis of Cell Inter-Relations in Multiplex Microscopy for Lung Cancer Prognosis",
            "authors": [
                "Olle Edgren Schüllerqvist",
                "Jens Baumann",
                "Joakim Lindblad",
                "Love Nordling",
                "Artur Mezheyeuski",
                "Patrick Micke",
                "Nataša Sladoje"
            ],
            "arxiv_id": "2512.08572v1",
            "summary": "The tumor microenvironment (TME) has emerged as a promising source of prognostic biomarkers. To fully leverage its potential, analysis methods must capture complex interactions between different cell types. We propose HiGINE -- a hierarchical graph-based approach to predict patient survival (short vs. long) from TME characterization in multiplex immunofluorescence (mIF) images and enhance risk stratification in lung cancer. Our model encodes both local and global inter-relations in cell neighborhoods, incorporating information about cell types and morphology. Multimodal fusion, aggregating cancer stage with mIF-derived features, further boosts performance. We validate HiGINE on two public datasets, demonstrating improved risk stratification, robustness, and generalizability.",
            "headline_zh": "提出HiGINE分层图方法，基于多路免疫荧光图像预测肺癌患者生存风险。",
            "intro_zh": [
                "核心问题：肿瘤微环境中细胞间复杂交互的捕获不足，影响预后生物标志物开发。",
                "方法要点：采用分层图编码细胞邻域的局部与全局关系，融合细胞类型和形态信息。",
                "实验或效果：在两个公共数据集上验证，显示风险分层、鲁棒性和泛化性提升。"
            ],
            "tags_zh": [
                "肿瘤微环境分析",
                "分层图模型",
                "多路免疫荧光",
                "生存预测",
                "肺癌预后"
            ],
            "_index": 101
        },
        {
            "title": "Instance-Aware Test-Time Segmentation for Continual Domain Shifts",
            "authors": [
                "Seunghwan Lee",
                "Inyoung Jung",
                "Hojoon Lee",
                "Eunil Park",
                "Sungeun Hong"
            ],
            "arxiv_id": "2512.08569v1",
            "summary": "Continual Test-Time Adaptation (CTTA) enables pre-trained models to adapt to continuously evolving domains. Existing methods have improved robustness but typically rely on fixed or batch-level thresholds, which cannot account for varying difficulty across classes and instances. This limitation is especially problematic in semantic segmentation, where each image requires dense, multi-class predictions. We propose an approach that adaptively adjusts pseudo labels to reflect the confidence distribution within each image and dynamically balances learning toward classes most affected by domain shifts. This fine-grained, class- and instance-aware adaptation produces more reliable supervision and mitigates error accumulation throughout continual adaptation. Extensive experiments across eight CTTA and TTA scenarios, including synthetic-to-real and long-term shifts, show that our method consistently outperforms state-of-the-art techniques, setting a new standard for semantic segmentation under evolving conditions.",
            "headline_zh": "提出实例感知测试时分割方法，以解决持续域偏移下语义分割的伪标签可靠性问题。",
            "intro_zh": [
                "核心问题：现有持续测试时适应方法依赖固定阈值，无法处理不同类别和实例的难度差异，导致语义分割中错误累积。",
                "方法要点：自适应调整伪标签以反映每张图像的置信度分布，并动态平衡受域偏移影响最大的类别的学习。",
                "实验或效果：在八个持续测试时适应和测试时适应场景中，包括合成到真实和长期偏移，方法一致优于现有技术。"
            ],
            "tags_zh": [
                "持续测试时适应",
                "语义分割",
                "域偏移",
                "伪标签调整",
                "实例感知学习",
                "动态平衡"
            ],
            "_index": 102
        },
        {
            "title": "A Hybrid Model for Stock Market Forecasting: Integrating News Sentiment and Time Series Data with Graph Neural Networks",
            "authors": [
                "Nader Sadek",
                "Mirette Moawad",
                "Christina Naguib",
                "Mariam Elzahaby"
            ],
            "arxiv_id": "2512.08567v1",
            "summary": "Stock market prediction is a long-standing challenge in finance, as accurate forecasts support informed investment decisions. Traditional models rely mainly on historical prices, but recent work shows that financial news can provide useful external signals. This paper investigates a multimodal approach that integrates companies' news articles with their historical stock data to improve prediction performance. We compare a Graph Neural Network (GNN) model with a baseline LSTM model. Historical data for each company is encoded using an LSTM, while news titles are embedded with a language model. These embeddings form nodes in a heterogeneous graph, and GraphSAGE is used to capture interactions between articles, companies, and industries. We evaluate two targets: a binary direction-of-change label and a significance-based label. Experiments on the US equities and Bloomberg datasets show that the GNN outperforms the LSTM baseline, achieving 53% accuracy on the first target and a 4% precision gain on the second. Results also indicate that companies with more associated news yield higher prediction accuracy. Moreover, headlines contain stronger predictive signals than full articles, suggesting that concise news summaries play an important role in short-term market reactions.",
            "headline_zh": "提出融合新闻情感与时间序列数据的图神经网络混合模型以提升股市预测性能",
            "intro_zh": [
                "核心问题：股市预测依赖历史价格，但外部新闻信号可提供补充信息。",
                "方法要点：结合LSTM编码历史数据与语言模型嵌入新闻，构建异构图并使用GraphSAGE捕捉交互。",
                "实验或效果：在美股和Bloomberg数据集上，GNN优于LSTM基线，准确率达53%，新闻量多的公司预测更准。"
            ],
            "tags_zh": [
                "股市预测",
                "图神经网络",
                "新闻情感分析",
                "多模态融合",
                "时间序列分析"
            ],
            "_index": 103
        },
        {
            "title": "Modular Neural Image Signal Processing",
            "authors": [
                "Mahmoud Afifi",
                "Zhongling Wang",
                "Ran Zhang",
                "Michael S. Brown"
            ],
            "arxiv_id": "2512.08564v1",
            "summary": "This paper presents a modular neural image signal processing (ISP) framework that processes raw inputs and renders high-quality display-referred images. Unlike prior neural ISP designs, our method introduces a high degree of modularity, providing full control over multiple intermediate stages of the rendering process.~This modular design not only achieves high rendering accuracy but also improves scalability, debuggability, generalization to unseen cameras, and flexibility to match different user-preference styles. To demonstrate the advantages of this design, we built a user-interactive photo-editing tool that leverages our neural ISP to support diverse editing operations and picture styles. The tool is carefully engineered to take advantage of the high-quality rendering of our neural ISP and to enable unlimited post-editable re-rendering. Our method is a fully learning-based framework with variants of different capacities, all of moderate size (ranging from ~0.5 M to ~3.9 M parameters for the entire pipeline), and consistently delivers competitive qualitative and quantitative results across multiple test sets. Watch the supplemental video at: https://youtu.be/ByhQjQSjxVM",
            "headline_zh": "提出模块化神经图像信号处理框架以提升渲染控制与灵活性",
            "intro_zh": [
                "核心问题：传统神经ISP缺乏对渲染中间阶段的控制，影响可扩展性和调试性",
                "方法要点：引入高度模块化设计，支持多阶段渲染控制，实现高质量图像渲染",
                "实验或效果：构建交互式照片编辑工具，在多个测试集上取得竞争性定性和定量结果"
            ],
            "tags_zh": [
                "神经图像信号处理",
                "模块化设计",
                "图像渲染",
                "交互式编辑",
                "学习型框架"
            ],
            "_index": 104
        },
        {
            "title": "BrainExplore: Large-Scale Discovery of Interpretable Visual Representations in the Human Brain",
            "authors": [
                "Navve Wasserman",
                "Matias Cosarinsky",
                "Yuval Golbari",
                "Aude Oliva",
                "Antonio Torralba",
                "Tamar Rott Shaham",
                "Michal Irani"
            ],
            "arxiv_id": "2512.08560v1",
            "summary": "Understanding how the human brain represents visual concepts, and in which brain regions these representations are encoded, remains a long-standing challenge. Decades of work have advanced our understanding of visual representations, yet brain signals remain large and complex, and the space of possible visual concepts is vast. As a result, most studies remain small-scale, rely on manual inspection, focus on specific regions and properties, and rarely include systematic validation. We present a large-scale, automated framework for discovering and explaining visual representations across the human cortex. Our method comprises two main stages. First, we discover candidate interpretable patterns in fMRI activity through unsupervised, data-driven decomposition methods. Next, we explain each pattern by identifying the set of natural images that most strongly elicit it and generating a natural-language description of their shared visual meaning. To scale this process, we introduce an automated pipeline that tests multiple candidate explanations, assigns quantitative reliability scores, and selects the most consistent description for each voxel pattern. Our framework reveals thousands of interpretable patterns spanning many distinct visual concepts, including fine-grained representations previously unreported.",
            "headline_zh": "提出大规模自动化框架BrainExplore，以发现和解释人脑视觉表征",
            "intro_zh": [
                "核心问题：人脑如何编码视觉概念，现有研究规模小且依赖人工，缺乏系统验证。",
                "方法要点：通过无监督分解发现候选模式，自动化识别图像和生成语言描述，并评估可靠性。",
                "实验或效果：揭示数千个可解释模式，涵盖多种视觉概念，包括未报告的细粒度表征。"
            ],
            "tags_zh": [
                "脑视觉表征",
                "fMRI数据分析",
                "无监督分解",
                "自动化解释",
                "大规模发现",
                "可解释模式"
            ],
            "_index": 105
        },
        {
            "title": "SSCATeR: Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling for Real-Time 3D Object Detection in LiDAR Point Clouds",
            "authors": [
                "Alexander Dow",
                "Manduhu Manduhu",
                "Matheus Santos",
                "Ben Bartlett",
                "Gerard Dooly",
                "James Riordan"
            ],
            "arxiv_id": "2512.08557v1",
            "summary": "This work leverages the continuous sweeping motion of LiDAR scanning to concentrate object detection efforts on specific regions that receive a change in point data from one frame to another. We achieve this by using a sliding time window with short strides and consider the temporal dimension by storing convolution results between passes. This allows us to ignore unchanged regions, significantly reducing the number of convolution operations per forward pass without sacrificing accuracy. This data reuse scheme introduces extreme sparsity to detection data. To exploit this sparsity, we extend our previous work on scatter-based convolutions to allow for data reuse, and as such propose Sparse Scatter-Based Convolution Algorithm with Temporal Data Recycling (SSCATeR). This operation treats incoming LiDAR data as a continuous stream and acts only on the changing parts of the point cloud. By doing so, we achieve the same results with as much as a 6.61-fold reduction in processing time. Our test results show that the feature maps output by our method are identical to those produced by traditional sparse convolution techniques, whilst greatly increasing the computational efficiency of the network.",
            "headline_zh": "提出SSCATeR算法，利用时间数据回收和稀疏散射卷积，实现激光雷达点云实时3D目标检测。",
            "intro_zh": [
                "核心问题：传统稀疏卷积在连续激光雷达扫描中处理未变化区域导致计算冗余，影响实时性。",
                "方法要点：采用滑动时间窗口和短步长，存储卷积结果以重用数据，仅处理点云变化部分，减少卷积操作。",
                "实验或效果：处理时间最多减少6.61倍，特征图与传统方法相同，显著提升计算效率。"
            ],
            "tags_zh": [
                "激光雷达点云",
                "3D目标检测",
                "稀疏卷积",
                "时间数据回收",
                "实时处理",
                "散射卷积"
            ],
            "_index": 106
        },
        {
            "title": "Bridging Scale Discrepancies in Robotic Control via Language-Based Action Representations",
            "authors": [
                "Yuchi Zhang",
                "Churui Sun",
                "Shiqi Liang",
                "Diyuan Liu",
                "Chao Ji",
                "Wei-Nan Zhang",
                "Ting Liu"
            ],
            "arxiv_id": "2512.08548v1",
            "summary": "Recent end-to-end robotic manipulation research increasingly adopts architectures inspired by large language models to enable robust manipulation. However, a critical challenge arises from severe distribution shifts between robotic action data, primarily due to substantial numerical variations in action commands across diverse robotic platforms and tasks, hindering the effective transfer of pretrained knowledge. To address this limitation, we propose a semantically grounded linguistic representation to normalize actions for efficient pretraining. Unlike conventional discretized action representations that are sensitive to numerical scales, the motion representation specifically disregards numeric scale effects, emphasizing directionality instead. This abstraction mitigates distribution shifts, yielding a more generalizable pretraining representation. Moreover, using the motion representation narrows the feature distance between action tokens and standard vocabulary tokens, mitigating modality gaps. Multi-task experiments on two benchmarks demonstrate that the proposed method significantly improves generalization performance and transferability in robotic manipulation tasks.",
            "headline_zh": "提出基于语言的动作表示以解决机器人控制中的尺度差异问题",
            "intro_zh": [
                "核心问题：机器人动作数据因平台和任务差异导致数值尺度变化，阻碍预训练知识迁移。",
                "方法要点：采用语义基础的语言表示，忽略数值尺度，强调方向性，以归一化动作。",
                "实验或效果：在基准测试中，该方法显著提升机器人操作任务的泛化性能和可转移性。"
            ],
            "tags_zh": [
                "机器人操作",
                "动作表示",
                "预训练",
                "泛化性能",
                "语言模型"
            ],
            "_index": 107
        },
        {
            "title": "An Iteration-Free Fixed-Point Estimator for Diffusion Inversion",
            "authors": [
                "Yifei Chen",
                "Kaiyu Song",
                "Yan Pan",
                "Jianxing Yu",
                "Jian Yin",
                "Hanjiang Lai"
            ],
            "arxiv_id": "2512.08547v1",
            "summary": "Diffusion inversion aims to recover the initial noise corresponding to a given image such that this noise can reconstruct the original image through the denoising diffusion process. The key component of diffusion inversion is to minimize errors at each inversion step, thereby mitigating cumulative inaccuracies. Recently, fixed-point iteration has emerged as a widely adopted approach to minimize reconstruction errors at each inversion step. However, it suffers from high computational costs due to its iterative nature and the complexity of hyperparameter selection. To address these issues, we propose an iteration-free fixed-point estimator for diffusion inversion. First, we derive an explicit expression of the fixed point from an ideal inversion step. Unfortunately, it inherently contains an unknown data prediction error. Building upon this, we introduce the error approximation, which uses the calculable error from the previous inversion step to approximate the unknown error at the current inversion step. This yields a calculable, approximate expression for the fixed point, which is an unbiased estimator characterized by low variance, as shown by our theoretical analysis. We evaluate reconstruction performance on two text-image datasets, NOCAPS and MS-COCO. Compared to DDIM inversion and other inversion methods based on the fixed-point iteration, our method achieves consistent and superior performance in reconstruction tasks without additional iterations or training.",
            "headline_zh": "提出迭代无关的定点估计器以解决扩散反演中的计算成本高和超参数选择复杂问题。",
            "intro_zh": [
                "扩散反演旨在通过最小化每一步误差来恢复初始噪声，但现有定点迭代方法计算成本高且超参数选择复杂。",
                "方法推导理想反演步的定点显式表达式，并引入误差近似来估计未知误差，形成低方差无偏估计器。",
                "在NOCAPS和MS-COCO数据集上评估，相比DDIM反演和其他定点迭代方法，重建性能一致更优，无需额外迭代或训练。"
            ],
            "tags_zh": [
                "扩散反演",
                "定点估计",
                "误差近似",
                "图像重建",
                "计算效率",
                "无偏估计"
            ],
            "_index": 108
        },
        {
            "title": "Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks",
            "authors": [
                "Indrajit Kar",
                "Kalathur Chenchu Kishore Kumar"
            ],
            "arxiv_id": "2512.08545v1",
            "summary": "Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.",
            "headline_zh": "提出基于空间课程的分层多智能体系统，以解决长时程推理任务中的计算成本与稳定性问题。",
            "intro_zh": [
                "核心问题：大语言模型与多智能体系统在长时程推理任务中面临计算成本高和稳定性不足的挑战。",
                "方法要点：采用64*64网格的轻量级智能体分层架构，结合空间课程和负对数似然置信度度量，通过Thompson Sampling自适应管理训练区域。",
                "实验或效果：在空间化汉诺塔基准测试中，系统表现出稳定性提升、预言机使用减少和分布式协作增强的长程推理能力。"
            ],
            "tags_zh": [
                "分层多智能体系统",
                "空间课程学习",
                "长时程推理",
                "负对数似然置信度",
                "Thompson Sampling",
                "分布式协作"
            ],
            "_index": 109
        },
        {
            "title": "A Novel Wasserstein Quaternion Generative Adversarial Network for Color Image Generation",
            "authors": [
                "Zhigang Jia",
                "Duan Wang",
                "Hengkai Wang",
                "Yajun Xie",
                "Meixiang Zhao",
                "Xiaoyu Zhao"
            ],
            "arxiv_id": "2512.08542v1",
            "summary": "Color image generation has a wide range of applications, but the existing generation models ignore the correlation among color channels, which may lead to chromatic aberration problems. In addition, the data distribution problem of color images has not been systematically elaborated and explained, so that there is still the lack of the theory about measuring different color images datasets. In this paper, we define a new quaternion Wasserstein distance and develop its dual theory. To deal with the quaternion linear programming problem, we derive the strong duality form with helps of quaternion convex set separation theorem and quaternion Farkas lemma. With using quaternion Wasserstein distance, we propose a novel Wasserstein quaternion generative adversarial network. Experiments demonstrate that this novel model surpasses both the (quaternion) generative adversarial networks and the Wasserstein generative adversarial network in terms of generation efficiency and image quality.",
            "headline_zh": "提出基于四元数Wasserstein距离的生成对抗网络，以解决彩色图像生成中的通道相关性和数据分布问题。",
            "intro_zh": [
                "核心问题：现有彩色图像生成模型忽略颜色通道相关性，可能导致色差，且缺乏系统理论衡量不同数据集分布。",
                "方法要点：定义新四元数Wasserstein距离并发展对偶理论，利用四元数凸集分离定理和Farkas引理推导强对偶形式，构建Wasserstein四元数生成对抗网络。",
                "实验或效果：实验表明该模型在生成效率和图像质量上超越传统（四元数）生成对抗网络和Wasserstein生成对抗网络。"
            ],
            "tags_zh": [
                "彩色图像生成",
                "四元数Wasserstein距离",
                "生成对抗网络",
                "数据分布理论",
                "通道相关性",
                "强对偶形式"
            ],
            "_index": 110
        },
        {
            "title": "vEDGAR - Can CARLA Do HiL?",
            "authors": [
                "Nils Gehrke",
                "David Brecht",
                "Dominik Kulmer",
                "Dheer Patel",
                "Frank Diermeyer"
            ],
            "arxiv_id": "2512.08541v1",
            "summary": "Simulation offers advantages throughout the development process of automated driving functions, both in research and product development. Common open-source simulators like CARLA are extensively used in training, evaluation, and software-in-the-loop testing of new automated driving algorithms. However, the CARLA simulator lacks an evaluation where research and automated driving vehicles are simulated with their entire sensor and actuation stack in real time. The goal of this work is therefore to create a simulation framework for testing the automation software on its dedicated hardware and identifying its limits. Achieving this goal would greatly benefit the open-source development workflow of automated driving functions, designating CARLA as a consistent evaluation tool along the entire development process. To achieve this goal, in a first step, requirements are derived, and a simulation architecture is specified and implemented. Based on the formulated requirements, the proposed vEDGAR software is evaluated, resulting in a final conclusion on the applicability of CARLA for HiL testing of automated vehicles. The tool is available open source: Modified CARLA fork: https://github.com/TUMFTM/carla, vEDGAR Framework: https://github.com/TUMFTM/vEDGAR",
            "headline_zh": "提出vEDGAR框架以评估CARLA在硬件在环测试中的适用性",
            "intro_zh": [
                "核心问题：CARLA缺乏实时全传感器与执行器堆栈的硬件在环测试能力",
                "方法要点：基于需求推导，设计并实现vEDGAR仿真架构，集成专用硬件",
                "实验或效果：评估vEDGAR软件，得出CARLA用于自动驾驶硬件在环测试的适用性结论"
            ],
            "tags_zh": [
                "硬件在环测试",
                "自动驾驶仿真",
                "CARLA扩展",
                "实时仿真",
                "开源框架"
            ],
            "_index": 111
        },
        {
            "title": "Fast-ARDiff: An Entropy-informed Acceleration Framework for Continuous Space Autoregressive Generation",
            "authors": [
                "Zhen Zou",
                "Xiaoxiao Ma",
                "Jie Huang",
                "Zichao Yu",
                "Feng Zhao"
            ],
            "arxiv_id": "2512.08537v1",
            "summary": "Autoregressive(AR)-diffusion hybrid paradigms combine AR's structured modeling with diffusion's photorealistic synthesis, yet suffer from high latency due to sequential AR generation and iterative denoising. In this work, we tackle this bottleneck and propose a unified AR-diffusion framework Fast-ARDiff that jointly optimizes both components, accelerating AR speculative decoding while simultaneously facilitating faster diffusion decoding. Specifically: (1) The entropy-informed speculative strategy encourages draft model to produce higher-entropy representations aligned with target model's entropy characteristics, mitigating entropy mismatch and high rejection rates caused by draft overconfidence. (2) For diffusion decoding, rather than treating it as an independent module, we integrate it into the same end-to-end framework using a dynamic scheduler that prioritizes AR optimization to guide the diffusion part in further steps. The diffusion part is optimized through a joint distillation framework combining trajectory and distribution matching, ensuring stable training and high-quality synthesis with extremely few steps. During inference, shallow feature entropy from AR module is used to pre-filter low-entropy drafts, avoiding redundant computation and improving latency. Fast-ARDiff achieves state-of-the-art acceleration across diverse models: on ImageNet 256$\\times$256, TransDiff attains 4.3$\\times$ lossless speedup, and NextStep-1 achieves 3$\\times$ acceleration on text-conditioned generation. Code will be available at https://github.com/aSleepyTree/Fast-ARDiff.",
            "headline_zh": "提出Fast-ARDiff框架，通过熵引导策略和联合优化加速自回归-扩散混合生成",
            "intro_zh": [
                "核心问题：自回归-扩散混合范式因顺序生成和迭代去噪导致高延迟",
                "方法要点：采用熵引导推测解码和动态调度器联合优化自回归与扩散组件",
                "实验或效果：在ImageNet 256×256上实现4.3倍无损加速，文本条件生成加速3倍"
            ],
            "tags_zh": [
                "自回归-扩散混合生成",
                "熵引导加速",
                "推测解码",
                "联合蒸馏训练",
                "动态调度器",
                "图像生成加速"
            ],
            "_index": 112
        },
        {
            "title": "Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans",
            "authors": [
                "Tammy Zhong",
                "Yang Song",
                "Maurice Pagnucco"
            ],
            "arxiv_id": "2512.08536v1",
            "summary": "Ethical awareness is critical for robots operating in human environments, yet existing automated planning tools provide little support. Manually specifying ethical rules is labour-intensive and highly context-specific. We present Principles2Plan, an interactive research prototype demonstrating how a human and a Large Language Model (LLM) can collaborate to produce context-sensitive ethical rules and guide automated planning. A domain expert provides the planning domain, problem details, and relevant high-level principles such as beneficence and privacy. The system generates operationalisable ethical rules consistent with these principles, which the user can review, prioritise, and supply to a planner to produce ethically-informed plans. To our knowledge, no prior system supports users in generating principle-grounded rules for classical planning contexts. Principles2Plan showcases the potential of human-LLM collaboration for making ethical automated planning more practical and feasible.",
            "headline_zh": "提出Principles2Plan系统，通过人-大语言模型协作生成情境化伦理规则以指导自动化规划",
            "intro_zh": [
                "核心问题：现有自动化规划工具缺乏伦理支持，手动指定规则耗时且依赖情境。",
                "方法要点：结合人类专家输入与LLM生成可操作伦理规则，支持用户审查和优先排序。",
                "实验或效果：展示原型系统，使伦理自动化规划更实用可行，填补了经典规划中原则基础规则生成的空白。"
            ],
            "tags_zh": [
                "伦理自动化规划",
                "人-LLM协作",
                "情境化规则生成",
                "经典规划",
                "伦理原则操作化"
            ],
            "_index": 113
        },
        {
            "title": "Photo3D: Advancing Photorealistic 3D Generation through Structure-Aligned Detail Enhancement",
            "authors": [
                "Xinyue Liang",
                "Zhinyuan Ma",
                "Lingchen Sun",
                "Yanjun Guo",
                "Lei Zhang"
            ],
            "arxiv_id": "2512.08535v1",
            "summary": "Although recent 3D-native generators have made great progress in synthesizing reliable geometry, they still fall short in achieving realistic appearances. A key obstacle lies in the lack of diverse and high-quality real-world 3D assets with rich texture details, since capturing such data is intrinsically difficult due to the diverse scales of scenes, non-rigid motions of objects, and the limited precision of 3D scanners. We introduce Photo3D, a framework for advancing photorealistic 3D generation, which is driven by the image data generated by the GPT-4o-Image model. Considering that the generated images can distort 3D structures due to their lack of multi-view consistency, we design a structure-aligned multi-view synthesis pipeline and construct a detail-enhanced multi-view dataset paired with 3D geometry. Building on it, we present a realistic detail enhancement scheme that leverages perceptual feature adaptation and semantic structure matching to enforce appearance consistency with realistic details while preserving the structural consistency with the 3D-native geometry. Our scheme is general to different 3D-native generators, and we present dedicated training strategies to facilitate the optimization of geometry-texture coupled and decoupled 3D-native generation paradigms. Experiments demonstrate that Photo3D generalizes well across diverse 3D-native generation paradigms and achieves state-of-the-art photorealistic 3D generation performance.",
            "headline_zh": "提出Photo3D框架，通过结构对齐细节增强提升3D生成的真实感",
            "intro_zh": [
                "核心问题：现有3D生成器缺乏高质量真实世界3D资产，导致外观不真实",
                "方法要点：利用GPT-4o-Image生成图像，设计结构对齐多视图合成和细节增强方案",
                "实验或效果：在多种3D生成范式中泛化良好，实现最先进的真实感3D生成性能"
            ],
            "tags_zh": [
                "3D生成",
                "真实感渲染",
                "多视图合成",
                "细节增强",
                "结构对齐"
            ],
            "_index": 114
        },
        {
            "title": "PaintFlow: A Unified Framework for Interactive Oil Paintings Editing and Generation",
            "authors": [
                "Zhangli Hu",
                "Ye Chen",
                "Jiajun Yao",
                "Bingbing Ni"
            ],
            "arxiv_id": "2512.08534v1",
            "summary": "Oil painting, as a high-level medium that blends human abstract thinking with artistic expression, poses substantial challenges for digital generation and editing due to its intricate brushstroke dynamics and stylized characteristics. Existing generation and editing techniques are often constrained by the distribution of training data and primarily focus on modifying real photographs. In this work, we introduce a unified multimodal framework for oil painting generation and editing. The proposed system allows users to incorporate reference images for precise semantic control, hand-drawn sketches for spatial structure alignment, and natural language prompts for high-level semantic guidance, while consistently maintaining a unified painting style across all outputs. Our method achieves interactive oil painting creation through three crucial technical advancements. First, we enhance the training stage with spatial alignment and semantic enhancement conditioning strategy, which map masks and sketches into spatial constraints, and encode contextual embedding from reference images and text into feature constraints, enabling object-level semantic alignment. Second, to overcome data scarcity, we propose a self-supervised style transfer pipeline based on Stroke-Based Rendering (SBR), which simulates the inpainting dynamics of oil painting restoration, converting real images into stylized oil paintings with preserved brushstroke textures to construct a large-scale paired training dataset. Finally, during inference, we integrate features using the AdaIN operator to ensure stylistic consistency. Extensive experiments demonstrate that our interactive system enables fine-grained editing while preserving the artistic qualities of oil paintings, achieving an unprecedented level of imagination realization in stylized oil paintings generation and editing.",
            "headline_zh": "提出PaintFlow统一框架，通过多模态交互实现油画生成与编辑，解决风格一致性和语义控制难题。",
            "intro_zh": [
                "核心问题：油画数字生成与编辑因复杂笔触和风格化特性而受限，现有方法依赖训练数据分布且多针对真实照片。",
                "方法要点：结合空间对齐与语义增强条件策略、基于SBR的自监督风格迁移管道，以及AdaIN特征融合，实现多模态交互控制。",
                "实验或效果：系统支持参考图像、手绘草图和自然语言提示，保持统一油画风格，实验证明能精细编辑并保留艺术品质。"
            ],
            "tags_zh": [
                "油画生成",
                "交互编辑",
                "多模态框架",
                "风格迁移",
                "语义控制",
                "自监督学习"
            ],
            "_index": 115
        },
        {
            "title": "MVP: Multiple View Prediction Improves GUI Grounding",
            "authors": [
                "Yunzhu Zhang",
                "Zeyu Pan",
                "Zhengwen Zeng",
                "Shuheng Shen",
                "Changhua Meng",
                "Linchao Zhu"
            ],
            "arxiv_id": "2512.08529v1",
            "summary": "GUI grounding, which translates natural language instructions into precise pixel coordinates, is essential for developing practical GUI agents. However, we observe that existing grounding models exhibit significant coordinate prediction instability, minor visual perturbations (e.g. cropping a few pixels) can drastically alter predictions, flipping results between correct and incorrect. This instability severely undermines model performance, especially for samples with high-resolution and small UI elements. To address this issue, we propose Multi-View Prediction (MVP), a training-free framework that enhances grounding performance through multi-view inference. Our key insight is that while single-view predictions may be unstable, aggregating predictions from multiple carefully cropped views can effectively distinguish correct coordinates from outliers. MVP comprises two components: (1) Attention-Guided View Proposal, which derives diverse views guided by instruction-to-image attention scores, and (2) Multi-Coordinates Clustering, which ensembles predictions by selecting the centroid of the densest spatial cluster. Extensive experiments demonstrate MVP's effectiveness across various models and benchmarks. Notably, on ScreenSpot-Pro, MVP boosts UI-TARS-1.5-7B to 56.1%, GTA1-7B to 61.7%, Qwen3VL-8B-Instruct to 65.3%, and Qwen3VL-32B-Instruct to 74.0%. The code is available at https://github.com/ZJUSCL/MVP.",
            "headline_zh": "提出多视图预测框架以解决GUI grounding中的坐标预测不稳定问题",
            "intro_zh": [
                "核心问题：现有GUI grounding模型对微小视觉扰动敏感，导致坐标预测不稳定，影响高分辨率和小UI元素样本的性能。",
                "方法要点：通过注意力引导视图提议和多坐标聚类，无训练地聚合多视图预测，区分正确坐标与异常值。",
                "实验或效果：在ScreenSpot-Pro等基准上显著提升多种模型性能，如将Qwen3VL-32B-Instruct提升至74.0%。"
            ],
            "tags_zh": [
                "GUI grounding",
                "坐标预测稳定性",
                "多视图推理",
                "注意力引导",
                "无训练框架",
                "视觉扰动鲁棒性"
            ],
            "_index": 116
        },
        {
            "title": "Beyond Real Weights: Hypercomplex Representations for Stable Quantization",
            "authors": [
                "Jawad Ibn Ahad",
                "Maisha Rahman",
                "Amrijit Biswas",
                "Muhammad Rafsan Kabir",
                "Robin Krambroeckers",
                "Sifat Momen",
                "Nabeel Mohammed",
                "Shafin Rahman"
            ],
            "arxiv_id": "2512.08524v1",
            "summary": "Multimodal language models (MLLMs) require large parameter capacity to align high-dimensional visual features with linguistic representations, making them computationally heavy and difficult to deploy efficiently. We introduce a progressive reparameterization strategy that compresses these models by gradually replacing dense feed-forward network blocks with compact Parameterized Hypercomplex Multiplication (PHM) layers. A residual interpolation schedule, together with lightweight reconstruction and knowledge distillation losses, ensures that the PHM modules inherit the functional behavior of their dense counterparts during training. This transition yields substantial parameter and FLOP reductions while preserving strong multimodal alignment, enabling faster inference without degrading output quality. We evaluate the approach on multiple vision-language models (VLMs). Our method maintains performance comparable to the base models while delivering significant reductions in model size and inference latency. Progressive PHM substitution thus offers an architecture-compatible path toward more efficient multimodal reasoning and complements existing low-bit quantization techniques.",
            "headline_zh": "提出渐进式重参数化策略，通过PHM层压缩多模态语言模型以提升效率。",
            "intro_zh": [
                "多模态语言模型参数庞大，部署困难，需高效压缩方法。",
                "渐进替换密集前馈网络为PHM层，结合残差插值和轻量损失保持功能。",
                "在多个视觉语言模型上验证，保持性能同时显著减少参数和推理延迟。"
            ],
            "tags_zh": [
                "多模态语言模型",
                "模型压缩",
                "渐进式重参数化",
                "参数化超复数乘法",
                "知识蒸馏",
                "推理加速"
            ],
            "_index": 117
        },
        {
            "title": "SensHRPS: Sensing Comfortable Human-Robot Proxemics and Personal Space With Eye-Tracking",
            "authors": [
                "Nadezhda Kushina",
                "Ko Watanabe",
                "Aarthi Kannan",
                "Ashita Ashok",
                "Andreas Dengel",
                "Karsten Berns"
            ],
            "arxiv_id": "2512.08518v1",
            "summary": "Social robots must adjust to human proxemic norms to ensure user comfort and engagement. While prior research demonstrates that eye-tracking features reliably estimate comfort in human-human interactions, their applicability to interactions with humanoid robots remains unexplored. In this study, we investigate user comfort with the robot \"Ameca\" across four experimentally controlled distances (0.5 m to 2.0 m) using mobile eye-tracking and subjective reporting (N=19). We evaluate multiple machine learning and deep learning models to estimate comfort based on gaze features. Contrary to previous human-human studies where Transformer models excelled, a Decision Tree classifier achieved the highest performance (F1-score = 0.73), with minimum pupil diameter identified as the most critical predictor. These findings suggest that physiological comfort thresholds in human-robot interaction differ from human-human dynamics and can be effectively modeled using interpretable logic.",
            "headline_zh": "提出基于眼动追踪的舒适人机距离感知方法，以提升社交机器人交互体验。",
            "intro_zh": [
                "核心问题：社交机器人需适应人类距离规范以确保用户舒适，但眼动特征在人机交互中的适用性未知。",
                "方法要点：使用移动眼动追踪和主观报告，在四个距离下评估用户舒适度，并基于注视特征训练机器学习模型。",
                "实验或效果：决策树模型表现最佳（F1分数0.73），最小瞳孔直径是关键预测因子，表明人机交互舒适阈值与人人交互不同。"
            ],
            "tags_zh": [
                "人机交互",
                "眼动追踪",
                "距离感知",
                "机器学习",
                "舒适度评估",
                "社交机器人"
            ],
            "_index": 118
        },
        {
            "title": "Minimax and Bayes Optimal Adaptive Experimental Design for Treatment Choice",
            "authors": [
                "Masahiro Kato"
            ],
            "arxiv_id": "2512.08513v1",
            "summary": "We consider an adaptive experiment for treatment choice and design a minimax and Bayes optimal adaptive experiment with respect to regret. Given binary treatments, the experimenter's goal is to choose the treatment with the highest expected outcome through an adaptive experiment, in order to maximize welfare. We consider adaptive experiments that consist of two phases, the treatment allocation phase and the treatment choice phase. The experiment starts with the treatment allocation phase, where the experimenter allocates treatments to experimental subjects to gather observations. During this phase, the experimenter can adaptively update the allocation probabilities using the observations obtained in the experiment. After the allocation phase, the experimenter proceeds to the treatment choice phase, where one of the treatments is selected as the best. For this adaptive experimental procedure, we propose an adaptive experiment that splits the treatment allocation phase into two stages, where we first estimate the standard deviations and then allocate each treatment proportionally to its standard deviation. We show that this experiment, often referred to as Neyman allocation, is minimax and Bayes optimal in the sense that its regret upper bounds exactly match the lower bounds that we derive. To show this optimality, we derive minimax and Bayes lower bounds for the regret using change-of-measure arguments. Then, we evaluate the corresponding upper bounds using the central limit theorem and large deviation bounds.",
            "headline_zh": "提出两阶段自适应实验设计，实现治疗选择的最小最大和贝叶斯最优后悔",
            "intro_zh": [
                "核心问题：在二元治疗自适应实验中，如何设计实验以最小化后悔并最大化福利。",
                "方法要点：将治疗分配阶段分为两阶段，先估计标准差，再按标准差比例分配治疗。",
                "实验或效果：证明该设计（Neyman分配）的后悔上界与推导的下界匹配，达到最优性。"
            ],
            "tags_zh": [
                "自适应实验设计",
                "治疗选择",
                "最小最大后悔",
                "贝叶斯最优",
                "Neyman分配",
                "后悔分析"
            ],
            "_index": 119
        },
        {
            "title": "A Lightweight Transfer Learning-Based State-of-Health Monitoring with Application to Lithium-ion Batteries in Unmanned Air Vehicles",
            "authors": [
                "Jiang Liu",
                "Yan Qin",
                "Wei Dai",
                "Chau Yuen"
            ],
            "arxiv_id": "2512.08512v1",
            "summary": "Accurate and rapid state-of-health (SOH) monitoring plays an important role in indicating energy information for lithium-ion battery-powered portable mobile devices. To confront their variable working conditions, transfer learning (TL) emerges as a promising technique for leveraging knowledge from data-rich source working conditions, significantly reducing the training data required for SOH monitoring from target working conditions. However, traditional TL-based SOH monitoring is infeasible when applied in portable mobile devices since substantial computational resources are consumed during the TL stage and unexpectedly reduce the working endurance. To address these challenges, this paper proposes a lightweight TL-based SOH monitoring approach with constructive incremental transfer learning (CITL). First, taking advantage of the unlabeled data in the target domain, a semi-supervised TL mechanism is proposed to minimize the monitoring residual in a constructive way, through iteratively adding network nodes in the CITL. Second, the cross-domain learning ability of node parameters for CITL is comprehensively guaranteed through structural risk minimization, transfer mismatching minimization, and manifold consistency maximization. Moreover, the convergence analysis of the CITL is given, theoretically guaranteeing the efficacy of TL performance and network compactness. Finally, the proposed approach is verified through extensive experiments with a realistic unmanned air vehicles (UAV) battery dataset collected from dozens of flight missions. Specifically, the CITL outperforms SS-TCA, MMD-LSTM-DA, DDAN, BO-CNN-TL, and AS$^3$LSTM, in SOH estimation by 83.73%, 61.15%, 28.24%, 87.70%, and 57.34%, respectively, as evaluated using the index root mean square error.",
            "headline_zh": "提出轻量级迁移学习方法，用于无人机锂离子电池健康状态监测。",
            "intro_zh": [
                "核心问题：传统迁移学习在便携设备中计算资源消耗大，影响续航。",
                "方法要点：采用半监督迁移学习，通过构造性增量迁移学习迭代增加网络节点。",
                "实验或效果：在真实无人机电池数据集上验证，性能优于多种基线方法。"
            ],
            "tags_zh": [
                "锂离子电池",
                "健康状态监测",
                "迁移学习",
                "轻量级模型",
                "无人机应用"
            ],
            "_index": 120
        },
        {
            "title": "Thinking with Images via Self-Calling Agent",
            "authors": [
                "Wenxi Yang",
                "Yuzhong Zhao",
                "Fang Wan",
                "Qixiang Ye"
            ],
            "arxiv_id": "2512.08511v1",
            "summary": "Thinking-with-images paradigms have showcased remarkable visual reasoning capability by integrating visual information as dynamic elements into the Chain-of-Thought (CoT). However, optimizing interleaved multimodal CoT (iMCoT) through reinforcement learning remains challenging, as it relies on scarce high-quality reasoning data. In this study, we propose Self-Calling Chain-of-Thought (sCoT), a novel visual reasoning paradigm that reformulates iMCoT as a language-only CoT with self-calling. Specifically, a main agent decomposes the complex visual reasoning task to atomic subtasks and invokes its virtual replicas, i.e. parameter-sharing subagents, to solve them in isolated context. sCoT enjoys substantial training effectiveness and efficiency, as it requires no explicit interleaving between modalities. sCoT employs group-relative policy optimization to reinforce effective reasoning behavior to enhance optimization. Experiments on HR-Bench 4K show that sCoT improves the overall reasoning performance by up to $1.9\\%$ with $\\sim 75\\%$ fewer GPU hours compared to strong baseline approaches. Code is available at https://github.com/YWenxi/think-with-images-through-self-calling.",
            "headline_zh": "提出自调用思维链以优化视觉推理，通过语言化处理提升训练效率与性能。",
            "intro_zh": [
                "核心问题：多模态思维链依赖高质量数据，强化学习优化困难。",
                "方法要点：将视觉推理重构为纯语言思维链，使用自调用代理分解任务。",
                "实验或效果：在HR-Bench 4K上性能提升1.9%，GPU时间减少约75%。"
            ],
            "tags_zh": [
                "视觉推理",
                "思维链",
                "自调用代理",
                "强化学习优化",
                "多模态处理"
            ],
            "_index": 121
        },
        {
            "title": "Data-Efficient Learning of Anomalous Diffusion with Wavelet Representations: Enabling Direct Learning from Experimental Trajectories",
            "authors": [
                "Gongyi Wang",
                "Yu Zhang",
                "Zihan Huang"
            ],
            "arxiv_id": "2512.08510v1",
            "summary": "Machine learning (ML) has become a versatile tool for analyzing anomalous diffusion trajectories, yet most existing pipelines are trained on large collections of simulated data. In contrast, experimental trajectories, such as those from single-particle tracking (SPT), are typically scarce and may differ substantially from the idealized models used for simulation, leading to degradation or even breakdown of performance when ML methods are applied to real data. To address this mismatch, we introduce a wavelet-based representation of anomalous diffusion that enables data-efficient learning directly from experimental recordings. This representation is constructed by applying six complementary wavelet families to each trajectory and combining the resulting wavelet modulus scalograms. We first evaluate the wavelet representation on simulated trajectories from the andi-datasets benchmark, where it clearly outperforms both feature-based and trajectory-based methods with as few as 1000 training trajectories and still retains an advantage on large training sets. We then use this representation to learn directly from experimental SPT trajectories of fluorescent beads diffusing in F-actin networks, where the wavelet representation remains superior to existing alternatives for both diffusion-exponent regression and mesh-size classification. In particular, when predicting the diffusion exponents of experimental trajectories, a model trained on 1200 experimental tracks using the wavelet representation achieves significantly lower errors than state-of-the-art deep learning models trained purely on $10^6$ simulated trajectories. We associate this data efficiency with the emergence of distinct scale fingerprints disentangling underlying diffusion mechanisms in the wavelet spectra.",
            "headline_zh": "提出基于小波表示的数据高效学习方法，以直接从实验轨迹学习异常扩散",
            "intro_zh": [
                "核心问题：机器学习分析异常扩散时，模拟数据与稀缺实验数据不匹配导致性能下降",
                "方法要点：使用六种小波族构建轨迹表示，结合小波模量尺度图以提升数据效率",
                "实验或效果：在模拟和实验轨迹上优于现有方法，用少量实验数据实现更优预测"
            ],
            "tags_zh": [
                "异常扩散分析",
                "小波表示",
                "数据高效学习",
                "单粒子追踪",
                "实验轨迹学习",
                "扩散机制解耦"
            ],
            "_index": 122
        },
        {
            "title": "Fused Gromov-Wasserstein Contrastive Learning for Effective Enzyme-Reaction Screening",
            "authors": [
                "Gengmo Zhou",
                "Feng Yu",
                "Wenda Wang",
                "Zhifeng Gao",
                "Guolin Ke",
                "Zhewei Wei",
                "Zhen Wang"
            ],
            "arxiv_id": "2512.08508v1",
            "summary": "Enzymes are crucial catalysts that enable a wide range of biochemical reactions. Efficiently identifying specific enzymes from vast protein libraries is essential for advancing biocatalysis. Traditional computational methods for enzyme screening and retrieval are time-consuming and resource-intensive. Recently, deep learning approaches have shown promise. However, these methods focus solely on the interaction between enzymes and reactions, overlooking the inherent hierarchical relationships within each domain. To address these limitations, we introduce FGW-CLIP, a novel contrastive learning framework based on optimizing the fused Gromov-Wasserstein distance. FGW-CLIP incorporates multiple alignments, including inter-domain alignment between reactions and enzymes and intra-domain alignment within enzymes and reactions. By introducing a tailored regularization term, our method minimizes the Gromov-Wasserstein distance between enzyme and reaction spaces, which enhances information integration across these domains. Extensive evaluations demonstrate the superiority of FGW-CLIP in challenging enzyme-reaction tasks. On the widely-used EnzymeMap benchmark, FGW-CLIP achieves state-of-the-art performance in enzyme virtual screening, as measured by BEDROC and EF metrics. Moreover, FGW-CLIP consistently outperforms across all three splits of ReactZyme, the largest enzyme-reaction benchmark, demonstrating robust generalization to novel enzymes and reactions. These results position FGW-CLIP as a promising framework for enzyme discovery in complex biochemical settings, with strong adaptability across diverse screening scenarios.",
            "headline_zh": "提出FGW-CLIP对比学习框架以优化酶-反应筛选任务",
            "intro_zh": [
                "核心问题：传统酶筛选方法耗时且忽略酶与反应域内层次关系",
                "方法要点：基于融合Gromov-Wasserstein距离，结合域间与域内对齐",
                "实验或效果：在EnzymeMap和ReactZyme基准上实现最优性能，泛化性强"
            ],
            "tags_zh": [
                "酶-反应筛选",
                "对比学习",
                "Gromov-Wasserstein距离",
                "生物信息学",
                "深度学习"
            ],
            "_index": 123
        },
        {
            "title": "OCCDiff: Occupancy Diffusion Model for High-Fidelity 3D Building Reconstruction from Noisy Point Clouds",
            "authors": [
                "Jialu Sui",
                "Rui Liu",
                "Hongsheng Zhang"
            ],
            "arxiv_id": "2512.08506v1",
            "summary": "A major challenge in reconstructing buildings from LiDAR point clouds lies in accurately capturing building surfaces under varying point densities and noise interference. To flexibly gather high-quality 3D profiles of the building in diverse resolution, we propose OCCDiff applying latent diffusion in the occupancy function space. Our OCCDiff combines a latent diffusion process with a function autoencoder architecture to generate continuous occupancy functions evaluable at arbitrary locations. Moreover, a point encoder is proposed to provide condition features to diffusion learning, constraint the final occupancy prediction for occupancy decoder, and insert multi-modal features for latent generation to latent encoder. To further enhance the model performance, a multi-task training strategy is employed, ensuring that the point encoder learns diverse and robust feature representations. Empirical results show that our method generates physically consistent samples with high fidelity to the target distribution and exhibits robustness to noisy data.",
            "headline_zh": "提出OCCDiff，基于占用函数空间的潜在扩散模型，用于从噪声点云高保真重建3D建筑",
            "intro_zh": [
                "核心问题：从LiDAR点云重建建筑时，点密度变化和噪声干扰导致表面捕捉不准确",
                "方法要点：结合潜在扩散过程和函数自编码器，在占用函数空间生成连续函数，支持任意位置评估",
                "实验或效果：模型生成物理一致样本，高保真度，对噪声数据鲁棒，多任务训练提升特征表示"
            ],
            "tags_zh": [
                "3D建筑重建",
                "点云处理",
                "潜在扩散模型",
                "占用函数",
                "噪声鲁棒性",
                "多任务学习"
            ],
            "_index": 124
        },
        {
            "title": "Beyond the Noise: Aligning Prompts with Latent Representations in Diffusion Models",
            "authors": [
                "Vasco Ramos",
                "Regev Cohen",
                "Idan Szpektor",
                "Joao Magalhaes"
            ],
            "arxiv_id": "2512.08505v1",
            "summary": "Conditional diffusion models rely on language-to-image alignment methods to steer the generation towards semantically accurate outputs. Despite the success of this architecture, misalignment and hallucinations remain common issues and require automatic misalignment detection tools to improve quality, for example by applying them in a Best-of-N (BoN) post-generation setting. Unfortunately, measuring the alignment after the generation is an expensive step since we need to wait for the overall generation to finish to determine prompt adherence. In contrast, this work hypothesizes that text/image misalignments can be detected early in the denoising process, enabling real-time alignment assessment without waiting for the complete generation. In particular, we propose NoisyCLIP a method that measures semantic alignment in the noisy latent space. This work is the first to explore and benchmark prompt-to-latent misalignment detection during image generation using dual encoders in the reverse diffusion process. We evaluate NoisyCLIP qualitatively and quantitatively and find it reduces computational cost by 50% while achieving 98% of CLIP alignment performance in BoN settings. This approach enables real-time alignment assessment during generation, reducing costs without sacrificing semantic fidelity.",
            "headline_zh": "提出NoisyCLIP方法，在去噪过程中早期检测文本-图像错位，实现实时对齐评估。",
            "intro_zh": [
                "核心问题：条件扩散模型中文本-图像错位和幻觉常见，传统后生成对齐检测成本高。",
                "方法要点：在噪声潜在空间使用双编码器测量语义对齐，探索反向扩散过程中的错位检测。",
                "实验或效果：在BoN设置中减少50%计算成本，达到CLIP对齐性能的98%，支持实时评估。"
            ],
            "tags_zh": [
                "扩散模型",
                "文本-图像对齐",
                "噪声潜在空间",
                "实时检测",
                "计算成本优化"
            ],
            "_index": 125
        },
        {
            "title": "Disrupting Hierarchical Reasoning: Adversarial Protection for Geographic Privacy in Multimodal Reasoning Models",
            "authors": [
                "Jiaming Zhang",
                "Che Wang",
                "Yang Cao",
                "Longtao Huang",
                "Wei Yang Bryan Lim"
            ],
            "arxiv_id": "2512.08503v1",
            "summary": "Multi-modal large reasoning models (MLRMs) pose significant privacy risks by inferring precise geographic locations from personal images through hierarchical chain-of-thought reasoning. Existing privacy protection techniques, primarily designed for perception-based models, prove ineffective against MLRMs' sophisticated multi-step reasoning processes that analyze environmental cues. We introduce \\textbf{ReasonBreak}, a novel adversarial framework specifically designed to disrupt hierarchical reasoning in MLRMs through concept-aware perturbations. Our approach is founded on the key insight that effective disruption of geographic reasoning requires perturbations aligned with conceptual hierarchies rather than uniform noise. ReasonBreak strategically targets critical conceptual dependencies within reasoning chains, generating perturbations that invalidate specific inference steps and cascade through subsequent reasoning stages. To facilitate this approach, we contribute \\textbf{GeoPrivacy-6K}, a comprehensive dataset comprising 6,341 ultra-high-resolution images ($\\geq$2K) with hierarchical concept annotations. Extensive evaluation across seven state-of-the-art MLRMs (including GPT-o3, GPT-5, Gemini 2.5 Pro) demonstrates ReasonBreak's superior effectiveness, achieving a 14.4\\% improvement in tract-level protection (33.8\\% vs 19.4\\%) and nearly doubling block-level protection (33.5\\% vs 16.8\\%). This work establishes a new paradigm for privacy protection against reasoning-based threats.",
            "headline_zh": "提出ReasonBreak对抗框架，通过概念感知扰动保护多模态推理模型中的地理隐私",
            "intro_zh": [
                "多模态大推理模型通过分层思维链推理从个人图像推断精确地理位置，现有隐私保护技术无效",
                "ReasonBreak利用概念感知扰动，针对推理链中的关键概念依赖，破坏分层推理过程",
                "在七种先进模型上评估，ReasonBreak在区域级保护提升14.4%，区块级保护近翻倍"
            ],
            "tags_zh": [
                "地理隐私保护",
                "对抗扰动",
                "多模态推理模型",
                "分层推理",
                "概念感知",
                "隐私数据集"
            ],
            "_index": 126
        },
        {
            "title": "Learning to Control Physically-simulated 3D Characters via Generating and Mimicking 2D Motions",
            "authors": [
                "Jianan Li",
                "Xiao Chen",
                "Tao Huang",
                "Tien-Tsin Wong"
            ],
            "arxiv_id": "2512.08500v1",
            "summary": "Video data is more cost-effective than motion capture data for learning 3D character motion controllers, yet synthesizing realistic and diverse behaviors directly from videos remains challenging. Previous approaches typically rely on off-the-shelf motion reconstruction techniques to obtain 3D trajectories for physics-based imitation. These reconstruction methods struggle with generalizability, as they either require 3D training data (potentially scarce) or fail to produce physically plausible poses, hindering their application to challenging scenarios like human-object interaction (HOI) or non-human characters. We tackle this challenge by introducing Mimic2DM, a novel motion imitation framework that learns the control policy directly and solely from widely available 2D keypoint trajectories extracted from videos. By minimizing the reprojection error, we train a general single-view 2D motion tracking policy capable of following arbitrary 2D reference motions in physics simulation, using only 2D motion data. The policy, when trained on diverse 2D motions captured from different or slightly different viewpoints, can further acquire 3D motion tracking capabilities by aggregating multiple views. Moreover, we develop a transformer-based autoregressive 2D motion generator and integrate it into a hierarchical control framework, where the generator produces high-quality 2D reference trajectories to guide the tracking policy. We show that the proposed approach is versatile and can effectively learn to synthesize physically plausible and diverse motions across a range of domains, including dancing, soccer dribbling, and animal movements, without any reliance on explicit 3D motion data. Project Website: https://jiann-li.github.io/mimic2dm/",
            "headline_zh": "提出Mimic2DM框架，通过生成和模仿2D运动学习物理模拟3D角色控制，无需3D数据。",
            "intro_zh": [
                "核心问题：从视频学习3D角色控制时，现有方法依赖3D运动重建，泛化性差且难以处理复杂场景。",
                "方法要点：直接利用2D关键点轨迹训练跟踪策略，结合变换器生成2D参考运动，实现分层控制。",
                "实验或效果：在舞蹈、足球运球和动物运动等场景中合成物理合理且多样的运动，无需3D数据。"
            ],
            "tags_zh": [
                "2D运动模仿",
                "物理模拟控制",
                "变换器生成",
                "分层控制",
                "视频数据学习"
            ],
            "_index": 127
        },
        {
            "title": "Developing Distance-Aware Uncertainty Quantification Methods in Physics-Guided Neural Networks for Reliable Bearing Health Prediction",
            "authors": [
                "Waleed Razzaq",
                "Yun-Bo Zhao"
            ],
            "arxiv_id": "2512.08499v1",
            "summary": "Accurate and uncertainty-aware degradation estimation is essential for predictive maintenance in safety-critical systems like rotating machinery with rolling-element bearings. Many existing uncertainty methods lack confidence calibration, are costly to run, are not distance-aware, and fail to generalize under out-of-distribution data. We introduce two distance-aware uncertainty methods for deterministic physics-guided neural networks: PG-SNGP, based on Spectral Normalization Gaussian Process, and PG-SNER, based on Deep Evidential Regression. We apply spectral normalization to the hidden layers so the network preserves distances from input to latent space. PG-SNGP replaces the final dense layer with a Gaussian Process layer for distance-sensitive uncertainty, while PG-SNER outputs Normal Inverse Gamma parameters to model uncertainty in a coherent probabilistic form. We assess performance using standard accuracy metrics and a new distance-aware metric based on the Pearson Correlation Coefficient, which measures how well predicted uncertainty tracks the distance between test and training samples. We also design a dynamic weighting scheme in the loss to balance data fidelity and physical consistency. We test our methods on rolling-element bearing degradation using the PRONOSTIA dataset and compare them with Monte Carlo and Deep Ensemble PGNNs. Results show that PG-SNGP and PG-SNER improve prediction accuracy, generalize reliably under OOD conditions, and remain robust to adversarial attacks and noise.",
            "headline_zh": "提出基于谱归一化的距离感知不确定性量化方法，用于物理引导神经网络以提升轴承健康预测的可靠性。",
            "intro_zh": [
                "现有不确定性方法在置信度校准、计算成本、距离感知和分布外泛化方面存在不足。",
                "引入PG-SNGP和PG-SNER两种方法，通过谱归一化保持输入到潜在空间的距离，结合高斯过程或深度证据回归进行不确定性建模。",
                "在PRONOSTIA数据集上测试，显示方法提高预测精度，在分布外条件下可靠泛化，并对对抗攻击和噪声保持鲁棒性。"
            ],
            "tags_zh": [
                "不确定性量化",
                "物理引导神经网络",
                "轴承健康预测",
                "谱归一化",
                "距离感知",
                "分布外泛化"
            ],
            "_index": 128
        },
        {
            "title": "On-the-fly Large-scale 3D Reconstruction from Multi-Camera Rigs",
            "authors": [
                "Yijia Guo",
                "Tong Hu",
                "Zhiwei Li",
                "Liwen Hu",
                "Keming Qian",
                "Xitong Lin",
                "Shengbo Chen",
                "Tiejun Huang",
                "Lei Ma"
            ],
            "arxiv_id": "2512.08498v1",
            "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled efficient free-viewpoint rendering and photorealistic scene reconstruction. While on-the-fly extensions of 3DGS have shown promise for real-time reconstruction from monocular RGB streams, they often fail to achieve complete 3D coverage due to the limited field of view (FOV). Employing a multi-camera rig fundamentally addresses this limitation. In this paper, we present the first on-the-fly 3D reconstruction framework for multi-camera rigs. Our method incrementally fuses dense RGB streams from multiple overlapping cameras into a unified Gaussian representation, achieving drift-free trajectory estimation and efficient online reconstruction. We propose a hierarchical camera initialization scheme that enables coarse inter-camera alignment without calibration, followed by a lightweight multi-camera bundle adjustment that stabilizes trajectories while maintaining real-time performance. Furthermore, we introduce a redundancy-free Gaussian sampling strategy and a frequency-aware optimization scheduler to reduce the number of Gaussian primitives and the required optimization iterations, thereby maintaining both efficiency and reconstruction fidelity. Our method reconstructs hundreds of meters of 3D scenes within just 2 minutes using only raw multi-camera video streams, demonstrating unprecedented speed, robustness, and Fidelity for on-the-fly 3D scene reconstruction.",
            "headline_zh": "提出首个多相机阵列实时3D重建框架，通过增量融合与轻量优化实现高效无漂移重建。",
            "intro_zh": [
                "核心问题：单目3D高斯溅射实时重建因视野有限导致覆盖不全，多相机阵列可解决此问题。",
                "方法要点：采用分层相机初始化与轻量多相机束调整，结合冗余无高斯采样和频率感知优化调度。",
                "实验或效果：仅用原始多相机视频流，在2分钟内重建数百米场景，展现高速、鲁棒和高保真度。"
            ],
            "tags_zh": [
                "实时3D重建",
                "多相机阵列",
                "3D高斯溅射",
                "增量融合",
                "轻量优化",
                "无漂移轨迹估计"
            ],
            "_index": 129
        },
        {
            "title": "LLM-based Vulnerable Code Augmentation: Generate or Refactor?",
            "authors": [
                "Dyna Soumhane Ouchebara",
                "Stéphane Dupont"
            ],
            "arxiv_id": "2512.08493v1",
            "summary": "Vulnerability code-bases often suffer from severe imbalance, limiting the effectiveness of Deep Learning-based vulnerability classifiers. Data Augmentation could help solve this by mitigating the scarcity of under-represented CWEs. In this context, we investigate LLM-based augmentation for vulnerable functions, comparing controlled generation of new vulnerable samples with semantics-preserving refactoring of existing ones. Using Qwen2.5-Coder to produce augmented data and CodeBERT as a vulnerability classifier on the SVEN dataset, we find that our approaches are indeed effective in enriching vulnerable code-bases through a simple process and with reasonable quality, and that a hybrid strategy best boosts vulnerability classifiers' performance.",
            "headline_zh": "提出基于LLM的漏洞代码增强方法，通过生成与重构解决漏洞数据集不平衡问题。",
            "intro_zh": [
                "漏洞代码库存在严重类别不平衡，限制深度学习分类器性能。",
                "比较LLM生成新漏洞样本与重构现有样本的增强策略。",
                "实验表明混合策略能有效提升漏洞分类器在SVEN数据集上的表现。"
            ],
            "tags_zh": [
                "漏洞代码增强",
                "LLM生成",
                "代码重构",
                "数据不平衡",
                "漏洞分类器",
                "SVEN数据集"
            ],
            "_index": 130
        },
        {
            "title": "Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance",
            "authors": [
                "Aliaksei Kaliutau"
            ],
            "arxiv_id": "2512.08492v1",
            "summary": "Recent advances in Large Language Models have revolutionized function-level code generation; however, repository-scale Automated Program Repair (APR) remains a significant challenge. Current approaches typically employ a control-centric paradigm, forcing agents to navigate complex directory structures and irrelevant control logic. In this paper, we propose a paradigm shift from the standard Code Property Graphs (CPGs) to the concept of Data Transformation Graph (DTG) that inverts the topology by modeling data states as nodes and functions as edges, enabling agents to trace logic defects through data lineage rather than control flow. We introduce a multi-agent framework that reconciles data integrity navigation with control flow logic. Our theoretical analysis and case studies demonstrate that this approach resolves the \"Semantic Trap\" inherent in standard RAG systems in modern coding agents. We provide a comprehensive implementation in the form of Autonomous Issue Resolver (AIR), a self-improvement system for zero-touch code maintenance that utilizes neuro-symbolic reasoning and uses the DTG structure for scalable logic repair. Our approach has demonstrated good results on several SWE benchmarks, reaching a resolution rate of 87.1% on SWE-Verified benchmark. Our approach directly addresses the core limitations of current AI code-assistant tools and tackles the critical need for a more robust foundation for our increasingly software-dependent world.",
            "headline_zh": "提出数据转换图与多智能体框架，实现零接触代码维护以解决仓库级程序修复难题。",
            "intro_zh": [
                "核心问题：当前仓库级自动程序修复方法受限于控制中心范式，导致智能体陷入复杂目录和无关控制逻辑的语义陷阱。",
                "方法要点：从代码属性图转向数据转换图，以数据状态为节点、函数为边，通过数据谱系追踪逻辑缺陷，结合神经符号推理。",
                "实验或效果：在SWE-Verified基准测试中达到87.1%的解决率，验证了方法的有效性。"
            ],
            "tags_zh": [
                "自动程序修复",
                "数据转换图",
                "多智能体框架",
                "神经符号推理",
                "零接触代码维护"
            ],
            "_index": 131
        },
        {
            "title": "Temporal Concept Dynamics in Diffusion Models via Prompt-Conditioned Interventions",
            "authors": [
                "Ada Gorgun",
                "Fawaz Sammani",
                "Nikos Deligiannis",
                "Bernt Schiele",
                "Jonas Fischer"
            ],
            "arxiv_id": "2512.08486v1",
            "summary": "Diffusion models are usually evaluated by their final outputs, gradually denoising random noise into meaningful images. Yet, generation unfolds along a trajectory, and analyzing this dynamic process is crucial for understanding how controllable, reliable, and predictable these models are in terms of their success/failure modes. In this work, we ask the question: when does noise turn into a specific concept (e.g., age) and lock in the denoising trajectory? We propose PCI (Prompt-Conditioned Intervention) to study this question. PCI is a training-free and model-agnostic framework for analyzing concept dynamics through diffusion time. The central idea is the analysis of Concept Insertion Success (CIS), defined as the probability that a concept inserted at a given timestep is preserved and reflected in the final image, offering a way to characterize the temporal dynamics of concept formation. Applied to several state-of-the-art text-to-image diffusion models and a broad taxonomy of concepts, PCI reveals diverse temporal behaviors across diffusion models, in which certain phases of the trajectory are more favorable to specific concepts even within the same concept type. These findings also provide actionable insights for text-driven image editing, highlighting when interventions are most effective without requiring access to model internals or training, and yielding quantitatively stronger edits that achieve a balance of semantic accuracy and content preservation than strong baselines. Code is available at: https://github.com/adagorgun/PCI-Prompt-Controlled-Interventions",
            "headline_zh": "提出PCI框架以分析扩散模型中概念形成的时序动态，用于文本驱动图像编辑。",
            "intro_zh": [
                "核心问题：扩散模型生成过程中，特定概念何时形成并锁定轨迹，影响可控性与可靠性。",
                "方法要点：PCI通过训练无关、模型无关的框架，分析概念插入成功率来量化概念动态。",
                "实验或效果：应用于多款扩散模型和概念分类，揭示时序行为差异，提供编辑时机洞察，提升编辑效果。"
            ],
            "tags_zh": [
                "扩散模型",
                "概念动态分析",
                "时序干预",
                "文本到图像生成",
                "图像编辑",
                "模型可解释性"
            ],
            "_index": 132
        },
        {
            "title": "Optimal Perturbation Budget Allocation for Data Poisoning in Offline Reinforcement Learning",
            "authors": [
                "Junnan Qiu",
                "Jie Li"
            ],
            "arxiv_id": "2512.08485v1",
            "summary": "Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to data poisoning attacks. Existing attack strategies typically rely on locally uniform perturbations, which treat all samples indiscriminately. This approach is inefficient, as it wastes the perturbation budget on low-impact samples, and lacks stealthiness due to significant statistical deviations. In this paper, we propose a novel Global Budget Allocation attack strategy. Leveraging the theoretical insight that a sample's influence on value function convergence is proportional to its Temporal Difference (TD) error, we formulate the attack as a global resource allocation problem. We derive a closed-form solution where perturbation magnitudes are assigned proportional to the TD-error sensitivity under a global L2 constraint. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms baseline strategies, achieving up to 80% performance degradation with minimal perturbations that evade detection by state-of-the-art statistical and spectral defenses.",
            "headline_zh": "提出全局预算分配攻击策略，以优化离线强化学习中的数据投毒扰动分配",
            "intro_zh": [
                "离线强化学习易受数据投毒攻击，现有方法采用均匀扰动效率低且隐蔽性差",
                "基于TD误差影响理论，将攻击建模为全局资源分配问题，推导出闭式解分配扰动幅度",
                "在D4RL基准测试中，以最小扰动实现高达80%性能下降，并规避先进防御检测"
            ],
            "tags_zh": [
                "离线强化学习",
                "数据投毒攻击",
                "全局预算分配",
                "TD误差",
                "扰动优化",
                "防御规避"
            ],
            "_index": 133
        },
        {
            "title": "Prospect Theory in Physical Human-Robot Interaction: A Pilot Study of Probability Perception",
            "authors": [
                "Yixiang Lin",
                "Tiancheng Yang",
                "Jonathan Eden",
                "Ying Tan"
            ],
            "arxiv_id": "2512.08481v1",
            "summary": "Understanding how humans respond to uncertainty is critical for designing safe and effective physical human-robot interaction (pHRI), as physically working with robots introduces multiple sources of uncertainty, including trust, comfort, and perceived safety. Conventional pHRI control frameworks typically build on optimal control theory, which assumes that human actions minimize a cost function; however, human behavior under uncertainty often departs from such optimal patterns. To address this gap, additional understanding of human behavior under uncertainty is needed. This pilot study implemented a physically coupled target-reaching task in which the robot delivered assistance or disturbances with systematically varied probabilities (10\\% to 90\\%). Analysis of participants' force inputs and decision-making strategies revealed two distinct behavioral clusters: a \"trade-off\" group that modulated their physical responses according to disturbance likelihood, and an \"always-compensate\" group characterized by strong risk aversion irrespective of probability. These findings provide empirical evidence that human decision-making in pHRI is highly individualized and that the perception of probability can differ to its true value. Accordingly, the study highlights the need for more interpretable behavioral models, such as cumulative prospect theory (CPT), to more accurately capture these behaviors and inform the design of future adaptive robot controllers.",
            "headline_zh": "通过概率感知实验揭示物理人机交互中人类决策的个体差异，支持累积前景理论建模。",
            "intro_zh": [
                "核心问题：物理人机交互中人类在不确定性下的行为偏离最优控制假设，需更准确的行为模型。",
                "方法要点：设计物理耦合目标达成任务，系统变化机器人辅助或干扰概率（10%至90%）。",
                "实验或效果：分析发现两种行为集群：概率调节组和风险规避组，显示概率感知个体化差异。"
            ],
            "tags_zh": [
                "物理人机交互",
                "概率感知",
                "累积前景理论",
                "行为建模",
                "不确定性决策",
                "自适应控制"
            ],
            "_index": 134
        },
        {
            "title": "Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform",
            "authors": [
                "Yuning Gong",
                "Yifei Liu",
                "Yifan Zhan",
                "Muyao Niu",
                "Xueying Li",
                "Yuanjun Liao",
                "Jiaming Chen",
                "Yuanyuan Gao",
                "Jiaqi Chen",
                "Minming Chen",
                "Li Zhou",
                "Yuning Zhang",
                "Wei Wang",
                "Xiaoqing Hou",
                "Huaxi Huang",
                "Shixiang Tang",
                "Le Ma",
                "Dingwen Zhang",
                "Xue Yang",
                "Junchi Yan",
                "Yanchi Zhang",
                "Yinqiang Zheng",
                "Xiao Sun",
                "Zhihang Zhong"
            ],
            "arxiv_id": "2512.08478v1",
            "summary": "Neural rendering, particularly 3D Gaussian Splatting (3DGS), has evolved rapidly and become a key component for building world models. However, existing viewer solutions remain fragmented, heavy, or constrained by legacy pipelines, resulting in high deployment friction and limited support for dynamic content and generative models. In this work, we present Visionary, an open, web-native platform for real-time various Gaussian Splatting and meshes rendering. Built on an efficient WebGPU renderer with per-frame ONNX inference, Visionary enables dynamic neural processing while maintaining a lightweight, \"click-to-run\" browser experience. It introduces a standardized Gaussian Generator contract, which not only supports standard 3DGS rendering but also allows plug-and-play algorithms to generate or update Gaussians each frame. Such inference also enables us to apply feedforward generative post-processing. The platform further offers a plug in three.js library with a concise TypeScript API for seamless integration into existing web applications. Experiments show that, under identical 3DGS assets, Visionary achieves superior rendering efficiency compared to current Web viewers due to GPU-based primitive sorting. It already supports multiple variants, including MLP-based 3DGS, 4DGS, neural avatars, and style transformation or enhancement networks. By unifying inference and rendering directly in the browser, Visionary significantly lowers the barrier to reproduction, comparison, and deployment of 3DGS-family methods, serving as a unified World Model Carrier for both reconstructive and generative paradigms.",
            "headline_zh": "提出Visionary平台，基于WebGPU和ONNX推理实现浏览器内实时动态高斯溅射渲染，降低世界模型部署门槛。",
            "intro_zh": [
                "现有高斯溅射渲染方案碎片化、笨重，部署困难且动态内容支持有限。",
                "Visionary采用WebGPU渲染器和每帧ONNX推理，支持标准3DGS及插件式算法生成动态高斯。",
                "实验显示，在相同资产下，Visionary通过GPU基元排序实现更高渲染效率，支持多种变体如4DGS和神经化身。"
            ],
            "tags_zh": [
                "高斯溅射渲染",
                "WebGPU平台",
                "动态神经处理",
                "浏览器内推理",
                "世界模型载体",
                "实时渲染"
            ],
            "_index": 135
        },
        {
            "title": "ContextDrag: Precise Drag-Based Image Editing via Context-Preserving Token Injection and Position-Consistent Attention",
            "authors": [
                "Huiguo He",
                "Pengyu Yan",
                "Ziqi Yi",
                "Weizhi Zhong",
                "Zheng Liu",
                "Yejun Tang",
                "Huan Yang",
                "Kun Gai",
                "Guanbin Li",
                "Lianwen Jin"
            ],
            "arxiv_id": "2512.08477v1",
            "summary": "Drag-based image editing aims to modify visual content followed by user-specified drag operations. Despite existing methods having made notable progress, they still fail to fully exploit the contextual information in the reference image, including fine-grained texture details, leading to edits with limited coherence and fidelity. To address this challenge, we introduce ContextDrag, a new paradigm for drag-based editing that leverages the strong contextual modeling capability of editing models, such as FLUX-Kontext. By incorporating VAE-encoded features from the reference image, ContextDrag can leverage rich contextual cues and preserve fine-grained details, without the need for finetuning or inversion. Specifically, ContextDrag introduced a novel Context-preserving Token Injection (CTI) that injects noise-free reference features into their correct destination locations via a Latent-space Reverse Mapping (LRM) algorithm. This strategy enables precise drag control while preserving consistency in both semantics and texture details. Second, ContextDrag adopts a novel Position-Consistent Attention (PCA), which positional re-encodes the reference tokens and applies overlap-aware masking to eliminate interference from irrelevant reference features. Extensive experiments on DragBench-SR and DragBench-DR demonstrate that our approach surpasses all existing SOTA methods. Code will be publicly available.",
            "headline_zh": "提出ContextDrag，通过上下文保留令牌注入和位置一致注意力实现精确拖拽式图像编辑",
            "intro_zh": [
                "核心问题：现有拖拽式编辑方法未能充分利用参考图像的上下文信息，导致编辑连贯性和保真度不足",
                "方法要点：引入上下文保留令牌注入（CTI）和位置一致注意力（PCA），无需微调即可保留细粒度细节",
                "实验或效果：在DragBench-SR和DragBench-DR上超越所有现有SOTA方法，代码将公开"
            ],
            "tags_zh": [
                "拖拽式图像编辑",
                "上下文建模",
                "令牌注入",
                "注意力机制",
                "图像保真度"
            ],
            "_index": 136
        },
        {
            "title": "A Multi-Agent LLM Framework for Design Space Exploration in Autonomous Driving Systems",
            "authors": [
                "Po-An Shih",
                "Shao-Hua Wang",
                "Yung-Che Li",
                "Chia-Heng Tu",
                "Chih-Han Chang"
            ],
            "arxiv_id": "2512.08476v1",
            "summary": "Designing autonomous driving systems requires efficient exploration of large hardware/software configuration spaces under diverse environmental conditions, e.g., with varying traffic, weather, and road layouts. Traditional design space exploration (DSE) approaches struggle with multi-modal execution outputs and complex performance trade-offs, and often require human involvement to assess correctness based on execution outputs. This paper presents a multi-agent, large language model (LLM)-based DSE framework, which integrates multi-modal reasoning with 3D simulation and profiling tools to automate the interpretation of execution outputs and guide the exploration of system designs. Specialized LLM agents are leveraged to handle user input interpretation, design point generation, execution orchestration, and analysis of both visual and textual execution outputs, which enables identification of potential bottlenecks without human intervention. A prototype implementation is developed and evaluated on a robotaxi case study (an SAE Level 4 autonomous driving application). Compared with a genetic algorithm baseline, the proposed framework identifies more Pareto-optimal, cost-efficient solutions with reduced navigation time under the same exploration budget. Experimental results also demonstrate the efficiency of the adoption of the LLM-based approach for DSE. We believe that this framework paves the way to the design automation of autonomous driving systems.",
            "headline_zh": "提出基于多智能体LLM的设计空间探索框架，以自动化自动驾驶系统设计优化。",
            "intro_zh": [
                "核心问题：传统设计空间探索方法难以处理多模态执行输出和复杂性能权衡，依赖人工评估。",
                "方法要点：利用多智能体LLM集成多模态推理与3D仿真工具，自动化解释执行输出并生成设计点。",
                "实验或效果：在机器人出租车案例中，相比遗传算法基线，在相同探索预算下识别更多帕累托最优、成本效益高的解决方案。"
            ],
            "tags_zh": [
                "自动驾驶系统",
                "设计空间探索",
                "多智能体LLM",
                "多模态推理",
                "自动化设计"
            ],
            "_index": 137
        },
        {
            "title": "Solving Over-Smoothing in GNNs via Nonlocal Message Passing: Algebraic Smoothing and Depth Scalability",
            "authors": [
                "Weiqi Guan",
                "Junlin He"
            ],
            "arxiv_id": "2512.08475v1",
            "summary": "The relationship between Layer Normalization (LN) placement and the over-smoothing phenomenon remains underexplored. We identify a critical dilemma: Pre-LN architectures avoid over-smoothing but suffer from the curse of depth, while Post-LN architectures bypass the curse of depth but experience over-smoothing.\n  To resolve this, we propose a new method based on Post-LN that induces algebraic smoothing, preventing over-smoothing without the curse of depth. Empirical results across five benchmarks demonstrate that our approach supports deeper networks (up to 256 layers) and improves performance, requiring no additional parameters.\n  Key contributions:\n  Theoretical Characterization: Analysis of LN dynamics and their impact on over-smoothing and the curse of depth.\n  A Principled Solution: A parameter-efficient method that induces algebraic smoothing and avoids over-smoothing and the curse of depth.\n  Empirical Validation: Extensive experiments showing the effectiveness of the method in deeper GNNs.",
            "headline_zh": "提出基于Post-LN的非局部消息传递方法，通过代数平滑解决GNN中的过平滑问题，避免深度诅咒。",
            "intro_zh": [
                "核心问题：层归一化位置选择导致过平滑与深度诅咒的困境，Post-LN架构易过平滑，Pre-LN架构受深度诅咒影响。",
                "方法要点：基于Post-LN引入代数平滑机制，无需额外参数，防止过平滑同时避免深度诅咒。",
                "实验或效果：在五个基准测试中验证，支持高达256层的深层网络，性能提升。"
            ],
            "tags_zh": [
                "图神经网络",
                "过平滑问题",
                "层归一化",
                "深度可扩展性",
                "代数平滑"
            ],
            "_index": 138
        },
        {
            "title": "Team-Aware Football Player Tracking with SAM: An Appearance-Based Approach to Occlusion Recovery",
            "authors": [
                "Chamath Ranasinghe",
                "Uthayasanker Thayasivam"
            ],
            "arxiv_id": "2512.08467v1",
            "summary": "Football player tracking is challenged by frequent occlusions, similar appearances, and rapid motion in crowded scenes. This paper presents a lightweight SAM-based tracking method combining the Segment Anything Model (SAM) with CSRT trackers and jersey color-based appearance models. We propose a team-aware tracking system that uses SAM for precise initialization and HSV histogram-based re-identification to improve occlusion recovery. Our evaluation measures three dimensions: processing speed (FPS and memory), tracking accuracy (success rate and box stability), and robustness (occlusion recovery and identity consistency). Experiments on football video sequences show that the approach achieves 7.6-7.7 FPS with stable memory usage (~1880 MB), maintaining 100 percent tracking success in light occlusions and 90 percent in crowded penalty-box scenarios with 5 or more players. Appearance-based re-identification recovers 50 percent of heavy occlusions, demonstrating the value of domain-specific cues. Analysis reveals key trade-offs: the SAM + CSRT combination provides consistent performance across crowd densities but struggles with long-term occlusions where players leave the frame, achieving only 8.66 percent re-acquisition success. These results offer practical guidelines for deploying football tracking systems under resource constraints, showing that classical tracker-based methods work well with continuous visibility but require stronger re-identification mechanisms for extended absences.",
            "headline_zh": "提出基于SAM的团队感知足球球员跟踪方法，结合外观模型以提升遮挡恢复能力。",
            "intro_zh": [
                "核心问题：足球球员跟踪面临频繁遮挡、外观相似和快速运动等挑战。",
                "方法要点：结合SAM进行精确初始化，使用HSV直方图外观模型进行重识别以改进遮挡恢复。",
                "实验效果：在足球视频序列中，轻遮挡下跟踪成功率100%，拥挤场景下90%，重遮挡恢复率50%。"
            ],
            "tags_zh": [
                "足球球员跟踪",
                "遮挡恢复",
                "SAM模型",
                "外观重识别",
                "团队感知",
                "实时处理"
            ],
            "_index": 139
        },
        {
            "title": "Using reinforcement learning to probe the role of feedback in skill acquisition",
            "authors": [
                "Antonio Terpin",
                "Raffaello D'Andrea"
            ],
            "arxiv_id": "2512.08463v1",
            "summary": "Many high-performance human activities are executed with little or no external feedback: think of a figure skater landing a triple jump, a pitcher throwing a curveball for a strike, or a barista pouring latte art. To study the process of skill acquisition under fully controlled conditions, we bypass human subjects. Instead, we directly interface a generalist reinforcement learning agent with a spinning cylinder in a tabletop circulating water channel to maximize or minimize drag. This setup has several desirable properties. First, it is a physical system, with the rich interactions and complex dynamics that only the physical world has: the flow is highly chaotic and extremely difficult, if not impossible, to model or simulate accurately. Second, the objective -- drag minimization or maximization -- is easy to state and can be captured directly in the reward, yet good strategies are not obvious beforehand. Third, decades-old experimental studies provide recipes for simple, high-performance open-loop policies. Finally, the setup is inexpensive and far easier to reproduce than human studies. In our experiments we find that high-dimensional flow feedback lets the agent discover high-performance drag-control strategies with only minutes of real-world interaction. When we later replay the same action sequences without any feedback, we obtain almost identical performance. This shows that feedback, and in particular flow feedback, is not needed to execute the learned policy. Surprisingly, without flow feedback during training the agent fails to discover any well-performing policy in drag maximization, but still succeeds in drag minimization, albeit more slowly and less reliably. Our studies show that learning a high-performance skill can require richer information than executing it, and learning conditions can be kind or wicked depending solely on the goal, not on dynamics or policy complexity.",
            "headline_zh": "通过强化学习探究反馈在技能获取中的作用，使用旋转圆柱体实验验证反馈对学习与执行的影响差异。",
            "intro_zh": [
                "研究技能获取中反馈的作用，以物理系统替代人类实验，聚焦于拖曳力控制任务。",
                "采用强化学习代理与旋转圆柱体交互，利用高维流反馈快速发现高性能策略。",
                "实验显示学习需要反馈，但执行无需反馈，且学习效果受目标（最小化或最大化拖曳力）影响显著。"
            ],
            "tags_zh": [
                "强化学习",
                "技能获取",
                "反馈机制",
                "物理系统实验",
                "拖曳力控制"
            ],
            "_index": 140
        },
        {
            "title": "Transformers for Multimodal Brain State Decoding: Integrating Functional Magnetic Resonance Imaging Data and Medical Metadata",
            "authors": [
                "Danial Jafarzadeh Jazi",
                "Maryam Hajiesmaeili"
            ],
            "arxiv_id": "2512.08462v1",
            "summary": "Decoding brain states from functional magnetic resonance imaging (fMRI) data is vital for advancing neuroscience and clinical applications. While traditional machine learning and deep learning approaches have made strides in leveraging the high-dimensional and complex nature of fMRI data, they often fail to utilize the contextual richness provided by Digital Imaging and Communications in Medicine (DICOM) metadata. This paper presents a novel framework integrating transformer-based architectures with multimodal inputs, including fMRI data and DICOM metadata. By employing attention mechanisms, the proposed method captures intricate spatial-temporal patterns and contextual relationships, enhancing model accuracy, interpretability, and robustness. The potential of this framework spans applications in clinical diagnostics, cognitive neuroscience, and personalized medicine. Limitations, such as metadata variability and computational demands, are addressed, and future directions for optimizing scalability and generalizability are discussed.",
            "headline_zh": "提出基于Transformer的多模态框架，整合fMRI数据与DICOM元数据以解码脑状态。",
            "intro_zh": [
                "核心问题：传统方法难以利用DICOM元数据的上下文信息解码fMRI脑状态。",
                "方法要点：采用Transformer架构，通过注意力机制融合fMRI和元数据，捕捉时空模式。",
                "实验或效果：增强模型准确性、可解释性和鲁棒性，应用于临床诊断和神经科学。"
            ],
            "tags_zh": [
                "脑状态解码",
                "多模态Transformer",
                "fMRI数据分析",
                "DICOM元数据",
                "注意力机制",
                "临床应用"
            ],
            "_index": 141
        },
        {
            "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models III: Implementing the Bacterial Biothreat Benchmark (B3) Dataset",
            "authors": [
                "Gary Ackerman",
                "Theodore Wilson",
                "Zachary Kallenborn",
                "Olivia Shoemaker",
                "Anna Wetzel",
                "Hayley Peterson",
                "Abigail Danfora",
                "Jenna LaTourette",
                "Brandon Behlendorf",
                "Douglas Clifford"
            ],
            "arxiv_id": "2512.08459v1",
            "summary": "The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper discusses the pilot implementation of the Bacterial Biothreat Benchmark (B3) dataset. It is the third in a series of three papers describing an overall Biothreat Benchmark Generation (BBG) framework, with previous papers detailing the development of the B3 dataset. The pilot involved running the benchmarks through a sample frontier AI model, followed by human evaluation of model responses, and an applied risk analysis of the results along several dimensions. Overall, the pilot demonstrated that the B3 dataset offers a viable, nuanced method for rapidly assessing the biosecurity risk posed by a LLM, identifying the key sources of that risk and providing guidance for priority areas of mitigation priority.",
            "headline_zh": "提出细菌生物威胁基准数据集以评估前沿AI模型的生物安全风险",
            "intro_zh": [
                "核心问题：前沿AI模型可能助长生物恐怖主义，需量化风险。",
                "方法要点：开发B3数据集作为基准，用于快速评估大型语言模型的生物安全风险。",
                "实验或效果：通过样本模型测试和人工评估，验证B3能识别风险源并提供缓解指导。"
            ],
            "tags_zh": [
                "生物安全基准",
                "大型语言模型评估",
                "细菌生物威胁",
                "风险分析",
                "AI模型测试"
            ],
            "_index": 142
        },
        {
            "title": "Biothreat Benchmark Generation Framework for Evaluating Frontier AI Models II: Benchmark Generation Process",
            "authors": [
                "Gary Ackerman",
                "Zachary Kallenborn",
                "Anna Wetzel",
                "Hayley Peterson",
                "Jenna LaTourette",
                "Olivia Shoemaker",
                "Brandon Behlendorf",
                "Sheriff Almakki",
                "Doug Clifford",
                "Noah Sheinbaum"
            ],
            "arxiv_id": "2512.08451v1",
            "summary": "The potential for rapidly-evolving frontier artificial intelligence (AI) models, especially large language models (LLMs), to facilitate bioterrorism or access to biological weapons has generated significant policy, academic, and public concern. Both model developers and policymakers seek to quantify and mitigate any risk, with an important element of such efforts being the development of model benchmarks that can assess the biosecurity risk posed by a particular model. This paper, the second in a series of three, describes the second component of a novel Biothreat Benchmark Generation (BBG) framework: the generation of the Bacterial Biothreat Benchmark (B3) dataset. The development process involved three complementary approaches: 1) web-based prompt generation, 2) red teaming, and 3) mining existing benchmark corpora, to generate over 7,000 potential benchmarks linked to the Task-Query Architecture that was developed during the first component of the project. A process of de-duplication, followed by an assessment of uplift diagnosticity, and general quality control measures, reduced the candidates to a set of 1,010 final benchmarks. This procedure ensured that these benchmarks are a) diagnostic in terms of providing uplift; b) directly relevant to biosecurity threats; and c) are aligned with a larger biosecurity architecture permitting nuanced analysis at different levels of analysis.",
            "headline_zh": "提出细菌生物威胁基准生成框架，用于评估前沿AI模型的生物安全风险",
            "intro_zh": [
                "核心问题：前沿AI模型可能被用于生物恐怖主义，需量化其生物安全风险",
                "方法要点：通过网页提示生成、红队测试和挖掘现有语料库，生成超过7,000个潜在基准",
                "实验或效果：经过去重和诊断性评估，最终筛选出1,010个基准，确保其诊断性、相关性和分析层次对齐"
            ],
            "tags_zh": [
                "生物安全基准",
                "前沿AI评估",
                "红队测试",
                "基准生成框架",
                "生物威胁分析"
            ],
            "_index": 143
        },
        {
            "title": "From Accuracy to Impact: The Impact-Driven AI Framework (IDAIF) for Aligning Engineering Architecture with Theory of Change",
            "authors": [
                "Yong-Woon Kim"
            ],
            "arxiv_id": "2512.08449v1",
            "summary": "This paper introduces the Impact-Driven AI Framework (IDAIF), a novel architectural methodology that integrates Theory of Change (ToC) principles with modern artificial intelligence system design. As AI systems increasingly influence high-stakes domains including healthcare, finance, and public policy, the alignment problem--ensuring AI behavior corresponds with human values and intentions--has become critical. Current approaches predominantly optimize technical performance metrics while neglecting the sociotechnical dimensions of AI deployment. IDAIF addresses this gap by establishing a systematic mapping between ToC's five-stage model (Inputs-Activities-Outputs-Outcomes-Impact) and corresponding AI architectural layers (Data Layer-Pipeline Layer-Inference Layer-Agentic Layer-Normative Layer). Each layer incorporates rigorous theoretical foundations: multi-objective Pareto optimization for value alignment, hierarchical multi-agent orchestration for outcome achievement, causal directed acyclic graphs (DAGs) for hallucination mitigation, and adversarial debiasing with Reinforcement Learning from Human Feedback (RLHF) for fairness assurance. We provide formal mathematical formulations for each component and introduce an Assurance Layer that manages assumption failures through guardian architectures. Three case studies demonstrate IDAIF application across healthcare, cybersecurity, and software engineering domains. This framework represents a paradigm shift from model-centric to impact-centric AI development, providing engineers with concrete architectural patterns for building ethical, trustworthy, and socially beneficial AI systems.",
            "headline_zh": "提出IDAIF框架以解决AI系统在高风险领域中的对齐问题，通过整合变革理论与AI架构设计。",
            "intro_zh": [
                "核心问题：AI系统在高风险领域部署时，技术性能优化常忽视社会技术维度，导致对齐问题。",
                "方法要点：IDAIF将变革理论的五阶段模型映射到AI架构层，集成多目标优化、多智能体编排等技术。",
                "实验或效果：通过三个案例研究在医疗、网络安全和软件工程领域展示应用，实现从模型中心到影响中心的范式转变。"
            ],
            "tags_zh": [
                "AI对齐",
                "变革理论",
                "多目标优化",
                "多智能体系统",
                "因果图",
                "RLHF"
            ],
            "_index": 144
        },
        {
            "title": "Uncertainty-Aware Subset Selection for Robust Visual Explainability under Distribution Shifts",
            "authors": [
                "Madhav Gupta",
                "Vishak Prasad C",
                "Ganesh Ramakrishnan"
            ],
            "arxiv_id": "2512.08445v1",
            "summary": "Subset selection-based methods are widely used to explain deep vision models: they attribute predictions by highlighting the most influential image regions and support object-level explanations. While these methods perform well in in-distribution (ID) settings, their behavior under out-of-distribution (OOD) conditions remains poorly understood. Through extensive experiments across multiple ID-OOD sets, we find that reliability of the existing subset based methods degrades markedly, yielding redundant, unstable, and uncertainty-sensitive explanations. To address these shortcomings, we introduce a framework that combines submodular subset selection with layer-wise, gradient-based uncertainty estimation to improve robustness and fidelity without requiring additional training or auxiliary models. Our approach estimates uncertainty via adaptive weight perturbations and uses these estimates to guide submodular optimization, ensuring diverse and informative subset selection. Empirical evaluations show that, beyond mitigating the weaknesses of existing methods under OOD scenarios, our framework also yields improvements in ID settings. These findings highlight limitations of current subset-based approaches and demonstrate how uncertainty-driven optimization can enhance attribution and object-level interpretability, paving the way for more transparent and trustworthy AI in real-world vision applications.",
            "headline_zh": "提出不确定性感知子集选择框架，以提升视觉可解释性在分布偏移下的鲁棒性。",
            "intro_zh": [
                "核心问题：现有基于子集选择的可解释方法在分布外场景中可靠性下降，产生冗余、不稳定解释。",
                "方法要点：结合子模子集选择与基于梯度的层间不确定性估计，通过自适应权重扰动引导优化。",
                "实验或效果：在多个分布内外数据集上验证，框架提升鲁棒性和保真度，且在分布内场景也有改进。"
            ],
            "tags_zh": [
                "视觉可解释性",
                "子集选择",
                "分布偏移",
                "不确定性估计",
                "鲁棒性",
                "梯度方法"
            ],
            "_index": 145
        },
        {
            "title": "Learned iterative networks: An operator learning perspective",
            "authors": [
                "Andreas Hauptmann",
                "Ozan Öktem"
            ],
            "arxiv_id": "2512.08444v1",
            "summary": "Learned image reconstruction has become a pillar in computational imaging and inverse problems. Among the most successful approaches are learned iterative networks, which are formulated by unrolling classical iterative optimisation algorithms for solving variational problems. While the underlying algorithm is usually formulated in the functional analytic setting, learned approaches are often viewed as purely discrete. In this chapter we present a unified operator view for learned iterative networks. Specifically, we formulate a learned reconstruction operator, defining how to compute, and separately the learning problem, which defines what to compute. In this setting we present common approaches and show that many approaches are closely related in their core. We review linear as well as nonlinear inverse problems in this framework and present a short numerical study to conclude.",
            "headline_zh": "提出统一算子视角以分析学习迭代网络在计算成像中的应用",
            "intro_zh": [
                "核心问题：学习迭代网络在计算成像中缺乏统一的算子理论框架",
                "方法要点：将学习重建算子分解为计算方式与学习目标两部分",
                "实验或效果：通过数值研究验证框架对线性和非线性逆问题的适用性"
            ],
            "tags_zh": [
                "学习迭代网络",
                "算子学习",
                "计算成像",
                "逆问题",
                "变分方法"
            ],
            "_index": 146
        },
        {
            "title": "Fully Decentralized Certified Unlearning",
            "authors": [
                "Hithem Lamri",
                "Michail Maniatakos"
            ],
            "arxiv_id": "2512.08443v1",
            "summary": "Machine unlearning (MU) seeks to remove the influence of specified data from a trained model in response to privacy requests or data poisoning. While certified unlearning has been analyzed in centralized and server-orchestrated federated settings (via guarantees analogous to differential privacy, DP), the decentralized setting -- where peers communicate without a coordinator remains underexplored. We study certified unlearning in decentralized networks with fixed topologies and propose RR-DU, a random-walk procedure that performs one projected gradient ascent step on the forget set at the unlearning client and a geometrically distributed number of projected descent steps on the retained data elsewhere, combined with subsampled Gaussian noise and projection onto a trust region around the original model. We provide (i) convergence guarantees in the convex case and stationarity guarantees in the nonconvex case, (ii) $(\\varepsilon,δ)$ network-unlearning certificates on client views via subsampled Gaussian $Rényi$ DP (RDP) with segment-level subsampling, and (iii) deletion-capacity bounds that scale with the forget-to-local data ratio and quantify the effect of decentralization (network mixing and randomized subsampling) on the privacy--utility trade-off. Empirically, on image benchmarks (MNIST, CIFAR-10), RR-DU matches a given $(\\varepsilon,δ)$ while achieving higher test accuracy than decentralized DP baselines and reducing forget accuracy to random guessing ($\\approx 10\\%$).",
            "headline_zh": "提出RR-DU方法以解决去中心化网络中认证遗忘的核心挑战",
            "intro_zh": [
                "研究去中心化网络中的认证遗忘问题，填补无协调器场景的空白",
                "基于随机游走结合梯度上升/下降、子采样高斯噪声和信任区域投影",
                "在图像基准上实现高测试精度，遗忘准确率降至随机猜测水平"
            ],
            "tags_zh": [
                "认证遗忘",
                "去中心化网络",
                "差分隐私",
                "随机游走",
                "梯度优化",
                "图像分类"
            ],
            "_index": 147
        },
        {
            "title": "Leveraging Multispectral Sensors for Color Correction in Mobile Cameras",
            "authors": [
                "Luca Cogo",
                "Marco Buzzelli",
                "Simone Bianco",
                "Javier Vazquez-Corral",
                "Raimondo Schettini"
            ],
            "arxiv_id": "2512.08441v1",
            "summary": "Recent advances in snapshot multispectral (MS) imaging have enabled compact, low-cost spectral sensors for consumer and mobile devices. By capturing richer spectral information than conventional RGB sensors, these systems can enhance key imaging tasks, including color correction. However, most existing methods treat the color correction pipeline in separate stages, often discarding MS data early in the process. We propose a unified, learning-based framework that (i) performs end-to-end color correction and (ii) jointly leverages data from a high-resolution RGB sensor and an auxiliary low-resolution MS sensor. Our approach integrates the full pipeline within a single model, producing coherent and color-accurate outputs. We demonstrate the flexibility and generality of our framework by refactoring two different state-of-the-art image-to-image architectures. To support training and evaluation, we construct a dedicated dataset by aggregating and repurposing publicly available spectral datasets, rendering under multiple RGB camera sensitivities. Extensive experiments show that our approach improves color accuracy and stability, reducing error by up to 50% compared to RGB-only and MS-driven baselines. Datasets, code, and models will be made available upon acceptance.",
            "headline_zh": "提出统一学习框架，利用多光谱传感器提升移动相机色彩校正精度",
            "intro_zh": [
                "核心问题：现有方法多阶段处理色彩校正，早期丢弃多光谱数据，导致信息利用不足",
                "方法要点：构建端到端学习框架，联合高分辨率RGB与低分辨率多光谱传感器数据，统一模型处理",
                "实验或效果：通过重构两种先进架构验证，在自建数据集上实验，色彩误差降低达50%"
            ],
            "tags_zh": [
                "多光谱成像",
                "色彩校正",
                "端到端学习",
                "移动相机",
                "传感器融合",
                "图像处理"
            ],
            "_index": 148
        },
        {
            "title": "LapFM: A Laparoscopic Segmentation Foundation Model via Hierarchical Concept Evolving Pre-training",
            "authors": [
                "Qing Xu",
                "Kun Yuan",
                "Yuxiang Luo",
                "Yuhao Zhai",
                "Wenting Duan",
                "Nassir Navab",
                "Zhen Chen"
            ],
            "arxiv_id": "2512.08439v1",
            "summary": "Surgical segmentation is pivotal for scene understanding yet remains hindered by annotation scarcity and semantic inconsistency across diverse procedures. Existing approaches typically fine-tune natural foundation models (e.g., SAM) with limited supervision, functioning merely as domain adapters rather than surgical foundation models. Consequently, they struggle to generalize across the vast variability of surgical targets. To bridge this gap, we present LapFM, a foundation model designed to evolve robust segmentation capabilities from massive unlabeled surgical images. Distinct from medical foundation models relying on inefficient self-supervised proxy tasks, LapFM leverages a Hierarchical Concept Evolving Pre-training paradigm. First, we establish a Laparoscopic Concept Hierarchy (LCH) via a hierarchical mask decoder with parent-child query embeddings, unifying diverse entities (i.e., Anatomy, Tissue, and Instrument) into a scalable knowledge structure with cross-granularity semantic consistency. Second, we propose a Confidence-driven Evolving Labeling that iteratively generates and filters pseudo-labels based on hierarchical consistency, progressively incorporating reliable samples from unlabeled images into training. This process yields LapBench-114K, a large-scale benchmark comprising 114K image-mask pairs. Extensive experiments demonstrate that LapFM significantly outperforms state-of-the-art methods, establishing new standards for granularity-adaptive generalization in universal laparoscopic segmentation. The source code is available at https://github.com/xq141839/LapFM.",
            "headline_zh": "提出LapFM基础模型，通过分层概念演化预训练解决腹腔镜分割中标注稀缺与语义不一致问题。",
            "intro_zh": [
                "核心问题：手术分割因标注稀缺和跨程序语义不一致而受限，现有方法泛化能力差。",
                "方法要点：采用分层概念演化预训练，构建腹腔镜概念层次并迭代生成伪标签，从无标注图像中学习。",
                "实验或效果：在LapBench-114K基准上显著优于先进方法，实现粒度自适应泛化。"
            ],
            "tags_zh": [
                "腹腔镜分割",
                "基础模型",
                "分层概念演化",
                "伪标签生成",
                "无监督预训练",
                "手术场景理解"
            ],
            "_index": 149
        },
        {
            "title": "Beyond Wave Variables: A Data-Driven Ensemble Approach for Enhanced Teleoperation Transparency and Stability",
            "authors": [
                "Nour Mitiche",
                "Farid Ferguene",
                "Mourad Oussalah"
            ],
            "arxiv_id": "2512.08436v1",
            "summary": "Time delays in communication channels present significant challenges for bilateral teleoperation systems, affecting both transparency and stability. Although traditional wave variable-based methods for a four-channel architecture ensure stability via passivity, they remain vulnerable to wave reflections and disturbances like variable delays and environmental noise. This article presents a data-driven hybrid framework that replaces the conventional wave-variable transform with an ensemble of three advanced sequence models, each optimized separately via the state-of-the-art Optuna optimizer, and combined through a stacking meta-learner. The base predictors include an LSTM augmented with Prophet for trend correction, an LSTM-based feature extractor paired with clustering and a random forest for improved regression, and a CNN-LSTM model for localized and long-term dynamics. Experimental validation was performed in Python using data generated from the baseline system implemented in MATLAB/Simulink. The results show that our optimized ensemble achieves a transparency comparable to the baseline wave-variable system under varying delays and noise, while ensuring stability through passivity constraints.",
            "headline_zh": "提出数据驱动集成方法以增强双边遥操作在时延下的透明度和稳定性",
            "intro_zh": [
                "核心问题：通信时延影响双边遥操作系统的透明度和稳定性，传统波变量方法易受波反射和噪声干扰。",
                "方法要点：用三个序列模型集成替代波变量变换，通过Optuna优化和堆叠元学习器组合，提升预测性能。",
                "实验或效果：在Python中验证，集成方法在变时延和噪声下达到与基线相当的透明度，并通过无源性确保稳定性。"
            ],
            "tags_zh": [
                "双边遥操作",
                "数据驱动集成",
                "序列模型",
                "透明度增强",
                "稳定性保证",
                "Optuna优化"
            ],
            "_index": 150
        },
        {
            "title": "SDT-6D: Fully Sparse Depth-Transformer for Staged End-to-End 6D Pose Estimation in Industrial Multi-View Bin Picking",
            "authors": [
                "Nico Leuze",
                "Maximilian Hoh",
                "Samed Doğan",
                "Nicolas R. -Peña",
                "Alfred Schoettl"
            ],
            "arxiv_id": "2512.08430v1",
            "summary": "Accurately recovering 6D poses in densely packed industrial bin-picking environments remain a serious challenge, owing to occlusions, reflections, and textureless parts. We introduce a holistic depth-only 6D pose estimation approach that fuses multi-view depth maps into either a fine-grained 3D point cloud in its vanilla version, or a sparse Truncated Signed Distance Field (TSDF). At the core of our framework lies a staged heatmap mechanism that yields scene-adaptive attention priors across different resolutions, steering computation toward foreground regions, thus keeping memory requirements at high resolutions feasible. Along, we propose a density-aware sparse transformer block that dynamically attends to (self-) occlusions and the non-uniform distribution of 3D data. While sparse 3D approaches has proven effective for long-range perception, its potential in close-range robotic applications remains underexplored. Our framework operates fully sparse, enabling high-resolution volumetric representations to capture fine geometric details crucial for accurate pose estimation in clutter. Our method processes the entire scene integrally, predicting the 6D pose via a novel per-voxel voting strategy, allowing simultaneous pose predictions for an arbitrary number of target objects. We validate our method on the recently published IPD and MV-YCB multi-view datasets, demonstrating competitive performance in heavily cluttered industrial and household bin picking scenarios.",
            "headline_zh": "提出全稀疏深度Transformer，用于工业多视角箱拣中分阶段端到端6D姿态估计",
            "intro_zh": [
                "核心问题：工业箱拣中密集遮挡、反射和无纹理部件导致6D姿态估计困难",
                "方法要点：融合多视角深度图，采用分阶段热图机制和密度感知稀疏Transformer块",
                "实验或效果：在IPD和MV-YCB数据集上验证，在杂乱场景中表现竞争性"
            ],
            "tags_zh": [
                "6D姿态估计",
                "稀疏Transformer",
                "多视角深度融合",
                "工业箱拣",
                "端到端学习",
                "点云处理"
            ],
            "_index": 151
        },
        {
            "title": "Prismatic World Model: Learning Compositional Dynamics for Planning in Hybrid Systems",
            "authors": [
                "Mingwei Li",
                "Xiaoyuan Zhang",
                "Chengwei Yang",
                "Zilong Zheng",
                "Yaodong Yang"
            ],
            "arxiv_id": "2512.08411v1",
            "summary": "Model-based planning in robotic domains is fundamentally challenged by the hybrid nature of physical dynamics, where continuous motion is punctuated by discrete events such as contacts and impacts. Conventional latent world models typically employ monolithic neural networks that enforce global continuity, inevitably over-smoothing the distinct dynamic modes (e.g., sticking vs. sliding, flight vs. stance). For a planner, this smoothing results in catastrophic compounding errors during long-horizon lookaheads, rendering the search process unreliable at physical boundaries. To address this, we introduce the Prismatic World Model (PRISM-WM), a structured architecture designed to decompose complex hybrid dynamics into composable primitives. PRISM-WM leverages a context-aware Mixture-of-Experts (MoE) framework where a gating mechanism implicitly identifies the current physical mode, and specialized experts predict the associated transition dynamics. We further introduce a latent orthogonalization objective to ensure expert diversity, effectively preventing mode collapse. By accurately modeling the sharp mode transitions in system dynamics, PRISM-WM significantly reduces rollout drift. Extensive experiments on challenging continuous control benchmarks, including high-dimensional humanoids and diverse multi-task settings, demonstrate that PRISM-WM provides a superior high-fidelity substrate for trajectory optimization algorithms (e.g., TD-MPC), proving its potential as a powerful foundational model for next-generation model-based agents.",
            "headline_zh": "提出棱镜世界模型以解决混合系统中基于模型的规划问题",
            "intro_zh": [
                "核心问题：混合动态（连续运动与离散事件）导致传统世界模型过度平滑，规划时产生累积误差。",
                "方法要点：采用上下文感知的专家混合框架，分解动态为可组合基元，引入潜在正交化目标防止模式崩溃。",
                "实验或效果：在连续控制基准测试中显著减少滚动漂移，提升轨迹优化算法性能。"
            ],
            "tags_zh": [
                "混合系统",
                "世界模型",
                "专家混合",
                "轨迹优化",
                "模型规划"
            ],
            "_index": 152
        },
        {
            "title": "Towards Effective and Efficient Long Video Understanding of Multimodal Large Language Models via One-shot Clip Retrieval",
            "authors": [
                "Tao Chen",
                "Shaobo Ju",
                "Qiong Wu",
                "Chenxin Fang",
                "Kun Zhang",
                "Jun Peng",
                "Hui Li",
                "Yiyi Zhou",
                "Rongrong Ji"
            ],
            "arxiv_id": "2512.08410v1",
            "summary": "Due to excessive memory overhead, most Multimodal Large Language Models (MLLMs) can only process videos of limited frames. In this paper, we propose an effective and efficient paradigm to remedy this shortcoming, termed One-shot video-Clip based Retrieval AuGmentation (OneClip-RAG). Compared with existing video RAG methods, OneClip-RAG makes full use of the merits of video clips for augmented video understanding in terms of both knowledge integrity and semantic coherence. Besides, it is also equipped with a novel query-guided video chunking algorithm that can unify clip chunking and cross-modal retrieval in one processing step, avoiding redundant computations. To improve instruction following, we further propose a new dataset called SynLongVideo and design a progressive training regime for OneClip-RAG. OneClip-RAG is plugged into five recent MLLMs and validated on a set of long-video benchmarks. Experimental results not only show the obvious performance gains by OneClip-RAG over MLLMs, e.g., boosting InternLV2 8B and Qwen2-VL 7B to the level of GPT-4o on MLVU, but also show its superior efficiency in handling long videos. e.g., enabling LLaVA-Video understand up to an hour of videos in less than 2.2 minutes on a single 4090 GPU.",
            "headline_zh": "提出OneClip-RAG范式以解决多模态大语言模型处理长视频时内存开销过大的问题",
            "intro_zh": [
                "核心问题：多模态大语言模型因内存开销大，只能处理有限帧视频，限制长视频理解能力",
                "方法要点：基于单次视频片段检索增强，结合查询引导的视频分块算法，提升知识完整性和语义连贯性",
                "实验或效果：在多个MLLMs上验证，显著提升性能，如InternLV2 8B和Qwen2-VL 7B在MLVU基准上达到GPT-4o水平，并在单GPU上高效处理长达一小时视频"
            ],
            "tags_zh": [
                "长视频理解",
                "多模态大语言模型",
                "检索增强生成",
                "视频分块算法",
                "高效计算"
            ],
            "_index": 153
        },
        {
            "title": "SAM-Body4D: Training-Free 4D Human Body Mesh Recovery from Videos",
            "authors": [
                "Mingqi Gao",
                "Yunqi Miao",
                "Jungong Han"
            ],
            "arxiv_id": "2512.08406v1",
            "summary": "Human Mesh Recovery (HMR) aims to reconstruct 3D human pose and shape from 2D observations and is fundamental to human-centric understanding in real-world scenarios. While recent image-based HMR methods such as SAM 3D Body achieve strong robustness on in-the-wild images, they rely on per-frame inference when applied to videos, leading to temporal inconsistency and degraded performance under occlusions. We address these issues without extra training by leveraging the inherent human continuity in videos. We propose SAM-Body4D, a training-free framework for temporally consistent and occlusion-robust HMR from videos. We first generate identity-consistent masklets using a promptable video segmentation model, then refine them with an Occlusion-Aware module to recover missing regions. The refined masklets guide SAM 3D Body to produce consistent full-body mesh trajectories, while a padding-based parallel strategy enables efficient multi-human inference. Experimental results demonstrate that SAM-Body4D achieves improved temporal stability and robustness in challenging in-the-wild videos, without any retraining. Our code and demo are available at: https://github.com/gaomingqi/sam-body4d.",
            "headline_zh": "提出SAM-Body4D框架，无需训练实现视频中4D人体网格恢复，提升时间一致性与遮挡鲁棒性。",
            "intro_zh": [
                "核心问题：视频中基于图像的HMR方法存在时间不一致和遮挡下性能下降问题。",
                "方法要点：利用视频连续性，通过身份一致掩码生成和遮挡感知模块，指导SAM 3D Body恢复网格。",
                "实验或效果：在野外视频中验证了时间稳定性和鲁棒性提升，无需额外训练。"
            ],
            "tags_zh": [
                "4D人体网格恢复",
                "视频理解",
                "遮挡鲁棒性",
                "训练免费框架",
                "时间一致性"
            ],
            "_index": 154
        },
        {
            "title": "Learning Robot Manipulation from Audio World Models",
            "authors": [
                "Fan Zhang",
                "Michael Gienger"
            ],
            "arxiv_id": "2512.08405v1",
            "summary": "World models have demonstrated impressive performance on robotic learning tasks. Many such tasks inherently demand multimodal reasoning; for example, filling a bottle with water will lead to visual information alone being ambiguous or incomplete, thereby requiring reasoning over the temporal evolution of audio, accounting for its underlying physical properties and pitch patterns. In this paper, we propose a generative latent flow matching model to anticipate future audio observations, enabling the system to reason about long-term consequences when integrated into a robot policy. We demonstrate the superior capabilities of our system through two manipulation tasks that require perceiving in-the-wild audio or music signals, compared to methods without future lookahead. We further emphasize that successful robot action learning for these tasks relies not merely on multi-modal input, but critically on the accurate prediction of future audio states that embody intrinsic rhythmic patterns.",
            "headline_zh": "提出生成式潜在流匹配模型以预测未来音频，增强机器人操作中的多模态推理能力。",
            "intro_zh": [
                "核心问题：机器人操作任务中仅依赖视觉信息可能不完整，需结合音频的时序演化进行推理。",
                "方法要点：使用生成式潜在流匹配模型预测未来音频观测，集成到机器人策略中以推理长期后果。",
                "实验或效果：在需要感知真实音频或音乐信号的操作任务中，相比无未来预测的方法展现优越性能。"
            ],
            "tags_zh": [
                "机器人操作学习",
                "多模态推理",
                "音频世界模型",
                "生成式模型",
                "潜在流匹配"
            ],
            "_index": 155
        },
        {
            "title": "Are generative AI text annotations systematically biased?",
            "authors": [
                "Sjoerd B. Stolwijk",
                "Mark Boukes",
                "Damian Trilling"
            ],
            "arxiv_id": "2512.08404v1",
            "summary": "This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.",
            "headline_zh": "揭示生成式AI文本标注存在系统性偏见，与人工标注差异显著",
            "intro_zh": [
                "研究生成式大语言模型在文本标注中的偏见问题，概念性复现人工标注",
                "使用多种GLLM和提示评估五个概念，发现F1分数尚可但存在系统性偏差",
                "GLLM标注与人工标注在流行度和下游结果上差异大，F1分数无法充分反映偏见程度"
            ],
            "tags_zh": [
                "生成式AI",
                "文本标注",
                "系统性偏见",
                "大语言模型",
                "人工标注对比"
            ],
            "_index": 156
        },
        {
            "title": "Towards Visual Re-Identification of Fish using Fine-Grained Classification for Electronic Monitoring in Fisheries",
            "authors": [
                "Samitha Nuwan Thilakarathna",
                "Ercan Avsar",
                "Martin Mathias Nielsen",
                "Malte Pedersen"
            ],
            "arxiv_id": "2512.08400v1",
            "summary": "Accurate fisheries data are crucial for effective and sustainable marine resource management. With the recent adoption of Electronic Monitoring (EM) systems, more video data is now being collected than can be feasibly reviewed manually. This paper addresses this challenge by developing an optimized deep learning pipeline for automated fish re-identification (Re-ID) using the novel AutoFish dataset, which simulates EM systems with conveyor belts with six similarly looking fish species. We demonstrate that key Re-ID metrics (R1 and mAP@k) are substantially improved by using hard triplet mining in conjunction with a custom image transformation pipeline that includes dataset-specific normalization. By employing these strategies, we demonstrate that the Vision Transformer-based Swin-T architecture consistently outperforms the Convolutional Neural Network-based ResNet-50, achieving peak performance of 41.65% mAP@k and 90.43% Rank-1 accuracy. An in-depth analysis reveals that the primary challenge is distinguishing visually similar individuals of the same species (Intra-species errors), where viewpoint inconsistency proves significantly more detrimental than partial occlusion. The source code and documentation are available at: https://github.com/msamdk/Fish_Re_Identification.git",
            "headline_zh": "提出基于细粒度分类的深度学习流水线，用于渔业电子监控中的鱼类重识别。",
            "intro_zh": [
                "核心问题：渔业电子监控视频数据量大，手动审核不可行，需自动化鱼类重识别。",
                "方法要点：使用硬三元组挖掘和自定义图像变换流水线，优化Swin-T架构以提升性能。",
                "实验或效果：Swin-T优于ResNet-50，最高mAP@k达41.65%，Rank-1准确率90.43%。"
            ],
            "tags_zh": [
                "鱼类重识别",
                "细粒度分类",
                "电子监控",
                "深度学习流水线",
                "视觉Transformer"
            ],
            "_index": 157
        },
        {
            "title": "Detection of Digital Facial Retouching utilizing Face Beauty Information",
            "authors": [
                "Philipp Srock",
                "Juan E. Tapia",
                "Christoph Busch"
            ],
            "arxiv_id": "2512.08397v1",
            "summary": "Facial retouching to beautify images is widely spread in social media, advertisements, and it is even applied in professional photo studios to let individuals appear younger, remove wrinkles and skin impurities. Generally speaking, this is done to enhance beauty. This is not a problem itself, but when retouched images are used as biometric samples and enrolled in a biometric system, it is one. Since previous work has proven facial retouching to be a challenge for face recognition systems,the detection of facial retouching becomes increasingly necessary. This work proposes to study and analyze changes in beauty assessment algorithms of retouched images, assesses different feature extraction methods based on artificial intelligence in order to improve retouching detection, and evaluates whether face beauty can be exploited to enhance the detection rate. In a scenario where the attacking retouching algorithm is unknown, this work achieved 1.1% D-EER on single image detection.",
            "headline_zh": "提出利用面部美容信息检测数字面部修饰，以应对未知攻击算法场景",
            "intro_zh": [
                "核心问题：面部修饰在生物识别系统中作为样本时，可能影响人脸识别准确性，需检测修饰以保障系统安全。",
                "方法要点：分析修饰图像的美容评估算法变化，评估基于人工智能的特征提取方法，探索利用面部美容信息提升检测率。",
                "实验或效果：在未知攻击修饰算法场景下，单图像检测达到1.1% D-EER，显示检测性能提升。"
            ],
            "tags_zh": [
                "面部修饰检测",
                "美容评估算法",
                "特征提取",
                "生物识别安全",
                "未知攻击场景"
            ],
            "_index": 158
        },
        {
            "title": "DeepFeature: Iterative Context-aware Feature Generation for Wearable Biosignals",
            "authors": [
                "Kaiwei Liu",
                "Yuting He",
                "Bufang Yang",
                "Mu Yuan",
                "Chun Man Victor Wong",
                "Ho Pong Andrew Sze",
                "Zhenyu Yan",
                "Hongkai Chen"
            ],
            "arxiv_id": "2512.08379v1",
            "summary": "Biosignals collected from wearable devices are widely utilized in healthcare applications. Machine learning models used in these applications often rely on features extracted from biosignals due to their effectiveness, lower data dimensionality, and wide compatibility across various model architectures. However, existing feature extraction methods often lack task-specific contextual knowledge, struggle to identify optimal feature extraction settings in high-dimensional feature space, and are prone to code generation and automation errors. In this paper, we propose DeepFeature, the first LLM-empowered, context-aware feature generation framework for wearable biosignals. DeepFeature introduces a multi-source feature generation mechanism that integrates expert knowledge with task settings. It also employs an iterative feature refinement process that uses feature assessment-based feedback for feature re-selection. Additionally, DeepFeature utilizes a robust multi-layer filtering and verification approach for robust feature-to-code translation to ensure that the extraction functions run without crashing. Experimental evaluation results show that DeepFeature achieves an average AUROC improvement of 4.21-9.67% across eight diverse tasks compared to baseline methods. It outperforms state-of-the-art approaches on five tasks while maintaining comparable performance on the remaining tasks.",
            "headline_zh": "提出DeepFeature框架，利用LLM生成可穿戴生物信号的任务感知特征以提升医疗应用性能",
            "intro_zh": [
                "核心问题：现有特征提取方法缺乏任务上下文知识，在高维空间难以优化，易产生代码错误",
                "方法要点：集成专家知识与任务设置的多源生成机制，基于评估反馈的迭代特征精炼",
                "实验或效果：在八项任务中平均AUROC提升4.21-9.67%，优于或持平现有方法"
            ],
            "tags_zh": [
                "可穿戴生物信号",
                "特征生成",
                "大语言模型",
                "上下文感知",
                "迭代精炼",
                "医疗应用"
            ],
            "_index": 159
        },
        {
            "title": "Simultaneous Enhancement and Noise Suppression under Complex Illumination Conditions",
            "authors": [
                "Jing Tao",
                "You Li",
                "Banglei Guan",
                "Yang Shang",
                "Qifeng Yu"
            ],
            "arxiv_id": "2512.08378v1",
            "summary": "Under challenging light conditions, captured images often suffer from various degradations, leading to a decline in the performance of vision-based applications. Although numerous methods have been proposed to enhance image quality, they either significantly amplify inherent noise or are only effective under specific illumination conditions. To address these issues, we propose a novel framework for simultaneous enhancement and noise suppression under complex illumination conditions. Firstly, a gradient-domain weighted guided filter (GDWGIF) is employed to accurately estimate illumination and improve image quality. Next, the Retinex model is applied to decompose the captured image into separate illumination and reflection layers. These layers undergo parallel processing, with the illumination layer being corrected to optimize lighting conditions and the reflection layer enhanced to improve image quality. Finally, the dynamic range of the image is optimized through multi-exposure fusion and a linear stretching strategy. The proposed method is evaluated on real-world datasets obtained from practical applications. Experimental results demonstrate that our proposed method achieves better performance compared to state-of-the-art methods in both contrast enhancement and noise suppression.",
            "headline_zh": "提出梯度域加权引导滤波与Retinex分解框架，以在复杂光照下同时增强图像并抑制噪声。",
            "intro_zh": [
                "核心问题：复杂光照导致图像退化，现有方法易放大噪声或仅适用于特定条件。",
                "方法要点：使用GDWGIF估计光照，Retinex分解并行处理光照与反射层，结合多曝光融合优化动态范围。",
                "实验或效果：在真实数据集上验证，对比度增强和噪声抑制性能优于现有方法。"
            ],
            "tags_zh": [
                "图像增强",
                "噪声抑制",
                "Retinex模型",
                "梯度域滤波",
                "多曝光融合"
            ],
            "_index": 160
        },
        {
            "title": "The Unseen Bias: How Norm Discrepancy in Pre-Norm MLLMs Leads to Visual Information Loss",
            "authors": [
                "Bozhou Li",
                "Xinda Xue",
                "Sihan Yang",
                "Yang Shi",
                "Xinlong Chen",
                "Yushuo Guan",
                "Yuanxing Zhang",
                "Wentao Zhang"
            ],
            "arxiv_id": "2512.08374v1",
            "summary": "Multimodal Large Language Models (MLLMs), which couple pre-trained vision encoders and language models, have shown remarkable capabilities. However, their reliance on the ubiquitous Pre-Norm architecture introduces a subtle yet critical flaw: a severe norm disparity between the high-norm visual tokens and the low-norm text tokens. In this work, we present a formal theoretical analysis demonstrating that this imbalance is not a static issue. Instead, it induces an ``asymmetric update dynamic,'' where high-norm visual tokens exhibit a ``representational inertia,'' causing them to transform semantically much slower than their textual counterparts. This fundamentally impairs effective cross-modal feature fusion. Our empirical validation across a range of mainstream MLLMs confirms that this theoretical dynamic -- the persistence of norm disparity and the resulting asymmetric update rates -- is a prevalent phenomenon. Based on this insight, we propose a remarkably simple yet effective solution: inserting a single, carefully initialized LayerNorm layer after the visual projector to enforce norm alignment. Experiments conducted on the LLaVA-1.5 architecture show that this intervention yields significant performance gains not only on a wide suite of multimodal benchmarks but also, notably, on text-only evaluations such as MMLU, suggesting that resolving the architectural imbalance leads to a more holistically capable model.",
            "headline_zh": "提出在视觉投影器后插入LayerNorm层以解决MLLMs中视觉与文本令牌范数差异导致的跨模态融合问题",
            "intro_zh": [
                "核心问题：Pre-Norm架构导致视觉令牌高范数与文本令牌低范数差异，引发不对称更新动态，损害跨模态特征融合",
                "方法要点：在视觉投影器后添加单个LayerNorm层，强制对齐视觉与文本令牌范数，实现简单有效",
                "实验或效果：在LLaVA-1.5架构上验证，多模态和纯文本基准（如MMLU）性能显著提升"
            ],
            "tags_zh": [
                "多模态大语言模型",
                "范数差异",
                "跨模态融合",
                "LayerNorm",
                "视觉信息损失",
                "不对称更新动态"
            ],
            "_index": 161
        },
        {
            "title": "A Multivariate Bernoulli-Based Sampling Method for Multi-Label Data with Application to Meta-Research",
            "authors": [
                "Simon Chung",
                "Colby J. Vorland",
                "Donna L. Maney",
                "Andrew W. Brown"
            ],
            "arxiv_id": "2512.08371v1",
            "summary": "Datasets may contain observations with multiple labels. If the labels are not mutually exclusive, and if the labels vary greatly in frequency, obtaining a sample that includes sufficient observations with scarcer labels to make inferences about those labels, and which deviates from the population frequencies in a known manner, creates challenges. In this paper, we consider a multivariate Bernoulli distribution as our underlying distribution of a multi-label problem. We present a novel sampling algorithm that takes label dependencies into account. It uses observed label frequencies to estimate multivariate Bernoulli distribution parameters and calculate weights for each label combination. This approach ensures the weighted sampling acquires target distribution characteristics while accounting for label dependencies. We applied this approach to a sample of research articles from Web of Science labeled with 64 biomedical topic categories. We aimed to preserve category frequency order, reduce frequency differences between most and least common categories, and account for category dependencies. This approach produced a more balanced sub-sample, enhancing the representation of minority categories.",
            "headline_zh": "提出基于多元伯努利分布的采样方法，以解决多标签数据中稀有标签样本不足的问题。",
            "intro_zh": [
                "核心问题：多标签数据中标签非互斥且频率差异大，导致稀有标签样本不足，影响推断准确性。",
                "方法要点：利用多元伯努利分布建模标签依赖，基于观测频率估计参数并计算权重，实现加权采样。",
                "实验或效果：应用于Web of Science生物医学文章数据集，平衡了类别频率，提升了少数类别的代表性。"
            ],
            "tags_zh": [
                "多标签采样",
                "多元伯努利分布",
                "标签依赖",
                "加权采样",
                "数据平衡",
                "元研究"
            ],
            "_index": 162
        },
        {
            "title": "Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making",
            "authors": [
                "Wentao Zhang",
                "Qunbo Wang",
                "Tao Zhang",
                "Junsheng Wu",
                "Hongping Gan",
                "Yang Liu",
                "Ling Dai",
                "Shizhuang Deng",
                "Shuntong Sun"
            ],
            "arxiv_id": "2512.08366v1",
            "summary": "Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) - a demonstration-free framework that enables a single frozen LLM to perform co-adaptive reasoning via two complementary strategies: a high-level holistic plan and a context-grounded local policy. These strategies interact through a lightweight reflection mechanism, where the agent continuously assesses progress via a Strategy Fitness Score and dynamically revises its global plan when stuck or refines it upon meaningful advancement, mimicking human metacognitive behavior. On ALFWorld and Mind2Web, DuSAR achieves state-of-the-art performance with open-source LLMs (7B-70B), reaching 37.1% success on ALFWorld (Llama3.1-70B) - more than doubling the best prior result (13.0%) - and 4.02% on Mind2Web, also more than doubling the strongest baseline. Remarkably, it reduces per-step token consumption by 3-9X while maintaining strong performance. Ablation studies confirm the necessity of dual-strategy coordination. Moreover, optional integration of expert demonstrations further boosts results, highlighting DuSAR's flexibility and compatibility with external knowledge.",
            "headline_zh": "提出DuSAR框架，通过双策略协同适应解决LLM代理决策中的脆弱性和高开销问题。",
            "intro_zh": [
                "核心问题：LLM代理依赖外部演示或检索增强规划，导致脆弱性、泛化差和计算开销高。",
                "方法要点：采用双策略（全局规划和局部策略）与轻量级反思机制，实现协同适应推理，无需演示。",
                "实验或效果：在ALFWorld和Mind2Web上实现SOTA性能，成功率和效率显著提升，消融研究验证双策略必要性。"
            ],
            "tags_zh": [
                "LLM代理决策",
                "双策略协同适应",
                "反思机制",
                "轻量级推理",
                "演示无关框架",
                "计算效率优化"
            ],
            "_index": 163
        },
        {
            "title": "Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging",
            "authors": [
                "Yi Pan",
                "Wenbo Qian",
                "Dedong Xie",
                "Ruiyan Hu",
                "Yigong Hu",
                "Baris Kasikci"
            ],
            "arxiv_id": "2512.08365v1",
            "summary": "The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving performance. These inefficiencies arise in widely used ML frameworks and applications, yet developers often lack the visibility and tools to detect and diagnose them.\n  We propose differential energy debugging, a novel approach that leverages the observation that competing ML systems often implement similar functionality with vastly different energy consumption. Building on this insight, we design and implement Magneton, an energy profiler that compares energy consumption between similar ML systems at the operator level and automatically pinpoints code regions and configuration choices responsible for excessive energy use. Applied to 9 popular ML systems spanning LLM inference, general ML frameworks, and image generation, Magneton detects and diagnoses 16 known cases of software energy inefficiency and further discovers 8 previously unknown cases, 7 of which have been confirmed by developers.",
            "headline_zh": "提出Magneton通过差分能量调试优化机器学习系统的能源效率",
            "intro_zh": [
                "核心问题：机器学习系统软件设计不良导致能源浪费，现有工具难以检测。",
                "方法要点：基于相似系统能源消耗差异，设计差分能量调试方法，在算子级别定位高能耗代码。",
                "实验或效果：应用于9个流行系统，诊断16个已知和8个未知能源低效案例，7个获开发者确认。"
            ],
            "tags_zh": [
                "能源效率优化",
                "差分能量调试",
                "机器学习系统",
                "能源分析工具",
                "软件能源浪费"
            ],
            "_index": 164
        },
        {
            "title": "SCU-CGAN: Enhancing Fire Detection through Synthetic Fire Image Generation and Dataset Augmentation",
            "authors": [
                "Ju-Young Kim",
                "Ji-Hong Park",
                "Gun-Woo Kim"
            ],
            "arxiv_id": "2512.08362v1",
            "summary": "Fire has long been linked to human life, causing severe disasters and losses. Early detection is crucial, and with the rise of home IoT technologies, household fire detection systems have emerged. However, the lack of sufficient fire datasets limits the performance of detection models. We propose the SCU-CGAN model, which integrates U-Net, CBAM, and an additional discriminator to generate realistic fire images from nonfire images. We evaluate the image quality and confirm that SCU-CGAN outperforms existing models. Specifically, SCU-CGAN achieved a 41.5% improvement in KID score compared to CycleGAN, demonstrating the superior quality of the generated fire images. Furthermore, experiments demonstrate that the augmented dataset significantly improves the accuracy of fire detection models without altering their structure. For the YOLOv5 nano model, the most notable improvement was observed in the mAP@0.5:0.95 metric, which increased by 56.5%, highlighting the effectiveness of the proposed approach.",
            "headline_zh": "提出SCU-CGAN模型以增强火灾检测，通过合成火灾图像进行数据集增强。",
            "intro_zh": [
                "火灾检测模型性能受限于数据集不足，影响早期预警效果。",
                "SCU-CGAN集成U-Net、CBAM和额外判别器，从非火图像生成逼真火灾图像。",
                "实验显示生成图像质量提升，增强数据集显著提高检测模型准确率，如YOLOv5 nano的mAP@0.5:0.95增加56.5%。"
            ],
            "tags_zh": [
                "火灾检测",
                "图像生成",
                "数据集增强",
                "生成对抗网络",
                "计算机视觉"
            ],
            "_index": 165
        },
        {
            "title": "Conditional Morphogenesis: Emergent Generation of Structural Digits via Neural Cellular Automata",
            "authors": [
                "Ali Sakour"
            ],
            "arxiv_id": "2512.08360v1",
            "summary": "Biological systems exhibit remarkable morphogenetic plasticity, where a single genome can encode various specialized cellular structures triggered by local chemical signals. In the domain of Deep Learning, Differentiable Neural Cellular Automata (NCA) have emerged as a paradigm to mimic this self-organization. However, existing NCA research has predominantly focused on continuous texture synthesis or single-target object recovery, leaving the challenge of class-conditional structural generation largely unexplored. In this work, we propose a novel Conditional Neural Cellular Automata (c-NCA) architecture capable of growing distinct topological structures - specifically MNIST digits - from a single generic seed, guided solely by a spatially broadcasted class vector. Unlike traditional generative models (e.g., GANs, VAEs) that rely on global reception fields, our model enforces strict locality and translation equivariance. We demonstrate that by injecting a one-hot condition into the cellular perception field, a single set of local rules can learn to break symmetry and self-assemble into ten distinct geometric attractors. Experimental results show that our c-NCA achieves stable convergence, correctly forming digit topologies from a single pixel, and exhibits robustness characteristic of biological systems. This work bridges the gap between texture-based NCAs and structural pattern formation, offering a lightweight, biologically plausible alternative for conditional generation.",
            "headline_zh": "提出条件神经细胞自动机以解决类别条件结构生成问题",
            "intro_zh": [
                "核心问题：现有神经细胞自动机研究多关注连续纹理合成或单目标恢复，类别条件结构生成挑战未充分探索。",
                "方法要点：通过空间广播类向量引导，从通用种子生长出不同拓扑结构，如MNIST数字，保持严格局部性和平移等变性。",
                "实验或效果：模型实现稳定收敛，从单像素正确形成数字拓扑，展现出类似生物系统的鲁棒性。"
            ],
            "tags_zh": [
                "条件生成",
                "神经细胞自动机",
                "结构模式形成",
                "自组织",
                "局部规则",
                "生物启发性"
            ],
            "_index": 166
        },
        {
            "title": "TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels",
            "authors": [
                "Jiahao Lu",
                "Weitao Xiong",
                "Jiacheng Deng",
                "Peng Li",
                "Tianyu Huang",
                "Zhiyang Dou",
                "Cheng Lin",
                "Sai-Kit Yeung",
                "Yuan Liu"
            ],
            "arxiv_id": "2512.08358v1",
            "summary": "Monocular 3D tracking aims to capture the long-term motion of pixels in 3D space from a single monocular video and has witnessed rapid progress in recent years. However, we argue that the existing monocular 3D tracking methods still fall short in separating the camera motion from foreground dynamic motion and cannot densely track newly emerging dynamic subjects in the videos. To address these two limitations, we propose TrackingWorld, a novel pipeline for dense 3D tracking of almost all pixels within a world-centric 3D coordinate system. First, we introduce a tracking upsampler that efficiently lifts the arbitrary sparse 2D tracks into dense 2D tracks. Then, to generalize the current tracking methods to newly emerging objects, we apply the upsampler to all frames and reduce the redundancy of 2D tracks by eliminating the tracks in overlapped regions. Finally, we present an efficient optimization-based framework to back-project dense 2D tracks into world-centric 3D trajectories by estimating the camera poses and the 3D coordinates of these 2D tracks. Extensive evaluations on both synthetic and real-world datasets demonstrate that our system achieves accurate and dense 3D tracking in a world-centric coordinate frame.",
            "headline_zh": "提出TrackingWorld以解决单目3D跟踪中相机运动分离和新动态物体密集跟踪问题",
            "intro_zh": [
                "核心问题：现有方法难以分离相机运动与前景动态运动，且无法密集跟踪视频中新出现的动态物体。",
                "方法要点：通过跟踪上采样器提升稀疏2D轨迹为密集轨迹，优化框架将密集2D轨迹反投影到世界中心3D坐标系。",
                "实验或效果：在合成和真实数据集上评估，系统在世界中心坐标系中实现准确密集的3D跟踪。"
            ],
            "tags_zh": [
                "单目3D跟踪",
                "世界中心坐标系",
                "密集跟踪",
                "相机运动分离",
                "动态物体跟踪",
                "优化框架"
            ],
            "_index": 167
        },
        {
            "title": "The High Cost of Incivility: Quantifying Interaction Inefficiency via Multi-Agent Monte Carlo Simulations",
            "authors": [
                "Benedikt Mangold"
            ],
            "arxiv_id": "2512.08345v1",
            "summary": "Workplace toxicity is widely recognized as detrimental to organizational culture, yet quantifying its direct impact on operational efficiency remains methodologically challenging due to the ethical and practical difficulties of reproducing conflict in human subjects. This study leverages Large Language Model (LLM) based Multi-Agent Systems to simulate 1-on-1 adversarial debates, creating a controlled \"sociological sandbox\". We employ a Monte Carlo method to simulate hundrets of discussions, measuring the convergence time (defined as the number of arguments required to reach a conclusion) between a baseline control group and treatment groups involving agents with \"toxic\" system prompts. Our results demonstrate a statistically significant increase of approximately 25\\% in the duration of conversations involving toxic participants. We propose that this \"latency of toxicity\" serves as a proxy for financial damage in corporate and academic settings. Furthermore, we demonstrate that agent-based modeling provides a reproducible, ethical alternative to human-subject research for measuring the mechanics of social friction.",
            "headline_zh": "提出基于LLM多代理系统的蒙特卡洛模拟方法，量化职场毒性对互动效率的影响。",
            "intro_zh": [
                "核心问题：职场毒性对运营效率的直接量化存在伦理和方法挑战。",
                "方法要点：利用LLM多代理系统模拟对抗性辩论，采用蒙特卡洛方法控制变量。",
                "实验或效果：毒性参与者使对话时长显著增加约25%，作为财务损失代理指标。"
            ],
            "tags_zh": [
                "多代理系统",
                "蒙特卡洛模拟",
                "LLM应用",
                "社会摩擦量化",
                "职场效率"
            ],
            "_index": 168
        },
        {
            "title": "Enhancing Explainability of Graph Neural Networks Through Conceptual and Structural Analyses and Their Extensions",
            "authors": [
                "Tien Cuong Bui"
            ],
            "arxiv_id": "2512.08344v1",
            "summary": "Graph Neural Networks (GNNs) have become a powerful tool for modeling and analyzing data with graph structures. The wide adoption in numerous applications underscores the value of these models. However, the complexity of these methods often impedes understanding their decision-making processes. Current Explainable AI (XAI) methods struggle to untangle the intricate relationships and interactions within graphs. Several methods have tried to bridge this gap via a post-hoc approach or self-interpretable design. Most of them focus on graph structure analysis to determine essential patterns that correlate with prediction outcomes. While post-hoc explanation methods are adaptable, they require extra computational resources and may be less reliable due to limited access to the model's internal workings. Conversely, Interpretable models can provide immediate explanations, but their generalizability to different scenarios remains a major concern. To address these shortcomings, this thesis seeks to develop a novel XAI framework tailored for graph-based machine learning. The proposed framework aims to offer adaptable, computationally efficient explanations for GNNs, moving beyond individual feature analysis to capture how graph structure influences predictions.",
            "headline_zh": "提出可解释AI框架以增强图神经网络在复杂图结构中的决策透明度",
            "intro_zh": [
                "核心问题：图神经网络决策过程复杂，现有可解释方法难以解析图内关系与交互",
                "方法要点：结合概念与结构分析，开发适配图机器学习的新型可解释AI框架",
                "实验或效果：未知"
            ],
            "tags_zh": [
                "图神经网络",
                "可解释人工智能",
                "图结构分析",
                "后验解释",
                "自解释模型"
            ],
            "_index": 169
        },
        {
            "title": "Soil Compaction Parameters Prediction Based on Automated Machine Learning Approach",
            "authors": [
                "Caner Erden",
                "Alparslan Serhat Demir",
                "Abdullah Hulusi Kokcam",
                "Talas Fikret Kurnaz",
                "Ugur Dagdeviren"
            ],
            "arxiv_id": "2512.08343v1",
            "summary": "Soil compaction is critical in construction engineering to ensure the stability of structures like road embankments and earth dams. Traditional methods for determining optimum moisture content (OMC) and maximum dry density (MDD) involve labor-intensive laboratory experiments, and empirical regression models have limited applicability and accuracy across diverse soil types. In recent years, artificial intelligence (AI) and machine learning (ML) techniques have emerged as alternatives for predicting these compaction parameters. However, ML models often struggle with prediction accuracy and generalizability, particularly with heterogeneous datasets representing various soil types. This study proposes an automated machine learning (AutoML) approach to predict OMC and MDD. AutoML automates algorithm selection and hyperparameter optimization, potentially improving accuracy and scalability. Through extensive experimentation, the study found that the Extreme Gradient Boosting (XGBoost) algorithm provided the best performance, achieving R-squared values of 80.4% for MDD and 89.1% for OMC on a separate dataset. These results demonstrate the effectiveness of AutoML in predicting compaction parameters across different soil types. The study also highlights the importance of heterogeneous datasets in improving the generalization and performance of ML models. Ultimately, this research contributes to more efficient and reliable construction practices by enhancing the prediction of soil compaction parameters.",
            "headline_zh": "提出基于AutoML的方法预测土壤压实参数，以提升建筑工程中的预测准确性与泛化能力。",
            "intro_zh": [
                "核心问题：传统土壤压实参数预测方法劳动密集且准确性有限，机器学习模型在异质数据集上泛化能力不足。",
                "方法要点：采用自动化机器学习（AutoML）自动选择算法和优化超参数，以XGBoost为最佳算法。",
                "实验或效果：在独立数据集上，XGBoost对最大干密度和最优含水率的预测R²值分别达80.4%和89.1%。"
            ],
            "tags_zh": [
                "土壤压实参数预测",
                "自动化机器学习",
                "XGBoost算法",
                "建筑工程应用",
                "异质数据集"
            ],
            "_index": 170
        },
        {
            "title": "Multi-Agent Deep Reinforcement Learning for Collaborative UAV Relay Networks under Jamming Atatcks",
            "authors": [
                "Thai Duong Nguyen",
                "Ngoc-Tan Nguyen",
                "Thanh-Dao Nguyen",
                "Nguyen Van Huynh",
                "Dinh-Hieu Tran",
                "Symeon Chatzinotas"
            ],
            "arxiv_id": "2512.08341v1",
            "summary": "The deployment of Unmanned Aerial Vehicle (UAV) swarms as dynamic communication relays is critical for next-generation tactical networks. However, operating in contested environments requires solving a complex trade-off, including maximizing system throughput while ensuring collision avoidance and resilience against adversarial jamming. Existing heuristic-based approaches often struggle to find effective solutions due to the dynamic and multi-objective nature of this problem. This paper formulates this challenge as a cooperative Multi-Agent Reinforcement Learning (MARL) problem, solved using the Centralized Training with Decentralized Execution (CTDE) framework. Our approach employs a centralized critic that uses global state information to guide decentralized actors which operate using only local observations. Simulation results show that our proposed framework significantly outperforms heuristic baselines, increasing the total system throughput by approximately 50% while simultaneously achieving a near-zero collision rate. A key finding is that the agents develop an emergent anti-jamming strategy without explicit programming. They learn to intelligently position themselves to balance the trade-off between mitigating interference from jammers and maintaining effective communication links with ground users.",
            "headline_zh": "提出基于多智能体深度强化学习的协作无人机中继网络抗干扰方法",
            "intro_zh": [
                "核心问题：无人机群在干扰环境下需平衡吞吐量最大化、防碰撞和抗干扰等多目标动态优化",
                "方法要点：采用集中训练分散执行框架，通过全局状态指导局部决策，实现协作抗干扰",
                "实验或效果：仿真显示系统吞吐量提升约50%，碰撞率接近零，智能体自发学习抗干扰策略"
            ],
            "tags_zh": [
                "多智能体强化学习",
                "无人机中继网络",
                "抗干扰策略",
                "集中训练分散执行",
                "协作通信"
            ],
            "_index": 171
        },
        {
            "title": "Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from Türkiye",
            "authors": [
                "Abdullah Hulusi Kökçam",
                "Uğur Dağdeviren",
                "Talas Fikret Kurnaz",
                "Alparslan Serhat Demir",
                "Caner Erden"
            ],
            "arxiv_id": "2512.08340v1",
            "summary": "The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of subgrade soils, especially in transportation infrastructure and foundation design. Traditional CBR determination relies on laboratory penetration tests. Despite their accuracy, these tests are often time-consuming, costly, and can be impractical, particularly for large-scale or diverse soil profiles. Recent progress in artificial intelligence, especially machine learning (ML), has enabled data-driven approaches for modeling complex soil behavior with greater speed and precision. This study introduces a comprehensive ML framework for CBR prediction using a dataset of 382 soil samples collected from various geoclimatic regions in Türkiye. The dataset includes physicochemical soil properties relevant to bearing capacity, allowing multidimensional feature representation in a supervised learning context. Twelve ML algorithms were tested, including decision tree, random forest, extra trees, gradient boosting, xgboost, k-nearest neighbors, support vector regression, multi-layer perceptron, adaboost, bagging, voting, and stacking regressors. Each model was trained, validated, and evaluated to assess its generalization and robustness. Among them, the random forest regressor performed the best, achieving strong R2 scores of 0.95 (training), 0.76 (validation), and 0.83 (test). These outcomes highlight the model's powerful nonlinear mapping ability, making it a promising tool for predictive geotechnical tasks. The study supports the integration of intelligent, data-centric models in geotechnical engineering, offering an effective alternative to traditional methods and promoting digital transformation in infrastructure analysis and design.",
            "headline_zh": "提出集成与神经网络模型预测加州承载比，应用于土耳其土样案例研究。",
            "intro_zh": [
                "核心问题：传统加州承载比测试耗时、成本高，难以大规模应用。",
                "方法要点：使用382个土耳其土样数据集，测试12种机器学习算法进行预测。",
                "实验或效果：随机森林回归器表现最佳，测试R2达0.83，验证了模型的有效性。"
            ],
            "tags_zh": [
                "加州承载比预测",
                "机器学习模型",
                "土工技术工程",
                "随机森林回归",
                "数据驱动方法"
            ],
            "_index": 172
        },
        {
            "title": "DINO-BOLDNet: A DINOv3-Guided Multi-Slice Attention Network for T1-to-BOLD Generation",
            "authors": [
                "Jianwei Wang",
                "Qing Wang",
                "Menglan Ruan",
                "Rongjun Ge",
                "Chunfeng Yang",
                "Yang Chen",
                "Chunming Xie"
            ],
            "arxiv_id": "2512.08337v1",
            "summary": "Generating BOLD images from T1w images offers a promising solution for recovering missing BOLD information and enabling downstream tasks when BOLD images are corrupted or unavailable. Motivated by this, we propose DINO-BOLDNet, a DINOv3-guided multi-slice attention framework that integrates a frozen self-supervised DINOv3 encoder with a lightweight trainable decoder. The model uses DINOv3 to extract within-slice structural representations, and a separate slice-attention module to fuse contextual information across neighboring slices. A multi-scale generation decoder then restores fine-grained functional contrast, while a DINO-based perceptual loss encourages structural and textural consistency between predictions and ground-truth BOLD in the transformer feature space. Experiments on a clinical dataset of 248 subjects show that DINO-BOLDNet surpasses a conditional GAN baseline in both PSNR and MS-SSIM. To our knowledge, this is the first framework capable of generating mean BOLD images directly from T1w images, highlighting the potential of self-supervised transformer guidance for structural-to-functional mapping.",
            "headline_zh": "提出DINO-BOLDNet，利用DINOv3引导的多切片注意力网络从T1加权图像生成BOLD图像，以恢复缺失功能信息。",
            "intro_zh": [
                "核心问题：当BOLD图像损坏或缺失时，从T1加权图像生成BOLD图像以支持下游任务。",
                "方法要点：结合冻结的DINOv3编码器提取切片内结构表示，使用切片注意力模块融合跨切片上下文信息，并通过多尺度解码器恢复功能对比度。",
                "实验或效果：在248名受试者的临床数据集上，PSNR和MS-SSIM指标优于条件GAN基线，首次实现从T1加权图像直接生成平均BOLD图像。"
            ],
            "tags_zh": [
                "T1到BOLD生成",
                "自监督Transformer引导",
                "多切片注意力",
                "结构到功能映射",
                "医学图像生成"
            ],
            "_index": 173
        },
        {
            "title": "HybridSplat: Fast Reflection-baked Gaussian Tracing using Hybrid Splatting",
            "authors": [
                "Chang Liu",
                "Hongliang Yuan",
                "Lianghao Zhang",
                "Sichao Wang",
                "Jianwei Guo",
                "Shi-Sheng Huang"
            ],
            "arxiv_id": "2512.08334v1",
            "summary": "Rendering complex reflection of real-world scenes using 3D Gaussian splatting has been a quite promising solution for photorealistic novel view synthesis, but still faces bottlenecks especially in rendering speed and memory storage. This paper proposes a new Hybrid Splatting(HybridSplat) mechanism for Gaussian primitives. Our key idea is a new reflection-baked Gaussian tracing, which bakes the view-dependent reflection within each Gaussian primitive while rendering the reflection using tile-based Gaussian splatting. Then we integrate the reflective Gaussian primitives with base Gaussian primitives using a unified hybrid splatting framework for high-fidelity scene reconstruction. Moreover, we further introduce a pipeline-level acceleration for the hybrid splatting, and reflection-sensitive Gaussian pruning to reduce the model size, thus achieving much faster rendering speed and lower memory storage while preserving the reflection rendering quality. By extensive evaluation, our HybridSplat accelerates about 7x rendering speed across complex reflective scenes from Ref-NeRF, NeRF-Casting with 4x fewer Gaussian primitives than similar ray-tracing based Gaussian splatting baselines, serving as a new state-of-the-art method especially for complex reflective scenes.",
            "headline_zh": "提出HybridSplat机制，通过反射烘焙高斯追踪和混合溅射，加速复杂反射场景渲染并减少内存占用。",
            "intro_zh": [
                "核心问题：基于3D高斯溅射的复杂反射渲染存在速度慢和内存占用高的瓶颈。",
                "方法要点：引入反射烘焙高斯追踪，在单个高斯基元内烘焙视图相关反射，结合基于瓦片的高斯溅射进行渲染。",
                "实验或效果：在Ref-NeRF和NeRF-Casting数据集上，渲染速度提升约7倍，高斯基元数量减少4倍，保持反射质量。"
            ],
            "tags_zh": [
                "3D高斯溅射",
                "反射渲染",
                "混合溅射",
                "渲染加速",
                "内存优化",
                "复杂场景重建"
            ],
            "_index": 174
        },
        {
            "title": "Robust Finetuning of Vision-Language-Action Robot Policies via Parameter Merging",
            "authors": [
                "Yajat Yadav",
                "Zhiyuan Zhou",
                "Andrew Wagenmaker",
                "Karl Pertsch",
                "Sergey Levine"
            ],
            "arxiv_id": "2512.08333v1",
            "summary": "Generalist robot policies, trained on large and diverse datasets, have demonstrated the ability to generalize across a wide spectrum of behaviors, enabling a single policy to act in varied real-world environments. However, they still fall short on new tasks not covered in the training data. When finetuned on limited demonstrations of a new task, these policies often overfit to the specific demonstrations--not only losing their prior abilities to solve a wide variety of generalist tasks but also failing to generalize within the new task itself. In this work, we aim to develop a method that preserves the generalization capabilities of the generalist policy during finetuning, allowing a single policy to robustly incorporate a new skill into its repertoire. Our goal is a single policy that both learns to generalize to variations of the new task and retains the broad competencies gained from pretraining. We show that this can be achieved through a simple yet effective strategy: interpolating the weights of a finetuned model with that of the pretrained model. We show, across extensive simulated and real-world experiments, that such model merging produces a single model that inherits the generalist abilities of the base model and learns to solve the new task robustly, outperforming both the pretrained and finetuned model on out-of-distribution variations of the new task. Moreover, we show that model merging enables continual acquisition of new skills in a lifelong learning setting, without sacrificing previously learned generalist abilities.",
            "headline_zh": "提出参数合并方法以解决机器人策略微调中的过拟合与泛化能力丧失问题",
            "intro_zh": [
                "核心问题：通用机器人策略微调新任务时易过拟合，丧失原有泛化能力",
                "方法要点：通过合并微调模型与预训练模型的权重，实现新技能稳健融入",
                "实验或效果：在模拟与真实实验中，合并模型在新任务分布外变体上优于预训练和微调模型"
            ],
            "tags_zh": [
                "机器人策略",
                "参数合并",
                "微调泛化",
                "视觉语言动作模型",
                "终身学习"
            ],
            "_index": 175
        },
        {
            "title": "Bi^2MAC: Bimodal Bi-Adaptive Mask-Aware Convolution for Remote Sensing Pansharpening",
            "authors": [
                "Xianghong Xiao",
                "Zeyu Xia",
                "Zhou Fei",
                "Jinliang Xiao",
                "Haorui Chen",
                "Liangjian Deng"
            ],
            "arxiv_id": "2512.08331v1",
            "summary": "Pansharpening aims to fuse a high-resolution panchromatic (PAN) image with a low-resolution multispectral (LRMS) image to generate a high-resolution multispectral image (HRMS). Conventional deep learning-based methods are inherently limited in their ability to adapt to regional heterogeneity within feature representations. Although various adaptive convolution methods have been proposed to address this limitation, they often suffer from excessive computational costs and a limited ability to capture heterogeneous regions in remote sensing images effectively. To overcome these challenges, we propose Bimodal Bi-Adaptive Mask-Aware Convolution (Bi^2MAC), which effectively exploits information from different types of regions while intelligently allocating computational resources. Specifically, we design a lightweight module to generate both soft and hard masks, which are used to modulate the input features preliminarily and to guide different types of regions into separate processing branches, respectively. Redundant features are directed to a compact branch for low-cost global processing. In contrast, heterogeneous features are routed to a focused branch that invests more computational resources for fine-grained modeling. Extensive experiments on multiple benchmark datasets demonstrate that Bi^2MAC achieves state-of-the-art (SOTA) performance while requiring substantially lower training time and parameter counts, and the minimal computational cost among adaptive convolution models.",
            "headline_zh": "提出Bi^2MAC卷积以解决遥感图像融合中区域异质性和计算效率问题",
            "intro_zh": [
                "核心问题：传统自适应卷积方法在遥感图像中捕获异质区域能力有限且计算成本高",
                "方法要点：设计轻量级模块生成软硬掩码，将冗余和异质特征分别路由到紧凑分支和聚焦分支处理",
                "实验或效果：在多个基准数据集上实现SOTA性能，同时显著降低训练时间、参数量和计算成本"
            ],
            "tags_zh": [
                "遥感图像融合",
                "自适应卷积",
                "掩码生成",
                "计算效率优化",
                "异质区域处理"
            ],
            "_index": 176
        },
        {
            "title": "PointDico: Contrastive 3D Representation Learning Guided by Diffusion Models",
            "authors": [
                "Pengbo Li",
                "Yiding Sun",
                "Haozhe Cheng"
            ],
            "arxiv_id": "2512.08330v1",
            "summary": "Self-supervised representation learning has shown significant improvement in Natural Language Processing and 2D Computer Vision. However, existing methods face difficulties in representing 3D data because of its unordered and uneven density. Through an in-depth analysis of mainstream contrastive and generative approaches, we find that contrastive models tend to suffer from overfitting, while 3D Mask Autoencoders struggle to handle unordered point clouds. This motivates us to learn 3D representations by sharing the merits of diffusion and contrast models, which is non-trivial due to the pattern difference between the two paradigms. In this paper, we propose \\textit{PointDico}, a novel model that seamlessly integrates these methods. \\textit{PointDico} learns from both denoising generative modeling and cross-modal contrastive learning through knowledge distillation, where the diffusion model serves as a guide for the contrastive model. We introduce a hierarchical pyramid conditional generator for multi-scale geometric feature extraction and employ a dual-channel design to effectively integrate local and global contextual information. \\textit{PointDico} achieves a new state-of-the-art in 3D representation learning, \\textit{e.g.}, \\textbf{94.32\\%} accuracy on ScanObjectNN, \\textbf{86.5\\%} Inst. mIoU on ShapeNetPart.",
            "headline_zh": "提出PointDico模型，通过扩散模型引导对比学习以解决3D点云表示学习中的过拟合和无序性问题。",
            "intro_zh": [
                "核心问题：现有对比方法易过拟合，生成方法难处理无序点云，阻碍3D表示学习。",
                "方法要点：结合扩散模型和对比学习，通过知识蒸馏实现多尺度特征提取与局部全局信息融合。",
                "实验或效果：在ScanObjectNN和ShapeNetPart上达到新SOTA，准确率分别为94.32%和86.5% mIoU。"
            ],
            "tags_zh": [
                "3D表示学习",
                "点云处理",
                "扩散模型",
                "对比学习",
                "知识蒸馏",
                "多尺度特征提取"
            ],
            "_index": 177
        },
        {
            "title": "Interpreting Structured Perturbations in Image Protection Methods for Diffusion Models",
            "authors": [
                "Michael R. Martin",
                "Garrick Chan",
                "Kwan-Liu Ma"
            ],
            "arxiv_id": "2512.08329v1",
            "summary": "Recent image protection mechanisms such as Glaze and Nightshade introduce imperceptible, adversarially designed perturbations intended to disrupt downstream text-to-image generative models. While their empirical effectiveness is known, the internal structure, detectability, and representational behavior of these perturbations remain poorly understood. This study provides a systematic, explainable AI analysis using a unified framework that integrates white-box feature-space inspection and black-box signal-level probing. Through latent-space clustering, feature-channel activation analysis, occlusion-based spatial sensitivity mapping, and frequency-domain characterization, we show that protection mechanisms operate as structured, low-entropy perturbations tightly coupled to underlying image content across representational, spatial, and spectral domains. Protected images preserve content-driven feature organization with protection-specific substructure rather than inducing global representational drift. Detectability is governed by interacting effects of perturbation entropy, spatial deployment, and frequency alignment, with sequential protection amplifying detectable structure rather than suppressing it. Frequency-domain analysis shows that Glaze and Nightshade redistribute energy along dominant image-aligned frequency axes rather than introducing diffuse noise. These findings indicate that contemporary image protection operates through structured feature-level deformation rather than semantic dislocation, explaining why protection signals remain visually subtle yet consistently detectable. This work advances the interpretability of adversarial image protection and informs the design of future defenses and detection strategies for generative AI systems.",
            "headline_zh": "系统分析图像保护机制的结构化扰动，揭示其在扩散模型中的可检测性与表示行为",
            "intro_zh": [
                "核心问题：Glaze和Nightshade等图像保护机制的结构、可检测性和表示行为尚不明确",
                "方法要点：采用统一框架，结合白盒特征空间检查和黑盒信号级探测进行可解释AI分析",
                "实验或效果：通过聚类、激活分析、空间敏感度映射和频域表征，发现扰动为结构化低熵，与图像内容紧密耦合"
            ],
            "tags_zh": [
                "图像保护机制",
                "结构化扰动",
                "可解释AI",
                "扩散模型",
                "频域分析",
                "特征空间检查"
            ],
            "_index": 178
        },
        {
            "title": "Low Rank Support Quaternion Matrix Machine",
            "authors": [
                "Wang Chen",
                "Ziyan Luo",
                "Shuangyue Wang"
            ],
            "arxiv_id": "2512.08327v1",
            "summary": "Input features are conventionally represented as vectors, matrices, or third order tensors in the real field, for color image classification. Inspired by the success of quaternion data modeling for color images in image recovery and denoising tasks, we propose a novel classification method for color image classification, named as the Low-rank Support Quaternion Matrix Machine (LSQMM), in which the RGB channels are treated as pure quaternions to effectively preserve the intrinsic coupling relationships among channels via the quaternion algebra. For the purpose of promoting low-rank structures resulting from strongly correlated color channels, a quaternion nuclear norm regularization term, serving as a natural extension of the conventional matrix nuclear norm to the quaternion domain, is added to the hinge loss in our LSQMM model. An Alternating Direction Method of Multipliers (ADMM)-based iterative algorithm is designed to effectively resolve the proposed quaternion optimization model. Experimental results on multiple color image classification datasets demonstrate that our proposed classification approach exhibits advantages in classification accuracy, robustness and computational efficiency, compared to several state-of-the-art methods using support vector machines, support matrix machines, and support tensor machines.",
            "headline_zh": "提出低秩支持四元数矩阵机以提升彩色图像分类性能",
            "intro_zh": [
                "核心问题：传统彩色图像分类方法使用向量、矩阵或张量表示，可能忽略通道间内在耦合关系。",
                "方法要点：将RGB通道建模为纯四元数，引入四元数核范数正则化以促进低秩结构，设计ADMM算法求解优化模型。",
                "实验或效果：在多个数据集上验证，相比支持向量机、支持矩阵机和支持张量机，在准确性、鲁棒性和计算效率方面有优势。"
            ],
            "tags_zh": [
                "彩色图像分类",
                "四元数建模",
                "低秩正则化",
                "ADMM算法",
                "支持矩阵机"
            ],
            "_index": 179
        },
        {
            "title": "Argus: A Multi-Agent Sensitive Information Leakage Detection Framework Based on Hierarchical Reference Relationships",
            "authors": [
                "Bin Wang",
                "Hui Li",
                "Liyang Zhang",
                "Qijia Zhuang",
                "Ao Yang",
                "Dong Zhang",
                "Xijun Luo",
                "Bing Lin"
            ],
            "arxiv_id": "2512.08326v1",
            "summary": "Sensitive information leakage in code repositories has emerged as a critical security challenge. Traditional detection methods that rely on regular expressions, fingerprint features, and high-entropy calculations often suffer from high false-positive rates. This not only reduces detection efficiency but also significantly increases the manual screening burden on developers. Recent advances in large language models (LLMs) and multi-agent collaborative architectures have demonstrated remarkable potential for tackling complex tasks, offering a novel technological perspective for sensitive information detection. In response to these challenges, we propose Argus, a multi-agent collaborative framework for detecting sensitive information. Argus employs a three-tier detection mechanism that integrates key content, file context, and project reference relationships to effectively reduce false positives and enhance overall detection accuracy. To comprehensively evaluate Argus in real-world repository environments, we developed two new benchmarks, one to assess genuine leak detection capabilities and another to evaluate false-positive filtering performance. Experimental results show that Argus achieves up to 94.86% accuracy in leak detection, with a precision of 96.36%, recall of 94.64%, and an F1 score of 0.955. Moreover, the analysis of 97 real repositories incurred a total cost of only 2.2$. All code implementations and related datasets are publicly available at https://github.com/TheBinKing/Argus-Guard for further research and application.",
            "headline_zh": "提出Argus多智能体框架，基于分层参考关系检测代码库敏感信息泄露，降低误报率。",
            "intro_zh": [
                "核心问题：传统敏感信息检测方法误报率高，增加开发者手动筛查负担。",
                "方法要点：采用三层检测机制，结合内容、文件上下文和项目参考关系，多智能体协作。",
                "实验或效果：在真实仓库测试中，准确率达94.86%，成本仅2.2美元，代码开源。"
            ],
            "tags_zh": [
                "敏感信息泄露检测",
                "多智能体协作",
                "分层参考关系",
                "代码库安全",
                "大语言模型应用",
                "误报率降低"
            ],
            "_index": 180
        },
        {
            "title": "GeoDiffMM: Geometry-Guided Conditional Diffusion for Motion Magnification",
            "authors": [
                "Xuedeng Liu",
                "Jiabao Guo",
                "Zheng Zhang",
                "Fei Wang",
                "Zhi Liu",
                "Dan Guo"
            ],
            "arxiv_id": "2512.08325v1",
            "summary": "Video Motion Magnification (VMM) amplifies subtle macroscopic motions to a perceptible level. Recently, existing mainstream Eulerian approaches address amplification-induced noise via decoupling representation learning such as texture, shape and frequancey schemes, but they still struggle to separate photon noise from true micro-motion when motion displacements are very small. We propose GeoDiffMM, a novel diffusion-based Lagrangian VMM framework conditioned on optical flow as a geometric cue, enabling structurally consistent motion magnification. Specifically, we design a Noise-free Optical Flow Augmentation strategy that synthesizes diverse nonrigid motion fields without photon noise as supervision, helping the model learn more accurate geometry-aware optial flow and generalize better. Next, we develop a Diffusion Motion Magnifier that conditions the denoising process on (i) optical flow as a geometry prior and (ii) a learnable magnification factor controlling magnitude, thereby selectively amplifying motion components consistent with scene semantics and structure while suppressing content-irrelevant perturbations. Finally, we perform Flow-based Video Synthesis to map the amplified motion back to the image domain with high fidelity. Extensive experiments on real and synthetic datasets show that GeoDiffMM outperforms state-of-the-art methods and significantly improves motion magnification.",
            "headline_zh": "提出GeoDiffMM，一种基于扩散的拉格朗日视频运动放大框架，利用光流作为几何先验以提升放大效果。",
            "intro_zh": [
                "核心问题：现有欧拉方法在微小位移下难以分离光子噪声与真实微运动，导致放大噪声。",
                "方法要点：设计无噪声光流增强策略和扩散运动放大器，以光流为条件选择性放大结构一致的运动。",
                "实验或效果：在真实和合成数据集上优于先进方法，显著改善运动放大质量。"
            ],
            "tags_zh": [
                "视频运动放大",
                "扩散模型",
                "光流引导",
                "拉格朗日方法",
                "几何先验"
            ],
            "_index": 181
        },
        {
            "title": "Detecting Dental Landmarks from Intraoral 3D Scans: the 3DTeethLand challenge",
            "authors": [
                "Achraf Ben-Hamadou",
                "Nour Neifar",
                "Ahmed Rekik",
                "Oussama Smaoui",
                "Firas Bouzguenda",
                "Sergi Pujades",
                "Niels van Nistelrooij",
                "Shankeeth Vinayahalingam",
                "Kaibo Shi",
                "Hairong Jin",
                "Youyi Zheng",
                "Tibor Kubík",
                "Oldřich Kodym",
                "Petr Šilling",
                "Kateřina Trávníčková",
                "Tomáš Mojžiš",
                "Jan Matula",
                "Jeffry Hartanto",
                "Xiaoying Zhu",
                "Kim-Ngan Nguyen",
                "Tudor Dascalu",
                "Huikai Wu",
                "and Weijie Liu",
                "Shaojie Zhuang",
                "Guangshun Wei",
                "Yuanfeng Zhou"
            ],
            "arxiv_id": "2512.08323v1",
            "summary": "Teeth landmark detection is a critical task in modern clinical orthodontics. Their precise identification enables advanced diagnostics, facilitates personalized treatment strategies, and supports more effective monitoring of treatment progress in clinical dentistry. However, several significant challenges may arise due to the intricate geometry of individual teeth and the substantial variations observed across different individuals. To address these complexities, the development of advanced techniques, especially through the application of deep learning, is essential for the precise and reliable detection of 3D tooth landmarks. In this context, the 3DTeethLand challenge was held in collaboration with the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) in 2024, calling for algorithms focused on teeth landmark detection from intraoral 3D scans. This challenge introduced the first publicly available dataset for 3D teeth landmark detection, offering a valuable resource to assess the state-of-the-art methods in this task and encourage the community to provide methodological contributions towards the resolution of their problem with significant clinical implications.",
            "headline_zh": "提出3DTeethLand挑战赛以解决口腔内3D扫描中的牙齿标志点检测问题",
            "intro_zh": [
                "核心问题：牙齿几何结构复杂且个体差异大，影响3D牙齿标志点的精确检测。",
                "方法要点：通过深度学习技术开发先进算法，用于从口腔内3D扫描中检测牙齿标志点。",
                "实验或效果：引入首个公开3D牙齿标志点检测数据集，评估现有方法并推动社区贡献。"
            ],
            "tags_zh": [
                "牙齿标志点检测",
                "口腔内3D扫描",
                "深度学习",
                "医学图像计算",
                "MICCAI挑战赛",
                "临床牙科"
            ],
            "_index": 182
        },
        {
            "title": "GeoDM: Geometry-aware Distribution Matching for Dataset Distillation",
            "authors": [
                "Xuhui Li",
                "Zhengquan Luo",
                "Zihui Cui",
                "Zhiqiang Xu"
            ],
            "arxiv_id": "2512.08317v1",
            "summary": "Dataset distillation aims to synthesize a compact subset of the original data, enabling models trained on it to achieve performance comparable to those trained on the original large dataset. Existing distribution-matching methods are confined to Euclidean spaces, making them only capture linear structures and overlook the intrinsic geometry of real data, e.g., curvature. However, high-dimensional data often lie on low-dimensional manifolds, suggesting that dataset distillation should have the distilled data manifold aligned with the original data manifold. In this work, we propose a geometry-aware distribution-matching framework, called \\textbf{GeoDM}, which operates in the Cartesian product of Euclidean, hyperbolic, and spherical manifolds, with flat, hierarchical, and cyclical structures all captured by a unified representation. To adapt to the underlying data geometry, we introduce learnable curvature and weight parameters for three kinds of geometries. At the same time, we design an optimal transport loss to enhance the distribution fidelity. Our theoretical analysis shows that the geometry-aware distribution matching in a product space yields a smaller generalization error bound than the Euclidean counterparts. Extensive experiments conducted on standard benchmarks demonstrate that our algorithm outperforms state-of-the-art data distillation methods and remains effective across various distribution-matching strategies for the single geometries.",
            "headline_zh": "提出GeoDM框架，通过几何感知分布匹配解决数据集蒸馏中忽略数据内在几何结构的问题。",
            "intro_zh": [
                "核心问题：现有分布匹配方法局限于欧氏空间，无法捕捉高维数据的非线性几何结构如曲率。",
                "方法要点：在欧氏、双曲和球面流形的笛卡尔积空间中操作，引入可学习曲率和权重参数以适配数据几何。",
                "实验或效果：在标准基准测试中优于现有数据集蒸馏方法，理论分析显示泛化误差界更小。"
            ],
            "tags_zh": [
                "数据集蒸馏",
                "几何感知",
                "分布匹配",
                "流形学习",
                "最优传输",
                "泛化误差"
            ],
            "_index": 183
        },
        {
            "title": "Minimizing Layerwise Activation Norm Improves Generalization in Federated Learning",
            "authors": [
                "M Yashwanth",
                "Gaurav Kumar Nayak",
                "Harsh Rangwani",
                "Arya Singh",
                "R. Venkatesh Babu",
                "Anirban Chakraborty"
            ],
            "arxiv_id": "2512.08314v1",
            "summary": "Federated Learning (FL) is an emerging machine learning framework that enables multiple clients (coordinated by a server) to collaboratively train a global model by aggregating the locally trained models without sharing any client's training data. It has been observed in recent works that learning in a federated manner may lead the aggregated global model to converge to a 'sharp minimum' thereby adversely affecting the generalizability of this FL-trained model. Therefore, in this work, we aim to improve the generalization performance of models trained in a federated setup by introducing a 'flatness' constrained FL optimization problem. This flatness constraint is imposed on the top eigenvalue of the Hessian computed from the training loss. As each client trains a model on its local data, we further re-formulate this complex problem utilizing the client loss functions and propose a new computationally efficient regularization technique, dubbed 'MAN,' which Minimizes Activation's Norm of each layer on client-side models. We also theoretically show that minimizing the activation norm reduces the top eigenvalue of the layer-wise Hessian of the client's loss, which in turn decreases the overall Hessian's top eigenvalue, ensuring convergence to a flat minimum. We apply our proposed flatness-constrained optimization to the existing FL techniques and obtain significant improvements, thereby establishing new state-of-the-art.",
            "headline_zh": "提出MAN正则化以提升联邦学习中模型的泛化性能",
            "intro_zh": [
                "联邦学习易收敛至尖锐最小值，损害模型泛化能力",
                "通过最小化层激活范数约束Hessian特征值，确保平坦最小值",
                "在现有FL技术上应用，显著提升性能，达到新SOTA"
            ],
            "tags_zh": [
                "联邦学习",
                "泛化性能",
                "平坦最小值",
                "Hessian特征值",
                "激活范数正则化"
            ],
            "_index": 184
        },
        {
            "title": "Terrain Diffusion: A Diffusion-Based Successor to Perlin Noise in Infinite, Real-Time Terrain Generation",
            "authors": [
                "Alexander Goslin"
            ],
            "arxiv_id": "2512.08309v1",
            "summary": "For decades, procedural worlds have been built on procedural noise functions such as Perlin noise, which are fast and infinite, yet fundamentally limited in realism and large-scale coherence. We introduce Terrain Diffusion, an AI-era successor to Perlin noise that bridges the fidelity of diffusion models with the properties that made procedural noise indispensable: seamless infinite extent, seed-consistency, and constant-time random access. At its core is InfiniteDiffusion, a novel algorithm for infinite generation, enabling seamless, real-time synthesis of boundless landscapes. A hierarchical stack of diffusion models couples planetary context with local detail, while a compact Laplacian encoding stabilizes outputs across Earth-scale dynamic ranges. An open-source infinite-tensor framework supports constant-memory manipulation of unbounded tensors, and few-step consistency distillation enables efficient generation. Together, these components establish diffusion models as a practical foundation for procedural world generation, capable of synthesizing entire planets coherently, controllably, and without limits.",
            "headline_zh": "提出Terrain Diffusion以解决Perlin噪声在无限实时地形生成中真实性和大规模连贯性不足的问题。",
            "intro_zh": [
                "核心问题：Perlin噪声等传统方法在无限地形生成中真实性和大规模连贯性有限。",
                "方法要点：引入InfiniteDiffusion算法，结合分层扩散模型和拉普拉斯编码，实现无缝无限生成。",
                "实验或效果：支持实时合成无边景观，能连贯可控地生成整个行星，开源框架提供恒定内存操作。"
            ],
            "tags_zh": [
                "无限地形生成",
                "扩散模型",
                "实时合成",
                "拉普拉斯编码",
                "一致性蒸馏",
                "开源框架"
            ],
            "_index": 185
        },
        {
            "title": "Jacobian Aligned Random Forests",
            "authors": [
                "Sarwesh Rauniyar"
            ],
            "arxiv_id": "2512.08306v1",
            "summary": "Axis-aligned decision trees are fast and stable but struggle on datasets with rotated or interaction-dependent decision boundaries, where informative splits require linear combinations of features rather than single-feature thresholds. Oblique forests address this with per-node hyperplane splits, but at added computational cost and implementation complexity. We propose a simple alternative: JARF, Jacobian-Aligned Random Forests. Concretely, we first fit an axis-aligned forest to estimate class probabilities or regression outputs, compute finite-difference gradients of these predictions with respect to each feature, aggregate them into an expected Jacobian outer product that generalizes the expected gradient outer product (EGOP), and use it as a single global linear preconditioner for all inputs. This supervised preconditioner applies a single global rotation of the feature space, then hands the transformed data back to a standard axis-aligned forest, preserving off-the-shelf training pipelines while capturing oblique boundaries and feature interactions that would otherwise require many axis-aligned splits to approximate. The same construction applies to any model that provides gradients, though we focus on random forests and gradient-boosted trees in this work. On tabular classification and regression benchmarks, this preconditioning consistently improves axis-aligned forests and often matches or surpasses oblique baselines while improving training time. Our experimental results and theoretical analysis together indicate that supervised preconditioning can recover much of the accuracy of oblique forests while retaining the simplicity and robustness of axis-aligned trees.",
            "headline_zh": "提出JARF方法，通过雅可比对齐预处理器提升轴对齐森林在旋转或交互依赖决策边界数据集上的性能。",
            "intro_zh": [
                "轴对齐决策树在旋转或交互依赖决策边界上表现不佳，需要线性组合特征而非单特征阈值。",
                "JARF利用森林预测的梯度计算雅可比外积，作为全局线性预处理器旋转特征空间，再训练轴对齐森林。",
                "实验表明，该方法在表格分类和回归基准上提升轴对齐森林性能，常匹配或超越斜森林，同时保持训练效率。"
            ],
            "tags_zh": [
                "随机森林",
                "雅可比对齐",
                "特征预处理器",
                "决策边界优化",
                "表格数据学习"
            ],
            "_index": 186
        },
        {
            "title": "Magnetic activity of ultracool dwarfs in the LAMOST DR11",
            "authors": [
                "Yue Xiang",
                "Shenghong Gu",
                "Dongtao Cao"
            ],
            "arxiv_id": "2512.08305v1",
            "summary": "Ultracool dwarfs consist of lowest-mass stars and brown dwarfs. Their interior is fully convective, different from that of the partly-convective Sun-like stars. Magnetic field generation process beneath the surface of ultracool dwarfs is still poorly understood and controversial. To increase samples of active ultracool dwarfs significantly, we have identified 962 ultracool dwarfs in the latest LAMOST data release, DR11. We also simulate the Chinese Space Station Survey Telescope (CSST) low-resolution slitless spectra by degrading the LAMOST spectra. A semi-supervised machine learning approach with an autoencoder model is built to identify ultracool dwarfs with the simulated CSST spectra, which demonstrates the capability of the CSST all-sky slitless spectroscopic survey on the detection of ultracool dwarfs. Magnetic activity of the ultracool dwarfs is investigated by using the H$α$ line emission as a proxy. The rotational periods of 82 ultracool dwarfs are derived based on the Kepler/K2 light curves. We also derive the activity-rotation relation of the ultracool dwarfs, which is saturated around a Rossby number of 0.12.",
            "headline_zh": "利用LAMOST DR11数据识别超冷矮星并研究其磁活动与自转关系",
            "intro_zh": [
                "研究超冷矮星磁活动生成机制，因内部全对流与类太阳星不同，理解不足且存在争议。",
                "从LAMOST DR11识别962颗超冷矮星，模拟CSST光谱，用自编码器半监督学习识别超冷矮星。",
                "以Hα线发射为代理研究磁活动，基于Kepler/K2光变曲线推导82颗自转周期，发现活动-自转关系在罗斯贝数0.12饱和。"
            ],
            "tags_zh": [
                "超冷矮星",
                "磁活动",
                "自转周期",
                "LAMOST光谱",
                "半监督学习",
                "活动-自转关系"
            ],
            "_index": 187
        },
        {
            "title": "rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection",
            "authors": [
                "Sijia Chen",
                "Baochun Li",
                "Di Niu"
            ],
            "arxiv_id": "2512.08300v1",
            "summary": "Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.",
            "headline_zh": "提出强化策略注入机制，通过多智能体强化学习提升大语言模型推理能力。",
            "intro_zh": [
                "核心问题：大语言模型在推理任务中缺乏策略性思考，如自我反思和深度思考。",
                "方法要点：使用小型规划器作为领导者智能体，通过强化学习自适应注入推理策略到链式思考中。",
                "实验或效果：rSIM使小模型性能超越大模型，规划器可通用化并支持持续学习。"
            ],
            "tags_zh": [
                "强化学习",
                "推理语言模型",
                "多智能体系统",
                "策略注入",
                "链式思考",
                "通用规划器"
            ],
            "_index": 188
        },
        {
            "title": "Towards a Science of Scaling Agent Systems",
            "authors": [
                "Yubin Kim",
                "Ken Gu",
                "Chanwoo Park",
                "Chunjong Park",
                "Samuel Schmidgall",
                "A. Ali Heydari",
                "Yao Yan",
                "Zhihan Zhang",
                "Yuchen Zhuang",
                "Mark Malhotra",
                "Paul Pu Liang",
                "Hae Won Park",
                "Yuzhe Yang",
                "Xuhai Xu",
                "Yilun Du",
                "Shwetak Patel",
                "Tim Althoff",
                "Daniel McDuff",
                "Xin Liu"
            ],
            "arxiv_id": "2512.08296v1",
            "summary": "Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.",
            "headline_zh": "提出基于经验协调度量的定量缩放原则，以预测多智能体系统性能",
            "intro_zh": [
                "核心问题：智能体系统性能缺乏量化原则，依赖启发式设计",
                "方法要点：通过五种架构在四个基准上评估180种配置，使用效率、开销等度量建模",
                "实验或效果：模型交叉验证R^2=0.513，识别工具协调权衡等效应，预测87%配置最优策略"
            ],
            "tags_zh": [
                "智能体缩放",
                "协调度量",
                "多智能体架构",
                "性能预测",
                "语言模型系统"
            ],
            "_index": 189
        },
        {
            "title": "OpenSubject: Leveraging Video-Derived Identity and Diversity Priors for Subject-driven Image Generation and Manipulation",
            "authors": [
                "Yexin Liu",
                "Manyuan Zhang",
                "Yueze Wang",
                "Hongyu Li",
                "Dian Zheng",
                "Weiming Zhang",
                "Changsheng Lu",
                "Xunliang Cai",
                "Yan Feng",
                "Peng Pei",
                "Harry Yang"
            ],
            "arxiv_id": "2512.08294v1",
            "summary": "Despite the promising progress in subject-driven image generation, current models often deviate from the reference identities and struggle in complex scenes with multiple subjects. To address this challenge, we introduce OpenSubject, a video-derived large-scale corpus with 2.5M samples and 4.35M images for subject-driven generation and manipulation. The dataset is built with a four-stage pipeline that exploits cross-frame identity priors. (i) Video Curation. We apply resolution and aesthetic filtering to obtain high-quality clips. (ii) Cross-Frame Subject Mining and Pairing. We utilize vision-language model (VLM)-based category consensus, local grounding, and diversity-aware pairing to select image pairs. (iii) Identity-Preserving Reference Image Synthesis. We introduce segmentation map-guided outpainting to synthesize the input images for subject-driven generation and box-guided inpainting to generate input images for subject-driven manipulation, together with geometry-aware augmentations and irregular boundary erosion. (iv) Verification and Captioning. We utilize a VLM to validate synthesized samples, re-synthesize failed samples based on stage (iii), and then construct short and long captions. In addition, we introduce a benchmark covering subject-driven generation and manipulation, and then evaluate identity fidelity, prompt adherence, manipulation consistency, and background consistency with a VLM judge. Extensive experiments show that training with OpenSubject improves generation and manipulation performance, particularly in complex scenes.",
            "headline_zh": "提出OpenSubject数据集以解决主题驱动图像生成与编辑中的身份偏离和复杂场景难题",
            "intro_zh": [
                "当前主题驱动图像生成模型常偏离参考身份，在复杂多主题场景中表现不佳",
                "构建视频衍生大规模数据集，通过四阶段流程利用跨帧身份先验，包括视频筛选、主题挖掘配对、身份保持图像合成和验证标注",
                "实验表明使用OpenSubject训练能提升生成和编辑性能，尤其在复杂场景中"
            ],
            "tags_zh": [
                "主题驱动图像生成",
                "视频衍生数据集",
                "身份先验",
                "图像编辑",
                "视觉语言模型",
                "复杂场景处理"
            ],
            "_index": 190
        },
        {
            "title": "Systematization of Knowledge: Security and Safety in the Model Context Protocol Ecosystem",
            "authors": [
                "Shiva Gaire",
                "Srijan Gyawali",
                "Saroj Mishra",
                "Suman Niroula",
                "Dilip Thakur",
                "Umesh Yadav"
            ],
            "arxiv_id": "2512.08290v1",
            "summary": "The Model Context Protocol (MCP) has emerged as the de facto standard for connecting Large Language Models (LLMs) to external data and tools, effectively functioning as the \"USB-C for Agentic AI.\" While this decoupling of context and execution solves critical interoperability challenges, it introduces a profound new threat landscape where the boundary between epistemic errors (hallucinations) and security breaches (unauthorized actions) dissolves. This Systematization of Knowledge (SoK) aims to provide a comprehensive taxonomy of risks in the MCP ecosystem, distinguishing between adversarial security threats (e.g., indirect prompt injection, tool poisoning) and epistemic safety hazards (e.g., alignment failures in distributed tool delegation). We analyze the structural vulnerabilities of MCP primitives, specifically Resources, Prompts, and Tools, and demonstrate how \"context\" can be weaponized to trigger unauthorized operations in multi-agent environments. Furthermore, we survey state-of-the-art defenses, ranging from cryptographic provenance (ETDI) to runtime intent verification, and conclude with a roadmap for securing the transition from conversational chatbots to autonomous agentic operating systems.",
            "headline_zh": "系统化分析模型上下文协议生态中的安全与安全风险，提出分类与防御路线图",
            "intro_zh": [
                "核心问题：模型上下文协议（MCP）作为LLM连接外部数据和工具的标准，模糊了幻觉与安全漏洞的边界，引入新威胁。",
                "方法要点：建立风险分类学，区分对抗性安全威胁（如间接提示注入）和认知性安全危害（如分布式工具委托中的对齐失败）。",
                "实验或效果：分析MCP原语（资源、提示、工具）的结构性漏洞，并调查从加密来源到运行时意图验证的先进防御方法。"
            ],
            "tags_zh": [
                "模型上下文协议",
                "安全风险分类",
                "对抗性威胁",
                "认知性危害",
                "多代理环境",
                "防御路线图"
            ],
            "_index": 191
        },
        {
            "title": "Empowering smart app development with SolidGPT: an edge-cloud hybrid AI agent framework",
            "authors": [
                "Liao Hu",
                "Qiteng Wu",
                "Ruoyu Qi"
            ],
            "arxiv_id": "2512.08286v1",
            "summary": "The integration of Large Language Models (LLMs) into mobile and software development workflows faces a persistent tension among three demands: semantic awareness, developer productivity, and data privacy. Traditional cloud-based tools offer strong reasoning but risk data exposure and latency, while on-device solutions lack full-context understanding across codebase and developer tooling. We introduce SolidGPT, an open-source, edge-cloud hybrid developer assistant built on GitHub, designed to enhance code and workspace semantic search. SolidGPT enables developers to: talk to your codebase: interactively query code and project structure, discovering the right methods and modules without manual searching. Automate software project workflows: generate PRDs, task breakdowns, Kanban boards, and even scaffold web app beginnings, with deep integration via VSCode and Notion. Configure private, extensible agents: onboard private code folders (up to approximately 500 files), connect Notion, customize AI agent personas via embedding and in-context training, and deploy via Docker, CLI, or VSCode extension. In practice, SolidGPT empowers developer productivity through: Semantic-rich code navigation: no more hunting through files or wondering where a feature lives. Integrated documentation and task management: seamlessly sync generated PRD content and task boards into developer workflows. Privacy-first design: running locally via Docker or VSCode, with full control over code and data, while optionally reaching out to LLM APIs as needed. By combining interactive code querying, automated project scaffolding, and human-AI collaboration, SolidGPT provides a practical, privacy-respecting edge assistant that accelerates real-world development workflows, ideal for intelligent mobile and software engineering contexts.",
            "headline_zh": "提出SolidGPT边缘-云混合AI代理框架，以增强智能应用开发中的语义搜索与隐私保护",
            "intro_zh": [
                "核心问题：LLM集成到开发流程中面临语义感知、开发效率与数据隐私的平衡挑战",
                "方法要点：基于GitHub构建开源框架，支持代码库交互查询、项目工作流自动化与私有代理配置",
                "实验或效果：通过本地部署和工具集成，提升代码导航效率，并尊重数据隐私"
            ],
            "tags_zh": [
                "边缘-云混合框架",
                "代码语义搜索",
                "开发工作流自动化",
                "隐私保护设计",
                "AI代理定制",
                "智能软件开发"
            ],
            "_index": 192
        },
        {
            "title": "Self-Reinforced Deep Priors for Reparameterized Full Waveform Inversion",
            "authors": [
                "Guangyuan Zou",
                "Junlun Li",
                "Feng Liu",
                "Xuejing Zheng",
                "Jianjian Xie",
                "Guoyi Chen"
            ],
            "arxiv_id": "2512.08284v1",
            "summary": "Full waveform inversion (FWI) has become a widely adopted technique for high-resolution subsurface imaging. However, its inherent strong nonlinearity often results in convergence toward local minima. Recently, deep image prior-based reparameterized FWI (DIP-FWI) has been proposed to alleviate the dependence on massive training data. By exploiting the spectral bias and implicit regularization in the neural network architecture, DIP-FWI can effectively avoid local minima and reconstruct more geologically plausible velocity models. Nevertheless, existing DIP-FWI typically use a fixed random input throughout the inversion process, which fails to utilize the mapping and correlation between the input and output of the network. Moreover, under complex geological conditions, the lack of informative prior in the input can exacerbate the ill-posedness of the inverse problem, leading to artifacts and unstable reconstructions. To address these limitations, we propose a self-reinforced DIP-FWI (SRDIP-FWI) framework, in which a steering algorithm alternately updates both the network parameters and the input at each iteration using feedback from the current network output. This design allows adaptive structural enhancement and improved regularization, thereby effectively mitigating the ill-posedness in FWI. Additionally, we analyze the spectral bias of the network in SRDIP-FWI and quantify its role in multiscale velocity model building. Synthetic tests and field land data application demonstrate that SRDIP-FWI achieves superior resolution, improved accuracy and greater depth penetration compared to multiscale FWI. More importantly, SRDIP-FWI eliminates the need for manual frequency-band selection and time-window picking, substantially simplifying the inversion workflow. Overall, the proposed method provides a novel, adaptive and robust framework for accurate subsurface velocity model reconstruction.",
            "headline_zh": "提出自增强深度先验重参数化全波形反演框架，以解决复杂地质条件下反演不稳定和伪影问题。",
            "intro_zh": [
                "核心问题：传统深度先验全波形反演使用固定随机输入，无法利用网络输入输出映射，加剧反演不适定性。",
                "方法要点：通过转向算法交替更新网络参数和输入，实现自适应结构增强和正则化改进。",
                "实验或效果：合成和实地数据测试显示，该方法提升分辨率、精度和深度穿透，无需手动频带选择和时间窗选取。"
            ],
            "tags_zh": [
                "全波形反演",
                "深度先验",
                "重参数化",
                "自增强学习",
                "速度模型重建",
                "不适定问题"
            ],
            "_index": 193
        },
        {
            "title": "PAVAS: Physics-Aware Video-to-Audio Synthesis",
            "authors": [
                "Oh Hyun-Bin",
                "Yuhta Takida",
                "Toshimitsu Uesaka",
                "Tae-Hyun Oh",
                "Yuki Mitsufuji"
            ],
            "arxiv_id": "2512.08282v1",
            "summary": "Recent advances in Video-to-Audio (V2A) generation have achieved impressive perceptual quality and temporal synchronization, yet most models remain appearance-driven, capturing visual-acoustic correlations without considering the physical factors that shape real-world sounds. We present Physics-Aware Video-to-Audio Synthesis (PAVAS), a method that incorporates physical reasoning into a latent diffusion-based V2A generation through the Physics-Driven Audio Adapter (Phy-Adapter). The adapter receives object-level physical parameters estimated by the Physical Parameter Estimator (PPE), which uses a Vision-Language Model (VLM) to infer the moving-object mass and a segmentation-based dynamic 3D reconstruction module to recover its motion trajectory for velocity computation. These physical cues enable the model to synthesize sounds that reflect underlying physical factors. To assess physical realism, we curate VGG-Impact, a benchmark focusing on object-object interactions, and introduce Audio-Physics Correlation Coefficient (APCC), an evaluation metric that measures consistency between physical and auditory attributes. Comprehensive experiments show that PAVAS produces physically plausible and perceptually coherent audio, outperforming existing V2A models in both quantitative and qualitative evaluations. Visit https://physics-aware-video-to-audio-synthesis.github.io for demo videos.",
            "headline_zh": "提出PAVAS方法，通过物理感知适配器将物理推理融入视频到音频合成，以提升声音的物理真实性。",
            "intro_zh": [
                "现有视频到音频生成模型多基于外观驱动，忽略物理因素对声音的影响。",
                "PAVAS引入物理驱动音频适配器，利用视觉语言模型和3D重建估计物体质量与速度，指导音频合成。",
                "实验基于VGG-Impact基准和APCC指标，显示PAVAS在物理合理性和感知一致性上优于现有模型。"
            ],
            "tags_zh": [
                "视频到音频合成",
                "物理感知生成",
                "扩散模型",
                "物体交互",
                "音频物理一致性"
            ],
            "_index": 194
        },
        {
            "title": "Probabilistic Multi-Agent Aircraft Landing Time Prediction",
            "authors": [
                "Kyungmin Kim",
                "Seokbin Yoon",
                "Keumjin Lee"
            ],
            "arxiv_id": "2512.08281v1",
            "summary": "Accurate and reliable aircraft landing time prediction is essential for effective resource allocation in air traffic management. However, the inherent uncertainty of aircraft trajectories and traffic flows poses significant challenges to both prediction accuracy and trustworthiness. Therefore, prediction models should not only provide point estimates of aircraft landing times but also the uncertainties associated with these predictions. Furthermore, aircraft trajectories are frequently influenced by the presence of nearby aircraft through air traffic control interventions such as radar vectoring. Consequently, landing time prediction models must account for multi-agent interactions in the airspace. In this work, we propose a probabilistic multi-agent aircraft landing time prediction framework that provides the landing times of multiple aircraft as distributions. We evaluate the proposed framework using an air traffic surveillance dataset collected from the terminal airspace of the Incheon International Airport in South Korea. The results demonstrate that the proposed model achieves higher prediction accuracy than the baselines and quantifies the associated uncertainties of its outcomes. In addition, the model uncovered underlying patterns in air traffic control through its attention scores, thereby enhancing explainability.",
            "headline_zh": "提出概率多智能体飞机着陆时间预测框架，以提升空管资源分配中的准确性和不确定性量化。",
            "intro_zh": [
                "核心问题：飞机轨迹和交通流的不确定性挑战着陆时间预测的准确性和可信度。",
                "方法要点：采用概率多智能体框架，预测多架飞机着陆时间的分布，并考虑空域交互。",
                "实验或效果：在仁川国际机场数据集上验证，模型优于基线，提供不确定性量化和可解释性。"
            ],
            "tags_zh": [
                "飞机着陆时间预测",
                "概率预测",
                "多智能体交互",
                "空管不确定性",
                "可解释性模型"
            ],
            "_index": 195
        },
        {
            "title": "Model-Based Diffusion Sampling for Predictive Control in Offline Decision Making",
            "authors": [
                "Haldun Balim",
                "Na Li",
                "Yilun Du"
            ],
            "arxiv_id": "2512.08280v1",
            "summary": "Offline decision-making requires synthesizing reliable behaviors from fixed datasets without further interaction, yet existing generative approaches often yield trajectories that are dynamically infeasible. We propose Model Predictive Diffuser (MPDiffuser), a compositional model-based diffusion framework consisting of: (i) a planner that generates diverse, task-aligned trajectories; (ii) a dynamics model that enforces consistency with the underlying system dynamics; and (iii) a ranker module that selects behaviors aligned with the task objectives. MPDiffuser employs an alternating diffusion sampling scheme, where planner and dynamics updates are interleaved to progressively refine trajectories for both task alignment and feasibility during the sampling process. We also provide a theoretical rationale for this procedure, showing how it balances fidelity to data priors with dynamics consistency. Empirically, the compositional design improves sample efficiency, as it leverages even low-quality data for dynamics learning and adapts seamlessly to novel dynamics. We evaluate MPDiffuser on both unconstrained (D4RL) and constrained (DSRL) offline decision-making benchmarks, demonstrating consistent gains over existing approaches. Furthermore, we present a preliminary study extending MPDiffuser to vision-based control tasks, showing its potential to scale to high-dimensional sensory inputs. Finally, we deploy our method on a real quadrupedal robot, showcasing its practicality for real-world control.",
            "headline_zh": "提出基于模型的扩散采样框架MPDiffuser，以解决离线决策中轨迹动态不可行的问题。",
            "intro_zh": [
                "离线决策需从固定数据集合成可靠行为，但现有生成方法常产生动态不可行轨迹。",
                "MPDiffuser结合规划器、动力学模型和排序器，通过交替扩散采样优化轨迹的任务对齐与可行性。",
                "在D4RL和DSRL基准上表现优于现有方法，并初步扩展到视觉控制与真实机器人部署。"
            ],
            "tags_zh": [
                "离线决策",
                "扩散模型",
                "模型预测控制",
                "轨迹生成",
                "机器人控制"
            ],
            "_index": 196
        },
        {
            "title": "FedLAD: A Modular and Adaptive Testbed for Federated Log Anomaly Detection",
            "authors": [
                "Yihan Liao",
                "Jacky Keung",
                "Zhenyu Mao",
                "Jingyu Zhang",
                "Jialong Li"
            ],
            "arxiv_id": "2512.08277v1",
            "summary": "Log-based anomaly detection (LAD) is critical for ensuring the reliability of large-scale distributed systems. However, most existing LAD approaches assume centralized training, which is often impractical due to privacy constraints and the decentralized nature of system logs. While federated learning (FL) offers a promising alternative, there is a lack of dedicated testbeds tailored to the needs of LAD in federated settings. To address this, we present FedLAD, a unified platform for training and evaluating LAD models under FL constraints. FedLAD supports plug-and-play integration of diverse LAD models, benchmark datasets, and aggregation strategies, while offering runtime support for validation logging (self-monitoring), parameter tuning (self-configuration), and adaptive strategy control (self-adaptation). By enabling reproducible and scalable experimentation, FedLAD bridges the gap between FL frameworks and LAD requirements, providing a solid foundation for future research. Project code is publicly available at: https://github.com/AA-cityu/FedLAD.",
            "headline_zh": "提出FedLAD测试平台，以解决联邦学习中日志异常检测缺乏专用工具的问题。",
            "intro_zh": [
                "核心问题：现有日志异常检测方法依赖集中训练，不适用于隐私约束和日志分散的场景。",
                "方法要点：FedLAD支持模块化集成多种模型、数据集和聚合策略，并提供自监控、自配置和自适应控制功能。",
                "实验或效果：平台促进可复现和可扩展的实验，为未来研究奠定基础，代码已开源。"
            ],
            "tags_zh": [
                "联邦学习",
                "日志异常检测",
                "测试平台",
                "模块化设计",
                "自适应控制"
            ],
            "_index": 197
        },
        {
            "title": "gHAWK: Local and Global Structure Encoding for Scalable Training of Graph Neural Networks on Knowledge Graphs",
            "authors": [
                "Humera Sabir",
                "Fatima Farooq",
                "Ashraf Aboulnaga"
            ],
            "arxiv_id": "2512.08274v1",
            "summary": "Knowledge Graphs (KGs) are a rich source of structured, heterogeneous data, powering a wide range of applications. A common approach to leverage this data is to train a graph neural network (GNN) on the KG. However, existing message-passing GNNs struggle to scale to large KGs because they rely on the iterative message passing process to learn the graph structure, which is inefficient, especially under mini-batch training, where a node sees only a partial view of its neighborhood. In this paper, we address this problem and present gHAWK, a novel and scalable GNN training framework for large KGs. The key idea is to precompute structural features for each node that capture its local and global structure before GNN training even begins. Specifically, gHAWK introduces a preprocessing step that computes: (a)~Bloom filters to compactly encode local neighborhood structure, and (b)~TransE embeddings to represent each node's global position in the graph. These features are then fused with any domain-specific features (e.g., text embeddings), producing a node feature vector that can be incorporated into any GNN technique. By augmenting message-passing training with structural priors, gHAWK significantly reduces memory usage, accelerates convergence, and improves model accuracy. Extensive experiments on large datasets from the Open Graph Benchmark (OGB) demonstrate that gHAWK achieves state-of-the-art accuracy and lower training time on both node property prediction and link prediction tasks, topping the OGB leaderboard for three graphs.",
            "headline_zh": "提出gHAWK框架，通过预计算局部与全局结构特征，解决知识图谱上大规模图神经网络训练的可扩展性问题。",
            "intro_zh": [
                "核心问题：现有消息传递图神经网络在大规模知识图谱上训练效率低，受限于迭代消息传递过程。",
                "方法要点：预处理阶段计算Bloom过滤器编码局部邻域结构，TransE嵌入表示全局位置，融合特征以增强GNN训练。",
                "实验或效果：在Open Graph Benchmark数据集上实现最优准确率和更低训练时间，提升节点属性预测和链接预测任务性能。"
            ],
            "tags_zh": [
                "知识图谱",
                "图神经网络",
                "可扩展训练",
                "结构编码",
                "预计算特征",
                "Open Graph Benchmark"
            ],
            "_index": 198
        },
        {
            "title": "AgentEval: Generative Agents as Reliable Proxies for Human Evaluation of AI-Generated Content",
            "authors": [
                "Thanh Vu",
                "Richi Nayak",
                "Thiru Balasubramaniam"
            ],
            "arxiv_id": "2512.08273v1",
            "summary": "Modern businesses are increasingly challenged by the time and expense required to generate and assess high-quality content. Human writers face time constraints, and extrinsic evaluations can be costly. While Large Language Models (LLMs) offer potential in content creation, concerns about the quality of AI-generated content persist. Traditional evaluation methods, like human surveys, further add operational costs, highlighting the need for efficient, automated solutions. This research introduces Generative Agents as a means to tackle these challenges. These agents can rapidly and cost-effectively evaluate AI-generated content, simulating human judgment by rating aspects such as coherence, interestingness, clarity, fairness, and relevance. By incorporating these agents, businesses can streamline content generation and ensure consistent, high-quality output while minimizing reliance on costly human evaluations. The study provides critical insights into enhancing LLMs for producing business-aligned, high-quality content, offering significant advancements in automated content generation and evaluation.",
            "headline_zh": "提出生成式代理作为可靠代理，以低成本自动化评估AI生成内容的质量。",
            "intro_zh": [
                "核心问题：AI生成内容质量评估依赖昂贵人工，需高效自动化方案。",
                "方法要点：利用生成式代理模拟人类判断，评估连贯性、趣味性等维度。",
                "实验或效果：研究提供关键见解，优化LLM生成业务对齐的高质量内容。"
            ],
            "tags_zh": [
                "生成式代理",
                "AI生成内容评估",
                "自动化评估",
                "大语言模型优化",
                "内容质量"
            ],
            "_index": 199
        },
        {
            "title": "Zero-Splat TeleAssist: A Zero-Shot Pose Estimation Framework for Semantic Teleoperation",
            "authors": [
                "Srijan Dokania",
                "Dharini Raghavan"
            ],
            "arxiv_id": "2512.08271v1",
            "summary": "We introduce Zero-Splat TeleAssist, a zero-shot sensor-fusion pipeline that transforms commodity CCTV streams into a shared, 6-DoF world model for multilateral teleoperation. By integrating vision-language segmentation, monocular depth, weighted-PCA pose extraction, and 3D Gaussian Splatting (3DGS), TeleAssist provides every operator with real-time global positions and orientations of multiple robots without fiducials or depth sensors in an interaction-centric teleoperation setup.",
            "headline_zh": "提出Zero-Splat TeleAssist框架，通过零样本传感器融合实现基于CCTV流的语义远程操作姿态估计。",
            "intro_zh": [
                "核心问题：在无标记或深度传感器的交互式远程操作中，实时估计多机器人的全局6自由度姿态。",
                "方法要点：集成视觉语言分割、单目深度、加权PCA姿态提取和3D高斯泼溅，构建共享世界模型。",
                "实验或效果：提供实时姿态信息，支持多边远程操作，无需额外传感器或标记。"
            ],
            "tags_zh": [
                "零样本姿态估计",
                "传感器融合",
                "远程操作",
                "3D高斯泼溅",
                "视觉语言分割",
                "单目深度估计"
            ],
            "_index": 200
        },
        {
            "title": "Reasoning Models Ace the CFA Exams",
            "authors": [
                "Jaisal Patel",
                "Yunzhe Chen",
                "Kaiwen He",
                "Keyi Wang",
                "David Li",
                "Kairong Xiao",
                "Xiao-Yang Liu"
            ],
            "arxiv_id": "2512.08270v1",
            "summary": "Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered Financial Analyst (CFA) exams. However, recent reasoning models have achieved strong results on graduate-level academic and professional examinations across various disciplines. In this paper, we evaluate state-of-the-art reasoning models on a set of mock CFA exams consisting of 980 questions across three Level I exams, two Level II exams, and three Level III exams. Using the same pass/fail criteria from prior studies, we find that most models clear all three levels. The models that pass, ordered by overall performance, are Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, and DeepSeek-V3.1. Specifically, Gemini 3.0 Pro achieves a record score of 97.6% on Level I. Performance is also strong on Level II, led by GPT-5 at 94.3%. On Level III, Gemini 2.5 Pro attains the highest score with 86.4% on multiple-choice questions while Gemini 3.0 Pro achieves 92.0% on constructed-response questions.",
            "headline_zh": "评估推理模型在CFA考试中的表现，发现多数模型通过所有级别",
            "intro_zh": [
                "核心问题：大型语言模型在CFA考试中表现不佳，但推理模型在专业考试中的能力未知",
                "方法要点：使用模拟CFA考试数据集，包含三个级别的980道问题，评估多个先进推理模型",
                "实验或效果：多数模型通过所有级别，Gemini 3.0 Pro在Level I创纪录得分97.6%"
            ],
            "tags_zh": [
                "推理模型",
                "CFA考试",
                "专业评估",
                "大语言模型",
                "性能测试"
            ],
            "_index": 201
        },
        {
            "title": "EgoX: Egocentric Video Generation from a Single Exocentric Video",
            "authors": [
                "Taewoong Kang",
                "Kinam Kim",
                "Dohyeon Kim",
                "Minho Park",
                "Junha Hyung",
                "Jaegul Choo"
            ],
            "arxiv_id": "2512.08269v1",
            "summary": "Egocentric perception enables humans to experience and understand the world directly from their own point of view. Translating exocentric (third-person) videos into egocentric (first-person) videos opens up new possibilities for immersive understanding but remains highly challenging due to extreme camera pose variations and minimal view overlap. This task requires faithfully preserving visible content while synthesizing unseen regions in a geometrically consistent manner. To achieve this, we present EgoX, a novel framework for generating egocentric videos from a single exocentric input. EgoX leverages the pretrained spatio temporal knowledge of large-scale video diffusion models through lightweight LoRA adaptation and introduces a unified conditioning strategy that combines exocentric and egocentric priors via width and channel wise concatenation. Additionally, a geometry-guided self-attention mechanism selectively attends to spatially relevant regions, ensuring geometric coherence and high visual fidelity. Our approach achieves coherent and realistic egocentric video generation while demonstrating strong scalability and robustness across unseen and in-the-wild videos.",
            "headline_zh": "提出EgoX框架，通过单视角外中心视频生成内中心视频，解决视角差异大和重叠少的挑战。",
            "intro_zh": [
                "核心问题：外中心到内中心视频转换因相机姿态变化大和视图重叠少而困难，需保持几何一致性和视觉保真度。",
                "方法要点：利用预训练视频扩散模型，通过LoRA轻量适配和统一条件策略结合外中心与内中心先验，引入几何引导自注意力机制。",
                "实验或效果：在未见和野外视频上实现连贯真实的内中心视频生成，展示强可扩展性和鲁棒性。"
            ],
            "tags_zh": [
                "视频生成",
                "视角转换",
                "扩散模型",
                "几何一致性",
                "自注意力机制",
                "轻量适配"
            ],
            "_index": 202
        },
        {
            "title": "SOFA-FL: Self-Organizing Hierarchical Federated Learning with Adaptive Clustered Data Sharing",
            "authors": [
                "Yi Ni",
                "Xinkun Wang",
                "Han Zhang"
            ],
            "arxiv_id": "2512.08267v1",
            "summary": "Federated Learning (FL) faces significant challenges in evolving environments, particularly regarding data heterogeneity and the rigidity of fixed network topologies. To address these issues, this paper proposes \\textbf{SOFA-FL} (Self-Organizing Hierarchical Federated Learning with Adaptive Clustered Data Sharing), a novel framework that enables hierarchical federated systems to self-organize and adapt over time.\n  The framework is built upon three core mechanisms: (1) \\textbf{Dynamic Multi-branch Agglomerative Clustering (DMAC)}, which constructs an initial efficient hierarchical structure; (2) \\textbf{Self-organizing Hierarchical Adaptive Propagation and Evolution (SHAPE)}, which allows the system to dynamically restructure its topology through atomic operations -- grafting, pruning, consolidation, and purification -- to adapt to changes in data distribution; and (3) \\textbf{Adaptive Clustered Data Sharing}, which mitigates data heterogeneity by enabling controlled partial data exchange between clients and cluster nodes.\n  By integrating these mechanisms, SOFA-FL effectively captures dynamic relationships among clients and enhances personalization capabilities without relying on predetermined cluster structures.",
            "headline_zh": "提出SOFA-FL框架以解决联邦学习在动态环境中的数据异构性和网络拓扑僵化问题",
            "intro_zh": [
                "核心问题：联邦学习在动态环境中面临数据异构性和固定网络拓扑的挑战",
                "方法要点：通过动态聚类、自组织拓扑演化和自适应数据共享机制实现系统自适应",
                "实验或效果：未知，但框架旨在增强客户端关系捕捉和个性化能力"
            ],
            "tags_zh": [
                "联邦学习",
                "自组织网络",
                "数据异构性",
                "动态聚类",
                "自适应拓扑",
                "数据共享"
            ],
            "_index": 203
        },
        {
            "title": "Mathematical Foundations of Neural Tangents and Infinite-Width Networks",
            "authors": [
                "Rachana Mysore",
                "Preksha Girish",
                "Kavitha Jayaram",
                "Shrey Kumar",
                "Preksha Girish",
                "Shravan Sanjeev Bagal",
                "Kavitha Jayaram",
                "Shreya Aravind Shastry"
            ],
            "arxiv_id": "2512.08264v1",
            "summary": "We investigate the mathematical foundations of neural networks in the infinite-width regime through the Neural Tangent Kernel (NTK). We propose the NTK-Eigenvalue-Controlled Residual Network (NTK-ECRN), an architecture integrating Fourier feature embeddings, residual connections with layerwise scaling, and stochastic depth to enable rigorous analysis of kernel evolution during training. Our theoretical contributions include deriving bounds on NTK dynamics, characterizing eigenvalue evolution, and linking spectral properties to generalization and optimization stability. Empirical results on synthetic and benchmark datasets validate the predicted kernel behavior and demonstrate improved training stability and generalization. This work provides a comprehensive framework bridging infinite-width theory and practical deep-learning architectures.",
            "headline_zh": "提出NTK-ECRN架构以分析无限宽度神经网络中的核演化",
            "intro_zh": [
                "研究无限宽度神经网络中神经正切核的数学基础",
                "提出NTK-ECRN架构，集成傅里叶特征嵌入和残差连接",
                "理论推导NTK动态边界，实验验证训练稳定性和泛化提升"
            ],
            "tags_zh": [
                "神经正切核",
                "无限宽度网络",
                "核演化分析",
                "训练稳定性",
                "泛化理论"
            ],
            "_index": 204
        },
        {
            "title": "RLCNet: An end-to-end deep learning framework for simultaneous online calibration of LiDAR, RADAR, and Camera",
            "authors": [
                "Hafeez Husain Cholakkal",
                "Stefano Arrigoni",
                "Francesco Braghin"
            ],
            "arxiv_id": "2512.08262v1",
            "summary": "Accurate extrinsic calibration of LiDAR, RADAR, and camera sensors is essential for reliable perception in autonomous vehicles. Still, it remains challenging due to factors such as mechanical vibrations and cumulative sensor drift in dynamic environments. This paper presents RLCNet, a novel end-to-end trainable deep learning framework for the simultaneous online calibration of these multimodal sensors. Validated on real-world datasets, RLCNet is designed for practical deployment and demonstrates robust performance under diverse conditions. To support real-time operation, an online calibration framework is introduced that incorporates a weighted moving average and outlier rejection, enabling dynamic adjustment of calibration parameters with reduced prediction noise and improved resilience to drift. An ablation study highlights the significance of architectural choices, while comparisons with existing methods demonstrate the superior accuracy and robustness of the proposed approach.",
            "headline_zh": "提出RLCNet端到端深度学习框架，用于自动驾驶中LiDAR、RADAR和相机的同步在线校准。",
            "intro_zh": [
                "核心问题：动态环境下传感器外参校准因机械振动和漂移而困难，影响自动驾驶感知可靠性。",
                "方法要点：设计端到端可训练框架，结合加权移动平均和异常值剔除，实现实时在线校准和参数动态调整。",
                "实验或效果：在真实数据集验证，展示优于现有方法的精度和鲁棒性，支持实际部署。"
            ],
            "tags_zh": [
                "多模态传感器校准",
                "在线校准",
                "深度学习框架",
                "自动驾驶感知",
                "端到端训练",
                "鲁棒性优化"
            ],
            "_index": 205
        },
        {
            "title": "Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes",
            "authors": [
                "Yibowen Zhao",
                "Yinan Zhang",
                "Zhixiang Su",
                "Lizhen Cui",
                "Chunyan Miao"
            ],
            "arxiv_id": "2512.08261v1",
            "summary": "Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has attracted significant research attention due to its potential to enhance patient awareness, facilitate early healthcare engagement, and improve healthcare system efficiency. However, existing approaches encounter critical challenges, including imbalanced disease distributions and a lack of interpretability, resulting in biased or unreliable predictions. To address these issues, we propose the Knowledge graph-enhanced, Prototype-aware, and Interpretable (KPI) framework. KPI systematically integrates structured and trusted medical knowledge into a unified disease knowledge graph, constructs clinically meaningful disease prototypes, and employs contrastive learning to enhance predictive accuracy, which is particularly important for long-tailed diseases. Additionally, KPI utilizes large language models (LLMs) to generate patient-specific, medically relevant explanations, thereby improving interpretability and reliability. Extensive experiments on real-world datasets demonstrate that KPI outperforms state-of-the-art methods in predictive accuracy and provides clinically valid explanations that closely align with patient narratives, highlighting its practical value for patient-centered healthcare delivery.",
            "headline_zh": "提出KPI框架以解决基于患者信息预测疾病时的数据不平衡和可解释性不足问题。",
            "intro_zh": [
                "核心问题：疾病分布不平衡和预测缺乏可解释性导致偏差或不可靠。",
                "方法要点：整合医学知识图谱、构建疾病原型、使用对比学习和LLM生成解释。",
                "实验或效果：在真实数据集上超越现有方法，提供临床有效解释，提升预测准确性。"
            ],
            "tags_zh": [
                "疾病预测",
                "知识图谱",
                "原型学习",
                "对比学习",
                "可解释性",
                "长尾分布"
            ],
            "_index": 206
        },
        {
            "title": "Geometric-Stochastic Multimodal Deep Learning for Predictive Modeling of SUDEP and Stroke Vulnerability",
            "authors": [
                "Preksha Girish",
                "Rachana Mysore",
                "Mahanthesha U",
                "Shrey Kumar",
                "Misbah Fatimah Annigeri",
                "Tanish Jain"
            ],
            "arxiv_id": "2512.08257v1",
            "summary": "Sudden Unexpected Death in Epilepsy (SUDEP) and acute ischemic stroke are life-threatening conditions involving complex interactions across cortical, brainstem, and autonomic systems. We present a unified geometric-stochastic multimodal deep learning framework that integrates EEG, ECG, respiration, SpO2, EMG, and fMRI signals to model SUDEP and stroke vulnerability. The approach combines Riemannian manifold embeddings, Lie-group invariant feature representations, fractional stochastic dynamics, Hamiltonian energy-flow modeling, and cross-modal attention mechanisms. Stroke propagation is modeled using fractional epidemic diffusion over structural brain graphs. Experiments on the MULTI-CLARID dataset demonstrate improved predictive accuracy and interpretable biomarkers derived from manifold curvature, fractional memory indices, attention entropy, and diffusion centrality. The proposed framework provides a mathematically principled foundation for early detection, risk stratification, and interpretable multimodal modeling in neural-autonomic disorders.",
            "headline_zh": "提出几何-随机多模态深度学习框架，用于预测SUDEP和卒中易感性。",
            "intro_zh": [
                "核心问题：SUDEP和急性缺血性卒中涉及皮质、脑干和自主神经系统的复杂交互，需要多模态建模。",
                "方法要点：结合黎曼流形嵌入、李群不变特征、分数随机动力学、哈密顿能量流建模和跨模态注意力机制。",
                "实验或效果：在MULTI-CLARID数据集上验证，提升预测准确性，并提取可解释的生物标志物。"
            ],
            "tags_zh": [
                "多模态深度学习",
                "几何-随机建模",
                "SUDEP预测",
                "卒中易感性",
                "黎曼流形",
                "分数随机动力学"
            ],
            "_index": 207
        },
        {
            "title": "Wavelet-Accelerated Physics-Informed Quantum Neural Network for Multiscale Partial Differential Equations",
            "authors": [
                "Deepak Gupta",
                "Himanshu Pandey",
                "Ratikanta Behera"
            ],
            "arxiv_id": "2512.08256v1",
            "summary": "This work proposes a wavelet-based physics-informed quantum neural network framework to efficiently address multiscale partial differential equations that involve sharp gradients, stiffness, rapid local variations, and highly oscillatory behavior. Traditional physics-informed neural networks (PINNs) have demonstrated substantial potential in solving differential equations, and their quantum counterparts, quantum-PINNs, exhibit enhanced representational capacity with fewer trainable parameters. However, both approaches face notable challenges in accurately solving multiscale features. Furthermore, their reliance on automatic differentiation for constructing loss functions introduces considerable computational overhead, resulting in longer training times. To overcome these challenges, we developed a wavelet-accelerated physics-informed quantum neural network that eliminates the need for automatic differentiation, significantly reducing computational complexity. The proposed framework incorporates the multiresolution property of wavelets within the quantum neural network architecture, thereby enhancing the network's ability to effectively capture both local and global features of multiscale problems. Numerical experiments demonstrate that our proposed method achieves superior accuracy while requiring less than five percent of the trainable parameters compared to classical wavelet-based PINNs, resulting in faster convergence. Moreover, it offers a speedup of three to five times compared to existing quantum PINNs, highlighting the potential of the proposed approach for efficiently solving challenging multiscale and oscillatory problems.",
            "headline_zh": "提出基于小波的物理信息量子神经网络框架，以高效求解多尺度偏微分方程",
            "intro_zh": [
                "传统物理信息神经网络及其量子版本在多尺度特征求解中面临精度挑战和计算开销大问题",
                "该方法结合小波多分辨率特性于量子神经网络，无需自动微分，降低计算复杂度",
                "数值实验显示，相比经典小波PINNs，参数减少超95%，比现有量子PINNs提速3-5倍"
            ],
            "tags_zh": [
                "小波加速",
                "物理信息量子神经网络",
                "多尺度偏微分方程",
                "计算复杂度降低",
                "参数效率提升"
            ],
            "_index": 208
        },
        {
            "title": "SFP: Real-World Scene Recovery Using Spatial and Frequency Priors",
            "authors": [
                "Yun Liu",
                "Tao Li",
                "Cosmin Ancuti",
                "Wenqi Ren",
                "Weisi Lin"
            ],
            "arxiv_id": "2512.08254v1",
            "summary": "Scene recovery serves as a critical task for various computer vision applications. Existing methods typically rely on a single prior, which is inherently insufficient to handle multiple degradations, or employ complex network architectures trained on synthetic data, which suffer from poor generalization for diverse real-world scenarios. In this paper, we propose Spatial and Frequency Priors (SFP) for real-world scene recovery. In the spatial domain, we observe that the inverse of the degraded image exhibits a projection along its spectral direction that resembles the scene transmission. Leveraging this spatial prior, the transmission map is estimated to recover the scene from scattering degradation. In the frequency domain, a mask is constructed for adaptive frequency enhancement, with two parameters estimated using our proposed novel priors. Specifically, one prior assumes that the mean intensity of the degraded image's direct current (DC) components across three channels in the frequency domain closely approximates that of each channel in the clear image. The second prior is based on the observation that, for clear images, the magnitude of low radial frequencies below 0.001 constitutes approximately 1% of the total spectrum. Finally, we design a weighted fusion strategy to integrate spatial-domain restoration, frequency-domain enhancement, and salient features from the input image, yielding the final recovered result. Extensive evaluations demonstrate the effectiveness and superiority of our proposed SFP for scene recovery under various degradation conditions.",
            "headline_zh": "提出空间与频率先验方法以解决真实场景恢复中的多重退化问题",
            "intro_zh": [
                "核心问题：现有方法依赖单一先验或合成数据训练，难以泛化处理真实场景的多重退化。",
                "方法要点：利用空间先验估计透射图恢复散射退化，基于频率先验构建自适应增强掩码。",
                "实验或效果：通过加权融合策略整合空间恢复、频率增强和显著特征，在各种退化条件下表现优越。"
            ],
            "tags_zh": [
                "场景恢复",
                "空间先验",
                "频率先验",
                "真实世界图像",
                "退化处理",
                "加权融合"
            ],
            "_index": 209
        },
        {
            "title": "Query-aware Hub Prototype Learning for Few-Shot 3D Point Cloud Semantic Segmentation",
            "authors": [
                "YiLin Zhou",
                "Lili Wei",
                "Zheming Xu",
                "Ziyi Chen",
                "Congyan Lang"
            ],
            "arxiv_id": "2512.08253v1",
            "summary": "Few-shot 3D point cloud semantic segmentation (FS-3DSeg) aims to segment novel classes with only a few labeled samples. However, existing metric-based prototype learning methods generate prototypes solely from the support set, without considering their relevance to query data. This often results in prototype bias, where prototypes overfit support-specific characteristics and fail to generalize to the query distribution, especially in the presence of distribution shifts, which leads to degraded segmentation performance. To address this issue, we propose a novel Query-aware Hub Prototype (QHP) learning method that explicitly models semantic correlations between support and query sets. Specifically, we propose a Hub Prototype Generation (HPG) module that constructs a bipartite graph connecting query and support points, identifies frequently linked support hubs, and generates query-relevant prototypes that better capture cross-set semantics. To further mitigate the influence of bad hubs and ambiguous prototypes near class boundaries, we introduce a Prototype Distribution Optimization (PDO) module, which employs a purity-reweighted contrastive loss to refine prototype representations by pulling bad hubs and outlier prototypes closer to their corresponding class centers. Extensive experiments on S3DIS and ScanNet demonstrate that QHP achieves substantial performance gains over state-of-the-art methods, effectively narrowing the semantic gap between prototypes and query sets in FS-3DSeg.",
            "headline_zh": "提出查询感知枢纽原型学习方法，以解决少样本三维点云语义分割中的原型偏差问题。",
            "intro_zh": [
                "核心问题：现有基于度量的原型学习方法仅从支持集生成原型，忽略查询数据相关性，导致原型偏差和性能下降。",
                "方法要点：通过枢纽原型生成模块构建二分图识别支持枢纽，生成查询相关原型；原型分布优化模块使用纯度加权对比损失优化原型表示。",
                "实验或效果：在S3DIS和ScanNet数据集上实验显示，QHP方法显著超越现有方法，有效缩小原型与查询集间的语义差距。"
            ],
            "tags_zh": [
                "少样本学习",
                "三维点云语义分割",
                "原型学习",
                "查询感知",
                "枢纽原型",
                "对比损失"
            ],
            "_index": 210
        },
        {
            "title": "Learning Spatiotemporal Tubes for Temporal Reach-Avoid-Stay Tasks using Physics-Informed Neural Networks",
            "authors": [
                "Ahan Basu",
                "Ratnangshu Das",
                "Pushpak Jagtap"
            ],
            "arxiv_id": "2512.08248v1",
            "summary": "This paper presents a Spatiotemporal Tube (STT)-based control framework for general control-affine MIMO nonlinear pure-feedback systems with unknown dynamics to satisfy prescribed time reach-avoid-stay tasks under external disturbances. The STT is defined as a time-varying ball, whose center and radius are jointly approximated by a Physics-Informed Neural Network (PINN). The constraints governing the STT are first formulated as loss functions of the PINN, and a training algorithm is proposed to minimize the overall violation. The PINN being trained on certain collocation points, we propose a Lipschitz-based validity condition to formally verify that the learned PINN satisfies the conditions over the continuous time horizon. Building on the learned STT representation, an approximation-free closed-form controller is defined to guarantee satisfaction of the T-RAS specification. Finally, the effectiveness and scalability of the framework are validated through two case studies involving a mobile robot and an aerial vehicle navigating through cluttered environments.",
            "headline_zh": "提出基于时空管的控制框架，利用物理信息神经网络满足未知非线性系统的时间到达-避障-停留任务。",
            "intro_zh": [
                "针对未知动态的控制仿射非线性系统，在外部扰动下满足时间到达-避障-停留任务。",
                "使用物理信息神经网络近似时空管的中心和半径，通过损失函数和训练算法最小化约束违反。",
                "通过移动机器人和飞行器案例验证框架的有效性和可扩展性。"
            ],
            "tags_zh": [
                "时空管控制",
                "物理信息神经网络",
                "非线性系统控制",
                "时间到达-避障-停留任务",
                "形式验证"
            ],
            "_index": 211
        },
        {
            "title": "Distilling Future Temporal Knowledge with Masked Feature Reconstruction for 3D Object Detection",
            "authors": [
                "Haowen Zheng",
                "Hu Zhu",
                "Lu Deng",
                "Weihao Gu",
                "Yang Yang",
                "Yanyan Liang"
            ],
            "arxiv_id": "2512.08247v1",
            "summary": "Camera-based temporal 3D object detection has shown impressive results in autonomous driving, with offline models improving accuracy by using future frames. Knowledge distillation (KD) can be an appealing framework for transferring rich information from offline models to online models. However, existing KD methods overlook future frames, as they mainly focus on spatial feature distillation under strict frame alignment or on temporal relational distillation, thereby making it challenging for online models to effectively learn future knowledge. To this end, we propose a sparse query-based approach, Future Temporal Knowledge Distillation (FTKD), which effectively transfers future frame knowledge from an offline teacher model to an online student model. Specifically, we present a future-aware feature reconstruction strategy to encourage the student model to capture future features without strict frame alignment. In addition, we further introduce future-guided logit distillation to leverage the teacher's stable foreground and background context. FTKD is applied to two high-performing 3D object detection baselines, achieving up to 1.3 mAP and 1.3 NDS gains on the nuScenes dataset, as well as the most accurate velocity estimation, without increasing inference cost.",
            "headline_zh": "提出未来时序知识蒸馏方法，通过掩码特征重建解决在线3D目标检测中未来帧知识迁移问题。",
            "intro_zh": [
                "核心问题：现有知识蒸馏方法忽视未来帧，难以让在线模型有效学习未来知识。",
                "方法要点：采用稀疏查询和未来感知特征重建策略，无需严格帧对齐即可迁移未来特征。",
                "实验或效果：在nuScenes数据集上提升mAP和NDS达1.3，实现最准确速度估计，推理成本不变。"
            ],
            "tags_zh": [
                "3D目标检测",
                "知识蒸馏",
                "时序建模",
                "自动驾驶",
                "特征重建"
            ],
            "_index": 212
        },
        {
            "title": "SPROCKET: Extending ROCKET to Distance-Based Time-Series Transformations With Prototypes",
            "authors": [
                "Nicholas Harner"
            ],
            "arxiv_id": "2512.08246v1",
            "summary": "Classical Time Series Classification algorithms are dominated by feature engineering strategies. One of the most prominent of these transforms is ROCKET, which achieves strong performance through random kernel features. We introduce SPROCKET (Selected Prototype Random Convolutional Kernel Transform), which implements a new feature engineering strategy based on prototypes. On a majority of the UCR and UEA Time Series Classification archives, SPROCKET achieves performance comparable to existing convolutional algorithms and the new MR-HY-SP ( MultiROCKET-HYDRA-SPROCKET) ensemble's average accuracy ranking exceeds HYDRA-MR, the previous best convolutional ensemble's performance. These experimental results demonstrate that prototype-based feature transformation can enhance both accuracy and robustness in time series classification.",
            "headline_zh": "提出SPROCKET，基于原型的特征变换以增强时间序列分类性能。",
            "intro_zh": [
                "核心问题：传统时间序列分类依赖特征工程，ROCKET等算法使用随机核特征。",
                "方法要点：SPROCKET引入基于原型的特征工程策略，扩展ROCKET的距离变换。",
                "实验或效果：在UCR和UEA数据集上性能可比现有卷积算法，MR-HY-SP集成排名超越HYDRA-MR。"
            ],
            "tags_zh": [
                "时间序列分类",
                "特征工程",
                "原型学习",
                "卷积核变换",
                "集成方法"
            ],
            "_index": 213
        },
        {
            "title": "Residual-SwinCA-Net: A Channel-Aware Integrated Residual CNN-Swin Transformer for Malignant Lesion Segmentation in BUSI",
            "authors": [
                "Saeeda Naz",
                "Saddam Hussain Khan"
            ],
            "arxiv_id": "2512.08243v1",
            "summary": "A novel deep hybrid Residual-SwinCA-Net segmentation framework is proposed in the study for addressing such challenges by extracting locally correlated and robust features, incorporating residual CNN modules. Furthermore, for learning global dependencies, Swin Transformer blocks are customized using internal residual pathways, which reinforce gradient stability, refine local patterns, and facilitate global feature fusion. Formerly, for enhancing tissue continuity, ultrasound noise suppressions, and accentuating fine structural transitions Laplacian-of-Gaussian regional operator is applied, and for maintaining the morphological integrity of malignant lesion contours, a boundary-oriented operator has been incorporated. Subsequently, a contraction strategy was applied stage-wise by progressively reducing features-map progressively for capturing scale invariance and enhancing the robustness of structural variability. In addition, each decoder level prior augmentation integrates a new Multi-Scale Channel Attention and Squeezing (MSCAS) module. The MSCAS selectively emphasizes encoder salient maps, retains discriminative global context, and complementary local structures with minimal computational cost while suppressing redundant activations. Finally, the Pixel-Attention module encodes class-relevant spatial cues by adaptively weighing malignant lesion pixels while suppressing background interference. The Residual-SwinCA-Net and existing CNNs/ViTs techniques have been implemented on the publicly available BUSI dataset. The proposed Residual-SwinCA-Net framework outperformed and achieved 99.29% mean accuracy, 98.74% IoU, and 0.9041 Dice for breast lesion segmentation. The proposed Residual-SwinCA-Net framework improves the BUSI lesion diagnostic performance and strengthens timely clinical decision-making.",
            "headline_zh": "提出Residual-SwinCA-Net用于乳腺超声图像恶性病灶分割，结合残差CNN与Swin Transformer提升特征提取能力。",
            "intro_zh": [
                "核心问题：乳腺超声图像分割面临噪声干扰、病灶形态多变和局部-全局特征融合挑战。",
                "方法要点：集成残差CNN模块提取局部特征，定制Swin Transformer块学习全局依赖，并引入MSCAS模块增强通道注意力。",
                "实验或效果：在BUSI数据集上实现99.29%平均准确率，优于现有CNNs/ViTs方法，提升临床诊断性能。"
            ],
            "tags_zh": [
                "医学图像分割",
                "残差网络",
                "Swin Transformer",
                "通道注意力",
                "乳腺超声",
                "病灶分割"
            ],
            "_index": 214
        },
        {
            "title": "Persistent Topological Structures and Cohomological Flows as a Mathematical Framework for Brain-Inspired Representation Learning",
            "authors": [
                "Preksha Girish",
                "Rachana Mysore",
                "Mahanthesha U",
                "Shrey Kumar",
                "Shipra Prashant"
            ],
            "arxiv_id": "2512.08241v1",
            "summary": "This paper presents a mathematically rigorous framework for brain-inspired representation learning founded on the interplay between persistent topological structures and cohomological flows. Neural computation is reformulated as the evolution of cochain maps over dynamic simplicial complexes, enabling representations that capture invariants across temporal, spatial, and functional brain states. The proposed architecture integrates algebraic topology with differential geometry to construct cohomological operators that generalize gradient-based learning within a homological landscape. Synthetic data with controlled topological signatures and real neural datasets are jointly analyzed using persistent homology, sheaf cohomology, and spectral Laplacians to quantify stability, continuity, and structural preservation. Empirical results demonstrate that the model achieves superior manifold consistency and noise resilience compared to graph neural and manifold-based deep architectures, establishing a coherent mathematical foundation for topology-driven representation learning.",
            "headline_zh": "提出基于持久拓扑结构与上同调流的数学框架，用于脑启发表示学习",
            "intro_zh": [
                "核心问题：如何构建数学严谨的脑启发表示学习框架，捕捉大脑状态的时空与功能不变量",
                "方法要点：将神经计算重构为动态单纯复形上的上链映射演化，结合代数拓扑与微分几何",
                "实验或效果：在合成与真实神经数据上验证模型在流形一致性和噪声鲁棒性方面优于图神经网络"
            ],
            "tags_zh": [
                "持久拓扑结构",
                "上同调流",
                "脑启发表示学习",
                "代数拓扑",
                "动态单纯复形",
                "噪声鲁棒性"
            ],
            "_index": 215
        },
        {
            "title": "HybridToken-VLM: Hybrid Token Compression for Vision-Language Models",
            "authors": [
                "Jusheng Zhang",
                "Xiaoyang Guo",
                "Kaitong Cai",
                "Qinhan Lv",
                "Yijia Fan",
                "Wenhao Chai",
                "Jian Wang",
                "Keze Wang"
            ],
            "arxiv_id": "2512.08240v1",
            "summary": "Vision-language models (VLMs) have transformed multimodal reasoning, but feeding hundreds of visual patch tokens into LLMs incurs quadratic computational costs, straining memory and context windows. Traditional approaches face a trade-off: continuous compression dilutes high-level semantics such as object identities, while discrete quantization loses fine-grained details such as textures. We introduce HTC-VLM, a hybrid framework that disentangles semantics and appearance through dual channels, i.e., a continuous pathway for fine-grained details via ViT patches and a discrete pathway for symbolic anchors using MGVQ quantization projected to four tokens. These are fused into a 580-token hybrid sequence and compressed into a single voco token via a disentanglement attention mask and bottleneck, ensuring efficient and grounded representations. HTC-VLM achieves an average performance retention of 87.2 percent across seven benchmarks (GQA, VQAv2, MMBench, MME, POPE, SEED-Bench, ScienceQA-Image), outperforming the leading continuous baseline at 81.0 percent with a 580-to-1 compression ratio. Attention analyses show that the compressed token prioritizes the discrete anchor, validating its semantic guidance. Our work demonstrates that a minimalist hybrid design can resolve the efficiency-fidelity dilemma and advance scalable VLMs.",
            "headline_zh": "提出混合令牌压缩框架HTC-VLM，通过双通道解耦语义与外观，解决视觉语言模型的计算效率与表示保真度困境。",
            "intro_zh": [
                "视觉语言模型中大量视觉补丁令牌导致二次计算成本，传统连续压缩与离散量化方法各有缺陷。",
                "采用双通道混合设计：连续路径保留细粒度细节，离散路径通过MGVQ量化生成符号锚点，融合后压缩为单一令牌。",
                "在七个基准测试中平均性能保持87.2%，以580:1压缩比优于连续基线，注意力分析验证语义引导有效性。"
            ],
            "tags_zh": [
                "视觉语言模型",
                "令牌压缩",
                "混合表示",
                "计算效率",
                "多模态推理",
                "解耦注意力"
            ],
            "_index": 216
        },
        {
            "title": "SpeechQualityLLM: LLM-Based Multimodal Assessment of Speech Quality",
            "authors": [
                "Mahathir Monjur",
                "Shahriar Nirjon"
            ],
            "arxiv_id": "2512.08238v1",
            "summary": "Objective speech quality assessment is central to telephony, VoIP, and streaming systems, where large volumes of degraded audio must be monitored and optimized at scale. Classical metrics such as PESQ and POLQA approximate human mean opinion scores (MOS) but require carefully controlled conditions and expensive listening tests, while learning-based models such as NISQA regress MOS and multiple perceptual dimensions from waveforms or spectrograms, achieving high correlation with subjective ratings yet remaining rigid: they do not support interactive, natural-language queries and do not natively provide textual rationales. In this work, we introduce SpeechQualityLLM, a multimodal speech quality question-answering (QA) system that couples an audio encoder with a language model and is trained on the NISQA corpus using template-based question-answer pairs covering overall MOS and four perceptual dimensions (noisiness, coloration, discontinuity, and loudness) in both single-ended (degraded only) and double-ended (degraded plus clean reference) setups. Instead of directly regressing scores, our system is supervised to generate textual answers from which numeric predictions are parsed and evaluated with standard regression and ranking metrics; on held-out NISQA clips, the double-ended model attains a MOS mean absolute error (MAE) of 0.41 with Pearson correlation of 0.86, with competitive performance on dimension-wise tasks. Beyond these quantitative gains, it offers a flexible natural-language interface in which the language model acts as an audio quality expert: practitioners can query arbitrary aspects of degradations, prompt the model to emulate different listener profiles to capture human variability and produce diverse but plausible judgments rather than a single deterministic score, and thereby reduce reliance on large-scale crowdsourced tests and their monetary cost.",
            "headline_zh": "提出SpeechQualityLLM，基于LLM的多模态语音质量评估系统，支持自然语言查询以优化语音通信质量监控。",
            "intro_zh": [
                "核心问题：传统语音质量评估方法如PESQ和POLQA依赖受控条件和高成本主观测试，而学习模型如NISQA缺乏交互性和文本解释能力。",
                "方法要点：结合音频编码器和语言模型，在NISQA语料上训练，通过模板问答对覆盖MOS和四个感知维度，支持单端和双端设置。",
                "实验或效果：在NISQA测试集上，双端模型MOS平均绝对误差为0.41，皮尔逊相关系数0.86，并提供灵活的自然语言接口以模拟不同听众和生成多样化判断。"
            ],
            "tags_zh": [
                "语音质量评估",
                "多模态学习",
                "语言模型",
                "自然语言接口",
                "主观评分预测"
            ],
            "_index": 217
        },
        {
            "title": "FastBEV++: Fast by Algorithm, Deployable by Design",
            "authors": [
                "Yuanpeng Chen",
                "Hui Song",
                "Wei Tao",
                "ShanHui Mo",
                "Shuang Zhang",
                "Xiao Hua",
                "TianKun Zhao"
            ],
            "arxiv_id": "2512.08237v1",
            "summary": "The advancement of camera-only Bird's-Eye-View(BEV) perception is currently impeded by a fundamental tension between state-of-the-art performance and on-vehicle deployment tractability. This bottleneck stems from a deep-rooted dependency on computationally prohibitive view transformations and bespoke, platform-specific kernels. This paper introduces FastBEV++, a framework engineered to reconcile this tension, demonstrating that high performance and deployment efficiency can be achieved in unison via two guiding principles: Fast by Algorithm and Deployable by Design. We realize the \"Deployable by Design\" principle through a novel view transformation paradigm that decomposes the monolithic projection into a standard Index-Gather-Reshape pipeline. Enabled by a deterministic pre-sorting strategy, this transformation is executed entirely with elementary, operator native primitives (e.g Gather, Matrix Multiplication), which eliminates the need for specialized CUDA kernels and ensures fully TensorRT-native portability. Concurrently, our framework is \"Fast by Algorithm\", leveraging this decomposed structure to seamlessly integrate an end-to-end, depth-aware fusion mechanism. This jointly learned depth modulation, further bolstered by temporal aggregation and robust data augmentation, significantly enhances the geometric fidelity of the BEV representation.Empirical validation on the nuScenes benchmark corroborates the efficacy of our approach. FastBEV++ establishes a new state-of-the-art 0.359 NDS while maintaining exceptional real-time performance, exceeding 134 FPS on automotive-grade hardware (e.g Tesla T4). By offering a solution that is free of custom plugins yet highly accurate, FastBEV++ presents a mature and scalable design philosophy for production autonomous systems. The code is released at: https://github.com/ymlab/advanced-fastbev",
            "headline_zh": "提出FastBEV++框架，通过算法优化与设计可部署性解决相机BEV感知的性能与部署矛盾。",
            "intro_zh": [
                "核心问题：相机BEV感知依赖计算密集的视图变换和定制内核，导致性能与部署效率冲突。",
                "方法要点：采用分解视图变换为标准索引-聚集-重塑流程，结合深度感知融合，提升几何保真度。",
                "实验或效果：在nuScenes基准上达到0.359 NDS，Tesla T4硬件上超过134 FPS，实现高精度与实时性。"
            ],
            "tags_zh": [
                "鸟瞰图感知",
                "视图变换",
                "实时部署",
                "深度融合",
                "自动驾驶系统"
            ],
            "_index": 218
        },
        {
            "title": "Semantic-Metric Bayesian Risk Fields: Learning Robot Safety from Human Videos with a VLM Prior",
            "authors": [
                "Timothy Chen",
                "Marcus Dominguez-Kuhne",
                "Aiden Swann",
                "Xu Liu",
                "Mac Schwager"
            ],
            "arxiv_id": "2512.08233v1",
            "summary": "Humans interpret safety not as a binary signal but as a continuous, context- and spatially-dependent notion of risk. While risk is subjective, humans form rational mental models that guide action selection in dynamic environments. This work proposes a framework for extracting implicit human risk models by introducing a novel, semantically-conditioned and spatially-varying parametrization of risk, supervised directly from safe human demonstration videos and VLM common sense. Notably, we define risk through a Bayesian formulation. The prior is furnished by a pretrained vision-language model. In order to encourage the risk estimate to be more human aligned, a likelihood function modulates the prior to produce a relative metric of risk. Specifically, the likelihood is a learned ViT that maps pretrained features, to pixel-aligned risk values. Our pipeline ingests RGB images and a query object string, producing pixel-dense risk images. These images that can then be used as value-predictors in robot planning tasks or be projected into 3D for use in conventional trajectory optimization to produce human-like motion. This learned mapping enables generalization to novel objects and contexts, and has the potential to scale to much larger training datasets. In particular, the Bayesian framework that is introduced enables fast adaptation of our model to additional observations or common sense rules. We demonstrate that our proposed framework produces contextual risk that aligns with human preferences. Additionally, we illustrate several downstream applications of the model; as a value learner for visuomotor planners or in conjunction with a classical trajectory optimization algorithm. Our results suggest that our framework is a significant step toward enabling autonomous systems to internalize human-like risk. Code and results can be found at https://riskbayesian.github.io/bayesian_risk/.",
            "headline_zh": "提出语义度量贝叶斯风险场框架，从人类视频中学习机器人安全风险",
            "intro_zh": [
                "核心问题：人类安全风险是连续、上下文和空间依赖的，需从视频中提取隐式风险模型",
                "方法要点：基于贝叶斯框架，结合VLM先验和ViT似然，从RGB图像和查询对象生成像素级风险图",
                "实验或效果：模型能泛化到新对象和上下文，在机器人规划任务中产生类人运动，对齐人类偏好"
            ],
            "tags_zh": [
                "机器人安全",
                "贝叶斯风险建模",
                "视觉语言模型",
                "像素级风险估计",
                "轨迹优化",
                "人类视频学习"
            ],
            "_index": 219
        },
        {
            "title": "Empowerment Gain and Causal Model Construction: Children and adults are sensitive to controllability and variability in their causal interventions",
            "authors": [
                "Eunice Yiu",
                "Kelsey Allen",
                "Shiry Ginosar",
                "Alison Gopnik"
            ],
            "arxiv_id": "2512.08230v1",
            "summary": "Learning about the causal structure of the world is a fundamental problem for human cognition. Causal models and especially causal learning have proved to be difficult for large pretrained models using standard techniques of deep learning. In contrast, cognitive scientists have applied advances in our formal understanding of causation in computer science, particularly within the Causal Bayes Net formalism, to understand human causal learning. In the very different tradition of reinforcement learning, researchers have described an intrinsic reward signal called \"empowerment\" which maximizes mutual information between actions and their outcomes. \"Empowerment\" may be an important bridge between classical Bayesian causal learning and reinforcement learning and may help to characterize causal learning in humans and enable it in machines. If an agent learns an accurate causal world model, they will necessarily increase their empowerment, and increasing empowerment will lead to a more accurate causal world model. Empowerment may also explain distinctive features of childrens causal learning, as well as providing a more tractable computational account of how that learning is possible. In an empirical study, we systematically test how children and adults use cues to empowerment to infer causal relations, and design effective causal interventions.",
            "headline_zh": "提出赋能增益作为因果学习桥梁，通过可控性和变异性线索测试儿童与成人的因果推断。",
            "intro_zh": [
                "核心问题：人类如何学习因果结构，传统深度学习模型在此任务上表现困难。",
                "方法要点：结合因果贝叶斯网络与强化学习中的赋能概念，作为因果学习的计算框架。",
                "实验或效果：实证研究儿童和成人如何利用可控性和变异性线索进行因果推断和干预设计。"
            ],
            "tags_zh": [
                "因果学习",
                "赋能增益",
                "因果贝叶斯网络",
                "强化学习",
                "人类认知",
                "干预设计"
            ],
            "_index": 220
        },
        {
            "title": "Geometry-Aware Sparse Depth Sampling for High-Fidelity RGB-D Depth Completion in Robotic Systems",
            "authors": [
                "Tony Salloom",
                "Dandi Zhou",
                "Xinhai Sun"
            ],
            "arxiv_id": "2512.08229v1",
            "summary": "Accurate three-dimensional perception is essential for modern industrial robotic systems that perform manipulation, inspection, and navigation tasks. RGB-D and stereo vision sensors are widely used for this purpose, but the depth maps they produce are often noisy, incomplete, or biased due to sensor limitations and environmental conditions. Depth completion methods aim to generate dense, reliable depth maps from RGB images and sparse depth input. However, a key limitation in current depth completion pipelines is the unrealistic generation of sparse depth: sparse pixels are typically selected uniformly at random from dense ground-truth depth, ignoring the fact that real sensors exhibit geometry-dependent and spatially nonuniform reliability. In this work, we propose a normal-guided sparse depth sampling strategy that leverages PCA-based surface normal estimation on the RGB-D point cloud to compute a per-pixel depth reliability measure. The sparse depth samples are then drawn according to this reliability distribution. We integrate this sampling method with the Marigold-DC diffusion-based depth completion model and evaluate it on NYU Depth v2 using the standard metrics. Experiments show that our geometry-aware sparse depth improves accuracy, reduces artifacts near edges and discontinuities, and produces more realistic training conditions that better reflect real sensor behavior.",
            "headline_zh": "提出基于法线引导的稀疏深度采样策略，以提升机器人系统中RGB-D深度补全的精度与真实性。",
            "intro_zh": [
                "核心问题：现有深度补全方法中稀疏深度采样忽略传感器几何依赖性和空间非均匀可靠性，导致训练条件不真实。",
                "方法要点：利用RGB-D点云的PCA法线估计计算像素级深度可靠性，并据此采样稀疏深度，集成到扩散模型Marigold-DC中。",
                "实验或效果：在NYU Depth v2上评估，几何感知采样提高精度、减少边缘伪影，并模拟更真实的传感器行为。"
            ],
            "tags_zh": [
                "深度补全",
                "稀疏深度采样",
                "法线估计",
                "机器人视觉",
                "RGB-D感知",
                "扩散模型"
            ],
            "_index": 221
        },
        {
            "title": "MM-CoT:A Benchmark for Probing Visual Chain-of-Thought Reasoning in Multimodal Models",
            "authors": [
                "Jusheng Zhang",
                "Kaitong Cai",
                "Xiaoyang Guo",
                "Sidi Liu",
                "Qinhan Lv",
                "Ruiqi Chen",
                "Jing Yang",
                "Yijia Fan",
                "Xiaofei Sun",
                "Jian Wang",
                "Ziliang Chen",
                "Liang Lin",
                "Keze Wang"
            ],
            "arxiv_id": "2512.08228v1",
            "summary": "The ability to perform Chain-of-Thought (CoT) reasoning marks a major milestone for multimodal models (MMs), enabling them to solve complex visual reasoning problems. Yet a critical question remains: is such reasoning genuinely grounded in visual evidence and logically coherent? Existing benchmarks emphasize generation but neglect verification, i.e., the capacity to assess whether a reasoning chain is both visually consistent and logically valid. To fill this gap, we introduce MM-CoT, a diagnostic benchmark specifically designed to probe the visual grounding and logical coherence of CoT reasoning in MMs. Instead of generating free-form explanations, models must select the sole event chain that satisfies two orthogonal constraints: (i) visual consistency, ensuring all steps are anchored in observable evidence, and (ii) logical coherence, ensuring causal and commonsense validity. Adversarial distractors are engineered to violate one of these constraints, exposing distinct reasoning failures. We evaluate leading vision-language models on MM-CoT and find that even the most advanced systems struggle, revealing a sharp discrepancy between generative fluency and true reasoning fidelity. MM-CoT shows low correlation with existing benchmarks, confirming that it measures a unique combination of visual grounding and logical reasoning. This benchmark provides a foundation for developing future models that reason not just plausibly, but faithfully and coherently within the visual world.",
            "headline_zh": "提出MM-CoT基准以评估多模态模型视觉思维链推理的视觉一致性与逻辑连贯性",
            "intro_zh": [
                "核心问题：现有基准忽视验证，无法评估多模态模型思维链推理是否基于视觉证据且逻辑连贯",
                "方法要点：设计诊断基准，要求模型选择满足视觉一致性和逻辑连贯性约束的唯一事件链",
                "实验或效果：评估领先模型发现其表现不佳，揭示生成流畅性与真实推理保真度间的差距"
            ],
            "tags_zh": [
                "多模态模型",
                "思维链推理",
                "视觉一致性",
                "逻辑连贯性",
                "诊断基准",
                "视觉语言模型"
            ],
            "_index": 222
        },
        {
            "title": "New VVC profiles targeting Feature Coding for Machines",
            "authors": [
                "Md Eimran Hossain Eimon",
                "Ashan Perera",
                "Juan Merlos",
                "Velibor Adzic",
                "Hari Kalva"
            ],
            "arxiv_id": "2512.08227v1",
            "summary": "Modern video codecs have been extensively optimized to preserve perceptual quality, leveraging models of the human visual system. However, in split inference systems-where intermediate features from neural network are transmitted instead of pixel data-these assumptions no longer apply. Intermediate features are abstract, sparse, and task-specific, making perceptual fidelity irrelevant. In this paper, we investigate the use of Versatile Video Coding (VVC) for compressing such features under the MPEG-AI Feature Coding for Machines (FCM) standard. We perform a tool-level analysis to understand the impact of individual coding components on compression efficiency and downstream vision task accuracy. Based on these insights, we propose three lightweight essential VVC profiles-Fast, Faster, and Fastest. The Fast profile provides 2.96% BD-Rate gain while reducing encoding time by 21.8%. Faster achieves a 1.85% BD-Rate gain with a 51.5% speedup. Fastest reduces encoding time by 95.6% with only a 1.71% loss in BD-Rate.",
            "headline_zh": "提出三种轻量级VVC配置以优化面向机器的特征编码，提升压缩效率与编码速度。",
            "intro_zh": [
                "核心问题：传统视频编码基于人类视觉优化，不适用于神经网络中间特征的抽象、稀疏和任务特定性。",
                "方法要点：在MPEG-AI FCM标准下，分析VVC工具对特征压缩效率和下游任务准确性的影响，设计Fast、Faster、Fastest配置。",
                "实验或效果：Fast配置提升2.96% BD-Rate并减少21.8%编码时间，Fastest配置减少95.6%编码时间仅损失1.71% BD-Rate。"
            ],
            "tags_zh": [
                "特征编码",
                "VVC配置",
                "压缩效率",
                "编码速度",
                "MPEG-AI FCM",
                "下游任务准确性"
            ],
            "_index": 223
        },
        {
            "title": "SOP^2: Transfer Learning with Scene-Oriented Prompt Pool on 3D Object Detection",
            "authors": [
                "Ching-Hung Cheng",
                "Hsiu-Fu Wu",
                "Bing-Chen Wu",
                "Khanh-Phong Bui",
                "Van-Tin Luu",
                "Ching-Chun Huang"
            ],
            "arxiv_id": "2512.08223v1",
            "summary": "With the rise of Large Language Models (LLMs) such as GPT-3, these models exhibit strong generalization capabilities. Through transfer learning techniques such as fine-tuning and prompt tuning, they can be adapted to various downstream tasks with minimal parameter adjustments. This approach is particularly common in the field of Natural Language Processing (NLP). This paper aims to explore the effectiveness of common prompt tuning methods in 3D object detection. We investigate whether a model trained on the large-scale Waymo dataset can serve as a foundation model and adapt to other scenarios within the 3D object detection field. This paper sequentially examines the impact of prompt tokens and prompt generators, and further proposes a Scene-Oriented Prompt Pool (\\textbf{SOP$^2$}). We demonstrate the effectiveness of prompt pools in 3D object detection, with the goal of inspiring future researchers to delve deeper into the potential of prompts in the 3D field.",
            "headline_zh": "提出场景导向提示池以提升3D目标检测的迁移学习效果",
            "intro_zh": [
                "核心问题：探索提示调优在3D目标检测中的有效性，验证基础模型跨场景适应能力",
                "方法要点：研究提示令牌和提示生成器影响，并设计场景导向提示池（SOP^2）",
                "实验或效果：在Waymo数据集上验证提示池的有效性，旨在激发3D领域提示潜力研究"
            ],
            "tags_zh": [
                "3D目标检测",
                "迁移学习",
                "提示调优",
                "场景导向提示池",
                "基础模型"
            ],
            "_index": 224
        },
        {
            "title": "VisKnow: Constructing Visual Knowledge Base for Object Understanding",
            "authors": [
                "Ziwei Yao",
                "Qiyang Wan",
                "Ruiping Wang",
                "Xilin Chen"
            ],
            "arxiv_id": "2512.08221v1",
            "summary": "Understanding objects is fundamental to computer vision. Beyond object recognition that provides only a category label as typical output, in-depth object understanding represents a comprehensive perception of an object category, involving its components, appearance characteristics, inter-category relationships, contextual background knowledge, etc. Developing such capability requires sufficient multi-modal data, including visual annotations such as parts, attributes, and co-occurrences for specific tasks, as well as textual knowledge to support high-level tasks like reasoning and question answering. However, these data are generally task-oriented and not systematically organized enough to achieve the expected understanding of object categories. In response, we propose the Visual Knowledge Base that structures multi-modal object knowledge as graphs, and present a construction framework named VisKnow that extracts multi-modal, object-level knowledge for object understanding. This framework integrates enriched aligned text and image-source knowledge with region annotations at both object and part levels through a combination of expert design and large-scale model application. As a specific case study, we construct AnimalKB, a structured animal knowledge base covering 406 animal categories, which contains 22K textual knowledge triplets extracted from encyclopedic documents, 420K images, and corresponding region annotations. A series of experiments showcase how AnimalKB enhances object-level visual tasks such as zero-shot recognition and fine-grained VQA, and serves as challenging benchmarks for knowledge graph completion and part segmentation. Our findings highlight the potential of automatically constructing visual knowledge bases to advance visual understanding and its practical applications. The project page is available at https://vipl-vsu.github.io/VisKnow.",
            "headline_zh": "提出VisKnow框架以构建视觉知识库，支持深度物体理解任务。",
            "intro_zh": [
                "核心问题：现有多模态数据缺乏系统组织，难以实现全面的物体理解。",
                "方法要点：结合专家设计和大规模模型，从文本和图像中提取物体级知识并构建图结构。",
                "实验或效果：构建AnimalKB知识库，提升零样本识别和细粒度VQA等任务性能。"
            ],
            "tags_zh": [
                "视觉知识库",
                "物体理解",
                "多模态学习",
                "知识图谱",
                "零样本识别",
                "细粒度视觉问答"
            ],
            "_index": 225
        },
        {
            "title": "PR-CapsNet: Pseudo-Riemannian Capsule Network with Adaptive Curvature Routing for Graph Learning",
            "authors": [
                "Ye Qin",
                "Jingchao Wang",
                "Yang Shi",
                "Haiying Huang",
                "Junxu Li",
                "Weijian Liu",
                "Tinghui Chen",
                "Jinghui Qin"
            ],
            "arxiv_id": "2512.08218v1",
            "summary": "Capsule Networks (CapsNets) show exceptional graph representation capacity via dynamic routing and vectorized hierarchical representations, but they model the complex geometries of real\\-world graphs poorly by fixed\\-curvature space due to the inherent geodesical disconnectedness issues, leading to suboptimal performance. Recent works find that non\\-Euclidean pseudo\\-Riemannian manifolds provide specific inductive biases for embedding graph data, but how to leverage them to improve CapsNets is still underexplored. Here, we extend the Euclidean capsule routing into geodesically disconnected pseudo\\-Riemannian manifolds and derive a Pseudo\\-Riemannian Capsule Network (PR\\-CapsNet), which models data in pseudo\\-Riemannian manifolds of adaptive curvature, for graph representation learning. Specifically, PR\\-CapsNet enhances the CapsNet with Adaptive Pseudo\\-Riemannian Tangent Space Routing by utilizing pseudo\\-Riemannian geometry. Unlike single\\-curvature or subspace\\-partitioning methods, PR\\-CapsNet concurrently models hierarchical and cluster or cyclic graph structures via its versatile pseudo\\-Riemannian metric. It first deploys Pseudo\\-Riemannian Tangent Space Routing to decompose capsule states into spherical\\-temporal and Euclidean\\-spatial subspaces with diffeomorphic transformations. Then, an Adaptive Curvature Routing is developed to adaptively fuse features from different curvature spaces for complex graphs via a learnable curvature tensor with geometric attention from local manifold properties. Finally, a geometric properties\\-preserved Pseudo\\-Riemannian Capsule Classifier is developed to project capsule embeddings to tangent spaces and use curvature\\-weighted softmax for classification. Extensive experiments on node and graph classification benchmarks show PR\\-CapsNet outperforms SOTA models, validating PR\\-CapsNet's strong representation power for complex graph structures.",
            "headline_zh": "提出PR-CapsNet，通过自适应曲率伪黎曼流形改进胶囊网络，用于图表示学习。",
            "intro_zh": [
                "核心问题：胶囊网络在固定曲率空间中建模真实世界图的复杂几何结构不佳，导致性能次优。",
                "方法要点：扩展胶囊路由至伪黎曼流形，利用自适应曲率路由融合不同曲率空间特征，增强图表示能力。",
                "实验或效果：在节点和图分类基准测试中优于现有方法，验证了对复杂图结构的强表示能力。"
            ],
            "tags_zh": [
                "图表示学习",
                "胶囊网络",
                "伪黎曼流形",
                "自适应曲率路由",
                "图分类"
            ],
            "_index": 226
        },
        {
            "title": "Correction of Decoupled Weight Decay",
            "authors": [
                "Jason Chuan-Chih Chou"
            ],
            "arxiv_id": "2512.08217v1",
            "summary": "Decoupled weight decay, solely responsible for the performance advantage of AdamW over Adam, has long been set to proportional to learning rate $γ$ without questioning. Some researchers have recently challenged such assumption and argued that decoupled weight decay should be set $\\propto γ^2$ instead based on orthogonality arguments at steady state. To the contrary, we find that eliminating the contribution of the perpendicular component of the update to the weight norm leads to little change to the training dynamics. Instead, we derive that decoupled weight decay $\\propto γ^2$ results in stable weight norm based on the simple assumption that updates become independent of the weights at steady state, regardless of the nature of the optimizer. Based on the same assumption, we derive and empirically verify that the Total Update Contribution (TUC) of a minibatch under the Scion optimizer is better characterized by the momentum-dependent effective learning rate whose optimal value transfers and we show that decoupled weight decay $\\propto γ^2$ leads to stable weight and gradient norms and allows us to better control the training dynamics and improve the model performance.",
            "headline_zh": "提出基于稳态独立假设的权重衰减比例修正，以稳定训练动态并提升模型性能",
            "intro_zh": [
                "核心问题：解耦权重衰减长期设为与学习率γ成正比，但近期有研究主张应设为γ²比例",
                "方法要点：基于稳态下更新与权重独立的假设，推导出解耦权重衰减∝γ²可稳定权重范数",
                "实验或效果：经验验证该比例能稳定权重和梯度范数，更好控制训练动态并改善性能"
            ],
            "tags_zh": [
                "权重衰减",
                "优化器",
                "训练动态",
                "稳态分析",
                "AdamW",
                "Scion优化器"
            ],
            "_index": 227
        },
        {
            "title": "Tumor-anchored deep feature random forests for out-of-distribution detection in lung cancer segmentation",
            "authors": [
                "Aneesh Rangnekar",
                "Harini Veeraraghavan"
            ],
            "arxiv_id": "2512.08216v1",
            "summary": "Accurate segmentation of cancerous lesions from 3D computed tomography (CT) scans is essential for automated treatment planning and response assessment. However, even state-of-the-art models combining self-supervised learning (SSL) pretrained transformers with convolutional decoders are susceptible to out-of-distribution (OOD) inputs, generating confidently incorrect tumor segmentations, posing risks for safe clinical deployment. Existing logit-based methods suffer from task-specific model biases, while architectural enhancements to explicitly detect OOD increase parameters and computational costs. Hence, we introduce a plug-and-play and lightweight post-hoc random forests-based OOD detection framework called RF-Deep that leverages deep features with limited outlier exposure. RF-Deep enhances generalization to imaging variations by repurposing the hierarchical features from the pretrained-then-finetuned backbone encoder, providing task-relevant OOD detection by extracting the features from multiple regions of interest anchored to the predicted tumor segmentations. Hence, it scales to images of varying fields-of-view. We compared RF-Deep against existing OOD detection methods using 1,916 CT scans across near-OOD (pulmonary embolism, negative COVID-19) and far-OOD (kidney cancer, healthy pancreas) datasets. RF-Deep achieved AUROC > 93.50 for the challenging near-OOD datasets and near-perfect detection (AUROC > 99.00) for the far-OOD datasets, substantially outperforming logit-based and radiomics approaches. RF-Deep maintained similar performance consistency across networks of different depths and pretraining strategies, demonstrating its effectiveness as a lightweight, architecture-agnostic approach to enhance the reliability of tumor segmentation from CT volumes.",
            "headline_zh": "提出基于肿瘤锚定深度特征的随机森林框架RF-Deep，用于肺癌分割中的分布外检测。",
            "intro_zh": [
                "核心问题：现有肺癌分割模型易受分布外输入影响，产生错误分割，威胁临床安全部署。",
                "方法要点：利用预训练编码器的层次特征，通过肿瘤锚定区域提取特征，构建轻量级随机森林进行检测。",
                "实验或效果：在近分布外和远分布外数据集上，RF-Deep的AUROC分别超过93.50%和99.00%，优于基线方法。"
            ],
            "tags_zh": [
                "肺癌分割",
                "分布外检测",
                "深度特征",
                "随机森林",
                "计算机断层扫描",
                "医学影像分析"
            ],
            "_index": 228
        },
        {
            "title": "Blur2Sharp: Human Novel Pose and View Synthesis with Generative Prior Refinement",
            "authors": [
                "Chia-Hern Lai",
                "I-Hsuan Lo",
                "Yen-Ku Yeh",
                "Thanh-Nguyen Truong",
                "Ching-Chun Huang"
            ],
            "arxiv_id": "2512.08215v1",
            "summary": "The creation of lifelike human avatars capable of realistic pose variation and viewpoint flexibility remains a fundamental challenge in computer vision and graphics. Current approaches typically yield either geometrically inconsistent multi-view images or sacrifice photorealism, resulting in blurry outputs under diverse viewing angles and complex motions. To address these issues, we propose Blur2Sharp, a novel framework integrating 3D-aware neural rendering and diffusion models to generate sharp, geometrically consistent novel-view images from only a single reference view. Our method employs a dual-conditioning architecture: initially, a Human NeRF model generates geometrically coherent multi-view renderings for target poses, explicitly encoding 3D structural guidance. Subsequently, a diffusion model conditioned on these renderings refines the generated images, preserving fine-grained details and structural fidelity. We further enhance visual quality through hierarchical feature fusion, incorporating texture, normal, and semantic priors extracted from parametric SMPL models to simultaneously improve global coherence and local detail accuracy. Extensive experiments demonstrate that Blur2Sharp consistently surpasses state-of-the-art techniques in both novel pose and view generation tasks, particularly excelling under challenging scenarios involving loose clothing and occlusions.",
            "headline_zh": "提出Blur2Sharp框架，通过生成先验细化从单视图生成几何一致且清晰的新姿态和视角图像。",
            "intro_zh": [
                "核心问题：现有方法在生成人类新姿态和视角时，常导致几何不一致或模糊输出，尤其在复杂运动和视角下。",
                "方法要点：结合Human NeRF和扩散模型，先生成几何一致的多视图渲染，再通过条件扩散模型细化细节，并融合SMPL先验提升质量。",
                "实验或效果：在挑战性场景如宽松衣物和遮挡下，Blur2Sharp超越现有技术，生成更清晰、几何一致的新姿态和视角图像。"
            ],
            "tags_zh": [
                "人类姿态合成",
                "新视角生成",
                "神经渲染",
                "扩散模型",
                "几何一致性",
                "SMPL先验"
            ],
            "_index": 229
        },
        {
            "title": "MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones",
            "authors": [
                "Jiaxiang Geng",
                "Lunyu Zhao",
                "Yiyi Lu",
                "Bing Luo"
            ],
            "arxiv_id": "2512.08211v1",
            "summary": "Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training.",
            "headline_zh": "提出MobileFineTuner框架以在移动设备上实现端到端大语言模型微调",
            "intro_zh": [
                "核心问题：移动设备缺乏开源框架支持大语言模型微调，现有方法多基于模拟或非移动设备",
                "方法要点：引入参数分片、梯度累积和能量感知调度等系统级优化，支持全参数和参数高效微调",
                "实验或效果：在真实手机上微调GPT-2、Gemma 3和Qwen 2.5，验证优化有效性并确立框架可行性"
            ],
            "tags_zh": [
                "移动设备微调",
                "大语言模型",
                "参数高效微调",
                "系统优化",
                "隐私保护",
                "开源框架"
            ],
            "_index": 230
        },
        {
            "title": "High-Performance Dual-Arm Task and Motion Planning for Tabletop Rearrangement",
            "authors": [
                "Duo Zhang",
                "Junshan Huang",
                "Jingjin Yu"
            ],
            "arxiv_id": "2512.08206v1",
            "summary": "We propose Synchronous Dual-Arm Rearrange- ment Planner (SDAR), a task and motion planning (TAMP) framework for tabletop rearrangement, where two robot arms equipped with 2-finger grippers must work together in close proximity to rearrange objects whose start and goal config- urations are strongly entangled. To tackle such challenges, SDAR tightly knit together its dependency-driven task planner (SDAR-T) and synchronous dual-arm motion planner (SDAR- M), to intelligently sift through a large number of possible task and motion plans. Specifically, SDAR-T applies a simple yet effective strategy to decompose the global object dependency graph induced by the rearrangement task, to produce more optimal dual-arm task plans than solutions derived from optimal task plans for a single arm. Leveraging state-of-the-art GPU SIMD-based motion planning tools, SDAR-M employs a layered motion planning strategy to sift through many task plans for the best synchronous dual-arm motion plan while ensuring high levels of success rate. Comprehensive evaluation demonstrates that SDAR delivers a 100% success rate in solving complex, non-monotone, long-horizon tabletop rearrangement tasks with solution quality far exceeding the previous state- of-the-art. Experiments on two UR-5e arms further confirm SDAR directly and reliably transfers to robot hardware.",
            "headline_zh": "提出SDAR框架以解决双臂协同桌面重排任务中的强纠缠对象规划问题",
            "intro_zh": [
                "核心问题：双臂机器人在桌面重排中处理起始与目标配置强纠缠对象的任务与运动规划挑战",
                "方法要点：SDAR结合依赖驱动任务规划与同步双臂运动规划，通过分解全局依赖图优化任务计划",
                "实验或效果：在复杂非单调长视距任务中实现100%成功率，解决方案质量远超先前最优方法"
            ],
            "tags_zh": [
                "任务与运动规划",
                "双臂机器人",
                "桌面重排",
                "同步规划",
                "GPU加速运动规划"
            ],
            "_index": 231
        },
        {
            "title": "Animal Re-Identification on Microcontrollers",
            "authors": [
                "Yubo Chen",
                "Di Zhao",
                "Yun Sing Koh",
                "Talia Xu"
            ],
            "arxiv_id": "2512.08198v1",
            "summary": "Camera-based animal re-identification (Animal Re-ID) can support wildlife monitoring and precision livestock management in large outdoor environments with limited wireless connectivity. In these settings, inference must run directly on collar tags or low-power edge nodes built around microcontrollers (MCUs), yet most Animal Re-ID models are designed for workstations or servers and are too large for devices with small memory and low-resolution inputs. We propose an on-device framework. First, we characterise the gap between state-of-the-art Animal Re-ID models and MCU-class hardware, showing that straightforward knowledge distillation from large teachers offers limited benefit once memory and input resolution are constrained. Second, guided by this analysis, we design a high-accuracy Animal Re-ID architecture by systematically scaling a CNN-based MobileNetV2 backbone for low-resolution inputs. Third, we evaluate the framework with a real-world dataset and introduce a data-efficient fine-tuning strategy to enable fast adaptation with just three images per animal identity at a new site. Across six public Animal Re-ID datasets, our compact model achieves competitive retrieval accuracy while reducing model size by over two orders of magnitude. On a self-collected cattle dataset, the deployed model performs fully on-device inference with only a small accuracy drop and unchanged Top-1 accuracy relative to its cluster version. We demonstrate that practical, adaptable Animal Re-ID is achievable on MCU-class devices, paving the way for scalable deployment in real field environments.",
            "headline_zh": "提出基于微控制器的动物重识别框架，实现低功耗边缘设备上的高效部署",
            "intro_zh": [
                "核心问题：现有动物重识别模型在微控制器上因内存小和输入分辨率低而难以部署",
                "方法要点：通过缩放MobileNetV2骨干网络，设计适应低分辨率输入的高精度架构",
                "实验或效果：在六个公共数据集上，模型尺寸减少两个数量级，保持竞争性检索准确率"
            ],
            "tags_zh": [
                "动物重识别",
                "微控制器部署",
                "低分辨率输入",
                "知识蒸馏",
                "边缘计算",
                "数据高效微调"
            ],
            "_index": 232
        },
        {
            "title": "ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access",
            "authors": [
                "Jiwoo Park",
                "Ruoqi Liu",
                "Avani Jagdale",
                "Andrew Srisuwananukorn",
                "Jing Zhao",
                "Lang Li",
                "Ping Zhang",
                "Sachin Kumar"
            ],
            "arxiv_id": "2512.08193v1",
            "summary": "We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.",
            "headline_zh": "提出ClinicalTrialsHub平台，整合临床试验注册数据与文献信息以提升可访问性。",
            "intro_zh": [
                "核心问题：临床试验数据分散于注册库与文献，导致信息获取不全面。",
                "方法要点：利用大语言模型自动从PubMed文章提取结构化信息，增强搜索与问答功能。",
                "实验或效果：相比仅用ClinicalTrials.gov，结构化数据访问量增加83.8%，用户研究验证实用性。"
            ],
            "tags_zh": [
                "临床试验整合",
                "大语言模型应用",
                "信息提取",
                "结构化数据",
                "问答系统",
                "医学证据平台"
            ],
            "_index": 233
        },
        {
            "title": "Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model",
            "authors": [
                "Wenjiang Xu",
                "Cindy Wang",
                "Rui Fang",
                "Mingkang Zhang",
                "Lusong Li",
                "Jing Xu",
                "Jiayuan Gu",
                "Zecui Zeng",
                "Rui Chen"
            ],
            "arxiv_id": "2512.08188v1",
            "summary": "World models have emerged as a pivotal component in robot manipulation planning, enabling agents to predict future environmental states and reason about the consequences of actions before execution. While video-generation models are increasingly adopted, they often lack rigorous physical grounding, leading to hallucinations and a failure to maintain consistency in long-horizon physical constraints. To address these limitations, we propose Embodied Tree of Thoughts (EToT), a novel Real2Sim2Real planning framework that leverages a physics-based interactive digital twin as an embodied world model. EToT formulates manipulation planning as a tree search expanded through two synergistic mechanisms: (1) Priori Branching, which generates diverse candidate execution paths based on semantic and spatial analysis; and (2) Reflective Branching, which utilizes VLMs to diagnose execution failures within the simulator and iteratively refine the planning tree with corrective actions. By grounding high-level reasoning in a physics simulator, our framework ensures that generated plans adhere to rigid-body dynamics and collision constraints. We validate EToT on a suite of short- and long-horizon manipulation tasks, where it consistently outperforms baselines by effectively predicting physical dynamics and adapting to potential failures. Website at https://embodied-tree-of-thoughts.github.io .",
            "headline_zh": "提出Embodied Tree of Thoughts框架，利用物理数字孪生解决机器人操作规划中的幻觉与约束一致性问题。",
            "intro_zh": [
                "问题：视频生成模型在机器人操作规划中缺乏物理基础，导致幻觉和长时程物理约束不一致。",
                "方法：结合先验分支和反思分支的树搜索，通过物理模拟器实现Real2Sim2Real规划。",
                "效果：在短长时程任务中优于基线，有效预测物理动态并适应失败。"
            ],
            "tags_zh": [
                "机器人操作规划",
                "物理世界模型",
                "数字孪生",
                "树搜索",
                "Real2Sim2Real框架",
                "视觉语言模型"
            ],
            "_index": 234
        },
        {
            "title": "Ground Slow, Move Fast: A Dual-System Foundation Model for Generalizable Vision-and-Language Navigation",
            "authors": [
                "Meng Wei",
                "Chenyang Wan",
                "Jiaqi Peng",
                "Xiqian Yu",
                "Yuqiang Yang",
                "Delin Feng",
                "Wenzhe Cai",
                "Chenming Zhu",
                "Tai Wang",
                "Jiangmiao Pang",
                "Xihui Liu"
            ],
            "arxiv_id": "2512.08186v1",
            "summary": "While recent large vision-language models (VLMs) have improved generalization in vision-language navigation (VLN), existing methods typically rely on end-to-end pipelines that map vision-language inputs directly to short-horizon discrete actions. Such designs often produce fragmented motions, incur high latency, and struggle with real-world challenges like dynamic obstacle avoidance. We propose DualVLN, the first dual-system VLN foundation model that synergistically integrates high-level reasoning with low-level action execution. System 2, a VLM-based global planner, \"grounds slowly\" by predicting mid-term waypoint goals via image-grounded reasoning. System 1, a lightweight, multi-modal conditioning Diffusion Transformer policy, \"moves fast\" by leveraging both explicit pixel goals and latent features from System 2 to generate smooth and accurate trajectories. The dual-system design enables robust real-time control and adaptive local decision-making in complex, dynamic environments. By decoupling training, the VLM retains its generalization, while System 1 achieves interpretable and effective local navigation. DualVLN outperforms prior methods across all VLN benchmarks and real-world experiments demonstrate robust long-horizon planning and real-time adaptability in dynamic environments.",
            "headline_zh": "提出DualVLN双系统基础模型，通过高低层协同解决视觉语言导航中的碎片化动作和动态环境适应问题。",
            "intro_zh": [
                "现有端到端方法在视觉语言导航中产生碎片化动作，延迟高且难以应对动态障碍。",
                "DualVLN结合基于VLM的全局规划器和轻量级扩散Transformer策略，实现高低层推理与执行协同。",
                "在VLN基准测试和真实世界实验中，模型表现优于先前方法，支持实时适应和长程规划。"
            ],
            "tags_zh": [
                "视觉语言导航",
                "双系统模型",
                "扩散Transformer",
                "实时控制",
                "动态环境适应",
                "基础模型"
            ],
            "_index": 235
        },
        {
            "title": "A Practical Framework for Evaluating Medical AI Security: Reproducible Assessment of Jailbreaking and Privacy Vulnerabilities Across Clinical Specialties",
            "authors": [
                "Jinghao Wang",
                "Ping Zhang",
                "Carter Yagemann"
            ],
            "arxiv_id": "2512.08185v1",
            "summary": "Medical Large Language Models (LLMs) are increasingly deployed for clinical decision support across diverse specialties, yet systematic evaluation of their robustness to adversarial misuse and privacy leakage remains inaccessible to most researchers. Existing security benchmarks require GPU clusters, commercial API access, or protected health data -- barriers that limit community participation in this critical research area. We propose a practical, fully reproducible framework for evaluating medical AI security under realistic resource constraints. Our framework design covers multiple medical specialties stratified by clinical risk -- from high-risk domains such as emergency medicine and psychiatry to general practice -- addressing jailbreaking attacks (role-playing, authority impersonation, multi-turn manipulation) and privacy extraction attacks. All evaluation utilizes synthetic patient records requiring no IRB approval. The framework is designed to run entirely on consumer CPU hardware using freely available models, eliminating cost barriers. We present the framework specification including threat models, data generation methodology, evaluation protocols, and scoring rubrics. This proposal establishes a foundation for comparative security assessment of medical-specialist models and defense mechanisms, advancing the broader goal of ensuring safe and trustworthy medical AI systems.",
            "headline_zh": "提出可复现框架以评估医疗AI在资源受限下的安全漏洞",
            "intro_zh": [
                "核心问题：医疗大语言模型在临床部署中面临对抗性滥用和隐私泄露风险，缺乏可访问的安全评估方法。",
                "方法要点：设计涵盖多专科的威胁模型，使用合成患者记录，支持在消费级CPU硬件上运行，无需GPU或受保护数据。",
                "实验或效果：提供框架规范，包括攻击类型（如越狱和隐私提取）、数据生成、评估协议和评分标准，促进比较安全评估。"
            ],
            "tags_zh": [
                "医疗大语言模型",
                "安全评估框架",
                "对抗性攻击",
                "隐私保护",
                "可复现性",
                "临床专科"
            ],
            "_index": 236
        },
        {
            "title": "GeoLoom: High-quality Geometric Diagram Generation from Textual Input",
            "authors": [
                "Xiaojing Wei",
                "Ting Zhang",
                "Wei He",
                "Jingdong Wang",
                "Hua Huang"
            ],
            "arxiv_id": "2512.08180v1",
            "summary": "High-quality geometric diagram generation presents both a challenge and an opportunity: it demands strict spatial accuracy while offering well-defined constraints to guide generation. Inspired by recent advances in geometry problem solving that employ formal languages and symbolic solvers for enhanced correctness and interpretability, we propose GeoLoom, a novel framework for text-to-diagram generation in geometric domains. GeoLoom comprises two core components: an autoformalization module that translates natural language into a specifically designed generation-oriented formal language GeoLingua, and a coordinate solver that maps formal constraints to precise coordinates using the efficient Monte Carlo optimization. To support this framework, we introduce GeoNF, a dataset aligning natural language geometric descriptions with formal GeoLingua descriptions. We further propose a constraint-based evaluation metric that quantifies structural deviation, offering mathematically grounded supervision for iterative refinement. Empirical results demonstrate that GeoLoom significantly outperforms state-of-the-art baselines in structural fidelity, providing a principled foundation for interpretable and scalable diagram generation.",
            "headline_zh": "提出GeoLoom框架，通过形式化语言和坐标求解实现文本到高质量几何图生成。",
            "intro_zh": [
                "核心问题：几何图生成需高空间精度，现有方法难以保证结构保真度。",
                "方法要点：结合自动形式化模块和蒙特卡洛优化求解器，将自然语言转换为形式约束并映射为坐标。",
                "实验或效果：在GeoNF数据集上评估，结构保真度显著优于基线，支持可解释和可扩展生成。"
            ],
            "tags_zh": [
                "几何图生成",
                "文本到图生成",
                "形式化语言",
                "坐标求解",
                "蒙特卡洛优化",
                "结构保真度"
            ],
            "_index": 237
        },
        {
            "title": "Worst-case generation via minimax optimization in Wasserstein space",
            "authors": [
                "Xiuyuan Cheng",
                "Yao Xie",
                "Linglingzhi Zhu",
                "Yunqin Zhu"
            ],
            "arxiv_id": "2512.08176v1",
            "summary": "Worst-case generation plays a critical role in evaluating robustness and stress-testing systems under distribution shifts, in applications ranging from machine learning models to power grids and medical prediction systems. We develop a generative modeling framework for worst-case generation for a pre-specified risk, based on min-max optimization over continuous probability distributions, namely the Wasserstein space. Unlike traditional discrete distributionally robust optimization approaches, which often suffer from scalability issues, limited generalization, and costly worst-case inference, our framework exploits the Brenier theorem to characterize the least favorable (worst-case) distribution as the pushforward of a transport map from a continuous reference measure, enabling a continuous and expressive notion of risk-induced generation beyond classical discrete DRO formulations. Based on the min-max formulation, we propose a Gradient Descent Ascent (GDA)-type scheme that updates the decision model and the transport map in a single loop, establishing global convergence guarantees under mild regularity assumptions and possibly without convexity-concavity. We also propose to parameterize the transport map using a neural network that can be trained simultaneously with the GDA iterations by matching the transported training samples, thereby achieving a simulation-free approach. The efficiency of the proposed method as a risk-induced worst-case generator is validated by numerical experiments on synthetic and image data.",
            "headline_zh": "提出基于Wasserstein空间极小极大优化的最坏情况生成框架，用于评估系统在分布偏移下的鲁棒性。",
            "intro_zh": [
                "核心问题：传统离散分布鲁棒优化方法存在可扩展性差、泛化有限和最坏情况推断成本高的问题。",
                "方法要点：利用Brenier定理将最坏分布表征为连续参考测度的推前映射，实现连续且表达性强的风险诱导生成。",
                "实验或效果：通过合成和图像数据实验验证了方法作为风险诱导最坏情况生成器的效率。"
            ],
            "tags_zh": [
                "最坏情况生成",
                "Wasserstein空间",
                "极小极大优化",
                "分布鲁棒优化",
                "梯度下降上升",
                "神经网络参数化"
            ],
            "_index": 238
        },
        {
            "title": "RAVES-Calib: Robust, Accurate and Versatile Extrinsic Self Calibration Using Optimal Geometric Features",
            "authors": [
                "Haoxin Zhang",
                "Shuaixin Li",
                "Xiaozhou Zhu",
                "Hongbo Chen",
                "Wen Yao"
            ],
            "arxiv_id": "2512.08170v1",
            "summary": "In this paper, we present a user-friendly LiDAR-camera calibration toolkit that is compatible with various LiDAR and camera sensors and requires only a single pair of laser points and a camera image in targetless environments. Our approach eliminates the need for an initial transform and remains robust even with large positional and rotational LiDAR-camera extrinsic parameters. We employ the Gluestick pipeline to establish 2D-3D point and line feature correspondences for a robust and automatic initial guess. To enhance accuracy, we quantitatively analyze the impact of feature distribution on calibration results and adaptively weight the cost of each feature based on these metrics. As a result, extrinsic parameters are optimized by filtering out the adverse effects of inferior features. We validated our method through extensive experiments across various LiDAR-camera sensors in both indoor and outdoor settings. The results demonstrate that our method provides superior robustness and accuracy compared to SOTA techniques. Our code is open-sourced on GitHub to benefit the community.",
            "headline_zh": "提出RAVES-Calib方法，用于无目标环境下鲁棒、精确的LiDAR-相机外参自校准。",
            "intro_zh": [
                "核心问题：无需初始变换，在单对激光点与图像下实现多传感器兼容的外参校准。",
                "方法要点：利用Gluestick建立2D-3D特征对应，基于特征分布自适应加权优化参数。",
                "实验或效果：在室内外多传感器实验中，相比SOTA技术展现更优的鲁棒性和精度。"
            ],
            "tags_zh": [
                "LiDAR-相机校准",
                "外参自校准",
                "特征对应",
                "自适应加权",
                "无目标环境",
                "多传感器兼容"
            ],
            "_index": 239
        },
        {
            "title": "Information-Dense Reasoning for Efficient and Auditable Security Alert Triage",
            "authors": [
                "Guangze Zhao",
                "Yongzheng Zhang",
                "Changbo Tian",
                "Dan Xie",
                "Hongri Liu",
                "Bailing Wang"
            ],
            "arxiv_id": "2512.08169v1",
            "summary": "Security Operations Centers face massive, heterogeneous alert streams under minute-level service windows, creating the Alert Triage Latency Paradox: verbose reasoning chains ensure accuracy and compliance but incur prohibitive latency and token costs, while minimal chains sacrifice transparency and auditability. Existing solutions fail: signature systems are brittle, anomaly methods lack actionability, and fully cloud-hosted LLMs raise latency, cost, and privacy concerns. We propose AIDR, a hybrid cloud-edge framework that addresses this trade-off through constrained information-density optimization. The core innovation is gradient-based compression of reasoning chains to retain only decision-critical steps--minimal evidence sufficient to justify predictions while respecting token and latency budgets. We demonstrate that this approach preserves decision-relevant information while minimizing complexity. We construct compact datasets by distilling alerts into 3-5 high-information bullets (68% token reduction), train domain-specialized experts via LoRA, and deploy a cloud-edge architecture: a cloud LLM routes alerts to on-premises experts generating SOAR-ready JSON. Experiments demonstrate AIDR achieves higher accuracy and 40.6% latency reduction versus Chain-of-Thought, with robustness to data corruption and out-of-distribution generalization, enabling auditable and efficient SOC triage with full data residency compliance.",
            "headline_zh": "提出AIDR混合云边框架，通过信息密度优化解决安全告警分诊中的延迟与可审计性矛盾",
            "intro_zh": [
                "核心问题：安全运营中心面临告警分诊延迟悖论——详尽推理链确保准确性但延迟高，精简链则牺牲可审计性",
                "方法要点：采用梯度压缩技术精简推理链，保留决策关键步骤，构建云边架构实现高效路由与本地处理",
                "实验效果：相比思维链方法，AIDR实现更高准确率与40.6%延迟降低，保持数据驻留合规性"
            ],
            "tags_zh": [
                "安全告警分诊",
                "信息密度优化",
                "推理链压缩",
                "云边计算",
                "可审计性",
                "延迟优化"
            ],
            "_index": 240
        },
        {
            "title": "Accuracy Does Not Guarantee Human-Likeness in Monocular Depth Estimators",
            "authors": [
                "Yuki Kubota",
                "Taiki Fukiage"
            ],
            "arxiv_id": "2512.08163v1",
            "summary": "Monocular depth estimation is a fundamental capability for real-world applications such as autonomous driving and robotics. Although deep neural networks (DNNs) have achieved superhuman accuracy on physical-based benchmarks, a key challenge remains: aligning model representations with human perception, a promising strategy for enhancing model robustness and interpretability. Research in object recognition has revealed a complex trade-off between model accuracy and human-like behavior, raising a question whether a similar divergence exist in depth estimation, particularly for natural outdoor scenes where benchmarks rely on sensor-based ground truth rather than human perceptual estimates. In this study, we systematically investigated the relationship between model accuracy and human similarity across 69 monocular depth estimators using the KITTI dataset. To dissect the structure of error patterns on a factor-by-factor basis, we applied affine fitting to decompose prediction errors into interpretable components. Intriguingly, our results reveal while humans and DNNs share certain estimation biases (positive error correlations), we observed distinct trade-off relationships between model accuracy and human similarity. This finding indicates that improving accuracy does not necessarily lead to more human-like behavior, underscoring the necessity of developing multifaceted, human-centric evaluations beyond traditional accuracy.",
            "headline_zh": "揭示单目深度估计中模型精度与人类相似性之间的权衡关系",
            "intro_zh": [
                "核心问题：模型精度提升是否保证人类感知对齐，尤其在自然户外场景中",
                "方法要点：使用KITTI数据集，通过仿射拟合分解误差模式，分析69个模型",
                "实验或效果：发现精度与人类相似性存在不同权衡，强调需超越传统精度评估"
            ],
            "tags_zh": [
                "单目深度估计",
                "人类感知对齐",
                "模型精度",
                "误差分解",
                "KITTI数据集",
                "仿射拟合"
            ],
            "_index": 241
        },
        {
            "title": "Fourier-RWKV: A Multi-State Perception Network for Efficient Image Dehazing",
            "authors": [
                "Lirong Zheng",
                "Yanshan Li",
                "Rui Yu",
                "Kaihao Zhang"
            ],
            "arxiv_id": "2512.08161v1",
            "summary": "Image dehazing is crucial for reliable visual perception, yet it remains highly challenging under real-world non-uniform haze conditions. Although Transformer-based methods excel at capturing global context, their quadratic computational complexity hinders real-time deployment. To address this, we propose Fourier Receptance Weighted Key Value (Fourier-RWKV), a novel dehazing framework based on a Multi-State Perception paradigm. The model achieves comprehensive haze degradation modeling with linear complexity by synergistically integrating three distinct perceptual states: (1) Spatial-form Perception, realized through the Deformable Quad-directional Token Shift (DQ-Shift) operation, which dynamically adjusts receptive fields to accommodate local haze variations; (2) Frequency-domain Perception, implemented within the Fourier Mix block, which extends the core WKV attention mechanism of RWKV from the spatial domain to the Fourier domain, preserving the long-range dependencies essential for global haze estimation while mitigating spatial attenuation; (3) Semantic-relation Perception, facilitated by the Semantic Bridge Module (SBM), which utilizes Dynamic Semantic Kernel Fusion (DSK-Fusion) to precisely align encoder-decoder features and suppress artifacts. Extensive experiments on multiple benchmarks demonstrate that Fourier-RWKV delivers state-of-the-art performance across diverse haze scenarios while significantly reducing computational overhead, establishing a favorable trade-off between restoration quality and practical efficiency. Code is available at: https://github.com/Dilizlr/Fourier-RWKV.",
            "headline_zh": "提出Fourier-RWKV多状态感知网络，以线性复杂度高效解决非均匀图像去雾问题。",
            "intro_zh": [
                "核心问题：真实世界非均匀雾霾条件下图像去雾挑战大，Transformer方法计算复杂度高。",
                "方法要点：结合空间、频域和语义感知状态，通过DQ-Shift、Fourier Mix和SBM模块实现高效去雾。",
                "实验或效果：在多个基准测试中达到先进性能，显著降低计算开销，平衡恢复质量与效率。"
            ],
            "tags_zh": [
                "图像去雾",
                "线性复杂度",
                "多状态感知",
                "傅里叶变换",
                "非均匀雾霾",
                "高效模型"
            ],
            "_index": 242
        },
        {
            "title": "LayerPipe2: Multistage Pipelining and Weight Recompute via Improved Exponential Moving Average for Training Neural Networks",
            "authors": [
                "Nanda K. Unnikrishnan",
                "Keshab K. Parhi"
            ],
            "arxiv_id": "2512.08160v1",
            "summary": "In our prior work, LayerPipe, we had introduced an approach to accelerate training of convolutional, fully connected, and spiking neural networks by overlapping forward and backward computation. However, despite empirical success, a principled understanding of how much gradient delay needs to be introduced at each layer to achieve desired level of pipelining was not addressed. This paper, LayerPipe2, fills that gap by formally deriving LayerPipe using variable delayed gradient adaptation and retiming. We identify where delays may be legally inserted and show that the required amount of delay follows directly from the network structure where inner layers require fewer delays and outer layers require longer delays. When pipelining is applied at every layer, the amount of delay depends only on the number of remaining downstream stages. When layers are pipelined in groups, all layers in the group share the same assignment of delays. These insights not only explain previously observed scheduling patterns but also expose an often overlooked challenge that pipelining implicitly requires storage of historical weights. We overcome this storage bottleneck by developing a pipeline--aware moving average that reconstructs the required past states rather than storing them explicitly. This reduces memory cost without sacrificing the accuracy guarantees that makes pipelined learning viable. The result is a principled framework that illustrates how to construct LayerPipe architectures, predicts their delay requirements, and mitigates their storage burden, thereby enabling scalable pipelined training with controlled communication computation tradeoffs.",
            "headline_zh": "提出LayerPipe2框架，通过延迟梯度分析和权重重构实现可扩展的神经网络流水线训练",
            "intro_zh": [
                "核心问题：流水线训练中梯度延迟的量化与历史权重存储瓶颈",
                "方法要点：基于网络结构推导延迟需求，开发流水线感知移动平均重构权重",
                "实验或效果：降低内存成本，保持精度，支持可控计算通信权衡"
            ],
            "tags_zh": [
                "神经网络训练",
                "流水线并行",
                "梯度延迟",
                "权重重构",
                "内存优化",
                "可扩展性"
            ],
            "_index": 243
        },
        {
            "title": "TreeGRPO: Tree-Advantage GRPO for Online RL Post-Training of Diffusion Models",
            "authors": [
                "Zheng Ding",
                "Weirui Ye"
            ],
            "arxiv_id": "2512.08153v1",
            "summary": "Reinforcement learning (RL) post-training is crucial for aligning generative models with human preferences, but its prohibitive computational cost remains a major barrier to widespread adoption. We introduce \\textbf{TreeGRPO}, a novel RL framework that dramatically improves training efficiency by recasting the denoising process as a search tree. From shared initial noise samples, TreeGRPO strategically branches to generate multiple candidate trajectories while efficiently reusing their common prefixes. This tree-structured approach delivers three key advantages: (1) \\emph{High sample efficiency}, achieving better performance under same training samples (2) \\emph{Fine-grained credit assignment} via reward backpropagation that computes step-specific advantages, overcoming the uniform credit assignment limitation of trajectory-based methods, and (3) \\emph{Amortized computation} where multi-child branching enables multiple policy updates per forward pass. Extensive experiments on both diffusion and flow-based models demonstrate that TreeGRPO achieves \\textbf{2.4$\\times$ faster training} while establishing a superior Pareto frontier in the efficiency-reward trade-off space. Our method consistently outperforms GRPO baselines across multiple benchmarks and reward models, providing a scalable and effective pathway for RL-based visual generative model alignment. The project website is available at treegrpo.github.io.",
            "headline_zh": "提出TreeGRPO以高效解决扩散模型在线强化学习后训练的计算成本问题",
            "intro_zh": [
                "核心问题：强化学习后训练计算成本高，阻碍生成模型与人类偏好的对齐。",
                "方法要点：将去噪过程重构为搜索树，通过分支生成候选轨迹并重用公共前缀，实现高效样本利用和细粒度信用分配。",
                "实验或效果：在扩散和流模型中，训练速度提升2.4倍，在效率-奖励权衡空间建立更优帕累托前沿。"
            ],
            "tags_zh": [
                "强化学习后训练",
                "扩散模型对齐",
                "树结构搜索",
                "样本效率",
                "信用分配",
                "计算优化"
            ],
            "_index": 244
        }
    ]
}