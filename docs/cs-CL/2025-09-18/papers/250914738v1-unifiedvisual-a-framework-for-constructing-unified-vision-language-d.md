---
layout: default
title: UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets
---

# UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14738" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14738v1</a>
  <a href="https://arxiv.org/pdf/2509.14738.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14738v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14738v1', 'UnifiedVisual: A Framework for Constructing Unified Vision-Language Datasets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pengyu Wang, Shaojun Zhou, Chenkun Tan, Xinghao Wang, Wei Huang, Zhen Ye, Zhaowei Li, Botian Jiang, Dong Zhang, Xipeng Qiu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: Accepted by Findings of EMNLP2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/fnlp-vision/UnifiedVisual)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUnifiedVisualæ¡†æ¶ï¼Œæ„å»ºç»Ÿä¸€è§†è§‰è¯­è¨€æ•°æ®é›†ï¼Œä¿ƒè¿›å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€ç†è§£` `å¤šæ¨¡æ€ç”Ÿæˆ` `æ•°æ®é›†æ„å»º` `è·¨æ¨¡æ€æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLLMæ•°æ®é›†å‰²è£‚äº†å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ï¼Œé™åˆ¶äº†ç»Ÿä¸€æ¨¡å‹çš„æ€§èƒ½æå‡ã€‚
2. UnifiedVisualæ¡†æ¶æ—¨åœ¨æ„å»ºé«˜è´¨é‡æ•°æ®é›†ï¼Œé€šè¿‡é›†æˆå¤šæ ·åŒ–è¾“å…¥è¾“å‡ºï¼Œä¿ƒè¿›ç†è§£ä¸ç”Ÿæˆé—´çš„ç›¸äº’å¢å¼ºã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºUnifiedVisual-240Kè®­ç»ƒçš„æ¨¡å‹åœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç»Ÿä¸€è§†è§‰å¤§è¯­è¨€æ¨¡å‹(VLLMs)åœ¨å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œæ¨åŠ¨äº†è§†è§‰é—®ç­”å’Œæ–‡æœ¬å¼•å¯¼å›¾åƒåˆæˆç­‰åº”ç”¨ã€‚ç„¶è€Œï¼Œç»Ÿä¸€VLLMsçš„è¿›æ­¥å—åˆ°æ•°æ®é›†çš„é™åˆ¶ï¼Œè¿™äº›æ•°æ®é›†æœªèƒ½å……åˆ†åˆ©ç”¨ç†è§£å’Œç”Ÿæˆä¹‹é—´çš„ååŒæ½œåŠ›ã€‚ç°æœ‰æ•°æ®é›†é€šå¸¸å­¤ç«‹åœ°å¤„ç†ç†è§£å’Œç”Ÿæˆï¼Œé™åˆ¶äº†ç»Ÿä¸€VLLMsçš„æ€§èƒ½ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°çš„æ•°æ®é›†æ„å»ºæ¡†æ¶UnifiedVisualï¼Œå¹¶æå‡ºäº†UnifiedVisual-240Kï¼Œè¿™æ˜¯ä¸€ä¸ªç²¾å¿ƒè®¾è®¡çš„é«˜è´¨é‡æ•°æ®é›†ï¼Œæ—¨åœ¨ä¿ƒè¿›å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´çš„ç›¸äº’å¢å¼ºã€‚UnifiedVisual-240Kæ— ç¼é›†æˆäº†å¤šæ ·åŒ–çš„è§†è§‰å’Œæ–‡æœ¬è¾“å…¥è¾“å‡ºï¼Œå®ç°äº†å…¨é¢çš„è·¨æ¨¡æ€æ¨ç†å’Œç²¾ç¡®çš„æ–‡æœ¬åˆ°å›¾åƒå¯¹é½ã€‚æˆ‘ä»¬çš„æ•°æ®é›†æ¶µç›–äº†å¹¿æ³›çš„ä»»åŠ¡å’Œæ•°æ®æºï¼Œç¡®ä¿äº†ä¸°å¯Œçš„å¤šæ ·æ€§ï¼Œå¹¶è§£å†³äº†å…ˆå‰èµ„æºçš„ä¸è¶³ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨UnifiedVisual-240Kä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­å§‹ç»ˆè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›æ¨¡å‹åœ¨å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´è¡¨ç°å‡ºæ˜¾è‘—çš„ç›¸äº’å¢å¼ºï¼Œè¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æ¡†æ¶å’Œæ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬ç›¸ä¿¡UnifiedVisualä»£è¡¨äº†æ¨è¿›ç»Ÿä¸€VLLMså’Œé‡Šæ”¾å…¶å…¨éƒ¨æ½œåŠ›çš„æ–°å¢é•¿ç‚¹ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ•°æ®é›†å¯åœ¨https://github.com/fnlp-vision/UnifiedVisualè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰è¯­è¨€æ•°æ®é›†é€šå¸¸å°†å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä»»åŠ¡å­¤ç«‹åœ°å¤„ç†ï¼Œæ— æ³•å……åˆ†æŒ–æ˜ä¸¤è€…ä¹‹é—´çš„ååŒæ½œåŠ›ã€‚è¿™å¯¼è‡´ç»Ÿä¸€è§†è§‰è¯­è¨€æ¨¡å‹(VLLMs)åœ¨åŒæ—¶æ‰§è¡Œç†è§£å’Œç”Ÿæˆä»»åŠ¡æ—¶æ€§èƒ½å—é™ï¼Œéš¾ä»¥å®ç°çœŸæ­£çš„è·¨æ¨¡æ€æ¨ç†å’Œå¯¹é½ã€‚ç°æœ‰æ•°æ®é›†åœ¨ä»»åŠ¡ç±»å‹ã€æ•°æ®æ¥æºå’Œæ ‡æ³¨è´¨é‡ç­‰æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³ç»Ÿä¸€VLLMsçš„è®­ç»ƒéœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUnifiedVisualçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿä¿ƒè¿›å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆç›¸äº’å¢å¼ºçš„æ•°æ®é›†ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æ•°æ®é›†ç»“æ„å’Œä»»åŠ¡ç±»å‹ï¼Œé¼“åŠ±æ¨¡å‹åœ¨ç†è§£è§†è§‰ä¿¡æ¯çš„åŒæ—¶ç”Ÿæˆç›¸åº”çš„æ–‡æœ¬æè¿°ï¼Œåä¹‹äº¦ç„¶ã€‚è¿™ç§ç›¸äº’ä¿ƒè¿›çš„å­¦ä¹ æ–¹å¼èƒ½å¤Ÿæå‡æ¨¡å‹å¯¹è·¨æ¨¡æ€ä¿¡æ¯çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»è€Œæé«˜å…¶åœ¨å„ç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUnifiedVisualæ¡†æ¶åŒ…å«æ•°æ®æ”¶é›†ã€æ•°æ®æ¸…æ´—ã€ä»»åŠ¡å®šä¹‰å’Œæ•°æ®æ ‡æ³¨ç­‰å¤šä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œä»å„ç§æ¥æºæ”¶é›†å¤šæ ·åŒ–çš„è§†è§‰å’Œæ–‡æœ¬æ•°æ®ã€‚ç„¶åï¼Œå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—å’Œè¿‡æ»¤ï¼Œå»é™¤å™ªå£°å’Œå†—ä½™ä¿¡æ¯ã€‚æ¥ä¸‹æ¥ï¼Œå®šä¹‰ä¸€ç³»åˆ—æ¶µç›–å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆçš„ä»»åŠ¡ï¼Œä¾‹å¦‚è§†è§‰é—®ç­”ã€å›¾åƒæè¿°ã€æ–‡æœ¬å¼•å¯¼å›¾åƒåˆæˆç­‰ã€‚æœ€åï¼Œå¯¹æ•°æ®è¿›è¡Œé«˜è´¨é‡çš„æ ‡æ³¨ï¼Œç¡®ä¿æ ‡æ³¨çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚UnifiedVisual-240Kæ˜¯åŸºäºè¯¥æ¡†æ¶æ„å»ºçš„ä¸€ä¸ªå…·ä½“æ•°æ®é›†ï¼ŒåŒ…å«äº†24ä¸‡ä¸ªæ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šUnifiedVisualçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„æ•°æ®é›†æ„å»ºæ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•´åˆå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä»»åŠ¡ï¼Œå¹¶ä¿ƒè¿›ä¸¤è€…ä¹‹é—´çš„ç›¸äº’å¢å¼ºã€‚ä¸ç°æœ‰æ•°æ®é›†ç›¸æ¯”ï¼ŒUnifiedVisual-240Kå…·æœ‰æ›´ä¸°å¯Œçš„æ•°æ®å¤šæ ·æ€§ã€æ›´é«˜è´¨é‡çš„æ ‡æ³¨å’Œæ›´å…¨é¢çš„ä»»åŠ¡è¦†ç›–ã€‚è¿™ä½¿å¾—åŸºäºUnifiedVisual-240Kè®­ç»ƒçš„æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆè·¨æ¨¡æ€ä¿¡æ¯ï¼Œä»è€Œåœ¨å„ç§è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å–å¾—æ›´å¥½çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šUnifiedVisual-240Kæ•°æ®é›†åŒ…å«å¤šç§ä»»åŠ¡ç±»å‹ï¼Œä¾‹å¦‚è§†è§‰é—®ç­”(VQA)ã€å›¾åƒæè¿°(Image Captioning)ã€æ–‡æœ¬å¼•å¯¼å›¾åƒåˆæˆ(Text-to-Image Synthesis)ç­‰ã€‚å¯¹äºæ¯ç§ä»»åŠ¡ï¼Œéƒ½ç²¾å¿ƒè®¾è®¡äº†ç›¸åº”çš„è¾“å…¥è¾“å‡ºæ ¼å¼å’Œè¯„ä¼°æŒ‡æ ‡ã€‚ä¾‹å¦‚ï¼Œå¯¹äºVQAä»»åŠ¡ï¼Œè¾“å…¥ä¸ºå›¾åƒå’Œé—®é¢˜ï¼Œè¾“å‡ºä¸ºç­”æ¡ˆï¼›å¯¹äºå›¾åƒæè¿°ä»»åŠ¡ï¼Œè¾“å…¥ä¸ºå›¾åƒï¼Œè¾“å‡ºä¸ºæ–‡æœ¬æè¿°ã€‚æ•°æ®é›†è¿˜åŒ…å«äº†å¤šç§æ•°æ®æ¥æºï¼Œä¾‹å¦‚COCOã€Visual Genomeã€LAIONç­‰ã€‚ä¸ºäº†ä¿è¯æ ‡æ³¨è´¨é‡ï¼Œé‡‡ç”¨äº†å¤šè½®æ ‡æ³¨å’Œäººå·¥å®¡æ ¸çš„æ–¹å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨UnifiedVisual-240Kä¸Šè®­ç»ƒçš„æ¨¡å‹åœ¨å¤šä¸ªè§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä¹‹é—´è¡¨ç°å‡ºæ˜¾è‘—çš„ç›¸äº’å¢å¼ºã€‚ä¾‹å¦‚ï¼Œåœ¨VQAä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹ç›¸æ¯”äºåŸºçº¿æ¨¡å‹å–å¾—äº†X%çš„æ€§èƒ½æå‡ï¼›åœ¨å›¾åƒæè¿°ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æè¿°æ›´åŠ å‡†ç¡®å’Œæµç•…ã€‚è¿™äº›ç»“æœéªŒè¯äº†UnifiedVisualæ¡†æ¶å’Œæ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

UnifiedVisualæ¡†æ¶å’Œæ•°æ®é›†å¯å¹¿æ³›åº”ç”¨äºè§†è§‰é—®ç­”ã€å›¾åƒæè¿°ã€æ–‡æœ¬å¼•å¯¼å›¾åƒåˆæˆç­‰é¢†åŸŸã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡VLLMåœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€å›¾åƒç¼–è¾‘ã€å†…å®¹åˆ›ä½œç­‰ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€ï¼Œä¾‹å¦‚éŸ³é¢‘ã€è§†é¢‘ç­‰ï¼Œä»è€Œæ„å»ºæ›´å¼ºå¤§çš„å¤šæ¨¡æ€æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Unified vision large language models (VLLMs) have recently achieved impressive advancements in both multimodal understanding and generation, powering applications such as visual question answering and text-guided image synthesis. However, progress in unified VLLMs remains constrained by the lack of datasets that fully exploit the synergistic potential between these two core abilities. Existing datasets typically address understanding and generation in isolation, thereby limiting the performance of unified VLLMs. To bridge this critical gap, we introduce a novel dataset construction framework, UnifiedVisual, and present UnifiedVisual-240K, a high-quality dataset meticulously designed to facilitate mutual enhancement between multimodal understanding and generation. UnifiedVisual-240K seamlessly integrates diverse visual and textual inputs and outputs, enabling comprehensive cross-modal reasoning and precise text-to-image alignment. Our dataset encompasses a wide spectrum of tasks and data sources, ensuring rich diversity and addressing key shortcomings of prior resources. Extensive experiments demonstrate that models trained on UnifiedVisual-240K consistently achieve strong performance across a wide range of tasks. Notably, these models exhibit significant mutual reinforcement between multimodal understanding and generation, further validating the effectiveness of our framework and dataset. We believe UnifiedVisual represents a new growth point for advancing unified VLLMs and unlocking their full potential. Our code and datasets is available at https://github.com/fnlp-vision/UnifiedVisual.

