---
layout: default
title: Benchmarking and Improving LLM Robustness for Personalized Generation
---

# Benchmarking and Improving LLM Robustness for Personalized Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19358" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19358v1</a>
  <a href="https://arxiv.org/pdf/2509.19358.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19358v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19358v1', 'Benchmarking and Improving LLM Robustness for Personalized Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chimaobi Okite, Naihao Deng, Kiran Bodipati, Huaidian Hou, Joyce Chai, Rada Mihalcea

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: First draft. First camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPERGæ¡†æ¶ä¸Pref-Aligneræ–¹æ³•ï¼Œæå‡LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä¸­çš„äº‹å®æ€§ä¸é²æ£’æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªæ€§åŒ–ç”Ÿæˆ` `äº‹å®æ€§` `é²æ£’æ€§` `è¯„ä¼°æ¡†æ¶` `ç”¨æˆ·åå¥½` `Pref-Aligner`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMä¸ªæ€§åŒ–ç”Ÿæˆè¯„ä¼°ä¸»è¦å…³æ³¨ç”¨æˆ·åå¥½å¯¹é½ï¼Œå¿½ç•¥äº†äº‹å®å‡†ç¡®æ€§è¿™ä¸€é‡è¦ç»´åº¦ã€‚
2. è®ºæ–‡æå‡ºPERGæ¡†æ¶ä¸Pref-Aligneræ–¹æ³•ï¼Œæ—¨åœ¨æå‡LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä¸­çš„äº‹å®æ€§ä¸é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPref-Aligneræ–¹æ³•å¹³å‡æå‡äº†æ¨¡å‹é²æ£’æ€§25%ï¼Œæœ‰æ•ˆç¼“è§£äº†LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä¸­äº‹å®æ€§ä¸è¶³çš„é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸ªæ€§åŒ–å“åº”å—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç°æœ‰è¯„ä¼°ä¸»è¦å…³æ³¨å“åº”æ˜¯å¦ç¬¦åˆç”¨æˆ·åå¥½ï¼Œä½†æˆ‘ä»¬è®¤ä¸ºäº‹å®æ€§æ˜¯ä¸€ä¸ªåŒæ ·é‡è¦ä½†ç»å¸¸è¢«å¿½è§†çš„ç»´åº¦ã€‚åœ¨ä¸ªæ€§åŒ–èƒŒæ™¯ä¸‹ï¼Œå¦‚æœæ¨¡å‹å“åº”æ—¢åœ¨äº‹å®ä¸Šå‡†ç¡®åˆç¬¦åˆç”¨æˆ·åå¥½ï¼Œåˆ™è®¤ä¸ºè¯¥æ¨¡å‹æ˜¯é²æ£’çš„ã€‚ä¸ºäº†è¯„ä¼°è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬å¼•å…¥äº†PERGï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°LLMé²æ£’æ€§çš„å¯æ‰©å±•æ¡†æ¶ï¼Œä»¥åŠä¸€ä¸ªæ–°çš„æ•°æ®é›†PERGDataã€‚æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„promptæ–¹æ³•è¯„ä¼°äº†æ¥è‡ªäº”ä¸ªä¸åŒæ¨¡å‹ç³»åˆ—çš„åå››ä¸ªæ¨¡å‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå½“å‰çš„LLMåœ¨é²æ£’çš„ä¸ªæ€§åŒ–æ–¹é¢å­˜åœ¨å›°éš¾ï¼šå³ä½¿æ˜¯æœ€å¼ºå¤§çš„æ¨¡å‹ï¼ˆGPT-4.1, LLaMA3-70Bï¼‰åœ¨æ²¡æœ‰ä¸ªæ€§åŒ–çš„æƒ…å†µä¸‹ï¼Œä¹Ÿä¼šåœ¨5%çš„å…ˆå‰æˆåŠŸæ¡ˆä¾‹ä¸­æ— æ³•ä¿æŒæ­£ç¡®æ€§ï¼Œè€Œè¾ƒå°çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ7Bè§„æ¨¡ï¼‰å¯èƒ½ä¼šå¤±è´¥è¶…è¿‡20%çš„æ—¶é—´ã€‚è¿›ä¸€æ­¥çš„åˆ†æè¡¨æ˜ï¼Œé²æ£’æ€§å—åˆ°æŸ¥è¯¢æ€§è´¨å’Œç”¨æˆ·åå¥½ç±»å‹çš„æ˜¾è‘—å½±å“ã€‚ä¸ºäº†å‡è½»è¿™äº›å¤±è´¥ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µæ–¹æ³•Pref-Alignerï¼Œè¯¥æ–¹æ³•å¹³å‡æé«˜äº†æ‰€æœ‰æ¨¡å‹çš„é²æ£’æ€§25%ã€‚æˆ‘ä»¬çš„å·¥ä½œçªå‡ºäº†å½“å‰è¯„ä¼°å®è·µä¸­çš„å…³é”®å·®è·ï¼Œå¹¶å¼•å…¥äº†å·¥å…·å’ŒæŒ‡æ ‡æ¥æ”¯æŒæ›´å¯é ã€ç”¨æˆ·å¯¹é½çš„LLMéƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œäº‹å®å‡†ç¡®æ€§ä¸ç”¨æˆ·åå¥½å¯¹é½ä¹‹é—´çš„å¹³è¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å¦‚ä½•ä½¿LLMçš„è¾“å‡ºç¬¦åˆç”¨æˆ·åå¥½ï¼Œè€Œå¿½ç•¥äº†LLMç”Ÿæˆå†…å®¹çš„äº‹å®æ€§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ»¡è¶³ç”¨æˆ·ä¸ªæ€§åŒ–éœ€æ±‚çš„åŒæ—¶ï¼Œå¯èƒ½ä¼šäº§ç”Ÿä¸å‡†ç¡®ç”šè‡³é”™è¯¯çš„ä¿¡æ¯ã€‚è¿™ç§ç°è±¡åœ¨å®é™…åº”ç”¨ä¸­ä¼šä¸¥é‡å½±å“ç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå¹¶å¯èƒ½é€ æˆè¯¯å¯¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤ŸåŒæ—¶è¯„ä¼°LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­äº‹å®å‡†ç¡®æ€§å’Œç”¨æˆ·åå¥½å¯¹é½ç¨‹åº¦çš„æ¡†æ¶ï¼Œå¹¶æå‡ºä¸€ç§æ–¹æ³•æ¥æå‡LLMåœ¨è¿™ä¸¤ä¸ªæ–¹é¢çš„è¡¨ç°ã€‚é€šè¿‡PERGæ¡†æ¶ï¼Œå¯ä»¥é‡åŒ–LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­çš„é²æ£’æ€§ï¼Œå³åœ¨æ»¡è¶³ç”¨æˆ·åå¥½çš„åŒæ—¶ä¿æŒäº‹å®å‡†ç¡®æ€§ã€‚Pref-Aligneræ–¹æ³•åˆ™é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œé¦–å…ˆç¡®ä¿æ¨¡å‹ç”Ÿæˆäº‹å®å‡†ç¡®çš„å†…å®¹ï¼Œç„¶åå†å°†ç”¨æˆ·åå¥½èå…¥å…¶ä¸­ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•´ä½“é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šPERGè¯„ä¼°æ¡†æ¶å’ŒPref-Aligneræ–¹æ³•ã€‚PERGæ¡†æ¶ç”¨äºè¯„ä¼°LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­çš„é²æ£’æ€§ï¼Œå®ƒåŒ…å«ä¸€ä¸ªæ•°æ®é›†PERGDataï¼Œä»¥åŠä¸€å¥—è¯„ä¼°æŒ‡æ ‡ã€‚Pref-Aligneræ–¹æ³•åˆ™æ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µçš„è®­ç»ƒæ–¹æ³•ï¼Œé¦–å…ˆä½¿ç”¨äº‹å®æ•°æ®è®­ç»ƒLLMï¼Œä½¿å…¶å…·å¤‡ç”Ÿæˆäº‹å®å‡†ç¡®å†…å®¹çš„èƒ½åŠ›ï¼Œç„¶åä½¿ç”¨ç”¨æˆ·åå¥½æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆç¬¦åˆç”¨æˆ·åå¥½çš„å†…å®¹ã€‚æ•´ä¸ªæµç¨‹æ—¨åœ¨æé«˜LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†PERGæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­é²æ£’æ€§çš„æ¡†æ¶ã€‚ä¸ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸åŒï¼ŒPERGæ¡†æ¶åŒæ—¶è€ƒè™‘äº†äº‹å®å‡†ç¡®æ€§å’Œç”¨æˆ·åå¥½å¯¹é½ä¸¤ä¸ªç»´åº¦ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°LLMçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒPref-Aligneræ–¹æ³•é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œæœ‰æ•ˆåœ°æé«˜äº†LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­çš„é²æ£’æ€§ï¼Œé¿å…äº†æ¨¡å‹åœ¨æ»¡è¶³ç”¨æˆ·åå¥½çš„åŒæ—¶ç‰ºç‰²äº‹å®å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šPERGDataæ•°æ®é›†åŒ…å«ä¸€ç³»åˆ—æŸ¥è¯¢ï¼Œæ¯ä¸ªæŸ¥è¯¢éƒ½ä¸ä¸€ä¸ªç”¨æˆ·åå¥½ç›¸å…³è”ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬äº‹å®å‡†ç¡®ç‡å’Œç”¨æˆ·åå¥½å¯¹é½ç‡ã€‚Pref-Aligneræ–¹æ³•çš„ç¬¬ä¸€é˜¶æ®µä½¿ç”¨æ ‡å‡†çš„äº‹å®æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç¬¬äºŒé˜¶æ®µä½¿ç”¨ç”¨æˆ·åå¥½æ•°æ®è¿›è¡Œå¾®è°ƒã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å¼ºå¤§çš„æ¨¡å‹ï¼ˆGPT-4.1, LLaMA3-70Bï¼‰åœ¨æ²¡æœ‰ä¸ªæ€§åŒ–çš„æƒ…å†µä¸‹ï¼Œä¹Ÿä¼šåœ¨5%çš„å…ˆå‰æˆåŠŸæ¡ˆä¾‹ä¸­æ— æ³•ä¿æŒæ­£ç¡®æ€§ï¼Œè€Œè¾ƒå°çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼Œ7Bè§„æ¨¡ï¼‰å¯èƒ½ä¼šå¤±è´¥è¶…è¿‡20%çš„æ—¶é—´ã€‚Pref-Aligneræ–¹æ³•å¹³å‡æé«˜äº†æ‰€æœ‰æ¨¡å‹çš„é²æ£’æ€§25%ï¼Œæ˜¾è‘—æå‡äº†LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä¸ªæ€§åŒ–ç”Ÿæˆå†…å®¹çš„åœºæ™¯ï¼Œä¾‹å¦‚ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€æ™ºèƒ½å®¢æœã€å†…å®¹åˆ›ä½œåŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜LLMåœ¨ä¸ªæ€§åŒ–ç”Ÿæˆä¸­çš„é²æ£’æ€§ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå¹¶å‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒç”Ÿæˆã€éŸ³é¢‘ç”Ÿæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent years have witnessed a growing interest in personalizing the responses of large language models (LLMs). While existing evaluations primarily focus on whether a response aligns with a user's preferences, we argue that factuality is an equally important yet often overlooked dimension. In the context of personalization, we define a model as robust if its responses are both factually accurate and align with the user preferences. To assess this, we introduce PERG, a scalable framework for evaluating robustness in LLMs, along with a new dataset, PERGData. We evaluate fourteen models from five different model families using different prompting methods. Our findings show that current LLMs struggle with robust personalization: even the strongest models (GPT-4.1, LLaMA3-70B) fail to maintain correctness in 5% of previously successful cases without personalization, while smaller models (e.g., 7B-scale) can fail more than 20% of the time. Further analysis reveals that robustness is significantly affected by the nature of the query and the type of user preference. To mitigate these failures, we propose Pref-Aligner, a two-stage approach that improves robustness by an average of 25% across models. Our work highlights critical gaps in current evaluation practices and introduces tools and metrics to support more reliable, user-aligned LLM deployments.

