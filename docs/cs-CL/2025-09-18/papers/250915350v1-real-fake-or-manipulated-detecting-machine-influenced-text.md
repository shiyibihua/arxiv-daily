---
layout: default
title: Real, Fake, or Manipulated? Detecting Machine-Influenced Text
---

# Real, Fake, or Manipulated? Detecting Machine-Influenced Text

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15350" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15350v1</a>
  <a href="https://arxiv.org/pdf/2509.15350.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15350v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15350v1', 'Real, Fake, or Manipulated? Detecting Machine-Influenced Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yitong Wang, Zhongping Zhang, Margherita Piana, Zheng Zhou, Peter Gerstoft, Bryan A. Plummer

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: Accepted to EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHEROæ¨¡å‹ï¼Œç”¨äºåŒºåˆ†äººç±»æ’°å†™ã€æœºå™¨ç”Ÿæˆã€æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘çš„æ–‡æœ¬ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬åˆ†ç±»` `å­ç±»åˆ«æŒ‡å¯¼` `é•¿åº¦é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨ç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•å¿½ç•¥äº†LLMçš„ç»†ç²’åº¦ä½¿ç”¨åœºæ™¯ï¼Œå¦‚æœºå™¨æ¶¦è‰²å’Œç¿»è¯‘ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸è¶³ã€‚
2. HEROæ¨¡å‹é€šè¿‡åˆ†å±‚ç»“æ„å’Œé•¿åº¦ä¸“å®¶æ¨¡å‹ï¼Œç»“åˆå­ç±»åˆ«æŒ‡å¯¼ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å››ç§ç±»å‹çš„æ–‡æœ¬ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒHEROåœ¨å¤šä¸ªLLMå’Œé¢†åŸŸä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹³å‡mAPæå‡2.5-3ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥ç”¨äºæ’°å†™æˆ–ä¿®æ”¹æ–‡æ¡£ï¼Œè¿™ç»™ç†è§£å…¶ä½¿ç”¨æ„å›¾å¸¦æ¥äº†æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼Œè‰¯æ€§ä½¿ç”¨å¯èƒ½åŒ…æ‹¬ä½¿ç”¨LLMæ”¹è¿›äººå·¥æ’°å†™æ–‡æ¡£çš„è¯­æ³•æˆ–å°†å…¶ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ã€‚ç„¶è€Œï¼Œå®Œå…¨ç”±LLMç”Ÿæˆçš„æ–‡æ¡£å¯èƒ½æ¯”ç®€å•çš„ç¿»è¯‘æ›´å¯èƒ½è¢«ç”¨äºä¼ æ’­é”™è¯¯ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œè¢«æ¶æ„è¡Œä¸ºè€…ä½¿ç”¨æˆ–ä»…ä»…æ˜¯äº§ç”Ÿå¹»è§‰ï¼‰ã€‚å…ˆå‰åœ¨æœºå™¨ç”Ÿæˆæ–‡æœ¬ï¼ˆMGTï¼‰æ£€æµ‹æ–¹é¢çš„å·¥ä½œä¸»è¦é›†ä¸­äºç®€å•åœ°è¯†åˆ«æ–‡æ¡£æ˜¯äººå·¥è¿˜æ˜¯æœºå™¨ç¼–å†™çš„ï¼Œå¿½ç•¥äº†è¿™äº›ç»†ç²’åº¦çš„ä½¿ç”¨æƒ…å†µã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§åˆ†å±‚çš„ã€é•¿åº¦é²æ£’çš„æœºå™¨å½±å“æ–‡æœ¬æ£€æµ‹å™¨ï¼ˆHEROï¼‰ï¼Œå®ƒå­¦ä¹ åŒºåˆ†æ¥è‡ªå››ç§ä¸»è¦ç±»å‹çš„ä¸åŒé•¿åº¦çš„æ–‡æœ¬æ ·æœ¬ï¼šäººå·¥æ’°å†™ã€æœºå™¨ç”Ÿæˆã€æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘ã€‚HEROé€šè¿‡ç»“åˆé•¿åº¦ä¸“å®¶æ¨¡å‹çš„é¢„æµ‹æ¥å®ç°è¿™ä¸€ç‚¹ï¼Œè¿™äº›æ¨¡å‹å·²ç»ä½¿ç”¨å­ç±»åˆ«æŒ‡å¯¼è¿›è¡Œè®­ç»ƒã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºå®¹æ˜“æ··æ·†çš„ç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„æºè¯­è¨€ï¼‰ï¼Œæˆ‘ä»¬çš„å­ç±»åˆ«æŒ‡å¯¼æ¨¡å—é¼“åŠ±ç»†ç²’åº¦ç±»åˆ«çš„åˆ†ç¦»ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚åœ¨äº”ä¸ªLLMå’Œå…­ä¸ªé¢†åŸŸè¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜äº†æˆ‘ä»¬çš„HEROçš„ä¼˜åŠ¿ï¼Œå¹³å‡ä¼˜äºæœ€å…ˆè¿›æ°´å¹³2.5-3 mAPã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒºåˆ†äººç±»æ’°å†™ã€æœºå™¨ç”Ÿæˆã€æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘æ–‡æœ¬çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºåŒºåˆ†äººç±»æ’°å†™å’Œæœºå™¨ç”Ÿæˆæ–‡æœ¬ï¼Œå¿½ç•¥äº†æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘ç­‰ç»†ç²’åº¦åœºæ™¯ï¼Œå¯¼è‡´æ£€æµ‹ç²¾åº¦ä¸‹é™ï¼Œæ— æ³•æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåˆ†å±‚çš„ã€é•¿åº¦é²æ£’çš„æ£€æµ‹å™¨ï¼Œåˆ©ç”¨é•¿åº¦ä¸“å®¶æ¨¡å‹å¤„ç†ä¸åŒé•¿åº¦çš„æ–‡æœ¬ï¼Œå¹¶é€šè¿‡å­ç±»åˆ«æŒ‡å¯¼æ¨¡å—åŒºåˆ†å®¹æ˜“æ··æ·†çš„ç±»åˆ«ï¼Œä»è€Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ä¸åŒç±»å‹æ–‡æœ¬çš„ç‰¹å¾ï¼Œå¹¶æœ‰æ•ˆåŒºåˆ†ç›¸ä¼¼çš„æ–‡æœ¬ç±»å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHEROæ¨¡å‹åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) é•¿åº¦ä¸“å®¶æ¨¡å‹ï¼šé’ˆå¯¹ä¸åŒé•¿åº¦çš„æ–‡æœ¬è®­ç»ƒå¤šä¸ªä¸“å®¶æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹ä¸“æ³¨äºç‰¹å®šé•¿åº¦èŒƒå›´çš„æ–‡æœ¬ã€‚2) åˆ†å±‚ç»“æ„ï¼šå°†æ–‡æœ¬åˆ†ä¸ºå››ä¸ªä¸»è¦ç±»åˆ«ï¼ˆäººç±»æ’°å†™ã€æœºå™¨ç”Ÿæˆã€æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘ï¼‰ï¼Œå¹¶åœ¨æ¯ä¸ªç±»åˆ«ä¸‹è¿›ä¸€æ­¥ç»†åˆ†å­ç±»åˆ«ï¼ˆä¾‹å¦‚ï¼Œä¸åŒçš„æºè¯­è¨€ï¼‰ã€‚3) å­ç±»åˆ«æŒ‡å¯¼æ¨¡å—ï¼šé€šè¿‡å¼•å…¥é¢å¤–çš„æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åŒºåˆ†å®¹æ˜“æ··æ·†çš„å­ç±»åˆ«ï¼Œä»è€Œæé«˜æ•´ä½“æ£€æµ‹ç²¾åº¦ã€‚4) é¢„æµ‹èåˆï¼šå°†å„ä¸ªé•¿åº¦ä¸“å®¶æ¨¡å‹çš„é¢„æµ‹ç»“æœè¿›è¡Œèåˆï¼Œå¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šHEROçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªåˆ†å±‚çš„ã€é•¿åº¦é²æ£’çš„æ£€æµ‹æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†ä¸åŒé•¿åº¦çš„æ–‡æœ¬ã€‚2) å¼•å…¥äº†å­ç±»åˆ«æŒ‡å¯¼æ¨¡å—ï¼Œèƒ½å¤ŸåŒºåˆ†å®¹æ˜“æ··æ·†çš„ç±»åˆ«ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹ç²¾åº¦ã€‚3) ç»“åˆäº†é•¿åº¦ä¸“å®¶æ¨¡å‹å’Œåˆ†å±‚ç»“æ„ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ä¸åŒç±»å‹æ–‡æœ¬çš„ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šå­ç±»åˆ«æŒ‡å¯¼æ¨¡å—é€šè¿‡å¼•å…¥é¢å¤–çš„äº¤å‰ç†µæŸå¤±å‡½æ•°æ¥å®ç°ï¼Œè¯¥æŸå¤±å‡½æ•°é¼“åŠ±æ¨¡å‹åŒºåˆ†å®¹æ˜“æ··æ·†çš„å­ç±»åˆ«ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸ªæ–‡æœ¬æ ·æœ¬ï¼Œæ¨¡å‹ä¸ä»…é¢„æµ‹å…¶æ‰€å±çš„ä¸»è¦ç±»åˆ«ï¼Œè¿˜é¢„æµ‹å…¶æ‰€å±çš„å­ç±»åˆ«ã€‚ç„¶åï¼Œå°†ä¸»è¦ç±»åˆ«å’Œå­ç±»åˆ«çš„é¢„æµ‹ç»“æœç»“åˆèµ·æ¥ï¼Œè®¡ç®—æ€»çš„æŸå¤±å‡½æ•°ã€‚é•¿åº¦ä¸“å®¶æ¨¡å‹é‡‡ç”¨Transformeræ¶æ„ï¼Œå¹¶é’ˆå¯¹ä¸åŒé•¿åº¦çš„æ–‡æœ¬è¿›è¡Œå¾®è°ƒã€‚æ¨¡å‹ä½¿ç”¨Adamä¼˜åŒ–å™¨è¿›è¡Œè®­ç»ƒï¼Œå­¦ä¹ ç‡è®¾ç½®ä¸º1e-5ï¼Œbatch sizeè®¾ç½®ä¸º32ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHEROæ¨¡å‹åœ¨äº”ä¸ªLLMï¼ˆåŒ…æ‹¬GPT-2ã€GPT-3ç­‰ï¼‰å’Œå…­ä¸ªé¢†åŸŸä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼Œå¹³å‡mAPæå‡2.5-3ã€‚ç‰¹åˆ«æ˜¯åœ¨åŒºåˆ†æœºå™¨æ¶¦è‰²å’Œæœºå™¨ç¿»è¯‘æ–‡æœ¬æ–¹é¢ï¼ŒHEROçš„æ€§èƒ½æå‡æ›´ä¸ºæ˜æ˜¾ï¼Œè¯æ˜äº†å…¶åœ¨ç»†ç²’åº¦æ–‡æœ¬æ£€æµ‹æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå†…å®¹å®¡æ ¸ã€è™šå‡ä¿¡æ¯æ£€æµ‹ã€å­¦æœ¯è¯šä¿¡è¯„ä¼°ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®è¯†åˆ«æœºå™¨å½±å“çš„æ–‡æœ¬ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢æ¶æ„è¡Œä¸ºè€…åˆ©ç”¨LLMä¼ æ’­è™šå‡ä¿¡æ¯ï¼Œç»´æŠ¤ç½‘ç»œç©ºé—´çš„å¥åº·å’Œå®‰å…¨ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºè¯„ä¼°å­¦ç”Ÿè®ºæ–‡çš„åŸåˆ›æ€§ï¼Œé˜²æ­¢å­¦æœ¯ä¸ç«¯è¡Œä¸ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLMs) can be used to write or modify documents, presenting a challenge for understanding the intent behind their use. For example, benign uses may involve using LLM on a human-written document to improve its grammar or to translate it into another language. However, a document entirely produced by a LLM may be more likely to be used to spread misinformation than simple translation (\eg, from use by malicious actors or simply by hallucinating). Prior works in Machine Generated Text (MGT) detection mostly focus on simply identifying whether a document was human or machine written, ignoring these fine-grained uses. In this paper, we introduce a HiErarchical, length-RObust machine-influenced text detector (HERO), which learns to separate text samples of varying lengths from four primary types: human-written, machine-generated, machine-polished, and machine-translated. HERO accomplishes this by combining predictions from length-specialist models that have been trained with Subcategory Guidance. Specifically, for categories that are easily confused (\eg, different source languages), our Subcategory Guidance module encourages separation of the fine-grained categories, boosting performance. Extensive experiments across five LLMs and six domains demonstrate the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on average.

