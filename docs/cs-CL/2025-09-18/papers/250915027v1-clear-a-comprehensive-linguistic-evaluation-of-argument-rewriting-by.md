---
layout: default
title: CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models
---

# CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15027" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15027v1</a>
  <a href="https://arxiv.org/pdf/2509.15027.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15027v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15027v1', 'CLEAR: A Comprehensive Linguistic Evaluation of Argument Rewriting by Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thomas Huber, Christina Niklaus

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: Accepted at EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CLEARï¼šæå‡ºä¸€å¥—å…¨é¢çš„è¯­è¨€å­¦è¯„ä¼°æµç¨‹ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®ºè¯æ”¹å†™ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®ºè¯æ”¹å†™` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­è¨€å­¦è¯„ä¼°` `æ–‡æœ¬æ”¹è¿›` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹LLMåœ¨é€šç”¨æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†å¹¿æ³›ç ”ç©¶ï¼Œä½†å¯¹æ–‡æœ¬æ”¹å†™ï¼Œç‰¹åˆ«æ˜¯è®ºè¯æ”¹è¿›ä»»åŠ¡çš„ç ”ç©¶è¾ƒå°‘ã€‚
2. è®ºæ–‡æå‡ºCLEARè¯„ä¼°æµç¨‹ï¼ŒåŒ…å«57ä¸ªæŒ‡æ ‡ï¼Œè¦†ç›–è¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼Œç”¨äºè¯„ä¼°LLMæ”¹å†™è®ºè¯æ–‡æœ¬çš„è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMé€šè¿‡ç¼©çŸ­æ–‡æœ¬ã€å¢åŠ å¹³å‡è¯é•¿å’Œåˆå¹¶å¥å­æ¥æ”¹è¿›è®ºè¯ï¼Œå¹¶åœ¨è¯´æœåŠ›å’Œè¿è´¯æ€§æ–¹é¢æœ‰æ‰€æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ–‡æœ¬æ”¹å†™ä»»åŠ¡ä¸­çš„è¡Œä¸ºï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹è®ºè¯æ–‡æœ¬æ”¹è¿›ï¼ˆArgument Improvement, ArgImpï¼‰ä»»åŠ¡ã€‚æˆ‘ä»¬æå‡ºäº†CLEARï¼šä¸€ä¸ªåŒ…å«57ä¸ªæŒ‡æ ‡çš„è¯„ä¼°æµç¨‹ï¼Œè¿™äº›æŒ‡æ ‡æ˜ å°„åˆ°å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼šè¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨ã€‚è¯¥æµç¨‹ç”¨äºè¯„ä¼°LLMæ”¹å†™åçš„è®ºè¯æ–‡æœ¬çš„è´¨é‡ï¼Œæ¶µç›–å¹¿æ³›çš„è®ºè¯è¯­æ–™åº“ï¼Œæ¯”è¾ƒä¸åŒLLMåœ¨æ­¤ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œå¹¶åˆ†æå®ƒä»¬åœ¨ä¸åŒè¯­è¨€å­¦å±‚é¢çš„è¡Œä¸ºã€‚é€šè¿‡è€ƒè™‘æ‰€æœ‰å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼Œæˆ‘ä»¬å‘ç°æ¨¡å‹é€šè¿‡ç¼©çŸ­æ–‡æœ¬ã€åŒæ—¶å¢åŠ å¹³å‡è¯é•¿å’Œåˆå¹¶å¥å­æ¥æ‰§è¡ŒArgImpã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬æ³¨æ„åˆ°è¯´æœåŠ›å’Œè¿è´¯æ€§ç»´åº¦çš„æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®ºè¯æ”¹è¿›ï¼ˆArgument Improvement, ArgImpï¼‰ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹LLMæ”¹å†™è®ºè¯æ–‡æœ¬çš„å…¨é¢è¯­è¨€å­¦è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨è¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨å››ä¸ªå±‚é¢çš„ç»†è‡´åˆ†æã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´å…¨é¢çš„è¯„ä¼°æ¡†æ¶æ¥ç†è§£LLMåœ¨è®ºè¯æ”¹å†™ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤šç»´åº¦çš„è¯„ä¼°æµç¨‹ï¼Œä»è¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼Œå¯¹LLMæ”¹å†™åçš„è®ºè¯æ–‡æœ¬è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚é€šè¿‡åˆ†æLLMåœ¨ä¸åŒè¯­è¨€å­¦å±‚é¢çš„è¡¨ç°ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°äº†è§£å…¶æ”¹å†™ç­–ç•¥å’Œæ•ˆæœã€‚è¿™ç§å¤šç»´åº¦è¯„ä¼°æ–¹æ³•èƒ½å¤Ÿæä¾›æ›´ç»†ç²’åº¦çš„åé¦ˆï¼Œå¸®åŠ©æ”¹è¿›LLMçš„è®ºè¯æ”¹å†™èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCLEARè¯„ä¼°æµç¨‹åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†å¹¿æ³›çš„è®ºè¯è¯­æ–™åº“ï¼›2) LLMæ”¹å†™ï¼šä½¿ç”¨ä¸åŒçš„LLMå¯¹è®ºè¯æ–‡æœ¬è¿›è¡Œæ”¹å†™ï¼›3) æŒ‡æ ‡è®¡ç®—ï¼šè®¡ç®—57ä¸ªæŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡æ˜ å°„åˆ°è¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼›4) ç»“æœåˆ†æï¼šåˆ†æLLMåœ¨ä¸åŒè¯­è¨€å­¦å±‚é¢çš„è¡¨ç°ï¼Œæ¯”è¾ƒä¸åŒLLMä¹‹é—´çš„å·®å¼‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªå…¨é¢çš„è¯­è¨€å­¦è¯„ä¼°æµç¨‹CLEARï¼Œè¯¥æµç¨‹è¦†ç›–äº†è¯æ±‡ã€å¥æ³•ã€è¯­ä¹‰å’Œè¯­ç”¨å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼Œèƒ½å¤Ÿå¯¹LLMæ”¹å†™åçš„è®ºè¯æ–‡æœ¬è¿›è¡Œç»†è‡´çš„è¯„ä¼°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒCLEARæä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°è§†è§’ï¼Œèƒ½å¤Ÿæ›´æ·±å…¥åœ°äº†è§£LLMåœ¨è®ºè¯æ”¹å†™ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šCLEARè¯„ä¼°æµç¨‹çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) 57ä¸ªæŒ‡æ ‡çš„é€‰æ‹©ï¼šè¿™äº›æŒ‡æ ‡æ¶µç›–äº†è¯æ±‡å¤šæ ·æ€§ã€å¥æ³•å¤æ‚åº¦ã€è¯­ä¹‰ç›¸ä¼¼åº¦ã€è®ºè¯è¿è´¯æ€§ç­‰å¤šä¸ªæ–¹é¢ï¼›2) æŒ‡æ ‡æ˜ å°„åˆ°å››ä¸ªè¯­è¨€å­¦å±‚é¢ï¼šè¿™ç§æ˜ å°„æ–¹å¼ä½¿å¾—è¯„ä¼°ç»“æœæ›´å…·ç»“æ„æ€§å’Œå¯è§£é‡Šæ€§ï¼›3) è¯„ä¼°æµç¨‹çš„æ¨¡å—åŒ–è®¾è®¡ï¼šè¿™ç§è®¾è®¡ä½¿å¾—è¯„ä¼°æµç¨‹æ›´æ˜“äºæ‰©å±•å’Œå®šåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨è®ºè¯æ”¹è¿›ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¸€å®šçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿé€šè¿‡ç¼©çŸ­æ–‡æœ¬ã€å¢åŠ å¹³å‡è¯é•¿å’Œåˆå¹¶å¥å­æ¥æé«˜è®ºè¯çš„è¯´æœåŠ›å’Œè¿è´¯æ€§ã€‚CLEARè¯„ä¼°æµç¨‹èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒLLMåœ¨ä¸åŒè¯­è¨€å­¦å±‚é¢çš„è¡¨ç°å·®å¼‚ï¼Œä¸ºæ”¹è¿›LLMçš„è®ºè¯æ”¹å†™èƒ½åŠ›æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨è®ºè¯ç”Ÿæˆã€æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰é¢†åŸŸã€‚é€šè¿‡è¯„ä¼°å’Œæ”¹è¿›LLMçš„è®ºè¯æ”¹å†™èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨åŒ–è®ºè¯ç³»ç»Ÿçš„è´¨é‡å’Œå¯é æ€§ï¼Œè¾…åŠ©å†³ç­–åˆ¶å®šï¼Œå¹¶ä¿ƒè¿›æ›´æœ‰æ•ˆçš„æ²Ÿé€šã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ–‡æœ¬æ”¹å†™ä»»åŠ¡ï¼Œå¹¶åº”ç”¨äºæ•™è‚²ã€æ³•å¾‹ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While LLMs have been extensively studied on general text generation tasks, there is less research on text rewriting, a task related to general text generation, and particularly on the behavior of models on this task. In this paper we analyze what changes LLMs make in a text rewriting setting. We focus specifically on argumentative texts and their improvement, a task named Argument Improvement (ArgImp). We present CLEAR: an evaluation pipeline consisting of 57 metrics mapped to four linguistic levels: lexical, syntactic, semantic and pragmatic. This pipeline is used to examine the qualities of LLM-rewritten arguments on a broad set of argumentation corpora and compare the behavior of different LLMs on this task and analyze the behavior of different LLMs on this task in terms of linguistic levels. By taking all four linguistic levels into consideration, we find that the models perform ArgImp by shortening the texts while simultaneously increasing average word length and merging sentences. Overall we note an increase in the persuasion and coherence dimensions.

