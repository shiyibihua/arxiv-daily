---
layout: default
title: HARNESS: Lightweight Distilled Arabic Speech Foundation Models
---

# HARNESS: Lightweight Distilled Arabic Speech Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14689" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14689v1</a>
  <a href="https://arxiv.org/pdf/2509.14689.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14689v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14689v1', 'HARNESS: Lightweight Distilled Arabic Speech Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vrunda N. sukhadia, Shammur Absar Chowdhury

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: 5 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³åŸºç¡€æ¨¡å‹HArnESSï¼Œè§£å†³èµ„æºå—é™åœºæ™¯ä¸‹çš„éƒ¨ç½²éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³è¯†åˆ«` `è‡ªç›‘ç£å­¦ä¹ ` `çŸ¥è¯†è’¸é¦` `è½»é‡çº§æ¨¡å‹` `ä½ç§©è¿‘ä¼¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹é¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹æ€§èƒ½ä¼˜å¼‚ï¼Œä½†éƒ¨ç½²åœ¨èµ„æºå—é™ç¯å¢ƒä¸­ä¸åˆ‡å®é™…ï¼Œå­˜åœ¨éƒ¨ç½²éš¾é¢˜ã€‚
2. é‡‡ç”¨è¿­ä»£è‡ªè’¸é¦æ–¹æ³•ï¼Œå°†å¤§å‹åŒè¯­æ¨¡å‹çŸ¥è¯†æç‚¼åˆ°å°å‹å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œä¿ç•™é˜¿æ‹‰ä¼¯è¯­ç‰¹å®šè¡¨ç¤ºã€‚
3. åœ¨é˜¿æ‹‰ä¼¯è¯­ASRã€SERå’ŒDIDä»»åŠ¡ä¸Šï¼ŒHArnESSè¡¨ç°å‡ºä¼˜äºHuBERTå’ŒXLS-Rçš„æ€§èƒ½ï¼Œä¸”å¾®è°ƒæˆæœ¬ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»HArnESSï¼Œé¦–ä¸ªä»¥é˜¿æ‹‰ä¼¯è¯­ä¸ºä¸­å¿ƒçš„è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹ç³»åˆ—ï¼Œæ—¨åœ¨æ•æ‰é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³çš„ç»†å¾®å·®åˆ«ã€‚é€šè¿‡è¿­ä»£è‡ªè’¸é¦ï¼Œæˆ‘ä»¬è®­ç»ƒäº†å¤§å‹åŒè¯­HArnESS (HL) SSLæ¨¡å‹ï¼Œç„¶åå°†çŸ¥è¯†æç‚¼åˆ°å‹ç¼©çš„å­¦ç”Ÿæ¨¡å‹(HS, HST)ä¸­ï¼Œä¿ç•™äº†é˜¿æ‹‰ä¼¯è¯­ç‰¹å®šçš„è¡¨ç¤ºã€‚æˆ‘ä»¬ä½¿ç”¨ä½ç§©è¿‘ä¼¼è¿›ä¸€æ­¥å°†æ•™å¸ˆçš„ç¦»æ•£ç›‘ç£å‹ç¼©åˆ°æµ…å±‚ã€è–„æ¨¡å‹ä¸­ã€‚æˆ‘ä»¬åœ¨é˜¿æ‹‰ä¼¯è¯­ASRã€è¯´è¯äººæƒ…æ„Ÿè¯†åˆ«(SER)å’Œæ–¹è¨€è¯†åˆ«(DID)ä¸Šè¯„ä¼°äº†HArnESSï¼Œè¯æ˜äº†å…¶ç›¸å¯¹äºHuBERTå’ŒXLS-Rçš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡æœ€å°çš„å¾®è°ƒï¼ŒHArnESSå®ç°äº†SOTAæˆ–å¯æ¯”çš„æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºå®é™…åº”ç”¨ä¸­è½»é‡çº§ä½†åŠŸèƒ½å¼ºå¤§çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬å‘å¸ƒäº†æˆ‘ä»¬çš„è’¸é¦æ¨¡å‹å’Œç ”ç©¶ç»“æœï¼Œä»¥æ”¯æŒä½èµ„æºç¯å¢ƒä¸­çš„è´Ÿè´£ä»»ç ”ç©¶å’Œéƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹é¢„è®­ç»ƒè¯­éŸ³æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºæ¨¡å‹ä½“ç§¯åºå¤§ï¼Œè®¡ç®—èµ„æºéœ€æ±‚é«˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡æˆ–åµŒå…¥å¼ç³»ç»Ÿã€‚é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­è¯­éŸ³ï¼Œç¼ºä¹ä¸“é—¨ä¼˜åŒ–çš„è½»é‡çº§æ¨¡å‹ï¼Œç°æœ‰æ¨¡å‹éš¾ä»¥æ•æ‰é˜¿æ‹‰ä¼¯è¯­çš„è¯­éŸ³ç‰¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªè’¸é¦æŠ€æœ¯ï¼Œå°†å¤§å‹æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°å°å‹å­¦ç”Ÿæ¨¡å‹ä¸­ï¼Œä»è€Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°æ¨¡å‹ä½“ç§¯ã€‚é€šè¿‡è¿­ä»£è’¸é¦ï¼Œé€æ­¥æå‡å­¦ç”Ÿæ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶åˆ©ç”¨ä½ç§©è¿‘ä¼¼è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHArnESSçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) é¢„è®­ç»ƒå¤§å‹åŒè¯­æ•™å¸ˆæ¨¡å‹(HL)ï¼Œè¯¥æ¨¡å‹åœ¨å¤§é‡é˜¿æ‹‰ä¼¯è¯­å’Œè‹±è¯­è¯­éŸ³æ•°æ®ä¸Šè¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ã€‚2) è¿­ä»£è‡ªè’¸é¦ï¼Œä½¿ç”¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆä¼ªæ ‡ç­¾ï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹(HS, HST)çš„è®­ç»ƒã€‚3) ä½ç§©è¿‘ä¼¼ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ•™å¸ˆæ¨¡å‹çš„ç¦»æ•£ç›‘ç£ä¿¡æ¯ï¼Œå¾—åˆ°æ›´è½»é‡çº§çš„æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†é¦–ä¸ªä»¥é˜¿æ‹‰ä¼¯è¯­ä¸ºä¸­å¿ƒçš„è‡ªç›‘ç£è¯­éŸ³æ¨¡å‹å®¶æ—HArnESSã€‚2) é‡‡ç”¨äº†è¿­ä»£è‡ªè’¸é¦çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°å°†å¤§å‹æ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°å°å‹æ¨¡å‹ä¸­ï¼ŒåŒæ—¶ä¿ç•™äº†é˜¿æ‹‰ä¼¯è¯­çš„è¯­éŸ³ç‰¹æ€§ã€‚3) ä½¿ç”¨ä½ç§©è¿‘ä¼¼è¿›ä¸€æ­¥å‹ç¼©æ¨¡å‹ï¼Œå®ç°äº†æ›´é«˜çš„å‹ç¼©ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‡ªè’¸é¦è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†KLæ•£åº¦æŸå¤±å‡½æ•°æ¥è¡¡é‡å­¦ç”Ÿæ¨¡å‹å’Œæ•™å¸ˆæ¨¡å‹è¾“å‡ºåˆ†å¸ƒçš„å·®å¼‚ã€‚ä½ç§©è¿‘ä¼¼é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£(SVD)æ¥é™ä½æ¨¡å‹å‚æ•°çš„ç»´åº¦ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼ˆä¾‹å¦‚ï¼Œè’¸é¦è¿­ä»£æ¬¡æ•°ã€ä½ç§©è¿‘ä¼¼çš„ç§©ï¼‰éœ€è¦æ ¹æ®å®éªŒç»“æœè¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HArnESSåœ¨é˜¿æ‹‰ä¼¯è¯­ASRã€SERå’ŒDIDä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚åœ¨ASRä»»åŠ¡ä¸Šï¼ŒHArnESSåœ¨ä¿æŒè¾ƒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œæ¨¡å‹ä½“ç§¯è¿œå°äºHuBERTå’ŒXLS-Rã€‚åœ¨SERå’ŒDIDä»»åŠ¡ä¸Šï¼ŒHArnESSä¹Ÿå–å¾—äº†SOTAæˆ–å¯æ¯”çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨ä¸åŒè¯­éŸ³ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡æœ€å°çš„å¾®è°ƒï¼ŒHArnESSå³å¯è¾¾åˆ°ä¼˜å¼‚çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HArnESSæ¨¡å‹å¯å¹¿æ³›åº”ç”¨äºé˜¿æ‹‰ä¼¯è¯­è¯­éŸ³ç›¸å…³çš„å„ç§åº”ç”¨åœºæ™¯ï¼Œå¦‚è¯­éŸ³åŠ©æ‰‹ã€æ™ºèƒ½å®¢æœã€è¯­éŸ³æœç´¢ã€æƒ…æ„Ÿåˆ†æã€æ–¹è¨€è¯†åˆ«ç­‰ã€‚å…¶è½»é‡çº§çš„ç‰¹æ€§ä½¿å…¶éå¸¸é€‚åˆåœ¨ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿç­‰èµ„æºå—é™çš„ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œä¸ºé˜¿æ‹‰ä¼¯è¯­åœ°åŒºçš„è¯­éŸ³æŠ€æœ¯å‘å±•æä¾›äº†æœ‰åŠ›æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„æœªæ¥å‘å±•å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large pre-trained speech models excel in downstream tasks but their deployment is impractical for resource-limited environments. In this paper, we introduce HArnESS, the first Arabic-centric self-supervised speech model family, designed to capture Arabic speech nuances. Using iterative self-distillation, we train large bilingual HArnESS (HL) SSL models and then distill knowledge into compressed student models (HS, HST), preserving Arabic-specific representations. We use low-rank approximation to further compact the teacher's discrete supervision into shallow, thin models. We evaluate HArnESS on Arabic ASR, Speaker Emotion Recognition (SER), and Dialect Identification (DID), demonstrating effectiveness against HuBERT and XLS-R. With minimal fine-tuning, HArnESS achieves SOTA or comparable performance, making it a lightweight yet powerful alternative for real-world use. We release our distilled models and findings to support responsible research and deployment in low-resource settings.

