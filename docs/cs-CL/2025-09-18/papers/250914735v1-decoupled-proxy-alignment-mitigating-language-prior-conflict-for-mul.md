---
layout: default
title: Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM
---

# Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14735" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14735v1</a>
  <a href="https://arxiv.org/pdf/2509.14735.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14735v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14735v1', 'Decoupled Proxy Alignment: Mitigating Language Prior Conflict for Multimodal Alignment in MLLM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenkun Tan, Pengyu Wang, Shaojun Zhou, Botian Jiang, Zhaowei Li, Dong Zhang, Xinghao Wang, Yaqian Zhou, Xipeng Qiu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: Accepted by Findings of EMNLP2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/fnlp-vision/DPA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§£è€¦ä»£ç†å¯¹é½(DPA)æ–¹æ³•ï¼Œç¼“è§£MLLMä¸­è¯­è¨€å…ˆéªŒå†²çªï¼Œæå‡è§†è§‰-è¯­è¨€å¯¹é½æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è§†è§‰-è¯­è¨€å¯¹é½` `è¯­è¨€å…ˆéªŒå†²çª` `è§£è€¦ä»£ç†å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLLMè®­ç»ƒæ˜“å—è®­ç»ƒæ•°æ®é›†ä¸­è¯­è¨€é£æ ¼çš„å½±å“ï¼Œå¯¼è‡´è¯­è¨€å…ˆéªŒå†²çªï¼Œé˜»ç¢äº†è§†è§‰-è¯­è¨€çš„æœ‰æ•ˆå¯¹é½ã€‚
2. DPAæ–¹æ³•é€šè¿‡å¼•å…¥ä»£ç†LLMè§£è€¦å¯¹é½è¿‡ç¨‹ï¼Œå¹¶åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡ï¼Œä»è€Œç¼“è§£è¯­è¨€å…ˆéªŒå†²çªã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDPAåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹¶å±•ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)å› å…¶æ•´åˆè§†è§‰å’Œè¯­è¨€æ¨¡æ€çš„å¼ºå¤§èƒ½åŠ›è€Œå¤‡å—å…³æ³¨ã€‚æœ€è¿‘MLLMçš„è¿›å±•ä¸»è¦é›†ä¸­äºé€šè¿‡é«˜è´¨é‡æ•°æ®é›†ã€æ–°é¢–æ¶æ„å’Œä¼˜åŒ–è®­ç»ƒç­–ç•¥æ¥æé«˜æ€§èƒ½ã€‚ç„¶è€Œï¼Œæœ¬æ–‡å‘ç°äº†ä¸€ä¸ªå…ˆå‰è¢«å¿½è§†çš„é—®é¢˜ï¼Œå³è¯­è¨€å…ˆéªŒå†²çªï¼Œè¿™æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹(LLM)å›ºæœ‰çš„è¯­è¨€å…ˆéªŒä¸è®­ç»ƒæ•°æ®é›†ä¸­è¯­è¨€å…ˆéªŒä¹‹é—´çš„ä¸åŒ¹é…ã€‚è¿™ç§å†²çªå¯¼è‡´æ¬¡ä¼˜çš„è§†è§‰-è¯­è¨€å¯¹é½ï¼Œå› ä¸ºMLLMå®¹æ˜“é€‚åº”è®­ç»ƒæ ·æœ¬çš„è¯­è¨€é£æ ¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºè§£è€¦ä»£ç†å¯¹é½(DPA)çš„æ–°å‹è®­ç»ƒæ–¹æ³•ã€‚DPAå¼•å…¥äº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1)åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨ä»£ç†LLMï¼Œå°†è§†è§‰-è¯­è¨€å¯¹é½è¿‡ç¨‹ä¸è¯­è¨€å…ˆéªŒå¹²æ‰°è§£è€¦ï¼Œä»¥åŠ(2)åŸºäºè§†è§‰ç›¸å…³æ€§çš„åŠ¨æ€æŸå¤±è°ƒæ•´ï¼Œä»¥åŠ å¼ºè§†è§‰ç›¸å…³tokençš„ä¼˜åŒ–ä¿¡å·ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDPAæ˜¾è‘—ç¼“è§£äº†è¯­è¨€å…ˆéªŒå†²çªï¼Œåœ¨ä¸åŒçš„æ•°æ®é›†ã€æ¨¡å‹å®¶æ—å’Œè§„æ¨¡ä¸Šå®ç°äº†å“è¶Šçš„å¯¹é½æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…æé«˜äº†MLLMè®­ç»ƒçš„æœ‰æ•ˆæ€§ï¼Œè€Œä¸”è¡¨ç°å‡ºå“è¶Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶æˆä¸ºä¸€ç§é²æ£’çš„è§†è§‰-è¯­è¨€å¯¹é½æ–¹æ³•ã€‚ä»£ç å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)è®­ç»ƒä¸­å­˜åœ¨çš„è¯­è¨€å…ˆéªŒå†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç›´æ¥ä½¿ç”¨LLMè¿›è¡Œè§†è§‰-è¯­è¨€å¯¹é½ï¼Œä½†LLMå›ºæœ‰çš„è¯­è¨€å…ˆéªŒä¸è®­ç»ƒæ•°æ®çš„è¯­è¨€å…ˆéªŒå¯èƒ½å­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´MLLMè¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®çš„è¯­è¨€é£æ ¼ï¼Œä»è€Œå½±å“è§†è§‰-è¯­è¨€å¯¹é½çš„å‡†ç¡®æ€§ã€‚è¿™ç§å†²çªé˜»ç¢äº†MLLMå……åˆ†åˆ©ç”¨è§†è§‰ä¿¡æ¯ï¼Œé™åˆ¶äº†å…¶æ€§èƒ½çš„è¿›ä¸€æ­¥æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§£è€¦è§†è§‰-è¯­è¨€å¯¹é½è¿‡ç¨‹ä¸è¯­è¨€å…ˆéªŒå¹²æ‰°æ¥ç¼“è§£è¯­è¨€å…ˆéªŒå†²çªã€‚å…·ä½“è€Œè¨€ï¼Œå¼•å…¥ä¸€ä¸ªä»£ç†LLMï¼Œè¯¥ä»£ç†LLMçš„è¯­è¨€å…ˆéªŒä¸ç›®æ ‡LLMä¸åŒï¼Œç”¨äºåœ¨é¢„è®­ç»ƒé˜¶æ®µè¿›è¡Œè§†è§‰-è¯­è¨€å¯¹é½ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥é¿å…ç›®æ ‡LLMç›´æ¥æš´éœ²äºè®­ç»ƒæ•°æ®çš„è¯­è¨€é£æ ¼ï¼Œä»è€Œå‡å°‘è¯­è¨€å…ˆéªŒå†²çªçš„å½±å“ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºåŠ¨æ€æŸå¤±è°ƒæ•´ç­–ç•¥ï¼Œæ ¹æ®è§†è§‰ç›¸å…³æ€§è°ƒæ•´æŸå¤±æƒé‡ï¼Œä»¥åŠ å¼ºè§†è§‰ç›¸å…³tokençš„ä¼˜åŒ–ä¿¡å·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDPAæ–¹æ³•çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½¿ç”¨ä»£ç†LLMè¿›è¡Œè§†è§‰-è¯­è¨€é¢„è®­ç»ƒï¼Œç”Ÿæˆè§†è§‰ç‰¹å¾å’Œè¯­è¨€tokençš„å¯¹é½è¡¨ç¤ºï¼›2) å°†å¯¹é½è¡¨ç¤ºè¾“å…¥åˆ°ç›®æ ‡LLMä¸­è¿›è¡Œå¾®è°ƒï¼›3) åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨åŠ¨æ€æŸå¤±è°ƒæ•´ç­–ç•¥ï¼Œæ ¹æ®è§†è§‰ç›¸å…³æ€§è°ƒæ•´æŸå¤±æƒé‡ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ¨¡å—åŒ…æ‹¬ä»£ç†LLMã€ç›®æ ‡LLMå’ŒåŠ¨æ€æŸå¤±è°ƒæ•´æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šDPAæ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè§£è€¦ä»£ç†å¯¹é½çš„æ€æƒ³ã€‚ä¸ç°æœ‰æ–¹æ³•ç›´æ¥ä½¿ç”¨ç›®æ ‡LLMè¿›è¡Œè§†è§‰-è¯­è¨€å¯¹é½ä¸åŒï¼ŒDPAæ–¹æ³•å¼•å…¥ä»£ç†LLMï¼Œå°†è§†è§‰-è¯­è¨€å¯¹é½è¿‡ç¨‹ä¸è¯­è¨€å…ˆéªŒå¹²æ‰°è§£è€¦ã€‚è¿™ç§è§£è€¦ç­–ç•¥å¯ä»¥æœ‰æ•ˆç¼“è§£è¯­è¨€å…ˆéªŒå†²çªï¼Œæé«˜è§†è§‰-è¯­è¨€å¯¹é½çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€æŸå¤±è°ƒæ•´ç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒå¯ä»¥åŠ å¼ºè§†è§‰ç›¸å…³tokençš„ä¼˜åŒ–ä¿¡å·ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DPAæ–¹æ³•ä¸­ï¼Œä»£ç†LLMçš„é€‰æ‹©æ˜¯ä¸€ä¸ªå…³é”®è®¾è®¡ã€‚è®ºæ–‡å»ºè®®é€‰æ‹©ä¸ç›®æ ‡LLMå…·æœ‰ä¸åŒè¯­è¨€å…ˆéªŒçš„LLMä½œä¸ºä»£ç†LLMã€‚åŠ¨æ€æŸå¤±è°ƒæ•´ç­–ç•¥çš„å…·ä½“å®ç°æ–¹å¼æ˜¯ï¼šé¦–å…ˆè®¡ç®—æ¯ä¸ªtokençš„è§†è§‰ç›¸å…³æ€§å¾—åˆ†ï¼Œç„¶åæ ¹æ®è¯¥å¾—åˆ†è°ƒæ•´æŸå¤±æƒé‡ã€‚è§†è§‰ç›¸å…³æ€§å¾—åˆ†å¯ä»¥é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æˆ–å…¶ä»–æ–¹æ³•è®¡ç®—ã€‚æŸå¤±å‡½æ•°çš„å…·ä½“å½¢å¼å¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œé€‰æ‹©ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±æˆ–å¯¹æ¯”æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDPAæ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨è§†è§‰é—®ç­”ä»»åŠ¡ä¸Šï¼ŒDPAæ–¹æ³•ç›¸æ¯”åŸºçº¿æ–¹æ³•æå‡äº†5%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒDPAæ–¹æ³•åœ¨ä¸åŒçš„æ¨¡å‹å®¶æ—å’Œè§„æ¨¡ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶é²æ£’æ€§å’Œæœ‰æ•ˆæ€§ã€‚ä»£ç å·²å¼€æºï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜å¤ç°å’Œè¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå¤šæ¨¡æ€ç†è§£å’Œç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒæè¿°ã€è§†è§‰é—®ç­”ã€è§†é¢‘ç†è§£ç­‰ã€‚é€šè¿‡æå‡MLLMçš„è§†è§‰-è¯­è¨€å¯¹é½èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è¿™äº›ä»»åŠ¡çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œå¹¶åšå‡ºæ›´å‡†ç¡®çš„å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨å¤šæ¨¡æ€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have gained significant attention due to their impressive ability to integrate vision and language modalities. Recent advancements in MLLMs have primarily focused on improving performance through high-quality datasets, novel architectures, and optimized training strategies. However, in this paper, we identify a previously overlooked issue, language prior conflict, a mismatch between the inherent language priors of large language models (LLMs) and the language priors in training datasets. This conflict leads to suboptimal vision-language alignment, as MLLMs are prone to adapting to the language style of training samples. To address this issue, we propose a novel training method called Decoupled Proxy Alignment (DPA). DPA introduces two key innovations: (1) the use of a proxy LLM during pretraining to decouple the vision-language alignment process from language prior interference, and (2) dynamic loss adjustment based on visual relevance to strengthen optimization signals for visually relevant tokens. Extensive experiments demonstrate that DPA significantly mitigates the language prior conflict, achieving superior alignment performance across diverse datasets, model families, and scales. Our method not only improves the effectiveness of MLLM training but also shows exceptional generalization capabilities, making it a robust approach for vision-language alignment. Our code is available at https://github.com/fnlp-vision/DPA.

