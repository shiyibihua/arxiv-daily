---
layout: default
title: Reveal and Release: Iterative LLM Unlearning with Self-generated Data
---

# Reveal and Release: Iterative LLM Unlearning with Self-generated Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14624" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14624v1</a>
  <a href="https://arxiv.org/pdf/2509.14624.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14624v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14624v1', 'Reveal and Release: Iterative LLM Unlearning with Self-generated Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linxi Xie, Xin Teng, Shichang Ke, Hongyi Wen, Shengjie Wang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: Accepted to EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReveal-and-Releaseè¿­ä»£æ¡†æ¶ï¼Œåˆ©ç”¨è‡ªç”Ÿæˆæ•°æ®å®ç°å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆä¸å¯å­¦ä¹ ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ä¸å¯å­¦ä¹ ` `è‡ªç”Ÿæˆæ•°æ®` `éšç§ä¿æŠ¤` `è¿­ä»£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMä¸å¯å­¦ä¹ æ–¹æ³•ä¾èµ–å®Œæ•´é—å¿˜æ•°æ®é›†ï¼Œä½†å®é™…ä¸­æ•°æ®å¸¸å› éšç§ã€ç¨€ç¼ºæ€§ç­‰é—®é¢˜éš¾ä»¥è·å–ã€‚
2. æå‡ºReveal-and-Releaseæ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æŒ‡ä»¤æç¤ºLLMè‡ªç”Ÿæˆé—å¿˜æ•°æ®ï¼Œè§£å†³æ•°æ®è·å–éš¾é¢˜ã€‚
3. æ„å»ºè¿­ä»£ä¸å¯å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨å‚æ•°é«˜æ•ˆæ¨¡å—åœ¨è‡ªç”Ÿæˆæ•°æ®ä¸Šå¾®è°ƒï¼Œå¹³è¡¡é—å¿˜è´¨é‡ä¸æ¨¡å‹æ•ˆç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸å¯å­¦ä¹ æ—¨åœ¨æ¶ˆé™¤æ¨¡å‹å—ä¸è‰¯æ•°æ®ï¼ˆåˆç§°é—å¿˜æ•°æ®ï¼‰çš„å½±å“ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾å¯ä»¥å®Œå…¨è®¿é—®é—å¿˜æ•°æ®é›†ï¼Œä½†å¿½ç•¥äº†ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰é—å¿˜æ•°æ®é€šå¸¸å¯¹éšç§æ•æ„Ÿã€ç¨€æœ‰æˆ–å—æ³•å¾‹ç›‘ç®¡ï¼Œä½¿å¾—è·å–æˆæœ¬é«˜æ˜‚æˆ–ä¸åˆ‡å®é™…ï¼›ï¼ˆ2ï¼‰å¯ç”¨é—å¿˜æ•°æ®çš„åˆ†å¸ƒå¯èƒ½ä¸è¯¥ä¿¡æ¯åœ¨æ¨¡å‹ä¸­çš„è¡¨ç¤ºæ–¹å¼ä¸ä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§â€œReveal-and-Releaseâ€æ–¹æ³•ï¼Œé€šè¿‡è‡ªç”Ÿæˆæ•°æ®è¿›è¡Œä¸å¯å­¦ä¹ ï¼Œå…¶ä¸­æˆ‘ä»¬ä½¿ç”¨ä¼˜åŒ–çš„æŒ‡ä»¤æç¤ºæ¨¡å‹æ­ç¤ºå®ƒæ‰€çŸ¥é“çš„å†…å®¹ã€‚ä¸ºäº†å……åˆ†åˆ©ç”¨è‡ªç”Ÿæˆçš„é—å¿˜æ•°æ®ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè¿­ä»£ä¸å¯å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡åœ¨é—å¿˜æ•°æ®ä¸Šè®­ç»ƒçš„å‚æ•°é«˜æ•ˆæ¨¡å—ï¼Œå¯¹æ¨¡å‹çš„æƒé‡ç©ºé—´è¿›è¡Œå¢é‡è°ƒæ•´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å¹³è¡¡äº†é—å¿˜è´¨é‡å’Œæ•ˆç”¨ä¿æŒä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹ä¸å¯å­¦ä¹ æ–¹æ³•é€šå¸¸éœ€è¦è®¿é—®å®Œæ•´çš„é—å¿˜æ•°æ®é›†ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ã€‚é—å¿˜æ•°æ®å¯èƒ½æ¶‰åŠç”¨æˆ·éšç§ï¼Œè·å–æˆæœ¬é«˜æ˜‚ï¼Œæˆ–è€…å—åˆ°æ³•å¾‹æ³•è§„çš„é™åˆ¶ã€‚æ­¤å¤–ï¼Œå³ä½¿èƒ½å¤Ÿè·å–åˆ°é—å¿˜æ•°æ®ï¼Œå…¶åˆ†å¸ƒä¹Ÿå¯èƒ½ä¸æ¨¡å‹å†…éƒ¨çŸ¥è¯†çš„è¡¨ç¤ºæ–¹å¼å­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´ä¸å¯å­¦ä¹ æ•ˆæœä¸ä½³ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ç¼ºä¹æˆ–éš¾ä»¥è·å–çœŸå®é—å¿˜æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆåœ°å®ç°å¤§è¯­è¨€æ¨¡å‹çš„ä¸å¯å­¦ä¹ ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªèº«çš„ç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯­ï¼ˆPromptï¼‰ï¼Œå¼•å¯¼æ¨¡å‹â€œæ­ç¤ºâ€ï¼ˆRevealï¼‰å…¶æ‰€æŒæ¡çš„å…³äºé—å¿˜æ•°æ®çš„ä¿¡æ¯ï¼Œç„¶åå°†è¿™äº›è‡ªç”Ÿæˆçš„æ•°æ®â€œé‡Šæ”¾â€ï¼ˆReleaseï¼‰å‡ºæ¥ï¼Œä½œä¸ºåç»­ä¸å¯å­¦ä¹ è¿‡ç¨‹çš„è®­ç»ƒæ•°æ®ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ç›´æ¥è®¿é—®æ•æ„Ÿæˆ–éš¾ä»¥è·å–çš„çœŸå®é—å¿˜æ•°æ®ï¼Œé™ä½äº†æ•°æ®è·å–çš„æˆæœ¬å’Œé£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨è¿­ä»£çš„ä¸å¯å­¦ä¹ æ¡†æ¶ã€‚é¦–å…ˆï¼Œä½¿ç”¨ä¼˜åŒ–çš„æŒ‡ä»¤æç¤ºå¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶ç”Ÿæˆé—å¿˜æ•°æ®ã€‚ç„¶åï¼Œåˆ©ç”¨è¿™äº›è‡ªç”Ÿæˆçš„æ•°æ®ï¼Œè®­ç»ƒå‚æ•°é«˜æ•ˆçš„æ¨¡å—ï¼ˆå¦‚Adapteræˆ–LoRAï¼‰ã€‚è¿™äº›æ¨¡å—è¢«ç”¨æ¥å¯¹åŸå§‹æ¨¡å‹çš„æƒé‡è¿›è¡Œå¾®è°ƒï¼Œä»è€Œé€æ­¥æ¶ˆé™¤æ¨¡å‹ä¸­ä¸é—å¿˜æ•°æ®ç›¸å…³çš„çŸ¥è¯†ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥è¿­ä»£å¤šæ¬¡ï¼Œæ¯æ¬¡è¿­ä»£éƒ½ä½¿ç”¨æ–°ç”Ÿæˆçš„é—å¿˜æ•°æ®ï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œå¾®å°çš„è°ƒæ•´ï¼Œç›´åˆ°è¾¾åˆ°é¢„æœŸçš„ä¸å¯å­¦ä¹ æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªèº«çš„ç”Ÿæˆèƒ½åŠ›æ¥æ„å»ºé—å¿˜æ•°æ®é›†ã€‚ä¸ä¼ ç»Ÿçš„ä¾èµ–å¤–éƒ¨æ•°æ®é›†çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§è‡ªç”Ÿæˆæ•°æ®çš„æ–¹æ³•æ›´åŠ çµæ´»ï¼Œå¯ä»¥æ ¹æ®éœ€è¦ç”Ÿæˆç‰¹å®šç±»å‹çš„é—å¿˜æ•°æ®ï¼Œå¹¶ä¸”é¿å…äº†éšç§æ³„éœ²çš„é£é™©ã€‚æ­¤å¤–ï¼Œè¿­ä»£çš„ä¸å¯å­¦ä¹ æ¡†æ¶å…è®¸é€æ­¥åœ°è°ƒæ•´æ¨¡å‹çš„æƒé‡ï¼Œä»è€Œåœ¨é—å¿˜è´¨é‡å’Œæ¨¡å‹æ•ˆç”¨ä¹‹é—´å–å¾—æ›´å¥½çš„å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä¼˜åŒ–çš„æŒ‡ä»¤è®¾è®¡ï¼šè®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡é—å¿˜æ•°æ®çš„æç¤ºè¯­ï¼Œä¾‹å¦‚ä½¿ç”¨å¯¹æŠ—æ€§çš„æé—®æ–¹å¼ã€‚2) å‚æ•°é«˜æ•ˆæ¨¡å—çš„é€‰æ‹©ï¼šé€‰æ‹©åˆé€‚çš„å‚æ•°é«˜æ•ˆæ¨¡å—ï¼ˆå¦‚Adapteræˆ–LoRAï¼‰ï¼Œä»¥ä¾¿åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­åªä¿®æ”¹å°‘é‡å‚æ•°ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬å¹¶ä¿æŒæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚3) è¿­ä»£æ¬¡æ•°çš„ç¡®å®šï¼šé€šè¿‡å®éªŒç¡®å®šåˆé€‚çš„è¿­ä»£æ¬¡æ•°ï¼Œä»¥åœ¨é—å¿˜è´¨é‡å’Œæ¨¡å‹æ•ˆç”¨ä¹‹é—´å–å¾—æœ€ä½³å¹³è¡¡ã€‚4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼šå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œæ¥è®­ç»ƒå‚æ•°é«˜æ•ˆæ¨¡å—ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¶ˆé™¤æ¨¡å‹ä¸­ä¸é—å¿˜æ•°æ®ç›¸å…³çš„çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¹³è¡¡é—å¿˜è´¨é‡å’Œæ•ˆç”¨ä¿æŒæ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æœ‰æ•ˆæ¶ˆé™¤æ¨¡å‹ä¸­ä¸é—å¿˜æ•°æ®ç›¸å…³çš„çŸ¥è¯†çš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°ä¿æŒæ¨¡å‹åœ¨å…¶ä»–ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æŸäº›æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œä¾‹å¦‚ï¼Œåœ¨é—å¿˜ç‡æ–¹é¢æé«˜äº†X%ï¼Œè€Œåœ¨æ¨¡å‹å‡†ç¡®ç‡æ–¹é¢ä»…ä¸‹é™äº†Y%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¯ä¸€ç§æœ‰æ•ˆçš„ã€å®ç”¨çš„LLMä¸å¯å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§åœºæ™¯ï¼Œä¾‹å¦‚ï¼šä¿æŠ¤ç”¨æˆ·éšç§ï¼Œé˜²æ­¢æ¨¡å‹æ³„éœ²æ•æ„Ÿä¿¡æ¯ï¼›éµå®ˆæ³•å¾‹æ³•è§„ï¼Œç§»é™¤æ¨¡å‹ä¸­ä¸åˆè§„çš„å†…å®¹ï¼›æé«˜æ¨¡å‹å®‰å…¨æ€§ï¼Œé˜²æ­¢æ¨¡å‹è¢«æ¶æ„åˆ©ç”¨ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæ¨¡å‹çš„ä¸ªæ€§åŒ–å®šåˆ¶ï¼Œç§»é™¤æ¨¡å‹ä¸­ä¸ç‰¹å®šç”¨æˆ·æ— å…³çš„çŸ¥è¯†ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨é‡‘èã€åŒ»ç–—ã€æ•™è‚²ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language model (LLM) unlearning has demonstrated effectiveness in removing the influence of undesirable data (also known as forget data). Existing approaches typically assume full access to the forget dataset, overlooking two key challenges: (1) Forget data is often privacy-sensitive, rare, or legally regulated, making it expensive or impractical to obtain (2) The distribution of available forget data may not align with how that information is represented within the model. To address these limitations, we propose a ``Reveal-and-Release'' method to unlearn with self-generated data, where we prompt the model to reveal what it knows using optimized instructions. To fully utilize the self-generated forget data, we propose an iterative unlearning framework, where we make incremental adjustments to the model's weight space with parameter-efficient modules trained on the forget data. Experimental results demonstrate that our method balances the tradeoff between forget quality and utility preservation.

