---
layout: default
title: V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models
---

# V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14837" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14837v1</a>
  <a href="https://arxiv.org/pdf/2509.14837.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14837v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14837v1', 'V-SEAM: Visual Semantic Editing and Attention Modulating for Causal Interpretability of Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qidong Wang, Junjie Hu, Ming Jiang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: EMNLP 2025 Main

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/petergit1/V-SEAM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**V-SEAMï¼šé€šè¿‡è§†è§‰è¯­ä¹‰ç¼–è¾‘å’Œæ³¨æ„åŠ›è°ƒåˆ¶æå‡è§†è§‰-è¯­è¨€æ¨¡å‹å› æœå¯è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å› æœå¯è§£é‡Šæ€§` `è§†è§‰è¯­ä¹‰ç¼–è¾‘` `æ³¨æ„åŠ›æœºåˆ¶` `è§†è§‰é—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹å› æœå¯è§£é‡Šæ€§ç ”ç©¶ä¸­ï¼Œè§†è§‰å¹²é¢„é€šå¸¸ä¾èµ–äºç²—ç³™çš„åƒç´ çº§æ‰°åŠ¨ï¼Œé™åˆ¶äº†å¯¹å¤šæ¨¡æ€èåˆçš„è¯­ä¹‰æ´å¯Ÿã€‚
2. V-SEAMæ¡†æ¶é€šè¿‡è§†è§‰è¯­ä¹‰ç¼–è¾‘å®ç°æ¦‚å¿µçº§åˆ«çš„è§†è§‰æ“ä½œï¼Œå¹¶è¯†åˆ«å¯¹é¢„æµ‹æœ‰ç§¯ææˆ–æ¶ˆæè´¡çŒ®çš„æ³¨æ„åŠ›å¤´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒV-SEAMèƒ½å¤Ÿæœ‰æ•ˆæå‡LLaVAå’ŒInstructBLIPåœ¨å¤šä¸ªVQAåŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºV-SEAMçš„æ–°æ¡†æ¶ï¼Œå®ƒç»“åˆäº†è§†è§‰è¯­ä¹‰ç¼–è¾‘å’Œæ³¨æ„åŠ›è°ƒåˆ¶ï¼Œç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„å› æœè§£é‡Šã€‚V-SEAMå®ç°äº†æ¦‚å¿µçº§åˆ«çš„è§†è§‰æ“ä½œï¼Œå¹¶è¯†åˆ«äº†åœ¨å¯¹è±¡ã€å±æ€§å’Œå…³ç³»ä¸‰ä¸ªè¯­ä¹‰å±‚é¢ä¸Šå¯¹é¢„æµ‹æœ‰ç§¯ææˆ–æ¶ˆæè´¡çŒ®çš„æ³¨æ„åŠ›å¤´ã€‚ç ”ç©¶å‘ç°ï¼Œç§¯æçš„å¤´é€šå¸¸åœ¨åŒä¸€è¯­ä¹‰çº§åˆ«å†…å…±äº«ï¼Œä½†åœ¨ä¸åŒçº§åˆ«ä¹‹é—´æœ‰æ‰€ä¸åŒï¼Œè€Œæ¶ˆæçš„å¤´å¾€å¾€å…·æœ‰å¹¿æ³›çš„æ³›åŒ–èƒ½åŠ›ã€‚æœ€åï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§è‡ªåŠ¨è°ƒåˆ¶å…³é”®å¤´åµŒå…¥çš„æ–¹æ³•ï¼Œè¯æ˜äº†åœ¨ä¸‰ä¸ªä¸åŒçš„VQAåŸºå‡†æµ‹è¯•ä¸­ï¼ŒLLaVAå’ŒInstructBLIPçš„æ€§èƒ½å‡å¾—åˆ°äº†æå‡ã€‚æ•°æ®å’Œä»£ç å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯å› æœå¯è§£é‡Šæ€§ï¼Œåœ¨è§†è§‰å¹²é¢„æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚ä»¥å¾€çš„æ–¹æ³•ä¸»è¦ä¾èµ–äºåƒç´ çº§åˆ«çš„æ‰°åŠ¨ï¼Œæ— æ³•æä¾›ç»†ç²’åº¦çš„è¯­ä¹‰å±‚é¢çš„ç†è§£ï¼Œéš¾ä»¥æ´å¯Ÿè§†è§‰å’Œè¯­è¨€ä¿¡æ¯èåˆçš„æœºåˆ¶ã€‚å› æ­¤ï¼Œå¦‚ä½•è¿›è¡Œæ¦‚å¿µçº§åˆ«çš„è§†è§‰å¹²é¢„ï¼Œå¹¶åˆ†æä¸åŒè§†è§‰æ¦‚å¿µå¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šV-SEAMçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§†è§‰è¯­ä¹‰ç¼–è¾‘ï¼Œå®ç°å¯¹å›¾åƒä¸­ä¸åŒæ¦‚å¿µï¼ˆå¯¹è±¡ã€å±æ€§ã€å…³ç³»ï¼‰çš„ç²¾ç¡®æ“ä½œã€‚ç„¶åï¼Œé€šè¿‡åˆ†æä¸åŒæ³¨æ„åŠ›å¤´å¯¹è¿™äº›æ¦‚å¿µæ“ä½œçš„å“åº”ï¼Œè¯†åˆ«å‡ºå¯¹æ¨¡å‹é¢„æµ‹æœ‰é‡è¦å½±å“çš„æ³¨æ„åŠ›å¤´ã€‚æœ€åï¼Œé€šè¿‡è°ƒåˆ¶è¿™äº›å…³é”®æ³¨æ„åŠ›å¤´çš„åµŒå…¥ï¼Œæ¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šV-SEAMæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šè§†è§‰è¯­ä¹‰ç¼–è¾‘æ¨¡å—å’Œæ³¨æ„åŠ›è°ƒåˆ¶æ¨¡å—ã€‚è§†è§‰è¯­ä¹‰ç¼–è¾‘æ¨¡å—è´Ÿè´£å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ¦‚å¿µçº§åˆ«çš„ä¿®æ”¹ï¼Œä¾‹å¦‚æ·»åŠ æˆ–åˆ é™¤ç‰¹å®šå¯¹è±¡ï¼Œæ”¹å˜å¯¹è±¡çš„å±æ€§ï¼Œæˆ–è€…ä¿®æ”¹å¯¹è±¡ä¹‹é—´çš„å…³ç³»ã€‚æ³¨æ„åŠ›è°ƒåˆ¶æ¨¡å—åˆ™è´Ÿè´£åˆ†æä¸åŒæ³¨æ„åŠ›å¤´å¯¹è¿™äº›ä¿®æ”¹çš„å“åº”ï¼Œå¹¶æ ¹æ®å…¶è´¡çŒ®åº¦è¿›è¡Œè°ƒåˆ¶ã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬ï¼š1ï¼‰è¾“å…¥å›¾åƒå’Œæ–‡æœ¬ï¼›2ï¼‰è§†è§‰è¯­ä¹‰ç¼–è¾‘ï¼›3ï¼‰æ¨¡å‹é¢„æµ‹ï¼›4ï¼‰æ³¨æ„åŠ›åˆ†æï¼›5ï¼‰å…³é”®å¤´è¯†åˆ«ï¼›6ï¼‰æ³¨æ„åŠ›è°ƒåˆ¶ï¼›7ï¼‰æ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šV-SEAMæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå®ƒå®ç°äº†æ¦‚å¿µçº§åˆ«çš„è§†è§‰å¹²é¢„ï¼Œå¹¶å°†å…¶ä¸æ³¨æ„åŠ›æœºåˆ¶åˆ†æç›¸ç»“åˆï¼Œä»è€Œèƒ½å¤Ÿæ›´æ·±å…¥åœ°ç†è§£è§†è§‰-è¯­è¨€æ¨¡å‹çš„å†…éƒ¨å·¥ä½œæœºåˆ¶ã€‚ä¸ä»¥å¾€çš„åƒç´ çº§æ‰°åŠ¨æ–¹æ³•ç›¸æ¯”ï¼ŒV-SEAMèƒ½å¤Ÿæä¾›æ›´ç»†ç²’åº¦çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶èƒ½å¤Ÿè¯†åˆ«å‡ºå¯¹ä¸åŒè¯­ä¹‰æ¦‚å¿µæœ‰ä¸åŒè´¡çŒ®çš„æ³¨æ„åŠ›å¤´ã€‚

**å…³é”®è®¾è®¡**ï¼šV-SEAMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰ä½¿ç”¨é¢„è®­ç»ƒçš„è§†è§‰è¯­ä¹‰åˆ†å‰²æ¨¡å‹æ¥å®ç°æ¦‚å¿µçº§åˆ«çš„è§†è§‰ç¼–è¾‘ï¼›2ï¼‰è®¾è®¡äº†ä¸€ç§åŸºäºæ¢¯åº¦çš„æ–¹æ³•æ¥è¯†åˆ«å¯¹é¢„æµ‹æœ‰é‡è¦å½±å“çš„æ³¨æ„åŠ›å¤´ï¼›3ï¼‰æå‡ºäº†ä¸€ç§è‡ªåŠ¨è°ƒåˆ¶å…³é”®å¤´åµŒå…¥çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®æ³¨æ„åŠ›å¤´çš„è´¡çŒ®åº¦æ¥è°ƒæ•´å…¶åµŒå…¥å‘é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒV-SEAMèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¯¹ä¸åŒè¯­ä¹‰æ¦‚å¿µæœ‰ä¸åŒè´¡çŒ®çš„æ³¨æ„åŠ›å¤´ã€‚é€šè¿‡è°ƒåˆ¶å…³é”®å¤´åµŒå…¥ï¼ŒLLaVAå’ŒInstructBLIPåœ¨ä¸‰ä¸ªä¸åŒçš„VQAåŸºå‡†æµ‹è¯•ä¸­å‡è·å¾—äº†æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªVQAåŸºå‡†ä¸Šï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡æå‡äº†è¶…è¿‡2%ã€‚è¿™äº›ç»“æœéªŒè¯äº†V-SEAMçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

V-SEAMçš„ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œä¾‹å¦‚åœ¨åŒ»ç–—å½±åƒè¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶ç­‰å®‰å…¨æ”¸å…³çš„é¢†åŸŸï¼Œå¸®åŠ©äººä»¬ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼Œå¹¶æé«˜æ¨¡å‹çš„å¯ä¿¡åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæ¨¡å‹è°ƒè¯•å’Œä¼˜åŒ–ï¼Œé€šè¿‡è¯†åˆ«å’Œä¿®æ­£æ¨¡å‹ä¸­çš„åå·®ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in causal interpretability have extended from language models to vision-language models (VLMs), seeking to reveal their internal mechanisms through input interventions. While textual interventions often target semantics, visual interventions typically rely on coarse pixel-level perturbations, limiting semantic insights on multimodal integration. In this study, we introduce V-SEAM, a novel framework that combines Visual Semantic Editing and Attention Modulating for causal interpretation of VLMs. V-SEAM enables concept-level visual manipulations and identifies attention heads with positive or negative contributions to predictions across three semantic levels: objects, attributes, and relationships. We observe that positive heads are often shared within the same semantic level but vary across levels, while negative heads tend to generalize broadly. Finally, we introduce an automatic method to modulate key head embeddings, demonstrating enhanced performance for both LLaVA and InstructBLIP across three diverse VQA benchmarks. Our data and code are released at: https://github.com/petergit1/V-SEAM.

