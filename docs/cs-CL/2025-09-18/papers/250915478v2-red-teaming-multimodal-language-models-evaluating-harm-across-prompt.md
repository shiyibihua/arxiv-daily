---
layout: default
title: Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models
---

# Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15478" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15478v2</a>
  <a href="https://arxiv.org/pdf/2509.15478.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15478v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15478v2', 'Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Madison Van Doren, Casey Ford

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-11-21)

**æœŸåˆŠ**: AAAI 2026 AIGOV Workshop and EurIPS 2025 Workshop on Unifying Perspectives on Learning Biases

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**çº¢é˜Ÿè¯„ä¼°å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼šè·¨æ¨¡æ€æç¤ºçš„æœ‰å®³æ€§è¯„ä¼°ä¸æ¨¡å‹å¯¹æ¯”**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§è¯„ä¼°` `çº¢é˜Ÿæµ‹è¯•` `å¯¹æŠ—æ€§æç¤º` `æœ‰å®³æ€§åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—æ€§æ”»å‡»åœºæ™¯ä¸‹ï¼Œæ¨¡å‹å¯èƒ½äº§ç”Ÿæœ‰å®³å†…å®¹ã€‚
2. é€šè¿‡çº¢é˜Ÿç”Ÿæˆå¯¹æŠ—æ€§æç¤ºï¼ŒåŒ…æ‹¬æ–‡æœ¬å’Œå¤šæ¨¡æ€å½¢å¼ï¼Œè¯„ä¼°æ¨¡å‹åœ¨éæ³•æ´»åŠ¨ã€è™šå‡ä¿¡æ¯å’Œä¸é“å¾·è¡Œä¸ºæ–¹é¢çš„å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒæ¨¡å‹å’Œæ¨¡æ€çš„å®‰å…¨æ€§å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œæ–‡æœ¬æç¤ºæœ‰æ—¶æ¯”å¤šæ¨¡æ€æç¤ºæ›´å®¹æ˜“ç»•è¿‡å®‰å…¨æœºåˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†å››ä¸ªé¢†å…ˆçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼šGPT-4oã€Claude Sonnet 3.5ã€Pixtral 12Bå’ŒQwen VL Plusåœ¨å¯¹æŠ—æ€§æç¤ºä¸‹çš„å®‰å…¨æ€§ã€‚ç”±26åçº¢é˜Ÿæˆå‘˜ç”Ÿæˆäº†726ä¸ªæç¤ºï¼Œç›®æ ‡æ˜¯ä¸‰ä¸ªæœ‰å®³ç±»åˆ«ï¼šéæ³•æ´»åŠ¨ã€è™šå‡ä¿¡æ¯å’Œä¸é“å¾·è¡Œä¸ºã€‚è¿™äº›æç¤ºè¢«æäº¤ç»™æ¯ä¸ªæ¨¡å‹ï¼Œå¹¶ç”±17åæ ‡æ³¨å‘˜ä½¿ç”¨5åˆ†åˆ¶è¯„ä¼°äº†2904ä¸ªæ¨¡å‹è¾“å‡ºçš„æœ‰å®³æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œä¸åŒæ¨¡å‹å’Œæ¨¡æ€ä¹‹é—´çš„è„†å¼±æ€§å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚Pixtral 12Bè¡¨ç°å‡ºæœ€é«˜çš„æœ‰å®³å“åº”ç‡ï¼ˆçº¦62%ï¼‰ï¼Œè€ŒClaude Sonnet 3.5æœ€å…·æŠµæŠ—åŠ›ï¼ˆçº¦10%ï¼‰ã€‚ä¸é¢„æœŸç›¸åï¼Œçº¯æ–‡æœ¬æç¤ºåœ¨ç»•è¿‡å®‰å…¨æœºåˆ¶æ–¹é¢ç•¥ä¼˜äºå¤šæ¨¡æ€æç¤ºã€‚ç»Ÿè®¡åˆ†æè¯å®ï¼Œæ¨¡å‹ç±»å‹å’Œè¾“å…¥æ¨¡æ€éƒ½æ˜¯æœ‰å®³æ€§çš„é‡è¦é¢„æµ‹å› ç´ ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†éšç€MLLMçš„å¹¿æ³›éƒ¨ç½²ï¼Œè¿«åˆ‡éœ€è¦ç¨³å¥çš„å¤šæ¨¡æ€å®‰å…¨åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¯¥è®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨é¢å¯¹å¯¹æŠ—æ€§æç¤ºæ—¶ï¼Œæ˜¯å¦ä¼šäº§ç”Ÿæœ‰å®³çš„è¾“å‡ºï¼Œä¾‹å¦‚æ¶‰åŠéæ³•æ´»åŠ¨ã€ä¼ æ’­è™šå‡ä¿¡æ¯æˆ–ä¸é“å¾·è¡Œä¸ºã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹MLLMsåœ¨å¤šæ¨¡æ€è¾“å…¥ä¸‹çš„å®‰å…¨æ€§è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œå¹¶ä¸”æ²¡æœ‰å……åˆ†è€ƒè™‘å¯¹æŠ—æ€§æ”»å‡»åœºæ™¯ï¼Œå¯¼è‡´æ¨¡å‹å¯èƒ½è¢«æ¶æ„åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡çº¢é˜Ÿï¼ˆRed Teamingï¼‰çš„æ–¹å¼ï¼Œæ¨¡æ‹Ÿæ”»å‡»è€…ï¼Œè®¾è®¡å„ç§å¯¹æŠ—æ€§æç¤ºï¼ŒåŒ…æ‹¬çº¯æ–‡æœ¬å’Œå¤šæ¨¡æ€å½¢å¼ï¼Œæ¥æµ‹è¯•MLLMsçš„å®‰å…¨æ€§ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨è¿™äº›æç¤ºä¸‹çš„è¾“å‡ºï¼Œè¯„ä¼°å…¶åœ¨ä¸åŒæœ‰å®³ç±»åˆ«ä¸­çš„è„†å¼±æ€§ï¼Œå¹¶æ‰¾å‡ºæ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) çº¢é˜Ÿæç¤ºç”Ÿæˆï¼šç”±26åçº¢é˜Ÿæˆå‘˜è®¾è®¡726ä¸ªå¯¹æŠ—æ€§æç¤ºï¼Œæ¶µç›–éæ³•æ´»åŠ¨ã€è™šå‡ä¿¡æ¯å’Œä¸é“å¾·è¡Œä¸ºä¸‰ä¸ªç±»åˆ«ã€‚æç¤ºåŒ…æ‹¬çº¯æ–‡æœ¬å’Œå¤šæ¨¡æ€å½¢å¼ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å«å›¾åƒçš„æ–‡æœ¬æç¤ºï¼‰ã€‚2) æ¨¡å‹æ¨ç†ï¼šå°†ç”Ÿæˆçš„æç¤ºè¾“å…¥åˆ°å››ä¸ªMLLMsï¼ˆGPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plusï¼‰ä¸­ï¼Œè·å–æ¨¡å‹çš„è¾“å‡ºã€‚3) æœ‰å®³æ€§è¯„ä¼°ï¼šç”±17åæ ‡æ³¨å‘˜ä½¿ç”¨5åˆ†åˆ¶è¯„ä¼°2904ä¸ªæ¨¡å‹è¾“å‡ºçš„æœ‰å®³æ€§ã€‚4) ç»Ÿè®¡åˆ†æï¼šå¯¹è¯„ä¼°ç»“æœè¿›è¡Œç»Ÿè®¡åˆ†æï¼Œç¡®å®šæ¨¡å‹ç±»å‹å’Œè¾“å…¥æ¨¡æ€å¯¹æœ‰å®³æ€§çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é‡‡ç”¨çº¢é˜Ÿæ–¹æ³•ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°MLLMsåœ¨å¯¹æŠ—æ€§æç¤ºä¸‹çš„å®‰å…¨æ€§ã€‚2) å…³æ³¨å¤šæ¨¡æ€è¾“å…¥ï¼Œå¼¥è¡¥äº†ç°æœ‰ç ”ç©¶å¯¹å¤šæ¨¡æ€å®‰å…¨æ€§çš„ä¸è¶³ã€‚3) å¯¹æ¯”äº†å¤šä¸ªä¸»æµMLLMsçš„å®‰å…¨æ€§ï¼Œæ­ç¤ºäº†ä¸åŒæ¨¡å‹ä¹‹é—´çš„å·®å¼‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºè®¾è®¡æ–¹é¢ï¼Œçº¢é˜Ÿæˆå‘˜è¢«è¦æ±‚å°½å¯èƒ½åœ°ç»•è¿‡æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ï¼Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„å¯¹æŠ—æ€§æç¤ºã€‚åœ¨æœ‰å®³æ€§è¯„ä¼°æ–¹é¢ï¼Œä½¿ç”¨5åˆ†åˆ¶é‡åŒ–æœ‰å®³ç¨‹åº¦ï¼Œå¹¶ç”±å¤šåæ ‡æ³¨å‘˜è¿›è¡Œè¯„ä¼°ï¼Œä»¥æé«˜è¯„ä¼°çš„å¯é æ€§ã€‚ç»Ÿè®¡åˆ†æé‡‡ç”¨äº†æ–¹å·®åˆ†æç­‰æ–¹æ³•ï¼Œä»¥ç¡®å®šæ¨¡å‹ç±»å‹å’Œè¾“å…¥æ¨¡æ€å¯¹æœ‰å®³æ€§çš„æ˜¾è‘—å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒMLLMçš„å®‰å…¨æ€§å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒPixtral 12Bçš„æœ‰å®³å“åº”ç‡é«˜è¾¾62%ï¼Œè€ŒClaude Sonnet 3.5ä»…ä¸º10%ã€‚ä»¤äººæ„å¤–çš„æ˜¯ï¼Œçº¯æ–‡æœ¬æç¤ºåœ¨ç»•è¿‡å®‰å…¨æœºåˆ¶æ–¹é¢ç•¥ä¼˜äºå¤šæ¨¡æ€æç¤ºã€‚ç»Ÿè®¡åˆ†æè¯å®ï¼Œæ¨¡å‹ç±»å‹å’Œè¾“å…¥æ¨¡æ€éƒ½æ˜¯æœ‰å®³æ€§çš„é‡è¦é¢„æµ‹å› ç´ ï¼Œè¿™äº›å‘ç°ä¸ºåç»­æ¨¡å‹å®‰å…¨æ€§çš„æå‡æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒæŒ‡å¯¼æ¨¡å‹å¼€å‘è€…è®¾è®¡æ›´æœ‰æ•ˆçš„å®‰å…¨æœºåˆ¶ï¼Œå‡å°‘æ¨¡å‹è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚åŒæ—¶ï¼Œå¯ä»¥ä¸ºå¤šæ¨¡æ€å®‰å…¨åŸºå‡†çš„å»ºç«‹æä¾›å‚è€ƒï¼Œä¿ƒè¿›äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å®‰å…¨å¯é å‘å±•ã€‚è¯¥ç ”ç©¶å¯¹äºæ„å»ºè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿå…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) are increasingly used in real world applications, yet their safety under adversarial conditions remains underexplored. This study evaluates the harmlessness of four leading MLLMs (GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to adversarial prompts across text-only and multimodal formats. A team of 26 red teamers generated 726 prompts targeting three harm categories: illegal activity, disinformation, and unethical behaviour. These prompts were submitted to each model, and 17 annotators rated 2,904 model outputs for harmfulness using a 5-point scale. Results show significant differences in vulnerability across models and modalities. Pixtral 12B exhibited the highest rate of harmful responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%). Contrary to expectations, text-only prompts were slightly more effective at bypassing safety mechanisms than multimodal ones. Statistical analysis confirmed that both model type and input modality were significant predictors of harmfulness. These findings underscore the urgent need for robust, multimodal safety benchmarks as MLLMs are deployed more widely.

