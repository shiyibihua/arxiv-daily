---
layout: default
title: ATTS: Asynchronous Test-Time Scaling via Conformal Prediction
---

# ATTS: Asynchronous Test-Time Scaling via Conformal Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15148" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.15148v2</a>
  <a href="https://arxiv.org/pdf/2509.15148.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15148v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15148v2', 'ATTS: Asynchronous Test-Time Scaling via Conformal Prediction')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jing Xiong, Qiujiang Chen, Fanghua Ye, Zhongwei Wan, Chuanyang Zheng, Chenyang Zhao, Hui Shen, Alexander Hanbo Li, Chaofan Tao, Haochen Tan, Haoli Bai, Lifeng Shang, Lingpeng Kong, Ngai Wong

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-18 (Êõ¥Êñ∞: 2025-09-28)

**Â§áÊ≥®**: Tech Report

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/menik1126/asynchronous-test-time-scaling)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ATTSÔºö‰∏ÄÁßçÂü∫‰∫é‰øùÂΩ¢È¢ÑÊµãÁöÑÂºÇÊ≠•ÊµãËØïÊó∂Áº©ÊîæÊ°ÜÊû∂ÔºåÊòæËëóÂä†ÈÄüLLMÊé®ÁêÜ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßËØ≠Ë®ÄÊ®°Âûã` `ÊµãËØïÊó∂Áº©Êîæ` `Êé®ÊµãËß£Á†Å` `ÂºÇÊ≠•Êé®ÁêÜ` `‰øùÂΩ¢È¢ÑÊµã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLLMÊµãËØïÊó∂Áº©ÊîæÂèóÈôê‰∫éÈ´òÊé®ÁêÜÂª∂ËøüÂíåÂêåÊ≠•ÂºÄÈîÄÔºåÂ∞§ÂÖ∂ÊòØÂú®Âπ∂Ë°åÂíåÈ°∫Â∫èÁª¥Â∫¶ÂêåÊó∂Áº©ÊîæÊó∂„ÄÇ
2. ATTSÈÄöËøáÂú®Á∫øÊ†°ÂáÜÂÆûÁé∞ÂºÇÊ≠•Êé®ÁêÜÔºåÂπ∂Âà©Áî®Â∫èÊï∞ÂàÜÁ±ªÁÆóÊ≥ïÊîØÊåÅ‰∏âÈò∂ÊÆµÊãíÁªùÈááÊ†∑Ôºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÂπ∂Ë°åÂíåÈ°∫Â∫èÁº©Êîæ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåATTSÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÂä†ÈÄüÂíåÂêûÂêêÈáèÊèêÂçáÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÁ≤æÂ∫¶ÔºåÂπ∂Èôç‰Ωé‰∫ÜÂª∂ËøüÂíåÂÜÖÂ≠òÂºÄÈîÄ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂèóÁõä‰∫éÊµãËØïÊó∂Áº©ÊîæÔºå‰ΩÜÂ∏∏Â∏∏ÂèóÂà∞È´òÊé®ÁêÜÂª∂ËøüÁöÑÈòªÁ¢ç„ÄÇÊé®ÊµãËß£Á†ÅÊòØÂä†ÈÄüÁº©ÊîæËøáÁ®ãÁöÑ‰∏ÄÁßçËá™ÁÑ∂ÊñπÂºèÔºõÁÑ∂ËÄåÔºåÊ≤øÂπ∂Ë°åÂíåÈ°∫Â∫èÁª¥Â∫¶ËøõË°åÁº©ÊîæÈÉΩÂ∏¶Êù•‰∫ÜÈáçÂ§ßÊåëÊàòÔºåÂåÖÊã¨Â§ßÈáèÁöÑÂÜÖÂ≠òÂØÜÈõÜÂûãÊâßË°åÂíåÂêåÊ≠•ÂºÄÈîÄ„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫ÜATTSÔºàÂºÇÊ≠•ÊµãËØïÊó∂Áº©ÊîæÔºâÔºåËøôÊòØ‰∏Ä‰∏™ÁªüËÆ°‰øùËØÅÁöÑËá™ÈÄÇÂ∫îÁº©ÊîæÊ°ÜÊû∂ÔºåÂÆÉÈÅµÂæ™ÂÅáËÆæÊ£ÄÈ™åËøáÁ®ãÊù•Ëß£ÂÜ≥Ëøô‰∫õÊåëÊàò„ÄÇÈÄöËøáÈáçÊñ∞ÂÆ°ËßÜÁÆóÊúØÂº∫Â∫¶ÔºåATTSÂ∞ÜÂêåÊ≠•Á°ÆÂÆö‰∏∫‰∏ªË¶ÅÁì∂È¢à„ÄÇÂÆÉÈÄöËøáÂú®Á∫øÊ†°ÂáÜÂÆûÁé∞ÂºÇÊ≠•Êé®ÁêÜÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊîØÊåÅ‰∏âÈò∂ÊÆµÊãíÁªùÈááÊ†∑ÁÆ°ÈÅìÁöÑÂ∫èÊï∞ÂàÜÁ±ªÁÆóÊ≥ïÔºå‰ªéËÄåÊ≤øÈ°∫Â∫èÂíåÂπ∂Ë°åËΩ¥ËøõË°åÁº©Êîæ„ÄÇÂú®MATH„ÄÅAMC23„ÄÅAIME24ÂíåAIME25Êï∞ÊçÆÈõÜ‰ª•ÂèäÂ§ö‰∏™draft-targetÊ®°ÂûãÂÆ∂ÊóèÁöÑÂÆûÈ™å‰∏≠ÔºåÊàë‰ª¨Ë°®ÊòéATTSÂú®ÊµãËØïÊó∂Áº©Êîæ‰∏≠Êèê‰æõ‰∫ÜÈ´òËææ56.7ÂÄçÁöÑÂä†ÈÄüÂíå4.14ÂÄçÁöÑÂêûÂêêÈáèÊèêÂçáÔºåÂêåÊó∂‰øùÊåÅÂØπÊãíÁªùÁéáÁöÑÁ≤æÁ°ÆÊéßÂà∂ÔºåÈôç‰ΩéÂª∂ËøüÂíåÂÜÖÂ≠òÂºÄÈîÄÔºåÂπ∂‰∏î‰∏ç‰ºöÈÄ†ÊàêÁ≤æÂ∫¶ÊçüÂ§±„ÄÇÈÄöËøáÂú®Âπ∂Ë°åÂíåÈ°∫Â∫èÁª¥Â∫¶‰∏äËøõË°åÁº©ÊîæÔºåÊàë‰ª¨‰Ωø1.5B/70B draft/targetÊ®°ÂûãÁªÑÂêàËÉΩÂ§üÂú®AIMEÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞ÊúÄÂÖàËøõÁöÑÊé®ÁêÜÊ®°Âûão3-mini (high)ÁöÑÊÄßËÉΩ„ÄÇÊàë‰ª¨Â∑≤Âú®https://github.com/menik1126/asynchronous-test-time-scaling‰∏äÂèëÂ∏É‰∫Ü‰ª£Á†Å„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÊµãËØïÊó∂Áº©ÊîæËøáÁ®ã‰∏≠ÔºåÁî±‰∫éÈ´òÊé®ÁêÜÂª∂ËøüÂíåÂêåÊ≠•ÂºÄÈîÄÂØºËá¥ÁöÑÊïàÁéáÁì∂È¢àÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑÊé®ÊµãËß£Á†ÅÊñπÊ≥ïÂú®Âπ∂Ë°åÂíåÈ°∫Â∫èÁª¥Â∫¶‰∏äÂêåÊó∂Áº©ÊîæÊó∂Ôºå‰ºöÈù¢‰∏¥‰∏•ÈáçÁöÑÂÜÖÂ≠òÂØÜÈõÜÂûãÊâßË°åÂíåÂêåÊ≠•ÂºÄÈîÄÔºåÈôêÂà∂‰∫ÜÊï¥‰ΩìÊÄßËÉΩÁöÑÊèêÂçá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöATTSÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºÇÊ≠•Êé®ÁêÜÊù•Ê∂àÈô§ÂêåÊ≠•Áì∂È¢à„ÄÇÂÆÉÂü∫‰∫éÂÅáËÆæÊ£ÄÈ™åËøáÁ®ãÔºåÈááÁî®ÁªüËÆ°‰øùËØÅÁöÑËá™ÈÄÇÂ∫îÁº©ÊîæÊ°ÜÊû∂ÔºåÂÖÅËÆ∏draftÊ®°ÂûãÂíåtargetÊ®°ÂûãÂºÇÊ≠•ÊâßË°åÔºå‰ªéËÄåÂáèÂ∞ëÁ≠âÂæÖÊó∂Èó¥ÔºåÊèêÈ´òËµÑÊ∫êÂà©Áî®Áéá„ÄÇÈÄöËøáÂú®Á∫øÊ†°ÂáÜÔºåATTSËÉΩÂ§üÂä®ÊÄÅË∞ÉÊï¥Áº©ÊîæÁ≠ñÁï•Ôºå‰ª•ÈÄÇÂ∫î‰∏çÂêåÁöÑËæìÂÖ•ÂíåÊ®°ÂûãÁä∂ÊÄÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöATTSÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÈò∂ÊÆµÔºö1) **Âú®Á∫øÊ†°ÂáÜ**ÔºöÊ†πÊçÆÂéÜÂè≤Êï∞ÊçÆÂä®ÊÄÅË∞ÉÊï¥Áº©ÊîæÂèÇÊï∞Ôºå‰øùËØÅÁªüËÆ°ÊúâÊïàÊÄß„ÄÇ2) **‰∏âÈò∂ÊÆµÊãíÁªùÈááÊ†∑**ÔºöÂà©Áî®Â∫èÊï∞ÂàÜÁ±ªÁÆóÊ≥ïÔºåÂØπdraftÊ®°ÂûãÁöÑÈ¢ÑÊµãËøõË°åÂ§öËΩÆÈ™åËØÅÔºåÈÄêÊ≠•ÊèêÈ´òÈ¢ÑÊµãÁöÑÁΩÆ‰ø°Â∫¶„ÄÇ3) **ÂºÇÊ≠•Êé®ÁêÜ**ÔºödraftÊ®°ÂûãÂíåtargetÊ®°ÂûãÂºÇÊ≠•ÊâßË°åÔºåÂáèÂ∞ëÂêåÊ≠•Á≠âÂæÖÊó∂Èó¥„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊó®Âú®ÂÆûÁé∞È´òÊïàÁöÑÂπ∂Ë°åÂíåÈ°∫Â∫èÁº©ÊîæÔºåÂêåÊó∂‰øùÊåÅÁ≤æÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöATTSÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂºÇÊ≠•Êé®ÁêÜÊú∫Âà∂ÂíåÂú®Á∫øÊ†°ÂáÜÁ≠ñÁï•„ÄÇ‰º†ÁªüÁöÑÊé®ÊµãËß£Á†ÅÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂêåÊ≠•Á≠âÂæÖdraftÊ®°ÂûãÂíåtargetÊ®°ÂûãÁöÑÁªìÊûúÔºåËÄåATTSÈÄöËøáÂºÇÊ≠•ÊâßË°åÔºåÊòæËëóÂáèÂ∞ë‰∫ÜÁ≠âÂæÖÊó∂Èó¥„ÄÇÂú®Á∫øÊ†°ÂáÜÂàôËÉΩÂ§üÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµÂä®ÊÄÅË∞ÉÊï¥Áº©ÊîæÂèÇÊï∞ÔºåÊèêÈ´ò‰∫ÜÊ°ÜÊû∂ÁöÑÈÄÇÂ∫îÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöATTSÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) **Â∫èÊï∞ÂàÜÁ±ªÁÆóÊ≥ï**ÔºöÁî®‰∫éÂØπdraftÊ®°ÂûãÁöÑÈ¢ÑÊµãËøõË°åÂ§öËΩÆÈ™åËØÅÔºåËæìÂá∫ÁΩÆ‰ø°Â∫¶Á≠âÁ∫ß„ÄÇ2) **Âú®Á∫øÊ†°ÂáÜÁ≠ñÁï•**ÔºöÂü∫‰∫é‰øùÂΩ¢È¢ÑÊµãÔºåÂä®ÊÄÅË∞ÉÊï¥Áº©ÊîæÂèÇÊï∞Ôºå‰øùËØÅÁªüËÆ°ÊúâÊïàÊÄß„ÄÇ3) **‰∏âÈò∂ÊÆµÊãíÁªùÈááÊ†∑ÁÆ°ÈÅì**ÔºöÈÄöËøáÂ§öËΩÆÈ™åËØÅÔºåÈÄêÊ≠•ÊèêÈ´òÈ¢ÑÊµãÁöÑÁΩÆ‰ø°Â∫¶ÔºåÂáèÂ∞ëÈîôËØØÈ¢ÑÊµãÁöÑÊ¶ÇÁéá„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÈÄâÊã©ÂèñÂÜ≥‰∫éÂÖ∑‰ΩìÁöÑÊ®°ÂûãÂíåÊï∞ÊçÆÈõÜ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ATTSÂú®MATH„ÄÅAMC23„ÄÅAIME24ÂíåAIME25Êï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÔºåATTSÂú®ÊµãËØïÊó∂Áº©Êîæ‰∏≠Êèê‰æõ‰∫ÜÈ´òËææ56.7ÂÄçÁöÑÂä†ÈÄüÂíå4.14ÂÄçÁöÑÂêûÂêêÈáèÊèêÂçáÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÂØπÊãíÁªùÁéáÁöÑÁ≤æÁ°ÆÊéßÂà∂ÔºåÈôç‰Ωé‰∫ÜÂª∂ËøüÂíåÂÜÖÂ≠òÂºÄÈîÄÔºåÂπ∂‰∏îÊ≤°ÊúâÈÄ†ÊàêÁ≤æÂ∫¶ÊçüÂ§±„ÄÇÈÄöËøáÂπ∂Ë°åÂíåÈ°∫Â∫èÁª¥Â∫¶Áº©ÊîæÔºå1.5B/70B draft/targetÊ®°ÂûãÁªÑÂêàÂú®AIMEÊï∞ÊçÆÈõÜ‰∏äËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊé®ÁêÜÊ®°Âûão3-mini (high)ÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ATTSÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÈúÄË¶ÅÂø´ÈÄüÊé®ÁêÜÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®Âú∫ÊôØÔºå‰æãÂ¶ÇÂú®Á∫øÈóÆÁ≠î„ÄÅÊú∫Âô®ÁøªËØë„ÄÅÊñáÊú¨ÁîüÊàêÁ≠â„ÄÇËØ•ÊäÄÊúØËÉΩÂ§üÊòæËëóÈôç‰ΩéÊé®ÁêÜÂª∂ËøüÔºåÊèêÈ´òÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇÊú™Êù•ÔºåATTSÊúâÊúõËøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑÊ®°ÂûãÂíå‰ªªÂä°Ôºå‰æãÂ¶ÇÂõæÂÉèËØÜÂà´„ÄÅËØ≠Èü≥ËØÜÂà´Á≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models (LLMs) benefit from test-time scaling but are often hampered by high inference latency. Speculative decoding is a natural way to accelerate the scaling process; however, scaling along both the parallel and sequential dimensions poses significant challenges, including substantial memory-bound execution and synchronization overhead. We introduce ATTS (Asynchronous Test-Time Scaling), a statistically guaranteed adaptive scaling framework that follows the hypothesis testing process to address these challenges. By revisiting arithmetic intensity, ATTS identifies synchronization as the primary bottleneck. It enables asynchronous inference through online calibration and proposes an ordinal classification algorithm that supports a three-stage rejection sampling pipeline, scaling along both the sequential and parallel axes. Across experiments on the MATH, AMC23, AIME24, and AIME25 datasets and across multiple draft-target model families, we show that ATTS delivers up to 56.7x speedup in test-time scaling and a 4.14x throughput improvement, while maintaining accurate control of the rejection rate, reducing latency and memory overhead, and incurring no accuracy loss. By scaling both in parallel and sequential dimensions, we enable the 1.5B/70B draft/target model combination to achieve the performance of the state-of-the-art reasoning model o3-mini (high) on the AIME dataset. We have released the code at https://github.com/menik1126/asynchronous-test-time-scaling.

