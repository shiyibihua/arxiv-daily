---
layout: default
title: Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering
---

# Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15403" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15403v1</a>
  <a href="https://arxiv.org/pdf/2509.15403.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15403v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15403v1', 'Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yangyi Li, Mengdi Huai

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹é—®ç­”è§£é‡Šï¼Œæå‡ºä¸€ç§è‡ªç„¶è¯­è¨€è§£é‡Šä¸ç¡®å®šæ€§é‡åŒ–æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç„¶è¯­è¨€è§£é‡Š` `ä¸ç¡®å®šæ€§é‡åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹` `é—®ç­”ç³»ç»Ÿ` `å¯è§£é‡Šæ€§` `é²æ£’æ€§` `æ¨¡å‹æ— å…³`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç„¶è¯­è¨€è§£é‡Šæ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼Œéš¾ä»¥è¯„ä¼°è§£é‡Šçš„å¯é æ€§ã€‚
2. æå‡ºä¸€ç§æ–°é¢–çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¡†æ¶ï¼Œä¸ºè‡ªç„¶è¯­è¨€è§£é‡Šæä¾›æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ï¼Œä¸”æ¨¡å‹æ— å…³ã€‚
3. è®¾è®¡é²æ£’çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œå³ä½¿å­˜åœ¨å™ªå£°å¹²æ‰°ï¼Œä¹Ÿèƒ½ä¿æŒä¸ç¡®å®šæ€§ä¼°è®¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ï¼ˆQAï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæä¾›ç®€æ´ã€ä¸Šä¸‹æ–‡ç›¸å…³çš„ç­”æ¡ˆã€‚ç”±äºå¤æ‚LLMsç¼ºä¹é€æ˜æ€§ï¼Œæ¿€å‘äº†å¤§é‡ç ”ç©¶ï¼Œæ—¨åœ¨å¼€å‘è§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹è¡Œä¸ºçš„æ–¹æ³•ã€‚åœ¨ç°æœ‰çš„è§£é‡Šæ–¹æ³•ä¸­ï¼Œè‡ªç„¶è¯­è¨€è§£é‡Šå› å…¶èƒ½å¤Ÿä»¥è‡ªè§£é‡Šçš„æ–¹å¼è§£é‡ŠLLMsï¼Œå¹¶ä¸”å³ä½¿åœ¨æ¨¡å‹æ˜¯é—­æºçš„æƒ…å†µä¸‹ä¹Ÿèƒ½ç†è§£æ¨¡å‹è¡Œä¸ºè€Œè„±é¢–è€Œå‡ºã€‚ç„¶è€Œï¼Œå°½ç®¡å–å¾—äº†è¿™äº›æœ‰å¸Œæœ›çš„è¿›å±•ï¼Œä½†ç›®å‰è¿˜æ²¡æœ‰ç ”ç©¶å¦‚ä½•ä¸ºè¿™äº›ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€è§£é‡Šæä¾›æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ã€‚è¿™ç§ä¸ç¡®å®šæ€§é‡åŒ–å¯¹äºç†è§£è¿™äº›è§£é‡ŠèƒŒåçš„ç½®ä¿¡åº¦è‡³å…³é‡è¦ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç”±äºLLMsçš„è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹ä»¥åŠåŒ»ç–—æŸ¥è¯¢ä¸­å­˜åœ¨çš„å™ªå£°ï¼Œä¸ºè‡ªç„¶è¯­è¨€è§£é‡Šç”Ÿæˆæœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¼°è®¡å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆä¸ºè¿™äº›ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€è§£é‡Šæå‡ºäº†ä¸€ç§æ–°çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä»¥äº‹åå’Œæ¨¡å‹æ— å…³çš„æ–¹å¼æä¾›æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è®¾è®¡äº†ä¸€ç§æ–°çš„é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œå³ä½¿åœ¨å™ªå£°ä¸‹ä¹Ÿèƒ½ä¿æŒæœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ã€‚åœ¨QAä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„é¢„æœŸæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é—®ç­”ä»»åŠ¡ä¸­ï¼Œä½¿ç”¨è‡ªç„¶è¯­è¨€è¿›è¡Œè§£é‡Šæ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§é‡åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æä¾›å¯¹è§£é‡Šå¯é æ€§çš„æœ‰æ•ˆè¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—ç­‰é«˜é£é™©é¢†åŸŸï¼Œé”™è¯¯çš„è§£é‡Šå¯èƒ½å¯¼è‡´ä¸¥é‡åæœã€‚æ­¤å¤–ï¼ŒLLMsçš„è‡ªå›å½’ç”Ÿæˆè¿‡ç¨‹å’Œè¾“å…¥æ•°æ®ä¸­çš„å™ªå£°è¿›ä¸€æ­¥åŠ å‰§äº†ä¸ç¡®å®šæ€§ä¼°è®¡çš„éš¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ç§äº‹åï¼ˆpost-hocï¼‰ä¸”æ¨¡å‹æ— å…³ï¼ˆmodel-agnosticï¼‰çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿé‡åŒ–è‡ªç„¶è¯­è¨€è§£é‡Šçš„ä¸ç¡®å®šæ€§ï¼Œå¹¶æä¾›æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç”¨æˆ·å¯ä»¥æ›´å¥½åœ°ç†è§£è§£é‡ŠèƒŒåçš„ç½®ä¿¡åº¦ï¼Œä»è€Œåšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†å™ªå£°çš„å½±å“ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§é²æ£’çš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œä»¥æé«˜åœ¨å™ªå£°ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨LLMç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼›2) åˆ©ç”¨æå‡ºçš„ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•é‡åŒ–è§£é‡Šçš„ä¸ç¡®å®šæ€§ï¼›3) è¯„ä¼°ä¸ç¡®å®šæ€§ä¼°è®¡çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¿›è¡Œå¿…è¦çš„æ ¡æ­£ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•å¯èƒ½æ¶‰åŠå¯¹LLMç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œåˆ†æï¼Œæˆ–è€…ä½¿ç”¨é›†æˆæ–¹æ³•æ¥è·å¾—å¤šä¸ªè§£é‡Šï¼Œå¹¶è®¡ç®—å®ƒä»¬ä¹‹é—´çš„å·®å¼‚ã€‚é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•å¯èƒ½é‡‡ç”¨å¯¹æŠ—è®­ç»ƒæˆ–æ•°æ®å¢å¼ºç­‰æŠ€æœ¯æ¥æé«˜æ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªé’ˆå¯¹è‡ªç„¶è¯­è¨€è§£é‡Šçš„ä¸ç¡®å®šæ€§é‡åŒ–æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å…·æœ‰äº‹åå’Œæ¨¡å‹æ— å…³çš„ç‰¹æ€§ã€‚è¿™æ„å‘³ç€è¯¥æ¡†æ¶å¯ä»¥åº”ç”¨äºå„ç§LLMï¼Œè€Œæ— éœ€ä¿®æ”¹LLMçš„å†…éƒ¨ç»“æ„æˆ–è®­ç»ƒè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œè§£å†³äº†å™ªå£°ç¯å¢ƒä¸‹çš„ä¸ç¡®å®šæ€§é‡åŒ–é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæä¾›æ›´å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡ï¼Œä»è€Œæé«˜äº†è§£é‡Šçš„å¯ä¿¡åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹å¯èƒ½æ¶‰åŠä»¥ä¸‹æ–¹é¢ï¼š1) å¦‚ä½•å®šä¹‰å’Œè®¡ç®—è‡ªç„¶è¯­è¨€è§£é‡Šçš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œä¾‹å¦‚åŸºäºæ¦‚ç‡åˆ†å¸ƒçš„ç†µæˆ–æ–¹å·®ï¼›2) å¦‚ä½•è®¾è®¡é²æ£’ä¸ç¡®å®šæ€§ä¼°è®¡æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨å¯¹æŠ—è®­ç»ƒæˆ–æ•°æ®å¢å¼ºï¼›3) å¦‚ä½•è¯„ä¼°ä¸ç¡®å®šæ€§ä¼°è®¡çš„æœ‰æ•ˆæ€§ï¼Œä¾‹å¦‚ä½¿ç”¨æ ¡å‡†æ›²çº¿æˆ–è¦†ç›–ç‡æŒ‡æ ‡ï¼›4) å¦‚ä½•å°†ä¸ç¡®å®šæ€§ä¿¡æ¯å‘ˆç°ç»™ç”¨æˆ·ï¼Œä¾‹å¦‚é€šè¿‡ç½®ä¿¡åŒºé—´æˆ–å¯è§†åŒ–æ–¹å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨é—®ç­”ä»»åŠ¡ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼ŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæä¾›æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§ä¿è¯ï¼Œå¹¶ä¸”åœ¨å™ªå£°ç¯å¢ƒä¸‹å…·æœ‰è¾ƒå¥½çš„é²æ£’æ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†æ‘˜è¦å¼ºè°ƒäº†è¯¥æ–¹æ³•è¾¾åˆ°äº†é¢„æœŸçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ã€æ³•å¾‹å’¨è¯¢ç­‰é«˜é£é™©é¢†åŸŸï¼Œæé«˜LLMè§£é‡Šçš„å¯ä¿¡åº¦å’Œå¯é æ€§ã€‚é€šè¿‡é‡åŒ–è§£é‡Šçš„ä¸ç¡®å®šæ€§ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£LLMçš„å†³ç­–è¿‡ç¨‹ï¼Œä»è€Œåšå‡ºæ›´æ˜æ™ºçš„åˆ¤æ–­ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›ä¿ƒè¿›äººæœºåä½œï¼Œæå‡AIç³»ç»Ÿçš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown strong capabilities, enabling concise, context-aware answers in question answering (QA) tasks. The lack of transparency in complex LLMs has inspired extensive research aimed at developing methods to explain large language behaviors. Among existing explanation methods, natural language explanations stand out due to their ability to explain LLMs in a self-explanatory manner and enable the understanding of model behaviors even when the models are closed-source. However, despite these promising advancements, there is no existing work studying how to provide valid uncertainty guarantees for these generated natural language explanations. Such uncertainty quantification is critical in understanding the confidence behind these explanations. Notably, generating valid uncertainty estimates for natural language explanations is particularly challenging due to the auto-regressive generation process of LLMs and the presence of noise in medical inquiries. To bridge this gap, in this work, we first propose a novel uncertainty estimation framework for these generated natural language explanations, which provides valid uncertainty guarantees in a post-hoc and model-agnostic manner. Additionally, we also design a novel robust uncertainty estimation method that maintains valid uncertainty guarantees even under noise. Extensive experiments on QA tasks demonstrate the desired performance of our methods.

