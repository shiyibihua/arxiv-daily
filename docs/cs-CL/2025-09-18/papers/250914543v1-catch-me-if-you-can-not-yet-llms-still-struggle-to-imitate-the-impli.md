---
layout: default
title: Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors
---

# Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14543" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14543v1</a>
  <a href="https://arxiv.org/pdf/2509.14543.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14543v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14543v1', 'Catch Me If You Can? Not Yet: LLMs Still Struggle to Imitate the Implicit Writing Styles of Everyday Authors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhengxiang Wang, Nafis Irtiza Tripto, Solha Park, Zhenzhen Li, Jiawei Zhou

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: EMNLP 2025 (Findings)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼èƒ½åŠ›ï¼šç°æœ‰æ¨¡å‹åœ¨éæ­£å¼æ–‡ä½“ä¸­è¡¨ç°ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å†™ä½œé£æ ¼æ¨¡ä»¿` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `é£æ ¼è¿ç§»` `ä¸ªæ€§åŒ–å†™ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹éš¾ä»¥å‡†ç¡®æ•æ‰å’Œæ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼ä¸­ç»†å¾®çš„ã€éšå¼çš„ç‰¹å¾ï¼Œå°¤å…¶æ˜¯åœ¨éæ­£å¼æ–‡ä½“ä¸­ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œåˆ©ç”¨å°‘é‡ç”¨æˆ·å†™ä½œæ ·æœ¬ï¼Œè¯„ä¼°LLMsæ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼çš„èƒ½åŠ›ï¼Œå¹¶åˆ†æä¸åŒæç¤ºç­–ç•¥çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨ç»“æ„åŒ–æ–‡ä½“ï¼ˆå¦‚æ–°é—»å’Œé‚®ä»¶ï¼‰ä¸­è¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨éæ­£å¼æ–‡ä½“ï¼ˆå¦‚åšå®¢å’Œè®ºå›ï¼‰ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸ªæ€§åŒ–é€‚åº”å­˜åœ¨å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¥ç›Šèå…¥ä¸ªäººå†™ä½œå·¥å…·ï¼Œä¸€ä¸ªå…³é”®é—®é¢˜æµ®å‡ºæ°´é¢ï¼šLLMsèƒ½å¦ä»…ä»å°‘é‡ç¤ºä¾‹ä¸­å¿ å®åœ°æ¨¡ä»¿ä¸ªäººçš„å†™ä½œé£æ ¼ï¼Ÿä¸ªäººé£æ ¼é€šå¸¸æ˜¯å¾®å¦™å’Œéšå¼çš„ï¼Œéš¾ä»¥é€šè¿‡æç¤ºæ˜ç¡®æŒ‡å®šï¼Œä½†å¯¹äºç”¨æˆ·å¯¹é½çš„ç”Ÿæˆè‡³å…³é‡è¦ã€‚æœ¬æ–‡å¯¹æœ€å…ˆè¿›çš„LLMsé€šè¿‡å°‘é‡ç”¨æˆ·åˆ›ä½œæ ·æœ¬è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ æ¥æ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼çš„èƒ½åŠ›è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç»„äº’è¡¥çš„æŒ‡æ ‡ï¼ŒåŒ…æ‹¬ä½œè€…èº«ä»½å½’å±ã€ä½œè€…èº«ä»½éªŒè¯ã€é£æ ¼åŒ¹é…å’ŒAIæ£€æµ‹ï¼Œä»¥ç¨³å¥åœ°è¯„ä¼°é£æ ¼æ¨¡ä»¿ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¶µç›–äº†æ¯ä¸ªæ¨¡å‹åœ¨æ–°é—»ã€ç”µå­é‚®ä»¶ã€è®ºå›å’Œåšå®¢ç­‰é¢†åŸŸè¶…è¿‡40000ä¸ªç”Ÿæˆç»“æœï¼Œæ¶µç›–äº†æ¥è‡ª400å¤šä½çœŸå®ä½œè€…çš„å†™ä½œæ ·æœ¬ã€‚ç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMså¯ä»¥åœ¨æ–°é—»å’Œç”µå­é‚®ä»¶ç­‰ç»“æ„åŒ–æ ¼å¼ä¸­è¿‘ä¼¼ç”¨æˆ·é£æ ¼ï¼Œä½†å®ƒä»¬åœ¨åšå®¢å’Œè®ºå›ä¸­éš¾ä»¥å¤„ç†ç»†å¾®çš„éæ­£å¼å†™ä½œã€‚å¯¹å„ç§æç¤ºç­–ç•¥ï¼ˆå¦‚æ¼”ç¤ºæ•°é‡ï¼‰çš„è¿›ä¸€æ­¥åˆ†ææ­ç¤ºäº†æœ‰æ•ˆä¸ªæ€§åŒ–çš„å…³é”®å±€é™æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªå‡ºäº†ä¸ªæ€§åŒ–LLMé€‚åº”æ–¹é¢çš„æ ¹æœ¬å·®è·ï¼Œä»¥åŠæ”¹è¿›æŠ€æœ¯ä»¥æ”¯æŒéšå¼ã€é£æ ¼ä¸€è‡´çš„ç”Ÿæˆçš„éœ€æ±‚ã€‚ä¸ºäº†å¸®åŠ©æœªæ¥çš„ç ”ç©¶å’Œå¯é‡å¤æ€§ï¼Œæˆ‘ä»¬å¼€æºäº†æˆ‘ä»¬çš„æ•°æ®å’Œä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç”¨æˆ·é£æ ¼å…·æœ‰éšå¼æ€§å’Œå¾®å¦™æ€§çš„æƒ…å†µä¸‹ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥é€šè¿‡ç®€å•çš„æç¤ºè¯æ¥ç²¾ç¡®æ§åˆ¶LLMçš„è¾“å‡ºé£æ ¼ï¼Œå¯¼è‡´ç”Ÿæˆçš„æ–‡æœ¬ä¸ç›®æ ‡ä½œè€…çš„é£æ ¼ä¸ä¸€è‡´ã€‚è¿™ç§ä¸ä¸€è‡´æ€§é™åˆ¶äº†LLMåœ¨ä¸ªæ€§åŒ–å†™ä½œè¾…åŠ©å·¥å…·ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆin-context learningï¼‰ï¼Œå³å‘LLMæä¾›å°‘é‡ç›®æ ‡ä½œè€…çš„å†™ä½œæ ·æœ¬ï¼Œè®©LLMä»ä¸­å­¦ä¹ å¹¶æ¨¡ä»¿å…¶å†™ä½œé£æ ¼ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œé¿å…äº†æ˜¾å¼åœ°å®šä¹‰é£æ ¼ç‰¹å¾ï¼Œè€Œæ˜¯è®©LLMè‡ªåŠ¨æ•æ‰éšå¼çš„é£æ ¼ä¿¡æ¯ã€‚åŒæ—¶ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç³»åˆ—è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºå…¨é¢è¡¡é‡LLMçš„é£æ ¼æ¨¡ä»¿èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†æ¥è‡ªä¸åŒé¢†åŸŸï¼ˆæ–°é—»ã€é‚®ä»¶ã€è®ºå›ã€åšå®¢ï¼‰çš„çœŸå®ä½œè€…çš„å†™ä½œæ ·æœ¬ã€‚2) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©å½“å‰æœ€å…ˆè¿›çš„LLMsä½œä¸ºç ”ç©¶å¯¹è±¡ã€‚3) æç¤ºç­–ç•¥ï¼šè®¾è®¡ä¸åŒçš„æç¤ºç­–ç•¥ï¼Œä¾‹å¦‚æ”¹å˜æ¼”ç¤ºæ ·æœ¬çš„æ•°é‡ã€‚4) é£æ ¼ç”Ÿæˆï¼šä½¿ç”¨LLMç”Ÿæˆæ–‡æœ¬ï¼Œå¹¶å°è¯•æ¨¡ä»¿ç›®æ ‡ä½œè€…çš„é£æ ¼ã€‚5) é£æ ¼è¯„ä¼°ï¼šä½¿ç”¨ä¸€ç³»åˆ—æŒ‡æ ‡è¯„ä¼°ç”Ÿæˆçš„æ–‡æœ¬ä¸ç›®æ ‡ä½œè€…é£æ ¼çš„ç›¸ä¼¼åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¡¡é‡LLMçš„é£æ ¼æ¨¡ä»¿èƒ½åŠ›ï¼ŒåŒ…æ‹¬ä½œè€…èº«ä»½å½’å±ã€ä½œè€…èº«ä»½éªŒè¯ã€é£æ ¼åŒ¹é…å’ŒAIæ£€æµ‹ç­‰å¤šä¸ªç»´åº¦ã€‚2) æ­ç¤ºäº†LLMåœ¨ä¸åŒæ–‡ä½“ä¸­é£æ ¼æ¨¡ä»¿èƒ½åŠ›çš„å·®å¼‚ï¼Œå‘ç°LLMåœ¨éæ­£å¼æ–‡ä½“ä¸­è¡¨ç°è¾ƒå·®ã€‚3) åˆ†æäº†ä¸åŒæç¤ºç­–ç•¥å¯¹é£æ ¼æ¨¡ä»¿æ•ˆæœçš„å½±å“ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å…¨é¢è¡¡é‡LLMçš„é£æ ¼æ¨¡ä»¿èƒ½åŠ›ã€‚è¿™äº›æŒ‡æ ‡åŒ…æ‹¬ï¼šä½œè€…èº«ä»½å½’å±ï¼ˆåˆ¤æ–­ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦èƒ½è¢«å½’å±åˆ°ç›®æ ‡ä½œè€…ï¼‰ã€ä½œè€…èº«ä»½éªŒè¯ï¼ˆåˆ¤æ–­ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦ä¸ç›®æ ‡ä½œè€…çš„é£æ ¼ä¸€è‡´ï¼‰ã€é£æ ¼åŒ¹é…ï¼ˆè¡¡é‡ç”Ÿæˆçš„æ–‡æœ¬ä¸ç›®æ ‡ä½œè€…é£æ ¼çš„ç›¸ä¼¼åº¦ï¼‰å’ŒAIæ£€æµ‹ï¼ˆåˆ¤æ–­ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦å®¹æ˜“è¢«è¯†åˆ«ä¸ºæœºå™¨ç”Ÿæˆï¼‰ã€‚2) å®éªŒä¸­ä½¿ç”¨äº†è¶…è¿‡400ä½çœŸå®ä½œè€…çš„å†™ä½œæ ·æœ¬ï¼Œä¿è¯äº†å®éªŒç»“æœçš„å¯é æ€§ã€‚3) é’ˆå¯¹ä¸åŒçš„æ–‡ä½“ï¼Œé‡‡ç”¨äº†ä¸åŒçš„æç¤ºç­–ç•¥ï¼Œä»¥æ¢ç´¢æœ€ä½³çš„é£æ ¼æ¨¡ä»¿æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨ç»“æ„åŒ–æ–‡ä½“ï¼ˆå¦‚æ–°é—»å’Œé‚®ä»¶ï¼‰ä¸­èƒ½å¤Ÿè¾ƒå¥½åœ°æ¨¡ä»¿ä¸ªäººå†™ä½œé£æ ¼ï¼Œä½†åœ¨éæ­£å¼æ–‡ä½“ï¼ˆå¦‚åšå®¢å’Œè®ºå›ï¼‰ä¸­è¡¨ç°ä¸ä½³ã€‚ä¾‹å¦‚ï¼Œåœ¨ä½œè€…èº«ä»½å½’å±ä»»åŠ¡ä¸­ï¼ŒLLMsåœ¨æ–°é—»æ–‡ä½“ä¸­çš„å‡†ç¡®ç‡é«˜äºåšå®¢æ–‡ä½“ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜å‘ç°ï¼Œå¢åŠ æ¼”ç¤ºæ ·æœ¬çš„æ•°é‡å¹¶ä¸ä¸€å®šèƒ½æé«˜é£æ ¼æ¨¡ä»¿çš„æ•ˆæœï¼Œæœ‰æ—¶åè€Œä¼šé™ä½æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºä¸ªæ€§åŒ–å†™ä½œè¾…åŠ©å·¥å…·çš„å¼€å‘ï¼Œä¾‹å¦‚å¸®åŠ©ç”¨æˆ·ç”Ÿæˆé£æ ¼ä¸€è‡´çš„é‚®ä»¶ã€åšå®¢æ–‡ç« ç­‰ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ç”¨äºæ£€æµ‹AIç”Ÿæˆçš„æ–‡æœ¬ï¼Œé˜²æ­¢æ¶æ„ä½¿ç”¨LLMè¿›è¡Œè™šå‡ä¿¡æ¯ä¼ æ’­ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„é£æ ¼è¿ç§»æ–¹æ³•ï¼Œæé«˜LLMåœ¨å„ç§æ–‡ä½“ä¸­çš„é£æ ¼æ¨¡ä»¿èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) become increasingly integrated into personal writing tools, a critical question arises: can LLMs faithfully imitate an individual's writing style from just a few examples? Personal style is often subtle and implicit, making it difficult to specify through prompts yet essential for user-aligned generation. This work presents a comprehensive evaluation of state-of-the-art LLMs' ability to mimic personal writing styles via in-context learning from a small number of user-authored samples. We introduce an ensemble of complementary metrics-including authorship attribution, authorship verification, style matching, and AI detection-to robustly assess style imitation. Our evaluation spans over 40000 generations per model across domains such as news, email, forums, and blogs, covering writing samples from more than 400 real-world authors. Results show that while LLMs can approximate user styles in structured formats like news and email, they struggle with nuanced, informal writing in blogs and forums. Further analysis on various prompting strategies such as number of demonstrations reveal key limitations in effective personalization. Our findings highlight a fundamental gap in personalized LLM adaptation and the need for improved techniques to support implicit, style-consistent generation. To aid future research and for reproducibility, we open-source our data and code.

