---
layout: default
title: Beyond the Surface: Probing the Ideological Depth of Large Language Models
---

# Beyond the Surface: Probing the Ideological Depth of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21448" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21448v2</a>
  <a href="https://arxiv.org/pdf/2508.21448.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21448v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21448v2', 'Beyond the Surface: Probing the Ideological Depth of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shariar Kabir, Kevin Esterling, Yue Dong

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-11-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ„è¯†æ·±åº¦æ¦‚å¿µä»¥åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¿æ²»å€¾å‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ„è¯†æ·±åº¦` `æ”¿æ²»å€¾å‘` `å¯æ“æ§æ€§` `ç¨€ç–è‡ªç¼–ç å™¨` `ç‰¹å¾åˆ†æ` `å› æœæ¶ˆèå®éªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¡¨ç°æ”¿æ²»å€¾å‘æ—¶å­˜åœ¨ä¸€è‡´æ€§ä¸è¶³çš„é—®é¢˜ï¼Œå½±å“å…¶åœ¨ç‰¹å®šæŒ‡ä»¤ä¸‹çš„å“åº”èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºæ„è¯†æ·±åº¦çš„æ¦‚å¿µï¼Œé€šè¿‡å¯æ“æ§æ€§å’Œå†…éƒ¨ç‰¹å¾ä¸°å¯Œæ€§æ¥è¯„ä¼°æ¨¡å‹çš„æ”¿æ²»è¡¨ç°ï¼Œé‡‡ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œåˆ†æã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGemmaåœ¨å¯æ“æ§æ€§å’Œæ¿€æ´»çš„æ”¿æ²»ç‰¹å¾æ•°é‡ä¸Šå‡æ˜¾è‘—ä¼˜äºLlamaï¼Œä¸”ç‰¹å¾æ¶ˆèå®éªŒæ­ç¤ºäº†æ‹’ç»å“åº”çš„æ½œåœ¨åŸå› ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¡¨ç°å‡ºæ˜æ˜¾çš„æ”¿æ²»å€¾å‘ï¼Œä½†åœ¨ä¸€è‡´æ€§è¡¨ç°ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚æœ¬æ–‡å®šä¹‰äº†æ„è¯†æ·±åº¦ï¼ŒåŒ…å«æ¨¡å‹åœ¨æ— å¤±è´¥åœ°éµå¾ªæ”¿æ²»æŒ‡ä»¤çš„èƒ½åŠ›ï¼ˆå¯æ“æ§æ€§ï¼‰å’Œå…¶å†…éƒ¨æ”¿æ²»è¡¨ç¤ºçš„ç‰¹å¾ä¸°å¯Œæ€§ã€‚é€šè¿‡å¯¹Llama-3.1-8B-Instructå’ŒGemma-2-9B-ITçš„æ¯”è¾ƒï¼Œå‘ç°Gemmaåœ¨å¯æ“æ§æ€§å’Œæ¿€æ´»çš„æ”¿æ²»ç‰¹å¾æ•°é‡ä¸Šå‡ä¼˜äºLlamaã€‚æ­¤å¤–ï¼Œé’ˆå¯¹Gemmaçš„ç‰¹å®šæ”¿æ²»ç‰¹å¾è¿›è¡Œå› æœæ¶ˆèå®éªŒï¼Œè¡¨æ˜æ‹’ç»å“åº”çš„åŸå› å¯èƒ½æºäºèƒ½åŠ›ä¸è¶³ï¼Œè€Œéå®‰å…¨é˜²æŠ¤ã€‚è¿™äº›ç»“æœè¡¨æ˜æ„è¯†æ·±åº¦æ˜¯LLMsçš„å¯æµ‹é‡å±æ€§ï¼Œå¯æ“æ§æ€§åˆ™ä¸ºå…¶æ½œåœ¨æ”¿æ²»æ¶æ„æä¾›äº†è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éµå¾ªæ”¿æ²»æŒ‡ä»¤æ—¶è¡¨ç°ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé‡åŒ–æ¨¡å‹çš„æ”¿æ²»å€¾å‘å’Œå¯æ“æ§æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å®šä¹‰æ„è¯†æ·±åº¦ï¼Œç»“åˆå¯æ“æ§æ€§å’Œå†…éƒ¨ç‰¹å¾ä¸°å¯Œæ€§ï¼Œåˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰å¯¹æ¨¡å‹çš„æ”¿æ²»è¡¨ç¤ºè¿›è¡Œæ·±å…¥åˆ†æï¼Œä»¥æ­ç¤ºå…¶æ½œåœ¨çš„æ”¿æ²»æ¶æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨Llama-3.1-8B-Instructå’ŒGemma-2-9B-ITä½œä¸ºå®éªŒå¯¹è±¡ï¼Œæ¯”è¾ƒåŸºäºæç¤ºå’Œæ¿€æ´»çš„å¹²é¢„æ–¹æ³•ï¼Œåˆ†æå…¶æ”¿æ²»ç‰¹å¾çš„æ¿€æ´»æƒ…å†µã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€å¹²é¢„æ–¹æ³•ã€ç‰¹å¾æå–å’Œè¡Œä¸ºåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæ„è¯†æ·±åº¦ä½œä¸ºLLMsçš„æ–°æµ‹é‡å±æ€§ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£æ¨¡å‹çš„æ”¿æ²»å€¾å‘ï¼Œå°¤å…¶æ˜¯å¯æ“æ§æ€§ä¸å†…éƒ¨ç‰¹å¾çš„å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å› æœæ¶ˆèå®éªŒï¼Œä»¥éªŒè¯ä¸åŒæ”¿æ²»ç‰¹å¾å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œç¡®ä¿å®éªŒçš„å¯é‡å¤æ€§å’Œç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGemmaåœ¨å¯æ“æ§æ€§æ–¹é¢ä¼˜äºLlamaï¼Œæ¿€æ´»çš„æ”¿æ²»ç‰¹å¾æ•°é‡çº¦ä¸ºLlamaçš„7.3å€ã€‚æ­¤å¤–ï¼Œç‰¹å¾æ¶ˆèå®éªŒè¡¨æ˜ï¼ŒGemmaåœ¨ç‰¹å®šæ”¿æ²»ç‰¹å¾ç¼ºå¤±æ—¶ï¼Œæ‹’ç»å“åº”çš„é¢‘ç‡æ˜¾è‘—å¢åŠ ï¼Œæ­ç¤ºäº†èƒ½åŠ›ä¸è¶³çš„å½±å“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¿æ²»å€¾å‘æä¾›äº†æ–°çš„æ¡†æ¶ï¼Œæ½œåœ¨åº”ç”¨äºæ”¿æ²»åˆ†æã€èˆ†æƒ…ç›‘æµ‹å’Œç¤¾ä¼šç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸã€‚é€šè¿‡é‡åŒ–æ¨¡å‹çš„æ„è¯†æ·±åº¦ï¼Œå¯ä»¥ä¸ºæ¨¡å‹çš„è®¾è®¡å’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ï¼Œæå‡å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) display recognizable political leanings, yet they vary significantly in their ability to represent a political orientation consistently. In this paper, we define ideological depth as (i) a model's ability to follow political instructions without failure (steerability), and (ii) the feature richness of its internal political representations measured with sparse autoencoders (SAEs), an unsupervised sparse dictionary learning (SDL) approach. Using Llama-3.1-8B-Instruct and Gemma-2-9B-IT as candidates, we compare prompt-based and activation-steering interventions and probe political features with publicly available SAEs. We find large, systematic differences: Gemma is more steerable in both directions and activates approximately 7.3x more distinct political features than Llama. Furthermore, causal ablations of a small targeted set of Gemma's political features to create a similar feature-poor setting induce consistent shifts in its behavior, with increased rates of refusals across topics. Together, these results indicate that refusals on benign political instructions or prompts can arise from capability deficits rather than safety guardrails. Ideological depth thus emerges as a measurable property of LLMs, and steerability serves as a window into their latent political architecture.

