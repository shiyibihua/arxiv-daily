---
layout: default
title: Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards
---

# Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21476" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21476v1</a>
  <a href="https://arxiv.org/pdf/2508.21476.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21476v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21476v1', 'Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaolong Wei, Bo Lu, Xingyu Zhang, Zhejun Zhao, Dongdong Shen, Long Xia, Dawei Yin

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

**å¤‡æ³¨**: EMNLP 2025 Main

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRLAIFæ¡†æ¶ä»¥æå‡å°å‹è¯­è¨€æ¨¡å‹çš„åˆ›æ„å†™ä½œèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `åˆ›æ„å†™ä½œ` `å¼ºåŒ–å­¦ä¹ ` `AIåé¦ˆ` `å¤šä»£ç†æ¡†æ¶` `å¯¹æŠ—è®­ç»ƒ` `ä¸­æ–‡ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å°å‹è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„å†™ä½œæ–¹é¢çš„èƒ½åŠ›æœ‰é™ï¼Œå°¤å…¶æ˜¯åœ¨æ–°é¢–æ€§å’Œç”Ÿæˆè´¨é‡ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸¤ç§åŸºäºAIåé¦ˆçš„å¥–åŠ±ç­–ç•¥ï¼Œæ—¨åœ¨æå‡å°å‹è¯­è¨€æ¨¡å‹çš„åˆ›æ„å†™ä½œèƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯ä¸­æ–‡é—®å€™è¯­çš„ç”Ÿæˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…åœ¨ç”Ÿæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†åˆ›æ„è¾“å‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åˆ›æ„å†™ä½œæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é«˜è®¡ç®—éœ€æ±‚é™åˆ¶äº†å¹¿æ³›åº”ç”¨ã€‚å¢å¼ºå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç°æœ‰çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ–¹æ³•åœ¨æ–°é¢–æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œè€ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æˆæœ¬é«˜æ˜‚ã€‚æœ¬æ–‡æ¢è®¨äº†åœ¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸‹çš„ä¸¤ç§AIé©±åŠ¨å¥–åŠ±ç­–ç•¥ï¼Œä»¥æ¿€å‘7Bå‚æ•°SLMçš„åˆ›æ„å†™ä½œèƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨ç”Ÿæˆä¸­æ–‡é—®å€™è¯­æ–¹é¢ã€‚ç¬¬ä¸€ç§ç­–ç•¥åˆ©ç”¨é«˜è´¨é‡åå¥½æ•°æ®è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰ï¼Œé€šè¿‡ä¸€ç§æ–°é¢–çš„å¤šä»£ç†æ‹’ç»é‡‡æ ·æ¡†æ¶è¿›è¡Œåˆ›æ„ä»»åŠ¡çš„è®¾è®¡ã€‚ç¬¬äºŒç§æ›´å…·åˆ›æ–°æ€§çš„ç­–ç•¥é‡‡ç”¨åŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæ–¹æ¡ˆä¼˜åŒ–å¥–åŠ±å‡½æ•°ï¼Œç›´æ¥æä¾›å¥–åŠ±ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸¤ç§æ–¹æ³•å‡æ˜¾è‘—æå‡äº†åˆ›æ„è¾“å‡ºï¼Œä¸”åŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…åœ¨ç”Ÿæˆè´¨é‡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œè®­ç»ƒæ•ˆç‡é«˜ä¸”å¯¹äººç±»æ ‡æ³¨æ•°æ®çš„ä¾èµ–å‡å°‘ï¼Œå±•ç¤ºäº†æ›´å…·å¯æ‰©å±•æ€§å’Œæœ‰æ•ˆæ€§çš„åˆ›æ„SLMè·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°å‹è¯­è¨€æ¨¡å‹åœ¨åˆ›æ„å†™ä½œä¸­çš„æ–°é¢–æ€§ä¸è¶³å’Œç”Ÿæˆè´¨é‡ä½çš„é—®é¢˜ã€‚ç°æœ‰çš„ç›‘ç£å¾®è°ƒå’ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æˆæœ¬å’Œæ•ˆç‡ä¸Šå‡å­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„RLAIFæ¡†æ¶ç»“åˆäº†ä¸¤ç§AIé©±åŠ¨çš„å¥–åŠ±ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡é«˜è´¨é‡çš„åå¥½æ•°æ®å’ŒåŸåˆ™å¼•å¯¼çš„è¯„åˆ¤æœºåˆ¶æ¥æå‡å°å‹è¯­è¨€æ¨¡å‹çš„åˆ›æ„å†™ä½œèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€æ˜¯åŸºäºå¤šä»£ç†æ‹’ç»é‡‡æ ·çš„å¥–åŠ±æ¨¡å‹ï¼Œç¬¬äºŒæ˜¯åŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…ï¼Œåè€…é€šè¿‡å¯¹æŠ—è®­ç»ƒä¼˜åŒ–å¥–åŠ±ä¿¡å·ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†åŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…ï¼Œé€šè¿‡å¯¹æŠ—è®­ç»ƒæœºåˆ¶ç›´æ¥æä¾›å¥–åŠ±ä¿¡å·ï¼Œè¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†ç”Ÿæˆè´¨é‡å’Œè®­ç»ƒæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¥–åŠ±æ¨¡å‹çš„è®­ç»ƒä¸­ï¼Œä½¿ç”¨äº†é«˜è´¨é‡çš„åå¥½æ•°æ®ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†ç”Ÿæˆå†…å®¹çš„å¤šæ ·æ€§å’Œè´¨é‡ï¼Œç½‘ç»œç»“æ„åˆ™é‡‡ç”¨äº†é€‚åˆåˆ›æ„ä»»åŠ¡çš„å¤šä»£ç†æ¡†æ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸåˆ™å¼•å¯¼çš„LLMä½œä¸ºè¯„åˆ¤è€…åœ¨ç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œåˆ›æ„è¾“å‡ºæå‡å¹…åº¦æ˜æ˜¾ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒæ•ˆç‡ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œå‡å°‘äº†å¯¹äººç±»æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå±•ç¤ºäº†æ›´é«˜çš„å¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å†™ä½œåŠ©æ‰‹ã€ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆå’Œä¸ªæ€§åŒ–é—®å€™è¯­ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡å°å‹è¯­è¨€æ¨¡å‹çš„åˆ›æ„å†™ä½œèƒ½åŠ›ï¼Œå¯ä»¥åœ¨å¤šç§åœºæ™¯ä¸­å®ç°æ›´è‡ªç„¶å’Œäººæ€§åŒ–çš„äº¤äº’ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable creative writing capabilities, yet their substantial computational demands hinder widespread use. Enhancing Small Language Models (SLMs) offers a promising alternative, but current methods like Supervised Fine-Tuning (SFT) struggle with novelty, and Reinforcement Learning from Human Feedback (RLHF) is costly. This paper explores two distinct AI-driven reward strategies within a Reinforcement Learning from AI Feedback (RLAIF) framework to ignite the creative writing of a 7B-parameter SLM, specifically for generating Chinese greetings. The first strategy employs a RM trained on high-quality preference data curated by a novel multi-agent rejection sampling framework designed for creative tasks. The second, more novel strategy utilizes a principle-guided LLM-as-a-Judge, whose reward function is optimized via an adversarial training scheme with a reflection mechanism, to directly provide reward signals. Comprehensive experiments reveal that while both approaches significantly enhance creative output over baselines, the principle-guided LLM-as-a-Judge demonstrably yields superior generation quality. Furthermore, it offers notable advantages in training efficiency and reduced dependency on human-annotated data, presenting a more scalable and effective path towards creative SLMs. Our automated evaluation methods also exhibit strong alignment with human judgments. Our code and data are publicly available at https://github.com/weixiaolong94-hub/Igniting-Creative-Writing-in-Small-Language-Models.

