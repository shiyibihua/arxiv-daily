---
layout: default
title: Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning
---

# Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21589" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21589v5</a>
  <a href="https://arxiv.org/pdf/2508.21589.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21589v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21589v5', 'Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zinan Tang, Xin Gao, Qizhi Pei, Zhuoshi Pan, Mengzhang Cai, Jiang Wu, Conghui He, Lijun Wu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-10-22)

**å¤‡æ³¨**: Accepted by EMNLP 2025 (Main)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Word2VecT/Middo)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMiddoæ¡†æ¶ä»¥è§£å†³LLMè®­ç»ƒæ•°æ®ä¼˜åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŠ¨æ€æ•°æ®ä¼˜åŒ–` `é—­ç¯å­¦ä¹ ` `æ¨¡å‹å¾®è°ƒ` `æ•°æ®é€‰æ‹©` `æ•°æ®ç²¾ç‚¼` `è‡ªæˆ‘æ¼”åŒ–` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨æ•°æ®é€‰æ‹©å’Œåˆæˆä¸Šå­˜åœ¨å±€é™ï¼Œæ— æ³•é€‚åº”æ¨¡å‹èƒ½åŠ›çš„åŠ¨æ€å˜åŒ–ã€‚
2. Middoæ¡†æ¶é€šè¿‡æ¨¡å‹æ„ŸçŸ¥çš„æ•°æ®é€‰æ‹©å’Œä¸Šä¸‹æ–‡ä¿ç•™çš„æ•°æ®ç²¾ç‚¼ï¼Œå»ºç«‹äº†é—­ç¯ä¼˜åŒ–ç³»ç»Ÿã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMiddoåœ¨å¤šä¸ªåŸºå‡†ä¸Šæå‡äº†LLMçš„æ€§èƒ½ï¼Œå¹³å‡æé«˜äº†7.15%çš„å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ¬è´¨ä¸Šä¾èµ–äºé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚å°½ç®¡æ•°æ®é€‰æ‹©å’Œæ•°æ®åˆæˆæ˜¯æé«˜æ•°æ®è´¨é‡çš„å¸¸ç”¨ç­–ç•¥ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨é™æ€æ•°æ®é›†ç­–åˆ’æ–¹é¢å­˜åœ¨å±€é™ï¼Œæ— æ³•é€‚åº”æ¨¡å‹èƒ½åŠ›çš„æ¼”å˜ã€‚æœ¬æ–‡æå‡ºäº†Middoï¼Œä¸€ä¸ªè‡ªæˆ‘æ¼”åŒ–çš„æ¨¡å‹ä¿¡æ¯åŠ¨æ€æ•°æ®ä¼˜åŒ–æ¡†æ¶ï¼Œé‡‡ç”¨æ¨¡å‹æ„ŸçŸ¥çš„æ•°æ®é€‰æ‹©å’Œä¸Šä¸‹æ–‡ä¿ç•™çš„æ•°æ®ç²¾ç‚¼ã€‚ä¸ä¼ ç»Ÿçš„ä¸€æ¬¡æ€§è¿‡æ»¤/åˆæˆæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ¡†æ¶å»ºç«‹äº†ä¸€ä¸ªé—­ç¯ä¼˜åŒ–ç³»ç»Ÿï¼Œèƒ½å¤ŸæŒç»­æå‡æ•°æ®è´¨é‡å’Œæ¨¡å‹æ€§èƒ½ã€‚å®éªŒè¡¨æ˜ï¼ŒMiddoåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å¹³å‡æé«˜äº†7.15%çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶ä¿æŒäº†åŸå§‹æ•°æ®é›†çš„è§„æ¨¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒä¸­æ•°æ®è´¨é‡ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®é€‰æ‹©å’Œåˆæˆä¸Šå¾€å¾€æ˜¯é™æ€çš„ï¼Œæ— æ³•é€‚åº”æ¨¡å‹èƒ½åŠ›çš„å˜åŒ–ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMiddoæ¡†æ¶é€šè¿‡å»ºç«‹ä¸€ä¸ªè‡ªæˆ‘æ¼”åŒ–çš„åŠ¨æ€æ•°æ®ä¼˜åŒ–ç³»ç»Ÿï¼Œåˆ©ç”¨æ¨¡å‹æ„ŸçŸ¥çš„æ–¹å¼é€‰æ‹©å’Œç²¾ç‚¼æ•°æ®ï¼Œä»è€Œæå‡è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œæ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMiddoæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼šè‡ªæˆ‘è¯Šæ–­æ¨¡å—ã€é€‚åº”æ€§ä¼˜åŒ–å¼•æ“å’ŒåŠ¨æ€å­¦ä¹ æœºåˆ¶ã€‚è‡ªæˆ‘è¯Šæ–­æ¨¡å—é€šè¿‡ä¸‰è½´æ¨¡å‹ä¿¡å·ï¼ˆæŸå¤±æ¨¡å¼ã€åµŒå…¥èšç±»åŠ¨æ€å’Œè‡ªå¯¹é½åˆ†æ•°ï¼‰è¯†åˆ«æ¬¡ä¼˜æ ·æœ¬ï¼Œé€‚åº”æ€§ä¼˜åŒ–å¼•æ“åˆ™å°†è¿™äº›æ ·æœ¬è½¬åŒ–ä¸ºæœ‰ä»·å€¼çš„è®­ç»ƒç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMiddoçš„åˆ›æ–°åœ¨äºå…¶é—­ç¯ä¼˜åŒ–ç³»ç»Ÿï¼Œèƒ½å¤Ÿæ ¹æ®æ¨¡å‹èƒ½åŠ›çš„æ¼”å˜åŠ¨æ€è°ƒæ•´æ•°æ®é€‰æ‹©å’Œä¼˜åŒ–ç­–ç•¥ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ä¸€æ¬¡æ€§æ•°æ®å¤„ç†æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒMiddoé‡‡ç”¨äº†ä¸‰è½´ä¿¡å·åˆ†ææ–¹æ³•ï¼Œç»“åˆæŸå¤±å‡½æ•°å’Œè‡ªå¯¹é½è¯„åˆ†æ¥è¯„ä¼°æ ·æœ¬è´¨é‡ï¼Œå¹¶é€šè¿‡ä¸Šä¸‹æ–‡ä¿ç•™æŠ€æœ¯ç¡®ä¿æ•°æ®çš„è¯­ä¹‰å®Œæ•´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMiddoæ¡†æ¶æ˜¾è‘—æé«˜äº†LLMçš„æ€§èƒ½ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº†7.15%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒMiddoåœ¨ä¿æŒåŸå§‹æ•°æ®é›†è§„æ¨¡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¼˜åŒ–è®­ç»ƒæ•°æ®è´¨é‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Middoæ¡†æ¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„è®­ç»ƒä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚å…¶åŠ¨æ€æ•°æ®ä¼˜åŒ–æœºåˆ¶ä¸ä»…é€‚ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œè¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦é«˜è´¨é‡æ•°æ®çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå¦‚å›¾åƒè¯†åˆ«å’Œè¯­éŸ³å¤„ç†ç­‰ã€‚æœªæ¥ï¼ŒMiddoå¯èƒ½æ¨åŠ¨äººæœºåä½œçš„è¿›ä¸€æ­¥å‘å±•ï¼Œå®ç°æ›´æ™ºèƒ½çš„è®­ç»ƒè¿‡ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Supervised Fine-Tuning (SFT) Large Language Models (LLM) fundamentally rely on high-quality training data. While data selection and data synthesis are two common strategies to improve data quality, existing approaches often face limitations in static dataset curation that fail to adapt to evolving model capabilities. In this paper, we introduce Middo, a self-evolving Model-informed dynamic data optimization framework that uses model-aware data selection and context-preserving data refinement. Unlike conventional one-off filtering/synthesis methods, our framework establishes a closed-loop optimization system: (1) A self-referential diagnostic module proactively identifies suboptimal samples through tri-axial model signals - loss patterns (complexity), embedding cluster dynamics (diversity), and self-alignment scores (quality); (2) An adaptive optimization engine then transforms suboptimal samples into pedagogically valuable training points while preserving semantic integrity; (3) This optimization process continuously evolves with model capability through dynamic learning principles. Experiments on multiple benchmarks demonstrate that our Middo consistently enhances the quality of seed data and boosts LLM's performance with improving accuracy by 7.15% on average while maintaining the original dataset scale. This work establishes a new paradigm for sustainable LLM training through dynamic human-AI co-evolution of data and models. Our datasets, models, and code are publicly available at https://github.com/Word2VecT/Middo.

