---
layout: default
title: COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions
---

# COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04470" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04470v1</a>
  <a href="https://arxiv.org/pdf/2509.04470.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04470v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04470v1', 'COCORELI: Cooperative, Compositional Reconstitution \& Execution of Language Instructions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Swarnadeep Bhar, Omar Naim, Eleni Metheniti, Bastien Navarri, LoÃ¯c Cabannes, Morteza Ezzabady, Nicholas Asher

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

**å¤‡æ³¨**: 18 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOCORELIä»¥è§£å†³å¤æ‚æŒ‡ä»¤æ‰§è¡Œä¸­çš„å±€é™æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ™ºèƒ½ä½“ç³»ç»Ÿ` `å¤æ‚æŒ‡ä»¤æ‰§è¡Œ` `åŠ¨æ€å­¦ä¹ ` `æŠ½è±¡æœºåˆ¶` `ç©ºé—´æ¨ç†` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æŒ‡ä»¤æ—¶å­˜åœ¨å¹»è§‰ã€ç©ºé—´æ¨ç†ä¸è¶³å’Œä¿¡æ¯ç¼ºå¤±ç­‰é—®é¢˜ã€‚
2. COCORELIé€šè¿‡é›†æˆä¸­å‹LLMæ™ºèƒ½ä½“ä¸æ–°å‹æŠ½è±¡æœºåˆ¶å’Œè¯è¯­æ¨¡å—ï¼Œæå‡äº†æŒ‡ä»¤è§£æå’Œç¯å¢ƒè¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCOCORELIåœ¨è‡ªç„¶åä½œæ„å»ºä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œæ˜¾è‘—å‡å°‘äº†å¹»è§‰ç°è±¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†COCORELIï¼Œä¸€ä¸ªæ··åˆæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œå¤æ‚æŒ‡ä»¤ã€å‡å°‘å¹»è§‰å’Œç©ºé—´æ¨ç†ç­‰ä»»åŠ¡ä¸­çš„å±€é™æ€§ã€‚COCORELIå°†ä¸­å‹LLMæ™ºèƒ½ä½“ä¸æ–°é¢–çš„æŠ½è±¡æœºåˆ¶å’Œè¯è¯­æ¨¡å—ç›¸ç»“åˆï¼Œä»¥è§£ææŒ‡ä»¤å¹¶åœ¨ä¸Šä¸‹æ–‡ä¸­å­¦ä¹ åŠ¨æ€çš„é«˜å±‚æ¬¡ç¯å¢ƒè¡¨ç¤ºã€‚åœ¨è‡ªç„¶åä½œæ„å»ºä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCOCORELIçš„è¡¨ç°ä¼˜äºå•ä¸€LLMçš„é“¾å¼æ¨ç†å’Œæ™ºèƒ½ä½“LLMç³»ç»Ÿï¼Œä¸”å‡ä½¿ç”¨æ›´å¤§çš„LLMã€‚å®ƒèƒ½å¤Ÿåœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šé¿å…å¹»è§‰ï¼Œè¯†åˆ«ç¼ºå¤±ä¿¡æ¯ï¼Œæå‡ºæ¾„æ¸…è¯·æ±‚ï¼Œå¹¶æ›´æ–°å…¶å­¦ä¹ çš„å¯¹è±¡ã€‚COCORELIçš„æŠ½è±¡èƒ½åŠ›è¶…è¶Šäº†ç¯å¢ƒï¼Œè¯æ˜äº†åœ¨ToolBench APIå®Œæˆä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‰§è¡Œå¤æ‚æŒ‡ä»¤æ—¶çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬å¹»è§‰ç°è±¡ã€ç©ºé—´æ¨ç†èƒ½åŠ›ä¸è¶³å’Œä¿¡æ¯ç¼ºå¤±ç­‰ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCOCORELIçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç»“åˆä¸­å‹LLMæ™ºèƒ½ä½“ä¸æ–°é¢–çš„æŠ½è±¡æœºåˆ¶å’Œè¯è¯­æ¨¡å—ï¼Œæ¥è§£ææŒ‡ä»¤å¹¶åŠ¨æ€å­¦ä¹ ç¯å¢ƒçš„é«˜å±‚æ¬¡è¡¨ç¤ºï¼Œä»è€Œæå‡æ‰§è¡Œèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCOCORELIçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šä¸­å‹LLMæ™ºèƒ½ä½“ç”¨äºæŒ‡ä»¤å¤„ç†ï¼ŒæŠ½è±¡æœºåˆ¶ç”¨äºä¿¡æ¯æå–ï¼Œè¯è¯­æ¨¡å—ç”¨äºä¸Šä¸‹æ–‡ç†è§£ï¼Œå½¢æˆä¸€ä¸ªåä½œçš„æ™ºèƒ½ä½“ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šCOCORELIçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æŠ½è±¡èƒ½åŠ›å’ŒåŠ¨æ€å­¦ä¹ æœºåˆ¶ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ç¼ºå¤±ä¿¡æ¯å¹¶è¿›è¡Œæ¾„æ¸…è¯·æ±‚ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€LLMæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒCOCORELIé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æŒ‡ä»¤è§£æå’Œç¯å¢ƒè¡¨ç¤ºçš„å­¦ä¹ æ•ˆæœï¼ŒåŒæ—¶ç¡®ä¿æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­é€‚åº”å˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒCOCORELIåœ¨è‡ªç„¶åä½œæ„å»ºä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºå•ä¸€LLMçš„é“¾å¼æ¨ç†å’Œå…¶ä»–æ™ºèƒ½ä½“LLMç³»ç»Ÿï¼Œæ˜¾è‘—å‡å°‘äº†å¹»è§‰ç°è±¡ï¼Œæå‡äº†ä¿¡æ¯è¯†åˆ«å’Œæ¾„æ¸…è¯·æ±‚çš„èƒ½åŠ›ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

COCORELIçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¤æ‚æŒ‡ä»¤æ‰§è¡Œçš„é¢†åŸŸï¼Œå¦‚æœºå™¨äººåä½œã€æ™ºèƒ½å®¶å±…ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–ç”Ÿäº§çº¿ç­‰ã€‚å…¶åˆ›æ–°çš„æŠ½è±¡æœºåˆ¶å’ŒåŠ¨æ€å­¦ä¹ èƒ½åŠ›å°†æ¨åŠ¨æ™ºèƒ½ä½“åœ¨å®é™…ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ•ˆç‡ï¼Œæœªæ¥å¯èƒ½å¯¹äººæœºåä½œäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present COCORELI, a hybrid agent framework designed to tackle the limitations of large language models (LLMs) in tasks requiring: following complex instructions, minimizing hallucination, and spatial reasoning. COCORELI integrates medium-sized LLM agents with novel abstraction mechanisms and a discourse module to parse instructions to in-context learn dynamic, high-level representations of the environment. Experiments on natural collaborative construction tasks show that COCORELI outperforms single-LLM CoT and agentic LLM systems, all using larger LLMs. It manages to largely avoid hallucinations, identify missing information, ask for clarifications, and update its learned objects. COCORELI's abstraction abilities extend beyond ENVIRONMENT, as shown in the ToolBench API completion task.

