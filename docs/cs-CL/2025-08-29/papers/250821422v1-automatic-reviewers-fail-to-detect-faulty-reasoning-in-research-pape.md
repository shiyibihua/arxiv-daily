---
layout: default
title: Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework
---

# Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21422" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21422v1</a>
  <a href="https://arxiv.org/pdf/2508.21422.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21422v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21422v1', 'Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nils Dycke, Iryna Gurevych

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨åŒ–åäº‹å®è¯„ä¼°æ¡†æ¶ä»¥æ£€æµ‹ç ”ç©¶è®ºæ–‡ä¸­çš„é€»è¾‘ç¼ºé™·**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨åŒ–è¯„å®¡` `é€»è¾‘æ£€æµ‹` `åäº‹å®è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç§‘å­¦è¯šä¿¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨åŒ–è¯„å®¡ç”Ÿæˆå™¨åœ¨æ£€æµ‹ç ”ç©¶é€»è¾‘ç¼ºé™·æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå¯èƒ½å½±å“ç§‘å­¦ç ”ç©¶çš„è´¨é‡å’Œå¯ä¿¡åº¦ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åäº‹å®è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨åœ¨å—æ§ç¯å¢ƒä¸­æµ‹è¯•ARGçš„é€»è¾‘æ£€æµ‹èƒ½åŠ›ï¼Œç¡®ä¿è¯„å®¡çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒARGåœ¨é¢å¯¹ç ”ç©¶é€»è¾‘ç¼ºé™·æ—¶ï¼Œå…¶è¾“å‡ºè¯„å®¡æœªå—åˆ°æ˜¾è‘—å½±å“ï¼Œæ­ç¤ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠ é€Ÿå’Œæ”¯æŒå­¦æœ¯åŒè¡Œè¯„å®¡æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œè¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œå®Œå…¨è‡ªåŠ¨åŒ–çš„è¯„å®¡ç”Ÿæˆå™¨ï¼ˆARGsï¼‰ã€‚ç„¶è€Œï¼Œæ½œåœ¨çš„åè§å’Œç³»ç»Ÿæ€§é”™è¯¯å¯èƒ½å¯¹ç§‘å­¦è¯šä¿¡æ„æˆé‡å¤§é£é™©ï¼Œå› æ­¤ç†è§£æœ€å…ˆè¿›çš„ARGçš„å…·ä½“èƒ½åŠ›å’Œå±€é™æ€§è‡³å…³é‡è¦ã€‚æœ¬æ–‡èšç„¦äºé«˜è´¨é‡åŒè¡Œè¯„å®¡çš„æ ¸å¿ƒæŠ€èƒ½ï¼šæ£€æµ‹ç ”ç©¶é€»è¾‘ç¼ºé™·ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå®Œå…¨è‡ªåŠ¨åŒ–çš„åäº‹å®è¯„ä¼°æ¡†æ¶ï¼Œåœ¨å—æ§æ¡ä»¶ä¸‹éš”ç¦»å’Œæµ‹è¯•è¿™ä¸€æŠ€èƒ½ã€‚æµ‹è¯•å¤šç§ARGæ–¹æ³•åï¼Œæˆ‘ä»¬å‘ç°ï¼Œä¸é¢„æœŸç›¸åï¼Œç ”ç©¶é€»è¾‘ä¸­çš„ç¼ºé™·å¯¹å…¶è¾“å‡ºè¯„å®¡æ²¡æœ‰æ˜¾è‘—å½±å“ã€‚åŸºäºæˆ‘ä»¬çš„å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸‰é¡¹å¯è¡Œçš„æœªæ¥å·¥ä½œå»ºè®®ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†æˆ‘ä»¬çš„åäº‹å®æ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨åŒ–è¯„å®¡ç”Ÿæˆå™¨åœ¨æ£€æµ‹ç ”ç©¶è®ºæ–‡é€»è¾‘ç¼ºé™·æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å†…éƒ¨ä¸€è‡´æ€§é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´é”™è¯¯çš„è¯„å®¡ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„åäº‹å®è¯„ä¼°æ¡†æ¶é€šè¿‡éš”ç¦»å’Œæµ‹è¯•ARGçš„é€»è¾‘æ£€æµ‹èƒ½åŠ›ï¼Œç¡®ä¿åœ¨å—æ§æ¡ä»¶ä¸‹è¯„ä¼°å…¶æ€§èƒ½ï¼Œæ—¨åœ¨æ­ç¤ºARGçš„æ½œåœ¨ç¼ºé™·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€é€»è¾‘ç¼ºé™·ç”Ÿæˆã€ARGè¯„å®¡ç”Ÿæˆå’Œè¯„ä¼°æŒ‡æ ‡è®¡ç®—ç­‰ä¸»è¦æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è¯„ä¼°æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡æå‡ºåäº‹å®è¯„ä¼°æ–¹æ³•ï¼Œç³»ç»Ÿæ€§åœ°æµ‹è¯•ARGåœ¨é€»è¾‘æ£€æµ‹æ–¹é¢çš„èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿè¯„å®¡æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºå®¢è§‚çš„è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†å¤šç§é€»è¾‘ç¼ºé™·ç±»å‹ï¼Œå¹¶ä½¿ç”¨æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡æ¥é‡åŒ–ARGçš„è¾“å‡ºè´¨é‡ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒARGåœ¨é¢å¯¹ç ”ç©¶é€»è¾‘ç¼ºé™·æ—¶ï¼Œå…¶è¾“å‡ºè¯„å®¡æœªå—åˆ°æ˜¾è‘—å½±å“ï¼Œè¡¨æ˜å½“å‰è‡ªåŠ¨åŒ–è¯„å®¡æ–¹æ³•åœ¨é€»è¾‘æ£€æµ‹æ–¹é¢çš„å±€é™æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥æ”¹è¿›ARGæä¾›äº†é‡è¦çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å­¦æœ¯å‡ºç‰ˆã€åŒè¡Œè¯„å®¡ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ–‡çŒ®åˆ†æå·¥å…·ã€‚é€šè¿‡æé«˜ARGçš„é€»è¾‘æ£€æµ‹èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå­¦æœ¯è¯„å®¡çš„è´¨é‡ï¼Œä¿ƒè¿›ç§‘å­¦ç ”ç©¶çš„è¯šä¿¡ä¸é€æ˜åº¦ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯æ‰©å±•è‡³å…¶ä»–é¢†åŸŸçš„è‡ªåŠ¨åŒ–è¯„ä¼°ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have great potential to accelerate and support scholarly peer review and are increasingly used as fully automatic review generators (ARGs). However, potential biases and systematic errors may pose significant risks to scientific integrity; understanding the specific capabilities and limitations of state-of-the-art ARGs is essential. We focus on a core reviewing skill that underpins high-quality peer review: detecting faulty research logic. This involves evaluating the internal consistency between a paper's results, interpretations, and claims. We present a fully automated counterfactual evaluation framework that isolates and tests this skill under controlled conditions. Testing a range of ARG approaches, we find that, contrary to expectation, flaws in research logic have no significant effect on their output reviews. Based on our findings, we derive three actionable recommendations for future work and release our counterfactual dataset and evaluation framework publicly.

