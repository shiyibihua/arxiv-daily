---
layout: default
title: GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting
---

# GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.06782" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.06782v1</a>
  <a href="https://arxiv.org/pdf/2510.06782.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06782v1" onclick="toggleFavorite(this, '2510.06782v1', 'GPT-5 Model Corrected GPT-4V\'s Chart Reading Errors, Not Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaichun Yang, Jian Chen

**åˆ†ç±»**: cs.HC, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-08

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**GPT-5æ— éœ€æç¤ºå³å¯ä¿®æ­£GPT-4Våœ¨å›¾è¡¨é˜…è¯»ä¸­çš„é”™è¯¯**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾è¡¨é˜…è¯»` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `GPT-5` `GPT-4V` `é›¶æ ·æœ¬å­¦ä¹ ` `å®šé‡è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚å›¾è¡¨ç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨å¤„ç†è§†è§‰ä¿¡æ¯æ—¶ä»æœ‰æå‡ç©ºé—´ã€‚
2. è¯¥ç ”ç©¶å¯¹æ¯”äº†GPT-5å’ŒGPT-4Våœ¨å›¾è¡¨é˜…è¯»ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç€é‡å…³æ³¨æ¨¡å‹æ¶æ„æœ¬èº«å¯¹æ€§èƒ½çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ›´å…ˆè¿›çš„æ¨¡å‹æ¶æ„ï¼ˆGPT-5ï¼‰åœ¨å›¾è¡¨é˜…è¯»å‡†ç¡®æ€§æ–¹é¢æœ‰æ˜¾è‘—æå‡ï¼Œæç¤ºå·¥ç¨‹çš„å½±å“ç›¸å¯¹è¾ƒå°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å¯¹é›¶æ ·æœ¬å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå…¶æç¤ºåœ¨å›¾è¡¨é˜…è¯»ä»»åŠ¡ä¸­çš„å½±å“è¿›è¡Œäº†å®šé‡è¯„ä¼°ã€‚æˆ‘ä»¬è¦æ±‚LLMså›ç­”107ä¸ªå¯è§†åŒ–é—®é¢˜ï¼Œä»¥æ¯”è¾ƒagentic GPT-5å’Œå¤šæ¨¡æ€GPT-4Våœ¨å›°éš¾å›¾åƒå®ä¾‹ä¸Šçš„æ¨ç†å‡†ç¡®æ€§ï¼Œåœ¨è¿™äº›å®ä¾‹ä¸­GPT-4Væœªèƒ½äº§ç”Ÿæ­£ç¡®çš„ç­”æ¡ˆã€‚ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹æ¶æ„ä¸»å¯¼äº†æ¨ç†å‡†ç¡®æ€§ï¼šGPT-5åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæé«˜äº†å‡†ç¡®æ€§ï¼Œè€Œæç¤ºå˜ä½“ä»…äº§ç”Ÿäº†å¾ˆå°çš„å½±å“ã€‚è¯¥å·¥ä½œçš„é¢„æ³¨å†Œç‰ˆæœ¬å¯åœ¨æ­¤å¤„è·å¾—ï¼šhttps://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3ï¼›Google Driveææ–™ä½äºï¼šhttps://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/viewã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨é˜…è¯»ç†è§£ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚GPT-4Vï¼Œåœ¨å¤„ç†å¤æ‚æˆ–å…·æœ‰æŒ‘æˆ˜æ€§çš„å›¾è¡¨æ—¶ï¼Œå®¹æ˜“å‡ºç°ç†è§£åå·®æˆ–é”™è¯¯ï¼Œå¯¼è‡´å›ç­”ä¸å‡†ç¡®ã€‚è¿™äº›ç—›ç‚¹é™åˆ¶äº†LLMsåœ¨æ•°æ®åˆ†æå’Œå¯è§†åŒ–é¢†åŸŸçš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¯¹æ¯”ä¸åŒæ¨¡å‹æ¶æ„ï¼ˆGPT-5 vs. GPT-4Vï¼‰åœ¨å›¾è¡¨é˜…è¯»ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä»¥æ­¤æ¥è¯„ä¼°æ¨¡å‹æ¶æ„æœ¬èº«å¯¹æ€§èƒ½çš„å½±å“ã€‚é€šè¿‡æ§åˆ¶æç¤ºå˜é‡ï¼Œç ”ç©¶äººå‘˜è¯•å›¾åˆ†ç¦»æ¨¡å‹æ¶æ„å’Œæç¤ºå·¥ç¨‹å¯¹æœ€ç»ˆç»“æœçš„è´¡çŒ®ï¼Œä»è€Œæ›´æ¸…æ™°åœ°äº†è§£æ¨¡å‹èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®šé‡è¯„ä¼°æ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«107ä¸ªå¯è§†åŒ–é—®é¢˜çš„å›¾è¡¨é˜…è¯»æ•°æ®é›†ã€‚ç ”ç©¶æµç¨‹åŒ…æ‹¬ï¼š1) ä½¿ç”¨GPT-4Vå’ŒGPT-5å›ç­”æ•°æ®é›†ä¸­çš„é—®é¢˜ï¼›2) æ¯”è¾ƒä¸¤ç§æ¨¡å‹åœ¨å›ç­”å‡†ç¡®æ€§ä¸Šçš„å·®å¼‚ï¼›3) åˆ†æä¸åŒæç¤ºç­–ç•¥å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚é‡ç‚¹å…³æ³¨GPT-4Væ— æ³•æ­£ç¡®å›ç­”çš„å›°éš¾å›¾åƒå®ä¾‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºç›´æ¥å¯¹æ¯”äº†GPT-5å’ŒGPT-4Våœ¨å›¾è¡¨é˜…è¯»ä»»åŠ¡ä¸Šçš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œå¹¶é‡åŒ–äº†æ¨¡å‹æ¶æ„å¯¹å‡†ç¡®æ€§çš„å½±å“ã€‚ä¸ä»¥å¾€ä¾§é‡äºæç¤ºå·¥ç¨‹çš„ç ”ç©¶ä¸åŒï¼Œè¯¥ç ”ç©¶å¼ºè°ƒäº†æ¨¡å‹æ¶æ„æœ¬èº«çš„é‡è¦æ€§ï¼Œä¸ºæœªæ¥æ¨¡å‹è®¾è®¡æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†107ä¸ªå¯è§†åŒ–é—®é¢˜ï¼Œè¿™äº›é—®é¢˜æ¶µç›–äº†ä¸åŒç±»å‹çš„å›¾è¡¨å’Œä¸åŒçš„ä¿¡æ¯æå–éœ€æ±‚ã€‚ç ”ç©¶äººå‘˜æ²¡æœ‰è¯¦ç»†è¯´æ˜å…·ä½“çš„å‚æ•°è®¾ç½®æˆ–ç½‘ç»œç»“æ„ï¼Œå› ä¸ºé‡ç‚¹åœ¨äºå¯¹æ¯”ç°æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚æç¤ºå˜ä½“çš„ä½¿ç”¨æ˜¯ä¸ºäº†è¯„ä¼°æç¤ºå·¥ç¨‹çš„å½±å“ï¼Œä½†å…·ä½“æç¤ºå†…å®¹æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-5åœ¨å›¾è¡¨é˜…è¯»ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§æ˜¾è‘—ä¼˜äºGPT-4Vï¼Œå°¤å…¶æ˜¯åœ¨GPT-4Væ— æ³•æ­£ç¡®å›ç­”çš„å›°éš¾å›¾åƒå®ä¾‹ä¸Šã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†æ¨¡å‹æ¶æ„å¯¹æ€§èƒ½çš„å†³å®šæ€§å½±å“ï¼Œæç¤ºå·¥ç¨‹çš„ä½œç”¨ç›¸å¯¹è¾ƒå°ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œä½†ç»“è®ºæ˜ç¡®æŒ‡å‡ºGPT-5çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½æ•°æ®åˆ†æã€è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆã€è¾…åŠ©å†³ç­–æ”¯æŒç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹å¯¹å›¾è¡¨çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°ä»å¯è§†åŒ–æ•°æ®ä¸­æå–ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®ã€æ›´ä¾¿æ·çš„æ•°æ®åˆ†ææœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ¨åŠ¨å¤šæ¨¡æ€å¤§æ¨¡å‹åœ¨å•†ä¸šæ™ºèƒ½ã€ç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a quantitative evaluation to understand the effect of zero-shot large-language model (LLMs) and prompting uses on chart reading tasks. We asked LLMs to answer 107 visualization questions to compare inference accuracies between the agentic GPT-5 and multimodal GPT-4V, for difficult image instances, where GPT-4V failed to produce correct answers. Our results show that model architecture dominates the inference accuracy: GPT5 largely improved accuracy, while prompt variants yielded only small effects. Pre-registration of this work is available here: https://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google Drive materials are here:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.

