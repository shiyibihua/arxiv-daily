---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-09-25
---

# cs.CLï¼ˆ2025-09-25ï¼‰

ğŸ“Š å…± **35** ç¯‡è®ºæ–‡
 | ğŸ”— **6** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (25 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (25 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250921679v1-reviewscore-misinformed-peer-review-detection-with-large-language-mo.html">ReviewScore: Misinformed Peer Review Detection with Large Language Models</a></td>
  <td>æå‡ºReviewScoreä»¥æ£€æµ‹åŒè¡Œè¯„å®¡ä¸­çš„é”™è¯¯ä¿¡æ¯ï¼Œæå‡è¯„å®¡è´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21679v1" data-paper-url="./papers/250921679v1-reviewscore-misinformed-peer-review-detection-with-large-language-mo.html" onclick="toggleFavorite(this, '2509.21679v1', 'ReviewScore: Misinformed Peer Review Detection with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250921284v1-bounds-of-chain-of-thought-robustness-reasoning-steps-embed-norms-an.html">Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond</a></td>
  <td>ç†è®ºåˆ†æCoTæ¨ç†çš„é²æ£’æ€§è¾¹ç•Œï¼Œæ­ç¤ºæ¨ç†æ­¥æ•°å’ŒåµŒå…¥èŒƒæ•°çš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21284v1" data-paper-url="./papers/250921284v1-bounds-of-chain-of-thought-robustness-reasoning-steps-embed-norms-an.html" onclick="toggleFavorite(this, '2509.21284v1', 'Bounds of Chain-of-Thought Robustness: Reasoning Steps, Embed Norms, and Beyond')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250921208v1-claw-benchmarking-chinese-legal-knowledge-in-large-language-models-a.html">CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis</a></td>
  <td>CLawï¼šæ„å»ºä¸­æ–‡æ³•å¾‹çŸ¥è¯†åŸºå‡†ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ³•å¾‹æ¨ç†ä¸­çš„èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21208v1" data-paper-url="./papers/250921208v1-claw-benchmarking-chinese-legal-knowledge-in-large-language-models-a.html" onclick="toggleFavorite(this, '2509.21208v1', 'CLaw: Benchmarking Chinese Legal Knowledge in Large Language Models - A Fine-grained Corpus and Reasoning Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250921106v1-bespoke-benchmark-for-search-augmented-large-language-model-personal.html">BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback</a></td>
  <td>æå‡ºBESPOKEåŸºå‡†ï¼Œç”¨äºè¯Šæ–­åé¦ˆé©±åŠ¨çš„æœç´¢å¢å¼ºLLMä¸ªæ€§åŒ–</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21106v1" data-paper-url="./papers/250921106v1-bespoke-benchmark-for-search-augmented-large-language-model-personal.html" onclick="toggleFavorite(this, '2509.21106v1', 'BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250921104v1-perhallueval-persian-hallucination-evaluation-benchmark-for-large-la.html">PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models</a></td>
  <td>æå‡ºPerHalluEvalï¼Œé¦–ä¸ªæ³¢æ–¯è¯­LLMå¹»è§‰è¯„ä¼°åŸºå‡†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21104v1" data-paper-url="./papers/250921104v1-perhallueval-persian-hallucination-evaluation-benchmark-for-large-la.html" onclick="toggleFavorite(this, '2509.21104v1', 'PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250921079v1-som-1k-a-thousand-problem-benchmark-dataset-for-strength-of-material.html">SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials</a></td>
  <td>æå‡ºSoM-1Kææ–™åŠ›å­¦åŸºå‡†æ•°æ®é›†ï¼Œè¯„ä¼°å¹¶æå‡å¤šæ¨¡æ€å·¥ç¨‹é—®é¢˜ä¸­å¤§æ¨¡å‹çš„æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21079v1" data-paper-url="./papers/250921079v1-som-1k-a-thousand-problem-benchmark-dataset-for-strength-of-material.html" onclick="toggleFavorite(this, '2509.21079v1', 'SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250921450v1-llm-based-support-for-diabetes-diagnosis-opportunities-scenarios-and.html">LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5</a></td>
  <td>åˆ©ç”¨GPT-5è¾…åŠ©ç³–å°¿ç—…è¯Šæ–­ï¼Œæå‡ä¸´åºŠå†³ç­–æ”¯æŒä¸æ‚£è€…ç†è§£</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21450v1" data-paper-url="./papers/250921450v1-llm-based-support-for-diabetes-diagnosis-opportunities-scenarios-and.html" onclick="toggleFavorite(this, '2509.21450v1', 'LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250921051v1-when-instructions-multiply-measuring-and-estimating-llm-capabilities.html">When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following</a></td>
  <td>æå‡ºManyIFEvalå’ŒStyleMBPPåŸºå‡†ï¼Œè¯„ä¼°å¹¶é¢„æµ‹LLMå¤šæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21051v1" data-paper-url="./papers/250921051v1-when-instructions-multiply-measuring-and-estimating-llm-capabilities.html" onclick="toggleFavorite(this, '2509.21051v1', 'When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250921623v1-ojakv-context-aware-online-low-rank-kv-cache-compression-with-ojas-r.html">OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule</a></td>
  <td>OjaKVï¼šåˆ©ç”¨Ojaè§„åˆ™è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥åœ¨çº¿ä½ç§©KVç¼“å­˜å‹ç¼©ï¼Œæå‡é•¿æ–‡æœ¬å¤„ç†æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21623v1" data-paper-url="./papers/250921623v1-ojakv-context-aware-online-low-rank-kv-cache-compression-with-ojas-r.html" onclick="toggleFavorite(this, '2509.21623v1', 'OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja&#39;s Rule')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251002326v1-hallucination-resistant-domain-specific-research-assistant-with-self.html">Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval</a></td>
  <td>æå‡ºRA-FSMï¼Œä¸€ç§æŠ—å¹»è§‰ã€é¢†åŸŸç‰¹å®šçš„ç ”ç©¶åŠ©æ‰‹ï¼Œé€šè¿‡è‡ªè¯„ä¼°å’Œå‘é‡æ£€ç´¢æå‡ä¸“å®¶å·¥ä½œæµæ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02326v1" data-paper-url="./papers/251002326v1-hallucination-resistant-domain-specific-research-assistant-with-self.html" onclick="toggleFavorite(this, '2510.02326v1', 'Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250921557v1-generation-time-vs-post-hoc-citation-a-holistic-evaluation-of-llm-at.html">Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution</a></td>
  <td>å¯¹æ¯”ç”Ÿæˆæ—¶å’Œåç½®å¼•ç”¨ï¼Œå…¨é¢è¯„ä¼°LLMçš„å½’å› èƒ½åŠ›ï¼Œä¸ºé«˜é£é™©åœºæ™¯æä¾›é€‰æ‹©ä¾æ®ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21557v1" data-paper-url="./papers/250921557v1-generation-time-vs-post-hoc-citation-a-holistic-evaluation-of-llm-at.html" onclick="toggleFavorite(this, '2509.21557v1', 'Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250921499v2-on-code-induced-reasoning-in-llms.html">On Code-Induced Reasoning in LLMs</a></td>
  <td>ç³»ç»Ÿæ€§ç ”ç©¶ä»£ç ç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œæ­ç¤ºç»“æ„ä¸è¯­ä¹‰æ‰°åŠ¨çš„å…³é”®ä½œç”¨</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21499v2" data-paper-url="./papers/250921499v2-on-code-induced-reasoning-in-llms.html" onclick="toggleFavorite(this, '2509.21499v2', 'On Code-Induced Reasoning in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250921443v1-one-model-many-morals-uncovering-cross-linguistic-misalignments-in-c.html">One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning</a></td>
  <td>æ­ç¤ºå¤šè¯­è¨€ç¯å¢ƒä¸‹å¤§è¯­è¨€æ¨¡å‹é“å¾·æ¨ç†çš„è·¨è¯­è¨€é”™ä½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21443v1" data-paper-url="./papers/250921443v1-one-model-many-morals-uncovering-cross-linguistic-misalignments-in-c.html" onclick="toggleFavorite(this, '2509.21443v1', 'One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250921305v2-sycophancy-is-not-one-thing-causal-separation-of-sycophantic-behavio.html">Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs</a></td>
  <td>å› LLMæºœé¡»æ‹é©¬è¡Œä¸ºå¹¶éå•ä¸€æœºåˆ¶ï¼Œè®ºæ–‡æå‡ºå› æœåˆ†ç¦»æ–¹æ³•ä»¥ç‹¬ç«‹æ§åˆ¶ä¸åŒè¡Œä¸ºã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21305v2" data-paper-url="./papers/250921305v2-sycophancy-is-not-one-thing-causal-separation-of-sycophantic-behavio.html" onclick="toggleFavorite(this, '2509.21305v2', 'Sycophancy Is Not One Thing: Causal Separation of Sycophantic Behaviors in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250921294v1-the-role-of-synthetic-data-in-multilingual-multi-cultural-ai-systems.html">The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages</a></td>
  <td>æå‡ºUpdeshæ•°æ®é›†ï¼Œåˆ©ç”¨åˆæˆæ•°æ®æå‡å¤šè¯­è¨€ã€å¤šæ–‡åŒ–AIç³»ç»Ÿåœ¨å°åº¦è¯­è¨€ä¸Šçš„æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21294v1" data-paper-url="./papers/250921294v1-the-role-of-synthetic-data-in-multilingual-multi-cultural-ai-systems.html" onclick="toggleFavorite(this, '2509.21294v1', 'The role of synthetic data in Multilingual, Multi-cultural AI systems: Lessons from Indic Languages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250921287v1-discoclip-a-distributional-compositional-tensor-network-encoder-for-.html">DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding</a></td>
  <td>DisCoCLIPï¼šä¸€ç§ç”¨äºè§†è§‰-è¯­è¨€ç†è§£çš„åˆ†å¸ƒç»„åˆå¼ é‡ç½‘ç»œç¼–ç å™¨</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21287v1" data-paper-url="./papers/250921287v1-discoclip-a-distributional-compositional-tensor-network-encoder-for-.html" onclick="toggleFavorite(this, '2509.21287v1', 'DisCoCLIP: A Distributional Compositional Tensor Network Encoder for Vision-Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250921269v1-llmtrace-a-corpus-for-classification-and-fine-grained-localization-o.html">LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text</a></td>
  <td>LLMTraceï¼šç”¨äºAIç”Ÿæˆæ–‡æœ¬åˆ†ç±»ä¸ç²¾ç»†å®šä½çš„åŒè¯­æ•°æ®é›†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21269v1" data-paper-url="./papers/250921269v1-llmtrace-a-corpus-for-classification-and-fine-grained-localization-o.html" onclick="toggleFavorite(this, '2509.21269v1', 'LLMTrace: A Corpus for Classification and Fine-Grained Localization of AI-Written Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250921267v2-llm-output-homogenization-is-task-dependent.html">LLM Output Homogenization is Task Dependent</a></td>
  <td>æå‡ºä»»åŠ¡ä¾èµ–çš„LLMè¾“å‡ºåŒè´¨åŒ–è¯„ä¼°ä¸ç¼“è§£æ–¹æ³•ï¼Œæå‡åŠŸèƒ½å¤šæ ·æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21267v2" data-paper-url="./papers/250921267v2-llm-output-homogenization-is-task-dependent.html" onclick="toggleFavorite(this, '2509.21267v2', 'LLM Output Homogenization is Task Dependent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250921193v1-eigen-1-adaptive-multi-agent-refinement-with-monitor-based-rag-for-s.html">Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning</a></td>
  <td>Eigen-1ï¼šåŸºäºMonitorçš„RAGè‡ªé€‚åº”å¤šæ™ºèƒ½ä½“ç²¾ç‚¼ï¼Œç”¨äºç§‘å­¦æ¨ç†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21193v1" data-paper-url="./papers/250921193v1-eigen-1-adaptive-multi-agent-refinement-with-monitor-based-rag-for-s.html" onclick="toggleFavorite(this, '2509.21193v1', 'Eigen-1: Adaptive Multi-Agent Refinement with Monitor-Based RAG for Scientific Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250921175v1-whos-laughing-now-an-overview-of-computational-humour-generation-and.html">Who's Laughing Now? An Overview of Computational Humour Generation and Explanation</a></td>
  <td>è®¡ç®—å¹½é»˜ç”Ÿæˆä¸è§£é‡Šç»¼è¿°ï¼šæ¢ç´¢NLPåœ¨å¹½é»˜ç†è§£ä¸åˆ›é€ ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21175v1" data-paper-url="./papers/250921175v1-whos-laughing-now-an-overview-of-computational-humour-generation-and.html" onclick="toggleFavorite(this, '2509.21175v1', 'Who&#39;s Laughing Now? An Overview of Computational Humour Generation and Explanation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250921080v1-which-cultural-lens-do-models-adopt-on-cultural-positioning-bias-and.html">Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs</a></td>
  <td>æ­ç¤ºLLMæ–‡åŒ–å®šä½åå·®å¹¶æå‡ºåŸºäºAgentçš„åè§ç¼“è§£æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21080v1" data-paper-url="./papers/250921080v1-which-cultural-lens-do-models-adopt-on-cultural-positioning-bias-and.html" onclick="toggleFavorite(this, '2509.21080v1', 'Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250921057v1-pmark-towards-robust-and-distortion-free-semantic-level-watermarking.html">PMark: Towards Robust and Distortion-free Semantic-level Watermarking with Channel Constraints</a></td>
  <td>PMarkï¼šåŸºäºé€šé“çº¦æŸçš„é²æ£’æ— å¤±çœŸè¯­ä¹‰çº§æ°´å°æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21057v1" data-paper-url="./papers/250921057v1-pmark-towards-robust-and-distortion-free-semantic-level-watermarking.html" onclick="toggleFavorite(this, '2509.21057v1', 'PMark: Towards Robust and Distortion-free Semantic-level Watermarking with Channel Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250921042v1-behind-rope-how-does-causal-mask-encode-positional-information.html">Behind RoPE: How Does Causal Mask Encode Positional Information?</a></td>
  <td>æ­ç¤ºRoPEèƒŒåæœºåˆ¶ï¼šå› æœæ©ç å¦‚ä½•ç¼–ç ä½ç½®ä¿¡æ¯</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21042v1" data-paper-url="./papers/250921042v1-behind-rope-how-does-causal-mask-encode-positional-information.html" onclick="toggleFavorite(this, '2509.21042v1', 'Behind RoPE: How Does Causal Mask Encode Positional Information?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250921040v1-generative-ai-for-ffrdcs.html">Generative AI for FFRDCs</a></td>
  <td>åˆ©ç”¨ç”Ÿæˆå¼AIåŠ é€ŸFFRDCæ–‡æœ¬åˆ†æï¼Œæå‡æ”¿åºœæœºæ„æ•ˆç‡ä¸å®‰å…¨æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21040v1" data-paper-url="./papers/250921040v1-generative-ai-for-ffrdcs.html" onclick="toggleFavorite(this, '2509.21040v1', 'Generative AI for FFRDCs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250920982v1-analysis-of-instruction-based-llms-capabilities-to-score-and-judge-t.html">Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting</a></td>
  <td>æå‡ºåŸºäºLLMçš„è‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿï¼Œç”¨äºè¯„ä¼°å­¦æœ¯æ–‡æœ¬è¾“å…¥é—®é¢˜ï¼Œå‚è€ƒç­”æ¡ˆè¾…åŠ©æ•ˆæœæœ€ä½³ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.20982v1" data-paper-url="./papers/250920982v1-analysis-of-instruction-based-llms-capabilities-to-score-and-judge-t.html" onclick="toggleFavorite(this, '2509.20982v1', 'Analysis of instruction-based LLMs&#39; capabilities to score and judge text-input problems in an academic setting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>26</td>
  <td><a href="./papers/250921613v1-multi-objective-reinforcement-learning-for-large-language-model-opti.html">Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective</a></td>
  <td>é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ä¼˜åŒ–ï¼Œæå‡ºå¤šç›®æ ‡å¼ºåŒ–å­¦ä¹ çš„è¿œæ™¯æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21613v1" data-paper-url="./papers/250921613v1-multi-objective-reinforcement-learning-for-large-language-model-opti.html" onclick="toggleFavorite(this, '2509.21613v1', 'Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250921151v1-retrieval-over-classification-integrating-relation-semantics-for-mul.html">Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction</a></td>
  <td>æå‡ºROCæ¡†æ¶ï¼Œå°†å¤šæ¨¡æ€å…³ç³»æŠ½å–é‡æ„ä¸ºæ£€ç´¢ä»»åŠ¡ï¼Œæå‡ç»†ç²’åº¦å…³ç³»ç†è§£èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21151v1" data-paper-url="./papers/250921151v1-retrieval-over-classification-integrating-relation-semantics-for-mul.html" onclick="toggleFavorite(this, '2509.21151v1', 'Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250922739v2-painless-activation-steering-an-automated-lightweight-approach-for-p.html">Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models</a></td>
  <td>æå‡ºPainless Activation Steering (PAS)ï¼Œä¸€ç§å…¨è‡ªåŠ¨ã€è½»é‡çº§çš„åè®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æ¿€æ´»å‘é‡è°ƒæ§æ–¹æ³•ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.22739v2" data-paper-url="./papers/250922739v2-painless-activation-steering-an-automated-lightweight-approach-for-p.html" onclick="toggleFavorite(this, '2509.22739v2', 'Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250921320v3-scireasoner-laying-the-scientific-reasoning-ground-across-discipline.html">SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines</a></td>
  <td>SciReasonerï¼šæ„å»ºè·¨å­¦ç§‘çš„ç§‘å­¦æ¨ç†åŸºç¡€æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward shaping</span> <span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21320v3" data-paper-url="./papers/250921320v3-scireasoner-laying-the-scientific-reasoning-ground-across-discipline.html" onclick="toggleFavorite(this, '2509.21320v3', 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250921487v2-dual-head-reasoning-distillation-improving-classifier-accuracy-with-.html">Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning</a></td>
  <td>æå‡ºåŒå¤´æ¨ç†è’¸é¦(DHRD)ï¼Œåœ¨ä¸ç‰ºç‰²æ¨ç†é€Ÿåº¦çš„å‰æä¸‹æå‡åˆ†ç±»å™¨ç²¾åº¦ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21487v2" data-paper-url="./papers/250921487v2-dual-head-reasoning-distillation-improving-classifier-accuracy-with-.html" onclick="toggleFavorite(this, '2509.21487v2', 'Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250921482v1-learning-to-reason-with-mixture-of-tokens.html">Learning to Reason with Mixture of Tokens</a></td>
  <td>æå‡ºæ··åˆTokenç”Ÿæˆæ–¹æ³•ï¼Œæå‡LLMåœ¨å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21482v1" data-paper-url="./papers/250921482v1-learning-to-reason-with-mixture-of-tokens.html" onclick="toggleFavorite(this, '2509.21482v1', 'Learning to Reason with Mixture of Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/251002324v2-hallucination-reduction-with-casal-contrastive-activation-steering-f.html">Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning</a></td>
  <td>CASALï¼šå¯¹æ¯”æ¿€æ´»å¼•å¯¼çš„æ‘Šé”€å­¦ä¹ ï¼Œæœ‰æ•ˆé™ä½å¤§è¯­è¨€æ¨¡å‹å¹»è§‰</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02324v2" data-paper-url="./papers/251002324v2-hallucination-reduction-with-casal-contrastive-activation-steering-f.html" onclick="toggleFavorite(this, '2510.02324v2', 'Hallucination reduction with CASAL: Contrastive Activation Steering For Amortized Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250921459v1-a-state-of-the-art-sql-reasoning-model-using-rlvr.html">A State-of-the-Art SQL Reasoning Model using RLVR</a></td>
  <td>åˆ©ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œæå‡ºSQLæ¨ç†æ¨¡å‹RLVRï¼Œåœ¨BIRDæ•°æ®é›†ä¸Šè¾¾åˆ°SOTAã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline RL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21459v1" data-paper-url="./papers/250921459v1-a-state-of-the-art-sql-reasoning-model-using-rlvr.html" onclick="toggleFavorite(this, '2509.21459v1', 'A State-of-the-Art SQL Reasoning Model using RLVR')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250921319v2-rlbff-binary-flexible-feedback-to-bridge-between-human-feedback-veri.html">RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards</a></td>
  <td>æå‡ºRLBFFï¼Œç»“åˆäººç±»åé¦ˆå’Œå¯éªŒè¯å¥–åŠ±ï¼Œæå‡LLMå¯¹é½æ•ˆæœå¹¶æ”¯æŒæ¨ç†æ—¶è‡ªå®šä¹‰åŸåˆ™ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21319v2" data-paper-url="./papers/250921319v2-rlbff-binary-flexible-feedback-to-bridge-between-human-feedback-veri.html" onclick="toggleFavorite(this, '2509.21319v2', 'RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>35</td>
  <td><a href="./papers/250921576v1-vision-language-models-cannot-plan-but-can-they-formalize.html">Vision Language Models Cannot Plan, but Can They Formalize?</a></td>
  <td>æå‡ºVLMä½œä¸ºå½¢å¼åŒ–å·¥å…·ä»¥è§£å†³å¤šæ¨¡æ€è§„åˆ’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">open-vocabulary</span> <span class="paper-tag">open vocabulary</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.21576v1" data-paper-url="./papers/250921576v1-vision-language-models-cannot-plan-but-can-they-formalize.html" onclick="toggleFavorite(this, '2509.21576v1', 'Vision Language Models Cannot Plan, but Can They Formalize?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)