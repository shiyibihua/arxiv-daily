---
layout: default
title: On Code-Induced Reasoning in LLMs
---

# On Code-Induced Reasoning in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21499" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21499v2</a>
  <a href="https://arxiv.org/pdf/2509.21499.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21499v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21499v2', 'On Code-Induced Reasoning in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdul Waheed, Zhen Wu, Carolyn RosÃ©, Daphne Ippolito

**åˆ†ç±»**: cs.CL, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25 (æ›´æ–°: 2025-10-02)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿæ€§ç ”ç©¶ä»£ç ç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œæ­ç¤ºç»“æ„ä¸è¯­ä¹‰æ‰°åŠ¨çš„å…³é”®ä½œç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç æ¨ç†` `ç»“æ„æ‰°åŠ¨` `è¯­ä¹‰æ‰°åŠ¨` `å¤šè¯­è¨€æ•°æ®é›†` `æ¨¡å‹å¾®è°ƒ` `æ¨ç†èƒ½åŠ›` `æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹ä»£ç å¢å¼ºLLMæ¨ç†èƒ½åŠ›çš„æœºåˆ¶ç†è§£ä¸è¶³ï¼Œç¼ºä¹å¯¹ä»£ç ç»“æ„å’Œè¯­ä¹‰ä½œç”¨çš„ç³»ç»Ÿæ€§åˆ†æã€‚
2. é€šè¿‡æ„å»ºå¤šè¯­è¨€ä»£ç æ•°æ®é›†å¹¶å¼•å…¥ç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨ï¼Œç ”ç©¶ä¸åŒä»£ç ç‰¹æ€§å¯¹LLMæ¨ç†çš„å½±å“ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMå¯¹ä»£ç ç»“æ„æ‰°åŠ¨æ›´æ•æ„Ÿï¼Œä¸”é€‚å½“çš„ä»£ç æŠ½è±¡å½¢å¼ï¼ˆå¦‚ä¼ªä»£ç ï¼‰ä¹Ÿèƒ½æœ‰æ•ˆæå‡æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†ä»£ç æ•°æ®å¦‚ä½•å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¢ç©¶äº†ä»£ç ä¸­å“ªäº›æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ã€‚ä½œè€…æ„å»ºäº†åç§ç¼–ç¨‹è¯­è¨€çš„å¹¶è¡ŒæŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åº”ç”¨å¯æ§æ‰°åŠ¨é€‰æ‹©æ€§åœ°ç ´åä»£ç çš„ç»“æ„æˆ–è¯­ä¹‰å±æ€§ã€‚ç„¶åï¼Œåœ¨æ¯ä¸ªå˜ä½“ä¸Šå¾®è°ƒæ¥è‡ªäº”ä¸ªæ¨¡å‹å®¶æ—å’Œå…«ä¸ªå°ºåº¦çš„LLMï¼Œå¹¶åœ¨è‡ªç„¶è¯­è¨€ã€æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šè¯„ä¼°å®ƒä»¬çš„æ€§èƒ½ã€‚é€šè¿‡3331ä¸ªå®éªŒï¼Œç»“æœè¡¨æ˜LLMå¯¹ç»“æ„æ‰°åŠ¨æ¯”è¯­ä¹‰æ‰°åŠ¨æ›´æ•æ„Ÿï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šã€‚ä¼ªä»£ç å’Œæµç¨‹å›¾ç­‰é€‚å½“çš„æŠ½è±¡å¯ä»¥ä¸ä»£ç ä¸€æ ·æœ‰æ•ˆï¼Œè€Œç”¨æ›´å°‘çš„tokenç¼–ç ç›¸åŒçš„ä¿¡æ¯è€Œä¸éµå®ˆåŸå§‹è¯­æ³•é€šå¸¸å¯ä»¥ä¿æŒç”šè‡³æé«˜æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå³ä½¿æ˜¯å¸¦æœ‰è¯¯å¯¼æ€§ä¿¡å·çš„æŸåä»£ç ï¼Œå½“è¡¨é¢å±‚é¢çš„è§„å¾‹æ€§ä»ç„¶å­˜åœ¨æ—¶ï¼Œä»ç„¶å…·æœ‰ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œä¸åŒçš„è¯­æ³•é£æ ¼ä¹Ÿä¼šå½±å“ç‰¹å®šä»»åŠ¡çš„å¢ç›Šï¼ŒPythonæœ‰åˆ©äºè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œè€ŒJavaå’ŒRustç­‰è¾ƒä½çº§åˆ«çš„è¯­è¨€åˆ™æœ‰åˆ©äºæ•°å­¦ã€‚é€šè¿‡æœ¬æ–‡çš„ç³»ç»Ÿæ€§æ¡†æ¶ï¼Œæ—¨åœ¨æ·±å…¥äº†è§£ä»£ç çš„ä¸åŒå±æ€§å¦‚ä½•å½±å“æ¨ç†ï¼Œå¹¶ä¸ºå¢å¼ºLLMæ¨ç†èƒ½åŠ›çš„è®­ç»ƒæ•°æ®è®¾è®¡æä¾›ä¿¡æ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç ”ç©¶è¡¨æ˜ï¼Œä»£ç æ•°æ®å¯ä»¥æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…·ä½“æ˜¯ä»£ç çš„å“ªäº›ç‰¹æ€§èµ·ä½œç”¨å°šä¸æ˜ç¡®ã€‚ç°æœ‰çš„æ–¹æ³•ç¼ºä¹å¯¹ä»£ç ç»“æ„å’Œè¯­ä¹‰åœ¨LLMæ¨ç†ä¸­ä½œç”¨çš„ç³»ç»Ÿæ€§åˆ†æï¼Œéš¾ä»¥æŒ‡å¯¼LLMè®­ç»ƒæ•°æ®çš„æœ‰æ•ˆè®¾è®¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿæ€§åœ°æ§åˆ¶ä»£ç æ•°æ®çš„ç»“æ„å’Œè¯­ä¹‰å±æ€§ï¼Œå¹¶è§‚å¯ŸLLMåœ¨ä¸åŒæ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä»è€Œæ­ç¤ºä»£ç çš„ä¸åŒç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚é€šè¿‡æ„å»ºå¤šè¯­è¨€çš„å¹¶è¡ŒæŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶å¼•å…¥å¯æ§çš„ç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨ï¼Œå¯ä»¥ç²¾ç¡®åœ°è¯„ä¼°ä¸åŒä»£ç ç‰¹æ€§å¯¹LLMçš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) æ„å»ºå¤šè¯­è¨€å¹¶è¡ŒæŒ‡ä»¤æ•°æ®é›†ï¼ŒåŒ…å«åç§ç¼–ç¨‹è¯­è¨€ï¼›2) å¯¹ä»£ç æ•°æ®è¿›è¡Œç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨ï¼Œç”Ÿæˆä¸åŒçš„å˜ä½“ï¼›3) åœ¨ä¸åŒçš„ä»£ç å˜ä½“ä¸Šå¾®è°ƒæ¥è‡ªäº”ä¸ªæ¨¡å‹å®¶æ—å’Œå…«ä¸ªå°ºåº¦çš„LLMï¼›4) åœ¨è‡ªç„¶è¯­è¨€ã€æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šè¯„ä¼°å¾®è°ƒåçš„LLMçš„æ€§èƒ½ï¼›5) åˆ†æå®éªŒç»“æœï¼Œæ­ç¤ºä»£ç çš„ä¸åŒç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„ã€æ•°æ®é©±åŠ¨çš„æ¡†æ¶ï¼Œç”¨äºç ”ç©¶ä»£ç ç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºå¤šè¯­è¨€å¹¶è¡ŒæŒ‡ä»¤æ•°æ®é›†å’Œå¼•å…¥å¯æ§çš„ç»“æ„å’Œè¯­ä¹‰æ‰°åŠ¨ï¼Œå®ç°äº†å¯¹ä»£ç ç‰¹æ€§çš„ç²¾ç¡®æ§åˆ¶å’Œè¯„ä¼°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ›´æ·±å…¥åœ°ç†è§£ä»£ç çš„ä¸åŒç‰¹æ€§åœ¨LLMæ¨ç†ä¸­æ‰€èµ·çš„ä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®æ‰°åŠ¨æ–¹é¢ï¼Œè®¾è®¡äº†å¤šç§ç»“æ„æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œæ”¹å˜ä»£ç çš„ç¼©è¿›ã€åˆ é™¤æ³¨é‡Šç­‰ï¼‰å’Œè¯­ä¹‰æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œæ”¹å˜å˜é‡åã€æ›¿æ¢ç­‰ä»·çš„å‡½æ•°ç­‰ï¼‰ã€‚åœ¨æ¨¡å‹è®­ç»ƒæ–¹é¢ï¼Œé€‰æ‹©äº†æ¥è‡ªä¸åŒæ¨¡å‹å®¶æ—å’Œä¸åŒå°ºåº¦çš„LLMï¼Œä»¥ä¿è¯å®éªŒç»“æœçš„æ³›åŒ–æ€§ã€‚åœ¨è¯„ä¼°æ–¹é¢ï¼Œé€‰æ‹©äº†è‡ªç„¶è¯­è¨€ã€æ•°å­¦å’Œä»£ç ä¸‰ç§ä¸åŒç±»å‹çš„æ¨ç†ä»»åŠ¡ï¼Œä»¥å…¨é¢è¯„ä¼°ä»£ç ç‰¹æ€§å¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMå¯¹ä»£ç çš„ç»“æ„æ‰°åŠ¨æ¯”è¯­ä¹‰æ‰°åŠ¨æ›´æ•æ„Ÿï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦å’Œä»£ç ä»»åŠ¡ä¸Šã€‚ä¼ªä»£ç å’Œæµç¨‹å›¾ç­‰é€‚å½“çš„æŠ½è±¡å¯ä»¥ä¸ä»£ç ä¸€æ ·æœ‰æ•ˆï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œç”¨æ›´å°‘çš„tokenç¼–ç ç›¸åŒçš„ä¿¡æ¯å¯ä»¥æé«˜æ€§èƒ½ã€‚Pythonæ›´é€‚åˆè‡ªç„¶è¯­è¨€æ¨ç†ï¼Œè€ŒJavaå’ŒRustç­‰åº•å±‚è¯­è¨€æ›´é€‚åˆæ•°å­¦æ¨ç†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæŒ‡å¯¼LLMè®­ç»ƒæ•°æ®çš„è®¾è®¡ï¼Œé€šè¿‡ä¼˜åŒ–ä»£ç æ•°æ®çš„ç»“æ„å’Œè¯­ä¹‰å±æ€§ï¼Œæå‡LLMåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆç­‰é¢†åŸŸçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥å¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£LLMçš„æ¨ç†æœºåˆ¶ï¼Œä»è€Œå¼€å‘å‡ºæ›´æœ‰æ•ˆçš„LLMåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Code data has been shown to enhance the reasoning capabilities of large language models (LLMs), but it remains unclear which aspects of code are most responsible. We investigate this question with a systematic, data-centric framework. We construct parallel instruction datasets in ten programming languages and apply controlled perturbations that selectively disrupt structural or semantic properties of code. We then finetune LLMs from five model families and eight scales on each variant and evaluate their performance on natural language, math, and code tasks. Across 3,331 experiments, our results show that LLMs are more vulnerable to structural perturbations than semantic ones, particularly on math and code tasks. Appropriate abstractions like pseudocode and flowcharts can be as effective as code, while encoding the same information with fewer tokens without adhering to original syntax can often retain or even improve performance. Remarkably, even corrupted code with misleading signals remains competitive when surface-level regularities persist. Finally, syntactic styles also shape task-specific gains with Python favoring natural language reasoning and lower-level languages such as Java and Rust favoring math. Through our systematic framework, we aim to provide insight into how different properties of code influence reasoning and inform the design of training data for enhancing LLM reasoning capabilities.

