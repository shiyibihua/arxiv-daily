---
layout: default
title: Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction
---

# Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21151" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21151v1</a>
  <a href="https://arxiv.org/pdf/2509.21151.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21151v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21151v1', 'Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lei Hei, Tingjing Liao, Yingxin Pei, Yiyang Qi, Jiaqi Wang, Ruiting Li, Feiliang Ren

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: Accepted by EMNLP 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºROCæ¡†æ¶ï¼Œå°†å¤šæ¨¡æ€å…³ç³»æŠ½å–é‡æ„ä¸ºæ£€ç´¢ä»»åŠ¡ï¼Œæå‡ç»†ç²’åº¦å…³ç³»ç†è§£èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å…³ç³»æŠ½å–` `æ£€ç´¢å¼å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `è‡ªç„¶è¯­è¨€å¤„ç†` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€å…³ç³»æŠ½å–ä¸­é‡‡ç”¨åˆ†ç±»èŒƒå¼ï¼Œå¿½ç•¥äº†å®ä½“ç±»å‹ç­‰ç»“æ„ä¿¡æ¯ï¼Œé™åˆ¶äº†ç»†ç²’åº¦å…³ç³»ç†è§£ã€‚
2. ROCæ¡†æ¶å°†å…³ç³»æŠ½å–è½¬åŒ–ä¸ºæ£€ç´¢ä»»åŠ¡ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºå…³ç³»è¯­ä¹‰è¡¨è¾¾ï¼Œå¹¶é€šè¿‡å¯¹æ¯”å­¦ä¹ å¯¹é½å®ä½“-å…³ç³»å¯¹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒROCåœ¨MNREå’ŒMOREæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶å±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³ç³»æŠ½å–ï¼ˆREï¼‰æ—¨åœ¨è¯†åˆ«éç»“æ„åŒ–æ–‡æœ¬ä¸­å®ä½“é—´çš„è¯­ä¹‰å…³ç³»ã€‚è™½ç„¶æœ€è¿‘çš„ç ”ç©¶å°†ä¼ ç»ŸREæ‰©å±•åˆ°å¤šæ¨¡æ€åœºæ™¯ï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä»ç„¶é‡‡ç”¨åŸºäºåˆ†ç±»çš„èŒƒå¼ï¼Œèåˆå¤šæ¨¡æ€ç‰¹å¾ï¼Œå¹¶å°†å…³ç³»è¡¨ç¤ºä¸ºç¦»æ•£æ ‡ç­¾ã€‚è¿™ç§èŒƒå¼å­˜åœ¨ä¸¤ä¸ªæ˜¾è‘—çš„å±€é™æ€§ï¼šï¼ˆ1ï¼‰å¿½ç•¥äº†å®ä½“ç±»å‹å’Œä½ç½®çº¿ç´¢ç­‰ç»“æ„çº¦æŸï¼›ï¼ˆ2ï¼‰ç¼ºä¹å¯¹ç»†ç²’åº¦å…³ç³»ç†è§£çš„è¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†æ£€ç´¢ä¼˜äºåˆ†ç±»ï¼ˆROCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒå°†å¤šæ¨¡æ€REé‡æ„ä¸ºç”±å…³ç³»è¯­ä¹‰é©±åŠ¨çš„æ£€ç´¢ä»»åŠ¡ã€‚ROCé€šè¿‡å¤šæ¨¡æ€ç¼–ç å™¨æ•´åˆå®ä½“ç±»å‹å’Œä½ç½®ä¿¡æ¯ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å°†å…³ç³»æ ‡ç­¾æ‰©å±•ä¸ºè‡ªç„¶è¯­è¨€æè¿°ï¼Œå¹¶é€šè¿‡åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„å¯¹æ¯”å­¦ä¹ å¯¹é½å®ä½“-å…³ç³»å¯¹ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŸºå‡†æ•°æ®é›†MNREå’ŒMOREä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤šæ¨¡æ€å…³ç³»æŠ½å–æ–¹æ³•ä¸»è¦é‡‡ç”¨åŸºäºåˆ†ç±»çš„èŒƒå¼ï¼Œç›´æ¥å°†èåˆåçš„å¤šæ¨¡æ€ç‰¹å¾æ˜ å°„åˆ°é¢„å®šä¹‰çš„ç¦»æ•£å…³ç³»æ ‡ç­¾ã€‚è¿™ç§æ–¹æ³•å¿½ç•¥äº†å®ä½“ç±»å‹ã€ä½ç½®ç­‰ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶ä¸”ç¦»æ•£æ ‡ç­¾éš¾ä»¥è¡¨è¾¾ç»†ç²’åº¦çš„å…³ç³»è¯­ä¹‰ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤šæ¨¡æ€å…³ç³»æŠ½å–é—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªæ£€ç´¢é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œç»™å®šä¸€ä¸ªå®ä½“å¯¹ï¼Œæ¨¡å‹ä¸æ˜¯ç›´æ¥é¢„æµ‹å®ƒä»¬ä¹‹é—´çš„å…³ç³»æ ‡ç­¾ï¼Œè€Œæ˜¯ä»ä¸€ä¸ªå…³ç³»æè¿°åº“ä¸­æ£€ç´¢æœ€ç›¸å…³çš„å…³ç³»æè¿°ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨å…³ç³»è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ä¸”å¯ä»¥æ›´å®¹æ˜“åœ°æ•´åˆå®ä½“ç±»å‹å’Œä½ç½®ç­‰ç»“æ„åŒ–ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šROCæ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šå¤šæ¨¡æ€ç¼–ç å™¨ã€å…³ç³»æè¿°ç”Ÿæˆå™¨å’Œå¯¹æ¯”å­¦ä¹ æ¨¡å—ã€‚å¤šæ¨¡æ€ç¼–ç å™¨è´Ÿè´£å°†æ–‡æœ¬å’Œå›¾åƒä¿¡æ¯ç¼–ç æˆå®ä½“å¯¹çš„è¡¨ç¤ºå‘é‡ï¼ŒåŒæ—¶æ•´åˆå®ä½“ç±»å‹å’Œä½ç½®ä¿¡æ¯ã€‚å…³ç³»æè¿°ç”Ÿæˆå™¨ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å°†å…³ç³»æ ‡ç­¾æ‰©å±•ä¸ºè‡ªç„¶è¯­è¨€æè¿°ï¼Œä»è€Œå¢å¼ºå…³ç³»è¯­ä¹‰è¡¨è¾¾ã€‚å¯¹æ¯”å­¦ä¹ æ¨¡å—é€šè¿‡æœ€å¤§åŒ–å®ä½“å¯¹è¡¨ç¤ºå‘é‡å’Œç›¸å…³å…³ç³»æè¿°å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–ä¸ä¸ç›¸å…³å…³ç³»æè¿°å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä»è€Œå­¦ä¹ åˆ°æ›´å¥½çš„å®ä½“-å…³ç³»å¯¹é½è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šROCæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤šæ¨¡æ€å…³ç³»æŠ½å–é—®é¢˜è½¬åŒ–ä¸ºæ£€ç´¢é—®é¢˜ï¼Œå¹¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¢å¼ºå…³ç³»è¯­ä¹‰è¡¨è¾¾ã€‚ä¸ä¼ ç»Ÿçš„åˆ†ç±»æ–¹æ³•ç›¸æ¯”ï¼ŒROCæ¡†æ¶å¯ä»¥æ›´å¥½åœ°åˆ©ç”¨å…³ç³»è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ä¸”å¯ä»¥æ›´å®¹æ˜“åœ°æ•´åˆå®ä½“ç±»å‹å’Œä½ç½®ç­‰ç»“æ„åŒ–ä¿¡æ¯ã€‚æ­¤å¤–ï¼ŒROCæ¡†æ¶è¿˜é€šè¿‡å¯¹æ¯”å­¦ä¹ æ¥å­¦ä¹ å®ä½“-å…³ç³»å¯¹é½è¡¨ç¤ºï¼Œä»è€Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¤šæ¨¡æ€ç¼–ç å™¨ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†Transformerç½‘ç»œæ¥èåˆæ–‡æœ¬å’Œå›¾åƒä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨å®ä½“ç±»å‹åµŒå…¥å’Œä½ç½®åµŒå…¥æ¥æ•´åˆç»“æ„åŒ–ä¿¡æ¯ã€‚åœ¨å…³ç³»æè¿°ç”Ÿæˆå™¨ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†GPT-3æ¨¡å‹æ¥ç”Ÿæˆè‡ªç„¶è¯­è¨€å…³ç³»æè¿°ã€‚åœ¨å¯¹æ¯”å­¦ä¹ æ¨¡å—ä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†InfoNCEæŸå¤±å‡½æ•°æ¥æœ€å¤§åŒ–å®ä½“å¯¹è¡¨ç¤ºå‘é‡å’Œç›¸å…³å…³ç³»æè¿°å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œæœ€å°åŒ–ä¸ä¸ç›¸å…³å…³ç³»æè¿°å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ROCåœ¨MNREå’ŒMOREæ•°æ®é›†ä¸Šå–å¾—äº†SOTAæ€§èƒ½ã€‚åœ¨MNREæ•°æ®é›†ä¸Šï¼ŒROCçš„F1å€¼æ¯”ä¹‹å‰çš„SOTAæ¨¡å‹æé«˜äº†2.3%ã€‚åœ¨MOREæ•°æ®é›†ä¸Šï¼ŒROCçš„F1å€¼æ¯”ä¹‹å‰çš„SOTAæ¨¡å‹æé«˜äº†1.8%ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜è¡¨æ˜ï¼ŒROCæ¡†æ¶å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®¢æœã€çŸ¥è¯†å›¾è°±æ„å»ºã€ä¿¡æ¯æ£€ç´¢ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å®¢æœä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯å‡†ç¡®è¯†åˆ«ç”¨æˆ·é—®é¢˜ä¸­çš„å®ä½“å…³ç³»ï¼Œä»è€Œæä¾›æ›´ç²¾å‡†çš„ç­”æ¡ˆã€‚åœ¨çŸ¥è¯†å›¾è°±æ„å»ºä¸­ï¼Œå¯ä»¥è‡ªåŠ¨æŠ½å–æ–‡æœ¬å’Œå›¾åƒä¸­çš„å®ä½“å…³ç³»ï¼Œä»è€Œä¸°å¯ŒçŸ¥è¯†å›¾è°±çš„å†…å®¹ã€‚åœ¨ä¿¡æ¯æ£€ç´¢ä¸­ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·è¾“å…¥çš„å®ä½“å…³ç³»è¿›è¡Œæ£€ç´¢ï¼Œä»è€Œæä¾›æ›´ç›¸å…³çš„ç»“æœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Relation extraction (RE) aims to identify semantic relations between entities in unstructured text. Although recent work extends traditional RE to multimodal scenarios, most approaches still adopt classification-based paradigms with fused multimodal features, representing relations as discrete labels. This paradigm has two significant limitations: (1) it overlooks structural constraints like entity types and positional cues, and (2) it lacks semantic expressiveness for fine-grained relation understanding. We propose \underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a novel framework that reformulates multimodal RE as a retrieval task driven by relation semantics. ROC integrates entity type and positional information through a multimodal encoder, expands relation labels into natural language descriptions using a large language model, and aligns entity-relation pairs via semantic similarity-based contrastive learning. Experiments show that our method achieves state-of-the-art performance on the benchmark datasets MNRE and MORE and exhibits stronger robustness and interpretability.

