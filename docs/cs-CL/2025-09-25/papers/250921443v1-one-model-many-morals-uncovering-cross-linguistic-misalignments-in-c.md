---
layout: default
title: One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning
---

# One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21443" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21443v1</a>
  <a href="https://arxiv.org/pdf/2509.21443.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21443v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21443v1', 'One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sualeha Farid, Jayden Lin, Zean Chen, Shivani Kumar, David Jurgens

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: 22 pages, 11 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºå¤šè¯­è¨€ç¯å¢ƒä¸‹å¤§è¯­è¨€æ¨¡å‹é“å¾·æ¨ç†çš„è·¨è¯­è¨€é”™ä½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨¡å‹` `é“å¾·æ¨ç†` `è·¨æ–‡åŒ–å¯¹é½` `é›¶æ ·æœ¬å­¦ä¹ ` `æ–‡åŒ–é”™ä½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨é“å¾·æ¨ç†æ–¹é¢å­˜åœ¨è·¨è¯­è¨€å’Œæ–‡åŒ–æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨éè‹±è¯­è¯­å¢ƒä¸‹ã€‚
2. é€šè¿‡å°†é“å¾·æ¨ç†åŸºå‡†ç¿»è¯‘æˆå¤šç§è¯­è¨€ï¼Œè®ºæ–‡æ—¨åœ¨æ­ç¤ºè¯­è¨€åœ¨LLMé“å¾·å†³ç­–ä¸­çš„è°ƒèŠ‚ä½œç”¨å’Œæ–‡åŒ–é”™ä½ç°è±¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨ä¸åŒè¯­è¨€ä¸­çš„é“å¾·åˆ¤æ–­å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¹¶åˆ†æäº†é€ æˆè¿™äº›å·®å¼‚çš„æ½œåœ¨åŸå› ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒæ•°æ®çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²åœ¨å¤šè¯­è¨€å’Œå¤šå…ƒæ–‡åŒ–ç¯å¢ƒä¸­ï¼Œåœ¨è¿™äº›ç¯å¢ƒä¸­ï¼Œé“å¾·æ¨ç†å¯¹äºç”Ÿæˆç¬¦åˆä¼¦ç†çš„å›åº”è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼ŒLLMsä¸»è¦åœ¨è‹±è¯­æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¿™å¼•å‘äº†äººä»¬å¯¹å…¶åœ¨ä¸åŒè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹æ¨å¹¿åˆ¤æ–­èƒ½åŠ›çš„æ‹…å¿§ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°ç ”ç©¶äº†è¯­è¨€å¦‚ä½•è°ƒèŠ‚LLMsä¸­çš„é“å¾·å†³ç­–ã€‚æˆ‘ä»¬å°†ä¸¤ä¸ªå·²å»ºç«‹çš„é“å¾·æ¨ç†åŸºå‡†ç¿»è¯‘æˆäº”ç§æ–‡åŒ–å’Œç±»å‹ä¸Šä¸åŒçš„è¯­è¨€ï¼Œä»è€Œå®ç°å¤šè¯­è¨€é›¶æ ·æœ¬è¯„ä¼°ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†LLMsåœ¨ä¸åŒè¯­è¨€ä¸­çš„é“å¾·åˆ¤æ–­å­˜åœ¨æ˜¾è‘—çš„ä¸ä¸€è‡´æ€§ï¼Œé€šå¸¸åæ˜ å‡ºæ–‡åŒ–é”™ä½ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç ”ç©¶é—®é¢˜ï¼Œæˆ‘ä»¬æ­ç¤ºäº†è¿™äº›å·®å¼‚çš„æ ¹æœ¬é©±åŠ¨å› ç´ ï¼ŒåŒ…æ‹¬LLMsæ‰€é‡‡ç”¨çš„æ¨ç†ç­–ç•¥ã€‚æœ€åï¼Œé€šè¿‡ä¸€ä¸ªæ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒæ•°æ®åœ¨å¡‘é€ LLMé“å¾·æŒ‡å—é’ˆä¸­çš„ä½œç”¨è”ç³»èµ·æ¥ã€‚é€šè¿‡è¿™é¡¹å·¥ä½œï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„è§è§£æç‚¼æˆä¸€ä¸ªç»“æ„åŒ–çš„é“å¾·æ¨ç†é”™è¯¯ç±»å‹å­¦ï¼Œå‘¼åæ›´å¤šå…·æœ‰æ–‡åŒ–æ„è¯†çš„AIã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤šè¯­è¨€å’Œå¤šå…ƒæ–‡åŒ–ç¯å¢ƒä¸­è¿›è¡Œé“å¾·æ¨ç†æ—¶ï¼Œç”±äºä¸»è¦åŸºäºè‹±è¯­æ•°æ®é¢„è®­ç»ƒè€Œå¯¼è‡´çš„è·¨è¯­è¨€æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•ä¿è¯LLMsåœ¨ä¸åŒè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹åšå‡ºä¸€è‡´ä¸”ç¬¦åˆä¼¦ç†çš„åˆ¤æ–­ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šè¯­è¨€é›¶æ ·æœ¬è¯„ä¼°ï¼Œç³»ç»Ÿåœ°ç ”ç©¶è¯­è¨€å¦‚ä½•è°ƒèŠ‚LLMsçš„é“å¾·å†³ç­–ã€‚é€šè¿‡å°†ç°æœ‰çš„é“å¾·æ¨ç†åŸºå‡†ç¿»è¯‘æˆå¤šç§è¯­è¨€ï¼Œå¹¶åˆ†æLLMsåœ¨ä¸åŒè¯­è¨€ä¸‹çš„åˆ¤æ–­å·®å¼‚ï¼Œä»è€Œæ­ç¤ºæ–‡åŒ–é”™ä½å’Œæ½œåœ¨çš„æ¨ç†ç­–ç•¥å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) å°†ä¸¤ä¸ªå·²å»ºç«‹çš„é“å¾·æ¨ç†åŸºå‡†ç¿»è¯‘æˆäº”ç§æ–‡åŒ–å’Œç±»å‹ä¸Šä¸åŒçš„è¯­è¨€ã€‚2) ä½¿ç”¨LLMså¯¹ç¿»è¯‘åçš„åŸºå‡†è¿›è¡Œé›¶æ ·æœ¬è¯„ä¼°ï¼Œè·å¾—ä¸åŒè¯­è¨€ä¸‹çš„é“å¾·åˆ¤æ–­ç»“æœã€‚3) åˆ†æä¸åŒè¯­è¨€ä¸‹çš„é“å¾·åˆ¤æ–­å·®å¼‚ï¼Œè¯†åˆ«æ–‡åŒ–é”™ä½å’Œæ½œåœ¨çš„æ¨ç†ç­–ç•¥å·®å¼‚ã€‚4) é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œåˆ†æé¢„è®­ç»ƒæ•°æ®å¯¹LLMé“å¾·åˆ¤æ–­çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ç³»ç»Ÿåœ°ç ”ç©¶äº†LLMsåœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„é“å¾·æ¨ç†èƒ½åŠ›ï¼Œæ­ç¤ºäº†è·¨è¯­è¨€çš„é“å¾·åˆ¤æ–­ä¸ä¸€è‡´æ€§ã€‚2) é€šè¿‡å¤šè¯­è¨€é›¶æ ·æœ¬è¯„ä¼°ï¼Œé‡åŒ–äº†æ–‡åŒ–é”™ä½å¯¹LLMé“å¾·åˆ¤æ–­çš„å½±å“ã€‚3) æå‡ºäº†ä¸€ä¸ªç»“æ„åŒ–çš„é“å¾·æ¨ç†é”™è¯¯ç±»å‹å­¦ï¼Œä¸ºå¼€å‘æ›´å…·æ–‡åŒ–æ„è¯†çš„AIæä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©å…·æœ‰æ–‡åŒ–å’Œç±»å‹å·®å¼‚çš„äº”ç§è¯­è¨€è¿›è¡Œç¿»è¯‘ï¼Œä»¥ç¡®ä¿ç ”ç©¶çš„ä»£è¡¨æ€§ã€‚2) ä½¿ç”¨é›¶æ ·æœ¬è¯„ä¼°ï¼Œé¿å…äº†åœ¨ç›®æ ‡è¯­è¨€ä¸Šè¿›è¡Œå¾®è°ƒå¯èƒ½å¼•å…¥çš„åå·®ã€‚3) é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç ”ç©¶é—®é¢˜ï¼Œæ·±å…¥åˆ†æäº†é€ æˆé“å¾·åˆ¤æ–­å·®å¼‚çš„æ½œåœ¨åŸå› ï¼Œä¾‹å¦‚æ¨ç†ç­–ç•¥å’Œé¢„è®­ç»ƒæ•°æ®çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼ŒLLMåœ¨ä¸åŒè¯­è¨€ä¸­çš„é“å¾·åˆ¤æ–­å­˜åœ¨æ˜¾è‘—çš„ä¸ä¸€è‡´æ€§ï¼Œåæ˜ å‡ºæ–‡åŒ–é”™ä½ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›è¯­è¨€ä¸­ï¼ŒLLMæ›´å€¾å‘äºåŠŸåˆ©ä¸»ä¹‰çš„åˆ¤æ–­ï¼Œè€Œåœ¨å¦ä¸€äº›è¯­è¨€ä¸­åˆ™æ›´å€¾å‘äºä¹‰åŠ¡è®ºçš„åˆ¤æ–­ã€‚æ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œé¢„è®­ç»ƒæ•°æ®åœ¨å¡‘é€ LLMçš„é“å¾·æŒ‡å—é’ˆä¸­èµ·ç€é‡è¦ä½œç”¨ï¼Œè‹±è¯­é¢„è®­ç»ƒæ•°æ®å¯èƒ½å¯¼è‡´LLMåœ¨éè‹±è¯­è¯­å¢ƒä¸‹äº§ç”Ÿåå·®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´å…·æ–‡åŒ–æ•æ„Ÿæ€§å’Œä¼¦ç†æ„è¯†çš„å¤šè¯­è¨€AIç³»ç»Ÿï¼Œä¾‹å¦‚è·¨æ–‡åŒ–äº¤æµæœºå™¨äººã€å¤šè¯­è¨€å†…å®¹å®¡æ ¸å·¥å…·å’Œå…¨çƒåŒ–çš„æ™ºèƒ½å®¢æœç³»ç»Ÿã€‚é€šè¿‡ç†è§£å’Œè§£å†³LLMåœ¨ä¸åŒè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„é“å¾·æ¨ç†é”™ä½é—®é¢˜ï¼Œå¯ä»¥æé«˜AIç³»ç»Ÿçš„å…¬å¹³æ€§ã€å¯é æ€§å’Œç¤¾ä¼šè´£ä»»æ„Ÿï¼Œé¿å…æ½œåœ¨çš„ä¼¦ç†é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly deployed in multilingual and multicultural environments where moral reasoning is essential for generating ethically appropriate responses. Yet, the dominant pretraining of LLMs on English-language data raises critical concerns about their ability to generalize judgments across diverse linguistic and cultural contexts. In this work, we systematically investigate how language mediates moral decision-making in LLMs. We translate two established moral reasoning benchmarks into five culturally and typologically diverse languages, enabling multilingual zero-shot evaluation. Our analysis reveals significant inconsistencies in LLMs' moral judgments across languages, often reflecting cultural misalignment. Through a combination of carefully constructed research questions, we uncover the underlying drivers of these disparities, ranging from disagreements to reasoning strategies employed by LLMs. Finally, through a case study, we link the role of pretraining data in shaping an LLM's moral compass. Through this work, we distill our insights into a structured typology of moral reasoning errors that calls for more culturally-aware AI.

