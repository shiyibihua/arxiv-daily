---
layout: default
title: When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following
---

# When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21051" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21051v1</a>
  <a href="https://arxiv.org/pdf/2509.21051.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21051v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21051v1', 'When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Keno Harada, Yudai Yamazaki, Masachika Taniguchi, Edison Marrese-Taylor, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: Accepted to EMNLP2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºManyIFEvalå’ŒStyleMBPPåŸºå‡†ï¼Œè¯„ä¼°å¹¶é¢„æµ‹LLMå¤šæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæŒ‡ä»¤éµå¾ª` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ€§èƒ½è¯„ä¼°` `å›å½’æ¨¡å‹` `æ–‡æœ¬ç”Ÿæˆ` `ä»£ç ç”Ÿæˆ` `åŸºå‡†æµ‹è¯•` `æŒ‡ä»¤ç»„åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å¤šæŒ‡ä»¤å¹¶è¡Œå¤„ç†èƒ½åŠ›æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„è¯„ä¼°åŸºå‡†ã€‚
2. æ„å»ºManyIFEvalå’ŒStyleMBPPåŸºå‡†ï¼Œå¹¶æå‡ºåŸºäºå›å½’æ¨¡å‹çš„æ€§èƒ½é¢„æµ‹æ–¹æ³•ï¼Œé™ä½è¯„ä¼°æˆæœ¬ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMæ€§èƒ½éšæŒ‡ä»¤æ•°é‡å¢åŠ è€Œä¸‹é™ï¼Œä¸”å›å½’æ¨¡å‹èƒ½æœ‰æ•ˆé¢„æµ‹æœªè§æŒ‡ä»¤ç»„åˆçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å®é™…åº”ç”¨ä¸­åŒæ—¶éµå¾ªå¤šæ¡æŒ‡ä»¤èƒ½åŠ›çš„é‡è¦æ€§ï¼Œæå‡ºäº†ä¸¤ä¸ªä¸“é—¨çš„åŸºå‡†æµ‹è¯•ï¼šç”¨äºæ–‡æœ¬ç”Ÿæˆçš„Many Instruction-Following Eval (ManyIFEval)ï¼Œæœ€å¤šåŒ…å«åæ¡æŒ‡ä»¤ï¼›ä»¥åŠç”¨äºä»£ç ç”Ÿæˆçš„Style-aware Mostly Basic Programming Problems (StyleMBPP)ï¼Œæœ€å¤šåŒ…å«å…­æ¡æŒ‡ä»¤ã€‚é€šè¿‡å¯¹åä¸ªLLMçš„å®éªŒè¡¨æ˜ï¼Œæ€§èƒ½éšç€æŒ‡ä»¤æ•°é‡çš„å¢åŠ è€ŒæŒç»­ä¸‹é™ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°è¯„ä¼°æ‰€æœ‰å¯èƒ½çš„æŒ‡ä»¤ç»„åˆåœ¨å®é™…åº”ç”¨ä¸­è®¡ç®—é‡è¿‡å¤§ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸‰ç§ç±»å‹çš„å›å½’æ¨¡å‹ï¼Œç”¨äºä¼°è®¡æœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆå’Œä¸åŒæŒ‡ä»¤æ•°é‡ä¸‹çš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æŒ‡ä»¤è®¡æ•°ä½œä¸ºè§£é‡Šå˜é‡çš„é€»è¾‘å›å½’æ¨¡å‹å¯ä»¥é¢„æµ‹éµå¾ªå¤šæ¡æŒ‡ä»¤çš„æ€§èƒ½ï¼Œè¯¯å·®çº¦ä¸º10%ï¼Œå³ä½¿å¯¹äºæœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç›¸å¯¹é€‚åº¦çš„æ ·æœ¬é‡ï¼ˆManyIFEvalä¸º500ï¼ŒStyleMBPPä¸º300ï¼‰è¶³ä»¥è¿›è¡Œæ€§èƒ½ä¼°è®¡ï¼Œä»è€Œèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°LLMåœ¨å„ç§æŒ‡ä»¤ç»„åˆä¸‹çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒæ—¶éµå¾ªå¤šæ¡æŒ‡ä»¤æ—¶çš„èƒ½åŠ›è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰çš„è¯„ä¼°æ–¹æ³•é€šå¸¸ä¾§é‡äºå•æ¡æŒ‡ä»¤çš„æ€§èƒ½ï¼Œç¼ºä¹å¯¹å¤šæŒ‡ä»¤ç»„åˆåœºæ™¯çš„ç³»ç»Ÿæ€§åˆ†æã€‚ç›´æ¥è¯„ä¼°æ‰€æœ‰å¯èƒ½çš„æŒ‡ä»¤ç»„åˆåœ¨è®¡ç®—ä¸Šæ˜¯ä¸å¯è¡Œçš„ï¼Œå› æ­¤éœ€è¦ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•æ¥ä¼°è®¡LLMåœ¨ä¸åŒæŒ‡ä»¤ç»„åˆä¸‹çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸“é—¨çš„åŸºå‡†æµ‹è¯•æ¥è¯„ä¼°LLMçš„å¤šæŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå¹¶å¼€å‘å›å½’æ¨¡å‹æ¥é¢„æµ‹LLMåœ¨æœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆå’Œä¸åŒæŒ‡ä»¤æ•°é‡ä¸‹çš„æ€§èƒ½ã€‚é€šè¿‡å°‘é‡æ ·æœ¬æ•°æ®è®­ç»ƒå›å½’æ¨¡å‹ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä¼°è®¡LLMåœ¨å„ç§æŒ‡ä»¤ç»„åˆä¸‹çš„è¡¨ç°ï¼Œä»è€Œé™ä½è¯„ä¼°æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªéƒ¨åˆ†ï¼š1) æ„å»ºå¤šæŒ‡ä»¤éµå¾ªè¯„ä¼°åŸºå‡†ï¼ŒåŒ…æ‹¬ManyIFEvalï¼ˆæ–‡æœ¬ç”Ÿæˆï¼‰å’ŒStyleMBPPï¼ˆä»£ç ç”Ÿæˆï¼‰ï¼›2) å¼€å‘æ€§èƒ½é¢„æµ‹æ¨¡å‹ï¼ŒåŒ…æ‹¬ä¸‰ç§ç±»å‹çš„å›å½’æ¨¡å‹ã€‚æ•´ä½“æµç¨‹æ˜¯é¦–å…ˆä½¿ç”¨æ„å»ºçš„åŸºå‡†æµ‹è¯•è¯„ä¼°LLMçš„æ€§èƒ½ï¼Œç„¶åä½¿ç”¨è¯„ä¼°æ•°æ®è®­ç»ƒå›å½’æ¨¡å‹ï¼Œæœ€åä½¿ç”¨è®­ç»ƒå¥½çš„å›å½’æ¨¡å‹é¢„æµ‹LLMåœ¨æœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸“é—¨é’ˆå¯¹å¤šæŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„è¯„ä¼°åŸºå‡†ï¼Œå¹¶å¼€å‘äº†åŸºäºå›å½’æ¨¡å‹çš„æ€§èƒ½é¢„æµ‹æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„å•æŒ‡ä»¤è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°LLMåœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œé€šè¿‡å›å½’æ¨¡å‹é¢„æµ‹æ€§èƒ½ï¼Œå¯ä»¥é¿å…å¯¹æ‰€æœ‰å¯èƒ½çš„æŒ‡ä»¤ç»„åˆè¿›è¡Œè¯„ä¼°ï¼Œä»è€Œå¤§å¤§é™ä½äº†è¯„ä¼°æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŸºå‡†æµ‹è¯•è®¾è®¡æ–¹é¢ï¼ŒManyIFEvalæœ€å¤šåŒ…å«åæ¡æŒ‡ä»¤ï¼ŒStyleMBPPæœ€å¤šåŒ…å«å…­æ¡æŒ‡ä»¤ï¼ŒæŒ‡ä»¤æ•°é‡çš„é€‰æ‹©æ—¨åœ¨æ¨¡æ‹Ÿå®é™…åº”ç”¨ä¸­å¸¸è§çš„æŒ‡ä»¤ç»„åˆæ•°é‡ã€‚åœ¨å›å½’æ¨¡å‹æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨äº†ä¸‰ç§ç±»å‹çš„å›å½’æ¨¡å‹ï¼ŒåŒ…æ‹¬çº¿æ€§å›å½’ã€å¤šé¡¹å¼å›å½’å’Œé€»è¾‘å›å½’ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æŒ‡ä»¤è®¡æ•°ä½œä¸ºè§£é‡Šå˜é‡çš„é€»è¾‘å›å½’æ¨¡å‹èƒ½å¤Ÿè·å¾—æœ€ä½³çš„é¢„æµ‹æ€§èƒ½ã€‚æ ·æœ¬é‡æ–¹é¢ï¼ŒManyIFEvalä½¿ç”¨äº†500ä¸ªæ ·æœ¬ï¼ŒStyleMBPPä½¿ç”¨äº†300ä¸ªæ ·æœ¬ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMçš„æ€§èƒ½éšç€æŒ‡ä»¤æ•°é‡çš„å¢åŠ è€ŒæŒç»­ä¸‹é™ã€‚ä½¿ç”¨æŒ‡ä»¤è®¡æ•°ä½œä¸ºè§£é‡Šå˜é‡çš„é€»è¾‘å›å½’æ¨¡å‹å¯ä»¥é¢„æµ‹éµå¾ªå¤šæ¡æŒ‡ä»¤çš„æ€§èƒ½ï¼Œè¯¯å·®çº¦ä¸º10%ï¼Œå³ä½¿å¯¹äºæœªè§è¿‡çš„æŒ‡ä»¤ç»„åˆä¹Ÿæ˜¯å¦‚æ­¤ã€‚ç›¸å¯¹é€‚åº¦çš„æ ·æœ¬é‡ï¼ˆManyIFEvalä¸º500ï¼ŒStyleMBPPä¸º300ï¼‰è¶³ä»¥è¿›è¡Œæ€§èƒ½ä¼°è®¡ï¼Œä»è€Œèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°LLMåœ¨å„ç§æŒ‡ä»¤ç»„åˆä¸‹çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œä¼˜åŒ–LLMåœ¨å„ç§å®é™…åº”ç”¨åœºæ™¯ä¸­çš„æ€§èƒ½ï¼Œä¾‹å¦‚æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–ä»£ç ç”Ÿæˆã€å¤šä»»åŠ¡æ–‡æœ¬å¤„ç†ç­‰ã€‚é€šè¿‡é¢„æµ‹LLMåœ¨ä¸åŒæŒ‡ä»¤ç»„åˆä¸‹çš„æ€§èƒ½ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·é€‰æ‹©æœ€é€‚åˆç‰¹å®šä»»åŠ¡çš„LLMï¼Œå¹¶ä¼˜åŒ–æŒ‡ä»¤ç»„åˆï¼Œæé«˜LLMçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›LLMå¤šæŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„ç ”ç©¶å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly applied to real-world scenarios, it becomes crucial to understand their ability to follow multiple instructions simultaneously. To systematically evaluate these capabilities, we introduce two specialized benchmarks for fundamental domains where multiple instructions following is important: Many Instruction-Following Eval (ManyIFEval) for text generation with up to ten instructions, and Style-aware Mostly Basic Programming Problems (StyleMBPP) for code generation with up to six instructions. Our experiments with the created benchmarks across ten LLMs reveal that performance consistently degrades as the number of instructions increases. Furthermore, given the fact that evaluating all the possible combinations of multiple instructions is computationally impractical in actual use cases, we developed three types of regression models that can estimate performance on both unseen instruction combinations and different numbers of instructions which are not used during training. We demonstrate that a logistic regression model using instruction count as an explanatory variable can predict performance of following multiple instructions with approximately 10% error, even for unseen instruction combinations. We show that relatively modest sample sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance estimation, enabling efficient evaluation of LLMs under various instruction combinations.

