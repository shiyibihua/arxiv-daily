---
layout: default
title: Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval
---

# Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02326" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02326v1</a>
  <a href="https://arxiv.org/pdf/2510.02326.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02326v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02326v1', 'Hallucination-Resistant, Domain-Specific Research Assistant with Self-Evaluation and Vector-Grounded Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vivek Bhavsar, Joseph Ereifej, Aravanan Gurusami

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: 21 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRA-FSMï¼Œä¸€ç§æŠ—å¹»è§‰ã€é¢†åŸŸç‰¹å®šçš„ç ”ç©¶åŠ©æ‰‹ï¼Œé€šè¿‡è‡ªè¯„ä¼°å’Œå‘é‡æ£€ç´¢æå‡ä¸“å®¶å·¥ä½œæµæ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç ”ç©¶åŠ©æ‰‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¹»è§‰æŠ‘åˆ¶` `å‘é‡æ£€ç´¢` `æœ‰é™çŠ¶æ€æœº` `é¢†åŸŸçŸ¥è¯†åº“` `å…‰å­å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡çŒ®ç»¼è¿°ä¸­å­˜åœ¨å¹»è§‰å’Œé”™è¯¯å¼•ç”¨çš„é—®é¢˜ï¼Œå½±å“äº†å…¶åœ¨ä¸“ä¸šé¢†åŸŸçš„åº”ç”¨ã€‚
2. RA-FSMé€šè¿‡æœ‰é™çŠ¶æ€æ§åˆ¶å¾ªç¯ï¼ˆç›¸å…³æ€§ã€ç½®ä¿¡åº¦ã€çŸ¥è¯†ï¼‰å’Œå‘é‡æ£€ç´¢ï¼Œå¢å¼ºäº†ç­”æ¡ˆçš„å¯é æ€§å’Œå¯ä¿¡åº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRA-FSMåœ¨å…‰å­å­¦é¢†åŸŸçš„å¤šä¸ªä»»åŠ¡ä¸­ä¼˜äºNotebook LMå’Œvanilla GPTï¼Œå¹¶æä¾›äº†æ›´å¯é çš„è¯æ®æ”¯æŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åŠ é€Ÿäº†æ–‡çŒ®ç»¼è¿°ï¼Œä½†å­˜åœ¨å¹»è§‰å’Œé”™è¯¯å¼•ç”¨çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸“å®¶å·¥ä½œæµç¨‹ä¸­çš„åº”ç”¨ã€‚æœ¬æ–‡æå‡ºRA-FSMï¼ˆç ”ç©¶åŠ©æ‰‹-æœ‰é™çŠ¶æ€æœºï¼‰ï¼Œä¸€ä¸ªåŸºäºGPTçš„æ¨¡å—åŒ–ç ”ç©¶åŠ©æ‰‹ï¼Œå®ƒå°†ç”Ÿæˆè¿‡ç¨‹å°è£…åœ¨ä¸€ä¸ªæœ‰é™çŠ¶æ€æ§åˆ¶å¾ªç¯ä¸­ï¼šç›¸å…³æ€§ -> ç½®ä¿¡åº¦ -> çŸ¥è¯†ã€‚è¯¥ç³»ç»ŸåŸºäºå‘é‡æ£€ç´¢å’Œä¸€ä¸ªç¡®å®šæ€§çš„å¼•ç”¨ç®¡é“ã€‚æ§åˆ¶å™¨è¿‡æ»¤è¶…å‡ºèŒƒå›´çš„æŸ¥è¯¢ï¼Œè¯„ä¼°å¯å›ç­”æ€§ï¼Œåˆ†è§£é—®é¢˜ï¼Œå¹¶åœ¨éœ€è¦æ—¶è§¦å‘æ£€ç´¢ï¼Œå¹¶ä»¥ç½®ä¿¡åº¦æ ‡ç­¾å’Œè¯­æ–™åº“å†…çš„å»é‡å‚è€ƒæ–‡çŒ®è¾“å‡ºç­”æ¡ˆã€‚ä¸€ä¸ªåˆ†çº§æ‘„å–å·¥ä½œæµç¨‹ä»æœŸåˆŠã€ä¼šè®®ã€ç´¢å¼•ã€é¢„å°æœ¬å’Œä¸“åˆ©æ„å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼ŒåŒæ—¶å†™å…¥å¯†é›†å‘é‡ç´¢å¼•å’Œè§„èŒƒåŒ–æŒ‡æ ‡çš„å…³ç³»å­˜å‚¨ã€‚æˆ‘ä»¬åœ¨å…‰å­å­¦é¢†åŸŸå®ç°äº†è¯¥ç³»ç»Ÿï¼Œå¹¶åœ¨å…­ä¸ªä»»åŠ¡ç±»åˆ«ä¸Šå¯¹å…¶è¿›è¡Œäº†è¯„ä¼°ï¼šåˆ†ææ¨ç†ã€æ•°å€¼åˆ†æã€æ–¹æ³•è®ºæ‰¹åˆ¤ã€æ¯”è¾ƒç»¼åˆã€äº‹å®æå–å’Œåº”ç”¨è®¾è®¡ã€‚åœ¨ç›²æ³•A/Bè¯„ä¼°ä¸­ï¼Œé¢†åŸŸä¸“å®¶æ›´å–œæ¬¢RA-FSMï¼Œè€Œä¸æ˜¯å¼ºå¤§çš„Notebook LMï¼ˆNLMï¼‰å’Œvanilla Default GPT APIè°ƒç”¨å•æ¬¡åŸºçº¿ï¼Œç†ç”±æ˜¯RA-FSMå…·æœ‰æ›´å¼ºçš„è¾¹ç•Œæ¡ä»¶å¤„ç†èƒ½åŠ›å’Œæ›´å¯é çš„è¯æ®ä½¿ç”¨ã€‚è¦†ç›–ç‡å’Œæ–°é¢–æ€§åˆ†æè¡¨æ˜ï¼ŒRA-FSMæ¢ç´¢çš„èŒƒå›´è¶…å‡ºäº†NLMï¼ŒåŒæ—¶äº§ç”Ÿäº†å¯è°ƒçš„å»¶è¿Ÿå’Œæˆæœ¬å¼€é”€ã€‚è¯¥è®¾è®¡å¼ºè°ƒé€æ˜ã€å……åˆ†å¼•ç”¨çš„ç­”æ¡ˆï¼Œé€‚ç”¨äºé«˜é£é™©çš„æŠ€æœ¯å·¥ä½œï¼Œå¹¶ä¸”å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–ç§‘å­¦é¢†åŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡çŒ®ç»¼è¿°å’Œç ”ç©¶è¾…åŠ©æ–¹é¢è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†å…¶å›ºæœ‰çš„å¹»è§‰é—®é¢˜ï¼Œå³ç”Ÿæˆä¸çœŸå®æˆ–ä¸å‡†ç¡®çš„ä¿¡æ¯ï¼Œä»¥åŠé”™è¯¯å¼•ç”¨æ–‡çŒ®ï¼Œä¸¥é‡é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦é«˜åº¦å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦çš„ä¸“ä¸šç ”ç©¶å·¥ä½œæµç¨‹ä¸­çš„åº”ç”¨ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥ä¿è¯ç­”æ¡ˆçš„å¯é æ€§å’Œå¯è¿½æº¯æ€§ï¼Œä½¿å¾—ä¸“å®¶éš¾ä»¥ä¿¡ä»»å’Œä½¿ç”¨è¿™äº›å·¥å…·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRA-FSMçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥ä¸€ä¸ªæœ‰é™çŠ¶æ€æ§åˆ¶å¾ªç¯æ¥çº¦æŸå’Œå¼•å¯¼è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼Œä»è€Œå‡å°‘å¹»è§‰çš„äº§ç”Ÿã€‚è¯¥å¾ªç¯åŒ…å«ä¸‰ä¸ªå…³é”®çŠ¶æ€ï¼šç›¸å…³æ€§ã€ç½®ä¿¡åº¦å’ŒçŸ¥è¯†ã€‚é€šè¿‡åœ¨æ¯ä¸ªçŠ¶æ€è¿›è¡Œè¯„ä¼°å’Œè¿‡æ»¤ï¼Œç¡®ä¿åªæœ‰ç›¸å…³ã€å¯ä¿¡å’Œæœ‰æ®å¯æŸ¥çš„ä¿¡æ¯æ‰èƒ½æœ€ç»ˆè¾“å‡ºã€‚æ­¤å¤–ï¼Œç³»ç»Ÿè¿˜ä¾èµ–äºå‘é‡æ£€ç´¢æ¥å¢å¼ºçŸ¥è¯†çš„è·å–å’ŒéªŒè¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRA-FSMçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š
1. **æŸ¥è¯¢å¤„ç†æ¨¡å—**ï¼šè´Ÿè´£æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢ï¼Œå¹¶è¿›è¡Œåˆæ­¥çš„è¿‡æ»¤å’Œåˆ†è§£ã€‚
2. **æœ‰é™çŠ¶æ€æ§åˆ¶å™¨**ï¼šæ§åˆ¶æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹ï¼Œæ ¹æ®å½“å‰çŠ¶æ€å’Œè¯„ä¼°ç»“æœå†³å®šä¸‹ä¸€æ­¥çš„åŠ¨ä½œã€‚
3. **å‘é‡æ£€ç´¢æ¨¡å—**ï¼šä»é¢„å…ˆæ„å»ºçš„é¢†åŸŸçŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ã€‚
4. **ç”Ÿæˆæ¨¡å—**ï¼šåŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯å’Œæ§åˆ¶å™¨çš„æŒ‡å¯¼ï¼Œç”Ÿæˆç­”æ¡ˆã€‚
5. **å¼•ç”¨ç®¡é“**ï¼šè´Ÿè´£å¯¹ç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡Œå¼•ç”¨æ ‡æ³¨ï¼Œå¹¶è¿›è¡Œå»é‡å¤„ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šRA-FSMæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶æœ‰é™çŠ¶æ€æ§åˆ¶å¾ªç¯ï¼Œå®ƒå°†ç”Ÿæˆè¿‡ç¨‹åˆ†è§£ä¸ºå¤šä¸ªå¯æ§çš„é˜¶æ®µï¼Œå¹¶åœ¨æ¯ä¸ªé˜¶æ®µè¿›è¡Œè¯„ä¼°å’Œè¿‡æ»¤ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘å¹»è§‰çš„äº§ç”Ÿï¼Œå¹¶æé«˜ç­”æ¡ˆçš„å¯é æ€§å’Œå¯ä¿¡åº¦ã€‚ä¸ä¼ ç»Ÿçš„å•æ¬¡ç”Ÿæˆæ–¹æ³•ç›¸æ¯”ï¼ŒRA-FSMèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è¾¹ç•Œæ¡ä»¶ï¼Œå¹¶æä¾›æ›´å¯é çš„è¯æ®æ”¯æŒã€‚

**å…³é”®è®¾è®¡**ï¼šRA-FSMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š
1. **é¢†åŸŸçŸ¥è¯†åº“çš„æ„å»º**ï¼šé€šè¿‡åˆ†çº§æ‘„å–å·¥ä½œæµç¨‹ï¼Œä»æœŸåˆŠã€ä¼šè®®ã€ç´¢å¼•ã€é¢„å°æœ¬å’Œä¸“åˆ©ç­‰æ¥æºæ„å»ºé¢†åŸŸçŸ¥è¯†åº“ï¼Œå¹¶åŒæ—¶å†™å…¥å¯†é›†å‘é‡ç´¢å¼•å’Œå…³ç³»å­˜å‚¨ã€‚
2. **æœ‰é™çŠ¶æ€æ§åˆ¶å™¨çš„çŠ¶æ€è½¬ç§»è§„åˆ™**ï¼šå®šä¹‰äº†ä¸åŒçŠ¶æ€ä¹‹é—´çš„è½¬ç§»æ¡ä»¶ï¼Œä»¥åŠåœ¨æ¯ä¸ªçŠ¶æ€éœ€è¦æ‰§è¡Œçš„æ“ä½œã€‚
3. **ç½®ä¿¡åº¦è¯„ä¼°æ–¹æ³•**ï¼šç”¨äºè¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„ç½®ä¿¡åº¦ï¼Œå¹¶å†³å®šæ˜¯å¦éœ€è¦è¿›è¡Œè¿›ä¸€æ­¥çš„æ£€ç´¢æˆ–ç”Ÿæˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…‰å­å­¦é¢†åŸŸçš„å…­ä¸ªä»»åŠ¡ç±»åˆ«è¯„ä¼°ä¸­ï¼Œé¢†åŸŸä¸“å®¶åœ¨ç›²æ³•A/Bè¯„ä¼°ä¸­æ›´å€¾å‘äºRA-FSMï¼Œè€Œä¸æ˜¯Notebook LMå’Œvanilla Default GPT APIã€‚ä¸“å®¶è®¤ä¸ºRA-FSMå…·æœ‰æ›´å¼ºçš„è¾¹ç•Œæ¡ä»¶å¤„ç†èƒ½åŠ›å’Œæ›´å¯é çš„è¯æ®ä½¿ç”¨ã€‚è¦†ç›–ç‡å’Œæ–°é¢–æ€§åˆ†æè¡¨æ˜ï¼ŒRA-FSMæ¢ç´¢çš„èŒƒå›´è¶…å‡ºäº†NLMï¼ŒåŒæ—¶äº§ç”Ÿäº†å¯è°ƒçš„å»¶è¿Ÿå’Œæˆæœ¬å¼€é”€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RA-FSMå¯åº”ç”¨äºå„ç§éœ€è¦é«˜ç²¾åº¦å’Œå¯ä¿¡åº¦çš„ç§‘å­¦ç ”ç©¶é¢†åŸŸï¼Œä¾‹å¦‚åŒ»å­¦ã€å·¥ç¨‹å­¦å’Œæ³•å¾‹ç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å¿«é€Ÿå‡†ç¡®åœ°æ‰¾åˆ°æ‰€éœ€çš„ä¿¡æ¯ï¼Œå¹¶å‡å°‘å› å¹»è§‰å’Œé”™è¯¯å¼•ç”¨è€Œå¯¼è‡´çš„é”™è¯¯ã€‚è¯¥ç³»ç»Ÿè¿˜å¯ä»¥ç”¨äºæ•™è‚²é¢†åŸŸï¼Œå¸®åŠ©å­¦ç”Ÿå­¦ä¹ å’Œç†è§£å¤æ‚çš„æ¦‚å¿µã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models accelerate literature synthesis but can hallucinate and mis-cite, limiting their usefulness in expert workflows. We present RA-FSM (Research Assistant - Finite State Machine), a modular GPT-based research assistant that wraps generation in a finite-state control loop: Relevance -> Confidence -> Knowledge. The system is grounded in vector retrieval and a deterministic citation pipeline. The controller filters out-of-scope queries, scores answerability, decomposes questions, and triggers retrieval only when needed, and emits answers with confidence labels and in-corpus, de-duplicated references. A ranked-tier ingestion workflow constructs a domain knowledge base from journals, conferences, indices, preprints, and patents, writing both to a dense vector index and to a relational store of normalized metrics. We implement the system for photonics and evaluate it on six task categories: analytical reasoning, numerical analysis, methodological critique, comparative synthesis, factual extraction, and application design. In blinded A/B reviews, domain experts prefer RA-FSM to both a strong Notebook LM (NLM) and a vanilla Default GPT API call single-pass baseline, citing stronger boundary-condition handling and more defensible evidence use. Coverage and novelty analyses indicate that RA-FSM explores beyond the NLM while incurring tunable latency and cost overheads. The design emphasizes transparent, well-cited answers for high-stakes technical work and is generalizable to other scientific domains.

