---
layout: default
title: SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines
---

# SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21320" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21320v3</a>
  <a href="https://arxiv.org/pdf/2509.21320.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21320v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21320v3', 'SciReasoner: Laying the Scientific Reasoning Ground Across Disciplines')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yizhou Wang, Chen Tang, Han Deng, Jiabei Xiao, Jiaqi Liu, Jianyu Wu, Jun Yao, Pengze Li, Encheng Su, Lintao Wang, Guohang Zhuang, Yuchen Ren, Ben Fei, Ming Hu, Xin Chen, Dongzhan Zhou, Junjun He, Xiangyu Yue, Zhenfei Yin, Jiamin Wu, Qihao Zheng, Yuhao Zhou, Huihui Xu, Chenglong Ma, Yan Lu, Wenlong Zhang, Chunfeng Song, Philip Torr, Shixiang Tang, Xinzhu Ma, Wanli Ouyang, Lei Bai

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25 (æ›´æ–°: 2025-12-14)

**å¤‡æ³¨**: technical report

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/open-sciencelab/SciReason) | [HUGGINGFACE](https://huggingface.co/SciReason)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SciReasonerï¼šæ„å»ºè·¨å­¦ç§‘çš„ç§‘å­¦æ¨ç†åŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç§‘å­¦æ¨ç†` `åŸºç¡€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ ` `è·¨å­¦ç§‘å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç§‘å­¦æ¨ç†ç³»ç»Ÿåœ¨è·¨é¢†åŸŸæ³›åŒ–å’ŒæŒ‡ä»¤è¦†ç›–æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å¤„ç†å¤æ‚çš„ç§‘å­¦ä»»åŠ¡ã€‚
2. SciReasoneré€šè¿‡é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€è‡ªä¸¾å’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œå®ç°äº†è‡ªç„¶è¯­è¨€ä¸å¼‚æ„ç§‘å­¦è¡¨ç¤ºçš„å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSciReasoneråœ¨å¤šä¸ªç§‘å­¦ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæé«˜äº†è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›å’Œä¸‹æ¸¸ä»»åŠ¡çš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç§‘å­¦æ¨ç†åŸºç¡€æ¨¡å‹SciReasonerï¼Œæ—¨åœ¨å¯¹é½è‡ªç„¶è¯­è¨€å’Œå¼‚æ„ç§‘å­¦è¡¨ç¤ºã€‚è¯¥æ¨¡å‹é¦–å…ˆåœ¨ä¸€ä¸ªåŒ…å«2060äº¿tokençš„è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¯¥è¯­æ–™åº“æ¶µç›–ç§‘å­¦æ–‡æœ¬ã€çº¯åºåˆ—å’Œåºåˆ—-æ–‡æœ¬å¯¹ã€‚ç„¶åï¼Œé€šè¿‡åœ¨4000ä¸‡æ¡æŒ‡ä»¤ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ¥å¯¹é½æ¨¡å‹ï¼Œå¹¶é‡‡ç”¨é€€ç«å†·å¯åŠ¨è‡ªä¸¾ï¼ˆannealed cold-start bootstrappingï¼‰æ¥è¯±å¯¼é•¿å½¢å¼çš„æ€ç»´é“¾ï¼ˆchain-of-thoughtï¼‰ã€‚æ­¤å¤–ï¼Œè¿˜åˆ©ç”¨ä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±å¡‘é€ ï¼ˆreward shapingï¼‰è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»è€ŒåŸ¹å…»å®¡æ…çš„ç§‘å­¦æ¨ç†èƒ½åŠ›ã€‚SciReasoneræ”¯æŒå››ä¸ªèƒ½åŠ›æ—ï¼Œæ¶µç›–å¤šè¾¾103ä¸ªè·¨å·¥ä½œæµçš„ä»»åŠ¡ï¼šï¼ˆiï¼‰æ–‡æœ¬å’Œç§‘å­¦æ ¼å¼ä¹‹é—´çš„å¿ å®ç¿»è¯‘ï¼Œï¼ˆiiï¼‰æ–‡æœ¬/çŸ¥è¯†æå–ï¼Œï¼ˆiiiï¼‰å±æ€§é¢„æµ‹ï¼Œï¼ˆivï¼‰å±æ€§åˆ†ç±»ï¼Œï¼ˆvï¼‰æ— æ¡ä»¶å’Œæ¡ä»¶åºåˆ—ç”Ÿæˆä¸è®¾è®¡ã€‚ä¸ä¸“ä¸šç³»ç»Ÿç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ‰©å±•äº†æŒ‡ä»¤è¦†ç›–èŒƒå›´ï¼Œæé«˜äº†è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å¢å¼ºäº†ä¿çœŸåº¦ã€‚æ–‡ç« è¯¦ç»†ä»‹ç»äº†æ•°æ®æ•´ç†å’Œè®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è¡¨æ˜è·¨å­¦ç§‘å­¦ä¹ å¯ä»¥åŠ å¼ºè¿ç§»å’Œä¸‹æ¸¸å¯é æ€§ã€‚è¯¥æ¨¡å‹ã€æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†å’Œè¯„ä¼°ä»£ç å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç§‘å­¦æ¨ç†ç³»ç»Ÿé€šå¸¸ä¸“æ³¨äºç‰¹å®šé¢†åŸŸæˆ–ä»»åŠ¡ï¼Œç¼ºä¹è·¨å­¦ç§‘çš„é€šç”¨æ€§å’Œçµæ´»æ€§ã€‚å®ƒä»¬åœ¨å¤„ç†å¤æ‚çš„ç§‘å­¦é—®é¢˜æ—¶ï¼ŒæŒ‡ä»¤è¦†ç›–èŒƒå›´æœ‰é™ï¼Œéš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„æ¨ç†å’ŒçŸ¥è¯†è¿ç§»ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•åœ¨æ–‡æœ¬å’Œç§‘å­¦æ ¼å¼ä¹‹é—´çš„è½¬æ¢ä¿çœŸåº¦æ–¹é¢ä¹Ÿå­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSciReasonerçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªé€šç”¨çš„ç§‘å­¦æ¨ç†åŸºç¡€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç†è§£å’Œç”Ÿæˆå¤šç§ç§‘å­¦è¡¨ç¤ºï¼Œå¹¶å…·å¤‡è·¨å­¦ç§‘çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°ä¸°å¯Œçš„ç§‘å­¦çŸ¥è¯†å’Œæ¨ç†æ¨¡å¼ï¼Œä»è€Œé€‚åº”ä¸åŒçš„ç§‘å­¦ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSciReasonerçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) **é¢„è®­ç»ƒ**ï¼šåœ¨å¤§è§„æ¨¡ç§‘å­¦è¯­æ–™åº“ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œå­¦ä¹ ç§‘å­¦çŸ¥è¯†å’Œè¯­è¨€æ¨¡å¼ã€‚2) **ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰**ï¼šä½¿ç”¨æŒ‡ä»¤æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿç†è§£å’Œæ‰§è¡Œå„ç§ç§‘å­¦ä»»åŠ¡ã€‚3) **é€€ç«å†·å¯åŠ¨è‡ªä¸¾**ï¼šé€šè¿‡è‡ªä¸¾æ–¹æ³•ç”Ÿæˆé•¿å½¢å¼çš„æ€ç»´é“¾ï¼Œæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚4) **å¼ºåŒ–å­¦ä¹ **ï¼šä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±å¡‘é€ è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šSciReasonerçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»¼åˆåˆ©ç”¨äº†å¤šç§è®­ç»ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒã€è‡ªä¸¾å’Œå¼ºåŒ–å­¦ä¹ ï¼Œä»è€Œæ„å»ºäº†ä¸€ä¸ªé€šç”¨çš„ç§‘å­¦æ¨ç†åŸºç¡€æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜æ”¯æŒå¤šç§ç§‘å­¦è¡¨ç¤ºï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€åºåˆ—å’ŒçŸ¥è¯†å›¾è°±ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†å„ç§ä¸åŒçš„ç§‘å­¦ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨äº†åŒ…å«2060äº¿tokençš„è¯­æ–™åº“ï¼Œæ¶µç›–ç§‘å­¦æ–‡æœ¬ã€çº¯åºåˆ—å’Œåºåˆ—-æ–‡æœ¬å¯¹ã€‚åœ¨ç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œä½¿ç”¨äº†4000ä¸‡æ¡æŒ‡ä»¤ã€‚åœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œä½¿ç”¨äº†ä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±å¡‘é€ å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SciReasoneråœ¨å¤šä¸ªç§‘å­¦ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸ä¸“ä¸šç³»ç»Ÿç›¸æ¯”ï¼Œæ‰©å±•äº†æŒ‡ä»¤è¦†ç›–èŒƒå›´ï¼Œæé«˜äº†è·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶å¢å¼ºäº†ä¿çœŸåº¦ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªåœ¨æ‘˜è¦ä¸­ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚è¯¥æ¨¡å‹ã€æŒ‡ä»¤è°ƒä¼˜æ•°æ®é›†å’Œè¯„ä¼°ä»£ç å·²å¼€æºï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜ä½¿ç”¨å’Œè¿›ä¸€æ­¥å¼€å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SciReasonerå¯åº”ç”¨äºå¤šä¸ªç§‘å­¦é¢†åŸŸï¼Œä¾‹å¦‚åŒ–å­¦ã€ç”Ÿç‰©å­¦ã€ææ–™ç§‘å­¦ç­‰ã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨åŒ–ç§‘å­¦å‘ç°ã€çŸ¥è¯†æå–ã€å±æ€§é¢„æµ‹ã€åºåˆ—ç”Ÿæˆå’Œè®¾è®¡ç­‰ä»»åŠ¡ã€‚è¯¥æ¨¡å‹æœ‰æœ›åŠ é€Ÿç§‘å­¦ç ”ç©¶è¿›ç¨‹ï¼Œå¹¶ä¸ºç§‘å­¦å®¶æä¾›å¼ºå¤§çš„è¾…åŠ©å·¥å…·ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•SciReasonerçš„èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ç§‘å­¦é—®é¢˜ï¼Œå¹¶ä¸å…¶ä»–ç§‘å­¦å·¥å…·é›†æˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a scientific reasoning foundation model that aligns natural language with heterogeneous scientific representations. The model is pretrained on a 206B-token corpus spanning scientific text, pure sequences, and sequence-text pairs, then aligned via SFT on 40M instructions, annealed cold-start bootstrapping to elicit long-form chain-of-thought, and reinforcement learning with task-specific reward shaping, which instills deliberate scientific reasoning. It supports four capability families, covering up to 103 tasks across workflows: (i) faithful translation between text and scientific formats, (ii) text/knowledge extraction, (iii) property prediction, (iv) property classification, (v) unconditional and conditional sequence generation and design. Compared with specialist systems, our approach broadens instruction coverage, improves cross-domain generalization, and enhances fidelity. We detail data curation and training and show that cross-discipline learning strengthens transfer and downstream reliability. The model, instruct tuning datasets and the evaluation code are open-sourced at https://huggingface.co/SciReason and https://github.com/open-sciencelab/SciReason.

