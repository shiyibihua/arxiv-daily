---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-08-20
---

# cs.CLï¼ˆ2025-08-20ï¼‰

ğŸ“Š å…± **30** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (22 ğŸ”—4)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (22 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250815851v1-dochop-qa-towards-multi-hop-reasoning-over-multimodal-document-colle.html">DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections</a></td>
  <td>æå‡ºDocHop-QAä»¥è§£å†³å¤šæ–‡æ¡£å¤šæ¨¡æ€é—®ç­”ä¸­çš„æ¨ç†æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15851v1" data-paper-url="./papers/250815851v1-dochop-qa-towards-multi-hop-reasoning-over-multimodal-document-colle.html" onclick="toggleFavorite(this, '2508.15851v1', 'DocHop-QA: Towards Multi-Hop Reasoning over Multimodal Document Collections')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250815849v1-medcot-rag-causal-chain-of-thought-rag-for-medical-question-answerin.html">MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering</a></td>
  <td>æå‡ºMedCoT-RAGä»¥è§£å†³åŒ»ç–—é—®ç­”ä¸­çš„æ¨ç†ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15849v1" data-paper-url="./papers/250815849v1-medcot-rag-causal-chain-of-thought-rag-for-medical-question-answerin.html" onclick="toggleFavorite(this, '2508.15849v1', 'MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250814828v2-long-chain-of-thought-reasoning-across-languages.html">Long Chain-of-Thought Reasoning Across Languages</a></td>
  <td>ç ”ç©¶å¤šè¯­è¨€é•¿é“¾æ¨ç†èƒ½åŠ›çš„è¿ç§»ä¸æå‡</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14828v2" data-paper-url="./papers/250814828v2-long-chain-of-thought-reasoning-across-languages.html" onclick="toggleFavorite(this, '2508.14828v2', 'Long Chain-of-Thought Reasoning Across Languages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250814390v1-credence-calibration-game-calibrating-large-language-models-through-.html">Credence Calibration Game? Calibrating Large Language Models through Structured Play</a></td>
  <td>æå‡ºåŸºäºæ¸¸æˆç»“æ„çš„æ ¡å‡†æ¡†æ¶ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„ä¿¡å¿ƒä¼°è®¡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14390v1" data-paper-url="./papers/250814390v1-credence-calibration-game-calibrating-large-language-models-through-.html" onclick="toggleFavorite(this, '2508.14390v1', 'Credence Calibration Game? Calibrating Large Language Models through Structured Play')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250814869v1-the-prompting-brain-neurocognitive-markers-of-expertise-in-guiding-l.html">The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models</a></td>
  <td>é€šè¿‡ç¥ç»è®¤çŸ¥æ ‡è®°æ¢ç´¢æç¤ºå·¥ç¨‹ä¸“å®¶çš„è„‘åŠŸèƒ½è¿æ¥</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14869v1" data-paper-url="./papers/250814869v1-the-prompting-brain-neurocognitive-markers-of-expertise-in-guiding-l.html" onclick="toggleFavorite(this, '2508.14869v1', 'The Prompting Brain: Neurocognitive Markers of Expertise in Guiding Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250814427v1-knowledge-graph-infused-fine-tuning-for-structured-reasoning-in-larg.html">Knowledge Graph-Infused Fine-Tuning for Structured Reasoning in Large Language Models</a></td>
  <td>æå‡ºçŸ¥è¯†å›¾è°±æ³¨å…¥å¾®è°ƒæ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14427v1" data-paper-url="./papers/250814427v1-knowledge-graph-infused-fine-tuning-for-structured-reasoning-in-larg.html" onclick="toggleFavorite(this, '2508.14427v1', 'Knowledge Graph-Infused Fine-Tuning for Structured Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250815861v1-xfinbench-benchmarking-llms-in-complex-financial-problem-solving-and.html">XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning</a></td>
  <td>æå‡ºXFinBenchä»¥è¯„ä¼°LLMsåœ¨å¤æ‚é‡‘èé—®é¢˜è§£å†³ä¸­çš„èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15861v1" data-paper-url="./papers/250815861v1-xfinbench-benchmarking-llms-in-complex-financial-problem-solving-and.html" onclick="toggleFavorite(this, '2508.15861v1', 'XFinBench: Benchmarking LLMs in Complex Financial Problem Solving and Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250900030v3-signbind-llm-multi-stage-modality-fusion-for-sign-language-translati.html">SignBind-LLM: Multi-Stage Modality Fusion for Sign Language Translation</a></td>
  <td>æå‡ºSignBind-LLMä»¥è§£å†³æ‰‹è¯­ç¿»è¯‘ä¸­çš„å¤šæ¨¡æ€èåˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00030v3" data-paper-url="./papers/250900030v3-signbind-llm-multi-stage-modality-fusion-for-sign-language-translati.html" onclick="toggleFavorite(this, '2509.00030v3', 'SignBind-LLM: Multi-Stage Modality Fusion for Sign Language Translation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250815096v1-nemotron-cc-math-a-133-billion-token-scale-high-quality-math-pretrai.html">Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset</a></td>
  <td>æå‡ºNemotron-CC-Mathä»¥è§£å†³æ•°å­¦æ•°æ®é›†è´¨é‡ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15096v1" data-paper-url="./papers/250815096v1-nemotron-cc-math-a-133-billion-token-scale-high-quality-math-pretrai.html" onclick="toggleFavorite(this, '2508.15096v1', 'Nemotron-CC-Math: A 133 Billion-Token-Scale High Quality Math Pretraining Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250816665v3-trust-but-verify-a-survey-on-verification-design-for-test-time-scali.html">Trust but Verify! A Survey on Verification Design for Test-time Scaling</a></td>
  <td>æå‡ºéªŒè¯è®¾è®¡ä»¥ä¼˜åŒ–æµ‹è¯•æ—¶æ‰©å±•æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.16665v3" data-paper-url="./papers/250816665v3-trust-but-verify-a-survey-on-verification-design-for-test-time-scali.html" onclick="toggleFavorite(this, '2508.16665v3', 'Trust but Verify! A Survey on Verification Design for Test-time Scaling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250814896v2-quantization-meets-dllms-a-systematic-study-of-post-training-quantiz.html">Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs</a></td>
  <td>ç³»ç»Ÿç ”ç©¶åè®­ç»ƒé‡åŒ–ä»¥ä¼˜åŒ–æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14896v2" data-paper-url="./papers/250814896v2-quantization-meets-dllms-a-systematic-study-of-post-training-quantiz.html" onclick="toggleFavorite(this, '2508.14896v2', 'Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250814735v1-evaluating-multilingual-and-code-switched-alignment-in-llms-via-synt.html">Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference</a></td>
  <td>æå‡ºå¤šè¯­è¨€è‡ªç„¶è¯­è¨€æ¨ç†æ¡†æ¶ä»¥æå‡LLMçš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14735v1" data-paper-url="./papers/250814735v1-evaluating-multilingual-and-code-switched-alignment-in-llms-via-synt.html" onclick="toggleFavorite(this, '2508.14735v1', 'Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250814723v3-transplant-then-regenerate-a-new-paradigm-for-text-data-augmentation.html">Transplant Then Regenerate: A New Paradigm for Text Data Augmentation</a></td>
  <td>æå‡ºLMTransplantä»¥è§£å†³æ–‡æœ¬æ•°æ®å¢å¼ºçš„å¤šæ ·æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14723v3" data-paper-url="./papers/250814723v3-transplant-then-regenerate-a-new-paradigm-for-text-data-augmentation.html" onclick="toggleFavorite(this, '2508.14723v3', 'Transplant Then Regenerate: A New Paradigm for Text Data Augmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250814377v2-zpd-sca-unveiling-the-blind-spots-of-llms-in-assessing-students-cogn.html">ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities</a></td>
  <td>æå‡ºZPD-SCAä»¥è§£å†³LLMsè¯„ä¼°å­¦ç”Ÿè®¤çŸ¥èƒ½åŠ›çš„ç›²ç‚¹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14377v2" data-paper-url="./papers/250814377v2-zpd-sca-unveiling-the-blind-spots-of-llms-in-assessing-students-cogn.html" onclick="toggleFavorite(this, '2508.14377v2', 'ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students&#39; Cognitive Abilities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250815110v1-llms-and-agentic-ai-in-insurance-decision-making-opportunities-and-c.html">LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa</a></td>
  <td>æ¢è®¨å¤§è¯­è¨€æ¨¡å‹ä¸ä»£ç†AIåœ¨éæ´²ä¿é™©å†³ç­–ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15110v1" data-paper-url="./papers/250815110v1-llms-and-agentic-ai-in-insurance-decision-making-opportunities-and-c.html" onclick="toggleFavorite(this, '2508.15110v1', 'LLMs and Agentic AI in Insurance Decision-Making: Opportunities and Challenges For Africa')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250814982v1-multilingual-datasets-for-custom-input-extraction-and-explanation-re.html">Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems</a></td>
  <td>æå‡ºMultiCoXQLå’ŒCompassä»¥è§£å†³å¤šè¯­è¨€ConvXAIç³»ç»Ÿçš„æ•°æ®ç¨€ç¼ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14982v1" data-paper-url="./papers/250814982v1-multilingual-datasets-for-custom-input-extraction-and-explanation-re.html" onclick="toggleFavorite(this, '2508.14982v1', 'Multilingual Datasets for Custom Input Extraction and Explanation Requests Parsing in Conversational XAI Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250814685v2-scaled-signed-averaging-improves-in-context-and-early-learning-bench.html">Scaled Signed Averaging Improves In-Context and Early Learning Benchmark Performance in Small Transformers</a></td>
  <td>æå‡ºç¼©æ”¾ç­¾åå¹³å‡æ³•ä»¥è§£å†³å°å‹å˜æ¢å™¨çš„å­¦ä¹ é™åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14685v2" data-paper-url="./papers/250814685v2-scaled-signed-averaging-improves-in-context-and-early-learning-bench.html" onclick="toggleFavorite(this, '2508.14685v2', 'Scaled Signed Averaging Improves In-Context and Early Learning Benchmark Performance in Small Transformers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250815855v1-counterspeech-for-mitigating-the-influence-of-media-bias-comparing-h.html">Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses</a></td>
  <td>æå‡ºåè¨€è®ºä»¥ç¼“è§£åª’ä½“åè§å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15855v1" data-paper-url="./papers/250815855v1-counterspeech-for-mitigating-the-influence-of-media-bias-comparing-h.html" onclick="toggleFavorite(this, '2508.15855v1', 'Counterspeech for Mitigating the Influence of Media Bias: Comparing Human and LLM-Generated Responses')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250815854v1-qu-nlp-at-qias-2025-shared-task-a-two-phase-llm-fine-tuning-and-retr.html">QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning</a></td>
  <td>æå‡ºåŸºäºRAGçš„LLMå¾®è°ƒæ–¹æ³•ä»¥è§£å†³ä¼Šæ–¯å…°ç»§æ‰¿æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15854v1" data-paper-url="./papers/250815854v1-qu-nlp-at-qias-2025-shared-task-a-two-phase-llm-fine-tuning-and-retr.html" onclick="toggleFavorite(this, '2508.15854v1', 'QU-NLP at QIAS 2025 Shared Task: A Two-Phase LLM Fine-Tuning and Retrieval-Augmented Generation Approach for Islamic Inheritance Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250815848v1-self-disguise-attack-induce-the-llm-to-disguise-itself-for-aigt-dete.html">Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion</a></td>
  <td>æå‡ºè‡ªæˆ‘ä¼ªè£…æ”»å‡»ä»¥è§£å†³AIGTæ£€æµ‹è§„é¿é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15848v1" data-paper-url="./papers/250815848v1-self-disguise-attack-induce-the-llm-to-disguise-itself-for-aigt-dete.html" onclick="toggleFavorite(this, '2508.15848v1', 'Self-Disguise Attack: Induce the LLM to disguise itself for AIGT detection evasion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250814941v1-robust-symbolic-reasoning-for-visual-narratives-via-hierarchical-and.html">Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs</a></td>
  <td>æå‡ºè¯­ä¹‰å½’ä¸€åŒ–æ¡†æ¶ä»¥è§£å†³è§†è§‰å™äº‹ä¸­çš„ç¬¦å·æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14941v1" data-paper-url="./papers/250814941v1-robust-symbolic-reasoning-for-visual-narratives-via-hierarchical-and.html" onclick="toggleFavorite(this, '2508.14941v1', 'Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250814317v1-surveygen-i-consistent-scientific-survey-generation-with-evolving-pl.html">SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing</a></td>
  <td>æå‡ºSurveyGen-Iä»¥è§£å†³ç§‘å­¦è°ƒæŸ¥ç”Ÿæˆä¸­çš„ä¸€è‡´æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14317v1" data-paper-url="./papers/250814317v1-surveygen-i-consistent-scientific-survey-generation-with-evolving-pl.html" onclick="toggleFavorite(this, '2508.14317v1', 'SurveyGen-I: Consistent Scientific Survey Generation with Evolving Plans and Memory-Guided Writing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250814782v1-transllm-a-unified-multi-task-foundation-framework-for-urban-transpo.html">TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting</a></td>
  <td>æå‡ºTransLLMä»¥è§£å†³åŸå¸‚äº¤é€šå¤šä»»åŠ¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">spatiotemporal</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14782v1" data-paper-url="./papers/250814782v1-transllm-a-unified-multi-task-foundation-framework-for-urban-transpo.html" onclick="toggleFavorite(this, '2508.14782v1', 'TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250814951v1-improving-llms-for-machine-translation-using-synthetic-preference-da.html">Improving LLMs for Machine Translation Using Synthetic Preference Data</a></td>
  <td>é€šè¿‡åˆæˆåå¥½æ•°æ®æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æœºå™¨ç¿»è¯‘èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">direct preference optimization</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14951v1" data-paper-url="./papers/250814951v1-improving-llms-for-machine-translation-using-synthetic-preference-da.html" onclick="toggleFavorite(this, '2508.14951v1', 'Improving LLMs for Machine Translation Using Synthetic Preference Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250814574v1-towards-skeletal-and-signer-noise-reduction-in-sign-language-product.html">Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning</a></td>
  <td>æå‡ºåŸºäºå››å…ƒæ•°çš„å§¿æ€ç¼–ç ä¸å¯¹æ¯”å­¦ä¹ ä»¥å‡å°‘æ‰‹è¯­ç”Ÿæˆä¸­çš„å™ªå£°</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14574v1" data-paper-url="./papers/250814574v1-towards-skeletal-and-signer-noise-reduction-in-sign-language-product.html" onclick="toggleFavorite(this, '2508.14574v1', 'Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250814444v4-nvidia-nemotron-nano-2-an-accurate-and-efficient-hybrid-mamba-transf.html">NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model</a></td>
  <td>æå‡ºNemotron-Nano-9B-v2ä»¥æå‡æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§ä¸æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14444v4" data-paper-url="./papers/250814444v4-nvidia-nemotron-nano-2-an-accurate-and-efficient-hybrid-mamba-transf.html" onclick="toggleFavorite(this, '2508.14444v4', 'NVIDIA Nemotron Nano 2: An Accurate and Efficient Hybrid Mamba-Transformer Reasoning Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250814391v1-depth-hallucination-free-relation-extraction-via-dependency-aware-se.html">DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement</a></td>
  <td>æå‡ºDEPTHæ¡†æ¶ä»¥è§£å†³å…³ç³»æå–ä¸­çš„å¹»è§‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14391v1" data-paper-url="./papers/250814391v1-depth-hallucination-free-relation-extraction-via-dependency-aware-se.html" onclick="toggleFavorite(this, '2508.14391v1', 'DEPTH: Hallucination-Free Relation Extraction via Dependency-Aware Sentence Simplification and Two-tiered Hierarchical Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250815044v3-reward-shifted-speculative-sampling-is-an-efficient-test-time-weak-t.html">Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner</a></td>
  <td>æå‡ºå¥–åŠ±è½¬ç§»çš„æ¨æµ‹é‡‡æ ·ä»¥æé«˜æµ‹è¯•æ—¶å¯¹é½æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15044v3" data-paper-url="./papers/250815044v3-reward-shifted-speculative-sampling-is-an-efficient-test-time-weak-t.html" onclick="toggleFavorite(this, '2508.15044v3', 'Reward-Shifted Speculative Sampling Is An Efficient Test-Time Weak-to-Strong Aligner')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250814323v2-beyond-semantic-similarity-reducing-unnecessary-api-calls-via-behavi.html">Beyond Semantic Similarity: Reducing Unnecessary API Calls via Behavior-Aligned Retriever</a></td>
  <td>æå‡ºè¡Œä¸ºå¯¹é½æ£€ç´¢å™¨ä»¥å‡å°‘ä¸å¿…è¦çš„APIè°ƒç”¨</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14323v2" data-paper-url="./papers/250814323v2-beyond-semantic-similarity-reducing-unnecessary-api-calls-via-behavi.html" onclick="toggleFavorite(this, '2508.14323v2', 'Beyond Semantic Similarity: Reducing Unnecessary API Calls via Behavior-Aligned Retriever')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>30</td>
  <td><a href="./papers/250814706v1-shizhengpt-towards-multimodal-llms-for-traditional-chinese-medicine.html">ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine</a></td>
  <td>æå‡ºShizhenGPTä»¥è§£å†³ä¸­åŒ»é¢†åŸŸå¤šæ¨¡æ€æ•°æ®ç¨€ç¼ºé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.14706v1" data-paper-url="./papers/250814706v1-shizhengpt-towards-multimodal-llms-for-traditional-chinese-medicine.html" onclick="toggleFavorite(this, '2508.14706v1', 'ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)