---
layout: default
title: Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning
---

# Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14574" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14574v1</a>
  <a href="https://arxiv.org/pdf/2508.14574.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14574v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14574v1', 'Towards Skeletal and Signer Noise Reduction in Sign Language Production via Quaternion-Based Pose Encoding and Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guilhem FaurÃ©, Mostafa Sadeghi, Sam Bigeard, Slim Ouni

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**æœŸåˆŠ**: SLTAT 2025: 9th Workshop on Sign Language Translation and Avatar Technologies, Sep 2025, Berlin, Germany

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå››å…ƒæ•°çš„å§¿æ€ç¼–ç ä¸å¯¹æ¯”å­¦ä¹ ä»¥å‡å°‘æ‰‹è¯­ç”Ÿæˆä¸­çš„å™ªå£°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ‰‹è¯­ç”Ÿæˆ` `å››å…ƒæ•°ç¼–ç ` `å¯¹æ¯”å­¦ä¹ ` `æ¸è¿›å¼å˜æ¢å™¨` `å§¿æ€è¯†åˆ«` `è¯­ä¹‰ç›¸ä¼¼æ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰‹è¯­ç”Ÿæˆä¸­çš„é«˜ç±»å†…å˜å¼‚æ€§å¯¼è‡´æ¨¡å‹é²æ£’æ€§ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†ä¸åŒç­¾ç½²è€…çš„é£æ ¼å·®å¼‚ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å››å…ƒæ•°ç¼–ç å§¿æ€å’Œå¯¹æ¯”æŸå¤±æ¥å¢å¼ºæ¸è¿›å¼å˜æ¢å™¨æ¶æ„ï¼Œæé«˜æ‰‹è¯­ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œæ¸…æ™°åº¦ã€‚
3. åœ¨Phoenix14Tæ•°æ®é›†ä¸Šï¼Œç»“åˆæ–°æ–¹æ³•çš„æ¨¡å‹åœ¨å…³é”®ç‚¹æ¦‚ç‡å’Œéª¨è§’è¯¯å·®ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰‹è¯­ç”Ÿæˆï¼ˆSLPï¼‰ä¸­çš„ä¸»è¦æŒ‘æˆ˜ä¹‹ä¸€æ˜¯æ‰‹åŠ¿çš„é«˜ç±»å†…å˜å¼‚æ€§ï¼Œè¿™æºäºç­¾ç½²è€…çš„å½¢æ€ç‰¹å¾å’Œè®­ç»ƒæ•°æ®ä¸­çš„é£æ ¼å¤šæ ·æ€§ã€‚ä¸ºæé«˜å¯¹è¿™äº›å˜å¼‚çš„é²æ£’æ€§ï¼Œæœ¬æ–‡å¯¹æ ‡å‡†çš„æ¸è¿›å¼å˜æ¢å™¨æ¶æ„è¿›è¡Œäº†ä¸¤é¡¹å¢å¼ºï¼šé¦–å…ˆï¼Œä½¿ç”¨å››å…ƒæ•°ç©ºé—´ä¸­çš„éª¨éª¼æ—‹è½¬ç¼–ç å§¿æ€ï¼Œå¹¶é€šè¿‡æµ‹åœ°æŸå¤±è®­ç»ƒï¼Œä»¥æé«˜å…³èŠ‚è¿åŠ¨çš„å‡†ç¡®æ€§å’Œæ¸…æ™°åº¦ï¼›å…¶æ¬¡ï¼Œå¼•å…¥å¯¹æ¯”æŸå¤±ï¼Œé€šè¿‡è¯­ä¹‰ç›¸ä¼¼æ€§ç»“æ„åŒ–è§£ç å™¨åµŒå…¥ï¼Œæ—¨åœ¨è¿‡æ»¤æ‰ä¸ä¼ è¾¾ç›¸å…³è¯­ä¹‰ä¿¡æ¯çš„è§£å‰–å’Œé£æ ¼ç‰¹å¾ã€‚åœ¨Phoenix14Tæ•°æ®é›†ä¸Šï¼Œä»…å¯¹æ¯”æŸå¤±å°±ä½¿å¾—æ­£ç¡®å…³é”®ç‚¹æ¦‚ç‡æé«˜äº†16%ã€‚ç»“åˆå››å…ƒæ•°å§¿æ€ç¼–ç åï¼Œæ¨¡å‹çš„å¹³å‡éª¨è§’è¯¯å·®å‡å°‘äº†6%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå°†éª¨éª¼ç»“æ„å»ºæ¨¡å’Œè¯­ä¹‰å¼•å¯¼çš„å¯¹æ¯”ç›®æ ‡çº³å…¥åŸºäºå˜æ¢å™¨çš„SLPæ¨¡å‹è®­ç»ƒä¸­å…·æœ‰æ˜¾è‘—ç›Šå¤„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ‰‹è¯­ç”Ÿæˆï¼ˆSLPï¼‰é¢ä¸´çš„ä¸»è¦é—®é¢˜æ˜¯é«˜ç±»å†…å˜å¼‚æ€§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ä¸åŒç­¾ç½²è€…çš„æ‰‹åŠ¿è¡¨ç°ä¸Šç¼ºä¹é²æ£’æ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£å†³è¿™ä¸€æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºé€šè¿‡å››å…ƒæ•°ç¼–ç æ¥è¡¨ç¤ºéª¨éª¼å§¿æ€ï¼Œå¹¶ç»“åˆå¯¹æ¯”æŸå¤±æ¥ä¼˜åŒ–è§£ç å™¨åµŒå…¥ï¼Œä»è€Œæé«˜æ‰‹è¯­ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŸºäºæ¸è¿›å¼å˜æ¢å™¨ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬å››å…ƒæ•°å§¿æ€ç¼–ç æ¨¡å—å’Œå¯¹æ¯”æŸå¤±æ¨¡å—ã€‚å››å…ƒæ•°æ¨¡å—è´Ÿè´£å°†å…³èŠ‚æ—‹è½¬ä¿¡æ¯è½¬åŒ–ä¸ºå››å…ƒæ•°è¡¨ç¤ºï¼Œè€Œå¯¹æ¯”æŸå¤±æ¨¡å—åˆ™é€šè¿‡è¯­ä¹‰ç›¸ä¼¼æ€§æ¥ä¼˜åŒ–æ¨¡å‹è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å››å…ƒæ•°ç©ºé—´çš„å§¿æ€ç¼–ç å’Œå¯¹æ¯”æŸå¤±ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æ¬§å‡ é‡Œå¾—ç©ºé—´è¡¨ç¤ºå’Œç®€å•çš„æŸå¤±å‡½æ•°æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å…³èŠ‚è¿åŠ¨çš„ç»†å¾®å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨æµ‹åœ°æŸå¤±æ¥ä¼˜åŒ–å››å…ƒæ•°è¡¨ç¤ºçš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä½¿ç”¨åŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§çš„å¯¹æ¯”æŸå¤±æ¥å¢å¼ºè§£ç å™¨çš„è¯­ä¹‰ç»“æ„ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºçš„æ‰‹åŠ¿åœ¨è¯­ä¹‰ä¸Šæ›´ä¸ºä¸€è‡´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä»…å¯¹æ¯”æŸå¤±å°±ä½¿å¾—æ­£ç¡®å…³é”®ç‚¹æ¦‚ç‡æé«˜äº†16%ï¼Œè€Œç»“åˆå››å…ƒæ•°ç¼–ç åï¼Œæ¨¡å‹çš„å¹³å‡éª¨è§’è¯¯å·®å‡å°‘äº†6%ã€‚è¿™äº›ç»“æœæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼ŒéªŒè¯äº†æ–°æ–¹æ³•åœ¨æ‰‹è¯­ç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‰‹è¯­ç¿»è¯‘ã€è™šæ‹Ÿç°å®ä¸­çš„æ‰‹åŠ¿äº¤äº’ä»¥åŠè¾…åŠ©æ²Ÿé€šå·¥å…·çš„å¼€å‘ã€‚é€šè¿‡æé«˜æ‰‹è¯­ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æœåŠ¡äºå¬éšœäººå£«ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„æ— éšœç¢æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–éœ€è¦å§¿æ€è¯†åˆ«çš„é¢†åŸŸï¼Œå¦‚è¿åŠ¨åˆ†æå’Œäººæœºåä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> One of the main challenges in neural sign language production (SLP) lies in the high intra-class variability of signs, arising from signer morphology and stylistic variety in the training data. To improve robustness to such variations, we propose two enhancements to the standard Progressive Transformers (PT) architecture (Saunders et al., 2020). First, we encode poses using bone rotations in quaternion space and train with a geodesic loss to improve the accuracy and clarity of angular joint movements. Second, we introduce a contrastive loss to structure decoder embeddings by semantic similarity, using either gloss overlap or SBERT-based sentence similarity, aiming to filter out anatomical and stylistic features that do not convey relevant semantic information. On the Phoenix14T dataset, the contrastive loss alone yields a 16% improvement in Probability of Correct Keypoint over the PT baseline. When combined with quaternion-based pose encoding, the model achieves a 6% reduction in Mean Bone Angle Error. These results point to the benefit of incorporating skeletal structure modeling and semantically guided contrastive objectives on sign pose representations into the training of Transformer-based SLP models.

