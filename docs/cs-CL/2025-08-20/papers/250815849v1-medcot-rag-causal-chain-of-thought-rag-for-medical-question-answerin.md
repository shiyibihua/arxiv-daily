---
layout: default
title: MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering
---

# MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15849" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15849v1</a>
  <a href="https://arxiv.org/pdf/2508.15849.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15849v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15849v1', 'MedCoT-RAG: Causal Chain-of-Thought RAG for Medical Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyu Wang, Elahe Khatibi, Amir M. Rahmani

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedCoT-RAGä»¥è§£å†³åŒ»ç–—é—®ç­”ä¸­çš„æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»ç–—é—®ç­”` `å› æœæ¨ç†` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸´åºŠå†³ç­–æ”¯æŒ` `ç»“æ„åŒ–æ€ç»´æç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»ç–—é—®ç­”æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä¸´åºŠé—®é¢˜æ—¶ï¼Œå¸¸å¸¸å‡ºç°æ¨ç†ä¸è¶³å’Œä¿¡æ¯å¹»è§‰ï¼Œå½±å“å‡†ç¡®æ€§ã€‚
2. MedCoT-RAGé€šè¿‡ç»“åˆå› æœæ„è¯†çš„æ–‡æ¡£æ£€ç´¢ä¸ç»“æ„åŒ–æ€ç»´æç¤ºï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œä¸´åºŠé€‚åº”æ€§ã€‚
3. åœ¨ä¸‰ä¸ªåŒ»ç–—é—®ç­”åŸºå‡†ä¸Šï¼ŒMedCoT-RAGç›¸æ¯”äºä¼ ç»ŸRAGæå‡äº†10.3%çš„å‡†ç¡®ç‡ï¼Œå±•ç°å‡ºæ›´å¥½çš„å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é—®ç­”ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†åœ¨éœ€è¦ç»†è‡´ä¸´åºŠç†è§£çš„ä»»åŠ¡ä¸­å¸¸å¸¸é¢ä¸´å¹»è§‰å’Œæµ…å±‚æ¨ç†çš„é—®é¢˜ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸ºå¢å¼ºLLMæä¾›äº†å®ç”¨ä¸”ä¿æŠ¤éšç§çš„æ–¹å¼ï¼Œä½†ç°æœ‰æ–¹æ³•å¤šä¾èµ–è¡¨å±‚è¯­ä¹‰æ£€ç´¢ï¼Œç¼ºä¹ä¸´åºŠå†³ç­–æ”¯æŒæ‰€éœ€çš„ç»“æ„åŒ–æ¨ç†ã€‚æœ¬æ–‡æå‡ºMedCoT-RAGï¼Œä¸€ä¸ªç»“åˆå› æœæ„è¯†æ–‡æ¡£æ£€ç´¢ä¸ç»“æ„åŒ–æ€ç»´æç¤ºçš„é¢†åŸŸç‰¹å®šæ¡†æ¶ï¼Œæ—¨åœ¨ä¸åŒ»ç–—å·¥ä½œæµç¨‹ç›¸é€‚åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMedCoT-RAGåœ¨ä¸‰ä¸ªå¤šæ ·çš„åŒ»ç–—é—®ç­”åŸºå‡†ä¸Šè¶…è¶Šäº†å¼ºåŸºçº¿ï¼Œå‡†ç¡®æ€§ã€å¯è§£é‡Šæ€§å’Œä¸€è‡´æ€§å‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŒ»ç–—é—®ç­”ç³»ç»Ÿåœ¨å¤æ‚ä¸´åºŠé—®é¢˜ä¸­æ¨ç†ä¸è¶³å’Œä¿¡æ¯å¹»è§‰çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–è¡¨å±‚è¯­ä¹‰æ£€ç´¢ï¼Œç¼ºä¹æ·±å±‚æ¬¡çš„å› æœæ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMedCoT-RAGçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå› æœæ„è¯†çš„æ–‡æ¡£æ£€ç´¢ä¸ç»“æ„åŒ–çš„æ€ç»´æç¤ºï¼Œæ—¨åœ¨ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆç¬¦åˆä¸´åºŠé€»è¾‘çš„æ¨ç†è¿‡ç¨‹ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæé«˜æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸçš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ¨¡å—ï¼šå› æœæ„è¯†æ–‡æ¡£æ£€ç´¢æ¨¡å—å’Œç»“æ„åŒ–æ€ç»´æç¤ºæ¨¡å—ã€‚å‰è€…è´Ÿè´£ä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¸è¯Šæ–­é€»è¾‘ç›¸å…³çš„è¯æ®ï¼Œåè€…åˆ™å¼•å¯¼æ¨¡å‹ç”Ÿæˆé€æ­¥çš„å› æœæ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMedCoT-RAGçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶å°†å› æœæ¨ç†ä¸æ£€ç´¢å¢å¼ºç”Ÿæˆç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„åŒ»ç–—é—®ç­”æ¡†æ¶ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„è¡¨å±‚æ£€ç´¢å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å› æœæ¨ç†çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„ä»¥é€‚åº”åŒ»ç–—é¢†åŸŸçš„ç‰¹å®šéœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedCoT-RAGåœ¨ä¸‰ä¸ªåŒ»ç–—é—®ç­”åŸºå‡†ä¸Šç›¸è¾ƒäºä¼ ç»ŸRAGæå‡äº†10.3%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨ä¸å…ˆè¿›çš„é¢†åŸŸé€‚åº”æ–¹æ³•å¯¹æ¯”ä¸­æå‡äº†6.4%ã€‚è¿™äº›ç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤æ‚åŒ»ç–—ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MedCoT-RAGåœ¨åŒ»ç–—é—®ç­”ç³»ç»Ÿä¸­çš„åº”ç”¨æ½œåŠ›å·¨å¤§ï¼Œå¯ä»¥ç”¨äºä¸´åºŠå†³ç­–æ”¯æŒã€æ‚£è€…å’¨è¯¢å’ŒåŒ»å­¦æ•™è‚²ç­‰é¢†åŸŸã€‚é€šè¿‡æä¾›æ›´å‡†ç¡®å’Œå¯è§£é‡Šçš„ç­”æ¡ˆï¼Œè¯¥æ¡†æ¶æœ‰åŠ©äºæå‡åŒ»ç–—æœåŠ¡è´¨é‡ï¼Œå¹¶å¯èƒ½åœ¨æœªæ¥æ¨åŠ¨æ™ºèƒ½åŒ»ç–—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown promise in medical question answering but often struggle with hallucinations and shallow reasoning, particularly in tasks requiring nuanced clinical understanding. Retrieval-augmented generation (RAG) offers a practical and privacy-preserving way to enhance LLMs with external medical knowledge. However, most existing approaches rely on surface-level semantic retrieval and lack the structured reasoning needed for clinical decision support. We introduce MedCoT-RAG, a domain-specific framework that combines causal-aware document retrieval with structured chain-of-thought prompting tailored to medical workflows. This design enables models to retrieve evidence aligned with diagnostic logic and generate step-by-step causal reasoning reflective of real-world clinical practice. Experiments on three diverse medical QA benchmarks show that MedCoT-RAG outperforms strong baselines by up to 10.3% over vanilla RAG and 6.4% over advanced domain-adapted methods, improving accuracy, interpretability, and consistency in complex medical tasks.

