---
layout: default
title: ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine
---

# ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14706" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.14706v1</a>
  <a href="https://arxiv.org/pdf/2508.14706.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14706v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14706v1', 'ShizhenGPT: Towards Multimodal LLMs for Traditional Chinese Medicine')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Junying Chen, Zhenyang Cai, Zhiheng Liu, Yunjin Yang, Rongsheng Wang, Qingying Xiao, Xiangyi Feng, Zhan Su, Jing Guo, Xiang Wan, Guangjun Yu, Haizhou Li, Benyou Wang

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.CV, cs.LG, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ShizhenGPT‰ª•Ëß£ÂÜ≥‰∏≠ÂåªÈ¢ÜÂüüÂ§öÊ®°ÊÄÅÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ´ÔºöÁâ©ÁêÜÂä®Áîª (Physics-based Animation)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `‰º†Áªü‰∏≠ÂåªÂ≠¶` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êï∞ÊçÆÈõÜÊûÑÂª∫` `ËßÜËßâÁêÜËß£` `ÂåªÂ≠¶ËØäÊñ≠` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®‰º†Áªü‰∏≠ÂåªÈ¢ÜÂüüÁöÑÂ∫îÁî®ÂèóÂà∞Êï∞ÊçÆÁ®ÄÁº∫ÂíåÂ§öÊ®°ÊÄÅÁâπÊÄßÈôêÂà∂ÔºåÈöæ‰ª•ÊúâÊïàËøõË°å‰∏≠ÂåªËØäÊñ≠„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ShizhenGPTÔºåÁªìÂêà‰∫ÜÂ§ßËßÑÊ®°‰∏≠ÂåªÊï∞ÊçÆÈõÜÂíåÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÔºåÊó®Âú®ÊèêÂçá‰∏≠ÂåªÁü•ËØÜÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåShizhenGPTÂú®‰∏≠ÂåªËµÑÊ†ºËÄÉËØïÂíåËßÜËßâËØäÊñ≠Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºò‰∫éÂêåËßÑÊ®°Ê®°ÂûãÔºåÂπ∂‰∏éÊõ¥Â§ßÊ®°ÂûãÁ´û‰∫â„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ö‰∏™È¢ÜÂüüÂèñÂæó‰∫ÜÊàêÂäüÔºå‰ΩÜÂú®‰º†Áªü‰∏≠ÂåªÂ≠¶ÔºàTCMÔºâ‰∏≠ÁöÑÊΩúÂäõ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢Ôºå‰∏ªË¶ÅÈù¢‰∏¥‰∏§‰∏™ÂÖ≥ÈîÆÈöúÁ¢çÔºö‰∏ÄÊòØÈ´òË¥®Èáè‰∏≠ÂåªÊï∞ÊçÆÁöÑÁ®ÄÁº∫Ôºå‰∫åÊòØ‰∏≠ÂåªËØäÊñ≠ÁöÑÂ§öÊ®°ÊÄÅÁâπÊÄßÔºåÂåÖÊã¨ËßÜËßâ„ÄÅÂê¨Ëßâ„ÄÅÂóÖËßâÂíåËÑâÊêèÊ£ÄÊµã„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜShizhenGPTÔºåËøôÊòØÈ¶ñ‰∏™ÈíàÂØπ‰∏≠ÂåªÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã„ÄÇ‰∏∫ÂÖãÊúçÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢òÔºåÊàë‰ª¨Êï¥ÁêÜ‰∫ÜËøÑ‰ªä‰∏∫Ê≠¢ÊúÄÂ§ßÁöÑ‰∏≠ÂåªÊï∞ÊçÆÈõÜÔºåÂåÖÂê´Ë∂ÖËøá100GBÁöÑÊñáÊú¨Âíå200GBÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÔºåÂåÖÊã¨120‰∏áÂº†ÂõæÂÉè„ÄÅ200Â∞èÊó∂Èü≥È¢ëÂíåÁîüÁêÜ‰ø°Âè∑„ÄÇShizhenGPTÁªèËøáÈ¢ÑËÆ≠ÁªÉÂíåÊåá‰ª§Ë∞É‰ºòÔºåÂÖ∑Â§áÊ∑±ÂéöÁöÑ‰∏≠ÂåªÁü•ËØÜÂíåÂ§öÊ®°ÊÄÅÊé®ÁêÜËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåShizhenGPTÂú®‰∏≠ÂåªËßÜËßâÁêÜËß£ÊñπÈù¢È¢ÜÂÖà‰∫éÁé∞ÊúâÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂Âú®Â§ö‰∏™ËØÑ‰º∞‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥‰º†Áªü‰∏≠ÂåªÈ¢ÜÂüü‰∏≠Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÂ∫îÁî®‰∏çË∂≥ÔºåÁâπÂà´ÊòØÁî±‰∫éÈ´òË¥®Èáè‰∏≠ÂåªÊï∞ÊçÆÁ®ÄÁº∫ÂíåÂ§öÊ®°ÊÄÅËØäÊñ≠ÈúÄÊ±ÇÂØºËá¥ÁöÑÊåëÊàò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜ‰∏≠ÂåªÁöÑÂ§öÁßçÊÑüÂÆò‰ø°ÊÅØÔºåÈôêÂà∂‰∫ÜÂÖ∂Â∫îÁî®ÊΩúÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑShizhenGPTÈÄöËøáÊï¥ÂêàÂ§ßËßÑÊ®°ÁöÑ‰∏≠ÂåªÊï∞ÊçÆÈõÜÔºåÁªìÂêàÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ëÁ≠âÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÊó®Âú®ÊèêÂçáÊ®°ÂûãÂØπ‰∏≠ÂåªÁü•ËØÜÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂ§ÑÁêÜÂ§çÊùÇÁöÑÂ§öÊ®°ÊÄÅËæìÂÖ•ÔºåÈÄÇÂ∫î‰∏≠ÂåªÁöÑËØäÊñ≠ÈúÄÊ±Ç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöShizhenGPTÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÊî∂ÈõÜ„ÄÅÈ¢ÑËÆ≠ÁªÉÂíåÊåá‰ª§Ë∞É‰ºò‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµ„ÄÇÈ¶ñÂÖàÔºåÊûÑÂª∫‰∫ÜÂåÖÂê´ÊñáÊú¨„ÄÅÂõæÂÉè„ÄÅÈü≥È¢ëÂíåÁîüÁêÜ‰ø°Âè∑ÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÈõÜÔºõÂÖ∂Ê¨°ÔºåËøõË°åÊ®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉ‰ª•Â≠¶‰π†‰∏≠ÂåªÁü•ËØÜÔºõÊúÄÂêéÔºåÈÄöËøáÊåá‰ª§Ë∞É‰ºòÊèêÂçáÊ®°ÂûãÂú®ÁâπÂÆö‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöShizhenGPTÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÂÖ∂ÈíàÂØπ‰∏≠ÂåªÈ¢ÜÂüüÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†ËÉΩÂäõÔºåËÉΩÂ§üÁªü‰∏ÄÂ§ÑÁêÜËßÜËßâ„ÄÅÂê¨ËßâÂíåÁîüÁêÜ‰ø°Âè∑Á≠âÂ§öÁßçËæìÂÖ•ÂΩ¢Âºè„ÄÇËøô‰∏ÄÁâπÊÄß‰ΩøÂÖ∂Âú®‰∏≠ÂåªËßÜËßâÁêÜËß£ÂíåËØäÊñ≠ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºå‰∏é‰º†ÁªüÁöÑÂçï‰∏ÄÊ®°ÊÄÅÊ®°ÂûãÁõ∏ÊØîÔºåÂÖ∑Â§áÊõ¥ÂÖ®Èù¢ÁöÑÊÑüÁü•ËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÈÄÇÂ∫îÂ§öÊ®°ÊÄÅËæìÂÖ•ÁöÑÁΩëÁªúÁªìÊûÑÔºåÂπ∂ÈíàÂØπ‰∏çÂêåÊ®°ÊÄÅËÆæÁΩÆ‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰ºòÂåñÊ®°ÂûãÂú®Â§öÊ®°ÊÄÅ‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇÊ≠§Â§ñÔºåÊï∞ÊçÆÈõÜÁöÑÊûÑÂª∫ÂíåÊ∏ÖÊ¥óËøáÁ®ã‰πüÁ°Æ‰øù‰∫ÜÊï∞ÊçÆÁöÑÈ´òË¥®ÈáèÂíåÂ§öÊ†∑ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåShizhenGPTÂú®‰∏≠ÂåªËµÑÊ†ºËÄÉËØïÂíåËßÜËßâËØäÊñ≠Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜÂêåËßÑÊ®°ÁöÑÂÖ∂‰ªñÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÂπ∂‰∏éÊõ¥Â§ßËßÑÊ®°ÁöÑ‰∏ìÊúâÊ®°ÂûãÁ´û‰∫âÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰∏≠ÂåªËßÜËßâÁêÜËß£ÊñπÈù¢ÁöÑÈ¢ÜÂÖàÂú∞‰Ωç„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéShizhenGPTÂú®Â§öÊ®°ÊÄÅÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ‰∏äÁöÑÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ShizhenGPTÁöÑÊΩúÂú®Â∫îÁî®Âú∫ÊôØÂåÖÊã¨‰∏≠ÂåªËØäÊñ≠ËæÖÂä©Á≥ªÁªü„ÄÅÂåªÂ≠¶ÊïôËÇ≤ÂíåÁ†îÁ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèê‰æõÊõ¥ÂÖ®Èù¢ÁöÑÂ§öÊ®°ÊÄÅÁêÜËß£ËÉΩÂäõÔºåËØ•Ê®°ÂûãËÉΩÂ§üÂ∏ÆÂä©ÂåªÁîüÊõ¥ÂáÜÁ°ÆÂú∞ËøõË°åËØäÊñ≠ÔºåÂπ∂‰∏∫‰∏≠ÂåªÈ¢ÜÂüüÁöÑÁ†îÁ©∂Êèê‰æõÊñ∞ÁöÑÂ∑•ÂÖ∑ÂíåËßÜËßí„ÄÇÊú™Êù•ÔºåËØ•Á†îÁ©∂ÊúâÊúõÊé®Âä®‰∏≠Âåª‰∏éÁé∞‰ª£ÂåªÂ≠¶ÁöÑÁªìÂêàÔºåÊèêÂçáÊï¥‰ΩìÂåªÁñóÊ∞¥Âπ≥„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Despite the success of large language models (LLMs) in various domains, their potential in Traditional Chinese Medicine (TCM) remains largely underexplored due to two critical barriers: (1) the scarcity of high-quality TCM data and (2) the inherently multimodal nature of TCM diagnostics, which involve looking, listening, smelling, and pulse-taking. These sensory-rich modalities are beyond the scope of conventional LLMs. To address these challenges, we present ShizhenGPT, the first multimodal LLM tailored for TCM. To overcome data scarcity, we curate the largest TCM dataset to date, comprising 100GB+ of text and 200GB+ of multimodal data, including 1.2M images, 200 hours of audio, and physiological signals. ShizhenGPT is pretrained and instruction-tuned to achieve deep TCM knowledge and multimodal reasoning. For evaluation, we collect recent national TCM qualification exams and build a visual benchmark for Medicinal Recognition and Visual Diagnosis. Experiments demonstrate that ShizhenGPT outperforms comparable-scale LLMs and competes with larger proprietary models. Moreover, it leads in TCM visual understanding among existing multimodal LLMs and demonstrates unified perception across modalities like sound, pulse, smell, and vision, paving the way toward holistic multimodal perception and diagnosis in TCM. Datasets, models, and code are publicly available. We hope this work will inspire further exploration in this field.

