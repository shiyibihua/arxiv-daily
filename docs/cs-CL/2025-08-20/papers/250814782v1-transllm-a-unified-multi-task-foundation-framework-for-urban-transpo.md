---
layout: default
title: TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting
---

# TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14782" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14782v1</a>
  <a href="https://arxiv.org/pdf/2508.14782.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14782v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14782v1', 'TransLLM: A Unified Multi-Task Foundation Framework for Urban Transportation via Learnable Prompting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaming Leng, Yunying Bi, Chuan Qin, Bing Yin, Yanyong Zhang, Chao Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/BiYunying/TransLLM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTransLLMä»¥è§£å†³åŸå¸‚äº¤é€šå¤šä»»åŠ¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸå¸‚äº¤é€š` `å¤šä»»åŠ¡å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—¶ç©ºå»ºæ¨¡` `å¼ºåŒ–å­¦ä¹ ` `æç¤ºæœºåˆ¶` `ç”µåŠ¨è½¦å……ç”µé¢„æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŸå¸‚äº¤é€šå¤šä»»åŠ¡ä¸­å­˜åœ¨ä»»åŠ¡ç‰¹å®šå’Œæ•°æ®éœ€æ±‚é«˜çš„å±€é™æ€§ï¼Œå½±å“äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. TransLLMé€šè¿‡å¯å­¦ä¹ çš„æç¤ºç»„åˆï¼Œå°†æ—¶ç©ºå»ºæ¨¡ä¸å¤§å‹è¯­è¨€æ¨¡å‹æ•´åˆï¼Œæä¾›äº†ä¸€ç§ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆã€‚
3. åœ¨ä¸ƒä¸ªæ•°æ®é›†å’Œä¸‰ä¸ªä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒTransLLMåœ¨å›å½’å’Œè§„åˆ’é—®é¢˜ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå…·æœ‰å¼ºå¤§çš„è·¨ä»»åŠ¡é€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸå¸‚äº¤é€šç³»ç»Ÿé¢ä¸´å¤šç§æŒ‘æˆ˜ï¼Œå¦‚äº¤é€šé¢„æµ‹ã€ç”µåŠ¨è½¦å……ç”µéœ€æ±‚é¢„æµ‹å’Œå‡ºç§Ÿè½¦è°ƒåº¦ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦å±€é™ï¼šå°è§„æ¨¡æ·±åº¦å­¦ä¹ æ¨¡å‹ä»»åŠ¡ç‰¹å®šä¸”æ•°æ®éœ€æ±‚é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨å¤šåœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ï¼›è€Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ç»“æ„åŒ–æ—¶ç©ºæ•°æ®å’Œæ•°å€¼æ¨ç†æ—¶è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†TransLLMï¼Œä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€æ¡†æ¶ï¼Œé€šè¿‡å¯å­¦ä¹ çš„æç¤ºç»„åˆå°†æ—¶ç©ºå»ºæ¨¡ä¸å¤§å‹è¯­è¨€æ¨¡å‹æ•´åˆã€‚è¯¥æ–¹æ³•é‡‡ç”¨è½»é‡çº§çš„æ—¶ç©ºç¼–ç å™¨ï¼Œé€šè¿‡æ‰©å¼ å·ç§¯å’ŒåŒé‚»æ¥å›¾æ³¨æ„åŠ›ç½‘ç»œæ•æ‰å¤æ‚ä¾èµ–å…³ç³»ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–åµŒå…¥ä¸LLMæ— ç¼å¯¹æ¥ã€‚æ–°é¢–çš„å®ä¾‹çº§æç¤ºè·¯ç”±æœºåˆ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ŒåŸºäºè¾“å…¥ç‰¹å¾åŠ¨æ€ä¸ªæ€§åŒ–æç¤ºï¼Œè¶…è¶Šäº†å›ºå®šçš„ä»»åŠ¡ç‰¹å®šæ¨¡æ¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTransLLMåœ¨ä¸ƒä¸ªæ•°æ®é›†å’Œä¸‰ä¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç°äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œè·¨ä»»åŠ¡é€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸå¸‚äº¤é€šç³»ç»Ÿä¸­å¤šä»»åŠ¡çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å› ä»»åŠ¡ç‰¹å®šå’Œæ•°æ®éœ€æ±‚é«˜è€Œé™åˆ¶äº†æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTransLLMé€šè¿‡å¯å­¦ä¹ çš„æç¤ºç»„åˆï¼Œå°†æ—¶ç©ºå»ºæ¨¡ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç»“åˆï¼Œæ—¨åœ¨æå‡æ¨¡å‹åœ¨å¤šä»»åŠ¡åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬è½»é‡çº§çš„æ—¶ç©ºç¼–ç å™¨ã€ç»“æ„åŒ–åµŒå…¥ä¸LLMçš„æ¥å£ï¼Œä»¥åŠé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„åŠ¨æ€æç¤ºè·¯ç”±æœºåˆ¶ï¼Œæ•´ä½“æµç¨‹ä¸ºç¼–ç æ—¶ç©ºæ¨¡å¼ã€åŠ¨æ€ç»„åˆä¸ªæ€§åŒ–æç¤ºã€ç”Ÿæˆä»»åŠ¡ç‰¹å®šé¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå®ä¾‹çº§æç¤ºè·¯ç”±æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€è°ƒæ•´æç¤ºï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å›ºå®šæ¨¡æ¿æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨æ‰©å¼ å·ç§¯å’ŒåŒé‚»æ¥å›¾æ³¨æ„åŠ›ç½‘ç»œæ¥æ•æ‰å¤æ‚çš„æ—¶ç©ºä¾èµ–å…³ç³»ï¼Œè®¾è®¡äº†ä¸“é—¨çš„è¾“å‡ºå±‚ä»¥ç”Ÿæˆä»»åŠ¡ç‰¹å®šçš„é¢„æµ‹ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ä¸ƒä¸ªæ•°æ®é›†å’Œä¸‰ä¸ªä»»åŠ¡çš„å®éªŒä¸­ï¼ŒTransLLMåœ¨å›å½’å’Œè§„åˆ’é—®é¢˜ä¸Šç›¸è¾ƒäºåä¸ªåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œå±•ç°äº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œè·¨ä»»åŠ¡é€‚åº”æ€§ï¼Œå…·ä½“æ€§èƒ½æ•°æ®æœªè¯¦è¿°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TransLLMçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŸå¸‚äº¤é€šç®¡ç†ã€æ™ºèƒ½å‡ºè¡ŒæœåŠ¡å’Œç”µåŠ¨è½¦å……ç”µç½‘ç»œä¼˜åŒ–ç­‰ã€‚å…¶ç»Ÿä¸€æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆæ•´åˆå¤šç§äº¤é€šä»»åŠ¡ï¼Œæé«˜å†³ç­–æ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Urban transportation systems encounter diverse challenges across multiple tasks, such as traffic forecasting, electric vehicle (EV) charging demand prediction, and taxi dispatch. Existing approaches suffer from two key limitations: small-scale deep learning models are task-specific and data-hungry, limiting their generalizability across diverse scenarios, while large language models (LLMs), despite offering flexibility through natural language interfaces, struggle with structured spatiotemporal data and numerical reasoning in transportation domains. To address these limitations, we propose TransLLM, a unified foundation framework that integrates spatiotemporal modeling with large language models through learnable prompt composition. Our approach features a lightweight spatiotemporal encoder that captures complex dependencies via dilated temporal convolutions and dual-adjacency graph attention networks, seamlessly interfacing with LLMs through structured embeddings. A novel instance-level prompt routing mechanism, trained via reinforcement learning, dynamically personalizes prompts based on input characteristics, moving beyond fixed task-specific templates. The framework operates by encoding spatiotemporal patterns into contextual representations, dynamically composing personalized prompts to guide LLM reasoning, and projecting the resulting representations through specialized output layers to generate task-specific predictions. Experiments across seven datasets and three tasks demonstrate the exceptional effectiveness of TransLLM in both supervised and zero-shot settings. Compared to ten baseline models, it delivers competitive performance on both regression and planning problems, showing strong generalization and cross-task adaptability. Our code is available at https://github.com/BiYunying/TransLLM.

