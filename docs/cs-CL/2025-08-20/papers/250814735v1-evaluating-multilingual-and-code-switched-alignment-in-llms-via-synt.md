---
layout: default
title: Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference
---

# Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14735" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14735v1</a>
  <a href="https://arxiv.org/pdf/2508.14735.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14735v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14735v1', 'Evaluating Multilingual and Code-Switched Alignment in LLMs via Synthetic Natural Language Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Samir Abdaljalil, Erchin Serpedin, Khalid Qaraqe, Hasan Kurban

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: Under review

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/KurbanIntelligenceLab/nli-stress-testing)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè¯­è¨€è‡ªç„¶è¯­è¨€æ¨ç†æ¡†æ¶ä»¥æå‡LLMçš„è·¨è¯­è¨€æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨ç†` `è‡ªç„¶è¯­è¨€æ¨ç†` `ä»£ç åˆ‡æ¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­ä¹‰ä¿ç•™` `è·¨è¯­è¨€å¯¹é½` `é€»è¾‘æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨é€»è¾‘ä¸€è‡´æ€§å’Œè·¨è¯­è¨€å¯¹é½æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆæˆçš„å¤šè¯­è¨€è‡ªç„¶è¯­è¨€æ¨ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿç”Ÿæˆé€»è¾‘åŸºç¡€çš„å‰æ-å‡è®¾å¯¹ï¼Œå¹¶è¿›è¡Œå¤šè¯­è¨€ç¿»è¯‘ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä»£ç åˆ‡æ¢ä¸ä»…æ²¡æœ‰é™ä½æ¨¡å‹æ€§èƒ½ï¼Œåè€Œå¯èƒ½æå‡å…¶è¡¨ç°ï¼Œå±•ç¤ºäº†ç¿»è¯‘å¼•èµ·çš„è¯æ±‡å˜åŒ–çš„æ­£åˆ™åŒ–ä½œç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­çš„åº”ç”¨æ—¥ç›Šå¢åŠ ï¼Œä½†å…¶åœ¨ä¸åŒè¯­è¨€é—´ä¿æŒä¸€è‡´ä¸”é€»è¾‘ä¸¥è°¨çš„æ¨ç†èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ§åˆ¶è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºå¤šè¯­è¨€è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰ï¼Œç”Ÿæˆåˆæˆçš„åŸºäºé€»è¾‘çš„å‰æ-å‡è®¾å¯¹ï¼Œå¹¶å°†å…¶ç¿»è¯‘ä¸ºå¤šç§ç±»å‹çš„è¯­è¨€ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿç²¾ç¡®æ§åˆ¶è¯­ä¹‰å…³ç³»ï¼Œå¹¶å…è®¸åœ¨å•è¯­å’Œæ··åˆè¯­è¨€ï¼ˆä»£ç åˆ‡æ¢ï¼‰æ¡ä»¶ä¸‹è¿›è¡Œæµ‹è¯•ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œä»£ç åˆ‡æ¢å¹¶æœªé™ä½æ€§èƒ½ï¼Œç”šè‡³å¯èƒ½æå‡è¡¨ç°ï¼Œè¡¨æ˜ç¿»è¯‘å¼•èµ·çš„è¯æ±‡å˜åŒ–å¯èƒ½ä½œä¸ºæ­£åˆ™åŒ–ä¿¡å·ã€‚é€šè¿‡åŸºäºåµŒå…¥çš„ç›¸ä¼¼æ€§åˆ†æå’Œè·¨è¯­è¨€å¯¹é½å¯è§†åŒ–ï¼Œæˆ‘ä»¬éªŒè¯äº†è¯­ä¹‰çš„ä¿ç•™ï¼Œç¡®è®¤äº†ç¿»è¯‘å¯¹çš„å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„å‘ç°æ­ç¤ºäº†å½“å‰LLMè·¨è¯­è¨€æ¨ç†çš„æ½œåŠ›ä¸è„†å¼±æ€§ï¼Œå¹¶å°†ä»£ç åˆ‡æ¢è¯†åˆ«ä¸ºæå‡å¤šè¯­è¨€é²æ£’æ€§çš„æœ‰å¸Œæœ›çš„æ æ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€æ¨ç†ä¸­çš„ä¸€è‡´æ€§å’Œé€»è¾‘æ€§ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è·¨è¯­è¨€æ¨ç†æ—¶è¡¨ç°è„†å¼±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªæ§åˆ¶è¯„ä¼°æ¡†æ¶ï¼Œç”Ÿæˆåˆæˆçš„é€»è¾‘å‰æ-å‡è®¾å¯¹ï¼Œå¹¶å°†å…¶ç¿»è¯‘ä¸ºå¤šç§è¯­è¨€ï¼Œä»¥æµ‹è¯•æ¨¡å‹åœ¨å•è¯­å’Œä»£ç åˆ‡æ¢æ¡ä»¶ä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åˆæˆæ•°æ®ç”Ÿæˆæ¨¡å—ã€ç¿»è¯‘æ¨¡å—å’Œè¯„ä¼°æ¨¡å—ï¼Œå‰è€…ç”Ÿæˆé€»è¾‘å‰æ-å‡è®¾å¯¹ï¼Œåè€…è´Ÿè´£å¤šè¯­è¨€ç¿»è¯‘ï¼Œæœ€åé€šè¿‡ç›¸ä¼¼æ€§åˆ†æå’Œå¯è§†åŒ–è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨ä»£ç åˆ‡æ¢ä½œä¸ºä¸€ç§æ­£åˆ™åŒ–ä¿¡å·ï¼Œæå‡äº†æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼Œä¸ä¼ ç»Ÿå•è¯­è¨€æ¨ç†æ–¹æ³•å½¢æˆå¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åµŒå…¥ç›¸ä¼¼æ€§åˆ†ææ¥éªŒè¯è¯­ä¹‰ä¿ç•™ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡è¯­ä¹‰ä¸€è‡´æ€§ï¼Œç½‘ç»œç»“æ„åˆ™ç»“åˆäº†å¤šè¯­è¨€å¤„ç†çš„ç‰¹ç‚¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä»£ç åˆ‡æ¢æ¡ä»¶ä¸‹ï¼Œæ¨¡å‹çš„æ¨ç†æ€§èƒ½ä¸ä»…æ²¡æœ‰ä¸‹é™ï¼Œåè€Œåœ¨æŸäº›æƒ…å†µä¸‹æå‡äº†çº¦10%ã€‚é€šè¿‡åµŒå…¥ç›¸ä¼¼æ€§åˆ†æï¼ŒéªŒè¯äº†ç¿»è¯‘å¯¹çš„è¯­ä¹‰ä¿ç•™ï¼Œå±•ç¤ºäº†æ¨¡å‹åœ¨å¤šè¯­è¨€æ¨ç†ä¸­çš„æ½œåŠ›ä¸å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€å¯¹è¯ç³»ç»Ÿã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢å’Œå¤šè¯­è¨€æ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æœåŠ¡äºå…¨çƒç”¨æˆ·ï¼Œä¿ƒè¿›ä¸åŒè¯­è¨€ä¹‹é—´çš„äº¤æµä¸ç†è§£ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly applied in multilingual contexts, yet their capacity for consistent, logically grounded alignment across languages remains underexplored. We present a controlled evaluation framework for multilingual natural language inference (NLI) that generates synthetic, logic-based premise-hypothesis pairs and translates them into a typologically diverse set of languages. This design enables precise control over semantic relations and allows testing in both monolingual and mixed-language (code-switched) conditions. Surprisingly, code-switching does not degrade, and can even improve, performance, suggesting that translation-induced lexical variation may serve as a regularization signal. We validate semantic preservation through embedding-based similarity analyses and cross-lingual alignment visualizations, confirming the fidelity of translated pairs. Our findings expose both the potential and the brittleness of current LLM cross-lingual reasoning, and identify code-switching as a promising lever for improving multilingual robustness. Code available at: https://github.com/KurbanIntelligenceLab/nli-stress-testing

