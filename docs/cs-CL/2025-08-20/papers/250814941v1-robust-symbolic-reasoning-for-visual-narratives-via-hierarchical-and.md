---
layout: default
title: Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs
---

# Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14941" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14941v1</a>
  <a href="https://arxiv.org/pdf/2508.14941.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14941v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14941v1', 'Robust Symbolic Reasoning for Visual Narratives via Hierarchical and Semantically Normalized Knowledge Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yi-Chun Chen

**åˆ†ç±»**: cs.MM, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: 12 pages, 4 figures, 2 tables. Extends our earlier framework on hierarchical narrative graphs with a semantic normalization module

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰å½’ä¸€åŒ–æ¡†æ¶ä»¥è§£å†³è§†è§‰å™äº‹ä¸­çš„ç¬¦å·æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰å™äº‹` `çŸ¥è¯†å›¾è°±` `è¯­ä¹‰å½’ä¸€åŒ–` `å™äº‹æ¨ç†` `å¤šæ¨¡æ€ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¬¦å·å™äº‹å›¾å­˜åœ¨æ ‡æ³¨ä¸ä¸€è‡´å’Œå†—ä½™çš„é—®é¢˜ï¼Œå½±å“æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. æå‡ºäº†ä¸€ç§è¯­ä¹‰å½’ä¸€åŒ–æ¡†æ¶ï¼Œé€šè¿‡è¯æ±‡ç›¸ä¼¼æ€§å’ŒåµŒå…¥èšç±»æ•´åˆç›¸å…³åŠ¨ä½œå’Œäº‹ä»¶ã€‚
3. åœ¨Manga109æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯­ä¹‰å½’ä¸€åŒ–æ˜¾è‘—æé«˜äº†å™äº‹æ¨ç†ä»»åŠ¡çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£è§†è§‰å™äº‹ï¼ˆå¦‚æ¼«ç”»ï¼‰éœ€è¦ç»“æ„åŒ–çš„è¡¨ç¤ºï¼Œæ•æ‰äº‹ä»¶ã€è§’è‰²åŠå…¶å…³ç³»ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç¬¦å·å™äº‹å›¾å¸¸å¸¸é¢ä¸´ä¸ä¸€è‡´æ€§å’Œå†—ä½™æ€§çš„é—®é¢˜ï¼Œé™åˆ¶äº†æ¨ç†å’Œæ³›åŒ–çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–å™äº‹çŸ¥è¯†å›¾çš„è¯­ä¹‰å½’ä¸€åŒ–æ¡†æ¶ï¼ŒåŸºäºè®¤çŸ¥æ¨¡å‹ï¼Œåˆ©ç”¨è¯æ±‡ç›¸ä¼¼æ€§å’ŒåµŒå…¥èšç±»æ–¹æ³•æ•´åˆè¯­ä¹‰ç›¸å…³çš„åŠ¨ä½œå’Œäº‹ä»¶ã€‚å½’ä¸€åŒ–è¿‡ç¨‹å‡å°‘äº†æ ‡æ³¨å™ªå£°ï¼Œåè°ƒäº†å™äº‹å±‚æ¬¡é—´çš„ç¬¦å·ç±»åˆ«ï¼ŒåŒæ—¶ä¿æŒäº†è§£é‡Šæ€§ã€‚é€šè¿‡åœ¨Manga109æ•°æ®é›†ä¸Šè¿›è¡Œçš„åˆæ­¥è¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯­ä¹‰å½’ä¸€åŒ–åœ¨åŠ¨ä½œæ£€ç´¢ã€è§’è‰²å®šä½å’Œäº‹ä»¶æ‘˜è¦ç­‰å™äº‹æ¨ç†ä»»åŠ¡ä¸­æé«˜äº†è¿è´¯æ€§å’Œé²æ£’æ€§ï¼Œä¸”ä¿æŒäº†ç¬¦å·é€æ˜æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰å™äº‹ä¸­çš„ç¬¦å·æ¨ç†é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç”±äºæ ‡æ³¨ä¸ä¸€è‡´å’Œå†—ä½™ï¼Œå¯¼è‡´æ¨ç†æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„è¯­ä¹‰å½’ä¸€åŒ–æ¡†æ¶é€šè¿‡æ•´åˆè¯­ä¹‰ç›¸å…³çš„åŠ¨ä½œå’Œäº‹ä»¶ï¼Œå‡å°‘æ ‡æ³¨å™ªå£°ï¼Œæå‡å™äº‹å›¾çš„æœ‰æ•ˆæ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ ‡æ³¨å™ªå£°è¯†åˆ«ã€è¯­ä¹‰å½’ä¸€åŒ–å¤„ç†å’Œå™äº‹å›¾æ„å»ºã€‚é¦–å…ˆè¯†åˆ«å¹¶æ¶ˆé™¤æ ‡æ³¨ä¸­çš„å™ªå£°ï¼Œç„¶åé€šè¿‡èšç±»æ–¹æ³•æ•´åˆç›¸å…³äº‹ä»¶ï¼Œæœ€åæ„å»ºå±‚æ¬¡åŒ–çš„å™äº‹çŸ¥è¯†å›¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥è¯­ä¹‰å½’ä¸€åŒ–çš„æ¦‚å¿µï¼Œé€šè¿‡è¯æ±‡ç›¸ä¼¼æ€§å’ŒåµŒå…¥èšç±»å®ç°å¯¹ç¬¦å·ç±»åˆ«çš„åè°ƒï¼Œæ˜¾è‘—æå‡äº†å™äº‹å›¾çš„è¿è´¯æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†åŸºäºè¯åµŒå…¥çš„èšç±»ç®—æ³•ï¼Œè®¾ç½®äº†åˆé€‚çš„ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¹¶è®¾è®¡äº†æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å½’ä¸€åŒ–è¿‡ç¨‹çš„æ•ˆæœã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç¡®ä¿äº†å½’ä¸€åŒ–åçš„å™äº‹å›¾åœ¨ä¿æŒè§£é‡Šæ€§çš„åŒæ—¶ï¼Œå‡å°‘äº†å†—ä½™ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯­ä¹‰å½’ä¸€åŒ–åœ¨å¤šä¸ªå™äº‹æ¨ç†ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨ä½œæ£€ç´¢ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ€§èƒ½æå‡è¾¾åˆ°äº†20%ã€‚æ­¤å¤–ï¼Œå½’ä¸€åŒ–åçš„å™äº‹å›¾åœ¨è§’è‰²å®šä½å’Œäº‹ä»¶æ‘˜è¦ä»»åŠ¡ä¸­ä¹Ÿæ˜¾è‘—æé«˜äº†è¿è´¯æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¼«ç”»åˆ†æã€æ•…äº‹ç†è§£å’Œå¤šæ¨¡æ€å†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡è§†è§‰å™äº‹çš„ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºæ•™è‚²ã€å¨±ä¹å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå¸¦æ¥å®é™…ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„å™äº‹ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding visual narratives such as comics requires structured representations that capture events, characters, and their relations across multiple levels of story organization. However, symbolic narrative graphs often suffer from inconsistency and redundancy, where similar actions or events are labeled differently across annotations or contexts. Such variance limits the effectiveness of reasoning and generalization.
>   This paper introduces a semantic normalization framework for hierarchical narrative knowledge graphs. Building on cognitively grounded models of narrative comprehension, we propose methods that consolidate semantically related actions and events using lexical similarity and embedding-based clustering. The normalization process reduces annotation noise, aligns symbolic categories across narrative levels, and preserves interpretability.
>   We demonstrate the framework on annotated manga stories from the Manga109 dataset, applying normalization to panel-, event-, and story-level graphs. Preliminary evaluations across narrative reasoning tasks, such as action retrieval, character grounding, and event summarization, show that semantic normalization improves coherence and robustness, while maintaining symbolic transparency. These findings suggest that normalization is a key step toward scalable, cognitively inspired graph models for multimodal narrative understanding.

