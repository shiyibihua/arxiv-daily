---
layout: default
title: From Evidence to Trajectory: Abductive Reasoning Path Synthesis for Training Retrieval-Augmented Generation Agents
---

# From Evidence to Trajectory: Abductive Reasoning Path Synthesis for Training Retrieval-Augmented Generation Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23071v1</a>
  <a href="https://arxiv.org/pdf/2509.23071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23071v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23071v1', 'From Evidence to Trajectory: Abductive Reasoning Path Synthesis for Training Retrieval-Augmented Generation Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Muzhi Li, Jinhu Qi, Yihong Wu, Minghao Zhao, Liheng Ma, Yifan Li, Xinyu Wang, Yingxue Zhang, Ho-fung Leung, Irwin King

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEviPathï¼Œé€šè¿‡è¯æ®å¢å¼ºçš„æ¨ç†è·¯å¾„åˆæˆï¼Œæå‡RAG Agentçš„è®­ç»ƒæ•ˆæœã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `RAG Agent` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `æ¨ç†è·¯å¾„åˆæˆ` `æ¼”ç»æ¨ç†` `å¯¹è¯å¼å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰RAG Agentè®­ç»ƒç¼ºä¹è¿‡ç¨‹çº§ç›‘ç£ï¼Œå¯¼è‡´ä»»åŠ¡åˆ†è§£å’Œå†³ç­–èƒ½åŠ›ä¸è¶³ï¼Œå¼ºåŒ–å­¦ä¹ æ–¹æ³•é¢ä¸´å¥–åŠ±ç¨€ç–é—®é¢˜ã€‚
2. EviPathé€šè¿‡æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’ã€å¿ å®å­é—®é¢˜å›ç­”å’Œå¯¹è¯å¼å¾®è°ƒï¼Œåˆæˆé«˜è´¨é‡çš„Agent-ç¯å¢ƒäº¤äº’è½¨è¿¹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨EviPathè®­ç»ƒçš„80äº¿å‚æ•°æ¨¡å‹åœ¨å¼€æ”¾åŸŸé—®ç­”ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒEMå€¼æå‡14.7%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰Agentçš„å¼€å‘å—åˆ°ç¼ºä¹è¿‡ç¨‹çº§ç›‘ç£çš„é˜»ç¢ï¼Œéš¾ä»¥æœ‰æ•ˆæŒ‡å¯¼Agentçš„ä»»åŠ¡åˆ†è§£ã€æ£€ç´¢å™¨è°ƒç”¨å’Œé€æ­¥å†³ç­–ç­‰èƒ½åŠ›ã€‚å¼ºåŒ–å­¦ä¹ è™½ç„¶æ˜¯ä¸€ç§æ½œåœ¨çš„è§£å†³æ–¹æ¡ˆï¼Œä½†é¢ä¸´å¥–åŠ±ç¨€ç–å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›æœ‰é™çš„é—®é¢˜ã€‚åŒæ—¶ï¼Œç°æœ‰çš„æ•°æ®åˆæˆæ–¹æ³•ä»…ç”Ÿæˆæ€ç»´é“¾æ¨ç†ï¼Œæ— æ³•æ¨¡æ‹Ÿç¯å¢ƒäº¤äº’ã€‚æœ¬æ–‡æå‡ºäº†EviPathï¼Œä¸€ç§ç”¨äºRAG Agentå¼€å‘çš„è¯æ®é”šå®šæ¨ç†è·¯å¾„åˆæˆèŒƒå¼ã€‚EviPathåŒ…æ‹¬ï¼šï¼ˆiï¼‰æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’ï¼Œå°†é—®é¢˜åˆ†è§£ä¸ºå­é—®é¢˜ï¼Œå¹¶åŸºäºå®ƒä»¬ä¹‹é—´çš„ä¾èµ–å…³ç³»è¿­ä»£åœ°è§„åˆ’æœ€ä¼˜è§£å†³æ–¹æ¡ˆè·¯å¾„ï¼›ï¼ˆiiï¼‰å¿ å®çš„å­é—®é¢˜å›ç­”ï¼Œä½¿ç”¨æ”¯æŒæ€§è¯æ®æ„å»ºä»£ç†ç¯å¢ƒï¼Œä¸ºæ¯ä¸ªå­é—®é¢˜ç”Ÿæˆæ¨ç†æ€è·¯å’Œç­”æ¡ˆï¼›ï¼ˆiiiï¼‰å¯¹è¯å¼å¾®è°ƒï¼Œå°†å®Œæ•´çš„Agent-ç¯å¢ƒäº¤äº’è½¨è¿¹æ ¼å¼åŒ–ä¸ºé€‚åˆç›‘ç£å¾®è°ƒçš„å¯¹è¯æ ¼å¼ã€‚EviPathä½¿LLMèƒ½å¤Ÿç›´æ¥ä»åˆæˆæ•°æ®ä¸­å­¦ä¹ å¤æ‚çš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚åœ¨å¹¿æ³›ä½¿ç”¨çš„é—®ç­”åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨EviPathåˆæˆæ•°æ®è®­ç»ƒçš„80äº¿å‚æ•°æ¨¡å‹ï¼Œæ˜¾è‘—ä¸”æŒç»­åœ°ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼Œåœ¨å¼€æ”¾åŸŸé—®ç­”ä¸­è·å¾—äº†14.7%çš„ç»å¯¹EMå¢ç›Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰RAG Agentçš„è®­ç»ƒé¢ä¸´ç¼ºä¹è¿‡ç¨‹çº§ç›‘ç£çš„é—®é¢˜ï¼Œéš¾ä»¥æœ‰æ•ˆåœ°æŒ‡å¯¼Agentè¿›è¡Œä»»åŠ¡åˆ†è§£ã€æ£€ç´¢å™¨è°ƒç”¨å’Œé€æ­¥å†³ç­–ã€‚å¼ºåŒ–å­¦ä¹ æ–¹æ³•è™½ç„¶å¯ä»¥å°è¯•è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä½†ç”±äºå¥–åŠ±ç¨€ç–ä»¥åŠå¤§è¯­è¨€æ¨¡å‹æœ¬èº«æ¨ç†èƒ½åŠ›çš„é™åˆ¶ï¼Œæ•ˆæœå¹¶ä¸ç†æƒ³ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æ•°æ®åˆæˆæ–¹æ³•é€šå¸¸åªå…³æ³¨ç”Ÿæˆæ€ç»´é“¾å¼çš„æ¨ç†è¿‡ç¨‹ï¼Œè€Œå¿½ç•¥äº†Agentä¸ç¯å¢ƒä¹‹é—´çš„äº¤äº’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEviPathçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆæˆé«˜è´¨é‡çš„Agent-ç¯å¢ƒäº¤äº’è½¨è¿¹æ¥è§£å†³RAG Agentè®­ç»ƒä¸­ç¼ºä¹è¿‡ç¨‹çº§ç›‘ç£çš„é—®é¢˜ã€‚å®ƒé€šè¿‡æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—ç›¸äº’ä¾èµ–çš„å­é—®é¢˜ï¼Œç„¶ååˆ©ç”¨è¯æ®æ„å»ºä»£ç†ç¯å¢ƒæ¥ç”Ÿæˆæ¯ä¸ªå­é—®é¢˜çš„æ¨ç†æ€è·¯å’Œç­”æ¡ˆï¼Œæœ€åå°†æ•´ä¸ªäº¤äº’è¿‡ç¨‹è½¬åŒ–ä¸ºå¯¹è¯å½¢å¼ï¼Œæ–¹ä¾¿è¿›è¡Œç›‘ç£å¾®è°ƒã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯è®©Agentèƒ½å¤Ÿä»åˆæˆæ•°æ®ä¸­å­¦ä¹ åˆ°å¤æ‚çš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEviPathåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š
1. **æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’ï¼ˆAbductive Subtask Planningï¼‰**ï¼šå°†åŸå§‹é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å­é—®é¢˜ï¼Œå¹¶è§„åˆ’å‡ºè§£å†³è¿™äº›å­é—®é¢˜çš„æœ€ä¼˜è·¯å¾„ã€‚è¿™ä¸ªè¿‡ç¨‹è€ƒè™‘åˆ°å­é—®é¢˜ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œç¡®ä¿æœ€ç»ˆèƒ½å¤Ÿå¾—åˆ°å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚
2. **å¿ å®çš„å­é—®é¢˜å›ç­”ï¼ˆFaithful Sub-question Answeringï¼‰**ï¼šåˆ©ç”¨æ£€ç´¢åˆ°çš„è¯æ®æ„å»ºä¸€ä¸ªä»£ç†ç¯å¢ƒï¼Œç„¶ååŸºäºè¿™ä¸ªç¯å¢ƒç”Ÿæˆæ¯ä¸ªå­é—®é¢˜çš„æ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆã€‚è¿™ä¸ªæ¨¡å—çš„ç›®æ ‡æ˜¯ç¡®ä¿ç”Ÿæˆçš„ç­”æ¡ˆæ˜¯åŸºäºå¯é çš„è¯æ®ï¼Œå¹¶ä¸”æ¨ç†è¿‡ç¨‹æ˜¯å¯ä¿¡çš„ã€‚
3. **å¯¹è¯å¼å¾®è°ƒï¼ˆConversational Fine-Tuningï¼‰**ï¼šå°†Agentä¸ç¯å¢ƒçš„å®Œæ•´äº¤äº’è½¨è¿¹è½¬åŒ–ä¸ºå¯¹è¯å½¢å¼ï¼Œç„¶åä½¿ç”¨è¿™äº›æ•°æ®å¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç›‘ç£å¾®è°ƒã€‚è¿™æ ·å¯ä»¥ä½¿æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å¦‚ä½•è¿›è¡Œå¯¹è¯å¼çš„äº¤äº’ï¼Œå¹¶æé«˜å…¶æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šEviPathçš„å…³é”®åˆ›æ–°åœ¨äºå®ƒæå‡ºäº†ä¸€ç§è¯æ®é”šå®šçš„æ¨ç†è·¯å¾„åˆæˆèŒƒå¼ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„Agent-ç¯å¢ƒäº¤äº’è½¨è¿¹ã€‚ä¸ç°æœ‰çš„æ•°æ®åˆæˆæ–¹æ³•ç›¸æ¯”ï¼ŒEviPathä¸ä»…å…³æ³¨æ¨ç†è¿‡ç¨‹ï¼Œè¿˜æ¨¡æ‹Ÿäº†Agentä¸ç¯å¢ƒä¹‹é—´çš„äº¤äº’ï¼Œä»è€Œä½¿Agentèƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ å¦‚ä½•è¿›è¡Œå¤æ‚çš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨ã€‚æ­¤å¤–ï¼ŒEviPathè¿˜é‡‡ç”¨äº†æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’çš„æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯è§£å†³çš„å­é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¼”ç»å¼å­ä»»åŠ¡è§„åˆ’ä¸­ï¼Œéœ€è¦è®¾è®¡åˆé€‚çš„ç®—æ³•æ¥åˆ†è§£é—®é¢˜å¹¶è§„åˆ’æœ€ä¼˜è·¯å¾„ã€‚åœ¨å¿ å®çš„å­é—®é¢˜å›ç­”ä¸­ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„è¯æ®æ£€ç´¢æ–¹æ³•å’Œä»£ç†ç¯å¢ƒæ„å»ºæ–¹æ³•ã€‚åœ¨å¯¹è¯å¼å¾®è°ƒä¸­ï¼Œéœ€è¦è®¾è®¡åˆé€‚çš„å¯¹è¯æ ¼å¼å’ŒæŸå¤±å‡½æ•°ã€‚è®ºæ–‡ä¸­å¯èƒ½åŒ…å«å…³äºè¿™äº›æ–¹é¢çš„å…·ä½“æŠ€æœ¯ç»†èŠ‚ï¼Œä½†æ‘˜è¦ä¸­æœªæ˜ç¡®æåŠã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨EviPathåˆæˆæ•°æ®è®­ç»ƒçš„80äº¿å‚æ•°æ¨¡å‹åœ¨å¼€æ”¾åŸŸé—®ç­”ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸å¯¹äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œè·å¾—äº†14.7%çš„ç»å¯¹EMå¢ç›Šã€‚è¿™ä¸€ç»“æœè¡¨æ˜EviPathæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡RAG Agentçš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œå¹¶ä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EviPathæ–¹æ³•å¯ä»¥å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦RAG Agentçš„åœºæ™¯ï¼Œä¾‹å¦‚å¼€æ”¾åŸŸé—®ç­”ã€çŸ¥è¯†å›¾è°±æ¨ç†ã€æ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡åˆæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œå¯ä»¥æ˜¾è‘—æå‡Agentçš„æ¨ç†å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œä»è€Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å’Œå¯é æ€§ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæ¨åŠ¨RAG AgentæŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºæ„å»ºæ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„AIç³»ç»Ÿæä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-augmented generation agents development is hindered by the lack of process-level supervision to effectively guide agentic capabilities like task decomposition, retriever invocation, and stepwise decision-making. While reinforcement learning offers a potential solution, it suffers from sparse rewards and the limited reasoning capabilities of large language models (LLMs). Meanwhile, existing data synthesis methods only produce chain-of-thought rationales and fail to model environmental interactions. In this paper, we propose EviPath, an evidence-anchored reasoning path synthesis paradigm for RAG agent development. EviPath comprises: (i) Abductive Subtask Planning, which decomposes the problem into sub-questions and iteratively plans an optimal solution path based on the dependencies between them; (ii) Faithful Sub-question Answering, which uses supporting evidence to construct a proxy environment to generate reasoning thoughts and answers for each sub-question; and (iii) Conversational Fine-Tuning, which formats the complete agent-environment interaction trajectory into a dialogue format suitable for Supervised Fine-Tuning. EviPath allows LLMs to learn complex reasoning and tool-use capabilities directly from synthesized data. Extensive experiments on widely-used question-answering benchmarks show that an 8B parameter model trained with EviPath-synthesized data significantly and consistently outperforms state-of-the-art baselines with a double-digit absolute EM gain of 14.7% in open-domain question answering.

