---
layout: default
title: Modeling the language cortex with form-independent and enriched representations of sentence meaning reveals remarkable semantic abstractness
---

# Modeling the language cortex with form-independent and enriched representations of sentence meaning reveals remarkable semantic abstractness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02354" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02354v1</a>
  <a href="https://arxiv.org/pdf/2510.02354.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02354v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02354v1', 'Modeling the language cortex with form-independent and enriched representations of sentence meaning reveals remarkable semantic abstractness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shreya Saha, Shurui Li, Greta Tuckute, Yuanning Li, Ru-Yuan Zhang, Leila Wehbe, Evelina Fedorenko, Meenakshi Khosla

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å½¢å¼æ— å…³ä¸”ä¸°å¯Œçš„å¥å­è¡¨å¾å»ºæ¨¡è¯­è¨€çš®å±‚ï¼Œæ­ç¤ºæ˜¾è‘—çš„è¯­ä¹‰æŠ½è±¡æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€çš®å±‚` `è¯­ä¹‰è¡¨å¾` `è§†è§‰æ¨¡å‹` `è¯­è¨€æ¨¡å‹` `å¤šé‡é‡Šä¹‰` `ç¥ç»å»ºæ¨¡` `æŠ½è±¡è¯­ä¹‰` `ä¸Šä¸‹æ–‡å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€æ¨¡å‹åœ¨ç†è§£å¥å­å«ä¹‰çš„æŠ½è±¡æ€§æ–¹é¢å­˜åœ¨å±€é™ï¼Œæœªèƒ½å……åˆ†æ•æ‰äººç±»è¯­è¨€çš®å±‚çš„å¤æ‚è¯­ä¹‰è¡¨å¾ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡ç»“åˆè§†è§‰å’Œè¯­è¨€æ¨¡å‹ï¼Œå¹¶å¯¹å¥å­è¿›è¡Œå¤šé‡é‡Šä¹‰å’Œä¸Šä¸‹æ–‡å¢å¼ºï¼Œæ¥æ¢ç©¶è¯­è¨€çš®å±‚ä¸­æŠ½è±¡è¯­ä¹‰è¡¨å¾ã€‚
3. å®éªŒè¡¨æ˜ï¼Œèšåˆè§†è§‰ä¿¡æ¯å’Œå¢å¼ºé‡Šä¹‰èƒ½æ˜¾è‘—æé«˜è¯­è¨€çš®å±‚ååº”çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿè¯­è¨€æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»è¯­è¨€ç³»ç»ŸåŒæ—¶è¡¨å¾è¯­è¨€å½¢å¼å’Œæ„ä¹‰ï¼Œä½†æ„ä¹‰è¡¨å¾çš„æŠ½è±¡æ€§ä»å­˜åœ¨äº‰è®®ã€‚æœ¬æ–‡é€šè¿‡ä½¿ç”¨æ¥è‡ªè§†è§‰å’Œè¯­è¨€æ¨¡å‹çš„è¡¨å¾æ¥å»ºæ¨¡å¯¹å¥å­çš„ç¥ç»ååº”ï¼Œä»è€Œåœ¨è¯­è¨€çš®å±‚ä¸­å¯»æ‰¾æŠ½è±¡çš„æ„ä¹‰è¡¨å¾ã€‚å½“ç”Ÿæˆä¸å¥å­å¯¹åº”çš„å›¾åƒå¹¶æå–è§†è§‰æ¨¡å‹åµŒå…¥æ—¶ï¼Œå‘ç°èšåˆå¤šä¸ªç”Ÿæˆçš„å›¾åƒå¯ä»¥äº§ç”Ÿè¶Šæ¥è¶Šå‡†ç¡®çš„è¯­è¨€çš®å±‚ååº”é¢„æµ‹ï¼Œæœ‰æ—¶ç”šè‡³å¯ä»¥ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸åª²ç¾ã€‚ç±»ä¼¼åœ°ï¼Œä¸ä»»ä½•å•ä¸ªé‡Šä¹‰ç›¸æ¯”ï¼Œå¹³å‡å¤šä¸ªå¥å­é‡Šä¹‰çš„åµŒå…¥å¯ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚ç”¨å¯èƒ½éšå«çš„ä¸Šä¸‹æ–‡ç»†èŠ‚ä¸°å¯Œé‡Šä¹‰ï¼ˆä¾‹å¦‚ï¼Œå°†â€œæˆ‘åƒäº†ä¸€ä¸ªç…é¥¼â€æ‰©å±•åˆ°åŒ…å«â€œæ«ç³–æµ†â€ç­‰ç»†èŠ‚ï¼‰è¿›ä¸€æ­¥æé«˜äº†é¢„æµ‹å‡†ç¡®æ€§ï¼Œç”šè‡³è¶…è¿‡äº†åŸºäºåŸå§‹å¥å­åµŒå…¥çš„é¢„æµ‹ï¼Œè¡¨æ˜è¯­è¨€ç³»ç»Ÿç»´æŠ¤ç€æ¯”è¯­è¨€æ¨¡å‹æ›´ä¸°å¯Œå’Œæ›´å¹¿æ³›çš„è¯­ä¹‰è¡¨å¾ã€‚æ€»ä¹‹ï¼Œè¿™äº›ç»“æœè¯æ˜äº†è¯­è¨€çš®å±‚ä¸­å­˜åœ¨é«˜åº¦æŠ½è±¡çš„ã€å½¢å¼æ— å…³çš„æ„ä¹‰è¡¨å¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¯¥è®ºæ–‡æ—¨åœ¨ç ”ç©¶äººç±»è¯­è¨€çš®å±‚å¦‚ä½•ä»¥æŠ½è±¡çš„æ–¹å¼è¡¨å¾å¥å­å«ä¹‰ï¼Œå¹¶è¯„ä¼°ç°æœ‰è¯­è¨€æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå……åˆ†æ•æ‰è¿™ç§æŠ½è±¡æ€§ã€‚ç°æœ‰è¯­è¨€æ¨¡å‹åœ¨ç†è§£æ·±å±‚è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•å®Œå…¨è§£é‡Šè¯­è¨€çš®å±‚çš„ç¥ç»æ´»åŠ¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç»“åˆè§†è§‰ä¿¡æ¯å’Œå¤šé‡é‡Šä¹‰æ¥ä¸°å¯Œå¥å­çš„è¯­ä¹‰è¡¨å¾ï¼Œå¹¶åˆ©ç”¨è¿™äº›ä¸°å¯Œçš„è¡¨å¾æ¥é¢„æµ‹è¯­è¨€çš®å±‚çš„ç¥ç»ååº”ã€‚é€šè¿‡æ¯”è¾ƒä¸åŒè¡¨å¾æ–¹å¼çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œå¯ä»¥æ¨æ–­è¯­è¨€çš®å±‚ä¸­è¯­ä¹‰è¡¨å¾çš„æŠ½è±¡ç¨‹åº¦å’Œä¸°å¯Œç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) å¥å­è¡¨å¾ç”Ÿæˆï¼šä½¿ç”¨è§†è§‰æ¨¡å‹ï¼ˆåŸºäºç”Ÿæˆçš„å›¾åƒï¼‰å’Œè¯­è¨€æ¨¡å‹ï¼ˆåŸºäºå¤šé‡é‡Šä¹‰ï¼‰ç”Ÿæˆå¥å­çš„å¤šç§è¡¨å¾ã€‚2) ç¥ç»ååº”å»ºæ¨¡ï¼šä½¿ç”¨ç”Ÿæˆçš„å¥å­è¡¨å¾æ¥é¢„æµ‹è¯­è¨€çš®å±‚çš„ç¥ç»ååº”ã€‚3) é¢„æµ‹å‡†ç¡®æ€§è¯„ä¼°ï¼šæ¯”è¾ƒä¸åŒè¡¨å¾æ–¹å¼çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œä»¥è¯„ä¼°å…¶å¯¹è¯­è¨€çš®å±‚æ´»åŠ¨çš„è§£é‡Šèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºç»“åˆäº†è§†è§‰ä¿¡æ¯å’Œå¤šé‡é‡Šä¹‰æ¥å¢å¼ºå¥å­çš„è¯­ä¹‰è¡¨å¾ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä»…ä¾èµ–è¯­è¨€æ¨¡å‹ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ©ç”¨è§†è§‰ä¿¡æ¯æ•æ‰å¥å­çš„å…·è±¡å«ä¹‰ï¼Œå¹¶åˆ©ç”¨å¤šé‡é‡Šä¹‰æ•æ‰å¥å­çš„ä¸åŒè¡¨è¾¾æ–¹å¼å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å›¾åƒç”Ÿæˆæ¨¡å‹å°†å¥å­è½¬åŒ–ä¸ºè§†è§‰è¡¨å¾ï¼Œå¹¶æå–è§†è§‰æ¨¡å‹çš„åµŒå…¥ã€‚2) å¯¹å¥å­è¿›è¡Œå¤šé‡é‡Šä¹‰ï¼Œå¹¶ä½¿ç”¨è¯­è¨€æ¨¡å‹æå–æ¯ä¸ªé‡Šä¹‰çš„åµŒå…¥ã€‚3) é€šè¿‡å¹³å‡å¤šä¸ªå›¾åƒæˆ–é‡Šä¹‰çš„åµŒå…¥æ¥è·å¾—æ›´é²æ£’çš„å¥å­è¡¨å¾ã€‚4) é€šè¿‡æ·»åŠ ä¸Šä¸‹æ–‡ç»†èŠ‚æ¥å¢å¼ºé‡Šä¹‰ï¼Œä¾‹å¦‚å°†â€œæˆ‘åƒäº†ä¸€ä¸ªç…é¥¼â€æ‰©å±•åˆ°åŒ…å«â€œæ«ç³–æµ†â€ç­‰ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡èšåˆå¤šä¸ªç”Ÿæˆçš„å›¾åƒï¼Œè§†è§‰æ¨¡å‹å¯ä»¥äº§ç”Ÿä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸åª²ç¾çš„è¯­è¨€çš®å±‚ååº”é¢„æµ‹ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¹³å‡å¤šä¸ªå¥å­é‡Šä¹‰çš„åµŒå…¥ï¼Œå¯ä»¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œç”¨ä¸Šä¸‹æ–‡ç»†èŠ‚ä¸°å¯Œé‡Šä¹‰å¯ä»¥è¿›ä¸€æ­¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œç”šè‡³è¶…è¿‡åŸºäºåŸå§‹å¥å­åµŒå…¥çš„é¢„æµ‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œä¾‹å¦‚æ”¹è¿›æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦å’Œé—®ç­”ç³»ç»Ÿã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£äººç±»è¯­è¨€çš®å±‚çš„è¿ä½œæœºåˆ¶ï¼Œå¯ä»¥å¼€å‘å‡ºæ›´æ™ºèƒ½ã€æ›´äººæ€§åŒ–çš„AIç³»ç»Ÿï¼Œå¹¶ä¸ºè„‘æœºæ¥å£ç­‰æŠ€æœ¯æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The human language system represents both linguistic forms and meanings, but the abstractness of the meaning representations remains debated. Here, we searched for abstract representations of meaning in the language cortex by modeling neural responses to sentences using representations from vision and language models. When we generate images corresponding to sentences and extract vision model embeddings, we find that aggregating across multiple generated images yields increasingly accurate predictions of language cortex responses, sometimes rivaling large language models. Similarly, averaging embeddings across multiple paraphrases of a sentence improves prediction accuracy compared to any single paraphrase. Enriching paraphrases with contextual details that may be implicit (e.g., augmenting "I had a pancake" to include details like "maple syrup") further increases prediction accuracy, even surpassing predictions based on the embedding of the original sentence, suggesting that the language system maintains richer and broader semantic representations than language models. Together, these results demonstrate the existence of highly abstract, form-independent meaning representations within the language cortex.

