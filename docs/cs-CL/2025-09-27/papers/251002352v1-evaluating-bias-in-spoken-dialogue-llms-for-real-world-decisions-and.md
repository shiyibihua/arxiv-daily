---
layout: default
title: Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations
---

# Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02352" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02352v1</a>
  <a href="https://arxiv.org/pdf/2510.02352.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02352v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02352v1', 'Evaluating Bias in Spoken Dialogue LLMs for Real-World Decisions and Recommendations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yihao Wu, Tianrui Wang, Yizhou Peng, Yi-Wen Chao, Xuyi Zhuang, Xinsheng Wang, Shunshun Yin, Ziyang Ma

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿè¯„ä¼°è¯­éŸ³å¯¹è¯å¤§æ¨¡å‹åœ¨å†³ç­–å’Œæ¨èä¸­çš„åè§ï¼Œæ­ç¤ºå¤šè½®å¯¹è¯ä¸‹çš„åè§æ”¾å¤§æ•ˆåº”ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³å¯¹è¯æ¨¡å‹` `åè§è¯„ä¼°` `å…¬å¹³æ€§` `å¤šè½®å¯¹è¯` `å‰¯è¯­è¨€ç‰¹å¾` `å†³ç­–æ¨è` `ç¾¤ä½“ä¸å…¬å¹³æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶è¾ƒå°‘å…³æ³¨è¯­éŸ³å¯¹è¯æ¨¡å‹ä¸­å­˜åœ¨çš„åè§ï¼Œç‰¹åˆ«æ˜¯å‰¯è¯­è¨€ç‰¹å¾ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ã€å£éŸ³ï¼‰å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚
2. è¯¥ç ”ç©¶ç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†è¯­éŸ³LLMä¸­çš„åè§ï¼Œå¹¶ç ”ç©¶äº†å¤šè½®å¯¹è¯ä¸­é‡å¤è´Ÿåé¦ˆå¯¹åè§çš„å½±å“ï¼Œç€é‡å…³æ³¨å†³ç­–å’Œæ¨èä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé—­æºæ¨¡å‹åè§è¾ƒä½ï¼Œå¼€æºæ¨¡å‹å¯¹å¹´é¾„å’Œæ€§åˆ«æ›´æ•æ„Ÿï¼Œæ¨èä»»åŠ¡æ˜“æ”¾å¤§ç¾¤ä½“å·®å¼‚ï¼Œä¸”åè§å†³ç­–å¯èƒ½åœ¨å¤šè½®å¯¹è¯ä¸­æŒç»­å­˜åœ¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„åè§ï¼Œé‡ç‚¹å…³æ³¨éŸ³é¢‘è¾“å…¥å’Œè¾“å‡ºçš„å£è¯­å¯¹è¯æ¨¡å‹ï¼ˆSDMï¼‰ã€‚ç ”ç©¶è€ƒå¯Ÿäº†å¹´é¾„ã€æ€§åˆ«å’Œå£éŸ³ç­‰å‰¯è¯­è¨€ç‰¹å¾å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œä»¥åŠå¤šè½®å¯¹è¯ä¸­é‡å¤è´Ÿåé¦ˆå¦‚ä½•åŠ å‰§åè§ï¼Œä»è€Œå½±å“å†³ç­–å’Œæ¨èä»»åŠ¡çš„å…¬å¹³æ€§ã€‚è®ºæ–‡ä½¿ç”¨ç¾¤ä½“ä¸å…¬å¹³åˆ†æ•°ï¼ˆGUSï¼‰å’ŒåŸºäºç›¸ä¼¼æ€§çš„å½’ä¸€åŒ–ç»Ÿè®¡ç‡ï¼ˆSNSRï¼‰æ¥è¡¡é‡åè§ï¼Œè¯„ä¼°äº†Qwen2.5-Omniã€GLM-4-Voiceç­‰å¼€æºæ¨¡å‹ä»¥åŠGPT-4o Audioã€Gemini-2.5-Flashç­‰é—­æºAPIã€‚ç»“æœè¡¨æ˜ï¼Œé—­æºæ¨¡å‹é€šå¸¸è¡¨ç°å‡ºè¾ƒä½çš„åè§ï¼Œè€Œå¼€æºæ¨¡å‹å¯¹å¹´é¾„å’Œæ€§åˆ«æ›´æ•æ„Ÿï¼Œæ¨èä»»åŠ¡æ›´å®¹æ˜“æ”¾å¤§ç¾¤ä½“å·®å¼‚ã€‚æ­¤å¤–ï¼Œåè§å†³ç­–å¯èƒ½åœ¨å¤šè½®å¯¹è¯ä¸­æŒç»­å­˜åœ¨ã€‚è¯¥ç ”ç©¶é¦–æ¬¡å¯¹ç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯æ¨¡å‹ä¸­çš„åè§è¿›è¡Œäº†ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œä¸ºæ„å»ºå…¬å¹³å¯é çš„éŸ³é¢‘äº¤äº’ç³»ç»Ÿæä¾›äº†è§è§£ã€‚ä¸ºäº†ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ï¼Œè®ºæ–‡å‘å¸ƒäº†FairDialogueæ•°æ®é›†å’Œè¯„ä¼°ä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åè§ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬é¢†åŸŸï¼Œè€Œå¿½ç•¥äº†è¯­éŸ³å¯¹è¯æ¨¡å‹ï¼ˆSDMï¼‰ä¸­ç”±äºéŸ³é¢‘è¾“å…¥å¸¦æ¥çš„åè§ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¹´é¾„ã€æ€§åˆ«ã€å£éŸ³ç­‰å‰¯è¯­è¨€ç‰¹å¾å¦‚ä½•å½±å“æ¨¡å‹çš„å†³ç­–å’Œæ¨èï¼Œä»¥åŠå¤šè½®å¯¹è¯å¦‚ä½•æ”¾å¤§è¿™äº›åè§ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„ç ”ç©¶ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè¯„ä¼°å’Œç¼“è§£è¿™äº›åè§ï¼Œå¯èƒ½å¯¼è‡´ä¸å…¬å¹³çš„å†³ç­–å’Œæ¨èç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡ç‰¹å®šçš„è¯„ä¼°æŒ‡æ ‡å’Œå®éªŒåœºæ™¯ï¼Œç³»ç»Ÿæ€§åœ°é‡åŒ–è¯­éŸ³å¯¹è¯æ¨¡å‹åœ¨å†³ç­–å’Œæ¨èä»»åŠ¡ä¸­çš„åè§ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ¨¡å‹ï¼ˆå¼€æºå’Œé—­æºï¼‰åœ¨ä¸åŒå‰¯è¯­è¨€ç‰¹å¾ä¸‹çš„è¡¨ç°ï¼Œæ­ç¤ºåè§çš„æ¥æºå’Œå½±å“å› ç´ ã€‚åŒæ—¶ï¼Œç ”ç©¶å¤šè½®å¯¹è¯ä¸­åè§çš„æ¼”å˜ï¼Œåˆ†æé‡å¤è´Ÿåé¦ˆæ˜¯å¦ä¼šåŠ å‰§åè§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é›†æ„å»ºï¼šæ„å»ºåŒ…å«ä¸åŒå¹´é¾„ã€æ€§åˆ«ã€å£éŸ³çš„è¯­éŸ³å¯¹è¯æ•°æ®é›†FairDialogueã€‚2) åè§è¯„ä¼°æŒ‡æ ‡ï¼šé‡‡ç”¨ç¾¤ä½“ä¸å…¬å¹³åˆ†æ•°ï¼ˆGUSï¼‰è¡¡é‡å†³ç­–ä»»åŠ¡ä¸­çš„åè§ï¼Œé‡‡ç”¨åŸºäºç›¸ä¼¼æ€§çš„å½’ä¸€åŒ–ç»Ÿè®¡ç‡ï¼ˆSNSRï¼‰è¡¡é‡æ¨èä»»åŠ¡ä¸­çš„åè§ã€‚3) æ¨¡å‹è¯„ä¼°ï¼šåœ¨FairDialogueæ•°æ®é›†ä¸Šè¯„ä¼°å¼€æºæ¨¡å‹ï¼ˆå¦‚Qwen2.5-Omniã€GLM-4-Voiceï¼‰å’Œé—­æºAPIï¼ˆå¦‚GPT-4o Audioã€Gemini-2.5-Flashï¼‰çš„åè§ã€‚4) å¤šè½®å¯¹è¯åˆ†æï¼šè®¾è®¡å¤šè½®å¯¹è¯åœºæ™¯ï¼Œåˆ†æåè§åœ¨å¯¹è¯è¿‡ç¨‹ä¸­çš„æ¼”å˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºï¼š1) é¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†ç«¯åˆ°ç«¯è¯­éŸ³å¯¹è¯æ¨¡å‹ä¸­çš„åè§ã€‚2) æå‡ºäº†é€‚ç”¨äºè¯­éŸ³å¯¹è¯åœºæ™¯çš„åè§è¯„ä¼°æŒ‡æ ‡ï¼ˆGUSå’ŒSNSRï¼‰ã€‚3) æ­ç¤ºäº†å¤šè½®å¯¹è¯ä¸­åè§çš„æ”¾å¤§æ•ˆåº”ã€‚4) æ„å»ºäº†FairDialogueæ•°æ®é›†ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åè§è¯„ä¼°æŒ‡æ ‡æ–¹é¢ï¼ŒGUSç”¨äºè¡¡é‡ä¸åŒç¾¤ä½“åœ¨å†³ç­–ä»»åŠ¡ä¸­çš„ä¸å…¬å¹³ç¨‹åº¦ï¼ŒSNSRç”¨äºè¡¡é‡æ¨èä»»åŠ¡ä¸­ä¸åŒç¾¤ä½“çš„æ¨èç›¸ä¼¼åº¦å·®å¼‚ã€‚åœ¨å¤šè½®å¯¹è¯è®¾è®¡æ–¹é¢ï¼Œé€šè¿‡å¼•å…¥é‡å¤çš„è´Ÿåé¦ˆï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­ç”¨æˆ·å¯¹æ¨¡å‹æ¨èçš„ä¸æ»¡ï¼Œè§‚å¯Ÿæ¨¡å‹æ˜¯å¦ä¼šå› ä¸ºè´Ÿåé¦ˆè€ŒåŠ å‰§åè§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€è¯„ä¼°çš„è¯­éŸ³å¯¹è¯æ¨¡å‹ï¼Œç ”ç©¶é‡ç‚¹åœ¨äºè¯„ä¼°è€Œéä¿®æ”¹æ¨¡å‹æœ¬èº«ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé—­æºæ¨¡å‹ï¼ˆå¦‚GPT-4o Audioã€Gemini-2.5-Flashï¼‰é€šå¸¸è¡¨ç°å‡ºè¾ƒä½çš„åè§ï¼Œè€Œå¼€æºæ¨¡å‹ï¼ˆå¦‚Qwen2.5-Omniã€GLM-4-Voiceï¼‰å¯¹å¹´é¾„å’Œæ€§åˆ«æ›´æ•æ„Ÿã€‚æ¨èä»»åŠ¡æ›´å®¹æ˜“æ”¾å¤§ç¾¤ä½“å·®å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ï¼Œåœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œå³ä½¿ç»™äºˆé‡å¤çš„è´Ÿåé¦ˆï¼Œæ¨¡å‹ä»ç„¶å¯èƒ½åšæŒå¸¦æœ‰åè§çš„å†³ç­–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´å…¬å¹³ã€æ›´å¯é çš„è¯­éŸ³åŠ©æ‰‹ã€æ™ºèƒ½å®¢æœå’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€‚é€šè¿‡è¯†åˆ«å’Œç¼“è§£è¯­éŸ³å¯¹è¯æ¨¡å‹ä¸­çš„åè§ï¼Œå¯ä»¥é¿å…æ­§è§†æ€§å†³ç­–å’Œæ¨èï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å…¬å¹³åº”ç”¨ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•åˆ©ç”¨è¯¥ç ”ç©¶çš„å‘ç°æ¥è®¾è®¡æ›´æœ‰æ•ˆçš„åè§ç¼“è§£ç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While biases in large language models (LLMs), such as stereotypes and cultural tendencies in outputs, have been examined and identified, their presence and characteristics in spoken dialogue models (SDMs) with audio input and output remain largely unexplored. Paralinguistic features, such as age, gender, and accent, can affect model outputs; when compounded by multi-turn conversations, these effects may exacerbate biases, with potential implications for fairness in decision-making and recommendation tasks. In this paper, we systematically evaluate biases in speech LLMs and study the impact of multi-turn dialogues with repeated negative feedback. Bias is measured using Group Unfairness Score (GUS) for decisions and similarity-based normalized statistics rate (SNSR) for recommendations, across both open-source models like Qwen2.5-Omni and GLM-4-Voice, as well as closed-source APIs such as GPT-4o Audio and Gemini-2.5-Flash. Our analysis reveals that closed-source models generally exhibit lower bias, while open-source models are more sensitive to age and gender, and recommendation tasks tend to amplify cross-group disparities. We found that biased decisions may persist in multi-turn conversations. This work provides the first systematic study of biases in end-to-end spoken dialogue models, offering insights towards fair and reliable audio-based interactive systems. To facilitate further research, we release the FairDialogue dataset and evaluation code.

