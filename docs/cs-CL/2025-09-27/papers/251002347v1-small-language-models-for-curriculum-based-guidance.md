---
layout: default
title: Small Language Models for Curriculum-based Guidance
---

# Small Language Models for Curriculum-based Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02347" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02347v1</a>
  <a href="https://arxiv.org/pdf/2510.02347.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02347v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02347v1', 'Small Language Models for Curriculum-based Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Konstantinos Katharakis, Sippo Rossi, Raghava Rao Mukkamala

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å°å‹è¯­è¨€æ¨¡å‹å’Œè¯¾ç¨‹æŒ‡å¯¼ï¼Œæ„å»ºå¯æŒç»­çš„AIæ•™å­¦åŠ©æ‰‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `AIæ•™å­¦åŠ©æ‰‹` `è¯¾ç¨‹æŒ‡å¯¼` `å¯æŒç»­AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨é¢ä¸´é«˜æ˜‚çš„è®¡ç®—æˆæœ¬å’Œå¯¹äº‘åŸºç¡€è®¾æ–½çš„ä¾èµ–ã€‚
2. è®ºæ–‡æå‡ºä½¿ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ç»“åˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œæ„å»ºAIæ•™å­¦åŠ©æ‰‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç»è¿‡é€‚å½“æç¤ºå’Œæ£€ç´¢ä¼˜åŒ–ï¼ŒSLMåœ¨æ•™å­¦æŒ‡å¯¼æ–¹é¢å¯ä»¥åª²ç¾å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸”æ›´å…·å¯æŒç»­æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢ç´¢äº†AIæ•™å­¦åŠ©æ‰‹çš„å¼€å‘ä¸è¯„ä¼°ï¼Œè¯¥åŠ©æ‰‹åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æµç¨‹ï¼Œå¹¶åº”ç”¨äºé€‰å®šçš„å¼€æºå°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ï¼Œä»¥æä¾›åŸºäºè¯¾ç¨‹çš„æŒ‡å¯¼ã€‚æˆ‘ä»¬å¯¹åŒ…æ‹¬LLaMA 3.1ã€IBM Granite 3.3å’ŒGemma 3ï¼ˆ7-17Bå‚æ•°ï¼‰åœ¨å†…çš„å…«ä¸ªSLMè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œå¹¶ä¸GPT-4oè¿›è¡Œäº†æ¯”è¾ƒã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡é€‚å½“çš„æç¤ºå’Œæœ‰é’ˆå¯¹æ€§çš„æ£€ç´¢ï¼ŒSLMåœ¨æä¾›å‡†ç¡®ä¸”ç¬¦åˆæ•™å­¦åŸåˆ™çš„å“åº”æ–¹é¢å¯ä»¥ä¸LLMç›¸åª²ç¾ã€‚é‡è¦çš„æ˜¯ï¼ŒSLMç”±äºå…¶è¾ƒä½çš„è®¡ç®—å’Œèƒ½æºéœ€æ±‚ï¼Œæä¾›äº†æ˜¾è‘—çš„å¯æŒç»­æ€§ä¼˜åŠ¿ï¼Œä»è€Œå¯ä»¥åœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šå®æ—¶ä½¿ç”¨ï¼Œè€Œæ— éœ€ä¾èµ–äº‘åŸºç¡€è®¾æ–½ã€‚è¿™ä¸ä»…ä½¿å…¶å…·æœ‰æˆæœ¬æ•ˆç›Šå’Œéšç§ä¿æŠ¤ï¼Œè€Œä¸”å¯¹ç¯å¢ƒè´Ÿè´£ï¼Œä½¿å…¶æˆä¸ºæ•™è‚²æœºæ„æ—¨åœ¨ä»¥å¯æŒç»­å’ŒèŠ‚èƒ½çš„æ–¹å¼æ‰©å±•ä¸ªæ€§åŒ–å­¦ä¹ çš„å¯è¡ŒAIæ•™å­¦åŠ©æ‰‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•™è‚²é¢†åŸŸåº”ç”¨æ—¶é¢ä¸´çš„è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€ä¾èµ–äº‘åŸºç¡€è®¾æ–½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºé«˜æ˜‚çš„æˆæœ¬ã€éšç§é£é™©ä»¥åŠå¯¹ç¯å¢ƒçš„å½±å“ï¼Œé˜»ç¢äº†ä¸ªæ€§åŒ–å­¦ä¹ çš„æ™®åŠã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰æ›¿ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯å¼¥è¡¥SLMåœ¨çŸ¥è¯†å‚¨å¤‡ä¸Šçš„ä¸è¶³ã€‚é€šè¿‡RAGï¼ŒSLMå¯ä»¥ä»è¯¾ç¨‹ç›¸å…³æ–‡æ¡£ä¸­æ£€ç´¢ä¿¡æ¯ï¼Œä»è€Œæä¾›å‡†ç¡®ä¸”ç¬¦åˆæ•™å­¦åŸåˆ™çš„æŒ‡å¯¼ã€‚è¿™æ ·æ—¢é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œåˆä¿è¯äº†æ•™å­¦è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶æ˜¯ä¸€ä¸ªå…¸å‹çš„RAGæµç¨‹ã€‚é¦–å…ˆï¼Œç”¨æˆ·æå‡ºé—®é¢˜ï¼›ç„¶åï¼Œç³»ç»Ÿä»è¯¾ç¨‹ç›¸å…³æ–‡æ¡£ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼›æ¥ç€ï¼Œå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯ä¸ç”¨æˆ·é—®é¢˜ä¸€èµ·è¾“å…¥åˆ°SLMä¸­ï¼›æœ€åï¼ŒSLMç”Ÿæˆç­”æ¡ˆã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ï¼šæ–‡æ¡£ç´¢å¼•æ¨¡å—ï¼ˆç”¨äºå­˜å‚¨å’Œç´¢å¼•è¯¾ç¨‹æ–‡æ¡£ï¼‰ã€æ£€ç´¢æ¨¡å—ï¼ˆç”¨äºæ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼‰å’Œç”Ÿæˆæ¨¡å—ï¼ˆåŸºäºSLMç”Ÿæˆç­”æ¡ˆï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºè¯æ˜äº†å°å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²åœºæ™¯ä¸‹ï¼Œé€šè¿‡RAGæŠ€æœ¯ï¼Œå¯ä»¥è¾¾åˆ°ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å½“çš„æ€§èƒ½ã€‚è¿™æ‰“ç ´äº†äººä»¬å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­ä¸å¯æ›¿ä»£çš„è®¤çŸ¥ï¼Œä¸ºä½æˆæœ¬ã€å¯æŒç»­çš„AIæ•™è‚²åº”ç”¨æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šé’ˆå¯¹ç‰¹å®šè¯¾ç¨‹çš„æ–‡æ¡£ç´¢å¼•æ„å»ºæ–¹æ³•ã€ä¼˜åŒ–æ£€ç´¢ç­–ç•¥ä»¥æé«˜æ£€ç´¢å‡†ç¡®ç‡ã€ä»¥åŠé’ˆå¯¹SLMçš„æç¤ºå·¥ç¨‹ï¼Œä»¥å¼•å¯¼SLMç”Ÿæˆç¬¦åˆæ•™å­¦åŸåˆ™çš„ç­”æ¡ˆã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æ²¡æœ‰è¯¦ç»†æè¿°ï¼Œéœ€è¦è¿›ä¸€æ­¥æŸ¥é˜…ç›¸å…³æ–‡çŒ®æˆ–ä»£ç ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç»è¿‡é€‚å½“çš„æç¤ºå’Œæœ‰é’ˆå¯¹æ€§çš„æ£€ç´¢ï¼Œå°å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚LLaMA 3.1ã€IBM Granite 3.3å’ŒGemma 3ï¼‰åœ¨æä¾›å‡†ç¡®ä¸”ç¬¦åˆæ•™å­¦åŸåˆ™çš„å“åº”æ–¹é¢å¯ä»¥ä¸GPT-4oç›¸åª²ç¾ã€‚è¿™æ„å‘³ç€åœ¨ç‰¹å®šé¢†åŸŸï¼Œå°å‹æ¨¡å‹å¯ä»¥é€šè¿‡ä¼˜åŒ–ç­–ç•¥è¾¾åˆ°å¤§å‹æ¨¡å‹çš„æ€§èƒ½æ°´å¹³ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å’Œèƒ½æºæ¶ˆè€—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ„å»ºä½æˆæœ¬ã€å¯æŒç»­çš„AIæ•™å­¦åŠ©æ‰‹ï¼Œä¸ºæ•™è‚²æœºæ„æä¾›ä¸ªæ€§åŒ–å­¦ä¹ è§£å†³æ–¹æ¡ˆã€‚è¿™äº›åŠ©æ‰‹å¯ä»¥è¾…åŠ©æ•™å¸ˆè¿›è¡Œè¯¾ç¨‹è®²è§£ã€ç­”ç–‘è§£æƒ‘ã€ä½œä¸šæ‰¹æ”¹ç­‰å·¥ä½œï¼Œæé«˜æ•™å­¦æ•ˆç‡å’Œå­¦ç”Ÿå­¦ä¹ æ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯åº”ç”¨äºä¼ä¸šåŸ¹è®­ã€åœ¨çº¿æ•™è‚²ç­‰é¢†åŸŸï¼Œå®ç°å¤§è§„æ¨¡çš„ä¸ªæ€§åŒ–çŸ¥è¯†ä¼ é€’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The adoption of generative AI and large language models (LLMs) in education is still emerging. In this study, we explore the development and evaluation of AI teaching assistants that provide curriculum-based guidance using a retrieval-augmented generation (RAG) pipeline applied to selected open-source small language models (SLMs). We benchmarked eight SLMs, including LLaMA 3.1, IBM Granite 3.3, and Gemma 3 (7-17B parameters), against GPT-4o. Our findings show that with proper prompting and targeted retrieval, SLMs can match LLMs in delivering accurate, pedagogically aligned responses. Importantly, SLMs offer significant sustainability benefits due to their lower computational and energy requirements, enabling real-time use on consumer-grade hardware without depending on cloud infrastructure. This makes them not only cost-effective and privacy-preserving but also environmentally responsible, positioning them as viable AI teaching assistants for educational institutions aiming to scale personalized learning in a sustainable and energy-efficient manner.

