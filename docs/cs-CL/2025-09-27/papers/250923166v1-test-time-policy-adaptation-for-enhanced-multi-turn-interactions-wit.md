---
layout: default
title: Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs
---

# Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23166" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23166v1</a>
  <a href="https://arxiv.org/pdf/2509.23166.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23166v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23166v1', 'Test-Time Policy Adaptation for Enhanced Multi-Turn Interactions with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenxing Wei, Hong Wang, Ying He, Fei Yu, Yao Shu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: 32 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæµ‹è¯•æ—¶ç­–ç•¥è‡ªé€‚åº”(T2PAM)æ¡†æ¶ï¼Œå¢å¼ºLLMå¤šè½®äº¤äº’ä¸­çš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šè½®äº¤äº’` `ç­–ç•¥è‡ªé€‚åº”` `ç”¨æˆ·åé¦ˆ` `åœ¨çº¿å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å¤šè½®äº¤äº’ä¸­æ€§èƒ½ä¸‹é™ï¼Œä¸»å› æ˜¯ç¼ºä¹å¯¹å®æ—¶ç”¨æˆ·åé¦ˆçš„é€‚åº”èƒ½åŠ›ï¼Œæ¨¡å‹è®­ç»ƒæ•°æ®å¤šä¸ºé™æ€å•è½®æ•°æ®ã€‚
2. è®ºæ–‡æå‡ºT2PAMæ¡†æ¶ï¼Œåˆ©ç”¨ç”¨æˆ·åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä¼°è®¡æ½œåœ¨æœ€ä¼˜ç­–ç•¥ï¼Œå¹¶æ›´æ–°å°‘é‡å‚æ•°å¼•å¯¼æ¨¡å‹å‘è¯¥ç­–ç•¥é æ‹¢ã€‚
3. ROSAç®—æ³•æ˜¯T2PAMçš„å…·ä½“å®ç°ï¼Œé€šè¿‡å•æ­¥æ›´æ–°å®ç°ç­–ç•¥è‡ªé€‚åº”ï¼Œé¿å…äº†è¿­ä»£ä¼˜åŒ–ï¼Œå®éªŒè¯æ˜å…¶æœ‰æ•ˆæ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLM)é‡‡ç”¨å¤šè½®äº¤äº’ä½œä¸ºå®Œæˆå¤æ‚ä»»åŠ¡çš„åŸºæœ¬èŒƒä¾‹ã€‚ç„¶è€Œï¼Œç”±äºå®ƒä»¬é€šå¸¸åœ¨é™æ€çš„å•è½®æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå› æ­¤åœ¨æ‰©å±•çš„äº¤äº’ä¸­ï¼Œå®ƒä»¬çš„æ€§èƒ½ç»å¸¸ä¼šä¸‹é™ï¼Œè¿™é˜»ç¢äº†å®ƒä»¬é€‚åº”å®æ—¶ç”¨æˆ·åé¦ˆçš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§æ–°çš„èŒƒä¾‹ï¼šå¤šè½®äº¤äº’çš„æµ‹è¯•æ—¶ç­–ç•¥è‡ªé€‚åº”(T2PAM)ï¼Œå®ƒåˆ©ç”¨æ¥è‡ªæ­£åœ¨è¿›è¡Œçš„äº¤äº’çš„ç”¨æˆ·åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä»¥ä¼°è®¡ä¸ç”¨æˆ·åå¥½å¯¹é½çš„æ½œåœ¨æœ€ä¼˜ç­–ç•¥ï¼Œç„¶åæ›´æ–°ä¸€å°éƒ¨åˆ†å‚æ•°ï¼Œä»¥å¼•å¯¼æ¨¡å‹æœç€è¿™ä¸ªç­–ç•¥å‘å±•ï¼Œæœ€ç»ˆå®ç°é«˜æ•ˆçš„å¯¹è¯å†…è‡ªæˆ‘çº æ­£ã€‚ç„¶åï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§è½»é‡çº§ç®—æ³•ï¼Œå³æœ€ä¼˜å‚è€ƒå•æ­¥è‡ªé€‚åº”(ROSA)ï¼Œå®ƒå®ç°äº†T2PAMã€‚ROSAåœ¨ä¸€ä¸ªé«˜æ•ˆçš„æ›´æ–°æ­¥éª¤ä¸­å°†æ¨¡å‹å‚æ•°å¼•å¯¼åˆ°ç†è®ºä¸Šçš„æœ€ä¼˜ç­–ç•¥ï¼Œé¿å…äº†ä»£ä»·é«˜æ˜‚çš„è¿­ä»£æ¢¯åº¦ä¼˜åŒ–ï¼Œå¹¶æœ€å¤§é™åº¦åœ°å‡å°‘äº†è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬æä¾›äº†ä¸¥æ ¼çš„ç†è®ºåˆ†æï¼Œä¿è¯ROSAçš„ç­–ç•¥éšç€äº¤äº’æ¬¡æ•°çš„å¢åŠ è€Œæ”¶æ•›åˆ°ç”¨æˆ·çš„åå¥½ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒROSAåœ¨ä»»åŠ¡æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œç”±äºæ— æ³•æœ‰æ•ˆåˆ©ç”¨ç”¨æˆ·åé¦ˆè¿›è¡Œå®æ—¶è°ƒæ•´ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰çš„LLMé€šå¸¸åœ¨é™æ€çš„å•è½®æ•°æ®ä¸Šè®­ç»ƒï¼Œç¼ºä¹åœ¨äº¤äº’è¿‡ç¨‹ä¸­æ ¹æ®ç”¨æˆ·åå¥½è¿›è¡Œè‡ªæˆ‘ä¿®æ­£çš„èƒ½åŠ›ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥æµ‹è¯•æ—¶ç­–ç•¥è‡ªé€‚åº”(T2PAM)æ¡†æ¶ï¼Œå°†ç”¨æˆ·åœ¨äº¤äº’è¿‡ç¨‹ä¸­çš„åé¦ˆè§†ä¸ºå¥–åŠ±ä¿¡å·ï¼Œä»¥æ­¤æ¥ä¼°è®¡ä¸€ä¸ªä¸ç”¨æˆ·åå¥½å¯¹é½çš„æ½œåœ¨æœ€ä¼˜ç­–ç•¥ã€‚é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨¡å‹çš„è¡Œä¸ºæ›´ç¬¦åˆç”¨æˆ·çš„æœŸæœ›ï¼Œä»è€Œå®ç°å¯¹è¯è¿‡ç¨‹ä¸­çš„è‡ªæˆ‘çº æ­£ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå°†ç”¨æˆ·åé¦ˆèå…¥åˆ°æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ä¸­ï¼Œä½¿å…¶èƒ½å¤ŸåŠ¨æ€é€‚åº”ç”¨æˆ·çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šT2PAMæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š
1. **ç”¨æˆ·äº¤äº’**ï¼šLLMä¸ç”¨æˆ·è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œå®Œæˆç‰¹å®šä»»åŠ¡ã€‚
2. **åé¦ˆæ”¶é›†**ï¼šæ”¶é›†ç”¨æˆ·å¯¹LLMå›å¤çš„åé¦ˆï¼Œä¾‹å¦‚ç‚¹èµã€ç‚¹è¸©æˆ–æ›´è¯¦ç»†çš„è¯„ä»·ã€‚
3. **æœ€ä¼˜ç­–ç•¥ä¼°è®¡**ï¼šåˆ©ç”¨ç”¨æˆ·åé¦ˆä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œä¼°è®¡ä¸€ä¸ªæ½œåœ¨çš„æœ€ä¼˜ç­–ç•¥ï¼Œè¯¥ç­–ç•¥ä»£è¡¨äº†ç”¨æˆ·æœŸæœ›çš„æ¨¡å‹è¡Œä¸ºã€‚
4. **å‚æ•°æ›´æ–°**ï¼šä½¿ç”¨ROSAç®—æ³•ï¼Œé€šè¿‡å•æ­¥æ›´æ–°è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨¡å‹çš„ç­–ç•¥å‘ä¼°è®¡çš„æœ€ä¼˜ç­–ç•¥é æ‹¢ã€‚
5. **è¿­ä»£ä¼˜åŒ–**ï¼šé‡å¤ä»¥ä¸Šæ­¥éª¤ï¼Œéšç€äº¤äº’æ¬¡æ•°çš„å¢åŠ ï¼Œæ¨¡å‹é€æ¸é€‚åº”ç”¨æˆ·çš„åå¥½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†æµ‹è¯•æ—¶ç­–ç•¥è‡ªé€‚åº”(T2PAM)çš„æ¦‚å¿µï¼Œå¹¶è®¾è®¡äº†é«˜æ•ˆçš„ROSAç®—æ³•æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ä¸åŒï¼ŒT2PAMä¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè€Œæ˜¯åˆ©ç”¨å®æ—¶ç”¨æˆ·åé¦ˆè¿›è¡Œåœ¨çº¿å­¦ä¹ ã€‚ROSAç®—æ³•é¿å…äº†ä»£ä»·é«˜æ˜‚çš„è¿­ä»£æ¢¯åº¦ä¼˜åŒ–ï¼Œé€šè¿‡å•æ­¥æ›´æ–°å®ç°ç­–ç•¥è‡ªé€‚åº”ï¼Œå¤§å¤§æé«˜äº†æ•ˆç‡ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—LLMèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„éœ€æ±‚ï¼Œæé«˜äº¤äº’è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šROSAç®—æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š
1. **æœ€ä¼˜ç­–ç•¥çš„è¡¨ç¤º**ï¼šè®ºæ–‡éœ€è¦å®šä¹‰ä¸€ç§æ–¹å¼æ¥è¡¨ç¤ºæœ€ä¼˜ç­–ç•¥ï¼Œä¾‹å¦‚ä½¿ç”¨æŸç§å½¢å¼çš„ç­–ç•¥æ¢¯åº¦æˆ–è¡Œä¸ºå…‹éš†ã€‚
2. **å¥–åŠ±ä¿¡å·çš„è®¾è®¡**ï¼šå¦‚ä½•å°†ç”¨æˆ·åé¦ˆè½¬åŒ–ä¸ºæœ‰æ•ˆçš„å¥–åŠ±ä¿¡å·æ˜¯å…³é”®ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ç”¨æˆ·è¯„åˆ†æˆ–è‡ªç„¶è¯­è¨€åé¦ˆè¿›è¡Œå¥–åŠ±å»ºæ¨¡ã€‚
3. **å‚æ•°æ›´æ–°ç­–ç•¥**ï¼šROSAç®—æ³•é‡‡ç”¨å•æ­¥æ›´æ–°ï¼Œéœ€è¦ä»”ç»†è®¾è®¡æ›´æ–°çš„æ­¥é•¿å’Œæ–¹å‘ï¼Œä»¥ä¿è¯æ”¶æ•›æ€§å’Œç¨³å®šæ€§ã€‚
4. **æŸå¤±å‡½æ•°**ï¼šè®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œç”¨äºè¡¡é‡å½“å‰ç­–ç•¥ä¸æœ€ä¼˜ç­–ç•¥ä¹‹é—´çš„å·®è·ï¼Œå¹¶æŒ‡å¯¼å‚æ•°æ›´æ–°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒROSAç®—æ³•åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚å…·ä½“æ¥è¯´ï¼ŒROSAåœ¨ä»»åŠ¡æœ‰æ•ˆæ€§å’Œæ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨å¯¹è¯å®Œæˆç‡ä¸Šæå‡äº†XX%ï¼Œåœ¨äº¤äº’è½®æ•°ä¸Šå‡å°‘äº†YY%ã€‚è¿™äº›ç»“æœéªŒè¯äº†T2PAMæ¡†æ¶å’ŒROSAç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºLLMå¤šè½®äº¤äº’èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦äººæœºäº¤äº’çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è™šæ‹ŸåŠ©æ‰‹ã€æ•™è‚²è¾…å¯¼ç­‰ã€‚é€šè¿‡å®æ—¶é€‚åº”ç”¨æˆ·åå¥½ï¼Œæå‡äº¤äº’è´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚ä¸ªæ€§åŒ–æ¨èã€æ™ºèƒ½å†³ç­–æ”¯æŒç­‰ï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´äººæ€§åŒ–çš„äººå·¥æ™ºèƒ½æœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) employ multi-turn interaction as a fundamental paradigm for completing complex tasks. However, their performance often degrades in extended interactions, as they are typically trained on static, single-turn data, which hinders their ability to adapt to real-time user feedback. To address this limitation, we first propose a new paradigm: Test-Time Policy Adaptation for Multi-Turn Interactions (T2PAM), which utilizes user feedback from the ongoing interaction as a reward signal to estimate a latent optimal policy aligned with user preferences, then updates a small subset of parameters to steer the model toward this policy, ultimately enabling efficient in-conversation self-correction. We then introduce Optimum-Referenced One-Step Adaptation (ROSA), a lightweight algorithm that operationalizes T2PAM. ROSA guides the model parameters toward a theoretical optimal policy in a single, efficient update step, avoiding costly iterative gradient-based optimization and minimizing computational overhead. We provide a rigorous theoretical analysis guaranteeing that the policy of ROSA converges to the preference of user as the number of interactions increases. Extensive experiments on challenging benchmark demonstrate that ROSA achieves significant improvements in both task effectiveness and efficiency.

