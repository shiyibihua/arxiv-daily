---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-08-21
---

# cs.CLï¼ˆ2025-08-21ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250815164v1-contextuallvlm-agent-a-holistic-framework-for-multi-turn-visually-gr.html">ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following</a></td>
  <td>æå‡ºCoLVLM-Agentä»¥è§£å†³å¤æ‚å¤šè½®è§†è§‰å¯¹è¯é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15164v1" data-paper-url="./papers/250815164v1-contextuallvlm-agent-a-holistic-framework-for-multi-turn-visually-gr.html" onclick="toggleFavorite(this, '2508.15164v1', 'ContextualLVLM-Agent: A Holistic Framework for Multi-Turn Visually-Grounded Dialogue and Complex Instruction Following')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250815214v2-self-guided-function-calling-in-large-language-models-via-stepwise-e.html">Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall</a></td>
  <td>æå‡ºè‡ªæŒ‡å¯¼å‡½æ•°è°ƒç”¨æ–¹æ³•ä»¥è§£å†³å¤šæ­¥éª¤å·¥å…·ä½¿ç”¨é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15214v2" data-paper-url="./papers/250815214v2-self-guided-function-calling-in-large-language-models-via-stepwise-e.html" onclick="toggleFavorite(this, '2508.15214v2', 'Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250815212v3-spark-query-aware-unstructured-sparsity-with-recoverable-kv-cache-ch.html">SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning</a></td>
  <td>æå‡ºSparKä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡æ¨ç†ä¸­çš„KVç¼“å­˜ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15212v3" data-paper-url="./papers/250815212v3-spark-query-aware-unstructured-sparsity-with-recoverable-kv-cache-ch.html" onclick="toggleFavorite(this, '2508.15212v3', 'SparK: Query-Aware Unstructured Sparsity with Recoverable KV Cache Channel Pruning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250815190v1-semtoken-semantic-aware-tokenization-for-efficient-long-context-lang.html">SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling</a></td>
  <td>æå‡ºSemTokenä»¥è§£å†³é•¿æ–‡æœ¬è¯­è¨€å»ºæ¨¡ä¸­çš„è¯­ä¹‰æ„ŸçŸ¥åˆ†è¯é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15190v1" data-paper-url="./papers/250815190v1-semtoken-semantic-aware-tokenization-for-efficient-long-context-lang.html" onclick="toggleFavorite(this, '2508.15190v1', 'SemToken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250815139v2-identifying-and-answering-questions-with-false-assumptions-an-interp.html">Identifying and Answering Questions with False Assumptions: An Interpretable Approach</a></td>
  <td>æå‡ºä¸€ç§å¯è§£é‡Šçš„æ–¹æ³•ä»¥è¯†åˆ«å’Œå›ç­”å¸¦æœ‰é”™è¯¯å‡è®¾çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15139v2" data-paper-url="./papers/250815139v2-identifying-and-answering-questions-with-false-assumptions-an-interp.html" onclick="toggleFavorite(this, '2508.15139v2', 'Identifying and Answering Questions with False Assumptions: An Interpretable Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250815868v2-carft-boosting-llm-reasoning-via-contrastive-learning-with-annotated.html">CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning</a></td>
  <td>æå‡ºCARFTä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">contrastive learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15868v2" data-paper-url="./papers/250815868v2-carft-boosting-llm-reasoning-via-contrastive-learning-with-annotated.html" onclick="toggleFavorite(this, '2508.15868v2', 'CARFT: Boosting LLM Reasoning via Contrastive Learning with Annotated Chain-of-Thought-based Reinforced Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250815202v1-fin-prm-a-domain-specialized-process-reward-model-for-financial-reas.html">Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models</a></td>
  <td>æå‡ºFin-PRMä»¥è§£å†³é‡‘èé¢†åŸŸæ¨ç†æ¨¡å‹ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15202v1" data-paper-url="./papers/250815202v1-fin-prm-a-domain-specialized-process-reward-model-for-financial-reas.html" onclick="toggleFavorite(this, '2508.15202v1', 'Fin-PRM: A Domain-Specialized Process Reward Model for Financial Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)