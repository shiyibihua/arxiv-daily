---
layout: default
title: Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition
---

# Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04480" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04480v1</a>
  <a href="https://arxiv.org/pdf/2509.04480.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04480v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04480v1', 'Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ryo Takahashi, Naoki Saito, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: 11 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¦»æ•£æç¤ºè°ƒä¼˜ä»¥è§£å†³ä¸ªæ€§åŒ–è§†è§‰æƒ…æ„Ÿè¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰æƒ…æ„Ÿè¯†åˆ«` `ä¸ªæ€§åŒ–è¯†åˆ«` `å¤šæ¨¡æ€å­¦ä¹ ` `æç¤ºè°ƒä¼˜` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸ªæ€§åŒ–è§†è§‰æƒ…æ„Ÿè¯†åˆ«ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå…¶è®­ç»ƒæ•°æ®åå‘äºæ™®éè§‚ç‚¹ï¼Œé™åˆ¶äº†å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¦»æ•£æç¤ºè°ƒä¼˜çš„æ–¹æ³•ï¼Œçµæ„Ÿæ¥æºäºäººç±»çš„æç¤ºå·¥ç¨‹ï¼Œæ—¨åœ¨å°†VERä»»åŠ¡é€‚åº”äºæ¯ä¸ªä¸ªä½“ã€‚
3. é€šè¿‡å®éªŒéªŒè¯ï¼Œæ‰€ææ–¹æ³•åœ¨ä¸ªæ€§åŒ–VERä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæå‡äº†è¯†åˆ«å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰æƒ…æ„Ÿè¯†åˆ«ï¼ˆVERï¼‰å› å…¶åœ¨èˆ†æƒ…åˆ†æå’Œå¹¿å‘Šè®¾è®¡ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨è€Œå¤‡å—å…³æ³¨ã€‚å°†è¿™ä¸€èƒ½åŠ›æ‰©å±•åˆ°ä¸ªä½“å±‚é¢è¿›ä¸€æ­¥æ‹“å®½äº†å…¶æ½œåœ¨åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ä¸ªæ€§åŒ–VERä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå…¶è®­ç»ƒæ•°æ®åå‘äºæ™®éè§‚ç‚¹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å—äººç±»æç¤ºå·¥ç¨‹å¯å‘çš„ç¦»æ•£æç¤ºè°ƒä¼˜æ–¹æ³•ï¼Œä»¥é€‚åº”ä¸ªä½“çš„VERä»»åŠ¡ã€‚è¯¥æ–¹æ³•ä»ç”Ÿæˆçš„æç¤ºä¸­é€‰æ‹©æœ€ä½³çš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨å…¶æ›´æ–°æç¤ºï¼Œä»è€Œå®ç°å‡†ç¡®çš„ä¸ªæ€§åŒ–VERã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸ªæ€§åŒ–è§†è§‰æƒ…æ„Ÿè¯†åˆ«ä¸­çš„æ€§èƒ½ä¸è¶³é—®é¢˜ï¼Œç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ç”±äºè®­ç»ƒæ•°æ®çš„åå‘æ€§ï¼Œéš¾ä»¥é€‚åº”ä¸ªä½“å·®å¼‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„ç¦»æ•£æç¤ºè°ƒä¼˜æ–¹æ³•é€šè¿‡é€‰æ‹©æœ€ä½³çš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºæ¥æ›´æ–°æç¤ºï¼Œä»è€Œä½¿VERä»»åŠ¡æ›´å¥½åœ°é€‚åº”ä¸ªä½“éœ€æ±‚ï¼Œæå‡è¯†åˆ«å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æç¤ºç”Ÿæˆã€æç¤ºé€‰æ‹©å’Œæ¨¡å‹æ›´æ–°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹è¾“å…¥æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åç”Ÿæˆå¤šä¸ªæç¤ºï¼Œæ¥ç€é€‰æ‹©æœ€ä¼˜æç¤ºå¹¶æ›´æ–°æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç¦»æ•£æç¤ºè°ƒä¼˜çš„å¼•å…¥ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„è®­ç»ƒæ–¹å¼ä¸åŒï¼Œèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸ªä½“æƒ…æ„Ÿè¯†åˆ«çš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€‰æ‹©äº†é€‚åˆä¸ªæ€§åŒ–ä»»åŠ¡çš„æŸå¤±å‡½æ•°ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä¸ªä½“é—´çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å®éªŒéªŒè¯äº†è¿™äº›è®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ä¸ªæ€§åŒ–è§†è§‰æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œè¯†åˆ«å‡†ç¡®ç‡æå‡äº†çº¦15%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæ–°çš„æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºæ›´é«˜çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“åˆ†æã€ä¸ªæ€§åŒ–å¹¿å‘Šæ¨èå’Œæƒ…æ„Ÿè®¡ç®—ç­‰ã€‚é€šè¿‡æé«˜è§†è§‰æƒ…æ„Ÿè¯†åˆ«çš„ä¸ªæ€§åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visual Emotion Recognition (VER) is an important research topic due to its wide range of applications, including opinion mining and advertisement design. Extending this capability to recognize emotions at the individual level further broadens its potential applications. Recently, Multimodal Large Language Models (MLLMs) have attracted increasing attention and demonstrated performance comparable to that of conventional VER methods. However, MLLMs are trained on large and diverse datasets containing general opinions, which causes them to favor majority viewpoints and familiar patterns. This tendency limits their performance in a personalized VER, which is crucial for practical and real-world applications, and indicates a key area for improvement. To address this limitation, the proposed method employs discrete prompt tuning inspired by the process of humans' prompt engineering to adapt the VER task to each individual. Our method selects the best natural language representation from the generated prompts and uses it to update the prompt for the realization of accurate personalized VER.

