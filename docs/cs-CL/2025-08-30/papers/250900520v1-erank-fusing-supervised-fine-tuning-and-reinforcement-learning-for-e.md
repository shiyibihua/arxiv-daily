---
layout: default
title: ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking
---

# ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00520" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00520v1</a>
  <a href="https://arxiv.org/pdf/2509.00520.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00520v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00520v1', 'ERank: Fusing Supervised Fine-Tuning and Reinforcement Learning for Effective and Efficient Text Reranking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuzheng Cai, Yanzhao Zhang, Dingkun Long, Mingxin Li, Pengjun Xie, Weiguo Zheng

**åˆ†ç±»**: cs.IR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºERankä»¥è§£å†³æ–‡æœ¬é‡æ’åºä¸­çš„æ•ˆç‡ä¸æ•ˆæœé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬é‡æ’åº` `ç›‘ç£å¾®è°ƒ` `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `ä¿¡æ¯æ£€ç´¢` `æ¨èç³»ç»Ÿ` `æ•ˆç‡æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬é‡æ’åºæ–¹æ³•åœ¨æ•ˆç‡å’Œæ•ˆæœä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œå°¤å…¶æ˜¯åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é‡æ’åºå™¨ã€‚
2. æœ¬æ–‡æå‡ºERankï¼Œé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ç»“åˆç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œæå‡äº†æ¨¡å‹çš„ç›¸å…³æ€§åŒºåˆ†èƒ½åŠ›å’Œæ•ˆç‡ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒERankè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨æ¨ç†å¯†é›†çš„BRIGHTåŸºå‡†ä¸Šï¼Œè¾¾åˆ°äº†40.2çš„nDCG@10ï¼Œè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬é‡æ’åºæ¨¡å‹æ˜¯ç°ä»£ç³»ç»Ÿï¼ˆå¦‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰çš„å…³é”®ç»„æˆéƒ¨åˆ†ï¼Œè´Ÿè´£åœ¨ç”Ÿæˆä¹‹å‰é€‰æ‹©æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚ç„¶è€Œï¼Œå½“å‰åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é‡æ’åºå™¨é¢ä¸´ç€åŸºæœ¬çš„æƒè¡¡ã€‚ä¸€æ–¹é¢ï¼ŒåŸºäºç›‘ç£å¾®è°ƒçš„ç‚¹å¯¹ç‚¹æ–¹æ³•å°†ç›¸å…³æ€§è§†ä¸ºäºŒåˆ†ç±»ä»»åŠ¡ï¼Œç¼ºä¹å¿…è¦çš„è¯„åˆ†åŒºåˆ†èƒ½åŠ›ï¼›å¦ä¸€æ–¹é¢ï¼Œå¤æ‚æ¨ç†è®¾è®¡çš„åˆ—è¡¨å¼æ–¹æ³•è™½ç„¶å¼ºå¤§ï¼Œä½†æ•ˆç‡ä½ä¸‹ï¼Œä¸é€‚åˆä½å»¶è¿Ÿåº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å›°å¢ƒï¼Œæœ¬æ–‡æå‡ºäº†ERankï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„ç‚¹å¯¹ç‚¹é‡æ’åºå™¨ï¼ŒåŸºäºæ¨ç†å¤§è¯­è¨€æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å¤šç§ç›¸å…³æ€§åœºæ™¯ä¸­è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œé¦–å…ˆè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œè®­ç»ƒæ¨¡å‹ç”Ÿæˆç»†ç²’åº¦æ•´æ•°è¯„åˆ†ï¼Œæ˜¾è‘—å¢å¼ºç›¸å…³æ€§åŒºåˆ†èƒ½åŠ›ã€‚éšåï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œæ–°é¢–çš„åˆ—è¡¨å¼å¥–åŠ±è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¯„ä¼°ERankï¼Œç»“æœæ˜¾ç¤ºå…¶ä¼˜è¶Šçš„æ•ˆæœå’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–‡æœ¬é‡æ’åºæ–¹æ³•åœ¨æ•ˆç‡ä¸æ•ˆæœä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚å½“å‰åŸºäºç›‘ç£å¾®è°ƒçš„ç‚¹å¯¹ç‚¹æ–¹æ³•ç¼ºä¹è¶³å¤Ÿçš„è¯„åˆ†åŒºåˆ†èƒ½åŠ›ï¼Œè€Œå¤æ‚æ¨ç†çš„åˆ—è¡¨å¼æ–¹æ³•åˆæ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥åº”ç”¨äºä½å»¶è¿Ÿåœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šERanké€šè¿‡å¼•å…¥ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œé¦–å…ˆè¿›è¡Œç›‘ç£å¾®è°ƒä»¥ç”Ÿæˆç»†ç²’åº¦çš„æ•´æ•°è¯„åˆ†ï¼Œå¢å¼ºç›¸å…³æ€§åŒºåˆ†èƒ½åŠ›ï¼›ç„¶ååˆ©ç”¨å¼ºåŒ–å­¦ä¹ è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹ï¼Œæå‡å…¨å±€æ’åæ„è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šERankçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºç›‘ç£å¾®è°ƒï¼Œæ¨¡å‹ç”Ÿæˆç»†ç²’åº¦è¯„åˆ†ï¼›ç¬¬äºŒé˜¶æ®µä¸ºå¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨åˆ—è¡¨å¼å¥–åŠ±è¿›è¡Œè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šERankçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ç›‘ç£å¾®è°ƒä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è¯„åˆ†åŒºåˆ†å’Œæ•ˆç‡æ–¹é¢çš„æå‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œæ¨¡å‹è¾“å‡ºç»†ç²’åº¦æ•´æ•°è¯„åˆ†ï¼›åœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œè®¾è®¡äº†æ–°é¢–çš„åˆ—è¡¨å¼å¥–åŠ±æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å…¨å±€æ’åæ„è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨BRIGHTåŸºå‡†æµ‹è¯•ä¸­ï¼ŒERank-4Bæ¨¡å‹è¾¾åˆ°äº†38.7çš„nDCG@10ï¼Œè€Œæ›´å¤§çš„32Bå˜ä½“åˆ™è¾¾åˆ°äº†40.2ï¼Œæˆä¸ºå½“å‰çš„æœ€ä½³æ€§èƒ½ã€‚è¿™ä¸€æˆæœæ˜¾è‘—ä¼˜äºç°æœ‰çš„é‡æ’åºæ–¹æ³•ï¼Œå±•ç¤ºäº†ERankåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ERankçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºä¿¡æ¯æ£€ç´¢ã€æ¨èç³»ç»Ÿå’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦å¿«é€Ÿå“åº”çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚åœ¨çº¿æœç´¢å’Œå®æ—¶æ¨èã€‚å…¶é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§å°†ä¸ºç›¸å…³é¢†åŸŸå¸¦æ¥æ˜¾è‘—çš„å®é™…ä»·å€¼ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text reranking models are a crucial component in modern systems like Retrieval-Augmented Generation, tasked with selecting the most relevant documents prior to generation. However, current Large Language Models (LLMs) powered rerankers often face a fundamental trade-off. On one hand, Supervised Fine-Tuning based pointwise methods that frame relevance as a binary classification task lack the necessary scoring discrimination, particularly for those built on reasoning LLMs. On the other hand, approaches designed for complex reasoning often employ powerful yet inefficient listwise formulations, rendering them impractical for low latency applications. To resolve this dilemma, we introduce ERank, a highly effective and efficient pointwise reranker built from a reasoning LLM that excels across diverse relevance scenarios. We propose a novel two-stage training pipeline that begins with Supervised Fine-Tuning (SFT). In this stage, we move beyond binary labels and train the model generatively to output fine grained integer scores, which significantly enhances relevance discrimination. The model is then further refined using Reinforcement Learning (RL) with a novel, listwise derived reward. This technique instills global ranking awareness into the efficient pointwise architecture. We evaluate the ERank reranker on the BRIGHT, FollowIR, TREC DL, and BEIR benchmarks, demonstrating superior effectiveness and robustness compared to existing approaches. On the reasoning-intensive BRIGHT benchmark, our ERank-4B achieves an nDCG@10 of 38.7, while a larger 32B variant reaches a state of the art nDCG@10 of 40.2.

