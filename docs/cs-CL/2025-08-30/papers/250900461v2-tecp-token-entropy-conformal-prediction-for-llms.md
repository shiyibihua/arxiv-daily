---
layout: default
title: TECP: Token-Entropy Conformal Prediction for LLMs
---

# TECP: Token-Entropy Conformal Prediction for LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00461" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00461v2</a>
  <a href="https://arxiv.org/pdf/2509.00461.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00461v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00461v2', 'TECP: Token-Entropy Conformal Prediction for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Beining Xu, Yongming Lu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30 (æ›´æ–°: 2025-09-05)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTECPä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ç¡®å®šæ€§é‡åŒ–` `å¼€æ”¾å¼è¯­è¨€ç”Ÿæˆ` `ä¿å½¢é¢„æµ‹` `ä»¤ç‰Œç†µ` `é»‘ç®±æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªä¸€è‡´æ€§æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é»‘ç®±ç¯å¢ƒä¸‹éš¾ä»¥æœ‰æ•ˆé‡åŒ–ç”Ÿæˆæ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´é¢„æµ‹ç»“æœç¼ºä¹å¯é æ€§ã€‚
2. TECPæ¡†æ¶é€šè¿‡ä»¤ç‰Œçº§ç†µä½œä¸ºä¸ç¡®å®šæ€§åº¦é‡ï¼Œç»“åˆåˆ†è£‚ä¿å½¢é¢„æµ‹ï¼Œæä¾›äº†æ— é€»è¾‘ã€æ— å‚è€ƒçš„è§£å†³æ–¹æ¡ˆã€‚
3. åœ¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒTECPåœ¨è¦†ç›–ç‡å’Œé¢„æµ‹é›†ç´§å‡‘æ€§æ–¹é¢ä¼˜äºä¼ ç»Ÿçš„è‡ªä¸€è‡´æ€§æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰åœ¨å¼€æ”¾å¼è¯­è¨€ç”Ÿæˆä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®ä½†æœªè¢«å……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é»‘ç®±çº¦æŸä¸‹ï¼Œå†…éƒ¨æ¨¡å‹ä¿¡å·æ— æ³•è®¿é—®ã€‚æœ¬æ–‡æå‡ºäº†Token-Entropy Conformal Predictionï¼ˆTECPï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨ä»¤ç‰Œçº§ç†µä½œä¸ºæ— é€»è¾‘ã€æ— å‚è€ƒçš„ä¸ç¡®å®šæ€§åº¦é‡ï¼Œå¹¶å°†å…¶æ•´åˆåˆ°åˆ†è£‚çš„ä¿å½¢é¢„æµ‹ï¼ˆCPï¼‰ç®¡é“ä¸­ï¼Œä»¥æ„å»ºå…·æœ‰æ­£å¼è¦†ç›–ä¿è¯çš„é¢„æµ‹é›†ã€‚ä¸ä¾èµ–è¯­ä¹‰ä¸€è‡´æ€§å¯å‘å¼æˆ–ç™½ç®±ç‰¹å¾çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒTECPç›´æ¥ä»é‡‡æ ·ç”Ÿæˆçš„ä»¤ç‰Œç†µç»“æ„ä¸­ä¼°è®¡è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œå¹¶é€šè¿‡CPåˆ†ä½æ•°æ ¡å‡†ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œä»¥ç¡®ä¿å¯è¯æ˜çš„é”™è¯¯æ§åˆ¶ã€‚åœ¨å…­ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸¤ä¸ªåŸºå‡†ï¼ˆCoQAå’ŒTriviaQAï¼‰ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒTECPå§‹ç»ˆå®ç°å¯é çš„è¦†ç›–å’Œç´§å‡‘çš„é¢„æµ‹é›†ï¼Œè¶…è¶Šäº†å…ˆå‰åŸºäºè‡ªä¸€è‡´æ€§çš„UQæ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºé»‘ç®±LLMç¯å¢ƒä¸­çš„å¯ä¿¡ç”Ÿæˆæä¾›äº†ä¸€ä¸ªæœ‰åŸåˆ™ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¼€æ”¾å¼è¯­è¨€ç”Ÿæˆä¸­çš„ä¸ç¡®å®šæ€§é‡åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨é»‘ç®±çº¦æŸä¸‹æ— æ³•æœ‰æ•ˆåˆ©ç”¨å†…éƒ¨æ¨¡å‹ä¿¡å·ï¼Œå¯¼è‡´ä¸ç¡®å®šæ€§è¯„ä¼°ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTECPé€šè¿‡ä»¤ç‰Œçº§ç†µç›´æ¥ä¼°è®¡è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼Œé¿å…äº†ä¾èµ–è¯­ä¹‰ä¸€è‡´æ€§æˆ–ç™½ç®±ç‰¹å¾çš„å±€é™æ€§ï¼Œå¹¶é€šè¿‡åˆ†è£‚ä¿å½¢é¢„æµ‹æ ¡å‡†ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œç¡®ä¿é”™è¯¯æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTECPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»¤ç‰Œç†µè®¡ç®—æ¨¡å—å’Œåˆ†è£‚ä¿å½¢é¢„æµ‹æ¨¡å—ï¼Œå‰è€…ç”¨äºç”Ÿæˆçš„ä»¤ç‰Œç†µè¯„ä¼°ï¼Œåè€…ç”¨äºæ„å»ºå…·æœ‰è¦†ç›–ä¿è¯çš„é¢„æµ‹é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šTECPçš„ä¸»è¦åˆ›æ–°åœ¨äºåˆ©ç”¨ä»¤ç‰Œçº§ç†µä½œä¸ºæ— é€»è¾‘çš„ã€ä¸ä¾èµ–å‚è€ƒçš„åº¦é‡ï¼Œç›´æ¥ä»ç”Ÿæˆæ ·æœ¬ä¸­æå–ä¸ç¡®å®šæ€§ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡äº†ä¸ç¡®å®šæ€§é‡åŒ–çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨TECPä¸­ï¼Œç†µçš„è®¡ç®—æ–¹å¼å’Œåˆ†ä½æ•°çš„é€‰æ‹©æ˜¯å…³é”®è®¾è®¡ï¼Œç¡®ä¿äº†ä¸ç¡®å®šæ€§é˜ˆå€¼çš„æœ‰æ•ˆæ ¡å‡†ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†å…¶åœ¨ä¸åŒæ¨¡å‹å’Œæ•°æ®é›†ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…­ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„å®éªŒä¸­ï¼ŒTECPåœ¨CoQAå’ŒTriviaQAåŸºå‡†ä¸Šå®ç°äº†è¶…è¿‡90%çš„è¦†ç›–ç‡ï¼Œä¸”é¢„æµ‹é›†çš„ç´§å‡‘æ€§æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„è‡ªä¸€è‡´æ€§æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸ç¡®å®šæ€§é‡åŒ–ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TECPæ¡†æ¶åœ¨å¼€æ”¾å¼è¯­è¨€ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨é—®ç­”ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›å¯é çš„ä¸ç¡®å®šæ€§é‡åŒ–ï¼ŒTECPèƒ½å¤Ÿæå‡ç”Ÿæˆæ¨¡å‹çš„å¯ä¿¡åº¦ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šé»‘ç®±æ¨¡å‹çš„åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Uncertainty quantification (UQ) for open-ended language generation remains a critical yet underexplored challenge, especially under black-box constraints where internal model signals are inaccessible. In this paper, we introduce Token-Entropy Conformal Prediction (TECP), a novel framework that leverages token-level entropy as a logit-free, reference-free uncertainty measure and integrates it into a split conformal prediction (CP) pipeline to construct prediction sets with formal coverage guarantees. Unlike existing approaches that rely on semantic consistency heuristics or white-box features, TECP directly estimates epistemic uncertainty from the token entropy structure of sampled generations and calibrates uncertainty thresholds via CP quantiles to ensure provable error control. Empirical evaluations across six large language models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP consistently achieves reliable coverage and compact prediction sets, outperforming prior self-consistency-based UQ methods. Our method provides a principled and efficient solution for trustworthy generation in black-box LLM settings.

