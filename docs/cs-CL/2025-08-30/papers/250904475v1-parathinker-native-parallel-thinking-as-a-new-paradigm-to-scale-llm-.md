---
layout: default
title: ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute
---

# ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04475" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04475v1</a>
  <a href="https://arxiv.org/pdf/2509.04475.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04475v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04475v1', 'ParaThinker: Native Parallel Thinking as a New Paradigm to Scale LLM Test-time Compute')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Wen, Yifan Su, Feifei Zhang, Yunxin Liu, Yunhao Liu, Ya-Qin Zhang, Yuanchun Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºParaThinkerä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†æ•ˆç‡` `æ€ç»´å¹¶è¡Œæ€§` `è®¡ç®—æ‰©å±•` `æ¨¡å‹ä¼˜åŒ–` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ™ºèƒ½é—®ç­”` `å†³ç­–æ”¯æŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨ç†æ–¹æ³•åœ¨è®¡ç®—æ‰©å±•æ—¶é¢ä¸´æ€§èƒ½ç“¶é¢ˆï¼Œè¿›ä¸€æ­¥è®¡ç®—å¸¦æ¥çš„æå‡å¾®ä¹å…¶å¾®ã€‚
2. è®ºæ–‡æå‡ºçš„ParaThinkeræ¡†æ¶é€šè¿‡åŸç”Ÿæ€ç»´å¹¶è¡Œæ€§è®­ç»ƒLLMï¼Œç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„å¹¶è¿›è¡Œç»¼åˆã€‚
3. åœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒParaThinkeråœ¨1.5Bå’Œ7Bæ¨¡å‹ä¸Šå¹³å‡åˆ†åˆ«æå‡äº†12.3%å’Œ7.5%çš„å‡†ç¡®ç‡ï¼Œä¸”å»¶è¿Ÿå¢åŠ ä»…ä¸º7.1%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•ä¸»è¦ä¾èµ–äºæµ‹è¯•æ—¶è®¡ç®—çš„æ‰©å±•ç­–ç•¥ï¼Œé€šè¿‡ç”Ÿæˆæ›´é•¿çš„æ¨ç†è¿‡ç¨‹æ¥æå‡æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•åœ¨è®¡ç®—å¢åŠ æ—¶é‡åˆ°æ˜¾è‘—ç“¶é¢ˆï¼Œè¿›ä¸€æ­¥çš„è®¡ç®—ä»…å¸¦æ¥è¾¹é™…æ€§èƒ½æå‡ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™ä¸€ä¸Šé™å¹¶éæ¨¡å‹èƒ½åŠ›çš„å›ºæœ‰é™åˆ¶ï¼Œè€Œæ˜¯æ‰©å±•ç­–ç•¥æœ¬èº«çš„ç¼ºé™·ï¼Œç§°ä¹‹ä¸ºâ€œéš§é“è§†é‡â€ï¼Œå³æ¨¡å‹åˆå§‹æ­¥éª¤çš„ä¸å®Œç¾ä½¿å…¶é”å®šåœ¨æ¬¡ä¼˜æ¨ç†è·¯å¾„ä¸Šã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ‰©å±•èŒƒå¼ï¼šåŸç”Ÿæ€ç»´å¹¶è¡Œæ€§ã€‚æˆ‘ä»¬å±•ç¤ºäº†ParaThinkerï¼Œä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ï¼Œè®­ç»ƒLLMå¹¶è¡Œç”Ÿæˆå¤šä¸ªå¤šæ ·åŒ–çš„æ¨ç†è·¯å¾„ï¼Œå¹¶å°†å…¶ç»¼åˆä¸ºæ›´ä¼˜çš„æœ€ç»ˆç­”æ¡ˆã€‚é€šè¿‡åŒæ—¶æ¢ç´¢ä¸åŒçš„æ€è·¯ï¼ŒParaThinkeræœ‰æ•ˆè§„é¿äº†éš§é“è§†é‡é—®é¢˜ï¼Œé‡Šæ”¾äº†æ¨¡å‹æ½œåœ¨çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶çš„è®¡ç®—æ‰©å±•ç­–ç•¥å­˜åœ¨ç“¶é¢ˆï¼Œå¯¼è‡´æ€§èƒ½æå‡æœ‰é™ï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—èµ„æºå¢åŠ æ—¶ã€‚ç°æœ‰æ–¹æ³•å®¹æ˜“é™·å…¥æ¬¡ä¼˜æ¨ç†è·¯å¾„ï¼Œæ— æ³•å……åˆ†å‘æŒ¥æ¨¡å‹çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯å¼•å…¥åŸç”Ÿæ€ç»´å¹¶è¡Œæ€§ï¼Œé€šè¿‡å¹¶è¡Œç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„ï¼Œé¿å…æ¨¡å‹åœ¨æ¨ç†åˆæœŸçš„å±€é™æ€§ï¼Œä»è€Œå®ç°æ›´ä¼˜çš„æ¨ç†ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šParaThinkerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯å¹¶è¡Œç”Ÿæˆæ¨ç†è·¯å¾„çš„æ¨¡å—ï¼Œç„¶åæ˜¯è·¯å¾„ç»¼åˆæ¨¡å—ï¼Œæœ€åæ˜¯è¾“å‡ºæœ€ç»ˆç­”æ¡ˆçš„æ¨¡å—ã€‚è¯¥æ¡†æ¶æ”¯æŒå¤šæ¡æ€è·¯çš„åŒæ—¶æ¢ç´¢ï¼Œæå‡æ¨ç†çš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†æ€ç»´å¹¶è¡Œæ€§è¿™ä¸€æ–°èŒƒå¼ï¼Œä¸ä¼ ç»Ÿçš„é¡ºåºæ¨ç†æ–¹æ³•ç›¸æ¯”ï¼ŒParaThinkerèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®¡ç®—èµ„æºï¼Œé¿å…äº†â€œéš§é“è§†é‡â€ç°è±¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼ŒParaThinkerè®¾ç½®äº†å¤šä¸ªå¹¶è¡Œè·¯å¾„çš„ç”Ÿæˆæœºåˆ¶ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§çš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è·¯å¾„çš„å¤šæ ·æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥æ”¯æŒå¹¶è¡Œè®¡ç®—çš„é«˜æ•ˆæ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒParaThinkeråœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„å‡†ç¡®ç‡æå‡ï¼Œ1.5Bå’Œ7Bæ¨¡å‹åˆ†åˆ«æé«˜äº†12.3%å’Œ7.5%ã€‚åŒæ—¶ï¼Œå¢åŠ çš„å»¶è¿Ÿä»…ä¸º7.1%ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æ¨ç†æ•ˆç‡ï¼ŒParaThinkerèƒ½å¤Ÿå¸®åŠ©æ›´å°çš„æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­è¶…è¶Šæ›´å¤§çš„æ¨¡å‹ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Large Language Models (LLMs) have been driven by test-time compute scaling - a strategy that improves reasoning by generating longer, sequential thought processes. While effective, this approach encounters a significant bottleneck as computation increases, where further computation offers only marginal performance gains. We argue this ceiling is not an inherent limit of the model's capability but a flaw in the scaling strategy itself, a phenomenon we term "Tunnel Vision", where a model's imperfect initial steps lock it into a suboptimal reasoning path. To overcome this, we introduce a new scaling paradigm: native thought parallelism. We present ParaThinker, an end-to-end framework that trains an LLM to generate multiple, diverse reasoning paths in parallel and synthesize them into a superior final answer. By exploring different lines of thoughts simultaneously, ParaThinker effectively sidesteps the Tunnel Vision issue and unlocks the model's latent reasoning potential. Our approach demonstrates that scaling compute in parallel (width) is a more effective and efficient way to superior reasoning than simply scaling sequentially (depth). On challenging reasoning benchmarks, ParaThinker achieves substantial accuracy improvements over sequential LLMs (12.3% for 1.5B and 7.5% for 7B models on average with 8 parallel paths), while adding only negligible latency overhead (7.1%). This enables smaller models to surpass much larger counterparts and establishes parallel thinking as a critical, efficient dimension for scaling future LLMs.

