---
layout: default
title: The Resurgence of GCG Adversarial Attacks on Large Language Models
---

# The Resurgence of GCG Adversarial Attacks on Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00391" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00391v1</a>
  <a href="https://arxiv.org/pdf/2509.00391.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00391v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00391v1', 'The Resurgence of GCG Adversarial Attacks on Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuting Tan, Xuying Li, Zhuo Li, Huizhen Shu, Peikang Hu

**åˆ†ç±»**: cs.CL, cs.AI, cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: 12 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGCGå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å¯¹æŠ—æ”»å‡»è¯„ä¼°æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¢¯åº¦æ–¹æ³•` `æ¨ç†ä»»åŠ¡` `å®‰å…¨æ€§è¯„ä¼°` `æ¨¡æ‹Ÿé€€ç«` `æ¨¡å‹è„†å¼±æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•åœ¨é¢å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ—¶æ•ˆæœä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„æŸå¤±ç©ºé—´ä¸­ã€‚
2. æœ¬æ–‡æå‡ºäº†GCGåŠå…¶å˜ä½“T-GCGï¼Œé€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒè§„æ¨¡çš„LLMsï¼Œæ¢ç´¢å…¶å¯¹æŠ—æ”»å‡»çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç¼–ç ç›¸å…³æç¤ºçš„è„†å¼±æ€§æ˜¾è‘—é«˜äºå®‰å…¨æç¤ºï¼ŒåŒæ—¶T-GCGåœ¨å‰ç¼€è¯„ä¼°ä¸‹è¡¨ç°å‡ºä¸€å®šçš„ç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæ¢¯åº¦çš„å¯¹æŠ—æç¤ºæ–¹æ³•ï¼Œå¦‚è´ªå©ªåæ ‡æ¢¯åº¦ï¼ˆGCGï¼‰ç®—æ³•ï¼Œå·²æˆä¸ºç ´è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ‰æ•ˆæ‰‹æ®µã€‚æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†GCGåŠå…¶å¢å¼ºå˜ä½“T-GCGåœ¨ä¸åŒè§„æ¨¡å¼€æºLLMsä¸Šçš„è¡¨ç°ã€‚é€šè¿‡å¯¹Qwen2.5-0.5Bã€LLaMA-3.2-1Bå’ŒGPT-OSS-20Bçš„æ”»å‡»æ•ˆæœè¿›è¡Œè¯„ä¼°ï¼Œå‘ç°æ”»å‡»æˆåŠŸç‡éšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ è€Œé™ä½ï¼Œå‰ç¼€åŸºå¯å‘å¼æ–¹æ³•é«˜ä¼°äº†æ”»å‡»æ•ˆæœï¼Œè€Œç¼–ç ç›¸å…³æç¤ºæ¯”å®‰å…¨æç¤ºæ›´æ˜“å—æ”»å‡»ã€‚æ­¤å¤–ï¼ŒT-GCGçš„åˆæ­¥ç»“æœæ˜¾ç¤ºï¼Œæ¨¡æ‹Ÿé€€ç«å¯ä»¥å¤šæ ·åŒ–å¯¹æŠ—æœç´¢å¹¶åœ¨å‰ç¼€è¯„ä¼°ä¸‹å®ç°ç«äº‰æ€§æ”»å‡»æˆåŠŸç‡ï¼Œä½†åœ¨è¯­ä¹‰åˆ¤æ–­ä¸‹çš„æ•ˆæœæœ‰é™ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†GCGçš„å¯æ‰©å±•æ€§é™åˆ¶ï¼Œå¹¶æš´éœ²äº†æ¨ç†ä»»åŠ¡ä¸­çš„è¢«å¿½è§†çš„è„†å¼±æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸­çš„è„†å¼±æ€§ï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æ›´å¤æ‚çš„æ¨¡å‹æ—¶æ•ˆæœé€æ¸å‡å¼±ï¼Œå°¤å…¶åœ¨æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºGCGç®—æ³•åŠå…¶å˜ä½“T-GCGï¼Œé€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒè§„æ¨¡çš„å¼€æºLLMsï¼Œæ¢ç´¢å…¶åœ¨å®‰å…¨å’Œæ¨ç†ä»»åŠ¡ä¸­çš„æ”»å‡»æ•ˆæœã€‚è®¾è®¡ä¸Šè€ƒè™‘äº†æ¨¡å‹è§„æ¨¡å¯¹æ”»å‡»æˆåŠŸç‡çš„å½±å“ï¼Œä»¥åŠå‰ç¼€åŸºå¯å‘å¼æ–¹æ³•çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬GCGç®—æ³•çš„å®ç°ã€T-GCGçš„æ¨¡æ‹Ÿé€€ç«å¢å¼ºã€ä»¥åŠå¯¹ä¸åŒæ¨¡å‹ï¼ˆå¦‚Qwen2.5ã€LLaMAã€GPT-OSSï¼‰çš„æ”»å‡»æ•ˆæœè¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ”»å‡»ç­–ç•¥è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯ç¼–ç ç›¸å…³æç¤ºçš„æ”»å‡»æˆåŠŸç‡æ˜¾è‘—é«˜äºå®‰å…¨æç¤ºï¼Œä¸”GCGçš„å¯æ‰©å±•æ€§å—åˆ°æ¨¡å‹è§„æ¨¡çš„é™åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨GCGå’ŒT-GCGä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬å­¦ä¹ ç‡ã€è¿­ä»£æ¬¡æ•°å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯åœ¨T-GCGä¸­å¼•å…¥çš„æ¨¡æ‹Ÿé€€ç«ç­–ç•¥ç”¨äºå¤šæ ·åŒ–å¯¹æŠ—æœç´¢ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œæ”»å‡»æˆåŠŸç‡æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨ç¼–ç ç›¸å…³æç¤ºä¸­ï¼Œæ”»å‡»æˆåŠŸç‡é«˜è¾¾XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚åŒæ—¶ï¼ŒT-GCGåœ¨å‰ç¼€è¯„ä¼°ä¸‹çš„æ”»å‡»æˆåŠŸç‡ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”æå‡äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œä½†åœ¨è¯­ä¹‰åˆ¤æ–­ä¸‹çš„æ•ˆæœä»æœ‰é™ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§è¯„ä¼°ã€å¯¹æŠ—æ ·æœ¬ç”Ÿæˆå’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§æå‡ã€‚é€šè¿‡è¯†åˆ«å’Œåˆ©ç”¨æ¨¡å‹çš„è„†å¼±æ€§ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´å®‰å…¨çš„AIç³»ç»Ÿæä¾›é‡è¦å‚è€ƒï¼Œæœªæ¥å¯èƒ½åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œäººå·¥æ™ºèƒ½çš„å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient (GCG) algorithm, has emerged as a powerful method for jailbreaking large language models (LLMs). In this paper, we present a systematic appraisal of GCG and its annealing-augmented variant, T-GCG, across open-source LLMs of varying scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack effectiveness on both safety-oriented prompts (AdvBench) and reasoning-intensive coding prompts. Our study reveals three key findings: (1) attack success rates (ASR) decrease with model size, reflecting the increasing complexity and non-convexity of larger models' loss landscapes; (2) prefix-based heuristics substantially overestimate attack effectiveness compared to GPT-4o semantic judgments, which provide a stricter and more realistic evaluation; and (3) coding-related prompts are significantly more vulnerable than adversarial safety prompts, suggesting that reasoning itself can be exploited as an attack vector. In addition, preliminary results with T-GCG show that simulated annealing can diversify adversarial search and achieve competitive ASR under prefix evaluation, though its benefits under semantic judgment remain limited. Together, these findings highlight the scalability limits of GCG, expose overlooked vulnerabilities in reasoning tasks, and motivate further development of annealing-inspired strategies for more robust adversarial evaluation.

