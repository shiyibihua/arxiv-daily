---
layout: default
title: Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models
---

# Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00309" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00309v1</a>
  <a href="https://arxiv.org/pdf/2509.00309.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00309v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00309v1', 'Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chen Zheng, Yiyuan Ma, Yuan Yang, Deyi Liu, Jing Liu, Zuquan Song, Yuxin Song, Cheng Ren, Hang Zhu, Xin Liu, Yiyuan Ma, Siyuan Qiao, Xun Zhou, Liang Xiang, Yonghui Wu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹³è¡¡æ¼”å‘˜åˆå§‹åŒ–ä»¥è§£å†³è’¸é¦æ¨¡å‹çš„RLHFè®­ç»ƒä¸ç¨³å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `äººç±»åé¦ˆ` `æ¨¡å‹è’¸é¦` `æ¨ç†èƒ½åŠ›` `è®­ç»ƒç¨³å®šæ€§` `åºåˆ—ç”Ÿæˆ` `æ¨¡å‹åˆå¹¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„RLHFä¸è’¸é¦æ¨¡å‹ç»“åˆçš„è®­ç»ƒæ–¹æ³•å­˜åœ¨åºåˆ—é•¿åº¦å´©æºƒå’Œå¥–åŠ±æ›²çº¿ä¸ç¨³å®šç­‰é—®é¢˜ï¼Œå½±å“æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºçš„å¹³è¡¡æ¼”å‘˜åˆå§‹åŒ–ï¼ˆBAIï¼‰é€šè¿‡ä¸¤é˜¶æ®µåŠ æƒæ¨¡å‹åˆå¹¶ï¼Œè§£å†³äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸ç¨³å®šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBAIæœ‰æ•ˆæ”¹å–„äº†åºåˆ—é•¿åº¦å’Œå¥–åŠ±æ›²çº¿çš„ç¨³å®šæ€§ï¼Œæå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œè®­ç»ƒç¨³å®šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¯¹é½å’Œæ¨ç†èƒ½åŠ›çš„å‘å±•ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä¸»è¦é€šè¿‡æŒ‡ä»¤è°ƒä¼˜å’ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰å¯¹é½èŒƒå¼ï¼Œä»¥åŠåŸºäºè’¸é¦çš„æ¨ç†å¾®è°ƒèŒƒå¼ã€‚å°½ç®¡è¿™ä¸¤ç§æ–¹æ³•å„è‡ªæœ‰æ•ˆï¼Œä½†å°†RLHFåº”ç”¨äºè’¸é¦è®­ç»ƒæ¨¡å‹çš„ç¬¬ä¸‰ç§èŒƒå¼é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†è¿™ä¸€èŒƒå¼ä¸­å‡ºç°çš„ä¸¤ä¸ªå…³é”®ç°è±¡ï¼šåºåˆ—é•¿åº¦å´©æºƒå’Œå¥–åŠ±æ›²çº¿çš„â€œæ›²æ£çƒæ£’â€æ•ˆåº”ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¹³è¡¡æ¼”å‘˜åˆå§‹åŒ–ï¼ˆBAIï¼‰ï¼Œä¸€ç§ä¸¤é˜¶æ®µåŠ æƒæ¨¡å‹åˆå¹¶æ–¹æ³•ã€‚é€šè¿‡å…¨é¢çš„å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†BAIèƒ½å¤Ÿè§£å†³åºåˆ—é•¿åº¦å´©æºƒï¼Œå‡è½»å¥–åŠ±æ›²çº¿çš„æ³¢åŠ¨ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®ç°è¿ç»­çš„åºåˆ—é•¿åº¦æ”¹å–„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å°†RLHFåº”ç”¨äºè’¸é¦è®­ç»ƒæ¨¡å‹æ—¶å‡ºç°çš„åºåˆ—é•¿åº¦å´©æºƒå’Œå¥–åŠ±æ›²çº¿ä¸ç¨³å®šçš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜ä¸¥é‡å½±å“äº†æ¨¡å‹çš„å¯¹é½å’Œæ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å¹³è¡¡æ¼”å‘˜åˆå§‹åŒ–ï¼ˆBAIï¼‰æ–¹æ³•ï¼Œé€šè¿‡ä¸¤é˜¶æ®µçš„åŠ æƒæ¨¡å‹åˆå¹¶ï¼Œé¦–å…ˆåˆå¹¶æŒ‡ä»¤è·Ÿéšæ¨¡å‹å’Œè’¸é¦æ¨ç†å¾®è°ƒæ¨¡å‹ï¼Œç„¶åå°†ä¸­é—´æ¨¡å‹ä¸é¢„è®­ç»ƒæ¨¡å‹è¿›ä¸€æ­¥ç»“åˆï¼Œä»¥ä¿ç•™åŸºç¡€çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBAIçš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯æ¨¡å‹åˆå¹¶ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯ä¸é¢„è®­ç»ƒæ¨¡å‹çš„ç»“åˆã€‚è¯¥æ–¹æ³•é€šè¿‡åŠ æƒåˆå¹¶ç­–ç•¥æ¥å®ç°æ¨¡å‹çš„å¹³è¡¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šBAIçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åŠ æƒåˆå¹¶ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£å†³åºåˆ—é•¿åº¦å´©æºƒå’Œå¥–åŠ±æ›²çº¿ä¸ç¨³å®šçš„é—®é¢˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹å’Œæ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨BAIä¸­ï¼Œåˆå¹¶æ¯”ä¾‹çš„è®¾ç½®æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ï¼Œé€šè¿‡å®éªŒåˆ†æç¡®å®šæœ€ä½³çš„åˆå¹¶æ¯”ä¾‹ï¼Œä»¥å®ç°è®­ç»ƒç¨³å®šæ€§ä¸æ¨ç†èƒ½åŠ›çš„æœ€ä½³å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBAIæ–¹æ³•æœ‰æ•ˆè§£å†³äº†åºåˆ—é•¿åº¦å´©æºƒé—®é¢˜ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­åºåˆ—é•¿åº¦å¹³å‡æå‡äº†20%ã€‚åŒæ—¶ï¼Œå¥–åŠ±æ›²çº¿çš„æ³¢åŠ¨æ€§æ˜¾è‘—é™ä½ï¼Œæ¨¡å‹çš„æ¨ç†èƒ½åŠ›åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æå‡äº†15%ä»¥ä¸Šï¼Œå±•ç°äº†BAIçš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œè®­ç»ƒç¨³å®šæ€§ï¼ŒBAIèƒ½å¤Ÿæ¨åŠ¨æ›´å¤æ‚çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆä»»åŠ¡çš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The development of alignment and reasoning capabilities in large language models has seen remarkable progress through two paradigms: instruction tuning and reinforcement learning from human feedback (RLHF) alignment paradigm, and distillation-based reasoning fine-tuning paradigm. While both approaches prove effective independently, the third paradigm of applying RLHF to distillation-trained models presents significant challenges. Our investigation reveals two critical phenomena that emerge in this paradigm: Sequence Length Collapse, where language generation dramatically reduces during early RLHF training, and the Reward Hockey Stick Curve, featuring severe reward score drops followed by gradual recovery. These instabilities fundamentally compromise the model's alignment and reasoning capabilities. To address these challenges, we propose Balanced Actor Initialization (BAI), a two-stage weighted model merging approach. BAI first merges instruction-following and distillation-based reasoning fine-tuned models, then further combines this intermediate model with the pretrained model to preserve foundational knowledge. Through comprehensive experiments across diverse benchmarks and detailed analysis of training experiments, we demonstrate that BAI resolves Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables continuous sequence length improvement during training. Additionally, our analysis reveals that balanced merging ratios achieve optimal trade-offs between training stability and reasoning capability preservation. Our work provides the effective solution for stable training in this third paradigm, enabling more capable reasoning models that combine distillation efficiency with RLHF alignment.

