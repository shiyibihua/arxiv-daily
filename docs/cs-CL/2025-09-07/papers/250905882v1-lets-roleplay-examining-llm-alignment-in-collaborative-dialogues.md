---
layout: default
title: Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues
---

# Let's Roleplay: Examining LLM Alignment in Collaborative Dialogues

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05882" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05882v1</a>
  <a href="https://arxiv.org/pdf/2509.05882.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05882v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05882v1', 'Let\'s Roleplay: Examining LLM Alignment in Collaborative Dialogues')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abhijnan Nath, Carine Graff, Nikhil Krishnaswamy

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-07

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§’è‰²æ‰®æ¼”çš„LLMå¯¹é½è¯„ä¼°æ¡†æ¶ï¼Œæå‡å¤šæ–¹å¯¹è¯åä½œä¸­çš„å†³ç­–è´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæœºåä½œ` `å¤šæ–¹å¯¹è¯` `å¯¹é½æ–¹æ³•` `è§’è‰²æ‰®æ¼”` `åäº‹å®è¯„ä¼°` `æ‘©æ“¦æ™ºèƒ½ä½“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMå¯¹é½æ–¹æ³•ä¸»è¦é’ˆå¯¹å•ç”¨æˆ·åœºæ™¯ï¼Œå¿½ç•¥äº†å¤šæ–¹äº¤äº’ä¸­é•¿æœŸåŠ¨æ€å˜åŒ–å¸¦æ¥çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºè§’è‰²æ‰®æ¼”çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥â€œæ‘©æ“¦æ™ºèƒ½ä½“â€å¹²é¢„å¯¹è¯ï¼Œä¿ƒä½¿ç¾¤ä½“åæ€å†³ç­–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‘©æ“¦æ„ŸçŸ¥å¯¹é½æ–¹æ³•åœ¨æå‡ç¾¤ä½“å…±è¯†å’Œä»»åŠ¡ç»“æœæ­£ç¡®æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¯¹é½åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èå…¥å„ç§å·¥ä½œæµç¨‹ï¼Œå®ƒä»¬è¶Šæ¥è¶Šå¤šåœ°è¢«è§†ä¸ºäººç±»çš„â€œåˆä½œè€…â€ã€‚ä¸ºäº†ç¡®ä¿è¿™äº›AIåˆä½œè€…çš„å¯é æ€§ï¼Œå¿…é¡»åœ¨éƒ¨ç½²å‰å¯¹å…¶å¤šè½®äº¤äº’è¡Œä¸ºè¿›è¡Œé¢„æµ‹ã€éªŒè¯å’Œç¡®è®¤ã€‚å¸¸è§çš„å¯¹é½æŠ€æœ¯é€šå¸¸åœ¨ç®€åŒ–çš„å•ç”¨æˆ·è®¾ç½®ä¸‹å¼€å‘ï¼Œæ²¡æœ‰è€ƒè™‘åˆ°é•¿æœŸå¤šæ–¹äº¤äº’çš„åŠ¨æ€æ€§ã€‚æœ¬æ–‡ç ”ç©¶äº†ä¸åŒçš„å¯¹é½æ–¹æ³•å¦‚ä½•å½±å“LLMæ™ºèƒ½ä½“åœ¨å¤šè½®ã€å¤šæ–¹åä½œä¸­ä½œä¸ºä¼™ä¼´çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬é€šè¿‡æ‘©æ“¦æ™ºèƒ½ä½“çš„è§†è§’æ¥ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œè¿™äº›æ™ºèƒ½ä½“å¹²é¢„ç¾¤ä½“å¯¹è¯ï¼Œé¼“åŠ±åä½œç¾¤ä½“æ”¾æ…¢é€Ÿåº¦å¹¶åæ€å…¶å†³ç­–æ¨ç†ã€‚ä½¿ç”¨è§’è‰²æ‰®æ¼”æ–¹æ³•ï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸åŒè®­ç»ƒçš„æ‘©æ“¦æ™ºèƒ½ä½“åœ¨åä½œä»»åŠ¡å¯¹è¯ä¸­çš„å¹²é¢„æ•ˆæœã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åäº‹å®è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºé‡åŒ–æ‘©æ“¦å¹²é¢„å¦‚ä½•æ”¹å˜ç¾¤ä½“åä½œå’Œä¿¡å¿µå¯¹é½çš„è½¨è¿¹ã€‚ç»“æœè¡¨æ˜ï¼Œåœ¨å¸®åŠ©è¾¾æˆå…±è¯†ï¼ˆæˆ–å•†å®šçš„ä»»åŠ¡ç›¸å…³å‘½é¢˜ï¼‰å’Œä»»åŠ¡ç»“æœçš„æ­£ç¡®æ€§æ–¹é¢ï¼Œæ‘©æ“¦æ„ŸçŸ¥æ–¹æ³•æ˜æ˜¾ä¼˜äºå¸¸è§çš„å¯¹é½åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹é½æ–¹æ³•ä¸»è¦å…³æ³¨å•ç”¨æˆ·åœºæ™¯ï¼Œç¼ºä¹å¯¹å¤šæ–¹åä½œå¯¹è¯ä¸­é•¿æœŸäº¤äº’åŠ¨æ€æ€§çš„æœ‰æ•ˆå»ºæ¨¡å’Œè¯„ä¼°ã€‚åœ¨å¤šäººåä½œç¯å¢ƒä¸­ï¼ŒLLMéœ€è¦èƒ½å¤Ÿç†è§£å’Œå½±å“ç¾¤ä½“å†³ç­–è¿‡ç¨‹ï¼Œä½†ç°æœ‰æ–¹æ³•éš¾ä»¥ä¿è¯LLMåœ¨å¤æ‚äº¤äº’ä¸­çš„å¯é æ€§å’Œå¯é¢„æµ‹æ€§ã€‚å› æ­¤ï¼Œå¦‚ä½•è¯„ä¼°å’Œæå‡LLMåœ¨å¤šæ–¹åä½œå¯¹è¯ä¸­çš„å¯¹é½æ•ˆæœæ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥â€œæ‘©æ“¦æ™ºèƒ½ä½“â€æ¥å¹²é¢„ç¾¤ä½“å¯¹è¯ï¼Œä¿ƒä½¿å‚ä¸è€…æ”¾æ…¢é€Ÿåº¦å¹¶åæ€å…¶æ¨ç†è¿‡ç¨‹ã€‚è¿™ç§å¹²é¢„æ—¨åœ¨å¸®åŠ©ç¾¤ä½“æˆå‘˜æ›´å¥½åœ°ç†è§£å½¼æ­¤çš„è§‚ç‚¹ï¼Œä»è€Œè¾¾æˆæ›´å‡†ç¡®çš„å…±è¯†å’Œæ›´ä¼˜çš„ä»»åŠ¡ç»“æœã€‚é€šè¿‡è¯„ä¼°ä¸åŒå¯¹é½æ–¹æ³•çš„æ‘©æ“¦æ™ºèƒ½ä½“åœ¨åä½œä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥æ›´å…¨é¢åœ°äº†è§£å…¶åœ¨å¤šæ–¹äº¤äº’ä¸­çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ä¸ªåŸºäºè§’è‰²æ‰®æ¼”çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) åä½œä»»åŠ¡ç¯å¢ƒï¼šæ¨¡æ‹ŸçœŸå®çš„å¤šäººåä½œåœºæ™¯ï¼Œä¾‹å¦‚å†³ç­–åˆ¶å®šæˆ–é—®é¢˜è§£å†³ã€‚2) æ‘©æ“¦æ™ºèƒ½ä½“ï¼šæ‰®æ¼”ç‰¹å®šçš„è§’è‰²ï¼Œé€šè¿‡åœ¨å¯¹è¯ä¸­æ’å…¥é—®é¢˜æˆ–å»ºè®®æ¥å¹²é¢„ç¾¤ä½“è®¨è®ºã€‚3) å¯¹é½æ–¹æ³•ï¼šä½¿ç”¨ä¸åŒçš„å¯¹é½æŠ€æœ¯è®­ç»ƒæ‘©æ“¦æ™ºèƒ½ä½“ï¼Œä¾‹å¦‚æŒ‡ä»¤å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ ã€‚4) åäº‹å®è¯„ä¼°ï¼šé‡åŒ–æ‘©æ“¦å¹²é¢„å¯¹ç¾¤ä½“åä½œè½¨è¿¹å’Œä¿¡å¿µå¯¹é½çš„å½±å“ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆè®©å¤šä¸ªå‚ä¸è€…åœ¨åä½œä»»åŠ¡ç¯å¢ƒä¸­è¿›è¡Œå¯¹è¯ï¼Œç„¶åç”±æ‘©æ“¦æ™ºèƒ½ä½“åœ¨ç‰¹å®šæ—¶åˆ»è¿›è¡Œå¹²é¢„ï¼Œæœ€åé€šè¿‡åäº‹å®è¯„ä¼°æ¥åˆ†æå¹²é¢„çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„åäº‹å®è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºé‡åŒ–æ‘©æ“¦å¹²é¢„å¯¹ç¾¤ä½“åä½œå’Œä¿¡å¿µå¯¹é½çš„å½±å“ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè¯„ä¼°ä¸åŒå¯¹é½æ–¹æ³•åœ¨å¤šæ–¹äº¤äº’ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æ­ç¤ºå…¶åœ¨æå‡ç¾¤ä½“å…±è¯†å’Œä»»åŠ¡ç»“æœæ­£ç¡®æ€§æ–¹é¢çš„æ½œåŠ›ã€‚æ­¤å¤–ï¼Œå¼•å…¥â€œæ‘©æ“¦æ™ºèƒ½ä½“â€çš„æ¦‚å¿µä¹Ÿä¸ºç ”ç©¶LLMåœ¨åä½œç¯å¢ƒä¸­çš„ä½œç”¨æä¾›äº†ä¸€ç§æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®ºæ–‡ä½¿ç”¨äº†ä¸åŒçš„å¯¹é½æ–¹æ³•æ¥è®­ç»ƒæ‘©æ“¦æ™ºèƒ½ä½“ï¼ŒåŒ…æ‹¬æŒ‡ä»¤å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ã€‚å¯¹äºåäº‹å®è¯„ä¼°ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ç³»åˆ—æŒ‡æ ‡æ¥è¡¡é‡ç¾¤ä½“åä½œçš„è½¨è¿¹å˜åŒ–å’Œä¿¡å¿µå¯¹é½ç¨‹åº¦ï¼Œä¾‹å¦‚å…±è¯†è¾¾æˆé€Ÿåº¦å’Œä»»åŠ¡ç»“æœçš„å‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€ä½¿ç”¨çš„å¯¹é½æ–¹æ³•ï¼Œä½†æ ¸å¿ƒç›®æ ‡æ˜¯ä½¿æ‘©æ“¦æ™ºèƒ½ä½“èƒ½å¤Ÿæœ‰æ•ˆåœ°å¹²é¢„ç¾¤ä½“å¯¹è¯ï¼Œå¹¶ä¿ƒä½¿å‚ä¸è€…è¿›è¡Œæ›´æ·±å…¥çš„æ€è€ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‘©æ“¦æ„ŸçŸ¥æ–¹æ³•åœ¨å¸®åŠ©è¾¾æˆå…±è¯†å’Œä»»åŠ¡ç»“æœçš„æ­£ç¡®æ€§æ–¹é¢æ˜æ˜¾ä¼˜äºå¸¸è§çš„å¯¹é½åŸºçº¿ã€‚å…·ä½“æ¥è¯´ï¼Œæ‘©æ“¦æ„ŸçŸ¥æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¿ƒä½¿ç¾¤ä½“æˆå‘˜åæ€å…¶æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œå‡å°‘é”™è¯¯å†³ç­–çš„å‘ç”Ÿã€‚é€šè¿‡åäº‹å®è¯„ä¼°ï¼Œè®ºæ–‡é‡åŒ–äº†æ‘©æ“¦å¹²é¢„å¯¹ç¾¤ä½“åä½œè½¨è¿¹å’Œä¿¡å¿µå¯¹é½çš„å½±å“ï¼Œè¯æ˜äº†å…¶åœ¨æå‡å¤šæ–¹åä½œæ•ˆæœæ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦äººæœºåä½œçš„åœºæ™¯ï¼Œä¾‹å¦‚åœ¨çº¿æ•™è‚²ã€å›¢é˜Ÿå†³ç­–ã€å®¢æˆ·æœåŠ¡ç­‰ã€‚é€šè¿‡éƒ¨ç½²èƒ½å¤Ÿæœ‰æ•ˆå¹²é¢„å’Œå¼•å¯¼å¯¹è¯çš„LLMæ™ºèƒ½ä½“ï¼Œå¯ä»¥æå‡åä½œæ•ˆç‡ã€æ”¹å–„å†³ç­–è´¨é‡ï¼Œå¹¶ä¿ƒè¿›çŸ¥è¯†å…±äº«ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åä½œç¯å¢ƒï¼Œä¾‹å¦‚è·¨æ–‡åŒ–äº¤æµå’Œå¤šè¯­è¨€åä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) integrate into diverse workflows, they are increasingly being considered "collaborators" with humans. If such AI collaborators are to be reliable, their behavior over multiturn interactions must be predictable, validated and verified before deployment. Common alignment techniques are typically developed under simplified single-user settings and do not account for the dynamics of long-horizon multiparty interactions. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multiturn, multiparty collaborations. We study this question through the lens of friction agents that intervene in group dialogues to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Using a roleplay methodology, we evaluate interventions from differently-trained friction agents in collaborative task conversations. We propose a novel counterfactual evaluation framework that quantifies how friction interventions change the trajectory of group collaboration and belief alignment. Our results show that a friction-aware approach significantly outperforms common alignment baselines in helping both convergence to a common ground, or agreed-upon task-relevant propositions, and correctness of task outcomes.

