---
layout: default
title: Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction
---

# Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01739" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01739v1</a>
  <a href="https://arxiv.org/pdf/2508.01739.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01739v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01739v1', 'Enhancing the Preference Extractor in Multi-turn Dialogues: From Annotating Disasters to Accurate Preference Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cheng Wang, ziru Liu, Pengcheng Tang, Mingyu Zhang, Quanyu Dai, Yue Zhu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIterChatæ¡†æ¶ä»¥è§£å†³å¤šè½®å¯¹è¯ä¸­çš„åå¥½æå–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè½®å¯¹è¯` `åå¥½æå–` `æ•°æ®ç”Ÿæˆ` `GPT-4` `å¯¹è¯ç³»ç»Ÿ` `æ ‡æ³¨æ•ˆç‡` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šè½®å¯¹è¯ä¸­åå¥½æå–é¢ä¸´é«˜è´¨é‡æ ‡æ³¨æ•°æ®è·å–å›°éš¾ï¼Œå¯¼è‡´åå¥½è½¬å˜è·Ÿè¸ªä¸å‡†ç¡®ã€‚
2. æœ¬æ–‡æå‡ºIterChatæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºæ–°æ•°æ®æ ¼å¼å’Œåˆ©ç”¨GPT-4ç”Ÿæˆå¯¹è¯æ•°æ®ï¼Œé™ä½æ ‡æ³¨é”™è¯¯ç‡ï¼Œæé«˜æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æ–°æ ¼å¼å¾®è°ƒæˆ–å°‘é‡æç¤ºçš„æ€§èƒ½ä¼˜äºåŸå§‹å¤šè½®å¯¹è¯ï¼Œæ ‡æ³¨æ•ˆç‡æå‡28.4%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¯¹è¯ç³»ç»Ÿä¸­è¯†åˆ«ç”¨æˆ·åå¥½æ˜¯æä¾›æ»¡æ„æœåŠ¡çš„å…³é”®ã€‚ç°æœ‰ç ”ç©¶è¡¨æ˜ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾®è°ƒç‰¹å®šä»»åŠ¡çš„åå¥½æå–å™¨èƒ½å¤Ÿå–å¾—è‰¯å¥½çš„å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè·å–é«˜è´¨é‡çš„æ ‡æ³¨å¤šè½®å¯¹è¯æ•°æ®çš„éš¾åº¦è¾ƒå¤§ï¼Œå¯¼è‡´åå¥½è½¬å˜çš„å‡†ç¡®è·Ÿè¸ªé¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¯¹è¯æ•°æ®ç”Ÿæˆæ¡†æ¶IterChatï¼Œé€šè¿‡æ„å»ºæ–°çš„æ•°æ®æ ¼å¼å’Œåˆ©ç”¨GPT-4ç”Ÿæˆå¤šæ ·åŒ–çš„å¯¹è¯æ•°æ®ï¼Œæ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ–°æ•°æ®æ ¼å¼è¿›è¡Œå¾®è°ƒæˆ–å°‘é‡æç¤ºçš„æ€§èƒ½ä¼˜äºåŸå§‹å¤šè½®å¯¹è¯ï¼Œæ ‡æ³¨æ•ˆç‡æå‡28.4%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šè½®å¯¹è¯ä¸­ç”¨æˆ·åå¥½æå–çš„å‡†ç¡®æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è·å–é«˜è´¨é‡æ ‡æ³¨æ•°æ®æ—¶é¢ä¸´å›°éš¾ï¼Œå¯¼è‡´åå¥½è½¬å˜è·Ÿè¸ªä¸å‡†ç¡®ï¼Œå½±å“æ¨¡å‹è®­ç»ƒæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„IterChatæ¡†æ¶é€šè¿‡å°†å¤šè½®åå¥½æå–è¿‡ç¨‹åˆ†è§£ä¸ºå•è½®æå–çš„è¿­ä»£æ‰§è¡Œï¼Œæ„å»ºæ–°çš„å¯¹è¯æ•°æ®æ ¼å¼ï¼Œä»¥å‡å°‘æ ‡æ³¨é”™è¯¯å¹¶æé«˜æ ‡æ³¨æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIterChatæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€ï¼Œæ„å»ºæ–°çš„æ•°æ®æ ¼å¼ï¼Œå°†å¯¹è¯æ•°æ®åˆ†ç±»ä¸ºå¸¦å±æ€§çš„å†å²åå¥½å’Œå•è½®å¯¹è¯ï¼›ç¬¬äºŒï¼Œåˆ©ç”¨GPT-4é¢„å®šä¹‰åå¥½æ§½å¹¶éšæœºæŠ½æ ·ç”Ÿæˆå¯¹è¯æ•°æ®é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ–°æ•°æ®æ ¼å¼çš„æ„å»ºå’ŒGPT-4çš„åº”ç”¨ï¼Œä½¿å¾—åå¥½æå–è¿‡ç¨‹æ›´ä¸ºé«˜æ•ˆï¼Œæ˜¾è‘—é™ä½äº†æ ‡æ³¨é”™è¯¯ç‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒIterChatåœ¨æ•°æ®ç”Ÿæˆå’Œæ ‡æ³¨æ•ˆç‡ä¸Šå…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–°æ•°æ®æ ¼å¼ä¸­ï¼Œå†å²åå¥½ä¸å•è½®å¯¹è¯çš„åˆ†ç¦»è®¾è®¡å‡å°‘äº†æ ‡æ³¨å¤æ‚æ€§ï¼ŒGPT-4çš„ä½¿ç”¨ç¡®ä¿äº†ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§å’Œé«˜è´¨é‡ï¼Œæœ€ç»ˆæå‡äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ–°å¯¹è¯æ ¼å¼è¿›è¡Œå¾®è°ƒæˆ–å°‘é‡æç¤ºçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸå§‹å¤šè½®å¯¹è¯ï¼Œæ ‡æ³¨æ•ˆç‡æå‡28.4%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒIterChatæ¡†æ¶åœ¨åå¥½æå–ä»»åŠ¡ä¸­å…·æœ‰æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜å¯¹è¯ç³»ç»Ÿä¸­ç”¨æˆ·åå¥½çš„æå–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’ŒæœåŠ¡è´¨é‡ï¼Œæœªæ¥å¯èƒ½åœ¨å•†ä¸šå’Œç¤¾äº¤é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Identifying user preferences in dialogue systems is a pivotal aspect of providing satisfying services. Current research shows that using large language models (LLMs) to fine-tune a task-specific preference extractor yields excellent results in terms of accuracy and generalization. However, the primary challenge stems from the inherent difficulty in obtaining high-quality labeled multi-turn dialogue data. Accurately tracking user preference transitions across turns not only demands intensive domain expertise and contextual consistency maintenance for annotators (termed \textbf{``Annotating Disaster''}) but also complicates model training due to error propagation in sequential dependency learning. Inspired by the observation that multi-turn preference extraction can be decomposed into iterative executions of one-turn extraction processes. We propose a novel dialogue data generation framework named \textbf{IterChat}. First, we construct a new data format that categorizes the dialogue data into attributed historical preferences and one-turn dialogues. This reduces the probability of annotation errors and improves annotation efficiency. Then, to generate a high-quality and diverse dialogue dataset, we adopt GPT4 to pre-define the preference slots in the target preference extractor task and then randomly sample the subset of the slots and their corresponding schema values to create the dialogue datasets. Experimental results indicate that fine-tuning or only few-shot prompting with the new dialogue format yields superior performance compared to the original multi-turn dialogues. Additionally, the new data format improves annotator efficiency with a win rate of 28.4\% higher than the original multi-turn dialogues.

