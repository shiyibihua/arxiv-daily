---
layout: default
title: BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses
---

# BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00232" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00232v1</a>
  <a href="https://arxiv.org/pdf/2510.00232.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00232v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00232v1', 'BiasFreeBench: a Benchmark for Mitigating Bias in Large Language Model Responses')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Xu, Xunzhi He, Churan Zhi, Ruizhe Chen, Julian McAuley, Zexue He

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: Work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BiasFreeBenchï¼šç”¨äºè¯„ä¼°å’Œç¼“è§£å¤§è¯­è¨€æ¨¡å‹åè§çš„ç»¼åˆåŸºå‡†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `åè§ç¼“è§£` `è¯„ä¼°åŸºå‡†` `å…¬å¹³æ€§` `å®‰å…¨æ€§` `ååˆ»æ¿å°è±¡` `BiasFreeBench`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåè§ç¼“è§£æ–¹æ³•ç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†ï¼Œå¯¼è‡´æ€§èƒ½æ¯”è¾ƒå›°éš¾ï¼Œä¸”è¯„ä¼°æ–¹å¼ä¸å®é™…åº”ç”¨åœºæ™¯å­˜åœ¨è„±èŠ‚ã€‚
2. BiasFreeBenché€šè¿‡ç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”è®¾ç½®å’Œå“åº”çº§åˆ«çš„Bias-Free Scoreï¼Œæä¾›äº†ä¸€ä¸ªç»¼åˆæ€§çš„åè§è¯„ä¼°åŸºå‡†ã€‚
3. è¯¥åŸºå‡†æ¯”è¾ƒäº†å…«ç§ä¸»æµå»åç½®æŠ€æœ¯ï¼Œå¹¶åˆ†æäº†ä¸åŒå› ç´ ï¼ˆå¦‚æ¨¡å‹å¤§å°ã€è®­ç»ƒç­–ç•¥ï¼‰å¯¹å»åç½®æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹(LLM)åè§ç¼“è§£æ–¹æ³•ç ”ç©¶ï¼Œåœ¨è¯„ä¼°å»åç½®æ€§èƒ½æ—¶ä½¿ç”¨äº†ä¸åŒçš„åŸºçº¿å’ŒæŒ‡æ ‡ï¼Œå¯¼è‡´æ–¹æ³•é—´çš„æ¯”è¾ƒä¸ä¸€è‡´ã€‚æ­¤å¤–ï¼Œå®ƒä»¬çš„è¯„ä¼°ä¸»è¦åŸºäºLLMåœ¨æœ‰åå’Œæ— åä¸Šä¸‹æ–‡ä¸­çš„æ¦‚ç‡æ¯”è¾ƒï¼Œå¿½ç•¥äº†è¿™ç§è¯„ä¼°ä¸çœŸå®ä¸–ç•Œç”¨ä¾‹ä¹‹é—´çš„å·®è·ï¼Œåœ¨çœŸå®åœºæ™¯ä¸­ï¼Œç”¨æˆ·é€šè¿‡é˜…è¯»æ¨¡å‹å“åº”ä¸LLMäº¤äº’ï¼Œå¹¶æœŸæœ›è·å¾—å…¬å¹³å’Œå®‰å…¨çš„ç»“æœï¼Œè€Œä¸æ˜¯LLMçš„æ¦‚ç‡ã€‚ä¸ºäº†å®ç°è·¨å»åç½®æ–¹æ³•çš„ä¸€è‡´è¯„ä¼°å¹¶å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†BiasFreeBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå®è¯åŸºå‡†ï¼Œé€šè¿‡å°†ç°æœ‰æ•°æ®é›†é‡ç»„ä¸ºç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”è®¾ç½®ï¼Œåœ¨ä¸¤ç§æµ‹è¯•åœºæ™¯ï¼ˆå¤šé¡¹é€‰æ‹©QAå’Œå¼€æ”¾å¼å¤šè½®QAï¼‰ä¸­å…¨é¢æ¯”è¾ƒäº†å…«ç§ä¸»æµçš„åè§ç¼“è§£æŠ€æœ¯ï¼ˆåŒ…æ‹¬å››ç§åŸºäºæç¤ºçš„æ–¹æ³•å’Œå››ç§åŸºäºè®­ç»ƒçš„æ–¹æ³•ï¼‰ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ä¸ªå“åº”çº§åˆ«çš„æŒ‡æ ‡ï¼ŒBias-Free Scoreï¼Œæ¥è¡¡é‡LLMå“åº”åœ¨å¤šå¤§ç¨‹åº¦ä¸Šæ˜¯å…¬å¹³ã€å®‰å…¨å’Œååˆ»æ¿å°è±¡çš„ã€‚ç³»ç»Ÿåœ°æ¯”è¾ƒå’Œåˆ†æäº†å»åç½®æ€§èƒ½çš„å…³é”®ç»´åº¦ï¼šæç¤ºä¸è®­ç»ƒèŒƒå¼ã€æ¨¡å‹å¤§å°ä»¥åŠä¸åŒè®­ç»ƒç­–ç•¥å¯¹æœªè§è¿‡çš„åè§ç±»å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æˆ‘ä»¬å°†å…¬å¼€å‘å¸ƒæˆ‘ä»¬çš„åŸºå‡†ï¼Œæ—¨åœ¨ä¸ºåè§ç¼“è§£ç ”ç©¶å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åè§ç¼“è§£æ–¹æ³•ç ”ç©¶ï¼Œç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†ï¼Œå¯¼è‡´ä¸åŒæ–¹æ³•ä¹‹é—´çš„æ€§èƒ½æ¯”è¾ƒå›°éš¾ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„è¯„ä¼°æ–¹æ³•ä¸»è¦å…³æ³¨æ¨¡å‹åœ¨æœ‰åå’Œæ— åä¸Šä¸‹æ–‡ä¸­çš„æ¦‚ç‡å·®å¼‚ï¼Œè€Œå¿½ç•¥äº†ç”¨æˆ·åœ¨å®é™…åº”ç”¨ä¸­æ›´å…³æ³¨æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬å“åº”æ˜¯å¦å…¬å¹³ã€å®‰å…¨å’Œååˆ»æ¿å°è±¡ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´è´´è¿‘å®é™…åº”ç”¨åœºæ™¯ã€æ›´å…¨é¢çš„è¯„ä¼°åŸºå‡†æ¥è¡¡é‡å’Œæ¯”è¾ƒä¸åŒåè§ç¼“è§£æ–¹æ³•çš„æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBiasFreeBenchçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„ã€é¢å‘å“åº”çš„è¯„ä¼°åŸºå‡†ï¼Œè¯¥åŸºå‡†åŒ…å«ç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”è®¾ç½®ï¼Œå¹¶å¼•å…¥å“åº”çº§åˆ«çš„è¯„ä¼°æŒ‡æ ‡Bias-Free Scoreã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´ç›´æ¥åœ°è¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬å“åº”æ˜¯å¦åŒ…å«åè§ï¼Œå¹¶æ¯”è¾ƒä¸åŒåè§ç¼“è§£æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBiasFreeBenchçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ•°æ®é›†é‡ç»„ï¼šå°†ç°æœ‰çš„å¤šä¸ªæ•°æ®é›†é‡ç»„ä¸ºç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”æ ¼å¼ï¼Œä½¿å…¶é€‚ç”¨äºä¸åŒç±»å‹çš„åè§è¯„ä¼°ã€‚2) åè§ç¼“è§£æ–¹æ³•é›†æˆï¼šé›†æˆäº†å…«ç§ä¸»æµçš„åè§ç¼“è§£æŠ€æœ¯ï¼ŒåŒ…æ‹¬åŸºäºæç¤ºçš„æ–¹æ³•å’ŒåŸºäºè®­ç»ƒçš„æ–¹æ³•ã€‚3) è¯„ä¼°æŒ‡æ ‡ï¼šå¼•å…¥äº†å“åº”çº§åˆ«çš„Bias-Free Scoreï¼Œç”¨äºè¡¡é‡æ¨¡å‹å“åº”çš„å…¬å¹³æ€§ã€å®‰å…¨æ€§å’Œååˆ»æ¿å°è±¡ç¨‹åº¦ã€‚4) è¯„ä¼°æµç¨‹ï¼šè®¾è®¡äº†ä¸¤ç§æµ‹è¯•åœºæ™¯ï¼ˆå¤šé¡¹é€‰æ‹©QAå’Œå¼€æ”¾å¼å¤šè½®QAï¼‰ï¼Œç”¨äºå…¨é¢è¯„ä¼°ä¸åŒåè§ç¼“è§£æ–¹æ³•çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šBiasFreeBenchçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ã€é¢å‘å“åº”çš„åè§è¯„ä¼°åŸºå‡†ï¼Œå¼¥è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸å®é™…åº”ç”¨åœºæ™¯ä¹‹é—´çš„å·®è·ã€‚2) å¼•å…¥äº†å“åº”çº§åˆ«çš„Bias-Free Scoreï¼Œå¯ä»¥æ›´ç›´æ¥åœ°è¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬å“åº”æ˜¯å¦åŒ…å«åè§ã€‚3) ç³»ç»Ÿåœ°æ¯”è¾ƒå’Œåˆ†æäº†ä¸åŒåè§ç¼“è§£æ–¹æ³•åœ¨ä¸åŒç»´åº¦ä¸Šçš„æ€§èƒ½ï¼Œä¸ºåè§ç¼“è§£ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šBiasFreeBenchçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ•°æ®é›†çš„é€‰æ‹©å’Œé‡ç»„ï¼šé€‰æ‹©äº†å¤šä¸ªåŒ…å«ä¸åŒç±»å‹åè§çš„æ•°æ®é›†ï¼Œå¹¶å°†å…¶é‡ç»„ä¸ºç»Ÿä¸€çš„æŸ¥è¯¢-å“åº”æ ¼å¼ã€‚2) Bias-Free Scoreçš„è®¡ç®—æ–¹æ³•ï¼šBias-Free Scoreçš„è®¡ç®—æ–¹æ³•æœªçŸ¥ï¼Œè®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ã€‚3) è¯„ä¼°åœºæ™¯çš„è®¾è®¡ï¼šè®¾è®¡äº†å¤šé¡¹é€‰æ‹©QAå’Œå¼€æ”¾å¼å¤šè½®QAä¸¤ç§æµ‹è¯•åœºæ™¯ï¼Œä»¥å…¨é¢è¯„ä¼°ä¸åŒåè§ç¼“è§£æ–¹æ³•çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

BiasFreeBenchç³»ç»Ÿåœ°æ¯”è¾ƒäº†å…«ç§ä¸»æµåè§ç¼“è§£æŠ€æœ¯ï¼Œæ¶µç›–æç¤ºå’Œè®­ç»ƒèŒƒå¼ï¼Œå¹¶åˆ†æäº†æ¨¡å‹å¤§å°å’Œè®­ç»ƒç­–ç•¥å¯¹æ³›åŒ–èƒ½åŠ›çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒæ–¹æ³•åœ¨ä¸åŒç»´åº¦ä¸Šè¡¨ç°å„å¼‚ï¼Œä¸ºåè§ç¼“è§£ç ”ç©¶æä¾›äº†å®è´µçš„ç»éªŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BiasFreeBenchå¯ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒå¤§è¯­è¨€æ¨¡å‹åè§ç¼“è§£æ–¹æ³•çš„æ•ˆæœï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…é€‰æ‹©åˆé€‚çš„å»åç½®æŠ€æœ¯ã€‚è¯¥åŸºå‡†è¿˜å¯ç”¨äºç›‘æ§å’Œæ”¹è¿›å¤§è¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§ã€å®‰å…¨æ€§å’Œååˆ»æ¿å°è±¡ç¨‹åº¦ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½æ½œåœ¨çš„ç¤¾ä¼šé£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing studies on bias mitigation methods for large language models (LLMs) use diverse baselines and metrics to evaluate debiasing performance, leading to inconsistent comparisons among them. Moreover, their evaluations are mostly based on the comparison between LLMs' probabilities of biased and unbiased contexts, which ignores the gap between such evaluations and real-world use cases where users interact with LLMs by reading model responses and expect fair and safe outputs rather than LLMs' probabilities. To enable consistent evaluation across debiasing methods and bridge this gap, we introduce BiasFreeBench, an empirical benchmark that comprehensively compares eight mainstream bias mitigation techniques (covering four prompting-based and four training-based methods) on two test scenarios (multi-choice QA and open-ended multi-turn QA) by reorganizing existing datasets into a unified query-response setting. We further introduce a response-level metric, Bias-Free Score, to measure the extent to which LLM responses are fair, safe, and anti-stereotypical. Debiasing performances are systematically compared and analyzed across key dimensions: the prompting vs. training paradigm, model size, and generalization of different training strategies to unseen bias types. We will publicly release our benchmark, aiming to establish a unified testbed for bias mitigation research.

