---
layout: default
title: Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications
---

# Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25736" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25736v1</a>
  <a href="https://arxiv.org/pdf/2509.25736.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25736v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25736v1', 'Think Less, Label Better: Multi-Stage Domain-Grounded Synthetic Data Generation for Fine-Tuning Large Language Models in Telecommunications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenhua Shi, Gregor Macdonald, Bhavika Jalli, Wanlu Lei, John Zou, Mridul Jain, Joji Philip

**åˆ†ç±»**: cs.CL, cs.AI, cs.IT, cs.NI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 6 pages, 6 figures, 5 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé¢†åŸŸçŸ¥è¯†å›¾è°±çš„å¤šé˜¶æ®µåˆæˆæ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œç”¨äºç”µä¿¡é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹å¾®è°ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆæˆæ•°æ®ç”Ÿæˆ` `å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒ` `é¢†åŸŸçŸ¥è¯†å›¾è°±` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `ç”µä¿¡ç½‘ç»œæ•…éšœæ’é™¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººå·¥æ ‡æ³¨é¢†åŸŸç‰¹å®šæ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œå°¤å…¶æ˜¯åœ¨ç”µä¿¡ç­‰éœ€è¦ä¸“ä¸šçŸ¥è¯†çš„åœºæ™¯ã€‚
2. æå‡ºä¸€ç§å…¨è‡ªåŠ¨çš„æ£€ç´¢å¢å¼ºæµæ°´çº¿ï¼ŒåŸºäºé¢†åŸŸçŸ¥è¯†å›¾è°±ç”Ÿæˆé«˜è´¨é‡åˆæˆé—®ç­”æ•°æ®ã€‚
3. é€šè¿‡å®šåˆ¶çš„RAGASè¯„åˆ†è¿‡æ»¤ä½è´¨é‡æ ·æœ¬ï¼Œç”Ÿæˆçš„æ•°æ®é€‚ç”¨äºå¼ºåŒ–å¾®è°ƒï¼Œæå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æˆåŠŸå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æŒ‡ä»¤éµå¾ªå’Œå¼ºåŒ–å­¦ä¹ æ•°æ®é›†ã€‚ç„¶è€Œï¼Œé€šè¿‡äººå·¥æ ‡æ³¨ç”Ÿæˆæ­¤ç±»æ•°æ®éå¸¸è€—æ—¶ï¼Œå°¤å…¶æ˜¯åœ¨ç”µä¿¡ç½‘ç»œæ•…éšœæ’é™¤ç­‰ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­ï¼Œå‡†ç¡®çš„å“åº”éœ€è¦æ·±åšçš„æŠ€æœ¯ä¸“ä¸šçŸ¥è¯†å’Œä¸Šä¸‹æ–‡ç†è§£ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å…¨è‡ªåŠ¨ã€æ£€ç´¢å¢å¼ºçš„æµæ°´çº¿ï¼Œç”¨äºç”ŸæˆåŸºäºç»“æ„åŒ–é¢†åŸŸçŸ¥è¯†çš„åˆæˆé—®ç­”ï¼ˆQAï¼‰å¯¹ã€‚æˆ‘ä»¬çš„å¤šé˜¶æ®µæ¡†æ¶é›†æˆäº†æ£€ç´¢å™¨ã€åŸºç¡€ç”Ÿæˆå™¨å’Œç²¾ç‚¼æ¨¡å‹ï¼Œåˆ©ç”¨ä»é¢†åŸŸç‰¹å®šçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢åˆ°çš„æ–‡æ¡£æ¥åˆæˆå’Œå¢å¼ºQAå¯¹ã€‚ä¸ºäº†ç¡®ä¿æ•°æ®è´¨é‡ï¼Œæˆ‘ä»¬é‡‡ç”¨å®šåˆ¶çš„åŸºäºRAGASçš„è¯„åˆ†æ¥è¿‡æ»¤ä½è´¨é‡æ ·æœ¬ï¼Œä»è€Œç”Ÿæˆé€‚ç”¨äºå¼ºåŒ–å¾®è°ƒï¼ˆRFTï¼‰çš„é«˜è´¨é‡æ•°æ®é›†ã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªçœŸå®çš„ç”µä¿¡åœºæ™¯ä¸­ï¼Œé‡ç‚¹å…³æ³¨æ— çº¿æ¥å…¥ç½‘ï¼ˆRANï¼‰æ•…éšœæ’é™¤ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œè¯¥æµæ°´çº¿æ— éœ€äººå·¥å¹²é¢„å³å¯ç”Ÿæˆå¤æ‚çš„ã€ä¸Šä¸‹æ–‡ä¸°å¯Œçš„æ•…éšœæ’é™¤è§£å†³æ–¹æ¡ˆè®¡åˆ’ã€‚è¿™é¡¹å·¥ä½œä¸ºåœ¨ä¸“ä¸šé¢†åŸŸæ„å»ºæŒ‡ä»¤å’Œå¼ºåŒ–æ•°æ®é›†æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—é™ä½äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„æŠ€æœ¯ä¿çœŸåº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç”µä¿¡é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯æ— çº¿æ¥å…¥ç½‘ï¼ˆRANï¼‰æ•…éšœæ’é™¤ä¸­ï¼Œç¼ºä¹é«˜è´¨é‡ã€å¤§è§„æ¨¡çš„æŒ‡ä»¤éµå¾ªå’Œå¼ºåŒ–å­¦ä¹ æ•°æ®é›†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºäººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜ã€è€—æ—¶ï¼Œä¸”éœ€è¦é¢†åŸŸä¸“å®¶å‚ä¸ï¼Œéš¾ä»¥æ‰©å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢†åŸŸçŸ¥è¯†å›¾è°±ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼Œè‡ªåŠ¨ç”Ÿæˆåˆæˆé—®ç­”æ•°æ®ã€‚é€šè¿‡å¤šé˜¶æ®µçš„ç”Ÿæˆå’Œç²¾ç‚¼è¿‡ç¨‹ï¼Œä»¥åŠåŸºäºRAGASçš„è´¨é‡è¯„ä¼°å’Œè¿‡æ»¤ï¼Œä¿è¯ç”Ÿæˆæ•°æ®çš„è´¨é‡ï¼Œä»è€Œé™ä½å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) **æ£€ç´¢å™¨**ï¼šä»é¢†åŸŸçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼›2) **åŸºç¡€ç”Ÿæˆå™¨**ï¼šåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£ç”Ÿæˆåˆå§‹çš„é—®ç­”å¯¹ï¼›3) **ç²¾ç‚¼æ¨¡å‹**ï¼šå¯¹ç”Ÿæˆçš„é—®ç­”å¯¹è¿›è¡Œä¼˜åŒ–å’Œæ”¹è¿›ï¼Œæå‡è´¨é‡å’Œä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…æ‹¬ä¸€ä¸ªåŸºäºRAGASçš„**è´¨é‡è¯„ä¼°æ¨¡å—**ï¼Œç”¨äºè¿‡æ»¤ä½è´¨é‡çš„æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºå°†æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ä¸é¢†åŸŸçŸ¥è¯†å›¾è°±ç›¸ç»“åˆï¼Œå¹¶é‡‡ç”¨å¤šé˜¶æ®µçš„ç”Ÿæˆå’Œç²¾ç‚¼æµç¨‹ï¼Œä»¥åŠå®šåˆ¶çš„RAGASè¯„åˆ†æœºåˆ¶ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œæ˜¾è‘—é™ä½äº†å¯¹äººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚ä¸ä¼ ç»Ÿçš„çº¯äººå·¥æ ‡æ³¨æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´å…·å¯æ‰©å±•æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å®šåˆ¶äº†åŸºäºRAGASçš„è¯„åˆ†æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°ç”Ÿæˆæ•°æ®çš„è´¨é‡ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡ç›¸å…³æ€§ã€ç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ç­‰ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œæ¨¡å‹é€‰æ‹©ï¼ˆä¾‹å¦‚ï¼Œæ£€ç´¢å™¨ã€ç”Ÿæˆå™¨å’Œç²¾ç‚¼æ¨¡å‹çš„å…·ä½“æ¶æ„ï¼‰åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæ˜ç¡®æåŠã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚ä¹Ÿéœ€è¦å‚è€ƒåŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶åœ¨çœŸå®çš„ç”µä¿¡åœºæ™¯ä¸­è¿›è¡Œäº†éªŒè¯ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¤æ‚çš„ã€ä¸Šä¸‹æ–‡ä¸°å¯Œçš„æ•…éšœæ’é™¤è§£å†³æ–¹æ¡ˆè®¡åˆ’ï¼Œä¸”æ— éœ€äººå·¥å¹²é¢„ã€‚é€šè¿‡å®šåˆ¶çš„RAGASè¯„åˆ†è¿‡æ»¤ä½è´¨é‡æ ·æœ¬ï¼Œä¿è¯äº†ç”Ÿæˆæ•°æ®çš„è´¨é‡ï¼Œä»è€Œæå‡äº†å¾®è°ƒåæ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºç”µä¿¡ã€é‡‘èã€åŒ»ç–—ç­‰ä¸“ä¸šé¢†åŸŸï¼Œä¸ºè¿™äº›é¢†åŸŸçš„å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒæä¾›é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚é€šè¿‡é™ä½å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œå¯ä»¥åŠ é€Ÿé¢†åŸŸæ¨¡å‹çš„å¼€å‘å’Œéƒ¨ç½²ï¼Œæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¾‹å¦‚æ•…éšœè¯Šæ–­ã€å®¢æˆ·æœåŠ¡ã€çŸ¥è¯†é—®ç­”ç­‰ã€‚è¯¥æ–¹æ³•è¿˜å¯ç”¨äºæ„å»ºæ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The success of large language models (LLMs) depends heavily on large-scale, high-quality instruction-following and reinforcement datasets. However, generating such data through human annotation is prohibitively time-consuming particularly for domain-specific tasks like telecom network troubleshooting, where accurate responses require deep technical expertise and contextual understanding. In this paper, we present a fully automated, retrieval-augmented pipeline for generating synthetic question-answer (QA) pairs grounded in structured domain knowledge. Our multi-stage framework integrates a retriever, base generator, and refinement model to synthesize and enhance QA pairs using documents retrieved from a domain-specific knowledge graph. To ensure data quality, we employ customized RAGAS-based scoring to filter low-quality samples, producing a high-quality dataset suitable for reinforcement fine-tuning (RFT). We demonstrate our approach in a real-world telecom scenario focused on radio access network (RAN) troubleshooting. The resulting pipeline generates complex, context-rich troubleshooting solution plans without human intervention. This work offers a scalable solution for building instruction and reinforcement datasets in specialized domains, significantly reducing dependence on manual labeling while maintaining high technical fidelity.

