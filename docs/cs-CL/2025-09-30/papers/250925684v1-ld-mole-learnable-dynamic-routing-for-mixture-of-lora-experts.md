---
layout: default
title: LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts
---

# LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25684" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25684v1</a>
  <a href="https://arxiv.org/pdf/2509.25684.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25684v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25684v1', 'LD-MoLE: Learnable Dynamic Routing for Mixture of LoRA Experts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuan Zhuang, Yi Shen, Yuexin Bian, Qing Su, Shihao Ji, Yuanyuan Shi, Fei Miao

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLD-MoLEï¼Œé€šè¿‡å¯å­¦ä¹ åŠ¨æ€è·¯ç”±å®ç°LoRAä¸“å®¶æ··åˆï¼Œæå‡LLMå¾®è°ƒæ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `æ··åˆä¸“å®¶æ¨¡å‹` `åŠ¨æ€è·¯ç”±` `å¯å­¦ä¹ è·¯ç”±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MoEæ–¹æ³•ä¾èµ–TopKè·¯ç”±ï¼Œè¶…å‚æ•°æ•æ„Ÿä¸”ä¸“å®¶åˆ†é…å›ºå®šï¼Œé™åˆ¶äº†æ¨¡å‹æ€§èƒ½ã€‚
2. LD-MoLEé‡‡ç”¨å¯å­¦ä¹ åŠ¨æ€è·¯ç”±ï¼Œé€šè¿‡å¯å¾®åˆ†å‡½æ•°å’Œé—­å¼è§£å®ç°è‡ªé€‚åº”ä¸“å®¶åˆ†é…ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLD-MoLEåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶ŠSOTAæ–¹æ³•ï¼Œå¹¶èƒ½å­¦ä¹ tokenå’Œå±‚çº§çš„ä¸“å®¶åˆ†é…ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºLD-MoLEçš„å¯å­¦ä¹ åŠ¨æ€è·¯ç”±æœºåˆ¶ï¼Œç”¨äºLoRAä¸“å®¶æ··åˆï¼Œæ—¨åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„é€‚åº”èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºTopKè·¯ç”±ï¼Œéœ€è¦ç²¾ç»†çš„è¶…å‚æ•°è°ƒæ•´ï¼Œå¹¶ä¸”ä¸ºæ¯ä¸ªtokenåˆ†é…å›ºå®šæ•°é‡çš„ä¸“å®¶ã€‚LD-MoLEé€šè¿‡å¯å¾®åˆ†çš„è·¯ç”±å‡½æ•°å’Œé—­å¼è§£å–ä»£äº†ä¸å¯å¾®çš„TopKé€‰æ‹©ï¼Œå®ç°äº†è‡ªé€‚åº”çš„ã€tokenç›¸å…³çš„ã€ä»¥åŠå±‚çº§çš„ä¸“å®¶åˆ†é…ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å…è®¸æ¨¡å‹è‡ªé€‚åº”åœ°ç¡®å®šåœ¨ä¸åŒå±‚ä¸ºæ¯ä¸ªtokenæ¿€æ´»çš„ä¸“å®¶æ•°é‡ã€‚åŒæ—¶ï¼Œå¼•å…¥äº†è§£æç¨€ç–æ€§æ§åˆ¶ç›®æ ‡æ¥æ­£åˆ™åŒ–æ¿€æ´»ä¸“å®¶çš„æ•°é‡ã€‚åœ¨Qwen3-1.7Bå’ŒLlama-3.2-3Bæ¨¡å‹ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLD-MoLEåœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¼˜äºç°æœ‰æœ€ä½³æ–¹æ³•çš„å¹³å‡åˆ†æ•°ã€‚è¯¥æ–¹æ³•ä¸ä»…å®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œè¿˜å±•ç¤ºäº†å­¦ä¹ tokenç›¸å…³å’Œå±‚çº§ä¸“å®¶åˆ†é…çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºMoEçš„LLMå¾®è°ƒæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç»“åˆLoRAçš„æ–¹æ³•ï¼Œé€šå¸¸ä½¿ç”¨TopKè·¯ç”±æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯éœ€è¦æ‰‹åŠ¨è°ƒæ•´TopKä¸­çš„Kå€¼ï¼Œå¯¹è¶…å‚æ•°éå¸¸æ•æ„Ÿï¼›äºŒæ˜¯æ¯ä¸ªtokenè¢«åˆ†é…çš„ä¸“å®¶æ•°é‡æ˜¯å›ºå®šçš„ï¼Œæ— æ³•æ ¹æ®tokençš„ç‰¹æ€§è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼Œé™åˆ¶äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLD-MoLEçš„æ ¸å¿ƒæ€è·¯æ˜¯ä½¿ç”¨ä¸€ä¸ªå¯å­¦ä¹ çš„åŠ¨æ€è·¯ç”±æœºåˆ¶æ¥æ›¿ä»£ä¼ ç»Ÿçš„TopKè·¯ç”±ã€‚é€šè¿‡å¼•å…¥å¯å¾®åˆ†çš„è·¯ç”±å‡½æ•°ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®tokençš„ç‰¹å¾è‡ªé€‚åº”åœ°é€‰æ‹©æ¿€æ´»çš„ä¸“å®¶ï¼Œå¹¶ä¸”å¯ä»¥åŠ¨æ€åœ°è°ƒæ•´æ¯ä¸ªtokenæ¿€æ´»çš„ä¸“å®¶æ•°é‡ã€‚è¿™ç§è‡ªé€‚åº”æ€§ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰tokenä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œæé«˜æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLD-MoLEçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) LoRAä¸“å®¶å±‚ï¼šä½¿ç”¨å¤šä¸ªLoRAæ¨¡å—ä½œä¸ºä¸“å®¶ï¼Œæ¯ä¸ªä¸“å®¶è´Ÿè´£å¤„ç†ä¸åŒç±»å‹çš„tokenï¼›2) å¯å­¦ä¹ è·¯ç”±å‡½æ•°ï¼šä½¿ç”¨ä¸€ä¸ªç¥ç»ç½‘ç»œæ¥é¢„æµ‹æ¯ä¸ªtokenåº”è¯¥æ¿€æ´»å“ªäº›ä¸“å®¶ï¼Œä»¥åŠæ¿€æ´»çš„æƒé‡ï¼›3) é—­å¼è§£ï¼šä½¿ç”¨é—­å¼è§£æ¥è®¡ç®—æ¯ä¸ªä¸“å®¶çš„æ¿€æ´»æ¦‚ç‡ï¼Œä»è€Œé¿å…äº†ä½¿ç”¨é‡‡æ ·ç­‰è¿‘ä¼¼æ–¹æ³•ï¼›4) ç¨€ç–æ€§æ§åˆ¶ï¼šå¼•å…¥ä¸€ä¸ªç¨€ç–æ€§æ§åˆ¶ç›®æ ‡æ¥æ­£åˆ™åŒ–æ¿€æ´»ä¸“å®¶çš„æ•°é‡ï¼Œé¿å…æ¨¡å‹è¿‡åº¦ä¾èµ–å°‘æ•°ä¸“å®¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šLD-MoLEæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶å¯å­¦ä¹ çš„åŠ¨æ€è·¯ç”±æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„TopKè·¯ç”±ç›¸æ¯”ï¼ŒLD-MoLEå¯ä»¥æ ¹æ®tokençš„ç‰¹å¾è‡ªé€‚åº”åœ°é€‰æ‹©æ¿€æ´»çš„ä¸“å®¶ï¼Œå¹¶ä¸”å¯ä»¥åŠ¨æ€åœ°è°ƒæ•´æ¯ä¸ªtokenæ¿€æ´»çš„ä¸“å®¶æ•°é‡ã€‚æ­¤å¤–ï¼ŒLD-MoLEè¿˜å¼•å…¥äº†ä¸€ä¸ªé—­å¼è§£æ¥è®¡ç®—æ¯ä¸ªä¸“å®¶çš„æ¿€æ´»æ¦‚ç‡ï¼Œé¿å…äº†ä½¿ç”¨é‡‡æ ·ç­‰è¿‘ä¼¼æ–¹æ³•ï¼Œæé«˜äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šLD-MoLEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨softmaxå‡½æ•°ä½œä¸ºå¯å¾®åˆ†çš„è·¯ç”±å‡½æ•°ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥é¢„æµ‹æ¯ä¸ªtokenåº”è¯¥æ¿€æ´»å“ªäº›ä¸“å®¶ï¼Œä»¥åŠæ¿€æ´»çš„æƒé‡ï¼›2) å¼•å…¥KLæ•£åº¦ä½œä¸ºç¨€ç–æ€§æ§åˆ¶ç›®æ ‡ï¼Œé¼“åŠ±æ¨¡å‹æ¿€æ´»å°½å¯èƒ½å°‘çš„ä¸“å®¶ï¼›3) ä½¿ç”¨é—­å¼è§£æ¥è®¡ç®—æ¯ä¸ªä¸“å®¶çš„æ¿€æ´»æ¦‚ç‡ï¼Œé¿å…äº†ä½¿ç”¨é‡‡æ ·ç­‰è¿‘ä¼¼æ–¹æ³•ï¼›4) åœ¨ä¸åŒçš„å±‚ä½¿ç”¨ä¸åŒçš„è·¯ç”±å‡½æ•°ï¼Œä½¿å¾—æ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°å±‚çº§çš„ä¸“å®¶åˆ†é…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLD-MoLEåœ¨Qwen3-1.7Bå’ŒLlama-3.2-3Bæ¨¡å‹ä¸Šï¼Œç›¸æ¯”äºSOTAåŸºçº¿æ–¹æ³•ï¼Œåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€é«˜çš„å¹³å‡åˆ†æ•°ã€‚è¿™è¯æ˜äº†LD-MoLEèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ tokenç›¸å…³å’Œå±‚çº§çš„ä¸“å®¶åˆ†é…ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“æ€§èƒ½æå‡æ•°æ®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LD-MoLEå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå„ç§éœ€è¦å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé«˜æ•ˆå¾®è°ƒçš„åœºæ™¯ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæå‡æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶é™ä½è®¡ç®—æˆæœ¬ï¼Œå°¤å…¶é€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒã€‚æœªæ¥ï¼ŒLD-MoLEæœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„æ¨¡å‹ç»“æ„å’Œæ›´å¤§è§„æ¨¡çš„æ•°æ®é›†ï¼Œè¿›ä¸€æ­¥æå‡LLMçš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies have shown that combining parameter-efficient fine-tuning (PEFT) with mixture-of-experts (MoE) is an effective strategy for adapting large language models (LLMs) to the downstream tasks. However, most existing approaches rely on conventional TopK routing, which requires careful hyperparameter tuning and assigns a fixed number of experts to each token. In this work, we propose LD-MoLE, a Learnable Dynamic routing mechanism for Mixture of LoRA Experts that enables adaptive, token-dependent, and layer-wise expert allocation. Our method replaces the non-differentiable TopK selection with a differentiable routing function and a closed-form solution. Moreover, our design allows the model to adaptively determine the number of experts to activate for each token at different layers. In addition, we introduce an analytical sparsity control objective to regularize the number of activated experts. Extensive experiments on the Qwen3-1.7B and Llama-3.2-3B models show that LD-MoLE achieves the highest average scores compared to state-of-the-art baselines, across a diverse set of benchmarks. Our method not only achieves superior performance, but also demonstrates the ability to learn token-dependent and layer-wise expert allocation.

