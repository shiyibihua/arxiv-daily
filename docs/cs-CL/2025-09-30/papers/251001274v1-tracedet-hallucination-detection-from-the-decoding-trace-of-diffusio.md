---
layout: default
title: TraceDet: Hallucination Detection from the Decoding Trace of Diffusion Large Language Models
---

# TraceDet: Hallucination Detection from the Decoding Trace of Diffusion Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01274" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01274v1</a>
  <a href="https://arxiv.org/pdf/2510.01274.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01274v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01274v1', 'TraceDet: Hallucination Detection from the Decoding Trace of Diffusion Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shenxu Chang, Junchi Yu, Weixing Wang, Yongqiang Chen, Jialin Yu, Philip Torr, Jindong Gu

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TraceDetï¼šåˆ©ç”¨æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹è§£ç è½¨è¿¹è¿›è¡Œå¹»è§‰æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `å»å™ªè¿‡ç¨‹` `åŠ¨ä½œè½¨è¿¹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ä¸»è¦é’ˆå¯¹è‡ªå›å½’æ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨æ‰©æ•£æ¨¡å‹å¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­çš„å¹»è§‰ä¿¡å·ã€‚
2. TraceDetå°†æ‰©æ•£æ¨¡å‹çš„å»å™ªè¿‡ç¨‹å»ºæ¨¡ä¸ºåŠ¨ä½œè½¨è¿¹ï¼Œé€šè¿‡åˆ†æä¸­é—´æ­¥éª¤é¢„æµ‹æ¥è¯†åˆ«å¹»è§‰ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTraceDetåœ¨å¹»è§‰æ£€æµ‹æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒAUROCå¹³å‡æå‡15.2%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆD-LLMsï¼‰ä½œä¸ºè‡ªå›å½’LLMï¼ˆAR-LLMsï¼‰çš„ä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆè€Œå´­éœ²å¤´è§’ã€‚ç„¶è€Œï¼ŒD-LLMä¸­çš„å¹»è§‰é—®é¢˜ä»æœªå¾—åˆ°å……åˆ†ç ”ç©¶ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•æ˜¯ä¸ºAR-LLMè®¾è®¡çš„ï¼Œä¾èµ–äºå•æ­¥ç”Ÿæˆä¸­çš„ä¿¡å·ï¼Œå› æ­¤ä¸é€‚ç”¨äºD-LLMï¼Œå› ä¸ºå¹»è§‰ä¿¡å·é€šå¸¸åœ¨å¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­å‡ºç°ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†TraceDetï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒæ˜¾å¼åœ°åˆ©ç”¨D-LLMçš„ä¸­é—´å»å™ªæ­¥éª¤è¿›è¡Œå¹»è§‰æ£€æµ‹ã€‚TraceDetå°†å»å™ªè¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªåŠ¨ä½œè½¨è¿¹ï¼Œæ¯ä¸ªåŠ¨ä½œè¢«å®šä¹‰ä¸ºæ¨¡å‹å¯¹æ¸…ç†åçš„å“åº”çš„é¢„æµ‹ï¼Œå¹¶ä»¥å…ˆå‰çš„ä¸­é—´è¾“å‡ºä¸ºæ¡ä»¶ã€‚é€šè¿‡è¯†åˆ«å¯¹å¹»è§‰å“åº”ä¿¡æ¯é‡æœ€å¤§çš„å­è½¨è¿¹ï¼ŒTraceDetåˆ©ç”¨D-LLMå¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­çš„å…³é”®å¹»è§‰ä¿¡å·è¿›è¡Œå¹»è§‰æ£€æµ‹ã€‚åœ¨å„ç§å¼€æºD-LLMä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼ŒTraceDetå§‹ç»ˆæé«˜äº†å¹»è§‰æ£€æµ‹èƒ½åŠ›ï¼ŒAUROCå¹³å‡æé«˜äº†15.2%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆD-LLMsï¼‰ä¸­å­˜åœ¨çš„å¹»è§‰é—®é¢˜ã€‚ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ä¸»è¦é’ˆå¯¹è‡ªå›å½’æ¨¡å‹ï¼ˆAR-LLMsï¼‰ï¼Œä¾èµ–äºå•æ­¥ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¿¡å·ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰D-LLMsåœ¨å¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ä¿¡å·ã€‚å› æ­¤ï¼Œå¦‚ä½•å……åˆ†åˆ©ç”¨D-LLMsçš„ä¸­é—´å»å™ªæ­¥éª¤è¿›è¡Œå¹»è§‰æ£€æµ‹æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†D-LLMsçš„å»å™ªè¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªåŠ¨ä½œè½¨è¿¹ï¼ˆaction traceï¼‰ï¼Œå…¶ä¸­æ¯ä¸ªåŠ¨ä½œä»£è¡¨æ¨¡å‹åœ¨ç»™å®šå…ˆå‰ä¸­é—´è¾“å‡ºçš„æƒ…å†µä¸‹ï¼Œå¯¹æ¸…ç†åçš„å“åº”çš„é¢„æµ‹ã€‚é€šè¿‡åˆ†æè¿™ä¸ªè½¨è¿¹ï¼Œå¯ä»¥è¯†åˆ«å‡ºå¯¹å¹»è§‰å“åº”ä¿¡æ¯é‡æœ€å¤§çš„å­è½¨è¿¹ï¼Œä»è€Œæå–å…³é”®çš„å¹»è§‰ä¿¡å·ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰D-LLMsåœ¨å¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTraceDetæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) å°†D-LLMçš„å»å™ªè¿‡ç¨‹å±•å¼€ä¸ºä¸€ç³»åˆ—ä¸­é—´æ­¥éª¤ï¼›2) å°†æ¯ä¸ªä¸­é—´æ­¥éª¤çš„é¢„æµ‹è§†ä¸ºä¸€ä¸ªåŠ¨ä½œï¼Œæ„å»ºåŠ¨ä½œè½¨è¿¹ï¼›3) åˆ©ç”¨æ¨¡å‹å­¦ä¹ æ¯ä¸ªåŠ¨ä½œå¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ï¼Œå¹¶è¯†åˆ«å‡ºå¯¹å¹»è§‰å“åº”å½±å“æœ€å¤§çš„å­è½¨è¿¹ï¼›4) åŸºäºè¯†åˆ«å‡ºçš„å­è½¨è¿¹è¿›è¡Œå¹»è§‰æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ˜¾å¼åœ°åˆ©ç”¨äº†D-LLMsçš„ä¸­é—´å»å™ªæ­¥éª¤è¿›è¡Œå¹»è§‰æ£€æµ‹ã€‚ä¸ç°æœ‰æ–¹æ³•ä»…å…³æ³¨æœ€ç»ˆè¾“å‡ºæˆ–å•æ­¥ç”Ÿæˆè¿‡ç¨‹ä¸åŒï¼ŒTraceDeté€šè¿‡å»ºæ¨¡å»å™ªè½¨è¿¹ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰D-LLMsåœ¨å¤šæ­¥å»å™ªè¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ä¿¡å·ã€‚è¿™ç§æ–¹æ³•æ›´é€‚åˆD-LLMsçš„ç‰¹æ€§ï¼Œå¹¶èƒ½æœ‰æ•ˆæé«˜å¹»è§‰æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šTraceDetçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•å®šä¹‰å’Œè¡¨ç¤ºåŠ¨ä½œè½¨è¿¹ï¼Œå³å¦‚ä½•å°†D-LLMçš„ä¸­é—´æ­¥éª¤è½¬åŒ–ä¸ºå¯åˆ†æçš„åŠ¨ä½œåºåˆ—ï¼›2) å¦‚ä½•å­¦ä¹ æ¯ä¸ªåŠ¨ä½œå¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æˆ–å¼ºåŒ–å­¦ä¹ ç­‰æ–¹æ³•ï¼›3) å¦‚ä½•è¯†åˆ«å¯¹å¹»è§‰å“åº”ä¿¡æ¯é‡æœ€å¤§çš„å­è½¨è¿¹ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨ä¿¡æ¯å¢ç›Šæˆ–äº’ä¿¡æ¯ç­‰æŒ‡æ ‡ï¼›4) å¦‚ä½•åŸºäºè¯†åˆ«å‡ºçš„å­è½¨è¿¹è¿›è¡Œå¹»è§‰æ£€æµ‹ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨åˆ†ç±»å™¨æˆ–å›å½’æ¨¡å‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTraceDetåœ¨å„ç§å¼€æºD-LLMä¸Šå‡èƒ½æ˜¾è‘—æé«˜å¹»è§‰æ£€æµ‹çš„æ€§èƒ½ï¼ŒAUROCå¹³å‡æå‡15.2%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒTraceDetèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨D-LLMçš„ä¸­é—´å»å™ªæ­¥éª¤è¿›è¡Œå¹»è§‰æ£€æµ‹ï¼Œå¹¶ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºD-LLMçš„å¹»è§‰æ£€æµ‹æä¾›äº†ä¸€ç§æ–°çš„æœ‰æ•ˆé€”å¾„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TraceDetå¯åº”ç”¨äºå„ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜æ‰©æ•£æ¨¡å‹çš„å¯é æ€§ï¼ŒTraceDetæœ‰åŠ©äºåœ¨å®é™…åº”ç”¨ä¸­å‡å°‘é”™è¯¯ä¿¡æ¯çš„äº§ç”Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½æ½œåœ¨é£é™©ã€‚è¯¥ç ”ç©¶å¯¹äºæ¨åŠ¨æ‰©æ•£æ¨¡å‹åœ¨å®‰å…¨å…³é”®é¢†åŸŸçš„åº”ç”¨å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion large language models (D-LLMs) have recently emerged as a promising alternative to auto-regressive LLMs (AR-LLMs). However, the hallucination problem in D-LLMs remains underexplored, limiting their reliability in real-world applications. Existing hallucination detection methods are designed for AR-LLMs and rely on signals from single-step generation, making them ill-suited for D-LLMs where hallucination signals often emerge throughout the multi-step denoising process. To bridge this gap, we propose TraceDet, a novel framework that explicitly leverages the intermediate denoising steps of D-LLMs for hallucination detection. TraceDet models the denoising process as an action trace, with each action defined as the model's prediction over the cleaned response, conditioned on the previous intermediate output. By identifying the sub-trace that is maximally informative to the hallucinated responses, TraceDet leverages the key hallucination signals in the multi-step denoising process of D-LLMs for hallucination detection. Extensive experiments on various open source D-LLMs demonstrate that TraceDet consistently improves hallucination detection, achieving an average gain in AUROC of 15.2% compared to baselines.

