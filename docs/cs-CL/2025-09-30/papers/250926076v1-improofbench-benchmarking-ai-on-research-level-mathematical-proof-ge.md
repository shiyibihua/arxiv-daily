---
layout: default
title: IMProofBench: Benchmarking AI on Research-Level Mathematical Proof Generation
---

# IMProofBench: Benchmarking AI on Research-Level Mathematical Proof Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26076" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.26076v1</a>
  <a href="https://arxiv.org/pdf/2509.26076.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26076v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26076v1', 'IMProofBench: Benchmarking AI on Research-Level Mathematical Proof Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Johannes Schmitt, Gergely B√©rczi, Jasper Dekoninck, Jeremy Feusi, Tim Gehrunger, Raphael Appenzeller, Jim Bryan, Niklas Canova, Timo de Wolff, Filippo Gaia, Michel van Garrel, Baran Hashemi, David Holmes, Aitor Iribar Lopez, Victor Jaeck, Martina J√∏rgensen, Steven Kelk, Stefan Kuhlmann, Adam Kurpisz, Chiara Meroni, Ingmar Metzler, Martin M√∂ller, Samuel Mu√±oz-Ech√°niz, Robert Nowak, Georg Oberdieck, Daniel Platt, Dylan Possama√Ø, Gabriel Ribeiro, Ra√∫l S√°nchez Gal√°n, Zheming Sun, Josef Teichmann, Richard P. Thomas, Charles Vial

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**IMProofBenchÔºöÁî®‰∫éËØÑ‰º∞AIÂú®Á†îÁ©∂Á∫ßÊï∞Â≠¶ËØÅÊòéÁîüÊàêËÉΩÂäõÁöÑÊñ∞Âü∫ÂáÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êï∞Â≠¶ËØÅÊòéÁîüÊàê` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `AIÂü∫ÂáÜÊµãËØï` `Á†îÁ©∂Á∫ßÈóÆÈ¢ò` `Êï∞Â≠¶Êé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊï∞Â≠¶ËÉΩÂäõËØÑ‰º∞Âü∫ÂáÜ‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÊúÄÁªàÁ≠îÊ°àÊàñÈ´ò‰∏≠Á´ûËµõÈ¢òÔºåÁº∫‰πèÂØπÁ†îÁ©∂Á∫ßÊï∞Â≠¶ËØÅÊòéÁîüÊàêËÉΩÂäõÁöÑÊúâÊïàËØÑ‰º∞„ÄÇ
2. IMProofBenchÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂåÖÂê´ÂêåË°åËØÑÂÆ°Á†îÁ©∂Á∫ßÊï∞Â≠¶ÈóÆÈ¢òÁöÑÂü∫ÂáÜÔºåÂπ∂Ê®°Êãü‰∫ÜÁúüÂÆûÁ†îÁ©∂ÁéØÂ¢ÉÔºåÂÖÅËÆ∏Ê®°Âûã‰ΩøÁî®ÁΩëÁªúÊêúÁ¥¢ÂíåÊï∞Â≠¶ËΩØ‰ª∂„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâLLMÂú®ËæÉÁÆÄÂçïÁ†îÁ©∂Á∫ßÈóÆÈ¢ò‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÈóÆÈ¢ò‰∏ä‰ªçÂ≠òÂú®Âõ∞ÈöæÔºåGrok-4ÂíåGPT-5ÂàÜÂà´Âú®ÊúÄÁªàÁ≠îÊ°àÂíåËØÅÊòéÁîüÊàê‰∏äÂèñÂæóÊúÄ‰Ω≥ÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÊï∞Â≠¶ËÉΩÂäõ‰∏çÊñ≠ÊèêÈ´òÔºåËØÑ‰º∞ÂÆÉ‰ª¨Âú®Êï∞Â≠¶Áü•ËØÜÂâçÊ≤øÁöÑÁ†îÁ©∂Á∫ß‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶Å„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÂü∫ÂáÜÊµãËØïÂ≠òÂú®Â±ÄÈôêÊÄßÔºåÂõ†‰∏∫ÂÆÉ‰ª¨Âè™ÂÖ≥Ê≥®ÊúÄÁªàÁ≠îÊ°àÈóÆÈ¢òÊàñÈ´ò‰∏≠Á´ûËµõÈóÆÈ¢ò„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨Êé®Âá∫‰∫ÜIMProofBenchÔºåËøôÊòØ‰∏Ä‰∏™ÁßÅÊúâÂü∫ÂáÜÔºåÂåÖÂê´Áî±Êï∞Â≠¶‰∏ìÂÆ∂ÂºÄÂèëÁöÑ39‰∏™ÁªèËøáÂêåË°åËØÑÂÆ°ÁöÑÈóÆÈ¢ò„ÄÇÊØè‰∏™ÈóÆÈ¢òÈÉΩÈúÄË¶ÅËØ¶ÁªÜÁöÑËØÅÊòéÔºåÂπ∂ÈÖçÊúâÊúÄÁªàÁ≠îÊ°àÁöÑÂ≠êÈóÆÈ¢òÔºåÊîØÊåÅÈÄöËøá‰∫∫Â∑•‰∏ìÂÆ∂ËØÑ‰º∞Êï∞Â≠¶Êé®ÁêÜËÉΩÂäõÔºåÂπ∂ÈÄöËøáËá™Âä®ËØÑÂàÜËøõË°åÂ§ßËßÑÊ®°ÂÆöÈáèÂàÜÊûê„ÄÇÊ≠§Â§ñÔºå‰∏é‰πãÂâçÁöÑÂü∫ÂáÜÊµãËØï‰∏çÂêåÔºåËØÑ‰º∞ËÆæÁΩÆÊ®°Êãü‰∫ÜÁúüÂÆûÁöÑÁ†îÁ©∂ÁéØÂ¢ÉÔºöÊ®°ÂûãÂú®ÂÖ∑ÊúâËØ∏Â¶ÇÁî®‰∫éÊñáÁåÆÁªºËø∞ÁöÑÁΩëÁªúÊêúÁ¥¢ÂíåËØ∏Â¶ÇSageMath‰πãÁ±ªÁöÑÊï∞Â≠¶ËΩØ‰ª∂ÁöÑ‰ª£ÁêÜÊ°ÜÊû∂‰∏≠ËøêË°å„ÄÇÊàë‰ª¨ÁöÑÁªìÊûúË°®ÊòéÔºåÂΩìÂâçÁöÑLLMÂèØ‰ª•ÊàêÂäüËß£ÂÜ≥Êõ¥ÂÆπÊòìÁöÑÁ†îÁ©∂Á∫ßÈóÆÈ¢òÔºå‰ΩÜÂú®Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÈóÆÈ¢ò‰∏ä‰ªçÁÑ∂ÈÅáÂà∞ÈáçÂ§ßÂõ∞Èöæ„ÄÇÂú®ÂÆöÈáèÊñπÈù¢ÔºåGrok-4Âú®ÊúÄÁªàÁ≠îÊ°àÂ≠êÈóÆÈ¢ò‰∏äÂÆûÁé∞‰∫Ü52%ÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéáÔºåËÄåGPT-5Âú®ËØÅÊòéÁîüÊàêÊñπÈù¢Ë°®Áé∞ÊúÄ‰Ω≥Ôºå‰∏∫22%ÁöÑÈóÆÈ¢òÂÆûÁé∞‰∫ÜÂÆåÂÖ®Ê≠£Á°ÆÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇIMProofBenchÂ∞ÜÁªßÁª≠ÂèëÂ±ïÊàê‰∏∫‰∏éÊï∞Â≠¶ÁïåÂêà‰ΩúÁöÑÂä®ÊÄÅÂü∫ÂáÜÔºåÁ°Æ‰øùÂÖ∂‰∏éËØÑ‰º∞‰∏ã‰∏Ä‰ª£LLMÁöÑÁõ∏ÂÖ≥ÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊï∞Â≠¶ËÉΩÂäõËØÑ‰º∞Âü∫ÂáÜÊó†Ê≥ïÊúâÊïàËØÑ‰º∞Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Á†îÁ©∂Á∫ßÊï∞Â≠¶ËØÅÊòéÁîüÊàêËÉΩÂäõÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÂü∫ÂáÜ‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÊúÄÁªàÁ≠îÊ°àÊàñÈ´ò‰∏≠Á´ûËµõÈ¢òÔºåÊó†Ê≥ïÂèçÊò†LLMsÂú®Â§çÊùÇÊï∞Â≠¶Êé®ÁêÜÂíåËØÅÊòéÊñπÈù¢ÁöÑÁúüÂÆûÊ∞¥Âπ≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Êõ¥ÂÖ∑ÊåëÊàòÊÄßÂíåÁé∞ÂÆûÊÄßÁöÑÂü∫ÂáÜÊµãËØïÔºåÂç≥IMProofBench„ÄÇËØ•Âü∫ÂáÜÂåÖÂê´Áî±Êï∞Â≠¶‰∏ìÂÆ∂ËÆæËÆ°ÁöÑ„ÄÅÁªèËøáÂêåË°åËØÑÂÆ°ÁöÑÁ†îÁ©∂Á∫ßÊï∞Â≠¶ÈóÆÈ¢òÔºåÂπ∂Ê®°Êãü‰∫ÜÁúüÂÆûÁöÑÁ†îÁ©∂ÁéØÂ¢ÉÔºåÂÖÅËÆ∏Ê®°Âûã‰ΩøÁî®ÁΩëÁªúÊêúÁ¥¢ÂíåÊï∞Â≠¶ËΩØ‰ª∂Á≠âÂ∑•ÂÖ∑„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöIMProofBenchÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™ÂÖ≥ÈîÆÁªÑÊàêÈÉ®ÂàÜÔºö1) ÈóÆÈ¢òÈõÜÔºöÂåÖÂê´39‰∏™Á†îÁ©∂Á∫ßÊï∞Â≠¶ÈóÆÈ¢òÔºåÊØè‰∏™ÈóÆÈ¢òÈÉΩÈúÄË¶ÅËØ¶ÁªÜÁöÑËØÅÊòéÔºõ2) Â≠êÈóÆÈ¢òÔºöÊØè‰∏™ÈóÆÈ¢òÈÉΩÈÖçÊúâÊúÄÁªàÁ≠îÊ°àÁöÑÂ≠êÈóÆÈ¢òÔºåÁî®‰∫éËæÖÂä©ËØÑ‰º∞Ôºõ3) ËØÑ‰º∞ÁéØÂ¢ÉÔºöÊ®°ÊãüÁúüÂÆûÁöÑÁ†îÁ©∂ÁéØÂ¢ÉÔºåÂÖÅËÆ∏Ê®°Âûã‰ΩøÁî®ÁΩëÁªúÊêúÁ¥¢ÂíåÊï∞Â≠¶ËΩØ‰ª∂Ôºõ4) ËØÑ‰º∞ÊåáÊ†áÔºöÂåÖÊã¨‰∫∫Â∑•ËØÑ‰º∞ÂíåËá™Âä®ËØÑÂàÜÔºåÁî®‰∫éÂÖ®Èù¢ËØÑ‰º∞Ê®°ÂûãÁöÑÊï∞Â≠¶Êé®ÁêÜÂíåËØÅÊòéËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöIMProofBenchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÈóÆÈ¢òÈõÜÁöÑÈöæÂ∫¶ÂíåÁúüÂÆûÊÄß„ÄÇ‰∏éÁé∞ÊúâÂü∫ÂáÜÁõ∏ÊØîÔºåIMProofBenchÁöÑÈóÆÈ¢òÊõ¥ÂÖ∑ÊåëÊàòÊÄßÔºåÊõ¥Êé•ËøëÊï∞Â≠¶Á†îÁ©∂ÁöÑÂâçÊ≤ø„ÄÇÊ≠§Â§ñÔºåIMProofBenchÊ®°Êãü‰∫ÜÁúüÂÆûÁöÑÁ†îÁ©∂ÁéØÂ¢ÉÔºåÂÖÅËÆ∏Ê®°Âûã‰ΩøÁî®ÂêÑÁßçÂ∑•ÂÖ∑ÔºåËøô‰ΩøÂæóËØÑ‰º∞ÁªìÊûúÊõ¥ÂÖ∑ÂèÇËÄÉ‰ª∑ÂÄº„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöIMProofBenchÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÈóÆÈ¢òÈõÜÁöÑÈÄâÊã©ÔºöÈóÆÈ¢òÁî±Êï∞Â≠¶‰∏ìÂÆ∂ËÆæËÆ°ÔºåÂπ∂ÁªèËøáÂêåË°åËØÑÂÆ°ÔºåÁ°Æ‰øùÂÖ∂ÈöæÂ∫¶ÂíåË¥®ÈáèÔºõ2) ËØÑ‰º∞ÁéØÂ¢ÉÁöÑÊûÑÂª∫ÔºöËØÑ‰º∞ÁéØÂ¢ÉÊ®°ÊãüÁúüÂÆûÁöÑÁ†îÁ©∂ÁéØÂ¢ÉÔºåÂÖÅËÆ∏Ê®°Âûã‰ΩøÁî®ÁΩëÁªúÊêúÁ¥¢ÂíåÊï∞Â≠¶ËΩØ‰ª∂Ôºõ3) ËØÑ‰º∞ÊåáÊ†áÁöÑËÆæËÆ°ÔºöËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨‰∫∫Â∑•ËØÑ‰º∞ÂíåËá™Âä®ËØÑÂàÜÔºåÁî®‰∫éÂÖ®Èù¢ËØÑ‰º∞Ê®°ÂûãÁöÑÊï∞Â≠¶Êé®ÁêÜÂíåËØÅÊòéËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂΩìÂâçLLMÂú®ËæÉÁÆÄÂçïÁöÑÁ†îÁ©∂Á∫ßÈóÆÈ¢ò‰∏äË°®Áé∞ËâØÂ•ΩÔºå‰ΩÜÂú®Êõ¥ÂÖ∑ÊåëÊàòÊÄßÁöÑÈóÆÈ¢ò‰∏ä‰ªçÂ≠òÂú®Âõ∞Èöæ„ÄÇGrok-4Âú®ÊúÄÁªàÁ≠îÊ°àÂ≠êÈóÆÈ¢ò‰∏äÂÆûÁé∞‰∫Ü52%ÁöÑÊúÄÈ´òÂáÜÁ°ÆÁéáÔºåËÄåGPT-5Âú®ËØÅÊòéÁîüÊàêÊñπÈù¢Ë°®Áé∞ÊúÄ‰Ω≥Ôºå‰∏∫22%ÁöÑÈóÆÈ¢òÂÆûÁé∞‰∫ÜÂÆåÂÖ®Ê≠£Á°ÆÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇËøô‰∫õÁªìÊûú‰∏∫Êú™Êù•LLMÂú®Êï∞Â≠¶È¢ÜÂüüÁöÑÊîπËøõÊñπÂêëÊèê‰æõ‰∫ÜÈáçË¶ÅÂèÇËÄÉ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

IMProofBenchÂèØÁî®‰∫éËØÑ‰º∞ÂíåÊèêÂçáAIÂú®Êï∞Â≠¶Á†îÁ©∂È¢ÜÂüüÁöÑÂ∫îÁî®ËÉΩÂäõÔºå‰æãÂ¶ÇËæÖÂä©Êï∞Â≠¶ÂÆ∂ËøõË°åÂÆöÁêÜËØÅÊòé„ÄÅÂèëÁé∞Êñ∞ÁöÑÊï∞Â≠¶ËßÑÂæãÁ≠â„ÄÇËØ•Âü∫ÂáÜÁöÑÊé®Âá∫Â∞ÜÊé®Âä®AIÂú®Êï∞Â≠¶È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÔºåÂπ∂ÊúâÊúõÂú®ÁßëÂ≠¶Á†îÁ©∂„ÄÅÂ∑•Á®ãËÆæËÆ°Á≠âÈ¢ÜÂüüÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> As the mathematical capabilities of large language models (LLMs) improve, it becomes increasingly important to evaluate their performance on research-level tasks at the frontier of mathematical knowledge. However, existing benchmarks are limited, as they focus solely on final-answer questions or high-school competition problems. To address this gap, we introduce IMProofBench, a private benchmark consisting of 39 peer-reviewed problems developed by expert mathematicians. Each problem requires a detailed proof and is paired with subproblems that have final answers, supporting both an evaluation of mathematical reasoning capabilities by human experts and a large-scale quantitative analysis through automated grading. Furthermore, unlike prior benchmarks, the evaluation setup simulates a realistic research environment: models operate in an agentic framework with tools like web search for literature review and mathematical software such as SageMath. Our results show that current LLMs can succeed at the more accessible research-level questions, but still encounter significant difficulties on more challenging problems. Quantitatively, Grok-4 achieves the highest accuracy of 52% on final-answer subproblems, while GPT-5 obtains the best performance for proof generation, achieving a fully correct solution for 22% of problems. IMProofBench will continue to evolve as a dynamic benchmark in collaboration with the mathematical community, ensuring its relevance for evaluating the next generation of LLMs.

