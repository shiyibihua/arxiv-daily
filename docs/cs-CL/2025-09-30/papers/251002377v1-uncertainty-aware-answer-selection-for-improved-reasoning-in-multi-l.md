---
layout: default
title: Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems
---

# Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02377" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02377v1</a>
  <a href="https://arxiv.org/pdf/2510.02377.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02377v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02377v1', 'Uncertainty-Aware Answer Selection for Improved Reasoning in Multi-LLM Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aakriti Agrawal, Rohith Aralikatti, Anirudh Satheesh, Souradip Chakraborty, Amrit Singh Bedi, Furong Huang

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ ¡å‡†å¯¹æ•°ä¼¼ç„¶çš„å¤šLLMç­”æ¡ˆé€‰æ‹©æ–¹æ³•ï¼Œæå‡æ¨ç†æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç­”æ¡ˆé€‰æ‹©` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `å¯¹æ•°ä¼¼ç„¶` `æ ¡å‡†` `å¤šLLMç³»ç»Ÿ` `æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šLLMç³»ç»Ÿä¸­é€‰æ‹©æœ€ä½³ç­”æ¡ˆæ—¶ï¼Œä¾èµ–é«˜æˆæœ¬çš„å¤–éƒ¨éªŒè¯æˆ–å¤šæ¬¡é‡‡æ ·ï¼Œæ•ˆç‡è¾ƒä½ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäºæ ¡å‡†å¯¹æ•°ä¼¼ç„¶çš„æ–¹æ³•ï¼Œåˆ©ç”¨LLMè‡ªèº«çŸ¥è¯†å’Œç½®ä¿¡åº¦ï¼Œé«˜æ•ˆé€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†å’Œè®¾ç½®ä¸‹ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œä¾‹å¦‚GSM8Kä¸Šæå‡çº¦4%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å¦‚ä½•ä»å¤šä¸ªLLMä¸­é€‰æ‹©æœ€å¯é çš„å“åº”ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜‚è´µçš„å¤–éƒ¨éªŒè¯å™¨ã€äººå·¥è¯„ä¼°å‘˜æˆ–éœ€è¦ä»å•ä¸ªæ¨¡å‹ä¸­è¿›è¡Œå¤šæ¬¡é‡‡æ ·çš„è‡ªæ´½æ€§æŠ€æœ¯ã€‚è™½ç„¶å¤šLLMç³»ç»Ÿæ¯”å•ä¸ªæ¨¡å‹äº§ç”Ÿæ›´å¤šæ ·åŒ–çš„å“åº”ï¼Œå› æ­¤å…·æœ‰æ›´å¤§çš„æ½œåŠ›ï¼Œä½†å®ƒä»¬é€šå¸¸ä¸å¦‚å•ä¸ªLLMè‡ªæ´½æ€§æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸåˆ™æ€§çš„ã€æ–°é¢–çš„ä¸”è®¡ç®—é«˜æ•ˆçš„æ–¹æ³•ï¼Œä½¿ç”¨æ ¡å‡†çš„å¯¹æ•°ä¼¼ç„¶å¾—åˆ†ä»å¤šä¸ªä¸åŒçš„LLMä¸­é€‰æ‹©æœ€ä½³å“åº”ï¼Œéšå¼åœ°åˆ©ç”¨è¿™äº›æ¨¡å‹å›ºæœ‰çš„çŸ¥è¯†å’Œç½®ä¿¡åº¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨GSM8Kã€MMLUï¼ˆ6ä¸ªå­é›†ï¼‰å’ŒARCæ•°æ®é›†ä¸Šçš„è¾©è®ºï¼ˆå¤šè½®LLMè®¨è®ºï¼‰å’Œéè¾©è®ºï¼ˆä½¿ç”¨å¤šä¸ªLLMçš„Best-of-Nï¼‰è®¾ç½®ä¸­åˆ†åˆ«æé«˜äº†çº¦4%ã€3%å’Œ5%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»å¤šä¸ªLLMç”Ÿæˆçš„ç­”æ¡ˆä¸­é€‰æ‹©æœ€ä½³ç­”æ¡ˆçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚å¤–éƒ¨éªŒè¯å™¨æˆ–è‡ªæ´½æ€§æ–¹æ³•ï¼Œå­˜åœ¨è®¡ç®—æˆæœ¬é«˜æ˜‚æˆ–éœ€è¦å¤šæ¬¡é‡‡æ ·çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨èµ„æºå—é™åœºæ™¯ä¸‹çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œå¤šLLMç³»ç»Ÿè™½ç„¶å…·æœ‰ç”Ÿæˆå¤šæ ·åŒ–ç­”æ¡ˆçš„æ½œåŠ›ï¼Œä½†å…¶æ€§èƒ½å¾€å¾€ä¸å¦‚å•LLMè‡ªæ´½æ€§æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMè‡ªèº«æä¾›çš„å¯¹æ•°ä¼¼ç„¶ä¿¡æ¯ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ ¡å‡†ï¼Œä»¥è¯„ä¼°æ¯ä¸ªç­”æ¡ˆçš„è´¨é‡ã€‚é€šè¿‡æ ¡å‡†å¯¹æ•°ä¼¼ç„¶ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°åæ˜ LLMå¯¹è‡ªèº«ç­”æ¡ˆçš„ç½®ä¿¡åº¦ï¼Œä»è€Œé€‰æ‹©å‡ºæœ€å¯é çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¤–éƒ¨éªŒè¯å™¨å’Œå¤šæ¬¡é‡‡æ ·ï¼Œæé«˜äº†æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨å¤šä¸ªä¸åŒçš„LLMç”Ÿæˆç­”æ¡ˆï¼›2) è®¡ç®—æ¯ä¸ªLLMå¯¹æ¯ä¸ªç­”æ¡ˆçš„å¯¹æ•°ä¼¼ç„¶å¾—åˆ†ï¼›3) å¯¹å¯¹æ•°ä¼¼ç„¶å¾—åˆ†è¿›è¡Œæ ¡å‡†ï¼Œä»¥æ¶ˆé™¤ä¸åŒLLMä¹‹é—´çš„åå·®ï¼›4) æ ¹æ®æ ¡å‡†åçš„å¯¹æ•°ä¼¼ç„¶å¾—åˆ†é€‰æ‹©æœ€ä½³ç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨æ ¡å‡†çš„å¯¹æ•°ä¼¼ç„¶ä½œä¸ºé€‰æ‹©æœ€ä½³ç­”æ¡ˆçš„æŒ‡æ ‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€å¤–éƒ¨éªŒè¯å™¨æˆ–å¤šæ¬¡é‡‡æ ·ï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨LLMè‡ªèº«çš„ä¿¡æ¯ï¼Œä»è€Œå®ç°äº†æ›´é«˜çš„æ•ˆç‡å’Œæ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¯¹æ•°ä¼¼ç„¶çš„æ ¡å‡†ä¹Ÿæ˜¯ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œå¯ä»¥æ¶ˆé™¤ä¸åŒLLMä¹‹é—´çš„åå·®ï¼Œæé«˜é€‰æ‹©çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•é€‰æ‹©åˆé€‚çš„LLMé›†åˆï¼›2) å¦‚ä½•æœ‰æ•ˆåœ°æ ¡å‡†å¯¹æ•°ä¼¼ç„¶å¾—åˆ†ï¼Œä¾‹å¦‚ä½¿ç”¨æ¸©åº¦ç¼©æ”¾ç­‰æ–¹æ³•ï¼›3) å¦‚ä½•å°†æ ¡å‡†åçš„å¯¹æ•°ä¼¼ç„¶å¾—åˆ†ç”¨äºç­”æ¡ˆé€‰æ‹©ï¼Œä¾‹å¦‚é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç­”æ¡ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨GSM8Kã€MMLUå’ŒARCæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨è¾©è®ºå’Œéè¾©è®ºè®¾ç½®ä¸­ï¼Œè¯¥æ–¹æ³•åˆ†åˆ«æé«˜äº†çº¦4%ã€3%å’Œ5%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨LLMè‡ªèº«çš„ä¿¡æ¯ï¼Œé€‰æ‹©å‡ºæœ€å¯é çš„ç­”æ¡ˆï¼Œä»è€Œæå‡æ¨ç†æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä»å¤šä¸ªLLMç”Ÿæˆç­”æ¡ˆä¸­é€‰æ‹©æœ€ä½³ç­”æ¡ˆçš„åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿã€æœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡æé«˜ç­”æ¡ˆé€‰æ‹©çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œå¯ä»¥æå‡è¿™äº›ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡æˆ–è¾¹ç¼˜è®¡ç®—è®¾å¤‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated exceptional capabilities, yet selecting the most reliable response from multiple LLMs remains a challenge, particularly in resource-constrained settings. Existing approaches often depend on costly external verifiers, human evaluators, or self-consistency techniques that require multiple samples from a single model. While multi-LLM systems produce more diverse responses than single models and thus have greater potential, they often underperform compared to single LLM self-consistency. We propose a principled, novel and computationally efficient method to select the best response from multiple different LLMs using a calibrated log-likelihood score, implicitly leveraging the inherent knowledge and confidence of these models. Our method demonstrates improvements of approx. 4%, 3%, and 5% across both debate (multi-round LLM discussions) and non-debate (Best-of-N with multiple LLMs) settings on GSM8K, MMLU (6 subsets), and ARC datasets respectively.

