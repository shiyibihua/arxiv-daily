---
layout: default
title: Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It
---

# Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00177" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00177v1</a>
  <a href="https://arxiv.org/pdf/2510.00177.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00177v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00177v1', 'Personalized Reasoning: Just-In-Time Personalization and Why LLMs Fail At It')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuyue Stella Li, Avinandan Bose, Faeze Brahman, Simon Shaolei Du, Pang Wei Koh, Maryam Fazel, Yulia Tsvetkov

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 57 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPREFDISCOè¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºLLMåœ¨å³æ—¶ä¸ªæ€§åŒ–æ¨ç†ä¸Šçš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–æ¨ç†` `å¤§è¯­è¨€æ¨¡å‹` `ç”¨æˆ·åå¥½` `äº¤äº’å¼è¯„ä¼°` `PREFDISCO`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨é¢å‘ç”¨æˆ·çš„åº”ç”¨ä¸­ï¼Œéš¾ä»¥åœ¨æ²¡æœ‰ç”¨æˆ·å†å²çš„æƒ…å†µä¸‹è¿›è¡Œå³æ—¶ä¸ªæ€§åŒ–æ¨ç†ï¼Œå¯¼è‡´å“åº”ä¸ç”¨æˆ·éœ€æ±‚ä¸åŒ¹é…ã€‚
2. è®ºæ–‡æå‡ºPREFDISCOè¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿå…·æœ‰ç¨€ç–åå¥½çš„äººç‰©è§’è‰²ï¼Œå°†é™æ€åŸºå‡†è½¬æ¢ä¸ºäº¤äº’å¼ä¸ªæ€§åŒ–ä»»åŠ¡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç®€å•ä¸ªæ€§åŒ–å°è¯•æ•ˆæœå¯èƒ½æ¯”é€šç”¨å“åº”æ›´å·®ï¼Œæ­ç¤ºäº†LLMåœ¨ä¸ªæ€§åŒ–æ¨ç†æ–¹é¢çš„å±€é™æ€§ï¼Œéœ€ä¸“é—¨å¼€å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼€å‘å°†ä»»åŠ¡è§£å†³å’Œåå¥½å¯¹é½è§†ä¸ºåˆ†ç¦»çš„æŒ‘æˆ˜ï¼Œé¦–å…ˆä¼˜åŒ–å®¢è§‚æ­£ç¡®æ€§ï¼Œç„¶åå¯¹é½èšåˆçš„äººç±»åå¥½ã€‚è¿™ç§æ¨¡å¼åœ¨é¢å‘ç”¨æˆ·çš„åº”ç”¨ä¸­å¤±æ•ˆï¼Œå› ä¸ºå¦‚æœå“åº”ä¸ç”¨æˆ·çš„éœ€æ±‚ä¸åŒ¹é…ï¼Œå³ä½¿æ­£ç¡®è§£å†³é—®é¢˜ä¹Ÿæ˜¯ä¸å¤Ÿçš„ã€‚åœ¨ç”±äºå†·å¯åŠ¨æ¡ä»¶æˆ–éšç§é™åˆ¶è€Œæ²¡æœ‰å…ˆå‰ç”¨æˆ·äº¤äº’å†å²çš„å³æ—¶åœºæ™¯ä¸­ï¼Œè¿™ä¸€æŒ‘æˆ˜æ›´åŠ å‰§çƒˆã€‚LLMéœ€è¦è¯†åˆ«å®ƒä»¬å¯¹ç”¨æˆ·åå¥½çš„æœªçŸ¥ä¿¡æ¯ï¼Œé€šè¿‡æé—®ç­–ç•¥æ€§åœ°å¼•å‡ºåå¥½å€¼ï¼Œç„¶åç›¸åº”åœ°è°ƒæ•´å®ƒä»¬çš„æ¨ç†è¿‡ç¨‹å’Œå“åº”â€”â€”è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„è®¤çŸ¥è¿‡ç¨‹é“¾ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºä¸ªæ€§åŒ–æ¨ç†ã€‚æˆ‘ä»¬å¼•å…¥äº†PREFDISCOï¼Œä¸€ç§è¯„ä¼°æ–¹æ³•ï¼Œå®ƒä½¿ç”¨åŸºäºå¿ƒç†å­¦çš„äººç‰©è§’è‰²å’Œç¨€ç–åå¥½å°†é™æ€åŸºå‡†è½¬æ¢ä¸ºäº¤äº’å¼ä¸ªæ€§åŒ–ä»»åŠ¡ã€‚æˆ‘ä»¬çš„æ¡†æ¶åˆ›å»ºäº†è¿™æ ·çš„åœºæ™¯ï¼šç›¸åŒçš„é—®é¢˜éœ€è¦ä¸åŒçš„æ¨ç†é“¾ï¼Œè¿™å–å†³äºç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œå› ä¸ºæœ€ä½³è§£é‡Šæ–¹æ³•å› ä¸ªäººä¸“ä¸šçŸ¥è¯†å’Œåå¥½è€Œå¼‚ï¼ŒåŒæ—¶ä¿æŒäº‹å®å‡†ç¡®æ€§ã€‚å¯¹10ä¸ªä»»åŠ¡ä¸­21ä¸ªå‰æ²¿æ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼Œ29.0%çš„æœ´ç´ ä¸ªæ€§åŒ–å°è¯•äº§ç”Ÿçš„åå¥½å¯¹é½æ¯”é€šç”¨å“åº”æ›´å·®ï¼Œä½†é€šç”¨å“åº”ä¹Ÿæœªèƒ½æœ‰æ•ˆåœ°æœåŠ¡äºä¸ªäººç”¨æˆ·éœ€æ±‚ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œä¸ªæ€§åŒ–æ¨ç†éœ€è¦ä¸“é—¨çš„å¼€å‘ï¼Œè€Œä¸æ˜¯è‡ªç„¶è€Œç„¶åœ°å‡ºç°ã€‚PREFDISCOå°†ä¸ªæ€§åŒ–æ¨ç†ç¡®ç«‹ä¸ºä¸€ä¸ªå¯è¡¡é‡çš„ç ”ç©¶å‰æ²¿ï¼Œå¹¶æ­ç¤ºäº†å½“å‰LLMäº¤äº’èƒ½åŠ›çš„åŸºæœ¬å±€é™æ€§ï¼Œä¸ºå¼€å‘èƒ½å¤Ÿåœ¨æ•™è‚²ã€åŒ»ç–—ä¿å¥å’ŒæŠ€æœ¯é¢†åŸŸé€‚åº”ä¸ªäººç”¨æˆ·çš„ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä¸ªæ€§åŒ–è‡³å…³é‡è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å³æ—¶ä¸ªæ€§åŒ–æ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚ç°æœ‰LLMé€šå¸¸å…ˆä¼˜åŒ–å®¢è§‚æ­£ç¡®æ€§ï¼Œå†å¯¹é½èšåˆçš„äººç±»åå¥½ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå°¤å…¶æ˜¯ç”¨æˆ·åå¥½æœªçŸ¥çš„æƒ…å†µä¸‹ï¼Œè¿™ç§æ–¹å¼æ— æ³•æ»¡è¶³ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆè¯„ä¼°LLMä¸ªæ€§åŒ–æ¨ç†èƒ½åŠ›çš„æ¡†æ¶ï¼Œä¹Ÿç¼ºä¹å¯¹LLMå¦‚ä½•ä¸»åŠ¨è·å–å¹¶åˆ©ç”¨ç”¨æˆ·åå¥½çš„ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªäº¤äº’å¼çš„è¯„ä¼°ç¯å¢ƒï¼Œä½¿LLMèƒ½å¤Ÿé€šè¿‡æé—®æ¥äº†è§£ç”¨æˆ·çš„åå¥½ï¼Œå¹¶æ ¹æ®è¿™äº›åå¥½è°ƒæ•´å…¶æ¨ç†è¿‡ç¨‹å’Œå“åº”ã€‚è¿™ç§â€œJust-In-Timeâ€çš„ä¸ªæ€§åŒ–æ¨ç†è¦æ±‚LLMå…·å¤‡è¯†åˆ«æœªçŸ¥åå¥½ã€ç­–ç•¥æ€§æé—®ã€åŠ¨æ€è°ƒæ•´æ¨ç†è¿‡ç¨‹çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPREFDISCOæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) åŸºäºå¿ƒç†å­¦çš„äººç‰©è§’è‰²ï¼ˆPersonasï¼‰ï¼Œè¿™äº›è§’è‰²å…·æœ‰ç¨€ç–çš„åå¥½ï¼›2) å°†é™æ€åŸºå‡†ä»»åŠ¡è½¬æ¢ä¸ºäº¤äº’å¼ä¸ªæ€§åŒ–ä»»åŠ¡ï¼›3) è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡LLMåœ¨åå¥½å¯¹é½æ–¹é¢çš„è¡¨ç°ã€‚LLMéœ€è¦é¦–å…ˆè¯†åˆ«ç”¨æˆ·åå¥½çš„æœªçŸ¥éƒ¨åˆ†ï¼Œç„¶åé€šè¿‡æé—®æ¥è·å–è¿™äº›åå¥½ä¿¡æ¯ï¼Œæœ€åæ ¹æ®è·å–çš„åå¥½ä¿¡æ¯è°ƒæ•´å…¶æ¨ç†è¿‡ç¨‹å’Œå“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šPREFDISCOçš„å…³é”®åˆ›æ–°åœ¨äºå…¶äº¤äº’å¼è¯„ä¼°æ–¹å¼å’ŒåŸºäºå¿ƒç†å­¦çš„äººç‰©è§’è‰²ã€‚ä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•é€šå¸¸æ˜¯é™æ€çš„ï¼Œæ— æ³•æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­ç”¨æˆ·åå¥½çš„åŠ¨æ€å˜åŒ–ã€‚PREFDISCOé€šè¿‡å¼•å…¥äººç‰©è§’è‰²å’Œäº¤äº’å¼ä»»åŠ¡ï¼Œä½¿LLMèƒ½å¤Ÿä¸»åŠ¨å­¦ä¹ ç”¨æˆ·çš„åå¥½ï¼Œå¹¶æ ¹æ®è¿™äº›åå¥½è¿›è¡Œä¸ªæ€§åŒ–æ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šPREFDISCOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) äººç‰©è§’è‰²çš„åå¥½æ˜¯ç¨€ç–çš„ï¼Œè¿™æ„å‘³ç€LLMéœ€è¦ä¸»åŠ¨æé—®æ‰èƒ½è·å–å®Œæ•´çš„åå¥½ä¿¡æ¯ï¼›2) ä»»åŠ¡çš„è®¾è®¡éœ€è¦ä¿è¯ç›¸åŒçš„é—®é¢˜åœ¨ä¸åŒçš„ç”¨æˆ·ä¸Šä¸‹æ–‡ä¸­éœ€è¦ä¸åŒçš„æ¨ç†é“¾ï¼›3) è¯„ä¼°æŒ‡æ ‡éœ€è¦èƒ½å¤Ÿè¡¡é‡LLMåœ¨åå¥½å¯¹é½æ–¹é¢çš„è¡¨ç°ï¼ŒåŒæ—¶è€ƒè™‘äº‹å®å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ29.0%çš„æœ´ç´ ä¸ªæ€§åŒ–å°è¯•äº§ç”Ÿçš„åå¥½å¯¹é½æ•ˆæœæ¯”é€šç”¨å“åº”æ›´å·®ï¼Œè¿™è¡¨æ˜ç®€å•çš„ä¸ªæ€§åŒ–æ–¹æ³•å¯èƒ½é€‚å¾—å…¶åã€‚åŒæ—¶ï¼Œé€šç”¨å“åº”ä¹Ÿæœªèƒ½æœ‰æ•ˆåœ°æœåŠ¡äºä¸ªäººç”¨æˆ·éœ€æ±‚ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†ä¸“é—¨å¼€å‘ä¸ªæ€§åŒ–æ¨ç†èƒ½åŠ›çš„å¿…è¦æ€§ï¼Œå¹¶æ­ç¤ºäº†å½“å‰LLMåœ¨äº¤äº’å¼ä¸ªæ€§åŒ–æ–¹é¢çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ•™è‚²ã€åŒ»ç–—ä¿å¥å’ŒæŠ€æœ¯æ”¯æŒç­‰é¢†åŸŸï¼Œæå‡äººæœºäº¤äº’çš„ä¸ªæ€§åŒ–ç¨‹åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨æ•™è‚²é¢†åŸŸï¼ŒLLMå¯ä»¥æ ¹æ®å­¦ç”Ÿçš„å­¦ä¹ é£æ ¼å’ŒçŸ¥è¯†èƒŒæ™¯æä¾›ä¸ªæ€§åŒ–çš„è¾…å¯¼ï¼›åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸï¼ŒLLMå¯ä»¥æ ¹æ®æ‚£è€…çš„ç—…æƒ…å’Œåå¥½æä¾›ä¸ªæ€§åŒ–çš„æ²»ç–—å»ºè®®ï¼›åœ¨æŠ€æœ¯æ”¯æŒé¢†åŸŸï¼ŒLLMå¯ä»¥æ ¹æ®ç”¨æˆ·çš„æŠ€æœ¯æ°´å¹³å’Œéœ€æ±‚æä¾›ä¸ªæ€§åŒ–çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶ä¸ºå¼€å‘èƒ½å¤Ÿé€‚åº”ä¸ªäººç”¨æˆ·çš„æ™ºèƒ½ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current large language model (LLM) development treats task-solving and preference alignment as separate challenges, optimizing first for objective correctness, then for alignment to aggregated human preferences. This paradigm fails in human-facing applications where solving a problem correctly is insufficient if the response mismatches the user's needs. This challenge intensifies in just-in-time scenarios where no prior user interaction history exists due to cold-start conditions or privacy constraints. LLMs need to identify what they don't know about user preferences, strategically elicit preference values through questioning, then adapt their reasoning processes and responses accordingly -- a complicated chain of cognitive processes which we term personalized reasoning. We introduce PREFDISCO, an evaluation methodology that transforms static benchmarks into interactive personalization tasks using psychologically-grounded personas with sparse preferences. Our framework creates scenarios where identical questions require different reasoning chains depending on user context, as optimal explanation approaches vary by individual expertise and preferences while maintaining factual accuracy. Evaluation of 21 frontier models across 10 tasks reveals 29.0% of naive personalization attempts produce worse preference alignment than generic responses, yet generic responses also fail to serve individual user needs effectively. These findings suggest personalized reasoning requires dedicated development rather than emerging naturally. PREFDISCO establishes personalized reasoning as a measurable research frontier and reveals fundamental limitations in current LLMs' interactive capabilities, providing a foundation for developing systems that can adapt to individual users in education, healthcare, and technical domains where personalization is critical.

