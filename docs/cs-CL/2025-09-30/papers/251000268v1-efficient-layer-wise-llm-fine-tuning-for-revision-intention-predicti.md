---
layout: default
title: Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction
---

# Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00268" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00268v1</a>
  <a href="https://arxiv.org/pdf/2510.00268.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00268v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00268v1', 'Efficient Layer-wise LLM Fine-tuning for Revision Intention Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhexiong Liu, Diane Litman

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: In The Conference on Empirical Methods in Natural Language Processing (EMNLP), November 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIR-Tuningï¼Œä¸€ç§é«˜æ•ˆçš„å±‚çº§LLMå¾®è°ƒæ¡†æ¶ï¼Œç”¨äºæ–‡æœ¬ä¿®è®¢æ„å›¾é¢„æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬ä¿®è®¢æ„å›¾é¢„æµ‹` `å±‚çº§é€‰æ‹©` `æ¢¯åº¦èŒƒæ•°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç»†å¾®æ–‡æœ¬ä¿®è®¢åˆ†ç±»æ—¶ï¼Œéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ã€‚
2. IR-Tuningé€šè¿‡åŠ¨æ€é€‰æ‹©å’Œå¾®è°ƒLLMä¸­é‡è¦çš„å±‚ï¼ŒåŒæ—¶å†»ç»“å†—ä½™å±‚ï¼Œå®ç°å‚æ•°é«˜æ•ˆçš„å¾®è°ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒIR-Tuningåœ¨æ–‡æœ¬ä¿®è®¢ä»»åŠ¡ä¸Šä¼˜äºå…¶ä»–å±‚çº§PEFTæ–¹æ³•ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¿«ï¼Œå†…å­˜æ¶ˆè€—ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å‡ºéå‡¡çš„æˆåŠŸï¼›ç„¶è€Œï¼Œå®ƒä»¬åœ¨ç®€å•ä½†è‡³å…³é‡è¦çš„æ–‡æœ¬åˆ†ç±»æ–¹é¢çš„æ½œåŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œå› ä¸ºLLMé¢„è®­ç»ƒå¾€å¾€ä¾§é‡äºç”Ÿæˆè€Œéåˆ†ç±»ã€‚è™½ç„¶å…·æœ‰æŒ‡ä»¤è°ƒä¼˜çš„LLMå¯ä»¥å°†åˆ†ç±»è½¬æ¢ä¸ºç”Ÿæˆä»»åŠ¡ï¼Œä½†å®ƒä»¬é€šå¸¸éš¾ä»¥å¯¹ç»†å¾®çš„æ–‡æœ¬è¿›è¡Œåˆ†ç±»ã€‚æ–‡æœ¬ä¿®è®¢å°±æ˜¯ä¸€ä¸ªä¾‹å­ï¼Œå®ƒæ¶‰åŠæ–‡æœ¬å¯¹ä¹‹é—´çš„ç»†å¾®ç¼–è¾‘ã€‚è™½ç„¶ç®€å•åœ°å¯¹LLMè¿›è¡Œä¿®è®¢åˆ†ç±»çš„å¾®è°ƒä¼¼ä¹æ˜¯å¯è¡Œçš„ï¼Œä½†è¿™éœ€è¦å¤§é‡çš„ä¿®è®¢æ³¨é‡Šï¼Œè€Œè¿™äº›æ³¨é‡Šåœ¨ç¤¾åŒºä¸­å¼‚å¸¸æ˜‚è´µå’Œç¨€ç¼ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªå³æ’å³ç”¨çš„å±‚çº§å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ¡†æ¶ï¼Œå³IR-Tuningï¼Œå®ƒå¾®è°ƒåŸºäºå…¶æ¢¯åº¦èŒƒæ•°åˆ†å¸ƒåŠ¨æ€é€‰æ‹©çš„é‡è¦LLMå±‚çš„ä¸€ä¸ªå­é›†ï¼ŒåŒæ—¶å†»ç»“å†—ä½™å±‚ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒIR-Tuningåœ¨ä¸åŒçš„æ–‡æœ¬ä¿®è®¢ä¸­è¶…è¶Šäº†å‡ ä¸ªå±‚çº§PEFTåŸºçº¿ï¼ŒåŒæ—¶å®ç°äº†å¿«é€Ÿæ”¶æ•›ã€ä½GPUå†…å­˜æ¶ˆè€—ä»¥åŠåœ¨å°å‹ä¿®è®¢è¯­æ–™åº“ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬ä¿®è®¢æ„å›¾é¢„æµ‹é—®é¢˜ï¼Œå³åˆ¤æ–­ä¸¤ä¸ªæ–‡æœ¬ä¹‹é—´çš„ä¿®æ”¹æ„å›¾ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ç›´æ¥å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œè€Œä¿®è®¢æ•°æ®çš„æ ‡æ³¨æˆæœ¬å¾ˆé«˜ï¼Œä¸”æ•°æ®ç¨€ç¼ºã€‚æ­¤å¤–ï¼Œç›´æ¥å¾®è°ƒLLMè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ï¼Œåªå¾®è°ƒLLMä¸­çš„ä¸€éƒ¨åˆ†å‚æ•°ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬å’Œæ•°æ®éœ€æ±‚ã€‚æ›´è¿›ä¸€æ­¥ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§å±‚çº§é€‰æ‹©ç­–ç•¥ï¼Œå³IR-Tuningï¼Œæ ¹æ®æ¢¯åº¦èŒƒæ•°åŠ¨æ€é€‰æ‹©éœ€è¦å¾®è°ƒçš„å±‚ï¼Œå†»ç»“ä¸é‡è¦çš„å±‚ï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜æ•ˆç‡ã€‚è¿™æ ·åšçš„åŸå› æ˜¯ï¼Œå¹¶éæ‰€æœ‰å±‚éƒ½å¯¹ç‰¹å®šä»»åŠ¡åŒç­‰é‡è¦ï¼Œé€‰æ‹©æ€§åœ°å¾®è°ƒé‡è¦å±‚å¯ä»¥è¾¾åˆ°æ›´å¥½çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIR-Tuningæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„LLMä½œä¸ºåŸºç¡€æ¨¡å‹ã€‚2) è®¡ç®—LLMæ¯ä¸€å±‚çš„æ¢¯åº¦èŒƒæ•°ï¼Œç”¨äºè¯„ä¼°è¯¥å±‚çš„é‡è¦æ€§ã€‚3) æ ¹æ®æ¢¯åº¦èŒƒæ•°é€‰æ‹©éœ€è¦å¾®è°ƒçš„å±‚ï¼Œå¹¶å†»ç»“å…¶ä»–å±‚ã€‚4) ä½¿ç”¨ä¿®è®¢æ„å›¾é¢„æµ‹æ•°æ®é›†å¯¹é€‰æ‹©çš„å±‚è¿›è¡Œå¾®è°ƒã€‚5) ä½¿ç”¨å¾®è°ƒåçš„LLMè¿›è¡Œä¿®è®¢æ„å›¾é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šIR-Tuningçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨æ€å±‚é€‰æ‹©ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„PEFTæ–¹æ³•ï¼ˆå¦‚LoRAã€Adapterç­‰ï¼‰ä¸åŒï¼ŒIR-Tuningä¸æ˜¯éšæœºé€‰æ‹©æˆ–é¢„å®šä¹‰éœ€è¦å¾®è°ƒçš„å±‚ï¼Œè€Œæ˜¯æ ¹æ®æ¢¯åº¦èŒƒæ•°åŠ¨æ€åœ°é€‰æ‹©ã€‚è¿™ç§åŠ¨æ€é€‰æ‹©ç­–ç•¥èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«å¯¹ç‰¹å®šä»»åŠ¡é‡è¦çš„å±‚ï¼Œä»è€Œæé«˜å¾®è°ƒæ•ˆç‡å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šIR-Tuningçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ¢¯åº¦èŒƒæ•°çš„è®¡ç®—æ–¹æ³•ï¼šè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†æŸç§ç‰¹å®šçš„æ¢¯åº¦èŒƒæ•°è®¡ç®—æ–¹æ³•ï¼Œä¾‹å¦‚L2èŒƒæ•°ã€‚2) å±‚é€‰æ‹©çš„é˜ˆå€¼ï¼šè®ºæ–‡éœ€è¦ç¡®å®šä¸€ä¸ªé˜ˆå€¼ï¼Œç”¨äºåˆ¤æ–­å“ªäº›å±‚çš„æ¢¯åº¦èŒƒæ•°è¶³å¤Ÿå¤§ï¼Œéœ€è¦è¿›è¡Œå¾®è°ƒã€‚3) å¾®è°ƒçš„ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡ï¼šè®ºæ–‡éœ€è¦é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨ï¼ˆå¦‚AdamWï¼‰å’Œå­¦ä¹ ç‡ï¼Œä»¥ä¿è¯å¾®è°ƒçš„ç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚4) æŸå¤±å‡½æ•°ï¼šè®ºæ–‡éœ€è¦é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°æ¥è¡¡é‡é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒIR-Tuningåœ¨æ–‡æœ¬ä¿®è®¢æ„å›¾é¢„æµ‹ä»»åŠ¡ä¸Šä¼˜äºå¤šä¸ªå±‚çº§PEFTåŸºçº¿æ–¹æ³•ã€‚IR-Tuningåœ¨ä¿æŒè¾ƒä½GPUå†…å­˜æ¶ˆè€—çš„åŒæ—¶ï¼Œå®ç°äº†å¿«é€Ÿæ”¶æ•›ï¼Œå¹¶ä¸”åœ¨å°å‹ä¿®è®¢è¯­æ–™åº“ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚å‡†ç¡®ç‡ã€F1å€¼ç­‰ï¼‰å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ–‡æœ¬ç¼–è¾‘è¾…åŠ©ã€æœºå™¨ç¿»è¯‘è´¨é‡è¯„ä¼°ã€ä»£ç å®¡æŸ¥ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®é¢„æµ‹æ–‡æœ¬ä¿®è®¢æ„å›¾ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›æ–‡æœ¬ï¼Œæé«˜æ–‡æœ¬è´¨é‡å’Œæ²Ÿé€šæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚æƒ…æ„Ÿåˆ†æã€ä¸»é¢˜åˆ†ç±»ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown extraordinary success across various text generation tasks; however, their potential for simple yet essential text classification remains underexplored, as LLM pre-training tends to emphasize generation over classification. While LLMs with instruction tuning can transform classification into a generation task, they often struggle to categorize nuanced texts. One such example is text revision, which involves nuanced edits between pairs of texts. Although simply fine-tuning LLMs for revision classification seems plausible, it requires a large amount of revision annotations, which are exceptionally expensive and scarce in the community. To address this issue, we introduce a plug-and-play layer-wise parameter-efficient fine-tuning (PEFT) framework, i.e., IR-Tuning, which fine-tunes a subset of important LLM layers that are dynamically selected based on their gradient norm distribution, while freezing those of redundant layers. Extensive experiments suggest that IR-Tuning surpasses several layer-wise PEFT baselines over diverse text revisions, while achieving fast convergence, low GPU memory consumption, and effectiveness on small revision corpora.

