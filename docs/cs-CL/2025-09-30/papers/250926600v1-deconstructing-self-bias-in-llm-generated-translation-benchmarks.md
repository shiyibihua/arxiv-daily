---
layout: default
title: Deconstructing Self-Bias in LLM-generated Translation Benchmarks
---

# Deconstructing Self-Bias in LLM-generated Translation Benchmarks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26600" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26600v1</a>
  <a href="https://arxiv.org/pdf/2509.26600.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26600v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26600v1', 'Deconstructing Self-Bias in LLM-generated Translation Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenda Xu, Sweta Agrawal, VilÃ©m Zouhar, Markus Freitag, Daniel Deutsch

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMç”Ÿæˆç¿»è¯‘è¯„æµ‹åŸºå‡†ä¸­çš„è‡ªåè§é—®é¢˜ï¼Œå¹¶æå‡ºç¼“è§£ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºå™¨ç¿»è¯‘` `è‡ªåŠ¨è¯„ä¼°` `åŸºå‡†æµ‹è¯•` `è‡ªåè§` `ä½èµ„æºè¯­è¨€` `æ–‡æœ¬å¤šæ ·æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¿»è¯‘åŸºå‡†ä¾èµ–äººå·¥ï¼Œæˆæœ¬é«˜ä¸”é€Ÿåº¦æ…¢ï¼ŒLLMè‡ªåŠ¨ç”ŸæˆåŸºå‡†æˆä¸ºä¸€ç§æœ‰æ½œåŠ›çš„æ›¿ä»£æ–¹æ¡ˆã€‚
2. è¯¥ç ”ç©¶æ­ç¤ºäº†LLMç”ŸæˆåŸºå‡†å­˜åœ¨ä¸¥é‡çš„è‡ªåè§é—®é¢˜ï¼Œå³åè¢’ç”Ÿæˆè¯¥åŸºå‡†çš„æ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè‡ªåè§æºäºæµ‹è¯•æ•°æ®å’Œè¯„ä¼°æ–¹æ³•ï¼Œå¹¶å—æºè¯­è¨€ç”Ÿæˆèƒ½åŠ›å’Œæ–‡æœ¬å¤šæ ·æ€§çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€æ¸é¥±å’Œç°æœ‰åŸºå‡†ï¼Œä½¿ç”¨LLMè‡ªåŠ¨åˆ›å»ºåŸºå‡†ï¼ˆLLMä½œä¸ºåŸºå‡†ï¼‰å·²æˆä¸ºä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä»¥å–ä»£ç¼“æ…¢ä¸”æ˜‚è´µçš„äººå·¥ç®¡ç†ã€‚è™½ç„¶è¿™äº›ç”Ÿæˆçš„æµ‹è¯•é›†æœ‰æ½œåŠ›ä»¥ä½æˆæœ¬å¯¹æ¨¡å‹è¿›è¡Œæ’åï¼Œä½†æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªå…³é”®ç¼ºé™·ã€‚LLMç”Ÿæˆçš„åŸºå‡†ç³»ç»Ÿæ€§åœ°åè¢’åˆ›å»ºè¯¥åŸºå‡†çš„æ¨¡å‹ï¼Œå®ƒä»¬åœ¨ä½èµ„æºè¯­è¨€åˆ°è‹±è¯­çš„ç¿»è¯‘ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‡ªæˆ‘åè§ã€‚æˆ‘ä»¬å±•ç¤ºäº†å…³äºLLMè‡ªåŠ¨åŸºå‡†æµ‹è¯•ç¿»è¯‘çš„ä¸‰ä¸ªå…³é”®å‘ç°ï¼šé¦–å…ˆï¼Œè¿™ç§åè§æºäºä¸¤ä¸ªæ¥æºï¼šç”Ÿæˆçš„æµ‹è¯•æ•°æ®ï¼ˆLLMä½œä¸ºæµ‹è¯•é›†ï¼‰å’Œè¯„ä¼°æ–¹æ³•ï¼ˆLLMä½œä¸ºè¯„ä¼°å™¨ï¼‰ï¼Œå®ƒä»¬çš„ç»„åˆæ”¾å¤§äº†è¿™ç§æ•ˆåº”ã€‚å…¶æ¬¡ï¼ŒLLMä½œä¸ºåŸºå‡†çš„è‡ªæˆ‘åè§å—åˆ°æ¨¡å‹åœ¨æºè¯­è¨€ä¸­çš„ç”Ÿæˆèƒ½åŠ›çš„ä¸¥é‡å½±å“ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°åœ¨è‹±è¯­ç¿»è¯‘ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹ç”Ÿæˆç³»ç»Ÿå¾—åˆ°å¼€å‘çš„åè§æ¯”åœ¨è‹±è¯­ç¿»è¯‘ä»»åŠ¡ä¸­æ›´ä¸ºæ˜æ˜¾ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°æºæ–‡æœ¬ä¸­ä½å¤šæ ·æ€§æ˜¯è‡ªæˆ‘åè§çš„ä¸€ä¸ªåŸå› ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œæé«˜è¿™äº›ç”Ÿæˆçš„æºæ–‡æœ¬çš„å¤šæ ·æ€§å¯ä»¥å‡è½»ä¸€äº›è§‚å¯Ÿåˆ°çš„è‡ªæˆ‘åè§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMè‡ªåŠ¨ç”Ÿæˆç¿»è¯‘åŸºå‡†æ—¶å­˜åœ¨çš„è‡ªåè§é—®é¢˜ã€‚ç°æœ‰çš„äººå·¥åŸºå‡†æ„å»ºæˆæœ¬é«˜æ˜‚ï¼Œè€Œåˆ©ç”¨LLMè‡ªåŠ¨ç”ŸæˆåŸºå‡†è™½ç„¶é™ä½äº†æˆæœ¬ï¼Œä½†å­˜åœ¨ç³»ç»Ÿæ€§åœ°åè¢’ç”ŸæˆåŸºå‡†æ¨¡å‹çš„ç¼ºé™·ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ï¼Œæ— æ³•çœŸå®åæ˜ æ¨¡å‹çš„ç¿»è¯‘èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ·±å…¥åˆ†æLLMç”ŸæˆåŸºå‡†ä¸­è‡ªåè§çš„æ¥æºï¼Œå¹¶æ¢ç©¶å½±å“è‡ªåè§çš„å› ç´ ã€‚é€šè¿‡å®éªŒåˆ†æï¼Œç¡®å®šè‡ªåè§æ¥æºäºç”Ÿæˆçš„æµ‹è¯•æ•°æ®å’Œè¯„ä¼°æ–¹æ³•ï¼Œå¹¶å—æºè¯­è¨€ç”Ÿæˆèƒ½åŠ›å’Œæ–‡æœ¬å¤šæ ·æ€§çš„å½±å“ã€‚åŸºäºæ­¤ï¼Œæå‡ºé€šè¿‡æé«˜æºæ–‡æœ¬å¤šæ ·æ€§æ¥ç¼“è§£è‡ªåè§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶ä¸»è¦é€šè¿‡å®éªŒåˆ†ææ¥æ­ç¤ºå’Œé‡åŒ–è‡ªåè§ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä¸åŒçš„LLMç”Ÿæˆç¿»è¯‘æµ‹è¯•é›†ï¼›2) ä½¿ç”¨ä¸åŒçš„LLMä½œä¸ºè¯„ä¼°å™¨å¯¹ç¿»è¯‘ç»“æœè¿›è¡Œè¯„ä¼°ï¼›3) åˆ†æè¯„ä¼°ç»“æœï¼Œé‡åŒ–è‡ªåè§ç¨‹åº¦ï¼›4) æ¢ç©¶æºè¯­è¨€ç”Ÿæˆèƒ½åŠ›å’Œæ–‡æœ¬å¤šæ ·æ€§å¯¹è‡ªåè§çš„å½±å“ï¼›5) æå‡ºé€šè¿‡æé«˜æºæ–‡æœ¬å¤šæ ·æ€§æ¥ç¼“è§£è‡ªåè§çš„ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†LLMè‡ªåŠ¨ç”Ÿæˆç¿»è¯‘åŸºå‡†ä¸­æ™®éå­˜åœ¨çš„è‡ªåè§é—®é¢˜ï¼Œå¹¶æ·±å…¥åˆ†æäº†è‡ªåè§çš„æ¥æºå’Œå½±å“å› ç´ ã€‚ä¸ä»¥å¾€ç ”ç©¶ä¸»è¦å…³æ³¨åŸºå‡†çš„æ„å»ºæ–¹æ³•ä¸åŒï¼Œè¯¥ç ”ç©¶å…³æ³¨åŸºå‡†çš„è¯„ä¼°åå·®ï¼Œä¸ºæ„å»ºæ›´å¯é çš„è‡ªåŠ¨è¯„ä¼°åŸºå‡†æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åœ¨äºå®éªŒåˆ†æçš„è®¾è®¡ã€‚é€šè¿‡æ§åˆ¶å˜é‡ï¼Œåˆ†åˆ«è€ƒå¯Ÿäº†ç”Ÿæˆæµ‹è¯•é›†çš„LLMã€è¯„ä¼°LLMä»¥åŠæºè¯­è¨€ç”Ÿæˆèƒ½åŠ›å’Œæ–‡æœ¬å¤šæ ·æ€§å¯¹è‡ªåè§çš„å½±å“ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡æ¯”è¾ƒä¸åŒLLMç”Ÿæˆçš„æµ‹è¯•é›†å¯¹åŒä¸€ç¿»è¯‘æ¨¡å‹çš„è¯„ä¼°ç»“æœï¼Œæ¥é‡åŒ–ç”Ÿæˆæµ‹è¯•é›†å¸¦æ¥çš„è‡ªåè§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†æé«˜æºæ–‡æœ¬å¤šæ ·æ€§çš„æ–¹æ³•ï¼Œä¾‹å¦‚ä½¿ç”¨ä¸åŒçš„promptæˆ–æ•°æ®å¢å¼ºæŠ€æœ¯ï¼Œæ¥ç¼“è§£è‡ªåè§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶è¡¨æ˜ï¼ŒLLMç”Ÿæˆçš„åŸºå‡†ä¼šç³»ç»Ÿæ€§åœ°åè¢’ç”Ÿæˆè¯¥åŸºå‡†çš„æ¨¡å‹ã€‚è‡ªåè§æ¥æºäºæµ‹è¯•æ•°æ®å’Œè¯„ä¼°æ–¹æ³•ï¼Œä¸”åœ¨ä½èµ„æºè¯­è¨€åˆ°è‹±è¯­çš„ç¿»è¯‘ä»»åŠ¡ä¸­æ›´ä¸ºæ˜æ˜¾ã€‚æé«˜æºæ–‡æœ¬çš„å¤šæ ·æ€§å¯ä»¥æœ‰æ•ˆç¼“è§£è‡ªåè§ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡å¢åŠ æºæ–‡æœ¬çš„å¤šæ ·æ€§ï¼Œå¯ä»¥é™ä½æ¨¡å‹å¯¹è‡ªå·±ç”Ÿæˆå†…å®¹çš„è¿‡åº¦åå¥½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ”¹è¿›LLMè‡ªåŠ¨ç”ŸæˆåŸºå‡†çš„æ„å»ºæ–¹æ³•ï¼Œæé«˜ç¿»è¯‘æ¨¡å‹è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚é€šè¿‡é™ä½è‡ªåè§ï¼Œå¯ä»¥æ›´å…¬å¹³åœ°æ¯”è¾ƒä¸åŒç¿»è¯‘æ¨¡å‹çš„æ€§èƒ½ï¼Œä¿ƒè¿›ç¿»è¯‘æŠ€æœ¯çš„è¿›æ­¥ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶çš„æ€è·¯å’Œæ–¹æ³•ä¹Ÿå¯ä»¥æ¨å¹¿åˆ°å…¶ä»–è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„è‡ªåŠ¨åŸºå‡†æ„å»ºä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) begin to saturate existing benchmarks, automated benchmark creation using LLMs (LLM as a benchmark) has emerged as a scalable alternative to slow and costly human curation. While these generated test sets have to potential to cheaply rank models, we demonstrate a critical flaw. LLM generated benchmarks systematically favor the model that created the benchmark, they exhibit self bias on low resource languages to English translation tasks. We show three key findings on automatic benchmarking of LLMs for translation: First, this bias originates from two sources: the generated test data (LLM as a testset) and the evaluation method (LLM as an evaluator), with their combination amplifying the effect. Second, self bias in LLM as a benchmark is heavily influenced by the model's generation capabilities in the source language. For instance, we observe more pronounced bias in into English translation, where the model's generation system is developed, than in out of English translation tasks. Third, we observe that low diversity in source text is one attribution to self bias. Our results suggest that improving the diversity of these generated source texts can mitigate some of the observed self bias.

