---
layout: default
title: VietBinoculars: A Zero-Shot Approach for Detecting Vietnamese LLM-Generated Text
---

# VietBinoculars: A Zero-Shot Approach for Detecting Vietnamese LLM-Generated Text

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26189" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26189v1</a>
  <a href="https://arxiv.org/pdf/2509.26189.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26189v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26189v1', 'VietBinoculars: A Zero-Shot Approach for Detecting Vietnamese LLM-Generated Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Trieu Hai Nguyen, Sivaswamy Akilesh

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 27 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VietBinocularsï¼šä¸€ç§é›¶æ ·æœ¬è¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹` `é›¶æ ·æœ¬å­¦ä¹ ` `è¶Šå—è¯­å¤„ç†` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ–‡æœ¬åˆ†ç±»` `Binocularsæ–¹æ³•` `å…¨å±€é˜ˆå€¼ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŒºåˆ†äººç±»æ’°å†™æ–‡æœ¬å’ŒLLMç”Ÿæˆæ–‡æœ¬æ˜¯ä¸€é¡¹æŒ‘æˆ˜ï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨é¢å¯¹å¤æ‚å’Œå¤šæ ·åŒ–çš„LLMç”Ÿæˆæ–‡æœ¬æ—¶æ•ˆæœä¸ä½³ã€‚
2. VietBinocularsé€šè¿‡ä¼˜åŒ–å…¨å±€é˜ˆå€¼æ”¹è¿›äº†Binocularsæ–¹æ³•ï¼Œä¸“é—¨ç”¨äºå¢å¼ºè¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬çš„æ£€æµ‹èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVietBinocularsåœ¨å¤šä¸ªé¢†åŸŸå¤–æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬å•†ä¸šæ£€æµ‹å·¥å…·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºTransformeræ¶æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•å¸¦æ¥äº†ä¸€ç³»åˆ—å…³é”®æŒ‘æˆ˜ï¼Œå…¶ä¸­ä¹‹ä¸€æ˜¯åŒºåˆ†äººå·¥æ’°å†™çš„æ–‡æœ¬å’ŒLLMç”Ÿæˆçš„æ–‡æœ¬ã€‚éšç€LLMç”Ÿæˆçš„æ–‡æœ¬å†…å®¹å˜å¾—è¶Šæ¥è¶Šå¤æ‚ï¼Œå¹¶ä¸”è¶Šæ¥è¶Šåƒäººç±»å†™ä½œï¼Œä¼ ç»Ÿçš„æ£€æµ‹æ–¹æ³•æ­£å˜å¾—è¶Šæ¥è¶Šæ— æ•ˆï¼Œç‰¹åˆ«æ˜¯éšç€LLMçš„æ•°é‡å’Œå¤šæ ·æ€§ä¸æ–­å¢é•¿ï¼Œæ–°çš„æ¨¡å‹å’Œç‰ˆæœ¬ä»¥æƒŠäººçš„é€Ÿåº¦å‘å¸ƒã€‚æœ¬ç ”ç©¶æå‡ºäº†VietBinocularsï¼Œè¿™æ˜¯ä¸€ç§å¯¹Binocularsæ–¹æ³•çš„æ”¹è¿›ï¼Œé€šè¿‡ä¼˜åŒ–å…¨å±€é˜ˆå€¼æ¥å¢å¼ºè¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬çš„æ£€æµ‹ã€‚æˆ‘ä»¬æ„å»ºäº†æ–°çš„è¶Šå—è¯­AIç”Ÿæˆæ•°æ®é›†ï¼Œä»¥ç¡®å®šVietBinocularsçš„æœ€ä½³é˜ˆå€¼å¹¶å®ç°åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVietBinocularsåœ¨å¤šä¸ªé¢†åŸŸå¤–æ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡ã€F1åˆ†æ•°å’ŒAUCå‡è¶…è¿‡99%ã€‚å®ƒä¼˜äºåŸå§‹çš„Binocularsæ¨¡å‹ã€ä¼ ç»Ÿçš„æ£€æµ‹æ–¹æ³•å’Œå…¶ä»–æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ZeroGPTå’ŒDetectGPTç­‰å•†ä¸šå·¥å…·ï¼Œå°¤å…¶æ˜¯åœ¨ç»è¿‡ä¸“é—¨ä¿®æ”¹çš„æç¤ºç­–ç•¥ä¸‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¶Šå—è¯­ç¯å¢ƒä¸‹ï¼ŒåŒºåˆ†äººå·¥æ’°å†™çš„æ–‡æœ¬å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„æ–‡æœ¬è¿™ä¸€é—®é¢˜ã€‚ç°æœ‰çš„æ£€æµ‹æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¼ ç»Ÿæ–¹æ³•å’Œä¸€äº›å•†ä¸šå·¥å…·ï¼Œåœ¨é¢å¯¹æ—¥ç›Šå¤æ‚å’Œå¤šæ ·åŒ–çš„LLMç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œæ•ˆæœä¸ä½³ï¼Œéš¾ä»¥æœ‰æ•ˆåŒºåˆ†ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—æ€§æç¤ºç­–ç•¥ä¸‹ï¼Œæ€§èƒ½ä¼šæ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ”¹è¿›ç°æœ‰çš„Binocularsæ–¹æ³•ï¼Œé€šè¿‡é’ˆå¯¹è¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬çš„ç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼Œç‰¹åˆ«æ˜¯ä¼˜åŒ–å…¨å±€é˜ˆå€¼ï¼Œä»è€Œæé«˜æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨åˆ©ç”¨LLMç”Ÿæˆæ–‡æœ¬ä¸äººç±»æ’°å†™æ–‡æœ¬åœ¨ç»Ÿè®¡ç‰¹å¾ä¸Šçš„å·®å¼‚ï¼Œå³ä½¿åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ä¹Ÿèƒ½æœ‰æ•ˆå·¥ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVietBinocularsæ–¹æ³•åŸºäºåŸå§‹çš„Binocularsæ¡†æ¶ï¼Œä½†é’ˆå¯¹è¶Šå—è¯­è¿›è¡Œäº†è°ƒæ•´ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1ï¼‰æ–‡æœ¬é¢„å¤„ç†ï¼›2ï¼‰ç‰¹å¾æå–ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºn-gramçš„ç»Ÿè®¡ç‰¹å¾ï¼‰ï¼›3ï¼‰ä½¿ç”¨ä¼˜åŒ–çš„å…¨å±€é˜ˆå€¼è¿›è¡Œåˆ¤åˆ«ï¼ŒåŒºåˆ†æ–‡æœ¬æ˜¯äººå·¥æ’°å†™è¿˜æ˜¯ç”±LLMç”Ÿæˆã€‚è®ºæ–‡æ„å»ºäº†æ–°çš„è¶Šå—è¯­AIç”Ÿæˆæ•°æ®é›†ï¼Œç”¨äºç¡®å®šæœ€ä½³é˜ˆå€¼å’Œè¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºé’ˆå¯¹è¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬çš„ç‰¹æ€§ï¼Œå¯¹Binocularsæ–¹æ³•çš„å…¨å±€é˜ˆå€¼è¿›è¡Œäº†ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ„å»ºäº†æ–°çš„è¶Šå—è¯­AIç”Ÿæˆæ•°æ®é›†ï¼Œè¿™ä¸ºè¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹çš„ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚è¿™ç§é’ˆå¯¹ç‰¹å®šè¯­è¨€çš„ä¼˜åŒ–æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ï¼Œå› ä¸ºç°æœ‰æ–¹æ³•é€šå¸¸æ˜¯é€šç”¨çš„ï¼Œæ²¡æœ‰é’ˆå¯¹ç‰¹å®šè¯­è¨€çš„ç‰¹æ€§è¿›è¡Œè°ƒæ•´ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰æ„å»ºé«˜è´¨é‡çš„è¶Šå—è¯­AIç”Ÿæˆæ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ï¼›2ï¼‰æ¢ç´¢ä¸åŒçš„ç‰¹å¾æå–æ–¹æ³•ï¼Œå¹¶é€‰æ‹©æœ€é€‚åˆè¶Šå—è¯­LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹çš„ç‰¹å¾ï¼›3ï¼‰ä½¿ç”¨è¯¥æ•°æ®é›†ç¡®å®šVietBinocularsçš„æœ€ä½³å…¨å±€é˜ˆå€¼ï¼Œä»¥æœ€å¤§åŒ–æ£€æµ‹æ€§èƒ½ã€‚å…·ä½“çš„é˜ˆå€¼ä¼˜åŒ–æ–¹æ³•å’Œç‰¹å¾é€‰æ‹©ç­–ç•¥åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVietBinocularsåœ¨å¤šä¸ªé¢†åŸŸå¤–æ•°æ®é›†ä¸Šå–å¾—äº†è¶…è¿‡99%çš„å‡†ç¡®ç‡ã€F1åˆ†æ•°å’ŒAUCï¼Œæ˜¾è‘—ä¼˜äºåŸå§‹çš„Binocularsæ¨¡å‹ã€ä¼ ç»Ÿçš„æ£€æµ‹æ–¹æ³•ä»¥åŠZeroGPTå’ŒDetectGPTç­‰å•†ä¸šå·¥å…·ã€‚å°¤å…¶æ˜¯åœ¨ç»è¿‡ä¸“é—¨ä¿®æ”¹çš„æç¤ºç­–ç•¥ä¸‹ï¼ŒVietBinocularsçš„ä¼˜åŠ¿æ›´åŠ æ˜æ˜¾ï¼Œè¡¨æ˜å…¶å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼ŒåŒ…æ‹¬ï¼šå†…å®¹å®¡æ ¸ã€å­¦æœ¯è¯šä¿¡æ£€æµ‹ã€æ–°é—»çœŸå®æ€§éªŒè¯ç­‰ã€‚é€šè¿‡è‡ªåŠ¨æ£€æµ‹LLMç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¯ä»¥å¸®åŠ©è¯†åˆ«å’Œè¿‡æ»¤è™šå‡ä¿¡æ¯ã€é˜²æ­¢å­¦æœ¯å‰½çªƒï¼Œå¹¶æé«˜åœ¨çº¿å†…å®¹çš„è´¨é‡å’Œå¯ä¿¡åº¦ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è¯­è¨€ï¼Œå¹¶ä¸å…¶ä»–æ£€æµ‹æŠ€æœ¯ç›¸ç»“åˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„AIç”Ÿæˆå†…å®¹æ£€æµ‹ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid development research of Large Language Models (LLMs) based on transformer architectures raises key challenges, one of them being the task of distinguishing between human-written text and LLM-generated text. As LLM-generated textual content, becomes increasingly complex over time, and resembles human writing, traditional detection methods are proving less effective, especially as the number and diversity of LLMs continue to grow with new models and versions being released at a rapid pace. This study proposes VietBinoculars, an adaptation of the Binoculars method with optimized global thresholds, to enhance the detection of Vietnamese LLM-generated text. We have constructed new Vietnamese AI-generated datasets to determine the optimal thresholds for VietBinoculars and to enable benchmarking. The results from our experiments show results show that VietBinoculars achieves over 99\% in all two domains of accuracy, F1-score, and AUC on multiple out-of-domain datasets. It outperforms the original Binoculars model, traditional detection methods, and other state-of-the-art approaches, including commercial tools such as ZeroGPT and DetectGPT, especially under specially modified prompting strategies.

