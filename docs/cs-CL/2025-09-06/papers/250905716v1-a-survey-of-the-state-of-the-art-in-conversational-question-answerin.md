---
layout: default
title: A Survey of the State-of-the-Art in Conversational Question Answering Systems
---

# A Survey of the State-of-the-Art in Conversational Question Answering Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05716" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05716v1</a>
  <a href="https://arxiv.org/pdf/2509.05716.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05716v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05716v1', 'A Survey of the State-of-the-Art in Conversational Question Answering Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Manoj Madushanka Perera, Adnan Mahmood, Kasun Eranda Wijethilake, Fahmida Islam, Maryam Tahermazandarani, Quan Z. Sheng

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

**å¤‡æ³¨**: 42 pages, 12 figures, 4 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°æ€§ç ”ç©¶ï¼šå¯¹è¯å¼é—®ç­”ç³»ç»Ÿçš„å‰æ²¿æŠ€æœ¯è¿›å±•ä¸æœªæ¥æ–¹å‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹è¯å¼é—®ç­”` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `è¿ç§»å­¦ä¹ ` `ä¸Šä¸‹æ–‡ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ConvQAç³»ç»Ÿåœ¨å¤„ç†å¤æ‚å¯¹è¯å†å²ã€ç†è§£ç”¨æˆ·æ„å›¾å’Œç”Ÿæˆç›¸å…³ç­”æ¡ˆæ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè½®å¯¹è¯ä¸­ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ã€‚
2. æœ¬æ–‡é€šè¿‡åˆ†æConvQAç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼ˆå†å²é€‰æ‹©ã€é—®é¢˜ç†è§£ã€ç­”æ¡ˆé¢„æµ‹ï¼‰å’Œå…ˆè¿›çš„æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œç»¼è¿°äº†æœ€æ–°çš„ç ”ç©¶è¿›å±•å’ŒæŠ€æœ¯æ¡†æ¶ã€‚
3. æœ¬æ–‡åˆ†æäº†å…³é”®ConvQAæ•°æ®é›†ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†æœ‰ä»·å€¼çš„å‚è€ƒï¼Œä»¥æ¨åŠ¨ConvQAé¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å…¨é¢ç»¼è¿°äº†å¯¹è¯å¼é—®ç­”ï¼ˆConvQAï¼‰ç³»ç»Ÿçš„æœ€æ–°è¿›å±•ã€‚ConvQAç³»ç»Ÿå·²æˆä¸ºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é¢†åŸŸçš„æ ¸å¿ƒï¼Œæ¨åŠ¨äº†æœºå™¨è¿›è¡ŒåŠ¨æ€å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥å¯¹è¯çš„èƒ½åŠ›ã€‚è¿™äº›èƒ½åŠ›æ­£æ—¥ç›Šåº”ç”¨äºå®¢æˆ·æ”¯æŒã€æ•™è‚²ã€æ³•å¾‹å’ŒåŒ»ç–—ä¿å¥ç­‰é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä¿æŒè¿è´¯å’Œç›¸å…³çš„å¯¹è¯è‡³å…³é‡è¦ã€‚æœ¬æ–‡é¦–å…ˆè€ƒå¯ŸConvQAç³»ç»Ÿçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œå³å†å²é€‰æ‹©ã€é—®é¢˜ç†è§£å’Œç­”æ¡ˆé¢„æµ‹ï¼Œå¼ºè°ƒå®ƒä»¬åœ¨ç¡®ä¿å¤šè½®å¯¹è¯çš„è¿è´¯æ€§å’Œç›¸å…³æ€§æ–¹é¢çš„ç›¸äº’ä½œç”¨ã€‚è¿›ä¸€æ­¥æ¢è®¨äº†åŒ…æ‹¬å¼ºåŒ–å­¦ä¹ ã€å¯¹æ¯”å­¦ä¹ å’Œè¿ç§»å­¦ä¹ ç­‰å…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯åœ¨æé«˜ConvQAå‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢çš„åº”ç”¨ã€‚è¿˜æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚RoBERTaã€GPT-4ã€Gemini 2.0 Flashã€Mistral 7Bå’ŒLLaMA 3ï¼‰çš„å…³é”®ä½œç”¨ï¼Œå±•ç¤ºäº†å®ƒä»¬é€šè¿‡æ•°æ®å¯æ‰©å±•æ€§å’Œæ¶æ„è¿›æ­¥æ‰€äº§ç”Ÿçš„å½±å“ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¯¹å…³é”®çš„ConvQAæ•°æ®é›†è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œå¹¶æ€»ç»“äº†å¼€æ”¾çš„ç ”ç©¶æ–¹å‘ã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¿™é¡¹å·¥ä½œå…¨é¢æ¦‚è¿°äº†ConvQAçš„ç°çŠ¶ï¼Œå¹¶ä¸ºæŒ‡å¯¼è¯¥é¢†åŸŸçš„æœªæ¥å‘å±•æä¾›äº†å®è´µçš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¯¹è¯å¼é—®ç­”ï¼ˆConvQAï¼‰æ—¨åœ¨ä½¿æœºå™¨èƒ½å¤Ÿå‚ä¸å¤šè½®å¯¹è¯ï¼Œå¹¶æ ¹æ®å¯¹è¯å†å²å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºéš¾ä»¥å‡†ç¡®æ•æ‰å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´ç­”æ¡ˆä¸ç›¸å…³æˆ–ä¸è¿è´¯ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨å¤§è§„æ¨¡æ•°æ®å’Œå…ˆè¿›çš„è¯­è¨€æ¨¡å‹ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¯¹ConvQAç³»ç»Ÿçš„å„ä¸ªç»„æˆéƒ¨åˆ†è¿›è¡Œæ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬å†å²é€‰æ‹©ã€é—®é¢˜ç†è§£å’Œç­”æ¡ˆé¢„æµ‹ã€‚é€šè¿‡ç ”ç©¶ä¸åŒçš„æœºå™¨å­¦ä¹ æŠ€æœ¯å’Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿™äº›ç»„ä»¶ä¸­çš„åº”ç”¨ï¼Œä»è€Œå…¨é¢äº†è§£ConvQAç³»ç»Ÿçš„ç°çŠ¶å’Œæœªæ¥å‘å±•æ–¹å‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡çš„ç»¼è¿°æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) ConvQAç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶åˆ†æï¼›2) å…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼ˆå¦‚å¼ºåŒ–å­¦ä¹ ã€å¯¹æ¯”å­¦ä¹ ã€è¿ç§»å­¦ä¹ ï¼‰çš„åº”ç”¨ï¼›3) å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¦‚RoBERTaã€GPT-4ç­‰ï¼‰çš„å½±å“ï¼›4) å…³é”®ConvQAæ•°æ®é›†çš„åˆ†æï¼›5) æœªæ¥ç ”ç©¶æ–¹å‘çš„å±•æœ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå¯¹ConvQAé¢†åŸŸè¿›è¡Œäº†å…¨é¢çš„ç»¼è¿°ï¼Œæ¶µç›–äº†æœ€æ–°çš„ç ”ç©¶è¿›å±•å’ŒæŠ€æœ¯è¶‹åŠ¿ã€‚é€šè¿‡å¯¹ä¸åŒæ–¹æ³•çš„æ¯”è¾ƒå’Œåˆ†æï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬æ–‡å¯¹å„ç§ConvQAæ¨¡å‹å’ŒæŠ€æœ¯è¿›è¡Œäº†è¯¦ç»†çš„æè¿°ï¼ŒåŒ…æ‹¬æ¨¡å‹çš„æ¶æ„ã€æŸå¤±å‡½æ•°ã€è®­ç»ƒç­–ç•¥ç­‰ã€‚ä¾‹å¦‚ï¼Œæ–‡ç« è®¨è®ºäº†å¦‚ä½•ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¥ä¼˜åŒ–å¯¹è¯ç­–ç•¥ï¼Œå¦‚ä½•ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥æé«˜è¡¨ç¤ºå­¦ä¹ çš„è´¨é‡ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨è¿ç§»å­¦ä¹ æ¥åˆ©ç”¨é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æœ¬æ–‡é‡ç‚¹åˆ†æäº†RoBERTaã€GPT-4ã€Gemini 2.0 Flashã€Mistral 7Bå’ŒLLaMA 3ç­‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ConvQAä¸­çš„åº”ç”¨ï¼Œå±•ç¤ºäº†å®ƒä»¬åœ¨æ•°æ®å¯æ‰©å±•æ€§å’Œæ¶æ„æ”¹è¿›æ–¹é¢çš„ä¼˜åŠ¿ã€‚è¿™äº›æ¨¡å‹é€šè¿‡é¢„è®­ç»ƒå’Œå¾®è°ƒï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜ConvQAç³»ç»Ÿçš„æ€§èƒ½ï¼Œå¹¶åœ¨å„ç§ConvQAæ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ConvQAç³»ç»Ÿåœ¨å®¢æˆ·æœåŠ¡ã€æ•™è‚²ã€åŒ»ç–—ä¿å¥å’Œæ³•å¾‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ„å»ºæ™ºèƒ½å®¢æœæœºå™¨äººï¼Œæä¾›ä¸ªæ€§åŒ–æ•™è‚²è¾…å¯¼ï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­ï¼Œä»¥åŠå¸®åŠ©å¾‹å¸ˆè¿›è¡Œæ³•å¾‹ç ”ç©¶ã€‚é€šè¿‡æä¾›æ›´è‡ªç„¶å’Œé«˜æ•ˆçš„äº¤äº’æ–¹å¼ï¼ŒConvQAç³»ç»Ÿå¯ä»¥æ˜¾è‘—æé«˜å·¥ä½œæ•ˆç‡å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conversational Question Answering (ConvQA) systems have emerged as a pivotal area within Natural Language Processing (NLP) by driving advancements that enable machines to engage in dynamic and context-aware conversations. These capabilities are increasingly being applied across various domains, i.e., customer support, education, legal, and healthcare where maintaining a coherent and relevant conversation is essential. Building on recent advancements, this survey provides a comprehensive analysis of the state-of-the-art in ConvQA. This survey begins by examining the core components of ConvQA systems, i.e., history selection, question understanding, and answer prediction, highlighting their interplay in ensuring coherence and relevance in multi-turn conversations. It further investigates the use of advanced machine learning techniques, including but not limited to, reinforcement learning, contrastive learning, and transfer learning to improve ConvQA accuracy and efficiency. The pivotal role of large language models, i.e., RoBERTa, GPT-4, Gemini 2.0 Flash, Mistral 7B, and LLaMA 3, is also explored, thereby showcasing their impact through data scalability and architectural advancements. Additionally, this survey presents a comprehensive analysis of key ConvQA datasets and concludes by outlining open research directions. Overall, this work offers a comprehensive overview of the ConvQA landscape and provides valuable insights to guide future advancements in the field.

