---
layout: default
title: Semantic-guided Diverse Decoding for Large Language Model
---

# Semantic-guided Diverse Decoding for Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23601" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23601v2</a>
  <a href="https://arxiv.org/pdf/2506.23601.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23601v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23601v2', 'Semantic-guided Diverse Decoding for Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weijie Shi, Yue Cui, Yaguang Wu, Jingzhi Fang, Shibo Zhang, Mengze Li, Sirui Han, Jia Zhu, Jiajie Xu, Xiaofang Zhou

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-09-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­ä¹‰å¼•å¯¼çš„å¤šæ ·è§£ç æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰å¤šæ ·æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¤šæ ·è§£ç ` `è¯­ä¹‰å¼•å¯¼` `å¼ºåŒ–å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å®ç°è¯­ä¹‰å¤šæ ·æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¸»è¦é›†ä¸­äºè¯æ±‡å±‚é¢çš„å¤šæ ·æ€§ï¼Œé™åˆ¶äº†å¤šæ ·è§£ç çš„æœ‰æ•ˆæ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„SemDiDæ–¹æ³•é€šè¿‡åœ¨åµŒå…¥ç©ºé—´ä¸­ç›´æ¥æ“ä½œï¼Œç»“åˆæ­£äº¤å¼•å¯¼å’ŒåŠ¨æ€æ’æ–¥ç­‰æœºåˆ¶ï¼Œå®ç°äº†è¯­ä¹‰ä¸Šçš„æ˜¾è‘—åŒºåˆ†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSemDiDåœ¨å¤šä¸ªä»»åŠ¡ä¸Šæå‡äº†æœ€ä½³é€‰æ‹©è¦†ç›–ç‡ï¼Œå¹¶åŠ é€Ÿäº†è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒæ—¶æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹çš„å¤šæ ·è§£ç åœ¨éœ€è¦å¤šä¸ªè¯­ä¹‰ä¸Šä¸åŒçš„å“åº”çš„åº”ç”¨ä¸­è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•ä¸»è¦å®ç°è¯æ±‡è€Œéè¯­ä¹‰çš„å¤šæ ·æ€§ã€‚è¿™ä¸€å±€é™æ€§æ˜¾è‘—åˆ¶çº¦äº†æœ€ä½³é€‰æ‹©ç­–ç•¥ã€åŸºäºç»„çš„å¼ºåŒ–å­¦ä¹ å’Œæ•°æ®åˆæˆã€‚æœ¬æ–‡æå‡ºäº†è¯­ä¹‰å¼•å¯¼çš„å¤šæ ·è§£ç ï¼ˆSemDiDï¼‰ï¼Œè¯¥æ–¹æ³•ç›´æ¥åœ¨åµŒå…¥ç©ºé—´ä¸­æ“ä½œï¼Œé€šè¿‡æ­£äº¤æ–¹å‘å¼•å¯¼ã€åŠ¨æ€ç»„é—´æ’æ–¥å’Œä½ç½®å»åæ¦‚ç‡è¯„ä¼°ä¸‰ç§äº’è¡¥æœºåˆ¶å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§ã€‚å®éªŒè¡¨æ˜ï¼ŒSemDiDåœ¨å¤šä¸ªä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæœ€ä½³é€‰æ‹©è¦†ç›–ç‡æé«˜äº†1.4-5.2%ï¼ŒåŒæ—¶åŠ é€Ÿäº†RLHFè®­ç»ƒæ”¶æ•›15%ï¼Œå‡†ç¡®ç‡æé«˜äº†æœ€å¤š2.1%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šæ ·è§£ç ä¸­ç¼ºä¹è¯­ä¹‰å¤šæ ·æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è¯æ±‡å±‚é¢çš„å¤šæ ·æ€§ï¼Œæœªèƒ½æœ‰æ•ˆå®ç°è¯­ä¹‰ä¸Šçš„æ˜¾è‘—åŒºåˆ†ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSemDiDæ–¹æ³•é€šè¿‡åœ¨åµŒå…¥ç©ºé—´ä¸­ç›´æ¥è¿›è¡Œæ“ä½œï¼Œé‡‡ç”¨æ­£äº¤æ–¹å‘å¼•å¯¼ã€åŠ¨æ€ç»„é—´æ’æ–¥å’Œä½ç½®å»åæ¦‚ç‡è¯„ä¼°ä¸‰ç§æœºåˆ¶ï¼Œæ—¨åœ¨å¹³è¡¡ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ä¸å¤šæ ·æ€§ï¼Œä»è€Œç¡®ä¿è¯­ä¹‰ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ­£äº¤æ–¹å‘å¼•å¯¼ç”¨äºå¼•å¯¼ç”Ÿæˆæ–¹å‘ï¼ŒåŠ¨æ€ç»„é—´æ’æ–¥ç”¨äºå¢åŠ ç”Ÿæˆæ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰å·®å¼‚ï¼Œä½ç½®å»åæ¦‚ç‡è¯„ä¼°ç”¨äºä¼˜åŒ–ç”Ÿæˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šSemDiDçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åœ¨åµŒå…¥ç©ºé—´ä¸­ç›´æ¥æ“ä½œï¼Œé€šè¿‡ä¸‰ç§äº’è¡¥æœºåˆ¶å®ç°è¯­ä¹‰å¤šæ ·æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„è¯æ±‡å±‚é¢è°ƒæ•´æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒSemDiDé‡‡ç”¨è‡ªé€‚åº”å¢ç›Šå‡½æ•°å’Œçº¦æŸä¼˜åŒ–æ¥åè°ƒè´¨é‡å’Œå¤šæ ·æ€§ç›®æ ‡ï¼Œç¡®ä¿ç”Ÿæˆæ–‡æœ¬è¾¾åˆ°è´¨é‡é˜ˆå€¼å¹¶å®ç°æœ€å¤§è¯­ä¹‰åŒºåˆ†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSemDiDåœ¨å¤šä¸ªä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæœ€ä½³é€‰æ‹©è¦†ç›–ç‡æé«˜äº†1.4-5.2%ï¼ŒåŒæ—¶åŠ é€Ÿäº†RLHFè®­ç»ƒæ”¶æ•›15%ï¼Œå¹¶åœ¨å‡†ç¡®æ€§ä¸Šæå‡äº†æœ€å¤š2.1%ã€‚è¿™äº›ç»“æœæ˜¾ç¤ºäº†è¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¯¹è¯ç³»ç»Ÿã€å†…å®¹ç”Ÿæˆå’Œæ•°æ®åˆæˆç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿä¸ºéœ€è¦å¤šæ ·åŒ–å“åº”çš„åº”ç”¨æä¾›æ›´é«˜è´¨é‡çš„è§£å†³æ–¹æ¡ˆã€‚æœªæ¥ï¼ŒSemDiDæ–¹æ³•å¯èƒ½åœ¨æå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œä¸°å¯Œæ€§æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diverse decoding of large language models is crucial for applications requiring multiple semantically distinct responses, yet existing methods primarily achieve lexical rather than semantic diversity. This limitation significantly constrains Best-of-N strategies, group-based reinforcement learning, and data synthesis. While temperature sampling and diverse beam search modify token distributions or apply n-gram penalties, they fail to ensure meaningful semantic differentiation. We introduce Semantic-guided Diverse Decoding (SemDiD), operating directly in embedding space that balances quality with diversity through three complementary mechanisms: orthogonal directional guidance, dynamic inter-group repulsion, and position-debiased probability assessment. SemDiD harmonizes these competing objectives using adaptive gain functions and constraint optimization, ensuring both quality thresholds and maximal semantic differentiation. Experiments show SemDiD consistently outperforms existing methods, improving Best-of-N coverage by 1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15% while increasing accuracy by up to 2.1%.

