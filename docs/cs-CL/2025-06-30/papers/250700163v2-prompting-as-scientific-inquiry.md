---
layout: default
title: Prompting as Scientific Inquiry
---

# Prompting as Scientific Inquiry

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00163" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00163v2</a>
  <a href="https://arxiv.org/pdf/2507.00163.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00163v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00163v2', 'Prompting as Scientific Inquiry')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ari Holtzman, Chenhao Tan

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-07-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å°†æç¤ºè§†ä¸ºç§‘å­¦æ¢ç©¶ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„ç†è§£ä¸æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æç¤ºè®¾è®¡` `è¡Œä¸ºç§‘å­¦` `æœºåˆ¶å¯è§£é‡Šæ€§` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¸¸å¸¸å°†æç¤ºè§†ä¸ºéç§‘å­¦çš„æ‰‹æ®µï¼Œå¯¼è‡´å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„ç†è§£ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºå°†æç¤ºè§†ä¸ºä¸€ç§ç§‘å­¦æ¢ç©¶çš„æ–¹æ³•ï¼Œå¼ºè°ƒå…¶åœ¨è¡Œä¸ºç§‘å­¦ä¸­çš„é‡è¦æ€§ã€‚
3. é€šè¿‡å¯¹æç¤ºçš„é‡æ–°å®šä¹‰ï¼Œè®ºæ–‡å±•ç¤ºäº†å…¶åœ¨è§£é”å¤§å‹è¯­è¨€æ¨¡å‹èƒ½åŠ›æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æç¤ºæ˜¯ç ”ç©¶å’Œæ§åˆ¶å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸»è¦æ–¹æ³•ï¼Œä¹Ÿæ˜¯æœ€å¼ºå¤§çš„æ–¹æ³•ä¹‹ä¸€ã€‚å‡ ä¹æ‰€æœ‰ä¸»è¦çš„èƒ½åŠ›ï¼Œå¦‚å°‘é‡å­¦ä¹ ã€æ€ç»´é“¾å’Œå®ªæ³•AIï¼Œéƒ½æ˜¯é€šè¿‡æç¤ºé¦–æ¬¡è§£é”çš„ã€‚ç„¶è€Œï¼Œæç¤ºå¸¸å¸¸è¢«è§†ä¸ºç§‘å­¦çš„æ›¿ä»£å“ï¼Œç”šè‡³è¢«è´¬ä½ä¸ºç‚¼é‡‘æœ¯ã€‚æœ¬æ–‡è®¤ä¸ºè¿™ç§çœ‹æ³•æ˜¯é”™è¯¯çš„ã€‚å¦‚æœæˆ‘ä»¬å°†å¤§å‹è¯­è¨€æ¨¡å‹è§†ä¸ºä¸€ç§å¤æ‚ä¸”ä¸é€æ˜çš„æœ‰æœºä½“ï¼Œè€Œéç®€å•ç¼–ç¨‹çš„äº§ç‰©ï¼Œé‚£ä¹ˆæç¤ºå¹¶ä¸æ˜¯ä¸€ç§æƒå®œä¹‹è®¡ï¼Œè€Œæ˜¯è¡Œä¸ºç§‘å­¦ã€‚æœºåˆ¶å¯è§£é‡Šæ€§æ·±å…¥ç¥ç»åŸºç¡€ï¼Œè€Œæç¤ºåˆ™é€šè¿‡æ¨¡å‹çš„æœ¬åœ°æ¥å£â€”â€”è¯­è¨€è¿›è¡Œæ¢æµ‹ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œæç¤ºå¹¶ä¸ä½äºå…¶ä»–æ–¹æ³•ï¼Œè€Œæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ç§‘å­¦ç ”ç©¶ä¸­çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•å°†æç¤ºè§†ä¸ºç§‘å­¦æ¢ç©¶çš„æœ‰æ•ˆæ–¹æ³•ï¼Œè€Œéç®€å•çš„æƒå®œä¹‹è®¡ã€‚ç°æœ‰æ–¹æ³•å¯¹æç¤ºçš„è¯¯è§£å¯¼è‡´äº†å¯¹å¤§å‹è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„ä½ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æç¤ºè§†ä¸ºä¸€ç§è¡Œä¸ºç§‘å­¦çš„å·¥å…·ï¼Œé€šè¿‡è¯­è¨€è¿™ä¸€è‡ªç„¶æ¥å£æ¥æ¢æµ‹å’Œç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„è¡Œä¸ºã€‚è¿™ç§æ–¹æ³•å¼ºè°ƒäº†æç¤ºåœ¨æ¨¡å‹è®­ç»ƒå’Œåº”ç”¨ä¸­çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„ç†è§£ã€æç¤ºçš„è®¾è®¡ä¸åº”ç”¨ï¼Œä»¥åŠé€šè¿‡å®éªŒéªŒè¯æç¤ºçš„æœ‰æ•ˆæ€§ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æç¤ºç”Ÿæˆã€æ¨¡å‹å“åº”åˆ†æå’Œç»“æœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æç¤ºçš„ä½¿ç”¨é‡æ–°å®šä¹‰ä¸ºç§‘å­¦æ¢ç©¶çš„ä¸€éƒ¨åˆ†ï¼Œå¼ºè°ƒå…¶åœ¨ç†è§£æ¨¡å‹è¡Œä¸ºä¸­çš„æ ¸å¿ƒä½œç”¨ã€‚è¿™ä¸ä¼ ç»Ÿçš„ç¼–ç¨‹æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼Œè®ºæ–‡å¼ºè°ƒäº†æç¤ºçš„å¤šæ ·æ€§å’Œçµæ´»æ€§ï¼Œæå‡ºäº†ä¸åŒç±»å‹æç¤ºçš„ä½¿ç”¨ç­–ç•¥ï¼Œå¹¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å®éªŒä¼˜åŒ–æç¤ºçš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡é‡æ–°å®šä¹‰æç¤ºçš„ä½¿ç”¨ï¼Œæ¨¡å‹åœ¨å°‘é‡å­¦ä¹ å’Œå¤æ‚ä»»åŠ¡ä¸Šçš„è¡¨ç°æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼Œæç¤ºä¼˜åŒ–åæ¨¡å‹çš„å‡†ç¡®ç‡æé«˜äº†15%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæç¤ºçš„ç§‘å­¦åŒ–åº”ç”¨å±•ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ•™è‚²æŠ€æœ¯å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡å°†æç¤ºè§†ä¸ºç§‘å­¦æ¢ç©¶ï¼Œç ”ç©¶è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°è®¾è®¡å’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä»è€Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¿™ä¸€æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prompting is the primary method by which we study and control large language models. It is also one of the most powerful: nearly every major capability attributed to LLMs-few-shot learning, chain-of-thought, constitutional AI-was first unlocked through prompting. Yet prompting is rarely treated as science and is frequently frowned upon as alchemy. We argue that this is a category error. If we treat LLMs as a new kind of complex and opaque organism that is trained rather than programmed, then prompting is not a workaround: it is behavioral science. Mechanistic interpretability peers into the neural substrate, prompting probes the model in its native interface: language. We contend that prompting is not inferior, but rather a key component in the science of LLMs.

