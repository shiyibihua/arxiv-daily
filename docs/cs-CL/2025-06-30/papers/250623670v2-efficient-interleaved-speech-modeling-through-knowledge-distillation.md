---
layout: default
title: Efficient Interleaved Speech Modeling through Knowledge Distillation
---

# Efficient Interleaved Speech Modeling through Knowledge Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23670" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23670v2</a>
  <a href="https://arxiv.org/pdf/2506.23670.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23670v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23670v2', 'Efficient Interleaved Speech Modeling through Knowledge Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammadmahdi Nouriborji, Morteza Rohanian

**åˆ†ç±»**: cs.SD, cs.CL, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-10-21)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTinyWaveä»¥è§£å†³è¯­éŸ³ç”Ÿæˆæ¨¡å‹ä½“ç§¯ä¸å»¶è¿Ÿé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³ç”Ÿæˆ` `è’¸é¦è®­ç»ƒ` `å¤šæ¨¡æ€å˜æ¢å™¨` `æ¨¡å‹å‹ç¼©` `å®æ—¶åº”ç”¨` `ä½èµ„æºç¯å¢ƒ` `TinyWave` `è¯­éŸ³è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³ç”Ÿæˆæ¨¡å‹åœ¨ä½“ç§¯å’Œå»¶è¿Ÿæ–¹é¢å­˜åœ¨æ˜¾è‘—é™åˆ¶ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å±‚å¯¹é½è’¸é¦æŠ€æœ¯ï¼Œå‹ç¼©å¤§å‹å¤šæ¨¡æ€å˜æ¢å™¨ï¼Œæ„å»ºç´§å‡‘çš„è¯­éŸ³ç”Ÿæˆæ¨¡å‹TinyWaveã€‚
3. TinyWaveåœ¨å¤šä¸ªä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå‡†ç¡®ç‡æ¥è¿‘æ•™å¸ˆæ¨¡å‹ï¼Œä¸”åœ¨èµ„æºä½¿ç”¨ä¸Šæ›´ä¸ºé«˜æ•ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„è¯­éŸ³è¯­è¨€æ¨¡å‹åœ¨è®¸å¤šéƒ¨ç½²ç¯å¢ƒä¸­è¶…å‡ºäº†å¤§å°å’Œå»¶è¿Ÿçš„é™åˆ¶ã€‚æœ¬æ–‡é€šè¿‡å±‚å¯¹é½è’¸é¦æ„å»ºç´§å‡‘ä¸”è¡¨è¾¾åŠ›å¼ºçš„è¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼Œå‹ç¼©å¤§å‹å¤šæ¨¡æ€å˜æ¢å™¨çš„ä½“ç§¯è¾¾åˆ°3å€ï¼ŒåŒæ—¶æ€§èƒ½æŸå¤±æœ€å°ã€‚æˆ‘ä»¬æå‡ºäº†TinyWaveï¼Œä¸€ä¸ªåŒ…å«20äº¿å‚æ•°çš„æ¨¡å‹ç³»åˆ—ï¼Œæ”¯æŒè¯­éŸ³åˆ°è¯­éŸ³åŠäº¤é”™è¯­éŸ³æ–‡æœ¬ç”Ÿæˆï¼Œç»è¿‡50,000å°æ—¶å…¬å…±éŸ³é¢‘è®­ç»ƒã€‚TinyWaveåœ¨Libri-Lightä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå…¶å½’ä¸€åŒ–å›°æƒ‘åº¦ä¸æ•™å¸ˆæ¨¡å‹ç›¸å·®ä»…1.4ç‚¹ï¼Œåœ¨å£è¯­StoryClozeå’ŒSALMonä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡è¾¾åˆ°æ•™å¸ˆæ¨¡å‹çš„93-97%ã€‚è¿™äº›æ¨¡å‹é’ˆå¯¹å•†å“ç¡¬ä»¶è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé€‚ç”¨äºå®æ—¶å¯¹è¯ä»£ç†ã€è¾…åŠ©æŠ€æœ¯å’Œä½èµ„æºç¯å¢ƒã€‚æˆ‘ä»¬å‘å¸ƒäº†æ¨¡å‹ã€è®­ç»ƒä»£ç å’Œè¯„ä¼°è„šæœ¬ï¼Œä»¥æ”¯æŒå¯é‡å¤çš„ç´§å‡‘è¯­éŸ³ç”Ÿæˆç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰çš„è¯­éŸ³ç”Ÿæˆæ¨¡å‹é€šå¸¸ä½“ç§¯åºå¤§ï¼Œå»¶è¿Ÿé«˜ï¼Œéš¾ä»¥åœ¨å®æ—¶åº”ç”¨ä¸­éƒ¨ç½²ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºé€šè¿‡å±‚å¯¹é½è’¸é¦æŠ€æœ¯ï¼ŒåŒ¹é…éšè—çŠ¶æ€ã€æ³¨æ„åŠ›å›¾å’Œè½¯åŒ–çš„logitsï¼Œä»è€Œæœ‰æ•ˆå‹ç¼©å¤§å‹å¤šæ¨¡æ€å˜æ¢å™¨ï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½æŸå¤±åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTinyWaveæ¨¡å‹ç³»åˆ—ç”±å¤šä¸ªæ¨¡å—ç»„æˆï¼ŒåŒ…æ‹¬è¯­éŸ³ç”Ÿæˆæ¨¡å—å’Œäº¤é”™æ–‡æœ¬ç”Ÿæˆæ¨¡å—ï¼Œæ”¯æŒè¯­éŸ³å’Œæ··åˆè¯­éŸ³æ–‡æœ¬çš„ç”Ÿæˆã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†50,000å°æ—¶çš„å…¬å…±éŸ³é¢‘æ•°æ®ï¼Œç¡®ä¿æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå±‚å¯¹é½è’¸é¦æ–¹æ³•ï¼Œé€šè¿‡ç²¾ç¡®åŒ¹é…æ•™å¸ˆæ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºï¼Œæ˜¾è‘—æé«˜äº†å‹ç¼©æ•ˆç‡ï¼Œä¸ä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½æŸå¤±æ›´å°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒTinyWaveé‡‡ç”¨äº†20äº¿å‚æ•°çš„ç»“æ„ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è’¸é¦è¿‡ç¨‹ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œäº†å¤šç§è¶…å‚æ•°è°ƒä¼˜ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TinyWaveåœ¨Libri-Lightæ•°æ®é›†ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œå…¶å½’ä¸€åŒ–å›°æƒ‘åº¦ä»…æ¯”æ•™å¸ˆæ¨¡å‹é«˜å‡º1.4ç‚¹ï¼Œä¸”åœ¨å£è¯­StoryClozeå’ŒSALMonä»»åŠ¡ä¸­å‡†ç¡®ç‡è¾¾åˆ°93-97%ã€‚ä¸åŒç±»åŸºçº¿ç›¸æ¯”ï¼ŒTinyWaveåœ¨æ€§èƒ½ä¸Šæœ‰æ˜¾è‘—æå‡ï¼ŒåŒæ—¶åœ¨æ¨¡å‹ä½“ç§¯ä¸Šå®ç°äº†3å€çš„å‹ç¼©ï¼Œå±•ç°å‡ºä¼˜è¶Šçš„æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TinyWaveæ¨¡å‹çš„è®¾è®¡ä½¿å…¶åœ¨å®æ—¶å¯¹è¯ä»£ç†ã€è¾…åŠ©æŠ€æœ¯å’Œä½èµ„æºç¯å¢ƒä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶ç´§å‡‘çš„ç»“æ„å’Œé«˜æ•ˆçš„æ€§èƒ½èƒ½å¤Ÿæ”¯æŒå¤šç§è¯­éŸ³ç”Ÿæˆä»»åŠ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹æœ‰æœ›æ¨åŠ¨è¯­éŸ³äº¤äº’æŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæµç•…æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current speech language models exceed the size and latency constraints of many deployment environments. We build compact, expressive speech generation models through layer-aligned distillation, matching hidden states, attention maps, and softened logits to compress large multimodal transformers by 3x with minimal loss in performance. We introduce TinyWave, a family of 2B-parameter models for speech-to-speech and interleaved speech-text generation, trained on 50,000 hours of public audio. TinyWave supports (i) speech-only generation using phonetic or expressive tokens and (ii) mixed speech-text continuations. Evaluation on Libri-Light shows TinyWave within 1.4 normalized perplexity points of its teacher. Accuracy on spoken StoryCloze and SALMon reaches 93-97% of the teacher's performance, outperforming size-matched baselines. These models are optimized for deployment on commodity hardware, enabling applications in real-time conversational agents, assistive technologies, and low-resource environments. We release models, training code, and evaluation scripts to support reproducible research on compact, expressive speech generation.

