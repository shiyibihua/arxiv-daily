---
layout: default
title: User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs
---

# User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.05266" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.05266v1</a>
  <a href="https://arxiv.org/pdf/2507.05266.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.05266v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.05266v1', 'User Behavior Prediction as a Generic, Robust, Scalable, and Low-Cost Evaluation Strategy for Estimating Generalization in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sougata Saha, Monojit Choudhury

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”¨æˆ·è¡Œä¸ºé¢„æµ‹ä»¥è§£å†³LLMsæ³›åŒ–èƒ½åŠ›è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”¨æˆ·è¡Œä¸ºé¢„æµ‹` `æ³›åŒ–èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªæ€§åŒ–æ¨è` `æ•°æ®æ±¡æŸ“` `æ¨¡å‹è¯„ä¼°` `æ¨èç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æµ‹é‡LLMsçš„æ³›åŒ–èƒ½åŠ›æ—¶ï¼Œé¢ä¸´æ•°æ®æ±¡æŸ“å’Œè®­ç»ƒé˜¶æ®µæœªè§ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºç”¨æˆ·è¡Œä¸ºé¢„æµ‹ä½œä¸ºè¯„ä¼°LLMsæ³›åŒ–èƒ½åŠ›çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¼ºè°ƒå…¶å¯æ‰©å±•æ€§å’Œç¨³å¥æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨æ¨èä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æµ‹é‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ³›åŒ–èƒ½åŠ›é¢ä¸´æ•°æ®æ±¡æŸ“çš„æŒ‘æˆ˜ã€‚éšç€æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§å’Œè®¡ç®—æˆæœ¬çš„é™ä½ï¼Œç¡®ä¿ä»»åŠ¡å’Œæµ‹è¯•æ¡ˆä¾‹åœ¨è®­ç»ƒé˜¶æ®µæœªè§å‡ ä¹å˜å¾—ä¸å¯èƒ½ã€‚æœ¬æ–‡æå‡ºç”¨æˆ·è¡Œä¸ºé¢„æµ‹ä½œä¸ºä¸€ç§ç†è®ºä¸Šåˆç†ã€å¯æ‰©å±•ä¸”ç¨³å¥çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé‡ç‚¹åœ¨äºä¸ªæ€§åŒ–ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°æ¡†æ¶ï¼Œå¹¶åœ¨ç”µå½±å’ŒéŸ³ä¹æ¨èæ•°æ®é›†ä¸Šå¯¹GPT-4oã€GPT-4o-miniå’ŒLlama-3.1-8B-Instructè¿›è¡Œäº†æµ‹è¯•ã€‚ç»“æœæ˜¾ç¤ºï¼ŒGPT-4oçš„è¡¨ç°ä¼˜äºGPT-4o-miniå’ŒLlamaï¼Œä½†æ‰€æœ‰æ¨¡å‹ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ï¼Œå°¤å…¶æ˜¯Llamaã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ³›åŒ–èƒ½åŠ›è¯„ä¼°ä¸­çš„æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºçŸ¥è¯†æ£€ç´¢å’Œæ¨ç†ä»»åŠ¡ï¼Œä½†è¿™äº›ä»»åŠ¡å¹¶ä¸é€‚åˆè¯„ä¼°LLMsçš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºç”¨æˆ·è¡Œä¸ºé¢„æµ‹ä½œä¸ºä¸€ç§æ–°çš„è¯„ä¼°ç­–ç•¥ï¼Œè®¤ä¸ºå…¶åœ¨ä¸ªæ€§åŒ–æ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¹¶ä¸”ç†è®ºä¸Šæ›´ä¸ºåˆç†ã€å¯æ‰©å±•å’Œç¨³å¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç”¨æˆ·è¡Œä¸ºå»ºæ¨¡å’Œæ¨¡å‹è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†ç”¨æˆ·è¡Œä¸ºæ•°æ®ï¼Œç„¶ååˆ©ç”¨è¿™äº›æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œæœ€åè¯„ä¼°æ¨¡å‹åœ¨æ¨èä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†ç”¨æˆ·è¡Œä¸ºé¢„æµ‹å¼•å…¥LLMsçš„æ³›åŒ–èƒ½åŠ›è¯„ä¼°ä¸­ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„çŸ¥è¯†æ£€ç´¢å’Œæ¨ç†ä»»åŠ¡ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–ç”¨æˆ·è¡Œä¸ºé¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨å®éªŒä¸­ä½¿ç”¨äº†å¤šä¸ªæ¨èæ•°æ®é›†è¿›è¡ŒéªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oåœ¨ç”µå½±å’ŒéŸ³ä¹æ¨èä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºGPT-4o-miniå’ŒLlamaï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜GPT-4oçš„æ¨èå‡†ç¡®ç‡æ˜¾è‘—é«˜äºå…¶ä»–æ¨¡å‹ï¼Œå°½ç®¡æ‰€æœ‰æ¨¡å‹ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œå°¤å…¶æ˜¯Llamaã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€ç”¨æˆ·è¡Œä¸ºåˆ†æå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ”¹è¿›LLMsçš„æ³›åŒ–èƒ½åŠ›è¯„ä¼°ï¼Œèƒ½å¤Ÿæå‡æ¨èç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œç”¨æˆ·æ»¡æ„åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Measuring the generalization ability of Large Language Models (LLMs) is challenging due to data contamination. As models grow and computation becomes cheaper, ensuring tasks and test cases are unseen during training phases will become nearly impossible. We argue that knowledge-retrieval and reasoning tasks are not ideal for measuring generalization, as LLMs are not trained for specific tasks. Instead, we propose user behavior prediction, also a key aspect of personalization, as a theoretically sound, scalable, and robust alternative. We introduce a novel framework for this approach and test it on movie and music recommendation datasets for GPT-4o, GPT-4o-mini, and Llama-3.1-8B-Instruct. Results align with our framework's predictions, showing GPT-4o outperforms GPT-4o-mini and Llama, though all models have much room for improvement, especially Llama.

