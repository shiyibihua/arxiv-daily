---
layout: default
title: The Trilemma of Truth in Large Language Models
---

# The Trilemma of Truth in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23921" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23921v4</a>
  <a href="https://arxiv.org/pdf/2506.23921.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23921v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23921v4', 'The Trilemma of Truth in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Germans Savcisens, Tina Eliassi-Rad

**åˆ†ç±»**: cs.CL, cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-11-14)

**å¤‡æ³¨**: Camera-ready (non-archival) version accepted at the Mechanistic Interpretability Workshop at NeurIPS 2025. The main text is 10 pages long (plus 3 pages of references); supplementary material (58 pages) is included in the same PDF

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºsAwMILæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çœŸä¼ªæ€§éªŒè¯é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çœŸå®æ€§éªŒè¯` `å¤šå®ä¾‹å­¦ä¹ ` `ç¬¦åˆé¢„æµ‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éªŒè¯æ–¹æ³•å­˜åœ¨ç¼ºé™·ï¼Œæ— æ³•å¯é åœ°åˆ¤æ–­LLMsæ‰€ç¼–ç çŸ¥è¯†çš„çœŸå®æ€§ã€‚
2. æå‡ºçš„sAwMILæ¡†æ¶ç»“åˆäº†å¤šå®ä¾‹å­¦ä¹ å’Œç¬¦åˆé¢„æµ‹ï¼Œæ—¨åœ¨æ›´å‡†ç¡®åœ°åˆ†ç±»ä¿¡æ¯çš„çœŸå®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒsAwMILåœ¨å¤šä¸ªLLMsä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œæ­ç¤ºäº†çœŸä¸å‡ä¹‹é—´çš„ä¸å¯¹ç§°æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…¬ä¼—å¸¸å¸¸å°†äººç±»ç‰¹è´¨å½’äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¹¶å‡è®¾å®ƒä»¬â€œçŸ¥é“â€æŸäº›äº‹æƒ…ã€‚å®é™…ä¸Šï¼ŒLLMsåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç¼–ç çš„ä¿¡æ¯æ˜¯å†…éƒ¨çš„æ¦‚ç‡çŸ¥è¯†ã€‚æœ¬æ–‡ç ”ç©¶äº†ç°æœ‰çš„éªŒè¯è¿™äº›çŸ¥è¯†çœŸå®æ€§çš„æ–¹æ³•ï¼Œå¹¶è¯†åˆ«å‡ºå‡ ä¸ªå­˜åœ¨çš„å‡è®¾ç¼ºé™·ã€‚ä¸ºäº†è§£å†³è¿™äº›ç¼ºé™·ï¼Œæˆ‘ä»¬æå‡ºäº†sAwMILï¼ˆç¨€ç–æ„ŸçŸ¥å¤šå®ä¾‹å­¦ä¹ ï¼‰ï¼Œä¸€ä¸ªç»“åˆå¤šå®ä¾‹å­¦ä¹ ä¸ç¬¦åˆé¢„æµ‹çš„å¤šç±»æ¢æµ‹æ¡†æ¶ã€‚sAwMILåˆ©ç”¨LLMsçš„å†…éƒ¨æ¿€æ´»æ¥å°†é™ˆè¿°åˆ†ç±»ä¸ºçœŸã€å‡æˆ–ä¸ç¡®å®šã€‚æˆ‘ä»¬åœ¨16ä¸ªå¼€æºLLMsä¸Šè¯„ä¼°äº†sAwMILï¼ŒåŒ…æ‹¬é»˜è®¤å’ŒåŸºäºèŠå¤©çš„å˜ä½“ï¼Œä½¿ç”¨äº†ä¸‰ä¸ªæ–°åˆ›å»ºçš„æ•°æ®é›†ã€‚ç»“æœè¡¨æ˜ï¼Œå¸¸è§çš„æ¢æµ‹æ–¹æ³•æ— æ³•æä¾›å¯é çš„çœŸå®æ€§æ–¹å‘ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°ç”šè‡³ä¸å¦‚é›¶-shotæç¤ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ‰€ç¼–ç çŸ¥è¯†çš„çœŸå®æ€§éªŒè¯é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åˆ¤æ–­çœŸä¼ªæ€§æ—¶å­˜åœ¨å¤šç§å‡è®¾ç¼ºé™·ï¼Œå¯¼è‡´ç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šsAwMILæ¡†æ¶ç»“åˆå¤šå®ä¾‹å­¦ä¹ ä¸ç¬¦åˆé¢„æµ‹ï¼Œåˆ©ç”¨LLMsçš„å†…éƒ¨æ¿€æ´»ä¿¡æ¯æ¥åˆ†ç±»é™ˆè¿°çš„çœŸå®æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ï¼Œæä¾›æ›´å‡†ç¡®çš„åˆ†ç±»ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šsAwMILçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€å†…éƒ¨æ¿€æ´»æå–ã€å¤šå®ä¾‹å­¦ä¹ æ¨¡å—å’Œç¬¦åˆé¢„æµ‹æ¨¡å—ã€‚é¦–å…ˆæå–LLMsçš„å†…éƒ¨æ¿€æ´»ï¼Œç„¶åé€šè¿‡å¤šå®ä¾‹å­¦ä¹ è¿›è¡Œåˆ†ç±»ï¼Œæœ€åä½¿ç”¨ç¬¦åˆé¢„æµ‹æ¥è¯„ä¼°åˆ†ç±»çš„å¯é æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šsAwMILçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†å¤šå®ä¾‹å­¦ä¹ ä¸ç¬¦åˆé¢„æµ‹çš„æ–¹å¼ï¼Œä½¿å¾—å¯¹çœŸã€å‡å’Œä¸ç¡®å®šæ€§ä¿¡å·çš„åˆ†ç±»æ›´åŠ ç²¾ç¡®ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€åˆ†ç±»æ–¹å¼å½¢æˆäº†æ˜¾è‘—å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨sAwMILä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å¤šå®ä¾‹å­¦ä¹ çš„å®ä¾‹æ•°é‡å’Œç¬¦åˆé¢„æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºç»“åˆåˆ†ç±»å‡†ç¡®æ€§ä¸ä¸ç¡®å®šæ€§è¯„ä¼°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚å®éªŒä¸­ä½¿ç”¨çš„ç½‘ç»œç»“æ„ä¸ºåŸºäºTransformerçš„æ¶æ„ï¼Œé€‚åº”æ€§å¼ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒsAwMILåœ¨16ä¸ªå¼€æºLLMsä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ¢æµ‹æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†çœŸä¸å‡ä¿¡æ¯çš„ä¸å¯¹ç§°æ€§æ–¹é¢ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨æŸäº›è®¾ç½®ä¸‹ï¼ŒsAwMILçš„æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡äº†20%ï¼Œæ˜¾è‘—æé«˜äº†åˆ†ç±»çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€ä¿¡æ¯æ£€ç´¢å’Œè‡ªåŠ¨é—®ç­”ç³»ç»Ÿã€‚é€šè¿‡æé«˜å¯¹LLMsçŸ¥è¯†çœŸå®æ€§çš„éªŒè¯èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¢å¼ºç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œå¹¶æ¨åŠ¨æ›´å®‰å…¨çš„AIåº”ç”¨å¼€å‘ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½åœ¨æ³•å¾‹ã€åŒ»ç–—ç­‰éœ€è¦é«˜å‡†ç¡®æ€§çš„ä¿¡æ¯éªŒè¯é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The public often attributes human-like qualities to large language models (LLMs) and assumes they "know" certain things. In reality, LLMs encode information retained during training as internal probabilistic knowledge. This study examines existing methods for probing the veracity of that knowledge and identifies several flawed underlying assumptions. To address these flaws, we introduce sAwMIL (Sparse-Aware Multiple-Instance Learning), a multiclass probing framework that combines multiple-instance learning with conformal prediction. sAwMIL leverages internal activations of LLMs to classify statements as true, false, or neither. We evaluate sAwMIL across 16 open-source LLMs, including default and chat-based variants, on three new curated datasets. Our results show that (1) common probing methods fail to provide a reliable and transferable veracity direction and, in some settings, perform worse than zero-shot prompting; (2) truth and falsehood are not encoded symmetrically; and (3) LLMs encode a third type of signal that is distinct from both true and false.

