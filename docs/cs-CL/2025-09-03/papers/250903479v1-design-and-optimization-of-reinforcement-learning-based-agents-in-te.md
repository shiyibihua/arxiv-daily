---
layout: default
title: Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games
---

# Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03479" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03479v1</a>
  <a href="https://arxiv.org/pdf/2509.03479.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03479v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03479v1', 'Design and Optimization of Reinforcement Learning-Based Agents in Text-Based Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haonan Wang, Mingjia Zhao, Junfeng Sun, Wei Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

**å¤‡æ³¨**: 6 papges

**æœŸåˆŠ**: Copyright (c) 2025 International Journal of Computer Science and Information Technology International Journal of Computer Science and Information Technology International Journal of Computer Science and Information Technology

**DOI**: [10.62051/ijcsit.v5n2.02](https://doi.org/10.62051/ijcsit.v5n2.02)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–‡æœ¬æ¸¸æˆæ™ºèƒ½ä½“è®¾è®¡ä¸ä¼˜åŒ–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ–‡æœ¬æ¸¸æˆ` `å¼ºåŒ–å­¦ä¹ ` `æ·±åº¦å­¦ä¹ ` `ç­–ç•¥æ¢¯åº¦` `æ™ºèƒ½ä½“è®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡æœ¬æ¸¸æˆæ™ºèƒ½ä½“åœ¨ç†è§£å¤æ‚æ¸¸æˆç¯å¢ƒå’Œåˆ¶å®šæœ‰æ•ˆç­–ç•¥æ–¹é¢å­˜åœ¨æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨æ·±åº¦å­¦ä¹ æ„å»ºä¸–ç•Œæ¨¡å‹ï¼Œå¹¶ç»“åˆç­–ç•¥æ¢¯åº¦å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ™ºèƒ½ä½“ç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“åœ¨æ–‡æœ¬æ¸¸æˆä¸­çš„å®Œæˆç‡å’Œèƒœç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ™ºèƒ½ä½“è®¾è®¡å’Œå­¦ä¹ æ–¹æ³•ï¼Œåº”ç”¨äºæ–‡æœ¬æ¸¸æˆé¢†åŸŸï¼Œå¹¶ç»“åˆäº†å¼ºåŒ–å­¦ä¹ ã€‚é¦–å…ˆï¼Œä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å¤„ç†æ¸¸æˆæ–‡æœ¬å¹¶æ„å»ºä¸–ç•Œæ¨¡å‹ã€‚ç„¶åï¼Œé€šè¿‡åŸºäºç­–ç•¥æ¢¯åº¦çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•è®­ç»ƒæ™ºèƒ½ä½“ï¼Œä»¥ä¿ƒè¿›ä»çŠ¶æ€å€¼åˆ°æœ€ä¼˜ç­–ç•¥çš„è½¬æ¢ã€‚å¢å¼ºåçš„æ™ºèƒ½ä½“åœ¨å¤šä¸ªæ–‡æœ¬æ¸¸æˆå®éªŒä¸­è¡¨ç°æ›´å¥½ï¼Œå¹¶åœ¨æ¸¸æˆå®Œæˆç‡å’Œèƒœç‡æ–¹é¢æ˜¾è‘—è¶…è¿‡äº†ä¹‹å‰çš„æ™ºèƒ½ä½“ã€‚æœ¬ç ”ç©¶ä¸ºä½¿ç”¨å¼ºåŒ–å­¦ä¹ è¿›è¡Œæ–‡æœ¬æ¸¸æˆæä¾›äº†æ–°çš„ç†è§£å’Œç»éªŒåŸºç¡€ï¼Œå¹¶ä¸ºå¼€å‘å’Œä¼˜åŒ–å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ä»¥åº”ç”¨äºæ›´é€šç”¨çš„é¢†åŸŸå’Œé—®é¢˜å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬æ¸¸æˆä¸­æ™ºèƒ½ä½“ç­–ç•¥å­¦ä¹ çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éš¾ä»¥æœ‰æ•ˆåœ°ä»æ–‡æœ¬æè¿°ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯ç”¨äºå†³ç­–çš„çŠ¶æ€è¡¨ç¤ºï¼Œå¯¼è‡´æ™ºèƒ½ä½“éš¾ä»¥ç†è§£æ¸¸æˆç¯å¢ƒå¹¶åˆ¶å®šæœ‰æ•ˆçš„ç­–ç•¥ã€‚æ­¤å¤–ï¼Œæ¢ç´¢å¤æ‚çš„æ–‡æœ¬æ¸¸æˆç¯å¢ƒä¹Ÿé¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æœ‰æ•ˆçš„æ¢ç´¢ç­–ç•¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆæ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å¤„ç†æ–‡æœ¬ä¿¡æ¯ï¼Œæ„å»ºæ¸¸æˆçš„ä¸–ç•Œæ¨¡å‹ï¼Œç„¶åä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒæ™ºèƒ½ä½“ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®ä¸–ç•Œæ¨¡å‹çš„çŠ¶æ€ä¿¡æ¯å­¦ä¹ æœ€ä¼˜ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æ–‡æœ¬ä¿¡æ¯ï¼Œå¹¶å­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬å¤„ç†æ¨¡å—å’Œå¼ºåŒ–å­¦ä¹ æ¨¡å—ã€‚æ–‡æœ¬å¤„ç†æ¨¡å—ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰å°†æ¸¸æˆæ–‡æœ¬è½¬åŒ–ä¸ºçŠ¶æ€è¡¨ç¤ºï¼Œæ„å»ºä¸–ç•Œæ¨¡å‹ã€‚å¼ºåŒ–å­¦ä¹ æ¨¡å—ä½¿ç”¨ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼ˆå…·ä½“ç®—æ³•æœªçŸ¥ï¼‰è®­ç»ƒæ™ºèƒ½ä½“ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®ä¸–ç•Œæ¨¡å‹çš„çŠ¶æ€ä¿¡æ¯é€‰æ‹©åŠ¨ä½œï¼Œå¹¶è·å¾—å¥–åŠ±ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œæ™ºèƒ½ä½“æ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©åŠ¨ä½œï¼Œæ‰§è¡ŒåŠ¨ä½œåè·å¾—æ–°çš„æ¸¸æˆæ–‡æœ¬ï¼Œæ–‡æœ¬å¤„ç†æ¨¡å—å°†æ–°çš„æ¸¸æˆæ–‡æœ¬è½¬åŒ–ä¸ºæ–°çš„çŠ¶æ€è¡¨ç¤ºï¼Œå¼ºåŒ–å­¦ä¹ æ¨¡å—æ ¹æ®æ–°çš„çŠ¶æ€å’Œå¥–åŠ±æ›´æ–°æ™ºèƒ½ä½“ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºå°†æ·±åº¦å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆï¼Œç”¨äºè§£å†³æ–‡æœ¬æ¸¸æˆä¸­çš„æ™ºèƒ½ä½“ç­–ç•¥å­¦ä¹ é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æ„å»ºä¸–ç•Œæ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°ä»æ–‡æœ¬ä¿¡æ¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯ç”¨äºå†³ç­–çš„çŠ¶æ€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œä½¿ç”¨ç­–ç•¥æ¢¯åº¦ç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æ¢ç´¢å¤æ‚çš„æ–‡æœ¬æ¸¸æˆç¯å¢ƒï¼Œå¹¶å­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ï¼ŒåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å…·ä½“ç»“æ„ã€ç­–ç•¥æ¢¯åº¦ç®—æ³•çš„å…·ä½“å®ç°ã€å¥–åŠ±å‡½æ•°çš„è®¾è®¡ç­‰ã€‚è¿™äº›ç»†èŠ‚å¯¹äºæ™ºèƒ½ä½“çš„æ€§èƒ½è‡³å…³é‡è¦ï¼Œéœ€è¦åœ¨å®é™…åº”ç”¨ä¸­è¿›è¡Œä»”ç»†è°ƒæ•´å’Œä¼˜åŒ–ã€‚è®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šæ–‡æœ¬ç¼–ç æ–¹å¼çš„é€‰æ‹©ã€ç½‘ç»œç»“æ„çš„æ­å»ºã€æŸå¤±å‡½æ•°çš„å®šä¹‰ã€æ¢ç´¢ç­–ç•¥çš„è®¾è®¡ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†æ‰€æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¢å¼ºåçš„æ™ºèƒ½ä½“åœ¨å¤šä¸ªæ–‡æœ¬æ¸¸æˆå®éªŒä¸­è¡¨ç°æ›´å¥½ï¼Œå¹¶åœ¨æ¸¸æˆå®Œæˆç‡å’Œèƒœç‡æ–¹é¢æ˜¾è‘—è¶…è¿‡äº†ä¹‹å‰çš„æ™ºèƒ½ä½“ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ï¼Œä½†æ€»ä½“è€Œè¨€ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡æ™ºèƒ½ä½“åœ¨æ–‡æœ¬æ¸¸æˆä¸­çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´æ™ºèƒ½çš„æ–‡æœ¬æ¸¸æˆAIï¼Œæå‡æ¸¸æˆä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤„ç†æ–‡æœ¬ä¿¡æ¯çš„å†³ç­–ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å¯¹è¯ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢ã€æ™ºèƒ½å®¢æœç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶å¦‚ä½•å°†è¯¥æ–¹æ³•åº”ç”¨äºæ›´å¤æ‚çš„æ–‡æœ¬æ¸¸æˆå’Œç°å®ä¸–ç•Œé—®é¢˜ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As AI technology advances, research in playing text-based games with agents has becomeprogressively popular. In this paper, a novel approach to agent design and agent learning ispresented with the context of reinforcement learning. A model of deep learning is first applied toprocess game text and build a world model. Next, the agent is learned through a policy gradient-based deep reinforcement learning method to facilitate conversion from state value to optimal policy.The enhanced agent works better in several text-based game experiments and significantlysurpasses previous agents on game completion ratio and win rate. Our study introduces novelunderstanding and empirical ground for using reinforcement learning for text games and sets thestage for developing and optimizing reinforcement learning agents for more general domains andproblems.

