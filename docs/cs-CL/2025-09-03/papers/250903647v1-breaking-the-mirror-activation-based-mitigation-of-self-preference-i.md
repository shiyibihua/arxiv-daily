---
layout: default
title: Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators
---

# Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03647" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03647v1</a>
  <a href="https://arxiv.org/pdf/2509.03647.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03647v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03647v1', 'Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dani Roytburg, Matthew Bozoukov, Matthew Nguyen, Jou Barzdukas, Simon Fu, Narmeen Oozeer

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¿€æ´»çš„å¹²é¢„æ–¹æ³•ï¼Œç¼“è§£LLMè¯„ä¼°å™¨ä¸­çš„è‡ªæˆ‘åå¥½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªæˆ‘åå¥½åå·®` `æ¨¡å‹è¯„ä¼°` `steering vectors` `å¯¹æ¯”æ¿€æ´»æ·»åŠ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. LLMè¯„ä¼°å™¨å­˜åœ¨è‡ªæˆ‘åå¥½åå·®ï¼Œå³å€¾å‘äºé€‰æ‹©è‡ªèº«ç”Ÿæˆçš„ç­”æ¡ˆï¼Œå½±å“è¯„ä¼°çš„å…¬æ­£æ€§ã€‚
2. è®ºæ–‡æå‡ºä½¿ç”¨steering vectorsï¼Œé€šè¿‡å¯¹æ¯”æ¿€æ´»æ·»åŠ ï¼ˆCAAï¼‰å’Œä¼˜åŒ–æ–¹æ³•ï¼Œåœ¨æ¨ç†æ—¶å¹²é¢„LLMçš„æ¿€æ´»ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—é™ä½ä¸åˆç†çš„è‡ªæˆ‘åå¥½åå·®ï¼Œæœ€é«˜å¯è¾¾97%ï¼Œä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œè‡ªåŠ¨è¯„ä¼°å™¨ï¼Œä½†å®ƒä»¬å­˜åœ¨â€œè‡ªæˆ‘åå¥½åå·®â€ï¼šå€¾å‘äºåçˆ±è‡ªå·±çš„è¾“å‡ºè€Œä¸æ˜¯å…¶ä»–æ¨¡å‹çš„è¾“å‡ºã€‚è¿™ç§åå·®æŸå®³äº†è¯„ä¼°æµç¨‹çš„å…¬å¹³æ€§å’Œå¯é æ€§ï¼Œå°¤å…¶æ˜¯åœ¨åå¥½è°ƒæ•´å’Œæ¨¡å‹è·¯ç”±ç­‰ä»»åŠ¡ä¸­ã€‚æœ¬æ–‡ç ”ç©¶äº†æ˜¯å¦å¯ä»¥åœ¨æ¨ç†æ—¶ä½¿ç”¨è½»é‡çº§çš„steering vectorsæ¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒã€‚ä½œè€…æ„å»ºäº†ä¸€ä¸ªç²¾å¿ƒç­–åˆ’çš„æ•°æ®é›†ï¼Œå°†è‡ªæˆ‘åå¥½åå·®åŒºåˆ†ä¸ºåˆç†çš„è‡ªæˆ‘åå¥½å’Œä¸åˆç†çš„è‡ªæˆ‘åå¥½ï¼Œå¹¶ä½¿ç”¨ä¸¤ç§æ–¹æ³•æ„å»ºsteering vectorsï¼šå¯¹æ¯”æ¿€æ´»æ·»åŠ ï¼ˆCAAï¼‰å’ŒåŸºäºä¼˜åŒ–çš„æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œsteering vectorså¯ä»¥å°†ä¸åˆç†çš„è‡ªæˆ‘åå¥½åå·®é™ä½é«˜è¾¾97ï¼…ï¼Œå¤§å¤§ä¼˜äºpromptingå’Œç›´æ¥åå¥½ä¼˜åŒ–åŸºçº¿ã€‚ç„¶è€Œï¼Œsteering vectorsåœ¨åˆç†çš„è‡ªæˆ‘åå¥½å’Œæ— åä¸€è‡´æ€§æ–¹é¢ä¸ç¨³å®šï¼Œè¿™æ„å‘³ç€è‡ªæˆ‘åå¥½è·¨è¶Šå¤šä¸ªæˆ–éçº¿æ€§æ–¹å‘ã€‚è¿™çªæ˜¾äº†å®ƒä»¬ä½œä¸ºLLMè¯„ä¼°å™¨ä¿éšœæªæ–½çš„æ½œåŠ›å’Œå±€é™æ€§ï¼Œå¹¶æ¨åŠ¨äº†æ›´å¼ºå¤§çš„å¹²é¢„æªæ–½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä¼°å™¨æ—¶å­˜åœ¨çš„â€œè‡ªæˆ‘åå¥½åå·®â€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚promptingå’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæ— æ³•æœ‰æ•ˆæ¶ˆé™¤è¿™ç§åå·®ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ï¼Œå½±å“æ¨¡å‹é€‰æ‹©å’Œä¼˜åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨æ¨ç†é˜¶æ®µå¹²é¢„LLMçš„æ¿€æ´»ï¼Œæ¥æŠ‘åˆ¶å…¶è‡ªæˆ‘åå¥½ã€‚å…·ä½“è€Œè¨€ï¼Œé€šè¿‡æ„å»ºsteering vectorsï¼Œå¼•å¯¼LLMçš„æ¿€æ´»çŠ¶æ€ï¼Œä½¿å…¶å‡å°‘å¯¹è‡ªèº«ç”Ÿæˆå†…å®¹çš„åå¥½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) æ„å»ºåŒºåˆ†åˆç†å’Œä¸åˆç†è‡ªæˆ‘åå¥½çš„æ•°æ®é›†ï¼›2) ä½¿ç”¨å¯¹æ¯”æ¿€æ´»æ·»åŠ ï¼ˆCAAï¼‰å’Œä¼˜åŒ–æ–¹æ³•æ„å»ºsteering vectorsï¼›3) åœ¨æ¨ç†æ—¶ï¼Œå°†steering vectorsæ·»åŠ åˆ°LLMçš„æ¿€æ´»ä¸­ï¼Œä»è€Œå½±å“å…¶è¯„ä¼°ç»“æœï¼›4) è¯„ä¼°steering vectorsåœ¨å‡å°‘è‡ªæˆ‘åå¥½åå·®æ–¹é¢çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨steering vectorsåœ¨æ¨ç†æ—¶å¹²é¢„LLMçš„æ¿€æ´»ï¼Œä»è€Œç¼“è§£è‡ªæˆ‘åå¥½åå·®ã€‚ä¸ä¼ ç»Ÿçš„promptingå’Œç›´æ¥åå¥½ä¼˜åŒ–æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ è½»é‡çº§ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä¸”æ•ˆæœæ›´æ˜¾è‘—ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†ä¸¤ç§æ–¹æ³•æ„å»ºsteering vectorsï¼šå¯¹æ¯”æ¿€æ´»æ·»åŠ ï¼ˆCAAï¼‰å’ŒåŸºäºä¼˜åŒ–çš„æ–¹æ³•ã€‚CAAé€šè¿‡å¯¹æ¯”LLMå¯¹è‡ªèº«ç”Ÿæˆå†…å®¹å’Œå…¶ä»–æ¨¡å‹ç”Ÿæˆå†…å®¹çš„æ¿€æ´»å·®å¼‚ï¼Œæ¥æ„å»ºsteering vectorsã€‚åŸºäºä¼˜åŒ–çš„æ–¹æ³•åˆ™é€šè¿‡ä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œç›´æ¥å­¦ä¹ steering vectorsã€‚æ•°æ®é›†çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦åŒºåˆ†åˆç†å’Œä¸åˆç†çš„è‡ªæˆ‘åå¥½ï¼Œä»¥ç¡®ä¿steering vectorsèƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶åå·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨steering vectorså¯ä»¥å°†ä¸åˆç†çš„è‡ªæˆ‘åå¥½åå·®é™ä½é«˜è¾¾97ï¼…ï¼Œæ˜¾è‘—ä¼˜äºpromptingå’Œç›´æ¥åå¥½ä¼˜åŒ–åŸºçº¿ã€‚ç„¶è€Œï¼Œsteering vectorsåœ¨åˆç†çš„è‡ªæˆ‘åå¥½å’Œæ— åä¸€è‡´æ€§æ–¹é¢è¡¨ç°ä¸ç¨³å®šï¼Œè¡¨æ˜è‡ªæˆ‘åå¥½å¯èƒ½æ¶‰åŠå¤šä¸ªæˆ–éçº¿æ€§æ–¹å‘ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†steering vectorsä½œä¸ºLLMè¯„ä¼°å™¨ä¿éšœæªæ–½çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä½¿ç”¨LLMè¿›è¡Œè‡ªåŠ¨è¯„ä¼°çš„åœºæ™¯ï¼Œä¾‹å¦‚æ¨¡å‹é€‰æ‹©ã€åå¥½è°ƒæ•´ã€æ¨¡å‹è·¯ç”±ç­‰ã€‚é€šè¿‡å‡å°‘LLMè¯„ä¼°å™¨çš„è‡ªæˆ‘åå¥½åå·®ï¼Œå¯ä»¥æé«˜è¯„ä¼°ç»“æœçš„å‡†ç¡®æ€§å’Œå…¬æ­£æ€§ï¼Œä»è€Œæ›´å¥½åœ°æŒ‡å¯¼æ¨¡å‹å¼€å‘å’Œåº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–ç±»å‹çš„åå·®ç¼“è§£ï¼Œæå‡LLMçš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) increasingly serve as automated evaluators, yet they suffer from "self-preference bias": a tendency to favor their own outputs over those of other models. This bias undermines fairness and reliability in evaluation pipelines, particularly for tasks like preference tuning and model routing. We investigate whether lightweight steering vectors can mitigate this problem at inference time without retraining. We introduce a curated dataset that distinguishes self-preference bias into justified examples of self-preference and unjustified examples of self-preference, and we construct steering vectors using two methods: Contrastive Activation Addition (CAA) and an optimization-based approach. Our results show that steering vectors can reduce unjustified self-preference bias by up to 97\%, substantially outperforming prompting and direct preference optimization baselines. Yet steering vectors are unstable on legitimate self-preference and unbiased agreement, implying self-preference spans multiple or nonlinear directions. This underscores both their promise and limits as safeguards for LLM-as-judges and motivates more robust interventions.

