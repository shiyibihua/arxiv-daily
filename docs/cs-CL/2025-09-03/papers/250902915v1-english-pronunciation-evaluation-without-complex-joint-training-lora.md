---
layout: default
title: English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM
---

# English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02915" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02915v1</a>
  <a href="https://arxiv.org/pdf/2509.02915.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02915v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02915v1', 'English Pronunciation Evaluation without Complex Joint Training: LoRA Fine-tuned Speech Multimodal LLM')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Taekyung Ahn, Hosung Nam

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨LoRAå¾®è°ƒå¤šæ¨¡æ€LLMå®ç°é«˜æ•ˆè‹±è¯­å‘éŸ³è¯„ä¼°ä¸è¯Šæ–­**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ä½ç§©é€‚åº”` `å‘éŸ³è¯„ä¼°` `è¯­éŸ³è¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¿ç§»å­¦ä¹ ` `è®¡ç®—æœºè¾…åŠ©è¯­è¨€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å‘éŸ³è¯„ä¼°æ–¹æ³•é€šå¸¸éœ€è¦å¤æ‚çš„æ¶æ„è®¾è®¡å’Œé’ˆå¯¹ä¸åŒä»»åŠ¡çš„ç‹¬ç«‹è®­ç»ƒæµç¨‹ï¼Œæ•ˆç‡è¾ƒä½ã€‚
2. æœ¬ç ”ç©¶æå‡ºåˆ©ç”¨LoRAå¾®è°ƒå¤šæ¨¡æ€LLMï¼Œæ— éœ€å¤æ‚æ¶æ„ä¿®æ”¹å³å¯åŒæ—¶å®ç°APAå’ŒMDDã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‘éŸ³è¯„ä¼°ä»»åŠ¡ä¸Šå–å¾—äº†ä¸äººå·¥è¯„ä¼°é«˜åº¦ç›¸å…³çš„æ€§èƒ½ï¼Œä¸”é”™è¯¯ç‡è¾ƒä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡ä½ç§©é€‚åº”(LoRA)è°ƒæ•´çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)èƒ½å¤ŸåŒæ—¶æ‰§è¡Œè‡ªåŠ¨å‘éŸ³è¯„ä¼°(APA)å’Œå‘éŸ³é”™è¯¯æ£€æµ‹ä¸è¯Šæ–­(MDD)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¾®è½¯çš„Phi-4-multimodal-instructæ¨¡å‹ï¼Œæ— éœ€å¤æ‚çš„æ¶æ„æ›´æ”¹æˆ–ä¼ ç»Ÿä¸Šç”¨äºè¿™äº›ä¸åŒä»»åŠ¡çš„ç‹¬ç«‹è®­ç»ƒç¨‹åºã€‚åœ¨Speechocean762æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒåï¼Œæ¨¡å‹é¢„æµ‹çš„å‘éŸ³è¯„ä¼°åˆ†æ•°ä¸äººå·¥åˆ†é…çš„åˆ†æ•°è¡¨ç°å‡ºå¾ˆå¼ºçš„çš®å°”é€Šç›¸å…³ç³»æ•°(PCC > 0.7)ï¼ŒåŒæ—¶å®ç°äº†è¾ƒä½çš„è¯é”™è¯¯ç‡(WER)å’ŒéŸ³ç´ é”™è¯¯ç‡(PER)(å‡ < 0.15)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä»…å¾®è°ƒLoRAå±‚å°±è¶³ä»¥è¾¾åˆ°ä¸å¾®è°ƒæ‰€æœ‰éŸ³é¢‘å±‚ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚è¿™é¡¹ç ”ç©¶å¼ºè°ƒï¼Œé€šè¿‡è°ƒæ•´å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ— éœ€å®Œå…¨å¾®è°ƒï¼Œå°±å¯ä»¥å»ºç«‹ä¸€ä¸ªé›†æˆçš„å‘éŸ³è¯„ä¼°ç³»ç»Ÿï¼Œä¸ä»¥å‰ä¸ºåŒæ—¶è¿›è¡ŒAPAå’ŒMDDè€Œè®¾è®¡çš„è”åˆæ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ç§æ˜¾è‘—æ›´ç®€å•çš„è®­ç»ƒæ–¹æ³•ã€‚è¿™ç§é«˜æ•ˆçš„åŸºäºLoRAçš„æ–¹æ³•ä¸ºè‹±è¯­L2å­¦ä¹ è€…æä¾›äº†æ›´æ˜“äºè®¿é—®ã€é›†æˆå’Œæœ‰æ•ˆçš„è®¡ç®—æœºè¾…åŠ©å‘éŸ³è®­ç»ƒ(CAPT)æŠ€æœ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‹±è¯­å‘éŸ³è¯„ä¼°ä¸è¯Šæ–­é—®é¢˜ï¼Œå…·ä½“åŒ…æ‹¬è‡ªåŠ¨å‘éŸ³è¯„ä¼°(APA)å’Œå‘éŸ³é”™è¯¯æ£€æµ‹ä¸è¯Šæ–­(MDD)ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹APAå’ŒMDDåˆ†åˆ«è®¾è®¡å¤æ‚çš„æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæµç¨‹ï¼Œæˆ–è€…é‡‡ç”¨è”åˆè®­ç»ƒçš„æ–¹å¼ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”ä¸æ˜“éƒ¨ç½²ã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆåœ°æ„å»ºä¸€ä¸ªé›†æˆçš„å‘éŸ³è¯„ä¼°ç³»ç»Ÿæ˜¯æœ¬ç ”ç©¶è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)çš„å¼ºå¤§è¡¨å¾èƒ½åŠ›ï¼Œé€šè¿‡ä½ç§©é€‚åº”(LoRA)æŠ€æœ¯è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤ŸåŒæ—¶æ‰§è¡ŒAPAå’ŒMDDä»»åŠ¡ã€‚LoRAé€šè¿‡å¼•å…¥å°‘é‡å¯è®­ç»ƒå‚æ•°æ¥è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä»è€Œé¿å…äº†å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬å’Œå­˜å‚¨éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŸºäºå¾®è½¯çš„Phi-4-multimodal-instructæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ˜¯ä¸€ä¸ªé¢„è®­ç»ƒçš„å¤šæ¨¡æ€LLMã€‚ç ”ç©¶äººå‘˜é¦–å…ˆå°†è¯­éŸ³æ•°æ®è¾“å…¥æ¨¡å‹ï¼Œç„¶ååˆ©ç”¨LoRAæŠ€æœ¯å¯¹æ¨¡å‹çš„ç‰¹å®šå±‚è¿›è¡Œå¾®è°ƒã€‚å¾®è°ƒåçš„æ¨¡å‹å¯ä»¥åŒæ—¶è¾“å‡ºAPAåˆ†æ•°å’ŒMDDç»“æœã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒå’Œç»“æœè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨LoRAæŠ€æœ¯å¯¹å¤šæ¨¡æ€LLMè¿›è¡Œå¾®è°ƒï¼Œä»è€Œå®ç°é«˜æ•ˆçš„é›†æˆå‘éŸ³è¯„ä¼°ç³»ç»Ÿã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€å¤æ‚çš„æ¶æ„è®¾è®¡å’Œç‹¬ç«‹çš„è®­ç»ƒæµç¨‹ï¼Œå¤§å¤§ç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä»…å¾®è°ƒLoRAå±‚å³å¯è¾¾åˆ°ä¸å¾®è°ƒæ‰€æœ‰éŸ³é¢‘å±‚ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼Œè¿›ä¸€æ­¥æé«˜äº†æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨Speechocean762æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè¯¥æ•°æ®é›†åŒ…å«å¤§é‡çš„è‹±è¯­å‘éŸ³æ•°æ®å’Œäººå·¥æ ‡æ³¨ã€‚åœ¨LoRAå¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶äººå‘˜é€‰æ‹©äº†æ¨¡å‹çš„ç‰¹å®šå±‚è¿›è¡Œè°ƒæ•´ï¼Œå¹¶è®¾ç½®äº†åˆé€‚çš„å­¦ä¹ ç‡å’Œè®­ç»ƒè½®æ•°ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡éœ€è¦åŒæ—¶è€ƒè™‘APAå’ŒMDDä»»åŠ¡çš„éœ€æ±‚ï¼Œå¯èƒ½é‡‡ç”¨äº†åŠ æƒæŸå¤±å‡½æ•°æˆ–è€…å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹æ³•ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ç»†èŠ‚å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰æ›´è¯¦ç»†çš„æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡LoRAå¾®è°ƒçš„å¤šæ¨¡æ€LLMåœ¨Speechocean762æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ¨¡å‹é¢„æµ‹çš„å‘éŸ³è¯„ä¼°åˆ†æ•°ä¸äººå·¥åˆ†é…çš„åˆ†æ•°è¡¨ç°å‡ºå¾ˆå¼ºçš„çš®å°”é€Šç›¸å…³ç³»æ•°(PCC > 0.7)ï¼ŒåŒæ—¶å®ç°äº†è¾ƒä½çš„è¯é”™è¯¯ç‡(WER)å’ŒéŸ³ç´ é”™è¯¯ç‡(PER)(å‡ < 0.15)ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä»…å¾®è°ƒLoRAå±‚å°±è¶³ä»¥è¾¾åˆ°ä¸å¾®è°ƒæ‰€æœ‰éŸ³é¢‘å±‚ç›¸å½“çš„æ€§èƒ½æ°´å¹³ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æ•ˆç‡å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè®¡ç®—æœºè¾…åŠ©å‘éŸ³è®­ç»ƒ(CAPT)ç³»ç»Ÿï¼Œå¸®åŠ©è‹±è¯­L2å­¦ä¹ è€…æé«˜å‘éŸ³æ°´å¹³ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæä¾›è‡ªåŠ¨å‘éŸ³è¯„ä¼°å’Œé”™è¯¯è¯Šæ–­ï¼Œä¸ºå­¦ä¹ è€…æä¾›ä¸ªæ€§åŒ–çš„åé¦ˆå’ŒæŒ‡å¯¼ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºè¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆç­‰é¢†åŸŸï¼Œæé«˜è¯­éŸ³å¤„ç†ç³»ç»Ÿçš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„è¯­è¨€å­¦ä¹ å·¥å…·çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study demonstrates that a Multimodal Large Language Model (MLLM) adapted via Low-Rank Adaptation (LoRA) can perform both Automatic Pronunciation Assessment (APA) and Mispronunciation Detection and Diagnosis (MDD) simultaneously. Leveraging Microsoft's Phi-4-multimodal-instruct, our fine-tuning method eliminates the need for complex architectural changes or separate training procedures conventionally required for these distinct tasks. Fine-tuned on the Speechocean762 dataset, the pronunciation evaluation scores predicted by the model exhibited a strong Pearson Correlation Coefficient (PCC > 0.7) with human-assigned scores, while achieving low Word Error Rate (WER) and Phoneme Error Rate (PER) (both < 0.15). Notably, fine-tuning only the LoRA layers was sufficient to achieve performance levels comparable to those achieved by fine-tuning all audio layers. This research highlights that an integrated pronunciation assessment system can be established by adapting large multimodal models without full fine-tuning, utilizing a significantly simpler training methodology compared to previous joint models designed for simultaneous APA and MDD. This efficient LoRA-based approach paves the way for more accessible, integrated, and effective Computer-Assisted Pronunciation Training (CAPT) technologies for English L2 learners.

