---
layout: default
title: ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly
---

# ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02949" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02949v1</a>
  <a href="https://arxiv.org/pdf/2509.02949.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02949v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02949v1', 'ProMQA-Assembly: Multimodal Procedural QA Dataset on Assembly')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kimihiro Hasegawa, Wiradee Imrattanatrai, Masaki Asada, Susan Holm, Yuran Wang, Vincent Zhou, Ken Fukuda, Teruko Mitamura

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

**å¤‡æ³¨**: 29 pages. Code and data: https://github.com/kimihiroh/promqa-assembly

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºProMQA-Assemblyå¤šæ¨¡æ€ç¨‹åºåŒ–é—®ç­”æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°è£…é…ä»»åŠ¡åŠ©æ‰‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€é—®ç­”` `ç¨‹åºåŒ–æ´»åŠ¨ç†è§£` `è£…é…ä»»åŠ¡` `åŠè‡ªåŠ¨æ ‡æ³¨` `æŒ‡ä»¤ä»»åŠ¡å›¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹åœ¨å®é™…è£…é…ç¯å¢ƒä¸­è¯„ä¼°åº”ç”¨å¯¼å‘ç³»ç»Ÿçš„æµ‹è¯•å¹³å°ï¼Œé˜»ç¢äº†è£…é…åŠ©æ‰‹çš„å¼€å‘ã€‚
2. è®ºæ–‡æå‡ºProMQA-Assemblyæ•°æ®é›†ï¼Œç»“åˆäººç±»æ´»åŠ¨è®°å½•å’ŒæŒ‡ä»¤æ‰‹å†Œï¼Œé‡‡ç”¨åŠè‡ªåŠ¨æ ‡æ³¨æ–¹æ³•é™ä½æˆæœ¬ã€‚
3. é€šè¿‡åŸºå‡†æµ‹è¯•ï¼Œå‘ç°ç°æœ‰æ¨¡å‹åœ¨ç†è§£è£…é…ä»»åŠ¡çš„å¤šæ¨¡æ€ä¿¡æ¯æ–¹é¢ä»æœ‰æå‡ç©ºé—´ï¼Œä¸ºæœªæ¥ç ”ç©¶æŒ‡æ˜æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤šæ¨¡æ€é—®ç­”æ•°æ®é›†ProMQA-Assemblyï¼Œä¸“æ³¨äºè£…é…æ´»åŠ¨ï¼Œæ—¨åœ¨ä¿ƒè¿›ç¨‹åºåŒ–æ´»åŠ¨åŠ©æ‰‹çš„å¼€å‘ã€‚è¯¥æ•°æ®é›†åŒ…å«391ä¸ªé—®ç­”å¯¹ï¼Œéœ€è¦å¯¹äººç±»æ´»åŠ¨è®°å½•å’Œåœ¨çº¿æŒ‡ä»¤æ‰‹å†Œè¿›è¡Œå¤šæ¨¡æ€ç†è§£ã€‚ä¸ºäº†é«˜æ•ˆåœ°åˆ›å»ºæ•°æ®é›†ï¼Œé‡‡ç”¨äº†åŠè‡ªåŠ¨é—®ç­”æ ‡æ³¨æ–¹æ³•ï¼Œå³åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå€™é€‰ç­”æ¡ˆï¼Œç„¶åç”±äººå·¥è¿›è¡ŒéªŒè¯ã€‚é€šè¿‡æ•´åˆç»†ç²’åº¦çš„åŠ¨ä½œæ ‡ç­¾æ¥å¢åŠ é—®é¢˜ç±»å‹çš„å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œè¿˜ä¸ºç©å…·è½¦è¾†çš„è£…é…ä»»åŠ¡åˆ›å»ºäº†æŒ‡ä»¤ä»»åŠ¡å›¾ï¼Œç”¨äºåŸºå‡†æµ‹è¯•å’Œè¾…åŠ©äººå·¥éªŒè¯è¿‡ç¨‹ã€‚åˆ©ç”¨è¯¥æ•°æ®é›†ï¼Œå¯¹åŒ…æ‹¬æœ‰ç«äº‰åŠ›çš„å•†ä¸šå¤šæ¨¡æ€æ¨¡å‹åœ¨å†…çš„å¤šä¸ªæ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜å½“å‰æ¨¡å‹ä»æœ‰å¾ˆå¤§çš„æ”¹è¿›ç©ºé—´ã€‚è¯¥æ•°æ®é›†æœ‰æœ›ä¿ƒè¿›ç¨‹åºåŒ–æ´»åŠ¨åŠ©æ‰‹çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¼ºä¹é’ˆå¯¹è£…é…ä»»åŠ¡çš„ã€åº”ç”¨å¯¼å‘çš„å¤šæ¨¡æ€é—®ç­”æ•°æ®é›†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å®é™…è£…é…ç¯å¢ƒä¸­è¯„ä¼°è£…é…åŠ©æ‰‹çš„æ€§èƒ½ï¼Œé˜»ç¢äº†ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚ç¼ºä¹è¿™æ ·çš„æ•°æ®é›†ä½¿å¾—ç ”ç©¶äººå‘˜éš¾ä»¥å¼€å‘å’Œè¯„ä¼°èƒ½å¤Ÿç†è§£äººç±»æ´»åŠ¨å’ŒæŒ‡ä»¤æ‰‹å†Œçš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œä»è€Œé™åˆ¶äº†è£…é…åŠ©æ‰‹çš„å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«äººç±»æ´»åŠ¨è§†é¢‘å’Œå¯¹åº”æŒ‡ä»¤æ‰‹å†Œçš„å¤šæ¨¡æ€é—®ç­”æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨åŠè‡ªåŠ¨æ ‡æ³¨æ–¹æ³•æ¥é™ä½æ•°æ®é›†æ„å»ºçš„æˆæœ¬ã€‚é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå€™é€‰ç­”æ¡ˆï¼Œå¹¶ç”±äººå·¥è¿›è¡ŒéªŒè¯ï¼Œå¯ä»¥é«˜æ•ˆåœ°åˆ›å»ºé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚åŒæ—¶ï¼Œé€šè¿‡å¼•å…¥ç»†ç²’åº¦çš„åŠ¨ä½œæ ‡ç­¾ï¼Œå¯ä»¥å¢åŠ é—®é¢˜ç±»å‹çš„å¤šæ ·æ€§ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šProMQA-Assemblyæ•°æ®é›†çš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ”¶é›†äººç±»è¿›è¡Œç©å…·è½¦è¾†è£…é…çš„è§†é¢‘æ•°æ®ï¼›2) è·å–ç›¸åº”çš„åœ¨çº¿æŒ‡ä»¤æ‰‹å†Œï¼›3) åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå€™é€‰é—®ç­”å¯¹ï¼›4) äººå·¥éªŒè¯å’Œä¿®æ­£å€™é€‰é—®ç­”å¯¹ï¼›5) æ„å»ºæŒ‡ä»¤ä»»åŠ¡å›¾ï¼Œç”¨äºè¾…åŠ©äººå·¥éªŒè¯å’ŒåŸºå‡†æµ‹è¯•ã€‚è¯¥æ•°æ®é›†åŒ…å«è§†é¢‘ã€æ–‡æœ¬å’Œä»»åŠ¡å›¾ä¸‰ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªé’ˆå¯¹è£…é…ä»»åŠ¡çš„å¤šæ¨¡æ€é—®ç­”æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨åŠè‡ªåŠ¨æ ‡æ³¨æ–¹æ³•æ¥é™ä½æ•°æ®é›†æ„å»ºçš„æˆæœ¬ã€‚ä¸ä»¥å¾€çš„æ•°æ®é›†ç›¸æ¯”ï¼ŒProMQA-Assemblyæ•°æ®é›†æ›´ä¾§é‡äºå®é™…åº”ç”¨åœºæ™¯ï¼Œå¹¶ä¸”åŒ…å«äº†æŒ‡ä»¤ä»»åŠ¡å›¾ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹åœ¨è£…é…ä»»åŠ¡ä¸­çš„ç†è§£èƒ½åŠ›ã€‚åŠè‡ªåŠ¨æ ‡æ³¨æ–¹æ³•é€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œäººå·¥éªŒè¯ï¼Œå¯ä»¥é«˜æ•ˆåœ°åˆ›å»ºé«˜è´¨é‡çš„é—®ç­”å¯¹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŠè‡ªåŠ¨æ ‡æ³¨è¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†ç»†ç²’åº¦çš„åŠ¨ä½œæ ‡ç­¾æ¥æŒ‡å¯¼å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆé—®é¢˜ï¼Œä»è€Œå¢åŠ é—®é¢˜ç±»å‹çš„å¤šæ ·æ€§ã€‚æŒ‡ä»¤ä»»åŠ¡å›¾ç”¨äºè¡¨ç¤ºè£…é…ä»»åŠ¡çš„æ­¥éª¤å’Œä¾èµ–å…³ç³»ï¼Œå¯ä»¥è¾…åŠ©äººå·¥éªŒè¯é—®ç­”å¯¹çš„æ­£ç¡®æ€§ï¼Œå¹¶ç”¨äºåŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°æ¨¡å‹å¯¹ä»»åŠ¡æµç¨‹çš„ç†è§£èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºåŸºå‡†æµ‹è¯•ä¸­ä½¿ç”¨çš„æ¨¡å‹ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åˆ©ç”¨ProMQA-Assemblyæ•°æ®é›†å¯¹å¤šä¸ªæ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬æœ‰ç«äº‰åŠ›çš„å•†ä¸šå¤šæ¨¡æ€æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨ç†è§£è£…é…ä»»åŠ¡çš„å¤šæ¨¡æ€ä¿¡æ¯æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ï¼Œä¾‹å¦‚åœ¨ç†è§£è§†é¢‘ä¸­çš„åŠ¨ä½œå’ŒæŒ‡ä»¤æ‰‹å†Œä¸­çš„æ–‡æœ¬æè¿°ä¹‹é—´çš„å¯¹åº”å…³ç³»æ–¹é¢ã€‚è¿™ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ï¼Œå³éœ€è¦å¼€å‘æ›´å¼ºå¤§çš„å¤šæ¨¡æ€æ¨¡å‹æ¥æ›´å¥½åœ°ç†è§£å’Œæ¨ç†è£…é…ä»»åŠ¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ™ºèƒ½è£…é…åŠ©æ‰‹ï¼Œå¸®åŠ©äººä»¬å®Œæˆæ—¥å¸¸ä»»åŠ¡å’Œå·¥ä¸šç”Ÿäº§ä¸­çš„è£…é…å·¥ä½œã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åº”ç”¨äºæ™ºèƒ½å®¶å±…ã€æœºå™¨äººè¾…åŠ©è£…é…ã€è¿œç¨‹åä½œç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£äººç±»æ´»åŠ¨å’ŒæŒ‡ä»¤æ‰‹å†Œï¼Œè£…é…åŠ©æ‰‹å¯ä»¥æä¾›å®æ—¶çš„æŒ‡å¯¼å’Œåé¦ˆï¼Œæé«˜è£…é…æ•ˆç‡å’Œè´¨é‡ï¼Œé™ä½é”™è¯¯ç‡ï¼Œå¹¶å‡å°‘å¯¹ä¸“ä¸šæŠ€èƒ½çš„ä¾èµ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Assistants on assembly tasks have a large potential to benefit humans from everyday tasks to industrial settings. However, no testbeds support application-oriented system evaluation in a practical setting, especially in assembly. To foster the development, we propose a new multimodal QA dataset on assembly activities. Our dataset, ProMQA-Assembly, consists of 391 QA pairs that require the multimodal understanding of human-activity recordings and their instruction manuals in an online-style manner. In the development, we adopt a semi-automated QA annotation approach, where LLMs generate candidates and humans verify them, as a cost-effective method, and further improve it by integrating fine-grained action labels to diversify question types. Furthermore, we create instruction task graphs for the target tasks of assembling toy vehicles. These newly created task graphs are used in our benchmarking experiment, as well as to facilitate the human verification process in the QA annotation. Utilizing our dataset, we benchmark models, including competitive proprietary multimodal models. Our results suggest great room for improvement for the current models. We believe our new evaluation dataset can contribute to the further development of procedural-activity assistants.

