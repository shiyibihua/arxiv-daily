---
layout: default
title: MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions
---

# MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09556" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09556v2</a>
  <a href="https://arxiv.org/pdf/2506.09556.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09556v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09556v2', 'MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Georgios Chatzichristodoulou, Despoina Kosmopoulou, Antonios Kritikos, Anastasia Poulopoulou, Efthymios Georgiou, Athanasios Katsamanis, Vassilis Katsouros, Alexandros Potamianos

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-09-04)

**å¤‡æ³¨**: Interspeech 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMEDUSAæ¡†æ¶ä»¥è§£å†³è‡ªç„¶æ¡ä»¶ä¸‹çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«` `å¤šæ¨¡æ€èåˆ` `æ·±åº¦å­¦ä¹ ` `é›†æˆå­¦ä¹ ` `è‡ªç„¶æ¡ä»¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ–¹æ³•é¢ä¸´æƒ…æ„Ÿç±»åˆ«ä¸å¹³è¡¡å’Œæ¨¡ç³Šæ€§çš„é—®é¢˜ï¼Œå¯¼è‡´è¯†åˆ«å‡†ç¡®ç‡ä½ã€‚
2. MEDUSAæ¡†æ¶é€šè¿‡å››é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œç»“åˆå¤šæ¨¡æ€ä¿¡æ¯å’Œé›†æˆå­¦ä¹ ï¼Œæœ‰æ•ˆæå‡äº†æƒ…æ„Ÿè¯†åˆ«çš„æ€§èƒ½ã€‚
3. åœ¨2025å¹´å›½é™…è¯­éŸ³ä¼šè®®çš„æŒ‘æˆ˜ä¸­ï¼ŒMEDUSAåœ¨åˆ†ç±»æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­æ’åç¬¬ä¸€ï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¸»è¦ç”±äºäººç±»æƒ…æ„Ÿçš„ä¸»è§‚æ€§åŠå…¶åœ¨è‡ªç„¶æ¡ä»¶ä¸‹çš„ä¸å‡è¡¡è¡¨ç°ã€‚æœ¬æ–‡æå‡ºäº†MEDUSAï¼Œä¸€ä¸ªå¤šæ¨¡æ€æ¡†æ¶ï¼Œé‡‡ç”¨å››é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œæœ‰æ•ˆå¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œæƒ…æ„Ÿæ¨¡ç³Šæ€§ã€‚å‰ä¸¤é˜¶æ®µè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨é›†æˆï¼Œåˆ©ç”¨DeepSERï¼Œè¿™æ˜¯ä¸€ç§åŸºäºé¢„è®­ç»ƒè‡ªç›‘ç£å£°å­¦å’Œè¯­è¨€è¡¨ç¤ºçš„æ·±åº¦è·¨æ¨¡æ€å˜æ¢å™¨èåˆæœºåˆ¶çš„åˆ›æ–°æ‰©å±•ã€‚é‡‡ç”¨Manifold MixUpè¿›è¡Œè¿›ä¸€æ­¥çš„æ­£åˆ™åŒ–ã€‚åä¸¤é˜¶æ®µä¼˜åŒ–ä¸€ä¸ªå¯è®­ç»ƒçš„å…ƒåˆ†ç±»å™¨ï¼Œç»“åˆé›†æˆé¢„æµ‹ã€‚æˆ‘ä»¬çš„è®­ç»ƒæ–¹æ³•ç»“åˆäº†äººç±»æ³¨é‡Šåˆ†æ•°ä½œä¸ºè½¯ç›®æ ‡ï¼Œå¹¶é…åˆå¹³è¡¡æ•°æ®é‡‡æ ·å’Œå¤šä»»åŠ¡å­¦ä¹ ã€‚MEDUSAåœ¨2025å¹´å›½é™…è¯­éŸ³ä¼šè®®çš„è‡ªç„¶æ¡ä»¶ä¸‹è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æŒ‘æˆ˜ä¸­è·å¾—äº†ç¬¬ä¸€åã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªç„¶æ¡ä»¶ä¸‹è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ä¸­çš„ç±»åˆ«ä¸å¹³è¡¡å’Œæƒ…æ„Ÿæ¨¡ç³Šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆå¤„ç†è¿™äº›æŒ‘æˆ˜ï¼Œå¯¼è‡´è¯†åˆ«æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMEDUSAæ¡†æ¶é€šè¿‡å››ä¸ªè®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯å’Œé›†æˆå­¦ä¹ ç­–ç•¥ï¼Œå¢å¼ºæ¨¡å‹å¯¹æƒ…æ„Ÿçš„è¯†åˆ«èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥DeepSERå’ŒManifold MixUpï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºå››ä¸ªé˜¶æ®µï¼šå‰ä¸¤é˜¶æ®µè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨é›†æˆï¼Œåä¸¤é˜¶æ®µä¼˜åŒ–ä¸€ä¸ªå…ƒåˆ†ç±»å™¨ã€‚å‰è€…ä½¿ç”¨DeepSERè¿›è¡Œè·¨æ¨¡æ€èåˆï¼Œåè€…ç»“åˆé›†æˆé¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMEDUSAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å››é˜¶æ®µè®­ç»ƒæµç¨‹å’ŒDeepSERçš„å¼•å…¥ï¼Œæ˜¾è‘—æé«˜äº†å¯¹æƒ…æ„Ÿæ¨¡ç³Šæ€§çš„å¤„ç†èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´å¼ºçš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†äººç±»æ³¨é‡Šåˆ†æ•°ä½œä¸ºè½¯ç›®æ ‡ï¼Œç»“åˆå¹³è¡¡æ•°æ®é‡‡æ ·å’Œå¤šä»»åŠ¡å­¦ä¹ ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°æƒ…æ„Ÿç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨2025å¹´å›½é™…è¯­éŸ³ä¼šè®®çš„è‡ªç„¶æ¡ä»¶ä¸‹è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æŒ‘æˆ˜ä¸­ï¼ŒMEDUSAåœ¨åˆ†ç±»æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¸€åï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†æƒ…æ„Ÿæ¨¡ç³Šæ€§å’Œç±»åˆ«ä¸å¹³è¡¡æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒMEDUSAçš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå…·ä½“æ•°æ®æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MEDUSAæ¡†æ¶åœ¨è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å®¢æœã€å¿ƒç†å¥åº·ç›‘æµ‹å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ä¸­ã€‚å…¶é«˜æ•ˆçš„æƒ…æ„Ÿè¯†åˆ«èƒ½åŠ›èƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œå¸®åŠ©ç³»ç»Ÿæ›´å¥½åœ°ç†è§£å’Œå“åº”ç”¨æˆ·æƒ…æ„Ÿã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒMEDUSAå¯èƒ½ä¼šåœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> SER is a challenging task due to the subjective nature of human emotions and their uneven representation under naturalistic conditions. We propose MEDUSA, a multimodal framework with a four-stage training pipeline, which effectively handles class imbalance and emotion ambiguity. The first two stages train an ensemble of classifiers that utilize DeepSER, a novel extension of a deep cross-modal transformer fusion mechanism from pretrained self-supervised acoustic and linguistic representations. Manifold MixUp is employed for further regularization. The last two stages optimize a trainable meta-classifier that combines the ensemble predictions. Our training approach incorporates human annotation scores as soft targets, coupled with balanced data sampling and multitask learning. MEDUSA ranked 1st in Task 1: Categorical Emotion Recognition in the Interspeech 2025: Speech Emotion Recognition in Naturalistic Conditions Challenge.

