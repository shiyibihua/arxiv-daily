---
layout: default
title: GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture
---

# GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09440v1</a>
  <a href="https://arxiv.org/pdf/2506.09440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09440v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09440v1', 'GigaChat Family: Efficient Russian Language Modeling Through Mixture of Experts Architecture')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: GigaChat team, Mamedov Valentin, Evgenii Kosarev, Gregory Leleytner, Ilya Shchuckin, Valeriy Berezovskiy, Daniil Smirnov, Dmitry Kozlov, Sergei Averkiev, Lukyanenko Ivan, Aleksandr Proshunin, Ainur Israfilova, Ivan Baskov, Artem Chervyakov, Emil Shakirov, Mikhail Kolesov, Daria Khomich, Darya Latortseva, Sergei Porkhun, Yury Fedorov, Oleg Kutuzov, Polina Kudriavtseva, Sofiia Soldatova, Kolodin Egor, Stanislav Pyatkin, Dzmitry Menshykh, Grafov Sergei, Eldar Damirov, Karlov Vladimir, Ruslan Gaitukiev, Arkadiy Shatenov, Alena Fenogenova, Nikita Savushkin, Fedor Minkin

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: ACL-2025 System Demo

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/ai-sage)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGigaChatå®¶æ—ä»¥é«˜æ•ˆå»ºæ¨¡ä¿„è¯­è¯­è¨€**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿„è¯­å¤„ç†` `ç”Ÿæˆå¼æ¨¡å‹` `æ··åˆä¸“å®¶` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹ä¼˜åŒ–` `å¼€æºæ¨¡å‹` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é’ˆå¯¹ä¿„è¯­çš„åŸºç¡€æ¨¡å‹å¼€å‘å—é™ï¼Œè®¡ç®—èµ„æºéœ€æ±‚é«˜ï¼Œå½±å“äº†NLPç ”ç©¶çš„è¿›å±•ã€‚
2. GigaChatå®¶æ—æ¨¡å‹é‡‡ç”¨æ··åˆä¸“å®¶æ¶æ„ï¼Œæä¾›å¤šç§è§„æ¨¡çš„æ¨¡å‹ä»¥æ»¡è¶³ä¸åŒéœ€æ±‚ï¼Œæå‡äº†ä¿„è¯­å¤„ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGigaChatæ¨¡å‹åœ¨ä¿„è¯­å’Œè‹±è¯­åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰å¤šè¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ç ”ç©¶å’Œåº”ç”¨ä¸­å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œä¸“é—¨é’ˆå¯¹ä¿„è¯­çš„åŸºç¡€æ¨¡å‹å¼€å‘å—åˆ°é™åˆ¶ï¼Œä¸»è¦æ˜¯ç”±äºæ‰€éœ€çš„è®¡ç®—èµ„æºå·¨å¤§ã€‚æœ¬æ–‡ä»‹ç»äº†GigaChatå®¶æ—çš„ä¿„è¯­LLMsï¼Œæä¾›å¤šç§è§„æ¨¡çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹å’ŒæŒ‡ä»¤è°ƒä¼˜ç‰ˆæœ¬ã€‚æˆ‘ä»¬è¯¦ç»†æŠ¥å‘Šäº†æ¨¡å‹æ¶æ„ã€é¢„è®­ç»ƒè¿‡ç¨‹åŠå®éªŒï¼Œä»¥æŒ‡å¯¼è®¾è®¡é€‰æ‹©ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯„ä¼°äº†è¿™äº›æ¨¡å‹åœ¨ä¿„è¯­å’Œè‹±è¯­åŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä¸å¤šè¯­è¨€æ¨¡å‹è¿›è¡Œäº†æ¯”è¾ƒã€‚æœ¬æ–‡å±•ç¤ºäº†é€šè¿‡APIã€Telegramæœºå™¨äººå’ŒWebç•Œé¢è®¿é—®çš„æœ€ä½³æ¨¡å‹ï¼Œå¹¶å‘å¸ƒäº†ä¸‰ä¸ªå¼€æºGigaChatæ¨¡å‹ï¼Œæ—¨åœ¨æ‰©å±•NLPç ”ç©¶æœºä¼šï¼Œæ”¯æŒä¿„è¯­å·¥ä¸šè§£å†³æ–¹æ¡ˆçš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰ä¿„è¯­åŸºç¡€æ¨¡å‹å¼€å‘ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é¢ä¸´è®¡ç®—èµ„æºéœ€æ±‚é«˜ã€æ¨¡å‹è§„æ¨¡é™åˆ¶ç­‰æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGigaChatå®¶æ—æ¨¡å‹é‡‡ç”¨æ··åˆä¸“å®¶æ¶æ„ï¼Œé€šè¿‡åŠ¨æ€é€‰æ‹©ä¸“å®¶æ¨¡å‹æ¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡å’Œæ€§èƒ½ï¼Œæ—¨åœ¨æå‡ä¿„è¯­å¤„ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªä¸“å®¶æ¨¡å‹å’Œä¸€ä¸ªé—¨æ§æœºåˆ¶ï¼Œæ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µé€šè¿‡å¤§è§„æ¨¡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œéšåè¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ä»¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ··åˆä¸“å®¶æ¶æ„çš„åº”ç”¨ï¼Œä½¿å¾—æ¨¡å‹åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—èµ„æºçš„éœ€æ±‚ï¼Œä¸ä¼ ç»Ÿå•ä¸€æ¨¡å‹æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†å¤šå±‚æ¬¡çš„é—¨æ§æœºåˆ¶ï¼Œç¡®ä¿åœ¨æ¨ç†æ—¶ä»…æ¿€æ´»éƒ¨åˆ†ä¸“å®¶ï¼Œæ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç­–ç•¥ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥æé«˜æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGigaChatæ¨¡å‹åœ¨å¤šä¸ªä¿„è¯­å’Œè‹±è¯­åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸Šç›¸è¾ƒäºç°æœ‰å¤šè¯­è¨€æ¨¡å‹æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¼ºå¤§èƒ½åŠ›å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GigaChatæ¨¡å‹åœ¨ä¿„è¯­è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚å…¶é«˜æ•ˆçš„æ¶æ„è®¾è®¡ä½¿å¾—åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ä¹Ÿèƒ½å®ç°é«˜æ€§èƒ½çš„è¯­è¨€å¤„ç†ï¼Œæ¨åŠ¨ä¿„è¯­ç›¸å…³å·¥ä¸šè§£å†³æ–¹æ¡ˆçš„å‘å±•ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„æ™®åŠä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative large language models (LLMs) have become crucial for modern NLP research and applications across various languages. However, the development of foundational models specifically tailored to the Russian language has been limited, primarily due to the significant computational resources required. This paper introduces the GigaChat family of Russian LLMs, available in various sizes, including base models and instruction-tuned versions. We provide a detailed report on the model architecture, pre-training process, and experiments to guide design choices. In addition, we evaluate their performance on Russian and English benchmarks and compare GigaChat with multilingual analogs. The paper presents a system demonstration of the top-performing models accessible via an API, a Telegram bot, and a Web interface. Furthermore, we have released three open GigaChat models in open-source (https://huggingface.co/ai-sage), aiming to expand NLP research opportunities and support the development of industrial solutions for the Russian language.

