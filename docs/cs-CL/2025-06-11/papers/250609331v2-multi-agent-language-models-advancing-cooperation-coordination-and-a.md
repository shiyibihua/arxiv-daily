---
layout: default
title: Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation
---

# Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09331" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09331v2</a>
  <a href="https://arxiv.org/pdf/2506.09331.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09331v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09331v2', 'Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arjun Vaithilingam Sudhakar

**åˆ†ç±»**: cs.CL, cs.AI, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-06-17)

**å¤‡æ³¨**: arXiv admin note: substantial text overlap with arXiv:2311.07687

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ™ºèƒ½ä½“è¯­è¨€æ¨¡å‹ä»¥å¢å¼ºåˆä½œä¸é€‚åº”èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `è¯­è¨€æ¨¡å‹` `åˆä½œå­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£ä»–äººæ„å›¾æ–¹é¢çš„èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†éªŒè¯ï¼Œé™åˆ¶äº†å…¶åœ¨å¤šæ™ºèƒ½ä½“åˆä½œä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ¢ç´¢LLMsåœ¨ç†è§£å’Œæ¨ç†ä»–äººæ„å›¾æ–¹é¢çš„èƒ½åŠ›ï¼Œä»¥å¢å¼ºå…¶åˆä½œèƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•æ˜¾è‘—æå‡äº†äººå·¥æ™ºèƒ½ä½“åœ¨ä¸äººç±»åŠå…¶ä»–æ™ºèƒ½ä½“åˆä½œæ—¶çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°ä»£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„é›¶-shotå’Œfew-shotæ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶å¹¿æ³›åº”ç”¨äºç¿»è¯‘å’Œæ‘˜è¦ç­‰è™šæ‹ŸåŠ©æ‰‹åœºæ™¯ã€‚å°½ç®¡LLMsä»…åŸºäºå¤§é‡æ–‡æœ¬è¯­æ–™è¿›è¡Œè®­ç»ƒï¼Œæœªæ˜ç¡®ç›‘ç£ä½œè€…æ„å›¾ï¼Œä½†å®ƒä»¬ä¼¼ä¹èƒ½å¤Ÿæ¨æ–­æ–‡æœ¬äº¤äº’çš„æ½œåœ¨å«ä¹‰ã€‚æœ¬æ–‡æ¢è®¨LLMsæ˜¯å¦å…·å¤‡ç†è§£ä»–äººæ„å›¾çš„èƒ½åŠ›ï¼Œå³æ˜¯å¦æ‹¥æœ‰æŸç§ç†è®ºå¿ƒæ™ºã€‚ç†è§£ä»–äººæ„å›¾å¯¹äºæœ‰æ•ˆåˆä½œè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ™ºèƒ½ä½“ï¼ˆåŒ…æ‹¬äººç±»å’Œè‡ªä¸»ç³»ç»Ÿï¼‰ä¹‹é—´çš„äº’åŠ¨ä¸­ã€‚æˆ‘ä»¬é€šè¿‡åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ç ”ç©¶LLMsçš„ç†è®ºå¿ƒæ™ºï¼Œæ—¨åœ¨æå‡äººå·¥æ™ºèƒ½ä½“ä¸äººç±»åŠå…¶ä»–äººå·¥æ™ºèƒ½ä½“çš„é€‚åº”ä¸åˆä½œèƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ™ºèƒ½ä½“åˆä½œä¸­å¯¹ä»–äººæ„å›¾ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ¨¡æ‹Ÿäººç±»çš„ç¤¾ä¼šæ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´åˆä½œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥åˆä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¡†æ¶ï¼Œæœ¬æ–‡æ¢ç´¢LLMså¦‚ä½•é€šè¿‡åå¤äº¤äº’å­¦ä¹ ç†è§£ä»–äººæ„å›¾ï¼Œä»è€Œæå‡åˆä½œèƒ½åŠ›ã€‚è¯¥è®¾è®¡æ—¨åœ¨æ¨¡æ‹Ÿäººç±»çš„ç¤¾äº¤æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ™ºèƒ½ä½“é€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œäº¤äº’ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ„å›¾æ¨ç†æ¨¡å—ã€åˆä½œç­–ç•¥æ¨¡å—å’Œåé¦ˆå­¦ä¹ æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç†è®ºå¿ƒæ™ºçš„æ¦‚å¿µå¼•å…¥åˆ°LLMsçš„è®­ç»ƒä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­æœ‰æ•ˆæ¨ç†ä»–äººæ„å›¾ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†åˆä½œæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åŸºäºç­–ç•¥æ¢¯åº¦çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œç»“åˆäº†å¤šæ™ºèƒ½ä½“çš„äº¤äº’æœºåˆ¶ï¼Œè®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ„å›¾æ¨ç†çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„å¤šæ™ºèƒ½ä½“è¯­è¨€æ¨¡å‹åœ¨ä¸äººç±»åˆä½œæ—¶çš„é€‚åº”æ€§æå‡äº†çº¦30%ï¼Œåœ¨ä»»åŠ¡å®Œæˆæ•ˆç‡ä¸Šè¾ƒåŸºçº¿æ¨¡å‹æé«˜äº†25%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºåä½œã€æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡äººå·¥æ™ºèƒ½ä½“çš„åˆä½œèƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œå’Œæ›´è‡ªç„¶çš„äººæœºäº¤äº’ï¼Œæœªæ¥å¯èƒ½åœ¨å„ç±»æ™ºèƒ½ç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Modern Large Language Models (LLMs) exhibit impressive zero-shot and few-shot generalization capabilities across complex natural language tasks, enabling their widespread use as virtual assistants for diverse applications such as translation and summarization. Despite being trained solely on large corpora of text without explicit supervision on author intent, LLMs appear to infer the underlying meaning of textual interactions. This raises a fundamental question: can LLMs model and reason about the intentions of others, i.e., do they possess a form of theory of mind? Understanding other's intentions is crucial for effective collaboration, which underpins human societal success and is essential for cooperative interactions among multiple agents, including humans and autonomous systems. In this work, we investigate the theory of mind in LLMs through the lens of cooperative multi-agent reinforcement learning (MARL), where agents learn to collaborate via repeated interactions, mirroring human social reasoning. Our approach aims to enhance artificial agent's ability to adapt and cooperate with both artificial and human partners. By leveraging LLM-based agents capable of natural language interaction, we move towards creating hybrid human-AI systems that can foster seamless collaboration, with broad implications for the future of human-artificial interaction.

