---
layout: default
title: Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings
---

# Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09424" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09424v1</a>
  <a href="https://arxiv.org/pdf/2506.09424.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09424v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09424v1', 'Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: Accepted to ACL 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­çš„æ¬ºéª—æ£€æµ‹èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¬ºéª—æ£€æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€æ¨¡å‹` `å®éªŒè¯„ä¼°` `éè¯­è¨€ç‰¹å¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¬ºéª—æ£€æµ‹æ–¹æ³•åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è·¨æ¨¡æ€çº¿ç´¢çš„åˆ©ç”¨ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç³»ç»Ÿè¯„ä¼°LLMså’ŒLMMsåœ¨æ¬ºéª—æ£€æµ‹ä¸­çš„èƒ½åŠ›çš„æ–¹æ³•ï¼Œæ¶µç›–å¤šç§å®éªŒè®¾ç½®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„LLMsåœ¨æ–‡æœ¬æ¬ºéª—æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè€ŒLMMsçš„è·¨æ¨¡æ€èƒ½åŠ›å°šå¾…æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ•°å­—åŒ–æ—¥ç›Šæ™®åŠçš„èƒŒæ™¯ä¸‹ï¼Œæ¬ºéª—æ£€æµ‹æˆä¸ºä¸€é¡¹é‡è¦ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚æœ¬ç ”ç©¶å…¨é¢è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åœ¨ä¸åŒé¢†åŸŸçš„è‡ªåŠ¨åŒ–æ¬ºéª—æ£€æµ‹èƒ½åŠ›ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†å¼€æºå’Œå•†ä¸šLLMsçš„è¡¨ç°ï¼Œç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„LLMsåœ¨æ–‡æœ¬æ¬ºéª—æ£€æµ‹ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè€ŒLMMsåœ¨å……åˆ†åˆ©ç”¨è·¨æ¨¡æ€çº¿ç´¢æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ†æäº†éè¯­è¨€æ‰‹åŠ¿å’Œè§†é¢‘æ‘˜è¦ç­‰è¾…åŠ©ç‰¹å¾çš„å½±å“ï¼Œå¹¶è€ƒå¯Ÿäº†ä¸åŒæç¤ºç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶ç»“æœä¸ºLLMså¦‚ä½•å¤„ç†å’Œè§£è¯»å¤šæ¨¡æ€ä¸­çš„æ¬ºéª—çº¿ç´¢æä¾›äº†é‡è¦è§è§£ï¼Œçªæ˜¾äº†å…¶åœ¨ç°å®ä¸–ç•Œæ¬ºéª—æ£€æµ‹åº”ç”¨ä¸­çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­æ¬ºéª—æ£€æµ‹çš„æœ‰æ•ˆæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨åˆ©ç”¨è·¨æ¨¡æ€ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å…¨é¢æ•æ‰æ¬ºéª—çº¿ç´¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒç±»å‹çš„LLMså’ŒLMMsåœ¨å¤šç§æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œæ¢ç´¢å…¶åœ¨æ¬ºéª—æ£€æµ‹ä¸­çš„æ½œåŠ›å’Œå±€é™æ€§ï¼Œç‰¹åˆ«å…³æ³¨é›¶-shotå’Œfew-shotå­¦ä¹ ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸‰ä¸ªæ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œåˆ†åˆ«ä¸ºçœŸå®å®¡åˆ¤è®¿è°ˆï¼ˆRLTDï¼‰ã€äººé™…åœºæ™¯ä¸­çš„æŒ‡ä»¤æ€§æ¬ºéª—ï¼ˆMU3Dï¼‰å’Œæ¬ºéª—æ€§è¯„è®ºï¼ˆOpSpamï¼‰ã€‚è¯„ä¼°è¿‡ç¨‹ä¸­åŒ…æ‹¬ä¸åŒçš„å®éªŒè®¾ç½®ï¼Œå¦‚éšæœºé€‰æ‹©ç¤ºä¾‹å’ŒåŸºäºç›¸ä¼¼æ€§çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†LLMså’ŒLMMsåœ¨å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å¾®è°ƒLLMsåœ¨æ–‡æœ¬æ¬ºéª—æ£€æµ‹ä¸­çš„ä¼˜åŠ¿åŠLMMsåœ¨è·¨æ¨¡æ€çº¿ç´¢åˆ©ç”¨ä¸Šçš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­é‡‡ç”¨äº†å¤šç§æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬ç›´æ¥æ ‡ç­¾ç”Ÿæˆå’Œé“¾å¼æ€ç»´æ¨ç†ï¼ŒåŒæ—¶åˆ†æäº†éè¯­è¨€æ‰‹åŠ¿å’Œè§†é¢‘æ‘˜è¦ç­‰è¾…åŠ©ç‰¹å¾å¯¹æ¬ºéª—æ£€æµ‹çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„LLMsåœ¨æ–‡æœ¬æ¬ºéª—æ£€æµ‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œè€ŒLMMsåœ¨è·¨æ¨¡æ€æ¬ºéª—æ£€æµ‹ä¸­è¡¨ç°ä¸ä½³ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨è¾…åŠ©ç‰¹å¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹å®¡åˆ¤ã€åœ¨çº¿è¯„è®ºç›‘æµ‹å’Œç¤¾äº¤åª’ä½“åˆ†æç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ç›¸å…³è¡Œä¸šæé«˜æ¬ºéª—æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼ŒLLMså’ŒLMMsåœ¨æ¬ºéª—æ£€æµ‹ä¸­çš„åº”ç”¨å°†æ›´åŠ å¹¿æ³›ï¼Œæ¨åŠ¨æ™ºèƒ½ç›‘æ§å’Œå®‰å…¨ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detecting deception in an increasingly digital world is both a critical and challenging task. In this study, we present a comprehensive evaluation of the automated deception detection capabilities of Large Language Models (LLMs) and Large Multimodal Models (LMMs) across diverse domains. We assess the performance of both open-source and commercial LLMs on three distinct datasets: real life trial interviews (RLTD), instructed deception in interpersonal scenarios (MU3D), and deceptive reviews (OpSpam). We systematically analyze the effectiveness of different experimental setups for deception detection, including zero-shot and few-shot approaches with random or similarity-based in-context example selection. Our results show that fine-tuned LLMs achieve state-of-the-art performance on textual deception detection tasks, while LMMs struggle to fully leverage cross-modal cues. Additionally, we analyze the impact of auxiliary features, such as non-verbal gestures and video summaries, and examine the effectiveness of different prompting strategies, including direct label generation and chain-of-thought reasoning. Our findings provide key insights into how LLMs process and interpret deceptive cues across modalities, highlighting their potential and limitations in real-world deception detection applications.

