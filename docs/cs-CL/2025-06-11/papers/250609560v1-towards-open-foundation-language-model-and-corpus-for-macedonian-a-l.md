---
layout: default
title: Towards Open Foundation Language Model and Corpus for Macedonian: A Low-Resource Language
---

# Towards Open Foundation Language Model and Corpus for Macedonian: A Low-Resource Language

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09560" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09560v1</a>
  <a href="https://arxiv.org/pdf/2506.09560.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09560v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09560v1', 'Towards Open Foundation Language Model and Corpus for Macedonian: A Low-Resource Language')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Stefan Krsteski, Matea Tashkovska, Borjan Sazdov, Hristijan Gjoreski, Branislav Gerazov

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: Camera-ready version accepted at SlavNLP-2025@ACL

**DOI**: [10.18653/v1/2025.bsnlp-1.6](https://doi.org/10.18653/v1/2025.bsnlp-1.6)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé©¬å…¶é¡¿å¼€æ”¾åŸºç¡€è¯­è¨€æ¨¡å‹åŠè¯­æ–™åº“ä»¥è§£å†³ä½èµ„æºè¯­è¨€é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½èµ„æºè¯­è¨€` `é©¬å…¶é¡¿è¯­` `è¯­æ–™åº“` `æ¨¡å‹è®­ç»ƒ` `æ–‡åŒ–é€‚åº”æ€§` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„åº”ç”¨èƒ½åŠ›æœ‰é™ï¼Œå¯¼è‡´é©¬å…¶é¡¿è¯­çš„æŠ€æœ¯å·¥å…·ç¼ºä¹ï¼Œå½±å“äº†å…¶æ™®åŠã€‚
2. æœ¬æ–‡é€šè¿‡æ”¶é›†é©¬å…¶é¡¿è¯­çš„æœ€å¤§è¯­æ–™åº“å’Œæ„å»ºæ–‡åŒ–åŸºç¡€çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„èµ„æºæ”¯æŒæ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè®­ç»ƒçš„8Bå‚æ•°æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†æ‰€æœ‰ç°æœ‰æ¨¡å‹ï¼Œä¸”åœ¨è¯­æ³•å’Œæ–‡åŒ–é€‚åº”æ€§ä¸Šè·å¾—äº†æ›´é«˜çš„è¯„ä»·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å…¨çƒæŠ€æœ¯çš„æ™®åŠï¼Œå¯¹æ–°å·¥å…·çš„éœ€æ±‚æ—¥ç›Šå¢åŠ ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¿™æ–¹é¢æä¾›äº†è‰¯å¥½çš„æœºä¼šï¼Œä½†å¯¹äºä½èµ„æºè¯­è¨€çš„èƒ½åŠ›ä»ç„¶æœ‰é™ï¼Œé™åˆ¶äº†è¿™äº›è¯­è¨€çš„åº”ç”¨ã€‚æœ¬æ–‡åˆ›å»ºäº†å¤šä¸ªèµ„æºä»¥ä¿ƒè¿›LLMsçš„é‡‡ç”¨ï¼Œå¹¶æ”¯æŒé©¬å…¶é¡¿è¯­çš„ç ”ç©¶è¿›å±•ã€‚æˆ‘ä»¬æ”¶é›†äº†è¿„ä»Šä¸ºæ­¢æœ€å¤§çš„é©¬å…¶é¡¿è¯­è¯­æ–™åº“ï¼ŒåŒ…å«40GBæ–‡æœ¬æ•°æ®å’Œ35äº¿è¯æ±‡ã€‚ä¸ºæ”¯æŒå¯¹è¯åº”ç”¨ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ª106kå®ä¾‹çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œç¡®ä¿å…¶æ–‡åŒ–åŸºç¡€ã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†ä¸€ä¸ªæ¶µç›–ä¸ƒä¸ªåŸºå‡†çš„é©¬å…¶é¡¿è¯„ä¼°å¥—ä»¶ï¼Œå¹¶è®­ç»ƒäº†ä¸€ä¸ª8Bå‚æ•°çš„æ¨¡å‹ï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¨¡å‹åœ¨æ‰€æœ‰åŸºå‡†ä¸Šå‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨è¯­æ³•æ­£ç¡®æ€§å’Œæ–‡åŒ–é€‚åº”æ€§æ–¹é¢è·å¾—äº†æ›´é«˜çš„è¯„ä»·ã€‚æ‰€æœ‰æ•°æ®é›†ã€ä»£ç å’Œæ¨¡å‹æƒé‡å‡å·²å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä½èµ„æºè¯­è¨€é©¬å…¶é¡¿è¯­åœ¨å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æ»¡è¶³è¯¥è¯­è¨€çš„æŠ€æœ¯éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºå¤§è§„æ¨¡çš„é©¬å…¶é¡¿è¯­è¯­æ–™åº“å’Œæ–‡åŒ–åŸºç¡€çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œæä¾›æ”¯æŒä»¥ä¿ƒè¿›LLMsçš„ç ”ç©¶å’Œåº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†40GBçš„æ–‡æœ¬æ•°æ®ï¼Œç„¶åæ„å»º106kå®ä¾‹çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œæœ€åè®­ç»ƒ8Bå‚æ•°çš„æ¨¡å‹å¹¶è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹é©¬å…¶é¡¿è¯­çš„è¯„ä¼°å¥—ä»¶ï¼Œå¹¶è®­ç»ƒå‡ºåœ¨8Bå‚æ•°èŒƒå›´å†…è¡¨ç°æœ€ä¼˜çš„æ¨¡å‹ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æ‰€æœ‰åŒç±»æ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ï¼Œç¡®ä¿æ¨¡å‹åœ¨è¯­æ³•å’Œæ–‡åŒ–é€‚åº”æ€§æ–¹é¢çš„è¡¨ç°ä¼˜äºæ›´å¤§è§„æ¨¡çš„æ¨¡å‹ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè®­ç»ƒç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®­ç»ƒçš„8Bå‚æ•°æ¨¡å‹åœ¨æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­å‡è¶…è¶Šäº†ç°æœ‰çš„æ¨¡å‹ï¼Œä¸”åœ¨è¯­æ³•æ­£ç¡®æ€§å’Œæ–‡åŒ–é€‚åº”æ€§æ–¹é¢è·å¾—äº†æ›´é«˜çš„è¯„ä»·ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹çš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œç”šè‡³ä¸10å€å‚æ•°çš„æ¨¡å‹ç›¸å½“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ–‡åŒ–ä¼ æ’­å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚é€šè¿‡æä¾›é©¬å…¶é¡¿è¯­çš„åŸºç¡€è¯­è¨€æ¨¡å‹å’Œè¯­æ–™åº“ï¼Œå¯ä»¥ä¿ƒè¿›è¯¥è¯­è¨€åœ¨æŠ€æœ¯é¢†åŸŸçš„åº”ç”¨ï¼Œæå‡å…¶åœ¨å…¨çƒåŒ–èƒŒæ™¯ä¸‹çš„å¯ç”¨æ€§å’Œå½±å“åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increase in technological adoption worldwide comes with demands for novel tools to be used by the general population. Large Language Models (LLMs) provide a great opportunity in this respect, but their capabilities remain limited for low-resource languages, restricting applications in countries where such languages are spoken. We create several resources to facilitate the adoption of LLMs and to support research advancements for Macedonian. We collect the largest Macedonian corpus to date, consisting of 40GB of textual data and totaling 3.5B words. To support conversational applications, we collect a 106k-instance instruction dataset, carefully built to be culturally grounded. For evaluation, we construct a Macedonian evaluation suite covering seven benchmarks. Finally, we train domestic-yak, a state-of-the-art 8B-parameter model, on our curated datasets and evaluate it against eight baseline models using the newly constructed benchmark suite. Our model outperforms all existing models in the 8B parameter range across all benchmarks, and achieves performance comparable to models up to 10x larger. Furthermore, a qualitative analysis with native speakers reveals that our model is preferred over larger counterparts, receiving higher ratings for grammatical correctness and cultural appropriateness. All datasets, code, and model weights are openly released, setting a foundation for advancing LLMs in similarly underrepresented languages. These resources are publicly available at github.com/LVSTCK for source code, and at huggingface.co/LVSTCK for pretrained model weights and data.

