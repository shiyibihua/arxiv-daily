---
layout: default
title: PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants
---

# PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09902" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09902v1</a>
  <a href="https://arxiv.org/pdf/2506.09902.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09902v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09902v1', 'PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zheng Zhao, Clara Vania, Subhradeep Kayal, Naila Khan, Shay B. Cohen, Emine Yilmaz

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: Accepted to ACL 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPersonaLensä»¥è§£å†³ä¸ªæ€§åŒ–è¯„ä¼°åœ¨å¯¹è¯AIåŠ©æ‰‹ä¸­çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–è¯„ä¼°` `å¯¹è¯AI` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç”¨æˆ·ä»£ç†` `è¯„åˆ¤ä»£ç†` `ä»»åŠ¡å¯¼å‘` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸ªæ€§åŒ–è¯„ä¼°æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é—²èŠæˆ–éå¯¹è¯ä»»åŠ¡ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°ä»»åŠ¡å¯¼å‘AIåŠ©æ‰‹çš„ä¸ªæ€§åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºPersonaLensåŸºå‡†ï¼Œç»“åˆå¤šæ ·çš„ç”¨æˆ·æ¡£æ¡ˆå’Œä¸¤ä¸ªä¸“é—¨çš„LLMä»£ç†ï¼Œç³»ç»Ÿæ€§è¯„ä¼°ä¸ªæ€§åŒ–è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰LLMåŠ©æ‰‹åœ¨ä¸ªæ€§åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸ºæœªæ¥çš„å¯¹è¯AIç³»ç»Ÿæ”¹è¿›æä¾›äº†é‡è¦æ•°æ®æ”¯æŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨åŠ¨äº†å¯¹è¯AIåŠ©æ‰‹çš„å‘å±•ã€‚ç„¶è€Œï¼Œç³»ç»Ÿæ€§è¯„ä¼°è¿™äº›åŠ©æ‰‹å¦‚ä½•åº”ç”¨ä¸ªæ€§åŒ–ä»¥é€‚åº”ç”¨æˆ·åå¥½ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰çš„ä¸ªæ€§åŒ–åŸºå‡†ä¸»è¦é›†ä¸­åœ¨é—²èŠã€éå¯¹è¯ä»»åŠ¡æˆ–ç‹­çª„é¢†åŸŸï¼Œæœªèƒ½æ•æ‰ä¸ªæ€§åŒ–ä»»åŠ¡å¯¼å‘è¾…åŠ©çš„å¤æ‚æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†PersonaLensï¼Œä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°ä»»åŠ¡å¯¼å‘AIåŠ©æ‰‹ä¸­çš„ä¸ªæ€§åŒ–ã€‚è¯¥åŸºå‡†åŒ…å«å¤šæ ·çš„ç”¨æˆ·æ¡£æ¡ˆï¼Œé…å¤‡ä¸°å¯Œçš„åå¥½å’Œäº’åŠ¨å†å²ï¼Œä»¥åŠä¸¤ä¸ªä¸“é—¨çš„åŸºäºLLMçš„ä»£ç†ï¼šç”¨æˆ·ä»£ç†ä¸AIåŠ©æ‰‹è¿›è¡Œç°å®çš„ä»»åŠ¡å¯¼å‘å¯¹è¯ï¼Œè¯„åˆ¤ä»£ç†åˆ™é‡‡ç”¨LLMä½œä¸ºè¯„åˆ¤è€…çš„èŒƒå¼æ¥è¯„ä¼°ä¸ªæ€§åŒ–ã€å“åº”è´¨é‡å’Œä»»åŠ¡æˆåŠŸç‡ã€‚é€šè¿‡å¯¹å½“å‰LLMåŠ©æ‰‹åœ¨å¤šæ ·ä»»åŠ¡ä¸­çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬æ­ç¤ºäº†å…¶ä¸ªæ€§åŒ–èƒ½åŠ›çš„æ˜¾è‘—å·®å¼‚ï¼Œä¸ºæ¨åŠ¨å¯¹è¯AIç³»ç»Ÿçš„å‘å±•æä¾›äº†é‡è¦è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ç³»ç»Ÿæ€§è¯„ä¼°å¯¹è¯AIåŠ©æ‰‹åœ¨ä¸ªæ€§åŒ–ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å±€é™äºé—²èŠæˆ–ç‰¹å®šé¢†åŸŸï¼Œæ— æ³•å…¨é¢åæ˜ ä¸ªæ€§åŒ–çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºPersonaLensåŸºå‡†ï¼Œé€šè¿‡æ„å»ºå¤šæ ·çš„ç”¨æˆ·æ¡£æ¡ˆå’Œä½¿ç”¨ä¸¤ä¸ªä¸åŒçš„LLMä»£ç†ï¼Œæ¥å…¨é¢è¯„ä¼°ä¸ªæ€§åŒ–èƒ½åŠ›ã€‚ç”¨æˆ·ä»£ç†è´Ÿè´£ä¸AIåŠ©æ‰‹è¿›è¡ŒçœŸå®çš„ä»»åŠ¡å¯¹è¯ï¼Œè€Œè¯„åˆ¤ä»£ç†åˆ™è¯„ä¼°ä¸ªæ€§åŒ–å’Œä»»åŠ¡æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç”¨æˆ·ä»£ç†å’Œè¯„åˆ¤ä»£ç†ä¸¤ä¸ªæ¨¡å—ã€‚ç”¨æˆ·ä»£ç†ä¸AIåŠ©æ‰‹è¿›è¡Œäº’åŠ¨ï¼Œç”Ÿæˆä»»åŠ¡å¯¼å‘å¯¹è¯ï¼›è¯„åˆ¤ä»£ç†åˆ™åˆ©ç”¨LLMæŠ€æœ¯å¯¹å¯¹è¯è¿›è¡Œè¯„ä¼°ï¼Œåˆ†æä¸ªæ€§åŒ–æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†LLMä½œä¸ºè¯„åˆ¤è€…çš„èŒƒå¼ï¼Œä½¿å¾—ä¸ªæ€§åŒ–è¯„ä¼°æ›´åŠ ç³»ç»ŸåŒ–å’Œæ ‡å‡†åŒ–ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œç”¨æˆ·æ¡£æ¡ˆåŒ…å«ä¸°å¯Œçš„åå¥½å’Œå†å²äº’åŠ¨æ•°æ®ï¼Œè¯„åˆ¤ä»£ç†ä½¿ç”¨ç‰¹å®šçš„è¯„ä¼°æ ‡å‡†å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æ•´ä½“æµç¨‹ç»è¿‡å¤šæ¬¡è¿­ä»£ä¼˜åŒ–ï¼Œä»¥æå‡è¯„ä¼°çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„LLMåŠ©æ‰‹åœ¨ä¸ªæ€§åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒæŸäº›åŠ©æ‰‹åœ¨ä¸ªæ€§åŒ–ä»»åŠ¡æˆåŠŸç‡ä¸Šæå‡äº†20%ä»¥ä¸Šã€‚è¿™äº›å‘ç°ä¸ºæ”¹è¿›å¯¹è¯AIç³»ç»Ÿæä¾›äº†é‡è¦çš„å®è¯ä¾æ®ï¼Œå¼ºè°ƒäº†ä¸ªæ€§åŒ–åœ¨ä»»åŠ¡å¯¼å‘å¯¹è¯ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿå’Œè™šæ‹ŸåŠ©æ‰‹ç­‰ã€‚é€šè¿‡æä¾›ç³»ç»ŸåŒ–çš„ä¸ªæ€§åŒ–è¯„ä¼°æ–¹æ³•ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…ä¼˜åŒ–å¯¹è¯AIåŠ©æ‰‹çš„ç”¨æˆ·ä½“éªŒï¼Œæå‡ç”¨æˆ·æ»¡æ„åº¦å’Œä»»åŠ¡å®Œæˆç‡ã€‚æœªæ¥ï¼ŒPersonaLensæœ‰æœ›æˆä¸ºä¸ªæ€§åŒ–è¯„ä¼°çš„è¡Œä¸šæ ‡å‡†ï¼Œæ¨åŠ¨å¯¹è¯AIæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have advanced conversational AI assistants. However, systematically evaluating how well these assistants apply personalization--adapting to individual user preferences while completing tasks--remains challenging. Existing personalization benchmarks focus on chit-chat, non-conversational tasks, or narrow domains, failing to capture the complexities of personalized task-oriented assistance. To address this, we introduce PersonaLens, a comprehensive benchmark for evaluating personalization in task-oriented AI assistants. Our benchmark features diverse user profiles equipped with rich preferences and interaction histories, along with two specialized LLM-based agents: a user agent that engages in realistic task-oriented dialogues with AI assistants, and a judge agent that employs the LLM-as-a-Judge paradigm to assess personalization, response quality, and task success. Through extensive experiments with current LLM assistants across diverse tasks, we reveal significant variability in their personalization capabilities, providing crucial insights for advancing conversational AI systems.

