---
layout: default
title: Query-Level Uncertainty in Large Language Models
---

# Query-Level Uncertainty in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09669" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09669v3</a>
  <a href="https://arxiv.org/pdf/2506.09669.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09669v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09669v3', 'Query-Level Uncertainty in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lihu Chen, Gerard de Melo, Fabian M. Suchanek, GaÃ«l Varoquaux

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-10-06)

**å¤‡æ³¨**: Under Review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæŸ¥è¯¢çº§ä¸ç¡®å®šæ€§æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†è¾¹ç•Œè¯†åˆ«**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æŸ¥è¯¢çº§ä¸ç¡®å®šæ€§` `çŸ¥è¯†è¾¹ç•Œ` `è‡ªé€‚åº”æ¨ç†` `å†…éƒ¨ä¿¡å¿ƒ` `ä¿¡æ¯æ£€ç´¢` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«çŸ¥è¯†è¾¹ç•Œæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†å¯å›ç­”ä¸ä¸å¯å›ç­”çš„æŸ¥è¯¢ã€‚
2. æœ¬æ–‡æå‡ºçš„å†…éƒ¨ä¿¡å¿ƒæ–¹æ³•é€šè¿‡å±‚ä¸æ ‡è®°çš„è‡ªæˆ‘è¯„ä¼°ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆä¹‹å‰è¯„ä¼°æ¨¡å‹çš„å›ç­”èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå†…éƒ¨ä¿¡å¿ƒåœ¨ä¿¡å¿ƒè´¨é‡ä¸Šä¼˜äºå¤šä¸ªåŸºçº¿ï¼ŒåŒæ—¶åœ¨è‡ªé€‚åº”æ¨ç†ä¸­é™ä½äº†æ¨ç†æˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éœ€è¦è¯†åˆ«å…¶çŸ¥è¯†è¾¹ç•Œï¼Œä»¥åŒºåˆ†èƒ½å¤Ÿè‡ªä¿¡å›ç­”çš„æŸ¥è¯¢ä¸è¶…å‡ºå…¶èƒ½åŠ›èŒƒå›´çš„æŸ¥è¯¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æŸ¥è¯¢çº§ä¸ç¡®å®šæ€§æ¥æ£€æµ‹çŸ¥è¯†è¾¹ç•Œçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆä»»ä½•æ ‡è®°ä¹‹å‰è¯„ä¼°æ¨¡å‹æ˜¯å¦èƒ½å¤Ÿå›ç­”ç‰¹å®šæŸ¥è¯¢ï¼Œä»è€Œé¿å…ç”Ÿæˆæˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºå†…éƒ¨ä¿¡å¿ƒçš„è®­ç»ƒæ— å…³æ–¹æ³•ï¼Œåˆ©ç”¨å±‚å’Œæ ‡è®°çš„è‡ªæˆ‘è¯„ä¼°æä¾›å¯é çš„ä¸ç¡®å®šæ€§ä¿¡å·ã€‚å®è¯ç ”ç©¶è¡¨æ˜ï¼Œå†…éƒ¨ä¿¡å¿ƒåœ¨äº‹å®é—®ç­”å’Œæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ä¼˜äºå¤šä¸ªåŸºçº¿ï¼ŒåŒæ—¶è®¡ç®—æˆæœ¬æ›´ä½ï¼Œå¹¶åœ¨è‡ªé€‚åº”æ¨ç†è®¾ç½®ä¸­å±•ç°å‡ºå…¶ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å›ç­”æŸ¥è¯¢æ—¶æ— æ³•æœ‰æ•ˆè¯†åˆ«çŸ¥è¯†è¾¹ç•Œçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨ç”Ÿæˆå›ç­”åæ‰å‘ç°æ¨¡å‹çš„èƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´ä¸å¿…è¦çš„è®¡ç®—å¼€é”€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å†…éƒ¨ä¿¡å¿ƒæ–¹æ³•é€šè¿‡è‡ªæˆ‘è¯„ä¼°æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ç”Ÿæˆä»»ä½•æ ‡è®°ä¹‹å‰è¯„ä¼°æ¨¡å‹çš„å›ç­”èƒ½åŠ›ï¼Œä»è€Œé¿å…ä¸å¿…è¦çš„ç”Ÿæˆæˆæœ¬ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨é¢å¯¹ä¸ç¡®å®šæ€§æ—¶èƒ½å¤Ÿé‡‡å–æ›´ä¸ºçµæ´»çš„åº”å¯¹ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯è‡ªæˆ‘è¯„ä¼°æ¨¡å—ï¼Œé€šè¿‡å¯¹å±‚ä¸æ ‡è®°çš„åˆ†ææ¥è®¡ç®—ä¸ç¡®å®šæ€§ä¿¡å·ï¼›å…¶æ¬¡æ˜¯å†³ç­–æ¨¡å—ï¼Œæ ¹æ®ä¸ç¡®å®šæ€§ä¿¡å·å†³å®šæ˜¯å¦è¿›è¡Œç”Ÿæˆæˆ–è°ƒç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šå†…éƒ¨ä¿¡å¿ƒæ–¹æ³•çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶è®­ç»ƒæ— å…³æ€§å’Œé«˜æ•ˆæ€§ï¼Œé€šè¿‡è‡ªæˆ‘è¯„ä¼°æä¾›çš„ä¸ç¡®å®šæ€§ä¿¡å·ï¼Œä½¿å¾—æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„æŸ¥è¯¢ç±»å‹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼Œå†…éƒ¨ä¿¡å¿ƒæ–¹æ³•é‡‡ç”¨äº†å¤šå±‚æ¬¡çš„è‡ªæˆ‘è¯„ä¼°æœºåˆ¶ï¼Œç»“åˆäº†ä¸åŒå±‚çš„è¾“å‡ºä¿¡æ¯ï¼Œç¡®ä¿ä¿¡å¿ƒè¯„ä¼°çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†ä¸ç¡®å®šæ€§ä¿¡å·çš„æœ‰æ•ˆæ€§ï¼Œä»¥æå‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå†…éƒ¨ä¿¡å¿ƒæ–¹æ³•åœ¨äº‹å®é—®ç­”å’Œæ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºå¤šä¸ªåŸºçº¿æ–¹æ³•ï¼Œä¿¡å¿ƒè´¨é‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”è®¡ç®—æˆæœ¬é™ä½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨è‡ªé€‚åº”æ¨ç†è®¾ç½®ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨RAGå’Œæ¨¡å‹çº§è”ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¿æŒäº†æ•´ä½“æ€§èƒ½çš„åŒæ—¶å‡å°‘äº†æ¨ç†æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€æ•™è‚²è¾…åŠ©å·¥å…·ä»¥åŠä»»ä½•éœ€è¦é«˜æ•ˆä¿¡æ¯æ£€ç´¢çš„åœºæ™¯ã€‚é€šè¿‡æå‡æ¨¡å‹å¯¹çŸ¥è¯†è¾¹ç•Œçš„è¯†åˆ«èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç”¨æˆ·ä½“éªŒï¼Œå‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œæœªæ¥å¯èƒ½åœ¨ä¿¡ä»»åº¦é«˜çš„AIç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> It is important for Large Language Models (LLMs) to be aware of the boundary of their knowledge, distinguishing queries they can confidently answer from those that lie beyond their capabilities. Such awareness enables models to perform adaptive inference, such as invoking retrieval-augmented generation (RAG), engaging in slow and deep thinking, or abstaining from answering when appropriate. These mechanisms are key to developing efficient and trustworthy AI. In this work, we propose a method to detect knowledge boundaries via Query-Level Uncertainty, which estimates if a model is capable of answering a given query before generating any tokens, thus avoiding the generation cost. To this end, we propose a novel, training-free method called Internal Confidence, which leverages self-evaluations across layers and tokens to provide a reliable signal of uncertainty. Empirical studies on both factual question answering and mathematical reasoning tasks demonstrate that our Internal Confidence outperforms several baselines in quality of confidence while being computationally cheaper. Furthermore, we demonstrate its benefits in adaptive inference settings, showing that for RAG and model cascading it reduces inference costs while preserving overall performance.

