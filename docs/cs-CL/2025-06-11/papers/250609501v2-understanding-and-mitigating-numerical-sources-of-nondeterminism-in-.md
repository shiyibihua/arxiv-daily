---
layout: default
title: Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference
---

# Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09501" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09501v2</a>
  <a href="https://arxiv.org/pdf/2506.09501.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09501v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09501v2', 'Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiayi Yuan, Hao Li, Xinheng Ding, Wenya Xie, Yu-Jhe Li, Wentian Zhao, Kun Wan, Jing Shi, Xia Hu, Zirui Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-10-24)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/nanomaoli/llm_reproducibility)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLayerCastä»¥è§£å†³LLMæ¨ç†ä¸­çš„æ•°å€¼ä¸ç¡®å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°å€¼ä¸ç¡®å®šæ€§` `æ¨ç†å¯é‡å¤æ€§` `LayerCast` `æµ®ç‚¹ç²¾åº¦` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨LLMæ¨ç†ä¸­é¢ä¸´æ•°å€¼ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½çš„å¯é‡å¤æ€§è„†å¼±ã€‚
2. è®ºæ–‡æå‡ºLayerCastï¼Œé€šè¿‡åœ¨16ä½ç²¾åº¦ä¸‹å­˜å‚¨æƒé‡å¹¶åœ¨FP32ä¸‹è¿›è¡Œè®¡ç®—ï¼Œè§£å†³äº†æ•°å€¼ç²¾åº¦å¯¹æ¨ç†ç»“æœçš„å½±å“ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLayerCaståœ¨ä¸åŒç¡¬ä»¶å’Œè½¯ä»¶è®¾ç½®ä¸‹ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹è¾“å‡ºçš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ä¸ªé¢†åŸŸä¸­å·²æˆä¸ºä¸å¯æˆ–ç¼ºçš„å·¥å…·ï¼Œå¹¶å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ã€‚ç„¶è€Œï¼ŒLLMæ€§èƒ½çš„å¯é‡å¤æ€§å´ååˆ†è„†å¼±ï¼Œç³»ç»Ÿé…ç½®çš„å˜åŒ–ï¼ˆå¦‚è¯„ä¼°æ‰¹é‡å¤§å°ã€GPUæ•°é‡å’Œç‰ˆæœ¬ï¼‰ä¼šæ˜¾è‘—å½±å“ç”Ÿæˆçš„å“åº”ã€‚å°¤å…¶åœ¨æ¨ç†æ¨¡å‹ä¸­ï¼Œæ—©æœŸä»¤ç‰Œçš„å¾®å°èˆå…¥å·®å¼‚å¯èƒ½å¯¼è‡´æ€ç»´é“¾çš„åˆ†æ­§ï¼Œæœ€ç»ˆå½±å“å‡†ç¡®æ€§ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†æ•°å€¼ç²¾åº¦å¦‚ä½•å½±å“LLMæ¨ç†çš„å¯é‡å¤æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§è½»é‡çº§æ¨ç†ç®¡é“LayerCastï¼Œèƒ½å¤Ÿåœ¨16ä½ç²¾åº¦ä¸‹å­˜å‚¨æƒé‡ï¼ŒåŒæ—¶åœ¨FP32ä¸‹è¿›è¡Œæ‰€æœ‰è®¡ç®—ï¼Œä»è€Œå¹³è¡¡å†…å­˜æ•ˆç‡ä¸æ•°å€¼ç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†ä¸­çš„æ•°å€¼ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä¸åŒç³»ç»Ÿé…ç½®ä¸‹å¯¼è‡´æ€§èƒ½æ³¢åŠ¨ï¼Œå½±å“å¯é‡å¤æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡LayerCastç®¡é“ï¼Œåœ¨å­˜å‚¨æƒé‡æ—¶ä½¿ç”¨16ä½ç²¾åº¦ï¼Œè€Œåœ¨è®¡ç®—æ—¶ä½¿ç”¨FP32ï¼Œä»¥æ­¤æé«˜æ•°å€¼ç¨³å®šæ€§å¹¶å‡å°‘å†…å­˜å ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLayerCastçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æƒé‡å­˜å‚¨æ¨¡å—å’Œè®¡ç®—æ¨¡å—ï¼Œå‰è€…è´Ÿè´£ä»¥16ä½ç²¾åº¦å­˜å‚¨æ¨¡å‹å‚æ•°ï¼Œåè€…åˆ™åœ¨æ¨ç†æ—¶ä½¿ç”¨FP32è¿›è¡Œè®¡ç®—ï¼Œç¡®ä¿è¾“å‡ºçš„ç¨³å®šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†æ•°å€¼ç²¾åº¦å¯¹LLMæ¨ç†å¯é‡å¤æ€§çš„å½±å“ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¾“å‡ºä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨LayerCastä¸­ï¼Œæƒé‡å­˜å‚¨é‡‡ç”¨16ä½ç²¾åº¦ï¼Œè®¡ç®—è¿‡ç¨‹ä¸­ä½¿ç”¨FP32ï¼Œç¡®ä¿äº†åœ¨ä¸åŒç¡¬ä»¶å’Œè½¯ä»¶ç¯å¢ƒä¸‹çš„æ•°å€¼ç¨³å®šæ€§ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä½¿ç”¨bfloat16ç²¾åº¦å’Œè´ªå©ªè§£ç çš„æƒ…å†µä¸‹ï¼ŒDeepSeek-R1-Distill-Qwen-7Bæ¨¡å‹çš„å‡†ç¡®æ€§å˜åŒ–å¯è¾¾9%ï¼Œå“åº”é•¿åº¦å·®å¼‚å¯è¾¾9000ä¸ªä»¤ç‰Œï¼Œè¡¨æ˜LayerCaståœ¨ä¸åŒGPUé…ç½®ä¸‹æ˜¾è‘—æé«˜äº†æ¨¡å‹è¾“å‡ºçš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰ï¼Œèƒ½å¤Ÿåœ¨è¿™äº›é¢†åŸŸä¸­æé«˜æ¨¡å‹çš„å¯é‡å¤æ€§å’Œå¯é æ€§ï¼Œè¿›è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼ŒLayerCastçš„è®¾è®¡ç†å¿µä¹Ÿå¯èƒ½è¢«åº”ç”¨äºå…¶ä»–ç±»å‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ¨åŠ¨æ›´å¹¿æ³›çš„ç ”ç©¶å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are now integral across various domains and have demonstrated impressive performance. Progress, however, rests on the premise that benchmark scores are both accurate and reproducible. We demonstrate that the reproducibility of LLM performance is fragile: changing system configuration, such as evaluation batch size, GPU count, and GPU version, can introduce significant differences in the generated responses. This issue is especially pronounced in reasoning models, where minor rounding differences in early tokens can cascade into divergent chains of thought, ultimately affecting accuracy. For instance, under bfloat16 precision with greedy decoding, a reasoning model like DeepSeek-R1-Distill-Qwen-7B can exhibit up to 9% variation in accuracy and 9,000 tokens difference in response length due to differences in GPU count, type, and evaluation batch size. We trace the root cause of this variability to the non-associative nature of floating-point arithmetic under limited numerical precision. This work presents the first systematic investigation into how numerical precision affects reproducibility in LLM inference. Through carefully controlled experiments across various hardware, software, and precision settings, we quantify when and how model outputs diverge. Our analysis reveals that floating-point precision - while critical for reproducibility - is often neglected in evaluation practices. Inspired by this, we develop a lightweight inference pipeline, dubbed LayerCast, that stores weights in 16-bit precision but performs all computations in FP32, balancing memory efficiency with numerical stability. Code is available at https://github.com/nanomaoli/llm_reproducibility.

