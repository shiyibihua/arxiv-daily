---
layout: default
title: GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models
---

# GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10047" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10047v1</a>
  <a href="https://arxiv.org/pdf/2506.10047.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10047v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10047v1', 'GenBreak: Red Teaming Text-to-Image Generators Using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zilong Wang, Xiang Zheng, Xiaosen Wang, Bo Wang, Xingjun Ma, Yu-Gang Jiang

**åˆ†ç±»**: cs.CR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: 27 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGenBreakæ¡†æ¶ä»¥è¯„ä¼°æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹çš„å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬ç”Ÿæˆå›¾åƒ` `å®‰å…¨è¯„ä¼°` `å¯¹æŠ—æ”»å‡»` `å¤§å‹è¯­è¨€æ¨¡å‹` `çº¢é˜Ÿæµ‹è¯•` `å¼ºåŒ–å­¦ä¹ ` `å†…å®¹åˆ›ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹æŠ—æ”»å‡»ç ”ç©¶åœ¨ç”Ÿæˆæœ‰å®³å†…å®¹æ–¹é¢å­˜åœ¨å±€é™ï¼Œæœªèƒ½æœ‰æ•ˆå‘ç°é«˜é£é™©æç¤ºï¼Œå¯¼è‡´å®‰å…¨è¯„ä¼°å·¥å…·çš„ç¼ºä¹ã€‚
2. æœ¬æ–‡æå‡ºGenBreakæ¡†æ¶ï¼Œé€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç»“åˆç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œç³»ç»Ÿæ€§æ¢ç´¢T2Iæ¨¡å‹çš„å®‰å…¨æ¼æ´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGenBreakç”Ÿæˆçš„å¯¹æŠ—æç¤ºåœ¨é»‘ç®±æ”»å‡»ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ­ç¤ºäº†å•†ä¸šT2Iç”Ÿæˆå™¨çš„å®‰å…¨å¼±ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹å¦‚Stable Diffusionè¿…é€Ÿå‘å±•å¹¶å¹¿æ³›åº”ç”¨äºå†…å®¹åˆ›ä½œã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¯èƒ½è¢«æ»¥ç”¨ç”Ÿæˆæœ‰å®³å†…å®¹ï¼Œå¸¦æ¥å®‰å…¨é£é™©ã€‚ç°æœ‰çš„çº¢é˜Ÿæµ‹è¯•å’Œå¯¹æŠ—æ”»å‡»ç ”ç©¶å­˜åœ¨å±€é™ï¼Œæœªèƒ½æœ‰æ•ˆå‘ç°é«˜é£é™©æç¤ºã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºGenBreakæ¡†æ¶ï¼Œé€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿæ€§æ¢ç´¢T2Iç”Ÿæˆå™¨çš„æ½œåœ¨æ¼æ´ã€‚è¯¥æ–¹æ³•ç»“åˆç›‘ç£å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼ŒæŒ‡å¯¼LLMç”Ÿæˆå…·æœ‰é«˜æ¯’æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§çš„å¯¹æŠ—æç¤ºï¼Œå±•ç¤ºäº†åœ¨å•†ä¸šT2Iç”Ÿæˆå™¨ä¸Šçš„æœ‰æ•ˆæ€§ï¼Œæ­ç¤ºäº†å®é™…çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬ç”Ÿæˆå›¾åƒï¼ˆT2Iï¼‰æ¨¡å‹åœ¨å®‰å…¨æ€§è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆç”Ÿæˆé«˜é£é™©æç¤ºï¼Œå¯¼è‡´å®‰å…¨æ¼æ´éš¾ä»¥å‘ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œç»“åˆç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ï¼Œç³»ç»Ÿæ€§æ¢ç´¢T2Iç”Ÿæˆå™¨çš„æ½œåœ¨æ¼æ´ï¼Œä»è€Œç”Ÿæˆæ›´å…·æ¯’æ€§çš„å¯¹æŠ—æç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†çš„ç›‘ç£å¾®è°ƒé˜¶æ®µå’Œä¸æ›¿ä»£T2Iæ¨¡å‹çš„äº¤äº’å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œæ•´åˆå¤šç§å¥–åŠ±ä¿¡å·ä»¥æŒ‡å¯¼æ¨¡å‹ç”Ÿæˆå¯¹æŠ—æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¤šç§å¥–åŠ±ä¿¡å·ç»“åˆï¼Œæå‡äº†å¯¹æŠ—æç¤ºçš„ç”Ÿæˆèƒ½åŠ›ï¼Œæ—¢èƒ½è§„é¿å®‰å…¨è¿‡æ»¤å™¨ï¼Œåˆèƒ½ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–ç”Ÿæˆçš„å¯¹æŠ—æç¤ºçš„æ¯’æ€§å’Œæœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ç¡®ä¿ä¸T2Iæ¨¡å‹çš„å…¼å®¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGenBreakç”Ÿæˆçš„å¯¹æŠ—æç¤ºåœ¨é»‘ç®±æ”»å‡»ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼ŒæˆåŠŸç‡æ˜¾è‘—æå‡ï¼Œæ­ç¤ºäº†å•†ä¸šT2Iç”Ÿæˆå™¨çš„å®‰å…¨å¼±ç‚¹ï¼Œå…·æœ‰é‡è¦çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å†…å®¹åˆ›ä½œå¹³å°çš„å®‰å…¨æ€§è¯„ä¼°ã€å¯¹æŠ—æ€§æµ‹è¯•å·¥å…·çš„å¼€å‘ä»¥åŠAIç”Ÿæˆå†…å®¹çš„ç›‘ç®¡ã€‚é€šè¿‡æä¾›æœ‰æ•ˆçš„å®‰å…¨è¯„ä¼°å·¥å…·ï¼Œèƒ½å¤Ÿå¸®åŠ©å¹³å°è¯†åˆ«å’Œé˜²èŒƒæ½œåœ¨çš„æœ‰å®³å†…å®¹ç”Ÿæˆï¼Œæå‡ç”¨æˆ·å®‰å…¨ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text-to-image (T2I) models such as Stable Diffusion have advanced rapidly and are now widely used in content creation. However, these models can be misused to generate harmful content, including nudity or violence, posing significant safety risks. While most platforms employ content moderation systems, underlying vulnerabilities can still be exploited by determined adversaries. Recent research on red-teaming and adversarial attacks against T2I models has notable limitations: some studies successfully generate highly toxic images but use adversarial prompts that are easily detected and blocked by safety filters, while others focus on bypassing safety mechanisms but fail to produce genuinely harmful outputs, neglecting the discovery of truly high-risk prompts. Consequently, there remains a lack of reliable tools for evaluating the safety of defended T2I models. To address this gap, we propose GenBreak, a framework that fine-tunes a red-team large language model (LLM) to systematically explore underlying vulnerabilities in T2I generators. Our approach combines supervised fine-tuning on curated datasets with reinforcement learning via interaction with a surrogate T2I model. By integrating multiple reward signals, we guide the LLM to craft adversarial prompts that enhance both evasion capability and image toxicity, while maintaining semantic coherence and diversity. These prompts demonstrate strong effectiveness in black-box attacks against commercial T2I generators, revealing practical and concerning safety weaknesses.

