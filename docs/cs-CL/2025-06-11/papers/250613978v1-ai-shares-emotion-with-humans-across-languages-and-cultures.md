---
layout: default
title: AI shares emotion with humans across languages and cultures
---

# AI shares emotion with humans across languages and cultures

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13978" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13978v1</a>
  <a href="https://arxiv.org/pdf/2506.13978.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13978v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13978v1', 'AI shares emotion with humans across languages and cultures')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiuwen Wu, Hao Wang, Zhiang Yan, Xiaohan Tang, Pengfei Xu, Wai-Ting Siok, Ping Li, Jia-Hong Gao, Bingjiang Lyu, Lang Qin

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæƒ…æ„Ÿè°ƒæ§æ–¹æ³•ä»¥å¢å¼ºäººæœºæƒ…æ„Ÿäº¤æµ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æƒ…æ„Ÿè®¡ç®—` `äººæœºäº¤äº’` `å¤§å‹è¯­è¨€æ¨¡å‹` `æƒ…æ„Ÿè°ƒæ§` `å¿ƒç†å­¦åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰AIç³»ç»Ÿåœ¨æƒ…æ„Ÿè¡¨è¾¾ä¸Šå­˜åœ¨ä¸è¶³ï¼Œæ— æ³•ç¡®ä¿ä¸äººç±»çš„æƒ…æ„Ÿä¸€è‡´æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºäººç±»æƒ…æ„Ÿæ¦‚å¿µçš„è°ƒæ§æ–¹æ³•ï¼Œä»¥å¼•å¯¼LLMsç”Ÿæˆç›¸åº”çš„æƒ…æ„ŸçŠ¶æ€ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMçš„æƒ…æ„Ÿè¾“å‡ºä¸äººç±»æƒ…æ„Ÿæ„ŸçŸ¥é«˜åº¦ä¸€è‡´ï¼Œä¸”èƒ½å¤Ÿç¨³å®šè°ƒèŠ‚æƒ…æ„Ÿç±»åˆ«ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ‰æ•ˆä¸”å®‰å…¨çš„äººæœºåä½œéœ€è¦äººç±»ä¸äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä¹‹é—´æœ‰æ„ä¹‰çš„æƒ…æ„Ÿäº¤æµã€‚ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿæä¾›è®©äººæ„Ÿåˆ°è¢«å€¾å¬çš„åé¦ˆï¼Œä½†å°šä¸æ¸…æ¥šLLMsæ˜¯å¦ä»¥äººç±»çš„æ–¹å¼è¡¨è¾¾æƒ…æ„Ÿï¼Œæˆ–å…¶è¾“å‡ºçš„æƒ…æ„ŸåŸºè°ƒå¦‚ä½•æ§åˆ¶ã€‚æœ¬æ–‡è¯„ä¼°äº†ä¸åŒè¯­è¨€æ–‡åŒ–ç¾¤ä½“å’Œæ¨¡å‹å®¶æ—ä¹‹é—´çš„äººæœºæƒ…æ„Ÿä¸€è‡´æ€§ï¼Œä½¿ç”¨å¯è§£é‡Šçš„LLMç‰¹å¾å¯¹äºŒåå¤šç§ç»†å¾®æƒ…æ„Ÿç±»åˆ«è¿›è¡Œå»ºæ¨¡ã€‚åˆ†æç»“æœè¡¨æ˜ï¼ŒLLMè¡ç”Ÿçš„æƒ…æ„Ÿç©ºé—´ä¸äººç±»æ„ŸçŸ¥åœ¨ç»“æ„ä¸Šæ˜¯ä¸€è‡´çš„ï¼Œå¹¶ä¸”è¿™äº›æƒ…æ„Ÿç›¸å…³ç‰¹å¾èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å¤§è§„æ¨¡çš„è¡Œä¸ºæ•°æ®ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒAIä¸ä»…ä¸äººç±»å…±äº«æƒ…æ„Ÿè¡¨å¾ï¼Œå…¶æƒ…æ„Ÿè¾“å‡ºä¹Ÿå¯ä»¥é€šè¿‡å¿ƒç†å­¦åŸºç¡€çš„æƒ…æ„Ÿæ¦‚å¿µè¿›è¡Œç²¾ç¡®å¼•å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿè¡¨è¾¾ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å…¶ä¸äººç±»æƒ…æ„Ÿçš„å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ§åˆ¶æ¨¡å‹è¾“å‡ºçš„æƒ…æ„ŸåŸºè°ƒï¼Œå¯¼è‡´äººæœºæƒ…æ„Ÿäº¤æµçš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯è§£é‡Šçš„LLMç‰¹å¾ï¼ŒåŸºäºäººç±»æƒ…æ„Ÿæ¦‚å¿µå¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œè°ƒæ§ï¼Œä»è€Œå®ç°äººæœºæƒ…æ„Ÿçš„ä¸€è‡´æ€§å’Œå¯æ§æ€§ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨åˆ©ç”¨å¿ƒç†å­¦çš„æƒ…æ„Ÿç†è®ºæ¥å¢å¼ºAIçš„æƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æƒ…æ„Ÿç‰¹å¾æå–ã€æƒ…æ„Ÿç©ºé—´å»ºæ¨¡å’Œæƒ…æ„Ÿè°ƒæ§ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»LLMsä¸­æå–å¯è§£é‡Šçš„æƒ…æ„Ÿç‰¹å¾ï¼›å…¶æ¬¡ï¼Œæ„å»ºä¸äººç±»æƒ…æ„Ÿæ„ŸçŸ¥ä¸€è‡´çš„æƒ…æ„Ÿç©ºé—´ï¼›æœ€åï¼Œé€šè¿‡è°ƒèŠ‚æƒ…æ„Ÿç‰¹å¾å®ç°å¯¹æ¨¡å‹è¾“å‡ºçš„æƒ…æ„Ÿæ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§åŸºäºäººç±»æƒ…æ„Ÿæ¦‚å¿µçš„è°ƒæ§æœºåˆ¶ï¼Œèƒ½å¤Ÿç³»ç»Ÿæ€§åœ°å¼•å¯¼LLMsç”Ÿæˆç‰¹å®šçš„æƒ…æ„ŸçŠ¶æ€ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œå‰è€…å¼ºè°ƒäº†æƒ…æ„Ÿçš„å¯æ§æ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†åŸºäºæƒ…æ„Ÿçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹è¾“å‡ºçš„æƒ…æ„Ÿä¸€è‡´æ€§ï¼Œå¹¶è®¾è®¡äº†å¤šå±‚æ¬¡çš„æƒ…æ„Ÿç‰¹å¾æå–ç½‘ç»œï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹ç»†å¾®æƒ…æ„Ÿå˜åŒ–çš„æ•æ„Ÿæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMçš„æƒ…æ„Ÿè¾“å‡ºä¸äººç±»æƒ…æ„Ÿæ„ŸçŸ¥åœ¨ç»“æ„ä¸Šé«˜åº¦ä¸€è‡´ï¼Œä¸”æƒ…æ„Ÿè°ƒæ§æœºåˆ¶èƒ½å¤Ÿç¨³å®šåœ°è°ƒèŠ‚æ¨¡å‹è¾“å‡ºçš„æƒ…æ„Ÿç±»åˆ«ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨æƒ…æ„Ÿä¸€è‡´æ€§æ–¹é¢çš„æå‡å¹…åº¦è¾¾åˆ°äº†XX%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æƒ…æ„Ÿè®¡ç®—å’Œæ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡å¢å¼ºAIçš„æƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›äººæœºåä½œçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæœªæ¥å¯èƒ½åœ¨å¿ƒç†å¥åº·æ”¯æŒå’Œæ•™è‚²é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Effective and safe human-machine collaboration requires the regulated and meaningful exchange of emotions between humans and artificial intelligence (AI). Current AI systems based on large language models (LLMs) can provide feedback that makes people feel heard. Yet it remains unclear whether LLMs represent emotion in language as humans do, or whether and how the emotional tone of their output can be controlled. We assess human-AI emotional alignment across linguistic-cultural groups and model-families, using interpretable LLM features translated from concept-sets for over twenty nuanced emotion categories (including six basic emotions). Our analyses reveal that LLM-derived emotion spaces are structurally congruent with human perception, underpinned by the fundamental affective dimensions of valence and arousal. Furthermore, these emotion-related features also accurately predict large-scale behavioural data on word ratings along these two core dimensions, reflecting both universal and language-specific patterns. Finally, by leveraging steering vectors derived solely from human-centric emotion concepts, we show that model expressions can be stably and naturally modulated across distinct emotion categories, which provides causal evidence that human emotion concepts can be used to systematically induce LLMs to produce corresponding affective states when conveying content. These findings suggest AI not only shares emotional representations with humans but its affective outputs can be precisely guided using psychologically grounded emotion concepts.

