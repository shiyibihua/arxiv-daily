---
layout: default
title: DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations
---

# DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09349" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09349v3</a>
  <a href="https://arxiv.org/pdf/2506.09349.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09349v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09349v3', 'DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao-Hong Tan, Qian Chen, Wen Wang, Chong Deng, Qinglin Zhang, Luyao Cheng, Hai Yu, Xin Zhang, Xiang Lv, Tianyu Zhao, Chong Zhang, Yukun Ma, Yafeng Chen, Hui Wang, Jiaqing Liu, Xiangang Li, Jieping Ye

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-10-28)

**å¤‡æ³¨**: Work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDrVoiceä»¥è§£å†³è¯­éŸ³ç”Ÿæˆä¸­çš„æ¨¡æ€ä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³ç”Ÿæˆ` `åŒåˆ†è¾¨ç‡` `è”åˆè‡ªå›å½’` `æ¨¡æ€äº’çŸ¥` `å¤§è¯­è¨€æ¨¡å‹` `å¼€æºæ¨¡å‹` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„E2Eè¯­éŸ³ç”Ÿæˆæ–¹æ³•åœ¨æ¨¡æ€äº’çŸ¥å’Œè®¡ç®—æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„DrVoiceæ¨¡å‹é€šè¿‡è”åˆè‡ªå›å½’å»ºæ¨¡å’ŒåŒåˆ†è¾¨ç‡è¯­éŸ³è¡¨ç¤ºï¼Œæå‡äº†è¯­éŸ³å’Œæ–‡æœ¬ç”Ÿæˆçš„äº’çŸ¥èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDRVOICE-7Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ–°çš„SOTAï¼Œå±•ç°äº†å…¶åœ¨è¯­éŸ³ç”Ÿæˆé¢†åŸŸçš„é¢†å…ˆåœ°ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç«¯åˆ°ç«¯ï¼ˆE2Eï¼‰è¯­éŸ³ç”Ÿæˆç ”ç©¶å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç°æœ‰E2Eæ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šä¸€ç±»æ˜¯ç‹¬ç«‹ç”Ÿæˆç¦»æ•£è¯­éŸ³æ ‡è®°ï¼Œæœªèƒ½ä¸LLMçš„è‡ªå›å½’è¿‡ç¨‹ç»“åˆï¼›å¦ä¸€ç±»æ˜¯é€šè¿‡è”åˆè‡ªå›å½’å»ºæ¨¡ç”Ÿæˆäº¤é”™æˆ–å¹¶è¡Œçš„è¯­éŸ³-æ–‡æœ¬æ ‡è®°ï¼Œå®ç°ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ¨¡æ€äº’çŸ¥ã€‚æœ¬æ–‡æå‡ºäº†DrVoiceï¼Œä¸€ä¸ªåŸºäºè”åˆè‡ªå›å½’å»ºæ¨¡çš„å¹¶è¡Œè¯­éŸ³-æ–‡æœ¬å¯¹è¯æ¨¡å‹ï¼Œé‡‡ç”¨åŒåˆ†è¾¨ç‡è¯­éŸ³è¡¨ç¤ºã€‚ä¸ç°æœ‰æ–¹æ³•ä¸»è¦ä½¿ç”¨12.5Hzè¾“å…¥éŸ³é¢‘è¡¨ç¤ºä¸åŒï¼Œæˆ‘ä»¬çš„åŒåˆ†è¾¨ç‡æœºåˆ¶å°†LLMçš„è¾“å…¥é¢‘ç‡é™ä½è‡³5Hzï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œå¹¶ç¼“è§£äº†è¯­éŸ³å’Œæ–‡æœ¬æ ‡è®°ä¹‹é—´çš„é¢‘ç‡å·®å¼‚ï¼Œä»è€Œæ›´å¥½åœ°åˆ©ç”¨LLMsçš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDRVOICE-7Båœ¨OpenAudioBenchå’ŒBig Bench AudioåŸºå‡†ä¸Šå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›ï¼ˆSOTAï¼‰è®°å½•ï¼ŒåŒæ—¶åœ¨VoiceBenchå’ŒUltraEval-AudioåŸºå‡†ä¸Šè¡¨ç°å‡ºä¸SOTAç›¸å½“çš„æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºçº¦7Bæ¨¡å‹ä¸­çš„é¢†å…ˆå¼€æºè¯­éŸ³åŸºç¡€æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰E2Eè¯­éŸ³ç”Ÿæˆæ–¹æ³•ä¸­æ¨¡æ€ä¸ä¸€è‡´å’Œè®¡ç®—æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æœªèƒ½æœ‰æ•ˆç»“åˆè¯­éŸ³å’Œæ–‡æœ¬ç”Ÿæˆï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDrVoiceé€šè¿‡å¼•å…¥è”åˆè‡ªå›å½’å»ºæ¨¡å’ŒåŒåˆ†è¾¨ç‡è¯­éŸ³è¡¨ç¤ºï¼Œå¢å¼ºäº†è¯­éŸ³å’Œæ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹ä¸­çš„äº’çŸ¥æ€§ï¼ŒåŒæ—¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥éŸ³é¢‘çš„åŒåˆ†è¾¨ç‡å¤„ç†ã€è”åˆè‡ªå›å½’å»ºæ¨¡æ¨¡å—ä»¥åŠè¾“å‡ºç”Ÿæˆæ¨¡å—ï¼Œç¡®ä¿è¯­éŸ³å’Œæ–‡æœ¬çš„åŒæ­¥ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šDrVoiceçš„åŒåˆ†è¾¨ç‡æœºåˆ¶æ˜¯å…¶æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œé€šè¿‡å°†è¾“å…¥é¢‘ç‡é™ä½è‡³5Hzï¼Œæ˜¾è‘—å‡å°‘äº†è®¡ç®—è´Ÿæ‹…ï¼Œå¹¶æ”¹å–„äº†è¯­éŸ³ä¸æ–‡æœ¬ä¹‹é—´çš„é¢‘ç‡åŒ¹é…ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹åœ¨å‚æ•°è®¾ç½®ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡è¯­éŸ³å’Œæ–‡æœ¬ç”Ÿæˆçš„è´¨é‡ï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ä»¥æ”¯æŒåŒåˆ†è¾¨ç‡è¾“å…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDRVOICE-7Båœ¨OpenAudioBenchå’ŒBig Bench AudioåŸºå‡†ä¸Šè¾¾åˆ°äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œæ€§èƒ½è¶…è¶Šäº†ç°æœ‰çš„æœ€ä½³æ¨¡å‹ã€‚åŒæ—¶ï¼Œåœ¨VoiceBenchå’ŒUltraEval-AudioåŸºå‡†ä¸Šï¼Œå…¶è¡¨ç°ä¹Ÿä¸æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DrVoiceæ¨¡å‹åœ¨æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€å®æ—¶ç¿»è¯‘ã€è¯­éŸ³äº¤äº’ç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„è¯­éŸ³ç”Ÿæˆèƒ½åŠ›èƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶åœ¨å¤šæ¨¡æ€äº¤äº’ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æ¨åŠ¨æ›´è‡ªç„¶çš„äººæœºå¯¹è¯å’Œæ›´æ™ºèƒ½çš„è¯­éŸ³åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies on end-to-end (E2E) speech generation with large language models (LLMs) have attracted significant community attention, with multiple works extending text-based LLMs to generate discrete speech tokens. Existing E2E approaches primarily fall into two categories: (1) Methods that generate discrete speech tokens independently without incorporating them into the LLM's autoregressive process, resulting in text generation being unaware of concurrent speech synthesis. (2) Models that generate interleaved or parallel speech-text tokens through joint autoregressive modeling, enabling mutual modality awareness during generation. This paper presents DrVoice, a parallel speech-text voice conversation model based on joint autoregressive modeling, featuring dual-resolution speech representations. Notably, while current methods utilize mainly 12.5Hz input audio representation, our proposed dual-resolution mechanism reduces the input frequency for the LLM to 5Hz, significantly reducing computational cost and alleviating the frequency discrepancy between speech and text tokens and in turn better exploiting LLMs' capabilities. Experimental results demonstrate that DRVOICE-7B establishes new state-of-the-art (SOTA) on OpenAudioBench and Big Bench Audio benchmarks, while achieving performance comparable to the SOTA on VoiceBench and UltraEval-Audio benchmarks, making it a leading open-source speech foundation model in ~7B models.

