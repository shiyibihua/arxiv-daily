---
layout: default
title: When Large Language Models are Reliable for Judging Empathic Communication
---

# When Large Language Models are Reliable for Judging Empathic Communication

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10150" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10150v2</a>
  <a href="https://arxiv.org/pdf/2506.10150.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10150v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10150v2', 'When Large Language Models are Reliable for Judging Empathic Communication')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aakriti Kumar, Nalin Poungpeth, Diyi Yang, Erina Farrell, Bruce Lambert, Matthew Groh

**åˆ†ç±»**: cs.CL, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-10-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒç†æ²Ÿé€šåˆ¤æ–­ä¸­çš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒç†æ²Ÿé€š` `æƒ…æ„Ÿè®¡ç®—` `æ ‡æ³¨ä¸€è‡´æ€§` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¿ƒç†å­¦` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨åˆ¤æ–­åŒç†æ²Ÿé€šçš„ç»†å¾®å·®åˆ«æ—¶ï¼Œç¼ºä¹å¯é æ€§è¯„ä¼°æ ‡å‡†ï¼Œå°¤å…¶æ˜¯åœ¨æƒ…æ„Ÿæ•æ„Ÿçš„å¯¹è¯åœºæ™¯ä¸­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡é€šè¿‡å¯¹æ¯”ä¸“å®¶ã€ä¼—åŒ…å·¥ä½œè€…å’ŒLLMsçš„æ ‡æ³¨ç»“æœï¼Œè¯„ä¼°ä¸åŒè¯„ä¼°æ¡†æ¶ä¸‹çš„åŒç†æ²Ÿé€šåˆ¤æ–­å¯é æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶è¡¨æ˜ï¼ŒLLMsåœ¨åŒç†æ²Ÿé€šçš„åˆ¤æ–­ä¸Šæ¥è¿‘ä¸“å®¶æ°´å¹³ï¼Œä¸”è¶…è¶Šä¼—åŒ…å·¥ä½œè€…çš„å¯é æ€§ï¼Œæä¾›äº†æ›´å…·ä¿¡æ¯é‡çš„åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡æœ¬å¯¹è¯ä¸­ç”ŸæˆåŒç†ååº”æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬åœ¨åˆ¤æ–­åŒç†æ²Ÿé€šç»†å¾®å·®åˆ«çš„å¯é æ€§å¦‚ä½•ï¼Ÿæœ¬æ–‡é€šè¿‡æ¯”è¾ƒä¸“å®¶ã€ä¼—åŒ…å·¥ä½œè€…å’ŒLLMsåœ¨200ä¸ªçœŸå®å¯¹è¯ä¸­çš„åŒç†æ²Ÿé€šæ ‡æ³¨ï¼Œæ¢è®¨äº†è¿™ä¸€é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œä¸“å®¶ä¹‹é—´çš„åè®®åº¦è¾ƒé«˜ï¼Œä½†åœ¨ä¸åŒè¯„ä¼°æ¡†æ¶çš„å­ç»„ä»¶ä¸­å­˜åœ¨å·®å¼‚ã€‚LLMsåœ¨æ‰€æœ‰å››ä¸ªæ¡†æ¶ä¸­å‡æ¥è¿‘ä¸“å®¶æ°´å¹³ï¼Œå¹¶è¶…è¶Šäº†ä¼—åŒ…å·¥ä½œè€…çš„å¯é æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç»è¿‡ç‰¹å®šä»»åŠ¡éªŒè¯çš„LLMså¯ä»¥åœ¨æƒ…æ„Ÿæ•æ„Ÿåº”ç”¨ä¸­æ”¯æŒé€æ˜åº¦å’Œç›‘ç£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒç†æ²Ÿé€šåˆ¤æ–­ä¸­çš„å¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†ï¼Œå¯¼è‡´å¯¹æƒ…æ„Ÿæ²Ÿé€šçš„ç†è§£å’Œåº”ç”¨å­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒä¸“å®¶ã€ä¼—åŒ…å·¥ä½œè€…å’ŒLLMsåœ¨åŒç†æ²Ÿé€šæ ‡æ³¨ä¸­çš„è¡¨ç°ï¼Œæä¾›ä¸€ä¸ªå¤šç»´åº¦çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥æ›´å¥½åœ°ç†è§£å’ŒéªŒè¯LLMsçš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å››ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œç»“åˆå¿ƒç†å­¦ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œä¼ æ’­å­¦çš„ç†è®ºï¼Œåˆ†æ200ä¸ªçœŸå®å¯¹è¯çš„åŒç†æ²Ÿé€šã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ ‡æ³¨è¿‡ç¨‹å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡ä¸“å®¶æ ‡æ³¨æä¾›äº†ä¸€ä¸ªæ›´å…·ä¿¡æ¯é‡çš„åŸºå‡†ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿåˆ†ç±»æŒ‡æ ‡ï¼Œæ­ç¤ºäº†LLMsåœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†3150ä¸ªä¸“å®¶æ ‡æ³¨ã€2844ä¸ªä¼—åŒ…æ ‡æ³¨å’Œ3150ä¸ªLLMæ ‡æ³¨ï¼Œè¯„ä¼°äº†ä¸åŒæ¡†æ¶ä¸‹çš„åè®®åº¦ï¼Œå…³æ³¨æ ‡æ³¨çš„æ¸…æ™°åº¦ã€å¤æ‚æ€§å’Œä¸»è§‚æ€§ç­‰å› ç´ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨åŒç†æ²Ÿé€šçš„åˆ¤æ–­ä¸Šæ¥è¿‘ä¸“å®¶æ°´å¹³ï¼Œä¸”åœ¨æ‰€æœ‰å››ä¸ªè¯„ä¼°æ¡†æ¶ä¸­å‡è¶…è¶Šäº†ä¼—åŒ…å·¥ä½œè€…çš„å¯é æ€§ï¼Œæä¾›äº†3150ä¸ªä¸“å®¶æ ‡æ³¨å’Œ3150ä¸ªLLMæ ‡æ³¨çš„é«˜ä¸€è‡´æ€§ï¼ŒéªŒè¯äº†å…¶åœ¨æƒ…æ„Ÿåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æƒ…æ„Ÿæ”¯æŒç³»ç»Ÿã€æ™ºèƒ½å®¢æœå’Œå¿ƒç†å¥åº·å¹²é¢„ç­‰ã€‚é€šè¿‡æé«˜LLMsåœ¨åŒç†æ²Ÿé€šä¸­çš„å¯é æ€§ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨æƒ…æ„Ÿæ•æ„Ÿåœºæ™¯ä¸­çš„åº”ç”¨ä»·å€¼ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) excel at generating empathic responses in text-based conversations. But, how reliably do they judge the nuances of empathic communication? We investigate this question by comparing how experts, crowdworkers, and LLMs annotate empathic communication across four evaluative frameworks drawn from psychology, natural language processing, and communications applied to 200 real-world conversations where one speaker shares a personal problem and the other offers support. Drawing on 3,150 expert annotations, 2,844 crowd annotations, and 3,150 LLM annotations, we assess inter-rater reliability between these three annotator groups. We find that expert agreement is high but varies across the frameworks' sub-components depending on their clarity, complexity, and subjectivity. We show that expert agreement offers a more informative benchmark for contextualizing LLM performance than standard classification metrics. Across all four frameworks, LLMs consistently approach this expert level benchmark and exceed the reliability of crowdworkers. These results demonstrate how LLMs, when validated on specific tasks with appropriate benchmarks, can support transparency and oversight in emotionally sensitive applications including their use as conversational companions.

