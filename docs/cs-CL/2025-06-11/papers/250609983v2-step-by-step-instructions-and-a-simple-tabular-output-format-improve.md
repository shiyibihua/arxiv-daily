---
layout: default
title: Step-by-step Instructions and a Simple Tabular Output Format Improve the Dependency Parsing Accuracy of LLMs
---

# Step-by-step Instructions and a Simple Tabular Output Format Improve the Dependency Parsing Accuracy of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09983" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09983v2</a>
  <a href="https://arxiv.org/pdf/2506.09983.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09983v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09983v2', 'Step-by-step Instructions and a Simple Tabular Output Format Improve the Dependency Parsing Accuracy of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hiroshi Matsuda, Chunpeng Ma, Masayuki Asahara

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-06-16)

**å¤‡æ³¨**: 9 pages, 2 figures, accepted to SyntaxFest 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€æ­¥æŒ‡ä»¤ä¸ç®€åŒ–è¡¨æ ¼æ ¼å¼ä»¥æå‡LLMçš„ä¾å­˜è§£æå‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¾å­˜è§£æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `é€æ­¥æŒ‡ä»¤` `å¤šè¯­è¨€å¾®è°ƒ` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¥æ³•åˆ†æ` `CoNLL-Uæ ¼å¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ ‡å‡†æç¤ºæ–¹æ³•åœ¨ä¾å­˜è§£æä¸­éš¾ä»¥ç”Ÿæˆç»“æ„æœ‰æ•ˆä¸”å‡†ç¡®çš„è¾“å‡ºï¼Œå­˜åœ¨æ˜æ˜¾çš„å±€é™æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€æ­¥æŒ‡ä»¤ç­–ç•¥ï¼Œå…ˆè¿›è¡Œé€šç”¨è¯æ€§æ ‡æ³¨ï¼Œå†é¢„æµ‹å¥æ³•å¤´å’Œä¾å­˜æ ‡ç­¾ï¼Œå¹¶é‡‡ç”¨ç®€åŒ–çš„è¾“å‡ºæ ¼å¼ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨17ç§è¯­è¨€çš„Universal Dependenciesæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œä¸”æå‡äº†è·¨è¯­è¨€çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥åœ¨å¤šä¸ªä»»åŠ¡ä¸­å±•ç°äº†ä»¤äººç©ç›®çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œæ ‡å‡†æç¤ºåœ¨ç”Ÿæˆç»“æ„æœ‰æ•ˆä¸”å‡†ç¡®çš„è¾“å‡ºæ—¶å¸¸å¸¸é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¾å­˜è§£ææ–¹é¢ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„é€æ­¥æŒ‡ä»¤ç­–ç•¥ï¼Œå…¶ä¸­é€šç”¨è¯æ€§æ ‡æ³¨åœ¨é¢„æµ‹å¥æ³•å¤´å’Œä¾å­˜æ ‡ç­¾ä¹‹å‰è¿›è¡Œï¼Œå¹¶é‡‡ç”¨ç®€åŒ–çš„ç±»ä¼¼CoNLL-Uçš„è¾“å‡ºæ ¼å¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨17ç§è¯­è¨€çš„Universal Dependenciesæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œä¸”æ²¡æœ‰å‡ºç°å¹»è§‰æˆ–æ±¡æŸ“ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†å¤šè¯­è¨€å¾®è°ƒåŒæ—¶æå‡äº†è·¨è¯­è¨€æ³›åŒ–æ€§èƒ½ã€‚æˆ‘ä»¬çš„ç»“æœçªæ˜¾äº†æ˜¾å¼æ¨ç†æ­¥éª¤åœ¨åŸºäºLLMçš„è§£æä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æä¾›äº†ä¸€ç§å¯æ‰©å±•ã€æ ¼å¼ä¸€è‡´çš„æ›¿ä»£æ‹¬å·æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¾å­˜è§£æä¸­ç”Ÿæˆç»“æ„æœ‰æ•ˆå’Œå‡†ç¡®è¾“å‡ºçš„å›°éš¾ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å¥æ³•ç»“æ„æ—¶å¸¸å¸¸å‡ºç°é”™è¯¯ï¼Œå¯¼è‡´è§£æç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„é€æ­¥æŒ‡ä»¤ç­–ç•¥é€šè¿‡å¼•å…¥é€šç”¨è¯æ€§æ ‡æ³¨ä½œä¸ºç¬¬ä¸€æ­¥ï¼Œç¡®ä¿äº†å¥æ³•å¤´å’Œä¾å­˜æ ‡ç­¾çš„é¢„æµ‹æ›´åŠ å‡†ç¡®ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½å¤Ÿæ›´æ¸…æ™°åœ°ç†è§£å¥æ³•ç»“æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯é€šç”¨è¯æ€§æ ‡æ³¨ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯åŸºäºæ ‡æ³¨ç»“æœé¢„æµ‹å¥æ³•å¤´å’Œä¾å­˜æ ‡ç­¾ã€‚è¾“å‡ºé‡‡ç”¨ç®€åŒ–çš„CoNLL-Uæ ¼å¼ï¼Œä»¥æé«˜ç»“æœçš„å¯è¯»æ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€æ­¥æŒ‡ä»¤çš„å¼•å…¥å’Œç®€åŒ–è¾“å‡ºæ ¼å¼çš„ä½¿ç”¨ã€‚è¿™ä¸ä¼ ç»Ÿçš„æ‹¬å·æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†ä¸€ç§æ›´ç›´è§‚ä¸”æ˜“äºå¤„ç†çš„è§£ææ–¹å¼ï¼Œé¿å…äº†å¤æ‚çš„åµŒå¥—ç»“æ„ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¨¡å‹é‡‡ç”¨äº†å¤šè¯­è¨€å¾®è°ƒç­–ç•¥ï¼Œä»¥å¢å¼ºè·¨è¯­è¨€çš„æ³›åŒ–èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡ç‚¹å…³æ³¨ä¾å­˜å…³ç³»çš„å‡†ç¡®æ€§ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°å¥æ³•ç»“æ„çš„ç‰¹å¾ã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†é€‚åˆå¤„ç†åºåˆ—æ•°æ®çš„æ¶æ„ï¼Œä»¥æå‡è§£ææ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨17ç§è¯­è¨€çš„Universal Dependenciesæ•°æ®é›†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œæ˜æ˜¾ä¼˜äºç°æœ‰åŸºçº¿ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨ä¾å­˜è§£æä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡æå‡å¹…åº¦è¶…è¿‡äº†X%ï¼Œä¸”æœªå‡ºç°å¹»è§‰æˆ–æ±¡æŸ“ç°è±¡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¥æ³•åˆ†æã€æœºå™¨ç¿»è¯‘å’Œä¿¡æ¯æå–ç­‰ä»»åŠ¡ã€‚é€šè¿‡æå‡ä¾å­˜è§£æçš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºä¸‹æ¸¸ä»»åŠ¡æä¾›æ›´å¯é çš„åŸºç¡€ï¼Œè¿›è€Œæ”¹å–„æ•´ä½“ç³»ç»Ÿæ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“å¤šè¯­è¨€å¤„ç†çš„ç ”ç©¶æ–¹å‘ï¼Œæ¨åŠ¨æ›´é«˜æ•ˆçš„è§£ææŠ€æœ¯å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have enabled impressive performance in various tasks. However, standard prompting often struggles to produce structurally valid and accurate outputs, especially in dependency parsing. We propose a novel step-by-step instruction strategy, where universal part-of-speech tagging precedes the prediction of syntactic heads and dependency labels, and a simplified CoNLL-U like output format, our method achieves state-of-the-art accuracy on Universal Dependencies datasets across 17 languages without hallucination or contamination. We further show that multilingual fine-tuning simultaneously improves cross-language generalization performance. Our results highlight the effectiveness of explicit reasoning steps in LLM-based parsing and offer a scalable, format-consistent alternative to bracket-based approaches.

