---
layout: default
title: Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?
---

# Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09796" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09796v1</a>
  <a href="https://arxiv.org/pdf/2506.09796.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09796v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09796v1', 'Do LLMs Give Psychometrically Plausible Responses in Educational Assessments?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andreas SÃ¤uberli, Diego Frassinelli, Barbara Plank

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: Accepted for publication at the 20th Workshop on Innovative Use of NLP for Building Educational Applications (BEA) at ACL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²è¯„ä¼°ä¸­çš„å¿ƒç†æµ‹é‡åˆç†æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•™è‚²è¯„ä¼°` `å¿ƒç†æµ‹é‡` `æ¸©åº¦ç¼©æ”¾` `å¤šé¡¹é€‰æ‹©é¢˜` `é˜…è¯»ç†è§£` `é¡¹ç›®ååº”ç†è®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•™è‚²è¯„ä¼°æ–¹æ³•é€šå¸¸ä¾èµ–å¤§é‡äººç±»å‚ä¸è€…è¿›è¡Œè¯•ç‚¹ç ”ç©¶ï¼Œæ•ˆç‡ä½ä¸‹ä¸”æˆæœ¬é«˜æ˜‚ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºè¯•ç‚¹å‚ä¸è€…ï¼Œé€šè¿‡è¯„ä¼°å…¶å›ç­”çš„å¿ƒç†æµ‹é‡åˆç†æ€§æ¥åŠ é€Ÿæµ‹è¯•å¼€å‘ã€‚
3. ç ”ç©¶å‘ç°ï¼Œç»è¿‡æ¸©åº¦ç¼©æ”¾æ ¡å‡†åï¼ŒLLMsçš„å›ç­”åˆ†å¸ƒæ›´æ¥è¿‘äººç±»ï¼Œå°¤å…¶åœ¨é˜…è¯»ç†è§£é¢˜ç›®ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„ç›¸å…³æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äº†è§£è€ƒç”Ÿåœ¨æ•™è‚²è¯„ä¼°ä¸­å¦‚ä½•å›ç­”é¢˜ç›®å¯¹äºæµ‹è¯•å¼€å‘ã€è¯„ä¼°é¢˜ç›®è´¨é‡å’Œæé«˜æµ‹è¯•æœ‰æ•ˆæ€§è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œè¿™ä¸€è¿‡ç¨‹é€šå¸¸éœ€è¦å¤§é‡äººç±»å‚ä¸è€…çš„è¯•ç‚¹ç ”ç©¶ã€‚å¦‚æœå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿè¡¨ç°å‡ºç±»ä¼¼äººç±»çš„å›ç­”è¡Œä¸ºï¼Œåˆ™å¯ä»¥åˆ©ç”¨å®ƒä»¬ä½œä¸ºè¯•ç‚¹å‚ä¸è€…ï¼ŒåŠ é€Ÿæµ‹è¯•å¼€å‘ã€‚æœ¬æ–‡è¯„ä¼°äº†18ä¸ªç»è¿‡æŒ‡ä»¤è°ƒä¼˜çš„LLMsåœ¨ä¸‰ä¸ªå­¦ç§‘ï¼ˆé˜…è¯»ã€ç¾å›½å†å²å’Œç»æµå­¦ï¼‰çš„å¤šé¡¹é€‰æ‹©é¢˜ä¸Šçš„äººç±»ç›¸ä¼¼æ€§æˆ–å¿ƒç†æµ‹é‡åˆç†æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¾ƒå¤§çš„æ¨¡å‹è¿‡äºè‡ªä¿¡ï¼Œä½†ç»è¿‡æ¸©åº¦ç¼©æ”¾æ ¡å‡†åï¼Œå®ƒä»¬çš„å›ç­”åˆ†å¸ƒæ›´æ¥è¿‘äººç±»ã€‚æ­¤å¤–ï¼ŒLLMsåœ¨é˜…è¯»ç†è§£é¢˜ç›®ä¸Šçš„ç›¸å…³æ€§ä¼˜äºå…¶ä»–å­¦ç§‘ï¼Œä½†æ€»ä½“ç›¸å…³æ€§å¹¶ä¸å¼ºï¼Œè¡¨æ˜LLMsä¸åº”åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­ç”¨äºæ•™è‚²è¯„ä¼°çš„è¯•ç‚¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ•™è‚²è¯„ä¼°ä¸­å¯¹è€ƒç”Ÿå›ç­”è¡Œä¸ºçš„ç†è§£é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äººç±»å‚ä¸è€…è¿›è¡Œè¯•ç‚¹ç ”ç©¶ï¼Œæ•ˆç‡ä½ä¸”æˆæœ¬é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è¯„ä¼°18ä¸ªæŒ‡ä»¤è°ƒä¼˜çš„LLMsåœ¨å¤šé¡¹é€‰æ‹©é¢˜ä¸Šçš„å›ç­”ï¼Œæ¢ç´¢å…¶æ˜¯å¦èƒ½æ¨¡æ‹Ÿäººç±»çš„å›ç­”è¡Œä¸ºï¼Œä»è€Œä½œä¸ºè¯•ç‚¹å‚ä¸è€…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åŸºäºç»å…¸æµ‹è¯•ç†è®ºå’Œé¡¹ç›®ååº”ç†è®ºï¼Œä½¿ç”¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œæ¶µç›–é˜…è¯»ã€ç¾å›½å†å²å’Œç»æµå­¦ä¸‰ä¸ªå­¦ç§‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºå°†LLMsåº”ç”¨äºæ•™è‚²è¯„ä¼°çš„è¯•ç‚¹ç ”ç©¶ä¸­ï¼Œæå‡ºäº†æ¸©åº¦ç¼©æ”¾æ ¡å‡†çš„æ–¹æ³•ä»¥æé«˜æ¨¡å‹å›ç­”çš„å¿ƒç†æµ‹é‡åˆç†æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†æ¸©åº¦ç¼©æ”¾æŠ€æœ¯æ¥è°ƒæ•´æ¨¡å‹çš„å›ç­”åˆ†å¸ƒï¼Œç¡®ä¿å…¶æ›´æ¥è¿‘äººç±»çš„å›ç­”æ¨¡å¼ï¼ŒåŒæ—¶è¯„ä¼°äº†ä¸åŒæ¨¡å‹åœ¨å„å­¦ç§‘ä¸Šçš„è¡¨ç°å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡æ¸©åº¦ç¼©æ”¾æ ¡å‡†çš„LLMsåœ¨å›ç­”åˆ†å¸ƒä¸Šæ›´æ¥è¿‘äººç±»ï¼Œå°¤å…¶åœ¨é˜…è¯»ç†è§£é¢˜ç›®ä¸Šè¡¨ç°å‡ºæ›´å¥½çš„ç›¸å…³æ€§ã€‚å°½ç®¡è¾ƒå¤§çš„æ¨¡å‹åœ¨è‡ªä¿¡åº¦ä¸Šå­˜åœ¨è¿‡åº¦ç°è±¡ï¼Œä½†æ•´ä½“ç›¸å…³æ€§ä»ç„¶è¾ƒå¼±ï¼Œè¡¨æ˜åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­ä¸é€‚åˆç”¨äºæ•™è‚²è¯„ä¼°çš„è¯•ç‚¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºæ•™è‚²è¯„ä¼°é¢†åŸŸæä¾›äº†æ–°çš„æ€è·¯ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯•ç‚¹å‚ä¸è€…å¯ä»¥æ˜¾è‘—é™ä½æµ‹è¯•å¼€å‘çš„æ—¶é—´å’Œæˆæœ¬ã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹æ€§èƒ½çš„æå‡ï¼ŒLLMså¯èƒ½åœ¨æ•™è‚²è¯„ä¼°ä¸­å‘æŒ¥æ›´å¤§çš„ä½œç”¨ï¼Œå¸®åŠ©è®¾è®¡æ›´æœ‰æ•ˆçš„æµ‹è¯•å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowing how test takers answer items in educational assessments is essential for test development, to evaluate item quality, and to improve test validity. However, this process usually requires extensive pilot studies with human participants. If large language models (LLMs) exhibit human-like response behavior to test items, this could open up the possibility of using them as pilot participants to accelerate test development. In this paper, we evaluate the human-likeness or psychometric plausibility of responses from 18 instruction-tuned LLMs with two publicly available datasets of multiple-choice test items across three subjects: reading, U.S. history, and economics. Our methodology builds on two theoretical frameworks from psychometrics which are commonly used in educational assessment, classical test theory and item response theory. The results show that while larger models are excessively confident, their response distributions can be more human-like when calibrated with temperature scaling. In addition, we find that LLMs tend to correlate better with humans in reading comprehension items compared to other subjects. However, the correlations are not very strong overall, indicating that LLMs should not be used for piloting educational assessments in a zero-shot setting.

