---
layout: default
title: Comparing human and LLM politeness strategies in free production
---

# Comparing human and LLM politeness strategies in free production

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09391" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09391v2</a>
  <a href="https://arxiv.org/pdf/2506.09391.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09391v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09391v2', 'Comparing human and LLM politeness strategies in free production')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoran Zhao, Robert D. Hawkins

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-10-30)

**å¤‡æ³¨**: 25 pages, 5 figures \| EMNLP 2025 camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒäººç±»ä¸å¤§å‹è¯­è¨€æ¨¡å‹çš„ç¤¼è²Œç­–ç•¥ä»¥è§£å†³å¯¹é½æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤¼è²Œç­–ç•¥` `äººæœºäº¤äº’` `è®¡ç®—è¯­ç”¨å­¦` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¤¼è²Œè¯­è¨€ç”Ÿæˆä¸­é¢ä¸´å¯¹é½æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¿¡æ¯ä¸ç¤¾äº¤ç›®æ ‡çš„å¹³è¡¡ä¸Šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡æ¯”è¾ƒäººç±»ä¸LLMåœ¨ä¸åŒç”Ÿæˆä»»åŠ¡ä¸­çš„å“åº”ï¼Œæ¢è®¨LLMæ˜¯å¦å…·å¤‡ä¸Šä¸‹æ–‡æ•æ„Ÿçš„ç¤¼è²Œç­–ç•¥ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶å‘ç°ï¼Œè¾ƒå¤§çš„æ¨¡å‹èƒ½å¤Ÿå¤åˆ¶å…³é”®çš„è¯­ç”¨åå¥½ï¼Œäººç±»åœ¨å¼€æ”¾å¼ä»»åŠ¡ä¸­åå¥½LLMç”Ÿæˆçš„å“åº”ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¤¼è²Œè¯­è¨€åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æå‡ºäº†åŸºæœ¬çš„å¯¹é½æŒ‘æˆ˜ã€‚äººç±»ä½¿ç”¨ä¸°å¯Œçš„è¯­è¨€ç­–ç•¥æ¥å¹³è¡¡ä¿¡æ¯å’Œç¤¾äº¤ç›®æ ‡ï¼ŒåŒ…æ‹¬å»ºç«‹å…³ç³»çš„ç§¯æç­–ç•¥å’Œå‡å°‘è´Ÿæ‹…çš„æ¶ˆæç­–ç•¥ã€‚æœ¬æ–‡é€šè¿‡æ¯”è¾ƒäººç±»ä¸LLMåœ¨å—é™å’Œå¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ä¸­çš„å“åº”ï¼Œæ¢è®¨LLMæ˜¯å¦é‡‡ç”¨ç±»ä¼¼çš„ä¸Šä¸‹æ–‡æ•æ„Ÿç­–ç•¥ã€‚ç ”ç©¶å‘ç°ï¼Œå‚æ•°è¶…è¿‡70Bçš„æ¨¡å‹æˆåŠŸå¤åˆ¶äº†è®¡ç®—è¯­ç”¨å­¦æ–‡çŒ®ä¸­çš„å…³é”®åå¥½ï¼Œä¸”äººç±»è¯„ä¼°è€…åœ¨å¼€æ”¾å¼ä¸Šä¸‹æ–‡ä¸­æ„å¤–åå¥½LLMç”Ÿæˆçš„å“åº”ã€‚ç„¶è€Œï¼Œè¿›ä¸€æ­¥çš„è¯­è¨€åˆ†ææ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨ç§¯æä¸Šä¸‹æ–‡ä¸­ä¸æˆæ¯”ä¾‹åœ°ä¾èµ–æ¶ˆæç¤¼è²Œç­–ç•¥ï¼Œå¯èƒ½å¯¼è‡´è¯¯è§£ã€‚å°½ç®¡ç°ä»£LLMåœ¨ç¤¼è²Œç­–ç•¥ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†è¿™äº›å¾®å¦™çš„å·®å¼‚å¼•å‘äº†å…³äºAIç³»ç»Ÿä¸­è¯­ç”¨å¯¹é½çš„é‡è¦é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆç¤¼è²Œè¯­è¨€æ—¶çš„å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¿¡æ¯ä¸ç¤¾äº¤ç›®æ ‡çš„å¹³è¡¡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡æ•æ„Ÿæ€§æ–¹é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šç ”ç©¶é€šè¿‡æ¯”è¾ƒäººç±»ä¸LLMçš„å“åº”ï¼Œæ¢è®¨LLMæ˜¯å¦èƒ½å¤Ÿé‡‡ç”¨ç±»ä¼¼äºäººç±»çš„ç¤¼è²Œç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸åŒçš„ç”Ÿæˆä»»åŠ¡ä¸­ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ­ç¤ºLLMåœ¨ç¤¼è²Œè¯­è¨€ç”Ÿæˆä¸­çš„æ½œåŠ›ä¸å±€é™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯å—é™ç”Ÿæˆä»»åŠ¡ï¼Œå…¶æ¬¡æ˜¯å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ã€‚åœ¨æ¯ä¸ªé˜¶æ®µä¸­ï¼Œæ”¶é›†äººç±»ä¸LLMçš„å“åº”å¹¶è¿›è¡Œæ¯”è¾ƒåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå‘ç°è¾ƒå¤§çš„LLMï¼ˆå‚æ•°â‰¥70Bï¼‰èƒ½å¤ŸæˆåŠŸå¤åˆ¶è®¡ç®—è¯­ç”¨å­¦ä¸­çš„å…³é”®åå¥½ï¼Œè¿™ä¸ç°æœ‰çš„ç¤¼è²Œç­–ç•¥ç”Ÿæˆç ”ç©¶å­˜åœ¨æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡æ¥åˆ†æç”Ÿæˆçš„å“åº”ï¼ŒåŒ…æ‹¬ç¤¼è²Œç­–ç•¥çš„ä½¿ç”¨é¢‘ç‡å’Œä¸Šä¸‹æ–‡é€‚åº”æ€§ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç°å¾—åˆ°å…¨é¢è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå‚æ•°è¶…è¿‡70Bçš„LLMåœ¨å¼€æ”¾å¼ç”Ÿæˆä»»åŠ¡ä¸­è·å¾—äº†äººç±»è¯„ä¼°è€…çš„åå¥½ï¼Œè¡¨æ˜å…¶åœ¨ç¤¼è²Œç­–ç•¥ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå°½ç®¡LLMåœ¨æŸäº›ä¸Šä¸‹æ–‡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶å¯¹æ¶ˆæç¤¼è²Œç­–ç•¥çš„è¿‡åº¦ä¾èµ–å¯èƒ½å¯¼è‡´è¯¯è§£ï¼Œè¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æ™ºèƒ½å®¢æœå’Œç¤¾äº¤æœºå™¨äººç­‰ã€‚é€šè¿‡ä¼˜åŒ–LLMçš„ç¤¼è²Œç­–ç•¥ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºäººæœºæ²Ÿé€šçš„è‡ªç„¶æ€§ä¸æœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„ç¤¾äº¤åœºæ™¯ä¸­åº”ç”¨è¿™äº›ç­–ç•¥ï¼Œä¿ƒè¿›äººç±»ä¸AIçš„æ›´å¥½åä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Polite speech poses a fundamental alignment challenge for large language models (LLMs). Humans deploy a rich repertoire of linguistic strategies to balance informational and social goals -- from positive approaches that build rapport (compliments, expressions of interest) to negative strategies that minimize imposition (hedging, indirectness). We investigate whether LLMs employ a similarly context-sensitive repertoire by comparing human and LLM responses in both constrained and open-ended production tasks. We find that larger models ($\ge$70B parameters) successfully replicate key preferences from the computational pragmatics literature, and human evaluators surprisingly prefer LLM-generated responses in open-ended contexts. However, further linguistic analyses reveal that models disproportionately rely on negative politeness strategies even in positive contexts, potentially leading to misinterpretations. While modern LLMs demonstrate an impressive handle on politeness strategies, these subtle differences raise important questions about pragmatic alignment in AI systems.

