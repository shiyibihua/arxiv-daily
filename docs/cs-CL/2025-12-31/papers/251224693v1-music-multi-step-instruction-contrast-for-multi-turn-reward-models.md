---
layout: default
title: "MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models"
---

# MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.24693" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.24693v1</a>
  <a href="https://arxiv.org/pdf/2512.24693.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.24693v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.24693v1', 'MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenzhe Li, Shujian Zhang, Wenxuan Zhou, John Lambert, Chi Jin, Andrew Hard, Rajiv Mathews, Lun Wang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMUSICï¼šå¤šæ­¥æŒ‡ä»¤å¯¹æ¯”æ–¹æ³•ï¼Œæå‡å¤šè½®å¯¹è¯å¥–åŠ±æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè½®å¯¹è¯` `å¥–åŠ±æ¨¡å‹` `æ•°æ®å¢å¼º` `æŒ‡ä»¤å¯¹æ¯”` `æ— ç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¥–åŠ±æ¨¡å‹åœ¨å¤šè½®å¯¹è¯è¯„ä¼°ä¸­è¡¨ç°ä¸è¶³ï¼Œå› ä¸ºæ ‡å‡†åå¥½æ•°æ®é›†ç¼ºä¹è¶³å¤Ÿçš„å¤šè½®äº¤äº’ä¿¡å·ã€‚
2. MUSICé€šè¿‡æ— ç›‘ç£æ•°æ®å¢å¼ºï¼Œåˆæˆè·¨å¤šè½®çš„å¯¹æ¯”å¯¹è¯å¯¹ï¼Œä»è€Œå¢å¼ºå¥–åŠ±æ¨¡å‹å¯¹å¤šè½®äº¤äº’çš„ç†è§£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMUSICå¢å¼ºçš„å¥–åŠ±æ¨¡å‹åœ¨å¤šè½®å¯¹è¯è¯„ä¼°ä¸­ä¸LLM judgesçš„åˆ¤æ–­æ›´ä¸€è‡´ï¼Œä¸”ä¸å½±å“å•è½®æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯„ä¼°å¤šè½®å¯¹è¯çš„è´¨é‡å¯¹äºå¼€å‘å¼ºå¤§çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡³å…³é‡è¦ï¼Œä½†ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ï¼Œé€šå¸¸éœ€è¦æ˜‚è´µçš„äººå·¥è¯„ä¼°ã€‚å¤šè½®å¥–åŠ±æ¨¡å‹ï¼ˆRMsï¼‰æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶ä¸”å¯ä»¥ä¸ºæŒ‡å¯¼LLMè®­ç»ƒæä¾›æœ‰ä»·å€¼çš„ä¿¡å·ã€‚è™½ç„¶æœ€è¿‘çš„å·¥ä½œå·²ç»æ¨è¿›äº†å¤šè½®	extit{è®­ç»ƒ}æŠ€æœ¯ï¼Œä½†ä¸“é—¨é’ˆå¯¹å¤šè½®äº¤äº’çš„æœ‰æ•ˆè‡ªåŠ¨åŒ–	extit{è¯„ä¼°}ä»ç„¶æ»åã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæ ‡å‡†çš„åå¥½æ•°æ®é›†é€šå¸¸ä»…åŸºäºæœ€ç»ˆå¯¹è¯è½®æ¬¡æ¥å¯¹æ¯”å“åº”ï¼Œæä¾›çš„ä¿¡å·ä¸è¶³ä»¥æ•æ‰å¤šè½®äº¤äº’çš„ç»†å¾®å·®åˆ«ã€‚ç›¸åï¼Œæˆ‘ä»¬å‘ç°ï¼Œçº³å…¥è·¨è¶Š	extit{å¤šä¸ª}è½®æ¬¡çš„å¯¹æ¯”å¯¹äºæ„å»ºç¨³å¥çš„å¤šè½®RMè‡³å…³é‡è¦ã€‚å—æ­¤å‘ç°çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ— ç›‘ç£æ•°æ®å¢å¼ºç­–ç•¥ï¼Œå³	extbf{MU}lti-	extbf{S}tep 	extbf{I}nstruction 	extbf{C}ontrast (MUSIC)ï¼Œå®ƒåˆæˆäº†åœ¨å¤šä¸ªè½®æ¬¡ä¸­è¡¨ç°å‡ºå·®å¼‚çš„å¯¹æ¯”å¯¹è¯å¯¹ã€‚åˆ©ç”¨Skyworkåå¥½æ•°æ®é›†ä¸Šçš„MUSICï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªåŸºäºGemma-2-9B-Instructæ¨¡å‹çš„å¤šè½®RMã€‚ç»éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„MUSICå¢å¼ºRMä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œåœ¨å¤šè½®å¯¹è¯ä¸­å®ç°äº†ä¸é«˜çº§ä¸“æœ‰LLM judgesçš„åˆ¤æ–­æ›´é«˜çš„ä¸€è‡´æ€§ï¼Œå…³é”®æ˜¯ï¼Œæ²¡æœ‰å½±å“æ ‡å‡†å•è½®RMåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šè½®å¯¹è¯å¥–åŠ±æ¨¡å‹è®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰å¥–åŠ±æ¨¡å‹é€šå¸¸åŸºäºå•è½®å¯¹è¯æ•°æ®è®­ç»ƒï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡ä¾èµ–å’Œç»†å¾®å·®åˆ«ã€‚è¿™å¯¼è‡´å¥–åŠ±æ¨¡å‹åœ¨è¯„ä¼°å¤šè½®å¯¹è¯è´¨é‡æ—¶è¡¨ç°ä¸ä½³ï¼Œä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ— ç›‘ç£æ•°æ®å¢å¼ºï¼Œç”ŸæˆåŒ…å«å¤šè½®äº¤äº’ä¿¡æ¯çš„å¯¹æ¯”æ ·æœ¬ã€‚å…·ä½“æ¥è¯´ï¼ŒMUSICæ–¹æ³•é€šè¿‡ä¿®æ”¹å¯¹è¯å†å²ä¸­çš„å¤šä¸ªè½®æ¬¡ï¼Œç”Ÿæˆå…·æœ‰ç»†å¾®å·®å¼‚çš„å¯¹è¯å¯¹ï¼Œä»è€Œè¿«ä½¿å¥–åŠ±æ¨¡å‹å­¦ä¹ åŒºåˆ†ä¸åŒå¯¹è¯ç­–ç•¥çš„ä¼˜åŠ£ã€‚è¿™ç§å¤šæ­¥æŒ‡ä»¤å¯¹æ¯”èƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰å¤šè½®å¯¹è¯çš„å¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMUSICæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä»ç°æœ‰å¯¹è¯æ•°æ®é›†ä¸­é€‰æ‹©å¯¹è¯æ ·æœ¬ï¼›2) éšæœºé€‰æ‹©å¯¹è¯ä¸­çš„å¤šä¸ªè½®æ¬¡ï¼›3) ä½¿ç”¨æŒ‡ä»¤æ”¹å†™æ¨¡å‹å¯¹é€‰å®šçš„è½®æ¬¡è¿›è¡Œä¿®æ”¹ï¼Œç”Ÿæˆå¯¹æ¯”æ ·æœ¬ï¼›4) å°†åŸå§‹å¯¹è¯å’Œä¿®æ”¹åçš„å¯¹è¯ç»„æˆå¯¹æ¯”å¯¹ï¼Œç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚æ•´ä¸ªè¿‡ç¨‹æ˜¯æ— ç›‘ç£çš„ï¼Œä¸éœ€è¦äººå·¥æ ‡æ³¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šMUSICçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šæ­¥æŒ‡ä»¤å¯¹æ¯”ç­–ç•¥ã€‚ä¸ä»¥å¾€ä»…å…³æ³¨æœ€ç»ˆè½®æ¬¡å¯¹æ¯”çš„æ–¹æ³•ä¸åŒï¼ŒMUSICé€šè¿‡ä¿®æ”¹å¯¹è¯å†å²ä¸­çš„å¤šä¸ªè½®æ¬¡ï¼Œç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„å¯¹æ¯”æ ·æœ¬ï¼Œä»è€Œè¿«ä½¿å¥–åŠ±æ¨¡å‹å­¦ä¹ æ•æ‰å¤šè½®å¯¹è¯ä¸­çš„é•¿æœŸä¾èµ–å…³ç³»ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç°æœ‰æ•°æ®ï¼Œæå‡å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šMUSICæ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é«˜è´¨é‡çš„æŒ‡ä»¤æ”¹å†™æ¨¡å‹ï¼Œç¡®ä¿ç”Ÿæˆçš„å¯¹æ¯”æ ·æœ¬å…·æœ‰è¯­ä¹‰ä¸€è‡´æ€§å’Œåˆç†æ€§ï¼›2) éšæœºé€‰æ‹©ä¿®æ”¹çš„è½®æ¬¡æ•°é‡å’Œä½ç½®ï¼Œå¢åŠ å¯¹æ¯”æ ·æœ¬çš„å¤šæ ·æ€§ï¼›3) ä½¿ç”¨åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚hinge lossæˆ–margin ranking lossï¼Œé¼“åŠ±å¥–åŠ±æ¨¡å‹åŒºåˆ†ä¸åŒå¯¹è¯ç­–ç•¥çš„ä¼˜åŠ£ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.24693v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.24693v1/x2.png" alt="fig_1" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMUSICå¢å¼ºçš„å¥–åŠ±æ¨¡å‹åœ¨å¤šè½®å¯¹è¯è¯„ä¼°ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒMUSICåœ¨ä¸é«˜çº§ä¸“æœ‰LLM judgesçš„åˆ¤æ–­ä¸€è‡´æ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿æŒäº†åœ¨æ ‡å‡†å•è½®RMåŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚è¿™è¡¨æ˜MUSICèƒ½å¤Ÿæœ‰æ•ˆæå‡å¥–åŠ±æ¨¡å‹å¯¹å¤šè½®å¯¹è¯çš„ç†è§£èƒ½åŠ›ï¼Œè€Œä¸ä¼šç‰ºç‰²å…¶åœ¨å•è½®å¯¹è¯ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MUSICæ–¹æ³•å¯ä»¥å¹¿æ³›åº”ç”¨äºå¤šè½®å¯¹è¯ç³»ç»Ÿçš„è®­ç»ƒå’Œè¯„ä¼°ã€‚å®ƒå¯ä»¥ç”¨äºè®­ç»ƒæ›´å‡†ç¡®çš„å¥–åŠ±æ¨¡å‹ï¼Œä»è€ŒæŒ‡å¯¼å¯¹è¯ç­–ç•¥çš„å­¦ä¹ å’Œä¼˜åŒ–ã€‚æ­¤å¤–ï¼ŒMUSICè¿˜å¯ä»¥ç”¨äºè¯„ä¼°ä¸åŒå¯¹è¯ç³»ç»Ÿçš„æ€§èƒ½ï¼Œä¸ºç³»ç»Ÿæ”¹è¿›æä¾›ä¾æ®ã€‚è¯¥æ–¹æ³•åœ¨æ™ºèƒ½å®¢æœã€èŠå¤©æœºå™¨äººã€è™šæ‹ŸåŠ©æ‰‹ç­‰é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \textit{training} techniques, effective automated \textit{evaluation} specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \textit{multiple} turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \textbf{MU}lti-\textbf{S}tep \textbf{I}nstruction \textbf{C}ontrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.

