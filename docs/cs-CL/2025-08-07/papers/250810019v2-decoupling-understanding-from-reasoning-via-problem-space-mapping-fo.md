---
layout: default
title: Decoupling Understanding from Reasoning via Problem Space Mapping for Small-Scale Model Reasoning
---

# Decoupling Understanding from Reasoning via Problem Space Mapping for Small-Scale Model Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10019" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10019v2</a>
  <a href="https://arxiv.org/pdf/2508.10019.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10019v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10019v2', 'Decoupling Understanding from Reasoning via Problem Space Mapping for Small-Scale Model Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Li Wang, Changhao Zhang, Zengqi Xiu, Kai Lu, Xin Yu, Kui Zhang, Wenjun Wu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-07 (æ›´æ–°: 2025-12-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDURITæ¡†æ¶ä»¥è§£å†³å°è§„æ¨¡æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°è§„æ¨¡è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è‡ªç„¶è¯­è¨€å¤„ç†` `é—®é¢˜ç©ºé—´æ˜ å°„` `è§£è€¦è®­ç»ƒ` `å¼ºåŒ–å­¦ä¹ ` `è‡ªè’¸é¦` `æ•°å­¦æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å°è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚è‡ªç„¶è¯­è¨€æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆæå–æ ¸å¿ƒé—®é¢˜ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„DURITæ¡†æ¶é€šè¿‡å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°æ ‡å‡†åŒ–é—®é¢˜ç©ºé—´ï¼Œè§£è€¦ç†è§£ä¸æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDURITåœ¨æ•°å­¦å’Œé€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡äº†å°è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼Œå¦‚å‚æ•°ä¸è¶…è¿‡1.5Bï¼‰çš„æ¨ç†èƒ½åŠ›æå‡ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸»è¦éšœç¢åœ¨äºè‡ªç„¶è¯­è¨€çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼šæœ¬è´¨ä¸Šç­‰ä»·çš„é—®é¢˜å¸¸ä»¥ä¸åŒçš„è¡¨é¢å½¢å¼å‡ºç°ï¼Œä¸”å¸¸è¢«å†—ä½™æˆ–å¹²æ‰°ç»†èŠ‚æ‰€æ©ç›–ã€‚è¿™å¯¹SLMsé€ æˆäº†åŒé‡è´Ÿæ‹…ï¼šé¦–å…ˆå¿…é¡»ä»å¤æ‚çš„è¯­è¨€è¾“å…¥ä¸­æå–æ ¸å¿ƒé—®é¢˜ï¼Œç„¶ååŸºäºè¯¥ç†è§£è¿›è¡Œæ¨ç†ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¡†æ¶ï¼Œé€šè¿‡å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯­ä¹‰ç®€åŒ–é—®é¢˜ç©ºé—´ï¼Œä»è€Œå°†ç†è§£ä¸æ¨ç†è§£è€¦ã€‚æˆ‘ä»¬å¼•å…¥äº†DURITï¼ˆé€šè¿‡è¿­ä»£è®­ç»ƒè§£è€¦ç†è§£ä¸æ¨ç†ï¼‰ï¼Œè¯¥ç®—æ³•é€šè¿‡ä¸‰æ­¥è¿­ä»£è¿‡ç¨‹æ˜¾è‘—æå‡SLMsåœ¨æ•°å­¦å’Œé€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨å¤æ‚è‡ªç„¶è¯­è¨€è¾“å…¥ä¸­æå–æ ¸å¿ƒé—®é¢˜å’Œè¿›è¡Œæœ‰æ•ˆæ¨ç†çš„å›°éš¾ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–çš„è¯­è¨€å½¢å¼æ—¶ï¼Œå¾€å¾€å—åˆ°å†—ä½™ä¿¡æ¯çš„å¹²æ‰°ï¼Œå¯¼è‡´æ¨ç†æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°ä¸€ä¸ªè¯­ä¹‰ç®€åŒ–çš„æ ‡å‡†åŒ–é—®é¢˜ç©ºé—´ï¼Œä»è€Œä½¿å°è§„æ¨¡è¯­è¨€æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºæ¨ç†ï¼Œè€Œä¸å—è¯­è¨€å˜å¼‚çš„å½±å“ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å‡å°‘æ¨¡å‹çš„è´Ÿæ‹…ï¼Œæé«˜æ¨ç†æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé—®é¢˜æ˜ å°„æ¨¡å—ã€æ¨ç†è½¨è¿¹å¯¹é½æ¨¡å—å’Œæ¨ç†ç­–ç•¥è®­ç»ƒæ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°æ ‡å‡†åŒ–é—®é¢˜ç©ºé—´ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨è‡ªè’¸é¦æ–¹æ³•å¯¹æ¨ç†è½¨è¿¹è¿›è¡Œå¯¹é½ï¼›æœ€åï¼Œåœ¨é—®é¢˜ç©ºé—´ä¸­è®­ç»ƒæ¨ç†ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºè§£è€¦ç†è§£ä¸æ¨ç†çš„è¿‡ç¨‹ï¼Œé€šè¿‡æ ‡å‡†åŒ–é—®é¢˜ç©ºé—´çš„å¼•å…¥ï¼Œä½¿å¾—å°è§„æ¨¡è¯­è¨€æ¨¡å‹èƒ½å¤Ÿåœ¨æ›´ç®€åŒ–çš„ç¯å¢ƒä¸­è¿›è¡Œæ¨ç†ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„ç›´æ¥æ¨ç†æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œåè€…æœªèƒ½æœ‰æ•ˆå¤„ç†è¯­è¨€çš„å¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DURITæ¡†æ¶ä¸­ï¼Œé‡‡ç”¨äº†å¼ºåŒ–å­¦ä¹ è¿›è¡Œé—®é¢˜æ˜ å°„ï¼Œè®¾è®¡äº†è‡ªè’¸é¦æœºåˆ¶ä»¥å¯¹é½æ¨ç†è½¨è¿¹ï¼Œå¹¶åœ¨é—®é¢˜ç©ºé—´ä¸­è®­ç»ƒæ¨ç†ç­–ç•¥ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDURITåœ¨æ•°å­¦å’Œé€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—æå‡äº†å°è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å®šé¢†åŸŸä»»åŠ¡ä¸­ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ¨ç†ç­‰ã€‚é€šè¿‡æå‡å°è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒDURITæ¡†æ¶å¯ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„æ™ºèƒ½å†³ç­–ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite recent advances in the reasoning capabilities of Large Language Models (LLMs), improving the reasoning ability of Small Language Models (SLMs, e.g., up to 1.5B parameters) remains challenging. A key obstacle lies in the complexity and variability of natural language: essentially equivalent problems often appear in diverse surface forms, often obscured by redundant or distracting details. This imposes a dual burden on SLMs: they must first extract the core problem from complex linguistic input, and then perform reasoning based on that understanding. The resulting vast and noisy problem space hinders optimization, particularly for models with limited capacity. To address this, we propose a new framework that decouples understanding from reasoning by mapping natural language problems into a canonical problem space-a semantically simplified yet expressive domain. This enables SLMs to focus on reasoning over standardized inputs, free from linguistic variability. Within this framework, we introduce DURIT (Decoupled Understanding from Reasoning via Iterative Training), a three-step algorithm that iteratively: (1) mapping natural language problems via reinforcement learning, (2) aligns reasoning trajectories through self-distillation, and (3) trains reasoning policies in the problem space. The mapper and reasoner are co-trained in an alternating loop throughout this process. Experiments show that DURIT substantially improves SLMs' performance on both in-domain and out-of-domain mathematical and logical reasoning tasks. Beyond improving reasoning capabilities, DURIT also improves the robustness of reasoning, validating decoupling understanding from reasoning as an effective strategy for strengthening SLMs.

