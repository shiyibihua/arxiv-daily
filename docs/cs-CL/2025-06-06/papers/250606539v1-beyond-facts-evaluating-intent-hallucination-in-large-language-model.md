---
layout: default
title: Beyond Facts: Evaluating Intent Hallucination in Large Language Models
---

# Beyond Facts: Evaluating Intent Hallucination in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06539" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06539v1</a>
  <a href="https://arxiv.org/pdf/2506.06539.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06539v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06539v1', 'Beyond Facts: Evaluating Intent Hallucination in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yijie Hao, Haofei Yu, Jiaxuan You

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: Accepted to ACL 2025 main conference

**æœŸåˆŠ**: Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFAITHQAåŸºå‡†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æ„å›¾å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ„å›¾å¹»è§‰` `å¤§å‹è¯­è¨€æ¨¡å‹` `FAITHQA` `è‡ªåŠ¨è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `CONSTRAINT SCORE`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æŸ¥è¯¢ä¸­å¸¸å‡ºç°æ„å›¾å¹»è§‰ï¼Œå¯¼è‡´å“åº”ä¸å®Œæ•´æˆ–è¯¯è§£æŸ¥è¯¢ã€‚
2. æœ¬æ–‡æå‡ºFAITHQAåŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°æ„å›¾å¹»è§‰ï¼Œæ¶µç›–å¤šç§æŸ¥è¯¢å’Œç”Ÿæˆè®¾ç½®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ„å›¾å¹»è§‰æ™®éå­˜åœ¨ï¼Œä¸”CONSTRAINT SCOREåœ¨æ£€æµ‹ä¸Šä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é¢å¯¹åŒ…å«å¤šä¸ªæ¡ä»¶çš„å¤æ‚æŸ¥è¯¢æ—¶ï¼Œå½“å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾€å¾€åªéƒ¨åˆ†æ»¡è¶³æŸ¥è¯¢ï¼Œå¿½ç•¥æŸäº›æ¡ä»¶ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†æ„å›¾å¹»è§‰çš„æ¦‚å¿µï¼ŒæŒ‡çš„æ˜¯LLMsåœ¨ç”Ÿæˆå“åº”æ—¶è¦ä¹ˆé—æ¼ï¼ˆæœªèƒ½å¤„ç†æŸäº›éƒ¨åˆ†ï¼‰ï¼Œè¦ä¹ˆè¯¯è§£ï¼ˆå›åº”è™šæ„çš„æŸ¥è¯¢éƒ¨åˆ†ï¼‰ç»™å®šæŸ¥è¯¢çš„å…ƒç´ ã€‚ä¸ºç³»ç»Ÿè¯„ä¼°æ„å›¾å¹»è§‰ï¼Œæœ¬æ–‡æå‡ºäº†FAITHQAï¼Œä¸€ä¸ªåŒ…å«20,068ä¸ªé—®é¢˜çš„æ–°åŸºå‡†ï¼Œæ¶µç›–æŸ¥è¯¢å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è®¾ç½®ï¼Œæ¶‰åŠä¸åŒä¸»é¢˜å’Œéš¾åº¦ã€‚FAITHQAæ˜¯é¦–ä¸ªè¶…è¶Šäº‹å®éªŒè¯çš„å¹»è§‰åŸºå‡†ï¼Œæ—¨åœ¨è¯†åˆ«æ„å›¾å¹»è§‰çš„æ ¹æœ¬åŸå› ã€‚é€šè¿‡åœ¨FAITHQAä¸Šè¯„ä¼°å¤šç§LLMsï¼Œå‘ç°æ„å›¾å¹»è§‰æ˜¯å³ä½¿æ˜¯æœ€å…ˆè¿›æ¨¡å‹ä¹Ÿæ™®éå­˜åœ¨çš„é—®é¢˜ï¼Œä¸”è¯¥ç°è±¡æºäºLLMsçš„é—æ¼æˆ–è¯¯è§£ã€‚ä¸ºä¿ƒè¿›æœªæ¥ç ”ç©¶ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§è‡ªåŠ¨LLMç”Ÿæˆè¯„ä¼°æŒ‡æ ‡CONSTRAINT SCOREï¼Œç”¨äºæ£€æµ‹æ„å›¾å¹»è§‰ã€‚äººç±»è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒCONSTRAINT SCOREåœ¨æ„å›¾å¹»è§‰æ£€æµ‹ä¸Šæ›´æ¥è¿‘äººç±»è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶çš„æ„å›¾å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å’Œè¯„ä¼°è¿™ä¸€ç°è±¡ï¼Œå¯¼è‡´ç”Ÿæˆçš„å“åº”ä¸å‡†ç¡®æˆ–ä¸å®Œæ•´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºFAITHQAåŸºå‡†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°æ„å›¾å¹»è§‰ï¼Œè¯†åˆ«æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­é—æ¼æˆ–è¯¯è§£æŸ¥è¯¢çš„æ ¹æœ¬åŸå› ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFAITHQAåŸºå‡†åŒ…å«20,068ä¸ªé—®é¢˜ï¼Œåˆ†ä¸ºæŸ¥è¯¢ä»…å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆä¸¤ç§è®¾ç½®ï¼Œæ¶µç›–å¤šç§ä¸»é¢˜å’Œéš¾åº¦ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°æ„å›¾å¹»è§‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯å¼•å…¥äº†CONSTRAINT SCOREè¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ£€æµ‹æ„å›¾å¹»è§‰ï¼Œä¸”åœ¨æ€§èƒ½ä¸Šæ›´æ¥è¿‘äººç±»è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒFAITHQAçš„æ„å»ºè€ƒè™‘äº†å¤šæ ·æ€§å’Œéš¾åº¦ï¼ŒCONSTRAINT SCOREçš„è®¡ç®—æ–¹å¼åŸºäºå¯¹ç”Ÿæˆå†…å®¹çš„çº¦æŸåˆ†æï¼Œç¡®ä¿èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ„å›¾å¹»è§‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ„å›¾å¹»è§‰åœ¨å½“å‰çš„æœ€å…ˆè¿›æ¨¡å‹ä¸­æ™®éå­˜åœ¨ï¼ŒCONSTRAINT SCOREåœ¨æ£€æµ‹æ„å›¾å¹»è§‰æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œæ¥è¿‘äººç±»è¯„ä¼°ç»“æœï¼Œè¡¨æ˜è¯¥æŒ‡æ ‡çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´ä¸ºç²¾å‡†å’Œå¯é çš„è¯­è¨€æ¨¡å‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œä¿¡æ¯è·å–çš„å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œéšç€æ„å›¾å¹»è§‰é—®é¢˜çš„æ·±å…¥ç ”ç©¶ï¼Œå¯èƒ½ä¼šæ¨åŠ¨æ›´æ™ºèƒ½çš„AIç³»ç»Ÿçš„å‡ºç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> When exposed to complex queries containing multiple conditions, today's large language models (LLMs) tend to produce responses that only partially satisfy the query while neglecting certain conditions. We therefore introduce the concept of Intent Hallucination. In this phenomenon, LLMs either omit (neglecting to address certain parts) or misinterpret (responding to invented query parts) elements of the given query, leading to intent hallucinated generation. To systematically evaluate intent hallucination, we introduce FAITHQA, a novel benchmark for intent hallucination that contains 20,068 problems, covering both query-only and retrieval-augmented generation (RAG) setups with varying topics and difficulty. FAITHQA is the first hallucination benchmark that goes beyond factual verification, tailored to identify the fundamental cause of intent hallucination. By evaluating various LLMs on FAITHQA, we find that (1) intent hallucination is a common issue even for state-of-the-art models, and (2) the phenomenon stems from omission or misinterpretation of LLMs. To facilitate future research, we introduce an automatic LLM generation evaluation metric, CONSTRAINT SCORE, for detecting intent hallucination. Human evaluation results demonstrate that CONSTRAINT SCORE is closer to human performance for intent hallucination compared to baselines.

