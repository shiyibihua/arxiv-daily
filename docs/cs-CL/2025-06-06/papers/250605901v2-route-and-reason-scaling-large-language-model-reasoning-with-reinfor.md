---
layout: default
title: Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router
---

# Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05901" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.05901v2</a>
  <a href="https://arxiv.org/pdf/2506.05901.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05901v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05901v2', 'Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chenyang Shao, Xinyang Liu, Yutang Lin, Fengli Xu, Yong Li

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-06 (Êõ¥Êñ∞: 2025-12-04)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫R2-Reasoner‰ª•Ëß£ÂÜ≥Â§ßËßÑÊ®°ËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êé®ÁêÜÊïàÁéá` `Âº∫ÂåñÂ≠¶‰π†` `Ê®°ÂûãË∑ØÁî±` `‰ªªÂä°ÂàÜËß£` `ÂºÇÊûÑÊ®°ÂûãÂçè‰Ωú` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®‰ªªÂä°Â±ÇÈù¢Áõ¥Êé•ÂàÜÈÖçÁî®Êà∑Êü•ËØ¢ÔºåÊó†Ê≥ïÂÆûÁé∞LLMsÂú®ÁªÜÁ≤íÂ∫¶Â≠ê‰ªªÂä°‰∏äÁöÑÊúâÊïàÂçè‰ΩúÔºåÂØºËá¥Êé®ÁêÜÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫R2-ReasonerÊ°ÜÊû∂ÔºåÈÄöËøáÂº∫ÂåñÊ®°ÂûãË∑ØÁî±Âô®ÂÆûÁé∞Â§ö‰∏™ÂºÇÊûÑÊ®°ÂûãÁöÑÂçè‰ΩúÔºå‰ºòÂåñÂ§çÊùÇÊü•ËØ¢ÁöÑÂ§ÑÁêÜËøáÁ®ã„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåR2-ReasonerÂú®ÂÖ≠‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂ∞ÜAPIÊàêÊú¨Èôç‰Ωé‰∫Ü84.46%ÔºåÂêåÊó∂‰øùÊåÅ‰∫Ü‰∏éÊúÄÂÖàËøõÂü∫Á∫øÁõ∏ÂΩìÁöÑÊé®ÁêÜÂáÜÁ°ÆÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈìæÂºèÊÄùÁª¥Ë¢´ËØÅÊòéÂØπÂ¢ûÂº∫Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÂ§çÊùÇÊé®ÁêÜËÉΩÂäõËá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜ‰πüÂØºËá¥‰∫ÜÈ´òËÆ°ÁÆóÊàêÊú¨„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰ªªÂä°Â±ÇÈù¢Áõ¥Êé•Êìç‰ΩúÔºåÊó†Ê≥ïÂÆûÁé∞Ê∑∑ÂêàLLMsÂú®Êõ¥ÁªÜÁ≤íÂ∫¶Â≠ê‰ªªÂä°‰∏äÁöÑÁúüÊ≠£Âçè‰Ωú„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫R2-ReasonerÔºå‰∏Ä‰∏™Âõ¥ÁªïÂº∫ÂåñÊ®°ÂûãË∑ØÁî±Âô®ËÆæËÆ°ÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊó®Âú®È´òÊïàÊâ©Â±ïLLMÊé®ÁêÜ„ÄÇËØ•Ë∑ØÁî±Âô®ÈÄöËøáÂ∞ÜÂ§çÊùÇÊü•ËØ¢ÂàÜËß£‰∏∫Â≠ê‰ªªÂä°ÔºåÂπ∂Â∞ÜÊØè‰∏™Â≠ê‰ªªÂä°ÂàÜÈÖçÁªôÊúÄ‰ºòÊ®°ÂûãÔºåÂπ≥Ë°°ÊÄßËÉΩ‰∏éÊàêÊú¨„ÄÇÂÆûÈ™åË°®ÊòéÔºåR2-ReasonerÂú®ÂÖ≠‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÂ∞ÜAPIÊàêÊú¨Èôç‰Ωé‰∫Ü84.46%ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÁ´û‰∫âÂäõÁöÑÊé®ÁêÜÂáÜÁ°ÆÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÈ´òËÆ°ÁÆóÊàêÊú¨Âíå‰ΩéÊïàÁéáÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®‰ªªÂä°Â±ÇÈù¢ËøõË°åÊìç‰ΩúÔºåÊó†Ê≥ïÂÆûÁé∞Êõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÂçè‰ΩúÔºåÂØºËá¥ËµÑÊ∫êÊµ™Ë¥πÂíåÊÄßËÉΩÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöR2-ReasonerÈÄöËøáÂºïÂÖ•Âº∫ÂåñÊ®°ÂûãË∑ØÁî±Âô®ÔºåÈ¶ñÂÖàÂ∞ÜÂ§çÊùÇÊü•ËØ¢ÂàÜËß£‰∏∫Â§ö‰∏™Â≠ê‰ªªÂä°ÔºåÁÑ∂ÂêéÂ∞ÜÊØè‰∏™Â≠ê‰ªªÂä°ÂàÜÈÖçÁªôÊúÄÈÄÇÂêàÁöÑÊ®°ÂûãÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÂçè‰ΩúÂíåËµÑÊ∫êÂà©Áî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰∏§‰∏™Ê®°ÂùóÔºöÂàÜËß£Âô®ÂíåÂàÜÈÖçÂô®„ÄÇÂàÜËß£Âô®Ë¥üË¥£Â∞ÜÂ§çÊùÇÊü•ËØ¢ÊãÜÂàÜ‰∏∫Â≠ê‰ªªÂä°ÔºåÂàÜÈÖçÂô®ÂàôÊ†πÊçÆÊØè‰∏™Â≠ê‰ªªÂä°ÁöÑÁâπÁÇπÈÄâÊã©ÊúÄ‰ºòÊ®°Âûã„ÄÇËÆ≠ÁªÉËøáÁ®ã‰∏≠ÈááÁî®ÁõëÁù£ÂæÆË∞É‰∏éÂº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÁöÑÊñπÂºèÔºåÊèêÂçáË∑ØÁî±Âô®ÁöÑËá™Êàë‰ºòÂåñËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöR2-ReasonerÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂÖ∂Âº∫ÂåñÊ®°ÂûãË∑ØÁî±Âô®ÁöÑËÆæËÆ°Ôºå‰ΩøÂæóÂ§ö‰∏™ÂºÇÊûÑÊ®°ÂûãËÉΩÂ§üÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂçèÂêåÂ∑•‰ΩúÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊé®ÁêÜÊïàÁéáÂíåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•Ê°ÜÊû∂ÂÆûÁé∞‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑ‰ªªÂä°Âçè‰Ωú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∏§Èò∂ÊÆµ‰∫§ÊõøËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁªìÂêàÁõëÁù£Â≠¶‰π†ÂíåÂº∫ÂåñÂ≠¶‰π†ÔºåÁ°Æ‰øùÂàÜËß£Âô®ÂíåÂàÜÈÖçÂô®ÁöÑÊúâÊïàÊÄß„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÂèÇÊï∞ÁöÑÈÄâÊã©ÂíåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüÁªèËøáÁ≤æÂøÉË∞ÉÊï¥Ôºå‰ª•‰ºòÂåñÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÖ≠‰∏™Êé®ÁêÜÂü∫ÂáÜ‰∏äÔºåR2-ReasonerÁõ∏ËæÉ‰∫éÊúÄÂÖàËøõÁöÑÂü∫Á∫øÔºåAPIÊàêÊú¨Èôç‰Ωé‰∫Ü84.46%ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÁ´û‰∫âÂäõÁöÑÊé®ÁêÜÂáÜÁ°ÆÊÄß„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®Êé®ÁêÜÊïàÁéáÂíåÊàêÊú¨ÊéßÂà∂ÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

R2-ReasonerÊ°ÜÊû∂Âú®Â§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªüÂíåÂ§çÊùÇÂÜ≥Á≠ñÊîØÊåÅÁ≠â„ÄÇÂÖ∂È´òÊïàÁöÑÊé®ÁêÜËÉΩÂäõËÉΩÂ§üÊòæËëóÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨ÔºåÊèêÂçáÁ≥ªÁªüÂìçÂ∫îÈÄüÂ∫¶ÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®Êõ¥Â§ßËßÑÊ®°ÁöÑÊô∫ËÉΩÂ∫îÁî®ËêΩÂú∞„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Chain-of-thought has been proven essential for enhancing the complex reasoning abilities of Large Language Models (LLMs), but it also leads to high computational costs. Recent advances have explored the method to route queries among multiple models and proved it as a promising approach. However, previous works directly operate at the task level, i.e., assigning user queries to suitable LLMs, which does not allow hybrid LLMs to truly collaborate on finer-grained sub-tasks. Collaboration at the level of intermediate reasoning steps (thoughts) could enable more efficient coordination, but it also poses significant challenges for router scheduling, placing immense demands on the quality of task decomposition and the precision of the router. To address this, we propose R2-Reasoner, a novel framework centered around a Reinforced Model Router designed to efficiently scale LLM reasoning. This router orchestrates collaboration across nine heterogeneous models, whose parameter scales range from less than 1B to hundreds of billions, by first breaking down a complex query into subtasks with a decomposer, and then assigning each subtask to the optimal model with a subtask allocator, balancing performance with cost. Training this router involves a two-stage alternating process for the decomposer and the allocator, integrating supervised fine-tuning with reinforcement learning to enable effective self-supervised refinement. Extensive experiments across six challenging reasoning benchmarks demonstrate that R2-Reasoner reduces API costs by 84.46% compared with state-of-the-art baselines while maintaining competitive reasoning accuracy. Our framework paves the way for the development of more scalable and efficient reasoning systems. Our code is open-source at https://anonymous.4open.science/r/R2_Reasoner.

