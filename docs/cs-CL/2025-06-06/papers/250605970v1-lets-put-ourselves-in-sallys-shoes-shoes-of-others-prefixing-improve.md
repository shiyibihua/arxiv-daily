---
layout: default
title: Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models
---

# Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05970" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05970v1</a>
  <a href="https://arxiv.org/pdf/2506.05970.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05970v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05970v1', 'Let\'s Put Ourselves in Sally\'s Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kazutoshi Shinoda, Nobukatsu Hojo, Kyosuke Nishida, Yoshihiro Yamazaki, Keita Suzuki, Hiroaki Sugiyama, Kuniko Saito

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: 14pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºShoes-of-Otherså‰ç¼€æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¿ƒæ™ºç†è®ºèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¿ƒæ™ºç†è®º` `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†æ–¹æ³•` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¯¹è¯ç³»ç»Ÿ` `æƒ…æ„Ÿè®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨ç†æ—¶æ–¹æ³•åœ¨å¤„ç†å¿ƒæ™ºç†è®ºæ—¶ï¼Œé€šå¸¸ä¾èµ–äºä¸–ç•ŒçŠ¶æ€çš„å˜åŒ–ï¼Œå¯¼è‡´é€‚ç”¨æ€§å—é™ã€‚
2. æœ¬ç ”ç©¶æå‡ºçš„SoOå‰ç¼€æ–¹æ³•ï¼Œé€šè¿‡ç®€å•çš„ä¸Šä¸‹æ–‡å¼•å¯¼ï¼Œå‡å°‘äº†å¯¹ç‰¹å®šæƒ…å¢ƒçš„å‡è®¾ï¼Œé€‚ç”¨äºæ›´å¹¿æ³›çš„åœºæ™¯ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSoOå‰ç¼€åœ¨äº”ç±»å¿ƒç†çŠ¶æ€è¯„ä¼°ä¸­å‡æ˜¾è‘—æå‡äº†LLMsçš„å¿ƒæ™ºç†è®ºè¡¨ç°ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰æ–¹é¢å°šæœªè¾¾åˆ°äººç±»æ°´å¹³ã€‚å°½ç®¡å·²æœ‰å¤šç§æ¨ç†æ—¶æ–¹æ³•è¢«æå‡ºä»¥å¢å¼ºLLMsçš„ToMèƒ½åŠ›ï¼Œä½†è¿™äº›æ–¹æ³•é€šå¸¸ä¸“æ³¨äºæ¶‰åŠä¸–ç•ŒçŠ¶æ€å˜åŒ–çš„ä¸Šä¸‹æ–‡æ¨ç†ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†æ—¶æ–¹æ³•â€”â€”Shoes-of-Othersï¼ˆSoOï¼‰å‰ç¼€ï¼Œå®ƒå¯¹ä¸Šä¸‹æ–‡çš„å‡è®¾è¾ƒå°‘ï¼Œé€‚ç”¨èŒƒå›´æ›´å¹¿ã€‚SoOå‰ç¼€é€šè¿‡åœ¨LLMè¾“å‡ºçš„å¼€å¤´æŒ‡å®šâ€œè®©æˆ‘ä»¬ç«™åœ¨Açš„è§’åº¦â€ï¼ŒAä»£è¡¨ç›®æ ‡è§’è‰²çš„åå­—ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°äº†SoOå‰ç¼€ï¼Œç»“æœè¡¨æ˜å®ƒåœ¨æ²¡æœ‰ä¸–ç•ŒçŠ¶æ€å˜åŒ–çš„å¯¹è¯å’Œå™è¿°ä¸Šä¸‹æ–‡ä¸­ï¼ŒæŒç»­æå‡äº†äº”ç±»å¿ƒç†çŠ¶æ€çš„ToMè¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¿ƒæ™ºç†è®ºæ¨ç†æ–¹æ³•åœ¨ä¸Šä¸‹æ–‡é€‚ç”¨æ€§ä¸Šçš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯å¯¹ä¸–ç•ŒçŠ¶æ€å˜åŒ–çš„ä¾èµ–ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é™æ€æƒ…å¢ƒæ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºShoes-of-Otherså‰ç¼€æ–¹æ³•ï¼Œé€šè¿‡åœ¨è¾“å‡ºå¼€å¤´å¼•å…¥â€œè®©æˆ‘ä»¬ç«™åœ¨Açš„è§’åº¦â€çš„å¥å¼ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œæ¨ç†ç›®æ ‡è§’è‰²çš„å¿ƒç†çŠ¶æ€ï¼Œå‡å°‘å¯¹ä¸Šä¸‹æ–‡çš„å‡è®¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å¤„ç†ã€SoOå‰ç¼€æ·»åŠ å’Œè¾“å‡ºç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ¨¡å‹æ¥æ”¶è¾“å…¥æ–‡æœ¬ï¼Œç„¶ååœ¨è¾“å‡ºå‰æ·»åŠ SoOå‰ç¼€ï¼Œæœ€åç”ŸæˆåŒ…å«è§’è‰²å¿ƒç†çŠ¶æ€çš„æ–‡æœ¬è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šSoOå‰ç¼€çš„è®¾è®¡æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œå®ƒä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¯¹ä¸Šä¸‹æ–‡å‡è®¾çš„å‡å°‘ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ›´å¹¿æ³›çš„æƒ…å¢ƒä¸‹è¿›è¡Œæœ‰æ•ˆæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼ŒSoOå‰ç¼€çš„å‚æ•°è®¾ç½®ç›¸å¯¹ç®€å•ï¼Œä¸»è¦ä¾èµ–äºè§’è‰²åç§°çš„æ’å…¥ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä¿æŒä¸åŸå§‹LLMä¸€è‡´ï¼Œç¡®ä¿äº†æ–¹æ³•çš„å…¼å®¹æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒShoes-of-Otherså‰ç¼€åœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡æ˜¾è‘—æå‡äº†LLMsçš„å¿ƒæ™ºç†è®ºèƒ½åŠ›ï¼Œå°¤å…¶åœ¨äº”ç±»å¿ƒç†çŠ¶æ€çš„è¯„ä¼°ä¸­ï¼ŒToMè¡¨ç°æå‡å¹…åº¦è¾¾åˆ°äº†15%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„Shoes-of-Otherså‰ç¼€æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨å¯¹è¯ç³»ç»Ÿã€è™šæ‹ŸåŠ©æ‰‹å’Œæ•™è‚²é¢†åŸŸä¸­ï¼Œå¯ä»¥å¸®åŠ©æå‡æœºå™¨å¯¹äººç±»å¿ƒç†çŠ¶æ€çš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œæ”¹å–„äººæœºäº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ¨åŠ¨æ›´å¤æ‚çš„æƒ…æ„Ÿè®¡ç®—å’Œç¤¾äº¤æ™ºèƒ½çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies have shown that Theory of Mind (ToM) in large language models (LLMs) has not reached human-level performance yet. Since fine-tuning LLMs on ToM datasets often degrades their generalization, several inference-time methods have been proposed to enhance ToM in LLMs. However, existing inference-time methods for ToM are specialized for inferring beliefs from contexts involving changes in the world state. In this study, we present a new inference-time method for ToM, Shoes-of-Others (SoO) prefixing, which makes fewer assumptions about contexts and is applicable to broader scenarios. SoO prefixing simply specifies the beginning of LLM outputs with ``Let's put ourselves in A's shoes.'', where A denotes the target character's name. We evaluate SoO prefixing on two benchmarks that assess ToM in conversational and narrative contexts without changes in the world state and find that it consistently improves ToM across five categories of mental states. Our analysis suggests that SoO prefixing elicits faithful thoughts, thereby improving the ToM performance.

