---
layout: default
title: Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models
---

# Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05850" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05850v2</a>
  <a href="https://arxiv.org/pdf/2506.05850.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05850v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05850v2', 'Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cheonbok Park, Jeonghoon Kim, Joosung Lee, Sanghwan Bae, Jaegul Choo, Kang Min Yoo

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06 (æ›´æ–°: 2025-06-09)

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè·¨è¯­è¨€å´©æºƒç°è±¡ä»¥æ­ç¤ºå¤šè¯­è¨€æ¨¡å‹æ¨ç†çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è·¨è¯­è¨€æ¨ç†` `å¤šè¯­è¨€æ¨¡å‹` `é€»è¾‘æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `å¥–åŠ±è®¾è®¡` `ä½èµ„æºè¯­è¨€` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šè¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶å­˜åœ¨è¯­è¨€å´©æºƒç°è±¡ï¼Œå¯¼è‡´ä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›è¿…é€Ÿä¸‹é™ã€‚
2. è®ºæ–‡é€šè¿‡å¯¹å¤šè¯­è¨€å¤§å‹æ¨ç†æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæå‡ºäº†ä½¿ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯­è¨€ä¸€è‡´æ€§å¥–åŠ±å¯ä»¥ç¼“è§£å´©æºƒç°è±¡ï¼Œä½†ä¼šå¯¼è‡´å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼Œä¸”å´©æºƒç°è±¡å¤§éƒ¨åˆ†ä¸å¯é€†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡è¯†åˆ«äº†è·¨è¯­è¨€å´©æºƒç°è±¡ï¼Œå³å¤šè¯­è¨€æ¨¡å‹çš„æ¨ç†é“¾åœ¨ä½¿ç”¨ä¸åŒè¯­è¨€æç¤ºæ—¶ï¼Œä»ç„¶å›å½’åˆ°å…¶ä¸»å¯¼çš„é¢„è®­ç»ƒè¯­è¨€ã€‚å°½ç®¡é€šè¿‡å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å¤šè¯­è¨€æ¨ç†çš„æœºåˆ¶å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚æˆ‘ä»¬é€šè¿‡å¯¹å¤šè¯­è¨€å¤§å‹æ¨ç†æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå‘ç°é¢„è®­ç»ƒè¯­è¨€çš„ä¸å¹³è¡¡ä¼šè¿…é€ŸåŠ å‰§ï¼Œå¯¼è‡´ä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›ä¸‹é™ã€‚æ­¤å¤–ï¼Œå°½ç®¡è¯­è¨€ä¸€è‡´æ€§å¥–åŠ±å¯ä»¥ç¼“è§£è¿™ä¸€ç°è±¡ï¼Œä½†ä¼šå¯¼è‡´å‡†ç¡®ç‡ä¸‹é™5-10ä¸ªç™¾åˆ†ç‚¹ã€‚æœ€ç»ˆçš„è¯­è¨€å´©æºƒç°è±¡æ˜¯ä¸¥é‡ä¸”å¤§éƒ¨åˆ†ä¸å¯é€†çš„ï¼Œåç»­å¾®è°ƒéš¾ä»¥æ¢å¤æ¨¡å‹çš„ç›®æ ‡è¯­è¨€æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šè¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å‡ºç°çš„è·¨è¯­è¨€å´©æºƒç°è±¡ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†ä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›ä¸‹é™é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºé€šè¿‡ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¯¹å¤šè¯­è¨€å¤§å‹æ¨ç†æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æ”¹å–„å¤šè¯­è¨€æ¨ç†çš„å¹³è¡¡æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†ç¿»è¯‘åçš„GSM8Kå’ŒSimpleRL-Zooæ•°æ®é›†ï¼Œåˆ†åˆ«åœ¨ä¸­æ–‡ã€éŸ©æ–‡å’Œä¹Œå…‹å…°æ–‡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œç›‘æµ‹ä»»åŠ¡å‡†ç¡®æ€§å’Œæ¨ç†é“¾çš„ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè¯†åˆ«å¹¶åˆ†æäº†è·¨è¯­è¨€å´©æºƒç°è±¡ï¼Œæ­ç¤ºäº†ä¸åŒè¯­è¨€åœ¨æ¨ç†èƒ½åŠ›è®­ç»ƒä¸Šçš„ä¸å¹³ç­‰ï¼Œå¼ºè°ƒäº†å¥–åŠ±è®¾è®¡å’Œæ•°æ®éš¾åº¦å¯¹å¤šè¯­è¨€æ¨ç†çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†è¯­è¨€ä¸€è‡´æ€§å¥–åŠ±æœºåˆ¶ï¼Œå¹¶ç›‘æ§äº†æ¨¡å‹åœ¨ä¸åŒè¯­è¨€ä¸‹çš„æ¨ç†è¡¨ç°ï¼Œå‘ç°å…¶å¯¹å‡†ç¡®ç‡çš„å½±å“æ˜¾è‘—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨GRPOæ–¹æ³•åï¼Œä½èµ„æºè¯­è¨€çš„æ¨ç†èƒ½åŠ›åœ¨ä»…å‡ ç™¾æ¬¡æ›´æ–°å†…æ˜¾è‘—ä¸‹é™ï¼Œä¸”è¯­è¨€ä¸€è‡´æ€§å¥–åŠ±è™½ç„¶èƒ½å¤Ÿç¼“è§£å´©æºƒç°è±¡ï¼Œä½†å¯¼è‡´å‡†ç¡®ç‡ä¸‹é™5-10ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¤šè¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„ä¸å¹³ç­‰æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢å’Œå¤šè¯­è¨€å¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æ”¹å–„å¤šè¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿæå‡ä½èµ„æºè¯­è¨€çš„åº”ç”¨æ•ˆæœï¼Œæ¨åŠ¨å…¨çƒèŒƒå›´å†…çš„è¯­è¨€æŠ€æœ¯å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We identify \textbf{Cross-lingual Collapse}, a systematic drift in which the chain-of-thought (CoT) of a multilingual language model reverts to its dominant pre-training language even when the prompt is expressed in a different language. Recent large language models (LLMs) with reinforcement learning with verifiable reward (RLVR) have achieved strong logical reasoning performances by exposing their intermediate reasoning traces, giving rise to large reasoning models (LRMs). However, the mechanism behind multilingual reasoning in LRMs is not yet fully explored. To investigate the issue, we fine-tune multilingual LRMs with Group-Relative Policy Optimization (GRPO) on translated versions of the GSM$8$K and SimpleRL-Zoo datasets in three different languages: Chinese, Korean, and Ukrainian. During training, we monitor both task accuracy and language consistency of the reasoning chains. Our experiments reveal three key findings: (i) GRPO rapidly amplifies pre-training language imbalances, leading to the erosion of low-resource languages within just a few hundred updates; (ii) language consistency reward mitigates this drift but does so at the expense of an almost 5 - 10 pp drop in accuracy. and (iii) the resulting language collapse is severely damaging and largely irreversible, as subsequent fine-tuning struggles to steer the model back toward its original target-language reasoning capabilities. Together, these findings point to a remarkable conclusion: \textit{not all languages are trained equally for reasoning}. Furthermore, our paper sheds light on the roles of reward shaping, data difficulty, and pre-training priors in eliciting multilingual reasoning.

