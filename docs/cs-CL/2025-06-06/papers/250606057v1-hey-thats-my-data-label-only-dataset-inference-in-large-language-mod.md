---
layout: default
title: Hey, That's My Data! Label-Only Dataset Inference in Large Language Models
---

# Hey, That's My Data! Label-Only Dataset Inference in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06057" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06057v1</a>
  <a href="https://arxiv.org/pdf/2506.06057.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06057v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06057v1', 'Hey, That\'s My Data! Label-Only Dataset Inference in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chen Xiong, Zihao Wang, Rui Zhu, Tsung-Yi Ho, Pin-Yu Chen, Jingwei Xiong, Haixu Tang, Lucila Ohno-Machado

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCatShiftä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ•°æ®æ¨æ–­é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ¨æ–­` `ç¾éš¾æ€§é—å¿˜` `ç‰ˆæƒä¿æŠ¤` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ•°æ®é›†æ¨æ–­æ–¹æ³•ä¾èµ–äºæ¨¡å‹å†…éƒ¨çš„æ—¥å¿—æ¦‚ç‡ï¼Œå¯¼è‡´åœ¨è®¸å¤šæƒ…å†µä¸‹æ— æ³•æœ‰æ•ˆæ£€æµ‹å¯ç–‘æ•°æ®é›†ã€‚
2. CatShiftæ¡†æ¶åˆ©ç”¨ç¾éš¾æ€§é—å¿˜çš„ç‰¹æ€§ï¼Œé€šè¿‡æ¯”è¾ƒæ¨¡å‹è¾“å‡ºçš„å˜åŒ–æ¥åˆ¤æ–­æ•°æ®é›†çš„æˆå‘˜èµ„æ ¼ï¼Œé¿å…äº†å¯¹å†…éƒ¨ä¿¡å·çš„ä¾èµ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCatShiftåœ¨å¼€æ”¾æºä»£ç å’ŒAPIåŸºç¡€çš„LLMsä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ•°æ®é›†æˆå‘˜èµ„æ ¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶å¯¹å¤§è§„æ¨¡ã€å¸¸å¸¸æ˜¯ä¸“æœ‰æ•°æ®é›†çš„ä¾èµ–å¸¦æ¥äº†ç‰ˆæƒä¾µçŠ¯å’Œè´¢åŠ¡æŸå¤±çš„é£é™©ã€‚ç°æœ‰çš„æ•°æ®é›†æ¨æ–­æ–¹æ³•é€šå¸¸ä¾èµ–äºæ—¥å¿—æ¦‚ç‡æ¥æ£€æµ‹å¯ç–‘çš„è®­ç»ƒææ–™ï¼Œä½†è®¸å¤šé¢†å…ˆçš„LLMså·²å¼€å§‹éšç’è¿™äº›ä¿¡å·ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†CatShiftï¼Œä¸€ä¸ªåŸºäºæ ‡ç­¾çš„æ•°æ®é›†æ¨æ–­æ¡†æ¶ï¼Œåˆ©ç”¨ç¾éš¾æ€§é—å¿˜çš„ç‰¹æ€§æ¥è¯†åˆ«æ•°æ®é›†æˆå‘˜èµ„æ ¼ã€‚é€šè¿‡æ¯”è¾ƒæ¨¡å‹åœ¨å¯ç–‘æ•°æ®é›†ä¸Šçš„è¾“å‡ºå˜åŒ–ä¸å·²çŸ¥éæˆå‘˜éªŒè¯é›†çš„å˜åŒ–ï¼ŒCatShiftèƒ½å¤Ÿæœ‰æ•ˆåˆ¤æ–­å¯ç–‘æ•°æ®é›†æ˜¯å¦å¯èƒ½æ˜¯æ¨¡å‹åŸå§‹è®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†ã€‚å¤§é‡å®éªŒéªŒè¯äº†CatShiftåœ¨æ— æ³•è®¿é—®æ—¥å¿—çš„ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ºä¿æŠ¤ä¸“æœ‰æ•°æ®æä¾›äº†å¯é çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ•°æ®é›†æ¨æ–­ä¸­é¢ä¸´çš„ç‰ˆæƒé£é™©ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºæ—¥å¿—æ¦‚ç‡ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å¯ç–‘æ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCatShiftæ¡†æ¶åˆ©ç”¨ç¾éš¾æ€§é—å¿˜çš„ç‰¹æ€§ï¼Œé€šè¿‡å¯¹æ¨¡å‹åœ¨å¯ç–‘æ•°æ®é›†ä¸Šçš„è¾“å‡ºå˜åŒ–è¿›è¡Œåˆ†æï¼Œåˆ¤æ–­å…¶æ˜¯å¦ä¸ºæ¨¡å‹åŸå§‹è®­ç»ƒæ•°æ®çš„ä¸€éƒ¨åˆ†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCatShiftçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†è¾“å…¥ã€æ¨¡å‹è¾“å‡ºç›‘æµ‹å’Œç»Ÿè®¡åˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ¨¡å‹åœ¨å¯ç–‘æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œç„¶åæ¯”è¾ƒè¾“å‡ºå˜åŒ–ä¸å·²çŸ¥éæˆå‘˜é›†çš„å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šCatShiftçš„åˆ›æ–°åœ¨äºå…¶ä¸ä¾èµ–äºå†…éƒ¨æ¨¡å‹æ—¥å¿—ï¼Œè€Œæ˜¯é€šè¿‡è¾“å‡ºå˜åŒ–æ¥è¿›è¡Œæ¨æ–­ï¼Œè¿™ä¸€æ–¹æ³•åœ¨ç°æœ‰æŠ€æœ¯ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒCatShifté‡‡ç”¨äº†ç‰¹å®šçš„å¾®è°ƒç­–ç•¥å’Œè¾“å‡ºæ¯”è¾ƒæ–¹æ³•ï¼Œç¡®ä¿èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰åˆ°æ¨¡å‹åœ¨æ¥è§¦å¯ç–‘æ•°æ®é›†åçš„è¾“å‡ºå˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCatShiftåœ¨å¤šç§å¼€æ”¾æºä»£ç å’ŒAPIåŸºç¡€çš„LLMsä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿåœ¨æ— æ³•è®¿é—®æ—¥å¿—çš„æƒ…å†µä¸‹æœ‰æ•ˆè¯†åˆ«æ•°æ®é›†æˆå‘˜èµ„æ ¼ï¼Œæå‡äº†æ•°æ®ä¿æŠ¤çš„å¯é æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¿æŠ¤ä¸“æœ‰æ•°æ®é›†çš„ç‰ˆæƒã€å¢å¼ºæ•°æ®éšç§å®‰å…¨æ€§ä»¥åŠä¸ºæ³•å¾‹åˆè§„æä¾›æŠ€æœ¯æ”¯æŒã€‚éšç€å¤§è¯­è¨€æ¨¡å‹çš„å¹¿æ³›åº”ç”¨ï¼ŒCatShiftèƒ½å¤Ÿä¸ºä¼ä¸šå’Œç ”ç©¶æœºæ„æä¾›æœ‰æ•ˆçš„å·¥å…·ï¼Œä»¥é˜²æ­¢æ•°æ®æ³„éœ²å’Œç‰ˆæƒä¾µçŠ¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have revolutionized Natural Language Processing by excelling at interpreting, reasoning about, and generating human language. However, their reliance on large-scale, often proprietary datasets poses a critical challenge: unauthorized usage of such data can lead to copyright infringement and significant financial harm. Existing dataset-inference methods typically depend on log probabilities to detect suspicious training material, yet many leading LLMs have begun withholding or obfuscating these signals. This reality underscores the pressing need for label-only approaches capable of identifying dataset membership without relying on internal model logits.
>   We address this gap by introducing CatShift, a label-only dataset-inference framework that capitalizes on catastrophic forgetting: the tendency of an LLM to overwrite previously learned knowledge when exposed to new data. If a suspicious dataset was previously seen by the model, fine-tuning on a portion of it triggers a pronounced post-tuning shift in the model's outputs; conversely, truly novel data elicits more modest changes. By comparing the model's output shifts for a suspicious dataset against those for a known non-member validation set, we statistically determine whether the suspicious set is likely to have been part of the model's original training corpus. Extensive experiments on both open-source and API-based LLMs validate CatShift's effectiveness in logit-inaccessible settings, offering a robust and practical solution for safeguarding proprietary data.

