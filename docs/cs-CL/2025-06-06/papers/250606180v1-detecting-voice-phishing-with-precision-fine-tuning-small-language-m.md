---
layout: default
title: Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models
---

# Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06180" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06180v1</a>
  <a href="https://arxiv.org/pdf/2506.06180.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06180v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06180v1', 'Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ju Yong Sim, Seong Hwan Kim

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

**å¤‡æ³¨**: 15 pages, 4 figures, 8 tables, journal submission

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹æé«˜è¯­éŸ³é’“é±¼æ£€æµ‹ç²¾åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³é’“é±¼` `å°å‹è¯­è¨€æ¨¡å‹` `æ¨¡å‹å¾®è°ƒ` `æ€ç»´é“¾æŠ€æœ¯` `å¯¹æŠ—æ€§æµ‹è¯•` `æ•°æ®é›†æ„å»º` `å®‰å…¨æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³é’“é±¼æ£€æµ‹æ–¹æ³•åœ¨åº”å¯¹å¤æ‚åœºæ™¯æ—¶è¡¨ç°ä¸è¶³ï¼Œç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†å’Œé²æ£’æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å¾®è°ƒLlama3æ¨¡å‹ï¼Œç»“åˆVPè¯„ä¼°æ ‡å‡†å’Œæ€ç»´é“¾æŠ€æœ¯ï¼Œæå‡è¯­éŸ³é’“é±¼æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„Llama3-8Bæ¨¡å‹åœ¨å°å‹è¯­è¨€æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ï¼Œä¸”ä¸GPT-4æ¨¡å‹çš„æ€§èƒ½ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å¼€å‘äº†ä¸€ç§è¯­éŸ³é’“é±¼ï¼ˆVPï¼‰æ£€æµ‹å™¨ï¼Œé€šè¿‡å¾®è°ƒå¼€æºå°å‹è¯­è¨€æ¨¡å‹Llama3ã€‚æˆ‘ä»¬åœ¨æç¤ºä¸­æä¾›äº†ç²¾å¿ƒè®¾è®¡çš„VPè¯„ä¼°æ ‡å‡†ï¼Œå¹¶åº”ç”¨äº†æ€ç»´é“¾ï¼ˆCoTï¼‰æŠ€æœ¯ã€‚ä¸ºäº†è¯„ä¼°è¯­è¨€æ¨¡å‹çš„é²æ£’æ€§å¹¶çªå‡ºå…¶æ€§èƒ½å·®å¼‚ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¯¹æŠ—æ€§æµ‹è¯•æ•°æ®é›†ã€‚æ­¤å¤–ï¼Œä¸ºäº†è§£å†³VPè½¬å½•æœ¬çš„ç¼ºä¹ï¼Œæˆ‘ä»¬å‚è€ƒç°æœ‰æˆ–æ–°ç±»å‹çš„VPæŠ€æœ¯åˆ›å»ºäº†è½¬å½•æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åŒ…å«VPè¯„ä¼°æ ‡å‡†çš„æç¤ºå¾®è°ƒçš„Llama3-8Bæ¨¡å‹åœ¨å°å‹è¯­è¨€æ¨¡å‹ä¸­è¡¨ç°æœ€ä½³ï¼Œä¸”ä¸åŸºäºGPT-4çš„VPæ£€æµ‹å™¨ç›¸å½“ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå°†äººç±»ä¸“å®¶çŸ¥è¯†çº³å…¥æç¤ºæ¯”åœ¨å°å‹è¯­è¨€æ¨¡å‹ä¸­ä½¿ç”¨CoTæŠ€æœ¯æ›´ä¸ºæœ‰æ•ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­éŸ³é’“é±¼æ£€æµ‹ä¸­çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸‹çš„è¡¨ç°ä¸ä½³ï¼Œä¸”ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†å’Œæ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¾®è°ƒLlama3æ¨¡å‹ï¼Œç»“åˆäººç±»ä¸“å®¶çŸ¥è¯†å’Œæ€ç»´é“¾æŠ€æœ¯ï¼Œè®¾è®¡å‡ºæ›´æœ‰æ•ˆçš„æ£€æµ‹æç¤ºï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ£€æµ‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹å¾®è°ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ„å»ºå¯¹æŠ—æ€§æµ‹è¯•æ•°æ®é›†ï¼Œç„¶åå¯¹Llama3è¿›è¡Œå¾®è°ƒï¼Œæœ€åé€šè¿‡ä¸åŒæ¡ä»¶ä¸‹çš„å®éªŒè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†äººç±»ä¸“å®¶çŸ¥è¯†èå…¥æç¤ºä¸­ï¼Œè¿™ä¸€æ–¹æ³•æ˜¾è‘—ä¼˜äºå•çº¯ä¾èµ–æ€ç»´é“¾æŠ€æœ¯çš„ä¼ ç»Ÿæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ VPè¯„ä¼°æ ‡å‡†ï¼ŒåŒæ—¶ä¿æŒå¯¹æŠ—æ€§æ•°æ®é›†çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„Llama3-8Bæ¨¡å‹åœ¨åŒ…å«VPè¯„ä¼°æ ‡å‡†çš„æç¤ºä¸‹ï¼Œè¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ï¼Œå‡†ç¡®ç‡æ˜¾è‘—é«˜äºå…¶ä»–å°å‹è¯­è¨€æ¨¡å‹ï¼Œä¸”ä¸GPT-4æ¨¡å‹çš„æ€§èƒ½ç›¸å½“ï¼Œå±•ç¤ºäº†æå‡å¹…åº¦çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå®‰å…¨ã€ç½‘ç»œå®‰å…¨å’Œå®¢æˆ·æœåŠ¡ç­‰è¡Œä¸šï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œé˜²èŒƒè¯­éŸ³é’“é±¼æ”»å‡»ï¼Œä¿æŠ¤ç”¨æˆ·ä¿¡æ¯å®‰å…¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯æ‰©å±•è‡³å…¶ä»–ç±»å‹çš„æ¬ºè¯ˆæ£€æµ‹ï¼Œæé«˜æ•´ä½“å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We develop a voice phishing (VP) detector by fine-tuning Llama3, a representative open-source, small language model (LM). In the prompt, we provide carefully-designed VP evaluation criteria and apply the Chain-of-Thought (CoT) technique. To evaluate the robustness of LMs and highlight differences in their performance, we construct an adversarial test dataset that places the models under challenging conditions. Moreover, to address the lack of VP transcripts, we create transcripts by referencing existing or new types of VP techniques. We compare cases where evaluation criteria are included, the CoT technique is applied, or both are used together. In the experiment, our results show that the Llama3-8B model, fine-tuned with a dataset that includes a prompt with VP evaluation criteria, yields the best performance among small LMs and is comparable to that of a GPT-4-based VP detector. These findings indicate that incorporating human expert knowledge into the prompt is more effective than using the CoT technique for small LMs in VP detection.

