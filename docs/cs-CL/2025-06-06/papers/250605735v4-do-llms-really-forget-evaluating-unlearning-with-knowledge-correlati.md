---
layout: default
title: Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness
---

# Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05735" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05735v4</a>
  <a href="https://arxiv.org/pdf/2506.05735.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05735v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05735v4', 'Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rongzhe Wei, Peizhi Niu, Hans Hao-Hsun Hsu, Ruihan Wu, Haoteng Yin, Mohsen Ghassemi, Yifan Li, Vamsi K. Potluru, Eli Chien, Kamalika Chaudhuri, Olgica Milenkovic, Pan Li

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06 (æ›´æ–°: 2025-10-22)

**å¤‡æ³¨**: NeurIPS Camera-Ready Version. Code available at: https://github.com/Graph-COM/Knowledge_Unlearning

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Graph-COM/Knowledge_Unlearning.git)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçŸ¥è¯†å»å­¦ä¹ è¯„ä¼°æ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹é—å¿˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å»å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `è¯„ä¼°æ¡†æ¶` `æ¨ç†è¯„ä¼°` `ç½®ä¿¡åº¦è¯„åˆ†` `éšæ€§çŸ¥è¯†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å»å­¦ä¹ æ–¹æ³•ä¸»è¦å…³æ³¨æ˜¾å¼åˆ é™¤å­¤ç«‹äº‹å®ï¼Œå¿½è§†äº†çŸ¥è¯†çš„æ½œåœ¨æ¨ç†ä¾èµ–å’Œéç¡®å®šæ€§ç‰¹å¾ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§çŸ¥è¯†å»å­¦ä¹ è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡çŸ¥è¯†å›¾è°±å’Œç½®ä¿¡åº¦åˆ†æ•°æ›´å‡†ç¡®åœ°æ•æ‰çŸ¥è¯†ç»“æ„ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶æä¾›äº†æ›´ä¸¥æ ¼çš„è¯„ä¼°ï¼Œæ­ç¤ºäº†ç°æœ‰ç­–ç•¥é«˜ä¼°å»å­¦ä¹ æ•ˆæœçš„é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœºå™¨å»å­¦ä¹ æŠ€æœ¯æ—¨åœ¨å‡è½»å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„æ„å¤–è®°å¿†ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºæ˜¾å¼åˆ é™¤å­¤ç«‹äº‹å®ï¼Œå¾€å¾€å¿½è§†æ½œåœ¨çš„æ¨ç†ä¾èµ–å…³ç³»å’ŒLLMsä¸­çŸ¥è¯†çš„éç¡®å®šæ€§ç‰¹å¾ã€‚å› æ­¤ï¼Œå‡å®šè¢«é—å¿˜çš„äº‹å®å¯èƒ½é€šè¿‡ç›¸å…³ä¿¡æ¯éšæ€§å­˜åœ¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§çŸ¥è¯†å»å­¦ä¹ è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°†ç›¸å…³äº‹å®ä¸Šä¸‹æ–‡è¡¨ç¤ºä¸ºçŸ¥è¯†å›¾è°±å¹¶é™„åŠ ç½®ä¿¡åº¦åˆ†æ•°ï¼Œæ›´å‡†ç¡®åœ°æ•æ‰ç°å®ä¸–ç•ŒçŸ¥è¯†çš„éšå«ç»“æ„ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§åŸºäºæ¨ç†çš„è¯„ä¼°åè®®ï¼Œåˆ©ç”¨å¼ºå¤§çš„LLMsä½œä¸ºè¯„åˆ¤è€…ï¼Œè¯„ä¼°å»å­¦ä¹ çš„æˆåŠŸç‡ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æä¾›äº†æ›´ç°å®å’Œä¸¥æ ¼çš„å»å­¦ä¹ æ€§èƒ½è¯„ä¼°ï¼Œå¹¶æ­ç¤ºäº†å½“å‰è¯„ä¼°ç­–ç•¥å¾€å¾€é«˜ä¼°äº†å»å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸­çŸ¥è¯†å»å­¦ä¹ çš„è¯„ä¼°é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†çŸ¥è¯†çš„éšæ€§ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åŸºäºçŸ¥è¯†å›¾è°±çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å°†ç›¸å…³äº‹å®ä¸Šä¸‹æ–‡è¡¨ç¤ºä¸ºå›¾è°±ï¼Œå¹¶ç»“åˆç½®ä¿¡åº¦åˆ†æ•°ï¼Œæ¥æ›´å…¨é¢åœ°æ•æ‰çŸ¥è¯†çš„éšå«ç»“æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬çŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—ã€ç½®ä¿¡åº¦è¯„åˆ†æ¨¡å—å’ŒåŸºäºæ¨ç†çš„è¯„ä¼°åè®®ï¼Œåˆ©ç”¨LLMsä½œä¸ºè¯„åˆ¤è€…è¿›è¡ŒçŸ¥è¯†å»å­¦ä¹ çš„æ•ˆæœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥çŸ¥è¯†å›¾è°±å’Œç½®ä¿¡åº¦åˆ†æ•°çš„ç»“åˆï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ çŸ¥è¯†çš„éšæ€§ç»“æ„ï¼Œä¸ç°æœ‰æ–¹æ³•çš„æ˜¾å¼åˆ é™¤ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯­ä»¥å¼•å¯¼LLMsè¿›è¡Œæ¨ç†ï¼Œå¹¶é€šè¿‡ä¸äººç±»è¯„ä¼°çš„æ ¡å‡†æ¥ç¡®ä¿è¯„åˆ¤çš„å¯é æ€§å’Œç¨³å®šæ€§ã€‚å®éªŒä¸­æ„å»ºäº†æ–°çš„åŸºå‡†æ•°æ®é›†ä»¥éªŒè¯æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„è¯„ä¼°æ¡†æ¶åœ¨å»å­¦ä¹ æ€§èƒ½è¯„ä¼°ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´çœŸå®åœ°åæ˜ æ¨¡å‹çš„é—å¿˜æ•ˆæœã€‚å…·ä½“è€Œè¨€ï¼Œè¯„ä¼°ç»“æœæ˜¾ç¤ºå½“å‰ç­–ç•¥é«˜ä¼°äº†å»å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼Œæä¾›äº†æ›´ä¸ºä¸¥è°¨çš„è¯„ä¼°æ ‡å‡†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠæ•æ„Ÿä¿¡æ¯çš„åœºæ™¯ä¸­ã€‚é€šè¿‡æ”¹è¿›çš„å»å­¦ä¹ è¯„ä¼°æ¡†æ¶ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°ç®¡ç†å’Œæ§åˆ¶æ¨¡å‹çš„çŸ¥è¯†è®°å¿†ï¼Œæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯ä¿¡åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Machine unlearning techniques aim to mitigate unintended memorization in large language models (LLMs). However, existing approaches predominantly focus on the explicit removal of isolated facts, often overlooking latent inferential dependencies and the non-deterministic nature of knowledge within LLMs. Consequently, facts presumed forgotten may persist implicitly through correlated information. To address these challenges, we propose a knowledge unlearning evaluation framework that more accurately captures the implicit structure of real-world knowledge by representing relevant factual contexts as knowledge graphs with associated confidence scores. We further develop an inference-based evaluation protocol leveraging powerful LLMs as judges; these judges reason over the extracted knowledge subgraph to determine unlearning success. Our LLM judges utilize carefully designed prompts and are calibrated against human evaluations to ensure their trustworthiness and stability. Extensive experiments on our newly constructed benchmark demonstrate that our framework provides a more realistic and rigorous assessment of unlearning performance. Moreover, our findings reveal that current evaluation strategies tend to overestimate unlearning effectiveness. Our code is publicly available at https://github.com/Graph-COM/Knowledge_Unlearning.git.

