---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-06-06
---

# cs.CLï¼ˆ2025-06-06ï¼‰

ğŸ“Š å…± **46** ç¯‡è®ºæ–‡
 | ğŸ”— **11** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (37 ğŸ”—10)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (37 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250606406v2-smar-soft-modality-aware-routing-strategy-for-moe-based-multimodal-l.html">SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities</a></td>
  <td>æå‡ºSMARä»¥è§£å†³å¤šæ¨¡æ€MoEæ¨¡å‹è¯­è¨€èƒ½åŠ›ä¸‹é™é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06406v2" data-paper-url="./papers/250606406v2-smar-soft-modality-aware-routing-strategy-for-moe-based-multimodal-l.html" onclick="toggleFavorite(this, '2506.06406v2', 'SMAR: Soft Modality-Aware Routing Strategy for MoE-based Multimodal Large Language Models Preserving Language Capabilities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250606008v1-token-signature-predicting-chain-of-thought-gains-with-token-decodin.html">Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models</a></td>
  <td>æå‡ºåŠ¨æ€CoTæ–¹æ³•ä»¥æé«˜å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06008v1" data-paper-url="./papers/250606008v1-token-signature-predicting-chain-of-thought-gains-with-token-decodin.html" onclick="toggleFavorite(this, '2506.06008v1', 'Token Signature: Predicting Chain-of-Thought Gains with Token Decoding Feature in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250606211v1-puzzleworld-a-benchmark-for-multimodal-open-ended-reasoning-in-puzzl.html">PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts</a></td>
  <td>æå‡ºPuzzleWorldåŸºå‡†ä»¥è§£å†³å¤šæ¨¡æ€å¼€æ”¾å¼æ¨ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06211v1" data-paper-url="./papers/250606211v1-puzzleworld-a-benchmark-for-multimodal-open-ended-reasoning-in-puzzl.html" onclick="toggleFavorite(this, '2506.06211v1', 'PuzzleWorld: A Benchmark for Multimodal, Open-Ended Reasoning in Puzzlehunts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250606034v1-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimoda.html">MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?</a></td>
  <td>æå‡ºMATP-BENCHä»¥è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨å®šç†è¯æ˜ä¸­çš„èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06034v1" data-paper-url="./papers/250606034v1-matp-bench-can-mllm-be-a-good-automated-theorem-prover-for-multimoda.html" onclick="toggleFavorite(this, '2506.06034v1', 'MATP-BENCH: Can MLLM Be a Good Automated Theorem Prover for Multimodal Problems?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250606561v4-lamp-cap-personalized-figure-caption-generation-with-multimodal-figu.html">LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles</a></td>
  <td>æå‡ºLaMP-Capä»¥è§£å†³ä¸ªæ€§åŒ–å›¾å½¢æ ‡é¢˜ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06561v4" data-paper-url="./papers/250606561v4-lamp-cap-personalized-figure-caption-generation-with-multimodal-figu.html" onclick="toggleFavorite(this, '2506.06561v4', 'LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250605725v1-large-language-models-are-good-relational-learners.html">Large Language Models are Good Relational Learners</a></td>
  <td>æå‡ºRel-LLMä»¥è§£å†³å…³ç³»æ·±åº¦å­¦ä¹ ä¸­çš„ç»“æ„åŒ–æ•°æ®å¤„ç†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05725v1" data-paper-url="./papers/250605725v1-large-language-models-are-good-relational-learners.html" onclick="toggleFavorite(this, '2506.05725v1', 'Large Language Models are Good Relational Learners')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250606539v1-beyond-facts-evaluating-intent-hallucination-in-large-language-model.html">Beyond Facts: Evaluating Intent Hallucination in Large Language Models</a></td>
  <td>æå‡ºFAITHQAåŸºå‡†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æ„å›¾å¹»è§‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06539v1" data-paper-url="./papers/250606539v1-beyond-facts-evaluating-intent-hallucination-in-large-language-model.html" onclick="toggleFavorite(this, '2506.06539v1', 'Beyond Facts: Evaluating Intent Hallucination in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250611104v1-dam-dynamic-attention-mask-for-long-context-large-language-model-inf.html">DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration</a></td>
  <td>æå‡ºåŠ¨æ€æ³¨æ„åŠ›æ©ç ä»¥åŠ é€Ÿé•¿ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11104v1" data-paper-url="./papers/250611104v1-dam-dynamic-attention-mask-for-long-context-large-language-model-inf.html" onclick="toggleFavorite(this, '2506.11104v1', 'DAM: Dynamic Attention Mask for Long-Context Large Language Model Inference Acceleration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250611103v1-you-only-fine-tune-once-many-shot-in-context-fine-tuning-for-large-l.html">You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model</a></td>
  <td>æå‡ºManyICLä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒæ•ˆç‡ä½ä¸‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11103v1" data-paper-url="./papers/250611103v1-you-only-fine-tune-once-many-shot-in-context-fine-tuning-for-large-l.html" onclick="toggleFavorite(this, '2506.11103v1', 'You Only Fine-tune Once: Many-Shot In-Context Fine-Tuning for Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250606060v1-simple-yet-effective-extracting-private-data-across-clients-in-feder.html">Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models</a></td>
  <td>æå‡ºç®€å•æœ‰æ•ˆçš„æå–æ”»å‡»ç®—æ³•ä»¥è§£å†³è”é‚¦å¾®è°ƒä¸­çš„éšç§æ•°æ®é£é™©</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06060v1" data-paper-url="./papers/250606060v1-simple-yet-effective-extracting-private-data-across-clients-in-feder.html" onclick="toggleFavorite(this, '2506.06060v1', 'Simple Yet Effective: Extracting Private Data Across Clients in Federated Fine-Tuning of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250606057v1-hey-thats-my-data-label-only-dataset-inference-in-large-language-mod.html">Hey, That's My Data! Label-Only Dataset Inference in Large Language Models</a></td>
  <td>æå‡ºCatShiftä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ•°æ®æ¨æ–­é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06057v1" data-paper-url="./papers/250606057v1-hey-thats-my-data-label-only-dataset-inference-in-large-language-mod.html" onclick="toggleFavorite(this, '2506.06057v1', 'Hey, That&#39;s My Data! Label-Only Dataset Inference in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250605970v1-lets-put-ourselves-in-sallys-shoes-shoes-of-others-prefixing-improve.html">Let's Put Ourselves in Sally's Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models</a></td>
  <td>æå‡ºShoes-of-Otherså‰ç¼€æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¿ƒæ™ºç†è®ºèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05970v1" data-paper-url="./papers/250605970v1-lets-put-ourselves-in-sallys-shoes-shoes-of-others-prefixing-improve.html" onclick="toggleFavorite(this, '2506.05970v1', 'Let&#39;s Put Ourselves in Sally&#39;s Shoes: Shoes-of-Others Prefixing Improves Theory of Mind in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250605936v1-dynamicmind-a-tri-mode-thinking-system-for-large-language-models.html">DynamicMind: A Tri-Mode Thinking System for Large Language Models</a></td>
  <td>æå‡ºDynamicMindä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åŠ¨æ€æ¨ç†æ·±åº¦ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05936v1" data-paper-url="./papers/250605936v1-dynamicmind-a-tri-mode-thinking-system-for-large-language-models.html" onclick="toggleFavorite(this, '2506.05936v1', 'DynamicMind: A Tri-Mode Thinking System for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250605928v1-moa-heterogeneous-mixture-of-adapters-for-parameter-efficient-fine-t.html">MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models</a></td>
  <td>æå‡ºå¼‚æ„é€‚é…å™¨æ··åˆæ¨¡å‹ä»¥è§£å†³å‚æ•°é«˜æ•ˆå¾®è°ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05928v1" data-paper-url="./papers/250605928v1-moa-heterogeneous-mixture-of-adapters-for-parameter-efficient-fine-t.html" onclick="toggleFavorite(this, '2506.05928v1', 'MoA: Heterogeneous Mixture of Adapters for Parameter-Efficient Fine-Tuning of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250605700v1-rkefino1-a-regulation-knowledge-enhanced-large-language-model.html">RKEFino1: A Regulation Knowledge-Enhanced Large Language Model</a></td>
  <td>æå‡ºRKEFino1ä»¥è§£å†³æ•°å­—ç›‘ç®¡æŠ¥å‘Šä¸­çš„åˆè§„æ€§æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05700v1" data-paper-url="./papers/250605700v1-rkefino1-a-regulation-knowledge-enhanced-large-language-model.html" onclick="toggleFavorite(this, '2506.05700v1', 'RKEFino1: A Regulation Knowledge-Enhanced Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250606033v1-large-language-models-are-demonstration-pre-selectors-for-themselves.html">Large Language Models are Demonstration Pre-Selectors for Themselves</a></td>
  <td>æå‡ºFEEDERæ¡†æ¶ä»¥æé«˜å¤§è¯­è¨€æ¨¡å‹çš„ç¤ºä¾‹é€‰æ‹©æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06033v1" data-paper-url="./papers/250606033v1-large-language-models-are-demonstration-pre-selectors-for-themselves.html" onclick="toggleFavorite(this, '2506.06033v1', 'Large Language Models are Demonstration Pre-Selectors for Themselves')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250702870v1-lokis-dance-of-illusions-a-comprehensive-survey-of-hallucination-in-.html">Loki's Dance of Illusions: A Comprehensive Survey of Hallucination in Large Language Models</a></td>
  <td>ç³»ç»Ÿåˆ†ç±»ä¸åˆ†æå¤§è¯­è¨€æ¨¡å‹å¹»è§‰é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.02870v1" data-paper-url="./papers/250702870v1-lokis-dance-of-illusions-a-comprehensive-survey-of-hallucination-in-.html" onclick="toggleFavorite(this, '2507.02870v1', 'Loki&#39;s Dance of Illusions: A Comprehensive Survey of Hallucination in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250605950v1-elementary-math-word-problem-generation-using-large-language-models.html">Elementary Math Word Problem Generation using Large Language Models</a></td>
  <td>åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ•°å­¦æ–‡å­—é¢˜ç”Ÿæˆç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05950v1" data-paper-url="./papers/250605950v1-elementary-math-word-problem-generation-using-large-language-models.html" onclick="toggleFavorite(this, '2506.05950v1', 'Elementary Math Word Problem Generation using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250605675v2-zero-shot-event-causality-identification-via-multi-source-evidence-f.html">Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models</a></td>
  <td>æå‡ºMEFAæ¡†æ¶ä»¥è§£å†³äº‹ä»¶å› æœå…³ç³»è¯†åˆ«ä¸­çš„æ•°æ®ä¾èµ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05675v2" data-paper-url="./papers/250605675v2-zero-shot-event-causality-identification-via-multi-source-evidence-f.html" onclick="toggleFavorite(this, '2506.05675v2', 'Zero-Shot Event Causality Identification via Multi-source Evidence Fuzzy Aggregation with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250606401v1-direct-behavior-optimization-unlocking-the-potential-of-lightweight-.html">Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs</a></td>
  <td>æå‡ºDeBoPä»¥ä¼˜åŒ–è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹çš„è¡Œä¸º</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06401v1" data-paper-url="./papers/250606401v1-direct-behavior-optimization-unlocking-the-potential-of-lightweight-.html" onclick="toggleFavorite(this, '2506.06401v1', 'Direct Behavior Optimization: Unlocking the Potential of Lightweight LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250606522v3-fixing-it-in-post-a-comparative-study-of-llm-post-training-data-qual.html">Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance</a></td>
  <td>æå‡ºTuluTalkæ•°æ®é›†ä»¥æå‡LLMåè®­ç»ƒæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06522v3" data-paper-url="./papers/250606522v3-fixing-it-in-post-a-comparative-study-of-llm-post-training-data-qual.html" onclick="toggleFavorite(this, '2506.06522v3', 'Fixing It in Post: A Comparative Study of LLM Post-Training Data Quality and Model Performance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250606214v1-can-theoretical-physics-research-benefit-from-language-agents.html">Can Theoretical Physics Research Benefit from Language Agents?</a></td>
  <td>æå‡ºè¯­è¨€ä»£ç†ä»¥åŠ é€Ÿç†è®ºç‰©ç†ç ”ç©¶çš„è¿›å±•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06214v1" data-paper-url="./papers/250606214v1-can-theoretical-physics-research-benefit-from-language-agents.html" onclick="toggleFavorite(this, '2506.06214v1', 'Can Theoretical Physics Research Benefit from Language Agents?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250605947v1-intentionesc-an-intention-centered-framework-for-enhancing-emotional.html">IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems</a></td>
  <td>æå‡ºIntentionESCæ¡†æ¶ä»¥å¢å¼ºå¯¹è¯ç³»ç»Ÿä¸­çš„æƒ…æ„Ÿæ”¯æŒ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05947v1" data-paper-url="./papers/250605947v1-intentionesc-an-intention-centered-framework-for-enhancing-emotional.html" onclick="toggleFavorite(this, '2506.05947v1', 'IntentionESC: An Intention-Centered Framework for Enhancing Emotional Support in Dialogue Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250605766v1-biomol-mqa-a-multi-modal-question-answering-dataset-for-llm-reasonin.html">BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions</a></td>
  <td>æå‡ºBioMol-MQAä»¥è§£å†³å¤šæ¨¡æ€ç”Ÿç‰©åˆ†å­äº¤äº’é—®ç­”é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05766v1" data-paper-url="./papers/250605766v1-biomol-mqa-a-multi-modal-question-answering-dataset-for-llm-reasonin.html" onclick="toggleFavorite(this, '2506.05766v1', 'BioMol-MQA: A Multi-Modal Question Answering Dataset For LLM Reasoning Over Bio-Molecular Interactions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250606446v1-canonical-autoregressive-generation.html">Canonical Autoregressive Generation</a></td>
  <td>æå‡ºè§„èŒƒè‡ªå›å½’ç”Ÿæˆæ–¹æ³•ä»¥è§£å†³è¯­è¨€æ¨¡å‹ç”Ÿæˆéè§„èŒƒåºåˆ—é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06446v1" data-paper-url="./papers/250606446v1-canonical-autoregressive-generation.html" onclick="toggleFavorite(this, '2506.06446v1', 'Canonical Autoregressive Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250606069v1-zero-shot-detection-of-llm-generated-code-via-approximated-task-cond.html">Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning</a></td>
  <td>æå‡ºåŸºäºä»»åŠ¡æ¡ä»¶è¿‘ä¼¼çš„é›¶-shotæ£€æµ‹æ–¹æ³•ä»¥è¯†åˆ«LLMç”Ÿæˆä»£ç </td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06069v1" data-paper-url="./papers/250606069v1-zero-shot-detection-of-llm-generated-code-via-approximated-task-cond.html" onclick="toggleFavorite(this, '2506.06069v1', 'Zero-Shot Detection of LLM-Generated Code via Approximated Task Conditioning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250606404v1-unintended-harms-of-value-aligned-llms-psychological-and-empirical-i.html">Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights</a></td>
  <td>è¯†åˆ«ä»·å€¼å¯¹é½å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨é£é™©ä»¥æå‡å®‰å…¨æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06404v1" data-paper-url="./papers/250606404v1-unintended-harms-of-value-aligned-llms-psychological-and-empirical-i.html" onclick="toggleFavorite(this, '2506.06404v1', 'Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250605735v4-do-llms-really-forget-evaluating-unlearning-with-knowledge-correlati.html">Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness</a></td>
  <td>æå‡ºçŸ¥è¯†å»å­¦ä¹ è¯„ä¼°æ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹é—å¿˜é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05735v4" data-paper-url="./papers/250605735v4-do-llms-really-forget-evaluating-unlearning-with-knowledge-correlati.html" onclick="toggleFavorite(this, '2506.05735v4', 'Do LLMs Really Forget? Evaluating Unlearning with Knowledge Correlation and Confidence Awareness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250606020v1-when-to-trust-context-self-reflective-debates-for-context-reliabilit.html">When to Trust Context: Self-Reflective Debates for Context Reliability</a></td>
  <td>æå‡ºè‡ªåè¾©è®ºæ¡†æ¶ä»¥æå‡ä¸Šä¸‹æ–‡å¯é æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06020v1" data-paper-url="./papers/250606020v1-when-to-trust-context-self-reflective-debates-for-context-reliabilit.html" onclick="toggleFavorite(this, '2506.06020v1', 'When to Trust Context: Self-Reflective Debates for Context Reliability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250605767v1-dotsllm1-technical-report.html">dots.llm1 Technical Report</a></td>
  <td>æå‡ºdots.llm1ä»¥é«˜æ•ˆæ¿€æ´»è¯­è¨€æ¨¡å‹å‚æ•°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05767v1" data-paper-url="./papers/250605767v1-dotsllm1-technical-report.html" onclick="toggleFavorite(this, '2506.05767v1', 'dots.llm1 Technical Report')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250606500v1-improving-llm-powered-eda-assistants-with-raft.html">Improving LLM-Powered EDA Assistants with RAFT</a></td>
  <td>æå‡ºRAFTä»¥æå‡LLMåœ¨EDAä»»åŠ¡ä¸­çš„è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06500v1" data-paper-url="./papers/250606500v1-improving-llm-powered-eda-assistants-with-raft.html" onclick="toggleFavorite(this, '2506.06500v1', 'Improving LLM-Powered EDA Assistants with RAFT')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/250606240v1-bridging-external-and-parametric-knowledge-mitigating-hallucination-.html">Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge</a></td>
  <td>æå‡ºDSSP-RAGä»¥è§£å†³LLMsçš„å¹»è§‰é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06240v1" data-paper-url="./papers/250606240v1-bridging-external-and-parametric-knowledge-mitigating-hallucination-.html" onclick="toggleFavorite(this, '2506.06240v1', 'Bridging External and Parametric Knowledge: Mitigating Hallucination of LLMs with Shared-Private Semantic Synergy in Dual-Stream Knowledge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250606180v1-detecting-voice-phishing-with-precision-fine-tuning-small-language-m.html">Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models</a></td>
  <td>é€šè¿‡å¾®è°ƒå°å‹è¯­è¨€æ¨¡å‹æé«˜è¯­éŸ³é’“é±¼æ£€æµ‹ç²¾åº¦</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06180v1" data-paper-url="./papers/250606180v1-detecting-voice-phishing-with-precision-fine-tuning-small-language-m.html" onclick="toggleFavorite(this, '2506.06180v1', 'Detecting Voice Phishing with Precision: Fine-Tuning Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250606157v2-masked-language-models-are-good-heterogeneous-graph-generalizers.html">Masked Language Models are Good Heterogeneous Graph Generalizers</a></td>
  <td>æå‡ºMLM4HGä»¥è§£å†³å¼‚æ„å›¾æ³›åŒ–èƒ½åŠ›ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06157v2" data-paper-url="./papers/250606157v2-masked-language-models-are-good-heterogeneous-graph-generalizers.html" onclick="toggleFavorite(this, '2506.06157v2', 'Masked Language Models are Good Heterogeneous Graph Generalizers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>35</td>
  <td><a href="./papers/250606133v1-lets-confer-a-dataset-for-evaluating-natural-language-inference-mode.html">Let's CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition</a></td>
  <td>æå‡ºCONFERæ•°æ®é›†ä»¥è¯„ä¼°NLIæ¨¡å‹åœ¨æ¡ä»¶æ¨ç†ä¸­çš„è¡¨ç°</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06133v1" data-paper-url="./papers/250606133v1-lets-confer-a-dataset-for-evaluating-natural-language-inference-mode.html" onclick="toggleFavorite(this, '2506.06133v1', 'Let&#39;s CONFER: A Dataset for Evaluating Natural Language Inference Models on CONditional InFERence and Presupposition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>36</td>
  <td><a href="./papers/250606017v2-agentswift-efficient-llm-agent-design-via-value-guided-hierarchical-.html">AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search</a></td>
  <td>æå‡ºAgentSwiftä»¥è§£å†³è‡ªåŠ¨åŒ–ä»£ç†è®¾è®¡ä¸­çš„é«˜æˆæœ¬ä¸ä½æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06017v2" data-paper-url="./papers/250606017v2-agentswift-efficient-llm-agent-design-via-value-guided-hierarchical-.html" onclick="toggleFavorite(this, '2506.06017v2', 'AgentSwift: Efficient LLM Agent Design via Value-guided Hierarchical Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>37</td>
  <td><a href="./papers/250605690v2-when-to-use-graphs-in-rag-a-comprehensive-analysis-for-graph-retriev.html">When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation</a></td>
  <td>æå‡ºGraphRAG-Benchä»¥è¯„ä¼°å›¾æ£€ç´¢å¢å¼ºç”Ÿæˆçš„æœ‰æ•ˆæ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05690v2" data-paper-url="./papers/250605690v2-when-to-use-graphs-in-rag-a-comprehensive-analysis-for-graph-retriev.html" onclick="toggleFavorite(this, '2506.05690v2', 'When to use Graphs in RAG: A Comprehensive Analysis for Graph Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>38</td>
  <td><a href="./papers/250605850v2-cross-lingual-collapse-how-language-centric-foundation-models-shape-.html">Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models</a></td>
  <td>æå‡ºè·¨è¯­è¨€å´©æºƒç°è±¡ä»¥æ­ç¤ºå¤šè¯­è¨€æ¨¡å‹æ¨ç†çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward shaping</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05850v2" data-paper-url="./papers/250605850v2-cross-lingual-collapse-how-language-centric-foundation-models-shape-.html" onclick="toggleFavorite(this, '2506.05850v2', 'Cross-lingual Collapse: How Language-Centric Foundation Models Shape Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>39</td>
  <td><a href="./papers/250605695v1-being-strong-progressively-enhancing-knowledge-distillation-of-large.html">Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework</a></td>
  <td>æå‡ºæ¸è¿›å¼çŸ¥è¯†è’¸é¦æ¡†æ¶ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">curriculum learning</span> <span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05695v1" data-paper-url="./papers/250605695v1-being-strong-progressively-enhancing-knowledge-distillation-of-large.html" onclick="toggleFavorite(this, '2506.05695v1', 'Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>40</td>
  <td><a href="./papers/250605901v2-route-and-reason-scaling-large-language-model-reasoning-with-reinfor.html">Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router</a></td>
  <td>æå‡ºR2-Reasonerä»¥è§£å†³å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05901v2" data-paper-url="./papers/250605901v2-route-and-reason-scaling-large-language-model-reasoning-with-reinfor.html" onclick="toggleFavorite(this, '2506.05901v2', 'Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>41</td>
  <td><a href="./papers/250606009v1-unlocking-recursive-thinking-of-llms-alignment-via-refinement.html">Unlocking Recursive Thinking of LLMs: Alignment via Refinement</a></td>
  <td>æå‡ºAvRæ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„é€’å½’æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06009v1" data-paper-url="./papers/250606009v1-unlocking-recursive-thinking-of-llms-alignment-via-refinement.html" onclick="toggleFavorite(this, '2506.06009v1', 'Unlocking Recursive Thinking of LLMs: Alignment via Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>42</td>
  <td><a href="./papers/250605760v1-writing-rl-advancing-long-form-writing-via-adaptive-curriculum-reinf.html">Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning</a></td>
  <td>æå‡ºWriting-RLæ¡†æ¶ä»¥æå‡é•¿ç¯‡å†™ä½œèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05760v1" data-paper-url="./papers/250605760v1-writing-rl-advancing-long-form-writing-via-adaptive-curriculum-reinf.html" onclick="toggleFavorite(this, '2506.05760v1', 'Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>43</td>
  <td><a href="./papers/250606266v3-cartridges-lightweight-and-general-purpose-long-context-representati.html">Cartridges: Lightweight and general-purpose long context representations via self-study</a></td>
  <td>æå‡ºCartridgesä»¥è§£å†³é•¿æ–‡æœ¬ä¸Šä¸‹æ–‡å¤„ç†çš„é«˜æˆæœ¬é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06266v3" data-paper-url="./papers/250606266v3-cartridges-lightweight-and-general-purpose-long-context-representati.html" onclick="toggleFavorite(this, '2506.06266v3', 'Cartridges: Lightweight and general-purpose long context representations via self-study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>44</td>
  <td><a href="./papers/250606175v1-does-it-run-and-is-that-enough-revisiting-text-to-chart-generation-w.html">Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach</a></td>
  <td>æå‡ºå¤šä»£ç†æ–¹æ³•ä»¥é™ä½æ–‡æœ¬åˆ°å›¾è¡¨ç”Ÿæˆä¸­çš„æ‰§è¡Œé”™è¯¯ç‡</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06175v1" data-paper-url="./papers/250606175v1-does-it-run-and-is-that-enough-revisiting-text-to-chart-generation-w.html" onclick="toggleFavorite(this, '2506.06175v1', 'Does It Run and Is That Enough? Revisiting Text-to-Chart Generation with a Multi-Agent Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>45</td>
  <td><a href="./papers/250606093v1-reinforcing-code-generation-improving-text-to-sql-with-execution-bas.html">Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning</a></td>
  <td>é€šè¿‡æ‰§è¡Œåé¦ˆå¼ºåŒ–ä»£ç ç”Ÿæˆä»¥æå‡æ–‡æœ¬åˆ°SQLçš„è½¬æ¢èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.06093v1" data-paper-url="./papers/250606093v1-reinforcing-code-generation-improving-text-to-sql-with-execution-bas.html" onclick="toggleFavorite(this, '2506.06093v1', 'Reinforcing Code Generation: Improving Text-to-SQL with Execution-Based Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>46</td>
  <td><a href="./papers/250605817v1-codecontests-high-quality-test-case-generation-for-competitive-progr.html">CodeContests+: High-Quality Test Case Generation for Competitive Programming</a></td>
  <td>æå‡ºCodeContests+ä»¥è§£å†³ç«äº‰ç¼–ç¨‹æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.05817v1" data-paper-url="./papers/250605817v1-codecontests-high-quality-test-case-generation-for-competitive-progr.html" onclick="toggleFavorite(this, '2506.05817v1', 'CodeContests+: High-Quality Test Case Generation for Competitive Programming')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)