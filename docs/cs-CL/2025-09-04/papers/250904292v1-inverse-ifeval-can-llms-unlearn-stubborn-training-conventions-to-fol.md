---
layout: default
title: Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?
---

# Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04292" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04292v1</a>
  <a href="https://arxiv.org/pdf/2509.04292.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04292v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04292v1', 'Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qinyan Zhang, Xinping Lei, Ruijie Miao, Yu Fu, Haojie Fan, Le Chang, Jiafan Hou, Dingling Zhang, Zhongfei Hou, Ziqiang Yang, Changxin Pu, Fei Hu, Jingkai Liu, Mengyun Liu, Yang Liu, Xiang Gao, Jiaheng Liu, Tong Yang, Zaiyuan Wang, Ge Zhang, Wenhao Huang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInverse IFEvalåŸºå‡†ï¼Œè¯„ä¼°LLMå…‹æœè®­ç»ƒåå·®å¹¶éµå¾ªåå¸¸æŒ‡ä»¤çš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æŒ‡ä»¤éµå¾ª` `è®¤çŸ¥æƒ¯æ€§` `å¯¹æŠ—æ€§æŒ‡ä»¤` `è¯„ä¼°åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨éµå¾ªä¸è®­ç»ƒæ•°æ®ç›¸æ‚–çš„æŒ‡ä»¤æ—¶å­˜åœ¨å›°éš¾ï¼Œè¡¨ç°å‡ºè®¤çŸ¥æƒ¯æ€§ã€‚
2. æå‡ºInverse IFEvalåŸºå‡†ï¼Œé€šè¿‡å¯¹æŠ—æ€§æŒ‡ä»¤è¯„ä¼°LLMå…‹æœè®­ç»ƒåå·®çš„èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰LLMåœ¨Inverse IFEvalä¸Šè¡¨ç°ä¸ä½³ï¼Œçªå‡ºäº†æœªæ¥å¯¹é½å·¥ä½œçš„é‡ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å„ç§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å¸¸å¸¸è¡¨ç°å‡ºè®¤çŸ¥æƒ¯æ€§ï¼Œéš¾ä»¥éµå¾ªä¸ç›‘ç£å¾®è°ƒ(SFT)æœŸé—´å­¦ä¹ åˆ°çš„æ ‡å‡†åŒ–æ¨¡å¼ç›¸å†²çªçš„æŒ‡ä»¤ã€‚ä¸ºäº†è¯„ä¼°è¿™ç§å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†Inverse IFEvalï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºå‡†ï¼Œç”¨äºè¡¡é‡æ¨¡å‹è¿åç›´è§‰çš„èƒ½åŠ›â€”â€”å³è¦†ç›–è®­ç»ƒå¼•èµ·çš„åå·®å¹¶éµå®ˆå¯¹æŠ—æ€§æŒ‡ä»¤çš„èƒ½åŠ›ã€‚Inverse IFEvalå¼•å…¥äº†å…«ç§æ­¤ç±»æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬é—®é¢˜çº æ­£ã€æ•…æ„æ–‡æœ¬ç¼ºé™·ã€æ— æ³¨é‡Šä»£ç å’Œåäº‹å®å›ç­”ã€‚é€šè¿‡äººæœºåä½œæµç¨‹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«23ä¸ªé¢†åŸŸä¸­1012ä¸ªé«˜è´¨é‡ä¸­è‹±æ–‡é—®é¢˜çš„æ•°æ®é›†ï¼Œå¹¶åœ¨ä¼˜åŒ–çš„LLM-as-a-Judgeæ¡†æ¶ä¸‹è¿›è¡Œäº†è¯„ä¼°ã€‚å¯¹ç°æœ‰é¢†å…ˆLLMçš„å®éªŒè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„Inverse IFEvalåŸºå‡†çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒï¼Œæœªæ¥çš„å¯¹é½å·¥ä½œä¸ä»…åº”è¿½æ±‚æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§ï¼Œè¿˜åº”è€ƒè™‘åœ¨éå¸¸è§„ç¯å¢ƒä¸‹çš„é€‚åº”æ€§ã€‚æˆ‘ä»¬å¸Œæœ›Inverse IFEvalæ—¢å¯ä»¥ä½œä¸ºè¯Šæ–­å·¥å…·ï¼Œåˆå¯ä»¥ä½œä¸ºå¼€å‘æ–¹æ³•çš„åŸºçŸ³ï¼Œä»¥å‡è½»è®¤çŸ¥æƒ¯æ€§ï¼Œå‡å°‘å¯¹ç‹­éš˜æ¨¡å¼çš„è¿‡åº¦æ‹Ÿåˆï¼Œå¹¶æœ€ç»ˆæé«˜LLMåœ¨å„ç§ä¸å¯é¢„æµ‹çš„ç°å®åœºæ™¯ä¸­çš„æŒ‡ä»¤éµå¾ªå¯é æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é¢å¯¹ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸åŒçš„ã€å…·æœ‰å¯¹æŠ—æ€§çš„æŒ‡ä»¤æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆéµå¾ªçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨LLMçš„æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§ï¼Œè€Œå¿½ç•¥äº†å…¶åœ¨éå¸¸è§„æƒ…å¢ƒä¸‹çš„é€‚åº”èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹å®¹æ˜“å—åˆ°è®­ç»ƒåå·®çš„å½±å“ï¼Œæ— æ³•çµæ´»åº”å¯¹çœŸå®ä¸–ç•Œä¸­å¤æ‚å¤šå˜çš„æŒ‡ä»¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªä¸“é—¨çš„è¯„ä¼°åŸºå‡†ï¼Œå³Inverse IFEvalï¼Œç”¨äºè¡¡é‡LLMå…‹æœè®­ç»ƒåå·®å¹¶éµå¾ªåå¸¸æŒ‡ä»¤çš„èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„å¯¹æŠ—æ€§æŒ‡ä»¤ï¼Œä¾‹å¦‚é—®é¢˜çº æ­£ã€æ•…æ„æ–‡æœ¬ç¼ºé™·ç­‰ï¼Œæ¥è¿«ä½¿LLMæ‰“ç ´å…¶åœ¨ç›‘ç£å¾®è°ƒ(SFT)æœŸé—´å­¦ä¹ åˆ°çš„æ ‡å‡†åŒ–æ¨¡å¼ï¼Œä»è€Œè¯„ä¼°å…¶è®¤çŸ¥çµæ´»æ€§å’ŒæŒ‡ä»¤éµå¾ªçš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šInverse IFEvalçš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **æŒ‘æˆ˜ç±»å‹å®šä¹‰**ï¼šå®šä¹‰å…«ç§ç±»å‹çš„å¯¹æŠ—æ€§æŒ‡ä»¤æŒ‘æˆ˜ï¼Œæ¶µç›–é—®é¢˜çº æ­£ã€æ–‡æœ¬ç¼ºé™·ã€æ— æ³¨é‡Šä»£ç ã€åäº‹å®å›ç­”ç­‰ã€‚
2. **æ•°æ®é›†æ„å»º**ï¼šé€šè¿‡äººæœºåä½œçš„æ–¹å¼ï¼Œé’ˆå¯¹æ¯ç§æŒ‘æˆ˜ç±»å‹ï¼Œæ„å»ºé«˜è´¨é‡çš„ä¸­è‹±æ–‡é—®é¢˜æ•°æ®é›†ï¼Œè¦†ç›–23ä¸ªé¢†åŸŸã€‚
3. **è¯„ä¼°æ¡†æ¶**ï¼šé‡‡ç”¨ä¼˜åŒ–çš„LLM-as-a-Judgeæ¡†æ¶ï¼Œåˆ©ç”¨LLMä½œä¸ºè£åˆ¤ï¼Œè¯„ä¼°æ¨¡å‹åœ¨Inverse IFEvalä¸Šçš„è¡¨ç°ã€‚
4. **å®éªŒåˆ†æ**ï¼šå¯¹ç°æœ‰é¢†å…ˆçš„LLMè¿›è¡Œå®éªŒï¼Œåˆ†æå…¶åœ¨ä¸åŒæŒ‘æˆ˜ç±»å‹ä¸Šçš„è¡¨ç°ï¼Œå¹¶æå‡ºæ”¹è¿›å»ºè®®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†Inverse IFEvalè¿™ä¸€å…¨æ–°çš„è¯„ä¼°åŸºå‡†ï¼Œå®ƒä¸åŒäºä»¥å¾€å…³æ³¨æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§çš„è¯„ä¼°æ–¹æ³•ï¼Œè€Œæ˜¯ä¸“æ³¨äºè¯„ä¼°LLMåœ¨å¯¹æŠ—æ€§æŒ‡ä»¤ä¸‹çš„é€‚åº”èƒ½åŠ›å’Œè®¤çŸ¥çµæ´»æ€§ã€‚è¿™ç§è¯„ä¼°æ–¹å¼èƒ½å¤Ÿæ›´å…¨é¢åœ°åæ˜ LLMåœ¨çœŸå®ä¸–ç•Œå¤æ‚åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹å¯¹é½å·¥ä½œæä¾›æ–°çš„æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šInverse IFEvalçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š
1. **å¯¹æŠ—æ€§æŒ‡ä»¤ç±»å‹**ï¼šç²¾å¿ƒè®¾è®¡çš„å…«ç§å¯¹æŠ—æ€§æŒ‡ä»¤ç±»å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŒ‘æˆ˜LLMçš„è®¤çŸ¥æƒ¯æ€§ã€‚
2. **äººæœºåä½œçš„æ•°æ®é›†æ„å»º**ï¼šä¿è¯æ•°æ®é›†çš„é«˜è´¨é‡å’Œå¤šæ ·æ€§ã€‚
3. **ä¼˜åŒ–çš„LLM-as-a-Judgeæ¡†æ¶**ï¼šç¡®ä¿è¯„ä¼°çš„å®¢è§‚æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰é¢†å…ˆçš„LLMåœ¨Inverse IFEvalåŸºå‡†ä¸Šè¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨é—®é¢˜çº æ­£ã€æ–‡æœ¬ç¼ºé™·å’Œåäº‹å®å›ç­”ç­‰æŒ‘æˆ˜ç±»å‹ä¸Šã€‚è¿™è¡¨æ˜ï¼Œå³ä½¿æ˜¯ç»è¿‡å¤§è§„æ¨¡è®­ç»ƒçš„LLMï¼Œä»ç„¶å­˜åœ¨ä¸¥é‡çš„è®¤çŸ¥æƒ¯æ€§é—®é¢˜ï¼Œéš¾ä»¥æœ‰æ•ˆéµå¾ªå¯¹æŠ—æ€§æŒ‡ä»¤ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†æœªæ¥å¯¹é½å·¥ä½œä¸ä»…è¦å…³æ³¨æµç•…æ€§å’Œäº‹å®æ­£ç¡®æ€§ï¼Œæ›´è¦å…³æ³¨LLMåœ¨éå¸¸è§„ç¯å¢ƒä¸‹çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„å¯é æ€§å’Œé€‚åº”æ€§ï¼Œä¾‹å¦‚åœ¨è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¢æœã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸï¼ŒLLMéœ€è¦èƒ½å¤Ÿç†è§£å¹¶æ‰§è¡Œä¸ç¬¦åˆå¸¸è§„çš„æŒ‡ä»¤ã€‚é€šè¿‡ä½¿ç”¨Inverse IFEvalä½œä¸ºè¯Šæ–­å·¥å…·ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…è¯†åˆ«LLMçš„æ½œåœ¨ç¼ºé™·ï¼Œå¹¶å¼€å‘ç›¸åº”çš„æ”¹è¿›æ–¹æ³•ï¼Œä»è€Œæé«˜LLMåœ¨å¤æ‚å’Œä¸å¯é¢„æµ‹ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) achieve strong performance on diverse tasks but often exhibit cognitive inertia, struggling to follow instructions that conflict with the standardized patterns learned during supervised fine-tuning (SFT). To evaluate this limitation, we propose Inverse IFEval, a benchmark that measures models Counter-intuitive Abilitytheir capacity to override training-induced biases and comply with adversarial instructions. Inverse IFEval introduces eight types of such challenges, including Question Correction, Intentional Textual Flaws, Code without Comments, and Counterfactual Answering. Using a human-in-the-loop pipeline, we construct a dataset of 1012 high-quality Chinese and English questions across 23 domains, evaluated under an optimized LLM-as-a-Judge framework. Experiments on existing leading LLMs demonstrate the necessity of our proposed Inverse IFEval benchmark. Our findings emphasize that future alignment efforts should not only pursue fluency and factual correctness but also account for adaptability under unconventional contexts. We hope that Inverse IFEval serves as both a diagnostic tool and a foundation for developing methods that mitigate cognitive inertia, reduce overfitting to narrow patterns, and ultimately enhance the instruction-following reliability of LLMs in diverse and unpredictable real-world scenarios.

