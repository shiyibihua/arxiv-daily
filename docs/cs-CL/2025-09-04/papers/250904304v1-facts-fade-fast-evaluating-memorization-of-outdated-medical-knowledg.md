---
layout: default
title: Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models
---

# Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04304" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04304v1</a>
  <a href="https://arxiv.org/pdf/2509.04304.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04304v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04304v1', 'Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Juraj Vladika, Mahdi Dhaini, Florian Matthes

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

**å¤‡æ³¨**: Accepted to Findings of EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedRevQAå’ŒMedChangeQAæ•°æ®é›†ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹å¯¹è¿‡æ—¶åŒ»å­¦çŸ¥è¯†çš„è®°å¿†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒ»å­¦çŸ¥è¯†` `çŸ¥è¯†æ—¶æ•ˆæ€§` `é—®ç­”æ•°æ®é›†` `ä¸´åºŠæ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨å—é™äºå…¶å¯¹é™æ€è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œå¯¼è‡´æ¨¡å‹å¯èƒ½è®°å¿†å¹¶è¾“å‡ºè¿‡æ—¶çš„åŒ»å­¦çŸ¥è¯†ã€‚
2. è®ºæ–‡æ ¸å¿ƒåœ¨äºæ„å»ºMedRevQAå’ŒMedChangeQAä¸¤ä¸ªæ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°LLMå¯¹åŒ»å­¦çŸ¥è¯†æ—¶æ•ˆæ€§çš„æŒæ¡ç¨‹åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¤šä¸ªä¸»æµLLMåœ¨æ‰€æ„å»ºçš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¯¹è¿‡æ—¶åŒ»å­¦çŸ¥è¯†çš„ä¾èµ–ï¼Œæ­ç¤ºäº†ç°æœ‰æ¨¡å‹çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸå…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œå¯ä»¥è¾…åŠ©åŒ»å­¦ç ”ç©¶äººå‘˜å’ŒåŒ»ç”Ÿã€‚ç„¶è€Œï¼Œå½“åŒ»å­¦å»ºè®®éšç€æ–°çš„ç ”ç©¶è¿›å±•è€Œä¸æ–­å‘å±•æ—¶ï¼ŒLLMå¯¹é™æ€è®­ç»ƒæ•°æ®çš„ä¾èµ–æ„æˆäº†ä¸€ä¸ªä¸»è¦é£é™©ã€‚å¦‚æœLLMè®°ä½äº†è¿‡æ—¶çš„åŒ»å­¦çŸ¥è¯†ï¼Œå®ƒä»¬å¯èƒ½ä¼šæä¾›æœ‰å®³çš„å»ºè®®æˆ–åœ¨ä¸´åºŠæ¨ç†ä»»åŠ¡ä¸­å¤±è´¥ã€‚ä¸ºäº†ç ”ç©¶è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªæ–°çš„é—®ç­”(QA)æ•°æ®é›†ï¼Œå®ƒä»¬æ¥è‡ªç³»ç»Ÿç»¼è¿°ï¼šMedRevQA(åŒ…å«16,501ä¸ªQAå¯¹ï¼Œæ¶µç›–ä¸€èˆ¬çš„ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†)å’ŒMedChangeQA(åŒ…å«512ä¸ªQAå¯¹çš„å­é›†ï¼Œå…¶ä¸­åŒ»å­¦å…±è¯†éšæ—¶é—´å‘ç”Ÿäº†å˜åŒ–)ã€‚æˆ‘ä»¬å¯¹å…«ä¸ªä¸»æµLLMåœ¨è¿™äº›æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½ä¸€è‡´ä¾èµ–äºè¿‡æ—¶çš„çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜åˆ†æäº†è¿‡æ—¶çš„é¢„è®­ç»ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥çš„å½±å“ï¼Œä»¥è§£é‡Šè¿™ç§ç°è±¡ï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç¼“è§£æ–¹å‘ï¼Œä¸ºå¼€å‘æ›´å…·æ—¶æ•ˆæ€§å’Œå¯é æ€§çš„åŒ»å­¦AIç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒ»ç–—é¢†åŸŸåº”ç”¨æ—¶ï¼Œç”±äºä¾èµ–é™æ€è®­ç»ƒæ•°æ®è€Œå¯¼è‡´çš„è®°å¿†å’Œè¾“å‡ºè¿‡æ—¶åŒ»å­¦çŸ¥è¯†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆè¯„ä¼°å’Œè§£å†³LLMå¯¹åŒ»å­¦çŸ¥è¯†æ—¶æ•ˆæ€§çš„æŒæ¡ç¨‹åº¦ï¼Œå­˜åœ¨æ½œåœ¨çš„è¯¯å¯¼æˆ–å±å®³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸“é—¨çš„é—®ç­”æ•°æ®é›†ï¼Œå³MedRevQAå’ŒMedChangeQAï¼Œæ¥è¯„ä¼°LLMå¯¹åŒ»å­¦çŸ¥è¯†æ—¶æ•ˆæ€§çš„æŒæ¡ç¨‹åº¦ã€‚MedChangeQAç‰¹åˆ«å…³æ³¨åŒ»å­¦å…±è¯†éšæ—¶é—´å‘ç”Ÿå˜åŒ–çš„æƒ…å†µï¼Œä»è€Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¡¡é‡LLMæ˜¯å¦èƒ½å¤ŸåŒºåˆ†æ–°æ—§çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é›†æ„å»ºï¼šä»ç³»ç»Ÿç»¼è¿°ä¸­æå–QAå¯¹ï¼Œæ„å»ºMedRevQAå’ŒMedChangeQAæ•°æ®é›†ã€‚2) æ¨¡å‹è¯„ä¼°ï¼šé€‰æ‹©å¤šä¸ªä¸»æµLLMï¼Œåœ¨æ„å»ºçš„æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚3) ç»“æœåˆ†æï¼šåˆ†æå®éªŒç»“æœï¼Œæ¢è®¨è¿‡æ—¶é¢„è®­ç»ƒæ•°æ®å’Œè®­ç»ƒç­–ç•¥å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚4) æœªæ¥æ–¹å‘ï¼šæå‡ºç¼“è§£æ¨¡å‹ä¾èµ–è¿‡æ—¶çŸ¥è¯†çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†MedRevQAå’ŒMedChangeQAä¸¤ä¸ªæ•°æ®é›†ï¼Œä¸ºè¯„ä¼°LLMåœ¨åŒ»å­¦é¢†åŸŸå¯¹çŸ¥è¯†æ—¶æ•ˆæ€§çš„æŒæ¡ç¨‹åº¦æä¾›äº†æ–°çš„benchmarkã€‚MedChangeQAæ•°æ®é›†çš„æ„å»ºå°¤å…¶å…·æœ‰åˆ›æ–°æ€§ï¼Œå®ƒå…³æ³¨åŒ»å­¦å…±è¯†éšæ—¶é—´çš„å˜åŒ–ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¡¡é‡LLMæ˜¯å¦èƒ½å¤ŸåŒºåˆ†æ–°æ—§çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šMedRevQAæ•°æ®é›†åŒ…å«16,501ä¸ªQAå¯¹ï¼Œæ¶µç›–ä¸€èˆ¬çš„ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†ã€‚MedChangeQAæ•°æ®é›†æ˜¯MedRevQAçš„å­é›†ï¼ŒåŒ…å«512ä¸ªQAå¯¹ï¼Œå…¶ä¸­åŒ»å­¦å…±è¯†éšæ—¶é—´å‘ç”Ÿäº†å˜åŒ–ã€‚è®ºæ–‡æ²¡æœ‰æ¶‰åŠå…·ä½“çš„æ¨¡å‹ç»“æ„æˆ–æŸå¤±å‡½æ•°è®¾è®¡ï¼Œè€Œæ˜¯ä¾§é‡äºæ•°æ®é›†çš„æ„å»ºå’Œæ¨¡å‹è¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰è¢«è¯„ä¼°çš„LLMéƒ½è¡¨ç°å‡ºå¯¹è¿‡æ—¶åŒ»å­¦çŸ¥è¯†çš„ä¾èµ–ã€‚ä¾‹å¦‚ï¼Œåœ¨MedChangeQAæ•°æ®é›†ä¸Šï¼Œæ¨¡å‹åœ¨å›ç­”å…³äºå·²å‘ç”Ÿå˜åŒ–çš„åŒ»å­¦å…±è¯†çš„é—®é¢˜æ—¶ï¼Œå€¾å‘äºç»™å‡ºè¿‡æ—¶çš„ç­”æ¡ˆã€‚è¿™ä¸€ç»“æœçªæ˜¾äº†ç°æœ‰LLMåœ¨å¤„ç†æ—¶æ•ˆæ€§åŒ»å­¦çŸ¥è¯†æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘æ›´å…·æ—¶æ•ˆæ€§å’Œå¯é æ€§çš„åŒ»å­¦AIç³»ç»Ÿçš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´å¯é çš„åŒ»å­¦AIç³»ç»Ÿï¼Œè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­å’Œæ²»ç–—å†³ç­–ã€‚é€šè¿‡è¯„ä¼°å’Œæ”¹è¿›LLMå¯¹åŒ»å­¦çŸ¥è¯†æ—¶æ•ˆæ€§çš„æŒæ¡ï¼Œå¯ä»¥å‡å°‘æ¨¡å‹è¾“å‡ºè¿‡æ—¶æˆ–é”™è¯¯ä¿¡æ¯çš„é£é™©ï¼Œæé«˜åŒ»ç–—æœåŠ¡çš„è´¨é‡å’Œå®‰å…¨æ€§ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•åˆ©ç”¨è¯¥æ•°æ®é›†æ¥è®­ç»ƒå’Œä¼˜åŒ–LLMï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”åŒ»å­¦çŸ¥è¯†çš„å¿«é€Ÿæ›´æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing capabilities of Large Language Models (LLMs) show significant potential to enhance healthcare by assisting medical researchers and physicians. However, their reliance on static training data is a major risk when medical recommendations evolve with new research and developments. When LLMs memorize outdated medical knowledge, they can provide harmful advice or fail at clinical reasoning tasks. To investigate this problem, we introduce two novel question-answering (QA) datasets derived from systematic reviews: MedRevQA (16,501 QA pairs covering general biomedical knowledge) and MedChangeQA (a subset of 512 QA pairs where medical consensus has changed over time). Our evaluation of eight prominent LLMs on the datasets reveals consistent reliance on outdated knowledge across all models. We additionally analyze the influence of obsolete pre-training data and training strategies to explain this phenomenon and propose future directions for mitigation, laying the groundwork for developing more current and reliable medical AI systems.

