---
layout: default
title: Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text
---

# Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20375" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20375v1</a>
  <a href="https://arxiv.org/pdf/2509.20375.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20375v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20375v1', 'Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sharanya Parimanoharan, Ruwan D. Nawarathna

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°ç»å…¸æœºå™¨å­¦ä¹ ä¸Transformeræ¨¡å‹åœ¨AIç”Ÿæˆç ”ç©¶æ–‡æœ¬æ£€æµ‹ä¸­çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIæ–‡æœ¬æ£€æµ‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ ` `Transformeræ¨¡å‹` `DistilBERT` `å­¦æœ¯è¯šä¿¡` `å†…å®¹å®¡æ ¸`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡ç³Šäº†äººç±»ä¸AIç”Ÿæˆæ–‡æœ¬çš„ç•Œé™ï¼Œå¯¹å­¦æœ¯è¯šä¿¡å’Œä¿¡æ¯å®‰å…¨æ„æˆæŒ‘æˆ˜ã€‚
2. è®ºæ–‡å¯¹æ¯”äº†ç»å…¸æœºå™¨å­¦ä¹ å’ŒTransformeræ¨¡å‹ï¼Œç”¨äºåŒºåˆ†AIç”Ÿæˆçš„å­¦æœ¯æ‘˜è¦å’Œäººç±»æ’°å†™çš„æ‘˜è¦ã€‚
3. å®éªŒè¡¨æ˜DistilBERTæ¨¡å‹è¡¨ç°æœ€ä½³ï¼Œè€Œæ¨¡å‹é›†æˆæœªèƒ½æ˜¾è‘—æå‡æ€§èƒ½ï¼Œè¡¨æ˜æ¨¡å‹è¡¨ç¤ºçš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ChatGPTç­‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿæ™®åŠï¼Œäººç±»æ’°å†™æ–‡æœ¬å’ŒAIç”Ÿæˆæ–‡æœ¬ä¹‹é—´çš„ç•Œé™å˜å¾—æ¨¡ç³Šï¼Œå¼•å‘äº†å…³äºå­¦æœ¯è¯šä¿¡ã€çŸ¥è¯†äº§æƒå’Œè™šå‡ä¿¡æ¯ä¼ æ’­çš„ç´§è¿«é—®é¢˜ã€‚å› æ­¤ï¼Œéœ€è¦å¯é çš„AIæ–‡æœ¬æ£€æµ‹æŠ€æœ¯æ¥è¿›è¡Œå…¬å¹³è¯„ä¼°ï¼Œä»¥ç»´æŠ¤äººç±»åˆ›ä½œçš„çœŸå®æ€§ï¼Œå¹¶åœ¨æ•°å­—é€šä¿¡ä¸­åŸ¹å…»ä¿¡ä»»ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å½“å‰æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ–¹æ³•åŒºåˆ†ChatGPT-3.5ç”Ÿæˆçš„æ–‡æœ¬ä¸äººç±»æ’°å†™æ–‡æœ¬çš„èƒ½åŠ›ï¼Œä½¿ç”¨äº†åŒ…å«250å¯¹æ¥è‡ªå¹¿æ³›ç ”ç©¶ä¸»é¢˜çš„æ‘˜è¦çš„æ ‡è®°æ•°æ®é›†ã€‚æˆ‘ä»¬æµ‹è¯•å¹¶æ¯”è¾ƒäº†ç»å…¸æ–¹æ³•ï¼ˆé…å¤‡ç»å…¸è¯è¢‹æ¨¡å‹ã€è¯æ€§æ ‡æ³¨å’ŒTF-IDFç‰¹å¾çš„Logisticå›å½’ï¼‰å’ŒåŸºäºTransformerçš„æ–¹æ³•ï¼ˆä½¿ç”¨N-gramå¢å¼ºçš„BERTã€DistilBERTã€å¸¦æœ‰è½»é‡çº§è‡ªå®šä¹‰åˆ†ç±»å™¨çš„BERTä»¥åŠåŸºäºLSTMçš„N-gramæ¨¡å‹ï¼‰ã€‚æˆ‘ä»¬æ—¨åœ¨è¯„ä¼°æ¯ç§æ¨¡å‹åœ¨æ£€æµ‹AIç”Ÿæˆç ”ç©¶æ–‡æœ¬æ–¹é¢çš„æ€§èƒ½ï¼Œå¹¶æµ‹è¯•è¿™äº›æ¨¡å‹çš„é›†æˆæ˜¯å¦èƒ½ä¼˜äºä»»ä½•å•ä¸€æ£€æµ‹å™¨ã€‚ç»“æœè¡¨æ˜ï¼ŒDistilBERTå®ç°äº†æ€»ä½“æœ€ä½³æ€§èƒ½ï¼Œè€ŒLogisticå›å½’å’ŒBERT-Customæä¾›äº†å¯é ä¸”å¹³è¡¡çš„æ›¿ä»£æ–¹æ¡ˆï¼›LSTMå’ŒBERT-N-gramæ–¹æ³•è¡¨ç°è¾ƒå·®ã€‚ä¸‰ä¸ªæœ€ä½³æ¨¡å‹çš„æœ€å¤§æŠ•ç¥¨é›†æˆæœªèƒ½è¶…è¿‡DistilBERTæœ¬èº«ï¼Œçªå‡ºäº†å•ä¸ªåŸºäºTransformerçš„è¡¨ç¤ºä¼˜äºå•çº¯çš„æ¨¡å‹å¤šæ ·æ€§ã€‚é€šè¿‡å…¨é¢è¯„ä¼°è¿™äº›AIæ–‡æœ¬æ£€æµ‹æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œè¿™é¡¹å·¥ä½œä¸ºæ›´å¼ºå¤§çš„Transformeræ¡†æ¶å¥ å®šäº†åŸºç¡€ï¼Œè¿™äº›æ¡†æ¶å…·æœ‰æ›´å¤§ã€æ›´ä¸°å¯Œçš„æ•°æ®é›†ï¼Œä»¥è·Ÿä¸Šä¸æ–­æ”¹è¿›çš„ç”Ÿæˆå¼AIæ¨¡å‹çš„æ­¥ä¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆåŒºåˆ†AIï¼ˆç‰¹åˆ«æ˜¯ChatGPT-3.5ï¼‰ç”Ÿæˆçš„å­¦æœ¯ç ”ç©¶æ–‡æœ¬ä¸äººç±»æ’°å†™çš„å­¦æœ¯ç ”ç©¶æ–‡æœ¬çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æ—¥ç›Šå¼ºå¤§çš„ç”Ÿæˆå¼AIæ¨¡å‹æ—¶ï¼ŒåŒºåˆ†èƒ½åŠ›ä¸è¶³ï¼Œå®¹æ˜“é€ æˆå­¦æœ¯ä¸ç«¯è¡Œä¸ºå’Œè™šå‡ä¿¡æ¯ä¼ æ’­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¯”è¾ƒå’Œè¯„ä¼°å¤šç§æœºå™¨å­¦ä¹ æ–¹æ³•ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•å’ŒåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œåœ¨AIç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œä¸ºæ„å»ºæ›´é²æ£’çš„AIæ–‡æœ¬æ£€æµ‹ç³»ç»Ÿæä¾›æŒ‡å¯¼ã€‚è®ºæ–‡è¿˜å°è¯•äº†æ¨¡å‹é›†æˆçš„æ–¹æ³•ï¼Œä»¥æœŸæé«˜æ£€æµ‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®é›†æ„å»ºï¼šæ”¶é›†åŒ…å«äººç±»æ’°å†™å’ŒChatGPT-3.5ç”Ÿæˆçš„å­¦æœ¯æ‘˜è¦çš„æ•°æ®é›†ã€‚2) ç‰¹å¾æå–ï¼šå¯¹äºç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œæå–è¯è¢‹æ¨¡å‹ã€è¯æ€§æ ‡æ³¨å’ŒTF-IDFç­‰ç‰¹å¾ï¼›å¯¹äºTransformeræ¨¡å‹ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„BERTã€DistilBERTç­‰æ¨¡å‹æå–æ–‡æœ¬è¡¨ç¤ºã€‚3) æ¨¡å‹è®­ç»ƒï¼šè®­ç»ƒLogisticå›å½’ã€BERTã€DistilBERTã€LSTMç­‰æ¨¡å‹ã€‚4) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ç­‰æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚5) æ¨¡å‹é›†æˆï¼šå°è¯•å°†å¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆï¼Œä»¥æé«˜æ£€æµ‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹å¤šç§AIæ–‡æœ¬æ£€æµ‹æ–¹æ³•è¿›è¡Œäº†å…¨é¢çš„æ¯”è¾ƒå’Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•å’ŒåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å°è¯•äº†æ¨¡å‹é›†æˆçš„æ–¹æ³•ï¼Œå¹¶åˆ†æäº†æ¨¡å‹é›†æˆå¯¹æ£€æµ‹æ€§èƒ½çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDistilBERTæ¨¡å‹åœ¨AIç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œè€Œæ¨¡å‹é›†æˆæœªèƒ½æ˜¾è‘—æå‡æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åŒ…å«250å¯¹å­¦æœ¯æ‘˜è¦çš„æ•°æ®é›†è¿›è¡Œå®éªŒã€‚2) é‡‡ç”¨å¤šç§ç‰¹å¾æå–æ–¹æ³•ï¼ŒåŒ…æ‹¬è¯è¢‹æ¨¡å‹ã€è¯æ€§æ ‡æ³¨ã€TF-IDFå’Œé¢„è®­ç»ƒçš„Transformeræ¨¡å‹ã€‚3) è®­ç»ƒå¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ŒåŒ…æ‹¬Logisticå›å½’ã€BERTã€DistilBERTå’ŒLSTMã€‚4) ä½¿ç”¨å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ç­‰æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚5) å°è¯•äº†æœ€å¤§æŠ•ç¥¨é›†æˆæ–¹æ³•ï¼Œå°†å¤šä¸ªæ¨¡å‹è¿›è¡Œé›†æˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDistilBERTæ¨¡å‹åœ¨AIç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œä¼˜äºå…¶ä»–ç»å…¸æœºå™¨å­¦ä¹ æ–¹æ³•å’ŒåŸºäºBERTçš„æ¨¡å‹ã€‚Logisticå›å½’å’ŒBERT-Customæ¨¡å‹ä¹Ÿæä¾›äº†å¯é çš„æ›¿ä»£æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œæ¨¡å‹é›†æˆï¼ˆæœ€å¤§æŠ•ç¥¨é›†æˆï¼‰æœªèƒ½è¶…è¶ŠDistilBERTçš„æ€§èƒ½ï¼Œè¡¨æ˜å•ä¸ªå¼ºå¤§çš„Transformeræ¨¡å‹è¡¨ç¤ºæ¯”ç®€å•çš„æ¨¡å‹å¤šæ ·æ€§æ›´é‡è¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå­¦æœ¯è¯šä¿¡æ£€æµ‹ã€å†…å®¹å®¡æ ¸ã€è™šå‡ä¿¡æ¯è¯†åˆ«ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨æ£€æµ‹AIç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¯ä»¥å¸®åŠ©ç»´æŠ¤å­¦æœ¯ç ”ç©¶çš„çœŸå®æ€§å’Œå¯é æ€§ï¼Œé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œå¹¶ä¿ƒè¿›è´Ÿè´£ä»»çš„AIæŠ€æœ¯åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯é›†æˆåˆ°å­¦æœ¯å‡ºç‰ˆå¹³å°ã€ç¤¾äº¤åª’ä½“å¹³å°ç­‰ï¼Œä»¥æé«˜å†…å®¹è´¨é‡å’Œç”¨æˆ·ä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid adoption of large language models (LLMs) such as ChatGPT has blurred the line between human and AI-generated texts, raising urgent questions about academic integrity, intellectual property, and the spread of misinformation. Thus, reliable AI-text detection is needed for fair assessment to safeguard human authenticity and cultivate trust in digital communication. In this study, we investigate how well current machine learning (ML) approaches can distinguish ChatGPT-3.5-generated texts from human-written texts employing a labeled data set of 250 pairs of abstracts from a wide range of research topics. We test and compare both classical (Logistic Regression armed with classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier, and LSTM-based N-gram models) ML detection techniques. As we aim to assess each model's performance in detecting AI-generated research texts, we also aim to test whether an ensemble of these models can outperform any single detector. Results show DistilBERT achieves the overall best performance, while Logistic Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and BERT-N-gram approaches lag. The max voting ensemble of the three best models fails to surpass DistilBERT itself, highlighting the primacy of a single transformer-based representation over mere model diversity. By comprehensively assessing the strengths and weaknesses of these AI-text detection approaches, this work lays a foundation for more robust transformer frameworks with larger, richer datasets to keep pace with ever-improving generative AI models.

