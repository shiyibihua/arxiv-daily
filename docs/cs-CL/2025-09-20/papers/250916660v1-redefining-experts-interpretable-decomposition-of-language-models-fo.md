---
layout: default
title: Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation
---

# Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16660" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16660v1</a>
  <a href="https://arxiv.org/pdf/2509.16660.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16660v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16660v1', 'Redefining Experts: Interpretable Decomposition of Language Models for Toxicity Mitigation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zuhair Hasan Shaik, Abdullah Mazhar, Aseem Srivastava, Md Shad Akhtar

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

**å¤‡æ³¨**: Accepted to the NeurIPS 2025 Research Track

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEigenShiftæ–¹æ³•ï¼Œé€šè¿‡è¯­è¨€æ¨¡å‹åˆ†è§£å®ç°å¯è§£é‡Šçš„æ¯’æ€§å†…å®¹æŠ‘åˆ¶ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `æ¯’æ€§ç¼“è§£` `å¯è§£é‡Šæ€§` `ç‰¹å¾åˆ†è§£` `EigenShift` `è‡ªç„¶è¯­è¨€å¤„ç†` `äººå·¥æ™ºèƒ½å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¯’æ€§ç¼“è§£æ–¹æ³•ä¾èµ–ç¥ç»å…ƒæ¿€æ´»æ“ä½œï¼Œä½†å­˜åœ¨ä¸ç¨³å®šæ€§ã€ä¸Šä¸‹æ–‡ä¾èµ–æ€§ç­‰é—®é¢˜ï¼Œå¹¶å¯èƒ½æŸå®³æ¨¡å‹è¯­è¨€èƒ½åŠ›ã€‚
2. æå‡ºEigenShiftæ–¹æ³•ï¼Œé€šè¿‡ç‰¹å¾åˆ†è§£é€‰æ‹©æ€§åœ°æŠ‘åˆ¶è¯­è¨€æ¨¡å‹ä¸­ä¸æ¯’æ€§ç”Ÿæˆç›¸å…³çš„ç»„ä»¶ï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEigenShiftæ–¹æ³•èƒ½åœ¨æŠ‘åˆ¶æ¯’æ€§çš„åŒæ—¶ï¼Œä¿æŒè¯­è¨€æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ï¼Œä¸”è®¡ç®—æˆæœ¬ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„æµç•…æ€§ï¼Œä½†å…¶äº§ç”Ÿæœ‰å®³å†…å®¹çš„å€¾å‘ä»ç„¶æ˜¯äººå·¥æ™ºèƒ½å®‰å…¨å’Œå…¬ä¼—ä¿¡ä»»é¢ä¸´çš„å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ¯’æ€§ç¼“è§£æ–¹æ³•ä¸»è¦æ“çºµå•ä¸ªç¥ç»å…ƒçš„æ¿€æ´»ï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸ç¨³å®šæ€§ã€ä¸Šä¸‹æ–‡ä¾èµ–æ€§ï¼Œå¹¶ä¸”å¸¸å¸¸æŸå®³æ¨¡å‹çš„æ ¸å¿ƒè¯­è¨€èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›ç¼ºç‚¹ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸‰ä¸ªå…³é”®é—®é¢˜ï¼šç¥ç»å…ƒçº§åˆ«æ¯’æ€§æŒ‡æ ‡çš„ç¨³å®šæ€§ã€ç»“æ„åŒ–ï¼ˆå±‚çº§ï¼‰è¡¨ç¤ºçš„ä¼˜åŠ¿ä»¥åŠé©±åŠ¨æ¯’æ€§ç”Ÿæˆçš„æœºåˆ¶çš„å¯è§£é‡Šæ€§ã€‚é€šè¿‡å¯¹Jigsawå’ŒToxiCNæ•°æ®é›†è¿›è¡Œçš„å¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¡¨æ˜èšåˆçš„å±‚çº§ç‰¹å¾æ¯”å•ä¸ªç¥ç»å…ƒæä¾›æ›´ç¨³å¥çš„ä¿¡å·ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å…ˆå‰å·¥ä½œåœ¨åŸºäºç¥ç»å…ƒçš„å¹²é¢„ä¸­æ··æ·†äº†æ¯’æ€§æ£€æµ‹ä¸“å®¶å’Œç”Ÿæˆä¸“å®¶çš„æ¦‚å¿µæ€§å±€é™æ€§ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºåŸåˆ™çš„å¹²é¢„æŠ€æœ¯EigenShiftï¼Œè¯¥æŠ€æœ¯åŸºäºè¯­è¨€æ¨¡å‹æœ€ç»ˆè¾“å‡ºå±‚çš„ç‰¹å¾åˆ†è§£ã€‚è¯¥æ–¹æ³•é€‰æ‹©æ€§åœ°é’ˆå¯¹ç”Ÿæˆå¯¹é½çš„ç»„ä»¶ï¼Œä»è€Œå®ç°ç²¾ç¡®çš„æ¯’æ€§æŠ‘åˆ¶ï¼Œè€Œä¸ä¼šæŸå®³è¯­è¨€èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒï¼Œåªéœ€æå°‘çš„è®¡ç®—æˆæœ¬ï¼Œå¹¶ä¸”åŸºäºä¸¥æ ¼çš„ç†è®ºåˆ†æã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡æ“çºµå•ä¸ªç¥ç»å…ƒçš„æ¿€æ´»æ¥ç¼“è§£è¯­è¨€æ¨¡å‹ä¸­çš„æ¯’æ€§å†…å®¹ç”Ÿæˆï¼Œä½†è¿™äº›æ–¹æ³•å­˜åœ¨ä¸ç¨³å®šæ€§ï¼Œå¯¹ä¸Šä¸‹æ–‡çš„ä¾èµ–æ€§å¼ºï¼Œå¹¶ä¸”å®¹æ˜“æŸå®³æ¨¡å‹åŸæœ‰çš„è¯­è¨€èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸æ··æ·†äº†æ¯’æ€§æ£€æµ‹ä¸“å®¶å’Œæ¯’æ€§ç”Ÿæˆä¸“å®¶ï¼Œå¯¼è‡´å¹²é¢„æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹è¯­è¨€æ¨¡å‹çš„è¾“å‡ºå±‚è¿›è¡Œç‰¹å¾åˆ†è§£ï¼Œè¯†åˆ«å¹¶é€‰æ‹©æ€§åœ°æŠ‘åˆ¶ä¸æ¯’æ€§ç”Ÿæˆç›¸å…³çš„ç‰¹å¾å‘é‡ï¼ˆeigenvectorsï¼‰ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨ç²¾ç¡®åœ°æŠ‘åˆ¶æ¯’æ€§ï¼ŒåŒæ—¶ä¿ç•™æ¨¡å‹åŸæœ‰çš„è¯­è¨€èƒ½åŠ›ã€‚é€šè¿‡åˆ†è§£ï¼Œå¯ä»¥åŒºåˆ†è´Ÿè´£ç”Ÿæˆæ¯’æ€§å†…å®¹å’Œè´Ÿè´£è¯­è¨€è¡¨è¾¾çš„ç»„ä»¶ï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEigenShiftæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **ç‰¹å¾åˆ†è§£**ï¼šå¯¹è¯­è¨€æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºå±‚è¿›è¡Œç‰¹å¾åˆ†è§£ï¼ˆeigen-decompositionï¼‰ï¼Œå¾—åˆ°ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ã€‚
2. **æ¯’æ€§å¯¹é½åˆ¤æ–­**ï¼šé€šè¿‡æŸç§æŒ‡æ ‡ï¼ˆä¾‹å¦‚ï¼Œä¸æ¯’æ€§è¯æ±‡çš„å…³è”æ€§ï¼‰æ¥åˆ¤æ–­æ¯ä¸ªç‰¹å¾å‘é‡ä¸æ¯’æ€§ç”Ÿæˆçš„å¯¹é½ç¨‹åº¦ã€‚
3. **é€‰æ‹©æ€§æŠ‘åˆ¶**ï¼šé€‰æ‹©ä¸æ¯’æ€§ç”Ÿæˆé«˜åº¦å¯¹é½çš„ç‰¹å¾å‘é‡ï¼Œå¹¶å¯¹å…¶è¿›è¡ŒæŠ‘åˆ¶æˆ–è°ƒæ•´ï¼Œä»è€Œé™ä½æ¨¡å‹ç”Ÿæˆæ¯’æ€§å†…å®¹çš„æ¦‚ç‡ã€‚
4. **è¾“å‡ºç”Ÿæˆ**ï¼šä½¿ç”¨è°ƒæ•´åçš„è¾“å‡ºå±‚ç”Ÿæˆæ–‡æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶åŸºäºç‰¹å¾åˆ†è§£çš„æ¯’æ€§æŠ‘åˆ¶ç­–ç•¥ã€‚ä¸ä»¥å¾€ç›´æ¥æ“çºµç¥ç»å…ƒæ¿€æ´»çš„æ–¹æ³•ä¸åŒï¼ŒEigenShiftæ–¹æ³•é€šè¿‡åˆ†è§£è¾“å‡ºå±‚ï¼Œèƒ½å¤Ÿæ›´ç²¾ç¡®åœ°å®šä½å’ŒæŠ‘åˆ¶ä¸æ¯’æ€§ç”Ÿæˆç›¸å…³çš„ç»„ä»¶ï¼Œä»è€Œåœ¨æŠ‘åˆ¶æ¯’æ€§çš„åŒæ—¶ï¼Œæ›´å¥½åœ°ä¿ç•™æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒï¼Œé™ä½äº†å®æ–½æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼š
1. **ç‰¹å¾åˆ†è§£æ–¹æ³•**ï¼šè®ºæ–‡é‡‡ç”¨æ ‡å‡†çš„ç‰¹å¾åˆ†è§£æ–¹æ³•ï¼Œä¾‹å¦‚å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰æˆ–ç‰¹å¾å€¼åˆ†è§£ï¼ˆEVDï¼‰ã€‚
2. **æ¯’æ€§å¯¹é½æŒ‡æ ‡**ï¼šè®ºæ–‡éœ€è¦è®¾è®¡ä¸€ä¸ªæŒ‡æ ‡æ¥è¡¡é‡æ¯ä¸ªç‰¹å¾å‘é‡ä¸æ¯’æ€§ç”Ÿæˆçš„å¯¹é½ç¨‹åº¦ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°è®¡ç®—ç‰¹å¾å‘é‡ä¸æ¯’æ€§è¯æ±‡çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæˆ–è€…ä½¿ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„æ¯’æ€§æ£€æµ‹æ¨¡å‹æ¥è¯„ä¼°æ¯ä¸ªç‰¹å¾å‘é‡å¯¹æ¯’æ€§é¢„æµ‹çš„å½±å“ã€‚
3. **æŠ‘åˆ¶ç­–ç•¥**ï¼šè®ºæ–‡éœ€è¦è®¾è®¡ä¸€ç§ç­–ç•¥æ¥æŠ‘åˆ¶ä¸æ¯’æ€§ç”Ÿæˆç›¸å…³çš„ç‰¹å¾å‘é‡ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°å°†è¿™äº›ç‰¹å¾å‘é‡çš„æƒé‡è®¾ç½®ä¸ºé›¶ï¼Œæˆ–è€…å¯¹å…¶è¿›è¡Œå¾®è°ƒä»¥é™ä½å…¶ä¸æ¯’æ€§è¯æ±‡çš„å…³è”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡åœ¨Jigsawå’ŒToxiCNæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEigenShiftæ–¹æ³•èƒ½å¤Ÿåœ¨æœ‰æ•ˆæŠ‘åˆ¶æ¯’æ€§å†…å®¹ç”Ÿæˆçš„åŒæ—¶ï¼Œä¿æŒè¯­è¨€æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›ã€‚è¯¥æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒï¼Œä¸”è®¡ç®—æˆæœ¬ä½ï¼Œå…·æœ‰å¾ˆå¼ºçš„å®ç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¯’æ€§æŠ‘åˆ¶æ–¹é¢ä¼˜äºç°æœ‰çš„ç¥ç»å…ƒçº§åˆ«å¹²é¢„æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è‡ªç„¶è¯­è¨€ç”Ÿæˆç³»ç»Ÿï¼Œç‰¹åˆ«æ˜¯é‚£äº›éœ€è¦ç”Ÿæˆå®‰å…¨ã€æ— å®³å†…å®¹çš„åº”ç”¨åœºæ™¯ï¼Œå¦‚èŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œå¹³å°ã€åœ¨çº¿ç¤¾åŒºç®¡ç†ç­‰ã€‚é€šè¿‡é™ä½è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¯’æ€§å†…å®¹çš„æ¦‚ç‡ï¼Œå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¢å¼ºå…¬ä¼—å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¿¡ä»»ï¼Œå¹¶å‡å°‘æ½œåœ¨çš„æ³•å¾‹å’Œä¼¦ç†é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models have demonstrated impressive fluency across diverse tasks, yet their tendency to produce toxic content remains a critical challenge for AI safety and public trust. Existing toxicity mitigation approaches primarily manipulate individual neuron activations, but these methods suffer from instability, context dependence, and often compromise the model's core language abilities. To address these shortcomings, we investigate three key questions: the stability of neuron-level toxicity indicators, the advantages of structural (layer-wise) representations, and the interpretability of mechanisms driving toxic generation. Through extensive experiments on Jigsaw and ToxiCN datasets, we show that aggregated layer-wise features provide more robust signals than single neurons. Moreover, we observe conceptual limitations in prior works that conflate toxicity detection experts and generation experts within neuron-based interventions. To mitigate this, we propose a novel principled intervention technique, EigenShift, based on eigen-decomposition of the language model's final output layer. This method selectively targets generation-aligned components, enabling precise toxicity suppression without impairing linguistic competence. Our method requires no additional training or fine-tuning, incurs minimal computational cost, and is grounded in rigorous theoretical analysis.

