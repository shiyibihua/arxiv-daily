---
layout: default
title: ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models
---

# ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12387" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12387v1</a>
  <a href="https://arxiv.org/pdf/2508.12387.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12387v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12387v1', 'ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuanfeng Xu, Zehui Dai, Jian Liang, Jiapeng Guan, Guangrun Wang, Liang Lin, Xiaohui Lv

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17

**å¤‡æ³¨**: 16pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReaLMæ¡†æ¶ä»¥å¢å¼ºå°å‹è¯­è¨€æ¨¡å‹çš„è‡ªä¸»æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è‡ªä¸»æ€§` `æ³›åŒ–èƒ½åŠ›` `å¼ºåŒ–å­¦ä¹ ` `è’¸é¦æŠ€æœ¯` `é¢†åŸŸçŸ¥è¯†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å°å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºæ¨ç†èƒ½åŠ›ã€è‡ªä¸»æ€§å’Œæ³›åŒ–èƒ½åŠ›çš„ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºReaLMæ¡†æ¶ï¼Œé€šè¿‡å¤šè·¯å¾„è¿‡ç¨‹éªŒè¯å’Œæ¸è¿›è¯±å¯¼ç­–ç•¥ï¼Œå¢å¼ºæ¨ç†èƒ½åŠ›å’Œè‡ªä¸»æ€§ï¼ŒåŒæ—¶é€šè¿‡è’¸é¦æŠ€æœ¯æå‡æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReaLMåœ¨å‚ç›´å’Œä¸€èˆ¬æ¨ç†ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†å°å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰ä½œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç»æµæ›¿ä»£æ–¹æ¡ˆï¼Œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å¸¸å¸¸è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå…¶èƒ½åŠ›æœ‰é™ä»¥åŠåœ¨å¤šæ­¥æ¨ç†ä¸­å®¹æ˜“äº§ç”Ÿé”™è¯¯æˆ–ä¸ä¸€è‡´çš„ç­”æ¡ˆã€‚ç°æœ‰çš„æ”¹è¿›æ–¹æ³•é€šå¸¸åœ¨æ¨ç†èƒ½åŠ›ã€è‡ªä¸»æ€§å’Œæ³›åŒ–èƒ½åŠ›ç­‰å…³é”®æ–¹é¢å­˜åœ¨æƒè¡¡ã€‚æœ¬æ–‡æå‡ºäº†ReaLMï¼Œä¸€ä¸ªç”¨äºå¢å¼ºå‚ç›´é¢†åŸŸæ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚é€šè¿‡å¤šè·¯å¾„è¿‡ç¨‹éªŒè¯ï¼ˆMRPVï¼‰å¯¹æ¯”æ­£è´Ÿæ¨ç†è·¯å¾„ï¼Œæå‡æ¨ç†èƒ½åŠ›ï¼›é€šè¿‡æ¸è¿›è¯±å¯¼ï¼ˆEAAIï¼‰å‡å°‘å¯¹å¤–éƒ¨ä¿¡å·çš„ä¾èµ–ï¼Œå¢å¼ºè‡ªä¸»æ€§ï¼›é€šè¿‡å¼•å¯¼é“¾å¼æ€ç»´è’¸é¦å°†é¢†åŸŸç‰¹å®šè§„åˆ™å’Œä¸“å®¶çŸ¥è¯†ç¼–ç åˆ°SLMå‚æ•°ä¸­ï¼Œä»¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒReaLMåœ¨ä¸Šè¿°ä¸‰ä¸ªæ–¹é¢æ˜¾è‘—æå‡äº†SLMçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºåè§ç›‘ç£ï¼Œé™åˆ¶äº†æ¨¡å‹ä»é”™è¯¯ä¸­å­¦ä¹ çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReaLMæ¡†æ¶é€šè¿‡å¯¹æ¯”æ­£è´Ÿæ¨ç†è·¯å¾„æ¥æå‡æ¨ç†èƒ½åŠ›ï¼Œå‡å°‘å¯¹å¤–éƒ¨ä¿¡å·çš„ä¾èµ–ä»¥å¢å¼ºè‡ªä¸»æ€§ï¼Œå¹¶é€šè¿‡è’¸é¦æŠ€æœ¯å°†é¢†åŸŸçŸ¥è¯†èå…¥æ¨¡å‹ä¸­ä»¥æé«˜æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReaLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¤šè·¯å¾„è¿‡ç¨‹éªŒè¯ï¼ˆMRPVï¼‰ã€æ¸è¿›è¯±å¯¼ï¼ˆEAAIï¼‰å’Œå¼•å¯¼é“¾å¼æ€ç»´è’¸é¦ã€‚MRPVç”¨äºæå–æ¨ç†æ¨¡å¼ï¼ŒEAAIç”¨äºå‡å°‘å¤–éƒ¨ä¿¡å·ä¾èµ–ï¼Œè€Œè’¸é¦æ¨¡å—åˆ™å°†é¢†åŸŸçŸ¥è¯†ç¼–ç åˆ°æ¨¡å‹å‚æ•°ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šReaLMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†MRPVå’ŒEAAIç­–ç•¥ï¼Œå½¢æˆäº†ä¸€ç§è‡ªæˆ‘å¢å¼ºçš„æ¨ç†æœºåˆ¶ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿä¾èµ–å¤–éƒ¨ä¿¡å·çš„æ¨ç†æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒMRPVé€šè¿‡å¯¹æ¯”æ­£è´Ÿè·¯å¾„æ¥ä¼˜åŒ–æŸå¤±å‡½æ•°ï¼Œè€ŒEAAIåˆ™é€šè¿‡é€æ­¥å‡å°‘å¤–éƒ¨ä¿¡å·çš„å½±å“æ¥æå‡æ¨¡å‹çš„è‡ªä¸»æ€§ã€‚è’¸é¦è¿‡ç¨‹åˆ™ç¡®ä¿é¢†åŸŸçŸ¥è¯†æœ‰æ•ˆèå…¥æ¨¡å‹å‚æ•°ä¸­ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒReaLMåœ¨å¤šä¸ªå‚ç›´å’Œä¸€èˆ¬æ¨ç†ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›æå‡äº†20%ä»¥ä¸Šï¼Œè‡ªä¸»æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¹Ÿæœ‰æ˜¾è‘—æ”¹å–„ã€‚è¿™äº›ç»“æœéªŒè¯äº†ReaLMåœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReaLMæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨éœ€è¦å¤æ‚æ¨ç†çš„å‚ç›´é¢†åŸŸï¼Œå¦‚åŒ»ç–—è¯Šæ–­ã€æ³•å¾‹åˆ†æå’Œé‡‘èå†³ç­–ç­‰ã€‚é€šè¿‡å¢å¼ºå°å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œè‡ªä¸»æ€§ï¼Œè¯¥ç ”ç©¶èƒ½å¤Ÿæé«˜è¿™äº›é¢†åŸŸä¸­è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„æ™ºèƒ½æ°´å¹³å’Œå†³ç­–è´¨é‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Small Language Models (SLMs) are a cost-effective alternative to Large Language Models (LLMs), but often struggle with complex reasoning due to their limited capacity and a tendency to produce mistakes or inconsistent answers during multi-step reasoning. Existing efforts have improved SLM performance, but typically at the cost of one or more of three key aspects: (1) reasoning capability, due to biased supervision that filters out negative reasoning paths and limits learning from errors; (2) autonomy, due to over-reliance on externally generated reasoning signals; and (3) generalization, which suffers when models overfit to teacher-specific patterns. In this paper, we introduce ReaLM, a reinforcement learning framework for robust and self-sufficient reasoning in vertical domains. To enhance reasoning capability, we propose Multi-Route Process Verification (MRPV), which contrasts both positive and negative reasoning paths to extract decisive patterns. To reduce reliance on external guidance and improve autonomy, we introduce Enabling Autonomy via Asymptotic Induction (EAAI), a training strategy that gradually fades external signals. To improve generalization, we apply guided chain-of-thought distillation to encode domain-specific rules and expert knowledge into SLM parameters, making them part of what the model has learned. Extensive experiments on both vertical and general reasoning tasks demonstrate that ReaLM significantly improves SLM performance across aspects (1)-(3) above.

