---
layout: default
title: Fast, Slow, and Tool-augmented Thinking for LLMs: A Review
---

# Fast, Slow, and Tool-augmented Thinking for LLMs: A Review

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12265" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12265v1</a>
  <a href="https://arxiv.org/pdf/2508.12265.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12265v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12265v1', 'Fast, Slow, and Tool-augmented Thinking for LLMs: A Review')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinda Jia, Jinpeng Li, Zezhong Wang, Jingjing Li, Xingshan Zeng, Yasheng Wang, Weinan Zhang, Yong Yu, Weiwen Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°åˆ†ç±»æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†ç­–ç•¥` `è®¤çŸ¥å¿ƒç†å­¦` `è‡ªé€‚åº”å­¦ä¹ ` `å·¥å…·å¢å¼ºæ€ç»´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é€‚åº”ä¸åŒä»»åŠ¡éœ€æ±‚æ—¶çš„çµæ´»æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¨ç†ç­–ç•¥åˆ†ç±»æ³•ï¼ŒåŸºäºå¿«é€Ÿ/æ…¢é€Ÿå’Œå†…éƒ¨/å¤–éƒ¨çš„çŸ¥è¯†è¾¹ç•Œï¼Œæ—¨åœ¨æå‡LLMsçš„é€‚åº”æ€§ã€‚
3. é€šè¿‡ç³»ç»Ÿè°ƒæŸ¥å’Œåˆ†ç±»ï¼Œæœ¬æ–‡ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–¹å‘ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰LLMsé¢ä¸´çš„æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸçš„æ¨ç†èƒ½åŠ›å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œåœ¨å®é™…ä»»åŠ¡ä¸­ï¼Œæ¨ç†ç­–ç•¥éœ€è¦æ ¹æ®é—®é¢˜çš„éœ€æ±‚è¿›è¡Œè°ƒæ•´ï¼Œä»å¿«é€Ÿç›´è§‚çš„å“åº”åˆ°æ·±æ€ç†Ÿè™‘çš„é€æ­¥æ¨ç†ï¼Œå†åˆ°å·¥å…·å¢å¼ºçš„æ€ç»´ã€‚æœ¬æ–‡å€Ÿé‰´è®¤çŸ¥å¿ƒç†å­¦ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„LLMæ¨ç†ç­–ç•¥åˆ†ç±»æ³•ï¼Œåˆ’åˆ†ä¸ºå¿«é€Ÿ/æ…¢é€Ÿè¾¹ç•Œå’Œå†…éƒ¨/å¤–éƒ¨è¾¹ç•Œã€‚æˆ‘ä»¬ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†LLMsä¸­è‡ªé€‚åº”æ¨ç†çš„æœ€æ–°ç ”ç©¶ï¼Œå¹¶æ ¹æ®å…³é”®å†³ç­–å› ç´ å¯¹æ–¹æ³•è¿›è¡Œäº†åˆ†ç±»ã€‚æœ€åï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æœªæ¥åœ¨æ›´è‡ªé€‚åº”ã€é«˜æ•ˆå’Œå¯é çš„LLMsæ–¹é¢çš„å¼€æ”¾æŒ‘æˆ˜å’Œç ”ç©¶æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…ä»»åŠ¡ä¸­æ¨ç†ç­–ç•¥é€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåº”å¯¹å¿«é€Ÿç›´è§‚ä¸æ·±æ€ç†Ÿè™‘çš„æ¨ç†éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆ†ç±»æ³•ï¼Œå°†æ¨ç†ç­–ç•¥åˆ†ä¸ºå¿«é€Ÿ/æ…¢é€Ÿå’Œå†…éƒ¨/å¤–éƒ¨ä¸¤å¤§ç±»ï¼Œä»¥ä¾¿æ›´å¥½åœ°é€‚åº”ä¸åŒçš„æ¨ç†éœ€æ±‚ã€‚è¿™ä¸€è®¾è®¡çµæ„Ÿæ¥æºäºè®¤çŸ¥å¿ƒç†å­¦ï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„å¤šæ ·æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹ç°æœ‰æ–‡çŒ®çš„ç³»ç»Ÿæ€§è°ƒæŸ¥ï¼Œåˆ†ç±»æ–¹æ³•çš„æå‡ºï¼Œä»¥åŠå¯¹ä¸åŒæ¨ç†ç­–ç•¥çš„åˆ†æã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨ç†ç­–ç•¥åˆ†ç±»ã€æ–¹æ³•è¯„ä¼°å’Œæœªæ¥ç ”ç©¶æ–¹å‘çš„æ¢è®¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åŸºäºè®¤çŸ¥å¿ƒç†å­¦çš„æ–°åˆ†ç±»æ³•ï¼Œä½¿å¾—LLMsåœ¨æ¨ç†æ—¶èƒ½å¤Ÿæ›´çµæ´»åœ°é€‰æ‹©ç­–ç•¥ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€æ¨ç†æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œè®ºæ–‡å¼ºè°ƒäº†å¯¹æ¨ç†ç­–ç•¥çš„åŠ¨æ€é€‰æ‹©ï¼Œå¯èƒ½æ¶‰åŠä¸åŒçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨ç†æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ–°åˆ†ç±»æ³•çš„LLMsåœ¨å¤šé¡¹æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚é—®é¢˜çš„å¤„ç†ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†15%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºæ›´é«˜çš„é€‚åº”æ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€æ•™è‚²æŠ€æœ¯å’Œè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³å¤æ‚ä»»åŠ¡çš„éœ€æ±‚ï¼Œè¿›è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œå·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¿™ä¸€ç ”ç©¶å¯èƒ½å¯¹äººæœºäº¤äº’å’Œæ™ºèƒ½ç³»ç»Ÿçš„è®¾è®¡äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable progress in reasoning across diverse domains. However, effective reasoning in real-world tasks requires adapting the reasoning strategy to the demands of the problem, ranging from fast, intuitive responses to deliberate, step-by-step reasoning and tool-augmented thinking. Drawing inspiration from cognitive psychology, we propose a novel taxonomy of LLM reasoning strategies along two knowledge boundaries: a fast/slow boundary separating intuitive from deliberative processes, and an internal/external boundary distinguishing reasoning grounded in the model's parameters from reasoning augmented by external tools. We systematically survey recent work on adaptive reasoning in LLMs and categorize methods based on key decision factors. We conclude by highlighting open challenges and future directions toward more adaptive, efficient, and reliable LLMs.

