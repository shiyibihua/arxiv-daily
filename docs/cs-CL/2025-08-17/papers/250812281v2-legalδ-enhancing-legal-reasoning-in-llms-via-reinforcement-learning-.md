---
layout: default
title: Legal$Î”$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain
---

# Legal$Î”$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12281" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12281v2</a>
  <a href="https://arxiv.org/pdf/2508.12281.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12281v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12281v2', 'Legal$Î”$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Dai, Buqiang Xu, Zhenghao Liu, Yukun Yan, Huiyuan Xie, Xiaoyuan Yi, Shuo Wang, Ge Yu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17 (æ›´æ–°: 2025-08-19)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/NEUIR/LegalDelta)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLegal$Î”$ä»¥è§£å†³æ³•å¾‹æ¨ç†æ¨¡å‹çš„å¯é æ€§ä¸å¯è§£é‡Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ³•å¾‹æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `é“¾å¼æ€ç»´` `ä¿¡æ¯å¢ç›Š` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ³•å¾‹LLMsåœ¨å¤æ‚æ³•å¾‹åœºæ™¯ä¸­ç¼ºä¹å¯é çš„æ¨ç†èƒ½åŠ›ï¼Œå¸¸å¸¸åªç»™å‡ºç›´æ¥ç­”æ¡ˆï¼Œå¯¼è‡´å¯è§£é‡Šæ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„Legal$Î”$æ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ å’Œé“¾å¼æ€ç»´å¼•å¯¼çš„ä¿¡æ¯å¢ç›Šï¼Œæå‡æ³•å¾‹æ¨ç†çš„è´¨é‡å’Œæ·±åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLegal$Î”$åœ¨æ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­è¶…è¶Šäº†å¤šä¸ªåŸºçº¿æ¨¡å‹ï¼Œæå‡äº†å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ³•å¾‹äººå·¥æ™ºèƒ½ï¼ˆLegalAIï¼‰åœ¨è‡ªåŠ¨åŒ–å¸æ³•å†³ç­–æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰çš„æ³•å¾‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆå¯é å’Œå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ä¸­ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚å®ƒä»¬å¾€å¾€å¿«é€Ÿç»™å‡ºç­”æ¡ˆï¼Œè€Œç¼ºä¹æ˜ç¡®çš„å¤šæ­¥éª¤æ¨ç†ï¼Œè¿™é™åˆ¶äº†åœ¨å¤æ‚æ³•å¾‹åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Legal$Î”$ï¼Œä¸€ä¸ªé€šè¿‡é“¾å¼æ€ç»´å¼•å¯¼çš„ä¿¡æ¯å¢ç›Šæ¥å¢å¼ºæ³•å¾‹æ¨ç†çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚Legal$Î”$åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨åŒæ¨¡å¼è¾“å…¥è®¾ç½®ï¼Œæœ€å¤§åŒ–ç›´æ¥ç­”æ¡ˆä¸æ¨ç†å¢å¼ºæ¨¡å¼ä¹‹é—´çš„ä¿¡æ¯å¢ç›Šï¼Œä»è€Œé¼“åŠ±æ¨¡å‹è·å–æœ‰æ„ä¹‰çš„æ¨ç†æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLegal$Î”$åœ¨å¤šä¸ªæ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­è¶…è¶Šäº†å¼ºåŸºçº¿ï¼Œåœ¨å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ä¸Šå‡è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„æ³•å¾‹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚çš„æ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­ï¼Œå¾€å¾€ç¼ºä¹å¯é æ€§å’Œå¯è§£é‡Šæ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„ç­”æ¡ˆç¼ºä¹å¤šæ­¥éª¤æ¨ç†çš„æ”¯æŒï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„Legal$Î”$æ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ ç»“åˆé“¾å¼æ€ç»´å¼•å¯¼çš„ä¿¡æ¯å¢ç›Šï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæ›´ä¸ºæ·±åˆ»å’Œå¯é çš„æ³•å¾‹åˆ¤æ–­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLegal$Î”$é‡‡ç”¨åŒæ¨¡å¼è¾“å…¥è®¾ç½®ï¼ŒåŒ…æ‹¬ç›´æ¥ç­”æ¡ˆæ¨¡å¼å’Œæ¨ç†å¢å¼ºæ¨¡å¼ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡æœ€å¤§åŒ–è¿™ä¸¤ç§æ¨¡å¼ä¹‹é—´çš„ä¿¡æ¯å¢ç›Šï¼Œé€æ­¥æç‚¼å‡ºæœ‰æ•ˆçš„æ¨ç†æ¨¡å¼ã€‚æ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆä»å¼ºå¤§çš„å¤§å‹æ¨ç†æ¨¡å‹DeepSeek-R1ä¸­æç‚¼æ½œåœ¨æ¨ç†èƒ½åŠ›ï¼Œå…¶æ¬¡é€šè¿‡å·®å¼‚æ¯”è¾ƒå’Œå¤šç»´å¥–åŠ±æœºåˆ¶æ¥ä¼˜åŒ–æ¨ç†è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šLegal$Î”$çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŒæ¨¡å¼è¾“å…¥å’Œä¿¡æ¯å¢ç›Šæœ€å¤§åŒ–ç­–ç•¥ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€ç­”æ¡ˆç”Ÿæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚é€šè¿‡å¼•å¯¼æ¨¡å‹å…³æ³¨æ¨ç†è¿‡ç¨‹è€Œéä»…ä»…ç­”æ¡ˆï¼Œæå‡äº†æ³•å¾‹æ¨ç†çš„æ·±åº¦å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒLegal$Î”$é‡‡ç”¨äº†å¤šç»´å¥–åŠ±æœºåˆ¶ï¼Œè¯„ä¼°æ¨ç†çš„ç»“æ„ä¸€è‡´æ€§å’Œæ³•å¾‹é¢†åŸŸçš„ç‰¹å¼‚æ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†æ¨ç†çš„è´¨é‡ä¸ä¿¡æ¯å¢ç›Šä¹‹é—´çš„å¹³è¡¡ï¼Œç¡®ä¿ç”Ÿæˆçš„æ¨ç†è¿‡ç¨‹æ—¢æœ‰æ·±åº¦åˆå…·å¤‡å¯è§£é‡Šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLegal$Î”$åœ¨å¤šä¸ªæ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§å‡æ˜¾è‘—é«˜äºå¼ºåŸºçº¿æ¨¡å‹ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ã€‚è¯¥æ¨¡å‹åœ¨ä¸ä¾èµ–æ ‡æ³¨åå¥½æ•°æ®çš„æƒ…å†µä¸‹ï¼ŒæŒç»­ç”Ÿæˆæ›´ä¸ºç¨³å¥å’Œå¯ä¿¡çš„æ³•å¾‹åˆ¤æ–­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹å’¨è¯¢ã€æ™ºèƒ½åˆçº¦å®¡æŸ¥å’Œå¸æ³•åˆ¤å†³è¾…åŠ©ç­‰ã€‚é€šè¿‡æå‡æ³•å¾‹æ¨ç†çš„å¯é æ€§ä¸å¯è§£é‡Šæ€§ï¼ŒLegal$Î”$èƒ½å¤Ÿä¸ºæ³•å¾‹ä»ä¸šè€…æä¾›æ›´ä¸ºç²¾å‡†çš„å†³ç­–æ”¯æŒï¼Œè¿›è€Œæ¨åŠ¨æ³•å¾‹äººå·¥æ™ºèƒ½çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Legal Artificial Intelligence (LegalAI) has achieved notable advances in automating judicial decision-making with the support of Large Language Models (LLMs). However, existing legal LLMs still struggle to generate reliable and interpretable reasoning processes. They often default to fast-thinking behavior by producing direct answers without explicit multi-step reasoning, limiting their effectiveness in complex legal scenarios that demand rigorous justification. To address this challenge, we propose Legal$Î”$, a reinforcement learning framework designed to enhance legal reasoning through chain-of-thought guided information gain. During training, Legal$Î”$ employs a dual-mode input setup-comprising direct answer and reasoning-augmented modes-and maximizes the information gain between them. This encourages the model to acquire meaningful reasoning patterns rather than generating superficial or redundant explanations. Legal$Î”$ follows a two-stage approach: (1) distilling latent reasoning capabilities from a powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning quality via differential comparisons, combined with a multidimensional reward mechanism that assesses both structural coherence and legal-domain specificity. Experimental results on multiple legal reasoning tasks demonstrate that Legal$Î”$ outperforms strong baselines in both accuracy and interpretability. It consistently produces more robust and trustworthy legal judgments without relying on labeled preference data. All code and data will be released at https://github.com/NEUIR/LegalDelta.

