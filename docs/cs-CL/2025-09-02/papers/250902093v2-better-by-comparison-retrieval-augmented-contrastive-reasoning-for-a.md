---
layout: default
title: Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization
---

# Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02093" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02093v2</a>
  <a href="https://arxiv.org/pdf/2509.02093.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02093v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02093v2', 'Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Juhyeon Lee, Wonduk Seo, Hyunjin An, Seunghyun Lee, Yi Bu

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02 (æ›´æ–°: 2025-10-03)

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹æ¯”æ¨ç†æç¤ºä¼˜åŒ–ï¼ˆCRPOï¼‰ï¼Œé€šè¿‡æ£€ç´¢å¢å¼ºå¯¹æ¯”å­¦ä¹ æå‡LLMæç¤ºè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æç¤ºä¼˜åŒ–` `å¯¹æ¯”å­¦ä¹ ` `æ£€ç´¢å¢å¼º` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨æç¤ºå·¥ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªåŠ¨æç¤ºä¼˜åŒ–æ–¹æ³•ä¾§é‡äºç›´æ¥æ”¹è¿›æˆ–å¾®è°ƒï¼Œå¿½ç•¥äº†LLMä»å¯¹æ¯”ç¤ºä¾‹ä¸­å­¦ä¹ æ¨ç†çš„èƒ½åŠ›ã€‚
2. CRPOæ¡†æ¶å°†æç¤ºä¼˜åŒ–è§†ä¸ºæ£€ç´¢å¢å¼ºçš„æ¨ç†è¿‡ç¨‹ï¼Œé€šè¿‡å¯¹æ¯”ä¸åŒè´¨é‡çš„æç¤º-å“åº”å¯¹è¿›è¡Œå­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCRPOåœ¨HelpSteer2åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæå‡äº†æç¤ºä¼˜åŒ–çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨æç¤ºä¼˜åŒ–å·²æˆä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æç¤ºè´¨é‡çš„æœ‰æ•ˆç­–ç•¥ï¼Œæ—¨åœ¨ç”Ÿæˆæ›´å‡†ç¡®å’Œæœ‰ç”¨çš„å“åº”ã€‚ç„¶è€Œï¼Œç°æœ‰å·¥ä½œä¸»è¦é›†ä¸­äºç›´æ¥æç¤ºæ”¹è¿›æˆ–æ¨¡å‹å¾®è°ƒï¼Œå¿½ç•¥äº†åˆ©ç”¨LLMå†…åœ¨æ¨ç†èƒ½åŠ›ä»å¯¹æ¯”ç¤ºä¾‹ä¸­å­¦ä¹ çš„æ½œåŠ›ã€‚æœ¬æ–‡æå‡ºäº†å¯¹æ¯”æ¨ç†æç¤ºä¼˜åŒ–ï¼ˆCRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†æç¤ºä¼˜åŒ–å½¢å¼åŒ–ä¸ºæ£€ç´¢å¢å¼ºæ¨ç†è¿‡ç¨‹çš„æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•ä»HelpSteer2æ•°æ®é›†ä¸­æ£€ç´¢å‰kä¸ªå‚è€ƒæç¤º-å“åº”å¯¹ï¼Œè¯¥æ•°æ®é›†æ˜¯ä¸€ä¸ªå¼€æºé›†åˆï¼Œå…¶ä¸­æ¯ä¸ªå“åº”éƒ½æ ‡æ³¨äº†helpfulnessã€correctnessã€coherenceã€complexityå’Œverbosityã€‚CRPOæ„å»ºäº†ä¸¤ç§äº’è¡¥çš„ä¼˜åŒ–èŒƒå¼ï¼šï¼ˆ1ï¼‰åˆ†å±‚å¯¹æ¯”æ¨ç†ï¼ŒLLMæ¯”è¾ƒé«˜è´¨é‡ã€ä¸­ç­‰è´¨é‡å’Œä½è´¨é‡çš„ç¤ºä¾‹ï¼ˆåŒ…æ‹¬æç¤ºå’Œå“åº”ï¼‰ï¼Œé€šè¿‡åæ€æ€§æ¨ç†æ¥æ”¹è¿›å…¶è‡ªèº«çš„ç”Ÿæˆï¼›ï¼ˆ2ï¼‰å¤šæŒ‡æ ‡å¯¹æ¯”æ¨ç†ï¼ŒLLMåˆ†ææ¯ä¸ªè¯„ä¼°ç»´åº¦ä¸Šçš„æœ€ä½³ç¤ºä¾‹ï¼Œå¹¶å°†å®ƒä»¬çš„ä¼˜åŠ¿æ•´åˆåˆ°ä¼˜åŒ–çš„æç¤ºä¸­ã€‚é€šè¿‡æ˜¾å¼å¯¹æ¯”é«˜è´¨é‡å’Œä½è´¨é‡çš„ç¤ºä¾‹ï¼ŒCRPOä½¿æ¨¡å‹èƒ½å¤Ÿæ¨æ–­å‡ºä¸ºä»€ä¹ˆæŸäº›æç¤ºæˆåŠŸè€Œå¦ä¸€äº›æç¤ºå¤±è´¥ï¼Œä»è€Œå®ç°æ›´é²æ£’å’Œå¯è§£é‡Šçš„ä¼˜åŒ–ã€‚åœ¨HelpSteer2åŸºå‡†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCRPOæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚ç ”ç©¶ç»“æœçªå‡ºäº†å¯¹æ¯”çš„ã€æ£€ç´¢å¢å¼ºçš„æ¨ç†åœ¨æ¨è¿›è‡ªåŠ¨æç¤ºä¼˜åŒ–æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æ›´æœ‰æ•ˆåœ°è¿›è¡Œè‡ªåŠ¨æç¤ºä¼˜åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºç›´æ¥çš„æç¤ºä¿®æ”¹æˆ–æ¨¡å‹å¾®è°ƒï¼Œç¼ºä¹åˆ©ç”¨LLMè‡ªèº«æ¨ç†èƒ½åŠ›ä»å¯¹æ¯”ç¤ºä¾‹ä¸­å­¦ä¹ çš„æœºåˆ¶ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥è§£é‡Šä¼˜åŒ–è¿‡ç¨‹ï¼Œä¸”å¯èƒ½ä¸å¤Ÿé²æ£’ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„å¯¹æ¯”æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ£€ç´¢å¹¶å¯¹æ¯”é«˜è´¨é‡å’Œä½è´¨é‡çš„æç¤º-å“åº”å¯¹ï¼Œè®©LLMå­¦ä¹ åˆ°æˆåŠŸæç¤ºçš„è¦ç´ å’Œå¤±è´¥æç¤ºçš„ä¸è¶³ã€‚è¿™ç§å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼èƒ½å¤Ÿå¸®åŠ©LLMæ›´å¥½åœ°ç†è§£æç¤ºçš„æœ‰æ•ˆæ€§ï¼Œä»è€Œç”Ÿæˆæ›´ä¼˜çš„æç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRPOæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šæ£€ç´¢é˜¶æ®µå’Œå¯¹æ¯”æ¨ç†é˜¶æ®µã€‚åœ¨æ£€ç´¢é˜¶æ®µï¼Œä»HelpSteer2æ•°æ®é›†ä¸­æ£€ç´¢ä¸å½“å‰ä»»åŠ¡ç›¸å…³çš„top-kä¸ªæç¤º-å“åº”å¯¹ã€‚åœ¨å¯¹æ¯”æ¨ç†é˜¶æ®µï¼ŒCRPOæ„å»ºäº†ä¸¤ç§å¯¹æ¯”æ¨ç†èŒƒå¼ï¼šåˆ†å±‚å¯¹æ¯”æ¨ç†å’Œå¤šæŒ‡æ ‡å¯¹æ¯”æ¨ç†ã€‚åˆ†å±‚å¯¹æ¯”æ¨ç†æ¯”è¾ƒé«˜è´¨é‡ã€ä¸­ç­‰è´¨é‡å’Œä½è´¨é‡çš„ç¤ºä¾‹ï¼Œè€Œå¤šæŒ‡æ ‡å¯¹æ¯”æ¨ç†åˆ™åˆ†ææ¯ä¸ªè¯„ä¼°ç»´åº¦ä¸Šçš„æœ€ä½³ç¤ºä¾‹ã€‚LLMé€šè¿‡å¯¹è¿™äº›ç¤ºä¾‹è¿›è¡Œåæ€æ€§æ¨ç†ï¼Œä»è€Œä¼˜åŒ–æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šCRPOçš„å…³é”®åˆ›æ–°åœ¨äºå°†å¯¹æ¯”å­¦ä¹ å’Œæ£€ç´¢å¢å¼ºç›¸ç»“åˆï¼Œç”¨äºè‡ªåŠ¨æç¤ºä¼˜åŒ–ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒCRPOä¸æ˜¯ç›´æ¥ä¿®æ”¹æç¤ºï¼Œè€Œæ˜¯é€šè¿‡å¯¹æ¯”å­¦ä¹ è®©LLMç†è§£æç¤ºçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒCRPOè¿˜æå‡ºäº†åˆ†å±‚å¯¹æ¯”æ¨ç†å’Œå¤šæŒ‡æ ‡å¯¹æ¯”æ¨ç†ä¸¤ç§æ–°çš„å¯¹æ¯”æ¨ç†èŒƒå¼ã€‚

**å…³é”®è®¾è®¡**ï¼šCRPOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨HelpSteer2æ•°æ®é›†ä½œä¸ºæ£€ç´¢çš„çŸ¥è¯†åº“ï¼›2) è®¾è®¡äº†åˆ†å±‚å¯¹æ¯”æ¨ç†å’Œå¤šæŒ‡æ ‡å¯¹æ¯”æ¨ç†ä¸¤ç§å¯¹æ¯”æ¨ç†èŒƒå¼ï¼›3) ä½¿ç”¨LLMï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰ä½œä¸ºæ¨ç†å¼•æ“ï¼Œé€šè¿‡promptingçš„æ–¹å¼å¼•å¯¼LLMè¿›è¡Œå¯¹æ¯”åˆ†æå’Œæç¤ºä¼˜åŒ–ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚æœªåœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CRPOåœ¨HelpSteer2åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å¯¹æ¯”æ¨ç†å’Œæ£€ç´¢å¢å¼ºåœ¨æç¤ºä¼˜åŒ–ä¸­çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æåˆ°ï¼Œä½†æœªç»™å‡ºå…·ä½“æ•°å€¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCRPOèƒ½å¤Ÿç”Ÿæˆæ›´é²æ£’å’Œå¯è§£é‡Šçš„ä¼˜åŒ–æç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CRPOå¯åº”ç”¨äºå„ç§éœ€è¦æç¤ºå·¥ç¨‹çš„LLMåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡è‡ªåŠ¨ä¼˜åŒ–æç¤ºï¼Œå¯ä»¥æå‡LLMçš„æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒï¼Œé™ä½äººå·¥è®¾è®¡æç¤ºçš„æˆæœ¬ã€‚è¯¥ç ”ç©¶å¯¹äºæå‡LLMçš„å¯ç”¨æ€§å’Œå¯è§£é‡Šæ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Automatic prompt optimization has recently emerged as a strategy for improving the quality of prompts used in Large Language Models (LLMs), with the goal of generating more accurate and useful responses. However, most prior work focuses on direct prompt refinement or model fine-tuning, overlooking the potential of leveraging LLMs' inherent reasoning capability to learn from contrasting examples. In this paper, we present Contrastive Reasoning Prompt Optimization (CRPO), a novel framework that formulates prompt optimization as a retrieval-augmented reasoning process. Our approach retrieves top k reference prompt-response pairs from the HelpSteer2 dataset, an open source collection where each response is annotated for helpfulness, correctness, coherence, complexity, and verbosity, and constructs two complementary optimization paradigms: (1) tiered contrastive reasoning, where the LLM compares high-, medium-, and low-quality exemplars (both prompts and responses) to refine its own generation through reflective reasoning, and (2) multi-metric contrastive reasoning, where the LLM analyzes the best exemplars along each evaluation dimension and integrates their strengths into an optimized prompt. By explicitly contrasting high and low quality exemplars, CRPO enables the model to deduce why certain prompts succeed while others fail, thereby achieving more robust and interpretable optimization. Experimental results on the HelpSteer2 benchmark demonstrate that CRPO significantly outperforms baselines. Our findings highlight the promise of contrastive, retrieval-augmented reasoning for advancing automatic prompt optimization.

