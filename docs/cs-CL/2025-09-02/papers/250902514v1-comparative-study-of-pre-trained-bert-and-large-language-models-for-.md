---
layout: default
title: Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition
---

# Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02514" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02514v1</a>
  <a href="https://arxiv.org/pdf/2509.02514.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02514v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02514v1', 'Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mayur Shirke, Amey Shembade, Pavan Thorat, Madhushri Wagh, Raviraj Joshi

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”ç ”ç©¶é¢„è®­ç»ƒBERTä¸å¤§è¯­è¨€æ¨¡å‹åœ¨Code-Mixedå‘½åå®ä½“è¯†åˆ«ä¸­çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Code-Mixedæ–‡æœ¬` `å‘½åå®ä½“è¯†åˆ«` `é¢„è®­ç»ƒæ¨¡å‹` `Hinglish` `å¤§è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. Code-Mixedæ–‡æœ¬NERé¢ä¸´éæ­£å¼ç»“æ„ã€éŸ³è¯‘å’Œé¢‘ç¹è¯­è¨€åˆ‡æ¢çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†ã€‚
2. è®ºæ–‡å¯¹æ¯”äº†åœ¨Code-Mixedæ•°æ®ä¸Šå¾®è°ƒçš„æ¨¡å‹ã€éCode-Mixedå¤šè¯­è¨€æ¨¡å‹ä»¥åŠé›¶æ ·æœ¬LLMï¼Œæ¢ç©¶å…¶åœ¨Code-Mixed NERä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Code-Mixedæ•°æ®ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½æ›´ä¼˜ï¼Œç”šè‡³è¶…è¿‡äº†é—­æºLLMï¼Œè¯æ˜äº†é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶å¯¹æ¯”è¯„ä¼°äº†åœ¨Code-Mixedæ–‡æœ¬ï¼ˆç‰¹åˆ«æ˜¯å°åœ°è¯­-è‹±è¯­æ··åˆæ–‡æœ¬Hinglishï¼‰ä¸Šè¿›è¡Œå‘½åå®ä½“è¯†åˆ«(NER)çš„å¤šç§æ¨¡å‹ï¼ŒåŒ…æ‹¬åœ¨Code-Mixedæ•°æ®ä¸Šå¾®è°ƒçš„æ¨¡å‹ã€éCode-Mixedå¤šè¯­è¨€æ¨¡å‹ä»¥åŠé›¶æ ·æœ¬ç”Ÿæˆå¼å¤§è¯­è¨€æ¨¡å‹(LLM)ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è¯„ä¼°äº†HingBERTã€HingMBERTå’ŒHingRoBERTaï¼ˆåœ¨Code-Mixedæ•°æ®ä¸Šè®­ç»ƒï¼‰ï¼Œä»¥åŠBERT Base Casedã€IndicBERTã€RoBERTaå’ŒMuRILï¼ˆåœ¨éCode-Mixedå¤šè¯­è¨€æ•°æ®ä¸Šè®­ç»ƒï¼‰ã€‚æˆ‘ä»¬è¿˜ä½¿ç”¨å»é™¤äº†NERæ ‡ç­¾çš„æ•°æ®é›†ä¿®æ”¹ç‰ˆæœ¬ï¼Œè¯„ä¼°äº†Google Geminiåœ¨é›¶æ ·æœ¬ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚æ‰€æœ‰æ¨¡å‹å‡åœ¨åŸºå‡†Hinglish NERæ•°æ®é›†ä¸Šä½¿ç”¨ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°è¿›è¡Œæµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼Œç”±äºé¢†åŸŸç‰¹å®šçš„é¢„è®­ç»ƒï¼ŒCode-Mixedæ¨¡å‹ï¼ˆç‰¹åˆ«æ˜¯åŸºäºHingRoBERTaå’ŒHingBERTå¾®è°ƒçš„æ¨¡å‹ï¼‰ä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒåŒ…æ‹¬åƒGoogle Geminiè¿™æ ·çš„é—­æºLLMã€‚éCode-Mixedæ¨¡å‹çš„è¡¨ç°å°šå¯ï¼Œä½†é€‚åº”æ€§æœ‰é™ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGoogle Geminiè¡¨ç°å‡ºå…·æœ‰ç«äº‰åŠ›çš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œçªæ˜¾äº†ç°ä»£LLMçš„æ³›åŒ–èƒ½åŠ›ã€‚æœ¬ç ”ç©¶ä¸ºCode-Mixed NERä»»åŠ¡ä¸­ä¸“ç”¨æ¨¡å‹ä¸é€šç”¨æ¨¡å‹çš„æœ‰æ•ˆæ€§æä¾›äº†å…³é”®è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Code-Mixedæ–‡æœ¬ï¼ˆç‰¹åˆ«æ˜¯Hinglishï¼‰ä¸­çš„å‘½åå®ä½“è¯†åˆ«é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚é€šç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤„ç†è¿™ç§æ··åˆè¯­è¨€çš„éæ­£å¼æ–‡æœ¬æ—¶ï¼Œç”±äºç¼ºä¹å¯¹ç‰¹å®šè¯­è¨€æ··åˆæ¨¡å¼çš„ç†è§£ï¼Œæ€§èƒ½ä¼šå—åˆ°é™åˆ¶ã€‚æ­¤å¤–ï¼Œæ ‡æ³¨æ•°æ®ç¨€ç¼ºä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¯”è¾ƒä¸åŒç±»å‹çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…æ‹¬åœ¨Code-Mixedæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å’Œé€šç”¨å¤šè¯­è¨€æ¨¡å‹ï¼Œæ¥è¯„ä¼°å®ƒä»¬åœ¨Code-Mixed NERä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œè¿˜è€ƒå¯Ÿäº†é›¶æ ·æœ¬LLMçš„æ€§èƒ½ï¼Œä»¥äº†è§£å…¶æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡è¿™ç§å¯¹æ¯”ï¼Œæ—¨åœ¨æ­ç¤ºé¢†åŸŸç‰¹å®šé¢„è®­ç»ƒå¯¹äºCode-Mixed NERçš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŒ…æ‹¬HingBERTã€HingMBERTã€HingRoBERTaã€BERT Base Casedã€IndicBERTã€RoBERTaå’ŒMuRILã€‚2) å¯¹éƒ¨åˆ†æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿ç”¨Hinglish NERæ•°æ®é›†ã€‚3) ä½¿ç”¨ä¿®æ”¹åçš„æ•°æ®é›†è¯„ä¼°Google Geminiçš„é›¶æ ·æœ¬æ€§èƒ½ã€‚4) ä½¿ç”¨ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ç­‰æŒ‡æ ‡è¯„ä¼°æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹å¤šç§æ¨¡å‹åœ¨Code-Mixed NERä»»åŠ¡ä¸­çš„å…¨é¢å¯¹æ¯”è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯å¯¹åœ¨Code-Mixedæ•°æ®ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹å’Œé›¶æ ·æœ¬LLMçš„æ€§èƒ½è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è¿™ä¸ºé€‰æ‹©åˆé€‚çš„æ¨¡å‹ä»¥åŠç†è§£é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒçš„é‡è¦æ€§æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©äº†ä¸€ç³»åˆ—å…·æœ‰ä»£è¡¨æ€§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¶µç›–äº†åœ¨Code-Mixedæ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹å’Œé€šç”¨å¤šè¯­è¨€æ¨¡å‹ã€‚2) ä½¿ç”¨äº†æ ‡å‡†çš„Hinglish NERæ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œä¿è¯äº†ç»“æœçš„å¯æ¯”æ€§ã€‚3) é‡‡ç”¨äº†å¸¸ç”¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ï¼Œå¯¹æ¨¡å‹çš„æ€§èƒ½è¿›è¡Œé‡åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Code-Mixedæ•°æ®ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ï¼ˆå¦‚HingRoBERTaå’ŒHingBERTï¼‰åœ¨Hinglish NERä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œä¼˜äºé€šç”¨å¤šè¯­è¨€æ¨¡å‹å’ŒGoogle Geminiç­‰é—­æºLLMã€‚è¿™çªæ˜¾äº†é¢†åŸŸç‰¹å®šé¢„è®­ç»ƒå¯¹äºå¤„ç†Code-Mixedæ–‡æœ¬çš„é‡è¦æ€§ã€‚Google Geminiè™½ç„¶åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¡¨ç°å‡ºç«äº‰åŠ›ï¼Œä½†ä»ä¸å¦‚ç»è¿‡å¾®è°ƒçš„Code-Mixedæ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“åˆ†æã€å®¢æˆ·æœåŠ¡ã€èˆ†æƒ…ç›‘æ§ç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨å°åº¦ç­‰æ··åˆè¯­è¨€ä½¿ç”¨å¹¿æ³›çš„åœ°åŒºã€‚é€šè¿‡æå‡Code-Mixedæ–‡æœ¬çš„NERå‡†ç¡®ç‡ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æå–å…³é”®ä¿¡æ¯ï¼Œä»è€Œæ”¯æŒæ›´æ™ºèƒ½çš„å†³ç­–å’Œè‡ªåŠ¨åŒ–æµç¨‹ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–Code-Mixedè¯­è¨€å¯¹ï¼Œå¹¶æ¢ç´¢æ›´å…ˆè¿›çš„æ¨¡å‹æ¶æ„ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English (Hinglish), presents unique challenges due to informal structure, transliteration, and frequent language switching. This study conducts a comparative evaluation of code-mixed fine-tuned models and non-code-mixed multilingual models, along with zero-shot generative large language models (LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained on code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained on non-code-mixed multilingual data). We also assess the performance of Google Gemini in a zero-shot setting using a modified version of the dataset with NER tags removed. All models are tested on a benchmark Hinglish NER dataset using Precision, Recall, and F1-score. Results show that code-mixed models, particularly HingRoBERTa and HingBERT-based fine-tuned models, outperform others - including closed-source LLMs like Google Gemini - due to domain-specific pretraining. Non-code-mixed models perform reasonably but show limited adaptability. Notably, Google Gemini exhibits competitive zero-shot performance, underlining the generalization strength of modern LLMs. This study provides key insights into the effectiveness of specialized versus generalized models for code-mixed NER tasks.

