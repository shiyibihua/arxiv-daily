---
layout: default
title: Jointly Reinforcing Diversity and Quality in Language Model Generations
---

# Jointly Reinforcing Diversity and Quality in Language Model Generations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02534" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02534v1</a>
  <a href="https://arxiv.org/pdf/2509.02534.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02534v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02534v1', 'Jointly Reinforcing Diversity and Quality in Language Model Generations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianjian Li, Yiming Zhang, Ping Yu, Swarnadeep Saha, Daniel Khashabi, Jason Weston, Jack Lanchantin, Tianlu Wang

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

**å¤‡æ³¨**: 29 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDARLINGæ¡†æ¶ï¼Œè”åˆå¼ºåŒ–è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å¤šæ ·æ€§å’Œè´¨é‡ï¼Œæå‡åˆ›é€ æ€§ä»»åŠ¡è¡¨ç°ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å¤šæ ·æ€§ç”Ÿæˆ` `è‡ªç„¶è¯­è¨€ç”Ÿæˆ` `åˆ›é€ æ€§ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€æ¨¡å‹åè®­ç»ƒä¾§é‡è´¨é‡è€Œç‰ºç‰²äº†ç”Ÿæˆå†…å®¹çš„å¤šæ ·æ€§ï¼Œé™åˆ¶äº†å…¶åœ¨åˆ›é€ æ€§ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. DARLINGæ¡†æ¶é€šè¿‡å­¦ä¹ é…åˆ†å‡½æ•°æ¥è¡¡é‡è¯­ä¹‰å¤šæ ·æ€§ï¼Œå¹¶å°†å…¶ä¸è´¨é‡å¥–åŠ±ç»“åˆï¼Œè¿›è¡Œè”åˆä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDARLINGåœ¨æŒ‡ä»¤è·Ÿéšã€åˆ›æ„å†™ä½œå’Œç«èµ›æ•°å­¦ç­‰ä»»åŠ¡ä¸­ï¼Œå‡ä¼˜äºä»…å…³æ³¨è´¨é‡çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰çš„åè®­ç»ƒé€šå¸¸ä¼˜å…ˆè€ƒè™‘å‡†ç¡®æ€§å’Œæœ‰ç”¨æ€§ï¼Œä½†ç‰ºç‰²äº†å¤šæ ·æ€§ã€‚è¿™ç§ç°è±¡é€ æˆäº†ä¸€ç§çŸ›ç›¾ï¼šåè®­ç»ƒè™½ç„¶æé«˜äº†å“åº”è´¨é‡ï¼Œä½†ä¹Ÿé”åŒ–äº†è¾“å‡ºåˆ†å¸ƒï¼Œå‡å°‘äº†æƒ³æ³•çš„èŒƒå›´ï¼Œé™åˆ¶äº†LMåœ¨å¤´è„‘é£æš´ã€æ•…äº‹è®²è¿°æˆ–é—®é¢˜è§£å†³ç­‰åˆ›é€ æ€§å’Œæ¢ç´¢æ€§ä»»åŠ¡ä¸­çš„æ•ˆç”¨ã€‚æœ¬æ–‡æå‡ºäº†å¤šæ ·æ€§æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ï¼ˆDARLINGï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è”åˆä¼˜åŒ–å“åº”è´¨é‡å’Œè¯­ä¹‰å¤šæ ·æ€§ã€‚DARLINGçš„æ ¸å¿ƒæ˜¯å¼•å…¥äº†ä¸€ä¸ªå­¦ä¹ åˆ°çš„é…åˆ†å‡½æ•°ï¼Œä»¥è¡¡é‡è¶…å‡ºè¡¨é¢è¯æ±‡å˜åŒ–çš„å¤šæ ·æ€§ã€‚ç„¶åï¼Œåœ¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ æœŸé—´ï¼Œå°†è¿™ç§å¤šæ ·æ€§ä¿¡å·ä¸è´¨é‡å¥–åŠ±ç›¸ç»“åˆï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡ä¸”ç‹¬ç‰¹çš„è¾“å‡ºã€‚åœ¨å¤šä¸ªæ¨¡å‹ç³»åˆ—å’Œè§„æ¨¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDARLINGå¯ä»¥æ¨å¹¿åˆ°ä¸¤ç§åœºæ™¯ï¼šä¸å¯éªŒè¯çš„ä»»åŠ¡ï¼ˆæŒ‡ä»¤è·Ÿéšå’Œåˆ›æ„å†™ä½œï¼‰å’Œå¯éªŒè¯çš„ä»»åŠ¡ï¼ˆç«èµ›æ•°å­¦ï¼‰ã€‚åœ¨ç¬¬ä¸€ç§åœºæ™¯çš„äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDARLINGå§‹ç»ˆä¼˜äºä»…å…³æ³¨è´¨é‡çš„å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œäº§ç”Ÿæ›´é«˜è´¨é‡å’Œæ–°é¢–æ€§çš„è¾“å‡ºã€‚åœ¨ç¬¬äºŒç§åœºæ™¯ä¸­ï¼ŒDARLINGå®ç°äº†æ›´é«˜çš„pass@1ï¼ˆè§£å†³æ–¹æ¡ˆè´¨é‡ï¼‰å’Œpass@kï¼ˆè§£å†³æ–¹æ¡ˆå¤šæ ·æ€§ï¼‰ã€‚æœ€å¼•äººæ³¨ç›®çš„æ˜¯ï¼Œæ˜¾å¼åœ°ä¼˜åŒ–å¤šæ ·æ€§å¯ä»¥ä¿ƒè¿›åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢ï¼Œä»è€Œäº§ç”Ÿæ›´é«˜è´¨é‡çš„å“åº”ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»è¿‡åè®­ç»ƒåï¼Œè™½ç„¶åœ¨å‡†ç¡®æ€§å’Œæœ‰ç”¨æ€§æ–¹é¢æœ‰æ‰€æå‡ï¼Œä½†ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§å´æ˜¾è‘—é™ä½ã€‚è¿™ä½¿å¾—å®ƒä»¬åœ¨éœ€è¦åˆ›é€ æ€§å’Œæ¢ç´¢æ€§çš„ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œä¾‹å¦‚å¤´è„‘é£æš´ã€æ•…äº‹åˆ›ä½œç­‰ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªå…³æ³¨æé«˜ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ï¼Œè€Œå¿½ç•¥äº†å¤šæ ·æ€§çš„é‡è¦æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDARLINGçš„æ ¸å¿ƒæ€è·¯æ˜¯åŒæ—¶ä¼˜åŒ–ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚é€šè¿‡å¼•å…¥ä¸€ä¸ªå¯å­¦ä¹ çš„é…åˆ†å‡½æ•°æ¥è¡¡é‡ç”Ÿæˆæ–‡æœ¬çš„è¯­ä¹‰å¤šæ ·æ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸€ä¸ªå¥–åŠ±ä¿¡å·ä¸è´¨é‡å¥–åŠ±ç›¸ç»“åˆï¼Œåœ¨å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ—¢é«˜è´¨é‡åˆå¤šæ ·çš„æ–‡æœ¬ã€‚è¿™æ ·å¯ä»¥é¼“åŠ±æ¨¡å‹æ¢ç´¢æ›´å¹¿é˜”çš„ç”Ÿæˆç©ºé—´ï¼Œé¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDARLINGæ¡†æ¶é‡‡ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œæ¨¡å‹ç”Ÿæˆä¸€æ®µæ–‡æœ¬ï¼›ç„¶åï¼Œè®¡ç®—è¯¥æ–‡æœ¬çš„è´¨é‡å¥–åŠ±å’Œå¤šæ ·æ€§å¥–åŠ±ï¼›æœ€åï¼Œå°†è¿™ä¸¤ä¸ªå¥–åŠ±ç»“åˆèµ·æ¥ï¼Œç”¨äºæ›´æ–°æ¨¡å‹çš„å‚æ•°ã€‚å…¶ä¸­ï¼Œå¤šæ ·æ€§å¥–åŠ±çš„è®¡ç®—ä¾èµ–äºä¸€ä¸ªå¯å­¦ä¹ çš„é…åˆ†å‡½æ•°ï¼Œè¯¥å‡½æ•°èƒ½å¤Ÿè¡¡é‡ç”Ÿæˆæ–‡æœ¬çš„è¯­ä¹‰å¤šæ ·æ€§ï¼Œè€Œä¸ä»…ä»…æ˜¯è¡¨é¢ä¸Šçš„è¯æ±‡å¤šæ ·æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šDARLINGçš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯å­¦ä¹ çš„é…åˆ†å‡½æ•°æ¥è¡¡é‡ç”Ÿæˆæ–‡æœ¬çš„è¯­ä¹‰å¤šæ ·æ€§ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè¯æ±‡å¤šæ ·æ€§çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ ç”Ÿæˆæ–‡æœ¬çš„è¯­ä¹‰å·®å¼‚ï¼Œä»è€Œæ›´å¥½åœ°å¼•å¯¼æ¨¡å‹ç”Ÿæˆå¤šæ ·çš„æ–‡æœ¬ã€‚æ­¤å¤–ï¼ŒDARLINGè¿˜é€šè¿‡è”åˆä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼Œé¿å…äº†ä¸¤è€…ä¹‹é—´çš„trade-offï¼Œå®ç°äº†åŒèµ¢ã€‚

**å…³é”®è®¾è®¡**ï¼šDARLINGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformeræ¨¡å‹ä½œä¸ºç”Ÿæˆæ¨¡å‹ï¼›2) ä½¿ç”¨REINFORCEç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼›3) ä½¿ç”¨å­¦ä¹ åˆ°çš„é…åˆ†å‡½æ•°æ¥è®¡ç®—å¤šæ ·æ€§å¥–åŠ±ï¼›4) å°†è´¨é‡å¥–åŠ±å’Œå¤šæ ·æ€§å¥–åŠ±è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°æœ€ç»ˆçš„å¥–åŠ±ä¿¡å·ã€‚é…åˆ†å‡½æ•°çš„å…·ä½“å½¢å¼æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒå…¶å¯å­¦ä¹ æ€§ä»¥åŠå¯¹è¯­ä¹‰å¤šæ ·æ€§çš„è¡¡é‡èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DARLINGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨ä¸å¯éªŒè¯çš„ä»»åŠ¡ï¼ˆæŒ‡ä»¤è·Ÿéšå’Œåˆ›æ„å†™ä½œï¼‰ä¸­ï¼ŒDARLINGå§‹ç»ˆä¼˜äºä»…å…³æ³¨è´¨é‡çš„å¼ºåŒ–å­¦ä¹ åŸºçº¿ï¼Œç”Ÿæˆæ›´é«˜è´¨é‡å’Œæ–°é¢–æ€§çš„è¾“å‡ºã€‚åœ¨å¯éªŒè¯çš„ä»»åŠ¡ï¼ˆç«èµ›æ•°å­¦ï¼‰ä¸­ï¼ŒDARLINGå®ç°äº†æ›´é«˜çš„pass@1ï¼ˆè§£å†³æ–¹æ¡ˆè´¨é‡ï¼‰å’Œpass@kï¼ˆè§£å†³æ–¹æ¡ˆå¤šæ ·æ€§ï¼‰ã€‚å°¤å…¶å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒDARLINGé€šè¿‡æ˜¾å¼åœ°ä¼˜åŒ–å¤šæ ·æ€§ï¼Œä¿ƒè¿›äº†åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„æ¢ç´¢ï¼Œä»è€Œäº§ç”Ÿäº†æ›´é«˜è´¨é‡çš„å“åº”ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DARLINGæ¡†æ¶å¯åº”ç”¨äºå„ç§éœ€è¦åˆ›é€ æ€§å’Œæ¢ç´¢æ€§çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ï¼šå¤´è„‘é£æš´ã€æ•…äº‹åˆ›ä½œã€é—®é¢˜è§£å†³ã€å¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·è·å¾—æ›´ä¸°å¯Œçš„çµæ„Ÿå’Œæ›´å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºæå‡è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾åŸŸåœºæ™¯ä¸‹çš„åº”ç”¨èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å„ç§å¤æ‚å’Œä¸ç¡®å®šçš„ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Post-training of Large Language Models (LMs) often prioritizes accuracy and helpfulness at the expense of diversity. This creates a tension: while post-training improves response quality, it also sharpens output distributions and reduces the range of ideas, limiting the usefulness of LMs in creative and exploratory tasks such as brainstorming, storytelling, or problem solving. We address this challenge with Diversity-Aware Reinforcement Learning (DARLING), a framework that jointly optimizes for response quality and semantic diversity. At its core, DARLING introduces a learned partition function to measure diversity beyond surface-level lexical variations. This diversity signal is then combined with a quality reward during online reinforcement learning, encouraging models to generate outputs that are both high-quality and distinct. Experiments across multiple model families and sizes show that DARLING generalizes to two regimes: non-verifiable tasks (instruction following and creative writing) and verifiable tasks (competition math). On five benchmarks in the first setting, DARLING consistently outperforms quality-only RL baselines, producing outputs that are simultaneously of higher quality and novelty. In the second setting, DARLING achieves higher pass@1 (solution quality) and pass@k (solution variety). Most strikingly, explicitly optimizing for diversity catalyzes exploration in online RL, which manifests itself as higher-quality responses.

