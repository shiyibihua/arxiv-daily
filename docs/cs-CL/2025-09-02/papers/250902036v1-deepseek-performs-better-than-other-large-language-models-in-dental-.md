---
layout: default
title: DeepSeek performs better than other Large Language Models in Dental Cases
---

# DeepSeek performs better than other Large Language Models in Dental Cases

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02036" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02036v1</a>
  <a href="https://arxiv.org/pdf/2509.02036.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02036v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02036v1', 'DeepSeek performs better than other Large Language Models in Dental Cases')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hexian Zhang, Xinyu Yan, Yanqi Yang, Lijian Jin, Ping Yang, Junwen Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

**å¤‡æ³¨**: Abstract word count: 171; Total word count: 3130; Total number of tables: 2; Total number of figures: 3; Number of references: 32

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DeepSeekåœ¨å¤§è¯­è¨€æ¨¡å‹ç‰™ç§‘ç—…ä¾‹åˆ†æä¸­è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰™ç§‘ç—…ä¾‹åˆ†æ` `çºµå‘æ•°æ®` `åŒ»ç–—ä¿å¥` `DeepSeek` `ä¸´åºŠå†³ç­–æ”¯æŒ` `æ¨¡å‹è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£è¯»çºµå‘æ‚£è€…å™è¿°æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸã€‚
2. è¯¥ç ”ç©¶åˆ©ç”¨ç‰™ç§‘ç—…ä¾‹æ•°æ®ï¼Œè¯„ä¼°äº†å¤šä¸ªLLMåœ¨åˆ†æçºµå‘ç‰™å‘¨ç—…ä¾‹æ‘˜è¦æ–¹é¢çš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepSeekæ¨¡å‹åœ¨å¿ å®æ€§å’Œä¸“å®¶è¯„åˆ†æ–¹é¢å‡ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œæˆä¸ºæ¡ˆä¾‹åˆ†æçš„é¢†å…ˆLLMã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åŒ»ç–—ä¿å¥é¢†åŸŸå…·æœ‰å˜é©æ½œåŠ›ï¼Œä½†å…¶è§£è¯»çºµå‘æ‚£è€…å™è¿°çš„èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç‰™ç§‘æ‹¥æœ‰ä¸°å¯Œçš„ç»“æ„åŒ–ä¸´åºŠæ•°æ®ï¼Œä¸ºä¸¥æ ¼è¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›æä¾›äº†ç‹¬ç‰¹çš„æœºä¼šã€‚è™½ç„¶å·²ç»å­˜åœ¨ä¸€äº›å•†ä¸šLLMï¼Œä½†ä»Šå¹´æ—©äº›æ—¶å€™å¤‡å—å…³æ³¨çš„DeepSeekä¹ŸåŠ å…¥äº†ç«äº‰ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†å››ç§æœ€å…ˆè¿›çš„LLMï¼ˆGPT-4oã€Gemini 2.0 Flashã€Copilotå’ŒDeepSeek V3ï¼‰é€šè¿‡å¼€æ”¾å¼ä¸´åºŠä»»åŠ¡åˆ†æçºµå‘ç‰™ç§‘ç—…ä¾‹æ‘˜è¦çš„èƒ½åŠ›ã€‚ä½¿ç”¨34ä¸ªæ ‡å‡†åŒ–çš„çºµå‘ç‰™å‘¨ç—…ä¾‹ï¼ˆåŒ…æ‹¬258ä¸ªé—®ç­”å¯¹ï¼‰ï¼Œæˆ‘ä»¬é€šè¿‡è‡ªåŠ¨æŒ‡æ ‡å’ŒæŒç‰Œç‰™åŒ»çš„ç›²æ³•è¯„ä¼°æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚DeepSeekè¡¨ç°æœ€ä½³ï¼Œå±•ç¤ºå‡ºå“è¶Šçš„å¿ å®æ€§ï¼ˆä¸­ä½æ•°å¾—åˆ†=0.528 vs. 0.367-0.457ï¼‰å’Œæ›´é«˜çš„ä¸“å®¶è¯„åˆ†ï¼ˆä¸­ä½æ•°=4.5/5 vs. 4.0/5ï¼‰ï¼Œä¸”æ²¡æœ‰æ˜¾è‘—é™ä½å¯è¯»æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶å°†DeepSeekå®šä½ä¸ºæ¡ˆä¾‹åˆ†æé¢†åŸŸé¢†å…ˆçš„LLMï¼Œæ”¯æŒå°†å…¶æ•´åˆä¸ºåŒ»å­¦æ•™è‚²å’Œç ”ç©¶çš„è¾…åŠ©å·¥å…·ï¼Œå¹¶å¼ºè°ƒå…¶ä½œä¸ºé¢†åŸŸç‰¹å®šä»£ç†çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰™ç§‘çºµå‘ç—…ä¾‹åˆ†æä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•ï¼Œå³å…¶ä»–LLMï¼Œåœ¨å¤„ç†æ­¤ç±»ä»»åŠ¡æ—¶ï¼Œå¯èƒ½å­˜åœ¨å¿ å®æ€§ä¸è¶³ã€ä¸“å®¶è¯„åˆ†è¾ƒä½ç­‰é—®é¢˜ï¼Œæ— æ³•å……åˆ†æ»¡è¶³åŒ»ç–—é¢†åŸŸå¯¹å‡†ç¡®æ€§å’Œå¯é æ€§çš„è¦æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºæ ‡å‡†åŒ–çš„çºµå‘ç‰™å‘¨ç—…ä¾‹æ•°æ®é›†ï¼Œå¹¶è®¾è®¡å¼€æ”¾å¼ä¸´åºŠä»»åŠ¡ï¼Œæ¥ç³»ç»Ÿåœ°è¯„ä¼°ä¸åŒLLMçš„æ€§èƒ½ã€‚é€šè¿‡è‡ªåŠ¨æŒ‡æ ‡å’Œä¸“å®¶ç›²æ³•è¯„ä¼°ï¼Œå®¢è§‚åœ°æ¯”è¾ƒå„æ¨¡å‹çš„å¿ å®æ€§ã€å¯è¯»æ€§å’Œä¸“å®¶è¯„åˆ†ï¼Œä»è€Œæ‰¾å‡ºæœ€é€‚åˆç‰™ç§‘ç—…ä¾‹åˆ†æçš„LLMã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ„å»ºæ ‡å‡†åŒ–çš„çºµå‘ç‰™å‘¨ç—…ä¾‹æ•°æ®é›†ï¼ŒåŒ…å«258ä¸ªé—®ç­”å¯¹ï¼›2) é€‰æ‹©å››ç§æœ€å…ˆè¿›çš„LLMï¼ˆGPT-4oã€Gemini 2.0 Flashã€Copilotå’ŒDeepSeek V3ï¼‰è¿›è¡Œè¯„ä¼°ï¼›3) è®¾è®¡å¼€æ”¾å¼ä¸´åºŠä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹åˆ†æç—…ä¾‹æ‘˜è¦å¹¶å›ç­”ç›¸å…³é—®é¢˜ï¼›4) ä½¿ç”¨è‡ªåŠ¨æŒ‡æ ‡ï¼ˆå¦‚å¿ å®æ€§å¾—åˆ†ï¼‰å’Œä¸“å®¶ç›²æ³•è¯„ä¼°æ¥è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼›5) å¯¹æ¯”åˆ†æå„æ¨¡å‹çš„è¡¨ç°ï¼Œæ‰¾å‡ºæœ€ä½³æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡ç³»ç»Ÿåœ°è¯„ä¼°äº†å¤šä¸ªLLMåœ¨ç‰™ç§‘çºµå‘ç—…ä¾‹åˆ†æä¸­çš„è¡¨ç°ï¼›2) é‡‡ç”¨äº†æ ‡å‡†åŒ–çš„ç—…ä¾‹æ•°æ®é›†å’Œå¼€æ”¾å¼ä¸´åºŠä»»åŠ¡ï¼Œä½¿å¾—è¯„ä¼°æ›´åŠ å®¢è§‚å’Œå¯æ¯”ï¼›3) ç»“åˆäº†è‡ªåŠ¨æŒ‡æ ‡å’Œä¸“å®¶è¯„ä¼°ï¼Œå…¨é¢åœ°è¯„ä¼°äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†34ä¸ªæ ‡å‡†åŒ–çš„çºµå‘ç‰™å‘¨ç—…ä¾‹ï¼Œæ¯ä¸ªç—…ä¾‹åŒ…å«å¤šä¸ªé—®ç­”å¯¹ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„ä¸´åºŠåœºæ™¯ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å¿ å®æ€§å¾—åˆ†ï¼ˆè¡¡é‡æ¨¡å‹å›ç­”ä¸ç—…ä¾‹ä¿¡æ¯çš„åŒ¹é…ç¨‹åº¦ï¼‰ã€å¯è¯»æ€§å¾—åˆ†ï¼ˆè¡¡é‡æ¨¡å‹å›ç­”çš„æµç•…æ€§å’Œæ˜“æ‡‚æ€§ï¼‰å’Œä¸“å®¶è¯„åˆ†ï¼ˆç”±æŒç‰Œç‰™åŒ»è¿›è¡Œç›²æ³•è¯„ä¼°ï¼‰ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepSeekæ¨¡å‹åœ¨ç‰™ç§‘çºµå‘ç—…ä¾‹åˆ†æä¸­è¡¨ç°æœ€ä½³ï¼Œå…¶å¿ å®æ€§ä¸­ä½æ•°å¾—åˆ†è¾¾åˆ°0.528ï¼Œæ˜¾è‘—é«˜äºå…¶ä»–æ¨¡å‹ï¼ˆ0.367-0.457ï¼‰ã€‚åŒæ—¶ï¼ŒDeepSeekçš„ä¸“å®¶è¯„åˆ†ä¸­ä½æ•°ä¹Ÿè¾¾åˆ°4.5/5ï¼Œé«˜äºå…¶ä»–æ¨¡å‹çš„4.0/5ã€‚è¿™äº›æ•°æ®è¡¨æ˜ï¼ŒDeepSeekåœ¨å¤„ç†ç‰™ç§‘ç—…ä¾‹åˆ†æä»»åŠ¡æ—¶å…·æœ‰æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»å­¦æ•™è‚²å’Œç ”ç©¶é¢†åŸŸï¼ŒDeepSeekæ¨¡å‹å¯ä½œä¸ºè¾…åŠ©å·¥å…·ï¼Œå¸®åŠ©å­¦ç”Ÿå’Œç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å’Œåˆ†æç‰™ç§‘ç—…ä¾‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å…·æœ‰ä½œä¸ºé¢†åŸŸç‰¹å®šä»£ç†çš„æ½œåŠ›ï¼Œå¯ä»¥ä¸ºç‰™ç§‘åŒ»ç”Ÿæä¾›å†³ç­–æ”¯æŒï¼Œæé«˜è¯Šæ–­å’Œæ²»ç–—çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–åŒ»å­¦é¢†åŸŸï¼Œä¸ºæ›´å¹¿æ³›çš„åŒ»ç–—ä¿å¥åº”ç”¨æä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) hold transformative potential in healthcare, yet their capacity to interpret longitudinal patient narratives remains inadequately explored. Dentistry, with its rich repository of structured clinical data, presents a unique opportunity to rigorously assess LLMs' reasoning abilities. While several commercial LLMs already exist, DeepSeek, a model that gained significant attention earlier this year, has also joined the competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini 2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal dental case vignettes through open-ended clinical tasks. Using 34 standardized longitudinal periodontal cases (comprising 258 question-answer pairs), we assessed model performance via automated metrics and blinded evaluations by licensed dentists. DeepSeek emerged as the top performer, demonstrating superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising readability. Our study positions DeepSeek as the leading LLM for case analysis, endorses its integration as an adjunct tool in both medical education and research, and highlights its potential as a domain-specific agent.

