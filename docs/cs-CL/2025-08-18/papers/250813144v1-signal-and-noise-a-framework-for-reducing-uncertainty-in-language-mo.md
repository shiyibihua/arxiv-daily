---
layout: default
title: Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation
---

# Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13144" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13144v1</a>
  <a href="https://arxiv.org/pdf/2508.13144.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13144v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13144v1', 'Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: David Heineman, Valentin Hofmann, Ian Magnusson, Yuling Gu, Noah A. Smith, Hannaneh Hajishirzi, Kyle Lo, Jesse Dodge

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¿¡å·ä¸å™ªå£°æ¡†æ¶ä»¥é™ä½è¯­è¨€æ¨¡å‹è¯„ä¼°çš„ä¸ç¡®å®šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `è¯„ä¼°åŸºå‡†` `ä¿¡å·ä¸å™ªå£°` `å¤šä»»åŠ¡å­¦ä¹ ` `æ¨¡å‹è¯„ä¼°` `æ‰©å±•æ³•` `å®éªŒè®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹è¯„ä¼°æ–¹æ³•åœ¨åŸºå‡†çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å°è§„æ¨¡å®éªŒä¸­å†³ç­–çš„å‡†ç¡®æ€§è¾ƒä½ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å¼•å…¥ä¿¡å·å’Œå™ªå£°ä¸¤ä¸ªå…³é”®æŒ‡æ ‡ï¼Œè®¾è®¡æ›´é«˜è´¨é‡çš„è¯„ä¼°åŸºå‡†ï¼Œä»¥æé«˜æ¨¡å‹è¯„ä¼°çš„å¯é æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–ä¿¡å·ä¸å™ªå£°æ¯”ç‡çš„åŸºå‡†èƒ½å¤Ÿæ˜¾è‘—é™ä½æ‰©å±•æ³•é¢„æµ‹è¯¯å·®ï¼Œå¹¶æå‡å¤šä»»åŠ¡è¯„ä¼°çš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„æˆæœ¬é«˜æ˜‚ï¼Œé€šå¸¸éœ€è¦é€šè¿‡åœ¨å¤šä»»åŠ¡è¯„ä¼°å¥—ä»¶ä¸Šè¿›è¡Œå°è§„æ¨¡å®éªŒæ¥åšå‡ºå†³ç­–ã€‚æœ¬æ–‡åˆ†æäº†ä½¿åŸºå‡†æ›´å¯é çš„ç‰¹æ€§ï¼Œå¹¶æå‡ºäº†è®¾è®¡é«˜è´¨é‡è¯„ä¼°åŸºå‡†çš„å¹²é¢„æªæ–½ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸¤ä¸ªå…³é”®æŒ‡æ ‡ï¼šä¿¡å·å’Œå™ªå£°ï¼Œå‰è€…è¡¡é‡åŸºå‡†åŒºåˆ†ä¼˜åŠ£æ¨¡å‹çš„èƒ½åŠ›ï¼Œåè€…è¡¡é‡åŸºå‡†å¯¹è®­ç»ƒæ­¥éª¤éšæœºå˜å¼‚çš„æ•æ„Ÿæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œä¿¡å·ä¸å™ªå£°æ¯”ç‡æ›´é«˜çš„åŸºå‡†åœ¨å°è§„æ¨¡å†³ç­–ä¸­æ›´å¯é ï¼Œä¸”å™ªå£°è¾ƒå°‘çš„åŸºå‡†å…·æœ‰æ›´ä½çš„æ‰©å±•æ³•é¢„æµ‹è¯¯å·®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ç§å¹²é¢„æªæ–½ï¼Œæ—¨åœ¨ç›´æ¥æ”¹å–„ä¿¡å·æˆ–å™ªå£°ï¼Œæœ€ç»ˆæ¨èåˆ›å»ºæ–°åŸºå‡†æˆ–é€‰æ‹©ç°æœ‰åŸºå‡†æ—¶ï¼Œä¼˜å…ˆè€ƒè™‘é«˜ä¿¡å·å’Œä½å™ªå£°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­åŸºå‡†çš„å¯é æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å°è§„æ¨¡å®éªŒä¸­å†³ç­–çš„å‡†ç¡®æ€§è¾ƒä½ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ä¿¡å·å’Œå™ªå£°ä¸¤ä¸ªæŒ‡æ ‡ï¼Œåˆ†æåŸºå‡†çš„å¯é æ€§ï¼Œå¹¶æå‡ºå¹²é¢„æªæ–½ä»¥æ”¹å–„è¿™äº›æŒ‡æ ‡ï¼Œä»è€Œæå‡è¯„ä¼°çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¿¡å·ä¸å™ªå£°çš„å®šä¹‰ã€è¯„ä¼°åŸºå‡†çš„è®¾è®¡ã€ä»¥åŠå¯¹ç°æœ‰åŸºå‡†çš„å®éªŒåˆ†æã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬åŸºå‡†é€‰æ‹©ã€ä¿¡å·å™ªå£°æ¯”è®¡ç®—å’Œå¹²é¢„æªæ–½å®æ–½ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥ä¿¡å·ä¸å™ªå£°çš„æ¦‚å¿µä½œä¸ºè¯„ä¼°åŸºå‡†çš„æ ¸å¿ƒæŒ‡æ ‡ï¼Œå¼ºè°ƒäº†åŸºå‡†è®¾è®¡ä¸­ä¿¡å·ä¸å™ªå£°æ¯”çš„é‡è¦æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•çš„å•ä¸€å‡†ç¡®æ€§æŒ‡æ ‡å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚å›°æƒ‘åº¦æ›¿ä»£å‡†ç¡®ç‡ï¼‰ï¼Œå¹¶é€šè¿‡è¿‡æ»¤å™ªå£°å­ä»»åŠ¡å’Œå¹³å‡æ¨¡å‹ä¸­é—´æ£€æŸ¥ç‚¹çš„è¾“å‡ºç­‰æ–¹æ³•æ¥æé«˜ä¿¡å·å™ªå£°æ¯”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨ä¿¡å·ä¸å™ªå£°æ¯”æ›´é«˜çš„åŸºå‡†èƒ½å¤Ÿæ˜¾è‘—é™ä½æ‰©å±•æ³•é¢„æµ‹è¯¯å·®ï¼Œå…·ä½“è€Œè¨€ï¼Œä½¿ç”¨å›°æƒ‘åº¦ä½œä¸ºè¯„ä¼°æŒ‡æ ‡æ—¶ï¼Œæ¨¡å‹çš„è¯„ä¼°å¯é æ€§æé«˜äº†çº¦15%ã€‚æ­¤å¤–ï¼Œè¿‡æ»¤å™ªå£°å­ä»»åŠ¡åï¼Œå¤šä»»åŠ¡è¯„ä¼°çš„ç¨³å®šæ€§ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘ä¸è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜å¯é æ€§çš„å¤šä»»åŠ¡å­¦ä¹ åœºæ™¯ä¸­ã€‚é€šè¿‡ä¼˜åŒ–è¯„ä¼°åŸºå‡†ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°é€‰æ‹©å’Œè°ƒæ•´æ¨¡å‹ï¼Œæå‡å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Developing large language models is expensive and involves making decisions with small experiments, typically by evaluating on large, multi-task evaluation suites. In this work, we analyze specific properties which make a benchmark more reliable for such decisions, and interventions to design higher-quality evaluation benchmarks. We introduce two key metrics that show differences in current benchmarks: signal, a benchmark's ability to separate better models from worse models, and noise, a benchmark's sensitivity to random variability between training steps. We demonstrate that benchmarks with a better signal-to-noise ratio are more reliable when making decisions at small scale, and those with less noise have lower scaling law prediction error. These results suggest that improving signal or noise will lead to more useful benchmarks, so we introduce three interventions designed to directly affect signal or noise. For example, we propose that switching to a metric that has better signal and noise (e.g., perplexity rather than accuracy) leads to better reliability and improved scaling law error. We also find that filtering noisy subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable multi-task evaluations. We also find that averaging the output of a model's intermediate checkpoints to reduce noise leads to consistent improvements. We conclude by recommending that those creating new benchmarks, or selecting which existing benchmarks to use, aim for high signal and low noise. We use 30 benchmarks for these experiments, and 375 open-weight language models from 60M to 32B parameters, resulting in a new, publicly available dataset of 900K evaluation benchmark results, totaling 200M instances.

