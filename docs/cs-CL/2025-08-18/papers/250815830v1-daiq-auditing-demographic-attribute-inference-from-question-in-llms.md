---
layout: default
title: DAIQ: Auditing Demographic Attribute Inference from Question in LLMs
---

# DAIQ: Auditing Demographic Attribute Inference from Question in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15830" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15830v1</a>
  <a href="https://arxiv.org/pdf/2508.15830.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15830v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15830v1', 'DAIQ: Auditing Demographic Attribute Inference from Question in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Srikant Panda, Hitesh Laxmichand Patel, Shahad Al-Khalifa, Amit Agarwal, Hend Al-Khalifa, Sharefah Al-Ghamdi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDAIQæ¡†æ¶ä»¥å®¡è®¡LLMsä¸­çš„äººå£å±æ€§æ¨æ–­é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººå£å±æ€§æ¨æ–­` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤¾ä¼šåè§` `éšç§ä¿æŠ¤` `å…¬å¹³æ€§` `å®¡è®¡æ¡†æ¶` `æç¤ºç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„è¯­è¨€æ¨¡å‹åœ¨ç¼ºä¹æ˜ç¡®äººå£å±æ€§æç¤ºçš„æƒ…å†µä¸‹ï¼Œä»ä¼šæ¨æ–­ç”¨æˆ·èº«ä»½ï¼Œå¯¼è‡´éšç§å’Œå…¬å¹³æ€§é£é™©ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºDAIQæ¡†æ¶ï¼Œé€šè¿‡ä¸­ç«‹æŸ¥è¯¢å’Œç³»ç»Ÿæç¤ºï¼Œå®šé‡ä¸å®šæ€§åˆ†ææ¨¡å‹å¦‚ä½•æ¨æ–­äººå£ä¿¡æ¯ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶è¡¨æ˜ï¼ŒLLMsåœ¨ä¸åŒæ¨¡å‹ä¸­æ™®éå­˜åœ¨äººå£æ¨æ–­ï¼Œä¸”æå‡ºçš„ä¿æŠ¤æªæ–½æœ‰æ•ˆé™ä½äº†èº«ä»½æ¨æ–­çš„å‘ç”Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¾“å…¥ä¸­æ˜ç¡®å­˜åœ¨äººå£å±æ€§æ—¶ï¼Œå·²çŸ¥ä¼šåæ˜ ç¤¾ä¼šåè§ã€‚ç„¶è€Œï¼Œå³ä½¿åœ¨ç¼ºä¹è¿™äº›ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œè¿™äº›æ¨¡å‹ä»ç„¶ä¼šæ ¹æ®é—®é¢˜çš„æªè¾æ¨æ–­ç”¨æˆ·èº«ä»½ã€‚è¿™ç§å¾®å¦™çš„è¡Œä¸ºå—åˆ°çš„å…³æ³¨è¾ƒå°‘ï¼Œä½†å´å¸¦æ¥äº†ä¸¥é‡é£é™©ï¼šè¿åä¸­ç«‹æ€§æœŸæœ›ã€æ¨æ–­æ„å¤–çš„äººå£ä¿¡æ¯ï¼Œå¹¶ç¼–ç ç ´åå…¬å¹³çš„åˆ»æ¿å°è±¡ã€‚æœ¬æ–‡æå‡ºäº†äººå£å±æ€§æ¨æ–­ä»»åŠ¡ï¼ˆDAIQï¼‰ï¼Œä¸ºå®¡è®¡è¯­è¨€æ¨¡å‹ä¸­çš„è¿™ä¸€è¢«å¿½è§†çš„å¤±è´¥æ¨¡å¼æä¾›äº†æ¡†æ¶ã€‚æˆ‘ä»¬å±•ç¤ºäº†å¼€æ”¾å’Œé—­æºçš„LLMså¦‚ä½•ä»…åŸºäºé—®é¢˜æªè¾åˆ†é…äººå£æ ‡ç­¾ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºæç¤ºçš„ä¿æŠ¤æªæ–½ï¼Œä»¥æ˜¾è‘—å‡å°‘èº«ä»½æ¨æ–­ï¼Œå¸®åŠ©æ¨¡å‹è¡Œä¸ºä¸å…¬å¹³å’Œéšç§ç›®æ ‡å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¼ºä¹æ˜ç¡®äººå£å±æ€§æç¤ºæ—¶ï¼Œä»ç„¶èƒ½å¤Ÿæ¨æ–­ç”¨æˆ·èº«ä»½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†å…³æ³¨è¿™ä¸€éšæ€§é£é™©ï¼Œå¯¼è‡´æ½œåœ¨çš„éšç§ä¾µçŠ¯å’Œç¤¾ä¼šåè§ä¼ æ’­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºDAIQæ¡†æ¶ï¼Œé€šè¿‡ä½¿ç”¨ç»è¿‡ç­–åˆ’çš„ä¸­ç«‹æŸ¥è¯¢å’Œç³»ç»Ÿæç¤ºï¼Œåˆ†ææ¨¡å‹å¦‚ä½•åœ¨ç¼ºä¹äººå£ä¿¡æ¯çš„æƒ…å†µä¸‹æ¨æ–­ç”¨æˆ·èº«ä»½ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¨¡å‹çš„éšæ€§åè§å’Œæ¨æ–­æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹æ¨æ–­ã€å®šé‡åˆ†æå’Œå®šæ€§åˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†ä¸­ç«‹æŸ¥è¯¢æ•°æ®ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨ä¸åŒçš„LLMsè¿›è¡Œæ¨æ–­ï¼›ç„¶åï¼Œé€šè¿‡å®šé‡å’Œå®šæ€§æ–¹æ³•åˆ†ææ¨æ–­ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†DAIQæ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°å®¡è®¡å’Œåˆ†æè¯­è¨€æ¨¡å‹åœ¨ç¼ºä¹äººå£æç¤ºæ—¶çš„æ¨æ–­è¡Œä¸ºã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…³æ³¨éšæ€§æ¨æ–­è€Œéæ˜¾æ€§åè§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æç¤ºç­–ç•¥å’ŒæŸ¥è¯¢è®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹æ¨æ–­çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œä½¿ç”¨äº†å®šé‡æŒ‡æ ‡æ¥è¯„ä¼°æ¨æ–­çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¼€æ”¾å’Œé—­æºçš„LLMsåœ¨ä¸åŒæ¨¡å‹ä¸­æ™®éå­˜åœ¨äººå£æ¨æ–­ç°è±¡ï¼Œä¸”é€šè¿‡æå‡ºçš„åŸºäºæç¤ºçš„ä¿æŠ¤æªæ–½ï¼Œèº«ä»½æ¨æ–­çš„å‘ç”Ÿç‡æ˜¾è‘—é™ä½ï¼Œæå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨ä¿ƒè¿›å…¬å¹³æ€§å’Œéšç§ä¿æŠ¤æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€é‡‘èå’Œæ•™è‚²ç­‰å¤šä¸ªç¤¾ä¼šé‡è¦é¢†åŸŸã€‚é€šè¿‡å®¡è®¡å’Œå‡å°‘è¯­è¨€æ¨¡å‹ä¸­çš„äººå£å±æ€§æ¨æ–­ï¼Œå¯ä»¥æå‡ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œéšç§ä¿æŠ¤ï¼Œä¿ƒè¿›è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½éƒ¨ç½²ï¼Œå‡å°‘ç¤¾ä¼šåè§çš„ä¼ æ’­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are known to reflect social biases when demographic attributes, such as gender or race, are explicitly present in the input. But even in their absence, these models still infer user identities based solely on question phrasing. This subtle behavior has received far less attention, yet poses serious risks: it violates expectations of neutrality, infers unintended demographic information, and encodes stereotypes that undermine fairness in various domains including healthcare, finance and education.
>   We introduce Demographic Attribute Inference from Questions (DAIQ), a task and framework for auditing an overlooked failure mode in language models: inferring user demographic attributes from questions that lack explicit demographic cues. Our approach leverages curated neutral queries, systematic prompting, and both quantitative and qualitative analysis to uncover how models infer demographic information. We show that both open and closed source LLMs do assign demographic labels based solely on question phrasing.
>   Prevalence and consistency of demographic inferences across diverse models reveal a systemic and underacknowledged risk: LLMs can fabricate demographic identities, reinforce societal stereotypes, and propagate harms that erode privacy, fairness, and trust posing a broader threat to social equity and responsible AI deployment. To mitigate this, we develop a prompt-based guardrail that substantially reduces identity inference and helps align model behavior with fairness and privacy objectives.

