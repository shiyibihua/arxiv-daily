---
layout: default
title: DoÄŸal Dil Ä°ÅŸlemede Tokenizasyon StandartlarÄ± ve Ã–lÃ§Ã¼mÃ¼: TÃ¼rkÃ§e Ãœzerinden BÃ¼yÃ¼k Dil Modellerinin KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi
---

# DoÄŸal Dil Ä°ÅŸlemede Tokenizasyon StandartlarÄ± ve Ã–lÃ§Ã¼mÃ¼: TÃ¼rkÃ§e Ãœzerinden BÃ¼yÃ¼k Dil Modellerinin KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13058" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13058v1</a>
  <a href="https://arxiv.org/pdf/2508.13058.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13058v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13058v1', 'DoÄŸal Dil Ä°ÅŸlemede Tokenizasyon StandartlarÄ± ve Ã–lÃ§Ã¼mÃ¼: TÃ¼rkÃ§e Ãœzerinden BÃ¼yÃ¼k Dil Modellerinin KarÅŸÄ±laÅŸtÄ±rmalÄ± Analizi')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: M. Ali Bayram, Ali Arda Fincan, Ahmet Semih GÃ¼mÃ¼ÅŸ, Sercan KarakaÅŸ, Banu Diri, SavaÅŸ YÄ±ldÄ±rÄ±m

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

**å¤‡æ³¨**: in Turkish language, Presented at the 2025 33rd Signal Processing and Communications Applications Conference (SIU), 25--28 June 2025, Åile, Istanbul, TÃ¼rkiye

**DOI**: [10.1109/SIU66497.2025.11112220](https://doi.org/10.1109/SIU66497.2025.11112220)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé’ˆå¯¹åœŸè€³å…¶è¯­çš„åˆ†è¯æ ‡å‡†ä»¥è§£å†³è¯­è¨€æ¨¡å‹æ€§èƒ½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç„¶è¯­è¨€å¤„ç†` `åˆ†è¯æ ‡å‡†` `åœŸè€³å…¶è¯­` `å¤§è¯­è¨€æ¨¡å‹` `è¯„ä¼°æ¡†æ¶` `å½¢æ€ä¸°å¯Œè¯­è¨€` `ä½èµ„æºè¯­è¨€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åˆ†è¯æ–¹æ³•åœ¨å¤„ç†å½¢æ€ä¸°å¯Œçš„è¯­è¨€æ—¶ï¼Œå¸¸å¸¸æ— æ³•æœ‰æ•ˆæ•æ‰è¯­è¨€çš„ç»“æ„ç‰¹å¾ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œä¸“é—¨é’ˆå¯¹åœŸè€³å…¶è¯­çš„åˆ†è¯æŒ‘æˆ˜ï¼Œåˆ©ç”¨TR-MMLUæ•°æ®é›†è¿›è¡Œå…¨é¢è¯„ä¼°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”ä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„ç›¸å…³æ€§æ›´å¼ºï¼Œå¼ºè°ƒäº†é’ˆå¯¹ç‰¹å®šè¯­è¨€çš„åˆ†è¯æ–¹æ³•çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆ†è¯æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åŸºç¡€é¢„å¤„ç†æ­¥éª¤ï¼Œå¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ•æ‰è¯­è¨€å’Œè¯­ä¹‰ç»†å¾®å·®åˆ«æœ‰æ˜¾è‘—å½±å“ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œè§£å†³äº†ç‰¹å®šäºå½¢æ€ä¸°å¯Œå’Œèµ„æºåŒ®ä¹è¯­è¨€ï¼ˆå¦‚åœŸè€³å…¶è¯­ï¼‰çš„åˆ†è¯æŒ‘æˆ˜ã€‚åˆ©ç”¨åŒ…å«6200é“å¤šé¡¹é€‰æ‹©é¢˜çš„åœŸè€³å…¶MMLUï¼ˆTR-MMLUï¼‰æ•°æ®é›†ï¼Œæˆ‘ä»¬æ ¹æ®è¯æ±‡å¤§å°ã€æ ‡è®°æ•°é‡ã€å¤„ç†æ—¶é—´ã€è¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”ï¼ˆ%TRï¼‰å’Œæ ‡è®°çº¯åº¦ï¼ˆ%Pureï¼‰è¯„ä¼°äº†åˆ†è¯å™¨ã€‚è¿™äº›æ–°æå‡ºçš„æŒ‡æ ‡è¡¡é‡äº†åˆ†è¯å™¨ä¿ç•™è¯­è¨€ç»“æ„çš„æœ‰æ•ˆæ€§ã€‚åˆ†æç»“æœæ˜¾ç¤ºï¼Œè¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”ä¸ä¸‹æ¸¸æ€§èƒ½ï¼ˆå¦‚MMLUå¾—åˆ†ï¼‰ä¹‹é—´çš„ç›¸å…³æ€§å¼ºäºæ ‡è®°çº¯åº¦ã€‚æ­¤å¤–ï¼Œä»…å¢åŠ æ¨¡å‹å‚æ•°å¹¶ä¸ä¸€å®šæå‡è¯­è¨€æ€§èƒ½ï¼Œå¼ºè°ƒäº†é‡èº«å®šåˆ¶çš„è¯­è¨€ç‰¹å®šåˆ†è¯æ–¹æ³•çš„é‡è¦æ€§ã€‚è¯¥æ¡†æ¶ä¸ºå½¢æ€å¤æ‚è¯­è¨€å»ºç«‹äº†ç¨³å¥ä¸”å®ç”¨çš„åˆ†è¯æ ‡å‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰åˆ†è¯æ–¹æ³•åœ¨å¤„ç†åœŸè€³å…¶è¯­ç­‰å½¢æ€ä¸°å¯Œè¯­è¨€æ—¶çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¿ç•™è¯­è¨€ç»“æ„æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆé€‚åº”è¿™äº›è¯­è¨€çš„å¤æ‚æ€§ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œä¸“æ³¨äºè¯„ä¼°åˆ†è¯å™¨åœ¨ç‰¹å®šè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯é€šè¿‡å¼•å…¥è¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”ç­‰æ–°æŒ‡æ ‡æ¥è¡¡é‡åˆ†è¯æ•ˆæœã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†æ›´å¥½åœ°åæ˜ åˆ†è¯å¯¹ä¸‹æ¸¸ä»»åŠ¡çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€åˆ†è¯å™¨è¯„ä¼°å’Œæ€§èƒ½åˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨TR-MMLUæ•°æ®é›†è¿›è¡Œåˆ†è¯å™¨çš„è¯„ä¼°ï¼›å…¶æ¬¡ï¼Œé€šè¿‡æ–°æå‡ºçš„æŒ‡æ ‡å¯¹åˆ†è¯å™¨è¿›è¡Œé‡åŒ–åˆ†æï¼›æœ€åï¼Œåˆ†æç»“æœä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½è¿›è¡Œå…³è”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚è¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”å’Œæ ‡è®°çº¯åº¦ï¼Œè¿™äº›æŒ‡æ ‡èƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ åˆ†è¯å™¨åœ¨ç‰¹å®šè¯­è¨€ä¸Šçš„è¡¨ç°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…·é’ˆå¯¹æ€§çš„è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§å‚æ•°ä»¥è¯„ä¼°åˆ†è¯å™¨çš„è¡¨ç°ï¼ŒåŒ…æ‹¬è¯æ±‡å¤§å°ã€æ ‡è®°æ•°é‡å’Œå¤„ç†æ—¶é—´ç­‰ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åˆ†è¯å™¨çš„æ€§èƒ½ï¼Œç¡®ä¿å…¶åœ¨åœŸè€³å…¶è¯­ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯­è¨€ç‰¹å®šæ ‡è®°ç™¾åˆ†æ¯”ä¸ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ï¼ˆå¦‚MMLUå¾—åˆ†ï¼‰ä¹‹é—´çš„ç›¸å…³æ€§æ˜¾è‘—é«˜äºæ ‡è®°çº¯åº¦ï¼Œå¼ºè°ƒäº†é’ˆå¯¹ç‰¹å®šè¯­è¨€çš„åˆ†è¯æ–¹æ³•çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œå•çº¯å¢åŠ æ¨¡å‹å‚æ•°å¹¶æœªå¸¦æ¥é¢„æœŸçš„æ€§èƒ½æå‡ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†æœ¬ç ”ç©¶æå‡ºçš„åˆ†è¯æ ‡å‡†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†å½¢æ€ä¸°å¯Œè¯­è¨€æ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½ä¸ºå…¶ä»–ä½èµ„æºè¯­è¨€çš„åˆ†è¯æ ‡å‡†åŒ–æä¾›å‚è€ƒï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tokenization is a fundamental preprocessing step in Natural Language Processing (NLP), significantly impacting the capability of large language models (LLMs) to capture linguistic and semantic nuances. This study introduces a novel evaluation framework addressing tokenization challenges specific to morphologically-rich and low-resource languages such as Turkish. Utilizing the Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from the Turkish education system, we assessed tokenizers based on vocabulary size, token count, processing time, language-specific token percentages (\%TR), and token purity (\%Pure). These newly proposed metrics measure how effectively tokenizers preserve linguistic structures. Our analysis reveals that language-specific token percentages exhibit a stronger correlation with downstream performance (e.g., MMLU scores) than token purity. Furthermore, increasing model parameters alone does not necessarily enhance linguistic performance, underscoring the importance of tailored, language-specific tokenization methods. The proposed framework establishes robust and practical tokenization standards for morphologically complex languages.

