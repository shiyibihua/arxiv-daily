---
layout: default
title: Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning
---

# Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12591" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12591v1</a>
  <a href="https://arxiv.org/pdf/2508.12591.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12591v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12591v1', 'Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu-Hsuan Fang, Tien-Hong Lo, Yao-Ting Sung, Berlin Chen

**åˆ†ç±»**: cs.CL, cs.AI, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

**å¤‡æ³¨**: Accepted at IEEE ASRU 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä»¥è§£å†³è‡ªåŠ¨å£è¯­è¯„ä¼°ä¸­çš„æ¨¡æ€é™åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨å£è¯­è¯„ä¼°` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è¯¾ç¨‹å­¦ä¹ ` `è¯­éŸ³å»ºæ¨¡` `è·¨æ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨å£è¯­è¯„ä¼°ç³»ç»Ÿåœ¨æ¨¡æ€ä¸Šå­˜åœ¨å±€é™ï¼Œæ–‡æœ¬å’ŒéŸ³é¢‘ä¿¡æ¯çš„ç¼ºå¤±å¯¼è‡´è¯„ä¼°æ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒç­–ç•¥SFMTï¼Œå¼ºè°ƒåœ¨è·¨æ¨¡æ€èåˆä¹‹å‰ä¼˜å…ˆå»ºç«‹è¯­éŸ³å»ºæ¨¡åŸºç¡€ï¼Œä»¥åº”å¯¹è¯„ä¼°ä¸­çš„æŒ‘æˆ˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMLLMç³»ç»Ÿçš„æ•´ä½“è¯„ä¼°æ€§èƒ½æ˜¾è‘—æå‡ï¼ŒPCCå€¼ä»0.783æé«˜è‡³0.846ï¼Œäº¤ä»˜æ–¹é¢çš„å‡†ç¡®ç‡æå‡è¾¾4%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„è‡ªåŠ¨å£è¯­è¯„ä¼°ï¼ˆASAï¼‰ç³»ç»Ÿå­˜åœ¨å›ºæœ‰çš„æ¨¡æ€é™åˆ¶ï¼šåŸºäºæ–‡æœ¬çš„æ–¹æ³•ç¼ºä¹å£°å­¦ä¿¡æ¯ï¼Œè€ŒåŸºäºéŸ³é¢‘çš„æ–¹æ³•åˆ™ç¼ºå°‘è¯­ä¹‰ä¸Šä¸‹æ–‡ã€‚å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰é€šè¿‡åœ¨ç»Ÿä¸€æ¡†æ¶å†…åŒæ—¶å¤„ç†éŸ³é¢‘å’Œæ–‡æœ¬ï¼Œä¸ºå…¨é¢çš„ASAæä¾›äº†å‰æ‰€æœªæœ‰çš„æœºä¼šã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿç ”ç©¶äº†MLLMåœ¨å…¨é¢ASAä¸­çš„åº”ç”¨ï¼Œå±•ç¤ºäº†å…¶åœ¨å†…å®¹å’Œè¯­è¨€ä½¿ç”¨æ–¹é¢çš„ä¼˜è¶Šæ€§èƒ½ã€‚ç„¶è€Œï¼Œåœ¨äº¤ä»˜æ–¹é¢çš„è¯„ä¼°æ­ç¤ºäº†ç‹¬ç‰¹çš„æŒ‘æˆ˜ï¼Œè®¤ä¸ºéœ€è¦ä¸“é—¨çš„è®­ç»ƒç­–ç•¥ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä»¥è¯­éŸ³ä¸ºå…ˆçš„å¤šæ¨¡æ€è®­ç»ƒï¼ˆSFMTï¼‰ï¼Œåˆ©ç”¨è¯¾ç¨‹å­¦ä¹ åŸåˆ™åœ¨è·¨æ¨¡æ€ååŒèåˆä¹‹å‰å»ºç«‹æ›´ç¨³å¥çš„è¯­éŸ³å»ºæ¨¡åŸºç¡€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºMLLMçš„ç³»ç»Ÿå¯ä»¥å°†æ•´ä½“è¯„ä¼°æ€§èƒ½ä»PCCå€¼0.783æå‡è‡³0.846ï¼Œå°¤å…¶æ˜¯åœ¨äº¤ä»˜æ–¹é¢ï¼ŒSFMTç›¸è¾ƒäºä¼ ç»Ÿè®­ç»ƒæ–¹æ³•å®ç°äº†4%çš„ç»å¯¹å‡†ç¡®ç‡æå‡ï¼Œä¸ºASAå¼€è¾Ÿäº†æ–°é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿè‡ªåŠ¨å£è¯­è¯„ä¼°ç³»ç»Ÿåœ¨æ¨¡æ€ä¸Šçš„å±€é™æ€§ï¼Œç°æœ‰æ–¹æ³•æ— æ³•åŒæ—¶æœ‰æ•ˆåˆ©ç”¨æ–‡æœ¬å’ŒéŸ³é¢‘ä¿¡æ¯ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå…¨é¢å’Œå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¥æ•´åˆéŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œå¹¶å¼•å…¥ä»¥è¯­éŸ³ä¸ºå…ˆçš„å¤šæ¨¡æ€è®­ç»ƒï¼ˆSFMTï¼‰ç­–ç•¥ï¼Œä»¥å¼ºåŒ–è¯­éŸ³å»ºæ¨¡çš„åŸºç¡€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯é€šè¿‡SFMTè¿›è¡Œè¯­éŸ³å»ºæ¨¡ï¼Œç„¶åè¿›è¡Œè·¨æ¨¡æ€çš„ååŒèåˆã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆæ•´åˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼Œæé«˜è¯„ä¼°çš„å…¨é¢æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°åº”ç”¨MLLMäºè‡ªåŠ¨å£è¯­è¯„ä¼°ï¼Œå¹¶æå‡ºSFMTç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†äº¤ä»˜æ–¹é¢çš„è¯„ä¼°æ•ˆæœï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨çš„åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–è¯­éŸ³å»ºæ¨¡çš„æ•ˆæœï¼Œå¹¶ç¡®ä¿åœ¨è·¨æ¨¡æ€èåˆæ—¶ä¿æŒä¿¡æ¯çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºMLLMçš„è‡ªåŠ¨å£è¯­è¯„ä¼°ç³»ç»Ÿåœ¨æ•´ä½“è¯„ä¼°æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼ŒPCCå€¼ä»0.783æé«˜è‡³0.846ï¼Œç‰¹åˆ«æ˜¯åœ¨äº¤ä»˜æ–¹é¢ï¼ŒSFMTæ–¹æ³•å®ç°äº†4%çš„ç»å¯¹å‡†ç¡®ç‡æå‡ï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è¯­è¨€å­¦ä¹ å’Œè¯„ä¼°ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿä¸ºè‡ªåŠ¨å£è¯­è¯„ä¼°æä¾›æ›´å…¨é¢çš„è§£å†³æ–¹æ¡ˆï¼Œæå‡å­¦ä¹ è€…çš„è¯­è¨€èƒ½åŠ›è¯„ä¼°æ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å¤šæ¨¡æ€å­¦ä¹ å’Œæ™ºèƒ½æ•™è‚²é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Traditional Automated Speaking Assessment (ASA) systems exhibit inherent modality limitations: text-based approaches lack acoustic information while audio-based methods miss semantic context. Multimodal Large Language Models (MLLM) offer unprecedented opportunities for comprehensive ASA by simultaneously processing audio and text within unified frameworks. This paper presents a very first systematic study of MLLM for comprehensive ASA, demonstrating the superior performance of MLLM across the aspects of content and language use . However, assessment on the delivery aspect reveals unique challenges, which is deemed to require specialized training strategies. We thus propose Speech-First Multimodal Training (SFMT), leveraging a curriculum learning principle to establish more robust modeling foundations of speech before cross-modal synergetic fusion. A series of experiments on a benchmark dataset show MLLM-based systems can elevate the holistic assessment performance from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the evaluation of the delivery aspect, achieving an absolute accuracy improvement of 4% over conventional training approaches, which also paves a new avenue for ASA.

