---
layout: default
title: When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models
---

# When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12803" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12803v1</a>
  <a href="https://arxiv.org/pdf/2508.12803.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12803v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12803v1', 'When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ahmed Elshabrawy, Hour Kaing, Haiyue Song, Alham Fikri Aji, Hideki Tanaka, Masao Utiyama, Raj Dabre

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœ¨çº¿å˜åˆ†æ¢æµ‹æ¡†æ¶ä»¥è§£å†³å¤šè¯­è¨€æ¨¡å‹çš„è¡¨ç¤ºç©ºé—´è§£è€¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨¡å‹` `è¡¨ç¤ºç©ºé—´` `ç”Ÿæˆå»ºæ¨¡` `é˜¿æ‹‰ä¼¯æ–¹è¨€` `å› æœå¹²é¢„` `åœ¨çº¿å˜åˆ†æ¢æµ‹` `æœºå™¨ç¿»è¯‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å‡è®¾é«˜èµ„æºæ ‡å‡†è¯­è¨€çš„å¯¹é½èƒ½å¤Ÿå¸®åŠ©ä½èµ„æºæ–¹è¨€çš„å»ºæ¨¡ï¼Œä½†è¿‡åº¦çš„è¡¨ç¤ºçº ç¼ åè€Œä¼šé€ æˆè´Ÿé¢å½±å“ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åœ¨çº¿å˜åˆ†æ¢æµ‹æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æŒç»­ä¼°è®¡æ ‡å‡†æ–¹è¨€çš„å­ç©ºé—´ï¼Œå®ç°ä¸è¯¥ç©ºé—´çš„æœ‰æ•ˆè§£è€¦ã€‚
3. åœ¨25ç§é˜¿æ‹‰ä¼¯æ–¹è¨€çš„å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆè´¨é‡ä¸Šæå‡äº†æœ€é«˜4.9 chrF++ï¼Œå°½ç®¡åœ¨æ ‡å‡†è¯­è¨€æ€§èƒ½ä¸Šå­˜åœ¨ä¸€å®šçš„æƒè¡¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æŒ‘æˆ˜äº†é«˜èµ„æºæ ‡å‡†è¯­è¨€ä¸ä½èµ„æºæ–¹è¨€ä¹‹é—´çš„è¿‡åº¦å¯¹é½å‡è®¾ï¼Œè¡¨æ˜ä¸ä¸»æµæ–¹è¨€ï¼ˆå¦‚ç°ä»£æ ‡å‡†é˜¿æ‹‰ä¼¯è¯­ï¼‰è¿‡åº¦çº ç¼ ä¼šé˜»ç¢ç”Ÿæˆå»ºæ¨¡ã€‚æˆ‘ä»¬é¦–æ¬¡è¿›è¡Œäº†å…¨é¢çš„å› æœç ”ç©¶ï¼Œåˆ†æå¹¶ç›´æ¥å¹²é¢„å¤§å‹è¯­è¨€æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºå‡ ä½•ã€‚æå‡ºçš„åœ¨çº¿å˜åˆ†æ¢æµ‹æ¡†æ¶åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­æŒç»­ä¼°è®¡æ ‡å‡†æ–¹è¨€çš„å­ç©ºé—´ï¼Œä»è€Œå®ç°ä¸è¯¥ç©ºé—´çš„æŠ•å½±è§£è€¦ã€‚å°½ç®¡åœ¨æ ‡å‡†è¯­è¨€æ€§èƒ½ä¸Šå­˜åœ¨æƒè¡¡ï¼Œä½†åœ¨25ç§æ–¹è¨€çš„ç”Ÿæˆè´¨é‡ä¸Šæå‡äº†æœ€é«˜4.9 chrF++å’Œå¹³å‡2.0çš„æ•ˆæœï¼Œæä¾›äº†å› æœè¯æ®ï¼Œè¯æ˜é«˜èµ„æºæ–¹è¨€çš„å­ç©ºé—´ä¸»å¯¼æ€§ä¼šé™åˆ¶ç›¸å…³æ–¹è¨€çš„ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³é«˜èµ„æºæ ‡å‡†è¯­è¨€ä¸ä½èµ„æºæ–¹è¨€ä¹‹é—´çš„è¿‡åº¦å¯¹é½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†è¿™ç§è¡¨ç¤ºç©ºé—´çš„çº ç¼ ï¼Œå¯¼è‡´ç”Ÿæˆæ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåœ¨çº¿å˜åˆ†æ¢æµ‹æ¡†æ¶ï¼Œé€šè¿‡æŒç»­ä¼°è®¡æ ‡å‡†æ–¹è¨€çš„å­ç©ºé—´ï¼Œå®ç°ä¸è¯¥ç©ºé—´çš„æŠ•å½±è§£è€¦ï¼Œä»è€Œæ”¹å–„ç”Ÿæˆæ¨¡å‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®è¾“å…¥ã€æ¨¡å‹å¾®è°ƒã€å­ç©ºé—´ä¼°è®¡å’Œç”Ÿæˆè¾“å‡ºå››ä¸ªä¸»è¦æ¨¡å—ã€‚é€šè¿‡å¯¹æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å¹²é¢„ï¼Œè°ƒæ•´ç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¡¨ç¤ºåˆ†é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å‡ ä½•æ¢æµ‹ä¸ä¿¡æ¯è®ºæ¢æµ‹ç›¸ç»“åˆï¼Œæå‡ºäº†å­ç©ºé—´çº§åˆ«çš„å› æœå¹²é¢„æ–¹æ³•ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å­¦ä¹ ç‡å’ŒæŸå¤±å‡½æ•°ï¼Œç¡®ä¿åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œå­ç©ºé—´çš„ä¼°è®¡ä¸è§£è€¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨åœ¨çº¿å˜åˆ†æ¢æµ‹æ¡†æ¶åï¼Œåœ¨25ç§é˜¿æ‹‰ä¼¯æ–¹è¨€çš„ç”Ÿæˆè´¨é‡ä¸Šæå‡äº†æœ€é«˜4.9 chrF++å’Œå¹³å‡2.0çš„æ•ˆæœï¼Œç›¸è¾ƒäºæ ‡å‡†å¾®è°ƒæ–¹æ³•ï¼Œæ˜¾è‘—æ”¹å–„äº†ç”Ÿæˆèƒ½åŠ›ï¼Œå°½ç®¡åœ¨æ ‡å‡†è¯­è¨€æ€§èƒ½ä¸Šæœ‰æ‰€æƒè¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€æœºå™¨ç¿»è¯‘ã€è·¨æ–¹è¨€ç”Ÿæˆä»»åŠ¡ä»¥åŠå…¶ä»–éœ€è¦å¤„ç†å¤šç§è¯­è¨€å˜ä½“çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚é€šè¿‡ä¼˜åŒ–è¡¨ç¤ºç©ºé—´çš„åˆ†é…ï¼Œèƒ½å¤Ÿæé«˜ç”Ÿæˆæ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Alignment with high-resource standard languages is often assumed to aid the modeling of related low-resource varieties. We challenge this assumption by demonstrating that excessive representational entanglement with a dominant variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects, can actively hinder generative modeling. We present the first comprehensive causal study of this phenomenon by analyzing and directly intervening in the internal representation geometry of large language models (LLMs). Our key contribution is an online variational probing framework that continuously estimates the subspace of the standard variety during fine-tuning, enabling projection-based decoupling from this space. While our study uses Arabic as a case due to its unusually rich parallel resources across 25 dialects, the broader motivation is methodological: dialectal MT serves as a controlled proxy for generative tasks where comparable multi-variety corpora are unavailable. Across 25 dialects, our intervention improves generation quality by up to +4.9 chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured tradeoff in standard-language performance. These results provide causal evidence that subspace dominance by high-resource varieties can restrict generative capacity for related varieties. More generally, we unify geometric and information-theoretic probing with subspace-level causal interventions, offering practical tools for improving generative modeling in closely related language families and, more broadly, for controlling representational allocation in multilingual and multi-domain LLMs. Code will be released.

