---
layout: default
title: Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis
---

# Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13382" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.13382v1</a>
  <a href="https://arxiv.org/pdf/2508.13382.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13382v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13382v1', 'Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ayoub Ben Chaliah, Hela Dellagi

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-18

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Datarus-R1‰ª•Ëß£ÂÜ≥Ëá™Âä®ÂåñÊï∞ÊçÆÂàÜÊûê‰∏≠ÁöÑÊé®ÁêÜÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™Âä®ÂåñÊï∞ÊçÆÂàÜÊûê` `Êé®ÁêÜËÉΩÂäõ` `ËØ≠Ë®ÄÊ®°Âûã` `Ê∑±Â∫¶Â≠¶‰π†` `ÂêàÊàêÊï∞ÊçÆÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÊï∞ÊçÆÂàÜÊûê‰ªªÂä°Êó∂ÔºåÂæÄÂæÄÁº∫‰πèÊúâÊïàÁöÑÊé®ÁêÜËÉΩÂäõÂíåÁªìÊûÑÂåñÊÄùÁª¥ÔºåÂØºËá¥ÁªìÊûú‰∏çÂ§üÂáÜÁ°Æ„ÄÇ
2. Datarus-R1ÈÄöËøáËÆ≠ÁªÉÂÆåÊï¥ÁöÑÂàÜÊûêËΩ®ËøπÔºåÁªìÂêàÂèåÈáçÂ•ñÂä±Êú∫Âà∂Âíå‰ºòÂåñÁöÑÁîüÊàêÁ≠ñÁï•ÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåËæìÂá∫Ë¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDatarusÂú®Ê†áÂáÜÂü∫ÂáÜÊµãËØï‰∏≠Ë∂ÖË∂äÂêåÁ±ªÊ®°ÂûãÔºåÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫Ü30%Ôºå‰∏îÊØè‰∏™Ëß£ÂÜ≥ÊñπÊ°àÁöÑtokenÊï∞ÈáèÂáèÂ∞ë‰∫Ü18-49%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜDatarus-R1-14BÔºå‰∏Ä‰∏™Êã•Êúâ140‰∫øÂèÇÊï∞ÁöÑÂºÄÊîæÊùÉÈáçËØ≠Ë®ÄÊ®°ÂûãÔºåÁªèËøáÂæÆË∞É‰ª•ÂÖÖÂΩìËôöÊãüÊï∞ÊçÆÂàÜÊûêÂ∏àÂíåÁ†îÁ©∂ÁîüÁ∫ßÈóÆÈ¢òËß£ÂÜ≥ËÄÖ„ÄÇDatarusÁöÑËÆ≠ÁªÉ‰∏ç‰ªÖÂü∫‰∫éÂ≠§Á´ãÁöÑÈóÆÈ¢ò-Á≠îÊ°àÂØπÔºåËÄåÊòØÊ∂µÁõñ‰∫ÜÂÆåÊï¥ÁöÑÂàÜÊûêËΩ®ËøπÔºåÂåÖÊã¨Êé®ÁêÜÊ≠•È™§„ÄÅ‰ª£Á†ÅÊâßË°å„ÄÅÈîôËØØËøΩË∏™„ÄÅËá™Êàë‰øÆÊ≠£ÂíåÊúÄÁªàÁªìËÆ∫ÔºåÊâÄÊúâÂÜÖÂÆπ‰ª•ReActÈ£éÊ†ºÁöÑÁ¨îËÆ∞Êú¨Ê†ºÂºèÂëàÁé∞ÔºåÊ∂âÂèäÈáëËûç„ÄÅÂåªÂ≠¶„ÄÅÊï∞ÂÄºÂàÜÊûêÁ≠âÂ§ö‰∏™ÂÆöÈáèÈ¢ÜÂüü„ÄÇÊàë‰ª¨ÁöÑËÆ≠ÁªÉÁÆ°ÈÅìÁªìÂêà‰∫ÜËΩ®Ëøπ‰∏≠ÂøÉÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÂô®„ÄÅÂèåÈáçÂ•ñÂä±Ê°ÜÊû∂ÂíåÂÜÖÂ≠ò‰ºòÂåñÁöÑGroup Relative Policy OptimizationÂÆûÁé∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËá™Âä®ÂåñÊï∞ÊçÆÂàÜÊûêÊ®°ÂûãÂú®Êé®ÁêÜÂíåÁªìÊûÑÂåñÊÄùÁª¥ÊñπÈù¢ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÈóÆÈ¢ò‰∏äÁöÑË°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöDatarus-R1ÈÄöËøáËÆ≠ÁªÉÂÆåÊï¥ÁöÑÂàÜÊûêËΩ®ËøπËÄåÈùûÂ≠§Á´ãÁöÑÈóÆÁ≠îÂØπÔºåÁªìÂêàÂèåÈáçÂ•ñÂä±Êú∫Âà∂ÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÂíåËæìÂá∫Ë¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ËΩ®Ëøπ‰∏≠ÂøÉÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÂô®„ÄÅÂèåÈáçÂ•ñÂä±Ê°ÜÊû∂ÂíåÂÜÖÂ≠ò‰ºòÂåñÁöÑGRPOÂÆûÁé∞ÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Êé®ÁêÜÂíåÊâßË°å‰ª£Á†ÅÊó∂ÁöÑÈ´òÊïàÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöDatarusÁöÑÂèåÈáçÊé®ÁêÜÊé•Âè£ËÆæËÆ°ÊòØÂÖ∂Ê†∏ÂøÉÂàõÊñ∞ÔºåÊîØÊåÅÂú®‰ª£ÁêÜÊ®°Âºè‰∏ãÁîüÊàêReActÊ†áËÆ∞Ê≠•È™§Âπ∂ÊâßË°åÁúüÂÆû‰ª£Á†ÅÔºåÂú®ÂèçÊÄùÊ®°Âºè‰∏ãËæìÂá∫Á¥ßÂáëÁöÑÊÄùÁª¥ÈìæÊù°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊ®°ÂûãÈááÁî®‰∫ÜËΩªÈáèÁ∫ßÊ†áËÆ∞ÁªìÊûÑ‰ø°Âè∑‰∏éÂ±ÇÊ¨°Â•ñÂä±Ê®°ÂûãÁöÑÁªìÂêàÔºå‰ΩøÁî®‰ΩôÂº¶ËØæÁ®ãÂπ≥ÊªëÂú∞Ë∞ÉÊï¥ÁªìÊûÑ‰øùÁúüÂ∫¶‰∏éËØ≠‰πâÊ∑±Â∫¶ÁöÑÈáçÁÇπÔºåÂáèÂ∞ë‰∫ÜÂ∏∏ËßÅÁöÑÊ†ºÂºèÂ¥©Ê∫ÉÂíåÂÜóÈïøÈóÆÈ¢ò„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DatarusÂú®Ê†áÂáÜÂÖ¨ÂÖ±Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåË∂ÖË∂ä‰∫ÜÂêåÁ±ªÊ®°ÂûãÔºåÂ∞§ÂÖ∂Âú®AIME 2024/2025ÂíåLiveCodeBench‰∏äÔºåÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫Ü30%ÔºåÂêåÊó∂ÊØè‰∏™Ëß£ÂÜ≥ÊñπÊ°àÁöÑtokenÊï∞ÈáèÂáèÂ∞ë‰∫Ü18-49%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåDatarusÂú®Êé®ÁêÜÊïàÁéáÂíåËæìÂá∫Ë¥®Èáè‰∏äÂùáÊúâÊòæËëóÊèêÂçá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Datarus-R1Âú®ÈáëËûç„ÄÅÂåªÂ≠¶ÂíåÊï∞ÂÄºÂàÜÊûêÁ≠âÂ§ö‰∏™È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇ‰Ωú‰∏∫ËôöÊãüÊï∞ÊçÆÂàÜÊûêÂ∏àÔºåÂÆÉËÉΩÂ§üËá™Âä®ÂåñÂ§ÑÁêÜÂ§çÊùÇÁöÑÊï∞ÊçÆÂàÜÊûê‰ªªÂä°ÔºåÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂíåË°å‰∏ö‰∏ìÂÆ∂ÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÔºåÂáèÂ∞ë‰∫∫‰∏∫ÈîôËØØ„ÄÇÊ≠§Â§ñÔºåËØ•Ê®°ÂûãÁöÑËÆæËÆ°ÁêÜÂøµ‰πü‰∏∫Êú™Êù•ÁöÑÊô∫ËÉΩÂä©ÊâãÂíåÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªüÊèê‰æõ‰∫ÜÈáçË¶ÅÁöÑÂèÇËÄÉ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present Datarus-R1-14B, a 14 B-parameter open-weights language model fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and graduate-level problem solver. Datarus is trained not on isolated question-answer pairs but on full analytical trajectories including reasoning steps, code execution, error traces, self-corrections, and final conclusions, all captured in a ReAct-style notebook format spanning finance, medicine, numerical analysis, and other quantitative domains. Our training pipeline combines (i) a trajectory-centric synthetic data generator that yielded 144 000 tagged notebook episodes, (ii) a dual-reward framework blending a lightweight tag-based structural signal with a Hierarchical Reward Model (HRM) that scores both single-step soundness and end-to-end coherence, and (iii) a memory-optimized implementation of Group Relative Policy Optimization (GRPO) featuring KV-cache reuse, sequential generation, and reference-model sharding. A cosine curriculum smoothly shifts emphasis from structural fidelity to semantic depth, reducing the format collapse and verbosity that often plague RL-aligned LLMs. A central design choice in Datarus is it dual reasoning interface. In agentic mode the model produces ReAct-tagged steps that invoke Python tools to execute real code; in reflection mode it outputs compact Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On demanding postgraduate-level problems, Datarus exhibits an "AHA-moment" pattern: it sketches hypotheses, revises them once or twice, and converges avoiding the circular, token-inflating loops common to contemporary systems. Across standard public benchmarks Datarus surpasses similar size models and even reaches the level of larger reasoning models such as QwQ-32B achieving up to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting 18-49% fewer tokens per solution.

