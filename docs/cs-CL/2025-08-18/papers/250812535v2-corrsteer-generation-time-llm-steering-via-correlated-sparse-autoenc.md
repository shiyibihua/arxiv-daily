---
layout: default
title: CorrSteer: Generation-Time LLM Steering via Correlated Sparse Autoencoder Features
---

# CorrSteer: Generation-Time LLM Steering via Correlated Sparse Autoencoder Features

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12535" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12535v2</a>
  <a href="https://arxiv.org/pdf/2508.12535.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12535v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12535v2', 'CorrSteer: Generation-Time LLM Steering via Correlated Sparse Autoencoder Features')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seonglae Cho, Zekun Wu, Adriano Koshiyama

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18 (æ›´æ–°: 2025-10-17)

**å¤‡æ³¨**: 42 pages, 9 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCorrSteerä»¥è§£å†³ç¨€ç–è‡ªç¼–ç å™¨ç‰¹å¾é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `ç‰¹å¾é€‰æ‹©` `è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–å¼•å¯¼` `æ€§èƒ½æå‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¨€ç–è‡ªç¼–ç å™¨åœ¨ä¸‹æ¸¸å¼•å¯¼ä»»åŠ¡ä¸­å—é™äºå¯¹æ¯”æ•°æ®é›†å’Œå¤§è§„æ¨¡æ¿€æ´»å­˜å‚¨ï¼Œå½±å“äº†å…¶æœ‰æ•ˆæ€§ã€‚
2. CorrSteeré€šè¿‡åœ¨æ¨ç†æ—¶å°†æ ·æœ¬æ­£ç¡®æ€§ä¸SAEæ¿€æ´»ç›¸å…³è”ï¼Œè‡ªåŠ¨é€‰æ‹©ç‰¹å¾å¹¶æå–å¼•å¯¼ç³»æ•°ï¼Œç®€åŒ–äº†æµç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCorrSteeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†ä»»åŠ¡æ€§èƒ½ï¼Œå°¤å…¶åœ¨MMLUå’ŒHarmBenchä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰èƒ½å¤Ÿä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æå–å¯è§£é‡Šç‰¹å¾ï¼Œä½†åœ¨ä¸‹æ¸¸å¼•å¯¼ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å—åˆ°å¯¹æ¯”æ•°æ®é›†æˆ–å¤§è§„æ¨¡æ¿€æ´»å­˜å‚¨çš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†CorrSteerï¼Œé€šè¿‡åœ¨æ¨ç†æ—¶å°†æ ·æœ¬æ­£ç¡®æ€§ä¸SAEæ¿€æ´»ç›¸å…³è”æ¥é€‰æ‹©ç‰¹å¾ã€‚è¯¥æ–¹æ³•ä»…ä½¿ç”¨æ¨ç†æ—¶çš„æ¿€æ´»æ¥æå–æ›´ç›¸å…³çš„ç‰¹å¾ï¼Œä»è€Œå‡å°‘è™šå‡ç›¸å…³æ€§ï¼Œå¹¶ä»å¹³å‡æ¿€æ´»ä¸­è·å–å¼•å¯¼ç³»æ•°ï¼Œè‡ªåŠ¨åŒ–æ•´ä¸ªæµç¨‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶åœ¨Gemma-2 2Bå’ŒLLaMA-3.1 8Bä¸Šæ˜¾ç¤ºå‡ºåœ¨é—®ç­”ã€åè§ç¼“è§£ã€è¶Šç‹±é˜²æŠ¤å’Œæ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„ä»»åŠ¡æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨4000ä¸ªæ ·æœ¬ä¸­MMLUæ€§èƒ½æé«˜äº†3.3%ï¼Œåœ¨ä»…108ä¸ªæ ·æœ¬ä¸­HarmBenchæé«˜äº†27.2%ã€‚æ‰€é€‰ç‰¹å¾å±•ç¤ºäº†ä¸æ¯ä¸ªä»»åŠ¡è¦æ±‚ç›¸ä¸€è‡´çš„è¯­ä¹‰æ¨¡å¼ï¼Œæ­ç¤ºäº†é©±åŠ¨æ€§èƒ½çš„æ½œåœ¨èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å·¥ä½œç¡®ç«‹äº†åŸºäºç›¸å…³æ€§çš„é€‰æ‹©ä½œä¸ºåœ¨è¯­è¨€æ¨¡å‹åº”ç”¨ä¸­è‡ªåŠ¨åŒ–SAEå¼•å¯¼çš„æœ‰æ•ˆä¸”å¯æ‰©å±•çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¨€ç–è‡ªç¼–ç å™¨åœ¨ä¸‹æ¸¸å¼•å¯¼ä»»åŠ¡ä¸­ç”±äºå¯¹æ¯”æ•°æ®é›†å’Œå¤§è§„æ¨¡æ¿€æ´»å­˜å‚¨è€Œå¯¼è‡´çš„æœ‰æ•ˆæ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç‰¹å¾é€‰æ‹©ä¸Šå­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å®ç°è‡ªåŠ¨åŒ–å’Œé«˜æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCorrSteerçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨æ¨ç†é˜¶æ®µå°†æ ·æœ¬çš„æ­£ç¡®æ€§ä¸SAEçš„æ¿€æ´»è¿›è¡Œå…³è”ï¼Œä»è€Œé€‰æ‹©å‡ºæ›´ç›¸å…³çš„ç‰¹å¾ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å‡å°‘è™šå‡ç›¸å…³æ€§ï¼Œå¹¶æé«˜ç‰¹å¾é€‰æ‹©çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCorrSteerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾é€‰æ‹©æ¨¡å—å’Œå¼•å¯¼ç³»æ•°æå–æ¨¡å—ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œç³»ç»Ÿé¦–å…ˆè®¡ç®—SAEçš„æ¿€æ´»ï¼Œç„¶åæ ¹æ®æ ·æœ¬çš„æ­£ç¡®æ€§è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼Œæœ€åä»å¹³å‡æ¿€æ´»ä¸­æå–å¼•å¯¼ç³»æ•°ï¼Œå½¢æˆè‡ªåŠ¨åŒ–çš„å¼•å¯¼æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šCorrSteerçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†åŸºäºç›¸å…³æ€§çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„ä¾èµ–å¯¹æ¯”æ•°æ®é›†çš„æ–¹å¼ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æé«˜äº†ç‰¹å¾é€‰æ‹©çš„ç›¸å…³æ€§ï¼Œè¿˜å®ç°äº†å¼•å¯¼è¿‡ç¨‹çš„è‡ªåŠ¨åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡æ–¹é¢ï¼ŒCorrSteerä½¿ç”¨äº†ç‰¹å®šçš„æ¿€æ´»è®¡ç®—æ–¹å¼å’Œå¼•å¯¼ç³»æ•°æå–ç­–ç•¥ï¼Œç¡®ä¿åœ¨æ¨ç†æ—¶èƒ½å¤Ÿé«˜æ•ˆåœ°é€‰æ‹©å‡ºä¸ä»»åŠ¡ç›¸å…³çš„ç‰¹å¾ï¼ŒåŒæ—¶å‡å°‘äº†å¯¹å­˜å‚¨èµ„æºçš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒCorrSteeråœ¨MMLUåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†3.3%çš„æ€§èƒ½æå‡ï¼Œä½¿ç”¨4000ä¸ªæ ·æœ¬ï¼›åœ¨HarmBenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œä½¿ç”¨ä»…108ä¸ªæ ·æœ¬æ—¶å®ç°äº†27.2%çš„æ€§èƒ½æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒCorrSteeråœ¨å¤šä¸ªä»»åŠ¡ä¸­æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CorrSteerçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é—®ç­”ç³»ç»Ÿã€åè§æ£€æµ‹ä¸ç¼“è§£ã€ä»¥åŠå®‰å…¨æ€§å¢å¼ºç­‰ã€‚é€šè¿‡è‡ªåŠ¨åŒ–ç‰¹å¾é€‰æ‹©å’Œå¼•å¯¼è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ä¸ä¼˜åŒ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Sparse Autoencoders (SAEs) can extract interpretable features from large language models (LLMs) without supervision. However, their effectiveness in downstream steering tasks is limited by the requirement for contrastive datasets or large activation storage. To address these limitations, we propose CorrSteer, which selects features by correlating sample correctness with SAE activations from generated tokens at inference time. This approach uses only inference-time activations to extract more relevant features, thereby reducing spurious correlations. It also obtains steering coefficients from average activations, automating the entire pipeline. Our method shows improved task performance on QA, bias mitigation, jailbreaking prevention, and reasoning benchmarks on Gemma-2 2B and LLaMA-3.1 8B, notably achieving a +3.3% improvement in MMLU performance with 4000 samples and a +27.2% improvement in HarmBench with only 108 samples. Selected features demonstrate semantically meaningful patterns aligned with each task's requirements, revealing the underlying capabilities that drive performance. Our work establishes correlation-based selection as an effective and scalable approach for automated SAE steering across language model applications.

