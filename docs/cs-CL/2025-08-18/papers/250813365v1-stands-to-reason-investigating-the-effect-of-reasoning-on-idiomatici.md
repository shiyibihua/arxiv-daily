---
layout: default
title: Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection
---

# Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13365" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13365v1</a>
  <a href="https://arxiv.org/pdf/2508.13365.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13365v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13365v1', 'Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dylan Phelps, Rodrigo Wilkens, Edward Gow-Smith, Thomas Pickard, Maggie Mi, Aline Villavicencio

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨æ¨ç†èƒ½åŠ›å¯¹ä¹ è¯­æ£€æµ‹çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¹ è¯­æ£€æµ‹` `æ¨ç†èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `é“¾å¼æ¨ç†` `æ¨¡å‹è’¸é¦` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¹ è¯­æ£€æµ‹æ–¹æ³•åœ¨ç†è§£å’Œæ¶ˆæ­§ä¹‰æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¯¹è¾ƒå°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¾èµ–è¾ƒå¤§ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡åˆ†ææ¨ç†èƒ½åŠ›å¯¹ä¹ è¯­æ£€æµ‹çš„å½±å“ï¼Œæ¢ç´¢ä¸åŒè§„æ¨¡æ¨¡å‹çš„è¡¨ç°å·®å¼‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¾ƒå°æ¨¡å‹åœ¨é“¾å¼æ¨ç†ä¸‹æœ‰æ‰€æå‡ï¼Œä½†ä»æœªè¾¾åˆ°è¾ƒå¤§æ¨¡å‹çš„æ°´å¹³ï¼Œä¸”æä¾›å®šä¹‰å¯æ”¹å–„å°æ¨¡å‹çš„è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ¨ç†æ¨¡å‹çš„åº”ç”¨æå‡äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®¸å¤šæ¶‰åŠé€»è¾‘æ­¥éª¤çš„ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ä¹ è¯­æ£€æµ‹ä½œä¸ºä¸€ç§è¯­è¨€ä»»åŠ¡ï¼Œèƒ½å¤Ÿä»è¿™ç§æ¡†æ¶ä¸­å—ç›Šã€‚æœ¬æ–‡æ¢è®¨äº†LLMsä¸­çš„æ¨ç†èƒ½åŠ›å¦‚ä½•å½±å“ä¹ è¯­æ£€æµ‹çš„æ€§èƒ½ï¼Œå¹¶è€ƒå¯Ÿäº†æ¨¡å‹è§„æ¨¡çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨ç†çš„æ•ˆæœæ¯”é¢„æœŸçš„è¦å°ä¸”å˜åŒ–å¤šç«¯ã€‚è¾ƒå°æ¨¡å‹åœ¨é“¾å¼æ¨ç†ä¸‹æ€§èƒ½æœ‰æ‰€æå‡ï¼Œä½†æœªè¾¾åˆ°åŸºç¡€æ¨¡å‹æ°´å¹³ï¼Œè€Œè¾ƒå¤§æ¨¡å‹åˆ™è¡¨ç°å‡ºé€‚åº¦çš„æ”¹è¿›ã€‚æ·±å…¥åˆ†ææ˜¾ç¤ºï¼Œè¾ƒå¤§æ¨¡å‹å¯¹ä¹ è¯­çš„ç†è§£è¾ƒå¥½ï¼Œè€Œè¾ƒå°æ¨¡å‹å¸¸å¸¸æ— æ³•è¾“å‡ºå®é™…å«ä¹‰ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è¿˜å°è¯•åœ¨å°æ¨¡å‹çš„æç¤ºä¸­æä¾›å®šä¹‰ï¼Œç»“æœåœ¨æŸäº›æƒ…å†µä¸‹æå‡äº†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¹ è¯­æ£€æµ‹ä¸­æ¨ç†èƒ½åŠ›å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç°æœ‰æ–¹æ³•åœ¨å°æ¨¡å‹ä¸Šè¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥å‡†ç¡®ç†è§£ä¹ è¯­å«ä¹‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†æä¸åŒè§„æ¨¡çš„LLMsåœ¨ä¹ è¯­æ£€æµ‹ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œæ¢è®¨å¦‚ä½•æå‡å°æ¨¡å‹çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯é€šè¿‡é“¾å¼æ¨ç†å’Œå®šä¹‰æç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä½¿ç”¨äº†ä¸€ç³»åˆ—DeepSeek-R1è’¸é¦æ¨¡å‹ï¼Œå‚æ•°ä»1.5Båˆ°70Bï¼Œè¯„ä¼°å…¶åœ¨å››ä¸ªä¹ è¯­æ£€æµ‹æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œä¹ è¯­ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°æ¨ç†èƒ½åŠ›å¯¹ä¹ è¯­æ£€æµ‹çš„å½±å“ï¼Œå‘ç°æ¨ç†æ•ˆæœåœ¨ä¸åŒæ¨¡å‹é—´çš„å·®å¼‚ï¼Œå°¤å…¶æ˜¯å°æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­è®¾ç½®äº†ä¸åŒè§„æ¨¡çš„æ¨¡å‹ï¼Œé‡‡ç”¨é“¾å¼æ¨ç†æ–¹æ³•ï¼Œå¹¶åœ¨å°æ¨¡å‹çš„æç¤ºä¸­åŠ å…¥ä¹ è¯­å®šä¹‰ï¼Œä»¥è§‚å¯Ÿå…¶å¯¹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¾ƒå°æ¨¡å‹åœ¨é“¾å¼æ¨ç†ä¸‹æ€§èƒ½æœ‰æ‰€æå‡ï¼Œä½†æœªè¾¾åˆ°åŸºç¡€æ¨¡å‹çš„æ°´å¹³ã€‚è¾ƒå¤§æ¨¡å‹ï¼ˆ14Bã€32Bå’Œ70Bï¼‰åœ¨ä¹ è¯­ç†è§£ä¸Šè¡¨ç°è‰¯å¥½ï¼Œèƒ½å¤Ÿå‡†ç¡®ç”Ÿæˆè¡¨è¾¾çš„å®šä¹‰ã€‚æä¾›å®šä¹‰çš„æç¤ºåœ¨æŸäº›æƒ…å†µä¸‹æ˜¾è‘—æ”¹å–„äº†å°æ¨¡å‹çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ä¹ è¯­æ£€æµ‹ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹å¯¹ä¹ è¯­çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥åœ¨å®é™…åº”ç”¨ä¸­æé«˜è¯­è¨€æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ï¼Œè¿›è€Œæ”¹å–„ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The recent trend towards utilisation of reasoning models has improved the performance of Large Language Models (LLMs) across many tasks which involve logical steps. One linguistic task that could benefit from this framing is idiomaticity detection, as a potentially idiomatic expression must first be understood before it can be disambiguated and serves as a basis for reasoning. In this paper, we explore how reasoning capabilities in LLMs affect idiomaticity detection performance and examine the effect of model size. We evaluate, as open source representative models, the suite of DeepSeek-R1 distillation models ranging from 1.5B to 70B parameters across four idiomaticity detection datasets. We find the effect of reasoning to be smaller and more varied than expected. For smaller models, producing chain-of-thought (CoT) reasoning increases performance from Math-tuned intermediate models, but not to the levels of the base models, whereas larger models (14B, 32B, and 70B) show modest improvements. Our in-depth analyses reveal that larger models demonstrate good understanding of idiomaticity, successfully producing accurate definitions of expressions, while smaller models often fail to output the actual meaning. For this reason, we also experiment with providing definitions in the prompts of smaller models, which we show can improve performance in some cases.

