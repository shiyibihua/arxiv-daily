---
layout: default
title: I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations
---

# I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04939" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04939v1</a>
  <a href="https://arxiv.org/pdf/2508.04939.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04939v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04939v1', 'I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Julia Kharchenko, Tanya Roosta, Aman Chadha, Chirag Shah

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­è¨€æ ‡è®°æ£€æµ‹åŸºå‡†ä»¥è¯„ä¼°LLMæ‹›è˜è¯„ä¼°ä¸­çš„åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­è¨€åè§` `æ‹›è˜è¯„ä¼°` `å…¬å¹³æ€§` `è‡ªåŠ¨åŒ–å†³ç­–` `è¯­è¨€æ ‡è®°` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„æ‹›è˜è¯„ä¼°æ–¹æ³•å¯èƒ½å­˜åœ¨å¯¹æŸäº›è¯­è¨€æ¨¡å¼çš„åè§ï¼Œå¯¼è‡´ä¸å…¬å¹³çš„è¯„ä»·ç»“æœã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºå‡†ï¼Œé€šè¿‡æ§åˆ¶è¯­è¨€å˜ä½“æ¥è¯„ä¼°LLMså¯¹è¯­è¨€æ ‡è®°çš„ååº”ï¼Œç¡®ä¿è¯­ä¹‰ç­‰ä»·æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶æ˜¾ç¤ºï¼Œæ¨¡ç³Šè¯­è¨€çš„å›ç­”å¹³å‡è¯„åˆ†ä½25.6%ï¼Œæœ‰æ•ˆè¯†åˆ«äº†æ¨¡å‹ç‰¹å®šçš„åè§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹è¯­è¨€æ ‡è®°çš„å“åº”ï¼Œè¿™äº›æ ‡è®°å¯èƒ½æ— æ„ä¸­æ­ç¤ºæ€§åˆ«ã€ç¤¾ä¼šé˜¶å±‚æˆ–åœ°åŒºèƒŒæ™¯ç­‰äººå£å±æ€§ã€‚é€šè¿‡æ„å»º100ä¸ªç»è¿‡éªŒè¯çš„é—®é¢˜-å›ç­”å¯¹çš„é¢è¯•æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬å±•ç¤ºäº†LLMså¦‚ä½•ç³»ç»Ÿæ€§åœ°æƒ©ç½šæŸäº›è¯­è¨€æ¨¡å¼ï¼Œå°¤å…¶æ˜¯æ¨¡ç³Šè¯­è¨€ï¼Œå°½ç®¡å†…å®¹è´¨é‡ç›¸å½“ã€‚æˆ‘ä»¬çš„åŸºå‡†ç”Ÿæˆå—æ§çš„è¯­è¨€å˜ä½“ï¼Œèƒ½å¤Ÿç²¾ç¡®æµ‹é‡è‡ªåŠ¨è¯„ä¼°ç³»ç»Ÿä¸­çš„äººå£åè§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæ¨¡ç³Šå›ç­”çš„å¹³å‡è¯„åˆ†ä½25.6%ï¼Œå¹¶æœ‰æ•ˆè¯†åˆ«æ¨¡å‹ç‰¹å®šçš„åè§ï¼Œä¸ºæ£€æµ‹å’Œè¡¡é‡AIç³»ç»Ÿä¸­çš„è¯­è¨€æ­§è§†å¥ å®šäº†åŸºç¡€æ¡†æ¶ï¼Œå…·æœ‰å¹¿æ³›çš„å…¬å¹³æ€§åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ‹›è˜è¯„ä¼°ä¸­å¯¹è¯­è¨€æ ‡è®°çš„åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯†åˆ«å’Œé‡åŒ–è¿™ç§åè§ï¼Œå¯¼è‡´ä¸å…¬å¹³çš„è¯„ä¼°ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŸºå‡†ï¼Œé€šè¿‡è®¾è®¡å—æ§çš„è¯­è¨€å˜ä½“æ¥è¯„ä¼°LLMså¯¹ä¸åŒè¯­è¨€æ¨¡å¼çš„ååº”ï¼Œä»è€Œç²¾ç¡®æµ‹é‡äººå£åè§ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿç¡®ä¿è¯­ä¹‰çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶çªå‡ºä¸åŒè¯­è¨€æ¨¡å¼çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€é—®é¢˜è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†100ä¸ªç»è¿‡éªŒè¯çš„é—®é¢˜-å›ç­”å¯¹ï¼Œç„¶åé€šè¿‡æ§åˆ¶è¯­è¨€å˜ä½“è¿›è¡Œæ¨¡æ‹Ÿè¯„ä¼°ï¼Œæœ€ååˆ†ææ¨¡å‹çš„è¯„åˆ†ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç”Ÿæˆå—æ§çš„è¯­è¨€å˜ä½“ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒè¯­ä¹‰ç­‰ä»·çš„åŒæ—¶ï¼Œéš”ç¦»ç‰¹å®šçš„è¯­è¨€ç°è±¡ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œåè€…å¾€å¾€æ— æ³•æœ‰æ•ˆæ§åˆ¶å˜é‡ï¼Œå¯¼è‡´åè§è¯„ä¼°çš„ä¸å‡†ç¡®ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„è¯­è¨€æ¨¡å¼è¿›è¡Œå˜ä½“ç”Ÿæˆï¼Œè®¾ç½®æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹å¯¹ä¸åŒè¯­è¨€æ¨¡å¼çš„å“åº”ï¼Œä»¥åŠç¡®ä¿è¯„ä¼°è¿‡ç¨‹ä¸­çš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ¨¡ç³Šè¯­è¨€çš„å›ç­”åœ¨è¯„åˆ†ä¸Šå¹³å‡ä½25.6%ï¼Œæœ‰æ•ˆè¯†åˆ«äº†æ¨¡å‹ç‰¹å®šçš„åè§ã€‚è¿™ä¸€å‘ç°ä¸ºæ”¹è¿›æ‹›è˜è¯„ä¼°ä¸­çš„å…¬å¹³æ€§æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ‹›è˜ç³»ç»Ÿã€æ•™è‚²è¯„ä¼°å’Œå…¶ä»–è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿï¼Œèƒ½å¤Ÿå¸®åŠ©è¯†åˆ«å’Œå‡å°‘å› è¯­è¨€åè§å¯¼è‡´çš„ä¸å…¬å¹³ç°è±¡ã€‚æœªæ¥ï¼Œè¯¥åŸºå‡†æœ‰æœ›æ¨åŠ¨æ›´å…¬å¹³çš„AIç³»ç»Ÿè®¾è®¡ï¼Œä¿ƒè¿›ç¤¾ä¼šå…¬æ­£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a comprehensive benchmark for evaluating how Large Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic markers that can inadvertently reveal demographic attributes such as gender, social class, or regional background. Through carefully constructed interview simulations using 100 validated question-response pairs, we demonstrate how LLMs systematically penalize certain linguistic patterns, particularly hedging language, despite equivalent content quality. Our benchmark generates controlled linguistic variations that isolate specific phenomena while maintaining semantic equivalence, which enables the precise measurement of demographic bias in automated evaluation systems. We validate our approach along multiple linguistic dimensions, showing that hedged responses receive 25.6% lower ratings on average, and demonstrate the benchmark's effectiveness in identifying model-specific biases. This work establishes a foundational framework for detecting and measuring linguistic discrimination in AI systems, with broad applications to fairness in automated decision-making contexts.

