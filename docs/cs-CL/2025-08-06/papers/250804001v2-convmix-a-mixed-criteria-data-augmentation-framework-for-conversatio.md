---
layout: default
title: ConvMix: A Mixed-Criteria Data Augmentation Framework for Conversational Dense Retrieval
---

# ConvMix: A Mixed-Criteria Data Augmentation Framework for Conversational Dense Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04001" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04001v2</a>
  <a href="https://arxiv.org/pdf/2508.04001.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04001v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04001v2', 'ConvMix: A Mixed-Criteria Data Augmentation Framework for Conversational Dense Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fengran Mo, Jinghan Zhang, Yuchen Hui, Jia Ao Sun, Zhichao Xu, Zhan Su, Jian-Yun Nie

**åˆ†ç±»**: cs.IR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-11-12)

**å¤‡æ³¨**: Accepted by AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºConvMixæ¡†æ¶ä»¥è§£å†³å¯¹è¯å¯†é›†æ£€ç´¢çš„æ•°æ®ç¨€ç¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹è¯æ£€ç´¢` `æ•°æ®å¢å¼º` `æ·±åº¦å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹è¯å¯†é›†æ£€ç´¢æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹éš¾ä»¥æœ‰æ•ˆè®­ç»ƒï¼Œé™åˆ¶äº†å…¶æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºConvMixæ¡†æ¶ï¼Œé€šè¿‡åŒå‘ç›¸å…³æ€§åˆ¤æ–­å¢å¼ºå’Œè´¨é‡æ§åˆ¶æœºåˆ¶ï¼Œæå‡å¯¹è¯æ£€ç´¢çš„æ ·æœ¬å¤šæ ·æ€§å’Œè´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒConvMixæ¡†æ¶è®­ç»ƒçš„æ£€ç´¢å™¨åœ¨å¤šä¸ªåŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•çš„æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹è¯æœç´¢æ—¨åœ¨é€šè¿‡å¤šè½®äº¤äº’æ»¡è¶³ç”¨æˆ·å¤æ‚çš„ä¿¡æ¯éœ€æ±‚ï¼Œå…³é”®æŒ‘æˆ˜åœ¨äºä»ä¸Šä¸‹æ–‡ç›¸å…³çš„æŸ¥è¯¢ä¸­æ­ç¤ºçœŸå®ç”¨æˆ·çš„æœç´¢æ„å›¾ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡å¯¹ä¸Šä¸‹æ–‡ç›¸å…³æŸ¥è¯¢å’Œæ–‡æ¡£å¯¹çš„ç›¸å…³æ€§åˆ¤æ–­æ¥å¾®è°ƒå¯¹è¯å¯†é›†æ£€ç´¢å™¨ï¼Œä½†é¢ä¸´æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºConvMixï¼Œä¸€ä¸ªæ··åˆæ ‡å‡†æ¡†æ¶æ¥å¢å¼ºå¯¹è¯å¯†é›†æ£€ç´¢ï¼Œæ¶µç›–æ¯”ç°æœ‰æ•°æ®å¢å¼ºæ¡†æ¶æ›´å¤šçš„æ–¹é¢ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŒå‘ç›¸å…³æ€§åˆ¤æ–­å¢å¼ºæ–¹æ¡ˆï¼Œå€ŸåŠ©å¤§å‹è¯­è¨€æ¨¡å‹ä»¥å¯æ‰©å±•çš„æ–¹å¼å®ç°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ¡†æ¶ä¸è´¨é‡æ§åˆ¶æœºåˆ¶ç»“åˆï¼Œä»¥è·å¾—è¯­ä¹‰å¤šæ ·çš„æ ·æœ¬å’Œè¿‘åˆ†å¸ƒç›‘ç£ï¼Œç»“åˆå„ç§æ ‡æ³¨æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ConvMixæ¡†æ¶è®­ç»ƒçš„å¯¹è¯å¯†é›†æ£€ç´¢å™¨åœ¨äº”ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸Šè¶…è¶Šäº†ä¹‹å‰çš„åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å…¶å“è¶Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹è¯å¯†é›†æ£€ç´¢ä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæœ‰é™çš„ç›¸å…³æ€§åˆ¤æ–­æ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹è®­ç»ƒæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šConvMixæ¡†æ¶é€šè¿‡æ··åˆæ ‡å‡†çš„æ–¹å¼å¢å¼ºæ•°æ®ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„è®­ç»ƒæ ·æœ¬ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šConvMixçš„æ•´ä½“æ¶æ„åŒ…æ‹¬åŒå‘ç›¸å…³æ€§åˆ¤æ–­å¢å¼ºæ¨¡å—å’Œè´¨é‡æ§åˆ¶æœºåˆ¶ã€‚å‰è€…ç”Ÿæˆå¤šæ ·åŒ–çš„æ ·æœ¬ï¼Œåè€…ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„è¯­ä¹‰è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šConvMixçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŒå‘ç›¸å…³æ€§åˆ¤æ–­å¢å¼ºæ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ‰©å±•è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ ·æœ¬çš„ç›¸å…³æ€§ï¼ŒåŒæ—¶ç»“åˆäº†å¤šç§æ ‡æ³¨æ•°æ®ï¼Œä»¥å®ç°æ›´å¥½çš„æ¨¡å‹è®­ç»ƒæ•ˆæœã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ConvMixæ¡†æ¶è®­ç»ƒçš„å¯¹è¯å¯†é›†æ£€ç´¢å™¨åœ¨äº”ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»ŸåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€æœç´¢å¼•æ“å’Œä¿¡æ¯æ£€ç´¢ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡å¯¹è¯å¯†é›†æ£€ç´¢çš„æ•ˆæœï¼Œå¯ä»¥æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·çš„å¤æ‚ä¿¡æ¯éœ€æ±‚ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conversational search aims to satisfy users' complex information needs via multiple-turn interactions. The key challenge lies in revealing real users' search intent from the context-dependent queries. Previous studies achieve conversational search by fine-tuning a conversational dense retriever with relevance judgments between pairs of context-dependent queries and documents. However, this training paradigm encounters data scarcity issues. To this end, we propose ConvMix, a mixed-criteria framework to augment conversational dense retrieval, which covers more aspects than existing data augmentation frameworks. We design a two-sided relevance judgment augmentation schema in a scalable manner via the aid of large language models. Besides, we integrate the framework with quality control mechanisms to obtain semantically diverse samples and near-distribution supervisions to combine various annotated data. Experimental results on five widely used benchmarks show that the conversational dense retriever trained by our ConvMix framework outperforms previous baseline methods, which demonstrates our superior effectiveness.

