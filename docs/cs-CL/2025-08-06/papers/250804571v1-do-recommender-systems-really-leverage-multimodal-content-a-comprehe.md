---
layout: default
title: Do Recommender Systems Really Leverage Multimodal Content? A Comprehensive Analysis on Multimodal Representations for Recommendation
---

# Do Recommender Systems Really Leverage Multimodal Content? A Comprehensive Analysis on Multimodal Representations for Recommendation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04571" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04571v1</a>
  <a href="https://arxiv.org/pdf/2508.04571.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04571v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04571v1', 'Do Recommender Systems Really Leverage Multimodal Content? A Comprehensive Analysis on Multimodal Representations for Recommendation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Claudio Pomo, Matteo Attimonelli, Danilo Danese, Fedelucio Narducci, Tommaso Di Noia

**åˆ†ç±»**: cs.IR, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: Accepted as Full Research Papers at CIKM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹æå‡å¤šæ¨¡æ€æ¨èç³»ç»Ÿçš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨è` `è§†è§‰è¯­è¨€æ¨¡å‹` `è¯­ä¹‰å¯¹é½` `åµŒå…¥ç”Ÿæˆ` `æ¨èç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€æ¨èç³»ç»Ÿåœ¨æ€§èƒ½æå‡çš„æ¥æºä¸Šå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œä¸»è¦ä¾èµ–äºæ¨¡æ€ç‰¹å®šçš„ç¼–ç å™¨å’Œèåˆç­–ç•¥ï¼Œç¼ºä¹æœ‰æ•ˆçš„è·¨æ¨¡æ€å¯¹é½æ§åˆ¶ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥ï¼Œé‡‡ç”¨ç»“æ„åŒ–æç¤ºè®¾è®¡ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„å¤æ‚èåˆè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLVLMsç”Ÿæˆçš„åµŒå…¥åœ¨å¤šä¸ªè®¾ç½®ä¸­æ˜¾è‘—æå‡äº†æ¨èæ€§èƒ½ï¼Œå¹¶ä¸”èƒ½å¤Ÿè§£ç ä¸ºç»“æ„åŒ–æ–‡æœ¬ï¼Œå¢å¼ºäº†å¤šæ¨¡æ€ç†è§£çš„å¯è¯„ä¼°æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ¨èç³»ç»Ÿæ—¨åœ¨é€šè¿‡æ•´åˆå¼‚æ„å†…å®¹ï¼ˆå¦‚å›¾åƒå’Œæ–‡æœ¬å…ƒæ•°æ®ï¼‰æ¥æé«˜æ¨èå‡†ç¡®æ€§ã€‚ç„¶è€Œï¼Œç›®å‰å°šä¸æ¸…æ¥šå…¶æ€§èƒ½æå‡æ˜¯å¦æºäºçœŸæ­£çš„å¤šæ¨¡æ€ç†è§£æˆ–æ¨¡å‹å¤æ‚æ€§çš„å¢åŠ ã€‚æœ¬æ–‡ç ”ç©¶äº†å¤šæ¨¡æ€é¡¹ç›®åµŒå…¥çš„ä½œç”¨ï¼Œå¼ºè°ƒäº†è¡¨ç¤ºçš„è¯­ä¹‰ä¿¡æ¯é‡ã€‚åˆæ­¥å®éªŒè¡¨æ˜ï¼Œæ ‡å‡†æå–å™¨ï¼ˆå¦‚ResNet50ã€Sentence-Bertï¼‰ç”Ÿæˆçš„åµŒå…¥èƒ½å¤Ÿæå‡æ€§èƒ½ï¼Œä½†ä¾èµ–äºç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨å’Œç¼ºä¹æ§åˆ¶çš„èåˆç­–ç•¥ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰é€šè¿‡ç»“æ„åŒ–æç¤ºç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥ï¼Œé¿å…äº†èåˆçš„éœ€æ±‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹¶ä¸”LVLMsçš„åµŒå…¥èƒ½å¤Ÿè§£ç ä¸ºç»“æ„åŒ–æ–‡æœ¬æè¿°ï¼Œç›´æ¥è¯„ä¼°å…¶å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ã€‚å°†è¿™äº›æè¿°ä½œä¸ºé™„åŠ å†…å®¹çº³å…¥æ¨èç³»ç»Ÿä¸­ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨èæ€§èƒ½ï¼ŒéªŒè¯äº†LVLMsè¾“å‡ºçš„è¯­ä¹‰æ·±åº¦å’Œå¯¹é½æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ¨èç³»ç»Ÿä¸­æ€§èƒ½æå‡æ¥æºä¸æ˜ç¡®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–äºæ¨¡æ€ç‰¹å®šçš„ç¼–ç å™¨å’Œç¼ºä¹æ§åˆ¶çš„èåˆç­–ç•¥ï¼Œå¯¼è‡´è·¨æ¨¡æ€å¯¹é½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ©ç”¨å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥çš„æ–°æ–¹æ³•ï¼Œé‡‡ç”¨ç»“æ„åŒ–æç¤ºè®¾è®¡ï¼Œæ—¨åœ¨å®ç°è¯­ä¹‰å¯¹é½è€Œæ— éœ€å¤æ‚çš„èåˆè¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€LVLMsåµŒå…¥ç”Ÿæˆå’Œæ¨èç³»ç»Ÿé›†æˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£æ”¶é›†å’Œæ•´ç†å¤šæ¨¡æ€å†…å®¹ï¼ŒLVLMsåµŒå…¥ç”Ÿæˆé˜¶æ®µåˆ©ç”¨ç»“æ„åŒ–æç¤ºç”Ÿæˆè¯­ä¹‰å¯¹é½çš„åµŒå…¥ï¼Œæœ€åå°†ç”Ÿæˆçš„åµŒå…¥é›†æˆåˆ°æ¨èç³»ç»Ÿä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºåˆ©ç”¨LVLMsç”Ÿæˆå¤šæ¨¡æ€åµŒå…¥ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„æ¨¡æ€ç‰¹å®šç¼–ç å’Œå¤æ‚èåˆï¼Œç›´æ¥å®ç°äº†è¯­ä¹‰å¯¹é½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†LVLMsçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†é€‚åˆå¤šæ¨¡æ€å†…å®¹çš„ç»“æ„åŒ–æç¤ºï¼Œç¡®ä¿ç”Ÿæˆçš„åµŒå…¥å…·æœ‰è¾ƒé«˜çš„è¯­ä¹‰ä¿¡æ¯é‡å’Œå¯¹é½æ€§ã€‚å®éªŒä¸­ä½¿ç”¨äº†æ ‡å‡†çš„æ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥éªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåˆ©ç”¨LVLMsç”Ÿæˆçš„å¤šæ¨¡æ€åµŒå…¥åœ¨å¤šä¸ªè®¾ç½®ä¸­æ˜¾è‘—æå‡äº†æ¨èæ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°15%-20%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒLVLMsåµŒå…¥ä¸ä»…æé«˜äº†æ¨èå‡†ç¡®æ€§ï¼Œè¿˜å¢å¼ºäº†å¤šæ¨¡æ€ç†è§£çš„å¯è¯„ä¼°æ€§ï¼ŒéªŒè¯äº†å…¶åœ¨æ¨èä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå•†æ¨èã€ç¤¾äº¤åª’ä½“å†…å®¹æ¨èå’Œä¸ªæ€§åŒ–ä¿¡æ¯æ¨é€ç­‰ã€‚é€šè¿‡æå‡æ¨èç³»ç»Ÿçš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ç²¾å‡†çš„æ¨èï¼Œè¿›è€Œæé«˜ç”¨æˆ·æ»¡æ„åº¦å’Œå¹³å°çš„è½¬åŒ–ç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤šæ¨¡æ€ç†è§£çš„é¢†åŸŸï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨å†…å®¹ç”Ÿæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Recommender Systems aim to improve recommendation accuracy by integrating heterogeneous content, such as images and textual metadata. While effective, it remains unclear whether their gains stem from true multimodal understanding or increased model complexity. This work investigates the role of multimodal item embeddings, emphasizing the semantic informativeness of the representations. Initial experiments reveal that embeddings from standard extractors (e.g., ResNet50, Sentence-Bert) enhance performance, but rely on modality-specific encoders and ad hoc fusion strategies that lack control over cross-modal alignment. To overcome these limitations, we leverage Large Vision-Language Models (LVLMs) to generate multimodal-by-design embeddings via structured prompts. This approach yields semantically aligned representations without requiring any fusion. Experiments across multiple settings show notable performance improvements. Furthermore, LVLMs embeddings offer a distinctive advantage: they can be decoded into structured textual descriptions, enabling direct assessment of their multimodal comprehension. When such descriptions are incorporated as side content into recommender systems, they improve recommendation performance, empirically validating the semantic depth and alignment encoded within LVLMs outputs. Our study highlights the importance of semantically rich representations and positions LVLMs as a compelling foundation for building robust and meaningful multimodal representations in recommendation tasks.

