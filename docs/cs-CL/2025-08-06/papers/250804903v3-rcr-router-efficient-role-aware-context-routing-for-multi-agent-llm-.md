---
layout: default
title: RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory
---

# RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04903" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04903v3</a>
  <a href="https://arxiv.org/pdf/2508.04903.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04903v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04903v3', 'RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jun Liu, Zhenglun Kong, Changdi Yang, Fan Yang, Tianqi Li, Peiyan Dong, Joannah Nanjekye, Hao Tang, Geng Yuan, Wei Niu, Wenbin Zhang, Pu Zhao, Xue Lin, Dong Huang, Yanzhi Wang

**åˆ†ç±»**: cs.CL, cs.AI, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-08-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRCR-Routerä»¥è§£å†³å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿä¸­çš„ä¸Šä¸‹æ–‡è·¯ç”±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ä¸Šä¸‹æ–‡è·¯ç”±` `è§’è‰²æ„ŸçŸ¥` `å†…å­˜é€‰æ‹©` `é—®ç­”ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿåè°ƒæ–¹æ¡ˆä¾èµ–é™æ€è·¯ç”±ï¼Œå¯¼è‡´èµ„æºæµªè´¹å’Œé€‚åº”æ€§ä¸è¶³ã€‚
2. RCR-Routeré€šè¿‡åŠ¨æ€é€‰æ‹©ä¸æ™ºèƒ½ä½“è§’è‰²å’Œä»»åŠ¡é˜¶æ®µç›¸å…³çš„å†…å­˜å­é›†ï¼Œä¼˜åŒ–ä¸Šä¸‹æ–‡è·¯ç”±ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRCR-Routeråœ¨å‡å°‘ä»¤ç‰Œä½¿ç”¨çš„åŒæ—¶ï¼Œä¿æŒæˆ–æå‡äº†ç­”æ¡ˆè´¨é‡ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ™ºèƒ½ä½“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿåœ¨å¤æ‚æ¨ç†å’Œåä½œå†³ç­–ä»»åŠ¡ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åè°ƒæ–¹æ¡ˆå¾€å¾€ä¾èµ–é™æ€æˆ–å…¨ä¸Šä¸‹æ–‡è·¯ç”±ç­–ç•¥ï¼Œå¯¼è‡´è¿‡åº¦çš„ä»¤ç‰Œæ¶ˆè€—ã€å†—ä½™çš„å†…å­˜æš´éœ²ä»¥åŠåœ¨äº¤äº’è½®æ¬¡ä¸­çš„é€‚åº”æ€§æœ‰é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†RCR-Routerï¼Œä¸€ä¸ªæ¨¡å—åŒ–ä¸”è§’è‰²æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡è·¯ç”±æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¤šæ™ºèƒ½ä½“LLMçš„é«˜æ•ˆã€é€‚åº”æ€§åä½œã€‚è¯¥æ–¹æ³•åŠ¨æ€é€‰æ‹©ä¸æ¯ä¸ªæ™ºèƒ½ä½“çš„è§’è‰²å’Œä»»åŠ¡é˜¶æ®µç›¸å…³çš„è¯­ä¹‰å†…å­˜å­é›†ï¼ŒåŒæ—¶éµå¾ªä¸¥æ ¼çš„ä»¤ç‰Œé¢„ç®—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRCR-Routeråœ¨ä¸‰ä¸ªå¤šè·³é—®ç­”åŸºå‡†ä¸Šå‡å°‘äº†ä»¤ç‰Œä½¿ç”¨ï¼ˆæœ€é«˜å¯è¾¾30%ï¼‰ï¼ŒåŒæ—¶æ”¹å–„æˆ–ç»´æŒäº†ç­”æ¡ˆè´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿä¸­é™æ€ä¸Šä¸‹æ–‡è·¯ç”±å¯¼è‡´çš„ä»¤ç‰Œæ¶ˆè€—è¿‡é«˜å’Œé€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨äº¤äº’è¿‡ç¨‹ä¸­æ— æ³•æœ‰æ•ˆé€‰æ‹©ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´å†—ä½™å†…å­˜ä½¿ç”¨å’Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRCR-Routerçš„æ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®æ¯ä¸ªæ™ºèƒ½ä½“çš„è§’è‰²å’Œä»»åŠ¡é˜¶æ®µåŠ¨æ€é€‰æ‹©è¯­ä¹‰ç›¸å…³çš„å†…å­˜å­é›†ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„ä¸Šä¸‹æ–‡è·¯ç”±ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¯ä¸ªæ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨ä¸¥æ ¼çš„ä»¤ç‰Œé¢„ç®—å†…è¿›è¡Œæœ‰æ•ˆçš„åä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRCR-Routerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè§’è‰²æ„ŸçŸ¥çš„å†…å­˜é€‰æ‹©æ¨¡å—ã€è½»é‡çº§è¯„åˆ†ç­–ç•¥å’Œå…±äº«å†…å­˜å­˜å‚¨ã€‚æ™ºèƒ½ä½“çš„è¾“å‡ºä¼šè¢«è¿­ä»£æ•´åˆåˆ°å…±äº«å†…å­˜ä¸­ï¼Œä»¥ä¾¿é€æ­¥ä¼˜åŒ–ä¸Šä¸‹æ–‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡æå‡ºäº†åŠ¨æ€ä¸Šä¸‹æ–‡è·¯ç”±æ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®æ™ºèƒ½ä½“çš„è§’è‰²å’Œä»»åŠ¡é˜¶æ®µé€‰æ‹©ç›¸å…³å†…å­˜å­é›†ï¼Œæ˜¾è‘—æå‡äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šRCR-Routeré‡‡ç”¨è½»é‡çº§çš„è¯„åˆ†ç­–ç•¥æ¥æŒ‡å¯¼å†…å­˜é€‰æ‹©ï¼Œç¡®ä¿åœ¨ä»¤ç‰Œé¢„ç®—å†…ä¼˜åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæå‡ºçš„ç­”æ¡ˆè´¨é‡è¯„åˆ†æŒ‡æ ‡è¶…è¶Šäº†ä¼ ç»Ÿçš„é—®ç­”å‡†ç¡®æ€§è¯„ä¼°ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹ç”Ÿæˆçš„è§£é‡Šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRCR-Routeråœ¨HotPotQAã€MuSiQueå’Œ2WikiMultihopä¸‰ä¸ªå¤šè·³é—®ç­”åŸºå‡†ä¸Šï¼Œä»¤ç‰Œä½¿ç”¨é‡å‡å°‘äº†æœ€é«˜30%ï¼ŒåŒæ—¶åœ¨ç­”æ¡ˆè´¨é‡ä¸Šä¿æŒæˆ–æå‡äº†æ€§èƒ½ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†ç»“æ„åŒ–å†…å­˜è·¯ç”±å’Œè¾“å‡ºæ„ŸçŸ¥è¯„ä¼°åœ¨å¯æ‰©å±•å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€åä½œæœºå™¨äººå’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„å¤æ‚å†³ç­–æ”¯æŒã€‚é€šè¿‡æé«˜å¤šæ™ºèƒ½ä½“LLMçš„åä½œæ•ˆç‡å’Œé€‚åº”æ€§ï¼ŒRCR-Routerèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡ç³»ç»Ÿçš„å“åº”é€Ÿåº¦å’Œå†³ç­–è´¨é‡ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to excessive token consumption, redundant memory exposure, and limited adaptability across interaction rounds. We introduce RCR-Router, a modular and role-aware context routing framework designed to enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge, this is the first routing approach that dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, while adhering to a strict token budget. A lightweight scoring policy guides memory selection, and agent outputs are iteratively integrated into a shared memory store to facilitate progressive context refinement. To better evaluate model behavior, we further propose an Answer Quality Score metric that captures LLM-generated explanations beyond standard QA accuracy. Experiments on three multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate that RCR-Router reduces token usage (up to 30%) while improving or maintaining answer quality. These results highlight the importance of structured memory routing and output-aware evaluation in advancing scalable multi-agent LLM systems.

