---
layout: default
title: Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study
---

# Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13769" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13769v1</a>
  <a href="https://arxiv.org/pdf/2508.13769.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13769v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13769v1', 'Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanna Woloszyn, Benjamin Gagl

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒå¤§å‹è¯­è¨€æ¨¡å‹ä¸å„¿ç«¥è¯­è¨€æè¿°çš„ç›¸ä¼¼æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å„¿ç«¥è¯­è¨€` `å¿ƒç†è¯­è¨€å­¦` `æ–‡æœ¬ç”Ÿæˆ` `å¤šæ¨¡æ€æç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶è¾ƒå°‘å…³æ³¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆæ¨¡æ‹Ÿå„¿ç«¥çš„è¯­è¨€ç‰¹å¾ï¼Œå­˜åœ¨ç†è§£ä¸è¶³çš„é—®é¢˜ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡æ¯”è¾ƒLLMç”Ÿæˆçš„æ–‡æœ¬ä¸å„¿ç«¥æè¿°ï¼Œé‡‡ç”¨é›¶-shotå’Œfew-shotæç¤ºï¼Œæ¢ç´¢LLMåœ¨å„¿ç«¥è¯­è¨€ç”Ÿæˆä¸­çš„è¡¨ç°ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMç”Ÿæˆçš„æ–‡æœ¬åœ¨é•¿åº¦ä¸Šè¾ƒé•¿ï¼Œä½†åœ¨è¯æ±‡ä¸°å¯Œæ€§å’Œåè¯ä½¿ç”¨ä¸Šè¡¨ç°ä¸è¶³ï¼Œæç¤ºæ–¹æ³•å¯¹ç›¸ä¼¼æ€§æå‡æœ‰é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•™è‚²ä¸­çš„ä½œç”¨æ—¥ç›Šå¢åŠ ï¼Œä½†å¯¹å…¶ç”Ÿæˆæ–‡æœ¬æ˜¯å¦ç±»ä¼¼å„¿ç«¥è¯­è¨€çš„ç ”ç©¶è¾ƒå°‘ã€‚æœ¬ç ”ç©¶é€šè¿‡æ¯”è¾ƒLLMç”Ÿæˆçš„æ–‡æœ¬ä¸å¾·å›½å„¿ç«¥å¯¹å›¾ç”»æ•…äº‹çš„æè¿°ï¼Œè¯„ä¼°LLMåœ¨å„¿ç«¥è¯­è¨€æ–¹é¢çš„è¡¨ç°ã€‚ç ”ç©¶ç”Ÿæˆäº†ä¸¤ä¸ªåŸºäºLLMçš„è¯­æ–™åº“ï¼Œä½¿ç”¨ç›¸åŒçš„å›¾ç”»æ•…äº‹å’Œä¸¤ç§æç¤ºç±»å‹ï¼šé›¶-shotå’Œfew-shotæç¤ºã€‚åˆ†æç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„æ–‡æœ¬è¾ƒé•¿ä½†è¯æ±‡ä¸°å¯Œæ€§è¾ƒä½ï¼Œä¾èµ–é«˜é¢‘è¯ï¼Œå¹¶ä¸”åè¯çš„è¡¨ç°ä¸è¶³ã€‚è¯­ä¹‰å‘é‡ç©ºé—´åˆ†ææ­ç¤ºäº†ä¸¤ä¸ªè¯­æ–™åº“åœ¨è¯­ä¹‰å±‚é¢çš„ä½ç›¸ä¼¼æ€§ã€‚å°½ç®¡few-shotæç¤ºåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¢åŠ äº†å„¿ç«¥ä¸LLMæ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œä½†ä»æœªèƒ½å®Œå…¨å¤åˆ¶è¯æ±‡å’Œè¯­ä¹‰æ¨¡å¼ã€‚ç ”ç©¶ä¸ºç†è§£LLMå¦‚ä½•é€šè¿‡å¤šæ¨¡æ€æç¤ºæ¥è¿‘å„¿ç«¥è¯­è¨€æä¾›äº†è§è§£ï¼Œå¹¶å¯¹å…¶åœ¨å¿ƒç†è¯­è¨€å­¦ç ”ç©¶å’Œæ•™è‚²ä¸­çš„åº”ç”¨æå‡ºäº†é‡è¦é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆæ¨¡æ‹Ÿå„¿ç«¥è¯­è¨€çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æ¢è®¨LLMç”Ÿæˆæ–‡æœ¬çš„å„¿ç«¥è¯­è¨€ç‰¹å¾ï¼Œå¯¼è‡´å¯¹å…¶åœ¨æ•™è‚²ä¸­çš„é€‚ç”¨æ€§ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒLLMç”Ÿæˆçš„æ–‡æœ¬ä¸å„¿ç«¥çš„æè¿°ï¼Œé‡‡ç”¨ä¸åŒçš„æç¤ºæ–¹å¼ï¼ˆé›¶-shotå’Œfew-shotï¼‰ï¼Œåˆ†æå…¶åœ¨è¯­è¨€ç‰¹å¾ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œä»¥è¯„ä¼°LLMåœ¨å„¿ç«¥è¯­è¨€ç”Ÿæˆä¸­çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ç”Ÿæˆäº†ä¸¤ä¸ªåŸºäºLLMçš„è¯­æ–™åº“ï¼Œä½¿ç”¨ç›¸åŒçš„å›¾ç”»æ•…äº‹ï¼Œå¹¶å¯¹ç”Ÿæˆæ–‡æœ¬è¿›è¡Œå¿ƒç†è¯­è¨€å­¦ç‰¹æ€§åˆ†æï¼ŒåŒ…æ‹¬è¯é¢‘ã€è¯æ±‡ä¸°å¯Œæ€§ã€å¥å­å’Œå•è¯é•¿åº¦ã€è¯æ€§æ ‡è®°åŠè¯­ä¹‰ç›¸ä¼¼æ€§ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¯”è¾ƒLLMç”Ÿæˆæ–‡æœ¬ä¸å„¿ç«¥è¯­è¨€çš„ç›¸ä¼¼æ€§ï¼Œæ­ç¤ºäº†LLMåœ¨å„¿ç«¥è¯­è¨€ç”Ÿæˆä¸­çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è¯æ±‡å’Œè¯­ä¹‰å±‚é¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸¤ç§æç¤ºæ–¹å¼ï¼ˆé›¶-shotå’Œfew-shotï¼‰ï¼Œå¹¶å¯¹ç”Ÿæˆæ–‡æœ¬çš„å¿ƒç†è¯­è¨€å­¦ç‰¹æ€§è¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œä½¿ç”¨äº†è¯­ä¹‰å‘é‡ç©ºé—´åˆ†ææ¥è¯„ä¼°æ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„æ–‡æœ¬é•¿åº¦è¾ƒé•¿ï¼Œä½†è¯æ±‡ä¸°å¯Œæ€§è¾ƒä½ï¼Œä¾èµ–é«˜é¢‘è¯ï¼Œåè¯ä½¿ç”¨ä¸è¶³ã€‚å°½ç®¡few-shotæç¤ºåœ¨ä¸€å®šç¨‹åº¦ä¸Šæé«˜äº†å„¿ç«¥ä¸LLMæ–‡æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œä½†ä»æœªèƒ½å®Œå…¨å¤åˆ¶å„¿ç«¥è¯­è¨€çš„è¯æ±‡å’Œè¯­ä¹‰æ¨¡å¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯å’Œå¿ƒç†è¯­è¨€å­¦ç ”ç©¶ã€‚é€šè¿‡ç†è§£LLMåœ¨å„¿ç«¥è¯­è¨€ç”Ÿæˆä¸­çš„è¡¨ç°ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´æœ‰æ•ˆçš„å„¿ç«¥æ•™è‚²å·¥å…·æä¾›ç†è®ºåŸºç¡€ï¼Œä¿ƒè¿›å„¿ç«¥è¯­è¨€å­¦ä¹ å’Œè®¤çŸ¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The role of large language models (LLMs) in education is increasing, yet little attention has been paid to whether LLM-generated text resembles child language. This study evaluates how LLMs replicate child-like language by comparing LLM-generated texts to a collection of German children's descriptions of picture stories. We generated two LLM-based corpora using the same picture stories and two prompt types: zero-shot and few-shot prompts specifying a general age from the children corpus. We conducted a comparative analysis across psycholinguistic text properties, including word frequency, lexical richness, sentence and word length, part-of-speech tags, and semantic similarity with word embeddings. The results show that LLM-generated texts are longer but less lexically rich, rely more on high-frequency words, and under-represent nouns. Semantic vector space analysis revealed low similarity, highlighting differences between the two corpora on the level of corpus semantics. Few-shot prompt increased similarities between children and LLM text to a minor extent, but still failed to replicate lexical and semantic patterns. The findings contribute to our understanding of how LLMs approximate child language through multimodal prompting (text + image) and give insights into their use in psycholinguistic research and education while raising important questions about the appropriateness of LLM-generated language in child-directed educational tools.

