---
layout: default
title: Comparing energy consumption and accuracy in text classification inference
---

# Comparing energy consumption and accuracy in text classification inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14170" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14170v1</a>
  <a href="https://arxiv.org/pdf/2508.14170.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14170v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14170v1', 'Comparing energy consumption and accuracy in text classification inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Johannes Zschache, Tilman Hartwig

**åˆ†ç±»**: cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: Key results in Figure 1, submitted to Nature Communications, 25 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°æ–‡æœ¬åˆ†ç±»æ¨ç†ä¸­çš„èƒ½è€—ä¸å‡†ç¡®æ€§æƒè¡¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `èƒ½æ•ˆè¯„ä¼°` `æ–‡æœ¬åˆ†ç±»` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†é˜¶æ®µ` `å¯æŒç»­AI` `æ¨¡å‹æ¶æ„` `èƒ½è€—ä¸å‡†ç¡®æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„èƒ½è€—ï¼Œæ¨ç†é˜¶æ®µçš„èƒ½æ•ˆé—®é¢˜è¢«å¿½è§†ï¼Œå¯¼è‡´å¯æŒç»­æ€§æŒ‘æˆ˜ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒæ¨¡å‹æ¶æ„å’Œç¡¬ä»¶é…ç½®ä¸‹çš„æ–‡æœ¬åˆ†ç±»æ¨ç†ï¼Œæå‡ºäº†èƒ½è€—ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡åˆ†æã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ€ä½³å‡†ç¡®æ€§æ¨¡å‹ä¹Ÿå¯å®ç°èƒ½æ•ˆï¼Œä¸”æ¨ç†èƒ½è€—ä¸æ¨¡å‹è¿è¡Œæ—¶é—´é«˜åº¦ç›¸å…³ï¼Œæä¾›äº†å®ç”¨çš„èƒ½è€—ä¼°è®¡æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œèƒ½æ•ˆå’Œå¯æŒç»­æ€§é—®é¢˜æ—¥ç›Šå—åˆ°å…³æ³¨ã€‚å°½ç®¡ä»¥å¾€ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µçš„èƒ½è€—ï¼Œæ¨ç†é˜¶æ®µçš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†ä¸åŒæ¨¡å‹æ¶æ„å’Œç¡¬ä»¶é…ç½®ä¸‹æ–‡æœ¬åˆ†ç±»æ¨ç†çš„æ¨¡å‹å‡†ç¡®æ€§ä¸èƒ½è€—ä¹‹é—´çš„æƒè¡¡ã€‚å®è¯åˆ†æè¡¨æ˜ï¼Œå‡†ç¡®æ€§æœ€ä½³çš„æ¨¡å‹ä¹Ÿå¯ä»¥å®ç°èƒ½æ•ˆï¼Œè€Œè¾ƒå¤§çš„LLMså¾€å¾€æ¶ˆè€—æ›´å¤šèƒ½é‡ä¸”åˆ†ç±»å‡†ç¡®æ€§è¾ƒä½ã€‚æ¨ç†èƒ½è€—çš„æ˜¾è‘—å˜å¼‚æ€§å—åˆ°æ¨¡å‹ç±»å‹ã€è§„æ¨¡å’Œç¡¬ä»¶è§„æ ¼çš„å½±å“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ¨ç†èƒ½è€—ä¸æ¨¡å‹è¿è¡Œæ—¶é—´ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ï¼Œè¿™è¡¨æ˜åœ¨æ— æ³•ç›´æ¥æµ‹é‡çš„æƒ…å†µä¸‹ï¼Œæ‰§è¡Œæ—¶é—´å¯ä»¥ä½œä¸ºèƒ½è€—çš„å®ç”¨ä»£ç†ã€‚è¿™äº›å‘ç°ä¸ºå¯æŒç»­AIå‘å±•æä¾›äº†å¯è¡Œçš„è§è§£ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜ã€è¡Œä¸šä»ä¸šè€…å’Œæ”¿ç­–åˆ¶å®šè€…åœ¨NLPåº”ç”¨ä¸­å¹³è¡¡æ€§èƒ½ä¸èµ„æºæ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ†ç±»æ¨ç†é˜¶æ®µçš„èƒ½è€—ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºè®­ç»ƒé˜¶æ®µï¼Œå¿½è§†äº†æ¨ç†é˜¶æ®µçš„èƒ½æ•ˆè¯„ä¼°ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´å¯æŒç»­æ€§æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒæ¨¡å‹æ¶æ„å’Œç¡¬ä»¶é…ç½®ä¸‹çš„æ¨ç†èƒ½è€—ä¸å‡†ç¡®æ€§ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„åˆ†ææ¡†æ¶ï¼Œä»¥ä¾¿åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶æé«˜èƒ½æ•ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®è¯åˆ†ææ–¹æ³•ï¼Œæ¯”è¾ƒäº†å¤šç§æ¨¡å‹æ¶æ„ï¼ˆå¦‚å°å‹ä¸å¤§å‹LLMsï¼‰åœ¨ä¸åŒç¡¬ä»¶ä¸Šçš„æ¨ç†è¡¨ç°ï¼Œåˆ†æäº†èƒ½è€—ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°å°†æ¨ç†èƒ½è€—ä¸æ¨¡å‹è¿è¡Œæ—¶é—´å…³è”èµ·æ¥ï¼Œæå‡ºè¿è¡Œæ—¶é—´ä½œä¸ºèƒ½è€—çš„ä»£ç†æŒ‡æ ‡ï¼Œå¡«è¡¥äº†æ¨ç†é˜¶æ®µèƒ½æ•ˆç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å¤šç§æ¨¡å‹æ¶æ„å’Œç¡¬ä»¶é…ç½®ï¼Œå…³æ³¨æ¨¡å‹ç±»å‹ã€è§„æ¨¡åŠå…¶å¯¹èƒ½è€—çš„å½±å“ï¼Œé‡‡ç”¨äº†æ ‡å‡†åŒ–çš„è¯„ä¼°æµç¨‹ä»¥ç¡®ä¿ç»“æœçš„å¯æ¯”æ€§ã€‚å®éªŒä¸­è¿˜è€ƒè™‘äº†ä¸åŒçš„è¿è¡Œæ—¶é—´æµ‹é‡æ–¹æ³•ï¼Œä»¥éªŒè¯å…¶ä¸èƒ½è€—çš„ç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€ä½³å‡†ç¡®æ€§æ¨¡å‹åœ¨èƒ½è€—æ–¹é¢ä¹Ÿè¡¨ç°å‡ºè‰²ï¼Œæ¨ç†èƒ½è€—èŒƒå›´ä»å°äºæ¯«ç“¦åˆ°è¶…è¿‡åƒç“¦æ—¶ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„å˜å¼‚æ€§ã€‚æ­¤å¤–ï¼Œæ¨ç†èƒ½è€—ä¸æ¨¡å‹è¿è¡Œæ—¶é—´ä¹‹é—´çš„å¼ºç›¸å…³æ€§ä¸ºèƒ½è€—ä¼°ç®—æä¾›äº†æ–°çš„è§†è§’ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æå’Œä¿¡æ¯æ£€ç´¢ç­‰ä»»åŠ¡ã€‚é€šè¿‡ä¼˜åŒ–æ¨¡å‹çš„èƒ½è€—ä¸å‡†ç¡®æ€§å¹³è¡¡ï¼Œç ”ç©¶ä¸ºAIç³»ç»Ÿçš„å¯æŒç»­å‘å±•æä¾›äº†é‡è¦æŒ‡å¯¼ï¼Œèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šå’Œç ”ç©¶æœºæ„åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹å®ç°é«˜æ•ˆçš„æ¨¡å‹éƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increasing deployment of large language models (LLMs) in natural language processing (NLP) tasks raises concerns about energy efficiency and sustainability. While prior research has largely focused on energy consumption during model training, the inference phase has received comparatively less attention. This study systematically evaluates the trade-offs between model accuracy and energy consumption in text classification inference across various model architectures and hardware configurations. Our empirical analysis shows that the best-performing model in terms of accuracy can also be energy-efficient, while larger LLMs tend to consume significantly more energy with lower classification accuracy. We observe substantial variability in inference energy consumption ($<$mWh to $>$kWh), influenced by model type, model size, and hardware specifications. Additionally, we find a strong correlation between inference energy consumption and model runtime, indicating that execution time can serve as a practical proxy for energy usage in settings where direct measurement is not feasible. These findings have implications for sustainable AI development, providing actionable insights for researchers, industry practitioners, and policymakers seeking to balance performance and resource efficiency in NLP applications.

