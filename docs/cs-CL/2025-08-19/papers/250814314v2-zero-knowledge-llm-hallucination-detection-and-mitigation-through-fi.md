---
layout: default
title: Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency
---

# Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14314" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14314v2</a>
  <a href="https://arxiv.org/pdf/2508.14314.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14314v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14314v2', 'Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aman Goel, Daniel Schwartz, Yanjun Qi

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-11-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFinch-Zkä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„å¹»è§‰æ£€æµ‹ä¸ç¼“è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `è·¨æ¨¡å‹ä¸€è‡´æ€§` `å†…å®¹ç”Ÿæˆ` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å®¹æ˜“å‡ºç°å¹»è§‰ï¼Œå¯¼è‡´è¾“å‡ºçš„äº‹å®ä¸å‡†ç¡®ï¼Œå½±å“ç”¨æˆ·ä¿¡ä»»ã€‚
2. Finch-Zké€šè¿‡ç»†ç²’åº¦çš„è·¨æ¨¡å‹ä¸€è‡´æ€§æ£€æŸ¥å’Œé’ˆå¯¹æ€§ç¼“è§£æŠ€æœ¯ï¼Œæä¾›äº†ä¸€ç§æ— éœ€å¤–éƒ¨çŸ¥è¯†æºçš„å¹»è§‰æ£€æµ‹ä¸ä¿®æ­£æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFinch-Zkåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†å¹»è§‰æ£€æµ‹å’Œå›ç­”å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†ä»ç„¶å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†åŒ…å«äº‹å®é”™è¯¯çš„å†…å®¹ã€‚æœ¬æ–‡æå‡ºäº†Finch-Zkï¼Œä¸€ä¸ªé»‘ç®±æ¡†æ¶ï¼Œé€šè¿‡ç»†ç²’åº¦çš„è·¨æ¨¡å‹ä¸€è‡´æ€§æ¥æ£€æµ‹å’Œç¼“è§£LLMè¾“å‡ºä¸­çš„å¹»è§‰ï¼Œè€Œæ— éœ€å¤–éƒ¨çŸ¥è¯†æºã€‚Finch-Zkå¼•å…¥äº†ä¸¤ä¸ªå…³é”®åˆ›æ–°ï¼š1ï¼‰è·¨æ¨¡å‹ä¸€è‡´æ€§æ£€æŸ¥ç­–ç•¥ï¼Œé€šè¿‡æ¯”è¾ƒæ¥è‡ªè¯­ä¹‰ç­‰ä»·æç¤ºçš„ä¸åŒæ¨¡å‹ç”Ÿæˆçš„å“åº”ï¼Œæ­ç¤ºç»†ç²’åº¦çš„ä¸å‡†ç¡®æ€§ï¼›2ï¼‰é’ˆå¯¹æ€§ç¼“è§£æŠ€æœ¯ï¼Œå¯¹é—®é¢˜æ®µè½è¿›è¡Œç²¾ç¡®ä¿®æ­£ï¼ŒåŒæ—¶ä¿ç•™å‡†ç¡®å†…å®¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFinch-Zkåœ¨FELMæ•°æ®é›†ä¸Šæé«˜äº†å¹»è§‰æ£€æµ‹çš„F1åˆ†æ•°ï¼Œè¾ƒç°æœ‰æ–¹æ³•æå‡äº†6-39%ã€‚åœ¨GPQA-diamondæ•°æ®é›†ä¸Šï¼ŒFinch-Zkåœ¨åº”ç”¨äºLlama 4 Maverickå’ŒClaude 4 Sonnetç­‰æœ€å…ˆè¿›æ¨¡å‹æ—¶ï¼Œå›ç­”å‡†ç¡®ç‡æé«˜äº†æœ€å¤š9ä¸ªç™¾åˆ†ç‚¹ã€‚å¤šæ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒFinch-Zkä¸ºæå‡ç”Ÿäº§LLMç³»ç»Ÿçš„äº‹å®å¯é æ€§æä¾›äº†å®ç”¨çš„ã€å¯éƒ¨ç½²çš„ä¿éšœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹æ—¶çš„å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–å¤–éƒ¨çŸ¥è¯†æºï¼Œéš¾ä»¥å®æ—¶åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFinch-Zkçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç»†ç²’åº¦çš„è·¨æ¨¡å‹ä¸€è‡´æ€§æ£€æŸ¥ï¼Œæ¯”è¾ƒä¸åŒæ¨¡å‹åœ¨ç›¸åŒè¯­ä¹‰æç¤ºä¸‹çš„è¾“å‡ºï¼Œä»¥è¯†åˆ«å’Œä¿®æ­£å¹»è§‰å†…å®¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFinch-Zkçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè·¨æ¨¡å‹ä¸€è‡´æ€§æ£€æŸ¥æ¨¡å—å’Œé’ˆå¯¹æ€§ç¼“è§£æ¨¡å—ã€‚å‰è€…è´Ÿè´£æ£€æµ‹ä¸ä¸€è‡´æ€§ï¼Œåè€…åˆ™å¯¹é—®é¢˜æ®µè½è¿›è¡Œä¿®æ­£ã€‚

**å…³é”®åˆ›æ–°**ï¼šFinch-Zkçš„åˆ›æ–°åœ¨äºå…¶é»‘ç®±æ¡†æ¶è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¤–éƒ¨çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ¨¡å‹é—´çš„æ¯”è¾ƒå®ç°å¹»è§‰æ£€æµ‹ä¸ä¿®æ­£ï¼Œæ˜¾è‘—æå‡äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒFinch-Zké‡‡ç”¨äº†ç²¾ç¡®çš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹è¾“å‡ºçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶è®¾è®¡äº†é«˜æ•ˆçš„å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿åœ¨å¤šç§æ¨¡å‹é—´çš„æœ‰æ•ˆæ¯”è¾ƒã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒFinch-Zkèƒ½å¤Ÿåœ¨ä¿æŒå‡†ç¡®å†…å®¹çš„åŒæ—¶ï¼Œé’ˆå¯¹æ€§åœ°ä¿®æ­£é”™è¯¯ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Finch-Zkåœ¨FELMæ•°æ®é›†ä¸Šæé«˜äº†å¹»è§‰æ£€æµ‹çš„F1åˆ†æ•°ï¼Œè¾ƒç°æœ‰æ–¹æ³•æå‡äº†6-39%ã€‚åœ¨GPQA-diamondæ•°æ®é›†ä¸Šï¼ŒFinch-Zkåœ¨åº”ç”¨äºæœ€å…ˆè¿›æ¨¡å‹æ—¶ï¼Œå›ç­”å‡†ç¡®ç‡æé«˜äº†æœ€å¤š9ä¸ªç™¾åˆ†ç‚¹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Finch-Zkçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨éœ€è¦é«˜å¯é æ€§å†…å®¹ç”Ÿæˆçš„é¢†åŸŸï¼Œå¦‚æ•™è‚²ã€åŒ»ç–—å’Œæ³•å¾‹ç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„äº‹å®å‡†ç¡®æ€§ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¢å¼ºç”¨æˆ·å¯¹AIç”Ÿæˆå†…å®¹çš„ä¿¡ä»»ï¼Œæ¨åŠ¨å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠå’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have demonstrated impressive capabilities across diverse tasks, but they remain susceptible to hallucinations--generating content that appears plausible but contains factual inaccuracies. We present Finch-Zk, a black-box framework that leverages fine-grained cross-model consistency to detect and mitigate hallucinations in LLM outputs without requiring external knowledge sources. Finch-Zk introduces two key innovations: 1) a cross-model consistency checking strategy that reveals fine-grained inaccuracies by comparing responses generated by diverse models from semantically-equivalent prompts, and 2) a targeted mitigation technique that applies precise corrections to problematic segments while preserving accurate content. Experiments on the FELM dataset show Finch-Zk improves hallucination detection F1 scores by 6-39\% compared to existing approaches. For mitigation, Finch-Zk achieves up to 9 absolute percentage points improvement in answer accuracy on the GPQA-diamond dataset when applied to state-of-the-art models like Llama 4 Maverick and Claude 4 Sonnet. Extensive evaluation on multiple datasets demonstrates that Finch-Zk provides a practical, deployment-ready safeguard for enhancing factual reliability in production LLM systems.

