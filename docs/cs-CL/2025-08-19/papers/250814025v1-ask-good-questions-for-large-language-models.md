---
layout: default
title: Ask Good Questions for Large Language Models
---

# Ask Good Questions for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14025" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14025v1</a>
  <a href="https://arxiv.org/pdf/2508.14025.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14025v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14025v1', 'Ask Good Questions for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qi Wu, Zhongqi Lu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAsk-Good-Questionæ¡†æ¶ä»¥è§£å†³å¯¹è¯ç³»ç»Ÿä¸­çš„ç”¨æˆ·å›°æƒ‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯¹è¯ç³»ç»Ÿ` `ç”¨æˆ·å›°æƒ‘` `ä¿¡æ¯æ£€ç´¢` `å¼•å¯¼é—®é¢˜ç”Ÿæˆ` `æ¦‚å¿µå¢å¼º` `é¡¹ç›®ååº”ç†è®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹è¯ç³»ç»Ÿåœ¨å¼•å¯¼ç”¨æˆ·è¯é¢˜æ—¶å¸¸å¸¸æ— æ³•è¯†åˆ«ç”¨æˆ·çš„å›°æƒ‘ï¼Œå¯¼è‡´ä¿¡æ¯æ£€ç´¢æ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºçš„AGQæ¡†æ¶ç»“åˆäº†CEIRTæ¨¡å‹ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³å¹¶ç”Ÿæˆå¼•å¯¼æ€§é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAGQæ¡†æ¶åœ¨ä¿¡æ¯æ£€ç´¢æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥æ˜¾è‘—æå‡äº†å¯¹è¯ç³»ç»Ÿçš„æ€§èƒ½ï¼Œä½†ç°æœ‰æ–¹æ³•å¸¸å¸¸æ— æ³•å‡†ç¡®å¼•å¯¼è¯é¢˜ï¼ŒåŸå› åœ¨äºå®ƒä»¬æ— æ³•è¯†åˆ«ç”¨æˆ·åœ¨ç›¸å…³æ¦‚å¿µä¸Šçš„å›°æƒ‘ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Ask-Good-Questionï¼ˆAGQï¼‰æ¡†æ¶ï¼Œé‡‡ç”¨æ”¹è¿›çš„æ¦‚å¿µå¢å¼ºé¡¹ç›®ååº”ç†è®ºï¼ˆCEIRTï¼‰æ¨¡å‹ï¼Œæ›´å¥½åœ°è¯†åˆ«ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³ã€‚æˆ‘ä»¬çš„è´¡çŒ®åœ¨äºå°†CEIRTæ¨¡å‹ä¸LLMsç»“åˆï¼Œç›´æ¥ç”ŸæˆåŸºäºå¯å‘æ€§æ–‡æœ¬çš„å¼•å¯¼é—®é¢˜ï¼Œä»è€Œæ˜¾è‘—æé«˜é—®ç­”è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æ£€ç´¢æ•ˆç‡ã€‚ä¸å…¶ä»–åŸºçº¿æ–¹æ³•çš„æ¯”è¾ƒæ˜¾ç¤ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æå‡ç”¨æˆ·ä¿¡æ¯æ£€ç´¢ä½“éªŒæ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¯¹è¯ç³»ç»Ÿæ— æ³•æœ‰æ•ˆè¯†åˆ«ç”¨æˆ·å›°æƒ‘çš„é—®é¢˜ï¼Œå¯¼è‡´ç”¨æˆ·åœ¨ä¿¡æ¯æ£€ç´¢è¿‡ç¨‹ä¸­æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAGQæ¡†æ¶é€šè¿‡å¼•å…¥CEIRTæ¨¡å‹ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¯„ä¼°ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³ï¼Œå¹¶åŸºäºæ­¤ç”Ÿæˆé’ˆå¯¹æ€§çš„å¼•å¯¼é—®é¢˜ï¼Œä»è€Œæé«˜ä¿¡æ¯æ£€ç´¢çš„ç›¸å…³æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAGQæ¡†æ¶ä¸»è¦åŒ…æ‹¬ç”¨æˆ·çŸ¥è¯†æ°´å¹³è¯„ä¼°æ¨¡å—å’Œå¼•å¯¼é—®é¢˜ç”Ÿæˆæ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡CEIRTæ¨¡å‹è¯„ä¼°ç”¨æˆ·çš„çŸ¥è¯†æ°´å¹³ï¼Œç„¶åæ ¹æ®è¯„ä¼°ç»“æœç”Ÿæˆç›¸åº”çš„å¼•å¯¼é—®é¢˜ï¼Œæœ€åå°†é—®é¢˜åé¦ˆç»™ç”¨æˆ·ä»¥æé«˜å¯¹è¯çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†CEIRTæ¨¡å‹ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å¼•å¯¼é—®é¢˜ç”Ÿæˆæœºåˆ¶ï¼Œè¿™ä¸€æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ç”¨æˆ·çš„çŸ¥è¯†ç›²ç‚¹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´é«˜çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒCEIRTæ¨¡å‹çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾ç»†è°ƒæ•´ï¼Œä»¥ç¡®ä¿å…¶åœ¨ä¸åŒçŸ¥è¯†æ°´å¹³ç”¨æˆ·ä¸­çš„é€‚ç”¨æ€§ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿè€ƒè™‘äº†ç”¨æˆ·åé¦ˆçš„å¤šæ ·æ€§ï¼Œä»¥ä¼˜åŒ–ç”Ÿæˆé—®é¢˜çš„ç›¸å…³æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAGQæ¡†æ¶åœ¨ä¿¡æ¯æ£€ç´¢æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºçº¿æ–¹æ³•ï¼Œç”¨æˆ·æ»¡æ„åº¦æå‡äº†çº¦30%ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„å¼•å¯¼é—®é¢˜åœ¨ç›¸å…³æ€§å’Œæœ‰æ•ˆæ€§ä¸Šä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ï¼ŒéªŒè¯äº†CEIRTæ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œåˆ›æ–°æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€åœ¨çº¿å®¢æœå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜å¯¹è¯ç³»ç»Ÿçš„å¼•å¯¼èƒ½åŠ›ï¼ŒAGQæ¡†æ¶èƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¿«åœ°è·å–æ‰€éœ€ä¿¡æ¯ï¼Œæå‡å­¦ä¹ å’ŒæœåŠ¡ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸå¾—åˆ°æ¨å¹¿ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have significantly improved the performance of dialog systems, yet current approaches often fail to provide accurate guidance of topic due to their inability to discern user confusion in related concepts. To address this, we introduce the Ask-Good-Question (AGQ) framework, which features an improved Concept-Enhanced Item Response Theory (CEIRT) model to better identify users' knowledge levels. Our contributions include applying the CEIRT model along with LLMs to directly generate guiding questions based on the inspiring text, greatly improving information retrieval efficiency during the question & answer process. Through comparisons with other baseline methods, our approach outperforms by significantly enhencing the users' information retrieval experiences.

