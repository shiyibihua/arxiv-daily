---
layout: default
title: CRISP: Persistent Concept Unlearning via Sparse Autoencoders
---

# CRISP: Persistent Concept Unlearning via Sparse Autoencoders

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13650" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13650v2</a>
  <a href="https://arxiv.org/pdf/2508.13650.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13650v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13650v2', 'CRISP: Persistent Concept Unlearning via Sparse Autoencoders')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tomer Ashuach, Dana Arad, Aaron Mueller, Martin Tutek, Yonatan Belinkov

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-11-20)

**å¤‡æ³¨**: 18 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCRISPä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†å»é™¤é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `çŸ¥è¯†å»é™¤` `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§` `ç‰¹å¾æŠ‘åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºç¨€ç–è‡ªç¼–ç å™¨çš„æ–¹æ³•åœ¨æ¨ç†æ—¶è¿›è¡Œå¹²é¢„ï¼Œæ— æ³•å®ç°æ¨¡å‹å‚æ•°çš„æŒä¹…æ€§å˜åŒ–ï¼Œæ˜“è¢«æ¶æ„è¡Œä¸ºè€…ç»•è¿‡ã€‚
2. CRISPé€šè¿‡è‡ªåŠ¨è¯†åˆ«å¤šä¸ªå±‚ä¸­çš„æ˜¾è‘—ç‰¹å¾å¹¶æŠ‘åˆ¶å…¶æ¿€æ´»ï¼Œæä¾›äº†ä¸€ç§é«˜æ•ˆçš„æŒä¹…æ¦‚å¿µå»é™¤æ–¹æ¡ˆã€‚
3. åœ¨WMDPåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCRISPåœ¨å®‰å…¨å…³é”®å»é™¤ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒæˆåŠŸå»é™¤äº†æœ‰å®³çŸ¥è¯†ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„æ•´ä½“èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›éƒ¨ç½²ï¼Œé€‰æ‹©æ€§å»é™¤ä¸å¿…è¦çŸ¥è¯†çš„éœ€æ±‚å˜å¾—å°¤ä¸ºé‡è¦ã€‚è¿‘æœŸç ”ç©¶åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰å¯¹å•ä¹‰ç‰¹å¾è¿›è¡Œç²¾ç¡®å¹²é¢„ï¼Œä½†å¤§å¤šæ•°SAEæ–¹æ³•ä»…åœ¨æ¨ç†æ—¶æ“ä½œï¼Œæ— æ³•åœ¨æ¨¡å‹å‚æ•°ä¸­å®ç°æŒä¹…æ€§å˜åŒ–ã€‚æœ¬æ–‡æå‡ºCRISPï¼Œä¸€ç§åŸºäºSAEsçš„å‚æ•°é«˜æ•ˆçš„æŒä¹…æ¦‚å¿µå»é™¤æ–¹æ³•ã€‚CRISPè‡ªåŠ¨è¯†åˆ«å¤šä¸ªå±‚ä¸­çš„æ˜¾è‘—SAEç‰¹å¾å¹¶æŠ‘åˆ¶å…¶æ¿€æ´»ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨WMDPåŸºå‡†çš„å®‰å…¨å…³é”®å»é™¤ä»»åŠ¡ä¸­ä¼˜äºä»¥å¾€æ–¹æ³•ï¼ŒæˆåŠŸå»é™¤æœ‰å®³çŸ¥è¯†ï¼ŒåŒæ—¶ä¿ç•™ä¸€èˆ¬å’Œé¢†åŸŸå†…èƒ½åŠ›ã€‚ç‰¹å¾çº§åˆ†ææ˜¾ç¤ºï¼ŒCRISPå®ç°äº†ç›®æ ‡ä¸è‰¯æ€§æ¦‚å¿µä¹‹é—´çš„è¯­ä¹‰ä¸€è‡´åˆ†ç¦»ï¼Œå…è®¸ç²¾ç¡®æŠ‘åˆ¶ç›®æ ‡ç‰¹å¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ä¸å¿…è¦çŸ¥è¯†çš„å»é™¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šåœ¨æ¨ç†é˜¶æ®µè¿›è¡Œå¹²é¢„ï¼Œæ— æ³•å®ç°æŒä¹…æ€§æ•ˆæœï¼Œä¸”æ˜“è¢«æ¶æ„æ”»å‡»è€…é€†è½¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCRISPçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨è‡ªåŠ¨è¯†åˆ«å’ŒæŠ‘åˆ¶å¤šä¸ªå±‚ä¸­çš„æ˜¾è‘—ç‰¹å¾ï¼Œä»è€Œå®ç°æŒä¹…çš„æ¦‚å¿µå»é™¤ã€‚è¯¥è®¾è®¡æ—¨åœ¨ç¡®ä¿æ¨¡å‹åœ¨å»é™¤æœ‰å®³çŸ¥è¯†çš„åŒæ—¶ï¼Œä¿ç•™å…¶æœ‰æ•ˆæ€§å’ŒåŠŸèƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRISPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾è¯†åˆ«æ¨¡å—å’Œæ¿€æ´»æŠ‘åˆ¶æ¨¡å—ã€‚ç‰¹å¾è¯†åˆ«æ¨¡å—é€šè¿‡åˆ†ææ¨¡å‹çš„å¤šä¸ªå±‚ï¼Œè¯†åˆ«å‡ºéœ€è¦å»é™¤çš„æ˜¾è‘—ç‰¹å¾ï¼›æ¿€æ´»æŠ‘åˆ¶æ¨¡å—åˆ™è´Ÿè´£é™ä½è¿™äº›ç‰¹å¾çš„æ¿€æ´»æ°´å¹³ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRISPçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨å¤šä¸ªå±‚æ¬¡ä¸Šå®ç°ç‰¹å¾çš„æŒä¹…æ€§å»é™¤ï¼Œè€Œéä»…é™äºæ¨ç†é˜¶æ®µçš„ä¸´æ—¶å¹²é¢„ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†å»é™¤æ•ˆæœçš„ç¨³å®šæ€§å’Œå®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒCRISPé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç‰¹å¾æŠ‘åˆ¶æ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šç»“åˆäº†å¤šå±‚ç¨€ç–è‡ªç¼–ç å™¨ï¼Œä»¥ç¡®ä¿ç‰¹å¾çš„æœ‰æ•ˆè¯†åˆ«ä¸æŠ‘åˆ¶ã€‚å…·ä½“çš„å‚æ•°å’Œç»“æ„è®¾è®¡ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨WMDPåŸºå‡†æµ‹è¯•ä¸­ï¼ŒCRISPåœ¨å®‰å…¨å…³é”®å»é™¤ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä»¥å¾€æ–¹æ³•ï¼ŒæˆåŠŸå»é™¤äº†æœ‰å®³çŸ¥è¯†ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„æ•´ä½“èƒ½åŠ›ï¼Œå…·ä½“æå‡å¹…åº¦æœªæ˜ç¡®è¯´æ˜ï¼Œä½†å®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨ç‰¹å¾çº§åˆ«ä¸Šå®ç°äº†æ›´ä¸ºç²¾ç¡®çš„æŠ‘åˆ¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CRISPçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒçŸ¥è¯†ç®¡ç†å’Œå®‰å…¨æ§åˆ¶çš„åœºæ™¯ä¸­ï¼Œå¦‚é‡‘èã€åŒ»ç–—å’Œæ³•å¾‹ç­‰å®‰å…¨å…³é”®é¢†åŸŸã€‚é€šè¿‡æœ‰æ•ˆå»é™¤æœ‰å®³çŸ¥è¯†ï¼ŒCRISPèƒ½å¤Ÿæå‡æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œå‡å°‘æ½œåœ¨çš„é£é™©å’Œè¯¯ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šå…³äºæ¨¡å‹çŸ¥è¯†å»é™¤çš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly deployed in real-world applications, the need to selectively remove unwanted knowledge while preserving model utility has become paramount. Recent work has explored sparse autoencoders (SAEs) to perform precise interventions on monosemantic features. However, most SAE-based methods operate at inference time, which does not create persistent changes in the model's parameters. Such interventions can be bypassed or reversed by malicious actors with parameter access. We introduce CRISP, a parameter-efficient method for persistent concept unlearning using SAEs. CRISP automatically identifies salient SAE features across multiple layers and suppresses their activations. We experiment with two LLMs and show that our method outperforms prior approaches on safety-critical unlearning tasks from the WMDP benchmark, successfully removing harmful knowledge while preserving general and in-domain capabilities. Feature-level analysis reveals that CRISP achieves semantically coherent separation between target and benign concepts, allowing precise suppression of the target features.

