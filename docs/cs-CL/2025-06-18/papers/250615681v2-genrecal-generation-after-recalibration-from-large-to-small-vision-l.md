---
layout: default
title: GenRecal: Generation after Recalibration from Large to Small Vision-Language Models
---

# GenRecal: Generation after Recalibration from Large to Small Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15681" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15681v2</a>
  <a href="https://arxiv.org/pdf/2506.15681.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15681v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15681v2', 'GenRecal: Generation after Recalibration from Large to Small Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Byung-Kwan Lee, Ryo Hachiuma, Yong Man Ro, Yu-Chiang Frank Wang, Yueh-Hua Wu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-11-18)

**å¤‡æ³¨**: Project page: https://byungkwanlee.github.io/GenRecal-page/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGenRecalä»¥è§£å†³å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹çš„è’¸é¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `é‡æ ¡å‡†` `å¤šæ¨¡æ€å­¦ä¹ ` `æ¨¡å‹å‹ç¼©` `èµ„æºå—é™è®¾å¤‡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰è¯­è¨€æ¨¡å‹åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„éƒ¨ç½²é¢ä¸´å·¨å¤§çš„è®¡ç®—éœ€æ±‚ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„GenRecalæ¡†æ¶é€šè¿‡é‡æ ¡å‡†å™¨å®ç°å¼‚æ„VLMä¹‹é—´çš„ç‰¹å¾å¯¹é½ï¼Œä¿ƒè¿›çŸ¥è¯†è½¬ç§»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGenRecalåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¤§è§„æ¨¡VLMã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„è¿›å±•ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œåœ¨æ€§èƒ½ä¸Šä¸å°é—­æºç³»ç»Ÿå¦‚GPT-4Vç›¸å½“ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šçš„å®é™…éƒ¨ç½²ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºå…¶å·¨å¤§çš„è®¡ç®—éœ€æ±‚ã€‚å› æ­¤ï¼Œå¦‚ä½•å°†å¤§å‹VLMçš„çŸ¥è¯†è’¸é¦åˆ°æ›´å°ã€æ›´é«˜æ•ˆçš„æ¨¡å‹ä¸­æˆä¸ºç ”ç©¶çƒ­ç‚¹ã€‚é’ˆå¯¹VLMæ¶æ„çš„å¤šæ ·æ€§åŠå…¶åœ¨è¯æ±‡å¤§å°ã€æ ‡è®°æ‹†åˆ†å’Œç´¢å¼•é¡ºåºä¸Šçš„å·®å¼‚ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šç”¨çš„è’¸é¦æ¡†æ¶GenRecalã€‚GenRecalé€šè¿‡ä¸€ä¸ªé‡æ ¡å‡†å™¨å¯¹å¼‚æ„VLMä¹‹é—´çš„ç‰¹å¾è¡¨ç¤ºè¿›è¡Œå¯¹é½å’Œé€‚é…ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„çŸ¥è¯†è½¬ç§»ã€‚é€šè¿‡åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†GenRecalæ˜¾è‘—æå‡äº†åŸºçº¿æ€§èƒ½ï¼Œæœ€ç»ˆè¶…è¶Šäº†å¤§è§„æ¨¡çš„å¼€æºå’Œé—­æºVLMã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²çš„è®¡ç®—éœ€æ±‚è¿‡é«˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†è’¸é¦è¿‡ç¨‹ä¸­å—é™äºç‰¹å®šVLMæ¶æ„çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´çŸ¥è¯†è½¬ç§»æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„GenRecalæ¡†æ¶é€šè¿‡é‡æ ¡å‡†å™¨å¯¹ä¸åŒVLMçš„ç‰¹å¾è¡¨ç¤ºè¿›è¡Œå¯¹é½å’Œé€‚é…ï¼Œä»è€Œå®ç°è·¨æ¶æ„çš„æœ‰æ•ˆçŸ¥è¯†è½¬ç§»ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ä¸åŒç±»å‹çš„VLMèƒ½å¤Ÿå…±äº«çŸ¥è¯†ï¼Œå…‹æœäº†æ¶æ„å·®å¼‚å¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGenRecalçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé‡æ ¡å‡†å™¨ã€çŸ¥è¯†è’¸é¦æ¨¡å—å’Œæ€§èƒ½è¯„ä¼°æ¨¡å—ã€‚é‡æ ¡å‡†å™¨è´Ÿè´£å¯¹é½ç‰¹å¾è¡¨ç¤ºï¼ŒçŸ¥è¯†è’¸é¦æ¨¡å—åˆ™è¿›è¡ŒçŸ¥è¯†çš„å®é™…è½¬ç§»ï¼Œæœ€åé€šè¿‡æ€§èƒ½è¯„ä¼°æ¨¡å—éªŒè¯è’¸é¦æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šGenRecalçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶é‡æ ¡å‡†å™¨çš„è®¾è®¡ï¼Œä½¿å¾—ä¸åŒVLMä¹‹é—´çš„ç‰¹å¾è¡¨ç¤ºèƒ½å¤Ÿæœ‰æ•ˆå¯¹é½ï¼Œä»è€Œå®ç°çŸ¥è¯†çš„é«˜æ•ˆè½¬ç§»ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„è’¸é¦æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿå¤„ç†å¤šç§VLMæ¶æ„çš„å¼‚æ„æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡æ ¡å‡†å™¨çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾ç»†è°ƒæ•´ï¼Œä»¥ç¡®ä¿ç‰¹å¾å¯¹é½çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿç»è¿‡ä¼˜åŒ–ï¼Œä»¥å¹³è¡¡çŸ¥è¯†è½¬ç§»çš„æ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½çš„æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒGenRecalæ˜¾è‘—æå‡äº†åŸºçº¿æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æŸäº›ä»»åŠ¡ä¸Šæ€§èƒ½æå‡è¶…è¿‡20%ã€‚ä¸ç°æœ‰çš„å¤§è§„æ¨¡å¼€æºå’Œé—­æºVLMç›¸æ¯”ï¼ŒGenRecalåœ¨æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†å…¶åœ¨çŸ¥è¯†è’¸é¦é¢†åŸŸçš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€è¾¹ç¼˜è®¡ç®—è®¾å¤‡å’Œå…¶ä»–èµ„æºå—é™çš„ç¯å¢ƒä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆéƒ¨ç½²è§†è§‰è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡å°†å¤§å‹æ¨¡å‹çš„çŸ¥è¯†è½¬ç§»åˆ°å°å‹æ¨¡å‹ä¸­ï¼ŒGenRecalå¯ä»¥åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œé™ä½è®¡ç®—èµ„æºçš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in vision-language models (VLMs) have leveraged large language models (LLMs) to achieve performance on par with closed-source systems like GPT-4V. However, deploying these models in real-world scenarios, particularly on resource-constrained devices, remains challenging due to their substantial computational demands. This has spurred interest in distilling knowledge from large VLMs into smaller, more efficient counterparts. A key challenge arises here from the diversity of VLM architectures, which are built on different LLMs and employ varying token types-differing in vocabulary size, token splits, and token index ordering. To address this challenge of limitation to a specific VLM type, we present Generation after Recalibration (GenRecal), a general-purpose distillation framework for VLMs. GenRecal incorporates a Recalibrator that aligns and adapts feature representations between heterogeneous VLMs, enabling effective knowledge transfer across different types of VLMs. Through extensive experiments on multiple challenging benchmarks, we demonstrate that GenRecal significantly improves baseline performances, eventually outperforming large-scale open- and closed-source VLMs.

