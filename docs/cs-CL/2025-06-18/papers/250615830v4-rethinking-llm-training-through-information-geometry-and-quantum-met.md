---
layout: default
title: Rethinking LLM Training through Information Geometry and Quantum Metrics
---

# Rethinking LLM Training through Information Geometry and Quantum Metrics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15830" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15830v4</a>
  <a href="https://arxiv.org/pdf/2506.15830.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15830v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15830v4', 'Rethinking LLM Training through Information Geometry and Quantum Metrics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Riccardo Di Sipio

**åˆ†ç±»**: cs.CL, quant-ph

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-12-08)

**å¤‡æ³¨**: 9 pages, 1 figure(s)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡ä¿¡æ¯å‡ ä½•ä¸é‡å­åº¦é‡é‡æ–°æ€è€ƒå¤§è¯­è¨€æ¨¡å‹è®­ç»ƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿¡æ¯å‡ ä½•` `é‡å­åº¦é‡` `å¤§è¯­è¨€æ¨¡å‹` `è‡ªç„¶æ¢¯åº¦ä¸‹é™` `ä¼˜åŒ–ç®—æ³•` `æ³›åŒ–èƒ½åŠ›` `æ›²ç‡æ•ˆåº”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é«˜ç»´å‚æ•°ç©ºé—´ä¸­ä¼˜åŒ–æ—¶é¢ä¸´éæ¬§å‡ é‡Œå¾—ç»“æ„çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨ä¿¡æ¯å‡ ä½•ä¸­çš„è´¹èˆå°”ä¿¡æ¯åº¦é‡ï¼Œé€šè¿‡è‡ªç„¶æ¢¯åº¦ä¸‹é™å®ç°æ›´æœ‰æ•ˆçš„å­¦ä¹ ã€‚
3. é€šè¿‡å‡ ä½•è§†è§’ï¼Œè®ºæ–‡æ·±å…¥æ¢è®¨äº†å°–é”æå°å€¼å’Œæ³›åŒ–èƒ½åŠ›ç­‰ç°è±¡ï¼Œæä¾›äº†æ–°çš„ç†è§£æ¡†æ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œå‚æ•°ç©ºé—´å‘ˆç°é«˜ç»´ä¸”éæ¬§å‡ é‡Œå¾—çš„ç»“æ„ã€‚ä¿¡æ¯å‡ ä½•åˆ©ç”¨è´¹èˆå°”ä¿¡æ¯åº¦é‡æ¡†æ¶æ¥æè¿°è¿™ä¸€å¤æ‚æ™¯è§‚ï¼Œä»è€Œé€šè¿‡è‡ªç„¶æ¢¯åº¦ä¸‹é™å®ç°æ›´ä¸ºåŸåˆ™æ€§çš„å­¦ä¹ ã€‚å°½ç®¡è¿™ç§å‡ ä½•è§†è§’åœ¨å®é™…åº”ç”¨ä¸­å¸¸å¸¸ä¸å¤Ÿä¾¿åˆ©ï¼Œä½†å®ƒæœ‰åŠ©äºæ¾„æ¸…è¯¸å¦‚å°–é”æå°å€¼ã€æ³›åŒ–èƒ½åŠ›å’Œè§‚å¯Ÿåˆ°çš„ç¼©æ”¾è§„å¾‹ç­‰ç°è±¡ã€‚æˆ‘ä»¬è®¤ä¸ºåŸºäºæ›²ç‡çš„æ–¹æ³•èƒ½å¤ŸåŠ æ·±å¯¹LLMè®­ç»ƒçš„ç†è§£ã€‚æœ€åï¼Œæˆ‘ä»¬åŸºäºFubini-Studyåº¦é‡å’Œé‡å­è´¹èˆå°”ä¿¡æ¯æ¨æµ‹é‡å­ç±»æ¯”ï¼Œæš—ç¤ºåœ¨é‡å­å¢å¼ºç³»ç»Ÿä¸­å®ç°é«˜æ•ˆä¼˜åŒ–çš„å¯èƒ½æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨é«˜ç»´ä¸”éæ¬§å‡ é‡Œå¾—çš„å‚æ•°ç©ºé—´ä¸­ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å°–é”æå°å€¼å’Œæ³›åŒ–èƒ½åŠ›æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥ä¿¡æ¯å‡ ä½•çš„æ¡†æ¶ï¼Œåˆ©ç”¨è´¹èˆå°”ä¿¡æ¯åº¦é‡æ¥æŒ‡å¯¼è‡ªç„¶æ¢¯åº¦ä¸‹é™ï¼Œä»è€Œå®ç°æ›´ä¸ºæœ‰æ•ˆçš„å­¦ä¹ è¿‡ç¨‹ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å‚æ•°ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å‚æ•°ç©ºé—´çš„å‡ ä½•å»ºæ¨¡ï¼Œå…¶æ¬¡æ˜¯åŸºäºè´¹èˆå°”ä¿¡æ¯çš„è‡ªç„¶æ¢¯åº¦è®¡ç®—ï¼Œæœ€åæ˜¯ä¼˜åŒ–è¿‡ç¨‹çš„å®æ–½ä¸è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†ä¿¡æ¯å‡ ä½•ä¸é‡å­åº¦é‡ç»“åˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£LLMè®­ç»ƒä¸­çš„æ›²ç‡æ•ˆåº”ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æ¬§å‡ é‡Œå¾—æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®ºæ–‡å¼ºè°ƒäº†è´¹èˆå°”ä¿¡æ¯åº¦é‡çš„è®¡ç®—æ–¹å¼ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†åŸºäºæ›²ç‡çš„è°ƒæ•´æœºåˆ¶ï¼Œä»¥ä¼˜åŒ–å­¦ä¹ è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ä¿¡æ¯å‡ ä½•æ¡†æ¶çš„è‡ªç„¶æ¢¯åº¦ä¸‹é™æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†è®­ç»ƒæ•ˆç‡çº¦15%-20%ã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨æ³›åŒ–èƒ½åŠ›ä¸Šä¹Ÿè¡¨ç°å‡ºæ˜¾è‘—æ”¹å–„ï¼ŒéªŒè¯äº†ç†è®ºæ¨å¯¼çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿæå‡å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥ï¼Œç»“åˆé‡å­è®¡ç®—çš„ä¼˜åŒ–æ–¹æ³•å¯èƒ½ä¼šåœ¨æ›´å¤æ‚çš„æ¨¡å‹è®­ç»ƒä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Optimization in large language models (LLMs) unfolds over high-dimensional parameter spaces with non-Euclidean structure. Information geometry frames this landscape using the Fisher information metric, enabling more principled learning via natural gradient descent. Though often impractical, this geometric lens clarifies phenomena such as sharp minima, generalization, and observed scaling laws. We argue that curvature-based approaches deepen our understanding of LLM training. Finally, we speculate on quantum analogies based on the Fubini-Study metric and Quantum Fisher Information, hinting at efficient optimization in quantum-enhanced systems.

