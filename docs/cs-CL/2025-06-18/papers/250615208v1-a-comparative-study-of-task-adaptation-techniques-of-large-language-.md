---
layout: default
title: A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals
---

# A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15208" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15208v1</a>
  <a href="https://arxiv.org/pdf/2506.15208.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15208v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15208v1', 'A Comparative Study of Task Adaptation Techniques of Large Language Models for Identifying Sustainable Development Goals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrea Cadeddu, Alessandro Chessa, Vincenzo De Leo, Gianni Fenu, Enrico Motta, Francesco Osborne, Diego Reforgiato Recupero, Angelo Salatino, Luca Secchi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: Submitted to IEEE Access

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒå¤§å‹è¯­è¨€æ¨¡å‹ä»»åŠ¡é€‚åº”æŠ€æœ¯ä»¥è¯†åˆ«å¯æŒç»­å‘å±•ç›®æ ‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯æŒç»­å‘å±•ç›®æ ‡` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬åˆ†ç±»` `ä»»åŠ¡é€‚åº”æŠ€æœ¯` `é›¶æ ·æœ¬å­¦ä¹ ` `å°‘æ ·æœ¬å­¦ä¹ ` `å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è·Ÿè¸ªå¯æŒç»­å‘å±•ç›®æ ‡çš„è¿›å±•æ—¶é¢ä¸´æ•°æ®è§„æ¨¡å’Œå¤æ‚æ€§å¸¦æ¥çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºäº†å¯¹å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ¯”è¾ƒåˆ†æï¼Œå¹¶è¯„ä¼°ä¸åŒä»»åŠ¡é€‚åº”æŠ€æœ¯çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡ä¼˜åŒ–çš„å°å‹æ¨¡å‹åœ¨æ€§èƒ½ä¸Šå¯ä¸å¤§å‹æ¨¡å‹ç›¸åª²ç¾ï¼Œå…·æœ‰æ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

2012å¹´ï¼Œè”åˆå›½æå‡ºäº†17ä¸ªå¯æŒç»­å‘å±•ç›®æ ‡ï¼ˆSDGsï¼‰ï¼Œæ—¨åœ¨åˆ°2030å¹´å®ç°æ›´å¯æŒç»­å’Œæ”¹å–„çš„æœªæ¥ã€‚ç„¶è€Œï¼Œç”±äºæ¶‰åŠæ•°æ®çš„å¹¿æ³›è§„æ¨¡å’Œå¤æ‚æ€§ï¼Œè·Ÿè¸ªè¿™äº›ç›®æ ‡çš„è¿›å±•å˜å¾—å›°éš¾ã€‚æ–‡æœ¬åˆ†ç±»æ¨¡å‹åœ¨è¿™ä¸€é¢†åŸŸå˜å¾—è‡³å…³é‡è¦ï¼Œè‡ªåŠ¨åŒ–åˆ†ææ¥è‡ªå¤šç§æ¥æºçš„å¤§é‡æ–‡æœ¬ã€‚æ­¤å¤–ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®¸å¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¯æ˜äº†å…¶ä¸å¯æˆ–ç¼ºçš„ä½œç”¨ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€‚æœ¬æ–‡åˆ†æäº†å¤šç§ä¸“æœ‰å’Œå¼€æºLLMsåœ¨é’ˆå¯¹SDGsçš„å•æ ‡ç­¾å¤šç±»æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶è¯„ä¼°äº†ä»»åŠ¡é€‚åº”æŠ€æœ¯ï¼ˆå³ä¸Šä¸‹æ–‡å­¦ä¹ æ–¹æ³•ï¼‰ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬å­¦ä¹ å’Œå°‘æ ·æœ¬å­¦ä¹ ï¼Œä»¥åŠå¾®è°ƒçš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼Œé€šè¿‡æç¤ºå·¥ç¨‹ä¼˜åŒ–çš„å°å‹æ¨¡å‹èƒ½å¤Ÿä¸OpenAIçš„GPTç­‰å¤§å‹æ¨¡å‹ç›¸åª²ç¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆè¯†åˆ«å’Œåˆ†ç±»ä¸å¯æŒç»­å‘å±•ç›®æ ‡ç›¸å…³çš„æ–‡æœ¬æ•°æ®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡å’Œå¤æ‚æ•°æ®æ—¶æ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥å®ç°å‡†ç¡®çš„åˆ†ç±»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒä¸åŒçš„ä»»åŠ¡é€‚åº”æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯é›¶æ ·æœ¬å­¦ä¹ ã€å°‘æ ·æœ¬å­¦ä¹ å’Œå¾®è°ƒï¼Œæ¢ç´¢å¦‚ä½•æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨åˆ©ç”¨ç°æœ‰æ¨¡å‹çš„æ½œåŠ›ï¼ŒåŒæ—¶é™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆé€‰æ‹©å¤šç§ä¸“æœ‰å’Œå¼€æºçš„LLMsï¼Œç„¶åå¯¹å…¶è¿›è¡Œå•æ ‡ç­¾å¤šç±»æ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„è¯„ä¼°ã€‚æ¥ç€ï¼Œåº”ç”¨ä¸åŒçš„ä»»åŠ¡é€‚åº”æŠ€æœ¯è¿›è¡Œä¼˜åŒ–ï¼Œæœ€åé€šè¿‡å®éªŒæ¯”è¾ƒå„æ¨¡å‹çš„åˆ†ç±»æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå‘ç°å°å‹æ¨¡å‹åœ¨ç»è¿‡æç¤ºå·¥ç¨‹ä¼˜åŒ–åï¼Œèƒ½å¤Ÿåœ¨æ€§èƒ½ä¸Šä¸å¤§å‹æ¨¡å‹ç›¸åª²ç¾ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚å¿µï¼Œè¡¨æ˜å°å‹æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­åŒæ ·å…·æœ‰ç«äº‰åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„æç¤ºç­–ç•¥å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„è¾“å…¥æ ¼å¼å’Œå­¦ä¹ è¿‡ç¨‹ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©å’Œæ¨¡å‹æ¶æ„çš„è°ƒæ•´ä¹Ÿæ˜¯å…³é”®è®¾è®¡è¦ç´ ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å¤æ‚çš„è¯­è¨€æ¨¡å¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡ä¼˜åŒ–çš„å°å‹æ¨¡å‹åœ¨SDGsæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®ç‡ä¸OpenAIçš„GPTç­‰å¤§å‹æ¨¡å‹ç›¸å½“ï¼Œç”šè‡³åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°æ›´ä¼˜ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹ï¼Œå°å‹æ¨¡å‹çš„æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå…·æœ‰æ›´é«˜çš„å®ç”¨æ€§å’Œç»æµæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ”¿ç­–åˆ†æã€ç¤¾ä¼šç§‘å­¦ç ”ç©¶å’Œç¯å¢ƒç›‘æµ‹ç­‰ã€‚é€šè¿‡è‡ªåŠ¨åŒ–æ–‡æœ¬åˆ†ç±»ï¼Œç›¸å…³æœºæ„å¯ä»¥æ›´é«˜æ•ˆåœ°è·Ÿè¸ªå’Œè¯„ä¼°å¯æŒç»­å‘å±•ç›®æ ‡çš„è¿›å±•ï¼Œä»è€Œä¸ºå†³ç­–æä¾›æ•°æ®æ”¯æŒï¼Œæ¨åŠ¨å¯æŒç»­å‘å±•å®è·µçš„å®æ–½ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸçš„æ–‡æœ¬åˆ†æä»»åŠ¡ä¸­ï¼Œæå‡æ•°æ®å¤„ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In 2012, the United Nations introduced 17 Sustainable Development Goals (SDGs) aimed at creating a more sustainable and improved future by 2030. However, tracking progress toward these goals is difficult because of the extensive scale and complexity of the data involved. Text classification models have become vital tools in this area, automating the analysis of vast amounts of text from a variety of sources. Additionally, large language models (LLMs) have recently proven indispensable for many natural language processing tasks, including text classification, thanks to their ability to recognize complex linguistic patterns and semantics. This study analyzes various proprietary and open-source LLMs for a single-label, multi-class text classification task focused on the SDGs. Then, it also evaluates the effectiveness of task adaptation techniques (i.e., in-context learning approaches), namely Zero-Shot and Few-Shot Learning, as well as Fine-Tuning within this domain. The results reveal that smaller models, when optimized through prompt engineering, can perform on par with larger models like OpenAI's GPT (Generative Pre-trained Transformer).

