---
layout: default
title: COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation
---

# COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15372" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15372v1</a>
  <a href="https://arxiv.org/pdf/2506.15372.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15372v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15372v1', 'COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raghvendra Kumar, S. A. Mohammed Salman, Aryan Sahu, Tridib Nandi, Pragathi Y. P., Sriparna Saha, Jose G. Moreno

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: ACL 2025 MAINs

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCOSMMICä»¥è§£å†³å°åº¦è¯­è¨€å¤šæ¨¡æ€æ‘˜è¦ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ‘˜è¦` `å¤šè¯­è¨€å¤„ç†` `ç”¨æˆ·è¯„è®ºæ•´åˆ` `è‡ªç„¶è¯­è¨€ç”Ÿæˆ` `å°åº¦è¯­è¨€æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å’Œå¤šè¯­è¨€æ‘˜è¦ç ”ç©¶åœ¨å°åº¦è¯­è¨€æ–¹é¢è¿›å±•æœ‰é™ï¼Œç¼ºä¹æœ‰æ•ˆçš„ç”¨æˆ·è¯„è®ºæ•´åˆã€‚
2. COSMMICæ•°æ®é›†é€šè¿‡æ•´åˆæ–‡æœ¬ã€å›¾åƒå’Œç”¨æˆ·è¯„è®ºï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€å¤šè¯­è¨€æ‘˜è¦ç”Ÿæˆè§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆç”¨æˆ·è¯„è®ºå’Œå›¾åƒçš„é…ç½®åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œæ˜¾è‘—æå‡äº†æ‘˜è¦è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡åœ¨è‹±è¯­å’Œä¸­æ–‡çš„è¯„è®ºæ„ŸçŸ¥å¤šæ¨¡æ€å’Œå¤šè¯­è¨€æ‘˜è¦æ–¹é¢å–å¾—äº†è¿›å±•ï¼Œä½†å°åº¦è¯­è¨€çš„ç ”ç©¶ä»ç„¶æœ‰é™ã€‚æœ¬ç ”ç©¶é€šè¿‡å¼•å…¥COSMMICï¼Œä¸€ä¸ªå¼€åˆ›æ€§çš„è¯„è®ºæ•æ„Ÿå¤šæ¨¡æ€å¤šè¯­è¨€æ•°æ®é›†ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚COSMMICåŒ…å«9ç§ä¸»è¦å°åº¦è¯­è¨€çš„4,959ä¸ªæ–‡ç« -å›¾åƒå¯¹å’Œ24,484æ¡è¯»è€…è¯„è®ºï¼Œæ‰€æœ‰è¯­è¨€å‡æä¾›çœŸå®æ‘˜è¦ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡æ•´åˆè¯»è€…è§è§£å’Œåé¦ˆæ¥å¢å¼ºæ‘˜è¦ã€‚æˆ‘ä»¬æ¢ç´¢äº†å››ç§é…ç½®çš„æ‘˜è¦å’Œæ ‡é¢˜ç”Ÿæˆï¼Œè¯„ä¼°æ•°æ®é›†çš„æœ‰æ•ˆæ€§ï¼Œé‡‡ç”¨äº†æœ€å…ˆè¿›çš„è¯­è¨€æ¨¡å‹ï¼Œå¦‚LLama3å’ŒGPT-4ã€‚ä¸è®¸å¤šç°æœ‰æ•°æ®é›†ä¸åŒï¼ŒCOSMMICç‹¬ç‰¹åœ°æ•´åˆäº†æ–‡æœ¬ã€å›¾åƒå’Œç”¨æˆ·åé¦ˆï¼Œæ¨åŠ¨äº†è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶çš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å°åº¦è¯­è¨€å¤šæ¨¡æ€æ‘˜è¦ç”Ÿæˆä¸­çš„æ•°æ®ä¸è¶³å’Œç”¨æˆ·åé¦ˆæ•´åˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¸ºæ–‡æœ¬å•ä¸€æˆ–ç¼ºä¹ç”¨æˆ·è¯„è®ºï¼Œæ— æ³•å……åˆ†åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCOSMMICæ•°æ®é›†é€šè¿‡æ•´åˆæ–‡ç« æ–‡æœ¬ã€ç”¨æˆ·è¯„è®ºå’Œå›¾åƒï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„å¤šæ¨¡æ€æ•°æ®æºï¼Œæ—¨åœ¨æå‡æ‘˜è¦ç”Ÿæˆçš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ç”¨æˆ·è¯„è®ºåˆ†ç±»ã€å›¾åƒä¿¡æ¯æå–å’Œæ‘˜è¦ç”Ÿæˆå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†æ–‡ç« ã€å›¾åƒå’Œè¯„è®ºï¼Œç„¶åé€šè¿‡åˆ†ç±»å™¨ç­›é€‰æœ‰ç”¨è¯„è®ºï¼Œæœ€åç”Ÿæˆæ‘˜è¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šCOSMMICçš„åˆ›æ–°åœ¨äºå…¶ç‹¬ç‰¹çš„å¤šæ¨¡æ€æ•´åˆæ–¹å¼ï¼Œç»“åˆäº†æ–‡æœ¬ã€å›¾åƒå’Œç”¨æˆ·åé¦ˆï¼Œçªç ´äº†ä¼ ç»Ÿæ•°æ®é›†çš„å±€é™æ€§ï¼Œæå‡äº†å¤šè¯­è¨€å¤„ç†çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨IndicBERTè¿›è¡Œè¯„è®ºåˆ†ç±»ï¼Œä½¿ç”¨å¤šè¯­è¨€CLIPæ¨¡å‹æå–å›¾åƒä¿¡æ¯ï¼Œç¡®ä¿äº†æ•°æ®å¤„ç†çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆç”¨æˆ·è¯„è®ºå’Œå›¾åƒçš„æ‘˜è¦ç”Ÿæˆé…ç½®åœ¨å¤šç§è¯­è¨€æ¨¡å‹ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨LLama3å’ŒGPT-4æ—¶ï¼Œæ‘˜è¦è´¨é‡æ˜¾è‘—æå‡ï¼Œè¾ƒåŸºçº¿æé«˜äº†çº¦15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»æ‘˜è¦ç”Ÿæˆã€ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æå’Œå¤šè¯­è¨€ä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æä¾›ä¸°å¯Œçš„å¤šæ¨¡æ€æ•°æ®ï¼ŒCOSMMICèƒ½å¤Ÿä¿ƒè¿›å°åº¦è¯­è¨€çš„è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite progress in comment-aware multimodal and multilingual summarization for English and Chinese, research in Indian languages remains limited. This study addresses this gap by introducing COSMMIC, a pioneering comment-sensitive multimodal, multilingual dataset featuring nine major Indian languages. COSMMIC comprises 4,959 article-image pairs and 24,484 reader comments, with ground-truth summaries available in all included languages. Our approach enhances summaries by integrating reader insights and feedback. We explore summarization and headline generation across four configurations: (1) using article text alone, (2) incorporating user comments, (3) utilizing images, and (4) combining text, comments, and images. To assess the dataset's effectiveness, we employ state-of-the-art language models such as LLama3 and GPT-4. We conduct a comprehensive study to evaluate different component combinations, including identifying supportive comments, filtering out noise using a dedicated comment classifier using IndicBERT, and extracting valuable insights from images with a multilingual CLIP-based classifier. This helps determine the most effective configurations for natural language generation (NLG) tasks. Unlike many existing datasets that are either text-only or lack user comments in multimodal settings, COSMMIC uniquely integrates text, images, and user feedback. This holistic approach bridges gaps in Indian language resources, advancing NLP research and fostering inclusivity.

