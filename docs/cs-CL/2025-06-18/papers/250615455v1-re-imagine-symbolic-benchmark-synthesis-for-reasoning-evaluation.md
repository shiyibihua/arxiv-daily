---
layout: default
title: RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation
---

# RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15455" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15455v1</a>
  <a href="https://arxiv.org/pdf/2506.15455.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15455v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15455v1', 'RE-IMAGINE: Symbolic Benchmark Synthesis for Reasoning Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinnuo Xu, Rachel Lawrence, Kshitij Dubey, Atharva Pandey, Risa Ueno, Fabian Falck, Aditya V. Nori, Rahul Sharma, Amit Sharma, Javier Gonzalez

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRE-IMAGINEæ¡†æ¶ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `å› æœæ¨ç†` `é—®é¢˜ç”Ÿæˆ` `æ€§èƒ½è¯„ä¼°` `ç»Ÿè®¡å›å¿†` `æœºå™¨å­¦ä¹ ` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­çš„é«˜å‡†ç¡®ç‡å¯èƒ½æºäºç»Ÿè®¡å›å¿†ï¼Œè€ŒéçœŸå®æ¨ç†èƒ½åŠ›ã€‚
2. RE-IMAGINEæ¡†æ¶é€šè¿‡ç”Ÿæˆä¸åŒå±‚æ¬¡çš„é—®é¢˜å˜ä½“ï¼Œè¯„ä¼°LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå…‹æœäº†è®°å¿†ä¾èµ–çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨é¢å¯¹é—®é¢˜å˜ä½“æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ­ç¤ºäº†å…¶å¯¹ç»Ÿè®¡å›å¿†çš„ä¾èµ–ç¨‹åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºé«˜å‡†ç¡®ç‡ã€‚ç„¶è€Œï¼Œå°šä¸æ¸…æ¥šè¿™äº›ç»“æœæ˜¯å¦æºäºçœŸå®çš„æ¨ç†èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯å¯¹è®­ç»ƒé›†çš„ç»Ÿè®¡å›å¿†ã€‚å—å› æœå±‚æ¬¡ç†è®ºçš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†RE-IMAGINEæ¡†æ¶ï¼Œæ—¨åœ¨å¯¹LLMsçš„æ¨ç†èƒ½åŠ›è¿›è¡Œåˆ†å±‚è¡¨å¾ï¼Œå¹¶è‡ªåŠ¨ç”Ÿæˆä¸åŒå±‚æ¬¡é—®é¢˜å˜ä½“ã€‚é€šè¿‡æ”¹å˜ä¸­é—´ç¬¦å·è¡¨ç¤ºï¼ŒRE-IMAGINEèƒ½å¤Ÿç”Ÿæˆå¤§é‡æ— æ³•ä»…é€šè¿‡è®°å¿†è§£å†³çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å…·æœ‰é€šç”¨æ€§ï¼Œé€‚ç”¨äºæ•°å­¦ã€ä»£ç å’Œé€»è¾‘ç­‰å¤šä¸ªæ¨ç†é¢†åŸŸã€‚æˆ‘ä»¬åœ¨å››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†ä¸Šå±•ç¤ºäº†è¯¥æ¡†æ¶ï¼Œå¹¶è§‚å¯Ÿåˆ°åœ¨æ¨¡å‹æŸ¥è¯¢é—®é¢˜å˜ä½“æ—¶æ€§èƒ½ä¸‹é™ï¼Œè¡¨æ˜æ¨¡å‹åœ¨è¿‡å»è¡¨ç°ä¸­å¯¹ç»Ÿè®¡å›å¿†çš„ä¾èµ–ç¨‹åº¦ï¼Œè¿›è€Œä¸ºæœªæ¥é’ˆå¯¹æ¨ç†å±‚æ¬¡çš„æŠ€èƒ½ç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°é«˜å‡†ç¡®ç‡çš„çœŸå®æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†çœŸå®æ¨ç†ä¸ç»Ÿè®¡å›å¿†çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRE-IMAGINEæ¡†æ¶é€šè¿‡å¼•å…¥å› æœå±‚æ¬¡ç†è®ºï¼Œç”Ÿæˆä¸åŒå±‚æ¬¡çš„æ¨ç†é—®é¢˜å˜ä½“ï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œé¿å…ä»…ä¾èµ–è®°å¿†çš„è§£å†³æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬é—®é¢˜ç”Ÿæˆæ¨¡å—ã€æ¨ç†èƒ½åŠ›è¯„ä¼°æ¨¡å—å’Œç»“æœåˆ†ææ¨¡å—ã€‚é—®é¢˜ç”Ÿæˆæ¨¡å—é€šè¿‡ä¸­é—´ç¬¦å·è¡¨ç¤ºæ”¹å˜é—®é¢˜ï¼Œè¯„ä¼°æ¨¡å—åˆ™å¯¹æ¨¡å‹çš„æ¨ç†èƒ½åŠ›è¿›è¡Œé‡åŒ–åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šRE-IMAGINEçš„åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿç”Ÿæˆå¤§é‡æ— æ³•é€šè¿‡è®°å¿†è§£å†³çš„é—®é¢˜å˜ä½“ï¼Œå¹¶ä¸”é€‚ç”¨äºå¤šç§æ¨ç†é¢†åŸŸï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æ¶ä¸­çš„é—®é¢˜ç”Ÿæˆé‡‡ç”¨ç¬¦å·è¡¨ç¤ºï¼Œç¡®ä¿ç”Ÿæˆçš„é—®é¢˜å…·æœ‰å¤šæ ·æ€§å’Œå¤æ‚æ€§ï¼Œè¯„ä¼°æ¨¡å—åˆ™ä½¿ç”¨æ ‡å‡†åŒ–çš„æ€§èƒ½æŒ‡æ ‡æ¥é‡åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“æ¨¡å‹é¢å¯¹RE-IMAGINEç”Ÿæˆçš„é—®é¢˜å˜ä½“æ—¶ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œéƒ¨åˆ†æ¨¡å‹çš„å‡†ç¡®ç‡é™ä½äº†20%ä»¥ä¸Šã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­å¯¹ç»Ÿè®¡å›å¿†çš„ä¾èµ–ï¼Œæç¤ºäº†æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RE-IMAGINEæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿç”¨äºè¯„ä¼°å’Œæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦ã€ç¼–ç¨‹å’Œé€»è¾‘æ¨ç†ç­‰é¢†åŸŸçš„èƒ½åŠ›ã€‚å…¶è®¾è®¡å¯ä»¥ä¸ºæ•™è‚²ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ¨ç†å·¥å…·ç­‰é¢†åŸŸæä¾›æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent Large Language Models (LLMs) have reported high accuracy on reasoning benchmarks. However, it is still unclear whether the observed results arise from true reasoning or from statistical recall of the training set. Inspired by the ladder of causation (Pearl, 2009) and its three levels (associations, interventions and counterfactuals), this paper introduces RE-IMAGINE, a framework to characterize a hierarchy of reasoning ability in LLMs, alongside an automated pipeline to generate problem variations at different levels of the hierarchy. By altering problems in an intermediate symbolic representation, RE-IMAGINE generates arbitrarily many problems that are not solvable using memorization alone. Moreover, the framework is general and can work across reasoning domains, including math, code, and logic. We demonstrate our framework on four widely-used benchmarks to evaluate several families of LLMs, and observe reductions in performance when the models are queried with problem variations. These assessments indicate a degree of reliance on statistical recall for past performance, and open the door to further research targeting skills across the reasoning hierarchy.

