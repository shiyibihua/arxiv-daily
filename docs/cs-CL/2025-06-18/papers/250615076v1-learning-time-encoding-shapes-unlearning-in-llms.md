---
layout: default
title: Learning-Time Encoding Shapes Unlearning in LLMs
---

# Learning-Time Encoding Shapes Unlearning in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15076" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15076v1</a>
  <a href="https://arxiv.org/pdf/2506.15076.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15076v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15076v1', 'Learning-Time Encoding Shapes Unlearning in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruihan Wu, Konstantin Garov, Kamalika Chaudhuri

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå­¦ä¹ æ—¶é—´ç¼–ç ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å»å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å»å­¦ä¹ ` `çŸ¥è¯†ç¼–ç ` `éšç§ä¿æŠ¤` `å†…å®¹å®¡æŸ¥` `æ¨¡å‹æ›´æ–°` `å®è¯ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾è®­ç»ƒè¿‡ç¨‹å’Œæ¨¡å‹å›ºå®šï¼Œç¼ºä¹å¯¹å­¦ä¹ æ—¶é—´é€‰æ‹©å¯¹å»å­¦ä¹ å½±å“çš„æ·±å…¥ç ”ç©¶ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å®è¯ç ”ç©¶ï¼Œæ¢è®¨å­¦ä¹ æ—¶é—´çŸ¥è¯†ç¼–ç çš„é€‰æ‹©å¦‚ä½•å½±å“å»å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼Œæå‡ºä½¿ç”¨æ”¹å†™æè¿°ä»¥æé«˜å»å­¦ä¹ æ€§èƒ½ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæ”¹å†™æè¿°èƒ½æ˜¾è‘—æå‡å»å­¦ä¹ æ•ˆæœï¼Œä½†ä»æ–‡æœ¬ä¸­å»å­¦ä¹ å•ä¸ªçŸ¥è¯†ç‚¹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç°å®ä¸–ç•Œä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œå»å­¦ä¹ çš„èƒ½åŠ›ï¼Œå³åœ¨äº‹åç§»é™¤ç‰¹å®šçŸ¥è¯†å˜å¾—è‡³å…³é‡è¦ï¼ŒåŸå› åŒ…æ‹¬éšç§æ³•è§„å’Œçº æ­£è¿‡æ—¶æˆ–æœ‰å®³å†…å®¹ã€‚ä»¥å¾€çš„ç ”ç©¶æå‡ºäº†å»å­¦ä¹ çš„åŸºå‡†å’Œç®—æ³•ï¼Œé€šå¸¸å‡è®¾è®­ç»ƒè¿‡ç¨‹å’Œç›®æ ‡æ¨¡å‹æ˜¯å›ºå®šçš„ã€‚æœ¬æ–‡é€šè¿‡å®è¯ç ”ç©¶å­¦ä¹ æ—¶é—´çŸ¥è¯†ç¼–ç çš„é€‰æ‹©å¦‚ä½•å½±å“å»å­¦ä¹ çš„æœ‰æ•ˆæ€§ï¼Œå‘ç°å­¦ä¹ æ—¶ä½¿ç”¨æ”¹å†™æè¿°å¯ä»¥æé«˜å»å­¦ä¹ æ€§èƒ½ï¼Œè€Œä»ä¸€æ®µæ–‡æœ¬ä¸­å»å­¦ä¹ å•ä¸ªçŸ¥è¯†ç‚¹åˆ™é¢ä¸´æŒ‘æˆ˜ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå­¦ä¹ æ—¶é—´çš„çŸ¥è¯†ç¼–ç åœ¨å®ç°å¯é çš„äº‹åå»å­¦ä¹ ä¸­å¯èƒ½å‘æŒ¥æ ¸å¿ƒä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸­å»å­¦ä¹ çš„æœ‰æ•ˆæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸æœªè€ƒè™‘å­¦ä¹ æ—¶é—´çš„çŸ¥è¯†ç¼–ç é€‰æ‹©å¯¹å»å­¦ä¹ çš„å½±å“ï¼Œå¯¼è‡´å»å­¦ä¹ æ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å®è¯ç ”ç©¶æ¢ç´¢å­¦ä¹ æ—¶é—´çŸ¥è¯†ç¼–ç çš„é€‰æ‹©ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨æ”¹å†™æè¿°æ¥æé«˜å»å­¦ä¹ æ€§èƒ½ï¼Œè®¤ä¸ºå­¦ä¹ æ—¶é—´çš„çŸ¥è¯†ç¼–ç åœ¨å»å­¦ä¹ ä¸­èµ·ç€æ ¸å¿ƒä½œç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆè®¾è®¡äº†ä¸€ç³»åˆ—å®éªŒï¼Œæ¯”è¾ƒä¸åŒçŸ¥è¯†ç¼–ç æ–¹å¼å¯¹å»å­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€å»å­¦ä¹ ç®—æ³•åº”ç”¨åŠæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†å­¦ä¹ æ—¶é—´çŸ¥è¯†ç¼–ç å¯¹å»å­¦ä¹ çš„å½±å“ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨æ”¹å†™æè¿°çš„æœ‰æ•ˆæ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ–°çš„è§†è§’å’Œè§£å†³æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ”¹å†™ç­–ç•¥ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥é‡åŒ–å»å­¦ä¹ çš„æ•ˆæœï¼Œç¡®ä¿å®éªŒç»“æœçš„å¯é æ€§å’Œå¯é‡å¤æ€§ã€‚é€šè¿‡å¯¹æ¯”å®éªŒï¼ŒéªŒè¯äº†ä¸åŒç¼–ç æ–¹å¼çš„ä¼˜åŠ£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨æ”¹å†™æè¿°çš„å»å­¦ä¹ æ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œä»æ–‡æœ¬ä¸­å»å­¦ä¹ å•ä¸ªçŸ¥è¯†ç‚¹çš„æŒ‘æˆ˜æ€§ä¹Ÿå¾—åˆ°äº†éªŒè¯ï¼Œæç¤ºæœªæ¥ç ”ç©¶éœ€å…³æ³¨è¿™ä¸€é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éšç§ä¿æŠ¤ã€å†…å®¹å®¡æŸ¥å’Œæ¨¡å‹æ›´æ–°ç­‰åœºæ™¯ã€‚é€šè¿‡æœ‰æ•ˆçš„å»å­¦ä¹ æœºåˆ¶ï¼Œèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šå’Œç»„ç»‡éµå¾ªéšç§æ³•è§„ï¼ŒåŠæ—¶çº æ­£æ¨¡å‹ä¸­çš„é”™è¯¯ä¿¡æ¯ï¼Œä»è€Œæå‡ç”¨æˆ·ä¿¡ä»»å’Œæ¨¡å‹çš„ç¤¾ä¼šè´£ä»»æ„Ÿã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„æ¨¡å‹æ›´æ–°æœºåˆ¶çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly deployed in the real world, the ability to ``unlearn'', or remove specific pieces of knowledge post hoc, has become essential for a variety of reasons ranging from privacy regulations to correcting outdated or harmful content. Prior work has proposed unlearning benchmarks and algorithms, and has typically assumed that the training process and the target model are fixed. In this work, we empirically investigate how learning-time choices in knowledge encoding impact the effectiveness of unlearning factual knowledge. Our experiments reveal two key findings: (1) learning with paraphrased descriptions improves unlearning performance and (2) unlearning individual piece of knowledge from a chunk of text is challenging. Our results suggest that learning-time knowledge encoding may play a central role in enabling reliable post-hoc unlearning.

