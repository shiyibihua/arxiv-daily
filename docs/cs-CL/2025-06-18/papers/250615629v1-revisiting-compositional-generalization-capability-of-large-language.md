---
layout: default
title: Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability
---

# Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15629" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15629v1</a>
  <a href="https://arxiv.org/pdf/2506.15629.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15629v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15629v1', 'Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: ACL 2025 Main

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOrdered CommonGenåŸºå‡†ä»¥è¯„ä¼°LLMsçš„ç»„åˆæ³›åŒ–ä¸æŒ‡ä»¤éµå¾ªèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç»„åˆæ³›åŒ–` `æŒ‡ä»¤éµå¾ª` `ç”Ÿæˆå¸¸è¯†æ¨ç†` `è‡ªç„¶è¯­è¨€å¤„ç†` `è¯„ä¼°åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æŒ‡ä»¤æ—¶ï¼Œå¾€å¾€å¯¹æ¦‚å¿µé¡ºåºçš„éµå¾ªèƒ½åŠ›ä¸è¶³ï¼Œå¯¼è‡´è¾“å‡ºç»“æœçš„å¤šæ ·æ€§é™ä½ã€‚
2. æœ¬æ–‡æå‡ºOrdered CommonGenåŸºå‡†ï¼Œé€šè¿‡æµ‹é‡æœ‰åºè¦†ç›–ç‡æ¥åŒæ—¶è¯„ä¼°LLMsçš„ç»„åˆæ³›åŒ–å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡LLMsç†è§£æŒ‡ä»¤æ„å›¾ï¼Œä½†åœ¨æ¦‚å¿µé¡ºåºçš„éµå¾ªä¸Šä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œæœ€å¥½çš„æ¨¡å‹æœ‰åºè¦†ç›–ç‡ä»…ä¸º75%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç”Ÿæˆå¸¸è¯†æ¨ç†ä»»åŠ¡ä¸­ï¼Œç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éœ€è¦ç”ŸæˆåŒ…å«æ‰€æœ‰ç»™å®šæ¦‚å¿µçš„å¥å­ã€‚ç„¶è€Œï¼Œå½“æç¤ºæŒ‡å®šæ¦‚å¿µé¡ºåºæ—¶ï¼ŒLLMså¿…é¡»ç”Ÿæˆç¬¦åˆè¯¥é¡ºåºçš„å¥å­ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Ordered CommonGenåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°LLMsçš„ç»„åˆæ³›åŒ–å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚è¯¥åŸºå‡†é€šè¿‡æµ‹é‡æœ‰åºè¦†ç›–ç‡æ¥è¯„ä¼°æ¦‚å¿µæ˜¯å¦æŒ‰æŒ‡å®šé¡ºåºç”Ÿæˆï¼Œä»è€Œå®ç°å¯¹ä¸¤ç§èƒ½åŠ›çš„åŒæ—¶è¯„ä¼°ã€‚é€šè¿‡å¯¹36ä¸ªLLMsçš„ç»¼åˆåˆ†æï¼Œå‘ç°å°½ç®¡LLMsé€šå¸¸ç†è§£æŒ‡ä»¤æ„å›¾ï¼Œä½†å¯¹ç‰¹å®šæ¦‚å¿µé¡ºåºæ¨¡å¼çš„åè§å¸¸å¯¼è‡´è¾“å‡ºä½å¤šæ ·æ€§æˆ–ç›¸åŒç»“æœã€‚å³ä½¿æ˜¯æœ€ç¬¦åˆæŒ‡ä»¤çš„LLMï¼Œå…¶æœ‰åºè¦†ç›–ç‡ä¹Ÿä»…çº¦ä¸º75%ï¼Œçªæ˜¾äº†æŒ‡ä»¤éµå¾ªå’Œç»„åˆæ³›åŒ–èƒ½åŠ›çš„æå‡éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆå¼å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŒ‡ä»¤éµå¾ªèƒ½åŠ›æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ¦‚å¿µé¡ºåºçš„ç”Ÿæˆä¸Šã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æŒ‡ä»¤æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆç”Ÿæˆç¬¦åˆæŒ‡å®šé¡ºåºçš„å¥å­ï¼Œå¯¼è‡´è¾“å‡ºç»“æœçš„å¤šæ ·æ€§å’Œå‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºOrdered CommonGenåŸºå‡†ï¼Œè®¾è®¡äº†ä¸€ä¸ªæ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡æµ‹é‡æœ‰åºè¦†ç›–ç‡æ¥åŒæ—¶è€ƒå¯Ÿæ¨¡å‹çš„ç»„åˆæ³›åŒ–èƒ½åŠ›å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ç”Ÿæˆå¥å­æ—¶ä¸ä»…è¦è€ƒè™‘æ¦‚å¿µçš„å®Œæ•´æ€§ï¼Œè¿˜è¦éµå¾ªç‰¹å®šçš„é¡ºåºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«ä¸åŒæ¦‚å¿µé¡ºåºçš„ç”Ÿæˆä»»åŠ¡æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œè®­ç»ƒå¤šç§LLMsä»¥ç”Ÿæˆç¬¦åˆè¿™äº›ä»»åŠ¡çš„å¥å­ï¼›æœ€åï¼Œé€šè¿‡æœ‰åºè¦†ç›–ç‡æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†Ordered CommonGenåŸºå‡†ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°ç»„åˆæ³›åŒ–å’ŒæŒ‡ä»¤éµå¾ªèƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„å•ä¸€è¯„ä¼°æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†æ›´å…¨é¢çš„æ€§èƒ½åˆ†æã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§LLMsè¿›è¡Œå¯¹æ¯”ï¼Œè®¾ç½®äº†ä¸åŒçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå¹¶è°ƒæ•´äº†æ¨¡å‹çš„è¶…å‚æ•°ä»¥æé«˜æœ‰åºè¦†ç›–ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡LLMsèƒ½å¤Ÿç†è§£æŒ‡ä»¤æ„å›¾ï¼Œä½†åœ¨æ¦‚å¿µé¡ºåºéµå¾ªä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œæœ€å¥½çš„æ¨¡å‹æœ‰åºè¦†ç›–ç‡ä»…ä¸º75%ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨ç”Ÿæˆä»»åŠ¡ä¸­æå‡æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¯¹è¯ç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹å’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡LLMsçš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œç»„åˆæ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æ”¹å–„äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥åŸºå‡†å¯èƒ½æˆä¸ºè¯„ä¼°è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„é‡è¦æ ‡å‡†ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In generative commonsense reasoning tasks such as CommonGen, generative large language models (LLMs) compose sentences that include all given concepts. However, when focusing on instruction-following capabilities, if a prompt specifies a concept order, LLMs must generate sentences that adhere to the specified order. To address this, we propose Ordered CommonGen, a benchmark designed to evaluate the compositional generalization and instruction-following abilities of LLMs. This benchmark measures ordered coverage to assess whether concepts are generated in the specified order, enabling a simultaneous evaluation of both abilities. We conducted a comprehensive analysis using 36 LLMs and found that, while LLMs generally understand the intent of instructions, biases toward specific concept order patterns often lead to low-diversity outputs or identical results even when the concept order is altered. Moreover, even the most instruction-compliant LLM achieved only about 75% ordered coverage, highlighting the need for improvements in both instruction-following and compositional generalization capabilities.

