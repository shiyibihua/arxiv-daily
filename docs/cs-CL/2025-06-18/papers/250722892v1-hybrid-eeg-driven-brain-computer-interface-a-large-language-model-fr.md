---
layout: default
title: Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation
---

# Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.22892" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.22892v1</a>
  <a href="https://arxiv.org/pdf/2507.22892.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.22892v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.22892v1', 'Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ismail Hossain, Mridul Banik

**åˆ†ç±»**: cs.HC, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆEEGé©±åŠ¨çš„è„‘æœºæ¥å£ä»¥è§£å†³ä¸ªæ€§åŒ–è¯­è¨€åº·å¤é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è„‘æœºæ¥å£` `EEGä¿¡å·` `è¯­è¨€åº·å¤` `ä¸ªæ€§åŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¥ç»åé¦ˆ` `è¾…åŠ©æ²Ÿé€š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„AACç³»ç»Ÿå’Œè¯­è¨€å­¦ä¹ å¹³å°æ— æ³•å®æ—¶é€‚åº”ç”¨æˆ·çš„è®¤çŸ¥å’Œè¯­è¨€éœ€æ±‚ï¼Œå°¤å…¶åœ¨ç¥ç»ç–¾ç—…æ‚£è€…ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬ç ”ç©¶æå‡ºä¸€ç§æ··åˆæ¡†æ¶ï¼Œç»“åˆEEGä¿¡å·ä¸LLMï¼Œæ—¨åœ¨é€šè¿‡ç²¾ç¥æŒ‡ä»¤å®ç°ä¸ªæ€§åŒ–è¯­è¨€åº·å¤ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆæå‡ç”¨æˆ·çš„è¯­è¨€å­¦ä¹ ä½“éªŒï¼Œå¹¶æ ¹æ®è®¤çŸ¥è´Ÿè·åŠ¨æ€è°ƒæ•´ä»»åŠ¡éš¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ ç»Ÿçš„è¾…åŠ©æ€§å’Œæ›¿ä»£æ€§æ²Ÿé€šç³»ç»ŸåŠè¯­è¨€å­¦ä¹ å¹³å°åœ¨å®æ—¶é€‚åº”ç”¨æˆ·çš„è®¤çŸ¥å’Œè¯­è¨€éœ€æ±‚æ–¹é¢å¸¸å¸¸å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸­é£å¤±è¯­ç—‡æˆ–è‚Œèç¼©ä¾§ç´¢ç¡¬åŒ–ç­‰ç¥ç»ç–¾ç—…ä¸­ã€‚è¿‘æœŸéä¾µå…¥æ€§è„‘ç”µå›¾ï¼ˆEEGï¼‰é©±åŠ¨çš„è„‘æœºæ¥å£ï¼ˆBCIï¼‰å’ŒåŸºäºå˜æ¢å™¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¿›å±•æä¾›äº†äº’è¡¥çš„ä¼˜åŠ¿ï¼šBCIèƒ½å¤Ÿä½ç–²åŠ³åœ°æ•æ‰ç”¨æˆ·çš„ç¥ç»æ„å›¾ï¼Œè€ŒLLMåˆ™ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„è¯­è¨€å†…å®¹ã€‚æˆ‘ä»¬æå‡ºå¹¶è¯„ä¼°äº†ä¸€ç§æ–°é¢–çš„æ··åˆæ¡†æ¶ï¼Œåˆ©ç”¨å®æ—¶EEGä¿¡å·é©±åŠ¨LLMè¯­è¨€åº·å¤åŠ©æ‰‹ï¼Œæ—¨åœ¨å¸®åŠ©ä¸¥é‡è¨€è¯­æˆ–è¿åŠ¨éšœç¢çš„ç”¨æˆ·é€šè¿‡ç²¾ç¥æŒ‡ä»¤å¯¼èˆªè¯­è¨€å­¦ä¹ æ¨¡å—ï¼ŒåŠ¨æ€ä¸ªæ€§åŒ–è¯æ±‡ã€å¥å­æ„å»ºç»ƒä¹ å’Œçº æ­£åé¦ˆï¼Œå¹¶ç›‘æµ‹è®¤çŸ¥åŠªåŠ›çš„ç¥ç»æ ‡è®°ä»¥å®æ—¶è°ƒæ•´ä»»åŠ¡éš¾åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä¼ ç»ŸAACç³»ç»Ÿåœ¨å®æ—¶é€‚åº”ç”¨æˆ·éœ€æ±‚æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸­é£å¤±è¯­ç—‡å’Œè‚Œèç¼©ä¾§ç´¢ç¡¬åŒ–æ‚£è€…ä¸­çš„åº”ç”¨ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆEEGä¿¡å·ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè®¾è®¡ä¸€ä¸ªèƒ½å¤Ÿå®æ—¶å“åº”ç”¨æˆ·æ„å›¾çš„è¯­è¨€åº·å¤åŠ©æ‰‹ï¼Œåˆ©ç”¨ç”¨æˆ·çš„è„‘ç”µæ´»åŠ¨æ¥é©±åŠ¨ä¸ªæ€§åŒ–çš„è¯­è¨€å­¦ä¹ ä½“éªŒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬EEGä¿¡å·é‡‡é›†æ¨¡å—ã€ä¿¡å·å¤„ç†æ¨¡å—ã€LLMç”Ÿæˆæ¨¡å—å’Œç”¨æˆ·åé¦ˆæ¨¡å—ã€‚EEGä¿¡å·é€šè¿‡ç‰¹å®šç®—æ³•è¿›è¡Œå¤„ç†åï¼Œè¾“å…¥åˆ°LLMä¸­ç”Ÿæˆä¸ªæ€§åŒ–çš„è¯­è¨€å†…å®¹ï¼Œå¹¶æ ¹æ®ç”¨æˆ·åé¦ˆè¿›è¡Œè°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†EEGä¸LLMç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®æ—¶å“åº”ç”¨æˆ·ç¥ç»æ„å›¾çš„ç³»ç»Ÿï¼Œæ˜¾è‘—æå‡äº†è¯­è¨€åº·å¤çš„ä¸ªæ€§åŒ–ç¨‹åº¦å’Œæœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„EEGä¿¡å·å¤„ç†ç®—æ³•ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–LLMçš„ç”Ÿæˆæ•ˆæœï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹ä¸ç”¨æˆ·çš„è®¤çŸ¥çŠ¶æ€ç›¸åŒ¹é…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨è¯­è¨€å­¦ä¹ æ¨¡å—çš„é€‚åº”æ€§å’Œä¸ªæ€§åŒ–æ–¹é¢ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œç”¨æˆ·çš„å­¦ä¹ æ•ˆç‡æé«˜äº†çº¦30%ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ ¹æ®è®¤çŸ¥è´Ÿè·å®æ—¶è°ƒæ•´ä»»åŠ¡éš¾åº¦ï¼Œå¢å¼ºäº†ç”¨æˆ·ä½“éªŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯­è¨€åº·å¤ã€è¾…åŠ©æ²Ÿé€šè®¾å¤‡å’Œä¸ªæ€§åŒ–æ•™è‚²å·¥å…·ã€‚é€šè¿‡å®æ—¶ç›‘æµ‹ç”¨æˆ·çš„è„‘ç”µæ´»åŠ¨ï¼Œç³»ç»Ÿèƒ½å¤Ÿä¸ºä¸åŒçš„ç”¨æˆ·æä¾›é‡èº«å®šåˆ¶çš„å­¦ä¹ ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„ç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conventional augmentative and alternative communication (AAC) systems and language-learning platforms often fail to adapt in real time to the user's cognitive and linguistic needs, especially in neurological conditions such as post-stroke aphasia or amyotrophic lateral sclerosis. Recent advances in noninvasive electroencephalography (EEG)--based brain-computer interfaces (BCIs) and transformer--based large language models (LLMs) offer complementary strengths: BCIs capture users' neural intent with low fatigue, while LLMs generate contextually tailored language content. We propose and evaluate a novel hybrid framework that leverages real-time EEG signals to drive an LLM-powered language rehabilitation assistant. This system aims to: (1) enable users with severe speech or motor impairments to navigate language-learning modules via mental commands; (2) dynamically personalize vocabulary, sentence-construction exercises, and corrective feedback; and (3) monitor neural markers of cognitive effort to adjust task difficulty on the fly.

