---
layout: default
title: PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning
---

# PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15683" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15683v1</a>
  <a href="https://arxiv.org/pdf/2506.15683.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15683v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15683v1', 'PhantomHunter: Detecting Unseen Privately-Tuned LLM-Generated Text via Family-Aware Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuhui Shi, Yehan Yang, Qiang Sheng, Hao Mi, Beizhe Hu, Chaoxi Xu, Juan Cao

**åˆ†ç±»**: cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18

**å¤‡æ³¨**: 17 pages, 3 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPhantomHunterä»¥è§£å†³æœªè§ç§æœ‰è°ƒä¼˜LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬æ£€æµ‹` `å®¶æ—æ„ŸçŸ¥å­¦ä¹ ` `ç§æœ‰è°ƒä¼˜` `è™šå‡ä¿¡æ¯è¯†åˆ«` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹ç§æœ‰è°ƒä¼˜çš„LLMç”Ÿæˆæ–‡æœ¬æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæœªèƒ½æœ‰æ•ˆåº”å¯¹è¿™ä¸€æ–°æŒ‘æˆ˜ã€‚
2. PhantomHunteré‡‡ç”¨å®¶æ—æ„ŸçŸ¥å­¦ä¹ æ¡†æ¶ï¼Œä¸“æ³¨äºæ•æ‰åŸºç¡€æ¨¡å‹åŠå…¶è¡ç”Ÿæ¨¡å‹ä¹‹é—´çš„å…±äº«ç‰¹å¾ï¼Œä»è€Œæé«˜æ£€æµ‹èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPhantomHunteråœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šï¼ŒF1åˆ†æ•°è¶…è¿‡96%ï¼Œæ˜æ˜¾ä¼˜äºç°æœ‰çš„7ä¸ªåŸºçº¿å’Œ3ä¸ªå·¥ä¸šæœåŠ¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ™®åŠï¼Œè™šå‡ä¿¡æ¯å’Œå­¦æœ¯ä¸ç«¯ç­‰ç¤¾ä¼šé—®é¢˜æ„ˆå‘ä¸¥é‡ï¼Œä½¿å¾—LLMç”Ÿæˆæ–‡æœ¬çš„æ£€æµ‹å˜å¾—å‰æ‰€æœªæœ‰çš„é‡è¦ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†é’ˆå¯¹ç§æœ‰è°ƒä¼˜LLMç”Ÿæˆæ–‡æœ¬çš„æ–°æŒ‘æˆ˜å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡ç”¨ç§æœ‰è¯­æ–™å¾®è°ƒå¼€æºæ¨¡å‹è½»æ¾è·å¾—ç§æœ‰LLMï¼Œè¿™å¯¼è‡´ç°æœ‰æ£€æµ‹å™¨åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PhantomHunterï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºæ£€æµ‹æ¥è‡ªæœªè§ç§æœ‰è°ƒä¼˜LLMçš„æ–‡æœ¬çš„æ£€æµ‹å™¨ã€‚å…¶å®¶æ—æ„ŸçŸ¥å­¦ä¹ æ¡†æ¶æ•æ‰åŸºç¡€æ¨¡å‹åŠå…¶è¡ç”Ÿæ¨¡å‹ä¹‹é—´å…±äº«çš„å®¶æ—çº§ç‰¹å¾ï¼Œè€Œä¸æ˜¯è®°å¿†ä¸ªä½“ç‰¹å¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPhantomHunteråœ¨LLaMAã€Gemmaå’ŒMistralå®¶æ—çš„æ•°æ®ä¸Šä¼˜äº7ä¸ªåŸºçº¿å’Œ3ä¸ªå·¥ä¸šæœåŠ¡ï¼ŒF1åˆ†æ•°è¶…è¿‡96%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹æœªè§ç§æœ‰è°ƒä¼˜LLMç”Ÿæˆæ–‡æœ¬æ—¶çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºä¸ªä½“ç‰¹å¾çš„è®°å¿†ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹æ–°å‡ºç°çš„æ–‡æœ¬ç±»å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPhantomHunterçš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨å®¶æ—æ„ŸçŸ¥å­¦ä¹ æ¡†æ¶ï¼Œå…³æ³¨åŸºç¡€æ¨¡å‹åŠå…¶è¡ç”Ÿæ¨¡å‹ä¹‹é—´çš„å…±äº«ç‰¹å¾ï¼Œè€Œéå•ä¸€æ¨¡å‹çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æ£€æµ‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡æ•°æ®é¢„å¤„ç†æ¨¡å—æ¸…æ´—å’Œå‡†å¤‡æ•°æ®ï¼Œç„¶ååœ¨ç‰¹å¾æå–æ¨¡å—ä¸­æå–å®¶æ—çº§ç‰¹å¾ï¼Œæ¥ç€åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µè¿›è¡Œå®¶æ—æ„ŸçŸ¥å­¦ä¹ ï¼Œæœ€åé€šè¿‡è¯„ä¼°æ¨¡å—éªŒè¯æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šPhantomHunterçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å®¶æ—æ„ŸçŸ¥å­¦ä¹ æ¡†æ¶ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ•æ‰åˆ°ä¸åŒæ¨¡å‹ä¹‹é—´çš„å…±æ€§ç‰¹å¾ï¼Œæ˜¾è‘—æé«˜äº†å¯¹æœªè§æ–‡æœ¬çš„æ£€æµ‹èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•çš„ä¸ªä½“ç‰¹å¾è®°å¿†å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å®¶æ—ç‰¹å¾çš„å­¦ä¹ ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†å¤šå±‚æ¬¡ç‰¹å¾æå–æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒPhantomHunteråœ¨LLaMAã€Gemmaå’ŒMistralå®¶æ—çš„æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒF1åˆ†æ•°è¶…è¿‡96%ã€‚ä¸7ä¸ªåŸºçº¿å’Œ3ä¸ªå·¥ä¸šæœåŠ¡ç›¸æ¯”ï¼ŒPhantomHunterçš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨æœªè§ç§æœ‰è°ƒä¼˜LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PhantomHunterçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¤¾äº¤åª’ä½“ã€æ–°é—»å‡ºç‰ˆå’Œå­¦æœ¯ç ”ç©¶ç­‰é¢†åŸŸï¼Œå¯ä»¥æœ‰æ•ˆè¯†åˆ«å’Œé˜²æ­¢è™šå‡ä¿¡æ¯çš„ä¼ æ’­ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ä¸ºå†…å®¹å®¡æ ¸å’Œåˆè§„æ€§æ£€æŸ¥æä¾›æ”¯æŒï¼Œç¡®ä¿ä¿¡æ¯çš„çœŸå®æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œéšç€LLMæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼ŒPhantomHunteræœ‰æœ›æˆä¸ºæ–‡æœ¬æ£€æµ‹é¢†åŸŸçš„æ ‡å‡†å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the popularity of large language models (LLMs), undesirable societal problems like misinformation production and academic misconduct have been more severe, making LLM-generated text detection now of unprecedented importance. Although existing methods have made remarkable progress, a new challenge posed by text from privately tuned LLMs remains underexplored. Users could easily possess private LLMs by fine-tuning an open-source one with private corpora, resulting in a significant performance drop of existing detectors in practice. To address this issue, we propose PhantomHunter, an LLM-generated text detector specialized for detecting text from unseen, privately-tuned LLMs. Its family-aware learning framework captures family-level traits shared across the base models and their derivatives, instead of memorizing individual characteristics. Experiments on data from LLaMA, Gemma, and Mistral families show its superiority over 7 baselines and 3 industrial services, with F1 scores of over 96%.

