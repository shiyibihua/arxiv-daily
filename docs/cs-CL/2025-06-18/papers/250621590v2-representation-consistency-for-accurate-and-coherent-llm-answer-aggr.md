---
layout: default
title: Representation Consistency for Accurate and Coherent LLM Answer Aggregation
---

# Representation Consistency for Accurate and Coherent LLM Answer Aggregation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21590" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21590v2</a>
  <a href="https://arxiv.org/pdf/2506.21590.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21590v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21590v2', 'Representation Consistency for Accurate and Coherent LLM Answer Aggregation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junqi Jiang, Tom Bewley, Salim I. Amoukou, Francesco Leofante, Antonio Rago, Saumitra Mishra, Francesca Toni

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-11-03)

**å¤‡æ³¨**: Accepted at NeurIPS 2025. Camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¡¨ç¤ºä¸€è‡´æ€§æ–¹æ³•ä»¥æå‡LLMç­”æ¡ˆèšåˆçš„å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç­”æ¡ˆèšåˆ` `æ¨ç†ä¼˜åŒ–` `è¡¨ç¤ºä¸€è‡´æ€§` `å†…éƒ¨æ¿€æ´»` `ç¨€ç–ç¼–ç ` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­éœ€è¦å¤æ‚çš„æç¤ºå’Œé‡‡æ ·ç­–ç•¥ä¿®æ”¹ï¼Œé™åˆ¶äº†LLMçš„çµæ´»æ€§å’Œæ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºçš„è¡¨ç¤ºä¸€è‡´æ€§æ–¹æ³•é€šè¿‡åˆ†ææ¨¡å‹å†…éƒ¨æ¿€æ´»çš„ä¸€è‡´æ€§æ¥ä¼˜åŒ–ç­”æ¡ˆèšåˆï¼Œé¿å…äº†ä¸ä¸€è‡´æ¨ç†å¸¦æ¥çš„å¹²æ‰°ã€‚
3. é€šè¿‡å¯¹å››ä¸ªå¼€æºLLMå’Œå››ä¸ªæ¨ç†æ•°æ®é›†çš„å®éªŒï¼ŒéªŒè¯äº†RCæ–¹æ³•åœ¨å‡†ç¡®æ€§ä¸Šç›¸è¾ƒäºåŸºçº¿çš„æå‡ï¼Œè¾¾åˆ°äº†4%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æµ‹è¯•æ—¶æ‰©å±•é€šè¿‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­åˆ†é…æ›´å¤šè®¡ç®—é¢„ç®—æ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¯¹æç¤ºå’Œé‡‡æ ·ç­–ç•¥è¿›è¡Œå¤æ‚çš„ä¿®æ”¹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æµ‹è¯•æ—¶æ‰©å±•æ–¹æ³•â€”â€”è¡¨ç¤ºä¸€è‡´æ€§ï¼ˆRCï¼‰ï¼Œç”¨äºèšåˆæ¥è‡ªå¤šä¸ªå€™é€‰å“åº”çš„ç­”æ¡ˆï¼Œæ— è®ºè¿™äº›ç­”æ¡ˆæ˜¯å¦‚ä½•ç”Ÿæˆçš„ã€‚RCé€šè¿‡è€ƒè™‘æ¯ä¸ªç­”æ¡ˆåœ¨å€™é€‰å“åº”é›†ä¸­çš„å‡ºç°æ¬¡æ•°ä»¥åŠç”Ÿæˆæ¯ä¸ªç­”æ¡ˆçš„å†…éƒ¨æ¿€æ´»ä¸€è‡´æ€§æ¥å¢å¼ºç­”æ¡ˆèšåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRCåœ¨æ¨ç†è¿‡ç¨‹ä¸­æ˜¾è‘—æé«˜äº†ä»»åŠ¡æ€§èƒ½ï¼Œç›¸è¾ƒäºå¼ºåŸºçº¿æ–¹æ³•ï¼Œå‡†ç¡®æ€§æå‡å¯è¾¾4%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMåœ¨æ¨ç†æ—¶ç­”æ¡ˆèšåˆçš„å‡†ç¡®æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å¤æ‚çš„ä¿®æ”¹ï¼Œå¯¼è‡´çµæ´»æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè¡¨ç¤ºä¸€è‡´æ€§ï¼ˆRCï¼‰æ–¹æ³•ï¼Œé€šè¿‡åˆ†ææ¨¡å‹ç”Ÿæˆç­”æ¡ˆæ—¶çš„å†…éƒ¨æ¿€æ´»ä¸€è‡´æ€§ï¼Œæ¥ä¼˜åŒ–ç­”æ¡ˆèšåˆï¼Œé™ä½ä¸ä¸€è‡´æ¨ç†çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRCæ–¹æ³•çš„æ•´ä½“æµç¨‹åŒ…æ‹¬æ”¶é›†å€™é€‰å“åº”ã€è®¡ç®—å†…éƒ¨æ¿€æ´»ã€è¯„ä¼°ä¸€è‡´æ€§ä»¥åŠæœ€ç»ˆçš„ç­”æ¡ˆèšåˆï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ¿€æ´»ç¼“å­˜å’Œç›¸ä¼¼åº¦è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šRCçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥å†…éƒ¨æ¿€æ´»ä¸€è‡´æ€§ä½œä¸ºç­”æ¡ˆèšåˆçš„æ ‡å‡†ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ä»…ä¾èµ–ç­”æ¡ˆå‡ºç°æ¬¡æ•°çš„æ–¹å¼æœ¬è´¨ä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šæ–¹æ³•ä¸­ä½¿ç”¨äº†ç¼“å­˜çš„æ¿€æ´»ä¿¡å·å’Œè½»é‡çº§çš„ç›¸ä¼¼åº¦è®¡ç®—ï¼Œæ— éœ€é¢å¤–çš„æ¨¡å‹æŸ¥è¯¢ï¼Œä¸”æ”¯æŒç¨€ç–æ¿€æ´»ä¿¡å·çš„ç¼–ç ï¼Œæå‡äº†è®¡ç®—æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¡¨ç¤ºä¸€è‡´æ€§æ–¹æ³•åœ¨å››ä¸ªå¼€æºLLMä¸Šå‡å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºå¼ºåŸºçº¿æ–¹æ³•ï¼Œå‡†ç¡®æ€§æå‡å¹…åº¦å¯è¾¾4%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†ç¨€ç–æ¿€æ´»ä¿¡å·çš„ä¸€è‡´æ€§ä¸åˆç†æ¨ç†ä¹‹é—´çš„è‰¯å¥½å¯¹åº”å…³ç³»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æé«˜LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­çš„ç­”æ¡ˆèšåˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œæœªæ¥å¯èƒ½å½±å“æ›´å¹¿æ³›çš„AIåº”ç”¨åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Test-time scaling improves large language models' (LLMs) performance by allocating more compute budget during inference. To achieve this, existing methods often require intricate modifications to prompting and sampling strategies. In this work, we introduce representation consistency (RC), a test-time scaling method for aggregating answers drawn from multiple candidate responses of an LLM regardless of how they were generated, including variations in prompt phrasing and sampling strategy. RC enhances answer aggregation by not only considering the number of occurrences of each answer in the candidate response set, but also the consistency of the model's internal activations while generating the set of responses leading to each answer. These activations can be either dense (raw model activations) or sparse (encoded via pretrained sparse autoencoders). Our rationale is that if the model's representations of multiple responses converging on the same answer are highly variable, this answer is more likely to be the result of incoherent reasoning and should be down-weighted during aggregation. Importantly, our method only uses cached activations and lightweight similarity computations and requires no additional model queries. Through experiments with four open-source LLMs and four reasoning datasets, we validate the effectiveness of RC for improving task performance during inference, with consistent accuracy improvements (up to 4%) over strong test-time scaling baselines. We also show that consistency in the sparse activation signals aligns well with the common notion of coherent reasoning.

