---
layout: default
title: From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling
---

# From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16393" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.16393v1</a>
  <a href="https://arxiv.org/pdf/2506.16393.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16393v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16393v1', 'From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yao Lu, Zhaiyuan Ji, Jiawei Du, Yu Shanqing, Qi Xuan, Tianyi Zhou

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-19

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Zhaiyuan-Ji/AutoAnnotator)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öÊ®°ÂûãÂçè‰ΩúÊ≥®ÈáäÊ°ÜÊû∂AutoAnnotator‰ª•Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÊàêÊú¨È´òÂíåÁ≤æÂ∫¶‰ΩéÁöÑÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÂûãÂçè‰Ωú` `Ëá™Âä®Ê≥®Èáä` `Â∞èËØ≠Ë®ÄÊ®°Âûã` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÊñáÊú¨ÂàÜÁ±ª` `ÊàêÊú¨‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ßËßÑÊ®°Ê≥®Èáä‰∏≠ÁöÑÊàêÊú¨È´òÊòÇÔºå‰∏îÂú®ÁªÜÁ≤íÂ∫¶ËØ≠‰πâÁêÜËß£‰ªªÂä°‰∏≠ÁöÑÂáÜÁ°ÆÊÄß‰Ωé‰∫éÂ∞èËØ≠Ë®ÄÊ®°Âûã„ÄÇ
2. ÊèêÂá∫ÁöÑAutoAnnotatorÊ°ÜÊû∂ÈÄöËøáÂ§öÊ®°ÂûãÂçè‰ΩúÊ≥®ÈáäÔºåÂà©Áî®ÂÖÉÊéßÂà∂Âô®ÈÄâÊã©Âíå‰ºòÂåñÂ∞èËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ≥®ÈáäÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåAutoAnnotatorÂú®Â§öÁßçÊ≥®ÈáäËÆæÁΩÆ‰∏ãÊÄßËÉΩ‰ºòË∂äÔºåÊ≥®ÈáäÊàêÊú¨Èôç‰Ωé74.15%ÔºåÂáÜÁ°ÆÊÄßÊèêÂçá6.21%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Âü∫‰∫éÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÁöÑÊ≥®ÈáäËåÉÂºèËøëÂπ¥Êù•ÂèñÂæó‰∫ÜÊòæËëóÁ™ÅÁ†¥Ôºå‰ΩÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®‰ªçÈù¢‰∏¥‰∏§‰∏™Ê†∏ÂøÉÁì∂È¢àÔºö‰∏ÄÊòØÂ§ßËßÑÊ®°Ê≥®ÈáäÊó∂Ë∞ÉÁî®ÂïÜ‰∏öAPIÁöÑÊàêÊú¨ÈùûÂ∏∏È´òÔºõ‰∫åÊòØÂú®ÈúÄË¶ÅÁªÜÁ≤íÂ∫¶ËØ≠‰πâÁêÜËß£ÁöÑÂú∫ÊôØ‰∏≠ÔºåÂ¶ÇÊÉÖÊÑüÂàÜÁ±ªÂíåÊØíÊÄßÂàÜÁ±ªÔºåLLMsÁöÑÊ≥®ÈáäÂáÜÁ°ÆÊÄßÁîöËá≥‰Ωé‰∫é‰∏ìÈó®ÈíàÂØπËØ•È¢ÜÂüüÁöÑÂ∞èËØ≠Ë®ÄÊ®°ÂûãÔºàSLMsÔºâ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÂ§öÊ®°ÂûãÂçè‰ΩúÊ≥®ÈáäËåÉÂºèÔºåÂπ∂Âü∫‰∫éÊ≠§ËÆæËÆ°‰∫Ü‰∏Ä‰∏™ÂÖ®Ëá™Âä®Ê≥®ÈáäÊ°ÜÊû∂AutoAnnotator„ÄÇËØ•Ê°ÜÊû∂Áî±‰∏§‰∏™Â±ÇÊ¨°ÁªÑÊàêÔºå‰∏äÂ±ÇÁöÑÂÖÉÊéßÂà∂Âô®Âà©Áî®LLMsÁöÑÁîüÊàêÂíåÊé®ÁêÜËÉΩÂäõÈÄâÊã©SLMsËøõË°åÊ≥®ÈáäÔºåÂπ∂Ëá™Âä®ÁîüÊàêÊ≥®Èáä‰ª£Á†ÅÂíåÈ™åËØÅÂõ∞ÈöæÊ†∑Êú¨Ôºõ‰∏ãÂ±ÇÁöÑ‰ªªÂä°‰∏ìÂÆ∂Â±ÇÁî±Â§ö‰∏™SLMsÈÄöËøáÂ§öÊ®°ÂûãÊäïÁ•®ËøõË°åÊ≥®Èáä„ÄÇÂÆûÈ™åË°®ÊòéÔºåAutoAnnotatorÂú®Â§öÁßçËÆæÁΩÆ‰∏ãÂùá‰ºò‰∫éÁé∞ÊúâÁöÑÂºÄÊ∫ê/API LLMsÔºåÂπ∂ÊòæËëóÈôç‰Ωé‰∫ÜÊ≥®ÈáäÊàêÊú¨„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ßËßÑÊ®°Ê≥®Èáä‰∏≠ÁöÑÈ´òÊàêÊú¨ÂíåÂú®ÁªÜÁ≤íÂ∫¶ËØ≠‰πâÁêÜËß£‰ªªÂä°‰∏≠ÁöÑ‰ΩéÂáÜÁ°ÆÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Ëøô‰∫õÂú∫ÊôØ‰∏≠Ë°®Áé∞‰∏ç‰Ω≥ÔºåÊó†Ê≥ïÊª°Ë∂≥ÂÆûÈôÖÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂ§öÊ®°ÂûãÂçè‰ΩúÊ≥®ÈáäÔºåÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÁîüÊàêÂíåÊé®ÁêÜËÉΩÂäõÊù•‰ºòÂåñÂ∞èËØ≠Ë®ÄÊ®°ÂûãÁöÑÈÄâÊã©Âíå‰ΩøÁî®Ôºå‰ªéËÄåÊèêÈ´òÊ≥®ÈáäÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAutoAnnotatorÊ°ÜÊû∂ÂàÜ‰∏∫‰∏§‰∏™Â±ÇÊ¨°Ôºö‰∏äÂ±ÇÁöÑÂÖÉÊéßÂà∂Âô®Ë¥üË¥£ÈÄâÊã©ÂêàÈÄÇÁöÑÂ∞èËØ≠Ë®ÄÊ®°ÂûãËøõË°åÊ≥®ÈáäÔºåÂπ∂ÁîüÊàêÊ≥®Èáä‰ª£Á†ÅÔºõ‰∏ãÂ±ÇÁöÑ‰ªªÂä°‰∏ìÂÆ∂Â±ÇÁî±Â§ö‰∏™Â∞èËØ≠Ë®ÄÊ®°ÂûãÁªÑÊàêÔºåÈÄöËøáÂ§öÊ®°ÂûãÊäïÁ•®ËøõË°åÊúÄÁªàÊ≥®Èáä„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂºïÂÖ•‰∫ÜÂÖÉÊéßÂà∂Âô®Â±ÇÔºåÈÄöËøáÂØπÂõ∞ÈöæÊ†∑Êú¨ÁöÑ‰∫åÊ¨°ÂÆ°Ê†∏ÔºåÂà©Áî®Âº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÂØπÂ∞èËØ≠Ë®ÄÊ®°ÂûãËøõË°åÈò∂ÊÆµÊÄßÂæÆË∞ÉÔºå‰ªéËÄåÊèêÂçáÂÖ∂Ê≥õÂåñËÉΩÂäõ„ÄÇËøô‰∏ÄËÆæËÆ°‰∏é‰º†ÁªüÁöÑÂçï‰∏ÄÊ®°ÂûãÊ≥®ÈáäÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê°ÜÊû∂‰∏≠ÔºåÂÖÉÊéßÂà∂Âô®ÁöÑÈÄâÊã©Êú∫Âà∂ÂíåÂõ∞ÈöæÊ†∑Êú¨ÁöÑÂ§ÑÁêÜÁ≠ñÁï•ÊòØÂÖ≥ÈîÆËÆæËÆ°ÔºåÊ≠§Â§ñÔºåÈááÁî®‰∫ÜÊåÅÁª≠Â≠¶‰π†Á≠ñÁï•Êù•ÂæÆË∞ÉÂ∞èËØ≠Ë®ÄÊ®°ÂûãÔºå‰ª•ÈÄÇÂ∫î‰∏çÊñ≠ÂèòÂåñÁöÑÊ≥®ÈáäÈúÄÊ±Ç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåAutoAnnotatorÂú®Èõ∂-shot„ÄÅone-shot„ÄÅÈìæÂºèÊé®ÁêÜÔºàCoTÔºâÂíåÂ§öÊï∞ÊäïÁ•®ËÆæÁΩÆ‰∏ãÂùá‰ºò‰∫éÁé∞ÊúâÁöÑÂºÄÊ∫ê/API LLMsÔºåÊ≥®ÈáäÊàêÊú¨Áõ∏ÊØîÁõ¥Êé•‰ΩøÁî®GPT-3.5-turboÈôç‰Ωé‰∫Ü74.15%ÔºåÂêåÊó∂ÂáÜÁ°ÆÊÄßÊèêÂçá‰∫Ü6.21%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á§æ‰∫§Â™í‰ΩìÂÜÖÂÆπÂÆ°Ê†∏„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÂú®Á∫øËØÑËÆ∫ÂàÜÁ±ªÁ≠âÈúÄË¶ÅÈ´òÊïà‰∏îÂáÜÁ°ÆÁöÑÊñáÊú¨Ê≥®ÈáäÁöÑÂú∫ÊôØ„ÄÇÈÄöËøáÈôç‰ΩéÊ≥®ÈáäÊàêÊú¨ÂíåÊèêÈ´òÂáÜÁ°ÆÊÄßÔºåAutoAnnotatorËÉΩÂ§ü‰∏∫‰ºÅ‰∏öÂíåÁ†îÁ©∂Êú∫ÊûÑÊèê‰æõÊõ¥ÂÖ∑ÊàêÊú¨ÊïàÁõäÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Although the annotation paradigm based on Large Language Models (LLMs) has made significant breakthroughs in recent years, its actual deployment still has two core bottlenecks: first, the cost of calling commercial APIs in large-scale annotation is very expensive; second, in scenarios that require fine-grained semantic understanding, such as sentiment classification and toxicity classification, the annotation accuracy of LLMs is even lower than that of Small Language Models (SLMs) dedicated to this field. To address these problems, we propose a new paradigm of multi-model cooperative annotation and design a fully automatic annotation framework AutoAnnotator based on this. Specifically, AutoAnnotator consists of two layers. The upper-level meta-controller layer uses the generation and reasoning capabilities of LLMs to select SLMs for annotation, automatically generate annotation code and verify difficult samples; the lower-level task-specialist layer consists of multiple SLMs that perform annotation through multi-model voting. In addition, we use the difficult samples obtained by the secondary review of the meta-controller layer as the reinforcement learning set and fine-tune the SLMs in stages through a continual learning strategy, thereby improving the generalization of SLMs. Extensive experiments show that AutoAnnotator outperforms existing open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings. Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to directly annotating with GPT-3.5-turbo, while still improving the accuracy by 6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.

