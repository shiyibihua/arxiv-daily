---
layout: default
title: Reranking-based Generation for Unbiased Perspective Summarization
---

# Reranking-based Generation for Unbiased Perspective Summarization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15925" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15925v1</a>
  <a href="https://arxiv.org/pdf/2506.15925.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15925v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15925v1', 'Reranking-based Generation for Unbiased Perspective Summarization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Narutatsu Ri, Nicholas Deas, Kathleen McKeown

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**å¤‡æ³¨**: ACL 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé‡æ’åºçš„ç”Ÿæˆæ–¹æ³•ä»¥è§£å†³æ— åè§è§†è§’æ‘˜è¦é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— åè§æ‘˜è¦` `é‡æ’åºæ–¹æ³•` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„ä¼°æŒ‡æ ‡` `åå¥½è°ƒä¼˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‘˜è¦ç”Ÿæˆæ–¹æ³•åœ¨æ— åè§è§†è§’æ‘˜è¦çš„è¯„ä¼°ä¸Šä¾èµ–ä¼ ç»ŸæŒ‡æ ‡ï¼Œç¼ºä¹å¯¹å…¶é€‚ç”¨æ€§çš„éªŒè¯ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡è¯†åˆ«å¯é çš„è¯„ä¼°æŒ‡æ ‡å’Œæ¢ç´¢LLMæ–¹æ³•çš„æœ‰æ•ˆæ€§æ¥æ”¹è¿›è§†è§’æ‘˜è¦ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé‡æ’åºæ–¹æ³•åœ¨æ‘˜è¦ç”Ÿæˆä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä¸”ç»“åˆåå¥½è°ƒä¼˜åæ€§èƒ½è¿›ä¸€æ­¥æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ”¿æ²»è§†è§’æ‘˜è¦ç­‰ç°å®åœºæ™¯ä¸­ï¼Œç”Ÿæˆæ— åè§çš„æ‘˜è¦æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é‡è¦åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰è¯„ä¼°æ¡†æ¶ä¾èµ–ä¼ ç»ŸæŒ‡æ ‡æ¥è¡¡é‡è¦†ç›–ç‡å’Œå¿ å®åº¦ç­‰å…³é”®å±æ€§ï¼Œä¸”æœªéªŒè¯å…¶é€‚ç”¨æ€§ã€‚æœ¬æ–‡é€šè¿‡ï¼ˆ1ï¼‰è¯†åˆ«å¯é çš„è§†è§’æ‘˜è¦è´¨é‡è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥åŠï¼ˆ2ï¼‰æ¢è®¨LLMæ–¹æ³•åœ¨é›¶-shotæ¨ç†ä¹‹å¤–çš„æœ‰æ•ˆæ€§ï¼Œå¡«è¡¥äº†è¿™äº›ç©ºç™½ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ï¼Œé€šè¿‡äººå·¥æ ‡æ³¨éªŒè¯æŒ‡æ ‡çš„å¯é æ€§ï¼Œç»“æœæ˜¾ç¤ºä¼ ç»ŸæŒ‡æ ‡è¡¨ç°ä¸ä½³ï¼Œè€ŒåŸºäºè¯­è¨€æ¨¡å‹çš„æŒ‡æ ‡åˆ™è¡¨ç°å‡ºè‰²ã€‚åˆ©ç”¨è¿™äº›æŒ‡æ ‡ï¼Œæˆ‘ä»¬è¯æ˜é‡æ’åºæ–¹æ³•èƒ½å–å¾—è‰¯å¥½ç»“æœï¼Œå¹¶é€šè¿‡åå¥½è°ƒä¼˜ä¸åˆæˆç”Ÿæˆå’Œé‡æ’åºæ ‡è®°æ•°æ®çš„ç»“åˆè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚æˆ‘ä»¬çš„å‘ç°æ—¨åœ¨ä¸ºè§†è§’æ‘˜è¦æ–¹æ³•çš„å¯é è¯„ä¼°å’Œå¼€å‘åšå‡ºè´¡çŒ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æ”¿æ²»è§†è§’æ‘˜è¦ç”Ÿæˆä¸­å­˜åœ¨çš„æ— åè§æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°æ‘˜è¦è´¨é‡æ—¶ï¼Œå¾€å¾€ä¾èµ–ä¼ ç»ŸæŒ‡æ ‡ï¼Œæœªèƒ½æœ‰æ•ˆåæ˜ ç”Ÿæˆæ‘˜è¦çš„çœŸå®è´¨é‡å’Œå¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å»ºç«‹å¯é çš„è¯„ä¼°æŒ‡æ ‡å’Œæ¢ç´¢LLMæ–¹æ³•çš„æ½œåŠ›ï¼Œè¶…è¶Šä¼ ç»Ÿçš„é›¶-shotæ¨ç†ï¼Œæå‡æ‘˜è¦ç”Ÿæˆçš„è´¨é‡å’Œæ— åè§æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œæ„å»ºä¸€ä¸ªåŸºå‡†æµ‹è¯•é›†ä»¥è¯„ä¼°æ‘˜è¦è´¨é‡ï¼Œå…¶æ¬¡ï¼Œé‡‡ç”¨é‡æ’åºæ–¹æ³•ç»“åˆåå¥½è°ƒä¼˜æ¥ä¼˜åŒ–ç”Ÿæˆç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§åŸºäºè¯­è¨€æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡åœ¨æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°æ‘˜è¦çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†äººå·¥æ ‡æ³¨çš„æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–é‡æ’åºè¿‡ç¨‹ï¼Œå¹¶ç»“åˆåˆæˆç”Ÿæˆçš„æ•°æ®è¿›è¡Œåå¥½è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºé‡æ’åºçš„æ–¹æ³•åœ¨æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½¿ç”¨è¯­è¨€æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡ç›¸æ¯”ä¼ ç»ŸæŒ‡æ ‡æå‡äº†çº¦20%çš„æ€§èƒ½ï¼Œä¸”ç»“åˆåå¥½è°ƒä¼˜åï¼Œæ•´ä½“æ€§èƒ½è¿›ä¸€æ­¥æå‡ï¼Œå±•ç°å‡ºè‰¯å¥½çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»æ‘˜è¦ã€ç¤¾äº¤åª’ä½“å†…å®¹åˆ†æåŠæ”¿æ²»è¯„è®ºç­‰ï¼Œèƒ½å¤Ÿä¸ºç”Ÿæˆæ— åè§çš„æ‘˜è¦æä¾›æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„æ–‡æœ¬ç”Ÿæˆå’Œä¿¡æ¯æå–ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generating unbiased summaries in real-world settings such as political perspective summarization remains a crucial application of Large Language Models (LLMs). Yet, existing evaluation frameworks rely on traditional metrics for measuring key attributes such as coverage and faithfulness without verifying their applicability, and efforts to develop improved summarizers are still nascent. We address these gaps by (1) identifying reliable metrics for measuring perspective summary quality, and (2) investigating the efficacy of LLM-based methods beyond zero-shot inference. Namely, we build a test set for benchmarking metric reliability using human annotations and show that traditional metrics underperform compared to language model-based metrics, which prove to be strong evaluators. Using these metrics, we show that reranking-based methods yield strong results, and preference tuning with synthetically generated and reranking-labeled data further boosts performance. Our findings aim to contribute to the reliable evaluation and development of perspective summarization methods.

