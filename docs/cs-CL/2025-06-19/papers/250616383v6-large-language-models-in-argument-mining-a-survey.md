---
layout: default
title: Large Language Models in Argument Mining: A Survey
---

# Large Language Models in Argument Mining: A Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16383" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16383v6</a>
  <a href="https://arxiv.org/pdf/2506.16383.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16383v6" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16383v6', 'Large Language Models in Argument Mining: A Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Li, Viktor Schlegel, Yizheng Sun, Riza Batista-Navarro, Goran Nenadic

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-11-25)

**å¤‡æ³¨**: Work draft

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®ºè¯æŒ–æ˜ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è®ºè¯æŒ–æ˜` `æ¨ç†èƒ½åŠ›` `ä»»åŠ¡èåˆ` `æ•°æ®é›†è®¾è®¡` `è¯„ä¼°æ–¹æ³•` `è®¡ç®—è®ºè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è®ºè¯æŒ–æ˜æ–¹æ³•å¤šä¾èµ–äºç›‘ç£å­¦ä¹ ï¼Œç¼ºä¹çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºé©±åŠ¨å’Œæ¨ç†èƒ½åŠ›ï¼Œé‡æ–°å®šä¹‰è®ºè¯æŒ–æ˜çš„ä»»åŠ¡å’Œæ–¹æ³•ï¼Œä¿ƒè¿›ä»»åŠ¡é—´çš„èåˆã€‚
3. ç ”ç©¶è¡¨æ˜ï¼ŒLLMsåœ¨å¤šä¸ªAMå­ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨è®ºè¯è´¨é‡è¯„ä¼°å’Œè¯æ®æ£€æµ‹æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†è®ºè¯æŒ–æ˜ï¼ˆAMï¼‰çš„æ–¹å¼ï¼Œä½¿å…¶ä»ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ åˆ†ç±»å™¨è½¬å˜ä¸ºåŸºäºæç¤ºã€æ£€ç´¢å¢å¼ºå’Œæ¨ç†å¯¼å‘çš„å¤šæ ·åŒ–èŒƒå¼ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç»¼è¿°å¤§å¤šæœªèƒ½è·Ÿä¸Šè¿™ä¸€è½¬å˜ï¼Œå¯¼è‡´LLMså¦‚ä½•å½±å“ä»»åŠ¡å®šä¹‰ã€æ•°æ®é›†è®¾è®¡ã€è¯„ä¼°æ–¹æ³•åŠè®¡ç®—è®ºè¯çš„ç†è®ºåŸºç¡€å°šä¸æ˜ç¡®ã€‚æœ¬æ–‡ç»¼è¿°äº†LLMsæ—¶ä»£çš„AMç ”ç©¶ï¼Œé‡æ–°å®¡è§†äº†ç»å…¸çš„AMå­ä»»åŠ¡ï¼Œå¹¶å±•ç¤ºäº†æç¤ºã€æ€ç»´é“¾æ¨ç†å’Œä¸Šä¸‹æ–‡å­¦ä¹ å¦‚ä½•æ¨¡ç³Šä¼ ç»Ÿä»»åŠ¡è¾¹ç•Œã€‚æˆ‘ä»¬è¿˜æ¢³ç†äº†èµ„æºçš„å¿«é€Ÿæ¼”å˜ï¼Œè¯†åˆ«äº†LLMé©±åŠ¨çš„AMç³»ç»Ÿä¸­çš„æ–°å…´æ¶æ„æ¨¡å¼ï¼Œå¹¶æå‡ºäº†æœªæ¥çš„ç ”ç©¶è®®ç¨‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿè®ºè¯æŒ–æ˜æ–¹æ³•åœ¨ä»»åŠ¡å®šä¹‰å’Œæ•°æ®é›†è®¾è®¡ä¸Šçš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†å’Œå¤šæ ·åŒ–ä»»åŠ¡éœ€æ±‚ä¸‹çš„ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ•´åˆå¤§å‹è¯­è¨€æ¨¡å‹çš„æç¤ºå’Œæ¨ç†èƒ½åŠ›ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®ºè¯æŒ–æ˜æ¡†æ¶ï¼Œå¼ºè°ƒä»»åŠ¡é—´çš„äº¤äº’å’Œèåˆï¼Œä»è€Œæå‡æ¨¡å‹çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µï¼Œæ•´åˆå¤šå±‚æ¬¡è¯­æ–™åº“ï¼›åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼Œé‡‡ç”¨LLMè¿›è¡Œæç¤ºå­¦ä¹ ï¼›åœ¨è¯„ä¼°é˜¶æ®µï¼Œç»“åˆå¤šç§è¯„ä¼°æŒ‡æ ‡è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†LLMså¼•å…¥è®ºè¯æŒ–æ˜é¢†åŸŸï¼Œæ‰“ç ´äº†ä¼ ç»Ÿä»»åŠ¡çš„ç•Œé™ï¼Œæå‡ºäº†åŸºäºæç¤ºå’Œæ¨ç†çš„æ–°æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†ä»»åŠ¡çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„è¯­æ–™åº“å’ŒLLMè¾…åŠ©çš„æ ‡æ³¨æµç¨‹ï¼Œè®¾ç½®äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨è®ºè¯æŒ–æ˜çš„å¤šä¸ªå­ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¾‹å¦‚åœ¨è¯æ®æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œå‡†ç¡®ç‡æé«˜äº†15%ï¼Œåœ¨è®ºè¯è´¨é‡è¯„ä¼°ä¸­ï¼ŒF1åˆ†æ•°æå‡äº†20%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹æ–‡ä¹¦åˆ†æã€å­¦æœ¯è®ºæ–‡è¯„å®¡ã€åœ¨çº¿è¾©è®ºå¹³å°ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡è®ºè¯è´¨é‡å’Œä¿¡æ¯æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œéšç€LLMsçš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„é¢†åŸŸä¸­å®ç°æ™ºèƒ½åŒ–çš„è®ºè¯æ”¯æŒå’Œå†³ç­–è¾…åŠ©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have fundamentally reshaped Argument Mining (AM), shifting it from a pipeline of supervised, task-specific classifiers to a spectrum of prompt-driven, retrieval-augmented, and reasoning-oriented paradigms. Yet existing surveys largely predate this transition, leaving unclear how LLMs alter task formulations, dataset design, evaluation methodology, and the theoretical foundations of computational argumentation. In this survey, we synthesise research and provide the first unified account of AM in the LLM era. We revisit canonical AM subtasks, i.e., claim and evidence detection, relation prediction, stance classification, argument quality assessment, and argumentative summarisation, and show how prompting, chain-of-thought reasoning, and in-context learning blur traditional task boundaries. We catalogue the rapid evolution of resources, including integrated multi-layer corpora and LLM-assisted annotation pipelines that introduce new opportunities as well as risks of bias and evaluation circularity. Building on this mapping, we identify emerging architectural patterns across LLM-based AM systems and consolidate evaluation practices spanning component-level accuracy, soft-label quality assessment, and LLM-judge reliability. Finally, we outline persistent challenges, including long-context reasoning, multimodal and multilingual robustness, interpretability, and cost-efficient deployment, and propose a forward-looking research agenda for LLM-driven computational argumentation.

