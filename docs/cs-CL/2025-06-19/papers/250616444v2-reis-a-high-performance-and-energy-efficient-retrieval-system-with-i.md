---
layout: default
title: REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing
---

# REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16444" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16444v2</a>
  <a href="https://arxiv.org/pdf/2506.16444.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16444v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16444v2', 'REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kangqi Chen, Andreas Kosmas Kakolyris, Rakesh Nadig, Manos Frouzakis, Nika Mansouri Ghiasi, Yu Liang, Haiyu Mao, Jisung Park, Mohammad Sadrosadati, Onur Mutlu

**åˆ†ç±»**: cs.CL, cs.AR, cs.DB

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-11-11)

**å¤‡æ³¨**: Extended version of our publication at the 52nd International Symposium on Computer Architecture (ISCA-52), 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºREISä»¥è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆä¸­çš„æ•°æ®æ£€ç´¢ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å­˜å‚¨å†…å¤„ç†` `è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢` `æ•°æ®åº“ä¼˜åŒ–` `èƒ½æ•ˆæå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•åœ¨æ£€ç´¢é˜¶æ®µé¢ä¸´æ˜¾è‘—çš„æ•°æ®ç§»åŠ¨å¼€é”€ï¼Œæˆä¸ºæ¨ç†çš„ç“¶é¢ˆã€‚
2. REISé€šè¿‡ä¼˜åŒ–æ•°æ®åº“å¸ƒå±€ã€å¼•å…¥ISPå®šåˆ¶çš„æ•°æ®æ”¾ç½®æŠ€æœ¯å’Œåˆ©ç”¨å­˜å‚¨å†…è®¡ç®—èµ„æºï¼Œè§£å†³äº†æ£€ç´¢æ•ˆç‡ä½çš„é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒREISåœ¨æ£€ç´¢æ€§èƒ½ä¸Šæå‡äº†13å€ï¼Œèƒ½æ•ˆæå‡äº†55å€ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»ŸæœåŠ¡å™¨çº§ç³»ç»Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´çŸ¥è¯†å±€é™æ€§çš„é—®é¢˜ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰é€šè¿‡å¤–éƒ¨çŸ¥è¯†åº“æ¥è¡¥å……å…¶é™æ€çŸ¥è¯†ã€‚RAGçš„æ£€ç´¢é˜¶æ®µæ˜¯æ¨ç†ç®¡é“ä¸­çš„ç“¶é¢ˆï¼Œç°æœ‰çš„è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆANNSï¼‰ç®—æ³•åœ¨å¤§æ•°æ®åº“ä¸­å­˜åœ¨æ˜¾è‘—çš„æ•°æ®ç§»åŠ¨å¼€é”€ã€‚ä¸ºæ­¤ï¼ŒREISæå‡ºäº†ä¸€ç§ä¸“ä¸ºRAGè®¾è®¡çš„å­˜å‚¨å†…å¤„ç†ï¼ˆISPï¼‰ç³»ç»Ÿï¼Œé€šè¿‡ä¼˜åŒ–æ•°æ®åº“å¸ƒå±€ã€å¼•å…¥ISPå®šåˆ¶çš„æ•°æ®æ”¾ç½®æŠ€æœ¯ä»¥åŠåˆ©ç”¨å­˜å‚¨ç³»ç»Ÿå†…çš„è®¡ç®—èµ„æºï¼Œæ˜¾è‘—æé«˜äº†æ£€ç´¢æ€§èƒ½å’Œèƒ½æ•ˆã€‚ä¸æœåŠ¡å™¨çº§ç³»ç»Ÿç›¸æ¯”ï¼ŒREISåœ¨æ£€ç´¢æ€§èƒ½ä¸Šå¹³å‡æå‡äº†13å€ï¼Œèƒ½æ•ˆæå‡äº†55å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä¸­çš„æ£€ç´¢é˜¶æ®µç“¶é¢ˆï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®åº“æ—¶å­˜åœ¨æ˜¾è‘—çš„æ•°æ®ç§»åŠ¨å¼€é”€ï¼Œå½±å“äº†æ€§èƒ½å’Œèƒ½æ•ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šREISçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å­˜å‚¨å†…å¤„ç†ï¼ˆISPï¼‰æŠ€æœ¯ä¼˜åŒ–è¿‘ä¼¼æœ€è¿‘é‚»æœç´¢ï¼ˆANNSï¼‰ï¼Œå‡å°‘æ•°æ®ç§»åŠ¨å¹¶æé«˜æ£€ç´¢æ•ˆç‡ã€‚è®¾è®¡ä¸Šï¼ŒREISä¸“ä¸ºRAGç³»ç»Ÿé‡èº«å®šåˆ¶ï¼Œç¡®ä¿é«˜æ•ˆçš„æ•°æ®æ£€ç´¢å’Œå¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šREISçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ•°æ®åº“å¸ƒå±€ã€ISPå®šåˆ¶çš„æ•°æ®æ”¾ç½®æŠ€æœ¯å’ŒANNSå¼•æ“ã€‚æ•°æ®åº“å¸ƒå±€å°†åµŒå…¥å‘é‡ä¸å…¶ç›¸å…³æ–‡æ¡£é“¾æ¥ï¼Œä¾¿äºé«˜æ•ˆæ£€ç´¢ï¼›æ•°æ®æ”¾ç½®æŠ€æœ¯åœ¨å­˜å‚¨ç³»ç»Ÿçš„ä¸åŒå¹³é¢ä¸Šåˆ†å¸ƒåµŒå…¥ï¼›ANNSå¼•æ“åˆ©ç”¨å­˜å‚¨ç³»ç»Ÿå†…çš„è®¡ç®—èµ„æºè¿›è¡Œé«˜æ•ˆæ£€ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šREISçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸“ä¸ºISPè®¾è®¡çš„æ•°æ®åº“å¸ƒå±€å’Œæ•°æ®æ”¾ç½®æŠ€æœ¯ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•æœªèƒ½ä¼˜åŒ–æ•°æ®æ£€ç´¢æ“ä½œçš„é—®é¢˜ï¼Œå¹¶é¿å…äº†å¤§è§„æ¨¡ç¡¬ä»¶æ”¹åŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šREISé‡‡ç”¨è½»é‡çº§çš„é—ªå­˜è½¬æ¢å±‚ï¼ˆFlash Translation Layerï¼‰ï¼Œå¹¶åœ¨æ•°æ®æ”¾ç½®æ—¶è€ƒè™‘äº†å­˜å‚¨ç³»ç»Ÿçš„ç‰¹æ€§ï¼Œä»¥å®ç°é«˜æ•ˆçš„ANNSæ“ä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

REISåœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ä¼ ç»ŸæœåŠ¡å™¨çº§ç³»ç»Ÿç›¸æ¯”ï¼Œæ£€ç´¢æ€§èƒ½å¹³å‡æå‡äº†13å€ï¼Œèƒ½æ•ˆæå‡äº†55å€ã€‚è¿™ä¸€æ˜¾è‘—çš„æ€§èƒ½æå‡è¡¨æ˜REISåœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶çš„ä¼˜åŠ¿ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

REISçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¿«é€Ÿæ£€ç´¢å’Œå¤„ç†å¤§è§„æ¨¡æ•°æ®çš„åœºæ™¯ï¼Œå¦‚æ™ºèƒ½æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿå’Œè‡ªç„¶è¯­è¨€å¤„ç†ç­‰ã€‚é€šè¿‡æé«˜æ£€ç´¢æ•ˆç‡å’Œèƒ½æ•ˆï¼ŒREISèƒ½å¤Ÿä¸ºå®æ—¶æ•°æ®å¤„ç†å’Œåˆ†ææä¾›æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) face an inherent challenge: their knowledge is confined to the data that they have been trained on. To overcome this issue, Retrieval-Augmented Generation (RAG) complements the static training-derived knowledge of LLMs with an external knowledge repository. RAG consists of three stages: indexing, retrieval, and generation. The retrieval stage of RAG becomes a significant bottleneck in inference pipelines. In this stage, a user query is mapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS) algorithm searches for similar vectors in the database to identify relevant items. Due to the large database sizes, ANNS incurs significant data movement overheads between the host and the storage system. To alleviate these overheads, prior works propose In-Storage Processing (ISP) techniques that accelerate ANNS by performing computations inside storage. However, existing works that leverage ISP for ANNS (i) employ algorithms that are not tailored to ISP systems, (ii) do not accelerate data retrieval operations for data selected by ANNS, and (iii) introduce significant hardware modifications, limiting performance and hindering their adoption. We propose REIS, the first ISP system tailored for RAG that addresses these limitations with three key mechanisms. First, REIS employs a database layout that links database embedding vectors to their associated documents, enabling efficient retrieval. Second, it enables efficient ANNS by introducing an ISP-tailored data placement technique that distributes embeddings across the planes of the storage system and employs a lightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that uses the existing computational resources inside the storage system. Compared to a server-grade system, REIS improves the performance (energy efficiency) of retrieval by an average of 13x (55x).

