---
layout: default
title: JETHICS: Japanese Ethics Understanding Evaluation Dataset
---

# JETHICS: Japanese Ethics Understanding Evaluation Dataset

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16187" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16187v1</a>
  <a href="https://arxiv.org/pdf/2506.16187.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16187v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16187v1', 'JETHICS: Japanese Ethics Understanding Evaluation Dataset')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Masashi Takeshita, Rafal Rzepka

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºJETHICSæ•°æ®é›†ä»¥è¯„ä¼°AIæ¨¡å‹çš„ä¼¦ç†ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¼¦ç†ç†è§£` `æ•°æ®é›†æ„å»º` `å¤šè¯­è¨€æ¨¡å‹` `äººå·¥æ™ºèƒ½ä¼¦ç†` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„AIæ¨¡å‹åœ¨ä¼¦ç†ç†è§£æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ—¥è¯­ç¯å¢ƒä¸‹çš„è¡¨ç°è¾ƒå·®ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†JETHICSæ•°æ®é›†ï¼Œæ—¨åœ¨ä¸ºAIæ¨¡å‹çš„ä¼¦ç†ç†è§£æä¾›æ ‡å‡†åŒ–çš„è¯„ä¼°åŸºå‡†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„ä¸»æµå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼¦ç†ç†è§£ä»»åŠ¡ä¸Šä»æœ‰è¾ƒå¤§çš„æå‡ç©ºé—´ï¼Œå°¤å…¶æ˜¯æ—¥è¯­æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†JETHICSï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°AIæ¨¡å‹ä¼¦ç†ç†è§£èƒ½åŠ›çš„æ—¥è¯­æ•°æ®é›†ã€‚JETHICSåŒ…å«78,000ä¸ªç¤ºä¾‹ï¼Œæ„å»ºæ–¹æ³•å‚è€ƒäº†ç°æœ‰çš„è‹±è¯­ETHICSæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ¶µç›–äº†åŸºäºä¼¦ç†å­¦å’Œæ”¿æ²»å“²å­¦çš„å››ä¸ªç±»åˆ«çš„è§„èŒƒç†è®ºå’Œæ¦‚å¿µï¼Œä»¥åŠä¸€ä¸ªä»£è¡¨å¸¸è¯†é“å¾·çš„ç±»åˆ«ã€‚æˆ‘ä»¬çš„è¯„ä¼°å®éªŒé’ˆå¯¹éä¸“æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’ŒGPT-4oè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºå³ä½¿æ˜¯GPT-4oçš„å¹³å‡å¾—åˆ†ä¹Ÿä»…çº¦ä¸º0.7ï¼Œè€Œè¡¨ç°æœ€ä½³çš„æ—¥è¯­LLMå¾—åˆ†çº¦ä¸º0.5ï¼Œè¡¨æ˜å½“å‰LLMsåœ¨ä¼¦ç†ç†è§£æ–¹é¢ä»æœ‰è¾ƒå¤§çš„æ”¹è¿›ç©ºé—´ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³AIæ¨¡å‹åœ¨ä¼¦ç†ç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹æ—¥è¯­çš„ä¼¦ç†è¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–æ•°æ®é›†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„é€‚ç”¨æ€§å’Œå‡†ç¡®æ€§å­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºJETHICSæ•°æ®é›†ï¼Œå€Ÿé‰´è‹±è¯­ETHICSæ•°æ®é›†çš„æ„å»ºæ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºæ—¥è¯­ç¯å¢ƒä¸‹çš„AIä¼¦ç†ç†è§£æä¾›ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°å·¥å…·ã€‚é€šè¿‡åˆ†ç±»ä¸åŒçš„ä¼¦ç†ç†è®ºå’Œå¸¸è¯†é“å¾·ï¼Œå¢å¼ºæ¨¡å‹çš„ä¼¦ç†æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šJETHICSæ•°æ®é›†çš„æ„å»ºåŒ…æ‹¬æ•°æ®æ”¶é›†ã€åˆ†ç±»å’Œæ ‡æ³¨ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†ä¸ä¼¦ç†ç›¸å…³çš„æ–‡æœ¬æ•°æ®ï¼Œç„¶åæ ¹æ®ä¼¦ç†ç†è®ºè¿›è¡Œåˆ†ç±»ï¼Œæœ€åè¿›è¡Œäººå·¥æ ‡æ³¨ä»¥ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šJETHICSæ•°æ®é›†çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶é’ˆå¯¹æ—¥è¯­çš„ç‰¹å®šæ„å»ºï¼Œå¡«è¡¥äº†ç°æœ‰ä¼¦ç†ç†è§£è¯„ä¼°å·¥å…·åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„ç©ºç™½ï¼Œå°¤å…¶æ˜¯å¯¹æ—¥æœ¬æ–‡åŒ–å’Œç¤¾ä¼šèƒŒæ™¯çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†åŒ…å«78,000ä¸ªç¤ºä¾‹ï¼Œæ¶µç›–å››ä¸ªä¼¦ç†ç†è®ºç±»åˆ«å’Œä¸€ä¸ªå¸¸è¯†é“å¾·ç±»åˆ«ã€‚æ¯ä¸ªç¤ºä¾‹ç»è¿‡ä¸¥æ ¼çš„æ ‡æ³¨å’Œåˆ†ç±»ï¼Œä»¥ç¡®ä¿å…¶åœ¨ä¼¦ç†ç†è§£è¯„ä¼°ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oåœ¨ä¼¦ç†ç†è§£ä»»åŠ¡ä¸Šçš„å¹³å‡å¾—åˆ†çº¦ä¸º0.7ï¼Œè€Œè¡¨ç°æœ€ä½³çš„æ—¥è¯­LLMå¾—åˆ†ä»…ä¸º0.5ã€‚è¿™è¡¨æ˜å½“å‰æ¨¡å‹åœ¨ä¼¦ç†ç†è§£æ–¹é¢çš„æ€§èƒ½ä»æœ‰è¾ƒå¤§æå‡ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨æ—¥è¯­ç¯å¢ƒä¸‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

JETHICSæ•°æ®é›†çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIä¼¦ç†å®¡æŸ¥ã€æ•™è‚²å’Œç¤¾ä¼šç§‘å­¦ç ”ç©¶ã€‚å®ƒå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…è¯„ä¼°å’Œæ”¹è¿›AIæ¨¡å‹åœ¨ä¼¦ç†å†³ç­–ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ›´è´Ÿè´£ä»»çš„AIæŠ€æœ¯å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†å¯èƒ½æˆä¸ºå¤šè¯­è¨€ä¼¦ç†ç†è§£ç ”ç©¶çš„é‡è¦åŸºå‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we propose JETHICS, a Japanese dataset for evaluating ethics understanding of AI models. JETHICS contains 78K examples and is built by following the construction methods of the existing English ETHICS dataset. It includes four categories based normative theories and concepts from ethics and political philosophy; and one representing commonsense morality. Our evaluation experiments on non-proprietary large language models (LLMs) and on GPT-4o reveal that even GPT-4o achieves only an average score of about 0.7, while the best-performing Japanese LLM attains around 0.5, indicating a relatively large room for improvement in current LLMs.

