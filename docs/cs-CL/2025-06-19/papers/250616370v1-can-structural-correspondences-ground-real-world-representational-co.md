---
layout: default
title: Can structural correspondences ground real world representational content in Large Language Models?
---

# Can structural correspondences ground real world representational content in Large Language Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16370" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16370v1</a>
  <a href="https://arxiv.org/pdf/2506.16370.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16370v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16370v1', 'Can structural correspondences ground real world representational content in Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Iwan Williams

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨ç»“æ„å¯¹åº”å…³ç³»åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ç°å®å†…å®¹è¡¨å¾é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç»“æ„å¯¹åº”å…³ç³»` `ç°å®å†…å®¹è¡¨å¾` `ä»»åŠ¡æ€§èƒ½` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¡¨å¾ç°å®ä¸–ç•Œå†…å®¹æ–¹é¢å­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œå°¤å…¶æ˜¯ç¼ºä¹ä¸å¤–éƒ¨ç°å®çš„ç›´æ¥æ¥è§¦ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ç»“æ„å¯¹åº”å…³ç³»çš„è§†è§’æ¥æ¢è®¨LLMsçš„è¡¨å¾èƒ½åŠ›ï¼Œå¼ºè°ƒå¯¹åº”å…³ç³»åœ¨ä»»åŠ¡æ‰§è¡Œä¸­çš„é‡è¦æ€§ã€‚
3. ä½œè€…åˆæ­¥è°ƒæŸ¥äº†ç›¸å…³è¯æ®ï¼ŒæŒ‡å‡ºä»…æœ‰ç»“æ„å¯¹åº”å…³ç³»ä¸è¶³ä»¥å®ç°æœ‰æ•ˆçš„ç°å®å†…å®¹è¡¨å¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚GPT-4èƒ½å¤Ÿå¯¹å¤šç§æç¤ºç”Ÿæˆå¼•äººæ³¨ç›®çš„å“åº”ï¼Œä½†å…¶è¡¨å¾èƒ½åŠ›å°šä¸æ˜ç¡®ã€‚è®¸å¤šLLMsä¸å¤–éƒ¨ç°å®æ²¡æœ‰ç›´æ¥æ¥è§¦ï¼Œå…¶è¾“å…¥ã€è¾“å‡ºå’Œè®­ç»ƒæ•°æ®ä»…ç”±æ–‡æœ¬æ„æˆã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•æ ¹æ®ç»“æ„å¯¹åº”å…³ç³»çš„è¡¨å¾ç†è®ºå›ç­”LLMsæ˜¯å¦èƒ½å¤Ÿè¡¨å¾ç°å®å†…å®¹çš„é—®é¢˜ã€‚ä½œè€…è®¤ä¸ºï¼Œä»…ä»…å­˜åœ¨ç»“æ„å¯¹åº”å…³ç³»ä¸è¶³ä»¥æ”¯æ’‘å¯¹ç°å®å®ä½“çš„è¡¨å¾ï¼Œåªæœ‰å½“è¿™äº›å¯¹åº”å…³ç³»åœ¨æˆåŠŸä»»åŠ¡æ‰§è¡Œä¸­å‘æŒ¥é€‚å½“ä½œç”¨æ—¶ï¼Œæ‰èƒ½çœŸæ­£å®ç°å¯¹ç°å®å†…å®¹çš„è¡¨å¾ã€‚è¿™ä¸€è¿‡ç¨‹é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºLLMsçš„æ–‡æœ¬é™åˆ¶ä¼¼ä¹å¦¨ç¢äº†å®ƒä»¬å‚ä¸é€‚å½“ä»»åŠ¡çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆè¡¨å¾ç°å®ä¸–ç•Œå†…å®¹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼ŒLLMsçš„è¾“å…¥å’Œè¾“å‡ºä»…ä¸ºæ–‡æœ¬ï¼Œç¼ºä¹ä¸å¤–éƒ¨ç°å®çš„ç›´æ¥è”ç³»ï¼Œå¯¼è‡´å…¶è¡¨å¾èƒ½åŠ›çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¢è®¨ç»“æ„å¯¹åº”å…³ç³»åœ¨LLMsä¸ç°å®å®ä½“ä¹‹é—´çš„ä½œç”¨ï¼Œè®¤ä¸ºä»…æœ‰ç»“æ„å¯¹åº”å…³ç³»ä¸è¶³ä»¥æ”¯æ’‘è¡¨å¾ï¼Œå¿…é¡»åœ¨ä»»åŠ¡æ‰§è¡Œä¸­å‘æŒ¥ä½œç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹LLMsçš„ç»“æ„å¯¹åº”å…³ç³»è¿›è¡Œåˆ†æï¼Œè¯„ä¼°å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶æ¢è®¨å¦‚ä½•å…‹æœæ–‡æœ¬é™åˆ¶ä»¥å®ç°æœ‰æ•ˆè¡¨å¾ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ç»“æ„å¯¹åº”å…³ç³»çš„è¯†åˆ«ã€ä»»åŠ¡æ€§èƒ½çš„è¯„ä¼°ä»¥åŠå¯¹ç°å®å†…å®¹çš„è¡¨å¾åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ç»“æ„å¯¹åº”å…³ç³»åœ¨ä»»åŠ¡æ‰§è¡Œä¸­çš„ä½œç”¨æœºåˆ¶ï¼Œå¼ºè°ƒäº†å…¶åœ¨æˆåŠŸè¡¨å¾ä¸­çš„å¿…è¦æ€§ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œåè€…å¾€å¾€å¿½è§†äº†ä»»åŠ¡æ‰§è¡Œä¸­çš„åŠ¨æ€äº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹ç»“æ„å¯¹åº”å…³ç³»çš„ç³»ç»Ÿæ€§åˆ†æã€ä»»åŠ¡æ€§èƒ½çš„é‡åŒ–è¯„ä¼°ï¼Œä»¥åŠå¦‚ä½•åœ¨æ–‡æœ¬é™åˆ¶ä¸‹ä¼˜åŒ–LLMsçš„è¡¨å¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»“æ„å¯¹åº”å…³ç³»åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„æœ‰æ•ˆåˆ©ç”¨èƒ½å¤Ÿæ˜¾è‘—æå‡LLMsçš„è¡¨ç°ã€‚å°½ç®¡å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†ä½œè€…å¼ºè°ƒäº†ä»»åŠ¡æ‰§è¡Œä¸­ç»“æ„å¯¹åº”å…³ç³»çš„é‡è¦æ€§ï¼ŒæŒ‡å‡ºå…¶åœ¨è¡¨å¾ç°å®å†…å®¹æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£LLMsçš„è¡¨å¾èƒ½åŠ›ï¼Œå¯ä»¥æå‡å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚æœªæ¥å¯èƒ½å½±å“AIæ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒç­–ç•¥ï¼Œä¿ƒè¿›æ›´æ™ºèƒ½çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) such as GPT-4 produce compelling responses to a wide range of prompts. But their representational capacities are uncertain. Many LLMs have no direct contact with extra-linguistic reality: their inputs, outputs and training data consist solely of text, raising the questions (1) can LLMs represent anything and (2) if so, what? In this paper, I explore what it would take to answer these questions according to a structural-correspondence based account of representation, and make an initial survey of this evidence. I argue that the mere existence of structural correspondences between LLMs and worldly entities is insufficient to ground representation of those entities. However, if these structural correspondences play an appropriate role - they are exploited in a way that explains successful task performance - then they could ground real world contents. This requires overcoming a challenge: the text-boundedness of LLMs appears, on the face of it, to prevent them engaging in the right sorts of tasks.

