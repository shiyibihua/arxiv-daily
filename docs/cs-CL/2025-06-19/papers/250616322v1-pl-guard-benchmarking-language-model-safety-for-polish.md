---
layout: default
title: PL-Guard: Benchmarking Language Model Safety for Polish
---

# PL-Guard: Benchmarking Language Model Safety for Polish

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16322" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16322v1</a>
  <a href="https://arxiv.org/pdf/2506.16322.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16322v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16322v1', 'PL-Guard: Benchmarking Language Model Safety for Polish')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aleksandra KrasnodÄ™bska, Karolina Seweryn, Szymon Åukasik, Wojciech Kusa

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**å¤‡æ³¨**: Accepted to the 10th Workshop on Slavic Natural Language Processing

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPL-Guardä»¥è§£å†³æ³¢å…°è¯­è¯­è¨€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§è¯„ä¼°` `æ³¢å…°è¯­` `å¯¹æŠ—æ ·æœ¬` `æœºå™¨å­¦ä¹ ` `æ•°æ®é›†æ„å»º` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°å·¥å…·ä¸»è¦é›†ä¸­åœ¨é«˜èµ„æºè¯­è¨€ï¼Œå¯¼è‡´æ³¢å…°è¯­ç­‰è¯­è¨€çš„å®‰å…¨æ€§ç ”ç©¶ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ‰‹åŠ¨æ³¨é‡Šçš„æ³¢å…°è¯­å®‰å…¨åˆ†ç±»åŸºå‡†æ•°æ®é›†ï¼Œå¹¶åˆ›å»ºäº†å¯¹æŠ—æ‰°åŠ¨æ ·æœ¬ä»¥æµ‹è¯•æ¨¡å‹çš„é²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºHerBERTçš„åˆ†ç±»å™¨åœ¨å¤šç§æ¡ä»¶ä¸‹è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹æŠ—æ€§æµ‹è¯•ä¸­å–å¾—äº†æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡åœ¨ç¡®ä¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®‰å…¨æ€§æ–¹é¢çš„åŠªåŠ›ä¸æ–­å¢åŠ ï¼Œä½†ç°æœ‰çš„å®‰å…¨è¯„ä¼°å’Œå®¡æŸ¥å·¥å…·ä»ç„¶ä¸»è¦é›†ä¸­åœ¨è‹±è¯­å’Œå…¶ä»–é«˜èµ„æºè¯­è¨€ä¸Šï¼Œå¯¼è‡´å¤§å¤šæ•°å…¨çƒè¯­è¨€æœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªæ‰‹åŠ¨æ³¨é‡Šçš„æ³¢å…°è¯­è¯­è¨€æ¨¡å‹å®‰å…¨åˆ†ç±»åŸºå‡†æ•°æ®é›†ï¼Œå¹¶åˆ›å»ºäº†é’ˆå¯¹è¿™äº›æ ·æœ¬çš„å¯¹æŠ—æ‰°åŠ¨å˜ä½“ï¼Œä»¥æŒ‘æˆ˜æ¨¡å‹çš„é²æ£’æ€§ã€‚æˆ‘ä»¬è¿›è¡Œäº†ç³»åˆ—å®éªŒï¼Œè¯„ä¼°äº†ä¸åŒè§„æ¨¡å’Œæ¶æ„çš„LLMå’Œåˆ†ç±»å™¨æ¨¡å‹ï¼Œç»“æœè¡¨æ˜ï¼ŒåŸºäºHerBERTçš„åˆ†ç±»å™¨åœ¨å¯¹æŠ—æ¡ä»¶ä¸‹è¡¨ç°æœ€ä½³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ³¢å…°è¯­è¯­è¨€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­å­˜åœ¨åè§ï¼Œç¼ºä¹å¯¹æ³¢å…°è¯­çš„æ·±å…¥ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªæ‰‹åŠ¨æ³¨é‡Šçš„æ³¢å…°è¯­å®‰å…¨åˆ†ç±»åŸºå‡†æ•°æ®é›†ï¼Œå¹¶ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨æ ·æœ¬ï¼Œæ¥è¯„ä¼°å’Œæé«˜è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ‰‹åŠ¨æ ‡æ³¨æ•°æ®é›†ï¼Œç„¶åå¯¹ä¸åŒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæœ€åé€šè¿‡å®éªŒè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†é’ˆå¯¹æ³¢å…°è¯­çš„å®‰å…¨æ€§åŸºå‡†æ•°æ®é›†å’Œå¯¹æŠ—æ ·æœ¬ï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ï¼Œå¡«è¡¥äº†å¤šè¯­è¨€å®‰å…¨æ€§è¯„ä¼°çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†Llama-Guard-3-8Bã€åŸºäºHerBERTçš„åˆ†ç±»å™¨å’ŒPLLumç­‰æ¨¡å‹ï¼Œé‡‡ç”¨ä¸åŒç»„åˆçš„æ³¨é‡Šæ•°æ®è¿›è¡Œè®­ç»ƒï¼Œè¯„ä¼°æ—¶ä¸å…¬å¼€çš„é˜²æŠ¤æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºHerBERTçš„åˆ†ç±»å™¨åœ¨å¤šç§å¯¹æŠ—æ¡ä»¶ä¸‹è¡¨ç°æœ€ä½³ï¼Œæ•´ä½“æ€§èƒ½è¶…è¿‡å…¶ä»–æ¨¡å‹ï¼Œå°¤å…¶åœ¨å¯¹æŠ—æ ·æœ¬æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„é²æ£’æ€§æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æŸ¥ã€åœ¨çº¿å¹³å°çš„ç”¨æˆ·ç”Ÿæˆå†…å®¹ç›‘æ§ä»¥åŠä»»ä½•éœ€è¦ç¡®ä¿è¯­è¨€æ¨¡å‹è¾“å‡ºå®‰å…¨æ€§çš„åœºæ™¯ã€‚é€šè¿‡æå‡æ³¢å…°è¯­æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æœåŠ¡äºæ³¢å…°è¯­ç”¨æˆ·ï¼Œå‡å°‘æœ‰å®³å†…å®¹çš„ä¼ æ’­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite increasing efforts to ensure the safety of large language models (LLMs), most existing safety assessments and moderation tools remain heavily biased toward English and other high-resource languages, leaving majority of global languages underexamined. To address this gap, we introduce a manually annotated benchmark dataset for language model safety classification in Polish. We also create adversarially perturbed variants of these samples designed to challenge model robustness. We conduct a series of experiments to evaluate LLM-based and classifier-based models of varying sizes and architectures. Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B model. We train these models using different combinations of annotated data and evaluate their performance, comparing it against publicly available guard models. Results demonstrate that the HerBERT-based classifier achieves the highest overall performance, particularly under adversarial conditions.

