---
layout: default
title: Evaluating Large Language Models as Expert Annotators
---

# Evaluating Large Language Models as Expert Annotators

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07827" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07827v1</a>
  <a href="https://arxiv.org/pdf/2508.07827.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07827v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07827v1', 'Evaluating Large Language Models as Expert Annotators')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu-Min Tseng, Wei-Lin Chen, Chung-Chi Chen, Hsin-Hsi Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: Accepted to COLM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºä¸“å®¶æ ‡æ³¨è€…çš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®æ ‡æ³¨` `ä¸“å®¶çŸ¥è¯†` `å¤šä»£ç†è®¨è®º` `æ¨ç†æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `é‡‘è` `ç”Ÿç‰©åŒ»å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨éœ€è¦ä¸“å®¶çŸ¥è¯†çš„é¢†åŸŸä¸­ï¼ŒLLMsçš„æ ‡æ³¨æ•ˆæœå°šæœªå¾—åˆ°å……åˆ†éªŒè¯ï¼Œå­˜åœ¨æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§å¤šä»£ç†è®¨è®ºæ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»æ ‡æ³¨è€…çš„è®¨è®ºè¿‡ç¨‹ï¼Œä»¥æé«˜LLMsçš„æ ‡æ³¨å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•ä¸ªLLMsçš„æ¨ç†æŠ€æœ¯æ•ˆæœæœ‰é™ï¼Œä¸”å¤šä»£ç†ç¯å¢ƒä¸­æ¨¡å‹è¡Œä¸ºè¡¨ç°å‡ºç‰¹å®šç‰¹å¾ï¼Œæœªèƒ½æ˜¾è‘—æå‡æ ‡æ³¨æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬æ•°æ®æ ‡æ³¨æ˜¯ä¸€ä¸ªæˆæœ¬é«˜ã€è€—æ—¶é•¿ä¸”åŠ³åŠ¨å¯†é›†çš„è¿‡ç¨‹ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸€èˆ¬è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­æ˜¾ç¤ºå‡ºä½œä¸ºäººç±»æ ‡æ³¨è€…çš„æ½œåŠ›ï¼Œä½†åœ¨éœ€è¦ä¸“å®¶çŸ¥è¯†çš„é¢†åŸŸä¸­çš„æ ‡æ³¨ä»»åŠ¡æ•ˆæœä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡ç ”ç©¶äº†é¡¶å°–LLMsæ˜¯å¦èƒ½å¤Ÿä½œä¸ºäººç±»ä¸“å®¶æ ‡æ³¨è€…çš„ç›´æ¥æ›¿ä»£å“ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡‘èã€ç”Ÿç‰©åŒ»å­¦å’Œæ³•å¾‹ç­‰é«˜åº¦ä¸“ä¸šåŒ–é¢†åŸŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å¤šä»£ç†è®¨è®ºæ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»æ ‡æ³¨è€…çš„è®¨è®ºè¿‡ç¨‹ï¼ŒLLMsåœ¨æ­¤è¿‡ç¨‹ä¸­è€ƒè™‘å…¶ä»–ä»£ç†çš„æ ‡æ³¨å’Œç†ç”±ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå•ä¸ªLLMsçš„æ¨ç†æŠ€æœ¯åœ¨æ•°æ®æ ‡æ³¨ä¸­çš„æ•ˆæœæœ‰é™ï¼Œä¸”å¤šä»£ç†ç¯å¢ƒä¸­æ¨¡å‹è¡Œä¸ºè¡¨ç°å‡ºç‰¹å®šç‰¹å¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èã€ç”Ÿç‰©åŒ»å­¦å’Œæ³•å¾‹ç­‰ä¸“ä¸šé¢†åŸŸçš„æ ‡æ³¨æ•ˆæœï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†éªŒè¯å…¶åœ¨ä¸“å®¶çŸ¥è¯†é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºå¤šä»£ç†è®¨è®ºæ¡†æ¶ï¼Œæ¨¡æ‹Ÿäººç±»æ ‡æ³¨è€…çš„äº’åŠ¨ï¼Œä½¿LLMsåœ¨è€ƒè™‘ä»–äººæ ‡æ³¨å’Œç†ç”±çš„åŸºç¡€ä¸Šè¿›è¡Œæœ€ç»ˆæ ‡æ³¨ï¼Œä»¥æœŸæé«˜æ ‡æ³¨è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªLLMsä½œä¸ºä»£ç†ï¼Œå‚ä¸è®¨è®ºå¹¶è¿›è¡Œæ ‡æ³¨ã€‚æ¯ä¸ªä»£ç†åœ¨æ ‡æ³¨å‰éœ€è€ƒè™‘å…¶ä»–ä»£ç†çš„æ„è§å’Œç†ç”±ï¼Œå½¢æˆé›†ä½“å†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„å¤šä»£ç†è®¨è®ºæ¡†æ¶æ˜¯ä¸ç°æœ‰å•ä¸€LLMæ ‡æ³¨æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ï¼Œå¼ºè°ƒäº†æ¨¡å‹é—´çš„äº’åŠ¨å’Œè®¨è®ºå¯¹æ ‡æ³¨ç»“æœçš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ä½¿ç”¨äº†æ¨ç†æ¨¡å‹ï¼ˆå¦‚o3-miniï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œè®¾ç½®äº†ä¸åŒçš„æ¨ç†æ—¶é—´æŠ€æœ¯ï¼ˆå¦‚é“¾å¼æ€ç»´å’Œè‡ªä¸€è‡´æ€§ï¼‰ï¼Œä»¥è¯„ä¼°å…¶å¯¹æ ‡æ³¨æ•ˆæœçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨ç†æ¨¡å‹åœ¨å¤§å¤šæ•°è®¾ç½®ä¸‹æœªèƒ½æ˜¾è‘—æå‡æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•ä¸ªLLMsåœ¨æ¨ç†æŠ€æœ¯çš„åº”ç”¨ä¸‹ä»…æœ‰è¾¹é™…æˆ–è´Ÿå‘çš„æ€§èƒ½æå‡ï¼Œä¸”å¤šä»£ç†è®¨è®ºç¯å¢ƒä¸­ï¼ŒæŸäº›æ¨¡å‹ï¼ˆå¦‚Claude 3.7 Sonnetï¼‰åœ¨é¢å¯¹å…¶ä»–ä»£ç†çš„æ­£ç¡®æ ‡æ³¨æ—¶ï¼Œä»ç„¶ä¿æŒåˆå§‹æ ‡æ³¨ä¸å˜ï¼Œè¡¨æ˜æ¨¡å‹çš„å›ºæ‰§æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èåˆ†æã€ç”Ÿç‰©åŒ»å­¦ç ”ç©¶å’Œæ³•å¾‹æ–‡ä¹¦å¤„ç†ç­‰ä¸“ä¸šé¢†åŸŸï¼Œèƒ½å¤Ÿä¸ºæ•°æ®æ ‡æ³¨æä¾›æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œé™ä½äººå·¥æˆæœ¬ï¼Œæé«˜æ ‡æ³¨è´¨é‡ã€‚æœªæ¥ï¼Œéšç€LLMsæŠ€æœ¯çš„è¿›æ­¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šåœ¨æ›´å¤šä¸“ä¸šé¢†åŸŸå¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Textual data annotation, the process of labeling or tagging text with relevant information, is typically costly, time-consuming, and labor-intensive. While large language models (LLMs) have demonstrated their potential as direct alternatives to human annotators for general domains natural language processing (NLP) tasks, their effectiveness on annotation tasks in domains requiring expert knowledge remains underexplored. In this paper, we investigate: whether top-performing LLMs, which might be perceived as having expert-level proficiency in academic and professional benchmarks, can serve as direct alternatives to human expert annotators? To this end, we evaluate both individual LLMs and multi-agent approaches across three highly specialized domains: finance, biomedicine, and law. Specifically, we propose a multi-agent discussion framework to simulate a group of human annotators, where LLMs are tasked to engage in discussions by considering others' annotations and justifications before finalizing their labels. Additionally, we incorporate reasoning models (e.g., o3-mini) to enable a more comprehensive comparison. Our empirical results reveal that: (1) Individual LLMs equipped with inference-time techniques (e.g., chain-of-thought (CoT), self-consistency) show only marginal or even negative performance gains, contrary to prior literature suggesting their broad effectiveness. (2) Overall, reasoning models do not demonstrate statistically significant improvements over non-reasoning models in most settings. This suggests that extended long CoT provides relatively limited benefits for data annotation in specialized domains. (3) Certain model behaviors emerge in the multi-agent discussion environment. For instance, Claude 3.7 Sonnet with thinking rarely changes its initial annotations, even when other agents provide correct annotations or valid reasoning.

