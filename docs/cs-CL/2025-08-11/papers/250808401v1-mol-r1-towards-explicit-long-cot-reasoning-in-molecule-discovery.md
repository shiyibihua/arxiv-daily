---
layout: default
title: Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery
---

# Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08401" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.08401v1</a>
  <a href="https://arxiv.org/pdf/2508.08401.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08401v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08401v1', 'Mol-R1: Towards Explicit Long-CoT Reasoning in Molecule Discovery')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jiatong Li, Weida Wang, Qinggang Zhang, Junxian Li, Di Zhang, Changmeng Zheng, Shufei Zhang, Xiaoyong Wei, Qing Li

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-11

**Â§áÊ≥®**: 20 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Mol-R1‰ª•Ëß£ÂÜ≥ÂàÜÂ≠êÂèëÁé∞‰∏≠ÁöÑÈïøÈìæÊé®ÁêÜÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøÈìæÊé®ÁêÜ` `ÂàÜÂ≠êÂèëÁé∞` `ÊòæÂºèÊé®ÁêÜ` `Ëí∏È¶èËÆ≠ÁªÉ` `Âº∫ÂåñÂ≠¶‰π†` `ÂèØËß£ÈáäÊÄß` `Êï∞ÊçÆÈõÜÊûÑÂª∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÈïøÈìæÊé®ÁêÜÊ®°ÂûãÂú®ÂàÜÂ≠êÂèëÁé∞È¢ÜÂüüË°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÁî±‰∫éÂØπÈ¢ÜÂüüÁü•ËØÜÁöÑÁêÜËß£‰∏çË∂≥ÂíåÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Mol-R1Ê°ÜÊû∂ÔºåÈÄöËøáÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÂíåÂàÜÂ≠êËø≠‰ª£ÈÄÇÂ∫îÁ≠ñÁï•ÔºåÊèêÂçáR1Á±ªÊé®ÁêÜÊ®°ÂûãÁöÑÊé®ÁêÜÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMol-R1Âú®ÊñáÊú¨Âü∫Á°ÄÂàÜÂ≠êÊé®ÁêÜÁîüÊàê‰ªªÂä°‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÔºåÂ∞§ÂÖ∂ÊòØÊòæÂºèÈïøÈìæÊé®ÁêÜÊ®°ÂûãÂ¶ÇDeepSeek-R1ÂíåQWQÔºåÂ±ïÁé∞‰∫ÜÂº∫Â§ßÁöÑÊé®ÁêÜËÉΩÂäõÔºåÂú®Â∏∏ËØÜÊé®ÁêÜÂíåÊï∞Â≠¶Êé®ÁêÜ‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÊàêÁª©„ÄÇÁÑ∂ËÄåÔºåÂú®Áü•ËØÜÂØÜÈõÜÂûãÈ¢ÜÂüüÂ¶ÇÂàÜÂ≠êÂèëÁé∞‰∏≠ÔºåËøô‰∫õÊ®°ÂûãÁöÑËÉΩÂäõÂíåÊïàÁéáÂèóÂà∞ÈôêÂà∂„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜMol-R1Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÈ´òR1Á±ªÊòæÂºèÈïøÈìæÊé®ÁêÜLLMsÂú®ÊñáÊú¨Âü∫Á°ÄÂàÜÂ≠êÁîüÊàê‰∏≠ÁöÑÂèØËß£ÈáäÊÄßÂíåÊé®ÁêÜÊÄßËÉΩ„ÄÇÊàë‰ª¨È¶ñÂÖàÈÄöËøáÂÖàÂâçË∞ÉËäÇÂíå‰∏ä‰∏ãÊñáËí∏È¶èÔºàPRIDÔºâÊûÑÂª∫È´òË¥®ÈáèÊé®ÁêÜÊï∞ÊçÆÈõÜÔºåÊé•ÁùÄÂºïÂÖ•ÂàÜÂ≠êËø≠‰ª£ÈÄÇÂ∫îÔºàMoIAÔºâËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁªìÂêàÁõëÁù£ÂæÆË∞É‰∏éÂº∫ÂåñÁ≠ñÁï•‰ºòÂåñÔºåÊúÄÁªàÂú®ÊñáÊú¨Âü∫Á°ÄÂàÜÂ≠êÊé®ÁêÜÁîüÊàê‰ªªÂä°‰∏≠Â±ïÁé∞Âá∫‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÈïøÈìæÊé®ÁêÜÊ®°ÂûãÂú®ÂàÜÂ≠êÂèëÁé∞È¢ÜÂüüÁöÑËÉΩÂäõ‰∏çË∂≥ÂíåÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇÁî±‰∫éÂàÜÂ≠êÊï∞ÊçÆÁöÑÂ§çÊùÇÊÄßÂíåÈ´òË¥®Èáè‰∏ìÂÆ∂Ê≥®ÈáäÁöÑÁ®ÄÁº∫ÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂ∫îÁî®‰∫éÊ≠§È¢ÜÂüü„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMol-R1Ê°ÜÊû∂ÈÄöËøáÊûÑÂª∫È´òË¥®ÈáèÁöÑÊé®ÁêÜÊï∞ÊçÆÈõÜÂíåÂºïÂÖ•ÂàÜÂ≠êËø≠‰ª£ÈÄÇÂ∫îËÆ≠ÁªÉÁ≠ñÁï•ÔºåÊó®Âú®ÊèêÈ´òÊé®ÁêÜÊ®°ÂûãÂú®ÂàÜÂ≠êÁîüÊàê‰ªªÂä°‰∏≠ÁöÑË°®Áé∞„ÄÇËØ•ËÆæËÆ°ËÄÉËôë‰∫ÜÈ¢ÜÂüüÁü•ËØÜÁöÑÂ§çÊùÇÊÄßÔºåÂº∫Ë∞É‰∫ÜÊé®ÁêÜËøáÁ®ãÁöÑÂèØËß£ÈáäÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMol-R1ÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÊòØÈÄöËøáPRIDÁîüÊàêÁöÑÈ´òË¥®ÈáèÊé®ÁêÜÊï∞ÊçÆÈõÜÔºåÂÖ∂Ê¨°ÊòØMoIAËÆ≠ÁªÉÁ≠ñÁï•ÔºåÂêéËÄÖÁªìÂêà‰∫ÜÁõëÁù£ÂæÆË∞ÉÂíåÂº∫ÂåñÁ≠ñÁï•‰ºòÂåñÔºåÂΩ¢Êàê‰∏Ä‰∏™Ëø≠‰ª£ËÆ≠ÁªÉÊµÅÁ®ã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMol-R1ÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜPRIDÂíåMoIAÁ≠ñÁï•Ôºå‰ΩøÂæóÊ®°ÂûãÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®È¢ÜÂüüÁü•ËØÜÔºå‰ªéËÄåÊòæËëóÊèêÂçáÊé®ÁêÜÊÄßËÉΩ„ÄÇËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÂçï‰∏ÄËÆ≠ÁªÉÁ≠ñÁï•ÂΩ¢Êàê‰∫ÜÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåMol-R1ÈááÁî®‰∫ÜÈíàÂØπÂàÜÂ≠êÊï∞ÊçÆÁöÑÁâπÂÆöÊçüÂ§±ÂáΩÊï∞ÔºåÂπ∂Âú®ÁΩëÁªúÁªìÊûÑ‰∏äËøõË°å‰∫Ü‰ºòÂåñÔºå‰ª•ÈÄÇÂ∫îÂàÜÂ≠êÁîüÊàê‰ªªÂä°ÁöÑÈúÄÊ±Ç„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÊñáÊú¨Âü∫Á°ÄÂàÜÂ≠êÊé®ÁêÜÁîüÊàê‰ªªÂä°‰∏≠ÔºåMol-R1Â±ïÁ§∫‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÁé∞ÊúâÂü∫Á∫øÊ®°ÂûãÔºåÂÖ∂Êé®ÁêÜÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜXX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÂæÖË°•ÂÖÖÔºâÔºåÊúâÊïàËØÅÊòé‰∫ÜÂÖ∂Âú®Áü•ËØÜÂØÜÈõÜÂûãÈ¢ÜÂüüÁöÑÂ∫îÁî®‰ª∑ÂÄº„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Mol-R1Ê°ÜÊû∂Âú®ÂàÜÂ≠êÂèëÁé∞È¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåËÉΩÂ§üÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÊõ¥È´òÊïàÂú∞ÁîüÊàêÂíåÂàÜÊûêÂàÜÂ≠êÁªìÊûÑÔºåÊé®Âä®ËçØÁâ©ÂèëÁé∞„ÄÅÊùêÊñôÁßëÂ≠¶Á≠âÈ¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇÂÖ∂ÊèêÂçáÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂèØËß£ÈáäÊÄßÂ∞Ü‰∏∫ÁßëÂ≠¶Á†îÁ©∂Êèê‰æõÊõ¥Âº∫ÁöÑÊîØÊåÅÔºåÊú™Êù•ÂèØËÉΩÂΩ±ÂìçÂåñÂ≠¶„ÄÅËçØÁêÜÂ≠¶Á≠âÂ§ö‰∏™Â≠¶ÁßëÁöÑÁ†îÁ©∂ÊñπÂêë„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models (LLMs), especially Explicit Long Chain-of-Thought (CoT) reasoning models like DeepSeek-R1 and QWQ, have demonstrated powerful reasoning capabilities, achieving impressive performance in commonsense reasoning and mathematical inference. Despite their effectiveness, Long-CoT reasoning models are often criticized for their limited ability and low efficiency in knowledge-intensive domains such as molecule discovery. Success in this field requires a precise understanding of domain knowledge, including molecular structures and chemical principles, which is challenging due to the inherent complexity of molecular data and the scarcity of high-quality expert annotations. To bridge this gap, we introduce Mol-R1, a novel framework designed to improve explainability and reasoning performance of R1-like Explicit Long-CoT reasoning LLMs in text-based molecule generation. Our approach begins with a high-quality reasoning dataset curated through Prior Regulation via In-context Distillation (PRID), a dedicated distillation strategy to effectively generate paired reasoning traces guided by prior regulations. Building upon this, we introduce MoIA, Molecular Iterative Adaptation, a sophisticated training strategy that iteratively combines Supervised Fine-tuning (SFT) with Reinforced Policy Optimization (RPO), tailored to boost the reasoning performance of R1-like reasoning models for molecule discovery. Finally, we examine the performance of Mol-R1 in the text-based molecule reasoning generation task, showing superior performance against existing baselines.

