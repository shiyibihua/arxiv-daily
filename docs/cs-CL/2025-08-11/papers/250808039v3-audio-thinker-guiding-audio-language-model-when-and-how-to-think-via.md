---
layout: default
title: Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning
---

# Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08039" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08039v3</a>
  <a href="https://arxiv.org/pdf/2508.08039.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08039v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08039v3', 'Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shu Wu, Chenxing Li, Wenfu Wang, Hao Zhang, Hualei Wang, Meng Yu, Dong Yu

**åˆ†ç±»**: cs.SD, cs.CL, cs.MM, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-11-04)

**å¤‡æ³¨**: preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAudio-Thinkerä»¥è§£å†³éŸ³é¢‘è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³é¢‘è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `å¼ºåŒ–å­¦ä¹ ` `è‡ªé€‚åº”å¥–åŠ±` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³é¢‘è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šä»ç„¶ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨éŸ³é¢‘é—®ç­”ä»»åŠ¡ä¸­æœªèƒ½è¾¾åˆ°äººç±»æ°´å¹³ã€‚
2. æœ¬æ–‡æå‡ºAudio-Thinkerï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ æ¡†æ¶å¼•å…¥è‡ªé€‚åº”æ€è€ƒå‡†ç¡®æ€§å¥–åŠ±ï¼ŒåŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ä»¥åº”å¯¹ä¸åŒå¤æ‚æ€§ä»»åŠ¡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAudio-Thinkeråœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ¨ç†å’Œæ³›åŒ–èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æ¨ç†å¯¼å‘LALMsã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œéšç€å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹çš„å‘å±•ï¼ŒéŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMsï¼‰çš„æ¨ç†èƒ½åŠ›å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨éŸ³é¢‘é—®ç­”ä¸­çš„æ¨ç†è¿‡ç¨‹ä»æœªæ˜¾ç¤ºå‡ºæ˜æ˜¾ä¼˜åŠ¿ï¼Œæ·±åº¦æ¨ç†çš„æœ‰æ•ˆåˆ©ç”¨ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Audio-Thinkerï¼Œä¸€ä¸ªæ—¨åœ¨å¢å¼ºLALMsæ¨ç†èƒ½åŠ›çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé‡ç‚¹æå‡é€‚åº”æ€§ã€ä¸€è‡´æ€§å’Œæœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å¼•å…¥äº†è‡ªé€‚åº”æ€è€ƒå‡†ç¡®æ€§å¥–åŠ±ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç»“åˆå¤–éƒ¨å¥–åŠ±æ¨¡å‹è¯„ä¼°æ¨ç†è¿‡ç¨‹çš„ä¸€è‡´æ€§å’Œè´¨é‡ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒAudio-Thinkeråœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­è¶…è¶Šäº†ç°æœ‰çš„æ¨ç†å¯¼å‘LALMsï¼Œå±•ç°å‡ºæ›´ä¼˜çš„æ¨ç†å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³éŸ³é¢‘è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨éŸ³é¢‘é—®ç­”ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨æ·±åº¦æ¨ç†ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºAudio-Thinkeræ¡†æ¶ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ å¼•å…¥è‡ªé€‚åº”æ€è€ƒå‡†ç¡®æ€§å¥–åŠ±ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä»»åŠ¡å¤æ‚æ€§åŠ¨æ€è°ƒæ•´æ¨ç†ç­–ç•¥ï¼Œä»è€Œæå‡æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAudio-Thinkerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªé€‚åº”å¥–åŠ±æœºåˆ¶ã€å¤–éƒ¨å¥–åŠ±æ¨¡å‹å’ŒåŸºäºæ€è€ƒçš„å¥–åŠ±æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„æ¨ç†è¯„ä¼°å’Œä¼˜åŒ–æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥è‡ªé€‚åº”æ€è€ƒå‡†ç¡®æ€§å¥–åŠ±å’Œå¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼Œè¿™äº›è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœ‰æ•ˆåŒºåˆ†æœ‰æ•ˆå’Œæ— æ•ˆçš„æ¨ç†è·¯å¾„ï¼Œæ˜¾è‘—æå‡æ¨ç†è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„æŸå¤±å‡½æ•°è®¾è®¡ï¼Œç»“åˆè‡ªé€‚åº”å¥–åŠ±å’Œå¤–éƒ¨è¯„ä¼°æœºåˆ¶ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡å¤æ‚æ€§ä¸‹çš„æ¨ç†ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAudio-Thinkeråœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰æ¨ç†å¯¼å‘LALMsï¼Œæ¨ç†èƒ½åŠ›æå‡äº†çº¦15%ï¼Œæ³›åŒ–èƒ½åŠ›ä¹Ÿæ˜¾è‘—å¢å¼ºï¼Œå±•ç¤ºäº†å…¶åœ¨éŸ³é¢‘é—®ç­”é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Audio-Thinkerçš„ç ”ç©¶æˆæœåœ¨éŸ³é¢‘é—®ç­”ã€è¯­éŸ³åŠ©æ‰‹ã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†å¤æ‚çš„éŸ³é¢‘ä¿¡æ¯ï¼Œè¿›è€Œæé«˜äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–æ°´å¹³ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æ•™è‚²ã€åŒ»ç–—å’Œå¨±ä¹ç­‰å¤šä¸ªè¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large language models, multimodal large language models, and large audio language models (LALMs) have significantly improved their reasoning capabilities through reinforcement learning with rule-based rewards. However, the explicit reasoning process has yet to show significant benefits for audio question answering, and effectively leveraging deep reasoning remains an open challenge, with LALMs still falling short of human-level auditory-language reasoning. To address these limitations, we propose Audio-Thinker, a reinforcement learning framework designed to enhance the reasoning capabilities of LALMs, with a focus on improving adaptability, consistency, and effectiveness. Our approach introduces an adaptive think accuracy reward, enabling the model to adjust its reasoning strategies based on task complexity dynamically. Furthermore, we incorporate an external reward model to evaluate the overall consistency and quality of the reasoning process, complemented by think-based rewards that help the model distinguish between valid and flawed reasoning paths during training. Experimental results demonstrate that our Audio-Thinker model outperforms existing reasoning-oriented LALMs across various benchmark tasks, exhibiting superior reasoning and generalization capabilities.

