---
layout: default
title: Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression
---

# Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08509" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08509v1</a>
  <a href="https://arxiv.org/pdf/2508.08509.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08509v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08509v1', 'Steerable Pluralism: Pluralistic Alignment via Few-Shot Comparative Regression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jadie Adams, Brian Hu, Emily Veenhuis, David Joy, Bharadwaj Ravichandran, Aaron Bray, Anthony Hoogs, Arslan Basharat

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: AIES '25: Proceedings of the 2025 AAAI/ACM Conference on AI, Ethics, and Society

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯è°ƒèŠ‚çš„å¤šå…ƒå¯¹é½æ¨¡å‹ä»¥è§£å†³ç”¨æˆ·åå¥½æ•æ‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šå…ƒå¯¹é½` `å°‘é‡æ ·æœ¬å­¦ä¹ ` `æ¯”è¾ƒå›å½’` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ä¼¦ç†AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹é½æ–¹æ³•ä¸»è¦ä¾èµ–äºæ ‡é‡å¥–åŠ±ï¼Œæ— æ³•å…¨é¢åæ˜ ç”¨æˆ·çš„å¤šæ ·åŒ–åå¥½ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå°‘é‡æ ·æœ¬æ¯”è¾ƒå›å½’çš„å¯è°ƒèŠ‚å¤šå…ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„ä¸ªä½“åå¥½è¿›è¡Œé€‚åº”ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºçº¿å’Œæœ€å…ˆè¿›çš„æŠ€æœ¯ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå…·æœ‰è¾ƒå¼ºçš„å¯è§£é‡Šæ€§å’Œé€‚ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç›®å‰ä¸»è¦é€šè¿‡äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰è¿›è¡Œå¯¹é½ï¼Œä½†è¿™äº›æ–¹æ³•ä»…èƒ½åæ˜ ç”¨æˆ·åå¥½çš„å¹³å‡å€¼ã€‚å¤šå…ƒå¯¹é½æ—¨åœ¨æ•æ‰ç”¨æˆ·åœ¨å¤šä¸ªå±æ€§ä¸Šçš„å¤šæ ·åŒ–åå¥½ï¼Œè¶…è¶Šå•ä¸€çš„æœ‰ç”¨æ€§å’Œæ— å®³æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå°‘é‡æ ·æœ¬æ¯”è¾ƒå›å½’çš„å¯è°ƒèŠ‚å¤šå…ƒæ¨¡å‹ï¼Œèƒ½å¤Ÿé€‚åº”ä¸ªä½“ç”¨æˆ·çš„åå¥½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ å’Œæ¨ç†ï¼ŒåŸºäºä¸€ç»„ç»†ç²’åº¦å±æ€§æ¥æ¯”è¾ƒå“åº”é€‰é¡¹å¹¶åšå‡ºå¯¹é½é€‰æ‹©ã€‚æˆ‘ä»¬è¿˜é€šè¿‡æ”¹ç¼–é“å¾·å®Œæ•´æ€§è¯­æ–™åº“ï¼ˆMICï¼‰å’ŒHelpSteer2æ•°æ®é›†ï¼Œæå‡ºäº†ä¸¤ä¸ªæ–°çš„å¯è°ƒèŠ‚å¤šå…ƒåŸºå‡†ï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•åœ¨ä»·å€¼å¯¹é½å†³ç­–å’Œå¥–åŠ±å»ºæ¨¡ä¸­çš„é€‚ç”¨æ€§ã€‚æˆ‘ä»¬çš„å°‘é‡æ ·æœ¬æ¯”è¾ƒå›å½’æ–¹æ³•å…·æœ‰å¯è§£é‡Šæ€§ï¼Œå¹¶ä¸ä¸åŒå±æ€§å’ŒLLMså…¼å®¹ï¼ŒåŒæ—¶åœ¨å¤šä¸ªåŸºçº¿å’Œæœ€å…ˆè¿›çš„æ–¹æ³•ä¸­è¡¨ç°ä¼˜è¶Šã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºå¤šå…ƒå¯¹é½æä¾›äº†æ–°çš„è§è§£å’Œç ”ç©¶æ–¹å‘ï¼Œæ¨åŠ¨äº†ä¼¦ç†AIçš„è¿›æ­¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½æ–¹æ³•æ— æ³•æœ‰æ•ˆæ•æ‰ç”¨æˆ·å¤šæ ·åŒ–åå¥½çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºæ ‡é‡å¥–åŠ±ï¼Œå¯¼è‡´å¯¹ç”¨æˆ·åå¥½çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åŸºäºå°‘é‡æ ·æœ¬æ¯”è¾ƒå›å½’çš„å¯è°ƒèŠ‚å¤šå…ƒæ¨¡å‹ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ å’Œæ¨ç†ï¼Œç»“åˆç»†ç²’åº¦å±æ€§è¿›è¡Œå“åº”é€‰é¡¹çš„æ¯”è¾ƒï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–çš„å¯¹é½é€‰æ‹©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€ä¸Šä¸‹æ–‡å­¦ä¹ æ¨¡å—ã€æ¯”è¾ƒå›å½’æ¨¡å—å’Œè¾“å‡ºå†³ç­–æ¨¡å—ã€‚æ•°æ®è¾“å…¥é˜¶æ®µæ”¶é›†ç”¨æˆ·åé¦ˆï¼Œä¸Šä¸‹æ–‡å­¦ä¹ æ¨¡å—æå–ç»†ç²’åº¦å±æ€§ï¼Œæ¯”è¾ƒå›å½’æ¨¡å—è¿›è¡Œå“åº”é€‰é¡¹çš„è¯„ä¼°ï¼Œæœ€åè¾“å‡ºå¯¹é½çš„é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å°‘é‡æ ·æœ¬æ¯”è¾ƒå›å½’çš„æ–¹æ³•ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æœ‰é™çš„æ ·æœ¬ä¸‹è¿›è¡Œæœ‰æ•ˆçš„å­¦ä¹ å’Œé€‚åº”ï¼Œæ˜¾è‘—æå‡äº†å¯¹ç”¨æˆ·å¤šæ ·åŒ–åå¥½çš„æ•æ‰èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„ï¼Œç»“åˆäº†è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»¥å¢å¼ºä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼ŒåŒæ—¶ä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¤šå…ƒå¯¹é½æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªåŸºçº¿å’Œæœ€å…ˆè¿›çš„æŠ€æœ¯ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚é€šè¿‡æ–°æå‡ºçš„å¯è°ƒèŠ‚å¤šå…ƒåŸºå‡†ï¼ŒéªŒè¯äº†æ¨¡å‹åœ¨ä»·å€¼å¯¹é½å†³ç­–å’Œå¥–åŠ±å»ºæ¨¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹å’Œä¼¦ç†AIå†³ç­–æ”¯æŒç­‰ã€‚é€šè¿‡æ›´å¥½åœ°æ•æ‰ç”¨æˆ·çš„å¤šæ ·åŒ–åå¥½ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›æ›´å…¬å¹³å’Œä»£è¡¨æ€§çš„AIåº”ç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are currently aligned using techniques such as reinforcement learning from human feedback (RLHF). However, these methods use scalar rewards that can only reflect user preferences on average. Pluralistic alignment instead seeks to capture diverse user preferences across a set of attributes, moving beyond just helpfulness and harmlessness. Toward this end, we propose a steerable pluralistic model based on few-shot comparative regression that can adapt to individual user preferences. Our approach leverages in-context learning and reasoning, grounded in a set of fine-grained attributes, to compare response options and make aligned choices. To evaluate our algorithm, we also propose two new steerable pluralistic benchmarks by adapting the Moral Integrity Corpus (MIC) and the HelpSteer2 datasets, demonstrating the applicability of our approach to value-aligned decision-making and reward modeling, respectively. Our few-shot comparative regression approach is interpretable and compatible with different attributes and LLMs, while outperforming multiple baseline and state-of-the-art methods. Our work provides new insights and research directions in pluralistic alignment, enabling a more fair and representative use of LLMs and advancing the state-of-the-art in ethical AI.

