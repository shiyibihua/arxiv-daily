---
layout: default
title: Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models
---

# Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.13722" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.13722v1</a>
  <a href="https://arxiv.org/pdf/2511.13722.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.13722v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2511.13722v1', 'Signature vs. Substance: Evaluating the Balance of Adversarial Resistance and Linguistic Quality in Watermarking Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: William Guo, Adaku Uchendu, Ana Smith

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°æ°´å°æŠ€æœ¯åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¯¹æŠ—æŠµæŠ—åŠ›ä¸è¯­è¨€è´¨é‡å¹³è¡¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ°´å°æŠ€æœ¯` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ”»å‡»` `æ–‡æœ¬è´¨é‡` `è¯­è¨€æŒ‡æ ‡` `é²æ£’æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ°´å°æŠ€æœ¯åœ¨ä¿æŒæ–‡æœ¬è´¨é‡å’ŒæŠµæŠ—å¯¹æŠ—æ”»å‡»æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå½±å“äº†å…¶åœ¨LLMä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡æ¯”è¾ƒé‡Šä¹‰å’Œå›è¯‘æ”»å‡»ï¼Œè¯„ä¼°æ°´å°æŠ€æœ¯çš„é²æ£’æ€§åŠå…¶å¯¹æ–‡æœ¬è´¨é‡çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ°´å°æŠ€æœ¯åœ¨ä¿æŒè¯­ä¹‰çš„åŒæ—¶ï¼Œå†™ä½œé£æ ¼åç¦»æ˜æ˜¾ï¼Œå¹¶ä¸”å¯¹å›è¯‘æ”»å‡»ç‰¹åˆ«æ•æ„Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆæ–‡æœ¬çš„æ½œåœ¨å±å®³ï¼Œç ”ç©¶è€…æå‡ºäº†æ°´å°æŠ€æœ¯ï¼Œå³åœ¨æ–‡æœ¬ä¸­åµŒå…¥å¯æ£€æµ‹ä¿¡å·çš„è¿‡ç¨‹ã€‚å°½ç®¡æ°´å°å¯ä»¥å‡†ç¡®æ£€æµ‹LLMç”Ÿæˆçš„æ–‡æœ¬ï¼Œä½†è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›æŠ€æœ¯å¾€å¾€ä¼šè´Ÿé¢å½±å“ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ï¼Œå¹¶ä¸”å¯¹æŠ—æ”»å‡»å¯èƒ½ä¼šå‰¥ç¦»æ°´å°ä¿¡å·ï¼Œä½¿æ–‡æœ¬é€ƒé¿æ£€æµ‹ã€‚è¿™äº›å‘ç°é˜»ç¢äº†æ°´å°æŠ€æœ¯åœ¨LLMåˆ›ä½œè€…ä¸­çš„å¹¿æ³›é‡‡ç”¨ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è¯„ä¼°äº†å‡ ç§æ°´å°æŠ€æœ¯å¯¹æŠ—æ”»å‡»çš„é²æ£’æ€§ï¼Œæ¯”è¾ƒäº†é‡Šä¹‰å’Œå›è¯‘æ”»å‡»çš„æ•ˆæœï¼Œå¹¶ä½¿ç”¨è¯­è¨€æŒ‡æ ‡æ¥æ•æ‰æ–‡æœ¬çš„è´¨é‡å’Œå†™ä½œé£æ ¼ã€‚ç»“æœè¡¨æ˜ï¼Œè¿™äº›æ°´å°æŠ€æœ¯åœ¨ä¿æŒè¯­ä¹‰çš„åŒæ—¶ï¼Œåç¦»äº†æœªæ°´å°æ–‡æœ¬çš„å†™ä½œé£æ ¼ï¼Œå¹¶ä¸”å¯¹æŠ—æ”»å‡»å°¤å…¶æ˜¯å›è¯‘æ”»å‡»çš„è„†å¼±æ€§è¾ƒé«˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ°´å°æŠ€æœ¯åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åº”ç”¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯å…¶å¯¹æ–‡æœ¬è´¨é‡å’Œå¯¹æŠ—æ”»å‡»çš„è„†å¼±æ€§ã€‚ç°æœ‰æ–¹æ³•åœ¨åµŒå…¥æ°´å°æ—¶ï¼Œå¾€å¾€ä¼šå¯¼è‡´ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ä¸‹é™ï¼Œä¸”å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¯”è¾ƒä¸åŒçš„æ”»å‡»æ–¹å¼ï¼ˆé‡Šä¹‰ä¸å›è¯‘ï¼‰æ¥è¯„ä¼°æ°´å°æŠ€æœ¯çš„é²æ£’æ€§ï¼Œæ—¨åœ¨æ‰¾åˆ°ä¸€ç§å¹³è¡¡æ°´å°æ•ˆæœä¸æ–‡æœ¬è´¨é‡çš„æ–¹æ³•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å®éªŒè®¾è®¡ï¼Œé¦–å…ˆç”Ÿæˆå¸¦æ°´å°çš„æ–‡æœ¬ï¼Œç„¶åæ–½åŠ ä¸åŒç±»å‹çš„å¯¹æŠ—æ”»å‡»ï¼Œæœ€åä½¿ç”¨è¯­è¨€æŒ‡æ ‡è¯„ä¼°æ–‡æœ¬çš„è´¨é‡å’Œå†™ä½œé£æ ¼ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ°´å°åµŒå…¥ã€æ”»å‡»å®æ–½å’Œè´¨é‡è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†ä¸åŒå¯¹æŠ—æ”»å‡»å¯¹æ°´å°æŠ€æœ¯çš„å½±å“ï¼Œå°¤å…¶æ˜¯å›è¯‘æ”»å‡»çš„è„†å¼±æ€§ï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§è¯­è¨€æŒ‡æ ‡æ¥è¯„ä¼°æ–‡æœ¬è´¨é‡ï¼Œé‡‡ç”¨äº†æ ‡å‡†çš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ°´å°åµŒå…¥è¿‡ç¨‹ï¼Œç¡®ä¿åœ¨ä¿æŒè¯­ä¹‰çš„åŒæ—¶å°½é‡å‡å°‘å¯¹å†™ä½œé£æ ¼çš„å½±å“ã€‚å®éªŒè¿˜è€ƒè™‘äº†ä¸åŒè¯­è¨€å¯¹å›è¯‘æ•ˆæœçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€è¯„ä¼°çš„æ°´å°æŠ€æœ¯åœ¨ä¿æŒæ–‡æœ¬è¯­ä¹‰æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å†™ä½œé£æ ¼ä¸Šåç¦»æ˜æ˜¾ï¼Œå°¤å…¶æ˜¯åœ¨å›è¯‘æ”»å‡»ä¸‹è¡¨ç°å‡ºè¾ƒé«˜çš„è„†å¼±æ€§ã€‚è¿™äº›å‘ç°ä¸ºæ°´å°æŠ€æœ¯çš„æ”¹è¿›æä¾›äº†é‡è¦çš„å®éªŒä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€å†…å®¹å®¡æ ¸å’Œä¿¡æ¯å®‰å…¨ç­‰ã€‚é€šè¿‡æ”¹è¿›æ°´å°æŠ€æœ¯ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å’Œé˜²æ­¢ä¸å½“ä½¿ç”¨LLMç”Ÿæˆçš„æ–‡æœ¬ï¼Œæå‡æ–‡æœ¬ç”Ÿæˆçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼Œæ°´å°æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä¿ƒè¿›LLMçš„å¥åº·å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> To mitigate the potential harms of Large Language Models (LLMs)generated text, researchers have proposed watermarking, a process of embedding detectable signals within text. With watermarking, we can always accurately detect LLM-generated texts. However, recent findings suggest that these techniques often negatively affect the quality of the generated texts, and adversarial attacks can strip the watermarking signals, causing the texts to possibly evade detection. These findings have created resistance in the wide adoption of watermarking by LLM creators. Finally, to encourage adoption, we evaluate the robustness of several watermarking techniques to adversarial attacks by comparing paraphrasing and back translation (i.e., English $\to$ another language $\to$ English) attacks; and their ability to preserve quality and writing style of the unwatermarked texts by using linguistic metrics to capture quality and writing style of texts. Our results suggest that these watermarking techniques preserve semantics, deviate from the writing style of the unwatermarked texts, and are susceptible to adversarial attacks, especially for the back translation attack.

