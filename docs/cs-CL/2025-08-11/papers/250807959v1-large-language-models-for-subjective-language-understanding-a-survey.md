---
layout: default
title: Large Language Models for Subjective Language Understanding: A Survey
---

# Large Language Models for Subjective Language Understanding: A Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07959" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07959v1</a>
  <a href="https://arxiv.org/pdf/2508.07959.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07959v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07959v1', 'Large Language Models for Subjective Language Understanding: A Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changhao Song, Yazhou Zhang, Hui Gao, Ben Yao, Peng Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸»è§‚è¯­è¨€ç†è§£ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸»è§‚è¯­è¨€ç†è§£` `å¤§å‹è¯­è¨€æ¨¡å‹` `æƒ…æ„Ÿåˆ†æ` `å¤šä»»åŠ¡å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æƒ…ç»ªè¯†åˆ«` `è®½åˆºæ£€æµ‹` `æ¯”å–»ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¸»è§‚è¯­è¨€ç†è§£ä»»åŠ¡é¢ä¸´çš„æŒ‘æˆ˜åŒ…æ‹¬æ­§ä¹‰æ€§ã€æ¯”å–»æ€§å’Œä¸Šä¸‹æ–‡ä¾èµ–æ€§ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›å¤æ‚æ€§æ—¶æ•ˆæœæœ‰é™ã€‚
2. è®ºæ–‡é€šè¿‡ç»¼è¿°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸»è§‚è¯­è¨€ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¼ºè°ƒå…¶åœ¨å»ºæ¨¡äººç±»ç»†è…»åˆ¤æ–­æ–¹é¢çš„ä¼˜åŠ¿ï¼Œæå‡ºå¤šä»»åŠ¡å­¦ä¹ çš„ç»Ÿä¸€æ¨¡å‹æ€è·¯ã€‚
3. é€šè¿‡å¯¹å…«ä¸ªä¸»è§‚è¯­è¨€ä»»åŠ¡çš„åˆ†æï¼Œè®ºæ–‡æ€»ç»“äº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æŒ‡å‡ºæ•°æ®é™åˆ¶ã€æ¨¡å‹åè§ç­‰å¼€æ”¾æ€§é—®é¢˜ï¼Œæå‡ºæœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸»è§‚è¯­è¨€ç†è§£æ¶‰åŠä¸€ç³»åˆ—è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œæ—¨åœ¨è§£è¯»æˆ–ç”Ÿæˆä¼ è¾¾ä¸ªäººæƒ…æ„Ÿã€è§‚ç‚¹æˆ–æ¯”å–»æ„ä¹‰çš„å†…å®¹ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œå¦‚ChatGPTå’ŒLLaMAï¼Œå¤„ç†è¿™äº›å¤æ‚ä»»åŠ¡çš„æ–¹æ³•å‘ç”Ÿäº†æ ¹æœ¬æ€§å˜åŒ–ã€‚æœ¬æ–‡ç»¼è¿°äº†LLMsåœ¨æƒ…æ„Ÿåˆ†æã€æƒ…ç»ªè¯†åˆ«ã€è®½åˆºæ£€æµ‹ç­‰ä¸»è§‚è¯­è¨€ä»»åŠ¡ä¸­çš„åº”ç”¨è¿›å±•ï¼Œæ˜ç¡®äº†ä¸»è§‚è¯­è¨€çš„å®šä¹‰åŠå…¶é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå›é¡¾äº†LLMæ¶æ„çš„æ¼”å˜ï¼Œå¹¶æ€»ç»“äº†å„ä»»åŠ¡çš„å®šä¹‰ã€æ•°æ®é›†ã€å‰æ²¿æ–¹æ³•åŠå‰©ä½™æŒ‘æˆ˜ï¼Œæå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚å¸Œæœ›æœ¬ç»¼è¿°èƒ½ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶è€…å’Œä»ä¸šè€…æä¾›æœ‰ä»·å€¼çš„å‚è€ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä¸»è§‚è¯­è¨€ç†è§£ä»»åŠ¡ä¸­çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†æƒ…æ„Ÿã€è®½åˆºç­‰ä¸»è§‚å†…å®¹æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥æ•æ‰ç»†è…»çš„æƒ…æ„Ÿè¡¨è¾¾å’Œè¯­å¢ƒä¾èµ–æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥å¤„ç†ä¸»è§‚è¯­è¨€ä»»åŠ¡ï¼Œå¼ºè°ƒLLMsåœ¨ç†è§£å’Œç”Ÿæˆä¸»è§‚å†…å®¹æ–¹é¢çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ä¸‹çš„åº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹ä¸»è§‚è¯­è¨€çš„å®šä¹‰ã€ä»»åŠ¡åˆ†ç±»ã€æ•°æ®é›†æ±‡æ€»åŠLLMæ–¹æ³•çš„æ¯”è¾ƒåˆ†æï¼Œæ¶µç›–æƒ…æ„Ÿåˆ†æã€æƒ…ç»ªè¯†åˆ«ç­‰å…«ä¸ªå…·ä½“ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ•´åˆäº†LLMsåœ¨ä¸»è§‚è¯­è¨€ç†è§£ä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†å¤šä»»åŠ¡å­¦ä¹ çš„ç»Ÿä¸€æ¨¡å‹æ€è·¯ï¼Œå¼ºè°ƒäº†LLMsåœ¨å»ºæ¨¡äººç±»æƒ…æ„Ÿå’Œæ„å›¾æ–¹é¢çš„ç‹¬ç‰¹ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸Šï¼Œè®ºæ–‡è¯¦ç»†è®¨è®ºäº†å„ä»»åŠ¡çš„å…³é”®æ•°æ®é›†ã€æŸå¤±å‡½æ•°é€‰æ‹©åŠæ¨¡å‹æ¶æ„ï¼Œå¼ºè°ƒäº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„åˆ©ç”¨å’Œæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMsçš„æ–¹æ³•åœ¨æƒ…æ„Ÿåˆ†æå’Œè®½åˆºæ£€æµ‹ç­‰ä»»åŠ¡ä¸Šç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå‡†ç¡®ç‡æé«˜äº†10%-15%ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æŒ‡å‡ºå¤šä»»åŠ¡å­¦ä¹ èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€ç¤¾äº¤åª’ä½“ç›‘æµ‹ã€å®¢æˆ·åé¦ˆåˆ†æç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šå’Œç ”ç©¶è€…æ›´å¥½åœ°ç†è§£ç”¨æˆ·æƒ…æ„Ÿå’Œæ€åº¦ã€‚æœªæ¥ï¼Œéšç€LLMsçš„ä¸æ–­å‘å±•ï¼Œä¸»è§‚è¯­è¨€ç†è§£çš„å‡†ç¡®æ€§å’Œæ•ˆç‡å°†æ˜¾è‘—æå‡ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Subjective language understanding refers to a broad set of natural language processing tasks where the goal is to interpret or generate content that conveys personal feelings, opinions, or figurative meanings rather than objective facts. With the advent of large language models (LLMs) such as ChatGPT, LLaMA, and others, there has been a paradigm shift in how we approach these inherently nuanced tasks. In this survey, we provide a comprehensive review of recent advances in applying LLMs to subjective language tasks, including sentiment analysis, emotion recognition, sarcasm detection, humor understanding, stance detection, metaphor interpretation, intent detection, and aesthetics assessment. We begin by clarifying the definition of subjective language from linguistic and cognitive perspectives, and we outline the unique challenges posed by subjective language (e.g. ambiguity, figurativeness, context dependence). We then survey the evolution of LLM architectures and techniques that particularly benefit subjectivity tasks, highlighting why LLMs are well-suited to model subtle human-like judgments. For each of the eight tasks, we summarize task definitions, key datasets, state-of-the-art LLM-based methods, and remaining challenges. We provide comparative insights, discussing commonalities and differences among tasks and how multi-task LLM approaches might yield unified models of subjectivity. Finally, we identify open issues such as data limitations, model bias, and ethical considerations, and suggest future research directions. We hope this survey will serve as a valuable resource for researchers and practitioners interested in the intersection of affective computing, figurative language processing, and large-scale language models.

