---
layout: default
title: Augmenting Bias Detection in LLMs Using Topological Data Analysis
---

# Augmenting Bias Detection in LLMs Using Topological Data Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07516v1</a>
  <a href="https://arxiv.org/pdf/2508.07516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07516v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07516v1', 'Augmenting Bias Detection in LLMs Using Topological Data Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Keshav Varadarajan, Tananun Songdechakraiwut

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: 15 pages, 9 figures, 4 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨æ‹“æ‰‘æ•°æ®åˆ†æå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„åè§æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åè§æ£€æµ‹` `æ‹“æ‰‘æ•°æ®åˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åè§æ£€æµ‹æ–¹æ³•å°šæœªæœ‰æ•ˆè¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯¼è‡´ç‰¹å®šç¾¤ä½“åè§çš„å…·ä½“éƒ¨åˆ†ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ‹“æ‰‘æ•°æ®åˆ†æçš„æ–¹æ³•ï¼Œæ—¨åœ¨è¯†åˆ«GPT-2ä¸­ä¸åè§ç›¸å…³çš„æ³¨æ„åŠ›å¤´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç‰¹å®šç±»åˆ«çš„åè§é›†ä¸­åœ¨ç‰¹å®šçš„æ³¨æ„åŠ›å¤´ä¸­ï¼Œä¸ºæœªæ¥å»åè§å·¥ä½œæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè®¸å¤šåè§æ£€æµ‹æ–¹æ³•è¢«æå‡ºï¼Œä»¥ç¡®å®šå¤§å‹è¯­è¨€æ¨¡å‹æ‰€æ•è·çš„åè§ç¨‹åº¦ã€‚ç„¶è€Œï¼Œè¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å“ªäº›éƒ¨åˆ†å¯¼è‡´å¯¹ç‰¹å®šç¾¤ä½“çš„åè§çš„æµ‹è¯•ä»ç„¶ä¸å¤Ÿæˆç†Ÿã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨æ‹“æ‰‘æ•°æ®åˆ†æçš„æ–¹æ³•ï¼Œä»¥è¯†åˆ«åœ¨GPT-2ä¸­å“ªäº›æ³¨æ„åŠ›å¤´å¯¹StereoSetæ•°æ®é›†ä¸­èº«ä»½ç¾¤ä½“çš„è¯¯è¡¨å¾æœ‰æ‰€è´¡çŒ®ã€‚æˆ‘ä»¬å‘ç°ï¼Œç‰¹å®šç±»åˆ«ï¼ˆå¦‚æ€§åˆ«æˆ–èŒä¸šï¼‰çš„åè§é›†ä¸­åœ¨ä½œä¸ºçƒ­ç‚¹çš„æ³¨æ„åŠ›å¤´ä¸­ã€‚æˆ‘ä»¬æå‡ºçš„æŒ‡æ ‡è¿˜å¯ä»¥ç”¨äºç¡®å®šå“ªäº›å¤´éƒ¨æ•è·ç‰¹å®šç¾¤ä½“åœ¨åè§ç±»åˆ«ä¸­çš„åè§ï¼Œæœªæ¥çš„å·¥ä½œå¯ä»¥æ‰©å±•æ­¤æ–¹æ³•ä»¥å¸®åŠ©å»åè§å¤§å‹è¯­è¨€æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è¯†åˆ«å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¯¼è‡´ç‰¹å®šç¾¤ä½“åè§çš„å…·ä½“éƒ¨åˆ†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸçš„æµ‹è¯•å°šä¸æˆç†Ÿï¼Œæ— æ³•æœ‰æ•ˆå®šä½åè§æ¥æºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯åˆ©ç”¨æ‹“æ‰‘æ•°æ®åˆ†ææŠ€æœ¯ï¼Œåˆ†æGPT-2æ¨¡å‹ä¸­ä¸åŒæ³¨æ„åŠ›å¤´çš„è¡¨ç°ï¼Œä»¥è¯†åˆ«ä¸ç‰¹å®šèº«ä»½ç¾¤ä½“ç›¸å…³çš„åè§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´æ¸…æ™°åœ°äº†è§£æ¨¡å‹çš„åè§åˆ†å¸ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ‹“æ‰‘æ•°æ®åˆ†æã€æ³¨æ„åŠ›å¤´çš„åè§è¯„ä¼°ç­‰æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨StereoSetæ•°æ®é›†è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œç„¶åé€šè¿‡æ‹“æ‰‘åˆ†æè¯†åˆ«åè§çƒ­ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ‹“æ‰‘æ•°æ®åˆ†æå¼•å…¥åè§æ£€æµ‹é¢†åŸŸï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œé‡åŒ–ä¸åŒæ³¨æ„åŠ›å¤´å¯¹ç‰¹å®šåè§çš„è´¡çŒ®ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„åè§æ£€æµ‹æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ·±å…¥çš„åˆ†æè§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡å¯¹æ³¨æ„åŠ›å¤´çš„é€‰æ‹©å’Œè¯„ä¼°æŒ‡æ ‡è¿›è¡Œäº†ç²¾ç»†è®¾è®¡ï¼Œç¡®ä¿èƒ½å¤Ÿå‡†ç¡®æ•æ‰åˆ°åè§çš„åˆ†å¸ƒæƒ…å†µã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ä¹Ÿç»è¿‡äº†ä¼˜åŒ–ï¼Œä»¥æé«˜æ¨¡å‹çš„æ£€æµ‹èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç‰¹å®šç±»åˆ«çš„åè§ä¸»è¦é›†ä¸­åœ¨å°‘æ•°å‡ ä¸ªæ³¨æ„åŠ›å¤´ä¸­ï¼Œæä¾›äº†å…·ä½“çš„åè§è¯†åˆ«æŒ‡æ ‡ã€‚è¿™ä¸€æ–¹æ³•åœ¨åè§æ£€æµ‹çš„å‡†ç¡®æ€§ä¸Šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œä¸ºæœªæ¥çš„å»åè§ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…¬å¹³æ€§è¯„ä¼°ã€åè§æ¶ˆé™¤ä»¥åŠå¤§å‹è¯­è¨€æ¨¡å‹çš„æ”¹è¿›ã€‚é€šè¿‡è¯†åˆ«å’Œé‡åŒ–æ¨¡å‹ä¸­çš„åè§ï¼Œç ”ç©¶è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°è¿›è¡Œå»åè§å·¥ä½œï¼Œä»è€Œæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å…¬æ­£æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, many bias detection methods have been proposed to determine the level of bias a large language model captures. However, tests to identify which parts of a large language model are responsible for bias towards specific groups remain underdeveloped. In this study, we present a method using topological data analysis to identify which heads in GPT-2 contribute to the misrepresentation of identity groups present in the StereoSet dataset. We find that biases for particular categories, such as gender or profession, are concentrated in attention heads that act as hot spots. The metric we propose can also be used to determine which heads capture bias for a specific group within a bias category, and future work could extend this method to help de-bias large language models.

