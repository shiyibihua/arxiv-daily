---
layout: default
title: Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints
---

# Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08466" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08466v1</a>
  <a href="https://arxiv.org/pdf/2508.08466.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08466v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08466v1', 'Enhancing Small LLM Alignment through Margin-Based Objective Modifications under Resource Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daren Yao, Jinsong Yuan, Ruike Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: 10 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§DPOå˜ä½“ä»¥æå‡å°å‹LLMå¯¹é½èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å°å‹è¯­è¨€æ¨¡å‹` `å¯¹é½èƒ½åŠ›` `è¾¹é™…ç›®æ ‡` `å›°éš¾æ ·æœ¬æŒ–æ˜` `é€‰æ‹©æ€§æ›´æ–°æœºåˆ¶` `è‡ªç„¶è¯­è¨€å¤„ç†` `DPOå˜ä½“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å°å‹LLMåœ¨å¯¹é½äººç±»åå¥½æ—¶å­˜åœ¨æ˜¾è‘—æ€§èƒ½å·®è·ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè§£å†³è¿™ä¸€é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºè‡ªé€‚åº”è¾¹é™…-sigmoidæŸå¤±å’ŒAPO-hinge-zeroä¸¤ç§è½»é‡çº§å˜ä½“ï¼Œæ—¨åœ¨é€šè¿‡è¾¹é™…ç›®æ ‡å’Œé€‰æ‹©æ€§æ›´æ–°æœºåˆ¶æ”¹å–„æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAPO-hinge-zeroåœ¨AlpacaEvalä¸­èƒœç‡æå‡2.0ä¸ªç™¾åˆ†ç‚¹ï¼Œåœ¨MT-Benchä¸­å„ç±»ä»»åŠ¡è¡¨ç°ç«äº‰åŠ›ï¼Œå°¤å…¶åœ¨STEMå’Œäººæ–‡å­¦ç§‘ä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°å‹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¾“å‡ºä¸äººç±»åå¥½å¯¹é½æ—¶å¸¸é¢ä¸´å›°éš¾ï¼Œå°¤å…¶åœ¨æ€§èƒ½å·®è·è¾ƒå¤§çš„æƒ…å†µä¸‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸¤ç§è½»é‡çº§çš„åŸºäºDPOçš„å˜ä½“â€”â€”è‡ªé€‚åº”è¾¹é™…- sigmoidæŸå¤±å’ŒAPO-hinge-zeroï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥åŸºäºè¾¹é™…çš„ç›®æ ‡å’Œé€‰æ‹©æ€§æ›´æ–°æœºåˆ¶æ¥æ”¹å–„ä½æ€§èƒ½åœºæ™¯ã€‚APO-hinge-zeroæ–¹æ³•ç»“åˆäº†åŸºäºé“°é“¾çš„å›°éš¾æ ·æœ¬æŒ–æ˜ä¸APO-zeroçš„èšç„¦ä¼˜åŒ–ï¼Œåœ¨AlpacaEvalä¸­ç›¸è¾ƒäºAPO-zeroåŸºçº¿æå‡äº†2.0ä¸ªç™¾åˆ†ç‚¹çš„èƒœç‡å’Œ1.4ä¸ªç™¾åˆ†ç‚¹çš„é•¿åº¦æ§åˆ¶èƒœç‡ã€‚åœ¨MT-Benchä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¤šç§ç±»åˆ«ä¸­ä¿æŒäº†ç«äº‰åŠ›ï¼Œå°¤å…¶åœ¨STEMå’Œäººæ–‡å­¦ç§‘ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç®€å•çš„åå¥½ç›®æ ‡ä¿®æ”¹å¯ä»¥æ˜¾è‘—å¢å¼ºå°å‹LLMåœ¨èµ„æºé™åˆ¶ä¸‹çš„å¯¹é½èƒ½åŠ›ï¼Œä¸ºæ›´é«˜æ•ˆçš„éƒ¨ç½²æä¾›äº†å®é™…è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°å‹LLMåœ¨å¯¹é½äººç±»åå¥½æ—¶çš„æ€§èƒ½ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨èµ„æºé™åˆ¶ä¸‹éš¾ä»¥æœ‰æ•ˆæå‡æ¨¡å‹è¾“å‡ºè´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥è¾¹é™…ç›®æ ‡å’Œé€‰æ‹©æ€§æ›´æ–°æœºåˆ¶ï¼Œæå‡ºä¸¤ç§è½»é‡çº§çš„DPOå˜ä½“ï¼Œä»¥æ”¹å–„æ¨¡å‹åœ¨ä½æ€§èƒ½åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªé€‚åº”è¾¹é™…-sigmoidæŸå¤±å’ŒAPO-hinge-zeroï¼Œå‰è€…é€šè¿‡åŠ¨æ€è°ƒæ•´è¾¹é™…æ¥ä¼˜åŒ–æŸå¤±ï¼Œåè€…ç»“åˆå›°éš¾æ ·æœ¬æŒ–æ˜ä¸èšç„¦ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šAPO-hinge-zeroæ–¹æ³•çš„åˆ›æ–°åœ¨äºç»“åˆäº†é“°é“¾æŸå¤±ä¸é€‰æ‹©æ€§ä¼˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å›°éš¾æ ·æœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†è¾¹é™…è°ƒæ•´æœºåˆ¶ï¼Œå…³é”®å‚æ•°è®¾ç½®ä¸ºåŠ¨æ€æ›´æ–°ï¼Œä»¥é€‚åº”ä¸åŒçš„è®­ç»ƒé˜¶æ®µå’Œæ ·æœ¬ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAPO-hinge-zeroåœ¨AlpacaEvalä¸­ç›¸è¾ƒäºAPO-zeroåŸºçº¿æå‡äº†2.0ä¸ªç™¾åˆ†ç‚¹çš„èƒœç‡å’Œ1.4ä¸ªç™¾åˆ†ç‚¹çš„é•¿åº¦æ§åˆ¶èƒœç‡ã€‚åœ¨MT-Benchä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ä»»åŠ¡ä¸­ä¿æŒäº†ç«äº‰åŠ›ï¼Œå°¤å…¶åœ¨STEMå’Œäººæ–‡å­¦ç§‘ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ç§‘ç ”å’Œå•†ä¸šæ™ºèƒ½ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å°å‹LLMåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚é€šè¿‡æå‡æ¨¡å‹å¯¹é½èƒ½åŠ›ï¼Œæœªæ¥å¯ä»¥å®ç°æ›´é«˜æ•ˆçš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é—®ç­”ç³»ç»Ÿç­‰æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Small large language models (LLMs) often face difficulties in aligning output to human preferences, particularly when operating under severe performance gaps. In this work, we propose two lightweight DPO-based variants -- Adaptive Margin-Sigmoid Loss and APO-hinge-zero -- to better address underperformance scenarios by introducing margin-based objectives and selective update mechanisms.
>   Our APO-hinge-zero method, which combines hinge-induced hard-example mining with the chosen-focused optimization of APO-zero, achieves strong results. In AlpacaEval, APO-hinge-zero improves the win rate by +2.0 points and the length-controlled win rate by +1.4 points compared to the APO-zero baseline. In MT-Bench, our methods maintain competitive performance in diverse categories, particularly excelling in STEM and Humanities tasks.
>   These results demonstrate that simple modifications to preference-based objectives can significantly enhance small LLM alignment under resource constraints, offering a practical path toward more efficient deployment.

