---
layout: default
title: Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache
---

# Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11886" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11886v1</a>
  <a href="https://arxiv.org/pdf/2506.11886.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11886v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11886v1', 'Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaoran Liu, Siyang He, Qiqi Wang, Ruixiao Li, Yuerong Song, Zhigeng Liu, Linlin Li, Qun Liu, Zengfeng Huang, Qipeng Guo, Ziwei He, Xipeng Qiu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 10 pages, 7 figures, work in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFourierAttentionä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å†…å­˜æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å†…å­˜æ•ˆç‡` `å‚…é‡Œå¶å˜æ¢` `é•¿ä¸Šä¸‹æ–‡å¤„ç†` `è‡ªå®šä¹‰å†…æ ¸` `å˜æ¢å™¨æ¶æ„` `æ¨¡å‹å‹ç¼©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶ï¼ŒKVç¼“å­˜çš„å†…å­˜éœ€æ±‚ä¸æ–­å¢åŠ ï¼Œå¯¼è‡´å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡çš„æŠ˜ä¸­ã€‚
2. FourierAttentionåˆ©ç”¨å˜æ¢å™¨å¤´éƒ¨ç»´åº¦çš„å¼‚è´¨æ€§ï¼Œé€šè¿‡å‚…é‡Œå¶åŸºæŠ•å½±æ¥ä¼˜åŒ–é•¿ä¸Šä¸‹æ–‡çš„å¤„ç†ï¼Œé¿å…äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ã€‚
3. åœ¨LLaMAæ¨¡å‹çš„å®éªŒä¸­ï¼ŒFourierAttentionåœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†å‡†ç¡®æ€§ï¼Œå¹¶ä¸”å†…å­˜ä½¿ç”¨æ•ˆç‡å¾—åˆ°äº†ä¼˜åŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ æ—¶é¢ä¸´æ—¥ç›Šå¢é•¿çš„é”®å€¼ï¼ˆKVï¼‰ç¼“å­˜å†…å­˜éœ€æ±‚ã€‚ç°æœ‰çš„å‹ç¼©æ–¹æ³•é€šå¸¸ä¼šå‡åŒ–å¤´éƒ¨ç»´åº¦æˆ–ä¾èµ–äºæ³¨æ„åŠ›å¼•å¯¼çš„ä»¤ç‰Œå‰ªæï¼Œå¾€å¾€ç‰ºç‰²å‡†ç¡®æ€§æˆ–å¼•å…¥è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬æå‡ºäº†FourierAttentionï¼Œè¿™æ˜¯ä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨å˜æ¢å™¨å¤´éƒ¨ç»´åº¦çš„å¼‚è´¨è§’è‰²ï¼šä½ç»´åº¦ä¼˜å…ˆè€ƒè™‘å±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œè€Œé«˜ç»´åº¦åˆ™æ•æ‰é•¿ç¨‹ä¾èµ–ã€‚é€šè¿‡å°†é•¿ä¸Šä¸‹æ–‡ä¸æ•æ„Ÿçš„ç»´åº¦æŠ•å½±åˆ°æ­£äº¤å‚…é‡Œå¶åŸºä¸Šï¼ŒFourierAttentionç”¨å›ºå®šé•¿åº¦çš„è°±ç³»æ•°è¿‘ä¼¼å…¶æ—¶é—´æ¼”å˜ã€‚å¯¹LLaMAæ¨¡å‹çš„è¯„ä¼°è¡¨æ˜ï¼ŒFourierAttentionåœ¨LongBenchå’ŒNeedle-In-A-Haystackï¼ˆNIAHï¼‰ä¸Šå®ç°äº†æœ€ä½³çš„é•¿ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„Tritonå†…æ ¸FlashFourierAttentionï¼Œé€šè¿‡ç®€åŒ–è¯»å†™æ“ä½œä¼˜åŒ–å†…å­˜ï¼Œå®ç°é«˜æ•ˆéƒ¨ç½²è€Œä¸å½±å“æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„æ˜¯å¤§è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¤„ç†ä¸­çš„å†…å­˜æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡å‡åŒ–å¤´éƒ¨ç»´åº¦æˆ–å‰ªæç­–ç•¥ï¼Œå¾€å¾€å¯¼è‡´å‡†ç¡®æ€§ä¸‹é™æˆ–è®¡ç®—å¼€é”€å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„FourierAttentionæ¡†æ¶åˆ©ç”¨å˜æ¢å™¨å¤´éƒ¨ç»´åº¦çš„å¼‚è´¨æ€§ï¼Œä½ç»´åº¦å…³æ³¨å±€éƒ¨ä¸Šä¸‹æ–‡ï¼Œé«˜ç»´åº¦æ•æ‰é•¿ç¨‹ä¾èµ–ï¼Œé€šè¿‡å‚…é‡Œå¶åŸºçš„æŠ•å½±æ¥è¿‘ä¼¼é•¿ä¸Šä¸‹æ–‡çš„å¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFourierAttentionçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯å¯¹é•¿ä¸Šä¸‹æ–‡ä¸æ•æ„Ÿçš„ç»´åº¦è¿›è¡Œå‚…é‡Œå¶åŸºæŠ•å½±ï¼ŒäºŒæ˜¯ä½¿ç”¨å›ºå®šé•¿åº¦çš„è°±ç³»æ•°æ¥è¿‘ä¼¼å…¶æ—¶é—´æ¼”å˜ï¼Œç¡®ä¿å†…å­˜ä½¿ç”¨çš„é«˜æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šFourierAttentionçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„ç‰¹æ€§å’Œå¯¹å¤´éƒ¨ç»´åº¦å¼‚è´¨æ€§çš„åˆ©ç”¨ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒé¿å…äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ï¼ŒåŒæ—¶ä¿æŒäº†é•¿ä¸Šä¸‹æ–‡çš„å¤„ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ­£äº¤å‚…é‡Œå¶åŸºçš„æŠ•å½±æ–¹æ³•ï¼Œç¡®ä¿äº†ç»´åº¦çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¹¶é€šè¿‡è‡ªå®šä¹‰çš„Tritonå†…æ ¸FlashFourierAttentionä¼˜åŒ–äº†å†…å­˜è¯»å†™æ“ä½œï¼Œæå‡äº†æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFourierAttentionåœ¨LongBenchå’ŒNIAHä»»åŠ¡ä¸Šå®ç°äº†æœ€ä½³çš„é•¿ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å†…å­˜ä½¿ç”¨æ•ˆç‡ï¼Œç¡®ä¿äº†æ€§èƒ½çš„åŒæ—¶é™ä½äº†è®¡ç®—å¼€é”€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬å¤„ç†ä¸­çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models struggle with memory demands from the growing Key-Value (KV) cache as context lengths increase. Existing compression methods homogenize head dimensions or rely on attention-guided token pruning, often sacrificing accuracy or introducing computational overhead. We propose FourierAttention, a training-free framework that exploits the heterogeneous roles of transformer head dimensions: lower dimensions prioritize local context, while upper ones capture long-range dependencies. By projecting the long-context-insensitive dimensions onto orthogonal Fourier bases, FourierAttention approximates their temporal evolution with fixed-length spectral coefficients. Evaluations on LLaMA models show that FourierAttention achieves the best long-context accuracy on LongBench and Needle-In-A-Haystack (NIAH). Besides, a custom Triton kernel, FlashFourierAttention, is designed to optimize memory via streamlined read-write operations, enabling efficient deployment without performance compromise.

