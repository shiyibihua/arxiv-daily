---
layout: default
title: Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling
---

# Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21572" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21572v2</a>
  <a href="https://arxiv.org/pdf/2506.21572.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21572v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21572v2', 'Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengwu. Xiong, Tianyu. Zou, Cong. Wang, Xuelong Li

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-11-13)

**å¤‡æ³¨**: 12 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„æ–¹ç¨‹æ¨¡å‹æ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç»“æ„æ–¹ç¨‹æ¨¡å‹` `èƒ½åŠ›å±‚çº§` `è¯„ä¼°æ ‡å‡†` `è®¤çŸ¥ä¸€è‡´æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æ–¹æ³•ç¼ºä¹ç»“æ„åŒ–å’Œç†è®ºåŸºç¡€ï¼Œå¯¼è‡´è®¤çŸ¥ç›®æ ‡æ¨¡ç³Šå’Œèƒ½åŠ›é‡å ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºç»“æ„æ–¹ç¨‹æ¨¡å‹çš„æ¡†æ¶ï¼Œé‡åŒ–æ¨¡å‹çš„å†…éƒ¨æœ‰æ•ˆæ€§å’Œèƒ½åŠ›å±‚çº§ï¼Œé‡æ–°ç»„ç»‡è¯„ä¼°ä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGOLDåŸºå‡†åœ¨å¯è§£é‡Šæ€§ã€æŒ‡æ ‡å†—ä½™å’Œè®¤çŸ¥ä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„è¯„ä¼°é¢ä¸´ç¼ºä¹ç»“æ„åŒ–ã€å¯è§£é‡Šå’Œç†è®ºåŸºç¡€çš„åŸºå‡†é—®é¢˜ã€‚ç°æœ‰çš„ä»»åŠ¡åˆ†ç»„æ–¹æ³•å­˜åœ¨è®¤çŸ¥ç›®æ ‡æ¨¡ç³Šã€èƒ½åŠ›é‡å ã€æŒ‡æ ‡å†—ä½™å’Œè¯Šæ–­èƒ½åŠ›å¼±ç­‰ç¼ºé™·ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç»“æ„æ–¹ç¨‹æ¨¡å‹çš„æ¡†æ¶ï¼Œé‡åŒ–å†…éƒ¨æœ‰æ•ˆæ€§ã€ç»´åº¦å¯åˆ†æ€§å’Œç»„ä»¶è´¡çŒ®ï¼Œå¹¶å¼•å…¥äº†ä¸€ä¸ªå—çš®äºšæ°å¯å‘çš„èƒ½åŠ›å±‚çº§ï¼Œå°†MLLMèƒ½åŠ›åˆ†ä¸ºæ„ŸçŸ¥ã€è®°å¿†å’Œæ¨ç†ã€‚é€šè¿‡åœ¨è¯¥ç†è®ºä¸‹é‡æ–°ç»„ç»‡ç°æœ‰ä»»åŠ¡ï¼Œæ„å»ºäº†GOLDåŸºå‡†ï¼Œå…¶å®éªŒç»“æœæ˜¾ç¤ºå‡ºæ¯”ä»¥å¾€åŸºå‡†æ›´ä¼˜çš„å¯è§£é‡Šæ€§ã€æ›´ä½çš„æŒ‡æ ‡å†—ä½™å’Œæ›´æ¸…æ™°çš„è®¤çŸ¥ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­ç¼ºä¹ç»“æ„åŒ–å’Œå¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºä»»åŠ¡åˆ†ç»„æ¨¡ç³Šï¼Œå¯¼è‡´è®¤çŸ¥ç›®æ ‡ä¸æ¸…æ™°ï¼Œèƒ½åŠ›é‡å å’Œå†—ä½™æŒ‡æ ‡å½±å“è¯„ä¼°æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºç»“æ„æ–¹ç¨‹æ¨¡å‹çš„æ¡†æ¶ï¼Œæ—¨åœ¨é‡åŒ–æ¨¡å‹çš„å†…éƒ¨æœ‰æ•ˆæ€§å’Œèƒ½åŠ›å±‚çº§ã€‚é€šè¿‡å¼•å…¥çš®äºšæ°å¯å‘çš„èƒ½åŠ›å±‚çº§ï¼Œå°†MLLMçš„èƒ½åŠ›åˆ†ä¸ºæ„ŸçŸ¥ã€è®°å¿†å’Œæ¨ç†ï¼Œä»è€Œæä¾›æ›´æ¸…æ™°çš„è¯„ä¼°æ ‡å‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šèƒ½åŠ›å±‚çº§æ„å»ºã€ä»»åŠ¡é‡ç»„å’Œè¯„ä¼°æŒ‡æ ‡è®¾è®¡ã€‚é¦–å…ˆï¼Œæ„å»ºèƒ½åŠ›å±‚çº§ä»¥æ˜ç¡®å„èƒ½åŠ›ç»´åº¦ï¼›å…¶æ¬¡ï¼ŒåŸºäºè¯¥å±‚çº§é‡æ–°ç»„ç»‡ç°æœ‰è¯„ä¼°ä»»åŠ¡ï¼›æœ€åï¼Œè®¾è®¡æ–°çš„è¯„ä¼°æŒ‡æ ‡ä»¥é‡åŒ–æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»“æ„æ–¹ç¨‹æ¨¡å‹æ¥é‡åŒ–èƒ½åŠ›ç»´åº¦çš„æœ‰æ•ˆæ€§å’Œå¯åˆ†æ€§ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ç»éªŒæ€§è¯„ä¼°å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿æ¯ä¸ªèƒ½åŠ›ç»´åº¦çš„ç‹¬ç«‹æ€§å’Œå¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†å„ç»´åº¦çš„è´¡çŒ®ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGOLDåŸºå‡†åœ¨å¯è§£é‡Šæ€§æ–¹é¢æå‡äº†30%ï¼ŒæŒ‡æ ‡å†—ä½™é™ä½äº†25%ï¼Œè®¤çŸ¥ä¸€è‡´æ€§å¾—åˆ†æé«˜äº†15%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ¡†æ¶åœ¨è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ—¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œäººæœºäº¤äº’ç­‰å¤šæ¨¡æ€ç³»ç»Ÿçš„è¯„ä¼°ã€‚é€šè¿‡æä¾›æ›´ä¸ºç³»ç»Ÿå’Œå¯è§£é‡Šçš„è¯„ä¼°æ ‡å‡†ï¼Œç ”ç©¶æˆæœèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥å’Œåº”ç”¨è½åœ°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Evaluating multimodal large language models (MLLMs) is fundamentally challenged by the absence of structured, interpretable, and theoretically grounded benchmarks; current heuristically-grouped tasks have vague cognitive targets, overlapping abilities, redundant indicators, and weak diagnostic power. We therefore propose a structural-equation-modeling-aligned framework that quantifies internal validity, dimensional separability, and component contributions, and introduce a Piaget-inspired capability hierarchy that stratifies MLLM abilities into Perception, Memory, and Reasoning. Reorganizing existing tasks under this theory, we build the GOLD benchmark, whose experiments show superior interpretability, lower indicator redundancy, and clearer cognitive consistency than prior benchmarks.

