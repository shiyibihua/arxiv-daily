---
layout: default
title: AbsenceBench: Language Models Can't Tell What's Missing
---

# AbsenceBench: Language Models Can't Tell What's Missing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11440v1</a>
  <a href="https://arxiv.org/pdf/2506.11440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11440v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11440v1', 'AbsenceBench: Language Models Can\'t Tell What\'s Missing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Harvey Yiyun Fu, Aryan Shrivastava, Jared Moore, Peter West, Chenhao Tan, Ari Holtzman

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 23 pages, 8 figures. Code and data are publicly available at https://github.com/harvey-fin/absence-bench

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAbsenceBenchä»¥è¯„ä¼°è¯­è¨€æ¨¡å‹ç¼ºå¤±ä¿¡æ¯è¯†åˆ«èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `ç¼ºå¤±ä¿¡æ¯è¯†åˆ«` `AbsenceBench` `Transformer` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä¿¡æ¯æ£€ç´¢` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«ç¼ºå¤±ä¿¡æ¯æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚æ–‡æ¡£æ—¶ã€‚
2. æœ¬æ–‡æå‡ºAbsenceBenchï¼Œé€šè¿‡æä¾›åŸå§‹å’Œç¼–è¾‘åçš„ä¸Šä¸‹æ–‡ï¼Œè¦æ±‚æ¨¡å‹è¯†åˆ«æ–‡æ¡£ä¸­æ•…æ„åˆ é™¤çš„éƒ¨åˆ†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹åœ¨è¯¥ä»»åŠ¡ä¸Šä»…è¾¾åˆ°69.6%çš„F1-scoreï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è„†å¼±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿è¾“å…¥å’Œå®šä½ç‰¹å®šä¿¡æ¯æ–¹é¢è¶Šæ¥è¶Šå¼ºå¤§ï¼Œä½†åœ¨è¯†åˆ«æ˜æ˜¾ç¼ºå¤±çš„ä¿¡æ¯æ—¶ä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡å¼•å…¥AbsenceBenchï¼Œè¯„ä¼°LLMsåœ¨æ•°å€¼åºåˆ—ã€è¯—æ­Œå’ŒGitHubæ‹‰å–è¯·æ±‚ç­‰ä¸‰ä¸ªé¢†åŸŸè¯†åˆ«ç¼ºå¤±ä¿¡æ¯çš„èƒ½åŠ›ã€‚å°½ç®¡ä»»åŠ¡çœ‹ä¼¼ç®€å•ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå³ä½¿æ˜¯æœ€å…ˆè¿›çš„æ¨¡å‹Claude-3.7-Sonnetåœ¨å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦ä¸º5K tokensçš„æƒ…å†µä¸‹ï¼Œä»…è·å¾—69.6%çš„F1-scoreã€‚åˆ†æè¡¨æ˜ï¼Œè¿™ä¸€ä½è¡¨ç°æºäºTransformeræ³¨æ„åŠ›æœºåˆ¶çš„æ ¹æœ¬é™åˆ¶ï¼Œæ— æ³•æœ‰æ•ˆå…³æ³¨æ–‡æ¡£ä¸­çš„â€œç¼ºå£â€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯†åˆ«æ–‡æ¡£ä¸­ç¼ºå¤±ä¿¡æ¯çš„èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨æ­¤ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯æ— æ³•æœ‰æ•ˆå¤„ç†ä¿¡æ¯çš„ç¼ºå¤±éƒ¨åˆ†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡AbsenceBenchï¼Œæä¾›åŸå§‹æ–‡æ¡£å’Œç¼–è¾‘æ–‡æ¡£çš„å¯¹æ¯”ï¼Œè¦æ±‚æ¨¡å‹è¯†åˆ«ç¼ºå¤±çš„ä¿¡æ¯ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹çš„ç¼ºå¤±ä¿¡æ¯æ£€æµ‹èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAbsenceBenchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ•°å€¼åºåˆ—ã€è¯—æ­Œå’ŒGitHubæ‹‰å–è¯·æ±‚ã€‚æ¯ä¸ªæ¨¡å—éƒ½è¦æ±‚æ¨¡å‹åœ¨ç»™å®šä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ï¼Œè¯†åˆ«è¢«åˆ é™¤çš„å†…å®¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šAbsenceBenchçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶ä¸“æ³¨äºç¼ºå¤±ä¿¡æ¯çš„è¯†åˆ«ï¼Œè€Œä¸æ˜¯ä¿¡æ¯çš„æ£€ç´¢ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°æ–¹æ³•çš„ç©ºç™½ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†Claude-3.7-Sonnetç­‰å…ˆè¿›æ¨¡å‹ï¼Œè®¾ç½®äº†å¹³å‡ä¸Šä¸‹æ–‡é•¿åº¦ä¸º5K tokensï¼Œé‡‡ç”¨F1-scoreä½œä¸ºæ€§èƒ½è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥é‡åŒ–æ¨¡å‹çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒClaude-3.7-Sonnetåœ¨AbsenceBenchä»»åŠ¡ä¸Šä»…è·å¾—69.6%çš„F1-scoreï¼Œå°½ç®¡åœ¨å…¶ä»–ä»»åŠ¡ï¼ˆå¦‚NIAHï¼‰ä¸­è¡¨ç°è¶…äººç±»ã€‚è¿™ä¸€ç»“æœçªæ˜¾äº†æ¨¡å‹åœ¨å¤„ç†ç¼ºå¤±ä¿¡æ¯æ—¶çš„è„†å¼±æ€§ï¼Œæ­ç¤ºäº†Transformeræ³¨æ„åŠ›æœºåˆ¶çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€ä¿¡æ¯æ£€ç´¢å’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿã€‚é€šè¿‡è¯„ä¼°å’Œæå‡è¯­è¨€æ¨¡å‹åœ¨ç¼ºå¤±ä¿¡æ¯è¯†åˆ«æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºæ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œå‡†ç¡®æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚æœªæ¥ï¼ŒAbsenceBenchå¯èƒ½æˆä¸ºè¯„ä¼°è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„é‡è¦åŸºå‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly capable of processing long inputs and locating specific information within them, as evidenced by their performance on the Needle in a Haystack (NIAH) test. However, while models excel at recalling surprising information, they still struggle to identify clearly omitted information. We introduce AbsenceBench to assesses LLMs' capacity to detect missing information across three domains: numerical sequences, poetry, and GitHub pull requests. AbsenceBench asks models to identify which pieces of a document were deliberately removed, given access to both the original and edited contexts. Despite the apparent straightforwardness of these tasks, our experiments reveal that even state-of-the-art models like Claude-3.7-Sonnet achieve only 69.6% F1-score with a modest average context length of 5K tokens. Our analysis suggests this poor performance stems from a fundamental limitation: Transformer attention mechanisms cannot easily attend to "gaps" in documents since these absences don't correspond to any specific keys that can be attended to. Overall, our results and analysis provide a case study of the close proximity of tasks where models are already superhuman (NIAH) and tasks where models breakdown unexpectedly (AbsenceBench).

