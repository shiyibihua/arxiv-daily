---
layout: default
title: Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?
---

# Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11807" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11807v1</a>
  <a href="https://arxiv.org/pdf/2506.11807.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11807v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11807v1', 'Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Simeon Junker, Manar Ali, Larissa Koch, Sina ZarrieÃŸ, Hendrik Buschmeier

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: To appear in ACL Findings 2025

**æœŸåˆŠ**: Findings of the Association for Computational Linguistics: ACL 2025, pp. 24101-24109

**DOI**: [10.18653/v1/2025.findings-acl.1236](https://doi.org/10.18653/v1/2025.findings-acl.1236)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•æŒ‡ç§°è§£æä»»åŠ¡ä¸­çš„å®ç”¨èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æŒ‡ç§°è§£æ` `è¯­ç”¨èƒ½åŠ›` `é¢œè‰²æè¿°` `ä¸Šä¸‹æ–‡ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•çš„æŒ‡ç§°è§£æä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡ä¾èµ–çš„é¢œè‰²æè¿°æ–¹é¢ã€‚
2. è®ºæ–‡é€šè¿‡è®¾è®¡ç®€å•çš„è§†è§‰åˆºæ¿€ä»»åŠ¡ï¼Œæ¢è®¨MLLMsçš„è¯­ç”¨èƒ½åŠ›ï¼Œæ—¨åœ¨æ­ç¤ºå…¶åœ¨æŒ‡ç§°è§£æä¸­çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„MLLMsåœ¨å¤„ç†é¢œè‰²æè¿°æ—¶ä»å­˜åœ¨æ˜¾è‘—çš„ç†è§£éšœç¢ï¼Œæœªèƒ½è¾¾åˆ°äººç±»çš„æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è°ƒæŸ¥äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•æŒ‡ç§°è§£æä»»åŠ¡ä¸­çš„è¯­è¨€èƒ½åŠ›ï¼Œä»»åŠ¡æ¶‰åŠæŠ½è±¡è§†è§‰åˆºæ¿€ï¼Œå¦‚é¢œè‰²å—å’Œé¢œè‰²ç½‘æ ¼ã€‚å°½ç®¡è¯¥ä»»åŠ¡å¯¹äººç±»è€Œè¨€ç›¸å¯¹ç®€å•ï¼Œä½†æˆ‘ä»¬è®¤ä¸ºå®ƒæ˜¯æ£€éªŒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰è¯­ç”¨èƒ½åŠ›çš„é‡è¦å·¥å…·ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºæœ¬çš„è¯­ç”¨èƒ½åŠ›ï¼Œå¦‚å¯¹é¢œè‰²æè¿°çš„ä¸Šä¸‹æ–‡ä¾èµ–è§£é‡Šï¼Œä»ç„¶æ˜¯å½“å‰æœ€å…ˆè¿›çš„MLLMsé¢ä¸´çš„é‡å¤§æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•æŒ‡ç§°è§£æä»»åŠ¡ä¸­çš„è¡¨ç°ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡ä¾èµ–çš„é¢œè‰²æè¿°è§£ææ–¹é¢ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›åŸºæœ¬è¯­ç”¨èƒ½åŠ›æ—¶é¢ä¸´æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡è®¾è®¡ç®€å•ä¸”æŠ½è±¡çš„è§†è§‰åˆºæ¿€ä»»åŠ¡ï¼Œè€ƒå¯ŸMLLMsçš„è¯­ç”¨èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬å¦‚ä½•ç†è§£å’Œè§£æé¢œè‰²æè¿°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæ­ç¤ºæ¨¡å‹çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸€ç³»åˆ—ç®€å•çš„è§†è§‰åˆºæ¿€ï¼Œå¦‚é¢œè‰²å—å’Œé¢œè‰²ç½‘æ ¼ï¼Œæ„å»ºäº†ä¸€ä¸ªå®éªŒæ¡†æ¶æ¥è¯„ä¼°MLLMsçš„è¡¨ç°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è§†è§‰è¾“å…¥å¤„ç†ã€è¯­è¨€æè¿°è§£æå’Œä¸Šä¸‹æ–‡ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†ç®€å•çš„è§†è§‰ä»»åŠ¡ä½œä¸ºè¯­ç”¨èƒ½åŠ›çš„æµ‹è¯•å·¥å…·ï¼Œå¼ºè°ƒäº†å½“å‰MLLMsåœ¨åŸºæœ¬è¯­ç”¨ç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œä¸ç°æœ‰ç ”ç©¶ç›¸æ¯”ï¼Œæä¾›äº†æ–°çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†æ ‡å‡†åŒ–çš„é¢œè‰²æè¿°å’Œè§†è§‰åˆºæ¿€ï¼Œç¡®ä¿äº†ä»»åŠ¡çš„ä¸€è‡´æ€§ã€‚åŒæ—¶ï¼Œè®¾è®¡äº†ç‰¹å®šçš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥é‡åŒ–æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ç†è§£æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒç»“æœé€šè¿‡å¯¹æ¯”åŸºçº¿è¿›è¡Œåˆ†æï¼Œæ­ç¤ºäº†æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•çš„é¢œè‰²æè¿°è§£æä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸Šä¸‹æ–‡ä¾èµ–çš„ç†è§£æ–¹é¢ï¼Œå‡†ç¡®ç‡æœªèƒ½è¶…è¿‡åŸºçº¿æ¨¡å‹ï¼Œè¡¨æ˜å…¶åœ¨åŸºæœ¬è¯­ç”¨èƒ½åŠ›ä¸Šçš„æ˜¾è‘—ä¸è¶³ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„æ¨¡å‹æ”¹è¿›æä¾›äº†é‡è¦çš„ç ”ç©¶æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–å®¢æœç­‰ã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨æŒ‡ç§°è§£æä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ç†è§£èƒ½åŠ›å’Œå“åº”å‡†ç¡®æ€§ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œç ”ç©¶ç»“æœå¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„å¯¹è¯ç³»ç»Ÿå’Œè§†è§‰ç†è§£æ¨¡å‹çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We investigate the linguistic abilities of multimodal large language models in reference resolution tasks featuring simple yet abstract visual stimuli, such as color patches and color grids. Although the task may not seem challenging for today's language models, being straightforward for human dyads, we consider it to be a highly relevant probe of the pragmatic capabilities of MLLMs. Our results and analyses indeed suggest that basic pragmatic capabilities, such as context-dependent interpretation of color descriptions, still constitute major challenges for state-of-the-art MLLMs.

