---
layout: default
title: Towards Understanding the Cognitive Habits of Large Reasoning Models
---

# Towards Understanding the Cognitive Habits of Large Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21571" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21571v2</a>
  <a href="https://arxiv.org/pdf/2506.21571.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21571v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21571v2', 'Towards Understanding the Cognitive Habits of Large Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianshuo Dong, Yujia Fu, Chuanrui Hu, Chao Zhang, Han Qiu

**åˆ†ç±»**: cs.CL, cs.AI, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-07-06)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/jianshuod/CogTest)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCogTestä»¥è¯„ä¼°å¤§å‹æ¨ç†æ¨¡å‹çš„è®¤çŸ¥ä¹ æƒ¯**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹æ¨ç†æ¨¡å‹` `è®¤çŸ¥ä¹ æƒ¯` `CogTest` `æ¨ç†æ€ç»´é“¾` `æ¨¡å‹ç›‘æ§` `å®‰å…¨æ€§è¯„ä¼°` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†èƒ½åŠ›å’Œè¡Œä¸ºç›‘æ§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹å¯¹å…¶è®¤çŸ¥ä¹ æƒ¯çš„æ·±å…¥ç†è§£ã€‚
2. æå‡ºCogTeståŸºå‡†ï¼Œé€šè¿‡16ç§è®¤çŸ¥ä¹ æƒ¯å’Œ25ä¸ªä»»åŠ¡çš„å®ä¾‹åŒ–ï¼Œç³»ç»Ÿè¯„ä¼°LRMsçš„è®¤çŸ¥ä¹ æƒ¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLRMså±•ç°å‡ºäººç±»è®¤çŸ¥ä¹ æƒ¯ï¼Œå¹¶èƒ½æ ¹æ®ä»»åŠ¡è‡ªé€‚åº”è°ƒæ•´ï¼Œå°¤å…¶åœ¨å®‰å…¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºç‰¹å®šä¹ æƒ¯ä¸æœ‰å®³å“åº”çš„å…³è”ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨ç”Ÿæˆæœ€ç»ˆå“åº”ä¹‹å‰ï¼Œèƒ½å¤Ÿè‡ªä¸»äº§ç”Ÿæ¨ç†æ€ç»´é“¾ï¼ˆCoTï¼‰ï¼Œä¸ºç†è§£å’Œç›‘æ§æ¨¡å‹è¡Œä¸ºæä¾›äº†æ–°æ–¹æ³•ã€‚æœ¬æ–‡åŸºäºäººç±»æˆåŠŸè§£å†³é—®é¢˜çš„è®¤çŸ¥ä¹ æƒ¯æ¡†æ¶ï¼Œæå‡ºäº†CogTeståŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°LRMsçš„è®¤çŸ¥ä¹ æƒ¯ã€‚CogTeståŒ…å«16ç§è®¤çŸ¥ä¹ æƒ¯ï¼Œæ¯ç§ä¹ æƒ¯é€šè¿‡25ä¸ªå¤šæ ·åŒ–ä»»åŠ¡è¿›è¡Œå®ä¾‹åŒ–ï¼Œå¹¶é‡‡ç”¨è¯æ®ä¼˜å…ˆçš„æå–æ–¹æ³•ä»¥ç¡®ä¿ä¹ æƒ¯è¯†åˆ«çš„å¯é æ€§ã€‚ç ”ç©¶å‘ç°ï¼ŒLRMsä¸ä»…å±•ç°å‡ºäººç±»èˆ¬çš„ä¹ æƒ¯ï¼Œè¿˜èƒ½æ ¹æ®ä¸åŒä»»åŠ¡è‡ªé€‚åº”åœ°è¿ç”¨è¿™äº›ä¹ æƒ¯ã€‚è¿›ä¸€æ­¥åˆ†ææ­ç¤ºäº†LRMsè®¤çŸ¥ä¹ æƒ¯ç‰¹å¾çš„ç›¸ä¼¼æ€§ä¸å·®å¼‚æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚ç ”ç©¶è¿˜æ‰©å±•åˆ°å®‰å…¨ç›¸å…³ä»»åŠ¡ï¼Œå‘ç°æŸäº›ä¹ æƒ¯ä¸æœ‰å®³å“åº”çš„ç”Ÿæˆå¯†åˆ‡ç›¸å…³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰è®¤çŸ¥ä¹ æƒ¯çš„ç†è§£ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆç›‘æ§å’Œè§£é‡Šæ¨¡å‹è¡Œä¸ºçš„æ ¹æœ¬åŸå› ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥CogTeståŸºå‡†ï¼Œç³»ç»ŸåŒ–è¯„ä¼°LRMsçš„è®¤çŸ¥ä¹ æƒ¯ï¼Œå€Ÿé‰´äººç±»æˆåŠŸé—®é¢˜è§£å†³çš„è®¤çŸ¥ä¹ æƒ¯æ¡†æ¶ï¼Œæä¾›å¯é çš„è¯„ä¼°å·¥å…·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCogTeståŒ…æ‹¬16ç§è®¤çŸ¥ä¹ æƒ¯ï¼Œæ¯ç§ä¹ æƒ¯é€šè¿‡25ä¸ªå¤šæ ·åŒ–ä»»åŠ¡è¿›è¡Œè¯„ä¼°ï¼Œé‡‡ç”¨è¯æ®ä¼˜å…ˆçš„æå–æ–¹æ³•ç¡®ä¿ä¹ æƒ¯è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCogTestçš„è®¾è®¡ä½¿å¾—å¯¹LRMsçš„è®¤çŸ¥ä¹ æƒ¯è¿›è¡Œç³»ç»Ÿè¯„ä¼°æˆä¸ºå¯èƒ½ï¼Œæ­ç¤ºäº†LRMsä¸ä¼ ç»ŸLLMsåœ¨è®¤çŸ¥ä¹ æƒ¯ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨CogTestä¸­ï¼Œä»»åŠ¡è®¾è®¡å¤šæ ·åŒ–ï¼Œç¡®ä¿è¦†ç›–ä¸åŒåœºæ™¯ï¼Œé‡‡ç”¨è¯æ®ä¼˜å…ˆçš„æå–æ–¹æ³•ä»¥æé«˜ä¹ æƒ¯è¯†åˆ«çš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLRMsåœ¨è®¤çŸ¥ä¹ æƒ¯çš„è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸLLMsï¼Œå°¤å…¶åœ¨å®‰å…¨ç›¸å…³ä»»åŠ¡ä¸­ï¼ŒæŸäº›ä¹ æƒ¯å¦‚â€œæ‰¿æ‹…è´£ä»»çš„é£é™©â€ä¸æœ‰å®³å“åº”ç”Ÿæˆä¹‹é—´å­˜åœ¨å¼ºå…³è”ã€‚è¿™ä¸ºç†è§£å’Œæ”¹è¿›æ¨¡å‹è¡Œä¸ºæä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººå·¥æ™ºèƒ½æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°ã€è¡Œä¸ºç›‘æ§ä»¥åŠäººæœºäº¤äº’ä¼˜åŒ–ã€‚é€šè¿‡æ·±å…¥ç†è§£LRMsçš„è®¤çŸ¥ä¹ æƒ¯ï¼Œå¯ä»¥ä¸ºæ¨¡å‹çš„è®¾è®¡å’Œåº”ç”¨æä¾›æŒ‡å¯¼ï¼Œæå‡å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain of Thought (CoT) before producing final responses, offer a promising approach to interpreting and monitoring model behaviors. Inspired by the observation that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' -- consistently emerge across tasks, we explore whether LRMs exhibit human-like cognitive habits. Building on Habits of Mind, a well-established framework of cognitive habits associated with successful human problem-solving, we introduce CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits. CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks, and employs an evidence-first extraction method to ensure reliable habit identification. With CogTest, we conduct a comprehensive evaluation of 16 widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that LRMs, unlike conventional LLMs, not only exhibit human-like habits but also adaptively deploy them according to different tasks. Finer-grained analyses further uncover patterns of similarity and difference in LRMs' cognitive habit profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and DeepSeek-R1). Extending the study to safety-related tasks, we observe that certain habits, such as Taking Responsible Risks, are strongly associated with the generation of harmful responses. These findings suggest that studying persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper understanding of LLM misbehavior. The code is available at: https://github.com/jianshuod/CogTest.

