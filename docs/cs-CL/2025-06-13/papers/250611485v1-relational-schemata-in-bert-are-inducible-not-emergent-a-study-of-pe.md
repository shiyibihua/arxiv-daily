---
layout: default
title: Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models
---

# Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11485" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11485v1</a>
  <a href="https://arxiv.org/pdf/2506.11485.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11485v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11485v1', 'Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cole Gawin

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 15 pages, 4 figures, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨BERTä¸­çš„å…³ç³»æ¨¡å¼å¯è¯±å¯¼æ€§è€Œéè‡ªå‘æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `BERT` `å…³ç³»æ¨¡å¼` `æ¦‚å¿µç†è§£` `è¯­è¨€æ¨¡å‹` `ç›‘ç£å­¦ä¹ ` `å¾®è°ƒ` `è¯­ä¹‰ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶æœªèƒ½æ˜ç¡®åŒºåˆ†BERTçš„è¡¨ç°æ˜¯å¦æºäºçœŸæ­£çš„æ¦‚å¿µç†è§£æˆ–ä»…æ˜¯ç»Ÿè®¡å…³è”ã€‚
2. é€šè¿‡åˆ†æBERTå†…éƒ¨è¡¨ç¤ºï¼Œè®ºæ–‡æå‡ºå…³ç³»æ¨¡å¼å¯é€šè¿‡ä»»åŠ¡å¾®è°ƒè¯±å¯¼ï¼Œè€Œéè‡ªå‘å½¢æˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒåï¼ŒBERTåœ¨å…³ç³»åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†å…³ç³»ä¿¡å·çš„å­˜åœ¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹å¦‚BERTåœ¨è¯­ä¹‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ˜¯å¦åæ˜ çœŸå®çš„æ¦‚å¿µèƒ½åŠ›æˆ–ä»…æ˜¯è¡¨å±‚çš„ç»Ÿè®¡å…³è”ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡é€šè¿‡ç ”ç©¶æ¦‚å¿µå¯¹åœ¨åˆ†ç±»ã€éƒ¨åˆ†æ•´ä½“å’ŒåŠŸèƒ½å…³ç³»ä¸­çš„å†…éƒ¨è¡¨ç¤ºï¼Œæ¢è®¨BERTæ˜¯å¦ç¼–ç äº†æŠ½è±¡çš„å…³ç³»æ¨¡å¼ã€‚ç»“æœè¡¨æ˜ï¼Œé¢„è®­ç»ƒçš„BERTèƒ½å¤Ÿå®ç°é«˜åˆ†ç±»å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºæ½œåœ¨çš„å…³ç³»ä¿¡å·ã€‚ç„¶è€Œï¼Œæ¦‚å¿µå¯¹åœ¨é«˜ç»´åµŒå…¥ç©ºé—´ä¸­æŒ‰å…³ç³»ç±»å‹ç»„ç»‡ï¼Œä»…åœ¨ç»è¿‡ç›‘ç£å…³ç³»åˆ†ç±»ä»»åŠ¡çš„å¾®è°ƒåæ‰å¾—ä»¥å®ç°ã€‚è¿™è¡¨æ˜å…³ç³»æ¨¡å¼å¹¶éä»…é€šè¿‡é¢„è®­ç»ƒè‡ªå‘äº§ç”Ÿï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡ä»»åŠ¡æ”¯æ¶è¯±å¯¼ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè¡Œä¸ºè¡¨ç°å¹¶ä¸ä¸€å®šæ„å‘³ç€ç»“æ„åŒ–çš„æ¦‚å¿µç†è§£ï¼Œä½†æ¨¡å‹å¯ä»¥é€šè¿‡é€‚å½“çš„è®­ç»ƒè·å¾—æ‰æ ¹çš„å…³ç³»æŠ½è±¡çš„å½’çº³åå·®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨BERTæ˜¯å¦å…·å¤‡çœŸæ­£çš„æ¦‚å¿µèƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…ä¾èµ–äºè¡¨å±‚çš„ç»Ÿè®¡ç‰¹å¾ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†æ¨¡å‹çš„è¡Œä¸ºè¡¨ç°ä¸å…¶å†…éƒ¨ç»“æ„ç†è§£ä¹‹é—´çš„å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºï¼Œé€šè¿‡å¯¹BERTè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œèƒ½å¤Ÿè¯±å¯¼å‡ºå…¶å†…éƒ¨çš„å…³ç³»æ¨¡å¼ï¼Œè€Œè¿™äº›æ¨¡å¼åœ¨é¢„è®­ç»ƒé˜¶æ®µå¹¶æœªè‡ªå‘å½¢æˆã€‚è¿™ä¸€æ€è·¯å¼ºè°ƒäº†ä»»åŠ¡æ”¯æ¶åœ¨æ¨¡å‹å­¦ä¹ ä¸­çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¯¹æ¯”å®éªŒçš„æ–¹æ³•ï¼Œåˆ†æäº†BERTåœ¨ä¸åŒå…³ç³»ç±»å‹çš„æ¦‚å¿µå¯¹ä¸Šçš„åˆ†ç±»è¡¨ç°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µã€å¾®è°ƒé˜¶æ®µå’Œæ€§èƒ½è¯„ä¼°é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºè¯æ˜äº†å…³ç³»æ¨¡å¼çš„è¯±å¯¼æ€§ï¼Œè€Œéè‡ªå‘æ€§ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚ç‚¹ï¼Œå¼ºè°ƒäº†ä»»åŠ¡å¾®è°ƒçš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å…³ç³»åˆ†ç±»ä»»åŠ¡ï¼Œå¹¶é€šè¿‡è°ƒæ•´è¶…å‚æ•°æ¥æé«˜æ¨¡å‹çš„åˆ†ç±»æ€§èƒ½ï¼Œç¡®ä¿äº†å®éªŒç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡ç›‘ç£å¾®è°ƒåï¼ŒBERTåœ¨å…³ç³»åˆ†ç±»ä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼Œè¾¾åˆ°é«˜è¾¾90%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œè¡¨æ˜æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°æ•æ‰åˆ°æ½œåœ¨çš„å…³ç³»ä¿¡å·ã€‚è¿™ä¸€å‘ç°ä¸æœªå¾®è°ƒçš„åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œæå‡å¹…åº¦æ˜æ˜¾ï¼ŒéªŒè¯äº†å…³ç³»æ¨¡å¼çš„è¯±å¯¼æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯¹è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æ·±å±‚æ¬¡è¯­ä¹‰ç†è§£çš„ä»»åŠ¡ä¸­ï¼Œå¦‚é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆå’ŒçŸ¥è¯†å›¾è°±æ„å»ºç­‰ã€‚é€šè¿‡ç†è§£BERTçš„å…³ç³»æ¨¡å¼ï¼Œæœªæ¥çš„æ¨¡å‹è®¾è®¡å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›å…³ç³»ä¿¡æ¯ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ™ºèƒ½æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large language models like BERT demonstrate strong empirical performance on semantic tasks, whether this reflects true conceptual competence or surface-level statistical association remains unclear. I investigate whether BERT encodes abstract relational schemata by examining internal representations of concept pairs across taxonomic, mereological, and functional relations. I compare BERT's relational classification performance with representational structure in [CLS] token embeddings. Results reveal that pretrained BERT enables high classification accuracy, indicating latent relational signals. However, concept pairs organize by relation type in high-dimensional embedding space only after fine-tuning on supervised relation classification tasks. This indicates relational schemata are not emergent from pretraining alone but can be induced via task scaffolding. These findings demonstrate that behavioral performance does not necessarily imply structured conceptual understanding, though models can acquire inductive biases for grounded relational abstraction through appropriate training.

