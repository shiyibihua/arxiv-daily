---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-06-13
---

# cs.CLï¼ˆ2025-06-13ï¼‰

ğŸ“Š å…± **36** ç¯‡è®ºæ–‡
 | ğŸ”— **5** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (29 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (29 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250611807v1-are-multimodal-large-language-models-pragmatically-competent-listene.html">Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?</a></td>
  <td>æ¢è®¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç®€å•æŒ‡ç§°è§£æä»»åŠ¡ä¸­çš„å®ç”¨èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11807v1" data-paper-url="./papers/250611807v1-are-multimodal-large-language-models-pragmatically-competent-listene.html" onclick="toggleFavorite(this, '2506.11807v1', 'Are Multimodal Large Language Models Pragmatically Competent Listeners in Simple Reference Resolution Tasks?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250612116v3-unsupervised-document-and-template-clustering-using-multimodal-embed.html">Unsupervised Document and Template Clustering using Multimodal Embeddings</a></td>
  <td>æå‡ºæ— ç›‘ç£æ–‡æ¡£ä¸æ¨¡æ¿èšç±»æ–¹æ³•ä»¥è§£å†³æ–‡æ¡£ç»„ç»‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12116v3" data-paper-url="./papers/250612116v3-unsupervised-document-and-template-clustering-using-multimodal-embed.html" onclick="toggleFavorite(this, '2506.12116v3', 'Unsupervised Document and Template Clustering using Multimodal Embeddings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250612014v1-code-transformed-the-influence-of-large-language-models-on-code.html">code_transformed: The Influence of Large Language Models on Code</a></td>
  <td>ç ”ç©¶LLMå¯¹ä»£ç é£æ ¼çš„å½±å“åŠå…¶ç‰¹å¾åˆ†æ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12014v1" data-paper-url="./papers/250612014v1-code-transformed-the-influence-of-large-language-models-on-code.html" onclick="toggleFavorite(this, '2506.12014v1', 'code_transformed: The Influence of Large Language Models on Code')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250611798v2-persona-driven-simulation-of-voting-behavior-in-the-european-parliam.html">Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models</a></td>
  <td>åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿæ¬§æ´²è®®ä¼šæŠ•ç¥¨è¡Œä¸º</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11798v2" data-paper-url="./papers/250611798v2-persona-driven-simulation-of-voting-behavior-in-the-european-parliam.html" onclick="toggleFavorite(this, '2506.11798v2', 'Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250612189v2-supernova-event-dataset-interpreting-large-language-models-personali.html">Supernova Event Dataset: Interpreting Large Language Models' Personality through Critical Event Analysis</a></td>
  <td>æå‡ºè¶…æ–°æ˜Ÿäº‹ä»¶æ•°æ®é›†ä»¥è§£æå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12189v2" data-paper-url="./papers/250612189v2-supernova-event-dataset-interpreting-large-language-models-personali.html" onclick="toggleFavorite(this, '2506.12189v2', 'Supernova Event Dataset: Interpreting Large Language Models&#39; Personality through Critical Event Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250611638v1-lora-gen-specializing-large-language-model-via-online-lora-generatio.html">LoRA-Gen: Specializing Large Language Model via Online LoRA Generation</a></td>
  <td>æå‡ºLoRA-Genæ¡†æ¶ä»¥æå‡è¾¹ç¼˜æ¨¡å‹çš„ä»»åŠ¡é€‚åº”æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11638v1" data-paper-url="./papers/250611638v1-lora-gen-specializing-large-language-model-via-online-lora-generatio.html" onclick="toggleFavorite(this, '2506.11638v1', 'LoRA-Gen: Specializing Large Language Model via Online LoRA Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250612274v1-infoflood-jailbreaking-large-language-models-with-information-overlo.html">InfoFlood: Jailbreaking Large Language Models with Information Overload</a></td>
  <td>æå‡ºInfoFloodä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ¼æ´é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12274v1" data-paper-url="./papers/250612274v1-infoflood-jailbreaking-large-language-models-with-information-overlo.html" onclick="toggleFavorite(this, '2506.12274v1', 'InfoFlood: Jailbreaking Large Language Models with Information Overload')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250611999v3-generative-representational-learning-of-foundation-models-for-recomm.html">Generative Representational Learning of Foundation Models for Recommendation</a></td>
  <td>æå‡ºRecFoundæ¡†æ¶ä»¥è§£å†³æ¨èç³»ç»Ÿä¸­çš„å¤šä»»åŠ¡å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11999v3" data-paper-url="./papers/250611999v3-generative-representational-learning-of-foundation-models-for-recomm.html" onclick="toggleFavorite(this, '2506.11999v3', 'Generative Representational Learning of Foundation Models for Recommendation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250611499v1-on-the-effectiveness-of-integration-methods-for-multimodal-dialogue-.html">On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval</a></td>
  <td>æå‡ºå¤šæ¨¡æ€å¯¹è¯å“åº”æ£€ç´¢é›†æˆæ–¹æ³•ä»¥æå‡ç³»ç»Ÿæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11499v1" data-paper-url="./papers/250611499v1-on-the-effectiveness-of-integration-methods-for-multimodal-dialogue-.html" onclick="toggleFavorite(this, '2506.11499v1', 'On the Effectiveness of Integration Methods for Multimodal Dialogue Response Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250611410v1-predicting-early-onset-colorectal-cancer-with-large-language-models.html">Predicting Early-Onset Colorectal Cancer with Large Language Models</a></td>
  <td>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹é¢„æµ‹æ—©å‘æ€§ç»“ç›´è‚ ç™Œ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11410v1" data-paper-url="./papers/250611410v1-predicting-early-onset-colorectal-cancer-with-large-language-models.html" onclick="toggleFavorite(this, '2506.11410v1', 'Predicting Early-Onset Colorectal Cancer with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250612182v1-instruction-tuning-and-cot-prompting-for-contextual-medical-qa-with-.html">Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs</a></td>
  <td>æå‡ºæŒ‡ä»¤è°ƒä¼˜ä¸CoTæç¤ºä»¥æå‡åŒ»å­¦é—®ç­”æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12182v1" data-paper-url="./papers/250612182v1-instruction-tuning-and-cot-prompting-for-contextual-medical-qa-with-.html" onclick="toggleFavorite(this, '2506.12182v1', 'Instruction Tuning and CoT Prompting for Contextual Medical QA with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250621572v2-aligning-mllm-benchmark-with-human-preferences-via-structural-equati.html">Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling</a></td>
  <td>æå‡ºç»“æ„æ–¹ç¨‹æ¨¡å‹æ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.21572v2" data-paper-url="./papers/250621572v2-aligning-mllm-benchmark-with-human-preferences-via-structural-equati.html" onclick="toggleFavorite(this, '2506.21572v2', 'Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250612266v1-the-behavior-gap-evaluating-zero-shot-llm-agents-in-complex-task-ori.html">The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs</a></td>
  <td>æå‡ºå…¨é¢è¯„ä¼°æ¡†æ¶ä»¥è§£å†³é›¶-shot LLMä»£ç†åœ¨å¤æ‚ä»»åŠ¡å¯¹è¯ä¸­çš„è¡Œä¸ºå·®è·é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12266v1" data-paper-url="./papers/250612266v1-the-behavior-gap-evaluating-zero-shot-llm-agents-in-complex-task-ori.html" onclick="toggleFavorite(this, '2506.12266v1', 'The Behavior Gap: Evaluating Zero-shot LLM Agents in Complex Task-Oriented Dialogs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250611769v1-long-short-alignment-for-effective-long-context-modeling-in-llms.html">Long-Short Alignment for Effective Long-Context Modeling in LLMs</a></td>
  <td>æå‡ºé•¿çŸ­å¯¹é½æ–¹æ³•ä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11769v1" data-paper-url="./papers/250611769v1-long-short-alignment-for-effective-long-context-modeling-in-llms.html" onclick="toggleFavorite(this, '2506.11769v1', 'Long-Short Alignment for Effective Long-Context Modeling in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250611602v1-are-llms-good-text-diacritizers-an-arabic-and-yorÃ¹bÃ¡-case-study.html">Are LLMs Good Text Diacritizers? An Arabic and YorÃ¹bÃ¡ Case Study</a></td>
  <td>æå‡ºMultiDiacæ•°æ®é›†ä»¥æå‡é˜¿æ‹‰ä¼¯è¯­å’Œçº¦é²å·´è¯­çš„æ–‡æœ¬åŠ éŸ³æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11602v1" data-paper-url="./papers/250611602v1-are-llms-good-text-diacritizers-an-arabic-and-yorÃ¹bÃ¡-case-study.html" onclick="toggleFavorite(this, '2506.11602v1', 'Are LLMs Good Text Diacritizers? An Arabic and YorÃ¹bÃ¡ Case Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250612109v3-personalized-llm-decoding-via-contrasting-personal-preference.html">Personalized LLM Decoding via Contrasting Personal Preference</a></td>
  <td>æå‡ºCoPeä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸ªæ€§åŒ–è§£ç é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12109v3" data-paper-url="./papers/250612109v3-personalized-llm-decoding-via-contrasting-personal-preference.html" onclick="toggleFavorite(this, '2506.12109v3', 'Personalized LLM Decoding via Contrasting Personal Preference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250611485v1-relational-schemata-in-bert-are-inducible-not-emergent-a-study-of-pe.html">Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models</a></td>
  <td>æ¢è®¨BERTä¸­çš„å…³ç³»æ¨¡å¼å¯è¯±å¯¼æ€§è€Œéè‡ªå‘æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11485v1" data-paper-url="./papers/250611485v1-relational-schemata-in-bert-are-inducible-not-emergent-a-study-of-pe.html" onclick="toggleFavorite(this, '2506.11485v1', 'Relational Schemata in BERT Are Inducible, Not Emergent: A Study of Performance vs. Competence in Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250621571v2-towards-understanding-the-cognitive-habits-of-large-reasoning-models.html">Towards Understanding the Cognitive Habits of Large Reasoning Models</a></td>
  <td>æå‡ºCogTestä»¥è¯„ä¼°å¤§å‹æ¨ç†æ¨¡å‹çš„è®¤çŸ¥ä¹ æƒ¯</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.21571v2" data-paper-url="./papers/250621571v2-towards-understanding-the-cognitive-habits-of-large-reasoning-models.html" onclick="toggleFavorite(this, '2506.21571v2', 'Towards Understanding the Cognitive Habits of Large Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250611432v1-kogec-korean-grammatical-error-correction-with-pre-trained-translati.html">KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models</a></td>
  <td>æå‡ºKoGECä»¥è§£å†³éŸ©è¯­è¯­æ³•é”™è¯¯çº æ­£é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11432v1" data-paper-url="./papers/250611432v1-kogec-korean-grammatical-error-correction-with-pre-trained-translati.html" onclick="toggleFavorite(this, '2506.11432v1', 'KoGEC : Korean Grammatical Error Correction with Pre-trained Translation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250612158v3-a-rigorous-evaluation-of-llm-data-generation-strategies-for-low-reso.html">A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages</a></td>
  <td>ç³»ç»Ÿè¯„ä¼°ä½èµ„æºè¯­è¨€çš„LLMæ•°æ®ç”Ÿæˆç­–ç•¥</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12158v3" data-paper-url="./papers/250612158v3-a-rigorous-evaluation-of-llm-data-generation-strategies-for-low-reso.html" onclick="toggleFavorite(this, '2506.12158v3', 'A Rigorous Evaluation of LLM Data Generation Strategies for Low-Resource Languages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250611886v1-beyond-homogeneous-attention-memory-efficient-llms-via-fourier-appro.html">Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache</a></td>
  <td>æå‡ºFourierAttentionä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å†…å­˜æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11886v1" data-paper-url="./papers/250611886v1-beyond-homogeneous-attention-memory-efficient-llms-via-fourier-appro.html" onclick="toggleFavorite(this, '2506.11886v1', 'Beyond Homogeneous Attention: Memory-Efficient LLMs via Fourier-Approximated KV Cache')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250611857v2-post-persona-alignment-for-multi-session-dialogue-generation.html">Post Persona Alignment for Multi-Session Dialogue Generation</a></td>
  <td>æå‡ºåç½®ä¸ªæ€§å¯¹é½æ–¹æ³•ä»¥è§£å†³å¤šä¼šè¯å¯¹è¯ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11857v2" data-paper-url="./papers/250611857v2-post-persona-alignment-for-multi-session-dialogue-generation.html" onclick="toggleFavorite(this, '2506.11857v2', 'Post Persona Alignment for Multi-Session Dialogue Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250611681v2-a-hybrid-multi-agent-prompting-approach-for-simplifying-complex-sent.html">A Hybrid Multi-Agent Prompting Approach for Simplifying Complex Sentences</a></td>
  <td>æå‡ºæ··åˆå¤šæ™ºèƒ½ä½“æç¤ºæ–¹æ³•ä»¥ç®€åŒ–å¤æ‚å¥å­</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11681v2" data-paper-url="./papers/250611681v2-a-hybrid-multi-agent-prompting-approach-for-simplifying-complex-sent.html" onclick="toggleFavorite(this, '2506.11681v2', 'A Hybrid Multi-Agent Prompting Approach for Simplifying Complex Sentences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250611631v1-scenegram-conceptualizing-and-describing-tangrams-in-scene-context.html">SceneGram: Conceptualizing and Describing Tangrams in Scene Context</a></td>
  <td>æå‡ºSceneGramæ•°æ®é›†ä»¥ç ”ç©¶åœºæ™¯ä¸Šä¸‹æ–‡å¯¹æ¦‚å¿µåŒ–çš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11631v1" data-paper-url="./papers/250611631v1-scenegram-conceptualizing-and-describing-tangrams-in-scene-context.html" onclick="toggleFavorite(this, '2506.11631v1', 'SceneGram: Conceptualizing and Describing Tangrams in Scene Context')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250611557v1-from-persona-to-person-enhancing-the-naturalness-with-multiple-disco.html">From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation</a></td>
  <td>æå‡ºMUDIä»¥è§£å†³ä¸ªæ€§åŒ–å¯¹è¯ç”Ÿæˆä¸­çš„è‡ªç„¶æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11557v1" data-paper-url="./papers/250611557v1-from-persona-to-person-enhancing-the-naturalness-with-multiple-disco.html" onclick="toggleFavorite(this, '2506.11557v1', 'From Persona to Person: Enhancing the Naturalness with Multiple Discourse Relations Graph Learning in Personalized Dialogue Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250611498v1-lag-relative-sparse-attention-in-long-context-training.html">Lag-Relative Sparse Attention In Long Context Training</a></td>
  <td>æå‡ºLag-Relative Sparse Attentionä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡è®­ç»ƒä¸­çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11498v1" data-paper-url="./papers/250611498v1-lag-relative-sparse-attention-in-long-context-training.html" onclick="toggleFavorite(this, '2506.11498v1', 'Lag-Relative Sparse Attention In Long Context Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250611440v1-absencebench-language-models-cant-tell-whats-missing.html">AbsenceBench: Language Models Can't Tell What's Missing</a></td>
  <td>æå‡ºAbsenceBenchä»¥è¯„ä¼°è¯­è¨€æ¨¡å‹ç¼ºå¤±ä¿¡æ¯è¯†åˆ«èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11440v1" data-paper-url="./papers/250611440v1-absencebench-language-models-cant-tell-whats-missing.html" onclick="toggleFavorite(this, '2506.11440v1', 'AbsenceBench: Language Models Can&#39;t Tell What&#39;s Missing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>28</td>
  <td><a href="./papers/250611418v1-efficient-long-context-llm-inference-via-kv-cache-clustering.html">Efficient Long-Context LLM Inference via KV Cache Clustering</a></td>
  <td>æå‡ºChelseaæ¡†æ¶ä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡LLMæ¨ç†ä¸­çš„KVç¼“å­˜é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11418v1" data-paper-url="./papers/250611418v1-efficient-long-context-llm-inference-via-kv-cache-clustering.html" onclick="toggleFavorite(this, '2506.11418v1', 'Efficient Long-Context LLM Inference via KV Cache Clustering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250622449v1-computational-analysis-of-climate-policy.html">Computational Analysis of Climate Policy</a></td>
  <td>æ„å»ºPALLMç³»ç»Ÿä»¥åˆ†ææ°”å€™æ”¿ç­–çš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.22449v1" data-paper-url="./papers/250622449v1-computational-analysis-of-climate-policy.html" onclick="toggleFavorite(this, '2506.22449v1', 'Computational Analysis of Climate Policy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>30</td>
  <td><a href="./papers/250611938v1-improving-large-language-model-safety-with-contrastive-representatio.html">Improving Large Language Model Safety with Contrastive Representation Learning</a></td>
  <td>æå‡ºå¯¹æ¯”è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ä»¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11938v1" data-paper-url="./papers/250611938v1-improving-large-language-model-safety-with-contrastive-representatio.html" onclick="toggleFavorite(this, '2506.11938v1', 'Improving Large Language Model Safety with Contrastive Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250611752v2-dart-distilling-autoregressive-reasoning-to-silent-thought.html">DART: Distilling Autoregressive Reasoning to Silent Thought</a></td>
  <td>æå‡ºDARTä»¥è§£å†³è‡ªå›å½’æ¨ç†çš„è®¡ç®—å¼€é”€é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11752v2" data-paper-url="./papers/250611752v2-dart-distilling-autoregressive-reasoning-to-silent-thought.html" onclick="toggleFavorite(this, '2506.11752v2', 'DART: Distilling Autoregressive Reasoning to Silent Thought')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/250611425v2-agent-rlvr-training-software-engineering-agents-via-guidance-and-env.html">Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards</a></td>
  <td>æå‡ºAgent-RLVRä»¥è§£å†³å¤æ‚è½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­çš„å¥–åŠ±ç¨€ç–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11425v2" data-paper-url="./papers/250611425v2-agent-rlvr-training-software-engineering-agents-via-guidance-and-env.html" onclick="toggleFavorite(this, '2506.11425v2', 'Agent-RLVR: Training Software Engineering Agents via Guidance and Environment Rewards')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>33</td>
  <td><a href="./papers/250612149v1-maximally-informative-retrieval-for-state-space-model-generation.html">Maximally-Informative Retrieval for State Space Model Generation</a></td>
  <td>æå‡ºRICOæ–¹æ³•ä»¥ä¼˜åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹ç”Ÿæˆä¸­çš„ä¿¡æ¯æ£€ç´¢</td>
  <td class="tags-cell"><span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12149v1" data-paper-url="./papers/250612149v1-maximally-informative-retrieval-for-state-space-model-generation.html" onclick="toggleFavorite(this, '2506.12149v1', 'Maximally-Informative Retrieval for State Space Model Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>34</td>
  <td><a href="./papers/250611702v1-configurable-preference-tuning-with-rubric-guided-synthetic-data.html">Configurable Preference Tuning with Rubric-Guided Synthetic Data</a></td>
  <td>æå‡ºå¯é…ç½®åå¥½è°ƒä¼˜æ¡†æ¶ä»¥è§£å†³é™æ€åå¥½é™åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">direct preference optimization</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11702v1" data-paper-url="./papers/250611702v1-configurable-preference-tuning-with-rubric-guided-synthetic-data.html" onclick="toggleFavorite(this, '2506.11702v1', 'Configurable Preference Tuning with Rubric-Guided Synthetic Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>35</td>
  <td><a href="./papers/250612242v1-large-language-models-for-history-philosophy-and-sociology-of-scienc.html">Large Language Models for History, Philosophy, and Sociology of Science: Interpretive Uses, Methodological Challenges, and Critical Perspectives</a></td>
  <td>æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦å²ã€å“²å­¦ä¸ç¤¾ä¼šå­¦ä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">affordance</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.12242v1" data-paper-url="./papers/250612242v1-large-language-models-for-history-philosophy-and-sociology-of-scienc.html" onclick="toggleFavorite(this, '2506.12242v1', 'Large Language Models for History, Philosophy, and Sociology of Science: Interpretive Uses, Methodological Challenges, and Critical Perspectives')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>36</td>
  <td><a href="./papers/250611475v2-autogen-driven-multi-agent-framework-for-iterative-crime-data-analys.html">AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction</a></td>
  <td>æå‡ºLUCID-MAæ¡†æ¶ä»¥å®ç°çŠ¯ç½ªæ•°æ®çš„è¿­ä»£åˆ†æä¸é¢„æµ‹</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.11475v2" data-paper-url="./papers/250611475v2-autogen-driven-multi-agent-framework-for-iterative-crime-data-analys.html" onclick="toggleFavorite(this, '2506.11475v2', 'AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)