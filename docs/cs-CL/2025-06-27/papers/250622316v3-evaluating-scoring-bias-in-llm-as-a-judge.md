---
layout: default
title: Evaluating Scoring Bias in LLM-as-a-Judge
---

# Evaluating Scoring Bias in LLM-as-a-Judge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22316" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22316v3</a>
  <a href="https://arxiv.org/pdf/2506.22316.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22316v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22316v3', 'Evaluating Scoring Bias in LLM-as-a-Judge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qingquan Li, Shaoyu Dou, Kailai Shao, Chao Chen, Haixiang Hu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27 (æ›´æ–°: 2025-08-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯„ä¼°LLMä½œä¸ºè¯„åˆ¤è€…ä¸­çš„è¯„åˆ†åå·®çš„æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„åˆ†åå·®` `è¯„ä¼°æ¡†æ¶` `è‡ªç„¶è¯­è¨€å¤„ç†` `å…¬å¹³æ€§` `è‡ªåŠ¨è¯„åˆ†` `æ•°æ®åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMä½œä¸ºè¯„åˆ¤è€…çš„ç ”ç©¶å¤šé›†ä¸­äºæ¯”è¾ƒè¯„ä¼°ï¼Œç¼ºä¹å¯¹è¯„åˆ†è¯„ä¼°ä¸­åå·®çš„ç³»ç»Ÿæ€§ç ”ç©¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è¯„åˆ†åå·®å®šä¹‰ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥è¯„ä¼°LLMä½œä¸ºè¯„åˆ¤è€…çš„è¯„åˆ†åå·®ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰è¯„åˆ¤æ¨¡å‹çš„è¯„åˆ†ç¨³å®šæ€§å—åˆ°è¯„åˆ†åå·®çš„æ˜¾è‘—å½±å“ï¼Œæä¾›äº†æ”¹è¿›è¯„åˆ†æ¨¡æ¿è®¾è®¡çš„è§è§£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å“è¶Šè¡¨ç°ä¿ƒä½¿å…¶è¢«å¹¿æ³›åº”ç”¨äºå¤æ‚ä»»åŠ¡çš„è¯„ä¼°ä¸­ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œåå¥½å­¦ä¹ ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼ŒLLMä½œä¸ºè¯„åˆ¤è€…ä¸­å­˜åœ¨å¤šç§åå·®ï¼Œå½±å“äº†åˆ¤æ–­çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ¯”è¾ƒè¯„ä¼°çš„åå·®ä¸Šï¼Œè€Œå¯¹è¯„åˆ†è¯„ä¼°ä¸­çš„åå·®ç³»ç»Ÿæ€§ç ”ç©¶è¾ƒå°‘ã€‚æœ¬æ–‡å®šä¹‰äº†è¯„åˆ†åå·®ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªå…¨é¢è¯„ä¼°è¯„åˆ†åå·®çš„æ¡†æ¶ï¼Œé€šè¿‡æ•°æ®åˆæˆå¢å¼ºç°æœ‰åŸºå‡†ï¼Œè®¾è®¡å¤šç»´è¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰è¯„åˆ¤æ¨¡å‹çš„è¯„åˆ†ç¨³å®šæ€§å—åˆ°è¯„åˆ†åå·®çš„å¹²æ‰°ï¼Œè¿›ä¸€æ­¥çš„æ¢ç´¢æ€§å®éªŒä¸ºè¯„åˆ†æç¤ºæ¨¡æ¿çš„è®¾è®¡åŠåå·®çš„ç¼“è§£æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMä½œä¸ºè¯„åˆ¤è€…ä¸­è¯„åˆ†åå·®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¯„åˆ†è¯„ä¼°ä¸­å¯¹åå·®çš„å…³æ³¨ä¸è¶³ï¼Œå¯¼è‡´åˆ¤æ–­çš„å…¬å¹³æ€§å—åˆ°å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å®šä¹‰è¯„åˆ†åå·®ï¼Œå¹¶æ„å»ºä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œç³»ç»Ÿåœ°è¯„ä¼°LLMçš„è¯„åˆ†åå·®ï¼Œæ—¨åœ¨æé«˜è¯„åˆ¤çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®åˆæˆã€è¯„ä¼°æ•°æ®é›†æ„å»ºå’Œå¤šç»´è¯„ä¼°æŒ‡æ ‡è®¾è®¡ã€‚é¦–å…ˆï¼Œé€šè¿‡æ•°æ®åˆæˆå¢å¼ºç°æœ‰åŸºå‡†ï¼Œç„¶åè®¾è®¡é’ˆå¯¹è¯„åˆ†åå·®çš„è¯„ä¼°æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°å®šä¹‰å’Œè¯„ä¼°è¯„åˆ†åå·®ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œæä¾›äº†æ–°çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œè®¾è®¡äº†å¤šç»´åº¦çš„è¯„åˆ†æŒ‡æ ‡ï¼Œå…³æ³¨è¯„åˆ†æ¨¡æ¿ã€è¯„åˆ†IDå’Œå‚è€ƒç­”æ¡ˆé€‰æ‹©ç­‰æ–¹é¢ï¼Œä»¥å…¨é¢è¯„ä¼°è¯„åˆ†åå·®çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰è¯„åˆ¤æ¨¡å‹çš„è¯„åˆ†ç¨³å®šæ€§å—åˆ°è¯„åˆ†åå·®çš„æ˜¾è‘—å½±å“ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨ä¸åŒåå·®æ¡ä»¶ä¸‹è¯„åˆ†ç»“æœçš„æ³¢åŠ¨ã€‚é€šè¿‡è®¾è®¡çš„å¤šç»´è¯„ä¼°æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œé‡åŒ–è¯„åˆ†åå·®ï¼Œä¸ºåç»­æ”¹è¿›æä¾›äº†ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²è¯„ä¼°ã€å†…å®¹å®¡æ ¸å’Œè‡ªåŠ¨è¯„åˆ†ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿæå‡è¿™äº›é¢†åŸŸä¸­è¯„ä¼°çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œéšç€LLMçš„å¹¿æ³›åº”ç”¨ï¼Œç ”ç©¶æˆæœå°†å¯¹ä¼˜åŒ–è¯„ä¼°ç³»ç»Ÿè®¾è®¡å’Œæé«˜ç”¨æˆ·ä¿¡ä»»åº¦äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The remarkable performance of Large Language Models (LLMs) gives rise to``LLM-as-a-Judge'', where LLMs are employed as evaluators for complex tasks. Moreover, it has been widely adopted across fields such as Natural Language Processing (NLP), preference learning, and various specific domains. However, there are various biases within LLM-as-a-Judge, which adversely affect the fairness and reliability of judgments. Current research on evaluating or mitigating bias in LLM-as-a-Judge predominantly focuses on comparison-based evaluations, while systematic investigations into bias in scoring-based evaluations remain limited. Therefore, we define scoring bias in LLM-as-a-Judge as the scores differ when scoring judge models are bias-related perturbed, and provide a well-designed framework to comprehensively evaluate scoring bias. We augment existing LLM-as-a-Judge benchmarks through data synthesis to construct our evaluation dataset and design multi-faceted evaluation metrics. Our experimental results demonstrate that the scoring stability of existing judge models is disrupted by scoring biases. Further exploratory experiments and discussions provide valuable insights into the design of scoring prompt templates and the mitigation of scoring biases on aspects such as score rubrics, score IDs, and reference answer selection.

