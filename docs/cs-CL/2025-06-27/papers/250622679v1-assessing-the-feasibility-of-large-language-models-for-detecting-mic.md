---
layout: default
title: Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions
---

# Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22679" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22679v1</a>
  <a href="https://arxiv.org/pdf/2506.22679.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22679v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22679v1', 'Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ankush Raut, Projna Paromita, Sydney Begerowski, Suzanne Bell, Theodora Chaspari

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: 5 pages, 4 figures. Accepted to Interspeech 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ£€æµ‹å¤ªç©ºä»»åŠ¡å›¢é˜Ÿäº’åŠ¨ä¸­çš„å¾®è¡Œä¸º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¾®è¡Œä¸ºæ£€æµ‹` `å›¢é˜Ÿæ²Ÿé€š` `å¤ªç©ºä»»åŠ¡` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `åˆ†ç±»ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹å›¢é˜Ÿå¯¹è¯ä¸­çš„ç¨€æœ‰å¾®è¡Œä¸ºæ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¯¹æ¶ˆæè¨€è®ºçš„è¯†åˆ«èƒ½åŠ›è¾ƒå¼±ã€‚
2. è®ºæ–‡æå‡ºç»“åˆé›¶æ ·æœ¬åˆ†ç±»ã€å¾®è°ƒå’Œå¸¦é‡Šä¹‰çš„å¾®è°ƒç­‰æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è¡Œä¸ºé¢„æµ‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè§£ç å™¨æ¨¡å‹Llama-3.1åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå®F1åˆ†æ•°æ˜¾è‘—é«˜äºç¼–ç å™¨æ¨¡å‹ï¼Œæå‡æ•ˆæœæ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ£€æµ‹æ¨¡æ‹Ÿå¤ªç©ºä»»åŠ¡ä¸­å›¢é˜Ÿå¯¹è¯å¾®è¡Œä¸ºçš„å¯è¡Œæ€§ã€‚æˆ‘ä»¬åˆ†æäº†é›¶æ ·æœ¬åˆ†ç±»ã€å¾®è°ƒå’Œå¸¦é‡Šä¹‰çš„å¾®è°ƒç­‰æ–¹æ³•ï¼Œå‘ç°ç¼–ç å™¨æ¨¡å‹å¦‚RoBERTaå’ŒDistilBERTåœ¨æ£€æµ‹ç¨€æœ‰å¾®è¡Œä¸ºæ–¹é¢è¡¨ç°ä¸ä½³ï¼Œè€Œè§£ç å™¨æ¨¡å‹Llama-3.1çš„æŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬åœ¨åˆ†ç±»ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå®F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°44%å’Œ68%ã€‚è¿™äº›å‘ç°å¯¹å¼€å‘åˆ†æå›¢é˜Ÿæ²Ÿé€šåŠ¨æ€çš„è¯­éŸ³æŠ€æœ¯å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨æ–‡æœ¬ä¸ºå”¯ä¸€å¯ç”¨æ•°æ®çš„é«˜é£é™©ç¯å¢ƒä¸­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨æ¨¡æ‹Ÿå¤ªç©ºä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆæ£€æµ‹å›¢é˜Ÿå¯¹è¯ä¸­çš„å¾®è¡Œä¸ºï¼Œå°¤å…¶æ˜¯ç¨€æœ‰çš„æ¶ˆæè¨€è®ºã€‚ç°æœ‰çš„ç¼–ç å™¨æ¨¡å‹åœ¨æ­¤ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œæ— æ³•å‡†ç¡®è¯†åˆ«è¿™äº›å¾®è¡Œä¸ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¤šç§è®­ç»ƒæ–¹å¼ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬åˆ†ç±»å’Œå¾®è°ƒï¼Œæ¥æé«˜å¯¹å¾®è¡Œä¸ºçš„æ£€æµ‹èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ¨¡å‹å’Œè®­ç»ƒç­–ç•¥ï¼Œå¯»æ‰¾æœ€ä½³æ–¹æ¡ˆä»¥æå‡åˆ†ç±»æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹é€‰æ‹©ã€è®­ç»ƒç­–ç•¥å’Œè¯„ä¼°æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†æ¨¡æ‹Ÿå¤ªç©ºä»»åŠ¡çš„å¯¹è¯æ–‡æœ¬ï¼Œç„¶åé€‰æ‹©åˆé€‚çš„LLMsè¿›è¡Œè®­ç»ƒï¼Œæœ€åé€šè¿‡åˆ†ç±»ä»»åŠ¡è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è§£ç å™¨æ¨¡å‹Llama-3.1çš„æŒ‡ä»¤å¾®è°ƒåº”ç”¨äºå¾®è¡Œä¸ºæ£€æµ‹ï¼Œæ˜¾è‘—æå‡äº†å¯¹ç¨€æœ‰å¾®è¡Œä¸ºçš„è¯†åˆ«èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿç¼–ç å™¨æ¨¡å‹å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨åŠ æƒå¾®è°ƒç­–ç•¥æ¥åº”å¯¹æ•°æ®ä¸å¹³è¡¡é—®é¢˜ï¼Œå¹¶å¯¹æ¨¡å‹çš„è¶…å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä»¥æé«˜åˆ†ç±»ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè§£ç å™¨æ¨¡å‹Llama-3.1çš„æŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬åœ¨3ç±»åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†44%çš„å®F1åˆ†æ•°ï¼Œè€Œåœ¨äºŒåˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†68%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¼–ç å™¨æ¨¡å‹å¦‚RoBERTaå’ŒDistilBERTåœ¨æ£€æµ‹ç¨€æœ‰å¾®è¡Œä¸ºæ—¶è¡¨ç°ä¸ä½³ï¼Œæœªèƒ½æœ‰æ•ˆè¯†åˆ«æ¶ˆæè¨€è®ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤ªç©ºä»»åŠ¡ã€å†›äº‹è®­ç»ƒå’Œé«˜é£é™©ç¯å¢ƒä¸­çš„å›¢é˜Ÿæ²Ÿé€šåˆ†æã€‚é€šè¿‡æé«˜å¯¹å¾®è¡Œä¸ºçš„æ£€æµ‹èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå›¢é˜Ÿåä½œæ•ˆç‡ï¼Œæ”¹å–„æ²Ÿé€šç­–ç•¥ï¼Œè¿›è€Œæå‡ä»»åŠ¡æˆåŠŸç‡å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We explore the feasibility of large language models (LLMs) in detecting subtle expressions of micro-behaviors in team conversations using transcripts collected during simulated space missions. Specifically, we examine zero-shot classification, fine-tuning, and paraphrase-augmented fine-tuning with encoder-only sequence classification LLMs, as well as few-shot text generation with decoder-only causal language modeling LLMs, to predict the micro-behavior associated with each conversational turn (i.e., dialogue). Our findings indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to detect underrepresented micro-behaviors, particularly discouraging speech, even with weighted fine-tuning. In contrast, the instruction fine-tuned version of Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best models achieving macro F1-scores of 44% for 3-way classification and 68% for binary classification. These results have implications for the development of speech technologies aimed at analyzing team communication dynamics and enhancing training interventions in high-stakes environments such as space missions, particularly in scenarios where text is the only accessible data.

