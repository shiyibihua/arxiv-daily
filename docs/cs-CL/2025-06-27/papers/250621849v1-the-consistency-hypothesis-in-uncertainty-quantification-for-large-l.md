---
layout: default
title: The Consistency Hypothesis in Uncertainty Quantification for Large Language Models
---

# The Consistency Hypothesis in Uncertainty Quantification for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21849" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21849v1</a>
  <a href="https://arxiv.org/pdf/2506.21849.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21849v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21849v1', 'The Consistency Hypothesis in Uncertainty Quantification for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Quan Xiao, Debarun Bhattacharjya, Balaji Ganesan, Radu Marinescu, Katsiaryna Mirylenka, Nhan H Pham, Michael Glass, Junkyu Lee

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: Accepted by The Conference on Uncertainty in Artificial Intelligence (UAI) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€è‡´æ€§å‡è®¾ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§é‡åŒ–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ç¡®å®šæ€§é‡åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `ä¸€è‡´æ€§å‡è®¾` `é»‘ç®±æ–¹æ³•` `ç½®ä¿¡åº¦ä¼°è®¡` `ç»Ÿè®¡æ£€éªŒ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•åœ¨ä¼°è®¡å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºç½®ä¿¡åº¦æ—¶å­˜åœ¨éšå«å‡è®¾ï¼Œç¼ºä¹ç³»ç»Ÿæ€§éªŒè¯ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€è‡´æ€§å‡è®¾ï¼Œå¹¶é€šè¿‡æ•°å­¦é™ˆè¿°å’Œç»Ÿè®¡æ£€éªŒæ¥è¯„ä¼°LLMè¾“å‡ºçš„ä¸€è‡´æ€§ã€‚
3. å®éªŒè¯æ˜ï¼ŒåŸºäºä¸€è‡´æ€§å‡è®¾çš„æ— æ•°æ®é»‘ç®±UQæ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œå±•ç°äº†å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼°è®¡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºçš„ç½®ä¿¡åº¦å¯¹äºéœ€è¦é«˜ç”¨æˆ·ä¿¡ä»»çš„å®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚åŸºäºæ¨¡å‹APIè®¿é—®çš„é»‘ç®±ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ–¹æ³•å› å…¶å®é™…ä¼˜åŠ¿è€Œå—åˆ°å…³æ³¨ã€‚æœ¬æ–‡æ¢è®¨äº†å¤šä¸ªUQæ–¹æ³•èƒŒåçš„éšå«å‡è®¾ï¼Œå³å°†ç”Ÿæˆä¸€è‡´æ€§ä½œä¸ºç½®ä¿¡åº¦çš„ä»£ç†ï¼Œå½¢æˆä¸€è‡´æ€§å‡è®¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰ä¸ªæ•°å­¦é™ˆè¿°åŠç›¸åº”çš„ç»Ÿè®¡æ£€éªŒï¼Œä»¥æ•æ‰è¯¥å‡è®¾çš„å˜ä½“ï¼Œå¹¶è¯„ä¼°LLMè¾“å‡ºåœ¨ä¸åŒä»»åŠ¡ä¸­çš„ä¸€è‡´æ€§ã€‚é€šè¿‡å¯¹8ä¸ªåŸºå‡†æ•°æ®é›†å’Œ3ä¸ªä»»åŠ¡ï¼ˆé—®ç­”ã€æ–‡æœ¬æ‘˜è¦å’Œæ–‡æœ¬åˆ°SQLï¼‰çš„å®è¯ç ”ç©¶ï¼ŒéªŒè¯äº†è¯¥å‡è®¾åœ¨ä¸åŒè®¾ç½®ä¸‹çš„æ™®éæ€§ã€‚æˆ‘ä»¬å¼ºè°ƒäº†`Sim-Any`å‡è®¾çš„å¯æ“ä½œæ€§ï¼Œå¹¶æå‡ºäº†æ— æ•°æ®çš„é»‘ç®±UQæ–¹æ³•ï¼Œé€šè¿‡èšåˆç”Ÿæˆä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥ä¼°è®¡ç½®ä¿¡åº¦ï¼Œè¿™äº›æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†æœ€æ¥è¿‘çš„åŸºçº¿ï¼Œå±•ç¤ºäº†ä¸€è‡´æ€§å‡è®¾çš„å®é™…ä»·å€¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºç½®ä¿¡åº¦ä¼°è®¡ä¸­çš„éšå«å‡è®¾é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹ç³»ç»Ÿæ€§éªŒè¯ï¼Œå¯¼è‡´ç½®ä¿¡åº¦è¯„ä¼°ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€è‡´æ€§å‡è®¾ï¼Œåˆ©ç”¨ç”Ÿæˆä¸€è‡´æ€§ä½œä¸ºç½®ä¿¡åº¦çš„ä»£ç†ï¼Œé€šè¿‡æ•°å­¦é™ˆè¿°å’Œç»Ÿè®¡æ£€éªŒæ¥éªŒè¯è¿™ä¸€å‡è®¾çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œå®šä¹‰ä¸€è‡´æ€§å‡è®¾çš„æ•°å­¦é™ˆè¿°ï¼›å…¶æ¬¡ï¼Œè®¾è®¡ç»Ÿè®¡æ£€éªŒæ–¹æ³•ä»¥è¯„ä¼°å‡è®¾çš„æœ‰æ•ˆæ€§ï¼›æœ€åï¼ŒåŸºäº`Sim-Any`å‡è®¾æå‡ºæ— æ•°æ®çš„é»‘ç®±UQæ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†ç”Ÿæˆä¸€è‡´æ€§å½¢å¼åŒ–ä¸ºä¸€è‡´æ€§å‡è®¾ï¼Œå¹¶æå‡ºåŸºäºæ­¤çš„æ— æ•°æ®é»‘ç®±UQæ–¹æ³•ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºæœ‰æ•ˆçš„ç½®ä¿¡åº¦ä¼°è®¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šä¸ªç»Ÿè®¡æ£€éªŒæ¥éªŒè¯ä¸€è‡´æ€§å‡è®¾çš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡èšåˆç”Ÿæˆä¹‹é—´çš„ç›¸ä¼¼æ€§æ¥å®ç°ç½®ä¿¡åº¦çš„ä¼°è®¡ï¼Œç¡®ä¿æ–¹æ³•çš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºä¸€è‡´æ€§å‡è®¾çš„æ— æ•°æ®é»‘ç®±UQæ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨é—®ç­”å’Œæ–‡æœ¬æ‘˜è¦ä»»åŠ¡ä¸­ï¼Œç½®ä¿¡åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ç›¸æ¯”æœ€æ¥è¿‘çš„åŸºçº¿æå‡äº†çº¦15%ã€‚è¿™ä¸€å‘ç°éªŒè¯äº†ç†è®ºå‡è®¾çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨æ–‡æœ¬æ‘˜è¦ç”Ÿæˆå’Œæ•°æ®åº“æŸ¥è¯¢ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜å¤§è¯­è¨€æ¨¡å‹çš„è¾“å‡ºç½®ä¿¡åº¦ä¼°è®¡ï¼Œèƒ½å¤Ÿå¢å¼ºç”¨æˆ·å¯¹ç³»ç»Ÿçš„ä¿¡ä»»ï¼Œä¿ƒè¿›å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºä¸ç¡®å®šæ€§é‡åŒ–çš„æ™ºèƒ½åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Estimating the confidence of large language model (LLM) outputs is essential for real-world applications requiring high user trust. Black-box uncertainty quantification (UQ) methods, relying solely on model API access, have gained popularity due to their practical benefits. In this paper, we examine the implicit assumption behind several UQ methods, which use generation consistency as a proxy for confidence, an idea we formalize as the consistency hypothesis. We introduce three mathematical statements with corresponding statistical tests to capture variations of this hypothesis and metrics to evaluate LLM output conformity across tasks. Our empirical investigation, spanning 8 benchmark datasets and 3 tasks (question answering, text summarization, and text-to-SQL), highlights the prevalence of the hypothesis under different settings. Among the statements, we highlight the `Sim-Any' hypothesis as the most actionable, and demonstrate how it can be leveraged by proposing data-free black-box UQ methods that aggregate similarities between generations for confidence estimation. These approaches can outperform the closest baselines, showcasing the practical value of the empirically observed consistency hypothesis.

