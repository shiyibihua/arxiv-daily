---
layout: default
title: A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs
---

# A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21881" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21881v1</a>
  <a href="https://arxiv.org/pdf/2506.21881.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21881v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21881v1', 'A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sean Kim, Hyuhng Joon Kim

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: This paper is accepted to ACL Student Research Workshop (SRW) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒå±‚è¯„ä¼°æ¡†æ¶ä»¥åˆ†æLLMsä¸­çš„åœ°ç¼˜æ”¿æ²»ä¸æ–‡åŒ–åè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åè§åˆ†æ` `å¤šè¯­è¨€è¯„ä¼°` `åœ°ç¼˜æ”¿æ²»` `æ–‡åŒ–æ•æ„Ÿæ€§` `æ•°æ®é›†æ„å»º` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„è¡¨ç°å°šæœªå¾—åˆ°å……åˆ†ç†è§£ï¼Œå°¤å…¶æ˜¯åœ¨äº‹å®ä¸äº‰è®®é—®é¢˜ä¸Šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåŒå±‚è¯„ä¼°æ¡†æ¶ï¼Œåˆ†åˆ«é’ˆå¯¹æ¨¡å‹åè§å’Œæ¨ç†åè§è¿›è¡Œåˆ†æï¼Œä»¥æ­ç¤ºLLMsçš„è¡Œä¸ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨äº‹å®é—®é¢˜ä¸Šä¿æŒä¸€è‡´æ€§ï¼Œä½†åœ¨åœ°ç¼˜æ”¿æ²»æ•æ„Ÿé—®é¢˜ä¸Šåˆ™å—åˆ°è®­ç»ƒèƒŒæ™¯å’ŒæŸ¥è¯¢è¯­è¨€çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ ·åŒ–è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç†è§£å…¶åœ¨äº‹å®å’Œäº‰è®®åœºæ™¯ä¸­çš„è¡¨ç°è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯å½“å…¶è¾“å‡ºå¯èƒ½å½±å“å…¬ä¼—èˆ†è®ºæˆ–å¼ºåŒ–ä¸»å¯¼å™äº‹æ—¶ã€‚æœ¬æ–‡å®šä¹‰äº†LLMsä¸­çš„ä¸¤ç§åè§ï¼šæ¨¡å‹åè§ï¼ˆæºäºæ¨¡å‹è®­ç»ƒï¼‰å’Œæ¨ç†åè§ï¼ˆç”±æŸ¥è¯¢è¯­è¨€å¼•èµ·ï¼‰ï¼Œé€šè¿‡ä¸¤é˜¶æ®µè¯„ä¼°è¿›è¡Œåˆ†æã€‚ç¬¬ä¸€é˜¶æ®µè¯„ä¼°LLMsåœ¨å­˜åœ¨å•ä¸€å¯éªŒè¯ç­”æ¡ˆçš„äº‹å®é—®é¢˜ä¸Šçš„ä¸€è‡´æ€§ï¼Œç¬¬äºŒé˜¶æ®µåˆ™æ¢è®¨åœ°ç¼˜æ”¿æ²»æ•æ„Ÿäº‰è®®ï¼Œå“åº”å¯èƒ½åæ˜ æ–‡åŒ–åµŒå…¥æˆ–æ„è¯†å½¢æ€å€¾å‘ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªæ‰‹åŠ¨ç­–åˆ’çš„æ•°æ®é›†ï¼Œæ¶µç›–å››ç§è¯­è¨€å’Œé—®é¢˜ç±»å‹çš„äº‹å®ä¸äº‰è®®é—®ç­”ã€‚ç»“æœæ˜¾ç¤ºï¼Œç¬¬ä¸€é˜¶æ®µè¡¨ç°å‡ºæŸ¥è¯¢è¯­è¨€å¼•èµ·çš„å¯¹é½ï¼Œè€Œç¬¬äºŒé˜¶æ®µåˆ™åæ˜ æ¨¡å‹è®­ç»ƒèƒŒæ™¯ä¸æŸ¥è¯¢è¯­è¨€ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚æœ¬æ–‡ä¸ºè¯„ä¼°LLMåœ¨ä¸­ç«‹å’Œæ•æ„Ÿä¸»é¢˜ä¸Šçš„è¡¨ç°æä¾›äº†ç»“æ„åŒ–æ¡†æ¶ï¼Œä¸ºæœªæ¥çš„LLMéƒ¨ç½²å’Œå¤šè¯­è¨€ç¯å¢ƒä¸­çš„æ–‡åŒ–æ•æ„Ÿè¯„ä¼°å®è·µæä¾›äº†è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„åè§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†æ¨¡å‹åè§ä¸æ¨ç†åè§çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åŒé˜¶æ®µè¯„ä¼°æ¡†æ¶ï¼Œåˆ†åˆ«åˆ†ææ¨¡å‹åœ¨äº‹å®é—®é¢˜å’Œåœ°ç¼˜æ”¿æ²»æ•æ„Ÿé—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºåè§æ¥æºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“è¯„ä¼°åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µé’ˆå¯¹äº‹å®é—®é¢˜è¿›è¡Œä¸€è‡´æ€§è¯„ä¼°ï¼Œç¬¬äºŒé˜¶æ®µæ¢è®¨åœ°ç¼˜æ”¿æ²»äº‰è®®ï¼Œä½¿ç”¨æ‰‹åŠ¨ç­–åˆ’çš„æ•°æ®é›†è¿›è¡Œåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºäº†æ¨¡å‹åè§ä¸æ¨ç†åè§çš„æ˜ç¡®åŒºåˆ†ï¼Œæ„å»ºäº†å¤šè¯­è¨€æ•°æ®é›†ï¼Œæä¾›äº†ç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œæ¶µç›–äº†å››ç§è¯­è¨€å’Œå¤šç§é—®é¢˜ç±»å‹ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œä»£è¡¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç¬¬ä¸€é˜¶æ®µçš„äº‹å®é—®é¢˜è¯„ä¼°ä¸­ï¼Œæ¨¡å‹åœ¨ä¸åŒæŸ¥è¯¢è¯­è¨€ä¸Šä¿æŒäº†ä¸€è‡´æ€§ï¼Œè€Œåœ¨ç¬¬äºŒé˜¶æ®µçš„åœ°ç¼˜æ”¿æ²»æ•æ„Ÿé—®é¢˜ä¸­ï¼Œæ¨¡å‹çš„å“åº”åˆ™å—åˆ°è®­ç»ƒèƒŒæ™¯å’ŒæŸ¥è¯¢è¯­è¨€çš„æ˜¾è‘—å½±å“ã€‚è¿™è¡¨æ˜æ¨¡å‹çš„è¡Œä¸ºåœ¨ä¸åŒåœºæ™¯ä¸‹å­˜åœ¨æ˜æ˜¾å·®å¼‚ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„åº”ç”¨æä¾›äº†é‡è¦çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…è¯†åˆ«å’Œå‡è½»æ¨¡å‹è¾“å‡ºä¸­çš„åè§ï¼Œä¿ƒè¿›æ›´å…¬å¹³å’Œé€æ˜çš„AIç³»ç»Ÿã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºç¤¾äº¤åª’ä½“ã€æ–°é—»ç”Ÿæˆã€æ•™è‚²ç­‰é¢†åŸŸï¼Œæå‡å…¬ä¼—å¯¹AIç”Ÿæˆå†…å®¹çš„ä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly deployed across diverse linguistic and cultural contexts, understanding their behavior in both factual and disputable scenarios is essential, especially when their outputs may shape public opinion or reinforce dominant narratives. In this paper, we define two types of bias in LLMs: model bias (bias stemming from model training) and inference bias (bias induced by the language of the query), through a two-phase evaluation. Phase 1 evaluates LLMs on factual questions where a single verifiable answer exists, assessing whether models maintain consistency across different query languages. Phase 2 expands the scope by probing geopolitically sensitive disputes, where responses may reflect culturally embedded or ideologically aligned perspectives. We construct a manually curated dataset spanning both factual and disputable QA, across four languages and question types. The results show that Phase 1 exhibits query language induced alignment, while Phase 2 reflects an interplay between the model's training context and query language. This paper offers a structured framework for evaluating LLM behavior across neutral and sensitive topics, providing insights for future LLM deployment and culturally aware evaluation practices in multilingual contexts.

