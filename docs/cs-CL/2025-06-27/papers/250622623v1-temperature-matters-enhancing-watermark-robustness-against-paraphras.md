---
layout: default
title: Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks
---

# Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22623" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22623v1</a>
  <a href="https://arxiv.org/pdf/2506.22623.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22623v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22623v1', 'Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Badr Youbi Idrissi, Monica Millunzi, Amelia Sorrenti, Lorenzo Baraldi, Daryna Dementieva

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°æ°´å°æ–¹æ³•ä»¥å¢å¼ºå¯¹æŠ—æ”¹å†™æ”»å‡»çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ°´å°æŠ€æœ¯` `åˆæˆæ–‡æœ¬` `é²æ£’æ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬ç”Ÿæˆ` `ä¼¦ç†åº”ç”¨` `æ”¹å†™æ”»å‡»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ°´å°æ–¹æ³•åœ¨é¢å¯¹æ”¹å†™æ”»å‡»æ—¶è¡¨ç°å‡ºè¾ƒå¤§çš„è„†å¼±æ€§ï¼Œéš¾ä»¥æœ‰æ•ˆè¯†åˆ«åˆæˆæ–‡æœ¬ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ°´å°æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜æ°´å°åœ¨æ”¹å†™æ–‡æœ¬ä¸­çš„é²æ£’æ€§ï¼Œç¡®ä¿åˆæˆæ–‡æœ¬çš„å¯è¯†åˆ«æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨é²æ£’æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„æ°´å°æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å½“ä»Šç¤¾ä¼šï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºå¼ºå¤§çš„å·¥å…·æ­£åœ¨å„ä¸ªé¢†åŸŸä¸­å‘æŒ¥ä½œç”¨ã€‚å°½ç®¡å…¶åº”ç”¨ä¸ºç”¨æˆ·æä¾›äº†å®è´µæ”¯æŒï¼Œä½†ä¹Ÿå¼•å‘äº†æ½œåœ¨æ»¥ç”¨çš„æ‹…å¿§ã€‚å› æ­¤ï¼Œä¸€äº›å­¦æœ¯ç ”ç©¶å¼€å§‹æ¢ç´¢æ°´å°æŠ€æœ¯ï¼Œé€šè¿‡åœ¨æœºå™¨ç”Ÿæˆæ–‡æœ¬ä¸­åµŒå…¥æ ‡è®°æ¥å®ç°ç®—æ³•è¯†åˆ«ã€‚æœ¬ç ”ç©¶æ—¨åœ¨å¼€å‘ä¸€ç§æ–°æ–¹æ³•ï¼Œä»¥æ£€æµ‹åˆæˆæ–‡æœ¬ï¼Œç¡®ä¿LLMsåœ¨AIé©±åŠ¨æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¼¦ç†åº”ç”¨ã€‚ç ”ç©¶é¦–å…ˆå¤åˆ¶äº†å…ˆå‰åŸºçº¿ç ”ç©¶çš„å‘ç°ï¼Œå¼ºè°ƒå…¶å¯¹ç”Ÿæˆæ¨¡å‹å˜åŒ–çš„æ•æ„Ÿæ€§ã€‚éšåï¼Œæå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ°´å°æ–¹æ³•ï¼Œå¹¶é€šè¿‡ä¸¥æ ¼è¯„ä¼°å…¶åœ¨æ”¹å†™ç”Ÿæˆæ–‡æœ¬ä¸­çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç°æœ‰æ°´å°æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€ææ–¹æ³•å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ°´å°æ–¹æ³•åœ¨é¢å¯¹æ”¹å†™æ”»å‡»æ—¶çš„è„†å¼±æ€§ï¼Œå¯¼è‡´åˆæˆæ–‡æœ¬éš¾ä»¥è¢«æœ‰æ•ˆè¯†åˆ«çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¸åŒç”Ÿæˆæ¨¡å‹ä¸‹çš„è¡¨ç°ä¸ç¨³å®šï¼Œç¼ºä¹è¶³å¤Ÿçš„é²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ°´å°æ–¹æ³•ï¼Œé€šè¿‡ä¼˜åŒ–æ°´å°çš„åµŒå…¥æ–¹å¼å’Œå‚æ•°è®¾ç½®ï¼Œå¢å¼ºå…¶åœ¨æ–‡æœ¬æ”¹å†™åçš„å¯è¯†åˆ«æ€§ï¼Œä»è€Œæé«˜é²æ£’æ€§ã€‚è®¾è®¡æ€è·¯åŸºäºå¯¹æ”¹å†™æ–‡æœ¬ç‰¹å¾çš„æ·±å…¥åˆ†æã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ°´å°ç”Ÿæˆæ¨¡å—ã€æ–‡æœ¬åµŒå…¥æ¨¡å—å’Œé²æ£’æ€§è¯„ä¼°æ¨¡å—ã€‚æ°´å°ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆæ°´å°æ ‡è®°ï¼Œæ–‡æœ¬åµŒå…¥æ¨¡å—å°†æ°´å°åµŒå…¥åˆ°ç”Ÿæˆæ–‡æœ¬ä¸­ï¼Œé²æ£’æ€§è¯„ä¼°æ¨¡å—åˆ™é€šè¿‡å¯¹æ¯”å®éªŒè¯„ä¼°æ°´å°çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ°´å°åµŒå…¥ç­–ç•¥ï¼Œä½¿å¾—æ°´å°åœ¨æ–‡æœ¬æ”¹å†™åä»èƒ½ä¿æŒè¾ƒé«˜çš„è¯†åˆ«ç‡ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰æ°´å°æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†å¯¹æŠ—æ”¹å†™æ”»å‡»çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®ºæ–‡å¯¹æ°´å°çš„å¼ºåº¦å’ŒåµŒå…¥ä½ç½®è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡æ°´å°çš„å¯è§æ€§å’Œæ–‡æœ¬çš„è‡ªç„¶æ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šï¼Œç»“åˆäº†å¤šå±‚æ¬¡ç‰¹å¾æå–ï¼Œä»¥å¢å¼ºæ°´å°çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ°´å°æ–¹æ³•åœ¨å¯¹æŠ—æ”¹å†™æ”»å‡»æ—¶çš„é²æ£’æ€§æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–‡æœ¬ç”Ÿæˆã€å†…å®¹å®¡æ ¸å’Œä¿¡æ¯å®‰å…¨ç­‰ã€‚é€šè¿‡æé«˜æ°´å°çš„é²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢åˆæˆæ–‡æœ¬çš„æ»¥ç”¨ï¼Œç¡®ä¿AIç”Ÿæˆå†…å®¹çš„ä¼¦ç†ä½¿ç”¨ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the present-day scenario, Large Language Models (LLMs) are establishing their presence as powerful instruments permeating various sectors of society. While their utility offers valuable support to individuals, there are multiple concerns over potential misuse. Consequently, some academic endeavors have sought to introduce watermarking techniques, characterized by the inclusion of markers within machine-generated text, to facilitate algorithmic identification. This research project is focused on the development of a novel methodology for the detection of synthetic text, with the overarching goal of ensuring the ethical application of LLMs in AI-driven text generation. The investigation commences with replicating findings from a previous baseline study, thereby underscoring its susceptibility to variations in the underlying generation model. Subsequently, we propose an innovative watermarking approach and subject it to rigorous evaluation, employing paraphrased generated text to asses its robustness. Experimental results highlight the robustness of our proposal compared to the~\cite{aarson} watermarking method.

