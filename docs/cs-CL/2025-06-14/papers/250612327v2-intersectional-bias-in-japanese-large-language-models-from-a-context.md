---
layout: default
title: Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective
---

# Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.12327" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.12327v2</a>
  <a href="https://arxiv.org/pdf/2506.12327.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.12327v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.12327v2', 'Intersectional Bias in Japanese Large Language Models from a Contextualized Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hitomi Yanaka, Xinqi He, Jie Lu, Namgi Han, Sunjin Oh, Ryoma Kumon, Yuma Matsuoka, Katsuhiko Watabe, Yuko Itatsu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-14 (æ›´æ–°: 2025-07-27)

**å¤‡æ³¨**: Accepted to the 6th Workshop on Gender Bias in Natural Language Processing (GeBNLP2025) at ACL2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºæ—¥æœ¬åŸºå‡†æ•°æ®é›†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„äº¤å‰åè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äº¤å‰åè§` `ç¤¾ä¼šå±æ€§` `æ•°æ®é›†æ„å»º` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºå•ä¸€ç¤¾ä¼šå±æ€§çš„åè§ï¼Œå¿½è§†äº†äº¤å‰æ€§åè§çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†inter-JBBQåŸºå‡†æ•°æ®é›†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„äº¤å‰åè§ï¼Œæä¾›äº†æ–°çš„è¯„ä¼°æ¡†æ¶ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oå’ŒSwallowåœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­è¡¨ç°å‡ºä¸åŒçš„åè§è¾“å‡ºï¼Œæ­ç¤ºäº†äº¤å‰åè§çš„å­˜åœ¨å’Œå½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç¤¾ä¼šåè§çš„ç ”ç©¶é€æ¸å¢å¤šã€‚å¤§å¤šæ•°ç ”ç©¶é›†ä¸­äºå•ä¸€ç¤¾ä¼šå±æ€§çš„åè§ï¼Œè€Œç¤¾ä¼šç§‘å­¦ç ”ç©¶è¡¨æ˜ï¼Œç¤¾ä¼šåè§å¾€å¾€ä»¥äº¤å‰æ€§å½¢å¼å‡ºç°ã€‚æœ¬ç ”ç©¶æ„å»ºäº†æ—¥æœ¬åŸºå‡†æ•°æ®é›†inter-JBBQï¼Œæ—¨åœ¨è¯„ä¼°LLMsåœ¨é—®ç­”åœºæ™¯ä¸­çš„äº¤å‰åè§ã€‚é€šè¿‡å¯¹GPT-4oå’ŒSwallowçš„åˆ†æï¼Œæˆ‘ä»¬å‘ç°å³ä½¿åœ¨ç¤¾ä¼šå±æ€§ç»„åˆç›¸åŒçš„æƒ…å†µä¸‹ï¼Œåè§è¾“å‡ºä¹Ÿä¼šå› ä¸Šä¸‹æ–‡è€Œå¼‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é—®ç­”åœºæ™¯ä¸­å­˜åœ¨çš„äº¤å‰åè§è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šå…³æ³¨å•ä¸€å±æ€§ï¼Œæœªèƒ½å…¨é¢åæ˜ åè§çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºinter-JBBQæ•°æ®é›†ï¼Œè®ºæ–‡æä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶è€ƒè™‘å¤šä¸ªç¤¾ä¼šå±æ€§çš„äº¤å‰å½±å“ï¼Œä»è€Œæ›´å…¨é¢åœ°åˆ†ææ¨¡å‹çš„åè§è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆè®¾è®¡äº†inter-JBBQæ•°æ®é›†ï¼ŒåŒ…å«å¤šç§ç¤¾ä¼šå±æ€§çš„ç»„åˆã€‚ç„¶åï¼Œä½¿ç”¨è¯¥æ•°æ®é›†å¯¹GPT-4oå’ŒSwallowè¿›è¡Œè¯„ä¼°ï¼Œåˆ†æå…¶åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„è¾“å‡ºåè§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†äº¤å‰åè§çš„è¯„ä¼°æ¡†æ¶ï¼Œå¼ºè°ƒäº†ä¸Šä¸‹æ–‡å¯¹åè§è¾“å‡ºçš„å½±å“ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•ä¸€å±æ€§åè§è¯„ä¼°æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºè¿‡ç¨‹ä¸­ï¼Œç²¾å¿ƒè®¾è®¡äº†ç¤¾ä¼šå±æ€§çš„ç»„åˆå’Œä¸Šä¸‹æ–‡åœºæ™¯ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oå’ŒSwallowåœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„åè§å·®å¼‚ï¼Œæ­ç¤ºäº†äº¤å‰åè§çš„å¤æ‚æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨ç›¸åŒç¤¾ä¼šå±æ€§ç»„åˆä¸‹çš„è¾“å‡ºåè§å˜åŒ–ï¼Œæ˜¾ç¤ºå‡ºä¸Šä¸‹æ–‡å¯¹åè§çš„å½±å“ç¨‹åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€ç¤¾ä¼šç§‘å­¦ç ”ç©¶åŠäººå·¥æ™ºèƒ½ä¼¦ç†ç­‰ã€‚é€šè¿‡æ›´å…¨é¢åœ°ç†è§£å’Œè¯„ä¼°æ¨¡å‹çš„åè§ï¼Œèƒ½å¤Ÿä¸ºæ¨¡å‹çš„æ”¹è¿›å’Œç¤¾ä¼šè´£ä»»æä¾›æŒ‡å¯¼ï¼Œä¿ƒè¿›æ›´å…¬å¹³çš„AIç³»ç»Ÿå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> An increasing number of studies have examined the social bias of rapidly developed large language models (LLMs). Although most of these studies have focused on bias occurring in a single social attribute, research in social science has shown that social bias often occurs in the form of intersectionality -- the constitutive and contextualized perspective on bias aroused by social attributes. In this study, we construct the Japanese benchmark inter-JBBQ, designed to evaluate the intersectional bias in LLMs on the question-answering setting. Using inter-JBBQ to analyze GPT-4o and Swallow, we find that biased output varies according to its contexts even with the equal combination of social attributes.

