---
layout: default
title: Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning
---

# Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.12307" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.12307v2</a>
  <a href="https://arxiv.org/pdf/2506.12307.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.12307v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.12307v2', 'Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaotian Zhang, Yuan Wang, Zhaopeng Feng, Ruizhe Chen, Zhijie Zhou, Yan Zhang, Hongxia Xu, Jian Wu, Zuozhu Liu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-14 (æ›´æ–°: 2025-06-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMed-U1ä»¥è§£å†³åŒ»ç–—é—®ç­”ä»»åŠ¡ä¸­çš„ç»Ÿä¸€æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»ç–—é—®ç­”` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `å¤šç›®æ ‡ä¼˜åŒ–` `æ¨¡å‹æ³›åŒ–` `å¥–åŠ±æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŒ»ç–—é—®ç­”ç³»ç»Ÿç¼ºä¹ç»Ÿä¸€æ¡†æ¶ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†å¤šæ ·åŒ–çš„é—®ç­”ä»»åŠ¡ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. Med-U1é€šè¿‡å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ å’Œæ··åˆå¥–åŠ±å‡½æ•°ï¼Œæ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„åŒ»ç–—é—®ç­”æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ã€‚
3. å®éªŒè¯æ˜ï¼ŒMed-U1åœ¨å¤šä¸ªåŒ»ç–—é—®ç­”åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†è®¸å¤šç°æœ‰çš„ä¸“ç”¨æ¨¡å‹ï¼Œå¹¶åœ¨åˆ†å¸ƒå¤–ä»»åŠ¡ä¸Šå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒ»ç–—é—®ç­”ï¼ˆQAï¼‰æ¶µç›–äº†å¤šç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬é€‰æ‹©é¢˜ã€å¼€æ”¾å¼æ–‡æœ¬ç”Ÿæˆå’Œå¤æ‚è®¡ç®—æ¨ç†ã€‚å°½ç®¡åœ¨æ¨ç†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ–¹é¢å–å¾—äº†ä¸€å®šè¿›å±•ï¼Œä½†å…¶åœ¨å…¨é¢åŒ»ç–—ç†è§£æ–¹é¢çš„èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡æå‡ºäº†Med-U1ï¼Œä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºåŒ»ç–—QAä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ã€‚Med-U1é‡‡ç”¨å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ï¼Œç»“åˆåŸºäºè§„åˆ™çš„æ··åˆäºŒå…ƒå¥–åŠ±å‡½æ•°ï¼Œå¹¶å¼•å…¥é•¿åº¦æƒ©ç½šä»¥ç®¡ç†è¾“å‡ºå†—é•¿æ€§ã€‚é€šè¿‡å¤šç›®æ ‡å¥–åŠ±ä¼˜åŒ–ï¼ŒMed-U1å¼•å¯¼LLMsç”Ÿæˆç®€æ´ä¸”å¯éªŒè¯çš„æ¨ç†é“¾ã€‚å®éªŒè¯æ˜ï¼ŒMed-U1åœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŒ»ç–—QAåŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„ä¸“ç”¨æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŒ»ç–—é—®ç­”ä»»åŠ¡ä¸­ç¼ºä¹ç»Ÿä¸€æ¨ç†æ¡†æ¶çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–é—®ç­”ä»»åŠ¡æ—¶ï¼Œæ¨ç†èƒ½åŠ›å’Œè¾“å‡ºè´¨é‡å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMed-U1çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ï¼Œç»“åˆæ··åˆè§„åˆ™çš„å¥–åŠ±å‡½æ•°ï¼Œä¼˜åŒ–åŒ»ç–—é—®ç­”çš„æ¨ç†è¿‡ç¨‹ï¼Œç¡®ä¿ç”Ÿæˆçš„ç­”æ¡ˆç®€æ´ä¸”å¯éªŒè¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMed-U1çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†é˜¶æ®µã€‚é¦–å…ˆï¼Œåˆ©ç”¨å¤§è§„æ¨¡åŒ»ç–—æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç„¶åé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨ç†é“¾çš„è´¨é‡ï¼Œæœ€åç”Ÿæˆå¤šç§æ ¼å¼çš„ç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMed-U1çš„ä¸»è¦åˆ›æ–°åœ¨äºé‡‡ç”¨äº†çº¯å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ ä¸æ··åˆå¥–åŠ±æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯å¼•å…¥äº†é•¿åº¦æƒ©ç½šï¼Œä»¥æ§åˆ¶è¾“å‡ºçš„å†—é•¿æ€§ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒMed-U1ä½¿ç”¨äº†å¤šç›®æ ‡å¥–åŠ±ä¼˜åŒ–ç­–ç•¥ï¼Œè®¾ç½®äº†é€‚å½“çš„é•¿åº¦æƒ©ç½šå‚æ•°ï¼Œå¹¶è®¾è®¡äº†é€‚åˆåŒ»ç–—é¢†åŸŸçš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æ¨ç†é“¾æ—¢ç®€æ´åˆå‡†ç¡®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŒ»ç–—é—®ç­”åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMed-U1æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„ä¸“ç”¨æ¨¡å‹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šï¼ŒMed-U1çš„å‡†ç¡®ç‡æé«˜äº†15%ï¼Œå¹¶åœ¨å¤„ç†åˆ†å¸ƒå¤–ä»»åŠ¡æ—¶è¡¨ç°å‡ºè‰²ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Med-U1çš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºåŒ»ç–—é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½åŒ»ç–—åŠ©æ‰‹å’Œä¸´åºŠå†³ç­–æ”¯æŒå·¥å…·ç­‰é¢†åŸŸã€‚é€šè¿‡æä¾›é«˜è´¨é‡çš„æ¨ç†èƒ½åŠ›ï¼ŒMed-U1èƒ½å¤Ÿå¸®åŠ©åŒ»ç”Ÿå’Œæ‚£è€…æ›´æœ‰æ•ˆåœ°è·å–åŒ»ç–—ä¿¡æ¯ï¼Œæå‡åŒ»ç–—æœåŠ¡çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨åŒ»ç–—äººå·¥æ™ºèƒ½çš„è¿›ä¸€æ­¥å‘å±•ï¼Œæ”¹å–„åŒ»ç–—æœåŠ¡è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Medical Question-Answering (QA) encompasses a broad spectrum of tasks, including multiple choice questions (MCQ), open-ended text generation, and complex computational reasoning. Despite this variety, a unified framework for delivering high-quality medical QA has yet to emerge. Although recent progress in reasoning-augmented large language models (LLMs) has shown promise, their ability to achieve comprehensive medical understanding is still largely unexplored. In this paper, we present Med-U1, a unified framework for robust reasoning across medical QA tasks with diverse output formats, ranging from MCQs to complex generation and computation tasks. Med-U1 employs pure large-scale reinforcement learning with mixed rule-based binary reward functions, incorporating a length penalty to manage output verbosity. With multi-objective reward optimization, Med-U1 directs LLMs to produce concise and verifiable reasoning chains. Empirical results reveal that Med-U1 significantly improves performance across multiple challenging Med-QA benchmarks, surpassing even larger specialized and proprietary models. Furthermore, Med-U1 demonstrates robust generalization to out-of-distribution (OOD) tasks. Extensive analysis presents insights into training strategies, reasoning chain length control, and reward design for medical LLMs. Our code is available here.

