---
layout: default
title: CAPE: Context-Aware Personality Evaluation Framework for Large Language Models
---

# CAPE: Context-Aware Personality Evaluation Framework for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20385" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20385v1</a>
  <a href="https://arxiv.org/pdf/2508.20385.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20385v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20385v1', 'CAPE: Context-Aware Personality Evaluation Framework for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jivnesh Sandhan, Fei Cheng, Tushar Sandhan, Yugo Murawaki

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-28

**å¤‡æ³¨**: Accepted at EMNLP25 (Findings)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/jivnesh/CAPE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAPEæ¡†æ¶ä»¥è§£å†³LLMsä¸ªæ€§è¯„ä¼°ä¸­çš„ä¸Šä¸‹æ–‡ç¼ºå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§è¯„ä¼°` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯¹è¯ç³»ç»Ÿ` `å¿ƒç†æµ‹é‡` `æœºå™¨å­¦ä¹ ` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸ªæ€§æ—¶ç¼ºä¹ä¸Šä¸‹æ–‡è€ƒè™‘ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤ŸçœŸå®å’Œæœ‰æ•ˆã€‚
2. æœ¬æ–‡æå‡ºçš„CAPEæ¡†æ¶é€šè¿‡æ•´åˆå¯¹è¯å†å²ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°LLMsçš„ä¸ªæ€§ç‰¹å¾ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCAPEæ¡†æ¶æ˜¾è‘—æé«˜äº†å“åº”ä¸€è‡´æ€§ï¼Œå¹¶æ­ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨ä¸ªæ€§è¡¨ç°ä¸Šçš„å·®å¼‚ï¼Œå°¤å…¶æ˜¯GPTç³»åˆ—æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¿ƒç†æµ‹é‡æµ‹è¯•ä¼ ç»Ÿä¸Šç”¨äºè¯„ä¼°äººç±»è¡Œä¸ºç‰¹å¾ï¼Œç°åœ¨è¢«åº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»¥è¯„ä¼°å…¶è¡Œä¸ºç‰¹å¾ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶é‡‡ç”¨æ— ä¸Šä¸‹æ–‡çš„æ–¹æ³•ï¼Œå­¤ç«‹å›ç­”æ¯ä¸ªé—®é¢˜ï¼Œå¿½è§†äº†å¯¹è¯å†å²çš„å½±å“ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†é¦–ä¸ªä¸Šä¸‹æ–‡æ„ŸçŸ¥ä¸ªæ€§è¯„ä¼°æ¡†æ¶ï¼ˆCAPEï¼‰ï¼Œå°†å…ˆå‰çš„å¯¹è¯äº¤äº’çº³å…¥è¯„ä¼°ä¸­ã€‚é€šè¿‡å¼•å…¥æ–°é¢–çš„åº¦é‡æ ‡å‡†æ¥é‡åŒ–LLMå“åº”çš„ä¸€è‡´æ€§ï¼Œç ”ç©¶è¡¨æ˜å¯¹è¯å†å²å¢å¼ºäº†å“åº”ä¸€è‡´æ€§ï¼Œä½†ä¹Ÿå¯¼è‡´ä¸ªæ€§åç§»ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPTæ¨¡å‹å¯¹é—®é¢˜é¡ºåºå…·æœ‰é²æ£’æ€§ï¼Œè€Œå…¶ä»–æ¨¡å‹åˆ™è¡¨ç°å‡ºæ˜¾è‘—æ•æ„Ÿæ€§ã€‚åº”ç”¨è¯¥æ¡†æ¶äºè§’è‰²æ‰®æ¼”ä»£ç†ï¼ˆRPAï¼‰æ—¶ï¼Œå‘ç°ä¸Šä¸‹æ–‡ä¾èµ–çš„ä¸ªæ€§åç§»æé«˜äº†å“åº”ä¸€è‡´æ€§ï¼Œæ›´å¥½åœ°ç¬¦åˆäººç±»åˆ¤æ–­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ä¸ªæ€§è¯„ä¼°ä¸­ç¼ºä¹ä¸Šä¸‹æ–‡çš„å±€é™æ€§ï¼Œä¼ ç»Ÿæ–¹æ³•å­¤ç«‹å›ç­”é—®é¢˜ï¼Œæ— æ³•åæ˜ çœŸå®çš„å¯¹è¯æƒ…å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCAPEæ¡†æ¶é€šè¿‡å¼•å…¥å¯¹è¯å†å²ï¼Œè€ƒè™‘ä¸Šä¸‹æ–‡å¯¹æ¨¡å‹å“åº”çš„å½±å“ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„ä¸ªæ€§ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCAPEæ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€å¯¹è¯å†å²æ•´åˆã€ä¸ªæ€§è¯„ä¼°å’Œä¸€è‡´æ€§åº¦é‡å››ä¸ªä¸»è¦æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯è¯„ä¼°ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥æ–°é¢–çš„åº¦é‡æ ‡å‡†æ¥é‡åŒ–æ¨¡å‹å“åº”çš„ä¸€è‡´æ€§ï¼Œå¼ºè°ƒä¸Šä¸‹æ–‡å¯¹ä¸ªæ€§è¯„ä¼°çš„é‡è¦æ€§ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å“åº”ä¸€è‡´æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒæ¨¡å‹æ¶æ„çš„å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¡†æ¶çš„é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCAPEæ¡†æ¶æ˜¾è‘—æé«˜äº†å“åº”ä¸€è‡´æ€§ï¼Œå°¤å…¶åœ¨GPT-3.5-Turboå’ŒGPT-4-Turboæ¨¡å‹ä¸­ï¼Œä¸ªæ€§åç§»ç°è±¡æ˜æ˜¾ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒCAPEæ¡†æ¶æå‡äº†å“åº”ä¸€è‡´æ€§ï¼Œä¸”åœ¨è§’è‰²æ‰®æ¼”ä»£ç†ä¸­è¡¨ç°å‡ºæ›´å¥½çš„ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CAPEæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨äººæœºäº¤äº’ã€è™šæ‹ŸåŠ©æ‰‹å’Œè§’è‰²æ‰®æ¼”æ¸¸æˆç­‰é¢†åŸŸã€‚é€šè¿‡æ›´å‡†ç¡®çš„ä¸ªæ€§è¯„ä¼°ï¼Œèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œä½¿å¾—AIç³»ç»Ÿåœ¨ä¸äººç±»äº¤äº’æ—¶è¡¨ç°å¾—æ›´åŠ è‡ªç„¶å’Œäººæ€§åŒ–ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„å¯¹è¯ç³»ç»Ÿä¸­ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–AIçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Psychometric tests, traditionally used to assess humans, are now being applied to Large Language Models (LLMs) to evaluate their behavioral traits. However, existing studies follow a context-free approach, answering each question in isolation to avoid contextual influence. We term this the Disney World test, an artificial setting that ignores real-world applications, where conversational history shapes responses. To bridge this gap, we propose the first Context-Aware Personality Evaluation (CAPE) framework for LLMs, incorporating prior conversational interactions. To thoroughly analyze the influence of context, we introduce novel metrics to quantify the consistency of LLM responses, a fundamental trait in human behavior.
>   Our exhaustive experiments on 7 LLMs reveal that conversational history enhances response consistency via in-context learning but also induces personality shifts, with GPT-3.5-Turbo and GPT-4-Turbo exhibiting extreme deviations. While GPT models are robust to question ordering, Gemini-1.5-Flash and Llama-8B display significant sensitivity. Moreover, GPT models response stem from their intrinsic personality traits as well as prior interactions, whereas Gemini-1.5-Flash and Llama--8B heavily depend on prior interactions. Finally, applying our framework to Role Playing Agents (RPAs) shows context-dependent personality shifts improve response consistency and better align with human judgments. Our code and datasets are publicly available at: https://github.com/jivnesh/CAPE

