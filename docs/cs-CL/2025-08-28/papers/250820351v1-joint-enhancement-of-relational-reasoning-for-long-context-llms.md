---
layout: default
title: Joint Enhancement of Relational Reasoning for Long-Context LLMs
---

# Joint Enhancement of Relational Reasoning for Long-Context LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20351" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20351v1</a>
  <a href="https://arxiv.org/pdf/2508.20351.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20351v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20351v1', 'Joint Enhancement of Relational Reasoning for Long-Context LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhirui Chen, Wei Shen, Jiashui Huang, Ling Shao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-28

**å¤‡æ³¨**: 9 pages, 5 pages Accepted by EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºJERRæ¡†æ¶ä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡LLMsçš„æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡ç†è§£` `å›¾ç»“æ„æ¨ç†` `è’™ç‰¹å¡æ´›æ ‘æœç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿¡æ¯æ‘˜è¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶å­˜åœ¨å†…å­˜é™åˆ¶å’Œå¤æ‚ä»»åŠ¡æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„JERRæ¡†æ¶é€šè¿‡æ‘˜è¦æå–ã€å›¾æ„å»ºå’Œå…³ç³»æ¨ç†æ¥å¢å¼ºé•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒJERRåœ¨ROUGEå’ŒF1æŒ‡æ ‡ä¸Šè¶…è¶Šæ‰€æœ‰åŸºçº¿ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„å¯é æ€§å’Œé€æ˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶ä»é¢ä¸´å†…å­˜é™åˆ¶å’Œå¤æ‚ä»»åŠ¡çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼ŒLLMså¸¸å¸¸ç¼ºä¹é€æ˜æ€§ï¼Œå®¹æ˜“äº§ç”Ÿå¹»è§‰ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶JERRï¼Œé€šè¿‡åŸºäºå›¾çš„æ¨ç†å¢å¼ºLLMsçš„é•¿ä¸Šä¸‹æ–‡ç†è§£ã€‚JERRé›†æˆäº†ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼šæ‘˜è¦æå–ã€å›¾æ„å»ºå’Œå…³ç³»æ¨ç†ã€‚é¦–å…ˆï¼Œé€šè¿‡æˆ˜ç•¥æ€§åœ°åˆ†å—æ–‡æœ¬æå–æ‘˜è¦ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°æ€»ç»“å’Œç†è§£ä¿¡æ¯ã€‚å…¶æ¬¡ï¼Œæ„å»ºæœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ä»¥è§£å†³å†—ä½™ï¼Œç¡®ä¿é€»è¾‘ä¸€è‡´æ€§å’Œæ¸…æ™°æ€§ã€‚æœ€åï¼Œç»“åˆè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰å¸®åŠ©æ¨¡å‹å¯¼èˆªå¤æ‚æ¨ç†è·¯å¾„ï¼Œç¡®ä¿è¾“å‡ºæ›´å‡†ç¡®å’Œå¯è§£é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒJERRåœ¨ROUGEå’ŒF1æŒ‡æ ‡ä¸Šå§‹ç»ˆä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œåœ¨LLM-Raterè¯„ä¼°ä¸­å–å¾—äº†æœ€é«˜åˆ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£å’Œå¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å†…å­˜é™åˆ¶å’Œè¾“å‡ºçš„é€æ˜æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å†—ä½™ä¿¡æ¯å’Œé€»è¾‘ä¸€è‡´æ€§æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºä¸å‡†ç¡®æˆ–éš¾ä»¥è§£é‡Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šJERRæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å›¾ç»“æ„åŒ–çš„æ–¹å¼æ¥å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡æå–æ‘˜è¦ã€æ„å»ºæœ‰å‘æ— ç¯å›¾å’Œä½¿ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†é•¿ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶è¿›è¡Œå¤æ‚æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šJERRæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ‘˜è¦æå–æ¨¡å—è´Ÿè´£å°†é•¿æ–‡æœ¬åˆ†å—å¹¶æå–å…³é”®ä¿¡æ¯ï¼›å›¾æ„å»ºæ¨¡å—åˆ›å»ºæœ‰å‘æ— ç¯å›¾ä»¥æ¶ˆé™¤å†—ä½™å¹¶ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§ï¼›å…³ç³»æ¨ç†æ¨¡å—åˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„ã€‚

**å…³é”®åˆ›æ–°**ï¼šJERRçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå°†å›¾ç»“æ„ä¸è’™ç‰¹å¡æ´›æ ‘æœç´¢ç›¸ç»“åˆï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ¨ç†æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶æ›´åŠ é«˜æ•ˆå’Œé€æ˜ã€‚è¿™ä¸ä¼ ç»Ÿçš„åŸºäºåºåˆ—çš„æ¨ç†æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ‘˜è¦æå–é‡‡ç”¨äº†æ–‡æœ¬åˆ†å—ç­–ç•¥ï¼Œå›¾æ„å»ºä½¿ç”¨äº†æœ‰å‘æ— ç¯å›¾ä»¥ç¡®ä¿ä¿¡æ¯æµçš„é€»è¾‘æ€§ï¼Œè’™ç‰¹å¡æ´›æ ‘æœç´¢åˆ™é€šè¿‡éšæœºé‡‡æ ·ä¼˜åŒ–æ¨ç†è·¯å¾„ï¼Œæå‡äº†æ¨¡å‹çš„è¾“å‡ºå‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚å®éªŒä¸­ä½¿ç”¨äº†ROUGEå’ŒF1ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿äº†ç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒJERRåœ¨ROUGEå’ŒF1æŒ‡æ ‡ä¸Šå‡ä¼˜äºæ‰€æœ‰åŸºçº¿ï¼Œç‰¹åˆ«æ˜¯åœ¨LLM-Raterè¯„ä¼°ä¸­å–å¾—äº†æœ€é«˜åˆ†ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†JERRæ¡†æ¶åœ¨é•¿ä¸Šä¸‹æ–‡ç†è§£å’Œå¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡å¢å¼ºé•¿ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ï¼ŒJERRæ¡†æ¶å¯ä»¥æé«˜æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼ŒJERRçš„è®¾è®¡ç†å¿µä¹Ÿå¯èƒ½ä¸ºå…¶ä»–é¢†åŸŸçš„æ¨ç†ä»»åŠ¡æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite significant progress, large language models (LLMs) still struggle with long contexts due to memory limitations and their inability to tackle complex and long-context tasks. Additionally, LLMs often suffer from a lack of transparency and are prone to producing hallucinations. To address these challenges, we propose \textbf{JERR}, a novel framework designed to enhance long-context comprehension via graph-based reasoning in LLMs. JERR integrates three key components: synopsis extraction, graph construction, and relational reasoning. First, synopsis is extracted by chunking text strategically, allowing the model to summarize and understand information more efficiently. Second, we build a directed acyclic graph (DAG) to resolve redundancy, ensuring logical consistency and clarity. Finally, we incorporate Monte Carlo Tree Search (MCTS) to help the model navigate complex reasoning paths, ensuring more accurate and interpretable outputs. This framework provides a novel solution that enables LLMs to handle extended contexts and complex reasoning tasks with improved reliability and transparency. Experimental results show that JERR consistently outperforms all baselines on the ROUGE and F1 metrics, achieving the highest scores on the LLM-Rater evaluation.

