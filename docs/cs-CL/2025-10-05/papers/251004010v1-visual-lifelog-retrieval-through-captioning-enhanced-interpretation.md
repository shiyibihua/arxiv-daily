---
layout: default
title: Visual Lifelog Retrieval through Captioning-Enhanced Interpretation
---

# Visual Lifelog Retrieval through Captioning-Enhanced Interpretation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.04010" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.04010v1</a>
  <a href="https://arxiv.org/pdf/2510.04010.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.04010v1" onclick="toggleFavorite(this, '2510.04010v1', 'Visual Lifelog Retrieval through Captioning-Enhanced Interpretation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yu-Fei Shih, An-Zi Yen, Hen-Hsen Huang, Hsin-Hsi Chen

**åˆ†ç±»**: cs.IR, cs.CL, cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-10-05

**æœŸåˆŠ**: 2024 IEEE International Conference on Big Data (BigData), Washington, DC, USA, 2024, pp. 479-486

**DOI**: [10.1109/BigData62323.2024.10825835](https://doi.org/10.1109/BigData62323.2024.10825835)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCIVILç³»ç»Ÿä»¥è§£å†³ä¸ªäººè§†è§‰ç”Ÿæ´»æ—¥å¿—æ£€ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `è§†è§‰ç”Ÿæ´»æ—¥å¿—` `å›¾åƒæ£€ç´¢` `æ–‡æœ¬åµŒå…¥` `ç¬¬ä¸€äººç§°è§†è§’` `æ ‡é¢˜ç”Ÿæˆ` `å¤šæ¨¡æ€å­¦ä¹ ` `è®°å¿†è¾…åŠ©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¿«é€Ÿè®¿é—®ä¸ªäººç”Ÿæ´»æ—¥å¿—ä»¥è¾…åŠ©è®°å¿†å›å¿†æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆæå–ç‰¹å®šå›¾åƒã€‚
2. æœ¬æ–‡æå‡ºçš„CIVILç³»ç»Ÿé€šè¿‡ç”Ÿæˆæ ‡é¢˜å¹¶å°†å…¶ä¸ç”¨æˆ·æŸ¥è¯¢æ˜ å°„åˆ°å…±äº«å‘é‡ç©ºé—´ï¼Œæå‡äº†æ£€ç´¢æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCIVILç³»ç»Ÿåœ¨æè¿°ç¬¬ä¸€äººç§°è§†è§‰å›¾åƒæ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæ´»æ—¥å¿—æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººä»¬å¸¸å¸¸éš¾ä»¥è®°ä½è¿‡å»ç»å†çš„å…·ä½“ç»†èŠ‚ï¼Œè¿™å¯¼è‡´éœ€è¦é‡æ–°å›é¡¾è¿™äº›è®°å¿†ã€‚å› æ­¤ï¼Œç”Ÿæ´»æ—¥å¿—æ£€ç´¢æˆä¸ºä¸€ä¸ªé‡è¦çš„åº”ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–‡æœ¬æŸ¥è¯¢æå–ç”¨æˆ·è§†è§‰ç”Ÿæ´»æ—¥å¿—ä¸­ç‰¹å®šå›¾åƒçš„Captioning-Integrated Visual Lifelog (CIVIL)æ£€ç´¢ç³»ç»Ÿã€‚ä¸ä¼ ç»Ÿçš„åµŒå…¥æ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿé¦–å…ˆä¸ºè§†è§‰ç”Ÿæ´»æ—¥å¿—ç”Ÿæˆæ ‡é¢˜ï¼Œç„¶ååˆ©ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹å°†æ ‡é¢˜å’Œç”¨æˆ·æŸ¥è¯¢æŠ•å½±åˆ°å…±äº«çš„å‘é‡ç©ºé—´ä¸­ã€‚é€šè¿‡å¯ç©¿æˆ´æ‘„åƒå¤´æ•è·çš„è§†è§‰ç”Ÿæ´»æ—¥å¿—æä¾›äº†ç¬¬ä¸€äººç§°è§†è§’ï¼Œéœ€è§£é‡Šæ‹æ‘„è€…çš„æ´»åŠ¨è€Œéä»…ä»…æè¿°åœºæ™¯ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸‰ç§ä¸åŒçš„æ–¹æ³•ï¼šå•ä¸€æ ‡é¢˜æ³•ã€é›†ä½“æ ‡é¢˜æ³•å’Œåˆå¹¶æ ‡é¢˜æ³•ï¼Œæ—¨åœ¨è§£é‡Šç”Ÿæ´»æ—¥å¿—è®°å½•è€…çš„ç”Ÿæ´»ç»å†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ‰æ•ˆæè¿°äº†ç¬¬ä¸€äººç§°è§†è§‰å›¾åƒï¼Œæå‡äº†ç”Ÿæ´»æ—¥å¿—æ£€ç´¢çš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•ä»ç”¨æˆ·çš„è§†è§‰ç”Ÿæ´»æ—¥å¿—ä¸­å¿«é€Ÿæå–ç‰¹å®šå›¾åƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºåµŒå…¥æŠ€æœ¯ï¼Œéš¾ä»¥æœ‰æ•ˆæ•æ‰ç¬¬ä¸€äººç§°è§†è§’ä¸‹çš„ç”Ÿæ´»ç»å†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„CIVILç³»ç»Ÿé€šè¿‡ç”Ÿæˆè§†è§‰ç”Ÿæ´»æ—¥å¿—çš„æ ‡é¢˜ï¼Œç»“åˆç”¨æˆ·çš„æ–‡æœ¬æŸ¥è¯¢ï¼Œå°†äºŒè€…æ˜ å°„åˆ°å…±äº«çš„å‘é‡ç©ºé—´ä¸­ï¼Œä»è€Œå®ç°æ›´ç²¾å‡†çš„å›¾åƒæ£€ç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCIVILç³»ç»Ÿçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ ‡é¢˜ç”Ÿæˆæ¨¡å—ã€æ–‡æœ¬åµŒå…¥æ¨¡å—å’Œæ£€ç´¢æ¨¡å—ã€‚é¦–å…ˆï¼Œç³»ç»Ÿä¸ºæ¯ä¸ªè§†è§‰ç”Ÿæ´»æ—¥å¿—ç”Ÿæˆæè¿°æ€§æ ‡é¢˜ï¼›å…¶æ¬¡ï¼Œå°†æ ‡é¢˜å’Œç”¨æˆ·æŸ¥è¯¢é€šè¿‡æ–‡æœ¬åµŒå…¥æ¨¡å‹æ˜ å°„åˆ°åŒä¸€å‘é‡ç©ºé—´ï¼›æœ€åï¼ŒåŸºäºç›¸ä¼¼åº¦è¿›è¡Œå›¾åƒæ£€ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ä¸‰ç§ä¸åŒçš„æ ‡é¢˜ç”Ÿæˆæ–¹æ³•ï¼ˆå•ä¸€ã€é›†ä½“å’Œåˆå¹¶ï¼‰ï¼Œä»¥æ›´å…¨é¢åœ°è§£é‡Šç”Ÿæ´»æ—¥å¿—è®°å½•è€…çš„ç»å†ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€åµŒå…¥æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…ˆè¿›çš„æ–‡æœ¬åµŒå…¥æŠ€æœ¯ï¼Œå¹¶å¯¹æ ‡é¢˜ç”Ÿæˆçš„å‚æ•°è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æ ‡é¢˜èƒ½å¤Ÿå‡†ç¡®åæ˜ è§†è§‰å†…å®¹ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCIVILç³»ç»Ÿåœ¨ç”Ÿæ´»æ—¥å¿—æ£€ç´¢ä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦20%çš„å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨æè¿°ç¬¬ä¸€äººç§°è§†è§‰å›¾åƒæ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬ä¸ªäººè®°å¿†è¾…åŠ©ã€ç¤¾äº¤åª’ä½“å†…å®¹æ£€ç´¢ä»¥åŠæ™ºèƒ½å®¶å±…ç³»ç»Ÿä¸­çš„ç”Ÿæ´»æ—¥å¿—ç®¡ç†ã€‚é€šè¿‡æå‡è§†è§‰ç”Ÿæ´»æ—¥å¿—çš„æ£€ç´¢æ•ˆç‡ï¼Œç”¨æˆ·èƒ½å¤Ÿæ›´æ–¹ä¾¿åœ°å›é¡¾å’Œåˆ†äº«ä¸ªäººç»å†ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> People often struggle to remember specific details of past experiences, which can lead to the need to revisit these memories. Consequently, lifelog retrieval has emerged as a crucial application. Various studies have explored methods to facilitate rapid access to personal lifelogs for memory recall assistance. In this paper, we propose a Captioning-Integrated Visual Lifelog (CIVIL) Retrieval System for extracting specific images from a user's visual lifelog based on textual queries. Unlike traditional embedding-based methods, our system first generates captions for visual lifelogs and then utilizes a text embedding model to project both the captions and user queries into a shared vector space. Visual lifelogs, captured through wearable cameras, provide a first-person viewpoint, necessitating the interpretation of the activities of the individual behind the camera rather than merely describing the scene. To address this, we introduce three distinct approaches: the single caption method, the collective caption method, and the merged caption method, each designed to interpret the life experiences of lifeloggers. Experimental results show that our method effectively describes first-person visual images, enhancing the outcomes of lifelog retrieval. Furthermore, we construct a textual dataset that converts visual lifelogs into captions, thereby reconstructing personal life experiences.

