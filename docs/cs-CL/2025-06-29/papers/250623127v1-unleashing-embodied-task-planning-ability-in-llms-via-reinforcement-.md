---
layout: default
title: Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning
---

# Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23127" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23127v1</a>
  <a href="https://arxiv.org/pdf/2506.23127.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23127v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23127v1', 'Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhaoye Fei, Li Ji, Siyin Wang, Junhao Shi, Jingjing Gong, Xipeng Qiu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEmbodied Planner-R1ä»¥è§£å†³LLMsåœ¨ç¯å¢ƒä»»åŠ¡è§„åˆ’ä¸­çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¯å¢ƒä»»åŠ¡è§„åˆ’` `å¼ºåŒ–å­¦ä¹ ` `è‡ªä¸»æ¢ç´¢` `äº¤äº’å¼ç­–ç•¥ä¼˜åŒ–` `ç¨€ç–å¥–åŠ±` `æ³›åŒ–èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¯å¢ƒä»»åŠ¡è§„åˆ’ä¸­ä¾èµ–é™æ€çŸ¥è¯†ï¼Œéš¾ä»¥å¤„ç†å› æœå…³ç³»å’Œç¯å¢ƒåé¦ˆï¼Œå°¤å…¶åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚
2. æå‡ºçš„Embodied Planner-R1æ¡†æ¶é€šè¿‡çº¯å¼ºåŒ–å­¦ä¹ å’Œç»„å›åˆè®¾è®¡ï¼Œæ”¯æŒLLMsåœ¨è‡ªä¸»æ¢ç´¢ä¸­å­¦ä¹ äº’åŠ¨èƒ½åŠ›ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚
3. åœ¨ALFWorldå’ŒScienceWorldåŸºå‡†æµ‹è¯•ä¸­ï¼ŒEmbodied Planner-R1åˆ†åˆ«è¾¾åˆ°äº†97.78%å’Œ79.92%çš„å®Œæˆç‡ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡å’Œè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨éœ€è¦æŒç»­ç¯å¢ƒç†è§£å’ŒåŠ¨ä½œç”Ÿæˆçš„ç¯å¢ƒä»»åŠ¡è§„åˆ’åœºæ™¯ä¸­é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åŸºäºé™æ€çŸ¥è¯†ç”Ÿæˆå¼€æ”¾å¼åŠ¨ä½œè„šæœ¬ï¼Œéš¾ä»¥å­¦ä¹ åŠ¨ä½œä¸ç¯å¢ƒåé¦ˆä¹‹é—´çš„å› æœå…³ç³»ï¼Œå°¤å…¶æ˜¯åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒä¸­ã€‚æˆ‘ä»¬æå‡ºäº†Embodied Planner-R1ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„ä»¥ç»“æœä¸ºé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä½¿LLMsé€šè¿‡è‡ªä¸»æ¢ç´¢åœ¨æœ€å°ç›‘ç£ä¸‹å‘å±•äº’åŠ¨èƒ½åŠ›ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰é¡¹å…³é”®åˆ›æ–°ï¼š1ï¼‰é‡‡ç”¨çº¯å¼ºåŒ–å­¦ä¹ ä¸ç»„å›åˆï¼Œæ— éœ€äººå·¥æ ‡æ³¨ï¼Œé€šè¿‡å¹¶è¡Œæ¢ç´¢å®ç°ç¯å¢ƒå†…äº’åŠ¨ï¼›2ï¼‰åŸºäºå®Œæˆé©±åŠ¨çš„ç¨€ç–å¥–åŠ±ï¼›3ï¼‰äº¤äº’å¼ç­–ç•¥ä¼˜åŒ–ï¼ˆIPOï¼‰ï¼Œä»¥é«˜æ•ˆå­¦ä¹ åˆ†ç»„è½¨è¿¹ã€‚åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ–‡æœ¬åŸºç¡€ç¯å¢ƒè§„åˆ’åŸºå‡†ä¸Šï¼ŒEmbodied Planner-R1åœ¨ALFWorldä¸Šå®ç°äº†97.78%çš„å®Œæˆç‡ï¼Œåœ¨ScienceWorldä¸Šè¾¾åˆ°äº†79.92%ï¼Œå¤§å¹…è¶…è¶Šäº†å…ˆå‰çš„æ–¹æ³•ï¼Œå¹¶åœ¨æœªè§ç¯å¢ƒä¸­ä»…ä¸‹é™äº†-3.66%ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¯å¢ƒä»»åŠ¡è§„åˆ’ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯å¦‚ä½•åœ¨éƒ¨åˆ†å¯è§‚å¯Ÿç¯å¢ƒä¸­æœ‰æ•ˆå­¦ä¹ åŠ¨ä½œä¸ç¯å¢ƒåé¦ˆä¹‹é—´çš„å› æœå…³ç³»ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–é™æ€çŸ¥è¯†ï¼Œéš¾ä»¥é€‚åº”åŠ¨æ€ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Embodied Planner-R1æ¡†æ¶é€šè¿‡å¼•å…¥çº¯å¼ºåŒ–å­¦ä¹ å’Œç»„å›åˆçš„æ–¹å¼ï¼Œä½¿LLMsèƒ½å¤Ÿåœ¨è‡ªä¸»æ¢ç´¢ä¸­å­¦ä¹ äº’åŠ¨èƒ½åŠ›ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œä»è€Œæé«˜ä»»åŠ¡å®Œæˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š1ï¼‰ç¯å¢ƒäº¤äº’æ¨¡å—ï¼Œé€šè¿‡å¹¶è¡Œæ¢ç´¢å®ç°å¤šæ ·åŒ–çš„ç¯å¢ƒåé¦ˆï¼›2ï¼‰å¥–åŠ±æœºåˆ¶æ¨¡å—ï¼Œé‡‡ç”¨åŸºäºå®Œæˆé©±åŠ¨çš„ç¨€ç–å¥–åŠ±ï¼›3ï¼‰ç­–ç•¥ä¼˜åŒ–æ¨¡å—ï¼Œä½¿ç”¨äº¤äº’å¼ç­–ç•¥ä¼˜åŒ–ï¼ˆIPOï¼‰æ¥é«˜æ•ˆå­¦ä¹ åˆ†ç»„è½¨è¿¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé‡‡ç”¨äº†çº¯å¼ºåŒ–å­¦ä¹ ä¸ç»„å›åˆçš„ç»“åˆï¼Œå…è®¸æ¨¡å‹åœ¨æ²¡æœ‰äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç¯å¢ƒäº¤äº’è‡ªä¸»å­¦ä¹ ï¼Œä»è€Œæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆç‡å’Œä»»åŠ¡å®Œæˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¡†æ¶ä¼˜åŒ–äº†å¥–åŠ±å‡½æ•°è®¾è®¡ï¼Œé‡‡ç”¨ç¨€ç–å¥–åŠ±æœºåˆ¶ä»¥æ¿€åŠ±æœ‰æ•ˆçš„ä»»åŠ¡å®Œæˆï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œç»“åˆäº†æ·±åº¦å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Embodied Planner-R1åœ¨ALFWorldå’ŒScienceWorldåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«è¾¾åˆ°äº†97.78%å’Œ79.92%çš„å®Œæˆç‡ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨æœªè§ç¯å¢ƒä¸­ä»…ä¸‹é™äº†-3.66%ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œå­¦ä¹ æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€æ™ºèƒ½åŠ©æ‰‹å’Œæ¸¸æˆAIç­‰ï¼Œèƒ½å¤Ÿåœ¨åŠ¨æ€å’Œå¤æ‚ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡è§„åˆ’ä¸æ‰§è¡Œã€‚é€šè¿‡æå‡LLMsçš„ç¯å¢ƒç†è§£å’Œäº’åŠ¨èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks, yet they face significant challenges in embodied task planning scenarios that require continuous environmental understanding and action generation. Existing approaches generate open-loop action scripts based on static knowledge, making it difficult to learn causal relationships between actions and environmental feedback, particularly in partially observable environments. We introduce Embodied Planner-R1, a novel outcome-driven reinforcement learning framework that enables LLMs to develop interactive capabilities through autonomous exploration with minimal supervision. Our framework incorporates three key innovations: (1) Without human annotations, we employ pure reinforcement learning with group rollout, incorporating in-environment interaction through parallel exploration; (2) completion-driven sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient learning from grouped trajectories. Across two challenging text-based Embodied planning benchmarks, Embodied Planner-R1 achieves impressive completion rates of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a large margin, and suffers only a -3.66% drop in previously unseen environments, evidencing strong generalization.

