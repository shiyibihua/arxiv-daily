---
layout: default
title: Datasets for Fairness in Language Models: An In-Depth Survey
---

# Datasets for Fairness in Language Models: An In-Depth Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23411" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23411v2</a>
  <a href="https://arxiv.org/pdf/2506.23411.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23411v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23411v2', 'Datasets for Fairness in Language Models: An In-Depth Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiale Zhang, Zichong Wang, Avash Palikhe, Zhipeng Yin, Wenbin Zhang

**åˆ†ç±»**: cs.CL, cs.CY, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-09-22)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¬å¹³æ€§æ•°æ®é›†åˆ†ææ¡†æ¶ä»¥è§£å†³è¯­è¨€æ¨¡å‹è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…¬å¹³æ€§è¯„ä¼°` `è¯­è¨€æ¨¡å‹` `æ•°æ®é›†åˆ†æ` `åè§è¯†åˆ«` `ç®—æ³•é€æ˜æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°æ–¹æ³•ä¾èµ–çš„æ•°æ®é›†ç¼ºä¹æ·±å…¥åˆ†æï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„å¯é æ€§å—åˆ°è´¨ç–‘ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨æ­ç¤ºä¸åŒæ•°æ®é›†ä¸­çš„äººå£å·®å¼‚æ¨¡å¼ï¼Œä»è€Œæ”¹å–„å…¬å¹³æ€§è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚
3. é€šè¿‡å¯¹åå…­ä¸ªæµè¡Œæ•°æ®é›†çš„åˆ†æï¼Œå‘ç°äº†è®¸å¤šè¢«å¿½è§†çš„åè§ï¼Œå¹¶æä¾›äº†é€‰æ‹©å’Œè§£é‡Šæ•°æ®é›†çš„æŒ‡å¯¼ï¼Œä¿ƒè¿›äº†ç ”ç©¶çš„é€æ˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¯¹å…¬å¹³æ€§åŸºå‡†çš„ä¾èµ–æ—¥ç›Šå¢åŠ ï¼Œä½†æ”¯æ’‘è¿™äº›åŸºå‡†çš„æ•°æ®é›†ä»ç„¶ç¼ºä¹æ·±å…¥ç ”ç©¶ã€‚æœ¬è°ƒæŸ¥é€šè¿‡å…¨é¢åˆ†æè¯­è¨€æ¨¡å‹ç ”ç©¶ä¸­æœ€å¹¿æ³›ä½¿ç”¨çš„å…¬å¹³æ€§æ•°æ®é›†ï¼Œå¡«è¡¥äº†è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬ä»æ•°æ®é›†çš„æ¥æºã€äººå£èŒƒå›´ã€æ³¨é‡Šè®¾è®¡å’Œé¢„æœŸç”¨é€”ç­‰å…³é”®ç»´åº¦è¿›è¡Œç‰¹å¾åŒ–ï¼Œæ­ç¤ºäº†å½“å‰è¯„ä¼°å®è·µä¸­å›ºæœ‰çš„å‡è®¾å’Œå±€é™æ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œæ­ç¤ºäº†åŸºå‡†å’Œè¯„åˆ†æŒ‡æ ‡ä¸­äººå£å·®å¼‚çš„ä¸€è‡´æ¨¡å¼ã€‚é€šè¿‡å¯¹åå…­ä¸ªæµè¡Œæ•°æ®é›†çš„åº”ç”¨ï¼Œæˆ‘ä»¬å‘ç°äº†å¯èƒ½æ‰­æ›²æ¨¡å‹å…¬å¹³æ€§ç»“è®ºçš„è¢«å¿½è§†çš„åè§ï¼Œå¹¶æä¾›äº†æ›´æœ‰æ•ˆå’Œè´Ÿè´£ä»»åœ°é€‰æ‹©ã€ç»„åˆå’Œè§£é‡Šè¿™äº›èµ„æºçš„æŒ‡å¯¼ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†æ•æ‰æ›´å¹¿æ³›ç¤¾ä¼šèƒŒæ™¯å’Œå…¬å¹³æ¦‚å¿µçš„æ–°åŸºå‡†çš„è¿«åˆ‡éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å½“å‰è¯­è¨€æ¨¡å‹å…¬å¹³æ€§è¯„ä¼°ä¸­æ•°æ®é›†åˆ†æä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†æ•°æ®é›†çš„æ¥æºå’Œè®¾è®¡ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„åå·®å’Œä¸å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å…¨é¢åˆ†æç°æœ‰å…¬å¹³æ€§æ•°æ®é›†ï¼Œæå‡ºä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥æ­ç¤ºæ•°æ®é›†ä¸­çš„äººå£å·®å¼‚å’Œæ½œåœ¨åè§ï¼Œä»è€Œæé«˜è¯„ä¼°çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†ç‰¹å¾åŒ–ã€ç»Ÿä¸€è¯„ä¼°æ¡†æ¶çš„æ„å»ºä»¥åŠå¯¹åå…­ä¸ªæ•°æ®é›†çš„åº”ç”¨åˆ†æã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é›†çš„æ¥æºåˆ†æã€äººå£èŒƒå›´è¯„ä¼°ã€æ³¨é‡Šè®¾è®¡å®¡æŸ¥å’Œè¯„ä¼°ç»“æœçš„ç»¼åˆæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿæ­ç¤ºä¸åŒæ•°æ®é›†ä¸­çš„ä¸€è‡´æ€§åè§ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šæœªå¾—åˆ°å……åˆ†å…³æ³¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè®ºæ–‡å…³æ³¨æ•°æ®é›†çš„æ¥æºã€äººå£ç‰¹å¾ã€æ³¨é‡Šæ–¹æ³•ç­‰å…³é”®å‚æ•°ï¼Œç¡®ä¿è¯„ä¼°è¿‡ç¨‹çš„é€æ˜æ€§å’Œå¯é‡å¤æ€§ï¼ŒåŒæ—¶æä¾›äº†æ•°æ®ã€ä»£ç å’Œç»“æœçš„å…¬å¼€è®¿é—®ï¼Œä»¥ä¿ƒè¿›åç»­ç ”ç©¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

é€šè¿‡å¯¹åå…­ä¸ªæµè¡Œæ•°æ®é›†çš„åˆ†æï¼Œå‘ç°äº†å¤šä¸ªè¢«å¿½è§†çš„åè§ï¼Œå¯èƒ½å¯¼è‡´å¯¹æ¨¡å‹å…¬å¹³æ€§çš„è¯¯åˆ¤ã€‚è¯¥ç ”ç©¶æä¾›çš„ç»Ÿä¸€è¯„ä¼°æ¡†æ¶æ­ç¤ºäº†ä¸åŒæ•°æ®é›†ä¸­çš„ä¸€è‡´æ€§åè§ï¼Œä¿ƒè¿›äº†å¯¹å…¬å¹³æ€§è¯„ä¼°çš„æ·±å…¥ç†è§£å’Œæ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å…¬å¹³æ€§è¯„ä¼°ã€ç®—æ³•é€æ˜æ€§ç ”ç©¶ä»¥åŠç¤¾ä¼šç§‘å­¦ä¸­çš„æ•°æ®åˆ†æã€‚é€šè¿‡æä¾›ä¸€ä¸ªç³»ç»ŸåŒ–çš„è¯„ä¼°æ¡†æ¶ï¼Œç ”ç©¶è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œçº æ­£æ¨¡å‹ä¸­çš„åè§ï¼Œä»è€Œæ¨åŠ¨æ›´å…¬å¹³çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½å½±å“æ”¿ç­–åˆ¶å®šå’ŒæŠ€æœ¯æ ‡å‡†çš„åˆ¶å®šï¼Œä¿ƒè¿›ç¤¾ä¼šå…¬æ­£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the growing reliance on fairness benchmarks to evaluate language models, the datasets that underpin these benchmarks remain critically underexamined. This survey addresses that overlooked foundation by offering a comprehensive analysis of the most widely used fairness datasets in language model research. To ground this analysis, we characterize each dataset across key dimensions, including provenance, demographic scope, annotation design, and intended use, revealing the assumptions and limitations baked into current evaluation practices. Building on this foundation, we propose a unified evaluation framework that surfaces consistent patterns of demographic disparities across benchmarks and scoring metrics. Applying this framework to sixteen popular datasets, we uncover overlooked biases that may distort conclusions about model fairness and offer guidance on selecting, combining, and interpreting these resources more effectively and responsibly. Our findings highlight an urgent need for new benchmarks that capture a broader range of social contexts and fairness notions. To support future research, we release all data, code, and results at https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets, fostering transparency and reproducibility in the evaluation of language model fairness.

