---
layout: default
title: V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy
---

# V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23149" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23149v1</a>
  <a href="https://arxiv.org/pdf/2506.23149.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23149v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23149v1', 'V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dingzirui Wang, Xuanliang Zhang, Keyan Xu, Qingfu Zhu, Wanxiang Che, Yang Deng

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºV-Synthesisä»¥è§£å†³ä»é›¶å¼€å§‹åˆæˆä¸€è‡´ä¸”å¤šæ ·åŒ–ç¤ºä¾‹çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¤ºä¾‹åˆæˆ` `ä¸€è‡´æ€§åº¦é‡` `å¤šæ ·æ€§é‡‡æ ·` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¤ºä¾‹åˆæˆæ–¹æ³•ä¸»è¦ä¾èµ–äºå·²æœ‰ç¤ºä¾‹æˆ–é’ˆå¯¹ç‰¹å®šä»»åŠ¡ï¼Œç¼ºä¹é€šç”¨æ€§å’Œä¸€è‡´æ€§ã€‚
2. æœ¬æ–‡æå‡ºV-Synthesisï¼Œé€šè¿‡å¼•å…¥V-Scoreåº¦é‡ï¼Œè¿›è¡Œæ¯”ä¾‹é‡‡æ ·ä»¥ç¡®ä¿åˆæˆç¤ºä¾‹çš„ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒV-Synthesisåœ¨æ€§èƒ½ä¸Šå¹³å‡æå‡2.0%ï¼Œç›¸è¾ƒäºç°æœ‰åˆæˆæ–¹æ³•å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é«˜æ ‡æ³¨æˆæœ¬ä¿ƒä½¿ç ”ç©¶è€…ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œç¤ºä¾‹åˆæˆï¼Œä»¥é™ä½å¼€é”€ã€‚ç„¶è€Œï¼Œç°æœ‰åˆæˆæ–¹æ³•ä¸»è¦æ˜¯ä»»åŠ¡ç‰¹å®šçš„ï¼Œæˆ–ä¾èµ–äºå·²æœ‰ç¤ºä¾‹ã€‚æœ¬æ–‡èšç„¦äºä»é›¶å¼€å§‹ä¸ºä»»æ„ä»»åŠ¡åˆæˆç¤ºä¾‹ã€‚åˆæˆçš„ä¸€å¤§æŒ‘æˆ˜æ˜¯ç¡®ä¿ä¸ç›®æ ‡ä»»åŠ¡çš„ä¸€è‡´æ€§ï¼Œå› ä¸ºç¼ºä¹æ ‡æ³¨æŒ‡å¯¼å¯èƒ½å¯¼è‡´åˆæˆåå·®ã€‚æˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ç§ä¸€è‡´æ€§åº¦é‡V-Scoreï¼Œç›¸è¾ƒäºåŸºäºn-gramæˆ–åµŒå…¥å‘é‡çš„åº¦é‡ï¼Œå…·æœ‰æ›´é«˜çš„æ€§èƒ½å’Œæ›´ä½çš„è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥V-Synthesisï¼Œåˆ©ç”¨V-Scoreè¿›è¡Œæ¯”ä¾‹é‡‡æ ·ï¼Œä»¥ç¡®ä¿åˆæˆç¤ºä¾‹çš„é«˜ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒV-Synthesisçš„å¹³å‡æ€§èƒ½æå‡ä¸º2.0%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»é›¶å¼€å§‹åˆæˆä¸€è‡´ä¸”å¤šæ ·åŒ–çš„ç¤ºä¾‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¸ºä»»åŠ¡ç‰¹å®šï¼Œæˆ–ä¾èµ–äºå·²æœ‰ç¤ºä¾‹ï¼Œå¯¼è‡´é€šç”¨æ€§ä¸è¶³å’Œåˆæˆåå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åº¦é‡V-Scoreï¼Œç”¨äºè¯„ä¼°åˆæˆç¤ºä¾‹ä¸ç›®æ ‡ä»»åŠ¡çš„ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡æ¯”ä¾‹é‡‡æ ·ç¡®ä¿åˆæˆç¤ºä¾‹çš„å¤šæ ·æ€§ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å…‹æœç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼Œæä¾›æ›´çµæ´»çš„åˆæˆèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬V-Scoreè®¡ç®—æ¨¡å—å’ŒV-Synthesisåˆæˆæ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡V-Scoreè¯„ä¼°ç¤ºä¾‹çš„ä¸€è‡´æ€§ï¼Œç„¶åè¿›è¡Œæ¯”ä¾‹é‡‡æ ·ç”Ÿæˆå¤šæ ·åŒ–çš„åˆæˆç¤ºä¾‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šV-Scoreä½œä¸ºä¸€ç§æ–°çš„ä¸€è‡´æ€§åº¦é‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„n-gramæˆ–åµŒå…¥å‘é‡åº¦é‡ï¼Œå…·æœ‰æ›´é«˜çš„æ€§èƒ½å’Œæ›´ä½çš„è®¡ç®—æˆæœ¬ï¼Œæ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨V-Synthesisä¸­ï¼Œé‡‡ç”¨äº†æ¯”ä¾‹é‡‡æ ·ç­–ç•¥ï¼Œç¡®ä¿åˆæˆç¤ºä¾‹åœ¨ä¿æŒä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå…·å¤‡è¶³å¤Ÿçš„å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†åˆæˆç¤ºä¾‹çš„å¤šæ ·æ€§ä¸ä¸€è‡´æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒV-Synthesisåœ¨åˆæˆç¤ºä¾‹çš„ä¸€è‡´æ€§å’Œå¤šæ ·æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æ€§èƒ½æå‡è¾¾åˆ°2.0%ã€‚ä¸ç°æœ‰åˆæˆæ–¹æ³•ç›¸æ¯”ï¼ŒV-Synthesisåœ¨ä¿æŒé«˜ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æé«˜äº†åˆæˆç¤ºä¾‹çš„å¤šæ ·æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ•™è‚²æŠ€æœ¯å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æä¾›ä¸€è‡´ä¸”å¤šæ ·åŒ–çš„ç¤ºä¾‹ï¼ŒV-Synthesiså¯ä»¥å¸®åŠ©æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ï¼Œé™ä½äººå·¥æ ‡æ³¨æˆæœ¬ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å¹¿æ³›åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå’Œä¸ªæ€§åŒ–å­¦ä¹ ç­‰æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> High labeling cost for in-context learning (ICL) demonstrations motivates using large language models (LLMs) for synthesis to reduce overhead. However, existing synthesis methods are mainly task-specific or rely on pre-existing demonstrations. So this paper focuses on synthesizing demonstrations from scratch for arbitrary tasks. A major challenge in synthesizing from scratch is ensuring consistency with the target task, as the lack of labeling guidance could lead to synthesis bias. We first propose a consistency metric called V-Score, which has higher performance and lower computation cost compared with the metrics based on grams or embedding vectors. Furthermore, we introduce V-Synthesis, which leverages V-Score for proportional sampling to ensure both high consistency and diversity of synthesized demonstrations. Experimental results demonstrate that V-Synthesis yields an average performance improvement of 2.0% compared to existing synthesis methods confirming the effectiveness of V-Synthesis.

