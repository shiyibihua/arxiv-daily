---
layout: default
title: Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III
---

# Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.02954" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.02954v2</a>
  <a href="https://arxiv.org/pdf/2507.02954.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.02954v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.02954v2', 'Advanced Financial Reasoning at Scale: A Comprehensive Evaluation of Large Language Models on CFA Level III')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pranam Shetty, Abhisek Upadhayaya, Parth Mitesh Shah, Srikanth Jagabathula, Shilpi Nayak, Anna Joo Fee

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-09-22)

**å¤‡æ³¨**: Accepted at FinLLM @ IJCAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨CFAä¸‰çº§è€ƒè¯•ä¸­çš„é‡‘èæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é‡‘èæ¨ç†` `CFAè€ƒè¯•` `æ¨¡å‹è¯„ä¼°` `å¤šé¡¹é€‰æ‹©é¢˜` `è®ºæ–‡è¯„åˆ†` `æç¤ºç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é‡‘èé¢†åŸŸæ¨¡å‹è¯„ä¼°ç¼ºä¹é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸¥æ ¼æ ‡å‡†ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»¼åˆåŸºå‡†è¯„ä¼°æ–¹æ³•ï¼Œé’ˆå¯¹CFAä¸‰çº§è€ƒè¯•çš„å¤šé¡¹é€‰æ‹©é¢˜å’Œè®ºæ–‡å›ç­”è¿›è¡Œè¯„ä¼°ï¼Œé‡‡ç”¨å¤šç§æç¤ºç­–ç•¥ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé¢†å…ˆçš„LLMsåœ¨CFAä¸‰çº§è€ƒè¯•ä¸­å–å¾—äº†79.1%å’Œ77.3%çš„é«˜åˆ†ï¼Œè¡¨æ˜å…¶åœ¨é‡‘èæ¨ç†æ–¹é¢çš„æ˜¾è‘—è¿›æ­¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€é‡‘èæœºæ„è¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œè¿›è¡Œä¸¥æ ¼çš„é¢†åŸŸç‰¹å®šè¯„ä¼°å˜å¾—è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€é¡¹ç»¼åˆåŸºå‡†ï¼Œè¯„ä¼°23ç§æœ€å…ˆè¿›çš„LLMsåœ¨ç‰¹è®¸é‡‘èåˆ†æå¸ˆï¼ˆCFAï¼‰ä¸‰çº§è€ƒè¯•ä¸­çš„è¡¨ç°ï¼Œè¿™æ˜¯é«˜çº§é‡‘èæ¨ç†çš„é‡‘æ ‡å‡†ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šç§æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬æ€ç»´é“¾å’Œè‡ªæˆ‘å‘ç°ï¼Œè¯„ä¼°å¤šé¡¹é€‰æ‹©é¢˜ï¼ˆMCQsï¼‰å’Œè®ºæ–‡å¼å›ç­”ã€‚ç»“æœæ˜¾ç¤ºï¼Œé¢†å…ˆæ¨¡å‹åœ¨CFAä¸‰çº§è€ƒè¯•ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ï¼Œç»¼åˆå¾—åˆ†å¦‚79.1%ï¼ˆo4-miniï¼‰å’Œ77.3%ï¼ˆGemini 2.5 Flashï¼‰ã€‚è¿™äº›ç»“æœåœ¨ä¿®è®¢åçš„ä¸¥æ ¼è®ºæ–‡è¯„åˆ†æ–¹æ³•ä¸‹å–å¾—ï¼Œè¡¨æ˜LLMsåœ¨é«˜é£é™©é‡‘èåº”ç”¨ä¸­çš„èƒ½åŠ›æ˜¾è‘—æå‡ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºä»ä¸šè€…æä¾›äº†æ¨¡å‹é€‰æ‹©çš„é‡è¦æŒ‡å¯¼ï¼Œå¹¶å¼ºè°ƒäº†åœ¨æˆæœ¬æ•ˆç›Šéƒ¨ç½²å’Œå¯¹ä¸“ä¸šåŸºå‡†çš„ç»†è‡´è§£è¯»æ–¹é¢ä»ç„¶å­˜åœ¨çš„æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èé¢†åŸŸåº”ç”¨ä¸­çš„è¯„ä¼°ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨CFAä¸‰çº§è€ƒè¯•è¿™ä¸€é«˜é£é™©åœºæ™¯ä¸‹çš„è¡¨ç°è¯„ä¼°ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸¥æ ¼æ ‡å‡†ï¼Œå¯¼è‡´æ¨¡å‹çš„å®é™…åº”ç”¨æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç»¼åˆçš„è¯„ä¼°åŸºå‡†ï¼Œé€šè¿‡å¯¹23ç§æœ€å…ˆè¿›çš„LLMsè¿›è¡Œç³»ç»Ÿæ€§æµ‹è¯•ï¼Œä½¿ç”¨å¤šç§æç¤ºç­–ç•¥æ¥è¯„ä¼°å…¶åœ¨å¤æ‚é‡‘èæ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨ç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹é€‰æ‹©ã€è¯„ä¼°æŒ‡æ ‡è®¾å®šå’Œç»“æœåˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†CFAä¸‰çº§è€ƒè¯•çš„é¢˜ç›®ï¼Œç„¶åé€‰æ‹©23ç§LLMsè¿›è¡Œæµ‹è¯•ï¼Œæœ€åé€šè¿‡ä¸¥æ ¼çš„è¯„åˆ†æ ‡å‡†åˆ†æå…¶è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé‡‡ç”¨äº†ä¿®è®¢åçš„ä¸¥æ ¼è®ºæ–‡è¯„åˆ†æ–¹æ³•ï¼Œæå‡äº†è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºå…¶é’ˆå¯¹æ€§å’Œç³»ç»Ÿæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†å¤šç§æç¤ºç­–ç•¥ï¼Œå¦‚æ€ç»´é“¾å’Œè‡ªæˆ‘å‘ç°ï¼Œä»¥æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯„åˆ†æ ‡å‡†ç»è¿‡ä¿®è®¢ï¼Œä»¥ç¡®ä¿å¯¹æ¨¡å‹è¾“å‡ºçš„å‡†ç¡®è¯„ä¼°ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†è®¨è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œo4-miniæ¨¡å‹åœ¨CFAä¸‰çº§è€ƒè¯•ä¸­å–å¾—79.1%çš„å¾—åˆ†ï¼Œè€ŒGemini 2.5 Flashåˆ™ä¸º77.3%ã€‚è¿™äº›æˆç»©åœ¨ä¿®è®¢åçš„ä¸¥æ ¼è¯„åˆ†æ ‡å‡†ä¸‹å–å¾—ï¼Œè¡¨æ˜LLMsåœ¨é«˜é£é™©é‡‘èåº”ç”¨ä¸­çš„èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œå…·æœ‰é‡è¦çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èæœåŠ¡ã€æŠ•èµ„åˆ†æå’Œé£é™©ç®¡ç†ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èæ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œé‡‘èæœºæ„å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨è¿™äº›æ¨¡å‹è¿›è¡Œå†³ç­–æ”¯æŒå’Œå®¢æˆ·æœåŠ¡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨é‡‘èç§‘æŠ€çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As financial institutions increasingly adopt Large Language Models (LLMs), rigorous domain-specific evaluation becomes critical for responsible deployment. This paper presents a comprehensive benchmark evaluating 23 state-of-the-art LLMs on the Chartered Financial Analyst (CFA) Level III exam - the gold standard for advanced financial reasoning. We assess both multiple-choice questions (MCQs) and essay-style responses using multiple prompting strategies including Chain-of-Thought and Self-Discover. Our evaluation reveals that leading models demonstrate strong capabilities, with composite scores such as 79.1% (o4-mini) and 77.3% (Gemini 2.5 Flash) on CFA Level III. These results, achieved under a revised, stricter essay grading methodology, indicate significant progress in LLM capabilities for high-stakes financial applications. Our findings provide crucial guidance for practitioners on model selection and highlight remaining challenges in cost-effective deployment and the need for nuanced interpretation of performance against professional benchmarks.

