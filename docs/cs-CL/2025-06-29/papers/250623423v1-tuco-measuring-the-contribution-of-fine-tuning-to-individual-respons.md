---
layout: default
title: TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs
---

# TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23423" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23423v1</a>
  <a href="https://arxiv.org/pdf/2506.23423.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23423v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23423v1', 'TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Felipe Nuti, Tim Franzmeyer, JoÃ£o Henriques

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: ICML 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTuCoä»¥é‡åŒ–å¾®è°ƒå¯¹LLMä¸ªä½“å“åº”çš„è´¡çŒ®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `å¯¹æŠ—æ”»å‡»` `æ¨¡å‹å®‰å…¨æ€§` `å®šé‡åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ç¼ºä¹å¯¹å¾®è°ƒå¯¹LLMä¸ªä½“è¾“å‡ºå½±å“çš„å®šé‡åˆ†ææ–¹æ³•ï¼Œä¸»è¦é›†ä¸­åœ¨æ•´ä½“æ€§èƒ½ä¸Šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡è·Ÿè¸ªæ¨¡å‹ä¸­é—´çŠ¶æ€æ¥é‡åŒ–å¾®è°ƒå¯¹ä¸ªä½“å“åº”çš„è´¡çŒ®ï¼Œæä¾›æ›´ç»†è‡´çš„åˆ†æã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒç»„ä»¶çš„è°ƒæ•´èƒ½å¤Ÿæ˜¾è‘—å½±å“æ¨¡å‹è¡Œä¸ºï¼Œå¹¶ä¸”åœ¨å¯¹æŠ—æ”»å‡»ä¸­ï¼ŒTuCoçš„é™ä½ä¸æ”»å‡»æˆåŠŸç›¸å…³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»¥å¾€çš„ç ”ç©¶ä¸»è¦å…³æ³¨å¾®è°ƒå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ•´ä½“æ€§èƒ½çš„å½±å“ï¼Œä½†ç¼ºä¹å¯¹ä¸ªä½“è¾“å‡ºå½±å“çš„å®šé‡åˆ†ææ–¹æ³•ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œæµ‹é‡å¾®è°ƒå¯¹LLMå“åº”çš„è´¡çŒ®ï¼Œå‡è®¾å¯ä»¥è®¿é—®åŸå§‹é¢„è®­ç»ƒæ¨¡å‹ã€‚è¯¥æ–¹æ³•é€šè¿‡è·Ÿè¸ªæ¨¡å‹çš„ä¸­é—´éšè—çŠ¶æ€ï¼Œæä¾›æ¯”ç®€å•æ¯”è¾ƒé¢„è®­ç»ƒå’Œå¾®è°ƒæ¨¡å‹æœ€ç»ˆè¾“å‡ºæ›´ç»†è‡´çš„è§è§£ã€‚æˆ‘ä»¬å¼•å…¥å¹¶ç†è®ºåˆ†æäº†å¾®è°ƒLLMçš„ç²¾ç¡®åˆ†è§£ï¼Œå‘ç°é€šè¿‡è°ƒæ•´å¾®è°ƒç»„ä»¶çš„è§„æ¨¡å¯ä»¥å¼•å¯¼æ¨¡å‹è¡Œä¸ºå’Œæ€§èƒ½ã€‚æˆ‘ä»¬å®šä¹‰äº†è°ƒä¼˜è´¡çŒ®ï¼ˆTuCoï¼‰ï¼Œä½œä¸ºå¾®è°ƒç»„ä»¶ä¸é¢„è®­ç»ƒç»„ä»¶çš„æ¯”ç‡ï¼Œå¹¶è§‚å¯Ÿåˆ°åœ¨ä¸‰ç§ä¸»è¦å¯¹æŠ—æ”»å‡»ä¸­ï¼ŒTuCoçš„é™ä½ä¸æ”»å‡»æˆåŠŸç›¸å…³ã€‚è¿™è¡¨æ˜å¾®è°ƒå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“åœ¨æ”»å‡»æˆåŠŸä¸­èµ·åˆ°äº†ä¸€å®šä½œç”¨ã€‚æ€»ä¹‹ï¼ŒTuCoä½¿å¾—å¾®è°ƒå¦‚ä½•å½±å“æ¨¡å‹è¡Œä¸ºå’Œå®‰å…¨æ€§çš„å®šé‡ç ”ç©¶æˆä¸ºå¯èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¼ºä¹å®šé‡åˆ†æå¾®è°ƒå¯¹LLMä¸ªä½“å“åº”å½±å“çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ•´ä½“æ€§èƒ½ï¼Œæ— æ³•æ·±å…¥ç†è§£å¾®è°ƒå¯¹å…·ä½“è¾“å‡ºçš„è´¡çŒ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡è·Ÿè¸ªæ¨¡å‹çš„ä¸­é—´éšè—çŠ¶æ€ï¼Œç²¾ç¡®åˆ†è§£å¾®è°ƒLLMä¸ºé¢„è®­ç»ƒç»„ä»¶å’Œå¾®è°ƒç»„ä»¶ï¼Œä»è€Œé‡åŒ–å¾®è°ƒå¯¹ä¸ªä½“å“åº”çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é¢„è®­ç»ƒæ¨¡å‹ã€å¾®è°ƒè¿‡ç¨‹åŠå…¶å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“åˆ†æã€‚é€šè¿‡å¯¹æ¯”å¾®è°ƒå‰åçš„ä¸­é—´çŠ¶æ€ï¼Œæå–å‡ºå¾®è°ƒå¯¹è¾“å‡ºçš„å…·ä½“è´¡çŒ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è°ƒä¼˜è´¡çŒ®ï¼ˆTuCoï¼‰çš„æ¦‚å¿µï¼Œèƒ½å¤Ÿé‡åŒ–å¾®è°ƒä¸é¢„è®­ç»ƒçš„ç›¸å¯¹å½±å“ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šæœªå®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹çš„å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡è°ƒæ•´å¾®è°ƒç»„ä»¶çš„è§„æ¨¡ï¼Œè§‚å¯Ÿå…¶å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œè®¾è®¡äº†ç›¸åº”çš„å®éªŒæ¥éªŒè¯è¿™ä¸€ç†è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒç»„ä»¶çš„è°ƒæ•´èƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼æ¨¡å‹è¡Œä¸ºï¼Œä¸”åœ¨ä¸‰ç§å¯¹æŠ—æ”»å‡»ä¸­ï¼ŒæˆåŠŸæ”»å‡»çš„æƒ…å†µä¸‹TuCoæ˜¾è‘—é™ä½ã€‚è¿™è¡¨æ˜å¾®è°ƒå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“åœ¨å¯¹æŠ—æ”»å‡»ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œæä¾›äº†æ–°çš„å®‰å…¨æ€§åˆ†æè§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹æŠ—æ€§æœºå™¨å­¦ä¹ å’Œæ¨¡å‹å®‰å…¨æ€§åˆ†æã€‚é€šè¿‡é‡åŒ–å¾®è°ƒå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–LLMçš„è¡Œä¸ºï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Past work has studied the effects of fine-tuning on large language models' (LLMs) overall performance on certain tasks. However, a quantitative and systematic method for analyzing its effect on individual outputs is still lacking. Here, we propose a new method for measuring the contribution that fine-tuning makes to individual LLM responses, assuming access to the original pre-trained model. Our method tracks the model's intermediate hidden states, providing a more fine-grained insight into the effects of fine-tuning than a simple comparison of final outputs from pre-trained and fine-tuned models. We introduce and theoretically analyze an exact decomposition of any fine-tuned LLM into a pre-training component and a fine-tuning component. Empirically, we find that model behavior and performance can be steered by up- or down-scaling the fine-tuning component during the forward pass. Motivated by this finding and our theoretical analysis, we define the Tuning Contribution (TuCo) as the ratio of the magnitudes of the fine-tuning component to the pre-training component. We observe that three prominent adversarial attacks on LLMs circumvent safety measures in a way that reduces TuCo, and that TuCo is consistently lower on prompts where these attacks succeed compared to those where they do not. This suggests that attenuating the effect of fine-tuning on model outputs plays a role in the success of such attacks. In summary, TuCo enables the quantitative study of how fine-tuning influences model behavior and safety, and vice versa.

