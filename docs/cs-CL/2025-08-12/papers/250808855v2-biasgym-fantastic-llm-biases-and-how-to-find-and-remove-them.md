---
layout: default
title: BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them
---

# BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08855" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08855v2</a>
  <a href="https://arxiv.org/pdf/2508.08855.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08855v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08855v2', 'BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sekh Mainul Islam, Nadav Borenstein, Siddhesh Milind Pawar, Haeun Yu, Arnav Arora, Isabelle Augenstein

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-08-14)

**å¤‡æ³¨**: Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBiasGymæ¡†æ¶ä»¥è¯†åˆ«å’Œæ¶ˆé™¤å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åè§è¯†åˆ«` `å»åè§` `BiasGym` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¯è§£é‡Šæ€§ç ”ç©¶` `å®‰å…¨å¹²é¢„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯†åˆ«å’Œæ¶ˆé™¤å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åè§æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œåè§è¡Œä¸ºå¾€å¾€éš¾ä»¥ç³»ç»Ÿåˆ†æå’Œç¼“è§£ã€‚
2. è®ºæ–‡æå‡ºçš„BiasGymæ¡†æ¶é€šè¿‡BiasInjectå’ŒBiasScopeä¸¤ä¸ªç»„ä»¶å®ç°åè§çš„æ³¨å…¥ã€åˆ†æå’Œå»åè§ï¼Œå…·æœ‰è‰¯å¥½çš„å¯æ¨å¹¿æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBiasGymåœ¨å‡å°‘ç°å®ä¸–ç•Œçš„åˆ»æ¿å°è±¡å’Œæ¢æµ‹è™šæ„å…³è”æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ç¼–ç çš„åè§å’Œåˆ»æ¿å°è±¡å¯¹äºå¼€å‘æœ‰æ•ˆçš„ç¼“è§£ç­–ç•¥è‡³å…³é‡è¦ã€‚åè§è¡Œä¸ºå¾€å¾€å¾®å¦™ä¸”éš¾ä»¥å­¤ç«‹ï¼Œå³ä½¿åœ¨æ•…æ„å¼•å‘æ—¶ä¹Ÿä¸æ˜“è¯†åˆ«ï¼Œè¿™ä½¿å¾—ç³»ç»Ÿåˆ†æå’Œå»åè§å˜å¾—ç‰¹åˆ«å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†BiasGymï¼Œä¸€ä¸ªç®€å•ã€ç»æµä¸”å¯æ¨å¹¿çš„æ¡†æ¶ï¼Œç”¨äºå¯é åœ°æ³¨å…¥ã€åˆ†æå’Œç¼“è§£LLMsä¸­çš„æ¦‚å¿µå…³è”ã€‚BiasGymç”±ä¸¤ä¸ªç»„ä»¶ç»„æˆï¼šBiasInjecté€šè¿‡åŸºäºæ ‡è®°çš„å¾®è°ƒå°†ç‰¹å®šåè§æ³¨å…¥æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹ä¸å˜ï¼›BiasScopeåˆ©ç”¨è¿™äº›æ³¨å…¥ä¿¡å·è¯†åˆ«å¹¶å¼•å¯¼å¯¼è‡´åè§è¡Œä¸ºçš„ç»„ä»¶ã€‚æˆ‘ä»¬çš„ç ”ç©¶å±•ç¤ºäº†BiasGymåœ¨å‡å°‘ç°å®ä¸–ç•Œåˆ»æ¿å°è±¡å’Œæ¢æµ‹è™šæ„å…³è”æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾ç¤ºäº†å…¶åœ¨å®‰å…¨å¹²é¢„å’Œå¯è§£é‡Šæ€§ç ”ç©¶ä¸­çš„å®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­åè§çš„è¯†åˆ«ä¸æ¶ˆé™¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç³»ç»Ÿåˆ†æå’Œå»åè§æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå°¤å…¶æ˜¯åè§è¡Œä¸ºçš„å¾®å¦™æ€§ä½¿å¾—å…¶éš¾ä»¥è¢«æœ‰æ•ˆè¯†åˆ«å’Œç¼“è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡BiasGymæ¡†æ¶ï¼Œåˆ©ç”¨BiasInjectæ³¨å…¥ç‰¹å®šåè§ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„å…¶ä»–éƒ¨åˆ†ä¸å˜ï¼Œä»è€Œè¿›è¡Œæœ‰æ•ˆçš„åè§åˆ†æå’Œå»åè§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBiasGymæ¡†æ¶ç”±ä¸¤ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼šBiasInjectå’ŒBiasScopeã€‚BiasInjectè´Ÿè´£é€šè¿‡æ ‡è®°å¾®è°ƒæ³¨å…¥åè§ï¼Œè€ŒBiasScopeåˆ™åˆ©ç”¨è¿™äº›æ³¨å…¥ä¿¡å·è¯†åˆ«å’Œå¼•å¯¼å¯¼è‡´åè§è¡Œä¸ºçš„æ¨¡å‹ç»„ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºBiasGymçš„è®¾è®¡ï¼Œä½¿å¾—åè§çš„æ³¨å…¥å’Œåˆ†æå˜å¾—ç³»ç»ŸåŒ–å’Œå¯é‡å¤ï¼Œä¸”èƒ½å¤Ÿåœ¨ä¸å½±å“ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„æƒ…å†µä¸‹è¿›è¡Œé’ˆå¯¹æ€§çš„å»åè§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨BiasInjectä¸­ï¼Œé‡‡ç”¨äº†åŸºäºæ ‡è®°çš„å¾®è°ƒæŠ€æœ¯ï¼Œç¡®ä¿ç‰¹å®šåè§èƒ½å¤Ÿè¢«æœ‰æ•ˆæ³¨å…¥ï¼›åœ¨BiasScopeä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„ä¿¡å·è¯†åˆ«æœºåˆ¶ï¼Œä»¥ä¾¿å‡†ç¡®å®šä½åè§æ¥æºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBiasGymåœ¨å‡å°‘ç°å®ä¸–ç•Œåˆ»æ¿å°è±¡ï¼ˆå¦‚æ„å¤§åˆ©äººè¢«è§†ä¸ºâ€œé²è½å¸æœºâ€ï¼‰å’Œæ¢æµ‹è™šæ„å…³è”ï¼ˆå¦‚è™šæ„å›½å®¶çš„äººå…·æœ‰â€œè“è‰²çš®è‚¤â€ï¼‰æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†åè§è¯†åˆ«å’Œå»åè§çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BiasGymæ¡†æ¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åè§è¯†åˆ«ä¸æ¶ˆé™¤ã€AIç³»ç»Ÿçš„å®‰å…¨æ€§æå‡ä»¥åŠå¯è§£é‡Šæ€§ç ”ç©¶ã€‚é€šè¿‡æœ‰æ•ˆçš„åè§ç®¡ç†ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¸®åŠ©æ„å»ºæ›´å…¬æ­£å’Œé€æ˜çš„AIç³»ç»Ÿï¼Œä¿ƒè¿›ç¤¾ä¼šè´£ä»»æ„Ÿçš„å¢å¼ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging. To address this, we introduce BiasGym, a simple, cost-effective, and generalizable framework for reliably injecting, analyzing, and mitigating conceptual associations within LLMs. BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior. Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during token-based fine-tuning. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes (e.g., people from Italy being `reckless drivers') and in probing fictional associations (e.g., people from a fictional country having `blue skin'), showing its utility for both safety interventions and interpretability research.

