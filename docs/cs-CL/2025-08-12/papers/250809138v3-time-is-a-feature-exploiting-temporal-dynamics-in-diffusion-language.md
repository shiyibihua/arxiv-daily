---
layout: default
title: Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models
---

# Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09138" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09138v3</a>
  <a href="https://arxiv.org/pdf/2508.09138.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09138v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09138v3', 'Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wen Wang, Bozhen Fang, Chenchen Jing, Yongliang Shen, Yangyi Shen, Qiuyu Wang, Hao Ouyang, Hao Chen, Chunhua Shen

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-10-06)

**å¤‡æ³¨**: Project webpage: https://aim-uofa.github.io/dLLM-MidTruth

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—¶é—´ä¸€è‡´æ€§æ–¹æ³•ä»¥è§£å†³æ‰©æ•£è¯­è¨€æ¨¡å‹çš„é¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£è¯­è¨€æ¨¡å‹` `æ—¶é—´ä¸€è‡´æ€§` `å»å™ªç”Ÿæˆ` `è¯­ä¹‰ç¨³å®šæ€§` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‰©æ•£è¯­è¨€æ¨¡å‹åœ¨è§£ç è¿‡ç¨‹ä¸­å¿½è§†äº†ä¸­é—´æ­¥éª¤çš„é¢„æµ‹ï¼Œå¯¼è‡´æ½œåœ¨çš„æ­£ç¡®ç­”æ¡ˆè¢«è¦†ç›–ã€‚
2. æœ¬æ–‡æå‡ºäº†æ—¶é—´è‡ªä¸€è‡´æ€§æŠ•ç¥¨å’Œæ—¶é—´ä¸€è‡´æ€§å¼ºåŒ–ä¸¤ç§æ–¹æ³•ï¼Œä»¥å……åˆ†åˆ©ç”¨æ—¶é—´åŠ¨æ€ç‰¹æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨è´ŸTSEå¥–åŠ±åœ¨Countdownæ•°æ®é›†ä¸Šå¹³å‡æå‡24.7%ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†ä¸Šå–å¾—æ˜¾è‘—æ”¹è¿›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰é€šè¿‡è¿­ä»£å»å™ªç”Ÿæˆæ–‡æœ¬ï¼Œä½†ç°æœ‰è§£ç ç­–ç•¥å¿½è§†äº†ä¸­é—´é¢„æµ‹çš„ä¸°å¯Œä¿¡æ¯ï¼Œå¯¼è‡´æ­£ç¡®ç­”æ¡ˆåœ¨åç»­æ­¥éª¤ä¸­è¢«è¦†ç›–ã€‚æœ¬æ–‡æ­ç¤ºäº†ä¸€ä¸ªå…³é”®ç°è±¡â€”â€”æ—¶é—´æŒ¯è¡ï¼Œæå‡ºäº†ä¸¤ç§äº’è¡¥çš„æ–¹æ³•æ¥åˆ©ç”¨æ—¶é—´ä¸€è‡´æ€§ï¼š1ï¼‰æ—¶é—´è‡ªä¸€è‡´æ€§æŠ•ç¥¨ï¼Œä¸€ç§æ— è®­ç»ƒçš„æµ‹è¯•æ—¶è§£ç ç­–ç•¥ï¼Œé€šè¿‡èšåˆå»å™ªæ­¥éª¤ä¸­çš„é¢„æµ‹æ¥é€‰æ‹©æœ€ä¸€è‡´çš„è¾“å‡ºï¼›2ï¼‰åè®­ç»ƒæ–¹æ³•æ—¶é—´ä¸€è‡´æ€§å¼ºåŒ–ï¼Œåˆ©ç”¨æ—¶é—´è¯­ä¹‰ç†µï¼ˆTSEï¼‰ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œé¼“åŠ±ç¨³å®šç”Ÿæˆã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†ä¸Šæœ‰æ•ˆï¼Œä½¿ç”¨è´ŸTSEå¥–åŠ±å•ç‹¬è§‚å¯Ÿåˆ°Countdownæ•°æ®é›†ä¸Šå¹³å‡æå‡24.7%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰©æ•£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å¿½è§†ä¸­é—´é¢„æµ‹çš„é—®é¢˜ï¼Œå¯¼è‡´æ­£ç¡®ç­”æ¡ˆåœ¨åç»­å»å™ªæ­¥éª¤ä¸­è¢«è¦†ç›–ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨æ—¶é—´åŠ¨æ€ç‰¹æ€§ï¼Œå½±å“äº†ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡æ—¶é—´ä¸€è‡´æ€§çš„æ–¹æ³•æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæ ¸å¿ƒåœ¨äºèšåˆå¤šä¸ªå»å™ªæ­¥éª¤çš„é¢„æµ‹ï¼Œä»¥é€‰æ‹©æœ€ä¸€è‡´çš„è¾“å‡ºï¼Œä»è€Œæé«˜ç”Ÿæˆçš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ—¶é—´è‡ªä¸€è‡´æ€§æŠ•ç¥¨å’Œæ—¶é—´ä¸€è‡´æ€§å¼ºåŒ–ã€‚å‰è€…åœ¨æµ‹è¯•é˜¶æ®µèšåˆé¢„æµ‹ï¼Œåè€…åœ¨è®­ç»ƒååˆ©ç”¨æ—¶é—´è¯­ä¹‰ç†µä½œä¸ºå¥–åŠ±ä¿¡å·ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥æ—¶é—´è¯­ä¹‰ç†µï¼ˆTSEï¼‰ä½œä¸ºå¥–åŠ±ä¿¡å·ï¼Œé¼“åŠ±æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒè¯­ä¹‰ç¨³å®šæ€§ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€è¾“å‡ºé€‰æ‹©å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ—¶é—´è‡ªä¸€è‡´æ€§æŠ•ç¥¨ä¸­ï¼Œé‡‡ç”¨æ— è®­ç»ƒçš„èšåˆç­–ç•¥ï¼›åœ¨æ—¶é—´ä¸€è‡´æ€§å¼ºåŒ–ä¸­ï¼Œè®¾è®¡äº†åŸºäºTSEçš„å¥–åŠ±æœºåˆ¶ï¼Œä»¥ä¿ƒè¿›æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è´ŸTSEå¥–åŠ±å•ç‹¬åœ¨Countdownæ•°æ®é›†ä¸Šå®ç°äº†24.7%çš„å¹³å‡æå‡ã€‚ç»“åˆå‡†ç¡®æ€§å¥–åŠ±ï¼Œåœ¨GSM8Kã€MATH500ã€SVAMPå’ŒCountdownæ•°æ®é›†ä¸Šåˆ†åˆ«å–å¾—äº†2.0%ã€4.3%ã€6.6%å’Œ25.3%çš„ç»å¯¹å¢ç›Šï¼Œæ˜¾ç¤ºå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜ç”Ÿæˆæ–‡æœ¬çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿåœ¨æ•™è‚²ã€å®¢æœå’Œå†…å®¹åˆ›ä½œç­‰å¤šä¸ªå®é™…åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„è¯­è¨€æ¨¡å‹å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion large language models (dLLMs) generate text through iterative denoising, yet current decoding strategies discard rich intermediate predictions in favor of the final output. Our work here reveals a critical phenomenon, temporal oscillation, where correct answers often emerge in the middle process, but are overwritten in later denoising steps. To address this issue, we introduce two complementary methods that exploit temporal consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time decoding strategy that aggregates predictions across denoising steps to select the most consistent output; and 2) a post-training method termed Temporal Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a measure of semantic stability across intermediate predictions, as a reward signal to encourage stable generations. Empirical results across multiple benchmarks demonstrate the effectiveness of our approach. Using the negative TSE reward alone, we observe a remarkable average improvement of 24.7% on the Countdown dataset over an existing dLLM. Combined with the accuracy reward, we achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and 25.3% on Countdown, respectively. Our findings underscore the untapped potential of temporal dynamics in dLLMs and offer two simple yet effective tools to harness them.

