---
layout: default
title: IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization
---

# IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08719" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08719v2</a>
  <a href="https://arxiv.org/pdf/2508.08719.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08719v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08719v2', 'IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuzhuo Bai, Shitong Duan, Muhua Huang, Jing Yao, Zhenghao Liu, Peng Zhang, Tun Lu, Xiaoyuan Yi, Maosong Sun, Xing Xie

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-11-27)

**å¤‡æ³¨**: This paper is accepted by AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIROTEä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹ç‰¹å¾æå–ä¸ç¨³å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰¹å¾æå–` `è‡ªæˆ‘åæ€` `ä¿¡æ¯è®ºä¼˜åŒ–` `ä¸ªæ€§åŒ–æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç‰¹å¾æå–ä¸­å­˜åœ¨è¡¨é¢åŒ–é—®é¢˜ï¼ŒLLMsåªèƒ½æ¨¡ä»¿æµ…å±‚ä¸”ä¸ç¨³å®šçš„é£æ ¼æ¨¡å¼ï¼Œæ— æ³•ç²¾ç¡®ä½“ç°æ‰€éœ€ç‰¹å¾ã€‚
2. æœ¬æ–‡æå‡ºIROTEï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ–æ–‡æœ¬è‡ªæˆ‘åæ€ï¼Œåˆºæ¿€LLMsçš„ç‰¹å¾é©±åŠ¨è¡Œä¸ºï¼Œè§£å†³äº†ç‰¹å¾æå–çš„ä¸ç¨³å®šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒIROTEç”Ÿæˆçš„è‡ªæˆ‘åæ€åœ¨å¤šæ ·ä¸‹æ¸¸ä»»åŠ¡ä¸­èƒ½å¤Ÿç¨³å®šè¯±å¯¼LLMsæ¨¡ä»¿ç›®æ ‡ç‰¹å¾ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡æç¤ºå±•ç¤ºäº†åæ˜ ç‰¹å®šäººç±»ç‰¹å¾çš„èƒ½åŠ›ï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨è¡¨é¢åŒ–æå–çš„é—®é¢˜ï¼Œæ— æ³•åœ¨å¤šæ ·ä»»åŠ¡ä¸­ç¨³å®šä¸”ä¸€è‡´åœ°ä½“ç°æ‰€éœ€ç‰¹å¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†IROTEï¼Œä¸€ç§æ–°é¢–çš„ä¸Šä¸‹æ–‡è‡ªæˆ‘åæ€ä¼˜åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•è‡ªåŠ¨ç”Ÿæˆå¹¶ä¼˜åŒ–æ–‡æœ¬è‡ªæˆ‘åæ€ï¼Œä»¥åˆºæ¿€LLMsçš„ç‰¹å¾é©±åŠ¨è¡Œä¸ºã€‚é€šè¿‡è¿­ä»£æœ€å¤§åŒ–ä¿¡æ¯è®ºç›®æ ‡ï¼Œå¢å¼ºLLMsè¡Œä¸ºä¸ç›®æ ‡ç‰¹å¾ä¹‹é—´çš„è”ç³»ï¼ŒåŒæ—¶å‡å°‘åæ€ä¸­çš„å™ªå£°å†—ä½™ï¼Œæœ€ç»ˆå®ç°äº†ç”ŸåŠ¨ä¸”ç´§å‡‘çš„ç‰¹å¾åæ˜ ã€‚å®éªŒè¡¨æ˜ï¼Œå•ä¸ªIROTEç”Ÿæˆçš„è‡ªæˆ‘åæ€èƒ½å¤Ÿåœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­ç¨³å®šåœ°è¯±å¯¼LLMsæ¨¡ä»¿ç›®æ ‡ç‰¹å¾ï¼Œè¶…è¶Šç°æœ‰å¼ºåŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å¾æå–ä¸­çš„ä¸ç¨³å®šæ€§å’Œè¡¨é¢åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æ— æ³•åœ¨å¤šæ ·ä»»åŠ¡ä¸­ä¸€è‡´åœ°ä½“ç°äººç±»ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºIROTEæ–¹æ³•ï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆå’Œä¼˜åŒ–æ–‡æœ¬è‡ªæˆ‘åæ€ï¼Œåˆ©ç”¨å¿ƒç†å­¦ç†è®ºä¸­çš„èº«ä»½ç›¸å…³åæ€ï¼Œåˆºæ¿€LLMsçš„ç‰¹å¾é©±åŠ¨è¡Œä¸ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIROTEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è‡ªæˆ‘åæ€ç”Ÿæˆæ¨¡å—å’Œä¿¡æ¯è®ºä¼˜åŒ–æ¨¡å—ã€‚è‡ªæˆ‘åæ€æ¨¡å—ç”ŸæˆåŒ…å«è‡ªæˆ‘æ„ŸçŸ¥ç»éªŒçš„æ–‡æœ¬ï¼Œä¼˜åŒ–æ¨¡å—åˆ™é€šè¿‡è¿­ä»£æœ€å¤§åŒ–ä¿¡æ¯è®ºç›®æ ‡æ¥å¢å¼ºè¡Œä¸ºä¸ç‰¹å¾çš„è”ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡è‡ªæˆ‘åæ€çš„ä¼˜åŒ–ï¼Œè§£å†³äº†ç‰¹å¾æå–çš„ç¨³å®šæ€§é—®é¢˜ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿåœ¨å¤šæ ·ä»»åŠ¡ä¸­ä¸€è‡´åœ°ä½“ç°ç›®æ ‡ç‰¹å¾ï¼ŒåŒºåˆ«äºç°æœ‰æ–¹æ³•çš„æµ…å±‚æ¨¡ä»¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä¼˜åŒ–è¿‡ç¨‹ä¸­é‡‡ç”¨ä¿¡æ¯è®ºç›®æ ‡å‡½æ•°ï¼Œè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„åæ€æ–‡æœ¬ç”Ÿæˆæœºåˆ¶ï¼Œç¡®ä¿åæ€å†…å®¹çš„ç”ŸåŠ¨æ€§å’Œç´§å‡‘æ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒä¸­è¿›è¡Œäº†éªŒè¯å’Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•ä¸ªIROTEç”Ÿæˆçš„è‡ªæˆ‘åæ€åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­èƒ½å¤Ÿè¯±å¯¼LLMsç¨³å®šåœ°æ¨¡ä»¿ç›®æ ‡ç‰¹å¾ï¼Œæ€§èƒ½è¶…è¶Šç°æœ‰å¼ºåŸºçº¿ï¼Œæå‡å¹…åº¦æ˜¾è‘—ï¼Œå…·ä½“æ•°æ®æœªæä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬ä¸ªæ€§åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘ã€ç¤¾äº¤æ¨¡æ‹Ÿä»¥åŠäººæœºäº¤äº’ç­‰é¢†åŸŸã€‚é€šè¿‡ç¨³å®šçš„ç‰¹å¾æå–ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Trained on various human-authored corpora, Large Language Models (LLMs) have demonstrated a certain capability of reflecting specific human-like traits (e.g., personality or values) by prompting, benefiting applications like personalized LLMs and social simulations. However, existing methods suffer from the superficial elicitation problem: LLMs can only be steered to mimic shallow and unstable stylistic patterns, failing to embody the desired traits precisely and consistently across diverse tasks like humans. To address this challenge, we propose IROTE, a novel in-context method for stable and transferable trait elicitation. Drawing on psychological theories suggesting that traits are formed through identity-related reflection, our method automatically generates and optimizes a textual self-reflection within prompts, which comprises self-perceived experience, to stimulate LLMs' trait-driven behavior. The optimization is performed by iteratively maximizing an information-theoretic objective that enhances the connections between LLMs' behavior and the target trait, while reducing noisy redundancy in reflection without any fine-tuning, leading to evocative and compact trait reflection. Extensive experiments across three human trait systems manifest that one single IROTE-generated self-reflection can induce LLMs' stable impersonation of the target trait across diverse downstream tasks beyond simple questionnaire answering, consistently outperforming existing strong baselines.

