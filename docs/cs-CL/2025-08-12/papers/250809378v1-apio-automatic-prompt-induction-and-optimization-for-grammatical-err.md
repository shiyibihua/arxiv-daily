---
layout: default
title: APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification
---

# APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09378" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09378v1</a>
  <a href="https://arxiv.org/pdf/2508.09378.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09378v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09378v1', 'APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Artem Chernodub, Aman Saini, Yejin Huh, Vivek Kulkarni, Vipul Raheja

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: Accepted for publication at Recent Advances in Natural Language Processing conference (RANLP 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAPIOä»¥è§£å†³è¯­æ³•é”™è¯¯çº æ­£å’Œæ–‡æœ¬ç®€åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨æç¤ºä¼˜åŒ–` `è¯­æ³•é”™è¯¯çº æ­£` `æ–‡æœ¬ç®€åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æç¤ºå·¥ç¨‹æ–¹æ³•å¾€å¾€ä¾èµ–äºæ‰‹åŠ¨æŒ‡å®šçš„ç§å­æç¤ºï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚
2. APIOé€šè¿‡è‡ªåŠ¨å¼•å¯¼å’Œä¼˜åŒ–æç¤ºï¼Œæ¶ˆé™¤äº†å¯¹æ‰‹åŠ¨ç§å­æç¤ºçš„ä¾èµ–ï¼Œä»è€Œæé«˜äº†ä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡ã€‚
3. APIOåœ¨è¯­æ³•é”™è¯¯çº æ­£å’Œæ–‡æœ¬ç®€åŒ–ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æ–°çš„æ€§èƒ½å·…å³°ï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥ä½¿å¾—é€šè¿‡ç®€å•çš„æç¤ºäº¤äº’æ¥æ‰§è¡Œå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡æˆä¸ºå¯èƒ½ã€‚å› æ­¤ï¼Œè®¸å¤šæ–¹æ³•è¢«æå‡ºä»¥è®¾è®¡æœ€æœ‰æ•ˆçš„æç¤ºï¼Œä»è€Œä½¿LLMsèƒ½å¤Ÿæ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚é’ˆå¯¹å…·æœ‰æ˜ç¡®ä¼˜åŒ–æŒ‡æ ‡çš„è®¾ç½®ï¼Œè‡ªåŠ¨æç¤ºä¼˜åŒ–ï¼ˆAPOï¼‰æ–¹æ³•è¢«å¼€å‘ä»¥ç²¾ç‚¼ç§å­æç¤ºã€‚æœ¬æ–‡æå‡ºAPIOï¼Œä¸€ç§ç®€å•ä½†æœ‰æ•ˆçš„æç¤ºå¼•å¯¼å’Œä¼˜åŒ–æ–¹æ³•ï¼Œä¸“æ³¨äºè¯­æ³•é”™è¯¯çº æ­£ï¼ˆGECï¼‰å’Œæ–‡æœ¬ç®€åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä¾èµ–æ‰‹åŠ¨æŒ‡å®šçš„ç§å­æç¤ºã€‚APIOåœ¨è¿™äº›ä»»åŠ¡ä¸Šå®ç°äº†åŸºäºLLMçš„æç¤ºæ–¹æ³•çš„æ–°çŠ¶æ€ä¸‹çš„æ€§èƒ½ã€‚æˆ‘ä»¬å…¬å¼€äº†æ•°æ®ã€ä»£ç ã€æç¤ºå’Œè¾“å‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨è¯­æ³•é”™è¯¯çº æ­£å’Œæ–‡æœ¬ç®€åŒ–ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•å¯¹æ‰‹åŠ¨ç§å­æç¤ºçš„ä¾èµ–æ€§ï¼Œå¯¼è‡´çµæ´»æ€§ä¸è¶³å’Œæ€§èƒ½é™åˆ¶çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAPIOçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è‡ªåŠ¨åŒ–çš„æ–¹å¼å¼•å¯¼å’Œä¼˜åŒ–æç¤ºï¼Œé¿å…äº†æ‰‹åŠ¨è®¾è®¡çš„å¤æ‚æ€§ï¼ŒåŒæ—¶æå‡äº†æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAPIOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æç¤ºç”Ÿæˆæ¨¡å—å’Œä¼˜åŒ–æ¨¡å—ã€‚æç¤ºç”Ÿæˆæ¨¡å—è´Ÿè´£æ ¹æ®ä»»åŠ¡éœ€æ±‚ç”Ÿæˆåˆå§‹æç¤ºï¼Œè€Œä¼˜åŒ–æ¨¡å—åˆ™é€šè¿‡åé¦ˆæœºåˆ¶ä¸æ–­è°ƒæ•´å’Œæ”¹è¿›æç¤ºï¼Œä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šAPIOçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å®Œå…¨è‡ªåŠ¨åŒ–çš„æç¤ºå¼•å¯¼å’Œä¼˜åŒ–è¿‡ç¨‹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ¶ˆé™¤äº†å¯¹äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒAPIOä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è¯„ä¼°æç¤ºçš„æœ‰æ•ˆæ€§ï¼Œå¹¶é‡‡ç”¨äº†å¤šå±‚æ¬¡çš„ç½‘ç»œç»“æ„ä»¥å¢å¼ºæ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›ï¼Œç¡®ä¿åœ¨ä¸åŒä»»åŠ¡ä¸­éƒ½èƒ½å–å¾—è‰¯å¥½è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒAPIOåœ¨è¯­æ³•é”™è¯¯çº æ­£å’Œæ–‡æœ¬ç®€åŒ–ä»»åŠ¡ä¸Šå®ç°äº†æ–°çš„æ€§èƒ½è®°å½•ï¼Œè¶…è¶Šäº†ç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨åŸºäºLLMçš„æç¤ºæ–¹æ³•ä¸­çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€å†…å®¹åˆ›ä½œå’Œæœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡è‡ªåŠ¨åŒ–çš„æç¤ºä¼˜åŒ–ï¼ŒAPIOèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°è¿›è¡Œæ–‡æœ¬å¤„ç†ï¼Œæå‡æ–‡æœ¬è´¨é‡ï¼Œé™ä½äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.

