---
layout: default
title: LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement
---

# LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08653" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08653v1</a>
  <a href="https://arxiv.org/pdf/2508.08653.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08653v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08653v1', 'LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rajmohan C, Sarthak Harne, Arvind Agarwal

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå­ä»»åŠ¡å¼•å¯¼ä¸è¿­ä»£ä¼˜åŒ–çš„æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»»åŠ¡åˆ†è§£` `è¿­ä»£ä¼˜åŒ–` `è‡ªåé¦ˆæœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³Šæˆ–é¢†åŸŸç‰¹å®šæ•°æ®æ—¶å¸¸å¸¸è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥ç»´æŠ¤è¡¨æ ¼ç»“æ„å’Œè¿›è¡Œæ•°å€¼æ¨ç†ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å°†æ–‡æœ¬åˆ°è¡¨æ ¼ä»»åŠ¡åˆ†è§£ä¸ºå¼•å¯¼å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨è¿­ä»£è‡ªåé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆè¡¨æ ¼ï¼Œä»è€Œæé«˜ç”Ÿæˆè´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ä¸¤ä¸ªå¤æ‚æ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†éç»“æ„åŒ–æ–‡æœ¬è½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®æ˜¯ä¸€é¡¹å¤æ‚çš„ä»»åŠ¡ï¼Œæ¶‰åŠè¯­ä¹‰ç†è§£ã€æ¨ç†å’Œç»“æ„ç†è§£ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·æœ‰æ½œåŠ›ï¼Œä½†åœ¨å¤„ç†æ¨¡ç³Šæˆ–ç‰¹å®šé¢†åŸŸæ•°æ®ã€ç»´æŠ¤è¡¨æ ¼ç»“æ„ã€ç®¡ç†é•¿è¾“å…¥ä»¥åŠè§£å†³æ•°å€¼æ¨ç†æ–¹é¢å¸¸å¸¸é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„LLMé©±åŠ¨æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆç³»ç»Ÿï¼Œåˆ©ç”¨æ–°é¢–çš„æç¤ºæŠ€æœ¯ï¼Œå…·ä½“åŒ…æ‹¬å°†æ–‡æœ¬åˆ°è¡¨æ ¼ä»»åŠ¡åˆ†è§£ä¸ºå¯ç®¡ç†çš„å¼•å¯¼å­ä»»åŠ¡ï¼Œå¹¶é€šè¿‡è¿­ä»£è‡ªåé¦ˆæ¥ä¼˜åŒ–ç”Ÿæˆçš„è¡¨æ ¼ã€‚æˆ‘ä»¬å±•ç¤ºäº†è¿™ç§è‡ªå®šä¹‰ä»»åŠ¡åˆ†è§£èƒ½å¤Ÿä½¿æ¨¡å‹ä»¥é€æ­¥æ–¹å¼è§£å†³é—®é¢˜ï¼Œå¹¶æé«˜ç”Ÿæˆè¡¨æ ¼çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¨è®ºäº†è¿­ä»£è‡ªåé¦ˆå¯¹ç”Ÿæˆè¡¨æ ¼çš„å¥½å¤„å’Œæ½œåœ¨é£é™©ï¼ŒåŒæ—¶å¼ºè°ƒäº†æ€§èƒ½æå‡ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡ã€‚æˆ‘ä»¬çš„ç ”ç©¶åœ¨ä¸¤ä¸ªå…¬å¼€çš„å¤æ‚æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆæ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿å–å¾—äº†æ˜¾è‘—çš„ç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å°†éç»“æ„åŒ–æ–‡æœ¬è½¬åŒ–ä¸ºç»“æ„åŒ–è¡¨æ ¼æ•°æ®çš„å¤æ‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³Šæ•°æ®ã€ç»´æŠ¤è¡¨æ ¼ç»“æ„å’Œè¿›è¡Œæ•°å€¼æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å°†æ–‡æœ¬åˆ°è¡¨æ ¼çš„ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå¯ç®¡ç†çš„å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨è¿­ä»£è‡ªåé¦ˆæœºåˆ¶æ¥é€æ­¥ä¼˜åŒ–ç”Ÿæˆçš„è¡¨æ ¼ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å¤æ‚è¾“å…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä»»åŠ¡åˆ†è§£æ¨¡å—ï¼Œå°†æ–‡æœ¬å†…å®¹åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼›å…¶æ¬¡æ˜¯è¿­ä»£ä¼˜åŒ–æ¨¡å—ï¼Œé€šè¿‡è‡ªåé¦ˆæœºåˆ¶ä¸æ–­æ”¹è¿›ç”Ÿæˆçš„è¡¨æ ¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†ä»»åŠ¡åˆ†è§£ä¸è¿­ä»£è‡ªåé¦ˆçš„ç»“åˆï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€ç”Ÿæˆæ¨¡å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„æ–‡æœ¬è¾“å…¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¨¡å‹é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ç”Ÿæˆè´¨é‡ä¸è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†é€‚åº”æ€§è°ƒæ•´æœºåˆ¶ï¼Œä»¥åº”å¯¹ä¸åŒç±»å‹çš„è¾“å…¥æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ä¸¤ä¸ªå¤æ‚æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆæ•°æ®é›†ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ç”Ÿæˆè¡¨æ ¼çš„å‡†ç¡®æ€§æé«˜äº†20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®æ•´ç†ã€ä¿¡æ¯æå–å’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰ã€‚é€šè¿‡å°†éç»“æ„åŒ–æ–‡æœ¬é«˜æ•ˆè½¬åŒ–ä¸ºç»“æ„åŒ–æ•°æ®ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ•°æ®å¤„ç†çš„è‡ªåŠ¨åŒ–æ°´å¹³ï¼Œé™ä½äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transforming unstructured text into structured data is a complex task, requiring semantic understanding, reasoning, and structural comprehension. While Large Language Models (LLMs) offer potential, they often struggle with handling ambiguous or domain-specific data, maintaining table structure, managing long inputs, and addressing numerical reasoning. This paper proposes an efficient system for LLM-driven text-to-table generation that leverages novel prompting techniques. Specifically, the system incorporates two key strategies: breaking down the text-to-table task into manageable, guided sub-tasks and refining the generated tables through iterative self-feedback. We show that this custom task decomposition allows the model to address the problem in a stepwise manner and improves the quality of the generated table. Furthermore, we discuss the benefits and potential risks associated with iterative self-feedback on the generated tables while highlighting the trade-offs between enhanced performance and computational cost. Our methods achieve strong results compared to baselines on two complex text-to-table generation datasets available in the public domain.

