---
layout: default
title: TEN: Table Explicitization, Neurosymbolically
---

# TEN: Table Explicitization, Neurosymbolically

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09324" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09324v1</a>
  <a href="https://arxiv.org/pdf/2508.09324.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09324v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09324v1', 'TEN: Table Explicitization, Neurosymbolically')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikita Mehrotra, Aayush Kumar, Sumit Gulwani, Arjun Radhakrishna, Ashish Tiwari

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTENæ–¹æ³•ä»¥è§£å†³åŠç»“æ„åŒ–æ–‡æœ¬ä¸­çš„è¡¨æ ¼æ•°æ®æå–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ•°æ®æå–` `åŠç»“æ„åŒ–æ–‡æœ¬` `ç¥ç»ç¬¦å·æ–¹æ³•` `ç»“æ„åˆ†è§£æç¤º` `ç¬¦å·æ£€æŸ¥å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŠç»“æ„åŒ–æ–‡æœ¬æ—¶ï¼Œç¼ºä¹ä¸€è‡´çš„åˆ†éš”ç¬¦ï¼Œå¯¼è‡´è¡¨æ ¼æ•°æ®æå–çš„å‡†ç¡®æ€§å’Œå¯é æ€§ä¸è¶³ã€‚
2. TENæ–¹æ³•ç»“åˆäº†ç¥ç»ç½‘ç»œå’Œç¬¦å·æ¨ç†ï¼Œé€šè¿‡ç»“æ„åˆ†è§£æç¤ºç”Ÿæˆåˆå§‹è¡¨æ ¼ï¼Œå¹¶åˆ©ç”¨ç¬¦å·æ£€æŸ¥å™¨è¿›è¡ŒéªŒè¯å’Œä¿®æ­£ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTENåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†å‡†ç¡®ç‡ï¼Œå‡å°‘äº†å¹»è§‰ç°è±¡ï¼Œå¹¶åœ¨ç”¨æˆ·ç ”ç©¶ä¸­è·å¾—äº†æ›´é«˜çš„ç”¨æˆ·æ»¡æ„åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·æ–¹æ³•TENï¼Œç”¨äºä»åŠç»“æ„åŒ–è¾“å…¥æ–‡æœ¬ä¸­æå–è¡¨æ ¼æ•°æ®ã€‚è¯¥ä»»åŠ¡åœ¨æ²¡æœ‰ä¸€è‡´ä½¿ç”¨ç‰¹æ®Šåˆ†éš”ç¬¦æ¥åˆ†éš”åˆ—å’Œè¡Œçš„æ–‡æœ¬è¾“å…¥ä¸­å°¤ä¸ºå…·æœ‰æŒ‘æˆ˜æ€§ã€‚çº¯ç¥ç»æ–¹æ³•ç”±äºå¹»è§‰å’Œæ— æ³•å¼ºåˆ¶æ‰§è¡Œç¡¬çº¦æŸè€Œè¡¨ç°ä¸ä½³ã€‚TENé‡‡ç”¨ç»“æ„åˆ†è§£æç¤ºï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä¸“é—¨é“¾å¼æ€ç»´æç¤ºæ–¹æ³•ï¼Œç”Ÿæˆåˆå§‹è¡¨æ ¼ã€‚éšåï¼Œä½¿ç”¨ç¬¦å·æ£€æŸ¥å™¨è¯„ä¼°è¡¨æ ¼çš„è‰¯æ„æ€§ï¼Œå¹¶æ£€æµ‹å¹»è§‰æˆ–é—å¿˜çš„æƒ…å†µã€‚ç¬¦å·æ£€æŸ¥å™¨çš„è¾“å‡ºç”±æ‰¹è¯„LLMå¤„ç†ï¼Œä»¥ç”Ÿæˆä¿®å¤è¡¨æ ¼çš„æŒ‡å¯¼ï¼Œå½¢æˆè‡ªæˆ‘è°ƒè¯•å¾ªç¯ã€‚æˆ‘ä»¬çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTENåœ¨å¤šä¸ªæ•°æ®é›†å’ŒæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºçº¯ç¥ç»åŸºçº¿ï¼Œè·å¾—äº†æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ˜¾è‘—é™ä½çš„å¹»è§‰ç‡ã€‚21åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶è¿›ä¸€æ­¥ç¡®è®¤ï¼ŒTENç”Ÿæˆçš„è¡¨æ ¼åœ¨å‡†ç¡®æ€§ä¸Šå¾—åˆ†æ˜¾è‘—æ›´é«˜ï¼Œå¹¶ä¸”åœ¨éªŒè¯å’Œä¿®æ­£çš„ä¾¿åˆ©æ€§ä¸Šæ›´å—æ¬¢è¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä»åŠç»“æ„åŒ–æ–‡æœ¬ä¸­æå–è¡¨æ ¼æ•°æ®çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹ä¸€è‡´åˆ†éš”ç¬¦çš„æƒ…å†µä¸‹ï¼Œå®¹æ˜“å‡ºç°å¹»è§‰å’Œé”™è¯¯ï¼Œå¯¼è‡´æå–ç»“æœä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTENæ–¹æ³•é€šè¿‡ç»“åˆç¥ç»ç½‘ç»œå’Œç¬¦å·æ¨ç†ï¼Œåˆ©ç”¨ç»“æ„åˆ†è§£æç¤ºç”Ÿæˆåˆå§‹è¡¨æ ¼ï¼Œå¹¶é€šè¿‡ç¬¦å·æ£€æŸ¥å™¨è¿›è¡ŒéªŒè¯å’Œä¿®æ­£ï¼Œä»è€Œæé«˜æå–çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTENçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆå§‹è¡¨æ ¼çš„ç»“æ„åˆ†è§£æç¤ºï¼›å…¶æ¬¡æ˜¯ç¬¦å·æ£€æŸ¥å™¨å¯¹ç”Ÿæˆçš„è¡¨æ ¼è¿›è¡Œè¯„ä¼°ï¼Œæ£€æµ‹å…¶è‰¯æ„æ€§å’Œå¹»è§‰ï¼›æœ€åæ˜¯æ‰¹è¯„LLMæ ¹æ®æ£€æŸ¥ç»“æœæä¾›ä¿®æ­£å»ºè®®ï¼Œå½¢æˆè‡ªæˆ‘è°ƒè¯•å¾ªç¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šTENçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ç¥ç»ç½‘ç»œä¸ç¬¦å·æ¨ç†ç›¸ç»“åˆï¼Œåˆ©ç”¨ç»“æ„åˆ†è§£æç¤ºå’Œç¬¦å·æ£€æŸ¥å™¨çš„åŒé‡æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†è¡¨æ ¼æ•°æ®æå–çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿçš„çº¯ç¥ç»æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šTENåœ¨å‚æ•°è®¾ç½®ä¸Šé‡‡ç”¨äº†é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ä¼˜åŒ–ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†å¹»è§‰æ£€æµ‹å’Œè¡¨æ ¼è‰¯æ„æ€§è¯„ä¼°ï¼Œç½‘ç»œç»“æ„åˆ™åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›è¿›è¡Œå®šåˆ¶ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„è¡¨æ ¼ç¬¦åˆé¢„æœŸçš„æ ¼å¼å’Œå†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTENåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºçº¯ç¥ç»åŸºçº¿ï¼Œå‡†ç¡®ç‡æå‡æ˜¾è‘—ï¼Œå…·ä½“è¡¨ç°ä¸ºæ›´é«˜çš„ç²¾ç¡®åŒ¹é…ç‡å’Œæ˜¾è‘—é™ä½çš„å¹»è§‰ç‡ã€‚æ­¤å¤–ï¼Œç”¨æˆ·ç ”ç©¶æ˜¾ç¤ºï¼Œå‚ä¸è€…å¯¹TENç”Ÿæˆçš„è¡¨æ ¼å‡†ç¡®æ€§è¯„åˆ†å¹³å‡ä¸º5.0ï¼Œç›¸è¾ƒäº4.3çš„åŸºçº¿æ˜¾è‘—æé«˜ï¼ˆp = 0.021ï¼‰ï¼Œå¹¶åœ¨60%ä»¥ä¸Šçš„æƒ…å†µä¸‹æ›´å€¾å‘äºé€‰æ‹©TENæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TENæ–¹æ³•åœ¨æ•°æ®æå–ã€ä¿¡æ¯æ•´ç†å’Œè‡ªåŠ¨åŒ–æ–‡æ¡£å¤„ç†ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†åŠç»“æ„åŒ–æ–‡æœ¬ï¼Œæå‡æ•°æ®æå–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œæœªæ¥å¯åœ¨å•†ä¸šæ™ºèƒ½ã€æ³•å¾‹æ–‡æ¡£åˆ†æå’Œå­¦æœ¯ç ”ç©¶ç­‰å¤šä¸ªé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural approaches perform poorly due to hallucinations and their inability to enforce hard constraints. TEN uses Structural Decomposition prompting - a specialized chain-of-thought prompting approach - on a large language model (LLM) to generate an initial table, and thereafter uses a symbolic checker to evaluate not only the well-formedness of that table, but also detect cases of hallucinations or forgetting. The output of the symbolic checker is processed by a critique-LLM to generate guidance for fixing the table, which is presented to the original LLM in a self-debug loop. Our extensive experiments demonstrate that TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A 21-participant user study further confirms that TEN's tables are rated significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are consistently preferred for ease of verification and correction, with participants favoring our method in over 60% of the cases.

