---
layout: default
title: Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models
---

# Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08879" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08879v1</a>
  <a href="https://arxiv.org/pdf/2508.08879.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08879v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08879v1', 'Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haeun Yu, Seogyeong Jeong, Siddhesh Pawar, Jisu Shin, Jiho Jin, Junho Myung, Alice Oh, Isabelle Augenstein

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: 16 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCulturescopeä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡åŒ–åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡åŒ–åè§` `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºåˆ¶å¯è§£é‡Šæ€§` `æ–‡åŒ–çŸ¥è¯†` `æ–‡åŒ–æ‰å¹³åŒ–` `ä½èµ„æºæ–‡åŒ–` `è¥¿æ–¹ä¸»å¯¼åè§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é€šè¿‡å¤–éƒ¨è¯„ä¼°æ¥è€ƒå¯ŸLLMsçš„æ–‡åŒ–èƒ½åŠ›ï¼Œæœªèƒ½æ·±å…¥åˆ†æå…¶å†…éƒ¨æœºåˆ¶å¦‚ä½•å¯¼è‡´æ–‡åŒ–åè§ã€‚
2. æœ¬æ–‡æå‡ºCulturescopeï¼Œé€šè¿‡æœºåˆ¶å¯è§£é‡Šæ€§çš„æ–¹æ³•æ¢è®¨LLMsçš„å†…éƒ¨è¡¨ç¤ºï¼Œæ­ç¤ºå…¶æ–‡åŒ–çŸ¥è¯†ç©ºé—´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨æ–‡åŒ–çŸ¥è¯†ç©ºé—´ä¸­å­˜åœ¨è¥¿æ–¹ä¸»å¯¼åè§å’Œæ–‡åŒ–æ‰å¹³åŒ–ç°è±¡ï¼Œä½èµ„æºæ–‡åŒ–çš„åè§æ•æ„Ÿæ€§è¾ƒä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šå…ƒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„å¹¿æ³›åº”ç”¨ï¼Œç†è§£å…¶å†…éƒ¨æœºåˆ¶å¯¹æ–‡åŒ–ç†è§£çš„å½±å“å˜å¾—å°¤ä¸ºé‡è¦ã€‚ä»¥å¾€çš„ç ”ç©¶ä»…å¯¹LLMsçš„æ–‡åŒ–èƒ½åŠ›è¿›è¡Œå¤–éƒ¨è¯„ä¼°ï¼Œæœªè€ƒè™‘å…¶å†…éƒ¨æœºåˆ¶å¦‚ä½•å¯¼è‡´æ–‡åŒ–ï¼ˆè¯¯ï¼‰è¡¨ç°ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Culturescopeï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæœºåˆ¶å¯è§£é‡Šæ€§çš„æ–¹æ³•ï¼Œæ¢è®¨LLMsçš„å†…éƒ¨è¡¨ç¤ºä»¥æ­ç¤ºå…¶æ–‡åŒ–çŸ¥è¯†ç©ºé—´ã€‚Culturescopeé‡‡ç”¨è¡¥ä¸æ–¹æ³•æå–æ–‡åŒ–çŸ¥è¯†ï¼Œå¹¶å¼•å…¥æ–‡åŒ–æ‰å¹³åŒ–è¯„åˆ†ä½œä¸ºå†…åœ¨æ–‡åŒ–åè§çš„è¡¡é‡æ ‡å‡†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨å…¶æ–‡åŒ–çŸ¥è¯†ç©ºé—´ä¸­ç¼–ç äº†è¥¿æ–¹ä¸»å¯¼åè§å’Œæ–‡åŒ–æ‰å¹³åŒ–ç°è±¡ã€‚ç ”ç©¶å‘ç°ï¼Œä½èµ„æºæ–‡åŒ–å¯¹æ–‡åŒ–åè§çš„æ•æ„Ÿæ€§è¾ƒä½ï¼Œå¯èƒ½ä¸å…¶è®­ç»ƒèµ„æºæœ‰é™æœ‰å…³ã€‚æœ¬æ–‡ä¸ºæœªæ¥å‡è½»æ–‡åŒ–åè§å’Œå¢å¼ºLLMsæ–‡åŒ–ç†è§£æä¾›äº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡åŒ–ç†è§£ä¸­å­˜åœ¨çš„åè§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æ·±å…¥æ¢è®¨å…¶å†…éƒ¨æœºåˆ¶å¦‚ä½•å¯¼è‡´æ–‡åŒ–ï¼ˆè¯¯ï¼‰è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºCulturescopeï¼Œé€šè¿‡æœºåˆ¶å¯è§£é‡Šæ€§çš„æ–¹æ³•åˆ†æLLMsçš„å†…éƒ¨è¡¨ç¤ºï¼Œæå–æ–‡åŒ–çŸ¥è¯†å¹¶é‡åŒ–æ–‡åŒ–åè§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCulturescopeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ–‡åŒ–çŸ¥è¯†æå–ã€æ–‡åŒ–æ‰å¹³åŒ–è¯„åˆ†è®¡ç®—ä»¥åŠåè§åˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥æ–‡åŒ–æ‰å¹³åŒ–è¯„åˆ†ä½œä¸ºè¡¡é‡å†…åœ¨æ–‡åŒ–åè§çš„æ–°æŒ‡æ ‡ï¼Œé¦–æ¬¡ä»æœºåˆ¶å±‚é¢æ¢è®¨LLMsçš„æ–‡åŒ–çŸ¥è¯†ç©ºé—´ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡‡ç”¨è¡¥ä¸æ–¹æ³•æå–æ–‡åŒ–çŸ¥è¯†ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ–‡åŒ–çŸ¥è¯†çš„è¡¨ç¤ºï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ–‡åŒ–åè§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨å…¶æ–‡åŒ–çŸ¥è¯†ç©ºé—´ä¸­æ˜¾è‘—ç¼–ç äº†è¥¿æ–¹ä¸»å¯¼åè§å’Œæ–‡åŒ–æ‰å¹³åŒ–ç°è±¡ã€‚ç ”ç©¶å‘ç°ï¼Œä½èµ„æºæ–‡åŒ–å¯¹æ–‡åŒ–åè§çš„æ•æ„Ÿæ€§è¾ƒä½ï¼Œå¯èƒ½ä¸å…¶è®­ç»ƒèµ„æºçš„é™åˆ¶æœ‰å…³ã€‚è¿™äº›å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†é‡è¦çš„å®è¯åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ–‡åŒ–ç ”ç©¶å’Œç¤¾ä¼šç§‘å­¦ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£LLMsçš„æ–‡åŒ–åè§ï¼Œèƒ½å¤Ÿä¸ºæ¨¡å‹çš„å…¬å¹³æ€§å’Œå¤šæ ·æ€§æä¾›ç†è®ºæ”¯æŒï¼Œä¿ƒè¿›æ›´å…·åŒ…å®¹æ€§çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœå¯ä¸ºå‡è½»æ–‡åŒ–åè§æä¾›æŒ‡å¯¼ï¼Œæå‡LLMsåœ¨å¤šæ–‡åŒ–ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing deployment of large language models (LLMs) across diverse cultural contexts necessitates a better understanding of how the overgeneralization of less documented cultures within LLMs' representations impacts their cultural understanding. Prior work only performs extrinsic evaluation of LLMs' cultural competence, without accounting for how LLMs' internal mechanisms lead to cultural (mis)representation. To bridge this gap, we propose Culturescope, the first mechanistic interpretability-based method that probes the internal representations of LLMs to elicit the underlying cultural knowledge space. CultureScope utilizes a patching method to extract the cultural knowledge. We introduce a cultural flattening score as a measure of the intrinsic cultural biases. Additionally, we study how LLMs internalize Western-dominance bias and cultural flattening, which allows us to trace how cultural biases emerge within LLMs. Our experimental results reveal that LLMs encode Western-dominance bias and cultural flattening in their cultural knowledge space. We find that low-resource cultures are less susceptible to cultural biases, likely due to their limited training resources. Our work provides a foundation for future research on mitigating cultural biases and enhancing LLMs' cultural understanding. Our codes and data used for experiments are publicly available.

