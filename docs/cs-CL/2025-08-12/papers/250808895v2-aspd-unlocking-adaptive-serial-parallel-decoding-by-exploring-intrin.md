---
layout: default
title: ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs
---

# ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08895" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.08895v2</a>
  <a href="https://arxiv.org/pdf/2508.08895.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08895v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08895v2', 'ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Keyu Chen, Zhifeng Shen, Daohai Yu, Haoqian Wu, Wei Wen, Jianfeng He, Ruizhi Qiao, Xing Sun

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-12 (Êõ¥Êñ∞: 2025-08-14)

**Â§áÊ≥®**: 20 pages, 9 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Ëá™ÈÄÇÂ∫î‰∏≤Ë°å-Âπ∂Ë°åËß£Á†Å‰ª•Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÊé®ÁêÜÂª∂ËøüÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÈÄÇÂ∫îËß£Á†Å` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Âπ∂Ë°åËÆ°ÁÆó` `Êé®ÁêÜÂä†ÈÄü` `Ê∑∑ÂêàËß£Á†ÅÂºïÊìé`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Èù¢‰∏¥ÊòæËëóÁöÑÂª∂ËøüÊåëÊàòÔºå‰∏ªË¶ÅÁî±‰∫éËá™ÂõûÂΩíËß£Á†ÅÁöÑÈ°∫Â∫èÁâπÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Ëá™ÈÄÇÂ∫î‰∏≤Ë°å-Âπ∂Ë°åËß£Á†ÅÔºàASPDÔºâÔºåÈÄöËøáËá™Âä®ÊèêÂèñÂèØÂπ∂Ë°åÂåñÁªìÊûÑÊù•ÊèêÂçáËß£Á†ÅÊïàÁéá„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåASPDÂú®Â§ö‰∏™‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂ∞§ÂÖ∂Âú®ÈÄüÂ∫¶ÂíåÁîüÊàêË¥®ÈáèÊñπÈù¢Ë°®Áé∞‰ºòÂºÇ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËßÑÊ®°ÂíåÂ§çÊùÇÊÄßÁöÑÂ¢ûÂä†ÔºåÊé®ÁêÜÂª∂ËøüÈóÆÈ¢òÊó•Áõä‰∏•ÈáçÔºå‰∏ªË¶ÅÊ∫ê‰∫éÂÖ∂Ëá™ÂõûÂΩíËß£Á†ÅËåÉÂºèÁöÑÈ°∫Â∫èÁâπÊÄß„ÄÇÈÄöËøáÈáçÊñ∞ÂÆ°ËßÜËá™ÂõûÂΩíÊ®°ÂûãÁöÑËæìÂá∫ÔºåÂèëÁé∞Êüê‰∫õÁâáÊÆµÂÖ∑ÊúâÂèØÂπ∂Ë°åÂåñÁöÑÁªìÊûÑÔºåÁß∞‰∏∫ÂÜÖÂú®Âπ∂Ë°åÊÄß„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËá™ÈÄÇÂ∫î‰∏≤Ë°å-Âπ∂Ë°åËß£Á†ÅÔºàASPDÔºâÊñπÊ≥ïÔºåËá™Âä®ÊûÑÂª∫ÂèØÂπ∂Ë°åÂåñÊï∞ÊçÆÂπ∂ÂÆûÁé∞È´òÊïàÁöÑÂπ∂Ë°åËß£Á†ÅÊú∫Âà∂„ÄÇÊàë‰ª¨ÂÆûÁé∞‰∫Ü‰∏Ä‰∏™Ê∑∑ÂêàËß£Á†ÅÂºïÊìéÔºåËÉΩÂ§üÂú®‰∏≤Ë°åÂíåÂπ∂Ë°åËß£Á†ÅÊ®°Âºè‰πãÈó¥Êó†ÁºùÂàáÊç¢ÔºåÂêåÊó∂‰øùÊåÅÂèØÈáçÁî®ÁöÑKVÁºìÂ≠òÔºåÊúÄÂ§ßÂåñËÆ°ÁÆóÊïàÁéá„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåASPDÂú®Â§ö‰∏™‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÂâçÊâÄÊú™ÊúâÁöÑÊïàÊûúÂíåÊïàÁéáÊèêÂçáÔºåÂ∞§ÂÖ∂Âú®Vicuna Bench‰∏äÔºåÈÄüÂ∫¶ÊèêÂçáËææÂà∞3.19ÂÄçÔºåÂπ≥ÂùáÊèêÂçá1.85ÂÄçÔºåÂêåÊó∂ÁîüÊàêË¥®Èáè‰øùÊåÅÂú®1%ÁöÑÂ∑ÆÂºÇËåÉÂõ¥ÂÜÖ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Áî±‰∫éËá™ÂõûÂΩíËß£Á†ÅÁöÑÈ°∫Â∫èÁâπÊÄßÂØºËá¥ÁöÑÂª∂ËøüÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂà©Áî®Ê®°ÂûãËæìÂá∫‰∏≠ÁöÑÂèØÂπ∂Ë°åÂåñÁªìÊûÑÔºåÈôêÂà∂‰∫ÜÊé®ÁêÜÈÄüÂ∫¶ÁöÑÊèêÂçá„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáËØÜÂà´ÂíåÊèêÂèñËá™ÂõûÂΩíÊ®°ÂûãËæìÂá∫‰∏≠ÁöÑÂÜÖÂú®Âπ∂Ë°åÊÄßÔºåÈááÁî®Ëá™ÈÄÇÂ∫î‰∏≤Ë°å-Âπ∂Ë°åËß£Á†ÅÁ≠ñÁï•ÔºåÂÖÅËÆ∏ÂêåÊó∂Ëß£Á†ÅÂ§ö‰∏™ÂèØÂπ∂Ë°åÂåñÁöÑÂàÜÊîØÔºå‰ªéËÄåÊòæËëóÊèêÈ´òÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏Ä‰∏™Èùû‰æµÂÖ•ÂºèÁÆ°ÈÅìÔºåÁî®‰∫éËá™Âä®ÊèêÂèñÂíåÈ™åËØÅÂèØÂπ∂Ë°åÂåñÁªìÊûÑÔºå‰ª•Âèä‰∏Ä‰∏™Ê∑∑ÂêàËß£Á†ÅÂºïÊìéÔºåÊîØÊåÅ‰∏≤Ë°å‰∏éÂπ∂Ë°åËß£Á†ÅÊ®°ÂºèÁöÑÊó†ÁºùÂàáÊç¢„ÄÇËØ•Ê°ÜÊû∂ËøòÁª¥Êä§‰∏Ä‰∏™ÂèØÈáçÁî®ÁöÑKVÁºìÂ≠òÔºå‰ª•ÊèêÈ´òËÆ°ÁÆóÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜËá™ÈÄÇÂ∫î‰∏≤Ë°å-Âπ∂Ë°åËß£Á†ÅÊú∫Âà∂ÔºåËÉΩÂ§üËá™Âä®ËØÜÂà´Âπ∂Âà©Áî®Ê®°ÂûãËæìÂá∫‰∏≠ÁöÑÂπ∂Ë°åÁªìÊûÑÔºå‰∏é‰º†ÁªüÁöÑÈ°∫Â∫èËß£Á†ÅÊñπÊ≥ïÊú¨Ë¥®‰∏ä‰∏çÂêå„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÈ´òÊïàÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÔºåÁ°Æ‰øùÂú®Âπ∂Ë°åËß£Á†ÅÊó∂ËÉΩÂ§ü‰øùÊåÅÁîüÊàêË¥®ÈáèÔºåÂêåÊó∂‰ºòÂåñ‰∫ÜÁΩëÁªúÁªìÊûÑ‰ª•ÊîØÊåÅÊ∑∑ÂêàËß£Á†ÅÊ®°Âºè„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ÂíåÁªìÊûÑÁªÜËäÇÂú®ÂÆûÈ™åÈÉ®ÂàÜËøõË°å‰∫ÜËØ¶ÁªÜËØ¥Êòé„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåASPDÂú®Vicuna Bench‰∏äÂÆûÁé∞‰∫ÜÊúÄÈ´ò3.19ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºåÂπ≥ÂùáÊèêÂçá‰∏∫1.85ÂÄçÔºåÂêåÊó∂ÁîüÊàêË¥®Èáè‰∏éËá™ÂõûÂΩíÊ®°ÂûãÁõ∏ÊØî‰øùÊåÅÂú®1%ÁöÑÂ∑ÆÂºÇËåÉÂõ¥ÂÜÖ„ÄÇËøô‰∏ÄÁªìÊûúË°®ÊòéÔºåASPDÂú®ÊïàÁéáÂíåÊïàÊûú‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨AIÈ©±Âä®ÁöÑÂÆ¢Êà∑ÊúçÂä°Êú∫Âô®‰∫∫ÂíåÁ≠îÊ°àÊ£ÄÁ¥¢ÂºïÊìéÁ≠âÂª∂ËøüÊïèÊÑüÁöÑÂ∫îÁî®Âú∫ÊôØ„ÄÇÈÄöËøáÊòæËëóÊèêÂçáÊé®ÁêÜÈÄüÂ∫¶ÔºåASPDËÉΩÂ§ü‰∏∫ÂÆûÊó∂‰∫§‰∫íÂíåÂø´ÈÄüÂìçÂ∫îÁöÑÂ∫îÁî®Êèê‰æõÊîØÊåÅÔºåÊé®Âä®Â§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂú∫ÊôØ‰∏≠ÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.

