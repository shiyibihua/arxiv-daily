---
layout: default
title: A Survey on Training-free Alignment of Large Language Models
---

# A Survey on Training-free Alignment of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09016" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09016v4</a>
  <a href="https://arxiv.org/pdf/2508.09016.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09016v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09016v4', 'A Survey on Training-free Alignment of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Birong Pan, Yongqi Li, Weiyu Zhang, Wenpeng Lu, Mayi Xu, Shen Zhou, Yuanyuan Zhu, Ming Zhong, Tieyun Qian

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-09-10)

**å¤‡æ³¨**: Accepted to EMNLP 2025 (findings), camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— è®­ç»ƒå¯¹é½æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¯¹é½æŠ€æœ¯` `æ— è®­ç»ƒæ–¹æ³•` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ç”Ÿæˆåä¿®æ­£` `ä¼¦ç†AI` `å¤šæ¨¡æ€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹é½æ–¹æ³•ä¾èµ–äºå¾®è°ƒï¼Œé¢ä¸´çŸ¥è¯†é€€åŒ–å’Œèµ„æºé™åˆ¶ç­‰æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºæ— è®­ç»ƒå¯¹é½æŠ€æœ¯ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å’Œåç”Ÿæˆä¿®æ­£å®ç°å¯¹é½ï¼Œé¿å…é‡è®­ç»ƒã€‚
3. ç³»ç»Ÿæ€§å›é¡¾TFå¯¹é½æ–¹æ³•ï¼Œè¯†åˆ«å…³é”®æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›æŒ‡å¯¼ï¼Œæ¨åŠ¨æ›´å®‰å…¨çš„LLMså‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¯¹é½æ—¨åœ¨ç¡®ä¿å…¶è¾“å‡ºç¬¦åˆäººç±»ä»·å€¼è§‚ã€ä¼¦ç†æ ‡å‡†å’Œæ³•å¾‹è§„èŒƒã€‚ä¼ ç»Ÿçš„å¯¹é½æ–¹æ³•é€šå¸¸ä¾èµ–äºèµ„æºå¯†é›†å‹çš„å¾®è°ƒï¼ˆFTï¼‰ï¼Œè¿™å¯èƒ½å¯¼è‡´çŸ¥è¯†é€€åŒ–ï¼Œå¹¶åœ¨æ¨¡å‹å¯è®¿é—®æ€§æˆ–è®¡ç®—èµ„æºå—é™çš„æƒ…å†µä¸‹é¢ä¸´æŒ‘æˆ˜ã€‚ç›¸è¾ƒä¹‹ä¸‹ï¼Œæ— è®­ç»ƒï¼ˆTFï¼‰å¯¹é½æŠ€æœ¯é€šè¿‡åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ã€è§£ç æ—¶è°ƒæ•´å’Œç”Ÿæˆåä¿®æ­£ï¼Œæä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½¿å¾—å¯¹é½æ— éœ€é‡è®­ç»ƒLLMsï¼Œä»è€Œé€‚åº”å¼€æ”¾æºä»£ç å’Œé—­æºç¯å¢ƒã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§å›é¡¾äº†TFå¯¹é½æ–¹æ³•ï¼ŒæŒ‰é¢„è§£ç ã€è§£ç ä¸­å’Œåè§£ç é˜¶æ®µè¿›è¡Œåˆ†ç±»ï¼Œè¯¦ç»†æ¢è®¨äº†æ¯ä¸ªé˜¶æ®µçš„æœºåˆ¶å’Œå±€é™æ€§ï¼Œå¹¶è¯†åˆ«äº†å…³é”®æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ï¼Œä¸ºæ›´å…·åŒ…å®¹æ€§å’Œæœ‰æ•ˆæ€§çš„TFå¯¹é½æŠ€æœ¯é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³å¤§è¯­è¨€æ¨¡å‹å¯¹é½çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–å¾®è°ƒï¼Œå¯¼è‡´çŸ¥è¯†é€€åŒ–å’Œèµ„æºæ¶ˆè€—å¤§ï¼Œé™åˆ¶äº†æ¨¡å‹çš„é€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºæ— è®­ç»ƒå¯¹é½æ–¹æ³•ï¼Œåˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ã€è§£ç æ—¶è°ƒæ•´å’Œåç”Ÿæˆä¿®æ­£ï¼Œå®ç°å¯¹é½è€Œæ— éœ€é‡è®­ç»ƒï¼Œæå‡äº†å¯¹é½çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šé¢„è§£ç é˜¶æ®µã€è§£ç ä¸­é˜¶æ®µå’Œåè§£ç é˜¶æ®µã€‚æ¯ä¸ªé˜¶æ®µéƒ½æœ‰ç‰¹å®šçš„å¯¹é½æœºåˆ¶ï¼Œç¡®ä¿æ¨¡å‹è¾“å‡ºç¬¦åˆäººç±»ä»·å€¼è§‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ— è®­ç»ƒå¯¹é½çš„å®ç°æ–¹å¼ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•çš„é‡è®­ç»ƒï¼Œæä¾›äº†ä¸€ç§æ›´é«˜æ•ˆçš„å¯¹é½ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸Šä¸‹æ–‡å­¦ä¹ æœºåˆ¶å’ŒåŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒç¯å¢ƒä¸‹çš„é€‚åº”æ€§ï¼ŒåŒæ—¶å…³æ³¨ç”Ÿæˆåä¿®æ­£çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ— è®­ç»ƒå¯¹é½æ–¹æ³•çš„æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”åœ¨èµ„æºæ¶ˆè€—ä¸Šæ˜¾è‘—é™ä½ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†æ— è®­ç»ƒå¯¹é½æŠ€æœ¯çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€å†…å®¹ç”Ÿæˆå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡å®ç°æ›´å®‰å…¨å’Œå¯é çš„å¯¹é½ï¼Œèƒ½å¤Ÿæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼¦ç†æ€§å’Œåˆè§„æ€§ï¼Œä¿ƒè¿›å…¶åœ¨æ•æ„Ÿé¢†åŸŸçš„åº”ç”¨ã€‚æœªæ¥ï¼Œéšç€å¯¹é½æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨æ›´å¹¿æ³›çš„AIç³»ç»Ÿä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½çš„å¥åº·å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The alignment of large language models (LLMs) aims to ensure their outputs adhere to human values, ethical standards, and legal norms. Traditional alignment methods often rely on resource-intensive fine-tuning (FT), which may suffer from knowledge degradation and face challenges in scenarios where the model accessibility or computational resources are constrained. In contrast, training-free (TF) alignment techniques--leveraging in-context learning, decoding-time adjustments, and post-generation corrections--offer a promising alternative by enabling alignment without heavily retraining LLMs, making them adaptable to both open-source and closed-source environments. This paper presents the first systematic review of TF alignment methods, categorizing them by stages of pre-decoding, in-decoding, and post-decoding. For each stage, we provide a detailed examination from the viewpoint of LLMs and multimodal LLMs (MLLMs), highlighting their mechanisms and limitations. Furthermore, we identify key challenges and future directions, paving the way for more inclusive and effective TF alignment techniques. By synthesizing and organizing the rapidly growing body of research, this survey offers a guidance for practitioners and advances the development of safer and more reliable LLMs.

