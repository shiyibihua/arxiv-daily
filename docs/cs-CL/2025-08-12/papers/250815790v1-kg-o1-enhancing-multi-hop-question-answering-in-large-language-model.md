---
layout: default
title: KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration
---

# KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15790" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15790v1</a>
  <a href="https://arxiv.org/pdf/2508.15790.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15790v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15790v1', 'KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nan Wang, Yongqi Fan, yansha zhu, ZongYu Wang, Xuezhi Cao, Xinyan He, Haiyun Jiang, Tong Ruan, Jingping Liu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKG-o1ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¤šè·³é—®ç­”èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `å¤šè·³é—®ç­”` `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `é•¿æ­¥æ¨ç†` `æ‹’ç»é‡‡æ ·` `æ™ºèƒ½é—®ç­”` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œç”Ÿæˆçš„æ€ç»´é“¾å¸¸å¸¸ä¸çœŸå®æ¨ç†è·¯å¾„ä¸ç¬¦ã€‚
2. KG-o1é€šè¿‡å››ä¸ªé˜¶æ®µæ•´åˆçŸ¥è¯†å›¾è°±ï¼Œé¦–å…ˆç”Ÿæˆå¤æ‚å­å›¾ï¼Œç„¶åæ„å»ºé€»è¾‘è·¯å¾„ï¼Œæœ€åé€šè¿‡æ‹’ç»é‡‡æ ·ä¼˜åŒ–LLMsçš„æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKG-o1åœ¨ç®€å•å’Œå¤æ‚æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰LRMsï¼Œæå‡äº†å¤šè·³é—®ç­”çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç»å…¸çš„å¤šè·³é—®ç­”ä¸­ï¼ŒLLMsç”Ÿæˆçš„æ€ç»´é“¾ï¼ˆCoTsï¼‰å¾€å¾€åç¦»çœŸå®çš„æ¨ç†è·¯å¾„ã€‚çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰é€šè¿‡å®ä½“å’Œå…³ç³»æ˜ç¡®è¡¨ç¤ºäº‹å®ä¹‹é—´çš„é€»è¾‘è¿æ¥ï¼Œå¡«è¡¥äº†è¿™ä¸€å·®è·ã€‚åŸºäºæ­¤ï¼Œæœ¬æ–‡æå‡ºKG-o1ï¼Œä¸€ä¸ªå››é˜¶æ®µçš„æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆçŸ¥è¯†å›¾è°±æ¥å¢å¼ºLLMsçš„å¤šè·³æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒKG-o1æ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºç°æœ‰çš„å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†çŸ¥è¯†å¯†é›†å‹æ¨ç†æ—¶å¸¸å¸¸åç¦»çœŸå®æ¨ç†è·¯å¾„ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKG-o1çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ•´åˆçŸ¥è¯†å›¾è°±æ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨KGsæ˜ç¡®è¡¨ç¤ºäº‹å®ä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼Œä»è€ŒæŒ‡å¯¼LLMsè¿›è¡Œæ›´æœ‰æ•ˆçš„æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKG-o1çš„æ•´ä½“æ¶æ„åˆ†ä¸ºå››ä¸ªé˜¶æ®µï¼šé¦–å…ˆè¿‡æ»¤åˆå§‹å®ä½“å¹¶ç”Ÿæˆå¤æ‚å­å›¾ï¼›å…¶æ¬¡ä¸ºå­å›¾æ„å»ºé€»è¾‘è·¯å¾„ï¼›ç„¶ååˆ©ç”¨çŸ¥è¯†å›¾è°±æ„å»ºæ•°æ®é›†ä»¥è®­ç»ƒLLMsæ¨¡ä»¿é•¿æœŸæ¨ç†ï¼›æœ€åé‡‡ç”¨æ‹’ç»é‡‡æ ·ç”Ÿæˆè‡ªæˆ‘æ”¹è¿›çš„è¯­æ–™åº“ä»¥ä¼˜åŒ–æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šKG-o1çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†çŸ¥è¯†å›¾è°±ä¸é•¿æ­¥æ¨ç†æ¨¡å‹ç›¸ç»“åˆï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œè¿™ä¸€æ–¹æ³•åœ¨é€»è¾‘è·¯å¾„æ„å»ºå’Œè‡ªæˆ‘æ”¹è¿›è¯­æ–™ç”Ÿæˆæ–¹é¢å…·æœ‰ç‹¬ç‰¹æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒKG-o1é‡‡ç”¨äº†å¤æ‚å­å›¾ç”Ÿæˆå’Œé€»è¾‘è·¯å¾„æ„å»ºçš„ç­–ç•¥ï¼Œç»“åˆæ‹’ç»é‡‡æ ·æŠ€æœ¯ï¼Œç¡®ä¿ç”Ÿæˆçš„è¯­æ–™åº“èƒ½å¤Ÿæœ‰æ•ˆæå‡LLMsçš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

KG-o1åœ¨å®éªŒä¸­å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ•°æ®é›†ä¸Šï¼Œç›¸è¾ƒäºç°æœ‰çš„LRMsï¼ŒKG-o1æ¨¡å‹åœ¨å¤šè·³é—®ç­”ä»»åŠ¡ä¸­æå‡äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨çŸ¥è¯†æ¨ç†æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

KG-o1çš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†ç®¡ç†ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤šè·³é—®ç­”èƒ½åŠ›ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ”¯æŒå¤æ‚é—®é¢˜çš„è§£ç­”ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) face challenges in knowledge-intensive reasoning tasks like classic multi-hop question and answering, which involves reasoning across multiple facts. This difficulty arises because the chain of thoughts (CoTs) generated by LLMs in such tasks often deviate from real or a priori reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the logical connections between facts through entities and relationships. This reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as o1, have demonstrated that long-step reasoning significantly enhances the performance of LLMs. Building on these insights, we propose KG-o1, a four-stage approach that integrates KGs to enhance the multi-hop reasoning abilities of LLMs. We first filter out initial entities and generate complex subgraphs. Secondly, we construct logical paths for subgraphs and then use knowledge graphs to build a dataset with a complex and extended brainstorming process, which trains LLMs to imitate long-term reasoning. Finally, we employ rejection sampling to generate a self-improving corpus for direct preference optimization (DPO), further refining the LLMs reasoning abilities. We conducted experiments on two simple and two complex datasets. The results show that KG-o1 models exhibit superior performance across all tasks compared to existing LRMs.

