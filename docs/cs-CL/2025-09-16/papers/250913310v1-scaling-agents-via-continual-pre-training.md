---
layout: default
title: Scaling Agents via Continual Pre-training
---

# Scaling Agents via Continual Pre-training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13310" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13310v1</a>
  <a href="https://arxiv.org/pdf/2509.13310.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13310v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13310v1', 'Scaling Agents via Continual Pre-training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liangcai Su, Zhen Zhang, Guangyu Li, Zhuo Chen, Chenxi Wang, Maojia Song, Xinyu Wang, Kuan Li, Jialong Wu, Xuanzhong Chen, Zile Qiao, Zhongwang Zhang, Huifeng Yin, Shihao Cai, Runnan Fang, Zhengwei Tao, Wenbiao Yin, Chenxiong Qian, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-16

**å¤‡æ³¨**: https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentic CPTï¼Œæ„å»ºå¼ºå¤§çš„AgenticåŸºç¡€æ¨¡å‹ï¼Œæå‡æ™ºèƒ½ä½“ä»»åŠ¡æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ™ºèƒ½ä½“` `æŒç»­é¢„è®­ç»ƒ` `å¤§è¯­è¨€æ¨¡å‹` `å·¥å…·ä½¿ç”¨` `Agentic CPT`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ™ºèƒ½ä½“åè®­ç»ƒæ–¹æ³•åœ¨å¼€æºå®ç°ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦åŸå› æ˜¯ç¼ºä¹å¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ã€‚
2. è®ºæ–‡æå‡ºAgenticæŒç»­é¢„è®­ç»ƒï¼ˆAgentic CPTï¼‰æ–¹æ³•ï¼Œç”¨äºæ„å»ºæ›´å¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAgentFounderåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶ä¿æŒäº†å¼ºå¤§çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²ç»å‘å±•æˆä¸ºå…·æœ‰è‡ªä¸»å·¥å…·ä½¿ç”¨å’Œå¤šæ­¥éª¤æ¨ç†èƒ½åŠ›çš„æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¯ä»¥è§£å†³å¤æ‚çš„éš¾é¢˜ã€‚ç„¶è€Œï¼Œåœ¨é€šç”¨åŸºç¡€æ¨¡å‹ä¸Šè¿›è¡Œåè®­ç»ƒçš„æ–¹æ³•åœ¨æ™ºèƒ½ä½“ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å¼€æºå®ç°ä¸­ã€‚æˆ‘ä»¬å‘ç°æ ¹æœ¬åŸå› æ˜¯ç¼ºä¹å¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ï¼Œè¿™è¿«ä½¿æ¨¡å‹åœ¨åè®­ç»ƒæœŸé—´åŒæ—¶å­¦ä¹ å„ç§æ™ºèƒ½ä½“è¡Œä¸ºï¼Œå¹¶å°†å…¶ä¸ä¸“å®¶æ¼”ç¤ºå¯¹é½ï¼Œä»è€Œé€ æˆæ ¹æœ¬çš„ä¼˜åŒ–å†²çªã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–æ¬¡æå‡ºå°†AgenticæŒç»­é¢„è®­ç»ƒï¼ˆAgentic CPTï¼‰çº³å…¥æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“è®­ç»ƒæµç¨‹ä¸­ï¼Œä»¥æ„å»ºå¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ã€‚åŸºäºæ­¤æ–¹æ³•ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåä¸ºAgentFounderçš„æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨10ä¸ªåŸºå‡†æµ‹è¯•ä¸­è¯„ä¼°äº†æˆ‘ä»¬çš„AgentFounder-30Bï¼Œå¹¶å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å¼ºå¤§çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨BrowseComp-enä¸Šè¾¾åˆ°39.9%ï¼Œåœ¨BrowseComp-zhä¸Šè¾¾åˆ°43.3%ï¼Œåœ¨HLEä¸Šè¾¾åˆ°31.5%çš„Pass@1ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨é€šç”¨å¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œåè®­ç»ƒï¼Œä»¥èµ‹äºˆæ¨¡å‹æ™ºèƒ½ä½“èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹ä¸“é—¨ä¸ºæ™ºèƒ½ä½“ä»»åŠ¡ä¼˜åŒ–çš„åŸºç¡€æ¨¡å‹ï¼Œåè®­ç»ƒè¿‡ç¨‹éœ€è¦åŒæ—¶å­¦ä¹ å¤šç§æ™ºèƒ½ä½“è¡Œä¸ºå¹¶å¯¹é½ä¸“å®¶æ¼”ç¤ºï¼Œå¯¼è‡´ä¼˜åŒ–å›°éš¾ï¼Œæ€§èƒ½å—é™ã€‚å°¤å…¶æ˜¯åœ¨å¼€æºåœºæ™¯ä¸‹ï¼Œè¿™ä¸€é—®é¢˜æ›´åŠ çªå‡ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å…ˆé€šè¿‡AgenticæŒç»­é¢„è®­ç»ƒï¼ˆAgentic CPTï¼‰æ„å»ºä¸€ä¸ªå¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ï¼Œç„¶åå†è¿›è¡Œåç»­çš„å¾®è°ƒæˆ–å¯¹é½ã€‚è¿™æ ·å¯ä»¥é¿å…åè®­ç»ƒé˜¶æ®µåŒæ—¶å­¦ä¹ å¤šç§å¤æ‚è¡Œä¸ºçš„å›°éš¾ï¼Œä»è€Œæå‡æ™ºèƒ½ä½“ä»»åŠ¡çš„æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAgentFounderçš„è®­ç»ƒæµç¨‹åŒ…å«Agentic CPTé˜¶æ®µå’Œåç»­çš„å¾®è°ƒé˜¶æ®µã€‚Agentic CPTé˜¶æ®µåˆ©ç”¨å¤§é‡çš„æ™ºèƒ½ä½“äº¤äº’æ•°æ®ï¼ŒæŒç»­é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡åˆæ­¥çš„æ™ºèƒ½ä½“èƒ½åŠ›ã€‚åç»­çš„å¾®è°ƒé˜¶æ®µåˆ™æ ¹æ®å…·ä½“çš„ä»»åŠ¡éœ€æ±‚ï¼Œå¯¹æ¨¡å‹è¿›è¡Œè¿›ä¸€æ­¥çš„ä¼˜åŒ–å’Œå¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†Agentic CPTçš„æ¦‚å¿µï¼Œå¹¶å°†å…¶åº”ç”¨äºæ™ºèƒ½ä½“æ¨¡å‹çš„è®­ç»ƒä¸­ã€‚ä¸ä¼ ç»Ÿçš„åè®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒAgentic CPTèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ„å»ºæ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ï¼Œä»è€Œæå‡æ™ºèƒ½ä½“ä»»åŠ¡çš„æ€§èƒ½ã€‚è¿™æ˜¯é¦–æ¬¡å°†æŒç»­é¢„è®­ç»ƒçš„æ€æƒ³åº”ç”¨äºæ™ºèƒ½ä½“é¢†åŸŸã€‚

**å…³é”®è®¾è®¡**ï¼šAgentic CPTé˜¶æ®µçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ•°æ®ï¼Œæ¶µç›–å„ç§æ™ºèƒ½ä½“äº¤äº’åœºæ™¯ï¼›2) è®¾è®¡åˆé€‚çš„é¢„è®­ç»ƒç›®æ ‡ï¼Œä¾‹å¦‚æ¨¡ä»¿å­¦ä¹ ã€å¥–åŠ±æœ€å¤§åŒ–ç­‰ï¼›3) è°ƒæ•´é¢„è®­ç»ƒçš„è§„æ¨¡å’Œè¿­ä»£æ¬¡æ•°ï¼Œä»¥è·å¾—æœ€ä½³çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AgentFounder-30Båœ¨10ä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨BrowseComp-enä¸Šè¾¾åˆ°39.9%ï¼Œåœ¨BrowseComp-zhä¸Šè¾¾åˆ°43.3%ï¼Œåœ¨HLEä¸Šè¾¾åˆ°31.5%çš„Pass@1ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAgentic CPTèƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡æ™ºèƒ½ä½“æ¨¡å‹çš„æ€§èƒ½ï¼Œä½¿å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æ™ºèƒ½ä½“è‡ªä¸»å®Œæˆä»»åŠ¡çš„åœºæ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨åŒ–ç ”ç©¶ã€æ™ºèƒ½å®¢æœã€è‡ªåŠ¨åŒ–ç¼–ç¨‹ç­‰ã€‚é€šè¿‡æ„å»ºæ›´å¼ºå¤§çš„æ™ºèƒ½ä½“åŸºç¡€æ¨¡å‹ï¼Œå¯ä»¥æå‡è¿™äº›åº”ç”¨çš„æ™ºèƒ½åŒ–æ°´å¹³å’Œæ•ˆç‡ï¼Œå¹¶é™ä½å¼€å‘æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨æ™ºèƒ½ä½“æŠ€æœ¯åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have evolved into agentic systems capable of autonomous tool use and multi-step reasoning for complex problem-solving. However, post-training approaches building upon general-purpose foundation models consistently underperform in agentic tasks, particularly in open-source implementations. We identify the root cause: the absence of robust agentic foundation models forces models during post-training to simultaneously learn diverse agentic behaviors while aligning them to expert demonstrations, thereby creating fundamental optimization tensions. To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline to build powerful agentic foundational models. Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve state-of-the-art performance while retains strong tool-use ability, notably 39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.

