---
layout: default
title: Towards General Agentic Intelligence via Environment Scaling
---

# Towards General Agentic Intelligence via Environment Scaling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13311" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13311v1</a>
  <a href="https://arxiv.org/pdf/2509.13311.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13311v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13311v1', 'Towards General Agentic Intelligence via Environment Scaling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Runnan Fang, Shihao Cai, Baixuan Li, Jialong Wu, Guangyu Li, Wenbiao Yin, Xinyu Wang, Xiaobin Wang, Liangcai Su, Zhen Zhang, Shibin Wu, Zhengwei Tao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-16

**å¤‡æ³¨**: https://tongyi-agent.github.io/blog/introducing-tongyi-deep-research/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AgentScalerï¼šé€šè¿‡ç¯å¢ƒæ‰©å±•æå‡é€šç”¨Agentæ™ºèƒ½ï¼Œå¢å¼ºå‡½æ•°è°ƒç”¨èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Agentæ™ºèƒ½` `å‡½æ•°è°ƒç”¨` `ç¯å¢ƒæ‰©å±•` `æ¨¡æ‹Ÿç¯å¢ƒ` `ä¸¤é˜¶æ®µå¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Agentåœ¨å¤æ‚ã€å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•ŒAPIäº¤äº’ä¸­ï¼Œå‡½æ•°è°ƒç”¨èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚
2. æå‡ºAgentScaleræ¡†æ¶ï¼Œé€šè¿‡è‡ªåŠ¨æ„å»ºå¼‚æ„æ¨¡æ‹Ÿç¯å¢ƒï¼Œæ‰©å±•Agentçš„è®­ç»ƒåœºæ™¯ï¼Œæå‡å…¶å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAgentScaleråœ¨å¤šä¸ªAgentåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹çš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†åœ¨å®é™…åº”ç”¨ä¸­éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œéœ€è¦é«˜çº§çš„Agentæ™ºèƒ½ã€‚å¤šæ ·åŒ–çš„çœŸå®ä¸–ç•ŒAPIéœ€è¦ç²¾ç¡®ã€é²æ£’çš„å‡½æ•°è°ƒç”¨æ™ºèƒ½ï¼Œè¿™éœ€è¦Agenté€šè¿‡åœ¨ä¸åŒç¯å¢ƒä¸­äº¤äº’æ¥å‘å±•è¿™äº›èƒ½åŠ›ã€‚å‡½æ•°è°ƒç”¨èƒ½åŠ›çš„å¹¿åº¦ä¸Agentè®­ç»ƒç¯å¢ƒçš„å¤šæ ·æ€§å¯†åˆ‡ç›¸å…³ã€‚æœ¬æ–‡é€šè¿‡æ‰©å±•ç¯å¢ƒæ¥æå‡é€šç”¨Agentæ™ºèƒ½ã€‚è¿™å¸¦æ¥äº†ä¸¤ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼š(i) å¦‚ä½•ä»¥ä¸€ç§æœ‰åŸåˆ™çš„æ–¹å¼æ‰©å±•ç¯å¢ƒï¼Œä»¥åŠ (ii) å¦‚ä½•æœ‰æ•ˆåœ°ä»ä¸è¿™äº›ç¯å¢ƒäº¤äº’ä¸­è·å¾—çš„ç»éªŒä¸­è®­ç»ƒAgentèƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è‡ªåŠ¨æ„å»ºå®Œå…¨æ¨¡æ‹Ÿçš„å¼‚æ„ç¯å¢ƒï¼Œç³»ç»Ÿåœ°æ‰©å±•äº†å‡½æ•°è°ƒç”¨åœºæ™¯çš„ç©ºé—´ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é‡‡ç”¨äº†ä¸€ç§ä¸¤é˜¶æ®µçš„Agentå¾®è°ƒç­–ç•¥ï¼šé¦–å…ˆèµ‹äºˆAgentåŸºæœ¬çš„Agentèƒ½åŠ›ï¼Œç„¶åé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸Šä¸‹æ–‡è¿›è¡Œä¸“é—¨åŒ–ã€‚åœ¨AgentåŸºå‡†æµ‹è¯•tau-benchã€tau2-Benchå’ŒACEBenchä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬è®­ç»ƒçš„æ¨¡å‹AgentScaleræ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰Agentåœ¨é¢å¯¹çœŸå®ä¸–ç•Œä¸­å¤æ‚ä¸”å¤šæ ·åŒ–çš„APIæ—¶ï¼Œå‡½æ•°è°ƒç”¨èƒ½åŠ›ä¸è¶³ï¼Œæ³›åŒ–æ€§è¾ƒå·®ã€‚ä¸»è¦ç—›ç‚¹åœ¨äºç¼ºä¹è¶³å¤Ÿå¤šæ ·åŒ–çš„è®­ç»ƒç¯å¢ƒï¼Œå¯¼è‡´Agentæ— æ³•å……åˆ†å­¦ä¹ å’Œé€‚åº”å„ç§å‡½æ•°è°ƒç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ‰©å±•Agentçš„è®­ç»ƒç¯å¢ƒæ¥æå‡å…¶å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œè®¾è®¡ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ„å»ºå¼‚æ„çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œä»è€Œç³»ç»Ÿæ€§åœ°å¢åŠ å‡½æ•°è°ƒç”¨åœºæ™¯çš„å¤šæ ·æ€§ã€‚é€šè¿‡åœ¨è¿™äº›å¤šæ ·åŒ–çš„ç¯å¢ƒä¸­è¿›è¡Œè®­ç»ƒï¼ŒAgentå¯ä»¥å­¦ä¹ åˆ°æ›´é²æ£’å’Œæ³›åŒ–çš„å‡½æ•°è°ƒç”¨ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAgentScaleræ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) **ç¯å¢ƒç”Ÿæˆæ¨¡å—**ï¼šè´Ÿè´£è‡ªåŠ¨æ„å»ºå¼‚æ„çš„æ¨¡æ‹Ÿç¯å¢ƒï¼Œæ¶µç›–å„ç§å‡½æ•°è°ƒç”¨åœºæ™¯ã€‚2) **Agentè®­ç»ƒæ¨¡å—**ï¼šé‡‡ç”¨ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ï¼Œé¦–å…ˆèµ‹äºˆAgentåŸºæœ¬çš„Agentèƒ½åŠ›ï¼Œç„¶åé’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸Šä¸‹æ–‡è¿›è¡Œä¸“é—¨åŒ–è®­ç»ƒã€‚3) **è¯„ä¼°æ¨¡å—**ï¼šä½¿ç”¨å¤šä¸ªAgentåŸºå‡†æµ‹è¯•ï¼ˆtau-benchã€tau2-Benchå’ŒACEBenchï¼‰æ¥è¯„ä¼°Agentçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆé€šè¿‡ç¯å¢ƒç”Ÿæˆæ¨¡å—æ„å»ºå¤šæ ·åŒ–çš„è®­ç»ƒç¯å¢ƒï¼Œç„¶ååˆ©ç”¨Agentè®­ç»ƒæ¨¡å—åœ¨è¿™äº›ç¯å¢ƒä¸­è®­ç»ƒAgentï¼Œæœ€åé€šè¿‡è¯„ä¼°æ¨¡å—è¯„ä¼°Agentçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè‡ªåŠ¨æ„å»ºå¼‚æ„æ¨¡æ‹Ÿç¯å¢ƒçš„æ–¹æ³•ã€‚ä¸ä»¥å¾€æ‰‹åŠ¨è®¾è®¡ç¯å¢ƒçš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ›´é«˜æ•ˆã€æ›´ç³»ç»Ÿåœ°æ‰©å±•Agentçš„è®­ç»ƒç¯å¢ƒï¼Œä»è€Œæå‡Agentçš„æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ä¹Ÿæœ‰åŠ©äºAgentæ›´å¥½åœ°å­¦ä¹ å’Œé€‚åº”ä¸åŒé¢†åŸŸçš„å‡½æ•°è°ƒç”¨åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šç¯å¢ƒç”Ÿæˆæ¨¡å—çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å…¶æ ¸å¿ƒç›®æ ‡æ˜¯ç”Ÿæˆå¤šæ ·åŒ–çš„å‡½æ•°è°ƒç”¨åœºæ™¯ã€‚ä¸¤é˜¶æ®µå¾®è°ƒç­–ç•¥ä¸­ï¼Œç¬¬ä¸€é˜¶æ®µå¯èƒ½é‡‡ç”¨é€šç”¨çš„Agentè®­ç»ƒç›®æ ‡ï¼Œå¦‚æ¨¡ä»¿å­¦ä¹ æˆ–å¼ºåŒ–å­¦ä¹ ï¼Œä»¥èµ‹äºˆAgentåŸºæœ¬çš„Agentèƒ½åŠ›ã€‚ç¬¬äºŒé˜¶æ®µåˆ™é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„ä¸Šä¸‹æ–‡ï¼Œé‡‡ç”¨é¢†åŸŸç›¸å…³çš„è®­ç»ƒæ•°æ®å’Œç›®æ ‡ï¼Œä»¥æå‡Agentåœ¨è¯¥é¢†åŸŸçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AgentScaleråœ¨tau-benchã€tau2-Benchå’ŒACEBenchç­‰AgentåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¡¨æ˜å…¶èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºæ¨¡å‹çš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ï¼Œéœ€è¦åœ¨è®ºæ–‡æ­£æ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–è¿ç»´ã€æ™ºèƒ½å®¢æœç­‰é¢†åŸŸã€‚é€šè¿‡æå‡Agentçš„å‡½æ•°è°ƒç”¨èƒ½åŠ›ï¼Œå¯ä»¥å®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„ä»»åŠ¡è‡ªåŠ¨åŒ–ï¼Œé™ä½äººå·¥æˆæœ¬ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„çœŸå®ä¸–ç•Œåœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Advanced agentic intelligence is a prerequisite for deploying Large Language Models in practical, real-world applications. Diverse real-world APIs demand precise, robust function-calling intelligence, which needs agents to develop these capabilities through interaction in varied environments. The breadth of function-calling competence is closely tied to the diversity of environments in which agents are trained. In this work, we scale up environments as a step towards advancing general agentic intelligence. This gives rise to two central challenges: (i) how to scale environments in a principled manner, and (ii) how to effectively train agentic capabilities from experiences derived through interactions with these environments. To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated, systematically broadening the space of function-calling scenarios. We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts. Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.

