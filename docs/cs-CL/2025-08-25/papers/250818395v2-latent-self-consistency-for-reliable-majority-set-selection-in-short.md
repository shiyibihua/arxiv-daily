---
layout: default
title: Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning
---

# Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18395" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18395v2</a>
  <a href="https://arxiv.org/pdf/2508.18395.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18395v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18395v2', 'Latent Self-Consistency for Reliable Majority-Set Selection in Short- and Long-Answer Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jungsuk Oh, Jay-Yoon Lee

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25 (æ›´æ–°: 2025-12-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ½œåœ¨è‡ªä¸€è‡´æ€§æ–¹æ³•ä»¥è§£å†³é•¿çŸ­ç­”æ¡ˆæ¨ç†ä¸­çš„ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªä¸€è‡´æ€§` `è¯­è¨€æ¨¡å‹` `çŸ­ç­”æ¡ˆæ¨ç†` `é•¿ç­”æ¡ˆæ¨ç†` `è¯­ä¹‰ä¸€è‡´æ€§` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æˆ–é•¿å½¢å¼é—®é¢˜æ—¶ï¼Œè¾“å‡ºä¸€è‡´æ€§è¾ƒå·®ï¼Œå°¤å…¶æ˜¯çŸ­å½¢å¼é—®ç­”ä¸­çš„å‡†ç¡®æ€§å—åˆ°å½±å“ã€‚
2. è®ºæ–‡æå‡ºçš„æ½œåœ¨è‡ªä¸€è‡´æ€§ï¼ˆLSCï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¯å­¦ä¹ çš„æ ‡è®°åµŒå…¥é€‰æ‹©è¯­ä¹‰ä¸€è‡´çš„å“åº”ï¼Œæå‡äº†è¾“å‡ºçš„ä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLSCåœ¨çŸ­å½¢å¼å’Œé•¿å½¢å¼æ¨ç†åŸºå‡†ä¸Šå‡è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œä¸”è®¡ç®—å¼€é”€æå°ï¼Œè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼Œæ¦‚ç‡è§£ç å¸¸å¸¸å¯¼è‡´ä¸ä¸€è‡´çš„è¾“å‡ºï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æˆ–é•¿å½¢å¼é—®é¢˜ä¸Šã€‚è‡ªä¸€è‡´æ€§ï¼ˆSCï¼‰é€šè¿‡å¯¹ç²¾ç¡®å­—ç¬¦ä¸²è¿›è¡Œå¤šæ•°æŠ•ç¥¨æ¥ç¼“è§£çŸ­å½¢å¼é—®ç­”ä¸­çš„è¿™ä¸€é—®é¢˜ï¼Œè€Œé€šç”¨è‡ªä¸€è‡´æ€§ï¼ˆUSCï¼‰å’ŒåŠ æƒå•å…ƒä¸€è‡´æ€§è¯„åˆ†ï¼ˆWUCSï¼‰è™½ç„¶æ‰©å±•åˆ°é•¿å½¢å¼å“åº”ï¼Œä½†åœ¨çŸ­å½¢å¼åŸºå‡†ä¸Šå‡†ç¡®æ€§ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†æ½œåœ¨è‡ªä¸€è‡´æ€§ï¼ˆLSCï¼‰ï¼Œé€šè¿‡å¯å­¦ä¹ çš„æ ‡è®°åµŒå…¥é€‰æ‹©æœ€è¯­ä¹‰ä¸€è‡´çš„å“åº”ã€‚LSCåœ¨æ ‡å‡†è§£ç åŸºç¡€ä¸Šä»…å¼•å…¥æœ€å¤š0.9%çš„è¿è¡Œæ—¶å¼€é”€ï¼Œä¸”æ— éœ€æ”¹å˜æ¨¡å‹æ¶æ„ã€‚åœ¨6ä¸ªçŸ­å½¢å¼å’Œ5ä¸ªé•¿å½¢å¼æ¨ç†åŸºå‡†ä¸Šï¼ŒLSCåœ¨å¹³å‡æ€§èƒ½ä¸Šè¶…è¶Šäº†SCã€USCå’ŒWUCSï¼ŒåŒæ—¶åœ¨åŸå§‹æ¨ç†ä¸Šå¢åŠ çš„è®¡ç®—å¼€é”€å¾®ä¹å…¶å¾®ã€‚è¿™äº›ç»“æœä½¿LSCæˆä¸ºä¸€ç§å¯é çš„ä¸€è‡´æ€§é€‰æ‹©æ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å„ç§ç­”æ¡ˆæ ¼å¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚é—®é¢˜ä¸Šçš„è¾“å‡ºä¸ä¸€è‡´æ€§ï¼Œç°æœ‰çš„è‡ªä¸€è‡´æ€§æ–¹æ³•åœ¨çŸ­å½¢å¼å’Œé•¿å½¢å¼é—®ç­”ä¸­å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ½œåœ¨è‡ªä¸€è‡´æ€§ï¼ˆLSCï¼‰é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„æ ‡è®°åµŒå…¥ï¼Œé€‰æ‹©æœ€è¯­ä¹‰ä¸€è‡´çš„å“åº”ï¼Œä»è€Œæé«˜è¾“å‡ºçš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLSCçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹è¾“å…¥çš„æ ‡è®°è¿›è¡ŒåµŒå…¥å¤„ç†ï¼Œéšåé€šè¿‡è½»é‡çº§çš„å‰å‘å¤„ç†æ¥é€‰æ‹©æœ€ä¼˜å“åº”ï¼Œæ•´ä¸ªè¿‡ç¨‹ä¸éœ€è¦æ”¹å˜åŸºç¡€æ¨¡å‹çš„æ¶æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šLSCçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è½»é‡çº§çš„å¤„ç†æ–¹å¼å’Œå¯å­¦ä¹ çš„åµŒå…¥é€‰æ‹©æœºåˆ¶ï¼Œä½¿å…¶åœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œè®¡ç®—å¼€é”€æå°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLSCé‡‡ç”¨äº†å¯å­¦ä¹ çš„æ ‡è®°åµŒå…¥ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†è¯­ä¹‰ä¸€è‡´æ€§åº¦é‡ï¼Œç¡®ä¿é€‰æ‹©çš„å“åº”åœ¨è¯­ä¹‰ä¸Šæœ€ä¸ºä¸€è‡´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨6ä¸ªçŸ­å½¢å¼å’Œ5ä¸ªé•¿å½¢å¼æ¨ç†åŸºå‡†ä¸Šï¼ŒLSCæ–¹æ³•åœ¨å¹³å‡æ€§èƒ½ä¸Šè¶…è¶Šäº†è‡ªä¸€è‡´æ€§ï¼ˆSCï¼‰ã€é€šç”¨è‡ªä¸€è‡´æ€§ï¼ˆUSCï¼‰å’ŒåŠ æƒå•å…ƒä¸€è‡´æ€§è¯„åˆ†ï¼ˆWUCSï¼‰ï¼Œå¹¶ä¸”åœ¨è®¡ç®—å¼€é”€ä¸Šä»…å¢åŠ äº†æœ€å¤š0.9%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€å®¢æœå’Œä¿¡æ¯æ£€ç´¢ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡åŸºäºè¯­è¨€æ¨¡å‹çš„é—®ç­”ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼ŒLSCæ–¹æ³•å¯èƒ½åœ¨å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½é—®ç­”ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Probabilistic decoding in Large Language Models (LLMs) often yields inconsistent outputs, particularly on complex or long-form questions. Self-Consistency (SC) mitigates this for short-form QA by majority voting over exact strings, whereas Universal Self-Consistency (USC) and Weighted Unigram Consistency Score (WUCS) extend to long-form responses but lose accuracy on short-form benchmarks.
>   We introduce \textbf{Latent Self-Consistency (LSC)}, which selects the most semantically consistent response using learnable token embeddings. LSC's lightweight forward processing of summary tokens only introduces negligible runtime overhead (at most $0.9\%$) on top of standard decoding of the base LLM, and requires no changes to the model architecture.
>   Across 6 short-form and 5 long-form reasoning benchmarks (e.g., MATH, MMLU, TruthfulQA), LSC surpasses SC, USC, and WUCS on both short-form and long-form on average performance, while adding negligible computational overhead on vanilla inference. These results position LSC as a reliable consistency-selection method that works effectively across various answer formats. Additionally, LSC provides well-calibrated confidence estimates, maintaining low expected calibration error across both answer formats.

