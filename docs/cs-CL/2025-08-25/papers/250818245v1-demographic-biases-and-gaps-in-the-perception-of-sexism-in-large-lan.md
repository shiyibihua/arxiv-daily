---
layout: default
title: Demographic Biases and Gaps in the Perception of Sexism in Large Language Models
---

# Demographic Biases and Gaps in the Perception of Sexism in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18245" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18245v1</a>
  <a href="https://arxiv.org/pdf/2508.18245.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18245v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18245v1', 'Demographic Biases and Gaps in the Perception of Sexism in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Judith Tavarez-RodrÃ­guez, Fernando SÃ¡nchez-Vega, A. Pastor LÃ³pez-Monroy

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: This work was presented as a poster at the Latin American Meeting in Artificial Intelligence KHIPU 2025, Santiago, Chile, March 10th - 14th 2025, https://khipu.ai/khipu2025/poster-sessions-2025/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ€§åˆ«æ­§è§†æ„ŸçŸ¥çš„ç¾¤ä½“åè§ä¸å·®è·**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ€§åˆ«æ­§è§†æ£€æµ‹` `äººå£ç»Ÿè®¡åè§` `ç¤¾äº¤åª’ä½“åˆ†æ` `æ¨¡å‹æ ¡å‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«æ­§è§†æ£€æµ‹ä¸­å­˜åœ¨æ˜¾è‘—åè§ï¼Œå°¤å…¶å¯¹å°‘æ•°ç¾¤ä½“çš„æ„ŸçŸ¥æœªèƒ½å‡†ç¡®åæ˜ ã€‚
2. æœ¬æ–‡é€šè¿‡EXIST 2024æ¨æ–‡æ•°æ®é›†ï¼Œè¯„ä¼°ä¸åŒLLMsåœ¨æ€§åˆ«æ­§è§†æ£€æµ‹ä¸­çš„è¡¨ç°ï¼Œå¹¶åˆ†æäººå£ç»Ÿè®¡ç‰¹å¾çš„å½±å“ã€‚
3. ç ”ç©¶å‘ç°ï¼Œè™½ç„¶LLMså¯ä»¥æ£€æµ‹æ€§åˆ«æ­§è§†ï¼Œä½†æœªèƒ½å……åˆ†æ•æ‰ä¸åŒç¾¤ä½“çš„å¤šæ ·åŒ–è§‚ç‚¹ï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹æ ¡å‡†çš„å¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨æ£€æµ‹æ€§åˆ«æ­§è§†æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†ç°æœ‰æ¨¡å‹å­˜åœ¨åè§ï¼Œæœªèƒ½å‡†ç¡®åæ˜ å°‘æ•°ç¾¤ä½“çš„ç°å®ã€‚å°½ç®¡å·²æœ‰å¤šé¡¹åŠªåŠ›æ”¹å–„æ€§åˆ«æ­§è§†å†…å®¹çš„æ£€æµ‹ï¼Œä½†ç”±äºä»»åŠ¡çš„ä¸»è§‚æ€§åŠæ¨¡å‹ä¸­çš„åè§ï¼Œè¿™ä¸€æŒ‘æˆ˜ä¾ç„¶æ˜¾è‘—ã€‚æœ¬æ–‡åˆ©ç”¨EXIST 2024æ¨æ–‡æ•°æ®é›†ï¼Œè¯„ä¼°ä¸åŒLLMsåœ¨ç¤¾äº¤åª’ä½“æ–‡æœ¬ä¸­æ£€æµ‹æ€§åˆ«æ­§è§†çš„èƒ½åŠ›ï¼Œå¹¶åˆ†ææ¨¡å‹ä¸­çš„äººå£ç»Ÿè®¡åè§ï¼Œè¯†åˆ«å½±å“æ£€æµ‹æ•ˆæœçš„å…³é”®äººå£ç‰¹å¾ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨æ•´ä½“äººç¾¤æ„è§çš„åŸºç¡€ä¸Šèƒ½å¤Ÿæ£€æµ‹æ€§åˆ«æ­§è§†ï¼Œä½†æœªèƒ½å‡†ç¡®å†ç°ä¸åŒç¾¤ä½“çš„å¤šæ ·åŒ–æ„ŸçŸ¥ï¼Œå¼ºè°ƒäº†éœ€è¦æ›´å¥½æ ¡å‡†æ¨¡å‹ä»¥è€ƒè™‘ä¸åŒäººç¾¤çš„è§‚ç‚¹å¤šæ ·æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«æ­§è§†æ£€æµ‹ä¸­çš„åè§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å‡†ç¡®åæ˜ ä¸åŒäººå£ç¾¤ä½“çš„æ„ŸçŸ¥å·®å¼‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†æä¸åŒäººå£ç‰¹å¾ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ï¼‰å¯¹æ€§åˆ«æ­§è§†æ£€æµ‹çš„å½±å“ï¼Œæå‡ºæ”¹è¿›æ¨¡å‹çš„ç­–ç•¥ï¼Œä»¥æ›´å¥½åœ°æ•æ‰å¤šæ ·åŒ–çš„è§‚ç‚¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä½¿ç”¨EXIST 2024æ¨æ–‡æ•°æ®é›†ï¼ŒåŒ…å«å…­ä¸ªä¸åŒçš„ç”¨æˆ·ç”»åƒå¯¹æ¯æ¡æ¨æ–‡è¿›è¡Œæ ‡æ³¨ï¼Œè¯„ä¼°LLMsçš„æ£€æµ‹èƒ½åŠ›ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒã€åè§åˆ†æå’Œç»“æœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†LLMsåœ¨æ€§åˆ«æ­§è§†æ£€æµ‹ä¸­çš„äººå£ç»Ÿè®¡åè§ï¼Œå¼ºè°ƒäº†æ¨¡å‹åœ¨ä¸åŒç¾¤ä½“æ„ŸçŸ¥ä¸Šçš„ä¸è¶³ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…¨é¢çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å¤šç§LLMsï¼Œå¹¶é€šè¿‡ç»Ÿè®¡åˆ†æè¯†åˆ«å½±å“æ£€æµ‹æ•ˆæœçš„å…³é”®äººå£ç‰¹å¾ï¼Œè®¾è®¡äº†ç›¸åº”çš„å®éªŒä»¥éªŒè¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒåŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡LLMsåœ¨æ•´ä½“äººç¾¤æ„è§çš„åŸºç¡€ä¸Šèƒ½å¤Ÿæ£€æµ‹æ€§åˆ«æ­§è§†ï¼Œä½†åœ¨ä¸åŒäººå£ç¾¤ä½“çš„æ„ŸçŸ¥ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œæœªèƒ½å‡†ç¡®å†ç°å¤šæ ·åŒ–çš„è§‚ç‚¹ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†æ¨¡å‹æ ¡å‡†çš„é‡è¦æ€§ï¼Œæœªæ¥éœ€è¦é’ˆå¯¹ä¸åŒç¾¤ä½“è¿›è¡Œæ›´æ·±å…¥çš„ç ”ç©¶å’Œä¼˜åŒ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç›‘æµ‹ã€åœ¨çº¿å¹³å°çš„å†…å®¹å®¡æ ¸ä»¥åŠæ€§åˆ«æ­§è§†ç›¸å…³çš„æ”¿ç­–åˆ¶å®šã€‚é€šè¿‡æ”¹è¿›æ¨¡å‹çš„åè§æ£€æµ‹èƒ½åŠ›ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œåº”å¯¹æ€§åˆ«æ­§è§†ç°è±¡ï¼Œä¿ƒè¿›ç¤¾ä¼šå…¬å¹³ä¸åŒ…å®¹æ€§ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœæœ‰æœ›æ¨åŠ¨æ›´ä¸ºå…¬æ­£çš„AIåº”ç”¨å’ŒæŠ€æœ¯å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The use of Large Language Models (LLMs) has proven to be a tool that could help in the automatic detection of sexism. Previous studies have shown that these models contain biases that do not accurately reflect reality, especially for minority groups. Despite various efforts to improve the detection of sexist content, this task remains a significant challenge due to its subjective nature and the biases present in automated models. We explore the capabilities of different LLMs to detect sexism in social media text using the EXIST 2024 tweet dataset. It includes annotations from six distinct profiles for each tweet, allowing us to evaluate to what extent LLMs can mimic these groups' perceptions in sexism detection. Additionally, we analyze the demographic biases present in the models and conduct a statistical analysis to identify which demographic characteristics (age, gender) contribute most effectively to this task. Our results show that, while LLMs can to some extent detect sexism when considering the overall opinion of populations, they do not accurately replicate the diversity of perceptions among different demographic groups. This highlights the need for better-calibrated models that account for the diversity of perspectives across different populations.

