---
layout: default
title: Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails
---

# Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18384" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18384v1</a>
  <a href="https://arxiv.org/pdf/2508.18384.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18384v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18384v1', 'Backprompting: Leveraging Synthetic Production Data for Health Advice Guardrails')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kellen Tan Cheng, Anna Lisa Gentile, Chad DeLuca, Guang-Jie Ren

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåå‘æç¤ºæŠ€æœ¯ä»¥ç”Ÿæˆå¥åº·å»ºè®®çš„æ ‡æ³¨æ•°æ®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åå‘æç¤º` `å¥åº·å»ºè®®` `æ•°æ®æ ‡æ³¨` `æŠ¤æ æŠ€æœ¯` `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæœºåä½œ` `åˆæˆæ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æŠ¤æ æŠ€æœ¯åœ¨å¼€å‘å’Œç»´æŠ¤å¼ºå¤§çš„æ£€æµ‹å™¨æ—¶é¢ä¸´è·å–é«˜è´¨é‡æ ‡æ³¨æ•°æ®çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºåå‘æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆç”Ÿäº§ç¯å¢ƒç›¸ä¼¼çš„æ ‡æ³¨æ•°æ®æ¥æ”¯æŒå¥åº·å»ºè®®æŠ¤æ çš„å¼€å‘ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ£€æµ‹å™¨åœ¨å¥åº·å»ºè®®è¯†åˆ«ä»»åŠ¡ä¸­è¶…è¶Šäº†GPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°3.73%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¼ä¸šç¯å¢ƒä¸­çš„å¹¿æ³›åº”ç”¨å¸¦æ¥äº†æ˜¾è‘—çš„é£é™©ã€‚ä¸ºäº†é™ä½è¿™äº›é£é™©ï¼ŒæŠ¤æ æŠ€æœ¯é€šè¿‡å„ç§æ£€æµ‹å™¨è¿‡æ»¤LLMsçš„è¾“å…¥/è¾“å‡ºæ–‡æœ¬ã€‚ç„¶è€Œï¼Œå¼€å‘å’Œç»´æŠ¤å¼ºå¤§çš„æ£€æµ‹å™¨é¢ä¸´è®¸å¤šæŒ‘æˆ˜ï¼Œå…¶ä¸­ä¹‹ä¸€æ˜¯éš¾ä»¥è·å–é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•ç›´è§‚çš„è§£å†³æ–¹æ¡ˆâ€”â€”åå‘æç¤ºï¼ˆbackpromptingï¼‰ï¼Œç”¨äºç”Ÿæˆç±»ä¼¼ç”Ÿäº§ç¯å¢ƒçš„æ ‡æ³¨æ•°æ®ï¼Œä»¥æ”¯æŒå¥åº·å»ºè®®æŠ¤æ çš„å¼€å‘ã€‚æˆ‘ä»¬å°†åå‘æç¤ºæ–¹æ³•ä¸ç¨€ç–çš„äººæœºåä½œèšç±»æŠ€æœ¯ç»“åˆï¼Œæ ‡æ³¨ç”Ÿæˆçš„æ•°æ®ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªä¸åŸå§‹æ•°æ®é›†å¤§è‡´ç›¸ä¼¼çš„å¹³è¡Œè¯­æ–™åº“ï¼Œå¹¶å°†åˆæˆç¤ºä¾‹æ³¨å…¥ç°æœ‰æ•°æ®é›†ä¸­ï¼Œä»¥ç”Ÿæˆå¼ºå¤§çš„è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬åœ¨è¯†åˆ«LLMè¾“å‡ºä¸­çš„å¥åº·å»ºè®®è¿™ä¸€å¤æ‚æŠ¤æ ä¸Šæµ‹è¯•äº†è¯¥æŠ€æœ¯ï¼Œå¹¶å±•ç¤ºäº†ç›¸è¾ƒäºå…¶ä»–è§£å†³æ–¹æ¡ˆçš„æ”¹è¿›ã€‚å°½ç®¡å‚æ•°é‡å°‘è¾¾400å€ï¼Œæˆ‘ä»¬çš„æ£€æµ‹å™¨ä»èƒ½è¶…è¶ŠGPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°3.73%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤§å‹è¯­è¨€æ¨¡å‹è¾“å‡ºä¸­è¯†åˆ«å¥åº·å»ºè®®çš„éš¾é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è·å–é«˜è´¨é‡æ ‡æ³¨æ•°æ®æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†æ£€æµ‹å™¨çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåå‘æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆä¸çœŸå®ç”Ÿäº§ç¯å¢ƒç›¸ä¼¼çš„æ ‡æ³¨æ•°æ®ï¼Œæ¥å¢å¼ºå¥åº·å»ºè®®æŠ¤æ çš„å¼€å‘å’Œè®­ç»ƒã€‚è¯¥æ–¹æ³•ç®€å•ç›´è§‚ï¼Œæ˜“äºå®ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬åå‘æç¤ºç”Ÿæˆåˆæˆæ•°æ®ã€ç¨€ç–äººæœºåä½œèšç±»æ ‡æ³¨ç”Ÿæˆçš„æ•°æ®ï¼Œä»¥åŠå°†åˆæˆæ•°æ®ä¸ç°æœ‰æ•°æ®é›†ç»“åˆä»¥å¢å¼ºè®­ç»ƒæ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šåå‘æç¤ºæŠ€æœ¯æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼Œå®ƒé€šè¿‡ç”Ÿæˆç”Ÿäº§ç¯å¢ƒç›¸ä¼¼çš„æ ‡æ³¨æ•°æ®ï¼Œè§£å†³äº†è·å–çœŸå®æ ‡æ³¨æ•°æ®çš„å›°éš¾ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯å®ç°ä¸­ï¼Œé‡‡ç”¨äº†ç¨€ç–äººæœºåä½œèšç±»æŠ€æœ¯æ¥æ ‡æ³¨ç”Ÿæˆçš„æ•°æ®ï¼Œç¡®ä¿æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒä½çš„å‚æ•°é‡ï¼Œä½¿å¾—æ£€æµ‹å™¨åœ¨æ€§èƒ½ä¸Šå…·å¤‡ç«äº‰åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ£€æµ‹å™¨åœ¨å¥åº·å»ºè®®è¯†åˆ«ä»»åŠ¡ä¸­è¶…è¶Šäº†GPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°3.73%ã€‚å°½ç®¡å‚æ•°é‡å‡å°‘äº†400å€ï¼Œæ£€æµ‹å™¨ä»èƒ½ä¿æŒè¾ƒé«˜çš„æ€§èƒ½ï¼Œè¯æ˜äº†åå‘æç¤ºæŠ€æœ¯çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å¥åº·ã€åœ¨çº¿å’¨è¯¢å’Œæ™ºèƒ½å®¢æœç­‰åœºæ™¯ã€‚é€šè¿‡ç”Ÿæˆé«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¥åº·å»ºè®®é¢†åŸŸçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œé™ä½è¯¯å¯¼æ€§ä¿¡æ¯çš„é£é™©ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The pervasiveness of large language models (LLMs) in enterprise settings has also brought forth a significant amount of risks associated with their usage. Guardrails technologies aim to mitigate this risk by filtering LLMs' input/output text through various detectors. However, developing and maintaining robust detectors faces many challenges, one of which is the difficulty in acquiring production-quality labeled data on real LLM outputs prior to deployment. In this work, we propose backprompting, a simple yet intuitive solution to generate production-like labeled data for health advice guardrails development. Furthermore, we pair our backprompting method with a sparse human-in-the-loop clustering technique to label the generated data. Our aim is to construct a parallel corpus roughly representative of the original dataset yet resembling real LLM output. We then infuse existing datasets with our synthetic examples to produce robust training data for our detector. We test our technique in one of the most difficult and nuanced guardrails: the identification of health advice in LLM output, and demonstrate improvement versus other solutions. Our detector is able to outperform GPT-4o by up to 3.73%, despite having 400x less parameters.

