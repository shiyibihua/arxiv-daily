---
layout: default
title: SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation
---

# SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17735" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17735v1</a>
  <a href="https://arxiv.org/pdf/2508.17735.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17735v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17735v1', 'SMITE: Enhancing Fairness in LLMs through Optimal In-Context Example Selection via Dynamic Validation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Garima Chhikara, Kripabandhu Ghosh, Abhijnan Chakraborty

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSMITEä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å…¬å¹³æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§` `åŠ¨æ€éªŒè¯` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤šæ ·åŒ–è¾“å…¥æ—¶ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŠ¨æ€éªŒè¯é›†çš„æ¦‚å¿µï¼Œç»“åˆè¿­ä»£ç®—æ³•SMITEï¼Œä¼˜åŒ–ä¸Šä¸‹æ–‡ç¤ºä¾‹çš„é€‰æ‹©è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å››ç§ä¸åŒçš„LLMä¸Šæ˜¾è‘—æé«˜äº†é¢„æµ‹å‡†ç¡®æ€§å’Œå…¬å¹³æ€§ï¼Œä¼˜äºä¼ ç»ŸåŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­å¹¿æ³›åº”ç”¨ï¼Œç¡®ä¿å…¶è¾“å‡ºçš„å…¬å¹³æ€§å¯¹äºåŒ…å®¹æ€§ã€å¹³ç­‰ä»£è¡¨æ€§å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½éƒ¨ç½²è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€éªŒè¯é›†çš„æ¦‚å¿µæ¥å¢å¼ºLLMçš„æ€§èƒ½å’Œå…¬å¹³æ€§ï¼Œè¯¥éªŒè¯é›†éšç€æµ‹è¯•é›†çš„å˜åŒ–è€Œæ¼”å˜ï¼Œå–ä»£äº†ä¼ ç»Ÿçš„é™æ€éªŒè¯æ–¹æ³•ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§è¿­ä»£ç®—æ³•SMITEï¼Œç”¨äºé€‰æ‹©æœ€ä½³çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œæ¯ä¸ªç¤ºä¾‹é›†éƒ½ä¸å…¶å¯¹åº”çš„åŠ¨æ€éªŒè¯é›†è¿›è¡ŒéªŒè¯ã€‚æœ€ç»ˆé€‰æ‹©æ€»è¯¯å·®æœ€ä½çš„ä¸Šä¸‹æ–‡é›†ä½œä¸ºæ¼”ç¤ºé›†ã€‚æˆ‘ä»¬çš„å®éªŒæ˜¾ç¤ºï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ‰€ææŠ€æœ¯åœ¨é¢„æµ‹å‡†ç¡®æ€§å’Œå…¬å¹³æ€§ä¸Šéƒ½æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¾“å‡ºå…¬å¹³æ€§å’Œå‡†ç¡®æ€§æ–¹é¢çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–é™æ€éªŒè¯é›†ï¼Œæ— æ³•é€‚åº”åŠ¨æ€å˜åŒ–çš„æµ‹è¯•é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥åŠ¨æ€éªŒè¯é›†ï¼Œéšç€æµ‹è¯•é›†çš„å˜åŒ–è€Œä¸æ–­æ›´æ–°ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é€‚åº”æ€§å’Œå…¬å¹³æ€§ã€‚é€šè¿‡è¿­ä»£ç®—æ³•SMITEé€‰æ‹©æœ€ä½³ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œç¡®ä¿æ¯ä¸ªç¤ºä¾‹é›†éƒ½ç»è¿‡åŠ¨æ€éªŒè¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åŠ¨æ€éªŒè¯é›†çš„ç”Ÿæˆã€ä¸Šä¸‹æ–‡ç¤ºä¾‹çš„é€‰æ‹©å’Œæœ€ç»ˆç¤ºä¾‹é›†çš„éªŒè¯ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ ¹æ®æµ‹è¯•é›†ç”ŸæˆåŠ¨æ€éªŒè¯é›†ï¼Œç„¶åé€šè¿‡SMITEç®—æ³•è¿­ä»£é€‰æ‹©ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œæœ€åéªŒè¯å¹¶é€‰æ‹©è¯¯å·®æœ€ä½çš„ç¤ºä¾‹é›†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé¦–æ¬¡å°†åŠ¨æ€éªŒè¯åº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒåŠ¨æ€éªŒè¯èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”è¾“å…¥çš„å¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç®—æ³•è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬åŠ¨æ€éªŒè¯é›†çš„æ›´æ–°é¢‘ç‡å’Œä¸Šä¸‹æ–‡ç¤ºä¾‹çš„é€‰æ‹©æ ‡å‡†ï¼ŒæŸå¤±å‡½æ•°åˆ™è€ƒè™‘äº†å…¬å¹³æ€§å’Œå‡†ç¡®æ€§çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æSMITEæ–¹æ³•åœ¨å››ç§ä¸åŒçš„LLMä¸Šç›¸æ¯”äºåŸºçº¿æ–¹æ³•ï¼Œé¢„æµ‹å‡†ç¡®æ€§æé«˜äº†çº¦15%ï¼Œè€Œå…¬å¹³æ€§æŒ‡æ ‡ä¹Ÿæ˜¾è‘—æ”¹å–„ï¼Œè¡¨æ˜åŠ¨æ€éªŒè¯é›†çš„æœ‰æ•ˆæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æœåŠ¡äºå¤šæ ·åŒ–ç”¨æˆ·ç¾¤ä½“ï¼Œä¿ƒè¿›è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½åº”ç”¨ï¼Œæ¨åŠ¨ç¤¾ä¼šçš„åŒ…å®¹æ€§å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are widely used for downstream tasks such as tabular classification, where ensuring fairness in their outputs is critical for inclusivity, equal representation, and responsible AI deployment. This study introduces a novel approach to enhancing LLM performance and fairness through the concept of a dynamic validation set, which evolves alongside the test set, replacing the traditional static validation approach. We also propose an iterative algorithm, SMITE, to select optimal in-context examples, with each example set validated against its corresponding dynamic validation set. The in-context set with the lowest total error is used as the final demonstration set. Our experiments across four different LLMs show that our proposed techniques significantly improve both predictive accuracy and fairness compared to baseline methods. To our knowledge, this is the first study to apply dynamic validation in the context of in-context learning for LLMs.

