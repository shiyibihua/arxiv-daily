---
layout: default
title: Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages
---

# Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03529" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03529v1</a>
  <a href="https://arxiv.org/pdf/2509.03529.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03529v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03529v1', 'Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alejandro Ãlvarez Castro, JoaquÃ­n Ordieres-MerÃ©

**åˆ†ç±»**: cs.CL, cs.AI, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: Presented at NLMLT2025 (https://airccse.org/csit/V15N16.html), 15 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ¡†æ¶ä»¥å¢å¼ºè´¢æŠ¥ä¼šè®®çš„è·¨è¯„ä¼°èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€åˆ†æ` `å±‚æ¬¡è¯è¯­æ ‘` `æƒ…æ„Ÿä¿¡å·` `å¯¹æ¯”å­¦ä¹ ` `è´¢åŠ¡æ²Ÿé€š` `ç»“æ„åŒ–å…ƒæ•°æ®` `è¯­ä¹‰åµŒå…¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€é‡‘èæƒ…æ„Ÿåˆ†æç³»ç»Ÿå¤šä¾èµ–äºå¹³é¢æ¨¡å‹ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰è´¢æŠ¥ä¼šè®®çš„å¤æ‚è¯è¯­ç»“æ„ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå±‚æ¬¡è¯è¯­æ ‘çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œé€šè¿‡å¯¹èŠ‚ç‚¹çº§åˆ«çš„å¤šæ¨¡æ€å†…å®¹è¿›è¡Œç¼–ç ï¼Œç”Ÿæˆå…¨å±€åµŒå…¥ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„åµŒå…¥åœ¨æƒ…æ„ŸåŸºè°ƒå’Œä¸»é¢˜ä¸€è‡´æ€§ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„ç¨³å®šæ€§å’Œè¯­ä¹‰æ„ä¹‰ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è´¢æŠ¥ç”µè¯ä¼šè®®æ˜¯ç‹¬ç‰¹çš„åŠç»“æ„åŒ–è´¢åŠ¡æ²Ÿé€šæ¥æºï¼Œç»“åˆäº†ç®¡ç†è€…çš„è„šæœ¬è¯„è®ºå’Œåˆ†æå¸ˆçš„éè„šæœ¬å¯¹è¯ã€‚å°½ç®¡è¿‘æœŸåœ¨é‡‘èæƒ…æ„Ÿåˆ†æä¸­å·²æ•´åˆäº†å¤šæ¨¡æ€ä¿¡å·ï¼Œå¦‚æ–‡æœ¬å†…å®¹å’Œè¯­éŸ³è¯­è°ƒï¼Œä½†å¤§å¤šæ•°ç³»ç»Ÿä¾èµ–äºå¹³é¢æ–‡æ¡£çº§æˆ–å¥å­çº§æ¨¡å‹ï¼Œæœªèƒ½æ•æ‰è¿™äº›äº’åŠ¨çš„åˆ†å±‚è¯è¯­ç»“æ„ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œé€šè¿‡å°†è´¢æŠ¥ä¼šè®®ç¼–ç ä¸ºå±‚æ¬¡è¯è¯­æ ‘ï¼Œç”Ÿæˆè¯­ä¹‰ä¸°å¯Œä¸”ç»“æ„æ„è¯†å¼ºçš„åµŒå…¥ã€‚æ¯ä¸ªèŠ‚ç‚¹åŒ…å«å•ç‹¬çš„ç‹¬ç™½æˆ–é—®ç­”å¯¹ï¼Œå¹¶ç»“åˆæ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘çš„æƒ…æ„Ÿä¿¡å·ï¼Œä»¥åŠè¿è´¯æ€§è¯„åˆ†ã€ä¸»é¢˜æ ‡ç­¾å’Œå›ç­”è¦†ç›–è¯„ä¼°ç­‰ç»“æ„åŒ–å…ƒæ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç”Ÿæˆçš„åµŒå…¥å½¢æˆç¨³å®šä¸”å…·æœ‰è¯­ä¹‰æ„ä¹‰çš„è¡¨ç¤ºï¼Œåæ˜ æƒ…æ„ŸåŸºè°ƒã€ç»“æ„é€»è¾‘å’Œä¸»é¢˜ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è´¢æŠ¥ä¼šè®®åˆ†ææ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰å…¶åˆ†å±‚è¯è¯­ç»“æ„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºå¹³é¢æ¨¡å‹ï¼Œå¯¼è‡´ä¿¡æ¯ä¸¢å¤±å’Œè¯­ä¹‰ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡æ„å»ºå±‚æ¬¡è¯è¯­æ ‘æ¥ç¼–ç è´¢æŠ¥ä¼šè®®ï¼Œåˆ©ç”¨å¤šæ¨¡æ€ä¿¡å·ï¼ˆæ–‡æœ¬ã€éŸ³é¢‘ã€è§†é¢‘ï¼‰å’Œç»“æ„åŒ–å…ƒæ•°æ®ï¼Œç”Ÿæˆè¯­ä¹‰ä¸°å¯Œçš„åµŒå…¥ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿæ›´å¥½åœ°åæ˜ è´¢æŠ¥ä¼šè®®çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µçš„å˜æ¢å™¨ï¼šç¬¬ä¸€é˜¶æ®µåœ¨èŠ‚ç‚¹çº§åˆ«ä½¿ç”¨å¯¹æ¯”å­¦ä¹ ç¼–ç å¤šæ¨¡æ€å†…å®¹å’Œè¯è¯­å…ƒæ•°æ®ï¼Œç¬¬äºŒé˜¶æ®µåˆæˆæ•´ä¸ªä¼šè®®çš„å…¨å±€åµŒå…¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å±‚æ¬¡è¯è¯­æ ‘ç»“æ„å’Œå¤šæ¨¡æ€ä¿¡å·çš„ç»“åˆï¼Œä½¿å¾—åµŒå…¥ä¸ä»…åæ˜ æƒ…æ„ŸåŸºè°ƒï¼Œè¿˜èƒ½æ•æ‰ç»“æ„é€»è¾‘å’Œä¸»é¢˜ä¸€è‡´æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å¹³é¢æ¨¡å‹å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨èŠ‚ç‚¹çº§åˆ«ï¼Œä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥ä¼˜åŒ–å¤šæ¨¡æ€å†…å®¹çš„è¡¨ç¤ºï¼ŒåŒæ—¶ç»“åˆè¿è´¯æ€§è¯„åˆ†å’Œä¸»é¢˜æ ‡ç­¾ç­‰å…ƒæ•°æ®ï¼Œç¡®ä¿åµŒå…¥çš„è¯­ä¹‰ä¸°å¯Œæ€§å’Œç»“æ„æ„è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„åµŒå…¥åœ¨æƒ…æ„ŸåŸºè°ƒã€ç»“æ„é€»è¾‘å’Œä¸»é¢˜ä¸€è‡´æ€§æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„ç¨³å®šæ€§ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œä½†ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜æ˜¾æå‡ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„è¯­ä¹‰æ„ä¹‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èé¢„æµ‹ã€è¯è¯­è¯„ä¼°ã€è¿œç¨‹åŒ»ç–—ã€æ•™è‚²å’Œæ”¿æ²»è¯è¯­ç­‰é«˜é£é™©æ²Ÿé€šåœºæ™¯ã€‚å…¶æä¾›çš„å¤šæ¨¡æ€è¯è¯­è¡¨ç¤ºæ–¹æ³•å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§å’Œå®ç”¨æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©ç›¸å…³é¢†åŸŸçš„å†³ç­–æ”¯æŒå’Œåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Earnings calls represent a uniquely rich and semi-structured source of financial communication, blending scripted managerial commentary with unscripted analyst dialogue. Although recent advances in financial sentiment analysis have integrated multi-modal signals, such as textual content and vocal tone, most systems rely on flat document-level or sentence-level models, failing to capture the layered discourse structure of these interactions. This paper introduces a novel multi-modal framework designed to generate semantically rich and structurally aware embeddings of earnings calls, by encoding them as hierarchical discourse trees. Each node, comprising either a monologue or a question-answer pair, is enriched with emotional signals derived from text, audio, and video, as well as structured metadata including coherence scores, topic labels, and answer coverage assessments. A two-stage transformer architecture is proposed: the first encodes multi-modal content and discourse metadata at the node level using contrastive learning, while the second synthesizes a global embedding for the entire conference. Experimental results reveal that the resulting embeddings form stable, semantically meaningful representations that reflect affective tone, structural logic, and thematic alignment. Beyond financial reporting, the proposed system generalizes to other high-stakes unscripted communicative domains such as tele-medicine, education, and political discourse, offering a robust and explainable approach to multi-modal discourse representation. This approach offers practical utility for downstream tasks such as financial forecasting and discourse evaluation, while also providing a generalizable method applicable to other domains involving high-stakes communication.

