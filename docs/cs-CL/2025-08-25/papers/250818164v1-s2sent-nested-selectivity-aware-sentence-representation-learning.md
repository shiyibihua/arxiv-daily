---
layout: default
title: S2Sent: Nested Selectivity Aware Sentence Representation Learning
---

# S2Sent: Nested Selectivity Aware Sentence Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18164" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18164v1</a>
  <a href="https://arxiv.org/pdf/2508.18164.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18164v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18164v1', 'S2Sent: Nested Selectivity Aware Sentence Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianxiang Zang, Nijia Mo, Yonda Wei, Meiling Ning, Hui Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS2Sentä»¥ä¼˜åŒ–Transformerå¥å­è¡¨ç¤ºå­¦ä¹ ä¸­çš„è¯­ä¹‰é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¥å­è¡¨ç¤º` `Transformer` `å¯¹æ¯”å­¦ä¹ ` `åµŒå¥—é€‰æ‹©` `è¯­ä¹‰æ„ŸçŸ¥` `ä¿¡æ¯å†—ä½™` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºTransformerçš„å¥å­è¡¨ç¤ºå­¦ä¹ æ–¹æ³•åœ¨ä¸åŒå—çš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ä¸Šå­˜åœ¨å·®å¼‚ï¼Œå¯¼è‡´ä¿¡æ¯å†—ä½™å’Œè¯­ä¹‰æŸå¤±é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„S2Sentæœºåˆ¶é€šè¿‡å‚æ•°åŒ–çš„åµŒå¥—é€‰æ‹©å™¨ï¼Œç»“åˆç©ºé—´é€‰æ‹©å’ŒåµŒå¥—é¢‘ç‡é€‰æ‹©ï¼Œä¼˜åŒ–äº†å¥å­è¡¨ç¤ºçš„èåˆè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒS2Sentåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œä¸”é¢å¤–çš„å‚æ•°å’Œæ¨ç†å»¶è¿Ÿå‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰ä¸»æµçš„å¥å­è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ç»“åˆäº†åŸºäºTransformerçš„ç¼–ç å™¨ä¸å¯¹æ¯”å­¦ä¹ ï¼Œé€šå¸¸ä¾èµ–äºç¼–ç å™¨æœ€åä¸€ä¸ªTransformerå—çš„éšè—çŠ¶æ€ã€‚ç„¶è€Œï¼Œä¸åŒå—åœ¨è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ä¸Šå­˜åœ¨å·®å¼‚ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¥å­è¡¨ç¤ºé€‰æ‹©æœºåˆ¶S2Sentï¼Œé›†æˆäº†å‚æ•°åŒ–çš„åµŒå¥—é€‰æ‹©å™¨ï¼Œæ—¨åœ¨ä¼˜åŒ–è·¨å—è¡¨ç¤ºèåˆçš„è¯­ä¹‰å†—ä½™ä¸æŸå¤±ã€‚è¯¥é€‰æ‹©å™¨é€šè¿‡ç©ºé—´é€‰æ‹©å’ŒåµŒå¥—é¢‘ç‡é€‰æ‹©æ¥å®ç°ä½ä¿¡æ¯å†—ä½™çš„èåˆï¼Œå¹¶æ•æ‰åµŒå…¥ç‰¹å¾ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒS2Sentåœ¨åŸºçº¿æ–¹æ³•ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒäº†å‚æ•°å’Œæ¨ç†å»¶è¿Ÿçš„å¾®å°å¢åŠ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºTransformerçš„å¥å­è¡¨ç¤ºå­¦ä¹ ä¸­ï¼Œä¸åŒå—çš„è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›å·®å¼‚å¯¼è‡´çš„è¯­ä¹‰å†—ä½™å’Œä¿¡æ¯æŸå¤±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæœ€åä¸€ä¸ªå—çš„éšè—çŠ¶æ€ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨å…¶ä»–å—çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šS2Senté€šè¿‡å¼•å…¥ä¸€ä¸ªå‚æ•°åŒ–çš„åµŒå¥—é€‰æ‹©å™¨ï¼Œè¿›è¡Œç©ºé—´é€‰æ‹©å’ŒåµŒå¥—é¢‘ç‡é€‰æ‹©ï¼Œä»¥ä¼˜åŒ–å¥å­è¡¨ç¤ºçš„èåˆè¿‡ç¨‹ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å¹³è¡¡ä¿¡æ¯å†—ä½™ä¸è¯­ä¹‰æŸå¤±ï¼Œæå‡æ•´ä½“è¡¨ç¤ºè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šS2Sentçš„æ•´ä½“æ¶æ„åŒ…æ‹¬Transformerç¼–ç å™¨å’ŒåµŒå¥—é€‰æ‹©å™¨ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚ç¼–ç å™¨æå–å¥å­çš„åˆæ­¥è¡¨ç¤ºï¼Œè€ŒåµŒå¥—é€‰æ‹©å™¨åˆ™åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè¿›ä¸€æ­¥çš„é€‰æ‹©å’Œèåˆã€‚

**å…³é”®åˆ›æ–°**ï¼šS2Sentçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç©ºé—´é€‰æ‹©æœºåˆ¶ï¼Œé‡‡ç”¨è‡ªé—¨æ§æœºåˆ¶è·å–è‡ªé€‚åº”æƒé‡ï¼Œä»è€Œå®ç°ä½å†—ä½™çš„èåˆã€‚æ­¤å¤–ï¼ŒåµŒå¥—é¢‘ç‡é€‰æ‹©é€šè¿‡ä¸åŒçš„DCTåŸºå‡½æ•°æ›¿ä»£GAPï¼Œé™ä½äº†è¯­ä¹‰æŸå¤±ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé€‰æ‹©å™¨çš„å‚æ•°åŒ–è®¾ç½®å’Œè‡ªé—¨æ§æœºåˆ¶æ˜¯å…³é”®ï¼Œç¡®ä¿äº†é€‰æ‹©è¿‡ç¨‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†ä¿¡æ¯å†—ä½™ä¸è¯­ä¹‰ä¿ç•™çš„å¹³è¡¡ã€‚æ•´ä½“ç½‘ç»œç»“æ„ä¿æŒäº†è¾ƒä½çš„å‚æ•°é‡å’Œæ¨ç†å»¶è¿Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒS2Sentåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼ŒåŒæ—¶ä¿æŒäº†é¢å¤–å‚æ•°å’Œæ¨ç†å»¶è¿Ÿçš„å¾®å°å¢åŠ ï¼Œæ˜¾ç¤ºå‡ºå…¶é«˜é›†æˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å¥å­è¡¨ç¤ºã€æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡ã€‚é€šè¿‡ä¼˜åŒ–å¥å­è¡¨ç¤ºçš„è´¨é‡ï¼ŒS2Sentèƒ½å¤Ÿæå‡ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œå½±å“åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆè¯­ä¹‰ç†è§£çš„é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The combination of Transformer-based encoders with contrastive learning represents the current mainstream paradigm for sentence representation learning. This paradigm is typically based on the hidden states of the last Transformer block of the encoder. However, within Transformer-based encoders, different blocks exhibit varying degrees of semantic perception ability. From the perspective of interpretability, the semantic perception potential of knowledge neurons is modulated by stimuli, thus rational cross-block representation fusion is a direction worth optimizing. To balance the semantic redundancy and loss across block fusion, we propose a sentence representation selection mechanism S\textsuperscript{2}Sent, which integrates a parameterized nested selector downstream of the Transformer-based encoder. This selector performs spatial selection (SS) and nested frequency selection (FS) from a modular perspective. The SS innovatively employs a spatial squeeze based self-gating mechanism to obtain adaptive weights, which not only achieves fusion with low information redundancy but also captures the dependencies between embedding features. The nested FS replaces GAP with different DCT basis functions to achieve spatial squeeze with low semantic loss. Extensive experiments have demonstrated that S\textsuperscript{2}Sent achieves significant improvements over baseline methods with negligible additional parameters and inference latency, while highlighting high integrability and scalability.

