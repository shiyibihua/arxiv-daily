---
layout: default
title: Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios
---

# Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18183" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18183v2</a>
  <a href="https://arxiv.org/pdf/2508.18183.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18183v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18183v2', 'Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luana Bulla, Gabriele Tuccio, Misael MongiovÃ¬, Aldo Gangemi

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25 (æ›´æ–°: 2025-09-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAulSignä»¥è§£å†³ä½èµ„æºåœºæ™¯ä¸‹çš„æ‰‹è¯­ç¿»è¯‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰‹è¯­ç¿»è¯‘` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½èµ„æºåœºæ™¯` `åŠ¨æ€æç¤º` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æ— éšœç¢æŠ€æœ¯` `è¯­è¨€æ¨¡å‹åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ‰‹è¯­ç¿»è¯‘æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­éš¾ä»¥æ³›åŒ–ï¼Œç¼ºä¹æ ‡å‡†åŒ–å’Œä¸°å¯Œçš„è¯­è¨€ç‰¹æ€§æ•æ‰ã€‚
2. æå‡ºAulSignæ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€æç¤ºå’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ‰‹è¯­ç¿»è¯‘ã€‚
3. åœ¨SignBank+å’Œæ„å¤§åˆ©LaCAM CNR-ISTCæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºåœ¨ä½æ•°æ®åœºæ™¯ä¸‹æ€§èƒ½ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†è‡ªç„¶è¯­è¨€ç¿»è¯‘ä¸ºæ‰‹è¯­æ˜¯ä¸€é¡¹å¤æ‚ä¸”æœªè¢«å……åˆ†æ¢ç´¢çš„ä»»åŠ¡ã€‚å°½ç®¡å¯¹æ— éšœç¢å’ŒåŒ…å®¹æ€§çš„å…³æ³¨æ—¥ç›Šå¢åŠ ï¼Œä½†ç”±äºç¼ºä¹ä¸æ‰‹è¯­æ•°æ®å¯¹é½çš„å¹³è¡Œè¯­æ–™åº“ï¼Œå¼€å‘ç¨³å¥çš„ç¿»è¯‘ç³»ç»Ÿä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸­å¸¸å¸¸éš¾ä»¥æ³›åŒ–ï¼Œå› ä¸ºå¯ç”¨çš„æ•°æ®é›†é€šå¸¸æ˜¯ç‰¹å®šé¢†åŸŸçš„ï¼Œç¼ºä¹æ ‡å‡†åŒ–ï¼Œæˆ–æœªèƒ½æ•æ‰æ‰‹è¯­çš„ä¸°å¯Œè¯­è¨€ç‰¹æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•AulSignï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡åŠ¨æ€æç¤ºå’Œä¸Šä¸‹æ–‡å­¦ä¹ è¿›è¡Œæ ·æœ¬é€‰æ‹©å’Œåç»­æ‰‹åŠ¿å…³è”ã€‚å°½ç®¡LLMsåœ¨å¤„ç†æ–‡æœ¬æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ç¼ºä¹å¯¹æ‰‹è¯­çš„å†…åœ¨çŸ¥è¯†ï¼Œå› æ­¤æ— æ³•åŸç”Ÿæ‰§è¡Œæ­¤ç±»ç¿»è¯‘ã€‚ä¸ºå…‹æœè¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬å°†æ‰‹åŠ¿ä¸è‡ªç„¶è¯­è¨€ä¸­çš„ç®€æ´æè¿°å…³è”ï¼Œå¹¶æŒ‡ç¤ºæ¨¡å‹ä½¿ç”¨è¿™äº›æè¿°ã€‚æˆ‘ä»¬åœ¨è‹±è¯­å’Œæ„å¤§åˆ©è¯­ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œç»“æœæ˜¾ç¤ºåœ¨ä½æ•°æ®åœºæ™¯ä¸‹ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªç„¶è¯­è¨€ä¸æ‰‹è¯­ä¹‹é—´çš„ç¿»è¯‘é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä½èµ„æºåœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºç¼ºä¹è¶³å¤Ÿçš„å¹³è¡Œè¯­æ–™åº“å’Œæ‰‹è¯­çš„è¯­è¨€ç‰¹æ€§æœªè¢«å……åˆ†æ•æ‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAulSigné€šè¿‡å°†æ‰‹åŠ¿ä¸è‡ªç„¶è¯­è¨€çš„ç®€æ´æè¿°å…³è”ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œå…‹æœäº†LLMså¯¹æ‰‹è¯­ç¼ºä¹å†…åœ¨çŸ¥è¯†çš„é™åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬åŠ¨æ€æç¤ºç”Ÿæˆã€æ ·æœ¬é€‰æ‹©å’Œæ‰‹åŠ¿å…³è”ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡åŠ¨æ€æç¤ºç”Ÿæˆä¸è¾“å…¥æ–‡æœ¬ç›¸å…³çš„æ‰‹åŠ¿æè¿°ï¼›ç„¶åï¼ŒåŸºäºä¸Šä¸‹æ–‡å­¦ä¹ é€‰æ‹©åˆé€‚çš„æ ·æœ¬ï¼›æœ€åï¼Œå°†é€‰å®šçš„æ‰‹åŠ¿ä¸è‡ªç„¶è¯­è¨€æè¿°è¿›è¡Œå…³è”ã€‚

**å…³é”®åˆ›æ–°**ï¼šAulSignçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸æ‰‹è¯­ç¿»è¯‘ç»“åˆï¼Œé€šè¿‡åŠ¨æ€æç¤ºå’Œæ ·æœ¬é€‰æ‹©çš„æ–¹å¼ï¼Œæ˜¾è‘—æé«˜äº†åœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„ç¿»è¯‘å‡†ç¡®æ€§ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•çš„é™æ€ç¿»è¯‘ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ‰‹åŠ¿ä¸æ–‡æœ¬æè¿°çš„åŒ¹é…åº¦ï¼ŒåŒæ—¶åœ¨æ ·æœ¬é€‰æ‹©è¿‡ç¨‹ä¸­å¼•å…¥äº†å¤šæ ·æ€§å’Œç›¸å…³æ€§è¯„ä¼°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAulSignåœ¨ä½æ•°æ®åœºæ™¯ä¸‹çš„è¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œå…·ä½“åœ¨SignBank+æ•°æ®é›†ä¸Šæå‡äº†ç¿»è¯‘å‡†ç¡®ç‡çº¦15%ï¼Œåœ¨æ„å¤§åˆ©LaCAM CNR-ISTCæ•°æ®é›†ä¸Šä¹Ÿæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— éšœç¢é€šä¿¡æŠ€æœ¯ã€æ•™è‚²å’Œç¤¾äº¤å¹³å°ï¼Œèƒ½å¤Ÿå¸®åŠ©å¬éšœäººå£«æ›´å¥½åœ°ä¸ç¤¾ä¼šæ²Ÿé€šã€‚æœªæ¥ï¼ŒAulSignæœ‰æœ›æ¨åŠ¨æ‰‹è¯­ç¿»è¯‘æŠ€æœ¯çš„æ™®åŠï¼Œæå‡ä¸åŒè¯­è¨€ç¤¾åŒºä¹‹é—´çš„äº¤æµä¸ç†è§£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Translating natural languages into sign languages is a highly complex and underexplored task. Despite growing interest in accessibility and inclusivity, the development of robust translation systems remains hindered by the limited availability of parallel corpora which align natural language with sign language data. Existing methods often struggle to generalize in these data-scarce environments, as the few datasets available are typically domain-specific, lack standardization, or fail to capture the full linguistic richness of sign languages. To address this limitation, we propose Advanced Use of LLMs for Sign Language Translation (AulSign), a novel method that leverages Large Language Models via dynamic prompting and in-context learning with sample selection and subsequent sign association. Despite their impressive abilities in processing text, LLMs lack intrinsic knowledge of sign languages; therefore, they are unable to natively perform this kind of translation. To overcome this limitation, we associate the signs with compact descriptions in natural language and instruct the model to use them. We evaluate our method on both English and Italian languages using SignBank+, a recognized benchmark in the field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior performance compared to state-of-the-art models in low-data scenario. Our findings demonstrate the effectiveness of AulSign, with the potential to enhance accessibility and inclusivity in communication technologies for underrepresented linguistic communities.

