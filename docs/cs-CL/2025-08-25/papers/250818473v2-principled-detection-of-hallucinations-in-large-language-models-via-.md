---
layout: default
title: Principled Detection of Hallucinations in Large Language Models via Multiple Testing
---

# Principled Detection of Hallucinations in Large Language Models via Multiple Testing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18473" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18473v2</a>
  <a href="https://arxiv.org/pdf/2508.18473.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18473v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18473v2', 'Principled Detection of Hallucinations in Large Language Models via Multiple Testing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiawei Li, Akshayaa Magesh, Venugopal V. Veeravalli

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25 (æ›´æ–°: 2025-08-27)

**å¤‡æ³¨**: 16 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¤šé‡æ£€éªŒæ–¹æ³•æ£€æµ‹å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰ç°è±¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `å‡è®¾æ£€éªŒ` `å¤šé‡æ£€éªŒ` `æœºå™¨å­¦ä¹ ` `é²æ£’æ€§` `å†…å®¹ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å®¹æ˜“å‡ºç°å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´ç”Ÿæˆçš„å›ç­”ä¸å‡†ç¡®ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚
2. æœ¬æ–‡æå‡ºå°†å¹»è§‰æ£€æµ‹è§†ä¸ºå‡è®¾æ£€éªŒé—®é¢˜ï¼Œå€Ÿé‰´å¤šé‡æ£€éªŒçš„æ–¹æ³•æ¥æé«˜æ£€æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¹»è§‰æ£€æµ‹ä¸Šä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå±•ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä¹Ÿå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆå¬èµ·æ¥è‡ªä¿¡ä½†å®é™…ä¸Šé”™è¯¯æˆ–æ— æ„ä¹‰çš„å›åº”ã€‚æœ¬æ–‡å°†å¹»è§‰æ£€æµ‹é—®é¢˜å½¢å¼åŒ–ä¸ºå‡è®¾æ£€éªŒé—®é¢˜ï¼Œå¹¶ä¸æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­çš„åˆ†å¸ƒå¤–æ£€æµ‹é—®é¢˜è¿›è¡Œç±»æ¯”ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§å—å¤šé‡æ£€éªŒå¯å‘çš„æ–¹æ³•æ¥è§£å†³å¹»è§‰æ£€æµ‹é—®é¢˜ï¼Œå¹¶æä¾›äº†å¤§é‡å®éªŒç»“æœä»¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•åœ¨å¯¹æŠ—æœ€å…ˆè¿›æ–¹æ³•æ—¶çš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹æ—¶çš„å¹»è§‰ç°è±¡ï¼Œç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹è¿™äº›å¹»è§‰æ—¶å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³å’Œé²æ£’æ€§å·®çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬å°†å¹»è§‰æ£€æµ‹é—®é¢˜è§†ä¸ºå‡è®¾æ£€éªŒé—®é¢˜ï¼Œé€šè¿‡å¤šé‡æ£€éªŒçš„æ–¹æ³•æ¥æé«˜æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†çœŸå®ä¿¡æ¯ä¸å¹»è§‰å†…å®¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬å‡è®¾ç”Ÿæˆã€æ£€éªŒè¿‡ç¨‹å’Œç»“æœåˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆå‡è®¾ï¼Œç„¶åè¿›è¡Œå¤šé‡æ£€éªŒä»¥è¯„ä¼°å…¶æœ‰æ•ˆæ€§ï¼Œæœ€ååˆ†æç»“æœä»¥ç¡®å®šå¹»è§‰çš„å­˜åœ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºå°†å¹»è§‰æ£€æµ‹ä¸å¤šé‡æ£€éªŒç›¸ç»“åˆï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥å¤„ç†è¿™ä¸€é—®é¢˜ï¼Œæ˜¾è‘—æé«˜äº†æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†å¤šä¸ªæ£€éªŒå‚æ•°ï¼Œå¹¶é‡‡ç”¨äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å¹»è§‰æ£€æµ‹ä»»åŠ¡ä¸Šç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯æé«˜äº†çº¦15%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨å¤šç§æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€å†…å®¹ç”Ÿæˆå’Œæ•™è‚²è¾…å¯¼ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ï¼Œå‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹ä¸­ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨äººå·¥æ™ºèƒ½çš„å®‰å…¨åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Large Language Models (LLMs) have emerged as powerful foundational models to solve a variety of tasks, they have also been shown to be prone to hallucinations, i.e., generating responses that sound confident but are actually incorrect or even nonsensical. In this work, we formulate the problem of detecting hallucinations as a hypothesis testing problem and draw parallels to the problem of out-of-distribution detection in machine learning models. We propose a multiple-testing-inspired method to solve the hallucination detection problem, and provide extensive experimental results to validate the robustness of our approach against state-of-the-art methods.

