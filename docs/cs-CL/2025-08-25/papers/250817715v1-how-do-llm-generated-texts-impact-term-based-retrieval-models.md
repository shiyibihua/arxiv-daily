---
layout: default
title: How Do LLM-Generated Texts Impact Term-Based Retrieval Models?
---

# How Do LLM-Generated Texts Impact Term-Based Retrieval Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17715" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17715v1</a>
  <a href="https://arxiv.org/pdf/2508.17715.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17715v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17715v1', 'How Do LLM-Generated Texts Impact Term-Based Retrieval Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Huang, Keping Bi, Yinqiong Cai, Wei Chen, Jiafeng Guo, Xueqi Cheng

**åˆ†ç±»**: cs.IR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨LLMç”Ÿæˆæ–‡æœ¬å¯¹åŸºäºæœ¯è¯­æ£€ç´¢æ¨¡å‹çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¿¡æ¯æ£€ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `æœ¯è¯­æ£€ç´¢` `æºåè§` `æ–‡æœ¬ç‰¹å¾åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†æ··åˆæ¥æºæ–‡æœ¬æ—¶é¢ä¸´æºåè§çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯LLMç”Ÿæˆçš„å†…å®¹ä¸äººç±»æ’°å†™çš„å†…å®¹æ··åˆæ—¶ã€‚
2. æœ¬æ–‡é€šè¿‡è¯­è¨€å­¦åˆ†æï¼Œæå‡ºäº†LLMç”Ÿæˆæ–‡æœ¬çš„ç‰¹å¾ï¼Œå¹¶æ¢è®¨äº†è¿™äº›ç‰¹å¾å¦‚ä½•å½±å“åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹çš„æ€§èƒ½ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒåŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹å¹¶ä¸è¡¨ç°å‡ºæºåè§ï¼Œè€Œæ˜¯ä¼˜å…ˆè€ƒè™‘ä¸æŸ¥è¯¢æœ¯è¯­åˆ†å¸ƒç›¸ç¬¦çš„æ–‡æ¡£ï¼Œä»è€Œæå‡äº†æ£€ç´¢æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§é‡ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„å†…å®¹æ¶Œå…¥äº’è”ç½‘ï¼Œä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰ç³»ç»Ÿé¢ä¸´ç€åŒºåˆ†å’Œå¤„ç†äººç±»åˆ›ä½œä¸æœºå™¨ç”Ÿæˆæ–‡æœ¬çš„æŒ‘æˆ˜ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç¥ç»æ£€ç´¢å™¨å¯èƒ½æ›´å€¾å‘äºLLMç”Ÿæˆçš„å†…å®¹ï¼Œè€Œç»å…¸çš„åŸºäºæœ¯è¯­çš„æ£€ç´¢å™¨å¦‚BM25åˆ™æ›´åå‘äºäººç±»æ’°å†™çš„æ–‡æ¡£ã€‚æœ¬æ–‡ç ”ç©¶äº†LLMç”Ÿæˆå†…å®¹å¯¹åŸºäºæœ¯è¯­æ£€ç´¢æ¨¡å‹çš„å½±å“ï¼Œæ­ç¤ºäº†LLMç”Ÿæˆæ–‡æœ¬åœ¨é«˜é¢‘å’Œä½é¢‘Zipfæ–œç‡ä¸Šçš„ç‰¹å¾ï¼Œä»¥åŠæ›´é«˜çš„æœ¯è¯­ç‰¹å¼‚æ€§å’Œæ–‡æ¡£çº§å¤šæ ·æ€§ã€‚è¿™äº›ç‰¹å¾ä¸LLMä¼˜åŒ–è¯»è€…ä½“éªŒçš„è®­ç»ƒç›®æ ‡ç›¸ä¸€è‡´ã€‚ç ”ç©¶è¿˜æ¢è®¨äº†åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹æ˜¯å¦å­˜åœ¨æºåè§ï¼Œå¾—å‡ºç»“è®ºï¼šè¿™äº›æ¨¡å‹ä¼˜å…ˆè€ƒè™‘ä¸æŸ¥è¯¢æœ¯è¯­åˆ†å¸ƒç›¸ç¬¦çš„æ–‡æ¡£ï¼Œè€Œéå›ºæœ‰çš„æºåè§ã€‚æ­¤ç ”ç©¶ä¸ºç†è§£å’Œè§£å†³åŸºäºæœ¯è¯­çš„IRç³»ç»Ÿåœ¨å¤„ç†æ··åˆæºå†…å®¹æ—¶çš„æ½œåœ¨åè§å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†LLMç”Ÿæˆæ–‡æœ¬ä¸äººç±»æ’°å†™æ–‡æœ¬æ··åˆæ—¶çš„æºåè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹è¿™ç§æ··åˆå†…å®¹æ—¶ï¼Œå¯èƒ½æ— æ³•æœ‰æ•ˆåŒºåˆ†ä¸åŒæ¥æºçš„æ–‡æœ¬ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šç ”ç©¶é€šè¿‡åˆ†æLLMç”Ÿæˆæ–‡æœ¬çš„è¯­è¨€ç‰¹å¾ï¼Œæ¢è®¨è¿™äº›ç‰¹å¾å¦‚ä½•å½±å“åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹çš„è¡¨ç°ã€‚é€šè¿‡æ­ç¤ºLLMç”Ÿæˆæ–‡æœ¬çš„é«˜é¢‘å’Œä½é¢‘Zipfæ–œç‡ã€æœ¯è¯­ç‰¹å¼‚æ€§å’Œæ–‡æ¡£å¤šæ ·æ€§ï¼Œæä¾›äº†æ–°çš„è§†è§’æ¥ç†è§£æ£€ç´¢æ¨¡å‹çš„åå¥½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†è¯­è¨€å­¦åˆ†æçš„æ–¹æ³•ï¼Œé¦–å…ˆå¯¹LLMç”Ÿæˆæ–‡æœ¬å’Œäººç±»æ’°å†™æ–‡æœ¬è¿›è¡Œç‰¹å¾æå–ï¼Œç„¶åå°†è¿™äº›ç‰¹å¾ä¸åŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹çš„è¡¨ç°è¿›è¡Œå¯¹æ¯”åˆ†æã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ–‡æœ¬ç‰¹å¾æå–ã€æ¨¡å‹æ€§èƒ½è¯„ä¼°å’Œæºåè§åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡è¯­è¨€å­¦ç‰¹å¾åˆ†æï¼Œæ­ç¤ºäº†LLMç”Ÿæˆæ–‡æœ¬åœ¨æ£€ç´¢æ¨¡å‹ä¸­çš„å½±å“æœºåˆ¶ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚ç‚¹ï¼Œè®¤ä¸ºåŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹å­˜åœ¨æºåè§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­å¯¹æ–‡æœ¬ç‰¹å¾çš„æå–é‡‡ç”¨äº†Zipfå®šå¾‹åˆ†æï¼Œè®¾ç½®äº†é«˜é¢‘å’Œä½é¢‘æœ¯è¯­çš„æ–œç‡è®¡ç®—ï¼Œå¹¶é€šè¿‡æ–‡æ¡£çº§å¤šæ ·æ€§æŒ‡æ ‡æ¥è¯„ä¼°æ–‡æœ¬çš„ä¸°å¯Œæ€§ã€‚è¿™äº›è®¾è®¡ä¸ºåç»­çš„æ£€ç´¢æ¨¡å‹æ€§èƒ½è¯„ä¼°æä¾›äº†åŸºç¡€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºæœ¯è¯­çš„æ£€ç´¢æ¨¡å‹åœ¨å¤„ç†LLMç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ä¸æŸ¥è¯¢æœ¯è¯­åˆ†å¸ƒç›¸ç¬¦çš„æ–‡æ¡£ï¼Œæœªè¡¨ç°å‡ºæºåè§ã€‚ç›¸è¾ƒäºä¼ ç»Ÿæ¨¡å‹ï¼Œæ£€ç´¢æ•ˆæœæå‡æ˜¾è‘—ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿã€æœç´¢å¼•æ“ä¼˜åŒ–åŠå†…å®¹æ¨èç³»ç»Ÿã€‚é€šè¿‡ç†è§£LLMç”Ÿæˆæ–‡æœ¬çš„ç‰¹å¾ï¼ŒIRç³»ç»Ÿå¯ä»¥æ›´æœ‰æ•ˆåœ°å¤„ç†æ··åˆæ¥æºçš„å†…å®¹ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œæ£€ç´¢å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœå¯èƒ½æ¨åŠ¨æ›´æ™ºèƒ½çš„æ£€ç´¢æ¨¡å‹è®¾è®¡ï¼Œé€‚åº”ä¸æ–­å˜åŒ–çš„å†…å®¹ç”Ÿæˆç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As more content generated by large language models (LLMs) floods into the Internet, information retrieval (IR) systems now face the challenge of distinguishing and handling a blend of human-authored and machine-generated texts. Recent studies suggest that neural retrievers may exhibit a preferential inclination toward LLM-generated content, while classic term-based retrievers like BM25 tend to favor human-written documents. This paper investigates the influence of LLM-generated content on term-based retrieval models, which are valued for their efficiency and robust generalization across domains. Our linguistic analysis reveals that LLM-generated texts exhibit smoother high-frequency and steeper low-frequency Zipf slopes, higher term specificity, and greater document-level diversity. These traits are aligned with LLMs being trained to optimize reader experience through diverse and precise expressions. Our study further explores whether term-based retrieval models demonstrate source bias, concluding that these models prioritize documents whose term distributions closely correspond to those of the queries, rather than displaying an inherent source bias. This work provides a foundation for understanding and addressing potential biases in term-based IR systems managing mixed-source content.

