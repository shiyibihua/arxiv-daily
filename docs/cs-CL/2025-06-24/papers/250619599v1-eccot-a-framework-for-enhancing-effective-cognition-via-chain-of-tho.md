---
layout: default
title: ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model
---

# ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19599" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19599v1</a>
  <a href="https://arxiv.org/pdf/2506.19599.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19599v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19599v1', 'ECCoT: A Framework for Enhancing Effective Cognition via Chain of Thought in Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenke Duan, Jiqun Pan, Jiani Tu, Xiaoyi Wang, Yanqing Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/erwinmsmith/ECCoT.git)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºECCoTæ¡†æ¶ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æœ‰æ•ˆè®¤çŸ¥èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `é“¾å¼æ€ç»´` `æ¨ç†éªŒè¯` `ä¸»é¢˜å»ºæ¨¡` `å› æœæ¨ç†` `å¯è§£é‡Šæ€§` `äººå·¥æ™ºèƒ½` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¼ºä¹é€æ˜æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„ç»“æœä¸å¯é ï¼Œå½±å“äº†å…¶å¯è§£é‡Šæ€§ã€‚
2. ECCoTæ¡†æ¶é€šè¿‡å¼•å…¥MRF-ETMå’ŒCSBertï¼Œä¼˜åŒ–äº†æ¨ç†é“¾çš„ç”Ÿæˆä¸éªŒè¯ï¼Œæå‡äº†æ¨ç†çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒECCoTæ˜¾è‘—æé«˜äº†æ¨ç†é“¾çš„æœ‰æ•ˆæ€§ï¼Œå‡å°‘äº†åè§ï¼Œå¹¶å¢å¼ºäº†å†³ç­–çš„å¯ä¿¡åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è§„æ¨¡äººå·¥æ™ºèƒ½æ—¶ä»£ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¸¸å¸¸ç¼ºä¹é€æ˜æ€§ï¼Œç”Ÿæˆä¸å¯é çš„è¾“å‡ºï¼Œå¯¼è‡´å¯¹å…¶å¯è§£é‡Šæ€§çš„æ‹…å¿§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ–¹æ³•å°†æ¨ç†ç»“æ„åŒ–ä¸ºé€æ­¥æ¨å¯¼ã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰æ¨ç†é“¾éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œé”™è¯¯å¯èƒ½å¯¼è‡´ä¸å¯é çš„ç»“è®ºã€‚æœ¬æ–‡æå‡ºECCoTï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„è®¤çŸ¥é“¾æ€ç»´éªŒè¯æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’Œä¼˜åŒ–LLMsä¸­çš„æ¨ç†é“¾ã€‚ECCoTé›†æˆäº†é©¬å°”å¯å¤«éšæœºåœºåµŒå…¥ä¸»é¢˜æ¨¡å‹ï¼ˆMRF-ETMï¼‰ç”¨äºä¸»é¢˜æ„ŸçŸ¥çš„CoTç”Ÿæˆï¼Œä»¥åŠå› æœå¥å­-BERTï¼ˆCSBertï¼‰ç”¨äºå› æœæ¨ç†å¯¹é½ã€‚é€šè¿‡ä½¿ç”¨ç»“æ„åŒ–æ’åºç»Ÿè®¡è¿‡æ»¤æ— æ•ˆé“¾ï¼ŒECCoTæé«˜äº†å¯è§£é‡Šæ€§ï¼Œå‡å°‘äº†åè§ï¼Œå¢å¼ºäº†åŸºäºLLMçš„å†³ç­–çš„å¯ä¿¡åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ç¼ºä¹é€æ˜æ€§å’Œå¯é æ€§çš„é—®é¢˜ã€‚ç°æœ‰çš„é“¾å¼æ€ç»´æ–¹æ³•è™½ç„¶ç»“æ„åŒ–äº†æ¨ç†è¿‡ç¨‹ï¼Œä½†å¹¶éæ‰€æœ‰æ¨ç†é“¾éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œé”™è¯¯çš„æ¨ç†é“¾å¯èƒ½å¯¼è‡´ä¸å¯é çš„ç»“è®ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šECCoTæ¡†æ¶é€šè¿‡å¼•å…¥é©¬å°”å¯å¤«éšæœºåœºåµŒå…¥ä¸»é¢˜æ¨¡å‹ï¼ˆMRF-ETMï¼‰å’Œå› æœå¥å­-BERTï¼ˆCSBertï¼‰ï¼Œå®ç°äº†å¯¹æ¨ç†é“¾çš„è¯„ä¼°å’Œä¼˜åŒ–ã€‚MRF-ETMç”¨äºç”Ÿæˆä¸»é¢˜æ„ŸçŸ¥çš„æ¨ç†é“¾ï¼Œè€ŒCSBertåˆ™ç”¨äºç¡®ä¿å› æœæ¨ç†çš„ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šECCoTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) MRF-ETMç”¨äºç”Ÿæˆä¸»é¢˜ç›¸å…³çš„æ¨ç†é“¾ï¼›2) CSBertç”¨äºå¯¹æ¨ç†é“¾è¿›è¡Œå› æœå…³ç³»çš„å¯¹é½ï¼›3) ç»“æ„åŒ–æ’åºç»Ÿè®¡ç”¨äºè¿‡æ»¤æ— æ•ˆçš„æ¨ç†é“¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šECCoTçš„æœ€å¤§åˆ›æ–°åœ¨äºå°†MRF-ETMä¸CSBertç»“åˆï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¨ç†é“¾éªŒè¯æ¡†æ¶ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨ç†é“¾ä¸ä»…å…·å¤‡ä¸»é¢˜ç›¸å…³æ€§ï¼Œè¿˜èƒ½ä¿æŒå› æœä¸€è‡´æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨ç†çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šECCoTåœ¨å‚æ•°è®¾ç½®ä¸Šé‡‡ç”¨äº†é’ˆå¯¹ä¸»é¢˜å»ºæ¨¡çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†å› æœå…³ç³»çš„çº¦æŸï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æ¨ç†é“¾æ—¢ç¬¦åˆä¸»é¢˜é€»è¾‘ï¼Œåˆå…·å¤‡å› æœæ¨ç†çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒECCoTæ¡†æ¶åœ¨æ¨ç†é“¾çš„æœ‰æ•ˆæ€§ä¸Šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦30%ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†ç”Ÿæˆç»“æœä¸­çš„åè§ã€‚è¿™ä¸€æˆæœè¡¨æ˜ECCoTèƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å†³ç­–å¯ä¿¡åº¦ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†æ›´å¯é çš„æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ECCoTæ¡†æ¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå†³ç­–æ”¯æŒç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æ¨ç†é“¾çš„æœ‰æ•ˆæ€§å’Œå¯ä¿¡åº¦ï¼ŒECCoTèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»å¤§è¯­è¨€æ¨¡å‹çš„è¾“å‡ºï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­çš„æ™®åŠä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the era of large-scale artificial intelligence, Large Language Models (LLMs) have made significant strides in natural language processing. However, they often lack transparency and generate unreliable outputs, raising concerns about their interpretability. To address this, the Chain of Thought (CoT) prompting method structures reasoning into step-by-step deductions. Yet, not all reasoning chains are valid, and errors can lead to unreliable conclusions. We propose ECCoT, an End-to-End Cognitive Chain of Thought Validation Framework, to evaluate and refine reasoning chains in LLMs. ECCoT integrates the Markov Random Field-Embedded Topic Model (MRF-ETM) for topic-aware CoT generation and Causal Sentence-BERT (CSBert) for causal reasoning alignment. By filtering ineffective chains using structured ordering statistics, ECCoT improves interpretability, reduces biases, and enhances the trustworthiness of LLM-based decision-making. Key contributions include the introduction of ECCoT, MRF-ETM for topic-driven CoT generation, and CSBert for causal reasoning enhancement. Code is released at: https://github.com/erwinmsmith/ECCoT.git.

