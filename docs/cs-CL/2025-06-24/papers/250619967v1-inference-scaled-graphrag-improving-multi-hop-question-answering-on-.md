---
layout: default
title: Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs
---

# Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19967" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19967v1</a>
  <a href="https://arxiv.org/pdf/2506.19967.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19967v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19967v1', 'Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Travis Thompson, Seung-Hwan Lim, Paul Liu, Ruoying He, Dongkuan Xu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInference-Scaled GraphRAGä»¥è§£å†³çŸ¥è¯†å›¾è°±å¤šè·³é—®ç­”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `å¤šè·³é—®ç­”` `æ¨ç†å¢å¼º` `å¤§å‹è¯­è¨€æ¨¡å‹` `å›¾éå†` `è®¡ç®—æ‰©å±•` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„RAGå’ŒGraphRAGæ–¹æ³•åœ¨å¤„ç†çŸ¥è¯†å›¾è°±ä¸­çš„å¤šè·³æ¨ç†æ—¶ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰èŠ‚ç‚¹é—´çš„å…³ç³»ç»“æ„ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºçš„Inference-Scaled GraphRAGæ¡†æ¶ï¼Œé€šè¿‡æ¨ç†æ—¶è®¡ç®—æ‰©å±•ï¼Œç»“åˆæ·±åº¦æ€ç»´é“¾å›¾éå†å’Œå¤šæ•°æŠ•ç¥¨æœºåˆ¶ï¼Œæå‡äº†å›¾æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨GRBenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†å¤šè·³é—®ç­”çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—çš„æå‡ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è¯­è¨€ç†è§£å’Œç”Ÿæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨çŸ¥è¯†å¯†é›†å‹æ¨ç†ä»»åŠ¡ä¸Šä»è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ç”±äºå¯¹ç»“æ„åŒ–ä¸Šä¸‹æ–‡å’Œå¤šè·³ä¿¡æ¯çš„è®¿é—®æœ‰é™ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰éƒ¨åˆ†ç¼“è§£äº†è¿™ä¸€é—®é¢˜ï¼Œä½†ä¼ ç»Ÿçš„RAGå’ŒGraphRAGæ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰çŸ¥è¯†å›¾è°±ä¸­èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ç»“æ„ã€‚æˆ‘ä»¬æå‡ºäº†Inference-Scaled GraphRAGï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æ¨ç†æ—¶è®¡ç®—æ‰©å±•æ¥å¢å¼ºåŸºäºLLMçš„å›¾æ¨ç†çš„æ–°æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†é¡ºåºæ‰©å±•ä¸æ·±åº¦æ€ç»´é“¾å›¾éå†ï¼Œä»¥åŠåœ¨äº¤é”™æ¨ç†-æ‰§è¡Œå¾ªç¯ä¸­å¯¹é‡‡æ ·è½¨è¿¹è¿›è¡Œå¤šæ•°æŠ•ç¥¨çš„å¹¶è¡Œæ‰©å±•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨GRBenchåŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†å¤šè·³é—®ç­”æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„GraphRAGå’Œå…ˆå‰çš„å›¾éå†åŸºçº¿å–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œæ¨ç†æ—¶æ‰©å±•æ˜¯ä¸€ç§å®ç”¨ä¸”ä¸æ¶æ„æ— å…³çš„è§£å†³æ–¹æ¡ˆï¼Œé€‚ç”¨äºç»“æ„åŒ–çŸ¥è¯†æ¨ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å›¾è°±å¤šè·³é—®ç­”ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œç°æœ‰çš„RAGå’ŒGraphRAGæ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨çŸ¥è¯†å›¾è°±ä¸­çš„å…³ç³»ç»“æ„ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºInference-Scaled GraphRAGæ¡†æ¶ï¼Œé€šè¿‡æ¨ç†æ—¶è®¡ç®—æ‰©å±•ï¼Œç»“åˆæ·±åº¦æ€ç»´é“¾å›¾éå†å’Œå¤šæ•°æŠ•ç¥¨æœºåˆ¶ï¼Œæ—¨åœ¨æå‡LLMåœ¨çŸ¥è¯†å›¾è°±ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªæ‰©å±•é˜¶æ®µï¼šé¡ºåºæ‰©å±•å’Œå¹¶è¡Œæ‰©å±•ã€‚é¡ºåºæ‰©å±•é€šè¿‡æ·±åº¦æ€ç»´é“¾éå†çŸ¥è¯†å›¾è°±ï¼Œè€Œå¹¶è¡Œæ‰©å±•åˆ™é€šè¿‡å¯¹é‡‡æ ·è½¨è¿¹è¿›è¡Œå¤šæ•°æŠ•ç¥¨æ¥å¢å¼ºæ¨ç†çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ¨ç†æ—¶è®¡ç®—æ‰©å±•çš„åº”ç”¨ï¼Œè¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„RAGå’ŒGraphRAGæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰çŸ¥è¯†å›¾è°±ä¸­çš„å…³ç³»ç»“æ„ï¼Œä»è€Œæå‡æ¨ç†æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ·±åº¦æ€ç»´é“¾çš„å›¾éå†ç­–ç•¥ï¼Œç»“åˆäº†å¯¹å¤šä¸ªè½¨è¿¹çš„æŠ•ç¥¨æœºåˆ¶ï¼Œä»¥ç¡®ä¿æ¨ç†ç»“æœçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒInference-Scaled GraphRAGåœ¨GRBenchåŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†å¤šè·³é—®ç­”æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»ŸGraphRAGæ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œå¹¶ä¸”åœ¨å¤šä¸ªå›¾éå†åŸºçº¿ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†ç®¡ç†å’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡å¤šè·³é—®ç­”çš„èƒ½åŠ›ï¼ŒInference-Scaled GraphRAGèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´ä¸ºå‡†ç¡®å’Œé«˜æ•ˆçš„çŸ¥è¯†è·å–æ–¹å¼ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved impressive capabilities in language understanding and generation, yet they continue to underperform on knowledge-intensive reasoning tasks due to limited access to structured context and multi-hop information. Retrieval-Augmented Generation (RAG) partially mitigates this by grounding generation in retrieved context, but conventional RAG and GraphRAG methods often fail to capture relational structure across nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel framework that enhances LLM-based graph reasoning by applying inference-time compute scaling. Our method combines sequential scaling with deep chain-of-thought graph traversal, and parallel scaling with majority voting over sampled trajectories within an interleaved reasoning-execution loop. Experiments on the GRBench benchmark demonstrate that our approach significantly improves multi-hop question answering performance, achieving substantial gains over both traditional GraphRAG and prior graph traversal baselines. These findings suggest that inference-time scaling is a practical and architecture-agnostic solution for structured knowledge reasoning with LLMs

