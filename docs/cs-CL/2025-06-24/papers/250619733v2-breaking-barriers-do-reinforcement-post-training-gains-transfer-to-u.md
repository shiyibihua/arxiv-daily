---
layout: default
title: Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?
---

# Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19733" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19733v2</a>
  <a href="https://arxiv.org/pdf/2506.19733.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19733v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19733v2', 'Breaking Barriers: Do Reinforcement Post Training Gains Transfer To Unseen Domains?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chuxuan Hu, Yuxuan Zhu, Antony Kellermann, Caleb Biddulph, Suppakit Waiwitlikhit, Jason Benn, Daniel Kang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24 (æ›´æ–°: 2025-07-23)

**å¤‡æ³¨**: 9 pages, 4 figures, 2 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¼ºåŒ–åè®­ç»ƒåœ¨æ–°é¢†åŸŸçš„è¿ç§»èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è¯­è¨€æ¨¡å‹` `è¿ç§»å­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `é¢†åŸŸæ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦åœ¨ç›¸åŒé¢†åŸŸä¸Šè¯„ä¼°RPTæ¨¡å‹ï¼Œç¼ºä¹å¯¹æ–°é¢†åŸŸæ³›åŒ–èƒ½åŠ›çš„æ·±å…¥ç ”ç©¶ã€‚
2. è®ºæ–‡é€šè¿‡è§‚å¯Ÿæ€§å’Œå¹²é¢„æ€§ç ”ç©¶ï¼Œç³»ç»Ÿè¯„ä¼°RPTæ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ï¼Œæ¢ç´¢å…¶æ³›åŒ–èƒ½åŠ›ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒRPTåœ¨ç›¸ä¼¼ä»»åŠ¡ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œä½†åœ¨ä¸åŒæ¨ç†æ¨¡å¼çš„é¢†åŸŸä¸­ï¼Œæå‡æ•ˆæœä¸ç¨³å®šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–åè®­ç»ƒï¼ˆRPTï¼‰æœ€è¿‘åœ¨æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ã€‚ç„¶è€Œï¼Œå…³äºè¿™äº›æ”¹è¿›åœ¨æ–°é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ä»ä¸æ˜ç¡®ï¼Œä¹‹å‰çš„ç ”ç©¶ä¸»è¦åœ¨ä¸å¾®è°ƒæ•°æ®ç›¸åŒçš„é¢†åŸŸä¸Šè¯„ä¼°RPTæ¨¡å‹ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡è¿›è¡Œäº†ä¸¤é¡¹ç ”ç©¶ï¼šç¬¬ä¸€é¡¹æ˜¯è§‚å¯Ÿæ€§ç ”ç©¶ï¼Œæ¯”è¾ƒäº†å¤šç§å¼€æ”¾æƒé‡çš„RPTæ¨¡å‹ä¸å…¶åŸºç¡€æ¨¡å‹åœ¨å¤šä¸ªé¢†åŸŸï¼ˆåŒ…æ‹¬å·²è§å’Œæœªè§é¢†åŸŸï¼‰çš„è¡¨ç°ï¼›ç¬¬äºŒé¡¹æ˜¯å¹²é¢„æ€§ç ”ç©¶ï¼Œåœ¨å•ä¸€é¢†åŸŸä¸Šå¾®è°ƒLLMså¹¶è¯„ä¼°å…¶åœ¨å¤šä¸ªé¢†åŸŸçš„æ€§èƒ½ã€‚ä¸¤é¡¹ç ”ç©¶å‡å¾—å‡ºç›¸åŒç»“è®ºï¼šå°½ç®¡RPTåœ¨ä¸å¾®è°ƒæ•°æ®ç›¸ä¼¼çš„ä»»åŠ¡ä¸Šå¸¦æ¥äº†æ˜¾è‘—æå‡ï¼Œä½†è¿™äº›æå‡åœ¨å…·æœ‰ä¸åŒæ¨ç†æ¨¡å¼çš„é¢†åŸŸä¸­æ³›åŒ–ä¸ä¸€è‡´ï¼Œç”šè‡³å¯èƒ½æ¶ˆå¤±ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¼ºåŒ–åè®­ç»ƒï¼ˆRPTï¼‰åœ¨æ–°é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ä¸æ˜ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºç›¸åŒé¢†åŸŸçš„è¯„ä¼°ï¼Œæœªèƒ½å……åˆ†æ¢è®¨RPTçš„è¿ç§»èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä¸¤é¡¹ç ”ç©¶ï¼Œè§‚å¯Ÿæ€§å’Œå¹²é¢„æ€§ï¼Œæ¯”è¾ƒRPTæ¨¡å‹ä¸åŸºç¡€æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ï¼Œä»¥è¯„ä¼°å…¶æ³›åŒ–èƒ½åŠ›ã€‚è§‚å¯Ÿæ€§ç ”ç©¶åˆ†æå¤šé¢†åŸŸè¡¨ç°ï¼Œå¹²é¢„æ€§ç ”ç©¶åˆ™åœ¨å•ä¸€é¢†åŸŸå¾®è°ƒåè¯„ä¼°å¤šé¢†åŸŸæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“ç ”ç©¶æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯å¯¹å¤šç§RPTæ¨¡å‹è¿›è¡Œè§‚å¯Ÿæ€§æ¯”è¾ƒï¼Œåˆ†æå…¶åœ¨å·²è§å’Œæœªè§é¢†åŸŸçš„è¡¨ç°ï¼›å…¶æ¬¡æ˜¯å¯¹LLMsè¿›è¡Œå¹²é¢„æ€§å¾®è°ƒï¼Œè¯„ä¼°å…¶åœ¨å¤šä¸ªé¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯„ä¼°RPTæ¨¡å‹åœ¨æ–°é¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ï¼Œæ­ç¤ºäº†å…¶åœ¨ä¸åŒæ¨ç†æ¨¡å¼ä¸‹çš„è¡¨ç°ä¸ä¸€è‡´æ€§ï¼Œä¸ç°æœ‰ç ”ç©¶çš„å•ä¸€é¢†åŸŸè¯„ä¼°å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å¤šç§å¼€æ”¾æƒé‡çš„RPTæ¨¡å‹ï¼Œè®¾ç½®äº†ä¸åŒçš„å¾®è°ƒå‚æ•°ï¼Œå¹¶åœ¨å¤šä¸ªé¢†åŸŸè¿›è¡Œæ€§èƒ½è¯„ä¼°ï¼Œç¡®ä¿äº†ç»“æœçš„å…¨é¢æ€§å’Œå¯é æ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒå®Œæ•´è®ºæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRPTåœ¨ä¸å¾®è°ƒæ•°æ®ç›¸ä¼¼çš„ä»»åŠ¡ä¸Šæ€§èƒ½æå‡æ˜¾è‘—ï¼Œä½†åœ¨ä¸åŒæ¨ç†æ¨¡å¼çš„é¢†åŸŸä¸­ï¼Œæå‡å¹…åº¦ä¸ç¨³å®šï¼Œç”šè‡³å¯èƒ½æ¶ˆå¤±ã€‚è¿™ä¸€å‘ç°ä¸ºRPTçš„å®é™…åº”ç”¨æä¾›äº†é‡è¦çš„å‚è€ƒï¼Œå¼ºè°ƒäº†åœ¨æ–°é¢†åŸŸè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹åœ¨æ–°é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ï¼ŒRPTå¯ä»¥å¸®åŠ©æ„å»ºæ›´ä¸ºæ™ºèƒ½å’Œçµæ´»çš„AIç³»ç»Ÿï¼Œé€‚åº”å¤šæ ·åŒ–çš„åº”ç”¨åœºæ™¯ï¼Œæœªæ¥å¯èƒ½åœ¨æ•™è‚²ã€åŒ»ç–—å’Œå®¢æˆ·æœåŠ¡ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement post training (RPT) has recently shown promise in improving the reasoning abilities of large language models (LLMs). However, it remains unclear how well these improvements generalize to new domains, as prior work evaluates RPT models on data from the same domains used for fine-tuning. To understand the generalizability of RPT, we conduct two studies. (1) Observational: We compare a wide range of open-weight RPT models against their corresponding base models across multiple domains, including both seen and unseen domains in their fine-tuning data. (2) Interventional: we fine-tune LLMs with RPT on single domains and evaluate their performance across multiple domains. Both studies converge on the same conclusion that, although RPT brings substantial gains on tasks similar to the fine-tuning data, the gains generalize inconsistently and can vanish on domains with different reasoning patterns.

