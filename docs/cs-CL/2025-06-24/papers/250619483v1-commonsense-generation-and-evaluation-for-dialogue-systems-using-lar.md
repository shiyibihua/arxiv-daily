---
layout: default
title: Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models
---

# Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19483" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19483v1</a>
  <a href="https://arxiv.org/pdf/2506.19483.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19483v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19483v1', 'Commonsense Generation and Evaluation for Dialogue Systems using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marcos Estecha-Garitagoitia, Chen Zhang, Mario RodrÃ­guez-Cantelar, Luis Fernando D'Haro

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¯¹è¯ç³»ç»Ÿçš„å¸¸è¯†ç”Ÿæˆä¸è¯„ä¼°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹è¯ç³»ç»Ÿ` `å¸¸è¯†æ¨ç†` `æ•°æ®å¢å¼º` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¯¹è¯ç³»ç»Ÿåœ¨ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å¸¸è¯†çŸ¥è¯†æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆå¢å¼ºå¯¹è¯æ•°æ®ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„å›åˆçº§æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œåˆ©ç”¨å¸¸è¯†å…³ç³»ç”Ÿæˆåˆæˆå¯¹è¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆåˆæˆå¯¹è¯çš„è´¨é‡ä¸Šå…·æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†LLMsçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æä¾›äº†å…³äºåŸºäºä¸åŒç±»å‹å¸¸è¯†å…³ç³»è¿›è¡Œå¯¹è¯ç³»ç»Ÿå›åˆçº§æ•°æ®å¢å¼ºçš„åˆæ­¥ç»“æœï¼Œå¹¶å¯¹ç”Ÿæˆçš„åˆæˆå›åˆè¿›è¡Œè‡ªåŠ¨è¯„ä¼°ã€‚æ‰€æå‡ºçš„æ–¹æ³•åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ‰©å±•çŸ¥è¯†å’Œé›¶æ ·æœ¬èƒ½åŠ›ï¼Œèƒ½å¤Ÿç†è§£ä¸Šä¸‹æ–‡ä¿¡æ¯åŠå…¶å¸¸è¯†æ¨ç†èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å—åˆ°é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ–¹æ³•çš„å¯å‘ï¼Œæ˜ç¡®åº”ç”¨äºåŸºäºæç¤ºçš„ç”Ÿæˆä»»åŠ¡ï¼Œä»¥å¸¸è¯†å±æ€§ä¸ºæ¡ä»¶è¿›è¡Œå¯¹è¯æ•°æ®å¢å¼ºï¼Œå¹¶è‡ªåŠ¨è¯„ä¼°ç”Ÿæˆçš„å¯¹è¯ã€‚é€šè¿‡ä»äº”ä¸ªçŸ¥åå¯¹è¯æ•°æ®é›†ä¸­éšæœºæå–200ä¸ªéƒ¨åˆ†å¯¹è¯ï¼Œç”ŸæˆåŸºäºä¸åŒäº‹ä»¶å¸¸è¯†å±æ€§çš„æ›¿ä»£å“åº”ï¼Œæ„å»ºäº†ä¸€ä¸ªæ–°æ•°æ®é›†ï¼Œä»¥æµ‹é‡LLMsåœ¨ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å¸¸è¯†çŸ¥è¯†æ–¹é¢çš„èƒ½åŠ›ã€‚åˆæ­¥ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåˆ©ç”¨äº†LLMsåœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„å¸¸è¯†æ¨ç†å’Œè¯„ä¼°èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹è¯ç³»ç»Ÿç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³å¸¸è¯†çŸ¥è¯†çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•°æ®å¢å¼ºæ–¹é¢æ•ˆæœæœ‰é™ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ¡ä»¶ç”Ÿæˆä¸åŒå¸¸è¯†å±æ€§çš„å¯¹è¯å›åˆï¼Œä»è€Œå®ç°æ•°æ®å¢å¼ºã€‚è¯¥è®¾è®¡æ—¨åœ¨æé«˜ç”Ÿæˆå¯¹è¯çš„ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œè‡ªç„¶æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€å¸¸è¯†å±æ€§æ¡ä»¶ç”Ÿæˆå’Œè‡ªåŠ¨è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»å¤šä¸ªå¯¹è¯æ•°æ®é›†ä¸­æå–éƒ¨åˆ†å¯¹è¯ï¼Œç„¶ååŸºäºå¸¸è¯†å±æ€§ç”Ÿæˆæ›¿ä»£å“åº”ï¼Œæœ€åä½¿ç”¨è¯„ä¼°æ¡†æ¶æ£€æµ‹ç”Ÿæˆæ•°æ®çš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§åŸºäºæŒ‡ä»¤çš„æç¤ºç”Ÿæˆæ–¹æ³•ï¼Œæ›¿ä»£äº†å¤æ‚çš„äº‹ä»¶å…³ç³»å…ƒç»„æå–è¿‡ç¨‹ï¼Œä½¿å¾—ç”Ÿæˆè¿‡ç¨‹æ›´ä¸ºé«˜æ•ˆå’Œçµæ´»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é’ˆå¯¹æ¯ä¸ªå¸¸è¯†å±æ€§çš„æŒ‡ä»¤æç¤ºï¼Œåˆ©ç”¨æœ€å…ˆè¿›çš„LLMsè¿›è¡Œç”Ÿæˆå’Œè¯„ä¼°ï¼Œç¡®ä¿ç”Ÿæˆçš„å¯¹è¯å›åˆèƒ½å¤Ÿå‡†ç¡®åæ˜ æ‰€éœ€çš„å¸¸è¯†å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨ç”Ÿæˆåˆæˆå¯¹è¯çš„è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆä¸ä¸Šä¸‹æ–‡ç›¸å…³çš„å¸¸è¯†çŸ¥è¯†æ–¹é¢ï¼Œå±•ç°äº†LLMsçš„å¼ºå¤§èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œéœ€è¿›ä¸€æ­¥éªŒè¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€å¯¹è¯æœºå™¨äººå’Œæ•™è‚²è¾…å¯¼ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¯¹è¯ç³»ç»Ÿçš„äº¤äº’è´¨é‡å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„å¯¹è¯ç³»ç»Ÿä¸­æ¨å¹¿åº”ç”¨ï¼Œæ¨åŠ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper provides preliminary results on exploring the task of performing turn-level data augmentation for dialogue system based on different types of commonsense relationships, and the automatic evaluation of the generated synthetic turns. The proposed methodology takes advantage of the extended knowledge and zero-shot capabilities of pretrained Large Language Models (LLMs) to follow instructions, understand contextual information, and their commonsense reasoning capabilities. The approach draws inspiration from methodologies like Chain-of-Thought (CoT), applied more explicitly to the task of prompt-based generation for dialogue-based data augmentation conditioned on commonsense attributes, and the automatic evaluation of the generated dialogues.
>   To assess the effectiveness of the proposed approach, first we extracted 200 randomly selected partial dialogues, from 5 different well-known dialogue datasets, and generate alternative responses conditioned on different event commonsense attributes. This novel dataset allows us to measure the proficiency of LLMs in generating contextually relevant commonsense knowledge, particularly up to 12 different specific ATOMIC [10] database relations. Secondly, we propose an evaluation framework to automatically detect the quality of the generated dataset inspired by the ACCENT [26] metric, which offers a nuanced approach to assess event commonsense. However, our method does not follow ACCENT's complex eventrelation tuple extraction process. Instead, we propose an instruction-based prompt for each commonsense attribute and use state-of-the-art LLMs to automatically detect the original attributes used when creating each augmented turn in the previous step.
>   Preliminary results suggest that our approach effectively harnesses LLMs capabilities for commonsense reasoning and evaluation in dialogue systems.

