---
layout: default
title: Hallucination Detection with Small Language Models
---

# Hallucination Detection with Small Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22486" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22486v1</a>
  <a href="https://arxiv.org/pdf/2506.22486.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22486v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22486v1', 'Hallucination Detection with Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Cheung

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

**æœŸåˆŠ**: Hallucination Detection with Small Language Models, IEEE International Conference on Data Engineering (ICDE), Workshop, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå°å‹è¯­è¨€æ¨¡å‹æ¡†æ¶ä»¥æ£€æµ‹å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `ç­”æ¡ˆéªŒè¯` `å°å‹æ¨¡å‹` `å‘é‡åŒ–æ•°æ®åº“` `æœºå™¨å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå›ç­”æ—¶å¯èƒ½å‡ºç°å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´å…¶å¯é æ€§ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹çœŸå®ç­”æ¡ˆçš„æƒ…å†µä¸‹ã€‚
2. æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹å¯¹LLMsç”Ÿæˆçš„å›ç­”è¿›è¡ŒéªŒè¯ï¼Œå¢å¼ºäº†å›ç­”çš„å¯ä¿¡åº¦ã€‚
3. é€šè¿‡å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ£€æµ‹æ­£ç¡®å›ç­”æ–¹é¢çš„F1åˆ†æ•°æé«˜äº†10%ï¼Œæ˜¾ç¤ºå‡ºå°å‹è¯­è¨€æ¨¡å‹åœ¨ç­”æ¡ˆéªŒè¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªä»ChatGPTçš„æ¨å‡ºä»¥æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å›ç­”é—®é¢˜ç­‰å¤šé¡¹ä»»åŠ¡ä¸­å±•ç°äº†æ˜¾è‘—çš„å®ç”¨æ€§ã€‚ç„¶è€Œï¼ŒLLMsç”Ÿæˆçš„å›ç­”ä¸­å¯èƒ½å­˜åœ¨å¹»è§‰ç°è±¡ï¼Œè¿™ä¼šå‰Šå¼±å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹çœŸå®ç­”æ¡ˆçš„æƒ…å†µä¸‹ã€‚æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œæ•´åˆå¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡ä»å‘é‡åŒ–æ•°æ®åº“ä¸­æ£€ç´¢çš„ä¸Šä¸‹æ–‡æ¥éªŒè¯LLMsç”Ÿæˆçš„å›ç­”ã€‚é€šè¿‡å°†å›ç­”åˆ†è§£ä¸ºå•ä¸ªå¥å­ï¼Œå¹¶åˆ©ç”¨å¤šä¸ªæ¨¡å‹è¾“å‡ºä¸­ç”Ÿæˆâ€œæ˜¯â€ä»¤ç‰Œçš„æ¦‚ç‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹å¹»è§‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ£€æµ‹æ­£ç¡®å›ç­”æ–¹é¢çš„F1åˆ†æ•°æé«˜äº†10%ï¼Œè¯æ˜äº†å°å‹è¯­è¨€æ¨¡å‹åœ¨ç­”æ¡ˆéªŒè¯ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå­¦æœ¯å’Œå®é™…åº”ç”¨æä¾›äº†å¯æ‰©å±•ä¸”é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå›ç­”æ—¶çš„å¹»è§‰ç°è±¡ï¼Œç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹çœŸå®ç­”æ¡ˆçš„æƒ…å†µä¸‹éš¾ä»¥æ£€æµ‹è¿™äº›å¹»è§‰ï¼Œå½±å“äº†æ¨¡å‹çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡æ•´åˆå¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹ï¼Œåˆ©ç”¨ä»å‘é‡åŒ–æ•°æ®åº“ä¸­æ£€ç´¢çš„ä¸Šä¸‹æ–‡æ¥éªŒè¯LLMsç”Ÿæˆçš„å›ç­”ï¼Œå¢å¼ºäº†å›ç­”çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯¹LLMsç”Ÿæˆçš„å›ç­”è¿›è¡Œç‹¬ç«‹éªŒè¯ã€‚å…·ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆæ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œç„¶åå°†LLMsçš„å›ç­”åˆ†è§£ä¸ºå•ä¸ªå¥å­ï¼Œæœ€åé€šè¿‡è®¡ç®—ç”Ÿæˆâ€œæ˜¯â€ä»¤ç‰Œçš„æ¦‚ç‡æ¥åˆ¤æ–­å›ç­”çš„çœŸå®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡å¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹çš„é›†æˆï¼Œæä¾›äº†ä¸€ç§æ–°çš„ç­”æ¡ˆéªŒè¯æœºåˆ¶ï¼Œä¸ä¼ ç»Ÿçš„å•ä¸€æ¨¡å‹æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†å¹»è§‰æ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å°å‹è¯­è¨€æ¨¡å‹çš„é€‰æ‹©ã€å¥å­åˆ†è§£ç­–ç•¥ä»¥åŠç”Ÿæˆâ€œæ˜¯â€ä»¤ç‰Œçš„æ¦‚ç‡è®¡ç®—æ–¹æ³•ï¼Œè¿™äº›è®¾è®¡å…±åŒæ„æˆäº†æœ‰æ•ˆçš„éªŒè¯æµç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ¡†æ¶åœ¨æ£€æµ‹æ­£ç¡®å›ç­”æ–¹é¢çš„F1åˆ†æ•°æé«˜äº†10%ï¼Œç›¸è¾ƒäºå¹»è§‰æ£€æµ‹è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚è¿™ä¸€æå‡è¡¨æ˜ï¼Œå¤šä¸ªå°å‹è¯­è¨€æ¨¡å‹çš„é›†æˆåœ¨ç­”æ¡ˆéªŒè¯ä¸­å…·æœ‰è‰¯å¥½çš„æ•ˆæœï¼Œæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€åœ¨çº¿å®¢æœã€æ•™è‚²è¾…åŠ©å·¥å…·ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜å›ç­”çš„å¯é æ€§ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®çš„ä¿¡æ¯ï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œæœªæ¥å¯èƒ½åœ¨å…¶ä»–éœ€è¦é«˜å¯ä¿¡åº¦å›ç­”çš„åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Since the introduction of ChatGPT, large language models (LLMs) have demonstrated significant utility in various tasks, such as answering questions through retrieval-augmented generation. Context can be retrieved using a vectorized database, serving as a foundation for LLMs to generate responses. However, hallucinations in responses can undermine the reliability of LLMs in practical applications, and they are not easily detectable in the absence of ground truth, particularly in question-and-answer scenarios. This paper proposes a framework that integrates multiple small language models to verify responses generated by LLMs using the retrieved context from a vectorized database. By breaking down the responses into individual sentences and utilizing the probability of generating "Yes" tokens from the outputs of multiple models for a given set of questions, responses, and relevant context, hallucinations can be detected. The proposed framework is validated through experiments with real datasets comprising over 100 sets of questions, answers, and contexts, including responses with fully and partially correct sentences. The results demonstrate a 10\% improvement in F1 scores for detecting correct responses compared to hallucinations, indicating that multiple small language models can be effectively employed for answer verification, providing a scalable and efficient solution for both academic and practical applications.

