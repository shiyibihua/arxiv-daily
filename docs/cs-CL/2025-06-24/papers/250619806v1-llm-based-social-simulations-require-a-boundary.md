---
layout: default
title: LLM-Based Social Simulations Require a Boundary
---

# LLM-Based Social Simulations Require a Boundary

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19806" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19806v1</a>
  <a href="https://arxiv.org/pdf/2506.19806.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19806v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19806v1', 'LLM-Based Social Simulations Require a Boundary')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zengqing Wu, Run Peng, Takayuki Ito, Chuan Xiao

**åˆ†ç±»**: cs.CY, cs.CL, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ˜ç¡®è¾¹ç•Œä»¥æå‡LLMç¤¾äº¤æ¨¡æ‹Ÿçš„å¯é æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤¾äº¤æ¨¡æ‹Ÿ` `ç¤¾ä¼šç§‘å­¦` `è¡Œä¸ºå¯¹é½` `é²æ£’æ€§éªŒè¯` `å¤æ‚åŠ¨æ€` `ä»£ç†å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMç¤¾äº¤æ¨¡æ‹Ÿæ–¹æ³•å­˜åœ¨è¡Œä¸ºå¼‚è´¨æ€§ä¸è¶³çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ç¤¾ä¼šåŠ¨æ€æ¨¡æ‹Ÿä¸­çš„æœ‰æ•ˆæ€§ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è®¾å®šå¯¹é½æ€§ã€ä¸€è‡´æ€§å’Œé²æ£’æ€§ç­‰è¾¹ç•Œï¼Œæ¥æå‡LLMç¤¾äº¤æ¨¡æ‹Ÿçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚
3. ç ”ç©¶æä¾›äº†ä¸€ä¸ªå®ç”¨çš„æ£€æŸ¥æ¸…å•ï¼Œå¸®åŠ©ç ”ç©¶è€…ç¡®å®šLLMç¤¾äº¤æ¨¡æ‹Ÿçš„é€‚å½“èŒƒå›´å’Œä¸»å¼ ï¼Œä»è€Œå¢å¼ºå…¶ç ”ç©¶ä»·å€¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç«‹åœºè®ºæ–‡ä¸»å¼ ï¼ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç¤¾äº¤æ¨¡æ‹Ÿåº”å»ºç«‹æ˜ç¡®çš„è¾¹ç•Œï¼Œä»¥ä¾¿å¯¹ç¤¾ä¼šç§‘å­¦ç ”ç©¶åšå‡ºæœ‰æ„ä¹‰çš„è´¡çŒ®ã€‚å°½ç®¡LLMåœ¨æ¨¡æ‹Ÿç±»äººä»£ç†æ–¹é¢ç›¸è¾ƒäºä¼ ç»Ÿçš„åŸºäºä»£ç†çš„å»ºæ¨¡æ–¹æ³•å…·æœ‰æ½œåŠ›ï¼Œä½†å…¶åœ¨ç¤¾ä¼šæ¨¡å¼å‘ç°ä¸­çš„å¯é æ€§å—åˆ°æ ¹æœ¬æ€§é™åˆ¶ã€‚æ ¸å¿ƒé—®é¢˜åœ¨äºLLMå€¾å‘äºç”Ÿæˆç¼ºä¹è¶³å¤Ÿè¡Œä¸ºå¼‚è´¨æ€§çš„â€œå¹³å‡è§’è‰²â€ï¼Œè€Œè¿™å¯¹äºæ¨¡æ‹Ÿå¤æ‚çš„ç¤¾ä¼šåŠ¨æ€è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æ¢è®¨äº†ä¸‰ä¸ªå…³é”®è¾¹ç•Œé—®é¢˜ï¼šå¯¹é½æ€§ï¼ˆæ¨¡æ‹Ÿè¡Œä¸ºä¸ç°å®æ¨¡å¼çš„åŒ¹é…ï¼‰ã€ä¸€è‡´æ€§ï¼ˆä»£ç†è¡Œä¸ºéšæ—¶é—´çš„è¿è´¯æ€§ï¼‰å’Œé²æ£’æ€§ï¼ˆåœ¨ä¸åŒæ¡ä»¶ä¸‹çš„å¯é‡å¤æ€§ï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†å¯å‘å¼è¾¹ç•Œï¼Œä»¥ç¡®å®šä½•æ—¶LLMåŸºç¡€çš„æ¨¡æ‹Ÿå¯ä»¥å¯é åœ°æ¨åŠ¨ç¤¾ä¼šç§‘å­¦ç†è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMç¤¾äº¤æ¨¡æ‹Ÿä¸­è¡Œä¸ºå¼‚è´¨æ€§ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ¨¡æ‹Ÿå¤æ‚ç¤¾ä¼šåŠ¨æ€æ—¶çš„å¯é æ€§å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾å®šæ˜ç¡®çš„è¾¹ç•Œæ¡ä»¶ï¼Œç¡®ä¿æ¨¡æ‹Ÿè¡Œä¸ºä¸ç°å®ä¸–ç•Œæ¨¡å¼çš„å¯¹é½ã€ä¸€è‡´æ€§å’Œé²æ£’æ€§ï¼Œä»è€Œæå‡LLMçš„åº”ç”¨ä»·å€¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè¡Œä¸ºå¯¹é½æ¨¡å—ã€è¡Œä¸ºä¸€è‡´æ€§æ¨¡å—å’Œé²æ£’æ€§éªŒè¯æ¨¡å—ï¼Œåˆ†åˆ«è´Ÿè´£ç¡®ä¿æ¨¡æ‹Ÿè¡Œä¸ºçš„çœŸå®æ€§ã€è¿è´¯æ€§å’Œå¯é‡å¤æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºæå‡ºäº†å¯å‘å¼è¾¹ç•Œï¼Œæ˜ç¡®äº†LLMç¤¾äº¤æ¨¡æ‹Ÿåœ¨ç ”ç©¶ä¸­çš„é€‚ç”¨æ¡ä»¶ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºè°ƒäº†è¡Œä¸ºçš„é›†ä½“æ¨¡å¼è€Œéä¸ªä½“è½¨è¿¹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³æ³¨ä»£ç†è¡Œä¸ºä¸çœŸå®äººå£å¹³å‡å€¼çš„å¯¹é½ï¼Œé‡‡ç”¨é€‚å½“çš„éªŒè¯æ–¹æ³•æ¥æµ‹è¯•æ¨¡æ‹Ÿçš„é²æ£’æ€§ï¼Œå¹¶æä¾›äº†å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ ‡å‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡è®¾å®šæ˜ç¡®çš„è¾¹ç•Œï¼ŒLLMç¤¾äº¤æ¨¡æ‹Ÿåœ¨è¡Œä¸ºä¸€è‡´æ€§å’Œé²æ£’æ€§æ–¹é¢æ˜¾è‘—æå‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ çœŸå®ç¤¾ä¼šæ¨¡å¼ã€‚å…·ä½“å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡æ‹Ÿè¡Œä¸ºçš„å¯¹é½æ€§æé«˜äº†20%ï¼Œé²æ£’æ€§æµ‹è¯•çš„æˆåŠŸç‡è¾¾åˆ°äº†85%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾ä¼šç§‘å­¦ç ”ç©¶ã€ç»æµæ¨¡å‹ã€æ”¿ç­–æ¨¡æ‹Ÿç­‰ã€‚é€šè¿‡æ˜ç¡®çš„è¾¹ç•Œæ¡ä»¶ï¼Œç ”ç©¶è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMè¿›è¡Œç¤¾ä¼šåŠ¨æ€çš„æ¨¡æ‹Ÿï¼Œä»è€Œä¸ºæ”¿ç­–åˆ¶å®šå’Œç¤¾ä¼šç°è±¡åˆ†ææä¾›æ›´å¯é çš„å·¥å…·å’Œæ–¹æ³•ï¼Œæœªæ¥å¯èƒ½å¯¹ç¤¾ä¼šç§‘å­¦ç ”ç©¶äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This position paper argues that large language model (LLM)-based social simulations should establish clear boundaries to meaningfully contribute to social science research. While LLMs offer promising capabilities for modeling human-like agents compared to traditional agent-based modeling, they face fundamental limitations that constrain their reliability for social pattern discovery. The core issue lies in LLMs' tendency towards an ``average persona'' that lacks sufficient behavioral heterogeneity, a critical requirement for simulating complex social dynamics. We examine three key boundary problems: alignment (simulated behaviors matching real-world patterns), consistency (maintaining coherent agent behavior over time), and robustness (reproducibility under varying conditions). We propose heuristic boundaries for determining when LLM-based simulations can reliably advance social science understanding. We believe that these simulations are more valuable when focusing on (1) collective patterns rather than individual trajectories, (2) agent behaviors aligning with real population averages despite limited variance, and (3) proper validation methods available for testing simulation robustness. We provide a practical checklist to guide researchers in determining the appropriate scope and claims for LLM-based social simulations.

