---
layout: default
title: Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences
---

# Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.23451" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.23451v1</a>
  <a href="https://arxiv.org/pdf/2510.23451.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.23451v1" onclick="toggleFavorite(this, '2510.23451v1', 'Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhuoran Jin, Hongbang Yuan, Kejian Zhu, Jiachun Li, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao

**åˆ†ç±»**: cs.CL, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-27

**å¤‡æ³¨**: 48 pages, 17 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmni-Rewardï¼Œç”¨äºæ”¯æŒè‡ªç”±å½¢å¼åå¥½çš„é€šç”¨å…¨æ¨¡æ€å¥–åŠ±å»ºæ¨¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¥–åŠ±æ¨¡å‹` `å¤šæ¨¡æ€å­¦ä¹ ` `åå¥½å»ºæ¨¡` `é€šç”¨äººå·¥æ™ºèƒ½` `äººæœºå¯¹é½` `è‡ªç”±å½¢å¼åå¥½` `å…¨æ¨¡æ€æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¥–åŠ±æ¨¡å‹ä¸»è¦é›†ä¸­äºæ–‡æœ¬å’Œå›¾åƒæ¨¡æ€ï¼Œç¼ºä¹å¯¹è§†é¢‘ã€éŸ³é¢‘ç­‰æ¨¡æ€çš„æ”¯æŒï¼Œä¸”éš¾ä»¥æ•æ‰ä¸ªæ€§åŒ–åå¥½çš„å¤æ‚æ€§ã€‚
2. Omni-Rewardé€šè¿‡æ„å»ºå…¨æ¨¡æ€å¥–åŠ±æ¨¡å‹ï¼Œå¹¶å¼•å…¥è‡ªç”±å½¢å¼åå¥½ï¼Œæ—¨åœ¨æå‡å¥–åŠ±æ¨¡å‹åœ¨å¤šæ¨¡æ€æ•°æ®å’Œä¸ªæ€§åŒ–åå¥½æ–¹é¢çš„å»ºæ¨¡èƒ½åŠ›ã€‚
3. Omni-Rewardåœ¨è‡ªå»ºçš„Omni-RewardBenchåŸºå‡†æµ‹è¯•ä»¥åŠå…¶ä»–å¸¸ç”¨åŸºå‡†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨å…¨æ¨¡æ€å¥–åŠ±å»ºæ¨¡æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰åœ¨ä½¿AIè¡Œä¸ºä¸äººç±»åå¥½å¯¹é½æ–¹é¢èµ·ç€å…³é”®ä½œç”¨ï¼Œä½†å®ƒä»¬é¢ä¸´ä¸¤ä¸ªæ ¹æœ¬æŒ‘æˆ˜ï¼šï¼ˆ1ï¼‰æ¨¡æ€ä¸å¹³è¡¡ï¼Œå¤§å¤šæ•°RMä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬å’Œå›¾åƒæ¨¡æ€ï¼Œå¯¹è§†é¢‘ã€éŸ³é¢‘å’Œå…¶ä»–æ¨¡æ€çš„æ”¯æŒæœ‰é™ï¼›ï¼ˆ2ï¼‰åå¥½åˆšæ€§ï¼Œåœ¨å›ºå®šçš„äºŒå…ƒåå¥½å¯¹ä¸Šè®­ç»ƒæ— æ³•æ•æ‰ä¸ªæ€§åŒ–åå¥½çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†Omni-Rewardï¼Œæ—¨åœ¨å®ç°æ”¯æŒè‡ªç”±å½¢å¼åå¥½çš„é€šç”¨å…¨æ¨¡æ€å¥–åŠ±å»ºæ¨¡ï¼ŒåŒ…æ‹¬ï¼šï¼ˆ1ï¼‰è¯„ä¼°ï¼šæˆ‘ä»¬å¼•å…¥äº†Omni-RewardBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…·æœ‰è‡ªç”±å½¢å¼åå¥½çš„å…¨æ¨¡æ€RMåŸºå‡†ï¼Œæ¶µç›–æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘å’Œ3Dç­‰äº”ç§æ¨¡æ€çš„ä¹ä¸ªä»»åŠ¡ï¼›ï¼ˆ2ï¼‰æ•°æ®ï¼šæˆ‘ä»¬æ„å»ºäº†Omni-RewardDataï¼Œä¸€ä¸ªåŒ…å«248Kä¸ªé€šç”¨åå¥½å¯¹å’Œ69Kä¸ªæŒ‡ä»¤è°ƒä¼˜å¯¹çš„å¤šæ¨¡æ€åå¥½æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒé€šç”¨å…¨æ¨¡æ€RMï¼›ï¼ˆ3ï¼‰æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº†Omni-RewardModelï¼ŒåŒ…æ‹¬åˆ¤åˆ«å¼å’Œç”Ÿæˆå¼RMï¼Œå¹¶åœ¨Omni-RewardBenchä»¥åŠå…¶ä»–å¹¿æ³›ä½¿ç”¨çš„å¥–åŠ±å»ºæ¨¡åŸºå‡†ä¸Šå–å¾—äº†å¼ºå¤§çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¥–åŠ±æ¨¡å‹ä¸»è¦é›†ä¸­äºæ–‡æœ¬å’Œå›¾åƒæ¨¡æ€ï¼Œå¯¹è§†é¢‘ã€éŸ³é¢‘ç­‰æ¨¡æ€çš„æ”¯æŒä¸è¶³ï¼Œå¯¼è‡´åœ¨å¤„ç†å¤šæ¨¡æ€ä»»åŠ¡æ—¶æ€§èƒ½å—é™ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿçš„äºŒå…ƒåå¥½å¯¹è®­ç»ƒæ–¹å¼æ— æ³•æ•æ‰ç”¨æˆ·ä¸ªæ€§åŒ–åå¥½çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmni-Rewardçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªèƒ½å¤Ÿå¤„ç†å¤šç§æ¨¡æ€æ•°æ®å¹¶æ”¯æŒè‡ªç”±å½¢å¼åå¥½çš„é€šç”¨å¥–åŠ±æ¨¡å‹ã€‚é€šè¿‡å¼•å…¥å…¨æ¨¡æ€æ•°æ®å’Œè‡ªç”±å½¢å¼åå¥½ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°ä¸åŒæ¨¡æ€æ•°æ®çš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmni-RewardåŒ…å«ä¸‰ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šOmni-RewardBenchï¼ˆè¯„ä¼°åŸºå‡†ï¼‰ã€Omni-RewardDataï¼ˆå¤šæ¨¡æ€åå¥½æ•°æ®é›†ï¼‰å’ŒOmni-RewardModelï¼ˆå¥–åŠ±æ¨¡å‹ï¼‰ã€‚Omni-RewardBenchç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€å’Œä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚Omni-RewardDataç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚Omni-RewardModelåŒ…å«åˆ¤åˆ«å¼å’Œç”Ÿæˆå¼ä¸¤ç§æ¨¡å‹ç»“æ„ï¼Œç”¨äºå­¦ä¹ ä¸åŒæ¨¡æ€æ•°æ®ä¹‹é—´çš„å…³ç³»å’Œç”¨æˆ·åå¥½ã€‚

**å…³é”®åˆ›æ–°**ï¼šOmni-Rewardçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¯¹å…¨æ¨¡æ€æ•°æ®å’Œè‡ªç”±å½¢å¼åå¥½çš„æ”¯æŒã€‚é€šè¿‡æ„å»ºåŒ…å«å¤šç§æ¨¡æ€æ•°æ®å’Œè‡ªç”±å½¢å¼åå¥½çš„æ•°æ®é›†ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„æ¨¡å‹ç»“æ„ï¼ŒOmni-Rewardèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ç”¨æˆ·æ„å›¾ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°ä¸åŒæ¨¡æ€æ•°æ®çš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒOmni-RewardBenchçš„æå‡ºä¸ºå…¨æ¨¡æ€å¥–åŠ±å»ºæ¨¡æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°å¹³å°ã€‚

**å…³é”®è®¾è®¡**ï¼šOmni-RewardModelé‡‡ç”¨äº†åˆ¤åˆ«å¼å’Œç”Ÿæˆå¼ä¸¤ç§æ¨¡å‹ç»“æ„ã€‚åˆ¤åˆ«å¼æ¨¡å‹ç”¨äºç›´æ¥é¢„æµ‹å¥–åŠ±å€¼ï¼Œè€Œç”Ÿæˆå¼æ¨¡å‹ç”¨äºç”Ÿæˆç¬¦åˆç”¨æˆ·åå¥½çš„å†…å®¹ã€‚å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼šä½¿ç”¨Transformeræ¶æ„ä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œé‡‡ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°æ¥å­¦ä¹ ä¸åŒæ¨¡æ€æ•°æ®ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥ä¼˜åŒ–æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚æ•°æ®é›†æ„å»ºæ–¹é¢ï¼Œé‡‡ç”¨äº†äººå·¥æ ‡æ³¨å’Œè‡ªåŠ¨ç”Ÿæˆç›¸ç»“åˆçš„æ–¹å¼ï¼Œä»¥ä¿è¯æ•°æ®çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Omni-Rewardåœ¨Omni-RewardBenchåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨è§†é¢‘ã€éŸ³é¢‘å’Œ3Dç­‰æ¨¡æ€ä¸Šï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼ŒOmni-Rewardåœ¨å…¶ä»–å¸¸ç”¨çš„å¥–åŠ±å»ºæ¨¡åŸºå‡†ä¸Šä¹Ÿè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶é€šç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Omni-Rewardå¯åº”ç”¨äºå„ç§éœ€è¦ç†è§£å’Œå¯¹é½äººç±»åå¥½çš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚ï¼šå¤šæ¨¡æ€å†…å®¹æ¨èã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿã€æœºå™¨äººè¡Œä¸ºè§„åˆ’ç­‰ã€‚é€šè¿‡æ›´å‡†ç¡®åœ°æ•æ‰ç”¨æˆ·æ„å›¾ï¼ŒOmni-Rewardå¯ä»¥æå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¿ƒè¿›äººæœºåä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reward models (RMs) play a critical role in aligning AI behaviors with human preferences, yet they face two fundamental challenges: (1) Modality Imbalance, where most RMs are mainly focused on text and image modalities, offering limited support for video, audio, and other modalities; and (2) Preference Rigidity, where training on fixed binary preference pairs fails to capture the complexity and diversity of personalized preferences. To address the above challenges, we propose Omni-Reward, a step toward generalist omni-modal reward modeling with support for free-form preferences, consisting of: (1) Evaluation: We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form preferences, covering nine tasks across five modalities including text, image, video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal preference dataset comprising 248K general preference pairs and 69K instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We propose Omni-RewardModel, which includes both discriminative and generative RMs, and achieves strong performance on Omni-RewardBench as well as other widely used reward modeling benchmarks.

