---
layout: default
title: Semi-Supervised Learning for Large Language Models Safety and Content Moderation
---

# Semi-Supervised Learning for Large Language Models Safety and Content Moderation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.21107" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.21107v1</a>
  <a href="https://arxiv.org/pdf/2512.21107.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.21107v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.21107v1', 'Semi-Supervised Learning for Large Language Models Safety and Content Moderation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Eduard Stefan Dinuta, Iustin Sirbu, Traian Rebedea

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§å’Œå†…å®¹å®¡æ ¸èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠç›‘ç£å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§` `å†…å®¹å®¡æ ¸` `æ•°æ®å¢å¼º` `è‡ªç„¶è¯­è¨€å¤„ç†` `å®‰å…¨åˆ†ç±»å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMå®‰å…¨åˆ†ç±»å™¨ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜ã€æ˜“å‡ºé”™ï¼Œä¸”è´¨é‡éš¾ä»¥ä¿è¯ã€‚
2. æå‡ºåˆ©ç”¨åŠç›‘ç£å­¦ä¹ ï¼Œç»“åˆæ ‡æ³¨å’Œæœªæ ‡æ³¨æ•°æ®ï¼Œæå‡LLMå®‰å…¨æ€§å’Œå†…å®¹å®¡æ ¸èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œä»»åŠ¡ç‰¹å®šçš„æ•°æ®å¢å¼ºç­–ç•¥èƒ½æ˜¾è‘—æå‡åŠç›‘ç£å­¦ä¹ åœ¨å®‰å…¨åˆ†ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å®‰å…¨é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œåˆ©ç”¨åŠç›‘ç£å­¦ä¹ æŠ€æœ¯æ¥æå‡å®‰å…¨åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚ç”±äºè®­ç»ƒå®‰å…¨åˆ†ç±»å™¨éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®è·å–å›°éš¾ã€å®¹æ˜“å‡ºé”™ï¼Œä¸”å¸¸åŒ…å«åˆæˆæ•°æ®ï¼Œå› æ­¤æœ¬æ–‡åˆ©ç”¨åŠç›‘ç£å­¦ä¹ ï¼ŒåŒæ—¶åˆ©ç”¨æ ‡æ³¨æ•°æ®å’Œæœªæ ‡æ³¨æ•°æ®ã€‚ç ”ç©¶åˆ†æäº†è¯¥æŠ€æœ¯åœ¨LLMçš„æç¤ºå’Œå“åº”æ–¹é¢çš„æ”¹è¿›ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼ºè°ƒäº†ä»»åŠ¡ç‰¹å®šæ•°æ®å¢å¼ºçš„é‡è¦æ€§ï¼Œè¯æ˜å…¶ç›¸æ¯”é€šç”¨æ•°æ®å¢å¼ºæŠ€æœ¯èƒ½æ˜¾è‘—æé«˜æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç›®å‰ï¼Œè®­ç»ƒç”¨äºä¿éšœå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å®‰å…¨æ€§çš„åˆ†ç±»å™¨ï¼Œéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ã€‚ç„¶è€Œï¼Œè·å–é«˜è´¨é‡ã€å¤§è§„æ¨¡çš„æ ‡æ³¨æ•°æ®æˆæœ¬é«˜æ˜‚ï¼Œä¸”å®¹æ˜“å¼•å…¥æ ‡æ³¨é”™è¯¯ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•è¿˜å¸¸å¸¸ä¾èµ–åˆæˆæ•°æ®ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼ŒåŒæ—¶æœ‰æ•ˆåˆ©ç”¨æœªæ ‡æ³¨æ•°æ®ï¼Œæ˜¯å½“å‰LLMå®‰å…¨é¢†åŸŸé¢ä¸´çš„é‡è¦æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŠç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Œç»“åˆå·²æœ‰çš„å°‘é‡æ ‡æ³¨æ•°æ®å’Œå¤§é‡çš„æœªæ ‡æ³¨æ•°æ®ï¼Œæ¥è®­ç»ƒLLMå®‰å…¨åˆ†ç±»å™¨ã€‚åŠç›‘ç£å­¦ä¹ èƒ½å¤Ÿä»æ— æ ‡æ³¨æ•°æ®ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯ï¼Œä»è€Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œé™ä½å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®å‡†å¤‡ï¼šæ”¶é›†æ ‡æ³¨æ•°æ®å’Œæœªæ ‡æ³¨æ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚2) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©åˆé€‚çš„LLMä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå¹¶æ„å»ºå®‰å…¨åˆ†ç±»å™¨ã€‚3) åŠç›‘ç£å­¦ä¹ è®­ç»ƒï¼šé‡‡ç”¨åŠç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚ä¸€è‡´æ€§æ­£åˆ™åŒ–ã€ä¼ªæ ‡ç­¾ç­‰ï¼Œç»“åˆæ ‡æ³¨æ•°æ®å’Œæœªæ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒã€‚4) è¯„ä¼°ï¼šåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸åŸºçº¿æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼ºè°ƒäº†ä»»åŠ¡ç‰¹å®šæ•°æ®å¢å¼ºçš„é‡è¦æ€§ã€‚ä¸åŒäºé€šç”¨çš„æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œä»»åŠ¡ç‰¹å®šçš„æ•°æ®å¢å¼ºèƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™åŸå§‹æ•°æ®çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ç”Ÿæˆæ›´å…·ä»£è¡¨æ€§çš„å¢å¼ºæ ·æœ¬ï¼Œä»è€Œæå‡åŠç›‘ç£å­¦ä¹ çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŠç›‘ç£å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ä¸Šï¼Œå¯ä»¥é‡‡ç”¨ä¸€è‡´æ€§æ­£åˆ™åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚MixMatchã€ReMixMatchç­‰ã€‚è¿™äº›æ–¹æ³•é€šè¿‡å¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ‰°åŠ¨ï¼Œå¹¶è¦æ±‚æ¨¡å‹å¯¹æ‰°åŠ¨åçš„æ•°æ®è¾“å‡ºä¸€è‡´çš„é¢„æµ‹ç»“æœï¼Œä»è€Œæå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡æ ‡æ³¨æ•°æ®å’Œæœªæ ‡æ³¨æ•°æ®ä¹‹é—´çš„è´¡çŒ®ï¼Œå¹¶å¼•å…¥æ­£åˆ™åŒ–é¡¹ï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨åŠç›‘ç£å­¦ä¹ æ–¹æ³•å¯ä»¥æ˜¾è‘—æå‡LLMå®‰å…¨åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯ï¼Œä½¿ç”¨ä»»åŠ¡ç‰¹å®šçš„æ•°æ®å¢å¼ºç­–ç•¥åï¼Œæ¨¡å‹æ€§èƒ½å¾—åˆ°äº†è¿›ä¸€æ­¥æå‡ï¼Œç›¸æ¯”äºé€šç”¨æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ï¼‰éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä¿éšœLLMå®‰å…¨æ€§çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€å†…å®¹ç”Ÿæˆã€èŠå¤©æœºå™¨äººç­‰ã€‚é€šè¿‡é™ä½å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½LLMå®‰å…¨éƒ¨ç½²çš„æˆæœ¬ï¼Œå¹¶æé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ä¿ƒè¿›LLMåœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨ï¼Œä¾‹å¦‚æ•™è‚²ã€åŒ»ç–—ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Safety for Large Language Models (LLMs) has been an ongoing research focus since their emergence and is even more relevant nowadays with the increasing capacity of those models. Currently, there are several guardrails in place for all public LLMs and multiple proposed datasets for training safety classifiers. However, training these safety classifiers relies on large quantities of labeled data, which can be problematic to acquire, prone to labeling errors, or often include synthetic data. To address these issues, we suggest a different approach: utilizing semi-supervised learning techniques, which leverage both labeled and unlabeled data, to improve the performance on the safety task. We analyze the improvements that these techniques can offer for both prompts given to Large Language Models and the responses to those requests. Moreover, since augmentation is the central part of semi-supervised algorithms, we demonstrate the importance of using task-specific augmentations, which significantly increase the performance when compared to general-purpose augmentation techniques.

