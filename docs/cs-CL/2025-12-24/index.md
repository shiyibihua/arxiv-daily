---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-12-24
---

# cs.CLï¼ˆ2025-12-24ï¼‰

ğŸ“Š å…± **15** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251221107v1-semi-supervised-learning-for-large-language-models-safety-and-conten.html">Semi-Supervised Learning for Large Language Models Safety and Content Moderation</a></td>
  <td>æå‡ºåŠç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§å’Œå†…å®¹å®¡æ ¸èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21107v1" data-paper-url="./papers/251221107v1-semi-supervised-learning-for-large-language-models-safety-and-conten.html" onclick="toggleFavorite(this, '2512.21107v1', 'Semi-Supervised Learning for Large Language Models Safety and Content Moderation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251220949v1-neural-probe-based-hallucination-detection-for-large-language-models.html">Neural Probe-Based Hallucination Detection for Large Language Models</a></td>
  <td>æå‡ºåŸºäºç¥ç»æ¢é’ˆçš„å¤§è¯­è¨€æ¨¡å‹å¹»è§‰æ£€æµ‹æ¡†æ¶ï¼Œæå‡ä½è¯¯æŠ¥ç‡ä¸‹çš„æ£€æµ‹æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20949v1" data-paper-url="./papers/251220949v1-neural-probe-based-hallucination-detection-for-large-language-models.html" onclick="toggleFavorite(this, '2512.20949v1', 'Neural Probe-Based Hallucination Detection for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251221120v1-clarifymt-bench-benchmarking-and-improving-multi-turn-clarification-.html">ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models</a></td>
  <td>æå‡ºClarifyMT-Benchï¼Œç”¨äºè¯„ä¼°å’Œæå‡ä¼šè¯å¤§è¯­è¨€æ¨¡å‹çš„å¤šè½®æ¾„æ¸…èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21120v1" data-paper-url="./papers/251221120v1-clarifymt-bench-benchmarking-and-improving-multi-turn-clarification-.html" onclick="toggleFavorite(this, '2512.21120v1', 'ClarifyMT-Bench: Benchmarking and Improving Multi-Turn Clarification for Conversational Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251220948v1-foundation-model-based-evaluation-of-neuropsychiatric-disorders-a-li.html">Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study</a></td>
  <td>æå‡ºFENDæ¡†æ¶ï¼Œç”¨äºåŸºäºå¤šæ¨¡æ€èåˆå’Œé¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°ç¥ç»ç²¾ç¥ç–¾ç—…ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20948v1" data-paper-url="./papers/251220948v1-foundation-model-based-evaluation-of-neuropsychiatric-disorders-a-li.html" onclick="toggleFavorite(this, '2512.20948v1', 'Foundation Model-based Evaluation of Neuropsychiatric Disorders: A Lifespan-Inclusive, Multi-Modal, and Multi-Lingual Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251221017v1-rethinking-supervised-fine-tuning-emphasizing-key-answer-tokens-for-.html">Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy</a></td>
  <td>SFTKeyï¼šé€šè¿‡å¼ºåŒ–å…³é”®ç­”æ¡ˆtokenï¼Œæå‡LLMç›‘ç£å¾®è°ƒçš„å‡†ç¡®ç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21017v1" data-paper-url="./papers/251221017v1-rethinking-supervised-fine-tuning-emphasizing-key-answer-tokens-for-.html" onclick="toggleFavorite(this, '2512.21017v1', 'Rethinking Supervised Fine-Tuning: Emphasizing Key Answer Tokens for Improved LLM Accuracy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251220954v1-reflection-pretraining-enables-token-level-self-correction-in-biolog.html">Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models</a></td>
  <td>æå‡ºåå°„é¢„è®­ç»ƒï¼Œä½¿ç”Ÿç‰©åºåˆ—æ¨¡å‹å…·å¤‡tokençº§è‡ªçº é”™èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20954v1" data-paper-url="./papers/251220954v1-reflection-pretraining-enables-token-level-self-correction-in-biolog.html" onclick="toggleFavorite(this, '2512.20954v1', 'Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251221257v1-reaseq-unleashing-world-knowledge-via-reasoning-for-sequential-model.html">ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling</a></td>
  <td>ReaSeqï¼šé€šè¿‡æ¨ç†é‡Šæ”¾ä¸–ç•ŒçŸ¥è¯†ï¼Œç”¨äºåºåˆ—å»ºæ¨¡ï¼Œæå‡æ·˜å®æ¨èç³»ç»Ÿæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21257v1" data-paper-url="./papers/251221257v1-reaseq-unleashing-world-knowledge-via-reasoning-for-sequential-model.html" onclick="toggleFavorite(this, '2512.21257v1', 'ReaSeq: Unleashing World Knowledge via Reasoning for Sequential Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251220877v1-architectural-trade-offs-in-small-language-models-under-compute-cons.html">Architectural Trade-offs in Small Language Models Under Compute Constraints</a></td>
  <td>ç ”ç©¶è®¡ç®—çº¦æŸä¸‹å°å‹è¯­è¨€æ¨¡å‹çš„æ¶æ„æƒè¡¡ï¼Œæ­ç¤ºä¸åŒæ¶æ„é€‰æ‹©å¯¹æ€§èƒ½çš„å½±å“ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20877v1" data-paper-url="./papers/251220877v1-architectural-trade-offs-in-small-language-models-under-compute-cons.html" onclick="toggleFavorite(this, '2512.20877v1', 'Architectural Trade-offs in Small Language Models Under Compute Constraints')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251221332v1-c2llm-technical-report-a-new-frontier-in-code-retrieval-via-adaptive.html">C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling</a></td>
  <td>C2LLMï¼šé€šè¿‡è‡ªé€‚åº”è·¨æ³¨æ„åŠ›æ± åŒ–å®ç°ä»£ç æ£€ç´¢çš„æ–°çªç ´</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21332v1" data-paper-url="./papers/251221332v1-c2llm-technical-report-a-new-frontier-in-code-retrieval-via-adaptive.html" onclick="toggleFavorite(this, '2512.21332v1', 'C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>10</td>
  <td><a href="./papers/251221002v1-distilling-the-essence-efficient-reasoning-distillation-via-sequence.html">Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation</a></td>
  <td>æå‡ºåŸºäºåºåˆ—æˆªæ–­çš„é«˜æ•ˆæ¨ç†è’¸é¦æ–¹æ³•ï¼ŒåŠ é€ŸLLMçŸ¥è¯†è¿ç§»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21002v1" data-paper-url="./papers/251221002v1-distilling-the-essence-efficient-reasoning-distillation-via-sequence.html" onclick="toggleFavorite(this, '2512.21002v1', 'Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251220950v1-multimind-at-semeval-2025-task-7-crosslingual-fact-checked-claim-ret.html">MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment</a></td>
  <td>TriAlignerï¼šé€šè¿‡å¤šæºå¯¹é½å®ç°è·¨è¯­è¨€çš„äº‹å®éªŒè¯å£°æ˜æ£€ç´¢</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">contrastive learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20950v1" data-paper-url="./papers/251220950v1-multimind-at-semeval-2025-task-7-crosslingual-fact-checked-claim-ret.html" onclick="toggleFavorite(this, '2512.20950v1', 'MultiMind at SemEval-2025 Task 7: Crosslingual Fact-Checked Claim Retrieval via Multi-Source Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251220908v1-where-did-this-sentence-come-from-tracing-provenance-in-llm-reasonin.html">Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation</a></td>
  <td>æå‡ºè·¨æ¨¡å‹æ¨ç†è’¸é¦æº¯æºæ¡†æ¶ï¼Œåˆ†æå­¦ç”Ÿæ¨¡å‹èƒ½åŠ›æ¥æºå¹¶æŒ‡å¯¼æ•°æ®é€‰æ‹©ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">teacher-student</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20908v1" data-paper-url="./papers/251220908v1-where-did-this-sentence-come-from-tracing-provenance-in-llm-reasonin.html" onclick="toggleFavorite(this, '2512.20908v1', 'Where Did This Sentence Come From? Tracing Provenance in LLM Reasoning Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251221106v1-semantic-refinement-with-llms-for-graph-representations.html">Semantic Refinement with LLMs for Graph Representations</a></td>
  <td>æå‡ºDASæ¡†æ¶ï¼Œåˆ©ç”¨LLMè¿›è¡Œå›¾è¡¨ç¤ºçš„è¯­ä¹‰ç²¾ç‚¼ï¼Œè§£å†³å›¾ç»“æ„å¼‚æ„æ€§é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21106v1" data-paper-url="./papers/251221106v1-semantic-refinement-with-llms-for-graph-representations.html" onclick="toggleFavorite(this, '2512.21106v1', 'Semantic Refinement with LLMs for Graph Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/251220929v1-decoding-predictive-inference-in-visual-language-processing-via-spat.html">Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence</a></td>
  <td>æå‡ºåŸºäºæ—¶ç©ºç¥ç»ç›¸å¹²æ€§çš„è§†è§‰è¯­è¨€å¤„ç†é¢„æµ‹æ¨ç†è§£ç æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span> <span class="paper-tag">spatiotemporal</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20929v1" data-paper-url="./papers/251220929v1-decoding-predictive-inference-in-visual-language-processing-via-spat.html" onclick="toggleFavorite(this, '2512.20929v1', 'Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>15</td>
  <td><a href="./papers/251221336v1-optimizing-decoding-paths-in-masked-diffusion-models-by-quantifying-.html">Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty</a></td>
  <td>æå‡ºåŸºäºä¸ç¡®å®šæ€§é‡åŒ–çš„æ©ç æ‰©æ•£æ¨¡å‹è§£ç è·¯å¾„ä¼˜åŒ–æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">MDM</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.21336v1" data-paper-url="./papers/251221336v1-optimizing-decoding-paths-in-masked-diffusion-models-by-quantifying-.html" onclick="toggleFavorite(this, '2512.21336v1', 'Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)