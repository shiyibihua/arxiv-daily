---
layout: default
title: Do LLMs exhibit the same commonsense capabilities across languages?
---

# Do LLMs exhibit the same commonsense capabilities across languages?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06401" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06401v1</a>
  <a href="https://arxiv.org/pdf/2509.06401.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06401v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06401v1', 'Do LLMs exhibit the same commonsense capabilities across languages?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ivan MartÃ­nez-Murillo, Elena Lloret, Paloma Moreda, Albert Gatt

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/datasets/gplsi)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MULTICOMåŸºå‡†æµ‹è¯•æ­ç¤ºLLMåœ¨å¤šè¯­è¨€å¸¸è¯†ç”Ÿæˆèƒ½åŠ›ä¸Šçš„æ˜¾è‘—å·®è·**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€å¸¸è¯†ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•` `ä½èµ„æºè¯­è¨€` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å¤šè¯­è¨€å¸¸è¯†ç”Ÿæˆæ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä½èµ„æºè¯­è¨€ä¸Šè¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºMULTICOMåŸºå‡†ï¼Œæ‰©å±•COCOTEROSæ•°æ®é›†è‡³å››ç§è¯­è¨€ï¼Œç”¨äºè¯„ä¼°LLMçš„å¸¸è¯†ç”Ÿæˆèƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨è‹±è¯­ä¸Šçš„è¡¨ç°æ˜æ˜¾ä¼˜äºå…¶ä»–è¯­è¨€ï¼Œä¸Šä¸‹æ–‡æ”¯æŒå¯¹ä½èµ„æºè¯­è¨€æœ‰ä¸€å®šå¸®åŠ©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¤šè¯­è¨€å¸¸è¯†ç”Ÿæˆèƒ½åŠ›ã€‚ä¸ºäº†ä¾¿äºç ”ç©¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†MULTICOMï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„åŸºå‡†ï¼Œå®ƒå°†COCOTEROSæ•°æ®é›†æ‰©å±•åˆ°å››ç§è¯­è¨€ï¼šè‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€è·å…°è¯­å’Œç“¦ä¼¦è¥¿äºšè¯­ã€‚ä»»åŠ¡åŒ…æ‹¬ç”ŸæˆåŒ…å«ç»™å®šä¸‰ä¸ªå•è¯çš„å¸¸è¯†æ€§å¥å­ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸€ç³»åˆ—å¼€æºLLMï¼ŒåŒ…æ‹¬LLaMAã€Qwenã€Gemmaã€EuroLLMå’ŒSalamandraã€‚æˆ‘ä»¬çš„è¯„ä¼°ç»“åˆäº†è‡ªåŠ¨æŒ‡æ ‡ã€LLM-as-a-judgeæ–¹æ³•ï¼ˆä½¿ç”¨Prometheuså’ŒJudgeLMï¼‰ä»¥åŠäººå·¥æ ‡æ³¨ã€‚ç»“æœå§‹ç»ˆè¡¨æ˜è‹±è¯­çš„æ€§èƒ½ä¼˜è¶Šï¼Œè€Œèµ„æºè¾ƒå°‘çš„è¯­è¨€çš„æ€§èƒ½æ˜æ˜¾è¾ƒä½ã€‚è™½ç„¶ä¸Šä¸‹æ–‡æ”¯æŒäº§ç”Ÿçš„ç»“æœå¥½åå‚åŠï¼Œä½†å®ƒå¾€å¾€æœ‰åˆ©äºä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†LLMåœ¨å¤šè¯­è¨€å¸¸è¯†ç”Ÿæˆæ–¹é¢çš„å½“å‰å±€é™æ€§ã€‚è¯¥æ•°æ®é›†å¯åœ¨https://huggingface.co/datasets/gplsi/MULTICOMå…¬å¼€è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ä¸åŒè¯­è¨€ç¯å¢ƒä¸‹å¸¸è¯†ç”Ÿæˆèƒ½åŠ›ä¸å‡è¡¡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è‹±è¯­ç­‰é«˜èµ„æºè¯­è¨€ä¸Šï¼Œå¿½ç•¥äº†å…¶ä»–è¯­è¨€çš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´LLMåœ¨å¤„ç†å¤šè¯­è¨€ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªå¤šè¯­è¨€å¸¸è¯†ç”ŸæˆåŸºå‡†ï¼ˆMULTICOMï¼‰ï¼Œæ¥ç³»ç»Ÿåœ°è¯„ä¼°LLMåœ¨ä¸åŒè¯­è¨€ä¸Šçš„å¸¸è¯†æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ¯”LLMåœ¨ä¸åŒè¯­è¨€ä¸Šçš„è¡¨ç°ï¼Œæ­ç¤ºå…¶åœ¨å¤šè¯­è¨€å¸¸è¯†ç†è§£æ–¹é¢çš„å·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®é›†æ„å»ºå’Œæ¨¡å‹è¯„ä¼°ä¸¤ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é›†æ„å»ºé˜¶æ®µï¼Œä½œè€…å°†COCOTEROSæ•°æ®é›†æ‰©å±•åˆ°è‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€è·å…°è¯­å’Œç“¦ä¼¦è¥¿äºšè¯­å››ç§è¯­è¨€ã€‚æ¨¡å‹è¯„ä¼°é˜¶æ®µï¼Œä½œè€…ä½¿ç”¨è‡ªåŠ¨æŒ‡æ ‡ã€LLM-as-a-judgeæ–¹æ³•ï¼ˆPrometheuså’ŒJudgeLMï¼‰ä»¥åŠäººå·¥æ ‡æ³¨å¯¹LLMè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†MULTICOMå¤šè¯­è¨€å¸¸è¯†ç”ŸæˆåŸºå‡†ï¼Œè¯¥åŸºå‡†å¯ä»¥ç”¨äºè¯„ä¼°LLMåœ¨ä¸åŒè¯­è¨€ä¸Šçš„å¸¸è¯†æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é‡‡ç”¨äº†å¤šç§è¯„ä¼°æ–¹æ³•ï¼ŒåŒ…æ‹¬è‡ªåŠ¨æŒ‡æ ‡ã€LLM-as-a-judgeæ–¹æ³•å’Œäººå·¥æ ‡æ³¨ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°LLMçš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šMULTICOMæ•°æ®é›†åŸºäºCOCOTEROSï¼ŒåŒ…å«ç»™å®šä¸‰ä¸ªå•è¯ï¼Œè¦æ±‚ç”ŸæˆåŒ…å«è¿™ä¸‰ä¸ªå•è¯çš„å¸¸è¯†æ€§å¥å­ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬è‡ªåŠ¨æŒ‡æ ‡ï¼ˆBLEU, ROUGEç­‰ï¼‰ã€LLM-as-a-judgeæ–¹æ³•ï¼ˆPrometheus, JudgeLMï¼‰å’Œäººå·¥æ ‡æ³¨ã€‚å®éªŒä¸­ä½¿ç”¨äº†å¤šç§å¼€æºLLMï¼ŒåŒ…æ‹¬LLaMAã€Qwenã€Gemmaã€EuroLLMå’ŒSalamandraï¼Œå¹¶åˆ†æäº†ä¸Šä¸‹æ–‡ä¿¡æ¯å¯¹ç”Ÿæˆç»“æœçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨è‹±è¯­ä¸Šçš„å¸¸è¯†ç”Ÿæˆèƒ½åŠ›æ˜æ˜¾ä¼˜äºå…¶ä»–è¯­è¨€ï¼Œè¿™è¡¨æ˜LLMåœ¨å¤šè¯­è¨€å¸¸è¯†ç†è§£æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚ä¾‹å¦‚ï¼Œåœ¨MULTICOMåŸºå‡†æµ‹è¯•ä¸­ï¼ŒLLaMAåœ¨è‹±è¯­ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºè¥¿ç­ç‰™è¯­ã€è·å…°è¯­å’Œç“¦ä¼¦è¥¿äºšè¯­ã€‚ä¸Šä¸‹æ–‡æ”¯æŒå¯¹ä½èµ„æºè¯­è¨€çš„æ€§èƒ½æå‡æœ‰ä¸€å®šå¸®åŠ©ï¼Œä½†æ•ˆæœå¹¶ä¸ç¨³å®šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿçš„æ€§èƒ½ï¼Œä¾‹å¦‚æœºå™¨ç¿»è¯‘ã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢å’Œå¤šè¯­è¨€å¯¹è¯ç³»ç»Ÿã€‚é€šè¿‡äº†è§£LLMåœ¨ä¸åŒè¯­è¨€ä¸Šçš„å¸¸è¯†æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥é’ˆå¯¹æ€§åœ°æ”¹è¿›æ¨¡å‹ï¼Œä½¿å…¶æ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆä¸åŒè¯­è¨€çš„æ–‡æœ¬ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›ä½èµ„æºè¯­è¨€çš„è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper explores the multilingual commonsense generation abilities of Large Language Models (LLMs). To facilitate this investigation, we introduce MULTICOM, a novel benchmark that extends the COCOTEROS dataset to four languages: English, Spanish, Dutch, and Valencian. The task involves generating a commonsensical sentence that includes a given triplet of words. We evaluate a range of open-source LLMs, including LLaMA, Qwen, Gemma, EuroLLM, and Salamandra, on this benchmark. Our evaluation combines automatic metrics, LLM-as-a-judge approaches (using Prometheus and JudgeLM), and human annotations. Results consistently show superior performance in English, with significantly lower performance in less-resourced languages. While contextual support yields mixed results, it tends to benefit underrepresented languages. These findings underscore the current limitations of LLMs in multilingual commonsense generation. The dataset is publicly available at https://huggingface.co/datasets/gplsi/MULTICOM.

