---
layout: default
title: EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models
---

# EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06838" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06838v1</a>
  <a href="https://arxiv.org/pdf/2509.06838.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06838v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06838v1', 'EPT Benchmark: Evaluation of Persian Trustworthiness in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammad Reza Mirbagheri, Mohammad Mahdi Mirkamali, Zahra Motoshaker Arani, Ali Javeri, Amir Mahdi Sadeghzadeh, Rasool Jalili

**åˆ†ç±»**: cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Rezamirbagheri110/EPT-Benchmark)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEPTåŸºå‡†ï¼Œè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯ä¿¡åº¦è¯„ä¼°` `æ³¢æ–¯è¯­` `åŸºå‡†æµ‹è¯•` `æ–‡åŒ–é€‚åº”æ€§` `ä¼¦ç†å¯¹é½` `å®‰å…¨æ€§` `å…¬å¹³æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦è¯„ä¼°ç¼ºä¹æ ‡å‡†åŒ–çš„åŸºå‡†å’Œæ•°æ®é›†ï¼Œéš¾ä»¥å…¨é¢è¡¡é‡å…¶åœ¨æ–‡åŒ–å’Œä¼¦ç†æ–¹é¢çš„è¡¨ç°ã€‚
2. è®ºæ–‡æå‡ºEPTåŸºå‡†ï¼Œé€šè¿‡æ„å»ºåŒ…å«çœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ç­‰å…­ä¸ªç»´åº¦çš„è¯„ä¼°ä½“ç³»ï¼Œå…¨é¢è¯„ä¼°LLMåœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼ŒåŒæ—¶æ­ç¤ºäº†æ¨¡å‹ä¸æ³¢æ–¯æ–‡åŒ–ä¼¦ç†ä»·å€¼è§‚çš„å·®è·ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¹¿æ³›çš„è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œå·²æˆä¸ºç°ä»£äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åŸºçŸ³ã€‚ç„¶è€Œï¼Œç¡®ä¿å…¶å¯ä¿¡åº¦ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œå› ä¸ºå¯é æ€§å¯¹äºå‡†ç¡®çš„æ€§èƒ½ä»¥åŠç»´æŠ¤é“å¾·ã€æ–‡åŒ–å’Œç¤¾ä¼šä»·å€¼è§‚è‡³å…³é‡è¦ã€‚è®­ç»ƒæ•°æ®çš„ä»”ç»†å¯¹é½å’Œå…·æœ‰æ–‡åŒ–åŸºç¡€çš„è¯„ä¼°æ ‡å‡†å¯¹äºå¼€å‘è´Ÿè´£ä»»çš„AIç³»ç»Ÿè‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶å¼•å…¥äº†EPTï¼ˆæ³¢æ–¯è¯­å¯ä¿¡åº¦è¯„ä¼°ï¼‰æŒ‡æ ‡ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„ã€å…·æœ‰æ–‡åŒ–èƒŒæ™¯çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å…­ä¸ªå…³é”®æ–¹é¢çš„å¯ä¿¡åº¦ï¼šçœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€é²æ£’æ€§ã€éšç§å’Œä¼¦ç†ä¸€è‡´æ€§ã€‚æˆ‘ä»¬æ•´ç†äº†ä¸€ä¸ªå¸¦æ ‡ç­¾çš„æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨åŸºäºLLMçš„è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°æ¥è¯„ä¼°åŒ…æ‹¬ChatGPTã€Claudeã€DeepSeekã€Geminiã€Grokã€LLaMAã€Mistralå’ŒQwenåœ¨å†…çš„å¤šä¸ªé¢†å…ˆæ¨¡å‹çš„æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œå®‰å…¨ç»´åº¦å­˜åœ¨é‡å¤§ç¼ºé™·ï¼Œçªæ˜¾äº†è¿«åˆ‡éœ€è¦å…³æ³¨æ¨¡å‹è¡Œä¸ºçš„è¿™ä¸€å…³é”®æ–¹é¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœä¸ºè¿™äº›æ¨¡å‹ä¸æ³¢æ–¯ä¼¦ç†æ–‡åŒ–ä»·å€¼è§‚çš„å¯¹é½æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶å¼ºè°ƒäº†æ¨è¿›å¯ä¿¡å’Œæ–‡åŒ–è´Ÿè´£ä»»çš„AIçš„å…³é”®å·®è·å’Œæœºé‡ã€‚è¯¥æ•°æ®é›†å·²å…¬å¼€å‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹æ³¢æ–¯è¯­æ–‡åŒ–èƒŒæ™¯çš„ç»†ç²’åº¦è¯„ä¼°æ ‡å‡†ï¼Œéš¾ä»¥å…¨é¢è¡¡é‡æ¨¡å‹åœ¨çœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€éšç§ã€é²æ£’æ€§å’Œä¼¦ç†ä¸€è‡´æ€§ç­‰æ–¹é¢çš„è¡¨ç°ã€‚è¿™é™åˆ¶äº†LLMåœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯é åº”ç”¨ï¼Œå¹¶å¯èƒ½å¯¼è‡´ä¼¦ç†å’Œç¤¾ä¼šé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ³¢æ–¯è¯­æ–‡åŒ–èƒŒæ™¯çš„å¯ä¿¡åº¦è¯„ä¼°åŸºå‡†EPTã€‚è¯¥åŸºå‡†åŒ…å«å…­ä¸ªå…³é”®ç»´åº¦ï¼Œå¹¶æä¾›ç›¸åº”çš„è¯„ä¼°æ•°æ®é›†å’Œè¯„ä¼°æ–¹æ³•ï¼Œä»è€Œèƒ½å¤Ÿå…¨é¢ã€å®¢è§‚åœ°è¯„ä¼°LLMåœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦ã€‚é€šè¿‡å¯¹ç°æœ‰æ¨¡å‹çš„è¯„ä¼°ï¼Œå¯ä»¥è¯†åˆ«å…¶åœ¨å„ä¸ªç»´åº¦ä¸Šçš„ä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„æ¨¡å‹æ”¹è¿›æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEPTåŸºå‡†çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š1) å®šä¹‰å¯ä¿¡åº¦è¯„ä¼°çš„å…­ä¸ªå…³é”®ç»´åº¦ï¼šçœŸå®æ€§ã€å®‰å…¨æ€§ã€å…¬å¹³æ€§ã€é²æ£’æ€§ã€éšç§å’Œä¼¦ç†ä¸€è‡´æ€§ï¼›2) æ„å»ºä¸€ä¸ªå¸¦æ ‡ç­¾çš„æ³¢æ–¯è¯­æ•°æ®é›†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å„ä¸ªç»´åº¦ä¸Šçš„è¡¨ç°ï¼›3) è®¾è®¡åŸºäºLLMçš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•å’Œäººå·¥è¯„ä¼°æ–¹æ³•ï¼Œç”¨äºå¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼›4) å¯¹å¤šä¸ªé¢†å…ˆçš„LLMè¿›è¡Œè¯„ä¼°ï¼Œå¹¶åˆ†æå…¶åœ¨å„ä¸ªç»´åº¦ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ³¢æ–¯è¯­æ–‡åŒ–èƒŒæ™¯çš„å¯ä¿¡åº¦è¯„ä¼°åŸºå‡†EPTï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„ç©ºç™½ï¼›2) æ„å»ºäº†ä¸€ä¸ªåŒ…å«å…­ä¸ªå…³é”®ç»´åº¦çš„å…¨é¢è¯„ä¼°ä½“ç³»ï¼Œèƒ½å¤Ÿæ›´ç»†ç²’åº¦åœ°è¯„ä¼°LLMçš„å¯ä¿¡åº¦ï¼›3) ç»“åˆäº†è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°æ–¹æ³•ï¼Œæé«˜äº†è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šEPTåŸºå‡†çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ•°æ®é›†çš„æ„å»ºï¼šæ•°æ®é›†åŒ…å«é’ˆå¯¹å…­ä¸ªç»´åº¦çš„æ ‡æ³¨æ•°æ®ï¼Œæ¶µç›–äº†å„ç§åœºæ™¯å’Œä¸»é¢˜ï¼Œä»¥ä¿è¯è¯„ä¼°çš„å…¨é¢æ€§ï¼›2) è¯„ä¼°æŒ‡æ ‡çš„è®¾è®¡ï¼šé’ˆå¯¹æ¯ä¸ªç»´åº¦ï¼Œè®¾è®¡äº†ç›¸åº”çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡æ¨¡å‹çš„è¡¨ç°ï¼›3) è¯„ä¼°æ–¹æ³•çš„é€‰æ‹©ï¼šé‡‡ç”¨äº†åŸºäºLLMçš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•å’Œäººå·¥è¯„ä¼°æ–¹æ³•ï¼Œä»¥æé«˜è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å®‰å…¨æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚ä¾‹å¦‚ï¼ŒæŸäº›æ¨¡å‹å®¹æ˜“ç”Ÿæˆä¸å®‰å…¨æˆ–æœ‰å®³çš„å†…å®¹ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜æ­ç¤ºäº†æ¨¡å‹ä¸æ³¢æ–¯æ–‡åŒ–ä¼¦ç†ä»·å€¼è§‚çš„å·®è·ï¼Œè¡¨æ˜éœ€è¦åœ¨æ¨¡å‹è®­ç»ƒä¸­æ›´åŠ æ³¨é‡æ–‡åŒ–æ•æ„Ÿæ€§ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥æ”¹è¿›LLMåœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯ä¿¡åº¦æä¾›äº†é‡è¦çš„å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œä¿ƒè¿›è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½å‘å±•ã€‚å…¶æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ï¼šæ™ºèƒ½å®¢æœã€å†…å®¹å®¡æ ¸ã€æ•™è‚²è¾…åŠ©ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚é€šè¿‡ä½¿ç”¨EPTåŸºå‡†ï¼Œå¼€å‘è€…å¯ä»¥æ›´å¥½åœ°äº†è§£æ¨¡å‹åœ¨æ³¢æ–¯è¯­ç¯å¢ƒä¸‹çš„è¡¨ç°ï¼Œå¹¶é’ˆå¯¹æ€§åœ°è¿›è¡Œæ”¹è¿›ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å®ç”¨æ€§å’Œç¤¾ä¼šä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs), trained on extensive datasets using advanced deep learning architectures, have demonstrated remarkable performance across a wide range of language tasks, becoming a cornerstone of modern AI technologies. However, ensuring their trustworthiness remains a critical challenge, as reliability is essential not only for accurate performance but also for upholding ethical, cultural, and social values. Careful alignment of training data and culturally grounded evaluation criteria are vital for developing responsible AI systems. In this study, we introduce the EPT (Evaluation of Persian Trustworthiness) metric, a culturally informed benchmark specifically designed to assess the trustworthiness of LLMs across six key aspects: truthfulness, safety, fairness, robustness, privacy, and ethical alignment. We curated a labeled dataset and evaluated the performance of several leading models - including ChatGPT, Claude, DeepSeek, Gemini, Grok, LLaMA, Mistral, and Qwen - using both automated LLM-based and human assessments. Our results reveal significant deficiencies in the safety dimension, underscoring the urgent need for focused attention on this critical aspect of model behavior. Furthermore, our findings offer valuable insights into the alignment of these models with Persian ethical-cultural values and highlight critical gaps and opportunities for advancing trustworthy and culturally responsible AI. The dataset is publicly available at: https://github.com/Rezamirbagheri110/EPT-Benchmark.

