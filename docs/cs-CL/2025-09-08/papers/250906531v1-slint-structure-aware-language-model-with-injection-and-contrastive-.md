---
layout: default
title: SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion
---

# SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.06531" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.06531v1</a>
  <a href="https://arxiv.org/pdf/2509.06531.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.06531v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.06531v1', 'SLiNT: Structure-aware Language Model with Injection and Contrastive Training for Knowledge Graph Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mengxue Yang, Chun Yang, Jiaqi Zhu, Jiafan Li, Jingqi Zhang, Yuyang Li, Ying Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**å¤‡æ³¨**: Accepted by EMNLP Findings 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SLiNTï¼šé€šè¿‡æ³¨å…¥å’Œå¯¹æ¯”è®­ç»ƒçš„ç»“æ„æ„ŸçŸ¥è¯­è¨€æ¨¡å‹ï¼Œç”¨äºçŸ¥è¯†å›¾è°±è¡¥å…¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±è¡¥å…¨` `é“¾æ¥é¢„æµ‹` `ç»“æ„æ„ŸçŸ¥å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†å›¾è°±è¡¥å…¨æ–¹æ³•åœ¨åˆ©ç”¨ç»“æ„ä¿¡æ¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´ç»“æ„ç¨€ç–å’Œè¯­ä¹‰æ¨¡ç³Šï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ä¸å®Œæ•´æˆ–é›¶æ ·æœ¬åœºæ™¯ä¸‹ã€‚
2. SLiNTé€šè¿‡ç»“æ„å¼•å¯¼çš„é‚»åŸŸå¢å¼ºã€åŠ¨æ€ç¡¬å¯¹æ¯”å­¦ä¹ å’Œæ¢¯åº¦è§£è€¦åŒé‡æ³¨å…¥ï¼Œå°†ç»“æ„ä¿¡æ¯æ³¨å…¥åˆ°å†»ç»“çš„LLMä¸­ï¼Œæå‡é“¾æ¥é¢„æµ‹æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSLiNTåœ¨WN18RRå’ŒFB15k-237æ•°æ®é›†ä¸Šä¼˜äºæˆ–åª²ç¾ç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†å›¾è°±ä¸­çš„é“¾æ¥é¢„æµ‹éœ€è¦æ•´åˆç»“æ„ä¿¡æ¯å’Œè¯­ä¹‰ä¸Šä¸‹æ–‡ï¼Œä»¥æ¨æ–­ç¼ºå¤±çš„å®ä½“ã€‚å¤§å‹è¯­è¨€æ¨¡å‹è™½ç„¶å…·æœ‰å¼ºå¤§çš„ç”Ÿæˆæ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬å¯¹ç»“æ„ä¿¡å·çš„åˆ©ç”¨æœ‰é™ï¼Œå¸¸å¸¸å¯¼è‡´ç»“æ„ç¨€ç–å’Œè¯­ä¹‰æ¨¡ç³Šï¼Œå°¤å…¶æ˜¯åœ¨ä¸å®Œæ•´æˆ–é›¶æ ·æœ¬è®¾ç½®ä¸‹ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†SLiNTï¼ˆStructure-aware Language model with Injection and coNtrastive Trainingï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå®ƒå°†çŸ¥è¯†å›¾è°±å¯¼å‡ºçš„ç»“æ„ä¸Šä¸‹æ–‡æ³¨å…¥åˆ°å†»ç»“çš„LLMéª¨å¹²ä¸­ï¼Œå¹¶é€šè¿‡åŸºäºLoRAçš„è½»é‡çº§é€‚é…è¿›è¡Œé²æ£’çš„é“¾æ¥é¢„æµ‹ã€‚å…·ä½“æ¥è¯´ï¼Œç»“æ„å¼•å¯¼çš„é‚»åŸŸå¢å¼ºï¼ˆSGNEï¼‰æ£€ç´¢ä¼ªé‚»å±…ä»¥ä¸°å¯Œç¨€ç–å®ä½“å¹¶ç¼“è§£ç¼ºå¤±çš„ä¸Šä¸‹æ–‡ï¼›åŠ¨æ€ç¡¬å¯¹æ¯”å­¦ä¹ ï¼ˆDHCLï¼‰é€šè¿‡æ’å€¼ç¡¬æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬æ¥å¼•å…¥ç»†ç²’åº¦çš„ç›‘ç£ï¼Œä»¥è§£å†³å®ä½“çº§åˆ«çš„æ¨¡ç³Šæ€§ï¼›æ¢¯åº¦è§£è€¦åŒé‡æ³¨å…¥ï¼ˆGDDIï¼‰æ‰§è¡Œtokençº§åˆ«çš„ç»“æ„æ„ŸçŸ¥å¹²é¢„ï¼ŒåŒæ—¶ä¿ç•™æ ¸å¿ƒLLMå‚æ•°ã€‚åœ¨WN18RRå’ŒFB15k-237ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä¸åŸºäºåµŒå…¥å’ŒåŸºäºç”Ÿæˆçš„åŸºçº¿ç›¸æ¯”ï¼ŒSLiNTå®ç°äº†ä¼˜è¶Šæˆ–å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¯æ˜äº†ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ å¯¹äºå¯æ‰©å±•çŸ¥è¯†å›¾è°±è¡¥å…¨çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŸ¥è¯†å›¾è°±è¡¥å…¨ä»»åŠ¡æ—¨åœ¨é¢„æµ‹çŸ¥è¯†å›¾è°±ä¸­ç¼ºå¤±çš„å®ä½“æˆ–å…³ç³»ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œè™½ç„¶å…·å¤‡å¼ºå¤§çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œä½†åœ¨åˆ©ç”¨çŸ¥è¯†å›¾è°±çš„ç»“æ„ä¿¡æ¯æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤„ç†ç»“æ„ç¨€ç–æˆ–é›¶æ ·æœ¬åœºæ™¯æ—¶è¡¨ç°ä¸ä½³ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåŒºåˆ†è¯­ä¹‰ç›¸ä¼¼ä½†ç»“æ„ä¸åŒçš„å®ä½“ï¼Œé€ æˆè¯­ä¹‰æ¨¡ç³Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSLiNTçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†çŸ¥è¯†å›¾è°±çš„ç»“æ„ä¿¡æ¯æœ‰æ•ˆåœ°æ³¨å…¥åˆ°é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸­ï¼Œä»è€Œå¢å¼ºæ¨¡å‹å¯¹ç»“æ„ä¿¡æ¯çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œç¼“è§£ç»“æ„ç¨€ç–å’Œè¯­ä¹‰æ¨¡ç³Šé—®é¢˜ã€‚é€šè¿‡ç»“æ„ä¿¡æ¯å¢å¼ºï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å®ä½“ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œæé«˜é“¾æ¥é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ï¼Œè¿›ä¸€æ­¥åŒºåˆ†ç›¸ä¼¼å®ä½“ï¼Œæå‡æ¨¡å‹çš„åˆ¤åˆ«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSLiNTæ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œä¸»è¦åŒ…å«ä¸‰ä¸ªæ¨¡å—ï¼šç»“æ„å¼•å¯¼çš„é‚»åŸŸå¢å¼ºï¼ˆSGNEï¼‰ã€åŠ¨æ€ç¡¬å¯¹æ¯”å­¦ä¹ ï¼ˆDHCLï¼‰å’Œæ¢¯åº¦è§£è€¦åŒé‡æ³¨å…¥ï¼ˆGDDIï¼‰ã€‚é¦–å…ˆï¼ŒSGNEé€šè¿‡æ£€ç´¢ä¼ªé‚»å±…æ¥ä¸°å¯Œç¨€ç–å®ä½“çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ç„¶åï¼ŒDHCLé€šè¿‡å¼•å…¥ç¡¬æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬è¿›è¡Œå¯¹æ¯”å­¦ä¹ ï¼Œè§£å†³å®ä½“çº§åˆ«çš„æ¨¡ç³Šæ€§ã€‚æœ€åï¼ŒGDDIåœ¨tokençº§åˆ«è¿›è¡Œç»“æ„æ„ŸçŸ¥å¹²é¢„ï¼ŒåŒæ—¶å†»ç»“LLMçš„å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªå¯¹å°‘é‡å‚æ•°è¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šSLiNTçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»“æ„æ„ŸçŸ¥æ³¨å…¥å’Œå¯¹æ¯”è®­ç»ƒæœºåˆ¶ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒSLiNTä¸æ˜¯ç®€å•åœ°å°†ç»“æ„ä¿¡æ¯ä½œä¸ºé¢å¤–çš„è¾“å…¥ï¼Œè€Œæ˜¯é€šè¿‡SGNEã€DHCLå’ŒGDDIä¸‰ä¸ªæ¨¡å—ï¼Œå°†ç»“æ„ä¿¡æ¯æ·±åº¦èåˆåˆ°è¯­è¨€æ¨¡å‹çš„è¡¨ç¤ºå­¦ä¹ è¿‡ç¨‹ä¸­ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨ç»“æ„ä¿¡æ¯ï¼Œæé«˜æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ã€‚æ¢¯åº¦è§£è€¦åŒé‡æ³¨å…¥ï¼ˆGDDIï¼‰çš„è®¾è®¡ä¿è¯äº†åœ¨æ³¨å…¥ç»“æ„ä¿¡æ¯çš„åŒæ—¶ï¼Œä¸ä¼šç ´åé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„åŸæœ‰çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šSGNEæ¨¡å—ä½¿ç”¨åŸºäºåµŒå…¥ç›¸ä¼¼åº¦çš„é‚»å±…æ£€ç´¢æ–¹æ³•ï¼Œé€‰æ‹©ä¸ç›®æ ‡å®ä½“æœ€ç›¸å…³çš„ä¼ªé‚»å±…ã€‚DHCLæ¨¡å—é€šè¿‡æ’å€¼ç”Ÿæˆç¡¬æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼Œå¹¶ä½¿ç”¨InfoNCEæŸå¤±å‡½æ•°è¿›è¡Œå¯¹æ¯”å­¦ä¹ ã€‚GDDIæ¨¡å—ä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼Œå¹¶è®¾è®¡äº†æ¢¯åº¦è§£è€¦æœºåˆ¶ï¼Œé˜²æ­¢ç»“æ„ä¿¡æ¯æ›´æ–°å½±å“LLMçš„å›ºæœ‰çŸ¥è¯†ã€‚å…·ä½“æŸå¤±å‡½æ•°çš„è®¾è®¡å’Œè¶…å‚æ•°çš„é€‰æ‹©éœ€è¦æ ¹æ®å®é™…æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SLiNTåœ¨WN18RRå’ŒFB15k-237æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜SLiNTå–å¾—äº†ä¼˜è¶Šæˆ–å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨WN18RRæ•°æ®é›†ä¸Šï¼ŒSLiNTçš„MRRæŒ‡æ ‡è¶…è¿‡äº†ç°æœ‰æœ€ä½³åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶ç»“æ„æ„ŸçŸ¥è¡¨ç¤ºå­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¿˜è¡¨æ˜ï¼ŒSLiNTåœ¨å¤„ç†ç»“æ„ç¨€ç–å’Œé›¶æ ·æœ¬åœºæ™¯æ—¶è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SLiNTåœ¨çŸ¥è¯†å›¾è°±è¡¥å…¨æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½é—®ç­”ã€æ¨èç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡è¡¥å…¨çŸ¥è¯†å›¾è°±ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢å’Œæ¨ç†ä»»åŠ¡æ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼ŒSLiNTçš„ç»“æ„æ„ŸçŸ¥å­¦ä¹ æ–¹æ³•ä¹Ÿå¯ä»¥åº”ç”¨äºå…¶ä»–å›¾ç»“æ„æ•°æ®ï¼Œä¾‹å¦‚ç¤¾äº¤ç½‘ç»œåˆ†æã€ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰é¢†åŸŸï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Link prediction in knowledge graphs requires integrating structural information and semantic context to infer missing entities. While large language models offer strong generative reasoning capabilities, their limited exploitation of structural signals often results in structural sparsity and semantic ambiguity, especially under incomplete or zero-shot settings. To address these challenges, we propose SLiNT (Structure-aware Language model with Injection and coNtrastive Training), a modular framework that injects knowledge-graph-derived structural context into a frozen LLM backbone with lightweight LoRA-based adaptation for robust link prediction. Specifically, Structure-Guided Neighborhood Enhancement (SGNE) retrieves pseudo-neighbors to enrich sparse entities and mitigate missing context; Dynamic Hard Contrastive Learning (DHCL) introduces fine-grained supervision by interpolating hard positives and negatives to resolve entity-level ambiguity; and Gradient-Decoupled Dual Injection (GDDI) performs token-level structure-aware intervention while preserving the core LLM parameters. Experiments on WN18RR and FB15k-237 show that SLiNT achieves superior or competitive performance compared with both embedding-based and generation-based baselines, demonstrating the effectiveness of structure-aware representation learning for scalable knowledge graph completion.

