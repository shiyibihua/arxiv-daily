---
layout: default
title: Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models
---

# Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07142" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07142v1</a>
  <a href="https://arxiv.org/pdf/2509.07142.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07142v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07142v1', 'Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiyin Tan, Jennifer D'Souza

**åˆ†ç±»**: cs.CL, cs.AI, cs.DL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**å¤‡æ³¨**: Accepted for publication in International Journal on Digital Libraries (IJDL)

**æœŸåˆŠ**: International Journal on Digital Libraries, vol. 26, no. 4, pp. 23, December 2025

**DOI**: [10.1007/s00799-025-00429-5](https://doi.org/10.1007/s00799-025-00429-5)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zhiyintan/topic-model-LLMjudgment)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é¢å‘ç›®çš„çš„åŠ¨æ€ä¸»é¢˜æ¨¡å‹è‡ªåŠ¨è¯„ä¼°æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸»é¢˜æ¨¡å‹` `å¤§è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨è¯„ä¼°` `è¯­ä¹‰ç†è§£` `ä¿¡æ¯æ£€ç´¢` `çŸ¥è¯†å‘ç°` `åŠ¨æ€ä¸»é¢˜æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸»é¢˜æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ï¼‰æ— æ³•å……åˆ†æ•æ‰è¯­ä¹‰å±‚é¢çš„é—®é¢˜ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å®é™…æ•ˆæœè„±èŠ‚ã€‚
2. è¯¥è®ºæ–‡æå‡ºåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ„å»ºé¢å‘ç›®çš„çš„è¯„ä¼°æ¡†æ¶ï¼Œä»è¯æ±‡ã€è¯­ä¹‰ã€ç»“æ„å’Œå¯¹é½å››ä¸ªç»´åº¦è¯„ä¼°ä¸»é¢˜æ¨¡å‹çš„è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«ä¸»é¢˜æ¨¡å‹ä¸­çš„å†—ä½™å’Œè¯­ä¹‰æ¼‚ç§»ç­‰é—®é¢˜ï¼Œæä¾›æ›´å¯é çš„è¯„ä¼°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªåŠ¨è¯„ä¼°åŠ¨æ€æ¼”åŒ–ä¸»é¢˜æ¨¡å‹çš„æ¡†æ¶ã€‚ä¸»é¢˜å»ºæ¨¡å¯¹äºç»„ç»‡å’Œæ£€ç´¢æ•°å­—å›¾ä¹¦é¦†ç³»ç»Ÿä¸­çš„å­¦æœ¯å†…å®¹è‡³å…³é‡è¦ï¼Œå®ƒå¸®åŠ©ç”¨æˆ·æµè§ˆå¤æ‚ä¸”ä¸æ–­å‘å±•çš„çŸ¥è¯†é¢†åŸŸã€‚ç„¶è€Œï¼Œå¹¿æ³›ä½¿ç”¨çš„è‡ªåŠ¨æŒ‡æ ‡ï¼Œå¦‚ä¸€è‡´æ€§å’Œå¤šæ ·æ€§ï¼Œé€šå¸¸åªæ•æ‰åˆ°ç‹­çª„çš„ç»Ÿè®¡æ¨¡å¼ï¼Œæ— æ³•è§£é‡Šå®è·µä¸­çš„è¯­ä¹‰å¤±è´¥ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªé¢å‘ç›®çš„çš„è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ä¹ä¸ªåŸºäºLLMçš„æŒ‡æ ‡ï¼Œæ¶µç›–ä¸»é¢˜è´¨é‡çš„å››ä¸ªå…³é”®ç»´åº¦ï¼šè¯æ±‡æœ‰æ•ˆæ€§ã€ä¸»é¢˜å†…è¯­ä¹‰åˆç†æ€§ã€ä¸»é¢˜é—´ç»“æ„åˆç†æ€§å’Œæ–‡æ¡£-ä¸»é¢˜å¯¹é½åˆç†æ€§ã€‚è¯¥æ¡†æ¶é€šè¿‡å¯¹æŠ—æ€§å’ŒåŸºäºé‡‡æ ·çš„åè®®è¿›è¡ŒéªŒè¯ï¼Œå¹¶åº”ç”¨äºæ¶µç›–æ–°é—»æ–‡ç« ã€å­¦æœ¯å‡ºç‰ˆç‰©å’Œç¤¾äº¤åª’ä½“å¸–å­çš„æ•°æ®é›†ï¼Œä»¥åŠå¤šç§ä¸»é¢˜å»ºæ¨¡æ–¹æ³•å’Œå¼€æºLLMã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼ŒåŸºäºLLMçš„æŒ‡æ ‡æä¾›äº†å¯è§£é‡Šã€ç¨³å¥ä¸”ä¸ä»»åŠ¡ç›¸å…³çš„è¯„ä¼°ï¼Œæ­ç¤ºäº†ä¸»é¢˜æ¨¡å‹çš„å…³é”®å¼±ç‚¹ï¼Œå¦‚å†—ä½™å’Œè¯­ä¹‰æ¼‚ç§»ï¼Œè€Œè¿™äº›å¼±ç‚¹é€šå¸¸è¢«ä¼ ç»ŸæŒ‡æ ‡æ‰€å¿½ç•¥ã€‚è¿™äº›ç»“æœæ”¯æŒå¼€å‘å¯æ‰©å±•çš„ã€ç»†ç²’åº¦çš„è¯„ä¼°å·¥å…·ï¼Œä»¥åœ¨åŠ¨æ€æ•°æ®é›†ä¸­ä¿æŒä¸»é¢˜ç›¸å…³æ€§ã€‚æ‰€æœ‰æ”¯æŒè¿™é¡¹å·¥ä½œçš„ä»£ç å’Œæ•°æ®éƒ½å¯ä»¥åœ¨https://github.com/zhiyintan/topic-model-LLMjudgmentä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ä¸»é¢˜æ¨¡å‹è¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–äºç»Ÿè®¡æŒ‡æ ‡ï¼Œä¾‹å¦‚ä¸»é¢˜ä¸€è‡´æ€§å’Œä¸»é¢˜å¤šæ ·æ€§ã€‚è¿™äº›æŒ‡æ ‡æ— æ³•æœ‰æ•ˆæ•æ‰ä¸»é¢˜çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å®é™…åº”ç”¨æ•ˆæœä¸ç¬¦ã€‚å°¤å…¶æ˜¯åœ¨åŠ¨æ€æ•°æ®é›†ä¸Šï¼Œä¸»é¢˜éšç€æ—¶é—´æ¼”åŒ–ï¼Œä¼ ç»Ÿè¯„ä¼°æ–¹æ³•éš¾ä»¥è·Ÿè¸ªä¸»é¢˜çš„è¯­ä¹‰æ¼‚ç§»å’Œå†—ä½™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œæ¨¡æ‹Ÿäººç±»ä¸“å®¶å¯¹ä¸»é¢˜æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚é€šè¿‡è®¾è®¡ä¸€ç³»åˆ—åŸºäºLLMçš„æŒ‡æ ‡ï¼Œä»å¤šä¸ªç»´åº¦è¡¡é‡ä¸»é¢˜æ¨¡å‹çš„è´¨é‡ï¼Œä»è€Œæ›´å‡†ç¡®åœ°åæ˜ ä¸»é¢˜æ¨¡å‹çš„å®é™…æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«å››ä¸ªä¸»è¦æ¨¡å—ï¼š1) **è¯æ±‡æœ‰æ•ˆæ€§è¯„ä¼°**ï¼šè¯„ä¼°ä¸»é¢˜è¯æ±‡çš„åˆç†æ€§ï¼›2) **ä¸»é¢˜å†…è¯­ä¹‰åˆç†æ€§è¯„ä¼°**ï¼šè¯„ä¼°ä¸»é¢˜å†…éƒ¨è¯­ä¹‰çš„ä¸€è‡´æ€§ï¼›3) **ä¸»é¢˜é—´ç»“æ„åˆç†æ€§è¯„ä¼°**ï¼šè¯„ä¼°ä¸»é¢˜ä¹‹é—´çš„ç»“æ„å…³ç³»æ˜¯å¦åˆç†ï¼›4) **æ–‡æ¡£-ä¸»é¢˜å¯¹é½åˆç†æ€§è¯„ä¼°**ï¼šè¯„ä¼°æ–‡æ¡£ä¸ä¸»é¢˜çš„å¯¹é½ç¨‹åº¦ã€‚æ¯ä¸ªæ¨¡å—éƒ½åŒ…å«è‹¥å¹²åŸºäºLLMçš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼Œåˆ©ç”¨LLMç”Ÿæˆä¸»é¢˜æè¿°ï¼Œå¹¶è¯„ä¼°å…¶ä¸ä¸»é¢˜è¯æ±‡çš„ç›¸å…³æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤§è¯­è¨€æ¨¡å‹å¼•å…¥åˆ°ä¸»é¢˜æ¨¡å‹è¯„ä¼°ä¸­ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ä»…ä¾èµ–ç»Ÿè®¡ä¿¡æ¯çš„å±€é™æ€§ã€‚é€šè¿‡åˆ©ç”¨LLMçš„è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å…¨é¢ã€æ›´å‡†ç¡®åœ°è¯„ä¼°ä¸»é¢˜æ¨¡å‹çš„è´¨é‡ï¼Œä»è€Œæ›´å¥½åœ°æŒ‡å¯¼ä¸»é¢˜æ¨¡å‹çš„é€‰æ‹©å’Œä¼˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ¡†æ¶è®¾è®¡äº†ä¹ä¸ªåŸºäºLLMçš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ¶µç›–äº†ä¸»é¢˜è´¨é‡çš„å››ä¸ªå…³é”®ç»´åº¦ã€‚å…·ä½“å®ç°ä¸Šï¼Œä½¿ç”¨äº†å¤šä¸ªå¼€æºLLMï¼Œä¾‹å¦‚BERTå’ŒGPTç³»åˆ—æ¨¡å‹ã€‚åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œé€šè¿‡prompt engineeringæ¥å¼•å¯¼LLMç”Ÿæˆé«˜è´¨é‡çš„è¯„ä¼°ç»“æœã€‚æ­¤å¤–ï¼Œè¿˜è®¾è®¡äº†å¯¹æŠ—æ€§å®éªŒå’ŒåŸºäºé‡‡æ ·çš„å®éªŒï¼Œä»¥éªŒè¯è¯„ä¼°æ¡†æ¶çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯†åˆ«ä¸»é¢˜æ¨¡å‹ä¸­çš„å†—ä½™å’Œè¯­ä¹‰æ¼‚ç§»ç­‰é—®é¢˜ï¼Œè€Œä¼ ç»ŸæŒ‡æ ‡å¾€å¾€æ— æ³•æ•æ‰åˆ°è¿™äº›é—®é¢˜ã€‚é€šè¿‡å¯¹æŠ—æ€§å®éªŒå’ŒåŸºäºé‡‡æ ·çš„å®éªŒï¼ŒéªŒè¯äº†è¯¥è¯„ä¼°æ¡†æ¶çš„é²æ£’æ€§å’Œå¯é æ€§ã€‚åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼ŒåŒ…æ‹¬æ–°é—»æ–‡ç« ã€å­¦æœ¯å‡ºç‰ˆç‰©å’Œç¤¾äº¤åª’ä½“å¸–å­ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶çš„é€šç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ•°å­—å›¾ä¹¦é¦†ã€ä¿¡æ¯æ£€ç´¢ã€æ¨èç³»ç»Ÿç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·æ›´æœ‰æ•ˆåœ°ç»„ç»‡å’Œæ£€ç´¢ä¿¡æ¯ã€‚é€šè¿‡è‡ªåŠ¨è¯„ä¼°ä¸»é¢˜æ¨¡å‹çš„è´¨é‡ï¼Œå¯ä»¥æé«˜ä¿¡æ¯æ£€ç´¢çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´ä¸ªæ€§åŒ–çš„æ¨èæœåŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºç›‘æ§åŠ¨æ€æ•°æ®é›†ä¸­çš„ä¸»é¢˜æ¼”åŒ–ï¼ŒåŠæ—¶å‘ç°å’Œè§£å†³è¯­ä¹‰æ¼‚ç§»ç­‰é—®é¢˜ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study presents a framework for automated evaluation of dynamically evolving topic models using Large Language Models (LLMs). Topic modeling is essential for organizing and retrieving scholarly content in digital library systems, helping users navigate complex and evolving knowledge domains. However, widely used automated metrics, such as coherence and diversity, often capture only narrow statistical patterns and fail to explain semantic failures in practice. We introduce a purpose-oriented evaluation framework that employs nine LLM-based metrics spanning four key dimensions of topic quality: lexical validity, intra-topic semantic soundness, inter-topic structural soundness, and document-topic alignment soundness. The framework is validated through adversarial and sampling-based protocols, and is applied across datasets spanning news articles, scholarly publications, and social media posts, as well as multiple topic modeling methods and open-source LLMs. Our analysis shows that LLM-based metrics provide interpretable, robust, and task-relevant assessments, uncovering critical weaknesses in topic models such as redundancy and semantic drift, which are often missed by traditional metrics. These results support the development of scalable, fine-grained evaluation tools for maintaining topic relevance in dynamic datasets. All code and data supporting this work are accessible at https://github.com/zhiyintan/topic-model-LLMjudgment.

