---
layout: default
title: MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations
---

# MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07135" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07135v1</a>
  <a href="https://arxiv.org/pdf/2509.07135.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07135v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07135v1', 'MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruggero Marino Lazzaroni, Alessandro Angioi, Michelangelo Puliga, Davide Sanna, Roberto Marras

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-08

**å¤‡æ³¨**: Accepted as an oral presentation at CLiC-it 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MedBench-ITï¼šé¦–ä¸ªæ„å¤§åˆ©åŒ»å­¦å…¥å­¦è€ƒè¯•LLMç»¼åˆè¯„æµ‹åŸºå‡†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒ»å­¦å…¥å­¦è€ƒè¯•` `æ„å¤§åˆ©è¯­` `è¯„ä¼°åŸºå‡†` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é’ˆå¯¹éè‹±è¯­ã€ç‰¹å®šé¢†åŸŸçš„LLMè¯„ä¼°åŸºå‡†åŒ®ä¹ï¼Œé™åˆ¶äº†LLMåœ¨è¿™äº›é¢†åŸŸçš„åº”ç”¨å’Œå‘å±•ã€‚
2. MedBench-ITæ„å»ºäº†ä¸€ä¸ªåŒ…å«17410é“æ„å¤§åˆ©åŒ»å­¦å…¥å­¦è€ƒè¯•é¢˜ç›®çš„ç»¼åˆåŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨è¯¥é¢†åŸŸçš„æ€§èƒ½ã€‚
3. å®éªŒè¯„ä¼°äº†å¤šç§LLMï¼Œå¹¶åˆ†æäº†å¯é‡å¤æ€§ã€æ’åºåå·®å’Œé—®é¢˜å¯è¯»æ€§ç­‰å› ç´ ï¼Œä¸ºåç»­ç ”ç©¶æä¾›å‚è€ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•™è‚²é¢†åŸŸå±•ç°å‡ºæ—¥ç›Šå¢é•¿çš„æ½œåŠ›ï¼Œä½†é’ˆå¯¹ç‰¹å®šé¢†åŸŸéè‹±è¯­è¯­è¨€çš„åŸºå‡†ä»ç„¶ç¨€ç¼ºã€‚æˆ‘ä»¬æ¨å‡ºäº†MedBench-ITï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè¯„ä¼°LLMsåœ¨æ„å¤§åˆ©åŒ»å­¦å¤§å­¦å…¥å­¦è€ƒè¯•è¡¨ç°çš„ç»¼åˆåŸºå‡†ã€‚MedBench-ITçš„æ•°æ®æ¥æºäºé¢†å…ˆçš„å¤‡è€ƒææ–™å‡ºç‰ˆå•†Edizioni Simoneï¼ŒåŒ…å«17410é“ç”±ä¸“å®¶ç¼–å†™çš„é€‰æ‹©é¢˜ï¼Œæ¶µç›–å…­ä¸ªç§‘ç›®ï¼ˆç”Ÿç‰©ã€åŒ–å­¦ã€é€»è¾‘ã€æ™®é€šæ–‡åŒ–ã€æ•°å­¦ã€ç‰©ç†ï¼‰å’Œä¸‰ä¸ªéš¾åº¦çº§åˆ«ã€‚æˆ‘ä»¬è¯„ä¼°äº†åŒ…æ‹¬ä¸“æœ‰LLMsï¼ˆGPT-4oã€Claudeç³»åˆ—ï¼‰å’Œèµ„æºé«˜æ•ˆçš„å¼€æºæ›¿ä»£æ–¹æ¡ˆï¼ˆ<30Bå‚æ•°ï¼‰åœ¨å†…çš„å„ç§æ¨¡å‹ï¼Œé‡ç‚¹å…³æ³¨å®é™…éƒ¨ç½²èƒ½åŠ›ã€‚é™¤äº†å‡†ç¡®æ€§ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†ä¸¥æ ¼çš„å¯é‡å¤æ€§æµ‹è¯•ï¼ˆ88.86%çš„å“åº”ä¸€è‡´æ€§ï¼Œå› ç§‘ç›®è€Œå¼‚ï¼‰ï¼Œæ’åºåå·®åˆ†æï¼ˆå½±å“æå°ï¼‰å’Œæ¨ç†æç¤ºè¯„ä¼°ã€‚æˆ‘ä»¬è¿˜æ£€æŸ¥äº†é—®é¢˜å¯è¯»æ€§ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå‘ç°äº†ä¸€ç§ç»Ÿè®¡ä¸Šæ˜¾è‘—ä½†è¾ƒå°çš„è´Ÿç›¸å…³å…³ç³»ã€‚MedBench-ITä¸ºæ„å¤§åˆ©NLPç¤¾åŒºã€EdTechå¼€å‘è€…å’Œä»ä¸šè€…æä¾›äº†ä¸€ä¸ªå…³é”®èµ„æºï¼Œä¸ºè¿™ä¸€å…³é”®é¢†åŸŸæä¾›äº†å¯¹å½“å‰èƒ½åŠ›å’Œæ ‡å‡†åŒ–è¯„ä¼°æ–¹æ³•çš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¼ºä¹é’ˆå¯¹æ„å¤§åˆ©è¯­åŒ»å­¦å…¥å­¦è€ƒè¯•çš„LLMè¯„ä¼°åŸºå‡†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆæ˜¯é€šç”¨åŸºå‡†æ— æ³•å‡†ç¡®åæ˜ ç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ï¼Œè¦ä¹ˆæ˜¯ç¼ºä¹æ„å¤§åˆ©è¯­çš„ä¸“ä¸šæ•°æ®é›†ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆè¯„ä¼°LLMåœ¨æ„å¤§åˆ©åŒ»å­¦é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªé«˜è´¨é‡ã€å¤§è§„æ¨¡çš„æ„å¤§åˆ©è¯­åŒ»å­¦å…¥å­¦è€ƒè¯•é¢˜åº“ï¼Œå¹¶åŸºäºæ­¤é¢˜åº“è®¾è®¡ä¸€å¥—å…¨é¢çš„è¯„ä¼°æµç¨‹ï¼Œä»è€Œä¸ºLLMåœ¨è¯¥é¢†åŸŸçš„æ€§èƒ½æä¾›å®¢è§‚ã€å¯é çš„è¯„ä¼°ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒç§‘ç›®ã€ä¸åŒéš¾åº¦çº§åˆ«ä¸Šçš„è¡¨ç°ï¼Œä»¥åŠè€ƒå¯Ÿæ¨¡å‹çš„å¯é‡å¤æ€§ã€æ’åºåå·®ç­‰å› ç´ ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°äº†è§£LLMçš„ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMedBench-ITçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) æ•°æ®æ”¶é›†ï¼šä»Edizioni Simoneè·å–æ„å¤§åˆ©åŒ»å­¦å…¥å­¦è€ƒè¯•é¢˜ç›®ï¼Œæ¶µç›–å…­ä¸ªç§‘ç›®å’Œä¸‰ä¸ªéš¾åº¦çº§åˆ«ã€‚2) æ•°æ®æ¸…æ´—å’Œæ•´ç†ï¼šå¯¹åŸå§‹æ•°æ®è¿›è¡Œæ¸…æ´—ã€å»é‡ã€æ ¼å¼åŒ–ç­‰å¤„ç†ï¼Œç¡®ä¿æ•°æ®çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚3) æ¨¡å‹è¯„ä¼°ï¼šé€‰æ‹©å¤šç§LLMè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ä¸“æœ‰æ¨¡å‹å’Œå¼€æºæ¨¡å‹ã€‚4) æ€§èƒ½åˆ†æï¼šåˆ†ææ¨¡å‹åœ¨ä¸åŒç§‘ç›®ã€ä¸åŒéš¾åº¦çº§åˆ«ä¸Šçš„å‡†ç¡®ç‡ï¼Œå¹¶è¿›è¡Œç»Ÿè®¡åˆ†æã€‚5) å¯é æ€§åˆ†æï¼šè¯„ä¼°æ¨¡å‹çš„å¯é‡å¤æ€§ã€æ’åºåå·®ç­‰å› ç´ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†é¦–ä¸ªé’ˆå¯¹æ„å¤§åˆ©è¯­åŒ»å­¦å…¥å­¦è€ƒè¯•çš„LLMè¯„ä¼°åŸºå‡†MedBench-ITã€‚è¯¥åŸºå‡†ä¸ä»…æä¾›äº†å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„é¢˜åº“ï¼Œè¿˜è®¾è®¡äº†ä¸€å¥—å…¨é¢çš„è¯„ä¼°æµç¨‹ï¼ŒåŒ…æ‹¬æ€§èƒ½åˆ†æã€å¯é æ€§åˆ†æç­‰ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜åˆ†æäº†é—®é¢˜å¯è¯»æ€§ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è¯„ä¼°æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†æ ‡å‡†çš„å‡†ç¡®ç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹çš„å¯é‡å¤æ€§ï¼Œè®ºæ–‡å¯¹åŒä¸€é—®é¢˜å¤šæ¬¡æé—®ï¼Œå¹¶è®¡ç®—å“åº”çš„ä¸€è‡´æ€§ã€‚ä¸ºäº†è¯„ä¼°æ’åºåå·®ï¼Œè®ºæ–‡å¯¹é€‰é¡¹çš„é¡ºåºè¿›è¡Œéšæœºæ‰“ä¹±ï¼Œå¹¶è§‚å¯Ÿæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ã€‚åœ¨é—®é¢˜å¯è¯»æ€§åˆ†ææ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†Flesch Reading Easeå…¬å¼æ¥è®¡ç®—é—®é¢˜çš„å¯è¯»æ€§å¾—åˆ†ï¼Œå¹¶åˆ†æå…¶ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MedBench-ITåŸºå‡†åŒ…å«17410é“é¢˜ç›®ï¼Œæ¶µç›–å…­ä¸ªç§‘ç›®å’Œä¸‰ä¸ªéš¾åº¦çº§åˆ«ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒLLMåœ¨MedBench-ITä¸Šçš„è¡¨ç°å­˜åœ¨å·®å¼‚ï¼ŒGPT-4oç­‰ä¸“æœ‰æ¨¡å‹è¡¨ç°ä¼˜äºå¼€æºæ¨¡å‹ã€‚å¯é‡å¤æ€§æµ‹è¯•æ˜¾ç¤ºï¼Œæ¨¡å‹çš„å“åº”ä¸€è‡´æ€§ä¸º88.86%ï¼Œæ’åºåå·®çš„å½±å“æå°ã€‚é—®é¢˜å¯è¯»æ€§ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´å­˜åœ¨ç»Ÿè®¡ä¸Šæ˜¾è‘—ä½†è¾ƒå°çš„è´Ÿç›¸å…³å…³ç³»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MedBench-ITå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›LLMåœ¨æ„å¤§åˆ©åŒ»å­¦æ•™è‚²é¢†åŸŸçš„åº”ç”¨ï¼Œä¾‹å¦‚æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿã€è‡ªåŠ¨é˜…å·ç³»ç»Ÿç­‰ã€‚è¯¥åŸºå‡†è¿˜å¯ä»¥ä¿ƒè¿›æ„å¤§åˆ©è¯­NLPæŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºå…¶ä»–è¯­è¨€çš„ç‰¹å®šé¢†åŸŸåŸºå‡†æ„å»ºæä¾›å‚è€ƒã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶å¯ä»¥å¸®åŠ©æ•™è‚²æœºæ„å’Œå­¦ç”Ÿæ›´å¥½åœ°äº†è§£LLMçš„èƒ½åŠ›ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMè¾…åŠ©å­¦ä¹ ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) show increasing potential in education, yet benchmarks for non-English languages in specialized domains remain scarce. We introduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on Italian medical university entrance examinations. Sourced from Edizioni Simone, a leading preparatory materials publisher, MedBench-IT comprises 17,410 expert-written multiple-choice questions across six subjects (Biology, Chemistry, Logic, General Culture, Mathematics, Physics) and three difficulty levels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude series) and resource-efficient open-source alternatives (<30B parameters) focusing on practical deployability.
>   Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response consistency, varying by subject), ordering bias analysis (minimal impact), and reasoning prompt evaluation. We also examined correlations between question readability and model performance, finding a statistically significant but small inverse relationship. MedBench-IT provides a crucial resource for Italian NLP community, EdTech developers, and practitioners, offering insights into current capabilities and standardized evaluation methodology for this critical domain.

