---
layout: default
title: Multi-hop Reasoning via Early Knowledge Alignment
---

# Multi-hop Reasoning via Early Knowledge Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.20144" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.20144v1</a>
  <a href="https://arxiv.org/pdf/2512.20144.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.20144v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.20144v1', 'Multi-hop Reasoning via Early Knowledge Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-23

**å¤‡æ³¨**: 16 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/yxzwang/EarlyKnowledgeAlignment)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—©æœŸçŸ¥è¯†å¯¹é½(EKA)æ¨¡å—ï¼Œæå‡è¿­ä»£RAGå¤šè·³æ¨ç†æ€§èƒ½ä¸æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¤šè·³æ¨ç†` `çŸ¥è¯†å¯¹é½` `å¤§è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `è¿­ä»£RAG` `çŸ¥è¯†æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¿­ä»£RAGç³»ç»Ÿåœ¨åˆ†è§£é—®é¢˜æ—¶ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨æ£€ç´¢è¯­æ–™åº“çš„ä¿¡æ¯ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆç‡ä½ä¸‹å’Œæ¨ç†é“¾é”™è¯¯ç´¯ç§¯ã€‚
2. è®ºæ–‡æå‡ºæ—©æœŸçŸ¥è¯†å¯¹é½(EKA)æ¨¡å—ï¼Œåœ¨è§„åˆ’å‰å°†LLMä¸æ£€ç´¢é›†å¯¹é½ï¼Œæä¾›ä¸Šä¸‹æ–‡ç›¸å…³çš„çŸ¥è¯†ï¼Œå¢å¼ºæ¨ç†åŸºç¡€ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEKAæ˜¾è‘—æå‡äº†æ£€ç´¢ç²¾åº¦ï¼Œå‡å°‘äº†çº§è”é”™è¯¯ï¼Œæé«˜äº†RAGç³»ç»Ÿçš„æ€§èƒ½å’Œæ•ˆç‡ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å·²æˆä¸ºå¤§è¯­è¨€æ¨¡å‹(LLM)å¤„ç†çŸ¥è¯†å¯†é›†å‹æŸ¥è¯¢çš„å¼ºå¤§èŒƒä¾‹ï¼Œè¿™äº›æŸ¥è¯¢éœ€è¦é¢†åŸŸç‰¹å®šæˆ–æœ€æ–°çš„ä¿¡æ¯ã€‚ä¸ºäº†å¤„ç†å•æ­¥æ£€ç´¢éš¾ä»¥è§£å†³çš„å¤æ‚å¤šè·³é—®é¢˜ï¼Œå·²ç»æå‡ºäº†ç»“åˆå¼ºåŒ–å­¦ä¹ çš„è¿­ä»£RAGæ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è¿­ä»£RAGç³»ç»Ÿé€šå¸¸åœ¨ä¸åˆ©ç”¨å¯ç”¨æ£€ç´¢è¯­æ–™åº“ä¿¡æ¯çš„æƒ…å†µä¸‹è§„åˆ’åˆ†è§£é—®é¢˜ï¼Œå¯¼è‡´ä½æ•ˆçš„æ£€ç´¢å’Œæ¨ç†é“¾ï¼Œä»è€Œé€ æˆæ¬¡ä¼˜æ€§èƒ½ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†æ—©æœŸçŸ¥è¯†å¯¹é½(EKA)ï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ä½†æœ‰æ•ˆçš„æ¨¡å—ï¼Œå¯ä»¥åœ¨è¿­ä»£RAGç³»ç»Ÿä¸­è¿›è¡Œè§„åˆ’ä¹‹å‰ï¼Œå°†LLMä¸æ£€ç´¢é›†è¿›è¡Œå¯¹é½ï¼Œå¹¶æä¾›ä¸Šä¸‹æ–‡ç›¸å…³çš„æ£€ç´¢çŸ¥è¯†ã€‚åœ¨å…­ä¸ªæ ‡å‡†RAGæ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œé€šè¿‡å»ºç«‹æ›´å¼ºçš„æ¨ç†åŸºç¡€ï¼ŒEKAæ˜¾è‘—æé«˜äº†æ£€ç´¢ç²¾åº¦ï¼Œå‡å°‘äº†çº§è”é”™è¯¯ï¼Œå¹¶æé«˜äº†æ€§èƒ½å’Œæ•ˆç‡ã€‚ä»ç†µçš„è§’åº¦è¿›è¡Œçš„åˆ†æè¡¨æ˜ï¼Œç»“åˆæ—©æœŸçŸ¥è¯†å¯ä»¥å‡å°‘æ¨ç†è¿‡ç¨‹ä¸­ä¸å¿…è¦çš„æ¢ç´¢ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¸“æ³¨äºç›¸å…³ä¿¡æ¯å­é›†ã€‚æ­¤å¤–ï¼ŒEKAè¢«è¯æ˜æ˜¯ä¸€ç§é€šç”¨çš„ã€å…è®­ç»ƒçš„æ¨ç†ç­–ç•¥ï¼Œå¯ä»¥æ— ç¼æ‰©å±•åˆ°å¤§å‹æ¨¡å‹ã€‚è·¨ä¸åŒæ•°æ®é›†å’Œæ£€ç´¢è¯­æ–™åº“çš„æ³›åŒ–æµ‹è¯•è¯å®äº†æˆ‘ä»¬æ–¹æ³•çš„é²æ£’æ€§ã€‚æ€»çš„æ¥è¯´ï¼ŒEKAæ¨è¿›äº†è¿­ä»£RAGç³»ç»Ÿçš„æœ€æ–°æ°´å¹³ï¼ŒåŒæ—¶é˜æ˜äº†å¼ºåŒ–å­¦ä¹ å¢å¼ºæ¡†æ¶ä¸­ç»“æ„åŒ–æ¨ç†å’Œæœ‰æ•ˆæ¢ç´¢ä¹‹é—´çš„å…³é”®ç›¸äº’ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è¿­ä»£å¼æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•åœ¨å¤„ç†å¤šè·³é—®é¢˜æ—¶ï¼Œé€šå¸¸ç‹¬ç«‹åœ°è¿›è¡Œé—®é¢˜åˆ†è§£å’Œæ£€ç´¢ï¼Œå¿½ç•¥äº†æ£€ç´¢è¯­æ–™åº“çš„å…ˆéªŒçŸ¥è¯†ã€‚è¿™å¯¼è‡´æ£€ç´¢åˆ°çš„ä¿¡æ¯ä¸å½“å‰æ¨ç†æ­¥éª¤çš„ç›¸å…³æ€§è¾ƒä½ï¼Œäº§ç”Ÿä½æ•ˆçš„æ¨ç†é“¾ï¼Œå¹¶å®¹æ˜“ç´¯ç§¯é”™è¯¯ï¼Œæœ€ç»ˆå½±å“æ•´ä½“æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨é—®é¢˜åˆ†è§£å’Œè§„åˆ’ä¹‹å‰ï¼Œè®©LLMæå‰â€œæ„ŸçŸ¥â€åˆ°æ£€ç´¢è¯­æ–™åº“çš„å†…å®¹ï¼Œä»è€Œæ›´å¥½åœ°æŒ‡å¯¼åç»­çš„æ£€ç´¢å’Œæ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡è¿™ç§â€œæ—©æœŸçŸ¥è¯†å¯¹é½â€ï¼ŒLLMå¯ä»¥æ›´å‡†ç¡®åœ°åˆ¤æ–­å“ªäº›ä¿¡æ¯æ˜¯å¯ç”¨çš„ï¼Œå¹¶æ®æ­¤åˆ¶å®šæ›´æœ‰æ•ˆçš„æ¨ç†ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEKAæ¨¡å—è¢«é›†æˆåˆ°è¿­ä»£RAGç³»ç»Ÿä¸­ï¼Œä½œä¸ºä¸€ä¸ªé¢„å¤„ç†æ­¥éª¤ã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š1) ç»™å®šåŸå§‹é—®é¢˜ï¼Œé¦–å…ˆä½¿ç”¨LLMå¯¹æ£€ç´¢è¯­æ–™åº“è¿›è¡Œæ¦‚è¦ç†è§£ï¼›2) EKAæ¨¡å—åˆ©ç”¨LLMçš„ç†è§£ç»“æœï¼ŒæŒ‡å¯¼åç»­çš„é—®é¢˜åˆ†è§£å’Œæ£€ç´¢è§„åˆ’ï¼›3) è¿­ä»£åœ°è¿›è¡Œæ£€ç´¢å’Œæ¨ç†ï¼Œç›´åˆ°å¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šEKAçš„å…³é”®åˆ›æ–°åœ¨äºå…¶â€œæ—©æœŸâ€çš„çŸ¥è¯†å¯¹é½æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„è¿­ä»£RAGæ–¹æ³•ä¸åŒï¼ŒEKAä¸æ˜¯åœ¨æ£€ç´¢ä¹‹åæ‰åˆ©ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œè€Œæ˜¯åœ¨è§„åˆ’ä¹‹å‰å°±å°†LLMä¸æ£€ç´¢è¯­æ–™åº“å¯¹é½ã€‚è¿™ç§æå‰å¯¹é½çš„æ–¹å¼å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ£€ç´¢è¯­æ–™åº“çš„çŸ¥è¯†ï¼Œé¿å…ä¸å¿…è¦çš„æ¢ç´¢ï¼Œå¹¶å‡å°‘é”™è¯¯ç´¯ç§¯ã€‚

**å…³é”®è®¾è®¡**ï¼šEKAæ¨¡å—çš„å…·ä½“å®ç°æ–¹å¼æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨LLMå¯¹æ£€ç´¢è¯­æ–™åº“è¿›è¡Œæ‘˜è¦ï¼Œç„¶åå°†æ‘˜è¦ä¿¡æ¯ä½œä¸ºä¸Šä¸‹æ–‡è¾“å…¥åˆ°LLMä¸­ï¼ŒæŒ‡å¯¼å…¶è¿›è¡Œé—®é¢˜åˆ†è§£å’Œæ£€ç´¢è§„åˆ’ã€‚è®ºæ–‡ä¸­æ²¡æœ‰æåŠå…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ï¼ŒEKAä¸»è¦æ˜¯ä¸€ä¸ªæ¨ç†é˜¶æ®µçš„ç­–ç•¥ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20144v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20144v1/figurefigure/EKGRPO.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20144v1/close.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨å…­ä¸ªæ ‡å‡†RAGæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œç»“æœè¡¨æ˜EKAæ˜¾è‘—æé«˜äº†æ£€ç´¢ç²¾åº¦ï¼Œå‡å°‘äº†çº§è”é”™è¯¯ï¼Œå¹¶æé«˜äº†RAGç³»ç»Ÿçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚å…·ä½“æ€§èƒ½æå‡æ•°æ®æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®ç»™å‡ºï¼Œä½†å¼ºè°ƒäº†EKAä½œä¸ºä¸€ç§é€šç”¨ä¸”å…è®­ç»ƒçš„æ¨ç†ç­–ç•¥ï¼Œå¯ä»¥æ— ç¼æ‰©å±•åˆ°å¤§å‹æ¨¡å‹ï¼Œå¹¶åœ¨ä¸åŒæ•°æ®é›†å’Œæ£€ç´¢è¯­æ–™åº“ä¸Šè¡¨ç°å‡ºé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤šè·³æ¨ç†å’ŒçŸ¥è¯†æ£€ç´¢çš„åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€æ™ºèƒ½åŠ©æ‰‹ã€çŸ¥è¯†å›¾è°±æ¨ç†ç­‰ã€‚é€šè¿‡æé«˜æ£€ç´¢ç²¾åº¦å’Œæ¨ç†æ•ˆç‡ï¼ŒEKAå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¿«é€Ÿã€å‡†ç¡®åœ°è·å–æ‰€éœ€ä¿¡æ¯ï¼Œå¹¶æå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼ŒEKAæœ‰æœ›æˆä¸ºæ„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é çš„RAGç³»ç»Ÿçš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for Large Language Models (LLMs) to address knowledge-intensive queries requiring domain-specific or up-to-date information. To handle complex multi-hop questions that are challenging for single-step retrieval, iterative RAG approaches incorporating reinforcement learning have been proposed. However, existing iterative RAG systems typically plan to decompose questions without leveraging information about the available retrieval corpus, leading to inefficient retrieval and reasoning chains that cascade into suboptimal performance. In this paper, we introduce Early Knowledge Alignment (EKA), a simple but effective module that aligns LLMs with retrieval set before planning in iterative RAG systems with contextually relevant retrieved knowledge. Extensive experiments on six standard RAG datasets demonstrate that by establishing a stronger reasoning foundation, EKA significantly improves retrieval precision, reduces cascading errors, and enhances both performance and efficiency. Our analysis from an entropy perspective demonstrate that incorporating early knowledge reduces unnecessary exploration during the reasoning process, enabling the model to focus more effectively on relevant information subsets. Moreover, EKA proves effective as a versatile, training-free inference strategy that scales seamlessly to large models. Generalization tests across diverse datasets and retrieval corpora confirm the robustness of our approach. Overall, EKA advances the state-of-the-art in iterative RAG systems while illuminating the critical interplay between structured reasoning and efficient exploration in reinforcement learning-augmented frameworks. The code is released at \href{https://github.com/yxzwang/EarlyKnowledgeAlignment}{Github}.

