---
layout: default
title: AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications
---

# AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.20164" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.20164v1</a>
  <a href="https://arxiv.org/pdf/2512.20164.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.20164v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.20164v1', 'AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMåœ¨ç®€å†ç­›é€‰ç­‰ä¸“ä¸šåº”ç”¨ä¸­å¯¹æŠ—æ€§æ¼æ´ï¼Œå¹¶æå‡ºæœ‰æ•ˆé˜²å¾¡æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ€§æ”»å‡»` `ç®€å†ç­›é€‰` `å®‰å…¨æ¼æ´` `LoRAé€‚é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨ç®€å†ç­›é€‰ç­‰ä¸“ä¸šé¢†åŸŸåº”ç”¨ä¸­ï¼Œç¼ºä¹é’ˆå¯¹å¯¹æŠ—æ€§æŒ‡ä»¤æ”»å‡»çš„æœ‰æ•ˆé˜²å¾¡æœºåˆ¶ï¼Œå­˜åœ¨å®‰å…¨éšæ‚£ã€‚
2. è®ºæ–‡æå‡ºFIDSï¼ˆé€šè¿‡åˆ†ç¦»è¿›è¡Œå¤–éƒ¨æŒ‡ä»¤æ£€æµ‹ï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨LoRAé€‚é…å¢å¼ºæ¨¡å‹å¯¹å¯¹æŠ—æ€§æŒ‡ä»¤çš„è¯†åˆ«èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFIDSåŠä¸prompt-basedé˜²å¾¡ç»“åˆçš„æ–¹æ³•ï¼Œèƒ½æœ‰æ•ˆé™ä½æ”»å‡»æˆåŠŸç‡ï¼Œä¸”è®­ç»ƒæ—¶é˜²å¾¡ä¼˜äºæ¨ç†æ—¶ç¼“è§£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ–‡æœ¬ç†è§£å’Œç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½¿å…¶æˆä¸ºä»£ç å®¡æŸ¥å’Œå†…å®¹å®¡æ ¸ç­‰è‡ªåŠ¨åŒ–ä»»åŠ¡çš„ç†æƒ³é€‰æ‹©ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„ç ”ç©¶å‘ç°äº†ä¸€ä¸ªæ¼æ´ï¼šLLMå®¹æ˜“å—åˆ°éšè—åœ¨è¾“å…¥æ•°æ®ï¼ˆå¦‚ç®€å†æˆ–ä»£ç ï¼‰ä¸­çš„â€œå¯¹æŠ—æ€§æŒ‡ä»¤â€çš„æ“çºµï¼Œå¯¼è‡´å®ƒä»¬åç¦»é¢„æœŸçš„ä»»åŠ¡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶é’ˆå¯¹ä»£ç å®¡æŸ¥ç­‰æˆç†Ÿé¢†åŸŸå¯èƒ½å­˜åœ¨é˜²å¾¡æœºåˆ¶ï¼Œä½†åœ¨ç®€å†ç­›é€‰å’ŒåŒè¡Œè¯„å®¡ç­‰å…¶ä»–å¸¸è§åº”ç”¨ä¸­ï¼Œè¿™äº›é˜²å¾¡æœºåˆ¶å¾€å¾€ç¼ºå¤±ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªåŸºå‡†æ¥è¯„ä¼°ç®€å†ç­›é€‰ä¸­çš„è¿™ç§æ¼æ´ï¼Œæ­ç¤ºäº†æŸäº›æ”»å‡»ç±»å‹çš„æˆåŠŸç‡è¶…è¿‡80%ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸¤ç§é˜²å¾¡æœºåˆ¶ï¼šåŸºäºæç¤ºçš„é˜²å¾¡å®ç°äº†10.1%çš„æ”»å‡»å‡å°‘ï¼Œä½†è¯¯æ‹’ç‡å¢åŠ äº†12.5%ï¼Œè€Œæˆ‘ä»¬æå‡ºçš„ä½¿ç”¨LoRAé€‚é…çš„FIDSï¼ˆé€šè¿‡åˆ†ç¦»è¿›è¡Œå¤–éƒ¨æŒ‡ä»¤æ£€æµ‹ï¼‰å®ç°äº†15.4%çš„æ”»å‡»å‡å°‘ï¼Œè¯¯æ‹’ç‡å¢åŠ äº†10.4%ã€‚ç»„åˆæ–¹æ³•æä¾›äº†26.3%çš„æ”»å‡»å‡å°‘ï¼Œè¡¨æ˜è®­ç»ƒæ—¶é˜²å¾¡åœ¨å®‰å…¨æ€§å’Œæ•ˆç”¨ä¿æŒæ–¹é¢å‡ä¼˜äºæ¨ç†æ—¶ç¼“è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ç®€å†ç­›é€‰ç­‰ä¸“ä¸šåº”ç”¨ä¸­ï¼Œå®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æŒ‡ä»¤æ”»å‡»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä»£ç å®¡æŸ¥ç­‰æˆç†Ÿé¢†åŸŸçš„é˜²å¾¡æœºåˆ¶ï¼Œæ— æ³•ç›´æ¥åº”ç”¨äºè¿™äº›ä¸“ä¸šé¢†åŸŸï¼Œå¯¼è‡´LLMåœ¨å¤„ç†ç®€å†ç­‰æ•°æ®æ—¶å®¹æ˜“è¢«æ¶æ„æŒ‡ä»¤æ“çºµï¼Œåç¦»é¢„å®šç›®æ ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®­ç»ƒæ—¶é˜²å¾¡ï¼Œå¢å¼ºLLMå¯¹å¯¹æŠ—æ€§æŒ‡ä»¤çš„è¯†åˆ«å’ŒæŠµæŠ—èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œè®ºæ–‡æå‡ºäº†FIDSï¼ˆForeign Instruction Detection through Separationï¼‰æ–¹æ³•ï¼Œæ—¨åœ¨å°†æ¨¡å‹å¯¹æ­£å¸¸æŒ‡ä»¤å’Œå¯¹æŠ—æ€§æŒ‡ä»¤çš„å“åº”åˆ†ç¦»ï¼Œä»è€Œæ›´å®¹æ˜“æ£€æµ‹å’Œè¿‡æ»¤å¯¹æŠ—æ€§æŒ‡ä»¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šæ”»å‡»é˜¶æ®µå’Œé˜²å¾¡é˜¶æ®µã€‚åœ¨æ”»å‡»é˜¶æ®µï¼Œç ”ç©¶è€…æ„å»ºå¯¹æŠ—æ€§æŒ‡ä»¤å¹¶å°†å…¶åµŒå…¥åˆ°ç®€å†ä¸­ï¼Œä»¥è¯„ä¼°LLMçš„è„†å¼±æ€§ã€‚åœ¨é˜²å¾¡é˜¶æ®µï¼Œç ”ç©¶è€…è¯„ä¼°äº†prompt-basedé˜²å¾¡å’ŒFIDSä¸¤ç§æ–¹æ³•ã€‚FIDSä½¿ç”¨LoRAï¼ˆLow-Rank Adaptationï¼‰æŠ€æœ¯ï¼Œåœ¨é¢„è®­ç»ƒçš„LLMåŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä»¥åŒºåˆ†æ­£å¸¸æŒ‡ä»¤å’Œå¯¹æŠ—æ€§æŒ‡ä»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºFIDSæ–¹æ³•ï¼Œå®ƒé€šè¿‡LoRAé€‚é…ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å¼åœ°å­¦ä¹ åŒºåˆ†æ­£å¸¸æŒ‡ä»¤å’Œå¯¹æŠ—æ€§æŒ‡ä»¤ï¼Œä»è€Œæé«˜äº†æ¨¡å‹å¯¹å¯¹æŠ—æ€§æ”»å‡»çš„é²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿçš„æ¨ç†æ—¶é˜²å¾¡æ–¹æ³•ç›¸æ¯”ï¼ŒFIDSåœ¨è®­ç»ƒæ—¶å°±èå…¥äº†é˜²å¾¡æœºåˆ¶ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æŠµå¾¡å¯¹æŠ—æ€§æ”»å‡»ã€‚

**å…³é”®è®¾è®¡**ï¼šFIDSçš„å…³é”®è®¾è®¡åœ¨äºä½¿ç”¨LoRAé€‚é…å™¨ã€‚LoRAé€šè¿‡å¼•å…¥ä½ç§©çŸ©é˜µæ¥æ›´æ–°é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä»è€Œåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å‡å°‘äº†è®¡ç®—é‡å’Œå†…å­˜æ¶ˆè€—ã€‚åœ¨FIDSä¸­ï¼ŒLoRAè¢«ç”¨äºå­¦ä¹ åŒºåˆ†æ­£å¸¸æŒ‡ä»¤å’Œå¯¹æŠ—æ€§æŒ‡ä»¤çš„ç‰¹å¾è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†prompt-basedé˜²å¾¡ï¼Œé€šè¿‡ä¿®æ”¹è¾“å…¥æç¤ºæ¥å¼•å¯¼LLMå¿½ç•¥å¯¹æŠ—æ€§æŒ‡ä»¤ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½æ¶‰åŠå¯¹æ¯”å­¦ä¹ æˆ–äº¤å‰ç†µæŸå¤±ï¼Œä»¥é¼“åŠ±æ¨¡å‹åŒºåˆ†æ­£å¸¸å’Œå¯¹æŠ—æ€§æŒ‡ä»¤çš„è¡¨ç¤ºã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20164v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20164v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20164v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒæŸäº›æ”»å‡»ç±»å‹çš„æˆåŠŸç‡è¶…è¿‡80%ï¼Œå‡¸æ˜¾äº†LLMåœ¨ç®€å†ç­›é€‰ç­‰ä¸“ä¸šåº”ç”¨ä¸­çš„å®‰å…¨é£é™©ã€‚FIDSæ–¹æ³•å®ç°äº†15.4%çš„æ”»å‡»å‡å°‘ï¼Œè¯¯æ‹’ç‡å¢åŠ äº†10.4%ã€‚ç»“åˆprompt-basedé˜²å¾¡ï¼Œæ”»å‡»å‡å°‘ç‡è¾¾åˆ°26.3%ï¼Œè¡¨æ˜è®­ç»ƒæ—¶é˜²å¾¡ç­–ç•¥ä¼˜äºæ¨ç†æ—¶ç¼“è§£ç­–ç•¥ã€‚è¿™äº›æ•°æ®éªŒè¯äº†FIDSçš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºLLMå®‰å…¨é˜²å¾¡æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§åŸºäºLLMçš„è‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œå¦‚æ‹›è˜é¢†åŸŸçš„ç®€å†ç­›é€‰ã€å­¦æœ¯é¢†åŸŸçš„è®ºæ–‡è¯„å®¡ã€ä»¥åŠå†…å®¹å®¡æ ¸ç­‰ã€‚é€šè¿‡æå‡LLMå¯¹æŠ—æ¶æ„æŒ‡ä»¤æ”»å‡»çš„é²æ£’æ€§ï¼Œå¯ä»¥æé«˜è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜å·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ä¸“ä¸šé¢†åŸŸï¼Œå¹¶ä¸å…¶ä»–é˜²å¾¡æŠ€æœ¯ç›¸ç»“åˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„å®‰å…¨é˜²æŠ¤ä½“ç³»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by "adversarial instructions" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.

