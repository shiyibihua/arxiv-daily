---
layout: default
title: Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data
---

# Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15793" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15793v2</a>
  <a href="https://arxiv.org/pdf/2508.15793.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15793v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15793v2', 'Format as a Prior: Quantifying and Analyzing Bias in LLMs for Heterogeneous Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiacheng Liu, Mayi Xu, Qiankun Pi, Wenli Li, Ming Zhong, Yuanyuan Zhu, Mengchi Liu, Tieyun Qian

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13 (æ›´æ–°: 2025-11-14)

**å¤‡æ³¨**: Accepted by AAAI 2026, camera ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ¼å¼åè§åˆ†ææ–¹æ³•ä»¥è§£å†³LLMsåœ¨å¼‚æ„æ•°æ®å¤„ç†ä¸­çš„åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ ¼å¼åè§` `å¼‚æ„æ•°æ®` `æ³¨æ„åŠ›æœºåˆ¶` `æ•°æ®é¢„å¤„ç†` `å…¬å¹³æ€§` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMsåœ¨å¤„ç†å¼‚æ„æ•°æ®æ—¶å­˜åœ¨ç³»ç»Ÿæ€§æ ¼å¼åè§ï¼Œå½±å“å…¶æ¨ç†èƒ½åŠ›å’Œä¸‹æ¸¸ä»»åŠ¡çš„å®‰å…¨æ€§ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡ä¸‰é˜¶æ®µå®è¯åˆ†æï¼Œç³»ç»Ÿé‡åŒ–å’Œåˆ†æLLMsä¸­çš„æ ¼å¼åè§åŠå…¶å½±å“å› ç´ ã€‚
3. ç ”ç©¶å‘ç°æ ¼å¼åè§åœ¨ä¸åŒæ¨¡å‹ä¸­æ™®éå­˜åœ¨ï¼Œå¹¶æå‡ºæ•°æ®é¢„å¤„ç†å’Œæ¨ç†å¹²é¢„ç­‰æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†å¼‚æ„æ ¼å¼ä¿¡æ¯ï¼ˆå¦‚æ–‡æœ¬ã€è¡¨æ ¼ã€ä¿¡æ¯æ¡†å’ŒçŸ¥è¯†å›¾è°±ï¼‰æ—¶ï¼Œå¯èƒ½å­˜åœ¨ç³»ç»Ÿæ€§åè§ï¼Œè¿™ä¼šå½±å“å…¶å…¬æ­£æ•´åˆå¼‚æ„æ•°æ®çš„èƒ½åŠ›ï¼Œå¯¼è‡´æ¨ç†é”™è¯¯å’Œä¸‹æ¸¸ä»»åŠ¡é£é™©å¢åŠ ã€‚æœ¬æ–‡é€šè¿‡ä¸‰é˜¶æ®µå®è¯åˆ†æï¼Œé¦–æ¬¡å…¨é¢ç ”ç©¶LLMsä¸­çš„æ ¼å¼åè§ï¼Œæ¢è®¨åè§çš„å­˜åœ¨åŠæ–¹å‘ã€æ•°æ®å±‚é¢å› ç´ çš„å½±å“ä»¥åŠåè§åœ¨æ³¨æ„åŠ›æ¨¡å¼ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ ¼å¼åè§åœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¸­ä¸€è‡´å­˜åœ¨ï¼Œå—ä¿¡æ¯ä¸°å¯Œåº¦ã€ç»“æ„è´¨é‡å’Œè¡¨ç¤ºç±»å‹é©±åŠ¨ï¼Œå¹¶ä¸LLMså†…éƒ¨çš„æ³¨æ„åŠ›å¤±è¡¡å¯†åˆ‡ç›¸å…³ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†ä¸‰æ¡æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä»¥å‡å°‘æ ¼å¼åè§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¼‚æ„æ•°æ®æ—¶çš„æ ¼å¼åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿæ€§åˆ†æåè§çš„æ¥æºåŠå…¶å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä¸‰é˜¶æ®µå®è¯åˆ†æï¼Œæ¢ç´¢ä¸åŒLLMsä¸­çš„æ ¼å¼åè§åŠå…¶é©±åŠ¨å› ç´ ï¼Œåˆ†ææ³¨æ„åŠ›æ¨¡å¼ä¸­çš„åè§è¡¨ç°ï¼Œå¹¶æµ‹è¯•è½»é‡çº§å¹²é¢„çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µè¯„ä¼°ä¸åŒLLMsä¸­çš„åè§å­˜åœ¨åŠæ–¹å‘ï¼›ç¬¬äºŒé˜¶æ®µåˆ†ææ•°æ®å±‚é¢å› ç´ å¯¹åè§çš„å½±å“ï¼›ç¬¬ä¸‰é˜¶æ®µæ¢è®¨æ³¨æ„åŠ›æ¨¡å¼ä¸­çš„åè§åŠå¹²é¢„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡ç³»ç»Ÿæ€§ç ”ç©¶LLMsä¸­çš„æ ¼å¼åè§ï¼Œæ­ç¤ºå…¶åœ¨ä¸åŒæ¨¡å‹ä¸­çš„ä¸€è‡´æ€§åŠé©±åŠ¨å› ç´ ï¼Œæå‡ºäº†é’ˆå¯¹æ ¼å¼åè§çš„å¹²é¢„æªæ–½ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­å…³æ³¨ä¿¡æ¯ä¸°å¯Œåº¦ã€ç»“æ„è´¨é‡å’Œè¡¨ç¤ºç±»å‹ç­‰å› ç´ ï¼Œå¹¶é€šè¿‡æ³¨æ„åŠ›é‡åŠ æƒç­‰æ–¹æ³•è¿›è¡Œå¹²é¢„ï¼Œæ—¨åœ¨æå‡æ¨¡å‹åœ¨å¼‚æ„æ•°æ®å¤„ç†ä¸­çš„å…¬å¹³æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ ¼å¼åè§åœ¨ä¸åŒæ¨¡å‹å®¶æ—ä¸­æ™®éå­˜åœ¨ï¼Œä¸”ä¸ä¿¡æ¯ä¸°å¯Œåº¦ã€ç»“æ„è´¨é‡å’Œè¡¨ç¤ºç±»å‹å¯†åˆ‡ç›¸å…³ã€‚é€šè¿‡æ³¨æ„åŠ›æ¨¡å¼åˆ†æï¼Œå‘ç°æ³¨æ„åŠ›å¤±è¡¡æ˜¯åè§çš„é‡è¦è¡¨ç°ï¼Œæå‡ºçš„å¹²é¢„æªæ–½åœ¨ä¸€å®šç¨‹åº¦ä¸Šæœ‰æ•ˆæ”¹å–„äº†æ¨¡å‹çš„è¡¨ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼‚æ„æ•°æ®å¤„ç†ä¸­çš„åº”ç”¨æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ï¼Œå°¤å…¶åœ¨ä¿¡æ¯æ£€ç´¢ã€è‡ªåŠ¨é—®ç­”å’Œæ•°æ®é›†æˆç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å‡å°‘æ ¼å¼åè§ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„å…¬æ­£æ€§å’Œå¯é æ€§ï¼Œä¿ƒè¿›æ›´å®‰å…¨çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly employed in applications that require processing information from heterogeneous formats, including texts, tables, infoboxes, and knowledge graphs. However, systematic biases toward particular formats may undermine LLMs' ability to integrate heterogeneous data impartially, potentially resulting in reasoning errors and increased risks in downstream tasks. Yet it remains unclear whether such biases are systematic, which data-level factors drive them, and what internal mechanisms underlie their emergence.
>   In this paper, we present the first comprehensive study of format bias in LLMs through a three-stage empirical analysis. The first stage explores the presence and direction of bias across a diverse range of LLMs. The second stage examines how key data-level factors influence these biases. The third stage analyzes how format bias emerges within LLMs' attention patterns and evaluates a lightweight intervention to test its effectiveness. Our results show that format bias is consistent across model families, driven by information richness, structure quality, and representation type, and is closely associated with attention imbalance within the LLMs. Based on these investigations, we identify three future research directions to reduce format bias: enhancing data pre-processing through format repair and normalization, introducing inference-time interventions such as attention re-weighting, and developing format-balanced training corpora. These directions will support the design of more robust and fair heterogeneous data processing systems.

