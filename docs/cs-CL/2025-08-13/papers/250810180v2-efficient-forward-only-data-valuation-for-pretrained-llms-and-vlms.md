---
layout: default
title: Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs
---

# Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10180" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10180v2</a>
  <a href="https://arxiv.org/pdf/2508.10180.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10180v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10180v2', 'Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenlong Deng, Jiaming Zhang, Qi Zeng, Christos Thrampoulidis, Boying Gong, Xiaoxiao Li

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13 (æ›´æ–°: 2025-08-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFor-Valueæ¡†æ¶ä»¥é«˜æ•ˆè¯„ä¼°å¤§æ¨¡å‹æ•°æ®å½±å“åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°æ®ä¼°å€¼` `å¤§æ¨¡å‹` `å‰å‘è®¡ç®—` `å½±å“åŠ›è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†` `è®¡ç®—æœºè§†è§‰` `æ¨¡å‹é€æ˜åº¦` `æ ·æœ¬é€‰æ‹©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ•°æ®ä¼°å€¼æ–¹æ³•ä¾èµ–äºHessianä¿¡æ¯æˆ–æ¨¡å‹é‡è®­ç»ƒï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥åº”ç”¨äºäº¿å‚æ•°æ¨¡å‹ã€‚
2. æå‡ºFor-Valueæ¡†æ¶ï¼Œé€šè¿‡ä¸€æ¬¡å‰å‘ä¼ é€’è®¡ç®—å½±å“åŠ›åˆ†æ•°ï¼Œé¿å…äº†æ¢¯åº¦è®¡ç®—çš„é«˜æ˜‚å¼€é”€ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFor-Valueåœ¨è¯†åˆ«é‡è¦æ ·æœ¬å’Œæ£€æµ‹é”™è¯¯æ ‡è®°æ•°æ®æ–¹é¢ï¼Œæ€§èƒ½ä¸åŸºäºæ¢¯åº¦çš„æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é‡åŒ–å•ä¸ªè®­ç»ƒæ ·æœ¬çš„å½±å“åŠ›å¯¹äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„é€æ˜åº¦å’Œé—®è´£åˆ¶è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®ä¼°å€¼æ–¹æ³•é€šå¸¸ä¾èµ–äºHessianä¿¡æ¯æˆ–æ¨¡å‹é‡è®­ç»ƒï¼Œè¿™ä½¿å¾—å…¶åœ¨äº¿å‚æ•°æ¨¡å‹ä¸Šè®¡ç®—æˆæœ¬é«˜æ˜‚ã€‚æœ¬æ–‡æå‡ºäº†For-Valueï¼Œä¸€ä¸ªå‰å‘æ•°æ®ä¼°å€¼æ¡†æ¶ï¼Œèƒ½å¤Ÿä¸ºLLMså’ŒVLMsæä¾›å¯æ‰©å±•ä¸”é«˜æ•ˆçš„å½±å“åŠ›ä¼°è®¡ã€‚é€šè¿‡åˆ©ç”¨ç°ä»£åŸºç¡€æ¨¡å‹çš„ä¸°å¯Œè¡¨ç¤ºï¼ŒFor-Valueä»…é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ é€’è®¡ç®—å½±å“åŠ›åˆ†æ•°ï¼Œä»è€Œæ¶ˆé™¤äº†æ˜‚è´µçš„æ¢¯åº¦è®¡ç®—éœ€æ±‚ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼ŒFor-Valueé€šè¿‡æ•æ‰è®­ç»ƒæ ·æœ¬ä¸éªŒè¯æ ·æœ¬ä¹‹é—´çš„éšè—è¡¨ç¤ºå’Œé¢„æµ‹è¯¯å·®çš„å¯¹é½ï¼Œå‡†ç¡®ä¼°è®¡æ¯ä¸ªæ ·æœ¬çš„å½±å“åŠ›ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFor-Valueåœ¨è¯†åˆ«é‡è¦çš„å¾®è°ƒç¤ºä¾‹å’Œæœ‰æ•ˆæ£€æµ‹é”™è¯¯æ ‡è®°æ•°æ®æ–¹é¢ï¼Œä¸åŸºäºæ¢¯åº¦çš„æ–¹æ³•ç›¸æ¯”è¡¨ç°ç›¸å½“æˆ–æ›´ä¼˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®ä¼°å€¼æ–¹æ³•åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­è®¡ç®—æˆæœ¬é«˜çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºHessianä¿¡æ¯æˆ–é‡è®­ç»ƒï¼Œå¯¼è‡´åœ¨äº¿å‚æ•°æ¨¡å‹ä¸Šéš¾ä»¥å®æ–½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFor-Valueæ¡†æ¶é€šè¿‡ä¸€æ¬¡å‰å‘ä¼ é€’è®¡ç®—å½±å“åŠ›åˆ†æ•°ï¼Œåˆ©ç”¨ç°ä»£åŸºç¡€æ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œé¿å…äº†å¤æ‚çš„æ¢¯åº¦è®¡ç®—ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ•°æ®ä¼°å€¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFor-Valueçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€å‰å‘ä¼ é€’è®¡ç®—ã€å½±å“åŠ›åˆ†æ•°ç”Ÿæˆå’Œç»“æœè¾“å‡ºå››ä¸ªä¸»è¦æ¨¡å—ã€‚é€šè¿‡å‰å‘ä¼ é€’ï¼Œæ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿè¯„ä¼°æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„å½±å“åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šFor-Valueçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å‰å‘è®¡ç®—æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–æ¢¯åº¦ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œå‡†ç¡®è¯„ä¼°æ ·æœ¬å½±å“åŠ›ã€‚è¿™ä¸€è®¾è®¡æ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°ä¸­ï¼ŒFor-Valueé‡‡ç”¨ç®€å•çš„é—­å¼è¡¨è¾¾å¼æ¥è®¡ç®—å½±å“åŠ›åˆ†æ•°ï¼Œç¡®ä¿äº†è®¡ç®—çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚æ¨¡å‹çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFor-Valueåœ¨è¯†åˆ«é‡è¦å¾®è°ƒæ ·æœ¬æ–¹é¢ä¸åŸºäºæ¢¯åº¦çš„æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½ç›¸å½“æˆ–æ›´ä¼˜ï¼Œä¸”åœ¨æ£€æµ‹é”™è¯¯æ ‡è®°æ•°æ®æ—¶è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†å…¶åœ¨æ•°æ®ä¼°å€¼ä¸­çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰åŠå…¶äº¤å‰é¢†åŸŸï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„é€æ˜åº¦å’Œé—®è´£åˆ¶ã€‚For-Valueæ¡†æ¶å¯ç”¨äºæ•°æ®æ¸…æ´—ã€æ ·æœ¬é€‰æ‹©å’Œæ¨¡å‹ä¼˜åŒ–ç­‰ä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quantifying the influence of individual training samples is essential for enhancing the transparency and accountability of large language models (LLMs) and vision-language models (VLMs). However, existing data valuation methods often rely on Hessian information or model retraining, making them computationally prohibitive for billion-parameter models. In this work, we introduce For-Value, a forward-only data valuation framework that enables scalable and efficient influence estimation for both LLMs and VLMs. By leveraging the rich representations of modern foundation models, For-Value computes influence scores using a simple closed-form expression based solely on a single forward pass, thereby eliminating the need for costly gradient computations. Our theoretical analysis demonstrates that For-Value accurately estimates per-sample influence by capturing alignment in hidden representations and prediction errors between training and validation samples. Extensive experiments show that For-Value matches or outperforms gradient-based baselines in identifying impactful fine-tuning examples and effectively detecting mislabeled data.

