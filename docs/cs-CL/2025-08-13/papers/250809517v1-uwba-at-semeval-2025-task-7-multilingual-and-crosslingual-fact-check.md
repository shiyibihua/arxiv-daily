---
layout: default
title: UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval
---

# UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09517" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09517v1</a>
  <a href="https://arxiv.org/pdf/2508.09517.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09517v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09517v1', 'UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ladislav Lenc, Daniel CÃ­fka, JiÅ™Ã­ MartÃ­nek, Jakub Å mÃ­d, Pavel KrÃ¡l

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: Published in Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025). Official version: https://aclanthology.org/2025.semeval-1.31/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶-shotç³»ç»Ÿä»¥è§£å†³å¤šè¯­è¨€äº‹å®æ ¸æŸ¥å£°æ˜æ£€ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶-shotå­¦ä¹ ` `å¤šè¯­è¨€æ£€ç´¢` `äº‹å®æ ¸æŸ¥` `æ–‡æœ¬åµŒå…¥` `æ¨¡å‹ç»„åˆ` `ä½™å¼¦ç›¸ä¼¼åº¦` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šè¯­è¨€å’Œè·¨è¯­è¨€å£°æ˜æ£€ç´¢æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†äº‹å®æ ¸æŸ¥æ—¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé›¶-shotå­¦ä¹ çš„ç³»ç»Ÿï¼Œåˆ©ç”¨å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–‡æœ¬åµŒå…¥æ¥æé«˜å£°æ˜æ£€ç´¢çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å•è¯­ä»»åŠ¡ä¸­æ’åç¬¬ä¸ƒï¼Œåœ¨è·¨è¯­è¨€ä»»åŠ¡ä¸­æ’åç¬¬ä¹ï¼Œè¡¨æ˜å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶-shotç³»ç»Ÿç”¨äºäº‹å®æ ¸æŸ¥å£°æ˜çš„æ£€ç´¢ã€‚æˆ‘ä»¬é‡‡ç”¨äº†å¤šç§æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹æ¥è·å–æ–‡æœ¬åµŒå…¥ï¼Œå¹¶å°†è¿™äº›æ¨¡å‹ç»„åˆä»¥è·å¾—æœ€ä½³ç»“æœã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨å•è¯­ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¸ƒåï¼Œåœ¨è·¨è¯­è¨€å­ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¹åã€‚ç”±äºå¤šè¯­è¨€æ¨¡å‹æœªèƒ½å–å¾—ä»¤äººæ»¡æ„çš„ç»“æœï¼Œæˆ‘ä»¬ä»…ä½¿ç”¨è‹±æ–‡ç¿»è¯‘ä½œä¸ºæ–‡æœ¬åµŒå…¥æ¨¡å‹çš„è¾“å…¥ã€‚é€šè¿‡åˆ©ç”¨åµŒå…¥å¹¶æµ‹é‡ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºæ¯ä¸ªå¸–å­æœ€ç›¸å…³çš„å£°æ˜ã€‚æ€»ä½“è€Œè¨€ï¼ŒNVIDIA NV-Embed-v2æ¨¡å‹å–å¾—äº†æœ€ä½³ç»“æœã€‚åœ¨æŸäº›è¯­è¨€ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ¨¡å‹ç»„åˆï¼ˆå¦‚NV-Embedä¸GPTæˆ–Mistralï¼‰è·å¾—äº†é¢å¤–çš„æ”¶ç›Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šè¯­è¨€å’Œè·¨è¯­è¨€çš„äº‹å®æ ¸æŸ¥å£°æ˜æ£€ç´¢é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒè¯­è¨€çš„å£°æ˜æ—¶ï¼Œå‡†ç¡®æ€§å’Œæ•ˆç‡å‡å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹è¶³å¤Ÿè®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é›¶-shotå­¦ä¹ çš„ç³»ç»Ÿï¼Œåˆ©ç”¨å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åµŒå…¥ï¼Œå¹¶é€šè¿‡ç»„åˆè¿™äº›æ¨¡å‹æ¥ä¼˜åŒ–æ£€ç´¢æ•ˆæœã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–æ¨¡å‹çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬åµŒå…¥ç”Ÿæˆã€æ¨¡å‹ç»„åˆå’Œç›¸ä¼¼åº¦è®¡ç®—ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åµŒå…¥ï¼Œç„¶åé€šè¿‡ç»„åˆä¸åŒæ¨¡å‹çš„è¾“å‡ºï¼Œæœ€ååˆ©ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¯†åˆ«æœ€ç›¸å…³çš„å£°æ˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé‡‡ç”¨äº†é›¶-shotå­¦ä¹ ç­–ç•¥ï¼Œå¹¶é€šè¿‡ç»„åˆä¸åŒçš„è¯­è¨€æ¨¡å‹ï¼ˆå¦‚NV-Embedä¸GPTæˆ–Mistralï¼‰æ¥æå‡æ£€ç´¢æ€§èƒ½ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®çš„æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹é€‰æ‹©ä¸Šï¼Œæˆ‘ä»¬å‘ç°NVIDIA NV-Embed-v2æ¨¡å‹åœ¨å¤šä¸ªè¯­è¨€ä¸Šè¡¨ç°æœ€ä½³ã€‚æ­¤å¤–ï¼Œæ¨¡å‹ç»„åˆçš„ç­–ç•¥ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒè¯­è¨€ä¸­å‡èƒ½è·å¾—è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨å•è¯­ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¸ƒåï¼Œåœ¨è·¨è¯­è¨€ä»»åŠ¡ä¸­è·å¾—ç¬¬ä¹åï¼Œè¡¨æ˜å…¶åœ¨å¤šè¯­è¨€å£°æ˜æ£€ç´¢ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç‰¹åˆ«æ˜¯ï¼ŒNVIDIA NV-Embed-v2æ¨¡å‹çš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ç»„åˆï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ç›‘æ§ã€æ–°é—»éªŒè¯å’Œåœ¨çº¿ä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æé«˜å¤šè¯­è¨€å’Œè·¨è¯­è¨€çš„å£°æ˜æ£€ç´¢èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¸®åŠ©ç”¨æˆ·è¯†åˆ«å’ŒéªŒè¯ä¿¡æ¯çš„çœŸå®æ€§ï¼Œè¿›è€Œå‡å°‘è™šå‡ä¿¡æ¯çš„ä¼ æ’­ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨å…¨çƒèŒƒå›´å†…çš„äº‹å®æ ¸æŸ¥å’Œä¿¡æ¯é€æ˜åº¦æå‡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a zero-shot system for fact-checked claim retrieval. We employed several state-of-the-art large language models to obtain text embeddings. The models were then combined to obtain the best possible result. Our approach achieved 7th place in monolingual and 9th in cross-lingual subtasks. We used only English translations as an input to the text embedding models since multilingual models did not achieve satisfactory results. We identified the most relevant claims for each post by leveraging the embeddings and measuring cosine similarity. Overall, the best results were obtained by the NVIDIA NV-Embed-v2 model. For some languages, we benefited from model combinations (NV-Embed & GPT or Mistral).

