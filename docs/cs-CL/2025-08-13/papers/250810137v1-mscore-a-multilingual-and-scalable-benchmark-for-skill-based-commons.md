---
layout: default
title: mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning
---

# mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10137" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10137v1</a>
  <a href="https://arxiv.org/pdf/2508.10137.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10137v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10137v1', 'mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nghia Trung Ngo, Franck Dernoncourt, Thien Huu Nguyen

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºmSCoReä»¥è§£å†³å¤šè¯­è¨€å¸¸è¯†æ¨ç†çš„è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨ç†` `å¸¸è¯†æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†æŠ€èƒ½` `æ•°æ®åˆæˆ` `å¤æ‚æ€§è¯„ä¼°` `è·¨æ–‡åŒ–äº¤æµ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨ç†å¢å¼ºæ¨¡å‹åœ¨å¤šè¯­è¨€å¸¸è¯†æ¨ç†ä¸­é¢ä¸´è¯„ä¼°ä¸è¶³å’Œèƒ½åŠ›å±€é™çš„é—®é¢˜ï¼Œå°¤å…¶åœ¨æ–‡åŒ–å’Œè¯­è¨€çš„ç»†å¾®å·®åˆ«ä¸Šã€‚
2. æœ¬æ–‡æå‡ºçš„mSCoReåŸºå‡†é€šè¿‡æ–°çš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•ã€æ•°æ®åˆæˆç®¡é“å’Œå¤æ‚æ€§ç¼©æ”¾æ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒmSCoReå¯¹å½“å‰çš„LLMæ¨¡å‹ä»å…·æœ‰æ˜¾è‘—æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å¤æ‚æ€§ä»»åŠ¡ä¸­ï¼Œæ­ç¤ºäº†æ¨¡å‹çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ¨ç†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå…³äºå®ƒä»¬å¦‚ä½•åˆ©ç”¨ä¸åŒäººç±»æ¨ç†æŠ€èƒ½çš„æœºåˆ¶ä»ç„¶ç ”ç©¶ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠä¸åŒè¯­è¨€å’Œæ–‡åŒ–çš„å¤šè¯­è¨€å¸¸è¯†æ¨ç†æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤šè¯­è¨€å’Œå¯æ‰©å±•çš„åŸºå‡†æµ‹è¯•mSCoReã€‚è¯¥åŸºå‡†åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼Œæ—¨åœ¨ç³»ç»Ÿè¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›ï¼š1ï¼‰ä¸€ç§æ–°çš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•ï¼Œä¾¿äºå¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹è¿›è¡Œç»†è‡´åˆ†æï¼›2ï¼‰ä¸“é—¨ä¸ºå¸¸è¯†æ¨ç†è¯„ä¼°è®¾è®¡çš„å¼ºå¤§æ•°æ®åˆæˆç®¡é“ï¼›3ï¼‰å…è®¸ä»»åŠ¡éš¾åº¦éšLLMèƒ½åŠ›çš„æœªæ¥æå‡åŠ¨æ€æ‰©å±•çš„å¤æ‚æ€§ç¼©æ”¾æ¡†æ¶ã€‚å¯¹å…«ç§ä¸åŒè§„æ¨¡å’Œè®­ç»ƒæ–¹æ³•çš„æœ€å…ˆè¿›LLMè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒmSCoReå¯¹å½“å‰æ¨¡å‹ä»ç„¶å…·æœ‰æ˜¾è‘—æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ›´é«˜å¤æ‚æ€§æ°´å¹³ä¸‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šè¯­è¨€å¸¸è¯†æ¨ç†çš„è¯„ä¼°é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸åŒæ–‡åŒ–å’Œè¯­è¨€çš„ç»†å¾®å·®åˆ«æ—¶å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ä¸å¤Ÿå…¨é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„mSCoReåŸºå‡†é€šè¿‡å¼•å…¥æ–°çš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•å’Œå¤æ‚æ€§ç¼©æ”¾æ¡†æ¶ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§åœ°è¯„ä¼°å’Œåˆ†æLLMçš„æ¨ç†è¿‡ç¨‹ï¼Œå¸®åŠ©è¯†åˆ«å…¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šmSCoReçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•ï¼Œæä¾›ç»†è‡´çš„æ¨ç†è¿‡ç¨‹åˆ†æï¼›2ï¼‰æ•°æ®åˆæˆç®¡é“ï¼Œç”Ÿæˆé€‚ç”¨äºå¸¸è¯†æ¨ç†çš„è¯„ä¼°æ•°æ®ï¼›3ï¼‰å¤æ‚æ€§ç¼©æ”¾æ¡†æ¶ï¼ŒåŠ¨æ€è°ƒæ•´ä»»åŠ¡éš¾åº¦ä»¥é€‚åº”LLMèƒ½åŠ›çš„æå‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šmSCoReçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶æ¨ç†æŠ€èƒ½çš„ç»†åˆ†å’Œå¤æ‚æ€§åŠ¨æ€è°ƒæ•´æœºåˆ¶ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é™æ€è¯„ä¼°æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°åæ˜ æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæ¨ç†æŠ€èƒ½åˆ†ç±»æ³•é‡‡ç”¨äº†å¤šå±‚æ¬¡çš„åˆ†ç±»æ ‡å‡†ï¼Œæ•°æ®åˆæˆç®¡é“åˆ™åˆ©ç”¨äº†å¤šæ ·åŒ–çš„è¯­æ–™åº“ï¼Œç¡®ä¿ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ï¼Œå¤æ‚æ€§ç¼©æ”¾æ¡†æ¶åˆ™é€šè¿‡å‚æ•°è®¾ç½®å®ç°ä»»åŠ¡éš¾åº¦çš„çµæ´»è°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒmSCoReå¯¹å…«ç§æœ€å…ˆè¿›çš„LLMæ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå°¤å…¶åœ¨é«˜å¤æ‚æ€§ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹çš„è¡¨ç°æ˜¾è‘—ä½äºé¢„æœŸï¼Œæ­ç¤ºäº†å…¶åœ¨å¤šè¯­è¨€å’Œæ–‡åŒ–å¸¸è¯†æ¨ç†æ–¹é¢çš„å±€é™æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ï¼Œå¼ºè°ƒäº†æå‡å¤šè¯­è¨€å¸¸è¯†æ¨ç†èƒ½åŠ›çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½åŠ©æ‰‹å’Œè·¨æ–‡åŒ–äº¤æµç­‰ã€‚é€šè¿‡æä¾›æ›´å‡†ç¡®çš„å¤šè¯­è¨€å¸¸è¯†æ¨ç†è¯„ä¼°ï¼ŒmSCoReèƒ½å¤Ÿå¸®åŠ©æ”¹è¿›è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹èƒ½åŠ›çš„æå‡ï¼ŒmSCoReä¹Ÿå°†ä¸ºè¿›ä¸€æ­¥çš„ç ”ç©¶æä¾›åŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in reasoning-reinforced Large Language Models (LLMs) have shown remarkable capabilities in complex reasoning tasks. However, the mechanism underlying their utilization of different human reasoning skills remains poorly investigated, especially for multilingual commonsense reasoning that involves everyday knowledge across different languages and cultures. To address this gap, we propose a \textbf{M}ultilingual and Scalable Benchmark for \textbf{S}kill-based \textbf{Co}mmonsense \textbf{Re}asoning (\textbf{mSCoRe}). Our benchmark incorporates three key components that are designed to systematically evaluate LLM's reasoning capabilities, including: (1) a novel taxonomy of reasoning skills that enables fine-grained analysis of models' reasoning processes, (2) a robust data synthesis pipeline tailored specifically for commonsense reasoning evaluation, and (3) a complexity scaling framework allowing task difficulty to scale dynamically alongside future improvements in LLM abilities. Extensive experiments on eights state-of-the-art LLMs of varying sizes and training approaches demonstrate that \textbf{mSCoRe} remains significantly challenging for current models, particularly at higher complexity levels. Our results reveal the limitations of such reasoning-reinforced models when confronted with nuanced multilingual general and cultural commonsense. We further provide detailed analysis on the models' reasoning processes, suggesting future directions for improving multilingual commonsense reasoning capabilities.

