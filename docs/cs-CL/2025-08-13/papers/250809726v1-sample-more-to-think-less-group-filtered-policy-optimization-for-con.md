---
layout: default
title: Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning
---

# Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09726" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09726v1</a>
  <a href="https://arxiv.org/pdf/2508.09726.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09726v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09726v1', 'Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vaishnavi Shrivastava, Ahmed Awadallah, Vidhisha Balachandran, Shivam Garg, Harkirat Behl, Dimitris Papailiopoulos

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGFPOä»¥è§£å†³é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„å†—ä½™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿æ–‡æœ¬ç”Ÿæˆ` `å¼ºåŒ–å­¦ä¹ ` `è¯­è¨€æ¨¡å‹` `æ–‡æœ¬ä¼˜åŒ–` `åŠ¨æ€èµ„æºåˆ†é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆé•¿æ–‡æœ¬æ—¶ï¼Œå¾€å¾€ä¼šå‡ºç°å†—ä½™å’Œæ— æ•ˆçš„å¡«å……å†…å®¹ï¼Œå½±å“ç”Ÿæˆæ•ˆç‡ã€‚
2. GFPOé€šè¿‡åœ¨è®­ç»ƒæ—¶é‡‡æ ·æ›´å¤§çš„é—®é¢˜ç»„ï¼Œå¹¶æ ¹æ®å“åº”é•¿åº¦å’Œtokenæ•ˆç‡è¿›è¡Œè¿‡æ»¤ï¼Œä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ã€‚
3. åœ¨å¤šä¸ªSTEMå’Œç¼–ç åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGFPOæ˜¾è‘—å‡å°‘äº†ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½¿ç”¨å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ—¶ï¼Œå¾€å¾€ä¼šä¸ºäº†æé«˜å‡†ç¡®æ€§è€Œå¯¼è‡´ç”Ÿæˆæ–‡æœ¬é•¿åº¦çš„è†¨èƒ€ã€‚å°½ç®¡åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶ï¼Œè¾ƒé•¿çš„å›ç­”æ˜¯åˆç†çš„ï¼Œä½†è®¸å¤šæ–‡æœ¬ä»…ä¸ºâ€œå¡«å……â€ï¼Œå³é‡å¤å’Œå†—é•¿çš„å†…å®¹ï¼Œæœªèƒ½å®è´¨æ€§æ¨è¿›ã€‚æœ¬æ–‡æå‡ºäº†GFPOï¼ˆGroup Filtered Policy Optimizationï¼‰ï¼Œé€šè¿‡åœ¨è®­ç»ƒæœŸé—´å¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œæ›´å¤§ç»„çš„é‡‡æ ·ï¼Œå¹¶åŸºäºå“åº”é•¿åº¦å’Œæ¯ä¸ªtokençš„å¥–åŠ±æ¯”ç‡è¿™ä¸¤ä¸ªå…³é”®æŒ‡æ ‡è¿›è¡Œè¿‡æ»¤ï¼Œä»è€ŒæŠ‘åˆ¶æ–‡æœ¬é•¿åº¦çš„è†¨èƒ€ã€‚GFPOåœ¨Phi-4æ¨ç†æ¨¡å‹ä¸Šï¼Œæ˜¾è‘—å‡å°‘äº†46-71%çš„é•¿åº¦è†¨èƒ€ï¼ŒåŒæ—¶ä¿æŒäº†å‡†ç¡®æ€§ã€‚ä¼˜åŒ–æ¯ä¸ªtokençš„å¥–åŠ±æ¯”ç‡è¿›ä¸€æ­¥å°†é•¿åº¦è†¨èƒ€çš„å‡å°‘æå‡è‡³71-85%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶å‡ºç°çš„å†—é•¿å’Œæ— æ•ˆå¡«å……é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿½æ±‚å‡†ç¡®æ€§æ—¶ï¼Œå¾€å¾€å¯¼è‡´ç”Ÿæˆæ–‡æœ¬é•¿åº¦çš„æ˜¾è‘—è†¨èƒ€ï¼Œå½±å“äº†ç”Ÿæˆæ•ˆç‡å’Œå®ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGFPOçš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åœ¨è®­ç»ƒé˜¶æ®µå¯¹æ¯ä¸ªé—®é¢˜è¿›è¡Œæ›´å¤§ç»„çš„é‡‡æ ·ï¼Œä»è€Œå‡å°‘ç”Ÿæˆæ—¶çš„å†—ä½™å†…å®¹ã€‚é€šè¿‡è¿‡æ»¤å“åº”ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½ç”Ÿæˆæ–‡æœ¬çš„é•¿åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGFPOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯å¯¹é—®é¢˜è¿›è¡Œå¤§è§„æ¨¡é‡‡æ ·ï¼Œå…¶æ¬¡æ˜¯åŸºäºå“åº”é•¿åº¦å’Œtokenæ•ˆç‡è¿›è¡Œè¿‡æ»¤ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹åœ¨è®­ç»ƒæ—¶èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´æœ‰æ•ˆçš„ç”Ÿæˆç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šGFPOçš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡åŠ¨æ€è°ƒæ•´è®­ç»ƒèµ„æºï¼Œé’ˆå¯¹æ›´éš¾çš„é—®é¢˜åˆ†é…æ›´å¤šçš„è®¡ç®—èµ„æºï¼Œä»è€Œæé«˜äº†æ¨¡å‹åœ¨å¤æ‚é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é™æ€è®­ç»ƒæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨GFPOä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬å“åº”é•¿åº¦å’Œtokenæ•ˆç‡çš„æƒé‡è°ƒæ•´ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†ç”Ÿæˆæ–‡æœ¬çš„æœ‰æ•ˆæ€§ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿä¼˜åŒ–ç”Ÿæˆè´¨é‡ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒGFPOå®ç°äº†åœ¨ç”Ÿæˆæ•ˆç‡å’Œå‡†ç¡®æ€§ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GFPOåœ¨Phi-4æ¨ç†æ¨¡å‹ä¸Šå®ç°äº†46-71%çš„é•¿åº¦è†¨èƒ€å‡å°‘ï¼ŒåŒæ—¶ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚ä¼˜åŒ–æ¯ä¸ªtokençš„å¥–åŠ±æ¯”ç‡åï¼Œé•¿åº¦è†¨èƒ€çš„å‡å°‘å¹…åº¦è¿›ä¸€æ­¥æå‡è‡³71-85%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGFPOåœ¨ç”Ÿæˆæ•ˆç‡å’Œå‡†ç¡®æ€§ä¹‹é—´å®ç°äº†æœ‰æ•ˆçš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GFPOçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç”Ÿæˆé•¿æ–‡æœ¬çš„ä»»åŠ¡ä¸­ï¼Œå¦‚æ•™è‚²ã€ç¼–ç¨‹è¾…åŠ©å’Œç§‘å­¦ç ”ç©¶ç­‰ã€‚é€šè¿‡å‡å°‘å†—ä½™å†…å®¹ï¼ŒGFPOèƒ½å¤Ÿæé«˜æ–‡æœ¬ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models trained with reinforcement learning with verifiable rewards tend to trade accuracy for length--inflating response lengths to achieve gains in accuracy. While longer answers may be warranted for harder problems, many tokens are merely "filler": repetitive, verbose text that makes no real progress. We introduce GFPO (Group Filtered Policy Optimization), which curbs this length explosion by sampling larger groups per problem during training and filtering responses to train on based on two key metrics: (1) response length and (2) token efficiency: reward per token ratio. By sampling more at training time, we teach models to think less at inference time. On the Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH, LiveCodeBench) while maintaining accuracy. Optimizing for reward per token further increases reductions in length inflation to 71-85%. We also propose Adaptive Difficulty GFPO, which dynamically allocates more training resources to harder problems based on real-time difficulty estimates, improving the balance between computational efficiency and accuracy especially on difficult questions. GFPO demonstrates that increased training-time compute directly translates to reduced test-time compute--a simple yet effective trade-off for efficient reasoning.

