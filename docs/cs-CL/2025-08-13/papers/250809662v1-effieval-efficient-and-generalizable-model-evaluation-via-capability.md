---
layout: default
title: EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization
---

# EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09662" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09662v1</a>
  <a href="https://arxiv.org/pdf/2508.09662.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09662v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09662v1', 'EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yaoning Wang, Jiahao Ying, Yixin Cao, Yubo Ma, Yugang Jiang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEffiEvalä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­çš„è®¡ç®—æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å‹è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªé€‚åº”é€‰æ‹©` `è¯„ä¼°æ•ˆç‡` `å…¬å¹³æ€§` `ä»£è¡¨æ€§` `è®¡ç®—æœºè§†è§‰` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨¡å‹è¯„ä¼°æ–¹æ³•é€šå¸¸ä¾èµ–äºç»å¯¹æ€§èƒ½æˆ–éœ€è¦å¤§é‡è¯„ä¼°æ•°æ®ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæ¶ˆè€—å·¨å¤§ã€‚
2. EffiEvalæå‡ºäº†ä¸€ç§æ— è®­ç»ƒçš„è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡è‡ªé€‚åº”é€‰æ‹©é«˜è´¨é‡ä»£è¡¨æ€§å­é›†æ¥æé«˜è¯„ä¼°æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEffiEvalåœ¨å¤šä¸ªåŸºå‡†ä¸Šå®ç°äº†ä¸å…¨æ•°æ®é›†è¯„ä¼°ç›¸å½“çš„æ’åä¸€è‡´æ€§ï¼Œä¸”ä»…éœ€ä½¿ç”¨å°‘é‡æ•°æ®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å’Œæ—¥ç›Šå¤šæ ·åŒ–çš„è¯„ä¼°åŸºå‡†çš„å‡ºç°ï¼Œæ¨¡å‹è¯„ä¼°é¢ä¸´ç€æ˜¾è‘—çš„è®¡ç®—æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºEffiEvalï¼Œè¿™æ˜¯ä¸€ç§æ— è®­ç»ƒçš„é«˜æ•ˆåŸºå‡†è¯„ä¼°æ–¹æ³•ï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®å†—ä½™é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒé«˜è¯„ä¼°å¯é æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆæ—¨åœ¨æ»¡è¶³é«˜è´¨é‡è¯„ä¼°çš„ä¸‰ä¸ªå…³é”®æ ‡å‡†ï¼šä»£è¡¨æ€§ã€å…¬å¹³æ€§å’Œå¯è¿ç§»æ€§ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼ŒEffiEvalåŸºäºæ¨¡å‹æ•ˆç”¨æŒ‡æ•°ï¼ˆMUIï¼‰è‡ªé€‚åº”é€‰æ‹©é«˜è´¨é‡çš„ä»£è¡¨æ€§å­é›†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEffiEvalåœ¨å¤šä¸ªå…¬å…±åŸºå‡†å’Œä¸åŒçš„LLMsä¸Šå®ç°äº†ä¸å…¨æ•°æ®é›†è¯„ä¼°çš„å¼ºæ’åä¸€è‡´æ€§ï¼Œä»…ä½¿ç”¨åŸå§‹æ•°æ®çš„ä¸€å°éƒ¨åˆ†ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•çµæ´»ä¸”å¯æ‰©å±•ï¼Œå…è®¸ç”¨æˆ·æ ¹æ®å…·ä½“éœ€æ±‚å¹³è¡¡è¯„ä¼°æ•ˆç‡å’Œä»£è¡¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­çš„è®¡ç®—æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå¤§é‡æ•°æ®å’Œç»å¯¹æ€§èƒ½ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œåå·®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEffiEvalé€šè¿‡æ¨¡å‹æ•ˆç”¨æŒ‡æ•°ï¼ˆMUIï¼‰è‡ªé€‚åº”é€‰æ‹©é«˜è´¨é‡çš„ä»£è¡¨æ€§å­é›†ï¼Œç¡®ä¿è¯„ä¼°çš„ä»£è¡¨æ€§å’Œå…¬å¹³æ€§ï¼ŒåŒæ—¶é¿å…å¯¹æ¨¡å‹æ€§èƒ½çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEffiEvalçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é€‰æ‹©æ¨¡å—ã€è¯„ä¼°æŒ‡æ ‡è®¡ç®—æ¨¡å—å’Œç»“æœåˆ†ææ¨¡å—ã€‚æ•°æ®é€‰æ‹©æ¨¡å—æ ¹æ®MUIè¿›è¡Œæ ·æœ¬é€‰æ‹©ï¼Œè¯„ä¼°æŒ‡æ ‡æ¨¡å—è®¡ç®—æ¨¡å‹æ€§èƒ½ï¼Œç»“æœåˆ†ææ¨¡å—æä¾›è¯„ä¼°ç»“æœçš„å¯è§†åŒ–å’Œè§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šEffiEvalçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„è¯„ä¼°æ–¹æ³•å’Œè‡ªé€‚åº”æ ·æœ¬é€‰æ‹©æœºåˆ¶ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†è¯„ä¼°çš„æ•ˆç‡å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒEffiEvalä½¿ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®æ¥ä¼˜åŒ–MUIçš„è®¡ç®—ï¼Œå¹¶é‡‡ç”¨äº†çµæ´»çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥é€‚åº”ä¸åŒçš„æ•°æ®é›†å’Œæ¨¡å‹å®¶æ—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªå…¬å…±åŸºå‡†ä¸Šï¼ŒEffiEvalå±•ç¤ºäº†ä¸å…¨æ•°æ®é›†è¯„ä¼°ç›¸å½“çš„æ’åä¸€è‡´æ€§ï¼Œä¸”ä»…ä½¿ç”¨åŸå§‹æ•°æ®çš„10%è‡³20%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒEffiEvalåœ¨è¯„ä¼°æ•ˆç‡ä¸Šæœ‰æ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è¯„ä¼°å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EffiEvalçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜è¯„ä¼°æ•ˆç‡å’Œå¯é æ€§ï¼ŒEffiEvalèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´å¿«é€Ÿåœ°è¯„ä¼°å’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid advancement of large language models (LLMs) and the development of increasingly large and diverse evaluation benchmarks have introduced substantial computational challenges for model assessment. In this paper, we present EffiEval, a training-free approach for efficient benchmarking that effectively addresses data redundancy while maintaining high evaluation reliability. Our method is specifically designed to meet three key criteria for high-quality evaluation: representativeness, by ensuring comprehensive coverage of model capabilities; fairness, by remaining independent of model performance during sample selection to avoid bias; and generalizability, by enabling flexible transfer across datasets and model families without reliance on large-scale evaluation data. Unlike traditional methods that rely on absolute performance or require extensive evaluation data, our approach adaptively selects high-quality representative subsets based on the Model Utility Index (MUI). Extensive experiments on multiple public benchmarks and diverse LLMs demonstrate that EffiEval achieves strong ranking consistency with full-dataset evaluation using only a small fraction of the original data. Furthermore, our method is flexible and scalable in size, allowing users to balance evaluation efficiency and representativeness according to specific needs. Overall, EffiEval provides a practical and generalizable solution for reliable, fair, and efficient evaluation in the era of LLMs.

