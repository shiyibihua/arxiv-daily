---
layout: default
title: User-centric Subjective Leaderboard by Customizable Reward Modeling
---

# User-centric Subjective Leaderboard by Customizable Reward Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09463" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09463v1</a>
  <a href="https://arxiv.org/pdf/2508.09463.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09463v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09463v1', 'User-centric Subjective Leaderboard by Customizable Reward Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qi Jia, Xiujie Song, Zicheng Zhang, Yijin Guo, Kaiwei Zhang, Zijian Chen, Guangtao Zhai

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”¨æˆ·ä¸­å¿ƒçš„ä¸»è§‚æ’è¡Œæ¦œä»¥è§£å†³LLMé€‰æ‹©éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”¨æˆ·ä¸­å¿ƒ` `ä¸»è§‚æ’è¡Œæ¦œ` `å¯å®šåˆ¶å¥–åŠ±æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªæ€§åŒ–æ¨è` `äººç±»åå¥½åˆ†æ` `åŠ¨æ€æ’å`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMåŸºå‡†ä¸»è¦ä¾èµ–äºå¯éªŒè¯ä»»åŠ¡ï¼Œéš¾ä»¥æ»¡è¶³ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼Œå¯¼è‡´æ¨¡å‹é€‰æ‹©å›°éš¾ã€‚
2. æå‡ºç”¨æˆ·ä¸­å¿ƒçš„ä¸»è§‚æ’è¡Œæ¦œï¼ˆUSLï¼‰ï¼Œé€šè¿‡å¯¹äººç±»åå¥½çš„æ·±å…¥åˆ†æï¼Œæä¾›åŠ¨æ€çš„æ¨¡å‹æ’åã€‚
3. å¯å®šåˆ¶å¥–åŠ±æ¨¡å‹ï¼ˆCRMsï¼‰åœ¨ä»…æœ‰40äº¿å‚æ•°çš„æƒ…å†µä¸‹ï¼Œè¶…è¶Šäº†ç°æœ‰é¢†å…ˆæ¨¡å‹ï¼Œå±•ç°å‡ºä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŸºå‡†ä¸»è¦é€šè¿‡å¯éªŒè¯ä»»åŠ¡è¯„ä¼°å…¶èƒ½åŠ›ï¼Œè¿™ç§å®¢è§‚é™æ€çš„åŸºå‡†åœ¨å®é™…æ¨¡å‹é€‰æ‹©ä¸­æ•ˆç”¨æœ‰é™ï¼Œéš¾ä»¥æ»¡è¶³ç”¨æˆ·ä¸ªæ€§åŒ–éœ€æ±‚ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†é¦–ä¸ªç”¨æˆ·ä¸­å¿ƒçš„ä¸»è§‚æ’è¡Œæ¦œï¼ˆUSLï¼‰ï¼Œæä¾›åŸºäºåå¥½çš„åŠ¨æ€æ’åï¼Œæ¶µç›–å¤šç§ç°å®åœºæ™¯ã€‚æˆ‘ä»¬çš„ç ”ç©¶åŸºäºå¯¹è¶…è¿‡1ä¸‡æ¡ä¸»è§‚æŸ¥è¯¢çš„æ·±å…¥è°ƒæŸ¥ï¼Œæ­ç¤ºäº†äººç±»åå¥½çš„æ˜¾è‘—å¤šæ ·æ€§å’ŒçŸ›ç›¾æ€§ï¼Œè¿™é™åˆ¶äº†ç°æœ‰å¥–åŠ±æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¯å®šåˆ¶å¥–åŠ±æ¨¡å‹ï¼ˆCRMsï¼‰ï¼Œå…¶å‚æ•°é‡ä»…ä¸º40äº¿ï¼Œæ€§èƒ½è¶…è¶Šäº†GPT-4.1å’ŒGemini-2.5-proï¼Œå±•ç°å‡ºåœ¨æ–°ä¸»é¢˜å’Œæ ‡å‡†ä¸Šçš„å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚USLä¾æ‰˜CRMsï¼Œæ˜¾ç¤ºå‡ºä¸çŸ›ç›¾åå¥½çš„å¼ºè´Ÿç›¸å…³æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åŸºå‡†ä¸»è¦é›†ä¸­åœ¨å¯éªŒè¯ä»»åŠ¡çš„è¯„ä¼°ä¸Šï¼Œè¿™ç§æ–¹æ³•æ— æ³•æœ‰æ•ˆåæ˜ ç”¨æˆ·çš„ä¸ªæ€§åŒ–éœ€æ±‚ï¼Œå¯¼è‡´ç”¨æˆ·åœ¨é€‰æ‹©åˆé€‚æ¨¡å‹æ—¶é¢ä¸´å›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶æå‡ºç”¨æˆ·ä¸­å¿ƒçš„ä¸»è§‚æ’è¡Œæ¦œï¼ˆUSLï¼‰ï¼Œé€šè¿‡åˆ†æçœŸå®çš„äººç±»åå¥½æ•°æ®ï¼Œæ„å»ºåŠ¨æ€çš„æ¨¡å‹æ’åç³»ç»Ÿï¼Œä»¥æ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUSLçš„æ„å»ºåŸºäºå¯¹è¶…è¿‡1ä¸‡æ¡ä¸»è§‚æŸ¥è¯¢çš„è°ƒæŸ¥ï¼Œç»“åˆå¯å®šåˆ¶å¥–åŠ±æ¨¡å‹ï¼ˆCRMsï¼‰ï¼Œå½¢æˆä¸€ä¸ªåŒ…å«æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œæ’åç”Ÿæˆçš„å®Œæ•´æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥å¯å®šåˆ¶å¥–åŠ±æ¨¡å‹ï¼ˆCRMsï¼‰ï¼Œå…¶å‚æ•°é‡ä¸º40äº¿ï¼Œè¶…è¶Šäº†ç°æœ‰çš„é¢†å…ˆæ¨¡å‹ï¼Œå±•ç°å‡ºåœ¨æ–°ä¸»é¢˜å’Œæ ‡å‡†ä¸Šçš„å“è¶Šæ³›åŒ–èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„é™æ€å¥–åŠ±æ¨¡å‹ç›¸æ¯”ï¼ŒCRMsèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç”¨æˆ·çš„å¤šæ ·åŒ–åå¥½ã€‚

**å…³é”®è®¾è®¡**ï¼šCRMsçš„è®¾è®¡åŒ…æ‹¬ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–å¯¹ç”¨æˆ·åå¥½çš„å“åº”èƒ½åŠ›ï¼ŒåŒæ—¶ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ³›åŒ–æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCRMsåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†GPT-4.1å’ŒGemini-2.5-proï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒCRMsåœ¨æ–°ä¸»é¢˜å’Œæ ‡å‡†ä¸Šçš„æ³›åŒ–èƒ½åŠ›è¡¨ç°ä¼˜å¼‚ï¼Œä¸çŸ›ç›¾åå¥½çš„å¼ºè´Ÿç›¸å…³æ€§è¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€å†…å®¹ç”Ÿæˆå’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æä¾›ç”¨æˆ·ä¸­å¿ƒçš„æ¨¡å‹é€‰æ‹©å·¥å…·ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒï¼Œå¸®åŠ©ç”¨æˆ·æ‰¾åˆ°æœ€ç¬¦åˆå…¶éœ€æ±‚çš„è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing benchmarks for large language models (LLMs) predominantely focus on assessing their capabilities through verifiable tasks. Such objective and static benchmarks offer limited utility for practical LLM selection, making it difficult for users to find suitable models for their individual needs. To bridge this gap, we present the first User-Centric Subjective Leaderboard (USL), which provides a preference-driven, dynamic ranking of LLMs across diverse real-world scenarios. Our work is built upon a thorough investigation of real human preference data, involving more than 10K subjective queries. Our investigation reveals significant diversity and contradictions in human preferences, which limit the effectiveness of state-of-the-art reward models. To address this, we introduce Customizable Reward Models (CRMs). With only 4B parameters, our CRM surpasses the performance of leading models such as GPT-4.1 and Gemini-2.5-pro, showing exceptional generalization capabilities across new topics and criteria. The USL, powered by CRMs, exhibits strong negative correlations to contradictory preferences.

