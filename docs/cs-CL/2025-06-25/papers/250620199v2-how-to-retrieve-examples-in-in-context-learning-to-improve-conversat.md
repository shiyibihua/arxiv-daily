---
layout: default
title: How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?
---

# How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20199" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20199v2</a>
  <a href="https://arxiv.org/pdf/2506.20199.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20199v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20199v2', 'How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mengqi Wang, Tiantian Feng, Shrikanth Narayanan

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25 (æ›´æ–°: 2025-06-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç¤ºä¾‹æ£€ç´¢çš„æƒ…æ„Ÿè¯†åˆ«æ–¹æ³•ä»¥æå‡å¯¹è¯æƒ…æ„Ÿè¯†åˆ«æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹è¯æƒ…æ„Ÿè¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤ºä¾‹æ£€ç´¢` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æƒ…æ„Ÿåˆ†æ` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­å‡†ç¡®æ€§ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸»è§‚æ€§è¾ƒå¼ºçš„å¯¹è¯åœºæ™¯ä¸­ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ£€ç´¢é«˜è´¨é‡ç¤ºä¾‹æ¥å¢å¼ºä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œä»è€Œæå‡å¯¹è¯æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¢å¼ºç¤ºä¾‹æ£€ç´¢åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œæå‡äº†æƒ…æ„Ÿè¯†åˆ«çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸçš„å®é™…åº”ç”¨ä¸­å±•ç°å‡ºå¹¿æ³›çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œå°¤å…¶åœ¨æƒ…æ„Ÿè¯†åˆ«ç­‰ä¸»è§‚ä»»åŠ¡ä¸­ï¼Œæ„å»ºé«˜æ€§èƒ½åº”ç”¨ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚å—SLT 2024 GenSERæŒ‘æˆ˜çš„å¯å‘ï¼Œæœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ£€ç´¢é«˜è´¨é‡ç¤ºä¾‹æ¥æ”¹å–„å¯¹è¯æƒ…æ„Ÿè¯†åˆ«ï¼ˆCERï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†åŸºäºéšæœºå’Œå¢å¼ºç¤ºä¾‹æ£€ç´¢çš„å¤šç§ç­–ç•¥ï¼Œå¹¶åˆ†æäº†å¯¹è¯ä¸Šä¸‹æ–‡å¯¹CERå‡†ç¡®æ€§çš„å½±å“ã€‚å®éªŒåœ¨IEMOCAPã€MELDå’ŒEmoryNLPä¸‰ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜å¢å¼ºç¤ºä¾‹æ£€ç´¢åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡ä¼˜äºå…¶ä»–æŠ€æœ¯ï¼Œå¼ºè°ƒäº†æ£€ç´¢ä¸€è‡´æ€§ç›®æ ‡ç¤ºä¾‹å¹¶é€šè¿‡æ”¹å†™å¢å¼ºå…¶é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨å¯¹è¯æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œç¤ºä¾‹è´¨é‡æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¸»è§‚æ€§è¾ƒå¼ºçš„æƒ…æ„Ÿè¯†åˆ«åœºæ™¯ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ£€ç´¢é«˜è´¨é‡çš„ç¤ºä¾‹ï¼Œä»¥æé«˜æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ã€‚é€šè¿‡å¢å¼ºç¤ºä¾‹çš„æ£€ç´¢ç­–ç•¥ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å¯¹è¯ä¸­çš„æƒ…æ„Ÿä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç¤ºä¾‹æ£€ç´¢æ¨¡å—å’Œæƒ…æ„Ÿè¯†åˆ«æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡éšæœºå’Œå¢å¼ºç­–ç•¥æ£€ç´¢ç›¸å…³ç¤ºä¾‹ï¼Œç„¶åå°†è¿™äº›ç¤ºä¾‹è¾“å…¥åˆ°æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å¢å¼ºç¤ºä¾‹æ£€ç´¢ç­–ç•¥ï¼Œè¯¥ç­–ç•¥é€šè¿‡æ”¹å†™å’Œé€‰æ‹©ä¸€è‡´æ€§ç¤ºä¾‹ï¼Œæ˜¾è‘—æé«˜äº†æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†å¤šç§ç¤ºä¾‹æ£€ç´¢ç­–ç•¥ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†å¯¹è¯ä¸Šä¸‹æ–‡çš„å½±å“ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¢å¼ºç¤ºä¾‹æ£€ç´¢åœ¨IEMOCAPã€MELDå’ŒEmoryNLPä¸‰ä¸ªæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºå…¶ä»–æ£€ç´¢æŠ€æœ¯ï¼Œæå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨æƒ…æ„Ÿè¯†åˆ«ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€ç¤¾äº¤æœºå™¨äººå’Œæƒ…æ„Ÿåˆ†æå·¥å…·ç­‰ã€‚é€šè¿‡æå‡å¯¹è¯æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ç”¨æˆ·æƒ…æ„Ÿï¼Œè¿›è€Œæ”¹å–„äººæœºäº¤äº’ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.

