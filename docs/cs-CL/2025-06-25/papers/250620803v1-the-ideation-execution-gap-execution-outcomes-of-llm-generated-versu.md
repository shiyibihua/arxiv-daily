---
layout: default
title: The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas
---

# The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20803" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20803v1</a>
  <a href="https://arxiv.org/pdf/2506.20803.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20803v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20803v1', 'The Ideation-Execution Gap: Execution Outcomes of LLM-Generated versus Human Research Ideas')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenglei Si, Tatsunori Hashimoto, Diyi Yang

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY, cs.HC, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: main paper is 14 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMç”Ÿæˆç ”ç©¶åˆ›æ„ä¸äººç±»åˆ›æ„æ‰§è¡Œç»“æœçš„å·®è·**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç ”ç©¶åˆ›æ„` `æ‰§è¡Œæ•ˆæœ` `ç›²è¯„` `ç§‘å­¦ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶è¡¨æ˜ï¼ŒLLMç”Ÿæˆçš„åˆ›æ„åœ¨æ–°é¢–æ€§ä¸Šä¼˜äºäººç±»åˆ›æ„ï¼Œä½†æ‰§è¡Œæ•ˆæœå´æœªå¾—åˆ°éªŒè¯ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡è®©ä¸“å®¶æ‰§è¡Œéšæœºåˆ†é…çš„åˆ›æ„ï¼Œæ¯”è¾ƒLLMä¸äººç±»åˆ›æ„åœ¨å®é™…ç ”ç©¶ä¸­çš„æ•ˆæœï¼Œæ­ç¤ºå…¶å·®è·ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„åˆ›æ„åœ¨æ‰§è¡Œåçš„è¯„å®¡åˆ†æ•°æ˜¾è‘—ä¸‹é™ï¼Œè¡¨æ˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠ é€Ÿç§‘å­¦ç ”ç©¶æµç¨‹æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆæ–°é¢–ç ”ç©¶åˆ›æ„æ–¹é¢ã€‚ç„¶è€Œï¼Œåˆ›æ„çš„ä»·å€¼ä¸ä»…åœ¨äºå…¶è¡¨é¢æ–°é¢–æ€§ï¼Œæ›´åœ¨äºæ‰§è¡Œåçš„ç ”ç©¶æˆæœã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æ‹›å‹Ÿ43åä¸“å®¶ï¼Œéšæœºåˆ†é…ç”±äººç±»æˆ–LLMç”Ÿæˆçš„åˆ›æ„è¿›è¡Œæ‰§è¡Œã€‚ç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„åˆ›æ„åœ¨æ‰§è¡Œåçš„è¯„å®¡åˆ†æ•°æ˜¾è‘—ä½äºäººç±»åˆ›æ„ï¼Œæ­ç¤ºäº†å½“å‰LLMåœ¨ç”Ÿæˆæœ‰æ•ˆç ”ç©¶åˆ›æ„æ–¹é¢çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³LLMç”Ÿæˆçš„ç ”ç©¶åˆ›æ„åœ¨æ‰§è¡Œåæ•ˆæœä¸ä½³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯„ä¼°åˆ›æ„çš„å®é™…æ‰§è¡Œç»“æœï¼Œå¯¼è‡´å¯¹LLMèƒ½åŠ›çš„è¯¯åˆ¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®©ä¸“å®¶æ‰§è¡Œç”±LLMå’Œäººç±»ç”Ÿæˆçš„åˆ›æ„ï¼Œå¹¶è¿›è¡Œç›²è¯„ï¼Œæ¯”è¾ƒä¸¤è€…åœ¨å®é™…ç ”ç©¶ä¸­çš„è¡¨ç°ï¼Œä»è€Œæ­ç¤ºLLMç”Ÿæˆåˆ›æ„çš„å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬åˆ›æ„ç”Ÿæˆã€ä¸“å®¶æ‰§è¡Œã€å®éªŒè®°å½•å’Œç›²è¯„å››ä¸ªä¸»è¦é˜¶æ®µã€‚æ¯ä½ä¸“å®¶èŠ±è´¹è¶…è¿‡100å°æ—¶å®æ–½åˆ›æ„ï¼Œå¹¶æ’°å†™4é¡µçŸ­æ–‡è®°å½•å®éªŒè¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºé€šè¿‡å®é™…æ‰§è¡Œæ¥è¯„ä¼°åˆ›æ„çš„æœ‰æ•ˆæ€§ï¼Œè€Œéä»…ä¾èµ–äºä¸»è§‚åˆ¤æ–­ã€‚è¿™ä¸€æ–¹æ³•æ­ç¤ºäº†LLMç”Ÿæˆåˆ›æ„åœ¨å®é™…åº”ç”¨ä¸­çš„ä¸è¶³ä¹‹å¤„ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­é‡‡ç”¨äº†éšæœºåˆ†é…åˆ›æ„çš„æ–¹å¼ï¼Œç¡®ä¿è¯„ä¼°çš„å…¬æ­£æ€§ã€‚è¯„å®¡æŒ‡æ ‡åŒ…æ‹¬æ–°é¢–æ€§ã€å…´å¥‹åº¦ã€æœ‰æ•ˆæ€§å’Œæ€»ä½“è¯„åˆ†ï¼Œæ‰€æœ‰è¯„å®¡å‡ç”±ä¸“å®¶è¿›è¡Œç›²è¯„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„åˆ›æ„åœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå¾—åˆ†æ˜¾è‘—ä½äºäººç±»åˆ›æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMç”Ÿæˆçš„åˆ›æ„åœ¨æ‰§è¡Œåçš„è¯„å®¡åˆ†æ•°æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨æ–°é¢–æ€§ã€å…´å¥‹åº¦å’Œæœ‰æ•ˆæ€§ç­‰æŒ‡æ ‡ä¸Šï¼Œå¾—åˆ†ä¸‹é™å¹…åº¦è¶…è¿‡äººç±»åˆ›æ„ï¼Œä¸”åœ¨è®¸å¤šæŒ‡æ ‡ä¸Šæ’åå‘ç”Ÿç¿»è½¬ï¼Œæ˜¾ç¤ºå‡ºäººç±»åˆ›æ„çš„ä¼˜åŠ¿ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†LLMåœ¨ç”Ÿæˆæœ‰æ•ˆç ”ç©¶åˆ›æ„æ–¹é¢çš„å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„ç»“æœå¯¹ç§‘å­¦ç ”ç©¶é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨åˆ©ç”¨AIè¾…åŠ©åˆ›æ„ç”Ÿæˆæ—¶ã€‚é€šè¿‡æ­ç¤ºLLMç”Ÿæˆåˆ›æ„çš„å±€é™æ€§ï¼Œç ”ç©¶è€…å¯ä»¥æ›´å¥½åœ°ç†è§£å¦‚ä½•ç»“åˆäººç±»æ™ºæ…§ä¸AIå·¥å…·ï¼Œä»è€Œæé«˜ç ”ç©¶æˆæœçš„è´¨é‡å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œç ”ç©¶è€…å¯ä»¥æ¢ç´¢æ”¹è¿›LLMç”Ÿæˆåˆ›æ„çš„ç­–ç•¥ï¼Œä»¥ç¼©å°åˆ›æ„ç”Ÿæˆä¸æ‰§è¡Œä¹‹é—´çš„å·®è·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown promise in accelerating the scientific research pipeline. A key capability for this process is the ability to generate novel research ideas, and prior studies have found settings in which LLM-generated research ideas were judged as more novel than human-expert ideas. However, a good idea should not simply appear to be novel, it should also result in better research after being executed. To test whether AI-generated ideas lead to better research outcomes, we conduct an execution study by recruiting 43 expert researchers to execute randomly-assigned ideas, either written by experts or generated by an LLM. Each expert spent over 100 hours implementing the idea and wrote a 4-page short paper to document the experiments. All the executed projects are then reviewed blindly by expert NLP researchers. Comparing the review scores of the same ideas before and after execution, the scores of the LLM-generated ideas decrease significantly more than expert-written ideas on all evaluation metrics (novelty, excitement, effectiveness, and overall; p < 0.05), closing the gap between LLM and human ideas observed at the ideation stage. When comparing the aggregated review scores from the execution study, we even observe that for many metrics there is a flip in rankings where human ideas score higher than LLM ideas. This ideation-execution gap highlights the limitations of current LLMs in generating truly effective research ideas and the challenge of evaluating research ideas in the absence of execution outcomes.

