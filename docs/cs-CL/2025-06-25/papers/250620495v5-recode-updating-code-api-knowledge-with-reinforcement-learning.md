---
layout: default
title: ReCode: Updating Code API Knowledge with Reinforcement Learning
---

# ReCode: Updating Code API Knowledge with Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20495" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20495v5</a>
  <a href="https://arxiv.org/pdf/2506.20495.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20495v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20495v5', 'ReCode: Updating Code API Knowledge with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoze Wu, Yunzhi Yao, Wenhao Yu, Ningyu Zhang

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR, cs.LG, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25 (æ›´æ–°: 2025-11-23)

**å¤‡æ³¨**: AAAI 2026

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zjunlp/ReCode)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReCodeæ¡†æ¶ä»¥è§£å†³LLMsåœ¨APIæ›´æ–°ä¸­çš„é€‚åº”æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç ç”Ÿæˆ` `APIæ›´æ–°` `å¼ºåŒ–å­¦ä¹ ` `ç‰ˆæœ¬è¿ç§»` `ä»£ç è¯„ä¼°` `åŠ¨æ€ç¯å¢ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹å¤–éƒ¨åº“APIçš„é¢‘ç¹æ›´æ–°æ—¶ï¼Œæ— æ³•æœ‰æ•ˆé€‚åº”ï¼Œå¯¼è‡´ä»£ç ç”Ÿæˆçš„å¯é æ€§ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºReCodeæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºè®­ç»ƒé›†å’Œå¼•å…¥æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œæ¨¡æ‹Ÿäººç±»ç¨‹åºå‘˜å¯¹APIå˜åŒ–çš„é€‚åº”èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReCodeåœ¨å¤šä¸ªLLMså’Œå¼ºåŒ–å­¦ä¹ ç®—æ³•ä¸Šå‡å®ç°äº†æ€§èƒ½æå‡ï¼Œç‰¹åˆ«æ˜¯åœ¨CodeUpdateArenaä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é€‚åº”å¤–éƒ¨åº“APIçš„é¢‘ç¹æ›´æ–°æ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚è¿™ä¸€é—®é¢˜æºäºå®ƒä»¬ä¾èµ–äºè¿‡æ—¶çš„APIçŸ¥è¯†ï¼Œå³ä½¿èƒ½å¤Ÿè®¿é—®å½“å‰æ–‡æ¡£ï¼Œä¹Ÿä¼šå½±å“åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„å¯é ä»£ç ç”Ÿæˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ReCodeï¼ˆåŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ ä»£ç æ›´æ–°æ¡†æ¶ï¼‰ï¼Œè¯¥æ¡†æ¶æ¨¡æ‹Ÿäººç±»ç¨‹åºå‘˜å¯¹APIå˜åŒ–çš„é€‚åº”ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«çº¦2000æ¡æ•°æ®çš„è®­ç»ƒé›†ï¼Œä½¿LLMsèƒ½å¤ŸåŸºäºæ›´æ–°ä¿¡æ¯è¿›è¡Œç‰ˆæœ¬è¿ç§»ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ä¿®æ”¹åçš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦åº¦é‡ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±ã€‚å®éªŒè¡¨æ˜ï¼ŒReCodeæ˜¾è‘—æå‡äº†LLMsåœ¨åŠ¨æ€APIåœºæ™¯ä¸‹çš„ä»£ç ç”Ÿæˆæ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨æœªè§è¿‡çš„CodeUpdateArenaä»»åŠ¡ä¸Šã€‚ä¸ç›‘ç£å¾®è°ƒç›¸æ¯”ï¼ŒReCodeå¯¹LLMsçš„é€šç”¨ä»£ç ç”Ÿæˆèƒ½åŠ›å½±å“è¾ƒå°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŠ¨æ€APIç¯å¢ƒä¸­ä»£ç ç”Ÿæˆèƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºè¿‡æ—¶çš„APIçŸ¥è¯†ï¼Œæ— æ³•æœ‰æ•ˆé€‚åº”é¢‘ç¹çš„APIæ›´æ–°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReCodeæ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿäººç±»ç¨‹åºå‘˜å¯¹APIå˜åŒ–çš„é€‚åº”è¿‡ç¨‹ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ¥æ›´æ–°æ¨¡å‹çš„APIçŸ¥è¯†ï¼Œä»è€Œæå‡ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReCodeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒå’Œä»£ç è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«2000æ¡æ•°æ®çš„è®­ç»ƒé›†ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼›æœ€åï¼Œä½¿ç”¨ä¿®æ”¹åçš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦åº¦é‡è¿›è¡Œä»£ç è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šReCodeçš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å¼ºåŒ–å­¦ä¹ æœºåˆ¶æ¥æ›´æ–°APIçŸ¥è¯†ï¼Œå¹¶è®¾è®¡äº†æ–°çš„ä»£ç è¯„ä¼°æŒ‡æ ‡ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ å¾®è°ƒæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´çµæ´»åœ°é€‚åº”APIçš„å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶æ¥è¯„ä¼°ä»£ç ç”Ÿæˆçš„è´¨é‡ï¼Œé‡‡ç”¨äº†GRPOå’ŒDAPOç­‰å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ€§èƒ½æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReCodeæ˜¾è‘—æå‡äº†LLMsåœ¨åŠ¨æ€APIåœºæ™¯ä¸‹çš„ä»£ç ç”Ÿæˆæ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨CodeUpdateArenaä»»åŠ¡ä¸­ï¼ŒQwen2.5-Coder-7Bæ¨¡å‹çš„è¡¨ç°è¶…è¶Šäº†32Bå‚æ•°çš„ä»£ç æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹ï¼Œå±•ç¤ºäº†å¼ºåŒ–å­¦ä¹ åœ¨ä»£ç æ›´æ–°ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReCodeæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦é¢‘ç¹æ›´æ–°APIçš„å¼€å‘ç¯å¢ƒï¼Œå¦‚è½¯ä»¶å¼€å‘ã€è‡ªåŠ¨åŒ–æµ‹è¯•å’Œæ™ºèƒ½ç¼–ç¨‹åŠ©æ‰‹ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼ŒReCodeèƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒå¼€å‘è€…åœ¨å¿«é€Ÿå˜åŒ–çš„æŠ€æœ¯ç¯å¢ƒä¸­ä¿æŒé«˜æ•ˆç”Ÿäº§åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at https://github.com/zjunlp/ReCode.

