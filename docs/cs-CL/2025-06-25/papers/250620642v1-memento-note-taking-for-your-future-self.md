---
layout: default
title: Memento: Note-Taking for Your Future Self
---

# Memento: Note-Taking for Your Future Self

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20642" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20642v1</a>
  <a href="https://arxiv.org/pdf/2506.20642.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20642v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20642v1', 'Memento: Note-Taking for Your Future Self')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Wan, Albert Gong, Mihir Mishra, Carl-Leander Henneking, Claas Beger, Kilian Q. Weinberger

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMementoä»¥è§£å†³å¤šè·³é—®ç­”ä¸­çš„æ¨ç†ä¸æ£€ç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šè·³é—®ç­”` `ä¿¡æ¯æ£€ç´¢` `æ¨ç†ç­–ç•¥` `åŠ¨æ€æ•°æ®åº“` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šè·³é—®ç­”ä¸­éš¾ä»¥æœ‰æ•ˆç»“åˆæ¨ç†ä¸ä¿¡æ¯æ£€ç´¢ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. Mementoé€šè¿‡å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå°æ­¥éª¤ï¼ŒåŠ¨æ€æ„å»ºäº‹å®æ•°æ®åº“ï¼Œæå‡äº†é—®ç­”èƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMementoæ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå¦‚åœ¨PhantomWikiåŸºå‡†ä¸Šæ€§èƒ½ç¿»å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»…ä¾èµ–æ¨ç†çš„ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨æ¨ç†ä¸æ£€ç´¢ç´§å¯†ç»“åˆçš„å¤šè·³é—®ç­”ä¸­å´é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æç¤ºç­–ç•¥Mementoï¼Œè¯¥ç­–ç•¥é¦–å…ˆå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°çš„æ­¥éª¤ï¼Œç„¶ååŠ¨æ€æ„å»ºäº‹å®æ•°æ®åº“ï¼Œæœ€åå°†è¿™äº›äº‹å®ç»„åˆèµ·æ¥ä»¥è§£å†³é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMementoåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†ç°æœ‰æç¤ºç­–ç•¥çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè·³é—®ç­”ä¸­æ¨ç†ä¸æ£€ç´¢ç»“åˆä¸ä½³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆæ‰€éœ€ä¿¡æ¯ï¼Œå¯¼è‡´å›ç­”å‡†ç¡®æ€§é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMementoçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªå°æ­¥éª¤ï¼Œé€šè¿‡åŠ¨æ€æ„å»ºäº‹å®æ•°æ®åº“æ¥æ”¯æŒæ¨ç†è¿‡ç¨‹ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜å›ç­”çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMementoçš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯å°†å¤æ‚é—®é¢˜åˆ†è§£ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯åˆ©ç”¨LLMsåŠ¨æ€æ„å»ºäº‹å®æ•°æ®åº“ï¼›ç¬¬ä¸‰é˜¶æ®µæ˜¯å°†æ”¶é›†åˆ°çš„äº‹å®æ•´åˆä»¥å¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMementoçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸‰é˜¶æ®µçš„å¤„ç†æµç¨‹ï¼Œæ˜¾è‘—åŒºåˆ«äºä¼ ç»Ÿçš„é“¾å¼æ¨ç†æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å¤šè·³é—®ç­”ä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼ŒMementoé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨åŠ¨æ€æ„å»ºäº‹å®æ—¶çš„è¡¨ç°ï¼Œç¡®ä¿ä¿¡æ¯çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨9æ­¥çš„PhantomWikiåŸºå‡†æµ‹è¯•ä¸­ï¼ŒMementoä½¿å¾—é“¾å¼æ¨ç†çš„æ€§èƒ½ç¿»å€ã€‚åœ¨å¼€æ”¾åŸŸçš„2WikiMultiHopQAä¸­ï¼ŒMementoä½¿å¾—CoT-RAGçš„F1å¾—åˆ†æå‡è¶…è¿‡20ä¸ªç™¾åˆ†ç‚¹ï¼Œç›¸è¾ƒäºå¤šè·³RAGåŸºçº¿IRCoTæå‡è¶…è¿‡13ä¸ªç™¾åˆ†ç‚¹ã€‚åœ¨MuSiQueæ•°æ®é›†ä¸Šï¼ŒMementoä½¿ReActçš„F1å¾—åˆ†æå‡è¶…è¿‡3ä¸ªç™¾åˆ†ç‚¹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ä»£ç†è®¾ç½®ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mementoçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢ã€æ•™è‚²è¾…åŠ©å·¥å…·ç­‰ã€‚é€šè¿‡æå‡å¤šè·³é—®ç­”çš„å‡†ç¡®æ€§ï¼ŒMementoèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°è·å–ä¿¡æ¯ï¼Œä¿ƒè¿›çŸ¥è¯†çš„ä¼ æ’­ä¸å­¦ä¹ ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) excel at reasoning-only tasks, but struggle when reasoning must be tightly coupled with retrieval, as in multi-hop question answering. To overcome these limitations, we introduce a prompting strategy that first decomposes a complex question into smaller steps, then dynamically constructs a database of facts using LLMs, and finally pieces these facts together to solve the question. We show how this three-stage strategy, which we call Memento, can boost the performance of existing prompting strategies across diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the performance of chain-of-thought (CoT) when all information is provided in context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1 percentage points, demonstrating its utility in agentic settings.

