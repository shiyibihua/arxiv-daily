---
layout: default
title: Fingerprinting LLMs via Prompt Injection
---

# Fingerprinting LLMs via Prompt Injection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25448" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25448v2</a>
  <a href="https://arxiv.org/pdf/2509.25448.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25448v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25448v2', 'Fingerprinting LLMs via Prompt Injection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuepeng Hu, Zhengyuan Jiang, Mengyuan Li, Osama Ahmed, Zhicong Huang, Cheng Hong, Neil Gong

**åˆ†ç±»**: cs.CR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29 (æ›´æ–°: 2025-10-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LLMPrintï¼šåˆ©ç”¨Promptæ³¨å…¥ä¸ºLLMæ„å»ºé²æ£’æŒ‡çº¹ï¼Œå®ç°æ¨¡å‹æº¯æº**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨¡å‹æº¯æº` `Promptæ³¨å…¥` `æ¨¡å‹æŒ‡çº¹` `åå¤„ç†é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMæº¯æºæ–¹æ³•ä¾èµ–äºé¢„å…ˆåµŒå…¥æ°´å°æˆ–ä½¿ç”¨éšæœºpromptï¼Œå‰è€…æ— æ³•åº”ç”¨äºå·²å‘å¸ƒæ¨¡å‹ï¼Œåè€…å¯¹åå¤„ç†é²æ£’æ€§å·®ã€‚
2. LLMPrintåˆ©ç”¨promptæ³¨å…¥æ¼æ´ï¼Œé€šè¿‡ä¼˜åŒ–promptæ¥è¯±å¯¼æ¨¡å‹äº§ç”Ÿç‰¹å®šçš„tokenåå¥½ï¼Œä»¥æ­¤æ„å»ºå¯¹åå¤„ç†é²æ£’çš„æŒ‡çº¹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMPrintåœ¨å¤šç§æ¨¡å‹å’Œåå¤„ç†å˜ä½“ä¸Šå®ç°äº†é«˜çœŸé˜³æ€§ç‡å’Œä½å‡é˜³æ€§ç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å‘å¸ƒåé€šå¸¸ä¼šç»è¿‡åå¤„ç†ï¼Œå¦‚åè®­ç»ƒæˆ–é‡åŒ–ï¼Œè¿™ä½¿å¾—ç¡®å®šä¸€ä¸ªæ¨¡å‹æ˜¯å¦æºè‡ªå¦ä¸€ä¸ªæ¨¡å‹å˜å¾—å›°éš¾ã€‚ç°æœ‰çš„æº¯æºæ£€æµ‹æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦é™åˆ¶ï¼šï¼ˆ1ï¼‰å®ƒä»¬åœ¨å‘å¸ƒå‰å°†ä¿¡å·åµŒå…¥åˆ°åŸºç¡€æ¨¡å‹ä¸­ï¼Œè¿™å¯¹äºå·²å‘å¸ƒçš„æ¨¡å‹æ˜¯ä¸å¯è¡Œçš„ï¼›ï¼ˆ2ï¼‰å®ƒä»¬ä½¿ç”¨æ‰‹å·¥åˆ¶ä½œæˆ–éšæœºæç¤ºæ¯”è¾ƒæ¨¡å‹ä¹‹é—´çš„è¾“å‡ºï¼Œè¿™å¯¹äºåå¤„ç†ä¸å…·æœ‰é²æ£’æ€§ã€‚æœ¬æ–‡æå‡ºäº†LLMPrintï¼Œä¸€ç§æ–°é¢–çš„æ£€æµ‹æ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨LLMå›ºæœ‰çš„Promptæ³¨å…¥æ¼æ´æ¥æ„å»ºæŒ‡çº¹ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ä¼˜åŒ–æŒ‡çº¹æç¤ºæ¥å¼ºåˆ¶æ‰§è¡Œä¸€è‡´çš„tokenåå¥½ï¼Œä»è€Œè·å¾—å¯¹åŸºç¡€æ¨¡å‹ç‹¬ç‰¹ä¸”å¯¹åå¤„ç†å…·æœ‰é²æ£’æ€§çš„æŒ‡çº¹ã€‚è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§é€‚ç”¨äºç°ç›’å’Œé»‘ç›’è®¾ç½®çš„ç»Ÿä¸€éªŒè¯ç¨‹åºï¼Œå¹¶å…·æœ‰ç»Ÿè®¡ä¿è¯ã€‚åœ¨äº”ä¸ªåŸºç¡€æ¨¡å‹å’Œå¤§çº¦700ä¸ªåè®­ç»ƒæˆ–é‡åŒ–å˜ä½“ä¸Šè¯„ä¼°äº†LLMPrintã€‚ç»“æœè¡¨æ˜ï¼ŒLLMPrintå®ç°äº†é«˜çœŸé˜³æ€§ç‡ï¼ŒåŒæ—¶ä¿æŒå‡é˜³æ€§ç‡æ¥è¿‘äºé›¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æº¯æºé—®é¢˜ï¼Œå³åˆ¤æ–­ä¸€ä¸ªç»è¿‡åå¤„ç†ï¼ˆå¦‚é‡åŒ–ã€å¾®è°ƒï¼‰çš„æ¨¡å‹æ˜¯å¦è¡ç”Ÿè‡ªæŸä¸ªå·²çŸ¥çš„åŸå§‹æ¨¡å‹ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼Œè¦ä¹ˆéœ€è¦é¢„å…ˆåœ¨åŸå§‹æ¨¡å‹ä¸­åµŒå…¥æ°´å°ï¼ˆä¸é€‚ç”¨äºå·²å‘å¸ƒæ¨¡å‹ï¼‰ï¼Œè¦ä¹ˆä½¿ç”¨éšæœºæˆ–æ‰‹å·¥è®¾è®¡çš„promptè¿›è¡Œæ¯”å¯¹ï¼Œä½†è¿™äº›promptå¯¹åå¤„ç†çš„é²æ£’æ€§è¾ƒå·®ï¼Œå®¹æ˜“å—åˆ°å¹²æ‰°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMå¯¹promptæ³¨å…¥çš„è„†å¼±æ€§ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„promptï¼Œè¯±å¯¼æ¨¡å‹äº§ç”Ÿç‰¹å®šçš„ã€å…·æœ‰åŒºåˆ†æ€§çš„tokenåå¥½ã€‚è¿™äº›tokenåå¥½å¯ä»¥ä½œä¸ºæ¨¡å‹çš„â€œæŒ‡çº¹â€ï¼Œå³ä½¿ç»è¿‡åå¤„ç†ï¼Œè¿™äº›æŒ‡çº¹ä»ç„¶ç›¸å¯¹ç¨³å®šã€‚é€šè¿‡æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æŒ‡çº¹ï¼Œå¯ä»¥åˆ¤æ–­å®ƒä»¬æ˜¯å¦å…·æœ‰ç›¸åŒçš„æ¥æºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLMPrintæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šæŒ‡çº¹ç”Ÿæˆé˜¶æ®µå’ŒæŒ‡çº¹éªŒè¯é˜¶æ®µã€‚åœ¨æŒ‡çº¹ç”Ÿæˆé˜¶æ®µï¼Œé’ˆå¯¹æ¯ä¸ªåŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡ä¼˜åŒ–ç®—æ³•ç”Ÿæˆä¸€ç»„ç‰¹å®šçš„promptï¼Œè¿™äº›promptèƒ½å¤Ÿè¯±å¯¼æ¨¡å‹äº§ç”Ÿç‰¹å®šçš„tokenåºåˆ—ã€‚åœ¨æŒ‡çº¹éªŒè¯é˜¶æ®µï¼Œå¯¹äºå¾…éªŒè¯çš„æ¨¡å‹ï¼Œä½¿ç”¨ç›¸åŒçš„promptï¼Œè§‚å¯Ÿå…¶äº§ç”Ÿçš„tokenåºåˆ—ï¼Œå¹¶ä¸åŸºç¡€æ¨¡å‹çš„æŒ‡çº¹è¿›è¡Œæ¯”å¯¹ï¼Œä»è€Œåˆ¤æ–­å…¶æ˜¯å¦è¡ç”Ÿè‡ªè¯¥åŸºç¡€æ¨¡å‹ã€‚è¯¥æ¡†æ¶åŒæ—¶æ”¯æŒç°ç›’å’Œé»‘ç›’åœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨promptæ³¨å…¥æ¼æ´æ¥æ„å»ºæ¨¡å‹çš„æŒ‡çº¹ã€‚ä¸ä¼ ç»Ÿçš„æ°´å°æ–¹æ³•ä¸åŒï¼ŒLLMPrintä¸éœ€è¦é¢„å…ˆä¿®æ”¹æ¨¡å‹ï¼Œå› æ­¤å¯ä»¥åº”ç”¨äºå·²å‘å¸ƒçš„æ¨¡å‹ã€‚ä¸éšæœºpromptæ–¹æ³•ä¸åŒï¼ŒLLMPrinté€šè¿‡ä¼˜åŒ–promptæ¥æœ€å¤§åŒ–tokenåå¥½çš„ä¸€è‡´æ€§ï¼Œä»è€Œæé«˜æŒ‡çº¹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæŒ‡çº¹ç”Ÿæˆé˜¶æ®µçš„å…³é”®åœ¨äºpromptçš„ä¼˜åŒ–ç®—æ³•ã€‚è®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºæ¢¯åº¦ä¸‹é™çš„ä¼˜åŒ–æ–¹æ³•ï¼Œç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ç»„promptï¼Œä½¿å¾—æ¨¡å‹åœ¨è¿™äº›promptä¸‹äº§ç”Ÿç‰¹å®štokenåºåˆ—çš„æ¦‚ç‡æœ€å¤§åŒ–ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ç§ç»Ÿè®¡éªŒè¯æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°ä¸¤ä¸ªæ¨¡å‹æŒ‡çº¹ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå¹¶ç»™å‡ºç»Ÿè®¡æ˜¾è‘—æ€§ä¿è¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LLMPrintåœ¨äº”ä¸ªåŸºç¡€æ¨¡å‹å’Œçº¦700ä¸ªåå¤„ç†å˜ä½“ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®ç°äº†æ¥è¿‘100%çš„çœŸé˜³æ€§ç‡ï¼ŒåŒæ—¶ä¿æŒå‡é˜³æ€§ç‡æ¥è¿‘äºé›¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMPrintå¯¹é‡åŒ–å’Œåè®­ç»ƒç­‰åå¤„ç†æ–¹æ³•å…·æœ‰å¾ˆå¼ºçš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«è¡ç”Ÿæ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LLMPrintå¯ç”¨äºæ£€æµ‹æ¶æ„æ¨¡å‹æŠ„è¢­ã€éªŒè¯æ¨¡å‹æ¥æºã€é˜²æ­¢æœªç»æˆæƒçš„æ¨¡å‹ä¿®æ”¹å’Œåˆ†å‘ã€‚åœ¨æ¨¡å‹å®‰å…¨å’ŒçŸ¥è¯†äº§æƒä¿æŠ¤æ–¹é¢å…·æœ‰é‡è¦åº”ç”¨ä»·å€¼ã€‚æœªæ¥å¯æ‰©å±•åˆ°æ›´å¹¿æ³›çš„AIæ¨¡å‹æº¯æºå’Œå®‰å…¨å®¡è®¡é¢†åŸŸï¼Œä¿ƒè¿›AIæŠ€æœ¯çš„å¥åº·å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are often modified after release through post-processing such as post-training or quantization, which makes it challenging to determine whether one model is derived from another. Existing provenance detection methods have two main limitations: (1) they embed signals into the base model before release, which is infeasible for already published models, or (2) they compare outputs across models using hand-crafted or random prompts, which are not robust to post-processing. In this work, we propose LLMPrint, a novel detection framework that constructs fingerprints by exploiting LLMs' inherent vulnerability to prompt injection. Our key insight is that by optimizing fingerprint prompts to enforce consistent token preferences, we can obtain fingerprints that are both unique to the base model and robust to post-processing. We further develop a unified verification procedure that applies to both gray-box and black-box settings, with statistical guarantees. We evaluate LLMPrint on five base models and around 700 post-trained or quantized variants. Our results show that LLMPrint achieves high true positive rates while keeping false positive rates near zero.

