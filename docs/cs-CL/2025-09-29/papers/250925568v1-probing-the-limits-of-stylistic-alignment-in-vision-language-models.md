---
layout: default
title: Probing the Limits of Stylistic Alignment in Vision-Language Models
---

# Probing the Limits of Stylistic Alignment in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25568" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25568v1</a>
  <a href="https://arxiv.org/pdf/2509.25568.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25568v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25568v1', 'Probing the Limits of Stylistic Alignment in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Asma Farajidizaji, Akash Gupta, Vatsal Raina

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: 5 pages, 1 figure, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è§†è§‰-è¯­è¨€æ¨¡å‹é£æ ¼å¯¹é½çš„æé™ï¼Œæ¢ç´¢å¹½é»˜å’Œæµªæ¼«é£æ ¼æ‰€éœ€çš„æœ€å°‘åå¥½æ•°æ®ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `é£æ ¼å¯¹é½` `æ•°æ®æ•ˆç‡` `åå¥½å­¦ä¹ ` `å›¾åƒæè¿°ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é£æ ¼åŒ–å›¾åƒæè¿°ç”Ÿæˆæ–¹é¢é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡æ•°æ®æ•ˆç‡åˆ†æï¼Œæ¢ç´¢äº†ä½¿ç”¨å°‘é‡åå¥½æ•°æ®å¯¹é½è§†è§‰-è¯­è¨€æ¨¡å‹åˆ°ç‰¹å®šé£æ ¼çš„å¯è¡Œæ€§ã€‚
3. é€šè¿‡å¯¹å¹½é»˜å’Œæµªæ¼«é£æ ¼çš„å®éªŒï¼Œè¯„ä¼°äº†æ¨¡å‹åœ¨é£æ ¼å¯¹é½æ–¹é¢çš„æ€§èƒ½æé™å’Œæ•°æ®éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼ï¼ˆå¦‚å¹½é»˜æˆ–æµªæ¼«ï¼‰çš„å›¾åƒæè¿°ã€‚ç„¶è€Œï¼Œè¿™äº›åŸºäºTransformerçš„æ¨¡å‹åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼Œé€šå¸¸éš¾ä»¥èƒœä»»è¿™ç§ä¸»è§‚ä»»åŠ¡ã€‚è™½ç„¶åå¥½æ•°æ®å¯ä»¥ç”¨äºå°†å®ƒä»¬å¯¹é½åˆ°æœŸæœ›çš„é£æ ¼ï¼Œä½†è·å–è¿™äº›æ•°æ®çš„æˆæœ¬å¾ˆé«˜ï¼Œé™åˆ¶äº†æ¢ç´¢æ¨¡å‹å…¨éƒ¨èƒ½åŠ›çš„å¯èƒ½æ€§ã€‚æœ¬æ–‡é€šè¿‡ç ”ç©¶å°†å°å‹è§†è§‰-è¯­è¨€æ¨¡å‹å¯¹é½åˆ°å¹½é»˜å’Œæµªæ¼«é£æ ¼çš„æ•°æ®æ•ˆç‡æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚è¿™ç§æ–¹æ³•æœ‰åŠ©äºå®šä¹‰è¿™äº›æ¨¡å‹çš„æ€§èƒ½æé™ï¼Œå¹¶ç¡®å®šå®ç°é£æ ¼é¥±å’Œæ‰€éœ€çš„æœ€å°‘åå¥½æ•°æ®ï¼Œä»è€Œå¯¹å®ƒä»¬çš„èƒ½åŠ›å’Œå±€é™æ€§è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆç‰¹å®šé£æ ¼ï¼ˆå¦‚å¹½é»˜æˆ–æµªæ¼«ï¼‰å›¾åƒæè¿°æ—¶ï¼Œå¯¹å¤§é‡é£æ ¼åå¥½æ•°æ®ä¾èµ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®æ‰èƒ½ä½¿æ¨¡å‹ç”Ÿæˆç¬¦åˆç‰¹å®šé£æ ¼çš„æè¿°ï¼Œè¿™é™åˆ¶äº†æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹çš„åº”ç”¨ï¼Œå¹¶ä¸”éš¾ä»¥æ¢ç´¢æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›ä¸Šé™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç ”ç©¶æ•°æ®æ•ˆç‡ï¼Œå³ä½¿ç”¨å°½å¯èƒ½å°‘çš„åå¥½æ•°æ®æ¥å¯¹é½è§†è§‰-è¯­è¨€æ¨¡å‹åˆ°ç›®æ ‡é£æ ¼ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒæ•°æ®é‡ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼Œç¡®å®šæ¨¡å‹è¾¾åˆ°é£æ ¼é¥±å’Œæ‰€éœ€çš„æœ€å°æ•°æ®é‡ï¼Œä»è€Œè¯„ä¼°æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›æé™ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨é™ä½é£æ ¼å¯¹é½çš„æˆæœ¬ï¼Œå¹¶æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å†…åœ¨èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å°å‹è§†è§‰-è¯­è¨€æ¨¡å‹ä½œä¸ºå®éªŒå¯¹è±¡ï¼Œå¹¶ä½¿ç”¨åå¥½æ•°æ®è¿›è¡Œé£æ ¼å¯¹é½ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼›2) æ„å»ºæˆ–æ”¶é›†å¹½é»˜å’Œæµªæ¼«é£æ ¼çš„å›¾åƒæè¿°åå¥½æ•°æ®é›†ï¼›3) ä½¿ç”¨ä¸åŒæ•°é‡çš„åå¥½æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼›4) è¯„ä¼°æ¨¡å‹åœ¨é£æ ¼åŒ–å›¾åƒæè¿°ç”Ÿæˆæ–¹é¢çš„æ€§èƒ½ï¼Œå¹¶åˆ†ææ•°æ®æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹è§†è§‰-è¯­è¨€æ¨¡å‹é£æ ¼å¯¹é½çš„æ•°æ®æ•ˆç‡è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä¸ä»¥å¾€å…³æ³¨æ¨¡å‹ç»“æ„æˆ–è®­ç»ƒæ–¹æ³•çš„ç ”ç©¶ä¸åŒï¼Œè¯¥ç ”ç©¶ä¾§é‡äºæ¢ç´¢æ•°æ®é‡å¯¹é£æ ¼å¯¹é½æ€§èƒ½çš„å½±å“ï¼Œä»è€Œæ­ç¤ºäº†æ¨¡å‹åœ¨é£æ ¼åŒ–æ–¹é¢çš„å†…åœ¨å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡å›¾åƒæè¿°çš„é£æ ¼åŒ–ç¨‹åº¦ï¼Œä¾‹å¦‚ä½¿ç”¨é£æ ¼åˆ†ç±»å™¨æˆ–äººå·¥è¯„ä¼°ï¼›2) è®¾è®¡å®éªŒæ–¹æ¡ˆï¼Œç³»ç»Ÿåœ°æ”¹å˜åå¥½æ•°æ®çš„æ•°é‡ï¼Œå¹¶è§‚å¯Ÿæ¨¡å‹æ€§èƒ½çš„å˜åŒ–ï¼›3) åˆ†ææ¨¡å‹åœ¨ä¸åŒæ•°æ®é‡ä¸‹çš„å­¦ä¹ æ›²çº¿ï¼Œç¡®å®šé£æ ¼é¥±å’Œç‚¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡å®éªŒç¡®å®šäº†å°å‹è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¹½é»˜å’Œæµªæ¼«é£æ ¼å¯¹é½æ–¹é¢çš„æ•°æ®æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨è¾¾åˆ°é£æ ¼é¥±å’Œç‚¹ä¹‹å‰ï¼Œåªéœ€è¦ç›¸å¯¹è¾ƒå°‘çš„åå¥½æ•°æ®ã€‚è¯¥ç ”ç©¶ä¸ºè¯„ä¼°å’Œä¼˜åŒ–è§†è§‰-è¯­è¨€æ¨¡å‹çš„é£æ ¼åŒ–èƒ½åŠ›æä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒæè¿°ç”Ÿæˆã€å†…å®¹åˆ›ä½œã€ç¤¾äº¤åª’ä½“ç­‰é¢†åŸŸã€‚é€šè¿‡é™ä½é£æ ¼å¯¹é½æ‰€éœ€çš„æ•°æ®é‡ï¼Œå¯ä»¥æ›´ç»æµé«˜æ•ˆåœ°å®šåˆ¶å…·æœ‰ç‰¹å®šé£æ ¼çš„å›¾åƒæè¿°ç”Ÿæˆæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æœ‰åŠ©äºç†è§£è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é£æ ¼åŒ–æ–¹é¢çš„èƒ½åŠ›æé™ï¼Œä¸ºæœªæ¥æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒæä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models are increasingly used to generate image captions in specific styles, such as humor or romantic. However, these transformer-based models often struggle with this subjective task in a zero-shot setting. While preference data can be used to align them toward a desired style, such data is expensive to acquire, limiting the ability to explore the models' full capabilities. This work addresses this by studying the data efficiency of aligning small vision-language models to humor and romantic styles. This approach helps to define the performance limits of these models and determine how little preference data is needed to achieve stylistic saturation, benchmarking their capabilities and limitations.

