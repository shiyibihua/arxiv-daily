---
layout: default
title: Learning to Parallel: Accelerating Diffusion Large Language Models via Learnable Parallel Decoding
---

# Learning to Parallel: Accelerating Diffusion Large Language Models via Learnable Parallel Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25188" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25188v2</a>
  <a href="https://arxiv.org/pdf/2509.25188.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25188v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25188v2', 'Learning to Parallel: Accelerating Diffusion Large Language Models via Learnable Parallel Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenrui Bao, Zhiben Chen, Dan Xu, Yuzhang Shang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29 (æ›´æ–°: 2025-10-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLearn2PDä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†é€Ÿåº¦ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¹¶è¡Œè§£ç ` `è‡ªé€‚åº”è¿‡æ»¤` `æ‰©æ•£æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨ç†é€Ÿåº¦` `æœºå™¨å­¦ä¹ ` `EoTP`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªå›å½’è§£ç æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­éœ€è¦é¡ºåºå¤„ç†ï¼Œå¯¼è‡´é€Ÿåº¦ç“¶é¢ˆï¼Œé™åˆ¶äº†å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºLearn2PDæ¡†æ¶ï¼Œé€šè¿‡è®­ç»ƒè‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹ï¼ŒåŠ¨æ€é¢„æµ‹æ¯ä¸ªæ ‡è®°çš„æœ€ç»ˆè¾“å‡ºï¼Œä¼˜åŒ–å¹¶è¡Œè§£ç è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLearn2PDåœ¨LLaDAåŸºå‡†ä¸Šå®ç°äº†æœ€é«˜22.58å€çš„é€Ÿåº¦æå‡ï¼Œç»“åˆKV-Cacheæ—¶å¯è¾¾57.51å€ï¼Œä¸”æ— æ€§èƒ½ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªå›å½’è§£ç åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­éœ€è¦$	ext{O}(n)$çš„é¡ºåºæ­¥éª¤æ¥å¤„ç†$n$ä¸ªæ ‡è®°ï¼Œè¿™åœ¨æ ¹æœ¬ä¸Šé™åˆ¶äº†æ¨ç†ååé‡ã€‚è¿‘æœŸçš„æ‰©æ•£åŸºç¡€LLMsï¼ˆdLLMsï¼‰é€šè¿‡è¿­ä»£å»å™ªå®ç°äº†å¹¶è¡Œæ ‡è®°ç”Ÿæˆã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¹¶è¡Œè§£ç ç­–ç•¥ä¾èµ–äºå›ºå®šçš„ã€ä¸è¾“å…¥æ— å…³çš„å¯å‘å¼æ–¹æ³•ï¼ˆå¦‚ç½®ä¿¡åº¦é˜ˆå€¼ï¼‰ï¼Œæœªèƒ½é€‚åº”è¾“å…¥ç‰¹å¾ï¼Œå¯¼è‡´åœ¨ä¸åŒNLPä»»åŠ¡ä¸­é€Ÿåº¦ä¸è´¨é‡çš„æƒè¡¡ä¸ç†æƒ³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ›´çµæ´»å’ŒåŠ¨æ€çš„å¹¶è¡Œè§£ç æ–¹æ³•ï¼Œåä¸ºå­¦ä¹ å¹¶è¡Œè§£ç ï¼ˆLearn2PDï¼‰ï¼Œè¯¥æ¡†æ¶è®­ç»ƒä¸€ä¸ªè½»é‡çº§è‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹ï¼Œé¢„æµ‹æ¯ä¸ªæ ‡è®°ä½ç½®çš„å½“å‰é¢„æµ‹æ˜¯å¦ä¸æœ€ç»ˆè¾“å‡ºåŒ¹é…ã€‚è¯¥è¿‡æ»¤å™¨åœ¨åè®­ç»ƒé˜¶æ®µå­¦ä¹ ï¼Œä¼˜åŒ–è®¡ç®—é‡å°ï¼ˆä»…éœ€åˆ†é’Ÿçº§GPUæ—¶é—´ï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨LLaDAåŸºå‡†ä¸Šå®ç°äº†æœ€é«˜22.58å€çš„åŠ é€Ÿï¼Œä¸”æ²¡æœ‰æ€§èƒ½ä¸‹é™ï¼Œç»“åˆKV-Cacheæ—¶å¯è¾¾57.51å€çš„åŠ é€Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªå›å½’è§£ç ä¸­å­˜åœ¨çš„é€Ÿåº¦ç“¶é¢ˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå›ºå®šçš„å¯å‘å¼ç­–ç•¥ï¼Œæ— æ³•æ ¹æ®è¾“å…¥ç‰¹å¾è¿›è¡ŒåŠ¨æ€è°ƒæ•´ï¼Œå¯¼è‡´é€Ÿåº¦ä¸è´¨é‡çš„æƒè¡¡ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†Learn2PDæ¡†æ¶ï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªè½»é‡çº§çš„è‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹ï¼Œé¢„æµ‹æ¯ä¸ªæ ‡è®°ä½ç½®çš„å½“å‰é¢„æµ‹æ˜¯å¦ä¸æœ€ç»ˆè¾“å‡ºåŒ¹é…ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆçš„å¹¶è¡Œè§£ç ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹å’Œç»“æŸæ ‡è®°é¢„æµ‹ï¼ˆEoTPï¼‰ã€‚è‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹ç”¨äºåŠ¨æ€åˆ¤æ–­æ ‡è®°çš„é¢„æµ‹å‡†ç¡®æ€§ï¼Œè€ŒEoTPç”¨äºæ£€æµ‹åºåˆ—è§£ç çš„å®Œæˆï¼Œé¿å…å†—ä½™çš„å¡«å……æ ‡è®°è§£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è‡ªé€‚åº”è¿‡æ»¤æ¨¡å‹ï¼Œè¯¥æ¨¡å‹åœ¨åè®­ç»ƒé˜¶æ®µå­¦ä¹ ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥ç‰¹å¾åŠ¨æ€è°ƒæ•´è§£ç ç­–ç•¥ï¼Œä¸ç°æœ‰å›ºå®šç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šè¿‡æ»¤æ¨¡å‹çš„è®­ç»ƒä»…éœ€å°‘é‡è®¡ç®—èµ„æºï¼ˆåˆ†é’Ÿçº§GPUæ—¶é—´ï¼‰ï¼Œå¹¶ä¸”é€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥æé«˜é¢„æµ‹å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒEoTPçš„å¼•å…¥æœ‰æ•ˆå‡å°‘äº†ä¸å¿…è¦çš„è§£ç æ­¥éª¤ï¼Œè¿›ä¸€æ­¥æå‡äº†æ•´ä½“æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLearn2PDåœ¨LLaDAåŸºå‡†ä¸Šå®ç°äº†æœ€é«˜22.58å€çš„é€Ÿåº¦æå‡ï¼Œä¸”åœ¨ç»“åˆKV-Cacheæ—¶å¯è¾¾57.51å€çš„åŠ é€Ÿï¼Œä¸”åœ¨æ­¤è¿‡ç¨‹ä¸­æ²¡æœ‰æ€§èƒ½ä¸‹é™ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ é€Ÿè§£ç è¿‡ç¨‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å®æ—¶å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆå’Œæœºå™¨ç¿»è¯‘ç­‰åœºæ™¯ã€‚é€šè¿‡æé«˜æ¨ç†é€Ÿåº¦ï¼ŒLearn2PDèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒï¼Œæ»¡è¶³å¯¹å¿«é€Ÿå“åº”çš„éœ€æ±‚ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autoregressive decoding in large language models (LLMs) requires $\mathcal{O}(n)$ sequential steps for $n$ tokens, fundamentally limiting inference throughput. Recent diffusion-based LLMs (dLLMs) enable parallel token generation through iterative denoising. However, current parallel decoding strategies rely on fixed, input-agnostic heuristics (e.g., confidence thresholds), which fail to adapt to input-specific characteristics, resulting in suboptimal speed-quality trade-offs across diverse NLP tasks. In this work, we explore a more flexible and dynamic approach to parallel decoding. We propose Learning to Parallel Decode (Learn2PD), a framework that trains a lightweight and adaptive filter model to predict, for each token position, whether the current prediction matches the final output. This learned filter approximates an oracle parallel decoding strategy that unmasks tokens only when correctly predicted. Importantly, the filter model is learned in a post-training manner, requiring only a small amount of computation to optimize it (minute-level GPU time). Additionally, we introduce End-of-Text Prediction (EoTP) to detect decoding completion at the end of sequence, avoiding redundant decoding of padding tokens. Experiments on the LLaDA benchmark demonstrate that our method achieves up to 22.58$\times$ speedup without any performance drop, and up to 57.51$\times$ when combined with KV-Cache.

