---
layout: default
title: Not Wrong, But Untrue: LLM Overconfidence in Document-Based Queries
---

# Not Wrong, But Untrue: LLM Overconfidence in Document-Based Queries

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25498" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25498v1</a>
  <a href="https://arxiv.org/pdf/2509.25498.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25498v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25498v1', 'Not Wrong, But Untrue: LLM Overconfidence in Document-Based Queries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nick Hagar, Wilma Agustianto, Nicholas Diakopoulos

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: Accepted to Computation + Journalism Symposium 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**LLMåœ¨æ–‡æ¡£é—®ç­”ä¸­è¿‡åº¦è‡ªä¿¡ï¼šæ­ç¤ºæ–°é—»åœºæ™¯ä¸‹çš„å¹»è§‰é—®é¢˜ä¸æº¯æºæŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¹»è§‰é—®é¢˜` `æ–°é—»æŠ¥é“` `æ–‡æ¡£é—®ç­”` `æº¯æº` `çŸ¥è¯†å½’å±` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨æ–°é—»åœºæ™¯ä¸‹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå¨èƒæ–°é—»æŠ¥é“çš„æº¯æºå’Œå‡†ç¡®æ€§ï¼ŒäºŸéœ€è¯„ä¼°å’Œæ”¹è¿›ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡æ„å»ºæ–‡æ¡£é—®ç­”ä»»åŠ¡ï¼Œåˆ†æLLMåœ¨ä¸åŒæç¤ºå’Œä¸Šä¸‹æ–‡ä¸‹çš„å¹»è§‰ç±»å‹ä¸ä¸¥é‡ç¨‹åº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMå­˜åœ¨è¿‡åº¦è‡ªä¿¡é—®é¢˜ï¼Œå€¾å‘äºæ·»åŠ æ— æ ¹æ®æè¿°ï¼Œå¹¶æå‡ºæ–°é—»é¢†åŸŸå¹»è§‰åˆ†ç±»æ‰©å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºæ–°é—»ç¼–è¾‘å®¤çš„å·¥ä½œæµç¨‹ä¸­ï¼Œä½†å…¶äº§ç”Ÿå¹»è§‰çš„å€¾å‘å¯¹æ–°é—»æŠ¥é“çš„æ ¸å¿ƒå®è·µï¼Œå¦‚æº¯æºã€å½’å±å’Œå‡†ç¡®æ€§æ„æˆäº†é£é™©ã€‚æœ¬æ–‡è¯„ä¼°äº†ä¸‰ç§å¹¿æ³›ä½¿ç”¨çš„å·¥å…·â€”â€”ChatGPTã€Geminiå’ŒNotebookLMï¼Œåœ¨ä¸€ä¸ªåŸºäºç¾å›½TikTokè¯‰è®¼å’Œæ”¿ç­–ç›¸å…³çš„300ç¯‡æ–‡æ¡£è¯­æ–™åº“çš„æŠ¥å‘Šä»»åŠ¡ä¸­ã€‚é€šè¿‡æ”¹å˜æç¤ºçš„ç‰¹å¼‚æ€§å’Œä¸Šä¸‹æ–‡å¤§å°ï¼Œå¹¶ä½¿ç”¨åˆ†ç±»æ³•æ³¨é‡Šå¥å­çº§åˆ«çš„è¾“å‡ºï¼Œä»¥æµ‹é‡å¹»è§‰çš„ç±»å‹å’Œä¸¥é‡ç¨‹åº¦ã€‚åœ¨æˆ‘ä»¬çš„æ ·æœ¬ä¸­ï¼Œ30%çš„æ¨¡å‹è¾“å‡ºåŒ…å«è‡³å°‘ä¸€ä¸ªå¹»è§‰ï¼ŒGeminiå’ŒChatGPTçš„å¹»è§‰ç‡ï¼ˆ40%ï¼‰å¤§çº¦æ˜¯NotebookLMï¼ˆ13%ï¼‰çš„ä¸‰å€ã€‚ä»å®šæ€§è§’åº¦æ¥çœ‹ï¼Œå¤§å¤šæ•°é”™è¯¯ä¸æ¶‰åŠè™šæ„çš„å®ä½“æˆ–æ•°å­—ï¼›ç›¸åï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°è§£é‡Šæ€§è¿‡åº¦è‡ªä¿¡â€”â€”æ¨¡å‹æ·»åŠ äº†å¯¹æ¥æºçš„æ— æ ¹æ®æè¿°ï¼Œå¹¶å°†å½’å±çš„è§‚ç‚¹è½¬åŒ–ä¸ºä¸€èˆ¬æ€§é™ˆè¿°ã€‚è¿™äº›æ¨¡å¼æ­ç¤ºäº†ä¸€ç§æ ¹æœ¬æ€§çš„è®¤è¯†è®ºä¸åŒ¹é…ï¼šè™½ç„¶æ–°é—»æŠ¥é“è¦æ±‚å¯¹æ¯ä¸€é¡¹å£°æ˜è¿›è¡Œæ˜ç¡®çš„æº¯æºï¼Œä½†LLMä¼šç”Ÿæˆå¬èµ·æ¥æƒå¨çš„æ–‡æœ¬ï¼Œè€Œä¸ç®¡æ˜¯å¦æœ‰è¯æ®æ”¯æŒã€‚æˆ‘ä»¬æå‡ºäº†é’ˆå¯¹æ–°é—»æŠ¥é“çš„ç°æœ‰å¹»è§‰åˆ†ç±»æ³•çš„æ‰©å±•ï¼Œå¹¶è®¤ä¸ºæœ‰æ•ˆçš„æ–°é—»ç¼–è¾‘å®¤å·¥å…·éœ€è¦å¼ºåˆ¶æ‰§è¡Œå‡†ç¡®å½’å±çš„æ¶æ„ï¼Œè€Œä¸æ˜¯ä¼˜åŒ–æµç•…æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†åŸºäºæ–‡æ¡£çš„æ–°é—»æŠ¥é“ä»»åŠ¡æ—¶ï¼Œå‡ºç°çš„å¹»è§‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ–°é—»ç¼–è¾‘å®¤çš„åº”ç”¨ä¸­ï¼Œç”±äºLLMçš„å¹»è§‰å€¾å‘ï¼Œå¯¹æ–°é—»æŠ¥é“çš„æº¯æºã€å½’å±å’Œå‡†ç¡®æ€§æ„æˆæ½œåœ¨å¨èƒã€‚ç°æœ‰LLMåœ¨ç”Ÿæˆå†…å®¹æ—¶ï¼Œç¼ºä¹å¯¹è¯æ®çš„ä¸¥æ ¼ä¾èµ–ï¼Œå®¹æ˜“äº§ç”Ÿä¸å‡†ç¡®æˆ–æé€ çš„ä¿¡æ¯ï¼Œè¿™ä¸æ–°é—»è¡Œä¸šçš„ä¸“ä¸šè§„èŒƒç›¸æ‚–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªæ¨¡æ‹Ÿæ–°é—»æŠ¥é“åœºæ™¯çš„æ–‡æ¡£é—®ç­”ä»»åŠ¡ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒLLMçš„å¹»è§‰è¡¨ç°ã€‚é€šè¿‡æ”¹å˜æç¤ºçš„ç‰¹å¼‚æ€§å’Œä¸Šä¸‹æ–‡å¤§å°ï¼Œè§‚å¯Ÿæ¨¡å‹åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„å¹»è§‰ç‡å’Œç±»å‹ã€‚åŒæ—¶ï¼Œå¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œç»†ç²’åº¦çš„æ ‡æ³¨å’Œåˆ†æï¼Œä»¥è¯†åˆ«å¹»è§‰çš„æ¨¡å¼å’ŒåŸå› ã€‚æœ€ç»ˆï¼Œæå‡ºé’ˆå¯¹æ–°é—»é¢†åŸŸçš„å¹»è§‰åˆ†ç±»æ‰©å±•ï¼Œå¹¶å»ºè®®æ„å»ºå¼ºåˆ¶æ‰§è¡Œå‡†ç¡®å½’å±çš„LLMæ¶æ„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ„å»ºåŒ…å«300ç¯‡ä¸TikTokè¯‰è®¼å’Œæ”¿ç­–ç›¸å…³çš„æ–‡æ¡£è¯­æ–™åº“ï¼›2) è®¾è®¡åŸºäºè¯¥è¯­æ–™åº“çš„æ–‡æ¡£é—®ç­”ä»»åŠ¡ï¼Œæ¨¡æ‹Ÿæ–°é—»æŠ¥é“åœºæ™¯ï¼›3) é€‰æ‹©ä¸‰ç§å¹¿æ³›ä½¿ç”¨çš„LLMï¼ˆChatGPTã€Geminiå’ŒNotebookLMï¼‰è¿›è¡Œè¯„ä¼°ï¼›4) é€šè¿‡æ”¹å˜æç¤ºçš„ç‰¹å¼‚æ€§å’Œä¸Šä¸‹æ–‡å¤§å°æ¥æ§åˆ¶å®éªŒå˜é‡ï¼›5) å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œå¥å­çº§åˆ«çš„æ ‡æ³¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰çš„å¹»è§‰åˆ†ç±»æ³•æ¥æµ‹é‡å¹»è§‰ç±»å‹å’Œä¸¥é‡ç¨‹åº¦ï¼›6) å¯¹å®éªŒç»“æœè¿›è¡Œç»Ÿè®¡åˆ†æå’Œå®šæ€§åˆ†æï¼Œè¯†åˆ«å¹»è§‰çš„æ¨¡å¼å’ŒåŸå› ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ­ç¤ºäº†LLMåœ¨æ–°é—»æŠ¥é“åœºæ™¯ä¸‹å­˜åœ¨çš„â€œè§£é‡Šæ€§è¿‡åº¦è‡ªä¿¡â€é—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘äºæ·»åŠ å¯¹æ¥æºçš„æ— æ ¹æ®æè¿°ï¼Œå¹¶å°†å½’å±çš„è§‚ç‚¹è½¬åŒ–ä¸ºä¸€èˆ¬æ€§é™ˆè¿°ï¼›2) æå‡ºäº†é’ˆå¯¹æ–°é—»é¢†åŸŸçš„å¹»è§‰åˆ†ç±»æ‰©å±•ï¼Œæ›´ç»†è‡´åœ°åˆ»ç”»äº†æ–°é—»æŠ¥é“ä¸­å¯èƒ½å‡ºç°çš„å¹»è§‰ç±»å‹ï¼›3) å¼ºè°ƒäº†åœ¨æ–°é—»ç¼–è¾‘å®¤åº”ç”¨LLMæ—¶ï¼Œéœ€è¦æ„å»ºå¼ºåˆ¶æ‰§è¡Œå‡†ç¡®å½’å±çš„æ¶æ„ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¼˜åŒ–æµç•…æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æç¤ºå·¥ç¨‹ï¼šé€šè¿‡æ”¹å˜æç¤ºçš„ç‰¹å¼‚æ€§ï¼ˆä¾‹å¦‚ï¼Œè¦æ±‚æ¨¡å‹æä¾›æ˜ç¡®çš„æ¥æºï¼‰æ¥è§‚å¯Ÿæ¨¡å‹å¯¹è¯æ®çš„ä¾èµ–ç¨‹åº¦ï¼›2) ä¸Šä¸‹æ–‡æ§åˆ¶ï¼šé€šè¿‡æ”¹å˜ä¸Šä¸‹æ–‡å¤§å°æ¥è¯„ä¼°æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æ¡£æ—¶çš„å¹»è§‰è¡¨ç°ï¼›3) å¹»è§‰åˆ†ç±»æ³•ï¼šè®¾è®¡äº†åŒ…å«å¤šç§å¹»è§‰ç±»å‹çš„åˆ†ç±»æ³•ï¼Œä¾‹å¦‚ï¼Œäº‹å®æ€§é”™è¯¯ã€å½’å±é”™è¯¯ã€è§£é‡Šæ€§é”™è¯¯ç­‰ï¼Œä»¥ä¾¿å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œç»†ç²’åº¦çš„æ ‡æ³¨å’Œåˆ†æï¼›4) è¯„ä¼°æŒ‡æ ‡ï¼šä½¿ç”¨äº†å¹»è§‰ç‡ä½œä¸ºä¸»è¦çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå³æ¨¡å‹è¾“å‡ºä¸­åŒ…å«è‡³å°‘ä¸€ä¸ªå¹»è§‰çš„å¥å­æ¯”ä¾‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ30%çš„æ¨¡å‹è¾“å‡ºåŒ…å«è‡³å°‘ä¸€ä¸ªå¹»è§‰ï¼ŒGeminiå’ŒChatGPTçš„å¹»è§‰ç‡é«˜è¾¾40%ï¼Œè€ŒNotebookLMçš„å¹»è§‰ç‡ç›¸å¯¹è¾ƒä½ï¼Œä¸º13%ã€‚å®šæ€§åˆ†æå‘ç°ï¼ŒLLMçš„ä¸»è¦é—®é¢˜åœ¨äºè§£é‡Šæ€§è¿‡åº¦è‡ªä¿¡ï¼Œè€Œéæé€ äº‹å®æˆ–æ•°å­—ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†æ–°é—»é¢†åŸŸå¯¹LLMå‡†ç¡®æ€§å’Œæº¯æºèƒ½åŠ›çš„éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ–°é—»ç¼–è¾‘å®¤çš„LLMå·¥å…·å¼€å‘ï¼Œå¸®åŠ©æ„å»ºæ›´å¯é ã€å‡†ç¡®çš„æ–°é—»ç”Ÿæˆç³»ç»Ÿã€‚é€šè¿‡æ”¹è¿›LLMçš„æº¯æºèƒ½åŠ›ï¼Œå‡å°‘å¹»è§‰ï¼Œæå‡æ–°é—»æŠ¥é“çš„è´¨é‡å’Œå¯ä¿¡åº¦ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„å¹»è§‰åˆ†ç±»æ³•å¯ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å…¶ä»–é¢†åŸŸçš„LLMåº”ç”¨ï¼Œä¾‹å¦‚æ³•å¾‹ã€åŒ»ç–—ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used in newsroom workflows, but their tendency to hallucinate poses risks to core journalistic practices of sourcing, attribution, and accuracy. We evaluate three widely used tools - ChatGPT, Gemini, and NotebookLM - on a reporting-style task grounded in a 300-document corpus related to TikTok litigation and policy in the U.S. We vary prompt specificity and context size and annotate sentence-level outputs using a taxonomy to measure hallucination type and severity. Across our sample, 30% of model outputs contained at least one hallucination, with rates approximately three times higher for Gemini and ChatGPT (40%) than for NotebookLM (13%). Qualitatively, most errors did not involve invented entities or numbers; instead, we observed interpretive overconfidence - models added unsupported characterizations of sources and transformed attributed opinions into general statements. These patterns reveal a fundamental epistemological mismatch: While journalism requires explicit sourcing for every claim, LLMs generate authoritative-sounding text regardless of evidentiary support. We propose journalism-specific extensions to existing hallucination taxonomies and argue that effective newsroom tools need architectures that enforce accurate attribution rather than optimize for fluency.

