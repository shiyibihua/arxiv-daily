---
layout: default
title: Think Twice, Generate Once: Safeguarding by Progressive Self-Reflection
---

# Think Twice, Generate Once: Safeguarding by Progressive Self-Reflection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.01270" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.01270v1</a>
  <a href="https://arxiv.org/pdf/2510.01270.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.01270v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.01270v1', 'Think Twice, Generate Once: Safeguarding by Progressive Self-Reflection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hoang Phan, Victor Li, Qi Lei

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: Accepted to EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¸è¿›å¼è‡ªåæ€ï¼ˆPSRï¼‰æ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹çš„å®‰å…¨æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹å®‰å…¨` `è‡ªåæ€` `æ¨ç†æ—¶å¹²é¢„` `å†…å®¹å®‰å…¨` `é£é™©ç¼“è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œå­˜åœ¨ç”Ÿæˆæœ‰å®³æˆ–ä¸å½“å†…å®¹çš„æ½œåœ¨é£é™©ï¼Œç¼ºä¹æœ‰æ•ˆçš„è‡ªæˆ‘ç›‘æ§å’Œçº æ­£æœºåˆ¶ã€‚
2. è®ºæ–‡æå‡ºæ¸è¿›å¼è‡ªåæ€ï¼ˆPSRï¼‰æ–¹æ³•ï¼Œä½¿LLMèƒ½å¤Ÿåœ¨æ¨ç†æ—¶åŠ¨æ€åœ°è‡ªæˆ‘ç›‘æ§å’Œçº æ­£è¾“å‡ºï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPSRèƒ½æ˜¾è‘—é™ä½LLMçš„æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒå…¶åœ¨è‰¯æ€§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶å¼•å…¥è‡ªåæ€é¢„æµ‹å™¨å¹³è¡¡å®‰å…¨æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‡­å€Ÿå…¶ç”Ÿæˆè¿è´¯ä¸”ä¸Šä¸‹æ–‡ç›¸å…³æ–‡æœ¬çš„èƒ½åŠ›ï¼Œå½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„éƒ¨ç½²ä¹Ÿå¼•å‘äº†äººä»¬å¯¹å…¶ç”Ÿæˆæœ‰å®³æˆ–ä¸å½“å†…å®¹çš„æ½œåœ¨å¯èƒ½æ€§çš„ä¸¥é‡æ‹…å¿§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ–°é¢–çš„æ¨ç†æ—¶æŠ€æœ¯â€”â€”æ¸è¿›å¼è‡ªåæ€ï¼ˆPSRï¼‰ï¼Œè¯¥æŠ€æœ¯ä½¿LLMèƒ½å¤ŸåŠ¨æ€åœ°è‡ªæˆ‘ç›‘æ§å’Œçº æ­£å…¶è¾“å‡ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•åº”ç”¨äºLlama-3.1-8B-Instructå¯ä»¥å°†æ”»å‡»æˆåŠŸç‡ä»77.5ï¼…é™ä½åˆ°5.9ï¼…ï¼Œåº”ç”¨äºLlama-3.1-8BåŸºç¡€æ¨¡å‹å¯ä»¥å°†æ”»å‡»æˆåŠŸç‡ä»89.7ï¼…é™ä½åˆ°5.6ï¼…ï¼Œåº”ç”¨äºQwen2.5-7B-Instructå¯ä»¥å°†æ”»å‡»æˆåŠŸç‡ä»44.4ï¼…é™ä½åˆ°3.8ï¼…ï¼Œä¸”æ— éœ€é¢å¤–è®­ç»ƒï¼ŒåŒæ—¶ä¿æŒäº†å®ƒä»¬åœ¨è‰¯æ€§ä»»åŠ¡ä¸Šçš„åŸå§‹æ€§èƒ½ã€‚æˆ‘ä»¬çš„æ–¹æ³•å……å½“äº†ä¸€ç§æµ‹è¯•æ—¶ç¼©æ”¾æ–¹æ³•ï¼Œå…¶ä¸­é¢å¤–çš„è‡ªåæ€è½®æ¬¡ä»¥æ¨ç†å¼€é”€ä¸ºä»£ä»·æ¥å¢å¼ºå®‰å…¨æ€§ã€‚ä¸ºäº†å¹³è¡¡å®‰å…¨æ€§å’Œè®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§è½»é‡çº§çš„è‡ªåæ€é¢„æµ‹å™¨ï¼Œè¯¥é¢„æµ‹å™¨å¯ä»¥æ ¹æ®è¾“å…¥å¤æ‚åº¦æ¥ä¼°è®¡æœ€ä½³çš„åæ€è½®æ¬¡æ•°ã€‚è¿™ç§è‡ªé€‚åº”æœºåˆ¶å¯ä»¥é˜²æ­¢å¯¹è‰¯æ€§è¾“å…¥è¿›è¡Œä¸å¿…è¦çš„è‡ªæˆ‘è¯„ä¼°ï¼ŒåŒæ—¶ç¡®ä¿åœ¨é‡åˆ°æ½œåœ¨æœ‰å®³å†…å®¹æ—¶è¿›è¡Œå½»åº•è¯„ä¼°ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¸è¿›å¼è‡ªåæ€æ˜¯ä¸€ç§å¯æ‰©å±•çš„æµ‹è¯•æ—¶æ–¹æ³•ï¼Œå®ƒé€šè¿‡æ ¹æ®è¾“å…¥çš„é£é™©çŠ¶å†µåŠ¨æ€åˆ†é…è®¡ç®—èµ„æºæ¥å¢å¼ºLLMçš„å®‰å…¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶å¯èƒ½äº§ç”Ÿçš„æœ‰å®³æˆ–ä¸å½“å†…å®¹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºè®­ç»ƒæ—¶çš„å®‰å…¨å¯¹é½ï¼Œä½†éš¾ä»¥å®Œå…¨æ¶ˆé™¤æ¨ç†æ—¶äº§ç”Ÿçš„é£é™©ã€‚ç°æœ‰çš„é˜²å¾¡æ–¹æ³•å¯èƒ½éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–è€…å¾®è°ƒï¼Œæˆæœ¬è¾ƒé«˜ï¼Œå¹¶ä¸”æ³›åŒ–èƒ½åŠ›å¯èƒ½ä¸è¶³ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨æ¨ç†é˜¶æ®µåŠ¨æ€åœ°æå‡LLMçš„å®‰å…¨æ€§ï¼ŒåŒæ—¶ä¿æŒå…¶åŸæœ‰æ€§èƒ½ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®©LLMåœ¨ç”Ÿæˆå†…å®¹åè¿›è¡Œè‡ªæˆ‘åæ€ï¼Œå¹¶æ ¹æ®åæ€ç»“æœè¿›è¡Œä¿®æ­£ã€‚é€šè¿‡å¤šæ¬¡è¿­ä»£çš„è‡ªåæ€è¿‡ç¨‹ï¼Œé€æ­¥æé«˜ç”Ÿæˆå†…å®¹çš„å®‰å…¨æ€§ã€‚è¿™ç§æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥åœ¨æ¨ç†æ—¶åŠ¨æ€åœ°åº”ç”¨ï¼Œå…·æœ‰è¾ƒå¼ºçš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§çš„è‡ªåæ€é¢„æµ‹å™¨ï¼Œç”¨äºä¼°è®¡æœ€ä½³çš„åæ€è½®æ¬¡æ•°ï¼Œä»¥å¹³è¡¡å®‰å…¨æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPSRæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **åˆå§‹ç”Ÿæˆ**ï¼šLLMé¦–å…ˆæ ¹æ®è¾“å…¥ç”Ÿæˆåˆå§‹æ–‡æœ¬ã€‚2) **è‡ªæˆ‘åæ€**ï¼šLLMå¯¹ç”Ÿæˆçš„æ–‡æœ¬è¿›è¡Œè‡ªæˆ‘è¯„ä¼°ï¼Œåˆ¤æ–­å…¶æ˜¯å¦åŒ…å«æœ‰å®³æˆ–ä¸å½“å†…å®¹ã€‚3) **å†…å®¹ä¿®æ­£**ï¼šå¦‚æœLLMè®¤ä¸ºç”Ÿæˆçš„æ–‡æœ¬å­˜åœ¨é—®é¢˜ï¼Œåˆ™å¯¹å…¶è¿›è¡Œä¿®æ­£ï¼Œç”Ÿæˆæ›´å®‰å…¨çš„å†…å®¹ã€‚4) **è¿­ä»£ä¼˜åŒ–**ï¼šé‡å¤è‡ªæˆ‘åæ€å’Œå†…å®¹ä¿®æ­£çš„è¿‡ç¨‹ï¼Œç›´åˆ°è¾¾åˆ°é¢„è®¾çš„åæ€è½®æ¬¡æ•°æˆ–æ»¡è¶³å®‰å…¨æ ‡å‡†ã€‚5) **è‡ªåæ€é¢„æµ‹**ï¼šä½¿ç”¨è½»é‡çº§çš„è‡ªåæ€é¢„æµ‹å™¨ï¼Œæ ¹æ®è¾“å…¥å¤æ‚åº¦åŠ¨æ€è°ƒæ•´åæ€è½®æ¬¡æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ¸è¿›å¼è‡ªåæ€çš„æ¡†æ¶ï¼Œä½¿å¾—LLMèƒ½å¤Ÿåœ¨æ¨ç†æ—¶åŠ¨æ€åœ°æå‡å®‰å…¨æ€§ï¼Œè€Œæ— éœ€é¢å¤–çš„è®­ç»ƒã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPSRå…·æœ‰æ›´å¼ºçš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œå¯ä»¥åº”ç”¨äºå„ç§ä¸åŒçš„LLMã€‚æ­¤å¤–ï¼Œè‡ªåæ€é¢„æµ‹å™¨çš„å¼•å…¥ï¼Œä½¿å¾—PSRèƒ½å¤Ÿåœ¨å®‰å…¨æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šè‡ªåæ€é¢„æµ‹å™¨æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ¨¡å‹ï¼Œç”¨äºä¼°è®¡æœ€ä½³çš„åæ€è½®æ¬¡æ•°ã€‚è¯¥æ¨¡å‹å¯ä»¥åŸºäºè¾“å…¥æ–‡æœ¬çš„å¤æ‚åº¦ã€LLMçš„è¾“å‡ºä»¥åŠå†å²åæ€ç»“æœç­‰ä¿¡æ¯è¿›è¡Œé¢„æµ‹ã€‚å…·ä½“çš„å®ç°æ–¹å¼å¯ä»¥æ˜¯ç®€å•çš„çº¿æ€§æ¨¡å‹æˆ–æ›´å¤æ‚çš„ç¥ç»ç½‘ç»œã€‚è®ºæ–‡ä¸­å¯èƒ½è¿˜æ¶‰åŠä¸€äº›è¶…å‚æ•°çš„è®¾ç½®ï¼Œä¾‹å¦‚åæ€è½®æ¬¡æ•°çš„ä¸Šé™ã€å®‰å…¨æ ‡å‡†çš„é˜ˆå€¼ç­‰ã€‚è¿™äº›å‚æ•°éœ€è¦æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒPSRæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—é™ä½LLMçš„æ”»å‡»æˆåŠŸç‡ã€‚ä¾‹å¦‚ï¼Œåœ¨Llama-3.1-8B-Instructä¸Šï¼Œæ”»å‡»æˆåŠŸç‡ä»77.5%é™ä½åˆ°5.9%ï¼›åœ¨Llama-3.1-8BåŸºç¡€æ¨¡å‹ä¸Šï¼Œæ”»å‡»æˆåŠŸç‡ä»89.7%é™ä½åˆ°5.6%ï¼›åœ¨Qwen2.5-7B-Instructä¸Šï¼Œæ”»å‡»æˆåŠŸç‡ä»44.4%é™ä½åˆ°3.8%ã€‚åŒæ—¶ï¼ŒPSRæ–¹æ³•åœ¨é™ä½æ”»å‡»æˆåŠŸç‡çš„åŒæ—¶ï¼Œä¿æŒäº†LLMåœ¨è‰¯æ€§ä»»åŠ¡ä¸Šçš„åŸå§‹æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦ç”Ÿæˆæ–‡æœ¬çš„åœºæ™¯ï¼Œä¾‹å¦‚èŠå¤©æœºå™¨äººã€å†…å®¹åˆ›ä½œã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡åº”ç”¨PSRæ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½LLMç”Ÿæˆæœ‰å®³æˆ–ä¸å½“å†…å®¹çš„é£é™©ï¼Œæé«˜ç”¨æˆ·ä½“éªŒå’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ä¸å…¶ä»–å®‰å…¨æŠ€æœ¯ç›¸ç»“åˆï¼Œæ„å»ºæ›´å¼ºå¤§çš„LLMå®‰å…¨é˜²æŠ¤ä½“ç³»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have revolutionized natural language processing with their ability to generate coherent and contextually relevant text. However, their deployment raises significant concerns about the potential for generating harmful or inappropriate content. In this paper, we introduce Progressive Self-Reflection (PSR), a novel inference-time technique that empowers LLMs to self-monitor and correct their outputs dynamically. Experimental results demonstrate that applying our proposed method to Llama-3.1-8B-Instruct reduces the attack success rate from 77.5\% to 5.9\%, to Llama-3.1-8B base from 89.7\% to 5.6\%, and to Qwen2.5-7B-Instruct from 44.4\% to 3.8\%, without additional training, while maintaining their original performance on benign tasks. Our approach acts as a test-time scaling method, where additional self-reflection rounds enhance safety at the cost of inference overhead. To balance safety with computational efficiency, we introduce a lightweight self-reflection predictor that estimates the optimal number of reflection rounds based on input complexity. This adaptive mechanism prevents unnecessary self-assessment on benign inputs while ensuring thorough evaluation when encountering potentially harmful content. Our findings suggest that Progressive Self-Reflection serves as a scalable test-time approach, enhancing LLM safety by dynamically allocating computational resources in proportion to the input's risk profile.

