---
layout: default
title: Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study
---

# Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25063" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25063v1</a>
  <a href="https://arxiv.org/pdf/2509.25063.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25063v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25063v1', 'Learning from Convenience Samples: A Case Study on Fine-Tuning LLMs for Survey Non-response in the German Longitudinal Election Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tobias Holtdirk, Dennis Assenmacher, Arnim Bleier, Claudia Wagner

**åˆ†ç±»**: cs.CY, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¾®è°ƒLLMè§£å†³è°ƒæŸ¥éå›åº”é—®é¢˜ï¼Œåˆ©ç”¨ä¾¿åˆ©æ ·æœ¬æå‡é€‰ä¸¾ç ”ç©¶å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `è°ƒæŸ¥éå›åº”` `ä¾¿åˆ©æ ·æœ¬` `é€‰ä¸¾ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿè°ƒæŸ¥ç ”ç©¶é¢ä¸´æˆæœ¬é«˜æ˜‚å’Œæ•°æ®ç¼ºå¤±çš„æŒ‘æˆ˜ï¼Œå½±å“æ¨æ–­çš„å‡†ç¡®æ€§ï¼Œä¾¿åˆ©æ ·æœ¬çš„ä½¿ç”¨æ—¥ç›Šå¢åŠ ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡åœ¨éƒ¨åˆ†è°ƒæŸ¥å›å¤æ•°æ®ä¸Šå¾®è°ƒLLMï¼Œä»¥å¡«è¡¥éšæœºå’Œç³»ç»Ÿæ€§éå›åº”ä¸‹çš„æŠ•ç¥¨é€‰æ‹©ï¼Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¾®è°ƒåçš„LLMåœ¨æ•°æ®å®Œå…¨éšæœºç¼ºå¤±æ—¶ä¸è¡¨æ ¼åˆ†ç±»å™¨æ€§èƒ½ç›¸å½“ï¼Œä¼˜äºé›¶æ ·æœ¬æ–¹æ³•ï¼Œä¸”èƒ½æœ‰æ•ˆåˆ©ç”¨æœ‰åä¾¿åˆ©æ ·æœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è°ƒæŸ¥ç ”ç©¶äººå‘˜é¢ä¸´æ¦‚ç‡æ ·æœ¬æˆæœ¬ä¸Šå‡å’Œæ•°æ®ç¼ºå¤±ï¼ˆå¦‚éå›åº”æˆ–è¡°å‡ï¼‰çš„åŒé‡æŒ‘æˆ˜ï¼Œè¿™ä¼šæŸå®³æ¨æ–­å¹¶å¢åŠ ä¾¿åˆ©æ ·æœ¬çš„ä½¿ç”¨ã€‚æœ€è¿‘çš„ç ”ç©¶æ¢ç´¢äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡åŸºäºè§’è‰²çš„æç¤ºæ¥æ¨¡æ‹Ÿå—è®¿è€…ï¼Œé€šå¸¸æ— éœ€æ ‡è®°æ•°æ®ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸€ä¸ªæ›´å®é™…çš„åœºæ™¯ï¼Œå³å­˜åœ¨éƒ¨åˆ†è°ƒæŸ¥å›å¤ï¼šæˆ‘ä»¬ä½¿ç”¨å¾·å›½çºµå‘é€‰ä¸¾ç ”ç©¶ï¼Œåœ¨éšæœºå’Œç³»ç»Ÿæ€§éå›åº”ä¸‹ï¼Œå¾®è°ƒLLMä»¥æ¨ç®—è‡ªæˆ‘æŠ¥å‘Šçš„æŠ•ç¥¨é€‰æ‹©ã€‚æˆ‘ä»¬å°†é›¶æ ·æœ¬æç¤ºå’Œç›‘ç£å¾®è°ƒä¸è¡¨æ ¼åˆ†ç±»å™¨ï¼ˆå¦‚CatBoostï¼‰è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶æµ‹è¯•ç”¨äºå¾®è°ƒçš„ä¸åŒä¾¿åˆ©æ ·æœ¬ï¼ˆå¦‚å­¦ç”Ÿï¼‰å¦‚ä½•å½±å“æ³›åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è°ƒæŸ¥ç ”ç©¶ä¸­å› éå›åº”é€ æˆçš„æŠ•ç¥¨é€‰æ‹©æ•°æ®ç¼ºå¤±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿçš„ç»Ÿè®¡æ¨¡å‹å’Œé›¶æ ·æœ¬LLMï¼Œåœ¨å¤„ç†ç³»ç»Ÿæ€§éå›åº”å’Œæœ‰åä¾¿åˆ©æ ·æœ¬æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ¨æ–­åå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å·²æœ‰çš„éƒ¨åˆ†è°ƒæŸ¥å›å¤æ•°æ®ï¼Œå¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ åˆ°å—è®¿è€…çš„æ½œåœ¨ç‰¹å¾å’ŒæŠ•ç¥¨å€¾å‘ï¼Œä»è€Œæ›´å‡†ç¡®åœ°æ¨æ–­ç¼ºå¤±çš„æŠ•ç¥¨é€‰æ‹©ã€‚é€šè¿‡å¾®è°ƒï¼ŒLLMå¯ä»¥æ›´å¥½åœ°é€‚åº”ç‰¹å®šè°ƒæŸ¥æ•°æ®é›†çš„åˆ†å¸ƒï¼Œå¹¶å‡å°‘å¯¹å…ˆéªŒçŸ¥è¯†çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒã€ä»¥åŠæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œå¯¹å¾·å›½çºµå‘é€‰ä¸¾ç ”ç©¶çš„æ•°æ®è¿›è¡Œæ¸…æ´—å’Œæ•´ç†ï¼Œæ„å»ºç”¨äºå¾®è°ƒçš„æ•°æ®é›†ã€‚ç„¶åï¼Œé€‰æ‹©åˆé€‚çš„LLMï¼ˆå¦‚3Båˆ°8Bçš„å¼€æºæ¨¡å‹ï¼‰ï¼Œå¹¶ä½¿ç”¨ç›‘ç£å­¦ä¹ çš„æ–¹å¼åœ¨å·²æœ‰çš„éƒ¨åˆ†è°ƒæŸ¥å›å¤æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒã€‚æœ€åï¼Œä½¿ç”¨ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ä¸ªä½“é¢„æµ‹å‡†ç¡®ç‡å’Œç¾¤ä½“åˆ†å¸ƒè¿˜åŸåº¦ï¼Œæ¥è¯„ä¼°å¾®è°ƒåLLMçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæ¢ç´¢äº†ä½¿ç”¨å¾®è°ƒåçš„LLMæ¥å¤„ç†è°ƒæŸ¥éå›åº”é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨åªæœ‰æœ‰åä¾¿åˆ©æ ·æœ¬å¯ç”¨çš„æƒ…å†µä¸‹ã€‚ä¸ä¼ ç»Ÿçš„ç»Ÿè®¡æ–¹æ³•å’Œé›¶æ ·æœ¬LLMç›¸æ¯”ï¼Œå¾®è°ƒåçš„LLMèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰æ•°æ®ä¸­çš„å¤æ‚å…³ç³»ï¼Œå¹¶æé«˜é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¯”è¾ƒäº†ä¸åŒä¾¿åˆ©æ ·æœ¬å¯¹å¾®è°ƒæ•ˆæœçš„å½±å“ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç›‘ç£å­¦ä¹ çš„æ–¹å¼ï¼Œä½¿ç”¨å·²æœ‰çš„éƒ¨åˆ†è°ƒæŸ¥å›å¤æ•°æ®ä½œä¸ºè®­ç»ƒé›†ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨é‡‡ç”¨AdamWã€‚ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé‡‡ç”¨äº†dropoutå’Œæƒé‡è¡°å‡ç­‰æ­£åˆ™åŒ–æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¿˜æ¢ç´¢äº†ä¸åŒçš„å¾®è°ƒç­–ç•¥ï¼Œå¦‚å…¨å‚æ•°å¾®è°ƒå’ŒLoRAå¾®è°ƒï¼Œä»¥å¹³è¡¡æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ•°æ®å®Œå…¨éšæœºç¼ºå¤±çš„æƒ…å†µä¸‹ï¼Œå¾®è°ƒåçš„LLMä¸è¡¨æ ¼åˆ†ç±»å™¨ï¼ˆå¦‚CatBoostï¼‰æ€§èƒ½ç›¸å½“ï¼Œä¼˜äºé›¶æ ·æœ¬æ–¹æ³•ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œå½“åªæœ‰æœ‰åä¾¿åˆ©æ ·æœ¬å¯ç”¨æ—¶ï¼Œå¾®è°ƒåçš„LLMåœ¨ä¸ªä½“é¢„æµ‹å’Œç¾¤ä½“åˆ†å¸ƒè¿˜åŸæ–¹é¢é€šå¸¸ä¼˜äºé›¶æ ·æœ¬æ–¹æ³•å’Œè¡¨æ ¼æ–¹æ³•ï¼Œè¡¨æ˜å…¶åœ¨å¤„ç†å®é™…è°ƒæŸ¥æ•°æ®ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è°ƒæŸ¥ç ”ç©¶é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨é¢ä¸´é«˜æˆæœ¬æ¦‚ç‡æ ·æœ¬å’Œç³»ç»Ÿæ€§æ•°æ®ç¼ºå¤±çš„æƒ…å†µä¸‹ã€‚é€šè¿‡åˆ©ç”¨æ˜“äºè·å–çš„å­ç¾¤ä½“æ•°æ®å¾®è°ƒLLMï¼Œå¯ä»¥æ›´ç»æµé«˜æ•ˆåœ°è¿›è¡Œé€‰ä¸¾é¢„æµ‹ã€å¸‚åœºè°ƒç ”å’Œç¤¾ä¼šç§‘å­¦ç ”ç©¶ï¼Œå¹¶æé«˜æ•°æ®åˆ†æçš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä¸ºæ”¿ç­–åˆ¶å®šæä¾›æ›´å¯é çš„ä¾æ®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Survey researchers face two key challenges: the rising costs of probability samples and missing data (e.g., non-response or attrition), which can undermine inference and increase the use of convenience samples. Recent work explores using large language models (LLMs) to simulate respondents via persona-based prompts, often without labeled data. We study a more practical setting where partial survey responses exist: we fine-tune LLMs on available data to impute self-reported vote choice under both random and systematic nonresponse, using the German Longitudinal Election Study. We compare zero-shot prompting and supervised fine-tuning against tabular classifiers (e.g., CatBoost) and test how different convenience samples (e.g., students) used for fine-tuning affect generalization.
>   Our results show that when data are missing completely at random, fine-tuned LLMs match tabular classifiers but outperform zero-shot approaches. When only biased convenience samples are available, fine-tuning small (3B to 8B) open-source LLMs can recover both individual-level predictions and population-level distributions more accurately than zero-shot and often better than tabular methods. This suggests fine-tuned LLMs offer a promising strategy for researchers working with non-probability samples or systematic missingness, and may enable new survey designs requiring only easily accessible subpopulations.

