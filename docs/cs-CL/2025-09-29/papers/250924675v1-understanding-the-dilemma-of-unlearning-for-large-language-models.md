---
layout: default
title: Understanding the Dilemma of Unlearning for Large Language Models
---

# Understanding the Dilemma of Unlearning for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24675" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24675v1</a>
  <a href="https://arxiv.org/pdf/2509.24675.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24675v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24675v1', 'Understanding the Dilemma of Unlearning for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qingjie Zhang, Haoting Qian, Zhicong Huang, Cheng Hong, Minlie Huang, Ke Xu, Chao Zhang, Han Qiu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºunPactæ¡†æ¶ï¼Œæ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ä¸å¯é çš„çŸ¥è¯†é—å¿˜ç°è±¡ä¸æœºç†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†é—å¿˜` `å¤§è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `æç¤ºå½’å› ` `ç¾éš¾æ€§é—å¿˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†é—å¿˜æ–¹æ³•å­˜åœ¨æœ‰æ•ˆæ€§äº‰è®®ï¼Œä¸”ç¼ºä¹å¯¹é—å¿˜æœºåˆ¶çš„æ·±å…¥å¯è§£é‡Šæ€§åˆ†æã€‚
2. æå‡ºunPactæ¡†æ¶ï¼Œé€šè¿‡æç¤ºå½’å› å’Œè´¡çŒ®è¿½è¸ªï¼Œé‡åŒ–æ¯ä¸ªtokenå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œä»è€Œåˆ†æé—å¿˜è¿‡ç¨‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆæ— æ³•å½»åº•é—å¿˜çŸ¥è¯†ï¼Œè¦ä¹ˆå¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼Œå­˜åœ¨çŸ¥è¯†é—å¿˜å›°å¢ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†é—å¿˜æ—¨åœ¨ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ç§»é™¤ç‰¹å®šçŸ¥è¯†ï¼Œä½†å…¶æœ‰æ•ˆæ€§ä¸€ç›´å­˜åœ¨äº‰è®®ã€‚ä¸€æ–¹é¢ï¼Œâ€œé—å¿˜â€çš„çŸ¥è¯†é€šå¸¸å¯ä»¥é€šè¿‡è½»é‡çº§å¾®è°ƒç­‰å¹²é¢„æ‰‹æ®µæ¢å¤ï¼›å¦ä¸€æ–¹é¢ï¼ŒçŸ¥è¯†é—å¿˜å¯èƒ½å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼Œä»è€Œé™ä½æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚å°½ç®¡çŸ¥è¯†é—å¿˜æ–¹æ³•çš„ç ”ç©¶éå¸¸æ´»è·ƒï¼Œä½†ç”±äºéš¾ä»¥è¿½è¸ªLLMså¤æ‚æ¶æ„ä¸­çš„çŸ¥è¯†ï¼Œå¯¹å…¶æœºåˆ¶çš„å¯è§£é‡Šæ€§åˆ†æä»ç„¶åŒ®ä¹ã€‚æˆ‘ä»¬æå‡ºäº†unPactï¼Œä¸€ä¸ªé€šè¿‡æç¤ºå½’å› å’Œè´¡çŒ®è¿½è¸ªå®ç°å¯è§£é‡ŠçŸ¥è¯†é—å¿˜çš„æ¡†æ¶ï¼Œä»¥å¼¥è¡¥è¿™ä¸€ç©ºç™½ã€‚å®ƒé‡åŒ–äº†æ¯ä¸ªæç¤ºtokenå¯¹è¾“å‡ºçš„å½±å“ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œé—å¿˜å‰åçš„æ¯”è¾ƒï¼Œä»¥æ­ç¤ºå‘ç”Ÿäº†å“ªäº›å˜åŒ–ã€‚åœ¨å…­ç§ä¸»æµçŸ¥è¯†é—å¿˜æ–¹æ³•ã€ä¸‰ç§LLMså’Œä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼šï¼ˆ1ï¼‰çŸ¥è¯†é—å¿˜ä¼¼ä¹é€šè¿‡æ‰°ä¹±å¯¹æç¤ºä¸­å…³é”®è¯çš„å…³æ³¨è€Œç”Ÿæ•ˆï¼›ï¼ˆ2ï¼‰å¤§éƒ¨åˆ†çŸ¥è¯†å¹¶æ²¡æœ‰çœŸæ­£è¢«åˆ é™¤ï¼Œå¯ä»¥é€šè¿‡ç®€å•åœ°å¼ºè°ƒæç¤ºä¸­çš„è¿™äº›å…³é”®è¯æ¥æ¢å¤ï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹çš„æƒé‡ï¼›ï¼ˆ3ï¼‰ç¾éš¾æ€§é—å¿˜æºäºå¯¹æ‰€æœ‰tokençš„ä¸åŠ åŒºåˆ†çš„æƒ©ç½šã€‚æ€»è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬çš„ç»“æœè¡¨æ˜äº†ä¸€ä¸ªçŸ¥è¯†é—å¿˜å›°å¢ƒï¼šç°æœ‰æ–¹æ³•è¦ä¹ˆä¸è¶³â€”â€”çŸ¥è¯†ä»ç„¶å¯ä»¥é€šè¿‡å…³é”®è¯å¼ºè°ƒæ¥æ¢å¤ï¼Œè¦ä¹ˆè¿‡åº¦ç ´åâ€”â€”ç”±äºç¾éš¾æ€§é—å¿˜å¯¼è‡´é€šç”¨æ€§èƒ½å´©æºƒï¼Œè¿™ä»ç„¶ç•™ä¸‹äº†å¯é çŸ¥è¯†é—å¿˜çš„å·®è·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çŸ¥è¯†é—å¿˜æ•ˆæœä¸ä½³ä¸”ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆæ— æ³•å½»åº•åˆ é™¤çŸ¥è¯†ï¼Œå¯¼è‡´çŸ¥è¯†å®¹æ˜“è¢«æ¢å¤ï¼Œè¦ä¹ˆè¿‡åº¦åˆ é™¤çŸ¥è¯†ï¼Œå¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼ŒæŸå®³æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥è¿½è¸ªLLMså¤æ‚æ¶æ„ä¸­çš„çŸ¥è¯†å˜åŒ–ï¼Œç¼ºä¹å¯¹é—å¿˜æœºåˆ¶çš„æ·±å…¥ç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æç¤ºå½’å› å’Œè´¡çŒ®è¿½è¸ªæ¥åˆ†æçŸ¥è¯†é—å¿˜è¿‡ç¨‹ã€‚é€šè¿‡é‡åŒ–æ¯ä¸ªæç¤ºtokenå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°é—å¿˜å‰åtokené‡è¦æ€§çš„å˜åŒ–ï¼Œä»è€Œç†è§£é—å¿˜æœºåˆ¶ã€‚å¼ºè°ƒæç¤ºä¸­çš„å…³é”®è¯å¯ä»¥æ¢å¤â€œé—å¿˜â€çš„çŸ¥è¯†ï¼Œè¡¨æ˜çŸ¥è¯†å¹¶æ²¡æœ‰çœŸæ­£è¢«åˆ é™¤ã€‚å¯¹æ‰€æœ‰tokençš„ä¸åŠ åŒºåˆ†çš„æƒ©ç½šä¼šå¯¼è‡´ç¾éš¾æ€§é—å¿˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šunPactæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š1. æç¤ºè¾“å…¥ï¼šå‘LLMè¾“å…¥åŒ…å«ç›®æ ‡çŸ¥è¯†çš„æç¤ºã€‚2. æç¤ºå½’å› ï¼šä½¿ç”¨æ¢¯åº¦ç§¯åˆ†ç­‰æ–¹æ³•è®¡ç®—æ¯ä¸ªæç¤ºtokenå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚3. é—å¿˜æ“ä½œï¼šåº”ç”¨ç°æœ‰çš„çŸ¥è¯†é—å¿˜æ–¹æ³•ã€‚4. æç¤ºå½’å› ï¼ˆé—å¿˜åï¼‰ï¼šå†æ¬¡è®¡ç®—æ¯ä¸ªæç¤ºtokenå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚5. æ¯”è¾ƒåˆ†æï¼šæ¯”è¾ƒé—å¿˜å‰åtokené‡è¦æ€§çš„å˜åŒ–ï¼Œåˆ†æé—å¿˜æœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šunPactæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¯è§£é‡Šæ€§ã€‚é€šè¿‡æç¤ºå½’å› å’Œè´¡çŒ®è¿½è¸ªï¼Œå¯ä»¥é‡åŒ–æ¯ä¸ªtokenå¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œä»è€Œæ·±å…¥ç†è§£çŸ¥è¯†é—å¿˜çš„æœºåˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒunPactä¸ä»…å…³æ³¨é—å¿˜æ•ˆæœï¼Œæ›´å…³æ³¨é—å¿˜è¿‡ç¨‹ï¼Œä¸ºæ”¹è¿›çŸ¥è¯†é—å¿˜æ–¹æ³•æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šunPactæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1. ä½¿ç”¨æ¢¯åº¦ç§¯åˆ†ä½œä¸ºæç¤ºå½’å› æ–¹æ³•ï¼Œè®¡ç®—æ¯ä¸ªtokenå¯¹æ¨¡å‹è¾“å‡ºçš„æ¢¯åº¦ã€‚2. è®¾è®¡å®éªŒè¯„ä¼°ä¸åŒçŸ¥è¯†é—å¿˜æ–¹æ³•çš„æ•ˆæœï¼ŒåŒ…æ‹¬çŸ¥è¯†åˆ é™¤ç‡å’Œé€šç”¨æ€§èƒ½ä¸‹é™ç¨‹åº¦ã€‚3. åˆ†æé—å¿˜å‰åtokené‡è¦æ€§çš„å˜åŒ–ï¼Œæ­ç¤ºé—å¿˜æœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰çŸ¥è¯†é—å¿˜æ–¹æ³•è¦ä¹ˆæ— æ³•å½»åº•åˆ é™¤çŸ¥è¯†ï¼ŒçŸ¥è¯†å¯ä»¥é€šè¿‡å¼ºè°ƒå…³é”®è¯æ¢å¤ï¼›è¦ä¹ˆå¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼Œé€šç”¨æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›åŸºå‡†æµ‹è¯•ä¸­ï¼ŒçŸ¥è¯†åˆ é™¤ç‡å¯ä»¥è¾¾åˆ°è¾ƒé«˜æ°´å¹³ï¼Œä½†é€šç”¨æ€§èƒ½ä¸‹é™å¹…åº¦ä¹Ÿè¶…è¿‡10%ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†ç°æœ‰çŸ¥è¯†é—å¿˜æ–¹æ³•é¢ä¸´çš„å›°å¢ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºéœ€è¦ä¿æŠ¤ç”¨æˆ·éšç§ã€é˜²æ­¢æ¨¡å‹æ³„éœ²æ•æ„Ÿä¿¡æ¯çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸï¼Œå¯ä»¥åˆ©ç”¨çŸ¥è¯†é—å¿˜æŠ€æœ¯åˆ é™¤æ¨¡å‹ä¸­åŒ…å«çš„ä¸ªäººä¿¡æ¯æˆ–å•†ä¸šæœºå¯†ï¼Œä»è€Œé™ä½æ•°æ®æ³„éœ²çš„é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿæœ‰åŠ©äºæå‡æ¨¡å‹çš„å¯æ§æ€§å’Œå®‰å…¨æ€§ï¼Œé¿å…æ¨¡å‹è¢«ç”¨äºæ¶æ„ç›®çš„ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Unlearning seeks to remove specific knowledge from large language models (LLMs), but its effectiveness remains contested. On one side, "forgotten" knowledge can often be recovered through interventions such as light fine-tuning; on the other side, unlearning may induce catastrophic forgetting that degrades general capabilities. Despite active exploration of unlearning methods, interpretability analyses of the mechanism are scarce due to the difficulty of tracing knowledge in LLMs' complex architectures. We address this gap by proposing unPact, an interpretable framework for unlearning via prompt attribution and contribution tracking. Typically, it quantifies each prompt token's influence on outputs, enabling pre- and post-unlearning comparisons to reveal what changes. Across six mainstream unlearning methods, three LLMs, and three benchmarks, we find that: (1) Unlearning appears to be effective by disrupting focus on keywords in prompt; (2) Much of the knowledge is not truly erased and can be recovered by simply emphasizing these keywords in prompts, without modifying the model's weights; (3) Catastrophic forgetting arises from indiscriminate penalization of all tokens. Taken together, our results suggest an unlearning dilemma: existing methods tend either to be insufficient - knowledge remains recoverable by keyword emphasis, or overly destructive - general performance collapses due to catastrophic forgetting, still leaving a gap to reliable unlearning.

