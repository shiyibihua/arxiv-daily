---
layout: default
title: Do Retrieval Augmented Language Models Know When They Don't Know?
---

# Do Retrieval Augmented Language Models Know When They Don't Know?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01476" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01476v3</a>
  <a href="https://arxiv.org/pdf/2509.01476.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01476v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01476v3', 'Do Retrieval Augmented Language Models Know When They Don\'t Know?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Youchao Zhou, Heyan Huang, Yicheng Liu, Rui Dai, Xinglin Wang, Xingchen Zhang, Shumin Shi, Yang Deng

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01 (æ›´æ–°: 2025-11-18)

**å¤‡æ³¨**: AAAI 2026 camera ready version. Extended version with Appendix is coming soon

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆRALMï¼‰çš„æ‹’è¯†èƒ½åŠ›ï¼Œå¹¶æå‡ºæ”¹è¿›æ–¹æ¡ˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹` `æ‹’è¯†èƒ½åŠ›` `æ ¡å‡†` `å¹»è§‰` `ä¸ç¡®å®šæ€§ä¼°è®¡` `ä¸Šä¸‹æ–‡å¾®è°ƒ` `çŸ¥è¯†çŠ¶æ€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆRALMï¼‰å­˜åœ¨å¹»è§‰é—®é¢˜ï¼Œä¸”ç¼ºä¹å¯¹å…¶æ‹’è¯†èƒ½åŠ›çš„å……åˆ†è¯„ä¼°ã€‚
2. ç ”ç©¶æ ¸å¿ƒåœ¨äºè¯„ä¼°RALMåœ¨ä¸åŒçŸ¥è¯†çŠ¶æ€ä¸‹çš„æ ¡å‡†æƒ…å†µï¼Œå¹¶æ¢ç©¶å…¶æ‹’è¯†èƒ½åŠ›ä¸æ ¡å‡†è´¨é‡çš„å…³ç³»ã€‚
3. é€šè¿‡ä¸Šä¸‹æ–‡å¾®è°ƒç¼“è§£è¿‡åº¦æ‹’ç»é—®é¢˜ï¼Œå¹¶ç»“åˆä¸ç¡®å®šæ€§ä¼°è®¡æ”¹è¿›RALMçš„æ•´ä½“å›ç­”è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœ‰æ—¶ä¼šç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…ä¸Šä¸æ­£ç¡®çš„å›å¤ï¼Œå³å¹»è§‰ã€‚ç¼“è§£å¹»è§‰ä¸»è¦æœ‰ä¸¤ç§æ–¹æ³•ï¼šæ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆRALMï¼‰å’Œæ‹’ç»åè®­ç»ƒã€‚ç„¶è€Œï¼Œç›®å‰çš„ç ”ç©¶ä¸»è¦é›†ä¸­äºå®ƒä»¬å„è‡ªçš„æœ‰æ•ˆæ€§ï¼Œè€Œå¿½ç•¥äº†å¯¹RALMçš„æ‹’ç»èƒ½åŠ›çš„è¯„ä¼°ã€‚ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœRALMçŸ¥é“å®ƒä»¬ä¸çŸ¥é“ä»€ä¹ˆï¼Œå®ƒä»¬åº”è¯¥æ‹’ç»å›ç­”ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼šRALMæ˜¯å¦çŸ¥é“å®ƒä»¬ä¸çŸ¥é“ä»€ä¹ˆï¼Ÿå…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ç ”ç©¶äº†ä¸‰ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼ŒRALMåœ¨ä¸åŒçš„å†…éƒ¨å’Œå¤–éƒ¨çŸ¥è¯†çŠ¶æ€ä¸‹æ˜¯å¦æ ¡å‡†è‰¯å¥½ï¼Ÿæˆ‘ä»¬è€ƒå¯Ÿäº†å„ç§å› ç´ çš„å½±å“ã€‚ä¸é¢„æœŸç›¸åï¼Œå½“æ‰€æœ‰æ£€ç´¢åˆ°çš„æ–‡æ¡£éƒ½ä¸ç›¸å…³æ—¶ï¼ŒRALMä»ç„¶å€¾å‘äºæ‹’ç»å®ƒä»¬æœ¬å¯ä»¥æ­£ç¡®å›ç­”çš„é—®é¢˜ã€‚å…¶æ¬¡ï¼Œé‰´äºæ¨¡å‹æ˜æ˜¾çš„	extbf{è¿‡åº¦æ‹’ç»}è¡Œä¸ºï¼Œæˆ‘ä»¬æå‡ºäº†ç¬¬äºŒä¸ªé—®é¢˜ï¼šRALMçš„æ‹’ç»èƒ½åŠ›ä¸å…¶æ ¡å‡†è´¨é‡å¦‚ä½•ä¸€è‡´ï¼Ÿæˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè¿‡åº¦æ‹’ç»é—®é¢˜å¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡å¾®è°ƒæ¥ç¼“è§£ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œæ”¹è¿›çš„æ‹’ç»è¡Œä¸ºå¹¶ä¸ä¸€å®šæ„å‘³ç€æ›´å¥½çš„æ ¡å‡†æˆ–æ›´é«˜çš„æ€»ä½“å‡†ç¡®æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬é—®ï¼šæˆ‘ä»¬èƒ½å¦å°†å…·æœ‰æ‹’ç»æ„è¯†çš„RALMä¸åŸºäºä¸ç¡®å®šæ€§çš„ç­”æ¡ˆå›é¿ç›¸ç»“åˆï¼Œä»¥å‡è½»è¿‡åº¦æ‹’ç»ï¼Ÿæˆ‘ä»¬ä¸ºæ‹’ç»åè®­ç»ƒçš„RALMå¼€å‘äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ‹’ç»æœºåˆ¶ï¼Œé€šè¿‡å¹³è¡¡æ‹’ç»å’Œæ­£ç¡®ç­”æ¡ˆæ¥æé«˜å®ƒä»¬çš„æ•´ä½“ç­”æ¡ˆè´¨é‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†å¯¹å½±å“RALMè¡Œä¸ºçš„å› ç´ çš„æ›´å…¨é¢çš„ç†è§£ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼ºè°ƒï¼ŒRALMçš„ä¸ç¡®å®šæ€§ä¼°è®¡ä»ç„¶æ˜¯ä¸€ä¸ªå€¼å¾—æ·±å…¥ç ”ç©¶çš„å¼€æ”¾é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ£€ç´¢å¢å¼ºè¯­è¨€æ¨¡å‹ï¼ˆRALMï¼‰åœ¨é¢å¯¹æœªçŸ¥ä¿¡æ¯æ—¶ï¼Œæ— æ³•æœ‰æ•ˆæ‹’ç»å›ç­”ï¼Œä»è€Œäº§ç”Ÿå¹»è§‰çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æå‡RALMçš„æ£€ç´¢å’Œç”Ÿæˆèƒ½åŠ›ï¼Œè€Œå¿½ç•¥äº†å¯¹å…¶æ‹’è¯†èƒ½åŠ›çš„è¯„ä¼°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç¼ºä¹ç›¸å…³çŸ¥è¯†æ—¶ä»ç„¶ä¼šç»™å‡ºé”™è¯¯ç­”æ¡ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è¯„ä¼°RALMåœ¨ä¸åŒçŸ¥è¯†çŠ¶æ€ä¸‹çš„æ ¡å‡†æƒ…å†µï¼Œå³æ¨¡å‹å¯¹å…¶è‡ªèº«çŸ¥è¯†çš„ç½®ä¿¡åº¦æ˜¯å¦ä¸å…¶å›ç­”çš„æ­£ç¡®æ€§ç›¸ç¬¦ã€‚é€šè¿‡åˆ†æRALMåœ¨æ£€ç´¢åˆ°æ— å…³æ–‡æ¡£æ—¶çš„è¡Œä¸ºï¼Œä»¥åŠæ‹’è¯†èƒ½åŠ›ä¸æ ¡å‡†è´¨é‡ä¹‹é—´çš„å…³ç³»ï¼Œæ¥æ·±å…¥ç†è§£å½±å“RALMæ‹’è¯†èƒ½åŠ›çš„å› ç´ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„ç ”ç©¶æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è¯„ä¼°RALMåœ¨ä¸åŒçŸ¥è¯†çŠ¶æ€ä¸‹çš„æ ¡å‡†æƒ…å†µï¼ŒåŒ…æ‹¬æ£€ç´¢åˆ°ç›¸å…³æ–‡æ¡£ã€æ— å…³æ–‡æ¡£ä»¥åŠæ²¡æœ‰æ£€ç´¢åˆ°æ–‡æ¡£ç­‰æƒ…å†µã€‚2) åˆ†æRALMçš„æ‹’è¯†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯è¿‡åº¦æ‹’ç»ç°è±¡ï¼Œå³æ¨¡å‹æ‹’ç»å›ç­”å…¶æœ¬å¯ä»¥æ­£ç¡®å›ç­”çš„é—®é¢˜ã€‚3) é€šè¿‡ä¸Šä¸‹æ–‡å¾®è°ƒç­‰æ–¹æ³•æ¥ç¼“è§£è¿‡åº¦æ‹’ç»é—®é¢˜ï¼Œå¹¶è¯„ä¼°å…¶å¯¹æ ¡å‡†è´¨é‡å’Œæ€»ä½“å‡†ç¡®æ€§çš„å½±å“ã€‚4) æå‡ºä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„æ‹’ç»æœºåˆ¶ï¼Œç»“åˆæ‹’ç»åè®­ç»ƒçš„RALMï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ¨¡å‹çš„å›ç­”è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹RALMçš„æ‹’è¯†èƒ½åŠ›è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„è¯„ä¼°ï¼Œå¹¶æ­ç¤ºäº†å…¶ä¸æ ¡å‡†è´¨é‡ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ‹’ç»æœºåˆ¶ï¼Œé€šè¿‡å¹³è¡¡æ‹’ç»å’Œæ­£ç¡®ç­”æ¡ˆæ¥æé«˜RALMçš„æ•´ä½“å›ç­”è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä¸åŒçš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°RALMçš„æ ¡å‡†æƒ…å†µå’Œæ‹’è¯†èƒ½åŠ›ã€‚2) é€šè¿‡ä¸Šä¸‹æ–‡å¾®è°ƒæ¥è°ƒæ•´RALMçš„æ‹’è¯†é˜ˆå€¼ï¼Œä»¥ç¼“è§£è¿‡åº¦æ‹’ç»é—®é¢˜ã€‚3) è®¾è®¡ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„æ‹’ç»æœºåˆ¶ï¼Œåˆ©ç”¨æ¨¡å‹è¾“å‡ºçš„ç½®ä¿¡åº¦æ¥åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‹’ç»å›ç­”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸ç›¸å…³æ—¶ï¼ŒRALMå€¾å‘äºæ‹’ç»å›ç­”ï¼Œå³ä½¿å®ƒä»¬æœ¬å¯ä»¥æ­£ç¡®å›ç­”ã€‚é€šè¿‡ä¸Šä¸‹æ–‡å¾®è°ƒå¯ä»¥ç¼“è§£è¿‡åº¦æ‹’ç»é—®é¢˜ï¼Œä½†æ”¹è¿›çš„æ‹’ç»è¡Œä¸ºå¹¶ä¸ä¸€å®šæ„å‘³ç€æ›´å¥½çš„æ ¡å‡†æˆ–æ›´é«˜çš„æ€»ä½“å‡†ç¡®æ€§ã€‚æå‡ºçš„æ‹’ç»æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡æ‹’ç»å’Œæ­£ç¡®ç­”æ¡ˆï¼Œæé«˜RALMçš„æ•´ä½“å›ç­”è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¯é ä¿¡æ¯æ£€ç´¢å’Œé—®ç­”çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€çŸ¥è¯†åº“é—®ç­”ã€åŒ»ç–—è¯Šæ–­è¾…åŠ©ç­‰ã€‚é€šè¿‡æé«˜RALMçš„æ‹’è¯†èƒ½åŠ›ï¼Œå¯ä»¥å‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œæé«˜ç”¨æˆ·å¯¹ç³»ç»Ÿçš„ä¿¡ä»»åº¦ï¼Œå¹¶æœ€ç»ˆæå‡ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing large language models (LLMs) occasionally generate plausible yet factually incorrect responses, known as hallucinations. Two main approaches have been proposed to mitigate hallucinations: retrieval-augmented language models (RALMs) and refusal post-training. However, current research predominantly focuses on their individual effectiveness while overlooking the evaluation of the refusal capability of RALMs. Ideally, if RALMs know when they do not know, they should refuse to answer.In this study, we ask the fundamental question: Do RALMs know when they don't know? Specifically, we investigate three questions. First, are RALMs well calibrated with respect to different internal and external knowledge states? We examine the influence of various factors. Contrary to expectations, when all retrieved documents are irrelevant, RALMs still tend to refuse questions they could have answered correctly. Next, given the model's pronounced \textbf{over-refusal} behavior, we raise a second question: How does a RALM's refusal ability align with its calibration quality? Our results show that the over-refusal problem can be mitigated through in-context fine-tuning. However, we observe that improved refusal behavior does not necessarily imply better calibration or higher overall accuracy. Finally, we ask: Can we combine refusal-aware RALMs with uncertainty-based answer abstention to mitigate over-refusal? We develop a simple yet effective refusal mechanism for refusal-post-trained RALMs that improves their overall answer quality by balancing refusal and correct answers. Our study provides a more comprehensive understanding of the factors influencing RALM behavior. Meanwhile, we emphasize that uncertainty estimation for RALMs remains an open problem deserving deeper investigation.

