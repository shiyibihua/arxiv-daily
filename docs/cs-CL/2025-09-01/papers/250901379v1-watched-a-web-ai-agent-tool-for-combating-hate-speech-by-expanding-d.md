---
layout: default
title: WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data
---

# WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01379" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01379v1</a>
  <a href="https://arxiv.org/pdf/2509.01379.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01379v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01379v1', 'WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Paloma Piot, Diego SÃ¡nchez, Javier Parapar

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWATCHEDï¼Œä¸€ç§åŸºäºWeb AI Agentçš„å†…å®¹å®¡æ ¸å·¥å…·ï¼Œç”¨äºæ£€æµ‹å’Œè§£é‡Šä»‡æ¨è¨€è®ºã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»‡æ¨è¨€è®ºæ£€æµ‹` `å†…å®¹å®¡æ ¸` `äººå·¥æ™ºèƒ½ä»£ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åœ¨çº¿ä»‡æ¨è¨€è®ºæ£€æµ‹æ–¹æ³•ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥å»ºç«‹ç”¨æˆ·ä¿¡ä»»ï¼Œä¸”äººå·¥å®¡æ ¸æ•ˆç‡ä½ã€‚
2. WATCHEDé€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ã€BERTåˆ†ç±»å™¨ã€å¤–éƒ¨çŸ¥è¯†åº“å’Œå¹³å°æŒ‡å—ï¼Œå®ç°ä»‡æ¨è¨€è®ºæ£€æµ‹ä¸è§£é‡Šã€‚
3. å®éªŒè¡¨æ˜ï¼ŒWATCHEDçš„å®F1åˆ†æ•°è¾¾åˆ°0.91ï¼Œè¶…è¶Šç°æœ‰æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨çº¿å±å®³æ˜¯æ•°å­—ç©ºé—´ä¸­æ—¥ç›Šä¸¥é‡çš„é—®é¢˜ï¼Œå¨èƒç”¨æˆ·å®‰å…¨å¹¶é™ä½å¯¹ç¤¾äº¤åª’ä½“å¹³å°çš„ä¿¡ä»»ã€‚ä»‡æ¨è¨€è®ºæ˜¯å…¶ä¸­ä¸€ç§æœ€é¡½å›ºçš„å½¢å¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦å°†è‡ªåŠ¨åŒ–ç³»ç»Ÿçš„é€Ÿåº¦å’Œè§„æ¨¡ä¸äººå·¥å®¡æ ¸å‘˜çš„åˆ¤æ–­å’Œæ´å¯ŸåŠ›ç›¸ç»“åˆçš„å·¥å…·ã€‚è¿™äº›å·¥å…·ä¸ä»…åº”è¯¥æ‰¾åˆ°æœ‰å®³å†…å®¹ï¼Œè¿˜åº”è¯¥æ¸…æ¥šåœ°è§£é‡Šå…¶å†³ç­–ï¼Œå¸®åŠ©å»ºç«‹ä¿¡ä»»å’Œç†è§£ã€‚æœ¬æ–‡ä»‹ç»äº†WATCHEDï¼Œä¸€ä¸ªæ—¨åœ¨æ”¯æŒå†…å®¹å®¡æ ¸å‘˜å¤„ç†ä»‡æ¨è¨€è®ºçš„èŠå¤©æœºå™¨äººã€‚è¯¥èŠå¤©æœºå™¨äººæ„å»ºä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½ä»£ç†ç³»ç»Ÿï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»¥åŠå¤šä¸ªä¸“ç”¨å·¥å…·ã€‚å®ƒå°†æ–°å¸–å­ä¸ä»‡æ¨è¨€è®ºå’Œä¸­æ€§å†…å®¹çš„çœŸå®ç¤ºä¾‹è¿›è¡Œæ¯”è¾ƒï¼Œä½¿ç”¨åŸºäºBERTçš„åˆ†ç±»å™¨æ¥å¸®åŠ©æ ‡è®°æœ‰å®³æ¶ˆæ¯ï¼Œä½¿ç”¨Urban Dictionaryç­‰æ¥æºæŸ¥æ‰¾ä¿šè¯­å’Œéæ­£å¼è¯­è¨€ï¼Œç”Ÿæˆæ€ç»´é“¾æ¨ç†ï¼Œå¹¶æ£€æŸ¥å¹³å°æŒ‡å—ä»¥è§£é‡Šå’Œæ”¯æŒå…¶å†³ç­–ã€‚è¿™ç§ç»„åˆä½¿èŠå¤©æœºå™¨äººä¸ä»…å¯ä»¥æ£€æµ‹ä»‡æ¨è¨€è®ºï¼Œè¿˜å¯ä»¥æ ¹æ®å…ˆä¾‹å’Œæ”¿ç­–è§£é‡Šå†…å®¹ä¸ºä½•è¢«è®¤ä¸ºæ˜¯æœ‰å®³çš„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œè¾¾åˆ°äº†0.91çš„å®F1åˆ†æ•°ã€‚è¯¥å·¥å…·ä¸“ä¸ºå®¡æ ¸å‘˜ã€å®‰å…¨å›¢é˜Ÿå’Œç ”ç©¶äººå‘˜è®¾è®¡ï¼Œé€šè¿‡æ”¯æŒäººå·¥æ™ºèƒ½å’Œäººå·¥ç›‘ç£ä¹‹é—´çš„åä½œæ¥å¸®åŠ©å‡å°‘åœ¨çº¿å±å®³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨çº¿ä»‡æ¨è¨€è®ºæ£€æµ‹å’Œè§£é‡Šçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥è®©ç”¨æˆ·ç†è§£ä¸ºä½•å†…å®¹è¢«åˆ¤å®šä¸ºä»‡æ¨è¨€è®ºã€‚æ­¤å¤–ï¼Œäººå·¥å®¡æ ¸æ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥åº”å¯¹æµ·é‡ä¿¡æ¯ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§èƒ½å¤Ÿè‡ªåŠ¨æ£€æµ‹ä»‡æ¨è¨€è®ºå¹¶æä¾›åˆç†ä¾æ®çš„å·¥å…·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŸºäºWeb AI Agentçš„èŠå¤©æœºå™¨äººWATCHEDï¼Œè¯¥æœºå™¨äººèƒ½å¤Ÿæ¨¡æ‹Ÿäººå·¥å®¡æ ¸å‘˜çš„æ€ç»´è¿‡ç¨‹ï¼Œç»“åˆå¤šç§å·¥å…·å’ŒçŸ¥è¯†æ¥æºï¼Œå¯¹å†…å®¹è¿›è¡Œç»¼åˆåˆ†æï¼Œå¹¶ç»™å‡ºå¯è§£é‡Šçš„åˆ¤æ–­ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜ä»‡æ¨è¨€è®ºæ£€æµ‹çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWATCHEDçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **å†…å®¹æ¯”è¾ƒæ¨¡å—**ï¼šå°†æ–°å¸–å­ä¸å·²çŸ¥çš„ä»‡æ¨è¨€è®ºå’Œä¸­æ€§å†…å®¹ç¤ºä¾‹è¿›è¡Œæ¯”è¾ƒã€‚2) **BERTåˆ†ç±»æ¨¡å—**ï¼šä½¿ç”¨åŸºäºBERTçš„åˆ†ç±»å™¨æ¥æ ‡è®°æœ‰å®³ä¿¡æ¯ã€‚3) **çŸ¥è¯†æŸ¥è¯¢æ¨¡å—**ï¼šåˆ©ç”¨Urban Dictionaryç­‰èµ„æºæŸ¥æ‰¾ä¿šè¯­å’Œéæ­£å¼è¯­è¨€ã€‚4) **æ¨ç†ç”Ÿæˆæ¨¡å—**ï¼šç”Ÿæˆæ€ç»´é“¾æ¨ç†ï¼Œè§£é‡Šåˆ¤æ–­ä¾æ®ã€‚5) **å¹³å°æŒ‡å—æ£€æŸ¥æ¨¡å—**ï¼šæ£€æŸ¥å¹³å°æŒ‡å—ï¼Œç¡®ä¿åˆ¤æ–­ç¬¦åˆæ”¿ç­–ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œæœ€ç»ˆè¾“å‡ºä»‡æ¨è¨€è®ºæ£€æµ‹ç»“æœå’Œè§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šWATCHEDçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»¼åˆåˆ©ç”¨å¤šç§å·¥å…·å’ŒçŸ¥è¯†æ¥æºï¼Œå¹¶ç”Ÿæˆå¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚ä¸ä¼ ç»Ÿçš„å•ä¸€æ¨¡å‹æ–¹æ³•ä¸åŒï¼ŒWATCHEDèƒ½å¤Ÿæ¨¡æ‹Ÿäººå·¥å®¡æ ¸å‘˜çš„æ€ç»´æ–¹å¼ï¼Œæä¾›æ›´å…¨é¢å’Œå¯ä¿¡çš„åˆ¤æ–­ã€‚æ­¤å¤–ï¼Œå°†å¹³å°æŒ‡å—çº³å…¥åˆ¤æ–­ä¾æ®ï¼Œç¡®ä¿äº†ç»“æœçš„åˆè§„æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºå…³é”®å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„çš„å…·ä½“ç»†èŠ‚ã€‚ä½†å¯ä»¥æ¨æ–­ï¼ŒBERTåˆ†ç±»å™¨çš„è®­ç»ƒéœ€è¦å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ä»‡æ¨è¨€è®ºçš„ç‰¹ç‚¹è¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œæ€ç»´é“¾æ¨ç†çš„ç”Ÿæˆå¯èƒ½ä¾èµ–äºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å­¦ä¹ èƒ½åŠ›ï¼Œéœ€è¦ç²¾å¿ƒè®¾è®¡æç¤ºè¯ï¼ˆpromptï¼‰ã€‚Urban Dictionaryç­‰å¤–éƒ¨çŸ¥è¯†åº“çš„é›†æˆä¹Ÿéœ€è¦è€ƒè™‘æ•°æ®æ ¼å¼å’ŒæŸ¥è¯¢æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWATCHEDåœ¨ä»‡æ¨è¨€è®ºæ£€æµ‹ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå®F1åˆ†æ•°è¾¾åˆ°0.91ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼ŒWATCHEDèƒ½å¤Ÿæœ‰æ•ˆåœ°æ£€æµ‹å’Œè§£é‡Šä»‡æ¨è¨€è®ºï¼Œä¸ºå†…å®¹å®¡æ ¸å‘˜æä¾›æœ‰åŠ›çš„æ”¯æŒã€‚å…·ä½“çš„åŸºçº¿æ¨¡å‹å’Œæå‡å¹…åº¦æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®ç»™å‡ºï¼Œéœ€è¦æŸ¥é˜…åŸæ–‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WATCHEDå¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°ã€åœ¨çº¿è®ºå›ç­‰åœºæ™¯ï¼Œè¾…åŠ©å†…å®¹å®¡æ ¸å‘˜è¿›è¡Œä»‡æ¨è¨€è®ºæ£€æµ‹å’Œç®¡ç†ï¼Œæé«˜å®¡æ ¸æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚è¯¥å·¥å…·è¿˜å¯ç”¨äºæ•™è‚²å’Œç ”ç©¶ï¼Œå¸®åŠ©ç”¨æˆ·ç†è§£ä»‡æ¨è¨€è®ºçš„ç‰¹å¾å’Œå±å®³ï¼Œä¿ƒè¿›ç½‘ç»œç©ºé—´çš„å¥åº·å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„åœ¨çº¿æœ‰å®³å†…å®¹æ£€æµ‹ï¼Œä¾‹å¦‚ç½‘ç»œæ¬ºå‡Œå’Œè™šå‡ä¿¡æ¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Online harms are a growing problem in digital spaces, putting user safety at risk and reducing trust in social media platforms. One of the most persistent forms of harm is hate speech. To address this, we need tools that combine the speed and scale of automated systems with the judgment and insight of human moderators. These tools should not only find harmful content but also explain their decisions clearly, helping to build trust and understanding. In this paper, we present WATCHED, a chatbot designed to support content moderators in tackling hate speech. The chatbot is built as an Artificial Intelligence Agent system that uses Large Language Models along with several specialised tools. It compares new posts with real examples of hate speech and neutral content, uses a BERT-based classifier to help flag harmful messages, looks up slang and informal language using sources like Urban Dictionary, generates chain-of-thought reasoning, and checks platform guidelines to explain and support its decisions. This combination allows the chatbot not only to detect hate speech but to explain why content is considered harmful, grounded in both precedent and policy. Experimental results show that our proposed method surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91. Designed for moderators, safety teams, and researchers, the tool helps reduce online harms by supporting collaboration between AI and human oversight.

