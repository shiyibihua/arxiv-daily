---
layout: default
title: Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors
---

# Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01236" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01236v1</a>
  <a href="https://arxiv.org/pdf/2509.01236.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01236v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01236v1', 'Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Yang, Zhiyu Yang, Yunjie Zhang, Shanyi Zhu, Lin Yang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**DOI**: [10.1007/978-981-95-0020-8_34](https://doi.org/10.1007/978-981-95-0020-8_34)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ·±å…¥æ¢ç©¶æ€ç»´é“¾ï¼šä¸Šä¸‹æ–‡å­¦ä¹ ä¸é¢„è®­ç»ƒå…ˆéªŒçš„åŒé‡è§’è‰²**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ€ç»´é“¾æ¨ç†` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `é¢„è®­ç»ƒå…ˆéªŒ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æç¤ºå·¥ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ€ç»´é“¾æ¨ç†æœºåˆ¶å°šä¸æ˜ç¡®ï¼Œæ¨¡å‹è¡Œä¸ºä¾èµ–é¢„è®­ç»ƒå…ˆéªŒï¼Œæ˜“å—å™ªå£°å¹²æ‰°ã€‚
2. ä»ä¸Šä¸‹æ–‡å­¦ä¹ å’Œé¢„è®­ç»ƒå…ˆéªŒçš„åŒé‡å…³ç³»å…¥æ‰‹ï¼Œåˆ†ææ¨¡å‹æ¨ç†è¡Œä¸ºå’Œå†³ç­–æœºåˆ¶ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹ä¾èµ–é¢„è®­ç»ƒå…ˆéªŒï¼Œä½†å¯éšæ ·æœ¬è½¬ç§»å†³ç­–ï¼Œé•¿é“¾æç¤ºæå‡æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ€ç»´é“¾ï¼ˆChain-of-Thought, CoTï¼‰æ¨ç†å·²æˆä¸ºå¢å¼ºæ¨¡å‹æ¨ç†èƒ½åŠ›çš„å…³é”®æ–¹æ³•ã€‚å°½ç®¡äººä»¬å¯¹æ€ç»´é“¾æ¨ç†çš„å…´è¶£æ—¥ç›Šæµ“åšï¼Œä½†å…¶æ½œåœ¨æœºåˆ¶ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡ä»ä¸Šä¸‹æ–‡å­¦ä¹ å’Œé¢„è®­ç»ƒå…ˆéªŒçš„åŒé‡å…³ç³»è§’åº¦æ¢è®¨äº†æ€ç»´é“¾æ¨ç†çš„å·¥ä½œæœºåˆ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯¹ç†ç”±ï¼ˆrationalesï¼‰è¿›è¡Œç»†ç²’åº¦çš„è¯æ±‡çº§åˆ†æï¼Œä»¥æ£€æŸ¥æ¨¡å‹çš„æ¨ç†è¡Œä¸ºã€‚ç„¶åï¼Œé€šè¿‡é€æ­¥å¼•å…¥å™ªå£°æ ·æœ¬ï¼Œæˆ‘ä»¬ç ”ç©¶äº†æ¨¡å‹å¦‚ä½•åœ¨é¢„è®­ç»ƒå…ˆéªŒå’Œé”™è¯¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¹‹é—´è¿›è¡Œå¹³è¡¡ã€‚æœ€åï¼Œæˆ‘ä»¬ç ”ç©¶äº†æç¤ºå·¥ç¨‹æ˜¯å¦å¯ä»¥è¯±å¯¼å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ…¢æ€è€ƒã€‚æˆ‘ä»¬å¹¿æ³›çš„å®éªŒæ­ç¤ºäº†ä¸‰ä¸ªå…³é”®å‘ç°ï¼šï¼ˆ1ï¼‰æ¨¡å‹ä¸ä»…åœ¨è¯æ±‡å±‚é¢å¿«é€Ÿå­¦ä¹ æ¨ç†ç»“æ„ï¼Œè€Œä¸”æŒæ¡äº†æ›´æ·±å±‚æ¬¡çš„é€»è¾‘æ¨ç†æ¨¡å¼ï¼Œä½†å®ƒä¸¥é‡ä¾èµ–äºé¢„è®­ç»ƒå…ˆéªŒã€‚ï¼ˆ2ï¼‰æä¾›è¶³å¤Ÿçš„æ ·æœ¬å¯ä»¥å°†æ¨¡å‹çš„å†³ç­–ä»é¢„è®­ç»ƒå…ˆéªŒè½¬ç§»åˆ°ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œè€Œè¯¯å¯¼æ€§çš„æç¤ºä¼šå¼•å…¥ä¸ç¨³å®šæ€§ã€‚ï¼ˆ3ï¼‰é•¿æ€ç»´é“¾æç¤ºå¯ä»¥è¯±å¯¼æ¨¡å‹ç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ï¼Œä»è€Œæé«˜å…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ€ç»´é“¾æ¨ç†æ–¹æ³•çš„å†…åœ¨æœºåˆ¶å°šä¸æ¸…æ™°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œå¦‚ä½•å¹³è¡¡åˆ©ç”¨é¢„è®­ç»ƒçŸ¥è¯†å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚æ¨¡å‹å®¹æ˜“å—åˆ°å™ªå£°æ ·æœ¬çš„å¹²æ‰°ï¼Œå¯¼è‡´æ¨ç†ç»“æœä¸ç¨³å®šã€‚å› æ­¤ï¼Œéœ€è¦æ·±å…¥ç†è§£æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„çŸ¥è¯†æ¥æºå’Œå†³ç­–æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»ä¸Šä¸‹æ–‡å­¦ä¹ å’Œé¢„è®­ç»ƒå…ˆéªŒçš„åŒé‡è§’åº¦æ¥åˆ†ææ€ç»´é“¾æ¨ç†ã€‚é€šè¿‡ç»†ç²’åº¦çš„è¯æ±‡çº§åˆ†æï¼Œè€ƒå¯Ÿæ¨¡å‹å¦‚ä½•å­¦ä¹ æ¨ç†ç»“æ„å’Œé€»è¾‘æ¨¡å¼ã€‚é€šè¿‡å¼•å…¥å™ªå£°æ ·æœ¬ï¼Œç ”ç©¶æ¨¡å‹å¦‚ä½•åœ¨é¢„è®­ç»ƒå…ˆéªŒå’Œä¸Šä¸‹æ–‡ä¿¡æ¯ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚é€šè¿‡è®¾è®¡ä¸åŒçš„æç¤ºï¼Œæ¢ç´¢å¦‚ä½•è¯±å¯¼æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡çš„ç ”ç©¶æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†ï¼š1) å¯¹æ€ç»´é“¾æ¨ç†çš„ç†ç”±è¿›è¡Œè¯æ±‡çº§åˆ†æï¼Œè€ƒå¯Ÿæ¨¡å‹å¯¹æ¨ç†ç»“æ„çš„ç†è§£ç¨‹åº¦ï¼›2) é€šè¿‡é€æ­¥å¼•å…¥å™ªå£°æ ·æœ¬ï¼Œåˆ†ææ¨¡å‹å¦‚ä½•åœ¨é¢„è®­ç»ƒå…ˆéªŒå’Œä¸Šä¸‹æ–‡ä¿¡æ¯ä¹‹é—´è¿›è¡Œå¹³è¡¡ï¼›3) é€šè¿‡prompt engineeringï¼Œæ¢ç´¢å¦‚ä½•è¯±å¯¼æ¨¡å‹è¿›è¡Œæ…¢æ€è€ƒï¼Œç”Ÿæˆæ›´é•¿çš„æ¨ç†é“¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºä»ä¸Šä¸‹æ–‡å­¦ä¹ å’Œé¢„è®­ç»ƒå…ˆéªŒçš„åŒé‡è§’åº¦æ¥åˆ†ææ€ç»´é“¾æ¨ç†ï¼Œæ­ç¤ºäº†æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çŸ¥è¯†æ¥æºå’Œå†³ç­–æœºåˆ¶ã€‚é€šè¿‡ç»†ç²’åº¦çš„åˆ†æå’Œå®éªŒï¼Œå‘ç°æ¨¡å‹ä¸ä»…å­¦ä¹ äº†æ¨ç†ç»“æ„ï¼Œè¿˜æŒæ¡äº†é€»è¾‘æ¨ç†æ¨¡å¼ï¼Œä½†åŒæ—¶ä¹Ÿä¸¥é‡ä¾èµ–é¢„è®­ç»ƒå…ˆéªŒã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢ç´¢äº†å¦‚ä½•é€šè¿‡prompt engineeringæ¥æ”¹å–„æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒè®¾è®¡æ–¹é¢ï¼Œæœ¬æ–‡é‡‡ç”¨äº†å¤šç§ç­–ç•¥æ¥è€ƒå¯Ÿæ¨¡å‹çš„æ¨ç†è¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œé€šè¿‡è¯æ±‡çº§åˆ†æï¼Œè€ƒå¯Ÿæ¨¡å‹å¯¹æ¨ç†ç»“æ„çš„ç†è§£ç¨‹åº¦ï¼›é€šè¿‡å¼•å…¥ä¸åŒç¨‹åº¦çš„å™ªå£°æ ·æœ¬ï¼Œåˆ†ææ¨¡å‹å¯¹ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æ•æ„Ÿæ€§ï¼›é€šè¿‡è®¾è®¡ä¸åŒé•¿åº¦çš„æ€ç»´é“¾æç¤ºï¼Œæ¢ç´¢å¦‚ä½•è¯±å¯¼æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„æ¨ç†ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹ä¸ä»…èƒ½å¿«é€Ÿå­¦ä¹ æ¨ç†ç»“æ„ï¼Œè¿˜èƒ½æŒæ¡æ›´æ·±å±‚æ¬¡çš„é€»è¾‘æ¨ç†æ¨¡å¼ï¼Œä½†ä¸¥é‡ä¾èµ–é¢„è®­ç»ƒå…ˆéªŒã€‚æä¾›è¶³å¤Ÿæ ·æœ¬å¯å°†å†³ç­–ä»é¢„è®­ç»ƒå…ˆéªŒè½¬ç§»åˆ°ä¸Šä¸‹æ–‡ä¿¡å·ï¼Œè€Œè¯¯å¯¼æ€§æç¤ºä¼šå¼•å…¥ä¸ç¨³å®šæ€§ã€‚é•¿æ€ç»´é“¾æç¤ºèƒ½è¯±å¯¼æ¨¡å‹ç”Ÿæˆæ›´é•¿æ¨ç†é“¾ï¼Œæå‡ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤æ‚é€»è¾‘æ¨ç†çš„åœºæ™¯ä¸­ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†å›¾è°±æ¨ç†ã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£å’Œæ§åˆ¶æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­å‘æŒ¥æ›´å¤§çš„ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing model inference capabilities. Despite growing interest in Chain-of-Thought reasoning, its underlying mechanisms remain unclear. This paper explores the working mechanisms of Chain-of-Thought reasoning from the perspective of the dual relationship between in-context learning and pretrained priors. We first conduct a fine-grained lexical-level analysis of rationales to examine the model's reasoning behavior. Then, by incrementally introducing noisy exemplars, we examine how the model balances pretrained priors against erroneous in-context information. Finally, we investigate whether prompt engineering can induce slow thinking in large language models. Our extensive experiments reveal three key findings: (1) The model not only quickly learns the reasoning structure at the lexical level but also grasps deeper logical reasoning patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient exemplars shifts the model's decision-making from pretrained priors to in-context signals, while misleading prompts introduce instability. (3) Long Chain-of-Thought prompting can induce the model to generate longer reasoning chains, thereby improving its performance on downstream tasks.

