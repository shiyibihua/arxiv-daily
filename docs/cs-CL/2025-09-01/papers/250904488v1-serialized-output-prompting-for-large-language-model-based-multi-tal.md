---
layout: default
title: Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition
---

# Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04488" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04488v1</a>
  <a href="https://arxiv.org/pdf/2509.04488.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04488v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04488v1', 'Serialized Output Prompting for Large Language Model-based Multi-Talker Speech Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Shi, Yusuke Fujita, Tomoya Mizumoto, Lianbo Liu, Atsushi Kojima, Yui Sudo

**åˆ†ç±»**: cs.CL, cs.AI, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåºåˆ—åŒ–è¾“å‡ºæç¤ºä»¥æå‡å¤šè¯´è¯è€…è¯­éŸ³è¯†åˆ«æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯´è¯è€…è¯†åˆ«` `åºåˆ—åŒ–è¾“å‡º` `è¯­è¨€æ¨¡å‹` `è¯­éŸ³è¯†åˆ«` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMåŸºç¡€å¤šè¯´è¯è€…ASRç³»ç»Ÿè¦ä¹ˆçœç•¥æç¤ºï¼Œè¦ä¹ˆä»…ä¾èµ–ç®€å•çš„ä»»åŠ¡å®šä¹‰æç¤ºï¼Œæœªèƒ½æœ‰æ•ˆæå‡æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºåºåˆ—åŒ–è¾“å‡ºæç¤ºï¼ˆSOPï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–æç¤ºæ˜¾å¼å¼•å¯¼LLMï¼Œä»è€Œæ”¹å–„å¤šè¯´è¯è€…è¯­éŸ³è¯†åˆ«çš„æ€§èƒ½ã€‚
3. åœ¨LibriMixæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„SOPæ–¹æ³•åœ¨åŒè¯´è¯è€…å’Œä¸‰è¯´è¯è€…åœºæ™¯ä¸­å‡æ˜¾è‘—æå‡äº†è¯†åˆ«æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æç¤ºåœ¨ä»»åŠ¡å®šä¹‰å’Œæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿæ€§èƒ½ä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºäºLLMçš„å¤šè¯´è¯è€…è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ç³»ç»Ÿè¦ä¹ˆçœç•¥æç¤ºï¼Œè¦ä¹ˆä¾èµ–ç®€å•çš„ä»»åŠ¡å®šä¹‰æç¤ºï¼Œç¼ºä¹é’ˆå¯¹æç¤ºè®¾è®¡ä»¥å¢å¼ºæ€§èƒ½çš„ç ”ç©¶ã€‚æœ¬æ–‡æå‡ºæå–åºåˆ—åŒ–è¾“å‡ºæç¤ºï¼ˆSOPï¼‰ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–æç¤ºæ˜¾å¼å¼•å¯¼LLMï¼Œä»¥æ”¹å–„ç³»ç»Ÿæ€§èƒ½ï¼ˆSOP-MT-ASRï¼‰ã€‚åœ¨è¯­éŸ³ç¼–ç å™¨åæ’å…¥åˆ†éš”ç¬¦å’Œåºåˆ—åŒ–è¿æ¥æ—¶åºåˆ†ç±»ï¼ˆCTCï¼‰å±‚ï¼Œä»¥FIFOæ–¹å¼åˆ†ç¦»å’Œæå–æ··åˆè¯­éŸ³ç¼–ç ä¸­çš„å¤šè¯´è¯è€…å†…å®¹ã€‚éšåï¼Œé€šè¿‡è´ªå©ªæœç´¢è§£ç åºåˆ—åŒ–CTCè¾“å‡ºè·å¾—SOPï¼Œä½œä¸ºLLMçš„æç¤ºã€‚ä¸ºæœ‰æ•ˆè®­ç»ƒæ¨¡å‹ï¼Œè®¾è®¡äº†ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬åºåˆ—åŒ–è¾“å‡ºè®­ç»ƒï¼ˆSOTï¼‰å¾®è°ƒã€åºåˆ—åŒ–è¯­éŸ³ä¿¡æ¯æå–å’ŒåŸºäºSOPçš„é€‚åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡LLMåŸºäºSOTæ¨¡å‹åœ¨åŒè¯´è¯è€…åœºæ™¯ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ›´å¤æ‚çš„ä¸‰è¯´è¯è€…åœºæ™¯ä¸­æœªèƒ½å……åˆ†åˆ©ç”¨LLMã€‚æ‰€æSOPæ–¹æ³•åœ¨åŒè¯´è¯è€…å’Œä¸‰è¯´è¯è€…æ¡ä»¶ä¸‹æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŸºäºLLMçš„å¤šè¯´è¯è€…è‡ªåŠ¨è¯­éŸ³è¯†åˆ«ç³»ç»Ÿåœ¨å¤æ‚åœºæ™¯ä¸‹æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†æç¤ºè®¾è®¡ï¼Œå¯¼è‡´æ— æ³•å……åˆ†åˆ©ç”¨LLMçš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡æå–åºåˆ—åŒ–è¾“å‡ºæç¤ºï¼ˆSOPï¼‰æ¥æ˜¾å¼å¼•å¯¼LLMï¼Œåˆ©ç”¨ç»“æ„åŒ–æç¤ºæ¥æå‡å¤šè¯´è¯è€…è¯­éŸ³è¯†åˆ«çš„æ•ˆæœã€‚è¯¥æ–¹æ³•é€šè¿‡FIFOæ–¹å¼å¤„ç†æ··åˆè¯­éŸ³ç¼–ç ï¼Œç¡®ä¿æœ‰æ•ˆæå–å¤šè¯´è¯è€…å†…å®¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šè¯­éŸ³ç¼–ç å™¨ã€åºåˆ—åŒ–è¿æ¥æ—¶åºåˆ†ç±»ï¼ˆCTCï¼‰å±‚å’ŒLLMæç¤ºç”Ÿæˆã€‚é¦–å…ˆï¼Œè¯­éŸ³ç¼–ç å™¨å¤„ç†è¾“å…¥è¯­éŸ³ä¿¡å·ï¼Œæ¥ç€CTCå±‚åˆ†ç¦»å¹¶æå–å¤šè¯´è¯è€…å†…å®¹ï¼Œæœ€åç”ŸæˆSOPä½œä¸ºLLMçš„è¾“å…¥æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥åºåˆ—åŒ–è¾“å‡ºæç¤ºï¼ˆSOPï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–æç¤ºæ˜¾è‘—æå‡äº†å¤šè¯´è¯è€…è¯­éŸ³è¯†åˆ«çš„æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç®€å•ä»»åŠ¡å®šä¹‰æç¤ºæœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¼•å¯¼LLMã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œè®¾è®¡äº†ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬åºåˆ—åŒ–è¾“å‡ºè®­ç»ƒï¼ˆSOTï¼‰å¾®è°ƒã€åºåˆ—åŒ–è¯­éŸ³ä¿¡æ¯æå–å’ŒåŸºäºSOPçš„é€‚åº”ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒåŸæ–‡è·å–æ›´å¤šæŠ€æœ¯ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SOPæ–¹æ³•åœ¨åŒè¯´è¯è€…å’Œä¸‰è¯´è¯è€…åœºæ™¯ä¸­å‡æ˜¾è‘—æé«˜äº†è¯†åˆ«æ€§èƒ½ã€‚åœ¨åŒè¯´è¯è€…åœºæ™¯ä¸­ï¼ŒLLMåŸºäºSOTæ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ä¸‰è¯´è¯è€…åœºæ™¯ä¸­ï¼ŒSOPæ–¹æ³•çš„å¼•å…¥ä½¿å¾—æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå…·ä½“æå‡å¹…åº¦åœ¨å®éªŒä¸­æœ‰è¯¦ç»†æ•°æ®æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¼šè®®è®°å½•ã€è¯­éŸ³åŠ©æ‰‹å’Œå¤šæ–¹é€šè¯çš„è¯­éŸ³è¯†åˆ«ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡å¤šè¯´è¯è€…è¯­éŸ³è¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´ä¼˜è´¨çš„è¯­éŸ³äº¤äº’ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prompts are crucial for task definition and for improving the performance of large language models (LLM)-based systems. However, existing LLM-based multi-talker (MT) automatic speech recognition (ASR) systems either omit prompts or rely on simple task-definition prompts, with no prior work exploring the design of prompts to enhance performance. In this paper, we propose extracting serialized output prompts (SOP) and explicitly guiding the LLM using structured prompts to improve system performance (SOP-MT-ASR). A Separator and serialized Connectionist Temporal Classification (CTC) layers are inserted after the speech encoder to separate and extract MT content from the mixed speech encoding in a first-speaking-first-out manner. Subsequently, the SOP, which serves as a prompt for LLMs, is obtained by decoding the serialized CTC outputs using greedy search. To train the model effectively, we design a three-stage training strategy, consisting of serialized output training (SOT) fine-tuning, serialized speech information extraction, and SOP-based adaptation. Experimental results on the LibriMix dataset show that, although the LLM-based SOT model performs well in the two-talker scenario, it fails to fully leverage LLMs under more complex conditions, such as the three-talker scenario. The proposed SOP approach significantly improved performance under both two- and three-talker conditions.

