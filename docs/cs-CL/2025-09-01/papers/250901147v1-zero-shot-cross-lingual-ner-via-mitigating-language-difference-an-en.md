---
layout: default
title: Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective
---

# Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01147" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01147v1</a>
  <a href="https://arxiv.org/pdf/2509.01147.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01147v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01147v1', 'Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhihao Zhang, Sophia Yat Mei Lee, Dong Zhang, Shoushan Li, Guodong Zhou

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**å¤‡æ³¨**: EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®ä½“å¯¹é½ç¿»è¯‘æ–¹æ³•ï¼Œè§£å†³é›¶æ ·æœ¬è·¨è¯­è¨€å‘½åå®ä½“è¯†åˆ«ä¸­éæ‹‰ä¸è¯­ç³»æ€§èƒ½ä¸‹é™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è·¨è¯­è¨€å‘½åå®ä½“è¯†åˆ«` `é›¶æ ·æœ¬å­¦ä¹ ` `éæ‹‰ä¸è¯­ç³»è¯­è¨€` `å®ä½“å¯¹é½` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›¶æ ·æœ¬è·¨è¯­è¨€NERæ–¹æ³•åœ¨éæ‹‰ä¸è¯­ç³»è¯­è¨€ä¸Šè¡¨ç°ä¸ä½³ï¼Œæºäºæ·±å±‚ç»“æ„å·®å¼‚å¯¼è‡´çš„çŸ¥è¯†è¿ç§»å›°éš¾ã€‚
2. è®ºæ–‡æå‡ºå®ä½“å¯¹é½ç¿»è¯‘(EAT)æ–¹æ³•ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒåŒé‡ç¿»è¯‘ï¼Œå¯¹é½ä¸åŒè¯­è¨€çš„å®ä½“è¡¨ç¤ºã€‚
3. é€šè¿‡å¤šè¯­è¨€ç»´åŸºç™¾ç§‘æ•°æ®å¾®è°ƒLLMï¼ŒEATè¿›ä¸€æ­¥æå‡äº†å®ä½“å¯¹é½çš„å‡†ç¡®æ€§ï¼Œä»è€Œæ”¹å–„äº†è·¨è¯­è¨€NERæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è·¨è¯­è¨€å‘½åå®ä½“è¯†åˆ«(CL-NER)æ—¨åœ¨å°†çŸ¥è¯†ä»é«˜èµ„æºè¯­è¨€è¿ç§»åˆ°ä½èµ„æºè¯­è¨€ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é›¶æ ·æœ¬CL-NER (ZCL-NER)æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ‹‰ä¸è¯­ç³»è¯­è¨€(LSL)ä¸Šï¼Œè¿™äº›è¯­è¨€ä¸­å…±äº«çš„è¯­è¨€ç‰¹å¾æœ‰åŠ©äºæœ‰æ•ˆçš„çŸ¥è¯†è¿ç§»ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå¯¹äºéæ‹‰ä¸è¯­ç³»è¯­è¨€(NSL)ï¼Œå¦‚ä¸­æ–‡å’Œæ—¥è¯­ï¼Œç”±äºæ·±å±‚çš„ç»“æ„å·®å¼‚ï¼Œæ€§èƒ½é€šå¸¸ä¼šä¸‹é™ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å®ä½“å¯¹é½ç¿»è¯‘(EAT)æ–¹æ³•ã€‚EATåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ï¼Œé‡‡ç”¨åŒé‡ç¿»è¯‘ç­–ç•¥æ¥å¯¹é½NSLå’Œè‹±è¯­ä¹‹é—´çš„å®ä½“ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šè¯­è¨€ç»´åŸºç™¾ç§‘æ•°æ®å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä»¥å¢å¼ºä»æºè¯­è¨€åˆ°ç›®æ ‡è¯­è¨€çš„å®ä½“å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é›¶æ ·æœ¬è·¨è¯­è¨€å‘½åå®ä½“è¯†åˆ«ï¼ˆZCL-NERï¼‰åœ¨éæ‹‰ä¸è¯­ç³»è¯­è¨€ï¼ˆNSLï¼‰ä¸Šæ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ‹‰ä¸è¯­ç³»è¯­è¨€ä¸Šè¡¨ç°è‰¯å¥½ï¼Œå› ä¸ºå®ƒä»¬å…±äº«è®¸å¤šè¯­è¨€ç‰¹å¾ï¼Œä¾¿äºçŸ¥è¯†è¿ç§»ã€‚ç„¶è€Œï¼Œå¯¹äºåƒä¸­æ–‡å’Œæ—¥è¯­è¿™æ ·çš„NSLï¼Œç”±äºå…¶ä¸è‹±è¯­ç­‰æ‹‰ä¸è¯­ç³»è¯­è¨€å­˜åœ¨è¾ƒå¤§çš„ç»“æ„å·®å¼‚ï¼Œç›´æ¥åº”ç”¨ç°æœ‰æ–¹æ³•ä¼šå¯¼è‡´æ€§èƒ½å¤§å¹…é™ä½ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°å°†çŸ¥è¯†ä»é«˜èµ„æºæ‹‰ä¸è¯­ç³»è¯­è¨€è¿ç§»åˆ°ä½èµ„æºNSLæ˜¯æœ¬ç ”ç©¶è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å®ä½“å¯¹é½æ¥ç¼“è§£è¯­è¨€å·®å¼‚å¸¦æ¥çš„è´Ÿé¢å½±å“ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§å®ä½“å¯¹é½ç¿»è¯‘ï¼ˆEATï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å°†ä¸åŒè¯­è¨€çš„å®ä½“æ˜ å°„åˆ°åŒä¸€è¯­ä¹‰ç©ºé—´ã€‚é€šè¿‡å¯¹é½å®ä½“ï¼ŒEATèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨æºè¯­è¨€ä¸­çš„çŸ¥è¯†ï¼Œä»è€Œæé«˜ç›®æ ‡è¯­è¨€ä¸Šçš„NERæ€§èƒ½ã€‚è¿™ç§æ–¹æ³•çš„å…³é”®åœ¨äºç¡®ä¿ä¸åŒè¯­è¨€çš„å®ä½“åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEATæ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **åŒé‡ç¿»è¯‘**ï¼šé¦–å…ˆï¼Œåˆ©ç”¨LLMå°†NSLæ–‡æœ¬ç¿»è¯‘æˆè‹±æ–‡ï¼Œç„¶åå†å°†è‹±æ–‡ç¿»è¯‘å›NSLã€‚è¿™ç§åŒé‡ç¿»è¯‘çš„ç›®çš„æ˜¯å¢å¼ºå®ä½“è¯†åˆ«çš„é²æ£’æ€§ï¼Œå¹¶å‡å°‘ç¿»è¯‘è¿‡ç¨‹ä¸­çš„å™ªå£°ã€‚2) **å®ä½“å¯¹é½**ï¼šåœ¨åŒé‡ç¿»è¯‘çš„åŸºç¡€ä¸Šï¼ŒEATåˆ©ç”¨LLMå¯¹é½åŸå§‹NSLæ–‡æœ¬å’Œç¿»è¯‘åçš„NSLæ–‡æœ¬ä¸­çš„å®ä½“ã€‚è¿™ç§å¯¹é½è¿‡ç¨‹æ—¨åœ¨ç¡®ä¿ç¿»è¯‘åçš„æ–‡æœ¬èƒ½å¤Ÿä¿ç•™åŸå§‹æ–‡æœ¬ä¸­çš„å®ä½“ä¿¡æ¯ã€‚3) **LLMå¾®è°ƒ**ï¼šä¸ºäº†æé«˜å®ä½“å¯¹é½çš„å‡†ç¡®æ€§ï¼Œè®ºæ–‡ä½¿ç”¨å¤šè¯­è¨€ç»´åŸºç™¾ç§‘æ•°æ®å¯¹LLMè¿›è¡Œå¾®è°ƒã€‚è¿™ç§å¾®è°ƒè¿‡ç¨‹æ—¨åœ¨å¢å¼ºLLMå¯¹ä¸åŒè¯­è¨€å®ä½“çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šEATæ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºå…¶åˆ©ç”¨åŒé‡ç¿»è¯‘å’Œå®ä½“å¯¹é½æ¥ç¼“è§£è¯­è¨€å·®å¼‚ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒEATæ›´åŠ å…³æ³¨å®ä½“çº§åˆ«çš„å¯¹é½ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºè¯çº§åˆ«çš„ç¿»è¯‘ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä½¿ç”¨å¤šè¯­è¨€ç»´åŸºç™¾ç§‘æ•°æ®å¯¹LLMè¿›è¡Œå¾®è°ƒï¼ŒEATèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒè¯­è¨€çš„ç‰¹ç‚¹ï¼Œä»è€Œæé«˜å®ä½“å¯¹é½çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šEATæ–¹æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **LLMçš„é€‰æ‹©**ï¼šè®ºæ–‡é€‰æ‹©äº†å…·æœ‰å¼ºå¤§ç¿»è¯‘èƒ½åŠ›å’Œè¯­ä¹‰ç†è§£èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ã€‚2) **åŒé‡ç¿»è¯‘ç­–ç•¥**ï¼šé€šè¿‡å…ˆç¿»è¯‘æˆè‹±æ–‡å†ç¿»è¯‘å›ç›®æ ‡è¯­è¨€ï¼Œå¯ä»¥å‡å°‘ç¿»è¯‘è¿‡ç¨‹ä¸­çš„åå·®ã€‚3) **å®ä½“å¯¹é½æŸå¤±å‡½æ•°**ï¼šè®ºæ–‡è®¾è®¡äº†ä¸€ç§æŸå¤±å‡½æ•°ï¼Œç”¨äºè¡¡é‡åŸå§‹æ–‡æœ¬å’Œç¿»è¯‘åæ–‡æœ¬ä¸­å®ä½“å¯¹é½çš„ç¨‹åº¦ã€‚4) **å¾®è°ƒæ•°æ®é›†**ï¼šè®ºæ–‡ä½¿ç”¨äº†å¤šè¯­è¨€ç»´åŸºç™¾ç§‘æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»¥å¢å¼ºLLMå¯¹ä¸åŒè¯­è¨€å®ä½“çš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºçš„EATæ–¹æ³•åœ¨éæ‹‰ä¸è¯­ç³»è¯­è¨€çš„é›¶æ ·æœ¬è·¨è¯­è¨€NERä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEATæ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨ä¸­æ–‡å’Œæ—¥è¯­ç­‰è¯­è¨€ä¸Šï¼Œæ€§èƒ½æå‡å¹…åº¦æ˜æ˜¾ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šè¯­è¨€ä¿¡æ¯æŠ½å–ã€è·¨è¯­è¨€çŸ¥è¯†å›¾è°±æ„å»ºã€å…¨çƒåŒ–å®¢æˆ·æœåŠ¡ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡éæ‹‰ä¸è¯­ç³»è¯­è¨€çš„å‘½åå®ä½“è¯†åˆ«èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½è¯­è¨€éšœç¢ï¼Œä¿ƒè¿›è·¨æ–‡åŒ–äº¤æµä¸åˆä½œï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œå¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge from high-resource languages to low-resource languages. However, existing zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language (LSL), where shared linguistic features facilitate effective knowledge transfer. In contrast, for non-Latin script language (NSL), such as Chinese and Japanese, performance often degrades due to deep structural differences. To address these challenges, we propose an entity-aligned translation (EAT) approach. Leveraging large language models (LLMs), EAT employs a dual-translation strategy to align entities between NSL and English. In addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the entity alignment from source to target languages.

