---
layout: default
title: Efficient Large Language Models with Zero-Shot Adjustable Acceleration
---

# Efficient Large Language Models with Zero-Shot Adjustable Acceleration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01190" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01190v2</a>
  <a href="https://arxiv.org/pdf/2509.01190.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01190v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01190v2', 'Efficient Large Language Models with Zero-Shot Adjustable Acceleration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sajjad Kachuee, Mohammad Sharifkhani

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01 (æ›´æ–°: 2025-09-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶æ ·æœ¬å¯è°ƒåŠ é€Ÿæ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨¡å‹åŠ é€Ÿ` `é›¶æ ·æœ¬å­¦ä¹ ` `æ¨ç†ä¼˜åŒ–` `ç¡¬ä»¶åˆ©ç”¨ç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´è®¡ç®—æ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¾®è°ƒåå’Œæ¨ç†é˜¶æ®µçš„åŠ é€Ÿä¼˜åŒ–ã€‚
2. è®ºæ–‡æå‡ºé›¶æ ·æœ¬å¯è°ƒåŠ é€Ÿæ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´ç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œåœ¨æ¨ç†é˜¶æ®µå®ç°åŠ é€Ÿï¼Œæ— éœ€é¢å¤–å¾®è°ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœï¼Œæœ€é«˜å¯è¾¾11å€äºåŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºé›¶æ ·æœ¬å¯è°ƒåŠ é€Ÿçš„å…¨æ–°è®­ç»ƒå’Œæ¨ç†æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶ï¼Œè®¡ç®—æ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´éš¾ä»¥å¹³è¡¡çš„éš¾é¢˜ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œè€Œæ— éœ€é¢å¤–çš„å¾®è°ƒã€‚è¯¥æ–¹æ³•è¢«åº”ç”¨äºæœ€æ–°çš„LLMï¼Œå¹¶åœ¨å¤šä¸ªåˆ†ç±»å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ”¯æŒå¹¿æ³›çš„é›¶æ ·æœ¬åŠ é€Ÿï¼Œå¹¶å®ç°äº†é«˜è¾¾11å€äºåŸºçº¿çš„é€Ÿåº¦æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨éƒ¨ç½²åˆ°å®é™…åº”ç”¨ä¸­æ—¶ï¼Œé¢ä¸´ç€è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€æ¨ç†é€Ÿåº¦æ…¢çš„é—®é¢˜ã€‚å°¤å…¶æ˜¯åœ¨è¾¹ç¼˜è®¾å¤‡æˆ–èµ„æºå—é™çš„ç¯å¢ƒä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆåœ°åˆ©ç”¨ç¡¬ä»¶èµ„æºï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œå°½å¯èƒ½åœ°é™ä½å»¶è¿Ÿï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•é€šå¸¸éœ€è¦é’ˆå¯¹ç‰¹å®šç¡¬ä»¶è¿›è¡Œå¾®è°ƒï¼Œæˆ–è€…é‡‡ç”¨æ¨¡å‹å‹ç¼©ç­‰æŠ€æœ¯ï¼Œä½†è¿™äº›æ–¹æ³•å¾€å¾€ä¼šç‰ºç‰²æ¨¡å‹ç²¾åº¦ï¼Œæˆ–è€…éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æå‡ºä¸€ç§é›¶æ ·æœ¬å¯è°ƒåŠ é€Ÿæ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨æ¨ç†é˜¶æ®µåŠ¨æ€åœ°è°ƒæ•´ç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œä»è€Œåœ¨æ¨¡å‹æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªå¹³è¡¡ç‚¹ã€‚è¿™ç§æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„å¾®è°ƒï¼Œå› æ­¤å¯ä»¥å¿«é€Ÿåœ°åº”ç”¨äºå„ç§LLMï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚çµæ´»åœ°è°ƒæ•´åŠ é€Ÿç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šè®­ç»ƒé˜¶æ®µå’Œæ¨ç†é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹é‡‡ç”¨æ ‡å‡†çš„è®­ç»ƒæ–¹å¼è¿›è¡Œè®­ç»ƒã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥æ–¹æ³•ä¼šæ ¹æ®å½“å‰çš„ç¡¬ä»¶èµ„æºå’Œæ€§èƒ½éœ€æ±‚ï¼ŒåŠ¨æ€åœ°è°ƒæ•´æ¨¡å‹çš„è®¡ç®—å›¾ï¼Œä»è€Œå®ç°åŠ é€Ÿã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•ä¼šæ ¹æ®ä¸€ä¸ªå¯è°ƒèŠ‚çš„å‚æ•°ï¼Œæ§åˆ¶æ¨¡å‹ä¸­æŸäº›å±‚çš„è®¡ç®—é‡ï¼Œä»è€Œåœ¨æ¨¡å‹æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶é›¶æ ·æœ¬å¯è°ƒåŠ é€Ÿçš„èƒ½åŠ›ã€‚ä¸ç°æœ‰çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦é’ˆå¯¹ç‰¹å®šç¡¬ä»¶è¿›è¡Œå¾®è°ƒï¼Œä¹Ÿä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæ•°æ®ã€‚è¿™ä½¿å¾—è¯¥æ–¹æ³•å¯ä»¥å¿«é€Ÿåœ°åº”ç”¨äºå„ç§LLMï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚çµæ´»åœ°è°ƒæ•´åŠ é€Ÿç¨‹åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•åŠ¨æ€åœ°è°ƒæ•´æ¨¡å‹çš„è®¡ç®—å›¾ã€‚å…·ä½“æ¥è¯´ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªå¯è°ƒèŠ‚çš„å‚æ•°ï¼Œè¯¥å‚æ•°æ§åˆ¶æ¨¡å‹ä¸­æŸäº›å±‚çš„è®¡ç®—é‡ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥è·³è¿‡æŸäº›å±‚çš„è®¡ç®—ï¼Œæˆ–è€…é™ä½æŸäº›å±‚çš„è®¡ç®—ç²¾åº¦ã€‚é€šè¿‡è°ƒæ•´è¿™ä¸ªå‚æ•°ï¼Œå¯ä»¥åœ¨æ¨¡å‹æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ä¹‹é—´è¿›è¡Œæƒè¡¡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è®¾è®¡äº†ä¸€ç§æŸå¤±å‡½æ•°ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹å­¦ä¹ å¦‚ä½•æ ¹æ®ä¸åŒçš„ç¡¬ä»¶èµ„æºå’Œæ€§èƒ½éœ€æ±‚ï¼Œè‡ªåŠ¨åœ°è°ƒæ•´è®¡ç®—å›¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåˆ†ç±»å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„åŠ é€Ÿæ•ˆæœã€‚ä¾‹å¦‚ï¼Œåœ¨æŸä¸ªæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸Šï¼Œè¯¥æ–¹æ³•å®ç°äº†é«˜è¾¾11å€äºåŸºçº¿çš„é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜è¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ ¹æ®ä¸åŒçš„ç¡¬ä»¶èµ„æºå’Œæ€§èƒ½éœ€æ±‚ï¼Œçµæ´»åœ°è°ƒæ•´åŠ é€Ÿç¨‹åº¦ï¼Œä»è€Œåœ¨æ¨¡å‹æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ä¹‹é—´æ‰¾åˆ°ä¸€ä¸ªæœ€ä½³å¹³è¡¡ç‚¹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬ç”Ÿæˆç­‰ã€‚å°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜æ¨ç†é€Ÿåº¦ï¼Œé™ä½å»¶è¿Ÿï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºäº‘è®¡ç®—å¹³å°ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´ç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡ï¼Œé™ä½è¿è¥æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æˆä¸ºä¸€ç§é€šç”¨çš„LLMåŠ é€ŸæŠ€æœ¯ï¼Œæ¨åŠ¨LLMåœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Using Large Language Models (LLMs) in real-world applications presents significant challenges, particularly in balancing computational efficiency with model performance. Optimizing acceleration after fine-tuning and during inference is critical for building efficient architectures. This paper introduces Zero-Shot Adjustable Acceleration, a novel training and inference method that dynamically adjusts hardware utilization during inference without requiring additional fine-tuning. The proposed approach is applied to recent LLMs and evaluated across multiple classification and text generation tasks. Experimental results demonstrate that the method supports a wide range of zero-shot acceleration and achieves up to 11x speedup compared to the baseline.

