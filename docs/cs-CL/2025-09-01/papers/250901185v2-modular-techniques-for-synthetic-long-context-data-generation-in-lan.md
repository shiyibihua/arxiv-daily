---
layout: default
title: Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation
---

# Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01185" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01185v2</a>
  <a href="https://arxiv.org/pdf/2509.01185.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01185v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01185v2', 'Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seganrasan Subramanian, Abhigya Verma

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01 (æ›´æ–°: 2025-09-04)

**å¤‡æ³¨**: 26 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ¨¡å—åŒ–æ¡†æ¶ï¼Œç”¨äºåˆæˆé•¿æ–‡æœ¬æ•°æ®ï¼Œä»¥æå‡è¯­è¨€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°æ•ˆæœã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿æ–‡æœ¬ç”Ÿæˆ` `æ•°æ®åˆæˆ` `è¯­è¨€æ¨¡å‹è®­ç»ƒ` `æç¤ºå·¥ç¨‹` `æ¨¡å—åŒ–æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é•¿æ–‡æœ¬æ•°æ®é›†ç¼ºä¹é«˜è´¨é‡ã€å¤šæ ·æ€§å’Œå¯éªŒè¯æ€§ï¼Œé™åˆ¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬å¤„ç†æ–¹é¢çš„è¿›å±•ã€‚
2. è®ºæ–‡æå‡ºä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œé€šè¿‡æç¤ºå·¥ç¨‹ä¸LLMäº¤äº’ï¼Œåˆæˆç”¨äºè®­ç»ƒå’Œè¯„ä¼°çš„é•¿æ–‡æœ¬æ•°æ®ã€‚
3. è¯¥æ¡†æ¶æ”¯æŒå¤šç§è®­ç»ƒç›®æ ‡ï¼Œå¹¶åŒ…å«å¤šè½®å¯¹è¯ã€æ–‡æ¡£é—®ç­”ã€æŒ‡ä»¤å“åº”å’Œé•¿æ–‡æœ¬æ¨ç†ç­‰å¤šç§ç”ŸæˆèŒƒå¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤„ç†å’Œæ¨ç†é•¿æ–‡æœ¬è¾“å…¥çš„èƒ½åŠ›å¯¹äºå¹¿æ³›çš„å®é™…åº”ç”¨è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œé«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œå¯éªŒè¯çš„é•¿æ–‡æœ¬æ•°æ®é›†çš„ç¼ºä¹ä¸¥é‡åˆ¶çº¦äº†è¯¥é¢†åŸŸçš„å‘å±•ï¼Œè¿™äº›æ•°æ®é›†æ—¢é€‚ç”¨äºè®­ç»ƒä¹Ÿé€‚ç”¨äºè¯„ä¼°ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ¨¡å—åŒ–ã€å¯æ‰©å±•çš„æ¡†æ¶ï¼Œé€šè¿‡åŸºäºæç¤ºçš„LLMäº¤äº’æ¥åˆæˆé•¿æ–‡æœ¬æ•°æ®ã€‚è¯¥æ¡†æ¶æ”¯æŒå¤šç§è®­ç»ƒå’Œå¯¹é½ç›®æ ‡ï¼ŒåŒ…æ‹¬ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ã€‚å®ƒåŒ…å«å››ä¸ªæ ¸å¿ƒç”ŸæˆèŒƒå¼ï¼šå¤šè½®å¯¹è¯ã€æ–‡æ¡£ç›¸å…³çš„è¾“å…¥-è¾“å‡ºå¯¹ã€å¯éªŒè¯çš„æŒ‡ä»¤-å“åº”ä»»åŠ¡ä»¥åŠé•¿æ–‡æœ¬æ¨ç†ç¤ºä¾‹ã€‚é€šè¿‡æ¨¡æ¿åŒ–æç¤ºã€æ¨¡å‹æ— å…³æ¶æ„å’Œå¯Œå«å…ƒæ•°æ®çš„è¾“å‡ºï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¿ƒè¿›äº†å¯æ‰©å±•ã€å¯æ§å’Œç›®æ ‡å¯¹é½çš„æ•°æ®é›†åˆ›å»ºï¼Œä»è€Œæ¨è¿›LLMä¸­çš„é•¿æ–‡æœ¬èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œç¼ºä¹è¶³å¤Ÿçš„é«˜è´¨é‡ã€å¤šæ ·åŒ–å’Œå¯éªŒè¯çš„é•¿æ–‡æœ¬æ•°æ®é›†ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥ç”Ÿæˆæ»¡è¶³ç‰¹å®šè®­ç»ƒç›®æ ‡å’Œè¯„ä¼°éœ€æ±‚çš„é•¿æ–‡æœ¬æ•°æ®ï¼Œé™åˆ¶äº†æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç†è§£å’Œæ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªèº«çš„èƒ½åŠ›ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºï¼ˆpromptï¼‰æ¥ç”Ÿæˆé•¿æ–‡æœ¬æ•°æ®ã€‚é€šè¿‡æ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œå¯ä»¥çµæ´»åœ°æ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶é’ˆå¯¹ä¸åŒçš„è®­ç»ƒç›®æ ‡ï¼ˆå¦‚SFTã€DPOã€GRPOï¼‰å’Œç”ŸæˆèŒƒå¼ï¼ˆå¦‚å¯¹è¯ã€æ–‡æ¡£é—®ç­”ã€æŒ‡ä»¤å“åº”ã€æ¨ç†ï¼‰å®šåˆ¶ç”Ÿæˆç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«å››ä¸ªæ ¸å¿ƒç”Ÿæˆæ¨¡å—ï¼Œåˆ†åˆ«å¯¹åº”å››ç§ç”ŸæˆèŒƒå¼ï¼šå¤šè½®å¯¹è¯ç”Ÿæˆæ¨¡å—ã€æ–‡æ¡£ç›¸å…³çš„è¾“å…¥-è¾“å‡ºå¯¹ç”Ÿæˆæ¨¡å—ã€å¯éªŒè¯çš„æŒ‡ä»¤-å“åº”ä»»åŠ¡ç”Ÿæˆæ¨¡å—ä»¥åŠé•¿æ–‡æœ¬æ¨ç†ç¤ºä¾‹ç”Ÿæˆæ¨¡å—ã€‚æ¯ä¸ªæ¨¡å—éƒ½åŒ…å«æ¨¡æ¿åŒ–çš„æç¤ºï¼Œç”¨äºå¼•å¯¼LLMç”Ÿæˆç‰¹å®šç±»å‹çš„æ•°æ®ã€‚æ¡†æ¶è¿˜æ”¯æŒå¤šç§è®­ç»ƒå’Œå¯¹é½ç›®æ ‡ï¼ŒåŒ…æ‹¬SFTã€DPOå’ŒGRPOã€‚æ•´ä¸ªæ¡†æ¶é‡‡ç”¨æ¨¡å‹æ— å…³çš„è®¾è®¡ï¼Œå¯ä»¥ä¸ä¸åŒçš„LLMç»“åˆä½¿ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶æ¨¡å—åŒ–å’Œå¯æ‰©å±•æ€§ã€‚é€šè¿‡æ¨¡å—åŒ–çš„è®¾è®¡ï¼Œå¯ä»¥çµæ´»åœ°ç»„åˆä¸åŒçš„ç”Ÿæˆæ¨¡å—ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šçš„è®­ç»ƒç›®æ ‡å’Œè¯„ä¼°éœ€æ±‚å®šåˆ¶ç”Ÿæˆç­–ç•¥ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ”¯æŒå¤šç§è®­ç»ƒç›®æ ‡å’Œç”ŸæˆèŒƒå¼ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„é•¿æ–‡æœ¬æ•°æ®ã€‚å¦ä¸€ä¸ªåˆ›æ–°ç‚¹æ˜¯ä½¿ç”¨æ¨¡æ¿åŒ–çš„æç¤ºï¼Œè¿™ä½¿å¾—ç”Ÿæˆè¿‡ç¨‹æ›´åŠ å¯æ§ï¼Œå¹¶èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ¨¡æ¿åŒ–æç¤ºçš„è®¾è®¡ï¼Œéœ€è¦ä»”ç»†è€ƒè™‘æç¤ºçš„ç»“æ„å’Œå†…å®¹ï¼Œä»¥ç¡®ä¿LLMèƒ½å¤Ÿç”Ÿæˆç¬¦åˆè¦æ±‚çš„é•¿æ–‡æœ¬æ•°æ®ã€‚2) æ¨¡å—åŒ–çš„æ¡†æ¶è®¾è®¡ï¼Œéœ€è¦ç¡®ä¿å„ä¸ªæ¨¡å—ä¹‹é—´çš„æ¥å£æ¸…æ™°ï¼Œå¹¶ä¸”æ˜“äºæ‰©å±•ã€‚3) å…ƒæ•°æ®å¢å¼ºï¼Œä¸ºç”Ÿæˆçš„æ•°æ®æ·»åŠ å…ƒæ•°æ®ï¼Œä¾‹å¦‚ç”Ÿæˆæ•°æ®çš„æ¥æºã€ç”Ÿæˆæ—¶é—´ã€ç”Ÿæˆç›®æ ‡ç­‰ï¼Œè¿™æœ‰åŠ©äºæ›´å¥½åœ°ç®¡ç†å’Œä½¿ç”¨è¿™äº›æ•°æ®ã€‚4) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œéœ€è¦æ ¹æ®ä¸åŒçš„è®­ç»ƒç›®æ ‡é€‰æ‹©åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œå¯¹äºSFTï¼Œå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼›å¯¹äºDPOï¼Œå¯ä»¥ä½¿ç”¨åå¥½æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„é•¿æ–‡æœ¬æ•°æ®ç”Ÿæˆæ¡†æ¶ï¼Œæ”¯æŒå¤šç§è®­ç»ƒç›®æ ‡å’Œç”ŸæˆèŒƒå¼ã€‚é€šè¿‡æ¨¡æ¿åŒ–æç¤ºå’Œæ¨¡å‹æ— å…³æ¶æ„ï¼Œå®ç°äº†å¯æ‰©å±•ã€å¯æ§å’Œç›®æ ‡å¯¹é½çš„æ•°æ®é›†åˆ›å»ºã€‚è¯¥æ¡†æ¶ä¸ºæå‡LLMçš„é•¿æ–‡æœ¬èƒ½åŠ›æä¾›äº†æœ‰åŠ›çš„å·¥å…·ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚å…·ä½“çš„å®éªŒç»“æœï¼ˆå¦‚æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿ã€æå‡å¹…åº¦ç­‰ï¼‰åœ¨æ‘˜è¦ä¸­æœªæåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›çš„é¢†åŸŸï¼Œå¦‚æ–‡æ¡£æ‘˜è¦ã€ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡åˆæˆé«˜è´¨é‡çš„é•¿æ–‡æœ¬æ•°æ®é›†ï¼Œå¯ä»¥æ˜¾è‘—æå‡LLMåœ¨è¿™äº›é¢†åŸŸçš„æ€§èƒ½ï¼Œå¹¶ä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºè¯„ä¼°LLMçš„é•¿æ–‡æœ¬å¤„ç†èƒ½åŠ›ï¼Œå¹¶ä¸ºæ¨¡å‹ä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The ability of large language models (LLMs) to process and reason over long textual inputs is critical for a wide range of real-world applications. However, progress in this area is significantly constrained by the absence of high-quality, diverse, and verifiable long-context datasets suitable for both training and evaluation. This work introduces a modular, extensible framework for synthetic long-context data generation via prompt-based interaction with LLMs. The framework supports multiple training and alignment objectives, including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Group Relative Policy Optimization (GRPO). It encompasses four core generation paradigms: multi-turn conversational dialogues, document-grounded input-output pairs, verifiable instruction-response tasks, and long-context reasoning examples. Through templated prompting, a model-agnostic architecture, and metadata-enriched outputs, the proposed approach facilitates scalable, controllable, and purpose-aligned dataset creation for advancing long-context capabilities in LLMs.

