---
layout: default
title: Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief
---

# Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01564" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01564v1</a>
  <a href="https://arxiv.org/pdf/2509.01564.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01564v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01564v1', 'Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeguan Xiao, Diyang Dou, Boya Xiong, Yun Chen, Guanhua Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EAGLEï¼šåˆ©ç”¨LLMå†…éƒ¨ä¿¡å¿µèšåˆæœŸæœ›æå‡ä¸ç¡®å®šæ€§ä¼°è®¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ç¡®å®šæ€§ä¼°è®¡` `ç½®ä¿¡åº¦æ ¡å‡†` `è‡ªæˆ‘è¯„ä¼°` `å†…éƒ¨ä¿¡å¿µ` `å¼ºåŒ–å­¦ä¹ ` `éšè—çŠ¶æ€`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMå­˜åœ¨è¿‡åº¦è‡ªä¿¡é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨RLHFè®­ç»ƒåï¼Œå¯¼è‡´ä¸å‡†ç¡®çš„ç½®ä¿¡åº¦ä¼°è®¡ï¼Œå½±å“å®‰å…¨åº”ç”¨ã€‚
2. EAGLEé€šè¿‡èšåˆLLMåœ¨è‡ªæˆ‘è¯„ä¼°è¿‡ç¨‹ä¸­å¤šä¸ªä¸­é—´å±‚çš„å†…éƒ¨ä¿¡å¿µï¼Œè®¡ç®—æœŸæœ›ç½®ä¿¡åº¦ï¼Œä»è€Œæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEAGLEåœ¨å¤šä¸ªæ•°æ®é›†å’ŒLLMä¸Šæ˜¾è‘—æå‡äº†æ ¡å‡†æ€§èƒ½ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å„ç§è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å¸¸å¸¸è¡¨ç°å‡ºè¿‡åº¦è‡ªä¿¡ï¼Œå¹¶ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†ä¸æ­£ç¡®çš„ç­”æ¡ˆã€‚è¿™ç§è¿‡åº¦è‡ªä¿¡ï¼Œå°¤å…¶æ˜¯åœ¨ç»è¿‡äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ (RLHF)çš„æ¨¡å‹ä¸­ï¼Œå¯¹å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡å’Œå®‰å…¨éƒ¨ç½²æå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºEAGLE(AGgregated internaL bEiefçš„æœŸæœ›)ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºè‡ªæˆ‘è¯„ä¼°çš„æ ¡å‡†æ–¹æ³•ï¼Œå®ƒåˆ©ç”¨LLMsçš„å†…éƒ¨éšè—çŠ¶æ€æ¥è·å¾—æ›´å‡†ç¡®çš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸æ˜¯ä¾èµ–æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºï¼Œè€Œæ˜¯ä»è‡ªæˆ‘è¯„ä¼°æœŸé—´çš„å¤šä¸ªä¸­é—´å±‚æå–å†…éƒ¨ä¿¡å¿µã€‚é€šè¿‡èšåˆè¿™äº›å±‚çº§çš„ä¿¡å¿µå¹¶è®¡ç®—æ‰€å¾—ç½®ä¿¡åº¦åˆ†å¸ƒçš„æœŸæœ›ï¼ŒEAGLEäº§ç”Ÿä¸€ä¸ªæ›´çœŸå®åœ°åæ˜ æ¨¡å‹å†…éƒ¨ç¡®å®šæ€§çš„ç²¾ç»†ç½®ä¿¡åº¦åˆ†æ•°ã€‚åœ¨ä¸åŒçš„æ•°æ®é›†å’ŒLLMsä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEAGLEæ˜¾è‘—æé«˜äº†ä¼˜äºç°æœ‰åŸºçº¿çš„æ ¡å‡†æ€§èƒ½ã€‚æˆ‘ä»¬è¿˜å¯¹EAGLEè¿›è¡Œäº†æ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬å¯¹ä¸ç¡®å®šæ€§æ¨¡å¼çš„é€å±‚æ£€æŸ¥ã€å¯¹è‡ªæˆ‘è¯„ä¼°æç¤ºå½±å“çš„ç ”ç©¶ä»¥åŠå¯¹è‡ªæˆ‘è¯„ä¼°åˆ†æ•°èŒƒå›´å½±å“çš„åˆ†æã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆæ–‡æœ¬æ—¶å¸¸å¸¸è¡¨ç°å‡ºè¿‡åº¦è‡ªä¿¡ï¼Œå³ä½¿åœ¨ç»™å‡ºé”™è¯¯ç­”æ¡ˆæ—¶ä¹Ÿå¦‚æ­¤ã€‚è¿™ç§ä¸å‡†ç¡®çš„ç½®ä¿¡åº¦ä¼°è®¡å¯¹LLMçš„å®‰å…¨éƒ¨ç½²æ„æˆäº†æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜å¯é æ€§çš„åº”ç”¨åœºæ™¯ä¸­ã€‚ç°æœ‰çš„æ–¹æ³•å¾€å¾€ä¾èµ–äºæ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºè¿›è¡Œç½®ä¿¡åº¦è¯„ä¼°ï¼Œå¿½ç•¥äº†æ¨¡å‹å†…éƒ¨çš„å†³ç­–è¿‡ç¨‹ï¼Œå¯¼è‡´æ ¡å‡†æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEAGLEçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMåœ¨ç”Ÿæˆç­”æ¡ˆè¿‡ç¨‹ä¸­çš„å†…éƒ¨éšè—çŠ¶æ€ï¼Œè¿™äº›éšè—çŠ¶æ€å¯ä»¥è¢«è§†ä¸ºæ¨¡å‹åœ¨ä¸åŒé˜¶æ®µçš„â€œä¿¡å¿µâ€ã€‚é€šè¿‡èšåˆå¤šä¸ªä¸­é—´å±‚çš„ä¿¡å¿µï¼Œå¹¶è®¡ç®—è¿™äº›ä¿¡å¿µçš„æœŸæœ›å€¼ï¼ŒEAGLEèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„ä¸ç¡®å®šæ€§ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†äººç±»åœ¨åšå†³ç­–æ—¶ä¼šç»¼åˆè€ƒè™‘å¤šä¸ªè§’åº¦å’Œä¿¡æ¯æ¥æºçš„è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEAGLEæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **è‡ªæˆ‘è¯„ä¼°æç¤º**ï¼šä½¿ç”¨ç‰¹å®šçš„æç¤ºè¯­å¼•å¯¼LLMå¯¹è‡ªèº«ç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡Œè¯„ä¼°ã€‚2) **ä¸­é—´å±‚ä¿¡å¿µæå–**ï¼šåœ¨LLMè¿›è¡Œè‡ªæˆ‘è¯„ä¼°çš„è¿‡ç¨‹ä¸­ï¼Œæå–å¤šä¸ªä¸­é—´å±‚çš„éšè—çŠ¶æ€ï¼Œä½œä¸ºè¯¥å±‚å¯¹ç­”æ¡ˆçš„â€œä¿¡å¿µâ€ã€‚3) **ä¿¡å¿µèšåˆ**ï¼šå°†ä¸åŒå±‚çš„ä¿¡å¿µè¿›è¡Œèšåˆï¼Œä¾‹å¦‚é€šè¿‡åŠ æƒå¹³å‡æˆ–å…¶ä»–èšåˆå‡½æ•°ã€‚4) **æœŸæœ›è®¡ç®—**ï¼šè®¡ç®—èšåˆåçš„ä¿¡å¿µåˆ†å¸ƒçš„æœŸæœ›å€¼ï¼Œä½œä¸ºæœ€ç»ˆçš„ç½®ä¿¡åº¦åˆ†æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šEAGLEçš„å…³é”®åˆ›æ–°åœ¨äºå®ƒä¸å†ä»…ä»…ä¾èµ–äºæ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºï¼Œè€Œæ˜¯åˆ©ç”¨äº†æ¨¡å‹å†…éƒ¨çš„ä¸­é—´å±‚ä¿¡æ¯ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰æ¨¡å‹åœ¨ç”Ÿæˆç­”æ¡ˆè¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œä»è€Œæé«˜ç½®ä¿¡åº¦ä¼°è®¡çš„å‡†ç¡®æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒEAGLEæ›´æ¥è¿‘äºæ¨¡æ‹Ÿäººç±»çš„è®¤çŸ¥è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ æ¨¡å‹çš„çœŸå®ç½®ä¿¡æ°´å¹³ã€‚

**å…³é”®è®¾è®¡**ï¼šEAGLEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **ä¸­é—´å±‚é€‰æ‹©**ï¼šé€‰æ‹©å“ªäº›ä¸­é—´å±‚è¿›è¡Œä¿¡å¿µæå–ä¼šå½±å“æœ€ç»ˆçš„æ ¡å‡†æ•ˆæœã€‚è®ºæ–‡å¯èƒ½æ¢è®¨äº†ä¸åŒå±‚é€‰æ‹©ç­–ç•¥çš„å½±å“ã€‚2) **ä¿¡å¿µèšåˆå‡½æ•°**ï¼šå¦‚ä½•å°†ä¸åŒå±‚çš„ä¿¡å¿µè¿›è¡Œèšåˆæ˜¯ä¸€ä¸ªé‡è¦çš„è®¾è®¡é€‰æ‹©ã€‚å¯ä»¥ä½¿ç”¨ç®€å•çš„åŠ æƒå¹³å‡ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„èšåˆå‡½æ•°ï¼Œä¾‹å¦‚åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„èšåˆã€‚3) **è‡ªæˆ‘è¯„ä¼°æç¤ºè®¾è®¡**ï¼šæç¤ºè¯­çš„è®¾è®¡ä¼šå½±å“LLMçš„è‡ªæˆ‘è¯„ä¼°ç»“æœã€‚è®ºæ–‡å¯èƒ½ç ”ç©¶äº†ä¸åŒæç¤ºè¯­å¯¹æ ¡å‡†æ€§èƒ½çš„å½±å“ã€‚4) **ç½®ä¿¡åº¦åˆ†æ•°èŒƒå›´**ï¼šè‡ªæˆ‘è¯„ä¼°çš„åˆ†æ•°èŒƒå›´ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ ¡å‡†æ•ˆæœã€‚è®ºæ–‡å¯èƒ½åˆ†æäº†ä¸åŒåˆ†æ•°èŒƒå›´çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEAGLEåœ¨å¤šä¸ªæ•°æ®é›†å’ŒLLMä¸Šæ˜¾è‘—æé«˜äº†æ ¡å‡†æ€§èƒ½ï¼Œä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚è®ºæ–‡é€šè¿‡å±‚çº§åˆ†æã€æç¤ºå·¥ç¨‹å’Œåˆ†æ•°èŒƒå›´åˆ†æï¼Œæ·±å…¥æ¢è®¨äº†EAGLEçš„æœ‰æ•ˆæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¯¦ç»†å±•ç¤ºï¼Œè¯æ˜äº†EAGLEåœ¨æå‡LLMä¸ç¡®å®šæ€§ä¼°è®¡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EAGLEå¯åº”ç”¨äºå„ç§éœ€è¦å¯é ä¸ç¡®å®šæ€§ä¼°è®¡çš„LLMåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚åŒ»ç–—è¯Šæ–­ã€é‡‘èé£é™©è¯„ä¼°ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡æé«˜LLMçš„ç½®ä¿¡åº¦æ ¡å‡†ï¼Œå¯ä»¥å‡å°‘æ¨¡å‹çŠ¯é”™çš„æ¦‚ç‡ï¼Œæé«˜å†³ç­–çš„å®‰å…¨æ€§ä¸å¯é æ€§ã€‚æœªæ¥ï¼ŒEAGLEæœ‰æœ›æˆä¸ºLLMå®‰å…¨éƒ¨ç½²çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¿ƒè¿›LLMåœ¨æ›´å¤šå…³é”®é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved remarkable success across a wide range of natural language tasks, but often exhibit overconfidence and generate plausible yet incorrect answers. This overconfidence, especially in models undergone Reinforcement Learning from Human Feedback (RLHF), poses significant challenges for reliable uncertainty estimation and safe deployment. In this paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel self-evaluation-based calibration method that leverages the internal hidden states of LLMs to derive more accurate confidence scores. Instead of relying on the model's final output, our approach extracts internal beliefs from multiple intermediate layers during self-evaluation. By aggregating these layer-wise beliefs and calculating the expectation over the resulting confidence score distribution, EAGLE produces a refined confidence score that more faithfully reflects the model's internal certainty. Extensive experiments on diverse datasets and LLMs demonstrate that EAGLE significantly improves calibration performance over existing baselines. We also provide an in-depth analysis of EAGLE, including a layer-wise examination of uncertainty patterns, a study of the impact of self-evaluation prompts, and an analysis of the effect of self-evaluation score range.

