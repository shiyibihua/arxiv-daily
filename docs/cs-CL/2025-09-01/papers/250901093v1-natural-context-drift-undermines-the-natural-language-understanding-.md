---
layout: default
title: Natural Context Drift Undermines the Natural Language Understanding of Large Language Models
---

# Natural Context Drift Undermines the Natural Language Understanding of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01093" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01093v1</a>
  <a href="https://arxiv.org/pdf/2509.01093.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01093v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01093v1', 'Natural Context Drift Undermines the Natural Language Understanding of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yulong Wu, Viktor Schlegel, Riza Batista-Navarro

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**å¤‡æ³¨**: EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡†æ¶åˆ†æè‡ªç„¶æ–‡æœ¬æ¼”å˜å¯¹LLMé—®ç­”èƒ½åŠ›çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç„¶è¯­è¨€å¤„ç†` `å¤§è¯­è¨€æ¨¡å‹` `é—®ç­”ç³»ç»Ÿ` `æ–‡æœ¬æ¼”å˜` `è¯­ä¹‰ç›¸ä¼¼æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç”Ÿæˆå‹å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è‡ªç„¶æ¼”å˜çš„æ–‡æœ¬æ—¶è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨é—®ç­”ä»»åŠ¡ä¸­ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œèƒ½å¤Ÿç­–åˆ’å’Œåˆ†æè‡ªç„¶æ¼”å˜çš„æ–‡æœ¬ç‰ˆæœ¬ï¼Œä»è€Œè¯„ä¼°LLMçš„è¡¨ç°ã€‚
3. å®éªŒæ˜¾ç¤ºï¼ŒLLMçš„å‡†ç¡®ç‡éšç€æ–‡æœ¬çš„è‡ªç„¶åç¦»è€Œæ˜¾è‘—ä¸‹é™ï¼Œæœ€é«˜ä¸‹é™å¹…åº¦è¶…è¿‡30%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†è‡ªç„¶æ¼”å˜çš„ä¸Šä¸‹æ–‡æ®µè½å¦‚ä½•å½±å“ç”Ÿæˆå‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„é—®ç­”èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œç”¨äºç­–åˆ’è‡ªç„¶æ¼”å˜çš„äººä¸ºç¼–è¾‘ç‰ˆæœ¬çš„é˜…è¯»æ®µè½ï¼Œå¹¶åˆ†æLLMåœ¨å¤šä¸ªè¯­ä¹‰ç›¸ä¼¼æ€§è¯„åˆ†ä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€é˜…è¯»æ®µè½ä¸é¢„è®­ç»ƒç‰ˆæœ¬çš„è‡ªç„¶åç¦»ï¼ŒLLMçš„è¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œå°½ç®¡é—®é¢˜å’Œå¿…è¦ä¿¡æ¯åœ¨æ¨ç†æ—¶ä»ç„¶å­˜åœ¨ã€‚ä¾‹å¦‚ï¼ŒBoolQçš„å¹³å‡æ¨¡å‹å‡†ç¡®ç‡åœ¨æœ€é«˜å’Œæœ€ä½ç›¸ä¼¼æ€§åŒºé—´ä¹‹é—´ä¸‹é™è¶…è¿‡30%ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè‡ªç„¶æ–‡æœ¬æ¼”å˜å¯¹LLMçš„è¯­è¨€ç†è§£èƒ½åŠ›æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆå‹å¤§è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹è‡ªç„¶æ¼”å˜æ–‡æœ¬æ—¶çš„é—®ç­”èƒ½åŠ›ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹æ–‡æœ¬å†…å®¹çš„è‡ªç„¶å˜åŒ–ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—æŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªæ¡†æ¶ï¼Œç­–åˆ’è‡ªç„¶æ¼”å˜çš„æ–‡æœ¬ç‰ˆæœ¬ï¼Œå¹¶é€šè¿‡è¯­ä¹‰ç›¸ä¼¼æ€§è¯„åˆ†æ¥è¯„ä¼°LLMçš„è¡¨ç°ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æ­ç¤ºæ–‡æœ¬æ¼”å˜å¯¹æ¨¡å‹ç†è§£çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬ç‰ˆæœ¬çš„ç­–åˆ’ã€è¯­ä¹‰ç›¸ä¼¼æ€§è¯„åˆ†çš„è®¡ç®—ä»¥åŠLLMæ€§èƒ½çš„è¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿé‡åŒ–æ–‡æœ¬æ¼”å˜å¯¹LLMæ€§èƒ½çš„å½±å“ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ç»†è‡´çš„åˆ†æè§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†å…­ä¸ªé—®ç­”æ•°æ®é›†å’Œå…«ä¸ªå…¬å¼€å¯ç”¨çš„LLMï¼Œè®¾è®¡äº†ä¸åŒçš„ç›¸ä¼¼æ€§è¯„åˆ†åŒºé—´ï¼Œä»¥ä¾¿å…¨é¢è¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMåœ¨å¤„ç†è‡ªç„¶æ¼”å˜æ–‡æœ¬æ—¶çš„å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼ŒBoolQæ•°æ®é›†çš„å¹³å‡å‡†ç¡®ç‡åœ¨æœ€é«˜å’Œæœ€ä½ç›¸ä¼¼æ€§åŒºé—´ä¹‹é—´ä¸‹é™è¶…è¿‡30%ã€‚å¤šä¸ªLLMçš„è¡¨ç°æ–œç‡è¶…è¿‡70ï¼Œè¡¨æ˜æ–‡æœ¬æ¼”å˜å¯¹æ¨¡å‹ç†è§£èƒ½åŠ›çš„é‡å¤§å½±å“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ä¿¡æ¯æ£€ç´¢å’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿã€‚é€šè¿‡ç†è§£è‡ªç„¶æ–‡æœ¬æ¼”å˜å¯¹LLMçš„å½±å“ï¼Œå¯ä»¥ä¸ºæ¨¡å‹çš„æ”¹è¿›å’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> How does the natural evolution of context paragraphs affect question answering in generative Large Language Models (LLMs)? To investigate this, we propose a framework for curating naturally evolved, human-edited variants of reading passages from contemporary QA benchmarks and for analyzing LLM performance across a range of semantic similarity scores, which quantify how closely each variant aligns with content seen during pretraining. Using this framework, we evaluate six QA datasets and eight LLMs with publicly available training data. Our experiments reveal that LLM performance declines as reading passages naturally diverge from the versions encountered during pretraining-even when the question and all necessary information remains present at inference time. For instance, average model accuracy on BoolQ drops by over 30% from the highest to lowest similarity bins, with slopes exceeding 70 across several LLMs. These findings suggest that natural text evolution poses a significant challenge to the language understanding capabilities of LLMs.

