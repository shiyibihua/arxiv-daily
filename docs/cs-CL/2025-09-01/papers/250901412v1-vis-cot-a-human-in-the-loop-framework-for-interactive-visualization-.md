---
layout: default
title: Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning
---

# Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01412" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01412v1</a>
  <a href="https://arxiv.org/pdf/2509.01412.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01412v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01412v1', 'Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaviraj Pather, Elena Hadjigeorgiou, Arben Krasniqi, Claire Schmit, Irina Rusu, Marc Pons, Kabir Khan

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01

**å¤‡æ³¨**: 12 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Vis-CoTï¼šäººæœºååŒäº¤äº’å¼å¯è§†åŒ–LLMæ€ç»´é“¾æ¨ç†æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººæœºååŒ` `æ€ç»´é“¾` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯è§†åŒ–æ¨ç†` `äº¤äº’å¼å¹²é¢„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMçš„CoTæ¨ç†è¿‡ç¨‹ä¸é€æ˜ï¼Œéš¾ä»¥éªŒè¯ã€è°ƒè¯•å’Œæ§åˆ¶ï¼Œå°¤å…¶æ˜¯åœ¨é«˜é£é™©åœºæ™¯ä¸‹ã€‚
2. Vis-CoTå°†çº¿æ€§CoTæ–‡æœ¬è½¬åŒ–ä¸ºäº¤äº’å¼æ¨ç†å›¾ï¼Œå…è®¸ç”¨æˆ·å¯è§†åŒ–ã€è¯Šæ–­å’Œå¹²é¢„æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVis-CoTåœ¨GSM8Kå’ŒStrategyQAæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®ç‡ï¼Œå¹¶æé«˜äº†ç”¨æˆ·ä¿¡ä»»åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡æ€ç»´é“¾ï¼ˆCoTï¼‰æç¤ºå±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶è¿‡ç¨‹ä¸é€æ˜ï¼Œè¿™ä½¿å¾—åœ¨é«˜é£é™©åœºæ™¯ä¸­çš„éªŒè¯ã€è°ƒè¯•å’Œæ§åˆ¶å˜å¾—å›°éš¾ã€‚æˆ‘ä»¬æå‡ºäº†Vis-CoTï¼Œä¸€ä¸ªäººæœºååŒæ¡†æ¶ï¼Œå°†çº¿æ€§CoTæ–‡æœ¬è½¬æ¢ä¸ºäº¤äº’å¼æ¨ç†å›¾ã€‚ç”¨æˆ·å¯ä»¥å¯è§†åŒ–é€»è¾‘æµç¨‹ï¼Œè¯†åˆ«æœ‰ç¼ºé™·çš„æ­¥éª¤ï¼Œå¹¶é€šè¿‡å‰ªæä¸æ­£ç¡®çš„è·¯å¾„å’Œå«æ¥æ–°çš„ã€ç”¨æˆ·å®šä¹‰çš„ premise æ¥è¿›è¡Œå¹²é¢„ã€‚è¿™ä½¿å¾—äº¤äº’ä»è¢«åŠ¨è§‚å¯Ÿè½¬å˜ä¸ºä¸»åŠ¨åä½œï¼Œå¼•å¯¼æ¨¡å‹å¾—å‡ºæ›´å‡†ç¡®å’Œå¯ä¿¡çš„ç»“è®ºã€‚åœ¨GSM8Kå’ŒStrategyQAä¸Šï¼ŒVis-CoTæ¯”éäº¤äº’å¼åŸºçº¿æé«˜äº†é«˜è¾¾24ä¸ªç™¾åˆ†ç‚¹çš„æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ã€‚ä¸€é¡¹ç”¨æˆ·ç ”ç©¶ä¹Ÿæ˜¾ç¤ºå‡ºåœ¨æ„ŸçŸ¥å¯ç”¨æ€§å’Œä¿¡ä»»åº¦æ–¹é¢çš„å¤§å¹…æå‡ã€‚Vis-CoTä¸ºé€šè¿‡ç»“åˆLLMä¸æœ‰é’ˆå¯¹æ€§çš„äººå·¥ç›‘ç£æ¥å®ç°æ›´å¯é ã€å¯ç†è§£å’Œåä½œçš„æ¨ç†æŒ‡æ˜äº†ä¸€æ¡åˆ‡å®å¯è¡Œçš„é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ€ç»´é“¾ï¼ˆCoTï¼‰æ¨ç†è¿‡ç¨‹ä¸é€æ˜çš„é—®é¢˜ã€‚ç°æœ‰çš„CoTæ–¹æ³•è™½ç„¶èƒ½æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹éš¾ä»¥ç†è§£å’Œæ§åˆ¶ï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥ä¿¡ä»»å…¶ç»“æœï¼Œä¹Ÿéš¾ä»¥è¿›è¡Œè°ƒè¯•å’Œæ”¹è¿›ã€‚å°¤å…¶æ˜¯åœ¨éœ€è¦é«˜å¯é æ€§çš„åœºæ™¯ä¸‹ï¼Œè¿™ç§ä¸é€æ˜æ€§æ˜¯å¾ˆå¤§çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†çº¿æ€§çš„CoTæ¨ç†è¿‡ç¨‹è½¬åŒ–ä¸ºäº¤äº’å¼çš„æ¨ç†å›¾ï¼Œé€šè¿‡å¯è§†åŒ–æ¨ç†æ­¥éª¤ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿç†è§£æ¨¡å‹çš„æ¨ç†é€»è¾‘ã€‚åŒæ—¶ï¼Œå…è®¸ç”¨æˆ·å¯¹æ¨ç†è¿‡ç¨‹è¿›è¡Œå¹²é¢„ï¼Œä¾‹å¦‚ä¿®æ­£é”™è¯¯çš„æ¨ç†æ­¥éª¤ï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚è¿™ç§äººæœºååŒçš„æ–¹å¼æ—¨åœ¨ç»“åˆLLMçš„æ¨ç†èƒ½åŠ›å’Œäººç±»çš„çŸ¥è¯†ä¸åˆ¤æ–­åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVis-CoTæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) CoTæ–‡æœ¬è§£ææ¨¡å—ï¼Œå°†LLMç”Ÿæˆçš„çº¿æ€§CoTæ–‡æœ¬è§£æä¸ºæ¨ç†æ­¥éª¤ï¼›2) æ¨ç†å›¾æ„å»ºæ¨¡å—ï¼Œå°†è§£æåçš„æ¨ç†æ­¥éª¤æ„å»ºæˆå¯è§†åŒ–æ¨ç†å›¾ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºæ¨ç†æ­¥éª¤ï¼Œè¾¹è¡¨ç¤ºæ¨ç†å…³ç³»ï¼›3) äº¤äº’æ¨¡å—ï¼Œå…è®¸ç”¨æˆ·åœ¨æ¨ç†å›¾ä¸Šè¿›è¡Œæ“ä½œï¼Œä¾‹å¦‚æŸ¥çœ‹æ¨ç†æ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ã€å‰ªæé”™è¯¯çš„æ¨ç†è·¯å¾„ã€æ·»åŠ æ–°çš„æ¨ç†æ­¥éª¤ï¼›4) LLMé‡æ–°æ¨ç†æ¨¡å—ï¼Œæ ¹æ®ç”¨æˆ·å¹²é¢„åçš„æ¨ç†å›¾ï¼Œå¼•å¯¼LLMè¿›è¡Œé‡æ–°æ¨ç†ï¼Œå¾—åˆ°æœ€ç»ˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šVis-CoTçš„å…³é”®åˆ›æ–°åœ¨äºå°†LLMçš„CoTæ¨ç†è¿‡ç¨‹è½¬åŒ–ä¸ºäººæœºååŒçš„äº¤äº’å¼è¿‡ç¨‹ã€‚ä¸ä¼ ç»Ÿçš„CoTæ–¹æ³•ç›¸æ¯”ï¼ŒVis-CoTä¸å†æ˜¯ä¸€ä¸ªé»‘ç›’ï¼Œç”¨æˆ·å¯ä»¥ç†è§£æ¨¡å‹çš„æ¨ç†é€»è¾‘ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¹²é¢„ã€‚è¿™ç§äº¤äº’å¼çš„æ–¹å¼èƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚æ­¤å¤–ï¼ŒVis-CoTè¿˜æä¾›äº†ä¸€ç§å¯è§†åŒ–çš„æ¨ç†å›¾ï¼Œæ–¹ä¾¿ç”¨æˆ·ç†è§£å’Œæ“ä½œã€‚

**å…³é”®è®¾è®¡**ï¼šVis-CoTæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ¨ç†å›¾çš„æ„å»ºæ–¹å¼ï¼Œå¦‚ä½•å°†çº¿æ€§çš„CoTæ–‡æœ¬è½¬åŒ–ä¸ºæœ‰æ„ä¹‰çš„æ¨ç†å›¾ï¼›2) äº¤äº’æ–¹å¼çš„è®¾è®¡ï¼Œå¦‚ä½•è®©ç”¨æˆ·èƒ½å¤Ÿæ–¹ä¾¿åœ°å¯¹æ¨ç†å›¾è¿›è¡Œæ“ä½œï¼›3) LLMé‡æ–°æ¨ç†çš„ç­–ç•¥ï¼Œå¦‚ä½•æ ¹æ®ç”¨æˆ·å¹²é¢„åçš„æ¨ç†å›¾ï¼Œå¼•å¯¼LLMè¿›è¡Œæœ‰æ•ˆçš„é‡æ–°æ¨ç†ã€‚è®ºæ–‡ä¸­å¹¶æœªè¯¦ç»†è¯´æ˜å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ï¼Œè¿™äº›å¯èƒ½æ˜¯ä¾èµ–äºå…·ä½“LLMå’ŒCoTå®ç°ç»†èŠ‚çš„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Vis-CoTåœ¨GSM8Kå’ŒStrategyQAæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œä¸éäº¤äº’å¼åŸºçº¿ç›¸æ¯”ï¼ŒVis-CoTçš„æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡æé«˜äº†é«˜è¾¾24ä¸ªç™¾åˆ†ç‚¹ã€‚ç”¨æˆ·ç ”ç©¶ä¹Ÿè¡¨æ˜ï¼ŒVis-CoTæ˜¾è‘—æé«˜äº†ç”¨æˆ·å¯¹LLMæ¨ç†è¿‡ç¨‹çš„ç†è§£å’Œä¿¡ä»»åº¦ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVis-CoTæ˜¯ä¸€ç§æœ‰æ•ˆçš„äººæœºååŒæ¨ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜LLMæ¨ç†çš„æ€§èƒ½å’Œå¯ä¿¡åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Vis-CoTæ¡†æ¶å¯åº”ç”¨äºéœ€è¦é«˜å¯é æ€§å’Œå¯è§£é‡Šæ€§çš„LLMæ¨ç†åœºæ™¯ï¼Œä¾‹å¦‚åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ã€æ³•å¾‹å’¨è¯¢ç­‰ã€‚é€šè¿‡äººæœºååŒçš„æ–¹å¼ï¼Œå¯ä»¥æé«˜LLMæ¨ç†çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ï¼Œé™ä½å‡ºé”™é£é™©ã€‚æœªæ¥ï¼ŒVis-CoTå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„æ¨ç†ä»»åŠ¡ï¼Œå¹¶ä¸å…¶ä»–AIæŠ€æœ¯ç›¸ç»“åˆï¼Œä¾‹å¦‚çŸ¥è¯†å›¾è°±ã€å¼ºåŒ–å­¦ä¹ ç­‰ï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´å¯é çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) show strong reasoning via chain-of-thought (CoT) prompting, but the process is opaque, which makes verification, debugging, and control difficult in high-stakes settings. We present Vis-CoT, a human-in-the-loop framework that converts linear CoT text into an interactive reasoning graph. Users can visualize the logical flow, identify flawed steps, and intervene by pruning incorrect paths and grafting new, user-defined premises. This shifts interaction from passive observation to active collaboration, steering models toward more accurate and trustworthy conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer accuracy by up to 24 percentage points over non-interactive baselines. A user study also shows large gains in perceived usability and trust. Vis-CoT points to a practical path for more reliable, understandable, and collaborative reasoning by combining LLMs with targeted human oversight.

