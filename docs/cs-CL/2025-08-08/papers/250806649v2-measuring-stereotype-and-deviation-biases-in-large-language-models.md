---
layout: default
title: Measuring Stereotype and Deviation Biases in Large Language Models
---

# Measuring Stereotype and Deviation Biases in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06649" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06649v2</a>
  <a href="https://arxiv.org/pdf/2508.06649.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06649v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06649v2', 'Measuring Stereotype and Deviation Biases in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel Wang, Eli Brignac, Minjia Mao, Xiao Fang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08 (æ›´æ–°: 2025-08-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åˆ»æ¿å°è±¡ä¸åå·®åè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åˆ»æ¿å°è±¡åè§` `åå·®åè§` `å†…å®¹ç”Ÿæˆ` `å…¬å¹³æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å¯èƒ½å­˜åœ¨åˆ»æ¿å°è±¡å’Œåå·®åè§ï¼Œå½±å“å…¶åº”ç”¨çš„å…¬å¹³æ€§ä¸å‡†ç¡®æ€§ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡ç”Ÿæˆä¸ªä½“æ¡£æ¡ˆçš„æ–¹å¼ï¼Œç³»ç»Ÿæ€§åœ°åˆ†æäº†LLMsåœ¨ä¸åŒäººå£ç¾¤ä½“ä¸Šçš„åè§è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsåœ¨å¤šä¸ªç¾¤ä½“ä¸Šå‡å­˜åœ¨æ˜¾è‘—çš„åè§ï¼Œæ­ç¤ºäº†å…¶ç”Ÿæˆå†…å®¹çš„æ½œåœ¨é£é™©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸçš„å¹¿æ³›åº”ç”¨å¼•å‘äº†å¯¹å…¶å±€é™æ€§å’Œæ½œåœ¨é£é™©çš„å…³æ³¨ã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†LLMså¯èƒ½è¡¨ç°å‡ºçš„ä¸¤ç§åè§ï¼šåˆ»æ¿å°è±¡åè§å’Œåå·®åè§ã€‚åˆ»æ¿å°è±¡åè§æŒ‡çš„æ˜¯LLMsæŒç»­å°†ç‰¹å®šç‰¹å¾ä¸ç‰¹å®šäººå£ç¾¤ä½“å…³è”ï¼Œè€Œåå·®åè§åˆ™åæ˜ äº†LLMç”Ÿæˆå†…å®¹ä¸­çš„äººå£åˆ†å¸ƒä¸ç°å®ä¸–ç•Œäººå£åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚é€šè¿‡è®©å››ä¸ªå…ˆè¿›çš„LLMsç”Ÿæˆä¸ªä½“æ¡£æ¡ˆï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†æ¯ä¸ªç¾¤ä½“ä¸æ”¿æ²»å€¾å‘ã€å®—æ•™å’Œæ€§å–å‘ç­‰å±æ€§ä¹‹é—´çš„å…³è”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰è¢«æ£€éªŒçš„LLMså¯¹å¤šä¸ªç¾¤ä½“å‡è¡¨ç°å‡ºæ˜¾è‘—çš„åˆ»æ¿å°è±¡åè§å’Œåå·®åè§ï¼Œæ­ç¤ºäº†LLMsæ¨æ–­ç”¨æˆ·å±æ€§æ—¶å¯èƒ½å‡ºç°çš„åè§åŠå…¶æ½œåœ¨å±å®³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å¯èƒ½å­˜åœ¨çš„åˆ»æ¿å°è±¡åè§å’Œåå·®åè§ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯†åˆ«å’Œé‡åŒ–è¿™äº›åè§ï¼Œå¯¼è‡´ç”Ÿæˆå†…å®¹çš„å…¬å¹³æ€§å—åˆ°è´¨ç–‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®©å¤šä¸ªLLMsç”Ÿæˆä¸åŒäººå£ç¾¤ä½“çš„ä¸ªä½“æ¡£æ¡ˆï¼Œåˆ†æå…¶å¯¹ç‰¹å®šå±æ€§ï¼ˆå¦‚æ”¿æ²»å€¾å‘ã€å®—æ•™å’Œæ€§å–å‘ï¼‰çš„å…³è”ï¼Œä»è€Œæ­ç¤ºå…¶æ½œåœ¨çš„åè§è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®éªŒè®¾è®¡ï¼Œé¦–å…ˆé€‰æ‹©å››ä¸ªå…ˆè¿›çš„LLMsï¼Œç„¶åé’ˆå¯¹æ¯ä¸ªæ¨¡å‹ç”Ÿæˆå¤šç»„ä¸ªä½“æ¡£æ¡ˆï¼Œæœ€åå¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œåˆ†æå’Œæ¯”è¾ƒï¼Œä»¥è¯†åˆ«åè§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°é‡åŒ–å’Œæ¯”è¾ƒä¸åŒLLMsåœ¨åˆ»æ¿å°è±¡å’Œåå·®åè§æ–¹é¢çš„è¡¨ç°ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„ç”Ÿæˆä»»åŠ¡å’Œè¯„ä¼°æ ‡å‡†ï¼Œä»¥ç¡®ä¿å¯¹åè§çš„å‡†ç¡®æµ‹é‡ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„äººå£ç‰¹å¾å’Œå±æ€§ç»„åˆè¿›è¡Œåˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰æµ‹è¯•çš„LLMsåœ¨å¤šä¸ªç¾¤ä½“ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„åˆ»æ¿å°è±¡åè§å’Œåå·®åè§ï¼Œå…·ä½“è¡¨ç°ä¸ºä¸çœŸå®ä¸–ç•Œäººå£åˆ†å¸ƒå­˜åœ¨æ˜æ˜¾å·®å¼‚ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨ä½¿ç”¨LLMsæ—¶éœ€è°¨æ…å¯¹å¾…ç”Ÿæˆå†…å®¹çš„æ½œåœ¨åè§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„ç»“æœå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨å…·æœ‰é‡è¦çš„æŒ‡å¯¼æ„ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨ç¤¾äº¤åª’ä½“ã€æ‹›è˜ç³»ç»Ÿå’Œå†…å®¹ç”Ÿæˆç­‰é¢†åŸŸã€‚é€šè¿‡è¯†åˆ«å’Œé‡åŒ–åè§ï¼Œå¼€å‘è€…å¯ä»¥æ›´å¥½åœ°è°ƒæ•´æ¨¡å‹ï¼Œå‡å°‘æ½œåœ¨çš„ç¤¾ä¼šé£é™©ï¼Œæå‡æ¨¡å‹çš„å…¬å¹³æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are widely applied across diverse domains, raising concerns about their limitations and potential risks. In this study, we investigate two types of bias that LLMs may display: stereotype bias and deviation bias. Stereotype bias refers to when LLMs consistently associate specific traits with a particular demographic group. Deviation bias reflects the disparity between the demographic distributions extracted from LLM-generated content and real-world demographic distributions. By asking four advanced LLMs to generate profiles of individuals, we examine the associations between each demographic group and attributes such as political affiliation, religion, and sexual orientation. Our experimental results show that all examined LLMs exhibit both significant stereotype bias and deviation bias towards multiple groups. Our findings uncover the biases that occur when LLMs infer user attributes and shed light on the potential harms of LLM-generated outputs.

