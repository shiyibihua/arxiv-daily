---
layout: default
title: InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?
---

# InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06220v2</a>
  <a href="https://arxiv.org/pdf/2508.06220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06220v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06220v2', 'InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Keummin Ka, Junhyeong Park, Jaehyun Jeon, Youngjae Yu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08 (æ›´æ–°: 2025-08-13)

**å¤‡æ³¨**: 14 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInfoCausalQAä»¥è¯„ä¼°åŸºäºä¿¡æ¯å›¾çš„å› æœæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ä¿¡æ¯å›¾` `æ•°æ®é›†æ„å»º` `è¯­ä¹‰ç†è§£` `äººå·¥æ™ºèƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å› æœæ¨ç†æ–¹é¢èƒ½åŠ›ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºInfoCausalQAåŸºå‡†ï¼Œé€šè¿‡ä¿¡æ¯å›¾ç»“åˆæ–‡æœ¬ä¸Šä¸‹æ–‡ï¼Œè¯„ä¼°å› æœæ¨ç†èƒ½åŠ›ï¼ŒåŒ…å«å®šé‡å’Œè¯­ä¹‰å› æœæ¨ç†ä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰VLMåœ¨å› æœæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä½äºäººç±»ï¼Œæ˜¾ç¤ºå‡ºåœ¨ä¿¡æ¯å›¾ä¿¡æ¯åˆ©ç”¨æ–¹é¢çš„å·¨å¤§å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨æ„ŸçŸ¥å’Œæ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå› æœæ¨ç†èƒ½åŠ›ï¼Œä½œä¸ºäººç±»è®¤çŸ¥çš„æ ¸å¿ƒæ–¹é¢ï¼Œä»ç„¶æœªå¾—åˆ°å……åˆ†æ¢ç´¢ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­ã€‚æœ¬ç ”ç©¶ä»‹ç»äº†InfoCausalQAï¼Œä¸€ä¸ªæ–°é¢–çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°åŸºäºä¿¡æ¯å›¾çš„å› æœæ¨ç†èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…æ‹¬ä¸¤ä¸ªä»»åŠ¡ï¼šä»»åŠ¡ä¸€å…³æ³¨åŸºäºæ¨æ–­çš„æ•°å€¼è¶‹åŠ¿è¿›è¡Œå®šé‡å› æœæ¨ç†ï¼Œä»»åŠ¡äºŒåˆ™æ¶‰åŠäº”ç§å› æœå…³ç³»çš„è¯­ä¹‰å› æœæ¨ç†ã€‚æˆ‘ä»¬ä»å››ä¸ªå…¬å…±æ¥æºæ‰‹åŠ¨æ”¶é›†äº†494å¯¹ä¿¡æ¯å›¾-æ–‡æœ¬ï¼Œå¹¶ä½¿ç”¨GPT-4oç”Ÿæˆäº†1482ä¸ªé«˜è´¨é‡çš„å¤šé¡¹é€‰æ‹©é—®ç­”å¯¹ã€‚è¿™äº›é—®é¢˜ç»è¿‡äººå·¥ä»”ç»†ä¿®è®¢ï¼Œç¡®ä¿ä¸èƒ½ä»…é€šè¿‡è¡¨é¢çº¿ç´¢å›ç­”ï¼Œè€Œéœ€è¦çœŸæ­£çš„è§†è§‰åŸºç¡€ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„VLMåœ¨è®¡ç®—æ¨ç†æ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œè¯­ä¹‰å› æœæ¨ç†çš„å±€é™æ€§æ›´ä¸ºæ˜æ˜¾ï¼Œè¡¨æ˜åœ¨åˆ©ç”¨åŸºäºä¿¡æ¯å›¾çš„ä¿¡æ¯è¿›è¡Œå› æœæ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚é€šè¿‡InfoCausalQAï¼Œæˆ‘ä»¬å¼ºè°ƒäº†æå‡å¤šæ¨¡æ€AIç³»ç»Ÿå› æœæ¨ç†èƒ½åŠ›çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å› æœæ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­ï¼Œç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†å’ŒåŸºå‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡InfoCausalQAåŸºå‡†ï¼Œç»“åˆä¿¡æ¯å›¾å’Œæ–‡æœ¬ï¼Œåˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿè¯„ä¼°å› æœæ¨ç†èƒ½åŠ›çš„æ¡†æ¶ï¼Œå¼ºè°ƒè§†è§‰åŸºç¡€çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ä»»åŠ¡ï¼šä»»åŠ¡ä¸€è¿›è¡Œå®šé‡å› æœæ¨ç†ï¼Œä»»åŠ¡äºŒè¿›è¡Œè¯­ä¹‰å› æœæ¨ç†ã€‚æ•°æ®é›†ç”±494å¯¹ä¿¡æ¯å›¾-æ–‡æœ¬å¯¹å’Œ1482ä¸ªå¤šé¡¹é€‰æ‹©é—®ç­”å¯¹ç»„æˆï¼Œç¡®ä¿é—®é¢˜éœ€è¦æ·±å±‚æ¬¡çš„è§†è§‰ç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡ä¿¡æ¯å›¾ç»“åˆæ–‡æœ¬çš„æ–¹å¼ï¼Œåˆ›å»ºäº†ä¸€ä¸ªæ–°çš„å› æœæ¨ç†è¯„ä¼°åŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€å› æœæ¨ç†è¯„ä¼°ä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨GPT-4oç”Ÿæˆé—®ç­”å¯¹ï¼Œå¹¶ç»è¿‡äººå·¥ä¿®è®¢ï¼Œç¡®ä¿é—®é¢˜çš„å¤æ‚æ€§å’Œæ·±åº¦ï¼Œé¿å…ä»…ä¾èµ–è¡¨é¢çº¿ç´¢è¿›è¡Œå›ç­”ã€‚å®éªŒè®¾è®¡ä¸­æ³¨é‡å¯¹æ¯”åˆ†æï¼Œè¯„ä¼°VLMä¸äººç±»åœ¨å› æœæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å®šé‡å› æœæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ä»…ä¸ºäººç±»çš„X%ï¼Œè€Œåœ¨è¯­ä¹‰å› æœæ¨ç†ä»»åŠ¡ä¸­æ›´æ˜¯ä½äºY%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚å› æœå…³ç³»æ—¶å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå¼ºè°ƒäº†è¿›ä¸€æ­¥ç ”ç©¶çš„å¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ•°æ®å¯è§†åŒ–å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€AIç³»ç»Ÿçš„å› æœæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£å¤æ‚ä¿¡æ¯ï¼Œæ”¯æŒå†³ç­–åˆ¶å®šå’ŒçŸ¥è¯†ä¼ æ’­ï¼Œæœªæ¥å¯èƒ½å¯¹æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–åˆ†æå·¥å…·äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Vision-Language Models (VLMs) have demonstrated impressive capabilities in perception and reasoning. However, the ability to perform causal inference -- a core aspect of human cognition -- remains underexplored, particularly in multimodal settings. In this study, we introduce InfoCausalQA, a novel benchmark designed to evaluate causal reasoning grounded in infographics that combine structured visual data with textual context. The benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning based on inferred numerical trends, while Task 2 targets semantic causal reasoning involving five types of causal relations: cause, effect, intervention, counterfactual, and temporal. We manually collected 494 infographic-text pairs from four public sources and used GPT-4o to generate 1,482 high-quality multiple-choice QA pairs. These questions were then carefully revised by humans to ensure they cannot be answered based on surface-level cues alone but instead require genuine visual grounding. Our experimental results reveal that current VLMs exhibit limited capability in computational reasoning and even more pronounced limitations in semantic causal reasoning. Their significantly lower performance compared to humans indicates a substantial gap in leveraging infographic-based information for causal inference. Through InfoCausalQA, we highlight the need for advancing the causal reasoning abilities of multimodal AI systems.

