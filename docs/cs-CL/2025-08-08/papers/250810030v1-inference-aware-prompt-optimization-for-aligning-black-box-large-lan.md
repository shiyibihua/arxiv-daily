---
layout: default
title: Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models
---

# Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10030" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.10030v1</a>
  <a href="https://arxiv.org/pdf/2508.10030.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10030v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10030v1', 'Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Saaduddin Mahmud, Mason Nakamura, Kyle H. Wray, Shlomo Zilberstein

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-08

**Â§áÊ≥®**: 17 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫IAPOÊ°ÜÊû∂‰ª•‰ºòÂåñÈªëÁÆ±Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊèêÁ§∫‰∏éÊé®ÁêÜÁ≠ñÁï•**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊèêÁ§∫‰ºòÂåñ` `Êé®ÁêÜÁ≠ñÁï•` `ÈªëÁÆ±Ê®°Âûã` `Â§öÁõÆÊ†áÂ≠¶‰π†` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÊú™ËÄÉËôëÊé®ÁêÜÁ≠ñÁï•ÔºåÂØºËá¥Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠Â≠òÂú®ÊòæËëóÁöÑÊÄßËÉΩÂ∑ÆË∑ùÂíåÊñπÊ≥ïËÆ∫Á©∫ÁôΩ„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫ÜIAPOÊ°ÜÊû∂ÔºåËÅîÂêà‰ºòÂåñÊèêÁ§∫ÂíåÊé®ÁêÜËßÑÊ®°ÔºåÂÖ≥Ê≥®Êé®ÁêÜÈ¢ÑÁÆóÂíå‰ªªÂä°ÁõÆÊ†áÁöÑ‰∏çÂêåÈúÄÊ±Ç„ÄÇ
3. Âú®ÂÖ≠‰∏™‰ªªÂä°‰∏äËøõË°åÁöÑÂÆûÈ™åË°®ÊòéÔºåPSSTÁÆóÊ≥ïÊòæËëóÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÂØπÈΩêÊïàÊûúÔºåÈ™åËØÅ‰∫ÜÊé®ÁêÜÊÑüÁü•ÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÂú®ÂØπÈΩêÈªëÁÆ±Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊñπÈù¢Ë°®Áé∞Âá∫ÊòæËëóÊïàÊûú„ÄÇÂêåÊó∂ÔºåÊé®ÁêÜÊâ©Â±ïÁ≠ñÁï•Â¶ÇÊúÄ‰Ω≥NÈááÊ†∑ÂíåÂ§öÊï∞ÊäïÁ•®‰πüËØÅÊòéËÉΩÂ§üÈÄöËøáÊùÉË°°ËÆ°ÁÆóÊù•ÊèêÂçáÂØπÈΩêÂíåÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÁöÑÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÊú™ËÄÉËôëÊé®ÁêÜÁ≠ñÁï•ÔºåËøôÊûÑÊàê‰∫Ü‰∏Ä‰∏™ÈáçË¶ÅÁöÑÁêÜËÆ∫ÂíåÊñπÊ≥ïËÆ∫Á©∫ÁôΩ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏Ä‰∏™Áªü‰∏ÄÁöÑÊñ∞Ê°ÜÊû∂IAPOÔºàÊé®ÁêÜÊÑüÁü•ÊèêÁ§∫‰ºòÂåñÔºâÔºåËØ•Ê°ÜÊû∂Âú®‰ºòÂåñÊèêÁ§∫ÁöÑÂêåÊó∂ËÄÉËôëÊé®ÁêÜÈ¢ÑÁÆóÂíå‰∏çÂêå‰ªªÂä°ÁõÆÊ†á„ÄÇÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏ÄÁßçÂõ∫ÂÆöÈ¢ÑÁÆóËÆ≠ÁªÉÁÆóÊ≥ïPSSTÔºàÈÄöËøáÈ°∫Â∫è‰øÆÂâ™ËøõË°åÊèêÁ§∫Áº©ÊîæÔºâÔºåÂπ∂Âú®ÂÖ≠‰∏™‰∏çÂêå‰ªªÂä°‰∏äËØÑ‰º∞‰∫ÜÂÖ∂ÊúâÊïàÊÄßÔºåÂ±ïÁ§∫‰∫ÜÊé®ÁêÜÊÑüÁü•Âú®ÊèêÁ§∫‰ºòÂåñ‰∏≠ÁöÑÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊèêÁ§∫‰ºòÂåñÊñπÊ≥ï‰∏éÊé®ÁêÜÁ≠ñÁï•‰πãÈó¥ÁöÑÁõ∏‰∫íÁã¨Á´ãÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÄÉËôëÊé®ÁêÜÁ≠ñÁï•ÁöÑÂΩ±ÂìçÔºåÂØºËá¥Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊÄßËÉΩ‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑIAPOÊ°ÜÊû∂ÈÄöËøáËÅîÂêà‰ºòÂåñÊèêÁ§∫ÂíåÊé®ÁêÜËßÑÊ®°ÔºåËÄÉËôëÁî®Êà∑Âú®Â§öÁõÆÊ†áÂíåÊé®ÁêÜÈ¢ÑÁÆóÊñπÈù¢ÁöÑÂÅèÂ•ΩÔºå‰ªéËÄåÂÆûÁé∞Êõ¥ÊúâÊïàÁöÑÂØπÈΩê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöIAPOÊ°ÜÊû∂ÂåÖÊã¨ÊèêÁ§∫‰ºòÂåñÂíåÊé®ÁêÜÁ≠ñÁï•ÁöÑËÅîÂêà‰ºòÂåñÊ®°ÂùóÔºåÈááÁî®Âõ∫ÂÆöÈ¢ÑÁÆóËÆ≠ÁªÉÁÆóÊ≥ïPSSTÔºåÁ°Æ‰øùÂú®ÊúâÈôêÈ¢ÑÁÆó‰∏ãÁöÑÊúâÊïàÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•Êé®ÁêÜÊÑüÁü•ÁöÑÊèêÁ§∫‰ºòÂåñÊñπÊ≥ïÔºåÂ°´Ë°•‰∫ÜÁé∞ÊúâÊñπÊ≥ïÂú®Êé®ÁêÜÁ≠ñÁï•ËÄÉËôë‰∏äÁöÑÁ©∫ÁôΩÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöPSSTÁÆóÊ≥ïÈÄöËøáÈ°∫Â∫è‰øÆÂâ™ÂÆûÁé∞ÊèêÁ§∫ÁöÑÂä®ÊÄÅË∞ÉÊï¥ÔºåÈááÁî®ÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•Á°Æ‰øùÂú®ÊúâÈôêÈ¢ÑÁÆó‰∏ãÁöÑÈîôËØØÊ¶ÇÁéáÊéßÂà∂„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåPSSTÁÆóÊ≥ïÂú®ÂÖ≠‰∏™‰∏çÂêå‰ªªÂä°‰∏äÂùáÂèñÂæó‰∫ÜÊòæËëóÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊñπÊ≥ïÔºåÊ®°ÂûãÁöÑÂØπÈΩêÊïàÊûúÊèêÈ´ò‰∫ÜÁ∫¶15%-30%„ÄÇËøô‰∫õÁªìÊûúÈ™åËØÅ‰∫ÜÊé®ÁêÜÊÑüÁü•Âú®ÊèêÁ§∫‰ºòÂåñ‰∏≠ÁöÑÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÊô∫ËÉΩÂØπËØùÁ≥ªÁªüÂíåÂ§ö‰ªªÂä°Â≠¶‰π†Á≠â„ÄÇÈÄöËøá‰ºòÂåñÊèêÁ§∫‰∏éÊé®ÁêÜÁ≠ñÁï•ÁöÑÁªìÂêàÔºåËÉΩÂ§üÂú®ËµÑÊ∫êÊúâÈôêÁöÑÊÉÖÂÜµ‰∏ãÊèêÂçáÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÁî®Êà∑‰ΩìÈ™åÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Prompt optimization methods have demonstrated significant effectiveness in aligning black-box large language models (LLMs). In parallel, inference scaling strategies such as Best-of-N Sampling and Majority Voting have also proven to enhance alignment and performance by trading off computation. However, existing prompt optimization approaches are inference strategy agnostic; that is, they optimize prompts without regard to the inference strategy employed during deployment. This constitutes a significant methodological gap, as our empirical and theoretical analysis reveals a strong interdependence between these two paradigms. Moreover, we find that user preferences regarding trade-offs among multiple objectives and inference budgets substantially influence the choice of prompt and inference configuration. To address this gap, we introduce a unified novel framework named IAPO (Inference-Aware Prompt Optimization) that jointly optimizes the prompt and inference scale, while being aware of the inference budget and different task objectives. We then develop a fixed-budget training algorithm for IAPO, which we call PSST (Prompt Scaling via Sequential Trimming), and analyze finite-budget guarantees on error probability. Finally, we evaluate the effectiveness of PSST on six different tasks, including multi-objective text generation and reasoning, and demonstrate the critical role of incorporating inference-awareness when aligning black-box LLMs through prompt optimization.

