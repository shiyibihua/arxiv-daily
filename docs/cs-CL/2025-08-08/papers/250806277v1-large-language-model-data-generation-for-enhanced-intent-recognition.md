---
layout: default
title: Large Language Model Data Generation for Enhanced Intent Recognition in German Speech
---

# Large Language Model Data Generation for Enhanced Intent Recognition in German Speech

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06277" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06277v1</a>
  <a href="https://arxiv.org/pdf/2508.06277.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06277v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06277v1', 'Large Language Model Data Generation for Enhanced Intent Recognition in German Speech')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Theresa Pekarek Rosin, Burak Can Kaplan, Stefan Wermter

**åˆ†ç±»**: cs.CL, cs.LG, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08

**å¤‡æ³¨**: 11 pages, 3 figures, accepted at KONVENS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆç”Ÿæˆæ¨¡å‹ä»¥æå‡å¾·è¯­è¯­éŸ³æ„å›¾è¯†åˆ«èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ„å›¾è¯†åˆ«` `å¾·è¯­è¯­éŸ³` `ç”Ÿæˆæ¨¡å‹` `è€å¹´ç”¨æˆ·` `åˆæˆæ•°æ®` `Transformeræ¨¡å‹` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ„å›¾è¯†åˆ«æ–¹æ³•ä¸»è¦é’ˆå¯¹çŸ­å‘½ä»¤ï¼Œä¸”å¤§å¤šä¸ºè‹±è¯­å¼€å‘ï¼Œæ— æ³•æ»¡è¶³è€å¹´å¾·è¯­ç”¨æˆ·çš„éœ€æ±‚ã€‚
2. æœ¬æ–‡æå‡ºç»“åˆå¾®è°ƒçš„Whisper ASRæ¨¡å‹ä¸ç”Ÿæˆçš„åˆæˆæ–‡æœ¬æ•°æ®ï¼Œæå‡å¾·è¯­è¯­éŸ³æ„å›¾è¯†åˆ«çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨åˆæˆçš„LLMç”Ÿæˆæ•°æ®åï¼Œåˆ†ç±»æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯LeoLMåœ¨æ•°æ®é›†è´¨é‡ä¸Šä¼˜äºChatGPTã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ„å›¾è¯†åˆ«ï¼ˆIRï¼‰åœ¨äººå·¥æ™ºèƒ½åŠ©æ‰‹ç³»ç»Ÿä¸­è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰æ–¹æ³•å¤šå±€é™äºçŸ­å‘½ä»¤ä¸”ä¸»è¦é’ˆå¯¹è‹±è¯­ã€‚æœ¬æ–‡èšç„¦äºè€å¹´å¾·è¯­ç”¨æˆ·çš„è¯­éŸ³æ„å›¾è¯†åˆ«ï¼Œæå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç»“åˆäº†é’ˆå¯¹è€å¹´å¾·è¯­è¯­éŸ³å¾®è°ƒçš„Whisper ASRæ¨¡å‹ä¸åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹ä½¿ç”¨ä¸‰ç§çŸ¥åçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„åˆæˆæ–‡æœ¬æ•°æ®é›†è¿›è¡Œè®­ç»ƒã€‚é€šè¿‡ç”Ÿæˆåˆæˆè¯­éŸ³å¹¶è¿›è¡Œå¹¿æ³›çš„è·¨æ•°æ®é›†æµ‹è¯•ï¼Œç»“æœè¡¨æ˜ï¼Œåˆæˆçš„LLMç”Ÿæˆæ•°æ®æ˜¾è‘—æå‡äº†åˆ†ç±»æ€§èƒ½å’Œå¯¹ä¸åŒè¯´è¯é£æ ¼åŠæœªè§è¯æ±‡çš„é²æ£’æ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¾ƒå°çš„é¢†åŸŸç‰¹å®š13B LLM LeoLMåœ¨å¾·è¯­æ„å›¾è¯†åˆ«çš„æ•°æ®é›†è´¨é‡ä¸Šè¶…è¿‡äº†æ›´å¤§çš„ChatGPTï¼ˆ175Bï¼‰ã€‚è¯¥æ–¹æ³•å±•ç¤ºäº†ç”Ÿæˆæ€§AIåœ¨ä½èµ„æºé¢†åŸŸæœ‰æ•ˆå¼¥è¡¥æ•°æ®ç¼ºå£çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ„å›¾è¯†åˆ«æ–¹æ³•åœ¨è€å¹´å¾·è¯­ç”¨æˆ·è¯­éŸ³å‘½ä»¤è¯†åˆ«ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¯¹çŸ­å‘½ä»¤çš„å±€é™æ€§å’Œå¯¹è‹±è¯­çš„åé‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆå¾®è°ƒçš„Whisper ASRæ¨¡å‹ä¸ç”Ÿæˆçš„åˆæˆæ–‡æœ¬æ•°æ®ï¼Œæå‡å¯¹è€å¹´å¾·è¯­ç”¨æˆ·çš„æ„å›¾è¯†åˆ«èƒ½åŠ›ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯å¾®è°ƒçš„Whisper ASRæ¨¡å‹ç”¨äºè¯­éŸ³è¯†åˆ«ï¼Œå…¶æ¬¡æ˜¯åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹ç”¨äºç†è§£ç”Ÿæˆçš„æ–‡æœ¬ï¼Œæœ€åæ˜¯åˆæˆè¯­éŸ³ç”Ÿæˆæ¨¡å—ç”¨äºæµ‹è¯•å’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºä½¿ç”¨åˆæˆçš„LLMç”Ÿæˆæ•°æ®æ¥å¢å¼ºè®­ç»ƒé›†ï¼Œå°¤å…¶æ˜¯LeoLMåœ¨ç‰¹å®šé¢†åŸŸçš„è¡¨ç°è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ï¼Œå±•ç¤ºäº†ç”Ÿæˆæ€§AIåœ¨ä½èµ„æºé¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ è€å¹´å¾·è¯­ç”¨æˆ·çš„è¯­éŸ³ç‰¹å¾å’Œæ„å›¾ï¼ŒåŒæ—¶åœ¨åˆæˆè¯­éŸ³ç”Ÿæˆè¿‡ç¨‹ä¸­ä¿æŒé«˜è´¨é‡çš„è¾“å‡ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åˆæˆçš„LLMç”Ÿæˆæ•°æ®åï¼Œæ„å›¾è¯†åˆ«çš„åˆ†ç±»æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒè¯´è¯é£æ ¼å’Œæœªè§è¯æ±‡çš„é²æ£’æ€§æ–¹é¢ã€‚LeoLMåœ¨æ•°æ®é›†è´¨é‡ä¸Šè¶…è¶Šäº†ChatGPTï¼Œå±•ç¤ºäº†å…¶åœ¨å¾·è¯­æ„å›¾è¯†åˆ«ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…åŠ©æ‰‹ã€åŒ»ç–—è¾…åŠ©ç³»ç»ŸåŠè€å¹´äººè¯­éŸ³äº¤äº’ç•Œé¢ç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡è€å¹´ç”¨æˆ·çš„äº¤äº’ä½“éªŒå’Œç³»ç»Ÿçš„å“åº”èƒ½åŠ›ã€‚æœªæ¥ï¼Œéšç€æ›´å¤šä½èµ„æºè¯­è¨€çš„ç ”ç©¶ï¼Œç±»ä¼¼çš„æ–¹æ³•å¯èƒ½ä¼šåœ¨å…¨çƒèŒƒå›´å†…æ¨å¹¿ï¼Œä¿ƒè¿›æ— éšœç¢æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Intent recognition (IR) for speech commands is essential for artificial intelligence (AI) assistant systems; however, most existing approaches are limited to short commands and are predominantly developed for English. This paper addresses these limitations by focusing on IR from speech by elderly German speakers. We propose a novel approach that combines an adapted Whisper ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based language models trained on synthetic text datasets generated by three well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To evaluate the robustness of our approach, we generate synthetic speech with a text-to-speech model and conduct extensive cross-dataset testing. Our results show that synthetic LLM-generated data significantly boosts classification performance and robustness to different speaking styles and unseen vocabulary. Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the much larger ChatGPT (175B) in dataset quality for German intent recognition. Our approach demonstrates that generative AI can effectively bridge data gaps in low-resource domains. We provide detailed documentation of our data generation and training process to ensure transparency and reproducibility.

