---
layout: default
title: GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models
---

# GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06471" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06471v1</a>
  <a href="https://arxiv.org/pdf/2508.06471.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06471v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06471v1', 'GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: GLM-4. 5 Team, :, Aohan Zeng, Xin Lv, Qinkai Zheng, Zhenyu Hou, Bin Chen, Chengxing Xie, Cunxiang Wang, Da Yin, Hao Zeng, Jiajie Zhang, Kedong Wang, Lucen Zhong, Mingdao Liu, Rui Lu, Shulin Cao, Xiaohan Zhang, Xuancheng Huang, Yao Wei, Yean Cheng, Yifan An, Yilin Niu, Yuanhao Wen, Yushi Bai, Zhengxiao Du, Zihan Wang, Zilin Zhu, Bohan Zhang, Bosi Wen, Bowen Wu, Bowen Xu, Can Huang, Casey Zhao, Changpeng Cai, Chao Yu, Chen Li, Chendi Ge, Chenghua Huang, Chenhui Zhang, Chenxi Xu, Chenzheng Zhu, Chuang Li, Congfeng Yin, Daoyan Lin, Dayong Yang, Dazhi Jiang, Ding Ai, Erle Zhu, Fei Wang, Gengzheng Pan, Guo Wang, Hailong Sun, Haitao Li, Haiyang Li, Haiyi Hu, Hanyu Zhang, Hao Peng, Hao Tai, Haoke Zhang, Haoran Wang, Haoyu Yang, He Liu, He Zhao, Hongwei Liu, Hongxi Yan, Huan Liu, Huilong Chen, Ji Li, Jiajing Zhao, Jiamin Ren, Jian Jiao, Jiani Zhao, Jianyang Yan, Jiaqi Wang, Jiayi Gui, Jiayue Zhao, Jie Liu, Jijie Li, Jing Li, Jing Lu, Jingsen Wang, Jingwei Yuan, Jingxuan Li, Jingzhao Du, Jinhua Du, Jinxin Liu, Junkai Zhi, Junli Gao, Ke Wang, Lekang Yang, Liang Xu, Lin Fan, Lindong Wu, Lintao Ding, Lu Wang, Man Zhang, Minghao Li, Minghuan Xu, Mingming Zhao, Mingshu Zhai, Pengfan Du, Qian Dong, Shangde Lei, Shangqing Tu, Shangtong Yang, Shaoyou Lu, Shijie Li, Shuang Li, Shuang-Li, Shuxun Yang, Sibo Yi, Tianshu Yu, Wei Tian, Weihan Wang, Wenbo Yu, Weng Lam Tam, Wenjie Liang, Wentao Liu, Xiao Wang, Xiaohan Jia, Xiaotao Gu, Xiaoying Ling, Xin Wang, Xing Fan, Xingru Pan, Xinyuan Zhang, Xinze Zhang, Xiuqing Fu, Xunkai Zhang, Yabo Xu, Yandong Wu, Yida Lu, Yidong Wang, Yilin Zhou, Yiming Pan, Ying Zhang, Yingli Wang, Yingru Li, Yinpei Su, Yipeng Geng, Yitong Zhu, Yongkun Yang, Yuhang Li, Yuhao Wu, Yujiang Li, Yunan Liu, Yunqing Wang, Yuntao Li, Yuxuan Zhang, Zezhen Liu, Zhen Yang, Zhengda Zhou, Zhongpei Qiao, Zhuoer Feng, Zhuorui Liu, Zichen Zhang, Zihan Wang, Zijun Yao, Zikang Wang, Ziqiang Liu, Ziwei Chai, Zixuan Li, Zuodong Zhao, Wenguang Chen, Jidong Zhai, Bin Xu, Minlie Huang, Hongning Wang, Juanzi Li, Yuxiao Dong, Jie Tang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-08

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zai-org/GLM-4.5)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGLM-4.5ä»¥æ¨åŠ¨æ™ºèƒ½æ¨ç†ä¸ç¼–ç ä»»åŠ¡çš„ç ”ç©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ··åˆä¸“å®¶æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ™ºèƒ½æ¨ç†` `ç¼–ç ä»»åŠ¡` `å¼ºåŒ–å­¦ä¹ ` `å¤šé˜¶æ®µè®­ç»ƒ` `å‚æ•°æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†å’Œç¼–ç ä»»åŠ¡ä¸Šå­˜åœ¨æ€§èƒ½ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å‚æ•°æ•ˆç‡æ–¹é¢ã€‚
2. GLM-4.5é€šè¿‡æ··åˆä¸“å®¶æ¶æ„å’Œå¤šé˜¶æ®µè®­ç»ƒï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ ï¼Œæå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå“åº”æ•ˆç‡ã€‚
3. åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼ŒGLM-4.5è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨æ™ºèƒ½åŸºå‡†æµ‹è¯•ä¸­æ’åç¬¬äºŒï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†GLM-4.5ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰3550äº¿ä¸ªæ€»å‚æ•°å’Œ320äº¿ä¸ªæ¿€æ´»å‚æ•°ï¼Œé‡‡ç”¨æ··åˆæ¨ç†æ–¹æ³•ï¼Œæ”¯æŒæ€è€ƒå’Œç›´æ¥å“åº”æ¨¡å¼ã€‚é€šè¿‡å¯¹23ä¸‡äº¿ä¸ªæ ‡è®°çš„å¤šé˜¶æ®µè®­ç»ƒå’Œä¸“å®¶æ¨¡å‹è¿­ä»£åŠå¼ºåŒ–å­¦ä¹ çš„å…¨é¢åè®­ç»ƒï¼ŒGLM-4.5åœ¨æ™ºèƒ½ã€æ¨ç†å’Œç¼–ç ï¼ˆARCï¼‰ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œåœ¨TAU-Benchä¸Šå¾—åˆ†70.1%ï¼Œåœ¨AIME 24ä¸Šå¾—åˆ†91.0%ï¼Œåœ¨SWE-bench Verifiedä¸Šå¾—åˆ†64.2%ã€‚GLM-4.5çš„å‚æ•°æ•°é‡è¿œå°‘äºå¤šä¸ªç«äº‰å¯¹æ‰‹ï¼Œåœ¨æ‰€æœ‰è¯„ä¼°æ¨¡å‹ä¸­æ’åç¬¬ä¸‰ï¼Œåœ¨æ™ºèƒ½åŸºå‡†æµ‹è¯•ä¸­æ’åç¬¬äºŒã€‚æˆ‘ä»¬å‘å¸ƒäº†GLM-4.5ï¼ˆ3550äº¿å‚æ•°ï¼‰å’Œç´§å‡‘ç‰ˆGLM-4.5-Airï¼ˆ1060äº¿å‚æ•°ï¼‰ï¼Œä»¥æ¨åŠ¨æ¨ç†å’Œæ™ºèƒ½AIç³»ç»Ÿçš„ç ”ç©¶ã€‚ä»£ç ã€æ¨¡å‹åŠæ›´å¤šä¿¡æ¯å¯åœ¨https://github.com/zai-org/GLM-4.5è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ™ºèƒ½æ¨ç†å’Œç¼–ç ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯å‚æ•°æ•ˆç‡ä½çš„é—®é¢˜ã€‚ç°æœ‰æ¨¡å‹å¾€å¾€éœ€è¦å¤§é‡å‚æ•°æ‰èƒ½å®ç°è¾ƒå¥½çš„æ€§èƒ½ï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGLM-4.5é‡‡ç”¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¶æ„ï¼Œç»“åˆå¤šé˜¶æ®µè®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œæ—¨åœ¨é€šè¿‡æ¿€æ´»éƒ¨åˆ†å‚æ•°æ¥æé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå“åº”é€Ÿåº¦ï¼Œä»è€Œåœ¨ä¿æŒè¾ƒä½å‚æ•°é‡çš„åŒæ—¶å®ç°é«˜æ•ˆæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGLM-4.5çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯æ··åˆä¸“å®¶æ¨¡å—ï¼Œé€šè¿‡é€‰æ‹©æ€§æ¿€æ´»æ¥ä¼˜åŒ–è®¡ç®—èµ„æºï¼›å…¶æ¬¡æ˜¯å¤šé˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œåˆ©ç”¨23ä¸‡äº¿ä¸ªæ ‡è®°è¿›è¡Œé¢„è®­ç»ƒï¼Œæœ€åé€šè¿‡ä¸“å®¶æ¨¡å‹è¿­ä»£å’Œå¼ºåŒ–å­¦ä¹ è¿›è¡Œåè®­ç»ƒï¼Œä»¥æå‡æ¨¡å‹çš„æ™ºèƒ½å’Œæ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šGLM-4.5çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ··åˆä¸“å®¶æ¶æ„çš„è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹åœ¨å‚æ•°æ•°é‡è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œä¾ç„¶èƒ½å¤Ÿåœ¨å¤šä¸ªæ™ºèƒ½æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„å…¨å‚æ•°æ¨¡å‹æœ‰æœ¬è´¨åŒºåˆ«ï¼Œæ˜¾è‘—æé«˜äº†å‚æ•°åˆ©ç”¨ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒGLM-4.5é‡‡ç”¨äº†3550äº¿ä¸ªæ€»å‚æ•°å’Œ320äº¿ä¸ªæ¿€æ´»å‚æ•°çš„é…ç½®ï¼Œä¼˜åŒ–äº†æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥é€‚åº”æ··åˆä¸“å®¶çš„éœ€æ±‚ã€‚æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ çš„å¼•å…¥è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

GLM-4.5åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¼˜å¼‚çš„æˆç»©ï¼Œç‰¹åˆ«æ˜¯åœ¨TAU-Benchä¸Šå¾—åˆ†70.1%ï¼Œåœ¨AIME 24ä¸Šå¾—åˆ†91.0%ï¼Œåœ¨SWE-bench Verifiedä¸Šå¾—åˆ†64.2%ã€‚ç›¸æ¯”äºå…¶ä»–å¤§å‹æ¨¡å‹ï¼ŒGLM-4.5ä»¥æ›´å°‘çš„å‚æ•°æ•°é‡å®ç°äº†æ›´é«˜çš„æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ™ºèƒ½æ¨ç†ä»»åŠ¡ä¸­çš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GLM-4.5åœ¨æ™ºèƒ½æ¨ç†å’Œç¼–ç ä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿæ”¯æŒè‡ªç„¶è¯­è¨€å¤„ç†ã€ä»£ç ç”Ÿæˆã€æ™ºèƒ½é—®ç­”ç­‰é¢†åŸŸã€‚å…¶é«˜æ•ˆçš„å‚æ•°åˆ©ç”¨ç‡å’Œå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­å…·å¤‡æ˜¾è‘—çš„ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½AIç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at https://github.com/zai-org/GLM-4.5.

