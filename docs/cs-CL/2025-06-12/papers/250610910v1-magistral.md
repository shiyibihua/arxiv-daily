---
layout: default
title: Magistral
---

# Magistral

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10910" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10910v1</a>
  <a href="https://arxiv.org/pdf/2506.10910.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10910v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10910v1', 'Magistral')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mistral-AI, :, Abhinav Rastogi, Albert Q. Jiang, Andy Lo, Gabrielle Berrada, Guillaume Lample, Jason Rute, Joep Barmentlo, Karmesh Yadav, Kartik Khandelwal, Khyathi Raghavi Chandu, LÃ©onard Blier, Lucile Saulnier, Matthieu Dinot, Maxime Darrin, Neha Gupta, Roman Soletskyi, Sagar Vaze, Teven Le Scao, Yihan Wang, Adam Yang, Alexander H. Liu, Alexandre Sablayrolles, AmÃ©lie HÃ©liou, AmÃ©lie Martin, Andy Ehrenberg, Anmol Agarwal, Antoine Roux, Arthur Darcet, Arthur Mensch, Baptiste Bout, Baptiste RoziÃ¨re, Baudouin De Monicault, Chris Bamford, Christian Wallenwein, Christophe Renaudin, ClÃ©mence Lanfranchi, Darius Dabert, Devon Mizelle, Diego de las Casas, Elliot Chane-Sane, Emilien Fugier, Emma Bou Hanna, Gauthier Delerce, Gauthier Guinet, Georgii Novikov, Guillaume Martin, Himanshu Jaju, Jan Ludziejewski, Jean-Hadrien Chabran, Jean-Malo Delignon, Joachim Studnia, Jonas Amar, Josselin Somerville Roberts, Julien Denize, Karan Saxena, Kush Jain, Lingxiao Zhao, Louis Martin, Luyu Gao, LÃ©lio Renard Lavaud, Marie Pellat, Mathilde Guillaumin, Mathis Felardos, Maximilian Augustin, MickaÃ«l Seznec, Nikhil Raghuraman, Olivier Duchenne, Patricia Wang, Patrick von Platen, Patryk Saffer, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Pavankumar Reddy Muddireddy, PhilomÃ¨ne Chagniot, Pierre Stock, Pravesh Agrawal, Romain Sauvestre, RÃ©mi Delacourt, Sanchit Gandhi, Sandeep Subramanian, Shashwat Dalal, Siddharth Gandhi, Soham Ghosh, Srijan Mishra, Sumukh Aithal, Szymon Antoniak, Thibault Schueller, Thibaut Lavril, Thomas Robert, Thomas Wang, TimothÃ©e Lacroix, Valeriia Nemychnikova, Victor Paltz, Virgile Richard, Wen-Ding Li, William Marshall, Xuanyu Zhang, Yunhao Tang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMagistralä»¥å®ç°å¤§è§„æ¨¡å¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æ¨ç†æ¨¡å‹` `å¤šæ¨¡æ€ç†è§£` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹è®­ç»ƒ` `è‡ªä¸‹è€Œä¸Šæ–¹æ³•` `æ™ºèƒ½åŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¾€å¾€ä¾èµ–äºå…ˆå‰æ¨¡å‹çš„å®ç°å’Œè½¨è¿¹ï¼Œç¼ºä¹è‡ªä¸»æ„å»ºçš„èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œå®Œå…¨ä¾èµ–äºè‡ªèº«æ¨¡å‹å’ŒåŸºç¡€è®¾æ–½è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ–‡æœ¬æ•°æ®ä¸Šçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒèƒ½å¤Ÿä¿æŒæˆ–æå‡å¤šæ¨¡æ€ç†è§£å’ŒæŒ‡ä»¤è·Ÿéšèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†Magistralï¼Œè¿™æ˜¯Mistralçš„é¦–ä¸ªæ¨ç†æ¨¡å‹åŠå…¶å¯æ‰©å±•çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®¡é“ã€‚ä¸ä¾èµ–ç°æœ‰å®ç°å’Œä»å…ˆå‰æ¨¡å‹ä¸­æå–çš„RLè½¨è¿¹ä¸åŒï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œå®Œå…¨ä¾èµ–äºæˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹å’ŒåŸºç¡€è®¾æ–½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€ç§å †æ ˆï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿæ¢ç´¢çº¯RLè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„æé™ï¼Œæå‡ºäº†ä¸€ç§ç®€å•çš„æ–¹æ³•æ¥å¼ºåˆ¶æ¨¡å‹çš„æ¨ç†è¯­è¨€ï¼Œå¹¶è¡¨æ˜ä»…åœ¨æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œçš„RLè®­ç»ƒèƒ½å¤Ÿä¿æŒå¤§éƒ¨åˆ†åˆå§‹æ£€æŸ¥ç‚¹çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å‘ç°ï¼Œæ–‡æœ¬ä¸Šçš„RLè®­ç»ƒä¿æŒæˆ–æ”¹å–„äº†å¤šæ¨¡æ€ç†è§£ã€æŒ‡ä»¤è·Ÿéšå’ŒåŠŸèƒ½è°ƒç”¨ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨Mistral Medium 3åŸºç¡€ä¸Šä»…é€šè¿‡RLè®­ç»ƒçš„Magistral Mediumï¼Œå¹¶å¼€æºäº†Magistral Smallï¼ˆApache 2.0ï¼‰ï¼Œå…¶ä¸­è¿›ä¸€æ­¥åŒ…å«äº†æ¥è‡ªMagistral Mediumçš„å†·å¯åŠ¨æ•°æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¯¹å…ˆå‰æ¨¡å‹ä¾èµ–çš„é—®é¢˜ï¼Œæ¢ç´¢å¦‚ä½•é€šè¿‡è‡ªä¸»æ„å»ºçš„æ¨¡å‹è¿›è¡Œæœ‰æ•ˆçš„æ¨ç†è®­ç»ƒã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•å……åˆ†åˆ©ç”¨æ–°æ¨¡å‹çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨è‡ªä¸‹è€Œä¸Šçš„æ–¹æ³•ï¼Œå®Œå…¨ä¾èµ–è‡ªèº«çš„æ¨¡å‹å’ŒåŸºç¡€è®¾æ–½è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä»¥æ¢ç´¢çº¯RLè®­ç»ƒçš„æé™ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨æ²¡æœ‰å¤–éƒ¨ä¾èµ–çš„æƒ…å†µä¸‹è¿›è¡Œæ¨ç†èƒ½åŠ›çš„æå‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡è‡ªæœ‰æ•°æ®é›†è¿›è¡Œå†·å¯åŠ¨ï¼Œç„¶ååœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæœ€åè¯„ä¼°æ¨¡å‹åœ¨å¤šæ¨¡æ€ç†è§£å’ŒæŒ‡ä»¤è·Ÿéšç­‰ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„è®­ç»ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ–‡æœ¬æ•°æ®ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä¿æŒæˆ–æå‡æ¨¡å‹çš„èƒ½åŠ›ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå…ˆå‰æ¨¡å‹çš„è½¨è¿¹æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥æ”¯æŒå¤šæ¨¡æ€æ•°æ®çš„å¤„ç†ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMagistralåœ¨å¤šæ¨¡æ€ç†è§£å’ŒæŒ‡ä»¤è·Ÿéšä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä¿æŒæˆ–æå‡äº†åˆå§‹æ¨¡å‹çš„èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œæ–‡æœ¬æ•°æ®ä¸Šçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒä½¿å¾—æ¨¡å‹åœ¨è¿™äº›ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡å¹…åº¦æ˜¾è‘—ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½åŠ©æ‰‹ã€æ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒMagistralå¯ä»¥åœ¨å¤æ‚ä»»åŠ¡ä¸­æä¾›æ›´å‡†ç¡®çš„å“åº”ï¼Œå¢å¼ºç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Magistral, Mistral's first reasoning model and our own scalable reinforcement learning (RL) pipeline. Instead of relying on existing implementations and RL traces distilled from prior models, we follow a ground up approach, relying solely on our own models and infrastructure. Notably, we demonstrate a stack that enabled us to explore the limits of pure RL training of LLMs, present a simple method to force the reasoning language of the model, and show that RL on text data alone maintains most of the initial checkpoint's capabilities. We find that RL on text maintains or improves multimodal understanding, instruction following and function calling. We present Magistral Medium, trained for reasoning on top of Mistral Medium 3 with RL alone, and we open-source Magistral Small (Apache 2.0) which further includes cold-start data from Magistral Medium.

