---
layout: default
title: The Biased Samaritan: LLM biases in Perceived Kindness
---

# The Biased Samaritan: LLM biases in Perceived Kindness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11361" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11361v1</a>
  <a href="https://arxiv.org/pdf/2506.11361.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11361v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11361v1', 'The Biased Samaritan: LLM biases in Perceived Kindness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jack H Fagan, Ruhaan Juyaal, Amy Yue-Ming Yu, Siya Pun

**åˆ†ç±»**: cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ–¹æ³•è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åè§è¯„ä¼°` `é“å¾·è¯„ä¼°` `ç”ŸæˆAI` `ç¤¾ä¼šç§‘å­¦` `AIä¼¦ç†` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹çš„åè§æ—¶ç¼ºä¹å®šé‡åˆ†æï¼Œéš¾ä»¥æ˜ç¡®ä¸åŒäººå£ç‰¹å¾çš„å½±å“ã€‚
2. æœ¬æ–‡é€šè¿‡è®¾è®¡ç‰¹å®šçš„é“å¾·è¯„ä¼°ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§å®šé‡è¯„ä¼°LLMåè§çš„æ–°æ–¹æ³•ï¼Œå…³æ³¨ä¸åŒæ€§åˆ«ã€ç§æ—å’Œå¹´é¾„çš„è¡¨ç°å·®å¼‚ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹æ™®éå°†åŸºçº¿äººå£è§†ä¸ºç™½äººç”·æ€§ï¼Œè€ŒéåŸºçº¿äººå£åœ¨å¹²é¢„æ„æ„¿ä¸Šæ›´ä¸ºç§¯æï¼Œæ­ç¤ºäº†åè§çš„å¤æ‚æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œç†è§£å’Œç¼“è§£å…¶åè§é—®é¢˜ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œé€šè¿‡æç¤ºæ¨¡å‹è¯„ä¼°é“å¾·æ‚£è€…çš„å¹²é¢„æ„æ„¿ï¼Œå®šé‡è¯„ä¼°ä¸åŒç”ŸæˆAIæ¨¡å‹åœ¨æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰æ–¹é¢çš„åè§ã€‚ä¸ç°æœ‰ç ”ç©¶ä¸åŒï¼Œæˆ‘ä»¬æ—¨åœ¨ç¡®å®šå„ç§å•†ä¸šæ¨¡å‹çš„åŸºçº¿äººå£ç‰¹å¾åŠå…¶ä¸å…¶ä»–äººå£ç‰¹å¾ä¹‹é—´çš„å…³ç³»ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ¨¡å‹æ™®éå°†åŸºçº¿äººå£è§†ä¸ºç™½äººä¸­å¹´æˆ–å¹´è½»ç”·æ€§ï¼Œä½†éåŸºçº¿äººå£åœ¨å¸®åŠ©æ„æ„¿ä¸Šæ™®éé«˜äºåŸºçº¿äººå£ã€‚è¿™é¡¹ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„åè§å®¢è§‚è¯„ä¼°æä¾›äº†åŸºç¡€ï¼Œå¸®åŠ©ç”¨æˆ·æˆ–å¼€å‘è€…åœ¨LLMè¾“å‡ºæˆ–æœªæ¥æ¨¡å‹è®­ç»ƒä¸­è€ƒè™‘è¿™äº›åè§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰æ–¹é¢çš„åè§è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹å¯¹åè§çš„å®šé‡åˆ†æï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œç†è§£ä¸åŒäººå£ç‰¹å¾çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬é€šè¿‡è®¾è®¡é“å¾·è¯„ä¼°ä»»åŠ¡ï¼Œæç¤ºæ¨¡å‹è¯„ä¼°é“å¾·æ‚£è€…çš„å¹²é¢„æ„æ„¿ï¼Œä»è€Œå®šé‡åˆ†æä¸åŒLLMsåœ¨å„äººå£ç‰¹å¾ä¸Šçš„åè§ã€‚è¿™ç§æ–¹æ³•ä½¿å¾—åè§çš„è¯„ä¼°æ›´åŠ ç³»ç»Ÿå’Œå®¢è§‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹é€‰æ‹©ã€é“å¾·è¯„ä¼°ä»»åŠ¡è®¾è®¡å’Œç»“æœåˆ†æã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹çš„åŸºçº¿äººå£ç‰¹å¾è¯†åˆ«å’ŒéåŸºçº¿äººå£ç‰¹å¾çš„æ¯”è¾ƒåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsçš„åè§ï¼Œæ˜ç¡®åŒºåˆ†åŸºçº¿äººå£ä¸éåŸºçº¿äººå£çš„å¹²é¢„æ„æ„¿ï¼Œæ­ç¤ºäº†åè§çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç‰¹å®šçš„é“å¾·è¯„ä¼°ä»»åŠ¡ï¼Œé‡‡ç”¨äº†å¤šç§ç”ŸæˆAIæ¨¡å‹ï¼Œå¹¶é€šè¿‡å®šé‡æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹çš„åè§ç¨‹åº¦ï¼Œç¡®ä¿äº†å®éªŒçš„å¯é‡å¤æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹æ™®éå°†åŸºçº¿äººå£è§†ä¸ºç™½äººä¸­å¹´ç”·æ€§ï¼Œè€ŒéåŸºçº¿äººå£åœ¨å¹²é¢„æ„æ„¿ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„ç§¯ææ€§ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†LLMsåœ¨å¤„ç†ä¸åŒäººå£ç‰¹å¾æ—¶çš„åè§ç¨‹åº¦ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶å’Œåº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIä¼¦ç†ã€ç¤¾ä¼šç§‘å­¦ç ”ç©¶å’Œäººæœºäº¤äº’è®¾è®¡ã€‚é€šè¿‡ç†è§£å’Œè¯„ä¼°LLMsçš„åè§ï¼Œå¼€å‘è€…å¯ä»¥åœ¨æ¨¡å‹è®­ç»ƒå’Œåº”ç”¨ä¸­æ›´å¥½åœ°è€ƒè™‘è¿™äº›åè§ï¼Œä»è€Œæé«˜AIç³»ç»Ÿçš„å…¬å¹³æ€§å’Œé€æ˜åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Large Language Models (LLMs) have become ubiquitous in many fields, understanding and mitigating LLM biases is an ongoing issue. This paper provides a novel method for evaluating the demographic biases of various generative AI models. By prompting models to assess a moral patient's willingness to intervene constructively, we aim to quantitatively evaluate different LLMs' biases towards various genders, races, and ages. Our work differs from existing work by aiming to determine the baseline demographic identities for various commercial models and the relationship between the baseline and other demographics. We strive to understand if these biases are positive, neutral, or negative, and the strength of these biases. This paper can contribute to the objective assessment of bias in Large Language Models and give the user or developer the power to account for these biases in LLM output or in training future LLMs. Our analysis suggested two key findings: that models view the baseline demographic as a white middle-aged or young adult male; however, a general trend across models suggested that non-baseline demographics are more willing to help than the baseline. These methodologies allowed us to distinguish these two biases that are often tangled together.

