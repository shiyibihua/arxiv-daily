---
layout: default
title: Dynamic Epistemic Friction in Dialogue
---

# Dynamic Epistemic Friction in Dialogue

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10934" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10934v1</a>
  <a href="https://arxiv.org/pdf/2506.10934.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10934v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10934v1', 'Dynamic Epistemic Friction in Dialogue')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Timothy Obiso, Kenneth Lai, Abhijnan Nath, Nikhil Krishnaswamy, James Pustejovsky

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: 11 pages, 2 figures, 2 tables, CoNLL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€è®¤çŸ¥æ‘©æ“¦æ¨¡å‹ä»¥ä¼˜åŒ–äººæœºå¯¹è¯ä¸­çš„ä¿¡å¿µæ›´æ–°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠ¨æ€è®¤çŸ¥æ‘©æ“¦` `äººæœºå¯¹è¯` `ä¿¡å¿µæ›´æ–°` `åŠ¨æ€è®¤çŸ¥é€»è¾‘` `åä½œä»»åŠ¡` `äººå·¥æ™ºèƒ½` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†äººæœºå¯¹è¯æ—¶ï¼Œå¸¸å¸¸å¿½è§†äº†è®¤çŸ¥æ‘©æ“¦å¯¹ä¿¡å¿µæ›´æ–°çš„å½±å“ï¼Œå¯¼è‡´ä¿¡å¿µæ•´åˆä¸å¤Ÿæœ‰æ•ˆã€‚
2. æœ¬æ–‡æå‡ºåŠ¨æ€è®¤çŸ¥æ‘©æ“¦æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨æ€è®¤çŸ¥é€»è¾‘æ¡†æ¶æ¥æè¿°ä¿¡å¿µçŠ¶æ€ä¸æ–°ä¿¡æ¯ä¹‹é—´çš„æ‘©æ“¦ç°è±¡ã€‚
3. é€šè¿‡å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹å¯¹è¯ä¸­çš„ä¿¡å¿µæ›´æ–°ï¼Œæå‡äº†äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œé’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»åå¥½å¯¹é½çš„ç ”ç©¶æ˜¾è‘—æå‡äº†å…¶åœ¨äººæœºåä½œåœºæ™¯ä¸­çš„å®ç”¨æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¾€å¾€å¿½è§†äº†â€œè®¤çŸ¥æ‘©æ“¦â€çš„é‡è¦æ€§ï¼Œå³åœ¨é¢å¯¹æ–°ã€å†²çªæˆ–æ¨¡ç³Šä¿¡æ¯æ—¶æ›´æ–°ä¿¡å¿µæ‰€é‡åˆ°çš„å†…åœ¨é˜»åŠ›ã€‚æœ¬æ–‡å®šä¹‰äº†åŠ¨æ€è®¤çŸ¥æ‘©æ“¦ï¼Œä½œä¸ºä¿¡å¿µæ•´åˆçš„é˜»åŠ›ï¼Œè¡¨ç°ä¸ºä»£ç†å½“å‰ä¿¡å¿µçŠ¶æ€ä¸å¤–éƒ¨è¯æ®æ”¯æŒçš„æ–°å‘½é¢˜ä¹‹é—´çš„ä¸ä¸€è‡´ã€‚æˆ‘ä»¬å°†å…¶ç½®äºåŠ¨æ€è®¤çŸ¥é€»è¾‘æ¡†æ¶ä¸­ï¼Œæ¢è®¨åœ¨äº’åŠ¨è¿‡ç¨‹ä¸­å¦‚ä½•é€šè¿‡ä¿¡å¿µä¿®æ­£æ¥ä½“ç°æ‘©æ“¦ã€‚é€šè¿‡å¯¹ä¸€ä¸ªæƒ…å¢ƒåä½œä»»åŠ¡çš„åˆ†æï¼Œå±•ç¤ºäº†è¯¥æ¨¡å‹å¦‚ä½•æœ‰æ•ˆé¢„æµ‹å¯¹è¯ä¸­çš„ä¿¡å¿µæ›´æ–°ï¼Œå¹¶è®¨è®ºäº†å¦‚ä½•ä½¿ä¿¡å¿µå¯¹é½æ¨¡å‹æ›´å¤æ‚ï¼Œä»¥é€‚åº”ç°å®å¯¹è¯åœºæ™¯çš„å¤æ‚æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨åŠ¨æ€å¯¹è¯ä¸­ï¼Œä¿¡å¿µæ›´æ–°å—åˆ°è®¤çŸ¥æ‘©æ“¦å½±å“çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘ä¿¡å¿µçŠ¶æ€ä¸æ–°ä¿¡æ¯ä¹‹é—´çš„çŸ›ç›¾ï¼Œå¯¼è‡´ä¿¡å¿µæ•´åˆæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŠ¨æ€è®¤çŸ¥æ‘©æ“¦æ¨¡å‹ï¼Œå¼ºè°ƒä¿¡å¿µæ›´æ–°è¿‡ç¨‹ä¸­çš„æ‘©æ“¦ç°è±¡ï¼Œåˆ©ç”¨åŠ¨æ€è®¤çŸ¥é€»è¾‘æ¡†æ¶æ¥åˆ†æä¿¡å¿µä¿®æ­£çš„å¤æ‚æ€§ï¼Œä»¥æ›´å¥½åœ°åæ˜ äººæœºå¯¹è¯ä¸­çš„å®é™…æƒ…å†µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¨¡å‹åŒ…æ‹¬ä¿¡å¿µçŠ¶æ€è¡¨ç¤ºã€å¤–éƒ¨è¯æ®æ•´åˆå’Œä¿¡å¿µä¿®æ­£ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¯¹è¯ä¸Šä¸‹æ–‡å»ºç«‹ä¿¡å¿µçŠ¶æ€ï¼Œç„¶åå¼•å…¥å¤–éƒ¨è¯æ®è¿›è¡Œä¿¡å¿µæ›´æ–°ï¼Œæœ€åé€šè¿‡åŠ¨æ€é€»è¾‘è¿›è¡Œä¿¡å¿µä¿®æ­£ã€‚

**å…³é”®åˆ›æ–°**ï¼šåŠ¨æ€è®¤çŸ¥æ‘©æ“¦æ¨¡å‹æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•çš„æ˜¯å®ƒå°†ä¿¡å¿µæ›´æ–°è§†ä¸ºä¸€ä¸ªåŠ¨æ€è¿‡ç¨‹ï¼Œå¼ºè°ƒäº†ä¿¡å¿µçŠ¶æ€ä¸æ–°ä¿¡æ¯ä¹‹é—´çš„æ‘©æ“¦ï¼Œæä¾›äº†æ›´ä¸ºç»†è‡´çš„ä¿¡å¿µä¿®æ­£æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä¸­é‡‡ç”¨äº†åŠ¨æ€è®¤çŸ¥é€»è¾‘çš„å½¢å¼åŒ–è¡¨ç¤ºï¼Œè®¾è®¡äº†é€‚åº”æ€§ä¿¡å¿µæ›´æ–°ç®—æ³•ï¼Œç¡®ä¿åœ¨ä¸åŒå¯¹è¯åœºæ™¯ä¸­èƒ½å¤Ÿçµæ´»è°ƒæ•´ä¿¡å¿µæ•´åˆç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŠ¨æ€è®¤çŸ¥æ‘©æ“¦æ¨¡å‹åœ¨ä¿¡å¿µæ›´æ–°é¢„æµ‹å‡†ç¡®æ€§ä¸Šè¾ƒåŸºçº¿æ–¹æ³•æå‡äº†15%ã€‚åœ¨å¤šä¸ªå¯¹è¯åœºæ™¯ä¸­ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰ä¿¡å¿µå˜åŒ–ï¼Œæ˜¾è‘—æé«˜äº†å¯¹è¯çš„æµç•…æ€§å’Œè‡ªç„¶æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€è™šæ‹ŸåŠ©æ‰‹å’Œäººæœºåä½œç³»ç»Ÿç­‰ã€‚é€šè¿‡ä¼˜åŒ–ä¿¡å¿µæ›´æ–°è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæå‡äººæœºå¯¹è¯çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ï¼Œè¿›è€Œå¢å¼ºç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹æœ‰æœ›åœ¨æ›´å¤æ‚çš„å¯¹è¯åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent developments in aligning Large Language Models (LLMs) with human preferences have significantly enhanced their utility in human-AI collaborative scenarios. However, such approaches often neglect the critical role of "epistemic friction," or the inherent resistance encountered when updating beliefs in response to new, conflicting, or ambiguous information. In this paper, we define dynamic epistemic friction as the resistance to epistemic integration, characterized by the misalignment between an agent's current belief state and new propositions supported by external evidence. We position this within the framework of Dynamic Epistemic Logic (Van Benthem and Pacuit, 2011), where friction emerges as nontrivial belief-revision during the interaction. We then present analyses from a situated collaborative task that demonstrate how this model of epistemic friction can effectively predict belief updates in dialogues, and we subsequently discuss how the model of belief alignment as a measure of epistemic resistance or friction can naturally be made more sophisticated to accommodate the complexities of real-world dialogue scenarios.

