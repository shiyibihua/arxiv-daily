---
layout: default
title: ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization
---

# ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10822" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10822v1</a>
  <a href="https://arxiv.org/pdf/2506.10822.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10822v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10822v1', 'ReCUT: Balancing Reasoning Length and Accuracy in LLMs via Stepwise Trails and Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhensheng Jin, Xinze Li, Yifan Ji, Chunyi Peng, Zhenghao Liu, Qi Shi, Yukun Yan, Shuo Wang, Furong Peng, Ge Yu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/NEUIR/ReCUT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºReCUTä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†é•¿åº¦ä¸å‡†ç¡®æ€§å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†ä¼˜åŒ–` `é“¾å¼æ€ç»´` `é€æ­¥è¯•éªŒ` `é•¿çŸ­åˆ‡æ¢é‡‡æ ·` `æ•°å­¦æ¨ç†` `æ¨¡å‹é›†æˆ` `åå¥½å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é“¾å¼æ€ç»´æç¤ºæ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­å®¹æ˜“å¯¼è‡´å†—é•¿å’Œé‡å¤çš„æ¨ç†è½¨è¿¹ï¼Œå½±å“æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„ReCUTæ–¹æ³•é€šè¿‡é€æ­¥æ¢ç´¢å’Œé•¿çŸ­åˆ‡æ¢é‡‡æ ·ç­–ç•¥ï¼Œä¼˜åŒ–æ¨ç†è·¯å¾„çš„ç”Ÿæˆï¼Œå¹³è¡¡å‡†ç¡®æ€§ä¸é•¿åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReCUTåœ¨å¤šä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šå°†æ¨ç†é•¿åº¦å‡å°‘çº¦30-50%ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡äº†æ¨ç†å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºæ³•æ˜¾è‘—æå‡äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¸¸å¸¸å¯¼è‡´è¿‡åº¦æ€è€ƒï¼Œç”Ÿæˆå†—é•¿æˆ–é‡å¤çš„æ¨ç†è½¨è¿¹ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡ç­–åˆ’å¤šä¸ªæ¨ç†é“¾æ¥è®­ç»ƒLLMsï¼Œä½†æ•ˆæœå—é™äºç”Ÿæˆæ•°æ®çš„è´¨é‡ï¼Œä¸”æ˜“äºè¿‡æ‹Ÿåˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†æ¨ç†å‹ç¼©é€šè¿‡é€æ­¥è¯•éªŒï¼ˆReCUTï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨å¹³è¡¡æ¨ç†è½¨è¿¹çš„å‡†ç¡®æ€§å’Œé•¿åº¦ã€‚å…·ä½“è€Œè¨€ï¼ŒReCUTé‡‡ç”¨é€æ­¥æ¢ç´¢æœºåˆ¶å’Œé•¿çŸ­åˆ‡æ¢é‡‡æ ·ç­–ç•¥ï¼Œä½¿LLMsèƒ½å¤Ÿé€æ­¥ç”Ÿæˆå¤šæ ·çš„æ¨ç†è·¯å¾„ã€‚è¿™äº›è·¯å¾„ç»è¿‡è¯„ä¼°åç”¨äºæ„å»ºåå¥½å¯¹ï¼Œä»¥è®­ç»ƒä¸¤ä¸ªä¸“é—¨çš„æ¨¡å‹ï¼ˆGemini LLMsï¼‰â€”â€”ä¸€ä¸ªä¼˜åŒ–æ¨ç†å‡†ç¡®æ€§ï¼Œå¦ä¸€ä¸ªä¼˜åŒ–çŸ­æ¨ç†ã€‚æœ€ç»ˆé€šè¿‡æ’å€¼è¿™ä¸¤ä¸ªæ¨¡å‹çš„å‚æ•°è·å¾—é›†æˆæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReCUTåœ¨å¤šä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†å’ŒåŸºç¡€æ¨¡å‹ä¸Šæ˜¾è‘—å‡å°‘æ¨ç†é•¿åº¦çº¦30-50%ï¼ŒåŒæ—¶ä¿æŒæˆ–æé«˜æ¨ç†å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿå†—é•¿å’Œé‡å¤è½¨è¿¹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤šä¸ªæ¨ç†é“¾çš„ç­–åˆ’ï¼Œæ•ˆæœå—é™äºç”Ÿæˆæ•°æ®è´¨é‡ï¼Œä¸”æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReCUTé€šè¿‡é€æ­¥è¯•éªŒçš„æ–¹å¼ç”Ÿæˆå¤šæ ·åŒ–çš„æ¨ç†è·¯å¾„ï¼Œå¹¶åˆ©ç”¨é•¿çŸ­åˆ‡æ¢é‡‡æ ·ç­–ç•¥æ¥ä¼˜åŒ–æ¨ç†çš„å‡†ç¡®æ€§ä¸é•¿åº¦ï¼Œæ—¨åœ¨å®ç°æ›´é«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReCUTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬é€æ­¥æ¢ç´¢æœºåˆ¶å’Œåå¥½å¯¹æ„å»ºæ¨¡å—ã€‚é¦–å…ˆï¼Œæ¨¡å‹ç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„ï¼Œç„¶åè¯„ä¼°è¿™äº›è·¯å¾„çš„è´¨é‡ï¼Œæœ€åæ„å»ºåå¥½å¯¹ä»¥è®­ç»ƒä¸¤ä¸ªä¼˜åŒ–æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šReCUTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶é€æ­¥æ¢ç´¢æœºåˆ¶å’Œé•¿çŸ­åˆ‡æ¢é‡‡æ ·ç­–ç•¥ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€æ¨ç†é“¾ç”Ÿæˆæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ¨ç†é•¿åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å‡†ç¡®æ€§å’Œæ¨ç†é•¿åº¦ï¼ŒåŒæ—¶è®¾è®¡äº†ä¸¤ä¸ªä¸“é—¨çš„Gemini LLMsæ¨¡å‹ï¼Œåˆ†åˆ«ä¼˜åŒ–æ¨ç†çš„å‡†ç¡®æ€§å’Œç®€æ´æ€§ã€‚æ¨¡å‹å‚æ•°çš„æ’å€¼æ–¹æ³•ä¹Ÿä¸ºæœ€ç»ˆé›†æˆæ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒReCUTåœ¨å¤šä¸ªæ•°å­¦æ¨ç†æ•°æ®é›†ä¸Šå°†æ¨ç†é•¿åº¦å‡å°‘äº†çº¦30-50%ï¼ŒåŒæ—¶åœ¨å‡†ç¡®æ€§ä¸Šä¸å¤šç§åŸºçº¿æ¨¡å‹ç›¸æ¯”ä¿æŒæˆ–æå‡äº†æ€§èƒ½ã€‚è¿™ä¸€æ˜¾è‘—çš„æ”¹è¿›å±•ç¤ºäº†ReCUTåœ¨æ¨ç†æ•ˆç‡å’Œæ•ˆæœä¸Šçš„åŒé‡ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReCUTæ–¹æ³•åœ¨æ•™è‚²ã€è‡ªåŠ¨åŒ–é—®ç­”å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼Œè¯¥æ–¹æ³•å¯ä»¥æé«˜ç”¨æˆ·ä½“éªŒï¼Œå‡å°‘è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œå¹¶åœ¨å¤æ‚é—®é¢˜æ±‚è§£ä¸­æä¾›æ›´é«˜æ•ˆçš„æ”¯æŒã€‚æœªæ¥ï¼ŒReCUTçš„æ€è·¯ä¹Ÿå¯èƒ½è¢«åº”ç”¨äºå…¶ä»–ç±»å‹çš„ç”Ÿæˆæ¨¡å‹å’Œæ¨ç†ä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in Chain-of-Thought (CoT) prompting have substantially improved the reasoning capabilities of Large Language Models (LLMs). However, these methods often suffer from overthinking, leading to unnecessarily lengthy or redundant reasoning traces. Existing approaches attempt to mitigate this issue through curating multiple reasoning chains for training LLMs, but their effectiveness is often constrained by the quality of the generated data and prone to overfitting. To address the challenge, we propose Reasoning Compression ThroUgh Stepwise Trials (ReCUT), a novel method aimed at balancing the accuracy and length of reasoning trajectory. Specifically, ReCUT employs a stepwise exploration mechanism and a long-short switched sampling strategy, enabling LLMs to incrementally generate diverse reasoning paths. These paths are evaluated and used to construct preference pairs to train two specialized models (Gemini LLMs)-one optimized for reasoning accuracy, the other for shorter reasoning. A final integrated model is obtained by interpolating the parameters of these two models. Experimental results across multiple math reasoning datasets and backbone models demonstrate that ReCUT significantly reduces reasoning lengths by approximately 30-50%, while maintaining or improving reasoning accuracy compared to various baselines. All codes and data will be released via https://github.com/NEUIR/ReCUT.

