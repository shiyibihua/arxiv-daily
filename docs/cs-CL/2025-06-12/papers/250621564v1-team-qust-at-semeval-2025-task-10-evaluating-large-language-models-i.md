---
layout: default
title: Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing
---

# Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21564" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21564v1</a>
  <a href="https://arxiv.org/pdf/2506.21564.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21564v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21564v1', 'Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiyan Liu, Youzheng Liu, Taihang Wang, Xiaoman Xu, Yimin Wang, Ye Jiang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/warmth27/SemEval2025_Task7)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸‰é˜¶æ®µæ£€ç´¢æ¡†æ¶ä»¥ä¼˜åŒ–æ–°é—»å®ä½“æ¡†æ¶çš„å¤šç±»å¤šæ ‡ç­¾åˆ†ç±»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šç±»å¤šæ ‡ç­¾åˆ†ç±»` `æ–°é—»å®ä½“æ¡†æ¶` `äº‹å®æ ¸æŸ¥` `æ£€ç´¢æ¨¡å‹` `é‡æ’åº` `åŠ æƒæŠ•ç¥¨` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šç±»å¤šæ ‡ç­¾åˆ†ç±»æ–¹æ³•åœ¨å¤„ç†æ–°é—»å®ä½“æ¡†æ¶æ—¶é¢ä¸´æ£€ç´¢æ•ˆæœä¸ä½³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨äº‹å®æ ¸æŸ¥æ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸‰é˜¶æ®µæ£€ç´¢æ¡†æ¶ï¼Œé€šè¿‡å€™é€‰æ£€ç´¢ã€é‡æ’åºå’ŒåŠ æƒæŠ•ç¥¨æ¥ä¼˜åŒ–æ£€ç´¢ç»“æœï¼Œæå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å•è¯­è½¨é“ä¸­æ’åç¬¬äº”ï¼Œåœ¨è·¨è¯­è½¨é“ä¸­æ’åç¬¬ä¸ƒï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æè¿°äº†QUST_NLPåœ¨SemEval-2025ä»»åŠ¡7ä¸­çš„å‚ä¸ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸“é—¨ä¸ºäº‹å®æ ¸æŸ¥å£°æ˜æ£€ç´¢è®¾è®¡çš„ä¸‰é˜¶æ®µæ£€ç´¢æ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¯„ä¼°äº†å¤šç§æ£€ç´¢æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶é€‰æ‹©äº†æœ€ä½³å€™é€‰æ£€ç´¢æ¨¡å‹ã€‚æ¥ç€ï¼Œé‡‡ç”¨å¤šç§é‡æ’åºæ¨¡å‹æ¥å¢å¼ºå€™é€‰ç»“æœï¼Œæ¯ä¸ªæ¨¡å‹é€‰æ‹©å‰10ä¸ªç»“æœã€‚æœ€åï¼Œåˆ©ç”¨åŠ æƒæŠ•ç¥¨ç¡®å®šæœ€ç»ˆæ£€ç´¢ç»“æœã€‚æˆ‘ä»¬çš„æ–¹æ¡ˆåœ¨å•è¯­è½¨é“ä¸­è·å¾—ç¬¬äº”åï¼Œåœ¨è·¨è¯­è½¨é“ä¸­è·å¾—ç¬¬ä¸ƒåã€‚æˆ‘ä»¬å·²åœ¨GitHubä¸Šå‘å¸ƒäº†ç³»ç»Ÿä»£ç ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–°é—»å®ä½“æ¡†æ¶ä¸­çš„å¤šç±»å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨äº‹å®æ ¸æŸ¥å£°æ˜æ£€ç´¢ä¸­æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´ä¿¡æ¯å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸‰é˜¶æ®µæ£€ç´¢æ¡†æ¶ï¼Œé¦–å…ˆé€‰æ‹©æœ€ä½³å€™é€‰æ£€ç´¢æ¨¡å‹ï¼Œç„¶åé€šè¿‡é‡æ’åºæ¨¡å‹ä¼˜åŒ–ç»“æœï¼Œæœ€åé€šè¿‡åŠ æƒæŠ•ç¥¨ç¡®å®šæœ€ç»ˆè¾“å‡ºï¼Œä»¥æé«˜æ£€ç´¢çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºå€™é€‰æ£€ç´¢ï¼Œè¯„ä¼°å¤šç§æ£€ç´¢æ¨¡å‹å¹¶é€‰æ‹©æœ€ä½³è€…ï¼›ç¬¬äºŒé˜¶æ®µä¸ºé‡æ’åºï¼Œåˆ©ç”¨å¤šä¸ªæ¨¡å‹å¯¹å€™é€‰ç»“æœè¿›è¡Œä¼˜åŒ–ï¼›ç¬¬ä¸‰é˜¶æ®µä¸ºåŠ æƒæŠ•ç¥¨ï¼Œç»¼åˆå„æ¨¡å‹ç»“æœç¡®å®šæœ€ç»ˆè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†åŠ æƒæŠ•ç¥¨æœºåˆ¶ï¼Œç»“åˆå¤šç§é‡æ’åºæ¨¡å‹çš„ç»“æœï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢çš„å‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿå•ä¸€æ¨¡å‹æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹é€‰æ‹©ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ€§èƒ½è¯„ä¼°é€‰æ‹©æœ€ä½³å€™é€‰æ¨¡å‹ï¼Œé‡æ’åºé˜¶æ®µé‡‡ç”¨å¤šç§æ¨¡å‹å¹¶é€‰å–Top-10ç»“æœï¼Œæœ€åé€šè¿‡åŠ æƒæŠ•ç¥¨æ•´åˆç»“æœï¼Œç¡®ä¿äº†è¾“å‡ºçš„å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬çš„ä¸‰é˜¶æ®µæ£€ç´¢æ¡†æ¶åœ¨å•è¯­è½¨é“ä¸­è·å¾—äº†ç¬¬äº”åï¼Œåœ¨è·¨è¯­è½¨é“ä¸­è·å¾—ç¬¬ä¸ƒåï¼Œå±•ç¤ºäº†ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹çš„æ˜¾è‘—æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»åª’ä½“ã€ç¤¾äº¤ç½‘ç»œå’Œä¿¡æ¯æ£€ç´¢ç³»ç»Ÿï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å‡†ç¡®åœ°è·å–äº‹å®ä¿¡æ¯ï¼Œæå‡ä¿¡æ¯æ£€ç´¢çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•è‡³å…¶ä»–ç±»å‹çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper describes the participation of QUST_NLP in the SemEval-2025 Task 7. We propose a three-stage retrieval framework specifically designed for fact-checked claim retrieval. Initially, we evaluate the performance of several retrieval models and select the one that yields the best results for candidate retrieval. Next, we employ multiple re-ranking models to enhance the candidate results, with each model selecting the Top-10 outcomes. In the final stage, we utilize weighted voting to determine the final retrieval outcomes. Our approach achieved 5th place in the monolingual track and 7th place in the crosslingual track. We release our system code at: https://github.com/warmth27/SemEval2025_Task7.

