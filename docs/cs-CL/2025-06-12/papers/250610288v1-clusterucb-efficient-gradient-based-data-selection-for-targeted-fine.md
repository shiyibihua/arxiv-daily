---
layout: default
title: ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs
---

# ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10288" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10288v1</a>
  <a href="https://arxiv.org/pdf/2506.10288.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10288v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10288v1', 'ClusterUCB: Efficient Gradient-Based Data Selection for Targeted Fine-Tuning of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zige Wang, Qi Zhu, Fei Mi, Minghui Xu, Ruochun Jin, Wenjing Yang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºClusterUCBä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒä¸­çš„æ•°æ®é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `æ•°æ®é€‰æ‹©` `èšç±»` `ä¸Šç½®ä¿¡ç•Œ` `å¤šè‡‚èµŒåšæœº` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ–¹æ³•åœ¨å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹æ—¶è®¡ç®—èµ„æºæ¶ˆè€—è¿‡å¤§ï¼Œéš¾ä»¥å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºClusterUCBæ¡†æ¶ï¼Œé€šè¿‡èšç±»å’Œæ”¹è¿›çš„UCBç®—æ³•é«˜æ•ˆé€‰æ‹©æ•°æ®æ ·æœ¬ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒClusterUCBåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„æ•ˆæœï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†è®¡ç®—æ¶ˆè€—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è¯­è¨€æ¨¡å‹çš„ç›‘ç£å¾®è°ƒä¸­ï¼ŒåŸºäºæ¢¯åº¦çš„æ•°æ®å½±å“è¿‘ä¼¼å·²è¢«ç”¨äºé€‰æ‹©æœ‰ç”¨çš„æ•°æ®æ ·æœ¬ã€‚ç„¶è€Œï¼Œå¾®è°ƒè¿‡ç¨‹ä¸­æ¢¯åº¦è®¡ç®—éœ€è¦æ¶ˆè€—è¿‡å¤šèµ„æºï¼Œéš¾ä»¥åœ¨å®é™…ä¸­åº”ç”¨ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„åŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ¡†æ¶ClusterUCBï¼Œç»“åˆäº†èšç±»å’Œæ”¹è¿›çš„ä¸Šç½®ä¿¡ç•Œï¼ˆUCBï¼‰ç®—æ³•ã€‚æˆ‘ä»¬é¦–å…ˆå¯¹è®­ç»ƒæ•°æ®æ± è¿›è¡Œèšç±»ï¼ŒåŸºäºç›¸ä¼¼æ¢¯åº¦ç‰¹å¾çš„æ•°æ®æ ·æœ¬å…·æœ‰ç›¸ä¼¼å½±å“çš„ç›´è§‰ï¼Œå°†è·¨ç°‡æ•°æ®é€‰æ‹©è§†ä¸ºå—é™è®¡ç®—é¢„ç®—åˆ†é…é—®é¢˜ï¼Œå¹¶å°†å…¶è§†ä¸ºå¤šè‡‚èµŒåšæœºé—®é¢˜ã€‚é€šè¿‡è®°å½•å†å²æ•°æ®å½±å“ä¿¡æ¯ï¼ŒClusterUCBåœ¨è¿­ä»£é‡‡æ ·è¿‡ç¨‹ä¸­ç›´æ¥ä¼°è®¡æ¯ä¸ªç°‡çš„åˆ†å¸ƒï¼Œå¹¶é‡‡ç”¨å†·å¯åŠ¨ç­–ç•¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒClusterUCBåœ¨è®¡ç®—æ¶ˆè€—å¤§å¹…é™ä½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿå®ç°ä¸åŸå§‹åŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ–¹æ³•ç›¸å½“çš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•é«˜æ•ˆé€‰æ‹©æœ‰ç”¨çš„æ•°æ®æ ·æœ¬ä»¥é™ä½è®¡ç®—èµ„æºæ¶ˆè€—çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è®¡ç®—æ¢¯åº¦æ—¶éœ€è¦å¤§é‡èµ„æºï¼Œå¯¼è‡´å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡èšç±»å°†è®­ç»ƒæ•°æ®æ± ä¸­çš„æ ·æœ¬åˆ†ç»„ï¼Œåˆ©ç”¨ç›¸ä¼¼æ ·æœ¬çš„æ¢¯åº¦ç‰¹å¾æ¥æ¨æµ‹å…¶å½±å“ï¼Œä»è€Œåœ¨å¤šè‡‚èµŒåšæœºæ¡†æ¶ä¸‹è¿›è¡Œæ•°æ®é€‰æ‹©ï¼Œä¼˜åŒ–è®¡ç®—é¢„ç®—çš„åˆ†é…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®èšç±»ã€å½±å“ä¼°è®¡å’Œæ•°æ®é€‰æ‹©ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹è®­ç»ƒæ•°æ®è¿›è¡Œèšç±»ï¼Œç„¶ååœ¨æ¯ä¸ªç°‡å†…è®°å½•å†å²å½±å“ä¿¡æ¯ï¼Œæœ€åé€šè¿‡æ”¹è¿›çš„UCBç®—æ³•è¿›è¡Œæ•°æ®é€‰æ‹©ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ•°æ®é€‰æ‹©é—®é¢˜è½¬åŒ–ä¸ºå¤šè‡‚èµŒåšæœºé—®é¢˜ï¼Œå¹¶é€šè¿‡èšç±»æ¥å‡å°‘è®¡ç®—å¤æ‚åº¦ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é€æ ·æœ¬æ¢¯åº¦è®¡ç®—æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å†·å¯åŠ¨ç­–ç•¥ä»¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼ŒåŒæ—¶åœ¨æ¯æ¬¡è¿­ä»£ä¸­è®°å½•å†å²æ•°æ®å½±å“ä¿¡æ¯ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°ä¼°è®¡æ¯ä¸ªç°‡çš„åˆ†å¸ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒClusterUCBåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­èƒ½å¤Ÿå®ç°ä¸ä¼ ç»ŸåŸºäºæ¢¯åº¦çš„æ•°æ®é€‰æ‹©æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼ŒåŒæ—¶è®¡ç®—æ¶ˆè€—å‡å°‘äº†æ˜¾è‘—çš„æ¯”ä¾‹ï¼Œå±•ç¤ºäº†å…¶åœ¨é«˜æ•ˆæ•°æ®é€‰æ‹©æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæ•ˆç‡ï¼Œé™ä½è®¡ç®—èµ„æºæ¶ˆè€—ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gradient-based data influence approximation has been leveraged to select useful data samples in the supervised fine-tuning of large language models. However, the computation of gradients throughout the fine-tuning process requires too many resources to be feasible in practice. In this paper, we propose an efficient gradient-based data selection framework with clustering and a modified Upper Confidence Bound (UCB) algorithm. Based on the intuition that data samples with similar gradient features will have similar influences, we first perform clustering on the training data pool. Then, we frame the inter-cluster data selection as a constrained computing budget allocation problem and consider it a multi-armed bandit problem. A modified UCB algorithm is leveraged to solve this problem. Specifically, during the iterative sampling process, historical data influence information is recorded to directly estimate the distributions of each cluster, and a cold start is adopted to balance exploration and exploitation. Experimental results on various benchmarks show that our proposed framework, ClusterUCB, can achieve comparable results to the original gradient-based data selection methods while greatly reducing computing consumption.

