---
layout: default
title: Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning
---

# Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25534" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25534v1</a>
  <a href="https://arxiv.org/pdf/2509.25534.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25534v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25534v1', 'Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhiling Ye, Yun Yue, Haowen Wang, Xudong Han, Jiadi Jiang, Cheng Wei, Lei Fan, Jiaxin Liang, Shuowen Zhang, Ji Li, Chunxiao Guo, Jian Wang, Peng Wei, Jinjie Gu

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªå¥–åŠ±çš„åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæå‡å¼€æ”¾å¼æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªå¥–åŠ±å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `å¼€æ”¾å¼æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `è§„åˆ™å¥–åŠ±` `HealthBench` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾å¼æ¨ç†è¯„ä¼°ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œéœ€è¦æ›´æœ‰æ•ˆçš„å¥–åŠ±ä¿¡å·ã€‚
2. è®ºæ–‡æå‡ºè‡ªå¥–åŠ±çš„åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨æ¨¡å‹è‡ªèº«ä½œä¸ºè¯„åˆ†å™¨ç”Ÿæˆå¥–åŠ±ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨HealthBenchæ•°æ®é›†ä¸Šè¶…è¶Šäº†GPT-5ï¼Œä¸”è®­ç»ƒèµ„æºéœ€æ±‚æ›´ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€æ”¾å¼è¯„ä¼°å¯¹äºåœ¨å®é™…ç¯å¢ƒä¸­éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹è‡³å…³é‡è¦ã€‚åœ¨ç ”ç©¶HealthBenchæ—¶ï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨æ¨¡å‹æœ¬èº«ä½œä¸ºè¯„åˆ†å™¨å¹¶ç”ŸæˆåŸºäºè§„åˆ™çš„å¥–åŠ±ä¿¡å·å¯ä»¥æ˜¾è‘—æé«˜æ¨ç†æ€§èƒ½ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè®­ç»ƒåçš„æ¨¡å‹ä¹Ÿæˆä¸ºäº†æ›´å¼ºå¤§çš„è¯„åˆ†å™¨ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç”¨äºå¼€æ”¾å¼æ¨ç†çš„è‡ªå¥–åŠ±çš„åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§æ¡†æ¶ï¼Œå¯ä»¥å®ç°æ›´å¿«ã€èµ„æºæ•ˆç‡æ›´é«˜çš„è®­ç»ƒï¼ŒåŒæ—¶è¶…è¶ŠåŸºçº¿ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨Qwen3-32Bä¸Šï¼Œä»…ä½¿ç”¨4000ä¸ªæ ·æœ¬çš„HealthBench Easyå­é›†è¿›è¡Œè®­ç»ƒå°±è¶³ä»¥è·å¾—ä¸€ä¸ªåœ¨HealthBench Hardä¸Šè¶…è¿‡GPT-5çš„æ¨¡å‹ã€‚åŠ å…¥å°‘é‡æ•™å¸ˆè¯„åˆ†çš„æ•°æ®å¯ä»¥è¿›ä¸€æ­¥æé«˜èƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¼€æ”¾å¼æ¨ç†ä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æ›´æœ‰æ•ˆåœ°è¿›è¡Œè¯„ä¼°å’Œè®­ç»ƒçš„é—®é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•ä¾èµ–äºäººå·¥æ ‡æ³¨æˆ–å¤æ‚çš„å¥–åŠ±å‡½æ•°è®¾è®¡ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ³›åŒ–ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è‡ªèº«çš„èƒ½åŠ›è¯„ä¼°ä¹Ÿå­˜åœ¨åå·®ï¼Œéš¾ä»¥æä¾›å‡†ç¡®çš„è®­ç»ƒä¿¡å·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„èƒ½åŠ›ï¼Œé€šè¿‡ç”ŸæˆåŸºäºè§„åˆ™çš„å¥–åŠ±ä¿¡å·æ¥è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚æ¨¡å‹æ—¢æ˜¯æ¨ç†è€…ï¼Œåˆæ˜¯è¯„åˆ†è€…ï¼Œå½¢æˆä¸€ä¸ªè‡ªå¥–åŠ±çš„é—­ç¯ã€‚è¿™ç§æ–¹å¼å¯ä»¥å‡å°‘å¯¹å¤–éƒ¨æ ‡æ³¨çš„ä¾èµ–ï¼Œå¹¶ä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–è‡ªèº«çš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¨ç†ç»“æœï¼›2) ä½¿ç”¨åŒä¸€æ¨¡å‹ä½œä¸ºè¯„åˆ†å™¨ï¼Œæ ¹æ®é¢„å®šä¹‰çš„è§„åˆ™ï¼ˆrubricï¼‰å¯¹æ¨ç†ç»“æœè¿›è¡Œè¯„ä¼°ï¼Œç”Ÿæˆå¥–åŠ±ä¿¡å·ï¼›3) ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ ¹æ®å¥–åŠ±ä¿¡å·ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†ç­–ç•¥ã€‚æ¡†æ¶çš„å…³é”®åœ¨äºå¦‚ä½•è®¾è®¡æœ‰æ•ˆçš„è§„åˆ™å’Œå¥–åŠ±å‡½æ•°ï¼Œä»¥åŠå¦‚ä½•å¹³è¡¡æ¨ç†å’Œè¯„åˆ†ä¸¤ä¸ªä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºâ€œè‡ªå¥–åŠ±â€æœºåˆ¶ï¼Œå³æ¨¡å‹è‡ªèº«ç”Ÿæˆå¥–åŠ±ä¿¡å·ã€‚è¿™ä¸ä¼ ç»Ÿçš„ä¾èµ–å¤–éƒ¨å¥–åŠ±ä¿¡å·çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚é€šè¿‡è‡ªå¥–åŠ±ï¼Œæ¨¡å‹å¯ä»¥æ›´è‡ªä¸»åœ°å­¦ä¹ å’Œä¼˜åŒ–æ¨ç†ç­–ç•¥ï¼Œå‡å°‘å¯¹äººå·¥å¹²é¢„çš„ä¾èµ–ã€‚æ­¤å¤–ï¼ŒåŸºäºè§„åˆ™çš„å¥–åŠ±ä¿¡å·ä¹Ÿæ›´æ˜“äºè§£é‡Šå’Œæ§åˆ¶ï¼Œå¯ä»¥é¿å…æ¨¡å‹å­¦ä¹ åˆ°ä¸æœŸæœ›çš„è¡Œä¸ºã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç²¾å¿ƒè®¾è®¡çš„è§„åˆ™ï¼ˆrubricï¼‰ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹è¿›è¡Œè¯„åˆ†ï¼Œç¡®ä¿å¥–åŠ±ä¿¡å·çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ï¼›2) å¥–åŠ±å‡½æ•°çš„é€‰æ‹©ï¼Œéœ€è¦å¹³è¡¡å¥–åŠ±çš„ç¨€ç–æ€§å’Œæ¢¯åº¦çš„å¤§å°ï¼Œä»¥ä¿è¯å¼ºåŒ–å­¦ä¹ çš„ç¨³å®šæ€§å’Œæ•ˆç‡ï¼›3) æ¨¡å‹æ¶æ„çš„é€‰æ‹©ï¼Œè®ºæ–‡ä½¿ç”¨äº†Qwen3-32Bä½œä¸ºåŸºç¡€æ¨¡å‹ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäº†å¾®è°ƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†åŠ å…¥å°‘é‡æ•™å¸ˆè¯„åˆ†æ•°æ®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è‡ªå¥–åŠ±çš„åŸºäºè§„åˆ™çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä»…ä½¿ç”¨4000ä¸ªæ ·æœ¬çš„HealthBench Easyå­é›†è®­ç»ƒçš„Qwen3-32Bæ¨¡å‹ï¼Œåœ¨HealthBench Hardä¸Šçš„æ€§èƒ½å°±è¶…è¿‡äº†GPT-5ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰å¾ˆé«˜çš„æ•ˆç‡å’Œæ½œåŠ›ã€‚æ­¤å¤–ï¼ŒåŠ å…¥å°‘é‡æ•™å¸ˆè¯„åˆ†çš„æ•°æ®å¯ä»¥è¿›ä¸€æ­¥æé«˜èƒ½åŠ›è¾ƒå¼±çš„æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¼€æ”¾å¼æ¨ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¾‹å¦‚åŒ»ç–—è¯Šæ–­ã€æ³•å¾‹å’¨è¯¢ã€æ•™è‚²è¯„ä¼°ç­‰ã€‚é€šè¿‡è‡ªå¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼Œå¯ä»¥è®­ç»ƒå‡ºæ›´æ™ºèƒ½ã€æ›´è‡ªä¸»çš„è¯­è¨€æ¨¡å‹ï¼Œä»è€Œæé«˜è¿™äº›é¢†åŸŸçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥é™ä½å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œé™ä½å¼€å‘æˆæœ¬ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Open-ended evaluation is essential for deploying large language models in real-world settings. In studying HealthBench, we observe that using the model itself as a grader and generating rubric-based reward signals substantially improves reasoning performance. Remarkably, the trained model also becomes a stronger grader. Motivated by this, we introduce Self-Rewarding Rubric-Based Reinforcement Learning for Open-Ended Reasoning, a lightweight framework that enables faster and more resource-efficient training while surpassing baselines. Remarkably, on Qwen3-32B, training with just the 4000-sample HealthBench Easy subset is sufficient to obtain a model that exceeds GPT-5 on HealthBench Hard. Incorporating a small amount of teacher-graded data further enhances performance for less capable models.

