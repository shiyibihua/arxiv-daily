---
layout: default
title: How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages
---

# How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15518" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15518v1</a>
  <a href="https://arxiv.org/pdf/2509.15518.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15518v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15518v1', 'How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siyang Wu, Zhewei Sun

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿæ¯”è¾ƒäººç±»ä¸LLMç”Ÿæˆä¿šè¯­ç”¨æ³•ï¼Œæ­ç¤ºLLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„åå·®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¿šè¯­ç”Ÿæˆ` `ä¿šè¯­ç†è§£` `åå·®åˆ†æ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰NLPç³»ç»Ÿåœ¨å¤„ç†ä¿šè¯­ç­‰éæ­£å¼è¯­è¨€æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œç¼ºä¹å¯¹ä¿šè¯­ç»“æ„çŸ¥è¯†çš„æ·±å…¥ç†è§£ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡ç³»ç»Ÿæ¯”è¾ƒäººç±»ä¸LLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ï¼Œè¯„ä¼°LLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„èƒ½åŠ›å’Œåå·®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨ä¿šè¯­åˆ›é€ æ€§æ–¹é¢æœ‰æ‰€æŒæ¡ï¼Œä½†åœ¨ç†è§£äººç±»ä¿šè¯­ç”¨æ³•æ–¹é¢å­˜åœ¨æ˜¾è‘—åå·®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¿šè¯­æ˜¯ä¸€ç§å¸¸ç”¨çš„éæ­£å¼è¯­è¨€ï¼Œå¯¹è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿæ„æˆäº†ä¸¥å³»çš„æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ€æ–°è¿›å±•ä½¿è¿™ä¸ªé—®é¢˜å˜å¾—æ›´å®¹æ˜“è§£å†³ã€‚è™½ç„¶LLMä»£ç†æ­£è¢«è¶Šæ¥è¶Šå¹¿æ³›åœ°åº”ç”¨äºä¸­é—´ä»»åŠ¡ï¼Œå¦‚ä¿šè¯­æ£€æµ‹å’Œä¿šè¯­è§£é‡Šï¼Œä½†å®ƒä»¬çš„æ³›åŒ–æ€§å’Œå¯é æ€§åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºè¿™äº›æ¨¡å‹æ˜¯å¦å·²ç»æŒæ¡äº†ä¸äººç±»è®¤å¯çš„ä¿šè¯­ç”¨æ³•è‰¯å¥½å¯¹é½çš„ä¿šè¯­ç»“æ„çŸ¥è¯†ã€‚ä¸ºäº†å›ç­”è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯¹äººç±»å’Œæœºå™¨ç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•è¿›è¡Œäº†ç³»ç»Ÿçš„æ¯”è¾ƒã€‚æˆ‘ä»¬çš„è¯„ä¼°æ¡†æ¶ä¾§é‡äºä¸‰ä¸ªæ ¸å¿ƒæ–¹é¢ï¼š1) åæ˜ æœºå™¨å¦‚ä½•çœ‹å¾…ä¿šè¯­çš„ç³»ç»Ÿæ€§åå·®çš„ç”¨æ³•ç‰¹å¾ï¼Œ2) ä¿šè¯­ç”¨æ³•ä¸­ä½¿ç”¨çš„è¯æ±‡åˆ›é€ å’Œå•è¯é‡ç”¨æ‰€åæ˜ çš„åˆ›é€ åŠ›ï¼Œä»¥åŠ 3) å½“ç”¨ä½œæ¨¡å‹è’¸é¦çš„é»„é‡‘æ ‡å‡†ç¤ºä¾‹æ—¶ï¼Œä¿šè¯­ç”¨æ³•çš„ä¿¡æ¯é‡ã€‚é€šè¿‡æ¯”è¾ƒæ¥è‡ªåœ¨çº¿ä¿šè¯­è¯å…¸ï¼ˆOSDï¼‰çš„äººç±»è®¤å¯çš„ä¿šè¯­ç”¨æ³•å’ŒGPT-4oå’ŒLlama-3ç”Ÿæˆçš„ä¿šè¯­ï¼Œæˆ‘ä»¬å‘ç°LLMåœ¨å¦‚ä½•çœ‹å¾…ä¿šè¯­æ–¹é¢å­˜åœ¨æ˜¾è‘—åå·®ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMå·²ç»æŒæ¡äº†å…³äºä¿šè¯­åˆ›é€ æ€§æ–¹é¢çš„é‡è¦çŸ¥è¯†ï¼Œä½†è¿™äº›çŸ¥è¯†ä¸äººç±»çš„çŸ¥è¯†ä¸å¤Ÿä¸€è‡´ï¼Œæ— æ³•ä½¿LLMç”¨äºè¯¸å¦‚è¯­è¨€åˆ†æç­‰å¤–æ¨ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ä¿šè¯­ç†è§£å’Œç”Ÿæˆæ–¹é¢å­˜åœ¨çš„åå·®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•ä¿è¯LLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ä¸äººç±»çš„è®¤çŸ¥å¯¹é½ï¼Œå¯¼è‡´å…¶åœ¨ä¿šè¯­ç›¸å…³çš„NLPä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºç¼ºä¹å¯¹LLMä¿šè¯­ç”Ÿæˆèƒ½åŠ›çš„ç³»ç»Ÿæ€§è¯„ä¼°å’Œåˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹æ¯”åˆ†æäººç±»å’ŒLLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ï¼Œæ­ç¤ºLLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„åå·®ã€‚é€šè¿‡è¯„ä¼°LLMåœ¨ä¿šè¯­ç”¨æ³•ç‰¹å¾ã€åˆ›é€ æ€§å’Œä¿¡æ¯é‡ä¸‰ä¸ªæ–¹é¢çš„è¡¨ç°ï¼Œä»è€Œåˆ¤æ–­LLMæ˜¯å¦æŒæ¡äº†ä¸äººç±»ä¸€è‡´çš„ä¿šè¯­ç»“æ„çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä»åœ¨çº¿ä¿šè¯­è¯å…¸ï¼ˆOSDï¼‰æ”¶é›†äººç±»è®¤å¯çš„ä¿šè¯­ç”¨æ³•ä½œä¸ºåŸºå‡†ï¼›2) ä½¿ç”¨GPT-4oå’ŒLlama-3ç­‰LLMç”Ÿæˆä¿šè¯­ç”¨æ³•ï¼›3) è®¾è®¡è¯„ä¼°æ¡†æ¶ï¼Œä»ç”¨æ³•ç‰¹å¾ã€åˆ›é€ æ€§å’Œä¿¡æ¯é‡ä¸‰ä¸ªæ–¹é¢å¯¹äººç±»å’ŒLLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•è¿›è¡Œå¯¹æ¯”åˆ†æï¼›4) åˆ†æå®éªŒç»“æœï¼Œæ­ç¤ºLLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„åå·®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºå¯¹æ¯”åˆ†æäººç±»å’ŒLLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ï¼Œä»è€Œæ­ç¤ºLLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„åå·®ã€‚è¯¥æ¡†æ¶ä»ç”¨æ³•ç‰¹å¾ã€åˆ›é€ æ€§å’Œä¿¡æ¯é‡ä¸‰ä¸ªæ–¹é¢å¯¹ä¿šè¯­ç”¨æ³•è¿›è¡Œè¯„ä¼°ï¼Œèƒ½å¤Ÿå…¨é¢åœ°è¯„ä¼°LLMåœ¨ä¿šè¯­ç†è§£ä¸Šçš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç”¨æ³•ç‰¹å¾æ–¹é¢ï¼Œç ”ç©¶åˆ†æäº†LLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ä¸­è¯æ€§ã€å¥æ³•ç»“æ„ç­‰ç‰¹å¾çš„åˆ†å¸ƒï¼Œå¹¶ä¸äººç±»ç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•è¿›è¡Œå¯¹æ¯”ã€‚åœ¨åˆ›é€ æ€§æ–¹é¢ï¼Œç ”ç©¶è¯„ä¼°äº†LLMåœ¨è¯æ±‡åˆ›é€ å’Œå•è¯é‡ç”¨æ–¹é¢çš„èƒ½åŠ›ã€‚åœ¨ä¿¡æ¯é‡æ–¹é¢ï¼Œç ”ç©¶è¯„ä¼°äº†LLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ä½œä¸ºæ¨¡å‹è’¸é¦çš„é»„é‡‘æ ‡å‡†ç¤ºä¾‹æ—¶çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè™½ç„¶LLMåœ¨ä¿šè¯­åˆ›é€ æ€§æ–¹é¢æœ‰æ‰€æŒæ¡ï¼Œä½†åœ¨ç†è§£äººç±»ä¿šè¯­ç”¨æ³•æ–¹é¢å­˜åœ¨æ˜¾è‘—åå·®ã€‚å…·ä½“æ¥è¯´ï¼ŒLLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•åœ¨è¯æ€§åˆ†å¸ƒã€å¥æ³•ç»“æ„ç­‰æ–¹é¢ä¸äººç±»ç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•å­˜åœ¨å·®å¼‚ã€‚æ­¤å¤–ï¼ŒLLMç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ä½œä¸ºæ¨¡å‹è’¸é¦çš„é»„é‡‘æ ‡å‡†ç¤ºä¾‹æ—¶çš„æ•ˆæœä¸å¦‚äººç±»ç”Ÿæˆçš„ä¿šè¯­ç”¨æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨ä¿šè¯­ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„èƒ½åŠ›ï¼Œä»è€Œæ”¹å–„å…¶åœ¨ç¤¾äº¤åª’ä½“åˆ†æã€æƒ…æ„Ÿåˆ†æã€å¯¹è¯ç³»ç»Ÿç­‰é¢†åŸŸçš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æå‡ºçš„è¯„ä¼°æ¡†æ¶å¯ç”¨äºè¯„ä¼°å…¶ä»–è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éæ­£å¼è¯­è¨€æ–¹é¢çš„èƒ½åŠ›ï¼Œä¸ºè¯­è¨€æ¨¡å‹çš„å¼€å‘å’Œè¯„ä¼°æä¾›å‚è€ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Slang is a commonly used type of informal language that poses a daunting challenge to NLP systems. Recent advances in large language models (LLMs), however, have made the problem more approachable. While LLM agents are becoming more widely applied to intermediary tasks such as slang detection and slang interpretation, their generalizability and reliability are heavily dependent on whether these models have captured structural knowledge about slang that align well with human attested slang usages. To answer this question, we contribute a systematic comparison between human and machine-generated slang usages. Our evaluative framework focuses on three core aspects: 1) Characteristics of the usages that reflect systematic biases in how machines perceive slang, 2) Creativity reflected by both lexical coinages and word reuses employed by the slang usages, and 3) Informativeness of the slang usages when used as gold-standard examples for model distillation. By comparing human-attested slang usages from the Online Slang Dictionary (OSD) and slang generated by GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our results suggest that while LLMs have captured significant knowledge about the creative aspects of slang, such knowledge does not align with humans sufficiently to enable LLMs for extrapolative tasks such as linguistic analyses.

