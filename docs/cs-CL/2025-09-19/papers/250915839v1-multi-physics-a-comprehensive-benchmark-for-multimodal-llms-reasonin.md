---
layout: default
title: Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems
---

# Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15839" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15839v1</a>
  <a href="https://arxiv.org/pdf/2509.15839.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15839v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15839v1', 'Multi-Physics: A Comprehensive Benchmark for Multimodal LLMs Reasoning on Chinese Multi-Subject Physics Problems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhongze Luo, Zhenshuai Yin, Yongxin Guo, Zhichao Wang, Jionghao Zhu, Xiaoying Tang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/luozhongze/Multi-Physics)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMulti-Physicsï¼šä¸€ä¸ªç”¨äºè¯„ä¼°å¤šæ¨¡æ€LLMåœ¨ä¸­æ–‡ç‰©ç†é—®é¢˜ä¸Šæ¨ç†èƒ½åŠ›çš„ç»¼åˆåŸºå‡†ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰©ç†æ¨ç†` `ä¸­æ–‡åŸºå‡†` `ç§‘å­¦æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç‰©ç†æ¨ç†è¯„ä¼°åŸºå‡†ç¼ºä¹ç»†ç²’åº¦å­¦ç§‘è¦†ç›–ã€å¿½ç•¥é€æ­¥æ¨ç†è¿‡ç¨‹ï¼Œä¸”ä¸»è¦ä»¥è‹±æ–‡ä¸ºä¸­å¿ƒï¼Œæœªèƒ½å……åˆ†è¯„ä¼°è§†è§‰ä¿¡æ¯çš„ä½œç”¨ã€‚
2. Multi-PhysicsåŸºå‡†åŒ…å«1412é“å›¾åƒå…³è”çš„ä¸­æ–‡ç‰©ç†é€‰æ‹©é¢˜ï¼Œè¦†ç›–11ä¸ªé«˜ä¸­ç‰©ç†å­¦ç§‘ï¼Œå¹¶æä¾›5ä¸ªéš¾åº¦çº§åˆ«ã€‚
3. é€šè¿‡åŒé‡è¯„ä¼°æ¡†æ¶ï¼Œåˆ†æMLLMæœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§å’Œé€æ­¥æ¨ç†çš„å®Œæ•´æ€§ï¼Œå¹¶ç ”ç©¶éš¾åº¦å’Œè§†è§‰ä¿¡æ¯çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(MLLM)åœ¨æ¨ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å°†å…¶åº”ç”¨äºç‰©ç†ç­‰ä¸“ä¸šç§‘å­¦é¢†åŸŸæ—¶ï¼Œç°æœ‰çš„è¯„ä¼°åŸºå‡†å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚å…·ä½“è€Œè¨€ï¼Œç°æœ‰åŸºå‡†é€šå¸¸ç¼ºä¹ç»†ç²’åº¦çš„å­¦ç§‘è¦†ç›–ï¼Œå¿½ç•¥äº†é€æ­¥æ¨ç†è¿‡ç¨‹ï¼Œå¹¶ä¸”ä¸»è¦ä»¥è‹±è¯­ä¸ºä¸­å¿ƒï¼Œæœªèƒ½ç³»ç»Ÿåœ°è¯„ä¼°è§†è§‰ä¿¡æ¯çš„ä½œç”¨ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨å‡ºäº†Multi-Physicsï¼Œä¸€ä¸ªç”¨äºä¸­æ–‡ç‰©ç†æ¨ç†çš„ç»¼åˆåŸºå‡†ï¼ŒåŒ…å«5ä¸ªéš¾åº¦çº§åˆ«ï¼Œæ¶µç›–11ä¸ªé«˜ä¸­ç‰©ç†å­¦ç§‘çš„1412ä¸ªå›¾åƒå…³è”çš„é€‰æ‹©é¢˜ã€‚æˆ‘ä»¬é‡‡ç”¨åŒé‡è¯„ä¼°æ¡†æ¶æ¥è¯„ä¼°20ä¸ªä¸åŒçš„MLLMï¼Œåˆ†ææœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œé€æ­¥æ¨ç†è¿‡ç¨‹çš„å®Œæ•´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡æ¯”è¾ƒæ”¹å˜è¾“å…¥æ¨¡å¼å‰åæ¨¡å‹çš„æ€§èƒ½ï¼Œç³»ç»Ÿåœ°ç ”ç©¶äº†éš¾åº¦çº§åˆ«å’Œè§†è§‰ä¿¡æ¯çš„å½±å“ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ä»…ä¸ºç¤¾åŒºæä¾›äº†ç»†ç²’åº¦çš„èµ„æºï¼Œè€Œä¸”ä¸ºå‰–ææœ€å…ˆè¿›çš„MLLMçš„å¤šæ¨¡æ€æ¨ç†è¿‡ç¨‹æä¾›äº†ä¸€ç§ç¨³å¥çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å’Œä»£ç å·²å¼€æºï¼šhttps://github.com/luozhongze/Multi-Physicsã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰MLLMåœ¨ä¸­æ–‡ç‰©ç†é—®é¢˜æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­å­˜åœ¨çš„ä¸è¶³ã€‚ç°æœ‰åŸºå‡†æµ‹è¯•é›†åœ¨å­¦ç§‘è¦†ç›–èŒƒå›´ã€æ¨ç†è¿‡ç¨‹è¯„ä¼°ä»¥åŠå¯¹è§†è§‰ä¿¡æ¯çš„åˆ©ç”¨ä¸Šå­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å…¨é¢è¯„ä¼°MLLMåœ¨ç‰©ç†é¢†åŸŸçš„æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªæ›´å…¨é¢ã€ç»†ç²’åº¦çš„ä¸­æ–‡ç‰©ç†æ¨ç†åŸºå‡†æµ‹è¯•é›†ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„è¯„ä¼°æ–¹æ³•ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°MLLMåœ¨è§£å†³å¤æ‚ç‰©ç†é—®é¢˜æ—¶çš„æ¨ç†èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯è§†è§‰ä¿¡æ¯è¾…åŠ©ä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMulti-PhysicsåŸºå‡†æµ‹è¯•é›†åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š1) æ¶µç›–11ä¸ªé«˜ä¸­ç‰©ç†å­¦ç§‘çš„1412é“é€‰æ‹©é¢˜ï¼›2) é¢˜ç›®ä¸å›¾åƒå…³è”ï¼Œè€ƒå¯Ÿæ¨¡å‹å¯¹è§†è§‰ä¿¡æ¯çš„ç†è§£å’Œåˆ©ç”¨ï¼›3) é¢˜ç›®åˆ†ä¸º5ä¸ªéš¾åº¦çº§åˆ«ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒéš¾åº¦ä¸‹çš„è¡¨ç°ï¼›4) é‡‡ç”¨åŒé‡è¯„ä¼°æ¡†æ¶ï¼ŒåŒæ—¶è¯„ä¼°æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œé€æ­¥æ¨ç†è¿‡ç¨‹çš„å®Œæ•´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ä¸­æ–‡ç‰©ç†æ¨ç†çš„å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•é›†ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„è¯„ä¼°æ–¹æ³•ã€‚è¯¥åŸºå‡†æµ‹è¯•é›†ä¸ä»…æ¶µç›–äº†æ›´å¹¿æ³›çš„ç‰©ç†å­¦ç§‘ï¼Œè€Œä¸”æ›´åŠ æ³¨é‡å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„è¯„ä¼°ï¼Œä»¥åŠå¯¹è§†è§‰ä¿¡æ¯åˆ©ç”¨çš„è€ƒå¯Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºæ–¹é¢ï¼Œä½œè€…ç²¾å¿ƒæŒ‘é€‰å’Œè®¾è®¡äº†é¢˜ç›®ï¼Œç¡®ä¿å…¶è¦†ç›–äº†é«˜ä¸­ç‰©ç†çš„ä¸»è¦çŸ¥è¯†ç‚¹ï¼Œå¹¶ä¸å›¾åƒä¿¡æ¯ç›¸ç»“åˆï¼Œå¢åŠ äº†é¢˜ç›®çš„å¤æ‚æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚åœ¨è¯„ä¼°æ–¹æ³•æ–¹é¢ï¼Œä½œè€…é‡‡ç”¨äº†åŒé‡è¯„ä¼°æ¡†æ¶ï¼Œæ—¢å…³æ³¨æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œåˆå…³æ³¨é€æ­¥æ¨ç†è¿‡ç¨‹çš„å®Œæ•´æ€§ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚éš¾åº¦åˆ†çº§ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œç¡®ä¿èƒ½å¤ŸåŒºåˆ†ä¸åŒæ¨¡å‹çš„æ€§èƒ½æ°´å¹³ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å¯¹20ä¸ªMLLMè¿›è¡Œè¯„ä¼°ï¼Œå‘ç°ç°æœ‰æ¨¡å‹åœ¨Multi-PhysicsåŸºå‡†ä¸Šçš„è¡¨ç°ä»æœ‰è¾ƒå¤§æå‡ç©ºé—´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè§†è§‰ä¿¡æ¯å¯¹æ¨¡å‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œä½†ä¸åŒæ¨¡å‹å¯¹è§†è§‰ä¿¡æ¯çš„åˆ©ç”¨ç¨‹åº¦ä¸åŒã€‚æ­¤å¤–ï¼Œæ¨¡å‹åœ¨ä¸åŒéš¾åº¦çº§åˆ«ä¸Šçš„è¡¨ç°å·®å¼‚æ˜æ˜¾ï¼Œè¡¨æ˜æ¨¡å‹åœ¨å¤„ç†å¤æ‚ç‰©ç†é—®é¢˜æ—¶ä»é¢ä¸´æŒ‘æˆ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ•™è‚²é¢†åŸŸï¼Œç”¨äºè¯„ä¼°å’Œæå‡AIåœ¨ç‰©ç†æ•™å­¦ä¸­çš„åº”ç”¨æ•ˆæœã€‚åŒæ—¶ï¼Œè¯¥åŸºå‡†æµ‹è¯•é›†å¯ä¿ƒè¿›å¤šæ¨¡æ€LLMåœ¨ç§‘å­¦é¢†åŸŸçš„åº”ç”¨ï¼Œæ¨åŠ¨AIåœ¨è§£å†³å®é™…ç§‘å­¦é—®é¢˜æ–¹é¢çš„èƒ½åŠ›æå‡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯æ‰©å±•åˆ°å…¶ä»–ç§‘å­¦é¢†åŸŸï¼Œæ„å»ºæ›´é€šç”¨çš„ç§‘å­¦æ¨ç†åŸºå‡†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While multimodal LLMs (MLLMs) demonstrate remarkable reasoning progress, their application in specialized scientific domains like physics reveals significant gaps in current evaluation benchmarks. Specifically, existing benchmarks often lack fine-grained subject coverage, neglect the step-by-step reasoning process, and are predominantly English-centric, failing to systematically evaluate the role of visual information. Therefore, we introduce \textbf {Multi-Physics} for Chinese physics reasoning, a comprehensive benchmark that includes 5 difficulty levels, featuring 1,412 image-associated, multiple-choice questions spanning 11 high-school physics subjects. We employ a dual evaluation framework to evaluate 20 different MLLMs, analyzing both final answer accuracy and the step-by-step integrity of their chain-of-thought. Furthermore, we systematically study the impact of difficulty level and visual information by comparing the model performance before and after changing the input mode. Our work provides not only a fine-grained resource for the community but also offers a robust methodology for dissecting the multimodal reasoning process of state-of-the-art MLLMs, and our dataset and code have been open-sourced: https://github.com/luozhongze/Multi-Physics.

