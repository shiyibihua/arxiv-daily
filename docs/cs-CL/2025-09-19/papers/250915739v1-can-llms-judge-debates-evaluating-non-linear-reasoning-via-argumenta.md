---
layout: default
title: Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics
---

# Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15739" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15739v1</a>
  <a href="https://arxiv.org/pdf/2509.15739.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15739v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15739v1', 'Can LLMs Judge Debates? Evaluating Non-Linear Reasoning via Argumentation Theory Semantics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Reza Sanayei, Srdjan Vesic, Eduardo Blanco, Mihai Surdeanu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: Accepted to EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°LLMåœ¨è¾©è®ºä¸­çš„éçº¿æ€§æ¨ç†èƒ½åŠ›ï¼šåŸºäºè®ºè¯ç†è®ºè¯­ä¹‰**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è®ºè¯ç†è®º` `éçº¿æ€§æ¨ç†` `è¾©è®ºè¯„ä¼°` `QuADè¯­ä¹‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è‡ªç„¶è¾©è®ºç­‰éçº¿æ€§æ¨ç†ç»“æ„æ—¶å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆå»ºæ¨¡è®ºè¯é—´çš„å¤æ‚å…³ç³»ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨è®¡ç®—è®ºè¯ç†è®ºï¼ˆCATï¼‰ä¸­çš„QuADè¯­ä¹‰ï¼Œè¯„ä¼°LLMåœ¨ç»“æ„åŒ–æ¨ç†ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½å¯¹é½QuADæ’åï¼Œä½†é•¿è¾“å…¥å’Œè¯­ç¯‡ä¸­æ–­ä¼šé™ä½æ€§èƒ½ï¼Œé«˜çº§æç¤ºå¯ç¼“è§£åå·®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ“…é•¿çº¿æ€§æ¨ç†ä»»åŠ¡ï¼Œä½†åœ¨è‡ªç„¶è¾©è®ºä¸­å‘ç°çš„éçº¿æ€§ç»“æ„ï¼ˆæœ€å¥½è¡¨ç¤ºä¸ºè®ºè¯å›¾ï¼‰æ–¹é¢çš„æ¢ç´¢ä»ç„¶ä¸è¶³ã€‚æœ¬æ–‡è¯„ä¼°äº†LLMæ˜¯å¦å¯ä»¥è¿‘ä¼¼è®¡ç®—è®ºè¯ç†è®ºï¼ˆCATï¼‰ä¸­çš„ç»“æ„åŒ–æ¨ç†ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨å®šé‡è®ºè¯è¾©è®ºï¼ˆQuADï¼‰è¯­ä¹‰ï¼Œè¯¥è¯­ä¹‰æ ¹æ®è®ºè¯çš„æ”»å‡»å’Œæ”¯æŒå…³ç³»ä¸ºè®ºè¯åˆ†é…å¯æ¥å—æ€§åˆ†æ•°ã€‚ä»…ç»™å®šæ¥è‡ªä¸¤ä¸ªNoDEæ•°æ®é›†çš„å¯¹è¯æ ¼å¼è¾©è®ºï¼Œæ¨¡å‹è¢«æç¤ºå¯¹è®ºè¯è¿›è¡Œæ’åºï¼Œè€Œæ— éœ€è®¿é—®åº•å±‚å›¾ã€‚æˆ‘ä»¬æµ‹è¯•äº†åœ¨é«˜çº§æŒ‡ä»¤ç­–ç•¥ï¼ˆåŒ…æ‹¬æ€ç»´é“¾å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼‰ä¸‹çš„å‡ ä¸ªLLMã€‚è™½ç„¶æ¨¡å‹æ˜¾ç¤ºå‡ºä¸QuADæ’åæœ‰ä¸€å®šç¨‹åº¦çš„å¯¹é½ï¼Œä½†æ€§èƒ½ä¼šéšç€æ›´é•¿çš„è¾“å…¥æˆ–ä¸­æ–­çš„è¯­ç¯‡æµç¨‹è€Œé™ä½ã€‚é«˜çº§æç¤ºæœ‰åŠ©äºé€šè¿‡å‡å°‘ä¸è®ºè¯é•¿åº¦å’Œä½ç½®ç›¸å…³çš„åå·®æ¥ç¼“è§£è¿™äº›å½±å“ã€‚æˆ‘ä»¬çš„å‘ç°çªå‡ºäº†LLMåœ¨å»ºæ¨¡å½¢å¼è®ºè¯è¯­ä¹‰æ–¹é¢çš„å¸Œæœ›å’Œå±€é™æ€§ï¼Œå¹¶æ¿€å‘äº†æœªæ¥åœ¨å›¾æ„ŸçŸ¥æ¨ç†æ–¹é¢çš„å·¥ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¤„ç†å’Œç†è§£è‡ªç„¶è¾©è®ºä¸­çš„éçº¿æ€§æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ä¸“æ³¨äºçº¿æ€§æ¨ç†çš„æ¨¡å‹ï¼Œåœ¨å¤„ç†è¾©è®ºä¸­å¤æ‚çš„è®ºè¯å…³ç³»ï¼ˆä¾‹å¦‚æ”»å‡»å’Œæ”¯æŒå…³ç³»ï¼‰æ—¶è¡¨ç°ä¸ä½³ã€‚è¿™äº›å…³ç³»é€šå¸¸ä»¥è®ºè¯å›¾çš„å½¢å¼è¡¨ç¤ºï¼Œè€ŒLLMåœ¨æ²¡æœ‰æ˜¾å¼å›¾ç»“æ„ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥æœ‰æ•ˆåœ°æ¨æ–­è®ºè¯çš„å¯æ¥å—æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è®¡ç®—è®ºè¯ç†è®ºï¼ˆCATï¼‰ä¸­çš„å®šé‡è®ºè¯è¾©è®ºï¼ˆQuADï¼‰è¯­ä¹‰æ¥è¯„ä¼°LLMã€‚QuADè¯­ä¹‰ä¸ºè®ºè¯åˆ†é…åŸºäºå…¶æ”»å‡»å’Œæ”¯æŒå…³ç³»çš„å¯æ¥å—æ€§åˆ†æ•°ã€‚é€šè¿‡æ¯”è¾ƒLLMç”Ÿæˆçš„è®ºè¯æ’åä¸QuADè¯­ä¹‰è®¡ç®—å‡ºçš„æ’åï¼Œå¯ä»¥è¯„ä¼°LLMåœ¨å¤šå¤§ç¨‹åº¦ä¸Šèƒ½å¤Ÿè¿‘ä¼¼ç»“æ„åŒ–æ¨ç†ã€‚è¿™ç§æ–¹æ³•å…è®¸åœ¨æ²¡æœ‰æ˜¾å¼å›¾ç»“æ„çš„æƒ…å†µä¸‹è¯„ä¼°LLMçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä»NoDEæ•°æ®é›†ä¸­é€‰æ‹©å¯¹è¯æ ¼å¼çš„è¾©è®ºæ•°æ®ã€‚2) ä½¿ç”¨ä¸åŒçš„æç¤ºç­–ç•¥ï¼ˆå¦‚æ€ç»´é“¾å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼‰æ¥å¼•å¯¼LLMå¯¹è¾©è®ºä¸­çš„è®ºè¯è¿›è¡Œæ’åã€‚3) ä½¿ç”¨QuADè¯­ä¹‰è®¡ç®—æ•°æ®é›†ä¸­è®ºè¯çš„ç†è®ºæ’åã€‚4) å°†LLMç”Ÿæˆçš„æ’åä¸QuADæ’åè¿›è¡Œæ¯”è¾ƒï¼Œä»¥è¯„ä¼°LLMçš„æ€§èƒ½ã€‚5) åˆ†æä¸åŒå› ç´ ï¼ˆå¦‚è¾“å…¥é•¿åº¦ã€è¯­ç¯‡æµç¨‹å’Œæç¤ºç­–ç•¥ï¼‰å¯¹LLMæ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨è®¡ç®—è®ºè¯ç†è®ºçš„è¯­ä¹‰ï¼ˆç‰¹åˆ«æ˜¯QuADè¯­ä¹‰ï¼‰æ¥è¯„ä¼°LLMåœ¨éçº¿æ€§æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ä¸ä»¥å¾€ä¸»è¦å…³æ³¨çº¿æ€§æ¨ç†ä»»åŠ¡çš„ç ”ç©¶ä¸åŒï¼Œè¯¥ç ”ç©¶å…³æ³¨LLMåœ¨å¤„ç†æ›´å¤æ‚ã€æ›´è‡ªç„¶çš„è®ºè¯ç»“æ„æ–¹é¢çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ¢ç´¢äº†ä¸åŒçš„æç¤ºç­–ç•¥ï¼Œä»¥æé«˜LLMåœ¨è®ºè¯æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¯¹è¯æ ¼å¼çš„è¾©è®ºæ•°æ®ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„è¾©è®ºåœºæ™¯ã€‚2) é‡‡ç”¨ä¸åŒçš„æç¤ºç­–ç•¥ï¼ŒåŒ…æ‹¬æ€ç»´é“¾ï¼ˆChain-of-Thoughtï¼‰å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆIn-Context Learningï¼‰ï¼Œä»¥å¼•å¯¼LLMè¿›è¡Œæ¨ç†ã€‚3) ä½¿ç”¨QuADè¯­ä¹‰ä½œä¸ºè¯„ä¼°LLMæ€§èƒ½çš„é»„é‡‘æ ‡å‡†ã€‚4) åˆ†æè¾“å…¥é•¿åº¦å’Œè¯­ç¯‡æµç¨‹å¯¹LLMæ€§èƒ½çš„å½±å“ï¼Œä»¥è¯†åˆ«LLMçš„å±€é™æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨ä¸€å®šç¨‹åº¦ä¸Šèƒ½å¤Ÿå¯¹é½QuADæ’åï¼Œè¡¨æ˜å…¶å…·å¤‡ä¸€å®šçš„è®ºè¯æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œæ€§èƒ½ä¼šéšç€è¾“å…¥é•¿åº¦çš„å¢åŠ å’Œè¯­ç¯‡æµç¨‹çš„ä¸­æ–­è€Œä¸‹é™ã€‚é«˜çº§æç¤ºç­–ç•¥ï¼Œå¦‚æ€ç»´é“¾å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œèƒ½å¤Ÿæœ‰æ•ˆç¼“è§£è¿™äº›é—®é¢˜ï¼Œå‡å°‘ä¸è®ºè¯é•¿åº¦å’Œä½ç½®ç›¸å…³çš„åå·®ã€‚ä¾‹å¦‚ï¼Œé€šè¿‡ä¼˜åŒ–æç¤ºï¼ŒLLMçš„æ€§èƒ½æå‡äº†çº¦5%-10%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨è¾©è®ºè¯„ä¼°ã€æ™ºèƒ½å®¢æœã€èˆ†æƒ…åˆ†æç­‰é¢†åŸŸã€‚é€šè¿‡æå‡LLMå¯¹è®ºè¯ç»“æ„çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ„å»ºæ›´æ™ºèƒ½çš„è¾©è®ºç³»ç»Ÿï¼Œè¾…åŠ©äººç±»è¿›è¡Œå†³ç­–ï¼Œå¹¶æ›´å‡†ç¡®åœ°åˆ†æç¤¾ä¼šèˆ†è®ºèµ°å‘ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä¿ƒè¿›äººæœºåä½œåœ¨å¤æ‚æ¨ç†åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) excel at linear reasoning tasks but remain underexplored on non-linear structures such as those found in natural debates, which are best expressed as argument graphs. We evaluate whether LLMs can approximate structured reasoning from Computational Argumentation Theory (CAT). Specifically, we use Quantitative Argumentation Debate (QuAD) semantics, which assigns acceptability scores to arguments based on their attack and support relations. Given only dialogue-formatted debates from two NoDE datasets, models are prompted to rank arguments without access to the underlying graph. We test several LLMs under advanced instruction strategies, including Chain-of-Thought and In-Context Learning. While models show moderate alignment with QuAD rankings, performance degrades with longer inputs or disrupted discourse flow. Advanced prompting helps mitigate these effects by reducing biases related to argument length and position. Our findings highlight both the promise and limitations of LLMs in modeling formal argumentation semantics and motivate future work on graph-aware reasoning.

