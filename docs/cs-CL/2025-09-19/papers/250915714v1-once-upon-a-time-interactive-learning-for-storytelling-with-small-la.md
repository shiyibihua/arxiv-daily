---
layout: default
title: Once Upon a Time: Interactive Learning for Storytelling with Small Language Models
---

# Once Upon a Time: Interactive Learning for Storytelling with Small Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15714" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15714v1</a>
  <a href="https://arxiv.org/pdf/2509.15714.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15714v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15714v1', 'Once Upon a Time: Interactive Learning for Storytelling with Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jonas Mayer Martins, Ali Hamza Bashir, Muhammad Rehan Khalid, Lisa Beinborn

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: EMNLP 2025, BabyLM Challenge; 16 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº¤äº’å¼å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨è®¤çŸ¥åé¦ˆæå‡å°è¯­è¨€æ¨¡å‹çš„æ•…äº‹ç”Ÿæˆèƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº¤äº’å¼å­¦ä¹ ` `æ•…äº‹ç”Ÿæˆ` `å°è¯­è¨€æ¨¡å‹` `è®¤çŸ¥åé¦ˆ` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ä¾èµ–æµ·é‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œå¿½ç•¥äº†äººç±»é€šè¿‡äº¤äº’å­¦ä¹ è¯­è¨€çš„æœ‰æ•ˆæ–¹å¼ã€‚
2. è®ºæ–‡æå‡ºäº¤äº’å¼å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡æ•™å¸ˆæ¨¡å‹æä¾›å¯è¯»æ€§ã€è¿è´¯æ€§å’Œåˆ›é€ æ€§ç­‰é«˜å±‚æ¬¡åé¦ˆæ¥æŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ•°æ®æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ï¼Œä»…éœ€å°‘é‡æ•°æ®å³å¯è¾¾åˆ°ç›¸å½“çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å„¿ç«¥é€šè¿‡ä¸ç¤¾äº¤ç¯å¢ƒäº’åŠ¨æ¥é«˜æ•ˆåœ°å­¦ä¹ è¯­è¨€ï¼Œè€Œå¤§å‹è¯­è¨€æ¨¡å‹é€šå¸¸é€šè¿‡åœ¨æµ·é‡æ–‡æœ¬ä¸Šè¿›è¡Œä¸‹ä¸€ä¸ªè¯é¢„æµ‹æ¥è®­ç»ƒã€‚å—æ­¤å¯¹æ¯”çš„å¯å‘ï¼Œæœ¬æ–‡ç ”ç©¶äº†è¯­è¨€æ¨¡å‹æ˜¯å¦å¯ä»¥é€šè¿‡ä¸ä»…ä»ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ä¸­å­¦ä¹ ï¼Œè¿˜å¯ä»¥ä»é«˜å±‚æ¬¡ã€è®¤çŸ¥å¯å‘çš„åé¦ˆä¸­å­¦ä¹ ï¼Œä»è€Œç”¨æ›´å°‘çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚æœ¬æ–‡è®­ç»ƒä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹æ¥ç”Ÿæˆæ•…äº‹ï¼Œæ•™å¸ˆæ¨¡å‹æ ¹æ®å¯è¯»æ€§ã€å™äº‹è¿è´¯æ€§å’Œåˆ›é€ åŠ›å¯¹æ•…äº‹è¿›è¡Œè¯„åˆ†ã€‚é€šè¿‡æ”¹å˜åé¦ˆå¾ªç¯å‰çš„é¢„è®­ç»ƒé‡ï¼Œè¯„ä¼°äº†è¿™ç§äº¤äº’å¼å­¦ä¹ å¯¹å½¢å¼å’ŒåŠŸèƒ½è¯­è¨€èƒ½åŠ›çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œé«˜å±‚æ¬¡çš„åé¦ˆå…·æœ‰å¾ˆé«˜çš„æ•°æ®æ•ˆç‡ï¼šä»…é€šè¿‡äº¤äº’å¼å­¦ä¹ ä¸­çš„ 100 ä¸‡ä¸ªå•è¯çš„è¾“å…¥ï¼Œæ•…äº‹ç”ŸæˆæŠ€èƒ½çš„æå‡æ•ˆæœå¯ä»¥ä¸ 4.1 äº¿ä¸ªå•è¯çš„ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ç›¸å½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•…äº‹ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†é€šå¸¸éœ€è¦æµ·é‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæˆæœ¬é«˜æ˜‚ã€‚æ­¤å¤–ï¼Œä¼ ç»Ÿçš„è®­ç»ƒæ–¹æ³•ä¸»è¦ä¾èµ–äºä¸‹ä¸€ä¸ªè¯é¢„æµ‹ï¼Œç¼ºä¹å¯¹æ•…äº‹è´¨é‡ï¼ˆå¦‚å¯è¯»æ€§ã€è¿è´¯æ€§å’Œåˆ›é€ æ€§ï¼‰çš„ç›´æ¥åé¦ˆï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥ç”Ÿæˆé«˜è´¨é‡çš„æ•…äº‹ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨æ›´å°‘çš„æ•°æ®ï¼Œå¹¶å¼•å…¥æ›´æœ‰æ•ˆçš„åé¦ˆæœºåˆ¶ï¼Œæ¥æå‡è¯­è¨€æ¨¡å‹çš„æ•…äº‹ç”Ÿæˆèƒ½åŠ›æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡ä»¿äººç±»é€šè¿‡äº¤äº’å­¦ä¹ è¯­è¨€çš„æ–¹å¼ï¼Œå¼•å…¥ä¸€ä¸ªæ•™å¸ˆæ¨¡å‹æ¥å¯¹å­¦ç”Ÿæ¨¡å‹ç”Ÿæˆçš„æ•…äº‹è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æä¾›é«˜å±‚æ¬¡çš„åé¦ˆã€‚è¿™ç§åé¦ˆä¸ä»…åŒ…æ‹¬ä¸‹ä¸€ä¸ªè¯çš„é¢„æµ‹ï¼Œè¿˜åŒ…æ‹¬å¯¹æ•…äº‹æ•´ä½“è´¨é‡çš„è¯„ä¼°ï¼Œä»è€Œå¼•å¯¼å­¦ç”Ÿæ¨¡å‹æ›´å¥½åœ°å­¦ä¹ å¦‚ä½•ç”Ÿæˆé«˜è´¨é‡çš„æ•…äº‹ã€‚é€šè¿‡è¿™ç§äº¤äº’å¼å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ•°æ®ï¼Œå¹¶æ›´å¿«åœ°æå‡æ•…äº‹ç”Ÿæˆèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå­¦ç”Ÿæ¨¡å‹å’Œæ•™å¸ˆæ¨¡å‹ã€‚å­¦ç”Ÿæ¨¡å‹è´Ÿè´£ç”Ÿæˆæ•…äº‹ï¼Œæ•™å¸ˆæ¨¡å‹è´Ÿè´£è¯„ä¼°å­¦ç”Ÿæ¨¡å‹ç”Ÿæˆçš„æ•…äº‹çš„è´¨é‡ï¼Œå¹¶æä¾›åé¦ˆã€‚å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š1) å­¦ç”Ÿæ¨¡å‹ç”Ÿæˆæ•…äº‹ï¼›2) æ•™å¸ˆæ¨¡å‹æ ¹æ®å¯è¯»æ€§ã€å™äº‹è¿è´¯æ€§å’Œåˆ›é€ åŠ›å¯¹æ•…äº‹è¿›è¡Œè¯„åˆ†ï¼›3) å­¦ç”Ÿæ¨¡å‹æ ¹æ®æ•™å¸ˆæ¨¡å‹çš„è¯„åˆ†è¿›è¡Œå­¦ä¹ ï¼Œè°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä»¥ç”Ÿæˆæ›´é«˜è´¨é‡çš„æ•…äº‹ã€‚è¿™ä¸ªè¿‡ç¨‹å¾ªç¯è¿›è¡Œï¼Œç›´åˆ°å­¦ç”Ÿæ¨¡å‹è¾¾åˆ°é¢„å®šçš„æ€§èƒ½æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†é«˜å±‚æ¬¡çš„è®¤çŸ¥åé¦ˆæœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„ä¸‹ä¸€ä¸ªè¯é¢„æµ‹ç›¸æ¯”ï¼Œè¿™ç§åé¦ˆæœºåˆ¶èƒ½å¤Ÿæ›´ç›´æ¥åœ°æŒ‡å¯¼æ¨¡å‹å­¦ä¹ å¦‚ä½•ç”Ÿæˆé«˜è´¨é‡çš„æ•…äº‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡å®éªŒéªŒè¯äº†è¿™ç§äº¤äº’å¼å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ï¼Œè¯æ˜äº†å…¶åœ¨å‡å°‘æ•°æ®éœ€æ±‚æ–¹é¢çš„æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•™å¸ˆæ¨¡å‹ä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹å¯è¯»æ€§ã€å™äº‹è¿è´¯æ€§å’Œåˆ›é€ åŠ›ä¸‰ä¸ªæŒ‡æ ‡è¿›è¡Œå¾®è°ƒã€‚å­¦ç”Ÿæ¨¡å‹ä¹Ÿä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ çš„æ–¹å¼ï¼Œæ ¹æ®æ•™å¸ˆæ¨¡å‹çš„è¯„åˆ†æ¥è°ƒæ•´ç”Ÿæˆç­–ç•¥ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬ä¸‹ä¸€ä¸ªè¯é¢„æµ‹æŸå¤±å’ŒåŸºäºæ•™å¸ˆæ¨¡å‹è¯„åˆ†çš„å¥–åŠ±å‡½æ•°ã€‚å®éªŒä¸­ï¼Œä½œè€…æ¢ç´¢äº†ä¸åŒçš„é¢„è®­ç»ƒé‡å’Œåé¦ˆé¢‘ç‡ï¼Œä»¥è¯„ä¼°äº¤äº’å¼å­¦ä¹ çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡äº¤äº’å¼å­¦ä¹ ï¼Œä»…ä½¿ç”¨ 100 ä¸‡ä¸ªå•è¯çš„è¾“å…¥ï¼Œæ•…äº‹ç”ŸæˆæŠ€èƒ½çš„æå‡æ•ˆæœå¯ä»¥ä¸ä½¿ç”¨ 4.1 äº¿ä¸ªå•è¯è¿›è¡Œä¸‹ä¸€ä¸ªè¯é¢„æµ‹çš„è®­ç»ƒæ•ˆæœç›¸å½“ã€‚è¿™è¡¨æ˜é«˜å±‚æ¬¡çš„åé¦ˆå…·æœ‰æé«˜çš„æ•°æ®æ•ˆç‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½æ¨¡å‹è®­ç»ƒçš„æ•°æ®éœ€æ±‚ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¯è¯»æ€§ã€å™äº‹è¿è´¯æ€§å’Œåˆ›é€ æ€§ç­‰æ–¹é¢çš„æå‡æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„¿ç«¥æ•™è‚²ã€åˆ›æ„å†™ä½œè¾…åŠ©ã€æ¸¸æˆå‰§æƒ…ç”Ÿæˆç­‰é¢†åŸŸã€‚é€šè¿‡äº¤äº’å¼å­¦ä¹ ï¼Œå¯ä»¥è®­ç»ƒå‡ºæ›´å…·åˆ›é€ åŠ›å’Œè¡¨è¾¾èƒ½åŠ›çš„å°å‹è¯­è¨€æ¨¡å‹ï¼Œä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„æ•…äº‹ç”ŸæˆæœåŠ¡ï¼Œå¹¶é™ä½æ¨¡å‹è®­ç»ƒçš„æˆæœ¬å’Œèµ„æºæ¶ˆè€—ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å¯¹è¯ç”Ÿæˆã€æ–‡æœ¬æ‘˜è¦ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Children efficiently acquire language not just by listening, but by interacting with others in their social environment. Conversely, large language models are typically trained with next-word prediction on massive amounts of text. Motivated by this contrast, we investigate whether language models can be trained with less data by learning not only from next-word prediction but also from high-level, cognitively inspired feedback. We train a student model to generate stories, which a teacher model rates on readability, narrative coherence, and creativity. By varying the amount of pretraining before the feedback loop, we assess the impact of this interactive learning on formal and functional linguistic competence. We find that the high-level feedback is highly data efficient: With just 1 M words of input in interactive learning, storytelling skills can improve as much as with 410 M words of next-word prediction.

