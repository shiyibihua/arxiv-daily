---
layout: default
title: Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models
---

# Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16462" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16462v1</a>
  <a href="https://arxiv.org/pdf/2509.16462.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16462v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16462v1', 'Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: 'Mina Arzaghi', 'Alireza Dehghanpour Farashah', 'Florian Carichon', ' Golnoosh Farnadi'

**åˆ†ç±»**: cs.CL, cs.CY, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶LLMå†…å¤–éƒ¨å…¬å¹³æ€§ï¼šåå·®ç¼“è§£å¯¹ä¸‹æ¸¸ä»»åŠ¡çš„å½±å“è¯„ä¼°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§` `åå·®ç¼“è§£` `æ¦‚å¿µè§£å­¦ä¹ ` `åäº‹å®æ•°æ®å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†ç†è§£LLMå†…åœ¨åè§ä¸ä¸‹æ¸¸ä»»åŠ¡å…¬å¹³æ€§ä¹‹é—´çš„è”ç³»ï¼Œç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ã€‚
2. è®ºæ–‡æå‡ºç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¯”è¾ƒæ¦‚å¿µè§£å­¦ä¹ ï¼ˆå†…åœ¨ï¼‰å’Œåäº‹å®æ•°æ®å¢å¼ºï¼ˆå¤–åœ¨ï¼‰ä¸¤ç§åå·®ç¼“è§£æ–¹æ³•ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå†…åœ¨åå·®ç¼“è§£èƒ½æ˜¾è‘—é™ä½LLMçš„æ€§åˆ«åè§ï¼Œå¹¶æå‡ä¸‹æ¸¸ä»»åŠ¡çš„å…¬å¹³æ€§ï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¡¨ç°å‡ºç¤¾ä¼šç»æµåè§ï¼Œè¿™äº›åè§ä¼šä¼ æ’­åˆ°ä¸‹æ¸¸ä»»åŠ¡ä¸­ã€‚å…ˆå‰çš„ç ”ç©¶è´¨ç–‘äº†LLMä¸­çš„å†…åœ¨åè§æ˜¯å¦ä¼šå½±å“ä¸‹æ¸¸ä»»åŠ¡å±‚é¢çš„å…¬å¹³æ€§ã€‚æœ¬æ–‡é€šè¿‡å®è¯ç ”ç©¶è°ƒæŸ¥äº†è¿™ç§è”ç³»ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºæ¯”è¾ƒé€šè¿‡æ¦‚å¿µè§£å­¦ä¹ è¿›è¡Œçš„å†…åœ¨åå·®ç¼“è§£ä¸é€šè¿‡åäº‹å®æ•°æ®å¢å¼ºï¼ˆCDAï¼‰è¿›è¡Œçš„å¤–åœ¨åå·®ç¼“è§£ã€‚æˆ‘ä»¬é€šè¿‡çœŸå®çš„é‡‘èåˆ†ç±»ä»»åŠ¡ï¼ˆåŒ…æ‹¬è–ªèµ„é¢„æµ‹ã€å°±ä¸šçŠ¶æ€å’Œä¿¡ç”¨è¯„ä¼°ï¼‰æ¥æ£€éªŒè¿™ç§å…³ç³»ã€‚ä½¿ç”¨ä¸‰ä¸ªå¼€æºLLMï¼Œæˆ‘ä»¬è¯„ä¼°äº†æ¨¡å‹ä½œä¸ºå†»ç»“åµŒå…¥æå–å™¨å’Œå¾®è°ƒåˆ†ç±»å™¨ä¸¤ç§æƒ…å†µã€‚ç»“æœè¡¨æ˜ï¼Œé€šè¿‡è§£å­¦ä¹ è¿›è¡Œçš„å†…åœ¨åå·®ç¼“è§£å¯å°†å†…åœ¨æ€§åˆ«åè§é™ä½é«˜è¾¾94.9%ï¼ŒåŒæ—¶æé«˜ä¸‹æ¸¸ä»»åŠ¡çš„å…¬å¹³æ€§æŒ‡æ ‡ï¼ˆä¾‹å¦‚äººå£å‡ç­‰æ€§ï¼‰é«˜è¾¾82%ï¼Œä¸”ä¸å½±å“å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ¡†æ¶ä¸ºç¼“è§£å·¥ä½œåœ¨ä½•å¤„æœ€æœ‰æ•ˆæä¾›äº†å®è·µæŒ‡å¯¼ï¼Œå¹¶å¼ºè°ƒäº†åœ¨ä¸‹æ¸¸éƒ¨ç½²ä¹‹å‰åº”ç”¨æ—©æœŸç¼“è§£çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­å­˜åœ¨çš„ç¤¾ä¼šç»æµåè§å¦‚ä½•å½±å“ä¸‹æ¸¸ä»»åŠ¡å…¬å¹³æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å…³æ³¨äºç‹¬ç«‹åœ°ç¼“è§£LLMçš„å†…åœ¨åè§æˆ–ä¸‹æ¸¸ä»»åŠ¡çš„åè§ï¼Œè€Œå¿½ç•¥äº†ä¸¤è€…ä¹‹é—´çš„è”ç³»ï¼Œç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶æ¥æ¯”è¾ƒä¸åŒçš„ç¼“è§£ç­–ç•¥ï¼Œå¹¶æŒ‡å¯¼å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œæ¯”è¾ƒå†…åœ¨åå·®ç¼“è§£ï¼ˆé€šè¿‡æ¦‚å¿µè§£å­¦ä¹ ï¼‰å’Œå¤–åœ¨åå·®ç¼“è§£ï¼ˆé€šè¿‡åäº‹å®æ•°æ®å¢å¼ºï¼‰å¯¹ä¸‹æ¸¸ä»»åŠ¡å…¬å¹³æ€§çš„å½±å“ã€‚é€šè¿‡è¿™ç§æ¯”è¾ƒï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£LLMçš„å†…åœ¨åè§å¦‚ä½•ä¼ æ’­åˆ°ä¸‹æ¸¸ä»»åŠ¡ï¼Œä»¥åŠå“ªç§ç¼“è§£ç­–ç•¥æ›´æœ‰æ•ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) é€‰æ‹©ä¸‰ä¸ªå¼€æºLLMä½œä¸ºåŸºç¡€æ¨¡å‹ï¼›2) ä½¿ç”¨æ¦‚å¿µè§£å­¦ä¹ æ–¹æ³•ç¼“è§£LLMçš„å†…åœ¨åè§ï¼›3) ä½¿ç”¨åäº‹å®æ•°æ®å¢å¼ºæ–¹æ³•ç¼“è§£ä¸‹æ¸¸ä»»åŠ¡çš„åè§ï¼›4) åœ¨çœŸå®çš„é‡‘èåˆ†ç±»ä»»åŠ¡ï¼ˆè–ªèµ„é¢„æµ‹ã€å°±ä¸šçŠ¶æ€ã€ä¿¡ç”¨è¯„ä¼°ï¼‰ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å’Œå…¬å¹³æ€§ï¼›5) æ¯”è¾ƒä¸åŒç¼“è§£ç­–ç•¥çš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°å†…åœ¨å’Œå¤–åœ¨åå·®ç¼“è§£ç­–ç•¥å¯¹ä¸‹æ¸¸ä»»åŠ¡å…¬å¹³æ€§çš„å½±å“ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡å®è¯ç ”ç©¶æ­ç¤ºäº†LLMçš„å†…åœ¨åè§ä¸ä¸‹æ¸¸ä»»åŠ¡å…¬å¹³æ€§ä¹‹é—´çš„è”ç³»ï¼Œå¹¶æä¾›äº†å…³äºå¦‚ä½•é€‰æ‹©åˆé€‚çš„ç¼“è§£ç­–ç•¥çš„å®è·µæŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†æ¦‚å¿µè§£å­¦ä¹ æ–¹æ³•æ¥ç¼“è§£LLMçš„å†…åœ¨åè§ï¼Œå…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚åäº‹å®æ•°æ®å¢å¼ºæ–¹æ³•é€šè¿‡ç”Ÿæˆä¸åŸå§‹æ•°æ®ç›¸ä¼¼ä½†å…·æœ‰ä¸åŒæ•æ„Ÿå±æ€§å€¼çš„æ•°æ®æ¥ç¼“è§£ä¸‹æ¸¸ä»»åŠ¡çš„åè§ã€‚å…¬å¹³æ€§æŒ‡æ ‡åŒ…æ‹¬äººå£å‡ç­‰æ€§ç­‰ã€‚å®éªŒä¸­ï¼Œæ¨¡å‹è¢«è¯„ä¼°ä¸ºå†»ç»“åµŒå…¥æå–å™¨å’Œå¾®è°ƒåˆ†ç±»å™¨ä¸¤ç§æƒ…å†µï¼Œä»¥å…¨é¢è¯„ä¼°ç¼“è§£ç­–ç•¥çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡æ¦‚å¿µè§£å­¦ä¹ è¿›è¡Œçš„å†…åœ¨åå·®ç¼“è§£å¯å°†LLMçš„å†…åœ¨æ€§åˆ«åè§é™ä½é«˜è¾¾94.9%ï¼ŒåŒæ—¶æé«˜ä¸‹æ¸¸ä»»åŠ¡çš„å…¬å¹³æ€§æŒ‡æ ‡ï¼ˆä¾‹å¦‚äººå£å‡ç­‰æ€§ï¼‰é«˜è¾¾82%ï¼Œä¸”ä¸å½±å“å‡†ç¡®æ€§ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨ä¸‹æ¸¸éƒ¨ç½²ä¹‹å‰åº”ç”¨æ—©æœŸç¼“è§£çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé‡‘èã€æ‹›è˜ç­‰é¢†åŸŸï¼Œå¸®åŠ©ä¼ä¸šæ„å»ºæ›´å…¬å¹³çš„AIç³»ç»Ÿã€‚é€šè¿‡åœ¨LLMéƒ¨ç½²å‰è¿›è¡Œæ—©æœŸåå·®ç¼“è§£ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½ç®—æ³•æ­§è§†çš„é£é™©ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ç¬¦åˆä¼¦ç†è§„èŒƒã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸå’Œæ¨¡å‹ï¼Œä¸ºæ„å»ºè´Ÿè´£ä»»çš„AIæä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) exhibit socio-economic biases that can propagate into downstream tasks. While prior studies have questioned whether intrinsic bias in LLMs affects fairness at the downstream task level, this work empirically investigates the connection. We present a unified evaluation framework to compare intrinsic bias mitigation via concept unlearning with extrinsic bias mitigation via counterfactual data augmentation (CDA). We examine this relationship through real-world financial classification tasks, including salary prediction, employment status, and creditworthiness assessment. Using three open-source LLMs, we evaluate models both as frozen embedding extractors and as fine-tuned classifiers. Our results show that intrinsic bias mitigation through unlearning reduces intrinsic gender bias by up to 94.9%, while also improving downstream task fairness metrics, such as demographic parity by up to 82%, without compromising accuracy. Our framework offers practical guidance on where mitigation efforts can be most effective and highlights the importance of applying early-stage mitigation before downstream deployment.

