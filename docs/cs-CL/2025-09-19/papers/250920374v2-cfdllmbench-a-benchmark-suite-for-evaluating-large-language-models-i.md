---
layout: default
title: CFDLLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics
---

# CFDLLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20374" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20374v2</a>
  <a href="https://arxiv.org/pdf/2509.20374.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20374v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20374v2', 'CFDLLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nithin Somasekharan, Ling Yue, Yadi Cao, Weichao Li, Patrick Emami, Pochinapeddi Sai Bhargav, Anurag Acharya, Xingyu Xie, Shaowu Pan

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19 (æ›´æ–°: 2025-10-10)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/NREL-Theseus/cfdllmbench/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CFDLLMBenchï¼šç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨è®¡ç®—æµä½“åŠ¨åŠ›å­¦ä¸­åº”ç”¨èƒ½åŠ›çš„åŸºå‡†å¥—ä»¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¡ç®—æµä½“åŠ¨åŠ›å­¦` `å¤§è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•` `ç§‘å­¦è®¡ç®—` `è‡ªåŠ¨åŒ–` `æ•°å€¼æ¨¡æ‹Ÿ` `CFD` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥è‡ªåŠ¨åŒ–å¤æ‚ç‰©ç†ç³»ç»Ÿçš„æ•°å€¼å®éªŒï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰é¢†åŸŸï¼Œè¯¥é¢†åŸŸéœ€è¦ä¸“ä¸šçš„çŸ¥è¯†å’ŒæŠ€èƒ½ã€‚
2. CFDLLMBenché€šè¿‡æ„å»ºåŒ…å«CFDQueryã€CFDCodeBenchå’ŒFoamBenchä¸‰ä¸ªç»„ä»¶çš„åŸºå‡†å¥—ä»¶ï¼Œå…¨é¢è¯„ä¼°LLMåœ¨CFDé¢†åŸŸçš„åº”ç”¨èƒ½åŠ›ã€‚
3. è¯¥åŸºå‡†å¥—ä»¶åŸºäºçœŸå®CFDå®è·µï¼Œèƒ½å¤Ÿé‡åŒ–LLMåœ¨ä»£ç å¯æ‰§è¡Œæ€§ã€è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§å’Œæ•°å€¼æ”¶æ•›è¡Œä¸ºç­‰æ–¹é¢çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é€šç”¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬åœ¨è‡ªåŠ¨åŒ–å¤æ‚ç‰©ç†ç³»ç»Ÿæ•°å€¼å®éªŒä¸­çš„æ•ˆç”¨â€”â€”è¿™æ˜¯ä¸€ä¸ªå…³é”®ä¸”åŠ³åŠ¨å¯†é›†å‹çš„ç¯èŠ‚â€”â€”ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰ä½œä¸ºè¿‡å»å‡ åå¹´è®¡ç®—ç§‘å­¦çš„ä¸»è¦å·¥å…·ï¼Œä¸ºè¯„ä¼°LLMçš„ç§‘å­¦èƒ½åŠ›æä¾›äº†ä¸€ä¸ªç‹¬ç‰¹çš„æŒ‘æˆ˜æ€§è¯•éªŒå°ã€‚æˆ‘ä»¬æ¨å‡ºäº†CFDLLMBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªäº’è¡¥ç»„ä»¶çš„åŸºå‡†å¥—ä»¶â€”â€”CFDQueryã€CFDCodeBenchå’ŒFoamBenchâ€”â€”æ—¨åœ¨å…¨é¢è¯„ä¼°LLMåœ¨ä¸‰ä¸ªå…³é”®èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ï¼šç ”ç©¶ç”Ÿæ°´å¹³çš„CFDçŸ¥è¯†ã€CFDçš„æ•°å€¼å’Œç‰©ç†æ¨ç†ï¼Œä»¥åŠCFDå·¥ä½œæµç¨‹çš„ä¸Šä¸‹æ–‡ç›¸å…³å®ç°ã€‚æˆ‘ä»¬çš„åŸºå‡†åŸºäºçœŸå®çš„CFDå®è·µï¼Œå°†è¯¦ç»†çš„ä»»åŠ¡åˆ†ç±»ä¸ä¸¥æ ¼çš„è¯„ä¼°æ¡†æ¶ç›¸ç»“åˆï¼Œä»¥æä¾›å¯é‡ç°çš„ç»“æœï¼Œå¹¶é‡åŒ–LLMåœ¨ä»£ç å¯æ‰§è¡Œæ€§ã€è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§å’Œæ•°å€¼æ”¶æ•›è¡Œä¸ºæ–¹é¢çš„æ€§èƒ½ã€‚CFDLLMBenchä¸ºå¼€å‘å’Œè¯„ä¼°LLMé©±åŠ¨çš„å¤æ‚ç‰©ç†ç³»ç»Ÿæ•°å€¼å®éªŒè‡ªåŠ¨åŒ–å¥ å®šäº†åšå®çš„åŸºç¡€ã€‚ä»£ç å’Œæ•°æ®å¯åœ¨https://github.com/NREL-Theseus/cfdllmbench/è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è®¡ç®—æµä½“åŠ¨åŠ›å­¦ï¼ˆCFDï¼‰é¢†åŸŸçš„åº”ç”¨èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•åœ¨è‡ªåŠ¨åŒ–CFDæ•°å€¼å®éªŒæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå› ä¸ºCFDéœ€è¦æ·±åšçš„é¢†åŸŸçŸ¥è¯†ã€æ•°å€¼æ¨ç†èƒ½åŠ›å’Œä»£ç å®ç°èƒ½åŠ›ã€‚äººå·¥è¿›è¡ŒCFDå®éªŒè€—æ—¶è€—åŠ›ï¼Œä¸”å®¹æ˜“å‡ºé”™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå…¨é¢çš„åŸºå‡†å¥—ä»¶ï¼Œè¯¥å¥—ä»¶èƒ½å¤Ÿç³»ç»Ÿåœ°è¯„ä¼°LLMåœ¨CFDé¢†åŸŸçš„å…³é”®èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ä¸åŒç±»å‹çš„ä»»åŠ¡ï¼Œä¾‹å¦‚CFDçŸ¥è¯†é—®ç­”ã€ä»£ç ç”Ÿæˆå’Œå·¥ä½œæµç¨‹å®ç°ï¼Œæ¥è€ƒå¯ŸLLMåœ¨ä¸åŒæ–¹é¢çš„è¡¨ç°ã€‚è¿™æ ·å¯ä»¥æ›´å‡†ç¡®åœ°äº†è§£LLMåœ¨CFDé¢†åŸŸçš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCFDLLMBenchåŒ…å«ä¸‰ä¸ªä¸»è¦ç»„ä»¶ï¼šCFDQueryã€CFDCodeBenchå’ŒFoamBenchã€‚CFDQueryç”¨äºè¯„ä¼°LLMçš„CFDçŸ¥è¯†æ°´å¹³ï¼Œé€šè¿‡é—®ç­”å½¢å¼è¿›è¡Œã€‚CFDCodeBenchç”¨äºè¯„ä¼°LLMçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œè¦æ±‚LLMæ ¹æ®æè¿°ç”ŸæˆCFDä»£ç ç‰‡æ®µã€‚FoamBenchç”¨äºè¯„ä¼°LLMåœ¨å®é™…CFDå·¥ä½œæµç¨‹ä¸­çš„åº”ç”¨èƒ½åŠ›ï¼Œä¾‹å¦‚è®¾ç½®ä»¿çœŸå‚æ•°ã€è¿è¡Œä»¿çœŸå’Œåˆ†æç»“æœã€‚è¿™ä¸‰ä¸ªç»„ä»¶ç›¸äº’è¡¥å……ï¼Œå…±åŒæ„æˆä¸€ä¸ªå®Œæ•´çš„è¯„ä¼°ä½“ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªä¸“é—¨é’ˆå¯¹CFDé¢†åŸŸçš„LLMè¯„ä¼°åŸºå‡†ã€‚ä¸ç°æœ‰çš„é€šç”¨LLMåŸºå‡†ä¸åŒï¼ŒCFDLLMBenchæ›´åŠ å…³æ³¨LLMåœ¨ç§‘å­¦è®¡ç®—é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶é’ˆå¯¹CFDçš„ç‰¹ç‚¹è®¾è®¡äº†ç›¸åº”çš„è¯„ä¼°ä»»åŠ¡ã€‚è¿™ä½¿å¾—è¯„ä¼°ç»“æœæ›´åŠ å…·æœ‰é’ˆå¯¹æ€§å’Œå‚è€ƒä»·å€¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨CFDQueryä¸­ï¼Œé—®é¢˜æ¶µç›–äº†CFDçš„åŸºæœ¬æ¦‚å¿µã€æ–¹ç¨‹å’Œæ•°å€¼æ–¹æ³•ã€‚åœ¨CFDCodeBenchä¸­ï¼Œä»£ç ç”Ÿæˆä»»åŠ¡æ¶‰åŠä¸åŒçš„CFDç®—æ³•å’Œæ¨¡å‹ã€‚åœ¨FoamBenchä¸­ï¼Œå·¥ä½œæµç¨‹å®ç°ä»»åŠ¡æ¨¡æ‹Ÿäº†çœŸå®çš„CFDå®éªŒæµç¨‹ï¼Œä¾‹å¦‚ä½¿ç”¨OpenFOAMè¿›è¡Œä»¿çœŸã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬ä»£ç å¯æ‰§è¡Œæ€§ã€è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§å’Œæ•°å€¼æ”¶æ•›è¡Œä¸ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CFDLLMBenchåŸºå‡†å¥—ä»¶çš„æ¨å‡ºï¼Œä¸ºè¯„ä¼°LLMåœ¨CFDé¢†åŸŸçš„åº”ç”¨èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæ ‡å‡†åŒ–çš„å¹³å°ã€‚è¯¥åŸºå‡†å¥—ä»¶åŒ…å«å¤šç§ç±»å‹çš„ä»»åŠ¡ï¼Œèƒ½å¤Ÿå…¨é¢è¯„ä¼°LLMåœ¨CFDçŸ¥è¯†ã€ä»£ç ç”Ÿæˆå’Œå·¥ä½œæµç¨‹å®ç°ç­‰æ–¹é¢çš„è¡¨ç°ã€‚é€šè¿‡è¯¥åŸºå‡†å¥—ä»¶ï¼Œå¯ä»¥é‡åŒ–LLMåœ¨ä»£ç å¯æ‰§è¡Œæ€§ã€è§£å†³æ–¹æ¡ˆå‡†ç¡®æ€§å’Œæ•°å€¼æ”¶æ•›è¡Œä¸ºç­‰æ–¹é¢çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨åŒ–CFDå®éªŒæµç¨‹ï¼Œé™ä½CFDç ”ç©¶çš„é—¨æ§›ï¼ŒåŠ é€Ÿæ–°è®¾è®¡å’Œæ–°æŠ€æœ¯çš„å¼€å‘ã€‚é€šè¿‡åˆ©ç”¨LLMçš„å¼ºå¤§èƒ½åŠ›ï¼Œå¯ä»¥å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜CFDä»¿çœŸçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†å¥—ä»¶å¯ä»¥ä¿ƒè¿›LLMåœ¨ç§‘å­¦è®¡ç®—é¢†åŸŸçš„åº”ç”¨ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½ä¸ç§‘å­¦ç ”ç©¶çš„æ·±åº¦èåˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated strong performance across general NLP tasks, but their utility in automating numerical experiments of complex physical system -- a critical and labor-intensive component -- remains underexplored. As the major workhorse of computational science over the past decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging testbed for evaluating the scientific capabilities of LLMs. We introduce CFDLLMBench, a benchmark suite comprising three complementary components -- CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM performance across three key competencies: graduate-level CFD knowledge, numerical and physical reasoning of CFD, and context-dependent implementation of CFD workflows. Grounded in real-world CFD practices, our benchmark combines a detailed task taxonomy with a rigorous evaluation framework to deliver reproducible results and quantify LLM performance across code executability, solution accuracy, and numerical convergence behavior. CFDLLMBench establishes a solid foundation for the development and evaluation of LLM-driven automation of numerical experiments for complex physical systems. Code and data are available at https://github.com/NREL-Theseus/cfdllmbench/.

