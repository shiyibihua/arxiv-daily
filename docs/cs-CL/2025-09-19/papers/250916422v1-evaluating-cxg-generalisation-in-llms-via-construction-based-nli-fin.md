---
layout: default
title: Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning
---

# Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16422" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16422v1</a>
  <a href="https://arxiv.org/pdf/2509.16422.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16422v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16422v1', 'Evaluating CxG Generalisation in LLMs via Construction-Based NLI Fine Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tom Mackintosh, Harish Tayyar Madabushi, Claire Bonial

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºConTest-NLIåŸºå‡†ï¼Œè¯„ä¼°LLMåœ¨åŸºäºæ„å¼è¯­æ³•çš„NLIæ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ„å¼è¯­æ³•` `è‡ªç„¶è¯­è¨€æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ€§æ•°æ®` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å­¦ä¹ æ·±å±‚å½¢å¼-æ„ä¹‰æ˜ å°„æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æ„å¼è¯­æ³•æ—¶ã€‚
2. è®ºæ–‡æå‡ºConTest-NLIåŸºå‡†ï¼Œé€šè¿‡ç”Ÿæˆå¯¹æŠ—æ€§NLIæ•°æ®æ¥è¯„ä¼°LLMçš„æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMåœ¨å¯¹æŠ—æ€§æ•°æ®ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œå¾®è°ƒåè™½æœ‰æå‡ä½†ä»å­˜åœ¨å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ—¨åœ¨æ¢ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å­¦ä¹ ç”±æ„å¼è¯­æ³•å®šä¹‰çš„æ·±å±‚å½¢å¼-æ„ä¹‰æ˜ å°„çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ConTest-NLIåŸºå‡†ï¼Œå®ƒåŒ…å«8ä¸‡ä¸ªå¥å­ï¼Œæ¶µç›–äº†ä»é«˜åº¦è¯æ±‡åŒ–åˆ°é«˜åº¦å›¾å¼çš„å…«ç§è‹±è¯­æ„å¼ã€‚æˆ‘ä»¬çš„æµç¨‹é€šè¿‡æ¨¡æ¿åŒ–å’Œæ¨¡å‹åœ¨ç¯è¿‡æ»¤ç”Ÿæˆå¤šæ ·åŒ–çš„åˆæˆNLIä¸‰å…ƒç»„ï¼Œå¹¶ç»“åˆäººå·¥éªŒè¯ï¼Œä»¥ç¡®ä¿æŒ‘æˆ˜æ€§å’Œæ ‡ç­¾å¯é æ€§ã€‚åœ¨é¢†å…ˆçš„LLMä¸Šçš„é›¶æ ·æœ¬æµ‹è¯•è¡¨æ˜ï¼Œè‡ªç„¶æ•°æ®ï¼ˆ88%ï¼‰å’Œå¯¹æŠ—æ•°æ®ï¼ˆ64%ï¼‰ä¹‹é—´çš„å‡†ç¡®ç‡ä¸‹é™äº†24%ï¼Œå…¶ä¸­å›¾å¼æ¨¡å¼è¢«è¯æ˜æ˜¯æœ€éš¾çš„ã€‚åœ¨ConTest-NLIçš„ä¸€ä¸ªå­é›†ä¸Šè¿›è¡Œå¾®è°ƒå¯äº§ç”Ÿé«˜è¾¾9%çš„æ”¹è¿›ï¼Œä½†æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†å½“å‰LLMä¸­ä»ç„¶å­˜åœ¨çš„æŠ½è±¡å·®è·ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶æ¥è¯„ä¼°åŸºäºæ„å¼çš„å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç†è§£å’Œæ³›åŒ–æ„å¼è¯­æ³•ï¼ˆConstruction Grammar, CxGï¼‰æ–¹é¢çš„èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹æ„å¼è¯­æ³•çš„ä¸“é—¨è¯„ä¼°åŸºå‡†ï¼Œéš¾ä»¥å‡†ç¡®è¡¡é‡LLMå¯¹æ·±å±‚å½¢å¼-æ„ä¹‰æ˜ å°„çš„å­¦ä¹ æ•ˆæœã€‚æ­¤å¤–ï¼Œç°æœ‰NLIæ•°æ®é›†å¯èƒ½æ— æ³•å……åˆ†è¦†ç›–æ„å¼è¯­æ³•çš„å„ç§æ¨¡å¼ï¼Œå¯¼è‡´LLMåœ¨å¤„ç†å¯¹æŠ—æ€§æˆ–å›¾å¼æ„å¼æ—¶è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ„å¼è¯­æ³•çš„NLIåŸºå‡†ï¼ˆConTest-NLIï¼‰ï¼Œå¹¶åˆ©ç”¨è¯¥åŸºå‡†æ¥è¯„ä¼°LLMçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ç”ŸæˆåŒ…å«ä¸åŒæ„å¼æ¨¡å¼çš„å¯¹æŠ—æ€§NLIæ•°æ®ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æ­ç¤ºLLMåœ¨ç†è§£æ·±å±‚è¯­ä¹‰å…³ç³»æ–¹é¢çš„ä¸è¶³ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨ConTest-NLIä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥æå‡LLMå¯¹æ„å¼è¯­æ³•çš„ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) å®šä¹‰ç›®æ ‡æ„å¼ï¼šé€‰æ‹©æ¶µç›–ä¸åŒæŠ½è±¡ç¨‹åº¦çš„è‹±è¯­æ„å¼ï¼Œä¾‹å¦‚â€œThe X-er the Y-erâ€ç­‰ã€‚2) ç”ŸæˆNLIä¸‰å…ƒç»„ï¼šåˆ©ç”¨æ¨¡æ¿åŒ–æ–¹æ³•å’Œæ¨¡å‹åœ¨ç¯è¿‡æ»¤ç”ŸæˆåŒ…å«å‰æã€å‡è®¾å’Œæ ‡ç­¾çš„NLIä¸‰å…ƒç»„ã€‚3) æ„å»ºConTest-NLIåŸºå‡†ï¼šå°†ç”Ÿæˆçš„NLIä¸‰å…ƒç»„æ•´ç†æˆæ•°æ®é›†ï¼Œå¹¶è¿›è¡Œäººå·¥éªŒè¯ä»¥ç¡®ä¿æ ‡ç­¾çš„å‡†ç¡®æ€§ã€‚4) è¯„ä¼°LLMï¼šåœ¨ConTest-NLIä¸Šè¿›è¡Œé›¶æ ·æœ¬æµ‹è¯•å’Œå¾®è°ƒï¼Œè¯„ä¼°LLMçš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ConTest-NLIåŸºå‡†ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ„å¼è¯­æ³•çš„NLIæ•°æ®é›†ã€‚ä¸ç°æœ‰çš„NLIæ•°æ®é›†ç›¸æ¯”ï¼ŒConTest-NLIæ›´ä¾§é‡äºè¯„ä¼°LLMå¯¹æ·±å±‚å½¢å¼-æ„ä¹‰æ˜ å°„çš„ç†è§£èƒ½åŠ›ï¼Œå¹¶åŒ…å«æ›´å¤šå¯¹æŠ—æ€§å’Œå›¾å¼æ„å¼ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§åŸºäºæ¨¡æ¿åŒ–å’Œæ¨¡å‹åœ¨ç¯è¿‡æ»¤çš„NLIæ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œå¯ä»¥é«˜æ•ˆåœ°ç”Ÿæˆé«˜è´¨é‡çš„å¯¹æŠ—æ€§æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨NLIæ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†æ¨¡æ¿åŒ–æ–¹æ³•ï¼Œæ ¹æ®é¢„å®šä¹‰çš„æ„å¼æ¨¡å¼ç”Ÿæˆå¥å­ã€‚ä¸ºäº†ç¡®ä¿æ•°æ®çš„è´¨é‡ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†æ¨¡å‹åœ¨ç¯è¿‡æ»¤æœºåˆ¶ï¼Œåˆ©ç”¨LLMå¯¹ç”Ÿæˆçš„å¥å­è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç­›é€‰å‡ºå…·æœ‰æŒ‘æˆ˜æ€§å’Œæ ‡ç­¾å¯é æ€§çš„æ•°æ®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¿›è¡Œäº†äººå·¥éªŒè¯ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ•°æ®çš„å‡†ç¡®æ€§ã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†æ ‡å‡†çš„NLIå¾®è°ƒæ–¹æ³•ï¼Œå¹¶æ¢ç´¢äº†ä¸åŒçš„å­¦ä¹ ç‡å’Œè®­ç»ƒç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ConTest-NLIåŸºå‡†ä¸Šï¼ŒLLMåœ¨è‡ªç„¶æ•°æ®ä¸Šçš„å‡†ç¡®ç‡ä¸º88%ï¼Œè€Œåœ¨å¯¹æŠ—æ€§æ•°æ®ä¸Šçš„å‡†ç¡®ç‡ä¸‹é™è‡³64%ï¼Œè¡¨æ˜LLMåœ¨å¤„ç†æ„å¼è¯­æ³•æ—¶å­˜åœ¨æ³›åŒ–é—®é¢˜ã€‚åœ¨ConTest-NLIçš„ä¸€ä¸ªå­é›†ä¸Šè¿›è¡Œå¾®è°ƒåï¼ŒLLMçš„å‡†ç¡®ç‡æé«˜äº†9%ï¼Œä½†ä»ç„¶å­˜åœ¨ä¸€å®šçš„å·®è·ï¼Œè¡¨æ˜å½“å‰LLMåœ¨æŠ½è±¡èƒ½åŠ›æ–¹é¢ä»æœ‰æå‡ç©ºé—´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰é¢†åŸŸçš„æ€§èƒ½ã€‚é€šè¿‡æé«˜LLMå¯¹æ„å¼è¯­æ³•çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶æ›´å¥½åœ°å¤„ç†å¤æ‚çš„è¯­ä¹‰å…³ç³»ï¼Œä»è€Œæé«˜å…¶åœ¨å„ç§NLPä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚æ­¤å¤–ï¼ŒConTest-NLIåŸºå‡†å¯ä»¥ä½œä¸ºè¯„ä¼°å’Œæ”¹è¿›LLMçš„é€šç”¨å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We probe large language models' ability to learn deep form-meaning mappings as defined by construction grammars. We introduce the ConTest-NLI benchmark of 80k sentences covering eight English constructions from highly lexicalized to highly schematic. Our pipeline generates diverse synthetic NLI triples via templating and the application of a model-in-the-loop filter. This provides aspects of human validation to ensure challenge and label reliability. Zero-shot tests on leading LLMs reveal a 24% drop in accuracy between naturalistic (88%) and adversarial data (64%), with schematic patterns proving hardest. Fine-tuning on a subset of ConTest-NLI yields up to 9% improvement, yet our results highlight persistent abstraction gaps in current LLMs and offer a scalable framework for evaluating construction-informed learning.

