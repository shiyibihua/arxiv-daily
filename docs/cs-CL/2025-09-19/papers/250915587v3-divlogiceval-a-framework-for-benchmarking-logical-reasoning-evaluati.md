---
layout: default
title: DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models
---

# DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15587" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15587v3</a>
  <a href="https://arxiv.org/pdf/2509.15587.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15587v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15587v3', 'DivLogicEval: A Framework for Benchmarking Logical Reasoning Evaluation in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tsz Ting Chung, Lemao Liu, Mo Yu, Dit-Yan Yeung

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19 (æ›´æ–°: 2025-09-26)

**å¤‡æ³¨**: Accepted by EMNLP 2025. Project Page: https://ttchungc.github.io/projects/divlogiceval/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DivLogicEvalï¼šç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†èƒ½åŠ›çš„æ–°åŸºå‡†æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `é€»è¾‘æ¨ç†` `åŸºå‡†æµ‹è¯•` `è‡ªç„¶è¯­è¨€å¤„ç†` `è¯„ä¼°æŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€»è¾‘æ¨ç†åŸºå‡†å­˜åœ¨è¯­è¨€å¤šæ ·æ€§ä¸è¶³å’Œåˆ†å¸ƒåå·®é—®é¢˜ï¼Œå¯¼è‡´å¯¹å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸å‡†ç¡®ã€‚
2. æå‡ºDivLogicEvalåŸºå‡†ï¼ŒåŒ…å«å¤šç§é™ˆè¿°çš„è‡ªç„¶è¯­å¥ï¼Œå¹¶è®¾è®¡æ–°çš„è¯„ä¼°æŒ‡æ ‡ä»¥å‡è½»åå·®å’Œéšæœºæ€§çš„å½±å“ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDivLogicEvalèƒ½æœ‰æ•ˆè¯„ä¼°é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨è¯¥åŸºå‡†ä¸Šçš„æ€§èƒ½è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç»å…¸é€»è¾‘åŸºå‡†DivLogicEvalï¼Œç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰åŸºå‡†å¯èƒ½æ··æ·†å¤šç§æ¨ç†æŠ€èƒ½ï¼Œä»è€Œå¯¹é€»è¾‘æ¨ç†æŠ€èƒ½çš„è¯„ä¼°ä¸å‡†ç¡®ã€‚åŒæ—¶ï¼Œç°æœ‰çš„é€»è¾‘æ¨ç†åŸºå‡†åœ¨è¯­è¨€å¤šæ ·æ€§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œå¹¶ä¸”å®ƒä»¬çš„åˆ†å¸ƒåç¦»äº†ç†æƒ³é€»è¾‘æ¨ç†åŸºå‡†çš„åˆ†å¸ƒï¼Œè¿™å¯èƒ½å¯¼è‡´æœ‰åå·®çš„è¯„ä¼°ç»“æœã€‚DivLogicEvalç”±ä»¥è¿åç›´è§‰çš„æ–¹å¼ç»„æˆçš„è‡ªç„¶è¯­å¥æ„æˆï¼ŒåŒ…å«å¤šç§é™ˆè¿°ã€‚ä¸ºäº†ç¡®ä¿æ›´å¯é çš„è¯„ä¼°ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å‡è½»LLMä¸­å›ºæœ‰çš„åå·®å’Œéšæœºæ€§çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDivLogicEvalä¸­çš„é—®é¢˜éœ€è¦ä¸€å®šç¨‹åº¦çš„é€»è¾‘æ¨ç†æ‰èƒ½å›ç­”ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒæµè¡Œçš„LLMåœ¨è¿›è¡Œé€»è¾‘æ¨ç†æ–¹é¢çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹é€»è¾‘æ¨ç†èƒ½åŠ›è¯„ä¼°åŸºå‡†å­˜åœ¨ä»¥ä¸‹ç—›ç‚¹ï¼šä¸€æ˜¯æ··æ‚äº†å¤šç§æ¨ç†æŠ€èƒ½ï¼Œæ— æ³•å•ç‹¬è¯„ä¼°é€»è¾‘æ¨ç†èƒ½åŠ›ï¼›äºŒæ˜¯è¯­è¨€å¤šæ ·æ€§ä¸è¶³ï¼Œæ— æ³•è¦†ç›–çœŸå®åœºæ™¯ï¼›ä¸‰æ˜¯æ•°æ®åˆ†å¸ƒå­˜åœ¨åå·®ï¼Œè¯„ä¼°ç»“æœå¯èƒ½ä¸å‡†ç¡®ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´çº¯ç²¹ã€æ›´å…·ä»£è¡¨æ€§çš„é€»è¾‘æ¨ç†è¯„ä¼°åŸºå‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŒ…å«å¤šç§é™ˆè¿°çš„è‡ªç„¶è¯­å¥æ•°æ®é›†ï¼Œè¿™äº›è¯­å¥ä»¥è¿åç›´è§‰çš„æ–¹å¼ç»„åˆï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°è€ƒå¯Ÿæ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚åŒæ—¶ï¼Œè®¾è®¡ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å‡è½»æ¨¡å‹ä¸­å›ºæœ‰çš„åå·®å’Œéšæœºæ€§å¯¹è¯„ä¼°ç»“æœçš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDivLogicEvalæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ•°æ®é›†æ„å»ºï¼šæ”¶é›†åŒ…å«å¤šç§é™ˆè¿°çš„è‡ªç„¶è¯­å¥ï¼Œå¹¶ä»¥è¿åç›´è§‰çš„æ–¹å¼ç»„åˆï¼›2) é—®é¢˜ç”Ÿæˆï¼šåŸºäºæ„å»ºçš„æ•°æ®é›†ç”Ÿæˆé€»è¾‘æ¨ç†é—®é¢˜ï¼›3) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹å›ç­”é—®é¢˜ï¼Œå¹¶ä½¿ç”¨æ–°çš„è¯„ä¼°æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªæ–°çš„é€»è¾‘æ¨ç†è¯„ä¼°åŸºå‡†DivLogicEvalï¼Œè¯¥åŸºå‡†æ›´çº¯ç²¹ã€æ›´å…·ä»£è¡¨æ€§ï¼›2) è®¾è®¡äº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¯ä»¥å‡è½»æ¨¡å‹åå·®å’Œéšæœºæ€§å¯¹è¯„ä¼°ç»“æœçš„å½±å“ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDivLogicEvalèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†æ„å»ºæ–¹é¢ï¼Œéœ€è¦ä»”ç»†é€‰æ‹©å’Œç»„åˆè¯­å¥ï¼Œä»¥ç¡®ä¿é—®é¢˜çš„éš¾åº¦å’ŒåŒºåˆ†åº¦ã€‚è¯„ä¼°æŒ‡æ ‡æ–¹é¢ï¼Œéœ€è¦è€ƒè™‘å¦‚ä½•é‡åŒ–æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¹¶å‡è½»åå·®å’Œéšæœºæ€§çš„å½±å“ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDivLogicEvalèƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ­ç¤ºäº†ä¸åŒæ¨¡å‹åœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„å·®å¼‚ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿å’Œæå‡å¹…åº¦ç­‰ä¿¡æ¯æœªåœ¨æ‘˜è¦ä¸­æåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤§è¯­è¨€æ¨¡å‹çš„è¯„æµ‹ä¸æ”¹è¿›ï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¹¶æŒ‡å¯¼æ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†ä¹Ÿå¯ç”¨äºè¯„ä¼°å…¶ä»–äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Logic reasoning in natural language has been recognized as an important measure of human intelligence for Large Language Models (LLMs). Popular benchmarks may entangle multiple reasoning skills and thus provide unfaithful evaluations on the logic reasoning skill. Meanwhile, existing logic reasoning benchmarks are limited in language diversity and their distributions are deviated from the distribution of an ideal logic reasoning benchmark, which may lead to biased evaluation results. This paper thereby proposes a new classical logic benchmark DivLogicEval, consisting of natural sentences composed of diverse statements in a counterintuitive way. To ensure a more reliable evaluation, we also introduce a new evaluation metric that mitigates the influence of bias and randomness inherent in LLMs. Through experiments, we demonstrate the extent to which logical reasoning is required to answer the questions in DivLogicEval and compare the performance of different popular LLMs in conducting logical reasoning.

