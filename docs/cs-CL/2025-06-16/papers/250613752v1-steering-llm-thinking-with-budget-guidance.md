---
layout: default
title: Steering LLM Thinking with Budget Guidance
---

# Steering LLM Thinking with Budget Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13752" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13752v1</a>
  <a href="https://arxiv.org/pdf/2506.13752.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13752v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13752v1', 'Steering LLM Thinking with Budget Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junyan Li, Wenshuo Zhao, Yang Zhang, Chuang Gan

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/UMass-Embodied-AGI/BudgetGuidance)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé¢„ç®—å¼•å¯¼æ–¹æ³•ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†æ§åˆ¶` `é¢„ç®—å¼•å¯¼` `Gammaåˆ†å¸ƒ` `æ€§èƒ½ä¼˜åŒ–` `æ•°å­¦åŸºå‡†` `é«˜æ•ˆæ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¸¸å¸¸äº§ç”Ÿå†—é•¿çš„æ¨ç†é“¾ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬è¿‡é«˜ä¸”æ€§èƒ½æå‡ä¸æˆæ¯”ä¾‹ã€‚
2. æœ¬æ–‡æå‡ºçš„é¢„ç®—å¼•å¯¼æ–¹æ³•é€šè¿‡å¼•å…¥è½»é‡çº§é¢„æµ‹å™¨ï¼Œæ§åˆ¶æ¨ç†é•¿åº¦è€Œä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»è€Œå®ç°é«˜æ•ˆæ¨ç†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé¢„ç®—å¼•å¯¼åœ¨MATH-500åŸºå‡†ä¸Šå®ç°äº†æœ€é«˜26%çš„å‡†ç¡®ç‡æå‡ï¼ŒåŒæ—¶åœ¨æ¨ç†æ ‡è®°ä½¿ç”¨ä¸Šæ˜¾è‘—é«˜æ•ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæ·±åº¦æ€è€ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é€šè¿‡å¹¿æ³›æ¨ç†æ¥æå‡æ€§èƒ½ï¼Œä½†è¿™ç§å†—é•¿çš„æ¨ç†å¹¶ä¸æ€»æ˜¯å¯å–ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´è¿‡é«˜çš„æ¨ç†æˆæœ¬ä¸ä¸æˆæ¯”ä¾‹çš„æ€§èƒ½æå‡ã€‚å› æ­¤ï¼Œåœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„æƒ…å†µä¸‹æ§åˆ¶æ¨ç†é•¿åº¦å˜å¾—å°¤ä¸ºé‡è¦ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„é¢„ç®—å¼•å¯¼æ–¹æ³•ï¼Œæ—¨åœ¨å¼•å¯¼LLMçš„æ¨ç†è¿‡ç¨‹æœå‘ç›®æ ‡é¢„ç®—ï¼Œè€Œæ— éœ€å¯¹LLMè¿›è¡Œå¾®è°ƒã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªè½»é‡çº§é¢„æµ‹å™¨ï¼Œåœ¨ä¸‹ä¸€ä¸ªæ ‡è®°ç”Ÿæˆè¿‡ç¨‹ä¸­å¯¹å‰©ä½™æ€è€ƒé•¿åº¦å»ºæ¨¡Gammaåˆ†å¸ƒï¼Œå¹¶ä»¥è½¯æ€§ã€æ ‡è®°çº§çš„æ–¹å¼å¼•å¯¼ç”Ÿæˆï¼Œç¡®ä¿æ•´ä½“æ¨ç†è½¨è¿¹ç¬¦åˆæŒ‡å®šçš„æ€è€ƒé¢„ç®—ã€‚é¢„ç®—å¼•å¯¼åœ¨æŒ‘æˆ˜æ€§æ•°å­¦åŸºå‡†ä¸Šæ˜¾è‘—æé«˜äº†æ ‡è®°æ•ˆç‡ï¼Œä¾‹å¦‚åœ¨MATH-500åŸºå‡†ä¸Šï¼Œåœ¨ç´§å¼ é¢„ç®—ä¸‹ç›¸æ¯”åŸºçº¿æ–¹æ³•å®ç°äº†æœ€é«˜26%çš„å‡†ç¡®ç‡æå‡ï¼ŒåŒæ—¶ä»…ä½¿ç”¨å…¨æ€è€ƒæ¨¡å‹63%çš„æ€è€ƒæ ‡è®°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ¨ç†é•¿åº¦è¿‡é•¿çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ§åˆ¶æ¨ç†é•¿åº¦æ—¶å¾€å¾€æ— æ³•å…¼é¡¾æ€§èƒ½ä¸æ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºé¢„ç®—å¼•å¯¼æ–¹æ³•ï¼Œé€šè¿‡å»ºæ¨¡å‰©ä½™æ€è€ƒé•¿åº¦çš„Gammaåˆ†å¸ƒï¼Œè½¯æ€§å¼•å¯¼æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿æ¨ç†è¿‡ç¨‹ç¬¦åˆé¢„è®¾çš„é¢„ç®—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªè½»é‡çº§çš„é¢„æµ‹å™¨å’Œç”Ÿæˆæ¨¡å—ï¼Œé¢„æµ‹å™¨è´Ÿè´£è®¡ç®—å‰©ä½™æ€è€ƒé•¿åº¦çš„åˆ†å¸ƒï¼Œè€Œç”Ÿæˆæ¨¡å—åˆ™æ ¹æ®è¯¥åˆ†å¸ƒå¼•å¯¼ä¸‹ä¸€ä¸ªæ ‡è®°çš„ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†é¢„ç®—å¼•å¯¼æœºåˆ¶ï¼Œä½¿å¾—æ¨ç†è¿‡ç¨‹èƒ½å¤Ÿåœ¨ä¸è¿›è¡Œæ¨¡å‹å¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œçµæ´»æ§åˆ¶æ¨ç†é•¿åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒGammaåˆ†å¸ƒçš„å‚æ•°é€šè¿‡å†å²æ¨ç†æ•°æ®è¿›è¡Œè®­ç»ƒï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºå¹³è¡¡æ¨ç†é•¿åº¦ä¸ç”Ÿæˆè´¨é‡ï¼Œç¡®ä¿åœ¨é¢„ç®—å†…å®ç°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé¢„ç®—å¼•å¯¼æ–¹æ³•åœ¨MATH-500åŸºå‡†ä¸Šå®ç°äº†æœ€é«˜26%çš„å‡†ç¡®ç‡æå‡ï¼ŒåŒæ—¶åœ¨æ¨ç†æ ‡è®°ä½¿ç”¨ä¸Šä»…ä¸ºå…¨æ€è€ƒæ¨¡å‹çš„63%ã€‚è¿™ä¸€æ˜¾è‘—çš„æ€§èƒ½æå‡è¡¨æ˜è¯¥æ–¹æ³•åœ¨æ§åˆ¶æ¨ç†é•¿åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€é‡‘èå’Œç§‘å­¦è®¡ç®—ç­‰éœ€è¦é«˜æ•ˆæ¨ç†çš„åœºæ™¯ã€‚é€šè¿‡ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼Œé¢„ç®—å¼•å¯¼æ–¹æ³•èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œæå‡æ¨¡å‹çš„å®é™…åº”ç”¨ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½åŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent deep-thinking large language models often reason extensively to improve performance, but such lengthy reasoning is not always desirable, as it incurs excessive inference costs with disproportionate performance gains. Controlling reasoning length without sacrificing performance is therefore important, but remains challenging, especially under tight thinking budgets. We propose budget guidance, a simple yet effective method for steering the reasoning process of LLMs toward a target budget without requiring any LLM fine-tuning. Our approach introduces a lightweight predictor that models a Gamma distribution over the remaining thinking length during next-token generation. This signal is then used to guide generation in a soft, token-level manner, ensuring that the overall reasoning trace adheres to the specified thinking budget. Budget guidance enables natural control of the thinking length, along with significant token efficiency improvements over baseline methods on challenging math benchmarks. For instance, it achieves up to a 26% accuracy gain on the MATH-500 benchmark under tight budgets compared to baseline methods, while maintaining competitive accuracy with only 63% of the thinking tokens used by the full-thinking model. Budget guidance also generalizes to broader task domains and exhibits emergent capabilities, such as estimating question difficulty. The source code is available at: https://github.com/UMass-Embodied-AGI/BudgetGuidance.

