---
layout: default
title: Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles
---

# Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13886" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13886v2</a>
  <a href="https://arxiv.org/pdf/2506.13886.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13886v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13886v2', 'Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Antara Raaghavi Bhattacharya, Isabel Papadimitriou, Kathryn Davidson, David Alvarez-Melis

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16 (æ›´æ–°: 2025-10-15)

**å¤‡æ³¨**: Accepted to EMNLP 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨è¯­è¨€æ¨¡å‹ä¸­è¯­è¨€ä¸æ•°å­¦æ¨ç†çš„äº¤äº’ä»¥è§£å†³æ•°å­—éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `æ•°å­¦æ¨ç†` `è·¨è¯­è¨€` `æ•°å­—ç³»ç»Ÿ` `éšå«ç»“æ„` `å®éªŒç ”ç©¶` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è·¨è¯­è¨€æ•°å­—ç³»ç»Ÿçš„è¯­è¨€-æ•°å­¦éš¾é¢˜æ—¶è¡¨ç°ä¸ä½³ï¼Œç¼ºä¹æœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡å®éªŒæ¢è®¨æ•°å­—çš„è¯­è¨€å’Œæ•°å­¦ç‰¹æ€§ï¼Œå¼ºè°ƒæ•°å­¦è¿ç®—ç¬¦çš„æ˜¾å¼æ ‡è®°å¯¹æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶å‘ç°ï¼Œåªæœ‰åœ¨æ•°å­¦è¿ç®—ç¬¦æ˜ç¡®æ ‡è®°çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ‰èƒ½æœ‰æ•ˆè§£å†³é—®é¢˜ï¼Œæ­ç¤ºäº†éšå«æ•°å­—ç»“æ„æ¨ç†çš„ç¼ºå¤±ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸åŒè¯­è¨€çš„æ•°å­—ç³»ç»Ÿåœ¨æ„é€ å’Œç»„åˆæ•°å­—æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚å°½ç®¡äººç±»èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹è¿™ç§å¤šæ ·æ€§ï¼Œä½†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†æ¶‰åŠè·¨è¯­è¨€æ•°å­—ç³»ç»Ÿçš„è¯­è¨€-æ•°å­¦éš¾é¢˜æ—¶è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡é€šè¿‡ä¸€ç³»åˆ—å®éªŒæ¢è®¨äº†LLMsåœ¨æ­¤ä»»åŠ¡ä¸­çš„å›°éš¾ï¼Œå‘ç°æ¨¡å‹åªæœ‰åœ¨æ•°å­¦è¿ç®—è¢«æ˜ç¡®æ ‡è®°æ—¶æ‰èƒ½æœ‰æ•ˆè§£å†³é—®é¢˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡æ¶ˆèå®éªŒåˆ†æäº†æ•°å­—æ„é€ å’Œç»„åˆçš„å„ä¸ªå‚æ•°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼ŒLLMsç¼ºä¹äººç±»åœ¨æ•°å­—ç†è§£ä¸­æ‰€å…·å¤‡çš„éšå«ç»“æ„æ¨ç†èƒ½åŠ›ï¼Œè¿™ä¸€å‘ç°ä¸ºå½“å‰æ¨ç†æ¨¡å‹çš„æŒ‘æˆ˜æä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ¶‰åŠä¸åŒè¯­è¨€æ•°å­—ç³»ç»Ÿçš„è¯­è¨€-æ•°å­¦éš¾é¢˜æ—¶çš„æ¨ç†èƒ½åŠ›ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†éšå«çš„æ•°å­—ç»“æ„ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å®éªŒåˆ†æè¯­è¨€å’Œæ•°å­¦åœ¨æ•°å­—æ„é€ ä¸­çš„äº¤äº’ä½œç”¨ï¼Œå¼ºè°ƒæ•°å­¦è¿ç®—ç¬¦çš„æ˜¾å¼æ ‡è®°å¯¹æ¨¡å‹æ¨ç†çš„é‡è¦æ€§ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ­ç¤ºæ¨¡å‹åœ¨éšå«ç»“æ„æ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªå®éªŒé˜¶æ®µï¼Œé¦–å…ˆæ˜¯å¯¹ä¸åŒè¯­è¨€æ•°å­—ç³»ç»Ÿçš„åˆ†æï¼Œç„¶åæ˜¯è®¾è®¡åŒ…å«æ˜¾å¼æ•°å­¦è¿ç®—ç¬¦çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæœ€åé€šè¿‡æ¶ˆèå®éªŒè¯„ä¼°å„å‚æ•°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ˜ç¡®æŒ‡å‡ºå¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ•°å­—æ—¶ç¼ºä¹å¯¹éšå«ç»“æ„çš„æ¨ç†èƒ½åŠ›ï¼Œè¿™ä¸äººç±»çš„æ¨ç†æ–¹å¼å­˜åœ¨æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„æ•°å­¦è¿ç®—ç¬¦æ ‡è®°ï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒåˆ†æäº†æ•°å­—æ„é€ å’Œç»„åˆçš„å‚æ•°è®¾ç½®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç¡®ä¿äº†å®éªŒç»“æœçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåªæœ‰åœ¨æ•°å­¦è¿ç®—ç¬¦è¢«æ˜ç¡®æ ‡è®°çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ‰èƒ½æœ‰æ•ˆè§£å†³è¯­è¨€-æ•°å­¦éš¾é¢˜ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†LLMsåœ¨éšå«æ•°å­—ç»“æ„æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€è¯­è¨€å­¦ä¹ å·¥å…·å’Œè·¨æ–‡åŒ–äº¤æµå¹³å°ã€‚é€šè¿‡æ”¹è¿›è¯­è¨€æ¨¡å‹åœ¨æ•°å­—æ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥æå‡å…¶åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„åº”ç”¨æ•ˆæœï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Across languages, numeral systems vary widely in how they construct and combine numbers. While humans consistently learn to navigate this diversity, large language models (LLMs) struggle with linguistic-mathematical puzzles involving cross-linguistic numeral systems, which humans can learn to solve successfully. We investigate why this task is difficult for LLMs through a series of experiments that untangle the linguistic and mathematical aspects of numbers in language. Our experiments establish that models cannot consistently solve such problems unless the mathematical operations in the problems are explicitly marked using known symbols ($+$, $\times$, etc., as in "twenty + three"). In further ablation studies, we probe how individual parameters of numeral construction and combination affect performance. While humans use their linguistic understanding of numbers to make inferences about the implicit compositional structure of numerals, LLMs seem to lack this notion of implicit numeral structure. We conclude that the ability to flexibly infer compositional rules from implicit patterns in human-scale data remains an open challenge for current reasoning models.

