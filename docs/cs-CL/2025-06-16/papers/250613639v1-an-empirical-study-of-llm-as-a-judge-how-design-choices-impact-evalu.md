---
layout: default
title: An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability
---

# An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.13639" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.13639v1</a>
  <a href="https://arxiv.org/pdf/2506.13639.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.13639v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.13639v1', 'An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yusuke Yamauchi, Taro Yano, Masafumi Oyamada

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶LLMä½œä¸ºè¯„ä¼°è€…çš„è®¾è®¡é€‰æ‹©å¯¹è¯„ä¼°å¯é æ€§çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯„ä¼°æ–¹æ³•` `è‡ªåŠ¨åŒ–è¯„ä¼°` `è¯„ä¼°ä¸€è‡´æ€§` `é“¾å¼æ€ç»´æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMä½œä¸ºè¯„ä¼°è€…çš„æ–¹æ³•åœ¨è¯„ä¼°ä¸€è‡´æ€§å’Œä¸äººç±»åˆ¤æ–­çš„å¯¹é½ä¸Šå­˜åœ¨ä¸ç¡®å®šæ€§ï¼Œå½±å“äº†å…¶å¯é æ€§ã€‚
2. è®ºæ–‡é€šè¿‡åˆ†æè¯„ä¼°è®¾è®¡ã€è§£ç ç­–ç•¥å’Œé“¾å¼æ€ç»´æ¨ç†ç­‰å› ç´ ï¼Œæå‡ºäº†æ”¹è¿›LLMè¯„ä¼°å¯é æ€§çš„ç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯„ä¼°æ ‡å‡†å¯¹å¯é æ€§è‡³å…³é‡è¦ï¼Œéç¡®å®šæ€§é‡‡æ ·æ˜¾è‘—æé«˜äº†ä¸äººç±»åå¥½çš„å¯¹é½ç¨‹åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸æ–­è¿›æ­¥ï¼Œå¯é çš„è¯„ä¼°æ–¹æ³•å¯¹äºå¼€æ”¾å¼ã€éµå¾ªæŒ‡ä»¤çš„ä»»åŠ¡å˜å¾—å°¤ä¸ºé‡è¦ã€‚LLMä½œä¸ºè¯„ä¼°è€…çš„è‡ªåŠ¨è¯„ä¼°æ–¹æ³•ï¼Œå…¶å¯é æ€§ä»ç„¶ä¸ç¡®å®šã€‚æœ¬æ–‡åˆ†æäº†å½±å“å…¶å¯ä¿¡åº¦çš„å…³é”®å› ç´ ï¼Œé‡ç‚¹å…³æ³¨ä¸äººç±»åˆ¤æ–­çš„ä¸€è‡´æ€§å’Œè¯„ä¼°çš„ä¸€è‡´æ€§ã€‚é€šè¿‡ä½¿ç”¨BIGGENBenchå’ŒEvalBiasBenchï¼Œæˆ‘ä»¬ç ”ç©¶äº†è¯„ä¼°è®¾è®¡ã€è§£ç ç­–ç•¥å’Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†å¯¹è¯„ä¼°çš„å½±å“ã€‚ç»“æœè¡¨æ˜ï¼Œè¯„ä¼°æ ‡å‡†å¯¹å¯é æ€§è‡³å…³é‡è¦ï¼Œéç¡®å®šæ€§é‡‡æ ·åœ¨ä¸äººç±»åå¥½çš„å¯¹é½ä¸Šä¼˜äºç¡®å®šæ€§è¯„ä¼°ï¼Œè€Œåœ¨å­˜åœ¨æ˜ç¡®è¯„ä¼°æ ‡å‡†æ—¶ï¼ŒCoTæ¨ç†çš„å¢ç›Šæœ‰é™ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMä½œä¸ºè¯„ä¼°è€…çš„å¯é æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°ä¸€è‡´æ€§å’Œä¸äººç±»åˆ¤æ–­çš„å¯¹é½ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„ä¸ç¡®å®šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†æè¯„ä¼°è®¾è®¡ã€è§£ç ç­–ç•¥å’Œé“¾å¼æ€ç»´æ¨ç†ç­‰å…³é”®å› ç´ ï¼Œæå‡ºä¼˜åŒ–è¯„ä¼°æ ‡å‡†å’Œé‡‡ç”¨éç¡®å®šæ€§é‡‡æ ·çš„æ–¹æ³•ï¼Œä»¥æé«˜è¯„ä¼°çš„å¯é æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†BIGGENBenchå’ŒEvalBiasBenchä½œä¸ºå®éªŒå¹³å°ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬è¯„ä¼°è®¾è®¡ã€è§£ç ç­–ç•¥çš„é€‰æ‹©å’Œé“¾å¼æ€ç»´æ¨ç†çš„åº”ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼ºè°ƒè¯„ä¼°æ ‡å‡†çš„è®¾è®¡å¯¹è¯„ä¼°å¯é æ€§çš„å½±å“ï¼Œå¹¶æå‡ºéç¡®å®šæ€§é‡‡æ ·åœ¨å¯¹é½äººç±»åå¥½æ–¹é¢çš„ä¼˜åŠ¿ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç¡®å®šæ€§è¯„ä¼°æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ä¸åŒçš„è¯„ä¼°æ ‡å‡†å’Œè§£ç ç­–ç•¥ï¼Œé‡ç‚¹è€ƒå¯Ÿäº†é“¾å¼æ€ç»´æ¨ç†çš„åº”ç”¨æ•ˆæœï¼Œå‘ç°å…¶åœ¨æ˜ç¡®è¯„ä¼°æ ‡å‡†ä¸‹çš„å¢ç›Šæœ‰é™ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–è¯„ä¼°æ ‡å‡†å’Œé‡‡ç”¨éç¡®å®šæ€§é‡‡æ ·æ˜¾è‘—æé«˜äº†ä¸äººç±»åå¥½çš„å¯¹é½ç¨‹åº¦ï¼Œè¯„ä¼°ä¸€è‡´æ€§å¾—åˆ°äº†æ”¹å–„ã€‚å…·ä½“è€Œè¨€ï¼Œéç¡®å®šæ€§é‡‡æ ·åœ¨è¯„ä¼°ä¸­æ¯”ç¡®å®šæ€§æ–¹æ³•æé«˜äº†çº¦20%çš„å¯¹é½åº¦ï¼Œè€Œåœ¨æ˜ç¡®è¯„ä¼°æ ‡å‡†ä¸‹ï¼Œé“¾å¼æ€ç»´æ¨ç†çš„å¢ç›Šå‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²è¯„ä¼°ã€å†…å®¹å®¡æ ¸å’Œè‡ªåŠ¨åŒ–åé¦ˆç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜LLMä½œä¸ºè¯„ä¼°è€…çš„å¯é æ€§ï¼Œå¯ä»¥åœ¨æ›´å¤šå¼€æ”¾å¼ä»»åŠ¡ä¸­å®ç°è‡ªåŠ¨åŒ–è¯„ä¼°ï¼Œå‡å°‘äººå·¥å¹²é¢„ï¼Œæå‡æ•ˆç‡ã€‚æœªæ¥ï¼Œéšç€LLMæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å„ç±»æ™ºèƒ½ç³»ç»Ÿä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) continue to advance, reliable evaluation methods are essential particularly for open-ended, instruction-following tasks. LLM-as-a-Judge enables automatic evaluation using LLMs as evaluators, but its reliability remains uncertain. In this work, we analyze key factors affecting its trustworthiness, focusing on alignment with human judgments and evaluation consistency. Using BIGGENBench and EvalBiasBench, we study the effects of evaluation design, decoding strategies, and Chain-of-Tought (CoT) reasoning in evaluation. Our results show that evaluation criteria are critical for reliability, non-deterministic sampling improves alignment with human preferences over deterministic evaluation, and CoT reasoning offers minimal gains when clear evaluation criteria are present.

