---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-06-16
---

# cs.CLï¼ˆ2025-06-16ï¼‰

ğŸ“Š å…± **22** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (17 ğŸ”—2)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (17 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250614028v3-multifinben-benchmarking-large-language-models-for-multilingual-and-.html">MultiFinBen: Benchmarking Large Language Models for Multilingual and Multimodal Financial Application</a></td>
  <td>æå‡ºMultiFinBenä»¥è§£å†³å¤šè¯­è¨€å¤šæ¨¡æ€é‡‘èåˆ†æè¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14028v3" data-paper-url="./papers/250614028v3-multifinben-benchmarking-large-language-models-for-multilingual-and-.html" onclick="toggleFavorite(this, '2506.14028v3', 'MultiFinBen: Benchmarking Large Language Models for Multilingual and Multimodal Financial Application')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250613734v2-instruction-following-by-boosting-attention-of-large-language-models.html">Instruction Following by Boosting Attention of Large Language Models</a></td>
  <td>æå‡ºInstruction Attention Boostingä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è·Ÿéšèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13734v2" data-paper-url="./papers/250613734v2-instruction-following-by-boosting-attention-of-large-language-models.html" onclick="toggleFavorite(this, '2506.13734v2', 'Instruction Following by Boosting Attention of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250621580v1-from-general-reasoning-to-domain-expertise-uncovering-the-limits-of-.html">From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models</a></td>
  <td>æ¢è®¨å¤§è¯­è¨€æ¨¡å‹åœ¨é¢†åŸŸç‰¹å®šæ¨ç†ä¸­çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.21580v1" data-paper-url="./papers/250621580v1-from-general-reasoning-to-domain-expertise-uncovering-the-limits-of-.html" onclick="toggleFavorite(this, '2506.21580v1', 'From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250613472v2-rosaq-rotation-based-saliency-aware-weight-quantization-for-efficien.html">ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models</a></td>
  <td>æå‡ºROSAQä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹é‡åŒ–æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13472v2" data-paper-url="./papers/250613472v2-rosaq-rotation-based-saliency-aware-weight-quantization-for-efficien.html" onclick="toggleFavorite(this, '2506.13472v2', 'ROSAQ: Rotation-based Saliency-Aware Weight Quantization for Efficiently Compressing Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250613956v1-asmr-augmenting-life-scenario-using-large-generative-models-for-robo.html">ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection</a></td>
  <td>æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥å¢å¼ºæœºå™¨äººå¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13956v1" data-paper-url="./papers/250613956v1-asmr-augmenting-life-scenario-using-large-generative-models-for-robo.html" onclick="toggleFavorite(this, '2506.13956v1', 'ASMR: Augmenting Life Scenario using Large Generative Models for Robotic Action Reflection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250613639v1-an-empirical-study-of-llm-as-a-judge-how-design-choices-impact-evalu.html">An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability</a></td>
  <td>ç ”ç©¶LLMä½œä¸ºè¯„ä¼°è€…çš„è®¾è®¡é€‰æ‹©å¯¹è¯„ä¼°å¯é æ€§çš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13639v1" data-paper-url="./papers/250613639v1-an-empirical-study-of-llm-as-a-judge-how-design-choices-impact-evalu.html" onclick="toggleFavorite(this, '2506.13639v1', 'An Empirical Study of LLM-as-a-Judge: How Design Choices Impact Evaluation Reliability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250614046v1-ace-cefr-a-dataset-for-automated-evaluation-of-the-linguistic-diffic.html">Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications</a></td>
  <td>æå‡ºAce-CEFRæ•°æ®é›†ä»¥è§£å†³å¯¹è¯æ–‡æœ¬è¯­è¨€éš¾åº¦è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14046v1" data-paper-url="./papers/250614046v1-ace-cefr-a-dataset-for-automated-evaluation-of-the-linguistic-diffic.html" onclick="toggleFavorite(this, '2506.14046v1', 'Ace-CEFR -- A Dataset for Automated Evaluation of the Linguistic Difficulty of Conversational Texts for LLM Applications')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250614012v1-lost-in-the-mix-evaluating-llm-understanding-of-code-switched-text.html">Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text</a></td>
  <td>è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹å¯¹ä»£ç åˆ‡æ¢æ–‡æœ¬çš„ç†è§£èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14012v1" data-paper-url="./papers/250614012v1-lost-in-the-mix-evaluating-llm-understanding-of-code-switched-text.html" onclick="toggleFavorite(this, '2506.14012v1', 'Lost in the Mix: Evaluating LLM Understanding of Code-Switched Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250613886v2-investigating-the-interaction-of-linguistic-and-mathematical-reasoni.html">Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles</a></td>
  <td>æ¢è®¨è¯­è¨€æ¨¡å‹ä¸­è¯­è¨€ä¸æ•°å­¦æ¨ç†çš„äº¤äº’ä»¥è§£å†³æ•°å­—éš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13886v2" data-paper-url="./papers/250613886v2-investigating-the-interaction-of-linguistic-and-mathematical-reasoni.html" onclick="toggleFavorite(this, '2506.13886v2', 'Investigating the interaction of linguistic and mathematical reasoning in language models using multilingual number puzzles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250613752v1-steering-llm-thinking-with-budget-guidance.html">Steering LLM Thinking with Budget Guidance</a></td>
  <td>æå‡ºé¢„ç®—å¼•å¯¼æ–¹æ³•ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13752v1" data-paper-url="./papers/250613752v1-steering-llm-thinking-with-budget-guidance.html" onclick="toggleFavorite(this, '2506.13752v1', 'Steering LLM Thinking with Budget Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250613674v2-prefix-tuning-modernizing-prefix-tuning-by-decoupling-the-prefix-fro.html">Prefix-Tuning+: Modernizing Prefix-Tuning by Decoupling the Prefix from Attention</a></td>
  <td>æå‡ºPrefix-Tuning+ä»¥è§£å†³ä¼ ç»ŸPrefix-Tuningåœ¨LLMsä¸­çš„å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13674v2" data-paper-url="./papers/250613674v2-prefix-tuning-modernizing-prefix-tuning-by-decoupling-the-prefix-fro.html" onclick="toggleFavorite(this, '2506.13674v2', 'Prefix-Tuning+: Modernizing Prefix-Tuning by Decoupling the Prefix from Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250613641v1-evolvtrip-enhancing-literary-character-understanding-with-temporal-t.html">EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs</a></td>
  <td>æå‡ºEvolvTripä»¥å¢å¼ºæ–‡å­¦è§’è‰²ç†è§£èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13641v1" data-paper-url="./papers/250613641v1-evolvtrip-enhancing-literary-character-understanding-with-temporal-t.html" onclick="toggleFavorite(this, '2506.13641v1', 'EvolvTrip: Enhancing Literary Character Understanding with Temporal Theory-of-Mind Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250613541v1-mixture-of-weight-shared-heterogeneous-group-attention-experts-for-d.html">Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization</a></td>
  <td>æå‡ºmixSGAä»¥è§£å†³Transformeræ¨¡å‹åŠ¨æ€KVä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13541v1" data-paper-url="./papers/250613541v1-mixture-of-weight-shared-heterogeneous-group-attention-experts-for-d.html" onclick="toggleFavorite(this, '2506.13541v1', 'Mixture of Weight-shared Heterogeneous Group Attention Experts for Dynamic Token-wise KV Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250613514v1-tensorslm-energy-efficient-embedding-compression-of-sub-billion-para.html">TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices</a></td>
  <td>æå‡ºTensorSLMä»¥è§£å†³ä½ç«¯è®¾å¤‡ä¸Šè¯­è¨€æ¨¡å‹èƒ½æ•ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13514v1" data-paper-url="./papers/250613514v1-tensorslm-energy-efficient-embedding-compression-of-sub-billion-para.html" onclick="toggleFavorite(this, '2506.13514v1', 'TensorSLM: Energy-efficient Embedding Compression of Sub-billion Parameter Language Models on Low-end Devices')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250613479v1-position-pause-recycling-loras-and-prioritize-mechanisms-to-uncover-.html">Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness</a></td>
  <td>æå‡ºé‡ç”¨LoRAsçš„æœ‰æ•ˆæ€§åˆ†æä»¥è§£å†³æ¨¡å‹æ•´åˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13479v1" data-paper-url="./papers/250613479v1-position-pause-recycling-loras-and-prioritize-mechanisms-to-uncover-.html" onclick="toggleFavorite(this, '2506.13479v1', 'Position: Pause Recycling LoRAs and Prioritize Mechanisms to Uncover Limits and Effectiveness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250613470v2-abstract-align-predict-zero-shot-stance-detection-via-cognitive-indu.html">Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning</a></td>
  <td>æå‡ºCognitive Inductive Reasoningæ¡†æ¶ä»¥è§£å†³é›¶æ ·æœ¬ç«‹åœºæ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13470v2" data-paper-url="./papers/250613470v2-abstract-align-predict-zero-shot-stance-detection-via-cognitive-indu.html" onclick="toggleFavorite(this, '2506.13470v2', 'Abstract, Align, Predict: Zero-Shot Stance Detection via Cognitive Inductive Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250613464v2-unveiling-the-learning-mind-of-language-models-a-cognitive-framework.html">Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study</a></td>
  <td>æå‡ºè®¤çŸ¥æ¡†æ¶ä»¥æ­ç¤ºè¯­è¨€æ¨¡å‹çš„å­¦ä¹ èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13464v2" data-paper-url="./papers/250613464v2-unveiling-the-learning-mind-of-language-models-a-cognitive-framework.html" onclick="toggleFavorite(this, '2506.13464v2', 'Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250613888v1-vl-genrm-enhancing-vision-language-verification-via-vision-experts-a.html">VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training</a></td>
  <td>æå‡ºVL-GenRMä»¥è§£å†³è§†è§‰è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„åå·®é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13888v1" data-paper-url="./papers/250613888v1-vl-genrm-enhancing-vision-language-verification-via-vision-experts-a.html" onclick="toggleFavorite(this, '2506.13888v1', 'VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250613599v1-cams-a-citygpt-powered-agentic-framework-for-urban-human-mobility-si.html">CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation</a></td>
  <td>æå‡ºCAMSæ¡†æ¶ä»¥è§£å†³åŸå¸‚äººç±»ç§»åŠ¨æ¨¡æ‹Ÿä¸­çš„æ•°æ®é©±åŠ¨ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">DPO</span> <span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13599v1" data-paper-url="./papers/250613599v1-cams-a-citygpt-powered-agentic-framework-for-urban-human-mobility-si.html" onclick="toggleFavorite(this, '2506.13599v1', 'CAMS: A CityGPT-Powered Agentic Framework for Urban Human Mobility Simulation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250613502v2-bow-reinforcement-learning-for-bottlenecked-next-word-prediction.html">BOW: Reinforcement Learning for Bottlenecked Next Word Prediction</a></td>
  <td>æå‡ºBOWæ–¹æ³•ä»¥è§£å†³è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13502v2" data-paper-url="./papers/250613502v2-bow-reinforcement-learning-for-bottlenecked-next-word-prediction.html" onclick="toggleFavorite(this, '2506.13502v2', 'BOW: Reinforcement Learning for Bottlenecked Next Word Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250613474v1-language-agents-for-hypothesis-driven-clinical-decision-making-with-.html">Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå‡è®¾é©±åŠ¨çš„è¯­è¨€ä»£ç†ä»¥æå‡ä¸´åºŠå†³ç­–æ”¯æŒ</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13474v1" data-paper-url="./papers/250613474v1-language-agents-for-hypothesis-driven-clinical-decision-making-with-.html" onclick="toggleFavorite(this, '2506.13474v1', 'Language Agents for Hypothesis-driven Clinical Decision Making with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250613901v1-alignment-quality-index-aqi-beyond-refusals-aqi-as-an-intrinsic-alig.html">Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations</a></td>
  <td>æå‡ºAQIä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">RLHF</span> <span class="paper-tag">DPO</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.13901v1" data-paper-url="./papers/250613901v1-alignment-quality-index-aqi-beyond-refusals-aqi-as-an-intrinsic-alig.html" onclick="toggleFavorite(this, '2506.13901v1', 'Alignment Quality Index (AQI) : Beyond Refusals: AQI as an Intrinsic Alignment Diagnostic via Latent Geometry, Cluster Divergence, and Layer wise Pooled Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)