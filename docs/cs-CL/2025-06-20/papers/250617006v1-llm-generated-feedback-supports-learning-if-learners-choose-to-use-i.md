---
layout: default
title: LLM-Generated Feedback Supports Learning If Learners Choose to Use It
---

# LLM-Generated Feedback Supports Learning If Learners Choose to Use It

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17006" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17006v1</a>
  <a href="https://arxiv.org/pdf/2506.17006.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17006v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17006v1', 'LLM-Generated Feedback Supports Learning If Learners Choose to Use It')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Danielle R. Thomas, Conrad Borchers, Shambhavi Bhushan, Erin Gatz, Shivang Gupta, Kenneth R. Koedinger

**åˆ†ç±»**: cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Full research paper accepted at EC-TEL '25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶LLMç”Ÿæˆåé¦ˆå¯¹å­¦ä¹ çš„å½±å“åŠå…¶åº”ç”¨æ½œåŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å­¦ä¹ åé¦ˆ` `æ•™è‚²æŠ€æœ¯` `ä¸ªæ€§åŒ–å­¦ä¹ ` `å€¾å‘è¯„åˆ†æ³•` `å­¦ä¹ æ•ˆæœè¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åé¦ˆæ–¹æ³•å¯¹å­¦ä¹ çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨LLMç”Ÿæˆåé¦ˆçš„æƒ…å†µä¸‹ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åˆ†æå­¦ä¹ è€…å¯¹LLMç”Ÿæˆåé¦ˆçš„ä½¿ç”¨æƒ…å†µï¼Œæ¢è®¨å…¶å¯¹å­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œé‡‡ç”¨å€¾å‘è¯„åˆ†æ³•æ¥è§£å†³é€‰æ‹©åå·®é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå€¾å‘äºä½¿ç”¨LLMåé¦ˆçš„å­¦ä¹ è€…åœ¨åæµ‹ä¸­è¡¨ç°æ›´å¥½ï¼Œä¸”LLMåé¦ˆæœªæ˜¾è‘—å¢åŠ å®Œæˆæ—¶é—´ï¼Œå­¦ä¹ è€…æ™®éè®¤ä¸ºå…¶æœ‰å¸®åŠ©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆåé¦ˆæ–¹é¢çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œä½†å…¶å¯¹å­¦ä¹ çš„å½±å“ä»æœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚æœ¬ç ”ç©¶è€ƒå¯Ÿäº†æŒ‰éœ€ç”Ÿæˆçš„LLMè§£é‡Šæ€§åé¦ˆå¦‚ä½•å½±å“ä¸ƒä¸ªåŸºäºæƒ…å¢ƒçš„è¾…å¯¼åŸ¹è®­è¯¾ç¨‹çš„å­¦ä¹ ã€‚é€šè¿‡åˆ†æ885åè¾…å¯¼å­¦ä¹ è€…çš„2600å¤šä¸ªè¯¾ç¨‹å®Œæˆæƒ…å†µï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†ä¸‰ç»„å­¦ä¹ è€…çš„åæµ‹è¡¨ç°ï¼šæ¥å—gpt-3.5-turboç”Ÿæˆåé¦ˆçš„å­¦ä¹ è€…ã€æ‹’ç»åé¦ˆçš„å­¦ä¹ è€…ä»¥åŠæ²¡æœ‰è®¿é—®æƒé™çš„å­¦ä¹ è€…ã€‚ç»“æœæ˜¾ç¤ºï¼Œå€¾å‘äºä½¿ç”¨LLMåé¦ˆçš„å­¦ä¹ è€…åœ¨åæµ‹ä¸­å¾—åˆ†æ˜¾è‘—é«˜äºä¸å€¾å‘çš„å­¦ä¹ è€…ã€‚ç»è¿‡è°ƒæ•´åï¼Œä¸ƒä¸ªè¯¾ç¨‹ä¸­æœ‰ä¸¤ä¸ªæ˜¾ç¤ºå‡ºLLMåé¦ˆçš„ç»Ÿè®¡å­¦æ˜¾è‘—å­¦ä¹ æ•ˆç›Šï¼Œæ ‡å‡†åŒ–æ•ˆåº”å€¼ä¸º0.28å’Œ0.33ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMåé¦ˆçš„æœ‰æ•ˆæ€§ä¾èµ–äºå­¦ä¹ è€…å¯»æ±‚æ”¯æŒçš„å€¾å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³LLMç”Ÿæˆåé¦ˆå¯¹å­¦ä¹ æ•ˆæœçš„å½±å“å°šä¸æ˜ç¡®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨åé¦ˆç”Ÿæˆçš„æœ‰æ•ˆæ€§å’Œå­¦ä¹ è€…ä½¿ç”¨æ„æ„¿ä¸Šå­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹å­¦ä¹ è€…åœ¨ä½¿ç”¨LLMç”Ÿæˆåé¦ˆçš„å€¾å‘è¿›è¡Œåˆ†æï¼Œæ¢è®¨å…¶å¯¹å­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œé‡‡ç”¨å€¾å‘è¯„åˆ†æ³•æ¥æ§åˆ¶é€‰æ‹©åå·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ•°æ®æ”¶é›†ï¼ˆåˆ†æå­¦ä¹ è€…çš„è¯¾ç¨‹å®Œæˆæƒ…å†µï¼‰ã€åé¦ˆç”Ÿæˆï¼ˆä½¿ç”¨gpt-3.5-turboç”Ÿæˆåé¦ˆï¼‰å’Œæ•ˆæœè¯„ä¼°ï¼ˆæ¯”è¾ƒä¸åŒç»„å­¦ä¹ è€…çš„åæµ‹è¡¨ç°ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMç”Ÿæˆåé¦ˆå¯¹å­¦ä¹ æ•ˆæœçš„å½±å“ï¼Œå¹¶é€šè¿‡å€¾å‘è¯„åˆ†æ³•æ§åˆ¶é€‰æ‹©åå·®ï¼Œæä¾›äº†æ›´ä¸ºå‡†ç¡®çš„ç»“æœã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†æ ‡å‡†åŒ–æ•ˆåº”å€¼æ¥é‡åŒ–å­¦ä¹ æ•ˆæœï¼Œè®¾ç½®äº†ä¸åŒçš„åé¦ˆç»„ï¼Œå¹¶ç¡®ä¿æ‰€æœ‰ç»„å‡æ¥å—éLLMçš„çº æ­£åé¦ˆï¼Œä»¥ä¾¿è¿›è¡Œå…¬å¹³æ¯”è¾ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå€¾å‘äºä½¿ç”¨LLMåé¦ˆçš„å­¦ä¹ è€…åœ¨åæµ‹ä¸­å¾—åˆ†æ˜¾è‘—é«˜äºä¸å€¾å‘çš„å­¦ä¹ è€…ã€‚ç»è¿‡è°ƒæ•´åï¼Œä¸ƒä¸ªè¯¾ç¨‹ä¸­æœ‰ä¸¤ä¸ªè¯¾ç¨‹çš„å­¦ä¹ æ•ˆç›Šæ˜¾è‘—ï¼Œæ ‡å‡†åŒ–æ•ˆåº”å€¼åˆ†åˆ«ä¸º0.28å’Œ0.33ï¼Œè¡¨æ˜LLMåé¦ˆåœ¨ç‰¹å®šæƒ…å¢ƒä¸‹å…·æœ‰å®è´¨æ€§çš„å­¦ä¹ æå‡æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€åœ¨çº¿å­¦ä¹ å¹³å°å’Œä¸ªæ€§åŒ–å­¦ä¹ ç³»ç»Ÿã€‚LLMç”Ÿæˆçš„åé¦ˆå¯ä»¥ä½œä¸ºä¸€ç§ä½æˆæœ¬ã€å¯æ‰©å±•çš„æ–¹å¼ï¼Œå¸®åŠ©å­¦ä¹ è€…åœ¨å¼€æ”¾æ€§ä»»åŠ¡ä¸­è·å¾—æ›´å¥½çš„å­¦ä¹ æ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨å·²æœ‰åé¦ˆæœºåˆ¶çš„ç³»ç»Ÿä¸­ã€‚æœªæ¥ï¼Œéšç€LLMæŠ€æœ¯çš„è¿›æ­¥ï¼Œå…¶åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨å‰æ™¯å°†æ›´åŠ å¹¿é˜”ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used to generate feedback, yet their impact on learning remains underexplored, especially compared to existing feedback methods. This study investigates how on-demand LLM-generated explanatory feedback influences learning in seven scenario-based tutor training lessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we compare posttest performance among learners across three groups: learners who received feedback generated by gpt-3.5-turbo, those who declined it, and those without access. All groups received non-LLM corrective feedback. To address potential selection bias-where higher-performing learners may be more inclined to use LLM feedback-we applied propensity scoring. Learners with a higher predicted likelihood of engaging with LLM feedback scored significantly higher at posttest than those with lower propensity. After adjusting for this effect, two out of seven lessons showed statistically significant learning benefits from LLM feedback with standardized effect sizes of 0.28 and 0.33. These moderate effects suggest that the effectiveness of LLM feedback depends on the learners' tendency to seek support. Importantly, LLM feedback did not significantly increase completion time, and learners overwhelmingly rated it as helpful. These findings highlight LLM feedback's potential as a low-cost and scalable way to improve learning on open-ended tasks, particularly in existing systems already providing feedback without LLMs. This work contributes open datasets, LLM prompts, and rubrics to support reproducibility.

