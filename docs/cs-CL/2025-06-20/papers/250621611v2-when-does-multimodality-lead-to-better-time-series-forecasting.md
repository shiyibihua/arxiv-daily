---
layout: default
title: When Does Multimodality Lead to Better Time Series Forecasting?
---

# When Does Multimodality Lead to Better Time Series Forecasting?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21611" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21611v2</a>
  <a href="https://arxiv.org/pdf/2506.21611.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21611v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21611v2', 'When Does Multimodality Lead to Better Time Series Forecasting?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiyuan Zhang, Boran Han, Haoyang Fang, Abdul Fatir Ansari, Shuai Zhang, Danielle C. Maddix, Cuixiong Hu, Andrew Gordon Wilson, Michael W. Mahoney, Hao Wang, Yan Liu, Huzefa Rangwala, George Karypis, Bernie Wang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿç ”ç©¶å¤šæ¨¡æ€åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„æœ‰æ•ˆæ€§ä¸æ¡ä»¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `æ—¶é—´åºåˆ—é¢„æµ‹` `æ¨¡å‹æ¶æ„` `æ•°æ®ç‰¹å¾` `é¢„æµ‹æ€§èƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€é›†æˆçš„æœ‰æ•ˆæ€§ä¸Šç¼ºä¹ç³»ç»Ÿæ€§ç ”ç©¶ï¼Œå¯¼è‡´å…¶åº”ç”¨æ•ˆæœä¸ç¡®å®šã€‚
2. è®ºæ–‡é€šè¿‡å¯¹æ¯”å¯¹é½å’Œæç¤ºä¸¤ç§å¤šæ¨¡æ€é¢„æµ‹æ–¹æ³•ï¼Œæ¢è®¨å…¶åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°å·®å¼‚ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¤šæ¨¡æ€çš„ä¼˜åŠ¿ä¾èµ–äºæ¨¡å‹æ¶æ„å’Œæ•°æ®ç‰¹å¾ï¼Œä¸”å¹¶éåœ¨æ‰€æœ‰æƒ…å†µä¸‹å‡æœ‰æ•ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå°†æ–‡æœ¬ä¿¡æ¯çº³å…¥åŸºç¡€æ¨¡å‹ä»¥è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹çš„å…´è¶£æ—¥ç›Šå¢é•¿ã€‚ç„¶è€Œï¼Œå°šä¸æ¸…æ¥šè¿™ç§å¤šæ¨¡æ€é›†æˆåœ¨ä½•ç§æ¡ä»¶ä¸‹èƒ½å¤ŸæŒç»­å¸¦æ¥æ”¶ç›Šã€‚æœ¬æ–‡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†è¿™ä¸€é—®é¢˜ï¼Œæ¶µç›–äº†16ä¸ªé¢„æµ‹ä»»åŠ¡çš„å¤šæ ·åŸºå‡†ï¼Œæ¶‰åŠå¥åº·ã€ç¯å¢ƒå’Œç»æµç­‰7ä¸ªé¢†åŸŸã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸¤ç§æµè¡Œçš„å¤šæ¨¡æ€é¢„æµ‹èŒƒå¼ï¼šåŸºäºå¯¹é½çš„æ–¹æ³•å’ŒåŸºäºæç¤ºçš„æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ï¼Œå¤šæ¨¡æ€çš„å¥½å¤„é«˜åº¦ä¾èµ–äºæ¡ä»¶ï¼Œè™½ç„¶åœ¨æŸäº›è®¾ç½®ä¸­ç¡®è®¤äº†æ”¶ç›Šï¼Œä½†è¿™äº›æ”¹è¿›å¹¶éåœ¨æ‰€æœ‰æ•°æ®é›†æˆ–æ¨¡å‹ä¸­æ™®éé€‚ç”¨ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºç†è§£å¤šæ¨¡æ€ä½•æ—¶èƒ½åŠ©åŠ›é¢„æµ‹ä»»åŠ¡æä¾›äº†ä¸¥è°¨çš„å®šé‡åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ä¿¡æ¯åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­æœ‰æ•ˆæ€§çš„å…·ä½“é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä¸åŒæ•°æ®é›†å’Œæ¨¡å‹ä¸Šçš„è¡¨ç°ä¸ä¸€è‡´ï¼Œç¼ºä¹ç³»ç»Ÿæ€§åˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§è¯„ä¼°å¯¹é½å’Œæç¤ºä¸¤ç§å¤šæ¨¡æ€é¢„æµ‹æ–¹æ³•ï¼Œåˆ†æå…¶åœ¨ä¸åŒæ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œä»¥æ­ç¤ºå¤šæ¨¡æ€é›†æˆçš„æ½œåœ¨ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¤šç§æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ï¼Œæ¶µç›–å¥åº·ã€ç¯å¢ƒå’Œç»æµç­‰é¢†åŸŸï¼Œæ¯”è¾ƒäº†ä¸¤ç§å¤šæ¨¡æ€æ–¹æ³•çš„æ•ˆæœï¼Œåˆ†æäº†æ¨¡å‹æ¶æ„å’Œæ•°æ®ç‰¹å¾å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†å¤šæ¨¡æ€é›†æˆçš„æ¡ä»¶ä¾èµ–æ€§ï¼Œæä¾›äº†æ•°æ®æ— å…³çš„è§è§£ï¼Œå¸®åŠ©ç†è§£ä½•æ—¶å¯ä»¥æœŸå¾…å¤šæ¨¡æ€æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼Œå¼ºè°ƒé«˜å®¹é‡æ–‡æœ¬æ¨¡å‹ä¸ç›¸å¯¹è¾ƒå¼±çš„æ—¶é—´åºåˆ—æ¨¡å‹çš„ç»“åˆï¼Œé‡‡ç”¨é€‚å½“çš„å¯¹é½ç­–ç•¥ï¼Œå¹¶ç¡®ä¿æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®ï¼Œç¡®ä¿æ–‡æœ¬ä¿¡æ¯èƒ½å¤Ÿæä¾›è¶…å‡ºæ—¶é—´åºåˆ—æœ¬èº«çš„è¡¥å……é¢„æµ‹ä¿¡å·ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼Œå¤šæ¨¡æ€æ–¹æ³•æ˜¾è‘—æå‡äº†é¢„æµ‹æ€§èƒ½ã€‚åœ¨æŸäº›ä»»åŠ¡ä¸­ï¼Œä½¿ç”¨å¤šæ¨¡æ€æ–¹æ³•çš„æ¨¡å‹æ€§èƒ½æå‡å¹…åº¦å¯è¾¾15%ä»¥ä¸Šï¼Œå°¤å…¶æ˜¯åœ¨æ–‡æœ¬ä¿¡æ¯èƒ½å¤Ÿæä¾›é¢å¤–é¢„æµ‹ä¿¡å·çš„æƒ…å†µä¸‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å¥åº·ç›‘æµ‹ã€ç¯å¢ƒå˜åŒ–é¢„æµ‹åŠç»æµè¶‹åŠ¿åˆ†æç­‰ã€‚é€šè¿‡æœ‰æ•ˆæ•´åˆæ–‡æœ¬ä¿¡æ¯ï¼Œèƒ½å¤Ÿæå‡æ—¶é—´åºåˆ—é¢„æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, there has been growing interest in incorporating textual information into foundation models for time series forecasting. However, it remains unclear whether and under what conditions such multimodal integration consistently yields gains. We systematically investigate these questions across a diverse benchmark of 16 forecasting tasks spanning 7 domains, including health, environment, and economics. We evaluate two popular multimodal forecasting paradigms: aligning-based methods, which align time series and text representations; and prompting-based methods, which directly prompt large language models for forecasting. Our findings reveal that the benefits of multimodality are highly condition-dependent. While we confirm reported gains in some settings, these improvements are not universal across datasets or models. To move beyond empirical observations, we disentangle the effects of model architectural properties and data characteristics, drawing data-agnostic insights that generalize across domains. Our findings highlight that on the modeling side, incorporating text information is most helpful given (1) high-capacity text models, (2) comparatively weaker time series models, and (3) appropriate aligning strategies. On the data side, performance gains are more likely when (4) sufficient training data is available and (5) the text offers complementary predictive signal beyond what is already captured from the time series alone. Our study offers a rigorous, quantitative foundation for understanding when multimodality can be expected to aid forecasting tasks, and reveals that its benefits are neither universal nor always aligned with intuition.

