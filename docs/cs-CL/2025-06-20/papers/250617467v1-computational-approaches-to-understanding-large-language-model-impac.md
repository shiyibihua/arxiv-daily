---
layout: default
title: Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems
---

# Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17467" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17467v1</a>
  <a href="https://arxiv.org/pdf/2506.17467.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17467v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17467v1', 'Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weixin Liang

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY, cs.HC, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Stanford CS PhD Dissertation

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹å¯¹å†™ä½œä¸ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿçš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `AIæ£€æµ‹å™¨` `å†™ä½œç”Ÿæ€` `å…¬å¹³æ€§é—®é¢˜` `ç®—æ³•æ–¹æ³•` `ç ”ç©¶åé¦ˆ` `å­¦æœ¯å‡ºç‰ˆ` `ä¿¡æ¯ä¼ æ’­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨AIæ£€æµ‹å™¨çš„åº”ç”¨ä¸­å¼•å…¥äº†ç³»ç»Ÿæ€§åè§ï¼Œå½±å“äº†éä¸»æµè¯­è¨€å˜ä½“çš„å†™ä½œè€…ï¼Œé€ æˆå…¬å¹³æ€§é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºäº†æ–°çš„äººå£çº§ç®—æ³•æ–¹æ³•ï¼Œç³»ç»Ÿæµ‹é‡LLMsåœ¨å¤šä¸ªå†™ä½œé¢†åŸŸçš„é‡‡ç”¨æƒ…å†µï¼Œæ­ç¤ºäº†AIè¾…åŠ©å†…å®¹çš„æ™®éæ€§ã€‚
3. é€šè¿‡å¤§è§„æ¨¡å®è¯åˆ†æï¼Œç ”ç©¶äº†LLMsåœ¨æä¾›ç ”ç©¶æ‰‹ç¨¿åé¦ˆæ–¹é¢çš„æ½œåŠ›ï¼Œå°¤å…¶å¯¹æ—©æœŸèŒä¸šç ”ç©¶äººå‘˜çš„æ”¯æŒä½œç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ”¹å˜æˆ‘ä»¬çš„å†™ä½œã€æ²Ÿé€šå’Œåˆ›é€ æ–¹å¼æ–¹é¢å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œå¯¼è‡´å…¶åœ¨ç¤¾ä¼šä¸­çš„å¿«é€Ÿæ™®åŠã€‚æœ¬è®ºæ–‡ç ”ç©¶äº†ä¸ªäººå’Œæœºæ„å¦‚ä½•é€‚åº”å’Œå‚ä¸è¿™ä¸€æ–°å…´æŠ€æœ¯ï¼Œä¸»è¦é€šè¿‡ä¸‰ä¸ªç ”ç©¶æ–¹å‘è¿›è¡Œæ¢è®¨ã€‚é¦–å…ˆï¼Œå±•ç¤ºäº†AIæ£€æµ‹å™¨çš„æœºæ„é‡‡ç”¨å¼•å…¥ç³»ç»Ÿæ€§åè§ï¼Œç‰¹åˆ«æ˜¯å¯¹éä¸»æµè¯­è¨€å˜ä½“çš„å†™ä½œè€…é€ æˆä¸åˆ©å½±å“ï¼Œçªæ˜¾äº†AIæ²»ç†ä¸­çš„å…¬å¹³æ€§é—®é¢˜ã€‚å…¶æ¬¡ï¼Œæå‡ºäº†æ–°çš„äººå£çº§ç®—æ³•æ–¹æ³•ï¼Œæµ‹é‡LLMsåœ¨å†™ä½œé¢†åŸŸçš„é€æ¸é‡‡ç”¨ï¼Œæ­ç¤ºäº†å­¦æœ¯åŒè¡Œè¯„å®¡ã€ç§‘å­¦å‡ºç‰ˆã€æ¶ˆè´¹è€…æŠ•è¯‰ã€ä¼ä¸šæ²Ÿé€šã€æ‹›è˜ä¿¡æ¯å’Œå›½é™…ç»„ç»‡æ–°é—»ç¨¿ä¸­AIè¾…åŠ©å†…å®¹çš„ä¸€è‡´æ¨¡å¼ã€‚æœ€åï¼Œé€šè¿‡å¤§è§„æ¨¡å®è¯åˆ†æï¼Œç ”ç©¶äº†LLMsåœ¨ç ”ç©¶æ‰‹ç¨¿åé¦ˆæ–¹é¢çš„èƒ½åŠ›ï¼Œä¸ºé¢ä¸´åŠæ—¶åé¦ˆéšœç¢çš„ç ”ç©¶äººå‘˜æä¾›äº†è§è§£ï¼Œå°¤å…¶æ˜¯æ—©æœŸèŒä¸šç ”ç©¶äººå‘˜å’Œèµ„æºåŒ®ä¹ç¯å¢ƒä¸­çš„ç ”ç©¶è€…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†™ä½œå’Œä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿä¸­çš„å½±å“ï¼Œå°¤å…¶æ˜¯AIæ£€æµ‹å™¨å¼•å‘çš„å…¬å¹³æ€§é—®é¢˜å’Œåé¦ˆè·å–éšœç¢ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘ä¸åŒè¯­è¨€å˜ä½“çš„å†™ä½œè€…æ‰€é¢ä¸´çš„ç³»ç»Ÿæ€§åè§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç®—æ³•æ–¹æ³•é‡åŒ–LLMsçš„é‡‡ç”¨æƒ…å†µï¼Œå¹¶åˆ†æå…¶å¯¹ä¸åŒå†™ä½œé¢†åŸŸçš„å½±å“ï¼Œç‰¹åˆ«å…³æ³¨éä¸»æµè¯­è¨€å˜ä½“çš„å†™ä½œè€…å’Œæ—©æœŸèŒä¸šç ”ç©¶äººå‘˜çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) AIæ£€æµ‹å™¨çš„åè§åˆ†æï¼›2) äººå£çº§ç®—æ³•æ–¹æ³•çš„è®¾è®¡ä¸å®æ–½ï¼›3) LLMsåœ¨ç ”ç©¶åé¦ˆä¸­çš„åº”ç”¨è¯„ä¼°ã€‚æ¯ä¸ªæ¨¡å—é€šè¿‡å®è¯æ•°æ®æ”¯æŒå…¶ç»“è®ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ç³»ç»Ÿæ€§çš„æ–¹æ³•æ¥é‡åŒ–LLMsçš„å½±å“ï¼Œå¹¶æ­ç¤ºäº†å…¶åœ¨ä¸åŒå†™ä½œé¢†åŸŸçš„æ™®éæ¨¡å¼ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç®—æ³•è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ•°æ®æºè¿›è¡Œäº¤å‰éªŒè¯ï¼Œä½¿ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ä»¥å¤„ç†ä¸åŒç±»å‹çš„æ–‡æœ¬æ•°æ®ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç¡®ä¿äº†ç»“æœçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAIæ£€æµ‹å™¨åœ¨ä¸åŒè¯­è¨€å˜ä½“å†™ä½œä¸­çš„åè§æ˜¾è‘—ï¼Œä¸”LLMsåœ¨å­¦æœ¯åŒè¡Œè¯„å®¡å’Œä¼ä¸šæ²Ÿé€šä¸­çš„åº”ç”¨é€æ¸æ™®åŠï¼ŒAIè¾…åŠ©å†…å®¹çš„æ¯”ä¾‹åœ¨ç›¸å…³é¢†åŸŸä¸­æå‡äº†çº¦30%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ç§‘ç ”å’Œä¼ä¸šæ²Ÿé€šç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ä¸åŒèƒŒæ™¯çš„å†™ä½œè€…æ›´å¥½åœ°åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæé«˜å†™ä½œæ•ˆç‡å’Œè´¨é‡ã€‚æœªæ¥ï¼Œéšç€LLMsçš„è¿›ä¸€æ­¥å‘å±•ï¼Œç ”ç©¶ç»“æœå°†å¯¹AIæ²»ç†å’Œå…¬å¹³æ€§é—®é¢˜çš„è®¨è®ºäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown significant potential to change how we write, communicate, and create, leading to rapid adoption across society. This dissertation examines how individuals and institutions are adapting to and engaging with this emerging technology through three research directions. First, I demonstrate how the institutional adoption of AI detectors introduces systematic biases, particularly disadvantaging writers of non-dominant language varieties, highlighting critical equity concerns in AI governance. Second, I present novel population-level algorithmic approaches that measure the increasing adoption of LLMs across writing domains, revealing consistent patterns of AI-assisted content in academic peer reviews, scientific publications, consumer complaints, corporate communications, job postings, and international organization press releases. Finally, I investigate LLMs' capability to provide feedback on research manuscripts through a large-scale empirical analysis, offering insights into their potential to support researchers who face barriers in accessing timely manuscript feedback, particularly early-career researchers and those from under-resourced settings.

