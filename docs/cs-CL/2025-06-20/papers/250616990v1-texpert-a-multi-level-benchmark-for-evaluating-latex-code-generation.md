---
layout: default
title: TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs
---

# TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16990" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16990v1</a>
  <a href="https://arxiv.org/pdf/2506.16990.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16990v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16990v1', 'TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sahil Kale, Vijaykant Nadadur

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Accepted to the SDProc Workshop @ ACL 2025

**æœŸåˆŠ**: Proceedings of the Fifth Workshop on Scholarly Document Processing (SDP 2025), pages 7-16, 2025

**DOI**: [10.18653/v1/2025.sdp-1.2](https://doi.org/10.18653/v1/2025.sdp-1.2)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/knowledge-verse-ai/TeXpert)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTeXpertåŸºå‡†ä»¥è¯„ä¼°LLMsåœ¨LaTeXä»£ç ç”Ÿæˆä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LaTeXç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸºå‡†è¯„ä¼°` `å¼€æºæ¨¡å‹` `ç§‘å­¦æ–‡æ¡£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯„ä¼°åŸºå‡†æœªèƒ½æœ‰æ•ˆè¡¡é‡LLMsåœ¨LaTeXä»£ç ç”Ÿæˆä¸­çš„èƒ½åŠ›ï¼Œå¯¼è‡´ç ”ç©¶ç¼ºä¹é’ˆå¯¹æ€§ã€‚
2. è®ºæ–‡æå‡ºäº†TeXpertåŸºå‡†æ•°æ®é›†ï¼ŒåŒ…å«å¤šå±‚æ¬¡çš„è‡ªç„¶è¯­è¨€æç¤ºï¼Œä¸“æ³¨äºç§‘å­¦æ–‡æ¡£çš„LaTeXä»£ç ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨LaTeXç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ä¸æ ‡å‡†åŸºå‡†ç›¸æ‚–ï¼Œä¸”å¼€æºæ¨¡å‹è¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

LaTeXå› å…¶åœ¨æ’ç‰ˆä¸Šçš„ç²¾ç¡®æ€§å’Œçµæ´»æ€§ï¼Œæˆä¸ºç§‘å­¦æ–‡æ¡£å‡†å¤‡çš„é»„é‡‘æ ‡å‡†ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä½¿ç”¨è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç”Ÿæˆå‡ºç‰ˆç‰©æ‰€éœ€ææ–™çš„æœºä¼šï¼Œä½†ç°æœ‰åŸºå‡†å®Œå…¨ç¼ºä¹å¯¹è¿™ä¸€èƒ½åŠ›çš„è¯„ä¼°ã€‚é€šè¿‡å¼•å…¥TeXpertï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«è‡ªç„¶è¯­è¨€æç¤ºçš„åŸºå‡†æ•°æ®é›†ï¼Œä¸“æ³¨äºç§‘å­¦æ–‡æ¡£å„ä¸ªç»„æˆéƒ¨åˆ†çš„LaTeXä»£ç ç”Ÿæˆï¼Œå¹¶å¯¹LLMsåœ¨æ­¤æ–¹é¢çš„è¡¨ç°è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œè¯†åˆ«å‡ºå¸¸è§çš„é”™è¯¯ç±»å‹ã€‚æˆ‘ä»¬çš„è¯„ä¼°æ˜¾ç¤ºï¼Œå°½ç®¡LLMsåœ¨æ ‡å‡†åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨LaTeXç”Ÿæˆä»»åŠ¡ä¸­å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼›å¼€æºæ¨¡å‹å¦‚DeepSeek v3å’ŒDeepSeek Coderåœ¨LaTeXä»»åŠ¡ä¸­ä¸é—­æºæ¨¡å‹ç«äº‰åŠ›å¼ºï¼›æ ¼å¼å’ŒåŒ…é”™è¯¯æ„å¤–æ™®éï¼Œè¡¨æ˜å¤§å¤šæ•°LLMsçš„è®­ç»ƒæ•°æ®é›†ä¸­ç¼ºä¹å¤šæ ·åŒ–çš„LaTeXç¤ºä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°LLMsç”ŸæˆLaTeXä»£ç èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰åŸºå‡†æ— æ³•åæ˜ LLMsåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºTeXpertåŸºå‡†æ•°æ®é›†ï¼Œæä¾›å¤šå±‚æ¬¡çš„è‡ªç„¶è¯­è¨€æç¤ºï¼Œé’ˆå¯¹ç§‘å­¦æ–‡æ¡£çš„ä¸åŒç»„æˆéƒ¨åˆ†è¿›è¡ŒLaTeXä»£ç ç”Ÿæˆçš„è¯„ä¼°ï¼Œä»¥æ­¤æ¥åˆ†æLLMsçš„æ€§èƒ½å’Œå¸¸è§é”™è¯¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€LLMsæ€§èƒ½è¯„ä¼°å’Œé”™è¯¯ç±»å‹åˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†æ¶µç›–ä¸åŒéš¾åº¦çš„ä»»åŠ¡ï¼Œè¯„ä¼°è¿‡ç¨‹åˆ™é€šè¿‡å¯¹æ¯”å¼€æºå’Œé—­æºæ¨¡å‹çš„è¡¨ç°æ¥è¿›è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šTeXpertåŸºå‡†çš„æå‡ºæ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå¡«è¡¥äº†LLMsåœ¨LaTeXç”Ÿæˆèƒ½åŠ›è¯„ä¼°æ–¹é¢çš„ç©ºç™½ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…·é’ˆå¯¹æ€§çš„è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œè®¾è®¡äº†å¤šå±‚æ¬¡çš„è‡ªç„¶è¯­è¨€æç¤ºï¼Œå¹¶åœ¨è¯„ä¼°ä¸­å…³æ³¨æ ¼å¼å’ŒåŒ…é”™è¯¯ç­‰ç»†èŠ‚ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ LLMsåœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨LaTeXç”Ÿæˆä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™ï¼Œå°¤å…¶åœ¨ä»»åŠ¡å¤æ‚åº¦å¢åŠ æ—¶ï¼Œè¡¨ç°ä¸æ ‡å‡†åŸºå‡†ç›¸æ‚–ã€‚å¼€æºæ¨¡å‹å¦‚DeepSeek v3å’ŒDeepSeek Coderåœ¨LaTeXä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾ç¤ºå‡ºä¸é—­æºæ¨¡å‹çš„ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œæ ¼å¼å’ŒåŒ…é”™è¯¯çš„æ™®éæ€§æç¤ºäº†è®­ç»ƒæ•°æ®é›†çš„å¤šæ ·æ€§ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å­¦æœ¯å‡ºç‰ˆã€æ•™è‚²å’Œç§‘ç ”æ–‡æ¡£è‡ªåŠ¨åŒ–ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜LLMsåœ¨LaTeXä»£ç ç”Ÿæˆä¸­çš„å‡†ç¡®æ€§ï¼Œå¯ä»¥æå¤§åœ°æå‡ç§‘ç ”äººå‘˜çš„å·¥ä½œæ•ˆç‡ï¼Œé™ä½æ–‡æ¡£å‡†å¤‡çš„é—¨æ§›ï¼Œæ¨åŠ¨ç§‘å­¦äº¤æµçš„ä¾¿åˆ©æ€§ä¸æ•ˆç‡ã€‚æœªæ¥ï¼ŒTeXpertåŸºå‡†å¯èƒ½æˆä¸ºè¯„ä¼°LLMsåœ¨æ–‡æ¡£ç”Ÿæˆä»»åŠ¡ä¸­çš„æ ‡å‡†å·¥å…·ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> LaTeX's precision and flexibility in typesetting have made it the gold standard for the preparation of scientific documentation. Large Language Models (LLMs) present a promising opportunity for researchers to produce publication-ready material using LaTeX with natural language instructions, yet current benchmarks completely lack evaluation of this ability. By introducing TeXpert, our benchmark dataset with natural language prompts for generating LaTeX code focused on components of scientific documents across multiple difficulty levels, we conduct an in-depth analysis of LLM performance in this regard and identify frequent error types. Our evaluation across open and closed-source LLMs highlights multiple key findings: LLMs excelling on standard benchmarks perform poorly in LaTeX generation with a significant accuracy drop-off as the complexity of tasks increases; open-source models like DeepSeek v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks; and formatting and package errors are unexpectedly prevalent, suggesting a lack of diverse LaTeX examples in the training datasets of most LLMs. Our dataset, code, and model evaluations are available at https://github.com/knowledge-verse-ai/TeXpert.

