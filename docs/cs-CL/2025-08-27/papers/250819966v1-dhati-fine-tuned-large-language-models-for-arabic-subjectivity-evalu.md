---
layout: default
title: Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation
---

# Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19966" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19966v1</a>
  <a href="https://arxiv.org/pdf/2508.19966.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19966v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19966v1', 'Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Slimane Bellaouar, Attia Nehar, Soumia Souffi, Mounia Bouameur

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 25 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDhati+ä»¥è§£å†³é˜¿æ‹‰ä¼¯è¯­ä¸»è§‚æ€§è¯„ä¼°æ•°æ®ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é˜¿æ‹‰ä¼¯è¯­å¤„ç†` `ä¸»è§‚æ€§åˆ†æ` `æ•°æ®é›†æ„å»º` `æ¨¡å‹å¾®è°ƒ` `æƒ…æ„Ÿåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é˜¿æ‹‰ä¼¯è¯­åœ¨ä¸»è§‚æ€§åˆ†æå·¥å…·å¼€å‘ä¸­é¢ä¸´æ•°æ®é›†ç¨€ç¼ºçš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆå¤„ç†ã€‚
2. æœ¬æ–‡é€šè¿‡æ„å»ºAraDhati+æ•°æ®é›†å¹¶å¾®è°ƒå¤šç§é˜¿æ‹‰ä¼¯è¯­æ¨¡å‹ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ä¸»è§‚æ€§è¯„ä¼°æ–¹æ³•ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨é˜¿æ‹‰ä¼¯è¯­ä¸»è§‚æ€§åˆ†ç±»ä¸­è¾¾åˆ°äº†97.79%çš„é«˜å‡†ç¡®ç‡ï¼Œæ˜¾è‘—æå‡äº†åˆ†ç±»æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é˜¿æ‹‰ä¼¯è¯­ä½œä¸ºä¸€ç§è¯­è¨€ä¸°å¯Œä¸”å½¢æ€å¤æ‚çš„è¯­è¨€ï¼Œé¢ä¸´èµ„æºä¸è¶³çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¸»è§‚æ€§åˆ†æå·¥å…·çš„å¼€å‘ä¸Šã€‚ç°æœ‰çš„å¤§å‹æ ‡æ³¨æ•°æ®é›†ç¨€ç¼ºï¼Œé™åˆ¶äº†ç›¸å…³å·¥å…·çš„å‡†ç¡®æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é˜¿æ‹‰ä¼¯è¯­æ–‡æœ¬ä¸»è§‚æ€§è¯„ä¼°æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆç°æœ‰æ•°æ®é›†æ„å»ºäº†å…¨é¢çš„æ•°æ®é›†AraDhati+ï¼Œå¹¶å¯¹å…ˆè¿›çš„é˜¿æ‹‰ä¼¯è¯­æ¨¡å‹ï¼ˆå¦‚XLM-RoBERTaã€AraBERTå’ŒArabianGPTï¼‰è¿›è¡Œäº†å¾®è°ƒï¼Œæœ€ç»ˆå®ç°äº†97.79%çš„ä¸»è§‚æ€§åˆ†ç±»å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨é˜¿æ‹‰ä¼¯è¯­å¤„ç†ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é˜¿æ‹‰ä¼¯è¯­ä¸»è§‚æ€§è¯„ä¼°ä¸­çš„æ•°æ®ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é˜¿æ‹‰ä¼¯è¯­æ–‡æœ¬æ—¶å‡†ç¡®æ€§è¾ƒä½ï¼Œç¼ºä¹è¶³å¤Ÿçš„æ ‡æ³¨æ•°æ®é›†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ•´åˆç°æœ‰çš„é˜¿æ‹‰ä¼¯è¯­æ•°æ®é›†ï¼ˆå¦‚ASTDã€LABRã€HARDå’ŒSANADï¼‰ï¼Œæ„å»ºä¸€ä¸ªæ–°çš„ç»¼åˆæ•°æ®é›†AraDhati+ï¼Œå¹¶å¯¹å¤šç§å…ˆè¿›çš„é˜¿æ‹‰ä¼¯è¯­æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»¥æé«˜ä¸»è§‚æ€§åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒã€ä»¥åŠé›†æˆå†³ç­–æ–¹æ³•ã€‚é¦–å…ˆï¼Œæ•´åˆå¤šä¸ªæ•°æ®é›†å½¢æˆAraDhati+ï¼›å…¶æ¬¡ï¼Œé€‰æ‹©XLM-RoBERTaã€AraBERTå’ŒArabianGPTç­‰æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼›æœ€åï¼Œé‡‡ç”¨é›†æˆæ–¹æ³•ç»“åˆå„æ¨¡å‹çš„ä¼˜åŠ¿ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†AraDhati+æ•°æ®é›†ï¼Œå¹¶é€šè¿‡å¾®è°ƒå¤šç§æ¨¡å‹å®ç°äº†é«˜æ•ˆçš„ä¸»è§‚æ€§åˆ†ç±»ï¼Œå…‹æœäº†é˜¿æ‹‰ä¼¯è¯­å¤„ç†ä¸­çš„èµ„æºä¸è¶³é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„è¶…å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä¸»è§‚æ€§åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜å‡†ç¡®ç‡ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨é˜¿æ‹‰ä¼¯è¯­ä¸»è§‚æ€§åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†97.79%çš„å‡†ç¡®ç‡ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨èµ„æºæœ‰é™æƒ…å†µä¸‹çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“åˆ†æã€æƒ…æ„Ÿåˆ†æå’Œå¸‚åœºè°ƒç ”ç­‰ã€‚é€šè¿‡æé«˜é˜¿æ‹‰ä¼¯è¯­æ–‡æœ¬çš„ä¸»è§‚æ€§è¯„ä¼°èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºç›¸å…³è¡Œä¸šæä¾›æ›´å‡†ç¡®çš„ç”¨æˆ·åé¦ˆå’Œå¸‚åœºè¶‹åŠ¿åˆ†æï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite its significance, Arabic, a linguistically rich and morphologically complex language, faces the challenge of being under-resourced. The scarcity of large annotated datasets hampers the development of accurate tools for subjectivity analysis in Arabic. Recent advances in deep learning and Transformers have proven highly effective for text classification in English and French. This paper proposes a new approach for subjectivity assessment in Arabic textual data. To address the dearth of specialized annotated datasets, we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and ArabianGPT) on AraDhati+ for effective subjectivity classification. Furthermore, we experimented with an ensemble decision approach to harness the strengths of individual models. Our approach achieves a remarkable accuracy of 97.79\,\% for Arabic subjectivity classification. Results demonstrate the effectiveness of the proposed approach in addressing the challenges posed by limited resources in Arabic language processing.

