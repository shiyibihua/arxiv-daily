---
layout: default
title: 11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis
---

# 11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20068" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20068v1</a>
  <a href="https://arxiv.org/pdf/2508.20068.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20068v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20068v1', '11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chengzu Li, Wenshan Wu, Huanyu Zhang, Qingtao Li, Zeyu Gao, Yan Xia, JosÃ© HernÃ¡ndez-Orallo, Ivan VuliÄ‡, Furu Wei

**åˆ†ç±»**: cs.CL, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 9 pages, 4 figures (22 pages, 7 figures, 7 tables including references and appendices)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º11Plus-Benchä»¥è¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„ç©ºé—´æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `è®¤çŸ¥ç§‘å­¦` `æ ‡å‡†åŒ–æµ‹è¯•` `ä¸“å®¶æ³¨é‡Š` `æ¨¡å‹è¯„ä¼°` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸Šç¼ºä¹ç³»ç»Ÿæ€§æ¡†æ¶ï¼Œéš¾ä»¥ä¸äººç±»è¡¨ç°è¿›è¡Œæœ‰æ•ˆæ¯”è¾ƒã€‚
2. æœ¬æ–‡æå‡º11Plus-BenchåŸºå‡†ï¼Œç»“åˆç°å®æ ‡å‡†æµ‹è¯•ä¸ä¸“å®¶æ³¨é‡Šï¼Œç³»ç»Ÿè¯„ä¼°MLLMsçš„ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡MLLMsåœ¨ç©ºé—´è®¤çŸ¥ä¸Šè¡¨ç°å‡ºæ—©æœŸè¿¹è±¡ï¼Œä½†å…¶å®ä¾‹çº§è¡¨ç°ä»ç„¶éšæœºï¼Œä¸äººç±»çš„å¯é¢„æµ‹æ€§å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨äººç±»è®¤çŸ¥è¿‡ç¨‹ä¸­ï¼Œç©ºé—´æ¨ç†ä¸æ„ŸçŸ¥å¯†åˆ‡ç›¸å…³ï¼Œä½†è¿™ä¸€å…³ç³»åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰çš„è¯„ä¼°ä¸­ä»æœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚å°½ç®¡è¿‘æœŸMLLMsåœ¨æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶äººç±»èˆ¬çš„ç©ºé—´è®¤çŸ¥èƒ½åŠ›ä»ç„¶æ˜¯ä¸€ä¸ªæœªè§£ä¹‹è°œã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿçš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥è¯„ä¼°æœ€å…ˆè¿›çš„MLLMsåœ¨ç©ºé—´æ¨ç†èƒ½åŠ›ä¸Šçš„è¡¨ç°ï¼Œå¹¶å¼•å…¥äº†11Plus-Benchï¼Œä¸€ä¸ªåŸºäºç°å®æ ‡å‡†ç©ºé—´èƒ½åŠ›æµ‹è¯•çš„é«˜è´¨é‡åŸºå‡†ã€‚è¯¥åŸºå‡†è¿˜æä¾›äº†æ„ŸçŸ¥å¤æ‚æ€§å’Œæ¨ç†è¿‡ç¨‹çš„ç»†ç²’åº¦ä¸“å®¶æ³¨é‡Šï¼Œæ”¯æŒå¯¹æ¨¡å‹è¡Œä¸ºçš„è¯¦ç»†å®ä¾‹çº§åˆ†æã€‚é€šè¿‡å¯¹14ä¸ªMLLMså’Œäººç±»è¯„ä¼°çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„MLLMså±•ç°å‡ºç©ºé—´è®¤çŸ¥çš„æ—©æœŸè¿¹è±¡ï¼Œå°½ç®¡ä¸äººç±»ç›¸æ¯”å­˜åœ¨è¾ƒå¤§æ€§èƒ½å·®è·ï¼Œä½†MLLMsçš„è®¤çŸ¥ç‰¹å¾ä¸äººç±»ç›¸ä¼¼ï¼Œè®¤çŸ¥åŠªåŠ›ä¸æ¨ç†ç›¸å…³å¤æ‚æ€§ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†èƒ½åŠ›è¯„ä¼°ä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰äººç±»çš„è®¤çŸ¥è¿‡ç¨‹ä¸æ¨¡å‹è¡¨ç°ä¹‹é—´çš„å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥11Plus-BenchåŸºå‡†ï¼Œç»“åˆæ ‡å‡†åŒ–ç©ºé—´èƒ½åŠ›æµ‹è¯•ä¸ä¸“å®¶æ³¨é‡Šï¼Œç³»ç»Ÿè¯„ä¼°MLLMsçš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œæ­ç¤ºå…¶ä¸äººç±»è®¤çŸ¥çš„ç›¸ä¼¼æ€§ä¸å·®å¼‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä¸“å®¶æ³¨é‡Šã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é˜¶æ®µä½¿ç”¨æ ‡å‡†åŒ–æµ‹è¯•ï¼Œä¸“å®¶æ³¨é‡Šé˜¶æ®µæä¾›ç»†ç²’åº¦çš„æ„ŸçŸ¥å¤æ‚æ€§ä¸æ¨ç†è¿‡ç¨‹åˆ†æï¼Œæ¨¡å‹è¯„ä¼°é˜¶æ®µå¯¹14ä¸ªMLLMsè¿›è¡Œç³»ç»Ÿæµ‹è¯•ï¼Œæœ€åé€šè¿‡ç»“æœåˆ†ææ€»ç»“æ¨¡å‹è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼š11Plus-BenchåŸºå‡†çš„å¼•å…¥æ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå®ƒé€šè¿‡ç»“åˆæ ‡å‡†åŒ–æµ‹è¯•ä¸ä¸“å®¶æ³¨é‡Šï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢è¯„ä¼°MLLMsç©ºé—´æ¨ç†èƒ½åŠ›çš„æ–°æ–¹æ³•ï¼ŒåŒºåˆ«äºä»¥å¾€å•ä¸€çš„æ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç»†ç²’åº¦çš„ä¸“å®¶æ³¨é‡Šæ¥è¯„ä¼°æ„ŸçŸ¥å¤æ‚æ€§ä¸æ¨ç†è¿‡ç¨‹ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§ä¸å‡†ç¡®æ€§ï¼ŒåŒæ—¶åœ¨æ¨¡å‹è¯„ä¼°ä¸­å¼•å…¥äº†å¤šæ ·åŒ–çš„æµ‹è¯•å®ä¾‹ï¼Œä»¥å¢å¼ºè¯„ä¼°çš„ä»£è¡¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„MLLMsåœ¨ç©ºé—´è®¤çŸ¥æ–¹é¢å±•ç°å‡ºæ—©æœŸè¿¹è±¡ï¼Œä½†ä¸äººç±»çš„è¡¨ç°ç›¸æ¯”ï¼Œå­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚å…·ä½“è€Œè¨€ï¼ŒMLLMsçš„è®¤çŸ¥åŠªåŠ›ä¸æ¨ç†å¤æ‚æ€§ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ï¼Œä½†å®ä¾‹çº§è¡¨ç°ä»ç„¶éšæœºï¼Œç¼ºä¹äººç±»çš„å¯é¢„æµ‹æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æœºå™¨äººå¯¼èˆªå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£MLLMsçš„ç©ºé—´æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä¸ºæ™ºèƒ½ç³»ç»Ÿçš„è®¾è®¡ä¸ä¼˜åŒ–æä¾›é‡è¦å‚è€ƒï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> For human cognitive process, spatial reasoning and perception are closely entangled, yet the nature of this interplay remains underexplored in the evaluation of multimodal large language models (MLLMs). While recent MLLM advancements show impressive performance on reasoning, their capacity for human-like spatial cognition remains an open question. In this work, we introduce a systematic evaluation framework to assess the spatial reasoning abilities of state-of-the-art MLLMs relative to human performance. Central to our work is 11Plus-Bench, a high-quality benchmark derived from realistic standardized spatial aptitude tests. 11Plus-Bench also features fine-grained expert annotations of both perceptual complexity and reasoning process, enabling detailed instance-level analysis of model behavior. Through extensive experiments across 14 MLLMs and human evaluation, we find that current MLLMs exhibit early signs of spatial cognition. Despite a large performance gap compared to humans, MLLMs' cognitive profiles resemble those of humans in that cognitive effort correlates strongly with reasoning-related complexity. However, instance-level performance in MLLMs remains largely random, whereas human correctness is highly predictable and shaped by abstract pattern complexity. These findings highlight both emerging capabilities and limitations in current MLLMs' spatial reasoning capabilities and provide actionable insights for advancing model design.

