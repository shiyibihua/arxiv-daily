---
layout: default
title: AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios
---

# AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19988" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19988v1</a>
  <a href="https://arxiv.org/pdf/2508.19988.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19988v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19988v1', 'AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lisa Alazraki, Lihu Chen, Ana Brassard, Joe Stacey, Hossein A. Rahmani, Marek Rei

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentCoMaä»¥è§£å†³æ··åˆå¸¸è¯†ä¸æ•°å­¦æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¸¸è¯†æ¨ç†` `æ•°å­¦æ¨ç†` `ç»„åˆåŸºå‡†` `æ¨¡å‹è¯„ä¼°` `å¯è§£é‡Šæ€§åˆ†æ` `äººæœºäº¤äº’` `æ™ºèƒ½åŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç»„åˆåŸºå‡†æµ‹è¯•é€šå¸¸åªå…³æ³¨å¸¸è¯†æˆ–æ•°å­¦æ¨ç†ï¼Œç¼ºä¹å¯¹ä¸¤è€…ç»“åˆçš„è¯„ä¼°ï¼Œå¯¼è‡´LLMsåœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†AgentCoMaåŸºå‡†ï¼Œè¦æ±‚æ¯ä¸ªä»»åŠ¡åŒæ—¶åŒ…å«å¸¸è¯†æ¨ç†å’Œæ•°å­¦æ¨ç†ï¼Œä»¥æ›´çœŸå®åœ°æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„ä»»åŠ¡éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ç»„åˆä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡å¹³å‡ä¸‹é™çº¦30%ï¼Œè€Œéä¸“å®¶äººç±»æ ‡æ³¨è€…çš„è¡¨ç°åˆ™ä¿æŒé«˜æ°´å¹³ï¼Œæ­ç¤ºäº†æ¨¡å‹çš„è„†å¼±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚çš„å¸¸è¯†å’Œæ•°å­¦é—®é¢˜ä¸Šå–å¾—äº†é«˜å‡†ç¡®ç‡ï¼Œä½†ç°æœ‰çš„ç»„åˆåŸºå‡†æµ‹è¯•é€šå¸¸åªå…³æ³¨å¸¸è¯†æˆ–æ•°å­¦æ¨ç†ã€‚æœ¬æ–‡æå‡ºäº†Agentic Commonsense and MathåŸºå‡†ï¼ˆAgentCoMaï¼‰ï¼Œæ¯ä¸ªç»„åˆä»»åŠ¡éƒ½éœ€è¦ä¸€ä¸ªå¸¸è¯†æ¨ç†æ­¥éª¤å’Œä¸€ä¸ªæ•°å­¦æ¨ç†æ­¥éª¤ã€‚æˆ‘ä»¬å¯¹61ä¸ªä¸åŒè§„æ¨¡ã€æ¨¡å‹å®¶æ—å’Œè®­ç»ƒç­–ç•¥çš„LLMsè¿›è¡Œäº†æµ‹è¯•ï¼Œå‘ç°LLMsé€šå¸¸èƒ½å¤Ÿå•ç‹¬è§£å†³è¿™ä¸¤ä¸ªæ­¥éª¤ï¼Œä½†å½“ä¸¤è€…ç»“åˆæ—¶ï¼Œå‡†ç¡®ç‡å¹³å‡ä¸‹é™çº¦30%ã€‚è¿™ä¸€æ€§èƒ½å·®è·æ˜¾è‘—é«˜äºä»¥å¾€ç»„åˆåŸºå‡†çš„ç»“æœã€‚æ­¤å¤–ï¼Œéä¸“å®¶äººç±»æ ‡æ³¨è€…åœ¨AgentCoMaä¸­èƒ½å¤Ÿä»¥åŒæ ·é«˜çš„å‡†ç¡®ç‡è§£å†³ç»„åˆé—®é¢˜åŠå…¶å•ç‹¬æ­¥éª¤ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†åœ¨æ··åˆç±»å‹ç»„åˆæ¨ç†ä¸­çš„æ¨¡å‹è„†å¼±æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„æ”¹è¿›æä¾›äº†æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç»„åˆåŸºå‡†æµ‹è¯•ä¸­ç¼ºä¹å¯¹å¸¸è¯†ä¸æ•°å­¦æ¨ç†ç»“åˆçš„è¯„ä¼°é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œå¾€å¾€åªå…³æ³¨å•ä¸€æ¨ç†ç±»å‹ï¼Œå¯¼è‡´LLMsåœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºAgentCoMaåŸºå‡†ï¼Œè®¾è®¡æ¯ä¸ªä»»åŠ¡åŒæ—¶åŒ…å«å¸¸è¯†æ¨ç†å’Œæ•°å­¦æ¨ç†æ­¥éª¤ï¼Œä»¥æ›´å¥½åœ°æ¨¡æ‹ŸçœŸå®åœºæ™¯ä¸­çš„å¤æ‚æ¨ç†éœ€æ±‚ã€‚é€šè¿‡è¿™ç§ç»„åˆï¼Œç ”ç©¶è€…èƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°LLMsçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’Œå¯è§£é‡Šæ€§åˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ä»»åŠ¡è®¾è®¡éƒ¨åˆ†åˆ›å»ºäº†åŒ…å«å¸¸è¯†ä¸æ•°å­¦æ¨ç†çš„ç»„åˆé—®é¢˜ï¼Œæ¨¡å‹è¯„ä¼°åˆ™å¯¹61ä¸ªä¸åŒçš„LLMsè¿›è¡Œæ€§èƒ½æµ‹è¯•ï¼Œå¯è§£é‡Šæ€§åˆ†æåˆ™é€šè¿‡ç¥ç»å…ƒæ¨¡å¼ã€æ³¨æ„åŠ›å›¾å’Œæˆå‘˜æ¨æ–­ç­‰æ–¹æ³•æ·±å…¥ç†è§£æ¨¡å‹è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†AgentCoMaåŸºå‡†ï¼Œå¼ºè°ƒäº†å¸¸è¯†ä¸æ•°å­¦æ¨ç†çš„ç»“åˆå¯¹LLMsæ€§èƒ½çš„å½±å“ã€‚è¿™ä¸€åŸºå‡†ä¸ä»…æ­ç¤ºäº†æ¨¡å‹çš„è„†å¼±æ€§ï¼Œè¿˜ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ¨¡å‹è§„æ¨¡å’Œè®­ç»ƒç­–ç•¥ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„å…·ä½“ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­æ˜ç¡®ï¼Œä½†å¯è§£é‡Šæ€§åˆ†æä½¿ç”¨äº†ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼å’Œæ³¨æ„åŠ›æœºåˆ¶ï¼Œä»¥æ¢è®¨æ¨¡å‹åœ¨ä¸åŒæ¨ç†æ­¥éª¤ä¸­çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ç»„åˆä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡å¹³å‡ä¸‹é™çº¦30%ï¼Œè€Œéä¸“å®¶äººç±»æ ‡æ³¨è€…çš„è¡¨ç°åˆ™ä¿æŒé«˜æ°´å¹³ï¼Œæ˜¾ç¤ºå‡ºæ¨¡å‹åœ¨å¤„ç†æ··åˆæ¨ç†æ—¶çš„è„†å¼±æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥çš„æ¨¡å‹æ”¹è¿›æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´æ™ºèƒ½çš„LLMsï¼Œä»¥åº”å¯¹å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ã€‚é€šè¿‡æ”¹è¿›æ¨¡å‹åœ¨æ··åˆæ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæœªæ¥å¯ä»¥æå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved high accuracy on complex commonsense and mathematical problems that involve the composition of multiple reasoning steps. However, current compositional benchmarks testing these skills tend to focus on either commonsense or math reasoning, whereas LLM agents solving real-world tasks would require a combination of both. In this work, we introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each compositional task requires a commonsense reasoning step and a math reasoning step. We test it on 61 LLMs of different sizes, model families, and training strategies. We find that LLMs can usually solve both steps in isolation, yet their accuracy drops by ~30% on average when the two are combined. This is a substantially greater performance gap than the one we observe in prior compositional benchmarks that combine multiple steps of the same reasoning type. In contrast, non-expert human annotators can solve the compositional questions and the individual steps in AgentCoMa with similarly high accuracy. Furthermore, we conduct a series of interpretability studies to better understand the performance gap, examining neuron patterns, attention maps and membership inference. Our work underscores a substantial degree of model brittleness in the context of mixed-type compositional reasoning and offers a test bed for future improvement.

