---
layout: default
title: Survey of Specialized Large Language Model
---

# Survey of Specialized Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19667" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19667v1</a>
  <a href="https://arxiv.org/pdf/2508.19667.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19667v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19667v1', 'Survey of Specialized Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenghan Yang, Ruiyu Zhao, Yang Liu, Ling Jiang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 9 pages, 1 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿè¯„ä¼°ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä»¥è§£å†³ä¸“ä¸šé¢†åŸŸåº”ç”¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹` `é¢†åŸŸåŸç”Ÿè®¾è®¡` `å¤šæ¨¡æ€èƒ½åŠ›` `å‚æ•°æ•ˆç‡` `ç”µå­å•†åŠ¡` `æ€§èƒ½è¯„ä¼°` `ä¸“ä¸šåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸“ä¸šåº”ç”¨ä¸­å­˜åœ¨æ€§èƒ½ä¸è¶³å’Œé€‚åº”æ€§å·®çš„é—®é¢˜ï¼Œéš¾ä»¥æ»¡è¶³ç‰¹å®šé¢†åŸŸçš„éœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„ç³»ç»Ÿè¯„ä¼°ï¼Œå¼ºè°ƒé¢†åŸŸåŸç”Ÿè®¾è®¡å’Œå¤šæ¨¡æ€èƒ½åŠ›çš„é›†æˆï¼Œä»¥æé«˜æ¨¡å‹çš„å‚æ•°æ•ˆç‡å’Œåº”ç”¨æ•ˆæœã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œä¸“ç”¨æ¨¡å‹åœ¨å¤šä¸ªé¢†åŸŸç‰¹å®šåŸºå‡†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—å’Œé‡‘èç­‰ä¸“ä¸šé¢†åŸŸã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•å·²ä»ç®€å•çš„é¢†åŸŸé€‚åº”è½¬å‘å¤æ‚çš„åŸç”Ÿæ¶æ„ï¼Œæ ‡å¿—ç€äººå·¥æ™ºèƒ½å‘å±•çš„èŒƒå¼è½¬å˜ã€‚æœ¬è°ƒæŸ¥ç³»ç»Ÿåœ°è€ƒå¯Ÿäº†åŒ»ç–—ã€é‡‘èã€æ³•å¾‹å’ŒæŠ€æœ¯é¢†åŸŸçš„è¿™ä¸€è¿›å±•ã€‚é™¤äº†ä¸“ç”¨LLMsçš„å¹¿æ³›åº”ç”¨å¤–ï¼ŒæŠ€æœ¯çªç ´å¦‚è¶…è¶Šå¾®è°ƒçš„é¢†åŸŸåŸç”Ÿè®¾è®¡ã€é€šè¿‡ç¨€ç–è®¡ç®—å’Œé‡åŒ–æé«˜å‚æ•°æ•ˆç‡ã€æ—¥ç›Šå¢å¼ºçš„å¤šæ¨¡æ€èƒ½åŠ›ç­‰ä¹Ÿè¢«åº”ç”¨äºè¿‘æœŸçš„LLMä»£ç†ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†è¿™äº›åˆ›æ–°å¦‚ä½•è§£å†³é€šç”¨LLMsåœ¨ä¸“ä¸šåº”ç”¨ä¸­çš„åŸºæœ¬å±€é™æ€§ï¼Œä¸“ç”¨æ¨¡å‹åœ¨é¢†åŸŸç‰¹å®šåŸºå‡†ä¸Šå§‹ç»ˆè¡¨ç°å‡ºæ€§èƒ½æå‡ã€‚è°ƒæŸ¥è¿›ä¸€æ­¥å¼ºè°ƒäº†å¯¹ç”µå­å•†åŠ¡é¢†åŸŸçš„å½±å“ï¼Œä»¥å¡«è¡¥è¯¥é¢†åŸŸçš„ç©ºç™½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸“ä¸šé¢†åŸŸåº”ç”¨ä¸­çš„å±€é™æ€§ï¼ŒåŒ…æ‹¬æ€§èƒ½ä¸è¶³å’Œé€‚åº”æ€§å·®ç­‰ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¼ºè°ƒé¢†åŸŸåŸç”Ÿè®¾è®¡å’Œå¤šæ¨¡æ€èƒ½åŠ›çš„é›†æˆï¼Œä»¥æé«˜æ¨¡å‹çš„å‚æ•°æ•ˆç‡å’Œåº”ç”¨æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒã€æ€§èƒ½è¯„ä¼°å’Œåº”ç”¨åœºæ™¯åˆ†æç­‰ä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é˜¶æ®µèšç„¦äºç‰¹å®šé¢†åŸŸçš„è¯­æ–™åº“ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µé‡‡ç”¨é¢†åŸŸåŸç”Ÿè®¾è®¡ï¼Œæ€§èƒ½è¯„ä¼°åˆ™é€šè¿‡é¢†åŸŸç‰¹å®šåŸºå‡†è¿›è¡Œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºè¶…è¶Šä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œæå‡ºé¢†åŸŸåŸç”Ÿè®¾è®¡çš„æ¦‚å¿µï¼Œä½¿æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸä¸­è¡¨ç°å‡ºæ›´é«˜çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ç¨€ç–è®¡ç®—å’Œé‡åŒ–æŠ€æœ¯çš„åº”ç”¨ï¼Œä»¥æé«˜æ¨¡å‹çš„å‚æ•°æ•ˆç‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œä¼˜åŒ–ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åŒ»ç–—å’Œé‡‘èé¢†åŸŸçš„æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ï¼Œåœ¨å¤šä¸ªé¢†åŸŸç‰¹å®šåŸºå‡†ä¸Šå‡è¡¨ç°å‡ºä¼˜äºé€šç”¨æ¨¡å‹çš„æ•ˆæœï¼ŒéªŒè¯äº†é¢†åŸŸåŸç”Ÿè®¾è®¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€é‡‘èã€æ³•å¾‹å’Œç”µå­å•†åŠ¡ç­‰ä¸“ä¸šé¢†åŸŸã€‚é€šè¿‡ä¸“ç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„åº”ç”¨ï¼Œå¯ä»¥æ˜¾è‘—æé«˜è¿™äº›é¢†åŸŸä¸­çš„ä¿¡æ¯å¤„ç†æ•ˆç‡å’Œå†³ç­–æ”¯æŒèƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³è¡Œä¸šçš„æ™ºèƒ½åŒ–è½¬å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid evolution of specialized large language models (LLMs) has transitioned from simple domain adaptation to sophisticated native architectures, marking a paradigm shift in AI development. This survey systematically examines this progression across healthcare, finance, legal, and technical domains. Besides the wide use of specialized LLMs, technical breakthrough such as the emergence of domain-native designs beyond fine-tuning, growing emphasis on parameter efficiency through sparse computation and quantization, increasing integration of multimodal capabilities and so on are applied to recent LLM agent. Our analysis reveals how these innovations address fundamental limitations of general-purpose LLMs in professional applications, with specialized models consistently performance gains on domain-specific benchmarks. The survey further highlights the implications for E-Commerce field to fill gaps in the field.

