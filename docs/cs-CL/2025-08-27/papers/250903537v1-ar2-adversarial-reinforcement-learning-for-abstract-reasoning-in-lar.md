---
layout: default
title: AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models
---

# AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03537" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03537v1</a>
  <a href="https://arxiv.org/pdf/2509.03537.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03537v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03537v1', 'AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cheng-Kai Yeh, Hsing-Wang Lee, Chung-Hung Kuo, Hen-Hsen Huang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 7 pages, accepted by CIKM 2025 as a short paper

**DOI**: [10.1145/3746252.3760850](https://doi.org/10.1145/3746252.3760850)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAR$^2$æ¡†æ¶ä»¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„æŠ½è±¡æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ€§å¼ºåŒ–å­¦ä¹ ` `æŠ½è±¡æ¨ç†` `å¤§è¯­è¨€æ¨¡å‹` `ç¼–ç¨‹ä»»åŠ¡` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è¡¨é¢æ¨¡å¼è¯†åˆ«ï¼Œç¼ºä¹å¯¹æŠ½è±¡èƒ½åŠ›çš„æ˜ç¡®è®­ç»ƒï¼Œå¯¼è‡´å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚é—®é¢˜ä¸Šçš„è¡¨ç°ä¸è¶³ã€‚
2. AR$^2$æ¡†æ¶é€šè¿‡æ•™å¸ˆæ¨¡å‹å°†æ ¸å¿ƒé—®é¢˜è½¬åŒ–ä¸ºå¤æ‚å™è¿°ï¼Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹æå–è®¡ç®—å†…æ ¸ï¼Œä»è€Œå¢å¼ºæŠ½è±¡æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAR$^2$æ˜¾è‘—æé«˜äº†å­¦ç”Ÿæ¨¡å‹åœ¨æœªè§è¿‡çš„ç¼–ç¨‹ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ï¼Œè¯æ˜äº†æŠ½è±¡èƒ½åŠ›çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŠ½è±¡èƒ½åŠ›æ˜¯è®¡ç®—æœºç§‘å­¦ä¸­çš„åŸºç¡€æŠ€èƒ½ï¼Œå¯¹äºäººç±»é—®é¢˜è§£å†³è€…å’Œé¢å‘ç¼–ç çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡³å…³é‡è¦ã€‚å°½ç®¡è¿‘æœŸåœ¨ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒLLMsè¿›è¡Œä»£ç ç”Ÿæˆæ–¹é¢å–å¾—äº†ä¸€å®šè¿›å±•ï¼Œä½†å¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è¡¨é¢æ¨¡å¼è¯†åˆ«ä¸Šï¼Œå¿½è§†äº†å¯¹æŠ½è±¡èƒ½åŠ›çš„æ˜ç¡®è®­ç»ƒã€‚æœ¬ç ”ç©¶æå‡ºäº†AR$^2$ï¼ˆå¯¹æŠ—æ€§å¼ºåŒ–å­¦ä¹ ç”¨äºæŠ½è±¡æ¨ç†ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨è®¾è®¡çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºLLMsçš„æŠ½è±¡èƒ½åŠ›ã€‚AR$^2$åˆ©ç”¨æ•™å¸ˆæ¨¡å‹å°†æ ¸å¿ƒé—®é¢˜è½¬åŒ–ä¸ºå™è¿°ä¸°å¯Œã€å…·æœ‰æŒ‘æˆ˜æ€§çš„æè¿°ï¼ŒåŒæ—¶ä¸æ”¹å˜å…¶åŸºæœ¬é€»è¾‘ã€‚ä¸æ­¤åŒæ—¶ï¼Œå­¦ç”Ÿç¼–ç æ¨¡å‹è¢«è®­ç»ƒä»¥é€šè¿‡æå–æ½œåœ¨çš„è®¡ç®—å†…æ ¸æ¥è§£å†³è¿™äº›å¤æ‚çš„å™è¿°é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAR$^2$æ˜¾è‘—æé«˜äº†å­¦ç”Ÿæ¨¡å‹åœ¨ä»¥å‰æœªè§è¿‡çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„ç¼–ç¨‹ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ï¼Œå¼ºè°ƒäº†æŠ½è±¡ä½œä¸ºå¢å¼ºLLMæ³›åŒ–èƒ½åŠ›çš„å…³é”®æŠ€èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç¼–ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾§é‡äºè¡¨é¢æ¨¡å¼è¯†åˆ«ï¼Œæœªèƒ½æœ‰æ•ˆè®­ç»ƒæ¨¡å‹çš„æŠ½è±¡èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAR$^2$æ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ•™å¸ˆæ¨¡å‹å°†ç®€å•çš„æ ¸å¿ƒé—®é¢˜è½¬åŒ–ä¸ºå™è¿°ä¸°å¯Œçš„å¤æ‚é—®é¢˜ï¼Œä»è€Œè®­ç»ƒå­¦ç”Ÿæ¨¡å‹æå–æ½œåœ¨çš„è®¡ç®—å†…æ ¸ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å¢å¼ºæ¨¡å‹çš„æŠ½è±¡æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAR$^2$çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ã€‚æ•™å¸ˆæ¨¡å‹è´Ÿè´£å°†æ ¸å¿ƒé—®é¢˜è½¬åŒ–ä¸ºå¤æ‚å™è¿°ï¼Œè€Œå­¦ç”Ÿæ¨¡å‹åˆ™é€šè¿‡è§£å†³è¿™äº›å™è¿°é—®é¢˜æ¥å­¦ä¹ æå–è®¡ç®—å†…æ ¸ã€‚æ•´ä¸ªè¿‡ç¨‹é€šè¿‡å¯¹æŠ—æ€§å¼ºåŒ–å­¦ä¹ è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šAR$^2$çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¯¹æŠ—æ€§è®­ç»ƒæœºåˆ¶ï¼Œé€šè¿‡æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„äº’åŠ¨ï¼Œæ˜¾è‘—æå‡äº†å­¦ç”Ÿæ¨¡å‹çš„æŠ½è±¡æ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œåè€…é€šå¸¸ç¼ºä¹å¯¹æŠ½è±¡èƒ½åŠ›çš„ä¸“é—¨å…³æ³¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒAR$^2$é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œå­¦ç”Ÿæ¨¡å‹è¢«è®¾è®¡ä¸ºèƒ½å¤Ÿæœ‰æ•ˆæå–å’Œå¤„ç†å¤æ‚å™è¿°ä¸­çš„è®¡ç®—å†…æ ¸ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAR$^2$æ˜¾è‘—æé«˜äº†å­¦ç”Ÿæ¨¡å‹åœ¨æœªè§è¿‡çš„ç¼–ç¨‹ä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºæ›´å¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼ŒéªŒè¯äº†æŠ½è±¡èƒ½åŠ›åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¼–ç¨‹æ•™è‚²ã€è‡ªåŠ¨ä»£ç ç”Ÿæˆå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„æŠ½è±¡æ¨ç†èƒ½åŠ›ï¼ŒAR$^2$èƒ½å¤Ÿå¸®åŠ©å¼€å‘æ›´æ™ºèƒ½çš„ç¼–ç¨‹åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–å·¥å…·ï¼Œè¿›è€Œæ¨åŠ¨è½¯ä»¶å¼€å‘çš„æ•ˆç‡å’Œè´¨é‡ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½åœ¨æ›´å¹¿æ³›çš„äººå·¥æ™ºèƒ½åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Abstraction--the ability to recognize and distill essential computational patterns from complex problem statements--is a foundational skill in computer science, critical both for human problem-solvers and coding-oriented large language models (LLMs). Despite recent advances in training LLMs for code generation using reinforcement learning (RL), most existing approaches focus primarily on superficial pattern recognition, overlooking explicit training for abstraction. In this study, we propose AR$^2$ (Adversarial Reinforcement Learning for Abstract Reasoning), a novel framework explicitly designed to enhance the abstraction abilities of LLMs. AR$^2$ employs a teacher model to transform kernel problems into narrative-rich, challenging descriptions without changing their fundamental logic. Simultaneously, a student coding model is trained to solve these complex narrative problems by extracting their underlying computational kernels. Experimental results demonstrate that AR$^2$ substantially improves the student model's accuracy on previously unseen, challenging programming tasks, underscoring abstraction as a key skill for enhancing LLM generalization.

