---
layout: default
title: Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis
---

# Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04459" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.04459v1</a>
  <a href="https://arxiv.org/pdf/2509.04459.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04459v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04459v1', 'Uncertainty-Aware Collaborative System of Large and Small Models for Multimodal Sentiment Analysis')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shiqin Han, Manning Gao, Menghua Jiang, Yuncheng Jiang, Haifeng Hu, Sijie Mai

**ÂàÜÁ±ª**: cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-27

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Âçè‰ΩúÁ≥ªÁªü‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûê‰∏≠ÁöÑÊÄßËÉΩ‰∏éÊïàÁéáÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûê` `‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•` `Âçè‰ΩúÁ≥ªÁªü` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËΩªÈáèÁ∫ßÊ®°Âûã` `ËÆ°ÁÆóËµÑÊ∫ê‰ºòÂåñ` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûêÊñπÊ≥ïÂú®ËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±Ç‰∏äÂ≠òÂú®ËæÉÂ§ßÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂ§ßÂûãÊ®°ÂûãÁöÑÈ´òÂºÄÈîÄÈôêÂà∂‰∫ÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Âçè‰ΩúÁ≥ªÁªüÔºàU-ACSÔºâÈÄöËøáÂ∞ÜÂ∞èÂûãÊ®°Âûã‰∏éMLLMÁªìÂêàÔºåÂà©Áî®‰∏çÁ°ÆÂÆöÊÄßÈ©±Âä®ÁöÑÁ∫ßËÅîÊú∫Âà∂‰ºòÂåñÂàÜÊûêÊµÅÁ®ã„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåU-ACSÂú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂ËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±Ç‰ªÖ‰∏∫ÂçïÁã¨‰ΩøÁî®MLLMÁöÑ‰∏ÄÂ∞èÈÉ®ÂàÜ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÁöÑÂá∫Áé∞ÊòæËëóÊé®Âä®‰∫ÜÂ§öÊ®°ÊÄÅÊú∫Âô®Â≠¶‰π†ÁöÑËøõÂ±ïÔºå‰ΩÜÂÖ∂È´òËÆ°ÁÆóÈúÄÊ±ÇÊàê‰∏∫ÂÆûÈôÖÂ∫îÁî®ÁöÑÈöúÁ¢ç„ÄÇÁõ∏ÂØπËÄåË®ÄÔºåÂ∞èÂûã‰∏ìÁî®Ê®°ÂûãËôΩÁÑ∂È´òÊïàÔºå‰ΩÜÊÄßËÉΩÂæÄÂæÄÂèóÈôê„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÊÄßËÉΩ‰∏éÊïàÁéáÁöÑÊùÉË°°ÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Âçè‰ΩúÁ≥ªÁªüÔºàU-ACSÔºâÔºåËØ•Á≥ªÁªüÂ∞ÜÂº∫Â§ßÁöÑMLLMÔºàÂ¶ÇHumanOmniÔºâ‰∏éËΩªÈáèÁ∫ßÂü∫Á∫øÊ®°ÂûãÂçèÂêåËøê‰Ωú„ÄÇÁ≥ªÁªüÊ†∏ÂøÉÊòØ‰∏Ä‰∏™Âü∫‰∫é‰∏çÁ°ÆÂÆöÊÄßÁöÑÁ∫ßËÅîÊú∫Âà∂ÔºåÈ¶ñÂÖàÁî±Â∞èÂûãÊ®°ÂûãÂø´ÈÄüÁ≠õÈÄâËæìÂÖ•Ê†∑Êú¨Ôºå‰ªÖÂ∞ÜÈ´òÈ¢ÑÊµã‰∏çÁ°ÆÂÆöÊÄßÁöÑÊ†∑Êú¨ÊèêÂçáËá≥MLLMËøõË°åÊõ¥Ê∑±ÂÖ•ÂàÜÊûê„ÄÇÊ≠§Â§ñÔºåÁ≥ªÁªüËøòÂºïÂÖ•‰∫ÜÂ§ÑÁêÜÊ®°Á≥äÊàñÂÜ≤Á™ÅÈ¢ÑÊµãÁöÑÈ´òÁ∫ßÁ≠ñÁï•ÔºåÂåÖÊã¨ÂØπÁõ∏‰ººÊûÅÊÄßÁöÑÈ¢ÑÊµãËøõË°åÂä†ÊùÉÂπ≥ÂùáÔºå‰ª•ÂèäÂú®‰∏§ÁßçÊ®°ÂûãÂùáË°®Áé∞Âá∫È´ò‰∏çÁ°ÆÂÆöÊÄßÊó∂ËøõË°åÂü∫‰∫éÊèêÁ§∫ÁöÑ‰∫§ÂèâÈ™åËØÅ„ÄÇËØ•ÊñπÊ≥ïÊòæËëóÈôç‰Ωé‰∫ÜÊé®ÁêÜÊàêÊú¨ÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜMLLMÁöÑÈ´òÂáÜÁ°ÆÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûê‰∏≠Â§ßÂûãÊ®°ÂûãËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±ÇÈ´òÁöÑÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÊïàÁéá‰∏éÊÄßËÉΩ‰πãÈó¥Èöæ‰ª•ÂèñÂæóÂπ≥Ë°°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÊÑüÁü•Âçè‰ΩúÁ≥ªÁªüÔºàU-ACSÔºâÈÄöËøáÂ∞èÂûãÊ®°ÂûãÂø´ÈÄüÁ≠õÈÄâÊ†∑Êú¨Ôºå‰ªÖÂ∞ÜÈ´ò‰∏çÁ°ÆÂÆöÊÄßÊ†∑Êú¨‰º†ÈÄíÁªôMLLMÔºå‰ªéËÄåÊèêÈ´òÊïàÁéá„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöU-ACSÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂ∞èÂûãÊ®°Âûã‰Ωú‰∏∫ÂàùÊ≠•Á≠õÈÄâÂô®ÔºåMLLMÁî®‰∫éÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÁ≥ªÁªüÈÄöËøá‰∏çÁ°ÆÂÆöÊÄßËØÑ‰º∞Âä®ÊÄÅÂÜ≥ÂÆöÊ†∑Êú¨ÊµÅÂêë„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöU-ACSÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫é‰∏çÁ°ÆÂÆöÊÄßÈ©±Âä®ÁöÑÁ∫ßËÅîÊú∫Âà∂ÂíåÂ§ÑÁêÜÂÜ≤Á™ÅÈ¢ÑÊµãÁöÑÁ≠ñÁï•ÔºåÊòæËëóÊèêÈ´ò‰∫ÜËÆ°ÁÆóËµÑÊ∫êÁöÑÂà©Áî®ÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÁ≥ªÁªüËÆæËÆ°‰∏≠ÈááÁî®‰∫ÜÂä†ÊùÉÂπ≥ÂùáÁ≠ñÁï•Â§ÑÁêÜÁõ∏‰ººÊûÅÊÄßÁöÑÈ¢ÑÊµãÔºåÂπ∂Âú®È´ò‰∏çÁ°ÆÂÆöÊÄßÊÉÖÂÜµ‰∏ãÂºïÂÖ•Âü∫‰∫éÊèêÁ§∫ÁöÑ‰∫§ÂèâÈ™åËØÅÔºå‰ª•Á°Æ‰øùÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåU-ACSÂú®Â§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûê‰ªªÂä°‰∏≠ËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÁõ∏ËæÉ‰∫éÂçïÁã¨‰ΩøÁî®MLLMÔºåËÆ°ÁÆóËµÑÊ∫êÈúÄÊ±ÇÂáèÂ∞ë‰∫Ü90%‰ª•‰∏äÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈ´òÂáÜÁ°ÆÁéáÔºåÂ±ïÁé∞‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊïàÁéá‰∏éÊïàÊûú„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á§æ‰∫§Â™í‰ΩìÊÉÖÊÑüÂàÜÊûê„ÄÅÂÆ¢Êà∑ÂèçÈ¶àÂ§ÑÁêÜÂèäÂ∏ÇÂú∫Ë∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÂ§öÊ®°ÊÄÅÊÉÖÊÑüÂàÜÊûêÁöÑÊïàÁéá‰∏éÂáÜÁ°ÆÊÄßÔºåU-ACSËÉΩÂ§ü‰∏∫‰ºÅ‰∏öÊèê‰æõÊõ¥ÂÖ∑‰ª∑ÂÄºÁöÑÊ¥ûÂØüÔºåÊé®Âä®Êô∫ËÉΩÂÜ≥Á≠ñÁöÑÂÆûÁé∞„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØÊâ©Â±ïËá≥ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅ‰ªªÂä°ÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The advent of Multimodal Large Language Models (MLLMs) has significantly advanced the state-of-the-art in multimodal machine learning, yet their substantial computational demands present a critical barrier to real-world deployment. Conversely, smaller, specialized models offer high efficiency but often at the cost of performance. To reconcile this performance-efficiency trade-off, we propose a novel Uncertainty-Aware Collaborative System (U-ACS) that synergistically orchestrates a powerful MLLM (e.g., HumanOmni) and a lightweight baseline model for multimodal sentiment analysis. The core of our system is an uncertainty-driven cascade mechanism, where the efficient small model first acts as a rapid filter for all input samples. Only those samples yielding high predictive uncertainty, thereby indicating greater difficulty, are selectively escalated to the MLLM for more sophisticated analysis. Furthermore, our system introduces advanced strategies to handle ambiguous or conflicting predictions, including weighted averaging for predictions of similar polarity and a prompt-based cross-verification to resolve conflicting predictions when both models exhibit high uncertainty. This sample-difficulty-aware approach allows for a dynamic allocation of computational resources, drastically reducing inference costs while retaining the high accuracy of MLLM. Extensive experiments on benchmark datasets demonstrate that our proposed method achieves state-of-the-art performance, while requiring only a fraction of the computational resources compared to using a standalone MLLM.

