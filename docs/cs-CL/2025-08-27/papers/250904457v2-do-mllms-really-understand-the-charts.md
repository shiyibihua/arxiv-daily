---
layout: default
title: Do MLLMs Really Understand the Charts?
---

# Do MLLMs Really Understand the Charts?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04457" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04457v2</a>
  <a href="https://arxiv.org/pdf/2509.04457.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04457v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04457v2', 'Do MLLMs Really Understand the Charts?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiao Zhang, Dongyuan Li, Liuyu Xiang, Yao Zhang, Cheng Zhong, Zhaofeng He

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-12-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChartVRBenchä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨ç†è§£ä¸­çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å›¾è¡¨ç†è§£` `è§†è§‰æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `åŸºå‡†æµ‹è¯•` `æ•°æ®å¯è§†åŒ–` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æœªæ ‡æ³¨å›¾è¡¨æ—¶ï¼Œå¸¸å¸¸å‡ºç°å¹»è§‰å’Œæ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºChartVRBenchåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å›¾è¡¨ç†è§£ä¸­çš„è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå¹¶å¼•å…¥ChartVR-3B/7Bæ¨¡å‹ä»¥å¢å¼ºè§†è§‰æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChartVRåœ¨ChartVRBenchä¸Šè¡¨ç°ä¼˜äºç°æœ‰å¼ºå¤§æ¨¡å‹ï¼Œå¹¶åœ¨å¤šä¸ªå…¬å…±åŸºå‡†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å›¾è¡¨ç†è§£æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤„ç†æœªæ ‡æ³¨å›¾è¡¨æ—¶å´å­˜åœ¨æ˜¾è‘—çš„å¹»è§‰å’Œæ€§èƒ½ä¸‹é™ã€‚æœ¬æ–‡è®¤ä¸ºï¼Œå½“å‰çš„MLLMsä¸»è¦ä¾èµ–è§†è§‰è¯†åˆ«è€Œéè§†è§‰æ¨ç†æ¥è§£è¯»å›¾è¡¨ï¼Œè€Œæ•°å€¼çš„è§†è§‰ä¼°è®¡æ˜¯å›¾è¡¨ç†è§£ä¸­æœ€åŸºæœ¬çš„èƒ½åŠ›ä¹‹ä¸€ï¼Œéœ€è¦å¤æ‚çš„è§†è§‰æ¨ç†ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å¼•å…¥äº†ChartVRBenchï¼Œä¸€ä¸ªä¸“é—¨è®¾è®¡çš„åŸºå‡†ï¼Œä»¥éš”ç¦»å’Œè¯„ä¼°å›¾è¡¨ç†è§£ä¸­çš„è§†è§‰æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæå‡ºäº†ChartVR-3B/7Bï¼Œé‡‡ç”¨æ–°é¢–çš„è§†è§‰æ¨ç†å¼ºåŒ–å¾®è°ƒï¼ˆVR-RFTï¼‰ç­–ç•¥ï¼Œä»¥å¢å¼ºçœŸæ­£çš„å›¾è¡¨è§†è§‰æ¨ç†èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒChartVRåœ¨ChartVRBenchä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç”šè‡³è¶…è¶Šäº†å¼ºå¤§çš„ä¸“æœ‰æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å›¾è¡¨ç†è§£ä¸­ä¾èµ–è§†è§‰è¯†åˆ«è€Œéè§†è§‰æ¨ç†çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†æœªæ ‡æ³¨å›¾è¡¨æ—¶çš„æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ChartVRBenchåŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°è§†è§‰æ¨ç†èƒ½åŠ›ï¼Œå¹¶é‡‡ç”¨è§†è§‰æ¨ç†å¼ºåŒ–å¾®è°ƒï¼ˆVR-RFTï¼‰ç­–ç•¥æ¥æå‡æ¨¡å‹çš„è§†è§‰æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚ChartVR-3B/7Bæ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­åº”ç”¨VR-RFTç­–ç•¥ï¼Œä»¥å¼ºåŒ–è§†è§‰æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ChartVRBenchåŸºå‡†å’ŒVR-RFTç­–ç•¥ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¼ºè°ƒè§†è§‰æ¨ç†è€Œéå•çº¯çš„è§†è§‰è¯†åˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹çš„å…³é”®è®¾è®¡åŒ…æ‹¬ç‰¹å®šçš„æŸå¤±å‡½æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨è§†è§‰æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒChartVRåœ¨ChartVRBenchä¸Šè¡¨ç°ä¼˜äºç°æœ‰å¼ºå¤§æ¨¡å‹ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒVR-RFTç­–ç•¥æ‰€åŸ¹å…»çš„è§†è§‰æ¨ç†èƒ½åŠ›åœ¨å¤šä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸­ä¹Ÿå±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®å¯è§†åŒ–ã€å•†ä¸šæ™ºèƒ½å’Œæ•™è‚²ç­‰ã€‚é€šè¿‡æå‡å›¾è¡¨ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ä»æ•°æ®ä¸­æå–ä¿¡æ¯ï¼Œä¿ƒè¿›å†³ç­–åˆ¶å®šå’ŒçŸ¥è¯†ä¼ æ’­ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆå’Œæ™ºèƒ½æ•°æ®åˆ†æä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Although Multimodal Large Language Models (MLLMs) have demonstrated increasingly impressive performance in chart understanding, most of them exhibit alarming hallucinations and significant performance degradation when handling non-annotated charts. We argue that current MLLMs rely largely on visual recognition rather than visual reasoning to interpret the charts, and visual estimation of numerical values is one of the most fundamental capabilities in chart understanding that require complex visual reasoning. To prove this, we introduce ChartVRBench, a benchmark meticulously designed to isolate and evaluate visual reasoning ability in chart understanding. Furthermore, we propose ChartVR-3B/7B trained with a novel Visual Reasoning Reinforcement Finetuning (VR-RFT) strategy to strengthen genuine chart visual reasoning abilities. Extensive experiments show that ChartVR achieves superior performance on ChartVRBench, outperforming even powerful proprietary models. Moreover, the visual reasoning skills cultivated by the proposed VR-RFT demonstrate strong generalization, leading to significant performance gains across a diverse suite of public chart understanding benchmarks. The code and dataset will be publicly available upon publication.

