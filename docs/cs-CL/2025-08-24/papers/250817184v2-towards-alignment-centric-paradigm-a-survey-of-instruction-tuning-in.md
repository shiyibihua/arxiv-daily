---
layout: default
title: Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models
---

# Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17184" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17184v2</a>
  <a href="https://arxiv.org/pdf/2508.17184.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17184v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17184v2', 'Towards Alignment-Centric Paradigm: A Survey of Instruction Tuning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xudong Han, Junjie Yang, Tianyang Wang, Ziqian Bi, Xinyuan Song, Junfeng Hao, Junhao Song

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-24 (æ›´æ–°: 2025-11-19)

**å¤‡æ³¨**: 24 pages, 7 figures, 5 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä»¥å¯¹é½ä¸ºä¸­å¿ƒçš„èŒƒå¼ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤è°ƒä¼˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒ‡ä»¤è°ƒä¼˜` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®æ”¶é›†` `å¾®è°ƒç­–ç•¥` `å¤šæ¨¡æ€è¯„ä¼°` `é¢†åŸŸç‰¹å®šåŸºå‡†` `è®¡ç®—æ•ˆç‡` `äººç±»åé¦ˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æŒ‡ä»¤è°ƒä¼˜æ–¹æ³•åœ¨å¯¹é½äººç±»æ„å›¾å’Œå®‰å…¨æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ¨¡æ€å’Œå¤šè¯­è¨€åœºæ™¯ä¸­ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§å…¨é¢çš„è°ƒä¼˜æµç¨‹ï¼Œæ¶µç›–æ•°æ®æ”¶é›†ã€å¾®è°ƒç­–ç•¥å’Œè¯„ä¼°åè®®ï¼Œå¼ºè°ƒè®¡ç®—æ•ˆç‡å’Œæ¨¡å‹å¯é‡ç”¨æ€§ã€‚
3. é€šè¿‡å¯¹æ¯”ä¸åŒçš„å¾®è°ƒæŠ€æœ¯ï¼Œè®ºæ–‡å±•ç¤ºäº†åœ¨ç‰¹å®šé¢†åŸŸåŸºå‡†ä¸Šï¼Œæ¨¡å‹çš„æ€§èƒ½å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡ä»¤è°ƒä¼˜æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»æ„å›¾ã€å®‰å…¨çº¦æŸå’Œç‰¹å®šé¢†åŸŸéœ€æ±‚å¯¹é½çš„å…³é”®æŠ€æœ¯ã€‚æœ¬æ–‡ç»¼è¿°äº†å®Œæ•´çš„è°ƒä¼˜æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®æ”¶é›†æ–¹æ³•ã€å…¨å‚æ•°ä¸å‚æ•°é«˜æ•ˆçš„å¾®è°ƒç­–ç•¥ä»¥åŠè¯„ä¼°åè®®ã€‚æˆ‘ä»¬å°†æ•°æ®æ„å»ºåˆ†ä¸ºä¸‰å¤§èŒƒå¼ï¼šä¸“å®¶æ³¨é‡Šã€ä»æ›´å¤§æ¨¡å‹è’¸é¦å’Œè‡ªæˆ‘æ”¹è¿›æœºåˆ¶ï¼Œå„è‡ªå…·æœ‰è´¨é‡ã€å¯æ‰©å±•æ€§å’Œèµ„æºæˆæœ¬çš„ä¸åŒæƒè¡¡ã€‚å¾®è°ƒæŠ€æœ¯æ¶µç›–ä»ä¼ ç»Ÿçš„ç›‘ç£è®­ç»ƒåˆ°ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å’Œå‰ç¼€è°ƒä¼˜ç­‰è½»é‡çº§æ–¹æ³•ï¼Œé‡ç‚¹å…³æ³¨è®¡ç®—æ•ˆç‡å’Œæ¨¡å‹å¯é‡ç”¨æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†åœ¨å¤šè¯­è¨€å’Œå¤šæ¨¡æ€åœºæ™¯ä¸­è¯„ä¼°æ¨¡å‹çš„çœŸå®æ€§ã€å®ç”¨æ€§å’Œå®‰å…¨æ€§æ‰€é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†åŒ»ç–—ã€æ³•å¾‹å’Œé‡‘èç­‰é¢†åŸŸç‰¹å®šåŸºå‡†çš„å‡ºç°ã€‚æœ€åï¼Œè®¨è®ºäº†è‡ªåŠ¨æ•°æ®ç”Ÿæˆã€è‡ªé€‚åº”ä¼˜åŒ–å’Œç¨³å¥è¯„ä¼°æ¡†æ¶çš„å‰æ™¯ï¼Œè®¤ä¸ºæ•°æ®ã€ç®—æ³•å’Œäººç±»åé¦ˆçš„æ›´ç´§å¯†ç»“åˆå¯¹äºæ¨åŠ¨æŒ‡ä»¤è°ƒä¼˜çš„LLMsè‡³å…³é‡è¦ã€‚è¯¥ç»¼è¿°æ—¨åœ¨ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›è®¾è®¡æœ‰æ•ˆä¸”å¯é å¯¹é½çš„LLMsçš„å®ç”¨å‚è€ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¯¹é½äººç±»æ„å›¾å’Œå®‰å…¨æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè¯­è¨€å’Œå¤šæ¨¡æ€åœºæ™¯ä¸­çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æœºåˆ¶å’Œé€‚åº”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ä»¥å¯¹é½ä¸ºä¸­å¿ƒçš„è°ƒä¼˜èŒƒå¼ï¼Œé€šè¿‡ç³»ç»ŸåŒ–çš„æ•°æ®æ”¶é›†å’Œå¾®è°ƒç­–ç•¥ï¼Œæå‡æ¨¡å‹çš„å®ç”¨æ€§å’Œå®‰å…¨æ€§ã€‚å¼ºè°ƒæ•°æ®ã€ç®—æ³•ä¸äººç±»åé¦ˆçš„ç´§å¯†ç»“åˆï¼Œä»¥å®ç°æ›´å¥½çš„å¯¹é½æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€å¾®è°ƒç­–ç•¥å’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†åˆ†ä¸ºä¸“å®¶æ³¨é‡Šã€æ¨¡å‹è’¸é¦å’Œè‡ªæˆ‘æ”¹è¿›ï¼Œå¾®è°ƒç­–ç•¥åˆ™æ¶µç›–å…¨å‚æ•°å’Œé«˜æ•ˆå‚æ•°å¾®è°ƒï¼Œæœ€åé€šè¿‡å¤šç§è¯„ä¼°åè®®éªŒè¯æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¤šç§æ•°æ®æ„å»ºèŒƒå¼å’Œå¾®è°ƒç­–ç•¥çš„ç»“åˆï¼Œå°¤å…¶æ˜¯ä½ç§©é€‚åº”å’Œå‰ç¼€è°ƒä¼˜çš„åº”ç”¨ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è®¡ç®—æ•ˆç‡å’Œå¯é‡ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ä½ç§©é€‚åº”æŠ€æœ¯ä»¥å‡å°‘è®¡ç®—è´Ÿæ‹…ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™è€ƒè™‘äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§å’Œå®‰å…¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ–°æå‡ºçš„å¾®è°ƒç­–ç•¥åï¼Œæ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸåŸºå‡†ä¸Šæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—å’Œæ³•å¾‹é¢†åŸŸï¼Œå‡†ç¡®ç‡æé«˜äº†15%ä»¥ä¸Šï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€æ³•å¾‹å’Œé‡‘èç­‰è¡Œä¸šï¼Œèƒ½å¤Ÿå¸®åŠ©æ„å»ºæ›´ç¬¦åˆäººç±»æ„å›¾çš„æ™ºèƒ½ç³»ç»Ÿï¼Œæé«˜å†³ç­–çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œéšç€è‡ªåŠ¨æ•°æ®ç”Ÿæˆå’Œè‡ªé€‚åº”ä¼˜åŒ–æŠ€æœ¯çš„å‘å±•ï¼ŒæŒ‡ä»¤è°ƒä¼˜çš„LLMså°†åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction tuning is a pivotal technique for aligning large language models (LLMs) with human intentions, safety constraints, and domain-specific requirements. This survey provides a comprehensive overview of the full pipeline, encompassing (i) data collection methodologies, (ii) full-parameter and parameter-efficient fine-tuning strategies, and (iii) evaluation protocols. We categorized data construction into three major paradigms: expert annotation, distillation from larger models, and self-improvement mechanisms, each offering distinct trade-offs between quality, scalability, and resource cost. Fine-tuning techniques range from conventional supervised training to lightweight approaches, such as low-rank adaptation (LoRA) and prefix tuning, with a focus on computational efficiency and model reusability. We further examine the challenges of evaluating faithfulness, utility, and safety across multilingual and multimodal scenarios, highlighting the emergence of domain-specific benchmarks in healthcare, legal, and financial applications. Finally, we discuss promising directions for automated data generation, adaptive optimization, and robust evaluation frameworks, arguing that a closer integration of data, algorithms, and human feedback is essential for advancing instruction-tuned LLMs. This survey aims to serve as a practical reference for researchers and practitioners seeking to design LLMs that are both effective and reliably aligned with human intentions.

