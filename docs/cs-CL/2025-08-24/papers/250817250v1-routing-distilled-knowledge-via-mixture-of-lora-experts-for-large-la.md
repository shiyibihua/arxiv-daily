---
layout: default
title: Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation
---

# Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17250" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17250v1</a>
  <a href="https://arxiv.org/pdf/2508.17250.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17250v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17250v1', 'Routing Distilled Knowledge via Mixture of LoRA Experts for Large Language Model based Bundle Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaidong Feng, Zhu Sun, Hui Fang, Jie Yang, Wenyuan Liu, Yew-Soon Ong

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-08-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRouteDKæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†è’¸é¦å†²çªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `LoRAä¸“å®¶` `è‡ªåŠ¨åŒ–ç”Ÿæˆ` `è®¡ç®—æ•ˆç‡` `åŠ¨æ€èåˆ` `çŸ¥è¯†å†²çª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†è’¸é¦è¿‡ç¨‹ä¸­å®¹æ˜“å¯¼è‡´çŸ¥è¯†å†²çªï¼Œå½±å“æ†ç»‘ç”Ÿæˆçš„æ€§èƒ½å’Œæ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºRouteDKæ¡†æ¶ï¼Œé€šè¿‡æ··åˆLoRAä¸“å®¶æ¶æ„åŠ¨æ€è·¯ç”±è’¸é¦çŸ¥è¯†ï¼Œæœ‰æ•ˆæ•´åˆé«˜å±‚æ¬¡å’Œç»†ç²’åº¦çŸ¥è¯†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRouteDKåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†ä¸æ•™å¸ˆLLMç›¸å½“æˆ–æ›´å¥½çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨åŒ–æ†ç»‘ç”Ÿæˆä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†é¢ä¸´é«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚å°½ç®¡çŸ¥è¯†è’¸é¦ä¸ºæ›´é«˜æ•ˆçš„å­¦ç”Ÿæ¨¡å‹æä¾›äº†é€”å¾„ï¼Œä½†åˆæ­¥ç ”ç©¶è¡¨æ˜ï¼Œç®€å•åœ°å°†æ¥è‡ªæ•™å¸ˆLLMsçš„å¤šæ ·åŒ–è’¸é¦çŸ¥è¯†æ•´åˆåˆ°å­¦ç”ŸLLMsä¸­ä¼šå¯¼è‡´çŸ¥è¯†å†²çªï¼Œå½±å“æ†ç»‘ç”Ÿæˆçš„æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†RouteDKæ¡†æ¶ï¼Œé€šè¿‡æ··åˆLoRAä¸“å®¶æ¶æ„æ¥è·¯ç”±è’¸é¦çŸ¥è¯†ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆä»æ•™å¸ˆLLMä¸­è’¸é¦å‡ºä¸¤ç§äº’è¡¥ç±»å‹çš„çŸ¥è¯†ï¼šé«˜å±‚æ¬¡çŸ¥è¯†ï¼ˆå¯æ¨å¹¿è§„åˆ™ï¼‰å’Œç»†ç²’åº¦çŸ¥è¯†ï¼ˆä¼šè¯ç‰¹å®šæ¨ç†ï¼‰ã€‚ç„¶åï¼Œæˆ‘ä»¬ä¸ºæ¯ç§çŸ¥è¯†ç±»å‹è®­ç»ƒçŸ¥è¯†ç‰¹å®šçš„LoRAä¸“å®¶ï¼Œå¹¶ä¸åŸºç¡€LoRAä¸“å®¶ä¸€èµ·ä½¿ç”¨ã€‚ä¸ºäº†æœ‰æ•ˆæ•´åˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŠ¨æ€èåˆæ¨¡å—ï¼Œå…·æœ‰è¾“å…¥æ„ŸçŸ¥è·¯ç”±å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®è¾“å…¥åŠ¨æ€ç¡®å®šæœ€ä¼˜æƒé‡ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£çŸ¥è¯†å†²çªã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRouteDKåœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å‡†ç¡®æ€§ä¸æ•™å¸ˆLLMç›¸å½“æˆ–æ›´ä¼˜ï¼ŒåŒæ—¶ä¿æŒå¼ºå¤§çš„è®¡ç®—æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†è’¸é¦è¿‡ç¨‹ä¸­å‡ºç°çš„çŸ¥è¯†å†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å°†å¤šç§ç±»å‹çš„è’¸é¦çŸ¥è¯†æ•´åˆåˆ°å­¦ç”Ÿæ¨¡å‹æ—¶ï¼Œå¾€å¾€å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨æ†ç»‘ç”Ÿæˆä»»åŠ¡ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„RouteDKæ¡†æ¶é€šè¿‡æ··åˆLoRAä¸“å®¶æ¶æ„ï¼Œæœ‰æ•ˆè·¯ç”±å’Œæ•´åˆæ¥è‡ªæ•™å¸ˆæ¨¡å‹çš„é«˜å±‚æ¬¡å’Œç»†ç²’åº¦çŸ¥è¯†ã€‚é€šè¿‡åŠ¨æ€è°ƒæ•´ä¸“å®¶çš„è´¡çŒ®ï¼Œå‡å°‘çŸ¥è¯†å†²çªï¼Œä»è€Œæå‡ç”Ÿæˆæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRouteDKæ¡†æ¶ä¸»è¦åŒ…æ‹¬çŸ¥è¯†è’¸é¦æ¨¡å—ã€LoRAä¸“å®¶æ¨¡å—å’ŒåŠ¨æ€èåˆæ¨¡å—ã€‚é¦–å…ˆä»æ•™å¸ˆæ¨¡å‹ä¸­æå–çŸ¥è¯†ï¼Œç„¶åä¸ºä¸åŒç±»å‹çš„çŸ¥è¯†è®­ç»ƒä¸“é—¨çš„LoRAä¸“å®¶ï¼Œæœ€åé€šè¿‡åŠ¨æ€èåˆæ¨¡å—æ•´åˆè¿™äº›ä¸“å®¶çš„è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šRouteDKçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†è¾“å…¥æ„ŸçŸ¥è·¯ç”±å™¨ï¼Œè¯¥è·¯ç”±å™¨èƒ½å¤Ÿæ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´å„ä¸ªLoRAä¸“å®¶çš„æƒé‡ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£çŸ¥è¯†å†²çªã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„é™æ€æƒé‡åˆ†é…æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†çŸ¥è¯†ç‰¹å®šçš„LoRAä¸“å®¶ï¼Œå¹¶ç»“åˆåŸºç¡€LoRAä¸“å®¶è¿›è¡Œè®­ç»ƒã€‚åŠ¨æ€èåˆæ¨¡å—é€šè¿‡è¾“å…¥ç‰¹å¾æ¥å†³å®šå„ä¸“å®¶çš„è´¡çŒ®æƒé‡ï¼Œç¡®ä¿åœ¨æ¨ç†æ—¶çš„å¯é æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRouteDKåœ¨ä¸‰ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å‡†ç¡®æ€§ä¸æ•™å¸ˆLLMç›¸å½“æˆ–æ›´ä¼˜ï¼Œä¸”åœ¨è®¡ç®—æ•ˆç‡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚å…·ä½“è€Œè¨€ï¼ŒRouteDKåœ¨æ†ç»‘ç”Ÿæˆä»»åŠ¡ä¸­å®ç°äº†æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æ›´é«˜çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜å¤§è¯­è¨€æ¨¡å‹çš„è®¡ç®—æ•ˆç‡å’Œç”Ÿæˆæ€§èƒ½ï¼ŒRouteDKèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—é™ä½èµ„æºæ¶ˆè€—ï¼Œå¹¶æå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown potential in automatic bundle generation but suffer from prohibitive computational costs. Although knowledge distillation offers a pathway to more efficient student models, our preliminary study reveals that naively integrating diverse types of distilled knowledge from teacher LLMs into student LLMs leads to knowledge conflict, negatively impacting the performance of bundle generation. To address this, we propose RouteDK, a framework for routing distilled knowledge through a mixture of LoRA expert architecture. Specifically, we first distill knowledge from the teacher LLM for bundle generation in two complementary types: high-level knowledge (generalizable rules) and fine-grained knowledge (session-specific reasoning). We then train knowledge-specific LoRA experts for each type of knowledge together with a base LoRA expert. For effective integration, we propose a dynamic fusion module, featuring an input-aware router, where the router balances expert contributions by dynamically determining optimal weights based on input, thereby effectively mitigating knowledge conflicts. To further improve inference reliability, we design an inference-time enhancement module to reduce variance and mitigate suboptimal reasoning. Experiments on three public datasets show that our RouteDK achieves accuracy comparable to or even better than the teacher LLM, while maintaining strong computational efficiency. In addition, it outperforms state-of-the-art approaches for bundle generation.

