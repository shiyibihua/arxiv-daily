---
layout: default
title: Grounding Multilingual Multimodal LLMs With Cultural Knowledge
---

# Grounding Multilingual Multimodal LLMs With Cultural Knowledge

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07414v2</a>
  <a href="https://arxiv.org/pdf/2508.07414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07414v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07414v2', 'Grounding Multilingual Multimodal LLMs With Cultural Knowledge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jean de Dieu Nyandwi, Yueqi Song, Simran Khanuja, Graham Neubig

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-10 (æ›´æ–°: 2025-08-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–‡åŒ–çŸ¥è¯†é©±åŠ¨çš„å¤šè¯­è¨€å¤šæ¨¡æ€LLMä»¥è§£å†³æ–‡åŒ–å·®è·é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ–‡åŒ–çŸ¥è¯†` `è§†è§‰é—®ç­”` `å¤šè¯­è¨€å¤„ç†` `çŸ¥è¯†å›¾è°±` `æ¨¡å‹è®­ç»ƒ` `è·¨æ–‡åŒ–äº¤æµ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†ä½èµ„æºè¯­è¨€å’Œé•¿å°¾æ–‡åŒ–å®ä½“æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ–‡åŒ–å·®è·é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ•°æ®ä¸­å¿ƒçš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºCulturalGroundæ•°æ®é›†ï¼Œå°†å¤šè¯­è¨€å¤šæ¨¡æ€LLMä¸æ–‡åŒ–çŸ¥è¯†ç›´æ¥ç»“åˆã€‚
3. CulturalPangeaæ¨¡å‹åœ¨æ–‡åŒ–èšç„¦çš„å¤šè¯­è¨€å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æå‡5.0ï¼Œä¸”æœªå½±å“ä¸»æµä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é«˜èµ„æºç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å¤„ç†é•¿å°¾æ–‡åŒ–å®ä½“å’Œä½èµ„æºè¯­è¨€æ—¶å¸¸å¸¸å‡ºç°è¯¯è§£ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„æ–¹æ³•ï¼Œç›´æ¥å°†å¤šè¯­è¨€å¤šæ¨¡æ€LLMï¼ˆMLLMï¼‰ä¸æ–‡åŒ–çŸ¥è¯†ç›¸ç»“åˆã€‚é€šè¿‡åˆ©ç”¨Wikidataçš„å¤§è§„æ¨¡çŸ¥è¯†å›¾è°±ï¼Œæ”¶é›†ä»£è¡¨æ–‡åŒ–é‡è¦å®ä½“çš„å›¾åƒï¼Œå¹¶ç”Ÿæˆåˆæˆçš„å¤šè¯­è¨€è§†è§‰é—®ç­”æ•°æ®ã€‚æœ€ç»ˆæ„å»ºçš„CulturalGroundæ•°æ®é›†åŒ…å«2200ä¸‡å¯¹é«˜è´¨é‡ã€æ–‡åŒ–ä¸°å¯Œçš„è§†è§‰é—®ç­”å¯¹ï¼Œè¦†ç›–42ä¸ªå›½å®¶å’Œ39ç§è¯­è¨€ã€‚åŸºäºCulturalGroundè®­ç»ƒçš„å¼€æºMLLM CulturalPangeaåœ¨å¤šä¸ªæ–‡åŒ–èšç„¦çš„å¤šè¯­è¨€å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æå‡5.0ï¼ŒåŒæ—¶åœ¨ä¸»æµè§†è§‰-è¯­è¨€ä»»åŠ¡ä¸Šæœªå‡ºç°æ€§èƒ½ä¸‹é™ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé’ˆå¯¹æ€§çš„æ–‡åŒ–çŸ¥è¯†é©±åŠ¨æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—ç¼©å°MLLMä¸­çš„æ–‡åŒ–å·®è·ï¼Œä¸ºå…¨çƒåŒ…å®¹æ€§å¤šæ¨¡æ€ç³»ç»Ÿæä¾›äº†å®é™…è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€å’Œé•¿å°¾æ–‡åŒ–å®ä½“å¤„ç†ä¸­çš„è¯¯è§£é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™äº›é¢†åŸŸè¡¨ç°ä¸è¶³ï¼Œå¯¼è‡´æ–‡åŒ–å·®è·åŠ å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«ä¸°å¯Œæ–‡åŒ–çŸ¥è¯†çš„è§†è§‰é—®ç­”æ•°æ®é›†CulturalGroundï¼Œç›´æ¥å°†å¤šè¯­è¨€å¤šæ¨¡æ€LLMä¸æ–‡åŒ–çŸ¥è¯†ç›¸ç»“åˆï¼Œä»¥æå‡æ¨¡å‹åœ¨æ–‡åŒ–ç›¸å…³ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€çŸ¥è¯†å›¾è°±æ„å»ºã€åˆæˆæ•°æ®ç”Ÿæˆå’Œæ¨¡å‹è®­ç»ƒå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»Wikidataä¸­æå–æ–‡åŒ–å®ä½“ä¿¡æ¯ï¼Œç„¶åæ”¶é›†ç›¸åº”çš„å›¾åƒï¼Œç”Ÿæˆè§†è§‰é—®ç­”å¯¹ï¼Œæœ€åä½¿ç”¨è¿™äº›æ•°æ®è®­ç»ƒCulturalPangeaæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡æ–‡åŒ–çŸ¥è¯†å›¾è°±ç›´æ¥å¢å¼ºå¤šè¯­è¨€å¤šæ¨¡æ€LLMçš„è®­ç»ƒï¼Œå¡«è¡¥äº†ç°æœ‰æ¨¡å‹åœ¨æ–‡åŒ–ç†è§£ä¸Šçš„ç©ºç™½ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ä¸ºç²¾å‡†çš„æ–‡åŒ–è¯­å¢ƒç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†é«˜è´¨é‡çš„å›¾åƒå’Œå¤šæ ·åŒ–çš„è¯­è¨€å¯¹ï¼Œä»¥ç¡®ä¿æ•°æ®çš„ä¸°å¯Œæ€§å’Œä»£è¡¨æ€§ï¼›åœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œç»“åˆäº†æ ‡å‡†çš„å¤šè¯­è¨€æŒ‡ä»¤è°ƒä¼˜æ•°æ®ï¼Œä»¥ä¿æŒæ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CulturalPangeaæ¨¡å‹åœ¨æ–‡åŒ–èšç„¦çš„å¤šè¯­è¨€å¤šæ¨¡æ€åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹³å‡æå‡5.0ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æ¨¡å‹ï¼ŒåŒæ—¶åœ¨ä¸»æµè§†è§‰-è¯­è¨€ä»»åŠ¡ä¸Šä¿æŒäº†æ€§èƒ½ç¨³å®šï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è·¨æ–‡åŒ–äº¤æµã€æ•™è‚²ã€æ—…æ¸¸å’Œç¤¾äº¤åª’ä½“ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€LLMåœ¨æ–‡åŒ–ç†è§£ä¸Šçš„èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æœåŠ¡äºå…¨çƒç”¨æˆ·ï¼Œä¿ƒè¿›æ–‡åŒ–é—´çš„ç†è§£ä¸äº¤æµï¼Œæ¨åŠ¨å¤šæ¨¡æ€ç³»ç»Ÿçš„å…¨çƒåŒ…å®¹æ€§å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models excel in high-resource settings, but often misinterpret long-tail cultural entities and underperform in low-resource languages. To address this gap, we propose a data-centric approach that directly grounds MLLMs in cultural knowledge. Leveraging a large scale knowledge graph from Wikidata, we collect images that represent culturally significant entities, and generate synthetic multilingual visual question answering data. The resulting dataset, CulturalGround, comprises 22 million high-quality, culturally-rich VQA pairs spanning 42 countries and 39 languages. We train an open-source MLLM CulturalPangea on CulturalGround, interleaving standard multilingual instruction-tuning data to preserve general abilities. CulturalPangea achieves state-of-the-art performance among open models on various culture-focused multilingual multimodal benchmarks, outperforming prior models by an average of 5.0 without degrading results on mainstream vision-language tasks. Our findings show that our targeted, culturally grounded approach could substantially narrow the cultural gap in MLLMs and offer a practical path towards globally inclusive multimodal systems.

