---
layout: default
title: Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks
---

# Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07179" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07179v1</a>
  <a href="https://arxiv.org/pdf/2508.07179.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07179v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07179v1', 'Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaqi Yin, Yi-Wei Chen, Meng-Lung Lee, Xiya Liu

**åˆ†ç±»**: cs.CL, cs.AI, cs.DB

**å‘å¸ƒæ—¥æœŸ**: 2025-08-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨åŒ–æå–å¤šè¯­è¨€ä¼ä¸šæ•°æ®ç®¡é“çš„æ¨¡å¼è¡€ç»Ÿæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å¼è¡€ç»Ÿæå–` `å¤šè¯­è¨€æ•°æ®ç®¡é“` `è¯­ä¹‰æ¼‚ç§»` `æ•°æ®æ²»ç†` `æœºå™¨å­¦ä¹ è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¼ä¸šæ•°æ®ç®¡é“åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„å¤æ‚è½¬æ¢å¯¼è‡´è¯­ä¹‰æ¼‚ç§»ï¼Œå½±å“æ•°æ®çš„å¯é‡å¤æ€§å’Œæ²»ç†ã€‚
2. æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œè‡ªåŠ¨æå–å¤šè¯­è¨€ä¼ä¸šç®¡é“ä¸­çš„æ¨¡å¼è¡€ç»Ÿï¼Œæ ‡å‡†åŒ–æ•°æ®è½¬æ¢è¡¨ç¤ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹è§„æ¨¡å’Œæç¤ºæŠ€æœ¯çš„å¤æ‚æ€§æ˜¾è‘—æå‡äº†è¡€ç»Ÿæå–çš„æ€§èƒ½ï¼Œ32Bæ¨¡å‹è¡¨ç°æ¥è¿‘GPTç³»åˆ—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¼ä¸šæ•°æ®ç®¡é“å› å¤šç§ç¼–ç¨‹è¯­è¨€çš„å¤æ‚è½¬æ¢ï¼Œå¸¸å¯¼è‡´åŸå§‹å…ƒæ•°æ®ä¸ä¸‹æ¸¸æ•°æ®ä¹‹é—´çš„è¯­ä¹‰æ–­è£‚ã€‚è¿™ç§â€œè¯­ä¹‰æ¼‚ç§»â€å½±å“æ•°æ®çš„å¯é‡å¤æ€§å’Œæ²»ç†ï¼Œé™ä½äº†æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ–‡æœ¬åˆ°SQLç³»ç»Ÿçš„æ•ˆç”¨ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œè‡ªåŠ¨æå–å¤šè¯­è¨€ä¼ä¸šç®¡é“è„šæœ¬ä¸­çš„ç»†ç²’åº¦æ¨¡å¼è¡€ç»Ÿï¼Œè¯†åˆ«æºæ¨¡å¼ã€æºè¡¨ã€è½¬æ¢é€»è¾‘å’Œèšåˆæ“ä½œï¼Œåˆ›å»ºæ•°æ®è½¬æ¢çš„æ ‡å‡†åŒ–è¡¨ç¤ºã€‚ä¸ºä¸¥æ ¼è¯„ä¼°è¡€ç»Ÿè´¨é‡ï¼Œæœ¬æ–‡å¼•å…¥äº†æ¨¡å¼è¡€ç»Ÿå¤åˆè¯„ä¼°ï¼ˆSLiCEï¼‰æŒ‡æ ‡ï¼Œè¯„ä¼°ç»“æ„æ­£ç¡®æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªåŒ…å«1700ä¸ªæ‰‹åŠ¨æ ‡æ³¨è¡€ç»Ÿçš„åŸºå‡†ã€‚å®éªŒè¡¨æ˜ï¼Œè¡€ç»Ÿæå–çš„æ€§èƒ½éšç€æ¨¡å‹è§„æ¨¡å’Œæç¤ºæŠ€æœ¯çš„å¤æ‚æ€§è€Œæå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ä¸šæ•°æ®ç®¡é“ä¸­å› å¤šç§ç¼–ç¨‹è¯­è¨€å¼•èµ·çš„è¯­ä¹‰æ¼‚ç§»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æå–æ¨¡å¼è¡€ç»Ÿæ—¶å­˜åœ¨å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ä¸è¶³çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œé€šè¿‡è¯†åˆ«æºæ¨¡å¼ã€æºè¡¨ã€è½¬æ¢é€»è¾‘å’Œèšåˆæ“ä½œï¼Œæ¥å®ç°å¯¹æ•°æ®è½¬æ¢çš„ç»†ç²’åº¦æå–å’Œæ ‡å‡†åŒ–è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è§£ææ¨¡å—ã€æ¨¡å¼è¯†åˆ«æ¨¡å—å’Œè¯„ä¼°æ¨¡å—ã€‚æ•°æ®è§£ææ¨¡å—è´Ÿè´£ä»å¤šè¯­è¨€è„šæœ¬ä¸­æå–ä¿¡æ¯ï¼Œæ¨¡å¼è¯†åˆ«æ¨¡å—è¿›è¡Œè¡€ç»Ÿæå–ï¼Œè¯„ä¼°æ¨¡å—ä½¿ç”¨SLiCEæŒ‡æ ‡è¿›è¡Œè´¨é‡è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†æ¨¡å¼è¡€ç»Ÿå¤åˆè¯„ä¼°ï¼ˆSLiCEï¼‰æŒ‡æ ‡ï¼Œç»¼åˆè€ƒè™‘ç»“æ„æ­£ç¡®æ€§å’Œè¯­ä¹‰ä¿çœŸåº¦ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°æ–¹å¼ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°åæ˜ è¡€ç»Ÿæå–çš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ä½¿ç”¨äº†12ç§ä¸åŒè§„æ¨¡çš„è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯32Bå¼€æºæ¨¡å‹åœ¨å•ä¸€æ¨ç†è½¨è¿¹ä¸‹çš„è¡¨ç°ä¸GPTç³»åˆ—ç›¸å½“ï¼Œå±•ç¤ºäº†æ¨¡å‹è§„æ¨¡ä¸æå–æ€§èƒ½ä¹‹é—´çš„æ­£ç›¸å…³å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œéšç€æ¨¡å‹è§„æ¨¡çš„å¢åŠ ï¼Œè¡€ç»Ÿæå–çš„æ€§èƒ½æ˜¾è‘—æå‡ã€‚ç‰¹åˆ«æ˜¯32Bå¼€æºæ¨¡å‹åœ¨æ ‡å‡†æç¤ºä¸‹çš„è¡¨ç°ä¸GPTç³»åˆ—ç›¸å½“ï¼Œæ˜¾ç¤ºå‡ºä¸€ç§å¯æ‰©å±•ä¸”ç»æµçš„æ–¹æ¡ˆæ¥éƒ¨ç½²æ¨¡å¼æ„ŸçŸ¥ä»£ç†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¼ä¸šæ•°æ®æ²»ç†ã€æ•°æ®ä»“åº“ç®¡ç†å’Œæ™ºèƒ½æ•°æ®æ£€ç´¢ç­‰ã€‚é€šè¿‡æä¾›å‡†ç¡®çš„æ¨¡å¼è¡€ç»Ÿæå–ï¼Œä¼ä¸šèƒ½å¤Ÿæ›´å¥½åœ°ç®¡ç†æ•°æ®æµåŠ¨ï¼Œæé«˜æ•°æ®çš„å¯è¿½æº¯æ€§å’Œå¯é‡å¤æ€§ï¼Œè¿›è€Œæå‡æ•°æ®é©±åŠ¨å†³ç­–çš„è´¨é‡å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Enterprise data pipelines, characterized by complex transformations across multiple programming languages, often cause a semantic disconnect between original metadata and downstream data. This "semantic drift" compromises data reproducibility and governance, and impairs the utility of services like retrieval-augmented generation (RAG) and text-to-SQL systems. To address this, a novel framework is proposed for the automated extraction of fine-grained schema lineage from multilingual enterprise pipeline scripts. This method identifies four key components: source schemas, source tables, transformation logic, and aggregation operations, creating a standardized representation of data transformations. For the rigorous evaluation of lineage quality, this paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that assesses both structural correctness and semantic fidelity. A new benchmark is also presented, comprising 1,700 manually annotated lineages from real-world industrial scripts. Experiments were conducted with 12 language models, from 1.3B to 32B small language models (SLMs) to large language models (LLMs) like GPT-4o and GPT-4.1. The results demonstrate that the performance of schema lineage extraction scales with model size and the sophistication of prompting techniques. Specially, a 32B open-source model, using a single reasoning trace, can achieve performance comparable to the GPT series under standard prompting. This finding suggests a scalable and economical approach for deploying schema-aware agents in practical applications.

