---
layout: default
title: Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models
---

# Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07173" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07173v2</a>
  <a href="https://arxiv.org/pdf/2508.07173.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07173v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07173v2', 'Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Leyi Pan, Zheyu Fu, Yunpeng Zhai, Shuchang Tao, Sheng Guan, Shiyu Huang, Lingzhe Zhang, Zhaoyang Liu, Bolin Ding, Felix Henry, Aiwei Liu, Lijie Wen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-10 (æ›´æ–°: 2025-09-28)

**å¤‡æ³¨**: 22 pages, 10 figures, 12 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmni-SafetyBenchä»¥è§£å†³éŸ³è§†é¢‘å¤§è¯­è¨€æ¨¡å‹å®‰å…¨è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å®‰å…¨è¯„ä¼°` `éŸ³è§†é¢‘å¤„ç†` `è·¨æ¨¡æ€ä¸€è‡´æ€§` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹OLLMsçš„ä¸“é—¨åŸºå‡†ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°éŸ³è§†é¢‘è”åˆè¾“å…¥çš„å®‰å…¨æ€§å’Œè·¨æ¨¡æ€ä¸€è‡´æ€§ã€‚
2. æå‡ºOmni-SafetyBenchåŸºå‡†ï¼ŒåŒ…å«24ç§æ¨¡æ€å˜ä½“å’Œ972ä¸ªæ ·æœ¬ï¼Œè®¾è®¡äº†å®‰å…¨è¯„åˆ†å’Œè·¨æ¨¡æ€ä¸€è‡´æ€§è¯„åˆ†ä»¥è¯„ä¼°æ¨¡å‹å®‰å…¨æ€§ã€‚
3. è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œåªæœ‰3ä¸ªæ¨¡å‹åœ¨å®‰å…¨è¯„åˆ†å’ŒCMSC-scoreä¸Šè¶…è¿‡0.6ï¼Œå¤æ‚è¾“å…¥ä¸‹å®‰å…¨é˜²å¾¡æ˜¾è‘—å‡å¼±ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨ç‰¹å®šæ¨¡æ€ä¸Šå¾—åˆ†ä½è‡³0.14ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆOLLMsï¼‰çš„å…´èµ·ï¼Œé›†æˆè§†è§‰å’Œå¬è§‰å¤„ç†çš„èƒ½åŠ›ï¼Œè¿«åˆ‡éœ€è¦å¼ºæœ‰åŠ›çš„å®‰å…¨è¯„ä¼°æ¥å‡è½»æœ‰å®³è¾“å‡ºã€‚ç„¶è€Œï¼Œç›®å‰å°šæ— ä¸“é—¨é’ˆå¯¹OLLMsçš„åŸºå‡†ï¼Œç°æœ‰åŸºå‡†æ— æ³•è¯„ä¼°è”åˆéŸ³è§†é¢‘è¾“å…¥æˆ–è·¨æ¨¡æ€ä¸€è‡´æ€§ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†Omni-SafetyBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå…¨é¢çš„OLLMå®‰å…¨è¯„ä¼°åŸºå‡†ï¼ŒåŒ…å«24ç§æ¨¡æ€å˜ä½“ï¼Œæ¯ç§å˜ä½“æœ‰972ä¸ªæ ·æœ¬ï¼ŒåŒ…æ‹¬éŸ³è§†é¢‘å±å®³æ¡ˆä¾‹ã€‚æˆ‘ä»¬æå‡ºäº†å®šåˆ¶çš„è¯„ä¼°æŒ‡æ ‡ï¼šåŸºäºæ¡ä»¶æ”»å‡»æˆåŠŸç‡ï¼ˆC-ASRï¼‰å’Œæ‹’ç»ç‡ï¼ˆC-RRï¼‰çš„å®‰å…¨è¯„åˆ†ï¼Œä»¥åŠè·¨æ¨¡æ€å®‰å…¨ä¸€è‡´æ€§è¯„åˆ†ï¼ˆCMSC-scoreï¼‰ï¼Œä»¥è¯„ä¼°æ¨¡æ€é—´çš„ä¸€è‡´æ€§ã€‚å¯¹6ä¸ªå¼€æºå’Œ4ä¸ªé—­æºçš„OLLMè¿›è¡Œè¯„ä¼°ï¼Œå‘ç°äº†å…³é”®çš„è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†å¢å¼ºOLLMå®‰å…¨æ€§çš„ç´§è¿«éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å½“å‰ç¼ºä¹é’ˆå¯¹å…¨æ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆOLLMsï¼‰å®‰å…¨è¯„ä¼°çš„ä¸“é—¨åŸºå‡†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆè¯„ä¼°éŸ³è§†é¢‘è”åˆè¾“å…¥çš„å®‰å…¨æ€§å’Œè·¨æ¨¡æ€ä¸€è‡´æ€§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤æ‚è¾“å…¥ä¸‹çš„è„†å¼±æ€§æœªè¢«å……åˆ†è¯†åˆ«ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºOmni-SafetyBenchï¼Œä½œä¸ºç¬¬ä¸€ä¸ªå…¨é¢çš„OLLMå®‰å…¨è¯„ä¼°åŸºå‡†ï¼Œè®¾è®¡äº†é’ˆå¯¹å¤æ‚æ¨¡æ€è¾“å…¥çš„å®šåˆ¶è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å…¨é¢è¯„ä¼°æ¨¡å‹çš„å®‰å…¨æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmni-SafetyBenchåŒ…å«24ç§æ¨¡æ€å˜ä½“ï¼Œæ¯ç§å˜ä½“æœ‰972ä¸ªæ ·æœ¬ï¼Œæ¶µç›–éŸ³è§†é¢‘å±å®³æ¡ˆä¾‹ã€‚è¯„ä¼°è¿‡ç¨‹ä¸­ä½¿ç”¨äº†å®‰å…¨è¯„åˆ†ï¼ˆåŸºäºC-ASRå’ŒC-RRï¼‰å’ŒCMSC-scoreæ¥è¡¡é‡æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€é—´çš„ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†é’ˆå¯¹OLLMsçš„ä¸“é—¨å®‰å…¨è¯„ä¼°åŸºå‡†å’Œå®šåˆ¶è¯„ä¼°æŒ‡æ ‡ï¼Œå¡«è¡¥äº†ç°æœ‰æ–¹æ³•åœ¨éŸ³è§†é¢‘è”åˆè¾“å…¥å®‰å…¨æ€§è¯„ä¼°æ–¹é¢çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†å¤šç§æ¨¡æ€ç»„åˆï¼Œè®¾è®¡äº†å®‰å…¨è¯„åˆ†å’ŒCMSC-scoreï¼Œä»¥ä¾¿æ›´å¥½åœ°åæ˜ æ¨¡å‹åœ¨å¤æ‚è¾“å…¥ä¸‹çš„è¡¨ç°å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåªæœ‰3ä¸ªæ¨¡å‹åœ¨å®‰å…¨è¯„åˆ†å’ŒCMSC-scoreä¸Šè¶…è¿‡0.6ï¼Œæ˜¾ç¤ºå‡ºåœ¨å¤æ‚éŸ³è§†é¢‘è¾“å…¥ä¸‹ï¼Œç°æœ‰æ¨¡å‹çš„å®‰å…¨é˜²å¾¡èƒ½åŠ›æ˜¾è‘—å‡å¼±ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨ç‰¹å®šæ¨¡æ€ä¸Šå¾—åˆ†ä½è‡³0.14ï¼Œæ­ç¤ºäº†å½“å‰OLLMsçš„å®‰å…¨æ€§äºŸå¾…æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨å†…å®¹ç”Ÿæˆã€æ™ºèƒ½åŠ©æ‰‹å’Œå¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡OLLMsçš„å®‰å…¨æ€§ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘æœ‰å®³è¾“å‡ºï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rise of Omni-modal Large Language Models (OLLMs), which integrate visual and auditory processing with text, necessitates robust safety evaluations to mitigate harmful outputs. However, no dedicated benchmarks currently exist for OLLMs, and existing benchmarks fail to assess safety under joint audio-visual inputs or cross-modal consistency. To fill this gap, we introduce Omni-SafetyBench, the first comprehensive parallel benchmark for OLLM safety evaluation, featuring 24 modality variations with 972 samples each, including audio-visual harm cases. Considering OLLMs' comprehension challenges with complex omni-modal inputs and the need for cross-modal consistency evaluation, we propose tailored metrics: a Safety-score based on Conditional Attack Success Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and a Cross-Modal Safety Consistency score (CMSC-score) to measure consistency across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals critical vulnerabilities: (1) only 3 models achieving over 0.6 in both average Safety-score and CMSC-score; (2) safety defenses weaken with complex inputs, especially audio-visual joints; (3) severe weaknesses persist, with some models scoring as low as 0.14 on specific modalities. Using Omni-SafetyBench, we evaluated existing safety alignment algorithms and identified key challenges in OLLM safety alignment: (1) Inference-time methods are inherently less effective as they cannot alter the model's underlying understanding of safety; (2) Post-training methods struggle with out-of-distribution issues due to the vast modality combinations in OLLMs; and, safety tasks involving audio-visual inputs are more complex, making even in-distribution training data less effective. Our proposed benchmark, metrics and the findings highlight urgent needs for enhanced OLLM safety.

