---
layout: default
title: Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification
---

# Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04592" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04592v1</a>
  <a href="https://arxiv.org/pdf/2506.04592.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04592v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04592v1', 'Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Yasheng Wang, Lifeng Shang, Qun Liu, Ming Zhang

**ÂàÜÁ±ª**: cs.CL, cs.AI, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05

**Â§áÊ≥®**: Accepted in ACL 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SafeÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÊï∞Â≠¶Êé®ÁêÜ‰∏≠ÁöÑÂπªËßâÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êï∞Â≠¶Êé®ÁêÜ` `ÂΩ¢ÂºèÈ™åËØÅ` `ÈìæÂºèÊÄùÁª¥` `Lean 4` `ÂπªËßâÈóÆÈ¢ò` `Ëá™Âä®ÂåñËØÅÊòé`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÈìæÂºèÊÄùÁª¥ÊèêÁ§∫ÊñπÊ≥ïÂú®Â§ÑÁêÜÂπªËßâÈóÆÈ¢òÊó∂Áº∫‰πèÈÄèÊòéÊÄßÂíåÂèØÈ™åËØÅÊÄßÔºåÈôêÂà∂‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑSafeÊ°ÜÊû∂ÈÄöËøá‰ΩøÁî®ÂΩ¢ÂºèÊï∞Â≠¶ËØ≠Ë®ÄLean 4‰∏∫ÊØè‰∏™Êé®ÁêÜÊ≠•È™§Êèê‰æõÊ≠£ÂºèËØÅÊòéÔºå‰ªéËÄåÂ¢ûÂº∫‰∫ÜÊé®ÁêÜÁöÑÂèØÈù†ÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSafeÊ°ÜÊû∂Âú®Â§ö‰∏™ËØ≠Ë®ÄÊ®°ÂûãÂíåÊï∞Â≠¶Êï∞ÊçÆÈõÜ‰∏äÊòæËëóÊèêÂçá‰∫ÜÊÄßËÉΩÔºåÂπ∂Êèê‰æõ‰∫ÜÂèØËß£ÈáäÁöÑÈ™åËØÅËØÅÊçÆ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈìæÂºèÊÄùÁª¥ÔºàCoTÔºâÊèêÁ§∫Â∑≤Êàê‰∏∫ÂºïÂØºÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊé®ÁêÜËÉΩÂäõÁöÑ‰∏ªË¶ÅÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÊñπÊ≥ïÂ¶ÇËøáÁ®ãÂ•ñÂä±Ê®°ÂûãÔºàPRMsÔºâÊàñËá™‰∏ÄËá¥ÊÄßÂú®Âà§Êñ≠‰∏äÁº∫‰πèÂèØÊ£ÄÊü•ÁöÑËØÅÊçÆÔºåÂèØËÉΩÈôêÂà∂ÂÖ∂ÊúâÊïàÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂõûÈ°æÊÄß„ÄÅÈÄêÊ≠•ÊÑèËØÜÁöÑÂΩ¢ÂºèÈ™åËØÅÊ°ÜÊû∂Safe„ÄÇÊàë‰ª¨Âú®ÊØè‰∏™Êé®ÁêÜÊ≠•È™§‰∏≠‰ΩøÁî®ÂΩ¢ÂºèÊï∞Â≠¶ËØ≠Ë®ÄLean 4Êù•ÈòêËø∞Êï∞Â≠¶Â£∞ÊòéÔºåÂπ∂Êèê‰æõÊ≠£ÂºèËØÅÊòé‰ª•ËØÜÂà´ÂπªËßâ„ÄÇÈÄöËøáÂú®Â§ö‰∏™ËØ≠Ë®ÄÊ®°ÂûãÂíåÂêÑÁßçÊï∞Â≠¶Êï∞ÊçÆÈõÜ‰∏äÁöÑËØÑ‰º∞ÔºåÊàë‰ª¨ÁöÑÊ°ÜÊû∂SafeÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂêåÊó∂Êèê‰æõ‰∫ÜÂèØËß£ÈáäÂíåÂèØÈ™åËØÅÁöÑËØÅÊçÆ„ÄÇÊàë‰ª¨ËøòÊèêÂá∫‰∫ÜFormalStep‰Ωú‰∏∫Ê≠•È™§Ê≠£Á°ÆÊÄßÂÆöÁêÜËØÅÊòéÁöÑÂü∫ÂáÜÔºåÂåÖÂê´30,809‰∏™Ê≠£ÂºèÂ£∞Êòé„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÈ¶ñÊ¨°Âà©Áî®ÂΩ¢ÂºèÊï∞Â≠¶ËØ≠Ë®ÄLean 4Êù•È™åËØÅLLMsÁîüÊàêÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂÜÖÂÆπ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êï∞Â≠¶Êé®ÁêÜ‰∏≠‰∫ßÁîüÂπªËßâÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ¶ÇËøáÁ®ãÂ•ñÂä±Ê®°ÂûãÂíåËá™‰∏ÄËá¥ÊÄßÁº∫‰πèÈÄèÊòéÊÄßÔºåÊó†Ê≥ïÊèê‰æõÂèØÊ£ÄÊü•ÁöÑËØÅÊçÆÔºåÂØºËá¥Êé®ÁêÜÁªìÊûúÁöÑÂèØ‰ø°Â∫¶Èôç‰Ωé„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊàë‰ª¨ÊèêÂá∫ÁöÑSafeÊ°ÜÊû∂ÈÄöËøáÂú®ÊØè‰∏™Êé®ÁêÜÊ≠•È™§‰∏≠‰ΩøÁî®ÂΩ¢ÂºèÊï∞Â≠¶ËØ≠Ë®ÄLean 4Êù•ÊòéÁ°ÆÊï∞Â≠¶Â£∞ÊòéÔºåÂπ∂Êèê‰æõÊ≠£ÂºèËØÅÊòéÔºå‰ª•Ê≠§Êù•ËØÜÂà´ÂíåÁ∫†Ê≠£ÂπªËßâÁé∞Ë±°„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°Êó®Âú®ÊèêÈ´òÊé®ÁêÜÁöÑÂèØÈ™åËØÅÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSafeÊ°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºåÈ¶ñÂÖàÊòØËæìÂÖ•ÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÊï∞Â≠¶ÈóÆÈ¢òÔºåÁÑ∂ÂêéÈÄöËøáLean 4ËøõË°åÈÄêÊ≠•Êé®ÁêÜÔºåÊúÄÂêéÁîüÊàêÊ≠£ÂºèËØÅÊòéÂπ∂ËøõË°åÈ™åËØÅ„ÄÇÊï¥‰∏™ÊµÅÁ®ãÁ°Æ‰øùÊØè‰∏ÄÊ≠•ÈÉΩÊúâÊòéÁ°ÆÁöÑÊï∞Â≠¶‰æùÊçÆ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSafeÊ°ÜÊû∂ÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫éÈ¶ñÊ¨°Â∞ÜÂΩ¢ÂºèÊï∞Â≠¶ËØ≠Ë®ÄLean 4Â∫îÁî®‰∫éÈ™åËØÅLLMsÁîüÊàêÁöÑËá™ÁÑ∂ËØ≠Ë®ÄÂÜÖÂÆπ„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏éÁé∞ÊúâÁöÑÈªëÁÆ±Ê®°ÂûãÂΩ¢ÊàêÈ≤úÊòéÂØπÊØîÔºåÊèê‰æõ‰∫ÜÂèØÈ™åËØÅÁöÑÊé®ÁêÜËøáÁ®ã„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåSafeÊ°ÜÊû∂ËÆæÁΩÆ‰∫ÜÁâπÂÆöÁöÑÂèÇÊï∞‰ª•‰ºòÂåñLean 4ÁöÑÊé®ÁêÜËøáÁ®ãÔºåÂπ∂ËÆæËÆ°‰∫ÜÊçüÂ§±ÂáΩÊï∞‰ª•ÊúÄÂ∞èÂåñÂπªËßâÁöÑÂèëÁîü„ÄÇÂêåÊó∂ÔºåÁΩëÁªúÁªìÊûÑÁªèËøáË∞ÉÊï¥Ôºå‰ª•‰æøÊõ¥Â•ΩÂú∞Â§ÑÁêÜÂΩ¢ÂºèÂåñÁöÑÊï∞Â≠¶ËØ≠Ë®Ä„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåSafeÊ°ÜÊû∂Âú®Â§ö‰∏™ËØ≠Ë®ÄÊ®°Âûã‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®Êï∞Â≠¶Êé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜXX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÂπ∂‰∏îÂú®Êèê‰æõÁöÑÈ™åËØÅËØÅÊçÆÊñπÈù¢ÔºåÊòæËëó‰ºò‰∫é‰º†ÁªüÁöÑËøáÁ®ãÂ•ñÂä±Ê®°ÂûãÂíåËá™‰∏ÄËá¥ÊÄßÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊïôËÇ≤„ÄÅËá™Âä®ÂåñËØÅÊòéÂíåÁßëÂ≠¶Á†îÁ©∂Á≠â„ÄÇÈÄöËøáÊèêÈ´òÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êï∞Â≠¶Êé®ÁêÜ‰∏≠ÁöÑÂèØÈù†ÊÄßÔºåSafeÊ°ÜÊû∂ÂèØ‰ª•Â∏ÆÂä©Â≠¶ÁîüÊõ¥Â•ΩÂú∞ÁêÜËß£Êï∞Â≠¶Ê¶ÇÂøµÔºåËæÖÂä©Á†îÁ©∂‰∫∫ÂëòËøõË°åÂ§çÊùÇÁöÑÊï∞Â≠¶ËØÅÊòéÔºåÂπ∂Âú®Ëá™Âä®ÂåñÁ≥ªÁªü‰∏≠Êèê‰æõÊõ¥È´òÁöÑÂÜ≥Á≠ñÊîØÊåÅ„ÄÇÊú™Êù•ÔºåËØ•Ê°ÜÊû∂ÂèØËÉΩÊé®Âä®ÂΩ¢ÂºèÂåñÈ™åËØÅÂú®Êõ¥ÂπøÊ≥õÈ¢ÜÂüüÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Chain-of-Thought (CoT) prompting has become the de facto method to elicit reasoning capabilities from large language models (LLMs). However, to mitigate hallucinations in CoT that are notoriously difficult to detect, current methods such as process reward models (PRMs) or self-consistency operate as opaque boxes and do not provide checkable evidence for their judgments, possibly limiting their effectiveness. To address this issue, we draw inspiration from the idea that "the gold standard for supporting a mathematical claim is to provide a proof". We propose a retrospective, step-aware formal verification framework $Safe$. Rather than assigning arbitrary scores, we strive to articulate mathematical claims in formal mathematical language Lean 4 at each reasoning step and provide formal proofs to identify hallucinations. We evaluate our framework $Safe$ across multiple language models and various mathematical datasets, demonstrating a significant performance improvement while offering interpretable and verifiable evidence. We also propose $FormalStep$ as a benchmark for step correctness theorem proving with $30,809$ formal statements. To the best of our knowledge, our work represents the first endeavor to utilize formal mathematical language Lean 4 for verifying natural language content generated by LLMs, aligning with the reason why formal mathematical languages were created in the first place: to provide a robust foundation for hallucination-prone human-written proofs.

