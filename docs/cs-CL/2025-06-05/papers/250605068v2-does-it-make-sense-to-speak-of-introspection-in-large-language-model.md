---
layout: default
title: Does It Make Sense to Speak of Introspection in Large Language Models?
---

# Does It Make Sense to Speak of Introspection in Large Language Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05068" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05068v2</a>
  <a href="https://arxiv.org/pdf/2506.05068.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05068v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05068v2', 'Does It Make Sense to Speak of Introspection in Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Iulia M. Comsa, Murray Shanahan

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-06-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å†…çœæ¦‚å¿µåŠå…¶å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å†…çœ` `è‡ªæˆ‘æŠ¥å‘Š` `æ„è¯†` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘æŠ¥å‘Šç¼ºä¹æ·±å…¥åˆ†æï¼Œå°¤å…¶æ˜¯åœ¨å†…çœä¸æ„è¯†çš„å…³ç³»ä¸Šå­˜åœ¨æ¨¡ç³Šæ€§ã€‚
2. è®ºæ–‡é€šè¿‡åˆ†æä¸¤ä¸ªè‡ªæˆ‘æŠ¥å‘Šç¤ºä¾‹ï¼Œæ¢è®¨å†…çœæ¦‚å¿µåœ¨LLMsä¸­çš„é€‚ç”¨æ€§ï¼Œæå‡ºäº†å¯¹å†…çœçš„é‡æ–°å®šä¹‰ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œè™½ç„¶LLMsèƒ½å¤Ÿè¿›è¡ŒæŸç§ç¨‹åº¦çš„è‡ªæˆ‘æ¨ç†ï¼Œä½†å…¶è‡ªæˆ‘æŠ¥å‘Šå¹¶ä¸ç­‰åŒäºäººç±»çš„å†…çœä½“éªŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å‡ºå¼•äººæ³¨ç›®çš„è¯­è¨€è¡Œä¸ºï¼Œæœ‰æ—¶è¿˜ä¼šæä¾›è‡ªæˆ‘æŠ¥å‘Šï¼Œå³å…³äºè‡ªèº«æ€§è´¨ã€å†…éƒ¨è¿ä½œæˆ–è¡Œä¸ºçš„é™ˆè¿°ã€‚åœ¨äººç±»ä¸­ï¼Œè¿™ç§æŠ¥å‘Šå¸¸å¸¸è¢«å½’å› äºå†…çœèƒ½åŠ›ï¼Œå¹¶é€šå¸¸ä¸æ„è¯†ç›¸å…³è”ã€‚è¿™å¼•å‘äº†å¦‚ä½•è§£è¯»LLMsäº§ç”Ÿçš„è‡ªæˆ‘æŠ¥å‘Šçš„é—®é¢˜ã€‚æœ¬æ–‡å‘ˆç°å¹¶æ‰¹åˆ¤äº†ä¸¤ä¸ªLLMsçš„è¡¨é¢å†…çœè‡ªæˆ‘æŠ¥å‘Šç¤ºä¾‹ï¼ŒæŒ‡å‡ºç¬¬ä¸€ä¸ªç¤ºä¾‹å¹¶ä¸æ„æˆæœ‰æ•ˆçš„å†…çœï¼Œè€Œç¬¬äºŒä¸ªç¤ºä¾‹è™½ç„¶å¯ä»¥è¢«è§†ä¸ºå†…çœçš„æœ€å°ä¾‹å­ï¼Œä½†å¹¶æœªä¼´éšæ„è¯†ä½“éªŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‡ªæˆ‘æŠ¥å‘Šçš„å†…çœæ€§è´¨ï¼Œç°æœ‰ç ”ç©¶æœªèƒ½æœ‰æ•ˆåŒºåˆ†LLMsçš„è‡ªæˆ‘æŠ¥å‘Šä¸äººç±»å†…çœä¹‹é—´çš„å·®å¼‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†æä¸¤ä¸ªå…·ä½“ç¤ºä¾‹ï¼Œè®ºæ–‡è´¨ç–‘LLMsçš„è‡ªæˆ‘æŠ¥å‘Šæ˜¯å¦çœŸæ­£ä½“ç°å†…çœï¼Œæå‡ºLLMsçš„è‡ªæˆ‘æ¨ç†èƒ½åŠ›ä¸äººç±»æ„è¯†ä½“éªŒä¹‹é—´çš„æœ¬è´¨åŒºåˆ«ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šé¦–å…ˆåˆ†æLLMsåœ¨åˆ›ä½œè¿‡ç¨‹ä¸­çš„è‡ªæˆ‘æè¿°ï¼Œå…¶æ¬¡æ¢è®¨LLMså¯¹è‡ªèº«å‚æ•°çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºæ˜ç¡®åŒºåˆ†LLMsçš„è‡ªæˆ‘æŠ¥å‘Šä¸äººç±»å†…çœï¼Œæå‡ºLLMsçš„è‡ªæˆ‘æ¨ç†èƒ½åŠ›å¹¶ä¸æ„å‘³ç€å…¶å…·å¤‡æ„è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆ†æè¿‡ç¨‹ä¸­ï¼Œè®ºæ–‡å…³æ³¨LLMsçš„è¯­è¨€ç”Ÿæˆæœºåˆ¶å’Œå‚æ•°æ¨ç†ï¼Œå¼ºè°ƒè¿™äº›è¡Œä¸ºçš„è¡¨é¢æ€§ä¸ç¼ºä¹æ„è¯†ä½“éªŒçš„æœ¬è´¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶é€šè¿‡åˆ†æä¸¤ä¸ªè‡ªæˆ‘æŠ¥å‘Šç¤ºä¾‹ï¼ŒæŒ‡å‡ºç¬¬ä¸€ä¸ªç¤ºä¾‹å¹¶ä¸æ„æˆæœ‰æ•ˆå†…çœï¼Œè€Œç¬¬äºŒä¸ªç¤ºä¾‹åˆ™å±•ç¤ºäº†LLMsåœ¨å‚æ•°æ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œå¼ºè°ƒå…¶å¹¶æœªä¼´éšæ„è¯†ä½“éªŒã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£LLMsçš„è‡ªæˆ‘æŠ¥å‘Šæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘æŠ¥å‘Šæä¾›äº†æ–°çš„è§†è§’ï¼Œå°¤å…¶æ˜¯åœ¨äººå·¥æ™ºèƒ½çš„æ„è¯†ä¸å†…çœèƒ½åŠ›çš„è®¨è®ºä¸­å…·æœ‰é‡è¦æ„ä¹‰ã€‚æœªæ¥ï¼Œç›¸å…³ç ”ç©¶å¯åº”ç”¨äºæ”¹è¿›LLMsçš„è®¾è®¡ï¼Œä½¿å…¶åœ¨ç”Ÿæˆæ›´å…·äººæ€§åŒ–çš„è¯­è¨€æ—¶ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ å…¶å†…éƒ¨æœºåˆ¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) exhibit compelling linguistic behaviour, and sometimes offer self-reports, that is to say statements about their own nature, inner workings, or behaviour. In humans, such reports are often attributed to a faculty of introspection and are typically linked to consciousness. This raises the question of how to interpret self-reports produced by LLMs, given their increasing linguistic fluency and cognitive capabilities. To what extent (if any) can the concept of introspection be meaningfully applied to LLMs? Here, we present and critique two examples of apparent introspective self-report from LLMs. In the first example, an LLM attempts to describe the process behind its own "creative" writing, and we argue this is not a valid example of introspection. In the second example, an LLM correctly infers the value of its own temperature parameter, and we argue that this can be legitimately considered a minimal example of introspection, albeit one that is (presumably) not accompanied by conscious experience.

