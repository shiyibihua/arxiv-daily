---
layout: default
title: Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers
---

# Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05038" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05038v1</a>
  <a href="https://arxiv.org/pdf/2506.05038.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05038v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05038v1', 'Automatic Robustness Stress Testing of LLMs as Mathematical Problem Solvers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yutao Hou, Zeguan Xiao, Fei Yu, Yihan Jiang, Xuetao Wei, Hailiang Huang, Yun Chen, Guanhua Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAR-Checkerä»¥è§£å†³LLMsçš„é²æ£’æ€§æµ‹è¯•é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é²æ£’æ€§æµ‹è¯•` `æ•°å­¦é—®é¢˜ç”Ÿæˆ` `è‡ªåŠ¨åŒ–è¯„ä¼°` `å¤šè½®é‡å†™`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°LLMsçš„é²æ£’æ€§æ—¶ä¾èµ–æ‰‹å·¥æ¨¡æ¿æˆ–æœ‰é™çš„æ‰°åŠ¨è§„åˆ™ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºçš„AR-Checkeræ¡†æ¶é€šè¿‡å¤šè½®å¹¶è¡Œçš„LLMé‡å†™å’ŒéªŒè¯ç”Ÿæˆæ•°å­¦é—®é¢˜å˜ä½“ï¼Œæ—¨åœ¨æé«˜é²æ£’æ€§æµ‹è¯•çš„æœ‰æ•ˆæ€§ã€‚
3. åœ¨GSM8Kå’ŒMATH-500ç­‰æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAR-Checkeråœ¨æ•°å­¦ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨å…¶ä»–åŸºå‡†ä¸Šä¹Ÿå–å¾—äº†è‰¯å¥½æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§æ¨ç†å¯†é›†å‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨æŸäº›ç®€å•æ¨ç†ä»»åŠ¡ä¸­ä»å¯èƒ½é¢ä¸´é²æ£’æ€§é—®é¢˜ï¼Œå¯¼è‡´æ„å¤–å¤±è´¥ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡æ‰‹å·¥æ¨¡æ¿æˆ–æœ‰é™çš„æ‰°åŠ¨è§„åˆ™è¯„ä¼°LLMsçš„é²æ£’æ€§ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®æ±¡æŸ“çš„é£é™©ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶â€”â€”è‡ªåŠ¨é²æ£’æ€§æ£€æŸ¥å™¨ï¼ˆAR-Checkerï¼‰ï¼Œé€šè¿‡å¤šè½®å¹¶è¡Œçš„LLMé‡å†™å’ŒéªŒè¯ç”Ÿæˆæ•°å­¦é—®é¢˜å˜ä½“ï¼Œä¿æŒåŸé—®é¢˜çš„è¯­ä¹‰ä½†å¯èƒ½å¯¼è‡´LLMså¤±è´¥ã€‚AR-Checkerèƒ½å¤ŸåŠ¨æ€ç”Ÿæˆæ¯ä¸ªLLMçš„åŸºå‡†å˜ä½“ï¼Œä»è€Œæœ€å°åŒ–æ•°æ®æ±¡æŸ“é£é™©ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAR-Checkeråœ¨æ•°å­¦ä»»åŠ¡å’Œå…¶ä»–åŸºå‡†ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç®€å•æ¨ç†ä»»åŠ¡ä¸­çš„é²æ£’æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å®¹æ˜“å—åˆ°æ•°æ®æ±¡æŸ“çš„å½±å“ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAR-Checkeræ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡ç”Ÿæˆè¯­ä¹‰ç›¸åŒä½†å¯èƒ½å¯¼è‡´LLMså¤±è´¥çš„æ•°å­¦é—®é¢˜å˜ä½“ï¼Œæ¥è¿›è¡Œé²æ£’æ€§æµ‹è¯•ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAR-Checkerçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šè½®å¹¶è¡Œçš„LLMé‡å†™å’ŒéªŒè¯æ¨¡å—ï¼Œé¦–å…ˆç”Ÿæˆé—®é¢˜å˜ä½“ï¼Œç„¶åé€šè¿‡éªŒè¯ç¡®ä¿å…¶è¯­ä¹‰ä¸€è‡´æ€§ï¼Œæœ€åè¯„ä¼°LLMsçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šAR-Checkerçš„ä¸»è¦åˆ›æ–°åœ¨äºåŠ¨æ€ç”Ÿæˆé’ˆå¯¹æ¯ä¸ªLLMçš„åŸºå‡†å˜ä½“ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¯èƒ½å‡ºç°çš„æ•°æ®æ±¡æŸ“é—®é¢˜ï¼Œæå‡äº†é²æ£’æ€§æµ‹è¯•çš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒAR-Checkeré‡‡ç”¨äº†å¤šè½®é‡å†™ç­–ç•¥ï¼Œç»“åˆäº†å¤šç§éªŒè¯æœºåˆ¶ï¼Œç¡®ä¿ç”Ÿæˆçš„é—®é¢˜å˜ä½“åœ¨è¯­ä¹‰ä¸Šä¸åŸé—®é¢˜ä¸€è‡´ï¼ŒåŒæ—¶è®¾ç½®äº†åˆç†çš„å‚æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAR-Checkeråœ¨GSM8Kå’ŒMATH-500æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†LLMsçš„é²æ£’æ€§ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æ•°å­¦ä»»åŠ¡ä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æé«˜äº†20%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œåœ¨MMLUã€MMLU-Proå’ŒCommonsenseQAç­‰å…¶ä»–åŸºå‡†ä¸Šä¹Ÿå–å¾—äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰ã€‚AR-Checkerèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´å¯é çš„æ¨¡å‹è¯„ä¼°å·¥å…·ï¼Œå¸®åŠ©å¼€å‘æ›´é²æ£’çš„LLMsï¼Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have achieved distinguished performance on various reasoning-intensive tasks. However, LLMs might still face the challenges of robustness issues and fail unexpectedly in some simple reasoning tasks. Previous works evaluate the LLM robustness with hand-crafted templates or a limited set of perturbation rules, indicating potential data contamination in pre-training or fine-tuning datasets. In this work, inspired by stress testing in software engineering, we propose a novel framework, Automatic Robustness Checker (AR-Checker), to generate mathematical problem variants that maintain the semantic meanings of the original one but might fail the LLMs. The AR-Checker framework generates mathematical problem variants through multi-round parallel streams of LLM-based rewriting and verification. Our framework can generate benchmark variants dynamically for each LLM, thus minimizing the risk of data contamination. Experiments on GSM8K and MATH-500 demonstrate the strong performance of AR-Checker on mathematical tasks. We also evaluate AR-Checker on benchmarks beyond mathematics, including MMLU, MMLU-Pro, and CommonsenseQA, where it also achieves strong performance, further proving the effectiveness of AR-Checker.

