---
layout: default
title: Context Is Not Comprehension
---

# Context Is Not Comprehension

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04907" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04907v4</a>
  <a href="https://arxiv.org/pdf/2506.04907.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04907v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04907v4', 'Context Is Not Comprehension')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alex Pan, Mary-Anne Williams

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-06-12)

**å¤‡æ³¨**: 24 pages, 2 figures, 4 tables; under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVerbose ListOpsåŸºå‡†ä»¥è¯„ä¼°è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è¯„ä¼°åŸºå‡†` `å¤šæ­¥éª¤æ¨ç†` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸»è¦å…³æ³¨è¯­è¨€æ¨¡å‹çš„è®°å¿†èƒ½åŠ›ï¼Œå¿½è§†äº†å…¶æ¨ç†å’ŒçŠ¶æ€è·Ÿè¸ªçš„èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºVerbose ListOpsåŸºå‡†ï¼Œé€šè¿‡å™äº‹ä¼ªè£…åµŒå…¥ListOpsè®¡ç®—ï¼Œå…è®¸é€æ­¥è¯„ä¼°æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹åœ¨æ ‡å‡†ListOpsä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨VLOä¸Šå´æ˜¾è‘—ä¸‹é™ï¼Œæ­ç¤ºäº†å…¶æ¨ç†èƒ½åŠ›çš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨å…¶ä»é•¿è¾“å…¥ä¸­å›å¿†æ˜¾æ€§äº‹å®çš„èƒ½åŠ›ä¸Šã€‚å°½ç®¡ç°æœ‰æ¨¡å‹åœ¨æ­¤æ–¹é¢è¡¨ç°æ¥è¿‘å®Œç¾ï¼Œä½†è¿™æ©ç›–äº†æ›´å¤æ‚çš„æŠ€èƒ½ï¼šå¤šæ­¥éª¤æ¨ç†å’Œè·Ÿè¸ªæœªé€å­—å‡ºç°çš„ä¸­é—´çŠ¶æ€ã€‚æœ¬æ–‡æå‡ºäº†Verbose ListOpsï¼ˆVLOï¼‰åŸºå‡†ï¼Œå®ƒå°†ç¡®å®šæ€§çš„ListOpsè®¡ç®—åµŒå…¥å™äº‹ä¼ªè£…ä¸­ï¼Œå¹¶å…è®¸å¯¹æ¯ä¸ªä¸­é—´ç»“æœè¿›è¡Œé€æ­¥è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹åœ¨åŸå§‹ListOpsä¸Šå‡†ç¡®ç‡æ¥è¿‘100%ï¼Œä½†åœ¨VLOä¸Šå´åœ¨ä»…10,000ä¸ªæ ‡è®°åå´©æºƒã€‚VLOé€šè¿‡æ­ç¤ºæ¨¡å‹æ¨ç†é“¾é¦–æ¬¡åç¦»çš„åœ°æ–¹ï¼Œå°†è¯„ä¼°ä»å•çº¯çš„ä¸Šä¸‹æ–‡é•¿åº¦è½¬å‘çœŸæ­£çš„ç†è§£ã€‚VLOçš„ç”Ÿæˆç®¡é“æ˜¯ä»»åŠ¡æ— å…³çš„ï¼Œå¯ä»¥å°†ä»»ä½•ç¡®å®šæ€§å¯éªŒè¯çš„æ¨ç†æ¨¡å¼ç¼–ç»‡æˆå™äº‹å½¢å¼ï¼Œæˆä¸ºä¸‹ä¸€æ³¢ä»¥æ¨ç†ä¸ºä¸­å¿ƒçš„æ¨¡å‹è®¾è®¡çš„å¯é‡ç”¨æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å…¶åœ¨å¤šæ­¥éª¤æ¨ç†å’Œä¸­é—´çŠ¶æ€è·Ÿè¸ªæ–¹é¢çš„èƒ½åŠ›ç¼ºå¤±ã€‚ç°æœ‰æ–¹æ³•è¿‡äºä¾èµ–ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæœªèƒ½çœŸå®åæ˜ æ¨¡å‹çš„ç†è§£èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºVerbose ListOpsï¼ˆVLOï¼‰åŸºå‡†ï¼Œé€šè¿‡å°†ç¡®å®šæ€§çš„ListOpsè®¡ç®—åµŒå…¥å™äº‹ä¸­ï¼Œå…è®¸å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„é€æ­¥è¯„ä¼°ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°å…¶ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVLOçš„ç”Ÿæˆç®¡é“æ˜¯ä»»åŠ¡æ— å…³çš„ï¼Œèƒ½å¤Ÿå°†ä»»ä½•å¯éªŒè¯çš„æ¨ç†æ¨¡å¼ï¼ˆå¦‚ç®—æœ¯ã€ç¬¦å·ã€æ¨æµ‹ç­‰ï¼‰ç¼–ç»‡æˆå™äº‹å½¢å¼ã€‚æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥ç”Ÿæˆã€æ¨ç†è¿‡ç¨‹åµŒå…¥å’Œé€æ­¥è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šVLOçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å…è®¸é€æ­¥è¯„ä¼°æ¨ç†è¿‡ç¨‹ï¼Œæ­ç¤ºæ¨¡å‹æ¨ç†é“¾çš„åç¦»ç‚¹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ·±å…¥çš„ç†è§£è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VLOä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å™äº‹ç»“æ„å’Œæ¨ç†æ¨¡å¼ï¼Œç¡®ä¿æ¯ä¸ªä¸­é—´ç»“æœéƒ½å¯ä»¥è¢«æ˜ç¡®è¯„ä¼°ï¼Œä¸”æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½å¤Ÿè¢«æœ‰æ•ˆç›‘æ§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹åœ¨åŸå§‹ListOpsä¸Šå‡†ç¡®ç‡æ¥è¿‘100%ï¼Œä½†åœ¨VLOåŸºå‡†ä¸Šå´åœ¨ä»…10,000ä¸ªæ ‡è®°åå´©æºƒï¼Œè¡¨æ˜æ¨¡å‹åœ¨å¤šæ­¥éª¤æ¨ç†æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚è¿™ä¸€å‘ç°çªæ˜¾äº†VLOåœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹ç†è§£èƒ½åŠ›æ–¹é¢çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ•™è‚²æŠ€æœ¯å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒVLOå¯ä»¥å¸®åŠ©å¼€å‘æ›´æ™ºèƒ½çš„å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–å·¥å…·ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼ŒVLOå¯èƒ½æˆä¸ºè¯„ä¼°æ¨ç†èƒ½åŠ›çš„æ ‡å‡†åŸºå‡†ï¼Œå½±å“ç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œå¼€å‘æ–¹å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The dominant way of judging Large Language Models (LLMs) has been to ask how well they can recall explicit facts from very long inputs. While today's best models achieve near perfect recall, this masks a harder skill: performing multi-step reasoning and tracking intermediate state that never appears verbatim. We introduce Verbose ListOps (VLO), a benchmark that embeds deterministic ListOps computations inside narrative camouflage and, crucially, allows step-level evaluation of every intermediate result. Experiments show that models which solve raw ListOps with approximately 100% accuracy collapse on VLO after only 10,000 tokens. By exposing where a model's reasoning chain first diverges, VLO moves assessment beyond sheer context length and toward genuine comprehension. VLO's generation pipeline is task-agnostic: it can weave any deterministically verifiable reasoning schema -- arithmetic, symbolic, abductive, inductive or defeasible -- into narrative form. This makes VLO a reusable test-bed for the next wave of reasoning-centric model designs, not merely those with step-explicit scaffolds.

