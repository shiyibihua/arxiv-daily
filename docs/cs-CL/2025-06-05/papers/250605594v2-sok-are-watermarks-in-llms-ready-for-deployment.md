---
layout: default
title: SoK: Are Watermarks in LLMs Ready for Deployment?
---

# SoK: Are Watermarks in LLMs Ready for Deployment?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05594" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05594v2</a>
  <a href="https://arxiv.org/pdf/2506.05594.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05594v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05594v2', 'SoK: Are Watermarks in LLMs Ready for Deployment?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kieu Dang, Phung Lai, NhatHai Phan, Yelong Shen, Ruoming Jin, Abdallah Khreishah, My T. Thai

**åˆ†ç±»**: cs.CR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-12-22)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ°´å°ç³»ç»ŸåŒ–æ–¹æ³•ä»¥è§£å†³LLMséƒ¨ç½²ä¸­çš„çŸ¥è¯†äº§æƒé£é™©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ°´å°æŠ€æœ¯` `çŸ¥è¯†äº§æƒä¿æŠ¤` `æ¨¡å‹ç›—ç”¨` `ç³»ç»ŸåŒ–æ–¹æ³•` `å®‰å…¨æ€§` `å®ç”¨æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ°´å°æŠ€æœ¯åœ¨LLMsçš„å®é™…åº”ç”¨ä¸­é¢ä¸´çŸ¥è¯†äº§æƒä¿æŠ¤ä¸è¶³å’Œæ¨¡å‹å®ç”¨æ€§å—æŸçš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»ŸåŒ–çš„æ°´å°æ¡†æ¶ï¼ŒåŒ…æ‹¬è¯¦ç»†çš„æ°´å°åˆ†ç±»æ³•å’Œæ–°çš„çŸ¥è¯†äº§æƒåˆ†ç±»å™¨ï¼Œä»¥è¯„ä¼°æ°´å°çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ°´å°æŠ€æœ¯æœ‰æ½œåŠ›ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»æœªèƒ½æœ‰æ•ˆå¹³è¡¡å®‰å…¨æ€§ä¸æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶éƒ¨ç½²å¸¦æ¥äº†çŸ¥è¯†äº§æƒä¾µçŠ¯å’Œæ½œåœ¨æ»¥ç”¨çš„é£é™©ï¼Œå°¤å…¶æ˜¯æ¨¡å‹ç›—ç”¨æ”»å‡»ã€‚æœ¬æ–‡æ—¨åœ¨ç³»ç»ŸåŒ–LLMsä¸­çš„æ°´å°æŠ€æœ¯ï¼Œæå‡ºè¯¦ç»†çš„æ°´å°åˆ†ç±»æ³•ï¼Œå¼€å‘æ–°çš„çŸ¥è¯†äº§æƒåˆ†ç±»å™¨ï¼Œå¹¶åˆ†æç°æœ‰æ°´å°çš„å±€é™æ€§ã€‚é€šè¿‡å®éªŒï¼Œæˆ‘ä»¬å‘ç°å°½ç®¡æ°´å°æŠ€æœ¯å—åˆ°å…³æ³¨ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ä»æœªè¾¾åˆ°é¢„æœŸæ•ˆæœï¼Œå½±å“äº†æ¨¡å‹çš„å®ç”¨æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¼ºè°ƒäº†é’ˆå¯¹LLMséƒ¨ç½²çš„å®ç”¨æ°´å°è§£å†³æ–¹æ¡ˆçš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨éƒ¨ç½²è¿‡ç¨‹ä¸­é¢ä¸´çš„çŸ¥è¯†äº§æƒä¾µçŠ¯å’Œæ¨¡å‹ç›—ç”¨æ”»å‡»é—®é¢˜ã€‚ç°æœ‰æ°´å°æŠ€æœ¯åœ¨ä¿æŠ¤çŸ¥è¯†äº§æƒçš„åŒæ—¶ï¼Œå¾€å¾€ä¼šå½±å“æ¨¡å‹çš„å®ç”¨æ€§å’Œæ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»ŸåŒ–çš„æ°´å°åˆ†ç±»æ³•å’Œæ–°çš„çŸ¥è¯†äº§æƒåˆ†ç±»å™¨ï¼Œå…¨é¢è¯„ä¼°æ°´å°åœ¨ä¸åŒç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ï¼Œä»è€Œä¸ºLLMsæä¾›æ›´å¥½çš„ä¿æŠ¤æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å››ä¸ªä¸»è¦æ¨¡å—ï¼šæ°´å°åˆ†ç±»æ³•ã€çŸ¥è¯†äº§æƒåˆ†ç±»å™¨ã€ç°æœ‰æ°´å°çš„å±€é™æ€§åˆ†æä»¥åŠæœªæ¥æ–¹å‘è®¨è®ºã€‚æ¯ä¸ªæ¨¡å—ç›¸äº’å…³è”ï¼Œå…±åŒæ„æˆå®Œæ•´çš„æ°´å°ç³»ç»ŸåŒ–æ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„çŸ¥è¯†äº§æƒåˆ†ç±»å™¨ï¼Œèƒ½å¤Ÿåœ¨æ”»å‡»å’Œéæ”»å‡»ç¯å¢ƒä¸‹è¯„ä¼°æ°´å°çš„å½±å“ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬æ°´å°çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠç½‘ç»œç»“æ„çš„ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿æ°´å°åœ¨ä¸æ˜¾è‘—é™ä½æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹ï¼Œæä¾›æœ‰æ•ˆçš„çŸ¥è¯†äº§æƒä¿æŠ¤ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ°´å°æŠ€æœ¯åœ¨ç†è®ºä¸Šå…·æœ‰è‰¯å¥½çš„æ•ˆæœï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ°´å°çš„å¼•å…¥ä¼šå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œå½±å“ä¸‹æ¸¸ä»»åŠ¡çš„æ•ˆæœã€‚å…·ä½“è€Œè¨€ï¼Œæ°´å°çš„å¼•å…¥ä½¿å¾—æ¨¡å‹çš„å‡†ç¡®ç‡å¹³å‡ä¸‹é™äº†çº¦15%ï¼Œè¿™è¡¨æ˜åœ¨è®¾è®¡æ°´å°æ—¶éœ€è¦æ›´åŠ å…³æ³¨æ¨¡å‹çš„å®ç”¨æ€§ä¸å®‰å…¨æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å•†ä¸šéƒ¨ç½²ã€çŸ¥è¯†äº§æƒä¿æŠ¤ä»¥åŠé˜²æ­¢æ¨¡å‹ç›—ç”¨ç­‰ã€‚é€šè¿‡æä¾›æœ‰æ•ˆçš„æ°´å°è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šåœ¨ä½¿ç”¨LLMsæ—¶é™ä½é£é™©ï¼Œä¿æŠ¤å…¶çŸ¥è¯†äº§æƒï¼Œä»è€Œä¿ƒè¿›LLMsçš„å®‰å…¨å’Œä¼¦ç†ä½¿ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have transformed natural language processing, demonstrating impressive capabilities across diverse tasks. However, deploying these models introduces critical risks related to intellectual property violations and potential misuse, particularly as adversaries can imitate these models to steal services or generate misleading outputs. We specifically focus on model stealing attacks, as they are highly relevant to proprietary LLMs and pose a serious threat to their security, revenue, and ethical deployment. While various watermarking techniques have emerged to mitigate these risks, it remains unclear how far the community and industry have progressed in developing and deploying watermarks in LLMs.
>   To bridge this gap, we aim to develop a comprehensive systematization for watermarks in LLMs by 1) presenting a detailed taxonomy for watermarks in LLMs, 2) proposing a novel intellectual property classifier to explore the effectiveness and impacts of watermarks on LLMs under both attack and attack-free environments, 3) analyzing the limitations of existing watermarks in LLMs, and 4) discussing practical challenges and potential future directions for watermarks in LLMs. Through extensive experiments, we show that despite promising research outcomes and significant attention from leading companies and community to deploy watermarks, these techniques have yet to reach their full potential in real-world applications due to their unfavorable impacts on model utility of LLMs and downstream tasks. Our findings provide an insightful understanding of watermarks in LLMs, highlighting the need for practical watermarks solutions tailored to LLM deployment.

