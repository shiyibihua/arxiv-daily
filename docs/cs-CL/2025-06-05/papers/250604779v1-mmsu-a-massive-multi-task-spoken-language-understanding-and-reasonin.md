---
layout: default
title: MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark
---

# MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04779" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04779v1</a>
  <a href="https://arxiv.org/pdf/2506.04779.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04779v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04779v1', 'MMSU: A Massive Multi-task Spoken Language Understanding and Reasoning Benchmark')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dingdong Wang, Jincenzi Wu, Junan Li, Dongchao Yang, Xueyuan Chen, Tianhua Zhang, Helen Meng

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: MMSU benchmark is available at https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available at https://github.com/dingdongwang/MMSU_Bench

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/dingdongwang/MMSU_Bench) | [HUGGINGFACE](https://huggingface.co/datasets/ddwang2000)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMSUåŸºå‡†ä»¥è§£å†³å¤šä»»åŠ¡å£è¯­ç†è§£ä¸æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å£è¯­ç†è§£` `å¤šä»»åŠ¡å­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `å¤šæ¨¡æ€èåˆ` `è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹` `è¯­è¨€ç°è±¡` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€ä¸­çš„ç»†ç²’åº¦æ„ŸçŸ¥å’Œå¤æ‚æ¨ç†èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚
2. MMSUåŸºå‡†é€šè¿‡5000ä¸ªéŸ³é¢‘-é—®é¢˜-ç­”æ¡ˆä¸‰å…ƒç»„ï¼Œç³»ç»Ÿæ€§åœ°æ•´åˆäº†å¤šç§è¯­è¨€ç°è±¡ä»¥æå‡å£è¯­ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚
3. å¯¹14ä¸ªå…ˆè¿›æ¨¡å‹çš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨å£è¯­ç†è§£æ–¹é¢ä»æœ‰æ˜¾è‘—çš„æå‡ç©ºé—´ï¼ŒæŒ‡å¼•æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å£è¯­ä¸­è•´å«ä¸°å¯Œçš„å£°å­¦ä¿¡æ¯ï¼Œè¶…è¶Šäº†æ–‡æœ¬è¯­è¨€çš„èŒƒç•´ã€‚åœ¨å®é™…çš„å£è¯­ç†è§£ä¸­ï¼Œæœ‰æ•ˆçš„è§£è¯»é€šå¸¸éœ€è¦æ•´åˆè¯­ä¹‰æ„ä¹‰ã€æ—è¯­è¨€ç‰¹å¾å’ŒéŸ³éŸµç‰¹å¾ã€‚å°½ç®¡è¿‘æœŸçš„å¤šæ¨¡æ€è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éŸ³é¢‘ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åœ¨è‡ªç„¶è¯­éŸ³ä¸­çš„ç»†ç²’åº¦æ„ŸçŸ¥å’Œå¤æ‚æ¨ç†èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†MMSUåŸºå‡†ï¼Œä¸“é—¨ç”¨äºå£è¯­ç†è§£å’Œæ¨ç†ã€‚MMSUåŒ…å«5000ä¸ªç²¾å¿ƒç­–åˆ’çš„éŸ³é¢‘-é—®é¢˜-ç­”æ¡ˆä¸‰å…ƒç»„ï¼Œæ¶µç›–47ä¸ªä¸åŒä»»åŠ¡ï¼Œå¹¶ç³»ç»Ÿæ€§åœ°èå…¥äº†å¤šç§è¯­è¨€ç°è±¡ã€‚é€šè¿‡å¯¹14ä¸ªå…ˆè¿›çš„è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹çš„ä¸¥æ ¼è¯„ä¼°ï¼Œå‘ç°ç°æœ‰æ¨¡å‹ä»æœ‰æ˜¾è‘—æ”¹è¿›ç©ºé—´ï¼Œä¸ºæœªæ¥çš„ä¼˜åŒ–æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹åœ¨å£è¯­ç†è§£å’Œæ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç»†ç²’åº¦æ„ŸçŸ¥å’Œå¤æ‚æ¨ç†èƒ½åŠ›çš„ç¼ºå¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMMSUåŸºå‡†é€šè¿‡æ•´åˆå¤šç§è¯­è¨€ç°è±¡ï¼Œæä¾›äº†ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨æ¨åŠ¨å£è¯­ç†è§£å’Œæ¨ç†çš„ç ”ç©¶è¿›å±•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMMSUçš„æ•´ä½“æ¶æ„åŒ…æ‹¬éŸ³é¢‘è¾“å…¥ã€é—®é¢˜ç”Ÿæˆå’Œç­”æ¡ˆç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œæ¶µç›–äº†ä»éŸ³é¢‘å¤„ç†åˆ°è¯­ä¹‰ç†è§£çš„å®Œæ•´æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMMSUçš„åˆ›æ–°ç‚¹åœ¨äºå…¶ç³»ç»Ÿæ€§åœ°èå…¥äº†è¯­éŸ³å­¦ã€éŸµå¾‹å­¦ã€ä¿®è¾å­¦ã€å¥æ³•å­¦ã€è¯­ä¹‰å­¦å’Œæ—è¯­è¨€å­¦ç­‰å¤šç§è¯­è¨€ç°è±¡ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è¯„ä¼°ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°å‡è¡¡ï¼Œå…·ä½“ç»†èŠ‚åŒ…æ‹¬éŸ³é¢‘ç‰¹å¾æå–å’Œè¯­ä¹‰åµŒå…¥çš„ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¯¹14ä¸ªå…ˆè¿›è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°ä¸­ï¼ŒMMSUåŸºå‡†æ­ç¤ºäº†ç°æœ‰æ¨¡å‹åœ¨å£è¯­ç†è§£æ–¹é¢çš„æ˜¾è‘—ä¸è¶³ï¼Œéƒ¨åˆ†æ¨¡å‹çš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºä¼˜åŒ–çš„æ½œåŠ›å’Œæ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MMSUåŸºå‡†çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€æƒ…æ„Ÿè¯†åˆ«ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å£è¯­ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œè¯¥ç ”ç©¶ä¸ºæ„å»ºæ›´å¤æ‚çš„äººæœºè¯­éŸ³äº¤äº’ç³»ç»Ÿæä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ï¼Œæœªæ¥å¯èƒ½åœ¨æ•™è‚²ã€å®¢æœç­‰å¤šä¸ªè¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Speech inherently contains rich acoustic information that extends far beyond the textual language. In real-world spoken language understanding, effective interpretation often requires integrating semantic meaning (e.g., content), paralinguistic features (e.g., emotions, speed, pitch) and phonological characteristics (e.g., prosody, intonation, rhythm), which are embedded in speech. While recent multimodal Speech Large Language Models (SpeechLLMs) have demonstrated remarkable capabilities in processing audio information, their ability to perform fine-grained perception and complex reasoning in natural speech remains largely unexplored. To address this gap, we introduce MMSU, a comprehensive benchmark designed specifically for understanding and reasoning in spoken language. MMSU comprises 5,000 meticulously curated audio-question-answer triplets across 47 distinct tasks. To ground our benchmark in linguistic theory, we systematically incorporate a wide range of linguistic phenomena, including phonetics, prosody, rhetoric, syntactics, semantics, and paralinguistics. Through a rigorous evaluation of 14 advanced SpeechLLMs, we identify substantial room for improvement in existing models, highlighting meaningful directions for future optimization. MMSU establishes a new standard for comprehensive assessment of spoken language understanding, providing valuable insights for developing more sophisticated human-AI speech interaction systems. MMSU benchmark is available at https://huggingface.co/datasets/ddwang2000/MMSU. Evaluation Code is available at https://github.com/dingdongwang/MMSU_Bench.

