---
layout: default
title: Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights
---

# Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04851" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04851v1</a>
  <a href="https://arxiv.org/pdf/2506.04851.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04851v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04851v1', 'Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Giorgio Biancini, Alessio Ferrato, Carla Limongelli

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05

**Â§áÊ≥®**: Copyright ACM 2024. This is the author's version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization (UMAP Adjunct '24), http://dx.doi.org/10.1145/3631700.3665233

**DOI**: [10.1145/3631700.3665233](https://doi.org/10.1145/3631700.3665233)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢ò‰ª•Ëß£ÂÜ≥ÊïôËÇ≤ËØÑ‰º∞ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Â§öÈ°πÈÄâÊã©È¢ò` `ÊïôËÇ≤ÊäÄÊúØ` `‰∫∫Â∑•Êô∫ËÉΩ` `Áü•ËØÜÊ≥®ÂÖ•` `ËØÑ‰º∞Â∑•ÂÖ∑` `ÊïôËÇ≤ËØÑ‰º∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÈ°πÈÄâÊã©È¢òÁîüÊàêÊñπÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊó∂Èó¥ÂíåËÆ§Áü•ËµÑÊ∫êÔºåÊïàÁéá‰Ωé‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÈÄöËøáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢òÔºåÂà©Áî®ÊèêÁ§∫Ê≥®ÂÖ•Áü•ËØÜ‰ª•ÊèêÈ´òÁîüÊàêË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGPT-3.5ÁîüÊàêÁöÑÂ§öÈ°πÈÄâÊã©È¢òÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË°®Áé∞ÊúÄ‰Ω≥ÔºåÊòæÁ§∫Âá∫ÂÖ∂Âú®ÊïôËÇ≤‰∏≠ÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞Ü‰∫∫Â∑•Êô∫ËÉΩÔºàAIÔºâËûçÂÖ•ÊïôËÇ≤È¢ÜÂüüÂ∏¶Êù•‰∫ÜÊñ∞ÁöÑÂ≠¶‰π†ÊñπÊ≥ïÔºåÊîπÂèò‰∫ÜÂ≠¶ÁîüÂíåÊïôËÇ≤ËÄÖÁöÑÂÆûË∑µ„ÄÇÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâ‰Ωú‰∏∫Âº∫Â§ßÁöÑÊïôËÇ≤ÊùêÊñôÂíåÈóÆÁ≠îÂ∑•ÂÖ∑ÔºåÂÖ∑ÊúâÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢òÔºàMCQsÔºâÁöÑÊΩúÂäõ„ÄÇÊú¨ÊñáÂØπ‰∏âÁßçÁü•ÂêçÁöÑLLM‚Äî‚ÄîLlama 2„ÄÅMistralÂíåGPT-3.5ËøõË°å‰∫ÜÊØîËæÉÂàÜÊûêÔºåÊé¢ËÆ®ÂÖ∂ÁîüÊàê‰ø°ÊÅØ‰∏∞ÂØå‰∏îÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑMCQsÁöÑËÉΩÂäõ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÈÄöËøáÂú®ÊèêÁ§∫‰∏≠Ê≥®ÂÖ•Áü•ËØÜÊù•ÂØπÊäóÊ®°ÂûãÁöÑÂπªËßâÔºåËµã‰∫àÊïôËÇ≤ËÄÖÂØπÊµãËØïÊ∫êÊñáÊú¨ÁöÑÊéßÂà∂„ÄÇÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåGPT-3.5Âú®Â§ö‰∏™Â∑≤Áü•ÊåáÊ†á‰∏äÁîüÊàêÁöÑMCQsÊïàÊûúÊúÄ‰Ω≥ÔºåÂêåÊó∂‰πüÂèçÊò†Âá∫ÊïôËÇ≤È¢ÜÂüüÂØπAIÁöÑÈááÁî®‰ªçÂ≠òÂú®‰∏ÄÂÆöÁöÑÁäπË±´„ÄÇËØ•Á†îÁ©∂‰∏∫LLMsÂú®MCQsÁîüÊàê‰∏≠ÁöÑÊΩúÂäõÊèê‰æõ‰∫ÜÈáçË¶ÅËßÅËß£ÔºåÊîπÂñÑ‰∫ÜÊïôËÇ≤‰ΩìÈ™å„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÊïôËÇ≤ËÄÖÂú®ÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢òÊó∂Èù¢‰∏¥ÁöÑÊó∂Èó¥ÂíåËÆ§Áü•Ë¥üÊãÖÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊïàÁéá‰Ωé‰∏ã‰∏îÈöæ‰ª•‰øùËØÅÈ¢òÁõÆÁöÑË¥®Èáè„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêÂ§öÈ°πÈÄâÊã©È¢òÔºå‰ΩúËÄÖÂú®ÊèêÁ§∫‰∏≠Ê≥®ÂÖ•Áü•ËØÜÔºå‰ª•ÂáèÂ∞ëÊ®°ÂûãÁöÑÂπªËßâÁé∞Ë±°Ôºå‰ªéËÄåÊèêÈ´òÁîüÊàêÈ¢òÁõÆÁöÑÂáÜÁ°ÆÊÄßÂíåÁõ∏ÂÖ≥ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊñπÊ≥ïÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÈ¶ñÂÖàÔºåÈÄâÊã©ÂêàÈÄÇÁöÑLLMÔºõÂÖ∂Ê¨°ÔºåËÆæËÆ°ÂåÖÂê´Áü•ËØÜÁöÑÊèêÁ§∫ÔºõÊúÄÂêéÔºåËØÑ‰º∞ÁîüÊàêÁöÑMCQsË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÈÄöËøáÊèêÁ§∫Ê≥®ÂÖ•Áü•ËØÜÁöÑÊñπÂºèÔºåËµã‰∫àÊïôËÇ≤ËÄÖÂØπÁîüÊàêÂÜÖÂÆπÁöÑÊéßÂà∂ÊùÉÔºåËøô‰∏é‰º†Áªü‰æùËµñÊ®°ÂûãÂÜÖÁΩÆÁü•ËØÜÁöÑÊñπÊ≥ïÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠Ôºå‰ΩøÁî®‰∫ÜÁâπÂÆöÁöÑÊèêÁ§∫Ê†ºÂºèÂíåËØÑ‰º∞Ê†áÂáÜÔºåÁ°Æ‰øùÁîüÊàêÁöÑMCQsÁ¨¶ÂêàÊïôËÇ≤ÁõÆÊ†áÔºåÂêåÊó∂ÂØπÊØî‰∫Ü‰∏çÂêåLLMÁöÑË°®Áé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåGPT-3.5ÁîüÊàêÁöÑÂ§öÈ°πÈÄâÊã©È¢òÂú®Â§ö‰∏™ËØÑ‰º∞ÊåáÊ†á‰∏äË°®Áé∞ÊúÄ‰Ω≥ÔºåÂÖ∑‰ΩìÊÄßËÉΩÊï∞ÊçÆË°®ÊòéÂÖ∂Âú®‰ø°ÊÅØ‰∏∞ÂØåÊÄßÂíåÊåëÊàòÊÄßÊñπÈù¢‰ºò‰∫éLlama 2ÂíåMistralÔºåÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏ä„ÄÇËøô‰∏ÄÂèëÁé∞‰∏∫ÊïôËÇ≤È¢ÜÂüüÁöÑAIÂ∫îÁî®Êèê‰æõ‰∫ÜÈáçË¶Å‰æùÊçÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÊïôËÇ≤ËØÑ‰º∞„ÄÅÂú®Á∫øÂ≠¶‰π†Âπ≥Âè∞ÂíåÊô∫ËÉΩËæÖÂØºÁ≥ªÁªü„ÄÇÈÄöËøáÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁîüÊàêÈ´òË¥®ÈáèÁöÑÂ§öÈ°πÈÄâÊã©È¢òÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÊïôËÇ≤ËÄÖÁöÑÂ∑•‰ΩúÊïàÁéáÔºåÊîπÂñÑÂ≠¶ÁîüÁöÑÂ≠¶‰π†‰ΩìÈ™åÔºåÊé®Âä®ÊïôËÇ≤ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test's source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.

