---
layout: default
title: Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study
---

# Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04810" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04810v2</a>
  <a href="https://arxiv.org/pdf/2506.04810.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04810v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04810v2', 'Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yujun Zhou, Jiayi Ye, Zipeng Ling, Yufei Han, Yue Huang, Haomin Zhuang, Zhenwen Liang, Kehan Guo, Taicheng Guo, Xiangqi Wang, Xiangliang Zhang

**åˆ†ç±»**: cs.CL, cs.AI, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-10-09)

**å¤‡æ³¨**: Accepted by the Findings of EMNLP 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/YujunZhou/FineLogic)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFineLogicæ¡†æ¶ä»¥è§£å†³LLMsé€»è¾‘æ¨ç†è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é€»è¾‘æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç»†ç²’åº¦è¯„ä¼°` `å¾®è°ƒç­–ç•¥` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é€»è¾‘æ¨ç†è¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œæ— æ³•æœ‰æ•ˆåæ˜ æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚
2. æœ¬æ–‡æå‡ºFineLogicæ¡†æ¶ï¼Œé€šè¿‡æ•´ä½“å‡†ç¡®æ€§ã€é€æ­¥åˆç†æ€§å’Œè¡¨ç¤ºå±‚æ¬¡æ¢æµ‹ä¸‰ä¸ªç»´åº¦è¯„ä¼°é€»è¾‘æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè‡ªç„¶è¯­è¨€ç›‘ç£åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶è¡¨ç°ä¼˜è¶Šï¼Œè€Œç¬¦å·ç›‘ç£åˆ™åœ¨æ¨ç†æ­¥éª¤çš„ç»“æ„åˆç†æ€§ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€»è¾‘æ¨ç†æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œä½†ç°æœ‰åŸºå‡†ä»…ä¾èµ–æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œæ— æ³•å…¨é¢æ•æ‰æ¨ç†è¿‡ç¨‹çš„è´¨é‡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºFineLogicï¼Œä¸€ä¸ªç»†ç²’åº¦è¯„ä¼°æ¡†æ¶ï¼Œä»æ•´ä½“å‡†ç¡®æ€§ã€é€æ­¥åˆç†æ€§å’Œè¡¨ç¤ºå±‚æ¬¡æ¢æµ‹ä¸‰ä¸ªç»´åº¦è¯„ä¼°é€»è¾‘æ¨ç†ã€‚é€šè¿‡è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬å…¨é¢ç ”ç©¶äº†ä¸åŒå¾®è°ƒç›‘ç£æ ¼å¼å¯¹æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå‘ç°è‡ªç„¶è¯­è¨€ç›‘ç£åœ¨å¤„ç†åˆ†å¸ƒå¤–å’Œé•¿é“¾é—®é¢˜æ—¶è¡¨ç°ä¼˜è¶Šï¼Œè€Œç¬¦å·ç›‘ç£åˆ™åœ¨æ„å»ºç»“æ„åˆç†çš„åŸå­æ¨ç†æ­¥éª¤ä¸Šæ›´å…·ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæ¢æµ‹åˆ†æè¡¨æ˜ï¼Œå¾®è°ƒä¸»è¦ä¼˜åŒ–æ¨¡å‹çš„é€æ­¥ç”Ÿæˆè¿‡ç¨‹ï¼Œè€Œéæ—©æœŸæ”¶æ•›èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¡†æ¶å’Œåˆ†æä¸ºè¯„ä¼°å’Œæå‡LLMsçš„é€»è¾‘æ¨ç†æä¾›äº†æ›´ä¸¥æ ¼çš„è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é€»è¾‘æ¨ç†è¯„ä¼°æ–¹æ³•æ— æ³•å…¨é¢æ•æ‰æ¨ç†è¿‡ç¨‹è´¨é‡çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä»…å…³æ³¨æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œå¿½è§†äº†æ¨ç†è¿‡ç¨‹ä¸­çš„ç»†èŠ‚å’Œåˆç†æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºFineLogicæ¡†æ¶ï¼Œé€šè¿‡ç»†ç²’åº¦çš„è¯„ä¼°æ–¹å¼ï¼Œä»å¤šä¸ªç»´åº¦åˆ†æLLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œæ—¨åœ¨æå‡è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFineLogicæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ•´ä½“å‡†ç¡®æ€§è¯„ä¼°ã€é€æ­¥åˆç†æ€§è¯„ä¼°å’Œè¡¨ç¤ºå±‚æ¬¡æ¢æµ‹ã€‚æ•´ä½“å‡†ç¡®æ€§è¯„ä¼°å…³æ³¨æœ€ç»ˆç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼Œé€æ­¥åˆç†æ€§è¯„ä¼°åˆ†ææ¨ç†è¿‡ç¨‹ä¸­çš„æ¯ä¸€æ­¥ï¼Œè¡¨ç¤ºå±‚æ¬¡æ¢æµ‹åˆ™è¯„ä¼°æ¨¡å‹å¯¹æ¨ç†è¡¨ç¤ºçš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»†ç²’åº¦çš„è¯„ä¼°ç»´åº¦ï¼Œä½¿å¾—é€»è¾‘æ¨ç†çš„è¯„ä¼°ä¸ä»…é™äºæœ€ç»ˆç»“æœï¼Œè¿˜å…³æ³¨æ¨ç†è¿‡ç¨‹çš„æ¯ä¸€æ­¥ï¼Œæä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†å››ç§ä¸åŒçš„ç›‘ç£æ ¼å¼ï¼ŒåŒ…æ‹¬è‡ªç„¶è¯­è¨€å’Œä¸‰ç§ç¬¦å·å˜ä½“ï¼Œå®éªŒä¸­å‘ç°è‡ªç„¶è¯­è¨€ç›‘ç£åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶è¡¨ç°æ›´ä½³ï¼Œè€Œç¬¦å·ç›‘ç£åˆ™åœ¨æ¨ç†æ­¥éª¤çš„ç»“æ„åˆç†æ€§ä¸Šæ›´ä¸ºçªå‡ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè‡ªç„¶è¯­è¨€ç›‘ç£åœ¨å¤„ç†åˆ†å¸ƒå¤–å’Œé•¿é“¾é—®é¢˜æ—¶çš„å‡†ç¡®ç‡æ˜¾è‘—é«˜äºç¬¦å·ç›‘ç£ï¼Œåè€…åœ¨æ¨ç†æ­¥éª¤çš„ç»“æ„åˆç†æ€§ä¸Šè¡¨ç°æ›´ä½³ã€‚FineLogicæ¡†æ¶æä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°æ–¹æ³•ï¼Œä¸ºLLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›æå‡æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ³•å¾‹æ¨ç†ã€è‡ªåŠ¨åŒ–å†³ç­–ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æå‡LLMsåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚é€šè¿‡æ›´ç²¾ç»†çš„è¯„ä¼°å’Œå¾®è°ƒç­–ç•¥ï¼Œæœªæ¥å¯ä»¥åœ¨æ›´å¹¿æ³›çš„å®é™…åœºæ™¯ä¸­åº”ç”¨LLMsï¼Œæå‡å…¶é€»è¾‘æ¨ç†èƒ½åŠ›å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Logical reasoning is a core capability for large language models (LLMs), yet existing benchmarks that rely solely on final-answer accuracy fail to capture the quality of the reasoning process. To address this, we introduce FineLogic, a fine-grained evaluation framework that assesses logical reasoning across three dimensions: overall accuracy, stepwise soundness, and representation-level probing. Leveraging this framework, we conduct a comprehensive study on how different supervision formats in fine-tuning shape reasoning abilities. We fine-tune LLMs on four supervision styles: one in natural language and three symbolic variants. We find a key trade-off: natural language supervision excels at generalization to out-of-distribution and long-chain problems, whereas symbolic supervision is superior at instilling structurally sound, atomic reasoning steps. Furthermore, our probing analysis indicates that fine-tuning primarily refines the model's step-by-step generation process, rather than improving its ability to converge on an answer early. Together, our framework and analysis provide a more rigorous lens for evaluating and improving logical reasoning in LLMs. The code is available at https://github.com/YujunZhou/FineLogic.

