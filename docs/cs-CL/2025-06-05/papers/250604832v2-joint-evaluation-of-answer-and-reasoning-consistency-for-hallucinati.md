---
layout: default
title: Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models
---

# Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04832" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04832v2</a>
  <a href="https://arxiv.org/pdf/2506.04832.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04832v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04832v2', 'Joint Evaluation of Answer and Reasoning Consistency for Hallucination Detection in Large Reasoning Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Changyue Wang, Weihang Su, Qingyao Ai, Yiqun Liu

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05 (Êõ¥Êñ∞: 2025-11-15)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/bebr2/RACE)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RACEÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßÂûãÊé®ÁêÜÊ®°Âûã‰∏≠ÁöÑÂπªËßâÊ£ÄÊµãÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãÊé®ÁêÜÊ®°Âûã` `ÂπªËßâÊ£ÄÊµã` `Êé®ÁêÜ‰∏ÄËá¥ÊÄß` `Â§öÊ≠•È™§Êé®ÁêÜ` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ` `Êô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªü` `Ê®°ÂûãÈÄèÊòéÊÄß`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂπªËßâÊ£ÄÊµãÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®Á≠îÊ°àÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÊú™ËÉΩÊúâÊïàÊ£ÄÊµãÊé®ÁêÜËΩ®Ëøπ‰∏≠ÁöÑÂπªËßâÂíåÈÄªËæë‰∏ç‰∏ÄËá¥„ÄÇ
2. ÊèêÂá∫RACEÊ°ÜÊû∂ÔºåÈÄöËøáÊèêÂèñÊé®ÁêÜÊ≠•È™§Âπ∂ËÆ°ÁÆóÂõõ‰∏™ËØäÊñ≠‰ø°Âè∑ÔºåÂ¢ûÂº∫ÂπªËßâÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåRACEÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÂü∫Á∫øÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®LRMs‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÊôÆÈÄÇÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãÊé®ÁêÜÊ®°ÂûãÔºàLRMsÔºâÈÄöËøáÊòæÂºèÁöÑÂ§öÊ≠•È™§Êé®ÁêÜËΩ®ËøπÊâ©Â±ï‰∫ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºå‰ª•ÊèêÈ´òÂú®Â§çÊùÇ‰ªªÂä°‰∏äÁöÑÈÄèÊòéÂ∫¶ÂíåÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊé®ÁêÜËΩ®ËøπÂèØËÉΩÂÜó‰ΩôÊàñÈÄªËæë‰∏ç‰∏ÄËá¥ÔºåÊàê‰∏∫‰∏ÄÁßçÊñ∞ÁöÑÈöæ‰ª•Ê£ÄÊµãÁöÑÂπªËßâÊù•Ê∫ê„ÄÇÁé∞ÊúâÁöÑÂπªËßâÊ£ÄÊµãÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠Âú®Á≠îÊ°àÁ∫ßÂà´ÁöÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÂæÄÂæÄÊó†Ê≥ïÊ£ÄÊµãÂá∫Ê®°ÂûãÊé®ÁêÜËΩ®Ëøπ‰∏≠ÁöÑÂπªËßâÊàñÈÄªËæë‰∏ç‰∏ÄËá¥„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜRACEÔºàÊé®ÁêÜ‰∏éÁ≠îÊ°à‰∏ÄËá¥ÊÄßËØÑ‰º∞ÔºâÊ°ÜÊû∂Ôºå‰∏ìÈó®Áî®‰∫éLRMs‰∏≠ÁöÑÂπªËßâÊ£ÄÊµã„ÄÇRACEÈÄöËøáÊèêÂèñÂÖ≥ÈîÆÊé®ÁêÜÊ≠•È™§Âπ∂ËÆ°ÁÆóÂõõ‰∏™ËØäÊñ≠‰ø°Âè∑Ôºå‰ΩøÂÖ∂Êàê‰∏∫LRMs‰∏≠Êõ¥‰∏∫Á®≥ÂÅ•ÁöÑÂπªËßâÊ£ÄÊµãÂô®„ÄÇÂÆûÈ™åË°®ÊòéÔºåRACEÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜÂíå‰∏çÂêåÁöÑLLM‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÂπªËßâÊ£ÄÊµãÂü∫Á∫øÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçÁ®≥ÂÅ•‰∏îÂÖ∑ÊúâÊôÆÈÄÇÊÄßÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßÂûãÊé®ÁêÜÊ®°ÂûãÔºàLRMsÔºâ‰∏≠ÂπªËßâÊ£ÄÊµãÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÊúâÊïàËØÜÂà´Êé®ÁêÜËΩ®Ëøπ‰∏≠ÁöÑÈÄªËæë‰∏ç‰∏ÄËá¥ÊÄßÂíåÂπªËßâÁé∞Ë±°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRACEÊ°ÜÊû∂ÈÄöËøáÊèêÂèñÂÖ≥ÈîÆÊé®ÁêÜÊ≠•È™§Âπ∂ËÆ°ÁÆóÂõõ‰∏™ËØäÊñ≠‰ø°Âè∑ÔºåÁªºÂêàËØÑ‰º∞Êé®ÁêÜ‰∏éÁ≠îÊ°àÁöÑ‰∏ÄËá¥ÊÄßÔºå‰ªéËÄåÊèêÈ´òÂπªËßâÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRACEÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÊé®ÁêÜËΩ®ËøπÁöÑ‰∏ÄËá¥ÊÄßËØÑ‰º∞„ÄÅÂü∫‰∫éÁÜµÁöÑÁ≠îÊ°à‰∏çÁ°ÆÂÆöÊÄßËÆ°ÁÆó„ÄÅÊé®ÁêÜ‰∏éÁ≠îÊ°àÁöÑËØ≠‰πâÂØπÈΩêËØÑ‰º∞Ôºå‰ª•ÂèäÊé®ÁêÜÁöÑÂÜÖÈÉ®‰∏ÄËá¥ÊÄßÂàÜÊûê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRACEÁöÑÂàõÊñ∞Âú®‰∫éÂêåÊó∂ËÄÉËôëÊé®ÁêÜÊ≠•È™§ÂíåÁ≠îÊ°àÁöÑ‰∏ÄËá¥ÊÄßÔºåÂà©Áî®Â§öÁª¥Â∫¶‰ø°Âè∑ÂÖ±ÂêåÊ£ÄÊµãÂπªËßâÔºåÂÖãÊúç‰∫Ü‰º†ÁªüÊñπÊ≥ïÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöRACEËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞Ôºå‰ª•‰ºòÂåñÊé®ÁêÜËΩ®ËøπÁöÑ‰∏ÄËá¥ÊÄßÂíåÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄßÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRACEÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÁöÑÂπªËßâÊ£ÄÊµãÂü∫Á∫øÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§ßÂûãÊé®ÁêÜÊ®°Âûã‰∏≠‰Ωú‰∏∫ÂπªËßâÊ£ÄÊµãÂ∑•ÂÖ∑ÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªüÂíåËá™Âä®Êé®ÁêÜÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÂπªËßâÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåRACEÊ°ÜÊû∂ËÉΩÂ§üÂ¢ûÂº∫Â§ßÂûãÊé®ÁêÜÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÂèØÈù†ÊÄßÔºåÊé®Âä®Êô∫ËÉΩÁ≥ªÁªüÁöÑÈÄèÊòéÊÄßÂíå‰ø°‰ªªÂ∫¶„ÄÇÊú™Êù•ÔºåRACEÂèØËÉΩÂú®Êõ¥ÂπøÊ≥õÁöÑAIÂ∫îÁî®‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®Ôºå‰øÉËøõ‰∫∫Êú∫‰∫§‰∫íÁöÑÂÆâÂÖ®ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Reasoning Models (LRMs) extend large language models with explicit, multi-step reasoning traces to enhance transparency and performance on complex tasks. However, these reasoning traces can be redundant or logically inconsistent, becoming a new and hard-to-detect source of hallucination. Existing hallucination detection methods focus primarily on answer-level uncertainty and often fail to detect hallucinations or logical inconsistencies arising from the model's reasoning trace. This oversight is particularly problematic for LRMs, where the explicit thinking trace is not only an important support to the model's decision-making process but also a key source of potential hallucination. To this end, we propose RACE (Reasoning and Answer Consistency Evaluation), a novel framework specifically tailored for hallucination detection in LRMs. RACE operates by extracting essential reasoning steps and computing four diagnostic signals: inter-sample consistency of reasoning traces, entropy-based answer uncertainty, semantic alignment between reasoning and answers, and internal coherence of reasoning. The joint utilization of these signals makes RACE a more robust detector of hallucinations in LRMs. Experiments across datasets and different LLMs demonstrate that RACE outperforms existing hallucination detection baselines, offering a robust and generalizable solution for evaluating LRMs. The source code is available at https://github.com/bebr2/RACE

