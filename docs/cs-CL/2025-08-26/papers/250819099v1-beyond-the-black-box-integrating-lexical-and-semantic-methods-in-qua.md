---
layout: default
title: Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic
---

# Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19099" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19099v1</a>
  <a href="https://arxiv.org/pdf/2508.19099.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19099v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19099v1', 'Beyond the Black Box: Integrating Lexical and Semantic Methods in Quantitative Discourse Analysis with BERTopic')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thomas Compton

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

**å¤‡æ³¨**: 5 pages conference paper, 4 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€æ˜æ¡†æ¶ä»¥æå‡å®šé‡è¯è¯­åˆ†æçš„æœ‰æ•ˆæ€§ä¸å¯é‡å¤æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®šé‡è¯è¯­åˆ†æ` `é€æ˜æ¡†æ¶` `ä¸»é¢˜å»ºæ¨¡` `è¯­ä¹‰èšç±»` `è¯æ±‡åˆ†æ` `HDBSCAN` `UMAP` `Pythonç®¡é“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å®šé‡è¯è¯­åˆ†ææ–¹æ³•ä¾èµ–é»‘ç®±è½¯ä»¶ï¼Œç¼ºä¹é€æ˜æ€§å’Œç ”ç©¶ç›®æ ‡çš„ä¸€è‡´æ€§ã€‚
2. æå‡ºä¸€ç§ç»“åˆè¯æ±‡å’Œè¯­ä¹‰æ–¹æ³•çš„æ··åˆæ¡†æ¶ï¼Œå¢å¼ºåˆ†æçš„å¯é‡å¤æ€§å’Œå¯è§£é‡Šæ€§ã€‚
3. é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨ä¸»é¢˜å»ºæ¨¡å’Œå…³é”®è¯æå–ä¸­çš„æœ‰æ•ˆæ€§å’Œæå‡æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®šé‡è¯è¯­åˆ†æåœ¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œè®¡ç®—å·¥å…·çš„æ¨åŠ¨ä¸‹é€æ¸æ™®åŠã€‚ç„¶è€Œï¼Œä¾èµ–é»‘ç®±è½¯ä»¶å¦‚MAXQDAå’ŒNVivoå¯èƒ½ä¼šå‰Šå¼±æ–¹æ³•è®ºçš„é€æ˜æ€§å’Œç ”ç©¶ç›®æ ‡çš„ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆé€æ˜æ¡†æ¶ï¼Œç»“åˆè¯æ±‡å’Œè¯­ä¹‰æ–¹æ³•ï¼Œä»¥å®ç°ä¸‰è§’éªŒè¯ã€å¯é‡å¤æ€§å’Œå¯è§£é‡Šæ€§ã€‚é€šè¿‡å†å²æ”¿æ²»è¯è¯­çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œå±•ç¤ºäº†å¦‚ä½•åˆ©ç”¨NLTKã€spaCyå’ŒSentence Transformersæ„å»ºè‡ªå®šä¹‰Pythonç®¡é“ï¼Œä»¥ç²¾ç»†æ§åˆ¶é¢„å¤„ç†ã€è¯å½¢è¿˜åŸå’ŒåµŒå…¥ç”Ÿæˆã€‚æˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†BERTopicå»ºæ¨¡è¿‡ç¨‹ï¼Œç»“åˆUMAPé™ç»´ã€HDBSCANèšç±»å’Œc-TF-IDFå…³é”®è¯æå–ï¼Œé€šè¿‡å‚æ•°è°ƒä¼˜å’Œå¤šæ¬¡è¿è¡Œæ¥å¢å¼ºä¸»é¢˜çš„ä¸€è‡´æ€§å’Œè¦†ç›–é¢ã€‚é€šè¿‡ç²¾ç¡®çš„è¯æ±‡æœç´¢ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¯­ä¹‰èšç±»ç›¸ç»“åˆï¼Œæˆ‘ä»¬ä¸»å¼ é‡‡ç”¨å¤šå±‚æ¬¡çš„æ–¹æ³•ï¼Œä»¥å‡è½»å•ä¸€æ–¹æ³•çš„å±€é™æ€§ã€‚ä»£ç å’Œè¡¥å……ææ–™å¯é€šè¿‡GitHubè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å®šé‡è¯è¯­åˆ†æä¸­æ–¹æ³•è®ºé€æ˜æ€§ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰é»‘ç®±è½¯ä»¶é™åˆ¶äº†ç ”ç©¶è€…å¯¹åˆ†æè¿‡ç¨‹çš„æ§åˆ¶å’Œç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§é€æ˜çš„æ··åˆæ¡†æ¶ï¼Œç»“åˆè¯æ±‡å’Œè¯­ä¹‰åˆ†ææ–¹æ³•ï¼Œå…è®¸ç ”ç©¶è€…åœ¨åˆ†æè¿‡ç¨‹ä¸­è¿›è¡Œæ›´ç»†è‡´çš„æ§åˆ¶å’Œè°ƒæ•´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€è¯å½¢è¿˜åŸã€åµŒå…¥ç”Ÿæˆã€UMAPé™ç»´ã€HDBSCANèšç±»å’Œc-TF-IDFå…³é”®è¯æå–ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„åˆ†æç®¡é“ã€‚

**å…³é”®åˆ›æ–°**ï¼šé€šè¿‡ç»“åˆè¯æ±‡æœç´¢ä¸è¯­ä¹‰èšç±»ï¼Œæå‡ºå¤šå±‚æ¬¡çš„æ–¹æ³•ï¼Œå…‹æœäº†å•ä¸€æ–¹æ³•çš„å±€é™æ€§ï¼Œå¢å¼ºäº†ä¸»é¢˜çš„ä¸€è‡´æ€§å’Œè¦†ç›–é¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€šè¿‡è°ƒä¼˜å’Œå¤šæ¬¡è¿è¡Œä¼˜åŒ–UMAPå’ŒHDBSCANçš„å‚æ•°ï¼Œä»¥æé«˜èšç±»æ•ˆæœå’Œä¸»é¢˜çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¯¥æ¡†æ¶çš„ä¸»é¢˜å»ºæ¨¡åœ¨ä¸€è‡´æ€§å’Œè¦†ç›–é¢ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚é€šè¿‡å¤šæ¬¡å‚æ•°è°ƒä¼˜ï¼Œä¸»é¢˜çš„å¯è§£é‡Šæ€§å’Œèšç±»æ•ˆæœå¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾ä¼šç§‘å­¦ã€æ”¿æ²»å­¦å’Œäººæ–‡å­¦ç§‘çš„å®šé‡åˆ†æï¼Œèƒ½å¤Ÿä¸ºç ”ç©¶è€…æä¾›æ›´é«˜çš„åˆ†æé€æ˜åº¦å’Œå¯é‡å¤æ€§ï¼Œä¿ƒè¿›å¯¹è¯è¯­æ•°æ®çš„æ·±å…¥ç†è§£ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šé¢†åŸŸçš„è®¡ç®—è¯è¯­ç ”ç©¶ï¼Œæå‡ç ”ç©¶çš„ç§‘å­¦æ€§å’Œä¸¥è°¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quantitative Discourse Analysis has seen growing adoption with the rise of Large Language Models and computational tools. However, reliance on black box software such as MAXQDA and NVivo risks undermining methodological transparency and alignment with research goals. This paper presents a hybrid, transparent framework for QDA that combines lexical and semantic methods to enable triangulation, reproducibility, and interpretability. Drawing from a case study in historical political discourse, we demonstrate how custom Python pipelines using NLTK, spaCy, and Sentence Transformers allow fine-grained control over preprocessing, lemmatisation, and embedding generation. We further detail our iterative BERTopic modelling process, incorporating UMAP dimensionality reduction, HDBSCAN clustering, and c-TF-IDF keyword extraction, optimised through parameter tuning and multiple runs to enhance topic coherence and coverage. By juxtaposing precise lexical searches with context-aware semantic clustering, we argue for a multi-layered approach that mitigates the limitations of either method in isolation. Our workflow underscores the importance of code-level transparency, researcher agency, and methodological triangulation in computational discourse studies. Code and supplementary materials are available via GitHub.

