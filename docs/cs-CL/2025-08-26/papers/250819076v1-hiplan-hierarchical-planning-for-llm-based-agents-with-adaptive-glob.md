---
layout: default
title: HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance
---

# HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19076" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19076v1</a>
  <a href="https://arxiv.org/pdf/2508.19076.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19076v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19076v1', 'HiPlan: Hierarchical Planning for LLM-Based Agents with Adaptive Global-Local Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyue Li, Yuan Chang, Gaihong Yu, Xiaoqiu Le

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHiPlanä»¥è§£å†³LLMä»£ç†åœ¨å¤æ‚è§„åˆ’ä¸­çš„å†³ç­–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å±‚æ¬¡åŒ–è§„åˆ’` `å¤§å‹è¯­è¨€æ¨¡å‹` `å†³ç­–æ”¯æŒ` `åŠ¨æ€é€‚åº”` `æ™ºèƒ½ä»£ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMä»£ç†åœ¨å¤æ‚é•¿æ—¶é—´è§„åˆ’ä»»åŠ¡ä¸­ç¼ºä¹å®è§‚æŒ‡å¯¼ï¼Œå¯¼è‡´å†³ç­–å¤±è¯¯å’Œæ‰§è¡Œåå·®ã€‚
2. HiPlané€šè¿‡å±‚æ¬¡åŒ–è§„åˆ’æ¡†æ¶ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºé‡Œç¨‹ç¢‘å’Œé€æ­¥æç¤ºï¼Œæä¾›å…¨å±€ä¸å±€éƒ¨çš„è‡ªé€‚åº”æŒ‡å¯¼ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒHiPlançš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰å¼ºåŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œåˆ›æ–°æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ä»£ç†åœ¨å†³ç­–ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤æ‚çš„é•¿æ—¶é—´è§„åˆ’åœºæ™¯ä¸­å´é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚è¿™ä¸»è¦æºäºç¼ºä¹å®è§‚æŒ‡å¯¼ï¼Œå¯¼è‡´åœ¨å¤æ‚ä»»åŠ¡ä¸­è¿·å¤±æ–¹å‘ï¼Œå¹¶ä¸”åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­ç¼ºä¹æŒç»­çš„ç›‘ç£ï¼Œä½¿å…¶å¯¹ç¯å¢ƒå˜åŒ–ååº”è¿Ÿç¼“ä¸”å®¹æ˜“åç¦»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†HiPlanï¼Œä¸€ä¸ªå±‚æ¬¡åŒ–è§„åˆ’æ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”çš„å…¨å±€-å±€éƒ¨æŒ‡å¯¼æ¥æå‡LLMä»£ç†çš„å†³ç­–èƒ½åŠ›ã€‚HiPlanå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºé‡Œç¨‹ç¢‘è¡ŒåŠ¨æŒ‡å—å’Œé€æ­¥æç¤ºã€‚åœ¨ç¦»çº¿é˜¶æ®µï¼Œæˆ‘ä»¬ä»ä¸“å®¶æ¼”ç¤ºä¸­æ„å»ºäº†é‡Œç¨‹ç¢‘åº“ï¼Œå®ç°ç»“æ„åŒ–ç»éªŒé‡ç”¨ã€‚åœ¨æ‰§è¡Œé˜¶æ®µï¼ŒåŠ¨æ€é€‚åº”è¿‡å»é‡Œç¨‹ç¢‘çš„è½¨è¿¹ç‰‡æ®µï¼Œä»¥ç”Ÿæˆä¸å½“å‰è§‚å¯Ÿç›¸ä¸€è‡´çš„é€æ­¥æç¤ºï¼Œä»è€Œå¼¥è¡¥å·®è·å¹¶çº æ­£åå·®ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒHiPlanæ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿ï¼Œæ¶ˆèç ”ç©¶éªŒè¯äº†å…¶å±‚æ¬¡ç»„ä»¶çš„äº’è¡¥æ•ˆç›Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMä»£ç†åœ¨å¤æ‚é•¿æ—¶é—´è§„åˆ’ä¸­çš„å†³ç­–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹å®è§‚æŒ‡å¯¼å’ŒæŒç»­ç›‘ç£ï¼Œå¯¼è‡´æ‰§è¡Œä¸­çš„è¿·å¤±å’Œåå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHiPlançš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å±‚æ¬¡åŒ–è§„åˆ’ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºé‡Œç¨‹ç¢‘å’Œé€æ­¥æç¤ºï¼Œä»¥æä¾›æ›´æ¸…æ™°çš„å†³ç­–è·¯å¾„å’Œå®æ—¶è°ƒæ•´èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHiPlançš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç¦»çº¿é˜¶æ®µå’Œæ‰§è¡Œé˜¶æ®µã€‚åœ¨ç¦»çº¿é˜¶æ®µï¼Œæ„å»ºé‡Œç¨‹ç¢‘åº“ä»¥å®ç°ç»éªŒé‡ç”¨ï¼›åœ¨æ‰§è¡Œé˜¶æ®µï¼ŒåŠ¨æ€é€‚åº”è¿‡å»çš„è½¨è¿¹ç‰‡æ®µç”Ÿæˆé€æ­¥æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šHiPlançš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å±‚æ¬¡åŒ–çš„è§„åˆ’æ¡†æ¶ï¼Œé€šè¿‡é‡Œç¨‹ç¢‘å’Œé€æ­¥æç¤ºçš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†LLMä»£ç†çš„å†³ç­–èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´çµæ´»çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡Œç¨‹ç¢‘åº“çš„æ„å»ºä¾èµ–äºä¸“å®¶æ¼”ç¤ºï¼ŒåŠ¨æ€é€‚åº”æœºåˆ¶ç¡®ä¿äº†ç”Ÿæˆçš„æç¤ºä¸å½“å‰ç¯å¢ƒè§‚å¯Ÿç›¸ä¸€è‡´ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œéœ€å‚è€ƒå®Œæ•´è®ºæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒHiPlanåœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„åŸºå‡†æµ‹è¯•ä¸Šæ˜¾è‘—è¶…è¶Šäº†å¤šä¸ªå¼ºåŸºçº¿ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªåœ¨æ‘˜è¦ä¸­æä¾›ï¼Œä½†æ¶ˆèç ”ç©¶è¡¨æ˜å…¶å±‚æ¬¡ç»„ä»¶çš„äº’è¡¥æ•ˆç›Šæ˜¾è‘—ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HiPlançš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰å¤æ‚å†³ç­–ç³»ç»Ÿã€‚é€šè¿‡æå‡LLMä»£ç†çš„è§„åˆ’èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹åŠ¨æ€ç¯å¢ƒä¸­çš„å¤æ‚ä»»åŠ¡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½ä»£ç†åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›ä½¿ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language model (LLM)-based agents have demonstrated remarkable capabilities in decision-making tasks, but struggle significantly with complex, long-horizon planning scenarios. This arises from their lack of macroscopic guidance, causing disorientation and failures in complex tasks, as well as insufficient continuous oversight during execution, rendering them unresponsive to environmental changes and prone to deviations. To tackle these challenges, we introduce HiPlan, a hierarchical planning framework that provides adaptive global-local guidance to boost LLM-based agents'decision-making. HiPlan decomposes complex tasks into milestone action guides for general direction and step-wise hints for detailed actions. During the offline phase, we construct a milestone library from expert demonstrations, enabling structured experience reuse by retrieving semantically similar tasks and milestones. In the execution phase, trajectory segments from past milestones are dynamically adapted to generate step-wise hints that align current observations with the milestone objectives, bridging gaps and correcting deviations. Extensive experiments across two challenging benchmarks demonstrate that HiPlan substantially outperforms strong baselines, and ablation studies validate the complementary benefits of its hierarchical components.

