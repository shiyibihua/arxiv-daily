---
layout: default
title: What do language models model? Transformers, automata, and the format of thought
---

# What do language models model? Transformers, automata, and the format of thought

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18598" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18598v1</a>
  <a href="https://arxiv.org/pdf/2508.18598.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18598v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18598v1', 'What do language models model? Transformers, automata, and the format of thought')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Colin Klein

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨è¯­è¨€æ¨¡å‹çš„æœ¬è´¨åŠå…¶ä¸äººç±»è®¤çŸ¥çš„å…³ç³»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `å˜æ¢å™¨æ¶æ„` `äººç±»è¯­è¨€èƒ½åŠ›` `å¿«æ·è‡ªåŠ¨æœº` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„è¯­è¨€æ¨¡å‹æ˜¯å¦çœŸæ­£åæ˜ äº†äººç±»çš„è¯­è¨€èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯å¯¹è®­ç»ƒæ•°æ®çš„å»ºæ¨¡ï¼Ÿ
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡æå‡ºå˜æ¢å™¨æ¶æ„åœ¨å¤„ç†è¯­è¨€æ—¶çš„å±€é™æ€§ï¼Œå¹¶æ¢è®¨å…¶ç§¯æä½œç”¨ï¼Œç‰¹åˆ«æ˜¯å¿«æ·è‡ªåŠ¨æœºçš„æ¦‚å¿µã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šé€šè¿‡åˆ†æå˜æ¢å™¨çš„è®¡ç®—æ¶æ„ï¼Œå¾—å‡ºè¯­è¨€ä¸ä»…æ˜¯è¡¨è¾¾å·¥å…·ï¼Œæ›´æ˜¯ç”Ÿæˆæ–°è¯­è¨€çš„æœºåˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç©¶ç«Ÿå»ºæ¨¡äº†ä»€ä¹ˆï¼Œæ˜¯å¦åæ˜ äº†äººç±»çš„èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯è®­ç»ƒè¯­æ–™åº“çš„æ¨¡å‹ã€‚ä½œè€…æ”¯æŒåè€…çš„è§‚ç‚¹ï¼Œè®¤ä¸ºäººç±»çš„è¯­è¨€èƒ½åŠ›ä¾èµ–äºè¶…çº¿æ€§è®¡ç®—æ ¼å¼ï¼Œè€Œå˜æ¢å™¨æ¶æ„æœ€å¤šæ”¯æŒçº¿æ€§æ ¼å¼ã€‚æ–‡ç« è¿˜æå‡ºäº†å˜æ¢å™¨åœ¨å¤„ç†è¯­è¨€æ—¶çš„ç§¯æä½œç”¨ï¼Œç‰¹åˆ«æ˜¯åŸºäºLiuç­‰ï¼ˆ2022ï¼‰å…³äºå¿«æ·è‡ªåŠ¨æœºçš„æ¨æµ‹ã€‚æœ€åï¼Œä½œè€…è®¤ä¸ºè¯­è¨€ä¸ä»…æ˜¯è¡¨è¾¾å†…å¿ƒçŠ¶æ€çš„å·¥å…·ï¼Œæ›´æ˜¯ä¸€ç§â€˜è¯è¯­æœºå™¨â€™ï¼Œèƒ½å¤Ÿåœ¨é€‚å½“çš„ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆæ–°è¯­è¨€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç©¶ç«Ÿå»ºæ¨¡äº†ä»€ä¹ˆï¼Œå°¤å…¶æ˜¯å®ƒä»¬æ˜¯å¦åæ˜ äº†äººç±»çš„è¯­è¨€èƒ½åŠ›ï¼Œè¿˜æ˜¯ä»…ä»…æ˜¯å¯¹è®­ç»ƒè¯­æ–™åº“çš„å»ºæ¨¡ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è§£é‡Šå˜æ¢å™¨æ¶æ„ä¸äººç±»è¯­è¨€èƒ½åŠ›ä¹‹é—´çš„å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šä½œè€…æå‡ºï¼Œå˜æ¢å™¨æ¶æ„æ”¯æŒçš„çº¿æ€§è®¡ç®—æ ¼å¼ä¸äººç±»çš„è¶…çº¿æ€§è¯­è¨€èƒ½åŠ›å­˜åœ¨æ ¹æœ¬å·®å¼‚ã€‚é€šè¿‡åˆ†æå˜æ¢å™¨çš„è®¡ç®—ä¸å˜æ€§ï¼Œä½œè€…ä¸ºç†è§£å…¶åœ¨è¯­è¨€å¤„ç†ä¸­çš„ä½œç”¨æä¾›äº†æ–°çš„è§†è§’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ–‡ç« çš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹å˜æ¢å™¨æ¶æ„çš„åˆ†æã€å¯¹äººç±»è¯­è¨€èƒ½åŠ›çš„è®¤çŸ¥ç§‘å­¦èƒŒæ™¯çš„æ¢è®¨ï¼Œä»¥åŠå¯¹å¿«æ·è‡ªåŠ¨æœºçš„å¼•å…¥ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬å¯¹å˜æ¢å™¨è®¡ç®—ç‰¹æ€§çš„è®¨è®ºå’Œå¯¹è¯­è¨€ç”Ÿæˆæœºåˆ¶çš„é˜è¿°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å˜æ¢å™¨æ¶æ„ä¸äººç±»è¯­è¨€èƒ½åŠ›çš„è¶…çº¿æ€§æ ¼å¼è¿›è¡Œå¯¹æ¯”ï¼Œæå‡ºäº†å˜æ¢å™¨åœ¨è¯­è¨€å¤„ç†ä¸­çš„ç§¯æä½œç”¨ï¼Œå°¤å…¶æ˜¯å¿«æ·è‡ªåŠ¨æœºçš„æ¦‚å¿µï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„çº¿æ€§å¤„ç†æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œä½œè€…å¼ºè°ƒäº†å˜æ¢å™¨çš„è®¡ç®—ä¸å˜æ€§ï¼Œå¹¶æ¢è®¨äº†å…¶åœ¨è¯­è¨€ç”Ÿæˆä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†è¯­è¨€ä¸ä»…æ˜¯è¡¨è¾¾å†…å¿ƒçŠ¶æ€çš„å·¥å…·ï¼Œæ›´æ˜¯ç”Ÿæˆæ–°è¯­è¨€çš„æœºåˆ¶ã€‚ä½œè€…æœªè¯¦ç»†åˆ—å‡ºå…·ä½“çš„å‚æ•°è®¾ç½®æˆ–æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æ–‡ç« é€šè¿‡å¯¹å˜æ¢å™¨æ¶æ„çš„æ·±å…¥åˆ†æï¼Œæå‡ºäº†è¯­è¨€ä¸ä»…æ˜¯è¡¨è¾¾å·¥å…·ï¼Œæ›´æ˜¯ç”Ÿæˆæ–°è¯­è¨€çš„æœºåˆ¶ã€‚å°½ç®¡æœªæä¾›å…·ä½“çš„å®éªŒæ•°æ®ï¼Œä½†é€šè¿‡ç†è®ºæ¨å¯¼ï¼Œå¼ºè°ƒäº†å˜æ¢å™¨åœ¨è¯­è¨€å¤„ç†ä¸­çš„ç‹¬ç‰¹ä½œç”¨ï¼Œæ¨åŠ¨äº†å¯¹è¯­è¨€æ¨¡å‹ç†è§£çš„æ·±å…¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­è¨€ç”Ÿæˆå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£è¯­è¨€æ¨¡å‹çš„æœ¬è´¨ï¼Œå¯ä»¥æ”¹è¿›ç°æœ‰çš„è¯­è¨€ç”ŸæˆæŠ€æœ¯ï¼Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹å’Œå¯¹è¯ç³»ç»Ÿçš„å‘å±•ï¼Œæå‡äººæœºæ²Ÿé€šçš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> What do large language models actually model? Do they tell us something about human capacities, or are they models of the corpus we've trained them on? I give a non-deflationary defence of the latter position. Cognitive science tells us that linguistic capabilities in humans rely supralinear formats for computation. The transformer architecture, by contrast, supports at best a linear formats for processing. This argument will rely primarily on certain invariants of the computational architecture of transformers. I then suggest a positive story about what transformers are doing, focusing on Liu et al. (2022)'s intriguing speculations about shortcut automata. I conclude with why I don't think this is a terribly deflationary story. Language is not (just) a means for expressing inner state but also a kind of 'discourse machine' that lets us make new language given appropriate context. We have learned to use this technology in one way; LLMs have also learned to use it too, but via very different means.

