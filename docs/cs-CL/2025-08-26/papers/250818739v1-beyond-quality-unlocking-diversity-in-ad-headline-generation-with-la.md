---
layout: default
title: Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models
---

# Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18739" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18739v1</a>
  <a href="https://arxiv.org/pdf/2508.18739.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18739v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18739v1', 'Beyond Quality: Unlocking Diversity in Ad Headline Generation with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chang Wang, Siyu Yan, Depeng Yuan, Yuqi Chen, Yanhua Huang, Yuanhang Zheng, Shuhao Li, Yinqi Zhang, Kedi Chen, Mingrui Zhu, Ruiwen Xu

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDIVERæ¡†æ¶ä»¥è§£å†³å¹¿å‘Šæ ‡é¢˜ç”Ÿæˆä¸­çš„å¤šæ ·æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¹¿å‘Šæ ‡é¢˜ç”Ÿæˆ` `å¤šæ ·æ€§ä¼˜åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `æ•°æ®ç”Ÿæˆç®¡é“` `æ–‡æœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¹¿å‘Šæ ‡é¢˜ç”Ÿæˆæ–¹æ³•ä¸»è¦å…³æ³¨è´¨é‡æˆ–ç‚¹å‡»ç‡ï¼Œå¿½è§†äº†å¤šæ ·æ€§ï¼Œå¯¼è‡´è¾“å‡ºç»“æœåŒè´¨åŒ–ã€‚
2. æœ¬æ–‡æå‡ºDIVERæ¡†æ¶ï¼Œé€šè¿‡è¯­ä¹‰å’Œé£æ ¼æ„ŸçŸ¥çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œå®ç°é«˜è´¨é‡å’Œå¤šæ ·åŒ–æ ‡é¢˜çš„è”åˆä¼˜åŒ–ã€‚
3. åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDIVERæœ‰æ•ˆæå‡äº†å¹¿å‘Šä¸»ä»·å€¼å’Œç‚¹å‡»ç‡ï¼ŒéªŒè¯äº†å…¶å®é™…åº”ç”¨æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¹¿å‘Šæ ‡é¢˜çš„ç”Ÿæˆåœ¨ç°ä»£å¹¿å‘Šä¸­è‡³å…³é‡è¦ï¼Œè´¨é‡å’Œå¤šæ ·æ€§éƒ½æ˜¯å¸å¼•å¹¿æ³›å—ä¼—çš„å…³é”®ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¼˜åŒ–è¯­è¨€æ¨¡å‹ä»¥æé«˜æ ‡é¢˜è´¨é‡æˆ–ç‚¹å‡»ç‡ï¼ˆCTRï¼‰ï¼Œä½†å¾€å¾€å¿½è§†å¤šæ ·æ€§ï¼Œå¯¼è‡´è¾“å‡ºåŒè´¨åŒ–ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†DIVERï¼Œä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨åŒæ—¶ä¼˜åŒ–å¤šæ ·æ€§å’Œè´¨é‡ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè¯­ä¹‰å’Œé£æ ¼æ„ŸçŸ¥çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¹¿å‘Šå†…å®¹å’Œå¤šæ ·åŒ–æ ‡é¢˜çš„è®­ç»ƒå¯¹ã€‚é€šè¿‡å¤šé˜¶æ®µå¤šç›®æ ‡ä¼˜åŒ–æ¡†æ¶ç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼ŒDIVERåœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§ï¼Œå¹¶åœ¨å¤§å‹å†…å®¹åˆ†äº«å¹³å°ä¸Šæå‡å¹¿å‘Šä¸»ä»·å€¼ï¼ˆADVVï¼‰å’ŒCTRï¼Œåˆ†åˆ«æé«˜4.0%å’Œ1.4%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¹¿å‘Šæ ‡é¢˜ç”Ÿæˆä¸­çš„å¤šæ ·æ€§ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªä¼˜åŒ–æ ‡é¢˜è´¨é‡æˆ–ç‚¹å‡»ç‡ï¼Œå¯¼è‡´ç”Ÿæˆçš„æ ‡é¢˜ç¼ºä¹å¤šæ ·æ€§ï¼Œæ— æ³•æœ‰æ•ˆå¸å¼•ä¸åŒçš„å—ä¼—ç¾¤ä½“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDIVERæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è”åˆä¼˜åŒ–è´¨é‡å’Œå¤šæ ·æ€§ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå¤šæ ·åŒ–çš„å¹¿å‘Šæ ‡é¢˜ã€‚é€šè¿‡è®¾è®¡ä¸€ä¸ªè¯­ä¹‰å’Œé£æ ¼æ„ŸçŸ¥çš„æ•°æ®ç”Ÿæˆç®¡é“ï¼Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒå¯¹ï¼Œä»¥æ”¯æŒå¤šæ ·æ€§ç›®æ ‡çš„å®ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDIVERæ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯æ•°æ®ç”Ÿæˆç®¡é“ï¼Œæ¥ç€æ˜¯å¤šé˜¶æ®µå¤šç›®æ ‡ä¼˜åŒ–è¿‡ç¨‹ï¼Œç»“åˆç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ï¼Œä»¥å®ç°é«˜æ•ˆçš„æ ‡é¢˜ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šDIVERçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å¤šç›®æ ‡ä¼˜åŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­åŒæ—¶è€ƒè™‘æ ‡é¢˜çš„è´¨é‡ä¸å¤šæ ·æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€ä¼˜åŒ–ç›®æ ‡å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DIVERä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§çš„ç½‘ç»œç»“æ„ï¼Œä»¥æ”¯æŒå¤šæ ·åŒ–æ ‡é¢˜çš„ç”Ÿæˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDIVERæ¡†æ¶åœ¨çœŸå®å·¥ä¸šæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†å¹¿å‘Šä¸»ä»·å€¼ï¼ˆADVVï¼‰4.0%å’Œç‚¹å‡»ç‡ï¼ˆCTRï¼‰1.4%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒDIVERåœ¨å¹³è¡¡è´¨é‡ä¸å¤šæ ·æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿçš„å¹¿å‘Šæ ‡é¢˜ç”Ÿæˆæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ¨çº¿å¹¿å‘Šã€ç¤¾äº¤åª’ä½“å†…å®¹ç”ŸæˆåŠå¸‚åœºè¥é”€ç­‰ã€‚é€šè¿‡æå‡å¹¿å‘Šæ ‡é¢˜çš„å¤šæ ·æ€§å’Œè´¨é‡ï¼ŒDIVERæ¡†æ¶èƒ½å¤Ÿå¸®åŠ©å¹¿å‘Šä¸»æ›´å¥½åœ°å¸å¼•ç›®æ ‡å—ä¼—ï¼Œä»è€Œæé«˜å¹¿å‘Šæ•ˆæœå’ŒæŠ•èµ„å›æŠ¥ç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œæ¨åŠ¨å†…å®¹åˆ›ä½œçš„æ™ºèƒ½åŒ–å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The generation of ad headlines plays a vital role in modern advertising, where both quality and diversity are essential to engage a broad range of audience segments. Current approaches primarily optimize language models for headline quality or click-through rates (CTR), often overlooking the need for diversity and resulting in homogeneous outputs. To address this limitation, we propose DIVER, a novel framework based on large language models (LLMs) that are jointly optimized for both diversity and quality. We first design a semantic- and stylistic-aware data generation pipeline that automatically produces high-quality training pairs with ad content and multiple diverse headlines. To achieve the goal of generating high-quality and diversified ad headlines within a single forward pass, we propose a multi-stage multi-objective optimization framework with supervised fine-tuning (SFT) and reinforcement learning (RL). Experiments on real-world industrial datasets demonstrate that DIVER effectively balances quality and diversity. Deployed on a large-scale content-sharing platform serving hundreds of millions of users, our framework improves advertiser value (ADVV) and CTR by 4.0% and 1.4%.

