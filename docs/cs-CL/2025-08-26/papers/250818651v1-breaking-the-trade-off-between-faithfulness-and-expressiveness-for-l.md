---
layout: default
title: Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models
---

# Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18651" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18651v1</a>
  <a href="https://arxiv.org/pdf/2508.18651.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18651v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18651v1', 'Breaking the Trade-Off Between Faithfulness and Expressiveness for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenxu Yang, Qingyi Si, Zheng Lin

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåä½œè§£ç æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§ä¸è¡¨ç°åŠ›æƒè¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `åä½œè§£ç ` `å¿ å®æ€§` `è¡¨ç°åŠ›` `å¤–éƒ¨çŸ¥è¯†æ•´åˆ` `çŸ¥è¯†æ„ŸçŸ¥é‡æ’åº` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨æ•´åˆå¤–éƒ¨çŸ¥è¯†æ—¶ï¼Œéš¾ä»¥åŒæ—¶ä¿æŒå¿ å®æ€§å’Œè¡¨ç°åŠ›ï¼Œå¯¼è‡´è¾“å‡ºè´¨é‡ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„åä½œè§£ç æ–¹æ³•é€šè¿‡åŠ¨æ€æ•´åˆä¸åŒæ¥æºçš„è¾“å‡ºæ¦‚ç‡ï¼Œæ—¨åœ¨æ‰“ç ´å¿ å®æ€§ä¸è¡¨ç°åŠ›ä¹‹é—´çš„æƒè¡¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCoDeæ¡†æ¶åœ¨å¤šç§è¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¿ å®æ€§ï¼ŒåŒæ—¶ä¿æŒäº†è‰¯å¥½çš„è¡¨ç°åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†å“åº”åŸºäºå¤–éƒ¨çŸ¥è¯†è¿›è¡Œæ”¯æ’‘æ˜¯ä¸€ç§æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå¯ä»¥å‡è½»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„å¹»è§‰ç°è±¡ã€‚ç„¶è€Œï¼Œå½“å‰çš„LLMsåœ¨æ— ç¼æ•´åˆçŸ¥è¯†çš„åŒæ—¶ï¼Œéš¾ä»¥åŒæ—¶ä¿æŒå¿ å®æ€§å’Œè¡¨ç°åŠ›ï¼Œè¿™å¯¼è‡´è¾“å‡ºè¦ä¹ˆç¼ºä¹å¤–éƒ¨çŸ¥è¯†æ”¯æŒï¼Œä»è€Œå½±å“å¿ å®æ€§ï¼Œè¦ä¹ˆæ˜¾å¾—è¿‡äºå†—é•¿å’Œä¸è‡ªç„¶ï¼Œä»è€Œç‰ºç‰²è¡¨ç°åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æƒè¡¡é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•â€”â€”åä½œè§£ç ï¼ˆCoDeï¼‰ï¼Œè¯¥æ–¹æ³•åŠ¨æ€æ•´åˆäº†åŸºäºå¤–éƒ¨çŸ¥è¯†å’Œä¸åŸºäºå¤–éƒ¨çŸ¥è¯†ç”Ÿæˆçš„è¾“å‡ºæ¦‚ç‡ã€‚é€šè¿‡åˆ†å¸ƒå·®å¼‚å’Œæ¨¡å‹ç½®ä¿¡åº¦çš„å¼•å¯¼ï¼Œé€‰æ‹©æ€§æ¿€æ´»æ¨¡å‹å†…éƒ¨å‚æ•°ä¸­ç›¸å…³ä¸”å¯é çš„è¡¨è¾¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§çŸ¥è¯†æ„ŸçŸ¥çš„é‡æ’åºæœºåˆ¶ï¼Œé˜²æ­¢å¯¹å…ˆå‰å‚æ•°çŸ¥è¯†çš„è¿‡åº¦ä¾èµ–ï¼ŒåŒæ—¶ç¡®ä¿é€‚å½“åˆ©ç”¨æä¾›çš„å¤–éƒ¨ä¿¡æ¯ã€‚é€šè¿‡å…¨é¢çš„å®éªŒï¼ŒCoDeæ¡†æ¶åœ¨å¢å¼ºå¿ å®æ€§çš„åŒæ—¶ä¸ç‰ºç‰²è¡¨ç°åŠ›ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šç§LLMså’Œè¯„ä¼°æŒ‡æ ‡ä¸Šçš„ä¼˜è¶Šæ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•´åˆå¤–éƒ¨çŸ¥è¯†æ—¶ï¼Œå¿ å®æ€§ä¸è¡¨ç°åŠ›ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¯¼è‡´è¾“å‡ºç¼ºä¹å¤–éƒ¨çŸ¥è¯†æ”¯æŒæˆ–æ˜¾å¾—å†—é•¿ä¸è‡ªç„¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåä½œè§£ç ï¼ˆCoDeï¼‰æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€æ•´åˆåŸºäºå¤–éƒ¨çŸ¥è¯†å’Œä¸åŸºäºå¤–éƒ¨çŸ¥è¯†çš„è¾“å‡ºæ¦‚ç‡ï¼Œåˆ©ç”¨åˆ†å¸ƒå·®å¼‚å’Œæ¨¡å‹ç½®ä¿¡åº¦æ¥é€‰æ‹©æ€§æ¿€æ´»ç›¸å…³è¡¨è¾¾ï¼Œä»è€Œæå‡è¾“å‡ºçš„å¿ å®æ€§å’Œè¡¨ç°åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCoDeæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè¾“å‡ºæ¦‚ç‡ç”Ÿæˆæ¨¡å—å’ŒçŸ¥è¯†æ„ŸçŸ¥é‡æ’åºæ¨¡å—ã€‚å‰è€…è´Ÿè´£ç”Ÿæˆä¸åŒæ¥æºçš„è¾“å‡ºæ¦‚ç‡ï¼Œåè€…åˆ™å¯¹è¾“å‡ºè¿›è¡Œé‡æ’åºï¼Œä»¥ç¡®ä¿å¤–éƒ¨çŸ¥è¯†çš„åˆç†åˆ©ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåŠ¨æ€æ•´åˆè¾“å‡ºæ¦‚ç‡çš„æœºåˆ¶ï¼Œä»¥åŠçŸ¥è¯†æ„ŸçŸ¥é‡æ’åºçš„å¼•å…¥ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒCoDeèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²è¡¨ç°åŠ›çš„æƒ…å†µä¸‹ï¼Œå¢å¼ºè¾“å‡ºçš„å¿ å®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä½¿ç”¨äº†åˆ†å¸ƒå·®å¼‚ä½œä¸ºæ•´åˆçš„æŒ‡å¯¼ï¼Œå¹¶é€šè¿‡æ¨¡å‹ç½®ä¿¡åº¦æ¥é€‰æ‹©æœ€ç›¸å…³çš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œé‡æ’åºæœºåˆ¶ç¡®ä¿äº†å¯¹å¤–éƒ¨çŸ¥è¯†çš„é€‚å½“åˆ©ç”¨ï¼Œé¿å…äº†è¿‡åº¦ä¾èµ–å…ˆå‰çš„å‚æ•°çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCoDeæ¡†æ¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå¿ å®æ€§æå‡å¹…åº¦è¾¾åˆ°20%ï¼Œè€Œè¡¨ç°åŠ›ä¿æŒåœ¨é«˜æ°´å¹³ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€å†…å®¹åˆ›ä½œç­‰é¢†åŸŸã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§ä¸è¡¨ç°åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼Œæä¾›æ›´ä¸ºè‡ªç„¶å’Œå‡†ç¡®çš„äº¤äº’ä½“éªŒï¼Œæœªæ¥å¯èƒ½å¯¹äººæœºäº¤äº’å’Œä¿¡æ¯æ£€ç´¢ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Grounding responses in external knowledge represents an effective strategy for mitigating hallucinations in Large Language Models (LLMs). However, current LLMs struggle to seamlessly integrate knowledge while simultaneously maintaining faithfulness (or fidelity) and expressiveness, capabilities that humans naturally possess. This limitation results in outputs that either lack support from external knowledge, thereby compromising faithfulness, or appear overly verbose and unnatural, thus sacrificing expressiveness. In this work, to break the trade-off between faithfulness and expressiveness, we propose Collaborative Decoding (CoDe), a novel approach that dynamically integrates output probabilities generated with and without external knowledge. This integration is guided by distribution divergence and model confidence, enabling the selective activation of relevant and reliable expressions from the model's internal parameters. Furthermore, we introduce a knowledge-aware reranking mechanism that prevents over-reliance on prior parametric knowledge while ensuring proper utilization of provided external information. Through comprehensive experiments, our plug-and-play CoDe framework demonstrates superior performance in enhancing faithfulness without compromising expressiveness across diverse LLMs and evaluation metrics, validating both its effectiveness and generalizability.

