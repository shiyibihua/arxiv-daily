---
layout: default
title: Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models
---

# Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18655" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18655v3</a>
  <a href="https://arxiv.org/pdf/2508.18655.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18655v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18655v3', 'Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoyu Wang, Guangyan Zhang, Jiale Chen, Jingyu Li, Yuehai Wang, Yiwen Guo

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-09-17)

**å¤‡æ³¨**: 5 pages, 1 figure, submitted to ICASSP 2026

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://w311411.github.io/omni_demo/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEmotion Omniä»¥è§£å†³æƒ…æ„Ÿç†è§£ä¸è¶³çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æƒ…æ„Ÿç†è§£` `è¯­éŸ³åŠ©æ‰‹` `åŒç†å¿ƒç”Ÿæˆ` `å°æ•°æ®å­¦ä¹ ` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰ç”¨æˆ·è¯­éŸ³ä¸­çš„æƒ…æ„Ÿçº¿ç´¢ã€‚
2. æœ¬æ–‡æå‡ºEmotion Omniæ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡æœ‰é™çš„æ•°æ®ç”Ÿæˆå¯Œæœ‰åŒç†å¿ƒçš„è¯­éŸ³å“åº”ï¼Œé™ä½å¯¹å¤§è§„æ¨¡è®­ç»ƒçš„ä¾èµ–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEmotion Omniåœ¨è¯­éŸ³è´¨é‡ï¼ˆUTMOS:4.41ï¼‰å’ŒåŒç†å¿ƒï¼ˆEmotion GPT Score: 3.97ï¼‰æ–¹é¢å‡ä¼˜äºç°æœ‰æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹çš„å‘å±•ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³ç›´æ¥ä¸åŠ©æ‰‹äº’åŠ¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹å¾€å¾€ä»…å°†å“åº”å†…å®¹è½¬æ¢ä¸ºè¯­éŸ³ï¼Œæœªèƒ½å……åˆ†æ•æ‰ç”¨æˆ·æŸ¥è¯¢ä¸­çš„æƒ…æ„Ÿçº¿ç´¢ã€‚æƒ…æ„Ÿç†è§£å¯¹äºæå‡äººæœºäº¤äº’è‡³å…³é‡è¦ã€‚å¤§å¤šæ•°æƒ…æ„Ÿè¯­éŸ³æ¨¡å‹ä¾èµ–äºåºå¤§çš„æ•°æ®é›†ï¼Œè®¡ç®—æˆæœ¬é«˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºEmotion Omniæ¨¡å‹ï¼Œèƒ½å¤Ÿç†è§£ç”¨æˆ·è¯­éŸ³ä¸­çš„æƒ…æ„Ÿå†…å®¹å¹¶ç”Ÿæˆå¯Œæœ‰åŒç†å¿ƒçš„å“åº”ã€‚åŒæ—¶ï¼Œæ„å»ºäº†ä¸€ä¸ªæ”¯æŒæƒ…æ„Ÿè¯­éŸ³åŠ©æ‰‹çš„20ä¸‡æ¡æƒ…æ„Ÿå¯¹è¯æ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒEmotion Omniåœ¨æ— éœ€å¤§è§„æ¨¡é¢„è®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒæŒ‡ä»¤è·Ÿéšèƒ½åŠ›å¯ä¸ç°æœ‰æ¨¡å‹åª²ç¾ï¼ŒåŒæ—¶åœ¨è¯­éŸ³è´¨é‡å’Œæƒ…æ„Ÿè¡¨è¾¾ä¸Šè¶…è¶Šäº†ç°æœ‰æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­éŸ³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿç†è§£æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æœ‰é™æ•°æ®æ¡ä»¶ä¸‹ç”ŸæˆåŒç†å¿ƒå“åº”çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºåºå¤§çš„æ•°æ®é›†å’Œé«˜è®¡ç®—æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Emotion Omniæ¨¡å‹é€šè¿‡ç†è§£ç”¨æˆ·è¯­éŸ³ä¸­çš„æƒ…æ„Ÿå†…å®¹ï¼Œç”Ÿæˆæ›´å…·åŒç†å¿ƒçš„å“åº”ã€‚è¯¥è®¾è®¡æ—¨åœ¨æå‡äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEmotion Omniçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æƒ…æ„Ÿè¯†åˆ«æ¨¡å—å’Œå“åº”ç”Ÿæˆæ¨¡å—ã€‚æƒ…æ„Ÿè¯†åˆ«æ¨¡å—è´Ÿè´£åˆ†æç”¨æˆ·è¯­éŸ³ä¸­çš„æƒ…æ„Ÿä¿¡æ¯ï¼Œè€Œå“åº”ç”Ÿæˆæ¨¡å—åˆ™åŸºäºè¿™äº›ä¿¡æ¯ç”Ÿæˆé€‚å½“çš„è¯­éŸ³å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šEmotion Omniçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰å¤§è§„æ¨¡é¢„è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æœ‰é™çš„æ•°æ®é›†å®ç°æƒ…æ„Ÿç†è§£å’Œå“åº”ç”Ÿæˆã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—é™ä½äº†å¯¹è®¡ç®—èµ„æºçš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æƒ…æ„Ÿè¯†åˆ«çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥æé«˜ç”Ÿæˆå“åº”çš„è´¨é‡å’Œæƒ…æ„Ÿè¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEmotion Omniåœ¨è¯­éŸ³è´¨é‡æ–¹é¢çš„UTMOSè¯„åˆ†è¾¾åˆ°4.41ï¼Œè€Œåœ¨åŒç†å¿ƒè¯„ä¼°ä¸­çš„Emotion GPT Scoreä¸º3.97ï¼Œå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ã€‚è¿™äº›ç»“æœéªŒè¯äº†è¯¥æ¨¡å‹åœ¨è¯­éŸ³ä¿çœŸåº¦å’Œæƒ…æ„Ÿè¡¨è¾¾ä¸Šçš„æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹ã€å®¢æœæœºå™¨äººå’Œæƒ…æ„Ÿè®¡ç®—ç­‰ã€‚é€šè¿‡æå‡æœºå™¨å¯¹äººç±»æƒ…æ„Ÿçš„ç†è§£èƒ½åŠ›ï¼ŒEmotion Omnièƒ½å¤Ÿåœ¨å¤šç§åœºæ™¯ä¸­æä¾›æ›´ä¸ºè‡ªç„¶å’Œäººæ€§åŒ–çš„äº¤äº’ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨å¿ƒç†å¥åº·æ”¯æŒå’Œç¤¾äº¤æœºå™¨äººç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the development of speech large language models (speech LLMs), users can now interact directly with assistants via speech. However, most existing models only convert response content into speech without fully capturing the rich emotional cues in user queries, where the same sentence may convey different meanings depending on the expression. Emotional understanding is thus essential for improving human-machine interaction. Most empathetic speech LLMs rely on massive datasets, demanding high computational cost. A key challenge is to build models that generate empathetic responses with limited data and without large-scale training. To this end, we propose Emotion Omni, a model that understands emotional content in user speech and generates empathetic responses. We further developed a data pipeline to construct a 200k emotional dialogue dataset supporting empathetic speech assistants. Experiments show that Emotion Omni achieves comparable instruction-following ability without large-scale pretraining, while surpassing existing models in speech quality (UTMOS:4.41) and empathy (Emotion GPT Score: 3.97). These results confirm its improvements in both speech fidelity and emotional expressiveness. Demos are available at https://w311411.github.io/omni_demo/.

