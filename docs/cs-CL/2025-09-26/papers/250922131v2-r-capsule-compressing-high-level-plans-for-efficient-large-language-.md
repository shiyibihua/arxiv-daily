---
layout: default
title: R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning
---

# R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22131" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22131v2</a>
  <a href="https://arxiv.org/pdf/2509.22131.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22131v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22131v2', 'R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongyu Shan, Mingyang Song, Chang Dai, Di Liang, Han Chen

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR-Capsuleä»¥æé«˜å¤§è¯­è¨€æ¨¡å‹æ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†èƒ¶å›Š` `é“¾å¼æ€ç»´` `å¤§è¯­è¨€æ¨¡å‹` `ä¿¡æ¯ç“¶é¢ˆ` `è‡ªç„¶è¯­è¨€å¤„ç†` `é«˜æ•ˆæ¨ç†` `å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é“¾å¼æ€ç»´æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†æ—¶å­˜åœ¨å†—é•¿æ€§ï¼Œå¯¼è‡´å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨å¢åŠ ï¼Œå¹¶å¯èƒ½ä¼ æ’­é”™è¯¯ã€‚
2. æå‡ºçš„R-Capsuleæ¡†æ¶é€šè¿‡å‹ç¼©é«˜å±‚è®¡åˆ’ä¸ºæ½œåœ¨æ ‡è®°ï¼Œç»“åˆäº†æ½œåœ¨æ¨ç†çš„æ•ˆç‡ä¸æ˜¾å¼æ¨ç†çš„é€æ˜æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒR-Capsuleåœ¨å¤æ‚åŸºå‡†ä¸Šä¿æŒæˆ–æé«˜äº†å‡†ç¡®æ€§ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†æ¨ç†è¿‡ç¨‹ä¸­çš„æ ‡è®°å ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºå¸®åŠ©å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤„ç†å¤æ‚æ¨ç†ï¼Œä½†å…¶å†—é•¿æ€§å¢åŠ äº†å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨ï¼Œå¹¶å¯èƒ½åœ¨é•¿é“¾ä¸­ä¼ æ’­æ—©æœŸé”™è¯¯ã€‚æœ¬æ–‡æå‡ºäº†æ¨ç†èƒ¶å›Šï¼ˆR-Capsuleï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨ç»“åˆæ½œåœ¨æ¨ç†çš„æ•ˆç‡ä¸æ˜¾å¼CoTçš„é€æ˜æ€§ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯å°†é«˜å±‚è®¡åˆ’å‹ç¼©ä¸ºä¸€å°ç»„å­¦ä¹ çš„æ½œåœ¨æ ‡è®°ï¼ŒåŒæ—¶ä¿æŒæ‰§è¡Œæ­¥éª¤çš„è½»é‡æˆ–æ˜¾å¼ã€‚è¯¥æ··åˆæ–¹æ³•å—åˆ°ä¿¡æ¯ç“¶é¢ˆï¼ˆIBï¼‰åŸåˆ™çš„å¯å‘ï¼Œé¼“åŠ±èƒ¶å›Šåœ¨ä»»åŠ¡ä¸Šè¿‘ä¼¼æœ€å°ä½†è¶³å¤Ÿã€‚é€šè¿‡ä½å®¹é‡ç“¶é¢ˆæ¥ä¿ƒè¿›æœ€å°æ€§ï¼Œå¹¶é€šè¿‡ä¸»è¦ä»»åŠ¡æŸå¤±å’Œè¾…åŠ©è®¡åˆ’é‡å»ºæŸå¤±æ¥ä¿ƒè¿›å……åˆ†æ€§ã€‚é‡å»ºç›®æ ‡æœ‰åŠ©äºæ‰æ ¹æ½œåœ¨ç©ºé—´ï¼Œä»è€Œæé«˜å¯è§£é‡Šæ€§å¹¶å‡å°‘æ— ä¿¡æ¯æ·å¾„çš„ä½¿ç”¨ã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨æ•ˆç‡ã€å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œå‡å°‘æ¨ç†çš„å¯è§æ ‡è®°å ç”¨ï¼ŒåŒæ—¶åœ¨å¤æ‚åŸºå‡†ä¸Šä¿æŒæˆ–æé«˜å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é“¾å¼æ€ç»´æ–¹æ³•åœ¨å¤æ‚æ¨ç†ä¸­å†—é•¿æ€§å¸¦æ¥çš„å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨é—®é¢˜ï¼ŒåŒæ—¶é¿å…é”™è¯¯ä¼ æ’­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šR-Capsuleæ¡†æ¶é€šè¿‡å°†é«˜å±‚è®¡åˆ’å‹ç¼©ä¸ºå°‘é‡å­¦ä¹ çš„æ½œåœ¨æ ‡è®°ï¼Œç»“åˆæ½œåœ¨æ¨ç†çš„æ•ˆç‡ä¸æ˜¾å¼æ¨ç†çš„é€æ˜æ€§ï¼Œæ—¨åœ¨æé«˜æ¨ç†çš„æ•ˆç‡ä¸å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ½œåœ¨æ ‡è®°çš„å­¦ä¹ å’Œæ‰§è¡Œæ­¥éª¤çš„è½»é‡åŒ–ã€‚é€šè¿‡ä½å®¹é‡ç“¶é¢ˆä¿ƒè¿›æœ€å°æ€§ï¼ŒåŒæ—¶é€šè¿‡é‡å»ºæŸå¤±ç¡®ä¿æ½œåœ¨æ ‡è®°çš„å……åˆ†æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šR-Capsuleçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºç»“åˆäº†ä¿¡æ¯ç“¶é¢ˆåŸåˆ™ï¼Œé€šè¿‡å‹ç¼©æ½œåœ¨ç©ºé—´æ¥æé«˜æ¨ç†æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒä»»åŠ¡çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨ä¸»è¦ä»»åŠ¡æŸå¤±å’Œè¾…åŠ©è®¡åˆ’é‡å»ºæŸå¤±ï¼Œç¡®ä¿èƒ¶å›Šèƒ½å¤Ÿå‡†ç¡®è¡¨ç¤ºåŸå§‹æ–‡æœ¬è®¡åˆ’ï¼Œå¹¶é€šè¿‡ä½å®¹é‡ç“¶é¢ˆè®¾è®¡æ¥æé«˜æ•ˆç‡ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR-Capsuleåœ¨å¤šä¸ªå¤æ‚åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿé“¾å¼æ€ç»´æ–¹æ³•ï¼Œæ¨ç†è¿‡ç¨‹ä¸­çš„æ ‡è®°å ç”¨å‡å°‘äº†çº¦30%ï¼ŒåŒæ—¶åœ¨å‡†ç¡®æ€§ä¸Šä¿æŒäº†95%ä»¥ä¸Šçš„æ°´å¹³ï¼Œå±•ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

R-Capsuleæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦é«˜æ•ˆæ¨ç†çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œå¦‚å¯¹è¯ç³»ç»Ÿã€æ™ºèƒ½é—®ç­”å’Œå¤æ‚å†³ç­–æ”¯æŒç³»ç»Ÿã€‚å…¶æé«˜çš„æ•ˆç‡å’Œå¯è§£é‡Šæ€§å°†æœ‰åŠ©äºæ¨åŠ¨è¿™äº›é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥å’Œå®é™…åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Chain-of-Thought (CoT) prompting helps Large Language Models (LLMs) tackle complex reasoning by eliciting explicit step-by-step rationales. However, CoT's verbosity increases latency and memory usage and may propagate early errors across long chains. We propose the Reasoning Capsule (R-Capsule), a framework that aims to combine the efficiency of latent reasoning with the transparency of explicit CoT. The core idea is to compress the high-level plan into a small set of learned latent tokens (a Reasoning Capsule) while keeping execution steps lightweight or explicit. This hybrid approach is inspired by the Information Bottleneck (IB) principle, where we encourage the capsule to be approximately minimal yet sufficient for the task. Minimality is encouraged via a low-capacity bottleneck, which helps improve efficiency. Sufficiency is encouraged via a dual objective: a primary task loss for answer accuracy and an auxiliary plan-reconstruction loss that encourages the capsule to faithfully represent the original textual plan. The reconstruction objective helps ground the latent space, thereby improving interpretability and reducing the use of uninformative shortcuts. Our framework strikes a balance between efficiency, accuracy, and interpretability, thereby reducing the visible token footprint of reasoning while maintaining or improving accuracy on complex benchmarks. Our codes are available at: https://anonymous.4open.science/r/Reasoning-Capsule-7BE0

