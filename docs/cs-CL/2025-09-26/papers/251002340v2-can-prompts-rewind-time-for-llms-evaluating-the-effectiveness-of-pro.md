---
layout: default
title: Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs
---

# Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02340" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02340v2</a>
  <a href="https://arxiv.org/pdf/2510.02340.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02340v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02340v2', 'Can Prompts Rewind Time for LLMs? Evaluating the Effectiveness of Prompted Knowledge Cutoffs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Gao, Ruiyi Zhang, Daniel Du, Saurabh Mahindre, Sai Ashish Somayajula, Pengtao Xie

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-10-15)

**å¤‡æ³¨**: Published at EMNLP 2025; Code and data available at https://github.com/gxx27/time_unlearn

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/gxx27/time_unlearn)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨Promptæ¨¡æ‹ŸçŸ¥è¯†æˆªæ–­è¯„ä¼°LLMçš„æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ä¸é—å¿˜æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†æˆªæ–­` `æ—¶é—´æ„ŸçŸ¥` `Promptå·¥ç¨‹` `é—å¿˜å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨æ—¶é—´é¢„æµ‹ä»»åŠ¡ä¸­å­˜åœ¨ä¾èµ–é¢„è®­ç»ƒæ•°æ®çš„é—®é¢˜ï¼Œå¯¼è‡´æ— æ³•åŒºåˆ†æ˜¯è®°å¿†è¿˜æ˜¯æ¨ç†ï¼Œé«˜ä¼°äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
2. è¯¥è®ºæ–‡æå‡ºåˆ©ç”¨Promptæ¥æ¨¡æ‹ŸLLMçš„çŸ¥è¯†æˆªæ–­ï¼Œä»è€Œè¯„ä¼°æ¨¡å‹æ˜¯å¦çœŸæ­£å…·å¤‡æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›å’Œé—å¿˜èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒPromptåœ¨ç›´æ¥æŸ¥è¯¢æˆªæ–­æ—¥æœŸåçš„ä¿¡æ¯æ—¶æœ‰æ•ˆï¼Œä½†åœ¨æ¶‰åŠå› æœå…³ç³»çš„æŸ¥è¯¢æ—¶æ•ˆæœä¸ä½³ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¢«å¹¿æ³›åº”ç”¨äºæ—¶é—´é¢„æµ‹ï¼Œä½†å®ƒä»¬å¯¹é¢„è®­ç»ƒæ•°æ®çš„ä¾èµ–å¼•å‘äº†æ±¡æŸ“é—®é¢˜ã€‚åœ¨æˆªæ–­æ—¥æœŸä¹‹å‰çš„æµ‹è¯•æ•°æ®ä¸Šè·å¾—çš„å‡†ç¡®é¢„æµ‹å¯èƒ½åæ˜ äº†è®°å¿†ï¼Œè€Œéæ¨ç†ï¼Œä»è€Œå¯¼è‡´å¯¹å…¶æ³›åŒ–èƒ½åŠ›çš„è¿‡åº¦ä¼°è®¡ã€‚éšç€æœ€è¿‘åŸºäºPromptçš„é—å¿˜æŠ€æœ¯çš„å‡ºç°ï¼Œä¸€ä¸ªè‡ªç„¶çš„é—®é¢˜æ˜¯ï¼šLLMèƒ½å¦é€šè¿‡Promptæ¨¡æ‹Ÿæ›´æ—©çš„çŸ¥è¯†æˆªæ–­ï¼Ÿæœ¬æ–‡ç ”ç©¶äº†Promptåœ¨LLMä¸­æ¨¡æ‹Ÿæ›´æ—©çŸ¥è¯†æˆªæ–­çš„èƒ½åŠ›ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸‰ä¸ªè¯„ä¼°æ•°æ®é›†ï¼Œä»¥è¯„ä¼°LLMåœ¨å¤šå¤§ç¨‹åº¦ä¸Šå¯ä»¥å¿˜è®°ï¼ˆ1ï¼‰ç›´æ¥çš„äº‹å®çŸ¥è¯†ï¼Œï¼ˆ2ï¼‰è¯­ä¹‰è½¬å˜ï¼Œä»¥åŠï¼ˆ3ï¼‰å› æœç›¸å…³çš„çŸ¥è¯†ã€‚ç»“æœè¡¨æ˜ï¼Œå½“ç›´æ¥æŸ¥è¯¢æˆªæ–­æ—¥æœŸä¹‹åçš„ä¿¡æ¯æ—¶ï¼ŒåŸºäºPromptçš„æ¨¡æ‹ŸçŸ¥è¯†æˆªæ–­æ˜¾ç¤ºå‡ºæœ‰æ•ˆæ€§ï¼Œä½†å½“å¿˜è®°çš„å†…å®¹ä¸æ˜¯ç›´æ¥è¯¢é—®è€Œæ˜¯ä¸æŸ¥è¯¢å­˜åœ¨å› æœå…³ç³»æ—¶ï¼Œå®ƒä»¬éš¾ä»¥è¯±å¯¼é—å¿˜ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨å°†LLMåº”ç”¨äºæ—¶é—´é¢„æµ‹ä»»åŠ¡æ—¶ï¼Œéœ€è¦æ›´ä¸¥æ ¼çš„è¯„ä¼°è®¾ç½®ã€‚å®Œæ•´çš„æ•°æ®é›†å’Œè¯„ä¼°ä»£ç å¯åœ¨https://github.com/gxx27/time_unlearn è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„LLMåœ¨æ—¶é—´é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œç”±äºå…¶é¢„è®­ç»ƒæ•°æ®åŒ…å«äº†å¤§é‡æ—¶é—´ä¿¡æ¯ï¼Œå› æ­¤åœ¨è¯„ä¼°å…¶æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›æ—¶ï¼Œéš¾ä»¥åŒºåˆ†æ¨¡å‹æ˜¯é€šè¿‡è®°å¿†è¿˜æ˜¯é€šè¿‡æ¨ç†æ¥åšå‡ºé¢„æµ‹ã€‚è¿™å¯¼è‡´å¯¹LLMæ³›åŒ–èƒ½åŠ›çš„è¯„ä¼°å­˜åœ¨åå·®ï¼Œé«˜ä¼°äº†å…¶çœŸå®æ€§èƒ½ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–¹æ³•æ¥è¯„ä¼°LLMæ˜¯å¦çœŸæ­£å…·å¤‡â€œé—å¿˜â€è¿‡å»çŸ¥è¯†çš„èƒ½åŠ›ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œæ—¶é—´æ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Promptæ¥æ¨¡æ‹ŸLLMçš„çŸ¥è¯†æˆªæ–­ï¼Œå³é€šè¿‡ç‰¹å®šçš„PromptæŒ‡ä»¤ï¼Œè®©LLMâ€œå¿˜è®°â€æŸä¸ªæ—¶é—´ç‚¹ä¹‹åçš„ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªå—æ§çš„å®éªŒç¯å¢ƒï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°LLMçš„æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›å’Œé—å¿˜æ•ˆæœã€‚å¦‚æœLLMèƒ½å¤ŸæˆåŠŸåœ°æ¨¡æ‹ŸçŸ¥è¯†æˆªæ–­ï¼Œé‚£ä¹ˆå®ƒåœ¨å›ç­”ç›¸å…³é—®é¢˜æ—¶ï¼Œåº”è¯¥åªä¾èµ–äºæˆªæ–­æ—¥æœŸä¹‹å‰çš„çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1ï¼‰æ„å»ºè¯„ä¼°æ•°æ®é›†ï¼šé’ˆå¯¹äº‹å®çŸ¥è¯†ã€è¯­ä¹‰è½¬å˜å’Œå› æœå…³ç³»ä¸‰ç§ç±»å‹çš„ä¿¡æ¯ï¼Œæ„å»ºäº†ä¸‰ä¸ªè¯„ä¼°æ•°æ®é›†ï¼Œæ¯ä¸ªæ•°æ®é›†éƒ½åŒ…å«æ—¶é—´ä¿¡æ¯ã€‚2ï¼‰è®¾è®¡Promptï¼šè®¾è®¡ä¸åŒçš„PromptæŒ‡ä»¤ï¼Œå¼•å¯¼LLMæ¨¡æ‹ŸçŸ¥è¯†æˆªæ–­ï¼Œä¾‹å¦‚â€œè¯·å¿˜è®°2020å¹´ä¹‹åçš„ä¿¡æ¯â€ã€‚3ï¼‰è¿›è¡Œè¯„ä¼°ï¼šä½¿ç”¨æ„å»ºçš„æ•°æ®é›†å’Œè®¾è®¡çš„Promptï¼Œå¯¹LLMè¿›è¡Œè¯„ä¼°ï¼Œè€ƒå¯Ÿå…¶åœ¨ä¸åŒç±»å‹ä¿¡æ¯ä¸Šçš„é—å¿˜æ•ˆæœã€‚4ï¼‰åˆ†æç»“æœï¼šåˆ†æè¯„ä¼°ç»“æœï¼Œåˆ¤æ–­LLMæ˜¯å¦æˆåŠŸåœ°æ¨¡æ‹Ÿäº†çŸ¥è¯†æˆªæ–­ï¼Œå¹¶æ¢è®¨å…¶é—å¿˜èƒ½åŠ›çš„å±€é™æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åˆ©ç”¨Promptæ¥æ¨¡æ‹ŸLLMçŸ¥è¯†æˆªæ–­çš„æ–¹æ³•ï¼Œè¿™ä¸ºè¯„ä¼°LLMçš„æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›å’Œé—å¿˜æ•ˆæœæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚ä¸ä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ çµæ´»å’Œå¯æ§ï¼Œå¯ä»¥é’ˆå¯¹ä¸åŒç±»å‹çš„ä¿¡æ¯è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ·±å…¥äº†è§£LLMçš„é—å¿˜æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Promptè®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡å°è¯•äº†å¤šç§ä¸åŒçš„Promptå½¢å¼ï¼Œä¾‹å¦‚ç›´æ¥æŒ‡ä»¤ï¼ˆâ€œè¯·å¿˜è®°2020å¹´ä¹‹åçš„ä¿¡æ¯â€ï¼‰ã€é—´æ¥æŒ‡ä»¤ï¼ˆâ€œå‡è®¾ç°åœ¨æ˜¯2020å¹´â€ï¼‰ã€‚åœ¨æ•°æ®é›†æ„å»ºæ–¹é¢ï¼Œè®ºæ–‡ç‰¹åˆ«å…³æ³¨äº†å› æœå…³ç³»ä¿¡æ¯çš„æ„å»ºï¼Œå› ä¸ºè¿™ç§ç±»å‹çš„ä¿¡æ¯æ›´èƒ½ä½“ç°LLMçš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡LLMçš„é—å¿˜æ•ˆæœï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“ç›´æ¥æŸ¥è¯¢æˆªæ–­æ—¥æœŸä¹‹åçš„ä¿¡æ¯æ—¶ï¼ŒåŸºäºPromptçš„æ¨¡æ‹ŸçŸ¥è¯†æˆªæ–­æ˜¾ç¤ºå‡ºä¸€å®šçš„æœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œå½“æŸ¥è¯¢æ¶‰åŠå› æœå…³ç³»æ—¶ï¼ŒLLMéš¾ä»¥è¯±å¯¼é—å¿˜ï¼Œè¡¨æ˜å…¶é—å¿˜èƒ½åŠ›å­˜åœ¨å±€é™æ€§ã€‚è¿™æç¤ºæˆ‘ä»¬åœ¨è¯„ä¼°LLMçš„æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›æ—¶ï¼Œéœ€è¦æ›´åŠ å…³æ³¨å› æœå…³ç³»ç­‰å¤æ‚ä¿¡æ¯çš„å¤„ç†ï¼Œå¹¶è®¾è®¡æ›´ä¸¥æ ¼çš„è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨æ—¶é—´æ•æ„Ÿå‹ä»»åŠ¡ä¸­çš„å¯é æ€§ï¼Œä¾‹å¦‚é‡‘èé¢„æµ‹ã€æ–°é—»æ‘˜è¦ã€å†å²äº‹ä»¶åˆ†æç­‰ã€‚é€šè¿‡Promptæ§åˆ¶LLMçš„çŸ¥è¯†èŒƒå›´ï¼Œå¯ä»¥é¿å…æ¨¡å‹å—åˆ°æœ€æ–°ä¿¡æ¯çš„å¹²æ‰°ï¼Œä»è€Œæé«˜é¢„æµ‹çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿæœ‰åŠ©äºå¼€å‘æ›´å®‰å…¨ã€å¯æ§çš„LLMï¼Œé˜²æ­¢æ¨¡å‹æ³„éœ²æ•æ„Ÿä¿¡æ¯æˆ–äº§ç”Ÿä¸å½“è¨€è®ºã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are widely used for temporal prediction, but their reliance on pretraining data raises contamination concerns, as accurate predictions on pre-cutoff test data may reflect memorization rather than reasoning, leading to an overestimation of their generalization capability. With the recent emergence of prompting-based unlearning techniques, a natural question arises: Can LLMs be prompted to simulate an earlier knowledge cutoff? In this work, we investigate the capability of prompting to simulate earlier knowledge cutoff in LLMs. We construct three evaluation datasets to assess the extent to which LLMs can forget (1) direct factual knowledge, (2) semantic shifts, and (3) causally related knowledge. Results demonstrate that while prompt-based simulated knowledge cutoffs show effectiveness when directly queried with the information after that date, they struggle to induce forgetting when the forgotten content is not directly asked but causally related to the query. These findings highlight the need for more rigorous evaluation settings when applying LLMs for temporal prediction tasks. The full dataset and evaluation code are available at https://github.com/gxx27/time_unlearn.

