---
layout: default
title: VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing
---

# VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22651" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22651v1</a>
  <a href="https://arxiv.org/pdf/2509.22651.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22651v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22651v1', 'VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ke Wang, Houxing Ren, Zimu Lu, Mingjie Zhan, Hongsheng Li

**åˆ†ç±»**: cs.CL, cs.AI, cs.CV, cs.HC, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://mathllm.github.io/VoiceAssistantEval/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VoiceAssistant-Evalï¼šä¸€ä¸ªç»¼åˆæ€§çš„AIåŠ©æ‰‹è¯„æµ‹åŸºå‡†ï¼Œè¦†ç›–å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIåŠ©æ‰‹è¯„æµ‹` `å¤šæ¨¡æ€å­¦ä¹ ` `è¯­éŸ³è¯†åˆ«` `è¯­éŸ³åˆæˆ` `å›¾åƒç†è§£` `åŸºå‡†æ•°æ®é›†` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AIåŠ©æ‰‹è¯„æµ‹åŸºå‡†æ— æ³•å…¨é¢è¯„ä¼°å…¶å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰èƒ½åŠ›ï¼Œé™åˆ¶äº†ç›¸å…³æŠ€æœ¯å‘å±•ã€‚
2. æå‡ºVoiceAssistant-Evalï¼Œä¸€ä¸ªåŒ…å«10497ä¸ªç¤ºä¾‹çš„ç»¼åˆåŸºå‡†ï¼Œè¦†ç›–13ä¸ªä»»åŠ¡ç±»åˆ«ï¼Œè¯„ä¼°AIåŠ©æ‰‹å¤šæ¨¡æ€èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¼€æºæ¨¡å‹åœ¨æŸäº›æ–¹é¢å¯ä¸ä¸“æœ‰æ¨¡å‹ç«äº‰ï¼Œä½†å¤šæ¨¡æ€ç†è§£å’Œé²æ£’æ€§ä»æœ‰å¾…æé«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€ç³»ç»Ÿèƒ½åŠ›çš„ä¸æ–­å¢å¼ºæ¿€å‘äº†äººä»¬å¯¹è¯­éŸ³ä¼˜å…ˆAIåŠ©æ‰‹çš„å…´è¶£ï¼Œä½†ç°æœ‰çš„åŸºå‡†ä¸è¶³ä»¥è¯„ä¼°è¿™äº›ç³»ç»Ÿçš„å…¨éƒ¨èƒ½åŠ›ã€‚æˆ‘ä»¬æ¨å‡ºäº†VoiceAssistant-Evalï¼Œè¿™æ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°AIåŠ©æ‰‹åœ¨å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰æ–¹é¢çš„èƒ½åŠ›ã€‚VoiceAssistant-EvalåŒ…å«10497ä¸ªç²¾å¿ƒç­–åˆ’çš„ç¤ºä¾‹ï¼Œæ¶µç›–13ä¸ªä»»åŠ¡ç±»åˆ«ã€‚è¿™äº›ä»»åŠ¡åŒ…æ‹¬è‡ªç„¶å£°éŸ³ã€éŸ³ä¹å’Œå£è¯­å¯¹è¯çš„å¬è§‰ç†è§£ï¼›å¤šè½®å¯¹è¯ã€è§’è‰²æ‰®æ¼”æ¨¡ä»¿å’Œå„ç§åœºæ™¯çš„è¯­éŸ³ç”Ÿæˆï¼›ä»¥åŠé«˜åº¦å¼‚æ„çš„å›¾åƒçš„è§†è§‰ç†è§£ã€‚ä¸ºäº†è¯æ˜å…¶æ•ˆç”¨ï¼Œæˆ‘ä»¬è¯„ä¼°äº†21ä¸ªå¼€æºæ¨¡å‹å’ŒGPT-4o-Audioï¼Œæµ‹é‡äº†å“åº”å†…å®¹å’Œè¯­éŸ³çš„è´¨é‡ä»¥åŠå®ƒä»¬çš„ä¸€è‡´æ€§ã€‚ç»“æœæ­ç¤ºäº†ä¸‰ä¸ªå…³é”®å‘ç°ï¼š(1)ä¸“æœ‰æ¨¡å‹å¹¶éæ™®éä¼˜äºå¼€æºæ¨¡å‹ï¼›(2)å¤§å¤šæ•°æ¨¡å‹æ“…é•¿è¯­éŸ³ä»»åŠ¡ï¼Œä½†åœ¨éŸ³é¢‘ç†è§£æ–¹é¢æ»åï¼›(3)ç²¾å¿ƒè®¾è®¡çš„å°å‹æ¨¡å‹å¯ä»¥ä¸æ›´å¤§çš„æ¨¡å‹ç›¸åª²ç¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸­ç­‰è§„æ¨¡çš„Step-Audio-2-mini (7B)çš„å¬è§‰å‡†ç¡®ç‡æ˜¯LLaMA-Omni2-32B-Bilingualçš„ä¸¤å€å¤šã€‚ç„¶è€Œï¼Œä»ç„¶å­˜åœ¨æŒ‘æˆ˜ï¼šå¤šæ¨¡æ€ï¼ˆéŸ³é¢‘åŠ è§†è§‰ï¼‰è¾“å…¥å’Œè§’è‰²æ‰®æ¼”è¯­éŸ³æ¨¡ä»¿ä»»åŠ¡å¯¹äºå½“å‰æ¨¡å‹æ¥è¯´å¾ˆå›°éš¾ï¼Œå¹¶ä¸”åœ¨é²æ£’æ€§å’Œå®‰å…¨å¯¹é½æ–¹é¢ä»ç„¶å­˜åœ¨æ˜¾è‘—å·®è·ã€‚VoiceAssistant-Evalè¯†åˆ«äº†è¿™äº›å·®è·ï¼Œå¹¶å»ºç«‹äº†ä¸€ä¸ªä¸¥æ ¼çš„æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å’ŒæŒ‡å¯¼ä¸‹ä¸€ä»£AIåŠ©æ‰‹çš„å¼€å‘ã€‚ä»£ç å’Œæ•°æ®å°†åœ¨https://mathllm.github.io/VoiceAssistantEval/ ä¸Šå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰AIåŠ©æ‰‹è¯„æµ‹åŸºå‡†ä¸»è¦å…³æ³¨æ–‡æœ¬è¾“å…¥å’Œè¾“å‡ºï¼Œç¼ºä¹å¯¹å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰èƒ½åŠ›çš„ç»¼åˆè¯„ä¼°ã€‚è¿™å¯¼è‡´æˆ‘ä»¬éš¾ä»¥å…¨é¢äº†è§£AIåŠ©æ‰‹åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤„ç†å¤šæ¨¡æ€ä¿¡æ¯çš„å¤æ‚ä»»åŠ¡ä¸­ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ— æ³•æœ‰æ•ˆè¡¡é‡AIåŠ©æ‰‹åœ¨éŸ³é¢‘ç†è§£ã€è¯­éŸ³ç”Ÿæˆä»¥åŠå¤šæ¨¡æ€äº¤äº’æ–¹é¢çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVoiceAssistant-Evalçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå…¨é¢ã€å¤šæ ·åŒ–çš„è¯„æµ‹æ•°æ®é›†ï¼Œè¦†ç›–AIåŠ©æ‰‹åœ¨å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰æ–¹é¢çš„å…³é”®èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ä¸€ç³»åˆ—å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªç„¶å£°éŸ³è¯†åˆ«ã€å¤šè½®å¯¹è¯ã€è§’è‰²æ‰®æ¼”æ¨¡ä»¿å’Œå›¾åƒç†è§£ï¼Œæ¥è¯„ä¼°AIåŠ©æ‰‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚è¯¥åŸºå‡†æ—¨åœ¨æ­ç¤ºç°æœ‰æ¨¡å‹çš„ä¼˜åŠ¿å’Œä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVoiceAssistant-EvalåŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¬è§‰è¯„ä¼°ã€è¯­éŸ³è¯„ä¼°å’Œè§†è§‰è¯„ä¼°ã€‚å¬è§‰è¯„ä¼°æ¨¡å—åŒ…å«è‡ªç„¶å£°éŸ³ã€éŸ³ä¹å’Œå£è¯­å¯¹è¯ç­‰ä»»åŠ¡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å¯¹éŸ³é¢‘ä¿¡æ¯çš„ç†è§£èƒ½åŠ›ã€‚è¯­éŸ³è¯„ä¼°æ¨¡å—åŒ…å«å¤šè½®å¯¹è¯ã€è§’è‰²æ‰®æ¼”æ¨¡ä»¿å’Œå„ç§åœºæ™¯ç­‰ä»»åŠ¡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹çš„è¯­éŸ³ç”Ÿæˆèƒ½åŠ›ã€‚è§†è§‰è¯„ä¼°æ¨¡å—åŒ…å«é«˜åº¦å¼‚æ„çš„å›¾åƒï¼Œç”¨äºè¯„ä¼°æ¨¡å‹å¯¹å›¾åƒä¿¡æ¯çš„ç†è§£èƒ½åŠ›ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡ç»Ÿä¸€çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œä»è€Œå®ç°å¯¹AIåŠ©æ‰‹èƒ½åŠ›çš„å…¨é¢è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šVoiceAssistant-Evalæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶ç»¼åˆæ€§å’Œå¤šæ ·æ€§ã€‚ä¸ç°æœ‰çš„åŸºå‡†ç›¸æ¯”ï¼ŒVoiceAssistant-Evalä¸ä»…è¦†ç›–äº†å¬è§‰ã€è¯­éŸ³å’Œè§†è§‰ä¸‰ç§æ¨¡æ€ï¼Œè¿˜åŒ…å«äº†å„ç§å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä¾‹å¦‚è§’è‰²æ‰®æ¼”è¯­éŸ³æ¨¡ä»¿å’Œå¤šæ¨¡æ€è¾“å…¥ã€‚è¿™ç§è®¾è®¡ä½¿å¾—VoiceAssistant-Evalèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°AIåŠ©æ‰‹çš„çœŸå®ä¸–ç•Œæ€§èƒ½ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ›´ä¸°å¯Œçš„å®éªŒæ•°æ®ã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒVoiceAssistant-Evalæ›´åŠ å…³æ³¨AIåŠ©æ‰‹åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸‹çš„äº¤äº’èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯å•æ¨¡æ€çš„ç†è§£æˆ–ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºæ–¹é¢ï¼Œä½œè€…ç²¾å¿ƒæŒ‘é€‰äº†10497ä¸ªç¤ºä¾‹ï¼Œå¹¶å¯¹æ¯ä¸ªç¤ºä¾‹è¿›è¡Œäº†è¯¦ç»†çš„æ ‡æ³¨ã€‚åœ¨è¯„ä¼°æŒ‡æ ‡æ–¹é¢ï¼Œä½œè€…é‡‡ç”¨äº†å¤šç§æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼ŒåŒ…æ‹¬å‡†ç¡®ç‡ã€BLEUåˆ†æ•°å’Œè¯­éŸ³è´¨é‡è¯„ä¼°æŒ‡æ ‡ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜è®¾è®¡äº†ä¸€å¥—ç»Ÿä¸€çš„è¯„ä¼°æµç¨‹ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„å¯é æ€§å’Œå¯æ¯”æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚å–å†³äºè¢«è¯„ä¼°çš„æ¨¡å‹ï¼ŒVoiceAssistant-Evalä¸»è¦æä¾›ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°å¹³å°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸“æœ‰æ¨¡å‹å¹¶éåœ¨æ‰€æœ‰ä»»åŠ¡ä¸Šéƒ½ä¼˜äºå¼€æºæ¨¡å‹ï¼Œä¸­ç­‰è§„æ¨¡çš„Step-Audio-2-mini (7B)åœ¨å¬è§‰å‡†ç¡®ç‡ä¸Šè¶…è¿‡äº†LLaMA-Omni2-32B-Bilingualä¸¤å€ä»¥ä¸Šã€‚ç„¶è€Œï¼Œå¤šæ¨¡æ€è¾“å…¥å’Œè§’è‰²æ‰®æ¼”è¯­éŸ³æ¨¡ä»¿ä»»åŠ¡å¯¹ç°æœ‰æ¨¡å‹ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå¹¶ä¸”åœ¨é²æ£’æ€§å’Œå®‰å…¨å¯¹é½æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚è¿™äº›å‘ç°ä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†é‡è¦çš„å¯ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VoiceAssistant-Evalå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å„ç§è¯­éŸ³åŠ©æ‰‹ï¼Œä¾‹å¦‚æ™ºèƒ½éŸ³ç®±ã€è½¦è½½åŠ©æ‰‹å’Œç§»åŠ¨åº”ç”¨ä¸­çš„è¯­éŸ³äº¤äº’åŠŸèƒ½ã€‚è¯¥åŸºå‡†èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…è¯†åˆ«ç°æœ‰æ¨¡å‹çš„ä¸è¶³ï¼Œå¹¶æŒ‡å¯¼ä¸‹ä¸€ä»£AIåŠ©æ‰‹çš„å¼€å‘ï¼Œä½¿å…¶åœ¨å¤šæ¨¡æ€äº¤äº’ã€é²æ£’æ€§å’Œå®‰å…¨æ€§æ–¹é¢å¾—åˆ°æå‡ã€‚è¿™æœ‰åŠ©äºæ¨åŠ¨äººæœºäº¤äº’æŠ€æœ¯çš„è¿›æ­¥ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´è‡ªç„¶ã€æ›´æ™ºèƒ½çš„è¯­éŸ³åŠ©æ‰‹ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing capabilities of large language models and multimodal systems have spurred interest in voice-first AI assistants, yet existing benchmarks are inadequate for evaluating the full range of these systems' capabilities. We introduce VoiceAssistant-Eval, a comprehensive benchmark designed to assess AI assistants across listening, speaking, and viewing. VoiceAssistant-Eval comprises 10,497 curated examples spanning 13 task categories. These tasks include natural sounds, music, and spoken dialogue for listening; multi-turn dialogue, role-play imitation, and various scenarios for speaking; and highly heterogeneous images for viewing. To demonstrate its utility, we evaluate 21 open-source models and GPT-4o-Audio, measuring the quality of the response content and speech, as well as their consistency. The results reveal three key findings: (1) proprietary models do not universally outperform open-source models; (2) most models excel at speaking tasks but lag in audio understanding; and (3) well-designed smaller models can rival much larger ones. Notably, the mid-sized Step-Audio-2-mini (7B) achieves more than double the listening accuracy of LLaMA-Omni2-32B-Bilingual. However, challenges remain: multimodal (audio plus visual) input and role-play voice imitation tasks are difficult for current models, and significant gaps persist in robustness and safety alignment. VoiceAssistant-Eval identifies these gaps and establishes a rigorous framework for evaluating and guiding the development of next-generation AI assistants. Code and data will be released at https://mathllm.github.io/VoiceAssistantEval/ .

