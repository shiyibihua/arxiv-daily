---
layout: default
title: Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data
---

# Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22224" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22224v1</a>
  <a href="https://arxiv.org/pdf/2509.22224.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22224v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22224v1', 'Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zishan Ahmad, Saisubramaniam Gopalakrishnan

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: 7 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤åˆæ¨ç†(CR)æ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å°‘æ•°æ®ä¸‹çš„å¤æ‚é—®é¢˜æ±‚è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¤åˆæ¨ç†` `å°‘æ ·æœ¬å­¦ä¹ ` `æ¨ç†é£æ ¼` `ç§‘å­¦é—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚é—®é¢˜ä¸Šè¡¨ç°å—é™ï¼ŒåŸå› æ˜¯å®ƒä»¬ä¾èµ–äºå•ä¸€çš„æ¨ç†æ¨¡å¼ï¼Œç¼ºä¹çµæ´»æ€§ã€‚
2. è®ºæ–‡æå‡ºå¤åˆæ¨ç†(CR)æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€ç»„åˆæ¼”ç»ã€å½’çº³ã€æº¯å› ç­‰å¤šç§æ¨ç†é£æ ¼æ¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCRæ–¹æ³•åœ¨ç§‘å­¦å’ŒåŒ»å­¦é—®ç­”ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å…·æœ‰æ›´é«˜çš„æ ·æœ¬æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è™½ç„¶èƒ½åŠ›æ˜¾è‘—ï¼Œä½†ä¾èµ–äºå•ä¸€çš„ã€ä¸»å¯¼çš„æ¨ç†èŒƒå¼ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦å¤šæ ·åŒ–è®¤çŸ¥ç­–ç•¥çš„å¤æ‚é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†å¤åˆæ¨ç†(CR)ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¨ç†æ–¹æ³•ï¼Œå®ƒä½¿LLMsèƒ½å¤ŸåŠ¨æ€åœ°æ¢ç´¢å’Œç»„åˆå¤šç§æ¨ç†é£æ ¼ï¼Œå¦‚æ¼”ç»ã€å½’çº³å’Œæº¯å› ï¼Œä»è€Œå®ç°æ›´ç»†è‡´çš„è§£å†³é—®é¢˜ã€‚åœ¨ç§‘å­¦å’ŒåŒ»å­¦é—®ç­”åŸºå‡†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºç°æœ‰çš„åŸºçº¿ï¼Œå¦‚æ€ç»´é“¾(CoT)ï¼Œå¹¶ä¸”è¶…è¿‡äº†DeepSeek-R1é£æ ¼æ¨ç†(SR)çš„èƒ½åŠ›ï¼ŒåŒæ—¶è¡¨ç°å‡ºå“è¶Šçš„æ ·æœ¬æ•ˆç‡å’Œè¶³å¤Ÿçš„tokenä½¿ç”¨é‡ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒCRè‡ªé€‚åº”åœ°å¼ºè°ƒç‰¹å®šé¢†åŸŸé€‚å½“çš„æ¨ç†é£æ ¼ã€‚å®ƒä¼˜å…ˆè€ƒè™‘æº¯å› å’Œæ¼”ç»æ¨ç†ç”¨äºåŒ»å­¦é—®ç­”ï¼Œä½†è½¬å‘å› æœã€æ¼”ç»å’Œå½’çº³æ–¹æ³•ç”¨äºç§‘å­¦æ¨ç†ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé€šè¿‡åŸ¹å…»å†…éƒ¨æ¨ç†é£æ ¼çš„å¤šæ ·æ€§ï¼ŒLLMsè·å¾—äº†æ›´å¼ºå¤§ã€é€‚åº”æ€§å’Œé«˜æ•ˆçš„è§£å†³é—®é¢˜èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨è§£å†³å¤æ‚é—®é¢˜æ—¶ï¼Œé€šå¸¸ä¾èµ–äºå•ä¸€çš„æ¨ç†èŒƒå¼ï¼Œä¾‹å¦‚æ€ç»´é“¾(Chain-of-Thought, CoT)ã€‚è¿™ç§å•ä¸€çš„æ¨ç†æ–¹å¼éš¾ä»¥é€‚åº”éœ€è¦å¤šç§è®¤çŸ¥ç­–ç•¥çš„é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ç“¶é¢ˆã€‚å°¤å…¶æ˜¯åœ¨æ•°æ®é‡æœ‰é™çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å—åˆ°æ›´å¤§çš„é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®©å¤§è¯­è¨€æ¨¡å‹èƒ½å¤ŸåŠ¨æ€åœ°æ¢ç´¢å’Œç»„åˆå¤šç§æ¨ç†é£æ ¼ï¼Œä¾‹å¦‚æ¼”ç»æ¨ç†ã€å½’çº³æ¨ç†å’Œæº¯å› æ¨ç†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®é—®é¢˜çš„ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¨ç†æ–¹å¼ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°è§£å†³é—®é¢˜ã€‚è¿™ç§å¤åˆæ¨ç†(Composite Reasoning, CR)çš„æ€æƒ³æ—¨åœ¨æå‡æ¨¡å‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCRæ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ¢ç´¢ä¸åŒçš„æ¨ç†è·¯å¾„ã€‚å…·ä½“æ¥è¯´ï¼Œæ¨¡å‹é¦–å…ˆä¼šæ ¹æ®è¾“å…¥é—®é¢˜ç”Ÿæˆå¤šä¸ªå€™é€‰çš„æ¨ç†æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤å¯¹åº”ä¸€ç§ä¸åŒçš„æ¨ç†é£æ ¼ã€‚ç„¶åï¼Œæ¨¡å‹ä¼šè¯„ä¼°æ¯ä¸ªæ¨ç†æ­¥éª¤çš„è´¨é‡ï¼Œå¹¶é€‰æ‹©æœ€ä¼˜çš„æ­¥éª¤è¿›è¡Œä¸‹ä¸€æ­¥æ¨ç†ã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šè¿­ä»£è¿›è¡Œï¼Œç›´åˆ°å¾—åˆ°æœ€ç»ˆçš„ç­”æ¡ˆã€‚æ•´ä½“æµç¨‹å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªæœç´¢è¿‡ç¨‹ï¼Œæ¨¡å‹åœ¨ä¸åŒçš„æ¨ç†é£æ ¼ä¹‹é—´è¿›è¡Œæ¢ç´¢ï¼Œæœ€ç»ˆæ‰¾åˆ°æœ€ä¼˜çš„æ¨ç†è·¯å¾„ã€‚

**å…³é”®åˆ›æ–°**ï¼šCRæ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå®ƒæ‰“ç ´äº†ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹ä¾èµ–å•ä¸€æ¨ç†èŒƒå¼çš„å±€é™æ€§ï¼Œå¼•å…¥äº†æ¨ç†é£æ ¼å¤šæ ·æ€§çš„æ¦‚å¿µã€‚é€šè¿‡åŠ¨æ€ç»„åˆä¸åŒçš„æ¨ç†é£æ ¼ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°é€‚åº”å¤æ‚é—®é¢˜çš„éœ€æ±‚ã€‚ä¸ç°æœ‰çš„æ–¹æ³•ç›¸æ¯”ï¼ŒCRæ–¹æ³•æ›´åŠ çµæ´»å’Œé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å¹¶æ²¡æœ‰è¯¦ç»†æè¿°å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚ä½†æ˜¯ï¼Œå¯ä»¥æ¨æµ‹ï¼Œæ¨¡å‹éœ€è¦ä¸€ä¸ªæœºåˆ¶æ¥è¯„ä¼°ä¸åŒæ¨ç†æ­¥éª¤çš„è´¨é‡ï¼Œå¹¶é€‰æ‹©æœ€ä¼˜çš„æ­¥éª¤ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°ä¸€äº›å¯å­¦ä¹ çš„å‚æ•°ï¼Œä¾‹å¦‚ç”¨äºè¯„ä¼°æ¨ç†æ­¥éª¤è´¨é‡çš„è¯„åˆ†å‡½æ•°ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è¿˜éœ€è¦ä¸€ä¸ªç­–ç•¥æ¥æ§åˆ¶æ¨ç†è¿‡ç¨‹çš„æ¢ç´¢æ·±åº¦å’Œå¹¿åº¦ï¼Œä»¥é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜è§£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¤åˆæ¨ç†(CR)æ–¹æ³•åœ¨ç§‘å­¦å’ŒåŒ»å­¦é—®ç­”ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå¦‚æ€ç»´é“¾(CoT)ã€‚æ­¤å¤–ï¼ŒCRæ–¹æ³•è¿˜è¶…è¿‡äº†DeepSeek-R1é£æ ¼æ¨ç†(SR)çš„èƒ½åŠ›ï¼ŒåŒæ—¶è¡¨ç°å‡ºå“è¶Šçš„æ ·æœ¬æ•ˆç‡å’Œè¶³å¤Ÿçš„tokenä½¿ç”¨é‡ã€‚CRæ–¹æ³•èƒ½å¤Ÿè‡ªé€‚åº”åœ°å¼ºè°ƒç‰¹å®šé¢†åŸŸé€‚å½“çš„æ¨ç†é£æ ¼ï¼Œä¾‹å¦‚ä¼˜å…ˆè€ƒè™‘æº¯å› å’Œæ¼”ç»æ¨ç†ç”¨äºåŒ»å­¦é—®ç­”ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤æ‚æ¨ç†çš„é¢†åŸŸï¼Œä¾‹å¦‚åŒ»ç–—è¯Šæ–­ã€ç§‘å­¦ç ”ç©¶ã€æ³•å¾‹å’¨è¯¢ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å°‘æ•°æ®ä¸‹çš„é—®é¢˜æ±‚è§£èƒ½åŠ›ï¼Œå¯ä»¥é™ä½æ¨¡å‹è®­ç»ƒæˆæœ¬ï¼Œå¹¶ä½¿å…¶æ›´å®¹æ˜“éƒ¨ç½²åˆ°èµ„æºå—é™çš„ç¯å¢ƒä¸­ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs), despite their remarkable capabilities, rely on singular, pre-dominant reasoning paradigms, hindering their performance on intricate problems that demand diverse cognitive strategies. To address this, we introduce Composite Reasoning (CR), a novel reasoning approach empowering LLMs to dynamically explore and combine multiple reasoning styles like deductive, inductive, and abductive for more nuanced problem-solving. Evaluated on scientific and medical question-answering benchmarks, our approach outperforms existing baselines like Chain-of-Thought (CoT) and also surpasses the accuracy of DeepSeek-R1 style reasoning (SR) capabilities, while demonstrating superior sample efficiency and adequate token usage. Notably, CR adaptively emphasizes domain-appropriate reasoning styles. It prioritizes abductive and deductive reasoning for medical question answering, but shifts to causal, deductive, and inductive methods for scientific reasoning. Our findings highlight that by cultivating internal reasoning style diversity, LLMs acquire more robust, adaptive, and efficient problem-solving abilities.

