---
layout: default
title: Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference
---

# Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21791" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21791v2</a>
  <a href="https://arxiv.org/pdf/2509.21791.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21791v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21791v2', 'Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Han Yuan, Yue Zhao, Li Zhang, Wuqiong Luo, Zheng Ma

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-12-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å› æœæ¨æ–­åˆ†æç»“æ„åŒ–è¾“å‡ºæ ¼å¼å¯¹å¤§è¯­è¨€æ¨¡å‹çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç»“æ„åŒ–è¾“å‡º` `å› æœæ¨æ–­` `æ¨¡å‹è¯„ä¼°` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹ç»“æ„åŒ–è¾“å‡ºå¯¹LLMçš„å½±å“å­˜åœ¨ç‰‡é¢æ€§ï¼Œç¼ºä¹ä¸¥æ ¼æ§åˆ¶çš„å®éªŒç¯å¢ƒå’Œç»†ç²’åº¦çš„è¯„ä¼°æŒ‡æ ‡ã€‚
2. æœ¬ç ”ç©¶åˆ©ç”¨å› æœæ¨æ–­ï¼Œæ„å»ºäº†äº”ç§æ½œåœ¨çš„å› æœç»“æ„ï¼Œä»¥æ›´å‡†ç¡®åœ°åˆ†æç»“æ„åŒ–è¾“å‡ºå¯¹LLMç”Ÿæˆçš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç²—ç•¥æŒ‡æ ‡å¯èƒ½äº§ç”Ÿè¯¯å¯¼ï¼Œå› æœæ¨æ–­æ­ç¤ºäº†ç»“æ„åŒ–è¾“å‡ºåœ¨å¤šæ•°æƒ…å†µä¸‹å¯¹GPT-4oæ²¡æœ‰æ˜¾è‘—çš„å› æœå½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¥è‡ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç»“æ„åŒ–è¾“å‡ºæé«˜äº†å¤„ç†ç”Ÿæˆä¿¡æ¯çš„æ•ˆç‡ï¼Œå¹¶è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºå·¥ä¸šé¢†åŸŸã€‚å…ˆå‰çš„ç ”ç©¶è°ƒæŸ¥äº†ç»“æ„åŒ–è¾“å‡ºå¯¹LLMç”Ÿæˆè´¨é‡çš„å½±å“ï¼Œä½†å¾€å¾€å‘ˆç°å‡ºå•æ–¹é¢çš„ç»“æœã€‚ä¸€äº›ç ”ç©¶è¡¨æ˜ï¼Œç»“æ„åŒ–æ ¼å¼å¢å¼ºäº†å®Œæ•´æ€§å’Œäº‹å®å‡†ç¡®æ€§ï¼Œè€Œå¦ä¸€äº›ç ”ç©¶åˆ™è®¤ä¸ºå®ƒé™åˆ¶äº†LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶å¯¼è‡´æ ‡å‡†è¯„ä¼°æŒ‡æ ‡çš„ä¸‹é™ã€‚è¿™äº›è¯„ä¼°çš„æ½œåœ¨å±€é™æ€§åŒ…æ‹¬å—é™çš„æµ‹è¯•åœºæ™¯ã€å¼±æ§åˆ¶çš„æ¯”è¾ƒè®¾ç½®ä»¥åŠå¯¹ç²—ç•¥æŒ‡æ ‡çš„ä¾èµ–ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨å› æœæ¨æ–­æå‡ºäº†ä¸€ç§æ”¹è¿›çš„åˆ†ææ–¹æ³•ã€‚åŸºäºä¸€ä¸ªå‡è®¾å’Œä¸¤ä¸ªä¿è¯çš„çº¦æŸï¼Œæˆ‘ä»¬æ¨å¯¼å‡ºäº†äº”ä¸ªæ½œåœ¨çš„å› æœç»“æ„ï¼Œè¿™äº›ç»“æ„æè¿°äº†ç»“æ„åŒ–è¾“å‡ºå¯¹LLMç”Ÿæˆçš„å½±å“ï¼šï¼ˆ1ï¼‰æ— m-åå€šçš„ç¢°æ’å™¨ï¼Œï¼ˆ2ï¼‰æœ‰m-åå€šçš„ç¢°æ’å™¨ï¼Œï¼ˆ3ï¼‰æ¥è‡ªæŒ‡ä»¤çš„å•ä¸€åŸå› ï¼Œï¼ˆ4ï¼‰æ¥è‡ªè¾“å‡ºæ ¼å¼çš„å•ä¸€åŸå› ï¼Œä»¥åŠï¼ˆ5ï¼‰ç‹¬ç«‹æ€§ã€‚åœ¨ä¸ƒä¸ªå…¬å…±æ¨ç†ä»»åŠ¡å’Œä¸€ä¸ªå¼€å‘çš„æ¨ç†ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å‘ç°ç²—ç•¥æŒ‡æ ‡æŠ¥å‘Šäº†ç»“æ„åŒ–è¾“å‡ºå¯¹GPT-4oç”Ÿæˆçš„ç§¯æã€æ¶ˆææˆ–ä¸­æ€§å½±å“ã€‚ç„¶è€Œï¼Œå› æœæ¨æ–­æ˜¾ç¤ºåœ¨48ä¸ªåœºæ™¯ä¸­çš„43ä¸ªåœºæ™¯ä¸­æ²¡æœ‰å› æœå½±å“ã€‚åœ¨å‰©ä¸‹çš„5ä¸ªåœºæ™¯ä¸­ï¼Œæœ‰3ä¸ªæ¶‰åŠå—å…·ä½“æŒ‡ä»¤å½±å“çš„å¤šæ–¹é¢å› æœç»“æ„ã€‚è¿›ä¸€æ­¥çš„å®éªŒè¡¨æ˜ï¼ŒOpenAI-o3æ¯”é€šç”¨GPT-4oå’ŒGPT-4.1æ›´èƒ½æŠµæŠ—è¾“å‡ºæ ¼å¼çš„å½±å“ï¼Œçªå‡ºäº†æ¨ç†æ¨¡å‹çš„ä¸€ç§æœªè¢«å¯Ÿè§‰çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç ”ç©¶å¯¹äºç»“æ„åŒ–è¾“å‡ºæ ¼å¼å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆè´¨é‡çš„å½±å“å­˜åœ¨äº‰è®®ï¼Œéƒ¨åˆ†ç ”ç©¶è®¤ä¸ºç»“æ„åŒ–è¾“å‡ºæå‡äº†ç”Ÿæˆè´¨é‡ï¼Œè€Œå¦ä¸€äº›ç ”ç©¶åˆ™è®¤ä¸ºå…¶é™åˆ¶äº†LLMçš„æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰ç ”ç©¶çš„ç—›ç‚¹åœ¨äºç¼ºä¹ä¸¥æ ¼çš„å®éªŒæ§åˆ¶å’Œç»†è‡´çš„å› æœåˆ†æï¼Œå®¹æ˜“å¾—å‡ºç‰‡é¢çš„ç»“è®ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å› æœæ¨æ–­æ¥åˆ†æç»“æ„åŒ–è¾“å‡ºå¯¹LLMç”Ÿæˆçš„å½±å“ã€‚é€šè¿‡æ„å»ºä¸åŒçš„å› æœå›¾ï¼Œå¹¶åŸºäºè§‚æµ‹æ•°æ®è¿›è¡Œå› æœæ•ˆåº”ä¼°è®¡ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°ç»“æ„åŒ–è¾“å‡ºçš„çœŸå®å½±å“ã€‚è¿™ç§æ–¹æ³•èƒ½å¤ŸåŒºåˆ†ç›¸å…³æ€§å’Œå› æœå…³ç³»ï¼Œé¿å…ä¼ ç»Ÿè¯„ä¼°æ–¹æ³•ä¸­çš„åå·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1ï¼‰å®šä¹‰æ½œåœ¨çš„å› æœç»“æ„ï¼šåŸºäºä¸€ä¸ªå‡è®¾å’Œä¸¤ä¸ªä¿è¯çš„çº¦æŸï¼Œæ¨å¯¼å‡ºäº”ç§æ½œåœ¨çš„å› æœç»“æ„ï¼Œè¿™äº›ç»“æ„æè¿°äº†ç»“æ„åŒ–è¾“å‡ºå¯¹LLMç”Ÿæˆçš„å½±å“ã€‚2ï¼‰é€‰æ‹©æ¨ç†ä»»åŠ¡å’ŒLLMï¼šé€‰æ‹©äº†ä¸ƒä¸ªå…¬å…±æ¨ç†ä»»åŠ¡å’Œä¸€ä¸ªå¼€å‘çš„æ¨ç†ä»»åŠ¡ï¼Œå¹¶ä½¿ç”¨GPT-4oä½œä¸ºä¸»è¦å®éªŒå¯¹è±¡ã€‚3ï¼‰è¿›è¡Œå®éªŒå¹¶æ”¶é›†æ•°æ®ï¼šåœ¨ä¸åŒçš„ä»»åŠ¡å’Œè¾“å‡ºæ ¼å¼ä¸‹ï¼Œè¿è¡ŒLLMå¹¶æ”¶é›†ç”Ÿæˆç»“æœå’Œè¯„ä¼°æŒ‡æ ‡ã€‚4ï¼‰è¿›è¡Œå› æœæ¨æ–­ï¼šä½¿ç”¨æ”¶é›†åˆ°çš„æ•°æ®ï¼Œå¯¹ä¸åŒçš„å› æœç»“æ„è¿›è¡ŒéªŒè¯ï¼Œå¹¶ä¼°è®¡ç»“æ„åŒ–è¾“å‡ºçš„å› æœæ•ˆåº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å› æœæ¨æ–­å¼•å…¥åˆ°LLMçš„è¯„ä¼°ä¸­ã€‚ä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•å¾€å¾€åªå…³æ³¨ç›¸å…³æ€§ï¼Œè€Œå¿½ç•¥äº†å› æœå…³ç³»ã€‚é€šè¿‡å› æœæ¨æ–­ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°ç»“æ„åŒ–è¾“å‡ºçš„çœŸå®å½±å“ï¼Œé¿å…äº†æ½œåœ¨çš„åå·®ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰å› æœç»“æ„çš„å®šä¹‰ï¼šåŸºäºé¢†åŸŸçŸ¥è¯†å’Œå‡è®¾ï¼Œå®šä¹‰äº†äº”ç§æ½œåœ¨çš„å› æœç»“æ„ï¼Œè¿™äº›ç»“æ„æ¶µç›–äº†ç»“æ„åŒ–è¾“å‡ºå¯èƒ½äº§ç”Ÿçš„å„ç§å½±å“ã€‚2ï¼‰å®éªŒä»»åŠ¡çš„é€‰æ‹©ï¼šé€‰æ‹©äº†å…·æœ‰ä»£è¡¨æ€§çš„æ¨ç†ä»»åŠ¡ï¼Œä»¥è¯„ä¼°ç»“æ„åŒ–è¾“å‡ºå¯¹LLMæ¨ç†èƒ½åŠ›çš„å½±å“ã€‚3ï¼‰å› æœæ•ˆåº”çš„ä¼°è®¡æ–¹æ³•ï¼šä½¿ç”¨äº†åˆé€‚çš„å› æœæ¨æ–­æ–¹æ³•ï¼Œä¾‹å¦‚å€¾å‘å¾—åˆ†åŒ¹é…æˆ–å·¥å…·å˜é‡æ³•ï¼Œæ¥ä¼°è®¡ç»“æ„åŒ–è¾“å‡ºçš„å› æœæ•ˆåº”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼Œä½¿ç”¨ç²—ç•¥æŒ‡æ ‡è¯„ä¼°ç»“æ„åŒ–è¾“å‡ºå¯¹GPT-4oçš„å½±å“æ—¶ï¼Œç»“æœå¯èƒ½å‘ˆç°ç§¯æã€æ¶ˆææˆ–ä¸­æ€§ã€‚ä½†é€šè¿‡å› æœæ¨æ–­åˆ†æï¼Œåœ¨48ä¸ªåœºæ™¯ä¸­çš„43ä¸ªåœºæ™¯ä¸­ï¼Œç»“æ„åŒ–è¾“å‡ºå¹¶æ²¡æœ‰æ˜¾è‘—çš„å› æœå½±å“ã€‚OpenAI-o3æ¯”é€šç”¨GPT-4oå’ŒGPT-4.1æ›´èƒ½æŠµæŠ—è¾“å‡ºæ ¼å¼çš„å½±å“ï¼Œè¡¨æ˜å…¶åœ¨æ¨ç†èƒ½åŠ›æ–¹é¢å…·æœ‰ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤§è¯­è¨€æ¨¡å‹çš„è¯„ä¼°å’Œä¼˜åŒ–ï¼Œå¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£ç»“æ„åŒ–è¾“å‡ºå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œä»è€Œè®¾è®¡æ›´æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹ç­–ç•¥å’Œæ¨¡å‹è®­ç»ƒæ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¹Ÿå¯æ¨å¹¿åˆ°å…¶ä»–LLMåº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚ä¿¡æ¯æŠ½å–ã€æ–‡æœ¬æ‘˜è¦ç­‰ï¼Œæå‡LLMåœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Structured output from large language models (LLMs) has enhanced efficiency in processing generated information and is increasingly adopted in industrial applications. Prior studies have investigated the impact of structured output on LLMs' generation quality, often presenting one-way findings. Some suggest that structured format enhances completeness and factual accuracy, while others argue that it restricts the reasoning capacity of LLMs and leads to reductions in standard evaluation metrics. Potential limitations of these assessments include restricted testing scenarios, weakly controlled comparative settings, and reliance on coarse metrics. In this work, we present a refined analysis using causal inference. Based on one assumed and two guaranteed constraints, we derive five potential causal structures characterizing the influence of structured output on LLMs' generation: (1) collider without m-bias, (2) collider with m-bias, (3) single cause from instruction, (4) single cause from output format, and (5) independence. Across seven public and one developed reasoning tasks, we find that coarse metrics report positive, negative, or neutral effects of structured output on GPT-4o's generation. However, causal inference reveals no causal impact in 43 out of 48 scenarios. In the remaining 5, 3 involve multifaceted causal structures influenced by concrete instructions. Further experiments show that OpenAI-o3 are more resilient to output formats than general-purpose GPT-4o and GPT-4.1, highlighting an unaware advantage of reasoning models.

