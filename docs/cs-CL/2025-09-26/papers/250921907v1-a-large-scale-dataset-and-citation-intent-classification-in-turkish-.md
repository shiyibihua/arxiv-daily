---
layout: default
title: A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs
---

# A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21907" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21907v1</a>
  <a href="https://arxiv.org/pdf/2509.21907.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21907v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21907v1', 'A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kemal Sami Karaca, Bahaeddin EravcÄ±

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: Submitted to IEEE UBMK 2025 International Conference on Computer Science and Engineering

**æœŸåˆŠ**: In Proceedings of the 10th International Conference on Computer Science and Engineering (UBMK) 1 (2025) 509-514

**DOI**: [10.1109/UBMK67458.2025.11207038](https://doi.org/10.1109/UBMK67458.2025.11207038)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾åˆ†ç±»æ•°æ®é›†ä¸æ¡†æ¶ï¼Œåˆ©ç”¨LLMå’ŒDSPyå®ç°91.3%çš„å‡†ç¡®ç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åœŸè€³å…¶è¯­NLP` `å¼•æ–‡æ„å›¾åˆ†ç±»` `å¤§å‹è¯­è¨€æ¨¡å‹` `DSPyæ¡†æ¶` `å †å æ³›åŒ–` `XGBoost` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾åˆ†ç±»ä»»åŠ¡é¢ä¸´ç²˜ç€è¯­çš„ç‹¬ç‰¹æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æ•°æ®é›†å’Œå¯é çš„åˆ†ç±»æ¡†æ¶ã€‚
2. è®ºæ–‡æå‡ºåŸºäºDSPyæ¡†æ¶çš„å¯ç¼–ç¨‹åˆ†ç±»ç®¡é“ï¼Œè‡ªåŠ¨ä¼˜åŒ–LLMæç¤ºï¼Œå¹¶é‡‡ç”¨å †å æ³›åŒ–é›†æˆæé«˜é¢„æµ‹çš„ç¨³å®šæ€§å’Œå‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾åˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†91.3%çš„å‡†ç¡®ç‡ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£å¼•æ–‡çš„å®šæ€§æ„å›¾å¯¹äºå…¨é¢è¯„ä¼°å­¦æœ¯ç ”ç©¶è‡³å…³é‡è¦ï¼Œä½†å¯¹äºåƒåœŸè€³å…¶è¯­è¿™æ ·çš„ç²˜ç€è¯­æ¥è¯´ï¼Œè¿™é¡¹ä»»åŠ¡å…·æœ‰ç‹¬ç‰¹çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç³»ç»Ÿçš„æ–¹æ³•å’Œä¸€ä¸ªåŸºç¡€æ•°æ®é›†æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„ã€å…¬å¼€å¯ç”¨çš„åœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†æ˜¯ä½¿ç”¨ä¸“é—¨æ„å»ºçš„æ³¨é‡Šå·¥å…·åˆ›å»ºçš„ã€‚ç„¶åï¼Œæˆ‘ä»¬è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ ‡å‡†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰çš„æ€§èƒ½ï¼Œç»“æœè¡¨æ˜ï¼Œå…¶æœ‰æ•ˆæ€§å—åˆ°æ‰‹åŠ¨è®¾è®¡çš„æç¤ºå¯¼è‡´çš„ä¸ä¸€è‡´ç»“æœçš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªæ ¸å¿ƒé™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŸºäºDSPyæ¡†æ¶çš„å¯ç¼–ç¨‹åˆ†ç±»ç®¡é“ï¼Œè¯¥ç®¡é“å¯ä»¥ç³»ç»Ÿåœ°è‡ªåŠ¨ä¼˜åŒ–æç¤ºã€‚å¯¹äºæœ€ç»ˆåˆ†ç±»ï¼Œæˆ‘ä»¬é‡‡ç”¨å †å æ³›åŒ–é›†æˆæ¥èšåˆæ¥è‡ªå¤šä¸ªä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºï¼Œä»è€Œç¡®ä¿ç¨³å®šå’Œå¯é çš„é¢„æµ‹ã€‚è¯¥é›†æˆä½¿ç”¨XGBoostå…ƒæ¨¡å‹ï¼Œå®ç°äº†91.3%çš„æœ€å…ˆè¿›çš„å‡†ç¡®ç‡ã€‚æœ€ç»ˆï¼Œè¿™é¡¹ç ”ç©¶ä¸ºåœŸè€³å…¶è¯­NLPç¤¾åŒºå’Œæ›´å¹¿æ³›çš„å­¦æœ¯ç•Œæä¾›äº†ä¸€ä¸ªåŸºç¡€æ•°æ®é›†å’Œä¸€ä¸ªå¼ºå¤§çš„åˆ†ç±»æ¡†æ¶ï¼Œä¸ºæœªæ¥çš„å®šæ€§å¼•æ–‡ç ”ç©¶é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾åˆ†ç±»é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åœŸè€³å…¶è¯­è¿™ç§ç²˜ç€è¯­æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œç¼ºä¹é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®é›†ï¼Œå¹¶ä¸”ç›´æ¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ—¶ï¼Œç”±äºæ‰‹åŠ¨è®¾è®¡çš„æç¤ºä¸ç¨³å®šï¼Œå¯¼è‡´ç»“æœä¸ä¸€è‡´ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´ç³»ç»Ÿã€æ›´å¯é çš„åˆ†ç±»æ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨DSPyæ¡†æ¶è‡ªåŠ¨ä¼˜åŒ–LLMçš„æç¤ºï¼Œå¹¶é‡‡ç”¨å †å æ³›åŒ–é›†æˆæ–¹æ³•ï¼Œå°†å¤šä¸ªä¼˜åŒ–åçš„æ¨¡å‹è¿›è¡Œç»„åˆï¼Œä»è€Œæé«˜åˆ†ç±»çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚é€šè¿‡è‡ªåŠ¨åŒ–æç¤ºä¼˜åŒ–ï¼Œé¿å…äº†æ‰‹åŠ¨è®¾è®¡æç¤ºçš„ä¸ç¡®å®šæ€§ï¼Œå¹¶é€šè¿‡é›†æˆå­¦ä¹ å‡å°‘äº†å•ä¸ªæ¨¡å‹çš„è¯¯å·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ•°æ®é›†æ„å»ºï¼šä½¿ç”¨ä¸“é—¨çš„æ ‡æ³¨å·¥å…·åˆ›å»ºåœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾æ•°æ®é›†ã€‚2) åŸºäºDSPyçš„æç¤ºä¼˜åŒ–ï¼šä½¿ç”¨DSPyæ¡†æ¶è‡ªåŠ¨æœç´¢å’Œä¼˜åŒ–LLMçš„æç¤ºï¼Œä»¥æé«˜åˆ†ç±»æ€§èƒ½ã€‚3) æ¨¡å‹é›†æˆï¼šé‡‡ç”¨å †å æ³›åŒ–é›†æˆæ–¹æ³•ï¼Œå°†å¤šä¸ªä¼˜åŒ–åçš„LLMæ¨¡å‹è¿›è¡Œç»„åˆã€‚4) å…ƒæ¨¡å‹è®­ç»ƒï¼šä½¿ç”¨XGBoostä½œä¸ºå…ƒæ¨¡å‹ï¼Œå­¦ä¹ å¦‚ä½•æœ€ä½³åœ°ç»„åˆå„ä¸ªLLMæ¨¡å‹çš„è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨DSPyæ¡†æ¶è¿›è¡Œè‡ªåŠ¨æç¤ºä¼˜åŒ–ï¼Œä»¥åŠé‡‡ç”¨å †å æ³›åŒ–é›†æˆæ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„æ‰‹åŠ¨è®¾è®¡æç¤ºç›¸æ¯”ï¼ŒDSPyå¯ä»¥ç³»ç»Ÿåœ°æœç´¢å’Œä¼˜åŒ–æç¤ºï¼Œä»è€Œæé«˜LLMçš„æ€§èƒ½ã€‚å †å æ³›åŒ–é›†æˆåˆ™å¯ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¤šä¸ªæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæé«˜åˆ†ç±»çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DSPyæ¡†æ¶ä¸­ï¼Œè®ºæ–‡å¯èƒ½ä½¿ç”¨äº†ç‰¹å®šçš„ä¼˜åŒ–ç›®æ ‡å’Œæœç´¢ç­–ç•¥æ¥å¯»æ‰¾æœ€ä½³æç¤ºã€‚åœ¨å †å æ³›åŒ–é›†æˆä¸­ï¼ŒXGBoostå…ƒæ¨¡å‹çš„é€‰æ‹©å¯èƒ½åŸºäºå…¶åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„è‰¯å¥½è¡¨ç°ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚å¯èƒ½åœ¨è®ºæ–‡æ­£æ–‡ä¸­è¯¦ç»†æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæåŠã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡ç»“åˆDSPyæ¡†æ¶å’Œå †å æ³›åŒ–é›†æˆï¼Œåœ¨åœŸè€³å…¶è¯­å¼•æ–‡æ„å›¾åˆ†ç±»ä»»åŠ¡ä¸Šå–å¾—äº†91.3%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç›´æ¥ä½¿ç”¨LLMè¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ çš„æ–¹æ³•ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œè‡ªåŠ¨æç¤ºä¼˜åŒ–å’Œæ¨¡å‹é›†æˆå¯ä»¥æœ‰æ•ˆæé«˜LLMåœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå­¦æœ¯æ–‡çŒ®åˆ†æã€å¼•æ–‡ç½‘ç»œæ„å»ºã€ç§‘ç ”æˆæœè¯„ä¼°ç­‰é¢†åŸŸã€‚é€šè¿‡å‡†ç¡®è¯†åˆ«å¼•æ–‡æ„å›¾ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°ç†è§£å­¦æœ¯ç ”ç©¶ä¹‹é—´çš„å…³ç³»ï¼Œä¸ºç§‘ç ”äººå‘˜æä¾›æ›´æœ‰æ•ˆçš„æ–‡çŒ®æ£€ç´¢å’Œåˆ†æå·¥å…·ï¼Œå¹¶ä¸ºå­¦æœ¯è¯„ä»·æä¾›æ›´å…¨é¢çš„ä¾æ®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding the qualitative intent of citations is essential for a comprehensive assessment of academic research, a task that poses unique challenges for agglutinative languages like Turkish. This paper introduces a systematic methodology and a foundational dataset to address this problem. We first present a new, publicly available dataset of Turkish citation intents, created with a purpose-built annotation tool. We then evaluate the performance of standard In-Context Learning (ICL) with Large Language Models (LLMs), demonstrating that its effectiveness is limited by inconsistent results caused by manually designed prompts. To address this core limitation, we introduce a programmable classification pipeline built on the DSPy framework, which automates prompt optimization systematically. For final classification, we employ a stacked generalization ensemble to aggregate outputs from multiple optimized models, ensuring stable and reliable predictions. This ensemble, with an XGBoost meta-model, achieves a state-of-the-art accuracy of 91.3\%. Ultimately, this study provides the Turkish NLP community and the broader academic circles with a foundational dataset and a robust classification framework paving the way for future qualitative citation studies.

