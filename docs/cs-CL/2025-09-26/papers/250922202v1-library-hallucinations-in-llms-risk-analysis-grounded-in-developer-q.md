---
layout: default
title: Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries
---

# Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22202" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22202v1</a>
  <a href="https://arxiv.org/pdf/2509.22202.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22202v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22202v1', 'Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lukas Twist, Jie M. Zhang, Mark Harman, Helen Yannakoudakis

**åˆ†ç±»**: cs.SE, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: 23 pages, 5 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç³»ç»Ÿæ€§åˆ†æå¼€å‘è€…æŸ¥è¯¢å¯¹LLMä»£ç åº“å¹»è§‰çš„å½±å“ï¼Œæ­ç¤ºæ½œåœ¨å®‰å…¨é£é™©ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç ç”Ÿæˆ` `åº“å¹»è§‰` `æç¤ºå·¥ç¨‹` `å®‰å…¨é£é™©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨ä»£ç ç”Ÿæˆä¸­å­˜åœ¨åº“å¹»è§‰é—®é¢˜ï¼Œå¯èƒ½å¯¼è‡´å®‰å…¨é£é™©ï¼Œä½†ç¼ºä¹å¯¹ç”¨æˆ·æç¤ºå˜åŒ–å½±å“çš„ç³»ç»Ÿç ”ç©¶ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡åˆ†æçœŸå®å¼€å‘è€…æŸ¥è¯¢å’Œé”™è¯¯æç¤ºï¼Œè¯„ä¼°ä¸åŒLLMåœ¨åº“åå’Œæˆå‘˜å¹»è§‰æ–¹é¢çš„è¡¨ç°ã€‚
3. å®éªŒæ­ç¤ºLLMå¯¹ç»†å¾®æç¤ºå˜åŒ–çš„è„†å¼±æ€§ï¼Œå¼ºè°ƒäº†æç¤ºå·¥ç¨‹åœ¨ç¼“è§£å¹»è§‰æ–¹é¢çš„å±€é™æ€§ï¼Œå¹¶å‘¼ååŠ å¼ºå®‰å…¨é˜²æŠ¤ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°ç”¨äºç”Ÿæˆä»£ç ï¼Œä½†å®ƒä»¬ä»ç„¶å­˜åœ¨å¹»è§‰é—®é¢˜ï¼Œç»å¸¸ä¼šè™šæ„ä¸å­˜åœ¨çš„åº“ã€‚è¿™ç§åº“å¹»è§‰ä¸ä»…ä»…æ˜¯æ— å®³çš„é”™è¯¯ï¼Œå®ƒä»¬å¯èƒ½ä¼šè¯¯å¯¼å¼€å‘è€…ï¼Œç ´åæ„å»ºè¿‡ç¨‹ï¼Œå¹¶å°†ç³»ç»Ÿæš´éœ²äºä¾›åº”é“¾å¨èƒï¼Œä¾‹å¦‚åŸŸåæŠ¢æ³¨ã€‚å°½ç®¡äººä»¬è¶Šæ¥è¶Šæ„è¯†åˆ°è¿™äº›é£é™©ï¼Œä½†å¯¹äºçœŸå®ä¸–ç•Œçš„æç¤ºå˜åŒ–å¦‚ä½•å½±å“å¹»è§‰ç‡çŸ¥ä¹‹ç”šå°‘ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¦–æ¬¡ç³»ç»Ÿåœ°ç ”ç©¶äº†ç”¨æˆ·çº§åˆ«çš„æç¤ºå˜åŒ–å¦‚ä½•å½±å“LLMç”Ÿæˆçš„ä»£ç ä¸­çš„åº“å¹»è§‰ã€‚æˆ‘ä»¬è¯„ä¼°äº†å…­ä¸ªä¸åŒçš„LLMï¼Œæ¶µç›–ä¸¤ç§å¹»è§‰ç±»å‹ï¼šåº“åå¹»è§‰ï¼ˆæ— æ•ˆå¯¼å…¥ï¼‰å’Œåº“æˆå‘˜å¹»è§‰ï¼ˆæ¥è‡ªæœ‰æ•ˆåº“çš„æ— æ•ˆè°ƒç”¨ï¼‰ã€‚æˆ‘ä»¬è°ƒæŸ¥äº†ä»å¼€å‘è€…è®ºå›ä¸­æå–çš„çœŸå®ç”¨æˆ·è¯­è¨€ï¼Œä»¥åŠä¸åŒç¨‹åº¦çš„ç”¨æˆ·é”™è¯¯ï¼ˆå•å­—ç¬¦æˆ–å¤šå­—ç¬¦æ‹¼å†™é”™è¯¯ä»¥åŠå®Œå…¨è™šæ„çš„åç§°/æˆå‘˜ï¼‰å¦‚ä½•å½±å“LLMçš„å¹»è§‰ç‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ­ç¤ºäº†ç³»ç»Ÿæ€§æ¼æ´ï¼šåº“åä¸­çš„å•å­—ç¬¦æ‹¼å†™é”™è¯¯åœ¨é«˜è¾¾26%çš„ä»»åŠ¡ä¸­è§¦å‘å¹»è§‰ï¼Œè™šæ„çš„åº“ååœ¨é«˜è¾¾99%çš„ä»»åŠ¡ä¸­è¢«æ¥å—ï¼Œä¸æ—¶é—´ç›¸å…³çš„æç¤ºåœ¨é«˜è¾¾84%çš„ä»»åŠ¡ä¸­å¯¼è‡´å¹»è§‰ã€‚æç¤ºå·¥ç¨‹æ˜¾ç¤ºäº†ç¼“è§£å¹»è§‰çš„å¸Œæœ›ï¼Œä½†ä»ç„¶ä¸ä¸€è‡´ä¸”ä¾èµ–äºLLMã€‚æˆ‘ä»¬çš„ç»“æœå¼ºè°ƒäº†LLMå¯¹è‡ªç„¶æç¤ºå˜åŒ–çš„è„†å¼±æ€§ï¼Œå¹¶å¼ºè°ƒè¿«åˆ‡éœ€è¦é’ˆå¯¹ä¸åº“ç›¸å…³çš„å¹»è§‰åŠå…¶æ½œåœ¨åˆ©ç”¨é‡‡å–ä¿æŠ¤æªæ–½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°çš„åº“å¹»è§‰é—®é¢˜ï¼Œå³ç”Ÿæˆä¸å­˜åœ¨çš„åº“æˆ–åº“æˆå‘˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹ç”¨æˆ·å®é™…ä½¿ç”¨åœºæ™¯ä¸­å„ç§æç¤ºå˜åŒ–ï¼ˆä¾‹å¦‚æ‹¼å†™é”™è¯¯ã€è™šæ„åç§°ï¼‰å½±å“çš„ç³»ç»Ÿæ€§åˆ†æï¼Œéš¾ä»¥æœ‰æ•ˆè¯„ä¼°å’Œç¼“è§£æ­¤ç±»å¹»è§‰å¸¦æ¥çš„é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¨¡æ‹ŸçœŸå®å¼€å‘è€…åœ¨è®ºå›ä¸­æå‡ºçš„å„ç§æŸ¥è¯¢å’Œé”™è¯¯ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒLLMåœ¨é¢å¯¹è¿™äº›æç¤ºå˜åŒ–æ—¶äº§ç”Ÿåº“å¹»è§‰çš„æ¦‚ç‡ã€‚é€šè¿‡åˆ†æå¹»è§‰äº§ç”Ÿçš„æ¨¡å¼ï¼Œæ­ç¤ºLLMçš„è„†å¼±æ€§ï¼Œå¹¶ä¸ºåç»­çš„å¹»è§‰ç¼“è§£ç­–ç•¥æä¾›ä¾æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä»å¼€å‘è€…è®ºå›æ”¶é›†çœŸå®çš„ç”¨æˆ·æŸ¥è¯¢ï¼›2) æ¨¡æ‹Ÿç”¨æˆ·åœ¨åº“åå’Œåº“æˆå‘˜ä¸Šçš„å„ç§é”™è¯¯ï¼ˆä¾‹å¦‚å•å­—ç¬¦æ‹¼å†™é”™è¯¯ã€å¤šå­—ç¬¦æ‹¼å†™é”™è¯¯ã€å®Œå…¨è™šæ„çš„åç§°ï¼‰ï¼›3) ä½¿ç”¨è¿™äº›å¸¦æœ‰å˜åŒ–çš„æç¤ºï¼Œè¾“å…¥åˆ°ä¸åŒçš„LLMä¸­ç”Ÿæˆä»£ç ï¼›4) åˆ†æç”Ÿæˆçš„ä»£ç ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨åº“å¹»è§‰ï¼ˆæ— æ•ˆçš„åº“å¯¼å…¥æˆ–åº“æˆå‘˜è°ƒç”¨ï¼‰ï¼›5) ç»Ÿè®¡ä¸åŒæç¤ºå˜åŒ–ä¸‹LLMçš„å¹»è§‰ç‡ï¼Œå¹¶è¿›è¡Œå¯¹æ¯”åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†ç”¨æˆ·çº§åˆ«çš„æç¤ºå˜åŒ–å¯¹LLMä»£ç åº“å¹»è§‰çš„å½±å“ï¼›2) ä½¿ç”¨äº†ä»å¼€å‘è€…è®ºå›ä¸­æå–çš„çœŸå®ç”¨æˆ·æŸ¥è¯¢ï¼Œæ›´è´´è¿‘å®é™…åº”ç”¨åœºæ™¯ï¼›3) è¯„ä¼°äº†ä¸åŒç±»å‹çš„ç”¨æˆ·é”™è¯¯ï¼ˆæ‹¼å†™é”™è¯¯ã€è™šæ„åç§°ï¼‰å¯¹å¹»è§‰ç‡çš„å½±å“ï¼Œæ­ç¤ºäº†LLMå¯¹ç»†å¾®å˜åŒ–çš„è„†å¼±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©äº†å…­ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„LLMè¿›è¡Œè¯„ä¼°ï¼›2) åŒºåˆ†äº†åº“åå¹»è§‰å’Œåº“æˆå‘˜å¹»è§‰ä¸¤ç§ç±»å‹ï¼›3) è®¾è®¡äº†å¤šç§ç±»å‹çš„ç”¨æˆ·é”™è¯¯ï¼Œä¾‹å¦‚å•å­—ç¬¦æ‹¼å†™é”™è¯¯ã€å¤šå­—ç¬¦æ‹¼å†™é”™è¯¯ã€å®Œå…¨è™šæ„çš„åç§°ï¼Œä»¥æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼›4) ä½¿ç”¨å¹»è§‰ç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œé‡åŒ–äº†ä¸åŒæç¤ºå˜åŒ–å¯¹LLMçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMå¯¹ç»†å¾®çš„æç¤ºå˜åŒ–éå¸¸æ•æ„Ÿã€‚ä¾‹å¦‚ï¼Œåº“åä¸­ä¸€ä¸ªå­—ç¬¦çš„æ‹¼å†™é”™è¯¯å¯èƒ½å¯¼è‡´é«˜è¾¾26%çš„ä»»åŠ¡ä¸­å‡ºç°å¹»è§‰ã€‚æ›´ä»¤äººæ‹…å¿§çš„æ˜¯ï¼ŒLLMåœ¨é«˜è¾¾99%çš„ä»»åŠ¡ä¸­æ¥å—è™šæ„çš„åº“åã€‚ä¸æ—¶é—´ç›¸å…³çš„æç¤ºä¹Ÿä¼šå¯¼è‡´é«˜è¾¾84%çš„ä»»åŠ¡ä¸­å‡ºç°å¹»è§‰ã€‚è¿™äº›ç»“æœçªæ˜¾äº†LLMåœ¨ä»£ç ç”Ÿæˆæ–¹é¢å­˜åœ¨çš„å®‰å…¨éšæ‚£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡ä»£ç ç”Ÿæˆå·¥å…·çš„å®‰å…¨æ€§ï¼Œé™ä½å› åº“å¹»è§‰å¯¼è‡´çš„å®‰å…¨é£é™©ã€‚å¼€å‘è€…å¯ä»¥åˆ©ç”¨ç ”ç©¶ç»“æœï¼Œè®¾è®¡æ›´æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹ç­–ç•¥ï¼Œå‡å°‘LLMç”Ÿæˆé”™è¯¯ä»£ç çš„å¯èƒ½æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºLLMçš„å¼€å‘è€…æä¾›äº†æ”¹è¿›æ–¹å‘ï¼Œä¾‹å¦‚å¢å¼ºæ¨¡å‹å¯¹æ‹¼å†™é”™è¯¯çš„é²æ£’æ€§ï¼Œæé«˜å¯¹è™šæ„åº“çš„è¯†åˆ«èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used to generate code, yet they continue to hallucinate, often inventing non-existent libraries. Such library hallucinations are not just benign errors: they can mislead developers, break builds, and expose systems to supply chain threats such as slopsquatting. Despite increasing awareness of these risks, little is known about how real-world prompt variations affect hallucination rates. Therefore, we present the first systematic study of how user-level prompt variations impact library hallucinations in LLM-generated code. We evaluate six diverse LLMs across two hallucination types: library name hallucinations (invalid imports) and library member hallucinations (invalid calls from valid libraries). We investigate how realistic user language extracted from developer forums and how user errors of varying degrees (one- or multi-character misspellings and completely fake names/members) affect LLM hallucination rates. Our findings reveal systemic vulnerabilities: one-character misspellings in library names trigger hallucinations in up to 26% of tasks, fake library names are accepted in up to 99% of tasks, and time-related prompts lead to hallucinations in up to 84% of tasks. Prompt engineering shows promise for mitigating hallucinations, but remains inconsistent and LLM-dependent. Our results underscore the fragility of LLMs to natural prompt variation and highlight the urgent need for safeguards against library-related hallucinations and their potential exploitation.

