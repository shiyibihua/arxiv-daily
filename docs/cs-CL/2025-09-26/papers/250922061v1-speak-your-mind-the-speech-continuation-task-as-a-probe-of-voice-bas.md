---
layout: default
title: Speak Your Mind: The Speech Continuation Task as a Probe of Voice-Based Model Bias
---

# Speak Your Mind: The Speech Continuation Task as a Probe of Voice-Based Model Bias

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22061" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22061v1</a>
  <a href="https://arxiv.org/pdf/2509.22061.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22061v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22061v1', 'Speak Your Mind: The Speech Continuation Task as a Probe of Voice-Based Model Bias')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shree Harsha Bokkahalli Satish, Harm Lameris, Olivier Perrotin, Gustav Eje Henter, Ã‰va SzÃ©kely

**åˆ†ç±»**: eess.AS, cs.CL, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: 6 pages, 1 figure, Submitted to IEEE ICASSP 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯­éŸ³å»¶ç»­ä»»åŠ¡ä»¥æ¢æµ‹è¯­éŸ³æ¨¡å‹åè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³å»¶ç»­` `æ¨¡å‹åè§` `æ€§åˆ«å½±å“` `å‘å£°ç±»å‹` `è¯­éŸ³æŠ€æœ¯` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¢æµ‹è¯­éŸ³æ¨¡å‹åè§æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ€§åˆ«å’Œå‘å£°ç±»å‹å¯¹å»¶ç»­è¡Œä¸ºçš„å½±å“æ–¹é¢ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è¯­éŸ³å»¶ç»­ä»»åŠ¡ç³»ç»Ÿæ€§è¯„ä¼°è¯­éŸ³æ¨¡å‹ä¸­çš„åè§ï¼Œåˆ©ç”¨å•ä¸€éŸ³é¢‘æµçš„ç‰¹æ€§è¿›è¡Œæ·±å…¥åˆ†æã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¿è´¯æ€§ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œä½†åœ¨é«˜è¿è´¯æ€§æ¡ä»¶ä¸‹ï¼Œæ€§åˆ«å¯¹æ–‡æœ¬æŒ‡æ ‡å¦‚ä»£ç†æ€§å’Œå¥å­ææ€§äº§ç”Ÿæ˜¾è‘—å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­éŸ³å»¶ç»­ï¼ˆSCï¼‰æ˜¯ç”Ÿæˆä¸è¯­éŸ³æç¤ºä¸€è‡´çš„å»¶ç»­å†…å®¹çš„ä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰ä¸Šä¸‹æ–‡å’Œè¯´è¯è€…èº«ä»½ã€‚ç”±äºSCä»…é™äºå•ä¸€éŸ³é¢‘æµï¼Œå› æ­¤æ¯”å¯¹è¯æ›´ç›´æ¥åœ°æ¢æµ‹è¯­éŸ³åŸºç¡€æ¨¡å‹ä¸­çš„åè§ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿè¯„ä¼°äº†SCä¸­çš„åè§ï¼Œç ”ç©¶äº†æ€§åˆ«å’Œå‘å£°ç±»å‹ï¼ˆå¦‚æ°”å£°ã€å–‰éŸ³ã€å°¾å£°ï¼‰å¯¹å»¶ç»­è¡Œä¸ºçš„å½±å“ã€‚æˆ‘ä»¬è¯„ä¼°äº†ä¸‰ç§è¿‘æœŸæ¨¡å‹ï¼šSpiritLMï¼ˆåŸºç¡€å’Œè¡¨ç°å‹ï¼‰ã€VAE-GSLMå’ŒSpeechGPTï¼Œç»“æœæ˜¾ç¤ºè¯´è¯è€…ç›¸ä¼¼æ€§å’Œè¿è´¯æ€§ä»ç„¶æ˜¯æŒ‘æˆ˜ï¼Œè€Œæ–‡æœ¬è¯„ä¼°æ­ç¤ºäº†æ¨¡å‹å’Œæ€§åˆ«ä¹‹é—´çš„æ˜¾è‘—äº¤äº’ä½œç”¨ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†SCä½œä¸ºæ¢æµ‹è¯­éŸ³åŸºç¡€æ¨¡å‹ä¸­ç¤¾ä¼šç›¸å…³è¡¨ç°åè§çš„æœ‰æ•ˆå·¥å…·ï¼Œå¹¶è¡¨æ˜éšç€å»¶ç»­è´¨é‡çš„æé«˜ï¼Œå®ƒå°†æˆä¸ºè¶Šæ¥è¶Šæœ‰ä»·å€¼çš„è¯Šæ–­å·¥å…·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­éŸ³å»¶ç»­ä»»åŠ¡ä¸­å­˜åœ¨çš„æ¨¡å‹åè§é—®é¢˜ï¼Œå°¤å…¶æ˜¯æ€§åˆ«å’Œå‘å£°ç±»å‹å¯¹å»¶ç»­è¡Œä¸ºçš„å½±å“ã€‚ç°æœ‰æ–¹æ³•åœ¨æ¢æµ‹è¿™äº›åè§æ—¶ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå¯¼è‡´å¯¹æ¨¡å‹çš„ç†è§£ä¸å¤Ÿæ·±å…¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡è¯­éŸ³å»¶ç»­ä»»åŠ¡ä½œä¸ºæ¢æµ‹å·¥å…·ï¼Œç³»ç»Ÿè¯„ä¼°ä¸åŒæ¨¡å‹åœ¨å»¶ç»­è¡Œä¸ºä¸­çš„åè§è¡¨ç°ï¼Œç‰¹åˆ«å…³æ³¨æ€§åˆ«å’Œå‘å£°ç±»å‹çš„å½±å“ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç ”ç©¶èƒ½å¤Ÿåœ¨æ§åˆ¶æ¡ä»¶ä¸‹æ­ç¤ºæ¨¡å‹çš„åè§ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è¯„ä¼°äº†ä¸‰ç§æ¨¡å‹ï¼ˆSpiritLMã€VAE-GSLMå’ŒSpeechGPTï¼‰ï¼Œé€šè¿‡åˆ†æè¯´è¯è€…ç›¸ä¼¼æ€§ã€å£°éŸ³è´¨é‡ä¿æŒå’Œæ–‡æœ¬åè§æŒ‡æ ‡ï¼Œæ„å»ºäº†ä¸€ä¸ªå¤šç»´åº¦çš„è¯„ä¼°æ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†è¯­éŸ³å»¶ç»­ä»»åŠ¡ä½œä¸ºæ¢æµ‹è¯­éŸ³æ¨¡å‹åè§çš„å·¥å…·ï¼Œæ­ç¤ºäº†æ€§åˆ«å’Œå‘å£°ç±»å‹å¯¹æ¨¡å‹è¡Œä¸ºçš„ç³»ç»Ÿæ€§å½±å“ï¼Œè¿™åœ¨ä»¥å¾€çš„ç ”ç©¶ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„è¿è´¯æ€§æ ‡å‡†ï¼Œå¹¶ä½¿ç”¨æ–‡æœ¬æŒ‡æ ‡ï¼ˆå¦‚ä»£ç†æ€§å’Œå¥å­ææ€§ï¼‰è¿›è¡Œè¯„ä¼°ï¼Œç¡®ä¿äº†å¯¹æ¨¡å‹åè§çš„å…¨é¢åˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨é«˜è¿è´¯æ€§æ¡ä»¶ä¸‹ï¼Œæ€§åˆ«å¯¹æ–‡æœ¬æŒ‡æ ‡å¦‚ä»£ç†æ€§å’Œå¥å­ææ€§äº§ç”Ÿæ˜¾è‘—å½±å“ï¼Œå°¤å…¶æ˜¯å¥³æ€§æç¤ºçš„å»¶ç»­æ›´å€¾å‘äºå›å½’åˆ°æ¨¡æ€å‘å£°ã€‚è¿™è¡¨æ˜æ¨¡å‹åœ¨å£°éŸ³è´¨é‡ä¸Šçš„åè§ï¼Œå¼ºè°ƒäº†è¯­éŸ³å»¶ç»­ä»»åŠ¡åœ¨æ¢æµ‹æ¨¡å‹åè§ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯­éŸ³åŠ©æ‰‹ã€è¯­éŸ³è¯†åˆ«ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£è¯­éŸ³æ¨¡å‹ä¸­çš„åè§ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´å…¬å¹³å’ŒåŒ…å®¹çš„è¯­éŸ³æŠ€æœ¯æä¾›æŒ‡å¯¼ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå‡å°‘ç¤¾ä¼šåè§çš„ä¼ æ’­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Speech Continuation (SC) is the task of generating a coherent extension of a spoken prompt while preserving both semantic context and speaker identity. Because SC is constrained to a single audio stream, it offers a more direct setting for probing biases in speech foundation models than dialogue does. In this work we present the first systematic evaluation of bias in SC, investigating how gender and phonation type (breathy, creaky, end-creak) affect continuation behaviour. We evaluate three recent models: SpiritLM (base and expressive), VAE-GSLM, and SpeechGPT across speaker similarity, voice quality preservation, and text-based bias metrics. Results show that while both speaker similarity and coherence remain a challenge, textual evaluations reveal significant model and gender interactions: once coherence is sufficiently high (for VAE-GSLM), gender effects emerge on text-metrics such as agency and sentence polarity. In addition, continuations revert toward modal phonation more strongly for female prompts than for male ones, revealing a systematic voice-quality bias. These findings highlight SC as a controlled probe of socially relevant representational biases in speech foundation models, and suggest that it will become an increasingly informative diagnostic as continuation quality improves.

