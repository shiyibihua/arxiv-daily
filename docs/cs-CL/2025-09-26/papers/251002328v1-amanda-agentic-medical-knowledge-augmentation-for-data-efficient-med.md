---
layout: default
title: AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering
---

# AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02328" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02328v1</a>
  <a href="https://arxiv.org/pdf/2510.02328.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02328v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02328v1', 'AMANDA: Agentic Medical Knowledge Augmentation for Data-Efficient Medical Visual Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziqing Wang, Chengsheng Mao, Xiaole Wen, Yuan Luo, Kaize Ding

**åˆ†ç±»**: cs.CL, cs.AI, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: EMNLP Findings

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/REAL-Lab-NU/AMANDA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAMANDAï¼Œåˆ©ç”¨LLM Agentè¿›è¡ŒåŒ»å­¦çŸ¥è¯†å¢å¼ºï¼Œè§£å†³Med-VQAåœ¨ä½èµ„æºä¸‹çš„æ¨ç†ç“¶é¢ˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦è§†è§‰é—®ç­”` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å¢å¼º` `ä½èµ„æºå­¦ä¹ ` `æ™ºèƒ½Agent` `ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Med-MLLMåœ¨ä½èµ„æºMed-VQAä»»åŠ¡ä¸­ï¼Œé¢ä¸´å†…åœ¨çš„å›¾åƒç»†èŠ‚å¿½ç•¥å’Œå¤–åœ¨çš„åŒ»å­¦çŸ¥è¯†ç¼ºä¹çš„åŒé‡æ¨ç†ç“¶é¢ˆã€‚
2. AMANDAæ¡†æ¶åˆ©ç”¨LLM agentï¼Œé€šè¿‡é—®é¢˜åˆ†è§£å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢ï¼Œå®ç°åŒ»å­¦çŸ¥è¯†çš„æœ‰æ•ˆå¢å¼ºï¼Œæ— éœ€é¢å¤–è®­ç»ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAMANDAåœ¨å¤šä¸ªMed-VQAåŸºå‡†æµ‹è¯•ä¸­ï¼Œé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è®¾ç½®ä¸‹å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒ»å­¦å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹(Med-MLLMs)åœ¨åŒ»å­¦è§†è§‰é—®ç­”(Med-VQA)æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œå½“éƒ¨ç½²åœ¨ç¼ºä¹å……è¶³æ ‡æ³¨æ•°æ®çš„ä½èµ„æºç¯å¢ƒä¸­æ—¶ï¼Œç°æœ‰çš„Med-MLLMsé€šå¸¸ä¼šå› ä¸ºåŒ»å­¦æ¨ç†èƒ½åŠ›çš„ç“¶é¢ˆè€Œå¤±æ•ˆï¼Œè¿™äº›ç“¶é¢ˆåŒ…æ‹¬ï¼š(i)å¿½ç•¥åŒ»å­¦å›¾åƒç»†èŠ‚çš„å†…åœ¨æ¨ç†ç“¶é¢ˆï¼›(ii)æ— æ³•æ•´åˆä¸“ä¸šåŒ»å­¦çŸ¥è¯†çš„å¤–åœ¨æ¨ç†ç“¶é¢ˆã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†AMANDAï¼Œä¸€ä¸ªæ— éœ€è®­ç»ƒçš„agenticæ¡†æ¶ï¼Œé€šè¿‡LLM agentæ‰§è¡ŒåŒ»å­¦çŸ¥è¯†å¢å¼ºã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬çš„å†…åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºä¾§é‡äºç”±ç²—åˆ°ç²¾çš„é—®é¢˜åˆ†è§£ä»¥è¿›è¡Œå…¨é¢è¯Šæ–­ï¼Œè€Œå¤–åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºåˆ™é€šè¿‡ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±æ£€ç´¢æ¥æ”¯æŒæ¨ç†è¿‡ç¨‹ã€‚åœ¨å…«ä¸ªMed-VQAåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬Med-VQAè®¾ç½®ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„åŒ»å­¦è§†è§‰é—®ç­”æ¨¡å‹ï¼ˆMed-VQAï¼‰åœ¨æ•°æ®èµ„æºåŒ®ä¹çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨åŒ»å­¦å›¾åƒä¸­çš„ç»†èŠ‚ä¿¡æ¯ï¼Œå¹¶ä¸”æ— æ³•æœ‰æ•ˆåœ°æ•´åˆå¤–éƒ¨çš„ä¸“ä¸šåŒ»å­¦çŸ¥è¯†ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›å—é™ï¼Œæ— æ³•å‡†ç¡®å›ç­”åŒ»å­¦ç›¸å…³é—®é¢˜ã€‚è¿™äº›é—®é¢˜ä¸¥é‡é˜»ç¢äº†Med-VQAåœ¨å®é™…ä¸´åºŠåœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAMANDAçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºæ™ºèƒ½ä½“ï¼ˆAgentï¼‰ï¼Œé€šè¿‡é—®é¢˜åˆ†è§£å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢æ¥å¢å¼ºæ¨¡å‹çš„åŒ»å­¦çŸ¥è¯†ã€‚é€šè¿‡å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°çš„ã€æ›´æ˜“äºå¤„ç†çš„å­é—®é¢˜ï¼Œå¹¶ç»“åˆå¤–éƒ¨çŸ¥è¯†å›¾è°±æä¾›çš„åŒ»å­¦ä¿¡æ¯ï¼Œæ¨¡å‹å¯ä»¥æ›´å…¨é¢ã€æ›´å‡†ç¡®åœ°ç†è§£é—®é¢˜å¹¶ç»™å‡ºç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•æ— éœ€é¢å¤–çš„è®­ç»ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºç°æœ‰çš„Med-VQAæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAMANDAæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šå†…åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºå’Œå¤–åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºã€‚åœ¨å†…åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºé˜¶æ®µï¼Œæ¨¡å‹é¦–å…ˆå°†åŸå§‹é—®é¢˜åˆ†è§£ä¸ºä¸€ç³»åˆ—ç”±ç²—åˆ°ç²¾çš„å­é—®é¢˜ï¼Œä»¥ä¾¿æ›´å…¨é¢åœ°åˆ†æåŒ»å­¦å›¾åƒã€‚åœ¨å¤–åœ¨åŒ»å­¦çŸ¥è¯†å¢å¼ºé˜¶æ®µï¼Œæ¨¡å‹åˆ©ç”¨ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„åŒ»å­¦çŸ¥è¯†ï¼Œå¹¶å°†è¿™äº›çŸ¥è¯†èå…¥åˆ°æ¨ç†è¿‡ç¨‹ä¸­ã€‚æ•´ä¸ªæ¡†æ¶æ— éœ€è®­ç»ƒï¼Œå¯ä»¥å³æ’å³ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šAMANDAçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨LLM agentè¿›è¡ŒåŒ»å­¦çŸ¥è¯†å¢å¼ºï¼Œè¿™ä¸ä¼ ç»Ÿçš„Med-VQAæ¨¡å‹ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®è¿›è¡Œè®­ç»ƒçš„æ–¹æ³•ä¸åŒã€‚é€šè¿‡é—®é¢˜åˆ†è§£å’ŒçŸ¥è¯†å›¾è°±æ£€ç´¢ï¼ŒAMANDAèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†ï¼Œæé«˜æ¨¡å‹åœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒAMANDAæ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œå¯ä»¥æ–¹ä¾¿åœ°åº”ç”¨äºç°æœ‰çš„Med-VQAæ¨¡å‹ã€‚

**å…³é”®è®¾è®¡**ï¼šAMANDAæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ä½¿ç”¨LLMè¿›è¡Œé—®é¢˜åˆ†è§£ï¼Œå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºæ›´å°çš„å­é—®é¢˜ï¼›(2) åˆ©ç”¨ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±è¿›è¡ŒçŸ¥è¯†æ£€ç´¢ï¼Œè·å–ä¸é—®é¢˜ç›¸å…³çš„åŒ»å­¦ä¿¡æ¯ï¼›(3) å°†æ£€ç´¢åˆ°çš„çŸ¥è¯†èå…¥åˆ°æ¨ç†è¿‡ç¨‹ä¸­ï¼Œæé«˜æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€ä½¿ç”¨çš„LLMå’ŒçŸ¥è¯†å›¾è°±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AMANDAåœ¨å…«ä¸ªMed-VQAåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒAMANDAçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„Med-VQAæ¨¡å‹ã€‚åœ¨å°‘æ ·æœ¬è®¾ç½®ä¸‹ï¼ŒAMANDAçš„æ€§èƒ½ä¹Ÿå¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œè¡¨æ˜å…¶å…·æœ‰å¾ˆå¼ºçš„æ•°æ®æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAMANDAèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³Med-VQAåœ¨ä½èµ„æºç¯å¢ƒä¸‹çš„æ¨ç†ç“¶é¢ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AMANDAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºè¾…åŠ©åŒ»ç”Ÿè¿›è¡Œè¯Šæ–­ã€æä¾›åŒ»å­¦æ•™è‚²å’Œæ‚£è€…å’¨è¯¢ç­‰ã€‚åœ¨åŒ»ç–—èµ„æºåŒ®ä¹çš„åœ°åŒºï¼ŒAMANDAå¯ä»¥ä½œä¸ºä¸€ç§ä½æˆæœ¬ã€é«˜æ•ˆç›Šçš„è§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©åŒ»ç”Ÿåšå‡ºæ›´å‡†ç¡®çš„è¯Šæ–­ã€‚æ­¤å¤–ï¼ŒAMANDAè¿˜å¯ä»¥ç”¨äºå¼€å‘æ™ºèƒ½åŒ»å­¦åŠ©æ‰‹ï¼Œä¸ºæ‚£è€…æä¾›ä¸ªæ€§åŒ–çš„å¥åº·å»ºè®®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Medical Multimodal Large Language Models (Med-MLLMs) have shown great promise in medical visual question answering (Med-VQA). However, when deployed in low-resource settings where abundant labeled data are unavailable, existing Med-MLLMs commonly fail due to their medical reasoning capability bottlenecks: (i) the intrinsic reasoning bottleneck that ignores the details from the medical image; (ii) the extrinsic reasoning bottleneck that fails to incorporate specialized medical knowledge. To address those limitations, we propose AMANDA, a training-free agentic framework that performs medical knowledge augmentation via LLM agents. Specifically, our intrinsic medical knowledge augmentation focuses on coarse-to-fine question decomposition for comprehensive diagnosis, while extrinsic medical knowledge augmentation grounds the reasoning process via biomedical knowledge graph retrieval. Extensive experiments across eight Med-VQA benchmarks demonstrate substantial improvements in both zero-shot and few-shot Med-VQA settings. The code is available at https://github.com/REAL-Lab-NU/AMANDA.

