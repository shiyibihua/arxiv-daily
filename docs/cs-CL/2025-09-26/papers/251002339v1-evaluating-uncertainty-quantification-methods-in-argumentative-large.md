---
layout: default
title: Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models
---

# Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02339" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02339v1</a>
  <a href="https://arxiv.org/pdf/2510.02339.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02339v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02339v1', 'Evaluating Uncertainty Quantification Methods in Argumentative Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kevin Zhou, Adam Dejl, Gabriel Freedman, Lihu Chen, Antonio Rago, Francesca Toni

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: Accepted at EMNLP Findings 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°è®ºè¯å‹å¤§è¯­è¨€æ¨¡å‹ä¸­ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•çš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ç¡®å®šæ€§é‡åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `è®ºè¯å‹LLM` `å¯è§£é‡Šæ€§` `å£°æ˜éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•åœ¨å¤æ‚è®ºè¯åœºæ™¯ä¸‹è¡¨ç°ä¸è¶³ï¼Œå¯é æ€§é¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºåœ¨è®ºè¯å‹å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ä¸‹è¯„ä¼°ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œä»¥éªŒè¯å£°æ˜çš„å¯é æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç®€å•çš„ç›´æ¥æç¤ºæ–¹æ³•åœ¨è®ºè¯å‹å¤§è¯­è¨€æ¨¡å‹ä¸­ä¼˜äºå¤æ‚çš„é‡åŒ–æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸­è¿›è¡Œä¸ç¡®å®šæ€§é‡åŒ–(UQ)çš„ç ”ç©¶å¯¹äºä¿è¯è¿™é¡¹çªç ´æ€§æŠ€æœ¯çš„å¯é æ€§è‡³å…³é‡è¦ã€‚æœ¬æ–‡æ¢è®¨äº†å°†LLM UQæ–¹æ³•é›†æˆåˆ°è®ºè¯å‹LLM(ArgLLM)ä¸­ï¼ŒArgLLMæ˜¯ä¸€ç§åŸºäºè®¡ç®—è®ºè¯è¿›è¡Œå†³ç­–çš„å¯è§£é‡ŠLLMæ¡†æ¶ï¼Œå…¶ä¸­UQèµ·ç€å…³é”®ä½œç”¨ã€‚æˆ‘ä»¬é€šè¿‡å®éªŒè¯„ä¼°äº†ArgLLMåœ¨ä½¿ç”¨ä¸åŒLLM UQæ–¹æ³•æ—¶åœ¨å£°æ˜éªŒè¯ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä»è€Œè¯„ä¼°UQæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œå®éªŒè¿‡ç¨‹æœ¬èº«ä¹Ÿæ˜¯ä¸€ç§è¯„ä¼°UQæ–¹æ³•æœ‰æ•ˆæ€§çš„æ–°æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨å¤æ‚ä¸”å¯èƒ½å­˜åœ¨äº‰è®®çš„é™ˆè¿°æ—¶ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å…¶ç®€å•æ€§ï¼Œç›´æ¥æç¤ºæ˜¯ArgLLMä¸­ä¸€ç§æœ‰æ•ˆçš„UQç­–ç•¥ï¼Œå…¶æ€§èƒ½ä¼˜äºæ›´å¤æ‚çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°ä¸åŒä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUQï¼‰æ–¹æ³•åœ¨è®ºè¯å‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆArgLLMï¼‰ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç°æœ‰çš„UQæ–¹æ³•åœ¨å¤„ç†å¤æ‚å’Œæœ‰äº‰è®®çš„é™ˆè¿°æ—¶ï¼Œå…¶æœ‰æ•ˆæ€§éš¾ä»¥è¯„ä¼°ï¼Œå¹¶ä¸”å¯èƒ½æ— æ³•æä¾›å¯é çš„ä¸ç¡®å®šæ€§ä¼°è®¡ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ–°çš„æ–¹æ³•æ¥è¯„ä¼°UQæ–¹æ³•åœ¨ArgLLMä¸­çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¶‰åŠå¤æ‚è®ºè¯çš„åœºæ™¯ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ä¸åŒçš„LLM UQæ–¹æ³•é›†æˆåˆ°ArgLLMæ¡†æ¶ä¸­ï¼Œå¹¶ä½¿ç”¨å£°æ˜éªŒè¯ä»»åŠ¡æ¥è¯„ä¼°å®ƒä»¬çš„æ€§èƒ½ã€‚é€šè¿‡æ¯”è¾ƒä¸åŒUQæ–¹æ³•åœ¨ArgLLMä¸­çš„è¡¨ç°ï¼Œå¯ä»¥è¯„ä¼°è¿™äº›UQæ–¹æ³•åœ¨å¤„ç†å¤æ‚è®ºè¯æ—¶çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§æ–°çš„å®éªŒç¨‹åºï¼Œç”¨äºè¯„ä¼°UQæ–¹æ³•ï¼Œè¯¥ç¨‹åºç‰¹åˆ«é€‚ç”¨äºæ¶‰åŠå¤æ‚å’Œæœ‰äº‰è®®çš„é™ˆè¿°çš„æƒ…å†µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©ä¸€ç»„LLM UQæ–¹æ³•ï¼›2) å°†è¿™äº›UQæ–¹æ³•é›†æˆåˆ°ArgLLMæ¡†æ¶ä¸­ï¼›3) ä½¿ç”¨å£°æ˜éªŒè¯ä»»åŠ¡æ¥è¯„ä¼°ArgLLMçš„æ€§èƒ½ï¼›4) åˆ†æå®éªŒç»“æœï¼Œä»¥è¯„ä¼°ä¸åŒUQæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚ArgLLMæ¡†æ¶æœ¬èº«åŸºäºè®¡ç®—è®ºè¯ï¼Œå®ƒä½¿ç”¨è®ºè¯ç»“æ„æ¥è¡¨ç¤ºå’Œè¯„ä¼°å£°æ˜çš„å¯é æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥è¯„ä¼°LLM UQæ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºArgLLMæ¡†æ¶å’Œå£°æ˜éªŒè¯ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚ç”¨äºè¯„ä¼°UQæ–¹æ³•åœ¨å¤„ç†å¤æ‚å’Œæœ‰äº‰è®®çš„é™ˆè¿°æ—¶çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å‘ç°ï¼Œå°½ç®¡å…¶ç®€å•æ€§ï¼Œç›´æ¥æç¤ºæ˜¯ä¸€ç§æœ‰æ•ˆçš„UQç­–ç•¥ï¼Œå…¶æ€§èƒ½ä¼˜äºæ›´å¤æ‚çš„æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„LLM UQæ–¹æ³•ã€è®¾è®¡åˆé€‚çš„å£°æ˜éªŒè¯ä»»åŠ¡ã€ä»¥åŠä½¿ç”¨é€‚å½“çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡ArgLLMçš„æ€§èƒ½ã€‚è®ºæ–‡è¿˜ç‰¹åˆ«å…³æ³¨å¦‚ä½•å¤„ç†å¤æ‚å’Œæœ‰äº‰è®®çš„é™ˆè¿°ï¼Œä¾‹å¦‚ä½¿ç”¨è®ºè¯ç»“æ„æ¥è¡¨ç¤ºå’Œè¯„ä¼°è¿™äº›é™ˆè¿°çš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨è®ºè¯å‹å¤§è¯­è¨€æ¨¡å‹ä¸­ï¼Œç®€å•çš„ç›´æ¥æç¤ºæ–¹æ³•åœ¨ä¸ç¡®å®šæ€§é‡åŒ–æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œç”šè‡³ä¼˜äºæ›´å¤æ‚çš„é‡åŒ–æ–¹æ³•ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ä¼ ç»Ÿè§‚å¿µï¼Œè¡¨æ˜åœ¨ç‰¹å®šåœºæ™¯ä¸‹ï¼Œç®€å•çš„æ–¹æ³•å¯èƒ½æ›´æœ‰æ•ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºéœ€è¦é«˜å¯é æ€§å’Œå¯è§£é‡Šæ€§çš„å†³ç­–æ”¯æŒç³»ç»Ÿï¼Œä¾‹å¦‚åŒ»ç–—è¯Šæ–­ã€é‡‘èé£é™©è¯„ä¼°å’Œæ³•å¾‹æ¨ç†ç­‰é¢†åŸŸã€‚é€šè¿‡é‡åŒ–å¤§è¯­è¨€æ¨¡å‹åœ¨è®ºè¯è¿‡ç¨‹ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œå¯ä»¥æé«˜å†³ç­–çš„é€æ˜åº¦å’Œå¯ä¿¡åº¦ï¼Œå¹¶ä¸ºæœªæ¥çš„å¯ä¿¡äººå·¥æ™ºèƒ½ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Research in uncertainty quantification (UQ) for large language models (LLMs) is increasingly important towards guaranteeing the reliability of this groundbreaking technology. We explore the integration of LLM UQ methods in argumentative LLMs (ArgLLMs), an explainable LLM framework for decision-making based on computational argumentation in which UQ plays a critical role. We conduct experiments to evaluate ArgLLMs' performance on claim verification tasks when using different LLM UQ methods, inherently performing an assessment of the UQ methods' effectiveness. Moreover, the experimental procedure itself is a novel way of evaluating the effectiveness of UQ methods, especially when intricate and potentially contentious statements are present. Our results demonstrate that, despite its simplicity, direct prompting is an effective UQ strategy in ArgLLMs, outperforming considerably more complex approaches.

