---
layout: default
title: The Bias is in the Details: An Assessment of Cognitive Bias in LLMs
---

# The Bias is in the Details: An Assessment of Cognitive Bias in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22856" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22856v1</a>
  <a href="https://arxiv.org/pdf/2509.22856.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22856v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22856v1', 'The Bias is in the Details: An Assessment of Cognitive Bias in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: R. Alexander Knipper, Charles S. Knipper, Kaiqi Zhang, Valerie Sims, Clint Bowers, Santu Karmaker

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°LLMè®¤çŸ¥åå·®ï¼šæ­ç¤ºæ¨¡å‹åœ¨å†³ç­–ä¸­å­˜åœ¨çš„ç³»ç»Ÿæ€§åå·®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è®¤çŸ¥åå·®` `å†³ç­–åˆ¶å®š` `è¯„ä¼°æ¡†æ¶` `æç¤ºå·¥ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†³ç­–ä¸­åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†å…¶æ½œåœ¨çš„è®¤çŸ¥åå·®å¯èƒ½å¯¼è‡´å†³ç­–å¤±è¯¯ï¼Œéœ€è¦æ·±å…¥è¯„ä¼°ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§æ–°é¢–çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å¤šé¡¹é€‰æ‹©ä»»åŠ¡å’Œäººå·¥è®¾è®¡çš„åœºæ™¯ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMä¸­çš„å¤šç§è®¤çŸ¥åå·®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMç¡®å®å­˜åœ¨è®¤çŸ¥åå·®ï¼Œä¸”æ¨¡å‹å¤§å°å’Œæç¤ºç»†èŠ‚ä¼šæ˜¾è‘—å½±å“åå·®çš„ç¨‹åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°åµŒå…¥åˆ°ç°å®ä¸–ç•Œçš„å†³ç­–è¿‡ç¨‹ä¸­ï¼Œæ£€éªŒå®ƒä»¬åœ¨å¤šå¤§ç¨‹åº¦ä¸Šè¡¨ç°å‡ºè®¤çŸ¥åå·®è‡³å…³é‡è¦ã€‚è®¤çŸ¥åå·®åœ¨å¿ƒç†å­¦é¢†åŸŸè¢«å¹¿æ³›ç ”ç©¶ï¼Œè¡¨ç°ä¸ºäººç±»åˆ¤æ–­ä¸­å¸¸è§çš„ç³»ç»Ÿæ€§æ‰­æ›²ã€‚æœ¬æ–‡å¯¹45ä¸ªLLMçš„å…«ç§å·²çŸ¥çš„è®¤çŸ¥åå·®è¿›è¡Œäº†å¤§è§„æ¨¡è¯„ä¼°ï¼Œåˆ†æäº†é€šè¿‡æ§åˆ¶æç¤ºå˜åŒ–ç”Ÿæˆçš„è¶…è¿‡280ä¸‡ä¸ªLLMå“åº”ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§åŸºäºå¤šé¡¹é€‰æ‹©ä»»åŠ¡çš„æ–°å‹è¯„ä¼°æ¡†æ¶ï¼Œä¸å¿ƒç†å­¦å®¶åˆä½œï¼Œæ‰‹å·¥ç­–åˆ’äº†ä¸€ä¸ªåŒ…å«220ä¸ªå†³ç­–åœºæ™¯çš„æ•°æ®é›†ï¼Œé’ˆå¯¹åŸºæœ¬çš„è®¤çŸ¥åå·®ï¼Œå¹¶æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ï¼Œç”¨äºä»äººå·¥ç¼–å†™çš„åœºæ™¯æ¨¡æ¿ä¸­ç”Ÿæˆå¤šæ ·åŒ–çš„æç¤ºã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼ŒLLMåœ¨17.8%-57.3%çš„å®ä¾‹ä¸­è¡¨ç°å‡ºä¸åå·®ä¸€è‡´çš„è¡Œä¸ºï¼Œæ¶µç›–äº†ä¸€ç³»åˆ—é’ˆå¯¹é”šå®šæ•ˆåº”ã€å¯å¾—æ€§å¯å‘ã€ç¡®è®¤åå·®ã€æ¡†æ¶æ•ˆåº”ã€è§£é‡Šåå·®ã€è¿‡åº¦å½’å› ã€å‰æ™¯ç†è®ºå’Œä»£è¡¨æ€§åå·®çš„åˆ¤æ–­å’Œå†³ç­–æƒ…å¢ƒã€‚æˆ‘ä»¬å‘ç°æ¨¡å‹å¤§å°å’Œæç¤ºç‰¹å¼‚æ€§å¯¹åå·®æ•æ„Ÿæ€§æœ‰æ˜¾è‘—å½±å“ï¼šè¾ƒå¤§çš„æ¨¡å‹ï¼ˆ>32Bå‚æ•°ï¼‰å¯ä»¥åœ¨39.5%çš„æƒ…å†µä¸‹å‡å°‘åå·®ï¼Œè€Œæ›´é«˜çš„æç¤ºç»†èŠ‚å¯ä»¥å°†å¤§å¤šæ•°åå·®é™ä½é«˜è¾¾14.9%ï¼Œä½†åœ¨ä¸€ç§æƒ…å†µä¸‹ï¼ˆè¿‡åº¦å½’å› ï¼‰åå·®ä¼šåŠ å‰§é«˜è¾¾8.8%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å†³ç­–è¿‡ç¨‹ä¸­è¡¨ç°å‡ºçš„è®¤çŸ¥åå·®ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹ç³»ç»Ÿæ€§çš„è¯„ä¼°æ¡†æ¶ï¼Œéš¾ä»¥å…¨é¢è¡¡é‡LLMåœ¨å„ç§è®¤çŸ¥åå·®ä¸‹çš„è¡¨ç°ï¼Œå¹¶ä¸”ç¼ºä¹è¶³å¤Ÿè§„æ¨¡å’Œå¤šæ ·æ€§çš„æµ‹è¯•æ•°æ®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¯æ§çš„å®éªŒç¯å¢ƒï¼Œé€šè¿‡è®¾è®¡é’ˆå¯¹ç‰¹å®šè®¤çŸ¥åå·®çš„åœºæ™¯å’Œæç¤ºï¼Œè§‚å¯ŸLLMçš„å“åº”æ˜¯å¦è¡¨ç°å‡ºä¸åå·®ä¸€è‡´çš„è¡Œä¸ºã€‚é€šè¿‡å¤§è§„æ¨¡çš„å®éªŒï¼Œé‡åŒ–LLMå¯¹ä¸åŒè®¤çŸ¥åå·®çš„æ•æ„Ÿç¨‹åº¦ï¼Œå¹¶åˆ†ææ¨¡å‹å¤§å°å’Œæç¤ºç»†èŠ‚å¯¹åå·®çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **æ•°æ®é›†æ„å»º**ï¼šä¸å¿ƒç†å­¦å®¶åˆä½œï¼Œæ‰‹å·¥ç­–åˆ’åŒ…å«220ä¸ªå†³ç­–åœºæ™¯çš„æ•°æ®é›†ï¼Œæ¯ä¸ªåœºæ™¯é’ˆå¯¹ä¸€ç§æˆ–å¤šç§è®¤çŸ¥åå·®ã€‚2) **æç¤ºç”Ÿæˆ**ï¼šæå‡ºä¸€ç§å¯æ‰©å±•çš„æ–¹æ³•ï¼Œä»äººå·¥ç¼–å†™çš„åœºæ™¯æ¨¡æ¿ä¸­ç”Ÿæˆå¤šæ ·åŒ–çš„æç¤ºï¼Œä»¥å¢åŠ å®éªŒçš„é²æ£’æ€§ã€‚3) **æ¨¡å‹è¯„ä¼°**ï¼šä½¿ç”¨45ä¸ªLLMï¼Œé’ˆå¯¹æ¯ä¸ªåœºæ™¯ç”Ÿæˆå¤šä¸ªå“åº”ï¼Œå¹¶åˆ†æå“åº”ä¸­æ˜¯å¦å­˜åœ¨ä¸åå·®ä¸€è‡´çš„è¡Œä¸ºã€‚4) **ç»“æœåˆ†æ**ï¼šç»Ÿè®¡LLMåœ¨ä¸åŒè®¤çŸ¥åå·®ä¸‹çš„è¡¨ç°ï¼Œå¹¶åˆ†ææ¨¡å‹å¤§å°å’Œæç¤ºç»†èŠ‚å¯¹åå·®çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªç³»ç»Ÿæ€§çš„è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºé‡åŒ–LLMä¸­çš„è®¤çŸ¥åå·®ã€‚2) æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„è®¤çŸ¥åå·®æ•°æ®é›†ï¼Œæ¶µç›–å¤šç§åå·®ç±»å‹å’Œåœºæ™¯ã€‚3) æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„æç¤ºç”Ÿæˆæ–¹æ³•ï¼Œæé«˜äº†å®éªŒçš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†ä¸­çš„æ¯ä¸ªåœºæ™¯éƒ½è®¾è®¡æˆå¤šé¡¹é€‰æ‹©é¢˜çš„å½¢å¼ï¼Œæ¯ä¸ªé€‰é¡¹å¯¹åº”ä¸€ç§å¯èƒ½çš„å†³ç­–ç»“æœã€‚æç¤ºçš„è®¾è®¡è€ƒè™‘äº†ä¸åŒçš„ç»†èŠ‚ç¨‹åº¦ï¼Œä»¥è¯„ä¼°æç¤ºç»†èŠ‚å¯¹åå·®çš„å½±å“ã€‚å®éªŒä¸­ä½¿ç”¨äº†å¤šç§LLMï¼ŒåŒ…æ‹¬ä¸åŒå¤§å°å’Œæ¶æ„çš„æ¨¡å‹ï¼Œä»¥è¯„ä¼°æ¨¡å‹å¤§å°å¯¹åå·®çš„å½±å“ã€‚å¯¹äºæ¯ä¸ªLLMå’Œæ¯ä¸ªåœºæ™¯ï¼Œç”Ÿæˆå¤šä¸ªå“åº”ï¼Œå¹¶ç»Ÿè®¡ä¸åå·®ä¸€è‡´çš„å“åº”æ¯”ä¾‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨17.8%-57.3%çš„å®ä¾‹ä¸­è¡¨ç°å‡ºä¸åå·®ä¸€è‡´çš„è¡Œä¸ºã€‚è¾ƒå¤§çš„æ¨¡å‹ï¼ˆ>32Bå‚æ•°ï¼‰å¯ä»¥åœ¨39.5%çš„æƒ…å†µä¸‹å‡å°‘åå·®ï¼Œè€Œæ›´é«˜çš„æç¤ºç»†èŠ‚å¯ä»¥å°†å¤§å¤šæ•°åå·®é™ä½é«˜è¾¾14.9%ï¼Œä½†åœ¨è¿‡åº¦å½’å› åå·®ä¸­ï¼Œæç¤ºç»†èŠ‚çš„å¢åŠ åè€Œä¼šåŠ å‰§åå·®é«˜è¾¾8.8%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›LLMåœ¨å†³ç­–æ”¯æŒç³»ç»Ÿã€é£é™©è¯„ä¼°ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚é€šè¿‡è¯†åˆ«å’Œå‡è½»LLMä¸­çš„è®¤çŸ¥åå·®ï¼Œå¯ä»¥æé«˜å†³ç­–çš„å…¬å¹³æ€§ã€å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œé¿å…æ½œåœ¨çš„è´Ÿé¢å½±å“ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•åˆ©ç”¨è¿™äº›å‘ç°æ¥å¼€å‘æ›´é²æ£’ã€æ›´å€¼å¾—ä¿¡èµ–çš„AIç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) are increasingly embedded in real-world decision-making processes, it becomes crucial to examine the extent to which they exhibit cognitive biases. Extensively studied in the field of psychology, cognitive biases appear as systematic distortions commonly observed in human judgments. This paper presents a large-scale evaluation of eight well-established cognitive biases across 45 LLMs, analyzing over 2.8 million LLM responses generated through controlled prompt variations. To achieve this, we introduce a novel evaluation framework based on multiple-choice tasks, hand-curate a dataset of 220 decision scenarios targeting fundamental cognitive biases in collaboration with psychologists, and propose a scalable approach for generating diverse prompts from human-authored scenario templates. Our analysis shows that LLMs exhibit bias-consistent behavior in 17.8-57.3% of instances across a range of judgment and decision-making contexts targeting anchoring, availability, confirmation, framing, interpretation, overattribution, prospect theory, and representativeness biases. We find that both model size and prompt specificity play a significant role on bias susceptibility as follows: larger size (>32B parameters) can reduce bias in 39.5% of cases, while higher prompt detail reduces most biases by up to 14.9%, except in one case (Overattribution), which is exacerbated by up to 8.8%.

