---
layout: default
title: Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking
---

# Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.14824" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.14824v1</a>
  <a href="https://arxiv.org/pdf/2510.14824.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.14824v1" onclick="toggleFavorite(this, '2510.14824v1', 'Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziqi Dai, Xin Zhang, Mingxin Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Wenjie Li, Min Zhang

**åˆ†ç±»**: cs.CL, cs.CV, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-10-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹å¤šæ¨¡æ€LLMé‡æ’åºï¼Œå¯¹æ¯”ç›‘ç£å¾®è°ƒä¸å¯¹æ¯”å­¦ä¹ çš„ä¼˜åŠ£**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ£€ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `é‡æ’åº` `å¯¹æ¯”å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `ä¿¡æ¯æ£€ç´¢` `æƒé‡åˆ†æ` `æ–¹å‘åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºLLMçš„é‡æ’åºæ¨¡å‹è®­ç»ƒæ–¹æ³•é€‰æ‹©å­˜åœ¨äº‰è®®ï¼Œå¯¹æ¯”å­¦ä¹ å’Œç›‘ç£å¾®è°ƒå­°ä¼˜å­°åŠ£å°šä¸æ˜ç¡®ã€‚
2. è®ºæ–‡å°†è®­ç»ƒç›®æ ‡åˆ†è§£ä¸ºæƒé‡å’Œæ–¹å‘ä¸¤ä¸ªç»„æˆéƒ¨åˆ†ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥åˆ†æå¯¹æ¯”å­¦ä¹ å’Œç›‘ç£å¾®è°ƒçš„äº¤äº’ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç›‘ç£å¾®è°ƒåœ¨LLMé‡æ’åºä¸­å…·æœ‰ä¼˜åŠ¿ï¼Œå¹¶åœ¨MRBåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ–°çš„state-of-the-artç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä¿¡æ¯æ£€ç´¢ä¸­ï¼Œé‡æ’åºæ¨¡å‹çš„è®­ç»ƒä¸»è¦é›†ä¸­äºä¸¤ç§ç›®æ ‡ï¼šåº¦é‡å­¦ä¹ ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å¯¹æ¯”æŸå¤±æ¥å¢åŠ ç›¸å…³æŸ¥è¯¢-æ–‡æ¡£å¯¹çš„é¢„æµ‹åˆ†æ•°ï¼‰å’Œåˆ†ç±»ï¼ˆå¯¹ç›¸å…³ä¸ä¸ç›¸å…³çš„äºŒå…ƒæ ‡ç­¾è¿›è¡Œé¢„æµ‹ï¼‰ã€‚å¯¹äºBERTé£æ ¼çš„ç¼–ç å™¨ï¼Œå¤§é‡ç ”ç©¶è¡¨æ˜å¯¹æ¯”å­¦ä¹ ï¼ˆCLï¼‰æ¯”åˆ¤åˆ«å¼ï¼ˆåˆ†ç±»ï¼‰å­¦ä¹ æ›´æœ‰æ•ˆã€‚ç„¶è€Œï¼Œå¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿›è¡Œåˆ†ç±»ï¼Œå³é¢„æµ‹ç›¸å…³ï¼ˆæˆ–ä¸ç›¸å…³ï¼‰å¯¹çš„â€œæ˜¯â€ï¼ˆæˆ–â€œå¦â€ï¼‰tokenï¼Œä¼¼ä¹æ›´æœ‰å‰æ™¯ï¼Œå› ä¸ºå®ƒä¸LLMçš„ç”Ÿæˆç‰¹æ€§éå¸¸å»åˆã€‚è¿™ç§å·®å¼‚æå‡ºäº†ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šå“ªç§ç›®æ ‡æ›´é€‚åˆåŸºäºLLMçš„é‡æ’åºï¼Ÿå…¶å·®å¼‚çš„æ½œåœ¨æœºåˆ¶æ˜¯ä»€ä¹ˆï¼Ÿåœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¯¹CLå’ŒSFTåœ¨é‡æ’åºæ–¹é¢è¿›è¡Œäº†å…¨é¢çš„æ¯”è¾ƒå’Œåˆ†æï¼Œå¹¶å°†é€šç”¨å¤šæ¨¡æ€æ£€ç´¢ï¼ˆUMRï¼‰ä½œä¸ºå®éªŒå¹³å°ã€‚æˆ‘ä»¬é¦–å…ˆå°†ç›®æ ‡åˆ†è§£ä¸ºä¸¤ä¸ªç»„æˆéƒ¨åˆ†ï¼šæƒé‡ï¼ˆæ§åˆ¶æ›´æ–°å¹…åº¦ï¼‰å’Œæ–¹å‘ï¼ˆæŒ‡å¯¼æ¨¡å‹æ›´æ–°ï¼‰ï¼Œç„¶åæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥ç†è§£å®ƒä»¬çš„ç›¸äº’ä½œç”¨ã€‚é€šè¿‡æ¢æµ‹å®éªŒï¼Œæˆ‘ä»¬å‘ç°SFTæä¾›äº†æ¯”CLæ›´å¼ºçš„åŠ æƒæ–¹æ¡ˆï¼Œè€Œé¦–é€‰çš„è¯„åˆ†æ–¹å‘æ²¡æœ‰æ˜æ˜¾çš„èµ¢å®¶ã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¿™äº›ç»“æœè¡¨æ˜SFTåœ¨LLMé‡æ’åºæ–¹é¢å…·æœ‰ä¸€è‡´çš„ä¼˜åŠ¿ã€‚ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯æˆ‘ä»¬çš„å‘ç°ï¼Œæˆ‘ä»¬ä½¿ç”¨SFTè¿›è¡Œäº†å¤§è§„æ¨¡è®­ç»ƒï¼Œå¹¶åœ¨MRBåŸºå‡†æµ‹è¯•ä¸­æå‡ºäº†æ–°çš„æœ€å…ˆè¿›çš„é‡æ’åºå™¨ã€‚æˆ‘ä»¬è¿˜æä¾›äº†å…³äºSFTè®¾ç½®çš„æ¶ˆèç ”ç©¶ï¼Œå¹¶æœŸæœ›æˆ‘ä»¬çš„å‘ç°èƒ½å¤Ÿæœ‰ç›Šäºè¯¥é¢†åŸŸæœªæ¥çš„ç ”ç©¶å’Œåº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è®­ç»ƒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é‡æ’åºæ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¯¹æ¯”å­¦ä¹ ï¼ˆCLï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œåœ¨åº”ç”¨äºLLMæ—¶è¡¨ç°å‡ºå·®å¼‚ã€‚å¯¹äºBERTç±»æ¨¡å‹ï¼ŒCLé€šå¸¸æ›´æœ‰æ•ˆï¼Œä½†å¯¹äºLLMï¼ŒSFTä¼¼ä¹æ›´å…·æ½œåŠ›ã€‚å› æ­¤ï¼Œè®ºæ–‡è¦æ¢ç©¶å“ªç§è®­ç»ƒç›®æ ‡æ›´é€‚åˆLLMé‡æ’åºï¼Œå¹¶è§£é‡Šå…¶å†…åœ¨æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è®­ç»ƒç›®æ ‡åˆ†è§£ä¸ºä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šæƒé‡ï¼ˆweightï¼‰å’Œæ–¹å‘ï¼ˆdirectionï¼‰ã€‚æƒé‡æ§åˆ¶æ¨¡å‹æ›´æ–°çš„å¹…åº¦ï¼Œè€Œæ–¹å‘æŒ‡å¯¼æ¨¡å‹æ›´æ–°çš„æ–¹å‘ã€‚é€šè¿‡åˆ†æCLå’ŒSFTåœ¨è¿™ä¸¤ä¸ªæ–¹é¢çš„å·®å¼‚ï¼Œè®ºæ–‡æ—¨åœ¨ç†è§£å®ƒä»¬åœ¨LLMé‡æ’åºä¸­çš„è¡¨ç°å·®å¼‚ã€‚è¿™ç§åˆ†è§£æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œç”¨äºæ¯”è¾ƒå’Œç†è§£ä¸åŒè®­ç»ƒç›®æ ‡ä¹‹é—´çš„äº¤äº’ä½œç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é‡‡ç”¨é€šç”¨å¤šæ¨¡æ€æ£€ç´¢ï¼ˆUMRï¼‰ä½œä¸ºå®éªŒå¹³å°ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) ä½¿ç”¨CLæˆ–SFTè®­ç»ƒLLMé‡æ’åºæ¨¡å‹ï¼›2) å°†è®­ç»ƒç›®æ ‡åˆ†è§£ä¸ºæƒé‡å’Œæ–¹å‘ï¼›3) é€šè¿‡æ¢æµ‹å®éªŒåˆ†ææƒé‡å’Œæ–¹å‘çš„å½±å“ï¼›4) åœ¨MRBåŸºå‡†æµ‹è¯•ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚è¯¥æ¡†æ¶å…è®¸ç ”ç©¶äººå‘˜æ·±å…¥äº†è§£ä¸åŒè®­ç»ƒç›®æ ‡å¯¹LLMé‡æ’åºçš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†è®­ç»ƒç›®æ ‡åˆ†è§£ä¸ºæƒé‡å’Œæ–¹å‘ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥ç†è§£CLå’ŒSFTçš„äº¤äº’ä½œç”¨ã€‚è¿™ç§åˆ†è§£æ–¹æ³•æä¾›äº†ä¸€ç§æ–°çš„è§†è§’ï¼Œå¯ä»¥æ›´æ·±å…¥åœ°ç†è§£ä¸åŒè®­ç»ƒç›®æ ‡å¯¹LLMé‡æ’åºçš„å½±å“ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸ä»…å…³æ³¨æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜å…³æ³¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å†…åœ¨æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¯¹æ¯”æŸå¤±ï¼ˆCLï¼‰å’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ä½œä¸ºä¸¤ç§ä¸»è¦çš„è®­ç»ƒç›®æ ‡ï¼›2) è®¾è®¡æ¢æµ‹å®éªŒæ¥åˆ†ææƒé‡å’Œæ–¹å‘çš„å½±å“ï¼›3) åœ¨MRBåŸºå‡†æµ‹è¯•ä¸Šè¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒå’Œè¯„ä¼°ï¼›4) å¯¹SFTè®¾ç½®è¿›è¡Œæ¶ˆèç ”ç©¶ï¼Œä»¥è¿›ä¸€æ­¥éªŒè¯ç ”ç©¶ç»“æœã€‚è®ºæ–‡è¿˜ç‰¹åˆ«å…³æ³¨äº†å¦‚ä½•å°†SFTåº”ç”¨äºLLMï¼Œä¾‹å¦‚ï¼Œé€šè¿‡é¢„æµ‹â€œæ˜¯â€æˆ–â€œå¦â€tokenæ¥è¡¨ç¤ºç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨LLMé‡æ’åºæ–¹é¢å…·æœ‰ä¸€è‡´çš„ä¼˜åŠ¿ã€‚é€šè¿‡å¤§è§„æ¨¡è®­ç»ƒï¼Œè®ºæ–‡æå‡ºçš„SFTé‡æ’åºå™¨åœ¨MRBåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ–°çš„state-of-the-artç»“æœã€‚æ¢æµ‹å®éªŒè¡¨æ˜ï¼ŒSFTæä¾›äº†æ¯”å¯¹æ¯”å­¦ä¹ ï¼ˆCLï¼‰æ›´å¼ºçš„åŠ æƒæ–¹æ¡ˆã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥éªŒè¯äº†SFTè®¾ç½®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å¤šæ¨¡æ€ä¿¡æ¯æ£€ç´¢åœºæ™¯ï¼Œä¾‹å¦‚å›¾åƒæœç´¢ã€è§†é¢‘æœç´¢ã€è·¨æ¨¡æ€æ£€ç´¢ç­‰ã€‚é€šè¿‡é€‰æ‹©åˆé€‚çš„è®­ç»ƒç›®æ ‡ï¼Œå¯ä»¥æ˜¾è‘—æé«˜LLMé‡æ’åºæ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºæ¨åŠ¨LLMåœ¨ä¿¡æ¯æ£€ç´¢é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In information retrieval, training reranking models mainly focuses on two types of objectives: metric learning (e.g. contrastive loss to increase the predicted scores on relevant query-document pairs) and classification (binary label prediction of relevance vs. irrelevance). For BERT-style encoders, various studies have shown that contrastive learning (CL) can be more effective than discriminative (classification) learning. However, for large language models (LLMs), classification via supervised fine-tuning (SFT), which predicts ''yes'' (resp. ''no'') token for relevant (resp. irrelevant) pairs, appears more promising as it aligns well with the generative nature of LLMs. This divergence raises a central question: which objective is intrinsically better suited to LLM-based reranking, and what mechanism underlies the difference? In this work, we conduct a comprehensive comparison and analysis between CL and SFT for reranking, taking the universal multimodal retrieval (UMR) as the experimental playground. We first decompose the objectives into two components: weight, which controls the magnitude of those updates, and direction, which guides the model updates, then present a unified framework for understanding their interactions. Through probing experiments, we find that SFT provides a substantially stronger weighting scheme than CL, whereas the preferred scoring direction shows no clear winner. Taken together, these results point to a consistent advantage of SFT over CL for LLM reranking. To further validate our findings, we conduct large-scale training with SFT and present new state-of-the-art rerankers on the MRB benchmark. We also provide ablations on SFT settings and expect our findings to benefit future research and applications in this area.

