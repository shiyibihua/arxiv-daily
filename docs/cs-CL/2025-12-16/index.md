---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.CL - 2025-12-16
---

# cs.CLï¼ˆ2025-12-16ï¼‰

ğŸ“Š å…± **16** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (16 ğŸ”—2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (16 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251214620v1-jmmmu-pro-image-based-japanese-multi-discipline-multimodal-understan.html">JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction</a></td>
  <td>æå‡ºJMMMU-Proæ—¥è¯­å¤šå­¦ç§‘å¤šæ¨¡æ€ç†è§£åŸºå‡†ï¼Œå¹¶æå‡ºVibeåŸºå‡†æ„å»ºæ–¹æ³•ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14620v1" onclick="toggleFavorite(this, '2512.14620v1', 'JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251214427v1-effect-of-document-packing-on-the-latent-multi-hop-reasoning-capabil.html">Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models</a></td>
  <td>ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§è¯­è¨€æ¨¡å‹å¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14427v1" onclick="toggleFavorite(this, '2512.14427v1', 'Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251214554v1-vlegal-bench-cognitively-grounded-benchmark-for-vietnamese-legal-rea.html">VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models</a></td>
  <td>æå‡ºVLegal-Benchï¼Œç”¨äºè¯„ä¼°LLMåœ¨è¶Šå—æ³•å¾‹æ¨ç†ä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14554v1" onclick="toggleFavorite(this, '2512.14554v1', 'VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251214481v1-sasq-static-activation-scaling-for-quantization-aware-training-in-la.html">SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models</a></td>
  <td>SASQï¼šä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹æ¿€æ´»é‡åŒ–çš„é™æ€æ¿€æ´»ç¼©æ”¾é‡åŒ–æ„ŸçŸ¥è®­ç»ƒæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14481v1" onclick="toggleFavorite(this, '2512.14481v1', 'SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251214561v1-agreement-between-large-language-models-and-human-raters-in-essay-sc.html">Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis</a></td>
  <td>ç»¼åˆç ”ç©¶è¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨ä½œæ–‡è¯„åˆ†ä¸­ä¸äººç±»è¯„åˆ†è€…å…·æœ‰ä¸­ç­‰è‡³è‰¯å¥½çš„ä¸€è‡´æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14561v1" onclick="toggleFavorite(this, '2512.14561v1', 'Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251214306v1-inflation-attitudes-of-large-language-models.html">Inflation Attitudes of Large Language Models</a></td>
  <td>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹GPT-3.5ç ”ç©¶é€šè´§è†¨èƒ€æ„ŸçŸ¥ä¸é¢„æœŸï¼Œæ¨¡æ‹Ÿäººç±»è°ƒæŸ¥å¹¶åˆ†æå½±å“å› ç´ ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14306v1" onclick="toggleFavorite(this, '2512.14306v1', 'Inflation Attitudes of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251214118v1-cogmem-a-cognitive-memory-architecture-for-sustained-multi-turn-reas.html">CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models</a></td>
  <td>CogMemï¼šä¸€ç§è®¤çŸ¥è®°å¿†æ¶æ„ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ä¸­æŒç»­çš„å¤šè½®æ¨ç†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14118v1" onclick="toggleFavorite(this, '2512.14118v1', 'CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251214064v1-what-affects-the-effective-depth-of-large-language-models.html">What Affects the Effective Depth of Large Language Models?</a></td>
  <td>ç ”ç©¶æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹æœ‰æ•ˆæ·±åº¦å—é™ï¼Œä¸ºæ¨¡å‹ä¼˜åŒ–æä¾›æ–°è§†è§’</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14064v1" onclick="toggleFavorite(this, '2512.14064v1', 'What Affects the Effective Depth of Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251214237v1-ladder-up-memory-down-low-cost-fine-tuning-with-side-nets.html">Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets</a></td>
  <td>æå‡ºLadder Side Tuningä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒçš„å†…å­˜ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14237v1" onclick="toggleFavorite(this, '2512.14237v1', 'Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251214083v1-scalable-frameworks-for-real-world-audio-visual-speech-recognition.html">Scalable Frameworks for Real-World Audio-Visual Speech Recognition</a></td>
  <td>æå‡ºå¯æ‰©å±•æ¡†æ¶ï¼Œæå‡çœŸå®åœºæ™¯ä¸‹éŸ³è§†é¢‘è¯­éŸ³è¯†åˆ«çš„é²æ£’æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14083v1" onclick="toggleFavorite(this, '2512.14083v1', 'Scalable Frameworks for Real-World Audio-Visual Speech Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251214500v1-c-ing-clearly-enhanced-binary-code-explanations-using-c-code.html">C-ing Clearly: Enhanced Binary Code Explanations using C code</a></td>
  <td>C-ing Clearlyï¼šåˆ©ç”¨Cä»£ç å¢å¼ºLLMå¯¹äºŒè¿›åˆ¶ä»£ç çš„ç†è§£ï¼Œæå‡ä»£ç è§£é‡Šèƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14500v1" onclick="toggleFavorite(this, '2512.14500v1', 'C-ing Clearly: Enhanced Binary Code Explanations using C code')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251214531v1-versatileffn-achieving-parameter-efficiency-in-llms-via-adaptive-wid.html">VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse</a></td>
  <td>VersatileFFNï¼šé€šè¿‡è‡ªé€‚åº”å®½æ·±å¤ç”¨æå‡LLMçš„å‚æ•°æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14531v1" onclick="toggleFavorite(this, '2512.14531v1', 'VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251214239v1-two-cfg-nahuatl-for-automatic-corpora-expansion.html">Two CFG Nahuatl for automatic corpora expansion</a></td>
  <td>æå‡ºä¸¤ç§CFG Nahuatlæ–¹æ³•ï¼Œç”¨äºè‡ªåŠ¨æ‰©å±•Nawatlè¯­æ–™åº“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14239v1" onclick="toggleFavorite(this, '2512.14239v1', 'Two CFG Nahuatl for automatic corpora expansion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251214142v1-astraea-a-state-aware-scheduling-engine-for-llm-powered-agents.html">Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents</a></td>
  <td>Astraeaï¼šé¢å‘LLMæ™ºèƒ½ä½“çš„çŠ¶æ€æ„ŸçŸ¥è°ƒåº¦å¼•æ“ï¼Œä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14142v1" onclick="toggleFavorite(this, '2512.14142v1', 'Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251214085v1-multilingual-and-continuous-backchannel-prediction-a-cross-lingual-s.html">Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study</a></td>
  <td>æå‡ºä¸€ç§å¤šè¯­ç§è¿ç»­åé€šé“é¢„æµ‹æ¨¡å‹ï¼Œç”¨äºç ”ç©¶è·¨è¯­è¨€çš„äº¤äº’æ—¶åºè¡Œä¸ºã€‚</td>
  <td class="tags-cell"><span class="paper-tag">zero-shot transfer</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14085v1" onclick="toggleFavorite(this, '2512.14085v1', 'Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251214082v1-a-unified-sparse-attention-via-multi-granularity-compression.html">A Unified Sparse Attention via Multi-Granularity Compression</a></td>
  <td>æå‡ºUniSparseä»¥è§£å†³é•¿åºåˆ—è‡ªæ³¨æ„åŠ›è®¡ç®—ç“¶é¢ˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.14082v1" onclick="toggleFavorite(this, '2512.14082v1', 'A Unified Sparse Attention via Multi-Granularity Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.CL é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)