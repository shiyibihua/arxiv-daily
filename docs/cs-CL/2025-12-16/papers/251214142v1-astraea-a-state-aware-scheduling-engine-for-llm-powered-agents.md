---
layout: default
title: Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents
---

# Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14142" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14142v1</a>
  <a href="https://arxiv.org/pdf/2512.14142.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14142v1" onclick="toggleFavorite(this, '2512.14142v1', 'Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongqiu Ni, Jiabao Zhang, Guopeng Li, Zilong Wang, Ruiqi Wu, Chi Zhang, Haisheng Tan

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 12 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Astraeaï¼šé¢å‘LLMæ™ºèƒ½ä½“çš„çŠ¶æ€æ„ŸçŸ¥è°ƒåº¦å¼•æ“ï¼Œä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLMæ™ºèƒ½ä½“` `è°ƒåº¦å¼•æ“` `çŠ¶æ€æ„ŸçŸ¥` `ä½œä¸šå®Œæˆæ—¶é—´` `åˆ†å±‚è°ƒåº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMæ™ºèƒ½ä½“æ¨ç†ç³»ç»Ÿä¾§é‡äºå±€éƒ¨ä¼˜åŒ–ï¼Œå¿½ç•¥äº†å…¨å±€ä½œä¸šå®Œæˆæ—¶é—´ï¼ˆJCTï¼‰ï¼Œå¯¼è‡´ç«¯åˆ°ç«¯å»¶è¿Ÿè¾ƒé«˜ã€‚
2. Astraeaé€šè¿‡çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦ç®—æ³•ï¼Œç»“åˆè¯·æ±‚å†å²çŠ¶æ€å’Œæœªæ¥é¢„æµ‹ï¼ŒåŠ¨æ€åˆ†ç±»è¯·æ±‚å¹¶ä¼˜åŒ–å…¨å±€JCTã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAstraeaç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œå¹³å‡JCTé™ä½é«˜è¾¾25.5%ï¼Œå¹¶åœ¨é«˜è´Ÿè½½ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²ä¸ºæ™ºèƒ½ä»£ç†ã€‚å®ƒä»¬çš„å¤šé˜¶æ®µå·¥ä½œæµç¨‹åœ¨æœ¬åœ°è®¡ç®—å’Œè°ƒç”¨Web APIç­‰å¤–éƒ¨ç½‘ç»œæœåŠ¡ä¹‹é—´äº¤æ›¿ï¼Œè¿™å¯¼è‡´å®ƒä»¬çš„æ‰§è¡Œæ¨¡å¼ä¸ç°æœ‰æ¨ç†ç³»ç»Ÿï¼ˆå¦‚vLLMï¼‰çš„è°ƒåº¦ç²’åº¦ä¸åŒ¹é…ã€‚ç°æœ‰ç³»ç»Ÿé€šå¸¸ä¾§é‡äºæ¯ä¸ªç‰‡æ®µçš„ä¼˜åŒ–ï¼Œè¿™å¦¨ç¢äº†å®ƒä»¬æœ€å°åŒ–å®Œæ•´ä»£ç†å·¥ä½œæµç¨‹çš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œå³æ•´ä¸ªè¯·æ±‚ç”Ÿå‘½å‘¨æœŸå†…çš„å…¨å±€ä½œä¸šå®Œæˆæ—¶é—´ï¼ˆJCTï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†Astraeaï¼Œä¸€ç§æ—¨åœ¨å°†ä¼˜åŒ–ä»æœ¬åœ°ç‰‡æ®µè½¬ç§»åˆ°å…¨å±€è¯·æ±‚ç”Ÿå‘½å‘¨æœŸçš„æœåŠ¡å¼•æ“ã€‚Astraeaé‡‡ç”¨äº†ä¸€ç§çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦ç®—æ³•ï¼Œè¯¥ç®—æ³•å°†è¯·æ±‚çš„å†å²çŠ¶æ€ä¸æœªæ¥é¢„æµ‹ç›¸ç»“åˆã€‚å®ƒæ ¹æ®è¯·æ±‚çš„I/Oå’Œè®¡ç®—å¯†é›†å‹ç‰¹æ€§åŠ¨æ€åœ°å¯¹è¯·æ±‚è¿›è¡Œåˆ†ç±»ï¼Œå¹¶ä½¿ç”¨å¢å¼ºçš„HRRNç­–ç•¥æ¥å¹³è¡¡æ•ˆç‡å’Œå…¬å¹³æ€§ã€‚Astraeaè¿˜å®ç°äº†ä¸€ä¸ªè‡ªé€‚åº”KVç¼“å­˜ç®¡ç†å™¨ï¼Œè¯¥ç®¡ç†å™¨æ ¹æ®ç³»ç»Ÿå†…å­˜å‹åŠ›æ™ºèƒ½åœ°å¤„ç†I/Oç­‰å¾…æœŸé—´çš„ä»£ç†çŠ¶æ€ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒAstraeaå°†å¹³å‡JCTé™ä½äº†é«˜è¾¾25.5%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å„ç§æ¨¡å‹è§„æ¨¡çš„é«˜è´Ÿè½½ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMæ™ºèƒ½ä½“åœ¨å¤šé˜¶æ®µå·¥ä½œæµç¨‹ä¸­ï¼Œç”±äºæœ¬åœ°è®¡ç®—å’Œå¤–éƒ¨ç½‘ç»œæœåŠ¡è°ƒç”¨äº¤æ›¿ï¼Œå¯¼è‡´ç°æœ‰æ¨ç†ç³»ç»Ÿæ— æ³•æœ‰æ•ˆä¼˜åŒ–å…¨å±€ä½œä¸šå®Œæˆæ—¶é—´ï¼ˆJCTï¼‰çš„é—®é¢˜ã€‚ç°æœ‰ç³»ç»Ÿé€šå¸¸åªå…³æ³¨å•ä¸ªç‰‡æ®µçš„ä¼˜åŒ–ï¼Œè€Œå¿½ç•¥äº†æ•´ä¸ªè¯·æ±‚ç”Ÿå‘½å‘¨æœŸçš„ç«¯åˆ°ç«¯å»¶è¿Ÿï¼Œé€ æˆèµ„æºåˆ©ç”¨ç‡ä½ä¸‹å’Œç”¨æˆ·ä½“éªŒä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAstraeaçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ä¼˜åŒ–ç›®æ ‡ä»å±€éƒ¨ç‰‡æ®µè½¬ç§»åˆ°å…¨å±€è¯·æ±‚ç”Ÿå‘½å‘¨æœŸã€‚é€šè¿‡çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦ç®—æ³•ï¼ŒAstraeaèƒ½å¤Ÿæ ¹æ®è¯·æ±‚çš„å†å²çŠ¶æ€å’Œæœªæ¥é¢„æµ‹ï¼ŒåŠ¨æ€åœ°è°ƒæ•´è°ƒåº¦ç­–ç•¥ï¼Œä»è€Œæœ€å°åŒ–å…¨å±€JCTã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”LLMæ™ºèƒ½ä½“çš„å·¥ä½œè´Ÿè½½ç‰¹æ€§ï¼Œæé«˜æ•´ä½“æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAstraeaçš„æ•´ä½“æ¶æ„åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è¯·æ±‚åˆ†ç±»å™¨ï¼šæ ¹æ®è¯·æ±‚çš„I/Oå’Œè®¡ç®—å¯†é›†ç¨‹åº¦è¿›è¡ŒåŠ¨æ€åˆ†ç±»ã€‚2) åˆ†å±‚è°ƒåº¦å™¨ï¼šé‡‡ç”¨çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦ç®—æ³•ï¼Œç»“åˆè¯·æ±‚å†å²çŠ¶æ€å’Œæœªæ¥é¢„æµ‹è¿›è¡Œè°ƒåº¦ã€‚3) è‡ªé€‚åº”KVç¼“å­˜ç®¡ç†å™¨ï¼šæ ¹æ®ç³»ç»Ÿå†…å­˜å‹åŠ›ï¼Œæ™ºèƒ½åœ°ç®¡ç†I/Oç­‰å¾…æœŸé—´çš„ä»£ç†çŠ¶æ€ã€‚æ•´ä¸ªæµç¨‹å¦‚ä¸‹ï¼šè¯·æ±‚åˆ°è¾¾åï¼Œé¦–å…ˆç”±è¯·æ±‚åˆ†ç±»å™¨è¿›è¡Œåˆ†ç±»ï¼Œç„¶åç”±åˆ†å±‚è°ƒåº¦å™¨æ ¹æ®åˆ†ç±»ç»“æœå’Œç³»ç»ŸçŠ¶æ€è¿›è¡Œè°ƒåº¦ï¼Œæœ€åç”±è‡ªé€‚åº”KVç¼“å­˜ç®¡ç†å™¨è´Ÿè´£ç®¡ç†ç¼“å­˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šAstraeaçš„å…³é”®åˆ›æ–°åœ¨äºå…¶çŠ¶æ€æ„ŸçŸ¥çš„åˆ†å±‚è°ƒåº¦ç®—æ³•å’Œè‡ªé€‚åº”KVç¼“å­˜ç®¡ç†å™¨ã€‚çŠ¶æ€æ„ŸçŸ¥çš„è°ƒåº¦ç®—æ³•èƒ½å¤Ÿæ ¹æ®è¯·æ±‚çš„å†å²çŠ¶æ€å’Œæœªæ¥é¢„æµ‹ï¼ŒåŠ¨æ€åœ°è°ƒæ•´è°ƒåº¦ç­–ç•¥ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”LLMæ™ºèƒ½ä½“çš„å·¥ä½œè´Ÿè½½ç‰¹æ€§ã€‚è‡ªé€‚åº”KVç¼“å­˜ç®¡ç†å™¨èƒ½å¤Ÿæ ¹æ®ç³»ç»Ÿå†…å­˜å‹åŠ›ï¼Œæ™ºèƒ½åœ°ç®¡ç†I/Oç­‰å¾…æœŸé—´çš„ä»£ç†çŠ¶æ€ï¼Œä»è€Œæé«˜èµ„æºåˆ©ç”¨ç‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAstraeaèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°ä¼˜åŒ–å…¨å±€JCTï¼Œæé«˜æ•´ä½“æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šAstraeaçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¢å¼ºçš„HRRNï¼ˆHighest Response Ratio Nextï¼‰è°ƒåº¦ç­–ç•¥ï¼Œç”¨äºå¹³è¡¡æ•ˆç‡å’Œå…¬å¹³æ€§ã€‚2) åŸºäºç³»ç»Ÿå†…å­˜å‹åŠ›çš„è‡ªé€‚åº”KVç¼“å­˜ç®¡ç†ç­–ç•¥ï¼Œç”¨äºæ™ºèƒ½åœ°ç®¡ç†I/Oç­‰å¾…æœŸé—´çš„ä»£ç†çŠ¶æ€ã€‚3) è¯·æ±‚åˆ†ç±»å™¨çš„è®¾è®¡ï¼Œç”¨äºæ ¹æ®è¯·æ±‚çš„I/Oå’Œè®¡ç®—å¯†é›†ç¨‹åº¦è¿›è¡ŒåŠ¨æ€åˆ†ç±»ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14142v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14142v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.14142v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAstraeaç›¸æ¯”äºåŸºçº¿æ–¹æ³•ï¼Œå¹³å‡ä½œä¸šå®Œæˆæ—¶é—´ï¼ˆJCTï¼‰é™ä½äº†é«˜è¾¾25.5%ã€‚æ­¤å¤–ï¼ŒAstraeaåœ¨å„ç§æ¨¡å‹è§„æ¨¡çš„é«˜è´Ÿè½½ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§å’Œç¨³å®šæ€§ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜Astraeaèƒ½å¤Ÿæ˜¾è‘—æå‡LLMæ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Astraeaé€‚ç”¨äºå„ç§éœ€è¦LLMæ™ºèƒ½ä½“è¿›è¡Œå¤šé˜¶æ®µå·¥ä½œæµç¨‹å¤„ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆã€æ™ºèƒ½æ–‡æ¡£å¤„ç†ç­‰ã€‚é€šè¿‡ä¼˜åŒ–ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ŒAstraeaå¯ä»¥æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒï¼Œæé«˜å·¥ä½œæ•ˆç‡ï¼Œå¹¶é™ä½è®¡ç®—æˆæœ¬ã€‚æœªæ¥ï¼ŒAstraeaå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°æ”¯æŒæ›´å¤šç±»å‹çš„LLMæ™ºèƒ½ä½“å’Œæ›´å¤æ‚çš„åº”ç”¨åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly being deployed as intelligent agents. Their multi-stage workflows, which alternate between local computation and calls to external network services like Web APIs, introduce a mismatch in their execution pattern and the scheduling granularity of existing inference systems such as vLLM. Existing systems typically focus on per-segment optimization which prevents them from minimizing the end-to-end latency of the complete agentic workflow, i.e., the global Job Completion Time (JCT) over the entire request lifecycle. To address this limitation, we propose Astraea, a service engine designed to shift the optimization from local segments to the global request lifecycle. Astraea employs a state-aware, hierarchical scheduling algorithm that integrates a request's historical state with future predictions. It dynamically classifies requests by their I/O and compute intensive nature and uses an enhanced HRRN policy to balance efficiency and fairness. Astraea also implements an adaptive KV cache manager that intelligently handles the agent state during I/O waits based on the system memory pressure. Extensive experiments show that Astraea reduces average JCT by up to 25.5\% compared to baseline methods. Moreover, our approach demonstrates strong robustness and stability under high load across various model scales.

