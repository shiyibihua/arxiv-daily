---
layout: default
title: Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models
---

# Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14427" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14427v1</a>
  <a href="https://arxiv.org/pdf/2512.14427.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14427v1" onclick="toggleFavorite(this, '2512.14427v1', 'Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gabriele Prato, Shagun Sodhani, Alessandro Sordoni, Sarath Chandar

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§è¯­è¨€æ¨¡å‹å¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ–‡æ¡£æ‰“åŒ…` `å¤šè·³æ¨ç†` `æ¨¡å‹è®­ç»ƒ` `æ¶ˆèç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè®­ç»ƒé€šå¸¸é‡‡ç”¨æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ä»¥æå‡è®¡ç®—æ•ˆç‡ï¼Œä½†å…¶å¯¹æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ½œåœ¨å½±å“å°šä¸æ˜ç¡®ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡å¯¹æ¯”ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œåˆ†æå…¶å¯¹LLMå¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œæ—¨åœ¨ä¼˜åŒ–æ¨¡å‹è®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ–‡æ¡£æ‰“åŒ…èƒ½åœ¨å¢åŠ è®¡ç®—æˆæœ¬çš„åŒæ—¶æå‡æ¨¡å‹æ€§èƒ½ï¼Œæ¶ˆèå®éªŒæ­ç¤ºäº†æ‰“åŒ…ä¼˜åŠ¿çš„å…³é”®å› ç´ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ½œåœ¨å¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚é€šå¸¸ï¼Œè®­ç»ƒLLMæ—¶ä¼šå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…åœ¨ä¸€èµ·ï¼Œä»¥ä¼˜åŒ–è®¡ç®—æ•ˆç‡ã€‚ç„¶è€Œï¼Œè¿™ç§åšæ³•å¯¹æ¨¡å‹èƒ½åŠ›çš„å½±å“åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå°šæœªè¢«æ¢ç´¢ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä¸åœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ‰“åŒ…å¯ä»¥æé«˜æ¨¡å‹æ€§èƒ½ï¼Œä½†ä¼šå¢åŠ è®¡ç®—æˆæœ¬ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£å…¶æ½œåœ¨æœºåˆ¶ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹æ¶ˆèç ”ç©¶ï¼Œç¡®å®šäº†è§£é‡Šæ‰“åŒ…ä¼˜åŠ¿çš„å…³é”®å› ç´ ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç ”ç©¶åŠ æ·±äº†å¯¹LLMè®­ç»ƒåŠ¨æ€çš„ç†è§£ï¼Œå¹¶ä¸ºä¼˜åŒ–æ¨¡å‹å¼€å‘æä¾›äº†å®ç”¨çš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶åœ¨è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…åœ¨ä¸€èµ·å¯¹æ¨¡å‹çš„å¤šè·³æ¨ç†èƒ½åŠ›äº§ç”Ÿçš„å½±å“ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨è®¡ç®—æ•ˆç‡çš„æå‡ï¼Œè€Œå¿½ç•¥äº†æ–‡æ¡£æ‰“åŒ…å¯èƒ½å¯¹æ¨¡å‹å­¦ä¹ åˆ°çš„çŸ¥è¯†è¡¨ç¤ºå’Œæ¨ç†èƒ½åŠ›é€ æˆçš„æ½œåœ¨å½±å“ã€‚å› æ­¤ï¼Œå¦‚ä½•é€‰æ‹©åˆé€‚çš„æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œåœ¨ä¿è¯è®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œæœ€å¤§åŒ–æ¨¡å‹çš„å¤šè·³æ¨ç†èƒ½åŠ›ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å®éªŒå¯¹æ¯”ä¸åŒçš„æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œåˆ†æå®ƒä»¬å¯¹æ¨¡å‹å¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚é€šè¿‡æ¶ˆèå®éªŒï¼Œè¿›ä¸€æ­¥æ¢ç©¶æ–‡æ¡£æ‰“åŒ…æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æ­ç¤ºæ–‡æ¡£æ‰“åŒ…ä¸æ¨¡å‹æ¨ç†èƒ½åŠ›ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œä¸ºä¼˜åŒ–LLMè®­ç»ƒæä¾›ç†è®ºä¾æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é‡‡ç”¨å®éªŒé©±åŠ¨çš„ç ”ç©¶æ–¹æ³•ã€‚é¦–å…ˆï¼Œæ„å»ºåŒ…å«å¤šä¸ªæ–‡æ¡£çš„è®­ç»ƒæ•°æ®é›†ã€‚ç„¶åï¼Œè®¾è®¡ä¸åŒçš„æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œä¾‹å¦‚éšæœºæ‰“åŒ…ã€æŒ‰ä¸»é¢˜æ‰“åŒ…ç­‰ã€‚æ¥ç€ï¼Œä½¿ç”¨è¿™äº›æ‰“åŒ…åçš„æ•°æ®é›†è®­ç»ƒLLMï¼Œå¹¶åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚æœ€åï¼Œé€šè¿‡æ¶ˆèå®éªŒï¼Œåˆ†æä¸åŒå› ç´ ï¼ˆå¦‚æ–‡æ¡£æ•°é‡ã€æ–‡æ¡£é•¿åº¦ã€æ–‡æ¡£ç›¸å…³æ€§ç­‰ï¼‰å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„åˆ›æ–°ä¹‹å¤„åœ¨äºï¼Œé¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹LLMå¤šè·³æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦å…³æ³¨æ–‡æ¡£æ‰“åŒ…å¯¹è®¡ç®—æ•ˆç‡çš„æå‡ï¼Œè€Œå¿½ç•¥äº†å…¶å¯¹æ¨¡å‹å­¦ä¹ èƒ½åŠ›çš„å½±å“ã€‚è¯¥ç ”ç©¶å¡«è¡¥äº†è¿™ä¸€ç©ºç™½ï¼Œä¸ºä¼˜åŒ–LLMè®­ç»ƒæä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è®¾è®¡äº†å¤šç§æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œä»¥è¦†ç›–ä¸åŒçš„åœºæ™¯ï¼›2) é€‰æ‹©äº†åˆé€‚çš„å¤šè·³æ¨ç†ä»»åŠ¡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ï¼Œä»¥å‡†ç¡®è¡¡é‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼›3) è¿›è¡Œäº†è¯¦ç»†çš„æ¶ˆèå®éªŒï¼Œä»¥æ­ç¤ºæ–‡æ¡£æ‰“åŒ…æå‡æ¨¡å‹æ€§èƒ½çš„å…³é”®å› ç´ ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶è¡¨æ˜ï¼Œä¸åœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ–‡æ¡£æ‰“åŒ…å¯ä»¥æé«˜æ¨¡å‹åœ¨å¤šè·³æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚æ¶ˆèå®éªŒæ­ç¤ºäº†æ–‡æ¡£æ•°é‡ã€æ–‡æ¡£é•¿åº¦å’Œæ–‡æ¡£ç›¸å…³æ€§ç­‰å› ç´ å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦ä»¥åŠå¯¹æ¯”çš„åŸºçº¿æ¨¡å‹éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¤æ‚æ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†å›¾è°±æ¨ç†ã€æ™ºèƒ½å®¢æœç­‰ã€‚é€šè¿‡ä¼˜åŒ–æ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œå¯ä»¥æå‡LLMåœ¨è¿™äº›åº”ç”¨ä¸­çš„æ€§èƒ½ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒå’Œå·¥ä½œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºæœªæ¥LLMçš„è®­ç»ƒå’Œä¼˜åŒ–æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

