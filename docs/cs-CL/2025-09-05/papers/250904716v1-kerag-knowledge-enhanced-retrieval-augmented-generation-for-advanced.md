---
layout: default
title: KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering
---

# KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04716" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04716v1</a>
  <a href="https://arxiv.org/pdf/2509.04716.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04716v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04716v1', 'KERAG: Knowledge-Enhanced Retrieval-Augmented Generation for Advanced Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yushi Sun, Kai Sun, Yifan Ethan Xu, Xiao Yang, Xin Luna Dong, Nan Tang, Lei Chen

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: Accepted by EMNLP Findings 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**KERAGï¼šçŸ¥è¯†å¢å¼ºçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œæå‡å¤æ‚é—®ç­”è¦†ç›–ç‡ä¸å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±é—®ç­”` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ€ç»´é“¾` `çŸ¥è¯†æ£€ç´¢` `ä¿¡æ¯è¿‡æ»¤` `å­å›¾æŒ–æ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸKGQAæ–¹æ³•ä¾èµ–ä¸¥æ ¼çš„è¯­ä¹‰è§£æï¼Œå¯¼è‡´çŸ¥è¯†è¦†ç›–ç‡ä¸è¶³ï¼Œéš¾ä»¥åº”å¯¹å¤æ‚é—®é¢˜ã€‚
2. KERAGé€šè¿‡æ£€ç´¢æ›´å¹¿æ³›çš„çŸ¥è¯†å­å›¾ï¼Œå¹¶ç»“åˆè¿‡æ»¤å’Œæ€»ç»“ï¼Œæå‡RAGçš„çŸ¥è¯†è¦†ç›–ç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒKERAGåœ¨é—®ç­”è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒ…æ‹¬GPT-4oç­‰å¤§å‹æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)é€šè¿‡æ•´åˆå¤–éƒ¨æ•°æ®æ¥ç¼“è§£å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä¸­çš„å¹»è§‰é—®é¢˜ï¼Œå…¶ä¸­çŸ¥è¯†å›¾è°±(KG)ä¸ºé—®ç­”æä¾›äº†å…³é”®ä¿¡æ¯ã€‚ä¼ ç»Ÿçš„çŸ¥è¯†å›¾è°±é—®ç­”(KGQA)æ–¹æ³•ä¾èµ–äºè¯­ä¹‰è§£æï¼Œé€šå¸¸åªæ£€ç´¢ç”Ÿæˆç­”æ¡ˆä¸¥æ ¼å¿…éœ€çš„çŸ¥è¯†ï¼Œå› æ­¤ç”±äºä¸¥æ ¼çš„æ¨¡å¼è¦æ±‚å’Œè¯­ä¹‰æ­§ä¹‰ï¼Œå¸¸å¸¸é¢ä¸´è¦†ç›–ç‡ä½çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†KERAGï¼Œä¸€ç§æ–°é¢–çš„åŸºäºKGçš„RAGæµç¨‹ï¼Œé€šè¿‡æ£€ç´¢æ›´å¹¿æ³›çš„å­å›¾æ¥å¢å¼ºQAè¦†ç›–ç‡ï¼Œè¯¥å­å›¾å¯èƒ½åŒ…å«ç›¸å…³ä¿¡æ¯ã€‚æˆ‘ä»¬çš„æ£€ç´¢-è¿‡æ»¤-æ€»ç»“æ–¹æ³•ï¼Œç»“åˆå¾®è°ƒçš„LLMï¼Œç”¨äºçŸ¥è¯†å­å›¾ä¸Šçš„æ€ç»´é“¾æ¨ç†ï¼Œå‡å°‘äº†å™ªå£°ï¼Œå¹¶æé«˜äº†ç®€å•å’Œå¤æ‚é—®é¢˜çš„QAæ•ˆæœã€‚å®éªŒè¡¨æ˜ï¼ŒKERAGåœ¨è´¨é‡ä¸Šè¶…è¿‡äº†æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆçº¦7%ï¼Œå¹¶ä¸”è¶…è¿‡äº†GPT-4o (Tool) 10-21%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çŸ¥è¯†å›¾è°±é—®ç­”ä¸­ï¼Œç”±äºä¼ ç»Ÿæ–¹æ³•ä¾èµ–ä¸¥æ ¼çš„è¯­ä¹‰è§£æï¼Œå¯¼è‡´çŸ¥è¯†è¦†ç›–ç‡ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†å¤æ‚é—®é¢˜ï¼Œå¹¶ä¸”å®¹æ˜“å—åˆ°çŸ¥è¯†å›¾è°±æ¨¡å¼é™åˆ¶å’Œè¯­ä¹‰æ­§ä¹‰çš„å½±å“ï¼Œä»è€Œå½±å“é—®ç­”çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKERAGçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ£€ç´¢æ›´å¹¿æ³›çš„çŸ¥è¯†å­å›¾ï¼Œè€Œéä»…ä»…ä¾èµ–äºç²¾ç¡®åŒ¹é…çš„çŸ¥è¯†ã€‚è¿™æ ·å¯ä»¥å¢åŠ ç›¸å…³ä¿¡æ¯çš„è¦†ç›–èŒƒå›´ï¼Œä»è€Œæé«˜å›ç­”é—®é¢˜çš„å¯èƒ½æ€§ã€‚åŒæ—¶ï¼Œé€šè¿‡åç»­çš„è¿‡æ»¤å’Œæ€»ç»“æ­¥éª¤ï¼Œå¯ä»¥å‡å°‘å™ªå£°ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKERAGåŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ£€ç´¢ã€è¿‡æ»¤å’Œæ€»ç»“ã€‚é¦–å…ˆï¼Œæ£€ç´¢é˜¶æ®µä»çŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢ä¸€ä¸ªæ›´å¹¿æ³›çš„å­å›¾ï¼Œè¯¥å­å›¾å¯èƒ½åŒ…å«ä¸é—®é¢˜ç›¸å…³çš„å®ä½“å’Œå…³ç³»ã€‚ç„¶åï¼Œè¿‡æ»¤é˜¶æ®µå¯¹æ£€ç´¢åˆ°çš„å­å›¾è¿›è¡Œè¿‡æ»¤ï¼Œå»é™¤ä¸ç›¸å…³æˆ–å†—ä½™çš„ä¿¡æ¯ã€‚æœ€åï¼Œæ€»ç»“é˜¶æ®µåˆ©ç”¨å¾®è°ƒçš„LLMï¼ŒåŸºäºè¿‡æ»¤åçš„å­å›¾è¿›è¡Œæ€ç»´é“¾æ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šKERAGçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ£€ç´¢ç­–ç•¥ï¼Œå³ä¸å†å±€é™äºç²¾ç¡®åŒ¹é…çš„çŸ¥è¯†ï¼Œè€Œæ˜¯æ£€ç´¢ä¸€ä¸ªæ›´å¹¿æ³›çš„ã€å¯èƒ½åŒ…å«ç›¸å…³ä¿¡æ¯çš„å­å›¾ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æ˜¾è‘—æé«˜çŸ¥è¯†è¦†ç›–ç‡ï¼Œä»è€Œæ›´å¥½åœ°åº”å¯¹å¤æ‚é—®é¢˜ã€‚æ­¤å¤–ï¼Œç»“åˆè¿‡æ»¤å’Œæ€»ç»“æ­¥éª¤ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘å™ªå£°ï¼Œæé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šKERAGçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) æ£€ç´¢ç­–ç•¥ï¼šé‡‡ç”¨åŸºäºå®ä½“å’Œå…³ç³»çš„æ‰©å±•æ£€ç´¢æ–¹æ³•ï¼Œæ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„å¤šä¸ªè·³æ•°çš„å­å›¾ã€‚(2) è¿‡æ»¤ç­–ç•¥ï¼šåˆ©ç”¨LLMå¯¹æ£€ç´¢åˆ°çš„ä¸‰å…ƒç»„è¿›è¡Œç›¸å…³æ€§è¯„åˆ†ï¼Œå¹¶è®¾å®šé˜ˆå€¼è¿›è¡Œè¿‡æ»¤ã€‚(3) æ€»ç»“ç­–ç•¥ï¼šä½¿ç”¨å¾®è°ƒçš„LLMè¿›è¡Œæ€ç»´é“¾æ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

KERAGåœ¨é—®ç­”è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨å®éªŒä¸­ï¼ŒKERAGè¶…è¿‡äº†æœ€å…ˆè¿›çš„è§£å†³æ–¹æ¡ˆçº¦7%ï¼Œå¹¶ä¸”è¶…è¿‡äº†GPT-4o (Tool) 10-21%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒKERAGèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜çŸ¥è¯†å›¾è°±é—®ç­”çš„å‡†ç¡®æ€§å’Œè¦†ç›–ç‡ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚é—®é¢˜æ—¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

KERAGå¯åº”ç”¨äºå„ç§éœ€è¦çŸ¥è¯†å›¾è°±æ”¯æŒçš„é—®ç­”åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€åŒ»ç–—è¯Šæ–­ã€é‡‘èåˆ†æç­‰ã€‚é€šè¿‡æä¾›æ›´å…¨é¢ã€å‡†ç¡®çš„çŸ¥è¯†ï¼ŒKERAGå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£é—®é¢˜ï¼Œå¹¶è·å¾—æ›´å¯é çš„ç­”æ¡ˆã€‚æœªæ¥ï¼ŒKERAGå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼Œä¾‹å¦‚çŸ¥è¯†å›¾è°±è¡¥å…¨ã€å…³ç³»æŠ½å–ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Retrieval-Augmented Generation (RAG) mitigates hallucination in Large Language Models (LLMs) by incorporating external data, with Knowledge Graphs (KGs) offering crucial information for question answering. Traditional Knowledge Graph Question Answering (KGQA) methods rely on semantic parsing, which typically retrieves knowledge strictly necessary for answer generation, thus often suffer from low coverage due to rigid schema requirements and semantic ambiguity. We present KERAG, a novel KG-based RAG pipeline that enhances QA coverage by retrieving a broader subgraph likely to contain relevant information. Our retrieval-filtering-summarization approach, combined with fine-tuned LLMs for Chain-of-Thought reasoning on knowledge sub-graphs, reduces noises and improves QA for both simple and complex questions. Experiments demonstrate that KERAG surpasses state-of-the-art solutions by about 7% in quality and exceeds GPT-4o (Tool) by 10-21%.

