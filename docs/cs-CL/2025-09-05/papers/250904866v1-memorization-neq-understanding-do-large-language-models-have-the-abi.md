---
layout: default
title: Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?
---

# Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04866" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04866v1</a>
  <a href="https://arxiv.org/pdf/2509.04866.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04866v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04866v1', 'Memorization $\neq$ Understanding: Do Large Language Models Have the Ability of Scenario Cognition?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Boxiang Ma, Ru Li, Yuanlong Wang, Hongye Tan, Xiaoli Li

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: EMNLP 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒè§†è§’è¯„ä¼°æ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹åœºæ™¯è®¤çŸ¥èƒ½åŠ›é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åœºæ™¯è®¤çŸ¥` `åŒè§†è§’è¯„ä¼°` `è¯­ä¹‰ç†è§£` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åœºæ™¯è®¤çŸ¥èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œä¸»è¦ä¾èµ–äºå¯¹è®­ç»ƒæ•°æ®çš„è¡¨é¢è®°å¿†ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŒè§†è§’è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡åœºæ™¯åŸºç¡€æ•°æ®é›†è¯„ä¼°æ¨¡å‹çš„è¯­ä¹‰åœºæ™¯è®¤çŸ¥èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰LLMsåœ¨åœºæ™¯è®¤çŸ¥ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œæœªèƒ½æœ‰æ•ˆç†è§£è¯­ä¹‰å…³è”ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶æ³›åŒ–èƒ½åŠ›æ˜¯å¦æºäºå¯¹è®­ç»ƒæ•°æ®çš„ç®€å•è®°å¿†ï¼Œè¿˜æ˜¯æ·±å±‚è¯­ä¹‰ç†è§£ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŒè§†è§’è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è¯„ä¼°LLMsçš„åœºæ™¯è®¤çŸ¥èƒ½åŠ›ï¼Œå³å°†è¯­ä¹‰åœºæ™¯å…ƒç´ ä¸ä¸Šä¸‹æ–‡ä¸­çš„è®ºæ®å…³è”çš„èƒ½åŠ›ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°é¢–çš„åŸºäºåœºæ™¯çš„æ•°æ®é›†ï¼ŒåŒ…å«å¤šæ ·çš„è™šæ„äº‹å®æ–‡æœ¬æè¿°ï¼Œå¹¶å¯¹åœºæ™¯å…ƒç´ è¿›è¡Œäº†æ³¨é‡Šã€‚é€šè¿‡è¯„ä¼°æ¨¡å‹è¾“å‡ºå’Œå†…éƒ¨è¡¨ç¤ºï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œå½“å‰çš„LLMsä¸»è¦ä¾èµ–äºè¡¨é¢çš„è®°å¿†ï¼Œæœªèƒ½åœ¨ç®€å•æƒ…å†µä¸‹å®ç°ç¨³å¥çš„è¯­ä¹‰åœºæ™¯è®¤çŸ¥ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†LLMsåœ¨è¯­ä¹‰ç†è§£æ–¹é¢çš„å…³é”®å±€é™æ€§ï¼Œå¹¶ä¸ºæå‡å…¶èƒ½åŠ›æä¾›äº†è®¤çŸ¥æ´å¯Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åœºæ™¯è®¤çŸ¥èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåŒºåˆ†è®°å¿†ä¸ç†è§£çš„å·®å¼‚ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥åŒè§†è§’è¯„ä¼°æ¡†æ¶ï¼Œç»“åˆæ¨¡å‹è¾“å‡ºä¸å†…éƒ¨è¡¨ç¤ºçš„åˆ†æï¼Œå…¨é¢è¯„ä¼°LLMsçš„åœºæ™¯è®¤çŸ¥èƒ½åŠ›ï¼Œæ¢è®¨å…¶åœ¨è¯­ä¹‰ç†è§£ä¸Šçš„æ·±åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯åŸºäºåœºæ™¯çš„æ•°æ®é›†æ„å»ºï¼ŒäºŒæ˜¯åŒè§†è§’è¯„ä¼°æœºåˆ¶ï¼Œåˆ†åˆ«ä»æ¨¡å‹è¾“å‡ºå’Œå†…éƒ¨è¡¨ç¤ºä¸¤ä¸ªæ–¹é¢è¿›è¡Œåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åŒè§†è§’è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶è€ƒå¯Ÿæ¨¡å‹çš„è¾“å‡ºèƒ½åŠ›ä¸å†…éƒ¨è¡¨ç¤ºçš„è¯­ä¹‰å…³è”ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨åœºæ™¯è®¤çŸ¥ä¸Šçš„æ·±å±‚æ¬¡é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œè®¾è®¡äº†å¤šæ ·çš„è™šæ„äº‹å®æ–‡æœ¬ï¼Œå¹¶å¯¹åœºæ™¯å…ƒç´ è¿›è¡Œäº†è¯¦ç»†æ³¨é‡Šï¼›åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨åœºæ™¯è®¤çŸ¥ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰çš„LLMsåœ¨åœºæ™¯è®¤çŸ¥ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸»è¦ä¾èµ–è¡¨é¢è®°å¿†ï¼Œæœªèƒ½æœ‰æ•ˆç†è§£è¯­ä¹‰å…³è”ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨ç®€å•åœºæ™¯é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡æœªè¾¾åˆ°é¢„æœŸï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨è¯­ä¹‰ç†è§£æ–¹é¢çš„å…³é”®å±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿå’Œè‡ªåŠ¨æ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„åœºæ™¯è®¤çŸ¥èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨å¤æ‚è¯­å¢ƒä¸‹çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»è€Œæé«˜å®é™…åº”ç”¨çš„æ•ˆæœå’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰ç†è§£æ¨¡å‹çš„å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Driven by vast and diverse textual data, large language models (LLMs) have demonstrated impressive performance across numerous natural language processing (NLP) tasks. Yet, a critical question persists: does their generalization arise from mere memorization of training data or from deep semantic understanding? To investigate this, we propose a bi-perspective evaluation framework to assess LLMs' scenario cognition - the ability to link semantic scenario elements with their arguments in context. Specifically, we introduce a novel scenario-based dataset comprising diverse textual descriptions of fictional facts, annotated with scenario elements. LLMs are evaluated through their capacity to answer scenario-related questions (model output perspective) and via probing their internal representations for encoded scenario elements-argument associations (internal representation perspective). Our experiments reveal that current LLMs predominantly rely on superficial memorization, failing to achieve robust semantic scenario cognition, even in simple cases. These findings expose critical limitations in LLMs' semantic understanding and offer cognitive insights for advancing their capabilities.

