---
layout: default
title: The Token Tax: Systematic Bias in Multilingual Tokenization
---

# The Token Tax: Systematic Bias in Multilingual Tokenization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05486" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05486v1</a>
  <a href="https://arxiv.org/pdf/2509.05486.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05486v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05486v1', 'The Token Tax: Systematic Bias in Multilingual Tokenization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jessica M. Lundin, Ada Zhang, Nihal Karim, Hamza Louzan, Victor Wei, David Adelani, Cody Carroll

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºå¤šè¯­è¨€åˆ†è¯åå·®ï¼šToken Taxå¯¹ä½èµ„æºè¯­è¨€çš„å½±å“ä¸åº”å¯¹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€åˆ†è¯` `ä½èµ„æºè¯­è¨€` `Token Tax` `æ¨¡å‹åå·®` `å½¢æ€æ„ŸçŸ¥åˆ†è¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åˆ†è¯å™¨å¯¹å½¢æ€å¤æ‚çš„ä½èµ„æºè¯­è¨€å¤„ç†æ•ˆç‡ä½ï¼Œå¯¼è‡´è®¡ç®—èµ„æºæµªè´¹å’Œæ¨¡å‹å‡†ç¡®ç‡ä¸‹é™ã€‚
2. è®ºæ–‡æ ¸å¿ƒæ€æƒ³æ˜¯æ­ç¤ºåˆ†è¯æ•ˆç‡ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶é‡åŒ–åˆ†è¯ä½æ•ˆå¸¦æ¥çš„ç»æµæˆæœ¬ã€‚
3. å®éªŒè¡¨æ˜ï¼Œtokenæ•°é‡ä¸æ¨¡å‹å‡†ç¡®ç‡å‘ˆè´Ÿç›¸å…³ï¼Œä¸”æ¨ç†æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šè¡¨ç°æ›´ä¼˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†åˆ†è¯æ•ˆç‡ä½ä¸‹å¯¹å½¢æ€å¤æ‚ã€ä½èµ„æºè¯­è¨€é€ æˆçš„ç»“æ„æ€§åŠ£åŠ¿ï¼Œè¿™ç§åŠ£åŠ¿ä½“ç°åœ¨è®¡ç®—èµ„æºçš„æµªè´¹å’Œå‡†ç¡®ç‡çš„é™ä½ã€‚ä½œè€…åœ¨AfriMMLUæ•°æ®é›†ï¼ˆåŒ…å«16ç§éæ´²è¯­è¨€çš„9000ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼‰ä¸Šè¯„ä¼°äº†10ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œå‘ç°è¯è¯­çš„å¹³å‡tokenæ•°ï¼ˆfertilityï¼‰èƒ½å¤Ÿå¯é åœ°é¢„æµ‹å‡†ç¡®ç‡ã€‚è¾ƒé«˜çš„fertilityå§‹ç»ˆé¢„æµ‹è¾ƒä½çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ï¼Œæ¨ç†æ¨¡å‹ï¼ˆå¦‚DeepSeek, o1ï¼‰åœ¨AfriMMLUæ•°æ®é›†ä¸­å§‹ç»ˆä¼˜äºéæ¨ç†æ¨¡å‹ï¼Œç¼©å°äº†å…ˆå‰å‡ ä»£æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°çš„å‡†ç¡®ç‡å·®è·ã€‚æœ€åï¼Œå°†tokenè†¨èƒ€è½¬åŒ–ä¸ºç»æµæˆæœ¬ï¼Œtokenæ•°é‡ç¿»å€ä¼šå¯¼è‡´è®­ç»ƒæˆæœ¬å’Œæ—¶é—´å¢åŠ å››å€ï¼Œçªæ˜¾äº†è®¸å¤šè¯­è¨€é¢ä¸´çš„â€œtoken taxâ€ã€‚è¿™äº›ç»“æœä¿ƒä½¿äººä»¬å…³æ³¨å½¢æ€æ„ŸçŸ¥åˆ†è¯ã€å…¬å¹³å®šä»·ä»¥åŠç”¨äºå…¬å¹³è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å¤šè¯­è¨€åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šè¯­è¨€ç¯å¢ƒä¸‹ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå½¢æ€å¤æ‚çš„ä½èµ„æºè¯­è¨€ï¼Œç°æœ‰åˆ†è¯å™¨æ•ˆç‡ä½ä¸‹å¯¼è‡´çš„â€œToken Taxâ€é—®é¢˜ã€‚ç°æœ‰åˆ†è¯å™¨é€šå¸¸åŸºäºByte Pair Encoding (BPE) ç­‰æ–¹æ³•ï¼Œå¯¹é«˜èµ„æºè¯­è¨€ä¼˜åŒ–ï¼Œä½†åœ¨ä½èµ„æºè¯­è¨€ä¸Šä¼šäº§ç”Ÿè¿‡å¤šçš„tokenï¼Œå¢åŠ äº†è®¡ç®—æˆæœ¬ï¼Œé™ä½äº†æ¨¡å‹æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡åŒ–åˆ†è¯æ•ˆç‡ï¼ˆé€šè¿‡ fertilityï¼Œå³æ¯ä¸ªè¯çš„å¹³å‡tokenæ•°ï¼‰ä¸æ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æ­ç¤ºè¿™ç§å…³ç³»å¯¹ä½èµ„æºè¯­è¨€çš„å½±å“ã€‚é€šè¿‡åˆ†æä¸åŒæ¨¡å‹çš„è¡¨ç°ï¼Œæ‰¾å‡ºåœ¨ä½èµ„æºè¯­è¨€ä¸Šè¡¨ç°æ›´å¥½çš„æ¨¡å‹ç±»å‹ï¼ˆå¦‚æ¨ç†æ¨¡å‹ï¼‰ï¼Œä»è€Œä¸ºæœªæ¥çš„æ¨¡å‹è®¾è®¡å’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) åœ¨AfriMMLUæ•°æ®é›†ä¸Šè¯„ä¼°10ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼›2) è®¡ç®—æ¯ä¸ªè¯­è¨€çš„fertilityï¼›3) åˆ†æfertilityä¸æ¨¡å‹å‡†ç¡®ç‡ä¹‹é—´çš„ç›¸å…³æ€§ï¼›4) æ¯”è¾ƒä¸åŒç±»å‹æ¨¡å‹ï¼ˆæ¨ç†æ¨¡å‹ vs. éæ¨ç†æ¨¡å‹ï¼‰åœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„è¡¨ç°ï¼›5) å°†tokenè†¨èƒ€è½¬åŒ–ä¸ºç»æµæˆæœ¬ï¼Œé‡åŒ–â€œToken Taxâ€ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) é¦–æ¬¡ç³»ç»Ÿæ€§åœ°é‡åŒ–äº†åˆ†è¯æ•ˆç‡å¯¹ä½èµ„æºè¯­è¨€æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œæå‡ºäº†â€œToken Taxâ€çš„æ¦‚å¿µï¼›2) æ­ç¤ºäº†æ¨ç†æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šç›¸å¯¹äºéæ¨ç†æ¨¡å‹çš„ä¼˜åŠ¿ï¼›3) ä½¿ç”¨AfriMMLUæ•°æ®é›†ï¼Œä¸ºè¯„ä¼°å¤šè¯­è¨€æ¨¡å‹åœ¨éæ´²è¯­è¨€ä¸Šçš„æ€§èƒ½æä¾›äº†ä¸€ä¸ªåŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨AfriMMLUæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«16ç§éæ´²è¯­è¨€ï¼Œè¦†ç›–äº†ä¸åŒçš„è¯­è¨€å½¢æ€å’Œèµ„æºæ°´å¹³ï¼›2) ä½¿ç”¨fertilityä½œä¸ºåˆ†è¯æ•ˆç‡çš„æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡ç®€å•æ˜“æ‡‚ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åæ˜ åˆ†è¯å™¨åœ¨ä¸åŒè¯­è¨€ä¸Šçš„è¡¨ç°ï¼›3) å¯¹æ¯”ä¸åŒç±»å‹æ¨¡å‹ï¼ŒåŒ…æ‹¬æ¨ç†æ¨¡å‹ï¼ˆå¦‚DeepSeek, o1ï¼‰å’Œéæ¨ç†æ¨¡å‹ï¼Œä»¥æ­ç¤ºä¸åŒæ¨¡å‹æ¶æ„å¯¹ä½èµ„æºè¯­è¨€çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œfertilityä¸æ¨¡å‹å‡†ç¡®ç‡ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„è´Ÿç›¸å…³å…³ç³»ï¼Œå³è¾ƒé«˜çš„fertilityé€šå¸¸å¯¹åº”è¾ƒä½çš„å‡†ç¡®ç‡ã€‚å…·ä½“æ¥è¯´ï¼Œtokenæ•°é‡ç¿»å€ä¼šå¯¼è‡´è®­ç»ƒæˆæœ¬å’Œæ—¶é—´å¢åŠ å››å€ã€‚æ­¤å¤–ï¼Œæ¨ç†æ¨¡å‹ï¼ˆå¦‚DeepSeek, o1ï¼‰åœ¨AfriMMLUæ•°æ®é›†ä¸­å§‹ç»ˆä¼˜äºéæ¨ç†æ¨¡å‹ï¼Œç¼©å°äº†å…ˆå‰å‡ ä»£æ¨¡å‹ä¸­è§‚å¯Ÿåˆ°çš„å‡†ç¡®ç‡å·®è·ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ”¹è¿›å¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿçš„è®¾è®¡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤„ç†ä½èµ„æºè¯­è¨€æ—¶ã€‚é€šè¿‡é‡‡ç”¨å½¢æ€æ„ŸçŸ¥åˆ†è¯æ–¹æ³•ï¼Œå¯ä»¥é™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼ºè°ƒäº†å…¬å¹³å®šä»·çš„é‡è¦æ€§ï¼Œé¼“åŠ±äº‘æœåŠ¡æä¾›å•†é’ˆå¯¹ä¸åŒè¯­è¨€çš„tokenæ•°é‡è¿›è¡Œå·®å¼‚åŒ–å®šä»·ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ¨åŠ¨å¤šè¯­è¨€åŸºå‡†çš„å¼€å‘ï¼Œä¿ƒè¿›æ›´å…¬å¹³çš„è‡ªç„¶è¯­è¨€å¤„ç†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tokenization inefficiency imposes structural disadvantages on morphologically complex, low-resource languages, inflating compute resources and depressing accuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA items; 5 subjects; 16 African languages) and show that fertility (tokens/word) reliably predicts accuracy. Higher fertility consistently predicts lower accuracy across all models and subjects. We further find that reasoning models (DeepSeek, o1) consistently outperform non-reasoning peers across high and low resource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in prior generations. Finally, translating token inflation to economics, a doubling in tokens results in quadrupled training cost and time, underscoring the token tax faced by many languages. These results motivate morphologically aware tokenization, fair pricing, and multilingual benchmarks for equitable natural language processing (NLP).

