---
layout: default
title: Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework
---

# Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04770" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.04770v1</a>
  <a href="https://arxiv.org/pdf/2509.04770.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04770v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04770v1', 'Research on Multi-hop Inference Optimization of LLM Based on MQUAKE Framework')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zucheng Liang, Wenxin Wei, Kaijie Zhang, Hongyi Chen

**ÂàÜÁ±ª**: cs.CL, cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-05

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âü∫‰∫éMQUAKEÊ°ÜÊû∂ÁöÑÂ§öË∑≥Êé®ÁêÜ‰ºòÂåñLLMÊñπÊ≥ïÔºåÊèêÂçáÂ§çÊùÇÈóÆÈ¢òÂõûÁ≠îÁ≤æÂ∫¶**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öË∑≥Êé®ÁêÜ` `ÈóÆÈ¢òÂàÜËß£` `Áü•ËØÜÂõæË∞±` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `LLAMA3` `LoRA` `MQUAKEÊ°ÜÊû∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Â§çÊùÇÈóÆÈ¢òÂõûÁ≠îÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÈöæ‰ª•ÂáÜÁ°ÆÁêÜËß£ÂíåÊé®ÁêÜÂ§öÊ≠•È™§ÈóÆÈ¢ò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Âü∫‰∫éMQUAKEÊ°ÜÊû∂ÁöÑÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ïÔºåÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫Â§ö‰∏™ÂçïË∑≥ÈóÆÈ¢òÔºåÈÄêÂ±ÇÊé®ÁêÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂ§öË∑≥ÂàÜËß£ÊñπÊ≥ïÂú®LLAMA3Ê®°Âûã‰∏äÊòæËëóÊèêÂçá‰∫ÜÂ§çÊùÇÈóÆÈ¢òÂõûÁ≠îÁöÑÂáÜÁ°ÆÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Êú™ÂæÆË∞ÉÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÈíàÂØπÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ÂáÜÁ°ÆÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÊñπÈù¢Èù¢‰∏¥ÁöÑÊåëÊàòÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éMQUAKEÊ°ÜÊû∂ÁöÑÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ï„ÄÇÂà©Áî®LLAMA3Ê®°ÂûãÔºåÁ≥ªÁªüÂú∞Á†îÁ©∂‰∫ÜÁü•ËØÜÂõæË∞±‰∏≠ÁöÑÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÂØπÊ®°ÂûãÁêÜËß£ÂíåÊé®ÁêÜÂáÜÁ°ÆÊÄßÁöÑÂΩ±ÂìçÔºåÂåÖÊã¨Ê®°ÂûãËÆ≠ÁªÉÂâçÂêé„ÄÇÂÆûÈ™å‰∏≠ÔºåÂ∞ÜMQUAKE-TÊï∞ÊçÆÈõÜÂàíÂàÜ‰∏∫ÂçïË∑≥Êï∞ÊçÆÈõÜÔºàÁõ¥Êé•ÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÔºâÂíåÂ§öË∑≥Êï∞ÊçÆÈõÜÔºà‰ΩøÁî®Â§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ïÊûÑÂª∫Ôºâ„ÄÇÁÑ∂ÂêéÔºå‰ΩøÁî®Ëøô‰∫õÊï∞ÊçÆÈõÜÂØπLLAMA3Ê®°ÂûãËøõË°åÂæÆË∞ÉÔºåÂπ∂ËøõË°åÊé®ÁêÜÊµãËØï„ÄÇÁªìÊûúË°®ÊòéÔºåÂú®‰∏çÂæÆË∞ÉLLMÁöÑÊÉÖÂÜµ‰∏ãÔºåÂü∫‰∫éÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ïÁöÑÈ¢ÑÊµãÊÄßËÉΩÊòéÊòæ‰ºò‰∫éÁõ¥Êé•ÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÁöÑÊñπÊ≥ï„ÄÇ‰ΩøÁî®LoRAÔºàLow-Rank AdaptationÔºâÊñπÊ≥ïËøõË°åÂæÆË∞ÉÂêéÔºå‰∏§ÁßçÊñπÊ≥ïÁöÑÊÄßËÉΩÂùá‰ºò‰∫éÊú™ËÆ≠ÁªÉÁöÑÂü∫Á∫ø„ÄÇÈáçË¶ÅÁöÑÊòØÔºåÂ§öË∑≥ÂàÜËß£ÊñπÊ≥ïÂßãÁªà‰øùÊåÅÂÖ∂‰ºòË∂äÊÄß„ÄÇËøô‰∫õÂèëÁé∞È™åËØÅ‰∫ÜÂ§öË∑≥ÂàÜËß£ÊñπÊ≥ïÂú®ËÆ≠ÁªÉÂâçÂêéÁöÑÊúâÊïàÊÄßÔºåËØÅÊòé‰∫ÜÂÖ∂ËÉΩÂ§üÊúâÊïàÊèêÈ´òLLMÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÁöÑËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Â§ÑÁêÜÈúÄË¶ÅÂ§öÊ≠•Êé®ÁêÜÁöÑÂ§çÊùÇÈóÆÈ¢òÊó∂ÔºåÂæÄÂæÄÈöæ‰ª•ÂáÜÁ°ÆÁêÜËß£ÈóÆÈ¢òÊÑèÂõæÂπ∂ËøõË°åÊúâÊïàÊé®ÁêÜ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Áõ¥Êé•ËÆ©Ê®°ÂûãÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÔºåÁº∫‰πèÂØπÈóÆÈ¢òÁªìÊûÑÁöÑÂà©Áî®ÔºåÂØºËá¥ÊÄßËÉΩÁì∂È¢à„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫Â§ö‰∏™ÁÆÄÂçïÁöÑÂçïË∑≥ÈóÆÈ¢òÔºåÈÄöËøáÈÄêÊ≠•Êé®ÁêÜÁöÑÊñπÂºèÔºåÊ®°Êãü‰∫∫Á±ªËß£ÂÜ≥Â§çÊùÇÈóÆÈ¢òÁöÑËøáÁ®ã„ÄÇËøôÁßçÂàÜËß£ÊñπÂºèËÉΩÂ§üÈôç‰ΩéÊØè‰∏™Ê≠•È™§ÁöÑÈöæÂ∫¶ÔºåÊèêÈ´òÊ®°ÂûãÁêÜËß£ÂíåÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºö1) ÈóÆÈ¢òÂàÜËß£Ôºö‰ΩøÁî®Â§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ïÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫Â§ö‰∏™ÂçïË∑≥ÈóÆÈ¢ò„ÄÇ2) Áü•ËØÜÂõæË∞±Êü•ËØ¢ÔºöÈíàÂØπÊØè‰∏™ÂçïË∑≥ÈóÆÈ¢òÔºåÂú®Áü•ËØÜÂõæË∞±‰∏≠ËøõË°åÊü•ËØ¢ÔºåËé∑ÂèñÁõ∏ÂÖ≥‰ø°ÊÅØ„ÄÇ3) Á≠îÊ°àÁîüÊàêÔºöÂà©Áî®LLMÊ†πÊçÆÊü•ËØ¢ÁªìÊûúÁîüÊàêÊØè‰∏™ÂçïË∑≥ÈóÆÈ¢òÁöÑÁ≠îÊ°à„ÄÇ4) Á≠îÊ°àÊï¥ÂêàÔºöÂ∞ÜÂêÑ‰∏™ÂçïË∑≥ÈóÆÈ¢òÁöÑÁ≠îÊ°àÊï¥ÂêàËµ∑Êù•ÔºåÂæóÂà∞ÊúÄÁªàÁöÑÂ§çÊùÇÈóÆÈ¢òÁ≠îÊ°à„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÊñπÊ≥ï„ÄÇ‰∏éÁõ¥Êé•ÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®Áü•ËØÜÂõæË∞±ÁöÑÁªìÊûÑ‰ø°ÊÅØÔºåÂ∞ÜÂ§çÊùÇÊé®ÁêÜËøáÁ®ãÂàÜËß£‰∏∫Â§ö‰∏™ÁÆÄÂçïÁöÑÊ≠•È™§Ôºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰ΩøÁî®MQUAKE-TÊï∞ÊçÆÈõÜËøõË°åÂÆûÈ™åÔºåÂπ∂Â∞ÜÂÖ∂ÂàíÂàÜ‰∏∫ÂçïË∑≥ÂíåÂ§öË∑≥‰∏§ÁßçÊ†ºÂºè„ÄÇÂú®Ê®°ÂûãÂæÆË∞ÉÊñπÈù¢ÔºåÈááÁî®‰∫ÜLoRAÔºàLow-Rank AdaptationÔºâÊñπÊ≥ïÔºå‰ª•Èôç‰ΩéËÆ≠ÁªÉÊàêÊú¨„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠Êú™ËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂú®Êú™ËøõË°åÂæÆË∞ÉÁöÑÊÉÖÂÜµ‰∏ãÔºåÂü∫‰∫éÂ§öË∑≥ÈóÆÈ¢òÂàÜËß£ÁöÑÊñπÊ≥ïÊòæËëó‰ºò‰∫éÁõ¥Êé•ÂõûÁ≠îÂ§çÊùÇÈóÆÈ¢òÁöÑÊñπÊ≥ï„ÄÇ‰ΩøÁî®LoRAËøõË°åÂæÆË∞ÉÂêéÔºå‰∏§ÁßçÊñπÊ≥ïÁöÑÊÄßËÉΩÂùáÂæóÂà∞ÊèêÂçáÔºå‰ΩÜÂ§öË∑≥ÂàÜËß£ÊñπÊ≥ïÂßãÁªà‰øùÊåÅ‰ºòÂäø„ÄÇËøôÈ™åËØÅ‰∫ÜÂ§öË∑≥ÂàÜËß£ÊñπÊ≥ïÂú®ÊèêÈ´òLLMÂ§çÊùÇÈóÆÈ¢òÂõûÁ≠îËÉΩÂäõÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÈóÆÁ≠îÁ≥ªÁªü„ÄÅÁü•ËØÜÂõæË∞±Êé®ÁêÜ„ÄÅÂåªÁñóËØäÊñ≠ËæÖÂä©Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÂ∞ÜÂ§çÊùÇÈóÆÈ¢òÂàÜËß£‰∏∫Â§ö‰∏™ÁÆÄÂçïÊ≠•È™§ÔºåÂèØ‰ª•ÊèêÈ´òLLMÂú®Ëøô‰∫õÈ¢ÜÂüüÁöÑÂ∫îÁî®ÊïàÊûúÔºå‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÂáÜÁ°Æ„ÄÅÊõ¥ÂèØÈù†ÁöÑÁ≠îÊ°àÂíåÂª∫ËÆÆ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõËøõ‰∏ÄÊ≠•ÊãìÂ±ïÂà∞ÂÖ∂‰ªñÈúÄË¶ÅÂ§çÊùÇÊé®ÁêÜÁöÑÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurately answering complex questions has consistently been a significant challenge for Large Language Models (LLMs). To address this, this paper proposes a multi-hop question decomposition method for complex questions, building upon research within the MQUAKE framework. Utilizing the LLAMA3 model, we systematically investigate the impact of multi-hop question decomposition within knowledge graphs on model comprehension and reasoning accuracy, both before and after model training. In our experiments, we systematically partitioned and converted the MQUAKE-T dataset into two distinct formats: a single-hop dataset designed for directly answering complex questions, and a multi-hop dataset constructed using the multi-hop question decomposition method. We then fine-tuned the LLAMA3 model on these datasets and conducted inference tests. Our results demonstrate that, without fine-tuning the LLM, the prediction performance based on the multi-hop question decomposition method significantly outperforms the method of directly answering complex questions. After fine-tuning using the LoRA (Low-Rank Adaptation) method, the performance of both approaches improved compared to the untrained baseline. Crucially, the method utilizing multi-hop decomposition consistently maintained its superiority. These findings validate the effectiveness of the multi-hop decomposition method both before and after training, demonstrating its capability to effectively enhance the LLM's ability to answer complex questions.

