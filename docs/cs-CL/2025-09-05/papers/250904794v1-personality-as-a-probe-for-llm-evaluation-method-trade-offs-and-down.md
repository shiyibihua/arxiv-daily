---
layout: default
title: Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects
---

# Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04794" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04794v1</a>
  <a href="https://arxiv.org/pdf/2509.04794.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04794v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04794v1', 'Personality as a Probe for LLM Evaluation: Method Trade-offs and Downstream Effects')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gunmay Handa, Zekun Wu, Adriano Koshiyama, Philip Treleaven

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡äººæ ¼æ“æ§è¯„ä¼°LLMï¼šæ–¹æ³•æƒè¡¡ä¸ä¸‹æ¸¸å½±å“åˆ†æ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæ ¼æ“æ§` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `æœºåˆ¶å¼•å¯¼` `è¯„ä¼°æ¡†æ¶` `ç¨³å®šæ€§åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMäººæ ¼æ“æ§æ–¹æ³•åœ¨æœºåˆ¶å’Œæƒè¡¡æ–¹é¢å­˜åœ¨ä¸æ¸…æ™°ä¹‹å¤„ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„ç ”ç©¶å’Œè¯„ä¼°ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§äº”äººæ ¼ç‰¹è´¨çš„ç³»ç»Ÿç ”ç©¶æ–¹æ³•ï¼Œæ¯”è¾ƒäº†ICLã€PEFTå’ŒMSä¸‰ç§äººæ ¼æ§åˆ¶æ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒICLåœ¨èƒ½åŠ›æŸå¤±æœ€å°çš„æƒ…å†µä¸‹å®ç°å¼ºå¯¹é½ï¼ŒPEFTå¯¹é½åº¦æœ€é«˜ä½†ç‰ºç‰²äº†ä»»åŠ¡æ€§èƒ½ï¼ŒMSæä¾›è½»é‡çº§è¿è¡Œæ—¶æ§åˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­çš„äººæ ¼æ“æ§è¶Šæ¥è¶Šå¤šåœ°åº”ç”¨äºå®¢æˆ·æœåŠ¡å’Œæ™ºèƒ½ä½“åœºæ™¯ï¼Œä½†å…¶æœºåˆ¶å’Œæƒè¡¡ä»ä¸æ¸…æ¥šã€‚æœ¬æ–‡å¯¹ä½¿ç”¨å¤§äº”äººæ ¼ç‰¹è´¨è¿›è¡Œäººæ ¼æ§åˆ¶è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œæ¯”è¾ƒäº†ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ã€å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰å’Œæœºåˆ¶å¼•å¯¼ï¼ˆMSï¼‰ã€‚ä¸»è¦è´¡çŒ®æœ‰å››ç‚¹ï¼šæ„å»ºäº†ä¸€ä¸ªå…·æœ‰å¹³è¡¡çš„é«˜/ä½ç‰¹è´¨å“åº”çš„å¯¹æ¯”æ•°æ®é›†ï¼Œä»è€Œèƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„å¼•å¯¼å‘é‡è®¡ç®—å’Œå…¬å¹³çš„è·¨æ–¹æ³•è¯„ä¼°ï¼›å¼•å…¥äº†ä¸€ä¸ªåŸºäºè¿è¡Œå†…$Î”$åˆ†æçš„ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶è§£è€¦äº†MMLUã€GAIAå’ŒBBQåŸºå‡†æµ‹è¯•ä¸­çš„æ¨ç†èƒ½åŠ›ã€æ™ºèƒ½ä½“æ€§èƒ½å’Œäººå£ç»Ÿè®¡åå·®ï¼›å¼€å‘äº†ç‰¹è´¨çº¯åŒ–æŠ€æœ¯ï¼Œä»¥åˆ†ç¦»å¼€æ”¾æ€§å’Œè´£ä»»å¿ƒï¼Œè§£å†³ç‰¹è´¨ç¼–ç ä¸­çš„è¡¨å¾é‡å é—®é¢˜ï¼›æå‡ºäº†ä¸€ä¸ªä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é‡åŒ–äº†æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆçº§åˆ«çš„é²æ£’æ€§ï¼Œå¹¶åœ¨éƒ¨ç½²çº¦æŸä¸‹æä¾›å®ç”¨æŒ‡å¯¼ã€‚åœ¨Gemma-2-2B-ITå’ŒLLaMA-3-8B-Instructä¸Šçš„å®éªŒæ­ç¤ºäº†æ˜ç¡®çš„æƒè¡¡ï¼šICLåœ¨æœ€å°èƒ½åŠ›æŸå¤±çš„æƒ…å†µä¸‹å®ç°äº†å¼ºå¤§çš„å¯¹é½ï¼ŒPEFTä»¥é™ä½ä»»åŠ¡æ€§èƒ½ä¸ºä»£ä»·æä¾›äº†æœ€é«˜çš„å¯¹é½ï¼Œè€ŒMSæä¾›äº†å…·æœ‰ç«äº‰åŠ›çš„æœ‰æ•ˆæ€§çš„è½»é‡çº§è¿è¡Œæ—¶æ§åˆ¶ã€‚ç‰¹è´¨æ°´å¹³åˆ†æè¡¨æ˜ï¼Œå¼€æ”¾æ€§æ˜¯ç‹¬ä¸€æ— äºŒçš„æŒ‘æˆ˜ï¼Œå®œäººæ€§æœ€èƒ½æŠµæŠ—ICLï¼Œå¹¶ä¸”äººæ ¼ç¼–ç åœ¨ä¸­é—´å±‚å‘¨å›´å·©å›ºã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¿™äº›ç»“æœå°†äººæ ¼æ“çºµç¡®ç«‹ä¸ºå¯¹è¡Œä¸ºè¡¨å¾çš„å¤šå±‚æ¬¡æ¢æµ‹ï¼Œå°†è¡¨é¢æ¡ä»¶ã€å‚æ•°ç¼–ç å’Œæ¿€æ´»æ°´å¹³å¼•å¯¼è”ç³»èµ·æ¥ï¼Œå¹¶å°†æœºåˆ¶å¼•å¯¼å®šä½ä¸ºå¾®è°ƒçš„ä¸€ç§è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆï¼Œç”¨äºéƒ¨ç½²å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­äººæ ¼æ“æ§æœºåˆ¶ä¸æ˜ç¡®ï¼Œç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°å’Œæ¯”è¾ƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å’Œå¾®è°ƒï¼ˆFine-tuningï¼‰ï¼Œåœ¨äººæ ¼æ§åˆ¶çš„æœ‰æ•ˆæ€§ã€å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ä»¥åŠé²æ£’æ€§æ–¹é¢å­˜åœ¨æƒè¡¡ï¼Œå¹¶ä¸”ç¼ºä¹ç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºå¯¹æ¯”æ•°æ®é›†ã€å¼•å…¥ç»Ÿä¸€è¯„ä¼°æ¡†æ¶å’Œå¼€å‘ç‰¹è´¨çº¯åŒ–æŠ€æœ¯ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶å’Œæ¯”è¾ƒICLã€å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰å’Œæœºåˆ¶å¼•å¯¼ï¼ˆMSï¼‰ä¸‰ç§äººæ ¼æ§åˆ¶æ–¹æ³•ã€‚é€šè¿‡é‡åŒ–æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆçº§åˆ«çš„é²æ£’æ€§ï¼Œä¸ºå®é™…éƒ¨ç½²æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **å¯¹æ¯”æ•°æ®é›†æ„å»º**ï¼šæ„å»ºåŒ…å«é«˜/ä½ç‰¹è´¨å“åº”çš„å¹³è¡¡æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°ã€‚
2. **ç»Ÿä¸€è¯„ä¼°æ¡†æ¶**ï¼šåŸºäºè¿è¡Œå†…$Î”$åˆ†æï¼Œè¯„ä¼°æ¨ç†èƒ½åŠ›ã€æ™ºèƒ½ä½“æ€§èƒ½å’Œäººå£ç»Ÿè®¡åå·®ã€‚
3. **ç‰¹è´¨çº¯åŒ–**ï¼šå¼€å‘æŠ€æœ¯åˆ†ç¦»å¼€æ”¾æ€§å’Œè´£ä»»å¿ƒï¼Œè§£å†³ç‰¹è´¨ç¼–ç ä¸­çš„è¡¨å¾é‡å é—®é¢˜ã€‚
4. **ç¨³å®šæ€§åˆ†æ**ï¼šæå‡ºä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ï¼Œé‡åŒ–æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆçº§åˆ«çš„é²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
1. **å¯¹æ¯”æ•°æ®é›†**ï¼šæ„å»ºäº†ç”¨äºäººæ ¼æ§åˆ¶çš„å¯¹æ¯”æ•°æ®é›†ï¼Œèƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„å¼•å¯¼å‘é‡è®¡ç®—å’Œå…¬å¹³çš„è·¨æ–¹æ³•è¯„ä¼°ã€‚
2. **ç»Ÿä¸€è¯„ä¼°æ¡†æ¶**ï¼šæå‡ºäº†åŸºäºè¿è¡Œå†…$Î”$åˆ†æçš„ç»Ÿä¸€è¯„ä¼°æ¡†æ¶ï¼Œèƒ½å¤Ÿè§£è€¦æ¨ç†èƒ½åŠ›ã€æ™ºèƒ½ä½“æ€§èƒ½å’Œäººå£ç»Ÿè®¡åå·®ã€‚
3. **ç‰¹è´¨çº¯åŒ–æŠ€æœ¯**ï¼šå¼€å‘äº†ç‰¹è´¨çº¯åŒ–æŠ€æœ¯ï¼Œèƒ½å¤Ÿåˆ†ç¦»å¼€æ”¾æ€§å’Œè´£ä»»å¿ƒï¼Œè§£å†³ç‰¹è´¨ç¼–ç ä¸­çš„è¡¨å¾é‡å é—®é¢˜ã€‚
4. **ä¸‰çº§ç¨³å®šæ€§æ¡†æ¶**ï¼šæå‡ºäº†ä¸‰çº§ç¨³å®šæ€§æ¡†æ¶ï¼Œèƒ½å¤Ÿé‡åŒ–æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆçº§åˆ«çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š
1. **å¯¹æ¯”æ•°æ®é›†çš„æ„å»º**ï¼šç¡®ä¿æ•°æ®é›†åœ¨é«˜/ä½ç‰¹è´¨å“åº”ä¹‹é—´ä¿æŒå¹³è¡¡ï¼Œä»¥æé«˜å¼•å¯¼å‘é‡è®¡ç®—çš„å‡†ç¡®æ€§ã€‚
2. **è¿è¡Œå†…$Î”$åˆ†æ**ï¼šé€šè¿‡åˆ†æè¿è¡Œè¿‡ç¨‹ä¸­æ€§èƒ½çš„å˜åŒ–ï¼Œè¯„ä¼°äººæ ¼æ§åˆ¶å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚
3. **ç‰¹è´¨çº¯åŒ–æŠ€æœ¯çš„å®ç°**ï¼šé‡‡ç”¨ç‰¹å®šçš„ç®—æ³•æˆ–æ¨¡å‹æ¥åˆ†ç¦»å¼€æ”¾æ€§å’Œè´£ä»»å¿ƒï¼Œå‡å°‘ç‰¹è´¨ä¹‹é—´çš„å¹²æ‰°ã€‚
4. **ä¸‰çº§ç¨³å®šæ€§æ¡†æ¶çš„å®šä¹‰**ï¼šæ˜ç¡®å®šä¹‰æ–¹æ³•ã€ç‰¹è´¨å’Œç»„åˆçº§åˆ«çš„é²æ£’æ€§æŒ‡æ ‡ï¼Œå¹¶è®¾è®¡ç›¸åº”çš„è¯„ä¼°æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒICLåœ¨æœ€å°èƒ½åŠ›æŸå¤±çš„æƒ…å†µä¸‹å®ç°äº†å¼ºå¤§çš„å¯¹é½ï¼ŒPEFTä»¥é™ä½ä»»åŠ¡æ€§èƒ½ä¸ºä»£ä»·æä¾›äº†æœ€é«˜çš„å¯¹é½ï¼Œè€ŒMSæä¾›äº†å…·æœ‰ç«äº‰åŠ›çš„æœ‰æ•ˆæ€§çš„è½»é‡çº§è¿è¡Œæ—¶æ§åˆ¶ã€‚ç‰¹è´¨æ°´å¹³åˆ†æè¡¨æ˜ï¼Œå¼€æ”¾æ€§æ˜¯ç‹¬ä¸€æ— äºŒçš„æŒ‘æˆ˜ï¼Œå®œäººæ€§æœ€èƒ½æŠµæŠ—ICLã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå®¢æˆ·æœåŠ¡ã€è™šæ‹ŸåŠ©æ‰‹ã€æ¸¸æˆè§’è‰²æ‰®æ¼”ç­‰é¢†åŸŸï¼Œé€šè¿‡äººæ ¼æ“æ§æå‡ç”¨æˆ·ä½“éªŒå’Œäº¤äº’æ•ˆæœã€‚ç ”ç©¶æä¾›çš„è¯„ä¼°æ¡†æ¶å’Œç¨³å®šæ€§åˆ†ææ–¹æ³•ï¼Œæœ‰åŠ©äºå¼€å‘è€…é€‰æ‹©åˆé€‚çš„äººæ ¼æ§åˆ¶æ–¹æ³•ï¼Œå¹¶ä¼˜åŒ–æ¨¡å‹éƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Personality manipulation in large language models (LLMs) is increasingly applied in customer service and agentic scenarios, yet its mechanisms and trade-offs remain unclear. We present a systematic study of personality control using the Big Five traits, comparing in-context learning (ICL), parameter-efficient fine-tuning (PEFT), and mechanistic steering (MS). Our contributions are fourfold. First, we construct a contrastive dataset with balanced high/low trait responses, enabling effective steering vector computation and fair cross-method evaluation. Second, we introduce a unified evaluation framework based on within-run $Î”$ analysis that disentangles, reasoning capability, agent performance, and demographic bias across MMLU, GAIA, and BBQ benchmarks. Third, we develop trait purification techniques to separate openness from conscientiousness, addressing representational overlap in trait encoding. Fourth, we propose a three-level stability framework that quantifies method-, trait-, and combination-level robustness, offering practical guidance under deployment constraints. Experiments on Gemma-2-2B-IT and LLaMA-3-8B-Instruct reveal clear trade-offs: ICL achieves strong alignment with minimal capability loss, PEFT delivers the highest alignment at the cost of degraded task performance, and MS provides lightweight runtime control with competitive effectiveness. Trait-level analysis shows openness as uniquely challenging, agreeableness as most resistant to ICL, and personality encoding consolidating around intermediate layers. Taken together, these results establish personality manipulation as a multi-level probe into behavioral representation, linking surface conditioning, parameter encoding, and activation-level steering, and positioning mechanistic steering as a lightweight alternative to fine-tuning for both deployment and interpretability.

