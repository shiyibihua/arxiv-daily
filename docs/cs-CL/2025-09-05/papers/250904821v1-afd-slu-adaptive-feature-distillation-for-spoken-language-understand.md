---
layout: default
title: AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding
---

# AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04821" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04821v1</a>
  <a href="https://arxiv.org/pdf/2509.04821.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04821v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04821v1', 'AFD-SLU: Adaptive Feature Distillation for Spoken Language Understanding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yan Xie, Yibo Cui, Liang Xie, Erwei Yin

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: 5 pages, 1 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAFD-SLUæ¡†æ¶ï¼Œé€šè¿‡è‡ªé€‚åº”ç‰¹å¾è’¸é¦æå‡å£è¯­ç†è§£æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å£è¯­ç†è§£` `ç‰¹å¾è’¸é¦` `åŠ¨æ€é€‚é…å™¨` `æ®‹å·®æŠ•å½±ç¥ç»ç½‘ç»œ` `åŠ¨æ€è’¸é¦ç³»æ•°` `å¯¹è¯ç³»ç»Ÿ` `çŸ¥è¯†è¿ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å£è¯­ç†è§£ä»»åŠ¡é¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œå¤§å‹è¯­è¨€æ¨¡å‹è®¡ç®—å¼€é”€å¤§çš„æŒ‘æˆ˜ã€‚
2. æå‡ºè‡ªé€‚åº”ç‰¹å¾è’¸é¦æ¡†æ¶ï¼Œåˆ©ç”¨åŠ¨æ€é€‚é…å™¨å’ŒåŠ¨æ€è’¸é¦ç³»æ•°ï¼Œå°†GTEæ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°è½»é‡çº§å­¦ç”Ÿæ¨¡å‹ã€‚
3. åœ¨ProSLUåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAFD-SLUå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œæ˜¾è‘—æå‡äº†æ„å›¾è¯†åˆ«ã€æ§½ä½å¡«å……å’Œæ•´ä½“å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å£è¯­ç†è§£ï¼ˆSLUï¼‰æ˜¯å¯¹è¯ç³»ç»Ÿçš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œä½¿æœºå™¨èƒ½å¤Ÿç†è§£ç”¨æˆ·çš„è¯­éŸ³ã€‚å°½ç®¡å…¶é‡è¦æ€§ï¼Œä½†ç”±äºæ ‡è®°è®­ç»ƒæ•°æ®çš„ç¨€ç¼ºä»¥åŠåœ¨å®é™…åº”ç”¨ä¸­éƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è®¡ç®—è´Ÿæ‹…ï¼Œå¼€å‘æœ‰æ•ˆçš„SLUç³»ç»Ÿä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†è¿›ä¸€æ­¥ç¼“è§£è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè‡ªé€‚åº”ç‰¹å¾è’¸é¦æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†åŸºäºé€šç”¨æ–‡æœ¬åµŒå…¥ï¼ˆGTEï¼‰çš„æ•™å¸ˆæ¨¡å‹çš„ä¸°å¯Œè¯­ä¹‰è¡¨ç¤ºè½¬ç§»åˆ°è½»é‡çº§çš„å­¦ç”Ÿæ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†ä¸€ä¸ªé…å¤‡æ®‹å·®æŠ•å½±ç¥ç»ç½‘ç»œï¼ˆRPNNï¼‰çš„åŠ¨æ€é€‚é…å™¨ï¼Œä»¥å¯¹é½å¼‚æ„ç‰¹å¾ç©ºé—´ï¼Œä»¥åŠä¸€ä¸ªåŠ¨æ€è’¸é¦ç³»æ•°ï¼ˆDDCï¼‰ï¼Œè¯¥ç³»æ•°åŸºäºæ„å›¾å’Œæ§½ä½é¢„æµ‹æ€§èƒ½çš„å®æ—¶åé¦ˆè‡ªé€‚åº”åœ°è°ƒèŠ‚è’¸é¦å¼ºåº¦ã€‚åœ¨åŸºäºä¸­æ–‡é…ç½®æ–‡ä»¶çš„ProSLUåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAFD-SLUå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œæ„å›¾å‡†ç¡®ç‡ä¸º95.67ï¼…ï¼Œæ§½ä½F1å¾—åˆ†ä¸º92.02ï¼…ï¼Œæ€»ä½“å‡†ç¡®ç‡ä¸º85.50ï¼…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå£è¯­ç†è§£ï¼ˆSLUï¼‰æ—¨åœ¨ç†è§£ç”¨æˆ·è¯­éŸ³ä¸­çš„æ„å›¾å’Œæ§½ä½ä¿¡æ¯ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œå¹¶æœ‰æ•ˆåˆ©ç”¨å°‘é‡æ ‡æ³¨æ•°æ®ï¼Œæ˜¯å½“å‰SLUç ”ç©¶é¢ä¸´çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç‰¹å¾è’¸é¦ï¼Œå°†å¤§å‹é€šç”¨æ–‡æœ¬åµŒå…¥ï¼ˆGTEï¼‰æ¨¡å‹å­¦ä¹ åˆ°çš„ä¸°å¯Œè¯­ä¹‰ä¿¡æ¯è¿ç§»åˆ°è½»é‡çº§çš„å­¦ç”Ÿæ¨¡å‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå­¦ç”Ÿæ¨¡å‹å¯ä»¥åœ¨ä¿æŒè¾ƒä½è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œè·å¾—æ¥è¿‘æ•™å¸ˆæ¨¡å‹çš„æ€§èƒ½ã€‚å…³é”®åœ¨äºå¦‚ä½•æœ‰æ•ˆåœ°å¯¹é½æ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹ä¹‹é—´çš„å¼‚æ„ç‰¹å¾ç©ºé—´ï¼Œå¹¶è‡ªé€‚åº”åœ°è°ƒæ•´è’¸é¦å¼ºåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAFD-SLUæ¡†æ¶åŒ…å«ä¸€ä¸ªåŸºäºGTEçš„æ•™å¸ˆæ¨¡å‹å’Œä¸€ä¸ªè½»é‡çº§çš„å­¦ç”Ÿæ¨¡å‹ã€‚æ•™å¸ˆæ¨¡å‹è´Ÿè´£æå–è¾“å…¥æ–‡æœ¬çš„è¯­ä¹‰è¡¨ç¤ºï¼Œå­¦ç”Ÿæ¨¡å‹åˆ™åŸºäºè¿™äº›è¡¨ç¤ºè¿›è¡Œæ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……ã€‚æ¡†æ¶çš„æ ¸å¿ƒæ˜¯åŠ¨æ€é€‚é…å™¨å’ŒåŠ¨æ€è’¸é¦ç³»æ•°ã€‚åŠ¨æ€é€‚é…å™¨ä½¿ç”¨æ®‹å·®æŠ•å½±ç¥ç»ç½‘ç»œï¼ˆRPNNï¼‰æ¥å¯¹é½æ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹çš„ç‰¹å¾ç©ºé—´ã€‚åŠ¨æ€è’¸é¦ç³»æ•°ï¼ˆDDCï¼‰æ ¹æ®æ„å›¾å’Œæ§½ä½é¢„æµ‹çš„å®æ—¶åé¦ˆï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´è’¸é¦å¼ºåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åŠ¨æ€é€‚é…å™¨å’ŒåŠ¨æ€è’¸é¦ç³»æ•°ã€‚åŠ¨æ€é€‚é…å™¨èƒ½å¤Ÿæœ‰æ•ˆåœ°å¯¹é½å¼‚æ„ç‰¹å¾ç©ºé—´ï¼Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°å­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ã€‚åŠ¨æ€è’¸é¦ç³»æ•°èƒ½å¤Ÿæ ¹æ®æ¨¡å‹çš„å®é™…è¡¨ç°è‡ªé€‚åº”åœ°è°ƒæ•´è’¸é¦å¼ºåº¦ï¼Œé¿å…äº†å›ºå®šè’¸é¦ç³»æ•°å¯èƒ½å¯¼è‡´çš„æ¬ æ‹Ÿåˆæˆ–è¿‡æ‹Ÿåˆé—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€é€‚é…å™¨é‡‡ç”¨æ®‹å·®æŠ•å½±ç¥ç»ç½‘ç»œï¼ˆRPNNï¼‰ï¼ŒåŒ…å«å¤šä¸ªçº¿æ€§å±‚å’Œéçº¿æ€§æ¿€æ´»å‡½æ•°ï¼Œç”¨äºå°†æ•™å¸ˆæ¨¡å‹çš„ç‰¹å¾æŠ•å½±åˆ°å­¦ç”Ÿæ¨¡å‹çš„ç‰¹å¾ç©ºé—´ã€‚åŠ¨æ€è’¸é¦ç³»æ•°ï¼ˆDDCï¼‰çš„è®¡ç®—æ–¹å¼å¦‚ä¸‹ï¼šé¦–å…ˆè®¡ç®—æ„å›¾è¯†åˆ«å’Œæ§½ä½å¡«å……çš„æŸå¤±å‡½æ•°ï¼Œç„¶åæ ¹æ®è¿™äº›æŸå¤±å‡½æ•°çš„å€¼ï¼Œä½¿ç”¨ä¸€ä¸ªsigmoidå‡½æ•°æ¥è®¡ç®—è’¸é¦ç³»æ•°ã€‚è’¸é¦ç³»æ•°çš„å–å€¼èŒƒå›´åœ¨0åˆ°1ä¹‹é—´ï¼Œç”¨äºæ§åˆ¶æ•™å¸ˆæ¨¡å‹çŸ¥è¯†å¯¹å­¦ç”Ÿæ¨¡å‹çš„å½±å“ç¨‹åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AFD-SLUåœ¨ProSLUåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“æ¥è¯´ï¼Œæ„å›¾å‡†ç¡®ç‡è¾¾åˆ°äº†95.67%ï¼Œæ§½ä½F1å¾—åˆ†è¾¾åˆ°äº†92.02%ï¼Œæ•´ä½“å‡†ç¡®ç‡è¾¾åˆ°äº†85.50%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAFD-SLUæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°å­¦ç”Ÿæ¨¡å‹ï¼Œå¹¶åœ¨å®é™…åº”ç”¨ä¸­å–å¾—è‰¯å¥½çš„æ•ˆæœã€‚ç›¸è¾ƒäºå…¶ä»–åŸºçº¿æ¨¡å‹ï¼ŒAFD-SLUåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡å–å¾—äº†é¢†å…ˆä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AFD-SLUæ¡†æ¶å¯åº”ç”¨äºå„ç§å¯¹è¯ç³»ç»Ÿï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€èŠå¤©æœºå™¨äººå’Œè¯­éŸ³æœç´¢ç­‰ã€‚é€šè¿‡é™ä½æ¨¡å‹å¤æ‚åº¦å’Œæé«˜æ•°æ®åˆ©ç”¨ç‡ï¼Œè¯¥æ–¹æ³•å¯ä»¥å¸®åŠ©å¼€å‘è€…æ„å»ºæ›´é«˜æ•ˆã€æ›´ç»æµçš„å£è¯­ç†è§£ç³»ç»Ÿï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸‹ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰åŠ©äºæ¨åŠ¨äººæœºäº¤äº’æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºæ›´æ™ºèƒ½åŒ–çš„è¯­éŸ³åº”ç”¨æä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spoken Language Understanding (SLU) is a core component of conversational systems, enabling machines to interpret user utterances. Despite its importance, developing effective SLU systems remains challenging due to the scarcity of labeled training data and the computational burden of deploying Large Language Models (LLMs) in real-world applications. To further alleviate these issues, we propose an Adaptive Feature Distillation framework that transfers rich semantic representations from a General Text Embeddings (GTE)-based teacher model to a lightweight student model. Our method introduces a dynamic adapter equipped with a Residual Projection Neural Network (RPNN) to align heterogeneous feature spaces, and a Dynamic Distillation Coefficient (DDC) that adaptively modulates the distillation strength based on real-time feedback from intent and slot prediction performance. Experiments on the Chinese profile-based ProSLU benchmark demonstrate that AFD-SLU achieves state-of-the-art results, with 95.67% intent accuracy, 92.02% slot F1 score, and 85.50% overall accuracy.

