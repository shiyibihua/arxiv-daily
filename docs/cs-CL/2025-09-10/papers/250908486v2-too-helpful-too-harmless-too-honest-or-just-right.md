---
layout: default
title: Too Helpful, Too Harmless, Too Honest or Just Right?
---

# Too Helpful, Too Harmless, Too Honest or Just Right?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08486" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08486v2</a>
  <a href="https://arxiv.org/pdf/2509.08486.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08486v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08486v2', 'Too Helpful, Too Harmless, Too Honest or Just Right?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gautam Siddharth Kashyap, Mark Dras, Usman Naseem

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10 (æ›´æ–°: 2025-09-15)

**å¤‡æ³¨**: EMNLP'25 Main

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TrinityXï¼šæå‡ºä¸€ç§åŸºäºæ ¡å‡†ä¸“å®¶æ··åˆçš„æ¨¡å—åŒ–å¯¹é½æ¡†æ¶ï¼Œæå‡LLMçš„HHHå¯¹é½æ•ˆæœã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é½` `æ··åˆä¸“å®¶æ¨¡å‹` `æ ¡å‡†è·¯ç”±` `æœ‰ç”¨æ€§` `æ— å®³æ€§` `è¯šå®æ€§` `æ¨¡å—åŒ–æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMå¯¹é½æ–¹æ³•é€šå¸¸å­¤ç«‹ä¼˜åŒ–æœ‰ç”¨æ€§ã€æ— å®³æ€§å’Œè¯šå®æ€§ï¼Œå¯¼è‡´æ€§èƒ½æƒè¡¡å’Œè¡Œä¸ºä¸ä¸€è‡´ã€‚
2. TrinityXæå‡ºäº†ä¸€ç§æ¨¡å—åŒ–æ¡†æ¶ï¼Œåˆ©ç”¨æ ¡å‡†ä¸“å®¶æ··åˆ(MoCaE)åœ¨Transformerä¸­å®ç°å¯¹é½ï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTrinityXåœ¨HHHä¸‰ä¸ªç»´åº¦ä¸Šå‡ä¼˜äºç°æœ‰åŸºçº¿ï¼Œä¸”æ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨å’Œæ¨ç†å»¶è¿Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨å„ç§NLPä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä½¿å…¶è¾“å‡ºç¬¦åˆHelpfulnessï¼ˆæœ‰ç”¨æ€§ï¼‰ã€Harmlessnessï¼ˆæ— å®³æ€§ï¼‰å’ŒHonestyï¼ˆè¯šå®æ€§ï¼‰(HHH)åŸåˆ™ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å­¤ç«‹åœ°ä¼˜åŒ–å•ä¸ªå¯¹é½ç»´åº¦ï¼Œå¯¼è‡´æƒè¡¡å’Œä¸ä¸€è‡´çš„è¡Œä¸ºã€‚æ··åˆä¸“å®¶(MoE)æ¶æ„è™½ç„¶æä¾›äº†æ¨¡å—åŒ–ï¼Œä½†å…¶è·¯ç”±æ ¡å‡†ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åœ¨å¯¹é½ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬æå‡ºäº†TrinityXï¼Œä¸€ä¸ªæ¨¡å—åŒ–å¯¹é½æ¡†æ¶ï¼Œå®ƒåœ¨Transformeræ¶æ„ä¸­ç»“åˆäº†æ ¡å‡†ä¸“å®¶æ··åˆ(MoCaE)ã€‚TrinityXåˆ©ç”¨ä¸ºæ¯ä¸ªHHHç»´åº¦å•ç‹¬è®­ç»ƒçš„ä¸“å®¶ï¼Œé€šè¿‡æ ¡å‡†çš„ã€ä»»åŠ¡è‡ªé€‚åº”çš„è·¯ç”±æœºåˆ¶æ•´åˆå®ƒä»¬çš„è¾“å‡ºï¼Œå°†ä¸“å®¶ä¿¡å·ç»„åˆæˆç»Ÿä¸€çš„ã€å¯¹é½æ„ŸçŸ¥çš„è¡¨ç¤ºã€‚åœ¨ä¸‰ä¸ªæ ‡å‡†å¯¹é½åŸºå‡†Alpaca (Helpfulness)ã€BeaverTails (Harmlessness)å’ŒTruthfulQA (Honesty)ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒTrinityXä¼˜äºå¼ºå¤§çš„åŸºçº¿ï¼Œåœ¨èƒœç‡ã€å®‰å…¨è¯„åˆ†å’ŒçœŸå®æ€§æ–¹é¢åˆ†åˆ«å®ç°äº†32.5%ã€33.9%å’Œ28.4%çš„ç›¸å¯¹æ”¹è¿›ã€‚æ­¤å¤–ï¼Œä¸ä¹‹å‰çš„åŸºäºMoEçš„æ–¹æ³•ç›¸æ¯”ï¼ŒTrinityXå‡å°‘äº†è¶…è¿‡40%çš„å†…å­˜ä½¿ç”¨å’Œæ¨ç†å»¶è¿Ÿã€‚æ¶ˆèç ”ç©¶çªå‡ºäº†æ ¡å‡†è·¯ç”±çš„é‡è¦æ€§ï¼Œè·¨æ¨¡å‹è¯„ä¼°è¯å®äº†TrinityXåœ¨ä¸åŒLLMéª¨å¹²ä¸Šçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨Helpfulnessï¼ˆæœ‰ç”¨æ€§ï¼‰ã€Harmlessnessï¼ˆæ— å®³æ€§ï¼‰å’ŒHonestyï¼ˆè¯šå®æ€§ï¼‰(HHH)ä¸‰ä¸ªç»´åº¦ä¸Šçš„å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç‹¬ç«‹ä¼˜åŒ–è¿™ä¸‰ä¸ªç»´åº¦ï¼Œå¯¼è‡´æ¨¡å‹åœ¨ä¸åŒç»´åº¦ä¸Šè¡¨ç°ä¸ä¸€è‡´ï¼Œéš¾ä»¥å®ç°å…¨å±€æœ€ä¼˜ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ–¹æ³•è™½ç„¶å…·æœ‰æ¨¡å—åŒ–ä¼˜åŠ¿ï¼Œä½†å…¶è·¯ç”±æœºåˆ¶æ ¡å‡†ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨ä¸åŒä¸“å®¶çš„çŸ¥è¯†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTrinityXçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªæ¨¡å—åŒ–çš„å¯¹é½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤ŸåŒæ—¶è€ƒè™‘LLMçš„æœ‰ç”¨æ€§ã€æ— å®³æ€§å’Œè¯šå®æ€§ã€‚é€šè¿‡å¼•å…¥æ ¡å‡†ä¸“å®¶æ··åˆï¼ˆMoCaEï¼‰æœºåˆ¶ï¼ŒTrinityXèƒ½å¤Ÿæ ¹æ®ä»»åŠ¡è‡ªé€‚åº”åœ°æ•´åˆä¸åŒä¸“å®¶çš„è¾“å‡ºï¼Œä»è€Œå®ç°æ›´å¥½çš„å¯¹é½æ•ˆæœã€‚è¿™ç§è®¾è®¡å…è®¸æ¨¡å‹åœ¨ä¸åŒç»´åº¦ä¸Šè¿›è¡Œæƒè¡¡ï¼Œå¹¶é¿å…äº†ç°æœ‰æ–¹æ³•ä¸­å¸¸è§çš„æ€§èƒ½å†²çªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTrinityXçš„æ ¸å¿ƒæ˜¯Transformeræ¶æ„ï¼Œå¹¶åœ¨å…¶ä¸­é›†æˆäº†MoCaEæ¨¡å—ã€‚æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼šé¦–å…ˆï¼Œä¸ºæ¯ä¸ªHHHç»´åº¦è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„ä¸“å®¶æ¨¡å‹ã€‚ç„¶åï¼ŒMoCaEæ¨¡å—æ¥æ”¶æ¥è‡ªä¸åŒä¸“å®¶çš„è¾“å‡ºï¼Œå¹¶ä½¿ç”¨ä¸€ä¸ªæ ¡å‡†çš„è·¯ç”±æœºåˆ¶æ¥ç¡®å®šæ¯ä¸ªä¸“å®¶çš„æƒé‡ã€‚æœ€åï¼Œå°†åŠ æƒåçš„ä¸“å®¶è¾“å‡ºç»„åˆæˆä¸€ä¸ªç»Ÿä¸€çš„è¡¨ç¤ºï¼Œç”¨äºç”Ÿæˆæœ€ç»ˆçš„LLMè¾“å‡ºã€‚è¯¥æ¡†æ¶å…è®¸åœ¨Transformerçš„å¤šä¸ªå±‚ä¸­æ’å…¥MoCaEæ¨¡å—ï¼Œä»¥å®ç°æ›´ç²¾ç»†çš„å¯¹é½æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šTrinityXçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†æ ¡å‡†ä¸“å®¶æ··åˆï¼ˆMoCaEï¼‰æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„MoEæ–¹æ³•ç›¸æ¯”ï¼ŒMoCaEä½¿ç”¨ä¸€ä¸ªæ ¡å‡†çš„è·¯ç”±æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°æ¯ä¸ªä¸“å®¶çš„è´¡çŒ®ï¼Œå¹¶æ ¹æ®ä»»åŠ¡è‡ªé€‚åº”åœ°è°ƒæ•´å…¶æƒé‡ã€‚è¿™ç§æ ¡å‡†æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆè§£å†³ç°æœ‰MoEæ–¹æ³•ä¸­è·¯ç”±ä¸å‡†ç¡®çš„é—®é¢˜ï¼Œä»è€Œæé«˜å¯¹é½æ•ˆæœã€‚æ­¤å¤–ï¼ŒTrinityXçš„æ¨¡å—åŒ–è®¾è®¡ä½¿å¾—å¯ä»¥è½»æ¾åœ°æ‰©å±•åˆ°æ›´å¤šçš„å¯¹é½ç»´åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šMoCaEæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç‹¬ç«‹çš„ä¸“å®¶æ¨¡å‹æ¥å¤„ç†ä¸åŒçš„HHHç»´åº¦ï¼›2) ä½¿ç”¨ä¸€ä¸ªå¯å­¦ä¹ çš„è·¯ç”±ç½‘ç»œæ¥ç¡®å®šæ¯ä¸ªä¸“å®¶çš„æƒé‡ï¼›3) ä½¿ç”¨ä¸€ä¸ªæ ¡å‡†å‡½æ•°æ¥è°ƒæ•´è·¯ç”±ç½‘ç»œçš„è¾“å‡ºï¼Œä»¥ç¡®ä¿æƒé‡çš„å‡†ç¡®æ€§ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å¯¹é½æŸå¤±ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºå¥–åŠ±æ¨¡å‹çš„æŸå¤±ï¼‰å’Œè·¯ç”±æŸå¤±ï¼ˆä¾‹å¦‚ï¼Œé¼“åŠ±ä¸“å®¶ä¹‹é—´çš„å¤šæ ·æ€§ï¼‰ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œè·¯ç”±ç½‘ç»œé€šå¸¸æ˜¯ä¸€ä¸ªå°å‹çš„å‰é¦ˆç¥ç»ç½‘ç»œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TrinityXåœ¨Alpaca (Helpfulness)ã€BeaverTails (Harmlessness)å’ŒTruthfulQA (Honesty)ä¸‰ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒTrinityXåœ¨èƒœç‡æ–¹é¢æå‡äº†32.5%ï¼Œåœ¨å®‰å…¨è¯„åˆ†æ–¹é¢æå‡äº†33.9%ï¼Œåœ¨çœŸå®æ€§æ–¹é¢æå‡äº†28.4%ã€‚æ­¤å¤–ï¼ŒTrinityXè¿˜æ˜¾è‘—é™ä½äº†å†…å­˜ä½¿ç”¨å’Œæ¨ç†å»¶è¿Ÿï¼Œä¸ä¹‹å‰çš„MoEæ–¹æ³•ç›¸æ¯”ï¼Œé™ä½å¹…åº¦è¶…è¿‡40%ã€‚æ¶ˆèå®éªŒè¡¨æ˜ï¼Œæ ¡å‡†è·¯ç”±æ˜¯TrinityXå–å¾—æˆåŠŸçš„å…³é”®å› ç´ ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TrinityXå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºæå‡å„ç§LLMçš„å®‰å…¨æ€§ã€å¯é æ€§å’Œå®ç”¨æ€§ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥å°†å…¶åº”ç”¨äºèŠå¤©æœºå™¨äººã€å†…å®¹ç”Ÿæˆç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸï¼Œä»¥ç¡®ä¿è¿™äº›ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆæœ‰ç”¨ã€æ— å®³ä¸”è¯šå®çš„å†…å®¹ã€‚æ­¤å¤–ï¼ŒTrinityXçš„æ¨¡å—åŒ–è®¾è®¡ä½¿å…¶æ˜“äºé›†æˆåˆ°ç°æœ‰çš„LLMæ¡†æ¶ä¸­ï¼Œä»è€ŒåŠ é€ŸLLMå¯¹é½æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) exhibit strong performance across a wide range of NLP tasks, yet aligning their outputs with the principles of Helpfulness, Harmlessness, and Honesty (HHH) remains a persistent challenge. Existing methods often optimize for individual alignment dimensions in isolation, leading to trade-offs and inconsistent behavior. While Mixture-of-Experts (MoE) architectures offer modularity, they suffer from poorly calibrated routing, limiting their effectiveness in alignment tasks. We propose TrinityX, a modular alignment framework that incorporates a Mixture of Calibrated Experts (MoCaE) within the Transformer architecture. TrinityX leverages separately trained experts for each HHH dimension, integrating their outputs through a calibrated, task-adaptive routing mechanism that combines expert signals into a unified, alignment-aware representation. Extensive experiments on three standard alignment benchmarks-Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty)-demonstrate that TrinityX outperforms strong baselines, achieving relative improvements of 32.5% in win rate, 33.9% in safety score, and 28.4% in truthfulness. In addition, TrinityX reduces memory usage and inference latency by over 40% compared to prior MoE-based approaches. Ablation studies highlight the importance of calibrated routing, and cross-model evaluations confirm TrinityX's generalization across diverse LLM backbones.

