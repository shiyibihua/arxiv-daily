---
layout: default
title: Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning
---

# Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09731" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09731v1</a>
  <a href="https://arxiv.org/pdf/2509.09731.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09731v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09731v1', 'Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haiyang Yu, Yuchuan Wu, Fan Shi, Lei Liao, Jinghui Lu, Xiaodong Ge, Han Wang, Minghan Zhuo, Xuecheng Wu, Xiang Fei, Hao Feng, Guozhi Tang, An-Lan Wang, Hanshen Zhu, Yangfan He, Quanhuan Liang, Liyuan Meng, Chao Feng, Can Huang, Jingqun Tang, Bin Li

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAncientDocåŸºå‡†ï¼Œè¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤ç±æ–‡æ¡£ç†è§£ä¸­çš„OCRå’ŒçŸ¥è¯†æ¨ç†èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤ç±æ–‡æ¡£ç†è§£` `è§†è§‰-è¯­è¨€æ¨¡å‹` `OCR` `çŸ¥è¯†æ¨ç†` `åŸºå‡†æ•°æ®é›†` `ä¸­æ–‡å¤ç±` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†å¤ç±æ–‡æ¡£çš„æ•°å­—åŒ–å’Œç†è§£ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å…¶è§†è§‰å’Œè¯­è¨€å¤æ‚æ€§æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚
2. AncientDocåŸºå‡†æ—¨åœ¨å…¨é¢è¯„ä¼°VLMsåœ¨å¤ç±æ–‡æ¡£ä¸Šçš„æ€§èƒ½ï¼Œæ¶µç›–OCRã€ç¿»è¯‘ã€æ¨ç†å’ŒçŸ¥è¯†é—®ç­”ç­‰å¤šä¸ªä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰VLMsåœ¨AncientDocåŸºå‡†ä¸Šè¡¨ç°ä¸ä½³ï¼Œçªæ˜¾äº†å¤ç±æ–‡æ¡£ç†è§£çš„ç‰¹æ®Šæ€§å’ŒæŒ‘æˆ˜æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†AncientDocï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹ä¸­æ–‡å¤ç±æ–‡æ¡£çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ä»å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰åˆ°çŸ¥è¯†æ¨ç†çš„èƒ½åŠ›ã€‚ä¸­æ–‡å¤ç±æ–‡æ¡£æ˜¯ä¸­åå†å²å’Œæ–‡åŒ–çš„å®è´µè½½ä½“ï¼Œè•´å«ç€å„ä¸ªé¢†åŸŸçš„ä¸°å¯ŒçŸ¥è¯†ï¼Œä½†åœ¨æ•°å­—åŒ–å’Œç†è§£æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–‡æ¡£åŸºå‡†ä¸»è¦é›†ä¸­åœ¨è‹±æ–‡å°åˆ·æ–‡æœ¬æˆ–ç®€ä½“ä¸­æ–‡ä¸Šï¼Œç¼ºä¹å¯¹å¤ç±æ–‡æ¡£çš„VLMsè¯„ä¼°ã€‚AncientDocåŒ…å«äº”ä¸ªä»»åŠ¡ï¼ˆé¡µé¢çº§OCRã€ç™½è¯æ–‡ç¿»è¯‘ã€åŸºäºæ¨ç†çš„é—®ç­”ã€åŸºäºçŸ¥è¯†çš„é—®ç­”ã€è¯­è¨€å˜ä½“é—®ç­”ï¼‰ï¼Œæ¶µç›–14ç§æ–‡æ¡£ç±»å‹ï¼Œè¶…è¿‡100æœ¬ä¹¦ç±å’Œçº¦3,000é¡µã€‚åŸºäºAncientDocï¼Œæˆ‘ä»¬ä½¿ç”¨å¤šç§æŒ‡æ ‡è¯„ä¼°äº†ä¸»æµVLMsï¼Œå¹¶è¾…ä»¥äººå·¥å¯¹é½çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„åˆ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨ç†è§£ä¸­æ–‡å¤ç±æ–‡æ¡£æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»ŸOCRæŠ€æœ¯ï¼Œä»…èƒ½æ‰«æå›¾åƒï¼Œæ— æ³•è¿›è¡Œæ·±å±‚æ¬¡çš„è¯­ä¹‰ç†è§£å’ŒçŸ¥è¯†æ¨ç†ã€‚ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤ç±æ–‡æ¡£ç‰¹æœ‰çš„è§†è§‰å¤æ‚æ€§ï¼ˆå¦‚æ¨¡ç³Šçš„æ–‡å­—ã€ç‰¹æ®Šçš„æ’ç‰ˆï¼‰å’Œè¯­è¨€å¤æ‚æ€§ï¼ˆå¦‚å¤æ–‡è¯­æ³•ã€å¤šä¹‰è¯ï¼‰æ—¶è¡¨ç°ä¸ä½³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªä¸“é—¨çš„åŸºå‡†æ¥è¯„ä¼°å’Œæ¨åŠ¨VLMsåœ¨å¤ç±æ–‡æ¡£ç†è§£æ–¹é¢çš„ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå…¨é¢çš„ã€å¤šä»»åŠ¡çš„åŸºå‡†æ•°æ®é›†ï¼Œæ¶µç›–å¤ç±æ–‡æ¡£ç†è§£çš„å¤šä¸ªæ–¹é¢ï¼ŒåŒ…æ‹¬OCRã€ç¿»è¯‘ã€æ¨ç†å’ŒçŸ¥è¯†é—®ç­”ã€‚é€šè¿‡åœ¨è¿™ä¸€åŸºå‡†ä¸Šè¯„ä¼°ç°æœ‰VLMsçš„æ€§èƒ½ï¼Œå¯ä»¥æ¸…æ™°åœ°äº†è§£å®ƒä»¬çš„ä¼˜åŠ¿å’Œä¸è¶³ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æ–¹å‘ã€‚åŸºå‡†çš„è®¾è®¡è€ƒè™‘äº†å¤ç±æ–‡æ¡£çš„ç‰¹æ®Šæ€§ï¼Œä¾‹å¦‚åŒ…å«å¤šç§æ–‡æ¡£ç±»å‹ã€å¤æ‚çš„ç‰ˆå¼å’Œå¤æ–‡è¯­è¨€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAncientDocåŸºå‡†åŒ…å«äº”ä¸ªä¸»è¦ä»»åŠ¡ï¼š1) é¡µé¢çº§OCRï¼šè¯†åˆ«å¤ç±æ–‡æ¡£å›¾åƒä¸­çš„æ–‡å­—ã€‚2) ç™½è¯æ–‡ç¿»è¯‘ï¼šå°†å¤æ–‡ç¿»è¯‘æˆç°ä»£ç™½è¯æ–‡ã€‚3) åŸºäºæ¨ç†çš„é—®ç­”ï¼šæ ¹æ®æ–‡æ¡£å†…å®¹è¿›è¡Œé€»è¾‘æ¨ç†å’Œé—®é¢˜å›ç­”ã€‚4) åŸºäºçŸ¥è¯†çš„é—®ç­”ï¼šéœ€è¦åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“è¿›è¡Œé—®é¢˜å›ç­”ã€‚5) è¯­è¨€å˜ä½“é—®ç­”ï¼šè€ƒå¯Ÿæ¨¡å‹å¯¹å¤æ–‡ä¸åŒè¡¨è¾¾æ–¹å¼çš„ç†è§£èƒ½åŠ›ã€‚æ•°æ®é›†æ¶µç›–14ç§æ–‡æ¡£ç±»å‹ï¼Œè¶…è¿‡100æœ¬ä¹¦ç±å’Œçº¦3,000é¡µã€‚

**å…³é”®åˆ›æ–°**ï¼šAncientDocæ˜¯é¦–ä¸ªä¸“é—¨é’ˆå¯¹ä¸­æ–‡å¤ç±æ–‡æ¡£çš„è§†è§‰-è¯­è¨€ç†è§£åŸºå‡†ã€‚å®ƒä¸ä»…åŒ…å«OCRä»»åŠ¡ï¼Œè¿˜æ¶µç›–äº†ç¿»è¯‘ã€æ¨ç†å’ŒçŸ¥è¯†é—®ç­”ç­‰æ›´é«˜å±‚æ¬¡çš„ä»»åŠ¡ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°VLMsçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒAncientDocçš„æ•°æ®é›†æ¶µç›–äº†å¤šç§æ–‡æ¡£ç±»å‹å’Œå¤æ‚çš„ç‰ˆå¼ï¼Œæ›´è´´è¿‘çœŸå®çš„åº”ç”¨åœºæ™¯ã€‚

**å…³é”®è®¾è®¡**ï¼šä¸ºäº†è¯„ä¼°VLMsçš„æ€§èƒ½ï¼Œè®ºæ–‡é‡‡ç”¨äº†å¤šç§æŒ‡æ ‡ï¼ŒåŒ…æ‹¬OCRçš„å‡†ç¡®ç‡ã€ç¿»è¯‘çš„BLEUå€¼ã€é—®ç­”çš„å‡†ç¡®ç‡ç­‰ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä½¿ç”¨äººå·¥å¯¹é½çš„å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯„åˆ†ï¼Œä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚æ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œä½œè€…ä»¬ä»”ç»†ç­›é€‰äº†æ–‡æ¡£ï¼Œå¹¶è¿›è¡Œäº†äººå·¥æ ‡æ³¨ï¼Œä»¥ä¿è¯æ•°æ®çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰ä¸»æµVLMsåœ¨AncientDocåŸºå‡†ä¸Šçš„è¡¨ç°ä¸äººç±»æ°´å¹³å­˜åœ¨è¾ƒå¤§å·®è·ï¼Œå°¤å…¶æ˜¯åœ¨æ¨ç†å’ŒçŸ¥è¯†é—®ç­”ä»»åŠ¡ä¸Šã€‚ä¾‹å¦‚ï¼Œåœ¨çŸ¥è¯†é—®ç­”ä»»åŠ¡ä¸­ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡è¿œä½äºäººç±»æ°´å¹³ã€‚è¿™è¡¨æ˜ï¼Œç°æœ‰VLMsåœ¨å¤„ç†å¤ç±æ–‡æ¡£çš„å¤æ‚æ€§å’Œä¸“ä¸šæ€§æ–¹é¢ä»æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ã€‚è¯¥åŸºå‡†çš„å‘å¸ƒå°†ä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤ç±æ•°å­—åŒ–ã€å¤ç±çŸ¥è¯†å›¾è°±æ„å»ºã€æ™ºèƒ½å¤ç±é˜…è¯»åŠ©æ‰‹ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡è§†è§‰-è¯­è¨€æ¨¡å‹å¯¹å¤ç±æ–‡æ¡£çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°ä¿æŠ¤å’Œä¼ æ‰¿ä¸­åæ–‡åŒ–é—äº§ï¼Œå¹¶ä¸ºå†å²ç ”ç©¶æä¾›æ›´ä¾¿æ·çš„å·¥å…·ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•åˆ©ç”¨VLMsè¿›è¡Œå¤ç±ä¿®å¤ã€å¤ç±å†…å®¹ç”Ÿæˆç­‰ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Chinese ancient documents, invaluable carriers of millennia of Chinese history and culture, hold rich knowledge across diverse fields but face challenges in digitization and understanding, i.e., traditional methods only scan images, while current Vision-Language Models (VLMs) struggle with their visual and linguistic complexity. Existing document benchmarks focus on English printed texts or simplified Chinese, leaving a gap for evaluating VLMs on ancient Chinese documents. To address this, we present AncientDoc, the first benchmark for Chinese ancient documents, designed to assess VLMs from OCR to knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and covers 14 document types, over 100 books, and about 3,000 pages. Based on AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by a human-aligned large language model for scoring.

