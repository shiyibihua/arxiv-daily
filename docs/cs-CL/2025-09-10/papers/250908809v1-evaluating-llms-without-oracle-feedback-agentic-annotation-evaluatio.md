---
layout: default
title: Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals
---

# Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08809" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08809v1</a>
  <a href="https://arxiv.org/pdf/2509.08809.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08809v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08809v1', 'Evaluating LLMs Without Oracle Feedback: Agentic Annotation Evaluation Through Unsupervised Consistency Signals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cheng Chen, Haiyan Yin, Ivor Tsang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: 11 pages, 10 figures

**æœŸåˆŠ**: Published ICLR 2025 Workshop on Scaling Self-Improving Foundation Models without Human Supervision

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸€è‡´æ€§ä¿¡å·çš„Agenticæ ‡æ³¨è¯„ä¼°æ–¹æ³•ï¼Œæ— éœ€äººå·¥åé¦ˆè¯„ä¼°LLMæ ‡æ³¨è´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ— ç›‘ç£å­¦ä¹ ` `æ ‡æ³¨è´¨é‡è¯„ä¼°` `ä¸€è‡´æ€§ä¿¡å·` `Agenticæ ‡æ³¨` `æ¨¡å‹é€‰æ‹©` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ç¼ºä¹äººå·¥åé¦ˆçš„åŠ¨æ€ç¯å¢ƒä¸­è¯„ä¼°LLMæ ‡æ³¨è´¨é‡ï¼Œæˆæœ¬é«˜ä¸”æ•ˆç‡ä½ã€‚
2. æå‡ºAgenticæ ‡æ³¨èŒƒå¼ï¼Œåˆ©ç”¨å­¦ç”Ÿæ¨¡å‹ä¸LLMåä½œï¼Œé€šè¿‡ä¸€è‡´æ€§ä¿¡å·è¿›è¡Œæ— ç›‘ç£è¯„ä¼°å’Œæ”¹è¿›ã€‚
3. å¼•å…¥CAIæ¯”ç‡ä½œä¸ºæ— ç›‘ç£è¯„ä¼°æŒ‡æ ‡ï¼Œå®éªŒè¡¨æ˜å…¶ä¸LLMå‡†ç¡®ç‡å‘ˆå¼ºæ­£ç›¸å…³ï¼Œå¯ç”¨äºæ¨¡å‹é€‰æ‹©ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸åŸºäºæç¤ºçš„ä»»åŠ¡ç»“åˆï¼Œæ˜¾è‘—é™ä½äº†æ•°æ®æ ‡æ³¨æˆæœ¬å’Œå¯¹äººå·¥æ ‡æ³¨è€…çš„ä¾èµ–ã€‚ç„¶è€Œï¼Œåœ¨ç¼ºä¹äººå·¥åé¦ˆçš„åŠ¨æ€ã€æ— ç›‘ç£ç¯å¢ƒä¸­ï¼Œè¯„ä¼°å…¶æ ‡æ³¨è´¨é‡ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä¼ ç»Ÿæ–¹æ³•ä¹Ÿéš¾ä»¥å¥æ•ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„agenticæ ‡æ³¨èŒƒå¼ï¼Œå…¶ä¸­å­¦ç”Ÿæ¨¡å‹ä¸å™ªå£°æ•™å¸ˆï¼ˆLLMï¼‰åä½œï¼Œåœ¨ä¸ä¾èµ–äººå·¥åé¦ˆçš„æƒ…å†µä¸‹è¯„ä¼°å’Œæ”¹è¿›æ ‡æ³¨è´¨é‡ã€‚å­¦ç”Ÿæ¨¡å‹ä½œä¸ºä¸€ç§æ— ç›‘ç£åé¦ˆæœºåˆ¶ï¼Œé‡‡ç”¨åŸºäºç”¨æˆ·åå¥½çš„å¤šæ•°æŠ•ç¥¨ç­–ç•¥æ¥è¯„ä¼°LLMè¾“å‡ºçš„ä¸€è‡´æ€§ã€‚ä¸ºäº†ç³»ç»Ÿåœ°è¡¡é‡LLMç”Ÿæˆæ ‡æ³¨çš„å¯é æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€è‡´å’Œä¸ä¸€è‡´ï¼ˆCAIï¼‰æ¯”ç‡ï¼Œè¿™æ˜¯ä¸€ç§æ–°çš„æ— ç›‘ç£è¯„ä¼°æŒ‡æ ‡ã€‚CAIæ¯”ç‡ä¸ä»…é‡åŒ–äº†æœ‰é™ç”¨æˆ·åå¥½ä¸‹å™ªå£°æ•™å¸ˆçš„æ ‡æ³¨è´¨é‡ï¼Œè€Œä¸”åœ¨æ¨¡å‹é€‰æ‹©ä¸­èµ·ç€å…³é”®ä½œç”¨ï¼Œèƒ½å¤Ÿåœ¨åŠ¨æ€ã€æ— ç›‘ç£ç¯å¢ƒä¸­è¯†åˆ«å‡ºé²æ£’çš„LLMã€‚åº”ç”¨äºè·¨å››ä¸ªLLMçš„åä¸ªå¼€æ”¾é¢†åŸŸNLPæ•°æ®é›†ï¼ŒCAIæ¯”ç‡ä¸LLMå‡†ç¡®ç‡å‘ˆå¼ºæ­£ç›¸å…³ï¼Œä½¿å…¶æˆä¸ºå®é™…ç¯å¢ƒä¸­æ— ç›‘ç£è¯„ä¼°å’Œæ¨¡å‹é€‰æ‹©çš„é‡è¦å·¥å…·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨ç¼ºä¹äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æœ‰æ•ˆè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆçš„æ ‡æ³¨è´¨é‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºäººå·¥åé¦ˆæˆ–é¢„å…ˆæ ‡æ³¨å¥½çš„æ•°æ®é›†ï¼Œè¿™åœ¨åŠ¨æ€å˜åŒ–çš„ç¯å¢ƒä¸­æˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ— ç›‘ç£çš„æ–¹æ³•æ¥è¯„ä¼°LLMæ ‡æ³¨çš„å¯é æ€§ï¼Œå¹¶è¿›è¡Œæ¨¡å‹é€‰æ‹©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹ä½œä¸ºæ— ç›‘ç£çš„åé¦ˆæœºåˆ¶ï¼Œä¸LLMï¼ˆä½œä¸ºå™ªå£°æ•™å¸ˆï¼‰è¿›è¡Œåä½œã€‚å­¦ç”Ÿæ¨¡å‹é€šè¿‡è¯„ä¼°LLMç”Ÿæˆæ ‡æ³¨çš„ä¸€è‡´æ€§æ¥åˆ¤æ–­å…¶è´¨é‡ã€‚å¦‚æœLLMçš„æ ‡æ³¨åœ¨ä¸åŒæƒ…å†µä¸‹è¡¨ç°å‡ºè¾ƒé«˜çš„ä¸€è‡´æ€§ï¼Œåˆ™è®¤ä¸ºå…¶æ ‡æ³¨è´¨é‡è¾ƒé«˜ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œå¯ä»¥åœ¨åŠ¨æ€ã€æ— ç›‘ç£çš„ç¯å¢ƒä¸­è¿›è¡Œè¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸€ä¸ªå™ªå£°æ•™å¸ˆï¼ˆLLMï¼‰å’Œä¸€ä¸ªå­¦ç”Ÿæ¨¡å‹ã€‚LLMè´Ÿè´£ç”Ÿæˆæ ‡æ³¨ï¼Œå­¦ç”Ÿæ¨¡å‹è´Ÿè´£è¯„ä¼°è¿™äº›æ ‡æ³¨çš„ä¸€è‡´æ€§ã€‚å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š1) LLMå¯¹è¾“å…¥æ•°æ®è¿›è¡Œæ ‡æ³¨ï¼Œç”Ÿæˆå¤šä¸ªå€™é€‰æ ‡æ³¨ç»“æœï¼›2) å­¦ç”Ÿæ¨¡å‹åŸºäºç”¨æˆ·åå¥½ï¼Œå¯¹è¿™äº›å€™é€‰æ ‡æ³¨ç»“æœè¿›è¡Œå¤šæ•°æŠ•ç¥¨ï¼Œé€‰æ‹©æœ€ä¸€è‡´çš„æ ‡æ³¨ï¼›3) è®¡ç®—ä¸€è‡´å’Œä¸ä¸€è‡´ï¼ˆCAIï¼‰æ¯”ç‡ï¼Œä½œä¸ºè¯„ä¼°LLMæ ‡æ³¨è´¨é‡çš„æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†Agenticæ ‡æ³¨èŒƒå¼å’ŒCAIæ¯”ç‡ã€‚Agenticæ ‡æ³¨èŒƒå¼é€šè¿‡å¼•å…¥å­¦ç”Ÿæ¨¡å‹ï¼Œå®ç°äº†æ— ç›‘ç£çš„æ ‡æ³¨è´¨é‡è¯„ä¼°ã€‚CAIæ¯”ç‡åˆ™æä¾›äº†ä¸€ç§é‡åŒ–æ ‡æ³¨ä¸€è‡´æ€§çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨äºæ¨¡å‹é€‰æ‹©å’Œæ€§èƒ½ç›‘æ§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€äººå·¥æ ‡æ³¨ï¼Œæ›´å…·çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šCAIæ¯”ç‡çš„è®¡ç®—æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚å®ƒåŸºäºå­¦ç”Ÿæ¨¡å‹çš„å¤šæ•°æŠ•ç¥¨ç»“æœï¼Œç»Ÿè®¡ä¸€è‡´çš„æ ‡æ³¨å’Œä¸ä¸€è‡´çš„æ ‡æ³¨æ•°é‡ï¼Œç„¶åè®¡ç®—å®ƒä»¬çš„æ¯”ç‡ã€‚ç”¨æˆ·åå¥½é€šè¿‡promptå·¥ç¨‹èå…¥åˆ°å­¦ç”Ÿæ¨¡å‹çš„å¤šæ•°æŠ•ç¥¨ç­–ç•¥ä¸­ã€‚è®ºæ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåŠæŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ï¼Œå› ä¸ºå­¦ç”Ÿæ¨¡å‹ä¸»è¦ä¾èµ–äºpromptå’Œå¤šæ•°æŠ•ç¥¨ç­–ç•¥ï¼Œè€Œéå¤æ‚çš„ç¥ç»ç½‘ç»œç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCAIæ¯”ç‡ä¸LLMçš„å‡†ç¡®ç‡ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ­£ç›¸å…³å…³ç³»ã€‚åœ¨åä¸ªå¼€æ”¾é¢†åŸŸçš„NLPæ•°æ®é›†ä¸Šï¼ŒCAIæ¯”ç‡èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°ä¸åŒLLMçš„æ ‡æ³¨è´¨é‡ï¼Œå¹¶å¸®åŠ©é€‰æ‹©æ€§èƒ½æœ€ä½³çš„æ¨¡å‹ã€‚è¯¥æ–¹æ³•åœ¨æ— éœ€äººå·¥æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†ä¸äººå·¥è¯„ä¼°ç›¸è¿‘çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤§è§„æ¨¡æ•°æ®æ ‡æ³¨çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œä¾‹å¦‚æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»ã€ä¿¡æ¯æŠ½å–ç­‰ã€‚å°¤å…¶é€‚ç”¨äºæ•°æ®æ ‡æ³¨æˆæœ¬é«˜æ˜‚æˆ–éš¾ä»¥è·å–äººå·¥æ ‡æ³¨çš„åœºæ™¯ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·åœ¨æ— ç›‘ç£ç¯å¢ƒä¸‹é€‰æ‹©åˆé€‚çš„LLMï¼Œå¹¶ç›‘æ§å…¶æ ‡æ³¨è´¨é‡ï¼Œä»è€Œæé«˜ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs), when paired with prompt-based tasks, have significantly reduced data annotation costs and reliance on human annotators. However, evaluating the quality of their annotations remains challenging in dynamic, unsupervised environments where oracle feedback is scarce and conventional methods fail. To address this challenge, we propose a novel agentic annotation paradigm, where a student model collaborates with a noisy teacher (the LLM) to assess and refine annotation quality without relying on oracle feedback. The student model, acting as an unsupervised feedback mechanism, employs a user preference-based majority voting strategy to evaluate the consistency of the LLM outputs. To systematically measure the reliability of LLM-generated annotations, we introduce the Consistent and Inconsistent (CAI) Ratio, a novel unsupervised evaluation metric. The CAI Ratio not only quantifies the annotation quality of the noisy teacher under limited user preferences but also plays a critical role in model selection, enabling the identification of robust LLMs in dynamic, unsupervised environments. Applied to ten open-domain NLP datasets across four LLMs, the CAI Ratio demonstrates a strong positive correlation with LLM accuracy, establishing it as an essential tool for unsupervised evaluation and model selection in real-world settings.

