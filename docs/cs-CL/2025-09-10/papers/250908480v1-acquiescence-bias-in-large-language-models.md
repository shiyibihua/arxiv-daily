---
layout: default
title: Acquiescence Bias in Large Language Models
---

# Acquiescence Bias in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08480" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08480v1</a>
  <a href="https://arxiv.org/pdf/2509.08480.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08480v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08480v1', 'Acquiescence Bias in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel Braun

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: Accepted to EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹ä¸­çš„åå‘é¡ºä»åå·®ï¼šå€¾å‘äºå›ç­”â€œå¦â€**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `é¡ºä»åå·®` `è®¤çŸ¥åå·®` `è‡ªç„¶è¯­è¨€å¤„ç†` `å®éªŒåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººç±»çš„é¡ºä»åå·®ç ”ç©¶å……åˆ†ï¼Œä½†LLMæ˜¯å¦å…·å¤‡ç±»ä¼¼åå·®å°šä¸æ˜ç¡®ï¼Œè¿™å½±å“äº†LLMåœ¨è°ƒæŸ¥å’Œé—®ç­”åœºæ™¯çš„å¯é æ€§ã€‚
2. è¯¥ç ”ç©¶é€šè¿‡è®¾è®¡å®éªŒï¼Œåœ¨ä¸åŒæ¨¡å‹ã€ä»»åŠ¡å’Œè¯­è¨€ä¸‹æµ‹è¯•LLMå¯¹è‚¯å®šå’Œå¦å®šå›ç­”çš„å€¾å‘æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMè¡¨ç°å‡ºä¸äººç±»ç›¸åçš„åå·®ï¼Œå³å€¾å‘äºå›ç­”â€œå¦â€ï¼Œè¿™ä¸äººç±»çš„é¡ºä»åå·®ç›¸åã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é¡ºä»åå·®ï¼Œå³äººä»¬åœ¨è°ƒæŸ¥ä¸­å€¾å‘äºåŒæ„é™ˆè¿°ï¼Œè€Œä¸ä»–ä»¬çš„å®é™…ä¿¡å¿µæ— å…³ï¼Œå·²è¢«å¹¿æ³›ç ”ç©¶å’Œè®°å½•ã€‚ç”±äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å·²è¢«è¯æ˜å¾ˆå®¹æ˜“å—åˆ°è¾“å…¥ä¸­ç›¸å¯¹è¾ƒå°çš„å˜åŒ–çš„å½±å“ï¼Œå¹¶ä¸”æ˜¯åœ¨äººç±»ç”Ÿæˆçš„æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œå› æ­¤æœ‰ç†ç”±è®¤ä¸ºå®ƒä»¬å¯èƒ½è¡¨ç°å‡ºç±»ä¼¼çš„å€¾å‘ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹ç ”ç©¶ï¼Œè°ƒæŸ¥äº†LLMåœ¨ä¸åŒæ¨¡å‹ã€ä»»åŠ¡å’Œè¯­è¨€ï¼ˆè‹±è¯­ã€å¾·è¯­å’Œæ³¢å…°è¯­ï¼‰ä¸­æ˜¯å¦å­˜åœ¨é¡ºä»åå·®ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä¸äººç±»ç›¸åï¼ŒLLMè¡¨ç°å‡ºä¸€ç§å€¾å‘äºå›ç­”â€œå¦â€çš„åå·®ï¼Œæ— è®ºå®ƒè¡¨ç¤ºåŒæ„è¿˜æ˜¯ä¸åŒæ„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯å¦å­˜åœ¨é¡ºä»åå·®ï¼Œå³åœ¨æ²¡æœ‰å®é™…ä¿¡å¿µçš„æƒ…å†µä¸‹å€¾å‘äºåŒæ„è°ƒæŸ¥ä¸­çš„é™ˆè¿°ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨äººç±»çš„é¡ºä»åå·®ï¼Œè€Œå¿½ç•¥äº†LLMå¯èƒ½å­˜åœ¨çš„ç±»ä¼¼åå·®ã€‚å¦‚æœLLMå­˜åœ¨é¡ºä»åå·®ï¼Œä¼šå½±å“å…¶åœ¨é—®ç­”ã€è°ƒæŸ¥ç­‰ä»»åŠ¡ä¸­çš„å¯é æ€§ï¼Œå¯¼è‡´ç»“æœå¤±çœŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡ç‰¹å®šçš„å®éªŒï¼Œè¯„ä¼°LLMåœ¨é¢å¯¹è‚¯å®šå’Œå¦å®šé™ˆè¿°æ—¶ï¼Œå›ç­”â€œæ˜¯â€æˆ–â€œå¦â€çš„å€¾å‘æ€§ã€‚é€šè¿‡å¯¹æ¯”LLMåœ¨ä¸åŒä»»åŠ¡ã€æ¨¡å‹å’Œè¯­è¨€ä¸‹çš„è¡¨ç°ï¼Œåˆ†æå…¶æ˜¯å¦å­˜åœ¨ç³»ç»Ÿæ€§çš„é¡ºä»åå·®ã€‚ä¸äººç±»çš„é¡ºä»åå·®ï¼ˆå€¾å‘äºå›ç­”â€œæ˜¯â€ï¼‰è¿›è¡Œå¯¹æ¯”ï¼Œæ­ç¤ºLLMç‹¬ç‰¹çš„åå·®ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶é‡‡ç”¨å®éªŒæ–¹æ³•ï¼Œä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š1) é€‰æ‹©ä¸åŒçš„LLMæ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰ï¼›2) è®¾è®¡åŒ…å«è‚¯å®šå’Œå¦å®šé™ˆè¿°çš„è°ƒæŸ¥é—®å·ï¼›3) ä½¿ç”¨ä¸åŒè¯­è¨€ï¼ˆè‹±è¯­ã€å¾·è¯­ã€æ³¢å…°è¯­ï¼‰è¿›è¡Œæµ‹è¯•ï¼›4) åˆ†æLLMå¯¹è‚¯å®šå’Œå¦å®šé™ˆè¿°çš„å›ç­”å€¾å‘æ€§ï¼Œç»Ÿè®¡å›ç­”â€œæ˜¯â€å’Œâ€œå¦â€çš„æ¯”ä¾‹ï¼›5) å¯¹æ¯”ä¸åŒæ¨¡å‹ã€ä»»åŠ¡å’Œè¯­è¨€ä¸‹çš„ç»“æœï¼Œè¯„ä¼°é¡ºä»åå·®çš„ç¨‹åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºé¦–æ¬¡å…³æ³¨å¹¶æ­ç¤ºäº†LLMä¸­å­˜åœ¨çš„åå‘é¡ºä»åå·®ï¼Œå³LLMå€¾å‘äºå›ç­”â€œå¦â€ï¼Œè¿™ä¸äººç±»çš„é¡ºä»åå·®ç›¸åã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†äººä»¬å¯¹LLMè¡Œä¸ºæ¨¡å¼çš„è®¤çŸ¥ï¼Œå¹¶ä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è°ƒæŸ¥é—®å·çš„è®¾è®¡ï¼Œéœ€è¦ä¿è¯é™ˆè¿°çš„æ¸…æ™°æ€§å’Œå®¢è§‚æ€§ï¼Œé¿å…å¼•å…¥å…¶ä»–åå·®ï¼›2) è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ï¼Œéœ€è¦èƒ½å¤Ÿå‡†ç¡®åæ˜ LLMçš„å›ç­”å€¾å‘æ€§ï¼›3) å®éªŒå‚æ•°çš„è®¾ç½®ï¼Œä¾‹å¦‚æ¸©åº¦ç³»æ•°ç­‰ï¼Œå¯èƒ½ä¼šå½±å“LLMçš„å›ç­”ç»“æœï¼Œéœ€è¦è¿›è¡Œåˆç†çš„è°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMæ™®éå­˜åœ¨åå‘é¡ºä»åå·®ï¼Œå³å€¾å‘äºå›ç­”â€œå¦â€ï¼Œè¿™ä¸äººç±»çš„é¡ºä»åå·®ç›¸åã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è¯¥å‘ç°å…·æœ‰é‡è¦æ„ä¹‰ï¼Œæ­ç¤ºäº†LLMä¸äººç±»åœ¨è®¤çŸ¥åå·®ä¸Šçš„å·®å¼‚ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨é—®ç­”ç³»ç»Ÿã€è°ƒæŸ¥åˆ†æç­‰é¢†åŸŸçš„å¯é æ€§ã€‚é€šè¿‡äº†è§£LLMçš„åå‘é¡ºä»åå·®ï¼Œå¯ä»¥è®¾è®¡æ›´æœ‰æ•ˆçš„æç¤ºå·¥ç¨‹æ–¹æ³•ï¼Œå‡å°‘åå·®å¯¹ç»“æœçš„å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¼€å‘æ›´å€¼å¾—ä¿¡ä»»å’Œå¯¹é½äººç±»ä»·å€¼è§‚çš„LLMæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Acquiescence bias, i.e. the tendency of humans to agree with statements in surveys, independent of their actual beliefs, is well researched and documented. Since Large Language Models (LLMs) have been shown to be very influenceable by relatively small changes in input and are trained on human-generated data, it is reasonable to assume that they could show a similar tendency. We present a study investigating the presence of acquiescence bias in LLMs across different models, tasks, and languages (English, German, and Polish). Our results indicate that, contrary to humans, LLMs display a bias towards answering no, regardless of whether it indicates agreement or disagreement.

