---
layout: default
title: VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations
---

# VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.22373" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.22373v1</a>
  <a href="https://arxiv.org/pdf/2510.22373.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.22373v1" onclick="toggleFavorite(this, '2510.22373v1', 'VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yupeng Xie, Zhiyang Zhang, Yifan Wu, Sirong Lu, Jiayi Zhang, Zhaoyang Yu, Jinlin Wang, Sirui Hong, Bang Liu, Chenglin Wu, Yuyu Luo

**åˆ†ç±»**: cs.CL, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-25

**å¤‡æ³¨**: 53 pages, 26 figures, 5 tables

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HKUSTDial/VisJudgeBench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVisJudge-Benchï¼Œç”¨äºè¯„ä¼°MLLMåœ¨å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°ä¸­çš„æ€§èƒ½ï¼Œå¹¶æå‡ºVisJudgeæ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯è§†åŒ–è¯„ä¼°` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `åŸºå‡†æ•°æ®é›†` `ç¾å­¦è¯„ä¼°` `è´¨é‡è¯„ä¼°` `VisJudge-Bench` `VisJudge` `è‡ªåŠ¨åŒ–è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°çš„ç³»ç»Ÿæ€§åŸºå‡†ï¼Œéš¾ä»¥æœ‰æ•ˆè¯„ä¼°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨æ­¤é¢†åŸŸçš„æ€§èƒ½ã€‚
2. è®ºæ–‡æå‡ºVisJudge-BenchåŸºå‡†æ•°æ®é›†ï¼Œå¹¶è®¾è®¡VisJudgeæ¨¡å‹ï¼Œä¸“é—¨ç”¨äºæå‡å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡çš„è‡ªåŠ¨è¯„ä¼°èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVisJudgeæ¨¡å‹åœ¨VisJudge-Benchä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰MLLMï¼Œåœ¨MAEå’Œä¸€è‡´æ€§æ–¹é¢å‡æœ‰å¤§å¹…æå‡ï¼Œæ›´æ¥è¿‘äººç±»ä¸“å®¶æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯è§†åŒ–æ˜¯ä¸€ç§å°†å¤æ‚æ•°æ®é›†è½¬åŒ–ä¸ºç›´è§‚è§è§£çš„æœ‰æ•ˆæ–¹å¼ï¼Œå…¶ä»·å€¼å–å†³äºæ•°æ®æ˜¯å¦è¢«å¿ å®åœ°è¡¨ç¤ºã€æ¸…æ™°åœ°ä¼ è¾¾ä»¥åŠç¾è§‚åœ°è®¾è®¡ã€‚ç„¶è€Œï¼Œè¯„ä¼°å¯è§†åŒ–è´¨é‡å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒéœ€è¦åŒæ—¶åˆ¤æ–­æ•°æ®ç¼–ç çš„å‡†ç¡®æ€§ã€ä¿¡æ¯è¡¨è¾¾çš„æœ‰æ•ˆæ€§å’Œè§†è§‰ç¾å­¦ã€‚å°½ç®¡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨è‡ªç„¶å›¾åƒçš„ç¾å­¦è¯„ä¼°ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä½†ç›®å‰è¿˜æ²¡æœ‰ç³»ç»Ÿçš„åŸºå‡†æ¥è¡¡é‡å®ƒä»¬åœ¨è¯„ä¼°å¯è§†åŒ–æ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†VisJudge-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¯„ä¼°MLLMåœ¨å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°ä¸­æ€§èƒ½çš„ç»¼åˆåŸºå‡†ã€‚å®ƒåŒ…å«æ¥è‡ªçœŸå®åœºæ™¯çš„3090ä¸ªä¸“å®¶æ ‡æ³¨æ ·æœ¬ï¼Œæ¶µç›–32ç§å›¾è¡¨ç±»å‹çš„å•ä¸ªå¯è§†åŒ–ã€å¤šä¸ªå¯è§†åŒ–å’Œä»ªè¡¨æ¿ã€‚å¯¹è¯¥åŸºå‡†çš„ç³»ç»Ÿæµ‹è¯•è¡¨æ˜ï¼Œå³ä½¿æ˜¯æœ€å…ˆè¿›çš„MLLMï¼ˆå¦‚GPT-5ï¼‰åœ¨åˆ¤æ–­æ–¹é¢ä¸äººç±»ä¸“å®¶ç›¸æ¯”ä»ç„¶å­˜åœ¨æ˜¾è‘—å·®è·ï¼Œå¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ä¸º0.551ï¼Œä¸äººç±»è¯„åˆ†çš„ç›¸å…³æ€§ä»…ä¸º0.429ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†VisJudgeï¼Œä¸€ä¸ªä¸“é—¨ä¸ºå¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°è®¾è®¡çš„æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸GPT-5ç›¸æ¯”ï¼ŒVisJudgeæ˜¾è‘—ç¼©å°äº†ä¸äººç±»åˆ¤æ–­çš„å·®è·ï¼Œå°†MAEé™ä½åˆ°0.442ï¼ˆé™ä½äº†19.8%ï¼‰ï¼Œå¹¶å°†ä¸äººç±»ä¸“å®¶çš„ä¸€è‡´æ€§æé«˜åˆ°0.681ï¼ˆæé«˜äº†58.7%ï¼‰ã€‚è¯¥åŸºå‡†å¯åœ¨https://github.com/HKUSTDial/VisJudgeBenchä¸Šè·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°æ–¹é¢è¡¨ç°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹ä¸“é—¨é’ˆå¯¹å¯è§†åŒ–è®¾è®¡çš„è¯„ä¼°åŸºå‡†ï¼Œæ— æ³•æœ‰æ•ˆè¡¡é‡MLLMåœ¨æ­¤é¢†åŸŸçš„æ€§èƒ½ã€‚åŒæ—¶ï¼Œé€šç”¨MLLMåœ¨å¤„ç†å¯è§†åŒ–ç‰¹æœ‰çš„æ•°æ®ç¼–ç ã€ä¿¡æ¯è¡¨è¾¾å’Œè§†è§‰ç¾å­¦ç­‰å¤æ‚å› ç´ æ—¶å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸äººç±»ä¸“å®¶å­˜åœ¨è¾ƒå¤§å·®è·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªé«˜è´¨é‡çš„å¯è§†åŒ–è¯„ä¼°åŸºå‡†ï¼ˆVisJudge-Benchï¼‰ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®­ç»ƒä¸€ä¸ªä¸“é—¨é’ˆå¯¹å¯è§†åŒ–è¯„ä¼°çš„æ¨¡å‹ï¼ˆVisJudgeï¼‰ã€‚é€šè¿‡é«˜è´¨é‡çš„æ•°æ®å’Œé’ˆå¯¹æ€§çš„æ¨¡å‹è®¾è®¡ï¼Œæå‡MLLMåœ¨å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°æ–¹é¢çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVisJudge-BenchåŒ…å«3090ä¸ªä¸“å®¶æ ‡æ³¨çš„å¯è§†åŒ–æ ·æœ¬ï¼Œæ¶µç›–32ç§å›¾è¡¨ç±»å‹ï¼ŒåŒ…æ‹¬å•ä¸ªå¯è§†åŒ–ã€å¤šä¸ªå¯è§†åŒ–å’Œä»ªè¡¨æ¿ã€‚VisJudgeæ¨¡å‹åŸºäºç°æœ‰çš„MLLMæ¶æ„è¿›è¡Œæ”¹è¿›ï¼Œå¯èƒ½åŒ…æ‹¬é’ˆå¯¹å¯è§†åŒ–ç‰¹å¾æå–çš„ç‰¹å®šæ¨¡å—ï¼Œä»¥åŠé’ˆå¯¹è¯„ä¼°ä»»åŠ¡çš„ä¼˜åŒ–è®­ç»ƒç­–ç•¥ã€‚æ•´ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆï¼Œä½¿ç”¨VisJudge-Benchå¯¹ç°æœ‰MLLMè¿›è¡Œè¯„ä¼°ï¼Œå‘ç°å…¶ä¸è¶³ï¼›ç„¶åï¼ŒåŸºäºVisJudge-Benchè®­ç»ƒVisJudgeæ¨¡å‹ï¼›æœ€åï¼Œå¯¹æ¯”VisJudgeå’Œç°æœ‰MLLMåœ¨VisJudge-Benchä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†VisJudge-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨é’ˆå¯¹å¯è§†åŒ–ç¾å­¦å’Œè´¨é‡è¯„ä¼°çš„ç»¼åˆåŸºå‡†ï¼›2) è®¾è®¡äº†VisJudgeæ¨¡å‹ï¼Œè¯¥æ¨¡å‹é’ˆå¯¹å¯è§†åŒ–è¯„ä¼°ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å¯è§†åŒ–çš„è´¨é‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVisJudge-Benchæä¾›äº†æ›´å…·é’ˆå¯¹æ€§çš„è¯„ä¼°æ•°æ®ï¼ŒVisJudgeæ¨¡å‹åˆ™æä¾›äº†æ›´æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ï¼ˆå¦‚VisJudgeæ¨¡å‹çš„ç½‘ç»œç»“æ„ã€æŸå¤±å‡½æ•°ã€è®­ç»ƒç­–ç•¥ç­‰ï¼‰åœ¨è®ºæ–‡ä¸­å¯èƒ½æ²¡æœ‰è¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚å¯èƒ½æ¶‰åŠçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼šé’ˆå¯¹ä¸åŒå›¾è¡¨ç±»å‹çš„ç‰¹å¾æå–æ¨¡å—ã€ç”¨äºèåˆæ•°æ®ç¼–ç ã€ä¿¡æ¯è¡¨è¾¾å’Œè§†è§‰ç¾å­¦ä¿¡æ¯çš„æ³¨æ„åŠ›æœºåˆ¶ã€ä»¥åŠç”¨äºä¼˜åŒ–è¯„ä¼°ç»“æœä¸äººç±»ä¸“å®¶ä¸€è‡´æ€§çš„æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVisJudgeæ¨¡å‹åœ¨VisJudge-Benchä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰MLLMï¼Œå°†å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ä»GPT-5çš„0.551é™ä½åˆ°0.442ï¼ˆé™ä½äº†19.8%ï¼‰ï¼Œå¹¶å°†ä¸äººç±»ä¸“å®¶çš„ä¸€è‡´æ€§ä»0.429æé«˜åˆ°0.681ï¼ˆæé«˜äº†58.7%ï¼‰ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒVisJudgeæ¨¡å‹èƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°å¯è§†åŒ–çš„ç¾å­¦å’Œè´¨é‡ï¼Œæ›´æ¥è¿‘äººç±»ä¸“å®¶çš„åˆ¤æ–­ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨åŒ–å¯è§†åŒ–è´¨é‡è¯„ä¼°ã€å¯è§†åŒ–è®¾è®¡è¾…åŠ©ã€ä»¥åŠå¯è§†åŒ–æ•™å­¦ç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨è¯„ä¼°å¯è§†åŒ–è´¨é‡ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·å¿«é€Ÿå‘ç°å’Œæ”¹è¿›å¯è§†åŒ–è®¾è®¡ä¸­çš„é—®é¢˜ï¼Œæå‡æ•°æ®å‘ˆç°çš„æœ‰æ•ˆæ€§å’Œç¾è§‚æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¸ºå¯è§†åŒ–æ•™å­¦æä¾›å®¢è§‚çš„è¯„ä¼°æ ‡å‡†ï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°æŒæ¡å¯è§†åŒ–è®¾è®¡åŸåˆ™ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Visualization, a domain-specific yet widely used form of imagery, is an effective way to turn complex datasets into intuitive insights, and its value depends on whether data are faithfully represented, clearly communicated, and aesthetically designed. However, evaluating visualization quality is challenging: unlike natural images, it requires simultaneous judgment across data encoding accuracy, information expressiveness, and visual aesthetics. Although multimodal large language models (MLLMs) have shown promising performance in aesthetic assessment of natural images, no systematic benchmark exists for measuring their capabilities in evaluating visualizations. To address this, we propose VisJudge-Bench, the first comprehensive benchmark for evaluating MLLMs' performance in assessing visualization aesthetics and quality. It contains 3,090 expert-annotated samples from real-world scenarios, covering single visualizations, multiple visualizations, and dashboards across 32 chart types. Systematic testing on this benchmark reveals that even the most advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a correlation with human ratings of only 0.429. To address this issue, we propose VisJudge, a model specifically designed for visualization aesthetics and quality assessment. Experimental results demonstrate that VisJudge significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a 19.8% reduction) and increasing the consistency with human experts to 0.681 (a 58.7% improvement) compared to GPT-5. The benchmark is available at https://github.com/HKUSTDial/VisJudgeBench.

