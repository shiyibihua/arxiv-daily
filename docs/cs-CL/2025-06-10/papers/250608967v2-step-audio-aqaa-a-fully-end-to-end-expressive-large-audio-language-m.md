---
layout: default
title: Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model
---

# Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08967" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08967v2</a>
  <a href="https://arxiv.org/pdf/2506.08967.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08967v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08967v2', 'Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ailin Huang, Bingxin Li, Bruce Wang, Boyong Wu, Chao Yan, Chengli Feng, Heng Wang, Hongyu Zhou, Hongyuan Wang, Jingbei Li, Jianjian Sun, Joanna Wang, Mingrui Chen, Peng Liu, Ruihang Miao, Shilei Jiang, Tian Fei, Wang You, Xi Chen, Xuerui Yang, Yechang Huang, Yuxiang Zhang, Zheng Ge, Zheng Gong, Zhewei Huang, Zixin Zhang, Bin Wang, Bo Li, Buyun Ma, Changxin Miao, Changyi Wan, Chen Xu, Dapeng Shi, Dingyuan Hu, Enle Liu, Guanzhe Huang, Gulin Yan, Hanpeng Hu, Haonan Jia, Jiahao Gong, Jiaoren Wu, Jie Wu, Jie Yang, Junzhe Lin, Kaixiang Li, Lei Xia, Longlong Gu, Ming Li, Nie Hao, Ranchen Ming, Shaoliang Pang, Siqi Liu, Song Yuan, Tiancheng Cao, Wen Li, Wenqing He, Xu Zhao, Xuelin Zhang, Yanbo Yu, Yinmin Zhong, Yu Zhou, Yuanwei Liang, Yuanwei Lu, Yuxiang Yang, Zidong Yang, Zili Zhang, Binxing Jiao, Heung-Yeung Shum, Jiansheng Chen, Jing Li, Xiangyu Zhang, Xinhao Zhang, Yibo Zhu, Daxin Jiang, Shuchang Zhou, Chen Hu

**åˆ†ç±»**: cs.SD, cs.CL, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-06-13)

**å¤‡æ³¨**: 12 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStep-Audio-AQAAä»¥è§£å†³éŸ³é¢‘äº¤äº’ä¸­çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `éŸ³é¢‘è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€ç”Ÿæˆ` `éŸ³é¢‘äº¤äº’` `ç¥ç»å£°ç å™¨` `è¯­éŸ³åˆæˆ` `ç›´æ¥åå¥½ä¼˜åŒ–` `å…¨ç«¯åˆ°ç«¯æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè‡ªç„¶è¯­éŸ³å“åº”æ–¹é¢å­˜åœ¨å±€é™ï¼Œå½±å“äº†éŸ³é¢‘äº¤äº’çš„æµç•…æ€§ã€‚
2. Step-Audio-AQAAé€šè¿‡é›†æˆåŒä»£ç æœ¬éŸ³é¢‘æ ‡è®°å™¨å’Œ1300äº¿å‚æ•°çš„LLMï¼Œæä¾›å…¨ç«¯åˆ°ç«¯çš„éŸ³é¢‘æŸ¥è¯¢-éŸ³é¢‘å›ç­”è§£å†³æ–¹æ¡ˆã€‚
3. åœ¨StepEval-Audio-360åŸºå‡†æµ‹è¯•ä¸­ï¼ŒStep-Audio-AQAAåœ¨è¯­éŸ³æ§åˆ¶ç­‰å…³é”®é¢†åŸŸè¡¨ç°ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMsï¼‰åœ¨æ™ºèƒ½äººæœºäº¤äº’ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶ä¾èµ–æ–‡æœ¬è¾“å‡ºçš„ç‰¹æ€§é™åˆ¶äº†è‡ªç„¶è¯­éŸ³å“åº”çš„ç”Ÿæˆï¼Œå¦¨ç¢äº†æ— ç¼éŸ³é¢‘äº¤äº’ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Step-Audio-AQAAï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹éŸ³é¢‘æŸ¥è¯¢-éŸ³é¢‘å›ç­”ï¼ˆAQAAï¼‰ä»»åŠ¡çš„å…¨ç«¯åˆ°ç«¯LALMã€‚è¯¥æ¨¡å‹é›†æˆäº†åŒä»£ç æœ¬éŸ³é¢‘æ ‡è®°å™¨ç”¨äºè¯­è¨€å’Œè¯­ä¹‰ç‰¹å¾æå–ï¼Œé‡‡ç”¨1300äº¿å‚æ•°çš„ä¸»å¹²LLMå’Œç¥ç»å£°ç å™¨è¿›è¡Œé«˜ä¿çœŸè¯­éŸ³åˆæˆã€‚æˆ‘ä»¬çš„åè®­ç»ƒæ–¹æ³•é€šè¿‡äº¤é”™çš„æ–‡æœ¬å’ŒéŸ³é¢‘è¾“å‡ºå¢å¼ºè¯­ä¹‰ä¸€è‡´æ€§ï¼Œå¹¶ç»“åˆç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ä¸æ¨¡å‹åˆå¹¶ä»¥æå‡æ€§èƒ½ã€‚åœ¨StepEval-Audio-360åŸºå‡†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒStep-Audio-AQAAåœ¨è¯­éŸ³æ§åˆ¶æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„LALMsã€‚æ­¤é¡¹å·¥ä½œä¸ºå…¨ç«¯åˆ°ç«¯LALMsæä¾›äº†æœ‰å‰æ™¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶å¼ºè°ƒäº†åŸºäºæ ‡è®°çš„å£°ç å™¨åœ¨æå‡AQAAä»»åŠ¡æ•´ä½“æ€§èƒ½ä¸­çš„å…³é”®ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè‡ªç„¶è¯­éŸ³å“åº”æ—¶çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éŸ³é¢‘äº¤äº’åœºæ™¯ä¸­ï¼Œæ–‡æœ¬è¾“å‡ºçš„ä¾èµ–æ€§å¯¼è‡´äº†äº¤äº’çš„ç”Ÿç¡¬ä¸ä¸è‡ªç„¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Step-Audio-AQAAæ¨¡å‹é€šè¿‡å…¨ç«¯åˆ°ç«¯çš„è®¾è®¡ï¼Œç»“åˆéŸ³é¢‘æŸ¥è¯¢ä¸éŸ³é¢‘å›ç­”çš„ä»»åŠ¡ï¼Œæ—¨åœ¨å®ç°æ›´è‡ªç„¶çš„éŸ³é¢‘äº¤äº’ä½“éªŒã€‚é€šè¿‡åŒä»£ç æœ¬éŸ³é¢‘æ ‡è®°å™¨æå–è¯­è¨€å’Œè¯­ä¹‰ç‰¹å¾ï¼Œå¢å¼ºäº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåŒä»£ç æœ¬éŸ³é¢‘æ ‡è®°å™¨ç”¨äºç‰¹å¾æå–ï¼Œ1300äº¿å‚æ•°çš„ä¸»å¹²LLMç”¨äºç†è§£å’Œç”Ÿæˆå†…å®¹ï¼Œä»¥åŠç¥ç»å£°ç å™¨ç”¨äºé«˜ä¿çœŸè¯­éŸ³åˆæˆã€‚æ¨¡å‹é‡‡ç”¨åè®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡äº¤é”™çš„æ–‡æœ¬å’ŒéŸ³é¢‘è¾“å‡ºæå‡è¯­ä¹‰ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç»“åˆäº†ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ä¸æ¨¡å‹åˆå¹¶çš„ç­–ç•¥ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨AQAAä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€æ–‡æœ¬è¾“å‡ºæ¨¡å‹å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åŒä»£ç æœ¬éŸ³é¢‘æ ‡è®°å™¨ä»¥å®ç°é«˜æ•ˆçš„ç‰¹å¾æå–ï¼Œå¹¶é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œç¡®ä¿äº†éŸ³é¢‘åˆæˆçš„é«˜ä¿çœŸåº¦å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨StepEval-Audio-360åŸºå‡†æµ‹è¯•ä¸­ï¼ŒStep-Audio-AQAAåœ¨è¯­éŸ³æ§åˆ¶ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„LALMsï¼Œæ˜¾ç¤ºå‡ºåœ¨è¯­ä¹‰ä¸€è‡´æ€§å’Œè‡ªç„¶è¯­éŸ³ç”Ÿæˆæ–¹é¢çš„æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Step-Audio-AQAAçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æ™ºèƒ½åŠ©æ‰‹ã€è¯­éŸ³äº¤äº’ç³»ç»Ÿå’Œæ•™è‚²é¢†åŸŸç­‰åœºæ™¯ä¸­ï¼Œå¯ä»¥å®ç°æ›´è‡ªç„¶æµç•…çš„éŸ³é¢‘äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„æŠ€æœ¯å¯ä»¥æ¨åŠ¨äººæœºäº¤äº’çš„è¿›ä¸€æ­¥å‘å±•ï¼Œä½¿å¾—æœºå™¨èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå“åº”äººç±»çš„è¯­éŸ³æŒ‡ä»¤ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Audio-Language Models (LALMs) have significantly advanced intelligent human-computer interaction, yet their reliance on text-based outputs limits their ability to generate natural speech responses directly, hindering seamless audio interactions. To address this, we introduce Step-Audio-AQAA, a fully end-to-end LALM designed for Audio Query-Audio Answer (AQAA) tasks. The model integrates a dual-codebook audio tokenizer for linguistic and semantic feature extraction, a 130-billion-parameter backbone LLM and a neural vocoder for high-fidelity speech synthesis. Our post-training approach employs interleaved token-output of text and audio to enhance semantic coherence and combines Direct Preference Optimization (DPO) with model merge to improve performance. Evaluations on the StepEval-Audio-360 benchmark demonstrate that Step-Audio-AQAA excels especially in speech control, outperforming the state-of-art LALMs in key areas. This work contributes a promising solution for end-to-end LALMs and highlights the critical role of token-based vocoder in enhancing overall performance for AQAA tasks.

