---
layout: default
title: Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models
---

# Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11137" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.11137v3</a>
  <a href="https://arxiv.org/pdf/2506.11137.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11137v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11137v3', 'Scalable Medication Extraction and Discontinuation Identification from Electronic Health Records Using Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chong Shao, Douglas Snyder, Chiran Li, Bowen Gu, Kerry Ngan, Chun-Ting Yang, Jiageng Wu, Richard Wyss, Kueiyu Joshua Lin, Jie Yang

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-10 (Êõ¥Êñ∞: 2025-11-06)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÊèêÂèñÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩï‰∏≠ÁöÑËçØÁâ©‰ø°ÊÅØ‰∏éÂÅúËçØËØÜÂà´**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩï` `ËçØÁâ©‰ø°ÊÅØÊèêÂèñ` `ÂÅúËçØËØÜÂà´` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êó†‰∫∫Â∑•Ê†áÊ≥®` `ÂºÄÊ∫êÊ®°Âûã` `‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÊèêÂèñÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩï‰∏≠ÁöÑËçØÁâ©‰ø°ÊÅØÊó∂ÔºåÂ∏∏Âõ†‰ø°ÊÅØÂàÜÊï£Âú®ÈùûÁªìÊûÑÂåñÊñáÊú¨‰∏≠ËÄåÈù¢‰∏¥ÊåëÊàò„ÄÇ
2. Êú¨Á†îÁ©∂ÈÄöËøáËØÑ‰º∞Â§öÁßçÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊó†‰∫∫Â∑•Ê†áÊ≥®ÁöÑËçØÁâ©‰ø°ÊÅØÊèêÂèñÂíåÂÅúËçØËØÜÂà´ÊñπÊ≥ï„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGPT-4oÂú®ËçØÁâ©ÊèêÂèñÂíåÂÅúËçØÂàÜÁ±ª‰ªªÂä°‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂Âú®Èõ∂Ê†∑Êú¨ËÆæÁΩÆ‰∏ãÁöÑF1ÂàÜÊï∞ËææÂà∞94.0%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËØÜÂà´ÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩïÔºàEHRÔºâ‰∏≠ÁöÑËçØÁâ©ÂÅúÁî®ÊÉÖÂÜµÂØπÊÇ£ËÄÖÂÆâÂÖ®Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÂ∏∏Âõ†‰ø°ÊÅØÂüãËóèÂú®ÈùûÁªìÊûÑÂåñÁ¨îËÆ∞‰∏≠ËÄåÂèóÂà∞ÈòªÁ¢ç„ÄÇÊú¨Á†îÁ©∂Êó®Âú®ËØÑ‰º∞ÂÖàËøõÁöÑÂºÄÊ∫êÂíå‰∏ìÊúâÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®ÊèêÂèñËçØÁâ©‰ø°ÊÅØÂèäÂàÜÁ±ªÂÖ∂Áä∂ÊÄÅÊñπÈù¢ÁöÑËÉΩÂäõÔºåÈáçÁÇπÂÖ≥Ê≥®Êó†‰∫∫Â∑•Ê†áÊ≥®ÁöÑËçØÁâ©‰ø°ÊÅØÊèêÂèñÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇÊàë‰ª¨Êî∂ÈõÜ‰∫ÜÊù•Ëá™‰∏çÂêåÊù•Ê∫êÁöÑ‰∏â‰∏™EHRÊï∞ÊçÆÈõÜ‰ª•ÊûÑÂª∫ËØÑ‰º∞Âü∫ÂáÜÔºåÁ≥ªÁªüÊØîËæÉ‰∫Ü12‰∏™ÂÖàËøõLLMsÂú®ËçØÁâ©ÊèêÂèñ„ÄÅËçØÁâ©Áä∂ÊÄÅÂàÜÁ±ªÂèäÂÖ∂ËÅîÂêà‰ªªÂä°‰∏äÁöÑË°®Áé∞„ÄÇÁªìÊûúÊòæÁ§∫ÔºåLLMsÂú®EHRÁ¨îËÆ∞‰∏≠ÁöÑËçØÁâ©ÊèêÂèñÂíåÂÅúËçØÂàÜÁ±ªË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØGPT-4oÂú®ÊâÄÊúâ‰ªªÂä°‰∏≠ÂùáÂèñÂæó‰∫ÜÊúÄÈ´òÁöÑÂπ≥ÂùáF1ÂàÜÊï∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨Á†îÁ©∂Êó®Âú®Ëß£ÂÜ≥ÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩï‰∏≠ËçØÁâ©‰ø°ÊÅØÊèêÂèñÂíåÂÅúËçØËØÜÂà´ÁöÑÈöæÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜÈùûÁªìÊûÑÂåñÊñáÊú¨‰∏≠ÁöÑ‰ø°ÊÅØÔºåÂØºËá¥ÊÇ£ËÄÖÂÆâÂÖ®È£éÈô©Â¢ûÂä†„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâËøõË°åËçØÁâ©‰ø°ÊÅØÁöÑËá™Âä®ÊèêÂèñÂíåÁä∂ÊÄÅÂàÜÁ±ªÔºåÈáçÁÇπÂú®‰∫éÊó†‰∫∫Â∑•Ê†áÊ≥®ÁöÑÂèØÊâ©Â±ïÊÄßÔºå‰ª•ÊèêÈ´òÂ§ÑÁêÜÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÁ†îÁ©∂ÊûÑÂª∫‰∫Ü‰∏Ä‰∏™ËØÑ‰º∞Âü∫ÂáÜÔºåÂåÖÂê´‰∏â‰∏™Êù•Ëá™‰∏çÂêåÊù•Ê∫êÁöÑEHRÊï∞ÊçÆÈõÜÔºåÂπ∂ÂØπ12‰∏™ÂÖàËøõÁöÑLLMsËøõË°å‰∫ÜÁ≥ªÁªüÊØîËæÉÔºåÊé¢Á¥¢‰∫ÜÂ§öÁßçÊèêÁ§∫Á≠ñÁï•„ÄÇ‰∏ªË¶ÅÊ®°ÂùóÂåÖÊã¨ËçØÁâ©ÊèêÂèñ„ÄÅÁä∂ÊÄÅÂàÜÁ±ªÂíåËÅîÂêà‰ªªÂä°Â§ÑÁêÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨Á†îÁ©∂ÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂà©Áî®LLMsËøõË°åËçØÁâ©‰ø°ÊÅØÊèêÂèñÂíåÂÅúËçØËØÜÂà´ÔºåÂ∞§ÂÖ∂ÊòØÂú®Èõ∂Ê†∑Êú¨ËÆæÁΩÆ‰∏ãÔºåÂ±ïÁ§∫‰∫ÜÂºÄÊ∫êÊ®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊΩúÂäõÔºåË∂ÖË∂ä‰∫Ü‰º†ÁªüÊñπÊ≥ïÁöÑÈôêÂà∂„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠ÔºåÈááÁî®‰∫ÜÂ§öÁßçÊèêÁ§∫Á≠ñÁï•ÂíåÂ∞ëÈáèÊ†∑Êú¨Â≠¶‰π†Ôºå‰ºòÂåñ‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩÔºåÁâπÂà´ÊòØGPT-4oÂíåLlama-3.1-70B-InstructÂú®‰∏çÂêå‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÊòæËëóÊèêÂçá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåGPT-4oÂú®ËçØÁâ©ÊèêÂèñ‰ªªÂä°‰∏≠ÂèñÂæó‰∫Ü94.0%ÁöÑF1ÂàÜÊï∞ÔºåÂú®ÂÅúËçØÂàÜÁ±ª‰ªªÂä°‰∏≠‰∏∫78.1%ÔºåËÄåÂú®ËÅîÂêà‰ªªÂä°‰∏≠‰∏∫72.7%„ÄÇÂºÄÊ∫êÊ®°ÂûãLlama-3.1-70B-InstructÂú®ËçØÁâ©Áä∂ÊÄÅÂàÜÁ±ªÂíåËÅîÂêà‰ªªÂä°‰∏≠‰πüË°®Áé∞Âá∫Ëâ≤ÔºåÂàÜÂà´ËææÂà∞‰∫Ü68.7%Âíå76.2%ÁöÑF1ÂàÜÊï∞ÔºåÊòæÁ§∫Âá∫LLMsÂú®ÂåªÁñóÊï∞ÊçÆÂ§ÑÁêÜ‰∏≠ÁöÑÂº∫Â§ßÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂåªÁñóÂÅ•Â∫∑È¢ÜÂüüÔºåÂ∞§ÂÖ∂ÊòØÂú®ÁîµÂ≠êÂÅ•Â∫∑ËÆ∞ÂΩïÁöÑÁÆ°ÁêÜÂíåÂàÜÊûê‰∏≠„ÄÇÈÄöËøáËá™Âä®ÂåñËçØÁâ©‰ø°ÊÅØÊèêÂèñÂíåÂÅúËçØËØÜÂà´ÔºåÂèØ‰ª•ÊèêÈ´ò‰∏¥Â∫äÂÜ≥Á≠ñÁöÑÂáÜÁ°ÆÊÄßÔºåÈôç‰ΩéÂåªÁñóÈîôËØØÁöÑÈ£éÈô©ÔºåËøõËÄåÊèêÂçáÊÇ£ËÄÖÂÆâÂÖ®„ÄÇÊ≠§Â§ñÔºåÂºÄÊ∫êÊ®°ÂûãÁöÑÂèØÊâ©Â±ïÊÄß‰ΩøÂæóÂÖ∂Âú®ËµÑÊ∫êÊúâÈôêÁöÑÂåªÁñóÊú∫ÊûÑ‰∏≠‰πüËÉΩÂæóÂà∞Â∫îÁî®ÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Identifying medication discontinuations in electronic health records (EHRs) is vital for patient safety but is often hindered by information being buried in unstructured notes. This study aims to evaluate the capabilities of advanced open-sourced and proprietary large language models (LLMs) in extracting medications and classifying their medication status from EHR notes, focusing on their scalability on medication information extraction without human annotation. We collected three EHR datasets from diverse sources to build the evaluation benchmark. We evaluated 12 advanced LLMs and explored multiple LLM prompting strategies. Performance on medication extraction, medication status classification, and their joint task (extraction then classification) was systematically compared across all experiments. We found that LLMs showed promising performance on the medication extraction and discontinuation classification from EHR notes. GPT-4o consistently achieved the highest average F1 scores in all tasks under zero-shot setting - 94.0% for medication extraction, 78.1% for discontinuation classification, and 72.7% for the joint task. Open-sourced models followed closely, Llama-3.1-70B-Instruct achieved the highest performance in medication status classification on the MIV-Med dataset (68.7%) and in the joint task on both the Re-CASI (76.2%) and MIV-Med (60.2%) datasets. Medical-specific LLMs demonstrated lower performance compared to advanced general-domain LLMs. Few-shot learning generally improved performance, while CoT reasoning showed inconsistent gains. LLMs demonstrate strong potential for medication extraction and discontinuation identification on EHR notes, with open-sourced models offering scalable alternatives to proprietary systems and few-shot can further improve LLMs' capability.

