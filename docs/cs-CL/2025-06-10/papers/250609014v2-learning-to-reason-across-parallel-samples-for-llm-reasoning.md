---
layout: default
title: Learning to Reason Across Parallel Samples for LLM Reasoning
---

# Learning to Reason Across Parallel Samples for LLM Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09014" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09014v2</a>
  <a href="https://arxiv.org/pdf/2506.09014.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09014v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09014v2', 'Learning to Reason Across Parallel Samples for LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jianing Qi, Xi Ye, Hao Tang, Zhigang Zhu, Eunsol Choi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-10-10)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ·æœ¬é›†èšåˆå™¨ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `æ ·æœ¬èšåˆ` `å¼ºåŒ–å­¦ä¹ ` `æ•°å­¦æ¨ç†` `æ¨¡å‹ä¼˜åŒ–` `æ•°æ®é›†å®éªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šä¸ªç­”æ¡ˆæ—¶ï¼Œå¾€å¾€ä¾èµ–ç®€å•çš„èšåˆç­–ç•¥ï¼Œå¦‚å¤šæ•°æŠ•ç¥¨ï¼Œå¯¼è‡´æ€§èƒ½æå‡æœ‰é™ã€‚
2. æœ¬æ–‡æå‡ºçš„æ ·æœ¬é›†èšåˆå™¨ï¼ˆSSAï¼‰é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–å¤šä¸ªæ ·æœ¬çš„èšåˆè¿‡ç¨‹ï¼Œæ—¨åœ¨æé«˜ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSSAåœ¨å¤šä¸ªæ¨ç†æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨MATHæ•°æ®é›†ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æå‡äº†8%çš„é€šè¿‡ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æµ‹è¯•æ—¶è®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½æ˜¾è‘—æé«˜ã€‚é€šè¿‡å¯¹å¤šä¸ªç­”æ¡ˆè¿›è¡Œé‡‡æ ·å¹¶è¿›è¡Œå¯å‘å¼èšåˆï¼ˆå¦‚å¤šæ•°æŠ•ç¥¨æˆ–ä½¿ç”¨éªŒè¯å™¨å¯¹ç­”æ¡ˆè¿›è¡Œæ’åºï¼‰ï¼Œå¯ä»¥åœ¨æ•°å­¦é¢†åŸŸå®ç°ä¸€è‡´çš„æ€§èƒ½æå‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åˆ©ç”¨å¤šæ ·æœ¬é›†çš„æ–¹æ³•ï¼Œè®­ç»ƒäº†ä¸€ä¸ªç´§å‡‘å‹çš„LLMï¼Œç§°ä¸ºæ ·æœ¬é›†èšåˆå™¨ï¼ˆSSAï¼‰ï¼Œè¯¥æ¨¡å‹æ¥æ”¶å¤šä¸ªæ ·æœ¬çš„ä¸²è”åºåˆ—å¹¶è¾“å‡ºæœ€ç»ˆç­”æ¡ˆï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚åœ¨äº”ä¸ªæ¨ç†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜SSAåœ¨æœ‰æ•ˆæ€§å’Œæ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨MATHæ•°æ®é›†ä¸Šï¼ŒSSAç›¸è¾ƒäºç®€å•çš„å¤šæ•°æŠ•ç¥¨æé«˜äº†8%çš„é€šè¿‡ç‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„3B SSAåœ¨å¤„ç†å¥–åŠ±æ¨¡å‹æ—¶è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„72Bæ¨¡å‹ã€‚åˆ†æç»“æœæ˜¾ç¤ºSSAåœ¨æ ·æœ¬é›†å¤§å°ã€åŸºç¡€æ¨¡å‹å®¶æ—å’Œä»»åŠ¡ä¸Šçš„è‰¯å¥½æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­å¯¹å¤šä¸ªç­”æ¡ˆçš„èšåˆæ•ˆç‡å’Œå‡†ç¡®æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚å¤šæ•°æŠ•ç¥¨åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨å¤šæ ·æœ¬ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ·æœ¬é›†èšåˆå™¨ï¼ˆSSAï¼‰é€šè¿‡å°†å¤šä¸ªæ ·æœ¬çš„ç­”æ¡ˆä¸²è”è¾“å…¥ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æœ€ç»ˆç­”æ¡ˆçš„é€‰æ‹©ï¼Œæ—¨åœ¨æå‡èšåˆç»“æœçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSSAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ ·æœ¬ç”Ÿæˆæ¨¡å—å’Œèšåˆæ¨¡å—ã€‚æ ·æœ¬ç”Ÿæˆæ¨¡å—è´Ÿè´£ä»åŸºç¡€LLMä¸­ç”Ÿæˆå¤šä¸ªç­”æ¡ˆï¼Œè€Œèšåˆæ¨¡å—åˆ™å¯¹è¿™äº›ç­”æ¡ˆè¿›è¡Œåˆ†æå’Œä¼˜åŒ–ï¼Œæœ€ç»ˆè¾“å‡ºæœ€ä½³ç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šSSAçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ç­”æ¡ˆç”Ÿæˆä¸ç­”æ¡ˆèšåˆåˆ†å¼€å¤„ç†ï¼Œå…è®¸ä¸å…¶ä»–é»‘ç®±æ¨¡å‹çš„è¾“å‡ºé«˜æ•ˆç»“åˆï¼Œæ˜¾è‘—æå‡äº†èšåˆçš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒSSAé‡‡ç”¨äº†å¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¥ä¼˜åŒ–èšåˆè¿‡ç¨‹ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ ·æœ¬æ•°é‡ã€å¥–åŠ±å‡½æ•°çš„è®¾è®¡ç­‰ï¼Œç¡®ä¿æ¨¡å‹åœ¨å¤šæ ·æœ¬ç¯å¢ƒä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ å¹¶åšå‡ºå‡†ç¡®åˆ¤æ–­ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSSAåœ¨MATHæ•°æ®é›†ä¸Šç›¸è¾ƒäºä¼ ç»Ÿçš„å¤šæ•°æŠ•ç¥¨æ–¹æ³•æé«˜äº†8%çš„é€šè¿‡ç‡ã€‚æ­¤å¤–ï¼Œ3B SSAåœ¨å¤„ç†å¥–åŠ±æ¨¡å‹æ—¶è¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„72Bæ¨¡å‹ï¼Œå±•ç¤ºäº†å…¶åœ¨æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€é‡‘èå’Œç§‘å­¦ç ”ç©¶ç­‰éœ€è¦é«˜ç²¾åº¦æ¨ç†çš„åœºæ™¯ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒSSAå¯ä»¥ä¸ºè‡ªåŠ¨åŒ–å†³ç­–å’Œæ™ºèƒ½åŠ©æ‰‹æä¾›æ›´å¯é çš„æ”¯æŒï¼Œæœªæ¥å¯èƒ½åœ¨å¤šç§å®é™…åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Scaling test-time compute brings substantial performance gains for large language models (LLMs). By sampling multiple answers and heuristically aggregate their answers (e.g., either through majority voting or using verifiers to rank the answers), one can achieve consistent performance gains in math domains. In this paper, we propose a new way to leverage such multiple sample set. We train a compact LLM, called Sample Set Aggregator (SSA), that takes a concatenated sequence of multiple samples and output the final answer, optimizing it for the answer accuracy with reinforcement learning. Experiments on five reasoning datasets demonstrate both the efficacy and efficiency of SSA. Notably, SSA improves over naive majority voting by 8% pass@5 on MATH. Furthermore, our 3B SSA surpasses model-based re-ranking with a much larger 72B process reward model. Our analysis also shows promising generalization ability of SSA, across sample set sizes, base model families and scales, and tasks. By separating LLMs to generate answers and LLMs to analyze and aggregate sampled answers, our approach can work with the outputs from premier black box models easily and efficiently.

