---
layout: default
title: LLM-as-a-qualitative-judge: automating error analysis in natural language generation
---

# LLM-as-a-qualitative-judge: automating error analysis in natural language generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09147" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09147v4</a>
  <a href="https://arxiv.org/pdf/2506.09147.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09147v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09147v4', 'LLM-as-a-qualitative-judge: automating error analysis in natural language generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nadezhda Chirkova, Tunde Oluwaseyi Ajayi, Seth Aycock, Zain Muhammad Mujahid, Vladana PerliÄ‡, Ekaterina Borisova, Markarit Vartampetian

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-12-19)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/tunde-ajayi/llm-as-a-qualitative-judge)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMä½œä¸ºå®šæ€§è¯„ä¼°å·¥å…·ä»¥è‡ªåŠ¨åŒ–è‡ªç„¶è¯­è¨€ç”Ÿæˆé”™è¯¯åˆ†æ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç„¶è¯­è¨€ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å®šæ€§è¯„ä¼°` `é”™è¯¯åˆ†æ` `ç³»ç»Ÿä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMè¯„ä¼°æ–¹æ³•ä¸»è¦ä¾èµ–æ•°å€¼è¯„åˆ†ï¼Œç¼ºä¹å¯¹ç”Ÿæˆæ–‡æœ¬çš„å®šæ€§åˆ†æï¼Œé™åˆ¶äº†å¼€å‘è€…å¯¹ç³»ç»Ÿæ”¹è¿›çš„ç†è§£ã€‚
2. æœ¬æ–‡æå‡ºLLM-as-a-qualitative-judgeï¼Œé€šè¿‡ç”Ÿæˆç»“æ„åŒ–çš„é”™è¯¯æŠ¥å‘Šï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«å’Œåˆ†æNLGç³»ç»Ÿä¸­çš„å¸¸è§é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM-as-a-qualitative-judgeçš„è¾“å‡ºä¸äººå·¥æ ‡æ³¨çš„åŒ¹é…ç‡ä¸º2/3ï¼Œä¸”åœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æå‡äº†NLGç³»ç»Ÿçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNLGï¼‰ä¸­ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¯„ä¼°ç”Ÿæˆæ–‡æœ¬çš„æ–¹å¼å·²æˆä¸ºæ ‡å‡†çš„è¯„ä¼°æ–¹æ³•ï¼Œé€šå¸¸ä»¥æ•°å€¼è¯„åˆ†ä¸ºä¸»è¦è¾“å‡ºã€‚æœ¬æ–‡æå‡ºäº†LLMä½œä¸ºå®šæ€§è¯„ä¼°å·¥å…·ï¼ˆLLM-as-a-qualitative-judgeï¼‰ï¼Œå…¶ä¸»è¦è¾“å‡ºä¸ºNLGç³»ç»Ÿè¾“å‡ºä¸­å¸¸è§é—®é¢˜ç±»å‹çš„ç»“æ„åŒ–æŠ¥å‘Šã€‚è¯¥æ–¹æ³•æ—¨åœ¨ä¸ºå¼€å‘è€…æä¾›æœ‰æ„ä¹‰çš„æ”¹è¿›å»ºè®®ï¼ŒåŒ…å«å¼€æ”¾å¼é€å®ä¾‹é—®é¢˜åˆ†æå’Œä½¿ç”¨ç›´è§‚ç´¯ç§¯ç®—æ³•çš„å‘ç°é—®é¢˜èšç±»ä¸¤ä¸ªä¸»è¦æ­¥éª¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-as-a-qualitative-judgeè¾“å‡ºçš„å®ä¾‹ç‰¹å®šé—®é¢˜ä¸äººå·¥æ ‡æ³¨çš„åŒ¹é…ç‡è¾¾åˆ°2/3ï¼Œå¹¶ä¸”èƒ½å¤Ÿç”Ÿæˆç±»ä¼¼äºäººå·¥æ ‡æ³¨è€…çš„é”™è¯¯ç±»å‹æŠ¥å‘Šã€‚æ¡ˆä¾‹ç ”ç©¶æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†NLGç³»ç»Ÿçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰LLMè¯„ä¼°æ–¹æ³•ç¼ºä¹å®šæ€§åˆ†æçš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–æ•°å€¼è¯„åˆ†ï¼Œæ— æ³•æ·±å…¥ç†è§£ç”Ÿæˆæ–‡æœ¬ä¸­çš„å…·ä½“é”™è¯¯ç±»å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºLLM-as-a-qualitative-judgeï¼Œé€šè¿‡ç”Ÿæˆç»“æ„åŒ–çš„é”™è¯¯æŠ¥å‘Šï¼Œå¸®åŠ©å¼€å‘è€…è¯†åˆ«NLGç³»ç»Ÿä¸­çš„å¸¸è§é—®é¢˜ï¼Œä»è€Œæä¾›æœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›å»ºè®®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€æ­¥æ˜¯å¼€æ”¾å¼é€å®ä¾‹é—®é¢˜åˆ†æï¼Œç¬¬äºŒæ­¥æ˜¯ä½¿ç”¨ç´¯ç§¯ç®—æ³•å¯¹å‘ç°çš„é—®é¢˜è¿›è¡Œèšç±»ã€‚è¿™ä¸€æµç¨‹æ—¨åœ¨ç³»ç»ŸåŒ–åœ°åˆ†æå’Œæ€»ç»“ç”Ÿæˆæ–‡æœ¬ä¸­çš„é”™è¯¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMç”¨äºå®šæ€§è¯„ä¼°ï¼Œç”Ÿæˆçš„é”™è¯¯æŠ¥å‘Šä¸ä»…åŒ…å«é—®é¢˜ç±»å‹ï¼Œè¿˜èƒ½æä¾›å…·ä½“çš„æ”¹è¿›å»ºè®®ï¼Œä¸ä¼ ç»Ÿçš„æ•°å€¼è¯„åˆ†æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†ç›´è§‚çš„ç´¯ç§¯ç®—æ³•è¿›è¡Œé—®é¢˜èšç±»ï¼Œå¹¶ç»“åˆçº¦300ä¸ªæ ‡æ³¨çš„å®ä¾‹æ•°æ®è¿›è¡Œè®­ç»ƒå’ŒéªŒè¯ï¼Œä»¥ç¡®ä¿è¾“å‡ºçš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-as-a-qualitative-judgeç”Ÿæˆçš„å®ä¾‹ç‰¹å®šé—®é¢˜ä¸äººå·¥æ ‡æ³¨çš„åŒ¹é…ç‡è¾¾åˆ°2/3ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®šæ€§åˆ†æä¸­çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæ¡ˆä¾‹ç ”ç©¶æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æå‡NLGç³»ç»Ÿçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€ç”Ÿæˆç³»ç»Ÿçš„å¼€å‘ä¸ä¼˜åŒ–ï¼Œå°¤å…¶æ˜¯åœ¨å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆå’Œè‡ªåŠ¨æ‘˜è¦ç­‰ä»»åŠ¡ä¸­ã€‚é€šè¿‡æä¾›å®šæ€§åˆ†æï¼Œå¼€å‘è€…å¯ä»¥æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œä¿®æ­£ç”Ÿæˆæ–‡æœ¬ä¸­çš„é—®é¢˜ï¼Œä»è€Œæå‡ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šçš„NLGåº”ç”¨åœºæ™¯ä¸­å¾—åˆ°æ¨å¹¿ï¼Œæ¨åŠ¨æ™ºèƒ½æ–‡æœ¬ç”ŸæˆæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prompting large language models (LLMs) to evaluate generated text, known as LLM-as-a-judge, has become a standard evaluation approach in natural language generation (NLG), but is primarily used as a quantitative tool, i.e. with numerical scores as main outputs. In this work, we propose LLM-as-a-qualitative-judge, an LLM-based evaluation approach with the main output being a structured report of common issue types in the NLG system outputs. Our approach is targeted at providing developers with meaningful insights on what improvements can be done to a given NLG system and consists of two main steps, namely open-ended per-instance issue analysis and clustering of the discovered issues using an intuitive cumulative algorithm. We also introduce a strategy for evaluating the proposed approach, coupled with ~300 annotations of issues in instances from 12 NLG datasets. Our results show that instance-specific issues output by LLM-as-a-qualitative-judge match those annotated by humans in 2/3 cases, and that LLM-as-a-qualitative-judge is capable of producing error type reports resembling the reports composed by human annotators. We also demonstrate in a case study how the use of LLM-as-a-qualitative-judge can substantially improve NLG systems performance. Our code and data are publicly available at https://github.com/tunde-ajayi/llm-as-a-qualitative-judge.

