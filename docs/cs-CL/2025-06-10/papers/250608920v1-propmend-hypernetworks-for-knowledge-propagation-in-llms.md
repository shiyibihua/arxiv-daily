---
layout: default
title: PropMEND: Hypernetworks for Knowledge Propagation in LLMs
---

# PropMEND: Hypernetworks for Knowledge Propagation in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08920" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08920v1</a>
  <a href="https://arxiv.org/pdf/2506.08920.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08920v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08920v1', 'PropMEND: Hypernetworks for Knowledge Propagation in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeyu Leo Liu, Greg Durrett, Eunsol Choi

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10

**å¤‡æ³¨**: Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPropMENDä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†ä¼ æ’­é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†ä¼ æ’­` `å¤§è¯­è¨€æ¨¡å‹` `è¶…ç½‘ç»œ` `å…ƒå­¦ä¹ ` `å¤šè·³æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çŸ¥è¯†ç¼–è¾‘æŠ€æœ¯æ— æ³•æœ‰æ•ˆä¼ æ’­æ³¨å…¥çš„çŸ¥è¯†ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ¨ç†æ—¶çš„è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºçš„PropMENDé€šè¿‡å…ƒå­¦ä¹ è°ƒæ•´æ¢¯åº¦ï¼Œä½¿å¾—æ³¨å…¥çš„ä¿¡æ¯èƒ½å¤Ÿåœ¨å¤šè·³é—®é¢˜ä¸­æœ‰æ•ˆä¼ æ’­ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPropMENDåœ¨RippleEditæ•°æ®é›†ä¸Šå‡†ç¡®ç‡å‡ ä¹æé«˜äº†2å€ï¼Œä¸”åœ¨æ–°æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„çŸ¥è¯†ç¼–è¾‘æŠ€æœ¯å¯ä»¥æ³¨å…¥å¯é‡å¤çš„çŸ¥è¯†ï¼Œä½†åœ¨çŸ¥è¯†ä¼ æ’­æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ¨¡å‹æ— æ³•å›ç­”éœ€è¦æ¨ç†çš„ç›¸å…³é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¶…ç½‘ç»œçš„çŸ¥è¯†ä¼ æ’­æ–¹æ³•PropMENDï¼Œé€šè¿‡å…ƒå­¦ä¹ è°ƒæ•´è¯­è¨€å»ºæ¨¡æŸå¤±çš„æ¢¯åº¦ï¼Œä»¥ä¿ƒè¿›æ³¨å…¥ä¿¡æ¯çš„ä¼ æ’­ã€‚è¯¥æ–¹æ³•æ‰©å±•äº†MENDçš„å…ƒç›®æ ‡ï¼Œä½¿å¾—çŸ¥è¯†çš„æ¢¯åº¦æ›´æ–°èƒ½å¤Ÿæ”¯æŒå¤šè·³é—®é¢˜çš„å›ç­”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨RippleEditæ•°æ®é›†ä¸Šï¼ŒPropMENDåœ¨å¤æ‚çš„å¤šè·³é—®é¢˜ä¸Šå‡†ç¡®ç‡å‡ ä¹æé«˜äº†2å€ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†æ–°çš„Controlled RippleEditæ•°æ®é›†ï¼Œä»¥è¯„ä¼°è¶…ç½‘ç»œçš„æ³›åŒ–èƒ½åŠ›ï¼Œæµ‹è¯•åœ¨è¶…ç½‘ç»œè®­ç»ƒä¸­æœªè§çš„å…³ç³»å’Œå®ä½“ä¸Šçš„çŸ¥è¯†ä¼ æ’­ã€‚å°½ç®¡PropMENDåœ¨æœªè§çš„å®ä½“-å…³ç³»å¯¹ä¸Šä»ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä½†æ€§èƒ½å·®è·æ˜¾è‘—å‡å°ï¼Œæç¤ºæœªæ¥åœ¨å¹¿æ³›å…³ç³»çš„çŸ¥è¯†ä¼ æ’­æ–¹é¢çš„ç ”ç©¶æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†ç¼–è¾‘åæ— æ³•æœ‰æ•ˆä¼ æ’­çŸ¥è¯†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éœ€è¦æ¨ç†çš„å¤šè·³é—®é¢˜æ—¶è¡¨ç°ä¸è¶³ï¼Œæ— æ³•åˆ©ç”¨æ³¨å…¥çš„çŸ¥è¯†è¿›è¡Œåˆç†æ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPropMENDçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¶…ç½‘ç»œç»“æ„è¿›è¡Œå…ƒå­¦ä¹ ï¼Œè°ƒæ•´è¯­è¨€å»ºæ¨¡æŸå¤±çš„æ¢¯åº¦ï¼Œä»¥ä¿ƒè¿›çŸ¥è¯†çš„ä¼ æ’­ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å›ç­”å¤šè·³é—®é¢˜æ—¶ï¼Œåˆ©ç”¨æ³¨å…¥çš„çŸ¥è¯†è¿›è¡Œæ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPropMENDçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¶…ç½‘ç»œæ¨¡å—å’Œæ¢¯åº¦è°ƒæ•´æœºåˆ¶ã€‚è¶…ç½‘ç»œè´Ÿè´£ç”Ÿæˆé€‚åº”æ€§æ¢¯åº¦æ›´æ–°ï¼Œè€Œæ¢¯åº¦è°ƒæ•´æœºåˆ¶åˆ™ç¡®ä¿çŸ¥è¯†åœ¨å¤šè·³æ¨ç†ä¸­æœ‰æ•ˆä¼ æ’­ã€‚

**å…³é”®åˆ›æ–°**ï¼šPropMENDçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è¶…ç½‘ç»œçš„è®¾è®¡ï¼Œä½¿å¾—çŸ¥è¯†çš„æ¢¯åº¦æ›´æ–°èƒ½å¤Ÿè¢«è½¬åŒ–ä¸ºæ”¯æŒå¤šè·³æ¨ç†çš„å½¢å¼ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„ç›´æ¥çŸ¥è¯†æ³¨å…¥æ–¹å¼å½¢æˆäº†æ˜¾è‘—åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒPropMENDä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¢¯åº¦æ›´æ–°ï¼Œå¹¶è®¾è®¡äº†è¶…ç½‘ç»œçš„ç»“æ„ä»¥é€‚åº”ä¸åŒç±»å‹çš„çŸ¥è¯†æ³¨å…¥ï¼Œç¡®ä¿åœ¨æœªè§çš„å®ä½“-å…³ç³»å¯¹ä¸Šä¹Ÿèƒ½æœ‰æ•ˆå·¥ä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨RippleEditæ•°æ®é›†ä¸Šï¼ŒPropMENDçš„å‡†ç¡®ç‡å‡ ä¹æé«˜äº†2å€ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚æ­¤å¤–ï¼Œåœ¨Controlled RippleEditæ•°æ®é›†ä¸Šï¼ŒPropMENDåœ¨æœªè§å®ä½“-å…³ç³»å¯¹ä¸Šçš„è¡¨ç°ä»ç„¶ä¼˜å¼‚ï¼Œå°½ç®¡æ€§èƒ½å·®è·æœ‰æ‰€å‡å°ï¼Œæ˜¾ç¤ºå‡ºæœªæ¥ç ”ç©¶çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æœ‰æ•ˆçš„çŸ¥è¯†ä¼ æ’­ï¼ŒPropMENDèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowledge editing techniques for large language models (LLMs) can inject knowledge that is later reproducible verbatim, but they fall short on propagating that knowledge: models cannot answer questions that require reasoning with the injected knowledge. We present a hypernetwork-based approach for knowledge propagation, named PropMEND, where we meta-learn how to modify gradients of a language modeling loss to encourage injected information to propagate. Our approach extends the meta-objective of MEND [29] so that gradient updates on knowledge are transformed to enable answering multi-hop questions involving that knowledge. We show improved performance on the RippleEdit dataset, showing almost 2x accuracy on challenging multi-hop questions whose answers are not explicitly stated in the injected fact. We further introduce a new dataset, Controlled RippleEdit, to evaluate the generalization of our hypernetwork, testing knowledge propagation along relations and entities unseen during hypernetwork training. PropMEND still outperforms existing approaches in unseen entity-relation pairs, yet the performance gap decreases substantially, suggesting future work in propagating knowledge to a wide range of relations.

