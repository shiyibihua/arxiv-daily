---
layout: default
title: Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions
---

# Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08952" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08952v2</a>
  <a href="https://arxiv.org/pdf/2506.08952.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08952v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08952v2', 'Can LLMs Ground when they (Don\'t) Know: A Study on Direct and Loaded Political Questions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Clara Lachenmaier, Judith Sieker, Sina ZarrieÃŸ

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-06-11)

**å¤‡æ³¨**: Preprint accepted at ACL Main Conference 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¿æ²»é—®é¢˜ä¸­çš„ä¿¡æ¯åŸºç¡€èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ”¿æ²»å¯¹è¯` `è¯¯ä¿¡æ¯` `å…±åŒåŸºç¡€` `çŸ¥è¯†ç®¡ç†` `åŠ è½½é—®é¢˜` `ç”¨æˆ·ä¿¡å¿µçº æ­£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ”¿æ²»é¢†åŸŸçš„çŸ¥è¯†é—®é¢˜æ—¶ï¼Œå¸¸å¸¸æ— æ³•æœ‰æ•ˆç®¡ç†å…±åŒåŸºç¡€ï¼Œå¯¼è‡´è¯¯ä¿¡æ¯ä¼ æ’­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡é€šè¿‡åˆ†æLLMsåœ¨å›ç­”ç›´æ¥å’ŒåŠ è½½é—®é¢˜æ—¶çš„è¡¨ç°ï¼Œæ¢è®¨å…¶åœ¨çŸ¥è¯†ç¼ºå¤±æƒ…å†µä¸‹çš„åŸºç¡€ç®¡ç†èƒ½åŠ›ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶å‘ç°LLMsåœ¨ä¸»åŠ¨çº æ­£ç”¨æˆ·é”™è¯¯ä¿¡å¿µæ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå½±å“å…¶åœ¨æ”¿æ²»å¯¹è¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»ä¹‹é—´çš„äº¤æµä¾èµ–äºå¯¹è¯åŸºç¡€ï¼Œä½¿å¯¹è¯è€…å³ä½¿åœ¨çŸ¥è¯†ä¸å®Œå¤‡çš„æƒ…å†µä¸‹ä¹Ÿèƒ½è¾¾æˆå…±è¯†ã€‚æœ¬æ–‡ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨çŸ¥è¯†ç¼ºå¤±æ—¶å¦‚ä½•ç®¡ç†å…±åŒåŸºç¡€ï¼Œç‰¹åˆ«å…³æ³¨æ”¿æ²»é¢†åŸŸä¸­çš„äº‹å®ï¼Œå› ä¸ºè¯¥é¢†åŸŸå­˜åœ¨è¯¯ä¿¡æ¯å’ŒåŸºç¡€å¤±è´¥çš„é«˜é£é™©ã€‚æˆ‘ä»¬è€ƒå¯ŸLLMså›ç­”ç›´æ¥çŸ¥è¯†é—®é¢˜å’Œå‡è®¾è¯¯ä¿¡æ¯çš„åŠ è½½é—®é¢˜çš„èƒ½åŠ›ï¼Œå¹¶è¯„ä¼°åŠ è½½é—®é¢˜æ˜¯å¦ä¿ƒä½¿LLMsä¸»åŠ¨çº æ­£ç”¨æˆ·çš„é”™è¯¯ä¿¡å¿µã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†LLMsåœ¨å‚ä¸åŸºç¡€å»ºè®¾å’Œæ‹’ç»é”™è¯¯ç”¨æˆ·ä¿¡å¿µæ–¹é¢é¢ä¸´çš„é‡å¤§æŒ‘æˆ˜ï¼Œæå‡ºäº†å¯¹å…¶åœ¨æ”¿æ²»è¯è¯­ä¸­å‡è½»è¯¯ä¿¡æ¯ä½œç”¨çš„æ‹…å¿§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¿æ²»é¢†åŸŸä¸­å¤„ç†çŸ¥è¯†é—®é¢˜æ—¶çš„å…±åŒåŸºç¡€ç®¡ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹åŠ è½½é—®é¢˜æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆçº æ­£ç”¨æˆ·çš„é”™è¯¯ä¿¡å¿µï¼Œå¯¼è‡´è¯¯ä¿¡æ¯çš„ä¼ æ’­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹ç›´æ¥çŸ¥è¯†é—®é¢˜å’ŒåŠ è½½é—®é¢˜çš„æ¯”è¾ƒåˆ†æï¼Œè¯„ä¼°LLMsåœ¨çŸ¥è¯†ç¼ºå¤±æƒ…å†µä¸‹çš„è¡¨ç°ï¼Œæ¢è®¨å…¶ä¸»åŠ¨çº æ­£é”™è¯¯ä¿¡å¿µçš„èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ­ç¤ºLLMsåœ¨æ”¿æ²»å¯¹è¯ä¸­çš„æ½œåœ¨å±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¯¹æ¯”å®éªŒçš„æ–¹æ³•ï¼Œé¦–å…ˆè®¾è®¡äº†ç›´æ¥çŸ¥è¯†é—®é¢˜å’ŒåŠ è½½é—®é¢˜çš„é—®å·ï¼Œç„¶åé€šè¿‡LLMsè¿›è¡Œå›ç­”ï¼Œæœ€ååˆ†æå…¶å›ç­”çš„å‡†ç¡®æ€§å’Œå¯¹ç”¨æˆ·ä¿¡å¿µçš„å½±å“ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬é—®é¢˜è®¾è®¡ã€æ¨¡å‹å›ç­”å’Œç»“æœåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†LLMsåœ¨é¢å¯¹åŠ è½½é—®é¢˜æ—¶çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯å…¶åœ¨ä¸»åŠ¨çº æ­£ç”¨æˆ·é”™è¯¯ä¿¡å¿µæ–¹é¢çš„èƒ½åŠ›ï¼Œä¸ç°æœ‰ç ”ç©¶ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ·±å…¥çš„ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­é‡‡ç”¨äº†å¤šç§é—®é¢˜ç±»å‹ï¼Œå¹¶å¯¹LLMsçš„å›ç­”è¿›è¡Œäº†å®šé‡å’Œå®šæ€§çš„åˆ†æï¼Œå…³æ³¨å…¶åœ¨ä¸åŒçŸ¥è¯†æ°´å¹³å’Œæ”¿æ²»åè§ä¸‹çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨å¤„ç†åŠ è½½é—®é¢˜æ—¶ï¼Œä¸»åŠ¨çº æ­£ç”¨æˆ·é”™è¯¯ä¿¡å¿µçš„èƒ½åŠ›æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶åœ¨çŸ¥è¯†ç¼ºå¤±çš„æƒ…å†µä¸‹ï¼Œè¡¨ç°å‡ºè¾ƒé«˜çš„è¯¯ä¿¡æ¯ä¼ æ’­é£é™©ã€‚è¿™ä¸€å‘ç°å¯¹LLMsåœ¨æ”¿æ²»è¯è¯­ä¸­çš„åº”ç”¨æå‡ºäº†é‡è¦è­¦ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ”¿æ²»ä¼ æ’­ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œæ•™è‚²é¢†åŸŸï¼Œèƒ½å¤Ÿä¸ºè®¾è®¡æ›´æœ‰æ•ˆçš„å¯¹è¯ç³»ç»Ÿæä¾›ç†è®ºæ”¯æŒã€‚é€šè¿‡æ”¹å–„LLMsåœ¨æ”¿æ²»å¯¹è¯ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥å¸®åŠ©å‡å°‘è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œæé«˜å…¬ä¼—å¯¹æ”¿æ²»ä¿¡æ¯çš„ç†è§£å’Œåˆ¤æ–­èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Communication among humans relies on conversational grounding, allowing interlocutors to reach mutual understanding even when they do not have perfect knowledge and must resolve discrepancies in each other's beliefs. This paper investigates how large language models (LLMs) manage common ground in cases where they (don't) possess knowledge, focusing on facts in the political domain where the risk of misinformation and grounding failure is high. We examine the ability of LLMs to answer direct knowledge questions and loaded questions that presuppose misinformation. We evaluate whether loaded questions lead LLMs to engage in active grounding and correct false user beliefs, in connection to their level of knowledge and their political bias. Our findings highlight significant challenges in LLMs' ability to engage in grounding and reject false user beliefs, raising concerns about their role in mitigating misinformation in political discourse.

