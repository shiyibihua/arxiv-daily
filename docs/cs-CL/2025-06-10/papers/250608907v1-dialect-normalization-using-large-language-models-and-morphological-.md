---
layout: default
title: Dialect Normalization using Large Language Models and Morphological Rules
---

# Dialect Normalization using Large Language Models and Morphological Rules

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08907" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08907v1</a>
  <a href="https://arxiv.org/pdf/2506.08907.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08907v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08907v1', 'Dialect Normalization using Large Language Models and Morphological Rules')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Antonios Dimakis, John Pavlopoulos, Antonios Anastasopoulos

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10

**å¤‡æ³¨**: 19 pages, 18 figures, to be published in the Findings of the Association for Computational Linguistics 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“åˆè§„åˆ™ä¸å¤§è¯­è¨€æ¨¡å‹çš„æ–¹è¨€æ ‡å‡†åŒ–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–¹è¨€æ ‡å‡†åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `è§„åˆ™åŸºç¡€è½¬åŒ–` `ä½èµ„æºè¯­è¨€` `å¸Œè…Šæ–¹è¨€` `è¯­ä¹‰æŒ–æ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–¹è¨€æ ‡å‡†åŒ–æ–¹æ³•åœ¨å¤„ç†ä½èµ„æºè¯­è¨€æ—¶æ•ˆæœä¸ä½³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¹³è¡Œæ•°æ®çš„æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºçš„è§£å†³æ–¹æ¡ˆç»“åˆäº†åŸºäºè§„åˆ™çš„è¯­è¨€å­¦è½¬åŒ–ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨å°‘é‡ç¤ºä¾‹æç¤ºè¿›è¡Œè®­ç»ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°çš„æ–¹æ³•èƒ½å¤ŸæŒ–æ˜å‡ºæ›´æ·±å±‚æ¬¡çš„è¯­ä¹‰ä¿¡æ¯ï¼Œè¶…è¶Šäº†ä»¥å¾€ä»…ä¾èµ–è¡¨é¢è¯­è¨€ç‰¹å¾çš„åˆ†æã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç„¶è¯­è¨€ç†è§£ç³»ç»Ÿåœ¨å¤„ç†ä½èµ„æºè¯­è¨€æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯é«˜èµ„æºè¯­è¨€çš„æ–¹è¨€ã€‚æ–¹è¨€åˆ°æ ‡å‡†è¯­è¨€çš„æ ‡å‡†åŒ–æ—¨åœ¨å°†æ–¹è¨€æ–‡æœ¬è½¬æ¢ä¸ºå¯ä¾›æ ‡å‡†è¯­è¨€å·¥å…·ä½¿ç”¨çš„å½¢å¼ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œç»“åˆäº†åŸºäºè§„åˆ™çš„è¯­è¨€å­¦è½¬åŒ–å’Œå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œé€šè¿‡æœ‰é’ˆå¯¹æ€§çš„å°‘é‡ç¤ºä¾‹æç¤ºè¿›è¡Œè®­ç»ƒï¼Œä¸”ä¸éœ€è¦ä»»ä½•å¹³è¡Œæ•°æ®ã€‚ç ”ç©¶é’ˆå¯¹å¸Œè…Šæ–¹è¨€è¿›è¡Œå®ç°ï¼Œå¹¶åœ¨åŒºåŸŸè°šè¯­æ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºä»¥å¾€å¯¹è¿™äº›è°šè¯­çš„åˆ†æä»…ä¾èµ–äºè¡¨é¢çš„è¯­è¨€ä¿¡æ¯ï¼Œè€Œæ–°çš„è§‚å¯Ÿä»ç„¶å¯ä»¥é€šè¿‡å‰©ä½™çš„è¯­ä¹‰è¿›è¡ŒæŒ–æ˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–¹è¨€åˆ°æ ‡å‡†è¯­è¨€çš„æ ‡å‡†åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä½èµ„æºè¯­è¨€å¤„ç†ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¹³è¡Œæ•°æ®çš„æƒ…å†µä¸‹ï¼Œéš¾ä»¥å®ç°æœ‰æ•ˆçš„è½¬æ¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆåŸºäºè§„åˆ™çš„è¯­è¨€å­¦è½¬åŒ–ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å°‘é‡ç¤ºä¾‹æç¤ºæ¥è¿›è¡Œè®­ç»ƒï¼Œä»¥å®ç°é«˜æ•ˆçš„æ–¹è¨€æ ‡å‡†åŒ–ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿå……åˆ†åˆ©ç”¨è¯­è¨€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼ŒåŒæ—¶ç»“åˆè¯­è¨€å­¦çš„è§„åˆ™ï¼Œæå‡æ ‡å‡†åŒ–çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€è§„åˆ™å®šä¹‰ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹æ–¹è¨€æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åå®šä¹‰ç›¸åº”çš„è¯­è¨€å­¦è§„åˆ™ï¼Œæ¥ç€ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œæœ€åé€šè¿‡äººç±»è¯„ä¼°è¿›è¡Œæ•ˆæœéªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†è§„åˆ™åŸºç¡€çš„è½¬åŒ–ä¸å¤§è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„æ ‡å‡†åŒ–æ–¹æ³•ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºä¸å†ä¾èµ–å¹³è¡Œè¯­æ–™ï¼Œè€Œæ˜¯é€šè¿‡å°‘é‡ç¤ºä¾‹å’Œè§„åˆ™è¿›è¡Œæœ‰æ•ˆçš„è½¬æ¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œç»“åˆäº†Transformeræ¶æ„ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ–°çš„æ ‡å‡†åŒ–æ–¹æ³•åœ¨å¤„ç†å¸Œè…Šæ–¹è¨€çš„åŒºåŸŸè°šè¯­æ—¶ï¼Œç›¸è¾ƒäºä»¥å¾€æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ•æ‰è¯­ä¹‰ä¿¡æ¯ï¼Œæå‡äº†æ ‡å‡†åŒ–çš„æ•ˆæœã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæä¾›ï¼Œä½†ç ”ç©¶è¡¨æ˜æ–°æ–¹æ³•èƒ½å¤Ÿè¶…è¶Šè¡¨é¢è¯­è¨€ç‰¹å¾çš„é™åˆ¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ–¹è¨€è¯†åˆ«ç­‰ã€‚é€šè¿‡æœ‰æ•ˆçš„æ–¹è¨€æ ‡å‡†åŒ–ï¼Œå¯ä»¥æå‡ä½èµ„æºè¯­è¨€çš„å¤„ç†èƒ½åŠ›ï¼Œä¿ƒè¿›å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„äº¤æµä¸ç†è§£ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Natural language understanding systems struggle with low-resource languages, including many dialects of high-resource ones. Dialect-to-standard normalization attempts to tackle this issue by transforming dialectal text so that it can be used by standard-language tools downstream. In this study, we tackle this task by introducing a new normalization method that combines rule-based linguistically informed transformations and large language models (LLMs) with targeted few-shot prompting, without requiring any parallel data. We implement our method for Greek dialects and apply it on a dataset of regional proverbs, evaluating the outputs using human annotators. We then use this dataset to conduct downstream experiments, finding that previous results regarding these proverbs relied solely on superficial linguistic information, including orthographic artifacts, while new observations can still be made through the remaining semantics.

