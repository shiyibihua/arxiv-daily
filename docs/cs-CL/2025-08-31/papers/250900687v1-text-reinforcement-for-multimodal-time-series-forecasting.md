---
layout: default
title: Text Reinforcement for Multimodal Time Series Forecasting
---

# Text Reinforcement for Multimodal Time Series Forecasting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00687" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.00687v1</a>
  <a href="https://arxiv.org/pdf/2509.00687.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00687v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00687v1', 'Text Reinforcement for Multimodal Time Series Forecasting')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chen Su, Yuanhe Tian, Yan Song, Yongdong Zhang

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-31

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÊñáÊú¨Âº∫ÂåñÊ®°Âûã‰ª•ÊèêÂçáÂ§öÊ®°ÊÄÅÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÊÄßËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êó∂Èó¥Â∫èÂàóÈ¢ÑÊµã` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÊñáÊú¨Âº∫Âåñ` `Âº∫ÂåñÂ≠¶‰π†` `Ê®°Âûã‰ºòÂåñ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÊñπÊ≥ï‰æùËµñÈ´òË¥®ÈáèÊñáÊú¨ÔºåÊñáÊú¨‰ø°ÊÅØ‰∏çË∂≥ÂØºËá¥È¢ÑÊµãÊÄßËÉΩ‰∏çÁ®≥ÂÆö„ÄÇ
2. ÊèêÂá∫ÊñáÊú¨Âº∫ÂåñÊ®°ÂûãÔºàTeRÔºâÔºåÈÄöËøáÁîüÊàêÂº∫ÂåñÊñáÊú¨Êù•ÊîπÂñÑÂéüÂßãÊñáÊú¨ÁöÑ‰∏çË∂≥ÔºåÊèêÂçáÂ§öÊ®°ÊÄÅTSFÊ®°ÂûãÁöÑÁêÜËß£ËÉΩÂäõ„ÄÇ
3. Âú®ÁúüÂÆû‰∏ñÁïåÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äËøõË°åÂπøÊ≥õÂÆûÈ™åÔºåÁªìÊûúÊòæÁ§∫ËØ•ÊñπÊ≥ïË∂ÖË∂ä‰∫ÜÂ§ö‰∏™Âº∫Âü∫Á∫øÔºåÊòæËëóÊèêÂçá‰∫ÜÈ¢ÑÊµãÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËøëÂπ¥Êù•ÔºåÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÔºàTSFÔºâÁ†îÁ©∂Âà©Áî®Â§öÊ®°ÊÄÅËæìÂÖ•ÔºàÂ¶ÇÊñáÊú¨ÂíåÂéÜÂè≤Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆÔºâÊù•È¢ÑÊµãÊú™Êù•ÂÄº„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÈ´òË¥®ÈáèÁöÑÊñáÊú¨ÂíåÊó∂Èó¥Â∫èÂàóËæìÂÖ•ÔºåÂØºËá¥Âú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÊñáÊú¨Êú™ËÉΩÂáÜÁ°ÆÊçïÊçâÂéÜÂè≤Êó∂Èó¥Â∫èÂàóÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂΩ±ÂìçÈ¢ÑÊµãÊÄßËÉΩ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñáÊú¨Âº∫ÂåñÊ®°ÂûãÔºàTeRÔºâÔºåÊó®Âú®ÁîüÊàêÂº∫ÂåñÊñáÊú¨‰ª•Âº•Ë°•ÂéüÂßãÊñáÊú¨ÁöÑ‰∏çË∂≥ÔºåÂπ∂Â∞ÜÂÖ∂Â∫îÁî®‰∫éÂ§öÊ®°ÊÄÅTSFÊ®°ÂûãÔºå‰ª•ÊèêÂçáÈ¢ÑÊµãÊÄßËÉΩ„ÄÇÊàë‰ª¨ËÆæËÆ°‰∫Ü‰∏ÄÁßçÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÔºåÊ†πÊçÆÊØè‰∏™Âº∫ÂåñÊñáÊú¨ÂØπÂ§öÊ®°ÊÄÅTSFÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçÂíå‰∏éTSF‰ªªÂä°ÁöÑÁõ∏ÂÖ≥ÊÄßÊù•ÂàÜÈÖçÂ•ñÂä±Ôºå‰ªéËÄå‰ºòÂåñTeRÔºåÊèêÂçáÁîüÊàêÊñáÊú¨ÁöÑË¥®Èáè„ÄÇÂÆûÈ™åËØÅÊòéÔºåËØ•ÊñπÊ≥ïÂú®Â§ö‰∏™È¢ÜÂüüÁöÑÁúüÂÆûÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÂº∫Âü∫Á∫øÂíåÁé∞ÊúâÁ†îÁ©∂„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµã‰∏≠ÔºåÊñáÊú¨‰ø°ÊÅØ‰∏çË∂≥ÂØºËá¥ÁöÑÈ¢ÑÊµãÊÄßËÉΩ‰∏çÁ®≥ÂÆöÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂØπÊñáÊú¨ÂíåÊó∂Èó¥Â∫èÂàóËæìÂÖ•ÁöÑ‰æùËµñ‰ΩøÂæóÂú®ÊñáÊú¨Ë¥®Èáè‰∏ç‰Ω≥Êó∂ÔºåÊ®°ÂûãÊÄßËÉΩÂèóÂà∞ÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫ÊñáÊú¨Âº∫ÂåñÊ®°ÂûãÔºàTeRÔºâÔºåÈÄöËøáÁîüÊàêÂº∫ÂåñÊñáÊú¨Êù•Âº•Ë°•ÂéüÂßãÊñáÊú¨ÁöÑ‰∏çË∂≥ÔºåÂ¢ûÂº∫Â§öÊ®°ÊÄÅTSFÊ®°ÂûãÂØπÊó∂Èó¥Â∫èÂàóÁöÑÁêÜËß£Ôºå‰ªéËÄåÊèêÂçáÈ¢ÑÊµãÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÊñáÊú¨Âº∫ÂåñÊ®°ÂûãÔºàTeRÔºâÂíåÂº∫ÂåñÂ≠¶‰π†Êú∫Âà∂„ÄÇTeRÁîüÊàêÂº∫ÂåñÊñáÊú¨ÔºåÂº∫ÂåñÂ≠¶‰π†ÂàôÊ†πÊçÆÁîüÊàêÊñáÊú¨ÂØπTSFÊ®°ÂûãÊÄßËÉΩÁöÑÂΩ±ÂìçËøõË°å‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÂº∫ÂåñÂ≠¶‰π†Êù•ÊåáÂØºÊñáÊú¨ÁîüÊàêËøáÁ®ãÔºåÁ°Æ‰øùÁîüÊàêÁöÑÊñáÊú¨ËÉΩÂ§üÊúâÊïàÊèêÂçáTSFÊ®°ÂûãÁöÑÊÄßËÉΩÔºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÂÖ∑ÊúâÊõ¥È´òÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÂ•ñÂä±Êú∫Âà∂Êù•ËØÑ‰º∞Âº∫ÂåñÊñáÊú¨ÁöÑË¥®ÈáèÔºåÂπ∂ÈÄöËøá‰ºòÂåñÊçüÂ§±ÂáΩÊï∞Êù•ÊèêÂçáÁîüÊàêÊñáÊú¨ÁöÑÁõ∏ÂÖ≥ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊèêÂá∫ÁöÑÊñáÊú¨Âº∫ÂåñÊ®°ÂûãÂú®Â§ö‰∏™ÁúüÂÆû‰∏ñÁïåÂü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÂº∫Âü∫Á∫øÔºåÊèêÂçáÂπÖÂ∫¶ËææÂà∞10%‰ª•‰∏äÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÂú®Â§öÊ®°ÊÄÅÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµã‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÈáëËûçÂ∏ÇÂú∫È¢ÑÊµã„ÄÅÊ∞îË±°Êï∞ÊçÆÂàÜÊûêÂíåÂÅ•Â∫∑ÁõëÊµãÁ≠âÂ§ö‰∏™È¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáÂ§öÊ®°ÊÄÅÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÁöÑÊÄßËÉΩÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰∏∫ÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªüÊèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÈ¢ÑÊµãÁªìÊûúÔºåËøõËÄåÂΩ±ÂìçÂÆûÈôÖ‰∏öÂä°ÂÜ≥Á≠ñÂíåËµÑÊ∫êÈÖçÁΩÆ„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂú®Êõ¥Â§öÂ§çÊùÇÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂú∫ÊôØ‰∏≠ÂæóÂà∞Â∫îÁî®ÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent studies in time series forecasting (TSF) use multimodal inputs, such as text and historical time series data, to predict future values. These studies mainly focus on developing advanced techniques to integrate textual information with time series data to perform the task and achieve promising results. Meanwhile, these approaches rely on high-quality text and time series inputs, whereas in some cases, the text does not accurately or fully capture the information carried by the historical time series, which leads to unstable performance in multimodal TSF. Therefore, it is necessary to enhance the textual content to improve the performance of multimodal TSF. In this paper, we propose improving multimodal TSF by reinforcing the text modalities. We propose a text reinforcement model (TeR) to generate reinforced text that addresses potential weaknesses in the original text, then apply this reinforced text to support the multimodal TSF model's understanding of the time series, improving TSF performance. To guide the TeR toward producing higher-quality reinforced text, we design a reinforcement learning approach that assigns rewards based on the impact of each reinforced text on the performance of the multimodal TSF model and its relevance to the TSF task. We optimize the TeR accordingly, so as to improve the quality of the generated reinforced text and enhance TSF performance. Extensive experiments on a real-world benchmark dataset covering various domains demonstrate the effectiveness of our approach, which outperforms strong baselines and existing studies on the dataset.

