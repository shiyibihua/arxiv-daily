---
layout: default
title: Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs
---

# Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00707" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00707v2</a>
  <a href="https://arxiv.org/pdf/2509.00707.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00707v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00707v2', 'Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daehoon Gwak, Minseo Jung, Junwoo Park, Minho Park, ChaeHun Park, Junha Hyung, Jaegul Choo

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31 (æ›´æ–°: 2025-09-20)

**å¤‡æ³¨**: EMNLP 2025 Main Paper (Long)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¥–åŠ±åŠ æƒé‡‡æ ·ä»¥å¢å¼ºæ©è”½æ‰©æ•£æ¨¡å‹çš„éè‡ªå›å½’ç‰¹æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ©è”½æ‰©æ•£æ¨¡å‹` `éè‡ªå›å½’å»ºæ¨¡` `å¥–åŠ±åŠ æƒé‡‡æ ·` `åºåˆ—ç”Ÿæˆ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ©è”½æ‰©æ•£æ¨¡å‹åœ¨è§£ç æ—¶é‡‡ç”¨ç‹¬ç«‹ä»¤ç‰Œé€‰æ‹©ï¼Œå¯¼è‡´ç”Ÿæˆé¡ºåºç±»ä¼¼äºè‡ªå›å½’è¿‡ç¨‹ï¼Œé™åˆ¶äº†éè‡ªå›å½’å»ºæ¨¡çš„ä¼˜åŠ¿ã€‚
2. æœ¬æ–‡æå‡ºå¥–åŠ±åŠ æƒé‡‡æ ·ï¼ˆRWSï¼‰ï¼Œåˆ©ç”¨å¤–éƒ¨å¥–åŠ±æ¨¡å‹åœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤ä¸­è¯„ä¼°æ•´ä¸ªåºåˆ—çš„è´¨é‡ï¼Œä»¥å¢å¼ºç”Ÿæˆçš„å…¨å±€ä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRWSæ˜¾è‘—ä¿ƒè¿›äº†éè‡ªå›å½’ç”Ÿæˆé¡ºåºï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ©è”½æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰ä¸ºå¤§å‹è¯­è¨€å»ºæ¨¡æä¾›äº†æœ‰å‰æ™¯çš„éè‡ªå›å½’æ›¿ä»£æ–¹æ¡ˆã€‚ç°æœ‰çš„è§£ç æ–¹æ³•å¦‚åŸºäºç½®ä¿¡åº¦çš„é‡‡æ ·ï¼Œé€šå¸¸ç‹¬ç«‹é€‰æ‹©æ¯ä¸ªä»¤ç‰Œï¼Œå¯¼è‡´ç”Ÿæˆé¡ºåºç±»ä¼¼äºè‡ªå›å½’è¿‡ç¨‹ï¼Œé™åˆ¶äº†éè‡ªå›å½’å»ºæ¨¡çš„ä¼˜åŠ¿ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è§£ç ç­–ç•¥â€”â€”å¥–åŠ±åŠ æƒé‡‡æ ·ï¼ˆRWSï¼‰ï¼Œé€šè¿‡å¤–éƒ¨å¥–åŠ±æ¨¡å‹åœ¨è¿­ä»£æ‰©æ•£è¿‡ç¨‹ä¸­æä¾›å…¨å±€ä¿¡å·ã€‚RWSåœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤ä¸­è¯„ä¼°æ•´ä¸ªä¸­é—´åºåˆ—çš„è´¨é‡ï¼Œå¹¶ç›¸åº”åœ°è°ƒæ•´ä»¤ç‰Œçš„logitsï¼Œä»è€Œä¿ƒè¿›æ›´éè‡ªå›å½’çš„ç”Ÿæˆé¡ºåºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRWSæ˜¾è‘—æå‡äº†éè‡ªå›å½’ç”Ÿæˆé¡ºåºï¼Œå¹¶åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå–å¾—äº†æ”¹å–„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ©è”½æ‰©æ•£æ¨¡å‹åœ¨è§£ç è¿‡ç¨‹ä¸­ä»¤ç‰Œç‹¬ç«‹é€‰æ‹©å¯¼è‡´çš„ç”Ÿæˆé¡ºåºç±»ä¼¼äºè‡ªå›å½’è¿‡ç¨‹çš„é—®é¢˜ã€‚è¿™ç§ç°è±¡é™åˆ¶äº†éè‡ªå›å½’å»ºæ¨¡çš„ä¼˜åŠ¿ï¼Œå½±å“äº†ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å¥–åŠ±åŠ æƒé‡‡æ ·ï¼ˆRWSï¼‰ç­–ç•¥ï¼Œé€šè¿‡å¼•å…¥å¤–éƒ¨å¥–åŠ±æ¨¡å‹ï¼Œåœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤ä¸­è¯„ä¼°æ•´ä¸ªåºåˆ—çš„è´¨é‡ï¼Œä»è€Œè°ƒæ•´ä»¤ç‰Œçš„é€‰æ‹©è¿‡ç¨‹ï¼Œä¿ƒè¿›æ›´éè‡ªå›å½’çš„ç”Ÿæˆé¡ºåºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRWSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œåœ¨æ¯ä¸ªæ‰©æ•£æ­¥éª¤ä¸­è¯„ä¼°å½“å‰ç”Ÿæˆåºåˆ—çš„è´¨é‡ï¼›å…¶æ¬¡ï¼Œæ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´ä»¤ç‰Œçš„logitsï¼›æœ€åï¼ŒåŸºäºè°ƒæ•´åçš„logitsè¿›è¡Œä»¤ç‰Œé€‰æ‹©ï¼Œç¡®ä¿ç”Ÿæˆçš„åºåˆ—å…·æœ‰æ›´å¥½çš„å…¨å±€ä¸€è‡´æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šRWSçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥å¤–éƒ¨å¥–åŠ±æ¨¡å‹è¿›è¡Œå…¨å±€åºåˆ—è´¨é‡è¯„ä¼°ï¼Œå¹¶é€šè¿‡logitsçš„åŠ æƒè°ƒæ•´å®ç°ä»¤ç‰Œé€‰æ‹©çš„å…¨å±€ä¼˜åŒ–ã€‚è¿™ä¸ä¼ ç»Ÿçš„ç‹¬ç«‹ä»¤ç‰Œé€‰æ‹©æ–¹æ³•å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RWSä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å¥–åŠ±æ¨¡å‹çš„è®¾è®¡ã€logitsçš„åŠ æƒç­–ç•¥ä»¥åŠç”Ÿæˆåºåˆ—çš„è¯„ä¼°æ ‡å‡†ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å…¨å±€ä¸€è‡´æ€§å’Œéè‡ªå›å½’ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒRWSæ˜¾è‘—ä¿ƒè¿›äº†éè‡ªå›å½’ç”Ÿæˆé¡ºåºï¼Œæå‡å¹…åº¦åœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡æœ‰æ˜¾è‘—æ”¹å–„ã€‚ä¾‹å¦‚ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒRWSåœ¨ç”Ÿæˆè´¨é‡å’Œä¸€è‡´æ€§ä¸Šå‡æœ‰æ˜æ˜¾æå‡ï¼Œå…·ä½“æ•°æ®æœªæä¾›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿä»¥åŠæœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡æå‡éè‡ªå›å½’æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼ŒRWSèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æé«˜ç”Ÿæˆæ•ˆç‡å’Œç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked diffusion models (MDMs) offer a promising non-autoregressive alternative for large language modeling. Standard decoding methods for MDMs, such as confidence-based sampling, select tokens independently based on individual token confidences at each diffusion step. However, we observe that this independent token selection often results in generation orders resembling sequential autoregressive processes, limiting the advantages of non-autoregressive modeling. To mitigate this pheonomenon, we propose Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an external reward model to provide a principled global signal during the iterative diffusion process. Specifically, at each diffusion step, RWS evaluates the quality of the entire intermediate sequence and scales token logits accordingly, guiding token selection by integrating global sequence-level coherence. This method selectively increases the confidence of tokens that initially have lower scores, thereby promoting a more non-autoregressive generation order. Furthermore, we provide theoretical justification showing that reward-weighted logit scaling induces beneficial rank reversals in token selection and consistently improves expected reward. Experiments demonstrate that RWS significantly promotes non-autoregressive generation orders, leading to improvements across multiple evaluation metrics. These results highlight the effectiveness of integrating global signals in enhancing both the non-autoregressive properties and overall performance of MDMs.

