---
layout: default
title: Jackal: A Real-World Execution-Based Benchmark Evaluating Large Language Models on Text-to-JQL Tasks
---

# Jackal: A Real-World Execution-Based Benchmark Evaluating Large Language Models on Text-to-JQL Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23579" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.23579v1</a>
  <a href="https://arxiv.org/pdf/2509.23579.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23579v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23579v1', 'Jackal: A Real-World Execution-Based Benchmark Evaluating Large Language Models on Text-to-JQL Tasks')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Kevin Frank, Anmol Gulati, Elias Lumer, Sindy Campagna, Vamse Kumar Subbiah

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-28

**Â§áÊ≥®**: 17 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫JackalÔºö‰∏Ä‰∏™Âü∫‰∫éÁúüÂÆûÊâßË°åÁöÑÊñáÊú¨Âà∞JQLÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãËØÑÊµãÂü∫ÂáÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊñáÊú¨Âà∞JQL` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `ÊâßË°åÂü∫ÂáÜ` `JiraÊü•ËØ¢ËØ≠Ë®Ä` `Ëá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂú®ÁúüÂÆûJiraÁéØÂ¢É‰∏ãÔºåÂØπËá™ÁÑ∂ËØ≠Ë®ÄÂà∞JQLËΩ¨Êç¢ÁöÑÊúâÊïàËØÑ‰º∞Âü∫ÂáÜÔºåÈöæ‰ª•ÂèçÊò†ÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØ„ÄÇ
2. JackalÈÄöËøáÊûÑÂª∫ÂåÖÂê´10‰∏á‰∏™ÁúüÂÆûJQLÊü•ËØ¢ÂØπÁöÑÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÂπ∂ÈááÁî®Âü∫‰∫éÊâßË°åÁöÑËØÑ‰º∞ÊñπÊ≥ïÔºåÂº•Ë°•‰∫ÜËøô‰∏ÄÁ©∫ÁôΩ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåÂç≥‰ΩøÊòØGemini 2.5 ProÂú®Jackal-5KÂ≠êÈõÜ‰∏äÁöÑÂπ≥ÂùáÊâßË°åÂáÜÁ°ÆÁéá‰ªÖ‰∏∫60.3%ÔºåÂá∏Êòæ‰∫ÜÁé∞ÊúâLLMÁöÑ‰∏çË∂≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰ºÅ‰∏öÂõ¢Èòü‰æùËµñJiraÊü•ËØ¢ËØ≠Ë®Ä(JQL)‰ªéJira‰∏≠Ê£ÄÁ¥¢ÂíåËøáÊª§ÈóÆÈ¢ò„ÄÇÁÑ∂ËÄåÔºåÊçÆÊàë‰ª¨ÊâÄÁü•ÔºåÁõÆÂâçËøòÊ≤°ÊúâÂºÄÊîæÁöÑ„ÄÅÁúüÂÆûÁöÑ„ÄÅÂü∫‰∫éÊâßË°åÁöÑÂü∫ÂáÜÊù•ËØÑ‰º∞Ëá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢Âà∞JQLÁöÑÊò†Â∞Ñ„ÄÇÊàë‰ª¨Êé®Âá∫‰∫ÜJackalÔºåËøôÊòØ‰∏Ä‰∏™Êñ∞È¢ñÁöÑÂ§ßËßÑÊ®°ÊñáÊú¨Âà∞JQLÂü∫ÂáÜÔºåÂåÖÂê´10‰∏á‰∏™Ëá™ÁÑ∂ËØ≠Ë®Ä(NL)ËØ∑Ê±ÇÔºåÂπ∂ÈÖçÊúâÁªèËøáÈ™åËØÅÁöÑJQLÊü•ËØ¢‰ª•ÂèäÂú®ÂåÖÂê´Ë∂ÖËøá20‰∏á‰∏™ÈóÆÈ¢òÁöÑÂÆûÊó∂JiraÂÆû‰æã‰∏äÊâßË°åÁöÑÁªìÊûú„ÄÇ‰∏∫‰∫ÜÂèçÊò†ÁúüÂÆû‰∏ñÁïåÁöÑÁî®Ê≥ïÔºåÊØè‰∏™JQLÊü•ËØ¢ÈÉΩ‰∏éÂõõÁßçÁ±ªÂûãÁöÑÁî®Êà∑ËØ∑Ê±ÇÁõ∏ÂÖ≥ËÅîÔºö(i)ÈïøËá™ÁÑ∂ËØ≠Ë®ÄÔºå(ii)Áü≠Ëá™ÁÑ∂ËØ≠Ë®ÄÔºå(iii)ËØ≠‰πâÁõ∏‰ººÔºå‰ª•Âèä(iv)ËØ≠‰πâÁ≤æÁ°Æ„ÄÇÊàë‰ª¨ÂèëÂ∏ÉJackalÔºå‰∏Ä‰∏™ÂåÖÂê´10‰∏á‰∏™ÊñáÊú¨Âà∞JQLÂØπÁöÑËØ≠ÊñôÂ∫ìÔºå‰ª•Âèä‰∏Ä‰∏™Âü∫‰∫éÊâßË°åÁöÑËØÑÂàÜÂ∑•ÂÖ∑ÂåÖÔºå‰ª•Âèä‰∏Ä‰∏™Áî®‰∫éÈáçÁé∞ÊÄßÁöÑÂ∑≤ËØÑ‰º∞JiraÂÆû‰æãÁöÑÈùôÊÄÅÂø´ÁÖß„ÄÇÊàë‰ª¨Êä•Âëä‰∫Ü23‰∏™Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)Âú®ÊñáÊú¨Âà∞JQL‰∏äÁöÑÁªìÊûúÔºåËøô‰∫õÊ®°ÂûãÊ∂µÁõñ‰∫ÜÂèÇÊï∞Â§ßÂ∞è„ÄÅÂºÄÊ∫êÂíåÈó≠Ê∫êÊ®°ÂûãÔºå‰ª•ÂèäÊâßË°åÂáÜÁ°ÆÁéá„ÄÅÁ≤æÁ°ÆÂåπÈÖçÂíåËßÑËåÉÁ≤æÁ°ÆÂåπÈÖç„ÄÇÂú®Êú¨Êñá‰∏≠ÔºåÊàë‰ª¨Êä•Âëä‰∫ÜJackal-5KÁöÑÁªìÊûúÔºåÂÆÉÊòØJackalÁöÑ‰∏Ä‰∏™5000ÂØπÁöÑÂ≠êÈõÜ„ÄÇÂú®Jackal-5K‰∏äÔºåÊúÄ‰Ω≥Êï¥‰ΩìÊ®°Âûã(Gemini 2.5 Pro)Âú®ÂõõÁßçÁî®Êà∑ËØ∑Ê±ÇÁ±ªÂûã‰∏äÂπ≥Âùá‰ªÖËææÂà∞60.3%ÁöÑÊâßË°åÂáÜÁ°ÆÁéá„ÄÇÊÄßËÉΩÂú®Áî®Êà∑ËØ∑Ê±ÇÁ±ªÂûã‰πãÈó¥Â∑ÆÂºÇÂæàÂ§ßÔºö(i)ÈïøËá™ÁÑ∂ËØ≠Ë®Ä(86.0%)Ôºå(ii)Áü≠Ëá™ÁÑ∂ËØ≠Ë®Ä(35.7%)Ôºå(iii)ËØ≠‰πâÁõ∏‰ºº(22.7%)Ôºå‰ª•Âèä(iv)ËØ≠‰πâÁ≤æÁ°Æ(99.3%)„ÄÇÈÄöËøáÂü∫ÂáÜÊµãËØïLLMÁîüÊàêÊ≠£Á°ÆÂíåÂèØÊâßË°åÁöÑJQLÊü•ËØ¢ÁöÑËÉΩÂäõÔºåJackalÊè≠Á§∫‰∫ÜÂΩìÂâçÊúÄÂÖàËøõÁöÑLLMÁöÑÂ±ÄÈôêÊÄßÔºåÂπ∂‰∏∫Jira‰ºÅ‰∏öÊï∞ÊçÆÊú™Êù•ÁöÑÁ†îÁ©∂ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑ„ÄÅÂü∫‰∫éÊâßË°åÁöÑÊåëÊàò„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â∞ÜËá™ÁÑ∂ËØ≠Ë®ÄÊü•ËØ¢ËΩ¨Êç¢‰∏∫JQLÊü•ËØ¢ÁöÑÈóÆÈ¢òÔºåÂπ∂Êèê‰æõ‰∏Ä‰∏™ÂèØÈù†ÁöÑËØÑ‰º∞Âü∫ÂáÜ„ÄÇÁé∞ÊúâÊñπÊ≥ïÁº∫‰πèÂú®ÁúüÂÆûJiraÂÆû‰æã‰∏äÁöÑÊâßË°åÈ™åËØÅÔºåÊó†Ê≥ïÂáÜÁ°ÆÂèçÊò†Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÁº∫‰πèÂå∫ÂàÜ‰∏çÂêåÁ±ªÂûãÁî®Êà∑ËØ∑Ê±ÇÔºàÈïø/Áü≠Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÅËØ≠‰πâÁõ∏‰ºº/Á≤æÁ°ÆÔºâÁöÑÁªÜÁ≤íÂ∫¶ËØÑ‰º∞„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™Â§ßËßÑÊ®°„ÄÅÁúüÂÆû‰∏ñÁïåÁöÑÊñáÊú¨Âà∞JQLÊï∞ÊçÆÈõÜÔºåÂπ∂ÈááÁî®Âü∫‰∫éJiraÂÆû‰æãÊâßË°åÁªìÊûúÁöÑËØÑ‰º∞ÊñπÊ≥ï„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåÂèØ‰ª•Êõ¥ÂáÜÁ°ÆÂú∞Ë°°ÈáèÊ®°ÂûãÁîüÊàêJQLÊü•ËØ¢ÁöÑË¥®ÈáèÔºåÂπ∂ÂèëÁé∞Ê®°ÂûãÂú®‰∏çÂêåÁ±ªÂûãÁî®Êà∑ËØ∑Ê±Ç‰∏ãÁöÑÊÄßËÉΩÂ∑ÆÂºÇ„ÄÇÊï∞ÊçÆÈõÜÁöÑËÆæËÆ°ËÄÉËôë‰∫ÜÁúüÂÆûÁî®Êà∑ÁöÑ‰ΩøÁî®Âú∫ÊôØÔºåÂåÖÂê´Â§öÁßçÁ±ªÂûãÁöÑËá™ÁÑ∂ËØ≠Ë®ÄË°®Ëææ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöJackalÂü∫ÂáÜÊµãËØïÂåÖÂê´‰ª•‰∏ã‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºö1) ÂåÖÂê´10‰∏á‰∏™ÊñáÊú¨Âà∞JQLÂØπÁöÑÊï∞ÊçÆÈõÜÔºåÊØè‰∏™JQLÊü•ËØ¢ÂØπÂ∫îÂõõÁßçÁ±ªÂûãÁöÑÁî®Êà∑ËØ∑Ê±ÇÔºõ2) Âü∫‰∫éÁúüÂÆûJiraÂÆû‰æãÁöÑÊâßË°åÁéØÂ¢ÉÔºåÁî®‰∫éÈ™åËØÅJQLÊü•ËØ¢ÁöÑÊ≠£Á°ÆÊÄßÔºõ3) ËØÑ‰º∞ÊåáÊ†áÔºåÂåÖÊã¨ÊâßË°åÂáÜÁ°ÆÁéá„ÄÅÁ≤æÁ°ÆÂåπÈÖçÂíåËßÑËåÉÁ≤æÁ°ÆÂåπÈÖçÔºõ4) Áî®‰∫éÈáçÁé∞ÊÄßÁöÑJiraÂÆû‰æãÈùôÊÄÅÂø´ÁÖß„ÄÇÁ†îÁ©∂ËÄÖÂèØ‰ª•‰ΩøÁî®ËØ•Âü∫ÂáÜÊµãËØïËØÑ‰º∞ÂêÑÁßçLLMÂú®ÊñáÊú¨Âà∞JQL‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Âü∫‰∫éÁúüÂÆûÊâßË°åÁöÑËØÑ‰º∞ÊñπÊ≥ï„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éÊñáÊú¨ÂåπÈÖçÁöÑËØÑ‰º∞ÊñπÊ≥ï‰∏çÂêåÔºåJackalÈÄöËøáÂú®ÁúüÂÆûÁöÑJiraÂÆû‰æã‰∏äÊâßË°åÁîüÊàêÁöÑJQLÊü•ËØ¢ÔºåÊù•È™åËØÅÂÖ∂ÊòØÂê¶ËÉΩÂ§üËøîÂõûÊ≠£Á°ÆÁöÑÁªìÊûú„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§üÊõ¥ÂáÜÁ°ÆÂú∞ÂèçÊò†Ê®°ÂûãÂú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊÄßËÉΩÔºåÂπ∂ÂèëÁé∞Ê®°ÂûãÂú®Â§ÑÁêÜÂ§çÊùÇÊü•ËØ¢Âíå‰∏çÂêåÁ±ªÂûãÁî®Êà∑ËØ∑Ê±ÇÊó∂ÁöÑ‰∏çË∂≥„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÊï∞ÊçÆÈõÜÂåÖÂê´ÂõõÁßçÁ±ªÂûãÁöÑÁî®Êà∑ËØ∑Ê±ÇÔºå‰ª•Ê®°ÊãüÁúüÂÆû‰∏ñÁïåÁöÑ‰ΩøÁî®Âú∫ÊôØ„ÄÇÈïøËá™ÁÑ∂ËØ≠Ë®ÄËØ∑Ê±ÇÊèê‰æõÊõ¥ËØ¶ÁªÜÁöÑ‰∏ä‰∏ãÊñáÔºåËÄåÁü≠Ëá™ÁÑ∂ËØ≠Ë®ÄËØ∑Ê±ÇÂàôÊõ¥ÁÆÄÊ¥Å„ÄÇËØ≠‰πâÁõ∏‰ººËØ∑Ê±ÇÊµãËØïÊ®°ÂûãÁêÜËß£ËØ≠‰πâÂèò‰ΩìÁöÑËÉΩÂäõÔºåËÄåËØ≠‰πâÁ≤æÁ°ÆËØ∑Ê±ÇÂàôË¶ÅÊ±ÇÊ®°ÂûãÂáÜÁ°ÆÁêÜËß£Áî®Êà∑ÁöÑÊÑèÂõæ„ÄÇËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨ÊâßË°åÂáÜÁ°ÆÁéáÔºàJQLÊü•ËØ¢ËøîÂõûÊ≠£Á°ÆÁªìÊûúÁöÑÊØî‰æãÔºâ„ÄÅÁ≤æÁ°ÆÂåπÈÖçÔºàÁîüÊàêÁöÑJQLÊü•ËØ¢‰∏éÊ†áÂáÜÁ≠îÊ°àÂÆåÂÖ®‰∏ÄËá¥ÁöÑÊØî‰æãÔºâÂíåËßÑËåÉÁ≤æÁ°ÆÂåπÈÖçÔºàÁîüÊàêÁöÑJQLÊü•ËØ¢‰∏éÊ†áÂáÜÁ≠îÊ°àÂú®ÈÄªËæë‰∏äÁ≠â‰ª∑ÁöÑÊØî‰æãÔºâ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØÁõÆÂâçÊúÄÂÖàËøõÁöÑLLMÔºàGemini 2.5 ProÔºâÂú®Jackal-5K‰∏äÁöÑÂπ≥ÂùáÊâßË°åÂáÜÁ°ÆÁéá‰ªÖ‰∏∫60.3%„ÄÇÂú®‰∏çÂêåÁ±ªÂûãÁöÑÁî®Êà∑ËØ∑Ê±Ç‰∏≠ÔºåÊÄßËÉΩÂ∑ÆÂºÇÊòæËëóÔºöÈïøËá™ÁÑ∂ËØ≠Ë®ÄËØ∑Ê±ÇÁöÑÂáÜÁ°ÆÁéáËæÉÈ´òÔºà86.0%ÔºâÔºåËÄåÁü≠Ëá™ÁÑ∂ËØ≠Ë®ÄËØ∑Ê±ÇÂíåËØ≠‰πâÁõ∏‰ººËØ∑Ê±ÇÁöÑÂáÜÁ°ÆÁéáËæÉ‰ΩéÔºàÂàÜÂà´‰∏∫35.7%Âíå22.7%Ôºâ„ÄÇËøôË°®ÊòéÁé∞ÊúâLLMÂú®ÁêÜËß£Â§çÊùÇÊü•ËØ¢ÂíåÂ§ÑÁêÜËØ≠‰πâÂèò‰ΩìÊñπÈù¢‰ªçÊúâÂæàÂ§ßÁöÑÊèêÂçáÁ©∫Èó¥„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰ºÅ‰∏öÁ∫ßÊô∫ËÉΩÂä©Êâã„ÄÅËá™Âä®ÂåñÁº∫Èô∑Ë∑üË∏™Á≥ªÁªüÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáLLMÂú®ÊñáÊú¨Âà∞JQLËΩ¨Êç¢‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÔºåÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥È´òÊïàÂú∞‰ªéJiraÁ≠âÁ≥ªÁªü‰∏≠Ê£ÄÁ¥¢‰ø°ÊÅØÔºåÊèêÈ´òÂ∑•‰ΩúÊïàÁéá„ÄÇÊú™Êù•ÔºåËØ•Âü∫ÂáÜÊµãËØïÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñ‰ºÅ‰∏öÁ∫ßÊï∞ÊçÆÊü•ËØ¢ËØ≠Ë®ÄÔºå‰øÉËøõÁõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Enterprise teams rely on the Jira Query Language (JQL) to retrieve and filter issues from Jira. Yet, to our knowledge, there is no open, real-world, execution-based benchmark for mapping natural language queries to JQL. We introduce Jackal, a novel, large-scale text-to-JQL benchmark comprising 100,000 natural language (NL) requests paired with validated JQL queries and execution-based results on a live Jira instance with over 200,000 issues. To reflect real-world usage, each JQL query is associated with four types of user requests: (i) Long NL, (ii) Short NL, (iii) Semantically Similar, and (iv) Semantically Exact. We release Jackal, a corpus of 100,000 text-to-JQL pairs, together with an execution-based scoring toolkit, and a static snapshot of the evaluated Jira instance for reproducibility. We report text-to-JQL results on 23 Large Language Models (LLMs) spanning parameter sizes, open and closed source models, across execution accuracy, exact match, and canonical exact match. In this paper, we report results on Jackal-5K, a 5,000-pair subset of Jackal. On Jackal-5K, the best overall model (Gemini 2.5 Pro) achieves only 60.3% execution accuracy averaged equally across four user request types. Performance varies significantly across user request types: (i) Long NL (86.0%), (ii) Short NL (35.7%), (iii) Semantically Similar (22.7%), and (iv) Semantically Exact (99.3%). By benchmarking LLMs on their ability to produce correct and executable JQL queries, Jackal exposes the limitations of current state-of-the-art LLMs and sets a new, execution-based challenge for future research in Jira enterprise data.

