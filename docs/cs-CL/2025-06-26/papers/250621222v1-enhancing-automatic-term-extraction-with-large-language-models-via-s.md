---
layout: default
title: Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval
---

# Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21222" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21222v1</a>
  <a href="https://arxiv.org/pdf/2506.21222.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21222v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21222v1', 'Enhancing Automatic Term Extraction with Large Language Models via Syntactic Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yongchan Chun, Minhyuk Kim, Dongjun Kim, Chanjun Park, Heuiseok Lim

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¥æ³•æ£€ç´¢çš„æç¤ºç­–ç•¥ä»¥å¢å¼ºè‡ªåŠ¨æœ¯è¯­æå–**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨æœ¯è¯­æå–` `å¥æ³•æ£€ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨ç¿»è¯‘` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨æœ¯è¯­æå–æ–¹æ³•åœ¨å¤„ç†é¢†åŸŸç‰¹å®šè¡¨è¾¾æ—¶ï¼Œå¾€å¾€ä¾èµ–äºè¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´æœ¯è¯­è¾¹ç•Œæ•æ‰ä¸å‡†ç¡®ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¥æ³•æ£€ç´¢çš„æç¤ºç­–ç•¥ï¼Œé€šè¿‡é€‰æ‹©å¥æ³•ç›¸ä¼¼çš„ç¤ºä¾‹æ¥å¢å¼ºè‡ªåŠ¨æœ¯è¯­æå–çš„æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¥æ³•æ£€ç´¢åœ¨å¤šä¸ªATEåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†F1åˆ†æ•°ï¼ŒéªŒè¯äº†å¥æ³•çº¿ç´¢åœ¨æœ¯è¯­æå–ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨æœ¯è¯­æå–ï¼ˆATEï¼‰æ—¨åœ¨è¯†åˆ«å¯¹ä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚æœºå™¨ç¿»è¯‘å’Œä¿¡æ¯æ£€ç´¢ï¼‰è‡³å…³é‡è¦çš„é¢†åŸŸç‰¹å®šè¡¨è¾¾ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å…¶åœ¨ATEä¸­çš„æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢çš„æç¤ºç­–ç•¥ï¼Œåœ¨å°‘é‡ç¤ºä¾‹è®¾ç½®ä¸‹ï¼Œæ ¹æ®å¥æ³•è€Œéè¯­ä¹‰ç›¸ä¼¼æ€§é€‰æ‹©ç¤ºä¾‹ã€‚è¿™ç§å¥æ³•æ£€ç´¢æ–¹æ³•å…·æœ‰é¢†åŸŸæ— å…³æ€§ï¼Œå¹¶ä¸ºæ•æ‰æœ¯è¯­è¾¹ç•Œæä¾›äº†æ›´å¯é çš„æŒ‡å¯¼ã€‚æˆ‘ä»¬åœ¨é¢†åŸŸå†…å’Œè·¨é¢†åŸŸè®¾ç½®ä¸­è¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œåˆ†æäº†æŸ¥è¯¢å¥å­ä¸æ£€ç´¢ç¤ºä¾‹ä¹‹é—´çš„è¯æ±‡é‡å å¦‚ä½•å½±å“æ€§èƒ½ã€‚åœ¨ä¸‰ä¸ªä¸“ä¸šçš„ATEåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå¥æ³•æ£€ç´¢æé«˜äº†F1åˆ†æ•°ã€‚è¿™äº›å‘ç°çªæ˜¾äº†åœ¨å°†LLMsåº”ç”¨äºæœ¯è¯­æå–ä»»åŠ¡æ—¶å¥æ³•çº¿ç´¢çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„å…·ä½“é—®é¢˜æ˜¯å¦‚ä½•æé«˜è‡ªåŠ¨æœ¯è¯­æå–ï¼ˆATEï¼‰çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ç°æœ‰æ–¹æ³•ä¸­ï¼Œä¾èµ–è¯­ä¹‰ç›¸ä¼¼æ€§å¯¼è‡´æœ¯è¯­è¾¹ç•Œè¯†åˆ«ä¸å‡†ç¡®çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯å¼•å…¥åŸºäºå¥æ³•çš„æ£€ç´¢ç­–ç•¥ï¼Œé€šè¿‡é€‰æ‹©å¥æ³•ç›¸ä¼¼çš„ç¤ºä¾‹æ¥æä¾›æ›´å¯é çš„æŒ‡å¯¼ï¼Œä»è€Œæ”¹å–„æœ¯è¯­æå–çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå¥æ³•æ£€ç´¢æ¨¡å—å’Œæœ¯è¯­æå–æ¨¡å—ã€‚å¥æ³•æ£€ç´¢æ¨¡å—è´Ÿè´£ä»ç¤ºä¾‹åº“ä¸­æ£€ç´¢ä¸æŸ¥è¯¢å¥å­åœ¨å¥æ³•ä¸Šç›¸ä¼¼çš„ç¤ºä¾‹ï¼Œè€Œæœ¯è¯­æå–æ¨¡å—åˆ™åˆ©ç”¨è¿™äº›ç¤ºä¾‹æ¥æŒ‡å¯¼æœ¯è¯­è¾¹ç•Œçš„è¯†åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥å¥æ³•ç›¸ä¼¼æ€§ä½œä¸ºæ£€ç´¢æ ‡å‡†ï¼Œè€Œéä¼ ç»Ÿçš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸä¸­å…·æœ‰æ›´å¥½çš„é€‚åº”æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¨¡å‹é‡‡ç”¨äº†å°‘é‡ç¤ºä¾‹çš„å­¦ä¹ ç­–ç•¥ï¼Œå¹¶é€šè¿‡ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¥æ³•æ£€ç´¢çš„æ•ˆæœï¼Œç¡®ä¿åœ¨ä¸åŒé¢†åŸŸçš„åº”ç”¨ä¸­éƒ½èƒ½ä¿æŒé«˜æ•ˆçš„æœ¯è¯­æå–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨å¥æ³•æ£€ç´¢çš„è‡ªåŠ¨æœ¯è¯­æå–æ–¹æ³•åœ¨ä¸‰ä¸ªä¸“ä¸šATEåŸºå‡†æµ‹è¯•ä¸­ï¼ŒF1åˆ†æ•°æ˜¾è‘—æé«˜ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨ç¿»è¯‘ã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†å›¾è°±æ„å»ºç­‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡é¢†åŸŸç‰¹å®šæœ¯è¯­çš„è¯†åˆ«å‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­æ¨å¹¿åº”ç”¨ï¼Œä¿ƒè¿›ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Automatic Term Extraction (ATE) identifies domain-specific expressions that are crucial for downstream tasks such as machine translation and information retrieval. Although large language models (LLMs) have significantly advanced various NLP tasks, their potential for ATE has scarcely been examined. We propose a retrieval-based prompting strategy that, in the few-shot setting, selects demonstrations according to \emph{syntactic} rather than semantic similarity. This syntactic retrieval method is domain-agnostic and provides more reliable guidance for capturing term boundaries. We evaluate the approach in both in-domain and cross-domain settings, analyzing how lexical overlap between the query sentence and its retrieved examples affects performance. Experiments on three specialized ATE benchmarks show that syntactic retrieval improves F1-score. These findings highlight the importance of syntactic cues when adapting LLMs to terminology-extraction tasks.

