---
layout: default
title: Text2Cypher Across Languages: Evaluating and Finetuning LLMs
---

# Text2Cypher Across Languages: Evaluating and Finetuning LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21445" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21445v2</a>
  <a href="https://arxiv.org/pdf/2506.21445.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21445v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21445v2', 'Text2Cypher Across Languages: Evaluating and Finetuning LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Makbule Gulcin Ozsoy, William Tai

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-09-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè¯­è¨€Text2Cypherè¯„ä¼°ä¸å¾®è°ƒæ–¹æ³•ä»¥æå‡æ•°æ®åº“æŸ¥è¯¢ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šè¯­è¨€å¤„ç†` `æ•°æ®åº“æŸ¥è¯¢` `è‡ªç„¶è¯­è¨€æ¥å£` `è·¨è¯­è¨€è¯„ä¼°` `å¾®è°ƒæŠ€æœ¯` `CypheræŸ¥è¯¢ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„Text2Cypheræ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è‹±è¯­ï¼Œå…¶ä»–è¯­è¨€çš„è¯„ä¼°å’Œæ€§èƒ½åˆ†æç›¸å¯¹ä¸è¶³ï¼Œå¯¼è‡´å¤šè¯­è¨€æŸ¥è¯¢ç”Ÿæˆç³»ç»Ÿçš„æ„å»ºé¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡é€šè¿‡åˆ›å»ºå¤šè¯­è¨€æ•°æ®é›†å¹¶è¯„ä¼°åŸºç¡€å’Œå¾®è°ƒçš„LLMsï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è·¨è¯­è¨€æ¯”è¾ƒæ–¹æ³•ï¼Œä»¥è§£å†³ç°æœ‰ç ”ç©¶çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåŸºç¡€æ¨¡å‹åœ¨å¤šè¯­è¨€æ•°æ®é›†ä¸Šèƒ½æ˜¾è‘—ç¼©å°è¯­è¨€é—´çš„æ€§èƒ½å·®è·ï¼Œæå‡äº†æŸ¥è¯¢ç”Ÿæˆçš„å‡è¡¡æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥ä½¿å¾—è‡ªç„¶è¯­è¨€æ¥å£èƒ½å¤Ÿå°†ç”¨æˆ·é—®é¢˜è½¬åŒ–ä¸ºæ•°æ®åº“æŸ¥è¯¢ï¼Œå¦‚Text2SQLã€Text2SPARQLå’ŒText2Cypherã€‚å°½ç®¡è¿™äº›æ¥å£æé«˜äº†æ•°æ®åº“çš„å¯è®¿é—®æ€§ï¼Œä½†å¤§å¤šæ•°ç ”ç©¶é›†ä¸­åœ¨è‹±è¯­ä¸Šï¼Œå…¶ä»–è¯­è¨€çš„è¯„ä¼°ç›¸å¯¹æœ‰é™ã€‚æœ¬æ–‡ç ”ç©¶äº†åŸºç¡€å’Œå¾®è°ƒçš„LLMsåœ¨å¤šè¯­è¨€Text2Cypherä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œåˆ›å»ºå¹¶å‘å¸ƒäº†ä¸€ä¸ªå¤šè¯­è¨€æ•°æ®é›†ï¼Œé€šè¿‡å°†è‹±è¯­é—®é¢˜ç¿»è¯‘æˆè¥¿ç­ç‰™è¯­å’ŒåœŸè€³å…¶è¯­ï¼ŒåŒæ—¶ä¿ç•™åŸå§‹çš„CypheræŸ¥è¯¢ï¼Œä»è€Œå®ç°å…¬å¹³çš„è·¨è¯­è¨€æ¯”è¾ƒã€‚æˆ‘ä»¬å‘ç°ï¼Œè‹±è¯­çš„è¡¨ç°æœ€ä½³ï¼Œå…¶æ¬¡æ˜¯è¥¿ç­ç‰™è¯­ï¼ŒåœŸè€³å…¶è¯­è¡¨ç°æœ€ä½ï¼Œè¿™ä¸è®­ç»ƒæ•°æ®çš„å¯ç”¨æ€§å’Œè¯­è¨€ç‰¹å¾çš„å·®å¼‚æœ‰å…³ã€‚å¾®è°ƒç»“æœæ˜¾ç¤ºï¼Œè‹±è¯­å¾®è°ƒæé«˜äº†æ•´ä½“å‡†ç¡®æ€§ï¼Œä½†æ‰©å¤§äº†è¯­è¨€é—´çš„è¡¨ç°å·®è·ï¼Œè€Œå¤šè¯­è¨€å¾®è°ƒåˆ™ç¼©å°äº†è¿™ä¸€å·®è·ï¼Œæå‡äº†æ€§èƒ½çš„å‡è¡¡æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰Text2Cypheræ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è¯„ä¼°ä¸è¶³ï¼Œå°¤å…¶æ˜¯éè‹±è¯­è¯­è¨€çš„è¡¨ç°è¾ƒå·®ï¼Œå½±å“äº†æ•°æ®åº“æŸ¥è¯¢ç”Ÿæˆçš„æ™®é€‚æ€§å’Œå¯ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ›å»ºä¸€ä¸ªå¤šè¯­è¨€æ•°æ®é›†ï¼Œå°†è‹±è¯­é—®é¢˜ç¿»è¯‘ä¸ºè¥¿ç­ç‰™è¯­å’ŒåœŸè€³å…¶è¯­ï¼Œå¹¶ä¿ç•™åŸå§‹çš„CypheræŸ¥è¯¢ï¼Œä»è€Œå®ç°å…¬å¹³çš„è·¨è¯­è¨€æ€§èƒ½æ¯”è¾ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ¨¡å‹çš„è¯„ä¼°å’Œå¾®è°ƒä¸¤ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºå¤šè¯­è¨€æ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨æ ‡å‡†åŒ–çš„æç¤ºå’Œè¯„ä¼°æŒ‡æ ‡å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œè¯„ä¼°å’Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†å¤šè¯­è¨€æ•°æ®é›†çš„æ„å»ºå’Œè¯„ä¼°æ–¹æ³•ï¼Œå¼ºè°ƒäº†å¾®è°ƒå¯¹ä¸åŒè¯­è¨€é—´æ€§èƒ½å·®è·çš„å½±å“ï¼Œå°¤å…¶æ˜¯å¤šè¯­è¨€å¾®è°ƒçš„ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„è®­ç»ƒæ•°æ®é›†ï¼ŒåŒ…æ‹¬ä»…è‹±è¯­å’Œå¤šè¯­è¨€æ•°æ®é›†ï¼Œé‡‡ç”¨æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡æ¨¡å‹æ€§èƒ½ï¼Œç¡®ä¿äº†å®éªŒçš„å¯é‡å¤æ€§å’Œç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºç¡€æ¨¡å‹åœ¨è‹±è¯­ä¸Šçš„è¡¨ç°æœ€ä½³ï¼Œè¥¿ç­ç‰™è¯­æ¬¡ä¹‹ï¼Œè€ŒåœŸè€³å…¶è¯­è¡¨ç°æœ€ä½ã€‚å¾®è°ƒåŸºç¡€æ¨¡å‹åœ¨è‹±è¯­æ•°æ®é›†ä¸Šæå‡äº†å‡†ç¡®æ€§ï¼Œä½†æ‰©å¤§äº†è¯­è¨€é—´å·®è·ï¼›è€Œå¤šè¯­è¨€å¾®è°ƒåˆ™æ˜¾è‘—ç¼©å°äº†è¿™ä¸€å·®è·ï¼Œæå‡äº†æ€§èƒ½å‡è¡¡æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šè¯­è¨€æ•°æ®åº“æŸ¥è¯¢ç”Ÿæˆã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢å’Œè‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿçš„å¼€å‘ã€‚é€šè¿‡æå‡ä¸åŒè¯­è¨€é—´çš„æŸ¥è¯¢ç”Ÿæˆèƒ½åŠ›ï¼Œèƒ½å¤Ÿä½¿å¾—æ›´å¤šç”¨æˆ·æ— éšœç¢åœ°è®¿é—®å’Œåˆ©ç”¨æ•°æ®åº“ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have enabled natural language interfaces that translate user questions into database queries, such as Text2SQL, Text2SPARQL, and Text2Cypher. While these interfaces enhance database accessibility, most research today focuses on English, with limited evaluation in other languages. This paper investigates the performance of both foundational and finetuned LLMs on the Text2Cypher task across multiple languages. We create and release a multilingual dataset by translating English questions into Spanish and Turkish while preserving the original Cypher queries, enabling fair cross-lingual comparison. Using standardized prompts and metrics, we evaluate several foundational models and observe a consistent performance pattern: highest on English, followed by Spanish, and lowest on Turkish. We attribute this to differences in training data availability and linguistic features. We also examine the impact of translating task prompts into Spanish and Turkish. Results show little to no change in evaluation metrics, suggesting prompt translation has minor impact. Furthermore, we finetune a foundational model on two datasets: one in English only, and one multilingual. Finetuning on English improves overall accuracy but widens the performance gap between languages. In contrast, multilingual finetuning narrows the gap, resulting in more balanced performance. Our findings highlight the importance for multilingual evaluation and training to build more inclusive and robust query generation systems.

