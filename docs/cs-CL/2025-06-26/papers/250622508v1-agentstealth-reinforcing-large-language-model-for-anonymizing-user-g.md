---
layout: default
title: AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text
---

# AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22508" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22508v1</a>
  <a href="https://arxiv.org/pdf/2506.22508.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22508v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22508v1', 'AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenyang Shao, Tianxing Li, Chenhao Pu, Fengli Xu, Yong Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: This work has been submitted to NeurIPS 2025. Under review

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/tsinghua-fib-lab/AgentStealth)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentStealthä»¥è§£å†³ç”¨æˆ·ç”Ÿæˆæ–‡æœ¬åŒ¿ååŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬åŒ¿ååŒ–` `ç”¨æˆ·éšç§` `å°è§„æ¨¡è¯­è¨€æ¨¡å‹` `å¯¹æŠ—æ€§å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ–‡æœ¬åŒ¿ååŒ–æ–¹æ³•è¦ä¹ˆæŸå®³æ–‡æœ¬çš„å®ç”¨æ€§ï¼Œè¦ä¹ˆä¾èµ–äºäº‘ç«¯æ¨¡å‹ï¼Œå­˜åœ¨éšç§é£é™©ã€‚
2. æœ¬æ–‡æå‡ºäº†AgentStealthæ¡†æ¶ï¼Œé€šè¿‡å¯¹æŠ—æ€§åŒ¿ååŒ–å’Œè‡ªé€‚åº”æ§åˆ¶ï¼Œç»“åˆä¸Šä¸‹æ–‡å¯¹æ¯”å­¦ä¹ æ¥å¢å¼ºåŒ¿ååŒ–æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAgentStealthåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†åŒ¿ååŒ–æ•ˆæœ12.3%å’Œå®ç”¨æ€§6.8%ï¼Œè¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å½“ä»Šæ•°å­—ä¸–ç•Œä¸­ï¼Œç”¨æˆ·ç”Ÿæˆçš„å†…å®¹å¸¸å¸¸åŒ…å«å¯èƒ½æ— æ„ä¸­æš´éœ²æ•æ„Ÿä¸ªäººå±æ€§çš„ç»†å¾®çº¿ç´¢ã€‚è¿™ç§é£é™©å‡¸æ˜¾äº†æœ‰æ•ˆæ–‡æœ¬åŒ¿ååŒ–çš„é‡è¦æ€§ï¼Œä»¥ä¿æŠ¤ä¸ªäººéšç§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºæŸå®³å®ç”¨æ€§çš„åˆšæ€§æ›¿æ¢ï¼Œè¦ä¹ˆä¾èµ–äºæˆæœ¬é«˜ä¸”å­˜åœ¨éšç§é£é™©çš„äº‘ç«¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æ¢ç´¢äº†ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„å°è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰è¿›è¡ŒåŒ¿ååŒ–çš„å¯èƒ½æ€§ã€‚æˆ‘ä»¬æå‡ºäº†AgentStealthï¼Œä¸€ä¸ªè‡ªæˆ‘å¼ºåŒ–çš„LLMåŒ¿ååŒ–æ¡†æ¶ï¼Œç»“åˆäº†å¯¹æŠ—æ€§åŒ¿ååŒ–å·¥ä½œæµç¨‹ã€ä¸Šä¸‹æ–‡å¯¹æ¯”å­¦ä¹ å’Œè‡ªé€‚åº”å®ç”¨æ€§æ§åˆ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨åŒ¿ååŒ–æ•ˆæœå’Œå®ç”¨æ€§ä¸Šå‡ä¼˜äºåŸºçº¿ï¼Œä¸”è®¾è®¡è½»é‡ï¼Œæ”¯æŒåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šç›´æ¥éƒ¨ç½²ï¼Œé¿å…äº†å¯¹äº‘çš„ä¾èµ–å’Œé€šä¿¡å¸¦æ¥çš„éšç§é£é™©ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”¨æˆ·ç”Ÿæˆæ–‡æœ¬ä¸­çš„æ•æ„Ÿä¿¡æ¯åŒ¿ååŒ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€é€šè¿‡ç®€å•æ›¿æ¢æ¥å®ç°åŒ¿ååŒ–ï¼Œå¯¼è‡´æ–‡æœ¬å®ç”¨æ€§é™ä½ï¼Œæˆ–ä¾èµ–äº‘ç«¯æ¨¡å‹ï¼Œå¢åŠ éšç§æ³„éœ²é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„AgentStealthæ¡†æ¶é€šè¿‡è‡ªæˆ‘å¼ºåŒ–å­¦ä¹ å’Œå¯¹æŠ—æ€§åŒ¿ååŒ–å·¥ä½œæµç¨‹ï¼Œç»“åˆä¸Šä¸‹æ–‡å¯¹æ¯”å­¦ä¹ ï¼Œæ—¨åœ¨æé«˜å°è§„æ¨¡è¯­è¨€æ¨¡å‹çš„åŒ¿ååŒ–æ•ˆæœå’Œå®ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAgentStealthçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¯¹æŠ—æ€§åŒ¿ååŒ–å·¥ä½œæµç¨‹ã€ç›‘ç£é€‚åº”å’Œåœ¨çº¿å¼ºåŒ–å­¦ä¹ ã€‚é¦–å…ˆï¼Œé€šè¿‡å¯¹æŠ—æ€§å­¦ä¹ ç”Ÿæˆé«˜è´¨é‡çš„åŒ¿ååŒ–æ•°æ®ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨è¿™äº›æ•°æ®å¯¹å°è§„æ¨¡è¯­è¨€æ¨¡å‹è¿›è¡Œç›‘ç£é€‚åº”ï¼›æœ€åï¼Œåº”ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨å†…éƒ¨å¯¹æŠ—åé¦ˆä¸æ–­ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯¹æŠ—æ€§åŒ¿ååŒ–å’Œä¸Šä¸‹æ–‡å¯¹æ¯”å­¦ä¹ çš„ç»“åˆï¼Œå½¢æˆäº†ä¸€ä¸ªè‡ªæˆ‘å¼ºåŒ–çš„å­¦ä¹ æ¡†æ¶ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„åˆšæ€§æ›¿æ¢æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ–‡æœ¬å®ç”¨æ€§çš„åŒæ—¶æœ‰æ•ˆè¿›è¡ŒåŒ¿ååŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è‡ªé€‚åº”æ§åˆ¶æœºåˆ¶æ¥å¹³è¡¡åŒ¿ååŒ–æ•ˆæœä¸æ–‡æœ¬å®ç”¨æ€§ï¼Œå¹¶ä½¿ç”¨é«˜è´¨é‡çš„æ ‡æ³¨æ•°æ®è¿›è¡Œç›‘ç£å­¦ä¹ ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†åŒ¿ååŒ–æ•ˆæœå’Œæ–‡æœ¬å¯è¯»æ€§ä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAgentStealthåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„åŒ¿ååŒ–æ•ˆæœæé«˜äº†12.3%ï¼Œå®ç”¨æ€§æå‡äº†6.8%ã€‚è¿™äº›ç»“æœæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨æ–‡æœ¬åŒ¿ååŒ–é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ã€åœ¨çº¿è¯„è®ºå’Œä»»ä½•éœ€è¦ä¿æŠ¤ç”¨æˆ·éšç§çš„æ–‡æœ¬ç”Ÿæˆåœºæ™¯ã€‚é€šè¿‡åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šç›´æ¥éƒ¨ç½²AgentStealthï¼Œå¯ä»¥æœ‰æ•ˆé™ä½äº‘ç«¯ä¾èµ–å¸¦æ¥çš„éšç§é£é™©ï¼Œæå‡ç”¨æˆ·å¯¹åŒ¿ååŒ–æŠ€æœ¯çš„ä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šéœ€è¦éšç§ä¿æŠ¤çš„åº”ç”¨ä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In today's digital world, casual user-generated content often contains subtle cues that may inadvertently expose sensitive personal attributes. Such risks underscore the growing importance of effective text anonymization to safeguard individual privacy. However, existing methods either rely on rigid replacements that damage utility or cloud-based LLMs that are costly and pose privacy risks. To address these issues, we explore the use of locally deployed smaller-scale language models (SLMs) for anonymization. Yet training effective SLMs remains challenging due to limited high-quality supervision. To address the challenge, we propose AgentStealth, a self-reinforcing LLM anonymization framework.First, we introduce an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform supervised adaptation of SLMs using high-quality data collected from the workflow, which includes both anonymization and attack signals. Finally, we apply online reinforcement learning where the model leverages its internal adversarial feedback to iteratively improve anonymization performance. Experiments on two datasets show that our method outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks. Our code is open-source at https://github.com/tsinghua-fib-lab/AgentStealth.

