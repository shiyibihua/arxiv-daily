---
layout: default
title: DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning
---

# DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21096" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21096v2</a>
  <a href="https://arxiv.org/pdf/2506.21096.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21096v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21096v2', 'DALR: Dual-level Alignment Learning for Multimodal Sentence Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kang He, Yuzhe Ding, Haining Wang, Fei Li, Chong Teng, Donghong Ji

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-07-01)

**å¤‡æ³¨**: Accepted by ACL 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDALRä»¥è§£å†³å¤šæ¨¡æ€å¥å­è¡¨ç¤ºå­¦ä¹ ä¸­çš„å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¥å­è¡¨ç¤º` `å¯¹é½å­¦ä¹ ` `è¯­ä¹‰ç›¸ä¼¼æ€§` `æ’åè’¸é¦` `è®¡ç®—æœºè§†è§‰` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¥å­è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¸»è¦åœ¨ç²—ç²’åº¦ä¸Šå¯¹é½å›¾åƒå’Œæ–‡æœ¬ï¼Œå¯¼è‡´è·¨æ¨¡æ€é”™ä½åå·®å’Œæ¨¡æ€å†…éƒ¨è¯­ä¹‰å·®å¼‚ç­‰é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºDALRï¼Œé€šè¿‡ä¸€è‡´æ€§å­¦ä¹ æ¨¡å—å®ç°ç»†ç²’åº¦çš„è·¨æ¨¡æ€å¯¹é½ï¼Œå¹¶ç»“åˆæ’åè’¸é¦å¢å¼ºå¥å­å…³ç³»çš„æ•æ‰èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDALRåœ¨è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§å’Œè¿ç§»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒæŒç»­è¶…è¶Šç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¤šæ¨¡æ€å¥å­è¡¨ç¤ºå­¦ä¹ æ–¹æ³•å·²å–å¾—æ˜¾è‘—æˆæœï¼Œä½†å¤§å¤šæ•°æ–¹æ³•ä»…åœ¨ç²—ç²’åº¦ä¸Šå¯¹é½å›¾åƒå’Œæ–‡æœ¬ï¼Œé¢ä¸´è·¨æ¨¡æ€é”™ä½åå·®å’Œæ¨¡æ€å†…éƒ¨è¯­ä¹‰å·®å¼‚ç­‰æŒ‘æˆ˜ï¼Œä¸¥é‡å½±å“å¥å­è¡¨ç¤ºè´¨é‡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DALRï¼ˆåŒå±‚å¯¹é½å­¦ä¹ ï¼‰ï¼Œé€šè¿‡ä¸€è‡´æ€§å­¦ä¹ æ¨¡å—è½¯åŒ–è´Ÿæ ·æœ¬ï¼Œå¹¶åˆ©ç”¨è¾…åŠ©ä»»åŠ¡çš„è¯­ä¹‰ç›¸ä¼¼æ€§å®ç°ç»†ç²’åº¦çš„è·¨æ¨¡æ€å¯¹é½ã€‚æ­¤å¤–ï¼Œå¥å­å…³ç³»è¶…è¶Šäº†äºŒå…ƒæ­£è´Ÿæ ‡ç­¾ï¼Œå‘ˆç°å‡ºæ›´å¤æ‚çš„æ’åç»“æ„ã€‚ä¸ºæ›´å¥½åœ°æ•æ‰è¿™äº›å…³ç³»å¹¶æå‡è¡¨ç¤ºè´¨é‡ï¼Œæœ¬æ–‡å°†æ’åè’¸é¦ä¸å…¨å±€æ¨¡æ€å†…éƒ¨å¯¹é½å­¦ä¹ ç›¸ç»“åˆã€‚ç»¼åˆå®éªŒç»“æœè¡¨æ˜ï¼ŒDALRåœ¨è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§å’Œè¿ç§»ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¥å­è¡¨ç¤ºå­¦ä¹ ä¸­çš„è·¨æ¨¡æ€é”™ä½åå·®å’Œæ¨¡æ€å†…éƒ¨è¯­ä¹‰å·®å¼‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¯¹é½å›¾åƒå’Œæ–‡æœ¬æ—¶ï¼Œå¾€å¾€ä»…å…³æ³¨ç²—ç²’åº¦çš„å¯¹é½ï¼Œå¯¼è‡´è¡¨ç¤ºè´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDALRé€šè¿‡å¼•å…¥ä¸€è‡´æ€§å­¦ä¹ æ¨¡å—ï¼Œè½¯åŒ–è´Ÿæ ·æœ¬å¹¶åˆ©ç”¨è¾…åŠ©ä»»åŠ¡çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œå®ç°ç»†ç²’åº¦çš„è·¨æ¨¡æ€å¯¹é½ã€‚åŒæ—¶ï¼Œè€ƒè™‘åˆ°å¥å­å…³ç³»çš„å¤æ‚æ€§ï¼Œæœ¬æ–‡å°†æ’åè’¸é¦ä¸å…¨å±€æ¨¡æ€å†…éƒ¨å¯¹é½å­¦ä¹ ç›¸ç»“åˆï¼Œä»¥æå‡è¡¨ç¤ºè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDALRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€è‡´æ€§å­¦ä¹ æ¨¡å—å’Œæ’åè’¸é¦æ¨¡å—ã€‚å‰è€…è´Ÿè´£å®ç°ç»†ç²’åº¦çš„è·¨æ¨¡æ€å¯¹é½ï¼Œåè€…åˆ™é€šè¿‡æ•æ‰å¤æ‚çš„å¥å­å…³ç³»æ¥å¢å¼ºè¡¨ç¤ºèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šDALRçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åŒå±‚å¯¹é½å­¦ä¹ æœºåˆ¶ï¼Œæ—¢å…³æ³¨è·¨æ¨¡æ€å¯¹é½çš„ç»†ç²’åº¦ï¼Œåˆè€ƒè™‘æ¨¡æ€å†…éƒ¨çš„å¤æ‚å…³ç³»ã€‚è¿™ç§è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€å¯¹é½ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œæœ¬æ–‡é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ­£è´Ÿæ ·æœ¬çš„å½±å“ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§è°ƒæ•´çš„ç½‘ç»œç»“æ„ï¼Œä»¥ä¾¿æ›´å¥½åœ°æ•æ‰å¥å­ä¹‹é—´çš„æ’åå…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDALRåœ¨è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§å’Œè¿ç§»ä»»åŠ¡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼ŒéªŒè¯äº†å…¶åœ¨å¤šæ¨¡æ€å¥å­è¡¨ç¤ºå­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¥å­è¡¨ç¤ºçš„è´¨é‡ï¼ŒDALRå¯åœ¨å›¾åƒæè¿°ç”Ÿæˆã€è§†é¢‘ç†è§£å’Œè·¨æ¨¡æ€æ£€ç´¢ç­‰ä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Previous multimodal sentence representation learning methods have achieved impressive performance. However, most approaches focus on aligning images and text at a coarse level, facing two critical challenges:cross-modal misalignment bias and intra-modal semantic divergence, which significantly degrade sentence representation quality. To address these challenges, we propose DALR (Dual-level Alignment Learning for Multimodal Sentence Representation). For cross-modal alignment, we propose a consistency learning module that softens negative samples and utilizes semantic similarity from an auxiliary task to achieve fine-grained cross-modal alignment. Additionally, we contend that sentence relationships go beyond binary positive-negative labels, exhibiting a more intricate ranking structure. To better capture these relationships and enhance representation quality, we integrate ranking distillation with global intra-modal alignment learning. Comprehensive experiments on semantic textual similarity (STS) and transfer (TR) tasks validate the effectiveness of our approach, consistently demonstrating its superiority over state-of-the-art baselines.

