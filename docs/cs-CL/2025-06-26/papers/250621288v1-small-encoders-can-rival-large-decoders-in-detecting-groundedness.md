---
layout: default
title: Small Encoders Can Rival Large Decoders in Detecting Groundedness
---

# Small Encoders Can Rival Large Decoders in Detecting Groundedness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21288" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21288v1</a>
  <a href="https://arxiv.org/pdf/2506.21288.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21288v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21288v1', 'Small Encoders Can Rival Large Decoders in Detecting Groundedness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Istabrak Abbes, Gabriele Prato, Quentin Fournier, Fernando Rodriguez, Alaa Boukhary, Adam Elwood, Sarath Chandar

**åˆ†ç±»**: cs.CL, cs.AI, cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/chandarlab/Hallucinate-less)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½»é‡çº§ç¼–ç å™¨ä»¥è§£å†³å¤§å‹è§£ç å™¨åœ¨åŸºç¡€æ€§æ£€æµ‹ä¸­çš„ä¸è¶³**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸºç¡€æ€§æ£€æµ‹` `è½»é‡çº§ç¼–ç å™¨` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹å¾®è°ƒ` `æ¨ç†æ•ˆç‡` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¿¡æ¯ä¸è¶³æ—¶å®¹æ˜“äº§ç”Ÿæ— åŸºç¡€çš„æ¨æµ‹ï¼Œå½±å“å›ç­”çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§è½»é‡çº§ç¼–ç å™¨æ¨¡å‹ï¼Œé€šè¿‡å¾®è°ƒç‰¹å®šä»»åŠ¡æ•°æ®é›†æ¥å®ç°åŸºç¡€æ€§æ£€æµ‹ï¼Œé¿å…äº†æ˜‚è´µçš„ç­”æ¡ˆç”Ÿæˆè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè½»é‡çº§ç¼–ç å™¨åœ¨åŸºç¡€æ€§æ£€æµ‹çš„å‡†ç¡®ç‡ä¸Šä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å½“ï¼ŒåŒæ—¶æ¨ç†å»¶è¿Ÿé™ä½äº†å‡ ä¸ªæ•°é‡çº§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å¤–éƒ¨ä¸Šä¸‹æ–‡å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚å°½ç®¡LLMsåœ¨æä¾›ä¿¡æ¯ä¸è¶³çš„æƒ…å†µä¸‹å¸¸å¸¸ä¾èµ–äºæ— åŸºç¡€çš„æ¨æµ‹ï¼Œå¯¼è‡´ç”Ÿæˆçš„å›ç­”ç¼ºä¹äº‹å®ä¸€è‡´æ€§å’Œå¯ä¿¡åº¦ï¼ŒåŸºç¡€æ€§æ£€æµ‹æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„è½»é‡çº§ã€ä»»åŠ¡ç‰¹å®šçš„ç¼–ç å™¨æ¨¡å‹ï¼ˆå¦‚RoBERTaå’ŒNomicBERTï¼‰åœ¨åŸºç¡€æ€§æ£€æµ‹ä¸­èƒ½å¤Ÿè¾¾åˆ°ä¸æœ€å…ˆè¿›çš„LLMsï¼ˆå¦‚Llama3 8Bå’ŒGPT4oï¼‰ç›¸å½“çš„å‡†ç¡®ç‡ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½æ¨ç†å»¶è¿Ÿã€‚ç›¸å…³ä»£ç å·²åœ¨GitHubä¸Šå‘å¸ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¼ºä¹ä¿¡æ¯çš„ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆæ— åŸºç¡€å›ç­”çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†åŸºç¡€æ€§æ£€æµ‹æ—¶æ•ˆç‡ä½ä¸‹ï¼Œå¯¼è‡´èµ„æºæµªè´¹å’Œæ¨ç†æ—¶é—´è¿‡é•¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºä½¿ç”¨è½»é‡çº§ã€ä»»åŠ¡ç‰¹å®šçš„ç¼–ç å™¨æ¨¡å‹è¿›è¡ŒåŸºç¡€æ€§æ£€æµ‹ï¼Œä»¥åœ¨ç”Ÿæˆç­”æ¡ˆä¹‹å‰åˆ¤æ–­æŸ¥è¯¢æ˜¯å¦æœ‰åŸºç¡€ï¼Œä»è€Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒå’ŒåŸºç¡€æ€§æ£€æµ‹ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†å¹¶æ•´ç†ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ï¼Œç„¶åå¯¹ç¼–ç å™¨æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæœ€ååˆ©ç”¨å¾®è°ƒåçš„æ¨¡å‹è¿›è¡ŒåŸºç¡€æ€§æ£€æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡è½»é‡çº§ç¼–ç å™¨å®ç°ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸å½“çš„åŸºç¡€æ€§æ£€æµ‹å‡†ç¡®ç‡ï¼ŒåŒæ—¶å¤§å¹…é™ä½æ¨ç†å»¶è¿Ÿï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼Œé‡‡ç”¨RoBERTaå’ŒNomicBERTç­‰ç¼–ç å™¨ï¼Œå¹¶é€šè¿‡ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚æŸå¤±å‡½æ•°çš„é€‰æ‹©å’Œè®­ç»ƒå‚æ•°çš„è®¾ç½®ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨åŸºç¡€æ€§æ£€æµ‹ä»»åŠ¡ä¸­çš„æœ€ä½³è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„è½»é‡çº§ç¼–ç å™¨æ¨¡å‹åœ¨åŸºç¡€æ€§æ£€æµ‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†ä¸Llama3 8Bå’ŒGPT4oç›¸å½“çš„å‡†ç¡®ç‡ï¼Œæ¨ç†å»¶è¿Ÿé™ä½äº†å‡ ä¸ªæ•°é‡çº§ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆä¸”å‡†ç¡®çš„åŸºç¡€æ€§æ£€æµ‹çš„åœºæ™¯ä¸­ï¼Œå¦‚æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜åŸºç¡€æ€§æ£€æµ‹çš„æ•ˆç‡ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Augmenting large language models (LLMs) with external context significantly improves their performance in natural language processing (NLP) tasks. However, LLMs struggle to answer queries reliably when the provided context lacks information, often resorting to ungrounded speculation or internal knowledge. Groundedness - generating responses strictly supported by the context - is essential for ensuring factual consistency and trustworthiness. This study focuses on detecting whether a given query is grounded in a document provided in context before the costly answer generation by LLMs. Such a detection mechanism can significantly reduce both inference time and resource consumption. We show that lightweight, task specific encoder models such as RoBERTa and NomicBERT, fine-tuned on curated datasets, can achieve accuracy comparable to state-of-the-art LLMs, such as Llama3 8B and GPT4o, in groundedness detection while reducing inference latency by orders of magnitude. The code is available at : https://github.com/chandarlab/Hallucinate-less

