---
layout: default
title: Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation
---

# Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22518" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22518v1</a>
  <a href="https://arxiv.org/pdf/2506.22518.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22518v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22518v1', 'Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Deyu Zou, Yongqiang Chen, Mufei Li, Siqi Miao, Chenxi Liu, Bo Han, James Cheng, Pan Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRefined Graph-based RAGä»¥è§£å†³å¼±æ£€ç´¢å™¨ä¸å¤§è¯­è¨€æ¨¡å‹å¯¹é½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾æ£€ç´¢` `çŸ¥è¯†å›¾è°±` `ç”Ÿæˆæ¨¡å‹` `å¼±ç›‘ç£å­¦ä¹ ` `ç»“æ„é‡ç»„` `å¤§è¯­è¨€æ¨¡å‹` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºå›¾çš„RAGæ–¹æ³•ä¾èµ–äºå¼±æ£€ç´¢å™¨ï¼Œå¯¼è‡´è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥è™šå‡ä¿¡å·å’Œæ£€ç´¢ç»“æœçš„æ— åºæ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„ReGé€šè¿‡å¼•å…¥LLMåé¦ˆå’Œç»“æ„æ„ŸçŸ¥é‡ç»„æ¨¡å—ï¼Œæ—¨åœ¨æé«˜æ£€ç´¢ç»“æœçš„è´¨é‡å’Œé€»è¾‘æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒReGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡æ€§èƒ½ï¼Œä½¿ç”¨5%çš„è®­ç»ƒæ•°æ®å³å¯è¾¾åˆ°æœ€å…ˆè¿›çš„æ•ˆæœï¼Œå¹¶åœ¨æ¨ç†å‹LLMsä¸­å‡å°‘æ¨ç†tokenæˆæœ¬30%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºå›¾çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä½¿å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿåˆ©ç”¨æœ€æ–°çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰ä¸­çš„ç»“æ„åŒ–å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºå“åº”çš„å‡†ç¡®æ€§å¹¶å‡å°‘å¹»è§‰ã€‚ç„¶è€Œï¼ŒLLMsé€šå¸¸ä¾èµ–äºå¼±æ£€ç´¢å™¨ï¼Œè¿™å¯¼è‡´äº†è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥è™šå‡ä¿¡å·å’Œæ£€ç´¢ç»“æœçš„æ— åºæ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Refined Graph-based RAGï¼ˆReGï¼‰ï¼Œé€šè¿‡å¼•å…¥LLMåé¦ˆæ¥æ¶ˆé™¤è™šå‡ä¿¡å·å¹¶æ”¹å–„ç›‘ç£è´¨é‡ã€‚åŒæ—¶ï¼ŒReGè¿˜å¼•å…¥äº†ç»“æ„æ„ŸçŸ¥é‡ç»„æ¨¡å—ï¼Œå°†æ£€ç´¢ç»“æœé‡æ„ä¸ºé€»è¾‘è¿è´¯çš„è¯æ®é“¾ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReGåœ¨ä¸åŒLLMåŸºç¡€ä¸Šæ˜¾è‘—æå‡æ€§èƒ½ï¼Œæœ€å¤šå¯æé«˜10%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¼±æ£€ç´¢å™¨åœ¨åŸºäºå›¾çš„RAGä¸­å¼•å…¥è™šå‡ä¿¡å·å’Œæ£€ç´¢ç»“æœæ— åºæ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„ç›‘ç£ï¼Œå¯¼è‡´ç”Ÿæˆçš„å“åº”è´¨é‡ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReGé€šè¿‡ç»“åˆLLMåé¦ˆæ¥æ¶ˆé™¤è™šå‡ä¿¡å·ï¼Œå¹¶å¼•å…¥ç»“æ„æ„ŸçŸ¥é‡ç»„æ¨¡å—ï¼Œæ—¨åœ¨æå‡æ£€ç´¢ç»“æœçš„è´¨é‡å’Œé€»è¾‘è¿è´¯æ€§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç”Ÿæˆçš„å“åº”æ›´åŠ å‡†ç¡®å’Œå¯é ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReGçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯åŸºäºLLMçš„åé¦ˆæœºåˆ¶ï¼ŒäºŒæ˜¯ç»“æ„æ„ŸçŸ¥é‡ç»„æ¨¡å—ã€‚å‰è€…ç”¨äºä¼˜åŒ–æ£€ç´¢å™¨çš„è¾“å‡ºï¼Œåè€…åˆ™è´Ÿè´£å°†æ£€ç´¢ç»“æœé‡æ„ä¸ºé€»è¾‘è¿è´¯çš„è¯æ®é“¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šReGçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†LLMåé¦ˆä¸ç»“æ„æ„ŸçŸ¥é‡ç»„ç›¸ç»“åˆï¼Œè¿™ä¸€æ–¹æ³•æ˜¾è‘—æ”¹å–„äº†å¼±æ£€ç´¢å™¨çš„è¾“å‡ºè´¨é‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¶ˆé™¤è™šå‡ä¿¡å·ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒReGé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ£€ç´¢å™¨çš„è¾“å‡ºï¼Œå¹¶é€šè¿‡ç»“æ„æ„ŸçŸ¥é‡ç»„æ¨¡å—ç¡®ä¿æ£€ç´¢ç»“æœçš„é€»è¾‘æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒReGåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œæœ€å¤šå¯æé«˜10%ã€‚æ­¤å¤–ï¼Œä½¿ç”¨5%çš„è®­ç»ƒæ•°æ®å³å¯è¾¾åˆ°æœ€å…ˆè¿›çš„æ•ˆæœï¼Œå¹¶ä¸”åœ¨æ¨ç†å‹LLMsä¸­ï¼ŒReGèƒ½å¤Ÿå‡å°‘æ¨ç†tokenæˆæœ¬é«˜è¾¾30%ï¼ŒåŒæ—¶æå‡æ€§èƒ½4%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†ç®¡ç†ç­‰ã€‚é€šè¿‡æé«˜æ£€ç´¢ç»“æœçš„è´¨é‡å’Œé€»è¾‘æ€§ï¼ŒReGèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®çš„ç­”æ¡ˆï¼Œè¿›è€Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å¤šç§éœ€è¦å®æ—¶çŸ¥è¯†æ›´æ–°çš„åº”ç”¨åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Graph-based retrieval-augmented generation (RAG) enables large language models (LLMs) to ground responses with structured external knowledge from up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground truth, the retriever is often trained on weak supervision, which often introduces spurious signals to the LLMs. II) Due to the abstraction of graph data, the retrieved knowledge is often presented in unorganized forms. To mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM feedback to get rid of spurious signals and improve the quality of the supervision. Meanwhile, ReG introduces a structure-aware reorganization module to refactor the retrieval results into logically coherent evidence chains. Experiments on prominent benchmarks demonstrate that ReG significantly and consistently brings improvements across different LLM backbones by up to 10%. The improved supervision quality enables ReG to match the state-of-the-art performance with 5% training data and to transfer to out-of-distribution KGs. Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token cost by up to 30% and improves the performance by up to 4%.

