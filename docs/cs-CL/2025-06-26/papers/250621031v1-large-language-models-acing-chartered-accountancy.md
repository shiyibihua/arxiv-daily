---
layout: default
title: Large Language Models Acing Chartered Accountancy
---

# Large Language Models Acing Chartered Accountancy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21031" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21031v1</a>
  <a href="https://arxiv.org/pdf/2506.21031.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21031v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21031v1', 'Large Language Models Acing Chartered Accountancy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jatin Gupta, Akhil Sharma, Saransh Singhania, Mohammad Adnan, Sakshi Deo, Ali Imam Abidi, Keshav Gupta

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Accepted for publication at MoStart 2025: International Conference on Digital Transformation in Education and Applications of Artificial Intelligence, Bosnia and Herzegovina, 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCA-BenåŸºå‡†ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼šè®¡é¢†åŸŸçš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³¨å†Œä¼šè®¡å¸ˆ` `é‡‘èçŸ¥è¯†` `æ³•å¾‹æ¨ç†` `å®šé‡åˆ†æ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé‡‘èé¢†åŸŸçŸ¥è¯†çš„æ•æ‰å’Œåº”ç”¨æ•ˆæœä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨ä¼šè®¡å’Œæ³•å¾‹æ¨ç†æ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºCA-BenåŸºå‡†ï¼Œä¸“é—¨ç”¨äºè¯„ä¼°LLMsåœ¨è´¢åŠ¡ã€æ³•å¾‹å’Œå®šé‡æ¨ç†èƒ½åŠ›çš„è¡¨ç°ï¼Œå¡«è¡¥äº†å°åº¦é‡‘èé¢†åŸŸçš„ç ”ç©¶ç©ºç™½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒClaude 3.5 Sonnetå’ŒGPT-4oåœ¨æ¦‚å¿µå’Œæ³•å¾‹æ¨ç†æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨æ•°å€¼è®¡ç®—å’Œæ³•å¾‹è§£é‡Šä¸Šä»é¢ä¸´æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…ˆè¿›çš„æ™ºèƒ½ç³»ç»Ÿï¼Œå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œæ­£åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„è¿›æ­¥æ˜¾è‘—æ”¹å˜é‡‘èå®è·µã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨æ•æ‰å’Œåº”ç”¨ç‰¹å®šé¢†åŸŸçš„é‡‘èçŸ¥è¯†æ–¹é¢çš„æœ‰æ•ˆæ€§ä»ç„¶ä¸ç¡®å®šã€‚ä¸ºå¡«è¡¥è¿™ä¸€å…³é”®ç©ºç™½ï¼Œæœ¬æ–‡ä»‹ç»äº†CA-Benï¼Œä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºè¯„ä¼°LLMsåœ¨è´¢åŠ¡ã€æ³•å¾‹å’Œå®šé‡æ¨ç†èƒ½åŠ›çš„æ³¨å†Œä¼šè®¡å¸ˆåŸºå‡†ã€‚CA-BenåŒ…å«æ¥è‡ªå°åº¦æ³¨å†Œä¼šè®¡å¸ˆåä¼šï¼ˆICAIï¼‰ä¸¥æ ¼è€ƒè¯•çš„ç»“æ„åŒ–é—®ç­”æ•°æ®é›†ï¼Œæ¶µç›–åŸºç¡€ã€ä¸­çº§å’Œé«˜çº§CAè¯¾ç¨‹é˜¶æ®µã€‚é€šè¿‡æ ‡å‡†åŒ–åè®®è¯„ä¼°äº†å…­ä¸ªä¸»è¦çš„LLMsï¼Œç»“æœæ˜¾ç¤ºè¡¨ç°å­˜åœ¨å·®å¼‚ï¼ŒClaude 3.5 Sonnetå’ŒGPT-4oçš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå°¤å…¶åœ¨æ¦‚å¿µå’Œæ³•å¾‹æ¨ç†æ–¹é¢ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å½“å‰LLMsçš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶å»ºè®®é€šè¿‡æ··åˆæ¨ç†å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•è¿›è¡Œæœªæ¥æ”¹è¿›ï¼Œç‰¹åˆ«æ˜¯åœ¨å®šé‡åˆ†æå’Œå‡†ç¡®çš„æ³•å¾‹è§£é‡Šæ–¹é¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¼šè®¡é¢†åŸŸçš„çŸ¥è¯†åº”ç”¨ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ³•å¾‹æ¨ç†å’Œæ•°å€¼è®¡ç®—æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯„ä¼°LLMsåœ¨ç‰¹å®šé¢†åŸŸçš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºCA-BenåŸºå‡†ï¼Œé€šè¿‡ç»“æ„åŒ–é—®ç­”æ•°æ®é›†è¯„ä¼°LLMsçš„è´¢åŠ¡ã€æ³•å¾‹å’Œå®šé‡æ¨ç†èƒ½åŠ›ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªæ ‡å‡†åŒ–çš„è¯„ä¼°æ¡†æ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†æ¥æºäºICAIçš„è€ƒè¯•ï¼Œæ¶µç›–ä¸åŒCAè¯¾ç¨‹é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šCA-BenåŸºå‡†çš„æå‡ºæ˜¯æœ¬æ–‡çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå¡«è¡¥äº†ç°æœ‰LLMsè¯„ä¼°çš„ç©ºç™½ï¼Œç‰¹åˆ«æ˜¯åœ¨ä¼šè®¡å’Œæ³•å¾‹é¢†åŸŸçš„åº”ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šæ•°æ®é›†è®¾è®¡é‡‡ç”¨äº†ç»“æ„åŒ–é—®ç­”å½¢å¼ï¼Œç¡®ä¿æ¶µç›–è´¢åŠ¡ã€æ³•å¾‹å’Œå®šé‡æ¨ç†çš„å¤šæ ·æ€§ï¼Œè¯„ä¼°è¿‡ç¨‹ä¸­ä½¿ç”¨æ ‡å‡†åŒ–åè®®ä»¥ç¡®ä¿ç»“æœçš„å¯æ¯”æ€§ã€‚å®éªŒä¸­å¯¹å…­ä¸ªLLMsçš„è¯„ä¼°é‡‡ç”¨äº†ç»Ÿä¸€çš„æµ‹è¯•æ ‡å‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒClaude 3.5 Sonnetå’ŒGPT-4oåœ¨æ¦‚å¿µå’Œæ³•å¾‹æ¨ç†æ–¹é¢çš„è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå°¤å…¶åœ¨å‡†ç¡®æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚å°½ç®¡å¦‚æ­¤ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨æ•°å€¼è®¡ç®—å’Œæ³•å¾‹è§£é‡Šæ–¹é¢ä»å­˜åœ¨æ˜æ˜¾æŒ‘æˆ˜ï¼Œè¡¨æ˜æœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¼šè®¡æ•™è‚²ã€é‡‘èå’¨è¯¢å’Œæ³•å¾‹æœåŠ¡ç­‰ã€‚é€šè¿‡è¯„ä¼°LLMsåœ¨è¿™äº›é¢†åŸŸçš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿä¸ºé‡‘èè¡Œä¸šçš„æ™ºèƒ½åŒ–è½¬å‹æä¾›æ”¯æŒï¼Œæå‡å†³ç­–æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›æ­¥ï¼ŒLLMsåœ¨ä¼šè®¡å’Œæ³•å¾‹é¢†åŸŸçš„åº”ç”¨å°†æ›´åŠ å¹¿æ³›ï¼Œæ¨åŠ¨è¡Œä¸šçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Advanced intelligent systems, particularly Large Language Models (LLMs), are significantly reshaping financial practices through advancements in Natural Language Processing (NLP). However, the extent to which these models effectively capture and apply domain-specific financial knowledge remains uncertain. Addressing a critical gap in the expansive Indian financial context, this paper introduces CA-Ben, a Chartered Accountancy benchmark specifically designed to evaluate the financial, legal, and quantitative reasoning capabilities of LLMs. CA-Ben comprises structured question-answer datasets derived from the rigorous examinations conducted by the Institute of Chartered Accountants of India (ICAI), spanning foundational, intermediate, and advanced CA curriculum stages. Six prominent LLMs i.e. GPT 4o, LLAMA 3.3 70B, LLAMA 3.1 405B, MISTRAL Large, Claude 3.5 Sonnet, and Microsoft Phi 4 were evaluated using standardized protocols. Results indicate variations in performance, with Claude 3.5 Sonnet and GPT-4o outperforming others, especially in conceptual and legal reasoning. Notable challenges emerged in numerical computations and legal interpretations. The findings emphasize the strengths and limitations of current LLMs, suggesting future improvements through hybrid reasoning and retrieval-augmented generation methods, particularly for quantitative analysis and accurate legal interpretation.

