---
layout: default
title: Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning
---

# Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21285" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21285v3</a>
  <a href="https://arxiv.org/pdf/2506.21285.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21285v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21285v3', 'Double-Checker: Enhancing Reasoning of Slow-Thinking LLMs via Self-Critical Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xin Xu, Tianhao Chen, Fan Zhang, Wanlong Liu, Pengxiang Li, Ajay Kumar Jaiswal, Yuchen Yan, Jishan Hu, Yang Wang, Hao Chen, Shiwei Liu, Shizhe Diao, Can Yang, Lu Yin

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-10-02)

**å¤‡æ³¨**: 10 pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/XinXU-USTC/DoubleChecker)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDouble-Checkerä»¥å¢å¼ºæ…¢æ€ç»´LLMsçš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ…¢æ€ç»´LLMs` `è‡ªæˆ‘æ‰¹è¯„` `æ¨ç†èƒ½åŠ›` `æ¨¡å‹å¾®è°ƒ` `è¿­ä»£ä¼˜åŒ–` `AIMEåŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ…¢æ€ç»´LLMsåœ¨ç”Ÿæˆæ‰¹è¯„å’Œä¼˜åŒ–è§£å†³æ–¹æ¡ˆæ–¹é¢èƒ½åŠ›æœ‰é™ï¼Œå½±å“äº†å…¶æ¨ç†æ•ˆæœã€‚
2. Double-Checkeræ¡†æ¶é€šè¿‡è‡ªæˆ‘æ‰¹è¯„å’Œè¿­ä»£ä¼˜åŒ–ï¼Œæå‡äº†LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œå¢å¼ºäº†å…¶ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆçš„å¯é æ€§ã€‚
3. åœ¨AIMEåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDouble-Checkerå°†é€šè¿‡ç‡ä»4.4%æå‡è‡³18.2%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡æ…¢æ€ç»´çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°äº†ç±»ä¼¼åæ€çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒä»¬ç”Ÿæˆä¿¡æ¯æ€§æ‰¹è¯„å’Œä¼˜åŒ–å…ˆå‰è§£å†³æ–¹æ¡ˆçš„èƒ½åŠ›ä»ç„¶æœ‰é™ã€‚æœ¬æ–‡æå‡ºäº†Double-Checkerï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡ä¿ƒè¿›æ˜¾å¼è‡ªæˆ‘æ‰¹è¯„å’Œè¿­ä»£ä¼˜åŒ–æ¥å¢å¼ºæ…¢æ€ç»´LLMsæ¨ç†èƒ½åŠ›çš„æ¡†æ¶ã€‚é€šè¿‡åœ¨æˆ‘ä»¬ç²¾å¿ƒç­–åˆ’çš„1730ä¸ªè‡ªæˆ‘æ‰¹è¯„å®ä¾‹ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒDouble-Checkerä½¿é•¿é“¾æ¨ç†LLMsèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿­ä»£æ‰¹è¯„å’Œä¼˜åŒ–å…¶è¾“å‡ºï¼Œç›´åˆ°å®ƒä»¬åœ¨è‡ªç”Ÿæˆçš„æ‰¹è¯„ä¸‹è¯„ä¼°å…¶è§£å†³æ–¹æ¡ˆä¸ºæ­£ç¡®ã€‚æˆ‘ä»¬åœ¨å…¨é¢çš„æ¨ç†åŸºå‡†æµ‹è¯•ä¸­éªŒè¯äº†Double-Checkerçš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜ï¼Œè¿­ä»£è‡ªæˆ‘æ‰¹è¯„æ˜¾è‘—å¢å¼ºäº†é•¿é“¾æ¨ç†LLMsçš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ…¢æ€ç»´LLMsåœ¨ç”Ÿæˆä¿¡æ¯æ€§æ‰¹è¯„å’Œä¼˜åŒ–å…ˆå‰è§£å†³æ–¹æ¡ˆæ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆæå‡å…¶æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDouble-Checkeré€šè¿‡å¼•å…¥æ˜¾å¼è‡ªæˆ‘æ‰¹è¯„æœºåˆ¶ï¼Œä¿ƒä½¿LLMsåœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸æ–­åæ€å’Œä¼˜åŒ–å…¶è¾“å‡ºï¼Œä»è€Œæé«˜æ¨ç†çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹å¾®è°ƒå’Œæ¨ç†é˜¶æ®µã€‚é¦–å…ˆï¼Œä½¿ç”¨1730ä¸ªè‡ªæˆ‘æ‰¹è¯„å®ä¾‹å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç„¶ååœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œå¤šè½®è‡ªæˆ‘æ‰¹è¯„å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šDouble-Checkerçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†è¿­ä»£è‡ªæˆ‘æ‰¹è¯„æœºåˆ¶ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿåœ¨ç”Ÿæˆè¾“å‡ºåè¿›è¡Œåæ€å’Œä¿®æ­£ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å•æ¬¡ç”Ÿæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥é¼“åŠ±æ¨¡å‹ç”Ÿæˆæ›´å…·æ‰¹åˆ¤æ€§çš„è¾“å‡ºï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è‡ªæˆ‘æ‰¹è¯„æ—¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è°ƒæ•´å…¶ç”Ÿæˆç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDouble-Checkeråœ¨AIMEåŸºå‡†æµ‹è¯•ä¸­çš„é€šè¿‡ç‡ä»4.4%æå‡è‡³18.2%ï¼Œè¡¨æ˜è¿­ä»£è‡ªæˆ‘æ‰¹è¯„æ˜¾è‘—å¢å¼ºäº†LLMsçš„æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€æå‡å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½å®¢æœå’Œå†…å®¹ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡LLMsçš„æ¨ç†èƒ½åŠ›ï¼ŒDouble-Checkerèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®å’Œå¯é çš„ç­”æ¡ˆï¼Œè¿›è€Œæé«˜äººæœºäº¤äº’çš„è´¨é‡å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´é«˜çº§çš„è‡ªæˆ‘å­¦ä¹ å’Œè‡ªæˆ‘ä¼˜åŒ–æ¨¡å‹çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While slow-thinking large language models (LLMs) exhibit reflection-like reasoning, commonly referred to as the "aha moment:, their ability to generate informative critiques and refine prior solutions remains limited. In this paper, we introduce Double-Checker, a principled framework designed to enhance the reasoning capabilities of slow-thinking LLMs by fostering explicit self-critique and iterative refinement of their previous solutions. By fine-tuning on our curated 1,730 self-critical instances, Double-Checker empowers long-CoT LLMs to iteratively critique and refine their outputs during inference until they evaluate their solutions as correct under self-generated critiques. We validate the efficacy of Double-Checker across a comprehensive suite of reasoning benchmarks, demonstrating that iterative self-critique significantly enhances the reasoning capabilities of long-CoT LLMs. Notably, our Double-Checker increases the pass@1 performance on challenging AIME benchmarks from 4.4% to 18.2% compared to the original long-CoT LLMs. These results highlight a promising direction for developing more trustworthy and effective LLMs capable of structured self-critique. Our codes and data are available at https://github.com/XinXU-USTC/DoubleChecker

