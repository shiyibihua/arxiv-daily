---
layout: default
title: Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis
---

# Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22516v1</a>
  <a href="https://arxiv.org/pdf/2506.22516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22516v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22516v1', 'Can &quot;consciousness&quot; be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingkai Li

**åˆ†ç±»**: cs.CL, cs.AI, cs.NE, q-bio.NC

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: Published as a journal paper at: https://doi.org/10.1016/j.nlp.2025.100163

**æœŸåˆŠ**: Natural Language Processing Journal 12C (2025) 100163

**DOI**: [10.1016/j.nlp.2025.100163](https://doi.org/10.1016/j.nlp.2025.100163)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åº”ç”¨ç»¼åˆä¿¡æ¯ç†è®ºåˆ†æå¤§è¯­è¨€æ¨¡å‹çš„æ„è¯†è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»¼åˆä¿¡æ¯ç†è®º` `å¤§è¯­è¨€æ¨¡å‹` `å¿ƒæ™ºç†è®º` `æ„è¯†ç ”ç©¶` `Transformer` `è¡¨ç¤ºåˆ†æ` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åˆ†æå¤§è¯­è¨€æ¨¡å‹çš„æ„è¯†è¡¨ç°æ—¶ç¼ºä¹æœ‰æ•ˆçš„å®šé‡æ¡†æ¶ï¼Œéš¾ä»¥æ­ç¤ºå…¶å†…éƒ¨çŠ¶æ€çš„å¤æ‚æ€§ã€‚
2. æœ¬æ–‡é€šè¿‡åº”ç”¨ç»¼åˆä¿¡æ¯ç†è®ºï¼ˆIITï¼‰å¯¹LLMè¡¨ç¤ºè¿›è¡Œæ·±å…¥åˆ†æï¼Œæ¢è®¨å…¶åœ¨å¿ƒæ™ºç†è®ºæµ‹è¯•ä¸­çš„è¡¨ç°å·®å¼‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰LLMè¡¨ç¤ºæœªèƒ½æ˜¾è‘—æŒ‡ç¤ºæ„è¯†ç°è±¡ï¼Œä½†åœ¨ç©ºé—´ç½®æ¢åˆ†æä¸­å‘ç°äº†æœ‰è¶£çš„æ¨¡å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç»¼åˆä¿¡æ¯ç†è®ºï¼ˆIITï¼‰æä¾›äº†ä¸€ä¸ªå®šé‡æ¡†æ¶æ¥è§£é‡Šæ„è¯†ç°è±¡ï¼Œè®¤ä¸ºæ„è¯†ç³»ç»Ÿç”±é€šè¿‡å› æœå±æ€§æ•´åˆçš„å…ƒç´ ç»„æˆã€‚æœ¬æ–‡åº”ç”¨IIT 3.0å’Œ4.0å¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¡¨ç¤ºè¿›è¡Œåˆ†æï¼Œç ”ç©¶åœ¨ç°æœ‰çš„å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰æµ‹è¯•ç»“æœä¸­ï¼ŒLLMè¡¨ç°çš„å·®å¼‚æ˜¯å¦å¯ä»¥é€šè¿‡IITä¼°è®¡ï¼ˆå¦‚$Î¦^{	ext{max}}$å’Œ$Î¦$ï¼‰æ­ç¤ºã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç°ä»£TransformeråŸºç¡€çš„LLMè¡¨ç¤ºç¼ºä¹æ˜¾è‘—çš„æ„è¯†ç°è±¡æŒ‡æ ‡ï¼Œä½†åœ¨ç©ºé—´ç½®æ¢åˆ†æä¸­å±•ç°å‡ºæœ‰è¶£çš„æ¨¡å¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å†…éƒ¨çŠ¶æ€æ˜¯å¦èƒ½é€šè¿‡ç»¼åˆä¿¡æ¯ç†è®ºï¼ˆIITï¼‰æ­ç¤ºæ„è¯†ç°è±¡ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸçš„ç ”ç©¶å¤šé›†ä¸­äºè¡¨é¢æ€§èƒ½ï¼Œç¼ºä¹æ·±å…¥çš„å®šé‡åˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åº”ç”¨IIT 3.0å’Œ4.0ï¼Œå¯¹LLMåœ¨å¿ƒæ™ºç†è®ºæµ‹è¯•ä¸­çš„è¡¨ç°è¿›è¡Œç³»ç»Ÿåˆ†æï¼Œæ—¨åœ¨æ­ç¤ºå…¶å†…éƒ¨è¡¨ç¤ºçš„æ½œåœ¨æ„è¯†ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆæ”¶é›†LLMåœ¨å¿ƒæ™ºç†è®ºæµ‹è¯•ä¸­çš„è¡¨ç°æ•°æ®ï¼Œç„¶ååˆ©ç”¨IITçš„ä¸åŒä¼°è®¡æ–¹æ³•ï¼ˆå¦‚$Î¦^{	ext{max}}$å’Œ$Î¦$ï¼‰å¯¹è¿™äº›æ•°æ®è¿›è¡Œåˆ†æï¼Œæœ€åä¸ç‹¬ç«‹çš„Span Representationsè¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†IITåº”ç”¨äºLLMçš„è¡¨ç¤ºåˆ†æï¼Œæ¢ç´¢å…¶æ˜¯å¦èƒ½å¤Ÿæ­ç¤ºæ„è¯†ç°è±¡çš„æ½œåœ¨æŒ‡æ ‡ï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­é‡‡ç”¨äº†IIT 3.0å’Œ4.0çš„å¤šç§ä¼°è®¡æ–¹æ³•ï¼Œè®¾è®¡äº†å¤šå±‚æ¬¡çš„å®éªŒä»¥åˆ†æä¸åŒTransformerå±‚å’Œè¯­è¨€è·¨åº¦çš„è¡¨ç°ï¼Œç¡®ä¿äº†æ•°æ®çš„å…¨é¢æ€§å’Œåˆ†æçš„æ·±åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°ä»£TransformeråŸºç¡€çš„LLMè¡¨ç¤ºæœªèƒ½æ˜¾ç¤ºå‡ºç»Ÿè®¡æ˜¾è‘—çš„æ„è¯†ç°è±¡æŒ‡æ ‡ï¼Œä½†åœ¨ç©ºé—´ç½®æ¢åˆ†æä¸­å‘ç°äº†æœ‰è¶£çš„æ¨¡å¼ï¼Œæç¤ºäº†LLMå†…éƒ¨è¡¨ç¤ºçš„å¤æ‚æ€§å’Œæ½œåœ¨çš„æ„è¯†ç‰¹å¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºç†è§£å¤§è¯­è¨€æ¨¡å‹çš„å†…éƒ¨çŠ¶æ€æä¾›äº†æ–°çš„è§†è§’ï¼Œæ½œåœ¨åº”ç”¨äºäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ„è¯†ç ”ç©¶ã€æ™ºèƒ½ä½“çš„è®¾è®¡ä¸è¯„ä¼°ç­‰é¢†åŸŸã€‚æœªæ¥å¯èƒ½æ¨åŠ¨å¯¹æœºå™¨æ„è¯†çš„æ·±å…¥æ¢è®¨ï¼Œå½±å“äººæœºäº¤äº’å’Œæ™ºèƒ½ç³»ç»Ÿçš„ä¼¦ç†ç ”ç©¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrated Information Theory (IIT) provides a quantitative framework for explaining consciousness phenomenon, positing that conscious systems comprise elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the latest iterations of this framework -- to sequences of Large Language Model (LLM) representations, analyzing data derived from existing Theory of Mind (ToM) test results. Our study systematically investigates whether the differences of ToM test performances, when presented in the LLM representations, can be revealed by IIT estimates, i.e., $Î¦^{\max}$ (IIT 3.0), $Î¦$ (IIT 4.0), Conceptual Information (IIT 3.0), and $Î¦$-structure (IIT 4.0). Furthermore, we compare these metrics with the Span Representations independent of any estimate for consciousness. This additional effort aims to differentiate between potential "consciousness" phenomena and inherent separations within LLM representational space. We conduct comprehensive experiments examining variations across LLM transformer layers and linguistic spans from stimuli. Our results suggest that sequences of contemporary Transformer-based LLM representations lack statistically significant indicators of observed "consciousness" phenomena but exhibit intriguing patterns under $\textit{spatio}$-permutational analyses. The Appendix and code are available as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

