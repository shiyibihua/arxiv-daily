---
layout: default
title: Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations
---

# Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.11196" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.11196v2</a>
  <a href="https://arxiv.org/pdf/2510.11196.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.11196v2" onclick="toggleFavorite(this, '2510.11196v2', 'Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Johannes Moll, Markus Graf, Tristan Lemke, Nicolas Lenhart, Daniel Truhn, Jean-Benoit Delbrouck, Jiazhen Pan, Daniel Rueckert, Lisa C. Adams, Keno K. Bressem

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13 (æ›´æ–°: 2025-11-09)

**å¤‡æ³¨**: Accepted to ML4H 2025 Proceedings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤šæ¨¡æ€æ‰°åŠ¨çš„åŒ»å­¦VQAæ¨¡å‹æ¨ç†å¿ å®æ€§è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°èƒ¸éƒ¨Xå…‰ç‰‡é—®ç­”ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰é—®ç­”` `åŒ»å­¦å½±åƒ` `æ¨ç†å¿ å®æ€§` `å¤šæ¨¡æ€å­¦ä¹ ` `èƒ¸éƒ¨Xå…‰ç‰‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VQAæ¨¡å‹è§£é‡Šç¼ºä¹å¿ å®æ€§ï¼Œæ— æ³•åæ˜ çœŸå®å†³ç­–è¿‡ç¨‹ï¼Œä¸´åºŠåº”ç”¨ä¸­ä¿¡ä»»åº¦ä½ã€‚
2. é€šè¿‡æ§åˆ¶æ–‡æœ¬å’Œå›¾åƒæ‰°åŠ¨ï¼Œä»ä¸´åºŠä¿çœŸåº¦ã€å› æœå½’å› å’Œç½®ä¿¡åº¦æ ¡å‡†ä¸‰ä¸ªç»´åº¦è¯„ä¼°VQAæ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ç­”æ¡ˆå‡†ç¡®æ€§ä¸è§£é‡Šè´¨é‡è§£è€¦ï¼Œæ–‡æœ¬çº¿ç´¢å½±å“å¤§äºè§†è§‰çº¿ç´¢ï¼Œä¸“æœ‰æ¨¡å‹åœ¨å½’å› å’Œä¿çœŸåº¦ä¸Šè¡¨ç°æ›´å¥½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)ç”Ÿæˆçš„æ€ç»´é“¾(CoT)è§£é‡Šçœ‹ä¼¼åˆç†ï¼Œä½†æœªèƒ½åæ˜ æ½œåœ¨çš„å†³ç­–è¿‡ç¨‹ï¼Œä»è€Œé™ä½äº†åœ¨é«˜é£é™©ä¸´åºŠåº”ç”¨ä¸­çš„ä¿¡ä»»åº¦ã€‚ç°æœ‰çš„è¯„ä¼°å¾ˆå°‘èƒ½æ•æ‰åˆ°è¿™ç§é”™ä½ï¼Œè€Œæ˜¯ä¼˜å…ˆè€ƒè™‘ç­”æ¡ˆçš„å‡†ç¡®æ€§æˆ–å¯¹æ ¼å¼çš„éµå®ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªä¸´åºŠåŸºç¡€çš„èƒ¸éƒ¨Xå…‰ç‰‡è§†è§‰é—®ç­”(VQA)æ¡†æ¶ï¼Œé€šè¿‡åœ¨ä¸´åºŠä¿çœŸåº¦ã€å› æœå½’å› å’Œç½®ä¿¡åº¦æ ¡å‡†ä¸‰ä¸ªæ–¹é¢è¿›è¡Œå—æ§çš„æ–‡æœ¬å’Œå›¾åƒä¿®æ”¹æ¥æ¢æµ‹CoTçš„å¿ å®æ€§ã€‚åœ¨ä¸€é¡¹è¯»è€…ç ”ç©¶(n=4)ä¸­ï¼Œè¯„ä¼°è€…-æ”¾å°„ç§‘åŒ»ç”Ÿç›¸å…³æ€§è½åœ¨æ‰€æœ‰è½´çš„è§‚å¯Ÿåˆ°çš„æ”¾å°„ç§‘åŒ»ç”Ÿé—´èŒƒå›´å†…ï¼Œå½’å› çš„å¯¹é½åº¦å¾ˆé«˜(Kendall's $Ï„_b=0.670$)ï¼Œä¿çœŸåº¦çš„å¯¹é½åº¦ä¸­ç­‰($Ï„_b=0.387$)ï¼Œç½®ä¿¡åº¦è¯­æ°”çš„å¯¹é½åº¦è¾ƒå¼±($Ï„_b=0.091$)ï¼Œæˆ‘ä»¬è°¨æ…åœ°æŠ¥å‘Šäº†è¿™ä¸€ç‚¹ã€‚å¯¹å…­ä¸ªVLMsçš„åŸºå‡†æµ‹è¯•è¡¨æ˜ï¼Œç­”æ¡ˆçš„å‡†ç¡®æ€§å’Œè§£é‡Šçš„è´¨é‡å¯ä»¥è§£è€¦ï¼Œæ‰¿è®¤æ³¨å…¥çš„çº¿ç´¢å¹¶ä¸èƒ½ç¡®ä¿åŸºç¡€ï¼Œå¹¶ä¸”æ–‡æœ¬çº¿ç´¢æ¯”è§†è§‰çº¿ç´¢æ›´èƒ½æ”¹å˜è§£é‡Šã€‚è™½ç„¶ä¸€äº›å¼€æºæ¨¡å‹åŒ¹é…äº†æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œä½†ä¸“æœ‰æ¨¡å‹åœ¨å½’å› (25.0% vs. 1.4%)å’Œä¿çœŸåº¦(36.1% vs. 31.7%)ä¸Šå¾—åˆ†æ›´é«˜ï¼Œçªå‡ºäº†éƒ¨ç½²é£é™©ä»¥åŠè¯„ä¼°è¶…å‡ºæœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒ»å­¦è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨èƒ¸éƒ¨Xå…‰ç‰‡è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ä»»åŠ¡ä¸­ï¼Œæ¨ç†è¿‡ç¨‹ç¼ºä¹å¿ å®æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨ç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œè€Œå¿½ç•¥äº†è§£é‡Šæ˜¯å¦çœŸå®åæ˜ äº†æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚è¿™ç§ç¼ºä¹å¿ å®æ€§çš„è§£é‡Šä¼šé™ä½ä¸´åºŠåŒ»ç”Ÿå¯¹æ¨¡å‹çš„ä¿¡ä»»åº¦ï¼Œé˜»ç¢å…¶åœ¨é«˜é£é™©åŒ»ç–—åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥å¤šæ¨¡æ€æ‰°åŠ¨ï¼Œå³å¯¹è¾“å…¥å›¾åƒå’Œæ–‡æœ¬è¿›è¡Œæœ‰æ§åˆ¶çš„ä¿®æ”¹ï¼Œæ¥è¯„ä¼°VQAæ¨¡å‹è§£é‡Šçš„å¿ å®æ€§ã€‚å¦‚æœæ¨¡å‹çš„è§£é‡Šèƒ½å¤Ÿæ­£ç¡®åæ˜ è¿™äº›æ‰°åŠ¨çš„å½±å“ï¼Œåˆ™è®¤ä¸ºå…¶æ¨ç†è¿‡ç¨‹æ˜¯å¿ å®çš„ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œä¸ä»…ä»…æ˜¯ç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) æ„å»ºä¸€ä¸ªåŒ…å«èƒ¸éƒ¨Xå…‰ç‰‡å’Œå¯¹åº”é—®é¢˜çš„VQAæ•°æ®é›†ã€‚2) å®šä¹‰ä¸‰ç§ç±»å‹çš„å¤šæ¨¡æ€æ‰°åŠ¨ï¼šä¸´åºŠä¿çœŸåº¦æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œå¼•å…¥ä¸ç›¸å…³çš„ä¸´åºŠä¿¡æ¯ï¼‰ã€å› æœå½’å› æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œç§»é™¤å…³é”®çš„è§†è§‰ç‰¹å¾ï¼‰å’Œç½®ä¿¡åº¦æ ¡å‡†æ‰°åŠ¨ï¼ˆä¾‹å¦‚ï¼Œæ”¹å˜é—®é¢˜çš„è¯­æ°”ï¼‰ã€‚3) ä½¿ç”¨è¿™äº›æ‰°åŠ¨ç”Ÿæˆæ–°çš„VQAæ ·æœ¬ã€‚4) å°†åŸå§‹æ ·æœ¬å’Œæ‰°åŠ¨åçš„æ ·æœ¬è¾“å…¥åˆ°VQAæ¨¡å‹ä¸­ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„è§£é‡Šã€‚5) ä½¿ç”¨äººå·¥è¯„ä¼°ï¼ˆæ”¾å°„ç§‘åŒ»ç”Ÿï¼‰æ¥åˆ¤æ–­è§£é‡Šæ˜¯å¦å¿ å®åœ°åæ˜ äº†æ‰°åŠ¨çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªåŸºäºå¤šæ¨¡æ€æ‰°åŠ¨çš„VQAæ¨¡å‹æ¨ç†å¿ å®æ€§è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶ä¸ä»…å…³æ³¨ç­”æ¡ˆçš„å‡†ç¡®æ€§ï¼Œæ›´å…³æ³¨è§£é‡Šçš„è´¨é‡å’Œå¿ å®æ€§ã€‚é€šè¿‡å¼•å…¥ä¸´åºŠç›¸å…³çš„æ‰°åŠ¨ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°è¯„ä¼°æ¨¡å‹åœ¨å®é™…ä¸´åºŠåœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æä¾›äº†ä¸€ç§é‡åŒ–è§£é‡Šå¿ å®æ€§çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨äºæ¯”è¾ƒä¸åŒVQAæ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ‰°åŠ¨è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡ç‰¹åˆ«å…³æ³¨äº†ä¸´åºŠç›¸å…³æ€§ï¼Œä¾‹å¦‚ï¼Œå¼•å…¥çš„ä¸´åºŠä¿¡æ¯éƒ½æ˜¯çœŸå®çš„ï¼Œç§»é™¤çš„è§†è§‰ç‰¹å¾éƒ½æ˜¯ä¸ç–¾ç—…ç›¸å…³çš„ã€‚åœ¨è¯„ä¼°æŒ‡æ ‡æ–¹é¢ï¼Œè®ºæ–‡ä½¿ç”¨äº†Kendall's tau-bç›¸å…³ç³»æ•°æ¥è¡¡é‡è¯„ä¼°è€…ï¼ˆæ”¾å°„ç§‘åŒ»ç”Ÿï¼‰ä¹‹é—´ä»¥åŠè¯„ä¼°è€…ä¸æ¨¡å‹ä¹‹é—´çš„å¯¹é½ç¨‹åº¦ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜åˆ†æäº†ä¸åŒç±»å‹çš„æ‰°åŠ¨å¯¹æ¨¡å‹è§£é‡Šçš„å½±å“ï¼Œä¾‹å¦‚ï¼Œæ–‡æœ¬æ‰°åŠ¨é€šå¸¸æ¯”è§†è§‰æ‰°åŠ¨æ›´å®¹æ˜“å½±å“æ¨¡å‹çš„è§£é‡Šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç­”æ¡ˆå‡†ç¡®æ€§ä¸è§£é‡Šè´¨é‡å­˜åœ¨è§£è€¦ç°è±¡ï¼Œå³é«˜å‡†ç¡®ç‡çš„æ¨¡å‹ä¸ä¸€å®šå…·æœ‰é«˜è´¨é‡çš„è§£é‡Šã€‚ä¸“æœ‰æ¨¡å‹åœ¨å› æœå½’å› ï¼ˆ25.0% vs. 1.4%ï¼‰å’Œä¸´åºŠä¿çœŸåº¦ï¼ˆ36.1% vs. 31.7%ï¼‰æ–¹é¢ä¼˜äºå¼€æºæ¨¡å‹ï¼Œä½†æ–‡æœ¬çº¿ç´¢æ¯”è§†è§‰çº¿ç´¢æ›´å®¹æ˜“å½±å“æ¨¡å‹è§£é‡Šã€‚è¯»è€…ç ”ç©¶ä¸­ï¼Œè¯„ä¼°è€…-æ”¾å°„ç§‘åŒ»ç”Ÿç›¸å…³æ€§åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œå½’å› å¯¹é½åº¦æœ€é«˜ï¼ˆKendall's $Ï„_b=0.670$ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»å­¦å½±åƒè¾…åŠ©è¯Šæ–­é¢†åŸŸï¼Œå¸®åŠ©åŒ»ç”Ÿè¯„ä¼°VQAæ¨¡å‹çš„å¯ä¿¡åº¦ï¼Œä»è€Œæ›´å®‰å…¨æœ‰æ•ˆåœ°åˆ©ç”¨AIæŠ€æœ¯ã€‚é€šè¿‡æé«˜æ¨¡å‹è§£é‡Šçš„å¿ å®æ€§ï¼Œå¢å¼ºåŒ»ç”Ÿå¯¹AIè¾…åŠ©è¯Šæ–­çš„ä¿¡ä»»ï¼Œæœ€ç»ˆæå‡è¯Šæ–­æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œå¹¶å‡å°‘è¯¯è¯Šé£é™©ã€‚æœªæ¥å¯æ‰©å±•åˆ°å…¶ä»–åŒ»å­¦å½±åƒç±»å‹å’Œä¸´åºŠä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-language models (VLMs) often produce chain-of-thought (CoT) explanations that sound plausible yet fail to reflect the underlying decision process, undermining trust in high-stakes clinical use. Existing evaluations rarely catch this misalignment, prioritizing answer accuracy or adherence to formats. We present a clinically grounded framework for chest X-ray visual question answering (VQA) that probes CoT faithfulness via controlled text and image modifications across three axes: clinical fidelity, causal attribution, and confidence calibration. In a reader study (n=4), evaluator-radiologist correlations fall within the observed inter-radiologist range for all axes, with strong alignment for attribution (Kendall's $Ï„_b=0.670$), moderate alignment for fidelity ($Ï„_b=0.387$), and weak alignment for confidence tone ($Ï„_b=0.091$), which we report with caution. Benchmarking six VLMs shows that answer accuracy and explanation quality can be decoupled, acknowledging injected cues does not ensure grounding, and text cues shift explanations more than visual cues. While some open-source models match final answer accuracy, proprietary models score higher on attribution (25.0% vs. 1.4%) and often on fidelity (36.1% vs. 31.7%), highlighting deployment risks and the need to evaluate beyond final answer accuracy.

