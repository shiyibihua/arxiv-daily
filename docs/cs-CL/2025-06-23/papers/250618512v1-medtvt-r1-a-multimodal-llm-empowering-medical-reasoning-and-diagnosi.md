---
layout: default
title: MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis
---

# MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18512" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18512v1</a>
  <a href="https://arxiv.org/pdf/2506.18512.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18512v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18512v1', 'MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuting Zhang, Kaishen Yuan, Hao Lu, Yutao Yue, Jintai Chen, Kaishun Wu

**åˆ†ç±»**: eess.IV, cs.CL, cs.CV, q-bio.QM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/keke-nice/MedTVT-R1)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMedTVT-R1ä»¥è§£å†³å¤šç–¾ç—…è¯Šæ–­çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `åŒ»å­¦æ¨ç†` `å¤šç–¾ç—…è¯Šæ–­` `æ¨¡æ€æ„ŸçŸ¥` `å¼ºåŒ–å­¦ä¹ ` `ä¸´åºŠåº”ç”¨` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¤šä¾èµ–å•ä¸€æ¨¡æ€æ•°æ®ï¼Œéš¾ä»¥å…¨é¢ç†è§£å¤æ‚ç–¾ç—…ï¼Œå¯¼è‡´å¤šç–¾ç—…è¯Šæ–­çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºMedTVT-R1ï¼Œé€šè¿‡æ•´åˆå¤šæ¨¡æ€ä¸´åºŠæ•°æ®ï¼Œåˆ©ç”¨æ¨¡æ€æ„ŸçŸ¥å±‚å’Œå¼ºåŒ–å¾®è°ƒæŠ€æœ¯æ¥æå‡å¤šç–¾ç—…æ¨ç†ä¸è¯Šæ–­èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedTVT-R1åœ¨å¤šæ¨¡æ€ç‰¹å¾åˆ©ç”¨å’Œå¤šç–¾ç—…è¯Šæ–­ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç°å‡ºè‰¯å¥½çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®ä¸”å¯è§£é‡Šçš„å¤šç–¾ç—…è¯Šæ–­åœ¨åŒ»å­¦ç ”ç©¶ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨åˆ©ç”¨å¼‚æ„å¤šæ¨¡æ€åŒ»å­¦æ•°æ®æ—¶ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å•ä¸€æ¨¡æ€æ•°æ®ï¼Œé™åˆ¶äº†å¯¹å¤æ‚ç–¾ç—…çš„å…¨é¢ç†è§£ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†MedTVT-R1ï¼Œä¸€ä¸ªæ–°é¢–çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶ï¼Œæ—¨åœ¨æ•´åˆä¸´åºŠå¤šæ¨¡æ€æ•°æ®ä»¥è¿›è¡Œå¤šç–¾ç—…çš„æ¨ç†å’Œè¯Šæ–­ã€‚æˆ‘ä»¬æ„å»ºäº†MedTVT-QAï¼Œä¸€ä¸ªç­–åˆ’çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œæä¾›ç”Ÿç†å±‚é¢è§£é‡Šå’Œç–¾ç—…å±‚é¢è¯Šæ–­çš„é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œå¹¶é‡‡ç”¨è¯æ®é“¾æ–¹æ³•ã€‚MedTVT-R1åŒ…å«ä¸€ä¸ªæ¨¡æ€æ„ŸçŸ¥å±‚ï¼Œä»¥æ•æ‰æ¨¡æ€é—´çš„ä¾èµ–å…³ç³»å¹¶è‡ªé€‚åº”åœ°åŠ æƒæ¨¡æ€è´¡çŒ®ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å¾®è°ƒæ–¹æ³•ï¼Œç»“åˆJaccardå¥–åŠ±å‡½æ•°æ¥å¢å¼ºè¯Šæ–­æ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMedTVT-R1åœ¨å¤šæ¨¡æ€ç‰¹å¾åˆ©ç”¨å’Œå¤šç–¾ç—…è¯Šæ–­æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œä¸ºä¸´åºŠåº”ç”¨å¦‚è¯Šæ–­æŠ¥å‘Šç”Ÿæˆå’Œå…±ç—…æ¨ç†æä¾›äº†é‡è¦æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šç–¾ç—…è¯Šæ–­ä¸­çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¤šä¾èµ–å•ä¸€æ¨¡æ€æ•°æ®ï¼Œæ— æ³•å…¨é¢æ•æ‰å¤æ‚ç–¾ç—…çš„ç‰¹å¾å’Œç›¸äº’å…³ç³»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMedTVT-R1é€šè¿‡æ„å»ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼Œæ•´åˆä¸åŒæ¨¡æ€çš„ä¸´åºŠæ•°æ®ï¼Œåˆ©ç”¨æ¨¡æ€æ„ŸçŸ¥å±‚æ¥æ•æ‰æ¨¡æ€é—´çš„ä¾èµ–æ€§ï¼Œå¹¶è‡ªé€‚åº”åœ°åŠ æƒä¸åŒæ¨¡æ€çš„è´¡çŒ®ï¼Œä»¥å¢å¼ºæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡æ€æ„ŸçŸ¥å±‚ã€æ¨ç†æ¨¡å—å’Œå¼ºåŒ–å¾®è°ƒé˜¶æ®µã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£æ•´åˆå¤šæ¨¡æ€æ•°æ®ï¼Œæ¨¡æ€æ„ŸçŸ¥å±‚ç”¨äºæ•æ‰æ¨¡æ€é—´çš„å…³ç³»ï¼Œæ¨ç†æ¨¡å—è¿›è¡Œç–¾ç—…è¯Šæ–­ï¼Œæœ€åé€šè¿‡å¼ºåŒ–å¾®è°ƒä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥æ¨¡æ€æ„ŸçŸ¥å±‚å’ŒåŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å¾®è°ƒæ–¹æ³•ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤ŸåŠ¨æ€è°ƒæ•´æ¨¡æ€è´¡çŒ®ï¼Œæ˜¾è‘—æå‡äº†å¤šç–¾ç—…è¯Šæ–­çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†Jaccardå¥–åŠ±å‡½æ•°æ¥ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œç¡®ä¿æ¨¡å‹åœ¨æ¨ç†æ—¶èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡å’Œæ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMedTVT-R1åœ¨å¤šæ¨¡æ€ç‰¹å¾åˆ©ç”¨å’Œå¤šç–¾ç—…è¯Šæ–­ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸´åºŠè¯Šæ–­æ”¯æŒç³»ç»Ÿã€æ™ºèƒ½åŒ»ç–—åŠ©æ‰‹å’Œç–¾ç—…é¢„æµ‹æ¨¡å‹ç­‰ã€‚é€šè¿‡æ•´åˆå¤šæ¨¡æ€æ•°æ®ï¼ŒMedTVT-R1èƒ½å¤Ÿä¸ºåŒ»ç”Ÿæä¾›æ›´å‡†ç¡®çš„è¯Šæ–­å»ºè®®ï¼Œæå‡åŒ»ç–—å†³ç­–çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½åœ¨ä¸ªæ€§åŒ–åŒ»ç–—å’Œå…¬å…±å«ç”Ÿç®¡ç†ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate and interpretable multi-disease diagnosis remains a critical challenge in medical research, particularly when leveraging heterogeneous multimodal medical data. Current approaches often rely on single-modal data, limiting their ability to comprehensively understand complex diseases. To address this, we propose MedTVT-R1, a novel Multimodal Large Language Model (MLLM) framework designed to integrate clinical multimodal data for reasoning and diagnosing multiple diseases. We construct MedTVT-QA, a curated instruction dataset that provides question-answer pairs for physiological-level interpretations and disease-level diagnoses with a Chain of Evidence approach. MedTVT-R1 incorporates a modality perception layer to capture inter-modal dependencies and adaptively weight modality contributions. Additionally, we employ Group Relative Policy Optimization (GRPO)-based Reinforcement Fine-Tuning with a Jaccard Reward function to enhance diagnostic reasoning. Experimental results demonstrate MedTVT-R1's superiority in multimodal feature utilization and multi-disease diagnosis, offering significant potential for clinical applications such as diagnostic report generation and comorbidity reasoning. The dataset and code are available at https://github.com/keke-nice/MedTVT-R1.

