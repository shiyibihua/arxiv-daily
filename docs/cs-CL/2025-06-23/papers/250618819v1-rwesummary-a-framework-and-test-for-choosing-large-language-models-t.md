---
layout: default
title: RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies
---

# RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18819" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18819v1</a>
  <a href="https://arxiv.org/pdf/2506.18819.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18819v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18819v1', 'RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arjun Mukerji, Michael L. Jackson, Jason Jones, Neil Sanghavi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**å¤‡æ³¨**: 24 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRWESummaryæ¡†æ¶ä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨RWEç ”ç©¶æ€»ç»“ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `çœŸå®ä¸–ç•Œè¯æ®` `åŒ»å­¦ç ”ç©¶` `æ¨¡å‹è¯„ä¼°` `åŸºå‡†æµ‹è¯•` `RWESummary` `æ•°æ®åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ€»ç»“çœŸå®ä¸–ç•Œè¯æ®ç ”ç©¶ä¸­çš„è¡¨ç°ï¼Œå­˜åœ¨æ˜æ˜¾çš„ç ”ç©¶ç©ºç™½ã€‚
2. RWESummaryæ¡†æ¶é€šè¿‡å¼•å…¥ç‰¹å®šåœºæ™¯å’Œè¯„ä¼°æ ‡å‡†ï¼Œæ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œå¹¶æä¾›å¯¹LLMsçš„ç³»ç»Ÿæ€§è¯„ä¼°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGemini 2.5æ¨¡å‹åœ¨13ä¸ªRWEç ”ç©¶ä¸­è¡¨ç°æœ€ä½³ï¼Œæä¾›äº†æœ‰æ•ˆçš„åŸºå‡†å‚è€ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸€èˆ¬æ‘˜è¦ä»»åŠ¡å’ŒåŒ»å­¦ç ”ç©¶è¾…åŠ©æ–¹é¢å¾—åˆ°äº†å¹¿æ³›è¯„ä¼°ï¼Œä½†å°šæœªä¸“é—¨é’ˆå¯¹ä»RWEç ”ç©¶ç»“æ„åŒ–è¾“å‡ºä¸­æ€»ç»“çœŸå®ä¸–ç•Œè¯æ®ï¼ˆRWEï¼‰çš„ä»»åŠ¡è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬æå‡ºäº†RWESummaryï¼Œä½œä¸ºMedHELMæ¡†æ¶çš„è¡¥å……ï¼Œä»¥ä¾¿å¯¹LLMsåœ¨æ­¤ä»»åŠ¡ä¸­çš„è¡¨ç°è¿›è¡ŒåŸºå‡†æµ‹è¯•ã€‚RWESummaryåŒ…æ‹¬ä¸€ä¸ªåœºæ™¯å’Œä¸‰ä¸ªè¯„ä¼°ï¼Œæ¶µç›–äº†åŒ»å­¦ç ”ç©¶æ‘˜è¦ä¸­è§‚å¯Ÿåˆ°çš„ä¸»è¦é”™è¯¯ç±»å‹ï¼Œå¹¶ä½¿ç”¨Atropos Healthä¸“æœ‰æ•°æ®å¼€å‘ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åˆ©ç”¨RWESummaryæ¯”è¾ƒäº†ä¸åŒLLMsåœ¨å†…éƒ¨RWEæ‘˜è¦å·¥å…·ä¸­çš„è¡¨ç°ã€‚æ ¹æ®13ä¸ªä¸åŒçš„RWEç ”ç©¶ï¼Œå‘ç°Gemini 2.5æ¨¡å‹åœ¨æ•´ä½“è¡¨ç°ä¸Šæœ€ä½³ï¼ˆåŒ…æ‹¬Flashå’ŒProï¼‰ã€‚æˆ‘ä»¬å»ºè®®RWESummaryä½œä¸ºçœŸå®ä¸–ç•Œè¯æ®ç ”ç©¶æ‘˜è¦çš„ä¸€ä¸ªæ–°é¢–ä¸”æœ‰ç”¨çš„åŸºç¡€æ¨¡å‹åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ€»ç»“çœŸå®ä¸–ç•Œè¯æ®ï¼ˆRWEï¼‰ç ”ç©¶ä¸­çš„è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹RWEç ”ç©¶ç»“æ„åŒ–è¾“å‡ºçš„ä¸“é—¨è¯„ä¼°ï¼Œå¯¼è‡´æ— æ³•å‡†ç¡®åˆ¤æ–­æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRWESummaryæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡ç‰¹å®šçš„è¯„ä¼°åœºæ™¯å’Œæ ‡å‡†ï¼Œç³»ç»Ÿæ€§åœ°æ¯”è¾ƒä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨RWEæ‘˜è¦ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æä¾›ä¸€ä¸ªå¯é çš„åŸºå‡†ï¼Œä»¥ä¾¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿé€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRWESummaryæ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œä¸‰ä¸ªä¸»è¦è¯„ä¼°æ¨¡å—ï¼Œåˆ†åˆ«é’ˆå¯¹åŒ»å­¦ç ”ç©¶æ‘˜è¦ä¸­å¸¸è§çš„é”™è¯¯ç±»å‹è¿›è¡Œåˆ†æã€‚æ•´ä½“æµç¨‹æ¶µç›–æ•°æ®æ”¶é›†ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æç­‰é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šRWESummaryçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ä¸“é—¨é’ˆå¯¹RWEç ”ç©¶çš„è¯„ä¼°æœºåˆ¶ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­çš„ç©ºç™½ã€‚è¿™ä¸€æ¡†æ¶ä¸ä»…æä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°æ–¹æ³•ï¼Œè¿˜ä¸ºåç»­ç ”ç©¶æä¾›äº†å¯é‡å¤çš„åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RWESummaryä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹é”™è¯¯ç±»å‹çš„åˆ†ç±»ã€è¯„ä¼°æŒ‡æ ‡çš„è®¾å®šä»¥åŠæ¨¡å‹æ€§èƒ½çš„æ¯”è¾ƒæ–¹æ³•ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒRWESummaryæ¡†æ¶å¯¹13ä¸ªä¸åŒçš„RWEç ”ç©¶è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºGemini 2.5æ¨¡å‹åœ¨æ•´ä½“è¡¨ç°ä¸Šä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒåŒ…æ‹¬Flashå’ŒProç‰ˆæœ¬ã€‚è¿™ä¸€å‘ç°ä¸ºé€‰æ‹©åˆé€‚çš„è¯­è¨€æ¨¡å‹æä¾›äº†å®è¯ä¾æ®ï¼Œå…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RWESummaryæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»å­¦ç ”ç©¶å’Œä¸´åºŠå†³ç­–æ”¯æŒé¢†åŸŸã€‚é€šè¿‡æä¾›å¯¹å¤§è¯­è¨€æ¨¡å‹åœ¨RWEç ”ç©¶æ€»ç»“ä¸­çš„ç³»ç»Ÿè¯„ä¼°ï¼Œç ”ç©¶äººå‘˜å’Œä¸´åºŠåŒ»ç”Ÿå¯ä»¥æ›´æœ‰æ•ˆåœ°é€‰æ‹©é€‚åˆçš„å·¥å…·ï¼Œä»è€Œæé«˜ç ”ç©¶æˆæœçš„å¯ç”¨æ€§å’Œå®ç”¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸçš„è¯æ®æ€»ç»“å’Œåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have been extensively evaluated for general summarization tasks as well as medical research assistance, but they have not been specifically evaluated for the task of summarizing real-world evidence (RWE) from structured output of RWE studies. We introduce RWESummary, a proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al., 2025) to enable benchmarking of LLMs for this task. RWESummary includes one scenario and three evaluations covering major types of errors observed in summarization of medical research studies and was developed using Atropos Health proprietary data. Additionally, we use RWESummary to compare the performance of different LLMs in our internal RWE summarization tool. At the time of publication, with 13 distinct RWE studies, we found the Gemini 2.5 models performed best overall (both Flash and Pro). We suggest RWESummary as a novel and useful foundation model benchmark for real-world evidence study summarization.

