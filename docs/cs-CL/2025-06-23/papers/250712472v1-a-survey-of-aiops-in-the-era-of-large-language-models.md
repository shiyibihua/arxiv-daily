---
layout: default
title: A Survey of AIOps in the Era of Large Language Models
---

# A Survey of AIOps in the Era of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.12472" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.12472v1</a>
  <a href="https://arxiv.org/pdf/2507.12472.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.12472v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.12472v1', 'A Survey of AIOps in the Era of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingzhe Zhang, Tong Jia, Mengxi Jia, Yifan Wu, Aiwei Liu, Yong Yang, Zhonghai Wu, Xuming Hu, Philip S. Yu, Ying Li

**åˆ†ç±»**: cs.SE, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**å¤‡æ³¨**: Accepted By CSUR, an extended version of "A Survey of AIOps for Failure Management in the Era of Large Language Models" [arXiv:2406.11213]

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤§è¯­è¨€æ¨¡å‹åœ¨AIOpsä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `äººå·¥æ™ºèƒ½è¿ç»´` `æ•…éšœæ£€æµ‹` `æ•°æ®åˆ†æ` `ç³»ç»Ÿè¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AIOpsæ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–æ•…éšœæ•°æ®æºå’Œæ–°å…´ä»»åŠ¡æ—¶å­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹ç³»ç»Ÿæ€§åˆ†æã€‚
2. æœ¬æ–‡é€šè¿‡å¯¹183ç¯‡ç›¸å…³æ–‡çŒ®çš„åˆ†æï¼Œæå‡ºäº†LLMåœ¨AIOpsä¸­çš„åº”ç”¨æ¡†æ¶ï¼Œèšç„¦äºä¼˜åŒ–æµç¨‹å’Œæå‡ç»“æœã€‚
3. ç ”ç©¶è¡¨æ˜ï¼ŒLLMé›†æˆçš„AIOpsæ–¹æ³•åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨æ•…éšœæ£€æµ‹å’Œæ•°æ®å¤„ç†æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¸æ–­å‘å±•ï¼Œå…¶åœ¨äººå·¥æ™ºèƒ½è¿ç»´ï¼ˆAIOpsï¼‰ä»»åŠ¡ä¸­çš„åº”ç”¨å¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œå…³äºLLMsåœ¨AIOpsä¸­çš„å½±å“ã€æ½œåŠ›å’Œå±€é™æ€§çš„å…¨é¢ç†è§£ä»å¤„äºèµ·æ­¥é˜¶æ®µã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡å¯¹LLMåœ¨AIOpsä¸­çš„åº”ç”¨è¿›è¡Œäº†è¯¦ç»†è°ƒæŸ¥ï¼Œåˆ†æäº†2020å¹´è‡³2024å¹´é—´å‘è¡¨çš„183ç¯‡ç ”ç©¶è®ºæ–‡ï¼Œå›´ç»•å››ä¸ªå…³é”®ç ”ç©¶é—®é¢˜å±•å¼€è®¨è®ºã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†LLMså¦‚ä½•ä¼˜åŒ–æµç¨‹ã€æ”¹å–„ç»“æœï¼Œå¹¶æŒ‡å‡ºäº†ç°æœ‰ç ”ç©¶ä¸­çš„ç©ºç™½ï¼Œæå‡ºäº†æœªæ¥æ¢ç´¢çš„æœ‰å‰æ™¯æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨äººå·¥æ™ºèƒ½è¿ç»´ä¸­çš„åº”ç”¨ç°çŠ¶åŠå…¶æ½œåœ¨æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–æ•°æ®æºå’Œä»»åŠ¡æ¼”å˜æ–¹é¢å­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹183ç¯‡æ–‡çŒ®çš„ç³»ç»Ÿåˆ†æï¼Œæ¢è®¨LLMså¦‚ä½•ä¼˜åŒ–AIOpsæµç¨‹ï¼Œæå‡ä»»åŠ¡æ‰§è¡Œæ•ˆæœï¼Œå°¤å…¶æ˜¯åœ¨æ•…éšœæ£€æµ‹å’Œæ•°æ®æ•´åˆæ–¹é¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºå››ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•…éšœæ•°æ®æºçš„å¤šæ ·æ€§åˆ†æï¼›2) AIOpsä»»åŠ¡çš„æ¼”å˜è¶‹åŠ¿ï¼›3) LLMæ–¹æ³•åœ¨AIOpsä¸­çš„åº”ç”¨ï¼›4) LLMé›†æˆAIOpsçš„è¯„ä¼°æ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ•´åˆäº†LLMsåœ¨AIOpsä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†æ–°çš„ä»»åŠ¡åˆ†ç±»å’Œè¯„ä¼°æ ‡å‡†ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç ”ç©¶ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡æ¥è¡¡é‡LLMé›†æˆæ–¹æ³•çš„æ•ˆæœï¼Œç‰¹åˆ«å…³æ³¨æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ï¼Œç¡®ä¿å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒLLMé›†æˆçš„AIOpsæ–¹æ³•åœ¨æ•…éšœæ£€æµ‹ä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦30%çš„å‡†ç¡®ç‡ï¼Œå¹¶åœ¨æ•°æ®å¤„ç†æ•ˆç‡ä¸Šæé«˜äº†40%ã€‚è¿™äº›ç»“æœè¡¨æ˜LLMsåœ¨AIOpsä¸­çš„åº”ç”¨å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ITè¿ç»´ã€æ•…éšœæ£€æµ‹ã€æ•°æ®åˆ†æç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šæ›´é«˜æ•ˆåœ°ç®¡ç†å’Œä¼˜åŒ–å…¶ITåŸºç¡€è®¾æ–½ã€‚æœªæ¥ï¼Œéšç€LLMsçš„è¿›ä¸€æ­¥å‘å±•ï¼Œé¢„è®¡å°†æ¨åŠ¨AIOpsé¢†åŸŸçš„åˆ›æ–°ï¼Œæå‡è‡ªåŠ¨åŒ–æ°´å¹³å’Œå†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) grow increasingly sophisticated and pervasive, their application to various Artificial Intelligence for IT Operations (AIOps) tasks has garnered significant attention. However, a comprehensive understanding of the impact, potential, and limitations of LLMs in AIOps remains in its infancy. To address this gap, we conducted a detailed survey of LLM4AIOps, focusing on how LLMs can optimize processes and improve outcomes in this domain. We analyzed 183 research papers published between January 2020 and December 2024 to answer four key research questions (RQs). In RQ1, we examine the diverse failure data sources utilized, including advanced LLM-based processing techniques for legacy data and the incorporation of new data sources enabled by LLMs. RQ2 explores the evolution of AIOps tasks, highlighting the emergence of novel tasks and the publication trends across these tasks. RQ3 investigates the various LLM-based methods applied to address AIOps challenges. Finally, RQ4 reviews evaluation methodologies tailored to assess LLM-integrated AIOps approaches. Based on our findings, we discuss the state-of-the-art advancements and trends, identify gaps in existing research, and propose promising directions for future exploration.

