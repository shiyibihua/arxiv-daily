---
layout: default
title: Parallel Continuous Chain-of-Thought with Jacobi Iteration
---

# Parallel Continuous Chain-of-Thought with Jacobi Iteration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18582" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18582v1</a>
  <a href="https://arxiv.org/pdf/2506.18582.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18582v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18582v1', 'Parallel Continuous Chain-of-Thought with Jacobi Iteration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoyi Wu, Zhihao Teng, Kewei Tu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**å¤‡æ³¨**: under review

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/whyNLP/PCCoT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹¶è¡Œè¿ç»­æ€ç»´é“¾æ–¹æ³•ä»¥æå‡æ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¹¶è¡Œè®¡ç®—` `è¿ç»­æ€ç»´é“¾` `é›…å¯æ¯”è¿­ä»£` `æ¨ç†æ•ˆç‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹è®­ç»ƒ` `æ™ºèƒ½ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¿ç»­æ€ç»´é“¾æ–¹æ³•ç”±äºæ½œåœ¨æ€ç»´ä»¤ç‰Œçš„é¡ºåºä¾èµ–æ€§ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿ã€‚
2. æœ¬æ–‡æå‡ºçš„PCCoTé€šè¿‡é›…å¯æ¯”è¿­ä»£å®ç°æ½œåœ¨æ€ç»´ä»¤ç‰Œçš„å¹¶è¡Œæ›´æ–°ï¼Œå…‹æœäº†é¡ºåºä¾èµ–æ€§çš„é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPCCoTåœ¨èŠ‚çœè¿‘50%è®­ç»ƒå’Œæ¨ç†æ—¶é—´çš„åŒæ—¶ï¼Œæ€§èƒ½å¯æ¯”ç”šè‡³ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œä¸”è®­ç»ƒè¿‡ç¨‹æ›´ç¨³å®šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿ç»­æ€ç»´é“¾ï¼ˆCoTï¼‰åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å·²è¢«è¯æ˜èƒ½å¤Ÿæœ‰æ•ˆèŠ‚çœæ¨ç†ä»¤ç‰Œã€‚ç„¶è€Œï¼Œæ½œåœ¨æ€ç»´ä»¤ç‰Œä¹‹é—´çš„é¡ºåºä¾èµ–æ€§å½±å“äº†å¹¶è¡Œè®­ç»ƒï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´è¾ƒé•¿ã€‚æœ¬æ–‡æå‡ºäº†å¹¶è¡Œè¿ç»­æ€ç»´é“¾ï¼ˆPCCoTï¼‰ï¼Œé€šè¿‡å¯¹æ½œåœ¨æ€ç»´ä»¤ç‰Œè¿›è¡Œé›…å¯æ¯”è¿­ä»£ï¼Œå®ç°å¹¶è¡Œæ›´æ–°ï¼Œä»è€Œæé«˜äº†è¿ç»­CoTçš„è®­ç»ƒå’Œæ¨ç†æ•ˆç‡ã€‚å®éªŒè¡¨æ˜ï¼Œé€šè¿‡é€‰æ‹©é€‚å½“çš„è¿­ä»£æ¬¡æ•°ï¼ŒPCCoTèƒ½å¤Ÿåœ¨èŠ‚çœè¿‘50%è®­ç»ƒå’Œæ¨ç†æ—¶é—´çš„åŒæ—¶ï¼Œè¾¾åˆ°å¯æ¯”ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒPCCoTåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¡¨ç°å‡ºæ›´å¥½çš„ç¨³å®šæ€§å’Œé²æ£’æ€§ã€‚ä»£ç å¯åœ¨https://github.com/whyNLP/PCCoTè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¿ç»­æ€ç»´é“¾æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”±äºæ½œåœ¨æ€ç»´ä»¤ç‰Œçš„é¡ºåºä¾èµ–æ€§è€Œå¯¼è‡´çš„ä½æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ¨ç†æ—¶éœ€è¦ä¾èµ–äºå‰ä¸€ä¸ªä»¤ç‰Œçš„è¾“å‡ºï¼Œé™åˆ¶äº†å¹¶è¡Œå¤„ç†çš„èƒ½åŠ›ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´è¿‡é•¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPCCoTçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é›…å¯æ¯”è¿­ä»£å¯¹æ½œåœ¨æ€ç»´ä»¤ç‰Œè¿›è¡Œå¹¶è¡Œæ›´æ–°ï¼Œè€Œéé¡ºåºæ›´æ–°ã€‚è¿™ç§è®¾è®¡å…è®¸å¤šä¸ªä»¤ç‰ŒåŒæ—¶è¿›è¡Œè®¡ç®—ï¼Œä»è€Œæ˜¾è‘—æé«˜è®­ç»ƒå’Œæ¨ç†çš„æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPCCoTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ½œåœ¨æ€ç»´ä»¤ç‰Œçš„åˆå§‹åŒ–ã€é›…å¯æ¯”è¿­ä»£æ›´æ–°è¿‡ç¨‹ä»¥åŠæœ€ç»ˆçš„æ¨ç†é˜¶æ®µã€‚æ¯ä¸ªæ½œåœ¨æ€ç»´ä»¤ç‰Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­éƒ½èƒ½å¹¶è¡Œæ›´æ–°ï¼Œå‡å°‘äº†è®¡ç®—æ—¶é—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šPCCoTçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†é›…å¯æ¯”è¿­ä»£æ–¹æ³•ï¼Œä½¿å¾—æ½œåœ¨æ€ç»´ä»¤ç‰Œçš„æ›´æ–°è¿‡ç¨‹å¯ä»¥å¹¶è¡Œè¿›è¡Œã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é¡ºåºæ›´æ–°æ–¹å¼æœ¬è´¨ä¸Šä¸åŒï¼Œæå¤§åœ°æå‡äº†è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒPCCoTéœ€è¦è®¾ç½®é€‚å½“çš„è¿­ä»£æ¬¡æ•°ï¼Œä»¥ç¡®ä¿åœ¨èŠ‚çœæ—¶é—´çš„åŒæ—¶ä¸æŸå¤±æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©å’Œç½‘ç»œç»“æ„çš„è®¾è®¡ä¹Ÿå¯¹æœ€ç»ˆæ•ˆæœæœ‰é‡è¦å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPCCoTåœ¨é€‰æ‹©åˆé€‚çš„è¿­ä»£æ¬¡æ•°åï¼Œèƒ½å¤Ÿåœ¨èŠ‚çœè¿‘50%çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´çš„åŒæ—¶ï¼Œè¾¾åˆ°ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼ŒPCCoTåœ¨ç¨³å®šæ€§å’Œé²æ£’æ€§æ–¹é¢ä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PCCoTçš„ç ”ç©¶æˆæœåœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æ¨ç†æ•ˆç‡ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ”¯æŒæ›´å¤§è§„æ¨¡çš„æ¨¡å‹è®­ç»ƒå’Œå®æ—¶æ¨ç†ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å¿«é€Ÿå“åº”å’Œé«˜æ•ˆè¿è¡Œã€‚æœªæ¥ï¼ŒPCCoTå¯èƒ½ä¼šåœ¨å¤šæ¨¡æ€å­¦ä¹ å’Œå¤æ‚æ¨ç†ä»»åŠ¡ä¸­å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Continuous chain-of-thought has been shown to be effective in saving reasoning tokens for large language models. By reasoning with continuous latent thought tokens, continuous CoT is able to perform implicit reasoning in a compact manner. However, the sequential dependencies between latent thought tokens spoil parallel training, leading to long training time. In this paper, we propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi iteration on the latent thought tokens, updating them iteratively in parallel instead of sequentially and thus improving both training and inference efficiency of continuous CoT. Experiments demonstrate that by choosing the proper number of iterations, we are able to achieve comparable or even better performance while saving nearly 50% of the training and inference time. Moreover, PCCoT shows better stability and robustness in the training process. Our code is available at https://github.com/whyNLP/PCCoT.

