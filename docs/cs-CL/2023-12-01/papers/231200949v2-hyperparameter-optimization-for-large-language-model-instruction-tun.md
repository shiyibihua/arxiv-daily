---
layout: default
title: Hyperparameter Optimization for Large Language Model Instruction-Tuning
---

# Hyperparameter Optimization for Large Language Model Instruction-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00949" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00949v2</a>
  <a href="https://arxiv.org/pdf/2312.00949.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00949v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00949v2', 'Hyperparameter Optimization for Large Language Model Instruction-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Christophe Tribes, Sacha Benarroch-Lelong, Peng Lu, Ivan Kobyzev

**åˆ†ç±»**: cs.CL, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-01-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¶…å‚æ•°ä¼˜åŒ–æ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹çš„æŒ‡ä»¤å¾®è°ƒæ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è¶…å‚æ•°ä¼˜åŒ–` `ä½ç§©é€‚åº”` `é»‘ç®±ä¼˜åŒ–` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¾®è°ƒæŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨å¤„ç†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ—¶é¢ä¸´è¶…å‚æ•°é€‰æ‹©å›°éš¾ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡é»‘ç®±ä¼˜åŒ–æŠ€æœ¯æ¥é€‰æ‹©LoRAæ–¹æ³•ä¸­çš„è¶…å‚æ•°ï¼Œä»¥æé«˜å¾®è°ƒæ•ˆç‡å’Œæ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨
omadç®—æ³•è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–åï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—æå‡ï¼Œä¸”ä¸äººç±»æœŸæœ›æ›´åŠ ä¸€è‡´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¾®è°ƒä½¿å…¶åœ¨è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ä¸­å–å¾—äº†é‡è¦è¿›å±•ã€‚éšç€LLMsè§„æ¨¡çš„ä¸æ–­æ‰©å¤§ï¼Œå¼€å‘æ›´é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•å˜å¾—å°¤ä¸ºé‡è¦ã€‚ä½ç§©é€‚åº”ï¼ˆLoRAï¼‰æ–¹æ³•é€šè¿‡å†»ç»“å¤§éƒ¨åˆ†é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä»…å¯¹å°‘é‡ç½‘ç»œå‚æ•°è¿›è¡Œè°ƒæ•´ï¼Œä»è€Œå®ç°é«˜æ•ˆå¾®è°ƒã€‚ç„¶è€Œï¼ŒLoRAçš„æ€§èƒ½é«˜åº¦ä¾èµ–äºä¸€ç»„è¶…å‚æ•°çš„é€‰æ‹©ã€‚æœ¬æ–‡é€šè¿‡ä¸¤ç§ä¸»è¦çš„é»‘ç®±ä¼˜åŒ–æŠ€æœ¯ï¼Œç ”ç©¶äº†è¿™äº›è¶…å‚æ•°çš„é€‰æ‹©ï¼Œåˆ©ç”¨
omadç®—æ³•æœ‰æ•ˆæ¢ç´¢è¶…å‚æ•°ç©ºé—´ï¼Œæ˜¾è‘—æå‡äº†å¾®è°ƒæ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œäººç±»å¯¹é½åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­è¶…å‚æ•°é€‰æ‹©ä¸å½“å¯¼è‡´çš„æ€§èƒ½ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•åœ¨è¶…å‚æ•°ä¼˜åŒ–ä¸Šç¼ºä¹æœ‰æ•ˆçš„ç­–ç•¥ï¼Œå½±å“äº†æ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºåˆ©ç”¨é»‘ç®±ä¼˜åŒ–æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯
omadç®—æ³•ï¼Œæ¥ç³»ç»Ÿæ€§åœ°æ¢ç´¢å’Œä¼˜åŒ–LoRAæ–¹æ³•ä¸­çš„è¶…å‚æ•°ï¼Œä»è€Œæå‡æ¨¡å‹çš„å¾®è°ƒæ•ˆæœã€‚é€šè¿‡å°†å¾®è°ƒè¿‡ç¨‹è§†ä¸ºä¸€ä¸ªé»‘ç®±ï¼Œèƒ½å¤Ÿæ›´é«˜æ•ˆåœ°è¿›è¡Œè¶…å‚æ•°æœç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒå’ŒéªŒè¯ï¼Œé¦–å…ˆé€šè¿‡LoRAæ–¹æ³•è¿›è¡Œå¾®è°ƒï¼Œç„¶ååº”ç”¨
omadç®—æ³•å¯¹è¶…å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ä¿æŒå¤§éƒ¨åˆ†æƒé‡ä¸å˜çš„æƒ…å†µä¸‹ï¼Œä¸“æ³¨äºå°‘é‡å‚æ•°çš„è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†é»‘ç®±ä¼˜åŒ–æŠ€æœ¯åº”ç”¨äºè¶…å‚æ•°é€‰æ‹©ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹LoRAæ–¹æ³•çš„ä¼˜åŒ–ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„æ‰‹åŠ¨è°ƒå‚æ–¹å¼ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´ç³»ç»Ÿå’Œé«˜æ•ˆåœ°æ‰¾åˆ°æœ€ä½³è¶…å‚æ•°ç»„åˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¶…å‚æ•°è®¾ç½®ä¸­ï¼Œé‡ç‚¹å…³æ³¨ä½ç§©åˆ†è§£çš„ç§©å€¼ç­‰å…³é”®å‚æ•°ï¼Œé€šè¿‡å®éªŒéªŒè¯ä¸åŒå‚æ•°ç»„åˆå¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç¡®ä¿å¾®è°ƒè¿‡ç¨‹çš„é«˜æ•ˆæ€§å’Œæœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥é€‚åº”ä¼˜åŒ–ç›®æ ‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨
omadç®—æ³•ä¼˜åŒ–è¶…å‚æ•°åï¼Œæ¨¡å‹åœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œæ¨¡å‹ä¸äººç±»æœŸæœ›çš„å¯¹é½åº¦ä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ï¼ŒéªŒè¯äº†ä¼˜åŒ–æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæ»¡è¶³æ›´é«˜çš„ç”¨æˆ·éœ€æ±‚ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å¾®è°ƒä¸­ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The fine-tuning of Large Language Models (LLMs) has enabled them to recently achieve milestones in natural language processing applications. The emergence of ever larger LLMs has paved the way for more efficient fine-tuning methods. Among these, the Low-Rank Adaptation (LoRA) method keeps most of the weights of the pre-trained LLM frozen while introducing a low-rank decomposition of the weight matrix, enabling the tuning of only a very small proportion of the network. The performance on downstream tasks of models fine-tuned with LoRA heavily relies on a set of hyperparameters including the rank of the decomposition. In this work, we investigate the choice of these hyperparameters through two main blackbox optimization (BBO) techniques. We examine the whole pipeline of performing fine-tuning and validation on a pre-trained LLM as a blackbox and efficiently explore the space of hyperparameters with the \nomad algorithm, achieving a boost in performance and human alignment of the tuned model.

