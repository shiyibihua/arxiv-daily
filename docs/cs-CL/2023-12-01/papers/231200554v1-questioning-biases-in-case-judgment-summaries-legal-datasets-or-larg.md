---
layout: default
title: Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?
---

# Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00554" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00554v1</a>
  <a href="https://arxiv.org/pdf/2312.00554.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00554v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00554v1', 'Questioning Biases in Case Judgment Summaries: Legal Datasets or Large Language Models?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aniket Deroy, Subhankar Maity

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨æ³•å¾‹åˆ¤å†³æ‘˜è¦ä¸­çš„åè§é—®é¢˜åŠå…¶å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ³•å¾‹æŠ€æœ¯` `åè§åˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `åˆ¤å†³æ‘˜è¦` `äººå·¥æ™ºèƒ½ä¼¦ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ³•å¾‹æ•°æ®é›†å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„åˆ¤å†³æ‘˜è¦ä¸­å¯èƒ½å­˜åœ¨åè§ï¼Œå½±å“æ³•å¾‹å†³ç­–çš„å‡†ç¡®æ€§å’Œå…¬æ­£æ€§ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åˆ†æä¸åŒç±»å‹çš„åè§ï¼Œæ¢è®¨å…¶å¯¹æ³•å¾‹åˆ¤å†³çš„å½±å“ï¼Œæ—¨åœ¨æé«˜å¯¹æŠ€æœ¯åœ¨æ³•å¾‹é¢†åŸŸä½œç”¨çš„ç†è§£ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å’ŒæŠ½è±¡æ‘˜è¦æ¨¡å‹çš„è¾“å‡ºä¸­å­˜åœ¨æ˜æ˜¾çš„åè§ï¼Œæç¤ºéœ€è¦å¯¹è¿™äº›æŠ€æœ¯è¿›è¡Œæ›´æ·±å…¥çš„å®¡è§†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ³•å¾‹æ•°æ®é›†çš„å‘å±•å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å‡ºç°æ˜¾è‘—æ”¹å˜äº†æ³•å¾‹é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆæ¡ˆä»¶åˆ¤å†³æ‘˜è¦æ–¹é¢ã€‚ç„¶è€Œï¼Œæ½œè—äºè¿™äº›æ‘˜è¦ä¸­çš„åè§é—®é¢˜å¼•å‘äº†å…³æ³¨ã€‚æœ¬ç ”ç©¶å®¡è§†äº†æ³•å¾‹æ•°æ®é›†å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ¡ˆä»¶åˆ¤å†³æ‘˜è¦ä¸­çš„åè§ï¼Œåˆ†æäº†è¿™äº›åè§å¯¹æ³•å¾‹å†³ç­–çš„å½±å“ã€‚é€šè¿‡å¯¹æ€§åˆ«ã€ç§æ—ã€é’ˆå¯¹å¥³æ€§çš„çŠ¯ç½ªå…³é”®è¯ã€å›½å®¶åç§°å’Œå®—æ•™å…³é”®è¯çš„åè§è¿›è¡Œè°ƒæŸ¥ï¼Œç ”ç©¶æ˜¾ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹å’Œé¢„è®­ç»ƒçš„æŠ½è±¡æ‘˜è¦æ¨¡å‹è¾“å‡ºä¸­å­˜åœ¨æœ‰è¶£çš„åè§è¯æ®ã€‚è¿™äº›åè§çš„æˆå› éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³æ³•å¾‹åˆ¤å†³æ‘˜è¦ä¸­æ½œåœ¨çš„åè§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯†åˆ«å’Œåˆ†æè¿™äº›åè§å¯¹æ³•å¾‹å†³ç­–çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿåœ°å®¡è§†æ³•å¾‹æ•°æ®é›†å’Œå¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦ï¼Œåˆ†æä¸åŒç±»å‹çš„åè§ï¼Œå°¤å…¶æ˜¯ä¸æ€§åˆ«ã€ç§æ—å’Œå®—æ•™ç›¸å…³çš„åè§ï¼Œä»¥æ­ç¤ºå…¶å¯¹æ³•å¾‹å…¬æ­£çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®šé‡å’Œå®šæ€§åˆ†æç›¸ç»“åˆçš„æ–¹æ³•ï¼Œé¦–å…ˆè¯†åˆ«æ‘˜è¦ä¸­çš„åè§å…³é”®è¯ï¼Œç„¶åè¯„ä¼°è¿™äº›åè§å¯¹æ³•å¾‹å†³ç­–çš„æ½œåœ¨å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†æ³•å¾‹åˆ¤å†³æ‘˜è¦ä¸­çš„å¤šç§åè§ï¼Œå°¤å…¶æ˜¯é€šè¿‡æ¯”è¾ƒæ³•å¾‹æ•°æ®é›†å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„è¾“å‡ºï¼Œæ­ç¤ºäº†åè§çš„å­˜åœ¨åŠå…¶å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†ç‰¹å®šçš„å…³é”®è¯åˆ†ç±»æ–¹æ³•ï¼Œç»“åˆç»Ÿè®¡åˆ†æå·¥å…·ï¼Œè¯„ä¼°ä¸åŒæ¨¡å‹ç”Ÿæˆçš„æ‘˜è¦ä¸­åè§çš„æ˜¾è‘—æ€§å’Œå½±å“ç¨‹åº¦ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œåˆ†ææ–¹æ³•åœ¨ç ”ç©¶ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„æ³•å¾‹åˆ¤å†³æ‘˜è¦ä¸­å­˜åœ¨æ˜¾è‘—çš„æ€§åˆ«å’Œç§æ—åè§ï¼Œåè§çš„ç¨‹åº¦åœ¨ä¸åŒæ¨¡å‹ä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚è¿™ä¸€å‘ç°æç¤ºæ³•å¾‹æŠ€æœ¯åœ¨åº”ç”¨æ—¶éœ€è°¨æ…ï¼Œé¿å…åŠ å‰§ç°æœ‰çš„ç¤¾ä¼šä¸å¹³ç­‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ³•å¾‹æŠ€æœ¯ã€å¸æ³•ç³»ç»Ÿæ”¹é©å’Œäººå·¥æ™ºèƒ½ä¼¦ç†ã€‚é€šè¿‡è¯†åˆ«å’Œåˆ†ææ³•å¾‹åˆ¤å†³æ‘˜è¦ä¸­çš„åè§ï¼Œå¯ä»¥ä¸ºæ³•å¾‹å®è·µæä¾›æ›´å…¬æ­£çš„æŠ€æœ¯æ”¯æŒï¼Œä¿ƒè¿›æ³•å¾‹å†³ç­–çš„é€æ˜åº¦å’Œå…¬å¹³æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The evolution of legal datasets and the advent of large language models (LLMs) have significantly transformed the legal field, particularly in the generation of case judgment summaries. However, a critical concern arises regarding the potential biases embedded within these summaries. This study scrutinizes the biases present in case judgment summaries produced by legal datasets and large language models. The research aims to analyze the impact of biases on legal decision making. By interrogating the accuracy, fairness, and implications of biases in these summaries, this study contributes to a better understanding of the role of technology in legal contexts and the implications for justice systems worldwide. In this study, we investigate biases wrt Gender-related keywords, Race-related keywords, Keywords related to crime against women, Country names and religious keywords. The study shows interesting evidences of biases in the outputs generated by the large language models and pre-trained abstractive summarization models. The reasoning behind these biases needs further studies.

