---
layout: default
title: On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs
---

# On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00353v1</a>
  <a href="https://arxiv.org/pdf/2312.00353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00353v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00353v1', 'On Exploring the Reasoning Capability of Large Language Models with Knowledge Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pei-Chi Lo, Yi-Hang Tsai, Ee-Peng Lim, San-Yih Hwang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

**å¤‡æ³¨**: Presented at the Generative-IR Workshop during SIGIR 2023. https://coda.io/@sigir/gen-ir

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸çŸ¥è¯†å›¾è°±çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `æ¨ç†èƒ½åŠ›` `å†…å®¹å¹»è§‰` `æœ¬ä½“å¹»è§‰` `ä¿¡æ¯æ£€ç´¢` `æ™ºèƒ½é—®ç­”`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†å›¾è°±æ¨ç†ä¸­é¢ä¸´å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡æ¨æ–­èƒ½åŠ›çš„æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è®¾è®¡å››ç§çŸ¥è¯†å›¾è°±æ¨ç†ä»»åŠ¡ï¼Œè¯„ä¼°LLMsçš„æ¨ç†èƒ½åŠ›åŠå…¶å†…éƒ¨çŸ¥è¯†å›¾è°±çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå›å¿†å’Œæ¨æ–­çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åˆ©ç”¨å…¶å†…éƒ¨çŸ¥è¯†å›¾è°±è¿›è¡Œæ¨ç†çš„èƒ½åŠ›ï¼Œå³åœ¨é¢„è®­ç»ƒè¿‡ç¨‹ä¸­å­¦ä¹ åˆ°çš„çŸ¥è¯†å›¾è°±ã€‚é€šè¿‡æå‡ºä¸¤ä¸ªç ”ç©¶é—®é¢˜ï¼Œæ¢è®¨LLMsåœ¨å›å¿†é¢„è®­ç»ƒçŸ¥è¯†å›¾è°±ä¿¡æ¯çš„å‡†ç¡®æ€§åŠå…¶ä»ä¸Šä¸‹æ–‡æ¨æ–­çŸ¥è¯†å›¾è°±å…³ç³»çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œé‡‡ç”¨LLMsæ‰§è¡Œå››ç§ä¸åŒçš„çŸ¥è¯†å›¾è°±æ¨ç†ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯†åˆ«å‡ºåœ¨çŸ¥è¯†æ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„ä¸¤ç§å¹»è§‰ï¼šå†…å®¹å¹»è§‰å’Œæœ¬ä½“å¹»è§‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsèƒ½å¤ŸæˆåŠŸå¤„ç†æ¥è‡ªè‡ªèº«è®°å¿†çš„ç®€å•å’Œå¤æ‚çŸ¥è¯†å›¾è°±æ¨ç†ä»»åŠ¡ï¼Œå¹¶èƒ½å¤Ÿä»è¾“å…¥ä¸Šä¸‹æ–‡ä¸­è¿›è¡Œæ¨æ–­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å›¾è°±æ¨ç†ä¸­çš„å‡†ç¡®æ€§å’Œä¸Šä¸‹æ–‡æ¨æ–­èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨LLMsçš„å†…éƒ¨çŸ¥è¯†å›¾è°±è¿›è¡Œæœ‰æ•ˆæ¨ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡å››ç§ä¸åŒçš„çŸ¥è¯†å›¾è°±æ¨ç†ä»»åŠ¡ï¼Œè¯„ä¼°LLMsåœ¨å›å¿†å’Œæ¨æ–­çŸ¥è¯†å›¾è°±ä¿¡æ¯æ—¶çš„è¡¨ç°ï¼Œæ—¨åœ¨æ­ç¤ºå…¶æ¨ç†èƒ½åŠ›çš„æ½œåŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ä»»åŠ¡è®¾è®¡ã€æ¨¡å‹æ¨ç†å’Œç»“æœè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå‡†å¤‡çŸ¥è¯†å›¾è°±æ•°æ®ï¼Œç„¶åè®¾è®¡æ¨ç†ä»»åŠ¡ï¼Œæ¥ç€ä½¿ç”¨LLMsè¿›è¡Œæ¨ç†ï¼Œæœ€åè¯„ä¼°å…¶æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯†åˆ«å‡ºåœ¨çŸ¥è¯†æ¨ç†è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„å†…å®¹å¹»è§‰å’Œæœ¬ä½“å¹»è§‰ï¼Œæ­ç¤ºäº†LLMsæ¨ç†èƒ½åŠ›çš„å±€é™æ€§ä¸æ½œåœ¨é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡æä¾›äº†æ›´å…¨é¢çš„æ¨ç†èƒ½åŠ›è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§å‚æ•°ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡æ¨ç†çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ï¼Œç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚å®éªŒè®¾è®¡ä¸­è¿˜è€ƒè™‘äº†ä¸Šä¸‹æ–‡ä¿¡æ¯çš„å½±å“ï¼Œä»¥æé«˜æ¨ç†çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨çŸ¥è¯†å›¾è°±æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤ŸæˆåŠŸå¤„ç†ç®€å•å’Œå¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å›å¿†ä¿¡æ¯çš„å‡†ç¡®æ€§ä¸Šè¾¾åˆ°äº†XX%çš„æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨æ–­èƒ½åŠ›æ˜¾è‘—å¢å¼ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†ç®¡ç†å’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æå‡LLMsåœ¨çŸ¥è¯†å›¾è°±æ¨ç†ä¸­çš„èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper examines the capacity of LLMs to reason with knowledge graphs using their internal knowledge graph, i.e., the knowledge graph they learned during pre-training. Two research questions are formulated to investigate the accuracy of LLMs in recalling information from pre-training knowledge graphs and their ability to infer knowledge graph relations from context. To address these questions, we employ LLMs to perform four distinct knowledge graph reasoning tasks. Furthermore, we identify two types of hallucinations that may occur during knowledge reasoning with LLMs: content and ontology hallucination. Our experimental results demonstrate that LLMs can successfully tackle both simple and complex knowledge graph reasoning tasks from their own memory, as well as infer from input context.

