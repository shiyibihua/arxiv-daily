---
layout: default
title: The Cost of Thinking: Increased Jailbreak Risk in Large Language Models
---

# The Cost of Thinking: Increased Jailbreak Risk in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10032" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10032v1</a>
  <a href="https://arxiv.org/pdf/2508.10032.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10032v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10032v1', 'The Cost of Thinking: Increased Jailbreak Risk in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fan Yang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®‰å…¨æ€ç»´å¹²é¢„ä»¥é™ä½å¤§å‹è¯­è¨€æ¨¡å‹çš„è¶Šç‹±é£é™©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¶Šç‹±æ”»å‡»` `å®‰å…¨æ€§` `æ€ç»´æ¨¡å¼` `å¹²é¢„æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsåœ¨æ€ç»´æ¨¡å¼ä¸‹æ›´å®¹æ˜“å—åˆ°è¶Šç‹±æ”»å‡»ï¼Œå¯¼è‡´å®‰å…¨æ€§é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡æ·»åŠ ç‰¹å®šæ€ç»´æ ‡è®°æ¥å¼•å¯¼LLMsçš„æ€ç»´è¿‡ç¨‹ï¼Œä»è€Œå¢å¼ºå…¶å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå®‰å…¨æ€ç»´å¹²é¢„æ˜¾è‘—é™ä½äº†æ€ç»´æ¨¡å¼ä¸‹LLMsçš„æ”»å‡»æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ€ç»´æ¨¡å¼ä¸€ç›´è¢«è®¤ä¸ºæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æœ€æœ‰ä»·å€¼çš„æ¨¡å¼ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°ä¸€ä¸ªä»¤äººæƒŠè®¶ä¸”ä¹‹å‰æœªè¢«é‡è§†çš„ç°è±¡ï¼šå…·æœ‰æ€ç»´æ¨¡å¼çš„LLMsæ›´å®¹æ˜“å—åˆ°è¶Šç‹±æ”»å‡»ã€‚é€šè¿‡å¯¹9ä¸ªLLMsåœ¨AdvBenchå’ŒHarmBenchä¸Šçš„è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°æ€ç»´æ¨¡å¼çš„æ”»å‡»æˆåŠŸç‡å‡ ä¹é«˜äºéæ€ç»´æ¨¡å¼ã€‚å¤§é‡æ ·æœ¬ç ”ç©¶è¡¨æ˜ï¼Œæ•™è‚²ç›®çš„å’Œè¿‡é•¿çš„æ€ç»´é•¿åº¦æ˜¯æˆåŠŸæ”»å‡»æ•°æ®çš„ç‰¹å¾ï¼ŒLLMsåœ¨çŸ¥é“é—®é¢˜æœ‰å®³æ—¶ä»ä¼šç»™å‡ºæœ‰å®³ç­”æ¡ˆã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å®‰å…¨æ€ç»´å¹²é¢„æ–¹æ³•ï¼Œé€šè¿‡åœ¨æç¤ºä¸­æ·»åŠ â€œç‰¹å®šæ€ç»´æ ‡è®°â€æ¥æ˜ç¡®å¼•å¯¼LLMsçš„å†…éƒ¨æ€ç»´è¿‡ç¨‹ã€‚ç»“æœè¡¨æ˜ï¼Œå®‰å…¨æ€ç»´å¹²é¢„èƒ½å¤Ÿæ˜¾è‘—é™ä½å…·æœ‰æ€ç»´æ¨¡å¼çš„LLMsçš„æ”»å‡»æˆåŠŸç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€ç»´æ¨¡å¼ä¸‹æ˜“å—è¶Šç‹±æ”»å‡»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé˜²èŒƒæ­¤ç±»æ”»å‡»ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºæœ‰å®³å†…å®¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å®‰å…¨æ€ç»´å¹²é¢„æ–¹æ³•é€šè¿‡åœ¨æç¤ºä¸­åŠ å…¥ç‰¹å®šçš„æ€ç»´æ ‡è®°ï¼Œæ¥å¼•å¯¼æ¨¡å‹çš„å†…éƒ¨æ€ç»´è¿‡ç¨‹ï¼Œä»è€Œé™ä½å…¶è¢«æ”»å‡»çš„é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ€ç»´æ ‡è®°çš„ç”Ÿæˆä¸æ’å…¥ã€æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°ç­‰ä¸»è¦æ¨¡å—ã€‚é€šè¿‡è¿™äº›æ¨¡å—çš„ååŒå·¥ä½œï¼Œç¡®ä¿æ¨¡å‹åœ¨æ€ç»´æ¨¡å¼ä¸‹çš„å®‰å…¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥â€œç‰¹å®šæ€ç»´æ ‡è®°â€ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¹²é¢„æ¨¡å‹çš„æ€ç»´è¿‡ç¨‹ï¼Œæå‡å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œç‰¹å®šæ€ç»´æ ‡è®°çš„é€‰æ‹©ä¸æ’å…¥ä½ç½®è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†æ¨¡å‹è¾“å‡ºçš„å®‰å…¨æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨å®‰å…¨æ€ç»´å¹²é¢„åï¼Œå…·æœ‰æ€ç»´æ¨¡å¼çš„LLMsçš„æ”»å‡»æˆåŠŸç‡æ˜¾è‘—é™ä½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œä¸”åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿé˜²æŠ¤æªæ–½ã€‚è¿™ä¸€æˆæœä¸ºLLMsçš„å®‰å…¨æ€§æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€åŒ»ç–—å’Œé‡‘èç­‰å¯¹å®‰å…¨æ€§è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ã€‚é€šè¿‡å¢å¼ºLLMsçš„å®‰å…¨æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢æ¨¡å‹è¾“å‡ºæœ‰å®³ä¿¡æ¯ï¼Œä»è€Œæå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨æ›´å®‰å…¨çš„AIç³»ç»Ÿçš„å‘å±•ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„å®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Thinking mode has always been regarded as one of the most valuable modes in LLMs. However, we uncover a surprising and previously overlooked phenomenon: LLMs with thinking mode are more easily broken by Jailbreak attack. We evaluate 9 LLMs on AdvBench and HarmBench and find that the success rate of attacking thinking mode in LLMs is almost higher than that of non-thinking mode. Through large numbers of sample studies, it is found that for educational purposes and excessively long thinking lengths are the characteristics of successfully attacked data, and LLMs also give harmful answers when they mostly know that the questions are harmful. In order to alleviate the above problems, this paper proposes a method of safe thinking intervention for LLMs, which explicitly guides the internal thinking processes of LLMs by adding "specific thinking tokens" of LLMs to the prompt. The results demonstrate that the safe thinking intervention can significantly reduce the attack success rate of LLMs with thinking mode.

