---
layout: default
title: Many-Turn Jailbreaking
---

# Many-Turn Jailbreaking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.06755" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.06755v1</a>
  <a href="https://arxiv.org/pdf/2508.06755.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.06755v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.06755v1', 'Many-Turn Jailbreaking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xianjun Yang, Liqiang Xiao, Shiyang Li, Faisal Ladhak, Hyokun Yun, Linda Ruth Petzold, Yi Xu, William Yang Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šè½®è¶Šç‹±åŸºå‡†ä»¥åº”å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨å¨èƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè½®å¯¹è¯` `è¶Šç‹±æ”»å‡»` `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§è¯„ä¼°` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¶Šç‹±ç ”ç©¶ä»…å…³æ³¨å•è½®å¯¹è¯ï¼Œæœªèƒ½è€ƒè™‘ç”¨æˆ·å¯èƒ½çš„åç»­æé—®ï¼Œå¯¼è‡´å®‰å…¨éšæ‚£æœªè¢«å……åˆ†æ­ç¤ºã€‚
2. æœ¬æ–‡æå‡ºå¤šè½®è¶Šç‹±çš„æ¦‚å¿µï¼Œæ„å»ºäº†å¤šè½®è¶Šç‹±åŸºå‡†ï¼ˆMTJ-Benchï¼‰ï¼Œä»¥è¯„ä¼°LLMsåœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°ã€‚
3. é€šè¿‡å¯¹å¤šä¸ªå¼€æºå’Œé—­æºæ¨¡å‹çš„æµ‹è¯•ï¼Œæ­ç¤ºäº†LLMsåœ¨å¤šè½®å¯¹è¯ä¸­å­˜åœ¨çš„å®‰å…¨æ¼æ´ï¼Œå‘¼ååŠ å¼ºå®‰å…¨æ€§ç ”ç©¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¶Šç‹±ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•è½®å¯¹è¯ä¸­å¼•å‘ä¸å®‰å…¨è¾“å‡ºã€‚ç„¶è€Œï¼Œå…ˆè¿›çš„LLMsèƒ½å¤Ÿå¤„ç†æé•¿çš„ä¸Šä¸‹æ–‡å¹¶è¿›è¡Œå¤šè½®å¯¹è¯ã€‚å› æ­¤ï¼Œæœ¬æ–‡æå‡ºäº†å¤šè½®è¶Šç‹±çš„æ¦‚å¿µï¼Œå¼ºè°ƒåœ¨å¤šè½®å¯¹è¯ä¸­æµ‹è¯•è¶Šç‹±æ¨¡å‹çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤šè½®è¶Šç‹±åŸºå‡†ï¼ˆMTJ-Benchï¼‰ï¼Œç”¨äºè¯„ä¼°è¿™ä¸€æ–°è®¾å®šï¼Œå¹¶æ­ç¤ºäº†è¿™ä¸€å®‰å…¨å¨èƒçš„æ–°è„†å¼±æ€§ã€‚é€šè¿‡è¿™ä¸€ç ”ç©¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä¿ƒä½¿ç¤¾åŒºå…±åŒåŠªåŠ›ï¼Œæ„å»ºæ›´å®‰å…¨çš„LLMsï¼Œå¹¶æ·±å…¥ç†è§£LLMsçš„è¶Šç‹±æœºåˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰è¶Šç‹±ç ”ç©¶ä»…é™äºå•è½®å¯¹è¯çš„é—®é¢˜ï¼Œå¼ºè°ƒå¤šè½®å¯¹è¯ä¸­å¯èƒ½å‡ºç°çš„å®‰å…¨æ¼æ´ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½è€ƒè™‘ç”¨æˆ·çš„åç»­æé—®ï¼Œå¯¼è‡´æ½œåœ¨é£é™©æœªè¢«å……åˆ†è¯†åˆ«ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¤šè½®è¶Šç‹±çš„æ¦‚å¿µï¼Œå¼ºè°ƒåœ¨å¤šè½®å¯¹è¯ä¸­æµ‹è¯•è¶Šç‹±æ¨¡å‹çš„é‡è¦æ€§ã€‚é€šè¿‡æ„å»ºå¤šè½®è¶Šç‹±åŸºå‡†ï¼ˆMTJ-Benchï¼‰ï¼Œä¸ºè¯„ä¼°LLMsåœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°æä¾›äº†æ ‡å‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹æµ‹è¯•å’Œç»“æœåˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å¤šè½®å¯¹è¯æ•°æ®ï¼Œç„¶åå¯¹å¤šç§LLMsè¿›è¡Œè¶Šç‹±æµ‹è¯•ï¼Œæœ€ååˆ†ææ¨¡å‹åœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°å’Œå®‰å…¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡æå‡ºå¤šè½®è¶Šç‹±çš„æ¦‚å¿µï¼Œå¹¶æ„å»ºç›¸åº”çš„åŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚ä¸ä¼ ç»Ÿçš„å•è½®è¶Šç‹±æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ–¹æ³•æ›´å…¨é¢åœ°è¯„ä¼°äº†æ¨¡å‹çš„å®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŸºå‡†æ„å»ºä¸­ï¼Œè®¾ç½®äº†å¤šç§å¯¹è¯åœºæ™¯å’Œé—®é¢˜ç±»å‹ï¼Œç¡®ä¿æµ‹è¯•çš„å…¨é¢æ€§å’Œæœ‰æ•ˆæ€§ã€‚é‡‡ç”¨äº†å¤šæ ·åŒ–çš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä»¥éªŒè¯ä¸åŒæ¨¡å‹åœ¨å¤šè½®å¯¹è¯ä¸­çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šè½®å¯¹è¯ä¸­ï¼Œè¶Šç‹±æ¨¡å‹çš„å®‰å…¨æ€§æ˜¾è‘—ä¸‹é™ï¼Œéƒ¨åˆ†æ¨¡å‹åœ¨åç»­æé—®ä¸­ä»ç„¶äº§ç”Ÿä¸å®‰å…¨è¾“å‡ºã€‚é€šè¿‡ä¸åŸºçº¿æ¨¡å‹çš„å¯¹æ¯”ï¼Œå‘ç°å¤šè½®è¶Šç‹±çš„å½±å“æ›´ä¸ºä¸¥é‡ï¼Œå‘¼åå¯¹LLMsçš„å®‰å…¨æ€§è¿›è¡Œæ›´æ·±å…¥çš„ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°ã€å¯¹è¯ç³»ç»Ÿçš„è®¾è®¡ä¸ä¼˜åŒ–ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£å¤šè½®è¶Šç‹±çš„æœºåˆ¶ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´å®‰å…¨çš„å¯¹è¯ç³»ç»Ÿæä¾›ç†è®ºæ”¯æŒï¼Œå‡å°‘æ¨¡å‹è¢«æ»¥ç”¨çš„é£é™©ï¼Œæå‡ç”¨æˆ·ä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current jailbreaking work on large language models (LLMs) aims to elicit unsafe outputs from given prompts. However, it only focuses on single-turn jailbreaking targeting one specific query. On the contrary, the advanced LLMs are designed to handle extremely long contexts and can thus conduct multi-turn conversations. So, we propose exploring multi-turn jailbreaking, in which the jailbroken LLMs are continuously tested on more than the first-turn conversation or a single target query. This is an even more serious threat because 1) it is common for users to continue asking relevant follow-up questions to clarify certain jailbroken details, and 2) it is also possible that the initial round of jailbreaking causes the LLMs to respond to additional irrelevant questions consistently. As the first step (First draft done at June 2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and closed-source models and provide novel insights into this new safety threat. By revealing this new vulnerability, we aim to call for community efforts to build safer LLMs and pave the way for a more in-depth understanding of jailbreaking LLMs.

