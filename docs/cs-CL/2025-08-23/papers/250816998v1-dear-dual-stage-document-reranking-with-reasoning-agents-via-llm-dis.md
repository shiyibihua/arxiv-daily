---
layout: default
title: DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation
---

# DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16998" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16998v1</a>
  <a href="https://arxiv.org/pdf/2508.16998.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16998v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16998v1', 'DeAR: Dual-Stage Document Reranking with Reasoning Agents via LLM Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdelrahman Abdallah, Jamshid Mozafari, Bhawna Piryani, Adam Jatowt

**åˆ†ç±»**: cs.CL, cs.IR

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23

**å¤‡æ³¨**: Accept at EMNLP Findings 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/DataScienceUIBK/DeAR-Reranking)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDeARä»¥è§£å†³æ–‡æ¡£é‡æ’åºä¸­çš„æ¨ç†ä¸è¯„åˆ†å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æ¡£é‡æ’åº` `æ¨ç†æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡æ¡£é‡æ’åºæ–¹æ³•åœ¨ç»†ç²’åº¦ç›¸å…³æ€§è¯„åˆ†ä¸æ•´ä½“åˆ†æä¹‹é—´éš¾ä»¥å–å¾—å¹³è¡¡ï¼Œå½±å“äº†é‡æ’åºçš„å‡†ç¡®æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„DeARæ¡†æ¶é€šè¿‡åŒé˜¶æ®µæ–¹æ³•ï¼Œåˆ†åˆ«å¤„ç†ä»¤ç‰Œçº§ç›¸å…³æ€§å’Œåˆ—è¡¨æ¨ç†ï¼Œæå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒDeARåœ¨nDCG@5å’ŒnDCG@10ç­‰æŒ‡æ ‡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„å¼€æºåŸºçº¿ï¼Œå±•ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡å¯¹å€™é€‰é›†è¿›è¡Œå…¨å±€æ¨ç†ï¼Œæ”¹å˜äº†åˆ—è¡¨æ–‡æ¡£é‡æ’åºçš„æ–¹å¼ã€‚ç„¶è€Œï¼Œå•ä¸€æ¨¡å‹å¾€å¾€éš¾ä»¥åœ¨ç»†ç²’åº¦ç›¸å…³æ€§è¯„åˆ†å’Œæ•´ä½“è·¨æ–‡æ¡£åˆ†æä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†DeARï¼ˆæ·±åº¦ä»£ç†æ’åï¼‰ï¼Œä¸€ä¸ªå¼€æºæ¡†æ¶ï¼Œé‡‡ç”¨åŒé˜¶æ®µæ–¹æ³•è§£è€¦è¿™ä¸¤é¡¹ä»»åŠ¡ï¼Œä»è€Œå®ç°æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæˆ‘ä»¬ä»ä¸€ä¸ªå†»ç»“çš„13B LLaMAæ•™å¸ˆæ¨¡å‹ä¸­æç‚¼å‡ºä»¤ç‰Œçº§ç›¸å…³æ€§ä¿¡å·ï¼Œç”Ÿæˆä¸€ä¸ªç´§å‡‘çš„3Bæˆ–8Bå­¦ç”Ÿæ¨¡å‹ï¼Œç¡®ä¿ç¨³å¥çš„é€ç‚¹è¯„åˆ†ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬é™„åŠ äº†ç¬¬äºŒä¸ªLoRAé€‚é…å™¨ï¼Œå¹¶åœ¨20Kä¸ªGPT-4oç”Ÿæˆçš„æ€ç»´é“¾æ’åˆ—ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä½¿å¾—èƒ½å¤Ÿè¿›è¡Œå¸¦è‡ªç„¶è¯­è¨€è§£é‡Šçš„åˆ—è¡¨æ¨ç†ã€‚ç»è¿‡åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°ï¼ŒDeARåœ¨å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†å¼€æºåŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æ¡£é‡æ’åºä¸­ï¼Œç°æœ‰æ–¹æ³•åœ¨ç»†ç²’åº¦ç›¸å…³æ€§è¯„åˆ†ä¸æ•´ä½“è·¨æ–‡æ¡£åˆ†æä¹‹é—´çš„å¹³è¡¡é—®é¢˜ã€‚å•ä¸€æ¨¡å‹å¾€å¾€æ— æ³•åŒæ—¶å…¼é¡¾è¿™ä¸¤æ–¹é¢ï¼Œå¯¼è‡´é‡æ’åºæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDeARæ¡†æ¶é‡‡ç”¨åŒé˜¶æ®µæ–¹æ³•ï¼Œç¬¬ä¸€é˜¶æ®µæå–ä»¤ç‰Œçº§ç›¸å…³æ€§ä¿¡å·ï¼Œç¬¬äºŒé˜¶æ®µè¿›è¡Œåˆ—è¡¨æ¨ç†ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒé«˜å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæä¾›å¯è§£é‡Šçš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDeARçš„æ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨ä¸€ä¸ªå†»ç»“çš„13B LLaMAæ•™å¸ˆæ¨¡å‹è¿›è¡ŒçŸ¥è¯†è’¸é¦ï¼Œç”Ÿæˆä¸€ä¸ªç´§å‡‘çš„å­¦ç”Ÿæ¨¡å‹ï¼›ç¬¬äºŒé˜¶æ®µåˆ™åœ¨æ­¤åŸºç¡€ä¸Šï¼Œé™„åŠ LoRAé€‚é…å™¨ï¼Œå¹¶åœ¨ç”Ÿæˆçš„æ€ç»´é“¾ä¸Šè¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šDeARçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶åŒé˜¶æ®µçš„è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåˆ†åˆ«ä¼˜åŒ–ç»†ç²’åº¦è¯„åˆ†å’Œæ•´ä½“æ¨ç†ï¼Œæ˜¾è‘—æå‡äº†é‡æ’åºçš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé‡‡ç”¨äº¤å‰ç†µã€RankNetå’ŒKLæ•£åº¦æŸå¤±çš„æ··åˆæŸå¤±å‡½æ•°è¿›è¡Œè’¸é¦ï¼›åœ¨ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨20Kä¸ªGPT-4oç”Ÿæˆçš„æ€ç»´é“¾è¿›è¡Œå¾®è°ƒï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„åˆ—è¡¨æ¨ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨TREC-DL19/20å’ŒNovelEval-2306ç­‰å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒDeARåœ¨nDCG@5ä¸Šè¶…è¶Šå¼€æºåŸºçº¿5.1ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶åœ¨NovelEvalä¸Šè¾¾åˆ°90.97çš„nDCG@10ï¼Œè¶…è¶ŠGPT-4 3.09ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼ŒDeARåœ¨å¼€æ”¾åŸŸé—®ç­”ä¸­è¡¨ç°å‡ºè‰²ï¼ŒNatural Questionsçš„Top-1å‡†ç¡®ç‡è¾¾åˆ°54.29ï¼Œä¼˜äºMonoT5ã€UPRå’ŒRankGPTç­‰åŸºçº¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DeARæ¡†æ¶åœ¨æ–‡æ¡£é‡æ’åºé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨ä¿¡æ¯æ£€ç´¢ã€é—®ç­”ç³»ç»Ÿå’Œæ¨èç³»ç»Ÿç­‰åœºæ™¯ä¸­ã€‚å…¶é«˜å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼ŒDeARè¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤æ‚æ¨ç†çš„ä»»åŠ¡ä¸­ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have transformed listwise document reranking by enabling global reasoning over candidate sets, yet single models often struggle to balance fine-grained relevance scoring with holistic cross-document analysis. We propose \textbf{De}ep\textbf{A}gent\textbf{R}ank (\textbf{\DeAR}), an open-source framework that decouples these tasks through a dual-stage approach, achieving superior accuracy and interpretability. In \emph{Stage 1}, we distill token-level relevance signals from a frozen 13B LLaMA teacher into a compact \{3, 8\}B student model using a hybrid of cross-entropy, RankNet, and KL divergence losses, ensuring robust pointwise scoring. In \emph{Stage 2}, we attach a second LoRA adapter and fine-tune on 20K GPT-4o-generated chain-of-thought permutations, enabling listwise reasoning with natural-language justifications. Evaluated on TREC-DL19/20, eight BEIR datasets, and NovelEval-2306, \DeAR surpasses open-source baselines by +5.1 nDCG@5 on DL20 and achieves 90.97 nDCG@10 on NovelEval, outperforming GPT-4 by +3.09. Without fine-tuning on Wikipedia, DeAR also excels in open-domain QA, achieving 54.29 Top-1 accuracy on Natural Questions, surpassing baselines like MonoT5, UPR, and RankGPT. Ablations confirm that dual-loss distillation ensures stable calibration, making \DeAR a highly effective and interpretable solution for modern reranking systems.\footnote{Dataset and code available at https://github.com/DataScienceUIBK/DeAR-Reranking.}.

