---
layout: default
title: Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment
---

# Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16910" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16910v1</a>
  <a href="https://arxiv.org/pdf/2508.16910.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16910v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16910v1', 'Unbiased Reasoning for Knowledge-Intensive Tasks in Large Language Models via Conditional Front-Door Adjustment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bo Zhao, Yinghao Zhang, Ziqi Xu, Yongli Ren, Xiuzhen Zhang, Renqiang Luo, Zaiwen Feng, Feng Xia

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23

**å¤‡æ³¨**: This paper has been accepted to the 34th ACM International Conference on Information and Knowledge Management (CIKM 2025), Full Research Paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡ä»¶å‰é—¨è°ƒæ•´æ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å› æœæ¨ç†` `çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡` `æ¡ä»¶å‰é—¨è°ƒæ•´` `åäº‹å®çŸ¥è¯†` `æ¨ç†èƒ½åŠ›` `é²æ£’æ€§` `å¤–éƒ¨çŸ¥è¯†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­å­˜åœ¨å†…éƒ¨åè§ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡ä»¶å‰é—¨æç¤ºæ¡†æ¶é€šè¿‡æ„å»ºåäº‹å®å¤–éƒ¨çŸ¥è¯†ï¼Œæ¨¡æ‹ŸæŸ¥è¯¢åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¡Œä¸ºï¼Œä»è€Œå‡è½»å†…éƒ¨åè§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCFD-Promptingåœ¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹å’ŒåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ–¹é¢å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨éœ€è¦æ·±åº¦æ¨ç†å’Œæ•´åˆå¤–éƒ¨çŸ¥è¯†çš„çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­ä»ç„¶å­˜åœ¨ä¸è¶³ã€‚å°½ç®¡å·²æœ‰æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å’Œæ€ç»´é“¾ï¼ˆCoTï¼‰ç­‰æ–¹æ³•æ¥æå‡LLMsçš„å¤–éƒ¨çŸ¥è¯†èƒ½åŠ›ï¼Œä½†å†…éƒ¨åè§é—®é¢˜ä¾ç„¶å¯¼è‡´é”™è¯¯ç­”æ¡ˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å› æœæç¤ºæ¡†æ¶â€”â€”æ¡ä»¶å‰é—¨æç¤ºï¼ˆCFD-Promptingï¼‰ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨å¤–éƒ¨çŸ¥è¯†çš„æ¡ä»¶ä¸‹æ— åä¼°è®¡æŸ¥è¯¢ä¸ç­”æ¡ˆä¹‹é—´çš„å› æœæ•ˆåº”ï¼ŒåŒæ—¶å‡è½»å†…éƒ¨åè§ã€‚é€šè¿‡æ„å»ºåäº‹å®å¤–éƒ¨çŸ¥è¯†ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ¨¡æ‹Ÿäº†åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­æŸ¥è¯¢çš„è¡Œä¸ºï¼Œè§£å†³äº†å›ºå®šæŸ¥è¯¢æ— æ³•ç›´æ¥è¿›è¡Œå› æœå¹²é¢„çš„æŒ‘æˆ˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCFD-Promptingåœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­å› å†…éƒ¨åè§å¯¼è‡´çš„æ¨ç†é”™è¯¯é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚RAGå’ŒCoTè™½ç„¶å¼•å…¥äº†å¤–éƒ¨çŸ¥è¯†ï¼Œä½†ä»æœªèƒ½æœ‰æ•ˆæ¶ˆé™¤å†…éƒ¨åè§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¡ä»¶å‰é—¨æç¤ºæ¡†æ¶ï¼ˆCFD-Promptingï¼‰é€šè¿‡æ„å»ºåäº‹å®å¤–éƒ¨çŸ¥è¯†ï¼Œæ¨¡æ‹ŸæŸ¥è¯¢åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¡¨ç°ï¼Œä»è€Œå®ç°æ— åçš„å› æœæ•ˆåº”ä¼°è®¡ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸ç›´æ¥å¹²é¢„æŸ¥è¯¢çš„æƒ…å†µä¸‹ï¼Œè·å¾—æ›´å‡†ç¡®çš„æ¨ç†ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCFD-Promptingçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1ï¼‰æŸ¥è¯¢å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£æ¥æ”¶å’Œè§£æè¾“å…¥æŸ¥è¯¢ï¼›2ï¼‰åäº‹å®çŸ¥è¯†æ„å»ºæ¨¡å—ï¼Œç”Ÿæˆä¸åŒä¸Šä¸‹æ–‡ä¸‹çš„å¤–éƒ¨çŸ¥è¯†ï¼›3ï¼‰å› æœæ¨ç†æ¨¡å—ï¼ŒåŸºäºæ¡ä»¶å‰é—¨è°ƒæ•´è¿›è¡Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šCFD-Promptingçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ¡ä»¶å˜ä½“çš„è®¾è®¡ï¼Œç›¸è¾ƒäºæ ‡å‡†å‰é—¨è°ƒæ•´ï¼Œæ¡ä»¶å˜ä½“åœ¨æ›´å¼±çš„å‡è®¾ä¸‹è¿è¡Œï¼Œä»è€Œå¢å¼ºäº†æ¨ç†è¿‡ç¨‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å› æœæ¨ç†çš„å‡†ç¡®æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ç¨³å®šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCFD-Promptingåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šï¼ŒåŒæ—¶åœ¨é²æ£’æ€§æµ‹è¯•ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„ç¨³å®šæ€§ï¼Œè¶…è¶Šäº†ç°æœ‰çš„å¤šç§åŸºçº¿æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œå¤æ‚å†³ç­–æ”¯æŒç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ï¼ŒCFD-Promptingæœ‰æœ›åœ¨æ•™è‚²ã€åŒ»ç–—å’Œé‡‘èç­‰å¤šä¸ªè¡Œä¸šä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown impressive capabilities in natural language processing but still struggle to perform well on knowledge-intensive tasks that require deep reasoning and the integration of external knowledge. Although methods such as Retrieval-Augmented Generation (RAG) and Chain-of-Thought (CoT) have been proposed to enhance LLMs with external knowledge, they still suffer from internal bias in LLMs, which often leads to incorrect answers. In this paper, we propose a novel causal prompting framework, Conditional Front-Door Prompting (CFD-Prompting), which enables the unbiased estimation of the causal effect between the query and the answer, conditional on external knowledge, while mitigating internal bias. By constructing counterfactual external knowledge, our framework simulates how the query behaves under varying contexts, addressing the challenge that the query is fixed and is not amenable to direct causal intervention. Compared to the standard front-door adjustment, the conditional variant operates under weaker assumptions, enhancing both robustness and generalisability of the reasoning process. Extensive experiments across multiple LLMs and benchmark datasets demonstrate that CFD-Prompting significantly outperforms existing baselines in both accuracy and robustness.

