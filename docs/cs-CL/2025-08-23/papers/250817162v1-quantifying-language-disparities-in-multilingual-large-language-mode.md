---
layout: default
title: Quantifying Language Disparities in Multilingual Large Language Models
---

# Quantifying Language Disparities in Multilingual Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17162" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17162v1</a>
  <a href="https://arxiv.org/pdf/2508.17162.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17162v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17162v1', 'Quantifying Language Disparities in Multilingual Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Songbo Hu, Ivan VuliÄ‡, Anna Korhonen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23

**å¤‡æ³¨**: Accepted at EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¡†æ¶ä»¥é‡åŒ–å¤šè¯­è¨€å¤§æ¨¡å‹ä¸­çš„è¯­è¨€å·®å¼‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šè¯­è¨€æ¨¡å‹` `æ€§èƒ½è¯„ä¼°` `è¯­è¨€å·®å¼‚` `ä½èµ„æºè¯­è¨€` `å¯è§£é‡ŠæŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šè¯­è¨€æ¨¡å‹è¯„ä¼°ç»“æœå¸¸å› å¤šç§å› ç´ è€Œæ··æ·†ï¼Œéš¾ä»¥å‡†ç¡®é‡åŒ–è¯­è¨€é—´çš„æ€§èƒ½å·®å¼‚ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡å¼•å…¥ä¸‰ç§æ–°æŒ‡æ ‡ï¼Œæœ‰æ•ˆè§£è€¦æ··æ·†å˜é‡ï¼Œæä¾›æ›´æ¸…æ™°çš„æ€§èƒ½è¯„ä¼°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ä½èµ„æºè¯­è¨€çš„è¯„ä¼°ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œæ­ç¤ºäº†æ¨¡å‹æ€§èƒ½ä¸è¯­è¨€å…¬å¹³æ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è§„æ¨¡å¤šè¯­è¨€è¯„ä¼°ä¸­ï¼Œç»“æœå¸¸å¸¸å› ç›®æ ‡è¯­è¨€ã€å®éªŒè®¾ç½®å’Œæ¨¡å‹é€‰æ‹©ç­‰å› ç´ è€Œå˜å¾—ç¢ç‰‡åŒ–å’Œæ··æ·†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œèƒ½å¤Ÿè§£å¼€è¿™äº›æ··æ·†å˜é‡ï¼Œå¹¶å¼•å…¥ä¸‰ç§å¯è§£é‡Šçš„æŒ‡æ ‡â€”â€”æ€§èƒ½å®ç°æ¯”ã€å…¶å˜å¼‚ç³»æ•°å’Œè¯­è¨€æ½œåŠ›ï¼Œä»è€Œå®ç°å¯¹æ¨¡å‹å’Œè¯­è¨€é—´å®é™…æ€§èƒ½å·®å¼‚çš„æ›´ç»†è‡´å’Œæ·±å…¥çš„é‡åŒ–ã€‚é€šè¿‡å¯¹13ç§æ¨¡å‹å˜ä½“åœ¨11ä¸ªå¤šè¯­è¨€æ•°æ®é›†ä¸Šçš„æ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è¯¥æ¡†æ¶æä¾›äº†æ›´å¯é çš„æ¨¡å‹æ€§èƒ½å’Œè¯­è¨€å·®å¼‚æµ‹é‡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºä½èµ„æºè¯­è¨€çš„è¯„ä¼°ã€‚æ­¤å¤–ï¼Œç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹çš„æ•´ä½“æ€§èƒ½æå‡å¹¶ä¸ä¸€å®šæ„å‘³ç€è¯­è¨€é—´çš„å…¬å¹³æ€§å¢å¼ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šè¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­å› ç›®æ ‡è¯­è¨€å’Œå®éªŒè®¾ç½®ç­‰å› ç´ å¯¼è‡´çš„ç»“æœæ··æ·†é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä½èµ„æºè¯­è¨€çš„è¯„ä¼°ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œéš¾ä»¥æä¾›å¯é çš„æ€§èƒ½æ¯”è¾ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡å¼•å…¥æ€§èƒ½å®ç°æ¯”ã€å˜å¼‚ç³»æ•°å’Œè¯­è¨€æ½œåŠ›ç­‰æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè§£è€¦æ··æ·†å˜é‡ï¼Œä»è€Œå®ç°å¯¹æ¨¡å‹å’Œè¯­è¨€é—´æ€§èƒ½å·®å¼‚çš„æ›´ç»†è‡´é‡åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯æ•°æ®é¢„å¤„ç†ï¼Œç¡®ä¿ä¸åŒè¯­è¨€å’Œæ¨¡å‹çš„å¯æ¯”æ€§ï¼›å…¶æ¬¡æ˜¯æŒ‡æ ‡è®¡ç®—æ¨¡å—ï¼Œè®¡ç®—æ€§èƒ½å®ç°æ¯”ã€å˜å¼‚ç³»æ•°å’Œè¯­è¨€æ½œåŠ›ï¼›æœ€åæ˜¯ç»“æœåˆ†ææ¨¡å—ï¼Œæä¾›å¯è§†åŒ–å’Œæ·±å…¥åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ä¸‰ç§æ–°çš„å¯è§£é‡ŠæŒ‡æ ‡ï¼Œä½¿å¾—å¯¹å¤šè¯­è¨€æ¨¡å‹æ€§èƒ½çš„è¯„ä¼°æ›´åŠ å…¨é¢å’Œæ·±å…¥ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€æ€§èƒ½æŒ‡æ ‡è¯„ä¼°å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŒ‡æ ‡è®¡ç®—ä¸­ï¼Œæ€§èƒ½å®ç°æ¯”é€šè¿‡æ¨¡å‹åœ¨ç‰¹å®šè¯­è¨€ä¸Šçš„è¡¨ç°ä¸å…¶æ•´ä½“è¡¨ç°çš„æ¯”å€¼æ¥å®šä¹‰ï¼Œå˜å¼‚ç³»æ•°åˆ™ç”¨äºè¡¡é‡ä¸åŒè¯­è¨€é—´çš„æ€§èƒ½æ³¢åŠ¨ï¼Œè¯­è¨€æ½œåŠ›åˆ™è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šè¯­è¨€ä¸Šçš„æ½œåœ¨è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ¡†æ¶è¯„ä¼°çš„13ç§æ¨¡å‹å˜ä½“åœ¨11ä¸ªå¤šè¯­è¨€æ•°æ®é›†ä¸Šï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ æ¨¡å‹æ€§èƒ½ä¸è¯­è¨€é—´çš„å·®å¼‚ã€‚å°¤å…¶æ˜¯åœ¨ä½èµ„æºè¯­è¨€ä¸Šï¼Œæ¡†æ¶çš„åº”ç”¨æ˜¾è‘—æé«˜äº†è¯„ä¼°çš„å¯é æ€§ï¼Œæ­ç¤ºäº†æ¨¡å‹æ€§èƒ½ä¸è¯­è¨€å…¬å¹³æ€§ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ¡†æ¶å¯å¹¿æ³›åº”ç”¨äºå¤šè¯­è¨€è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æ€§èƒ½è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨ä½èµ„æºè¯­è¨€çš„ç ”ç©¶ä¸­å…·æœ‰é‡è¦ä»·å€¼ã€‚é€šè¿‡æä¾›æ›´å¯é çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–å¤šè¯­è¨€æ¨¡å‹çš„å…¬å¹³æ€§ä¸æ€§èƒ½ï¼Œæ¨åŠ¨å¤šè¯­è¨€æŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Results reported in large-scale multilingual evaluations are often fragmented and confounded by factors such as target languages, differences in experimental setups, and model choices. We propose a framework that disentangles these confounding variables and introduces three interpretable metrics--the performance realisation ratio, its coefficient of variation, and language potential--enabling a finer-grained and more insightful quantification of actual performance disparities across both (i) models and (ii) languages. Through a case study of 13 model variants on 11 multilingual datasets, we demonstrate that our framework provides a more reliable measurement of model performance and language disparities, particularly for low-resource languages, which have so far proven challenging to evaluate. Importantly, our results reveal that higher overall model performance does not necessarily imply greater fairness across languages.

