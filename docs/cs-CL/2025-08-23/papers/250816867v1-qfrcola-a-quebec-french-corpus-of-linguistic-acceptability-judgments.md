---
layout: default
title: QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments
---

# QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16867" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16867v1</a>
  <a href="https://arxiv.org/pdf/2508.16867.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16867v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16867v1', 'QFrCoLA: a Quebec-French Corpus of Linguistic Acceptability Judgments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: David Beauchemin, Richard Khoury

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23

**å¤‡æ³¨**: Accepted to EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQFrCoLAæ•°æ®é›†ä»¥è¯„ä¼°æ³•è¯­è¯­è¨€æ¨¡å‹çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `é­åŒ—å…‹æ³•è¯­` `å¯æ¥å—æ€§åˆ¤æ–­` `æ•°æ®é›†æ„å»º` `Transformeræ¨¡å‹` `è¯­è¨€è¯„ä¼°` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹åœ¨è¯­è¨€çŸ¥è¯†çš„å†…åŒ–æ–¹é¢ç†è§£æœ‰é™ï¼Œç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ ‡å‡†ã€‚
2. QFrCoLAæ•°æ®é›†æä¾›äº†ä¸€ä¸ªåŒ…å«é­åŒ—å…‹æ³•è¯­çš„å¯æ¥å—æ€§åˆ¤æ–­çš„äºŒå…ƒæ•°æ®é›†ï¼Œæ—¨åœ¨å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒçš„Transformeræ¨¡å‹åœ¨QFrCoLAåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œæ­ç¤ºäº†å…¶åœ¨è¯­è¨€åˆ¤æ–­èƒ½åŠ›ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹åŸºäºTransformerçš„è¯­è¨€æ¨¡å‹åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å¯¹å…¶è¯­è¨€çŸ¥è¯†çš„å†…åœ¨ç†è§£ä»æœ‰é™ã€‚æœ¬æ–‡ä»‹ç»äº†QFrCoLAï¼ˆé­åŒ—å…‹æ³•è¯­è¯­è¨€å¯æ¥å—æ€§åˆ¤æ–­è¯­æ–™åº“ï¼‰ï¼Œè¯¥æ•°æ®é›†åŒ…å«25,153ä¸ªé¢†åŸŸå†…å’Œ2,675ä¸ªé¢†åŸŸå¤–çš„å¥å­ã€‚é€šè¿‡QFrCoLAåŠå…¶ä»–ä¸ƒä¸ªè¯­è¨€å¯æ¥å—æ€§åˆ¤æ–­è¯­æ–™åº“ï¼Œæœ¬æ–‡å¯¹ä¸ƒç§è¯­è¨€æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚ç»“æœè¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„Transformerè¯­è¨€æ¨¡å‹åœ¨å¤§å¤šæ•°è¯­è¨€ä¸­è¡¨ç°è‰¯å¥½ï¼Œè€Œé›¶æ ·æœ¬åˆ†ç±»çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯¥ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚QFrCoLAåŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼Œå¾®è°ƒçš„Transformeræ¨¡å‹ä¼˜äºå…¶ä»–æ–¹æ³•ï¼Œä¸”é¢„è®­ç»ƒçš„è·¨è¯­è¨€æ¨¡å‹åœ¨é­åŒ—å…‹æ³•è¯­çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›ä¸Šè¡¨ç°æ¬ ä½³ã€‚è¯¥æ•°æ®é›†ä¸ºåŸºå‡†æµ‹è¯•è¯­è¨€æ¨¡å‹çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›æä¾›äº†æŒ‘æˆ˜æ€§æ•°æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­è¨€æ¨¡å‹åœ¨é­åŒ—å…‹æ³•è¯­çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›è¯„ä¼°ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ•æ‰è¯­è¨€æ¨¡å‹çš„è¯­è¨€çŸ¥è¯†å†…åŒ–æƒ…å†µã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºQFrCoLAæ•°æ®é›†ï¼Œæä¾›ä¸€ä¸ªåŒ…å«é­åŒ—å…‹æ³•è¯­çš„å¯æ¥å—æ€§åˆ¤æ–­çš„æ ‡å‡†åŒ–æ•°æ®é›†ï¼Œä»¥ä¾¿å¯¹è¯­è¨€æ¨¡å‹è¿›è¡Œç³»ç»Ÿè¯„ä¼°ã€‚è¯¥è®¾è®¡æ—¨åœ¨é€šè¿‡å…·ä½“çš„è¯­è¨€è§„èŒƒç¤ºä¾‹æ¥è¯„ä¼°æ¨¡å‹çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒã€ä»¥åŠåŸºå‡†æµ‹è¯•ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚æ•°æ®é›†æ„å»ºé˜¶æ®µæ¶‰åŠæ”¶é›†å’Œæ ‡æ³¨é­åŒ—å…‹æ³•è¯­å¥å­ï¼Œæ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒé˜¶æ®µåˆ™ä½¿ç”¨ä¸ƒç§ä¸åŒçš„è¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šQFrCoLAæ•°æ®é›†çš„æ„å»ºæ˜¯æœ¬æ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªä¸“æ³¨äºè¯­è¨€è§„èŒƒè€Œéè¯´è¯è€…æ„Ÿå—çš„è¯„ä¼°æ ‡å‡†ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è§‚æ€§è¯„ä¼°å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒç­–ç•¥ï¼Œä½¿ç”¨äº†æ ‡å‡†çš„äºŒå…ƒåˆ†ç±»æŸå¤±å‡½æ•°ï¼Œå¹¶åœ¨æ¨¡å‹è®­ç»ƒä¸­å…³æ³¨é­åŒ—å…‹æ³•è¯­çš„ç‰¹å®šè¯­è¨€ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„Transformerè¯­è¨€æ¨¡å‹åœ¨QFrCoLAåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æ€§èƒ½è¶…è¿‡å…¶ä»–æµ‹è¯•æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¾®è°ƒæ¨¡å‹åœ¨é­åŒ—å…‹æ³•è¯­çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºé›¶æ ·æœ¬åˆ†ç±»çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¡¨æ˜å¾®è°ƒç­–ç•¥åœ¨è¯¥ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è¯­è¨€æ¨¡å‹è¯„ä¼°ã€è¯­è¨€æ•™å­¦ã€ä»¥åŠè¯­è¨€å­¦ç ”ç©¶ã€‚é€šè¿‡æä¾›æ ‡å‡†åŒ–çš„è¯„ä¼°æ•°æ®é›†ï¼ŒQFrCoLAèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›è¯­è¨€æ¨¡å‹çš„è¯­è¨€åˆ¤æ–­èƒ½åŠ›ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†å¯èƒ½ä¼šè¢«æ‰©å±•è‡³å…¶ä»–è¯­è¨€æˆ–æ–¹è¨€ï¼Œè¿›ä¸€æ­¥æå‡å…¶åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large and Transformer-based language models perform outstandingly in various downstream tasks. However, there is limited understanding regarding how these models internalize linguistic knowledge, so various linguistic benchmarks have recently been proposed to facilitate syntactic evaluation of language models across languages. This paper introduces QFrCoLA (Quebec-French Corpus of Linguistic Acceptability Judgments), a normative binary acceptability judgments dataset comprising 25,153 in-domain and 2,675 out-of-domain sentences. Our study leverages the QFrCoLA dataset and seven other linguistic binary acceptability judgment corpora to benchmark seven language models. The results demonstrate that, on average, fine-tuned Transformer-based LM are strong baselines for most languages and that zero-shot binary classification large language models perform poorly on the task. However, for the QFrCoLA benchmark, on average, a fine-tuned Transformer-based LM outperformed other methods tested. It also shows that pre-trained cross-lingual LLMs selected for our experimentation do not seem to have acquired linguistic judgment capabilities during their pre-training for Quebec French. Finally, our experiment results on QFrCoLA show that our dataset, built from examples that illustrate linguistic norms rather than speakers' feelings, is similar to linguistic acceptability judgment; it is a challenging dataset that can benchmark LM on their linguistic judgment capabilities.

