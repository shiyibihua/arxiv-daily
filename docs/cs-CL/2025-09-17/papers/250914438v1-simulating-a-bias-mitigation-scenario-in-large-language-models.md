---
layout: default
title: Simulating a Bias Mitigation Scenario in Large Language Models
---

# Simulating a Bias Mitigation Scenario in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14438" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14438v1</a>
  <a href="https://arxiv.org/pdf/2509.14438.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14438v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14438v1', 'Simulating a Bias Mitigation Scenario in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kiana Kiashemshaki, Mohammad Jalili Torkamani, Negin Mahmoudi, Meysam Shirdel Bilehsavar

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: preprint, 16 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºæ¨¡æ‹Ÿæ¡†æ¶ï¼Œè¯„ä¼°ç¼“è§£å¤§å‹è¯­è¨€æ¨¡å‹åè§çš„ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åè§ç¼“è§£` `æ¨¡æ‹Ÿæ¡†æ¶` `æ•°æ®ç®¡ç†` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹å­˜åœ¨åè§ï¼Œå½±å“å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆç¼“è§£ã€‚
2. æ„å»ºæ¨¡æ‹Ÿæ¡†æ¶ï¼Œé›†æˆæ•°æ®ç®¡ç†ã€è®­ç»ƒå»åè§å’Œè¾“å‡ºæ ¡å‡†ç­‰ç­–ç•¥ï¼Œè¯„ä¼°å…¶æ•ˆæœã€‚
3. é€šè¿‡å—æ§å®éªŒéªŒè¯ç¼“è§£åè§ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå®é™…åº”ç”¨æä¾›ç»éªŒæ”¯æŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»æ ¹æœ¬ä¸Šæ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼›ç„¶è€Œï¼Œå®ƒä»¬æ˜“å—åè§å½±å“çš„å¼±ç‚¹æ„æˆäº†ä¸€ä¸ªæ˜¾è‘—çš„éšœç¢ï¼Œå¨èƒç€å…¬å¹³æ€§å’Œä¿¡ä»»ã€‚æœ¬æ–‡å¯¹LLMsä¸­çš„åè§è¿›è¡Œäº†å¹¿æ³›çš„åˆ†æï¼Œè¿½æº¯äº†å…¶åœ¨å„ç§NLPä»»åŠ¡ä¸­çš„æ ¹æºå’Œè¡¨ç°å½¢å¼ã€‚åè§è¢«åˆ†ä¸ºéšæ€§å’Œæ˜¾æ€§ç±»å‹ï¼Œç‰¹åˆ«å…³æ³¨å®ƒä»¬ä»æ•°æ®æºã€æ¶æ„è®¾è®¡å’Œä¸Šä¸‹æ–‡éƒ¨ç½²ä¸­çš„äº§ç”Ÿã€‚æœ¬ç ”ç©¶è¶…è¶Šäº†ç†è®ºåˆ†æï¼Œé€šè¿‡å®æ–½ä¸€ä¸ªæ¨¡æ‹Ÿæ¡†æ¶æ¥è¯„ä¼°å®è·µä¸­ç¼“è§£åè§çš„ç­–ç•¥ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤šç§æ–¹æ³•ï¼ŒåŒ…æ‹¬æ•°æ®ç®¡ç†ã€æ¨¡å‹è®­ç»ƒæœŸé—´çš„å»åè§ä»¥åŠäº‹åè¾“å‡ºæ ¡å‡†ï¼Œå¹¶åœ¨å—æ§å®éªŒç¯å¢ƒä¸­è¯„ä¼°å®ƒä»¬çš„å½±å“ã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¿™é¡¹å·¥ä½œä¸ä»…ç»¼åˆäº†å…³äºLLMsä¸­åè§çš„ç°æœ‰çŸ¥è¯†ï¼Œè€Œä¸”é€šè¿‡æ¨¡æ‹Ÿç¼“è§£ç­–ç•¥è´¡çŒ®äº†åŸåˆ›çš„ç»éªŒéªŒè¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å­˜åœ¨çš„åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¼“è§£è¿™äº›åè§æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•æœ‰æ•ˆä¿è¯æ¨¡å‹çš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ã€‚è¿™äº›åè§å¯èƒ½æºäºæ•°æ®ã€æ¨¡å‹æ¶æ„æˆ–éƒ¨ç½²ç¯å¢ƒï¼Œå¯¼è‡´æ¨¡å‹åœ¨ç‰¹å®šç¾¤ä½“æˆ–ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªæ¨¡æ‹Ÿæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°ä¸åŒçš„åè§ç¼“è§£ç­–ç•¥ã€‚é€šè¿‡åœ¨å—æ§ç¯å¢ƒä¸­æ¨¡æ‹Ÿå„ç§åœºæ™¯ï¼Œå¯ä»¥ç³»ç»Ÿåœ°æ¯”è¾ƒä¸åŒç­–ç•¥çš„æ•ˆæœï¼Œä»è€Œæ‰¾åˆ°æœ€æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§æ–¹æ³•å…è®¸ç ”ç©¶äººå‘˜åœ¨å®é™…éƒ¨ç½²ä¹‹å‰ï¼Œå¯¹ç¼“è§£ç­–ç•¥è¿›è¡Œå……åˆ†çš„æµ‹è¯•å’Œä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®ç®¡ç†æ¨¡å—ï¼Œç”¨äºå¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ¸…æ´—å’Œå¤„ç†ï¼Œå‡å°‘æ•°æ®ä¸­çš„åè§ï¼›2) æ¨¡å‹è®­ç»ƒæ¨¡å—ï¼Œé‡‡ç”¨å»åè§æŠ€æœ¯ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‡å°‘æ¨¡å‹å¯¹åè§çš„å­¦ä¹ ï¼›3) è¾“å‡ºæ ¡å‡†æ¨¡å—ï¼Œå¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œè°ƒæ•´ï¼Œä»¥å‡å°‘åè§çš„å½±å“ï¼›4) è¯„ä¼°æ¨¡å—ï¼Œç”¨äºè¯„ä¼°ä¸åŒç­–ç•¥çš„æ•ˆæœï¼Œå¹¶è¿›è¡Œæ¯”è¾ƒåˆ†æã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒã€åè§ç¼“è§£å’Œæ•ˆæœè¯„ä¼°ç­‰é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æ¨¡æ‹Ÿæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMsä¸­çš„åè§ç¼“è§£ç­–ç•¥ã€‚ä¸ä»¥å¾€çš„ç ”ç©¶ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ›´åŠ ç³»ç»Ÿå’Œå…¨é¢ï¼Œå¯ä»¥åŒæ—¶è¯„ä¼°å¤šç§ç­–ç•¥çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æä¾›äº†ä¸€ä¸ªå¯é‡å¤çš„å®éªŒç¯å¢ƒï¼Œæ–¹ä¾¿å…¶ä»–ç ”ç©¶äººå‘˜è¿›è¡ŒéªŒè¯å’Œæ”¹è¿›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ï¼Œæ‘˜è¦ä¸­æ²¡æœ‰è¯¦ç»†è¯´æ˜å…³é”®å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ã€‚ä½†æ˜¯ï¼Œå¯ä»¥æ¨æ–­ï¼Œæ•°æ®ç®¡ç†æ¨¡å—å¯èƒ½æ¶‰åŠæ•°æ®å¢å¼ºã€é‡é‡‡æ ·æˆ–å¯¹æŠ—è®­ç»ƒç­‰æŠ€æœ¯ã€‚æ¨¡å‹è®­ç»ƒæ¨¡å—å¯èƒ½é‡‡ç”¨æ­£åˆ™åŒ–ã€å¯¹æŠ—è®­ç»ƒæˆ–çŸ¥è¯†è’¸é¦ç­‰æ–¹æ³•ã€‚è¾“å‡ºæ ¡å‡†æ¨¡å—å¯èƒ½ä½¿ç”¨é˜ˆå€¼è°ƒæ•´ã€æ¦‚ç‡å¹³æ»‘æˆ–åå¤„ç†ç®—æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æ„å»ºçš„æ¨¡æ‹Ÿæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆè¯„ä¼°å¤šç§åè§ç¼“è§£ç­–ç•¥ï¼Œå¹¶åœ¨å—æ§å®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è™½ç„¶æ‘˜è¦ä¸­æ²¡æœ‰æä¾›å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦ï¼Œä½†è¯¥ç ”ç©¶ä¸ºLLMsçš„åè§ç¼“è§£æä¾›äº†ä¸€ä¸ªæœ‰ä»·å€¼çš„å·¥å…·å’Œæ–¹æ³•ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡ç¼“è§£LLMsä¸­çš„åè§ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ï¼Œé¿å…æ­§è§†æ€§æˆ–ä¸å‡†ç¡®çš„è¾“å‡ºã€‚è¿™å¯¹äºæ„å»ºè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠæ•æ„Ÿä¿¡æ¯æˆ–å†³ç­–çš„åº”ç”¨åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have fundamentally transformed the field of natural language processing; however, their vulnerability to biases presents a notable obstacle that threatens both fairness and trust. This review offers an extensive analysis of the bias landscape in LLMs, tracing its roots and expressions across various NLP tasks. Biases are classified into implicit and explicit types, with particular attention given to their emergence from data sources, architectural designs, and contextual deployments. This study advances beyond theoretical analysis by implementing a simulation framework designed to evaluate bias mitigation strategies in practice. The framework integrates multiple approaches including data curation, debiasing during model training, and post-hoc output calibration and assesses their impact in controlled experimental settings. In summary, this work not only synthesizes existing knowledge on bias in LLMs but also contributes original empirical validation through simulation of mitigation strategies.

