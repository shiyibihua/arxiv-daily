---
layout: default
title: Apertus: Democratizing Open and Compliant LLMs for Global Language Environments
---

# Apertus: Democratizing Open and Compliant LLMs for Global Language Environments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14233" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14233v2</a>
  <a href="https://arxiv.org/pdf/2509.14233.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14233v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14233v2', 'Apertus: Democratizing Open and Compliant LLMs for Global Language Environments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Project Apertus, Alejandro HernÃ¡ndez-Cano, Alexander HÃ¤gele, Allen Hao Huang, Angelika Romanou, Antoni-Joan Solergibert, Barna Pasztor, Bettina Messmer, Dhia Garbaya, Eduard Frank Äurech, Ido Hakimi, Juan GarcÃ­a Giraldo, Mete Ismayilzada, Negar Foroutan, Skander Moalla, Tiancheng Chen, Vinko SabolÄec, Yixuan Xu, Michael Aerni, Badr AlKhamissi, InÃ©s Altemir MariÃ±as, Mohammad Hossein Amani, Matin Ansaripour, Ilia Badanin, Harold Benoit, Emanuela Boros, Nicholas Browning, Fabian BÃ¶sch, Maximilian BÃ¶ther, Niklas Canova, Camille Challier, Clement Charmillot, Jonathan Coles, Jan Deriu, Arnout Devos, Lukas Drescher, Daniil Dzenhaliou, Maud Ehrmann, Dongyang Fan, Simin Fan, Silin Gao, Miguel Gila, MarÃ­a Grandury, Diba Hashemi, Alexander Hoyle, Jiaming Jiang, Mark Klein, Andrei Kucharavy, Anastasiia Kucherenko, Frederike LÃ¼beck, Roman Machacek, Theofilos Manitaras, Andreas Marfurt, Kyle Matoba, Simon Matrenok, Henrique MendonÃ§a, Fawzi Roberto Mohamed, Syrielle Montariol, Luca Mouchel, Sven Najem-Meyer, Jingwei Ni, Gennaro Oliva, Matteo Pagliardini, Elia Palme, Andrei Panferov, LÃ©o Paoletti, Marco Passerini, Ivan Pavlov, Auguste Poiroux, Kaustubh Ponkshe, Nathan Ranchin, Javi Rando, Mathieu Sauser, Jakhongir Saydaliev, Muhammad Ali Sayfiddinov, Marian Schneider, Stefano Schuppli, Marco Scialanga, Andrei Semenov, Kumar Shridhar, Raghav Singhal, Anna Sotnikova, Alexander Sternfeld, Ayush Kumar Tarun, Paul Teiletche, Jannis Vamvas, Xiaozhe Yao, Hao Zhao, Alexander Ilic, Ana Klimovic, Andreas Krause, Caglar Gulcehre, David Rosenthal, Elliott Ash, Florian TramÃ¨r, Joost VandeVondele, Livio Veraldi, Martin Rajman, Thomas Schulthess, Torsten Hoefler, Antoine Bosselut, Martin Jaggi, Imanol Schlag

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17 (æ›´æ–°: 2025-12-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Apertusï¼šæ„å»ºå¼€æ”¾ã€åˆè§„ä¸”æ”¯æŒå…¨çƒè¯­è¨€ç¯å¢ƒçš„å¤§è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¤šè¯­è¨€` `æ•°æ®åˆè§„` `å¼€æ”¾æ¨¡å‹` `é¢„è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼€æ”¾LLMåœ¨æ•°æ®åˆè§„æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¸¸å¿½ç•¥å†…å®¹æ‰€æœ‰è€…æƒåˆ©å’Œéšç§é—®é¢˜ã€‚
2. Apertusé€šè¿‡ä»…ä½¿ç”¨å…¬å¼€æ•°æ®é¢„è®­ç»ƒï¼Œå¹¶è¿½æº¯æ€§åœ°å°Šé‡robots.txtæ’é™¤é¡¹æ¥è§£å†³åˆè§„é—®é¢˜ã€‚
3. Apertusæ¨¡å‹åœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ¥è¿‘æˆ–è¶…è¿‡å…¶ä»–å¼€æ”¾æƒé‡æ¨¡å‹ï¼Œå¹¶å¼€æºæ‰€æœ‰å¼€å‘èµ„æºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†Apertusï¼Œä¸€å¥—å®Œå…¨å¼€æ”¾çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ—¨åœ¨è§£å†³å½“å‰å¼€æ”¾æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿä¸­çš„ä¸¤ä¸ªç³»ç»Ÿæ€§ç¼ºé™·ï¼šæ•°æ®åˆè§„æ€§å’Œå¤šè¯­è¨€è¡¨ç¤ºã€‚ä¸è®¸å¤šåœ¨æœªæä¾›å¯å¤ç°æ•°æ®æµç¨‹æˆ–æœªè€ƒè™‘å†…å®¹æ‰€æœ‰è€…æƒåˆ©çš„æƒ…å†µä¸‹å‘å¸ƒæƒé‡çš„æ¨¡å‹ä¸åŒï¼ŒApertusæ¨¡å‹ä»…åœ¨å…¬å¼€å¯ç”¨çš„æ•°æ®ä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œè¿½æº¯æ€§åœ°å°Šé‡`robots.txt`æ’é™¤é¡¹ï¼Œå¹¶è¿‡æ»¤éè®¸å¯ã€æœ‰å®³å’Œä¸ªäººèº«ä»½ä¿¡æ¯å†…å®¹ã€‚ä¸ºäº†é™ä½è®°å¿†é£é™©ï¼Œæˆ‘ä»¬åœ¨é¢„è®­ç»ƒæœŸé—´é‡‡ç”¨äº†Goldfishç›®æ ‡ï¼Œå¼ºçƒˆæŠ‘åˆ¶æ•°æ®çš„é€å­—å›å¿†ï¼ŒåŒæ—¶ä¿æŒä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ã€‚Apertusæ¨¡å‹è¿˜æ‰©å±•äº†å¤šè¯­è¨€è¦†ç›–èŒƒå›´ï¼Œåœ¨æ¥è‡ª1800å¤šç§è¯­è¨€çš„15T tokensä¸Šè¿›è¡Œè®­ç»ƒï¼Œå…¶ä¸­çº¦40%çš„é¢„è®­ç»ƒæ•°æ®åˆ†é…ç»™éè‹±è¯­å†…å®¹ã€‚Apertusæ¨¡å‹ä»¥8Bå’Œ70Bè§„æ¨¡å‘å¸ƒï¼Œåœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­æ¥è¿‘å®Œå…¨å¼€æ”¾æ¨¡å‹çš„æœ€æ–°ç»“æœï¼Œä¸å¼€æ”¾æƒé‡æ¨¡å‹ç›¸åª²ç¾æˆ–è¶…è¶Šã€‚é™¤äº†æ¨¡å‹æƒé‡å¤–ï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†å¼€å‘å‘¨æœŸä¸­çš„æ‰€æœ‰ç§‘å­¦æˆæœï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡è„šæœ¬ã€æ£€æŸ¥ç‚¹ã€è¯„ä¼°å¥—ä»¶å’Œè®­ç»ƒä»£ç ï¼Œå¹¶é‡‡ç”¨å®½æ¾çš„è®¸å¯è¯ï¼Œä»è€Œå®ç°é€æ˜çš„å®¡è®¡å’Œæ‰©å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰å¼€æºå¤§è¯­è¨€æ¨¡å‹ç”Ÿæ€é¢ä¸´æ•°æ®åˆè§„æ€§å’Œå¤šè¯­è¨€æ”¯æŒä¸è¶³çš„é—®é¢˜ã€‚è®¸å¤šæ¨¡å‹åœ¨è®­ç»ƒæ•°æ®æ¥æºä¸Šä¸å¤Ÿé€æ˜ï¼Œå¯èƒ½ä¾µçŠ¯ç‰ˆæƒæˆ–åŒ…å«æœ‰å®³ä¿¡æ¯ã€‚åŒæ—¶ï¼Œå¯¹éè‹±è¯­è¯­è¨€çš„æ”¯æŒä¹Ÿç›¸å¯¹æœ‰é™ï¼Œæ— æ³•æ»¡è¶³å…¨çƒç”¨æˆ·çš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šApertusçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå®Œå…¨å¼€æ”¾ã€åˆè§„ä¸”æ”¯æŒå¹¿æ³›è¯­è¨€çš„å¤§è¯­è¨€æ¨¡å‹ã€‚é€šè¿‡ä¸¥æ ¼ç­›é€‰è®­ç»ƒæ•°æ®ï¼Œç¡®ä¿å…¶æ¥æºåˆæ³•ä¸”ä¸åŒ…å«æœ‰å®³å†…å®¹ã€‚åŒæ—¶ï¼Œé€šè¿‡å¢åŠ éè‹±è¯­æ•°æ®çš„æ¯”ä¾‹ï¼Œæå‡æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šApertusçš„è®­ç»ƒæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ä¸æ¸…æ´—ï¼šä»å…¬å¼€æ¸ é“æ”¶é›†æ•°æ®ï¼Œå¹¶æ ¹æ®robots.txtæ’é™¤é¡¹è¿›è¡Œè¿‡æ»¤ï¼Œç§»é™¤æœ‰å®³å’Œä¸ªäººèº«ä»½ä¿¡æ¯å†…å®¹ã€‚2) é¢„è®­ç»ƒï¼šä½¿ç”¨æ”¶é›†åˆ°çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œé‡‡ç”¨Goldfishç›®æ ‡æ¥æŠ‘åˆ¶è®°å¿†æ•ˆåº”ã€‚3) è¯„ä¼°ï¼šä½¿ç”¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚4) å‘å¸ƒï¼šå‘å¸ƒæ¨¡å‹æƒé‡ã€æ•°æ®å‡†å¤‡è„šæœ¬ã€æ£€æŸ¥ç‚¹ã€è¯„ä¼°å¥—ä»¶å’Œè®­ç»ƒä»£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šApertusçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¯¹æ•°æ®åˆè§„æ€§çš„é‡è§†å’Œå¯¹å¤šè¯­è¨€æ”¯æŒçš„æ‰©å±•ã€‚é€šè¿‡ä¸¥æ ¼çš„æ•°æ®ç­›é€‰å’ŒGoldfishç›®æ ‡ï¼Œé™ä½äº†æ¨¡å‹è®°å¿†å’Œç”Ÿæˆæœ‰å®³å†…å®¹çš„é£é™©ã€‚åŒæ—¶ï¼Œé€šè¿‡å¢åŠ éè‹±è¯­æ•°æ®çš„æ¯”ä¾‹ï¼Œæå‡äº†æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šApertusé‡‡ç”¨äº†Goldfishç›®æ ‡ä½œä¸ºé¢„è®­ç»ƒçš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œæ—¨åœ¨å‡å°‘æ¨¡å‹å¯¹è®­ç»ƒæ•°æ®çš„è¿‡åº¦è®°å¿†ã€‚å…·ä½“æ¥è¯´ï¼ŒGoldfishç›®æ ‡é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸è¾“å…¥æ–‡æœ¬ç›¸ä¼¼ä½†åˆä¸å®Œå…¨ç›¸åŒçš„æ–‡æœ¬ï¼Œä»è€Œé™ä½äº†é€å­—å›å¿†çš„é£é™©ã€‚æ­¤å¤–ï¼ŒApertusåœ¨è®­ç»ƒæ•°æ®ä¸­åˆ†é…äº†çº¦40%çš„æ¯”ä¾‹ç»™éè‹±è¯­å†…å®¹ï¼Œä»¥æå‡æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Apertusæ¨¡å‹åœ¨å¤šè¯­è¨€åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¸ç°æœ‰å¼€æ”¾æƒé‡æ¨¡å‹ç›¸åª²ç¾ç”šè‡³è¶…è¶Šçš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›å¤šè¯­è¨€ä»»åŠ¡ä¸Šï¼ŒApertus 70Bæ¨¡å‹æ¥è¿‘äº†æœ€å…ˆè¿›çš„å¼€æ”¾æ¨¡å‹ï¼ŒåŒæ—¶ä¿è¯äº†æ•°æ®åˆè§„æ€§å’Œé€æ˜åº¦ã€‚æ­¤å¤–ï¼Œå¼€æºæ‰€æœ‰å¼€å‘èµ„æºä¹Ÿä¸ºç¤¾åŒºæä¾›äº†æå¤§çš„ä¾¿åˆ©ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Apertuså¯åº”ç”¨äºæœºå™¨ç¿»è¯‘ã€è·¨è¯­è¨€ä¿¡æ¯æ£€ç´¢ã€å¤šè¯­è¨€å†…å®¹ç”Ÿæˆç­‰é¢†åŸŸã€‚å…¶å¼€æ”¾æ€§å’Œåˆè§„æ€§ä½¿å…¶æ›´æ˜“äºè¢«ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…é‡‡ç”¨ï¼Œä¿ƒè¿›å…¨çƒè¯­è¨€ç¯å¢ƒä¸‹çš„AIåº”ç”¨å‘å±•ã€‚æœªæ¥ï¼ŒApertusæœ‰æœ›æˆä¸ºæ„å»ºè´Ÿè´£ä»»ã€å¯ä¿¡èµ–çš„AIç³»ç»Ÿçš„åŸºç¡€æ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Apertus, a fully open suite of large language models (LLMs) designed to address two systemic shortcomings in today's open model ecosystem: data compliance and multilingual representation. Unlike many prior models that release weights without reproducible data pipelines or regard for content-owner rights, Apertus models are pretrained exclusively on openly available data, retroactively respecting `robots.txt` exclusions and filtering for non-permissive, toxic, and personally identifiable content. To mitigate risks of memorization, we adopt the Goldfish objective during pretraining, strongly suppressing verbatim recall of data while retaining downstream task performance. The Apertus models also expand multilingual coverage, training on 15T tokens from over 1800 languages, with ~40% of pretraining data allocated to non-English content. Released at 8B and 70B scales, Apertus approaches state-of-the-art results among fully open models on multilingual benchmarks, rivalling or surpassing open-weight counterparts. Beyond model weights, we release all scientific artifacts from our development cycle with a permissive license, including data preparation scripts, checkpoints, evaluation suites, and training code, enabling transparent audit and extension.

