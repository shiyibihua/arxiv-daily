---
layout: default
title: Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs
---

# Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13869" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13869v1</a>
  <a href="https://arxiv.org/pdf/2509.13869.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13869v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13869v1', 'Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yang Liu, Chenhui Chu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: 38 pages, 31 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ç¤¾ä¼šåè§åœºæ™¯ä¸‹çš„äººç±»ä»·å€¼è§‚å¯¹é½ç¨‹åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤¾ä¼šåè§` `ä»·å€¼è§‚å¯¹é½` `æ¨¡å‹è¯„ä¼°` `å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–ä¸“å®¶è®¾è®¡æˆ–æ¨¡æ‹Ÿåœºæ™¯è¯„ä¼°LLMçš„ç¤¾ä¼šåè§ï¼Œç¼ºä¹å¯¹ä¸åŒç±»å‹åè§åœºæ™¯çš„ç»†è‡´åˆ†æã€‚
2. è¯¥ç ”ç©¶é€šè¿‡åˆ†æLLMåœ¨ä¸åŒç±»å‹ç¤¾ä¼šåè§åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œè¯„ä¼°å…¶ä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ç¨‹åº¦ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡ä¸å¯¹é½ç¨‹åº¦å¹¶éçº¿æ€§ç›¸å…³ï¼Œä¸”æ¨¡å‹å¯¹ç‰¹å®šåœºæ™¯æœ‰åå¥½ï¼ŒåŒç³»åˆ—æ¨¡å‹ä¸€è‡´æ€§æ›´é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è‹¥ä¸äººç±»ä»·å€¼è§‚ä¸ä¸€è‡´ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤æ‚å’Œæ•æ„Ÿçš„ç¤¾ä¼šåè§åœºæ™¯ä¸­ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä¸è‰¯åæœã€‚ä»¥å¾€ç ”ç©¶å·²é€šè¿‡ä¸“å®¶è®¾è®¡æˆ–åŸºäºä»£ç†çš„æ¨¡æ‹Ÿåè§åœºæ™¯æ­ç¤ºäº†LLMsä¸äººç±»ä»·å€¼è§‚çš„ä¸ä¸€è‡´æ€§ã€‚ç„¶è€Œï¼ŒLLMsä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ç¨‹åº¦æ˜¯å¦å› ä¸åŒç±»å‹çš„åœºæ™¯ï¼ˆä¾‹å¦‚ï¼ŒåŒ…å«è´Ÿé¢é—®é¢˜ä¸éè´Ÿé¢é—®é¢˜çš„åœºæ™¯ï¼‰è€Œå¼‚ï¼Œç›®å‰å°šä¸æ¸…æ¥šã€‚æœ¬ç ”ç©¶è°ƒæŸ¥äº†LLMsåœ¨ä¸åŒç±»å‹åè§åœºæ™¯ä¸­ï¼Œå…³äºç¤¾ä¼šåè§ï¼ˆHVSBï¼‰çš„äººç±»ä»·å€¼è§‚å¯¹é½ç¨‹åº¦ã€‚é€šè¿‡å¯¹æ¥è‡ªå››ä¸ªæ¨¡å‹ç³»åˆ—çš„12ä¸ªLLMså’Œå››ä¸ªæ•°æ®é›†çš„å¹¿æ³›åˆ†æï¼Œæˆ‘ä»¬è¯æ˜äº†å…·æœ‰å¤§å‹æ¨¡å‹å‚æ•°è§„æ¨¡çš„LLMsä¸ä¸€å®šå…·æœ‰è¾ƒä½çš„é”™ä½ç‡å’Œæ”»å‡»æˆåŠŸç‡ã€‚æ­¤å¤–ï¼ŒLLMså¯¹ç‰¹å®šç±»å‹çš„åœºæ™¯è¡¨ç°å‡ºä¸€å®šç¨‹åº¦çš„å¯¹é½åå¥½ï¼Œå¹¶ä¸”æ¥è‡ªåŒä¸€æ¨¡å‹ç³»åˆ—çš„LLMså¾€å¾€å…·æœ‰æ›´é«˜çš„åˆ¤æ–­ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç ”ç©¶äº†LLMsé€šè¿‡å…¶å¯¹HVSBçš„è§£é‡Šæ‰€è¡¨ç°å‡ºçš„ç†è§£èƒ½åŠ›ã€‚æˆ‘ä»¬å‘ç°ä¸åŒLLMsåœ¨å¯¹HVSBçš„ç†è§£æ–¹é¢æ²¡æœ‰æ˜¾ç€å·®å¼‚ã€‚æˆ‘ä»¬è¿˜å‘ç°LLMsæ›´å–œæ¬¢è‡ªå·±ç”Ÿæˆçš„è§£é‡Šã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬èµ‹äºˆè¾ƒå°çš„è¯­è¨€æ¨¡å‹ï¼ˆLMsï¼‰è§£é‡ŠHVSBçš„èƒ½åŠ›ã€‚ç”Ÿæˆç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„è¾ƒå°LMsç”Ÿæˆçš„è§£é‡Šæ›´å…·å¯è¯»æ€§ï¼Œä½†æ¨¡å‹ä¸€è‡´æ€§ç›¸å¯¹è¾ƒä½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¶‰åŠç¤¾ä¼šåè§æ—¶ï¼Œä¸äººç±»ä»·å€¼è§‚å¯¹é½ç¨‹åº¦çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºä¸“å®¶è®¾è®¡çš„åœºæ™¯æˆ–åŸºäºä»£ç†çš„æ¨¡æ‹Ÿï¼Œè¿™äº›æ–¹æ³•å¯èƒ½æ— æ³•å…¨é¢æ•æ‰ä¸åŒç±»å‹çš„åè§åœºæ™¯ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹LLMè§£é‡Šèƒ½åŠ›çš„æ·±å…¥åˆ†æã€‚å› æ­¤ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®è¯„ä¼°LLMåœ¨å¤æ‚ç¤¾ä¼šåè§åœºæ™¯ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºåŒ…å«ä¸åŒç±»å‹ç¤¾ä¼šåè§åœºæ™¯çš„æ•°æ®é›†ï¼Œå¹¶åˆ†æLLMåœ¨è¿™äº›åœºæ™¯ä¸­çš„åˆ¤æ–­å’Œè§£é‡Šï¼Œæ¥è¯„ä¼°å…¶ä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ç¨‹åº¦ã€‚é€šè¿‡æ¯”è¾ƒä¸åŒæ¨¡å‹å®¶æ—å’Œä¸åŒè§„æ¨¡çš„LLMï¼Œä»¥åŠåˆ†æå®ƒä»¬å¯¹åè§åœºæ™¯çš„è§£é‡Šï¼Œå¯ä»¥æ›´å…¨é¢åœ°äº†è§£LLMåœ¨ç¤¾ä¼šåè§æ–¹é¢çš„æ½œåœ¨é£é™©å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ„å»ºåŒ…å«ä¸åŒç±»å‹ç¤¾ä¼šåè§åœºæ™¯çš„æ•°æ®é›†ï¼›2) ä½¿ç”¨ä¸åŒçš„LLMå¯¹è¿™äº›åœºæ™¯è¿›è¡Œåˆ¤æ–­ï¼Œå¹¶åˆ†æå…¶åˆ¤æ–­ç»“æœï¼›3) åˆ†æLLMå¯¹åˆ¤æ–­ç»“æœçš„è§£é‡Šï¼Œè¯„ä¼°å…¶ç†è§£èƒ½åŠ›ï¼›4) å¯¹è¾ƒå°çš„è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶å…·å¤‡è§£é‡Šç¤¾ä¼šåè§çš„èƒ½åŠ›ï¼Œå¹¶è¯„ä¼°å…¶ç”Ÿæˆè§£é‡Šçš„è´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ç³»ç»Ÿæ€§åœ°åˆ†æäº†LLMåœ¨ä¸åŒç±»å‹ç¤¾ä¼šåè§åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºäº†æ¨¡å‹è§„æ¨¡ä¸å¯¹é½ç¨‹åº¦å¹¶éçº¿æ€§ç›¸å…³ï¼›2) æ·±å…¥ç ”ç©¶äº†LLMå¯¹ç¤¾ä¼šåè§çš„è§£é‡Šèƒ½åŠ›ï¼Œå‘ç°æ¨¡å‹æ›´å€¾å‘äºè‡ªå·±ç”Ÿæˆçš„è§£é‡Šï¼›3) æ¢ç´¢äº†èµ‹äºˆè¾ƒå°è¯­è¨€æ¨¡å‹è§£é‡Šç¤¾ä¼šåè§èƒ½åŠ›çš„æ–¹æ³•ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨å¯é çš„LLMæä¾›äº†æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å››ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–ä¸åŒç±»å‹çš„ç¤¾ä¼šåè§åœºæ™¯ã€‚é€‰æ‹©äº†æ¥è‡ªå››ä¸ªæ¨¡å‹ç³»åˆ—çš„12ä¸ªLLMè¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ä¸åŒè§„æ¨¡çš„æ¨¡å‹ã€‚è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬é”™ä½ç‡å’Œæ”»å‡»æˆåŠŸç‡ï¼Œç”¨äºè¡¡é‡LLMä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½ç¨‹åº¦ã€‚æ­¤å¤–ï¼Œè¿˜åˆ†æäº†LLMç”Ÿæˆçš„è§£é‡Šçš„å¯è¯»æ€§å’Œæ¨¡å‹ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMçš„æ¨¡å‹å‚æ•°è§„æ¨¡ä¸äººç±»ä»·å€¼è§‚å¯¹é½ç¨‹åº¦å¹¶éçº¿æ€§ç›¸å…³ã€‚ä¸åŒLLMå¯¹ç‰¹å®šç±»å‹çš„ç¤¾ä¼šåè§åœºæ™¯è¡¨ç°å‡ºä¸åŒçš„åå¥½ã€‚æ¥è‡ªåŒä¸€æ¨¡å‹å®¶æ—çš„LLMåœ¨åˆ¤æ–­ä¸Šå…·æœ‰è¾ƒé«˜çš„ä¸€è‡´æ€§ã€‚å¾®è°ƒåçš„è¾ƒå°è¯­è¨€æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å…·å¯è¯»æ€§çš„è§£é‡Šï¼Œä½†æ¨¡å‹ä¸€è‡´æ€§ç›¸å¯¹è¾ƒä½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¶‰åŠç¤¾ä¼šåè§æ—¶çš„å®‰å…¨æ€§ï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºæ›´ç¬¦åˆäººç±»ä»·å€¼è§‚çš„AIç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¼€å‘èƒ½å¤Ÿè§£é‡Šè‡ªèº«åˆ¤æ–­çš„AIæ¨¡å‹æä¾›äº†æ€è·¯ï¼Œå¢å¼ºäº†AIç³»ç»Ÿçš„é€æ˜åº¦å’Œå¯ä¿¡åº¦ï¼Œå¯åº”ç”¨äºå†…å®¹å®¡æ ¸ã€æ‹›è˜ç­›é€‰ç­‰æ•æ„Ÿé¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) can lead to undesired consequences when misaligned with human values, especially in scenarios involving complex and sensitive social biases. Previous studies have revealed the misalignment of LLMs with human values using expert-designed or agent-based emulated bias scenarios. However, it remains unclear whether the alignment of LLMs with human values differs across different types of scenarios (e.g., scenarios containing negative vs. non-negative questions). In this study, we investigate the alignment of LLMs with human values regarding social biases (HVSB) in different types of bias scenarios. Through extensive analysis of 12 LLMs from four model families and four datasets, we demonstrate that LLMs with large model parameter scales do not necessarily have lower misalignment rate and attack success rate. Moreover, LLMs show a certain degree of alignment preference for specific types of scenarios and the LLMs from the same model family tend to have higher judgment consistency. In addition, we study the understanding capacity of LLMs with their explanations of HVSB. We find no significant differences in the understanding of HVSB across LLMs. We also find LLMs prefer their own generated explanations. Additionally, we endow smaller language models (LMs) with the ability to explain HVSB. The generation results show that the explanations generated by the fine-tuned smaller LMs are more readable, but have a relatively lower model agreeability.

