---
layout: default
title: SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation
---

# SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14036" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.14036v1</a>
  <a href="https://arxiv.org/pdf/2509.14036.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14036v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14036v1', 'SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zekang Liu, Wei Feng, Fanhua Shang, Lianyu Hu, Jichao Feng, Liqing Gao

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-17

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÈóÆÈ¢òÁöÑÊâãËØ≠ÁøªËØë‰ªªÂä°ÂèäËá™ÁõëÁù£Â≠¶‰π†ËûçÂêàÊñπÊ≥ïSSL-SSAW**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊâãËØ≠ÁøªËØë` `Ëá™ÁõëÁù£Â≠¶‰π†` `Â§öÊ®°ÊÄÅËûçÂêà` `ÂØπÊØîÂ≠¶‰π†` `Ê≥®ÊÑèÂäõÊú∫Âà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊâãËØ≠ÁøªËØëÊñπÊ≥ï‰æùËµñËØçËØ≠Ê†áÊ≥®ÔºåÊàêÊú¨È´òÊòÇ‰∏îÂøΩÁï•‰∫ÜÂØπËØù‰∏ä‰∏ãÊñá„ÄÇ
2. ÊèêÂá∫SSL-SSAWÔºåÂà©Áî®ÂØπÊØîÂ≠¶‰π†ÂØπÈΩêÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÂπ∂Áî®SSAWÊ®°ÂùóËá™ÈÄÇÂ∫îÊèêÂèñÁâπÂæÅ„ÄÇ
3. Âú®CSL-Daily-QAÂíåPHOENIX-2014T-QAÊï∞ÊçÆÈõÜ‰∏äËææÂà∞SOTAÔºåÈóÆÈ¢òËæÖÂä©ÊïàÊûú‰ºò‰∫éËØçËØ≠ËæÖÂä©„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑ‰ªªÂä°ÔºöÂü∫‰∫éÈóÆÈ¢òÁöÑÊâãËØ≠ÁøªËØëÔºàQB-SLTÔºâÔºåÊó®Âú®Êé¢Á¥¢ÂØπËØù‰ø°ÊÅØÂú®ÊâãËØ≠ÁøªËØë‰∏≠ÁöÑÊúâÊïàËûçÂêà„ÄÇ‰∏éËØçËØ≠ÔºàÊâãËØ≠ËΩ¨ÂΩïÔºâÊ†áÊ≥®‰∏çÂêåÔºåÂØπËØùËá™ÁÑ∂Â≠òÂú®‰∫é‰∫§ÊµÅ‰∏≠Ôºå‰∏îÊõ¥ÂÆπÊòìÊ†áÊ≥®„ÄÇËØ•‰ªªÂä°ÁöÑÂÖ≥ÈîÆÊåëÊàòÂú®‰∫éÂØπÈΩêÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÂêåÊó∂Âà©Áî®ÈóÆÈ¢òÁöÑ‰∏ä‰∏ãÊñáÊù•ÊîπËøõÁøªËØë„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçË∑®Ê®°ÊÄÅÁöÑËá™ÁõëÁù£Â≠¶‰π†ÊñπÊ≥ïÔºåÁªìÂêàSigmoidËá™Ê≥®ÊÑèÂäõÊùÉÈáçÔºàSSL-SSAWÔºâËøõË°åÊâãËØ≠ÁøªËØë„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÊàë‰ª¨ÈááÁî®ÂØπÊØîÂ≠¶‰π†Êù•ÂØπÈΩêQB-SLT‰∏≠ÁöÑÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÁÑ∂ÂêéÂºïÂÖ•SigmoidËá™Ê≥®ÊÑèÂäõÊùÉÈáçÔºàSSAWÔºâÊ®°ÂùóÔºåÁî®‰∫é‰ªéÈóÆÈ¢òÂíåÊâãËØ≠Â∫èÂàó‰∏≠Ëá™ÈÄÇÂ∫îÂú∞ÊèêÂèñÁâπÂæÅ„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨Âà©Áî®ÂèØÁî®ÁöÑÈóÆÈ¢òÊñáÊú¨ÔºåÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†Êù•Â¢ûÂº∫Ë°®ÂæÅÂíåÁøªËØëËÉΩÂäõ„ÄÇÊàë‰ª¨Âú®Êñ∞Âª∫ÁöÑCSL-Daily-QAÂíåPHOENIX-2014T-QAÊï∞ÊçÆÈõÜ‰∏äËØÑ‰º∞‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåSSL-SSAWÂèñÂæó‰∫ÜSOTAÊÄßËÉΩ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºåÊòì‰∫éËé∑ÂèñÁöÑÈóÆÈ¢òËæÖÂä©ÂèØ‰ª•ËææÂà∞ÁîöËá≥Ë∂ÖËøáËØçËØ≠ËæÖÂä©ÁöÑÊÄßËÉΩ„ÄÇÊ≠§Â§ñÔºåÂèØËßÜÂåñÁªìÊûúË°®ÊòéÔºåÁªìÂêàÂØπËØù‰ø°ÊÅØÂèØ‰ª•ÊúâÊïàÊèêÈ´òÁøªËØëË¥®Èáè„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊâãËØ≠ÁøªËØëÁ≥ªÁªü‰∏ªË¶Å‰æùËµñ‰∫éÊâãËØ≠ÁöÑËØçËØ≠ÔºàglossÔºâÊ†áÊ≥®ÔºåËøôÁßçÊ†áÊ≥®ÊñπÂºèÊàêÊú¨È´òÊòÇÔºå‰∏îÂøΩÁï•‰∫ÜÂØπËØù‰∏≠ÈáçË¶ÅÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÊ≠§Â§ñÔºåÂ¶Ç‰ΩïÊúâÊïàÂú∞ËûçÂêàÂ§öÊ®°ÊÄÅ‰ø°ÊÅØÔºåÁâπÂà´ÊòØÈóÆÈ¢òÊñáÊú¨ÂíåÊâãËØ≠ËßÜÈ¢ëÔºåÊòØ‰∏Ä‰∏™ÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®ÂØπËØù‰∏≠ÁöÑÈóÆÈ¢ò‰Ωú‰∏∫‰∏ä‰∏ãÊñá‰ø°ÊÅØÔºåËæÖÂä©ÊâãËØ≠ÁøªËØë„ÄÇÈÄöËøáËá™ÁõëÁù£Â≠¶‰π†ÁöÑÊñπÂºèÔºåÂ≠¶‰π†ÈóÆÈ¢òÊñáÊú¨ÁöÑË°®ÂæÅÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÊâãËØ≠ËßÜÈ¢ëÁâπÂæÅËøõË°åËûçÂêàÔºå‰ªéËÄåÊèêÈ´òÁøªËØëÁöÑÂáÜÁ°ÆÊÄßÂíåÊµÅÁïÖÊÄß„ÄÇËÆæËÆ°ÁöÑSSAWÊ®°ÂùóËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÈóÆÈ¢òÂíåÊâãËØ≠Â∫èÂàóÁöÑÊùÉÈáçÔºå‰ªéËÄåÊõ¥Â•ΩÂú∞ÊèêÂèñÁõ∏ÂÖ≥ÁâπÂæÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSSL-SSAWÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ÁâπÂæÅÊèêÂèñÊ®°ÂùóÔºöÂàÜÂà´ÊèêÂèñÊâãËØ≠ËßÜÈ¢ëÂíåÈóÆÈ¢òÊñáÊú¨ÁöÑÁâπÂæÅ„ÄÇ2) ÂØπÊØîÂ≠¶‰π†Ê®°ÂùóÔºöÂà©Áî®ÂØπÊØîÂ≠¶‰π†ÂØπÈΩêÊâãËØ≠ËßÜÈ¢ëÂíåÈóÆÈ¢òÊñáÊú¨ÁöÑÁâπÂæÅÁ©∫Èó¥„ÄÇ3) SSAWÊ®°ÂùóÔºöÂà©Áî®SigmoidËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåËá™ÈÄÇÂ∫îÂú∞Â≠¶‰π†ÈóÆÈ¢òÂíåÊâãËØ≠Â∫èÂàóÁöÑÊùÉÈáçÔºåÂπ∂ËøõË°åÁâπÂæÅËûçÂêà„ÄÇ4) ÁøªËØëÊ®°ÂùóÔºöÂ∞ÜËûçÂêàÂêéÁöÑÁâπÂæÅËæìÂÖ•Âà∞ÁøªËØëÊ®°Âûã‰∏≠ÔºåÁîüÊàêÁõÆÊ†áËØ≠Ë®ÄÁöÑÂè•Â≠ê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÔºö1) ÊèêÂá∫‰∫ÜÂü∫‰∫éÈóÆÈ¢òÁöÑÊâãËØ≠ÁøªËØë‰ªªÂä°ÔºàQB-SLTÔºâÔºåÊõ¥Ë¥¥ËøëÂÆûÈôÖÂ∫îÁî®Âú∫ÊôØ„ÄÇ2) ÊèêÂá∫‰∫ÜSSL-SSAWÊñπÊ≥ïÔºåÈÄöËøáÂØπÊØîÂ≠¶‰π†ÂíåËá™Ê≥®ÊÑèÂäõÊú∫Âà∂ÔºåÊúâÊïàÂú∞ËûçÂêà‰∫ÜÂ§öÊ®°ÊÄÅ‰ø°ÊÅØ„ÄÇ3) Âà©Áî®Ëá™ÁõëÁù£Â≠¶‰π†Â¢ûÂº∫‰∫ÜÈóÆÈ¢òÊñáÊú¨ÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ï‰∏çÈúÄË¶ÅËØçËØ≠Ê†áÊ≥®Ôºå‰∏îËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ÂØπËØù‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂØπÊØîÂ≠¶‰π†Ê®°Âùó‰ΩøÁî®‰∫ÜInfoNCEÊçüÂ§±ÂáΩÊï∞ÔºåÁî®‰∫éÊãâËøëÊ≠£Ê†∑Êú¨ÔºàÁõ∏ÂÖ≥ÁöÑÊâãËØ≠ËßÜÈ¢ëÂíåÈóÆÈ¢òÊñáÊú¨Ôºâ‰πãÈó¥ÁöÑË∑ùÁ¶ªÔºåÊé®ËøúË¥üÊ†∑Êú¨Ôºà‰∏çÁõ∏ÂÖ≥ÁöÑÊâãËØ≠ËßÜÈ¢ëÂíåÈóÆÈ¢òÊñáÊú¨Ôºâ‰πãÈó¥ÁöÑË∑ùÁ¶ª„ÄÇSSAWÊ®°Âùó‰ΩøÁî®‰∫ÜSigmoidÂáΩÊï∞Êù•ÁîüÊàêÊùÉÈáçÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Âä†ÁÅµÊ¥ªÂú∞ÈÄâÊã©ÈáçË¶ÅÁöÑÁâπÂæÅ„ÄÇËá™ÁõëÁù£Â≠¶‰π†Ê®°Âùó‰ΩøÁî®‰∫ÜMasked Language Model (MLM) ÁõÆÊ†áÔºåÁî®‰∫éÈ¢ÑÊµãË¢´maskÊéâÁöÑËØçËØ≠Ôºå‰ªéËÄåÂ¢ûÂº∫ÈóÆÈ¢òÊñáÊú¨ÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SSL-SSAWÂú®CSL-Daily-QAÂíåPHOENIX-2014T-QAÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂà©Áî®ÈóÆÈ¢òËæÖÂä©ÂèØ‰ª•ËææÂà∞ÁîöËá≥Ë∂ÖËøáËØçËØ≠ËæÖÂä©ÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄß„ÄÇÂèØËßÜÂåñÁªìÊûú‰πüË°®ÊòéÔºåÁªìÂêàÂØπËØù‰ø°ÊÅØÂèØ‰ª•ÊúâÊïàÊèêÈ´òÁøªËØëË¥®Èáè„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÊâãËØ≠ÁøªËØëÁ≥ªÁªüÔºåÂ∏ÆÂä©Âê¨Èöú‰∫∫Â£´‰∏éÂÅ•Âê¨‰∫∫Â£´ËøõË°åÊó†ÈöúÁ¢ç‰∫§ÊµÅ„ÄÇ‰æãÂ¶ÇÔºåÂú®ÂÆ¢Êúç„ÄÅÊïôËÇ≤„ÄÅÂåªÁñóÁ≠âÈ¢ÜÂüüÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊäÄÊúØÊûÑÂª∫Ëá™Âä®ÂåñÁöÑÊâãËØ≠ÁøªËØëÊúçÂä°ÔºåÊèêÈ´òÊ≤üÈÄöÊïàÁéáÂíåÊúçÂä°Ë¥®Èáè„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØËøòÂèØ‰ª•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÂ§öÊ®°ÊÄÅÁøªËØë‰ªªÂä°‰∏≠Ôºå‰æãÂ¶ÇËßÜÈ¢ëÂ≠óÂπïÁîüÊàê„ÄÅËØ≠Èü≥ÁøªËØëÁ≠â„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Sign Language Translation (SLT) bridges the communication gap between deaf people and hearing people, where dialogue provides crucial contextual cues to aid in translation. Building on this foundational concept, this paper proposes Question-based Sign Language Translation (QB-SLT), a novel task that explores the efficient integration of dialogue. Unlike gloss (sign language transcription) annotations, dialogue naturally occurs in communication and is easier to annotate. The key challenge lies in aligning multimodality features while leveraging the context of the question to improve translation. To address this issue, we propose a cross-modality Self-supervised Learning with Sigmoid Self-attention Weighting (SSL-SSAW) fusion method for sign language translation. Specifically, we employ contrastive learning to align multimodality features in QB-SLT, then introduce a Sigmoid Self-attention Weighting (SSAW) module for adaptive feature extraction from question and sign language sequences. Additionally, we leverage available question text through self-supervised learning to enhance representation and translation capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably, easily accessible question assistance can achieve or even surpass the performance of gloss assistance. Furthermore, visualization results demonstrate the effectiveness of incorporating dialogue in improving translation quality.

