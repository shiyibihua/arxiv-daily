---
layout: default
title: Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning
---

# Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18163" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18163v1</a>
  <a href="https://arxiv.org/pdf/2509.18163.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18163v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18163v1', 'Thinking in a Crowd: How Auxiliary Information Shapes LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haodong Zhao, Chenyan Zhao, Yansi Li, Zhuosheng Zhang, Gongshen Liu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: Work in progress

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/datasets/billhdzhao)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¾…åŠ©ä¿¡æ¯å¯¹LLMæ¨ç†çš„å½±å“ï¼šæœ‰å®³ä¿¡æ¯ä¼šæ˜¾è‘—é™ä½LLMçš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è¾…åŠ©ä¿¡æ¯` `é²æ£’æ€§` `ä¿¡æ¯è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å®é™…åº”ç”¨ä¸­ä¾èµ–å¤–éƒ¨ä¿¡æ¯ï¼Œä½†å¦‚ä½•ä¿è¯LLMåœ¨é¢å¯¹ä¸ç›¸å…³ç”šè‡³é”™è¯¯ä¿¡æ¯æ—¶ä»èƒ½ä¿æŒæ¨ç†èƒ½åŠ›æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ„å»ºåŒ…å«ä¸åŒç±»å‹è¾…åŠ©ä¿¡æ¯çš„SciAuxæ•°æ®é›†ï¼Œæ¥ç³»ç»Ÿè¯„ä¼°LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯¹è¾…åŠ©ä¿¡æ¯çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMçš„â€œæ€è€ƒæ¨¡å¼â€åœ¨é¢å¯¹è¯¯å¯¼æ€§ä¿¡æ¯æ—¶ä¼šæ”¾å¤§é”™è¯¯ï¼Œè€Œéå¢å¼ºé²æ£’æ€§ï¼Œå‡¸æ˜¾äº†ä¿¡æ¯è¯„ä¼°çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨ç†èƒ½åŠ›æ˜¯å…¶åœ¨å¤æ‚ã€çŸ¥è¯†å¯†é›†å‹é¢†åŸŸåº”ç”¨çš„åŸºç¡€ã€‚åœ¨å®é™…åœºæ™¯ä¸­ï¼ŒLLMé€šå¸¸ä¼šè·å¾—å¤–éƒ¨ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯å¯èƒ½æ˜¯æœ‰å¸®åŠ©çš„ã€ä¸ç›¸å…³çš„ï¼Œç”šè‡³æ˜¯è¯¯å¯¼æ€§çš„ã€‚æœ¬æ–‡ç ”ç©¶äº†è¿™ç§è¾…åŠ©ä¿¡æ¯å¯¹LLMæ¨ç†è¿‡ç¨‹çš„å› æœå½±å“ï¼Œç‰¹åˆ«æ˜¯å½“LLMå…·å¤‡æ˜¾å¼çš„é€æ­¥æ€è€ƒèƒ½åŠ›æ—¶ã€‚æˆ‘ä»¬å¼•å…¥äº†SciAuxï¼Œè¿™æ˜¯ä¸€ä¸ªä»ScienceQAæ´¾ç”Ÿçš„æ–°æ•°æ®é›†ï¼Œç”¨äºç³»ç»Ÿåœ°æµ‹è¯•æ¨¡å‹å¯¹è¿™äº›ç±»å‹ä¿¡æ¯çš„é²æ£’æ€§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ­ç¤ºäº†ä¸€ä¸ªå…³é”®çš„å¼±ç‚¹ï¼šæ¨¡å‹å…·æœ‰çš„â€œæ€è€ƒæ¨¡å¼â€æ˜¯ä¸€æŠŠåŒåˆƒå‰‘ã€‚æœ‰ç”¨çš„ä¸Šä¸‹æ–‡å¯ä»¥æé«˜å‡†ç¡®æ€§ï¼Œä½†è¯¯å¯¼æ€§ä¿¡æ¯ä¼šå¯¼è‡´æ€§èƒ½æ€¥å‰§ä¸‹é™ï¼Œè€Œæ€è€ƒè¿‡ç¨‹ä¼šæ”¾å¤§è¿™ç§å½±å“ã€‚å½“æä¾›é”™è¯¯ä¿¡æ¯æ—¶ï¼Œæ€è€ƒéä½†æ²¡æœ‰å¢å¼ºé²æ£’æ€§ï¼Œåè€ŒåŠ å‰§äº†é”™è¯¯ç¨‹åº¦ã€‚è¿™è¡¨æ˜ï¼ŒæŒ‘æˆ˜ä¸ä»…ä»…æ˜¯è®©æ¨¡å‹â€œæ€è€ƒâ€ï¼Œè€Œæ˜¯èµ‹äºˆå®ƒä»¬è¯„ä¼°æ¨ç†æ‰€ä¾æ®ä¿¡æ¯çš„é‡è¦èƒ½åŠ›ã€‚SciAuxæ•°æ®é›†å¯åœ¨https://huggingface.co/datasets/billhdzhao/SciAux è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå¦‚ä½•å—åˆ°è¾…åŠ©ä¿¡æ¯ï¼ˆåŒ…æ‹¬æœ‰ç”¨çš„ã€ä¸ç›¸å…³çš„å’Œè¯¯å¯¼æ€§çš„ä¿¡æ¯ï¼‰çš„å½±å“ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾LLMèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨æ‰€æœ‰è¾“å…¥ä¿¡æ¯ï¼Œä½†å¿½ç•¥äº†LLMå¯èƒ½æ— æ³•åŒºåˆ†ä¿¡æ¯çš„è´¨é‡ï¼Œä»è€Œå¯¼è‡´æ¨ç†é”™è¯¯ã€‚å°¤å…¶æ˜¯åœ¨LLMå…·å¤‡é€æ­¥æ€è€ƒèƒ½åŠ›æ—¶ï¼Œè¿™ç§é—®é¢˜å¯èƒ½ä¼šè¢«æ”¾å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«ä¸åŒç±»å‹è¾…åŠ©ä¿¡æ¯çš„æ•°æ®é›†ï¼Œæ¥ç³»ç»Ÿåœ°è¯„ä¼°LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯¹è¿™äº›ä¿¡æ¯çš„é²æ£’æ€§ã€‚é€šè¿‡åˆ†æLLMåœ¨ä¸åŒè¾…åŠ©ä¿¡æ¯ä¸‹çš„æ¨ç†è¡¨ç°ï¼Œæ­ç¤ºLLMåœ¨ä¿¡æ¯è¯„ä¼°æ–¹é¢çš„å¼±ç‚¹ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ„å»ºSciAuxæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŸºäºScienceQAï¼Œå¹¶æ·»åŠ äº†ä¸åŒç±»å‹çš„è¾…åŠ©ä¿¡æ¯ï¼›2) ä½¿ç”¨LLMï¼ˆå¦‚GPT-3ï¼‰åœ¨SciAuxæ•°æ®é›†ä¸Šè¿›è¡Œæ¨ç†å®éªŒï¼›3) åˆ†æLLMåœ¨ä¸åŒè¾…åŠ©ä¿¡æ¯ä¸‹çš„æ¨ç†è¡¨ç°ï¼Œè¯„ä¼°å…¶é²æ£’æ€§ï¼›4) æ¢è®¨LLMçš„â€œæ€è€ƒæ¨¡å¼â€å¯¹æ¨ç†ç»“æœçš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†SciAuxæ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯¹è¾…åŠ©ä¿¡æ¯é²æ£’æ€§çš„æ•°æ®é›†ï¼›2) æ­ç¤ºäº†LLMçš„â€œæ€è€ƒæ¨¡å¼â€åœ¨é¢å¯¹è¯¯å¯¼æ€§ä¿¡æ¯æ—¶ä¼šæ”¾å¤§é”™è¯¯ï¼Œè€Œéå¢å¼ºé²æ£’æ€§ï¼›3) å¼ºè°ƒäº†ä¿¡æ¯è¯„ä¼°åœ¨LLMæ¨ç†ä¸­çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šSciAuxæ•°æ®é›†çš„è®¾è®¡å…³é”®åœ¨äºå¦‚ä½•ç”Ÿæˆä¸åŒç±»å‹çš„è¾…åŠ©ä¿¡æ¯ã€‚è®ºæ–‡é‡‡ç”¨äº†å¤šç§æ–¹æ³•ï¼ŒåŒ…æ‹¬ä»ScienceQAä¸­é€‰æ‹©ç›¸å…³çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€éšæœºç”Ÿæˆä¸ç›¸å…³çš„æ–‡æœ¬ã€ä»¥åŠæ•…æ„å¼•å…¥é”™è¯¯çš„çŸ¥è¯†ã€‚å®éªŒä¸­ï¼Œä½¿ç”¨äº†GPT-3ç­‰LLMï¼Œå¹¶é‡‡ç”¨äº†æ ‡å‡†çš„æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼Œå¼•å¯¼LLMè¿›è¡Œé€æ­¥æ€è€ƒã€‚æ²¡æœ‰æåŠå…·ä½“çš„æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ä¿®æ”¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå½“æä¾›æœ‰ç”¨çš„è¾…åŠ©ä¿¡æ¯æ—¶ï¼ŒLLMçš„æ¨ç†å‡†ç¡®ç‡æœ‰æ‰€æé«˜ã€‚ç„¶è€Œï¼Œå½“æä¾›è¯¯å¯¼æ€§ä¿¡æ¯æ—¶ï¼ŒLLMçš„æ€§èƒ½ä¼šæ€¥å‰§ä¸‹é™ï¼Œç”šè‡³ä½äºæ²¡æœ‰è¾…åŠ©ä¿¡æ¯çš„æƒ…å†µã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒLLMçš„â€œæ€è€ƒæ¨¡å¼â€ä¼šæ”¾å¤§è¿™ç§è´Ÿé¢å½±å“ï¼Œå¯¼è‡´é”™è¯¯ç‡æ˜¾è‘—å¢åŠ ã€‚ä¾‹å¦‚ï¼Œåœ¨SciAuxæ•°æ®é›†ä¸Šï¼ŒLLMåœ¨é¢å¯¹è¯¯å¯¼æ€§ä¿¡æ¯æ—¶çš„å‡†ç¡®ç‡ä¸‹é™å¹…åº¦è¶…è¿‡äº†20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨çŸ¥è¯†å¯†é›†å‹é¢†åŸŸçš„å¯é æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—è¯Šæ–­ã€é‡‘èåˆ†æç­‰åœºæ™¯ä¸­ï¼ŒLLMéœ€è¦å¤„ç†å¤§é‡çš„å¤–éƒ¨ä¿¡æ¯ã€‚é€šè¿‡æé«˜LLMå¯¹è¾…åŠ©ä¿¡æ¯çš„è¯„ä¼°èƒ½åŠ›ï¼Œå¯ä»¥å‡å°‘å› é”™è¯¯ä¿¡æ¯å¯¼è‡´çš„å†³ç­–å¤±è¯¯ï¼Œæå‡LLMçš„å®é™…åº”ç”¨ä»·å€¼ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢å¦‚ä½•è®©LLMæ›´å¥½åœ°è¯†åˆ«å’Œè¿‡æ»¤æœ‰å®³ä¿¡æ¯ï¼Œä»è€Œæé«˜å…¶æ¨ç†çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The capacity of Large Language Models (LLMs) to reason is fundamental to their application in complex, knowledge-intensive domains. In real-world scenarios, LLMs are often augmented with external information that can be helpful, irrelevant, or even misleading. This paper investigates the causal impact of such auxiliary information on the reasoning process of LLMs with explicit step-by-step thinking capabilities. We introduce SciAux, a new dataset derived from ScienceQA, to systematically test the robustness of the model against these types of information. Our findings reveal a critical vulnerability: the model's deliberative "thinking mode" is a double-edged sword. While helpful context improves accuracy, misleading information causes a catastrophic drop in performance, which is amplified by the thinking process. Instead of conferring robustness, thinking reinforces the degree of error when provided with misinformation. This highlights that the challenge is not merely to make models "think", but to endow them with the critical faculty to evaluate the information upon which their reasoning is based. The SciAux dataset is available at https://huggingface.co/datasets/billhdzhao/SciAux.

