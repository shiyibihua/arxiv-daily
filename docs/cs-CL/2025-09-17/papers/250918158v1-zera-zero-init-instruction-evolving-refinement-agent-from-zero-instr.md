---
layout: default
title: ZERA: Zero-init Instruction Evolving Refinement Agent -- From Zero Instructions to Structured Prompts via Principle-based Optimization
---

# ZERA: Zero-init Instruction Evolving Refinement Agent -- From Zero Instructions to Structured Prompts via Principle-based Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18158" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18158v1</a>
  <a href="https://arxiv.org/pdf/2509.18158.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18158v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18158v1', 'ZERA: Zero-init Instruction Evolving Refinement Agent -- From Zero Instructions to Structured Prompts via Principle-based Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seungyoun Yi, Minsoo Khang, Sungrae Park

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17

**å¤‡æ³¨**: 9 pages, 4 figures. To appear in EMNLP 2025 Main Conference (Oral Presentation)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/younatics/zera-agent)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ZERAï¼šé›¶åˆå§‹åŒ–æŒ‡ä»¤æ¼”åŒ–ä¼˜åŒ–Agentï¼Œé€šè¿‡åŸºäºåŸåˆ™çš„ä¼˜åŒ–ä»é›¶æŒ‡ä»¤ç”Ÿæˆç»“æ„åŒ–æç¤º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªåŠ¨æç¤ºä¼˜åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹` `æç¤ºå·¥ç¨‹` `é›¶åˆå§‹åŒ–å­¦ä¹ ` `æŒ‡ä»¤æ¼”åŒ–` `ç»“æ„åŒ–åé¦ˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªåŠ¨æç¤ºä¼˜åŒ–æ–¹æ³•ä¾èµ–éç»“æ„åŒ–åé¦ˆï¼Œéœ€è¦å¤§é‡æ ·æœ¬å’Œé•¿è¿­ä»£å‘¨æœŸï¼Œå¯¼è‡´æˆæœ¬é«˜ä¸”æ˜“å‡ºé”™ã€‚
2. ZERAæ¡†æ¶è”åˆä¼˜åŒ–ç³»ç»Ÿå’Œç”¨æˆ·æç¤ºï¼Œé€šè¿‡åŸºäºåŸåˆ™çš„ä½å¼€é”€ä¼˜åŒ–ï¼Œå®ç°å¿«é€Ÿæ”¶æ•›åˆ°é«˜è´¨é‡æç¤ºã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒZERAåœ¨æ¨ç†ã€æ‘˜è¦å’Œä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šï¼Œç›¸å¯¹äºåŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå¹¶å¼€æºäº†å…¨éƒ¨æç¤ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªåŠ¨æç¤ºä¼˜åŒ–(APO)é€šè¿‡æ”¹è¿›ç‰¹å®šä»»åŠ¡çš„æç¤ºæ¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå…ˆå‰çš„APOæ–¹æ³•é€šå¸¸åªå…³æ³¨ç”¨æˆ·æç¤ºï¼Œä¾èµ–äºéç»“æ„åŒ–çš„åé¦ˆï¼Œå¹¶ä¸”éœ€è¦å¤§é‡çš„æ ·æœ¬å’Œè¾ƒé•¿çš„è¿­ä»£å‘¨æœŸï¼Œè¿™ä½¿å¾—å®ƒä»¬æˆæœ¬é«˜æ˜‚ä¸”è„†å¼±ã€‚æˆ‘ä»¬æå‡ºäº†ZERAï¼ˆé›¶åˆå§‹åŒ–æŒ‡ä»¤æ¼”åŒ–ä¼˜åŒ–Agentï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒé€šè¿‡åŸºäºåŸåˆ™çš„ä½å¼€é”€ä¼˜åŒ–ï¼Œè”åˆä¼˜åŒ–ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤ºã€‚ZERAä½¿ç”¨å…«ä¸ªå¯æ³›åŒ–çš„æ ‡å‡†å’Œè‡ªåŠ¨æ¨æ–­çš„æƒé‡æ¥å¯¹æç¤ºè¿›è¡Œè¯„åˆ†ï¼Œå¹¶åŸºäºè¿™äº›ç»“æ„åŒ–çš„è¯„è®ºæ¥ä¿®æ”¹æç¤ºã€‚è¿™ä½¿å¾—å¯ä»¥ä½¿ç”¨æœ€å°‘çš„ç¤ºä¾‹å’ŒçŸ­çš„è¿­ä»£å‘¨æœŸå¿«é€Ÿæ”¶æ•›åˆ°é«˜è´¨é‡çš„æç¤ºã€‚æˆ‘ä»¬åœ¨äº”ä¸ªLLMå’Œä¹ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¯„ä¼°äº†ZERAï¼Œè¿™äº›æ•°æ®é›†æ¶µç›–äº†æ¨ç†ã€æ‘˜è¦å’Œä»£ç ç”Ÿæˆä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç›¸å¯¹äºå¼ºå¤§çš„åŸºçº¿ï¼ŒZERA å…·æœ‰ä¸€è‡´çš„æ”¹è¿›ã€‚è¿›ä¸€æ­¥çš„æ¶ˆèç ”ç©¶çªå‡ºäº†æ¯ä¸ªç»„ä»¶å¯¹æ›´æœ‰æ•ˆçš„æç¤ºæ„å»ºçš„è´¡çŒ®ã€‚æˆ‘ä»¬çš„å®ç°ï¼ˆåŒ…æ‹¬æ‰€æœ‰æç¤ºï¼‰å¯åœ¨https://github.com/younatics/zera-agent å…¬å¼€è·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è‡ªåŠ¨æç¤ºä¼˜åŒ–ï¼ˆAPOï¼‰æ–¹æ³•ä¸»è¦å…³æ³¨ç”¨æˆ·æç¤ºï¼Œä¾èµ–éç»“æ„åŒ–åé¦ˆï¼Œéœ€è¦å¤§é‡æ ·æœ¬å’Œé•¿è¿­ä»£å‘¨æœŸï¼Œå¯¼è‡´ä¼˜åŒ–è¿‡ç¨‹æˆæœ¬é«˜æ˜‚ä¸”è„†å¼±ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥å¿«é€Ÿæœ‰æ•ˆåœ°æ‰¾åˆ°é«˜è´¨é‡çš„æç¤ºï¼Œé™åˆ¶äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šZERAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è”åˆä¼˜åŒ–ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤ºï¼Œå¹¶å¼•å…¥åŸºäºåŸåˆ™çš„ç»“æ„åŒ–åé¦ˆæœºåˆ¶ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æç¤ºä¼˜åŒ–ã€‚ZERAä¸å†ä¾èµ–äººå·¥è®¾è®¡çš„æç¤ºæˆ–éç»“æ„åŒ–åé¦ˆï¼Œè€Œæ˜¯ä»é›¶å¼€å§‹ï¼Œé€šè¿‡è¿­ä»£æ¼”åŒ–æ¥ç”Ÿæˆé«˜è´¨é‡çš„æç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šZERAæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æç¤ºç”Ÿæˆæ¨¡å—ï¼Œç”¨äºåˆå§‹åŒ–ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤ºï¼›2) æç¤ºè¯„åˆ†æ¨¡å—ï¼Œä½¿ç”¨å…«ä¸ªå¯æ³›åŒ–çš„æ ‡å‡†ï¼ˆä¾‹å¦‚ï¼Œç›¸å…³æ€§ã€ç®€æ´æ€§ã€æµç•…æ€§ç­‰ï¼‰å’Œè‡ªåŠ¨æ¨æ–­çš„æƒé‡å¯¹æç¤ºè¿›è¡Œè¯„åˆ†ï¼›3) æç¤ºä¿®æ”¹æ¨¡å—ï¼ŒåŸºäºç»“æ„åŒ–çš„è¯„è®ºæ¥ä¿®æ”¹æç¤ºï¼Œæå‡æç¤ºè´¨é‡ã€‚æ•´ä¸ªæµç¨‹é€šè¿‡è¿­ä»£å¾ªç¯è¿›è¡Œï¼Œç›´åˆ°æç¤ºè´¨é‡è¾¾åˆ°é¢„è®¾é˜ˆå€¼æˆ–è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šZERAçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) è”åˆä¼˜åŒ–ç³»ç»Ÿæç¤ºå’Œç”¨æˆ·æç¤ºï¼Œå……åˆ†åˆ©ç”¨äº†ç³»ç»Ÿæç¤ºçš„å¼•å¯¼ä½œç”¨ï¼›2) å¼•å…¥åŸºäºåŸåˆ™çš„ç»“æ„åŒ–åé¦ˆæœºåˆ¶ï¼Œé¿å…äº†å¯¹éç»“æ„åŒ–åé¦ˆçš„ä¾èµ–ï¼Œæé«˜äº†ä¼˜åŒ–æ•ˆç‡ï¼›3) é‡‡ç”¨è‡ªåŠ¨æ¨æ–­çš„æƒé‡ï¼Œä½¿å¾—è¯„åˆ†æ ‡å‡†èƒ½å¤Ÿè‡ªé€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œæ•°æ®é›†ã€‚

**å…³é”®è®¾è®¡**ï¼šZERAä½¿ç”¨å…«ä¸ªå¯æ³›åŒ–çš„æ ‡å‡†æ¥è¯„ä¼°æç¤ºçš„è´¨é‡ï¼Œè¿™äº›æ ‡å‡†åŒ…æ‹¬ç›¸å…³æ€§ã€ç®€æ´æ€§ã€æµç•…æ€§ã€å®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€ä¸€è‡´æ€§ã€é€»è¾‘æ€§å’Œåˆ›é€ æ€§ã€‚æ¯ä¸ªæ ‡å‡†çš„æƒé‡é€šè¿‡è‡ªåŠ¨æ¨æ–­å¾—åˆ°ï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œæ•°æ®é›†ã€‚æç¤ºä¿®æ”¹æ¨¡å—ä½¿ç”¨åŸºäºè§„åˆ™çš„æ–¹æ³•æ¥ä¿®æ”¹æç¤ºï¼Œä¾‹å¦‚ï¼Œæ·»åŠ å…³é”®è¯ã€åˆ é™¤å†—ä½™ä¿¡æ¯ã€è°ƒæ•´å¥å­ç»“æ„ç­‰ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒZERAåœ¨äº”ä¸ªLLMå’Œä¹ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šï¼Œç›¸å¯¹äºå¼ºå¤§çš„åŸºçº¿æ¨¡å‹ï¼Œåœ¨æ¨ç†ã€æ‘˜è¦å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒZERAçš„å„ä¸ªç»„ä»¶éƒ½å¯¹æç¤ºæ„å»ºçš„æœ‰æ•ˆæ€§åšå‡ºäº†è´¡çŒ®ã€‚ZERAèƒ½å¤Ÿä½¿ç”¨æœ€å°‘çš„ç¤ºä¾‹å’ŒçŸ­çš„è¿­ä»£å‘¨æœŸå¿«é€Ÿæ”¶æ•›åˆ°é«˜è´¨é‡çš„æç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ZERAå¯åº”ç”¨äºå„ç§éœ€è¦æç¤ºå·¥ç¨‹çš„å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€æ–‡æœ¬æ‘˜è¦ã€ä»£ç ç”Ÿæˆã€æœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡è‡ªåŠ¨ä¼˜åŒ–æç¤ºï¼ŒZERAå¯ä»¥æ˜¾è‘—æé«˜LLMçš„æ€§èƒ½ï¼Œé™ä½äººå·¥æˆæœ¬ï¼Œå¹¶åŠ é€ŸLLMåœ¨å„è¡Œä¸šçš„è½åœ°ã€‚æœªæ¥ï¼ŒZERAå¯ä»¥æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€å’Œä»»åŠ¡ï¼Œå¹¶ä¸å…¶ä»–APOæŠ€æœ¯ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥æå‡LLMçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Automatic Prompt Optimization (APO) improves large language model (LLM) performance by refining prompts for specific tasks. However, prior APO methods typically focus only on user prompts, rely on unstructured feedback, and require large sample sizes and long iteration cycles-making them costly and brittle. We propose ZERA (Zero-init Instruction Evolving Refinement Agent), a novel framework that jointly optimizes both system and user prompts through principled, low-overhead refinement. ZERA scores prompts using eight generalizable criteria with automatically inferred weights, and revises prompts based on these structured critiques. This enables fast convergence to high-quality prompts using minimal examples and short iteration cycles. We evaluate ZERA across five LLMs and nine diverse datasets spanning reasoning, summarization, and code generation tasks. Experimental results demonstrate consistent improvements over strong baselines. Further ablation studies highlight the contribution of each component to more effective prompt construction. Our implementation including all prompts is publicly available at https://github.com/younatics/zera-agent.

