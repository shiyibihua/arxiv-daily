---
layout: default
title: Semantic uncertainty in advanced decoding methods for LLM generation
---

# Semantic uncertainty in advanced decoding methods for LLM generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17296" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17296v1</a>
  <a href="https://arxiv.org/pdf/2506.17296.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17296v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17296v1', 'Semantic uncertainty in advanced decoding methods for LLM generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Darius Foodeei, Simin Fan, Martin Jaggi

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§£ç æ–¹æ³•ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸­çš„è¯­ä¹‰ä¸ç¡®å®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è§£ç æ–¹æ³•` `è¯­ä¹‰ä¸ç¡®å®šæ€§` `æ¨æµ‹é‡‡æ ·` `æ€ç»´é“¾è§£ç ` `ä»£ç ç”Ÿæˆ` `æ–‡æœ¬æ‘˜è¦` `æ¨¡å‹è¾“å‡ºè´¨é‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§£ç æ–¹æ³•åœ¨ç”Ÿæˆå¤šæ ·æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œå¯¼è‡´æ¨¡å‹è¾“å‡ºçš„å¯é æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºäº†æ¨æµ‹é‡‡æ ·å’Œæ€ç»´é“¾è§£ç ç­‰æ–°è§£ç ç­–ç•¥ï¼Œä»¥å¢å¼ºè¯­ä¹‰æ¢ç´¢å’Œè¾“å‡ºè´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCoTè§£ç åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­æå‡äº†48.8%çš„Pass@2ç‡ï¼Œæ¨æµ‹é‡‡æ ·åœ¨æ‘˜è¦ä»»åŠ¡ä¸­è·å¾—äº†æ›´é«˜çš„ROUGEåˆ†æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¾“å‡ºä¸­çš„è¯­ä¹‰ä¸ç¡®å®šæ€§ï¼Œé‡ç‚¹å…³æ³¨æ–°å…´çš„è§£ç æŠ€æœ¯ï¼Œå¦‚æ¨æµ‹é‡‡æ ·å’Œæ€ç»´é“¾ï¼ˆCoTï¼‰è§£ç ã€‚é€šè¿‡åœ¨é—®ç­”ã€æ‘˜è¦å’Œä»£ç ç”Ÿæˆä»»åŠ¡ä¸Šçš„å®éªŒï¼Œæˆ‘ä»¬åˆ†æäº†ä¸åŒè§£ç ç­–ç•¥å¦‚ä½•å½±å“æ¨¡å‹è¾“å‡ºçš„å¤šæ ·æ€§å’Œå¯é æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡CoTè§£ç å±•ç¤ºäº†æ›´é«˜çš„è¯­ä¹‰å¤šæ ·æ€§ï¼Œä½†å…¶é¢„æµ‹ç†µè¾ƒä½ï¼Œè¡¨æ˜ç»“æ„åŒ–æ¢ç´¢å¯ä»¥å¯¼è‡´æ›´è‡ªä¿¡å’Œå‡†ç¡®çš„è¾“å‡ºã€‚åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒPass@2çš„æå‡è¾¾åˆ°äº†48.8%ï¼Œå°½ç®¡ä¸å‚è€ƒè§£å†³æ–¹æ¡ˆçš„å¯¹é½åº¦è¾ƒä½ã€‚å¯¹äºæ‘˜è¦ä»»åŠ¡ï¼Œæ¨æµ‹é‡‡æ ·è¡¨ç°å°¤ä¸ºæœ‰æ•ˆï¼Œè·å¾—äº†æ›´ä¼˜çš„ROUGEåˆ†æ•°ï¼ŒåŒæ—¶ä¿æŒäº†é€‚åº¦çš„è¯­ä¹‰å¤šæ ·æ€§ã€‚è¿™äº›ç»“æœæŒ‘æˆ˜äº†å…³äºè¯­è¨€æ¨¡å‹è¾“å‡ºå¤šæ ·æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´æƒè¡¡çš„ä¼ ç»Ÿå‡è®¾ï¼Œè¡¨æ˜é€‚å½“ç»“æ„åŒ–çš„è§£ç æ–¹æ³•å¯ä»¥åœ¨ä¿æŒæˆ–æé«˜è¾“å‡ºè´¨é‡çš„åŒæ—¶å¢åŠ è¯­ä¹‰æ¢ç´¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆè¿‡ç¨‹ä¸­å­˜åœ¨çš„è¯­ä¹‰ä¸ç¡®å®šæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„æƒè¡¡å¯¼è‡´è¾“å‡ºè´¨é‡ä¸ç¨³å®šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥æ¨æµ‹é‡‡æ ·å’Œæ€ç»´é“¾è§£ç ç­‰æ–°å‹è§£ç ç­–ç•¥ï¼Œè®ºæ–‡æ—¨åœ¨å®ç°æ›´é«˜çš„è¯­ä¹‰å¤šæ ·æ€§å’Œæ›´ä½çš„é¢„æµ‹ç†µï¼Œä»è€Œæé«˜æ¨¡å‹è¾“å‡ºçš„å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å®éªŒæ–¹æ³•ï¼Œé’ˆå¯¹é—®ç­”ã€æ‘˜è¦å’Œä»£ç ç”Ÿæˆä»»åŠ¡ï¼Œæ¯”è¾ƒä¸åŒè§£ç ç­–ç•¥çš„æ•ˆæœã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€è§£ç ç­–ç•¥åº”ç”¨åŠç»“æœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†ç»“æ„åŒ–çš„è§£ç æ–¹æ³•ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„å¤šæ ·æ€§ä¸å‡†ç¡®æ€§æƒè¡¡å‡è®¾ï¼Œå±•ç¤ºäº†å¦‚ä½•é€šè¿‡é€‚å½“çš„è§£ç ç­–ç•¥å®ç°æ›´é«˜çš„è¾“å‡ºè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨ä»£ç ç”Ÿæˆå’Œæ‘˜è¦ä»»åŠ¡ä¸­ï¼Œç¡®ä¿äº†è¾“å‡ºçš„å¤šæ ·æ€§ä¸å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ€ç»´é“¾è§£ç åœ¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­å®ç°äº†48.8%çš„Pass@2ç‡æå‡ï¼Œå°½ç®¡ä¸å‚è€ƒè§£å†³æ–¹æ¡ˆçš„å¯¹é½åº¦è¾ƒä½ã€‚åŒæ—¶ï¼Œæ¨æµ‹é‡‡æ ·åœ¨æ‘˜è¦ä»»åŠ¡ä¸­è·å¾—äº†æ›´é«˜çš„ROUGEåˆ†æ•°ï¼Œè¯æ˜äº†å…¶åœ¨è¯­ä¹‰å¤šæ ·æ€§å’Œè¾“å‡ºè´¨é‡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœåœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰é‡è¦ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç”Ÿæˆå¤šæ ·åŒ–ä¸”å¯é çš„æ–‡æœ¬è¾“å‡ºçš„åœºæ™¯ï¼Œå¦‚æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨æ‘˜è¦ç”Ÿæˆå’Œä»£ç è‡ªåŠ¨åŒ–ç­‰é¢†åŸŸã€‚æœªæ¥ï¼Œè¿™äº›è§£ç æ–¹æ³•å¯èƒ½ä¼šæ¨åŠ¨è¯­è¨€æ¨¡å‹åœ¨æ›´å¹¿æ³›åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study investigates semantic uncertainty in large language model (LLM) outputs across different decoding methods, focusing on emerging techniques like speculative sampling and chain-of-thought (CoT) decoding. Through experiments on question answering, summarization, and code generation tasks, we analyze how different decoding strategies affect both the diversity and reliability of model outputs. Our findings reveal that while CoT decoding demonstrates higher semantic diversity, it maintains lower predictive entropy, suggesting that structured exploration can lead to more confident and accurate outputs. This is evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower alignment with reference solutions. For summarization tasks, speculative sampling proved particularly effective, achieving superior ROUGE scores while maintaining moderate semantic diversity. Our results challenge conventional assumptions about trade-offs between diversity and accuracy in language model outputs, demonstrating that properly structured decoding methods can increase semantic exploration while maintaining or improving output quality. These findings have significant implications for deploying language models in practical applications where both reliability and diverse solution generation are crucial.

