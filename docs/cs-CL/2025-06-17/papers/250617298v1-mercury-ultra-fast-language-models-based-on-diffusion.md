---
layout: default
title: Mercury: Ultra-Fast Language Models Based on Diffusion
---

# Mercury: Ultra-Fast Language Models Based on Diffusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17298" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17298v1</a>
  <a href="https://arxiv.org/pdf/2506.17298.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17298v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17298v1', 'Mercury: Ultra-Fast Language Models Based on Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Inception Labs, Samar Khanna, Siddhant Kharbanda, Shufan Li, Harshit Varma, Eric Wang, Sawyer Birnbaum, Ziyang Luo, Yanis Miraoui, Akash Palrecha, Stefano Ermon, Aditya Grover, Volodymyr Kuleshov

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

**å¤‡æ³¨**: 15 pages; equal core, cross-function, senior authors listed alphabetically

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMercuryä»¥å®ç°è¶…å¿«çš„è¯­è¨€æ¨¡å‹ï¼Œæå‡ç¼–ç¨‹æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¼–ç¨‹åº”ç”¨` `Transformeræ¶æ„` `é€Ÿåº¦ä¼˜åŒ–` `ä»£ç ç”Ÿæˆ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¯­è¨€æ¨¡å‹åœ¨å¤„ç†é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œå°¤å…¶åœ¨ç¼–ç¨‹åº”ç”¨ä¸­è¡¨ç°ä¸ä½³ã€‚
2. Mercuryé€šè¿‡åŸºäºæ‰©æ•£çš„æ¨¡å‹è®¾è®¡ï¼Œé‡‡ç”¨Transformeræ¶æ„å¹¶è¡Œé¢„æµ‹å¤šä¸ªæ ‡è®°ï¼Œä»è€Œæå‡å¤„ç†é€Ÿåº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMercury Coder Miniå’ŒSmallåœ¨é€Ÿåº¦ä¸Šåˆ†åˆ«è¾¾åˆ°1109å’Œ737ä¸ªæ ‡è®°/ç§’ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰é€Ÿåº¦ä¼˜åŒ–æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†Mercuryï¼Œä¸€ç§åŸºäºæ‰©æ•£çš„å•†ä¸šè§„æ¨¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚è¿™äº›æ¨¡å‹é‡‡ç”¨Transformeræ¶æ„è¿›è¡Œå‚æ•°åŒ–ï¼Œå¹¶è®­ç»ƒä»¥å¹¶è¡Œé¢„æµ‹å¤šä¸ªæ ‡è®°ã€‚æœ¬æ–‡è¯¦ç»†ä»‹ç»äº†Mercury Coderï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸ºç¼–ç åº”ç”¨è®¾è®¡çš„é¦–æ‰¹æ‰©æ•£LLMsã€‚Mercury Coderç›®å‰æœ‰Miniå’ŒSmallä¸¤ä¸ªç‰ˆæœ¬ï¼Œåœ¨é€Ÿåº¦å’Œè´¨é‡çš„å¹³è¡¡ä¸Šè®¾ç«‹äº†æ–°çš„è¡Œä¸šæ ‡æ†ã€‚æ ¹æ®ç‹¬ç«‹è¯„ä¼°ï¼ŒMercury Coder Miniå’ŒSmallåœ¨NVIDIA H100 GPUä¸Šåˆ†åˆ«è¾¾åˆ°äº†1109å’Œ737ä¸ªæ ‡è®°/ç§’çš„å¤„ç†é€Ÿåº¦ï¼Œå¹³å‡è¶…è¶Šé€Ÿåº¦ä¼˜åŒ–æ¨¡å‹10å€ï¼ŒåŒæ—¶ä¿æŒç›¸å½“çš„è´¨é‡ã€‚æˆ‘ä»¬è¿˜è®¨è®ºäº†å¤šç§ç¼–ç¨‹è¯­è¨€å’Œç”¨ä¾‹çš„åŸºå‡†æµ‹è¯•ç»“æœï¼Œä»¥åŠåœ¨Copilot Arenaçš„å¼€å‘è€…å®é™…éªŒè¯ï¼Œæ¨¡å‹åœ¨è´¨é‡ä¸Šæ’åç¬¬äºŒï¼Œå¹¶ä¸”æ˜¯æ•´ä½“æœ€å¿«çš„æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å‘å¸ƒäº†å…¬å…±APIå’Œå…è´¹çš„åœ¨çº¿å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è¯­è¨€æ¨¡å‹åœ¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„æƒè¡¡ï¼Œå°¤å…¶åœ¨ç¼–ç¨‹ä»»åŠ¡ä¸­ï¼Œå¤„ç†é€Ÿåº¦å¾€å¾€æ— æ³•æ»¡è¶³å®é™…éœ€æ±‚ï¼Œå¯¼è‡´å¼€å‘æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMercuryé€šè¿‡å¼•å…¥æ‰©æ•£æ¨¡å‹çš„æ¦‚å¿µï¼Œåˆ©ç”¨Transformeræ¶æ„å¹¶è¡Œå¤„ç†å¤šä¸ªæ ‡è®°ï¼Œä»è€Œå®ç°æ›´é«˜çš„å¤„ç†é€Ÿåº¦å’Œè´¨é‡å¹³è¡¡ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¿æŒè¾“å‡ºè´¨é‡çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMercuryçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ•°æ®ç»è¿‡é¢„å¤„ç†åè¾“å…¥åˆ°åŸºäºTransformerçš„æ‰©æ•£æ¨¡å‹ä¸­è¿›è¡Œè®­ç»ƒï¼Œæœ€ååœ¨æ¨ç†é˜¶æ®µå®ç°å¹¶è¡Œæ ‡è®°é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMercuryçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åŸºäºæ‰©æ•£çš„è®­ç»ƒæ–¹æ³•å’Œå¹¶è¡Œé¢„æµ‹èƒ½åŠ›ï¼Œè¿™ä¸ä¼ ç»Ÿçš„è‡ªå›å½’æ¨¡å‹å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œåè€…é€šå¸¸åœ¨ç”Ÿæˆæ—¶ä¾èµ–äºå‰ä¸€ä¸ªæ ‡è®°çš„è¾“å‡ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼ŒMercuryé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¹¶è¡Œé¢„æµ‹çš„æ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”æ‰©æ•£è¿‡ç¨‹çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMercury Coder Miniå’ŒSmallåœ¨NVIDIA H100 GPUä¸Šåˆ†åˆ«å®ç°äº†1109å’Œ737ä¸ªæ ‡è®°/ç§’çš„å¤„ç†é€Ÿåº¦ï¼Œè¶…è¶Šç°æœ‰é€Ÿåº¦ä¼˜åŒ–æ¨¡å‹10å€ï¼ŒåŒæ—¶ä¿æŒç›¸ä¼¼çš„è¾“å‡ºè´¨é‡ã€‚æ­¤å¤–ï¼Œåœ¨Copilot Arenaä¸­ï¼ŒMercury Coderåœ¨è´¨é‡ä¸Šæ’åç¬¬äºŒï¼Œæ•´ä½“é€Ÿåº¦æœ€å¿«ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Mercuryçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¼–ç¨‹åŠ©æ‰‹ã€ä»£ç ç”Ÿæˆå’Œè‡ªåŠ¨åŒ–æµ‹è¯•ç­‰ã€‚å…¶é«˜æ•ˆçš„å¤„ç†èƒ½åŠ›å’Œä¼˜è´¨çš„è¾“å‡ºä½¿å…¶åœ¨è½¯ä»¶å¼€å‘ã€æ•°æ®ç§‘å­¦å’Œæ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸå…·æœ‰å®é™…ä»·å€¼ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å¼€å‘è€…çš„å·¥ä½œæ•ˆç‡ã€‚æœªæ¥ï¼ŒMercuryæœ‰æœ›æ¨åŠ¨æ›´å¤šåŸºäºè‡ªç„¶è¯­è¨€å¤„ç†çš„æ™ºèƒ½åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Mercury, a new generation of commercial-scale large language models (LLMs) based on diffusion. These models are parameterized via the Transformer architecture and trained to predict multiple tokens in parallel. In this report, we detail Mercury Coder, our first set of diffusion LLMs designed for coding applications. Currently, Mercury Coder comes in two sizes: Mini and Small. These models set a new state-of-the-art on the speed-quality frontier. Based on independent evaluations conducted by Artificial Analysis, Mercury Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109 tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform speed-optimized frontier models by up to 10x on average while maintaining comparable quality. We discuss additional results on a variety of code benchmarks spanning multiple languages and use-cases as well as real-world validation by developers on Copilot Arena, where the model currently ranks second on quality and is the fastest model overall. We also release a public API at https://platform.inceptionlabs.ai/ and free playground at https://chat.inceptionlabs.ai

