---
layout: default
title: Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality
---

# Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14681" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14681v2</a>
  <a href="https://arxiv.org/pdf/2506.14681.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14681v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14681v2', 'Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuto Harada, Yusuke Yamauchi, Yusuke Oda, Yohei Oseki, Yusuke Miyao, Yu Takagi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17 (æ›´æ–°: 2025-10-30)

**å¤‡æ³¨**: Accepted to EMNLP 2025 (Main Conference). Models and evaluation results available at: https://github.com/llm-jp/massive-sft

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/llm-jp/massive-sft)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¤§è§„æ¨¡ç›‘ç£å¾®è°ƒå®éªŒæ­ç¤ºæ•°æ®ä¸è®­ç»ƒå› ç´ å¯¹LLMå¯¹é½è´¨é‡çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç›‘ç£å¾®è°ƒ` `å¯¹é½è´¨é‡` `å›°æƒ‘åº¦` `æ¨¡å‹ç‰¹æ€§` `æ€§èƒ½æå‡` `æ•°æ®é›†åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›‘ç£å¾®è°ƒæ–¹æ³•å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹é½è´¨é‡å½±å“å› ç´ å°šä¸æ˜ç¡®ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ç¨³å®šã€‚
2. æœ¬ç ”ç©¶é€šè¿‡è®­ç»ƒå¤šç§åŸºç¡€æ¨¡å‹å¹¶åˆ†ææ•°æ®é›†ç‰¹æ€§ï¼Œæå‡ºäº†æ¨¡å‹ç‰¹å®šçš„å¾®è°ƒç­–ç•¥ä»¥æé«˜å¯¹é½è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå›°æƒ‘åº¦æ˜¯é¢„æµ‹SFTæœ‰æ•ˆæ€§çš„å¯é æŒ‡æ ‡ï¼Œä¸­é—´å±‚æƒé‡å˜åŒ–ä¸æ€§èƒ½æå‡ç›¸å…³æ€§æœ€å¼ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ˜¯å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸äººç±»æŒ‡ä»¤å’Œä»·å€¼è§‚å¯¹é½çš„é‡è¦æ­¥éª¤ï¼Œä½†è®¸å¤šSFTçš„æ–¹é¢ä»ç„¶ä¸å¤Ÿæ¸…æ™°ã€‚æˆ‘ä»¬åœ¨å¤šç§æ•°æ®é›†ä¸Šè®­ç»ƒäº†å¹¿æ³›çš„åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬ä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†å’Œé€šç”¨ä»»åŠ¡ï¼Œç»“æœç”Ÿæˆäº†1000å¤šä¸ªSFTæ¨¡å‹ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºæœ€é‡è¦çš„æ•°æ®é›†ç‰¹æ€§ï¼Œå¹¶è€ƒå¯Ÿäº†SFTå¼•å…¥çš„å±‚çº§ä¿®æ”¹ã€‚ç ”ç©¶å‘ç°æŸäº›è®­ç»ƒä»»åŠ¡çš„ååŒæ•ˆåº”åœ¨æ‰€æœ‰æ¨¡å‹ä¸­æŒç»­å­˜åœ¨ï¼Œè€Œå…¶ä»–åˆ™æœ‰æ˜¾è‘—å·®å¼‚ï¼Œå¼ºè°ƒäº†æ¨¡å‹ç‰¹å®šç­–ç•¥çš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å±•ç¤ºäº†å›°æƒ‘åº¦ï¼ˆperplexityï¼‰èƒ½å¤ŸæŒç»­é¢„æµ‹SFTçš„æœ‰æ•ˆæ€§ï¼Œé€šå¸¸è¶…è¶Šè®­ç»ƒæ•°æ®ä¸åŸºå‡†ä¹‹é—´çš„è¡¨é¢ç›¸ä¼¼æ€§ï¼Œè€Œä¸­é—´å±‚æƒé‡çš„å˜åŒ–ä¸æ€§èƒ½æå‡çš„ç›¸å…³æ€§æœ€å¼ºã€‚æˆ‘ä»¬å‘å¸ƒäº†è¿™äº›1000å¤šä¸ªSFTæ¨¡å‹åŠåŸºå‡†ç»“æœï¼Œä»¥åŠ é€Ÿåç»­ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰è¿‡ç¨‹ä¸­å¯¹é½è´¨é‡ä¸ç¨³å®šçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¯¹å½±å“å› ç´ çš„ç†è§£ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å·®å¼‚æ˜¾è‘—ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒå¤šç§åŸºç¡€æ¨¡å‹å¹¶åœ¨å¤šæ ·åŒ–æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè¯†åˆ«å‡ºå½±å“SFTæ•ˆæœçš„å…³é”®æ•°æ®é›†ç‰¹æ€§ï¼Œå¹¶åˆ†æå±‚çº§ä¿®æ”¹çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåœ¨æ§åˆ¶æ¡ä»¶ä¸‹è®­ç»ƒäº†1000å¤šä¸ªSFTæ¨¡å‹ï¼Œéšåé€šè¿‡å¯¹æ¯”åˆ†æä¸åŒæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œæ¢è®¨æ•°æ®é›†ç‰¹æ€§ä¸æ¨¡å‹å±‚çº§ä¿®æ”¹çš„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†å›°æƒ‘åº¦ä½œä¸ºé¢„æµ‹SFTæœ‰æ•ˆæ€§çš„æŒ‡æ ‡ï¼Œå…¶æœ‰æ•ˆæ€§è¶…è¶Šäº†è®­ç»ƒæ•°æ®ä¸åŸºå‡†çš„è¡¨é¢ç›¸ä¼¼æ€§ã€‚æ­¤å¤–ï¼Œå‘ç°ä¸­é—´å±‚æƒé‡å˜åŒ–ä¸æ€§èƒ½æå‡çš„å¼ºç›¸å…³æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œè®¾ç½®äº†ä¸åŒçš„è¶…å‚æ•°ï¼Œå¹¶å¯¹æ¨¡å‹çš„ä¸­é—´å±‚æƒé‡è¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œä»¥è¯„ä¼°å…¶å¯¹æœ€ç»ˆæ€§èƒ½çš„å½±å“ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå›°æƒ‘åº¦æ˜¯é¢„æµ‹SFTæœ‰æ•ˆæ€§çš„å¯é æŒ‡æ ‡ï¼Œå…¶æ•ˆæœé€šå¸¸ä¼˜äºè®­ç»ƒæ•°æ®ä¸åŸºå‡†ä¹‹é—´çš„è¡¨é¢ç›¸ä¼¼æ€§ã€‚ä¸­é—´å±‚æƒé‡çš„å˜åŒ–ä¸æ€§èƒ½æå‡ä¹‹é—´çš„ç›¸å…³æ€§æœ€å¼ºï¼Œå¼ºè°ƒäº†æ¨¡å‹ç‰¹å®šç­–ç•¥çš„é‡è¦æ€§ã€‚ç ”ç©¶å‘å¸ƒçš„1000å¤šä¸ªSFTæ¨¡å‹ä¸ºåç»­ç ”ç©¶æä¾›äº†å®è´µçš„èµ„æºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æˆæœå¯å¹¿æ³›åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»ä»·å€¼è§‚å’ŒæŒ‡ä»¤å¯¹é½çš„ä»»åŠ¡ä¸­ã€‚é€šè¿‡ä¼˜åŒ–å¾®è°ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œä¿ƒè¿›äººæœºäº¤äº’çš„è‡ªç„¶æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœä¹Ÿå¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒæ–¹æ³•å’Œå¯¹é½ç­–ç•¥çš„å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Supervised fine-tuning (SFT) is a critical step in aligning large language models (LLMs) with human instructions and values, yet many aspects of SFT remain poorly understood. We trained a wide range of base models on a variety of datasets including code generation, mathematical reasoning, and general-domain tasks, resulting in 1,000+ SFT models under controlled conditions. We then identified the dataset properties that matter most and examined the layer-wise modifications introduced by SFT. Our findings reveal that some training-task synergies persist across all models while others vary substantially, emphasizing the importance of model-specific strategies. Moreover, we demonstrate that perplexity consistently predicts SFT effectiveness, often surpassing superficial similarity between the training data and the benchmark, and that mid-layer weight changes correlate most strongly with performance gains. We release these 1,000+ SFT models and benchmark results to accelerate further research. All resources are available at https://github.com/llm-jp/massive-sft.

