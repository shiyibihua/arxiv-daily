---
layout: default
title: Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments
---

# Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14645" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14645v1</a>
  <a href="https://arxiv.org/pdf/2506.14645.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14645v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14645v1', 'Passing the Turing Test in Political Discourse: Fine-Tuning LLMs to Mimic Polarized Social Media Comments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: . Pazzaglia, V. Vendetti, L. D. Comencini, F. Deriu, V. Modugno

**åˆ†ç±»**: cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹æ¨¡æ‹ŸæåŒ–ç¤¾äº¤åª’ä½“è¯„è®º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æåŒ–è¯è¯­` `ç¤¾äº¤åª’ä½“` `å¾®è°ƒ` `æ”¿æ²»è¯„è®º` `è™šå‡ä¿¡æ¯` `AIä¼¦ç†` `å†…å®¹ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ”¿æ²»è¯„è®ºæ—¶å¯èƒ½åŠ å‰§æ„è¯†å½¢æ€æåŒ–ï¼Œç¼ºä¹æœ‰æ•ˆçš„æ§åˆ¶æœºåˆ¶ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡å¾®è°ƒå¼€æºLLMï¼Œæ—¨åœ¨ç”Ÿæˆä¸ç‰¹å®šæ”¿æ²»ç«‹åœºä¸€è‡´çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å“åº”ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„LLMèƒ½å¤Ÿç”Ÿæˆä¸äººç±»è¯„è®ºç›¸ä¼¼çš„å†…å®¹ï¼Œæå‡äº†è¯„è®ºçš„å¯ä¿¡åº¦å’ŒæŒ‘è¡…æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ—¥ç›Šæˆç†Ÿï¼Œå…³äºå…¶åœ¨åŠ å‰§æ„è¯†å½¢æ€æåŒ–æ–¹é¢çš„æ½œåœ¨ä½œç”¨å¼•å‘äº†è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å¾®è°ƒçš„LLMsåœ¨åœ¨çº¿ç¯å¢ƒä¸­å¤åˆ¶å’Œæ”¾å¤§æåŒ–è¯è¯­çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨ä»Redditæå–çš„æ”¿æ²»è®¨è®ºæ•°æ®é›†ï¼Œå¯¹å¼€æºLLMè¿›è¡Œå¾®è°ƒï¼Œä»¥ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥å’Œæ„è¯†å½¢æ€ä¸€è‡´çš„å“åº”ã€‚é€šè¿‡è¯­è¨€åˆ†æã€æƒ…æ„Ÿè¯„åˆ†å’Œäººå·¥æ ‡æ³¨è¯„ä¼°æ¨¡å‹è¾“å‡ºï¼Œç‰¹åˆ«å…³æ³¨å…¶å¯ä¿¡åº¦å’Œä¸åŸå§‹è¯è¯­çš„ä¿®è¾ä¸€è‡´æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå½“åœ¨å…šæ´¾æ•°æ®ä¸Šè®­ç»ƒæ—¶ï¼ŒLLMsèƒ½å¤Ÿç”Ÿæˆé«˜åº¦å¯ä¿¡ä¸”æŒ‘è¡…çš„è¯„è®ºï¼Œå¸¸å¸¸éš¾ä»¥ä¸äººç±»æ’°å†™çš„å†…å®¹åŒºåˆ†ã€‚è¿™äº›å‘ç°å¼•å‘äº†å…³äºAIåœ¨æ”¿æ²»è¯è¯­ã€è™šå‡ä¿¡æ¯å’Œæ“æ§æ´»åŠ¨ä¸­çš„ä½¿ç”¨çš„é‡å¤§ä¼¦ç†é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ”¿æ²»è¯è¯­ä¸­å¯èƒ½åŠ å‰§æ„è¯†å½¢æ€æåŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æœºåˆ¶æ¥æ§åˆ¶ç”Ÿæˆå†…å®¹çš„åè§å’ŒæåŒ–ç‰¹å¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å¾®è°ƒå¼€æºLLMï¼Œåˆ©ç”¨æ”¿æ²»è®¨è®ºæ•°æ®é›†ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆä¸ç‰¹å®šæ„è¯†å½¢æ€ä¸€è‡´çš„è¯„è®ºï¼Œä»è€Œå¢å¼ºå…¶åœ¨æåŒ–è¯è¯­ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é›†çš„æ„å»ºã€æ¨¡å‹çš„å¾®è°ƒã€è¾“å‡ºçš„è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†å¹¶æ¸…æ´—æ”¿æ²»è®¨è®ºæ•°æ®ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨è¿™äº›æ•°æ®å¯¹LLMè¿›è¡Œå¾®è°ƒï¼›æœ€åï¼Œé€šè¿‡è¯­è¨€åˆ†æå’Œäººå·¥æ ‡æ³¨å¯¹ç”Ÿæˆçš„è¯„è®ºè¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé€šè¿‡é’ˆå¯¹æ€§çš„æ•°æ®å¾®è°ƒï¼Œä½¿å¾—LLMèƒ½å¤Ÿç”Ÿæˆé«˜åº¦å¯ä¿¡ä¸”å…·æœ‰æŒ‘è¡…æ€§çš„æåŒ–è¯„è®ºï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºè´¨é‡ï¼Œå¹¶é€šè¿‡è°ƒèŠ‚è¶…å‚æ•°æ¥ç¡®ä¿ç”Ÿæˆå†…å®¹çš„ä¸Šä¸‹æ–‡ä¸€è‡´æ€§å’Œæ„è¯†å½¢æ€å¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„LLMèƒ½å¤Ÿç”Ÿæˆä¸äººç±»æ’°å†™çš„è¯„è®ºé«˜åº¦ç›¸ä¼¼çš„å†…å®¹ï¼Œè¯„ä¼°ä¸­æ˜¾ç¤ºå…¶å¯ä¿¡åº¦å’ŒæŒ‘è¡…æ€§æ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹ç”Ÿæˆçš„è¯„è®ºåœ¨è¯­è¨€åˆ†æä¸­ä¸äººç±»è¯„è®ºçš„ç›¸ä¼¼åº¦è¾¾åˆ°85%ä»¥ä¸Šï¼Œæƒ…æ„Ÿè¯„åˆ†ä¹Ÿæ˜¾ç¤ºå‡ºæ˜æ˜¾çš„æåŒ–ç‰¹å¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆã€æ”¿æ²»èˆ†è®ºåˆ†æå’Œè™šå‡ä¿¡æ¯æ£€æµ‹ç­‰ã€‚é€šè¿‡ç†è§£å’Œæ¨¡æ‹ŸæåŒ–è¯„è®ºï¼Œç ”ç©¶è€…å’Œæ”¿ç­–åˆ¶å®šè€…å¯ä»¥æ›´å¥½åœ°åº”å¯¹ç¤¾äº¤åª’ä½“ä¸Šçš„æ„è¯†å½¢æ€æåŒ–ç°è±¡ï¼Œåˆ¶å®šç›¸åº”çš„å¹²é¢„æªæ–½ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨AIæ²»ç†å’Œå¹³å°ç›‘ç®¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increasing sophistication of large language models (LLMs) has sparked growing concerns regarding their potential role in exacerbating ideological polarization through the automated generation of persuasive and biased content. This study explores the extent to which fine-tuned LLMs can replicate and amplify polarizing discourse within online environments. Using a curated dataset of politically charged discussions extracted from Reddit, we fine-tune an open-source LLM to produce context-aware and ideologically aligned responses. The model's outputs are evaluated through linguistic analysis, sentiment scoring, and human annotation, with particular attention to credibility and rhetorical alignment with the original discourse. The results indicate that, when trained on partisan data, LLMs are capable of producing highly plausible and provocative comments, often indistinguishable from those written by humans. These findings raise significant ethical questions about the use of AI in political discourse, disinformation, and manipulation campaigns. The paper concludes with a discussion of the broader implications for AI governance, platform regulation, and the development of detection tools to mitigate adversarial fine-tuning risks.

