---
layout: default
title: Readme_AI: Dynamic Context Construction for Large Language Models
---

# Readme_AI: Dynamic Context Construction for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19322" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19322v1</a>
  <a href="https://arxiv.org/pdf/2509.19322.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19322v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19322v1', 'Readme_AI: Dynamic Context Construction for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Millie Vyas, Timothy Blattner, Alden Dima

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/usnistgov/readme_ai)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Readme_AIï¼šæå‡ºåŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºæ–¹æ³•ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šæŸ¥è¯¢ä¸‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `åŠ¨æ€ä¸Šä¸‹æ–‡æ„å»º` `å…ƒæ•°æ®é©±åŠ¨` `çŸ¥è¯†åº“é—®ç­”` `ä¿¡æ¯æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸæˆ–æ•°æ®é›†ä¸Šï¼Œç”±äºç¼ºä¹é’ˆå¯¹æ€§ä¸Šä¸‹æ–‡ï¼Œå®¹æ˜“äº§ç”Ÿä¸å‡†ç¡®æˆ–å¹»è§‰ä¿¡æ¯ã€‚
2. Readme_AIé€šè¿‡æ„å»ºåŠ¨æ€ä¸Šä¸‹æ–‡ï¼Œè®©LLMèƒ½å¤ŸåŸºäºæ•°æ®æºæ‰€æœ‰è€…æä¾›çš„å…ƒæ•°æ®è¿›è¡Œæ¨ç†ï¼Œä»è€Œæå‡å“åº”è´¨é‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒReadme_AIèƒ½å¤Ÿä½¿LLMæ›´å‡†ç¡®åœ°ç†è§£NISTçš„Hedgehogåº“ï¼Œå¹¶ç”Ÿæˆç›¸å…³çš„ä»£ç ç¤ºä¾‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§è¯­è¨€æ¨¡å‹(LLMs)ç»è¿‡å¤§é‡æ•°æ®è®­ç»ƒï¼Œä½†åœ¨ç”¨æˆ·ç‰¹å®šæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå®ƒä»¬å¯èƒ½ä¼šæä¾›ä¸å‡†ç¡®æˆ–ä¸å¯é çš„ä¿¡æ¯ã€‚æä¾›ç‰¹å®šäºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡å¯ä»¥æ˜¾è‘—æé«˜å…¶å“åº”çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§è§„èŒƒï¼Œå¯ç”¨äºä¸ºæ•°æ®æºåŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡ã€‚æ•°æ®æºæ‰€æœ‰è€…åˆ›å»ºåŒ…å«å…ƒæ•°æ®çš„æ–‡ä»¶ï¼Œä¾›LLMsåœ¨æ¨ç†ä¸æ•°æ®é›†ç›¸å…³çš„æŸ¥è¯¢æ—¶ä½¿ç”¨ã€‚ä¸ºäº†æ¼”ç¤ºæˆ‘ä»¬æå‡ºçš„è§„èŒƒï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŸå‹Readme_AIæ¨¡å‹ä¸Šä¸‹æ–‡åè®®(MCP)æœåŠ¡å™¨ï¼Œè¯¥æœåŠ¡å™¨ä»æ•°æ®æºæ£€ç´¢å…ƒæ•°æ®ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥åŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡ã€‚è¯¥è§„èŒƒçš„ä¸€äº›åŠ¨æ€ç‰¹æ€§æ˜¯å¯æ‰©å±•çš„ç±»å‹ï¼Œè¿™äº›ç±»å‹è¡¨ç¤ºçˆ¬å–ç½‘é¡µã€ä»æ•°æ®å­˜å‚¨åº“è·å–æ•°æ®ã€ä¸‹è½½å’Œè§£æå‡ºç‰ˆç‰©ä»¥åŠé€šç”¨æ–‡æœ¬ã€‚ä¸Šä¸‹æ–‡ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ ‡ç­¾è¿›è¡Œæ ¼å¼åŒ–å’Œåˆ†ç»„ï¼Œè¿™äº›æ ‡ç­¾ä¸ºLLMæä¾›æ¸…æ™°çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥è¿›è¡Œæ¨ç†ã€‚æˆ‘ä»¬é€šè¿‡è¯¢é—®LLMå…³äºNISTå¼€å‘çš„Hedgehogåº“æ¥æ¼”ç¤ºè¿™ä¸ªæ—©æœŸåŸå‹çš„èƒ½åŠ›ï¼Œå¯¹äºè¯¥åº“ï¼Œå¸¸è§çš„LLMé€šå¸¸æä¾›åŒ…å«å¹»è§‰çš„ä¸å‡†ç¡®å’Œä¸ç›¸å…³çš„å“åº”ã€‚å€ŸåŠ©Readme_AIï¼ŒLLMæ¥æ”¶åˆ°è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡ï¼Œç°åœ¨èƒ½å¤Ÿæ¨ç†è¯¥åº“åŠå…¶ä½¿ç”¨ï¼Œç”šè‡³å¯ä»¥ç”Ÿæˆä»Hedgehogå¼€å‘äººå‘˜æä¾›çš„Readme_AIæ–‡ä»¶ä¸­åŒ…å«çš„ç¤ºä¾‹ä¸­æ’å…¥çš„ä»£ç ã€‚æˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®æ˜¯ä¸€ç§å¯æ‰©å±•çš„åè®®ï¼Œç”¨äºåœ¨ä¸“é—¨çš„ã€æ‰€æœ‰è€…æä¾›çš„æ•°æ®ä¸­åŠ¨æ€åœ° grounding LLMï¼Œä»è€Œå¢å¼ºLLMçš„å“åº”å¹¶å‡å°‘å¹»è§‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§è¯­è¨€æ¨¡å‹è™½ç„¶æ‹¥æœ‰å¼ºå¤§çš„çŸ¥è¯†å‚¨å¤‡ï¼Œä½†åœ¨é¢å¯¹ç‰¹å®šé¢†åŸŸæˆ–æ•°æ®é›†çš„æŸ¥è¯¢æ—¶ï¼Œç”±äºç¼ºä¹é’ˆå¯¹æ€§çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå®¹æ˜“äº§ç”Ÿä¸å‡†ç¡®ã€ä¸ç›¸å…³ç”šè‡³è™šå‡çš„å›ç­”ï¼ˆå³å¹»è§‰ï¼‰ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åŠ¨æ€åœ°ä¸ºLLMæä¾›æ‰€éœ€çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œé™åˆ¶äº†å…¶åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReadme_AIçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºåè®®ï¼Œå…è®¸æ•°æ®æºæ‰€æœ‰è€…æä¾›å…³äºå…¶æ•°æ®é›†çš„å…ƒæ•°æ®ï¼Œå¹¶åˆ©ç”¨è¿™äº›å…ƒæ•°æ®ä¸ºLLMæ„å»ºç‰¹å®šäºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡ã€‚è¿™æ ·ï¼ŒLLMå°±å¯ä»¥åœ¨æ›´å……åˆ†çš„èƒŒæ™¯ä¿¡æ¯ä¸‹è¿›è¡Œæ¨ç†ï¼Œä»è€Œæé«˜å›ç­”çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReadme_AIçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ•°æ®æºå…ƒæ•°æ®è§„èŒƒï¼šå®šä¹‰äº†æ•°æ®æºæ‰€æœ‰è€…å¦‚ä½•æä¾›å…³äºå…¶æ•°æ®é›†çš„å…ƒæ•°æ®ï¼ŒåŒ…æ‹¬æ•°æ®æè¿°ã€ä½¿ç”¨ç¤ºä¾‹ã€ç›¸å…³æ–‡æ¡£ç­‰ã€‚2) æ¨¡å‹ä¸Šä¸‹æ–‡åè®®(MCP)æœåŠ¡å™¨ï¼šè´Ÿè´£ä»æ•°æ®æºæ£€ç´¢å…ƒæ•°æ®ï¼Œå¹¶æ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡ã€‚3) ä¸Šä¸‹æ–‡æ ¼å¼åŒ–å’Œåˆ†ç»„ï¼šä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æ ‡ç­¾å¯¹ä¸Šä¸‹æ–‡è¿›è¡Œæ ¼å¼åŒ–å’Œåˆ†ç»„ï¼Œä»¥ä¾¿LLMæ›´å¥½åœ°ç†è§£å’Œåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šReadme_AIçš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨æ€ä¸Šä¸‹æ–‡æ„å»ºåè®®ï¼Œè¯¥åè®®å…è®¸æ•°æ®æºæ‰€æœ‰è€…ä»¥æ ‡å‡†åŒ–çš„æ–¹å¼æä¾›å…ƒæ•°æ®ï¼Œå¹¶åˆ©ç”¨è¿™äº›å…ƒæ•°æ®ä¸ºLLMæ„å»ºç‰¹å®šäºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡ã€‚è¿™ç§åŠ¨æ€æ„å»ºä¸Šä¸‹æ–‡çš„æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘LLMçš„å¹»è§‰ï¼Œå¹¶æé«˜å…¶åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šReadme_AIçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¯æ‰©å±•çš„å…ƒæ•°æ®ç±»å‹ï¼šæ”¯æŒå¤šç§å…ƒæ•°æ®ç±»å‹ï¼ŒåŒ…æ‹¬ç½‘é¡µçˆ¬å–ã€æ•°æ®ä»“åº“è®¿é—®ã€æ–‡æ¡£è§£æç­‰ã€‚2) ç”¨æˆ·å¯é…ç½®çš„ä¸Šä¸‹æ–‡æ ‡ç­¾ï¼šå…è®¸ç”¨æˆ·è‡ªå®šä¹‰ä¸Šä¸‹æ–‡æ ‡ç­¾ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç»„ç»‡å’Œåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚3) åŸºäºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡æ£€ç´¢ï¼šæ ¹æ®ç”¨æˆ·æŸ¥è¯¢åŠ¨æ€æ£€ç´¢ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¹¶æ„å»ºä¸Šä¸‹æ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒReadme_AIèƒ½å¤Ÿæ˜¾è‘—æå‡LLMåœ¨ç†è§£NISTå¼€å‘çš„Hedgehogåº“æ–¹é¢çš„èƒ½åŠ›ã€‚åœ¨æ²¡æœ‰Readme_AIçš„æƒ…å†µä¸‹ï¼ŒLLMé€šå¸¸ä¼šç»™å‡ºä¸å‡†ç¡®æˆ–ä¸ç›¸å…³çš„å›ç­”ã€‚è€Œå€ŸåŠ©Readme_AIæä¾›çš„ä¸Šä¸‹æ–‡ï¼ŒLLMèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£Hedgehogåº“ï¼Œå¹¶ç”Ÿæˆç›¸å…³çš„ä»£ç ç¤ºä¾‹ï¼Œæœ‰æ•ˆå‡å°‘äº†å¹»è§‰ç°è±¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Readme_AIå¯åº”ç”¨äºå„ç§éœ€è¦å¤§è¯­è¨€æ¨¡å‹æä¾›ä¸“ä¸šé¢†åŸŸçŸ¥è¯†çš„åœºæ™¯ï¼Œä¾‹å¦‚è½¯ä»¶å¼€å‘æ–‡æ¡£ç†è§£ã€ç§‘å­¦ç ”ç©¶æ•°æ®åˆ†æã€ä¼ä¸šå†…éƒ¨çŸ¥è¯†åº“é—®ç­”ç­‰ã€‚é€šè¿‡æä¾›åŠ¨æ€ä¸Šä¸‹æ–‡ï¼ŒReadme_AIå¯ä»¥æ˜¾è‘—æå‡LLMåœ¨è¿™äº›åœºæ™¯ä¸‹çš„åº”ç”¨æ•ˆæœï¼Œå¹¶é™ä½å¹»è§‰é£é™©ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æˆä¸ºLLMåœ¨ä¸“ä¸šé¢†åŸŸåº”ç”¨çš„é‡è¦åŸºç¡€è®¾æ–½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite being trained on significant amounts of data, Large Language Models (LLMs) can provide inaccurate or unreliable information in the context of a user's specific query. Given query-specific context significantly improves the usefulness of its responses. In this paper, we present a specification that can be used to dynamically build context for data sources. The data source owner creates the file containing metadata for LLMs to use when reasoning about dataset-related queries. To demonstrate our proposed specification, we created a prototype Readme_AI Model Context Protocol (MCP) server that retrieves the metadata from the data source and uses it to dynamically build context. Some features that make this specification dynamic are the extensible types that represent crawling web-pages, fetching data from data repositories, downloading and parsing publications, and general text. The context is formatted and grouped using user-specified tags that provide clear contextual information for the LLM to reason about the content. We demonstrate the capabilities of this early prototype by asking the LLM about the NIST-developed Hedgehog library, for which common LLMs often provides inaccurate and irrelevant responses containing hallucinations. With Readme_AI, the LLM receives enough context that it is now able to reason about the library and its use, and even generate code interpolated from examples that were included in the Readme_AI file provided by Hedgehog's developer. Our primary contribution is a extensible protocol for dynamically grounding LLMs in specialized, owner-provided data, enhancing responses from LLMs and reducing hallucinations. The source code for the Readme_AI tool is posted here: https://github.com/usnistgov/readme_ai .

