---
layout: default
title: A Survey on Retrieval And Structuring Augmented Generation with Large Language Models
---

# A Survey on Retrieval And Structuring Augmented Generation with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10697" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10697v1</a>
  <a href="https://arxiv.org/pdf/2509.10697.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10697v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10697v1', 'A Survey on Retrieval And Structuring Augmented Generation with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pengcheng Jiang, Siru Ouyang, Yizhu Jiao, Ming Zhong, Runchu Tian, Jiawei Han

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**å¤‡æ³¨**: KDD'25 survey track

**DOI**: [10.1145/3711896.3736557](https://doi.org/10.1145/3711896.3736557)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°æ£€ç´¢ä¸ç»“æ„å¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–¹æ³•ï¼Œè§£å†³å¹»è§‰ã€çŸ¥è¯†è¿‡æ—¶å’Œé¢†åŸŸå—é™é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `ç»“æ„åŒ–çŸ¥è¯†` `çŸ¥è¯†å›¾è°±` `ä¿¡æ¯æ£€ç´¢` `è‡ªç„¶è¯­è¨€å¤„ç†` `æç¤ºå·¥ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´å¹»è§‰ç”Ÿæˆã€çŸ¥è¯†è¿‡æ—¶å’Œé¢†åŸŸçŸ¥è¯†ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚
2. æ£€ç´¢ä¸ç»“æ„åŒ–å¢å¼ºç”Ÿæˆï¼ˆRASï¼‰é€šè¿‡æ•´åˆåŠ¨æ€ä¿¡æ¯æ£€ç´¢å’Œç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºæ¥è§£å†³è¿™äº›é—®é¢˜ã€‚
3. è¯¥ç»¼è¿°è€ƒå¯Ÿäº†æ£€ç´¢æœºåˆ¶ã€æ–‡æœ¬ç»“æ„åŒ–æŠ€æœ¯ä»¥åŠç»“æ„åŒ–è¡¨ç¤ºä¸LLMçš„é›†æˆæ–¹æ³•ï¼Œå¹¶æŒ‡å‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä»¥å…¶å“è¶Šçš„æ–‡æœ¬ç”Ÿæˆå’Œæ¨ç†èƒ½åŠ›å½»åº•æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´ç€ä¸¥å³»çš„æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¹»è§‰ç”Ÿæˆã€çŸ¥è¯†è¿‡æ—¶å’Œé¢†åŸŸä¸“ä¸šçŸ¥è¯†æœ‰é™ã€‚æ£€ç´¢ä¸ç»“æ„åŒ–ï¼ˆRASï¼‰å¢å¼ºç”Ÿæˆé€šè¿‡æ•´åˆåŠ¨æ€ä¿¡æ¯æ£€ç´¢ä¸ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºæ¥è§£å†³è¿™äº›å±€é™æ€§ã€‚æœ¬ç»¼è¿°ï¼ˆ1ï¼‰è€ƒå¯Ÿäº†ç”¨äºè®¿é—®å¤–éƒ¨çŸ¥è¯†çš„æ£€ç´¢æœºåˆ¶ï¼ŒåŒ…æ‹¬ç¨€ç–ã€å¯†é›†å’Œæ··åˆæ–¹æ³•ï¼›ï¼ˆ2ï¼‰æ¢è®¨äº†æ–‡æœ¬ç»“æ„åŒ–æŠ€æœ¯ï¼Œå¦‚åˆ†ç±»æ„å»ºã€åˆ†å±‚åˆ†ç±»å’Œä¿¡æ¯æå–ï¼Œè¿™äº›æŠ€æœ¯å°†éç»“æ„åŒ–æ–‡æœ¬è½¬æ¢ä¸ºæœ‰ç»„ç»‡çš„è¡¨ç¤ºï¼›ï¼ˆ3ï¼‰ç ”ç©¶äº†è¿™äº›ç»“æ„åŒ–è¡¨ç¤ºå¦‚ä½•é€šè¿‡åŸºäºæç¤ºçš„æ–¹æ³•ã€æ¨ç†æ¡†æ¶å’ŒçŸ¥è¯†åµŒå…¥æŠ€æœ¯ä¸LLMé›†æˆã€‚å®ƒè¿˜æŒ‡å‡ºäº†æ£€ç´¢æ•ˆç‡ã€ç»“æ„è´¨é‡å’ŒçŸ¥è¯†é›†æˆæ–¹é¢çš„æŠ€æœ¯æŒ‘æˆ˜ï¼ŒåŒæ—¶å¼ºè°ƒäº†å¤šæ¨¡æ€æ£€ç´¢ã€è·¨è¯­è¨€ç»“æ„å’Œäº¤äº’ç³»ç»Ÿæ–¹é¢çš„ç ”ç©¶æœºä¼šã€‚è¿™ä¸ªå…¨é¢çš„æ¦‚è¿°ä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šäººå‘˜æä¾›äº†å¯¹RASæ–¹æ³•ã€åº”ç”¨å’Œæœªæ¥æ–¹å‘çš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è™½ç„¶åœ¨æ–‡æœ¬ç”Ÿæˆå’Œæ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å­˜åœ¨çŸ¥è¯†æ›´æ–°æ»åã€ç”Ÿæˆå†…å®¹ç¼ºä¹äº‹å®ä¾æ®ï¼ˆå¹»è§‰é—®é¢˜ï¼‰ä»¥åŠç‰¹å®šé¢†åŸŸçŸ¥è¯†ä¸è¶³ç­‰é—®é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåœ°åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºLLMsçš„ç”Ÿæˆèƒ½åŠ›ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹æ£€ç´¢åˆ°çš„ä¿¡æ¯çš„æœ‰æ•ˆç»„ç»‡å’Œç»“æ„åŒ–åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç»¼è¿°çš„æ ¸å¿ƒæ€è·¯æ˜¯ç ”ç©¶å¦‚ä½•é€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†å¹¶å°†å…¶ç»“æ„åŒ–ï¼Œç„¶åå°†è¿™äº›ç»“æ„åŒ–çŸ¥è¯†æœ‰æ•ˆåœ°èå…¥åˆ°LLMsçš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œä»è€Œæé«˜ç”Ÿæˆå†…å®¹çš„è´¨é‡ã€å¯é æ€§å’Œé¢†åŸŸç›¸å…³æ€§ã€‚é€šè¿‡æ£€ç´¢å¢å¼ºLLMsçš„çŸ¥è¯†èŒƒå›´ï¼Œå¹¶é€šè¿‡ç»“æ„åŒ–ç»„ç»‡ä¿¡æ¯æ¥æé«˜LLMsçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRASå¢å¼ºç”Ÿæˆçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼š1) **æ£€ç´¢é˜¶æ®µ**ï¼šä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯ï¼Œé‡‡ç”¨ç¨€ç–æ£€ç´¢ã€å¯†é›†æ£€ç´¢æˆ–æ··åˆæ£€ç´¢æ–¹æ³•ã€‚2) **ç»“æ„åŒ–é˜¶æ®µ**ï¼šå°†æ£€ç´¢åˆ°çš„éç»“æ„åŒ–æ–‡æœ¬è½¬æ¢ä¸ºç»“æ„åŒ–è¡¨ç¤ºï¼Œä¾‹å¦‚æ„å»ºåˆ†ç±»ä½“ç³»ã€è¿›è¡Œåˆ†å±‚åˆ†ç±»æˆ–è¿›è¡Œä¿¡æ¯æå–ã€‚3) **ç”Ÿæˆé˜¶æ®µ**ï¼šå°†ç»“æ„åŒ–çŸ¥è¯†èå…¥LLMsï¼Œé€šè¿‡æç¤ºå·¥ç¨‹ã€æ¨ç†æ¡†æ¶æˆ–çŸ¥è¯†åµŒå…¥ç­‰æŠ€æœ¯ï¼Œå¼•å¯¼LLMsç”Ÿæˆæ›´å‡†ç¡®ã€æ›´å¯é çš„å†…å®¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç»¼è¿°çš„å…³é”®åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ€»ç»“å’Œåˆ†æäº†æ£€ç´¢ä¸ç»“æ„åŒ–å¢å¼ºç”Ÿæˆï¼ˆRASï¼‰è¿™ä¸€æ–°å…´é¢†åŸŸçš„ç ”ç©¶è¿›å±•ï¼Œå¹¶å°†å…¶åˆ†è§£ä¸ºæ£€ç´¢ã€ç»“æ„åŒ–å’Œç”Ÿæˆä¸‰ä¸ªå…³é”®é˜¶æ®µã€‚æ­¤å¤–ï¼Œè¯¥ç»¼è¿°è¿˜æŒ‡å‡ºäº†è¯¥é¢†åŸŸé¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜å’Œæœªæ¥çš„ç ”ç©¶æ–¹å‘ï¼Œä¾‹å¦‚å¤šæ¨¡æ€æ£€ç´¢ã€è·¨è¯­è¨€ç»“æ„å’Œäº¤äº’å¼ç³»ç»Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ£€ç´¢é˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„æ£€ç´¢æ–¹æ³•ï¼ˆç¨€ç–ã€å¯†é›†æˆ–æ··åˆï¼‰ï¼Œå¹¶è®¾è®¡æœ‰æ•ˆçš„æ£€ç´¢ç­–ç•¥ã€‚åœ¨ç»“æ„åŒ–é˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„ç»“æ„åŒ–æ–¹æ³•ï¼ˆåˆ†ç±»æ„å»ºã€åˆ†å±‚åˆ†ç±»ã€ä¿¡æ¯æå–ï¼‰ï¼Œå¹¶è®¾è®¡åˆé€‚çš„ç»“æ„åŒ–æ¨¡å¼ã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„çŸ¥è¯†èåˆæ–¹æ³•ï¼ˆæç¤ºå·¥ç¨‹ã€æ¨ç†æ¡†æ¶ã€çŸ¥è¯†åµŒå…¥ï¼‰ï¼Œå¹¶è®¾è®¡åˆé€‚çš„æç¤ºæˆ–æŸå¤±å‡½æ•°æ¥å¼•å¯¼LLMsçš„ç”Ÿæˆè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç»¼è¿°ç³»ç»Ÿæ€§åœ°æ€»ç»“äº†æ£€ç´¢ä¸ç»“æ„åŒ–å¢å¼ºç”Ÿæˆï¼ˆRASï¼‰é¢†åŸŸçš„ç ”ç©¶è¿›å±•ï¼Œå¹¶æŒ‡å‡ºäº†è¯¥é¢†åŸŸé¢ä¸´çš„æŠ€æœ¯æŒ‘æˆ˜å’Œæœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚å®ƒä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šäººå‘˜æä¾›äº†å¯¹RASæ–¹æ³•ã€åº”ç”¨å’Œæœªæ¥æ–¹å‘çš„æ·±åˆ»è§è§£ï¼Œæœ‰åŠ©äºæ¨åŠ¨è¯¥é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€å†…å®¹åˆ›ä½œã€çŸ¥è¯†å›¾è°±æ„å»ºç­‰é¢†åŸŸã€‚é€šè¿‡å¢å¼ºLLMsçš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨çš„å‡†ç¡®æ€§ã€å¯é æ€§å’Œå®ç”¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨åŒ»ç–—ã€é‡‘èã€æ³•å¾‹ç­‰ä¸“ä¸šé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œä¸ºç”¨æˆ·æä¾›æ›´ä¸“ä¸šã€æ›´æ™ºèƒ½çš„æœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have revolutionized natural language processing with their remarkable capabilities in text generation and reasoning. However, these models face critical challenges when deployed in real-world applications, including hallucination generation, outdated knowledge, and limited domain expertise. Retrieval And Structuring (RAS) Augmented Generation addresses these limitations by integrating dynamic information retrieval with structured knowledge representations. This survey (1) examines retrieval mechanisms including sparse, dense, and hybrid approaches for accessing external knowledge; (2) explore text structuring techniques such as taxonomy construction, hierarchical classification, and information extraction that transform unstructured text into organized representations; and (3) investigate how these structured representations integrate with LLMs through prompt-based methods, reasoning frameworks, and knowledge embedding techniques. It also identifies technical challenges in retrieval efficiency, structure quality, and knowledge integration, while highlighting research opportunities in multimodal retrieval, cross-lingual structures, and interactive systems. This comprehensive overview provides researchers and practitioners with insights into RAS methods, applications, and future directions.

