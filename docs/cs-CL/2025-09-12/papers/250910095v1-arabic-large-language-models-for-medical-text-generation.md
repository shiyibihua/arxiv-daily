---
layout: default
title: Arabic Large Language Models for Medical Text Generation
---

# Arabic Large Language Models for Medical Text Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10095" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10095v1</a>
  <a href="https://arxiv.org/pdf/2509.10095.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10095v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10095v1', 'Arabic Large Language Models for Medical Text Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdulrahman Allam, Seif Ahmed, Ali Hamdi, Ammar Mohammed

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**å¤‡æ³¨**: Published in 2025 4th International Conference on Computer Technologies (ICCTech)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¹¶å¾®è°ƒé˜¿æ‹‰ä¼¯è¯­å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç”¨äºç”ŸæˆåŒ»ç–—æ–‡æœ¬ï¼Œè¾…åŠ©åŒ»é™¢ç®¡ç†ç³»ç»Ÿã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é˜¿æ‹‰ä¼¯è¯­` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒ»ç–—æ–‡æœ¬ç”Ÿæˆ` `å¾®è°ƒ` `åŒ»é™¢ç®¡ç†ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»é™¢ç®¡ç†ç³»ç»Ÿåœ¨å¤„ç†ä¸è§„åˆ™è¾“å…¥å’Œæ¬ ä»£è¡¨æ€§è¯­è¨€æ—¶ï¼Œç¼ºä¹å‡†ç¡®ã€å®æ—¶çš„åŒ»ç–—å»ºè®®èƒ½åŠ›ã€‚
2. é€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ„å»ºé˜¿æ‹‰ä¼¯è¯­åŒ»ç–—æ–‡æœ¬ç”Ÿæˆç³»ç»Ÿï¼Œä¸ºæ‚£è€…æä¾›åŒ»ç–—å»ºè®®ã€è¯Šæ–­å’Œæ²»ç–—æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„Mistral-7Bæ¨¡å‹åœ¨BERT ScoreæŒ‡æ ‡ä¸Šä¼˜äºå…¶ä»–æ¨¡å‹ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ—¨åœ¨é€šè¿‡å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è§£å†³åŒ»é™¢ç®¡ç†ç³»ç»Ÿï¼ˆHMSï¼‰é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå¦‚æ‹¥æŒ¤ã€èµ„æºæœ‰é™å’Œç´§æ€¥åŒ»ç–—ä¿å¥å¯ç”¨æ€§å·®ç­‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æä¾›å‡†ç¡®ã€å®æ—¶åŒ»ç–—å»ºè®®çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ä¸è§„åˆ™è¾“å…¥å’Œä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€æ—¶ã€‚è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—æ–‡æœ¬ç”Ÿæˆçš„LLMå¾®è°ƒæ–¹æ³•ï¼Œæ—¨åœ¨æ ¹æ®ç”¨æˆ·è¾“å…¥ä¸ºæ‚£è€…æä¾›å‡†ç¡®çš„åŒ»ç–—å»ºè®®ã€è¯Šæ–­ã€è¯ç‰©æ¨èå’Œæ²»ç–—æ–¹æ¡ˆã€‚ç ”ç©¶æ”¶é›†äº†æ¥è‡ªç¤¾äº¤åª’ä½“å¹³å°çš„ç‹¬ç‰¹æ•°æ®é›†ï¼Œæ•æ‰äº†æ‚£è€…ä¸åŒ»ç”Ÿä¹‹é—´çš„çœŸå®åŒ»ç–—å¯¹è¯ï¼Œå¹¶å¯¹åŒ…å«å¤šç§é˜¿æ‹‰ä¼¯è¯­æ–¹è¨€çš„æ•°æ®é›†è¿›è¡Œäº†æ¸…æ´—å’Œé¢„å¤„ç†ã€‚é€šè¿‡å¾®è°ƒMistral-7B-Instruct-v0.2ã€LLaMA-2-7Bå’ŒGPT-2 Mediumç­‰å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹ï¼Œä¼˜åŒ–äº†ç³»ç»Ÿç”Ÿæˆå¯é åŒ»ç–—æ–‡æœ¬çš„èƒ½åŠ›ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåçš„Mistral-7Bæ¨¡å‹ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œå…¶BERT Scoreåœ¨ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ä¸Šçš„å¹³å‡å€¼åˆ†åˆ«ä¸º68.5%ã€69.08%å’Œ68.5%ã€‚å¯¹æ¯”åŸºå‡†æµ‹è¯•å’Œå®šæ€§è¯„ä¼°éªŒè¯äº†ç³»ç»Ÿé’ˆå¯¹éæ­£å¼è¾“å…¥ç”Ÿæˆè¿è´¯ä¸”ç›¸å…³çš„åŒ»ç–—å›å¤çš„èƒ½åŠ›ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨æ¨è¿›HMSæ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºå…¨çƒåŒ»ç–—ä¿å¥æŒ‘æˆ˜æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é€‚åº”æ€§å¼ºçš„è§£å†³æ–¹æ¡ˆï¼Œå°¤å…¶æ˜¯åœ¨è¯­è¨€å’Œæ–‡åŒ–å¤šæ ·çš„ç¯å¢ƒä¸­ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰åŒ»é™¢ç®¡ç†ç³»ç»Ÿåœ¨å¤„ç†é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—ä¿¡æ¯æ—¶ï¼Œç¼ºä¹å‡†ç¡®å’Œå®æ—¶çš„åŒ»ç–—å»ºè®®èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†éæ­£å¼çš„æ‚£è€…è¾“å…¥ï¼Œå¹¶ä¸”åœ¨é˜¿æ‹‰ä¼¯è¯­è¿™ç§æ¬ ä»£è¡¨æ€§è¯­è¨€ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚è¿™å¯¼è‡´æ‚£è€…éš¾ä»¥è·å¾—åŠæ—¶çš„åŒ»ç–—æŒ‡å¯¼ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡åœ¨çœŸå®çš„é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—å¯¹è¯æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£å¹¶ç”Ÿæˆå‡†ç¡®ã€ç›¸å…³çš„åŒ»ç–—å»ºè®®ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å¼¥åˆç°æœ‰ç³»ç»Ÿåœ¨è¯­è¨€ç†è§£å’Œç”Ÿæˆæ–¹é¢çš„å·®è·ï¼Œä»è€Œä¸ºæ‚£è€…æä¾›æ›´å¥½çš„åŒ»ç–—æœåŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šä»ç¤¾äº¤åª’ä½“å¹³å°æ”¶é›†çœŸå®çš„æ‚£è€…ä¸åŒ»ç”Ÿä¹‹é—´çš„é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—å¯¹è¯æ•°æ®ã€‚2) æ•°æ®é¢„å¤„ç†ï¼šå¯¹æ”¶é›†åˆ°çš„æ•°æ®è¿›è¡Œæ¸…æ´—ã€æ ‡å‡†åŒ–å’Œæ–¹è¨€å¤„ç†ï¼Œä»¥æé«˜æ•°æ®è´¨é‡ã€‚3) æ¨¡å‹é€‰æ‹©ä¸å¾®è°ƒï¼šé€‰æ‹©é¢„è®­ç»ƒçš„LLMsï¼ˆå¦‚Mistral-7B-Instruct-v0.2ã€LLaMA-2-7Bå’ŒGPT-2 Mediumï¼‰ï¼Œå¹¶åœ¨é¢„å¤„ç†åçš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚4) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨BERT Scoreç­‰æŒ‡æ ‡å¯¹å¾®è°ƒåçš„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è¿›è¡Œå¯¹æ¯”åŸºå‡†æµ‹è¯•å’Œå®šæ€§è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºé’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—æ–‡æœ¬ç”Ÿæˆï¼Œå¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œäº†å¾®è°ƒã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œç”Ÿæˆé˜¿æ‹‰ä¼¯è¯­åŒ»ç–—ä¿¡æ¯ï¼Œä»è€Œä¸ºé˜¿æ‹‰ä¼¯è¯­åœ°åŒºçš„æ‚£è€…æä¾›æ›´å¥½çš„åŒ»ç–—æœåŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å«çœŸå®æ‚£è€…ä¸åŒ»ç”Ÿå¯¹è¯çš„é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—æ•°æ®é›†ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†å®è´µèµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶äººå‘˜ä½¿ç”¨äº†æ ‡å‡†çš„è¯­è¨€æ¨¡å‹è®­ç»ƒæ–¹æ³•ï¼Œä¾‹å¦‚äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚å…·ä½“å‚æ•°è®¾ç½®ï¼ˆå¦‚å­¦ä¹ ç‡ã€batch sizeç­‰ï¼‰æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†å¯¹Mistral-7B-Instruct-v0.2ã€LLaMA-2-7Bå’ŒGPT-2 Mediumç­‰æ¨¡å‹çš„å¾®è°ƒï¼Œå¹¶ä½¿ç”¨BERT Scoreè¿›è¡Œè¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡å¾®è°ƒçš„Mistral-7Bæ¨¡å‹åœ¨é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³ï¼Œå…¶BERT Scoreåœ¨ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ä¸Šåˆ†åˆ«è¾¾åˆ°68.5%ã€69.08%å’Œ68.5%ã€‚è¯¥æ¨¡å‹ä¼˜äºå…¶ä»–åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨ç”Ÿæˆå‡†ç¡®å’Œç›¸å…³çš„é˜¿æ‹‰ä¼¯è¯­åŒ»ç–—å»ºè®®æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½åŒ»ç–—åŠ©æ‰‹ã€åœ¨çº¿åŒ»ç–—å’¨è¯¢å¹³å°å’ŒåŒ»é™¢ç®¡ç†ç³»ç»Ÿï¼Œä¸ºæ‚£è€…æä¾›ä¸ªæ€§åŒ–çš„åŒ»ç–—å»ºè®®å’Œè¯Šæ–­ï¼Œå°¤å…¶æ˜¯åœ¨é˜¿æ‹‰ä¼¯è¯­åœ°åŒºã€‚è¯¥æŠ€æœ¯æœ‰åŠ©äºç¼“è§£åŒ»ç–—èµ„æºç´§å¼ ï¼Œæé«˜åŒ»ç–—æœåŠ¡æ•ˆç‡ï¼Œå¹¶ä¸ºåŒ»ç–—ä¸“ä¸šäººå‘˜æä¾›è¾…åŠ©å†³ç­–æ”¯æŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–ä½èµ„æºè¯­è¨€ï¼Œä¿ƒè¿›å…¨çƒåŒ»ç–—æœåŠ¡çš„æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Efficient hospital management systems (HMS) are critical worldwide to address challenges such as overcrowding, limited resources, and poor availability of urgent health care. Existing methods often lack the ability to provide accurate, real-time medical advice, particularly for irregular inputs and underrepresented languages. To overcome these limitations, this study proposes an approach that fine-tunes large language models (LLMs) for Arabic medical text generation. The system is designed to assist patients by providing accurate medical advice, diagnoses, drug recommendations, and treatment plans based on user input. The research methodology required the collection of a unique dataset from social media platforms, capturing real-world medical conversations between patients and doctors. The dataset, which includes patient complaints together with medical advice, was properly cleaned and preprocessed to account for multiple Arabic dialects. Fine-tuning state-of-the-art generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2 Medium, optimized the system's ability to generate reliable medical text. Results from evaluations indicate that the fine-tuned Mistral-7B model outperformed the other models, achieving average BERT (Bidirectional Encoder Representations from Transformers) Score values in precision, recall, and F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative benchmarking and qualitative assessments validate the system's ability to produce coherent and relevant medical replies to informal input. This study highlights the potential of generative artificial intelligence (AI) in advancing HMS, offering a scalable and adaptable solution for global healthcare challenges, especially in linguistically and culturally diverse environments.

