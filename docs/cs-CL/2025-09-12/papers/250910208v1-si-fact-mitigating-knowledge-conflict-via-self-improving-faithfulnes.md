---
layout: default
title: SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning
---

# SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10208" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10208v1</a>
  <a href="https://arxiv.org/pdf/2509.10208.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10208v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10208v1', 'SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengqiang Fu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSI-FACTæ¡†æ¶ï¼Œé€šè¿‡è‡ªæå‡çš„å¿ å®åº¦æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ç¼“è§£LLMçš„çŸ¥è¯†å†²çªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å†²çª` `å¯¹æ¯”å­¦ä¹ ` `è‡ªæŒ‡ä»¤å­¦ä¹ ` `ä¸Šä¸‹æ–‡å¿ å®åº¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­é¢ä¸´çŸ¥è¯†å†²çªé—®é¢˜ï¼Œå³æ¨¡å‹å€¾å‘äºä½¿ç”¨å†…éƒ¨çŸ¥è¯†è€Œéç»™å®šçš„ä¸Šä¸‹æ–‡ã€‚
2. SI-FACTæ¡†æ¶åˆ©ç”¨è‡ªæŒ‡ä»¤æœºåˆ¶è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å­¦ä¹ æ•°æ®ï¼ŒåŒ…æ‹¬æ­£è´Ÿæ ·æœ¬ï¼Œé™ä½äº†äººå·¥æ ‡æ³¨æˆæœ¬ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSI-FACTåœ¨ä¸Šä¸‹æ–‡å¬å›ç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶é™ä½äº†æ¨¡å‹å¯¹å†…éƒ¨è®°å¿†çš„ä¾èµ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­ï¼Œç”±äºçŸ¥è¯†å†²çªï¼Œç»å¸¸äº§ç”Ÿä¸å¿ å®çš„å›åº”ï¼Œå³å€¾å‘äºä¾èµ–å†…éƒ¨å‚æ•°çŸ¥è¯†è€Œéæä¾›çš„ä¸Šä¸‹æ–‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªæå‡æ¡†æ¶ï¼Œå³è‡ªæå‡å¿ å®åº¦æ„ŸçŸ¥å¯¹æ¯”å­¦ä¹ ï¼ˆSI-FACTï¼‰ã€‚è¯¥æ¡†æ¶ä½¿ç”¨è‡ªæŒ‡ä»¤æœºåˆ¶ï¼Œå…è®¸åŸºç¡€LLMè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€ç»“æ„åŒ–çš„å¯¹æ¯”å­¦ä¹ æ•°æ®ï¼ŒåŒ…æ‹¬é”šæ ·æœ¬ã€è¯­ä¹‰ç­‰ä»·çš„æ­£æ ·æœ¬å’Œæ¨¡æ‹Ÿä¸å¿ å®åœºæ™¯çš„è´Ÿæ ·æœ¬ã€‚è¿™ç§æ–¹æ³•æ˜¾è‘—é™ä½äº†æ‰‹åŠ¨æ ‡æ³¨çš„æˆæœ¬ã€‚éšåï¼Œåº”ç”¨å¯¹æ¯”å­¦ä¹ æ¥è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶åœ¨è¡¨å¾ç©ºé—´ä¸­æ‹‰è¿‘å¿ å®å›åº”ï¼Œæ¨è¿œä¸å¿ å®å›åº”ã€‚åœ¨çŸ¥è¯†å†²çªè¯„ä¼°åŸºå‡†ECARE KREå’ŒCOSE KREä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒåŸºäºLlama3 8B Instructçš„SI-FACTæ¨¡å‹æ¯”æœ€ä½³åŸºçº¿æ–¹æ³•æé«˜äº†6.2%çš„ä¸Šä¸‹æ–‡å¬å›ç‡ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†å¯¹å†…éƒ¨è®°å¿†çš„ä¾èµ–ã€‚ç»“æœè¡¨æ˜ï¼ŒSI-FACTåœ¨å¢å¼ºLLMçš„ä¸Šä¸‹æ–‡å¿ å®åº¦æ–¹é¢æä¾›äº†å¼ºå¤§çš„æœ‰æ•ˆæ€§å’Œé«˜æ•°æ®æ•ˆç‡ï¼Œä¸ºæ„å»ºæ›´ä¸»åŠ¨å’Œå€¼å¾—ä¿¡èµ–çš„è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€æ¡å®ç”¨çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­å‡ºç°çš„çŸ¥è¯†å†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼ŒLLMå€¾å‘äºä¾èµ–å…¶å†…éƒ¨å‚æ•°çŸ¥è¯†ï¼Œè€Œå¿½ç•¥æˆ–é”™è¯¯åœ°åˆ©ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¯¼è‡´ç”Ÿæˆä¸å¿ å®çš„å›åº”ã€‚è¿™ç§ç°è±¡é™ä½äº†LLMåœ¨éœ€è¦ç²¾ç¡®çŸ¥è¯†çš„ä»»åŠ¡ä¸­çš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡æ‹‰è¿‘å¿ å®å›åº”çš„è¡¨å¾ï¼Œæ¨è¿œä¸å¿ å®å›åº”çš„è¡¨å¾ï¼Œä»è€Œä½¿æ¨¡å‹æ›´åŠ å…³æ³¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ºäº†é™ä½æ•°æ®æ ‡æ³¨æˆæœ¬ï¼Œè®ºæ–‡é‡‡ç”¨è‡ªæŒ‡ä»¤æœºåˆ¶ï¼Œè®©LLMè‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”å­¦ä¹ æ‰€éœ€çš„æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSI-FACTæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šæ•°æ®ç”Ÿæˆé˜¶æ®µå’Œå¯¹æ¯”å­¦ä¹ è®­ç»ƒé˜¶æ®µã€‚åœ¨æ•°æ®ç”Ÿæˆé˜¶æ®µï¼Œåˆ©ç”¨è‡ªæŒ‡ä»¤æœºåˆ¶ï¼Œé€šè¿‡è®¾è®¡ç‰¹å®šçš„promptï¼Œè®©LLMç”Ÿæˆé”šæ ·æœ¬ã€è¯­ä¹‰ç­‰ä»·çš„æ­£æ ·æœ¬ä»¥åŠæ¨¡æ‹Ÿä¸å¿ å®åœºæ™¯çš„è´Ÿæ ·æœ¬ã€‚åœ¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨ç”Ÿæˆçš„æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œé€šè¿‡å¯¹æ¯”æŸå¤±å‡½æ•°ï¼Œä½¿æ¨¡å‹å­¦ä¹ åˆ°åŒºåˆ†å¿ å®å’Œä¸å¿ å®å›åº”çš„è¡¨å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§è‡ªæå‡çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„å¯¹æ¯”å­¦ä¹ æ•°æ®ï¼Œä»è€Œé¿å…äº†æ˜‚è´µçš„äººå·¥æ ‡æ³¨ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ç‰¹å®šçš„promptï¼Œç”¨äºç”Ÿæˆæ¨¡æ‹Ÿä¸å¿ å®åœºæ™¯çš„è´Ÿæ ·æœ¬ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°è¯†åˆ«å’Œé¿å…çŸ¥è¯†å†²çªã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®ç”Ÿæˆé˜¶æ®µï¼Œè®¾è®¡äº†ä¸åŒçš„promptæ¨¡æ¿ï¼Œç”¨äºç”Ÿæˆä¸åŒç±»å‹çš„æ ·æœ¬ã€‚ä¾‹å¦‚ï¼Œå¯¹äºè´Ÿæ ·æœ¬çš„ç”Ÿæˆï¼Œpromptä¼šå¼•å¯¼æ¨¡å‹å¿½ç•¥æˆ–é”™è¯¯åœ°ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚åœ¨å¯¹æ¯”å­¦ä¹ è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨äº†InfoNCEæŸå¤±å‡½æ•°ï¼Œè¯¥æŸå¤±å‡½æ•°èƒ½å¤Ÿæœ‰æ•ˆåœ°æ‹‰è¿‘æ­£æ ·æœ¬çš„è¡¨å¾ï¼Œæ¨è¿œè´Ÿæ ·æœ¬çš„è¡¨å¾ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLlama3 8B Instructçš„SI-FACTæ¨¡å‹åœ¨ECARE KREå’ŒCOSE KREä¸¤ä¸ªçŸ¥è¯†å†²çªè¯„ä¼°åŸºå‡†ä¸Šï¼Œæ¯”æœ€ä½³åŸºçº¿æ–¹æ³•æé«˜äº†6.2%çš„ä¸Šä¸‹æ–‡å¬å›ç‡ã€‚åŒæ—¶ï¼ŒSI-FACTæ¨¡å‹æ˜¾è‘—é™ä½äº†å¯¹å†…éƒ¨è®°å¿†çš„ä¾èµ–ï¼Œè¡¨æ˜å…¶åœ¨å¢å¼ºLLMçš„ä¸Šä¸‹æ–‡å¿ å®åº¦æ–¹é¢å…·æœ‰å¼ºå¤§çš„æœ‰æ•ˆæ€§å’Œé«˜æ•°æ®æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬æ‘˜è¦ç­‰ã€‚é€šè¿‡æé«˜è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¿ å®åº¦ï¼Œå¯ä»¥æ˜¾è‘—æå‡è¿™äº›åº”ç”¨åœ¨å®é™…åœºæ™¯ä¸­çš„å¯é æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„è¯­è¨€æ¨¡å‹å’Œä»»åŠ¡ä¸­ï¼Œä»è€Œæ„å»ºæ›´åŠ å€¼å¾—ä¿¡èµ–çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models often generate unfaithful responses in knowledge intensive tasks due to knowledge conflict,that is,a preference for relying on internal parametric knowledge rather than the provided context.To address this issue,we propose a novel self improving framework,Self Improving Faithfulness Aware Contrastive Tuning.The framework uses a self instruct mechanism that allows the base LLM to automatically generate high quality,structured contrastive learning data,including anchor samples,semantically equivalent positive samples,and negative samples simulating unfaithful scenarios.This approach significantly reduces the cost of manual annotation.Subsequently,contrastive learning is applied to train the model,enabling it to pull faithful responses closer and push unfaithful responses farther apart in the representation space.Experiments on knowledge conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2% over the best baseline method,while significantly reducing dependence on internal memory.The results indicate that SI FACT provides strong effectiveness and high data efficiency in enhancing the contextual faithfulness of LLMs,offering a practical pathway toward building more proactive and trustworthy language models.

