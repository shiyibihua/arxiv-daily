---
layout: default
title: SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents
---

# SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02013" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02013v5</a>
  <a href="https://arxiv.org/pdf/2508.02013.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02013v5" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02013v5', 'SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Changhao Jiang, Jiajun Sun, Yifei Cao, Jiabao Zhuang, Hui Li, Baoyu Fan, Tao Ji, Tao Gui, Qi Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04 (æ›´æ–°: 2025-12-03)

**å¤‡æ³¨**: This work is withdrawn as all authors are not in agreement on the work

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ„å»ºSpeechRoleæ•°æ®é›†ä»¥è¯„ä¼°è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³è§’è‰²æ‰®æ¼”` `å¤šæ¨¡æ€äº¤äº’` `æ•°æ®é›†æ„å»º` `è¯„ä¼°åŸºå‡†` `è¯­éŸ³ç‰¹å¾`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºæ–‡æœ¬æ¨¡æ€ï¼Œç¼ºä¹å¯¹è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†çš„ç³»ç»Ÿè¯„ä¼°ï¼Œé™åˆ¶äº†å…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æ„å»ºäº†SpeechRole-Dataæ•°æ®é›†ï¼ŒåŒ…å«å¤šæ ·åŒ–è§’è‰²å’Œä¸°å¯Œçš„è¯­éŸ³å¯¹è¯ï¼Œæä¾›äº†è¯„ä¼°SRPAsçš„æ–°åŸºå‡†ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œçº§è”å’Œç«¯åˆ°ç«¯çš„è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†åœ¨å£°éŸ³é£æ ¼ä¸€è‡´æ€§å’Œè§’è‰²è¿è´¯æ€§æ–¹é¢å­˜åœ¨æ˜æ˜¾çš„ä¼˜åŠ¿ä¸æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§’è‰²æ‰®æ¼”ä»£ç†ä½œä¸ºå®ç°ä¸ªæ€§åŒ–äº’åŠ¨å’Œæƒ…æ„Ÿå…±é¸£çš„æœ‰å‰æ™¯çš„èŒƒå¼é€æ¸å…´èµ·ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬æ¨¡æ€ä¸Šï¼Œå¿½è§†äº†è¯­éŸ³åœ¨ç°å®äº’åŠ¨åœºæ™¯ä¸­çš„é‡è¦æ€§ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æ„å»ºäº†SpeechRole-Dataï¼Œè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æ•°æ®é›†ï¼ŒåŒ…å«98ç§å¤šæ ·åŒ–è§’è‰²å’Œ112,000ä¸ªåŸºäºè¯­éŸ³çš„å•è½®å’Œå¤šè½®å¯¹è¯ã€‚æ¯ä¸ªè§’è‰²å±•ç°äº†ç‹¬ç‰¹çš„å£°éŸ³ç‰¹å¾ï¼ŒåŒ…æ‹¬éŸ³è‰²å’ŒéŸµå¾‹ï¼Œä»è€Œå®ç°æ›´å¤æ‚çš„è¯­éŸ³è§’è‰²æ‰®æ¼”ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†SpeechRole-Evalï¼Œä¸€ä¸ªå¤šç»´åº¦è¯„ä¼°åŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°SRPAsåœ¨åŸºæœ¬äº’åŠ¨èƒ½åŠ›ã€è¯­éŸ³è¡¨ç°åŠ›å’Œè§’è‰²æ‰®æ¼”å¿ å®åº¦ç­‰å…³é”®æ–¹é¢çš„æ€§èƒ½ã€‚å®éªŒç»“æœæ­ç¤ºäº†çº§è”å’Œç«¯åˆ°ç«¯è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†åœ¨ä¿æŒå£°éŸ³é£æ ¼ä¸€è‡´æ€§å’Œè§’è‰²è¿è´¯æ€§æ–¹é¢çš„ä¼˜åŠ¿ä¸æŒ‘æˆ˜ã€‚æˆ‘ä»¬å‘å¸ƒäº†æ‰€æœ‰æ•°æ®ã€ä»£ç å’ŒåŸºçº¿æ¨¡å‹ï¼Œä¸ºè¯­éŸ³é©±åŠ¨çš„å¤šæ¨¡æ€è§’è‰²æ‰®æ¼”ç ”ç©¶æä¾›äº†åšå®åŸºç¡€ï¼Œå¹¶ä¿ƒè¿›è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†åœ¨è¯„ä¼°å’Œåº”ç”¨ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹ç³»ç»Ÿæ€§çš„æ•°æ®é›†å’Œè¯„ä¼°æ ‡å‡†ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘è¯­éŸ³ç‰¹å¾åœ¨è§’è‰²æ‰®æ¼”ä¸­çš„é‡è¦æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å¤šæ ·åŒ–è§’è‰²å’Œä¸°å¯Œè¯­éŸ³å¯¹è¯çš„æ•°æ®é›†ï¼Œæä¾›ä¸€ä¸ªå…¨é¢çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¯„ä¼°å’Œæå‡è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€è§’è‰²ç‰¹å¾å®šä¹‰ã€å¯¹è¯ç”Ÿæˆå’Œè¯„ä¼°æ ‡å‡†åˆ¶å®šç­‰ä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†åŒ…å«å•è½®å’Œå¤šè½®å¯¹è¯ï¼Œè§’è‰²ç‰¹å¾é€šè¿‡éŸ³è‰²å’ŒéŸµå¾‹è¿›è¡Œå®šä¹‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„è¯­éŸ³å¯¹è¯æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†å¤šç»´åº¦çš„è¯„ä¼°åŸºå‡†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°SRPAsåœ¨äº’åŠ¨èƒ½åŠ›å’Œè§’è‰²æ‰®æ¼”å¿ å®åº¦ç­‰æ–¹é¢çš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œé‡‡ç”¨äº†å¤šæ ·åŒ–çš„è§’è‰²å®šä¹‰å’Œä¸°å¯Œçš„å¯¹è¯åœºæ™¯ï¼›è¯„ä¼°æ ‡å‡†åˆ™æ¶µç›–äº†åŸºæœ¬äº’åŠ¨èƒ½åŠ›ã€è¯­éŸ³è¡¨ç°åŠ›å’Œè§’è‰²æ‰®æ¼”å¿ å®åº¦ç­‰å¤šä¸ªç»´åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œçº§è”å’Œç«¯åˆ°ç«¯çš„è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†åœ¨å£°éŸ³é£æ ¼ä¸€è‡´æ€§å’Œè§’è‰²è¿è´¯æ€§æ–¹é¢çš„è¡¨ç°å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦å°†åœ¨åç»­ç ”ç©¶ä¸­è¯¦ç»†æ¢è®¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹ŸåŠ©æ‰‹ã€æ¸¸æˆè§’è‰²äº’åŠ¨ã€æ•™è‚²åŸ¹è®­ç­‰ã€‚é€šè¿‡æå‡è¯­éŸ³è§’è‰²æ‰®æ¼”ä»£ç†çš„è¡¨ç°ï¼Œå¯ä»¥å®ç°æ›´è‡ªç„¶å’Œä¸ªæ€§åŒ–çš„ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, role-playing agents have emerged as a promising paradigm for achieving personalized interaction and emotional resonance. Existing research primarily focuses on the textual modality, neglecting the critical dimension of speech in realistic interactive scenarios. In particular, there is a lack of systematic evaluation for Speech Role-Playing Agents (SRPAs). To address this gap, we construct SpeechRole-Data, a large-scale, high-quality dataset that comprises 98 diverse roles and 112k speech-based single-turn and multi-turn conversations. Each role demonstrates distinct vocal characteristics, including timbre and prosody, thereby enabling more sophisticated speech role-playing. Furthermore, we propose SpeechRole-Eval, a multidimensional evaluation benchmark that systematically assesses SRPAs performance in key aspects such as fundamental interaction ability, speech expressiveness, and role-playing fidelity. Experimental results reveal the advantages and challenges of both cascaded and end-to-end speech role-playing agents in maintaining vocal style consistency and role coherence. We release all data, code, and baseline models to provide a solid foundation for speech-driven multimodal role-playing research and to foster further developments in this field.

