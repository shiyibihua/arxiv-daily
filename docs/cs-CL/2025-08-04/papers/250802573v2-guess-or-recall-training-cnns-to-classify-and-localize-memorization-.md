---
layout: default
title: Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs
---

# Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02573" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02573v2</a>
  <a href="https://arxiv.org/pdf/2508.02573.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02573v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02573v2', 'Guess or Recall? Training CNNs to Classify and Localize Memorization in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: JÃ©rÃ©mie Dentan, Davide Buscaldi, Sonia Vanier

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04 (æ›´æ–°: 2025-11-13)

**å¤‡æ³¨**: This paper has been accepted for publication at AAAI-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°åˆ†ç±»æ³•ä»¥åˆ†æå¤§è¯­è¨€æ¨¡å‹ä¸­çš„è®°å¿†ç°è±¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è®°å¿†æœºåˆ¶` `å·ç§¯ç¥ç»ç½‘ç»œ` `æ³¨æ„åŠ›æƒé‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è®°å¿†åˆ†ç±»æ³•æœªèƒ½æœ‰æ•ˆåæ˜ å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ä¸åŒè®°å¿†æœºåˆ¶ï¼Œå¯¼è‡´åˆ†æä¸å‡†ç¡®ã€‚
2. æœ¬æ–‡é€šè¿‡è®­ç»ƒCNNåˆ†æLLMçš„æ³¨æ„åŠ›æƒé‡ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è®°å¿†åˆ†ç±»æ³•ï¼Œæ—¨åœ¨æé«˜å¯¹è®°å¿†ç°è±¡çš„ç†è§£ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°‘é‡é€å­—è®°å¿†å¹¶ä¸å¯¹åº”äºç‰¹å®šçš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸”è®¸å¤šæ ·æœ¬æ˜¯æ¨¡å‹çš„çŒœæµ‹ï¼Œéœ€è¿›è¡Œå•ç‹¬ç ”ç©¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­ï¼Œé€å­—è®°å¿†æ˜¯ä¸€ç§å¤æ‚ç°è±¡ï¼Œæ¶‰åŠä¸åŒçš„åŸºæœ¬æœºåˆ¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åˆ†æLLMçš„æ³¨æ„åŠ›æƒé‡ï¼Œå¹¶è¯„ä¼°ç°æœ‰è®°å¿†åˆ†ç±»æ³•ä¸æ³¨æ„åŠ›æƒé‡çš„å¯¹é½æƒ…å†µã€‚ç ”ç©¶å‘ç°ï¼Œç°æœ‰åˆ†ç±»æ³•è¡¨ç°ä¸ä½³ï¼Œæœªèƒ½åæ˜ æ³¨æ„åŠ›å—ä¸­çš„ä¸åŒæœºåˆ¶ã€‚æˆ‘ä»¬æå‡ºçš„æ–°åˆ†ç±»æ³•åŒ…æ‹¬ä¸‰ç±»ï¼šé€šè¿‡è¯­è¨€å»ºæ¨¡èƒ½åŠ›çŒœæµ‹çš„è®°å¿†æ ·æœ¬ã€é«˜é‡å¤è®­ç»ƒé›†å¯¼è‡´çš„å›å¿†æ ·æœ¬ä»¥åŠéè®°å¿†æ ·æœ¬ã€‚ç»“æœæ˜¾ç¤ºï¼Œå°‘é‡é€å­—è®°å¿†å¹¶ä¸å¯¹åº”äºç‹¬ç‰¹çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸”å¤§é‡å¯æå–æ ·æœ¬å®é™…ä¸Šæ˜¯æ¨¡å‹çŒœæµ‹çš„ï¼Œéœ€å•ç‹¬ç ”ç©¶ã€‚æœ€åï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§è‡ªå®šä¹‰çš„å¯è§†åŒ–è§£é‡ŠæŠ€æœ¯ï¼Œä»¥å®šä½ä¸æ¯ç§è®°å¿†å½¢å¼ç›¸å…³çš„æ³¨æ„åŠ›æƒé‡åŒºåŸŸã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è®°å¿†åˆ†ç±»æ³•åœ¨åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯æœªèƒ½å‡†ç¡®åæ˜ æ³¨æ„åŠ›æœºåˆ¶çš„å¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åœ¨LLMçš„æ³¨æ„åŠ›æƒé‡ä¸Šè¿›è¡Œåˆ†æï¼Œæå‡ºæ–°çš„åˆ†ç±»æ³•ä»¥æé«˜å¯¹è®°å¿†ç°è±¡çš„ç†è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€CNNè®­ç»ƒã€æ³¨æ„åŠ›æƒé‡åˆ†æå’Œæ–°åˆ†ç±»æ³•çš„æå‡ºï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œç»“æœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„æ–°åˆ†ç±»æ³•å°†è®°å¿†æ ·æœ¬åˆ†ä¸ºä¸‰ç±»ï¼Œå¼ºè°ƒäº†æ¨¡å‹çŒœæµ‹å’Œé«˜é‡å¤æ ·æœ¬çš„åŒºåˆ«ï¼Œæ˜¾è‘—æ”¹å–„äº†å¯¹è®°å¿†æœºåˆ¶çš„ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œä½¿ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿CNNèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ³¨æ„åŠ›æƒé‡çš„ç‰¹å¾ï¼Œå¹¶è¿›è¡Œå¯è§†åŒ–è§£é‡Šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰çš„è®°å¿†åˆ†ç±»æ³•åœ¨åæ˜ æ³¨æ„åŠ›æœºåˆ¶æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œè€Œæ–°æå‡ºçš„åˆ†ç±»æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æ³¨æ„åŠ›æƒé‡ã€‚ç ”ç©¶å‘ç°ï¼Œå°‘é‡é€å­—è®°å¿†å¹¶ä¸å¯¹åº”äºç‹¬ç‰¹çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¸”çº¦æœ‰ç›¸å½“æ¯”ä¾‹çš„æ ·æœ¬æ˜¯æ¨¡å‹çš„çŒœæµ‹ï¼Œéœ€å•ç‹¬åˆ†æã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„è®°å¿†æœºåˆ¶ï¼Œå¯ä»¥ä¼˜åŒ–æ¨¡å‹è®¾è®¡ï¼Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒå’Œæ›´å‡†ç¡®çš„è®°å¿†åˆ†ææ–¹æ³•çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Verbatim memorization in Large Language Models (LLMs) is a multifaceted phenomenon involving distinct underlying mechanisms. We introduce a novel method to analyze the different forms of memorization described by the existing taxonomy. Specifically, we train Convolutional Neural Networks (CNNs) on the attention weights of the LLM and evaluate the alignment between this taxonomy and the attention weights involved in decoding.
>   We find that the existing taxonomy performs poorly and fails to reflect distinct mechanisms within the attention blocks. We propose a new taxonomy that maximizes alignment with the attention weights, consisting of three categories: memorized samples that are guessed using language modeling abilities, memorized samples that are recalled due to high duplication in the training set, and non-memorized samples. Our results reveal that few-shot verbatim memorization does not correspond to a distinct attention mechanism. We also show that a significant proportion of extractable samples are in fact guessed by the model and should therefore be studied separately. Finally, we develop a custom visual interpretability technique to localize the regions of the attention weights involved in each form of memorization.

