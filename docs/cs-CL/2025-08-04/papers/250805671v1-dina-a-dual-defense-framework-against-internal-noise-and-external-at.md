---
layout: default
title: DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing
---

# DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.05671" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.05671v1</a>
  <a href="https://arxiv.org/pdf/2508.05671.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.05671v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.05671v1', 'DINA: A Dual Defense Framework Against Internal Noise and External Attacks in Natural Language Processing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ko-Wei Chuang, Hen-Hsen Huang, Tsai-Yen Li

**åˆ†ç±»**: cs.CR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

**å¤‡æ³¨**: 7 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDINAæ¡†æ¶ä»¥åº”å¯¹NLPä¸­çš„å†…éƒ¨å™ªå£°å’Œå¤–éƒ¨æ”»å‡»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªç„¶è¯­è¨€å¤„ç†` `å¯¹æŠ—è®­ç»ƒ` `å™ªå£°æ ‡ç­¾å­¦ä¹ ` `æ¨¡å‹é²æ£’æ€§` `åŒé‡é˜²å¾¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•åœ¨é¢å¯¹å¤–éƒ¨æ”»å‡»å’Œå†…éƒ¨æ ‡ç­¾å™ªå£°æ—¶è¡¨ç°è„†å¼±ï¼Œç¼ºä¹æœ‰æ•ˆçš„åŒé‡é˜²å¾¡æœºåˆ¶ã€‚
2. DINAæ¡†æ¶é€šè¿‡ç»“åˆå™ªå£°æ ‡ç­¾å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒï¼Œæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨åŒæ—¶åº”å¯¹å†…éƒ¨å’Œå¤–éƒ¨å¨èƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDINAåœ¨çœŸå®æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æœ‰æ˜æ˜¾æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹å’Œç”Ÿæˆå¼äººå·¥æ™ºèƒ½åœ¨å®¢æˆ·æœåŠ¡å’Œå†…å®¹å®¡æ ¸ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œæ¥è‡ªå¤–éƒ¨æ“æ§å’Œå†…éƒ¨æ ‡ç­¾è…è´¥çš„å¯¹æŠ—æ€§å¨èƒæ—¥ç›Šçªå‡ºã€‚æœ¬æ–‡æå‡ºDINAï¼ˆåŒé‡é˜²å¾¡å†…éƒ¨å™ªå£°å’Œå¯¹æŠ—æ”»å‡»ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»Ÿä¸€æ¡†æ¶ã€‚è¯¥æ–¹æ³•ç»“åˆäº†è®¡ç®—æœºè§†è§‰ä¸­çš„å…ˆè¿›å™ªå£°æ ‡ç­¾å­¦ä¹ æŠ€æœ¯ä¸å¯¹æŠ—è®­ç»ƒï¼Œæ—¨åœ¨åŒæ—¶å‡è½»å†…éƒ¨æ ‡ç­¾ç ´åå’Œå¤–éƒ¨å¯¹æŠ—æ‰°åŠ¨çš„å½±å“ã€‚é€šè¿‡åœ¨çœŸå®åœ¨çº¿æ¸¸æˆæœåŠ¡æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼ŒDINAæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œå¼ºè°ƒäº†åŒé‡å¨èƒé˜²å¾¡çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºåœ¨ç°å®å¯¹æŠ—åœºæ™¯ä¸­ä¿æŠ¤NLPç³»ç»Ÿæä¾›äº†å®ç”¨ç­–ç•¥ï¼Œå…·æœ‰æ›´å¹¿æ³›çš„å…¬å¹³å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½éƒ¨ç½²æ„ä¹‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„åŒé‡å¯¹æŠ—å¨èƒï¼ŒåŒ…æ‹¬å¤–éƒ¨æ”»å‡»å’Œå†…éƒ¨æ ‡ç­¾å™ªå£°ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•ä¸€å¨èƒï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„è„†å¼±æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDINAæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è®¡ç®—æœºè§†è§‰ä¸­çš„å™ªå£°æ ‡ç­¾å­¦ä¹ æ–¹æ³•ä¸å¯¹æŠ—è®­ç»ƒç›¸ç»“åˆï¼Œå½¢æˆä¸€ä¸ªç»Ÿä¸€çš„é˜²å¾¡æœºåˆ¶ï¼Œä»¥åŒæ—¶åº”å¯¹å†…éƒ¨å’Œå¤–éƒ¨çš„å¯¹æŠ—æ€§å¹²æ‰°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDINAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå™ªå£°æ ‡ç­¾å­¦ä¹ æ¨¡å—å’Œå¯¹æŠ—è®­ç»ƒæ¨¡å—ã€‚å‰è€…ç”¨äºè¯†åˆ«å’Œä¿®æ­£å†…éƒ¨æ ‡ç­¾å™ªå£°ï¼Œåè€…åˆ™å¢å¼ºæ¨¡å‹å¯¹å¤–éƒ¨æ”»å‡»çš„æŠµæŠ—åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šDINAçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶åŒé‡é˜²å¾¡ç­–ç•¥ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†å†…éƒ¨å’Œå¤–éƒ¨å¨èƒï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•å•ä¸€é˜²å¾¡çš„ç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒDINAé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å™ªå£°æ ‡ç­¾å­¦ä¹ ä¸å¯¹æŠ—è®­ç»ƒçš„ç›®æ ‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜æ¨¡å‹çš„æ•´ä½“æ€§èƒ½å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDINAåœ¨çœŸå®åœ¨çº¿æ¸¸æˆæœåŠ¡æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°XX%ï¼Œæœ‰æ•ˆè¯æ˜äº†åŒé‡é˜²å¾¡ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DINAæ¡†æ¶åœ¨å®¢æˆ·æœåŠ¡ã€å†…å®¹å®¡æ ¸å’Œåœ¨çº¿æ¸¸æˆç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å¢å¼ºè‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿçš„é²æ£’æ€§ï¼Œè¯¥ç ”ç©¶ä¸ºå®é™…åº”ç”¨ä¸­çš„å¯¹æŠ—æ€§å¨èƒæä¾›äº†æœ‰æ•ˆçš„é˜²æŠ¤ç­–ç•¥ï¼Œä¿ƒè¿›äº†å…¬å¹³å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½æŠ€æœ¯çš„éƒ¨ç½²ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) and generative AI become increasingly integrated into customer service and moderation applications, adversarial threats emerge from both external manipulations and internal label corruption. In this work, we identify and systematically address these dual adversarial threats by introducing DINA (Dual Defense Against Internal Noise and Adversarial Attacks), a novel unified framework tailored specifically for NLP. Our approach adapts advanced noisy-label learning methods from computer vision and integrates them with adversarial training to simultaneously mitigate internal label sabotage and external adversarial perturbations. Extensive experiments conducted on a real-world dataset from an online gaming service demonstrate that DINA significantly improves model robustness and accuracy compared to baseline models. Our findings not only highlight the critical necessity of dual-threat defenses but also offer practical strategies for safeguarding NLP systems in realistic adversarial scenarios, underscoring broader implications for fair and responsible AI deployment.

