---
layout: default
title: From Monolingual to Bilingual: Investigating Language Conditioning in Large Language Models for Psycholinguistic Tasks
---

# From Monolingual to Bilingual: Investigating Language Conditioning in Large Language Models for Psycholinguistic Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02502" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02502v1</a>
  <a href="https://arxiv.org/pdf/2508.02502.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02502v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02502v1', 'From Monolingual to Bilingual: Investigating Language Conditioning in Large Language Models for Psycholinguistic Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuzhou Yuan, Zhan Qu, Mario Tawfelis, Michael FÃ¤rber

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¯­è¨€æ¡ä»¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹å¿ƒç†è¯­è¨€å­¦ä»»åŠ¡çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¿ƒç†è¯­è¨€å­¦` `è¯­è¨€èº«ä»½` `è·¨è¯­è¨€è®¤çŸ¥` `å£°éŸ³è±¡å¾` `è¯æ±‡æ•ˆä»·` `å¤šè¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è·¨è¯­è¨€å¿ƒç†è¯­è¨€å­¦ååº”ä¸­çš„è¡¨ç°äº†è§£ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒè¯­è¨€èº«ä»½ä¸‹çš„è¡¨ç°ã€‚
2. æœ¬æ–‡é€šè¿‡å£°éŸ³è±¡å¾å’Œè¯æ±‡æ•ˆä»·ä»»åŠ¡ï¼Œæ¢è®¨LLMså¦‚ä½•åœ¨å•è¯­å’ŒåŒè¯­æç¤ºä¸‹è°ƒæ•´å…¶è¾“å‡ºï¼Œæ­ç¤ºè¯­è¨€èº«ä»½çš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQwenæ¨¡å‹åœ¨è·å…°è¯­å’Œä¸­æ–‡ä¹‹é—´çš„åŒºåˆ†èƒ½åŠ›æ›´å¼ºï¼Œä¸”ä¸­æ–‡æç¤ºçš„æ•ˆä»·è¡¨ç¤ºæ›´ä¸ºç¨³å®šï¼Œæä¾›äº†æ–°çš„è®¤çŸ¥æ¨¡å‹è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç°å‡ºå¼ºå¤§çš„è¯­è¨€èƒ½åŠ›ï¼Œä½†å…³äºå®ƒä»¬å¦‚ä½•è·¨è¯­è¨€ç¼–ç å¿ƒç†è¯­è¨€å­¦çŸ¥è¯†çš„ç ”ç©¶ä»ç„¶è¾ƒå°‘ã€‚æœ¬æ–‡æ¢è®¨äº†LLMsåœ¨ä¸åŒè¯­è¨€èº«ä»½ä¸‹æ˜¯å¦ä»¥åŠå¦‚ä½•è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„å¿ƒç†è¯­è¨€å­¦ååº”ï¼Œä½¿ç”¨äº†å£°éŸ³è±¡å¾å’Œè¯æ±‡æ•ˆä»·ä¸¤ä¸ªä»»åŠ¡ã€‚æˆ‘ä»¬è¯„ä¼°äº†Llama-3.3-70B-Instructå’ŒQwen2.5-72B-Instructæ¨¡å‹åœ¨è‹±è¯­ã€è·å…°è¯­å’Œä¸­æ–‡çš„å•è¯­å’ŒåŒè¯­æç¤ºä¸‹çš„è¡¨ç°ã€‚ç»“æœè¡¨æ˜ï¼Œä¸¤ç§æ¨¡å‹çš„è¾“å‡ºä¼šæ ¹æ®æç¤ºçš„è¯­è¨€èº«ä»½è¿›è¡Œè°ƒæ•´ï¼Œå…¶ä¸­Qwenåœ¨è·å…°è¯­å’Œä¸­æ–‡ä¹‹é—´çš„åŒºåˆ†æ›´ä¸ºæ•æ„Ÿã€‚æ¢æµ‹åˆ†ææ˜¾ç¤ºï¼Œå¿ƒç†è¯­è¨€å­¦ä¿¡å·åœ¨æ›´æ·±å±‚æ¬¡ä¸­å˜å¾—æ›´æ˜“è§£ç ï¼Œä¸­æ–‡æç¤ºçš„æ•ˆä»·è¡¨ç¤ºæ¯”è·å…°è¯­æ›´å¼ºä¸”æ›´ç¨³å®šã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†è¯­è¨€èº«ä»½å¦‚ä½•å½±å“LLMsçš„è¾“å‡ºè¡Œä¸ºå’Œå†…éƒ¨è¡¨å¾ï¼Œä¸ºå…¶ä½œä¸ºè·¨è¯­è¨€è®¤çŸ¥æ¨¡å‹çš„åº”ç”¨æä¾›äº†æ–°è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸åŒè¯­è¨€èº«ä»½ä¸‹çš„å¿ƒç†è¯­è¨€å­¦ååº”è¡¨ç°ä¸æ˜ç¡®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æ¢è®¨è¯­è¨€èº«ä»½å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹æ¯”åˆ†æä¸¤ç§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å•è¯­å’ŒåŒè¯­æç¤ºä¸‹çš„è¡¨ç°ï¼Œç ”ç©¶è¯­è¨€èº«ä»½å¦‚ä½•å½±å“æ¨¡å‹çš„è¾“å‡ºè¡Œä¸ºå’Œå†…éƒ¨è¡¨å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å£°éŸ³è±¡å¾å’Œè¯æ±‡æ•ˆä»·ä¸¤ä¸ªä»»åŠ¡ï¼Œè¯„ä¼°Llama-3.3-70B-Instructå’ŒQwen2.5-72B-Instructæ¨¡å‹åœ¨è‹±è¯­ã€è·å…°è¯­å’Œä¸­æ–‡çš„è¡¨ç°ï¼Œåˆ†æå…¶è¾“å‡ºçš„è¯­è¨€èº«ä»½è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†è¯­è¨€èº«ä»½å¯¹LLMsè¾“å‡ºè¡Œä¸ºå’Œå†…éƒ¨è¡¨ç¤ºçš„æ¡ä»¶ä½œç”¨ï¼Œæä¾›äº†è·¨è¯­è¨€è®¤çŸ¥çš„æ–°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†ä¸åŒè¯­è¨€çš„æç¤ºï¼Œåˆ†æäº†æ¨¡å‹åœ¨ä¸åŒå±‚æ¬¡çš„å¿ƒç†è¯­è¨€å­¦ä¿¡å·è§£ç èƒ½åŠ›ï¼Œç‰¹åˆ«å…³æ³¨ä¸­æ–‡æç¤ºçš„æ•ˆä»·è¡¨ç¤ºçš„ç¨³å®šæ€§å’Œå¼ºåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQwenæ¨¡å‹åœ¨è·å…°è¯­å’Œä¸­æ–‡ä¹‹é—´çš„åŒºåˆ†èƒ½åŠ›æ˜¾è‘—ä¼˜äºLlamaæ¨¡å‹ï¼Œä¸”åœ¨ä¸­æ–‡æç¤ºä¸‹çš„æ•ˆä»·è¡¨ç¤ºæ¯”è·å…°è¯­æ›´å¼ºï¼Œè¡¨ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§ã€‚è¿™ä¸€å‘ç°ä¸ºç†è§£LLMsçš„è·¨è¯­è¨€è®¤çŸ¥æä¾›äº†é‡è¦æ•°æ®æ”¯æŒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è·¨è¯­è¨€æ•™è‚²ã€ç¿»è¯‘ç³»ç»Ÿå’Œå¤šè¯­è¨€å¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£è¯­è¨€èº«ä»½å¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œå¯ä»¥æå‡è¿™äº›ç³»ç»Ÿçš„è¯­è¨€é€‚åº”æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹å’Œæ•™è‚²å·¥å…·çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) exhibit strong linguistic capabilities, but little is known about how they encode psycholinguistic knowledge across languages. We investigate whether and how LLMs exhibit human-like psycholinguistic responses under different linguistic identities using two tasks: sound symbolism and word valence. We evaluate two models, Llama-3.3-70B-Instruct and Qwen2.5-72B-Instruct, under monolingual and bilingual prompting in English, Dutch, and Chinese. Behaviorally, both models adjust their outputs based on prompted language identity, with Qwen showing greater sensitivity and sharper distinctions between Dutch and Chinese. Probing analysis reveals that psycholinguistic signals become more decodable in deeper layers, with Chinese prompts yielding stronger and more stable valence representations than Dutch. Our results demonstrate that language identity conditions both output behavior and internal representations in LLMs, providing new insights into their application as models of cross-linguistic cognition.

