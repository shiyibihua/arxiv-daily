---
layout: default
title: I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2
---

# I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02527" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02527v2</a>
  <a href="https://arxiv.org/pdf/2508.02527.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02527v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02527v2', 'I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic Representations in LLaMA 3.2')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Oliver McLaughlin, Arjun Khurana, Jack Merullo

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04 (æ›´æ–°: 2025-10-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLaMA 3.2å†…éƒ¨éŸ³ç´ è¡¨ç¤ºä»¥æå‡éŸµå¾‹ä»»åŠ¡èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³ç´ è¡¨ç¤º` `éŸµå¾‹ä»»åŠ¡` `LLaMA` `è‡ªç„¶è¯­è¨€å¤„ç†` `éŸ³éŸµæ¨¡å‹` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éŸ³éŸµä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†ç¼ºä¹å¯¹éŸ³ç´ è¡¨ç¤ºçš„æ·±å…¥ç†è§£ï¼Œé™åˆ¶äº†å…¶åº”ç”¨æ½œåŠ›ã€‚
2. æœ¬æ–‡é€šè¿‡åˆ†æLLaMA 3.2çš„å†…éƒ¨éŸ³ç´ è¡¨ç¤ºï¼Œæ­ç¤ºå…¶åœ¨éŸµå¾‹ä»»åŠ¡ä¸­çš„éŸ³ç´ æ¨¡å‹åŠå…¶ç»„ç»‡ç»“æ„ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLaMAèƒ½å¤Ÿåœ¨æ²¡æœ‰ç›´æ¥ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œå­¦ä¹ ä¸æ ‡å‡†IPAå…ƒéŸ³å›¾ç›¸ä¼¼çš„éŸ³ç´ è¡¨ç¤ºï¼Œå±•ç°å‡ºå…¶éŸ³éŸµå¤„ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éŸµå¾‹ç­‰éŸ³éŸµä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå°½ç®¡æ²¡æœ‰æ˜ç¡®çš„éŸ³éŸµæˆ–å¬è§‰åŸºç¡€ã€‚æœ¬æ–‡ç ”ç©¶äº†LLaMA 3.2å¦‚ä½•è¡¨ç¤ºæ ‡è®°çº§éŸ³ç´ ä¿¡æ¯ã€‚ç»“æœè¡¨æ˜ï¼ŒLLaMAä½¿ç”¨ä¸°å¯Œçš„éŸ³ç´ å†…éƒ¨æ¨¡å‹æ¥å®ŒæˆéŸ³éŸµä»»åŠ¡ï¼Œå¹¶åœ¨å…¶æ½œåœ¨ç©ºé—´ä¸­å‘ç°éŸ³ç´ è¡¨ç¤ºçš„é«˜çº§ç»„ç»‡ç»“æ„ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¯†åˆ«å‡ºä¸€ä¸ªâ€œéŸ³ç´ ç§»åŠ¨å¤´â€ï¼Œåœ¨éŸµå¾‹ä»»åŠ¡ä¸­ä¿ƒè¿›éŸ³éŸµä¿¡æ¯çš„ä¼ é€’ã€‚æˆ‘ä»¬å¯è§†åŒ–äº†è¯¥å¤´çš„è¾“å‡ºç©ºé—´ï¼Œå‘ç°å°½ç®¡å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒLLaMAå­¦ä¹ çš„å…ƒéŸ³æ¨¡å‹ä¸æ ‡å‡†å›½é™…éŸ³æ ‡ï¼ˆIPAï¼‰å…ƒéŸ³å›¾ç›¸ä¼¼ï¼Œå°½ç®¡æ²¡æœ‰ç›´æ¥ç›‘ç£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨LLaMA 3.2å¦‚ä½•è¡¨ç¤ºéŸ³ç´ ä¿¡æ¯ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹éŸ³ç´ å†…éƒ¨ç»“æ„çš„æ·±å…¥åˆ†æï¼Œé™åˆ¶äº†å¯¹å…¶éŸ³éŸµèƒ½åŠ›çš„ç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç ”ç©¶LLaMAçš„æ½œåœ¨ç©ºé—´ï¼Œè¯†åˆ«éŸ³ç´ è¡¨ç¤ºçš„ç»„ç»‡ç»“æ„ï¼Œå¹¶å‘ç°ä¿ƒè¿›éŸ³éŸµä¿¡æ¯ä¼ é€’çš„â€œéŸ³ç´ ç§»åŠ¨å¤´â€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä¸»è¦åŒ…æ‹¬å¯¹LLaMA 3.2çš„éŸ³ç´ è¡¨ç¤ºè¿›è¡Œåˆ†æï¼Œè¯†åˆ«å…¶å†…éƒ¨ç»“æ„ï¼Œå¹¶å¯è§†åŒ–éŸ³ç´ ç§»åŠ¨å¤´çš„è¾“å‡ºç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯†åˆ«å‡ºâ€œéŸ³ç´ ç§»åŠ¨å¤´â€è¿™ä¸€æ–°æ¦‚å¿µï¼Œæ­ç¤ºäº†LLaMAåœ¨éŸµå¾‹ä»»åŠ¡ä¸­å¦‚ä½•åˆ©ç”¨éŸ³ç´ ä¿¡æ¯ï¼Œå±•ç¤ºäº†å…¶å†…éƒ¨éŸ³ç´ æ¨¡å‹çš„ä¸°å¯Œæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿éŸ³ç´ è¡¨ç¤ºçš„æœ‰æ•ˆå­¦ä¹ ï¼Œå¹¶é€šè¿‡å¯è§†åŒ–æŠ€æœ¯å±•ç¤ºäº†éŸ³ç´ ç§»åŠ¨å¤´çš„è¾“å‡ºç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLaMAåœ¨éŸµå¾‹ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨éŸ³ç´ è¡¨ç¤ºçš„å­¦ä¹ ä¸Šï¼Œå±•ç¤ºäº†ä¸æ ‡å‡†IPAå…ƒéŸ³å›¾çš„ç›¸ä¼¼æ€§ï¼Œè¡¨æ˜å…¶éŸ³éŸµå¤„ç†èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºéŸ³éŸµå¤„ç†å’Œè¯­è¨€ç”Ÿæˆé¢†åŸŸæä¾›äº†æ–°çš„è§†è§’ï¼Œæ½œåœ¨åº”ç”¨åŒ…æ‹¬è¯—æ­Œåˆ›ä½œã€æ­Œè¯ç”ŸæˆåŠå…¶ä»–éœ€è¦éŸ³éŸµæ„ŸçŸ¥çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹åœ¨éŸ³éŸµä»»åŠ¡ä¸Šçš„åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models demonstrate proficiency on phonetic tasks, such as rhyming, without explicit phonetic or auditory grounding. In this work, we investigate how \verb\|Llama-3.2-1B-Instruct\| represents token-level phonetic information. Our results suggest that Llama uses a rich internal model of phonemes to complete phonetic tasks. We provide evidence for high-level organization of phoneme representations in its latent space. In doing so, we also identify a ``phoneme mover head" which promotes phonetic information during rhyming tasks. We visualize the output space of this head and find that, while notable differences exist, Llama learns a model of vowels similar to the standard IPA vowel chart for humans, despite receiving no direct supervision to do so.

