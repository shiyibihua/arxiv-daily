---
layout: default
title: PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs
---

# PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02515" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02515v1</a>
  <a href="https://arxiv.org/pdf/2508.02515.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02515v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02515v1', 'PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhan Qu, Shuzhou Yuan, Michael FÃ¤rber

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPoeToneæ¡†æ¶ä»¥å®ç°ç»“æ„åŒ–ä¸­æ–‡å®‹è¯çš„çº¦æŸç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‹è¯ç”Ÿæˆ` `è‡ªåŠ¨è¯„ä¼°` `ç›‘ç£å¾®è°ƒ` `ç”Ÿæˆ-è¯„ä¼°æ¶æ„` `æ–‡åŒ–ä¼ æ‰¿` `ä¸­æ–‡è¯—æ­Œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆç»“æ„åŒ–ä¸­æ–‡å®‹è¯æ—¶ï¼Œéš¾ä»¥æ»¡è¶³ä¸¥æ ¼çš„éŸ³éŸµå’Œç»“æ„çº¦æŸï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸é«˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç”Ÿæˆ-è¯„ä¼°æ¶æ„ï¼Œåˆ©ç”¨è‡ªåŠ¨è¯„ä¼°æ¡†æ¶ä½œä¸ºåé¦ˆæœºåˆ¶æ¥ä¼˜åŒ–LLMsçš„ç”Ÿæˆèƒ½åŠ›ã€‚
3. é€šè¿‡å¯¹18ä¸ªLLMsçš„è¯„ä¼°ï¼Œå‘ç°å¾®è°ƒåçš„æ¨¡å‹åœ¨å½¢å¼ç¬¦åˆåº¦ä¸Šæé«˜äº†5.88%ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆå®‹è¯è¿™ä¸€å…·æœ‰ä¸¥æ ¼ç»“æ„ã€éŸ³è°ƒå’ŒéŸµå¾‹çº¦æŸçš„å¤å…¸ä¸­æ–‡è¯—æ­Œå½¢å¼æ–¹é¢çš„èƒ½åŠ›ã€‚æˆ‘ä»¬é¦–å…ˆå¼€å‘äº†ä¸€ä¸ªå…¨é¢çš„å¤šç»´è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼šå½¢å¼ç¬¦åˆåº¦è¯„åˆ†ã€åŸºäºLLMsçš„è‡ªåŠ¨è´¨é‡è¯„ä¼°ã€äººç±»è¯„ä¼°å’Œåˆ†ç±»æ¢æµ‹ä»»åŠ¡ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬è¯„ä¼°äº†18ä¸ªLLMsçš„ç”Ÿæˆæ€§èƒ½ï¼Œæ¶µç›–3ä¸ªä¸“æœ‰æ¨¡å‹å’Œ15ä¸ªå¼€æºæ¨¡å‹ï¼Œé‡‡ç”¨äº”ç§æç¤ºç­–ç•¥ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ç”Ÿæˆ-è¯„ä¼°æ¶æ„ï¼Œå…¶ä¸­è¯„ä¼°æ¡†æ¶ä½œä¸ºè‡ªåŠ¨è¯„ä¼°è€…ï¼Œé€šè¿‡åé¦ˆä¿¡å·å¯¹ä¸‰ç§è½»é‡çº§å¼€æºLLMsè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œå½¢å¼ç¬¦åˆåº¦æé«˜äº†5.88%ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºLLMsåœ¨ç”Ÿæˆå…·æœ‰æ–‡åŒ–æ„ä¹‰å’Œå½¢å¼çº¦æŸçš„æ–‡å­¦æ–‡æœ¬æ–¹é¢çš„ä¼˜ç¼ºç‚¹æä¾›äº†æ–°è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆç»“æ„åŒ–ä¸­æ–‡å®‹è¯æ—¶é¢ä¸´çš„éŸ³éŸµå’Œç»“æ„çº¦æŸé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ»¡è¶³è¿™äº›ä¸¥æ ¼çš„ç”Ÿæˆè¦æ±‚ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœä¸ç¬¦åˆä¼ ç»Ÿè¯—æ­Œçš„æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç”Ÿæˆ-è¯„ä¼°æ¶æ„ï¼Œé€šè¿‡è‡ªåŠ¨è¯„ä¼°æ¡†æ¶æä¾›åé¦ˆä¿¡å·ï¼ŒæŒ‡å¯¼æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ï¼Œä»è€Œæå‡ç”Ÿæˆçš„è´¨é‡å’Œç¬¦åˆåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å››ä¸ªä¸»è¦æ¨¡å—ï¼šè¯„ä¼°æ¡†æ¶ï¼ˆå½¢å¼ç¬¦åˆåº¦è¯„åˆ†ã€è‡ªåŠ¨è´¨é‡è¯„ä¼°ã€äººç±»è¯„ä¼°å’Œåˆ†ç±»æ¢æµ‹ä»»åŠ¡ï¼‰ã€18ä¸ªLLMsçš„æ€§èƒ½è¯„ä¼°ã€ç”Ÿæˆ-è¯„ä¼°æ¶æ„çš„å®ç°ï¼Œä»¥åŠåŸºäºåé¦ˆçš„æ¨¡å‹å¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ç”Ÿæˆ-è¯„ä¼°æ¶æ„ï¼Œä½¿å¾—è¯„ä¼°æ¡†æ¶ä¸ä»…ç”¨äºè¯„ä¼°ï¼Œè¿˜èƒ½ä½œä¸ºåé¦ˆæœºåˆ¶ï¼Œç›´æ¥å½±å“æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„ç”Ÿæˆæ¨¡å‹è®­ç»ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„æ–¹æ³•ï¼Œç»“åˆå½¢å¼ç¬¦åˆåº¦è¯„åˆ†ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œç¡®ä¿ç”Ÿæˆç»“æœåœ¨ç»“æ„å’ŒéŸµå¾‹ä¸Šæ›´ç¬¦åˆå®‹è¯çš„è¦æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒçš„ä¸‰ç§è½»é‡çº§å¼€æºLLMsåœ¨å½¢å¼ç¬¦åˆåº¦ä¸Šæé«˜äº†5.88%ã€‚è¿™ä¸€æå‡ç›¸è¾ƒäºæœªå¾®è°ƒæ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼ŒéªŒè¯äº†ç”Ÿæˆ-è¯„ä¼°æ¶æ„çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸­æ–‡è¯—æ­Œåˆ›ä½œã€æ–‡åŒ–é—äº§ä¿æŠ¤ä»¥åŠæ•™è‚²é¢†åŸŸçš„æ–‡å­¦åˆ›ä½œæ•™å­¦ã€‚é€šè¿‡æå‡LLMsåœ¨ç”Ÿæˆä¼ ç»Ÿæ–‡åŒ–æ–‡æœ¬æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥ä¿ƒè¿›æ–‡åŒ–ä¼ æ‰¿å’Œåˆ›æ–°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a systematic investigation into the constrained generation capabilities of large language models (LLMs) in producing Songci, a classical Chinese poetry form characterized by strict structural, tonal, and rhyme constraints defined by Cipai templates. We first develop a comprehensive, multi-faceted evaluation framework that includes: (i) a formal conformity score, (ii) automated quality assessment using LLMs, (iii) human evaluation, and (iv) classification-based probing tasks. Using this framework, we evaluate the generative performance of 18 LLMs, including 3 proprietary models and 15 open-source models across four families, under five prompting strategies: zero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought. Finally, we propose a Generate-Critic architecture in which the evaluation framework functions as an automated critic. Leveraging the critic's feedback as a reward signal, we fine-tune three lightweight open-source LLMs via supervised fine-tuning (SFT), resulting in improvements of up to 5.88% in formal conformity. Our findings offer new insights into the generative strengths and limitations of LLMs in producing culturally significant and formally constrained literary texts.

