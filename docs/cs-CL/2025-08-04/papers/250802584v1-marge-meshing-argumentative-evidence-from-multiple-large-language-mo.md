---
layout: default
title: MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification
---

# MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02584" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02584v1</a>
  <a href="https://arxiv.org/pdf/2508.02584.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02584v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02584v1', 'MArgE: Meshing Argumentative Evidence from Multiple Large Language Models for Justifiable Claim Verification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Pok Ng, Junqi Jiang, Gabriel Freedman, Antonio Rago, Francesca Toni

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMArgEæ¡†æ¶ä»¥è§£å†³å¤šLLMè¯æ®æ•´åˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸»å¼ éªŒè¯` `è®ºè¯æ€§æ¨ç†` `ç»“æ„åŒ–è¯æ®` `å¤šæ¨¡å‹æ•´åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ•´åˆå¤šä¸ªLLMè¾“å‡ºæ—¶ï¼Œå¾€å¾€ç¼ºä¹ç»“æ„åŒ–ï¼Œå¯¼è‡´ç”Ÿæˆçš„ç»“æœä¸å¤Ÿå¯ä¿¡ã€‚
2. æœ¬æ–‡æå‡ºMArgEæ¡†æ¶ï¼Œé€šè¿‡æ„å»ºç»“æ„åŒ–çš„è®ºè¯æ ‘ï¼Œä¸ºä¸»å¼ éªŒè¯æä¾›å½¢å¼åŒ–çš„è¯æ®æ”¯æŒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMArgEåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå•ä¸€LLMå’Œç°æœ‰çš„å¤šLLMè¾©è®ºæ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åˆ©ç”¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¾“å‡ºæ­£åœ¨æˆä¸ºä¸€ç§æ–¹æ³•ï¼Œä»¥åœ¨å¹¿æ³›ä»»åŠ¡ä¸­å‘æŒ¥å…¶èƒ½åŠ›ï¼ŒåŒæ—¶å‡è½»å…¶äº§ç”Ÿé”™è¯¯ï¼ˆå¦‚å¹»è§‰ï¼‰çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“å‰å°†å¤šä¸ªLLMçš„è§è§£ç»“åˆçš„æ–¹æ³•é€šå¸¸æ¶‰åŠéç»“æ„åŒ–çš„äº’åŠ¨ï¼Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆçš„ç»“æœç¼ºä¹å¯ä¿¡æ€§ã€‚æœ¬æ–‡æå‡ºäº†MArgEï¼Œä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œä¸ºæ¯ä¸ªLLMçš„è¯æ®æä¾›æ­£å¼ç»“æ„ï¼Œä»¥æå–è®ºè¯æ ‘çš„å½¢å¼è¿›è¡Œä¸»å¼ éªŒè¯ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸€ç§å˜ä½“çš„è®ºè¯æ€§LLMsï¼ˆArgLLMsï¼‰ï¼Œå³åŸºäºè®¡ç®—è®ºè¯é¢†åŸŸçš„æ¡†æ¶å’Œè¯­ä¹‰é©±åŠ¨çš„LLMsï¼Œæ„å»ºç»™å®šä¸»å¼ çš„ç»“æ„åŒ–è®ºè¯æ ‘ã€‚è¿™ä¸€è¿‡ç¨‹åˆ›å»ºäº†ä»åˆå§‹è®ºè¯åˆ°æœ€ç»ˆä¸»å¼ éªŒè¯å†³ç­–çš„å¯æ£€æŸ¥è·¯å¾„ï¼Œä»è€Œæä¾›äº†å¯ä¿¡çš„è¯æ˜ã€‚å®éªŒè¡¨æ˜ï¼ŒMArgEæ˜¾è‘—ä¼˜äºå•ä¸€LLMï¼ŒåŒ…æ‹¬ä¸‰ä¸ªå¼€æºæ¨¡å‹ï¼ˆ4Båˆ°8Bå‚æ•°ï¼‰ã€GPT-4o-miniä»¥åŠç°æœ‰çš„ArgLLMså’Œéç»“æ„åŒ–å¤šLLMè¾©è®ºçš„å…ˆå‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ä¸»å¼ éªŒè¯ä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆæ•´åˆå¤šä¸ªLLMçš„è¾“å‡ºä»¥æä¾›å¯ä¿¡çš„è¯æ®ã€‚ç°æœ‰æ–¹æ³•å¤šä¸ºéç»“æ„åŒ–çš„äº’åŠ¨ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœç¼ºä¹å¯è§£é‡Šæ€§å’Œå¯ä¿¡åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMArgEæ¡†æ¶é€šè¿‡æ„å»ºç»“æ„åŒ–çš„è®ºè¯æ ‘ï¼Œåˆ©ç”¨è®ºè¯æ€§LLMsï¼ˆArgLLMsï¼‰ä¸ºæ¯ä¸ªä¸»å¼ æä¾›å½¢å¼åŒ–çš„è¯æ®æ”¯æŒï¼Œç¡®ä¿ä»åˆå§‹è®ºè¯åˆ°æœ€ç»ˆå†³ç­–çš„è·¯å¾„å¯è¿½æº¯å’Œå¯æ£€æŸ¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMArgEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥ä¸»å¼ ã€ç”Ÿæˆè®ºè¯æ ‘ã€æå–è®ºè¯ã€ä»¥åŠæœ€ç»ˆçš„ä¸»å¼ éªŒè¯å†³ç­–ã€‚æ¯ä¸ªæ¨¡å—ç›¸äº’åä½œï¼Œç¡®ä¿ä¿¡æ¯çš„æœ‰æ•ˆæ•´åˆå’Œè¾“å‡ºçš„å¯ä¿¡æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMArgEçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†ç»“æ„åŒ–çš„è®ºè¯æ ‘ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„éç»“æ„åŒ–è¾©è®ºæ–¹æ³•ï¼Œä»è€Œæä¾›äº†æ›´ä¸ºæ¸…æ™°å’Œå¯éªŒè¯çš„å†³ç­–è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒMArgEä½¿ç”¨äº†åŸºäºè®¡ç®—è®ºè¯çš„æ¡†æ¶ï¼Œç»“åˆäº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–è®ºè¯æ ‘çš„ç”Ÿæˆå’ŒéªŒè¯è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMArgEåœ¨ä¸»å¼ éªŒè¯ä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºå•ä¸€LLMå’Œç°æœ‰çš„ArgLLMsï¼Œå°¤å…¶åœ¨å¤„ç†å¤æ‚ä¸»å¼ æ—¶ï¼ŒMArgEçš„æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç°å‡ºå…¶åœ¨å¤šLLMè¾“å‡ºæ•´åˆä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MArgEæ¡†æ¶åœ¨ä¸»å¼ éªŒè¯ã€ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†ç®¡ç†ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æä¾›ç»“æ„åŒ–çš„è¯æ®æ”¯æŒï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæå‡ä¿¡æ¯çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ï¼Œé€‚ç”¨äºæ³•å¾‹ã€æ–°é—»ã€å­¦æœ¯ç ”ç©¶ç­‰éœ€è¦é«˜å¯ä¿¡åº¦ä¿¡æ¯çš„åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Leveraging outputs from multiple large language models (LLMs) is emerging as a method for harnessing their power across a wide range of tasks while mitigating their capacity for making errors, e.g., hallucinations. However, current approaches to combining insights from multiple LLMs often involve unstructured interactions (e.g., free debate), resulting in model generations that are not faithfully justifiable. In this work, we introduce MArgE, a novel framework to provide formal structure to the evidence from each LLM, in the form of a tree of extracted arguments, for the task of claim verification. We use a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks and semantics from the field of computational argumentation, to construct structured argument trees for given claims. This process creates an inspectable pathway from the initial arguments to the final claim verification decisions, providing a faithful justification thereof. We show experimentally that MArgE can significantly outperform single LLMs, including three open-source models (4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior methods for unstructured multi-LLM debates. We thus demonstrate the advantages of incorporating formal, argumentative reasoning mechanisms when combining multiple LLM outputs.

