---
layout: default
title: Marco-Voice Technical Report
---

# Marco-Voice Technical Report

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02038" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02038v4</a>
  <a href="https://arxiv.org/pdf/2508.02038.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02038v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02038v4', 'Marco-Voice Technical Report')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fengping Tian, Chenyang Lyu, Xuanfan Ni, Haoqin Sun, Qingjuan Li, Zhiqiang Qian, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang

**åˆ†ç±»**: cs.CL, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04 (æ›´æ–°: 2025-08-14)

**å¤‡æ³¨**: Technical Report. Our code and dataset are publicly available at https://github.com/AIDC-AI/Marco-Voice and https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS respectively

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/AIDC-AI/Marco-Voice) | [HUGGINGFACE](https://huggingface.co/datasets/AIDC-AI)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMarco-Voiceä»¥è§£å†³è‡ªç„¶è¯­éŸ³åˆæˆä¸­çš„æƒ…æ„Ÿæ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¯­éŸ³åˆæˆ` `æƒ…æ„Ÿæ§åˆ¶` `è¯´è¯è€…å…‹éš†` `æ·±åº¦å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³åˆæˆæ–¹æ³•åœ¨æƒ…æ„Ÿè¡¨è¾¾å’Œè¯´è¯è€…èº«ä»½ä¿æŒæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å®ç°è‡ªç„¶ä¸”å¯æ§çš„è¯­éŸ³ç”Ÿæˆã€‚
2. æå‡ºäº†ä¸€ç§è¯´è¯è€…-æƒ…æ„Ÿè§£è€¦æœºåˆ¶ï¼Œç»“åˆæ‰¹å†…å¯¹æ¯”å­¦ä¹ ï¼Œå®ç°è¯´è¯è€…èº«ä»½ä¸æƒ…æ„Ÿé£æ ¼çš„ç‹¬ç«‹æ“æ§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMarco-Voiceåœ¨è¯­éŸ³æ¸…æ™°åº¦å’Œæƒ…æ„Ÿä¸°å¯Œæ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ï¼Œè¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šåŠŸèƒ½è¯­éŸ³åˆæˆç³»ç»ŸMarco-Voiceï¼Œè¯¥ç³»ç»Ÿåœ¨ç»Ÿä¸€æ¡†æ¶å†…é›†æˆäº†è¯­éŸ³å…‹éš†å’Œæƒ…æ„Ÿæ§åˆ¶è¯­éŸ³åˆæˆã€‚ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨å¤šç§è¯­è¨€å’Œæƒ…æ„Ÿä¸Šä¸‹æ–‡ä¸­å®ç°é«˜åº¦è¡¨ç°åŠ›ã€å¯æ§æ€§å’Œè‡ªç„¶è¯­éŸ³ç”Ÿæˆçš„é•¿æœŸæŒ‘æˆ˜ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æœ‰æ•ˆçš„è¯´è¯è€…-æƒ…æ„Ÿè§£è€¦æœºåˆ¶ï¼Œå¹¶é‡‡ç”¨æ‰¹å†…å¯¹æ¯”å­¦ä¹ ï¼Œä½¿å¾—è¯´è¯è€…èº«ä»½å’Œæƒ…æ„Ÿé£æ ¼å¯ä»¥ç‹¬ç«‹æ“æ§ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨æ—‹è½¬æƒ…æ„ŸåµŒå…¥é›†æˆæ–¹æ³•ä»¥å®ç°å¹³æ»‘çš„æƒ…æ„Ÿæ§åˆ¶ã€‚ä¸ºæ”¯æŒå…¨é¢çš„è®­ç»ƒå’Œè¯„ä¼°ï¼Œæˆ‘ä»¬æ„å»ºäº†CSEMOTIONSæ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªå…­ä½ä¸“ä¸šè¯´è¯è€…çš„10å°æ—¶æ™®é€šè¯æƒ…æ„Ÿè¯­éŸ³ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMarco-Voiceåœ¨è¯­éŸ³æ¸…æ™°åº¦å’Œæƒ…æ„Ÿä¸°å¯Œæ€§æ–¹é¢æ˜¾è‘—æå‡ï¼Œä»£è¡¨äº†è¡¨è¾¾æ€§ç¥ç»è¯­éŸ³åˆæˆé¢†åŸŸçš„é‡è¦è¿›å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤šç§è¯­è¨€å’Œæƒ…æ„Ÿä¸Šä¸‹æ–‡ä¸­å®ç°è‡ªç„¶ã€å¯æ§çš„è¯­éŸ³åˆæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æƒ…æ„Ÿè¡¨è¾¾å’Œè¯´è¯è€…èº«ä»½ä¿æŒæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§è¯´è¯è€…-æƒ…æ„Ÿè§£è€¦æœºåˆ¶ï¼Œé€šè¿‡æ‰¹å†…å¯¹æ¯”å­¦ä¹ å®ç°è¯´è¯è€…èº«ä»½ä¸æƒ…æ„Ÿé£æ ¼çš„ç‹¬ç«‹æ“æ§ï¼Œä»è€Œæé«˜è¯­éŸ³åˆæˆçš„è¡¨ç°åŠ›å’Œè‡ªç„¶æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæƒ…æ„Ÿæ§åˆ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºé«˜è´¨é‡çš„æƒ…æ„Ÿè¯­éŸ³æ•°æ®é›†CSEMOTIONSï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼›æœ€åï¼Œé€šè¿‡æ—‹è½¬æƒ…æ„ŸåµŒå…¥å®ç°æƒ…æ„Ÿçš„å¹³æ»‘æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†è¯´è¯è€…-æƒ…æ„Ÿè§£è€¦æœºåˆ¶ï¼Œå…è®¸ç‹¬ç«‹æ“æ§è¯´è¯è€…èº«ä»½å’Œæƒ…æ„Ÿé£æ ¼ï¼Œè¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶çµæ´»æ€§å’Œå¯æ§æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è¯´è¯è€…èº«ä»½å’Œæƒ…æ„Ÿé£æ ¼çš„è§£è€¦ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šå¼•å…¥äº†æ—‹è½¬æƒ…æ„ŸåµŒå…¥ä»¥å®ç°æƒ…æ„Ÿçš„å¹³æ»‘è¿‡æ¸¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMarco-Voiceåœ¨è¯­éŸ³æ¸…æ™°åº¦å’Œæƒ…æ„Ÿä¸°å¯Œæ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨è¡¨è¾¾æ€§ç¥ç»è¯­éŸ³åˆæˆé¢†åŸŸçš„ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯­éŸ³åŠ©æ‰‹ã€æ¸¸æˆè§’è‰²é…éŸ³ã€å½±è§†é…éŸ³ç­‰ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´åŠ è‡ªç„¶å’Œå¯Œæœ‰æƒ…æ„Ÿçš„è¯­éŸ³äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ•™è‚²ã€å¨±ä¹ç­‰å¤šä¸ªé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œæå‡äººæœºäº¤äº’çš„è´¨é‡å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a multifunctional speech synthesis system that integrates voice cloning and emotion control speech synthesis within a unified framework. The goal of this work is to address longstanding challenges in achieving highly expressive, controllable, and natural speech generation that faithfully preserves speaker identity across diverse linguistic and emotional contexts. Our approach introduces an effective speaker-emotion disentanglement mechanism with in-batch contrastive learning, enabling independent manipulation of speaker identity and eemotional style, as well as rotational emotional embedding integration method for smooth emotion control. To support comprehensive training and evaluation, we construct CSEMOTIONS, a high-quality emotional speech dataset containing 10 hours of Mandarin speech from six professional speakers across seven emotional categories. Extensive experiments demonstrate that our system, Marco-Voice, achieves substantial improvements in both objective and subjective metrics. Comprehensive evaluations and analysis were conducted, results show that MarcoVoice delivers competitive performance in terms of speech clarity and emotional richness, representing a substantial advance in the field of expressive neural speech synthesis. Our code and dataset are publicly available at https://github.com/AIDC-AI/Marco-Voice and https://huggingface.co/datasets/AIDC-AI/CSEMOTIONS respectively.

