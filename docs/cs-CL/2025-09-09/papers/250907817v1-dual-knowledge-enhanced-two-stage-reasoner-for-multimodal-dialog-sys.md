---
layout: default
title: Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems
---

# Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07817" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07817v1</a>
  <a href="https://arxiv.org/pdf/2509.07817.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07817v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07817v1', 'Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaolin Chen, Xuemeng Song, Haokun Wen, Weili Guan, Xiangyu Zhao, Liqiang Nie

**åˆ†ç±»**: cs.CL, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDK2Ræ¨¡å‹ï¼Œåˆ©ç”¨åŒé‡çŸ¥è¯†å¢å¼ºå¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿä¸­çš„æ–‡æœ¬å›å¤ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿ` `æ–‡æœ¬å›å¤ç”Ÿæˆ` `åŒé‡çŸ¥è¯†å¢å¼º` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†é€‰æ‹©` `æ„å›¾è§£è€¦` `ä»»åŠ¡å‹å¯¹è¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿä¸­ç”Ÿæˆæ–‡æœ¬å›å¤æ—¶ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨éç»“æ„åŒ–è¯„è®ºçŸ¥è¯†å’Œå¤§å‹è¯­è¨€æ¨¡å‹ã€‚
2. DK2Ræ¨¡å‹é€šè¿‡ä¸¤é˜¶æ®µæ¨ç†ï¼ŒåŠ¨æ€é€‰æ‹©ç»“æ„åŒ–å±æ€§çŸ¥è¯†å’Œéç»“æ„åŒ–è¯„è®ºçŸ¥è¯†ï¼Œå¹¶è§£è€¦æ„å›¾å’Œå›å¤ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDK2Ræ¨¡å‹åœ¨å…¬å…±æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ŒéªŒè¯äº†å…¶åœ¨æ–‡æœ¬å›å¤ç”Ÿæˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹å¤šæ¨¡æ€ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿä¸­çš„æ–‡æœ¬å›å¤ç”Ÿæˆé—®é¢˜ï¼Œæ—¨åœ¨åŸºäºå¤šæ¨¡æ€ä¸Šä¸‹æ–‡ç”Ÿæˆåˆé€‚çš„æ–‡æœ¬å›å¤ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªå±€é™æ€§ï¼šä¸€æ˜¯å¿½ç•¥äº†éç»“æ„åŒ–çš„è¯„è®ºçŸ¥è¯†ï¼ŒäºŒæ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åˆ©ç”¨ä¸è¶³ã€‚å—æ­¤å¯å‘ï¼Œæœ¬æ–‡æå‡ºåˆ©ç”¨åŒé‡çŸ¥è¯†ï¼ˆå³ç»“æ„åŒ–çš„å±æ€§çŸ¥è¯†å’Œéç»“æ„åŒ–çš„è¯„è®ºçŸ¥è¯†ï¼‰å¹¶ç»“åˆLLMsæ¥æå‡å¤šæ¨¡æ€ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿä¸­çš„æ–‡æœ¬å›å¤ç”Ÿæˆæ•ˆæœã€‚ç„¶è€Œï¼Œè¯¥ä»»åŠ¡é¢ä¸´ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šåŠ¨æ€çŸ¥è¯†ç±»å‹é€‰æ‹©å’Œæ„å›¾-å›å¤è§£è€¦ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŒé‡çŸ¥è¯†å¢å¼ºçš„ä¸¤é˜¶æ®µæ¨ç†å™¨DK2Rï¼Œé€šè¿‡è°ƒæ•´LLMsæ¥é€‚åº”å¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿã€‚å…·ä½“è€Œè¨€ï¼ŒDK2Ré¦–å…ˆä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æå–ç»“æ„åŒ–çš„å±æ€§çŸ¥è¯†å’Œéç»“æ„åŒ–çš„è¯„è®ºçŸ¥è¯†ï¼Œç„¶ååˆ©ç”¨LLMåˆ†æLLMç”Ÿæˆçš„ä¸´æ—¶æ¢æµ‹å›å¤æ¥è¯„ä¼°æ¯ç§çŸ¥è¯†ç±»å‹çš„æ•ˆç”¨ã€‚æ­¤å¤–ï¼ŒDK2Ré€šè¿‡ä¸“é—¨çš„æ¨ç†è¿‡ç¨‹åˆ†åˆ«æ€»ç»“é¢å‘æ„å›¾çš„å…³é”®çº¿ç´¢ï¼Œè¿™äº›çº¿ç´¢è¿›ä¸€æ­¥ç”¨ä½œè¾…åŠ©ä¿¡å·æ¥å¢å¼ºåŸºäºLLMçš„æ–‡æœ¬å›å¤ç”Ÿæˆã€‚åœ¨å…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒéªŒè¯äº†DK2Rçš„ä¼˜è¶Šæ€§ã€‚ä»£ç å’Œå‚æ•°å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿä¸­ï¼Œæ–‡æœ¬å›å¤ç”Ÿæˆè´¨é‡ä¸é«˜çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºï¼š1) å¿½ç•¥äº†éç»“æ„åŒ–çš„è¯„è®ºçŸ¥è¯†ï¼Œå¯¼è‡´å›å¤ä¸å¤Ÿå…¨é¢å’Œä¸ªæ€§åŒ–ï¼›2) å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åˆ©ç”¨ä¸è¶³ï¼Œæœªèƒ½å……åˆ†å‘æŒ¥LLMsçš„ç”Ÿæˆèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯åˆ©ç”¨åŒé‡çŸ¥è¯†ï¼ˆç»“æ„åŒ–å±æ€§çŸ¥è¯†å’Œéç»“æ„åŒ–è¯„è®ºçŸ¥è¯†ï¼‰æ¥å¢å¼ºLLMsåœ¨æ–‡æœ¬å›å¤ç”Ÿæˆä¸­çš„èƒ½åŠ›ã€‚é€šè¿‡åŠ¨æ€é€‰æ‹©åˆé€‚çš„çŸ¥è¯†ç±»å‹ï¼Œå¹¶è§£è€¦æ„å›¾å’Œå›å¤ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´ç›¸å…³çš„å›å¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDK2Ræ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µæ¨ç†æ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯çŸ¥è¯†æå–å’Œé€‰æ‹©ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æå–ç»“æ„åŒ–å±æ€§çŸ¥è¯†å’Œéç»“æ„åŒ–è¯„è®ºçŸ¥è¯†ï¼Œå¹¶åˆ©ç”¨LLMè¯„ä¼°æ¯ç§çŸ¥è¯†ç±»å‹çš„æ•ˆç”¨ã€‚ç¬¬äºŒé˜¶æ®µæ˜¯æ„å›¾æ¨ç†å’Œå›å¤ç”Ÿæˆï¼Œé€šè¿‡ä¸“é—¨çš„æ¨ç†è¿‡ç¨‹æ€»ç»“é¢å‘æ„å›¾çš„å…³é”®çº¿ç´¢ï¼Œå¹¶å°†å…¶ä½œä¸ºè¾…åŠ©ä¿¡å·æ¥å¢å¼ºLLMçš„æ–‡æœ¬å›å¤ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šDK2Ræ¨¡å‹çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†åŒé‡çŸ¥è¯†å¢å¼ºçš„æ–¹æ³•ï¼ŒåŒæ—¶åˆ©ç”¨ç»“æ„åŒ–å’Œéç»“æ„åŒ–çŸ¥è¯†ï¼›2) æå‡ºäº†åŠ¨æ€çŸ¥è¯†ç±»å‹é€‰æ‹©æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡é€‰æ‹©æœ€åˆé€‚çš„çŸ¥è¯†ç±»å‹ï¼›3) æå‡ºäº†æ„å›¾-å›å¤è§£è€¦ç­–ç•¥ï¼Œé€šè¿‡ä¸“é—¨çš„æ„å›¾æ¨ç†è¿‡ç¨‹æ¥æŒ‡å¯¼å›å¤ç”Ÿæˆã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDK2Ræ¨¡å‹èƒ½å¤Ÿæ›´å…¨é¢åœ°åˆ©ç”¨çŸ¥è¯†ï¼Œæ›´å‡†ç¡®åœ°æŠŠæ¡ç”¨æˆ·æ„å›¾ï¼Œä»è€Œç”Ÿæˆæ›´é«˜è´¨é‡çš„å›å¤ã€‚

**å…³é”®è®¾è®¡**ï¼šDK2Ræ¨¡å‹ä½¿ç”¨LLMï¼ˆå…·ä½“å‹å·æœªçŸ¥ï¼‰ä½œä¸ºæ ¸å¿ƒç”Ÿæˆå™¨ã€‚çŸ¥è¯†ç±»å‹æ•ˆç”¨è¯„ä¼°é€šè¿‡LLMç”Ÿæˆä¸´æ—¶æ¢æµ‹å›å¤å¹¶è¿›è¡Œåˆ†æå®ç°ã€‚æ„å›¾æ¨ç†æ¨¡å—çš„å…·ä½“ç½‘ç»œç»“æ„æœªçŸ¥ï¼Œä½†å¼ºè°ƒäº†å…¶å¯¹æ„å›¾å…³é”®çº¿ç´¢çš„æ€»ç»“èƒ½åŠ›ã€‚æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDK2Ræ¨¡å‹åœ¨å…¬å…±æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†DK2Ræ¨¡å‹åœ¨æ–‡æœ¬å›å¤ç”Ÿæˆè´¨é‡æ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚ä¸ç°æœ‰åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒDK2Ræ¨¡å‹èƒ½å¤Ÿç”Ÿæˆæ›´å‡†ç¡®ã€æ›´ç›¸å…³çš„å›å¤ï¼Œæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å¤šæ¨¡æ€ä»»åŠ¡å‹å¯¹è¯ç³»ç»Ÿï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è™šæ‹ŸåŠ©æ‰‹ã€ç”µå•†å¯¼è´­ç­‰ã€‚é€šè¿‡æå‡æ–‡æœ¬å›å¤çš„è´¨é‡å’Œç›¸å…³æ€§ï¼Œå¯ä»¥æ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œæé«˜å¯¹è¯æ•ˆç‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´ä¸ªæ€§åŒ–çš„æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€å’Œä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è¯­éŸ³å›å¤ç”Ÿæˆã€å›¾åƒæè¿°ç”Ÿæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Textual response generation is pivotal for multimodal \mbox{task-oriented} dialog systems, which aims to generate proper textual responses based on the multimodal context. While existing efforts have demonstrated remarkable progress, there still exist the following limitations: 1) \textit{neglect of unstructured review knowledge} and 2) \textit{underutilization of large language models (LLMs)}. Inspired by this, we aim to fully utilize dual knowledge (\textit{i.e., } structured attribute and unstructured review knowledge) with LLMs to promote textual response generation in multimodal task-oriented dialog systems. However, this task is non-trivial due to two key challenges: 1) \textit{dynamic knowledge type selection} and 2) \textit{intention-response decoupling}. To address these challenges, we propose a novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for multimodal dialog systems (named DK2R). To be specific, DK2R first extracts both structured attribute and unstructured review knowledge from external knowledge base given the dialog context. Thereafter, DK2R uses an LLM to evaluate each knowledge type's utility by analyzing LLM-generated provisional probe responses. Moreover, DK2R separately summarizes the intention-oriented key clues via dedicated reasoning, which are further used as auxiliary signals to enhance LLM-based textual response generation. Extensive experiments conducted on a public dataset verify the superiority of DK2R. We have released the codes and parameters.

