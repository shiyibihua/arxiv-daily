---
layout: default
title: Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias
---

# Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19314" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19314v1</a>
  <a href="https://arxiv.org/pdf/2509.19314.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19314v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19314v1', 'Automated Item Neutralization for Non-Cognitive Scales: A Large Language Model Approach to Reducing Social-Desirability Bias')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sirui Wu, Daijin Yang

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: Accepted for publication in NCME-AIME 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å‡å°‘ä¸ªæ€§è¯„ä¼°ä¸­çš„ç¤¾ä¼šæœŸæœ›åå·®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¤¾ä¼šæœŸæœ›åå·®` `ä¸ªæ€§è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¿ƒç†æµ‹é‡` `é—®å·ä¸­ç«‹åŒ–` `æ•°æ®åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰ä¸ªæ€§è¯„ä¼°æ–¹æ³•å®¹æ˜“å—åˆ°ç¤¾ä¼šæœŸæœ›åå·®çš„å½±å“ï¼Œå¯¼è‡´ç»“æœä¸å‡†ç¡®ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬ç ”ç©¶æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å¯¹é—®å·è¿›è¡Œä¸­ç«‹åŒ–å¤„ç†ï¼Œä»¥å‡å°‘ç¤¾ä¼šæœŸæœ›åå·®çš„å½±å“ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœæ˜¾ç¤ºï¼Œé—®å·çš„å¯é æ€§ä¿æŒä¸å˜ï¼Œä½†åœ¨ä¸åŒç»´åº¦ä¸Šè¡¨ç°å‡ºä¸åŒçš„å˜åŒ–è¶‹åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œé¡¹ç›®ä¸­ç«‹åŒ–ï¼Œä»¥å‡å°‘ä¸ªæ€§è¯„ä¼°ä¸­çš„ç¤¾ä¼šæœŸæœ›åå·®ã€‚ç ”ç©¶ä¸­ä½¿ç”¨GPT-o3é‡å†™äº†å›½é™…äººæ ¼é¡¹ç›®æ± å¤§äº”æµ‹é‡ï¼ˆIPIP-BFM-50ï¼‰ï¼Œ203åå‚ä¸è€…å®Œæˆäº†åŸå§‹æˆ–ä¸­ç«‹åŒ–å½¢å¼çš„é—®å·ï¼Œå¹¶é…åˆMarlowe-Crowneç¤¾ä¼šæœŸæœ›é‡è¡¨ã€‚ç»“æœæ˜¾ç¤ºï¼Œé—®å·çš„å¯é æ€§å’Œäº”å› ç´ ç»“æ„å¾—ä»¥ä¿æŒï¼Œå°½ç®¡åœ¨è´£ä»»å¿ƒä¸Šæœ‰æ‰€æå‡ï¼Œè€Œå®œäººæ€§å’Œå¼€æ”¾æ€§æœ‰æ‰€ä¸‹é™ã€‚å¤šä¸ªé¡¹ç›®ä¸ç¤¾ä¼šæœŸæœ›çš„ç›¸å…³æ€§æœ‰æ‰€é™ä½ï¼Œä½†è¡¨ç°ä¸ä¸€è‡´ã€‚å°½ç®¡ä¿æŒäº†æ„å‹ä¸å˜æ€§ï¼Œä½†åº¦é‡å’Œæ ‡é‡ä¸å˜æ€§æœªèƒ½å®ç°ã€‚ç ”ç©¶ç»“æœæ”¯æŒAIä¸­ç«‹åŒ–ä½œä¸ºä¸€ç§æ½œåœ¨ä½†ä¸å®Œç¾çš„åå·®å‡å°‘æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä¸ªæ€§è¯„ä¼°ä¸­å­˜åœ¨çš„ç¤¾ä¼šæœŸæœ›åå·®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ¶ˆé™¤è¿™ç§åå·®ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¤±çœŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆGPT-o3ï¼‰å¯¹ä¸ªæ€§è¯„ä¼°é—®å·è¿›è¡Œé‡å†™ï¼Œä»¥å®ç°é¡¹ç›®ä¸­ç«‹åŒ–ï¼Œä»è€Œå‡å°‘ç¤¾ä¼šæœŸæœ›åå·®çš„å½±å“ã€‚è¯¥æ–¹æ³•çš„è®¾è®¡åŸºäºå¯¹è¯­è¨€æ¨¡å‹åœ¨æ–‡æœ¬ç”Ÿæˆå’Œé‡å†™èƒ½åŠ›çš„åˆ©ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä½¿ç”¨GPT-o3å¯¹åŸå§‹é—®å·è¿›è¡Œé‡å†™ï¼Œç”Ÿæˆä¸­ç«‹åŒ–é—®å·ï¼Œå¹¶é€šè¿‡å‚ä¸è€…çš„åé¦ˆè¿›è¡Œæ•ˆæœè¯„ä¼°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬é—®å·é‡å†™ã€å‚ä¸è€…è¯„ä¼°å’Œæ•°æ®åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨äºå¿ƒç†æµ‹é‡é¢†åŸŸï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯æ¥å¤„ç†ç¤¾ä¼šæœŸæœ›åå·®é—®é¢˜ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬ç”Ÿæˆçš„çµæ´»æ€§å’Œé€‚åº”æ€§ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒGPT-o3çš„è®­ç»ƒæ•°æ®å’Œé‡å†™ç­–ç•¥ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„é—®å·åœ¨å†…å®¹ä¸Šä¿æŒä¸€è‡´æ€§ï¼ŒåŒæ—¶å‡å°‘ç¤¾ä¼šæœŸæœ›çš„å½±å“ã€‚æŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿè€ƒè™‘äº†æ–‡æœ¬çš„å¯è¯»æ€§å’Œå¿ƒç†æµ‹é‡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸­ç«‹åŒ–é—®å·åœ¨å¯é æ€§å’Œäº”å› ç´ ç»“æ„ä¸Šä¿æŒä¸€è‡´ï¼Œè´£ä»»å¿ƒå¾—åˆ†æœ‰æ‰€æå‡ï¼Œè€Œå®œäººæ€§å’Œå¼€æ”¾æ€§å¾—åˆ†æœ‰æ‰€ä¸‹é™ã€‚å¤šä¸ªé¡¹ç›®ä¸ç¤¾ä¼šæœŸæœ›çš„ç›¸å…³æ€§æœ‰æ‰€é™ä½ï¼Œå°½ç®¡è¡¨ç°ä¸ä¸€è‡´ï¼Œæ˜¾ç¤ºå‡ºAIä¸­ç«‹åŒ–çš„æ½œåŠ›å’Œå±€é™æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¿ƒç†æµ‹é‡ã€ä¸ªæ€§è¯„ä¼°å’Œç¤¾ä¼šç§‘å­¦ç ”ç©¶ã€‚é€šè¿‡å‡å°‘ç¤¾ä¼šæœŸæœ›åå·®ï¼Œå¯ä»¥æé«˜ä¸ªæ€§è¯„ä¼°çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä»è€Œä¸ºå¿ƒç†å­¦ç ”ç©¶å’Œä¸´åºŠåº”ç”¨æä¾›æ›´ä¸ºæœ‰æ•ˆçš„å·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šåœ¨å…¶ä»–ç±»å‹çš„é—®å·å’Œè¯„ä¼°å·¥å…·ä¸­å¾—åˆ°æ¨å¹¿å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study evaluates item neutralization assisted by the large language model (LLM) to reduce social desirability bias in personality assessment. GPT-o3 was used to rewrite the International Personality Item Pool Big Five Measure (IPIP-BFM-50), and 203 participants completed either the original or neutralized form along with the Marlowe-Crowne Social Desirability Scale. The results showed preserved reliability and a five-factor structure, with gains in Conscientiousness and declines in Agreeableness and Openness. The correlations with social desirability decreased for several items, but inconsistently. Configural invariance held, though metric and scalar invariance failed. Findings support AI neutralization as a potential but imperfect bias-reduction method.

