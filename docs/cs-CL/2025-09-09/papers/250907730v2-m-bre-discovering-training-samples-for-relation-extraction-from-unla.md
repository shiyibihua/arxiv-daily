---
layout: default
title: M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models
---

# M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07730" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.07730v2</a>
  <a href="https://arxiv.org/pdf/2509.07730.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07730v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07730v2', 'M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zexuan Li, Hongliang Dai, Piji Li

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-09 (Êõ¥Êñ∞: 2025-09-10)

**Â§áÊ≥®**: Accepted by EMNLP2025 Main Conference

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫M-BReÊ°ÜÊû∂ÔºåÂà©Áî®Â§ßËØ≠Ë®ÄÊ®°Âûã‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠È´òÊïàÊåñÊéòÂÖ≥Á≥ªÊäΩÂèñËÆ≠ÁªÉÊ†∑Êú¨**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂÖ≥Á≥ªÊäΩÂèñ` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Êó†ÁõëÁù£Â≠¶‰π†` `ËÆ≠ÁªÉÊï∞ÊçÆÊåñÊéò` `ÂÖ≥Á≥ªÂàÜÁªÑ` `Ëá™ÁõëÁù£Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂÖ≥Á≥ªÊäΩÂèñÊñπÊ≥ï‰æùËµñÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®Êï∞ÊçÆÔºåÊàêÊú¨È´òÊòÇ‰∏îÈöæ‰ª•Êâ©Â±ïÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ≥Á≥ªÁ±ªÂà´ËæÉÂ§öÊó∂„ÄÇ
2. M-BReÊ°ÜÊû∂ÁªìÂêàÂ§öÁ±ªÂàÜÁ±ªÂíå‰∫åÂÖÉÂàÜÁ±ªÁöÑ‰ºòÂäøÔºåÈÄöËøáÂÖ≥Á≥ªÂàÜÁªÑ„ÄÅÂÖ≥Á≥ªÊäΩÂèñÂíåÊ†áÁ≠æÂÜ≥Á≠ñ‰∏â‰∏™Ê®°ÂùóÔºåÈ´òÊïàÊåñÊéòÈ´òË¥®ÈáèËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåM-BReÊ°ÜÊû∂ËÉΩÂ§üÊúâÊïà‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊèêÂèñËÆ≠ÁªÉÊ†∑Êú¨ÔºåÊòæËëóÊèêÂçáÂÖ≥Á≥ªÊäΩÂèñÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂÖ≥Á≥ªÊäΩÂèñ(RE)‰ªªÂä°‰∏≠Ôºå‰∫∫Â∑•Ê†áÊ≥®ËÆ≠ÁªÉÊï∞ÊçÆÊàêÊú¨È´òÊòÇÔºåÂõ†‰∏∫ÂåÖÂê´ÁõÆÊ†áÂÖ≥Á≥ªÁöÑÂè•Â≠êÂú®ÊñáÊú¨‰∏≠ÈùûÂ∏∏Á®ÄÂ∞ë‰∏îÈöæ‰ª•ÂèëÁé∞„ÄÇÂõ†Ê≠§ÔºåÂºÄÂèë‰∏ÄÁßçËÉΩÂ§üËá™Âä®‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊèêÂèñËÆ≠ÁªÉÂÆû‰æã‰ª•ËÆ≠ÁªÉREÊ®°ÂûãÁöÑÊñπÊ≥ïÊòØÊúâÁõäÁöÑ„ÄÇÊúÄËøëÔºåÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)Â∑≤Ë¢´Â∫îÁî®‰∫éÂêÑÁßçËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ‰ªªÂä°ÔºåRE‰πüÂèóÁõä‰∫éÂÖ∂ÂèëÂ±ï„ÄÇÁÑ∂ËÄåÔºåÂΩìÂà©Áî®LLMËøõË°åÂÖ∑ÊúâÈ¢ÑÂÆö‰πâÂÖ≥Á≥ªÁ±ªÂà´ÁöÑREÊó∂Ôºå‰ºöÂá∫Áé∞‰∏§‰∏™ÂÖ≥ÈîÆÊåëÊàò„ÄÇÈ¶ñÂÖàÔºåÂú®Â§öÁ±ªÂàÜÁ±ªËÆæÁΩÆ‰∏≠ÔºåLLMÈÄöÂ∏∏Èöæ‰ª•ÂÖ®Èù¢ÊçïÊçâÊØè‰∏™ÂÖ≥Á≥ªÁöÑËØ≠‰πâÔºåÂØºËá¥Ê¨°‰ºòÁªìÊûú„ÄÇÂÖ∂Ê¨°ÔºåËôΩÁÑ∂ÂØπÊØè‰∏™ÂÖ≥Á≥ªÂçïÁã¨ÈááÁî®‰∫åÂÖÉÂàÜÁ±ªÂèØ‰ª•ÁºìËß£Ëøô‰∏™ÈóÆÈ¢òÔºå‰ΩÜÂÆÉ‰ºöÂºïÂÖ•ÊòæËëóÁöÑËÆ°ÁÆóÂºÄÈîÄÔºåÂØºËá¥ÂÆûÈôÖÂ∫îÁî®‰∏≠Êó∂Èó¥Â§çÊùÇÂ∫¶‰∏çÂàáÂÆûÈôÖ„ÄÇÂõ†Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫M-BReÁöÑÊ°ÜÊû∂ÔºåÁî®‰∫é‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊèêÂèñËÆ≠ÁªÉÂÆû‰æã‰ª•ËøõË°åRE„ÄÇÂÆÉÂà©Áî®‰∏â‰∏™Ê®°ÂùóÊù•ÁªìÂêà‰∏äËø∞‰∏§ÁßçÂàÜÁ±ªÊñπÊ≥ïÁöÑ‰ºòÁÇπÔºöÂÖ≥Á≥ªÂàÜÁªÑ„ÄÅÂÖ≥Á≥ªÊäΩÂèñÂíåÊ†áÁ≠æÂÜ≥Á≠ñ„ÄÇÂ§ßÈáèÂÆûÈ™åËØÅÂÆû‰∫ÜÂÖ∂Âú®‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÂèëÁé∞Áî®‰∫éREÁöÑÈ´òË¥®ÈáèËÆ≠ÁªÉÊ†∑Êú¨ÊñπÈù¢ÁöÑÂçìË∂äËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂÖ≥Á≥ªÊäΩÂèñ‰ªªÂä°‰∏≠Ôºå‰∫∫Â∑•Ê†áÊ≥®ËÆ≠ÁªÉÊï∞ÊçÆÊàêÊú¨È´òÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πà‰æùËµñÂ§ßÈáè‰∫∫Â∑•Ê†áÊ≥®ÔºåË¶Å‰πàÁõ¥Êé•‰ΩøÁî®LLMËøõË°åÂ§öÂàÜÁ±ªÔºåÂâçËÄÖÊàêÊú¨È´òÔºåÂêéËÄÖÈöæ‰ª•ÊçïÊçâÊâÄÊúâÂÖ≥Á≥ªÁöÑËØ≠‰πâÔºåÂØºËá¥ÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇÊ≠§Â§ñÔºåÂØπÊØè‰∏™ÂÖ≥Á≥ªÂçïÁã¨ËøõË°å‰∫åÂÖÉÂàÜÁ±ªËôΩÁÑ∂ÂèØ‰ª•ÁºìËß£ËØ≠‰πâÊçïÊçâÈóÆÈ¢òÔºå‰ΩÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶ËøáÈ´òÔºåÈöæ‰ª•ÂÆûÈôÖÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöM-BReÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÁªìÂêàÂ§öÁ±ªÂàÜÁ±ªÂíå‰∫åÂÖÉÂàÜÁ±ªÁöÑ‰ºòÁÇπÔºåÂà©Áî®ÂÖ≥Á≥ªÂàÜÁªÑÊù•Èôç‰Ωé‰∫åÂÖÉÂàÜÁ±ªÁöÑËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÂêåÊó∂Âà©Áî®LLMÁöÑËØ≠‰πâÁêÜËß£ËÉΩÂäõÊù•ÊèêÂèñÂÄôÈÄâÂÖ≥Á≥ªÂÆû‰æãÔºåÂπ∂ÈÄöËøáÊ†áÁ≠æÂÜ≥Á≠ñÊ®°ÂùóÊù•ÊèêÈ´òËÆ≠ÁªÉÊ†∑Êú¨ÁöÑË¥®Èáè„ÄÇËøôÊ†∑Êó¢ËÉΩ‰øùËØÅÂÖ≥Á≥ªËØ≠‰πâÁöÑÂÆåÊï¥ÊÄßÔºåÂèàËÉΩÊéßÂà∂ËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöM-BReÊ°ÜÊû∂ÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **ÂÖ≥Á≥ªÂàÜÁªÑ(Relation Grouping)**ÔºöÂ∞ÜËØ≠‰πâÁõ∏‰ººÁöÑÂÖ≥Á≥ªÂàÜÁªÑÔºåÂáèÂ∞ëÂêéÁª≠‰∫åÂÖÉÂàÜÁ±ªÁöÑÊï∞Èáè„ÄÇ2) **ÂÖ≥Á≥ªÊäΩÂèñ(Relation Extraction)**ÔºöÂà©Áî®LLM‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊèêÂèñÂÄôÈÄâÁöÑÂÖ≥Á≥ªÂÆû‰æã„ÄÇ3) **Ê†áÁ≠æÂÜ≥Á≠ñ(Label Decision)**ÔºöÂØπÂÄôÈÄâÂÆû‰æãËøõË°åËøáÊª§ÂíåÊ†áÊ≥®ÔºåÁîüÊàêÈ´òË¥®ÈáèÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊòØ‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨ÂºÄÂßãÔºåÁªèËøá‰∏â‰∏™Ê®°ÂùóÁöÑÂ§ÑÁêÜÔºåÊúÄÁªàÂæóÂà∞ÂèØÁî®‰∫éËÆ≠ÁªÉÂÖ≥Á≥ªÊäΩÂèñÊ®°ÂûãÁöÑÊï∞ÊçÆÈõÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöM-BReÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÁªìÂêà‰∫ÜÂ§öÁ±ªÂàÜÁ±ªÂíå‰∫åÂÖÉÂàÜÁ±ªÁöÑ‰ºòÂäøÔºåÂπ∂ÊèêÂá∫‰∫ÜÂÖ≥Á≥ªÂàÜÁªÑÁöÑÊ¶ÇÂøµÔºåÊúâÊïàÈôç‰Ωé‰∫ÜËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇ‰∏éÁõ¥Êé•‰ΩøÁî®LLMËøõË°åÂ§öÂàÜÁ±ªÊàñ‰∫åÂÖÉÂàÜÁ±ªÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåM-BReËÉΩÂ§üÂú®‰øùËØÅÊÄßËÉΩÁöÑÂêåÊó∂ÔºåÊòæËëóÈôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂÖ≥Á≥ªÂàÜÁªÑÊ®°ÂùóÂèØ‰ª•‰ΩøÁî®ËÅöÁ±ªÁÆóÊ≥ïÔºàÂ¶ÇK-meansÔºâÂØπÂÖ≥Á≥ªËøõË°åÂàÜÁªÑÔºåÂàÜÁªÑÁöÑÊï∞ÈáèÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÂèÇÊï∞ÔºåÈúÄË¶ÅÊ†πÊçÆÂÆûÈôÖÊÉÖÂÜµËøõË°åË∞ÉÊï¥„ÄÇÂÖ≥Á≥ªÊäΩÂèñÊ®°ÂùóÂèØ‰ª•‰ΩøÁî®Prompt EngineeringÊäÄÊúØÔºåÂºïÂØºLLMÁîüÊàêÂåÖÂê´ÁâπÂÆöÂÖ≥Á≥ªÁöÑÂè•Â≠ê„ÄÇÊ†áÁ≠æÂÜ≥Á≠ñÊ®°ÂùóÂèØ‰ª•‰ΩøÁî®ÈòàÂÄºËøáÊª§Âíå‰∫∫Â∑•Ê†°È™åÁõ∏ÁªìÂêàÁöÑÊñπÂºèÔºåÁ°Æ‰øùËÆ≠ÁªÉÊ†∑Êú¨ÁöÑË¥®Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåM-BReÊ°ÜÊû∂Âú®‰ªéÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊåñÊéòÂÖ≥Á≥ªÊäΩÂèñËÆ≠ÁªÉÊ†∑Êú¨ÊñπÈù¢Ë°®Áé∞Âá∫Ëâ≤„ÄÇÁõ∏ËæÉ‰∫éÁõ¥Êé•‰ΩøÁî®LLMËøõË°åÂÖ≥Á≥ªÊäΩÂèñÁöÑÊñπÊ≥ïÔºåM-BReËÉΩÂ§üÊòæËëóÊèêÂçáÊ®°ÂûãÊÄßËÉΩÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂÖ≥Á≥ªÁ±ªÂà´ËæÉÂ§öÊó∂„ÄÇÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞É‰∫ÜÂÖ∂Âú®ÂèëÁé∞È´òË¥®ÈáèËÆ≠ÁªÉÊ†∑Êú¨ÊñπÈù¢ÁöÑÂçìË∂äËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

M-BReÊ°ÜÊû∂ÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂÖ≥Á≥ªÊäΩÂèñÁöÑÂú∫ÊôØÔºå‰æãÂ¶ÇÁü•ËØÜÂõæË∞±ÊûÑÂª∫„ÄÅ‰ø°ÊÅØÊ£ÄÁ¥¢„ÄÅÊô∫ËÉΩÈóÆÁ≠îÁ≠â„ÄÇÈÄöËøáËá™Âä®‰ªéÊµ∑ÈáèÊó†Ê†áÊ≥®ÊñáÊú¨‰∏≠ÊèêÂèñËÆ≠ÁªÉÊï∞ÊçÆÔºåÂèØ‰ª•Èôç‰Ωé‰∫∫Â∑•Ê†áÊ≥®ÊàêÊú¨ÔºåÂä†ÈÄüÂÖ≥Á≥ªÊäΩÂèñÊ®°ÂûãÁöÑÂºÄÂèëÂíåÈÉ®ÁΩ≤Ôºå‰ªéËÄåÊèêÂçáÁõ∏ÂÖ≥Â∫îÁî®ÁöÑÊÄßËÉΩÂíåÊïàÁéá„ÄÇËØ•ÊñπÊ≥ïÂ∞§ÂÖ∂ÈÄÇÁî®‰∫éÂÖ≥Á≥ªÁ±ªÂà´ËæÉÂ§ö„ÄÅÊ†áÊ≥®Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÂú∫ÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> For Relation Extraction (RE), the manual annotation of training data may be prohibitively expensive, since the sentences that contain the target relations in texts can be very scarce and difficult to find. It is therefore beneficial to develop an efficient method that can automatically extract training instances from unlabeled texts for training RE models. Recently, large language models (LLMs) have been adopted in various natural language processing tasks, with RE also benefiting from their advances. However, when leveraging LLMs for RE with predefined relation categories, two key challenges arise. First, in a multi-class classification setting, LLMs often struggle to comprehensively capture the semantics of every relation, leading to suboptimal results. Second, although employing binary classification for each relation individually can mitigate this issue, it introduces significant computational overhead, resulting in impractical time complexity for real-world applications. Therefore, this paper proposes a framework called M-BRe to extract training instances from unlabeled texts for RE. It utilizes three modules to combine the advantages of both of the above classification approaches: Relation Grouping, Relation Extraction, and Label Decision. Extensive experiments confirm its superior capability in discovering high-quality training samples from unlabeled texts for RE.

