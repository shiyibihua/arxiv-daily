---
layout: default
title: Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning
---

# Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07768" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07768v1</a>
  <a href="https://arxiv.org/pdf/2509.07768.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07768v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07768v1', 'Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Michele Joshua Maggini, Dhia Merzougui, Rabiraj Bandyopadhyay, GaÃ«l Dias, Fabrice Maurel, Pablo Gamallo

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”In-Context Learningä¸å¾®è°ƒï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹æœ‰å®³å†…å®¹æ–¹é¢çš„èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æœ‰å®³å†…å®¹æ£€æµ‹` `In-Context Learning` `å¾®è°ƒ` `å¤šè¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åœ¨çº¿å¹³å°ä¸Šçš„è™šå‡æ–°é—»ã€æåŒ–å’Œæœ‰å®³å†…å®¹æ³›æ»¥ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹ä¸åŒæ¨¡å‹ã€ä½¿ç”¨æ–¹æ³•å’Œè¯­è¨€çš„å…¨é¢åŸºå‡†æµ‹è¯•ã€‚
2. æœ¬æ–‡å¯¹æ¯”äº†å¾®è°ƒå’ŒIn-Context Learningä¸¤ç§èŒƒå¼ï¼Œæ¢ç´¢å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹æœ‰å®³å†…å®¹æ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶åˆ†æäº†ä¸åŒæç¤ºç­–ç•¥çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ£€æµ‹æœ‰å®³å†…å®¹æ–¹é¢ï¼Œå¾®è°ƒæ¨¡å‹é€šå¸¸ä¼˜äºIn-Context Learningï¼Œå³ä½¿æ˜¯è¾ƒå°çš„æ¨¡å‹ï¼Œä¹Ÿèƒœè¿‡å¤§å‹æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å…¨é¢è¯„ä¼°äº†ä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹ç½‘ç»œå¹³å°ä¸Šçš„è™šå‡æ–°é—»ã€æåŒ–å†…å®¹ã€æ”¿æ²»åè§å’Œæœ‰å®³å†…å®¹æ–¹é¢çš„æ€§èƒ½ã€‚ç ”ç©¶æ¶µç›–äº†10ä¸ªæ•°æ®é›†å’Œ5ç§è¯­è¨€ï¼ˆè‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€è‘¡è„ç‰™è¯­ã€é˜¿æ‹‰ä¼¯è¯­å’Œä¿åŠ åˆ©äºšè¯­ï¼‰ï¼ŒåŒ…æ‹¬äºŒå…ƒå’Œå¤šç±»åˆ†ç±»åœºæ™¯ã€‚å®éªŒå¯¹æ¯”äº†å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•å’Œå„ç§In-Context Learningç­–ç•¥ï¼ŒåŒ…æ‹¬é›¶æ ·æœ¬æç¤ºã€ä»£ç æœ¬ã€å°‘æ ·æœ¬ï¼ˆä½¿ç”¨è¡Œåˆ—å¼ç‚¹è¿‡ç¨‹éšæœºé€‰æ‹©å’Œå¤šæ ·æ€§é€‰æ‹©ï¼‰å’Œæ€ç»´é“¾ã€‚ç ”ç©¶å‘ç°ï¼ŒIn-Context Learningé€šå¸¸ä¸å¦‚å¾®è°ƒæ¨¡å‹ã€‚è¿™ä¸€ä¸»è¦å‘ç°å¼ºè°ƒäº†å³ä½¿ä¸LlaMA3.1-8b-Instructã€Mistral-Nemo-Instruct-2407å’ŒQwen2.5-7B-Instructç­‰å¤§å‹æ¨¡å‹ç›¸æ¯”ï¼Œåœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¾®è°ƒè¾ƒå°æ¨¡å‹çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨çº¿å¹³å°ä¸Šè™šå‡æ–°é—»ã€æ”¿æ²»åè§ã€æåŒ–å’Œæœ‰å®³å†…å®¹çš„è‡ªåŠ¨æ£€æµ‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹çš„æ–¹æ³•ï¼Œç¼ºä¹è·¨æ¨¡å‹ã€è·¨è¯­è¨€å’Œè·¨ä½¿ç”¨æ–¹æ³•çš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œéš¾ä»¥ç¡®å®šæœ€ä½³å®è·µã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹æ¯”In-Context Learningå’Œå‚æ•°é«˜æ•ˆçš„å¾®è°ƒä¸¤ç§èŒƒå¼ï¼Œæ¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ£€æµ‹æœ‰å®³å†…å®¹æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡åœ¨å¤šç§è¯­è¨€å’Œæ•°æ®é›†ä¸Šè¿›è¡Œå®éªŒï¼Œæ—¨åœ¨æ­ç¤ºå“ªç§æ–¹æ³•æ›´é€‚åˆäºæ­¤ç±»ä»»åŠ¡ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹é€‰æ‹©ã€æ–¹æ³•å®ç°å’Œç»“æœåˆ†æå››ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ”¶é›†æ¶µç›–ä¸åŒè¯­è¨€å’Œæœ‰å®³å†…å®¹ç±»å‹çš„å¤šä¸ªæ•°æ®é›†ã€‚ç„¶åï¼Œé€‰æ‹©ä¸€ç³»åˆ—å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬LlaMA3.1-8b-Instructã€Mistral-Nemo-Instruct-2407å’ŒQwen2.5-7B-Instructã€‚æ¥ç€ï¼Œå®ç°In-Context Learningå’Œå¾®è°ƒä¸¤ç§æ–¹æ³•ï¼Œå¹¶é‡‡ç”¨ä¸åŒçš„æç¤ºç­–ç•¥ï¼ˆå¦‚é›¶æ ·æœ¬ã€å°‘æ ·æœ¬ã€æ€ç»´é“¾ï¼‰ã€‚æœ€åï¼Œå¯¹å®éªŒç»“æœè¿›è¡Œåˆ†æå’Œæ¯”è¾ƒï¼Œè¯„ä¼°ä¸åŒæ–¹æ³•çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹In-Context Learningå’Œå¾®è°ƒè¿›è¡Œäº†å…¨é¢çš„å¯¹æ¯”è¯„ä¼°ï¼Œæ¶µç›–äº†å¤šç§è¯­è¨€ã€æ•°æ®é›†å’Œæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†ä¸åŒçš„æç¤ºç­–ç•¥å¯¹In-Context Learningæ€§èƒ½çš„å½±å“ï¼Œå¹¶ä½¿ç”¨äº†è¡Œåˆ—å¼ç‚¹è¿‡ç¨‹æ¥é€‰æ‹©å…·æœ‰å¤šæ ·æ€§çš„å°‘æ ·æœ¬ç¤ºä¾‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨In-Context Learningä¸­ï¼Œä½¿ç”¨äº†é›¶æ ·æœ¬æç¤ºã€ä»£ç æœ¬ã€å°‘æ ·æœ¬ï¼ˆéšæœºé€‰æ‹©å’Œè¡Œåˆ—å¼ç‚¹è¿‡ç¨‹é€‰æ‹©ï¼‰å’Œæ€ç»´é“¾ç­‰ç­–ç•¥ã€‚åœ¨å¾®è°ƒä¸­ï¼Œé‡‡ç”¨äº†å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œä»¥å‡å°‘è®¡ç®—æˆæœ¬ã€‚å®éªŒä¸­ï¼Œä½¿ç”¨äº†ä¸åŒçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1å€¼ï¼Œä»¥å…¨é¢è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå¾®è°ƒæ¨¡å‹ä¼˜äºIn-Context Learningã€‚å³ä½¿æ˜¯è¾ƒå°çš„å¾®è°ƒæ¨¡å‹ï¼Œä¹Ÿèƒ½å¤Ÿèƒœè¿‡å¤§å‹çš„In-Context Learningæ¨¡å‹ï¼Œä¾‹å¦‚LlaMA3.1-8b-Instructã€Mistral-Nemo-Instruct-2407å’ŒQwen2.5-7B-Instructã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†åœ¨ç‰¹å®šä»»åŠ¡ä¸Šå¾®è°ƒæ¨¡å‹çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåœ¨çº¿å†…å®¹å®¡æ ¸ã€ç¤¾äº¤åª’ä½“ç›‘æ§ã€èˆ†æƒ…åˆ†æç­‰é¢†åŸŸã€‚é€šè¿‡è‡ªåŠ¨æ£€æµ‹æœ‰å®³å†…å®¹ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œç»´æŠ¤ç½‘ç»œç©ºé—´çš„å¥åº·ç”Ÿæ€ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•ç»“åˆIn-Context Learningå’Œå¾®è°ƒçš„ä¼˜åŠ¿ï¼Œå¼€å‘æ›´é«˜æ•ˆã€æ›´é²æ£’çš„æœ‰å®³å†…å®¹æ£€æµ‹ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The spread of fake news, polarizing, politically biased, and harmful content on online platforms has been a serious concern. With large language models becoming a promising approach, however, no study has properly benchmarked their performance across different models, usage methods, and languages. This study presents a comprehensive overview of different Large Language Models adaptation paradigms for the detection of hyperpartisan and fake news, harmful tweets, and political bias. Our experiments spanned 10 datasets and 5 different languages (English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and multiclass classification scenarios. We tested different strategies ranging from parameter efficient Fine-Tuning of language models to a variety of different In-Context Learning strategies and prompts. These included zero-shot prompts, codebooks, few-shot (with both randomly-selected and diversely-selected examples using Determinantal Point Processes), and Chain-of-Thought. We discovered that In-Context Learning often underperforms when compared to Fine-Tuning a model. This main finding highlights the importance of Fine-Tuning even smaller models on task-specific settings even when compared to the largest models evaluated in an In-Context Learning setup - in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and Qwen2.5-7B-Instruct.

