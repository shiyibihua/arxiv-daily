---
layout: default
title: Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents
---

# Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07389" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07389v1</a>
  <a href="https://arxiv.org/pdf/2509.07389.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07389v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07389v1', 'Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sankalp Tattwadarshi Swain, Anshika Krishnatray, Dhruv Kumar, Jagat Sesh Challa

**åˆ†ç±»**: cs.CL, cs.AI, cs.HC, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

**å¤‡æ³¨**: Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTinkatongueæ¡†æ¶ï¼Œè¯„ä¼°LLMæ™ºèƒ½ä½“åœ¨äº¤äº’ä¸­å­¦ä¹ æ–°è¯­è¨€çš„èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLMæ™ºèƒ½ä½“` `è¯­è¨€ä¹ å¾—` `äº¤äº’å¼å­¦ä¹ ` `Tinkatongue` `è¯„ä¼°æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè¯­è¨€èƒ½åŠ›è¯„ä¼°ç¼ºä¹å¯¹äº¤äº’å¼è¯­è¨€ä¹ å¾—çš„è€ƒå¯Ÿï¼Œå¿½ç•¥äº†äººç±»å­¦ä¹ è¯­è¨€çš„å…³é”®ç‰¹å¾ã€‚
2. è®ºæ–‡æ„å»ºTinkatongueè¯­è¨€ç¯å¢ƒï¼Œé€šè¿‡ä¸Botäº¤äº’ï¼Œè¯„ä¼°LLMæ™ºèƒ½ä½“å­¦ä¹ æ–°è¯­è¨€çš„èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜LLMæ™ºèƒ½ä½“éš¾ä»¥æœ‰æ•ˆå¯¹è¯ï¼Œä½†å±•ç°å‡ºä¸äººç±»ç›¸ä¼¼çš„è¯­è¨€å­¦ä¹ ç­–ç•¥ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMæ™ºèƒ½ä½“ï¼‰è¯­è¨€èƒ½åŠ›çš„è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨è¯æ±‡å­¦ä¹ ã€å½¢æ€è§„åˆ™å½’çº³ã€å¥æ³•æ³›åŒ–ã€è¯­ç”¨æ¨ç†å’Œè·¨è¯­è¨€è¿ç§»ç­‰æ–¹é¢ã€‚ç„¶è€Œï¼Œæ²¡æœ‰ç ”ç©¶è¯„ä¼°LLMæ™ºèƒ½ä½“æ˜¯å¦èƒ½é€šè¿‡æ¨¡å¼è¯†åˆ«å’Œäº¤äº’åé¦ˆæ¥ä¹ å¾—è¯­è¨€ï¼Œè€Œè¿™æ­£æ˜¯äººç±»è¯­è¨€ä¹ å¾—çš„æ ¸å¿ƒç‰¹å¾ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„å®éªŒæ¡†æ¶ï¼Œåœ¨è¯¥æ¡†æ¶ä¸­ï¼ŒLLMæ™ºèƒ½ä½“é€šè¿‡ä¸ä¸€ä¸ªåªç†è§£Tinkatongueè¯­è¨€çš„æœºå™¨äººè¿›è¡Œå¯¹è¯ï¼Œæ¥è¯„ä¼°å…¶å­¦ä¹ å’Œä½¿ç”¨ä¸€ç§æ–°æ„å»ºçš„è¯­è¨€ï¼ˆTinkatongueï¼‰çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMæ™ºèƒ½ä½“åœ¨100æ¬¡å›å¤å†…æœªèƒ½å»ºç«‹èµ·æœ‰æ•ˆçš„å¯¹è¯ï¼Œä½†å®ƒä»¬é‡‡ç”¨äº†ä¸äººç±»è¯­è¨€å­¦ä¹ æ–¹æ³•ç›¸ä¼¼çš„ä¸åŒç­–ç•¥ã€‚è¿™äº›ç»“æœä¸ºè¯„ä¼°åŸºå‡†æå‡ºäº†æ–°çš„æ–¹å‘ï¼Œå¹¶ä¸ºæ›´æœ‰æ•ˆåœ°ä»äº¤äº’åé¦ˆä¸­å­¦ä¹ çš„æ¨¡å‹è®¾è®¡å¼€è¾Ÿäº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰LLMè¯­è¨€èƒ½åŠ›è¯„ä¼°ä¸»è¦å…³æ³¨é™æ€çš„è¯­è¨€çŸ¥è¯†ï¼Œç¼ºä¹å¯¹LLMåœ¨åŠ¨æ€äº¤äº’ç¯å¢ƒä¸­å­¦ä¹ å’Œè¿ç”¨è¯­è¨€èƒ½åŠ›çš„è¯„ä¼°ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æ¨¡æ‹Ÿäººç±»é€šè¿‡å¯¹è¯å’Œåé¦ˆå­¦ä¹ è¯­è¨€çš„çœŸå®è¿‡ç¨‹ï¼Œå› æ­¤éš¾ä»¥å…¨é¢è¯„ä¼°LLMçš„è¯­è¨€æ™ºèƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ›å»ºä¸€ä¸ªå¯æ§çš„äº¤äº’å¼è¯­è¨€å­¦ä¹ ç¯å¢ƒï¼Œé€šè¿‡è®©LLMæ™ºèƒ½ä½“ä¸ä¸€ä¸ªåªç†è§£ç‰¹å®šäººå·¥è¯­è¨€çš„Botè¿›è¡Œå¯¹è¯ï¼Œè§‚å¯ŸLLMæ™ºèƒ½ä½“åœ¨äº¤äº’è¿‡ç¨‹ä¸­å­¦ä¹ å’Œä½¿ç”¨è¯¥è¯­è¨€çš„èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†äººç±»å­¦ä¹ è¯­è¨€çš„æ–¹å¼ï¼Œå³é€šè¿‡ä¸æ–­åœ°å°è¯•ã€æ¥æ”¶åé¦ˆå¹¶è°ƒæ•´ç­–ç•¥æ¥é€æ­¥æŒæ¡è¯­è¨€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼šLLMæ™ºèƒ½ä½“å’ŒTinkatongue Botã€‚LLMæ™ºèƒ½ä½“ä½œä¸ºå­¦ä¹ è€…ï¼Œè´Ÿè´£å°è¯•ä½¿ç”¨Tinkatongueä¸Botè¿›è¡Œäº¤æµã€‚Tinkatongue Botåˆ™ä½œä¸ºæ•™å¸ˆï¼Œåªç†è§£Tinkatongueè¯­è¨€ï¼Œå¹¶æ ¹æ®LLMæ™ºèƒ½ä½“çš„è¾“å…¥ç»™å‡ºç›¸åº”çš„åé¦ˆã€‚å®éªŒæµç¨‹å¦‚ä¸‹ï¼š1. å®šä¹‰Tinkatongueè¯­è¨€çš„è¯­æ³•å’Œè¯æ±‡ï¼›2. åˆå§‹åŒ–LLMæ™ºèƒ½ä½“ï¼›3. LLMæ™ºèƒ½ä½“å‘Botå‘é€Tinkatongueè¯­å¥ï¼›4. Botæ ¹æ®Tinkatongueè¯­æ³•è§„åˆ™è§£æLLMæ™ºèƒ½ä½“çš„è¯­å¥ï¼Œå¹¶ç»™å‡ºåé¦ˆï¼›5. LLMæ™ºèƒ½ä½“æ ¹æ®åé¦ˆè°ƒæ•´å…¶è¯­è¨€æ¨¡å‹ï¼Œå¹¶é‡å¤æ­¥éª¤3å’Œ4ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„å®éªŒæ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMæ™ºèƒ½ä½“åœ¨äº¤äº’å¼ç¯å¢ƒä¸­å­¦ä¹ æ–°è¯­è¨€çš„èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„é™æ€è¯„ä¼°æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»å­¦ä¹ è¯­è¨€çš„çœŸå®è¿‡ç¨‹ï¼Œå¹¶æä¾›æ›´å…¨é¢å’Œæ·±å…¥çš„è¯„ä¼°ç»“æœã€‚æ­¤å¤–ï¼ŒTinkatongueè¯­è¨€çš„è®¾è®¡ä¹Ÿä¸ºç ”ç©¶äººå‘˜æä¾›äº†ä¸€ä¸ªå¯æ§çš„å®éªŒç¯å¢ƒï¼Œå¯ä»¥æ–¹ä¾¿åœ°è°ƒæ•´è¯­è¨€çš„å¤æ‚åº¦å’Œè§„åˆ™ï¼Œä»è€Œæ›´å¥½åœ°ç ”ç©¶LLMæ™ºèƒ½ä½“çš„è¯­è¨€å­¦ä¹ èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šTinkatongueè¯­è¨€çš„è®¾è®¡éœ€è¦è€ƒè™‘å…¶å¤æ‚åº¦å’Œå¯å­¦ä¹ æ€§ã€‚è¯­è¨€çš„è¯­æ³•è§„åˆ™éœ€è¦è¶³å¤Ÿç®€å•ï¼Œä»¥ä¾¿Botèƒ½å¤Ÿæœ‰æ•ˆåœ°è§£æå’Œåé¦ˆï¼ŒåŒæ—¶ä¹Ÿè¦è¶³å¤Ÿå¤æ‚ï¼Œä»¥ä¾¿èƒ½å¤Ÿæµ‹è¯•LLMæ™ºèƒ½ä½“çš„æ³›åŒ–èƒ½åŠ›ã€‚LLMæ™ºèƒ½ä½“çš„é€‰æ‹©ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦é€‰æ‹©å…·æœ‰è¶³å¤Ÿè¯­è¨€èƒ½åŠ›çš„æ¨¡å‹ï¼Œä»¥ä¾¿èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ å’Œä½¿ç”¨Tinkatongueè¯­è¨€ã€‚å®éªŒä¸­ï¼Œéœ€è¦è®°å½•LLMæ™ºèƒ½ä½“åœ¨æ¯ä¸ªå›åˆçš„è¾“å…¥ã€Botçš„åé¦ˆä»¥åŠLLMæ™ºèƒ½ä½“çš„è¯­è¨€æ¨¡å‹çš„å˜åŒ–ï¼Œä»¥ä¾¿åˆ†æå…¶å­¦ä¹ è¿‡ç¨‹å’Œç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿ç»è¿‡100è½®çš„äº¤äº’ï¼ŒLLMæ™ºèƒ½ä½“ä»ç„¶éš¾ä»¥ä¸Tinkatongue Botå»ºç«‹æœ‰æ•ˆçš„å¯¹è¯ã€‚ç„¶è€Œï¼ŒLLMæ™ºèƒ½ä½“åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å±•ç°å‡ºä¸äººç±»ç›¸ä¼¼çš„è¯­è¨€å­¦ä¹ ç­–ç•¥ï¼Œä¾‹å¦‚å°è¯•ä¸åŒçš„è¯­æ³•ç»“æ„å’Œè¯æ±‡ç»„åˆï¼Œå¹¶æ ¹æ®Botçš„åé¦ˆè°ƒæ•´å…¶è¯­è¨€æ¨¡å‹ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMæ™ºèƒ½ä½“å…·æœ‰ä¸€å®šçš„è¯­è¨€å­¦ä¹ æ½œåŠ›ï¼Œä½†éœ€è¦æ›´æœ‰æ•ˆçš„å­¦ä¹ æ–¹æ³•å’Œæ¨¡å‹è®¾è®¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´æ™ºèƒ½ã€æ›´è‡ªç„¶çš„å¯¹è¯ç³»ç»Ÿã€‚é€šè¿‡æ¨¡æ‹Ÿäººç±»è¯­è¨€å­¦ä¹ è¿‡ç¨‹ï¼Œå¯ä»¥è®­ç»ƒå‡ºèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œä½¿ç”¨è‡ªç„¶è¯­è¨€çš„LLMæ™ºèƒ½ä½“ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMæ™ºèƒ½ä½“çš„è¯­è¨€èƒ½åŠ›ï¼Œå¹¶ä¸ºæ¨¡å‹è®¾è®¡æä¾›æŒ‡å¯¼ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨äººæœºäº¤äº’ã€æœºå™¨ç¿»è¯‘å’Œè¯­è¨€æ•™è‚²ç­‰é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing evaluation studies on linguistic competence of large language models (LLM agents) have focused primarily on vocabulary learning, morphological rule induction, syntactic generalization, pragmatic inference, and cross-linguistic transfer. However, none assess whether LLM agents can acquire a language through pattern recognition and interactive feedback, a central feature of human language acquisition. We propose a novel experimental framework in which an LLM agent is evaluated on its ability to acquire and use a newly constructed language (Tinkatongue) in conversation with a bot that understands only Tinkatongue. Our findings show that LLM agents fail to establish a conversation within 100 responses, yet they adopt distinct strategies that mirror human approaches to language learning. The results suggest a new direction for evaluation benchmarks and open pathways to model designs that learn more effectively from interactive feedback.

