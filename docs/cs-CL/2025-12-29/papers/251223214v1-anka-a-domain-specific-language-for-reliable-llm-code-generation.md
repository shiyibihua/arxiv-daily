---
layout: default
title: "Anka: A Domain-Specific Language for Reliable LLM Code Generation"
---

# Anka: A Domain-Specific Language for Reliable LLM Code Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23214" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23214v1</a>
  <a href="https://arxiv.org/pdf/2512.23214.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23214v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23214v1', 'Anka: A Domain-Specific Language for Reliable LLM Code Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saif Khalfan Saif Al Mazrouei

**åˆ†ç±»**: cs.CL, cs.LG, cs.PL, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

**å¤‡æ³¨**: 11 pages, 1 figure, 4 tables. Code and benchmarks available at https://github.com/BleBlo/Anka

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé¢†åŸŸç‰¹å®šè¯­è¨€Ankaï¼Œæå‡LLMåœ¨å¤æ‚æ•°æ®è½¬æ¢ä»»åŠ¡ä¸­çš„ä»£ç ç”Ÿæˆå¯é æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é¢†åŸŸç‰¹å®šè¯­è¨€` `ä»£ç ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®è½¬æ¢` `å¯é æ€§` `è¯­æ³•çº¦æŸ` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é€šç”¨ç¼–ç¨‹è¯­è¨€çš„çµæ´»æ€§å¯¼è‡´LLMåœ¨å¤æ‚å¤šæ­¥éª¤ç¼–ç¨‹ä»»åŠ¡ä¸­äº§ç”Ÿç³»ç»Ÿæ€§é”™è¯¯ï¼Œå¦‚æ“ä½œæ’åºå’Œå˜é‡ç®¡ç†é”™è¯¯ã€‚
2. æå‡ºé¢†åŸŸç‰¹å®šè¯­è¨€Ankaï¼Œé€šè¿‡æ˜¾å¼å’Œå—çº¦æŸçš„è¯­æ³•æ¥å‡å°‘ä»£ç ç”Ÿæˆä¸­çš„æ­§ä¹‰ï¼Œä»è€Œæé«˜LLMä»£ç ç”Ÿæˆçš„å¯é æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAnkaåœ¨å¤šæ­¥éª¤æ•°æ®è½¬æ¢ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºPythonï¼Œå¹¶ä¸”LLMå¯ä»¥ä»ä¸Šä¸‹æ–‡æç¤ºä¸­å¿«é€Ÿå­¦ä¹ å¹¶åº”ç”¨Ankaã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚çš„å¤šæ­¥éª¤ç¼–ç¨‹ä»»åŠ¡ä¸­å­˜åœ¨ç³»ç»Ÿæ€§é”™è¯¯ã€‚æˆ‘ä»¬å‡è®¾è¿™äº›é”™è¯¯æºäºé€šç”¨è¯­è¨€çš„çµæ´»æ€§ï¼Œå®ƒå…è®¸å¤šç§æœ‰æ•ˆæ–¹æ³•å¹¶éœ€è¦éšå¼çŠ¶æ€ç®¡ç†ã€‚ä¸ºäº†éªŒè¯è¿™ä¸€å‡è®¾ï¼Œæˆ‘ä»¬å¼•å…¥äº†Ankaï¼Œä¸€ç§ç”¨äºæ•°æ®è½¬æ¢ç®¡é“çš„é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰ï¼Œå®ƒå…·æœ‰æ˜¾å¼ã€å—çº¦æŸçš„è¯­æ³•ï¼Œä»è€Œå‡å°‘äº†ä»£ç ç”Ÿæˆä¸­çš„æ­§ä¹‰ã€‚å°½ç®¡ä¹‹å‰æ²¡æœ‰æ¥å—è¿‡Ankaçš„è®­ç»ƒï¼ŒClaude 3.5 Haikuåœ¨100ä¸ªåŸºå‡†é—®é¢˜ä¸­å®ç°äº†99.9%çš„è§£ææˆåŠŸç‡å’Œ95.8%çš„æ€»ä½“ä»»åŠ¡å‡†ç¡®ç‡ã€‚å…³é”®çš„æ˜¯ï¼ŒAnkaåœ¨å¤šæ­¥éª¤ç®¡é“ä»»åŠ¡ä¸Šæ¯”Pythonè¡¨ç°å‡º40ä¸ªç™¾åˆ†ç‚¹çš„å‡†ç¡®ç‡ä¼˜åŠ¿ï¼ˆ100% vs. 60%ï¼‰ï¼Œå…¶ä¸­Pythonçš„çµæ´»è¯­æ³•å¯¼è‡´æ“ä½œæ’åºå’Œå˜é‡ç®¡ç†ä¸­é¢‘ç¹å‡ºç°é”™è¯¯ã€‚ä½¿ç”¨GPT-4o-miniè¿›è¡Œçš„è·¨æ¨¡å‹éªŒè¯è¯å®äº†è¿™ä¸€ä¼˜åŠ¿ï¼ˆåœ¨å¤šæ­¥éª¤ä»»åŠ¡ä¸Š+26.7ä¸ªç™¾åˆ†ç‚¹ï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼šï¼ˆ1ï¼‰LLMå¯ä»¥å®Œå…¨ä»ä¸Šä¸‹æ–‡æç¤ºä¸­å­¦ä¹ æ–°çš„DSLï¼Œè¾¾åˆ°æ¥è¿‘åŸç”Ÿå‡†ç¡®ç‡ï¼›ï¼ˆ2ï¼‰å—çº¦æŸçš„è¯­æ³•æ˜¾è‘—å‡å°‘äº†å¤æ‚ä»»åŠ¡ä¸­çš„é”™è¯¯ï¼›ï¼ˆ3ï¼‰ä¸“é—¨ä¸ºLLMç”Ÿæˆè€Œè®¾è®¡çš„é¢†åŸŸç‰¹å®šè¯­è¨€å¯ä»¥èƒœè¿‡LLMæ¥å—è¿‡å¹¿æ³›è®­ç»ƒçš„é€šç”¨è¯­è¨€ã€‚æˆ‘ä»¬å‘å¸ƒå®Œæ•´çš„è¯­è¨€å®ç°ã€åŸºå‡†æµ‹è¯•å¥—ä»¶å’Œè¯„ä¼°æ¡†æ¶ï¼Œä»¥ä¿ƒè¿›è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ‰§è¡Œå¤æ‚ã€å¤šæ­¥éª¤æ•°æ®è½¬æ¢ä»»åŠ¡æ—¶ä»£ç ç”Ÿæˆå¯é æ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰é€šç”¨ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚Pythonï¼‰çš„çµæ´»æ€§å¯¼è‡´LLMsåœ¨æ“ä½œæ’åºã€å˜é‡ç®¡ç†ç­‰æ–¹é¢å®¹æ˜“å‡ºé”™ï¼Œä»è€Œé™ä½äº†ä»»åŠ¡çš„æ•´ä½“å‡†ç¡®ç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ç§é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰ï¼Œå³Ankaï¼Œå®ƒå…·æœ‰æ˜¾å¼ä¸”å—çº¦æŸçš„è¯­æ³•ï¼Œä»è€Œå‡å°‘LLMåœ¨ä»£ç ç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ­§ä¹‰ã€‚é€šè¿‡é™åˆ¶è¯­è¨€çš„è¡¨è¾¾æ–¹å¼ï¼Œå¯ä»¥å¼•å¯¼LLMç”Ÿæˆæ›´å¯é ã€æ›´ç¬¦åˆé¢„æœŸçš„ä»£ç ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAnkaçš„è®¾è®¡ç›®æ ‡æ˜¯ç®€åŒ–æ•°æ®è½¬æ¢ç®¡é“çš„æ„å»ºã€‚å…¶æ•´ä½“æ¡†æ¶åŒ…æ‹¬ï¼šå®šä¹‰æ˜ç¡®çš„æ•°æ®ç±»å‹å’Œæ“ä½œç¬¦ï¼›ä½¿ç”¨æ˜¾å¼è¯­æ³•æ¥æŒ‡å®šæ•°æ®æµå’Œæ“ä½œé¡ºåºï¼›æä¾›ä¸€å¥—å®Œæ•´çš„åŸºå‡†æµ‹è¯•å¥—ä»¶å’Œè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°LLMåœ¨Ankaä¸Šçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ä¸“é—¨ä¸ºLLMä»£ç ç”Ÿæˆè®¾è®¡çš„DSLï¼Œå¹¶éªŒè¯äº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒAnkaä¸æ˜¯è¯•å›¾æ”¹è¿›LLMæœ¬èº«ï¼Œè€Œæ˜¯é€šè¿‡çº¦æŸç¼–ç¨‹è¯­è¨€æ¥æé«˜LLMçš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šAnkaçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ˜¾å¼çš„æ•°æ®ç±»å‹å£°æ˜ï¼Œå‡å°‘ç±»å‹æ¨æ–­é”™è¯¯ï¼›2) å—é™çš„æ“ä½œç¬¦é›†åˆï¼Œé¿å…ä¸å¿…è¦çš„å¤æ‚æ€§ï¼›3) å¼ºåˆ¶æ€§çš„æ•°æ®æµå®šä¹‰ï¼Œç¡®ä¿æ“ä½œé¡ºåºçš„æ­£ç¡®æ€§ï¼›4) ç®€æ´çš„è¯­æ³•ç»“æ„ï¼Œé™ä½LLMçš„å­¦ä¹ éš¾åº¦ã€‚è®ºæ–‡æœªæåŠå…·ä½“çš„å‚æ•°è®¾ç½®æˆ–æŸå¤±å‡½æ•°ï¼Œå› ä¸ºAnkaæœ¬èº«æ˜¯ä¸€ç§ç¼–ç¨‹è¯­è¨€ï¼Œè€Œéæœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23214v1/complexity_advantage.png" alt="fig_0" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒClaude 3.5 Haikuåœ¨Ankaä¸Šå®ç°äº†99.9%çš„è§£ææˆåŠŸç‡å’Œ95.8%çš„æ€»ä½“ä»»åŠ¡å‡†ç¡®ç‡ã€‚åœ¨å¤šæ­¥éª¤ç®¡é“ä»»åŠ¡ä¸Šï¼ŒAnkaæ¯”Pythonè¡¨ç°å‡º40ä¸ªç™¾åˆ†ç‚¹çš„å‡†ç¡®ç‡ä¼˜åŠ¿ï¼ˆ100% vs. 60%ï¼‰ã€‚ä½¿ç”¨GPT-4o-miniè¿›è¡Œçš„è·¨æ¨¡å‹éªŒè¯ä¹Ÿè¯å®äº†Ankaçš„ä¼˜åŠ¿ï¼ˆåœ¨å¤šæ­¥éª¤ä»»åŠ¡ä¸Š+26.7ä¸ªç™¾åˆ†ç‚¹ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºéœ€è¦é«˜å¯é æ€§ä»£ç ç”Ÿæˆçš„é¢†åŸŸï¼Œä¾‹å¦‚æ•°æ®æ¸…æ´—ã€ETLæµç¨‹ã€è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆç­‰ã€‚é€šè¿‡ä½¿ç”¨é¢†åŸŸç‰¹å®šè¯­è¨€ï¼Œå¯ä»¥é™ä½å¼€å‘æˆæœ¬ï¼Œæé«˜ä»£ç è´¨é‡ï¼Œå¹¶å‡å°‘äººå·¥å¹²é¢„ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥æ‰©å±•Ankaçš„åŠŸèƒ½ï¼Œæ”¯æŒæ›´å¤æ‚çš„æ•°æ®è½¬æ¢åœºæ™¯ï¼Œå¹¶å°†å…¶åº”ç”¨äºå…¶ä»–é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet they exhibit systematic errors on complex, multi-step programming tasks. We hypothesize that these errors stem from the flexibility of general-purpose languages, which permits multiple valid approaches and requires implicit state management. To test this hypothesis, we introduce Anka, a domain-specific language (DSL) for data transformation pipelines designed with explicit, constrained syntax that reduces ambiguity in code generation. Despite having zero prior training exposure to Anka, Claude 3.5 Haiku achieves 99.9% parse success and 95.8% overall task accuracy across 100 benchmark problems. Critically, Anka demonstrates a 40 percentage point accuracy advantage over Python on multi-step pipeline tasks (100% vs. 60%), where Python's flexible syntax leads to frequent errors in operation sequencing and variable management. Cross-model validation with GPT-4o-mini confirms this advantage (+26.7 percentage points on multi-step tasks). Our results demonstrate that: (1) LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy; (2) constrained syntax significantly reduces errors on complex tasks; and (3) domain-specific languages purposefully designed for LLM generation can outperform general-purpose languages on which the LLM has extensive training. We release the complete language implementation, benchmark suite, and evaluation framework to facilitate further research.

