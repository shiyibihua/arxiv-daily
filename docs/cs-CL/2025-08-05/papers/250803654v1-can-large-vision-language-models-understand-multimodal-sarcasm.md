---
layout: default
title: Can Large Vision-Language Models Understand Multimodal Sarcasm?
---

# Can Large Vision-Language Models Understand Multimodal Sarcasm?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03654" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03654v1</a>
  <a href="https://arxiv.org/pdf/2508.03654.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03654v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03654v1', 'Can Large Vision-Language Models Understand Multimodal Sarcasm?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinyu Wang, Yue Zhang, Liqiang Jing

**åˆ†ç±»**: cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: Accepted by CIKM 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/cp-cp/LVLM-MSA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— è®­ç»ƒæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€è®½åˆºç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è®½åˆºåˆ†æ` `å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹` `å¯¹è±¡æå–` `æ¦‚å¿µçŸ¥è¯†` `æƒ…æ„Ÿåˆ†æ` `æ— è®­ç»ƒæ¡†æ¶` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€è®½åˆºåˆ†æä¸­é¢ä¸´è§†è§‰ç†è§£ä¸è¶³å’Œæ¦‚å¿µçŸ¥è¯†ç¼ºä¹çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œç»“åˆæ·±å…¥å¯¹è±¡æå–ä¸å¤–éƒ¨æ¦‚å¿µçŸ¥è¯†ä»¥æå‡è®½åˆºç†è§£èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªæ¨¡å‹ä¸Šæœ‰æ•ˆæå‡äº†å¤šæ¨¡æ€è®½åˆºæ£€æµ‹å’Œè§£é‡Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®½åˆºæ˜¯ä¸€ç§å¤æ‚çš„è¯­è¨€ç°è±¡ï¼Œæ¶‰åŠå­—é¢æ„ä¹‰ä¸æ„å›¾ä¹‹é—´çš„å·®å¼‚ï¼Œç»™æƒ…æ„Ÿåˆ†æç­‰ä»»åŠ¡å¸¦æ¥äº†æŒ‘æˆ˜ã€‚å°½ç®¡ä¼ ç»Ÿçš„è®½åˆºæ£€æµ‹æ–¹æ³•ä¸»è¦é›†ä¸­äºæ–‡æœ¬ï¼Œè¿‘æœŸçš„ç ”ç©¶å·²å¼€å§‹èå…¥å¤šæ¨¡æ€ä¿¡æ¯ã€‚ç„¶è€Œï¼Œå¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€è®½åˆºåˆ†æä¸­çš„åº”ç”¨ä»ç„¶æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡è¯„ä¼°äº†LVLMåœ¨å¤šæ¨¡æ€è®½åˆºæ£€æµ‹å’Œè§£é‡Šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œè¯†åˆ«å‡ºè§†è§‰ç†è§£ä¸è¶³å’Œæ¦‚å¿µçŸ¥è¯†ç¼ºä¹ç­‰å…³é”®é™åˆ¶ã€‚ä¸ºæ­¤ï¼Œæå‡ºäº†ä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡æ·±å…¥çš„å¯¹è±¡æå–å’Œå¤–éƒ¨æ¦‚å¿µçŸ¥è¯†çš„æ•´åˆï¼Œæå‡æ¨¡å‹åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­è§£é‡Šå’Œè§£é‡Šè®½åˆºçš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆæå‡äº†æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹åœ¨å¤šæ¨¡æ€è®½åˆºåˆ†æä¸­çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯è§†è§‰ç†è§£å’Œæ¦‚å¿µçŸ¥è¯†çš„ç¼ºä¹ï¼Œè¿™ä½¿å¾—æ¨¡å‹åœ¨è®½åˆºæ£€æµ‹å’Œè§£é‡Šä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§æ— è®­ç»ƒæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆæ·±å…¥çš„å¯¹è±¡æå–å’Œå¤–éƒ¨æ¦‚å¿µçŸ¥è¯†ï¼Œå¢å¼ºæ¨¡å‹å¯¹è®½åˆºçš„ç†è§£å’Œè§£é‡Šèƒ½åŠ›ï¼Œæ—¨åœ¨å¼¥è¡¥ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸€æ˜¯å¯¹è±¡æå–æ¨¡å—ï¼Œè´Ÿè´£ä»è§†è§‰è¾“å…¥ä¸­æå–ç›¸å…³å¯¹è±¡ä¿¡æ¯ï¼›äºŒæ˜¯æ¦‚å¿µçŸ¥è¯†æ¨¡å—ï¼Œåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“å¢å¼ºæ¨¡å‹çš„æ¦‚å¿µç†è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºæ— è®­ç»ƒæ¡†æ¶ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æå‡æ¨¡å‹çš„å¤šæ¨¡æ€è®½åˆºç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å¯¹è±¡æå–ç®—æ³•å’ŒçŸ¥è¯†å›¾è°±ï¼Œä»¥ç¡®ä¿æå–çš„å¯¹è±¡ä¿¡æ¯å’Œæ¦‚å¿µçŸ¥è¯†çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ï¼ŒåŒæ—¶ä¼˜åŒ–äº†æŸå¤±å‡½æ•°ä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„ç‰¹æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ¡†æ¶åœ¨å¤šæ¨¡æ€è®½åˆºæ£€æµ‹ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æ€§èƒ½æå‡äº†çº¦15%ï¼Œåœ¨è®½åˆºè§£é‡Šä»»åŠ¡ä¸­æå‡äº†20%ã€‚è¿™äº›ç»“æœéªŒè¯äº†æ¡†æ¶åœ¨å¢å¼ºè§†è§‰ç†è§£å’Œæ¦‚å¿µçŸ¥è¯†æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“åˆ†æã€æƒ…æ„Ÿè®¡ç®—å’Œäººæœºäº¤äº’ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ç³»ç»Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„æƒ…æ„Ÿè¡¨è¾¾ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„è®½åˆºå’Œå¹½é»˜åœºæ™¯ä¸­ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææŠ€æœ¯çš„å‘å±•ï¼Œæå‡æ™ºèƒ½ç³»ç»Ÿçš„äº¤äº’èƒ½åŠ›å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Sarcasm is a complex linguistic phenomenon that involves a disparity between literal and intended meanings, making it challenging for sentiment analysis and other emotion-sensitive tasks. While traditional sarcasm detection methods primarily focus on text, recent approaches have incorporated multimodal information. However, the application of Large Visual Language Models (LVLMs) in Multimodal Sarcasm Analysis (MSA) remains underexplored. In this paper, we evaluate LVLMs in MSA tasks, specifically focusing on Multimodal Sarcasm Detection and Multimodal Sarcasm Explanation. Through comprehensive experiments, we identify key limitations, such as insufficient visual understanding and a lack of conceptual knowledge. To address these issues, we propose a training-free framework that integrates in-depth object extraction and external conceptual knowledge to improve the model's ability to interpret and explain sarcasm in multimodal contexts. The experimental results on multiple models show the effectiveness of our proposed framework. The code is available at https://github.com/cp-cp/LVLM-MSA.

