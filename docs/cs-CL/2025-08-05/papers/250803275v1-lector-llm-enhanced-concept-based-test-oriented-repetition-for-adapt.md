---
layout: default
title: LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning
---

# LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03275" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03275v1</a>
  <a href="https://arxiv.org/pdf/2508.03275.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03275v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03275v1', 'LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiahao Zhao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: 15 pages, 4 figures, 1 table

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLECTORä»¥è§£å†³è¯­ä¹‰å¹²æ‰°å’Œä¸ªæ€§åŒ–é€‚åº”é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é—´éš”é‡å¤` `è‡ªé€‚åº”å­¦ä¹ ` `è¯­ä¹‰åˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸ªæ€§åŒ–å­¦ä¹ ` `æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿ` `è¯­è¨€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é—´éš”é‡å¤ç®—æ³•åœ¨è¯­ä¹‰å¹²æ‰°å’Œä¸ªæ€§åŒ–é€‚åº”æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå½±å“å­¦ä¹ æ•ˆæœã€‚
2. LECTORé€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰åˆ†æä¸ä¸ªæ€§åŒ–å­¦ä¹ æ¡£æ¡ˆï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”è°ƒåº¦ç®—æ³•ã€‚
3. åœ¨ä¸å…­ç§åŸºçº¿ç®—æ³•çš„å¯¹æ¯”å®éªŒä¸­ï¼ŒLECTORå–å¾—äº†90.2%çš„æˆåŠŸç‡ï¼Œæ˜¾è‘—æé«˜äº†å­¦ä¹ æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é—´éš”é‡å¤ç³»ç»Ÿæ˜¯é«˜æ•ˆå­¦ä¹ å’Œè®°å¿†ä¿æŒçš„åŸºç¡€ï¼Œä½†ç°æœ‰ç®—æ³•å¸¸å¸¸é¢ä¸´è¯­ä¹‰å¹²æ‰°å’Œä¸ªæ€§åŒ–é€‚åº”çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†LECTORï¼ˆLLMå¢å¼ºçš„åŸºäºæ¦‚å¿µçš„æµ‹è¯•å¯¼å‘é‡å¤ï¼‰ï¼Œä¸€ç§ä¸“ä¸ºæµ‹è¯•å¯¼å‘å­¦ä¹ åœºæ™¯è®¾è®¡çš„è‡ªé€‚åº”è°ƒåº¦ç®—æ³•ï¼Œå°¤å…¶é€‚ç”¨äºè¯­è¨€è€ƒè¯•ã€‚LECTORåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰åˆ†æï¼Œå¹¶ç»“åˆä¸ªæ€§åŒ–å­¦ä¹ æ¡£æ¡ˆï¼Œè§£å†³è¯æ±‡å­¦ä¹ ä¸­çš„è¯­ä¹‰æ··æ·†é—®é¢˜ã€‚é€šè¿‡å¯¹æ¯”å…­ç§åŸºçº¿ç®—æ³•çš„ç»¼åˆè¯„ä¼°ï¼ŒLECTORåœ¨100ä¸ªæ¨¡æ‹Ÿå­¦ä¹ è€…ä¸­å®ç°äº†90.2%çš„æˆåŠŸç‡ï¼Œç›¸è¾ƒäºæœ€ä½³åŸºçº¿ï¼ˆSSP-MMCï¼‰çš„88.4%æé«˜äº†2.0%ã€‚è¯¥ç®—æ³•åœ¨å¤„ç†è¯­ä¹‰ç›¸ä¼¼æ¦‚å¿µæ—¶è¡¨ç°å‡ºè‰²ï¼Œå‡å°‘äº†æ··æ·†å¼•èµ·çš„é”™è¯¯ï¼ŒåŒæ—¶ä¿æŒäº†è®¡ç®—æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰é—´éš”é‡å¤ç®—æ³•åœ¨è¯­ä¹‰å¹²æ‰°å’Œä¸ªæ€§åŒ–é€‚åº”æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨è¯­è¨€å­¦ä¹ ä¸­ï¼Œè¯­ä¹‰æ··æ·†ä¼šå½±å“å­¦ä¹ è€…çš„è®°å¿†æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLECTORçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦è¯„ä¼°ï¼Œå¹¶å°†å…¶ä¸ä¸ªæ€§åŒ–å­¦ä¹ æ¡£æ¡ˆç»“åˆï¼Œä»¥ä¼˜åŒ–å­¦ä¹ è°ƒåº¦ï¼Œå‡å°‘è¯­ä¹‰æ··æ·†å¸¦æ¥çš„é”™è¯¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLECTORçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¯­ä¹‰åˆ†ææ¨¡å—ã€ä¸ªæ€§åŒ–å­¦ä¹ æ¡£æ¡ˆæ¨¡å—å’Œè°ƒåº¦ç®—æ³•æ¨¡å—ã€‚è¯­ä¹‰åˆ†ææ¨¡å—è´Ÿè´£è¯„ä¼°è¯æ±‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œä¸ªæ€§åŒ–å­¦ä¹ æ¡£æ¡ˆæ¨¡å—è®°å½•å­¦ä¹ è€…çš„å­¦ä¹ è¿›åº¦å’Œåå¥½ï¼Œè°ƒåº¦ç®—æ³•æ¨¡å—åˆ™æ ¹æ®åˆ†æç»“æœè°ƒæ•´å­¦ä¹ è®¡åˆ’ã€‚

**å…³é”®åˆ›æ–°**ï¼šLECTORçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯­ä¹‰åˆ†æèƒ½åŠ›ä¸ä¼ ç»Ÿçš„é—´éš”é‡å¤åŸåˆ™ç›¸ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†å¯¹è¯­ä¹‰ç›¸ä¼¼æ¦‚å¿µçš„å¤„ç†èƒ½åŠ›ï¼Œå‡å°‘äº†æ··æ·†å¼•èµ·çš„é”™è¯¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒLECTORé‡‡ç”¨äº†åŠ¨æ€è°ƒæ•´çš„å­¦ä¹ é—´éš”ï¼Œå¹¶ç»“åˆä¸ªæ€§åŒ–çš„å­¦ä¹ åé¦ˆæœºåˆ¶ï¼Œç¡®ä¿å­¦ä¹ è€…åœ¨é€‚å½“çš„æ—¶é—´å¤ä¹ ç›¸å…³å†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒLECTORåœ¨100ä¸ªæ¨¡æ‹Ÿå­¦ä¹ è€…ä¸­å®ç°äº†90.2%çš„æˆåŠŸç‡ï¼Œç›¸è¾ƒäºæœ€ä½³åŸºçº¿ç®—æ³•SSP-MMCçš„88.4%æé«˜äº†2.0%ã€‚è¯¥ç®—æ³•åœ¨å¤„ç†è¯­ä¹‰ç›¸ä¼¼æ¦‚å¿µæ—¶è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—å‡å°‘äº†æ··æ·†å¼•èµ·çš„é”™è¯¯ï¼ŒåŒæ—¶ä¿æŒäº†è‰¯å¥½çš„è®¡ç®—æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LECTORçš„ç ”ç©¶æˆæœåœ¨æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œè‡ªé€‚åº”å­¦ä¹ å¹³å°ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å­¦ä¹ æ•ˆç‡å’Œè®°å¿†ä¿æŒç‡ï¼Œè¯¥ç®—æ³•å¯ä»¥å¸®åŠ©å­¦ä¹ è€…æ›´å¥½åœ°æŒæ¡è¯­è¨€çŸ¥è¯†ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å‹çš„è€ƒè¯•ç¯å¢ƒä¸­ã€‚æœªæ¥ï¼ŒLECTORå¯èƒ½ä¼šæ‰©å±•åˆ°å…¶ä»–å­¦ç§‘çš„å­¦ä¹ ä¸­ï¼Œæ¨åŠ¨ä¸ªæ€§åŒ–æ•™è‚²çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spaced repetition systems are fundamental to efficient learning and memory retention, but existing algorithms often struggle with semantic interference and personalized adaptation. We present LECTOR (\textbf{L}LM-\textbf{E}nhanced \textbf{C}oncept-based \textbf{T}est-\textbf{O}riented \textbf{R}epetition), a novel adaptive scheduling algorithm specifically designed for test-oriented learning scenarios, particularly language examinations where success rate is paramount. LECTOR leverages large language models for semantic analysis while incorporating personalized learning profiles, addressing the critical challenge of semantic confusion in vocabulary learning by utilizing LLM-powered semantic similarity assessment and integrating it with established spaced repetition principles. Our comprehensive evaluation against six baseline algorithms (SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over 100 days demonstrates significant improvements: LECTOR achieves a 90.2\% success rate compared to 88.4\% for the best baseline (SSP-MMC), representing a 2.0\% relative improvement. The algorithm shows particular strength in handling semantically similar concepts, reducing confusion-induced errors while maintaining computational efficiency. Our results establish LECTOR as a promising direction for intelligent tutoring systems and adaptive learning platforms.

