---
layout: default
title: Do language models accommodate their users? A study of linguistic convergence
---

# Do language models accommodate their users? A study of linguistic convergence

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03276" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03276v1</a>
  <a href="https://arxiv.org/pdf/2508.03276.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03276v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03276v1', 'Do language models accommodate their users? A study of linguistic convergence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Terra Blevins, Susanne Schmalwieser, Benjamin Roth

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¯­è¨€æ¨¡å‹çš„è¯­è¨€é€‚åº”æ€§ï¼Œæ­ç¤ºå…¶ä¸ç”¨æˆ·çš„è¯­è¨€è¶‹åŒç°è±¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `è¯­è¨€è¶‹åŒ` `äººæœºäº¤äº’` `å¯¹è¯ç³»ç»Ÿ` `é€‚åº”æ€§ç ”ç©¶` `æ¨¡å‹æ¯”è¾ƒ` `è¯­ç”¨å…ƒç´ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»è¯­è¨€ä½¿ç”¨çš„ç›¸ä¼¼æ€§å…³æ³¨ä¸è¶³ï¼Œç¼ºä¹å¯¹æ¨¡å‹æ˜¯å¦ä¼šé€‚åº”ç”¨æˆ·è¯­è¨€æ¨¡å¼çš„ç³»ç»Ÿæ€§ç ”ç©¶ã€‚
2. è®ºæ–‡é€šè¿‡æ¯”è¾ƒåå…­ç§è¯­è¨€æ¨¡å‹åœ¨å¯¹è¯ä¸­çš„ç”Ÿæˆç»“æœä¸äººç±»å“åº”ï¼Œæ¢è®¨æ¨¡å‹çš„è¯­è¨€è¶‹åŒç°è±¡ï¼Œæ­ç¤ºå…¶é€‚åº”æ€§ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨å¯¹è¯é£æ ¼ä¸Šå¼ºçƒˆè¶‹åŒï¼Œä¸”ä¸åŒæ¨¡å‹çš„è¶‹åŒç¨‹åº¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå°¤å…¶æ˜¯æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹è¶‹åŒè¾ƒå°‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆè¯­è¨€æ–¹é¢è¢«æ™®éè®¤ä¸ºæ˜¯ç†Ÿç»ƒçš„ï¼Œä½†å®ƒä»¬çš„è¯­è¨€ä½¿ç”¨ä¸äººç±»çš„ç›¸ä¼¼ç¨‹åº¦ä»ç„¶æœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æœ¬æ–‡æµ‹è¯•äº†æ¨¡å‹æ˜¯å¦è¡¨ç°å‡ºè¯­è¨€è¶‹åŒè¿™ä¸€äººç±»è¯­è¨€äº¤æµçš„æ ¸å¿ƒè¯­ç”¨å…ƒç´ ï¼Œæ¢è®¨æ¨¡å‹æ˜¯å¦ä¼šé€‚åº”æˆ–è¶‹åŒäºç”¨æˆ·çš„è¯­è¨€æ¨¡å¼ã€‚é€šè¿‡ç³»ç»Ÿæ¯”è¾ƒåå…­ç§è¯­è¨€æ¨¡å‹åœ¨ä¸‰ç§å¯¹è¯è¯­æ–™åº“ä¸­çš„ç”Ÿæˆç»“æœä¸åŸå§‹äººç±»å“åº”ï¼Œå‘ç°æ¨¡å‹åœ¨å¯¹è¯é£æ ¼ä¸Šå¼ºçƒˆè¶‹åŒï¼Œä¸”å¾€å¾€ç›¸å¯¹äºäººç±»åŸºçº¿æ˜¾è‘—è¿‡æ‹Ÿåˆã€‚å°½ç®¡è¶‹åŒæ¨¡å¼é€šå¸¸æ˜¯ç‰¹å¾ç‰¹å®šçš„ï¼Œä½†åœ¨ä¸åŒå»ºæ¨¡è®¾ç½®ä¸­è§‚å¯Ÿåˆ°è¶‹åŒçš„ä¸€è‡´æ€§å˜åŒ–ï¼ŒæŒ‡ä»¤è°ƒä¼˜å’Œæ›´å¤§æ¨¡å‹çš„è¶‹åŒç¨‹åº¦ä½äºå…¶é¢„è®­ç»ƒå¯¹åº”ç‰©ã€‚åŸºäºäººç±»ä¸æ¨¡å‹è¶‹åŒæ¨¡å¼çš„å·®å¼‚ï¼Œå‡è®¾å…¶èƒŒåçš„æœºåˆ¶å¯èƒ½æˆªç„¶ä¸åŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¯­è¨€ç”Ÿæˆä¸­æ˜¯å¦ä¼šè¶‹åŒäºç”¨æˆ·è¯­è¨€æ¨¡å¼çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿæ€§åœ°æ¢è®¨æ¨¡å‹ä¸äººç±»è¯­è¨€ä½¿ç”¨çš„ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´å¯¹æ¨¡å‹é€‚åº”æ€§çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿæ¯”è¾ƒæ¨¡å‹ç”Ÿæˆçš„å¯¹è¯ä¸äººç±»å“åº”ï¼Œåˆ†ææ¨¡å‹åœ¨è¯­è¨€ä½¿ç”¨ä¸Šçš„è¶‹åŒç°è±¡ï¼Œæ¢è®¨å…¶é€‚åº”æ€§å’Œç‰¹å¾ç‰¹å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†åå…­ç§è¯­è¨€æ¨¡å‹ï¼Œç»“åˆä¸‰ç§å¯¹è¯è¯­æ–™åº“ï¼Œåˆ†æäº†å¤šç§é£æ ¼ç‰¹å¾ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹ç”Ÿæˆã€ç‰¹å¾æå–å’Œæ¯”è¾ƒåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒä¸åŒæ¨¡å‹çš„è¯­è¨€è¶‹åŒç°è±¡ï¼Œæ­ç¤ºäº†æŒ‡ä»¤è°ƒä¼˜å’Œæ›´å¤§æ¨¡å‹åœ¨è¶‹åŒç¨‹åº¦ä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œè¿™ä¸ç°æœ‰ç ”ç©¶çš„å•ä¸€æ¨¡å‹åˆ†æå½¢æˆå¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†å¤šç§é£æ ¼ç‰¹å¾è¿›è¡Œåˆ†æï¼Œæ¨¡å‹çš„é€‰æ‹©æ¶µç›–äº†ä¸åŒè§„æ¨¡å’Œè®­ç»ƒæ–¹å¼ï¼Œç¡®ä¿äº†ç»“æœçš„å…¨é¢æ€§å’Œå¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨å¯¹è¯é£æ ¼ä¸Šè¡¨ç°å‡ºå¼ºçƒˆçš„è¶‹åŒç°è±¡ï¼Œç›¸è¾ƒäºäººç±»åŸºçº¿ï¼Œæ¨¡å‹çš„è¿‡æ‹Ÿåˆç¨‹åº¦æ˜¾è‘—ã€‚ç‰¹åˆ«æ˜¯æŒ‡ä»¤è°ƒä¼˜å’Œæ›´å¤§æ¨¡å‹çš„è¶‹åŒç¨‹åº¦ä½äºé¢„è®­ç»ƒæ¨¡å‹ï¼Œè¡¨æ˜æ¨¡å‹çš„é€‚åº”æ€§å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€å¯¹è¯ç³»ç»Ÿå’Œä¸ªæ€§åŒ–æ¨èç­‰ã€‚é€šè¿‡ç†è§£è¯­è¨€æ¨¡å‹çš„é€‚åº”æ€§ï¼Œå¯ä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œæé«˜ç”¨æˆ·ä½“éªŒå’Œäº¤äº’è´¨é‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´è‡ªç„¶çš„å¯¹è¯ç³»ç»Ÿå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large language models (LLMs) are generally considered proficient in generating language, how similar their language usage is to that of humans remains understudied. In this paper, we test whether models exhibit linguistic convergence, a core pragmatic element of human language communication, asking: do models adapt, or converge, to the linguistic patterns of their user? To answer this, we systematically compare model completions of exisiting dialogues to the original human responses across sixteen language models, three dialogue corpora, and a variety of stylometric features. We find that models strongly converge to the conversation's style, often significantly overfitting relative to the human baseline. While convergence patterns are often feature-specific, we observe consistent shifts in convergence across modeling settings, with instruction-tuned and larger models converging less than their pretrained counterparts. Given the differences between human and model convergence patterns, we hypothesize that the underlying mechanisms for these behaviors are very different.

