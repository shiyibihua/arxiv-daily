---
layout: default
title: CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation
---

# CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03935" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03935v1</a>
  <a href="https://arxiv.org/pdf/2508.03935.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03935v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03935v1', 'CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raymond Wilson, Cole Graham, Chase Carter, Zefeng Yang, Ruiqi Gu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAP-LLMä»¥è§£å†³ä¸ªæ€§åŒ–æ–°é—»æ ‡é¢˜ç”Ÿæˆä¸­çš„äº‹å®ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–ç”Ÿæˆ` `æ–°é—»æ ‡é¢˜` `äº‹å®ä¸€è‡´æ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å¢å¼º` `å¯¹æ¯”æŸå¤±` `ç”¨æˆ·åå¥½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸ªæ€§åŒ–æ–°é—»æ ‡é¢˜ç”Ÿæˆæ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰ç”¨æˆ·å¤æ‚å…´è¶£ï¼Œä¸”å¸¸å¸¸å¯¼è‡´äº‹å®ä¸ä¸€è‡´ã€‚
2. CAP-LLMé€šè¿‡ç”¨æˆ·åå¥½ç¼–ç å™¨å’Œä¸Šä¸‹æ–‡æ³¨å…¥é€‚é…å™¨ï¼Œå°†ç”¨æˆ·åå¥½ä¸æ–‡ç« ä¸Šä¸‹æ–‡ç»“åˆï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚
3. åœ¨PENSæ•°æ®é›†ä¸Šï¼ŒCAP-LLMåœ¨äº‹å®ä¸€è‡´æ€§ã€ä¸ªæ€§åŒ–å’Œå†…å®¹è¦†ç›–æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ä¿¡æ¯è¿‡è½½çš„æ—¶ä»£ï¼Œä¸ªæ€§åŒ–æ–°é—»æ ‡é¢˜ç”Ÿæˆå¯¹äºå¸å¼•ç”¨æˆ·è‡³å…³é‡è¦ï¼Œéœ€æ ¹æ®ç”¨æˆ·åå¥½å®šåˆ¶å†…å®¹å¹¶å‡†ç¡®ä¼ è¾¾æ–°é—»äº‹å®ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ•æ‰å¤æ‚çš„ç”¨æˆ·å…´è¶£å¹¶ç¡®ä¿äº‹å®ä¸€è‡´æ€§ï¼Œå¸¸å¯¼è‡´ç”Ÿæˆçš„æ ‡é¢˜è¿‡äºé€šç”¨æˆ–è¯¯å¯¼ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸Šä¸‹æ–‡å¢å¼ºä¸ªæ€§åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆCAP-LLMï¼‰ï¼Œè¯¥æ¡†æ¶å°†ç”¨æˆ·åå¥½å’Œäº‹å®ä¸€è‡´æ€§çº¦æŸæ•´åˆåˆ°å¼ºå¤§çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸­ã€‚CAP-LLMé€šè¿‡ç”¨æˆ·åå¥½ç¼–ç å™¨æ•æ‰é•¿æœŸç”¨æˆ·å…´è¶£ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ³¨å…¥é€‚é…å™¨å°†è¿™äº›åå¥½ä¸å½“å‰æ–‡ç« ä¸Šä¸‹æ–‡æ— ç¼æ•´åˆåˆ°ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¹¶é‡‡ç”¨å¯¹æ¯”æŸå¤±çš„äº‹å®ä¸€è‡´æ€§å¼ºåŒ–æ¨¡å—ä»¥å‡è½»å¹»è§‰ç°è±¡ã€‚CAP-LLMåœ¨çœŸå®ä¸–ç•Œçš„PENSæ•°æ®é›†ä¸Šè¯„ä¼°ï¼Œå–å¾—äº†å„é¡¹æŒ‡æ ‡çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸ªæ€§åŒ–æ–°é—»æ ‡é¢˜ç”Ÿæˆä¸­çš„äº‹å®ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•æ‰ç”¨æˆ·å…´è¶£å’Œç¡®ä¿ç”Ÿæˆæ ‡é¢˜çš„å‡†ç¡®æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´ç”Ÿæˆçš„æ ‡é¢˜å¾€å¾€ç¼ºä¹ä¸ªæ€§åŒ–å’ŒçœŸå®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCAP-LLMçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç”¨æˆ·åå¥½ä¸å½“å‰æ–‡ç« ä¸Šä¸‹æ–‡ç»“åˆï¼Œé€šè¿‡ä¸Šä¸‹æ–‡å¢å¼ºçš„æ–¹å¼æå‡ç”Ÿæˆæ ‡é¢˜çš„ä¸ªæ€§åŒ–å’Œäº‹å®ä¸€è‡´æ€§ã€‚è®¾è®¡ä¸Šï¼ŒCAP-LLMé€šè¿‡ç‰¹å®šæ¨¡å—æ¥æ•æ‰ç”¨æˆ·é•¿æœŸå…´è¶£ï¼Œå¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­è¿›è¡Œæœ‰æ•ˆæ•´åˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCAP-LLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç”¨æˆ·åå¥½ç¼–ç å™¨ã€ä¸Šä¸‹æ–‡æ³¨å…¥é€‚é…å™¨å’Œäº‹å®ä¸€è‡´æ€§å¼ºåŒ–æ¨¡å—ã€‚ç”¨æˆ·åå¥½ç¼–ç å™¨è´Ÿè´£æå–ç”¨æˆ·çš„é•¿æœŸå…´è¶£ï¼Œä¸Šä¸‹æ–‡æ³¨å…¥é€‚é…å™¨å°†è¿™äº›åå¥½ä¸å½“å‰æ–‡ç« çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ç»“åˆï¼Œè€Œäº‹å®ä¸€è‡´æ€§å¼ºåŒ–æ¨¡å—åˆ™é€šè¿‡å¯¹æ¯”æŸå¤±æ¥ç¡®ä¿ç”Ÿæˆå†…å®¹çš„çœŸå®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šCAP-LLMçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¯¹ç”¨æˆ·åå¥½å’Œäº‹å®ä¸€è‡´æ€§çš„åŒé‡å…³æ³¨ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ³¨å…¥å’Œå¯¹æ¯”æŸå¤±çš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ ‡é¢˜çš„è´¨é‡ã€‚è¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶ç»¼åˆè€ƒè™‘äº†ç”¨æˆ·ä¸ªæ€§åŒ–éœ€æ±‚ä¸äº‹å®å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒCAP-LLMé‡‡ç”¨äº†å¯¹æ¯”æŸå¤±å‡½æ•°æ¥å¼ºåŒ–äº‹å®ä¸€è‡´æ€§ï¼Œç¡®ä¿ç”Ÿæˆçš„æ ‡é¢˜ä¸ä»…ç¬¦åˆç”¨æˆ·åå¥½ï¼Œè¿˜èƒ½å‡†ç¡®åæ˜ æ–°é—»å†…å®¹ã€‚æ­¤å¤–ï¼Œç”¨æˆ·åå¥½ç¼–ç å™¨çš„ç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥æ›´å¥½åœ°æ•æ‰ç”¨æˆ·çš„é•¿æœŸå…´è¶£ã€‚æ•´ä½“ç½‘ç»œç»“æ„ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥æ”¯æŒé«˜æ•ˆçš„ä¸Šä¸‹æ–‡æ•´åˆå’Œç”Ÿæˆè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CAP-LLMåœ¨PENSæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå…¶äº‹å®ä¸€è‡´æ€§ï¼ˆFactCC 87.50ï¼‰æ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿BARTï¼ˆ86.67ï¼‰ï¼ŒåŒæ—¶åœ¨ä¸ªæ€§åŒ–ï¼ˆPc(avg) 2.73, Pc(max) 17.25ï¼‰å’Œå†…å®¹è¦†ç›–ï¼ˆROUGE-1 26.55, ROUGE-2 9.95, ROUGE-L 23.01ï¼‰æ–¹é¢ä¹Ÿå–å¾—äº†æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å„é¡¹æŒ‡æ ‡ä¸Šçš„é¢†å…ˆæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CAP-LLMåœ¨ä¸ªæ€§åŒ–æ–°é—»æ¨èã€ç¤¾äº¤åª’ä½“å†…å®¹ç”ŸæˆåŠä¿¡æ¯æ¨é€ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡ç”Ÿæˆæ ‡é¢˜çš„ä¸ªæ€§åŒ–å’Œäº‹å®ä¸€è‡´æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜ç”¨æˆ·çš„é˜…è¯»ä½“éªŒå’Œä¿¡æ¯è·å–æ•ˆç‡ï¼Œè¿›è€Œæ¨åŠ¨æ–°é—»è¡Œä¸šçš„æ™ºèƒ½åŒ–å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯æ‰©å±•è‡³å…¶ä»–æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ï¼Œå¦‚ä¸ªæ€§åŒ–å¹¿å‘Šå’Œå†…å®¹åˆ›ä½œç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In the era of information overload, personalized news headline generation is crucial for engaging users by tailoring content to their preferences while accurately conveying news facts. Existing methods struggle with effectively capturing complex user interests and ensuring factual consistency, often leading to generic or misleading headlines. Leveraging the unprecedented capabilities of Large Language Models (LLMs) in text generation, we propose Context-Augmented Personalized LLM (CAP-LLM), a novel framework that integrates user preferences and factual consistency constraints into a powerful pre-trained LLM backbone. CAP-LLM features a User Preference Encoder to capture long-term user interests, a Context Injection Adapter to seamlessly integrate these preferences and current article context into the LLM's generation process, and a Fact-Consistency Reinforcement Module employing a novel contrastive loss to mitigate hallucination. Evaluated on the real-world PENS dataset, CAP-LLM achieves state-of-the-art performance across all metrics. Notably, it significantly improves factual consistency (FactCC of 87.50) over strong baselines like BART (86.67), while simultaneously enhancing personalization (Pc(avg) 2.73, Pc(max) 17.25) and content coverage (ROUGE-1 26.55, ROUGE-2 9.95, ROUGE-L 23.01). Our ablation studies, human evaluations, and sensitivity analyses further validate the effectiveness of each component and the robustness of our approach, demonstrating CAP-LLM's ability to achieve a superior balance between personalization and factual accuracy in news headline generation.

