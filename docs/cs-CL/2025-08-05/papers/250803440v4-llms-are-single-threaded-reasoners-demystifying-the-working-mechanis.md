---
layout: default
title: LLMs are Single-threaded Reasoners: Demystifying the Working Mechanism of Soft Thinking
---

# LLMs are Single-threaded Reasoners: Demystifying the Working Mechanism of Soft Thinking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03440v4</a>
  <a href="https://arxiv.org/pdf/2508.03440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03440v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03440v4', 'LLMs are Single-threaded Reasoners: Demystifying the Working Mechanism of Soft Thinking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junhong Wu, Jinliang Lu, Zixuan Ren, Gangqiang Hu, Zhi Wu, Dai Dai, Hua Wu

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-10-16)

**å¤‡æ³¨**: 11 pages, 6 figures, working in progress

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšæœºè½¯æ€ç»´ä»¥è§£å†³LLMså•çº¿ç¨‹æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è½¯æ€ç»´` `éšæœºæ€§` `æ¨ç†èƒ½åŠ›` `Gumbel-Softmax` `è´ªå©ªé™·é˜±` `æ¢ç´¢æ½œåŠ›` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶ä¸»è¦ä¾èµ–æ¦‚ç‡æœ€é«˜çš„æ ‡è®°ï¼Œå¯¼è‡´å•çº¿ç¨‹æ¨ç†å’Œä¿¡æ¯ä¼ é€’èƒ½åŠ›ä¸è¶³ã€‚
2. æå‡ºéšæœºè½¯æ€ç»´ï¼Œé€šè¿‡å¼•å…¥éšæœºæ€§æ‰“ç ´è´ªå©ªåé¦ˆå¾ªç¯ï¼Œä»è€Œå¢å¼ºæ¨ç†è¿‡ç¨‹ä¸­çš„å¤šæ ·æ€§å’Œçµæ´»æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšæœºè½¯æ€ç»´åœ¨å…«ä¸ªæ¨ç†åŸºå‡†ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¢ç´¢æ½œåŠ›æ–¹é¢å…·æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººç±»è®¤çŸ¥è‡ªç„¶æ¶‰åŠæŠ½è±¡å’ŒæµåŠ¨çš„æ¦‚å¿µï¼Œè€Œç°æœ‰æ¨ç†æ¨¡å‹å¾€å¾€ä¾èµ–ç”Ÿæˆç¦»æ•£çš„æ ‡è®°ï¼Œé™åˆ¶äº†å…¶è¡¨è¾¾èƒ½åŠ›ã€‚æœ¬æ–‡é€šè¿‡ç³»ç»Ÿåˆ†æå¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å†…éƒ¨è¡Œä¸ºï¼Œæ¢è®¨å…¶è½¯æ€ç»´èƒ½åŠ›ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMsè¡¨ç°ä¸ºå•çº¿ç¨‹æ¨ç†è€…ï¼Œä¸»è¦ä¾èµ–è½¯è¾“å…¥ä¸­æ¦‚ç‡æœ€é«˜çš„æ ‡è®°è¿›è¡Œä¸‹ä¸€æ­¥é¢„æµ‹ï¼Œå¯¼è‡´è´ªå©ªåé¦ˆå¾ªç¯ï¼ŒæŠ‘åˆ¶äº†æ›¿ä»£æ¨ç†è·¯å¾„ã€‚ä¸ºäº†è§£å†³è¿™ä¸€è´ªå©ªé™·é˜±ï¼Œæœ¬æ–‡æå‡ºäº†éšæœºè½¯æ€ç»´ï¼Œå¼•å…¥éšæœºæ€§ä»¥æ‰“ç ´è¿™ä¸€å±€é™ã€‚å®éªŒè¡¨æ˜ï¼Œé‡‡ç”¨Gumbel-SoftmaxæŠ€å·§çš„éšæœºæ€§å¯ä»¥æ”¹å–„ä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³ï¼Œæå‡åœ¨å…«ä¸ªæ¨ç†åŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œå¹¶å±•ç¤ºå‡ºæ¯”ä¼ ç»Ÿé“¾å¼æ¨ç†æ›´å¼ºçš„æ¢ç´¢æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¡¨ç°ä¸ºå•çº¿ç¨‹ï¼Œä¸»è¦ä¾èµ–æ¦‚ç‡æœ€é«˜çš„æ ‡è®°ï¼Œå¯¼è‡´ä¿¡æ¯ä¼ é€’ä¸è¶³å’Œæ¨ç†è·¯å¾„çš„å•ä¸€åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºéšæœºè½¯æ€ç»´ï¼Œé€šè¿‡å¼•å…¥éšæœºæ€§æ¥æ‰“ç ´è´ªå©ªåé¦ˆå¾ªç¯ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ¢ç´¢æ›´å¤šçš„æ¨ç†è·¯å¾„ï¼Œä»è€Œæå‡æ¨ç†çš„å¤šæ ·æ€§å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥è½¯æ ‡è®°çš„ç”Ÿæˆã€éšæœºæ€§å¼•å…¥æ¨¡å—ï¼ˆå¦‚Gumbel-SoftmaxæŠ€å·§ï¼‰ï¼Œä»¥åŠæ¨ç†è·¯å¾„çš„è¯„ä¼°ä¸é€‰æ‹©ï¼Œç¡®ä¿æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„æ¢ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥éšæœºæ€§æ¥æ‰“ç ´è´ªå©ªé™·é˜±ï¼Œä½¿å¾—æ¨¡å‹ä¸å†å±€é™äºå•ä¸€çš„æ¨ç†è·¯å¾„ï¼Œä»è€Œèƒ½å¤Ÿæ›´å…¨é¢åœ°åˆ©ç”¨è½¯æ ‡è®°çš„ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨Gumbel-SoftmaxæŠ€å·§æ¥å®ç°éšæœºæ€§ï¼Œè®¾ç½®é€‚å½“çš„è¶…å‚æ•°ä»¥å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ï¼Œç¡®ä¿æ¨¡å‹åœ¨æ¨ç†æ—¶èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‰æ‹©ä¸åŒçš„è·¯å¾„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œéšæœºè½¯æ€ç»´åœ¨å…«ä¸ªæ¨ç†åŸºå‡†ä¸Šå‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶åœ¨æ¢ç´¢æ½œåŠ›æ–¹é¢è¡¨ç°çªå‡ºï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¤æ‚å†³ç­–æ”¯æŒç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æ›´å¤æ‚çš„ä»»åŠ¡ä¸­æä¾›æ›´å‡†ç¡®å’Œå¤šæ ·åŒ–çš„ç­”æ¡ˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Human cognition naturally engages with abstract and fluid concepts, whereas existing reasoning models often rely on generating discrete tokens, potentially constraining their expressive capabilities. Recent advancements aim to address this limitation by enabling large language models (LLMs) to generate soft, abstract tokens, thus facilitating reasoning within a continuous concept space. In this paper, we investigate the Soft Thinking capabilities of various LLMs through a systematic analysis of their internal behavior using a suite of probing techniques. Contrary to the prevailing belief that Soft Thinking supports parallel exploration of diverse reasoning paths, our findings reveal that LLMs behave as single-threaded reasoners--they predominantly rely on the token with the highest probability in the soft input to predict the next step. This behavior induces a greedy feedback loop that suppresses alternative reasoning paths and undermines the benefits of transmitting richer information via Soft Tokens. To address this Greedy Pitfall, we propose Stochastic Soft Thinking, which introduces stochasticity to break free from this Greedy Pitfall. Our experiments demonstrate that incorporating randomness--particularly with the Gumbel-Softmax trick--can alleviate the limitations of vanilla approaches and unleash the potential of Soft Thinking, resulting in superior performance across eight reasoning benchmarks. We further demonstrate that Stochastic Soft Thinking exhibits stronger exploration potential compared to conventional COT. Our findings deepen the understanding of continuous reasoning and establish the foundation for future work on improving Soft Thinking with Reinforcement Learning.

