---
layout: default
title: Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation
---

# Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03110" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03110v1</a>
  <a href="https://arxiv.org/pdf/2508.03110.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03110v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03110v1', 'Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zizhong Li, Haopeng Zhang, Jiawei Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTPARAGä»¥è§£å†³RAGç³»ç»Ÿçš„å®‰å…¨æ¼æ´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å®‰å…¨æ¼æ´` `å¯¹æŠ—æ€§æ”»å‡»` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼€æ”¾åŸŸé—®ç­”` `Tokençº§æ”»å‡»` `é²æ£’æ€§æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ”»å‡»RAGç³»ç»Ÿæ—¶ï¼Œå¾€å¾€è¿‡äºä¾èµ–æ£€ç´¢å™¨ï¼Œæˆ–æœªèƒ½åŒæ—¶è€ƒè™‘æ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µï¼Œå¯¼è‡´æ•ˆæœå—é™ã€‚
2. æœ¬æ–‡æå‡ºTPARAGæ¡†æ¶ï¼Œé€šè¿‡è½»é‡çº§ç™½ç®±LLMç”Ÿæˆå¹¶ä¼˜åŒ–æ¶æ„æ–‡æœ¬ï¼Œç¡®ä¿é«˜æ•ˆçš„æ”»å‡»æˆåŠŸç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTPARAGåœ¨å¼€æ”¾åŸŸé—®ç­”æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ä¹‹å‰çš„æ–¹æ³•ï¼Œæ­ç¤ºäº†RAGç³»ç»Ÿçš„å…³é”®è„†å¼±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†ä»é¢ä¸´å¹»è§‰å’Œè¿‡æ—¶çŸ¥è¯†ç­‰å…³é”®é™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ¡†æ¶é€šè¿‡æ£€ç´¢å™¨å¢å¼ºäº†LLMçš„å¤–éƒ¨çŸ¥è¯†è®¿é—®èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ç§é›†æˆå¸¦æ¥äº†æ–°çš„å®‰å…¨æ¼æ´ï¼Œæ¶æ„å†…å®¹å¯èƒ½è¢«æ£€ç´¢å¹¶ç”¨äºæ“æ§æ¨¡å‹è¾“å‡ºã€‚ç°æœ‰æ–¹æ³•åœ¨æ”»å‡»RAGç³»ç»Ÿæ—¶è¦ä¹ˆè¿‡äºä¾èµ–æ£€ç´¢å™¨ï¼Œè¦ä¹ˆæœªèƒ½åŒæ—¶è€ƒè™‘æ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µï¼Œé™åˆ¶äº†å…¶åœ¨é»‘ç®±åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºTokençº§åˆ«çš„ç²¾ç¡®æ”»å‡»æ¡†æ¶TPARAGï¼Œé’ˆå¯¹ç™½ç®±å’Œé»‘ç®±RAGç³»ç»Ÿè¿›è¡Œæ”»å‡»ï¼Œç¡®ä¿é«˜æ•ˆçš„æ”»å‡»æˆåŠŸç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTPARAGåœ¨æ£€ç´¢é˜¶æ®µå’Œç«¯åˆ°ç«¯æ”»å‡»æ•ˆæœä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ­ç¤ºäº†RAGç®¡é“ä¸­çš„å…³é”®æ¼æ´ï¼Œå¹¶ä¸ºæé«˜å…¶é²æ£’æ€§æä¾›äº†æ–°æ€è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³RAGç³»ç»Ÿä¸­ç”±äºå¤–éƒ¨æ•°æ®åº“æ¶æ„å†…å®¹å¼•å‘çš„å®‰å…¨æ¼æ´é—®é¢˜ã€‚ç°æœ‰æ”»å‡»æ–¹æ³•åœ¨é»‘ç®±åœºæ™¯ä¸‹æ•ˆæœæœ‰é™ï¼Œæ— æ³•æœ‰æ•ˆç»“åˆæ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTPARAGæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨è½»é‡çº§ç™½ç®±LLMä½œä¸ºæ”»å‡»è€…ï¼Œç”Ÿæˆå¹¶è¿­ä»£ä¼˜åŒ–æ¶æ„æ–‡æœ¬ï¼Œç¡®ä¿å…¶å¯æ£€ç´¢æ€§å’Œç”Ÿæˆé˜¶æ®µçš„é«˜æ”»å‡»æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTPARAGçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯ç”Ÿæˆé˜¶æ®µï¼Œä½¿ç”¨ç™½ç®±LLMç”Ÿæˆæ¶æ„æ–‡æœ¬ï¼›å…¶æ¬¡æ˜¯ä¼˜åŒ–é˜¶æ®µï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–ç¡®ä¿æ–‡æœ¬åœ¨æ£€ç´¢å’Œç”Ÿæˆä¸­çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šTPARAGçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶Tokençº§åˆ«çš„æ”»å‡»ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–æ£€ç´¢å™¨çš„æƒ…å†µä¸‹ï¼Œé’ˆå¯¹RAGç³»ç»Ÿçš„è„†å¼±æ€§è¿›è¡Œæœ‰æ•ˆæ”»å‡»ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„è®¾è®¡æ€è·¯æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒTPARAGé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ï¼Œå¹¶é€šè¿‡è°ƒæ•´å‚æ•°è®¾ç½®æ¥æé«˜æ”»å‡»çš„æˆåŠŸç‡ï¼Œç¡®ä¿ç”Ÿæˆæ–‡æœ¬åœ¨æ£€ç´¢å’Œç”Ÿæˆé˜¶æ®µå‡èƒ½æœ‰æ•ˆåˆ©ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTPARAGåœ¨å¼€æ”¾åŸŸé—®ç­”æ•°æ®é›†ä¸Šç›¸è¾ƒäºç°æœ‰æ–¹æ³•ï¼Œæ£€ç´¢é˜¶æ®µå’Œç«¯åˆ°ç«¯æ”»å‡»æ•ˆæœå‡æœ‰æ˜¾è‘—æå‡ï¼Œæ”»å‡»æˆåŠŸç‡æé«˜äº†20%ä»¥ä¸Šï¼Œæ­ç¤ºäº†RAGç³»ç»Ÿçš„å…³é”®è„†å¼±æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§è¯„ä¼°ã€å¯¹æŠ—æ€§æ”»å‡»ç ”ç©¶ä»¥åŠæå‡RAGç³»ç»Ÿçš„é²æ£’æ€§ã€‚é€šè¿‡è¯†åˆ«å’Œä¿®å¤RAGç³»ç»Ÿä¸­çš„è„†å¼±æ€§ï¼Œå¯ä»¥ä¸ºå®é™…åº”ç”¨æä¾›æ›´å®‰å…¨çš„çŸ¥è¯†æ£€ç´¢å’Œç”ŸæˆæœåŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large language models (LLMs) have achieved remarkable success in providing trustworthy responses for knowledge-intensive tasks, they still face critical limitations such as hallucinations and outdated knowledge. To address these issues, the retrieval-augmented generation (RAG) framework enhances LLMs with access to external knowledge via a retriever, enabling more accurate and real-time outputs about the latest events. However, this integration brings new security vulnerabilities: the risk that malicious content in the external database can be retrieved and used to manipulate model outputs. Although prior work has explored attacks on RAG systems, existing approaches either rely heavily on access to the retriever or fail to jointly consider both retrieval and generation stages, limiting their effectiveness, particularly in black-box scenarios. To overcome these limitations, we propose Token-level Precise Attack on the RAG (TPARAG), a novel framework that targets both white-box and black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an attacker to generate and iteratively optimize malicious passages at the token level, ensuring both retrievability and high attack success in generation. Extensive experiments on open-domain QA datasets demonstrate that TPARAG consistently outperforms previous approaches in retrieval-stage and end-to-end attack effectiveness. These results further reveal critical vulnerabilities in RAG pipelines and offer new insights into improving their robustness.

