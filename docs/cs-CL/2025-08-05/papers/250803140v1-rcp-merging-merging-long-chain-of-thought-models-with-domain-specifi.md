---
layout: default
title: RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior
---

# RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03140" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.03140v1</a>
  <a href="https://arxiv.org/pdf/2508.03140.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03140v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03140v1', 'RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Junyao Yang, Jianwei Wang, Huiping Zhuang, Cen Chen, Ziqian Zeng

**ÂàÜÁ±ª**: cs.CL, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-05

**Â§áÊ≥®**: 15 pages, 7 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RCP-Merging‰ª•Ëß£ÂÜ≥ÈïøÈìæÊé®ÁêÜÊ®°Âûã‰∏éÈ¢ÜÂüüÁâπÂÆöÊ®°ÂûãËûçÂêàÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÈïøÈìæÊé®ÁêÜ` `Ê®°ÂûãËûçÂêà` `È¢ÜÂüüÁâπÂÆöÊ®°Âûã` `Êé®ÁêÜËÉΩÂäõ` `ÁîüÁâ©ÂåªÂ≠¶` `ÈáëËûç` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËµÑÊ∫êÊïàÁéá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊ®°ÂûãËûçÂêàÊñπÊ≥ïÂú®ÂêàÂπ∂È¢ÜÂüüÁâπÂÆöLLMs‰∏éÈïøÈìæÊé®ÁêÜÊ®°ÂûãÊó∂ÔºåÂ∏∏ÂØºËá¥Êé®ÁêÜËÉΩÂäõ‰∏ãÈôçÂíåËæìÂá∫Ê∑∑‰π±Á≠âÈóÆÈ¢ò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫RCP-MergingÊ°ÜÊû∂ÔºåÈÄöËøáÂ∞ÜÊé®ÁêÜÊ®°ÂûãÊùÉÈáçËßÜ‰∏∫ÂÖàÈ™åÔºåÂà©Áî®Êé®ÁêÜËÉΩÂäõÊåáÊ†áÂÆûÁé∞ÊúâÊïàÁöÑÊ®°ÂûãËûçÂêà„ÄÇ
3. Âú®ÁîüÁâ©ÂåªÂ≠¶ÂíåÈáëËûçÈ¢ÜÂüüÁöÑÂÆûÈ™å‰∏≠ÔºåRCP-MergingÊòæËëóÊèêÂçá‰∫Ü‰ªªÂä°ÊÄßËÉΩÔºåÂàÜÂà´ÊèêÈ´ò‰∫Ü9.5%Âíå9.2%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂÖ∑Â§áÈïøÈìæÊé®ÁêÜÔºàCoTÔºâËÉΩÂäõÔºåÁß∞‰∏∫Êé®ÁêÜÊ®°ÂûãÔºåÂ±ïÁé∞Âá∫ÂçìË∂äÁöÑÂ§çÊùÇÈóÆÈ¢òËß£ÂÜ≥ËÉΩÂäõ„ÄÇ‰∏∫Âú®‰∏çÂ¢ûÂä†ËÆ°ÁÆóÂíåÊï∞ÊçÆÊàêÊú¨ÁöÑÊÉÖÂÜµ‰∏ãÂàõÂª∫ÂÖ∑Â§áÈïøCoTËÉΩÂäõÂíåÈ¢ÜÂüüÁâπÂÆöÁü•ËØÜÁöÑÂèåËÉΩÂäõÊ®°ÂûãÔºåÊ®°ÂûãËûçÂêàÊàê‰∏∫‰∏ÄÁßçÈ´òÊïàÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâËûçÂêàÊñπÊ≥ïÂú®ÂêàÂπ∂È¢ÜÂüüÁâπÂÆöLLMs‰∏éÈïøCoTÊ®°ÂûãÊó∂Èù¢‰∏¥Êé®ÁêÜËÉΩÂäõ‰∏ãÈôç„ÄÅËæìÂá∫Ê∑∑‰π±Á≠âÊåëÊàò„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫RCP-MergingÊ°ÜÊû∂ÔºåÊó®Âú®Â∞ÜÈ¢ÜÂüüÁâπÂÆöLLMs‰∏éÈïøCoTËÉΩÂäõÊ®°ÂûãÊúâÊïàËûçÂêàÔºåÂêåÊó∂‰øùÊåÅÂéüÈ¢ÜÂüüÁöÑÊ®°ÂûãÊÄßËÉΩ„ÄÇÈÄöËøáÂ∞ÜÊé®ÁêÜÊ®°ÂûãÊùÉÈáçËßÜ‰∏∫Âü∫Á°ÄÂÖàÈ™åÔºåÂà©Áî®Êé®ÁêÜËÉΩÂäõÊåáÊ†á‰øùÁïôÊ†∏ÂøÉÈïøCoTËÉΩÂäõÊ®°ÂûãÊùÉÈáçÔºåÂπ∂ÈÄâÊã©ÊÄßËûçÂêàÂøÖË¶ÅÁöÑÈ¢ÜÂüüÁâπÂÆöÊùÉÈáç„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåRCP-MergingÂú®ÁîüÁâ©ÂåªÂ≠¶ÂíåÈáëËûçÈ¢ÜÂüüÁöÑ‰ªªÂä°ÊÄßËÉΩÊèêÂçá‰∫Ü9.5%Âíå9.2%Ôºå‰∏îÊú™ÊòæËëóÊçüÂÆ≥ÂéüÊúâÁöÑÈïøCoTÊé®ÁêÜËÉΩÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøÈìæÊé®ÁêÜÊ®°Âûã‰∏éÈ¢ÜÂüüÁâπÂÆöÊ®°ÂûãËûçÂêàÊó∂Êé®ÁêÜËÉΩÂäõ‰∏ãÈôçÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®ËûçÂêàËøáÁ®ã‰∏≠Â∏∏Âá∫Áé∞ËæìÂá∫Ê∑∑‰π±ÂíåÊÄßËÉΩ‰∏ãÈôçÁöÑÁé∞Ë±°„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöRCP-MergingÊ°ÜÊû∂ÈÄöËøáÂ∞ÜÊé®ÁêÜÊ®°ÂûãÁöÑÊùÉÈáçËßÜ‰∏∫Âü∫Á°ÄÂÖàÈ™åÔºåÂà©Áî®Êé®ÁêÜËÉΩÂäõÊåáÊ†áÊù•‰øùÁïôÈïøÈìæÊé®ÁêÜÊ®°ÂûãÁöÑÊ†∏ÂøÉÊùÉÈáçÔºåÂêåÊó∂ÈÄâÊã©ÊÄßÂú∞ËûçÂêàÈ¢ÜÂüüÁâπÂÆöÁöÑÊùÉÈáçÔºå‰ªéËÄåÂÆûÁé∞ÊúâÊïàÁöÑÊ®°ÂûãËûçÂêà„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰∏§‰∏™Èò∂ÊÆµÔºöÈ¶ñÂÖàÔºåËØÑ‰º∞Êé®ÁêÜÊ®°ÂûãÁöÑÊùÉÈáçÂíåÈ¢ÜÂüüÁâπÂÆöÊ®°ÂûãÁöÑÊùÉÈáçÔºõÂÖ∂Ê¨°ÔºåÂü∫‰∫éÊé®ÁêÜËÉΩÂäõÊåáÊ†áËøõË°åÊùÉÈáçÁöÑÈÄâÊã©ÊÄßËûçÂêàÔºåÁ°Æ‰øù‰øùÁïôÊé®ÁêÜËÉΩÂäõÁöÑÂêåÊó∂ÂºïÂÖ•È¢ÜÂüüÁü•ËØÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRCP-MergingÁöÑÂàõÊñ∞Âú®‰∫éÂºïÂÖ•Êé®ÁêÜËÉΩÂäõÊåáÊ†á‰Ωú‰∏∫ËûçÂêàÁöÑÂÖàÈ™åÔºåÁ°Æ‰øùÂú®ÂêàÂπ∂ËøáÁ®ã‰∏≠‰∏çÊçüÂÆ≥ÈïøÈìæÊé®ÁêÜËÉΩÂäõÔºåËøôÊòØ‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåÈÄâÊã©‰∫ÜÈÄÇÂΩìÁöÑÊé®ÁêÜËÉΩÂäõÊåáÊ†áÔºåÂπ∂ËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•Âπ≥Ë°°Êé®ÁêÜËÉΩÂäõ‰∏éÈ¢ÜÂüüÁü•ËØÜÁöÑËûçÂêàÔºåÁ°Æ‰øùÊ®°ÂûãÂú®‰∏§‰∏™È¢ÜÂüüÁöÑÊÄßËÉΩÂùáÂæóÂà∞ÊèêÂçá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåRCP-MergingÂú®ÁîüÁâ©ÂåªÂ≠¶ÂíåÈáëËûçÈ¢ÜÂüüÁöÑ‰ªªÂä°ÊÄßËÉΩÂàÜÂà´ÊèêÂçá‰∫Ü9.5%Âíå9.2%ÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÔºåÂêåÊó∂‰øùÊåÅ‰∫ÜÈïøÈìæÊé®ÁêÜËÉΩÂäõÁöÑÂÆåÊï¥ÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂Âú®ÁîüÁâ©ÂåªÂ≠¶ÂíåÈáëËûçÁ≠âÈ¢ÜÂüüÔºåÂèØ‰ª•ÊúâÊïàÊèêÂçáÈ¢ÜÂüüÁâπÂÆö‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇÊú™Êù•ÔºåRCP-MergingÊ°ÜÊû∂ÂèØÊâ©Â±ïËá≥ÂÖ∂‰ªñÈ¢ÜÂüüÔºåÊé®Âä®Â§öÈ¢ÜÂüüÁü•ËØÜÁöÑËûçÂêà‰∏éÂ∫îÁî®ÔºåÊèêÂçáÊô∫ËÉΩÁ≥ªÁªüÁöÑÁªºÂêàËÉΩÂäõ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs) with long chain-of-thought (CoT) capability, termed Reasoning Models, demonstrate superior intricate problem-solving abilities through multi-step long CoT reasoning. To create a dual-capability model with long CoT capability and domain-specific knowledge without substantial computational and data costs, model merging emerges as a highly resource-efficient method. However, significant challenges lie in merging domain-specific LLMs with long CoT ones since nowadays merging methods suffer from reasoning capability degradation, even gibberish output and output collapse. To overcome this, we introduce RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior, a novel merging framework designed to integrate domain-specific LLMs with long CoT capability, meanwhile maintaining model performance in the original domain. Treating reasoning model weights as foundational prior, our method utilizes a reasoning capability indicator to preserve core long CoT capability model weights while selectively merging essential domain-specific weights. We conducted extensive experiments on Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance domains. Our results show that RCP-Merging successfully merges a reasoning model with domain-specific ones, improving domain task performance by 9.5% and 9.2% over state-of-the-art methods, without significantly harming the original long CoT reasoning capability.

