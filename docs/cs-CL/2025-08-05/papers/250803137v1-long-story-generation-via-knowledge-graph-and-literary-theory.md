---
layout: default
title: Long Story Generation via Knowledge Graph and Literary Theory
---

# Long Story Generation via Knowledge Graph and Literary Theory

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03137" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03137v1</a>
  <a href="https://arxiv.org/pdf/2508.03137.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03137v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03137v1', 'Long Story Generation via Knowledge Graph and Literary Theory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ge Shi, Kaiyu Huang, Guochen Feng

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šä»£ç†æ•…äº‹ç”Ÿæˆå™¨ä»¥è§£å†³é•¿ç¯‡æ•…äº‹ç”Ÿæˆä¸­çš„ä¸»é¢˜æ¼‚ç§»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿ç¯‡æ•…äº‹ç”Ÿæˆ` `å¤šä»£ç†ç³»ç»Ÿ` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†å›¾è°±` `æ–‡å­¦å™äº‹ç†è®º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºå¤§çº²çš„é•¿ç¯‡æ•…äº‹ç”Ÿæˆæ–¹æ³•å­˜åœ¨ä¸»é¢˜æ¼‚ç§»å’Œæƒ…èŠ‚ä¸è¿è´¯çš„é—®é¢˜ï¼Œå½±å“æ•…äº‹çš„å¸å¼•åŠ›ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šä»£ç†æ•…äº‹ç”Ÿæˆå™¨ç»“æ„ï¼Œåˆ©ç”¨é•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹å’Œæ–‡å­¦å™äº‹ç†è®ºæ¥æå‡æ•…äº‹ç”Ÿæˆè´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ç”Ÿæˆé•¿ç¯‡æ•…äº‹çš„è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºä»¥å¾€æ–¹æ³•ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¸å¼•è¯»è€…ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿ç¯‡æ•…äº‹ç”Ÿæˆæ˜¯é•¿æ–‡æœ¬ç”Ÿæˆé¢†åŸŸä¸­çš„ä¸€ä¸ªå­ä»»åŠ¡ã€‚ä»¥å¾€ç ”ç©¶é€šè¿‡åŸºäºå¤§çº²çš„ç”Ÿæˆæ–¹æ³•æ¥è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œä½†å­˜åœ¨ä¸»é¢˜æ¼‚ç§»å’Œæƒ…èŠ‚ä¹å‘³ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†å¤šä»£ç†æ•…äº‹ç”Ÿæˆå™¨ç»“æ„ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºæ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡å¼•å…¥é•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹æ¥é˜²æ­¢ä¸»é¢˜æ¼‚ç§»ï¼Œå¹¶è®¾è®¡äº†åŸºäºæ–‡å­¦å™äº‹ç†è®ºçš„æ•…äº‹ä¸»é¢˜éšœç¢æ¡†æ¶ï¼Œä»¥å¢å¼ºæ•…äº‹çš„å¸å¼•åŠ›ã€‚é€šè¿‡å¤šä»£ç†äº’åŠ¨é˜¶æ®µæ¨¡æ‹Ÿä½œå®¶ä¸è¯»è€…çš„äº’åŠ¨ï¼Œç¡®ä¿æ•…äº‹é€»è¾‘ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„é•¿ç¯‡æ•…äº‹è´¨é‡æ›´é«˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é•¿ç¯‡æ•…äº‹ç”Ÿæˆä¸­çš„ä¸»é¢˜æ¼‚ç§»å’Œæƒ…èŠ‚ä¸è¿è´¯é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å®¹æ˜“é—å¿˜ä¹‹å‰çš„å¤§çº²ï¼Œå¯¼è‡´æ•…äº‹é€»è¾‘æ··ä¹±å’Œå¸å¼•åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¤šä»£ç†æ•…äº‹ç”Ÿæˆå™¨ç»“æ„ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºä»£ç†æ ¸å¿ƒï¼Œé€šè¿‡é•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹æ¥ä¿æŒä¸»é¢˜ä¸€è‡´æ€§ï¼Œå¹¶å¼•å…¥æ–‡å­¦å™äº‹ç†è®ºä»¥å¢å¼ºæ•…äº‹çš„å¸å¼•åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹ã€æ•…äº‹ä¸»é¢˜éšœç¢æ¡†æ¶å’Œå¤šä»£ç†äº’åŠ¨é˜¶æ®µã€‚é•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹ç”¨äºå­˜å‚¨é‡è¦è®°å¿†å’Œæœ€æ–°å¤§çº²ï¼Œæ•…äº‹ä¸»é¢˜éšœç¢æ¡†æ¶åˆ™é€šè¿‡çŸ¥è¯†å›¾è°±ç”Ÿæˆå¸å¼•äººçš„æƒ…èŠ‚ï¼Œè€Œå¤šä»£ç†äº’åŠ¨é˜¶æ®µåˆ™æ¨¡æ‹Ÿä½œå®¶ä¸è¯»è€…çš„åé¦ˆäº’åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†é•¿çŸ­æœŸè®°å¿†å­˜å‚¨æ¨¡å‹å’ŒåŸºäºæ–‡å­¦å™äº‹ç†è®ºçš„æ•…äº‹ä¸»é¢˜éšœç¢æ¡†æ¶ï¼Œè¿™ä½¿å¾—ç”Ÿæˆçš„æ•…äº‹åœ¨ä¸»é¢˜å’Œæƒ…èŠ‚ä¸Šæ›´åŠ è¿è´¯å’Œå¸å¼•äººã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé•¿çŸ­æœŸè®°å¿†å­˜å‚¨çš„å‚æ•°è®¾ç½®å’ŒçŸ¥è¯†å›¾è°±çš„æ„å»ºæ˜¯å…³é”®ï¼Œç¡®ä¿äº†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¿¡æ¯ä¿ç•™å’Œæƒ…èŠ‚çš„ä¸°å¯Œæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ç”Ÿæˆçš„é•¿ç¯‡æ•…äº‹è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºæ•…äº‹çš„é€»è¾‘ä¸€è‡´æ€§å’Œå¸å¼•åŠ›æå‡ï¼Œç”Ÿæˆæ•…äº‹çš„è¯„åˆ†æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å°è¯´åˆ›ä½œã€æ¸¸æˆå‰§æƒ…ç”Ÿæˆå’Œæ•™è‚²é¢†åŸŸçš„æ•…äº‹æ•™å­¦ç­‰ã€‚é€šè¿‡æé«˜é•¿ç¯‡æ•…äº‹ç”Ÿæˆçš„è´¨é‡ï¼Œå¯ä»¥ä¸ºåˆ›ä½œè€…æä¾›æ›´å¥½çš„å·¥å…·ï¼Œæå‡è¯»è€…çš„ä½“éªŒï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–å†…å®¹åˆ›ä½œçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The generation of a long story consisting of several thousand words is a sub-task in the field of long text generation~(LTG). Previous research has addressed this challenge through outline-based generation, which employs a multi-stage method for generating outlines into stories. However, this approach suffers from two common issues: almost inevitable theme drift caused by the loss of memory of previous outlines, and tedious plots with incoherent logic that are less appealing to human readers.
>   In this paper, we propose the multi-agent Story Generator structure to improve the multi-stage method, using large language models~(LLMs) as the core components of agents. To avoid theme drift, we introduce a memory storage model comprising two components: a long-term memory storage that identifies the most important memories, thereby preventing theme drift; and a short-term memory storage that retains the latest outlines from each generation round. To incorporate engaging elements into the story, we design a story theme obstacle framework based on literary narratology theory that introduces uncertain factors and evaluation criteria to generate outline. This framework calculates the similarity of the former storyline and enhances the appeal of the story by building a knowledge graph and integrating new node content. Additionally, we establish a multi-agent interaction stage to simulate writer-reader interaction through dialogue and revise the story text according to feedback, to ensure it remains consistent and logical. Evaluations against previous methods demonstrate that our approach can generate higher-quality long stories.

