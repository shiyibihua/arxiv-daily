---
layout: default
title: Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models
---

# Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03860" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03860v2</a>
  <a href="https://arxiv.org/pdf/2508.03860.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03860v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03860v2', 'Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Subhey Sadi Rahman, Md. Adnanul Islam, Md. Mahbub Alam, Musarrat Zeba, Md. Abdur Rahman, Sadia Sultana Chowa, Mohaimenul Azam Khan Raiaan, Sami Azam

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-09-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼ºå¤§çš„äº‹å®æ£€æŸ¥æ¡†æ¶ä»¥è§£å†³LLMç”Ÿæˆå†…å®¹çš„è™šå‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äº‹å®æ£€æŸ¥` `è™šå‡ä¿¡æ¯` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `é¢†åŸŸç‰¹å®šå¾®è°ƒ` `å¤šä»£ç†æ¨ç†` `å†…å®¹å‡†ç¡®æ€§` `è¯„ä¼°æŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMåœ¨ç”Ÿæˆå†…å®¹æ—¶å®¹æ˜“å‡ºç°å¹»è§‰ï¼Œå¯¼è‡´è™šå‡ä¿¡æ¯çš„äº§ç”Ÿï¼Œç¼ºä¹æœ‰æ•ˆçš„äº‹å®æ£€æŸ¥æœºåˆ¶ã€‚
2. è®ºæ–‡æå‡ºäº†é›†æˆå…ˆè¿›æç¤ºç­–ç•¥ã€é¢†åŸŸç‰¹å®šå¾®è°ƒå’ŒRAGæ–¹æ³•çš„å¼ºå¤§äº‹å®æ£€æŸ¥æ¡†æ¶ï¼Œä»¥æé«˜å†…å®¹çš„å‡†ç¡®æ€§ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡é¢†åŸŸç‰¹å®šå®šåˆ¶å’ŒéªŒè¯å¤–éƒ¨è¯æ®ï¼Œå¯ä»¥æ˜¾è‘—æé«˜LLMç”Ÿæˆå†…å®¹çš„äº‹å®ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†å¤§é‡å¤šæ ·çš„äº’è”ç½‘è¯­æ–™ï¼Œè¿™äº›å†…å®¹ä¸­å¸¸å¸¸åŒ…å«ä¸å‡†ç¡®æˆ–è¯¯å¯¼æ€§çš„ä¿¡æ¯ã€‚å› æ­¤ï¼ŒLLMså¯èƒ½ç”Ÿæˆè™šå‡ä¿¡æ¯ï¼Œå¼ºæœ‰åŠ›çš„äº‹å®æ£€æŸ¥æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚æœ¬æ–‡ç³»ç»Ÿåˆ†æäº†LLMç”Ÿæˆå†…å®¹çš„äº‹å®å‡†ç¡®æ€§è¯„ä¼°ï¼Œæ¢è®¨äº†å¹»è§‰ã€æ•°æ®é›†é™åˆ¶å’Œè¯„ä¼°æŒ‡æ ‡å¯é æ€§ç­‰å…³é”®æŒ‘æˆ˜ã€‚å¼ºè°ƒäº†é›†æˆå…ˆè¿›æç¤ºç­–ç•¥ã€é¢†åŸŸç‰¹å®šå¾®è°ƒå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•çš„å¼ºå¤§äº‹å®æ£€æŸ¥æ¡†æ¶çš„å¿…è¦æ€§ã€‚æå‡ºäº†äº”ä¸ªç ”ç©¶é—®é¢˜ï¼ŒæŒ‡å¯¼å¯¹2020è‡³2025å¹´ç›¸å…³æ–‡çŒ®çš„åˆ†æï¼Œèšç„¦äºè¯„ä¼°æ–¹æ³•å’Œç¼“è§£æŠ€æœ¯ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºäº†å½“å‰æŒ‡æ ‡çš„å±€é™æ€§ã€éªŒè¯å¤–éƒ¨è¯æ®çš„é‡è¦æ€§ä»¥åŠé€šè¿‡é¢†åŸŸç‰¹å®šå®šåˆ¶æé«˜äº‹å®ä¸€è‡´æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºæ›´å‡†ç¡®ã€å¯ç†è§£å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„äº‹å®æ£€æŸ¥æä¾›äº†é‡è¦è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆå†…å®¹çš„è™šå‡ä¿¡æ¯é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å†…å®¹çš„äº‹å®å‡†ç¡®æ€§æ—¶é¢ä¸´å¹»è§‰ã€æ•°æ®é›†é™åˆ¶å’Œè¯„ä¼°æŒ‡æ ‡å¯é æ€§ç­‰æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¼ºå¤§çš„äº‹å®æ£€æŸ¥æ¡†æ¶ï¼Œç»“åˆå…ˆè¿›çš„æç¤ºç­–ç•¥ã€é¢†åŸŸç‰¹å®šçš„å¾®è°ƒå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•ï¼Œä»¥æé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒã€äº‹å®æ£€æŸ¥å’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œç„¶åé€šè¿‡é¢†åŸŸç‰¹å®šå¾®è°ƒè®­ç»ƒæ¨¡å‹ï¼Œæ¥ç€åº”ç”¨RAGæ–¹æ³•è¿›è¡Œå†…å®¹ç”Ÿæˆï¼Œæœ€åå¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œäº‹å®å‡†ç¡®æ€§è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ç»“åˆå¤šç§æ–¹æ³•çš„ç»¼åˆæ¡†æ¶ï¼Œå°¤å…¶æ˜¯å°†RAGä¸é¢†åŸŸç‰¹å®šå¾®è°ƒç»“åˆï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹å¤–éƒ¨çŸ¥è¯†çš„è®¿é—®èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„äº‹å®ä¸€è‡´æ€§ï¼Œå¹¶é€šè¿‡å¤šä»£ç†æ¨ç†æœºåˆ¶å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹çš„ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°æ¡†æ¶çš„æ¨¡å‹åœ¨äº‹å®ä¸€è‡´æ€§è¯„ä¼°ä¸­ç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æé«˜äº†15%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨å¤šä¸ªé¢†åŸŸç‰¹å®šä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œå¯é æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé›†æˆå…ˆè¿›æ–¹æ³•çš„äº‹å®æ£€æŸ¥æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—æå‡LLMç”Ÿæˆå†…å®¹çš„è´¨é‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»éªŒè¯ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œæ•™è‚²é¢†åŸŸçš„çŸ¥è¯†éªŒè¯ç­‰ã€‚é€šè¿‡æé«˜LLMç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘è™šå‡ä¿¡æ¯çš„ä¼ æ’­ï¼Œæå‡å…¬ä¼—å¯¹ä¿¡æ¯çš„ä¿¡ä»»åº¦ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…å½±å“ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­ï¼Œè¿›ä¸€æ­¥æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are trained on vast and diverse internet corpora that often include inaccurate or misleading content. Consequently, LLMs can generate misinformation, making robust fact-checking essential. This review systematically analyzes how LLM-generated content is evaluated for factual accuracy by exploring key challenges such as hallucinations, dataset limitations, and the reliability of evaluation metrics. The review emphasizes the need for strong fact-checking frameworks that integrate advanced prompting strategies, domain-specific fine-tuning, and retrieval-augmented generation (RAG) methods. It proposes five research questions that guide the analysis of the recent literature from 2020 to 2025, focusing on evaluation methods and mitigation techniques. Instruction tuning, multi-agent reasoning, and RAG frameworks for external knowledge access are also reviewed. The key findings demonstrate the limitations of current metrics, the importance of validated external evidence, and the improvement of factual consistency through domain-specific customization. The review underscores the importance of building more accurate, understandable, and context-aware fact-checking. These insights contribute to the advancement of research toward more trustworthy models.

