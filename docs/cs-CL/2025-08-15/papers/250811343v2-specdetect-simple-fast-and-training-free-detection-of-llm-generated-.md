---
layout: default
title: SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis
---

# SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11343" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11343v2</a>
  <a href="https://arxiv.org/pdf/2508.11343.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11343v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11343v2', 'SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haitong Luo, Weiyao Zhang, Suhang Wang, Wenji Zou, Chungang Lin, Xuying Meng, Yujun Zhang

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15 (æ›´æ–°: 2025-08-18)

**å¤‡æ³¨**: Under Review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpecDetectä»¥è§£å†³LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡æœ¬æ£€æµ‹` `ä¿¡å·å¤„ç†` `é¢‘åŸŸåˆ†æ` `å¤§å‹è¯­è¨€æ¨¡å‹` `é²æ£’æ€§å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹æ–¹æ³•å¤šä¾èµ–è¡¨é¢ç»Ÿè®¡ï¼Œå¿½è§†äº†æ–‡æœ¬ç”Ÿæˆçš„ä¿¡å·ç‰¹æ€§ï¼Œå¯¼è‡´æ£€æµ‹æ•ˆæœæœ‰é™ã€‚
2. æœ¬æ–‡æå‡ºå°†æ£€æµ‹è§†ä¸ºä¿¡å·å¤„ç†é—®é¢˜ï¼Œé€šè¿‡é¢‘åŸŸåˆ†ææ ‡è®°å¯¹æ•°æ¦‚ç‡åºåˆ—ï¼Œåˆ©ç”¨DFTå’ŒSTFTæå–æ–‡æœ¬çš„è°±ç‰¹æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpecDetectåœ¨æ€§èƒ½ä¸Šè¶…è¶Šäº†ç°æœ‰æ¨¡å‹ï¼Œä¸”è¿è¡Œæ—¶é—´å‡å°‘è¿‘ä¸€åŠï¼Œå±•ç°å‡ºé«˜æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬çš„æ™®åŠï¼Œå¯é ä¸”é«˜æ•ˆçš„æ£€æµ‹æ–¹æ³•å˜å¾—æ„ˆå‘é‡è¦ã€‚ç°æœ‰çš„æ— è®­ç»ƒæ–¹æ³•è™½ç„¶æœ‰å‰æ™¯ï¼Œä½†å¾€å¾€ä¾èµ–è¡¨é¢ç»Ÿè®¡ï¼Œå¿½è§†æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹çš„åŸºæœ¬ä¿¡å·ç‰¹æ€§ã€‚æœ¬æ–‡å°†æ£€æµ‹é‡æ–°æ¡†å®šä¸ºä¿¡å·å¤„ç†é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°èŒƒå¼ï¼Œé€šè¿‡é¢‘åŸŸåˆ†ææ ‡è®°å¯¹æ•°æ¦‚ç‡åºåˆ—ã€‚åˆ©ç”¨å…¨å±€ç¦»æ•£å‚…é‡Œå¶å˜æ¢ï¼ˆDFTï¼‰å’Œå±€éƒ¨çŸ­æ—¶å‚…é‡Œå¶å˜æ¢ï¼ˆSTFTï¼‰ç³»ç»Ÿåˆ†æä¿¡å·çš„è°±ç‰¹æ€§ï¼Œå‘ç°äººç±»å†™ä½œçš„æ–‡æœ¬åœ¨è°±èƒ½é‡ä¸Šæ˜¾è‘—é«˜äºLLMç”Ÿæˆæ–‡æœ¬ã€‚åŸºäºè¿™ä¸€å…³é”®æ´å¯Ÿï¼Œæˆ‘ä»¬æ„å»ºäº†SpecDetectï¼Œåˆ©ç”¨DFTæ€»èƒ½é‡è¿™ä¸€å•ä¸€ç‰¹å¾è¿›è¡Œæ£€æµ‹ï¼Œå¹¶æå‡ºäº†å¢å¼ºç‰ˆSpecDetect++ï¼Œé€šè¿‡é‡‡æ ·å·®å¼‚æœºåˆ¶è¿›ä¸€æ­¥æå‡é²æ£’æ€§ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨è¿è¡Œæ—¶é—´ä¸Šå‡ ä¹å‡å°‘äº†ä¸€åŠï¼Œä¸”æ€§èƒ½è¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMç”Ÿæˆæ–‡æœ¬çš„æ£€æµ‹é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºè¡¨é¢ç»Ÿè®¡ç‰¹å¾ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰æ–‡æœ¬ç”Ÿæˆè¿‡ç¨‹çš„æ·±å±‚ä¿¡å·ç‰¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬å°†æ–‡æœ¬æ£€æµ‹é‡æ–°å®šä¹‰ä¸ºä¿¡å·å¤„ç†é—®é¢˜ï¼Œé€šè¿‡åˆ†ææ ‡è®°å¯¹æ•°æ¦‚ç‡åºåˆ—çš„é¢‘åŸŸç‰¹æ€§ï¼Œå‘ç°äººç±»æ–‡æœ¬ä¸LLMç”Ÿæˆæ–‡æœ¬åœ¨è°±èƒ½é‡ä¸Šçš„æ˜¾è‘—å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€é¢‘åŸŸè½¬æ¢ï¼ˆDFTå’ŒSTFTï¼‰ã€è°±ç‰¹æ€§æå–å’Œåˆ†ç±»å†³ç­–ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ä¿¡å·åˆ†æå’Œç‰¹å¾æå–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåˆ©ç”¨DFTæ€»èƒ½é‡ä½œä¸ºå•ä¸€ç‰¹å¾è¿›è¡Œæ£€æµ‹ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿä¾èµ–å¤šç‰¹å¾çš„æ£€æµ‹æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†æ›´é«˜çš„æ•ˆç‡å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SpecDetect++ä¸­å¼•å…¥äº†é‡‡æ ·å·®å¼‚æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚å‚æ•°è®¾ç½®ç»è¿‡å¤šæ¬¡å®éªŒä¼˜åŒ–ï¼Œç¡®ä¿åœ¨ä¸åŒæ–‡æœ¬ç±»å‹ä¸Šå‡èƒ½ä¿æŒé«˜æ•ˆæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSpecDetectåœ¨æ£€æµ‹æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ï¼Œä¸”è¿è¡Œæ—¶é—´å‡å°‘è¿‘50%ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨ä¸åŒæ–‡æœ¬ç±»å‹ä¸Šçš„å‡†ç¡®ç‡å‡è¶…è¿‡äº†90%ï¼Œå±•ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç›‘æµ‹ã€å­¦æœ¯ä¸ç«¯æ£€æµ‹ä»¥åŠè‡ªåŠ¨åŒ–å†…å®¹å®¡æ ¸ç­‰ã€‚é€šè¿‡æä¾›é«˜æ•ˆçš„LLMç”Ÿæˆæ–‡æœ¬æ£€æµ‹å·¥å…·ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢è™šå‡ä¿¡æ¯ä¼ æ’­ï¼Œç»´æŠ¤ä¿¡æ¯çš„çœŸå®æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…æ„ä¹‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The proliferation of high-quality text from Large Language Models (LLMs) demands reliable and efficient detection methods. While existing training-free approaches show promise, they often rely on surface-level statistics and overlook fundamental signal properties of the text generation process. In this work, we reframe detection as a signal processing problem, introducing a novel paradigm that analyzes the sequence of token log-probabilities in the frequency domain. By systematically analyzing the signal's spectral properties using the global Discrete Fourier Transform (DFT) and the local Short-Time Fourier Transform (STFT), we find that human-written text consistently exhibits significantly higher spectral energy. This higher energy reflects the larger-amplitude fluctuations inherent in human writing compared to the suppressed dynamics of LLM-generated text. Based on this key insight, we construct SpecDetect, a detector built on a single, robust feature from the global DFT: DFT total energy. We also propose an enhanced version, SpecDetect++, which incorporates a sampling discrepancy mechanism to further boost robustness. Extensive experiments demonstrate that our approach outperforms the state-of-the-art model while running in nearly half the time. Our work introduces a new, efficient, and interpretable pathway for LLM-generated text detection, showing that classical signal processing techniques offer a surprisingly powerful solution to this modern challenge.

