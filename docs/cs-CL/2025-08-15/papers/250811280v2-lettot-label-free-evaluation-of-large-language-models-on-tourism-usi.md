---
layout: default
title: LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought
---

# LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11280" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11280v2</a>
  <a href="https://arxiv.org/pdf/2508.11280.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11280v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11280v2', 'LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruiyan Qi, Congding Wen, Weibo Zhou, Jiwei Li, Shangsong Liang, Lingbo Li

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15 (æ›´æ–°: 2025-08-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLETToTæ¡†æ¶ä»¥è§£å†³æ—…æ¸¸é¢†åŸŸLLMè¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—…æ¸¸é¢†åŸŸ` `æ ‡ç­¾è‡ªç”±è¯„ä¼°` `ä¸“å®¶æ¨ç†ç»“æ„` `æ¨¡å‹è¯„ä¼°` `è´¨é‡æå‡` `é¢†åŸŸç‰¹å®šè¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æ—…æ¸¸ï¼‰è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œé¢ä¸´é«˜æ˜‚çš„æ ‡æ³¨æˆæœ¬å’Œå¹»è§‰ç­‰é—®é¢˜ã€‚
2. æˆ‘ä»¬æå‡ºçš„LETToTæ¡†æ¶é€šè¿‡ä¸“å®¶æ¨ç†ç»“æ„è¿›è¡Œè¯„ä¼°ï¼Œé¿å…äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°æ€è·¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–åçš„ä¸“å®¶æ¨ç†åœ¨è´¨é‡ä¸Šç›¸è¾ƒäºåŸºçº¿æœ‰4.99%-14.15%çš„æå‡ï¼Œä¸”å°æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç‰¹å®šé¢†åŸŸï¼ˆå¦‚æ—…æ¸¸ï¼‰è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´ç€æ ‡æ³¨åŸºå‡†æˆæœ¬é«˜å’Œå¹»è§‰ç­‰é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†æ ‡ç­¾è‡ªç”±çš„æ—…æ¸¸é¢†åŸŸLLMè¯„ä¼°æ¡†æ¶LETToTï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä¸“å®¶æ¨ç†ç»“æ„è€Œéæ ‡æ³¨æ•°æ®æ¥è¯„ä¼°LLMsã€‚é€šè¿‡ä¸é€šç”¨è´¨é‡ç»´åº¦å’Œä¸“å®¶åé¦ˆå¯¹é½ï¼Œæˆ‘ä»¬è¿­ä»£ä¼˜åŒ–äº†å±‚æ¬¡åŒ–çš„æ¨ç†ç»„ä»¶ï¼Œç»“æœæ˜¾ç¤ºä¼˜åŒ–åçš„ä¸“å®¶æ¨ç†åœ¨åŸºå‡†æµ‹è¯•ä¸­ç›¸è¾ƒäºåŸºçº¿æœ‰4.99%-14.15%çš„ç›¸å¯¹è´¨é‡æå‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†LETToTåº”ç”¨äºä¸åŒè§„æ¨¡ï¼ˆ32B-671Bå‚æ•°ï¼‰çš„æ¨¡å‹è¯„ä¼°ï¼Œå‘ç°æ¨ç†å¢å¼ºçš„å°æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œç®€æ´æ€§ä¸Šä¼˜äºåŒç±»æ¨¡å‹ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºé¢†åŸŸç‰¹å®šçš„LLMè¯„ä¼°å»ºç«‹äº†å¯æ‰©å±•çš„æ ‡ç­¾è‡ªç”±èŒƒå¼ï¼Œæä¾›äº†å¯¹ä¼ ç»Ÿæ ‡æ³¨åŸºå‡†çš„æœ‰åŠ›æ›¿ä»£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨æ—…æ¸¸é¢†åŸŸè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œç¼ºä¹æ ‡æ³¨æ•°æ®å’Œé«˜æˆæœ¬çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºæ˜‚è´µçš„æ ‡æ³¨åŸºå‡†ï¼Œä¸”å­˜åœ¨æ¨¡å‹äº§ç”Ÿå¹»è§‰çš„é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºLETToTæ¡†æ¶ï¼Œé€šè¿‡ä¸“å®¶æ¨ç†ç»“æ„ä»£æ›¿æ ‡æ³¨æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸“å®¶åé¦ˆå’Œé€šç”¨è´¨é‡ç»´åº¦çš„å¯¹é½ï¼Œé€æ­¥ä¼˜åŒ–æ¨ç†ç»„ä»¶ï¼Œä»è€Œå®ç°æœ‰æ•ˆè¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLETToTçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œæ„å»ºå±‚æ¬¡åŒ–çš„æ¨ç†ç»“æ„ï¼›å…¶æ¬¡ï¼Œè¿›è¡Œè¿­ä»£ä¼˜åŒ–å’ŒéªŒè¯ï¼›æœ€åï¼Œåº”ç”¨ä¼˜åŒ–åçš„æ¨ç†ç»“æ„è¯„ä¼°ä¸åŒè§„æ¨¡çš„LLMsã€‚

**å…³é”®åˆ›æ–°**ï¼šLETToTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ ‡ç­¾è‡ªç”±çš„è¯„ä¼°æ–¹å¼ï¼Œåˆ©ç”¨ä¸“å®¶æ¨ç†ç»“æ„è€Œéä¼ ç»Ÿçš„æ ‡æ³¨æ•°æ®ï¼Œæ˜¾è‘—é™ä½äº†è¯„ä¼°æˆæœ¬å¹¶æé«˜äº†è¯„ä¼°çš„çµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å…³æ³¨äº†æ¨ç†ç»“æ„çš„å±‚æ¬¡åŒ–è®¾è®¡ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰é¢†åŸŸç‰¹å®šçš„çŸ¥è¯†ã€‚åŒæ—¶ï¼Œé€šè¿‡ä¸“å®¶åé¦ˆä¸æ–­è°ƒæ•´æ¨ç†ç»„ä»¶ï¼Œä»¥æå‡è¯„ä¼°çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–åçš„ä¸“å®¶æ¨ç†åœ¨è´¨é‡ä¸Šç›¸è¾ƒäºåŸºçº¿æœ‰4.99%-14.15%çš„æå‡ã€‚æ­¤å¤–ï¼Œå¯¹äºå°äº72Bå‚æ•°çš„æ¨¡å‹ï¼Œé‡‡ç”¨æ˜¾å¼æ¨ç†æ¶æ„çš„æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œç®€æ´æ€§ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œpå€¼å°äº0.05ï¼Œè¡¨æ˜ç»“æœçš„ç»Ÿè®¡æ˜¾è‘—æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LETToTæ¡†æ¶åœ¨æ—…æ¸¸é¢†åŸŸçš„æ½œåœ¨åº”ç”¨å¹¿æ³›ï¼Œå¯ä»¥ç”¨äºè¯„ä¼°æ—…æ¸¸ç›¸å…³çš„å¯¹è¯ç³»ç»Ÿã€æ¨èå¼•æ“å’Œä¿¡æ¯æ£€ç´¢æ¨¡å‹ç­‰ã€‚å…¶æ ‡ç­¾è‡ªç”±çš„ç‰¹æ€§ä½¿å¾—åœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œä»ç„¶èƒ½å¤Ÿè¿›è¡Œæœ‰æ•ˆçš„æ¨¡å‹è¯„ä¼°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Evaluating large language models (LLMs) in specific domain like tourism remains challenging due to the prohibitive cost of annotated benchmarks and persistent issues like hallucinations. We propose $\textbf{L}$able-Free $\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert $\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that leverages expert-derived reasoning structures-instead of labeled data-to access LLMs in tourism. First, we iteratively refine and validate hierarchical ToT components through alignment with generic quality dimensions and expert feedback. Results demonstrate the effectiveness of our systematically optimized expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we apply LETToT's optimized expert ToT to evaluate models of varying scales (32B-671B parameters), revealing: (1) Scaling laws persist in specialized domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g., DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit reasoning architectures outperform counterparts in accuracy and conciseness ($p<0.05$). Our work established a scalable, label-free paradigm for domain-specific LLM evaluation, offering a robust alternative to conventional annotated benchmarks.

