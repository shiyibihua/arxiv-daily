---
layout: default
title: A Multi-Task Evaluation of LLMs' Processing of Academic Text Input
---

# A Multi-Task Evaluation of LLMs' Processing of Academic Text Input

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11779" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11779v1</a>
  <a href="https://arxiv.org/pdf/2508.11779.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11779v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11779v1', 'A Multi-Task Evaluation of LLMs\' Processing of Academic Text Input')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyi Li, Yu Qin, Olivia R. Liu Sheng

**åˆ†ç±»**: cs.CL, econ.GN

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å­¦æœ¯æ–‡æœ¬å¤„ç†ä¸­çš„å¤šä»»åŠ¡èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å­¦æœ¯æ–‡æœ¬å¤„ç†` `åŒè¡Œè¯„å®¡` `å¤šä»»åŠ¡è¯„ä¼°` `ä¿¡æ¯ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¯¹LLMsåœ¨å­¦æœ¯æ–‡æœ¬å¤„ç†ä¸­çš„æœ‰æ•ˆæ€§å­˜åœ¨äº‰è®®ï¼Œå°¤å…¶æ˜¯åœ¨åŒè¡Œè¯„å®¡ä¸­çš„åº”ç”¨æ½œåŠ›å°šæœªå¾—åˆ°å……åˆ†éªŒè¯ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å°†è®¡ç®—æœºç§‘å­¦ç ”ç©¶ä»»åŠ¡æ•´åˆä¸ºå·¥ä½œæµç¨‹çš„æ–¹æ³•ï¼Œä»¥ç³»ç»Ÿæ€§è¯„ä¼°LLMsåœ¨å­¦æœ¯æ–‡æœ¬å¤„ç†ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡LLMsåœ¨æŸäº›ä»»åŠ¡ä¸Šè¡¨ç°å°šå¯ï¼Œä½†åœ¨æ–‡æœ¬è¯„åˆ†å’Œåæ€æ–¹é¢çš„èƒ½åŠ›æœ‰é™ï¼Œæ•´ä½“æ€§èƒ½ä¸ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç§‘å­¦å‘ç°ä¸­çš„ä½œç”¨ï¼Œå°¤å…¶æ˜¯åœ¨å­¦æœ¯åŒè¡Œè¯„å®¡ä¸­çš„è¾…åŠ©èƒ½åŠ›ï¼Œå­˜åœ¨æ¿€çƒˆçš„äº‰è®ºã€‚æœ¬æ–‡é€šè¿‡å°†è®¡ç®—æœºç§‘å­¦ç ”ç©¶ä¸­çš„ä¸ªåˆ«ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªæœ‰æŒ‡å¯¼æ€§çš„å·¥ä½œæµç¨‹ï¼Œè¯„ä¼°LLMså¯¹å­¦æœ¯æ–‡æœ¬è¾“å…¥çš„å¤„ç†èƒ½åŠ›ã€‚æˆ‘ä»¬è®¾è®¡äº†å››ä¸ªè¯„ä¼°ä»»åŠ¡ï¼Œåˆ†åˆ«è€ƒå¯ŸLLMsåœ¨å†…å®¹å†ç°ã€æ¯”è¾ƒã€è¯„åˆ†å’Œåæ€ä¸­çš„è¡¨ç°ã€‚é€šè¿‡å¯¹ä¸‰æœ¬é¡¶çº§æœŸåˆŠçš„é«˜è´¨é‡ä¿¡æ¯ç³»ç»Ÿæ–‡ç« è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºï¼Œè°·æ­Œçš„Geminiåœ¨å­¦æœ¯æ–‡æœ¬çš„æ€»ç»“å’Œæ”¹å†™æ–¹é¢è¡¨ç°å°šå¯ï¼Œä½†åœ¨æ–‡æœ¬æ’åå’Œè¯„åˆ†ä¸­å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œä¸”å…¶å¯¹æ–‡æœ¬çš„å®šæ€§åæ€ç¼ºä¹æ·±åº¦ã€‚æ•´ä½“ä¸Šï¼Œæˆ‘ä»¬ä¸å»ºè®®åœ¨åŒè¡Œè¯„å®¡ä¸­ä¸åŠ é™åˆ¶åœ°ä½¿ç”¨LLMsã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å­¦æœ¯æ–‡æœ¬æ—¶çš„èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯å…¶åœ¨åŒè¡Œè¯„å®¡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå¯¼è‡´å¯¹LLMsçš„èƒ½åŠ›å­˜åœ¨è¯¯è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†è®¡ç®—æœºç§‘å­¦ç ”ç©¶ä¸­çš„ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªæœ‰æŒ‡å¯¼æ€§çš„å·¥ä½œæµç¨‹ï¼Œæœ¬æ–‡ç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsåœ¨ä¸åŒå­¦æœ¯ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨å››ä¸ªè¯„ä¼°ä»»åŠ¡ï¼šå†…å®¹å†ç°ã€æ¯”è¾ƒã€è¯„åˆ†å’Œåæ€ï¼Œåˆ†åˆ«å¯¹åº”LLMsçš„ä¸åŒè§’è‰²ï¼ˆå¦‚çŸ¥è¯†ä»²è£è€…ã€åˆä½œä¼™ä¼´ç­‰ï¼‰ã€‚é€šè¿‡å¯¹ä¸‰æœ¬é¡¶çº§æœŸåˆŠçš„æ–‡ç« è¿›è¡Œè¾“å…¥ï¼Œç»“åˆå¤šç§æ–‡æœ¬æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°å°†å¤šç§å­¦æœ¯ä»»åŠ¡æ•´åˆä¸ºä¸€ä¸ªè¯„ä¼°æ¡†æ¶ï¼Œæä¾›äº†å¯¹LLMsèƒ½åŠ›çš„å…¨é¢åˆ†æï¼Œå°¤å…¶æ˜¯åœ¨å­¦æœ¯æ–‡æœ¬å¤„ç†ä¸­çš„åº”ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†é«˜è´¨é‡çš„å­¦æœ¯æ–‡ç« ä½œä¸ºè¾“å…¥æ–‡æœ¬ï¼Œå¹¶è®¾è®¡äº†è¯¦ç»†çš„æç¤ºä»¥æŒ‡å¯¼LLMsçš„ä»»åŠ¡æ‰§è¡Œã€‚è¯„ä¼°è¿‡ç¨‹ä¸­é‡‡ç”¨äº†å¤šç§æ–‡æœ¬åº¦é‡æ ‡å‡†ï¼ŒåŒ…æ‹¬è¯­è¨€è¯„ä¼°ã€ä¸çœŸå®æƒ…å†µçš„æ¯”è¾ƒä»¥åŠäººç±»è¯„ä¼°ï¼Œä»¥ç¡®ä¿ç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè°·æ­Œçš„Geminiåœ¨å­¦æœ¯æ–‡æœ¬çš„æ€»ç»“å’Œæ”¹å†™æ–¹é¢è¡¨ç°å°šå¯ï¼Œç„¶è€Œåœ¨æ–‡æœ¬æ’åçš„å¯æ‰©å±•æ€§å’Œè¯„åˆ†çš„åŒºåˆ†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚æ•´ä½“è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨å­¦æœ¯æ–‡æœ¬å¤„ç†ä¸­çš„èƒ½åŠ›å¹¶ä¸å¦‚é¢„æœŸï¼Œå°¤å…¶åœ¨å®šæ€§åæ€æ–¹é¢ç¼ºä¹æ·±åº¦å’Œå¯å‘æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å­¦æœ¯è¯„å®¡ã€ç§‘ç ”è¾…åŠ©å·¥å…·çš„å¼€å‘ä»¥åŠæ•™è‚²é¢†åŸŸçš„æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿã€‚é€šè¿‡å¯¹LLMsèƒ½åŠ›çš„æ·±å…¥è¯„ä¼°ï¼Œç ”ç©¶ä¸ºæœªæ¥åœ¨å­¦æœ¯ç•Œçš„åº”ç”¨æä¾›äº†é‡è¦å‚è€ƒï¼Œä¿ƒè¿›äº†å¯¹LLMsåœ¨ç§‘å­¦ç ”ç©¶ä¸­è§’è‰²çš„ç†è§£ä¸è§„èŒƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> How much large language models (LLMs) can aid scientific discovery, notably in assisting academic peer review, is in heated debate. Between a literature digest and a human-comparable research assistant lies their practical application potential. We organize individual tasks that computer science studies employ in separate terms into a guided and robust workflow to evaluate LLMs' processing of academic text input. We employ four tasks in the assessment: content reproduction/comparison/scoring/reflection, each demanding a specific role of the LLM (oracle/judgmental arbiter/knowledgeable arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs with questions that increasingly require intellectual capabilities towards a solid understanding of scientific texts to yield desirable solutions. We exemplify a rigorous performance evaluation with detailed instructions on the prompts. Adopting first-rate Information Systems articles at three top journals as the input texts and an abundant set of text metrics, we record a compromised performance of the leading LLM - Google's Gemini: its summary and paraphrase of academic text is acceptably reliable; using it to rank texts through pairwise text comparison is faintly scalable; asking it to grade academic texts is prone to poor discrimination; its qualitative reflection on the text is self-consistent yet hardly insightful to inspire meaningful research. This evidence against an endorsement of LLMs' text-processing capabilities is consistent across metric-based internal (linguistic assessment), external (comparing to the ground truth), and human evaluation, and is robust to the variations of the prompt. Overall, we do not recommend an unchecked use of LLMs in constructing peer reviews.

