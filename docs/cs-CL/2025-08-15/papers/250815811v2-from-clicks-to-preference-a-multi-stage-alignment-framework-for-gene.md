---
layout: default
title: From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System
---

# From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15811" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15811v2</a>
  <a href="https://arxiv.org/pdf/2508.15811.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15811v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15811v2', 'From Clicks to Preference: A Multi-stage Alignment Framework for Generative Query Suggestion in Conversational System')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junhao Yin, Haolin Wang, Peng Bao, Ju Xu, Yongliang Wang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15 (æ›´æ–°: 2025-12-15)

**å¤‡æ³¨**: Accepted by SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šé˜¶æ®µå¯¹é½æ¡†æ¶ä»¥è§£å†³ç”ŸæˆæŸ¥è¯¢å»ºè®®ä¸­çš„ç”¨æˆ·åå¥½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”ŸæˆæŸ¥è¯¢å»ºè®®` `ç”¨æˆ·åå¥½å¯¹é½` `é«˜æ–¯å¥–åŠ±æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `å¤šé˜¶æ®µæ¡†æ¶` `ç‚¹å‡»ç‡æå‡` `å¯¹è¯ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç”ŸæˆæŸ¥è¯¢å»ºè®®æ–¹æ³•åœ¨å¯¹é½ç”¨æˆ·åå¥½æ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå¯¼è‡´ç”Ÿæˆå†…å®¹ä¸ç”¨æˆ·æ„å›¾ä¸åŒ¹é…ã€‚
2. æœ¬æ–‡æå‡ºçš„å¤šé˜¶æ®µå¯¹é½æ¡†æ¶é€šè¿‡é€æ­¥å¯¹é½ç”Ÿæˆç­–ç•¥ä¸ç”¨æˆ·æ„å›¾ï¼Œåˆ©ç”¨é«˜æ–¯å¥–åŠ±æ¨¡å‹æ¥æ›´å¥½åœ°æ•æ‰ç”¨æˆ·åå¥½çš„ä¸ç¡®å®šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå¹¶åœ¨ç”¨æˆ·ç‚¹å‡»ç‡ä¸Šå®ç°äº†34%çš„ç›¸å¯¹æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”ŸæˆæŸ¥è¯¢å»ºè®®åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸ºå¯¹è¯ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„å¢å¼ºèƒ½åŠ›ï¼Œä½†å¦‚ä½•å°†è¾“å‡ºä¸ç»†å¾®çš„ç”¨æˆ·åå¥½å¯¹é½ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šé˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ç”Ÿæˆç­–ç•¥ä¸ç”¨æˆ·æ„å›¾ä¹‹é—´çš„é€æ­¥å¯¹é½ã€‚è¯¥æµç¨‹é¦–å…ˆé€šè¿‡æç¤ºå·¥ç¨‹ä½œä¸ºå†·å¯åŠ¨ç­–ç•¥ï¼Œç„¶ååœ¨ç›‘ç£å¾®è°ƒé˜¶æ®µå¼•å…¥ç‚¹å‡»æ—¥å¿—çš„è’¸é¦æ–¹æ³•ï¼Œä»¥åˆ›å»ºç¨³å¥çš„åŸºç¡€æ¨¡å‹ã€‚ä¸ºäº†æ›´å¥½åœ°å»ºæ¨¡ç”¨æˆ·åå¥½å¹¶æ•æ‰å…¶å›ºæœ‰çš„ä¸ç¡®å®šæ€§ï¼Œæœ¬æ–‡å¼€å‘äº†ä¸€ç§é«˜æ–¯å¥–åŠ±æ¨¡å‹ï¼ˆGaRMï¼‰ï¼Œå°†ç”¨æˆ·åå¥½è¡¨ç¤ºä¸ºæ¦‚ç‡åˆ†å¸ƒè€Œéç‚¹ä¼°è®¡ã€‚æœ€åï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ å°†ç”Ÿæˆç­–ç•¥ä¸è¿™äº›åå¥½å¯¹é½ï¼Œä½¿ç”¨å¤åˆå¥–åŠ±å‡½æ•°å°†GaRMä¸è¾…åŠ©å¯å‘å¼ç»“åˆï¼Œä»¥å‡è½»å¥–åŠ±é»‘å®¢è¡Œä¸ºã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨è‡ªåŠ¨å’Œäººå·¥è¯„ä¼°ä¸­æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œå¹¶åœ¨å®æ—¶A/Bæµ‹è¯•ä¸­å®ç°äº†34%çš„ç”¨æˆ·å‚ä¸åº¦ç›¸å¯¹æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”ŸæˆæŸ¥è¯¢å»ºè®®ä¸­ç”¨æˆ·åå¥½å¯¹é½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•æ‰ç”¨æˆ·çš„ç»†å¾®æ„å›¾å’Œåå¥½ï¼Œå¯¼è‡´ç”Ÿæˆå†…å®¹çš„ç›¸å…³æ€§å’Œç”¨æˆ·æ»¡æ„åº¦é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å¤šé˜¶æ®µå¯¹é½æ¡†æ¶é€šè¿‡é€æ­¥ä¼˜åŒ–ç”Ÿæˆç­–ç•¥ä¸ç”¨æˆ·æ„å›¾çš„å¯¹é½ï¼Œåˆ©ç”¨é«˜æ–¯å¥–åŠ±æ¨¡å‹ï¼ˆGaRMï¼‰å°†ç”¨æˆ·åå¥½å»ºæ¨¡ä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œä»è€Œæ›´å¥½åœ°åæ˜ ç”¨æˆ·çš„çœŸå®éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯æç¤ºå·¥ç¨‹ä½œä¸ºå†·å¯åŠ¨ç­–ç•¥ï¼Œå…¶æ¬¡æ˜¯ç›‘ç£å¾®è°ƒé˜¶æ®µï¼Œé€šè¿‡ç‚¹å‡»æ—¥å¿—çš„è’¸é¦æ–¹æ³•æ„å»ºåŸºç¡€æ¨¡å‹ï¼Œæœ€åæ˜¯é€šè¿‡å¼ºåŒ–å­¦ä¹ å¯¹ç”Ÿæˆç­–ç•¥è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥é«˜æ–¯å¥–åŠ±æ¨¡å‹ï¼ˆGaRMï¼‰ï¼Œå®ƒå°†ç”¨æˆ·åå¥½è¡¨ç¤ºä¸ºæ¦‚ç‡åˆ†å¸ƒï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œç»“åˆå¤åˆå¥–åŠ±å‡½æ•°å’Œè¾…åŠ©å¯å‘å¼è®¾è®¡ï¼Œæœ‰æ•ˆå‡è½»äº†å¥–åŠ±é»‘å®¢è¡Œä¸ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†æ–°çš„åˆ†å¸ƒå¤–æ­£åˆ™åŒ–æ–¹æ³•å’Œä¸¤é˜¶æ®µå¥–åŠ±èåˆæŠ€æœ¯ï¼Œä»¥ä¿æŒè®­ç»ƒçš„ç¨³å®šæ€§å’Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ¡†æ¶åœ¨è‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°ä¸­å‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼Œç”¨æˆ·ç‚¹å‡»ç‡åœ¨å®æ—¶A/Bæµ‹è¯•ä¸­å®ç°äº†34%çš„ç›¸å¯¹æå‡ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨æå‡ç”¨æˆ·å‚ä¸åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¢æœã€åœ¨çº¿æœç´¢å¼•æ“å’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£å’Œå¯¹é½ç”¨æˆ·åå¥½ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ï¼Œè¿›è€Œæ¨åŠ¨å•†ä¸šä»·å€¼çš„å¢é•¿ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯æ‰©å±•è‡³æ›´å¤šå¯¹è¯ç³»ç»Ÿå’Œäº¤äº’åœºæ™¯ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative query suggestion using large language models offers a powerful way to enhance conversational systems, but aligning outputs with nuanced user preferences remains a critical challenge. To address this, we introduce a multi-stage framework designed for progressive alignment between the generation policy and user intent. Our pipeline begins with prompt engineering as a cold-start strategy, followed by the Supervised Fine-Tuning stage, in which we introduce a distillation method on click logs to create a robust foundational model. To better model user preferences while capturing their inherent uncertainty, we develop a Gaussian Reward Model (GaRM) that represents user preferences as probability distributions rather than point estimates. Finally, we employ reinforcement learning to align the generation policy with these preferences, guided by a composite reward function that integrates GaRM with auxiliary heuristics to mitigate reward hacking. To maintain training stability, this process is enhanced by a novel out-of-distribution regularization method and a two-stage reward fusion technique. Extensive experiments demonstrate that our framework significantly outperforms baselines on both automatic and human evaluations and yields a 34\% relative increase in user engagement as measured by click-through rate in live A/B tests.

