---
layout: default
title: Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions
---

# Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11414v1</a>
  <a href="https://arxiv.org/pdf/2508.11414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11414v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11414v1', 'Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shangrui Nie, Florian Mai, David KaczÃ©r, Charles Welch, Zhixue Zhao, Lucie Flek

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15

**å¤‡æ³¨**: 7 pages 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡é—®å·è°ƒæŸ¥è°ƒæ•´å¤§å‹è¯­è¨€æ¨¡å‹çš„äººç±»ä»·å€¼è§‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººç±»ä»·å€¼è§‚` `ä»·å€¼é—®å·` `å¾®è°ƒ` `é“å¾·åˆ¤æ–­` `è¡Œä¸ºè°ƒæ•´` `ä¼¦ç†AI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»·å€¼è§‚æ—¶ï¼Œé€šå¸¸ä¾èµ–äºå¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„ä»·å€¼è°ƒæ•´ã€‚
2. æœ¬ç ”ç©¶æå‡ºé€šè¿‡è®­ç»ƒæ¨¡å‹å›ç­”ä»·å€¼é—®å·ï¼Œæ¥ç›´æ¥ä¿®æ”¹å…¶ä»·å€¼ä½“ç³»ï¼Œä»è€Œå®ç°ä¸‹æ¸¸è¡Œä¸ºçš„ä»·å€¼å¯¹é½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒåæ¨¡å‹åœ¨é¢†åŸŸå†…é—®å·é—®é¢˜çš„å›ç­”å‘ç”Ÿæ˜¾è‘—å˜åŒ–ï¼Œå¹¶åœ¨æ–‡æœ¬å†’é™©æ¸¸æˆä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„è¡Œä¸ºè°ƒæ•´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹éšå«åœ°ç¼–ç äº†å¯¹äººç±»ä»·å€¼è§‚çš„åå¥½ï¼Œä½†å¼•å¯¼å®ƒä»¬é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä¸€ç§ç®€å•çš„æ–¹æ³•ï¼šé€šè¿‡è®­ç»ƒæ¨¡å‹å›ç­”ä»·å€¼é—®å·ï¼Œæ˜¯å¦å¯ä»¥å¯é åœ°ä¿®æ”¹å…¶åœ¨ä¸‹æ¸¸è¡Œä¸ºä¸­çš„ä»·å€¼ä½“ç³»ã€‚æˆ‘ä»¬é¦–å…ˆæ„å»ºäº†å¤šä¸ªå¼€æºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»·å€¼æ¡£æ¡ˆï¼Œè¦æ±‚å®ƒä»¬å¯¹æ¶µç›–20ç§ä¸åŒäººç±»ä»·å€¼è§‚çš„æè¿°è¿›è¡Œè¯„åˆ†ï¼Œä½œä¸ºåç»­å®éªŒçš„åŸºçº¿ã€‚ç„¶åï¼Œæˆ‘ä»¬ç ”ç©¶äº†é€šè¿‡å¯¹ä»·å€¼é—®å·è¿›è¡Œå¾®è°ƒï¼Œæ¨¡å‹çš„ä»·å€¼ä½“ç³»æ˜¯å¦å¯ä»¥è¢«æ§åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡ä¸¤ç§æ–¹å¼è¯„ä¼°å¾®è°ƒå¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ï¼Œé¦–å…ˆè¯„ä¼°åœ¨é¢†åŸŸå†…çš„ä¿ç•™é—®å·é—®é¢˜ä¸Šçš„ç­”æ¡ˆå˜åŒ–ï¼Œå…¶æ¬¡è¯„ä¼°æ¨¡å‹åœ¨é¢†åŸŸå¤–æƒ…å¢ƒä¸­çš„è¡Œä¸ºå˜åŒ–ã€‚æˆ‘ä»¬æ„å»ºäº†åŸºäºRedditå¸–å­çš„äººé™…é“å¾·åˆ¤æ–­æ•°æ®é›†ï¼Œå¹¶è¯„ä¼°æ¨¡å‹åœ¨æ–‡æœ¬å†’é™©æ¸¸æˆä¸­çš„è¡Œä¸ºå˜åŒ–ã€‚ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä¸ä»…èƒ½æ”¹å˜æ¨¡å‹å¯¹é¢†åŸŸå†…é—®å·é—®é¢˜çš„å›ç­”ï¼Œè¿˜èƒ½åœ¨éšå«çš„ä¸‹æ¸¸ä»»åŠ¡è¡Œä¸ºä¸­äº§ç”Ÿæ˜¾è‘—çš„ä»·å€¼å¯¹é½å˜åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¦‚ä½•æœ‰æ•ˆå¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»·å€¼è§‚ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡è®­ç»ƒæ•°æ®ï¼Œéš¾ä»¥å®ç°çµæ´»çš„ä»·å€¼è°ƒæ•´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡è®­ç»ƒæ¨¡å‹å›ç­”ä»·å€¼é—®å·ï¼Œç›´æ¥å½±å“å…¶ä»·å€¼ä½“ç³»ï¼Œä»è€Œå®ç°ä¸‹æ¸¸è¡Œä¸ºçš„è°ƒæ•´ã€‚è¿™ç§æ–¹æ³•ç®€å•ä¸”æ˜“äºå®æ–½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ„å»ºä»·å€¼æ¡£æ¡ˆã€å¾®è°ƒæ¨¡å‹ä»¥åŠè¯„ä¼°æ¨¡å‹è¡Œä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œé€šè¿‡é—®å·æ”¶é›†æ¨¡å‹å¯¹ä¸åŒä»·å€¼è§‚çš„è¯„åˆ†ï¼›ç„¶åï¼ŒåŸºäºè¿™äº›è¯„åˆ†å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼›æœ€åï¼Œé€šè¿‡å¯¹æ¯”åˆ†æè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæƒ…å¢ƒä¸‹çš„è¡Œä¸ºå˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡ç®€å•çš„é—®å·å¾®è°ƒå®ç°äº†å¯¹æ¨¡å‹ä»·å€¼è§‚çš„æœ‰æ•ˆè°ƒæ•´ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹å¤§è§„æ¨¡è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹å¯¹é—®å·é—®é¢˜çš„å›ç­”ï¼ŒåŒæ—¶è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡å¾®è°ƒåï¼Œæ¨¡å‹åœ¨é¢†åŸŸå†…é—®å·é—®é¢˜çš„å›ç­”å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼Œä¸”åœ¨æ–‡æœ¬å†’é™©æ¸¸æˆä¸­çš„è¡Œä¸ºè¡¨ç°å‡ºæ˜æ˜¾çš„ä»·å€¼å¯¹é½å˜åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨é“å¾·åˆ¤æ–­ä»»åŠ¡ä¸­çš„è¡¨ç°æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººæœºäº¤äº’ã€é“å¾·å†³ç­–æ”¯æŒç³»ç»Ÿä»¥åŠç¤¾ä¼šæœºå™¨äººç­‰ã€‚é€šè¿‡è°ƒæ•´å¤§å‹è¯­è¨€æ¨¡å‹çš„ä»·å€¼è§‚ï¼Œå¯ä»¥ä½¿å…¶åœ¨ç‰¹å®šæƒ…å¢ƒä¸‹æ›´å¥½åœ°åæ˜ äººç±»çš„é“å¾·æ ‡å‡†ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¿™ä¸€æ–¹æ³•å¯èƒ½åœ¨ä¼¦ç†AIçš„å¼€å‘ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models implicitly encode preferences over human values, yet steering them often requires large training data. In this work, we investigate a simple approach: Can we reliably modify a model's value system in downstream behavior by training it to answer value survey questions accordingly? We first construct value profiles of several open-source LLMs by asking them to rate a series of value-related descriptions spanning 20 distinct human values, which we use as a baseline for subsequent experiments. We then investigate whether the value system of a model can be governed by fine-tuning on the value surveys. We evaluate the effect of finetuning on the model's behavior in two ways; first, we assess how answers change on in-domain, held-out survey questions. Second, we evaluate whether the model's behavior changes in out-of-domain settings (situational scenarios). To this end, we construct a contextualized moral judgment dataset based on Reddit posts and evaluate changes in the model's behavior in text-based adventure games. We demonstrate that our simple approach can not only change the model's answers to in-domain survey questions, but also produces substantial shifts (value alignment) in implicit downstream task behavior.

