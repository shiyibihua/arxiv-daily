---
layout: default
title: ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection
---

# ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11281" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11281v1</a>
  <a href="https://arxiv.org/pdf/2508.11281.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11281v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11281v1', 'ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Axel Delaval, Shujian Yang, Haicheng Wang, Han Qiu, Jialiang Lu

**åˆ†ç±»**: cs.CL, cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15

**å¤‡æ³¨**: 14 pages, 5 figures, 8 tables. This paper introduces TOXIFRENCH, a new large-scale benchmark for French toxicity detection, and proposes a Chain-of-Thought (CoT) fine-tuning method with a dynamic weighted loss. The resulting fine-tuned 4B parameter model, ToxiFrench, achieves state-of-the-art performance, outperforming larger models like GPT-4o

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºToxiFrenchä»¥è§£å†³æ³•è¯­æ¯’æ€§æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ³•è¯­æ¯’æ€§æ£€æµ‹` `é“¾å¼æ€ç»´å¾®è°ƒ` `åŠ¨æ€åŠ æƒæŸå¤±` `å°å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é›†æ„å»º` `å¤šè¯­è¨€èƒ½åŠ›` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ³•è¯­æ¯’æ€§æ£€æµ‹çš„ç°æœ‰æ–¹æ³•è¿›å±•ç¼“æ…¢ï¼Œç¼ºä¹ç›¸å…³çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸è¶³ã€‚
2. æå‡ºTOXIFRENCHåŸºå‡†æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨é“¾å¼æ€ç»´å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡åŠ¨æ€åŠ æƒæŸå¤±æå‡æ¨¡å‹å†³ç­–çš„å¯ä¿¡åº¦ã€‚
3. å¾®è°ƒåçš„4Bæ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šæé«˜äº†13%ï¼Œè¶…è¶Šäº†å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå±•ç¤ºäº†å¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä½¿ç”¨è¯­è¨€æ¨¡å‹æ£€æµ‹æœ‰æ¯’å†…å®¹è‡³å…³é‡è¦ï¼Œä½†åœ¨æ³•è¯­é¢†åŸŸä»é¢ä¸´æŒ‘æˆ˜ï¼Œä¸»è¦ç”±äºç¼ºä¹æ–‡åŒ–ç›¸å…³çš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚æœ¬æ–‡ä»‹ç»äº†TOXIFRENCHï¼Œä¸€ä¸ªåŒ…å«53,622æ¡æ³•è¯­åœ¨çº¿è¯„è®ºçš„æ–°å…¬å…±åŸºå‡†ï¼Œé‡‡ç”¨åŠè‡ªåŠ¨æ³¨é‡Šæµç¨‹ï¼Œå‡å°‘äº†äººå·¥æ ‡æ³¨çš„å·¥ä½œé‡ã€‚ç ”ç©¶å‘ç°ï¼Œå°å‹è¯­è¨€æ¨¡å‹åœ¨æ¯’æ€§æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åŸºäºæ­¤ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„é“¾å¼æ€ç»´ï¼ˆCoTï¼‰å¾®è°ƒç­–ç•¥ï¼Œé€šè¿‡åŠ¨æ€åŠ æƒæŸå¤±æ˜¾è‘—æé«˜æ¨¡å‹çš„å†³ç­–å¯ä¿¡åº¦ã€‚ç»è¿‡å¾®è°ƒçš„4Bæ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šæ¯”åŸºçº¿æé«˜äº†13%ï¼Œå¹¶è¶…è¶Šäº†GPT-40å’ŒGemini-2.5ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿›ä¸€æ­¥çš„è·¨è¯­è¨€è¯„ä¼°æ˜¾ç¤ºå‡ºå¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ï¼Œè¡¨æ˜è¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆæ‰©å±•åˆ°å…¶ä»–è¯­è¨€å’Œå®‰å…¨å…³é”®çš„åˆ†ç±»ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ³•è¯­æ¯’æ€§æ£€æµ‹ä¸­çš„æ•°æ®ç¨€ç¼ºå’Œæ¨¡å‹æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ³•è¯­é¢†åŸŸçš„åº”ç”¨å—é™ï¼Œç¼ºä¹æœ‰æ•ˆçš„æ ‡æ³¨æ•°æ®å’Œæ¨¡å‹è¯„ä¼°æ ‡å‡†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºTOXIFRENCHæ•°æ®é›†ï¼Œç»“åˆåŠè‡ªåŠ¨æ³¨é‡Šæµç¨‹ï¼Œå‡å°‘äººå·¥æ ‡æ³¨å·¥ä½œï¼ŒåŒæ—¶æå‡ºé“¾å¼æ€ç»´å¾®è°ƒç­–ç•¥ï¼Œä»¥åŠ¨æ€åŠ æƒæŸå¤±æå‡æ¨¡å‹çš„å†³ç­–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹åŸºå‡†æµ‹è¯•å’Œå¾®è°ƒã€‚æ•°æ®é›†é€šè¿‡é«˜ç½®ä¿¡åº¦çš„LLMé¢„æ³¨é‡Šå’Œäººå·¥éªŒè¯æ„å»ºï¼Œæ¨¡å‹åˆ™åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè¯„ä¼°å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºçš„é“¾å¼æ€ç»´å¾®è°ƒç­–ç•¥æ˜¯æœ¬ç ”ç©¶çš„æ ¸å¿ƒåˆ›æ–°ï¼Œä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ä¸åŒï¼Œå®ƒé€šè¿‡åŠ¨æ€åŠ æƒæŸå¤±å¼ºè°ƒæ¨¡å‹æœ€ç»ˆå†³ç­–çš„å¯ä¿¡åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨åŠ¨æ€åŠ æƒæŸå¤±å‡½æ•°ï¼Œé‡ç‚¹å…³æ³¨æ¨¡å‹çš„æœ€ç»ˆè¾“å‡ºã€‚æ­¤å¤–ï¼Œæ¨¡å‹ç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”æ¯’æ€§æ£€æµ‹ä»»åŠ¡çš„ç‰¹å®šéœ€æ±‚ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒåçš„4Bæ¨¡å‹åœ¨F1åˆ†æ•°ä¸Šæ¯”åŸºçº¿æé«˜äº†13%ï¼Œå¹¶åœ¨æ¯’æ€§æ£€æµ‹ä»»åŠ¡ä¸­è¶…è¶Šäº†GPT-40å’ŒGemini-2.5ç­‰å¤§å‹è¯­è¨€æ¨¡å‹ã€‚è¿™ä¸€å‘ç°æŒ‘æˆ˜äº†ä¼ ç»Ÿå¯¹å¤§å‹æ¨¡å‹æ€§èƒ½çš„é¢„æœŸï¼Œè¡¨æ˜å°å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç›‘æ§ã€åœ¨çº¿è¯„è®ºå®¡æ ¸å’Œè‡ªåŠ¨åŒ–å†…å®¹è¿‡æ»¤ç­‰ã€‚é€šè¿‡æå‡æ³•è¯­æ¯’æ€§æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æœ‰å®³å†…å®¹çš„ä¼ æ’­ï¼Œå¢å¼ºç½‘ç»œç¯å¢ƒçš„å®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•çš„å¤šè¯­è¨€èƒ½åŠ›ä½¿å…¶åœ¨å…¨çƒèŒƒå›´å†…çš„åº”ç”¨å‰æ™¯å¹¿é˜”ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Detecting toxic content using language models is crucial yet challenging. While substantial progress has been made in English, toxicity detection in French remains underdeveloped, primarily due to the lack of culturally relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new public benchmark of 53,622 French online comments, constructed via a semi-automated annotation pipeline that reduces manual labeling to only 10% through high-confidence LLM-based pre-annotation and human verification. Then, we benchmark a broad range of models and uncover a counterintuitive insight: Small Language Models (SLMs) outperform many larger models in robustness and generalization under the toxicity detection task. Motivated by this finding, we propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic weighted loss that progressively emphasizes the model's final decision, significantly improving faithfulness. Our fine-tuned 4B model achieves state-of-the-art performance, improving its F1 score by 13% over its baseline and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a cross-lingual toxicity benchmark demonstrates strong multilingual ability, suggesting that our methodology can be effectively extended to other languages and safety-critical classification tasks.

