---
layout: default
title: CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity
---

# CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11442" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11442v2</a>
  <a href="https://arxiv.org/pdf/2508.11442.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11442v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11442v2', 'CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bowen Zhang, Zixin Song, Chunquan Chen, Qian-Wen Zhang, Di Yin, Xing Sun

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCoDiEmbä»¥è§£å†³ä¿¡æ¯æ£€ç´¢ä¸è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§è”åˆå­¦ä¹ ä¸­çš„è´Ÿè¿ç§»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä¿¡æ¯æ£€ç´¢` `è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§` `è”åˆå­¦ä¹ ` `æ–‡æœ¬åµŒå…¥` `è´Ÿè¿ç§»` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¿¡æ¯æ£€ç´¢ä¸è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§è”åˆè®­ç»ƒä¸­å­˜åœ¨è´Ÿè¿ç§»é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½æŠ˜è¡·ã€‚
2. CoDiEmbæ¡†æ¶é€šè¿‡è§£è€¦ä»»åŠ¡ç‰¹å®šä¿¡å·ï¼Œé‡‡ç”¨åŠ¨æ€é‡‡æ ·å’Œä»»åŠ¡ä¸“ç”¨ç›®æ ‡å®ç°æœ‰æ•ˆè”åˆä¼˜åŒ–ã€‚
3. åœ¨15ä¸ªæ ‡å‡†åŸºå‡†ä¸Šè¿›è¡Œçš„å®éªŒéªŒè¯äº†CoDiEmbçš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—æå‡äº†åµŒå…¥ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è¡¨ç¤ºå­¦ä¹ ä¸­ï¼Œå­¦ä¹ èƒ½å¤Ÿåœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚çš„ç»Ÿä¸€æ–‡æœ¬åµŒå…¥æ˜¯ä¸€ä¸ªæ ¸å¿ƒç›®æ ‡ï¼Œä½†è´Ÿè¿ç§»ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„éšœç¢ã€‚ç‰¹åˆ«æ˜¯åœ¨ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰å’Œè¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ï¼ˆSTSï¼‰è¿™ä¸¤é¡¹åŸºæœ¬ä½†æœ¬è´¨ä¸Šä¸åŒçš„ä»»åŠ¡ä¸­ï¼Œè”åˆè®­ç»ƒå•ä¸€ç¼–ç å™¨é€šå¸¸ä¼šå¯¼è‡´æ€§èƒ½çš„æ˜¾è‘—æŠ˜è¡·ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å†²çªï¼Œæœ¬æ–‡æå‡ºäº†CoDiEmbæ¡†æ¶ï¼Œé€šè¿‡ç³»ç»Ÿæ€§åœ°è§£è€¦ä»»åŠ¡ç‰¹å®šçš„å­¦ä¹ ä¿¡å·ï¼Œæ•´åˆäº†ä¸‰é¡¹å…³é”®åˆ›æ–°ä»¥å®ç°æœ‰æ•ˆçš„è”åˆä¼˜åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶ä¸ä»…å‡è½»äº†è·¨ä»»åŠ¡çš„æŠ˜è¡·ï¼Œè¿˜æ˜¾è‘—æ”¹å–„äº†åµŒå…¥ç©ºé—´çš„å‡ ä½•ç‰¹æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¿¡æ¯æ£€ç´¢ï¼ˆIRï¼‰å’Œè¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ï¼ˆSTSï¼‰ä»»åŠ¡è”åˆè®­ç»ƒä¸­çš„è´Ÿè¿ç§»é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸¤é¡¹ä»»åŠ¡ä¸Šå¾€å¾€è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´æ€§èƒ½æŠ˜è¡·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCoDiEmbæ¡†æ¶é€šè¿‡ç³»ç»Ÿæ€§åœ°è§£è€¦ä»»åŠ¡ç‰¹å®šçš„å­¦ä¹ ä¿¡å·ï¼Œé‡‡ç”¨åŠ¨æ€é‡‡æ ·å’Œä»»åŠ¡ä¸“ç”¨ç›®æ ‡ï¼Œæ—¨åœ¨æœ‰æ•ˆåœ°è”åˆä¼˜åŒ–è¿™ä¸¤é¡¹ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCoDiEmbæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä»»åŠ¡ä¸“ç”¨ç›®æ ‡ä¸åŠ¨æ€é‡‡æ ·å™¨ã€åŸºäºåå·®çš„æ¨¡å‹èåˆç­–ç•¥ï¼Œä»¥åŠé«˜æ•ˆçš„å•é˜¶æ®µè®­ç»ƒç®¡é“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ¡†æ¶çš„åˆ›æ–°ç‚¹åœ¨äºé‡‡ç”¨ä»»åŠ¡ä¸“ç”¨ç›®æ ‡å’ŒåŠ¨æ€é‡‡æ ·ï¼Œé˜²æ­¢æ¢¯åº¦å¹²æ‰°ï¼›é€šè¿‡åˆ†æå‚æ•°åå·®å®ç°ç»†ç²’åº¦çš„æ¨¡å‹èåˆï¼›ä»¥åŠè®¾è®¡ç®€å•ä¸”ç¨³å®šæ”¶æ•›çš„å•é˜¶æ®µè®­ç»ƒæµç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼ŒIRä»»åŠ¡ä½¿ç”¨å¤šæ­£æ ·æœ¬å’Œéš¾è´Ÿæ ·æœ¬çš„å¯¹æ¯”æŸå¤±ï¼ŒSTSä»»åŠ¡åˆ™é‡‡ç”¨é¡ºåºæ„ŸçŸ¥ç›®æ ‡ï¼›æ¨¡å‹èåˆç­–ç•¥é€šè¿‡è®¡ç®—æ¯ä¸ªå‚æ•°çš„åå·®æ¥ç¡®å®šåˆå¹¶æƒé‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨15ä¸ªæ ‡å‡†åŸºå‡†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCoDiEmbæ¡†æ¶æ˜¾è‘—æ”¹å–„äº†ä¿¡æ¯æ£€ç´¢å’Œè¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ä»»åŠ¡çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼ŒåµŒå…¥ç©ºé—´çš„å‡ ä½•ç‰¹æ€§å¾—åˆ°äº†æ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CoDiEmbæ¡†æ¶åœ¨ä¿¡æ¯æ£€ç´¢å’Œè¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶æœ‰æ•ˆçš„è”åˆå­¦ä¹ æ–¹æ³•èƒ½å¤Ÿæé«˜æ–‡æœ¬åµŒå…¥çš„è´¨é‡ï¼Œè¿›è€Œæå‡æœç´¢å¼•æ“ã€æ¨èç³»ç»Ÿå’Œå¯¹è¯ç³»ç»Ÿç­‰åº”ç”¨çš„æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning unified text embeddings that excel across diverse downstream tasks is a central goal in representation learning, yet negative transfer remains a persistent obstacle. This challenge is particularly pronounced when jointly training a single encoder for Information Retrieval (IR) and Semantic Textual Similarity (STS), two essential but fundamentally disparate tasks for which naive co-training typically yields steep performance trade-offs. We argue that resolving this conflict requires systematically decoupling task-specific learning signals throughout the training pipeline. To this end, we introduce CoDiEmb, a unified framework that reconciles the divergent requirements of IR and STS in a collaborative yet distinct manner. CoDiEmb integrates three key innovations for effective joint optimization: (1) Task-specialized objectives paired with a dynamic sampler that forms single-task batches and balances per-task updates, thereby preventing gradient interference. For IR, we employ a contrastive loss with multiple positives and hard negatives, augmented by cross-device sampling. For STS, we adopt order-aware objectives that directly optimize correlation and ranking consistency. (2) A delta-guided model fusion strategy that computes fine-grained merging weights for checkpoints by analyzing each parameter's deviation from its pre-trained initialization, proving more effective than traditional Model Soups. (3) An efficient, single-stage training pipeline that is simple to implement and converges stably. Extensive experiments on 15 standard IR and STS benchmarks across three base encoders validate CoDiEmb. Our results and analysis demonstrate that the framework not only mitigates cross-task trade-offs but also measurably improves the geometric properties of the embedding space.

