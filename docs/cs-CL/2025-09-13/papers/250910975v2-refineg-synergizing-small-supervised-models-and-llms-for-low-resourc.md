---
layout: default
title: ReFineG: Synergizing Small Supervised Models and LLMs for Low-Resource Grounded Multimodal NER
---

# ReFineG: Synergizing Small Supervised Models and LLMs for Low-Resource Grounded Multimodal NER

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10975" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10975v2</a>
  <a href="https://arxiv.org/pdf/2509.10975.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10975v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10975v2', 'ReFineG: Synergizing Small Supervised Models and LLMs for Low-Resource Grounded Multimodal NER')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jielong Tang, Shuang Wang, Zhenxing Wang, Jianxing Yu, Jian Yin

**åˆ†ç±»**: cs.IR, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-13 (æ›´æ–°: 2025-11-12)

**å¤‡æ³¨**: CCKS 2025 Shared Task Paper

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ReFineGï¼šç»“åˆå°ç›‘ç£æ¨¡å‹ä¸LLMï¼Œè§£å†³ä½èµ„æºGMNERé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `GMNER` `å¤šæ¨¡æ€å‘½åå®ä½“è¯†åˆ«` `ä½èµ„æºå­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è¿ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰GMNERæ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œåœ¨ä½èµ„æºåœºæ™¯ä¸‹æ€§èƒ½å—é™ï¼ŒMLLMè™½æœ‰æ³›åŒ–èƒ½åŠ›ï¼Œä½†å­˜åœ¨é¢†åŸŸçŸ¥è¯†å†²çªã€‚
2. ReFineGé€šè¿‡ä¸‰é˜¶æ®µæ¡†æ¶ï¼Œç»“åˆå°ç›‘ç£æ¨¡å‹å’Œå†»ç»“çš„MLLMï¼Œåˆ©ç”¨æ•°æ®åˆæˆã€ä¸ç¡®å®šæ€§é€‰æ‹©å’Œä¸Šä¸‹æ–‡é€‰æ‹©æå‡æ€§èƒ½ã€‚
3. åœ¨CCKS2025 GMNERå…±äº«ä»»åŠ¡ä¸­ï¼ŒReFineGå–å¾—äº†ç¬¬äºŒåçš„æˆç»©ï¼ŒéªŒè¯äº†å…¶åœ¨ä½èµ„æºåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Grounded Multimodal Named Entity Recognition (GMNER) é€šè¿‡è”åˆæ£€æµ‹æ–‡æœ¬æåŠå¹¶åœ¨è§†è§‰åŒºåŸŸä¸­è¿›è¡Œå®šä½ï¼Œæ‰©å±•äº†ä¼ ç»Ÿçš„ NERã€‚ç°æœ‰çš„ç›‘ç£æ–¹æ³•è™½ç„¶æ€§èƒ½å¼ºå¤§ï¼Œä½†ä¾èµ–äºæ˜‚è´µçš„å¤šæ¨¡æ€æ ‡æ³¨ï¼Œå¹¶ä¸”åœ¨ä½èµ„æºé¢†åŸŸè¡¨ç°ä¸ä½³ã€‚å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ (MLLM) æ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†å­˜åœ¨é¢†åŸŸçŸ¥è¯†å†²çªï¼Œä¼šä¸ºç‰¹å®šé¢†åŸŸçš„å®ä½“ç”Ÿæˆå†—ä½™æˆ–ä¸æ­£ç¡®çš„æåŠã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† ReFineGï¼Œè¿™æ˜¯ä¸€ä¸ªä¸‰é˜¶æ®µçš„åä½œæ¡†æ¶ï¼Œå®ƒé›†æˆäº†å°å‹ç›‘ç£æ¨¡å‹å’Œå†»ç»“çš„ MLLMï¼Œç”¨äºä½èµ„æº GMNERã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œä¸€ç§é¢†åŸŸæ„ŸçŸ¥çš„ NER æ•°æ®åˆæˆç­–ç•¥å°† LLM çŸ¥è¯†è½¬ç§»åˆ°å…·æœ‰ç›‘ç£è®­ç»ƒçš„å°å‹æ¨¡å‹ï¼ŒåŒæ—¶é¿å…é¢†åŸŸçŸ¥è¯†å†²çªã€‚åœ¨ç»†åŒ–é˜¶æ®µï¼Œä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„æœºåˆ¶ä¿ç•™æ¥è‡ªç›‘ç£æ¨¡å‹çš„ç½®ä¿¡é¢„æµ‹ï¼Œå¹¶å°†ä¸ç¡®å®šçš„é¢„æµ‹å§”æ‰˜ç»™ MLLMã€‚åœ¨å®šä½é˜¶æ®µï¼Œä¸€ç§å¤šæ¨¡æ€ä¸Šä¸‹æ–‡é€‰æ‹©ç®—æ³•é€šè¿‡ç±»æ¯”æ¨ç†å¢å¼ºè§†è§‰å®šä½ã€‚åœ¨ CCKS2025 GMNER å…±äº«ä»»åŠ¡ä¸­ï¼ŒReFineG åœ¨åœ¨çº¿æ’è¡Œæ¦œä¸Šæ’åç¬¬äºŒï¼ŒF1 å¾—åˆ†ä¸º 0.6461ï¼Œè¯æ˜äº†å…¶åœ¨æœ‰é™æ ‡æ³¨ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä½èµ„æºåœºæ™¯ä¸‹çš„Grounded Multimodal Named Entity Recognition (GMNER)é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®è¿›è¡Œç›‘ç£å­¦ä¹ ï¼Œä½†åœ¨æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚åŒæ—¶ï¼Œç›´æ¥ä½¿ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)è¿›è¡ŒGMNERä»»åŠ¡ï¼Œå®¹æ˜“å—åˆ°é¢†åŸŸçŸ¥è¯†å†²çªçš„å½±å“ï¼Œäº§ç”Ÿä¸å‡†ç¡®æˆ–å†—ä½™çš„å®ä½“æåŠã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå°è§„æ¨¡ç›‘ç£æ¨¡å‹å’Œå†»ç»“çš„MLLMçš„ä¼˜åŠ¿ï¼Œåˆ©ç”¨å°è§„æ¨¡ç›‘ç£æ¨¡å‹å­¦ä¹ é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå¹¶åˆ©ç”¨MLLMçš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡ä¸€ä¸ªä¸‰é˜¶æ®µçš„æ¡†æ¶ï¼Œå®ç°çŸ¥è¯†çš„æœ‰æ•ˆè¿ç§»å’Œèåˆï¼Œä»è€Œåœ¨ä½èµ„æºåœºæ™¯ä¸‹æå‡GMNERçš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é¿å…ç›´æ¥å¾®è°ƒMLLMå¸¦æ¥çš„é«˜æˆæœ¬å’Œæ½œåœ¨çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReFineGæ¡†æ¶åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šè®­ç»ƒé˜¶æ®µã€ç»†åŒ–é˜¶æ®µå’Œå®šä½é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨é¢†åŸŸæ„ŸçŸ¥çš„NERæ•°æ®åˆæˆç­–ç•¥ï¼Œå°†LLMçš„çŸ¥è¯†è¿ç§»åˆ°å°è§„æ¨¡ç›‘ç£æ¨¡å‹ä¸­ã€‚åœ¨ç»†åŒ–é˜¶æ®µï¼ŒåŸºäºä¸ç¡®å®šæ€§çš„æœºåˆ¶ï¼Œé€‰æ‹©æ€§åœ°ä½¿ç”¨ç›‘ç£æ¨¡å‹å’ŒMLLMçš„é¢„æµ‹ç»“æœã€‚ç›‘ç£æ¨¡å‹ç½®ä¿¡åº¦é«˜çš„é¢„æµ‹è¢«ä¿ç•™ï¼Œè€Œç½®ä¿¡åº¦ä½çš„é¢„æµ‹åˆ™å§”æ‰˜ç»™MLLMã€‚åœ¨å®šä½é˜¶æ®µï¼Œä½¿ç”¨å¤šæ¨¡æ€ä¸Šä¸‹æ–‡é€‰æ‹©ç®—æ³•ï¼Œé€šè¿‡ç±»æ¯”æ¨ç†å¢å¼ºè§†è§‰å®šä½çš„å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ååŒåˆ©ç”¨å°è§„æ¨¡ç›‘ç£æ¨¡å‹å’Œå†»ç»“MLLMçš„æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ä½èµ„æºGMNERé—®é¢˜ã€‚ä¸ç›´æ¥å¾®è°ƒMLLMæˆ–å®Œå…¨ä¾èµ–ç›‘ç£æ¨¡å‹çš„æ–¹æ³•ç›¸æ¯”ï¼ŒReFineGèƒ½å¤Ÿæ›´å¥½åœ°å¹³è¡¡é¢†åŸŸçŸ¥è¯†å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒåŸºäºä¸ç¡®å®šæ€§çš„é€‰æ‹©æœºåˆ¶å’Œå¤šæ¨¡æ€ä¸Šä¸‹æ–‡é€‰æ‹©ç®—æ³•ä¹Ÿæ˜¯é‡è¦çš„åˆ›æ–°ç‚¹ï¼Œèƒ½å¤Ÿè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒé˜¶æ®µï¼Œé¢†åŸŸæ„ŸçŸ¥çš„NERæ•°æ®åˆæˆç­–ç•¥æ˜¯å…³é”®ã€‚å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†æ¨æµ‹å¯èƒ½æ¶‰åŠä½¿ç”¨LLMç”Ÿæˆä¸ç›®æ ‡é¢†åŸŸç›¸å…³çš„NERæ•°æ®ï¼Œå¹¶å¯¹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œç­›é€‰ï¼Œä»¥é¿å…å¼•å…¥å™ªå£°ã€‚åœ¨ç»†åŒ–é˜¶æ®µï¼Œä¸ç¡®å®šæ€§çš„åº¦é‡æ–¹å¼ä»¥åŠé˜ˆå€¼çš„é€‰æ‹©æ˜¯å…³é”®ã€‚åœ¨å®šä½é˜¶æ®µï¼Œå¤šæ¨¡æ€ä¸Šä¸‹æ–‡é€‰æ‹©ç®—æ³•çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†æ¨æµ‹å¯èƒ½æ¶‰åŠä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æˆ–å›¾ç¥ç»ç½‘ç»œæ¥å»ºæ¨¡æ–‡æœ¬å’Œå›¾åƒä¹‹é—´çš„å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ReFineGåœ¨CCKS2025 GMNERå…±äº«ä»»åŠ¡ä¸­å–å¾—äº†ç¬¬äºŒåçš„æˆç»©ï¼ŒF1å€¼ä¸º0.6461ã€‚è¯¥ç»“æœè¡¨æ˜ï¼Œåœ¨æœ‰é™æ ‡æ³¨æ•°æ®çš„æƒ…å†µä¸‹ï¼ŒReFineGèƒ½å¤Ÿæœ‰æ•ˆæå‡GMNERçš„æ€§èƒ½ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰æä¾›ä¸å…·ä½“åŸºçº¿çš„è¯¦ç»†å¯¹æ¯”æ•°æ®ï¼Œä½†æ’åç¬¬äºŒçš„ç»“æœè¶³ä»¥è¯æ˜è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ReFineGæ¡†æ¶å¯åº”ç”¨äºå¤šç§ä½èµ„æºåœºæ™¯ä¸‹çš„å¤šæ¨¡æ€å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰¹å®šé¢†åŸŸçš„æ–‡æ¡£ç†è§£ã€åŒ»å­¦å½±åƒæŠ¥å‘Šåˆ†æã€ä»¥åŠæœºå™¨äººè§†è§‰ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé™ä½å¯¹å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯ç”¨æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Grounded Multimodal Named Entity Recognition (GMNER) extends traditional NER by jointly detecting textual mentions and grounding them to visual regions. While existing supervised methods achieve strong performance, they rely on costly multimodal annotations and often underperform in low-resource domains. Multimodal Large Language Models (MLLMs) show strong generalization but suffer from Domain Knowledge Conflict, producing redundant or incorrect mentions for domain-specific entities. To address these challenges, we propose ReFineG, a three-stage collaborative framework that integrates small supervised models with frozen MLLMs for low-resource GMNER. In the Training Stage, a domain-aware NER data synthesis strategy transfers LLM knowledge to small models with supervised training while avoiding domain knowledge conflicts. In the Refinement Stage, an uncertainty-based mechanism retains confident predictions from supervised models and delegates uncertain ones to the MLLM. In the Grounding Stage, a multimodal context selection algorithm enhances visual grounding through analogical reasoning. In the CCKS2025 GMNER Shared Task, ReFineG ranked second with an F1 score of 0.6461 on the online leaderboard, demonstrating its effectiveness with limited annotations.

