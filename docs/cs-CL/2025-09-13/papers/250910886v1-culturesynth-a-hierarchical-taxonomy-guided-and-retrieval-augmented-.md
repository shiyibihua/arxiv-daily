---
layout: default
title: CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis
---

# CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10886" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10886v1</a>
  <a href="https://arxiv.org/pdf/2509.10886.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10886v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10886v1', 'CultureSynth: A Hierarchical Taxonomy-Guided and Retrieval-Augmented Framework for Cultural Question-Answer Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinyu Zhang, Pei Zhang, Shuang Luo, Jialong Tang, Yu Wan, Baosong Yang, Fei Huang

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-13

**å¤‡æ³¨**: Accepted as a Findings paper at EMNLP 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Eyr3/CultureSynth)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CultureSynthï¼šæå‡ºå±‚çº§åˆ†ç±»å¼•å¯¼å’Œæ£€ç´¢å¢å¼ºçš„æ–‡åŒ–é—®ç­”åˆæˆæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ–‡åŒ–èƒ½åŠ›` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å±‚çº§åˆ†ç±»ä½“ç³»` `å¤šè¯­è¨€è¯„ä¼°` `çŸ¥è¯†åº“` `é—®ç­”åˆæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–‡åŒ–è¯„ä¼°åŸºå‡†å­˜åœ¨åˆ†ç±»ä½“ç³»åˆ†æ•£ã€é¢†åŸŸç‰¹å®šæ€§å¼ºå’Œè¿‡åº¦ä¾èµ–äººå·¥æ ‡æ³¨çš„é—®é¢˜ã€‚
2. CultureSynthåˆ©ç”¨å±‚çº§æ–‡åŒ–åˆ†ç±»ä½“ç³»å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼Œè‡ªåŠ¨åˆæˆå¤§è§„æ¨¡æ–‡åŒ–ç›¸å…³çš„é—®ç­”å¯¹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡ã€æ¶æ„å’Œåœ°ç†ä½ç½®éƒ½ä¼šå½±å“LLMsçš„æ–‡åŒ–èƒ½åŠ›ï¼Œå¹¶æ„å»ºäº†åŒ…å«å¤šç§è¯­è¨€çš„è¯„æµ‹åŸºå‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æå‡å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å…¨çƒç¯å¢ƒä¸‹çš„æ–‡åŒ–èƒ½åŠ›ï¼Œæœ¬æ–‡æå‡ºäº†CultureSynthæ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ï¼š(1)ä¸€ä¸ªå…¨é¢çš„å¤šè¯­è¨€å±‚çº§æ–‡åŒ–åˆ†ç±»ä½“ç³»ï¼Œæ¶µç›–12ä¸ªä¸€çº§ä¸»é¢˜å’Œ130ä¸ªäºŒçº§ä¸»é¢˜ï¼›(2)ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)çš„æ–¹æ³•ï¼Œåˆ©ç”¨äº‹å®çŸ¥è¯†åˆæˆæ–‡åŒ–ç›¸å…³çš„é—®ç­”å¯¹ã€‚CultureSynth-7åˆæˆåŸºå‡†åŒ…å«19,360ä¸ªæ¡ç›®ï¼Œå…¶ä¸­4,149ä¸ªç»è¿‡äººå·¥éªŒè¯ï¼Œè¦†ç›–7ç§è¯­è¨€ã€‚å¯¹14ä¸ªä¸åŒè§„æ¨¡çš„LLMsçš„è¯„ä¼°è¡¨æ˜ï¼ŒChatGPT-4o-Latestå’ŒQwen2.5-72B-Instructè¡¨ç°é¢†å…ˆã€‚ç»“æœè¡¨æ˜ï¼Œè¾¾åˆ°åŸºæœ¬çš„æ–‡åŒ–èƒ½åŠ›éœ€è¦30äº¿å‚æ•°çš„æ¨¡å‹ï¼Œæ¨¡å‹åœ¨çŸ¥è¯†å¤„ç†ä¸­è¡¨ç°å‡ºä¸åŒçš„æ¶æ„åå·®ï¼Œå¹¶ä¸”æ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„åœ°åŸŸå·®å¼‚ã€‚CultureSynthæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•çš„æ¡†æ¶ï¼Œç”¨äºå¼€å‘å…·æœ‰æ–‡åŒ–æ„è¯†çš„AIç³»ç»Ÿï¼ŒåŒæ—¶å‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¨çƒåŒ–åº”ç”¨ä¸­ï¼Œæ–‡åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ–‡åŒ–è¯„ä¼°åŸºå‡†å­˜åœ¨è¯¸å¤šé—®é¢˜ï¼Œä¾‹å¦‚åˆ†ç±»ä½“ç³»ä¸å®Œæ•´ï¼Œç¼ºä¹ç»Ÿä¸€çš„æ ‡å‡†ï¼›é¢†åŸŸç‰¹å®šæ€§å¼ºï¼Œéš¾ä»¥æ³›åŒ–åˆ°ä¸åŒåœºæ™¯ï¼›ä»¥åŠä¸¥é‡ä¾èµ–äººå·¥æ ‡æ³¨ï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚è¿™äº›é—®é¢˜é˜»ç¢äº†æ–‡åŒ–æ„è¯†AIç³»ç»Ÿçš„å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCultureSynthçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç»“æ„åŒ–çš„æ–‡åŒ–çŸ¥è¯†ä½“ç³»å’Œæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ï¼Œè‡ªåŠ¨åŒ–åœ°åˆæˆå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„æ–‡åŒ–ç›¸å…³é—®ç­”å¯¹ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªå…¨é¢çš„æ–‡åŒ–åˆ†ç±»ä½“ç³»ï¼Œå¹¶ç»“åˆå¤–éƒ¨çŸ¥è¯†åº“ï¼Œæ¨¡å‹å¯ä»¥ç”Ÿæˆæ›´å…·æ–‡åŒ–èƒŒæ™¯å’Œä¸Šä¸‹æ–‡çš„é—®ç­”ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°è¯„ä¼°å’Œæå‡LLMsçš„æ–‡åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCultureSynthæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šä¸€æ˜¯å±‚çº§æ–‡åŒ–åˆ†ç±»ä½“ç³»ï¼ŒäºŒæ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æ¨¡å—ã€‚å±‚çº§æ–‡åŒ–åˆ†ç±»ä½“ç³»å®šä¹‰äº†12ä¸ªä¸€çº§ä¸»é¢˜å’Œ130ä¸ªäºŒçº§ä¸»é¢˜ï¼Œç”¨äºç»„ç»‡å’Œç®¡ç†æ–‡åŒ–çŸ¥è¯†ã€‚RAGæ¨¡å—é¦–å…ˆæ ¹æ®ç»™å®šçš„æ–‡åŒ–ä¸»é¢˜ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³çš„äº‹å®çŸ¥è¯†ï¼Œç„¶ååˆ©ç”¨è¿™äº›çŸ¥è¯†ç”Ÿæˆç›¸åº”çš„é—®ç­”å¯¹ã€‚æ•´ä¸ªæµç¨‹æ— éœ€å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå¯ä»¥å®ç°é«˜æ•ˆçš„æ–‡åŒ–é—®ç­”å¯¹åˆæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šCultureSynthçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»¼åˆåˆ©ç”¨äº†å±‚çº§åˆ†ç±»ä½“ç³»å’Œæ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ã€‚ä¼ ç»Ÿçš„æ–‡åŒ–è¯„ä¼°æ–¹æ³•å¾€å¾€ä¾èµ–äºäººå·¥æ ‡æ³¨çš„æ•°æ®ï¼Œè€ŒCultureSynthé€šè¿‡è‡ªåŠ¨åŒ–åˆæˆæ•°æ®çš„æ–¹å¼ï¼Œå¤§å¤§é™ä½äº†æˆæœ¬å’Œæé«˜äº†æ•ˆç‡ã€‚æ­¤å¤–ï¼Œå±‚çº§åˆ†ç±»ä½“ç³»çš„å¼•å…¥ä½¿å¾—æ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£æ–‡åŒ–çŸ¥è¯†çš„ç»“æ„å’Œå…³ç³»ï¼Œä»è€Œç”Ÿæˆæ›´å…·æ–‡åŒ–æ·±åº¦çš„é—®ç­”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RAGæ¨¡å—ä¸­ï¼Œä½¿ç”¨äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä½œä¸ºç”Ÿæˆå™¨ï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§åŸºäºç›¸ä¼¼åº¦åŒ¹é…çš„æ£€ç´¢ç­–ç•¥ï¼Œä»å¤–éƒ¨çŸ¥è¯†åº“ä¸­é€‰æ‹©æœ€ç›¸å…³çš„çŸ¥è¯†ç‰‡æ®µã€‚å…·ä½“è€Œè¨€ï¼Œä½¿ç”¨äº†ä½™å¼¦ç›¸ä¼¼åº¦æ¥è¡¡é‡æŸ¥è¯¢å’ŒçŸ¥è¯†ç‰‡æ®µä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œå¹¶é€‰æ‹©ç›¸ä¼¼åº¦æœ€é«˜çš„Top-Kä¸ªç‰‡æ®µä½œä¸ºç”Ÿæˆå™¨çš„è¾“å…¥ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†æ•°æ®è¿‡æ»¤ç­–ç•¥ï¼Œå¯¹ç”Ÿæˆçš„æ•°æ®è¿›è¡Œè´¨é‡æ§åˆ¶ï¼Œä»¥ç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨CultureSynth-7åŸºå‡†æµ‹è¯•ä¸­ï¼ŒChatGPT-4o-Latestå’ŒQwen2.5-72B-Instructè¡¨ç°é¢†å…ˆï¼ŒéªŒè¯äº†è¯¥åŸºå‡†çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¿˜è¡¨æ˜ï¼Œæ¨¡å‹è§„æ¨¡æ˜¯å½±å“æ–‡åŒ–èƒ½åŠ›çš„å…³é”®å› ç´ ï¼Œè‡³å°‘éœ€è¦30äº¿å‚æ•°çš„æ¨¡å‹æ‰èƒ½è¾¾åˆ°åŸºæœ¬çš„æ–‡åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä¸åŒæ¶æ„çš„æ¨¡å‹åœ¨çŸ¥è¯†å¤„ç†æ–¹é¢å­˜åœ¨å·®å¼‚ï¼Œä¸”æ¨¡å‹åœ¨ä¸åŒåœ°ç†åŒºåŸŸçš„è¡¨ç°ä¹Ÿå­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CultureSynthæ¡†æ¶å¯åº”ç”¨äºå¼€å‘æ›´å…·æ–‡åŒ–æ„è¯†çš„AIç³»ç»Ÿï¼Œä¾‹å¦‚å¤šè¯­è¨€èŠå¤©æœºå™¨äººã€è·¨æ–‡åŒ–äº¤æµå·¥å…·å’Œå…¨çƒåŒ–æ•™è‚²å¹³å°ã€‚é€šè¿‡æå‡LLMsçš„æ–‡åŒ–ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥å‡å°‘æ–‡åŒ–è¯¯è§£å’Œåè§ï¼Œä¿ƒè¿›ä¸åŒæ–‡åŒ–ä¹‹é—´çš„äº¤æµä¸åˆä½œã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºæ„å»ºæ›´å…¬å¹³ã€åŒ…å®¹å’Œè´Ÿè´£ä»»çš„AIç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Cultural competence, defined as the ability to understand and adapt to multicultural contexts, is increasingly vital for large language models (LLMs) in global environments. While several cultural benchmarks exist to assess LLMs' cultural competence, current evaluations suffer from fragmented taxonomies, domain specificity, and heavy reliance on manual data annotation. To address these limitations, we introduce CultureSynth, a novel framework comprising (1) a comprehensive hierarchical multilingual cultural taxonomy covering 12 primary and 130 secondary topics, and (2) a Retrieval-Augmented Generation (RAG)-based methodology leveraging factual knowledge to synthesize culturally relevant question-answer pairs. The CultureSynth-7 synthetic benchmark contains 19,360 entries and 4,149 manually verified entries across 7 languages. Evaluation of 14 prevalent LLMs of different sizes reveals clear performance stratification led by ChatGPT-4o-Latest and Qwen2.5-72B-Instruct. The results demonstrate that a 3B-parameter threshold is necessary for achieving basic cultural competence, models display varying architectural biases in knowledge processing, and significant geographic disparities exist across models. We believe that CultureSynth offers a scalable framework for developing culturally aware AI systems while reducing reliance on manual annotation\footnote{Benchmark is available at https://github.com/Eyr3/CultureSynth.}.

