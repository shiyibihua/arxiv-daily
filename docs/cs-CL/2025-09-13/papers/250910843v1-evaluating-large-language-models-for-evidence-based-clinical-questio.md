---
layout: default
title: Evaluating Large Language Models for Evidence-Based Clinical Question Answering
---

# Evaluating Large Language Models for Evidence-Based Clinical Question Answering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10843" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10843v1</a>
  <a href="https://arxiv.org/pdf/2509.10843.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10843v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10843v1', 'Evaluating Large Language Models for Evidence-Based Clinical Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Can Wang, Yiqun Chen

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¾ªè¯ä¸´åºŠé—®ç­”ä¸­çš„è¡¨ç°ï¼Œå¹¶æå‡ºæ”¹è¿›ç­–ç•¥ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸´åºŠé—®ç­”` `å¾ªè¯åŒ»å­¦` `æ£€ç´¢å¢å¼ºæç¤º` `è¯æ®æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠé—®ç­”ä¸­é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è¯æ®æ”¯æŒçš„å¤æ‚é—®é¢˜ä¸Šï¼Œå‡†ç¡®æ€§æœ‰å¾…æé«˜ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨æ£€ç´¢å¢å¼ºæç¤ºï¼Œé€šè¿‡æä¾›ç›¸å…³æ–‡çŒ®æ‘˜è¦æ¥æå‡æ¨¡å‹å›ç­”ä¸´åºŠé—®é¢˜çš„å‡†ç¡®æ€§å’Œå¯¹è¯æ®çš„ä¾èµ–æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæä¾›é»„é‡‘æ‘˜è¦èƒ½æ˜¾è‘—æå‡æ¨¡å‹å‡†ç¡®ç‡ï¼Œè€Œè¯­ä¹‰ç›¸å…³çš„PubMedæ‘˜è¦ä¹Ÿèƒ½å¸¦æ¥æå‡ï¼ŒéªŒè¯äº†æ£€ç´¢å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”Ÿç‰©åŒ»å­¦å’Œä¸´åºŠåº”ç”¨ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå› æ­¤éœ€è¦å¯¹å…¶å›ç­”ç»†è‡´çš„ã€åŸºäºè¯æ®çš„é—®é¢˜çš„èƒ½åŠ›è¿›è¡Œä¸¥æ ¼è¯„ä¼°ã€‚æœ¬æ–‡æ„å»ºäº†ä¸€ä¸ªå¤šæºåŸºå‡†ï¼Œæ•°æ®æ¥è‡ªCochraneç³»ç»Ÿè¯„ä»·å’Œä¸´åºŠæŒ‡å—ï¼ŒåŒ…æ‹¬ç¾å›½å¿ƒè„åä¼šçš„ç»“æ„åŒ–å»ºè®®å’Œä¿é™©å…¬å¸ä½¿ç”¨çš„å™è¿°æ€§æŒ‡å¯¼ã€‚ä½¿ç”¨GPT-4o-miniå’ŒGPT-5ï¼Œè§‚å¯Ÿåˆ°è·¨æ¥æºå’Œä¸´åºŠé¢†åŸŸçš„ä¸€è‡´æ€§èƒ½æ¨¡å¼ï¼šåœ¨ç»“æ„åŒ–æŒ‡å—å»ºè®®ä¸Šçš„å‡†ç¡®ç‡æœ€é«˜(90%)ï¼Œåœ¨å™è¿°æ€§æŒ‡å—å’Œç³»ç»Ÿè¯„ä»·é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡è¾ƒä½(60-70%)ã€‚è¿˜å‘ç°å‡†ç¡®ç‡ä¸åº•å±‚ç³»ç»Ÿè¯„ä»·çš„å¼•ç”¨æ¬¡æ•°ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„ç›¸å…³æ€§ï¼Œå¼•ç”¨æ¬¡æ•°æ¯å¢åŠ ä¸€å€ï¼Œæ­£ç¡®ç­”æ¡ˆçš„å‡ ç‡å¤§çº¦å¢åŠ 30%ã€‚æ¨¡å‹åœ¨æä¾›ä¸Šä¸‹æ–‡ä¿¡æ¯æ—¶ï¼Œæ˜¾ç¤ºå‡ºé€‚åº¦æ¨ç†è¯æ®è´¨é‡çš„èƒ½åŠ›ã€‚å½“ç»“åˆæ£€ç´¢å¢å¼ºæç¤ºæ—¶ï¼Œæä¾›é»„é‡‘æ¥æºæ‘˜è¦å¯å°†å…ˆå‰ä¸æ­£ç¡®é¡¹ç›®çš„å‡†ç¡®ç‡æé«˜åˆ°0.79ï¼›æä¾›å‰3ä¸ªPubMedæ‘˜è¦(æŒ‰è¯­ä¹‰ç›¸å…³æ€§æ’åº)å¯å°†å‡†ç¡®ç‡æé«˜åˆ°0.23ï¼Œè€Œéšæœºæ‘˜è¦ä¼šé™ä½å‡†ç¡®ç‡(0.10)ã€‚è¿™äº›å½±å“åœ¨GPT-4o-miniä¸­å¾—åˆ°äº†ä½“ç°ï¼Œå¼ºè°ƒäº†æ¥æºæ¸…æ™°åº¦å’Œæœ‰é’ˆå¯¹æ€§çš„æ£€ç´¢ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡å‹å¤§å°ï¼Œé©±åŠ¨äº†æ€§èƒ½ã€‚æ€»çš„æ¥è¯´ï¼Œç»“æœçªå‡ºäº†LLMåœ¨å¾ªè¯ä¸´åºŠé—®ç­”ä¸­çš„å¸Œæœ›å’Œå½“å‰å±€é™æ€§ã€‚æ£€ç´¢å¢å¼ºæç¤ºä½œä¸ºä¸€ç§æœ‰ç”¨çš„ç­–ç•¥å‡ºç°ï¼Œå¯ä»¥æé«˜äº‹å®å‡†ç¡®æ€§å’Œä¸æ¥æºè¯æ®çš„ä¸€è‡´æ€§ï¼Œè€ŒæŒ‰ä¸“ä¸šå’Œé—®é¢˜ç±»å‹åˆ†å±‚è¯„ä¼°ä»ç„¶æ˜¯ç†è§£å½“å‰çŸ¥è¯†è·å–å’Œå°†æ¨¡å‹æ€§èƒ½ç½®äºä¸Šä¸‹æ–‡ä¸­å¿…ä¸å¯å°‘çš„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›ç­”å¾ªè¯ä¸´åºŠé—®é¢˜æ—¶çš„èƒ½åŠ›ï¼Œå¹¶æ‰¾å‡ºæå‡å…¶å‡†ç¡®æ€§çš„æ–¹æ³•ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†éœ€è¦è¯æ®æ”¯æŒçš„å¤æ‚ä¸´åºŠé—®é¢˜æ—¶ï¼Œå‡†ç¡®ç‡è¾ƒä½ï¼Œä¸”å¯¹è¯æ®çš„æ¨ç†èƒ½åŠ›ä¸è¶³ï¼Œå®¹æ˜“äº§ç”Ÿå¹»è§‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ£€ç´¢å¢å¼ºæç¤ºï¼Œå³åœ¨å‘å¤§å‹è¯­è¨€æ¨¡å‹æé—®æ—¶ï¼ŒåŒæ—¶æä¾›ç›¸å…³çš„è¯æ®æ¥æºï¼ˆå¦‚æ–‡çŒ®æ‘˜è¦ï¼‰ï¼Œä»¥å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£é—®é¢˜å¹¶ç»™å‡ºå‡†ç¡®çš„ç­”æ¡ˆã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨å‡å°‘æ¨¡å‹å¯¹è‡ªèº«çŸ¥è¯†çš„ä¾èµ–ï¼Œæ›´å¤šåœ°ä¾èµ–å¤–éƒ¨è¯æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) æ„å»ºåŒ…å«ç»“æ„åŒ–æŒ‡å—ã€å™è¿°æ€§æŒ‡å—å’Œç³»ç»Ÿè¯„ä»·çš„å¤šæºåŸºå‡†æ•°æ®é›†ï¼›2) ä½¿ç”¨GPT-4o-miniå’ŒGPT-5ç­‰å¤§å‹è¯­è¨€æ¨¡å‹å›ç­”æ•°æ®é›†ä¸­çš„é—®é¢˜ï¼›3) è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒç±»å‹é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡ï¼›4) å¼•å…¥æ£€ç´¢å¢å¼ºæç¤ºï¼Œåˆ†åˆ«æä¾›é»„é‡‘æ¥æºæ‘˜è¦ã€è¯­ä¹‰ç›¸å…³çš„PubMedæ‘˜è¦å’Œéšæœºæ‘˜è¦ï¼›5) æ¯”è¾ƒä¸åŒæç¤ºç­–ç•¥ä¸‹çš„æ¨¡å‹æ€§èƒ½ï¼Œåˆ†ææ£€ç´¢å¢å¼ºå¯¹å‡†ç¡®ç‡çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†æ£€ç´¢å¢å¼ºæç¤ºåœ¨å¾ªè¯ä¸´åºŠé—®ç­”ä¸­çš„ä½œç”¨ï¼Œå¹¶éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚ä¸ä»¥å¾€ç ”ç©¶ç›¸æ¯”ï¼Œè¯¥ç ”ç©¶æ›´å…³æ³¨å¦‚ä½•åˆ©ç”¨å¤–éƒ¨è¯æ®æ¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ„å»ºå¤šæºåŸºå‡†æ•°æ®é›†ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§ï¼›2) ä½¿ç”¨ä¸åŒçš„æ£€ç´¢ç­–ç•¥ï¼ˆé»„é‡‘æ‘˜è¦ã€è¯­ä¹‰ç›¸å…³æ‘˜è¦ã€éšæœºæ‘˜è¦ï¼‰æ¥è¯„ä¼°æ£€ç´¢è´¨é‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼›3) ä½¿ç”¨GPT-4o-miniå’ŒGPT-5ç­‰ä¸åŒè§„æ¨¡çš„æ¨¡å‹ï¼ŒéªŒè¯ç»“è®ºçš„æ³›åŒ–æ€§ï¼›4) åˆ†æå¼•ç”¨æ¬¡æ•°ä¸å‡†ç¡®ç‡ä¹‹é—´çš„å…³ç³»ï¼Œæ¢ç©¶è¯æ®è´¨é‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç»“æ„åŒ–æŒ‡å—å»ºè®®ä¸Šçš„å‡†ç¡®ç‡æœ€é«˜(90%)ï¼Œåœ¨å™è¿°æ€§æŒ‡å—å’Œç³»ç»Ÿè¯„ä»·é—®é¢˜ä¸Šçš„å‡†ç¡®ç‡è¾ƒä½(60-70%)ã€‚æä¾›é»„é‡‘æ¥æºæ‘˜è¦å¯å°†å…ˆå‰ä¸æ­£ç¡®é¡¹ç›®çš„å‡†ç¡®ç‡æé«˜åˆ°0.79ï¼›æä¾›å‰3ä¸ªPubMedæ‘˜è¦(æŒ‰è¯­ä¹‰ç›¸å…³æ€§æ’åº)å¯å°†å‡†ç¡®ç‡æé«˜åˆ°0.23ï¼Œè€Œéšæœºæ‘˜è¦ä¼šé™ä½å‡†ç¡®ç‡(0.10)ã€‚å¼•ç”¨æ¬¡æ•°æ¯å¢åŠ ä¸€å€ï¼Œæ­£ç¡®ç­”æ¡ˆçš„å‡ ç‡å¤§çº¦å¢åŠ 30%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿï¼Œå¸®åŠ©åŒ»ç”Ÿå¿«é€Ÿè·å–é«˜è´¨é‡çš„å¾ªè¯åŒ»å­¦è¯æ®ï¼Œè¾…åŠ©è¯Šæ–­å’Œæ²»ç–—ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠé—®ç­”ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œå¯ä»¥å‡å°‘åŒ»ç–—é”™è¯¯ï¼Œæé«˜åŒ»ç–—æ•ˆç‡ï¼Œå¹¶ä¸ºæ‚£è€…æä¾›æ›´ä¼˜è´¨çš„åŒ»ç–—æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºè¿œç¨‹åŒ»ç–—ã€å¥åº·å’¨è¯¢ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated substantial progress in biomedical and clinical applications, motivating rigorous evaluation of their ability to answer nuanced, evidence-based questions. We curate a multi-source benchmark drawing from Cochrane systematic reviews and clinical guidelines, including structured recommendations from the American Heart Association and narrative guidance used by insurers. Using GPT-4o-mini and GPT-5, we observe consistent performance patterns across sources and clinical domains: accuracy is highest on structured guideline recommendations (90%) and lower on narrative guideline and systematic review questions (60--70%). We also find a strong correlation between accuracy and the citation count of the underlying systematic reviews, where each doubling of citations is associated with roughly a 30% increase in the odds of a correct answer. Models show moderate ability to reason about evidence quality when contextual information is supplied. When we incorporate retrieval-augmented prompting, providing the gold-source abstract raises accuracy on previously incorrect items to 0.79; providing top 3 PubMed abstracts (ranked by semantic relevance) improves accuracy to 0.23, while random abstracts reduce accuracy (0.10, within temperature variation). These effects are mirrored in GPT-4o-mini, underscoring that source clarity and targeted retrieval -- not just model size -- drive performance. Overall, our results highlight both the promise and current limitations of LLMs for evidence-based clinical question answering. Retrieval-augmented prompting emerges as a useful strategy to improve factual accuracy and alignment with source evidence, while stratified evaluation by specialty and question type remains essential to understand current knowledge access and to contextualize model performance.

