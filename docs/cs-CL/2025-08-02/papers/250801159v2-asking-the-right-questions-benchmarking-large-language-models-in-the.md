---
layout: default
title: Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates
---

# Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01159" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01159v2</a>
  <a href="https://arxiv.org/pdf/2508.01159.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01159v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01159v2', 'Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liam G. McCoy, Fateme Nateghi Haredasht, Kanav Chopra, David Wu, David JH Wu, Abass Conteh, Sarita Khemani, Saloni Kumar Maharaj, Vishnu Ravi, Arth Pahwa, Yingjie Weng, Leah Rosengaus, Lena Giang, Kelvin Zhenghao Li, Olivia Jee, Daniel Shirvani, Ethan Goh, Jonathan H. Chen

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02 (æ›´æ–°: 2025-11-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠå’¨è¯¢æ¨¡æ¿ç”Ÿæˆä¸­çš„åº”ç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸´åºŠå’¨è¯¢` `æ¨¡æ¿ç”Ÿæˆ` `ä¿¡æ¯ä¼˜å…ˆçº§` `åŒ»ç–—ä¿¡æ¯ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆä¸´åºŠå’¨è¯¢æ¨¡æ¿æ—¶ï¼Œå¸¸å¸¸æ— æ³•æœ‰æ•ˆä¼˜å…ˆè€ƒè™‘æœ€é‡è¦çš„é—®é¢˜ï¼Œå¯¼è‡´ä¿¡æ¯ä¼ é€’ä¸å¤Ÿé«˜æ•ˆã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§å¤šä»£ç†ç®¡é“ï¼Œç»“åˆæç¤ºä¼˜åŒ–ã€è¯­ä¹‰è‡ªåŠ¨è¯„åˆ†å’Œä¼˜å…ˆçº§åˆ†æï¼Œä»¥æå‡LLMsç”Ÿæˆä¸´åºŠå’¨è¯¢æ¨¡æ¿çš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æŸäº›æ¨¡å‹åœ¨å…¨é¢æ€§ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å™è¿°é©±åŠ¨çš„é¢†åŸŸå¦‚ç²¾ç¥ç—…å­¦å’Œç–¼ç—›åŒ»å­¦ä¸­ï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆç»“æ„åŒ–ä¸´åºŠå’¨è¯¢æ¨¡æ¿çš„èƒ½åŠ›ï¼Œä½¿ç”¨äº†145ä¸ªç”±æ–¯å¦ç¦eConsultå›¢é˜Ÿå¼€å‘çš„ä¸“å®¶æ¨¡æ¿ã€‚æˆ‘ä»¬å¯¹åŒ…æ‹¬o3ã€GPT-4oã€Kimi K2ç­‰å‰æ²¿æ¨¡å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°å°½ç®¡o3åœ¨å…¨é¢æ€§ä¸Šè¡¨ç°å‡ºè‰²ï¼ˆé«˜è¾¾92.2%ï¼‰ï¼Œä½†åœ¨é•¿åº¦é™åˆ¶ä¸‹ï¼Œæ¨¡å‹ç”Ÿæˆçš„æ¨¡æ¿å¾€å¾€è¿‡é•¿ï¼Œä¸”æœªèƒ½æ­£ç¡®ä¼˜å…ˆè€ƒè™‘æœ€é‡è¦çš„ä¸´åºŠé—®é¢˜ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMsèƒ½å¤Ÿå¢å¼ºåŒ»ç”Ÿä¹‹é—´çš„ç»“æ„åŒ–ä¿¡æ¯äº¤æµï¼Œä½†éœ€è¦æ›´å¼ºçš„è¯„ä¼°æ–¹æ³•æ¥æ•æ‰æ¨¡å‹åœ¨å®é™…æ²Ÿé€šä¸­çš„ä¼˜å…ˆçº§èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆä¸´åºŠå’¨è¯¢æ¨¡æ¿æ—¶çš„ä¼˜å…ˆçº§æ’åºå’Œä¿¡æ¯è¿‡è½½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”Ÿæˆæ¨¡æ¿æ—¶å¸¸å¸¸å¿½è§†ä¸´åºŠé‡è¦æ€§ï¼Œå¯¼è‡´ä¿¡æ¯ä¼ é€’æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªå¤šä»£ç†ç®¡é“ï¼Œç»“åˆæç¤ºä¼˜åŒ–å’Œè¯­ä¹‰è‡ªåŠ¨è¯„åˆ†ï¼Œè®ºæ–‡æ—¨åœ¨æå‡æ¨¡å‹ç”Ÿæˆçš„ä¸´åºŠé—®é¢˜æ¨¡æ¿çš„ç»“æ„åŒ–å’Œä¼˜å…ˆçº§æ’åºèƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡å¯ä»¥æ›´å¥½åœ°é€‚åº”åŒ»ç”Ÿåœ¨å®é™…æ²Ÿé€šä¸­çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯æç¤ºä¼˜åŒ–æ¨¡å—ï¼Œæ—¨åœ¨ç”Ÿæˆæ›´æœ‰æ•ˆçš„è¾“å…¥æç¤ºï¼›å…¶æ¬¡æ˜¯è¯­ä¹‰è‡ªåŠ¨è¯„åˆ†æ¨¡å—ï¼Œç”¨äºè¯„ä¼°ç”Ÿæˆæ¨¡æ¿çš„è´¨é‡ï¼›æœ€åæ˜¯ä¼˜å…ˆçº§åˆ†ææ¨¡å—ï¼Œç¡®ä¿ç”Ÿæˆçš„é—®é¢˜æŒ‰ç…§ä¸´åºŠé‡è¦æ€§æ’åºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å¤šä»£ç†ç®¡é“çš„æ¦‚å¿µï¼Œç»“åˆäº†ä¸åŒçš„è¯„ä¼°æ–¹æ³•ï¼Œä»¥æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹åœ¨ä¸´åºŠåœºæ™¯ä¸­çš„è¡¨ç°ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€è¯„ä¼°æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œç ”ç©¶ä½¿ç”¨äº†å¤šç§æ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼Œç‰¹åˆ«å…³æ³¨äº†ç”Ÿæˆæ¨¡æ¿çš„é•¿åº¦å’Œå†…å®¹çš„ä¼˜å…ˆçº§ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œå¼ºè°ƒäº†ä¸´åºŠé—®é¢˜çš„ä¼˜å…ˆçº§ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„æ¨¡æ¿ä¸ä»…å…¨é¢è€Œä¸”ç®€æ´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œo3æ¨¡å‹åœ¨æ¨¡æ¿çš„å…¨é¢æ€§ä¸Šè¾¾åˆ°äº†92.2%çš„é«˜åˆ†ï¼Œä½†åœ¨é•¿åº¦é™åˆ¶ä¸‹ç”Ÿæˆçš„æ¨¡æ¿è¿‡é•¿ï¼Œä¸”æœªèƒ½ä¼˜å…ˆè€ƒè™‘æœ€é‡è¦çš„ä¸´åºŠé—®é¢˜ã€‚å°¤å…¶åœ¨ç²¾ç¥ç—…å­¦å’Œç–¼ç—›åŒ»å­¦ç­‰å™è¿°é©±åŠ¨çš„é¢†åŸŸï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæç¤ºäº†åœ¨è¿™äº›é¢†åŸŸåº”ç”¨LLMsçš„æŒ‘æˆ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­åŒ»ç–—å’¨è¯¢ã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿå’ŒåŒ»ç–—ä¿¡æ¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆä¸´åºŠå’¨è¯¢æ¨¡æ¿æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆæ”¹å–„åŒ»ç”Ÿä¹‹é—´çš„ä¿¡æ¯äº¤æµï¼Œæé«˜åŒ»ç–—æœåŠ¡çš„æ•ˆç‡å’Œè´¨é‡ï¼Œæœªæ¥å¯èƒ½å¯¹åŒ»ç–—è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study evaluates the capacity of large language models (LLMs) to generate structured clinical consultation templates for electronic consultation. Using 145 expert-crafted templates developed and routinely used by Stanford's eConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2, Claude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to produce clinically coherent, concise, and prioritized clinical question schemas. Through a multi-agent pipeline combining prompt optimization, semantic autograding, and prioritization analysis, we show that while models like o3 achieve high comprehensiveness (up to 92.2\%), they consistently generate excessively long templates and fail to correctly prioritize the most clinically important questions under length constraints. Performance varies across specialties, with significant degradation in narrative-driven fields such as psychiatry and pain medicine. Our findings demonstrate that LLMs can enhance structured clinical information exchange between physicians, while highlighting the need for more robust evaluation methods that capture a model's ability to prioritize clinically salient information within the time constraints of real-world physician communication.

