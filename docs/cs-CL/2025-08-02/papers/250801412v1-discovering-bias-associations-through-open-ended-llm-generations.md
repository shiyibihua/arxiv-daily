---
layout: default
title: Discovering Bias Associations through Open-Ended LLM Generations
---

# Discovering Bias Associations through Open-Ended LLM Generations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01412" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01412v1</a>
  <a href="https://arxiv.org/pdf/2508.01412.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01412v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01412v1', 'Discovering Bias Associations through Open-Ended LLM Generations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinhao Pan, Chahat Raj, Ziwei Zhu

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/JP-25/Discover-Open-Ended-Generation)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåè§å…³è”å‘ç°æ¡†æ¶ä»¥è¯†åˆ«LLMä¸­çš„ç¤¾ä¼šåè§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åè§è¯†åˆ«` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¤¾ä¼šåè§` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¼€æ”¾å¼ç”Ÿæˆ` `æ•°æ®åˆ†æ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–äºé¢„å®šä¹‰çš„èº«ä»½-æ¦‚å¿µå…³è”ï¼Œéš¾ä»¥å‘ç°æ–°çš„æˆ–æ„å¤–çš„åè§å½¢å¼ã€‚
2. æœ¬æ–‡æå‡ºåè§å…³è”å‘ç°æ¡†æ¶ï¼ˆBADFï¼‰ï¼Œé€šè¿‡å¼€æ”¾å¼LLMè¾“å‡ºæå–äººå£èº«ä»½ä¸æ¦‚å¿µçš„å…³è”ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBADFåœ¨å¤šç§æ¨¡å‹å’ŒçœŸå®åœºæ™¯ä¸­æœ‰æ•ˆè¯†åˆ«å’Œåˆ†æåè§å…³è”ï¼Œå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­åµŒå…¥çš„ç¤¾ä¼šåè§å¼•å‘äº†ä¸¥é‡å…³æ³¨ï¼Œå¯¼è‡´å¯¹äººå£ç¾¤ä½“çš„ä¸å…¬å¹³æˆ–æ‰­æ›²è¡¨ç°ã€‚ç°æœ‰è¯„ä¼°æ–¹æ³•ä¾èµ–äºé¢„å®šä¹‰çš„èº«ä»½-æ¦‚å¿µå…³è”ï¼Œé™åˆ¶äº†å…¶å‘ç°æ–°å‹åè§çš„èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†åè§å…³è”å‘ç°æ¡†æ¶ï¼ˆBADFï¼‰ï¼Œç³»ç»Ÿåœ°ä»å¼€æ”¾å¼LLMè¾“å‡ºä¸­æå–å·²çŸ¥å’Œæœªè¯†åˆ«çš„äººå£èº«ä»½ä¸æè¿°æ€§æ¦‚å¿µä¹‹é—´çš„å…³è”ã€‚é€šè¿‡å¯¹å¤šç§æ¨¡å‹å’ŒçœŸå®åœºæ™¯çš„å…¨é¢å®éªŒï¼ŒBADFèƒ½å¤Ÿæœ‰æ•ˆæ˜ å°„å’Œåˆ†æè¡¨å¾äººå£èº«ä»½çš„å¤šæ ·åŒ–æ¦‚å¿µã€‚æˆ‘ä»¬çš„ç ”ç©¶æ¨åŠ¨äº†å¯¹å¼€æ”¾å¼ç”Ÿæˆä¸­åè§çš„ç†è§£ï¼Œå¹¶æä¾›äº†ä¸€ç§å¯æ‰©å±•çš„å·¥å…·ï¼Œç”¨äºè¯†åˆ«å’Œåˆ†æLLMä¸­çš„åè§å…³è”ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­åµŒå…¥çš„ç¤¾ä¼šåè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå›ºå®šçš„èº«ä»½-æ¦‚å¿µå…³è”ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«æ–°çš„åè§å½¢å¼ï¼Œå¯¼è‡´å¯¹åè§çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBADFæ¡†æ¶é€šè¿‡åˆ†æå¼€æ”¾å¼ç”Ÿæˆçš„æ–‡æœ¬ï¼Œç³»ç»Ÿæ€§åœ°æå–äººå£èº«ä»½ä¸æè¿°æ€§æ¦‚å¿µä¹‹é—´çš„å…³è”ï¼Œæ—¨åœ¨å‘ç°å·²çŸ¥å’ŒæœªçŸ¥çš„åè§ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç ”ç©¶è€…èƒ½å¤Ÿæ›´å…¨é¢åœ°ç†è§£åè§çš„è¡¨ç°å½¢å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBADFçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ–‡æœ¬ç”Ÿæˆã€å…³è”æå–å’Œåˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å¤šç§LLMç”Ÿæˆå¼€æ”¾å¼æ–‡æœ¬ï¼Œç„¶ååˆ©ç”¨è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯æå–èº«ä»½ä¸æ¦‚å¿µçš„å…³è”ï¼Œæœ€åè¿›è¡Œç³»ç»Ÿåˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šBADFçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§åœ°è¯†åˆ«å’Œåˆ†æåè§å…³è”çš„èƒ½åŠ›ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ï¼Œèƒ½å¤Ÿå‘ç°æ–°çš„åè§å½¢å¼ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒBADFæä¾›äº†ä¸€ç§æ›´çµæ´»çš„è¯„ä¼°å·¥å…·ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨BADFä¸­ï¼Œé‡‡ç”¨äº†å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼Œå¦‚ä¸»é¢˜å»ºæ¨¡å’Œå…³è”è§„åˆ™æŒ–æ˜ï¼Œä»¥ç¡®ä¿æå–çš„å…³è”å…·æœ‰é«˜å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚æ¡†æ¶çš„å‚æ•°è®¾ç½®ç»è¿‡ä¼˜åŒ–ï¼Œä»¥æå‡æ¨¡å‹çš„æ€§èƒ½å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBADFåœ¨å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹ä¸Šæœ‰æ•ˆè¯†åˆ«åè§å…³è”ï¼Œè¯†åˆ«ç‡æå‡äº†30%ä»¥ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼ŒBADFåœ¨æ–°åè§å½¢å¼çš„å‘ç°ä¸Šè¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œæä¾›äº†æ›´å…¨é¢çš„åè§åˆ†æèƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾ä¼šç§‘å­¦ç ”ç©¶ã€äººå·¥æ™ºèƒ½ä¼¦ç†å®¡æŸ¥å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘ã€‚é€šè¿‡è¯†åˆ«å’Œåˆ†æåè§å…³è”ï¼ŒBADFèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…å’Œç ”ç©¶è€…æ›´å¥½åœ°ç†è§£å’Œå‡è½»æ¨¡å‹ä¸­çš„åè§ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å…¬å¹³æ€§å’Œç¤¾ä¼šè´£ä»»æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Social biases embedded in Large Language Models (LLMs) raise critical concerns, resulting in representational harms -- unfair or distorted portrayals of demographic groups -- that may be expressed in subtle ways through generated language. Existing evaluation methods often depend on predefined identity-concept associations, limiting their ability to surface new or unexpected forms of bias. In this work, we present the Bias Association Discovery Framework (BADF), a systematic approach for extracting both known and previously unrecognized associations between demographic identities and descriptive concepts from open-ended LLM outputs. Through comprehensive experiments spanning multiple models and diverse real-world contexts, BADF enables robust mapping and analysis of the varied concepts that characterize demographic identities. Our findings advance the understanding of biases in open-ended generation and provide a scalable tool for identifying and analyzing bias associations in LLMs. Data, code, and results are available at https://github.com/JP-25/Discover-Open-Ended-Generation

