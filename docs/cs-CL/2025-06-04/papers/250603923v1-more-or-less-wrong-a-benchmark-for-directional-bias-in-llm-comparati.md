---
layout: default
title: More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning
---

# More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.03923" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.03923v1</a>
  <a href="https://arxiv.org/pdf/2506.03923.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.03923v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.03923v1', 'More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammadamin Shafiei, Hamidreza Saffari, Nafise Sadat Moosavi

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMathCompåŸºå‡†ä»¥è§£å†³LLMæ¯”è¾ƒæ¨ç†ä¸­çš„æ–¹å‘æ€§åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¯”è¾ƒæ¨ç†` `æ–¹å‘æ€§åå·®` `è¯­ä¹‰æ¡†æ¶` `é“¾å¼æ€ç»´æç¤º` `MathCompåŸºå‡†` `å…¬å¹³æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†æ¯”è¾ƒæ•°å­¦é—®é¢˜æ—¶ï¼Œå®¹æ˜“å—åˆ°è¾“å…¥æªè¾çš„å½±å“ï¼Œå¯¼è‡´æ–¹å‘æ€§åå·®ã€‚
2. æœ¬æ–‡æå‡ºMathCompåŸºå‡†ï¼Œé€šè¿‡300ä¸ªæ¯”è¾ƒåœºæ™¯å’Œ14ç§æç¤ºå˜ä½“ï¼Œç³»ç»Ÿæ€§ç ”ç©¶è¯­è¨€å¼•å¯¼å¯¹æ¨ç†çš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé“¾å¼æ€ç»´æç¤ºèƒ½å‡å°‘åå·®ï¼Œä½†æ•ˆæœå› æ¨ç†å½¢å¼è€Œå¼‚ï¼Œä¸”äººå£èº«ä»½æœ¯è¯­ä¼šåŠ å‰§æ–¹å‘æ€§æ¼‚ç§»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹è¾“å…¥æªè¾æ•æ„Ÿï¼Œä½†è¯­ä¹‰çº¿ç´¢å¦‚ä½•å½±å“æ¨ç†æœºåˆ¶å°šä¸æ¸…æ¥šã€‚æœ¬æ–‡åœ¨æ¯”è¾ƒæ•°å­¦é—®é¢˜çš„èƒŒæ™¯ä¸‹ç ”ç©¶è¿™ä¸€ç°è±¡ï¼Œæ­ç¤ºå‡ºä¸€ç§ä¸€è‡´ä¸”æ–¹å‘æ€§çš„æ¡†æ¶åå·®ï¼šåŒ…å«â€œæ›´å¤šâ€ã€â€œæ›´å°‘â€æˆ–â€œç›¸ç­‰â€ç­‰è¯è¯­çš„é€»è¾‘ç­‰ä»·é—®é¢˜ï¼Œç³»ç»Ÿæ€§åœ°å¼•å¯¼é¢„æµ‹æœå‘æ¡†æ¶æœ¯è¯­çš„æ–¹å‘ã€‚ä¸ºç ”ç©¶è¿™ä¸€æ•ˆåº”ï¼Œæœ¬æ–‡å¼•å…¥äº†MathCompï¼Œä¸€ä¸ªåŒ…å«300ä¸ªæ¯”è¾ƒåœºæ™¯çš„æ§åˆ¶åŸºå‡†ï¼Œæ¯ä¸ªåœºæ™¯åœ¨ä¸‰ç§LLMå®¶æ—ä¸‹è¯„ä¼°14ç§æç¤ºå˜ä½“ã€‚ç ”ç©¶å‘ç°ï¼Œæ¨¡å‹é”™è¯¯å¸¸å¸¸åæ˜ è¯­è¨€å¼•å¯¼ï¼Œç³»ç»Ÿæ€§åœ°åå‘æç¤ºä¸­å­˜åœ¨çš„æ¯”è¾ƒæœ¯è¯­ã€‚é“¾å¼æ€ç»´æç¤ºå¯ä»¥å‡å°‘è¿™äº›åå·®ï¼Œä½†å…¶æœ‰æ•ˆæ€§æœ‰æ‰€ä¸åŒï¼šè‡ªç”±å½¢å¼çš„æ¨ç†æ›´ä¸ºç¨³å¥ï¼Œè€Œç»“æ„åŒ–æ ¼å¼å¯èƒ½ä¿ç•™æˆ–é‡æ–°å¼•å…¥æ–¹å‘æ€§æ¼‚ç§»ã€‚æœ€åï¼Œç ”ç©¶è¡¨æ˜åœ¨è¾“å…¥åœºæ™¯ä¸­åŒ…å«äººå£èº«ä»½æœ¯è¯­ï¼ˆå¦‚â€œå¥³æ€§â€ã€â€œé»‘äººâ€ï¼‰ä¼šæ”¾å¤§æ–¹å‘æ€§æ¼‚ç§»ï¼Œå°½ç®¡åŸºç¡€æ•°é‡ç›¸åŒï¼Œçªæ˜¾äº†è¯­ä¹‰æ¡†æ¶ä¸ç¤¾ä¼šå‚ç…§ä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†æ ‡å‡†è¯„ä¼°ä¸­çš„å…³é”®ç›²ç‚¹ï¼Œå¹¶æ¨åŠ¨äº†é’ˆå¯¹æ¨ç†ç¨³å¥æ€§å’Œå…¬å¹³æ€§çš„æ¡†æ¶æ„ŸçŸ¥åŸºå‡†çš„å»ºç«‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¯”è¾ƒæ¨ç†ä¸­å­˜åœ¨çš„æ–¹å‘æ€§åå·®é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†ç†è§£è¯­ä¹‰çº¿ç´¢å¯¹æ¨ç†çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥MathCompåŸºå‡†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒæç¤ºå¯¹æ¨¡å‹æ¨ç†çš„å½±å“ï¼Œæ­ç¤ºè¯­è¨€å¼•å¯¼çš„æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬300ä¸ªæ¯”è¾ƒåœºæ™¯ï¼Œæ¯ä¸ªåœºæ™¯åœ¨ä¸‰ç§LLMå®¶æ—ä¸‹è¯„ä¼°14ç§æç¤ºå˜ä½“ï¼Œåˆ†ææ¨¡å‹è¾“å‡ºä¸è¾“å…¥æç¤ºçš„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºè¯†åˆ«å¹¶é‡åŒ–è¯­è¨€å¼•å¯¼å¯¹æ¨¡å‹æ¨ç†çš„å½±å“ï¼Œå°¤å…¶æ˜¯æ¯”è¾ƒæœ¯è¯­çš„ä½œç”¨ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æç¤ºå˜ä½“å’Œé“¾å¼æ€ç»´æç¤ºï¼Œåˆ†æå…¶å¯¹æ¨¡å‹è¾“å‡ºçš„å½±å“ï¼Œç‰¹åˆ«å…³æ³¨è‡ªç”±å½¢å¼æ¨ç†ä¸ç»“æ„åŒ–æ ¼å¼çš„è¡¨ç°å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé“¾å¼æ€ç»´æç¤ºèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æ–¹å‘æ€§åå·®ï¼Œå°¤å…¶åœ¨è‡ªç”±å½¢å¼æ¨ç†ä¸­è¡¨ç°æ›´ä¸ºç¨³å¥ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç»“æ„åŒ–æ ¼å¼å¯èƒ½ä¼šä¿ç•™æˆ–é‡æ–°å¼•å…¥åå·®ã€‚æ­¤å¤–ï¼ŒåŒ…å«äººå£èº«ä»½æœ¯è¯­çš„è¾“å…¥åœºæ™¯æ˜¾è‘—åŠ å‰§äº†æ–¹å‘æ€§æ¼‚ç§»ï¼Œå¼ºè°ƒäº†è¯­ä¹‰æ¡†æ¶ä¸ç¤¾ä¼šå‚ç…§çš„ç›¸äº’ä½œç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€å¿ƒç†å­¦å’Œç¤¾ä¼šç§‘å­¦ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©è®¾è®¡æ›´å…¬å¹³å’Œç¨³å¥çš„è¯­è¨€æ¨¡å‹ï¼Œå‡å°‘å› æªè¾å¼•èµ·çš„åå·®ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œå…¬æ­£æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are known to be sensitive to input phrasing, but the mechanisms by which semantic cues shape reasoning remain poorly understood. We investigate this phenomenon in the context of comparative math problems with objective ground truth, revealing a consistent and directional framing bias: logically equivalent questions containing the words ``more'', ``less'', or ``equal'' systematically steer predictions in the direction of the framing term. To study this effect, we introduce MathComp, a controlled benchmark of 300 comparison scenarios, each evaluated under 14 prompt variants across three LLM families. We find that model errors frequently reflect linguistic steering, systematic shifts toward the comparative term present in the prompt. Chain-of-thought prompting reduces these biases, but its effectiveness varies: free-form reasoning is more robust, while structured formats may preserve or reintroduce directional drift. Finally, we show that including demographic identity terms (e.g., ``a woman'', ``a Black person'') in input scenarios amplifies directional drift, despite identical underlying quantities, highlighting the interplay between semantic framing and social referents. These findings expose critical blind spots in standard evaluation and motivate framing-aware benchmarks for diagnosing reasoning robustness and fairness in LLMs.

