---
layout: default
title: SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models
---

# SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04180" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04180v1</a>
  <a href="https://arxiv.org/pdf/2506.04180.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04180v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04180v1', 'SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuhao Wu, Yushi Bai, Zhiqiang Hu, Juanzi Li, Roy Ka-Wei Lee

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSuperWriter-Agentä»¥è§£å†³é•¿æ–‡æœ¬ç”Ÿæˆä¸­çš„ä¸€è‡´æ€§å’Œè´¨é‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿æ–‡æœ¬ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç»“æ„åŒ–æ€ç»´` `ä¼˜åŒ–ç®—æ³•` `å†…å®¹åˆ›ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿æ–‡æœ¬ç”Ÿæˆé¢ä¸´è¿è´¯æ€§ã€é€»è¾‘ä¸€è‡´æ€§å’Œæ–‡æœ¬è´¨é‡ä¸‹é™ç­‰æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè§£å†³è¿™äº›é—®é¢˜ã€‚
2. æå‡ºSuperWriter-Agentæ¡†æ¶ï¼Œé€šè¿‡ç»“æ„åŒ–æ€ç»´å’Œè§„åˆ’é˜¶æ®µå¼•å¯¼ç”Ÿæˆè¿‡ç¨‹ï¼Œæå‡æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚
3. SuperWriter-LMåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é•¿æ–‡æœ¬ç”Ÿæˆä»ç„¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´çš„é‡è¦æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ä¿æŒè¿è´¯æ€§ã€ç¡®ä¿é€»è¾‘ä¸€è‡´æ€§å’Œæ–‡æœ¬è´¨é‡æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†SuperWriter-Agentï¼Œä¸€ä¸ªåŸºäºä»£ç†çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºé•¿æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†æ˜ç¡®çš„ç»“æ„åŒ–æ€ç»´ï¼Œé€šè¿‡è§„åˆ’å’Œä¼˜åŒ–é˜¶æ®µå¼•å¯¼æ¨¡å‹éµå¾ªæ›´ä¸ºæ·±æ€ç†Ÿè™‘çš„è¿‡ç¨‹ï¼Œç±»ä¼¼äºä¸“ä¸šä½œå®¶çš„å†™ä½œæ–¹å¼ã€‚åŸºäºæ­¤æ¡†æ¶ï¼Œæ„å»ºäº†ä¸€ä¸ªç›‘ç£å¾®è°ƒæ•°æ®é›†ä»¥è®­ç»ƒ7Bçš„SuperWriter-LMï¼Œå¹¶å¼€å‘äº†å±‚æ¬¡åŒ–ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ç¨‹åºï¼Œåˆ©ç”¨è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰ä¼ æ’­æœ€ç»ˆè´¨é‡è¯„ä¼°å¹¶ä¼˜åŒ–æ¯ä¸ªç”Ÿæˆæ­¥éª¤ã€‚å®éªŒè¯æ˜ï¼ŒSuperWriter-LMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„åŸºçº¿æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿æ–‡æœ¬ç”Ÿæˆä¸­é¢ä¸´çš„è¿è´¯æ€§ã€é€»è¾‘ä¸€è‡´æ€§å’Œæ–‡æœ¬è´¨é‡ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†é•¿åºåˆ—æ—¶ï¼Œå¾€å¾€æ— æ³•ä¿æŒé«˜è´¨é‡çš„ç”Ÿæˆæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºSuperWriter-Agentæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ç»“æ„åŒ–æ€ç»´çš„è§„åˆ’å’Œä¼˜åŒ–é˜¶æ®µï¼Œæ¨¡æ‹Ÿä¸“ä¸šä½œå®¶çš„å†™ä½œè¿‡ç¨‹ï¼Œä»è€Œæå‡ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè§„åˆ’é˜¶æ®µå’Œä¼˜åŒ–é˜¶æ®µã€‚åœ¨è§„åˆ’é˜¶æ®µï¼Œæ¨¡å‹è¿›è¡Œæ€ç»´ç»“æ„åŒ–ï¼Œæ˜ç¡®ç”Ÿæˆç›®æ ‡ï¼›åœ¨ä¼˜åŒ–é˜¶æ®µï¼Œåˆ©ç”¨å±‚æ¬¡åŒ–ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰è¿›è¡Œè´¨é‡è¯„ä¼°å’Œç”Ÿæˆæ­¥éª¤ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å±‚æ¬¡åŒ–DPOå’Œç»“æ„åŒ–æ€ç»´æ­¥éª¤ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç”Ÿæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåè€…é€šå¸¸ç¼ºä¹ç³»ç»Ÿçš„æ€ç»´å¼•å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œä½¿ç”¨äº†7Bå‚æ•°çš„SuperWriter-LMï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„æŸå¤±å‡½æ•°ä»¥æ”¯æŒDPOè¿‡ç¨‹ï¼Œç¡®ä¿ç”Ÿæˆçš„æ–‡æœ¬åœ¨è´¨é‡å’Œä¸€è‡´æ€§ä¸Šè¾¾åˆ°æœ€ä½³æ•ˆæœã€‚é€šè¿‡ç²¾ç»†çš„å‚æ•°è®¾ç½®å’Œç»“æ„è®¾è®¡ï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SuperWriter-LMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†æ›´å¤§è§„æ¨¡çš„åŸºçº¿æ¨¡å‹ï¼Œè‡ªåŠ¨è¯„ä¼°å’Œäººå·¥è¯„ä¼°å‡æ˜¾ç¤ºå‡ºæ˜¾è‘—æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡ä¸Šæé«˜äº†X%ï¼Œåœ¨é€»è¾‘ä¸€è‡´æ€§æ–¹é¢ä¹Ÿæœ‰æ˜¾è‘—æ”¹å–„ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å†…å®¹åˆ›ä½œã€è‡ªåŠ¨åŒ–å†™ä½œåŠ©æ‰‹å’Œæ•™è‚²é¢†åŸŸçš„å†™ä½œæŒ‡å¯¼ç­‰ã€‚é€šè¿‡æå‡é•¿æ–‡æœ¬ç”Ÿæˆçš„è´¨é‡ï¼ŒSuperWriter-Agentèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´é«˜æ•ˆã€ä¸“ä¸šçš„å†™ä½œæ”¯æŒï¼Œæœªæ¥å¯èƒ½åœ¨å¤šä¸ªè¡Œä¸šä¸­äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Long-form text generation remains a significant challenge for large language models (LLMs), particularly in maintaining coherence, ensuring logical consistency, and preserving text quality as sequence length increases. To address these limitations, we propose SuperWriter-Agent, an agent-based framework designed to enhance the quality and consistency of long-form text generation. SuperWriter-Agent introduces explicit structured thinking-through planning and refinement stages into the generation pipeline, guiding the model to follow a more deliberate and cognitively grounded process akin to that of a professional writer. Based on this framework, we construct a supervised fine-tuning dataset to train a 7B SuperWriter-LM. We further develop a hierarchical Direct Preference Optimization (DPO) procedure that uses Monte Carlo Tree Search (MCTS) to propagate final quality assessments and optimize each generation step accordingly. Empirical results across diverse benchmarks demonstrate that SuperWriter-LM achieves state-of-the-art performance, surpassing even larger-scale baseline models in both automatic evaluation and human evaluation. Furthermore, comprehensive ablation studies demonstrate the effectiveness of hierarchical DPO and underscore the value of incorporating structured thinking steps to improve the quality of long-form text generation.

