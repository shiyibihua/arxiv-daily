---
layout: default
title: MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP
---

# MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04385" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04385v2</a>
  <a href="https://arxiv.org/pdf/2506.04385.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04385v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04385v2', 'MELABenchv1: Benchmarking Large Language Models against Smaller Fine-Tuned Models for Low-Resource Maltese NLP')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kurt Micallef, Claudia Borg

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04 (æ›´æ–°: 2025-06-13)

**å¤‡æ³¨**: mT5 XXL & EuroLLM Instruct 9B 1-shot results

**DOI**: [10.18653/v1/2025.findings-acl.1053](https://doi.org/10.18653/v1/2025.findings-acl.1053)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMELABenchv1ä»¥è¯„ä¼°å°å‹å¾®è°ƒæ¨¡å‹åœ¨ä½èµ„æºé©¬è€³ä»–NLPä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½èµ„æºè¯­è¨€` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¾®è°ƒæ¨¡å‹` `é©¬è€³ä»–è¯­` `åŸºå‡†æµ‹è¯•` `ç”Ÿæˆä»»åŠ¡` `è¯­è¨€æŠ€æœ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½èµ„æºè¯­è¨€ä¸Šçš„è¡¨ç°æœ‰é™ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºå‡†MELABenchv1ï¼Œè¯„ä¼°55ä¸ªLLMsä¸å°å‹å¾®è°ƒæ¨¡å‹åœ¨é©¬è€³ä»–è¯­ä¸Šçš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¾ƒå°çš„å¾®è°ƒæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­è¡¨ç°æ›´å¥½ï¼Œä¸”é¢„è®­ç»ƒå’ŒæŒ‡ä»¤è°ƒä¼˜æ˜¯å½±å“æ€§èƒ½çš„å…³é”®å› ç´ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä½èµ„æºè¯­è¨€ä¸­çš„æœ‰æ•ˆæ€§ä»ç„¶æœ‰é™ã€‚æœ¬ç ”ç©¶è¯„ä¼°äº†55ä¸ªå…¬å¼€å¯ç”¨çš„LLMsåœ¨é©¬è€³ä»–è¯­è¿™ä¸€ä½èµ„æºè¯­è¨€ä¸Šçš„è¡¨ç°ï¼Œä½¿ç”¨äº†æ–°å¼•å…¥çš„åŸºå‡†ï¼Œæ¶µç›–11ä¸ªåˆ¤åˆ«å’Œç”Ÿæˆä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®¸å¤šæ¨¡å‹åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œè€Œè¾ƒå°çš„å¾®è°ƒæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­é€šå¸¸è¡¨ç°æ›´å¥½ã€‚é€šè¿‡å¤šç»´åˆ†æï¼Œæˆ‘ä»¬å‘ç°é¢„è®­ç»ƒå’ŒæŒ‡ä»¤è°ƒä¼˜å¯¹é©¬è€³ä»–è¯­çš„å…ˆå‰æ¥è§¦æ˜¯å½±å“æ€§èƒ½çš„æœ€é‡è¦å› ç´ ã€‚æˆ‘ä»¬è¿˜è€ƒå¯Ÿäº†å¾®è°ƒä¸æç¤ºä¹‹é—´çš„æƒè¡¡ï¼ŒæŒ‡å‡ºå¾®è°ƒè™½ç„¶åˆå§‹æˆæœ¬è¾ƒé«˜ï¼Œä½†èƒ½å¸¦æ¥æ›´å¥½çš„æ€§èƒ½å’Œè¾ƒä½çš„æ¨ç†æˆæœ¬ã€‚é€šè¿‡è¿™é¡¹å·¥ä½œï¼Œæˆ‘ä»¬æ—¨åœ¨å¼ºè°ƒæ›´å…·åŒ…å®¹æ€§çš„è¯­è¨€æŠ€æœ¯çš„å¿…è¦æ€§ï¼Œå¹¶å»ºè®®ç ”ç©¶ä½èµ„æºè¯­è¨€çš„ç ”ç©¶è€…è€ƒè™‘æ›´â€œä¼ ç»Ÿâ€çš„è¯­è¨€å»ºæ¨¡æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½èµ„æºé©¬è€³ä»–è¯­NLPä»»åŠ¡ä¸­çš„è¡¨ç°ä¸è¶³é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨ç”Ÿæˆä»»åŠ¡ä¸Šçš„ä½æ•ˆèƒ½ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨å°å‹å¾®è°ƒæ¨¡å‹çš„ä¼˜åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥MELABenchv1åŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°ä¸åŒæ¨¡å‹åœ¨é©¬è€³ä»–è¯­ä¸Šçš„è¡¨ç°ï¼Œå¼ºè°ƒå¾®è°ƒæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„ä¼˜è¶Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹é€‰æ‹©ã€åŸºå‡†æµ‹è¯•å’Œæ€§èƒ½è¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†é©¬è€³ä»–è¯­æ•°æ®ï¼Œç„¶åé€‰æ‹©55ä¸ªLLMsè¿›è¡Œæµ‹è¯•ï¼Œæœ€åé€šè¿‡11ä¸ªä»»åŠ¡è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†é’ˆå¯¹ä½èµ„æºè¯­è¨€çš„ä¸“é—¨åŸºå‡†MELABenchv1ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°å·¥å…·çš„ç©ºç™½ï¼Œå¹¶å¼ºè°ƒäº†å¾®è°ƒæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ï¼Œè®¾ç½®äº†ä¸åŒçš„å¾®è°ƒå‚æ•°ï¼Œå¹¶å¯¹æ¯”äº†å¾®è°ƒä¸æç¤ºçš„æ€§èƒ½å·®å¼‚ï¼Œç¡®ä¿äº†å®éªŒçš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè®¸å¤šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨é©¬è€³ä»–è¯­ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œè€Œå°å‹å¾®è°ƒæ¨¡å‹åœ¨æ‰€æœ‰ä»»åŠ¡ä¸­æ™®éè¡¨ç°æ›´å¥½ã€‚å…·ä½“è€Œè¨€ï¼Œå¾®è°ƒæ¨¡å‹çš„æ€§èƒ½æå‡å¹…åº¦å¯è¾¾20%ä»¥ä¸Šï¼Œä¸”åœ¨æ¨ç†æˆæœ¬ä¸Šæ˜¾è‘—ä½äºå¤§å‹æ¨¡å‹ï¼Œå¼ºè°ƒäº†å¾®è°ƒçš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä½èµ„æºè¯­è¨€çš„è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡é©¬è€³ä»–è¯­çš„å¤„ç†èƒ½åŠ›ï¼Œç ”ç©¶ä¸ºå…¶ä»–ä½èµ„æºè¯­è¨€çš„æŠ€æœ¯å‘å±•æä¾›äº†å€Ÿé‰´ï¼Œæ¨åŠ¨äº†è¯­è¨€æŠ€æœ¯çš„åŒ…å®¹æ€§å’Œå¤šæ ·æ€§ã€‚æœªæ¥ï¼Œè¿™ç§æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´å¤šä½èµ„æºè¯­è¨€ï¼Œä¿ƒè¿›å…¨çƒè¯­è¨€æŠ€æœ¯çš„å¹³ç­‰å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable performance across various Natural Language Processing (NLP) tasks, largely due to their generalisability and ability to perform tasks without additional training. However, their effectiveness for low-resource languages remains limited. In this study, we evaluate the performance of 55 publicly available LLMs on Maltese, a low-resource language, using a newly introduced benchmark covering 11 discriminative and generative tasks. Our experiments highlight that many models perform poorly, particularly on generative tasks, and that smaller fine-tuned models often perform better across all tasks. From our multidimensional analysis, we investigate various factors impacting performance. We conclude that prior exposure to Maltese during pre-training and instruction-tuning emerges as the most important factor. We also examine the trade-offs between fine-tuning and prompting, highlighting that while fine-tuning requires a higher initial cost, it yields better performance and lower inference costs. Through this work, we aim to highlight the need for more inclusive language technologies and recommend that researchers working with low-resource languages consider more "traditional" language modelling approaches.

