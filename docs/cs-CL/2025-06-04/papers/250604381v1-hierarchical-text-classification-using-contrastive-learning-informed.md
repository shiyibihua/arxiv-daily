---
layout: default
title: Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy
---

# Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04381" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04381v1</a>
  <a href="https://arxiv.org/pdf/2506.04381.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04381v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04381v1', 'Hierarchical Text Classification Using Contrastive Learning Informed Path Guided Hierarchy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Neeraj Agrawal, Saurabh Kumar, Priyanka Bhatt, Tanishka Agarwal

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: arXiv admin note: text overlap with arXiv:2203.03825 by other authors

**æœŸåˆŠ**: ECAI 2023, pp. 19-26. IOS Press, 2023

**DOI**: [10.3233/FAIA230249](https://doi.org/10.3233/FAIA230249)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¯¹æ¯”å­¦ä¹ çš„è·¯å¾„å¼•å¯¼å±‚æ¬¡æ–‡æœ¬åˆ†ç±»æ–¹æ³•ä»¥æå‡æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å±‚æ¬¡æ–‡æœ¬åˆ†ç±»` `å¯¹æ¯”å­¦ä¹ ` `è·¯å¾„å¼•å¯¼` `æ–‡æœ¬è¡¨ç¤º` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å±‚æ¬¡æ–‡æœ¬åˆ†ç±»æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ ‡ç­¾å±‚æ¬¡æ—¶å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨æ ‡ç­¾ä¹‹é—´çš„å…³ç³»ã€‚
2. æœ¬æ–‡æå‡ºçš„HTC-CLIPæ–¹æ³•ç»“åˆäº†å¯¹æ¯”å­¦ä¹ å’Œè·¯å¾„å¼•å¯¼çš„å±‚æ¬¡ç»“æ„ï¼Œæ—¨åœ¨å­¦ä¹ æ›´æœ‰æ•ˆçš„æ–‡æœ¬è¡¨ç¤ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHTC-CLIPåœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šç›¸è¾ƒäºç°æœ‰æ¨¡å‹æå‡äº†0.99%è‡³2.37%çš„Macro F1åˆ†æ•°ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å±‚æ¬¡æ–‡æœ¬åˆ†ç±»ï¼ˆHTCï¼‰è¿‘å¹´æ¥å—åˆ°å…³æ³¨ï¼Œå› å…¶èƒ½å¤Ÿå¤„ç†å¤æ‚çš„æ ‡ç­¾å±‚æ¬¡ç»“æ„ï¼Œå¹¿æ³›åº”ç”¨äºç”µå­å•†åŠ¡ã€å®¢æˆ·æœåŠ¡å’ŒåŒ»ç–—ç­‰é¢†åŸŸã€‚ç°æœ‰çš„HTCæ¨¡å‹é€šå¸¸åˆ†åˆ«ç¼–ç æ ‡ç­¾å±‚æ¬¡æˆ–åœ¨æ–‡æœ¬ç¼–ç ä¸­å¼•å¯¼æ ‡ç­¾å±‚æ¬¡ç»“æ„ï¼ŒäºŒè€…å„æœ‰ä¼˜ç¼ºç‚¹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„è·¯å¾„å¼•å¯¼å±‚æ¬¡æ–‡æœ¬åˆ†ç±»æ–¹æ³•ï¼ˆHTC-CLIPï¼‰ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ å­¦ä¹ å±‚æ¬¡æ„ŸçŸ¥çš„æ–‡æœ¬è¡¨ç¤ºå’Œæ–‡æœ¬å¼•å¯¼çš„å±‚æ¬¡è¡¨ç¤ºã€‚åœ¨HTC-CLIPçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¸¤ç»„ä¸åŒçš„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒï¼Œå¹¶åœ¨æ¨ç†æ—¶ç»“åˆè¿™ä¸¤ç§è¡¨ç¤ºçš„è¾“å‡ºï¼Œä»¥è·å¾—æœ€ä½³æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHTC-CLIPåœ¨ä¸¤ä¸ªå…¬å…±åŸºå‡†æ•°æ®é›†ä¸Šçš„Macro F1åˆ†æ•°æ¯”ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹æé«˜äº†0.99%è‡³2.37%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å±‚æ¬¡æ–‡æœ¬åˆ†ç±»ä¸­ç°æœ‰æ–¹æ³•å¯¹æ ‡ç­¾å±‚æ¬¡å…³ç³»åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ¨¡å‹é€šå¸¸åˆ†åˆ«å¤„ç†æ–‡æœ¬å’Œæ ‡ç­¾å±‚æ¬¡ï¼Œæœªèƒ½æœ‰æ•ˆç»“åˆäºŒè€…çš„ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHTC-CLIPé€šè¿‡å¯¹æ¯”å­¦ä¹ çš„æ–¹å¼ï¼Œå­¦ä¹ å±‚æ¬¡æ„ŸçŸ¥çš„æ–‡æœ¬è¡¨ç¤ºå’Œæ–‡æœ¬å¼•å¯¼çš„å±‚æ¬¡è¡¨ç¤ºï¼Œæ—¨åœ¨å°†ä¸¤ç§è¡¨ç¤ºçš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ï¼Œä»è€Œæå‡åˆ†ç±»æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHTC-CLIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ–‡æœ¬ç¼–ç æ¨¡å—å’Œå±‚æ¬¡å¼•å¯¼æ¨¡å—ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹åŒæ—¶å­¦ä¹ ä¸¤ç»„ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒï¼Œæ¨ç†æ—¶ç»“åˆè¿™ä¸¤ç»„è¾“å‡ºä»¥è·å¾—æ›´ä¼˜ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šHTC-CLIPçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¯¹æ¯”å­¦ä¹ ä¸å±‚æ¬¡å¼•å¯¼ç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å±‚æ¬¡æ–‡æœ¬åˆ†ç±»æ¡†æ¶ï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°æ•æ‰æ ‡ç­¾å±‚æ¬¡ç»“æ„çš„ä¿¡æ¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¯¹æ¯”å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†è·¯å¾„å¼•å¯¼æœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å±‚æ¬¡ä¿¡æ¯çš„ç†è§£ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HTC-CLIPåœ¨ä¸¤ä¸ªå…¬å…±åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›¸è¾ƒäºç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼ŒMacro F1åˆ†æ•°æå‡äº†0.99%è‡³2.37%ã€‚è¿™ä¸€æå‡è¡¨æ˜ï¼Œç»“åˆå¯¹æ¯”å­¦ä¹ å’Œè·¯å¾„å¼•å¯¼çš„å±‚æ¬¡ç»“æ„èƒ½å¤Ÿæ˜¾è‘—å¢å¼ºæ¨¡å‹çš„åˆ†ç±»æ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­å•†åŠ¡ä¸­çš„å•†å“åˆ†ç±»ã€å®¢æˆ·æœåŠ¡ä¸­çš„é—®é¢˜åˆ†ç±»ä»¥åŠåŒ»ç–—é¢†åŸŸçš„ç–¾ç—…åˆ†ç±»ç­‰ã€‚é€šè¿‡æå‡å±‚æ¬¡æ–‡æœ¬åˆ†ç±»çš„å‡†ç¡®æ€§ï¼ŒHTC-CLIPèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šå’Œæœºæ„æ›´æœ‰æ•ˆåœ°å¤„ç†å’Œåˆ†æå¤§é‡æ–‡æœ¬æ•°æ®ï¼Œæå‡æœåŠ¡è´¨é‡å’Œå†³ç­–æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–éœ€è¦å¤„ç†å¤æ‚æ ‡ç­¾å±‚æ¬¡çš„é¢†åŸŸï¼Œå¦‚ç¤¾äº¤åª’ä½“åˆ†æå’Œå†…å®¹æ¨èç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Hierarchical Text Classification (HTC) has recently gained traction given the ability to handle complex label hierarchy. This has found applications in domains like E- commerce, customer care and medicine industry among other real-world applications. Existing HTC models either encode label hierarchy separately and mix it with text encoding or guide the label hierarchy structure in the text encoder. Both approaches capture different characteristics of label hierarchy and are complementary to each other. In this paper, we propose a Hierarchical Text Classification using Contrastive Learning Informed Path guided hierarchy (HTC-CLIP), which learns hierarchy-aware text representation and text informed path guided hierarchy representation using contrastive learning. During the training of HTC-CLIP, we learn two different sets of class probabilities distributions and during inference, we use the pooled output of both probabilities for each class to get the best of both representations. Our results show that the two previous approaches can be effectively combined into one architecture to achieve improved performance. Tests on two public benchmark datasets showed an improvement of 0.99 - 2.37% in Macro F1 score using HTC-CLIP over the existing state-of-the-art models.

