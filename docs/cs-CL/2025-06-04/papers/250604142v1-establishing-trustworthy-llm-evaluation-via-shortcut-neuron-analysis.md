---
layout: default
title: Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis
---

# Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04142" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04142v1</a>
  <a href="https://arxiv.org/pdf/2506.04142.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04142v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04142v1', 'Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kejian Zhu, Shangqing Tu, Zhuoran Jin, Lei Hou, Juanzi Li, Jun Zhao

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: Accepted to ACL 2025 Main Conference

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/GaryStack/Trustworthy-Evaluation)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å¿«æ·ç¥ç»å…ƒåˆ†ææå‡ºå¯ä¿¡èµ–çš„LLMè¯„ä¼°æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®æ±¡æŸ“` `å¿«æ·ç¥ç»å…ƒ` `æ¨¡å‹è¯„ä¼°` `å¯ä¿¡èµ–æ€§` `å› æœåˆ†æ` `åŠ¨æ€åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æ–¹æ³•ä¾èµ–å…¬å…±åŸºå‡†ï¼Œå®¹æ˜“å—åˆ°æ•°æ®æ±¡æŸ“å½±å“ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å…¬æ­£ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åˆ†ææ±¡æŸ“æ¨¡å‹çš„æœºåˆ¶ï¼Œæå‡ºäº†ä¸€ç§è¯†åˆ«å¿«æ·ç¥ç»å…ƒçš„æ–¹æ³•ï¼Œå¹¶å¼•å…¥å¿«æ·ç¥ç»å…ƒä¿®è¡¥çš„è¯„ä¼°æ–¹æ³•ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå‡è½»äº†æ±¡æŸ“å½±å“ï¼Œå¹¶ä¸MixEvalåŸºå‡†çš„ç›¸å…³æ€§è¶…è¿‡0.95ï¼Œè¡¨æ˜å…¶å¯ä¿¡åº¦é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‘å±•ä¾èµ–äºå¯ä¿¡èµ–çš„è¯„ä¼°ã€‚ç„¶è€Œï¼Œç›®å‰çš„è¯„ä¼°å¤§å¤šä¾èµ–å…¬å…±åŸºå‡†ï¼Œå®¹æ˜“å—åˆ°æ•°æ®æ±¡æŸ“é—®é¢˜çš„å½±å“ï¼Œä¸¥é‡å½±å“å…¬å¹³æ€§ã€‚ä»¥å¾€ç ”ç©¶é›†ä¸­åœ¨æ„å»ºåŠ¨æ€åŸºå‡†ä»¥åº”å¯¹æ±¡æŸ“ï¼Œä½†æŒç»­æ„å»ºæ–°åŸºå‡†æˆæœ¬é«˜ä¸”å‘¨æœŸæ€§å¼ºã€‚æœ¬ç ”ç©¶é€šè¿‡åˆ†ææ±¡æŸ“æ¨¡å‹çš„æœºåˆ¶æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚å®éªŒå‘ç°ï¼Œæ±¡æŸ“æ¨¡å‹çš„è¿‡é«˜ä¼°è®¡å¯èƒ½æºäºå‚æ•°åœ¨è®­ç»ƒä¸­è·å¾—äº†å¿«æ·è§£å†³æ–¹æ¡ˆã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡æ¯”è¾ƒå’Œå› æœåˆ†æè¯†åˆ«å¿«æ·ç¥ç»å…ƒçš„æ–°æ–¹æ³•ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ç§°ä¸ºå¿«æ·ç¥ç»å…ƒä¿®è¡¥çš„è¯„ä¼°æ–¹æ³•ä»¥æŠ‘åˆ¶å¿«æ·ç¥ç»å…ƒã€‚å®éªŒéªŒè¯äº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡è½»æ±¡æŸ“æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”è¯„ä¼°ç»“æœä¸æœ€è¿‘å‘å¸ƒçš„å¯ä¿¡åŸºå‡†MixEvalå±•ç°å‡ºå¼ºçº¿æ€§ç›¸å…³æ€§ï¼ŒSpearmanç³»æ•°è¶…è¿‡0.95ï¼Œè¡¨æ˜æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤ŸçœŸå®åæ˜ æ¨¡å‹çš„èƒ½åŠ›ï¼Œå€¼å¾—ä¿¡èµ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°ä¸­çš„æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å…¬å…±åŸºå‡†ï¼Œå®¹æ˜“å—åˆ°æ±¡æŸ“å½±å“ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœå¤±çœŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†ææ±¡æŸ“æ¨¡å‹çš„å†…éƒ¨æœºåˆ¶ï¼Œè¯†åˆ«å¹¶æŠ‘åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­å½¢æˆçš„å¿«æ·ç¥ç»å…ƒï¼Œä»¥æé«˜è¯„ä¼°çš„å¯ä¿¡åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡æ¯”è¾ƒå’Œå› æœåˆ†æè¯†åˆ«å¿«æ·ç¥ç»å…ƒï¼›å…¶æ¬¡ï¼Œåº”ç”¨å¿«æ·ç¥ç»å…ƒä¿®è¡¥æ–¹æ³•å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼ŒæŠ‘åˆ¶è¿™äº›å¿«æ·ç¥ç»å…ƒçš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†å¿«æ·ç¥ç»å…ƒçš„è¯†åˆ«æ–¹æ³•å’Œä¿®è¡¥è¯„ä¼°æ–¹æ³•ï¼Œè¿™ä¸ä»¥å¾€ä¾èµ–åŠ¨æ€åŸºå‡†çš„è¯„ä¼°æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯æ¥è§£å†³æ±¡æŸ“é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•å®ç°ä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹æ¨¡å‹å‚æ•°çš„åˆ†æã€æŸå¤±å‡½æ•°çš„è°ƒæ•´ï¼Œä»¥åŠåœ¨ä¸åŒè¶…å‚æ•°è®¾ç½®ä¸‹çš„å®éªŒéªŒè¯ï¼Œä»¥ç¡®ä¿æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé€šç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨å‡è½»æ•°æ®æ±¡æŸ“æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸MixEvalåŸºå‡†çš„Spearmanç³»æ•°è¶…è¿‡0.95ï¼Œè¡¨æ˜å…¶è¯„ä¼°ç»“æœä¸çœŸå®èƒ½åŠ›é«˜åº¦ç›¸å…³ï¼Œæ˜¾è‘—æå‡äº†è¯„ä¼°çš„å¯ä¿¡åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æä¾›æ›´å¯ä¿¡èµ–çš„è¯„ä¼°æ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜æ›´å‡†ç¡®åœ°è¯„ä¼°å’Œä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„AIè¯„ä¼°é¢†åŸŸä¸­å¾—åˆ°åº”ç”¨ï¼Œæå‡æ¨¡å‹çš„å…¬å¹³æ€§ä¸å¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The development of large language models (LLMs) depends on trustworthy evaluation. However, most current evaluations rely on public benchmarks, which are prone to data contamination issues that significantly compromise fairness. Previous researches have focused on constructing dynamic benchmarks to address contamination. However, continuously building new benchmarks is costly and cyclical. In this work, we aim to tackle contamination by analyzing the mechanisms of contaminated models themselves. Through our experiments, we discover that the overestimation of contaminated models is likely due to parameters acquiring shortcut solutions in training. We further propose a novel method for identifying shortcut neurons through comparative and causal analysis. Building on this, we introduce an evaluation method called shortcut neuron patching to suppress shortcut neurons. Experiments validate the effectiveness of our approach in mitigating contamination. Additionally, our evaluation results exhibit a strong linear correlation with MixEval, a recently released trustworthy benchmark, achieving a Spearman coefficient ($Ï$) exceeding 0.95. This high correlation indicates that our method closely reveals true capabilities of the models and is trustworthy. We conduct further experiments to demonstrate the generalizability of our method across various benchmarks and hyperparameter settings. Code: https://github.com/GaryStack/Trustworthy-Evaluation

