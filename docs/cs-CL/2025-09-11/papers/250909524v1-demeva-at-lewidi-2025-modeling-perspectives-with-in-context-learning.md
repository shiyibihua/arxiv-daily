---
layout: default
title: DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning
---

# DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09524" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09524v1</a>
  <a href="https://arxiv.org/pdf/2509.09524.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09524v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09524v1', 'DeMeVa at LeWiDi-2025: Modeling Perspectives with In-Context Learning and Label Distribution Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniil Ignatev, Nan Li, Hugh Mee Wong, Anh Dang, Shane Kaszefski Yaschuk

**åˆ†ç±»**: cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: 11 pages, 4 figures; to appear at NLPerspectives@EMNLP-2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DeMeVaå›¢é˜Ÿæ¢ç´¢ä¸Šä¸‹æ–‡å­¦ä¹ å’Œæ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ï¼Œç”¨äºå»ºæ¨¡è§†è§’å·®å¼‚æ€§æ ‡æ³¨ä»»åŠ¡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸Šä¸‹æ–‡å­¦ä¹ ` `æ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ` `è§†è§’ä¸»ä¹‰` `è‡ªç„¶è¯­è¨€å¤„ç†` `RoBERTa` `è½¯æ ‡ç­¾é¢„æµ‹` `å­¦ä¹ å¼‚è®®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå»ºæ¨¡ä¸åŒæ ‡æ³¨è€…ä¹‹é—´çš„è§†è§’å·®å¼‚ï¼Œå¯¼è‡´æ ‡æ³¨ç»“æœå­˜åœ¨ä¸ä¸€è‡´æ€§ã€‚
2. åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰é¢„æµ‹ä¸ªä½“æ ‡æ³¨è€…çš„æ ‡æ³¨ï¼Œå¹¶å°†é¢„æµ‹ç»“æœèšåˆä¸ºè½¯æ ‡ç­¾ï¼Œä»è€Œæ•æ‰è§†è§’å·®å¼‚ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒICLæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹ä¸ªä½“æ ‡æ³¨ï¼Œä¸”æ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ï¼ˆLDLï¼‰åœ¨è½¯æ ‡ç­¾é¢„æµ‹æ–¹é¢å…·æœ‰æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†DeMeVaå›¢é˜Ÿåœ¨ç¬¬ä¸‰å±Šâ€œå­¦ä¹ å¼‚è®®â€ï¼ˆLeWiDi 2025ï¼‰å…±äº«ä»»åŠ¡ä¸­çš„æ–¹æ³•ã€‚æˆ‘ä»¬æ¢ç´¢äº†ä¸¤ä¸ªæ–¹å‘ï¼šä¸€æ˜¯ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰ï¼Œå¹¶æ¯”è¾ƒäº†ä¸åŒçš„ç¤ºä¾‹æŠ½æ ·ç­–ç•¥ï¼›äºŒæ˜¯ä½¿ç”¨RoBERTaæ¨¡å‹è¿›è¡Œæ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ï¼ˆLDLï¼‰ï¼Œå¹¶è¯„ä¼°äº†å‡ ç§å¾®è°ƒæ–¹æ³•ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸¤æ–¹é¢ï¼šï¼ˆ1ï¼‰æˆ‘ä»¬è¡¨æ˜ICLå¯ä»¥æœ‰æ•ˆåœ°é¢„æµ‹ç‰¹å®šæ ‡æ³¨è€…çš„æ ‡æ³¨ï¼ˆè§†è§’ä¸»ä¹‰æ ‡æ³¨ï¼‰ï¼Œå¹¶ä¸”å°†è¿™äº›é¢„æµ‹èšåˆä¸ºè½¯æ ‡ç­¾å¯ä»¥äº§ç”Ÿæœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼›ï¼ˆ2ï¼‰æˆ‘ä»¬è®¤ä¸ºLDLæ–¹æ³•å¯¹äºè½¯æ ‡ç­¾é¢„æµ‹å¾ˆæœ‰å‰æ™¯ï¼Œå€¼å¾—è§†è§’ä¸»ä¹‰ç¤¾åŒºè¿›ä¸€æ­¥æ¢ç´¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å­¦ä¹ å¼‚è®®ï¼ˆLeWiDiï¼‰ä»»åŠ¡ä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆå»ºæ¨¡ä¸åŒæ ‡æ³¨è€…è§†è§’å·®å¼‚çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æ•æ‰ä¸ªä½“æ ‡æ³¨è€…çš„ä¸»è§‚åˆ¤æ–­ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½å—é™ã€‚è¯¥ä»»åŠ¡çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå¦‚ä½•åˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼Œå­¦ä¹ åˆ°ä¸åŒæ ‡æ³¨è€…å¯¹åŒä¸€æ–‡æœ¬çš„ä¸åŒç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰å’Œæ ‡ç­¾åˆ†å¸ƒå­¦ä¹ ï¼ˆLDLï¼‰ä¸¤ç§æ–¹æ³•ï¼Œåˆ†åˆ«ä»ä¸åŒè§’åº¦å»ºæ¨¡è§†è§’å·®å¼‚ã€‚ICLé€šè¿‡æä¾›å°‘é‡ç¤ºä¾‹ï¼Œå¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹æ¨¡ä»¿ç‰¹å®šæ ‡æ³¨è€…çš„æ ‡æ³¨é£æ ¼ã€‚LDLåˆ™ç›´æ¥å­¦ä¹ è½¯æ ‡ç­¾çš„åˆ†å¸ƒï¼Œä»è€Œæ•æ‰æ ‡æ³¨è€…ä¹‹é—´çš„ç»†å¾®å·®å¼‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦åˆ†æ”¯ï¼šICLåˆ†æ”¯å’ŒLDLåˆ†æ”¯ã€‚ICLåˆ†æ”¯é¦–å…ˆä½¿ç”¨ä¸åŒçš„æŠ½æ ·ç­–ç•¥é€‰æ‹©ç¤ºä¾‹ï¼Œç„¶ååˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹é¢„æµ‹ä¸ªä½“æ ‡æ³¨è€…çš„æ ‡æ³¨ã€‚æ¥ç€ï¼Œå°†è¿™äº›é¢„æµ‹ç»“æœèšåˆä¸ºè½¯æ ‡ç­¾ã€‚LDLåˆ†æ”¯åˆ™ä½¿ç”¨RoBERTaæ¨¡å‹ï¼Œé€šè¿‡ä¸åŒçš„å¾®è°ƒæ–¹æ³•å­¦ä¹ è½¯æ ‡ç­¾çš„åˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†ICLæ–¹æ³•åº”ç”¨äºè§†è§’ä¸»ä¹‰æ ‡æ³¨ä»»åŠ¡ï¼Œå¹¶è¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†å°†ä¸ªä½“æ ‡æ³¨è€…çš„é¢„æµ‹ç»“æœèšåˆä¸ºè½¯æ ‡ç­¾çš„ç­–ç•¥ï¼Œä»è€Œæ›´å¥½åœ°åˆ©ç”¨äº†æ ‡æ³¨æ•°æ®ä¸­çš„ä¿¡æ¯ã€‚åŒæ—¶ï¼Œè®ºæ–‡å¼ºè°ƒäº†LDLæ–¹æ³•åœ¨è½¯æ ‡ç­¾é¢„æµ‹æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æ–¹å‘æä¾›äº†æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ICLåˆ†æ”¯ä¸­ï¼Œè®ºæ–‡æ¯”è¾ƒäº†ä¸åŒçš„ç¤ºä¾‹æŠ½æ ·ç­–ç•¥ï¼Œä¾‹å¦‚éšæœºæŠ½æ ·å’ŒåŸºäºç›¸ä¼¼åº¦çš„æŠ½æ ·ã€‚åœ¨LDLåˆ†æ”¯ä¸­ï¼Œè®ºæ–‡è¯„ä¼°äº†å‡ ç§å¾®è°ƒæ–¹æ³•ï¼Œä¾‹å¦‚ç›´æ¥å¾®è°ƒå’Œå¯¹æŠ—è®­ç»ƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚KLæ•£åº¦ï¼Œç”¨äºè¡¡é‡é¢„æµ‹æ ‡ç­¾åˆ†å¸ƒå’ŒçœŸå®æ ‡ç­¾åˆ†å¸ƒä¹‹é—´çš„å·®å¼‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒICLæ–¹æ³•åœ¨é¢„æµ‹ä¸ªä½“æ ‡æ³¨è€…æ ‡æ³¨æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”å°†ä¸ªä½“é¢„æµ‹èšåˆä¸ºè½¯æ ‡ç­¾èƒ½å¤Ÿè·å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒLDLæ–¹æ³•åœ¨è½¯æ ‡ç­¾é¢„æµ‹æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œå€¼å¾—è¿›ä¸€æ­¥ç ”ç©¶ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†ICLå’ŒLDLåœ¨å»ºæ¨¡è§†è§’å·®å¼‚æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæƒ…æ„Ÿåˆ†æã€è§‚ç‚¹æŒ–æ˜ã€æ–‡æœ¬æ‘˜è¦ç­‰é¢†åŸŸï¼Œæå‡æ¨¡å‹åœ¨å¤„ç†ä¸»è§‚æ€§æ–‡æœ¬æ—¶çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚é€šè¿‡å»ºæ¨¡è§†è§’å·®å¼‚ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾ï¼Œä»è€Œæ”¹è¿›æ¨èç³»ç»Ÿã€å¯¹è¯ç³»ç»Ÿç­‰åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œä¾‹å¦‚è¾…åŠ©å†³ç­–ã€æ™ºèƒ½å®¢æœç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This system paper presents the DeMeVa team's approaches to the third edition of the Learning with Disagreements shared task (LeWiDi 2025; Leonardelli et al., 2025). We explore two directions: in-context learning (ICL) with large language models, where we compare example sampling strategies; and label distribution learning (LDL) methods with RoBERTa (Liu et al., 2019b), where we evaluate several fine-tuning methods. Our contributions are twofold: (1) we show that ICL can effectively predict annotator-specific annotations (perspectivist annotations), and that aggregating these predictions into soft labels yields competitive performance; and (2) we argue that LDL methods are promising for soft label predictions and merit further exploration by the perspectivist community.

