---
layout: default
title: GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models
---

# GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09438" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.09438v1</a>
  <a href="https://arxiv.org/pdf/2509.09438.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09438v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09438v1', 'GrACE: A Generative Approach to Better Confidence Elicitation in Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhaohan Zhang, Ziquan Liu, Ioannis Patras

**ÂàÜÁ±ª**: cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-11

**Â§áÊ≥®**: 20 pages, 11 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**GrACEÔºö‰∏ÄÁßçÁîüÊàêÂºèÊñπÊ≥ïÔºåÊèêÂçáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁΩÆ‰ø°Â∫¶ËØÑ‰º∞ÁöÑÂèØÈù†ÊÄß‰∏éÂèØÊâ©Â±ïÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßËØ≠Ë®ÄÊ®°Âûã` `ÁΩÆ‰ø°Â∫¶ËØÑ‰º∞` `AIÂÆâÂÖ®` `ÁîüÊàêÂºèÊñπÊ≥ï` `Ê®°ÂûãÊ†°ÂáÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁΩÆ‰ø°Â∫¶ËØÑ‰º∞ÊñπÊ≥ïÂ≠òÂú®ËÆ°ÁÆóÂºÄÈîÄÂ§ßÂíåÊ†°ÂáÜÊïàÊûúÂ∑ÆÁöÑÈóÆÈ¢òÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®È´òÈ£éÈô©Âú∫ÊôØÁöÑÂ∫îÁî®„ÄÇ
2. GrACEÈÄöËøáÊØîËæÉÊ®°ÂûãÈöêËóèÁä∂ÊÄÅ‰∏éÁâπÊÆätokenÂµåÂÖ•ÁöÑÁõ∏‰ººÂ∫¶Êù•ËØÑ‰º∞ÁΩÆ‰ø°Â∫¶ÔºåÊó†ÈúÄÈ¢ùÂ§ñÈááÊ†∑ÊàñËæÖÂä©Ê®°Âûã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåGrACEÂú®ÂºÄÊîæÂºèÁîüÊàê‰ªªÂä°‰∏≠‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂ËÉΩÊúâÊïàÂáèÂ∞ëÊµãËØïÊó∂ÊâÄÈúÄÁöÑÊ†∑Êú¨Êï∞Èáè„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂêç‰∏∫GrACEÁöÑÁîüÊàêÂºèÊñπÊ≥ïÔºåÊó®Âú®‰∏∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÊèê‰æõÂèØÊâ©Â±ï‰∏îÂèØÈù†ÁöÑÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Ôºå‰ªéËÄåÊèêÂçáAIÂú®È´òÈ£éÈô©Â∫îÁî®ÔºàÂ¶ÇÂåªÁñóÂíåÈáëËûçÔºâ‰∏≠ÁöÑÂÆâÂÖ®ÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïË¶Å‰πàËÆ°ÁÆóÂºÄÈîÄÂ∑®Â§ßÔºåË¶Å‰πàÊ†°ÂáÜÊïàÊûú‰∏ç‰Ω≥Ôºå‰ΩøÂÖ∂Âú®ÂÆûÈôÖÈÉ®ÁΩ≤‰∏≠‰∏çÂàáÂÆûÈôÖ‰∏î‰∏çÂèØÈù†„ÄÇGrACEÈááÁî®‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÊú∫Âà∂ÔºåÊ®°ÂûãÈÄöËøáÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÁä∂ÊÄÅ‰∏éËØçÊ±áË°®‰∏≠ÈôÑÂä†ÁöÑÁâπÊÆätokenÁöÑÂµåÂÖ•‰πãÈó¥ÁöÑÁõ∏‰ººÊÄßÊù•ÂÆûÊó∂Ë°®ËææÁΩÆ‰ø°Â∫¶„ÄÇÈÄöËøáÂæÆË∞ÉÊ®°ÂûãÔºåÂà©Áî®‰∏éÂáÜÁ°ÆÁéáÁõ∏ÂÖ≥ÁöÑÊ†°ÂáÜÁõÆÊ†áÊù•Ê†°ÂáÜÁΩÆ‰ø°Â∫¶„ÄÇÂú®‰∏â‰∏™LLMÂíå‰∏§‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåGrACE‰∫ßÁîüÁöÑÁΩÆ‰ø°Â∫¶Âú®ÂºÄÊîæÂºèÁîüÊàê‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄ‰Ω≥ÁöÑÂå∫ÂàÜËÉΩÂäõÂíåÊ†°ÂáÜÊïàÊûúÔºå‰ºò‰∫éÂÖ≠ÁßçÁ´û‰∫âÊñπÊ≥ïÔºå‰∏îÊó†ÈúÄÈ¢ùÂ§ñÁöÑÈááÊ†∑ÊàñËæÖÂä©Ê®°Âûã„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏§ÁßçÂü∫‰∫éGrACEÁΩÆ‰ø°Â∫¶Êù•ÊîπËøõÊµãËØïÊó∂Áº©ÊîæÁöÑÁ≠ñÁï•„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå‰ΩøÁî®GrACE‰∏ç‰ªÖÊèêÈ´ò‰∫ÜÊúÄÁªàÂÜ≥Á≠ñÁöÑÂáÜÁ°ÆÊÄßÔºåËøòÊòæËëóÂáèÂ∞ë‰∫ÜÊµãËØïÊó∂Áº©ÊîæÊñπÊ°à‰∏≠ÊâÄÈúÄÁöÑÊ†∑Êú¨Êï∞ÈáèÔºåË°®ÊòéGrACEÊúâÊΩúÂäõÊàê‰∏∫‰∏ÄÁßçÂÆûÁî®ÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÁî®‰∫éÈÉ®ÁΩ≤ÂÖ∑ÊúâÂèØÊâ©Â±ï„ÄÅÂèØÈù†ÂíåÂÆûÊó∂ÁΩÆ‰ø°Â∫¶‰º∞ËÆ°ÁöÑLLM„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÁΩÆ‰ø°Â∫¶ËØÑ‰º∞ÊñπÈù¢Èù¢‰∏¥ÊåëÊàò„ÄÇ‰º†ÁªüÊñπÊ≥ïÔºåÂ¶ÇÂü∫‰∫éÈááÊ†∑ÁöÑÊäÄÊúØÔºåËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈöæ‰ª•Êâ©Â±ïÂà∞Â§ßÂûãÊ®°ÂûãÂíåÂ§çÊùÇ‰ªªÂä°„ÄÇËÄåÂÖ∂‰ªñÊñπÊ≥ïÂàôÊ†°ÂáÜÊïàÊûú‰∏ç‰Ω≥ÔºåÂØºËá¥ÁΩÆ‰ø°Â∫¶‰º∞ËÆ°‰∏éÂÆûÈôÖÂáÜÁ°ÆÁéá‰∏çÂåπÈÖçÔºåÂΩ±Âìç‰∫ÜÊ®°ÂûãÂú®ÂÆâÂÖ®Êî∏ÂÖ≥Âú∫ÊôØ‰∏≠ÁöÑÂèØÈù†ÊÄß„ÄÇÂõ†Ê≠§ÔºåÈúÄË¶Å‰∏ÄÁßçÊó¢È´òÊïàÂèàÂáÜÁ°ÆÁöÑÁΩÆ‰ø°Â∫¶ËØÑ‰º∞ÊñπÊ≥ï„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöGrACEÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®Ê®°ÂûãËá™Ë∫´ÁöÑÈöêËóèÁä∂ÊÄÅÊù•ÁîüÊàêÁΩÆ‰ø°Â∫¶‰º∞ËÆ°ÔºåÈÅøÂÖç‰∫ÜÈ¢ùÂ§ñÁöÑËÆ°ÁÆóÂºÄÈîÄ„ÄÇÂÖ∑‰ΩìÊù•ËØ¥ÔºåÂÆÉÈÄöËøáÊØîËæÉÊ®°ÂûãÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÁä∂ÊÄÅ‰∏é‰∏Ä‰∏™ÁâπÊÆätokenÁöÑÂµåÂÖ•‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶Êù•Ë°®Á§∫ÁΩÆ‰ø°Â∫¶„ÄÇËøôÁßçÊñπÊ≥ïÂÅáËÆæÊ®°ÂûãÂú®ÁîüÊàêÈ´òË¥®ÈáèÁ≠îÊ°àÊó∂ÔºåÂÖ∂ÈöêËóèÁä∂ÊÄÅ‰ºöÊõ¥Êé•Ëøë‰ª£Ë°®‚ÄúÈ´òÁΩÆ‰ø°Â∫¶‚ÄùÁöÑÁâπÊÆätokenÁöÑÂµåÂÖ•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGrACEÁöÑÊäÄÊúØÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Ê≠•È™§Ôºö1) Âú®LLMÁöÑËØçÊ±áË°®‰∏≠Ê∑ªÂä†‰∏Ä‰∏™ÁâπÊÆäÁöÑÁΩÆ‰ø°Â∫¶token„ÄÇ2) Âú®ÂæÆË∞ÉÈò∂ÊÆµÔºå‰ΩøÁî®Ê†°ÂáÜÁõÆÊ†áÔºàÂç≥ÂáÜÁ°ÆÁéáÔºâÊù•ËÆ≠ÁªÉÊ®°ÂûãÔºå‰ΩøÂÖ∂Â≠¶‰ºöÂ∞ÜÈ´òÁΩÆ‰ø°Â∫¶ÁöÑÁ≠îÊ°à‰∏éËØ•tokenÁöÑÂµåÂÖ•ÂÖ≥ËÅîËµ∑Êù•„ÄÇ3) Âú®Êé®ÁêÜÈò∂ÊÆµÔºåËÆ°ÁÆóÊ®°ÂûãÊúÄÂêé‰∏Ä‰∏™ÈöêËóèÁä∂ÊÄÅ‰∏éËØ•tokenÂµåÂÖ•‰πãÈó¥ÁöÑÁõ∏‰ººÂ∫¶Ôºå‰Ωú‰∏∫ÁΩÆ‰ø°Â∫¶ÂæóÂàÜ„ÄÇ4) Âà©Áî®ËØ•ÁΩÆ‰ø°Â∫¶ÂæóÂàÜËøõË°åÊµãËØïÊó∂Áº©ÊîæÔºå‰ª•ÊèêÈ´òÊúÄÁªàÂÜ≥Á≠ñÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGrACEÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÁΩÆ‰ø°Â∫¶ËØÑ‰º∞Êú∫Âà∂„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ï‰∏çÂêåÔºåGrACEÁõ¥Êé•Âà©Áî®Ê®°ÂûãËá™Ë∫´ÁöÑË°®Á§∫Á©∫Èó¥Êù•ÁîüÊàêÁΩÆ‰ø°Â∫¶‰º∞ËÆ°ÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑÈááÊ†∑ÊàñËæÖÂä©Ê®°Âûã„ÄÇËøôÁßçÊñπÊ≥ï‰∏ç‰ªÖÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨ÔºåËøòÊèêÈ´ò‰∫ÜÁΩÆ‰ø°Â∫¶‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇÊ≠§Â§ñÔºåGrACEËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁΩÆ‰ø°Â∫¶ÁöÑÊµãËØïÊó∂Áº©ÊîæÁ≠ñÁï•ÔºåËøõ‰∏ÄÊ≠•ÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöGrACEÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÁâπÊÆäÁΩÆ‰ø°Â∫¶tokenÁöÑÈÄâÊã©ÂíåÂµåÂÖ•ÂàùÂßãÂåñ„ÄÇ2) ÂæÆË∞ÉÈò∂ÊÆµÁöÑÊ†°ÂáÜÁõÆÊ†áËÆæËÆ°Ôºå‰æãÂ¶Ç‰ΩøÁî®‰∫§ÂèâÁÜµÊçüÂ§±ÂáΩÊï∞Êù•ÊúÄÂ∞èÂåñÈ¢ÑÊµãÁΩÆ‰ø°Â∫¶‰∏éÂÆûÈôÖÂáÜÁ°ÆÁéá‰πãÈó¥ÁöÑÂ∑ÆÂºÇ„ÄÇ3) Áõ∏‰ººÂ∫¶Â∫¶ÈáèÊñπÊ≥ïÁöÑÈÄâÊã©Ôºå‰æãÂ¶Ç‰ΩøÁî®‰ΩôÂº¶Áõ∏‰ººÂ∫¶Êù•Ë°°ÈáèÈöêËóèÁä∂ÊÄÅ‰∏étokenÂµåÂÖ•‰πãÈó¥ÁöÑÁõ∏‰ººÁ®ãÂ∫¶„ÄÇ4) ÊµãËØïÊó∂Áº©ÊîæÁ≠ñÁï•ÁöÑÂÖ∑‰ΩìÂÆûÁé∞Ôºå‰æãÂ¶ÇÊ†πÊçÆÁΩÆ‰ø°Â∫¶ÂæóÂàÜÂØπÂ§ö‰∏™ÂÄôÈÄâÁ≠îÊ°àËøõË°åÂä†ÊùÉÂπ≥Âùá„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGrACEÂú®ÂºÄÊîæÂºèÁîüÊàê‰ªªÂä°‰∏≠ÊòæËëó‰ºò‰∫éÂÖ≠ÁßçÁ´û‰∫âÊñπÊ≥ïÔºåÂÆûÁé∞‰∫ÜÊúÄ‰Ω≥ÁöÑÂå∫ÂàÜËÉΩÂäõÂíåÊ†°ÂáÜÊïàÊûú„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õÊï∞ÊçÆÈõÜ‰∏äÔºåGrACEÁöÑÊ†°ÂáÜËØØÂ∑ÆÈôç‰Ωé‰∫Ü20%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåGrACEËøòËÉΩÂ§üÊòæËëóÂáèÂ∞ëÊµãËØïÊó∂Áº©ÊîæÊâÄÈúÄÁöÑÊ†∑Êú¨Êï∞ÈáèÔºåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨Ôºå‰ΩøÂÖ∂Êõ¥ÈÄÇÁî®‰∫éÂÆûÈôÖÈÉ®ÁΩ≤„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

GrACEÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂπøÊ≥õÔºåÂåÖÊã¨ÂåªÁñóËØäÊñ≠„ÄÅÈáëËûçÈ£éÈô©ËØÑ‰º∞„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ´òÈ£éÈô©Âú∫ÊôØ„ÄÇÈÄöËøáÊèê‰æõÂèØÈù†ÁöÑÁΩÆ‰ø°Â∫¶‰º∞ËÆ°ÔºåGrACEÂèØ‰ª•Â∏ÆÂä©Áî®Êà∑Êõ¥Â•ΩÂú∞ÁêÜËß£Âíå‰ø°‰ªªLLMÁöÑÂÜ≥Á≠ñÔºå‰ªéËÄåÊèêÈ´òÂÜ≥Á≠ñÁöÑÂáÜÁ°ÆÊÄßÂíåÂÆâÂÖ®ÊÄß„ÄÇÊú™Êù•ÔºåGrACEÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÁ±ªÂûãÁöÑAIÊ®°ÂûãÂíå‰ªªÂä°ÔºåÂπ∂‰∏éÂÖ∂‰ªñAIÂÆâÂÖ®ÊäÄÊúØÁõ∏ÁªìÂêàÔºåÂÖ±ÂêåÊûÑÂª∫Êõ¥ÂÆâÂÖ®„ÄÅÂèØÈù†ÁöÑ‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Assessing the reliability of Large Language Models (LLMs) by confidence elicitation is a prominent approach to AI safety in high-stakes applications, such as healthcare and finance. Existing methods either require expensive computational overhead or suffer from poor calibration, making them impractical and unreliable for real-world deployment. In this work, we propose GrACE, a Generative Approach to Confidence Elicitation that enables scalable and reliable confidence elicitation for LLMs. GrACE adopts a novel mechanism in which the model expresses confidence by the similarity between the last hidden state and the embedding of a special token appended to the vocabulary, in real-time. We fine-tune the model for calibrating the confidence with calibration targets associated with accuracy. Experiments with three LLMs and two benchmark datasets show that the confidence produced by GrACE achieves the best discriminative capacity and calibration on open-ended generation tasks, outperforming six competing methods without resorting to additional sampling or an auxiliary model. Moreover, we propose two strategies for improving test-time scaling based on confidence induced by GrACE. Experimental results show that using GrACE not only improves the accuracy of the final decision but also significantly reduces the number of required samples in the test-time scaling scheme, indicating the potential of GrACE as a practical solution for deploying LLMs with scalable, reliable, and real-time confidence estimation.

