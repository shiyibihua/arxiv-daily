---
layout: default
title: Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia
---

# Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09121" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09121v1</a>
  <a href="https://arxiv.org/pdf/2509.09121.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09121v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09121v1', 'Compass-v3: Scaling Domain-Specific LLMs for Multilingual E-Commerce in Southeast Asia')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sophia Maria

**åˆ†ç±»**: cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Compass-v3ï¼šé¢å‘ä¸œå—äºšç”µå•†çš„å¤šè¯­è¨€MoEæ¨¡å‹ï¼Œæ€§èƒ½è¶…è¶ŠGPT-4**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ··åˆä¸“å®¶æ¨¡å‹` `ç”µå­å•†åŠ¡` `å¤šè¯­è¨€` `ä¸œå—äºš` `æŒ‡ä»¤å¯¹é½` `æœ€ä¼˜ä¼ è¾“` `ç¡¬ä»¶ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨é€šç”¨é¢†åŸŸè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç”µå•†ç­‰ç‰¹å®šé¢†åŸŸå› æ•°æ®å¤æ‚æ€§ï¼ˆå¤šè¯­è¨€ã€å¼‚æ„ï¼‰è€Œæ€§èƒ½ä¸‹é™ã€‚
2. Compass-v3é‡‡ç”¨MoEæ¶æ„ï¼Œé€šè¿‡æ›´å¤§è§„æ¨¡ä¸“å®¶å’Œç¡¬ä»¶ä¼˜åŒ–æå‡GPUåˆ©ç”¨ç‡ï¼Œå¹¶ä½¿ç”¨OTPOä¼˜åŒ–æŒ‡ä»¤å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCompass-v3åœ¨ä¸œå—äºšç”µå•†ä»»åŠ¡ä¸­è¶…è¶ŠDeepSeek-V3.1ã€GPT-4ç­‰æ¨¡å‹ï¼Œå¹¶åœ¨å¤šç§è¯­è¨€ä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é€šç”¨é¢†åŸŸåº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨éœ€è¦ç‰¹å®šé¢†åŸŸçŸ¥è¯†çš„ä¸“ä¸šä»»åŠ¡ä¸­ï¼Œæ€§èƒ½é€šå¸¸ä¼šä¸‹é™ã€‚ç”µå­å•†åŠ¡å°¤å…¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå…¶æ•°æ®å˜ˆæ‚ã€å¼‚æ„ã€å¤šè¯­è¨€ä¸”é«˜åº¦åŠ¨æ€ã€‚æˆ‘ä»¬æå‡ºäº†Compass-v3ï¼Œä¸€ä¸ªå‚ç›´é¢†åŸŸçš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Œæ€»å‚æ•°ä¸º245Bï¼Œæ¯ä¸ªtokenæ¿€æ´»71Bå‚æ•°ï¼Œä¸“ä¸ºä¸œå—äºšç”µå­å•†åŠ¡è®¾è®¡ã€‚Compass-v3é‡‡ç”¨æ›´å°‘ä½†æ›´å¤§çš„ä¸“å®¶ï¼Œå¹¶ç»“åˆç¡¬ä»¶é«˜æ•ˆä¼˜åŒ–ï¼ˆå¦‚èŠ‚ç‚¹å†…ä¸“å®¶å¹¶è¡Œå’Œå®šåˆ¶çš„memcpyç®—å­ï¼‰ä»¥æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡ã€‚è¯¥æ¨¡å‹åœ¨12T tokensçš„ç²¾é€‰å¤šè¯­è¨€è¯­æ–™åº“å’Œå¤§è§„æ¨¡åˆæˆç”µå­å•†åŠ¡æŒ‡ä»¤ä¸Šä½¿ç”¨æ··åˆè®­ç»ƒç­–ç•¥è¿›è¡Œè®­ç»ƒã€‚ä¸ºäº†å¢å¼ºå¯¹é½ï¼Œæˆ‘ä»¬æå‡ºäº†æœ€ä¼˜ä¼ è¾“ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆOTPOï¼‰ï¼Œå®ƒæ•è·tokençº§åˆ«çš„å·®å¼‚ï¼Œå¹¶æé«˜å•†ä¸šç‰¹å®šåœºæ™¯ä¸­çš„æŒ‡ä»¤éµå¾ªæ€§ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼ŒCompass-v3æä¾›äº†æœ€å…ˆè¿›çš„ç”µå­å•†åŠ¡æ€§èƒ½ï¼Œè¶…è¿‡äº†DeepSeek-V3.1ã€GPT-4ç³»åˆ—å’ŒQwen3-235Bã€‚æ­¤å¤–ï¼ŒCompass-v3åœ¨ä½èµ„æºä¸œå—äºšè¯­è¨€ï¼ˆå°åº¦å°¼è¥¿äºšè¯­ã€æ³°è¯­ã€è²å¾‹å®¾è¯­ã€è¶Šå—è¯­ã€é©¬æ¥è¯­ã€å¡”åŠ ç¦„è¯­ï¼‰å’Œè‘¡è„ç‰™è¯­ä¸­è¡¨ç°å‡ºå¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒäº†åœ¨é€šç”¨åŸºå‡†æµ‹è¯•ä¸­çš„ç«äº‰æ€§èƒ½ã€‚å®ƒå·²å¹¿æ³›åº”ç”¨äºShopeeçš„å·¥ä¸šçº§ç”µå­å•†åŠ¡å¹³å°ï¼Œå¹¶é€æ¸å–ä»£OpenAIçš„æµé‡ï¼Œç›®å‰å LLMæ€»ä½¿ç”¨é‡çš„70ï¼…ä»¥ä¸Šï¼Œçªæ˜¾äº†å…¶åœ¨ä¸“ä¸šå•†ä¸šçŸ¥è¯†å’Œå¹¿æ³›è¯­è¨€èƒ½åŠ›æ–¹é¢çš„åŒé‡ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€šç”¨é¢†åŸŸè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨ç”µå­å•†åŠ¡ç­‰ç‰¹å®šé¢†åŸŸï¼Œç”±äºæ•°æ®å™ªå£°å¤§ã€å¼‚æ„ã€å¤šè¯­è¨€ä¸”åŠ¨æ€æ€§å¼ºï¼Œæ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚å°¤å…¶æ˜¯åœ¨ä¸œå—äºšå¸‚åœºï¼Œå¤šè¯­è¨€ç¯å¢ƒå’Œä½èµ„æºè¯­è¨€çš„å­˜åœ¨è¿›ä¸€æ­¥åŠ å‰§äº†è¿™ä¸€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå¤„ç†è¿™äº›æŒ‘æˆ˜ï¼Œå¯¼è‡´ç”µå•†ä»»åŠ¡çš„æ€§èƒ½ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCompass-v3çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå‚ç›´é¢†åŸŸçš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹ï¼Œä¸“æ³¨äºä¸œå—äºšç”µå­å•†åŠ¡ã€‚é€šè¿‡å¢åŠ ä¸“å®¶æ¨¡å‹çš„è§„æ¨¡ï¼Œå¹¶ç»“åˆç¡¬ä»¶ä¼˜åŒ–æŠ€æœ¯ï¼Œæé«˜æ¨¡å‹çš„è®¡ç®—æ•ˆç‡å’ŒGPUåˆ©ç”¨ç‡ã€‚åŒæ—¶ï¼Œé‡‡ç”¨æœ€ä¼˜ä¼ è¾“ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆOTPOï¼‰æ–¹æ³•ï¼Œå¢å¼ºæ¨¡å‹åœ¨å•†ä¸šç‰¹å®šåœºæ™¯ä¸­çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨ç”µå•†ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCompass-v3çš„æ•´ä½“æ¶æ„æ˜¯ä¸€ä¸ªMoEæ¨¡å‹ï¼ŒåŒ…å«å¤šä¸ªä¸“å®¶ç½‘ç»œã€‚è®­ç»ƒæµç¨‹åŒ…æ‹¬ï¼š1) ä½¿ç”¨ç²¾é€‰çš„å¤šè¯­è¨€è¯­æ–™åº“å’Œå¤§è§„æ¨¡åˆæˆç”µå­å•†åŠ¡æŒ‡ä»¤è¿›è¡Œæ··åˆè®­ç»ƒï¼›2) ä½¿ç”¨OTPOæ–¹æ³•è¿›è¡Œå¯¹é½ä¼˜åŒ–ï¼Œæå‡æ¨¡å‹å¯¹ç”µå•†æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚æ¨¡å‹åœ¨Shopeeçš„å·¥ä¸šçº§ç”µå­å•†åŠ¡å¹³å°ä¸Šè¿›è¡Œéƒ¨ç½²å’Œåº”ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šCompass-v3çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºï¼š1) é’ˆå¯¹ä¸œå—äºšç”µå•†åœºæ™¯è®¾è®¡äº†å‚ç›´é¢†åŸŸçš„MoEæ¨¡å‹ï¼›2) æå‡ºäº†æœ€ä¼˜ä¼ è¾“ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆOTPOï¼‰æ–¹æ³•ï¼Œç”¨äºå¢å¼ºæ¨¡å‹åœ¨å•†ä¸šç‰¹å®šåœºæ™¯ä¸­çš„æŒ‡ä»¤éµå¾ªæ€§ï¼›3) é‡‡ç”¨äº†ç¡¬ä»¶é«˜æ•ˆä¼˜åŒ–æŠ€æœ¯ï¼Œå¦‚èŠ‚ç‚¹å†…ä¸“å®¶å¹¶è¡Œå’Œå®šåˆ¶çš„memcpyç®—å­ï¼Œä»¥æœ€å¤§åŒ–GPUåˆ©ç”¨ç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šCompass-v3æ¨¡å‹æ€»å‚æ•°ä¸º245Bï¼Œæ¯ä¸ªtokenæ¿€æ´»71Bå‚æ•°ã€‚é‡‡ç”¨äº†æ›´å°‘ä½†æ›´å¤§çš„ä¸“å®¶ï¼Œä»¥æé«˜è®¡ç®—æ•ˆç‡ã€‚OTPOæ–¹æ³•é€šè¿‡æ•è·tokençº§åˆ«çš„å·®å¼‚ï¼Œä¼˜åŒ–æ¨¡å‹å¯¹æŒ‡ä»¤çš„ç†è§£ã€‚ç¡¬ä»¶ä¼˜åŒ–æ–¹é¢ï¼ŒèŠ‚ç‚¹å†…ä¸“å®¶å¹¶è¡Œå’Œå®šåˆ¶çš„memcpyç®—å­æ˜¾è‘—æå‡äº†GPUåˆ©ç”¨ç‡ã€‚è®­ç»ƒæ•°æ®åŒ…æ‹¬12T tokensçš„ç²¾é€‰å¤šè¯­è¨€è¯­æ–™åº“å’Œå¤§è§„æ¨¡åˆæˆç”µå­å•†åŠ¡æŒ‡ä»¤ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Compass-v3åœ¨ç”µå­å•†åŠ¡ä»»åŠ¡ä¸­è¡¨ç°å‡ºæœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¶…è¶Šäº†DeepSeek-V3.1ã€GPT-4ç³»åˆ—å’ŒQwen3-235Bç­‰æ¨¡å‹ã€‚åœ¨ä½èµ„æºä¸œå—äºšè¯­è¨€ï¼ˆå¦‚å°åº¦å°¼è¥¿äºšè¯­ã€æ³°è¯­ã€è²å¾‹å®¾è¯­ç­‰ï¼‰å’Œè‘¡è„ç‰™è¯­ä¸­ï¼ŒCompass-v3ä¹Ÿå±•ç°å‡ºå¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨é€šç”¨åŸºå‡†æµ‹è¯•ä¸­ä¿æŒäº†ç«äº‰æ€§èƒ½ã€‚ç›®å‰ï¼ŒCompass-v3å·²å Shopeeå¹³å°LLMæ€»ä½¿ç”¨é‡çš„70%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Compass-v3åœ¨ä¸œå—äºšç”µå­å•†åŠ¡é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºå•†å“æœç´¢ã€æ¨èç³»ç»Ÿã€å®¢æˆ·æœåŠ¡ã€å†…å®¹ç”Ÿæˆç­‰ã€‚å…¶å¼ºå¤§çš„å¤šè¯­è¨€èƒ½åŠ›ä½¿å…¶èƒ½å¤ŸæœåŠ¡äºä¸åŒè¯­è¨€çš„ç”¨æˆ·ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚è¯¥æ¨¡å‹å·²åœ¨Shopeeçš„å·¥ä¸šçº§ç”µå­å•†åŠ¡å¹³å°ä¸­å¾—åˆ°åº”ç”¨ï¼Œå¹¶é€æ¸å–ä»£OpenAIçš„æµé‡ï¼Œæ˜¾ç¤ºäº†å…¶å·¨å¤§çš„å•†ä¸šä»·å€¼ã€‚æœªæ¥ï¼ŒCompass-v3æœ‰æœ›è¿›ä¸€æ­¥æ¨åŠ¨ä¸œå—äºšç”µå­å•†åŠ¡çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) excel in general-domain applications, yet their performance often degrades in specialized tasks requiring domain-specific knowledge. E-commerce is particularly challenging, as its data are noisy, heterogeneous, multilingual, and highly dynamic. We present Compass-v3, a vertical-domain Mixture-of-Experts (MoE) model with 245B total parameters and 71B active per token, designed for Southeast Asian e-commerce. Compass-v3 adopts fewer but larger experts, combined with hardware-efficient optimizations-such as intra-node expert parallelism and a customized memcpy operator-to maximize GPU utilization. The model is trained on 12T tokens of curated multilingual corpora and large-scale synthetic e-commerce instructions using a mixed-training strategy. To enhance alignment, we propose Optimal-Transport Direct Preference Optimization (OTPO), which captures token-level distinctions and improves instruction adherence in commerce-specific scenarios. Extensive evaluations demonstrate that Compass-v3 delivers state-of-the-art e-commerce performance, surpassing DeepSeek-V3.1, GPT-4 series, and Qwen3-235B. Moreover, Compass-v3 demonstrates strong multilingual capability across low-resource Southeast Asian languages (Indonesian, Thai, Filipino, Vietnamese, Malay, Taglog) and Portuguese while sustaining competitive performance on general benchmarks. It has already been widely applied in Shopee's industrial-scale e-commerce platform and is gradually replacing OpenAI's traffic, now accounting for over 70\% of total LLM usage, highlighting its dual strengths in specialized commerce expertise and broad linguistic competence.

