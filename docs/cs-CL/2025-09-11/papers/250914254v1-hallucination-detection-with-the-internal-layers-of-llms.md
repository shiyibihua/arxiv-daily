---
layout: default
title: Hallucination Detection with the Internal Layers of LLMs
---

# Hallucination Detection with the Internal Layers of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14254" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14254v1</a>
  <a href="https://arxiv.org/pdf/2509.14254.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14254v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14254v1', 'Hallucination Detection with the Internal Layers of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Martin PreiÃŸ

**åˆ†ç±»**: cs.CL, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

**å¤‡æ³¨**: Master's thesis

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºLLMå†…éƒ¨è¡¨å¾çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€åŠ æƒå±‚æå‡æ£€æµ‹æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¹»è§‰æ£€æµ‹` `å†…éƒ¨è¡¨å¾` `åŠ¨æ€åŠ æƒ` `è·¨åŸºå‡†æ³›åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. LLMå®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³ç”Ÿæˆçœ‹ä¼¼åˆç†ä½†ç¼ºä¹äº‹å®ä¾æ®çš„å†…å®¹ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ£€æµ‹ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§æ–°æ¶æ„ï¼ŒåŠ¨æ€åŠ æƒå’Œç»„åˆLLMå†…éƒ¨å±‚ï¼Œä»¥æå‡å¹»è§‰æ£€æµ‹çš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿæ¢æµ‹æ–¹æ³•ï¼Œä½†æ³›åŒ–æ€§ä»å…·æŒ‘æˆ˜ï¼Œè·¨åŸºå‡†è®­ç»ƒå’Œå‚æ•°å†»ç»“å¯ç¼“è§£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸã€‚ç„¶è€Œï¼Œå®ƒä»¬ä¹Ÿå­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ï¼Œå³å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œè¿™æ˜¯ä¸€ç§çœ‹ä¼¼åˆç†ä½†ç¼ºä¹äº‹å®ä¾æ®çš„è¾“å‡ºï¼Œä¼šå¸¦æ¥ä¸¥é‡çš„å®é™…åæœã€‚æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œåˆ©ç”¨LLMå†…éƒ¨è¡¨å¾çš„åŸºäºæ¢é’ˆçš„åˆ†ç±»å™¨å¯ä»¥æ£€æµ‹å¹»è§‰ã€‚è¿™ç§æ–¹æ³•ä¸æ¶‰åŠæ¨¡å‹è®­ç»ƒï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—å¢åŠ è®¡ç®—æˆæœ¬çš„æƒ…å†µä¸‹æé«˜å¯é æ€§ã€‚æœ¬æ–‡åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨LLMå†…éƒ¨è¡¨å¾è¿›è¡Œå¹»è§‰æ£€æµ‹çš„æ–°æ–¹æ³•ï¼Œå¹¶åœ¨TruthfulQAã€HaluEvalå’ŒReFactä¸‰ä¸ªåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å…·ä½“æ¥è¯´ï¼Œå¼€å‘äº†ä¸€ç§æ–°çš„æ¶æ„ï¼Œå¯ä»¥åŠ¨æ€åœ°åŠ æƒå’Œç»„åˆLLMå†…éƒ¨å±‚ï¼Œä»¥æé«˜å¹»è§‰æ£€æµ‹æ€§èƒ½ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒï¼Œè·å¾—äº†ä¸¤ä¸ªå…³é”®å‘ç°ï¼šé¦–å…ˆï¼Œä¸ä¼ ç»Ÿçš„æ¢æµ‹æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œä½†è·¨åŸºå‡†å’ŒLLMçš„æ³›åŒ–ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å…¶æ¬¡ï¼Œé€šè¿‡è·¨åŸºå‡†è®­ç»ƒå’Œå‚æ•°å†»ç»“å¯ä»¥ç¼“è§£è¿™äº›æ³›åŒ–é™åˆ¶ã€‚è™½ç„¶å¹¶éå§‹ç»ˆæ”¹è¿›ï¼Œä½†è¿™ä¸¤ç§æŠ€æœ¯åœ¨å•ä¸ªåŸºå‡†ä¸Šéƒ½äº§ç”Ÿäº†æ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶å‡å°‘äº†è½¬ç§»åˆ°å…¶ä»–åŸºå‡†æ—¶çš„æ€§èƒ½ä¸‹é™ã€‚è¿™äº›å‘ç°ä¸ºé€šè¿‡å†…éƒ¨è¡¨å¾åˆ†ææé«˜LLMçš„å¯é æ€§å¼€è¾Ÿäº†æ–°çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ™®éå­˜åœ¨çš„å¹»è§‰é—®é¢˜ï¼Œå³LLMsç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…ä¸Šä¸ç¬¦åˆäº‹å®çš„å†…å®¹ã€‚ç°æœ‰åŸºäºæ¢é’ˆçš„å¹»è§‰æ£€æµ‹æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨è·¨ä¸åŒåŸºå‡†æµ‹è¯•å’ŒLLMsæ—¶çš„æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ï¼Œéœ€è¦é’ˆå¯¹ç‰¹å®šæ¨¡å‹å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ï¼Œç¼ºä¹é€šç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMså†…éƒ¨å±‚çš„è¡¨å¾ä¿¡æ¯æ¥åˆ¤æ–­ç”Ÿæˆå†…å®¹æ˜¯å¦ä¸ºå¹»è§‰ã€‚é€šè¿‡åŠ¨æ€åœ°åŠ æƒå’Œç»„åˆä¸åŒå±‚çš„è¡¨å¾ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°æ•æ‰åˆ°ä¸å¹»è§‰ç›¸å…³çš„ç‰¹å¾ï¼Œä»è€Œæé«˜æ£€æµ‹çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è¿™ç§åŠ¨æ€åŠ æƒæœºåˆ¶å…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥è‡ªé€‚åº”åœ°é€‰æ‹©æœ€ç›¸å…³çš„å±‚ï¼Œä»è€Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) è·å–LLMå†…éƒ¨å„å±‚çš„è¡¨å¾ï¼›2) ä½¿ç”¨åŠ¨æ€åŠ æƒæœºåˆ¶å¯¹è¿™äº›è¡¨å¾è¿›è¡Œç»„åˆï¼Œç”Ÿæˆä¸€ä¸ªç»¼åˆçš„è¡¨å¾å‘é‡ï¼›3) å°†è¯¥å‘é‡è¾“å…¥åˆ°ä¸€ä¸ªåˆ†ç±»å™¨ä¸­ï¼Œåˆ¤æ–­ç”Ÿæˆå†…å®¹æ˜¯å¦ä¸ºå¹»è§‰ã€‚åŠ¨æ€åŠ æƒæœºåˆ¶æ˜¯è¯¥æ¡†æ¶çš„æ ¸å¿ƒï¼Œå®ƒæ ¹æ®è¾“å…¥åŠ¨æ€åœ°è°ƒæ•´å„å±‚è¡¨å¾çš„æƒé‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåŠ¨æ€åŠ æƒæœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„é™æ€åŠ æƒæˆ–ç®€å•æ‹¼æ¥ä¸åŒï¼Œè¯¥æœºåˆ¶å…è®¸æ¨¡å‹æ ¹æ®è¾“å…¥è‡ªé€‚åº”åœ°å­¦ä¹ å„å±‚è¡¨å¾çš„é‡è¦æ€§ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æ•æ‰åˆ°ä¸å¹»è§‰ç›¸å…³çš„ç‰¹å¾ã€‚è¿™ç§åŠ¨æ€æ€§ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„LLMså’Œæ•°æ®é›†ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€åŠ æƒæœºåˆ¶çš„å…·ä½“å®ç°æ–¹å¼æœªçŸ¥ï¼Œè®ºæ–‡ä¸­å¯èƒ½æ²¡æœ‰è¯¦ç»†æè¿°ã€‚ä½†å¯ä»¥æ¨æµ‹ï¼Œå¯èƒ½ä½¿ç”¨äº†æ³¨æ„åŠ›æœºåˆ¶æˆ–ç±»ä¼¼çš„è‡ªé€‚åº”æƒé‡å­¦ä¹ æ–¹æ³•ã€‚æ­¤å¤–ï¼Œåˆ†ç±»å™¨çš„é€‰æ‹©å’Œè®­ç»ƒæ–¹å¼ä¹Ÿæ˜¯å…³é”®çš„è®¾è®¡ç»†èŠ‚ï¼Œå¯èƒ½é‡‡ç”¨äº†äº¤å‰ç†µæŸå¤±å‡½æ•°å’Œä¸€äº›æ­£åˆ™åŒ–æŠ€æœ¯æ¥é˜²æ­¢è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„åŠ¨æ€åŠ æƒæ–¹æ³•åœ¨å¹»è§‰æ£€æµ‹ä»»åŠ¡ä¸Šä¼˜äºä¼ ç»Ÿçš„æ¢æµ‹æ–¹æ³•ã€‚è™½ç„¶è·¨åŸºå‡†å’ŒLLMçš„æ³›åŒ–ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œä½†é€šè¿‡è·¨åŸºå‡†è®­ç»ƒå’Œå‚æ•°å†»ç»“ç­‰æŠ€æœ¯ï¼Œå¯ä»¥æœ‰æ•ˆç¼“è§£æ³›åŒ–é—®é¢˜ï¼Œå¹¶åœ¨ç‰¹å®šåŸºå‡†ä¸Šå–å¾—æ›´å¥½çš„æ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘äº†æ¨¡å‹åœ¨ä¸åŒåŸºå‡†é—´è¿ç§»æ—¶çš„æ€§èƒ½ä¸‹é™ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦é«˜åº¦å¯é æ€§çš„è‡ªç„¶è¯­è¨€ç”Ÿæˆåœºæ™¯ï¼Œä¾‹å¦‚è‡ªåŠ¨é—®ç­”ç³»ç»Ÿã€æ–°é—»æ‘˜è¦ç”Ÿæˆã€åŒ»ç–—æŠ¥å‘Šç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜LLMç”Ÿæˆå†…å®¹çš„çœŸå®æ€§å’Œå¯é æ€§ï¼Œå¯ä»¥å‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½æ½œåœ¨çš„é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have succeeded in a variety of natural language processing tasks [Zha+25]. However, they have notable limitations. LLMs tend to generate hallucinations, a seemingly plausible yet factually unsupported output [Hua+24], which have serious real-world consequences [Kay23; Rum+24]. Recent work has shown that probing-based classifiers that utilize LLMs' internal representations can detect hallucinations [AM23; Bei+24; Bur+24; DYT24; Ji+24; SMZ24; Su+24]. This approach, since it does not involve model training, can enhance reliability without significantly increasing computational costs.
>   Building upon this approach, this thesis proposed novel methods for hallucination detection using LLM internal representations and evaluated them across three benchmarks: TruthfulQA, HaluEval, and ReFact. Specifically, a new architecture that dynamically weights and combines internal LLM layers was developed to improve hallucination detection performance. Throughout extensive experiments, two key findings were obtained: First, the proposed approach was shown to achieve superior performance compared to traditional probing methods, though generalization across benchmarks and LLMs remains challenging. Second, these generalization limitations were demonstrated to be mitigated through cross-benchmark training and parameter freezing. While not consistently improving, both techniques yielded better performance on individual benchmarks and reduced performance degradation when transferred to other benchmarks. These findings open new avenues for improving LLM reliability through internal representation analysis.

