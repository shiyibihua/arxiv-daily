[{"id":"2512.15258v1","title":"VLA-AN: An Efficient and Onboard Vision-Language-Action Framework for Aerial Navigation in Complex Environments","headline":"提出VLA-AN，用于复杂环境中无人机高效、安全的视觉-语言-动作端到端导航。","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215258v1-vla-an-an-efficient-and-onboard-vision-language-action-framework-for.html"},{"id":"2512.15692v1","title":"mimic-video: Video-Action Models for Generalizable Robot Control Beyond VLAs","headline":"提出mimic-video以解决机器人控制中的物理理解问题","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215692v1-mimic-video-video-action-models-for-generalizable-robot-control-beyo.html"},{"id":"2512.15557v1","title":"OMCL: Open-vocabulary Monte Carlo Localization","headline":"提出基于视觉-语言特征的开放词汇蒙特卡洛定位方法，提升跨模态地图环境下的机器人定位鲁棒性。","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215557v1-omcl-open-vocabulary-monte-carlo-localization.html"},{"id":"2512.15411v1","title":"MiVLA: Towards Generalizable Vision-Language-Action Model with Human-Robot Mutual Imitation Pre-training","headline":"MiVLA：基于人-机互模仿预训练的通用视觉-语言-动作模型","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215411v1-mivla-towards-generalizable-vision-language-action-model-with-human-.html"},{"id":"2512.15080v1","title":"NAP3D: NeRF Assisted 3D-3D Pose Alignment for Autonomous Vehicles","headline":"NAP3D：NeRF辅助的3D-3D位姿对齐，用于提升自动驾驶车辆定位精度","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215080v1-nap3d-nerf-assisted-3d-3d-pose-alignment-for-autonomous-vehicles.html"},{"id":"2512.15020v1","title":"ISS Policy : Scalable Diffusion Policy with Implicit Scene Supervision","headline":"提出隐式场景监督扩散策略，提升机器人操作任务的泛化性和训练效率","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215020v1-iss-policy-scalable-diffusion-policy-with-implicit-scene-supervision.html"},{"id":"2512.15309v1","title":"GuangMing-Explorer: A Four-Legged Robot Platform for Autonomous Exploration in General Environments","headline":"GuangMing-Explorer：用于通用环境自主探索的四足机器人平台","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215309v1-guangming-explorer-a-four-legged-robot-platform-for-autonomous-explo.html"},{"id":"2512.15111v1","title":"BEV-Patch-PF: Particle Filtering with BEV-Aerial Feature Matching for Off-Road Geo-Localization","headline":"提出BEV-Patch-PF，利用BEV特征匹配的粒子滤波实现越野环境无GPS定位","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215111v1-bev-patch-pf-particle-filtering-with-bev-aerial-feature-matching-for.html"},{"id":"2512.15476v1","title":"QuantGraph: A Receding-Horizon Quantum Graph Solver","headline":"提出QuantGraph，一种基于后退视界的量子图求解器，提升图优化效率。","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215476v1-quantgraph-a-receding-horizon-quantum-graph-solver.html"},{"id":"2512.15448v1","title":"Load-Based Variable Transmission Mechanism for Robotic Applications","headline":"提出基于负载的可变传动机制，提升机器人关节在动态负载下的性能","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215448v1-load-based-variable-transmission-mechanism-for-robotic-applications.html"},{"id":"2512.15047v1","title":"HERO: Hierarchical Traversable 3D Scene Graphs for Embodied Navigation Among Movable Obstacles","headline":"提出HERO框架以解决动态障碍物导航问题","tag":"cs.RO","date":"2025-12-17","url":"cs-RO/2025-12-17/papers/251215047v1-hero-hierarchical-traversable-3d-scene-graphs-for-embodied-navigatio.html"},{"id":"2512.15508v1","title":"Off The Grid: Detection of Primitives for Feed-Forward 3D Gaussian Splatting","headline":"提出一种新架构以解决3D高斯原语检测的像素对齐问题","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215508v1-off-the-grid-detection-of-primitives-for-feed-forward-3d-gaussian-sp.html"},{"id":"2512.15153v1","title":"Explainable Action Form Assessment by Exploiting Multimodal Chain-of-Thoughts Reasoning","headline":"提出基于多模态CoT推理的可解释动作形态评估方法与数据集，解决动作标准化评估问题。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215153v1-explainable-action-form-assessment-by-exploiting-multimodal-chain-of.html"},{"id":"2512.15715v1","title":"In Pursuit of Pixel Supervision for Visual Pre-training","headline":"Pixio：基于像素监督的视觉预训练，实现简单、高效且强大的表征学习","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215715v1-in-pursuit-of-pixel-supervision-for-visual-pre-training.html"},{"id":"2512.15160v1","title":"EagleVision: A Dual-Stage Framework with BEV-grounding-based Chain-of-Thought for Spatial Intelligence","headline":"EagleVision：基于BEV的链式思考双阶段框架，提升空间智能","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215160v1-eaglevision-a-dual-stage-framework-with-bev-grounding-based-chain-of.html"},{"id":"2512.15708v1","title":"Multi-View Foundation Models","headline":"提出多视角基础模型，提升多视角场景下特征一致性","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215708v1-multi-view-foundation-models.html"},{"id":"2512.15048v1","title":"MVGSR: Multi-View Consistent 3D Gaussian Super-Resolution via Epipolar Guidance","headline":"提出MVGSR，通过极线引导实现多视角一致的3D高斯超分辨率重建","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215048v1-mvgsr-multi-view-consistent-3d-gaussian-super-resolution-via-epipola.html"},{"id":"2512.15410v1","title":"Preserving Marker Specificity with Lightweight Channel-Independent Representation Learning","headline":"提出轻量级通道独立表示学习以提升标记特异性","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215410v1-preserving-marker-specificity-with-lightweight-channel-independent-r.html"},{"id":"2512.15261v1","title":"MMMamba: A Versatile Cross-Modal In Context Fusion Framework for Pan-Sharpening and Zero-Shot Image Enhancement","headline":"提出MMMamba，一种用于全色锐化和零样本图像增强的跨模态上下文融合框架","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215261v1-mmmamba-a-versatile-cross-modal-in-context-fusion-framework-for-pan-.html"},{"id":"2512.15423v1","title":"Photorealistic Phantom Roads in Real Scenes: Disentangling 3D Hallucinations from Physical Geometry","headline":"提出Grounded Self-Distillation框架，解决单目深度估计中的3D幻觉问题","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215423v1-photorealistic-phantom-roads-in-real-scenes-disentangling-3d-halluci.html"},{"id":"2512.15711v1","title":"Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering","headline":"提出高斯像素编解码头像(GPiCA)，用于高效渲染的混合人像表示","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215711v1-gaussian-pixel-codec-avatars-a-hybrid-representation-for-efficient-r.html"},{"id":"2512.15693v1","title":"Skyra: AI-Generated Video Detection via Grounded Artifact Reasoning","headline":"Skyra：通过可信的伪影推理实现AI生成视频检测","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215693v1-skyra-ai-generated-video-detection-via-grounded-artifact-reasoning.html"},{"id":"2512.15560v1","title":"GRAN-TED: Generating Robust, Aligned, and Nuanced Text Embedding for Diffusion Models","headline":"提出GRAN-TED框架，用于生成鲁棒、对齐和细致的扩散模型文本嵌入。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215560v1-gran-ted-generating-robust-aligned-and-nuanced-text-embedding-for-di.html"},{"id":"2512.15528v1","title":"EmoCaliber: Advancing Reliable Visual Emotion Comprehension via Confidence Verbalization and Calibration","headline":"EmoCaliber：通过置信度表达与校准，提升视觉情感理解的可靠性","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215528v1-emocaliber-advancing-reliable-visual-emotion-comprehension-via-confi.html"},{"id":"2512.15512v1","title":"VAAS: Vision-Attention Anomaly Scoring for Image Manipulation Detection in Digital Forensics","headline":"VAAS：用于数字取证中图像篡改检测的视觉注意力异常评分方法","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215512v1-vaas-vision-attention-anomaly-scoring-for-image-manipulation-detecti.html"},{"id":"2512.15445v1","title":"ST-DETrack: Identity-Preserving Branch Tracking in Entangled Plant Canopies via Dual Spatiotemporal Evidence","headline":"ST-DETrack：利用时空双重证据，解决复杂植物冠层中分支的身份保持跟踪问题","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215445v1-st-detrack-identity-preserving-branch-tracking-in-entangled-plant-ca.html"},{"id":"2512.15431v1","title":"Step-GUI Technical Report","headline":"提出Step-GUI，通过自进化训练和GUI-MCP协议，实现高效、安全、通用的GUI自动化。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215431v1-step-gui-technical-report.html"},{"id":"2512.15707v1","title":"GateFusion: Hierarchical Gated Cross-Modal Fusion for Active Speaker Detection","headline":"提出GateFusion，通过分层门控跨模态融合提升主动说话人检测性能","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215707v1-gatefusion-hierarchical-gated-cross-modal-fusion-for-active-speaker-.html"},{"id":"2512.15635v1","title":"IC-Effect: Precise and Efficient Video Effects Editing via In-Context Learning","headline":"提出IC-Effect，通过上下文学习实现精确高效的视频特效编辑","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215635v1-ic-effect-precise-and-efficient-video-effects-editing-via-in-context.html"},{"id":"2512.15581v1","title":"IMKD: Intensity-Aware Multi-Level Knowledge Distillation for Camera-Radar Fusion","headline":"提出IMKD，通过强度感知多层知识蒸馏提升雷达-相机融合3D目标检测性能。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215581v1-imkd-intensity-aware-multi-level-knowledge-distillation-for-camera-r.html"},{"id":"2512.15577v1","title":"MoonSeg3R: Monocular Online Zero-Shot Segment Anything in 3D with Reconstructive Foundation Priors","headline":"MoonSeg3R：利用重建基础先验实现单目在线零样本3D分割","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215577v1-moonseg3r-monocular-online-zero-shot-segment-anything-in-3d-with-rec.html"},{"id":"2512.15396v1","title":"SMART: Semantic Matching Contrastive Learning for Partially View-Aligned Clustering","headline":"提出SMART模型，通过语义匹配对比学习解决部分视图对齐聚类问题","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215396v1-smart-semantic-matching-contrastive-learning-for-partially-view-alig.html"},{"id":"2512.15713v1","title":"DiffusionVL: Translating Any Autoregressive Models into Diffusion Vision Language Models","headline":"DiffusionVL：将任意自回归模型转化为扩散视觉语言模型，提升性能与推理速度。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215713v1-diffusionvl-translating-any-autoregressive-models-into-diffusion-vis.html"},{"id":"2512.15340v1","title":"Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics","headline":"提出TIMAR，用于建模交互式3D对话头部的因果turn级动态生成。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215340v1-towards-seamless-interaction-causal-turn-level-modeling-of-interacti.html"},{"id":"2512.15254v1","title":"Assessing the Visual Enumeration Abilities of Specialized Counting Architectures and Vision-Language Models","headline":"对比分析专用计数架构与视觉-语言模型在视觉枚举任务中的性能","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215254v1-assessing-the-visual-enumeration-abilities-of-specialized-counting-a.html"},{"id":"2512.15098v1","title":"Uni-Parser Technical Report","headline":"Uni-Parser：面向科学文献和专利的高通量文档解析引擎","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215098v1-uni-parser-technical-report.html"},{"id":"2512.15069v1","title":"PMMD: A pose-guided multi-view multi-modal diffusion for person generation","headline":"提出PMMD框架，通过多视角多模态扩散模型实现姿态引导下的高质量人物生成。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215069v1-pmmd-a-pose-guided-multi-view-multi-modal-diffusion-for-person-gener.html"},{"id":"2512.15524v1","title":"DeX-Portrait: Disentangled and Expressive Portrait Animation via Explicit and Latent Motion Representations","headline":"DeX-Portrait：通过显式和隐式运动表征实现解耦且富有表现力的人像动画","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215524v1-dex-portrait-disentangled-and-expressive-portrait-animation-via-expl.html"},{"id":"2512.15716v1","title":"Spatia: Video Generation with Updatable Spatial Memory","headline":"Spatia：利用可更新空间记忆实现视频生成，提升时空一致性","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215716v1-spatia-video-generation-with-updatable-spatial-memory.html"},{"id":"2512.15055v1","title":"Asynchronous Event Stream Noise Filtering for High-frequency Structure Deformation Measurement","headline":"提出基于事件相机和LED标记的异步事件流噪声滤波方法，用于高频结构形变测量。","tag":"cs.CV","date":"2025-12-17","url":"cs-CV/2025-12-17/papers/251215055v1-asynchronous-event-stream-noise-filtering-for-high-frequency-structu.html"},{"id":"2512.15115v1","title":"How Many Heads Make an SSM? A Unified Framework for Attention and State Space Models","headline":"提出统一框架，分析Attention和状态空间模型(SSM)的表达能力与训练权衡。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215115v1-how-many-heads-make-an-ssm-a-unified-framework-for-attention-and-sta.html"},{"id":"2512.15687v1","title":"Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning","headline":"提出G2RL：利用梯度引导强化学习提升LLM推理能力","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215687v1-can-llms-guide-their-own-exploration-gradient-guided-reinforcement-l.html"},{"id":"2512.15521v1","title":"Autonomous Pressure Control in MuVacAS via Deep Reinforcement Learning and Deep Learning Surrogate Models","headline":"提出基于深度强化学习和深度学习代理模型的MuVacAS自主压力控制方法","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215521v1-autonomous-pressure-control-in-muvacas-via-deep-reinforcement-learni.html"},{"id":"2512.15442v1","title":"Copyright Infringement Risk Reduction via Chain-of-Thought and Task Instruction Prompting","headline":"结合思维链与任务指令提示，降低文本到图像生成模型的版权侵权风险","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215442v1-copyright-infringement-risk-reduction-via-chain-of-thought-and-task-.html"},{"id":"2512.15605v1","title":"Autoregressive Language Models are Secretly Energy-Based Models: Insights into the Lookahead Capabilities of Next-Token Prediction","headline":"揭示自回归语言模型与能量模型等价性，洞察其前瞻能力","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215605v1-autoregressive-language-models-are-secretly-energy-based-models-insi.html"},{"id":"2512.15120v1","title":"Automatic Reward Shaping from Multi-Objective Human Heuristics","headline":"提出MORSE框架，通过多目标人类启发式自动进行强化学习奖励塑造","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215120v1-automatic-reward-shaping-from-multi-objective-human-heuristics.html"},{"id":"2512.15606v1","title":"A Teacher-Student Perspective on the Dynamics of Learning Near the Optimal Point","headline":"研究神经网络优化点附近的学习动态，揭示Hessian矩阵特征谱的关键作用","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215606v1-a-teacher-student-perspective-on-the-dynamics-of-learning-near-the-o.html"},{"id":"2512.15405v1","title":"EUBRL: Epistemic Uncertainty Directed Bayesian Reinforcement Learning","headline":"提出EUBRL算法，利用认知不确定性指导贝叶斯强化学习探索，提升样本效率。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215405v1-eubrl-epistemic-uncertainty-directed-bayesian-reinforcement-learning.html"},{"id":"2512.15267v1","title":"Distillation-Guided Structural Transfer for Continual Learning Beyond Sparse Distributed Memory","headline":"提出选择性子网络蒸馏(SSD)框架，提升稀疏神经网络的持续学习能力。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215267v1-distillation-guided-structural-transfer-for-continual-learning-beyon.html"},{"id":"2512.15123v1","title":"TrajSyn: Privacy-Preserving Dataset Distillation from Federated Model Trajectories for Server-Side Adversarial Training","headline":"TrajSyn：联邦学习中基于模型轨迹的隐私保护数据集蒸馏，用于服务端对抗训练","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215123v1-trajsyn-privacy-preserving-dataset-distillation-from-federated-model.html"},{"id":"2512.15112v1","title":"Feature-Centric Unsupervised Node Representation Learning Without Homophily Assumption","headline":"FUEL：一种无需同质性假设的特征中心无监督节点表示学习方法","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215112v1-feature-centric-unsupervised-node-representation-learning-without-ho.html"},{"id":"2512.15036v1","title":"Spectral Representation-based Reinforcement Learning","headline":"提出基于谱表示的强化学习框架，解决传统方法在复杂环境中的难题。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215036v1-spectral-representation-based-reinforcement-learning.html"},{"id":"2512.15657v1","title":"SoFlow: Solution Flow Models for One-Step Generative Modeling","headline":"SoFlow：提出解决方案流模型，实现一步到位的生成建模，提升生成效率。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215657v1-soflow-solution-flow-models-for-one-step-generative-modeling.html"},{"id":"2512.15705v1","title":"Dynamic Rebatching for Efficient Early-Exit Inference with DREX","headline":"提出动态重批处理以解决早期退出推理效率问题","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215705v1-dynamic-rebatching-for-efficient-early-exit-inference-with-drex.html"},{"id":"2512.15614v1","title":"Behavior Tokens Speak Louder: Disentangled Explainable Recommendation with Behavior Vocabulary","headline":"BEAT：通过行为词汇实现可解释推荐，解决现有方法语义模糊和结构限制问题。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215614v1-behavior-tokens-speak-louder-disentangled-explainable-recommendation.html"},{"id":"2512.15176v1","title":"DEER: Draft with Diffusion, Verify with Autoregressive Models","headline":"DEER：利用扩散模型进行草稿生成，自回归模型进行验证，提升LLM推理效率。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215176v1-deer-draft-with-diffusion-verify-with-autoregressive-models.html"},{"id":"2512.15082v1","title":"The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks","headline":"FEAML：利用LLM桥接结构化数据与多标签任务，实现自动化特征工程","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215082v1-the-semantic-architect-how-feaml-bridges-structured-data-and-llms-fo.html"},{"id":"2512.15003v1","title":"SeBERTis: A Framework for Producing Classifiers of Security-Related Issue Reports","headline":"SEBERTIS：一个用于生成安全相关问题报告分类器的框架","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215003v1-sebertis-a-framework-for-producing-classifiers-of-security-related-i.html"},{"id":"2512.15000v1","title":"DreamPRM-Code: Function-as-Step Process Reward Model with Label Correction for LLM Coding","headline":"DreamPRM-Code：利用函数作为步骤的过程奖励模型，通过标签校正提升LLM代码生成能力","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215000v1-dreamprm-code-function-as-step-process-reward-model-with-label-corre.html"},{"id":"2512.15385v1","title":"Robustness Evaluation of Machine Learning Models for Fault Classification and Localization In Power System Protection","headline":"提出电力系统保护中机器学习模型鲁棒性评估框架，解决恶劣工况下的可靠性问题。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215385v1-robustness-evaluation-of-machine-learning-models-for-fault-classific.html"},{"id":"2512.15086v1","title":"PIP$^2$ Net: Physics-informed Partition Penalty Deep Operator Network","headline":"提出PIP$^2$ Net，通过物理信息分区惩罚提升DeepONet在求解参数化偏微分方程中的精度和鲁棒性。","tag":"cs.LG","date":"2025-12-17","url":"cs-LG/2025-12-17/papers/251215086v1-pip2-net-physics-informed-partition-penalty-deep-operator-network.html"},{"id":"2512.15119v1","title":"QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management","headline":"提出基于QoS感知的分层强化学习方法，解决SAGIN支持的UAV移动性管理中的联合链路选择和轨迹优化问题。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215119v1-qos-aware-hierarchical-reinforcement-learning-for-joint-link-selecti.html"},{"id":"2512.15089v1","title":"Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models","headline":"提出CogER框架，通过认知启发的弹性推理提升大语言模型在不同难度问题上的效率与准确性。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215089v1-beyond-fast-and-slow-cognitive-inspired-elastic-reasoning-for-large-.html"},{"id":"2512.15567v1","title":"Evaluating Large Language Models in Scientific Discovery","headline":"提出科学发现评估框架SDE，用于评估大语言模型在科学研究中的能力","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215567v1-evaluating-large-language-models-in-scientific-discovery.html"},{"id":"2512.15663v1","title":"Explaining the Reasoning of Large Language Models Using Attribution Graphs","headline":"提出CAGE框架，利用归因图解释大型语言模型推理过程，提升归因忠实度。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215663v1-explaining-the-reasoning-of-large-language-models-using-attribution-.html"},{"id":"2512.15033v1","title":"Beyond Accuracy: A Geometric Stability Analysis of Large Language Models in Chess Evaluation","headline":"提出几何稳定性框架，评估大语言模型在棋类评估中的推理能力，揭示准确率与鲁棒性悖论。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215033v1-beyond-accuracy-a-geometric-stability-analysis-of-large-language-mod.html"},{"id":"2512.15038v1","title":"LADY: Linear Attention for Autonomous Driving Efficiency without Transformers","headline":"提出LADY：一种基于线性注意力的高效自动驾驶模型，无需Transformer。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215038v1-lady-linear-attention-for-autonomous-driving-efficiency-without-tran.html"},{"id":"2512.15298v1","title":"ChatGPT and Gemini participated in the Korean College Scholastic Ability Test -- Earth Science I","headline":"分析大型语言模型在韩国高考地球科学I科目的表现，揭示其认知局限性，为设计抗AI考题提供依据。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215298v1-chatgpt-and-gemini-participated-in-the-korean-college-scholastic-abi.html"},{"id":"2512.15662v1","title":"Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning","headline":"提出Stepwise Think-Critique框架，提升LLM推理能力和可解释性","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215662v1-stepwise-think-critique-a-unified-framework-for-robust-and-interpret.html"},{"id":"2512.15489v1","title":"Nemotron-Math: Efficient Long-Context Distillation of Mathematical Reasoning from Multi-Mode Supervision","headline":"Nemotron-Math：通过多模式监督，高效地进行数学推理长文本蒸馏。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215489v1-nemotron-math-efficient-long-context-distillation-of-mathematical-re.html"},{"id":"2512.15295v1","title":"Graph Contextual Reinforcement Learning for Efficient Directed Controller Synthesis","headline":"提出GCRL，利用图上下文强化学习高效合成有向控制器","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215295v1-graph-contextual-reinforcement-learning-for-efficient-directed-contr.html"},{"id":"2512.15468v1","title":"How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?","headline":"语义等价代码变换削弱代码大语言模型成员推理攻击的有效性","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215468v1-how-do-semantically-equivalent-code-transformations-impact-membershi.html"},{"id":"2512.15466v1","title":"On Assessing the Relevance of Code Reviews Authored by Generative Models","headline":"提出多主观排序评估方法，评估生成模型在代码评审中的有效性","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215466v1-on-assessing-the-relevance-of-code-reviews-authored-by-generative-mo.html"},{"id":"2512.15388v1","title":"Bilateral Spatial Reasoning about Street Networks: Graph-based RAG with Qualitative Spatial Representations","headline":"提出基于图的RAG方法，利用定性空间关系增强LLM的街道网络路径引导能力","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215388v1-bilateral-spatial-reasoning-about-street-networks-graph-based-rag-wi.html"},{"id":"2512.15374v1","title":"SCOPE: Prompt Evolution for Enhancing Agent Effectiveness","headline":"SCOPE：通过提示进化增强Agent有效性，解决大规模动态上下文中的管理瓶颈。","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215374v1-scope-prompt-evolution-for-enhancing-agent-effectiveness.html"},{"id":"2512.15343v1","title":"Exploring User Acceptance and Concerns toward LLM-powered Conversational Agents in Immersive Extended Reality","headline":"探索用户对XR沉浸式环境中LLM驱动对话代理的接受度与担忧","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215343v1-exploring-user-acceptance-and-concerns-toward-llm-powered-conversati.html"},{"id":"2512.15149v1","title":"Offline Multi-Task Multi-Objective Data-Driven Evolutionary Algorithm with Language Surrogate Model and Implicit Q-Learning","headline":"提出Q-MetaSur，利用语言模型和强化学习解决离线多任务多目标优化问题","tag":"cs.AI","date":"2025-12-17","url":"cs-AI/2025-12-17/papers/251215149v1-offline-multi-task-multi-objective-data-driven-evolutionary-algorith.html"},{"id":"2512.15052v1","title":"SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification","headline":"SGM：通过神经元级解毒为多模态大语言模型提供安全保障","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215052v1-sgm-safety-glasses-for-multimodal-large-language-models-via-neuron-l.html"},{"id":"2512.15163v1","title":"MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers","headline":"提出MCP-SafetyBench，用于评估大语言模型在真实MCP服务器环境下的安全性","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215163v1-mcp-safetybench-a-benchmark-for-safety-evaluation-of-large-language-.html"},{"id":"2512.15274v1","title":"Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning","headline":"提出PPPO方法，通过优化LLM推理前缀token策略，提升强化学习推理能力。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215274v1-well-begun-half-done-reinforcement-learning-with-prefix-optimization.html"},{"id":"2512.15653v1","title":"Characterizing Mamba's Selective Memory using Auto-Encoders","headline":"利用自编码器剖析Mamba选择性记忆的遗忘特性，揭示其在特定类型信息上的记忆短板。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215653v1-characterizing-mambas-selective-memory-using-auto-encoders.html"},{"id":"2512.15146v1","title":"Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning","headline":"提出SCOPE框架，通过细粒度置信度加权伪标签提升测试时强化学习性能","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215146v1-beyond-majority-voting-towards-fine-grained-and-more-reliable-reward.html"},{"id":"2512.15358v1","title":"Dual-Density Inference for Efficient Language Model Reasoning","headline":"提出Denser双密度推理框架，提升LLM在复杂推理问答任务中的效率。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215358v1-dual-density-inference-for-efficient-language-model-reasoning.html"},{"id":"2512.15674v1","title":"Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers","headline":"提出Activation Oracles，通过多样化训练提升LLM激活解释的通用能力。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215674v1-activation-oracles-training-and-evaluating-llms-as-general-purpose-a.html"},{"id":"2512.15634v1","title":"How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness","headline":"探索LoRA秩对知识保留和领域泛化能力的权衡，优化下游问答任务","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215634v1-how-much-is-too-much-exploring-lora-rank-trade-offs-for-retaining-kn.html"},{"id":"2512.15053v1","title":"The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops","headline":"提出Meta-Prompting协议，通过对抗反馈循环实现LLM的可靠编排与自优化。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215053v1-the-meta-prompting-protocol-orchestrating-llms-via-adversarial-feedb.html"},{"id":"2512.15617v1","title":"Evaluating Metrics for Safety with LLM-as-Judges","headline":"提出基于LLM-as-Judges的加权指标评估方法，提升LLM在安全关键任务中的可靠性。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215617v1-evaluating-metrics-for-safety-with-llm-as-judges.html"},{"id":"2512.15312v1","title":"Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies","headline":"系统评估LLM在沸石合成事件抽取（ZSEE）中的提示策略有效性","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215312v1-evaluating-llms-for-zeolite-synthesis-event-extraction-zsee-a-system.html"},{"id":"2512.15226v1","title":"Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024","headline":"Yes-MT团队探索多种模型和微调策略，解决WMT 2024低资源印度语言翻译难题。","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215226v1-yes-mts-submission-to-the-low-resource-indic-language-translation-sh.html"},{"id":"2512.15219v1","title":"RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA","headline":"RFKG-CoT：关系驱动的自适应跳数选择与少样本路径引导，提升知识图谱问答效果","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215219v1-rfkg-cot-relation-driven-adaptive-hop-count-selection-and-few-shot-p.html"},{"id":"2512.15550v1","title":"CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing","headline":"提出CTKVR：一种基于质心和Token索引的长文本LLM的KV缓存检索方法","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215550v1-ctkvr-kv-cache-retrieval-for-long-context-llms-via-centroid-then-tok.html"},{"id":"2512.15446v1","title":"Toward expert-level motivational interviewing for health behavior improvement with LLMs","headline":"利用大型语言模型实现专家级动机访谈，促进健康行为改善","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215446v1-toward-expert-level-motivational-interviewing-for-health-behavior-im.html"},{"id":"2512.15302v1","title":"Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues","headline":"提出PersonalAgent，通过用户画像定制实现对话系统中的主动个性化","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215302v1-towards-proactive-personalization-through-profile-customization-for-.html"},{"id":"2512.15248v1","title":"The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres","headline":"构建道德化语料库，用于分析跨文本类型的道德化言语行为","tag":"cs.CL","date":"2025-12-17","url":"cs-CL/2025-12-17/papers/251215248v1-the-moralization-corpus-frame-based-annotation-and-analysis-of-moral.html"},{"id":"2512.15568v1","title":"Exact Learning of Linear Model Predictive Control Laws using Oblique Decision Trees with Linear Predictions","headline":"提出基于斜决策树的线性模型预测控制法以提升计算效率与可解释性","tag":"eess.SY","date":"2025-12-17","url":"eess-SY/2025-12-17/papers/251215568v1-exact-learning-of-linear-model-predictive-control-laws-using-oblique.html"},{"id":"2512.15668v1","title":"Enhancing industrial microalgae production through Economic Model Predictive Control","headline":"提出经济模型预测控制，提升工业微藻生产的经济效益和动态稳定性","tag":"eess.SY","date":"2025-12-17","url":"eess-SY/2025-12-17/papers/251215668v1-enhancing-industrial-microalgae-production-through-economic-model-pr.html"},{"id":"2512.15533v1","title":"Ising Machines for Model Predictive Path Integral-Based Optimal Control","headline":"提出基于Ising机器的MPPI方法以优化控制问题","tag":"eess.SY","date":"2025-12-17","url":"eess-SY/2025-12-17/papers/251215533v1-ising-machines-for-model-predictive-path-integral-based-optimal-cont.html"},{"id":"2512.15677v1","title":"Service-Oriented Fast Frequency Response from Flexible Loads and Energy Storage in Low-Inertia Power Systems","headline":"提出面向服务的快速频率响应框架，用于低惯量电力系统中灵活负荷和储能的协调控制。","tag":"eess.SY","date":"2025-12-17","url":"eess-SY/2025-12-17/papers/251215677v1-service-oriented-fast-frequency-response-from-flexible-loads-and-ene.html"},{"id":"2512.14031v1","title":"Sample-Efficient Robot Skill Learning for Construction Tasks: Benchmarking Hierarchical Reinforcement Learning and Vision-Language-Action VLA Model","headline":"对比VLA模型与强化学习，提升建筑机器人操作技能并实现高效样本利用","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214031v1-sample-efficient-robot-skill-learning-for-construction-tasks-benchma.html"},{"id":"2512.14666v1","title":"EVOLVE-VLA: Test-Time Training from Environment Feedback for Vision-Language-Action Models","headline":"提出EVOLVE-VLA以解决视觉-语言-动作模型适应性不足问题","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214666v1-evolve-vla-test-time-training-from-environment-feedback-for-vision-l.html"},{"id":"2512.14689v1","title":"CHIP: Adaptive Compliance for Humanoid Control through Hindsight Perturbation","headline":"CHIP：通过后见之明扰动实现人型机器人自适应柔顺控制","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214689v1-chip-adaptive-compliance-for-humanoid-control-through-hindsight-pert.html"},{"id":"2512.14270v1","title":"CaFe-TeleVision: A Coarse-to-Fine Teleoperation System with Immersive Situated Visualization for Enhanced Ergonomics","headline":"CaFe-TeleVision：基于粗细粒度控制与沉浸式可视化的人形机器人遥操作系统，提升人机工效","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214270v1-cafe-television-a-coarse-to-fine-teleoperation-system-with-immersive.html"},{"id":"2512.14111v1","title":"Interactive Motion Planning for Human-Robot Collaboration Based on Human-Centric Configuration Space Ergonomic Field","headline":"提出基于人机协作构型空间人体工学场的交互式运动规划方法","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214111v1-interactive-motion-planning-for-human-robot-collaboration-based-on-h.html"},{"id":"2512.14411v1","title":"Synthetic Data Pipelines for Adaptive, Mission-Ready Militarized Humanoids","headline":"Omnia提出一种基于合成数据的流程，加速军用人形机器人的训练和部署。","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214411v1-synthetic-data-pipelines-for-adaptive-mission-ready-militarized-huma.html"},{"id":"2512.14057v1","title":"Context Representation via Action-Free Transformer encoder-decoder for Meta Reinforcement Learning","headline":"提出CRAFT：一种基于无动作Transformer的元强化学习上下文表示方法","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214057v1-context-representation-via-action-free-transformer-encoder-decoder-f.html"},{"id":"2512.14350v1","title":"Fine-Tuning of Neural Network Approximate MPC without Retraining via Bayesian Optimization","headline":"提出基于贝叶斯优化的神经近似MPC调参方法，无需重训练网络。","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214350v1-fine-tuning-of-neural-network-approximate-mpc-without-retraining-via.html"},{"id":"2512.14189v1","title":"SUPER -- A Framework for Sensitivity-based Uncertainty-aware Performance and Risk Assessment in Visual Inertial Odometry","headline":"SUPER：基于敏感度的视觉惯性里程计性能与风险评估框架","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214189v1-super-a-framework-for-sensitivity-based-uncertainty-aware-performanc.html"},{"id":"2512.14428v1","title":"Odyssey: An Automotive Lidar-Inertial Odometry Dataset for GNSS-denied situations","headline":"Odyssey：面向GNSS拒止环境的车载激光雷达-惯性里程计数据集","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214428v1-odyssey-an-automotive-lidar-inertial-odometry-dataset-for-gnss-denie.html"},{"id":"2512.14206v1","title":"Trajectory Tracking for Multi-Manipulator Systems in Constrained Environments","headline":"提出多速率规划控制框架，解决约束环境下多机械臂系统的轨迹跟踪问题","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214206v1-trajectory-tracking-for-multi-manipulator-systems-in-constrained-env.html"},{"id":"2512.14001v1","title":"CLAIM: Camera-LiDAR Alignment with Intensity and Monodepth","headline":"CLAIM：提出一种基于单目深度和强度信息的相机-激光雷达标定方法","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214001v1-claim-camera-lidar-alignment-with-intensity-and-monodepth.html"},{"id":"2512.14340v1","title":"Field evaluation and optimization of a lightweight lidar-based UAV navigation system for dense boreal forest environments","headline":"提出一种轻量级激光雷达无人机导航系统，并优化其在稠密北方森林环境中的性能","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214340v1-field-evaluation-and-optimization-of-a-lightweight-lidar-based-uav-n.html"},{"id":"2512.14046v1","title":"E-Navi: Environmental Adaptive Navigation for UAVs on Resource Constrained Platforms","headline":"E-Navi：面向资源受限平台，环境自适应无人机导航系统","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251214046v1-e-navi-environmental-adaptive-navigation-for-uavs-on-resource-constr.html"},{"id":"2512.13974v1","title":"Autonomous Construction-Site Safety Inspection Using Mobile Robots: A Multilayer VLM-LLM Pipeline","headline":"提出基于多层VLM-LLM流水线的移动机器人自主建筑工地安全巡检方案","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251213974v1-autonomous-construction-site-safety-inspection-using-mobile-robots-a.html"},{"id":"2512.13981v1","title":"Impact of Robot Facial-Audio Expressions on Human Robot Trust Dynamics and Trust Repair","headline":"研究机器人面部-音频表情对人机信任动态及修复的影响，面向建筑行业人机协作。","tag":"cs.RO","date":"2025-12-16","url":"cs-RO/2025-12-16/papers/251213981v1-impact-of-robot-facial-audio-expressions-on-human-robot-trust-dynami.html"},{"id":"2512.14095v1","title":"AnchorHOI: Zero-shot Generation of 4D Human-Object Interaction via Anchor-based Prior Distillation","headline":"AnchorHOI：基于锚点的先验知识蒸馏实现零样本4D人-物交互生成","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214095v1-anchorhoi-zero-shot-generation-of-4d-human-object-interaction-via-an.html"},{"id":"2512.14696v1","title":"CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives","headline":"CRISP：基于单目视频和平面场景原语的接触引导Real2Sim方法","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214696v1-crisp-contact-guided-real2sim-from-monocular-video-with-planar-scene.html"},{"id":"2512.14536v1","title":"DASP: Self-supervised Nighttime Monocular Depth Estimation with Domain Adaptation of Spatiotemporal Priors","headline":"DASP：利用时空先验域适应的自监督夜间单目深度估计","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214536v1-dasp-self-supervised-nighttime-monocular-depth-estimation-with-domai.html"},{"id":"2512.14352v1","title":"HGS: Hybrid Gaussian Splatting with Static-Dynamic Decomposition for Compact Dynamic View Synthesis","headline":"提出混合高斯溅射HGS，通过静态-动态分解实现紧凑的动态视角合成","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214352v1-hgs-hybrid-gaussian-splatting-with-static-dynamic-decomposition-for-.html"},{"id":"2512.14052v1","title":"HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices","headline":"HyperVL：面向边缘设备的高效动态多模态大语言模型","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214052v1-hypervl-an-efficient-and-dynamic-multimodal-large-language-model-for.html"},{"id":"2512.14087v1","title":"GaussianPlant: Structure-aligned Gaussian Splatting for 3D Reconstruction of Plants","headline":"GaussianPlant：提出结构对齐的高斯溅射方法，用于植物三维重建。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214087v1-gaussianplant-structure-aligned-gaussian-splatting-for-3d-reconstruc.html"},{"id":"2512.14614v1","title":"WorldPlay: Towards Long-Term Geometric Consistency for Real-Time Interactive World Modeling","headline":"WorldPlay：提出一种具有长期几何一致性的实时交互式世界建模方法。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214614v1-worldplay-towards-long-term-geometric-consistency-for-real-time-inte.html"},{"id":"2512.14200v1","title":"Beyond a Single Light: A Large-Scale Aerial Dataset for Urban Scene Reconstruction Under Varying Illumination","headline":"SkyLume：一个大规模多光照城市重建航拍数据集，用于解决光照变化下的三维重建问题。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214200v1-beyond-a-single-light-a-large-scale-aerial-dataset-for-urban-scene-r.html"},{"id":"2512.14442v1","title":"A4-Agent: An Agentic Framework for Zero-Shot Affordance Reasoning","headline":"提出A4-Agent框架以解决零-shot可供性推理问题","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214442v1-a4-agent-an-agentic-framework-for-zero-shot-affordance-reasoning.html"},{"id":"2512.14698v1","title":"TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs","headline":"TimeLens：利用多模态LLM重新思考视频时序定位任务，构建高质量基线。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214698v1-timelens-rethinking-video-temporal-grounding-with-multimodal-llms.html"},{"id":"2512.14364v1","title":"Unified Semantic Transformer for 3D Scene Understanding","headline":"提出UNITE：用于3D场景理解的统一语义Transformer模型","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214364v1-unified-semantic-transformer-for-3d-scene-understanding.html"},{"id":"2512.14044v1","title":"OmniDrive-R1: Reinforcement-driven Interleaved Multi-modal Chain-of-Thought for Trustworthy Vision-Language Autonomous Driving","headline":"OmniDrive-R1：强化学习驱动的交错多模态CoT，提升自动驾驶视觉语言模型的可靠性","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214044v1-omnidrive-r1-reinforcement-driven-interleaved-multi-modal-chain-of-t.html"},{"id":"2512.14594v1","title":"LLM-driven Knowledge Enhancement for Multimodal Cancer Survival Prediction","headline":"提出KEMM模型，利用LLM增强知识的多模态癌症生存预测。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214594v1-llm-driven-knowledge-enhancement-for-multimodal-cancer-survival-pred.html"},{"id":"2512.14102v1","title":"Neurosymbolic Inference On Foundation Models For Remote Sensing Text-to-image Retrieval With Complex Queries","headline":"提出RUNE，结合神经符号推理与大模型，解决遥感图像复杂查询的文本到图像检索问题。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214102v1-neurosymbolic-inference-on-foundation-models-for-remote-sensing-text.html"},{"id":"2512.14099v1","title":"ViewMask-1-to-3: Multi-View Consistent Image Generation via Multimodal Diffusion Models","headline":"ViewMask-1-to-3：基于多模态扩散模型实现多视角一致的图像生成","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214099v1-viewmask-1-to-3-multi-view-consistent-image-generation-via-multimoda.html"},{"id":"2512.14008v1","title":"Sparse-LaViDa: Sparse Multimodal Discrete Diffusion Language Models","headline":"Sparse-LaViDa：通过稀疏化采样加速多模态离散扩散语言模型","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214008v1-sparse-lavida-sparse-multimodal-discrete-diffusion-language-models.html"},{"id":"2512.14406v1","title":"Broadening View Synthesis of Dynamic Scenes from Constrained Monocular Videos","headline":"ExpanDyNeRF：扩展动态场景视角合成，解决单目视频大角度渲染失真问题","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214406v1-broadening-view-synthesis-of-dynamic-scenes-from-constrained-monocul.html"},{"id":"2512.14126v1","title":"Consistent Instance Field for Dynamic Scene Understanding","headline":"提出一致性实例场，用于动态场景理解中的时空连续概率建模。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214126v1-consistent-instance-field-for-dynamic-scene-understanding.html"},{"id":"2512.14020v1","title":"Deep Learning Perspective of Scene Understanding in Autonomous Robots","headline":"综述深度学习在自主机器人场景理解中的应用，提升机器人感知与决策能力","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214020v1-deep-learning-perspective-of-scene-understanding-in-autonomous-robot.html"},{"id":"2512.14499v1","title":"Native Intelligence Emerges from Large-Scale Clinical Practice: A Retinal Foundation Model with Deployment Efficiency","headline":"ReVision：基于大规模临床实践的视网膜原生智能模型，提升部署效率","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214499v1-native-intelligence-emerges-from-large-scale-clinical-practice-a-ret.html"},{"id":"2512.14489v1","title":"SignIT: A Comprehensive Dataset and Multimodal Analysis for Italian Sign Language Recognition","headline":"发布SignIT意大利手语数据集，并进行多模态手语识别基准分析","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214489v1-signit-a-comprehensive-dataset-and-multimodal-analysis-for-italian-s.html"},{"id":"2512.14309v1","title":"PSMamba: Progressive Self-supervised Vision Mamba for Plant Disease Recognition","headline":"PSMamba：一种用于植物病害识别的渐进式自监督视觉Mamba框架","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214309v1-psmamba-progressive-self-supervised-vision-mamba-for-plant-disease-r.html"},{"id":"2512.14225v1","title":"OmniGen: Unified Multimodal Sensor Generation for Autonomous Driving","headline":"OmniGen：提出统一多模态传感器生成框架，用于自动驾驶场景数据增强。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214225v1-omnigen-unified-multimodal-sensor-generation-for-autonomous-driving.html"},{"id":"2512.14058v1","title":"Real-time prediction of workplane illuminance distribution for daylight-linked controls using non-intrusive multimodal deep learning","headline":"提出基于非侵入式多模态深度学习的日光照明工作面照度实时预测方法，用于日光联动控制。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214058v1-real-time-prediction-of-workplane-illuminance-distribution-for-dayli.html"},{"id":"2512.14217v1","title":"DRAW2ACT: Turning Depth-Encoded Trajectories into Robotic Demonstration Videos","headline":"DRAW2ACT：提出深度感知的轨迹条件视频生成框架，用于机器人操作演示视频生成。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214217v1-draw2act-turning-depth-encoded-trajectories-into-robotic-demonstrati.html"},{"id":"2512.14320v1","title":"Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity","headline":"提出协同中间特征操纵（SIFM）方法，提升图像针对恶意扩散模型编辑的免疫力。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214320v1-semantic-mismatch-and-perceptual-degradation-a-new-perspective-on-im.html"},{"id":"2512.14234v1","title":"ViBES: A Conversational Agent with Behaviorally-Intelligent 3D Virtual Body","headline":"ViBES：一种具有行为智能的3D虚拟身体对话代理","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214234v1-vibes-a-conversational-agent-with-behaviorally-intelligent-3d-virtua.html"},{"id":"2512.14180v1","title":"Spherical Voronoi: Directional Appearance as a Differentiable Partition of the Sphere","headline":"提出球Voronoi图，用于3D高斯溅射中可微的方向外观建模","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214180v1-spherical-voronoi-directional-appearance-as-a-differentiable-partiti.html"},{"id":"2512.14040v1","title":"ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning","headline":"提出ChartAgent，一个工具集成推理的图表理解框架，提升稀疏标注下的鲁棒性。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214040v1-chartagent-a-chart-understanding-framework-with-tool-integrated-reas.html"},{"id":"2512.14039v1","title":"ASAP-Textured Gaussians: Enhancing Textured Gaussians with Adaptive Sampling and Anisotropic Parameterization","headline":"提出自适应采样与各向异性参数化以解决纹理高效性问题","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214039v1-asap-textured-gaussians-enhancing-textured-gaussians-with-adaptive-s.html"},{"id":"2512.14028v1","title":"Robust Single-shot Structured Light 3D Imaging via Neural Feature Decoding","headline":"提出基于神经特征解码的鲁棒单目结构光3D成像方法，提升复杂场景下的深度估计精度。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214028v1-robust-single-shot-structured-light-3d-imaging-via-neural-feature-de.html"},{"id":"2512.14017v1","title":"KFS-Bench: Comprehensive Evaluation of Key Frame Sampling in Long Video Understanding","headline":"提出KFS-Bench基准，用于长视频问答中关键帧采样的全面评估。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214017v1-kfs-bench-comprehensive-evaluation-of-key-frame-sampling-in-long-vid.html"},{"id":"2512.14440v1","title":"S2D: Sparse-To-Dense Keymask Distillation for Unsupervised Video Instance Segmentation","headline":"提出S2D：一种稀疏到稠密的Keymask蒸馏方法，用于无监督视频实例分割","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214440v1-s2d-sparse-to-dense-keymask-distillation-for-unsupervised-video-inst.html"},{"id":"2512.14654v1","title":"ViRC: Enhancing Visual Interleaved Mathematical CoT with Reason Chunking","headline":"提出ViRC框架，通过Reason Chunking增强视觉交错数学CoT推理能力","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214654v1-virc-enhancing-visual-interleaved-mathematical-cot-with-reason-chunk.html"},{"id":"2512.14574v1","title":"FoodLogAthl-218: Constructing a Real-World Food Image Dataset Using Dietary Management Applications","headline":"FoodLogAthl-218：构建基于膳食管理应用的真实食物图像数据集","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214574v1-foodlogathl-218-constructing-a-real-world-food-image-dataset-using-d.html"},{"id":"2512.14420v1","title":"DISCODE: Distribution-Aware Score Decoder for Robust Automatic Evaluation of Image Captioning","headline":"提出DISCODE，一种分布感知的分数解码器，用于提升图像描述自动评估的鲁棒性。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214420v1-discode-distribution-aware-score-decoder-for-robust-automatic-evalua.html"},{"id":"2512.14257v1","title":"Enhancing Visual Programming for Visual Reasoning via Probabilistic Graphs","headline":"提出EVPG，通过概率图增强视觉编程以提升视觉推理能力","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214257v1-enhancing-visual-programming-for-visual-reasoning-via-probabilistic-.html"},{"id":"2512.14141v1","title":"TorchTraceAP: A New Benchmark Dataset for Detecting Performance Anti-Patterns in Computer Vision Models","headline":"提出TorchTraceAP基准数据集，用于检测计算机视觉模型中的性能反模式。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214141v1-torchtraceap-a-new-benchmark-dataset-for-detecting-performance-anti-.html"},{"id":"2512.14140v1","title":"SketchAssist: A Practical Assistant for Semantic Edits and Precise Local Redrawing","headline":"SketchAssist：用于语义编辑和精确局部重绘的实用草图助手","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214140v1-sketchassist-a-practical-assistant-for-semantic-edits-and-precise-lo.html"},{"id":"2512.14113v1","title":"Selective, Controlled and Domain-Agnostic Unlearning in Pretrained CLIP: A Training- and Data-Free Approach","headline":"提出一种免训练免数据的CLIP可控选择性领域无关知识遗忘方法","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214113v1-selective-controlled-and-domain-agnostic-unlearning-in-pretrained-cl.html"},{"id":"2512.14056v1","title":"FacEDiT: Unified Talking Face Editing and Generation via Facial Motion Infilling","headline":"FacEDiT：通过面部运动填充统一实现说话人脸编辑与生成","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214056v1-facedit-unified-talking-face-editing-and-generation-via-facial-motio.html"},{"id":"2512.14677v1","title":"VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image","headline":"VASA-3D：基于单张图像的逼真音频驱动高斯头部化身生成","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214677v1-vasa-3d-lifelike-audio-driven-gaussian-head-avatars-from-a-single-im.html"},{"id":"2512.14341v1","title":"Towards Transferable Defense Against Malicious Image Edits","headline":"提出TDAE框架，增强图像对恶意编辑的防御迁移能力","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214341v1-towards-transferable-defense-against-malicious-image-edits.html"},{"id":"2512.14336v1","title":"Vector Prism: Animating Vector Graphics by Stratifying Semantic Structure","headline":"提出Vector Prism，通过分层语义结构实现矢量图形动画","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214336v1-vector-prism-animating-vector-graphics-by-stratifying-semantic-struc.html"},{"id":"2512.14236v1","title":"Elastic3D: Controllable Stereo Video Conversion with Guided Latent Decoding","headline":"Elastic3D：基于引导式潜在解码的可控立体视频转换方法","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214236v1-elastic3d-controllable-stereo-video-conversion-with-guided-latent-de.html"},{"id":"2512.14032v1","title":"ACE-SLAM: Scene Coordinate Regression for Neural Implicit Real-Time SLAM","headline":"ACE-SLAM：基于场景坐标回归的神经隐式实时SLAM系统","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214032v1-ace-slam-scene-coordinate-regression-for-neural-implicit-real-time-s.html"},{"id":"2512.14560v1","title":"CLNet: Cross-View Correspondence Makes a Stronger Geo-Localizationer","headline":"提出CLNet，通过跨视角对应关系增强图像检索地理定位","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214560v1-clnet-cross-view-correspondence-makes-a-stronger-geo-localizationer.html"},{"id":"2512.14235v1","title":"4D-RaDiff: Latent Diffusion for 4D Radar Point Cloud Generation","headline":"提出4D-RaDiff，利用潜在扩散模型生成4D雷达点云，提升目标检测性能。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214235v1-4d-radiff-latent-diffusion-for-4d-radar-point-cloud-generation.html"},{"id":"2512.14222v1","title":"History-Enhanced Two-Stage Transformer for Aerial Vision-and-Language Navigation","headline":"提出历史增强型两阶段Transformer，解决无人机视觉语言导航中全局推理与局部理解的平衡问题","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214222v1-history-enhanced-two-stage-transformer-for-aerial-vision-and-languag.html"},{"id":"2512.14162v1","title":"FastDDHPose: Towards Unified, Efficient, and Disentangled 3D Human Pose Estimation","headline":"FastDDHPose：统一、高效、解耦的3D人体姿态估计方法","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214162v1-fastddhpose-towards-unified-efficient-and-disentangled-3d-human-pose.html"},{"id":"2512.14274v1","title":"TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning","headline":"提出TUN网络，利用深度学习自动检测持久同调图中显著特征点。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214274v1-tun-detecting-significant-points-in-persistence-diagrams-with-deep-l.html"},{"id":"2512.14273v1","title":"Zoom-Zero: Reinforced Coarse-to-Fine Video Understanding via Temporal Zoom-in","headline":"Zoom-Zero：通过时间域缩放增强视频理解，解决GVQA中时序定位不准问题。","tag":"cs.CV","date":"2025-12-16","url":"cs-CV/2025-12-16/papers/251214273v1-zoom-zero-reinforced-coarse-to-fine-video-understanding-via-temporal.html"},{"id":"2512.14133v1","title":"AnimaMimic: Imitating 3D Animation from Video Priors","headline":"AnimaMimic：利用视频先验模仿3D动画，实现可控、逼真的动画生成","tag":"cs.GR","date":"2025-12-16","url":"cs-GR/2025-12-16/papers/251214133v1-animamimic-imitating-3d-animation-from-video-priors.html"},{"id":"2512.14230v1","title":"Understanding the Gain from Data Filtering in Multimodal Contrastive Learning","headline":"提出教师模型过滤以提升多模态对比学习效果","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214230v1-understanding-the-gain-from-data-filtering-in-multimodal-contrastive.html"},{"id":"2512.14115v1","title":"Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting","headline":"提出联合多模态对比学习框架，提升语音检索任务的鲁棒性与效率","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214115v1-joint-multimodal-contrastive-learning-for-robust-spoken-term-detecti.html"},{"id":"2512.14100v1","title":"A First-Order Logic-Based Alternative to Reward Models in RLHF","headline":"提出基于逻辑相似性的S-GRPO，替代RLHF中的奖励模型，提升对齐效果。","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214100v1-a-first-order-logic-based-alternative-to-reward-models-in-rlhf.html"},{"id":"2512.14019v1","title":"EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment","headline":"EXAONE Path 2.5：多组学对齐的病理学基础模型，用于更全面的肿瘤生物学理解","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214019v1-exaone-path-25-pathology-foundation-model-with-multi-omics-alignment.html"},{"id":"2512.14098v1","title":"Cornserve: Efficiently Serving Any-to-Any Multimodal Models","headline":"Cornserve：高效服务任意到任意多模态模型的在线服务系统","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214098v1-cornserve-efficiently-serving-any-to-any-multimodal-models.html"},{"id":"2512.14202v1","title":"Understanding and Improving Hyperbolic Deep Reinforcement Learning","headline":"提出Hyper++，解决双曲深度强化学习中梯度不稳定和训练困难问题","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214202v1-understanding-and-improving-hyperbolic-deep-reinforcement-learning.html"},{"id":"2512.14220v1","title":"Estimating problem difficulty without ground truth using Large Language Model comparisons","headline":"提出LLM compare以解决无基准真值问题的难度估计","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214220v1-estimating-problem-difficulty-without-ground-truth-using-large-langu.html"},{"id":"2512.14617v1","title":"Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes","headline":"提出QR-MAX算法，解决离散动作非马尔可夫奖励决策过程中的模型学习与策略优化问题","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214617v1-model-based-reinforcement-learning-in-discrete-action-non-markovian-.html"},{"id":"2512.14619v1","title":"ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning","headline":"提出ParaFormer，一种基于PageRank增强的图Transformer，缓解图表示学习中的过平滑问题。","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214619v1-paraformer-a-generalized-pagerank-graph-transformer-for-graph-repres.html"},{"id":"2512.14471v1","title":"Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics","headline":"Kinetic-Mamba：利用Mamba架构预测刚性化学动力学，提升燃烧模拟精度。","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214471v1-kinetic-mamba-mamba-assisted-predictions-of-stiff-chemical-kinetics.html"},{"id":"2512.14263v1","title":"Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization","headline":"提出基于决策树的可解释偏好学习模型以优化偏好贝叶斯优化","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214263v1-explainable-preference-learning-a-decision-tree-based-surrogate-mode.html"},{"id":"2512.14391v1","title":"RePo: Language Models with Context Re-Positioning","headline":"提出RePo：通过上下文重定位增强语言模型处理噪声、结构化数据和长文本能力","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214391v1-repo-language-models-with-context-re-positioning.html"},{"id":"2512.14253v1","title":"FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting","headline":"FLAME：基于流增强勒让德记忆模型，用于通用时间序列预测","tag":"cs.LG","date":"2025-12-16","url":"cs-LG/2025-12-16/papers/251214253v1-flame-flow-enhanced-legendre-memory-models-for-general-time-series-f.html"},{"id":"2512.14228v1","title":"Georeferencing complex relative locality descriptions with large language models","headline":"利用大型语言模型解决生物多样性领域复杂相对位置描述的地理定位问题","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214228v1-georeferencing-complex-relative-locality-descriptions-with-large-lan.html"},{"id":"2512.14106v1","title":"HydroGEM: A Self Supervised Zero Shot Hybrid TCN Transformer Foundation Model for Continental Scale Streamflow Quality Control","headline":"HydroGEM：用于洲际尺度流量质量控制的自监督零样本混合TCN-Transformer基础模型","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214106v1-hydrogem-a-self-supervised-zero-shot-hybrid-tcn-transformer-foundati.html"},{"id":"2512.14069v1","title":"RADAR: Accelerating Large Language Model Inference With RL-Based Dynamic Draft Trees","headline":"RADAR：基于强化学习的动态草稿树加速大语言模型推理","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214069v1-radar-accelerating-large-language-model-inference-with-rl-based-dyna.html"},{"id":"2512.14048v1","title":"Intention Chain-of-Thought Prompting with Dynamic Routing for Code Generation","headline":"提出RoutingGen框架，通过动态路由和意图链式思考提升代码生成性能。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214048v1-intention-chain-of-thought-prompting-with-dynamic-routing-for-code-g.html"},{"id":"2512.13996v1","title":"Sparsity-Controllable Dynamic Top-p MoE for Large Foundation Model Pre-training","headline":"提出DTop-p MoE，实现稀疏度可控的动态Top-p路由，提升大模型预训练效果。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251213996v1-sparsity-controllable-dynamic-top-p-moe-for-large-foundation-model-p.html"},{"id":"2512.14233v1","title":"PentestEval: Benchmarking LLM-based Penetration Testing with Modular and Stage-Level Design","headline":"PentestEval：首个模块化、分阶段评估LLM渗透测试能力的综合基准","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214233v1-pentesteval-benchmarking-llm-based-penetration-testing-with-modular-.html"},{"id":"2512.14395v1","title":"Massive Editing for Large Language Models Based on Dynamic Weight Generation","headline":"提出基于动态权重生成的大语言模型批量知识编辑方法MeG","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214395v1-massive-editing-for-large-language-models-based-on-dynamic-weight-ge.html"},{"id":"2512.14329v1","title":"A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data","headline":"提出数据-物理混合生成模型，利用可穿戴传感器数据实现卒中后患者的个性化运动康复。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214329v1-a-data-physics-hybrid-generative-model-for-patient-specific-post-str.html"},{"id":"2512.14018v1","title":"PerfCoder: Large Language Models for Interpretable Code Performance Optimization","headline":"PerfCoder：基于大语言模型的可解释代码性能优化","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214018v1-perfcoder-large-language-models-for-interpretable-code-performance-o.html"},{"id":"2512.14157v1","title":"Incentivizing Tool-augmented Thinking with Images for Medical Image Analysis","headline":"Ophiuchus：一种工具增强的医学图像分析框架，提升MLLM的细粒度推理能力","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214157v1-incentivizing-tool-augmented-thinking-with-images-for-medical-image-.html"},{"id":"2512.14465v1","title":"Context-Picker: Dynamic context selection using multi-stage reinforcement learning","headline":"Context-Picker：利用多阶段强化学习动态选择长文本问答上下文","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214465v1-context-picker-dynamic-context-selection-using-multi-stage-reinforce.html"},{"id":"2512.14474v1","title":"Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling","headline":"提出Model-First Reasoning，通过显式建模减少LLM在复杂规划任务中的幻觉","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214474v1-model-first-reasoning-llm-agents-reducing-hallucinations-through-exp.html"},{"id":"2512.14288v1","title":"Leveraging LLMs for Collaborative Ontology Engineering in Parkinson Disease Monitoring and Alerting","headline":"利用大型语言模型进行帕金森病监测和预警的协同本体工程","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214288v1-leveraging-llms-for-collaborative-ontology-engineering-in-parkinson-.html"},{"id":"2512.14051v1","title":"OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value","headline":"OpenDataArena：一个公平开放的平台，用于评估后训练数据集的价值","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214051v1-opendataarena-a-fair-and-open-arena-for-benchmarking-post-training-d.html"},{"id":"2512.14043v1","title":"Evaluating Small Language Models for Agentic On-Farm Decision Support Systems","headline":"评估小型语言模型在农场决策支持系统中的应用潜力，Qwen-4B表现突出。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214043v1-evaluating-small-language-models-for-agentic-on-farm-decision-suppor.html"},{"id":"2512.14014v1","title":"MobileWorldBench: Towards Semantic World Modeling For Mobile Agents","headline":"提出MobileWorldBench，利用视觉-语言模型为移动Agent构建语义世界模型","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214014v1-mobileworldbench-towards-semantic-world-modeling-for-mobile-agents.html"},{"id":"2512.14429v1","title":"Seismology modeling agent: A smart assistant for geophysical researchers","headline":"提出基于大语言模型的地震学建模智能助手，降低SPECFEM使用门槛。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214429v1-seismology-modeling-agent-a-smart-assistant-for-geophysical-research.html"},{"id":"2512.14417v1","title":"PortAgent: LLM-driven Vehicle Dispatching Agent for Port Terminals","headline":"PortAgent：基于LLM的港口车辆调度智能体，提升跨港口迁移能力","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214417v1-portagent-llm-driven-vehicle-dispatching-agent-for-port-terminals.html"},{"id":"2512.14358v1","title":"TiCard: Deployable EXPLAIN-only Residual Learning for Cardinality Estimation","headline":"TiCard：一种可部署的、仅使用EXPLAIN信息的基数估计残差学习框架","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214358v1-ticard-deployable-explain-only-residual-learning-for-cardinality-est.html"},{"id":"2512.14297v1","title":"A Threshold-Triggered Deep Q-Network-Based Framework for Self-Healing in Autonomic Software-Defined IIoT-Edge Networks","headline":"提出基于阈值触发深度Q网络的自愈框架，用于软件定义IIoT边缘网络","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214297v1-a-threshold-triggered-deep-q-network-based-framework-for-self-healin.html"},{"id":"2512.14277v1","title":"SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions","headline":"SPARQL-LLM：一种基于轻量级元数据的实时自然语言到SPARQL查询生成方法","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214277v1-sparql-llm-real-time-sparql-query-generation-from-natural-language-q.html"},{"id":"2512.14166v1","title":"IntentMiner: Intent Inversion Attack via Tool Call Analysis in the Model Context Protocol","headline":"提出IntentMiner，通过分析工具调用日志实现用户意图反演攻击。","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214166v1-intentminer-intent-inversion-attack-via-tool-call-analysis-in-the-mo.html"},{"id":"2512.14138v1","title":"LAPPI: Interactive Optimization with LLM-Assisted Preference-Based Problem Instantiation","headline":"LAPPI：利用LLM辅助的偏好问题实例化进行交互式优化","tag":"cs.AI","date":"2025-12-16","url":"cs-AI/2025-12-16/papers/251214138v1-lappi-interactive-optimization-with-llm-assisted-preference-based-pr.html"},{"id":"2512.14620v1","title":"JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction","headline":"提出JMMMU-Pro日语多学科多模态理解基准，并提出Vibe基准构建方法。","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214620v1-jmmmu-pro-image-based-japanese-multi-discipline-multimodal-understan.html"},{"id":"2512.14427v1","title":"Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models","headline":"研究文档打包策略对大语言模型多跳推理能力的影响","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214427v1-effect-of-document-packing-on-the-latent-multi-hop-reasoning-capabil.html"},{"id":"2512.14554v1","title":"VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models","headline":"提出VLegal-Bench，用于评估LLM在越南法律推理任务中的能力。","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214554v1-vlegal-bench-cognitively-grounded-benchmark-for-vietnamese-legal-rea.html"},{"id":"2512.14481v1","title":"SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models","headline":"SASQ：一种面向大语言模型激活量化的静态激活缩放量化感知训练方法","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214481v1-sasq-static-activation-scaling-for-quantization-aware-training-in-la.html"},{"id":"2512.14561v1","title":"Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis","headline":"综合研究表明大型语言模型在自动作文评分中与人类评分者具有中等至良好的一致性","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214561v1-agreement-between-large-language-models-and-human-raters-in-essay-sc.html"},{"id":"2512.14306v1","title":"Inflation Attitudes of Large Language Models","headline":"利用大型语言模型GPT-3.5研究通货膨胀感知与预期，模拟人类调查并分析影响因素。","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214306v1-inflation-attitudes-of-large-language-models.html"},{"id":"2512.14118v1","title":"CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models","headline":"CogMem：一种认知记忆架构，用于大型语言模型中持续的多轮推理","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214118v1-cogmem-a-cognitive-memory-architecture-for-sustained-multi-turn-reas.html"},{"id":"2512.14064v1","title":"What Affects the Effective Depth of Large Language Models?","headline":"研究揭示大语言模型有效深度受限，为模型优化提供新视角","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214064v1-what-affects-the-effective-depth-of-large-language-models.html"},{"id":"2512.14237v1","title":"Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets","headline":"提出Ladder Side Tuning以解决大语言模型微调的内存瓶颈问题","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214237v1-ladder-up-memory-down-low-cost-fine-tuning-with-side-nets.html"},{"id":"2512.14083v1","title":"Scalable Frameworks for Real-World Audio-Visual Speech Recognition","headline":"提出可扩展框架，提升真实场景下音视频语音识别的鲁棒性。","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214083v1-scalable-frameworks-for-real-world-audio-visual-speech-recognition.html"},{"id":"2512.14500v1","title":"C-ing Clearly: Enhanced Binary Code Explanations using C code","headline":"C-ing Clearly：利用C代码增强LLM对二进制代码的理解，提升代码解释能力","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214500v1-c-ing-clearly-enhanced-binary-code-explanations-using-c-code.html"},{"id":"2512.14531v1","title":"VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse","headline":"VersatileFFN：通过自适应宽深复用提升LLM的参数效率","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214531v1-versatileffn-achieving-parameter-efficiency-in-llms-via-adaptive-wid.html"},{"id":"2512.14239v1","title":"Two CFG Nahuatl for automatic corpora expansion","headline":"提出两种CFG Nahuatl方法，用于自动扩展Nawatl语料库","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214239v1-two-cfg-nahuatl-for-automatic-corpora-expansion.html"},{"id":"2512.14142v1","title":"Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents","headline":"Astraea：面向LLM智能体的状态感知调度引擎，优化端到端延迟","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214142v1-astraea-a-state-aware-scheduling-engine-for-llm-powered-agents.html"},{"id":"2512.14085v1","title":"Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study","headline":"提出一种多语种连续后通道预测模型，用于研究跨语言的交互时序行为。","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214085v1-multilingual-and-continuous-backchannel-prediction-a-cross-lingual-s.html"},{"id":"2512.14082v1","title":"A Unified Sparse Attention via Multi-Granularity Compression","headline":"提出UniSparse以解决长序列自注意力计算瓶颈问题","tag":"cs.CL","date":"2025-12-16","url":"cs-CL/2025-12-16/papers/251214082v1-a-unified-sparse-attention-via-multi-granularity-compression.html"},{"id":"2512.14510v1","title":"Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX","headline":"提出基于SSARX的闭环一致因果数据驱动预测控制方法","tag":"eess.SY","date":"2025-12-16","url":"eess-SY/2025-12-16/papers/251214510v1-closed-loop-consistent-causal-data-driven-predictive-control-via-ssa.html"},{"id":"2512.14136v1","title":"Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems","headline":"提出一种协同控制框架，聚合电动汽车、数据中心和储能系统，实现快速频率响应。","tag":"eess.SY","date":"2025-12-16","url":"eess-SY/2025-12-16/papers/251214136v1-coordinated-fast-frequency-response-from-electric-vehicles-data-cent.html"},{"id":"2512.13304v1","title":"Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories","headline":"提出基于弹簧-质量轨迹的人形机器人步态自适应框架，实现复杂地形运动。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213304v1-humanoid-robot-running-through-random-stepping-stones-and-jumping-ov.html"},{"id":"2512.13644v1","title":"World Models Can Leverage Human Videos for Dexterous Manipulation","headline":"提出DexWM，利用人类视频提升灵巧操作世界模型的预测能力","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213644v1-world-models-can-leverage-human-videos-for-dexterous-manipulation.html"},{"id":"2512.12993v1","title":"Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations","headline":"提出一种基于降维感知表示的地形感知双足运动学习方法","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251212993v1-learning-terrain-aware-bipedal-locomotion-via-reduced-dimensional-pe.html"},{"id":"2512.13093v1","title":"PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations","headline":"提出PvP框架，利用本体感受特权对比学习提升人形机器人数据效率。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213093v1-pvp-data-efficient-humanoid-robot-learning-with-proprioceptive-privi.html"},{"id":"2512.13380v1","title":"Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning","headline":"提出DemoFunGrasp，通过演示编辑强化学习实现通用灵巧的功能性抓取","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213380v1-universal-dexterous-functional-grasping-via-demonstration-editing-re.html"},{"id":"2512.13100v1","title":"OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning","headline":"提出OXE-AugE数据集，通过机器人增强扩展OXE，提升跨具身策略学习能力。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213100v1-oxe-auge-a-large-scale-robot-augmentation-of-oxe-for-scaling-cross-e.html"},{"id":"2512.13215v1","title":"Multi-directional Safe Rectangle Corridor-Based MPC for Nonholonomic Robots Navigation in Cluttered Environment","headline":"提出基于多方向安全矩形走廊的MPC方法，解决非完整机器人复杂环境导航问题","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213215v1-multi-directional-safe-rectangle-corridor-based-mpc-for-nonholonomic.html"},{"id":"2512.13514v1","title":"Reinforcement Learning based 6-DoF Maneuvers for Microgravity Intravehicular Docking: A Simulation Study with Int-Ball2 in ISS-JEM","headline":"提出基于强化学习的6自由度微重力舱内对接方法，用于国际空间站Int-Ball2机器人。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213514v1-reinforcement-learning-based-6-dof-maneuvers-for-microgravity-intrav.html"},{"id":"2512.13359v1","title":"Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles","headline":"提出基于GPU加速强化学习的AUV六自由度位置控制方法，实现零样本迁移。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213359v1-fast-policy-learning-for-6-dof-position-control-of-underwater-vehicl.html"},{"id":"2512.13153v1","title":"START: Traversing Sparse Footholds with Terrain Reconstruction","headline":"START：基于地形重建的稀疏落脚点四足机器人运动","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213153v1-start-traversing-sparse-footholds-with-terrain-reconstruction.html"},{"id":"2512.13293v2","title":"Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration","headline":"提出基于内在动机的多机器人社会编队导航算法，实现协同探索。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213293v2-intrinsic-motivation-multi-robot-social-formation-navigation-with-co.html"},{"id":"2512.13670v1","title":"NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks","headline":"提出NL2SpaTiaL数据集和翻译验证框架，用于机器人操作任务中的自然语言到时空逻辑生成。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213670v1-nl2spatial-generating-geometric-spatio-temporal-logic-specifications.html"},{"id":"2512.13477v1","title":"Evaluating the Navigation Capabilities of a Modified COAST Guidewire Robot in an Anatomical Phantom Model","headline":"评估改进型COAST导丝机器人在解剖模型中的导航能力","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213477v1-evaluating-the-navigation-capabilities-of-a-modified-coast-guidewire.html"},{"id":"2512.13170v1","title":"Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks","headline":"提出一种基于任务级反馈的非线性模型预测控制迭代调优框架，用于机器人制造任务。","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213170v1-iterative-tuning-of-nonlinear-model-predictive-control-for-robotic-m.html"},{"id":"2512.13090v1","title":"Multi-Robot Motion Planning from Vision and Language using Heat-Inspired Diffusion","headline":"提出基于热扩散的多机器人视觉语言运动规划框架LCHD","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213090v1-multi-robot-motion-planning-from-vision-and-language-using-heat-insp.html"},{"id":"2512.12987v1","title":"Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning","headline":"提出基于鲁棒强化学习的车道保持系统，解决雪地自动驾驶难题","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251212987v1-tackling-snow-induced-challenges-safe-autonomous-lane-keeping-with-r.html"},{"id":"2512.13660v1","title":"RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics","headline":"RoboTracer：利用视觉-语言模型推理实现机器人空间轨迹追踪","tag":"cs.RO","date":"2025-12-15","url":"cs-RO/2025-12-15/papers/251213660v1-robotracer-mastering-spatial-trace-with-reasoning-in-vision-language.html"},{"id":"2512.13840v1","title":"MoLingo: Motion-Language Alignment for Text-to-Motion Generation","headline":"MoLingo：通过运动-语言对齐实现文本到动作生成，达到新的SOTA。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213840v1-molingo-motion-language-alignment-for-text-to-motion-generation.html"},{"id":"2512.13147v1","title":"StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion","headline":"StarryGazer：利用单目深度估计模型实现领域无关的单深度图像补全","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213147v1-starrygazer-leveraging-monocular-depth-estimation-models-for-domain-.html"},{"id":"2512.13796v1","title":"Nexels: Neurally-Textured Surfels for Real-Time Novel View Synthesis with Sparse Geometries","headline":"提出基于神经纹理Surfel的新视角合成方法，在稀疏几何下实现实时渲染。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213796v1-nexels-neurally-textured-surfels-for-real-time-novel-view-synthesis-.html"},{"id":"2512.13639v1","title":"Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All","headline":"提出Charge数据集，用于高质量新视角合成的综合基准测试。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213639v1-charge-a-comprehensive-novel-view-synthesis-benchmark-and-dataset-to.html"},{"id":"2512.13411v1","title":"Computer vision training dataset generation for robotic environments using Gaussian splatting","headline":"提出基于高斯溅射的机器人环境计算机视觉训练数据集生成流程","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213411v1-computer-vision-training-dataset-generation-for-robotic-environments.html"},{"id":"2512.13177v2","title":"MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion","headline":"MMDrive：提出多模态融合的交互式场景理解框架，超越视觉局限","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213177v2-mmdrive-interactive-scene-understanding-beyond-vision-with-multi-rep.html"},{"id":"2512.13030v1","title":"Motus: A Unified Latent Action World Model","headline":"提出Motus以解决多模态生成能力统一问题","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213030v1-motus-a-unified-latent-action-world-model.html"},{"id":"2512.13684v1","title":"Recurrent Video Masked Autoencoders","headline":"提出RVM：一种基于Transformer循环神经网络的视频掩码自编码器，用于高效视频表征学习。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213684v1-recurrent-video-masked-autoencoders.html"},{"id":"2512.13636v2","title":"MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning","headline":"MindDrive：提出基于在线强化学习的视觉-语言-动作模型，用于自动驾驶。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213636v2-minddrive-a-vision-language-action-model-for-autonomous-driving-via-.html"},{"id":"2512.13434v1","title":"Self-Supervised Ultrasound Representation Learning for Renal Anomaly Prediction in Prenatal Imaging","headline":"提出基于自监督学习的USF-MAE模型，用于产前超声肾脏异常自动预测。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213434v1-self-supervised-ultrasound-representation-learning-for-renal-anomaly.html"},{"id":"2512.13008v1","title":"TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading","headline":"提出TWLR框架，利用文本引导的弱监督学习进行糖尿病视网膜病变分级与病灶定位。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213008v1-twlr-text-guided-weakly-supervised-lesion-localization-and-severity-.html"},{"id":"2512.13874v1","title":"SAGE: Training Smart Any-Horizon Agents for Long Video Reasoning with Reinforcement Learning","headline":"提出SAGE，利用强化学习训练智能任意时域Agent，用于长视频推理。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213874v1-sage-training-smart-any-horizon-agents-for-long-video-reasoning-with.html"},{"id":"2512.13604v1","title":"LongVie 2: Multimodal Controllable Ultra-Long Video World Model","headline":"LongVie 2：多模态可控超长视频世界模型，实现高质量长时序视频生成。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213604v1-longvie-2-multimodal-controllable-ultra-long-video-world-model.html"},{"id":"2512.13095v1","title":"ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning","headline":"ADHint：利用难度先验的自适应提示强化学习，提升推理能力和泛化性","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213095v1-adhint-adaptive-hints-with-difficulty-priors-for-reinforcement-learn.html"},{"id":"2512.13680v1","title":"LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction","headline":"提出LASER以解决流媒体4D重建中的训练需求问题","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213680v1-laser-layer-wise-scale-alignment-for-training-free-streaming-4d-reco.html"},{"id":"2512.13421v1","title":"RecTok: Reconstruction Distillation along Rectified Flow","headline":"RecTok：通过校正流上的重构蒸馏，突破高维视觉Tokenizers的性能瓶颈","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213421v1-rectok-reconstruction-distillation-along-rectified-flow.html"},{"id":"2512.13671v1","title":"AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection","headline":"AgentIAD：工具增强的单智能体工业异常检测框架","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213671v1-agentiad-tool-augmented-single-agent-for-industrial-anomaly-detectio.html"},{"id":"2512.13665v1","title":"Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency","headline":"提出Grab-3D，利用3D几何时序一致性检测AI生成视频","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213665v1-grab-3d-detecting-ai-generated-videos-from-3d-geometric-temporal-con.html"},{"id":"2512.13560v1","title":"3D Human-Human Interaction Anomaly Detection","headline":"提出IADNet，用于检测3D人体交互中的异常行为","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213560v1-3d-human-human-interaction-anomaly-detection.html"},{"id":"2512.13689v1","title":"LitePT: Lighter Yet Stronger Point Transformer","headline":"LitePT：一种更轻量但更强大的点云Transformer，通过卷积与注意力机制的有效结合提升性能。","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213689v1-litept-lighter-yet-stronger-point-transformer.html"},{"id":"2512.13683v1","title":"I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners","headline":"I-Scene：利用预训练3D实例生成器实现可泛化的隐式场景空间学习","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213683v1-i-scene-3d-instance-models-are-implicit-generalizable-spatial-learne.html"},{"id":"2512.13313v1","title":"KlingAvatar 2.0 Technical Report","headline":"提出KlingAvatar 2.0以解决长视频生成中的效率与一致性问题","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213313v1-klingavatar-20-technical-report.html"},{"id":"2512.13122v1","title":"DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass","headline":"DePT3R：单次前向传播实现动态场景的联合稠密点追踪与3D重建","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251213122v1-dept3r-joint-dense-point-tracking-and-3d-reconstruction-of-dynamic-s.html"},{"id":"2512.12984v1","title":"VoroLight: Learning Quality Volumetric Voronoi Meshes from General Inputs","headline":"VoroLight：提出基于可微Voronoi图的通用输入三维形状重建框架","tag":"cs.CV","date":"2025-12-15","url":"cs-CV/2025-12-15/papers/251212984v1-vorolight-learning-quality-volumetric-voronoi-meshes-from-general-in.html"},{"id":"2512.13770v1","title":"Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training","headline":"提出MV-SupGCN，通过监督对比学习和自训练增强半监督多视图图卷积网络","tag":"cs.LG","date":"2025-12-15","url":"cs-LG/2025-12-15/papers/251213770v1-enhancing-semi-supervised-multi-view-graph-convolutional-networks-vi.html"},{"id":"2512.13497v1","title":"On-Device Continual Learning for Unsupervised Visual Anomaly Detection in Dynamic Manufacturing","headline":"提出基于设备端持续学习的PatchCore改进方法，用于动态制造中的无监督视觉异常检测。","tag":"cs.LG","date":"2025-12-15","url":"cs-LG/2025-12-15/papers/251213497v1-on-device-continual-learning-for-unsupervised-visual-anomaly-detecti.html"},{"id":"2512.12549v1","title":"Supervised Contrastive Frame Aggregation for Video Representation Learning","headline":"提出监督对比帧聚合方法，用于高效视频表征学习。","tag":"cs.CV","date":"2025-12-14","url":"cs-CV/2025-12-14/papers/251212549v1-supervised-contrastive-frame-aggregation-for-video-representation-le.html"},{"id":"2512.12437v1","title":"Sim2Real Reinforcement Learning for Soccer skills","headline":"提出基于课程学习和对抗运动先验的强化学习方法，用于训练人形机器人足球技能","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212437v1-sim2real-reinforcement-learning-for-soccer-skills.html"},{"id":"2512.12230v1","title":"Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy","headline":"提出一种通用人形机器人策略，实现跨形态零样本摔倒恢复","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212230v1-learning-to-get-up-across-morphologies-zero-shot-recovery-with-a-uni.html"},{"id":"2512.12203v1","title":"Navigation Around Unknown Space Objects Using Visible-Thermal Image Fusion","headline":"提出可见光-热红外图像融合方法，提升未知空间物体导航精度","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212203v1-navigation-around-unknown-space-objects-using-visible-thermal-image-.html"},{"id":"2512.12427v1","title":"Unifying Quadrotor Motion Planning and Control by Chaining Different Fidelity Models","headline":"Unique：通过链式不同精度模型，统一四旋翼运动规划与控制","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212427v1-unifying-quadrotor-motion-planning-and-control-by-chaining-different.html"},{"id":"2512.12377v1","title":"INDOOR-LiDAR: Bridging Simulation and Reality for Robot-Centric 360 degree Indoor LiDAR Perception -- A Robot-Centric Hybrid Dataset","headline":"INDOOR-LiDAR：提出机器人中心室内360度LiDAR感知混合数据集，弥合模拟与现实差距。","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212377v1-indoor-lidar-bridging-simulation-and-reality-for-robot-centric-360-d.html"},{"id":"2512.12233v1","title":"Robust Underwater Localization of Buoyancy Driven microFloats Using Acoustic Time-of-Flight Measurements","headline":"提出一种基于双向声学飞行时间测量的微浮标水下稳健定位方法","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212233v1-robust-underwater-localization-of-buoyancy-driven-microfloats-using-.html"},{"id":"2512.12194v1","title":"B-ActiveSEAL: Scalable Uncertainty-Aware Active Exploration with Tightly Coupled Localization-Mapping","headline":"B-ActiveSEAL：基于紧耦合定位-建图的可扩展不确定性感知主动探索框架","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212194v1-b-activeseal-scalable-uncertainty-aware-active-exploration-with-tigh.html"},{"id":"2512.12468v1","title":"Autonomously Unweaving Multiple Cables Using Visual Feedback","headline":"提出基于视觉反馈的多电缆自主解缠方法，解决机器人电缆管理难题","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212468v1-autonomously-unweaving-multiple-cables-using-visual-feedback.html"},{"id":"2512.12320v1","title":"Programmable Deformation Design of Porous Soft Actuator through Volumetric-Pattern-Induced Anisotropy","headline":"提出基于体积图案诱导各向异性的多孔软体驱动器可编程形变设计方法","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212320v1-programmable-deformation-design-of-porous-soft-actuator-through-volu.html"},{"id":"2512.12228v1","title":"Semantic Zone based 3D Map Management for Mobile Robot","headline":"提出基于语义区域的3D地图管理方法，解决移动机器人在大场景下的内存限制问题","tag":"cs.RO","date":"2025-12-13","url":"cs-RO/2025-12-13/papers/251212228v1-semantic-zone-based-3d-map-management-for-mobile-robot.html"},{"id":"2512.12425v1","title":"BokehDepth: Enhancing Monocular Depth Estimation through Bokeh Generation","headline":"提出BokehDepth，利用散焦作为辅助几何线索，提升单目深度估计的精度和鲁棒性。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212425v1-bokehdepth-enhancing-monocular-depth-estimation-through-bokeh-genera.html"},{"id":"2512.12386v1","title":"Speedrunning ImageNet Diffusion","headline":"提出SR-DiT，通过集成多种优化策略加速ImageNet扩散模型训练。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212386v1-speedrunning-imagenet-diffusion.html"},{"id":"2512.12165v2","title":"Audio-Visual Camera Pose Estimation with Passive Scene Sounds and In-the-Wild Video","headline":"提出一种音视频融合的相机位姿估计方法，利用场景声音增强视觉信息，提升野外视频的鲁棒性。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212165v2-audio-visual-camera-pose-estimation-with-passive-scene-sounds-and-in.html"},{"id":"2512.12208v1","title":"A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction","headline":"提出一种混合深度学习框架，用于识别自闭症儿童在NAO机器人交互中的情绪。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212208v1-a-hybrid-deep-learning-framework-for-emotion-recognition-in-children.html"},{"id":"2512.12307v1","title":"MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding","headline":"提出MRD，利用可微渲染探究视觉模型对3D场景的理解能力","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212307v1-mrd-using-physically-based-differentiable-rendering-to-probe-vision-.html"},{"id":"2512.12430v1","title":"Endless World: Real-Time 3D-Aware Long Video Generation","headline":"Endless World：实时3D感知无限长视频生成框架","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212430v1-endless-world-real-time-3d-aware-long-video-generation.html"},{"id":"2512.12410v1","title":"A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams","headline":"提出基于图注意力网络的LiDAR缺失波束重建框架，提升自动驾驶环境感知能力。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212410v1-a-graph-attention-network-based-framework-for-reconstructing-missing.html"},{"id":"2512.12206v1","title":"ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB","headline":"提出ISA-ViT和ALERT数据集，用于解决基于IR-UWB雷达的驾驶员行为识别问题","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212206v1-alert-open-dataset-and-input-size-agnostic-vision-transformer-for-dr.html"},{"id":"2512.12205v1","title":"A Multi-Year Urban Streetlight Imagery Dataset for Visual Monitoring and Spatio-Temporal Drift Detection","headline":"发布城市街道照明多年度图像数据集，用于视觉监控和时空漂移检测。","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212205v1-a-multi-year-urban-streetlight-imagery-dataset-for-visual-monitoring.html"},{"id":"2512.12193v1","title":"SMRABooth: Subject and Motion Representation Alignment for Customized Video Generation","headline":"SMRABooth：通过主体与运动表征对齐实现定制化视频生成","tag":"cs.CV","date":"2025-12-13","url":"cs-CV/2025-12-13/papers/251212193v1-smrabooth-subject-and-motion-representation-alignment-for-customized.html"},{"id":"2512.13729v1","title":"Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution","headline":"提出复合无分类器引导（CCFG）方法，用于提升风力动力学超分辨率重建质量。","tag":"cs.LG","date":"2025-12-13","url":"cs-LG/2025-12-13/papers/251213729v1-composite-classifier-free-guidance-for-multi-modal-conditioning-in-w.html"},{"id":"2512.11609v1","title":"UniBYD: A Unified Framework for Learning Robotic Manipulation Across Embodiments Beyond Imitation of Human Demonstrations","headline":"UniBYD：统一框架，超越人类模仿，学习跨形态机器人操作","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211609v1-unibyd-a-unified-framework-for-learning-robotic-manipulation-across-.html"},{"id":"2512.11773v1","title":"ProbeMDE: Uncertainty-Guided Active Proprioception for Monocular Depth Estimation in Surgical Robotics","headline":"ProbeMDE：不确定性引导的主动触觉单目深度估计，用于手术机器人","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211773v1-probemde-uncertainty-guided-active-proprioception-for-monocular-dept.html"},{"id":"2512.11736v1","title":"Bench-Push: Benchmarking Pushing-based Navigation and Manipulation Tasks for Mobile Robots","headline":"Bench-Push：移动机器人推碰式导航与操作任务的统一基准测试平台","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211736v1-bench-push-benchmarking-pushing-based-navigation-and-manipulation-ta.html"},{"id":"2512.11944v1","title":"A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach","headline":"提出数据驱动的最优控制范式，融合经典控制与机器学习解决自动驾驶运动规划难题","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211944v1-a-review-of-learning-based-motion-planning-toward-a-data-driven-opti.html"},{"id":"2512.11797v1","title":"AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis","headline":"AnchorDream：利用视频扩散模型进行具身感知机器人数据合成","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211797v1-anchordream-repurposing-video-diffusion-for-embodiment-aware-robot-d.html"},{"id":"2512.11275v1","title":"Towards Logic-Aware Manipulation: A Knowledge Primitive for VLM-Based Assistants in Smart Manufacturing","headline":"提出面向逻辑的操纵知识基元，增强VLM在智能制造中的辅助能力","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211275v1-towards-logic-aware-manipulation-a-knowledge-primitive-for-vlm-based.html"},{"id":"2512.11781v1","title":"Agile Flight Emerges from Multi-Agent Competitive Racing","headline":"基于多智能体竞争强化学习，实现无人机敏捷飞行与策略博弈","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211781v1-agile-flight-emerges-from-multi-agent-competitive-racing.html"},{"id":"2512.12058v1","title":"A Stochastic Approach to Terrain Maps for Safe Lunar Landing","headline":"提出一种基于高斯过程的两阶段随机地形图方法，用于月球安全着陆。","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251212058v1-a-stochastic-approach-to-terrain-maps-for-safe-lunar-landing.html"},{"id":"2512.11769v1","title":"BLURR: A Boosted Low-Resource Inference for Vision-Language-Action Models","headline":"BLURR：一种加速VLA模型低资源推理的轻量级封装器","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211769v1-blurr-a-boosted-low-resource-inference-for-vision-language-action-mo.html"},{"id":"2512.11571v1","title":"Cross-Entropy Optimization of Physically Grounded Task and Motion Plans","headline":"提出基于交叉熵优化的物理引擎驱动的任务与运动规划方法","tag":"cs.RO","date":"2025-12-12","url":"cs-RO/2025-12-12/papers/251211571v1-cross-entropy-optimization-of-physically-grounded-task-and-motion-pl.html"},{"id":"2512.11800v1","title":"Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance","headline":"提出基于矩的3D高斯溅射，通过与顺序无关的透射率解决体积遮挡问题","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211800v1-moment-based-3d-gaussian-splatting-resolving-volumetric-occlusion-wi.html"},{"id":"2512.11356v1","title":"Prior-Enhanced Gaussian Splatting for Dynamic Scene Reconstruction from Casual Video","headline":"提出先验增强的高斯溅射方法，用于从日常视频中重建动态场景","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211356v1-prior-enhanced-gaussian-splatting-for-dynamic-scene-reconstruction-f.html"},{"id":"2512.11186v1","title":"Lightweight 3D Gaussian Splatting Compression via Video Codec","headline":"提出基于视频编解码器的轻量级3D高斯溅射压缩方法，适用于轻量级设备。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211186v1-lightweight-3d-gaussian-splatting-compression-via-video-codec.html"},{"id":"2512.11503v1","title":"TSkel-Mamba: Temporal Dynamic Modeling via State Space Model for Human Skeleton-based Action Recognition","headline":"TSkel-Mamba：利用状态空间模型进行人体骨骼动作识别的时序动态建模","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211503v1-tskel-mamba-temporal-dynamic-modeling-via-state-space-model-for-huma.html"},{"id":"2512.11301v1","title":"MultiEgo: A Multi-View Egocentric Video Dataset for 4D Scene Reconstruction","headline":"提出MultiEgo：用于4D场景重建的多视角第一人称视频数据集","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211301v1-multiego-a-multi-view-egocentric-video-dataset-for-4d-scene-reconstr.html"},{"id":"2512.11988v1","title":"CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction","headline":"CARI4D：提出一种类别无关的4D人-物交互重建方法，解决单目RGB视频重建难题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211988v1-cari4d-category-agnostic-4d-reconstruction-of-human-object-interacti.html"},{"id":"2512.11654v1","title":"Kinetic Mining in Context: Few-Shot Action Synthesis via Text-to-Motion Distillation","headline":"KineMIC：通过文本到动作蒸馏实现少样本动作合成，解决HAR数据稀缺问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211654v1-kinetic-mining-in-context-few-shot-action-synthesis-via-text-to-moti.html"},{"id":"2512.11226v1","title":"FutureX: Enhance End-to-End Autonomous Driving via Latent Chain-of-Thought World Model","headline":"FutureX：基于潜在思维链世界模型的端到端自动驾驶增强方案","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211226v1-futurex-enhance-end-to-end-autonomous-driving-via-latent-chain-of-th.html"},{"id":"2512.11524v1","title":"Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France","headline":"提出THREASURE-Net，利用Sentinel-2时间序列和LiDAR数据进行高分辨率森林冠层高度制图。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211524v1-super-resolved-canopy-height-mapping-from-sentinel-2-time-series-usi.html"},{"id":"2512.11508v1","title":"On Geometric Understanding and Learned Data Priors in VGGT","headline":"分析VGGT几何理解能力：揭示其隐式几何学习与数据先验依赖","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211508v1-on-geometric-understanding-and-learned-data-priors-in-vggt.html"},{"id":"2512.11225v1","title":"VFMF: World Modeling by Forecasting Vision Foundation Model Features","headline":"VFMF：通过预测视觉基础模型特征实现世界建模","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211225v1-vfmf-world-modeling-by-forecasting-vision-foundation-model-features.html"},{"id":"2512.11189v1","title":"Multi-task Learning with Extended Temporal Shift Module for Temporal Action Localization","headline":"提出扩展时序位移模块的多任务学习方法，用于时序动作定位","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211189v1-multi-task-learning-with-extended-temporal-shift-module-for-temporal.html"},{"id":"2512.11438v1","title":"Flowception: Temporally Expansive Flow Matching for Video Generation","headline":"Flowception：时序扩展的Flow Matching用于可变长度视频生成","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211438v1-flowception-temporally-expansive-flow-matching-for-video-generation.html"},{"id":"2512.11327v1","title":"Physics-Informed Video Flare Synthesis and Removal Leveraging Motion Independence between Flare and Scene","headline":"提出一种基于物理信息的视频光晕合成与去除方法，解决光晕与场景运动独立性问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211327v1-physics-informed-video-flare-synthesis-and-removal-leveraging-motion.html"},{"id":"2512.12080v1","title":"BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models","headline":"提出BAgger，通过反向聚合缓解自回归视频扩散模型中的漂移问题","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251212080v1-bagger-backwards-aggregation-for-mitigating-drift-in-autoregressive-.html"},{"id":"2512.11480v1","title":"CADMorph: Geometry-Driven Parametric CAD Editing via a Plan-Generate-Verify Loop","headline":"CADMorph：提出几何驱动的参数化CAD编辑框架，解决设计迭代中几何形状调整与参数序列同步编辑问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211480v1-cadmorph-geometry-driven-parametric-cad-editing-via-a-plan-generate-.html"},{"id":"2512.11321v1","title":"KeyframeFace: From Text to Expressive Facial Keyframes","headline":"KeyframeFace：提出基于文本驱动的、可解释的关键帧人脸表情动画生成框架","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211321v1-keyframeface-from-text-to-expressive-facial-keyframes.html"},{"id":"2512.12013v1","title":"Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition","headline":"提出基于星型图的离散动态图神经网络，用于毫米波雷达人体活动识别","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251212013v1-exploring-spatial-temporal-representation-via-star-graph-for-mmwave-.html"},{"id":"2512.12012v2","title":"Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus","headline":"Semantic-Drive：通过开放词汇 grounding 和神经符号 VLM 共识实现长尾数据挖掘","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251212012v2-semantic-drive-democratizing-long-tail-data-curation-via-open-vocabu.html"},{"id":"2512.11799v1","title":"V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties","headline":"V-RGBX：首个支持精确控制内参属性的视频编辑端到端框架","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211799v1-v-rgbx-video-editing-with-accurate-controls-over-intrinsic-propertie.html"},{"id":"2512.11798v1","title":"Particulate: Feed-Forward 3D Object Articulation","headline":"Particulate：提出一种前馈3D物体关节运动估计方法，无需逐对象优化。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211798v1-particulate-feed-forward-3d-object-articulation.html"},{"id":"2512.11792v1","title":"Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation","headline":"提出SAM2VideoX，通过蒸馏结构保持运动先验，提升视频生成质量。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211792v1-structure-from-tracking-distilling-structure-preserving-motion-for-v.html"},{"id":"2512.11683v1","title":"Depth-Copy-Paste: Multimodal and Depth-Aware Compositing for Robust Face Detection","headline":"提出Depth-Copy-Paste，通过多模态深度感知合成增强人脸检测鲁棒性。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211683v1-depth-copy-paste-multimodal-and-depth-aware-compositing-for-robust-f.html"},{"id":"2512.11645v1","title":"FactorPortrait: Controllable Portrait Animation via Disentangled Expression, Pose, and Viewpoint","headline":"FactorPortrait：通过解耦的表情、姿势和视角实现可控的人像动画","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211645v1-factorportrait-controllable-portrait-animation-via-disentangled-expr.html"},{"id":"2512.11612v1","title":"Embodied Image Compression","headline":"提出具身图像压缩，解决具身智能体在低比特率下的实时任务执行问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211612v1-embodied-image-compression.html"},{"id":"2512.11557v1","title":"3DTeethSAM: Taming SAM2 for 3D Teeth Segmentation","headline":"3DTeethSAM：利用SAM2进行三维牙齿分割，实现牙科数字化","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211557v1-3dteethsam-taming-sam2-for-3d-teeth-segmentation.html"},{"id":"2512.11510v1","title":"Reconstruction as a Bridge for Event-Based Visual Question Answering","headline":"提出基于重建的事件相机视觉问答框架，解决事件数据与多模态大语言模型兼容性问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211510v1-reconstruction-as-a-bridge-for-event-based-visual-question-answering.html"},{"id":"2512.11465v1","title":"DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation","headline":"DOS：通过Zipfian原型蒸馏可观测软标签，实现自监督点云表示学习","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211465v1-dos-distilling-observable-softmaps-of-zipfian-prototypes-for-self-su.html"},{"id":"2512.11401v1","title":"Collaborative Reconstruction and Repair for Multi-class Industrial Anomaly Detection","headline":"提出协同重建与修复网络CRR，解决多类别工业异常检测中的身份映射问题。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211401v1-collaborative-reconstruction-and-repair-for-multi-class-industrial-a.html"},{"id":"2512.11369v1","title":"Assisted Refinement Network Based on Channel Information Interaction for Camouflaged and Salient Object Detection","headline":"提出基于通道信息交互的辅助精炼网络，用于伪装目标检测和显著性目标检测。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211369v1-assisted-refinement-network-based-on-channel-information-interaction.html"},{"id":"2512.11350v1","title":"Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture","headline":"提出基于Transformer的交通视频事故检测模型，并构建了大规模平衡数据集。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211350v1-surveillance-video-based-traffic-accident-detection-using-transforme.html"},{"id":"2512.11336v1","title":"UFVideo: Towards Unified Fine-Grained Video Cooperative Understanding with Large Language Models","headline":"提出UFVideo，实现统一的多粒度视频协同理解，超越现有Video LLM。","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211336v1-ufvideo-towards-unified-fine-grained-video-cooperative-understanding.html"},{"id":"2512.11215v1","title":"SmokeBench: Evaluating Multimodal Large Language Models for Wildfire Smoke Detection","headline":"SmokeBench：评估多模态大语言模型在野火烟雾检测中的性能","tag":"cs.CV","date":"2025-12-12","url":"cs-CV/2025-12-12/papers/251211215v1-smokebench-evaluating-multimodal-large-language-models-for-wildfire-.html"},{"id":"2512.12046v1","title":"Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning","headline":"提出Eik-HiQRL，结合Eikonal方程与分层强化学习解决复杂环境下的目标导向导航问题","tag":"cs.LG","date":"2025-12-12","url":"cs-LG/2025-12-12/papers/251212046v1-goal-reaching-with-eikonal-constrained-hierarchical-quasimetric-rein.html"},{"id":"2512.11713v1","title":"Two-dimensional Decompositions of High-dimensional Configurations for Efficient Multi-vehicle Coordination at Intelligent Intersections","headline":"提出基于二维分解的高维配置空间方法，用于智能路口多车辆高效协同","tag":"eess.SY","date":"2025-12-12","url":"eess-SY/2025-12-12/papers/251211713v1-two-dimensional-decompositions-of-high-dimensional-configurations-fo.html"},{"id":"2512.11047v2","title":"WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control","headline":"提出WholeBodyVLA，实现基于统一隐空间VLA的大范围全身Loco-Manipulation控制","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251211047v2-wholebodyvla-towards-unified-latent-vla-for-whole-body-loco-manipula.html"},{"id":"2512.10235v1","title":"Task-Oriented Grasping Using Reinforcement Learning with a Contextual Reward Machine","headline":"提出基于上下文奖励机制的强化学习框架以解决任务导向抓取问题","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210235v1-task-oriented-grasping-using-reinforcement-learning-with-a-contextua.html"},{"id":"2512.11173v1","title":"Learning Category-level Last-meter Navigation from RGB Demonstrations of a Single-instance","headline":"提出基于单实例RGB图像模仿学习的类别级末端导航方法","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251211173v1-learning-category-level-last-meter-navigation-from-rgb-demonstration.html"},{"id":"2512.10934v1","title":"Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit","headline":"提出基于课程学习的强化学习方法，用于未知弯曲管道中无人机自主导航","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210934v1-curriculum-based-reinforcement-learning-for-autonomous-uav-navigatio.html"},{"id":"2512.10481v1","title":"Contact SLAM: An Active Tactile Exploration Policy Based on Physical Reasoning Utilized in Robotic Fine Blind Manipulation Tasks","headline":"提出Contact SLAM，解决机器人盲操作中基于触觉的主动探索问题","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210481v1-contact-slam-an-active-tactile-exploration-policy-based-on-physical-.html"},{"id":"2512.10477v2","title":"Symphony: A Heuristic Normalized Calibrated Advantage Actor and Critic Algorithm in application for Humanoid Robots","headline":"提出Symphony算法，解决人形机器人从零开始训练的样本效率、样本邻近性和动作安全性问题。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210477v2-symphony-a-heuristic-normalized-calibrated-advantage-actor-and-criti.html"},{"id":"2512.10698v1","title":"How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning","headline":"提出基于深度强化学习的混合紧急制动方法，提升多车协同场景下的安全性。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210698v1-how-to-brake-ethical-emergency-braking-with-deep-reinforcement-learn.html"},{"id":"2512.11080v1","title":"Taxonomy and Modular Tool System for Versatile and Effective Non-Prehensile Manipulations","headline":"提出非抓取操作工具模块化系统，扩展通用夹爪末端执行器的功能","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251211080v1-taxonomy-and-modular-tool-system-for-versatile-and-effective-non-pre.html"},{"id":"2512.10540v1","title":"Mr. Virgil: Learning Multi-robot Visual-range Relative Localization","headline":"Mr. Virgil：提出一种基于学习的多机器人视觉相对定位方法","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210540v1-mr-virgil-learning-multi-robot-visual-range-relative-localization.html"},{"id":"2512.10360v1","title":"CLASH: Collaborative Large-Small Hierarchical Framework for Continuous Vision-and-Language Navigation","headline":"提出CLASH框架，融合大小模型优势，解决连续视觉语言导航任务。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210360v1-clash-collaborative-large-small-hierarchical-framework-for-continuou.html"},{"id":"2512.10349v1","title":"Design and Validation of an Under-actuated Robotic Finger with Synchronous Tendon Routing","headline":"提出基于同步腱索驱动的欠驱动机械手指，实现高负载、自适应顺应性和紧凑结构。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210349v1-design-and-validation-of-an-under-actuated-robotic-finger-with-synch.html"},{"id":"2512.10946v1","title":"ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning","headline":"提出ImplicitRDP，解决接触丰富操作中视觉与力觉融合难题","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210946v1-implicitrdp-an-end-to-end-visual-force-diffusion-policy-with-structu.html"},{"id":"2512.10595v1","title":"Motion Planning for Safe Landing of a Human-Piloted Parafoil","headline":"提出基于改进SST算法的伞翼飞行运动规划方法，提升人控伞翼安全着陆性能。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210595v1-motion-planning-for-safe-landing-of-a-human-piloted-parafoil.html"},{"id":"2512.10891v2","title":"Iterative Compositional Data Generation for Robot Control","headline":"提出基于组合扩散Transformer的迭代数据生成方法，提升机器人控制零样本泛化能力","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210891v2-iterative-compositional-data-generation-for-robot-control.html"},{"id":"2512.11921v1","title":"Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control","headline":"提出基于LoRA微调的VLA模型，用于低成本机器人控制。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251211921v1-towards-accessible-physical-ai-lora-based-fine-tuning-of-vla-models-.html"},{"id":"2512.10531v1","title":"Neural Ranging Inertial Odometry","headline":"提出基于图注意力UWB网络和循环神经网络的融合框架，解决复杂环境下惯性里程计定位问题。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210531v1-neural-ranging-inertial-odometry.html"},{"id":"2512.10480v1","title":"Seamless Outdoor-Indoor Pedestrian Positioning System with GNSS/UWB/IMU Fusion: A Comparison of EKF, FGO, and PF","headline":"提出GNSS/UWB/IMU融合的无缝室内外行人定位系统，对比EKF、FGO和PF算法。","tag":"cs.RO","date":"2025-12-11","url":"cs-RO/2025-12-11/papers/251210480v1-seamless-outdoor-indoor-pedestrian-positioning-system-with-gnssuwbim.html"},{"id":"2512.10369v1","title":"Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views","headline":"提出CoherentGS，解决稀疏和运动模糊视图下的高保真3D高斯重建问题","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210369v1-breaking-the-vicious-cycle-coherent-3d-gaussian-splatting-from-spars.html"},{"id":"2512.10730v1","title":"IRG-MotionLLM: Interleaving Motion Generation, Assessment and Refinement for Text-to-Motion Generation","headline":"提出IRG-MotionLLM，通过交错运动生成、评估和优化，提升文本到动作生成效果","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210730v1-irg-motionllm-interleaving-motion-generation-assessment-and-refineme.html"},{"id":"2512.10674v1","title":"Geo6DPose: Fast Zero-Shot 6D Object Pose Estimation via Geometry-Filtered Feature Matching","headline":"Geo6DPose：基于几何滤波特征匹配的快速零样本6D物体姿态估计","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210674v1-geo6dpose-fast-zero-shot-6d-object-pose-estimation-via-geometry-filt.html"},{"id":"2512.10321v1","title":"Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset","headline":"Point2Pose：提出一种基于多视角点云数据集的3D人体姿态估计生成框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210321v1-point2pose-a-generative-framework-for-3d-human-pose-estimation-with-.html"},{"id":"2512.10419v1","title":"TransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning","headline":"TransLocNet：基于跨模态注意力和对比学习的无人机-地面车辆定位","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210419v1-translocnet-cross-modal-attention-for-aerial-ground-vehicle-localiza.html"},{"id":"2512.10352v1","title":"Topology-Agnostic Animal Motion Generation from Text Prompt","headline":"提出OmniZoo数据集和拓扑无关的动物运动生成框架，解决异构骨骼和文本驱动的动物运动生成问题。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210352v1-topology-agnostic-animal-motion-generation-from-text-prompt.html"},{"id":"2512.10956v1","title":"Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision","headline":"StereoWalker：融合双目视觉与中层视觉增强动态城市导航","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210956v1-empowering-dynamic-urban-navigation-with-stereo-and-mid-level-vision.html"},{"id":"2512.10353v1","title":"Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation","headline":"提出TranSamba，一种混合Transformer-Mamba架构，用于弱监督体积医学图像分割。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210353v1-hybrid-transformer-mamba-architecture-for-weakly-supervised-volumetr.html"},{"id":"2512.11057v1","title":"Weakly Supervised Tuberculosis Localization in Chest X-rays through Knowledge Distillation","headline":"利用知识蒸馏的胸部X光片肺结核弱监督定位方法","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251211057v1-weakly-supervised-tuberculosis-localization-in-chest-x-rays-through-.html"},{"id":"2512.10958v1","title":"WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World","headline":"WorldLens：真实世界中驾驶世界模型的全方位评估基准","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210958v1-worldlens-full-spectrum-evaluations-of-driving-world-models-in-real-.html"},{"id":"2512.11130v1","title":"Fast-FoundationStereo: Real-Time Zero-Shot Stereo Matching","headline":"提出Fast-FoundationStereo，实现零样本立体匹配的实时性与高精度。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251211130v1-fast-foundationstereo-real-time-zero-shot-stereo-matching.html"},{"id":"2512.11061v1","title":"VDAWorld: World Modelling via VLM-Directed Abstraction and Simulation","headline":"VDAWorld：提出基于VLM引导的抽象与模拟的世界建模框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251211061v1-vdaworld-world-modelling-via-vlm-directed-abstraction-and-simulation.html"},{"id":"2512.10957v1","title":"SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model","headline":"SceneMaker：解耦去遮挡与姿态估计的开放场景三维生成框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210957v1-scenemaker-open-set-3d-scene-generation-with-decoupled-de-occlusion-.html"},{"id":"2512.10939v1","title":"GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting","headline":"提出GaussianHeadTalk，利用音频驱动高斯溅射生成无抖动3D说话头","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210939v1-gaussianheadtalk-wobble-free-3d-talking-heads-with-audio-driven-gaus.html"},{"id":"2512.10840v1","title":"PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View Reasoning","headline":"PoseGAM：基于几何感知多视角推理的鲁棒未知物体姿态估计","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210840v1-posegam-robust-unseen-object-pose-estimation-via-geometry-aware-mult.html"},{"id":"2512.10683v1","title":"Optimal transport unlocks end-to-end learning for single-molecule localization","headline":"利用最优传输实现单分子定位显微镜的端到端学习","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210683v1-optimal-transport-unlocks-end-to-end-learning-for-single-molecule-lo.html"},{"id":"2512.10660v1","title":"NaviHydra: Controllable Navigation-guided End-to-end Autonomous Driving with Hydra-distillation","headline":"NaviHydra：基于Hydra蒸馏的可控导航引导端到端自动驾驶","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210660v1-navihydra-controllable-navigation-guided-end-to-end-autonomous-drivi.html"},{"id":"2512.10386v1","title":"Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method","headline":"提出自适应双权重引力点云去噪方法，提升精度、效率与边缘保持能力","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210386v1-adaptive-dual-weighted-gravitational-point-cloud-denoising-method.html"},{"id":"2512.10376v1","title":"RaLiFlow: Scene Flow Estimation with 4D Radar and LiDAR Point Clouds","headline":"提出RaLiFlow，首个基于4D雷达和激光雷达点云的场景流估计框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210376v1-raliflow-scene-flow-estimation-with-4d-radar-and-lidar-point-clouds.html"},{"id":"2512.10310v1","title":"Efficient-VLN: A Training-Efficient Vision-Language Navigation Model","headline":"Efficient-VLN：一种训练高效的视觉-语言导航模型，显著降低训练开销。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210310v1-efficient-vln-a-training-efficient-vision-language-navigation-model.html"},{"id":"2512.10293v1","title":"Physically Aware 360$^\\circ$ View Generation from a Single Image using Disentangled Scene Embeddings","headline":"提出Disentangled360，通过解耦场景嵌入实现单图360度视图生成。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210293v1-physically-aware-360circ-view-generation-from-a-single-image-using-d.html"},{"id":"2512.10226v1","title":"Latent Chain-of-Thought World Modeling for End-to-End Driving","headline":"提出Latent-CoT-Drive，利用隐空间思维链进行端到端自动驾驶决策。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210226v1-latent-chain-of-thought-world-modeling-for-end-to-end-driving.html"},{"id":"2512.10950v1","title":"E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training","headline":"E-RayZer：提出自监督3D重建框架，作为空间视觉预训练模型。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210950v1-e-rayzer-self-supervised-3d-reconstruction-as-spatial-visual-pre-tra.html"},{"id":"2512.10437v1","title":"An M-Health Algorithmic Approach to Identify and Assess Physiotherapy Exercises in Real Time","headline":"提出一种基于移动设备的M-Health算法，用于实时识别和评估理疗运动","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210437v1-an-m-health-algorithmic-approach-to-identify-and-assess-physiotherap.html"},{"id":"2512.10251v1","title":"THE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose","headline":"THE-Pose：融合拓扑先验与混合图的类别级6D位姿估计","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210251v1-the-pose-topological-prior-with-hybrid-graph-fusion-for-estimating-c.html"},{"id":"2512.10554v1","title":"Grounding Everything in Tokens for Multimodal Large Language Models","headline":"GETok：通过token化实现多模态大语言模型中的精确2D空间定位","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210554v1-grounding-everything-in-tokens-for-multimodal-large-language-models.html"},{"id":"2512.10959v1","title":"StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space","headline":"StereoSpace：提出一种基于扩散模型的无深度单目图像到立体图像生成框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210959v1-stereospace-depth-free-synthesis-of-stereo-geometry-via-end-to-end-d.html"},{"id":"2512.11925v1","title":"FloraForge: LLM-Assisted Procedural Generation of Editable and Analysis-Ready 3D Plant Geometric Models For Agricultural Applications","headline":"FloraForge：LLM辅助生成可编辑、分析就绪的3D植物几何模型，用于农业应用","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251211925v1-floraforge-llm-assisted-procedural-generation-of-editable-and-analys.html"},{"id":"2512.10940v1","title":"OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis","headline":"OmniView：用于3D和4D视图合成的统一扩散模型","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210940v1-omniview-an-all-seeing-diffusion-model-for-3d-and-4d-view-synthesis.html"},{"id":"2512.10935v1","title":"Any4D: Unified Feed-Forward Metric 4D Reconstruction","headline":"Any4D：统一前馈式度量4D重建框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210935v1-any4d-unified-feed-forward-metric-4d-reconstruction.html"},{"id":"2512.10725v1","title":"Video Depth Propagation","headline":"提出VeloDepth，通过时空先验和特征传播实现高效鲁棒的视频深度估计","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210725v1-video-depth-propagation.html"},{"id":"2512.10668v1","title":"XDen-1K: A Density Field Dataset of Real-World Objects","headline":"XDen-1K：首个大规模真实物体密度场数据集，助力机器人操作和物理模拟。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210668v1-xden-1k-a-density-field-dataset-of-real-world-objects.html"},{"id":"2512.10517v1","title":"3D Blood Pulsation Maps","headline":"提出Pulse3DFace数据集以解决3D血液脉动映射问题","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210517v1-3d-blood-pulsation-maps.html"},{"id":"2512.10498v1","title":"Robust Shape from Focus via Multiscale Directional Dilated Laplacian and Recurrent Network","headline":"提出基于多尺度方向扩张拉普拉斯和循环网络的稳健Shape-from-Focus方法","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210498v1-robust-shape-from-focus-via-multiscale-directional-dilated-laplacian.html"},{"id":"2512.10450v1","title":"Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment","headline":"提出双域渐进式时序对齐的无误差传播学习视频压缩框架","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210450v1-error-propagation-free-learned-video-compression-with-dual-domain-pr.html"},{"id":"2512.10342v1","title":"CoSPlan: Corrective Sequential Planning via Scene Graph Incremental Updates","headline":"提出基于场景图增量更新的纠错序列规划方法CoSPlan，提升VLM在复杂任务中的推理能力。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210342v1-cosplan-corrective-sequential-planning-via-scene-graph-incremental-u.html"},{"id":"2512.10267v1","title":"Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction","headline":"Long-LRM++：结合半显式表达与轻量解码器，实现高质量、实时的宽覆盖场景重建。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210267v1-long-lrm-preserving-fine-details-in-feed-forward-wide-coverage-recon.html"},{"id":"2512.10248v1","title":"RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection","headline":"RobustSora：提出去水印基准测试，评估AI生成视频检测的鲁棒性","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210248v1-robustsora-de-watermarked-benchmark-for-robust-ai-generated-video-de.html"},{"id":"2512.10209v1","title":"Feature Coding for Scalable Machine Vision","headline":"提出FCTM，通过特征编码显著降低机器视觉边缘部署的带宽需求。","tag":"cs.CV","date":"2025-12-11","url":"cs-CV/2025-12-11/papers/251210209v1-feature-coding-for-scalable-machine-vision.html"},{"id":"2512.10572v1","title":"DeMapGS: Simultaneous Mesh Deformation and Surface Attribute Mapping via Gaussian Splatting","headline":"DeMapGS：基于高斯溅射的同时进行网格变形和表面属性映射","tag":"cs.GR","date":"2025-12-11","url":"cs-GR/2025-12-11/papers/251210572v1-demapgs-simultaneous-mesh-deformation-and-surface-attribute-mapping-.html"},{"id":"2512.10424v1","title":"Neural Hamiltonian Deformation Fields for Dynamic Scene Rendering","headline":"提出NeHaD，利用哈密顿力学实现动态场景的物理真实渲染","tag":"cs.GR","date":"2025-12-11","url":"cs-GR/2025-12-11/papers/251210424v1-neural-hamiltonian-deformation-fields-for-dynamic-scene-rendering.html"},{"id":"2512.10925v1","title":"Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation","headline":"提出基于数字孪生监督强化学习的水下自主导航框架，提升复杂环境适应性。","tag":"cs.LG","date":"2025-12-11","url":"cs-LG/2025-12-11/papers/251210925v1-digital-twin-supervised-reinforcement-learning-framework-for-autonom.html"},{"id":"2512.10738v1","title":"Distribution-Free Stochastic MPC for Joint-in-Time Chance-Constrained Linear Systems","headline":"提出一种基于Conformal Prediction的Distribution-Free随机MPC方法，用于解决时域联合概率约束线性系统控制问题。","tag":"eess.SY","date":"2025-12-11","url":"eess-SY/2025-12-11/papers/251210738v1-distribution-free-stochastic-mpc-for-joint-in-time-chance-constraine.html"},{"id":"2512.09297v1","title":"One-Shot Real-World Demonstration Synthesis for Scalable Bimanual Manipulation","headline":"BiDemoSyn：基于单样本真实演示合成可扩展的双臂操作数据","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209297v1-one-shot-real-world-demonstration-synthesis-for-scalable-bimanual-ma.html"},{"id":"2512.09656v1","title":"ReMoSPLAT: Reactive Mobile Manipulation Control on a Gaussian Splat","headline":"ReMoSPLAT：基于高斯溅射的移动机械臂反应式控制","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209656v1-remosplat-reactive-mobile-manipulation-control-on-a-gaussian-splat.html"},{"id":"2512.09537v1","title":"REASAN: Learning Reactive Safe Navigation for Legged Robots","headline":"REASAN：面向复杂动态环境，学习腿式机器人反应式安全导航","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209537v1-reasan-learning-reactive-safe-navigation-for-legged-robots.html"},{"id":"2512.09411v1","title":"D$^2$GSLAM: 4D Dynamic Gaussian Splatting SLAM","headline":"D$^2$GSLAM：基于高斯表示的动态场景4D SLAM系统，实现动态环境下的精确重建与鲁棒跟踪。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209411v1-d2gslam-4d-dynamic-gaussian-splatting-slam.html"},{"id":"2512.09903v1","title":"YOPO-Nav: Visual Navigation using 3DGS Graphs from One-Pass Videos","headline":"YOPO-Nav：利用单次视频的3DGS图进行视觉导航","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209903v1-yopo-nav-visual-navigation-using-3dgs-graphs-from-one-pass-videos.html"},{"id":"2512.09431v1","title":"A Hierarchical, Model-Based System for High-Performance Humanoid Soccer","headline":"提出一种分层、基于模型的系统，用于高性能人形机器人足球比赛。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209431v1-a-hierarchical-model-based-system-for-high-performance-humanoid-socc.html"},{"id":"2512.09310v1","title":"Scene-agnostic Hierarchical Bimanual Task Planning via Visual Affordance Reasoning","headline":"提出基于视觉可供性的场景无关分层双臂任务规划框架","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209310v1-scene-agnostic-hierarchical-bimanual-task-planning-via-visual-afford.html"},{"id":"2512.10099v1","title":"Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation","headline":"提出HeRD：一种用于高效非抓取操作的分层RL-扩散策略","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251210099v1-push-smarter-not-harder-hierarchical-rl-diffusion-policy-for-efficie.html"},{"id":"2512.10128v1","title":"Inertial Magnetic SLAM Systems Using Low-Cost Sensors","headline":"提出基于低成本惯性磁传感器的惯性磁SLAM系统，提升弱光环境定位精度。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251210128v1-inertial-magnetic-slam-systems-using-low-cost-sensors.html"},{"id":"2512.09851v1","title":"Simultaneous Tactile-Visual Perception for Learning Multimodal Robot Manipulation","headline":"提出TacThru-UMI，结合新型触觉视觉传感器与Transformer扩散策略，提升机器人操作精度。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209851v1-simultaneous-tactile-visual-perception-for-learning-multimodal-robot.html"},{"id":"2512.09920v1","title":"LISN: Language-Instructed Social Navigation with VLM-based Controller Modulating","headline":"提出LISN-Bench与Social-Nav-Modulator，实现基于语言指令的社交导航。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209920v1-lisn-language-instructed-social-navigation-with-vlm-based-controller.html"},{"id":"2512.09607v1","title":"UrbanNav: Learning Language-Guided Urban Navigation from Web-Scale Human Trajectories","headline":"提出UrbanNav以解决复杂城市环境中的语言引导导航问题","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209607v1-urbannav-learning-language-guided-urban-navigation-from-web-scale-hu.html"},{"id":"2512.09462v1","title":"Development of a Compliant Gripper for Safe Robot-Assisted Trouser Dressing-Undressing","headline":"开发用于安全机器人辅助穿脱裤子的柔顺夹持器","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209462v1-development-of-a-compliant-gripper-for-safe-robot-assisted-trouser-d.html"},{"id":"2512.09406v1","title":"H2R-Grounder: A Paired-Data-Free Paradigm for Translating Human Interaction Videos into Physically Grounded Robot Videos","headline":"提出H2R-Grounder，实现无需配对数据的物理可信人机交互视频转换。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209406v1-h2r-grounder-a-paired-data-free-paradigm-for-translating-human-inter.html"},{"id":"2512.10071v2","title":"Openpi Comet: Competition Solution For 2025 BEHAVIOR Challenge","headline":"OpenPI Comet在BEHAVIOR挑战赛中获得亚军，通过系统性研究提升具身智能性能。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251210071v2-openpi-comet-competition-solution-for-2025-behavior-challenge.html"},{"id":"2512.09619v1","title":"GLaD: Geometric Latent Distillation for Vision-Language-Action Models","headline":"GLaD：几何潜在蒸馏增强视觉-语言-动作模型的空间推理能力","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209619v1-glad-geometric-latent-distillation-for-vision-language-action-models.html"},{"id":"2512.09608v1","title":"Super4DR: 4D Radar-centric Self-supervised Odometry and Gaussian-based Map Optimization","headline":"Super4DR：面向4D雷达的自监督里程计与高斯优化建图","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209608v1-super4dr-4d-radar-centric-self-supervised-odometry-and-gaussian-base.html"},{"id":"2512.09510v1","title":"ViTA-Seg: Vision Transformer for Amodal Segmentation in Robotics","headline":"ViTA-Seg：用于机器人非模态分割的视觉Transformer，提升遮挡场景下的抓取规划。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209510v1-vita-seg-vision-transformer-for-amodal-segmentation-in-robotics.html"},{"id":"2512.11908v1","title":"Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models","headline":"综述：面向接触密集型机器人任务的安全学习方法，从经典方法到安全具身智能","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251211908v1-safe-learning-for-contact-rich-robot-tasks-a-survey-from-classical-l.html"},{"id":"2512.09410v1","title":"Generalizable Collaborative Search-and-Capture in Cluttered Environments via Path-Guided MAPPO and Directional Frontier Allocation","headline":"提出PGF-MAPPO，解决复杂环境下的协同搜索捕获问题，实现零样本泛化。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209410v1-generalizable-collaborative-search-and-capture-in-cluttered-environm.html"},{"id":"2512.10116v1","title":"Fast Functionally Redundant Inverse Kinematics for Robotic Toolpath Optimisation in Manufacturing Tasks","headline":"提出快速功能冗余逆运动学算法，优化机器人制造任务中的工具路径","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251210116v1-fast-functionally-redundant-inverse-kinematics-for-robotic-toolpath-.html"},{"id":"2512.09928v1","title":"HiF-VLA: Hindsight, Insight and Foresight through Motion Representation for Vision-Language-Action Models","headline":"HiF-VLA：利用运动表征进行双向时序推理，提升视觉-语言-动作模型的长时序操作能力","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209928v1-hif-vla-hindsight-insight-and-foresight-through-motion-representatio.html"},{"id":"2512.09911v1","title":"Py-DiSMech: A Scalable and Efficient Framework for Discrete Differential Geometry-Based Modeling and Control of Soft Robots","headline":"Py-DiSMech：基于离散微分几何的软机器人建模与控制高效框架","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209911v1-py-dismech-a-scalable-and-efficient-framework-for-discrete-different.html"},{"id":"2512.09833v1","title":"Bridging the Basilisk Astrodynamics Framework with ROS 2 for Modular Spacecraft Simulation and Hardware Integration","headline":"提出Basilisk与ROS 2的轻量级桥接方案，用于模块化航天器仿真与硬件集成","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209833v1-bridging-the-basilisk-astrodynamics-framework-with-ros-2-for-modular.html"},{"id":"2512.09798v1","title":"High-Resolution Water Sampling via a Solar-Powered Autonomous Surface Vehicle","headline":"提出一种太阳能自主水面船，实现高分辨率水样采集与水质监测","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251209798v1-high-resolution-water-sampling-via-a-solar-powered-autonomous-surfac.html"},{"id":"2512.11903v1","title":"Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics","headline":"提出Aion，将时序流动动态嵌入分层4D场景图，用于动态环境自主导航。","tag":"cs.RO","date":"2025-12-10","url":"cs-RO/2025-12-10/papers/251211903v1-aion-towards-hierarchical-4d-scene-graphs-with-temporal-flow-dynamic.html"},{"id":"2512.09646v1","title":"VHOI: Controllable Video Generation of Human-Object Interactions from Sparse Trajectories via Motion Densification","headline":"VHOI：通过运动稠密化，从稀疏轨迹控制人体-物体交互视频生成","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209646v1-vhoi-controllable-video-generation-of-human-object-interactions-from.html"},{"id":"2512.09923v1","title":"Splatent: Splatting Diffusion Latents for Novel View Synthesis","headline":"Splatent：通过Splatting扩散模型潜在空间提升新视角合成质量","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209923v1-splatent-splatting-diffusion-latents-for-novel-view-synthesis.html"},{"id":"2512.09335v2","title":"Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video","headline":"提出RnD-Avatar，基于3DGS重建可重光照和动态人体Avatar，提升几何细节。","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209335v2-relightable-and-dynamic-gaussian-avatar-reconstruction-from-monocula.html"},{"id":"2512.09375v1","title":"Log NeRF: Comparing Spaces for Learning Radiance Fields","headline":"Log NeRF：通过比较不同色彩空间，提升神经辐射场的学习效果","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209375v1-log-nerf-comparing-spaces-for-learning-radiance-fields.html"},{"id":"2512.09407v1","title":"Generative Point Cloud Registration","headline":"提出生成式点云配准方法，利用2D生成模型提升3D匹配性能","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209407v1-generative-point-cloud-registration.html"},{"id":"2512.09423v1","title":"FunPhase: A Periodic Functional Autoencoder for Motion Generation via Phase Manifolds","headline":"FunPhase：通过相位流形实现运动生成的周期性函数自编码器","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209423v1-funphase-a-periodic-functional-autoencoder-for-motion-generation-via.html"},{"id":"2512.11894v1","title":"mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description","headline":"mmWeaver：利用照片和活动描述合成环境特定的毫米波信号","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251211894v1-mmweaver-environment-specific-mmwave-signal-synthesis-from-a-photo-a.html"},{"id":"2512.09792v1","title":"FastPose-ViT: A Vision Transformer for Real-Time Spacecraft Pose Estimation","headline":"提出FastPose-ViT，用于资源受限平台上的航天器实时姿态估计","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209792v1-fastpose-vit-a-vision-transformer-for-real-time-spacecraft-pose-esti.html"},{"id":"2512.09393v1","title":"Detection and Localization of Subdural Hematoma Using Deep Learning on Computed Tomography","headline":"提出多模态深度学习框架，用于脑部CT影像中硬膜下血肿的精准检测与定位","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209393v1-detection-and-localization-of-subdural-hematoma-using-deep-learning-.html"},{"id":"2512.09270v1","title":"MoRel: Long-Range Flicker-Free 4D Motion Modeling via Anchor Relay-based Bidirectional Blending with Hierarchical Densification","headline":"MoRel：基于锚点中继双向融合和分层稠密化的长程无闪烁4D运动建模","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209270v1-morel-long-range-flicker-free-4d-motion-modeling-via-anchor-relay-ba.html"},{"id":"2512.09373v1","title":"FUSER: Feed-Forward MUltiview 3D Registration Transformer and SE(3)$^N$ Diffusion Refinement","headline":"提出FUSER以解决多视角点云配准问题","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209373v1-fuser-feed-forward-multiview-3d-registration-transformer-and-se3n-di.html"},{"id":"2512.11901v1","title":"CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities","headline":"CLARGA：提出一种通用的多模态图表示学习框架，适用于任意模态组合。","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251211901v1-clarga-multimodal-graph-representation-learning-over-arbitrary-sets-.html"},{"id":"2512.09925v1","title":"GAINS: Gaussian-based Inverse Rendering from Sparse Multi-View Captures","headline":"GAINS：基于高斯的稀疏多视角逆渲染，提升几何与材质恢复质量","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209925v1-gains-gaussian-based-inverse-rendering-from-sparse-multi-view-captur.html"},{"id":"2512.09363v2","title":"StereoWorld: Geometry-Aware Monocular-to-Stereo Video Generation","headline":"StereoWorld：提出几何感知单目视频转立体视频生成框架，提升视觉保真度和几何一致性。","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209363v2-stereoworld-geometry-aware-monocular-to-stereo-video-generation.html"},{"id":"2512.10095v1","title":"TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing","headline":"TraceFlow：光线追踪驱动的动态高光场景三维重建","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251210095v1-traceflow-dynamic-3d-reconstruction-of-specular-scenes-driven-by-ray.html"},{"id":"2512.09847v1","title":"From Detection to Anticipation: Online Understanding of Struggles across Various Tasks and Activities","headline":"提出在线挣扎检测与预测框架，助力实时辅助系统理解人类技能表现","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209847v1-from-detection-to-anticipation-online-understanding-of-struggles-acr.html"},{"id":"2512.09617v1","title":"FROMAT: Multiview Material Appearance Transfer via Few-Shot Self-Attention Adaptation","headline":"提出FROMAT，通过少样本自注意力适配实现多视角材质外观迁移","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209617v1-fromat-multiview-material-appearance-transfer-via-few-shot-self-atte.html"},{"id":"2512.09463v1","title":"Privacy-Preserving Computer Vision for Industry: Three Case Studies in Human-Centric Manufacturing","headline":"提出一种面向工业的隐私保护计算机视觉框架，应用于人机协作制造场景","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209463v1-privacy-preserving-computer-vision-for-industry-three-case-studies-i.html"},{"id":"2512.09364v1","title":"ASSIST-3D: Adapted Scene Synthesis for Class-Agnostic 3D Instance Segmentation","headline":"ASSIST-3D：用于类别无关3D实例分割的自适应场景合成","tag":"cs.CV","date":"2025-12-10","url":"cs-CV/2025-12-10/papers/251209364v1-assist-3d-adapted-scene-synthesis-for-class-agnostic-3d-instance-seg.html"},{"id":"2512.09929v1","title":"Closing the Train-Test Gap in World Models for Gradient-Based Planning","headline":"提出数据合成方法，弥合World Model训练与梯度规划的差距，加速模型预测控制。","tag":"cs.LG","date":"2025-12-10","url":"cs-LG/2025-12-10/papers/251209929v1-closing-the-train-test-gap-in-world-models-for-gradient-based-planni.html"},{"id":"2512.09213v1","title":"MPC for momentum counter-balanced and zero-impulse contact with a free-spinning satellite","headline":"提出基于MPC的控制框架，实现服务卫星与自由旋转目标卫星的零冲量接触","tag":"eess.SY","date":"2025-12-10","url":"eess-SY/2025-12-10/papers/251209213v1-mpc-for-momentum-counter-balanced-and-zero-impulse-contact-with-a-fr.html"},{"id":"2512.09162v1","title":"GTAvatar: Bridging Gaussian Splatting and Texture Mapping for Relightable and Editable Gaussian Avatars","headline":"GTAvatar：结合高斯溅射与纹理映射，实现可重光照和编辑的高斯头像","tag":"cs.CV","date":"2025-12-09","url":"cs-CV/2025-12-09/papers/251209162v1-gtavatar-bridging-gaussian-splatting-and-texture-mapping-for-relight.html"},{"id":"2512.06608v1","title":"A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance","headline":"提出一种新的面向轨迹的crowd navigation方法，提升综合性能。","tag":"cs.RO","date":"2025-12-07","url":"cs-RO/2025-12-07/papers/251206608v1-a-new-trajectory-oriented-approach-to-enhancing-comprehensive-crowd-.html"},{"id":"2512.06628v1","title":"MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment","headline":"MIND-V：用于长时程机器人操作的分层视频生成框架，通过强化学习实现物理对齐","tag":"cs.RO","date":"2025-12-07","url":"cs-RO/2025-12-07/papers/251206628v1-mind-v-hierarchical-video-generation-for-long-horizon-robotic-manipu.html"},{"id":"2512.06642v1","title":"Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution","headline":"提出基于掩码自编码器的强引力透镜图像预训练方法，用于暗物质模型分类和超分辨率重建。","tag":"cs.CV","date":"2025-12-07","url":"cs-CV/2025-12-07/papers/251206642v1-masked-autoencoder-pretraining-on-strong-lensing-images-for-joint-da.html"},{"id":"2512.06486v2","title":"Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains","headline":"提出基于熵控制的内在动机强化学习算法，提升四足机器人复杂地形运动能力。","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206486v2-entropy-controlled-intrinsic-motivation-reinforcement-learning-for-q.html"},{"id":"2512.06571v2","title":"Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input","headline":"提出基于强化学习的人形机器人敏捷踢球技能学习系统，提升感知噪声下的鲁棒性。","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206571v2-learning-agile-striker-skills-for-humanoid-soccer-robots-from-noisy-.html"},{"id":"2512.06517v1","title":"Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments","headline":"提出一种视觉引导的假肢手抓取规划算法，适用于非结构化环境。","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206517v1-vision-guided-grasp-planning-for-prosthetic-hands-in-unstructured-en.html"},{"id":"2512.06524v1","title":"TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping","headline":"TacFinRay：用于稳健抓取的间接触觉传感软体Fin-Ray手指","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206524v1-tacfinray-soft-tactile-fin-ray-finger-with-indirect-tactile-sensing-.html"},{"id":"2512.06423v1","title":"Leveraging Port-Hamiltonian Theory for Impedance Control Benchmarking","headline":"提出基于Port-Hamiltonian理论的阻抗控制基准测试方法","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206423v1-leveraging-port-hamiltonian-theory-for-impedance-control-benchmarkin.html"},{"id":"2512.06387v1","title":"Beyond Model Jailbreak: Systematic Dissection of the \"Ten DeadlySins\" in Embodied Intelligence","headline":"揭示具身智能“十大原罪”：对Unitree Go2平台进行系统性安全剖析","tag":"cs.RO","date":"2025-12-06","url":"cs-RO/2025-12-06/papers/251206387v1-beyond-model-jailbreak-systematic-dissection-of-the-ten-deadlysins-i.html"},{"id":"2512.06269v1","title":"TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting","headline":"TriaGS：通过可微三角测量引导几何一致性的3D高斯溅射","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206269v1-triags-differentiable-triangulation-guided-geometric-consistency-for.html"},{"id":"2512.06565v1","title":"GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation","headline":"GNC-Pose：结合几何感知的GNC-PnP方法，实现精确的6D位姿估计","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206565v1-gnc-pose-geometry-aware-gnc-pnp-for-accurate-6d-pose-estimation.html"},{"id":"2512.06438v2","title":"AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars","headline":"AGORA：提出基于对抗生成网络的实时可控3D高斯头部头像","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206438v2-agora-adversarial-generation-of-real-time-animatable-3d-gaussian-hea.html"},{"id":"2512.06306v1","title":"Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation","headline":"提出基于时空特性的事件相机人体姿态估计方法，提升效率与精度","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206306v1-exploiting-spatiotemporal-properties-for-efficient-event-driven-huma.html"},{"id":"2512.06368v2","title":"HuPrior3R: Incorporating Human Priors for Better 3D Dynamic Reconstruction from Monocular Videos","headline":"提出HuPrior3R，融合人体先验知识，提升单目视频3D动态重建效果","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206368v2-huprior3r-incorporating-human-priors-for-better-3d-dynamic-reconstru.html"},{"id":"2512.06373v1","title":"VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning","headline":"提出VG-Refiner，通过Agent强化学习优化工具反馈，提升指代 grounding 推理能力","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206373v1-vg-refiner-towards-tool-refined-referring-grounded-reasoning-via-age.html"},{"id":"2512.06330v1","title":"S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening","headline":"提出S2WMamba，通过谱-空域小波变换和Mamba模块实现高效遥感图像融合","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206330v1-s2wmamba-a-spectral-spatial-wavelet-mamba-for-pansharpening.html"},{"id":"2512.06328v1","title":"ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models","headline":"ReCAD：利用强化学习增强的参数化CAD模型生成，结合视觉-语言模型","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206328v1-recad-reinforcement-learning-enhanced-parametric-cad-model-generatio.html"},{"id":"2512.06424v1","title":"DragMesh: Interactive 3D Generation Made Easy","headline":"DragMesh：提出解耦运动生成框架，实现实时交互式3D模型可动性生成。","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206424v1-dragmesh-interactive-3d-generation-made-easy.html"},{"id":"2512.06426v1","title":"When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition","headline":"提出双路径Transformer框架，利用CLIP解决远距离图像性别识别难题","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206426v1-when-gender-is-hard-to-see-multi-attribute-support-for-long-range-re.html"},{"id":"2512.06276v2","title":"RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension","headline":"提出RefBench-PRO基准，用于评估多模态大模型在指代表达理解中的感知和推理能力。","tag":"cs.CV","date":"2025-12-06","url":"cs-CV/2025-12-06/papers/251206276v2-refbench-pro-perceptual-and-reasoning-oriented-benchmark-for-referri.html"},{"id":"2512.05578v1","title":"A Hyperspectral Imaging Guided Robotic Grasping System","headline":"提出基于高光谱成像的机器人抓取系统，提升复杂环境下物体识别与抓取能力","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205578v1-a-hyperspectral-imaging-guided-robotic-grasping-system.html"},{"id":"2512.06112v2","title":"WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving","headline":"提出WAM-Flow以解决自主驾驶中的轨迹规划问题","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206112v2-wam-flow-parallel-coarse-to-fine-motion-planning-via-discrete-flow-m.html"},{"id":"2512.06147v1","title":"GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers","headline":"GuideNav：面向视障人士的纯视觉机器人导航助手，通过用户调研指导开发","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206147v1-guidenav-user-informed-development-of-a-vision-only-robotic-navigati.html"},{"id":"2512.06182v1","title":"Situation-Aware Interactive MPC Switching for Autonomous Driving","headline":"提出情境感知交互式MPC切换策略，提升自动驾驶交互场景性能","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206182v1-situation-aware-interactive-mpc-switching-for-autonomous-driving.html"},{"id":"2512.05953v1","title":"Correspondence-Oriented Imitation Learning: Flexible Visuomotor Control with 3D Conditioning","headline":"提出面向对应关系的模仿学习框架COIL，实现灵活的3D视觉运动控制。","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205953v1-correspondence-oriented-imitation-learning-flexible-visuomotor-contr.html"},{"id":"2512.06198v1","title":"Cascaded Tightly-Coupled Observer Design for Single-Range-Aided Inertial Navigation","headline":"提出单范围辅助导航观察器以解决惯性导航状态重构问题","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206198v1-cascaded-tightly-coupled-observer-design-for-single-range-aided-iner.html"},{"id":"2512.05599v1","title":"An Integrated System for WEEE Sorting Employing X-ray Imaging, AI-based Object Detection and Segmentation, and Delta Robot Manipulation","headline":"提出集成X射线成像、AI检测分割和Delta机器人的WEEE分拣系统","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205599v1-an-integrated-system-for-weee-sorting-employing-x-ray-imaging-ai-bas.html"},{"id":"2512.05955v1","title":"SIMPACT: Simulation-Enabled Action Planning using Vision-Language Models","headline":"SIMPACT：利用视觉-语言模型和仿真进行动作规划，解决机器人操作中物理理解不足的问题","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205955v1-simpact-simulation-enabled-action-planning-using-vision-language-mod.html"},{"id":"2512.05812v2","title":"Toward Efficient and Robust Behavior Models for Multi-Agent Driving Simulation","headline":"提出一种高效鲁棒的多智能体驾驶行为模型，用于驾驶模拟。","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205812v2-toward-efficient-and-robust-behavior-models-for-multi-agent-driving-.html"},{"id":"2512.05693v1","title":"HiMoE-VLA: Hierarchical Mixture-of-Experts for Generalist Vision-Language-Action Policies","headline":"提出HiMoE-VLA，解决具身智能中异构机器人数据泛化难题","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205693v1-himoe-vla-hierarchical-mixture-of-experts-for-generalist-vision-lang.html"},{"id":"2512.06207v1","title":"Where to Fly, What to Send: Communication-Aware Aerial Support for Ground Robots","headline":"提出通信感知的无人机辅助地面机器人框架，解决带宽受限环境下的信息传输与探索问题","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206207v1-where-to-fly-what-to-send-communication-aware-aerial-support-for-gro.html"},{"id":"2512.06130v1","title":"Probabilistic Weapon Engagement Zones for a Turn Constrained Pursuer","headline":"针对转弯受限追击者，提出概率武器交战区(CSPEZ)方法，优化规避轨迹。","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251206130v1-probabilistic-weapon-engagement-zones-for-a-turn-constrained-pursuer.html"},{"id":"2512.05932v1","title":"Physically-Based Simulation of Automotive LiDAR","headline":"提出基于物理的汽车激光雷达仿真模型，包含光学校准与系统验证。","tag":"cs.RO","date":"2025-12-05","url":"cs-RO/2025-12-05/papers/251205932v1-physically-based-simulation-of-automotive-lidar.html"},{"id":"2512.06058v1","title":"Representation Learning for Point Cloud Understanding","headline":"提出一种融合2D预训练模型的3D点云表示学习方法，提升点云理解能力","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251206058v1-representation-learning-for-point-cloud-understanding.html"},{"id":"2512.05710v1","title":"Manifold-Aware Point Cloud Completion via Geodesic-Attentive Hierarchical Feature Learning","headline":"提出基于流形感知的点云补全框架，通过测地线注意力机制提升几何一致性。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205710v1-manifold-aware-point-cloud-completion-via-geodesic-attentive-hierarc.html"},{"id":"2512.05529v1","title":"See in Depth: Training-Free Surgical Scene Segmentation with Monocular Depth Priors","headline":"提出基于单目深度先验的无训练手术场景分割方法DepSeg","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205529v1-see-in-depth-training-free-surgical-scene-segmentation-with-monocula.html"},{"id":"2512.05905v1","title":"SCAIL: Towards Studio-Grade Character Animation via In-Context Learning of 3D-Consistent Pose Representations","headline":"SCAIL：通过3D一致姿态表示的上下文学习实现工作室级角色动画","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205905v1-scail-towards-studio-grade-character-animation-via-in-context-learni.html"},{"id":"2512.05783v1","title":"Curvature-Regularized Variational Autoencoder for 3D Scene Reconstruction from Sparse Depth","headline":"提出曲率正则化VAE，用于从稀疏深度数据重建3D场景","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205783v1-curvature-regularized-variational-autoencoder-for-3d-scene-reconstru.html"},{"id":"2512.11865v1","title":"Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation","headline":"提出可解释的对抗鲁棒视觉-语言-动作模型，用于提升机器人操作在智能农业中的鲁棒性。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251211865v1-explainable-adversarial-robust-vision-language-action-model-for-robo.html"},{"id":"2512.05759v1","title":"Label-Efficient Point Cloud Segmentation with Active Learning","headline":"提出基于2D网格划分和网络集成的点云主动学习分割方法，提升标注效率。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205759v1-label-efficient-point-cloud-segmentation-with-active-learning.html"},{"id":"2512.05446v1","title":"TED-4DGS: Temporally Activated and Embedding-based Deformation for 4DGS Compression","headline":"提出TED-4DGS，用于动态3D高斯溅射压缩，实现率失真优化。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205446v1-ted-4dgs-temporally-activated-and-embedding-based-deformation-for-4d.html"},{"id":"2512.05412v1","title":"YOLO and SGBM Integration for Autonomous Tree Branch Detection and Depth Estimation in Radiata Pine Pruning Applications","headline":"提出YOLO与SGBM融合框架，用于辐射松修剪中树枝的自主检测与深度估计","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205412v1-yolo-and-sgbm-integration-for-autonomous-tree-branch-detection-and-d.html"},{"id":"2512.05927v1","title":"World Models That Know When They Don't Know: Controllable Video Generation with Calibrated Uncertainty","headline":"提出C3方法，为可控视频生成模型提供校准的不确定性估计，缓解幻觉问题。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205927v1-world-models-that-know-when-they-dont-know-controllable-video-genera.html"},{"id":"2512.05809v1","title":"Probing the effectiveness of World Models for Spatial Reasoning through Test-time Scaling","headline":"提出ViSA框架，通过空间断言改进世界模型在空间推理中的测试时缩放效果","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205809v1-probing-the-effectiveness-of-world-models-for-spatial-reasoning-thro.html"},{"id":"2512.08980v2","title":"Training Multi-Image Vision Agents via End2End Reinforcement Learning","headline":"提出IMAgent，通过端到端强化学习训练多图视觉Agent，解决复杂多图QA任务。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251208980v2-training-multi-image-vision-agents-via-end2end-reinforcement-learnin.html"},{"id":"2512.05354v1","title":"SplatPainter: Interactive Authoring of 3D Gaussians from 2D Edits via Test-Time Training","headline":"提出SplatPainter以解决3D高斯模型交互编辑问题","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205354v1-splatpainter-interactive-authoring-of-3d-gaussians-from-2d-edits-via.html"},{"id":"2512.06179v1","title":"Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction","headline":"提出基于近似3D几何和光照方向的物理约束阴影检测方法","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251206179v1-physics-grounded-attached-shadow-detection-using-approximate-3d-geom.html"},{"id":"2512.06158v1","title":"Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation","headline":"提出Track4DGen，利用跟踪引导的运动先验实现高质量3D模型动画生成。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251206158v1-tracking-guided-4d-generation-foundation-tracker-motion-priors-for-3.html"},{"id":"2512.06080v1","title":"Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light","headline":"Shoot-Bounce-3D：利用单光子激光雷达和双次反射光进行遮挡感知的三维重建","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251206080v1-shoot-bounce-3d-single-shot-occlusion-aware-3d-from-lidar-by-decompo.html"},{"id":"2512.06065v1","title":"EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing","headline":"EgoEdit：用于第一人称视频编辑的数据集、实时模型与评测基准","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251206065v1-egoedit-dataset-real-time-streaming-model-and-benchmark-for-egocentr.html"},{"id":"2512.05941v1","title":"Zoom in, Click out: Unlocking and Evaluating the Potential of Zooming for GUI Grounding","headline":"提出ZoomClick，利用缩放先验提升GUI界面元素定位性能","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205941v1-zoom-in-click-out-unlocking-and-evaluating-the-potential-of-zooming-.html"},{"id":"2512.05663v1","title":"LeAD-M3D: Leveraging Asymmetric Distillation for Real-time Monocular 3D Detection","headline":"LeAD-M3D：利用非对称蒸馏实现实时单目3D目标检测","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205663v1-lead-m3d-leveraging-asymmetric-distillation-for-real-time-monocular-.html"},{"id":"2512.05610v1","title":"NormalView: sensor-agnostic tree species classification from backpack and aerial lidar data using geometric projections","headline":"NormalView：一种基于几何投影的传感器无关树种分类方法","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205610v1-normalview-sensor-agnostic-tree-species-classification-from-backpack.html"},{"id":"2512.05597v1","title":"Fast SceneScript: Accurate and Efficient Structured Language Model via Multi-Token Prediction","headline":"Fast SceneScript：通过多Token预测实现高效精确的结构化语言模型，用于3D场景布局估计。","tag":"cs.CV","date":"2025-12-05","url":"cs-CV/2025-12-05/papers/251205597v1-fast-scenescript-accurate-and-efficient-structured-language-model-vi.html"},{"id":"2512.04381v1","title":"FALCON: Actively Decoupled Visuomotor Policies for Loco-Manipulation with Foundation-Model-Based Coordination","headline":"FALCON：基于基础模型协调的主动解耦式操作-移动机器人策略","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204381v1-falcon-actively-decoupled-visuomotor-policies-for-loco-manipulation-.html"},{"id":"2512.04731v1","title":"Bridging Simulation and Reality: Cross-Domain Transfer with Semantic 2D Gaussian Splatting","headline":"提出语义2D高斯溅射(S2GS)，提升机器人操作中模拟到真实的跨域迁移能力","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204731v1-bridging-simulation-and-reality-cross-domain-transfer-with-semantic-.html"},{"id":"2512.04884v1","title":"Hoi! -- A Multimodal Dataset for Force-Grounded, Cross-View Articulated Manipulation","headline":"Hoi!：提出一个力感知的、跨视角铰接操作多模态数据集。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204884v1-hoi-a-multimodal-dataset-for-force-grounded-cross-view-articulated-m.html"},{"id":"2512.04772v1","title":"TEMPO-VINE: A Multi-Temporal Sensor Fusion Dataset for Localization and Mapping in Vineyards","headline":"TEMPO-VINE：用于葡萄园定位与建图的多时序传感器融合数据集","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204772v1-tempo-vine-a-multi-temporal-sensor-fusion-dataset-for-localization-a.html"},{"id":"2512.05094v2","title":"From Generated Human Videos to Physically Plausible Robot Trajectories","headline":"GenMimic：利用生成视频实现人形机器人零样本物理可行轨迹控制","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205094v2-from-generated-human-videos-to-physically-plausible-robot-trajectori.html"},{"id":"2512.04813v1","title":"MOVE: A Simple Motion-Based Data Collection Paradigm for Spatial Generalization in Robotic Manipulation","headline":"提出MOVE以解决机器人操作中的数据稀缺问题","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204813v1-move-a-simple-motion-based-data-collection-paradigm-for-spatial-gene.html"},{"id":"2512.06038v1","title":"Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction","headline":"提出基于深度学习微误差校正的透明基板闭环机器人操作方法，用于自驱动实验室。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251206038v1-closed-loop-robotic-manipulation-of-transparent-substrates-for-self-.html"},{"id":"2512.04399v1","title":"Development of a 15-Degree-of-Freedom Bionic Hand with Cable-Driven Transmission and Distributed Actuation","headline":"提出一种15自由度仿生灵巧手，采用线缆驱动和分布式驱动，适用于机器人操作任务。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204399v1-development-of-a-15-degree-of-freedom-bionic-hand-with-cable-driven-.html"},{"id":"2512.04373v1","title":"Vertical Planetary Landing on Sloped Terrain Using Optical Flow Divergence Estimates","headline":"提出基于光流散度估计的非线性控制策略，实现斜坡地形上的垂直行星着陆","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204373v1-vertical-planetary-landing-on-sloped-terrain-using-optical-flow-dive.html"},{"id":"2512.04960v1","title":"Hybrid-Diffusion Models: Combining Open-loop Routines with Visuomotor Diffusion Policies","headline":"Hybrid-Diffusion模型：结合开放循环程序和视觉运动扩散策略，提升操作精度与速度","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204960v1-hybrid-diffusion-models-combining-open-loop-routines-with-visuomotor.html"},{"id":"2512.05107v1","title":"STARE-VLA: Progressive Stage-Aware Reinforcement for Fine-Tuning Vision-Language-Action Models","headline":"提出STARE-VLA，通过阶段感知强化学习微调视觉-语言-动作模型，提升机器人操作性能。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205107v1-stare-vla-progressive-stage-aware-reinforcement-for-fine-tuning-visi.html"},{"id":"2512.05211v1","title":"Wake Vectoring for Efficient Morphing Flight","headline":"提出被动尾流导向机制，提升变形飞行器在形态变化期间的推力效率和控制能力","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205211v1-wake-vectoring-for-efficient-morphing-flight.html"},{"id":"2512.04973v1","title":"Preliminary Analysis and Simulation of a Compact Variable Stiffness Wrist","headline":"提出一种紧凑型变刚度腕部，通过冗余弹性驱动实现高精度位置和刚度控制。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204973v1-preliminary-analysis-and-simulation-of-a-compact-variable-stiffness-.html"},{"id":"2512.04446v1","title":"Vision-Language-Action Models for Selective Robotic Disassembly: A Case Study on Critical Component Extraction from Desktops","headline":"针对桌面电脑关键部件拆卸，探索视觉-语言-动作模型的应用潜力","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204446v1-vision-language-action-models-for-selective-robotic-disassembly-a-ca.html"},{"id":"2512.04404v1","title":"Bridging Probabilistic Inference and Behavior Trees: An Interactive Framework for Adaptive Multi-Robot Cooperation","headline":"提出交互式推理行为树，用于多机器人自适应协同","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251204404v1-bridging-probabilistic-inference-and-behavior-trees-an-interactive-f.html"},{"id":"2512.05303v1","title":"Seabed-to-Sky Mapping of Maritime Environments with a Dual Orthogonal SONAR and LiDAR Sensor Suite","headline":"提出一种GNSS独立的海洋环境映射系统以解决现有方法的局限性","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205303v1-seabed-to-sky-mapping-of-maritime-environments-with-a-dual-orthogona.html"},{"id":"2512.05008v1","title":"Contact-Implicit Modeling and Simulation of a Snake Robot on Compliant and Granular Terrain","headline":"针对蛇形机器人在复杂地形运动，提出接触隐式建模与仿真框架","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205008v1-contact-implicit-modeling-and-simulation-of-a-snake-robot-on-complia.html"},{"id":"2512.05171v1","title":"Two-Stage Camera Calibration Method for Multi-Camera Systems Using Scene Geometry","headline":"提出一种基于场景几何的多相机系统两阶段标定方法，无需同步视频流。","tag":"cs.RO","date":"2025-12-04","url":"cs-RO/2025-12-04/papers/251205171v1-two-stage-camera-calibration-method-for-multi-camera-systems-using-s.html"},{"id":"2512.04499v1","title":"Back to Basics: Motion Representation Matters for Human Motion Generation Using Diffusion Model","headline":"研究运动扩散模型中运动表征对人体运动生成的影响，并提出优化建议。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204499v1-back-to-basics-motion-representation-matters-for-human-motion-genera.html"},{"id":"2512.04537v1","title":"X-Humanoid: Robotize Human Videos to Generate Humanoid Videos at Scale","headline":"X-Humanoid：通过机器人化人类视频大规模生成类人机器人视频","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204537v1-x-humanoid-robotize-human-videos-to-generate-humanoid-videos-at-scal.html"},{"id":"2512.05259v1","title":"Age-Inclusive 3D Human Mesh Recovery for Action-Preserving Data Anonymization","headline":"提出AionHMR框架，实现年龄包容的3D人体网格重建，用于保护隐私的数据匿名化。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205259v1-age-inclusive-3d-human-mesh-recovery-for-action-preserving-data-anon.html"},{"id":"2512.04815v1","title":"RobustSplat++: Decoupling Densification, Dynamics, and Illumination for In-the-Wild 3DGS","headline":"RobustSplat++：解耦3DGS的稠密化、动态和光照，实现野外场景鲁棒建模","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204815v1-robustsplat-decoupling-densification-dynamics-and-illumination-for-i.html"},{"id":"2512.04542v1","title":"Gaussian Entropy Fields: Driving Adaptive Sparsity in 3D Gaussian Optimization","headline":"提出高斯熵场以驱动3D高斯优化中的自适应稀疏性","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204542v1-gaussian-entropy-fields-driving-adaptive-sparsity-in-3d-gaussian-opt.html"},{"id":"2512.04487v1","title":"Controllable Long-term Motion Generation with Extended Joint Targets","headline":"COMET：基于Transformer的实时可控长时程人体运动生成框架","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204487v1-controllable-long-term-motion-generation-with-extended-joint-targets.html"},{"id":"2512.04358v1","title":"MAFNet:Multi-frequency Adaptive Fusion Network for Real-time Stereo Matching","headline":"提出MAFNet，通过多频自适应融合网络实现实时高精度立体匹配","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204358v1-mafnetmulti-frequency-adaptive-fusion-network-for-real-time-stereo-m.html"},{"id":"2512.05044v1","title":"Joint 3D Geometry Reconstruction and Motion Generation for 4D Synthesis from a Single Image","headline":"提出MoRe4D，联合进行3D几何重建和运动生成，从单张图像合成4D场景。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205044v1-joint-3d-geometry-reconstruction-and-motion-generation-for-4d-synthe.html"},{"id":"2512.04970v1","title":"Stable Single-Pixel Contrastive Learning for Semantic and Geometric Tasks","headline":"提出稳定单像素对比学习方法，用于语义和几何任务","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204970v1-stable-single-pixel-contrastive-learning-for-semantic-and-geometric-.html"},{"id":"2512.04939v1","title":"LiteVGGT: Boosting Vanilla VGGT via Geometry-aware Cached Token Merging","headline":"LiteVGGT：通过几何感知缓存Token合并加速VGGT，实现大规模场景高效3D重建。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204939v1-litevggt-boosting-vanilla-vggt-via-geometry-aware-cached-token-mergi.html"},{"id":"2512.04890v3","title":"Equivariant symmetry-aware head pose estimation for fetal MRI","headline":"提出E(3)-Pose，解决胎儿MRI中对称感知的头部姿态估计问题","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204890v3-equivariant-symmetry-aware-head-pose-estimation-for-fetal-mri.html"},{"id":"2512.04511v1","title":"DuGI-MAE: Improving Infrared Mask Autoencoders via Dual-Domain Guidance","headline":"DuGI-MAE：通过双域引导改进红外图像掩码自编码器性能","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204511v1-dugi-mae-improving-infrared-mask-autoencoders-via-dual-domain-guidan.html"},{"id":"2512.04425v1","title":"Explainable Parkinsons Disease Gait Recognition Using Multimodal RGB-D Fusion and Large Language Models","headline":"提出基于RGB-D融合和LLM的可解释帕金森步态识别框架","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204425v1-explainable-parkinsons-disease-gait-recognition-using-multimodal-rgb.html"},{"id":"2512.04952v2","title":"FASTer: Toward Efficient Autoregressive Vision Language Action Modeling via Neural Action Tokenization","headline":"FASTer：通过神经动作标记化实现高效的自回归视觉-语言-动作建模","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204952v2-faster-toward-efficient-autoregressive-vision-language-action-modeli.html"},{"id":"2512.05172v1","title":"Semore: VLM-guided Enhanced Semantic Motion Representations for Visual Reinforcement Learning","headline":"Semore：VLM引导的增强语义运动表征用于视觉强化学习","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205172v1-semore-vlm-guided-enhanced-semantic-motion-representations-for-visua.html"},{"id":"2512.04904v1","title":"ReflexFlow: Rethinking Learning Objective for Exposure Bias Alleviation in Flow Matching","headline":"ReflexFlow：通过反思式优化Flow Matching学习目标，缓解生成模型的暴露偏差","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204904v1-reflexflow-rethinking-learning-objective-for-exposure-bias-alleviati.html"},{"id":"2512.04862v1","title":"Contact-Aware Refinement of Human Pose Pseudo-Ground Truth via Bioimpedance Sensing","headline":"提出BioTUCH，结合生物阻抗感知优化自接触场景下的人体姿态伪标签。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204862v1-contact-aware-refinement-of-human-pose-pseudo-ground-truth-via-bioim.html"},{"id":"2512.04395v1","title":"Fourier-Attentive Representation Learning: A Fourier-Guided Framework for Few-Shot Generalization in Vision-Language Models","headline":"提出FARL框架，利用傅里叶分析解耦视觉表征，提升视觉-语言模型在少样本学习中的泛化能力。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204395v1-fourier-attentive-representation-learning-a-fourier-guided-framework.html"},{"id":"2512.05113v2","title":"Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting","headline":"Splannequin：利用双重检测 Splatting 冻结单目人体雕塑挑战视频","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205113v2-splannequin-freezing-monocular-mannequin-challenge-footage-with-dual.html"},{"id":"2512.05060v1","title":"4DLangVGGT: 4D Language-Visual Geometry Grounded Transformer","headline":"提出4DLangVGGT，用于高效且可泛化的4D语言-视觉几何对齐","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205060v1-4dlangvggt-4d-language-visual-geometry-grounded-transformer.html"},{"id":"2512.05115v2","title":"Light-X: Generative 4D Video Rendering with Camera and Illumination Control","headline":"Light-X：提出可控相机与光照的生成式4D视频渲染框架","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205115v2-light-x-generative-4d-video-rendering-with-camera-and-illumination-c.html"},{"id":"2512.05079v1","title":"Object Reconstruction under Occlusion with Generative Priors and Contact-induced Constraints","headline":"提出基于生成先验和接触约束的物体遮挡重建方法，提升机器人操作性能。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205079v1-object-reconstruction-under-occlusion-with-generative-priors-and-con.html"},{"id":"2512.05076v1","title":"BulletTime: Decoupled Control of Time and Camera Pose for Video Generation","headline":"BulletTime：解耦时间和相机姿态控制的视频生成框架","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251205076v1-bullettime-decoupled-control-of-time-and-camera-pose-for-video-gener.html"},{"id":"2512.04996v1","title":"A dynamic memory assignment strategy for dilation-based ICP algorithm on embedded GPUs","headline":"针对嵌入式GPU，提出动态内存分配策略优化VANICP点云配准算法。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204996v1-a-dynamic-memory-assignment-strategy-for-dilation-based-icp-algorith.html"},{"id":"2512.04943v1","title":"Towards Adaptive Fusion of Multimodal Deep Networks for Human Action Recognition","headline":"提出基于门控机制的多模态自适应融合网络，提升人类行为识别精度","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204943v1-towards-adaptive-fusion-of-multimodal-deep-networks-for-human-action.html"},{"id":"2512.04888v2","title":"You Only Train Once (YOTO): A Retraining-Free Object Detection Framework","headline":"提出YOTO框架，解决目标检测中免重训练的新品增量学习问题","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204888v2-you-only-train-once-yoto-a-retraining-free-object-detection-framewor.html"},{"id":"2512.04686v2","title":"Towards Cross-View Point Correspondence in Vision-Language Models","headline":"提出CrossPoint-Bench和CroPond模型，解决视觉语言模型中跨视角点对应难题。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204686v2-towards-cross-view-point-correspondence-in-vision-language-models.html"},{"id":"2512.04619v1","title":"Denoise to Track: Harnessing Video Diffusion Priors for Robust Correspondence","headline":"提出HeFT，利用视频扩散先验实现鲁棒的零样本点跟踪","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204619v1-denoise-to-track-harnessing-video-diffusion-priors-for-robust-corres.html"},{"id":"2512.04599v1","title":"Malicious Image Analysis via Vision-Language Segmentation Fusion: Detection, Element, and Location in One-shot","headline":"提出基于视觉-语言分割融合的恶意图像分析方法，实现一步到位的内容检测、元素识别和定位。","tag":"cs.CV","date":"2025-12-04","url":"cs-CV/2025-12-04/papers/251204599v1-malicious-image-analysis-via-vision-language-segmentation-fusion-det.html"},{"id":"2512.04514v1","title":"SPLICE: Part-Level 3D Shape Editing from Local Semantic Extraction to Global Neural Mixing","headline":"SPLICE：局部语义提取到全局神经混合的部件级3D形状编辑","tag":"cs.GR","date":"2025-12-04","url":"cs-GR/2025-12-04/papers/251204514v1-splice-part-level-3d-shape-editing-from-local-semantic-extraction-to.html"},{"id":"2512.04385v1","title":"STeP-Diff: Spatio-Temporal Physics-Informed Diffusion Models for Mobile Fine-Grained Pollution Forecasting","headline":"STeP-Diff：时空物理信息扩散模型用于移动细粒度污染预测","tag":"cs.LG","date":"2025-12-04","url":"cs-LG/2025-12-04/papers/251204385v1-step-diff-spatio-temporal-physics-informed-diffusion-models-for-mobi.html"},{"id":"2512.05299v1","title":"ARCAS: An Augmented Reality Collision Avoidance System with SLAM-Based Tracking for Enhancing VRU Safety","headline":"ARCAS：基于SLAM的增强现实碰撞避免系统，提升弱势道路使用者安全","tag":"eess.SY","date":"2025-12-04","url":"eess-SY/2025-12-04/papers/251205299v1-arcas-an-augmented-reality-collision-avoidance-system-with-slam-base.html"},{"id":"2512.04579v1","title":"Gauss-Newton accelerated MPPI Control","headline":"提出Gauss-Newton加速的MPPI控制，提升高维控制问题的计算效率。","tag":"eess.SY","date":"2025-12-04","url":"eess-SY/2025-12-04/papers/251204579v1-gauss-newton-accelerated-mppi-control.html"},{"id":"2512.03774v1","title":"Safety Reinforced Model Predictive Control (SRMPC): Improving MPC with Reinforcement Learning for Motion Planning in Autonomous Driving","headline":"提出安全强化学习增强的模型预测控制(SRMPC)，提升自动驾驶运动规划的安全性与性能。","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203774v1-safety-reinforced-model-predictive-control-srmpc-improving-mpc-with-.html"},{"id":"2512.03958v2","title":"MDE-AgriVLN: Agricultural Vision-and-Language Navigation with Monocular Depth Estimation","headline":"MDE-AgriVLN：提出单目深度估计的农业视觉语言导航方法","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203958v2-mde-agrivln-agricultural-vision-and-language-navigation-with-monocul.html"},{"id":"2512.03707v1","title":"ContactRL: Safe Reinforcement Learning based Motion Planning for Contact based Human Robot Collaboration","headline":"ContactRL：基于强化学习的安全运动规划，用于人机协作中的接触任务","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203707v1-contactrl-safe-reinforcement-learning-based-motion-planning-for-cont.html"},{"id":"2512.03743v1","title":"Cross-embodied Co-design for Dexterous Hands","headline":"提出一种跨具身协同设计框架，用于灵巧手形态与控制策略的联合优化","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203743v1-cross-embodied-co-design-for-dexterous-hands.html"},{"id":"2512.03538v1","title":"AdaPower: Specializing World Foundation Models for Predictive Manipulation","headline":"AdaPower：通过自适应世界模型提升预测性操作的性能","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203538v1-adapower-specializing-world-foundation-models-for-predictive-manipul.html"},{"id":"2512.03891v1","title":"Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning","headline":"提出基于数字孪生和深度强化学习的全车主动悬架控制协同设计框架","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203891v1-digital-twin-based-control-co-design-of-full-vehicle-active-suspensi.html"},{"id":"2512.03736v1","title":"Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control","headline":"首次在国际空间站验证基于强化学习的自由飞行机器人自主控制","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203736v1-crossing-the-sim2real-gap-between-simulation-and-ground-testing-to-s.html"},{"id":"2512.03556v1","title":"RoboScape-R: Unified Reward-Observation World Models for Generalizable Robotics Training via RL","headline":"RoboScape-R：通过统一奖励-观测世界模型提升机器人强化学习的泛化能力","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203556v1-roboscape-r-unified-reward-observation-world-models-for-generalizabl.html"},{"id":"2512.03874v1","title":"OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance","headline":"OmniDexVLG：提出基于视觉语言模型引导的灵巧抓取生成框架，实现语义可控的抓取合成。","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203874v1-omnidexvlg-learning-dexterous-grasp-generation-from-vision-language-.html"},{"id":"2512.03772v1","title":"Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control","headline":"提出基于贝叶斯优化的力矩级非线性模型预测控制自动调参框架","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203772v1-bayesian-optimization-for-automatic-tuning-of-torque-level-nonlinear.html"},{"id":"2512.03756v1","title":"Prediction-Driven Motion Planning: Route Integration Strategies in Attention-Based Prediction Models","headline":"提出基于注意力机制的预测模型，融合导航信息以提升自动驾驶车辆交互能力","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203756v1-prediction-driven-motion-planning-route-integration-strategies-in-at.html"},{"id":"2512.03522v2","title":"MSG-Loc: Multi-Label Likelihood-based Semantic Graph Matching for Object-Level Global Localization","headline":"提出基于多标签似然语义图匹配的物体级全局定位方法","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203522v2-msg-loc-multi-label-likelihood-based-semantic-graph-matching-for-obj.html"},{"id":"2512.03729v1","title":"Autonomous Planning In-space Assembly Reinforcement-learning free-flYer (APIARY) International Space Station Astrobee Testing","headline":"APIARY实验：基于强化学习的国际空间站Astrobee机器人自主装配","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203729v1-autonomous-planning-in-space-assembly-reinforcement-learning-free-fl.html"},{"id":"2512.04308v1","title":"ResponsibleRobotBench: Benchmarking Responsible Robot Manipulation using Multi-modal Large Language Models","headline":"提出ResponsibleRobotBench，利用多模态大语言模型评估负责任的机器人操作。","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251204308v1-responsiblerobotbench-benchmarking-responsible-robot-manipulation-us.html"},{"id":"2512.04279v1","title":"Driving Beyond Privilege: Distilling Dense-Reward Knowledge into Sparse-Reward Policies","headline":"提出奖励特权世界模型蒸馏，解决自动驾驶中稠密奖励泛化性差的问题","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251204279v1-driving-beyond-privilege-distilling-dense-reward-knowledge-into-spar.html"},{"id":"2512.06017v1","title":"Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models","headline":"利用现成视觉-语言模型实现免训练机器人姿态估计","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251206017v1-training-free-robot-pose-estimation-using-off-the-shelf-foundational.html"},{"id":"2512.03795v1","title":"MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving","headline":"MPCFormer：基于物理信息与数据驱动的可解释社会感知自动驾驶方法","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203795v1-mpcformer-a-physics-informed-data-driven-approach-for-explainable-so.html"},{"id":"2512.03684v1","title":"A Novel Approach to Tomato Harvesting Using a Hybrid Gripper with Semantic Segmentation and Keypoint Detection","headline":"提出一种基于混合夹爪的番茄采摘系统，结合语义分割与关键点检测实现精准采摘。","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203684v1-a-novel-approach-to-tomato-harvesting-using-a-hybrid-gripper-with-se.html"},{"id":"2512.03913v1","title":"Hierarchical Vision Language Action Model Using Success and Failure Demonstrations","headline":"提出VINE模型，利用成功与失败演示提升视觉-语言-动作模型的鲁棒性","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203913v1-hierarchical-vision-language-action-model-using-success-and-failure-.html"},{"id":"2512.03911v1","title":"Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware","headline":"提出基于Loihi 2神经形态硬件的自主强化学习机器人控制方案","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203911v1-autonomous-reinforcement-learning-robot-control-with-intels-loihi-2-.html"},{"id":"2512.04231v1","title":"CRAFT-E: A Neuro-Symbolic Framework for Embodied Affordance Grounding","headline":"CRAFT-E：用于具身可供性接地的神经符号框架","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251204231v1-craft-e-a-neuro-symbolic-framework-for-embodied-affordance-grounding.html"},{"id":"2512.03995v1","title":"Artificial Microsaccade Compensation: Stable Vision for an Ornithopter","headline":"提出人工微眼跳补偿方法，稳定扑翼飞行器剧烈抖动下的视频","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203995v1-artificial-microsaccade-compensation-stable-vision-for-an-ornithopte.html"},{"id":"2512.03630v1","title":"Multimodal Control of Manipulators: Coupling Kinematics and Vision for Self-Driving Laboratory Operations","headline":"针对冗余机械臂，提出基于雅可比矩阵的运动规划方案，用于自动化实验室操作。","tag":"cs.RO","date":"2025-12-03","url":"cs-RO/2025-12-03/papers/251203630v1-multimodal-control-of-manipulators-coupling-kinematics-and-vision-fo.html"},{"id":"2512.04021v1","title":"C3G: Learning Compact 3D Representations with 2K Gaussians","headline":"C3G：使用2K高斯学习紧凑的3D表示，提升场景重建与理解","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204021v1-c3g-learning-compact-3d-representations-with-2k-gaussians.html"},{"id":"2512.03601v1","title":"Motion4D: Learning 3D-Consistent Motion and Semantics for 4D Scene Understanding","headline":"Motion4D：学习3D一致的运动和语义信息，用于4D场景理解","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203601v1-motion4d-learning-3d-consistent-motion-and-semantics-for-4d-scene-un.html"},{"id":"2512.04282v1","title":"Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer","headline":"提出GRU-SNF，通过推理时随机细化GRU-NF，实现实时视频运动迁移中多样性预测。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204282v1-inference-time-stochastic-refinement-of-gru-normalizing-flow-for-rea.html"},{"id":"2512.03577v1","title":"Cross-Stain Contrastive Learning for Paired Immunohistochemistry and Histopathology Slide Representation Learning","headline":"提出Cross-Stain Contrastive Learning框架，解决多染色病理切片表示学习中的对齐问题。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203577v1-cross-stain-contrastive-learning-for-paired-immunohistochemistry-and.html"},{"id":"2512.04303v1","title":"Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications","headline":"提出Gamma-from-Mono，用于车辆应用中道路相对、度量、自监督单目几何估计","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204303v1-gamma-from-mono-road-relative-metric-self-supervised-monocular-geome.html"},{"id":"2512.03520v1","title":"FloodDiffusion: Tailored Diffusion Forcing for Streaming Motion Generation","headline":"FloodDiffusion：用于流式运动生成的定制扩散强制框架","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203520v1-flooddiffusion-tailored-diffusion-forcing-for-streaming-motion-gener.html"},{"id":"2512.03963v2","title":"TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning","headline":"提出TempR1，通过时序感知多任务强化学习提升MLLM对长视频的时序理解能力。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203963v2-tempr1-improving-temporal-understanding-of-mllms-via-temporal-aware-.html"},{"id":"2512.04315v1","title":"SyncTrack4D: Cross-Video Motion Alignment and Video Synchronization for Multi-Video 4D Gaussian Splatting","headline":"SyncTrack4D：面向未同步多视角视频的4D高斯溅射动态场景重建。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204315v1-synctrack4d-cross-video-motion-alignment-and-video-synchronization-f.html"},{"id":"2512.03848v1","title":"PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation","headline":"PULSE：统一多任务架构，用于心脏分割、诊断和少样本跨模态临床自适应","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203848v1-pulse-a-unified-multi-task-architecture-for-cardiac-segmentation-dia.html"},{"id":"2512.03619v2","title":"LAMP: Language-Assisted Motion Planning for Controllable Video Generation","headline":"LAMP：利用语言辅助的运动规划实现可控视频生成","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203619v2-lamp-language-assisted-motion-planning-for-controllable-video-genera.html"},{"id":"2512.03598v1","title":"Memory-Guided Point Cloud Completion for Dental Reconstruction","headline":"提出基于记忆引导的点云补全框架，用于牙科重建，提升补全精度。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203598v1-memory-guided-point-cloud-completion-for-dental-reconstruction.html"},{"id":"2512.04040v1","title":"RELIC: Interactive Video World Model with Long-Horizon Memory","headline":"RELIC：基于长时记忆的交互式视频世界模型，实现实时场景探索","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204040v1-relic-interactive-video-world-model-with-long-horizon-memory.html"},{"id":"2512.04007v2","title":"On the Temporality for Sketch Representation Learning","headline":"研究草图表示学习中时序性的影响，揭示最优建模方式。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204007v2-on-the-temporality-for-sketch-representation-learning.html"},{"id":"2512.03852v1","title":"Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba","headline":"提出频率感知Mamba（FAMamba）用于恶劣天气下的交通图像恢复。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203852v1-traffic-image-restoration-under-adverse-weather-via-frequency-aware-.html"},{"id":"2512.04313v1","title":"Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding","headline":"Mind-to-Face：首个基于脑电信号解码的逼真人脸Avatar生成框架","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204313v1-mind-to-face-neural-driven-photorealistic-avatar-synthesis-via-eeg-d.html"},{"id":"2512.04085v1","title":"Unique Lives, Shared World: Learning from Single-Life Videos","headline":"提出单一生涯学习范式，利用个体生活视频自监督学习通用视觉表征。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204085v1-unique-lives-shared-world-learning-from-single-life-videos.html"},{"id":"2512.04069v1","title":"SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL","headline":"SpaceTools：通过双重交互强化学习增强工具辅助的空间推理能力","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204069v1-spacetools-tool-augmented-spatial-reasoning-via-double-interactive-r.html"},{"id":"2512.06013v1","title":"VAT: Vision Action Transformer by Unlocking Full Representation of ViT","headline":"提出Vision Action Transformer (VAT)，充分利用ViT各层特征进行机器人动作学习。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251206013v1-vat-vision-action-transformer-by-unlocking-full-representation-of-vi.html"},{"id":"2512.03918v1","title":"UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework","headline":"UniMo：提出一个自回归框架，统一建模2D视频和3D人体运动，实现同步生成与理解。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203918v1-unimo-unifying-2d-video-and-3d-human-motion-with-an-autoregressive-f.html"},{"id":"2512.04248v1","title":"MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models","headline":"MVRoom：基于多视角扩散模型的可控3D室内场景生成","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204248v1-mvroom-controllable-3d-indoor-scene-generation-with-multi-view-diffu.html"},{"id":"2512.04012v1","title":"Emergent Outlier View Rejection in Visual Geometry Grounded Transformers","headline":"发现VGGT中隐含的离群点抑制能力，提升野外图像三维重建鲁棒性","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251204012v1-emergent-outlier-view-rejection-in-visual-geometry-grounded-transfor.html"},{"id":"2512.03724v2","title":"PosA-VLA: Enhancing Action Generation via Pose-Conditioned Anchor Attention","headline":"PosA-VLA：通过姿态条件锚点注意力增强具身任务中的动作生成","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203724v2-posa-vla-enhancing-action-generation-via-pose-conditioned-anchor-att.html"},{"id":"2512.03621v1","title":"ReCamDriving: LiDAR-Free Camera-Controlled Novel Trajectory Video Generation","headline":"提出ReCamDriving，一种纯视觉相机控制的新轨迹视频生成框架","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203621v1-recamdriving-lidar-free-camera-controlled-novel-trajectory-video-gen.html"},{"id":"2512.03590v1","title":"Beyond Boundary Frames: Audio-Visual Semantic Guidance for Context-Aware Video Interpolation","headline":"提出BBF框架，利用音视频语义指导上下文感知的视频插帧","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203590v1-beyond-boundary-frames-audio-visual-semantic-guidance-for-context-aw.html"},{"id":"2512.03566v1","title":"GAOT: Generating Articulated Objects Through Text-Guided Diffusion Models","headline":"GAOT：提出基于文本引导扩散模型的铰接物体生成框架","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203566v1-gaot-generating-articulated-objects-through-text-guided-diffusion-mo.html"},{"id":"2512.03558v1","title":"CartoMapQA: A Fundamental Benchmark Dataset Evaluating Vision-Language Models on Cartographic Map Understanding","headline":"CartoMapQA：提出用于评估视觉-语言模型地图理解能力的基础基准数据集。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203558v1-cartomapqa-a-fundamental-benchmark-dataset-evaluating-vision-languag.html"},{"id":"2512.03532v1","title":"OpenTrack3D: Towards Accurate and Generalizable Open-Vocabulary 3D Instance Segmentation","headline":"OpenTrack3D：面向精确和泛化的开放词汇3D实例分割","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203532v1-opentrack3d-towards-accurate-and-generalizable-open-vocabulary-3d-in.html"},{"id":"2512.03509v1","title":"AfroBeats Dance Movement Analysis Using Computer Vision: A Proof-of-Concept Framework Combining YOLO and Segment Anything Model","headline":"提出结合YOLO和SAM的AfroBeats舞蹈动作分析框架，无需专业设备。","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203509v1-afrobeats-dance-movement-analysis-using-computer-vision-a-proof-of-c.html"},{"id":"2512.03500v1","title":"EEA: Exploration-Exploitation Agent for Long Video Understanding","headline":"提出EEA：一种用于长视频理解的探索-利用智能体框架","tag":"cs.CV","date":"2025-12-03","url":"cs-CV/2025-12-03/papers/251203500v1-eea-exploration-exploitation-agent-for-long-video-understanding.html"},{"id":"2512.04076v1","title":"Radiance Meshes for Volumetric Reconstruction","headline":"提出基于Delaunay三角剖分的辐射网格，实现快速高质量的体渲染","tag":"cs.GR","date":"2025-12-03","url":"cs-GR/2025-12-03/papers/251204076v1-radiance-meshes-for-volumetric-reconstruction.html"},{"id":"2512.11831v2","title":"On the Design of One-step Diffusion via Shortcutting Flow Paths","headline":"提出单步扩散通用设计框架，显著提升ImageNet图像生成质量，无需预训练。","tag":"cs.LG","date":"2025-12-03","url":"cs-LG/2025-12-03/papers/251211831v2-on-the-design-of-one-step-diffusion-via-shortcutting-flow-paths.html"},{"id":"2512.01194v1","title":"RoboLoc: A Benchmark Dataset for Point Place Recognition and Localization in Indoor-Outdoor Integrated Environments","headline":"RoboLoc：室内外一体化点云定位与场景识别基准数据集","tag":"cs.RO","date":"2025-12-01","url":"cs-RO/2025-12-01/papers/251201194v1-roboloc-a-benchmark-dataset-for-point-place-recognition-and-localiza.html"},{"id":"2512.01188v1","title":"Real-World Reinforcement Learning of Active Perception Behaviors","headline":"提出非对称优势加权回归(AAWR)，解决机器人主动感知行为的现实强化学习问题","tag":"cs.RO","date":"2025-12-01","url":"cs-RO/2025-12-01/papers/251201188v1-real-world-reinforcement-learning-of-active-perception-behaviors.html"},{"id":"2512.11824v1","title":"ReGlove: A Soft Pneumatic Glove for Activities of Daily Living Assistance via Wrist-Mounted Vision","headline":"ReGlove：基于腕部视觉的低成本软气动助力手套，辅助日常生活活动","tag":"cs.RO","date":"2025-12-01","url":"cs-RO/2025-12-01/papers/251211824v1-reglove-a-soft-pneumatic-glove-for-activities-of-daily-living-assist.html"},{"id":"2512.01214v1","title":"M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis","headline":"M4-BLIP：通过人脸增强的局部分析提升多模态媒体篡改检测","tag":"cs.CV","date":"2025-12-01","url":"cs-CV/2025-12-01/papers/251201214v1-m4-blip-advancing-multi-modal-media-manipulation-detection-through-f.html"},{"id":"2512.01178v1","title":"VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering","headline":"提出VSRD++以解决单目3D物体检测中的标注依赖问题","tag":"cs.CV","date":"2025-12-01","url":"cs-CV/2025-12-01/papers/251201178v1-vsrd-autolabeling-for-3d-object-detection-via-instance-aware-volumet.html"},{"id":"2512.01223v1","title":"S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance","headline":"S$^2$-MLLM：通过结构引导增强MLLM在3D视觉定位中的空间推理能力","tag":"cs.CV","date":"2025-12-01","url":"cs-CV/2025-12-01/papers/251201223v1-s2-mllm-boosting-spatial-reasoning-capability-of-mllms-for-3d-visual.html"},{"id":"2512.00971v1","title":"H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer","headline":"H-Zero：跨人形机器人运动预训练实现少样本新形态迁移","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200971v1-h-zero-cross-humanoid-locomotion-pretraining-enables-few-shot-novel-.html"},{"id":"2512.00727v1","title":"MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion","headline":"MS-PPO：用于腿式机器人运动的形态对称等变策略学习框架","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200727v1-ms-ppo-morphological-symmetry-equivariant-policy-for-legged-robot-lo.html"},{"id":"2512.01052v1","title":"Autonomous Grasping On Quadruped Robot With Task Level Interaction","headline":"提出基于任务级交互的四足机器人自主抓取系统，提升复杂环境服务能力","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201052v1-autonomous-grasping-on-quadruped-robot-with-task-level-interaction.html"},{"id":"2512.01061v1","title":"Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer","headline":"提出基于模拟的类人机器人像素到动作策略迁移框架，解决复杂环境下的操作难题。","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201061v1-opening-the-sim-to-real-door-for-humanoid-pixel-to-action-policy-tra.html"},{"id":"2512.00939v1","title":"Constant-Time Motion Planning with Manipulation Behaviors","headline":"提出B-CTMP算法，实现操作行为下的常数时间机器人运动规划","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200939v1-constant-time-motion-planning-with-manipulation-behaviors.html"},{"id":"2512.01022v1","title":"CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding","headline":"CycleManip：通过有效的历史感知与理解实现循环任务操作","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201022v1-cyclemanip-enabling-cyclic-task-manipulation-via-effective-historica.html"},{"id":"2512.00907v2","title":"Magnetic Tactile-Driven Soft Actuator for Intelligent Grasping and Firmness Evaluation","headline":"提出磁触觉驱动软体执行器SoftMag，用于智能抓取和硬度评估。","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200907v2-magnetic-tactile-driven-soft-actuator-for-intelligent-grasping-and-f.html"},{"id":"2512.01009v1","title":"FOM-Nav: Frontier-Object Maps for Object Goal Navigation","headline":"提出FOM-Nav，利用前沿-物体地图提升物体目标导航效率","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201009v1-fom-nav-frontier-object-maps-for-object-goal-navigation.html"},{"id":"2512.01066v1","title":"Reinforcement Learning for Gliding Projectile Guidance and Control","headline":"提出基于强化学习的光学制导滑翔弹控制方法，提升动态环境下的导航自主性和灵活性。","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201066v1-reinforcement-learning-for-gliding-projectile-guidance-and-control.html"},{"id":"2512.00797v1","title":"Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration","headline":"InteractGen：将单体模型转化为具身多智能体架构，促进人机协作","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200797v1-transforming-monolithic-foundation-models-into-embodied-multi-agent-.html"},{"id":"2512.01018v1","title":"Integration of UWB Radar on Mobile Robots for Continuous Obstacle and Environment Mapping","headline":"提出一种基于移动机器人UWB雷达的连续障碍物与环境地图构建方法","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251201018v1-integration-of-uwb-radar-on-mobile-robots-for-continuous-obstacle-an.html"},{"id":"2512.00775v1","title":"SAGAS: Semantic-Aware Graph-Assisted Stitching for Offline Temporal Logic Planning","headline":"SAGAS：一种用于离线时序逻辑规划的语义感知图辅助拼接方法","tag":"cs.RO","date":"2025-11-30","url":"cs-RO/2025-11-30/papers/251200775v1-sagas-semantic-aware-graph-assisted-stitching-for-offline-temporal-l.html"},{"id":"2512.00850v1","title":"Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting","headline":"Smol-GS：提出紧凑的抽象3D高斯溅射表示方法，实现高效场景压缩。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200850v1-smol-gs-compact-representations-for-abstract-3d-gaussian-splatting.html"},{"id":"2512.00877v1","title":"Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling","headline":"提出基于长程上下文建模的前馈3D高斯溅射压缩方法，实现高压缩率。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200877v1-feed-forward-3d-gaussian-splatting-compression-with-long-context-mod.html"},{"id":"2512.00960v2","title":"Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction","headline":"提出4DHOISolver框架，结合人工标注，高效重建单目视频中的人-物交互运动。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200960v2-efficient-and-scalable-monocular-human-object-interaction-motion-rec.html"},{"id":"2512.00794v1","title":"PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery","headline":"PolarGS：利用偏振信息实现无歧义高斯溅射和精确几何重建","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200794v1-polargs-polarimetric-cues-for-ambiguity-free-gaussian-splatting-with.html"},{"id":"2512.00771v1","title":"EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes","headline":"EAG3R：事件相机增强的3D几何估计，解决动态和极端光照场景问题","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200771v1-eag3r-event-augmented-3d-geometry-estimation-for-dynamic-and-extreme.html"},{"id":"2512.00927v1","title":"LAHNet: Local Attentive Hashing Network for Point Cloud Registration","headline":"LAHNet：面向点云配准的局部注意力哈希网络，提升特征区分性。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200927v1-lahnet-local-attentive-hashing-network-for-point-cloud-registration.html"},{"id":"2512.00883v1","title":"Audio-Visual World Models: Towards Multisensory Imagination in Sight and Sound","headline":"提出AVWM框架，利用视听信息进行环境建模，提升智能体导航性能","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200883v1-audio-visual-world-models-towards-multisensory-imagination-in-sight-.html"},{"id":"2512.00691v1","title":"Silhouette-based Gait Foundation Model","headline":"提出FoundationGait，首个可扩展的步态自监督预训练框架，提升多种步态任务性能。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200691v1-silhouette-based-gait-foundation-model.html"},{"id":"2512.00677v1","title":"Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer","headline":"Dynamic-eDiTor：基于多模态扩散Transformer的免训练文本驱动4D场景编辑","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200677v1-dynamic-editor-training-free-text-driven-4d-scene-editing-with-multi.html"},{"id":"2512.00995v1","title":"S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud","headline":"S2AM3D：提出可控粒度的三维点云部件分割方法","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200995v1-s2am3d-scale-controllable-part-segmentation-of-3d-point-cloud.html"},{"id":"2512.05992v2","title":"Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation","headline":"针对医学图像分割，研究对比学习中更优的数据增强策略","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251205992v2-stronger-is-not-better-better-augmentations-in-contrastive-learning-.html"},{"id":"2512.05991v2","title":"EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head","headline":"EmoDiffTalk：提出情感感知扩散模型，用于可编辑的3D高斯说话头生成。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251205991v2-emodifftalkemotion-aware-diffusion-for-editable-3d-gaussian-talking-.html"},{"id":"2512.00832v1","title":"PanFlow: Decoupled Motion Control for Panoramic Video Generation","headline":"PanFlow：解耦运动控制的全景视频生成方法","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200832v1-panflow-decoupled-motion-control-for-panoramic-video-generation.html"},{"id":"2512.01094v1","title":"Accelerating Inference of Masked Image Generators via Reinforcement Learning","headline":"提出Speed-RL，通过强化学习加速掩码图像生成模型推理，显著减少采样步骤。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251201094v1-accelerating-inference-of-masked-image-generators-via-reinforcement-.html"},{"id":"2512.00885v1","title":"HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics","headline":"HanDyVQA：一个用于细粒度手-物交互动态的视频问答基准","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200885v1-handyvqa-a-video-qa-benchmark-for-fine-grained-hand-object-interacti.html"},{"id":"2512.00944v1","title":"Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation","headline":"提出Binary-Gaussian，用于压缩3D高斯分割的特征表示并提升分割精度。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200944v1-binary-gaussian-compact-and-progressive-representation-for-3d-gaussi.html"},{"id":"2512.00796v1","title":"CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target","headline":"CircleFlow：利用圆形网格靶标和光流引导的相机模糊估计","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200796v1-circleflow-flow-guided-camera-blur-estimation-using-a-circle-grid-ta.html"},{"id":"2512.01148v1","title":"SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models","headline":"提出SocialFusion框架，解决预训练视觉-语言模型中的社会认知退化问题","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251201148v1-socialfusion-addressing-social-degradation-in-pre-trained-vision-lan.html"},{"id":"2512.01128v1","title":"OmniFD: A Unified Model for Versatile Face Forgery Detection","headline":"OmniFD：用于多功能人脸伪造检测的统一模型，提升效率和泛化性","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251201128v1-omnifd-a-unified-model-for-versatile-face-forgery-detection.html"},{"id":"2512.01103v1","title":"Learning Eigenstructures of Unstructured Data Manifolds","headline":"提出一种直接从非结构化数据学习谱基的框架，用于形状和流形分析。","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251201103v1-learning-eigenstructures-of-unstructured-data-manifolds.html"},{"id":"2512.00752v1","title":"Charts Are Not Images: On the Challenges of Scientific Chart Editing","headline":"提出FigEdit基准，揭示现有生成模型在科学图表编辑中的结构化转换能力不足","tag":"cs.CV","date":"2025-11-30","url":"cs-CV/2025-11-30/papers/251200752v1-charts-are-not-images-on-the-challenges-of-scientific-chart-editing.html"},{"id":"2512.00915v1","title":"Partially Equivariant Reinforcement Learning in Symmetry-Breaking Environments","headline":"提出部分等变强化学习，解决对称破缺环境下的泛化问题","tag":"cs.LG","date":"2025-11-30","url":"cs-LG/2025-11-30/papers/251200915v1-partially-equivariant-reinforcement-learning-in-symmetry-breaking-en.html"},{"id":"2512.00783v2","title":"Sigma: The Key for Vision-Language-Action Models toward Telepathic Alignment","headline":"Sigma：面向心电感应对齐的视觉-语言-动作模型，解决人型机器人认知系统语义鸿沟","tag":"cs.LG","date":"2025-11-30","url":"cs-LG/2025-11-30/papers/251200783v2-sigma-the-key-for-vision-language-action-models-toward-telepathic-al.html"},{"id":"2512.00736v1","title":"REM: Evaluating LLM Embodied Spatial Reasoning through Multi-Frame Trajectories","headline":"REM：通过多帧轨迹评估LLM具身空间推理能力","tag":"cs.LG","date":"2025-11-30","url":"cs-LG/2025-11-30/papers/251200736v1-rem-evaluating-llm-embodied-spatial-reasoning-through-multi-frame-tr.html"},{"id":"2512.00324v1","title":"MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation","headline":"MILE：一种机械同构外骨骼数据采集系统，配备指尖视觉触觉传感，用于灵巧操作","tag":"cs.RO","date":"2025-11-29","url":"cs-RO/2025-11-29/papers/251200324v1-mile-a-mechanically-isomorphic-exoskeleton-data-collection-system-wi.html"},{"id":"2512.00375v1","title":"DPNet: Doppler LiDAR Motion Planning for Highly-Dynamic Environments","headline":"提出DPNet，利用多普勒激光雷达进行高动态环境下的运动规划。","tag":"cs.RO","date":"2025-11-29","url":"cs-RO/2025-11-29/papers/251200375v1-dpnet-doppler-lidar-motion-planning-for-highly-dynamic-environments.html"},{"id":"2512.00592v1","title":"HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks","headline":"提出HAVEN：一种利用深度Transformer Q网络的分层对抗感知导航方法，提升部分可观测环境下的安全性。","tag":"cs.RO","date":"2025-11-29","url":"cs-RO/2025-11-29/papers/251200592v1-haven-hierarchical-adversary-aware-visibility-enabled-navigation-wit.html"},{"id":"2512.00453v1","title":"Sample-Efficient Expert Query Control in Active Imitation Learning via Conformal Prediction","headline":"提出CRSAIL，通过保角预测提升主动模仿学习的样本效率，显著降低专家查询次数。","tag":"cs.RO","date":"2025-11-29","url":"cs-RO/2025-11-29/papers/251200453v1-sample-efficient-expert-query-control-in-active-imitation-learning-v.html"},{"id":"2512.00427v1","title":"Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control","headline":"提出基于光子脉冲神经网络的硬件-软件协同计算架构，用于机器人连续控制。","tag":"cs.RO","date":"2025-11-29","url":"cs-RO/2025-11-29/papers/251200427v1-hardware-software-collaborative-computing-of-photonic-spiking-reinfo.html"},{"id":"2512.00547v1","title":"Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions","headline":"提出基于资产驱动的动态场景语义重建方法，解决多人-多物交互下的三维重建难题","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200547v1-asset-driven-sematic-reconstruction-of-dynamic-scene-with-multi-huma.html"},{"id":"2512.00534v1","title":"Cross-Temporal 3D Gaussian Splatting for Sparse-View Guided Scene Update","headline":"提出Cross-Temporal 3DGS，利用稀疏视图实现跨时序场景更新与重建","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200534v1-cross-temporal-3d-gaussian-splatting-for-sparse-view-guided-scene-up.html"},{"id":"2512.00413v1","title":"SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control","headline":"提出SplatFont3D框架，实现结构感知和部件级风格控制的3D艺术字体生成。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200413v1-splatfont3d-structure-aware-text-to-3d-artistic-font-generation-with.html"},{"id":"2512.00532v1","title":"Image Generation as a Visual Planner for Robotic Manipulation","headline":"提出基于图像生成的机器人操作视觉规划方法，无需大量特定领域数据。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200532v1-image-generation-as-a-visual-planner-for-robotic-manipulation.html"},{"id":"2512.00368v2","title":"THCRL: Trusted Hierarchical Contrastive Representation Learning for Multi-View Clustering","headline":"提出THCRL，解决多视图聚类中不可信融合问题，提升聚类性能。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200368v2-thcrl-trusted-hierarchical-contrastive-representation-learning-for-m.html"},{"id":"2512.00647v2","title":"MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba","headline":"MambaScope：用于高效Vision Mamba的粗到细自适应推理框架","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200647v2-mambascope-coarse-to-fine-scoping-for-efficient-vision-mamba.html"},{"id":"2512.00355v1","title":"SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction","headline":"提出SMamDiff，一种基于空间Mamba的单阶段扩散模型，用于随机人体运动预测。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200355v1-smamdiff-spatial-mamba-for-stochastic-human-motion-prediction.html"},{"id":"2512.00327v1","title":"Odometry Without Correspondence from Inertially Constrained Ruled Surfaces","headline":"提出一种基于惯性约束ruled surface的无对应点视觉里程计方法","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200327v1-odometry-without-correspondence-from-inertially-constrained-ruled-su.html"},{"id":"2512.00582v1","title":"SatireDecoder: Visual Cascaded Decoupling for Enhancing Satirical Image Comprehension","headline":"提出SatireDecoder，通过视觉级联解耦增强讽刺图像理解能力","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200582v1-satiredecoder-visual-cascaded-decoupling-for-enhancing-satirical-ima.html"},{"id":"2512.00565v1","title":"Describe Anything Anywhere At Any Moment","headline":"提出DAAAM框架，实现大规模场景下任意时空位置的实时语义描述与推理。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200565v1-describe-anything-anywhere-at-any-moment.html"},{"id":"2512.00493v1","title":"CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration","headline":"CC-FMO：利用基础模型编排，实现相机条件下的单图零样本3D场景生成","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200493v1-cc-fmo-camera-conditioned-zero-shot-single-image-to-3d-scene-generat.html"},{"id":"2512.00425v1","title":"What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards","headline":"提出NewtonRewards，通过可验证奖励后训练视频生成模型，提升物理真实性。","tag":"cs.CV","date":"2025-11-29","url":"cs-CV/2025-11-29/papers/251200425v1-what-about-gravity-in-video-generation-post-training-newtons-laws-wi.html"},{"id":"2512.00396v2","title":"Time-Series at the Edge: Tiny Separable CNNs for Wearable Gait Detection and Optimal Sensor Placement","headline":"针对可穿戴设备，提出超轻量级可分离卷积神经网络用于帕金森病步态检测和优化传感器位置。","tag":"cs.LG","date":"2025-11-29","url":"cs-LG/2025-11-29/papers/251200396v2-time-series-at-the-edge-tiny-separable-cnns-for-wearable-gait-detect.html"},{"id":"2511.22860v1","title":"MARVO: Marine-Adaptive Radiance-aware Visual Odometry","headline":"MARVO：一种水下环境自适应的、辐射感知的视觉里程计","tag":"cs.RO","date":"2025-11-28","url":"cs-RO/2025-11-28/papers/251122860v1-marvo-marine-adaptive-radiance-aware-visual-odometry.html"},{"id":"2511.22829v1","title":"Safe Autonomous Lane Changing: Planning with Dynamic Risk Fields and Time-Varying Convex Space Generation","headline":"提出动态风险场与时变凸空间生成方法，实现安全自主的变道轨迹规划","tag":"cs.RO","date":"2025-11-28","url":"cs-RO/2025-11-28/papers/251122829v1-safe-autonomous-lane-changing-planning-with-dynamic-risk-fields-and-.html"},{"id":"2511.22857v1","title":"GLOW: Global Illumination-Aware Inverse Rendering of Indoor Scenes Captured with Dynamic Co-Located Light & Camera","headline":"GLOW：全局光照感知的动态共位光相机室内场景逆渲染","tag":"cs.CV","date":"2025-11-28","url":"cs-CV/2025-11-28/papers/251122857v1-glow-global-illumination-aware-inverse-rendering-of-indoor-scenes-ca.html"},{"id":"2512.08952v1","title":"Learning When to Ask: Simulation-Trained Humanoids for Mental-Health Diagnosis","headline":"提出基于模拟训练的人形机器人心理健康诊断方法，提升对话效率与诊断准确性。","tag":"cs.LG","date":"2025-11-28","url":"cs-LG/2025-11-28/papers/251208952v1-learning-when-to-ask-simulation-trained-humanoids-for-mental-health-.html"},{"id":"2511.22744v1","title":"Beyond Egocentric Limits: Multi-View Depth-Based Learning for Robust Quadrupedal Locomotion","headline":"提出基于多视角深度信息的四足机器人运动学习框架，提升鲁棒性。","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122744v1-beyond-egocentric-limits-multi-view-depth-based-learning-for-robust-.html"},{"id":"2511.22100v1","title":"Design of an Adaptive Modular Anthropomorphic Dexterous Hand for Human-like Manipulation","headline":"提出一种自适应模块化拟人灵巧手，用于类人操作","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122100v1-design-of-an-adaptive-modular-anthropomorphic-dexterous-hand-for-hum.html"},{"id":"2511.22364v1","title":"BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands","headline":"BINDER：基于开放词汇命令的即时自适应移动操作框架","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122364v1-binder-instantly-adaptive-mobile-manipulation-with-open-vocabulary-c.html"},{"id":"2511.22338v1","title":"Nonholonomic Narrow Dead-End Escape with Deep Reinforcement Learning","headline":"提出深度强化学习方法以解决非完整约束下的狭窄死胡同逃逸问题","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122338v1-nonholonomic-narrow-dead-end-escape-with-deep-reinforcement-learning.html"},{"id":"2511.22777v1","title":"Improving Robotic Manipulation Robustness via NICE Scene Surgery","headline":"NICE场景手术：利用自然图像修复增强机器人操作的鲁棒性","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122777v1-improving-robotic-manipulation-robustness-via-nice-scene-surgery.html"},{"id":"2511.22505v2","title":"RealD$^2$iff: Bridging Real-World Gap in Robot Manipulation via Depth Diffusion","headline":"RealD$^2$iff：通过深度扩散弥合机器人操作中的真实世界差距","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122505v2-reald2iff-bridging-real-world-gap-in-robot-manipulation-via-depth-di.html"},{"id":"2511.22773v1","title":"CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance","headline":"CAPE：基于近端模式扩展的上下文感知扩散策略，用于机器人避障","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122773v1-cape-context-aware-diffusion-policy-via-proximal-mode-expansion-for-.html"},{"id":"2511.22445v1","title":"Visual-Geometry Diffusion Policy: Robust Generalization via Complementarity-Aware Multimodal Fusion","headline":"提出Visual-Geometry Diffusion Policy，通过互补感知的多模态融合提升模仿学习泛化性。","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122445v1-visual-geometry-diffusion-policy-robust-generalization-via-complemen.html"},{"id":"2511.22195v1","title":"3D Affordance Keypoint Detection for Robotic Manipulation","headline":"提出基于3D关键点的FAKP-Net，用于机器人操作中的可供性理解","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122195v1-3d-affordance-keypoint-detection-for-robotic-manipulation.html"},{"id":"2511.22685v1","title":"Deadlock-Free Hybrid RL-MAPF Framework for Zero-Shot Multi-Robot Navigation","headline":"提出一种混合RL-MAPF框架，用于零样本多机器人无死锁导航","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122685v1-deadlock-free-hybrid-rl-mapf-framework-for-zero-shot-multi-robot-nav.html"},{"id":"2511.22780v1","title":"Distracted Robot: How Visual Clutter Undermine Robotic Manipulation","headline":"提出基于心理物理学的评估协议，研究视觉杂乱对机器人操作的影响","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122780v1-distracted-robot-how-visual-clutter-undermine-robotic-manipulation.html"},{"id":"2511.22555v1","title":"Beyond Success: Refining Elegant Robot Manipulation from Mixed-Quality Data via Just-in-Time Intervention","headline":"LIBERO-Elegant：通过即时干预，从混合质量数据中提升机器人操作的优雅性","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122555v1-beyond-success-refining-elegant-robot-manipulation-from-mixed-qualit.html"},{"id":"2511.22467v1","title":"Motion-to-Motion Latency Measurement Framework for Connected and Autonomous Vehicle Teleoperation","headline":"提出一种用于车联网自动驾驶远程操控的运动到运动延迟测量框架","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122467v1-motion-to-motion-latency-measurement-framework-for-connected-and-aut.html"},{"id":"2511.22238v1","title":"MLATC: Fast Hierarchical Topological Mapping from 3D LiDAR Point Clouds Based on Adaptive Resonance Theory","headline":"提出MLATC，加速三维激光雷达点云的快速分层拓扑地图构建","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122238v1-mlatc-fast-hierarchical-topological-mapping-from-3d-lidar-point-clou.html"},{"id":"2511.22043v1","title":"SwordRiding: A Unified Navigation Framework for Quadrotors in Unknown Complex Environments via Online Guiding Vector Fields","headline":"提出基于在线引导向量场的四旋翼无人机未知复杂环境统一导航框架","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122043v1-swordriding-a-unified-navigation-framework-for-quadrotors-in-unknown.html"},{"id":"2511.22087v1","title":"SoftNash: Entropy-Regularized Nash Games for Non-Fighting Virtual Fixtures","headline":"提出SoftNash，通过熵正则化纳什博弈实现非对抗性虚约束器，提升遥操作舒适度。","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122087v1-softnash-entropy-regularized-nash-games-for-non-fighting-virtual-fix.html"},{"id":"2511.22042v1","title":"Constant-Volume Deformation Manufacturing for Material-Efficient Shaping","headline":"提出体积守恒的数字模具范式，实现材料高效的恒定体积变形制造","tag":"cs.RO","date":"2025-11-27","url":"cs-RO/2025-11-27/papers/251122042v1-constant-volume-deformation-manufacturing-for-material-efficient-sha.html"},{"id":"2511.22233v1","title":"IE-SRGS: An Internal-External Knowledge Fusion Framework for High-Fidelity 3D Gaussian Splatting Super-Resolution","headline":"提出IE-SRGS框架，融合内外知识提升3D高斯溅射超分辨率重建质量","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122233v1-ie-srgs-an-internal-external-knowledge-fusion-framework-for-high-fid.html"},{"id":"2511.22167v1","title":"IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer","headline":"IMTalker：利用隐式运动传递实现高效的音频驱动说话人脸生成","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122167v1-imtalker-efficient-audio-driven-talking-face-generation-with-implici.html"},{"id":"2511.22262v1","title":"Can Protective Watermarking Safeguard the Copyright of 3D Gaussian Splatting?","headline":"提出GSPure框架，针对3D高斯溅射的水印进行有效去除，同时保持场景完整性。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122262v1-can-protective-watermarking-safeguard-the-copyright-of-3d-gaussian-s.html"},{"id":"2511.22147v1","title":"RemedyGS: Defend 3D Gaussian Splatting against Computation Cost Attacks","headline":"提出RemedyGS框架，防御针对3D高斯溅射的计算成本攻击","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122147v1-remedygs-defend-3d-gaussian-splatting-against-computation-cost-attac.html"},{"id":"2511.22609v1","title":"MG-Nav: Dual-Scale Visual Navigation via Sparse Spatial Memory","headline":"提出MG-Nav以解决零-shot视觉导航中的规划与控制问题","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122609v1-mg-nav-dual-scale-visual-navigation-via-sparse-spatial-memory.html"},{"id":"2511.22704v1","title":"Splat-SAP: Feed-Forward Gaussian Splatting for Human-Centered Scene with Scale-Aware Point Map Reconstruction","headline":"Splat-SAP：面向以人为中心的稀疏场景，提出基于尺度感知点图重建的前馈高斯溅射方法","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122704v1-splat-sap-feed-forward-gaussian-splatting-for-human-centered-scene-w.html"},{"id":"2511.22039v1","title":"SparseWorld-TC: Trajectory-Conditioned Sparse Occupancy World Model","headline":"提出轨迹条件下的稀疏Occupancy World Model，用于未来3D场景Occupancy预测。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122039v1-sparseworld-tc-trajectory-conditioned-sparse-occupancy-world-model.html"},{"id":"2511.22466v1","title":"RoadSceneBench: A Lightweight Benchmark for Mid-Level Road Scene Understanding","headline":"RoadSceneBench：轻量级道路场景理解基准，提升视觉推理能力。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122466v1-roadscenebench-a-lightweight-benchmark-for-mid-level-road-scene-unde.html"},{"id":"2511.22102v1","title":"MRI-Based Brain Age Estimation with Supervised Contrastive Learning of Continuous Representation","headline":"提出基于监督对比学习的MRI脑年龄估计方法，提升神经形态学变化建模精度。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122102v1-mri-based-brain-age-estimation-with-supervised-contrastive-learning-.html"},{"id":"2511.22521v1","title":"DocVAL: Validated Chain-of-Thought Distillation for Grounded Document VQA","headline":"提出DocVAL：一种经验证的思维链蒸馏框架，用于提升文档VQA的空间推理能力。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122521v1-docval-validated-chain-of-thought-distillation-for-grounded-document.html"},{"id":"2511.22459v1","title":"Gaussians on Fire: High-Frequency Reconstruction of Flames","headline":"提出基于高斯分布的时空表示方法，用于从有限视角重建火焰高频动态。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122459v1-gaussians-on-fire-high-frequency-reconstruction-of-flames.html"},{"id":"2511.22172v1","title":"Guiding the Inner Eye: A Framework for Hierarchical and Flexible Visual Grounded Reasoning","headline":"提出GRiP框架，通过认知引导强化学习提升视觉基础推理的鲁棒性和灵活性","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122172v1-guiding-the-inner-eye-a-framework-for-hierarchical-and-flexible-visu.html"},{"id":"2511.22533v1","title":"Fast3Dcache: Training-free 3D Geometry Synthesis Acceleration","headline":"Fast3Dcache：一种无训练的几何感知缓存框架，加速3D几何体合成。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122533v1-fast3dcache-training-free-3d-geometry-synthesis-acceleration.html"},{"id":"2511.22411v1","title":"DiffStyle360: Diffusion-Based 360° Head Stylization via Style Fusion Attention","headline":"DiffStyle360：提出基于扩散模型的360°头部风格化方法，实现多视角一致的风格迁移。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122411v1-diffstyle360-diffusion-based-360-head-stylization-via-style-fusion-a.html"},{"id":"2511.22488v1","title":"AI killed the video star. Audio-driven diffusion model for expressive talking head generation","headline":"提出Dimitra++：一种音频驱动的扩散模型，用于生成富有表现力的说话人头部","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122488v1-ai-killed-the-video-star-audio-driven-diffusion-model-for-expressive.html"},{"id":"2511.22686v2","title":"Emergent Extreme-View Geometry in 3D Foundation Models","headline":"揭示3D基础模型涌现的极端视角几何能力，并提出轻量级对齐方案。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122686v2-emergent-extreme-view-geometry-in-3d-foundation-models.html"},{"id":"2511.22607v1","title":"GazeTrack: High-Precision Eye Tracking Based on Regularization and Spatial Computing","headline":"GazeTrack：基于正则化和空间计算的高精度眼动追踪","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122607v1-gazetrack-high-precision-eye-tracking-based-on-regularization-and-sp.html"},{"id":"2511.22586v1","title":"Revisiting the Necessity of Lengthy Chain-of-Thought in Vision-centric Reasoning Generalization","headline":"研究表明，在视觉推理泛化中，简洁的思维链（CoT）优于冗长的CoT。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122586v1-revisiting-the-necessity-of-lengthy-chain-of-thought-in-vision-centr.html"},{"id":"2511.22578v1","title":"Text Condition Embedded Regression Network for Automated Dental Abutment Design","headline":"提出TCEAD框架，通过文本引导的回归网络实现自动化牙种植体基台设计。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122578v1-text-condition-embedded-regression-network-for-automated-dental-abut.html"},{"id":"2512.00115v1","title":"MoLT: Mixture of Layer-Wise Tokens for Efficient Audio-Visual Learning","headline":"提出MoLT，通过混合层级Token实现高效的音视频学习。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251200115v1-molt-mixture-of-layer-wise-tokens-for-efficient-audio-visual-learnin.html"},{"id":"2511.22429v1","title":"Fin3R: Fine-tuning Feed-forward 3D Reconstruction Models via Monocular Knowledge Distillation","headline":"Fin3R：通过单目知识蒸馏微调前馈3D重建模型，提升几何精度。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122429v1-fin3r-fine-tuning-feed-forward-3d-reconstruction-models-via-monocula.html"},{"id":"2511.22330v1","title":"Prompt-based Consistent Video Colorization","headline":"提出基于提示词的视频一致性着色方法，解决时序闪烁和人工干预问题。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122330v1-prompt-based-consistent-video-colorization.html"},{"id":"2511.22327v1","title":"Content Adaptive Encoding For Interactive Game Streaming","headline":"提出基于编码元数据的自适应分辨率编码方法，用于交互式游戏流媒体。","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122327v1-content-adaptive-encoding-for-interactive-game-streaming.html"},{"id":"2511.22171v1","title":"BrepGPT: Autoregressive B-rep Generation with Voronoi Half-Patch","headline":"BrepGPT：基于Voronoi Half-Patch的单阶段自回归B-rep生成框架","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122171v1-brepgpt-autoregressive-b-rep-generation-with-voronoi-half-patch.html"},{"id":"2511.22134v1","title":"DualVLA: Building a Generalizable Embodied Agent via Partial Decoupling of Reasoning and Action","headline":"DualVLA：通过解耦推理与动作，构建可泛化的具身智能体","tag":"cs.CV","date":"2025-11-27","url":"cs-CV/2025-11-27/papers/251122134v1-dualvla-building-a-generalizable-embodied-agent-via-partial-decoupli.html"},{"id":"2511.22288v1","title":"Improving Sparse IMU-based Motion Capture with Motion Label Smoothing","headline":"提出基于运动标签平滑的稀疏IMU人体运动捕捉方法，提升模型泛化性。","tag":"cs.GR","date":"2025-11-27","url":"cs-GR/2025-11-27/papers/251122288v1-improving-sparse-imu-based-motion-capture-with-motion-label-smoothin.html"},{"id":"2511.22210v1","title":"BiCQL-ML: A Bi-Level Conservative Q-Learning Framework for Maximum Likelihood Inverse Reinforcement Learning","headline":"提出BiCQL-ML，通过双层保守Q学习解决离线逆强化学习中的奖励函数恢复问题","tag":"cs.LG","date":"2025-11-27","url":"cs-LG/2025-11-27/papers/251122210v1-bicql-ml-a-bi-level-conservative-q-learning-framework-for-maximum-li.html"},{"id":"2511.22810v1","title":"Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation","headline":"针对欠驱动多通道系统，提出基于事件触发切换控制的协同操作框架","tag":"eess.SY","date":"2025-11-27","url":"eess-SY/2025-11-27/papers/251122810v1-switching-control-of-underactuated-multi-channel-systems-with-input-.html"},{"id":"2511.21169v1","title":"Kinematics-Aware Multi-Policy Reinforcement Learning for Force-Capable Humanoid Loco-Manipulation","headline":"提出一种基于运动学感知的多策略强化学习方法，用于人形机器人力控操作","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121169v1-kinematics-aware-multi-policy-reinforcement-learning-for-force-capab.html"},{"id":"2511.21264v1","title":"Sampling-Based Optimization with Parallelized Physics Simulator for Bimanual Manipulation","headline":"提出基于并行物理模拟优化的采样方法，解决复杂双臂操作任务。","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121264v1-sampling-based-optimization-with-parallelized-physics-simulator-for-.html"},{"id":"2511.21083v1","title":"Dual-Agent Reinforcement Learning for Adaptive and Cost-Aware Visual-Inertial Odometry","headline":"提出基于双智能体强化学习的自适应、低成本视觉惯性里程计","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121083v1-dual-agent-reinforcement-learning-for-adaptive-and-cost-aware-visual.html"},{"id":"2511.21690v1","title":"TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos","headline":"TraceGen：通过3D轨迹空间的世界建模实现跨具身视频学习","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121690v1-tracegen-world-modeling-in-3d-trace-space-enables-learning-from-cros.html"},{"id":"2511.21149v1","title":"Maglev-Pentabot: Magnetic Levitation System for Non-Contact Manipulation using Deep Reinforcement Learning","headline":"Maglev-Pentabot：基于深度强化学习的磁悬浮非接触操控系统，突破微观尺度限制","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121149v1-maglev-pentabot-magnetic-levitation-system-for-non-contact-manipulat.html"},{"id":"2511.21135v1","title":"SocialNav: Training Human-Inspired Foundation Model for Socially-Aware Embodied Navigation","headline":"提出SocialNav，用于训练类人社交感知具身导航的基础模型","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121135v1-socialnav-training-human-inspired-foundation-model-for-socially-awar.html"},{"id":"2512.00085v1","title":"Hyper-GoalNet: Goal-Conditioned Manipulation Policy Learning with HyperNetworks","headline":"Hyper-GoalNet：利用超网络实现目标条件下的机器人操作策略学习","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251200085v1-hyper-goalnet-goal-conditioned-manipulation-policy-learning-with-hyp.html"},{"id":"2511.21666v1","title":"Uncertainty Quantification for Visual Object Pose Estimation","headline":"提出SLUE算法，用于单目视觉物体姿态估计的无分布不确定性量化。","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121666v1-uncertainty-quantification-for-visual-object-pose-estimation.html"},{"id":"2511.21557v1","title":"VacuumVLA: Boosting VLA Capabilities via a Unified Suction and Gripping Tool for Complex Robotic Manipulation","headline":"VacuumVLA：通过集成吸取与夹持工具，增强VLA模型在复杂机器人操作中的能力","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121557v1-vacuumvla-boosting-vla-capabilities-via-a-unified-suction-and-grippi.html"},{"id":"2511.21203v2","title":"Transformer Driven Visual Servoing and Dual Arm Impedance Control for Fabric Texture Matching","headline":"提出基于Transformer的视觉伺服与双臂阻抗控制方法，用于织物纹理精确对齐与放置。","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121203v2-transformer-driven-visual-servoing-and-dual-arm-impedance-control-fo.html"},{"id":"2511.21161v1","title":"MarketGen: A Scalable Simulation Platform with Auto-Generated Embodied Supermarket Environments","headline":"MarketGen：一个可扩展的具身智能超市环境自动生成仿真平台","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121161v1-marketgen-a-scalable-simulation-platform-with-auto-generated-embodie.html"},{"id":"2511.21312v1","title":"Neural NMPC through Signed Distance Field Encoding for Collision Avoidance","headline":"提出神经网络非线性模型预测控制以解决无人机避障问题","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121312v1-neural-nmpc-through-signed-distance-field-encoding-for-collision-avo.html"},{"id":"2511.21542v1","title":"$\\mathcal{E}_0$: Enhancing Generalization and Fine-Grained Control in VLA Models via Continuized Discrete Diffusion","headline":"提出E0框架，通过连续离散扩散提升VLA模型在机器人操作中的泛化性和精细控制能力","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121542v1-mathcale-0-enhancing-generalization-and-fine-grained-control-in-vla-.html"},{"id":"2511.21189v1","title":"Dual Preintegration for Relative State Estimation","headline":"提出双重预积分方法，提升相对状态估计在剧烈旋转下的精度和鲁棒性，尤其适用于VR场景。","tag":"cs.RO","date":"2025-11-26","url":"cs-RO/2025-11-26/papers/251121189v1-dual-preintegration-for-relative-state-estimation.html"},{"id":"2512.00086v1","title":"Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs","headline":"提出一种多模态片上学习方法，用于超低功耗MCU上的单目深度估计。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251200086v1-multi-modal-on-device-learning-for-monocular-depth-estimation-on-ult.html"},{"id":"2511.21265v1","title":"Unlocking Zero-shot Potential of Semi-dense Image Matching via Gaussian Splatting","headline":"MatchGS：利用高斯溅射解锁半稠密图像匹配的零样本潜力","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121265v1-unlocking-zero-shot-potential-of-semi-dense-image-matching-via-gauss.html"},{"id":"2511.21105v1","title":"Scaling Foundation Models for Radar Scene Understanding","headline":"提出RadarFM雷达基础模型，通过结构化空间语言监督实现场景理解。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121105v1-scaling-foundation-models-for-radar-scene-understanding.html"},{"id":"2511.21365v1","title":"PFF-Net: Patch Feature Fitting for Point Cloud Normal Estimation","headline":"提出PFF-Net，通过多尺度patch特征拟合实现鲁棒的点云法向量估计。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121365v1-pff-net-patch-feature-fitting-for-point-cloud-normal-estimation.html"},{"id":"2511.21317v1","title":"HTTM: Head-wise Temporal Token Merging for Faster VGGT","headline":"提出头部分时序Token合并(HTTM)加速VGGT，用于快速3D场景重建","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121317v1-httm-head-wise-temporal-token-merging-for-faster-vggt.html"},{"id":"2511.21237v2","title":"3-Tracer: A Tri-level Temporal-Aware Framework for Audio Forgery Detection and Localization","headline":"提出T3-Tracer，用于音频篡改检测与定位，实现帧、段、音频三层时序分析。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121237v2-3-tracer-a-tri-level-temporal-aware-framework-for-audio-forgery-dete.html"},{"id":"2511.21574v1","title":"Multimodal Robust Prompt Distillation for 3D Point Cloud Models","headline":"提出多模态鲁棒Prompt蒸馏框架，提升3D点云模型在对抗攻击下的鲁棒性。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121574v1-multimodal-robust-prompt-distillation-for-3d-point-cloud-models.html"},{"id":"2511.20983v1","title":"Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI","headline":"提出基于同态加密的联邦Vision Transformer学习框架，保护医疗AI中的患者隐私。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251120983v1-privacy-preserving-federated-vision-transformer-learning-leveraging-.html"},{"id":"2511.21902v1","title":"PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images","headline":"PathReasoning：一种用于全切片图像上基于查询的ROI导航的多模态推理Agent","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121902v1-pathreasoning-a-multimodal-reasoning-agent-for-query-based-roi-navig.html"},{"id":"2511.21490v1","title":"Merge and Bound: Direct Manipulations on Weights for Class Incremental Learning","headline":"提出Merge-and-Bound方法，通过权重空间操作解决类增量学习中的灾难性遗忘问题","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121490v1-merge-and-bound-direct-manipulations-on-weights-for-class-incrementa.html"},{"id":"2511.21339v1","title":"SurgMLLMBench: A Multimodal Large Language Model Benchmark Dataset for Surgical Scene Understanding","headline":"SurgMLLMBench：用于手术场景理解的多模态大语言模型基准数据集","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121339v1-surgmllmbench-a-multimodal-large-language-model-benchmark-dataset-fo.html"},{"id":"2511.21298v1","title":"PathMamba: A Hybrid Mamba-Transformer for Topologically Coherent Road Segmentation in Satellite Imagery","headline":"提出PathMamba，用于卫星图像中拓扑连续的道路分割","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121298v1-pathmamba-a-hybrid-mamba-transformer-for-topologically-coherent-road.html"},{"id":"2511.21194v1","title":"BotaCLIP: Contrastive Learning for Botany-Aware Representation of Earth Observation Data","headline":"BotaCLIP：通过对比学习实现地球观测数据的植物学感知表征","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121194v1-botaclip-contrastive-learning-for-botany-aware-representation-of-ear.html"},{"id":"2511.21097v1","title":"CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition","headline":"提出CLRecogEye，利用卷积特征和课程学习提升动态虹膜识别的鲁棒性。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121097v1-clrecogeye-curriculum-learning-towards-exploiting-convolution-featur.html"},{"id":"2511.21367v1","title":"Endo-G$^{2}$T: Geometry-Guided & Temporally Aware Time-Embedded 4DGS For Endoscopic Scenes","headline":"Endo-G²T：针对内窥镜场景，提出几何引导和时序感知的时序嵌入4D高斯溅射方法","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121367v1-endo-g2t-geometry-guided-temporally-aware-time-embedded-4dgs-for-end.html"},{"id":"2511.21192v2","title":"When Robots Obey the Patch: Universal Transferable Patch Attacks on Vision-Language-Action Models","headline":"提出UPA-RFAS以解决VLA模型的通用可转移攻击问题","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121192v2-when-robots-obey-the-patch-universal-transferable-patch-attacks-on-v.html"},{"id":"2511.21191v1","title":"Scenes as Tokens: Multi-Scale Normal Distributions Transform Tokenizer for General 3D Vision-Language Understanding","headline":"提出NDTokenizer3D，用于通用3D视觉-语言理解的多尺度NDT Tokenizer","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121191v1-scenes-as-tokens-multi-scale-normal-distributions-transform-tokenize.html"},{"id":"2511.21113v1","title":"FaithFusion: Harmonizing Reconstruction and Generation via Pixel-wise Information Gain","headline":"FaithFusion：提出基于像素级信息增益的3DGS-扩散融合框架，解决可控驾驶场景重建与生成问题。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121113v1-faithfusion-harmonizing-reconstruction-and-generation-via-pixel-wise.html"},{"id":"2511.21029v1","title":"FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation","headline":"FlowerDance：结合MeanFlow的高效精细3D舞蹈生成方法","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121029v1-flowerdance-meanflow-for-efficient-and-refined-3d-dance-generation.html"},{"id":"2511.21681v1","title":"Seeing without Pixels: Perception from Camera Trajectories","headline":"仅凭相机轨迹感知视频内容：提出CamFormer对比学习框架","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121681v1-seeing-without-pixels-perception-from-camera-trajectories.html"},{"id":"2511.21422v1","title":"E-M3RF: An Equivariant Multimodal 3D Re-assembly Framework","headline":"提出E-M3RF，一种用于多模态3D重组的等变框架，提升几何重建精度。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121422v1-e-m3rf-an-equivariant-multimodal-3d-re-assembly-framework.html"},{"id":"2511.21098v1","title":"Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction","headline":"提出基于图像到黏土转换的Pygmalion效应，用于反射几何体重建","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121098v1-pygmalion-effect-in-vision-image-to-clay-translation-for-reflective-.html"},{"id":"2511.21579v2","title":"Harmony: Harmonizing Audio and Video Generation through Cross-Task Synergy","headline":"Harmony：通过跨任务协同实现音视频生成和谐统一","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121579v2-harmony-harmonizing-audio-and-video-generation-through-cross-task-sy.html"},{"id":"2511.21428v1","title":"From Observation to Action: Latent Action-based Primitive Segmentation for VLA Pre-training in Industrial Settings","headline":"提出基于隐式动作原语分割的VLA预训练方法，用于工业场景","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121428v1-from-observation-to-action-latent-action-based-primitive-segmentatio.html"},{"id":"2511.21051v1","title":"MUSE: Manipulating Unified Framework for Synthesizing Emotions in Images via Test-Time Optimization","headline":"MUSE：提出统一框架，通过测试时优化实现图像情感的生成与编辑","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121051v1-muse-manipulating-unified-framework-for-synthesizing-emotions-in-ima.html"},{"id":"2511.21978v1","title":"PAT3D: Physics-Augmented Text-to-3D Scene Generation","headline":"PAT3D：首个物理增强的文本到3D场景生成框架，实现逼真、可交互的场景创建。","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121978v1-pat3d-physics-augmented-text-to-3d-scene-generation.html"},{"id":"2511.21945v1","title":"AmodalGen3D: Generative Amodal 3D Object Reconstruction from Sparse Unposed Views","headline":"提出AmodalGen3D以解决稀疏视角下的3D物体重建问题","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121945v1-amodalgen3d-generative-amodal-3d-object-reconstruction-from-sparse-u.html"},{"id":"2511.21592v1","title":"MoGAN: Improving Motion Quality in Video Diffusion via Few-Step Motion Adversarial Post-Training","headline":"MoGAN：通过少量步数的运动对抗后训练提升视频扩散模型的运动质量","tag":"cs.CV","date":"2025-11-26","url":"cs-CV/2025-11-26/papers/251121592v1-mogan-improving-motion-quality-in-video-diffusion-via-few-step-motio.html"},{"id":"2511.21459v1","title":"Resolution Where It Counts: Hash-based GPU-Accelerated 3D Reconstruction via Variance-Adaptive Voxel Grids","headline":"提出基于方差自适应体素栅格的GPU加速哈希3D重建方法","tag":"cs.GR","date":"2025-11-26","url":"cs-GR/2025-11-26/papers/251121459v1-resolution-where-it-counts-hash-based-gpu-accelerated-3d-reconstruct.html"},{"id":"2511.21848v1","title":"Massively Parallel Imitation Learning of Mouse Forelimb Musculoskeletal Reaching Dynamics","headline":"提出基于大规模并行模仿学习的小鼠前肢肌肉骨骼运动动力学建模方法","tag":"cs.LG","date":"2025-11-26","url":"cs-LG/2025-11-26/papers/251121848v1-massively-parallel-imitation-learning-of-mouse-forelimb-musculoskele.html"},{"id":"2511.21531v1","title":"Predictive Safety Shield for Dyna-Q Reinforcement Learning","headline":"提出基于预测的安全盾，提升Dyna-Q强化学习在离散空间的安全性和性能","tag":"cs.LG","date":"2025-11-26","url":"cs-LG/2025-11-26/papers/251121531v1-predictive-safety-shield-for-dyna-q-reinforcement-learning.html"},{"id":"2512.00077v1","title":"A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs","headline":"提出一种分层控制框架，提升超冗余肢人形机器人运动稳定性","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251200077v1-a-hierarchical-framework-for-humanoid-locomotion-with-supernumerary-.html"},{"id":"2511.20275v3","title":"HAFO: A Force-Adaptive Control Framework for Humanoid Robots in Intense Interaction Environments","headline":"提出HAFO框架以解决人形机器人在强交互环境中的运动控制问题","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120275v3-hafo-a-force-adaptive-control-framework-for-humanoid-robots-in-inten.html"},{"id":"2511.20887v1","title":"ACE-F: A Cross Embodiment Foldable System with Force Feedback for Dexterous Teleoperation","headline":"ACE-F：一种具有力反馈的跨具身可折叠遥操作系统","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120887v1-ace-f-a-cross-embodiment-foldable-system-with-force-feedback-for-dex.html"},{"id":"2511.20841v1","title":"OVAL-Grasp: Open-Vocabulary Affordance Localization for Task Oriented Grasping","headline":"OVAL-Grasp：面向任务的开放词汇抓取方法，提升机器人操作灵活性。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120841v1-oval-grasp-open-vocabulary-affordance-localization-for-task-oriented.html"},{"id":"2511.20894v1","title":"Efficient Greedy Algorithms for Feature Selection in Robot Visual Localization","headline":"提出高效贪婪算法，加速机器人视觉定位中的特征选择","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120894v1-efficient-greedy-algorithms-for-feature-selection-in-robot-visual-lo.html"},{"id":"2512.00076v1","title":"Arcadia: Toward a Full-Lifecycle Framework for Embodied Lifelong Learning","headline":"Arcadia：面向具身终身学习的全生命周期框架，提升导航与操作能力。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251200076v1-arcadia-toward-a-full-lifecycle-framework-for-embodied-lifelong-lear.html"},{"id":"2511.20593v1","title":"Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning","headline":"提出S$^2$-NNDS，学习安全稳定机器人运动，解决复杂动态环境下的运动规划问题。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120593v1-safe-and-stable-neural-network-dynamical-systems-for-robot-motion-pl.html"},{"id":"2511.20330v2","title":"ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation","headline":"提出ArtiBench和ArtiBrain，用于评估和提升通用视觉语言可动对象操作能力。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120330v2-artibench-and-artibrain-benchmarking-generalizable-vision-language-a.html"},{"id":"2511.19955v2","title":"ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation","headline":"ShapeForce：低成本软体机器人腕部，用于接触丰富的操作任务","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251119955v2-shapeforce-low-cost-soft-robotic-wrist-for-contact-rich-manipulation.html"},{"id":"2512.00074v2","title":"Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning","headline":"AFRO：用于可扩展机器人学习的动态感知3D视觉表征自监督框架","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251200074v2-bootstrap-dynamic-aware-3d-visual-representation-for-scalable-robot-.html"},{"id":"2511.20496v1","title":"Metric, inertially aligned monocular state estimation via kinetodynamic priors","headline":"提出基于运动动力学先验的单目惯性对齐状态估计方法，解决非刚性机器人平台的位姿估计问题","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120496v1-metric-inertially-aligned-monocular-state-estimation-via-kinetodynam.html"},{"id":"2511.20180v1","title":"Hibikino-Musashi@Home 2025 Team Description Paper","headline":"Hibikino-Musashi@Home 2025：面向家庭服务的机器人系统开发与个性化适应研究","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120180v1-hibikino-musashihome-2025-team-description-paper.html"},{"id":"2511.19859v1","title":"Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation","headline":"提出VITA框架，通过隐式视觉CoT统一感知与动作，提升机器人动作生成能力。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251119859v1-unifying-perception-and-action-a-hybrid-modality-pipeline-with-impli.html"},{"id":"2511.20906v1","title":"Dynamic Test-Time Compute Scaling in Control Policy: Difficulty-Aware Stochastic Interpolant Policy","headline":"提出DA-SIP，通过动态调整计算量，提升扩散模型和流模型在机器人控制中的效率。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120906v1-dynamic-test-time-compute-scaling-in-control-policy-difficulty-aware.html"},{"id":"2511.19932v1","title":"Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine","headline":"提出一种混合强化学习框架，结合物理引擎模拟与真实数据反馈，解决机器人装箱稳定性问题。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251119932v1-collaborate-sim-and-real-robot-bin-packing-learning-in-real-world-an.html"},{"id":"2511.20633v1","title":"Reinforcing Action Policies by Prophesying","headline":"ProphRL：通过预测进行视觉-语言-动作策略的强化学习，提升机器人控制性能。","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120633v1-reinforcing-action-policies-by-prophesying.html"},{"id":"2511.20467v1","title":"Power-Efficient Autonomous Mobile Robots","headline":"pNav：通过联合优化物理和信息子系统，提升自主移动机器人能效","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120467v1-power-efficient-autonomous-mobile-robots.html"},{"id":"2511.20394v1","title":"Improved adaptive wind driven optimization algorithm for real-time path planning","headline":"提出多层级自适应风驱动优化算法，提升动态环境下实时路径规划能力","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120394v1-improved-adaptive-wind-driven-optimization-algorithm-for-real-time-p.html"},{"id":"2511.20299v1","title":"How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks","headline":"研究机器人运动学对虚拟人机交接任务中人类表现的影响","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120299v1-how-robot-kinematics-influence-human-performance-in-virtual-robot-to.html"},{"id":"2511.20292v1","title":"Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes","headline":"提出Dynamic-ICP，解决动态场景下基于ICP的里程计配准问题","tag":"cs.RO","date":"2025-11-25","url":"cs-RO/2025-11-25/papers/251120292v1-dynamic-icp-doppler-aware-iterative-closest-point-registration-for-d.html"},{"id":"2511.20354v1","title":"GS-Checker: Tampering Localization for 3D Gaussian Splatting","headline":"GS-Checker：提出3D高斯溅射篡改定位方法，保障3D内容安全","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120354v1-gs-checker-tampering-localization-for-3d-gaussian-splatting.html"},{"id":"2511.20804v1","title":"$Δ$-NeRF: Incremental Refinement of Neural Radiance Fields through Residual Control and Knowledge Transfer","headline":"提出$Δ$-NeRF，通过残差控制和知识迁移实现神经辐射场的增量优化，适用于卫星图像等序列数据场景。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120804v1-δ-nerf-incremental-refinement-of-neural-radiance-fields-through-resi.html"},{"id":"2511.20058v1","title":"DeLightMono: Enhancing Self-Supervised Monocular Depth Estimation in Endoscopy by Decoupling Uneven Illumination","headline":"DeLightMono：通过解耦不均匀光照增强内窥镜自监督单目深度估计","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120058v1-delightmono-enhancing-self-supervised-monocular-depth-estimation-in-.html"},{"id":"2511.20278v1","title":"DAPointMamba: Domain Adaptive Point Mamba for Point Cloud Completion","headline":"DAPointMamba：面向点云补全的领域自适应Point Mamba模型","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120278v1-dapointmamba-domain-adaptive-point-mamba-for-point-cloud-completion.html"},{"id":"2511.19861v2","title":"GigaWorld-0: World Models as Data Engine to Empower Embodied AI","headline":"GigaWorld-0：构建世界模型作为数据引擎，赋能具身智能。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119861v2-gigaworld-0-world-models-as-data-engine-to-empower-embodied-ai.html"},{"id":"2511.20446v1","title":"Learning to Generate Human-Human-Object Interactions from Textual Descriptions","headline":"提出HHOI生成框架，从文本描述生成人-人-物交互场景，并构建了相关数据集。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120446v1-learning-to-generate-human-human-object-interactions-from-textual-de.html"},{"id":"2511.20359v1","title":"From Passive Perception to Active Memory: A Weakly Supervised Image Manipulation Localization Framework Driven by Coarse-Grained Annotations","headline":"提出BoxPromptIML框架，以低成本粗略标注实现图像篡改精确定位。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120359v1-from-passive-perception-to-active-memory-a-weakly-supervised-image-m.html"},{"id":"2511.20003v1","title":"Redefining Radar Segmentation: Simultaneous Static-Moving Segmentation and Ego-Motion Estimation using Radar Point Clouds","headline":"提出基于雷达点云的静态-动态分割与自运动估计同步方法","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120003v1-redefining-radar-segmentation-simultaneous-static-moving-segmentatio.html"},{"id":"2511.20646v1","title":"3D-Aware Multi-Task Learning with Cross-View Correlations for Dense Scene Understanding","headline":"提出基于跨视角相关性的3D感知多任务学习，用于密集场景理解","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120646v1-3d-aware-multi-task-learning-with-cross-view-correlations-for-dense-.html"},{"id":"2511.20041v1","title":"MFM-point: Multi-scale Flow Matching for Point Cloud Generation","headline":"MFM-Point：多尺度流匹配点云生成方法，提升点云生成质量与可扩展性。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120041v1-mfm-point-multi-scale-flow-matching-for-point-cloud-generation.html"},{"id":"2511.20348v2","title":"Material-informed Gaussian Splatting for 3D World Reconstruction in a Digital Twin","headline":"提出基于材质信息的3D高斯溅射方法，用于数字孪生中的三维世界重建","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120348v2-material-informed-gaussian-splatting-for-3d-world-reconstruction-in-.html"},{"id":"2511.20156v1","title":"Map-World: Masked Action planning and Path-Integral World Model for Autonomous Driving","headline":"提出MAP-World，结合掩码动作规划与路径积分世界模型，实现自动驾驶多模态运动规划。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120156v1-map-world-masked-action-planning-and-path-integral-world-model-for-a.html"},{"id":"2511.19971v1","title":"VGGT4D: Mining Motion Cues in Visual Geometry Transformers for 4D Scene Reconstruction","headline":"VGGT4D：挖掘视觉几何Transformer中的运动线索，用于4D场景重建","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119971v1-vggt4d-mining-motion-cues-in-visual-geometry-transformers-for-4d-sce.html"},{"id":"2511.20620v1","title":"Wanderland: Geometrically Grounded Simulation for Open-World Embodied AI","headline":"Wanderland：面向开放世界具身AI的几何校准仿真框架","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120620v1-wanderland-geometrically-grounded-simulation-for-open-world-embodied.html"},{"id":"2511.20020v1","title":"ACIT: Attention-Guided Cross-Modal Interaction Transformer for Pedestrian Crossing Intention Prediction","headline":"提出ACIT模型，利用注意力机制和跨模态交互Transformer提升行人过街意图预测精度。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120020v1-acit-attention-guided-cross-modal-interaction-transformer-for-pedest.html"},{"id":"2511.20325v1","title":"AD-R1: Closed-Loop Reinforcement Learning for End-to-End Autonomous Driving with Impartial World Models","headline":"AD-R1：基于公正世界模型的端到端自动驾驶闭环强化学习","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120325v1-ad-r1-closed-loop-reinforcement-learning-for-end-to-end-autonomous-d.html"},{"id":"2511.19909v1","title":"Motion Marionette: Rethinking Rigid Motion Transfer via Prior Guidance","headline":"提出Motion Marionette以解决刚性运动转移问题","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119909v1-motion-marionette-rethinking-rigid-motion-transfer-via-prior-guidanc.html"},{"id":"2511.20853v2","title":"MODEST: Multi-Optics Depth-of-Field Stereo Dataset","headline":"MODEST：多光圈景深立体视觉数据集，弥合真实光学与合成数据差距","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120853v2-modest-multi-optics-depth-of-field-stereo-dataset.html"},{"id":"2512.00080v1","title":"Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels","headline":"探索深度视觉立体里程计在加速器隧道辐射监测机器人中的应用","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251200080v1-conceptual-evaluation-of-deep-visual-stereo-odometry-for-the-marwin-.html"},{"id":"2511.20722v1","title":"DinoLizer: Learning from the Best for Generative Inpainting Localization","headline":"DinoLizer：利用DINOv2学习生成式图像修复篡改区域的定位","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120722v1-dinolizer-learning-from-the-best-for-generative-inpainting-localizat.html"},{"id":"2511.20431v2","title":"BRIC: Bridging Kinematic Plans and Physical Control at Test Time","headline":"BRIC：桥接运动规划与物理控制的测试时自适应框架","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120431v2-bric-bridging-kinematic-plans-and-physical-control-at-test-time.html"},{"id":"2511.19882v1","title":"ChessMamba: Structure-Aware Interleaving of State Spaces for Change Detection in Remote Sensing Images","headline":"ChessMamba：一种结构感知的状态空间交错方法，用于遥感图像变化检测","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119882v1-chessmamba-structure-aware-interleaving-of-state-spaces-for-change-d.html"},{"id":"2511.20549v1","title":"Flash-DMD: Towards High-Fidelity Few-Step Image Generation with Efficient Distillation and Joint Reinforcement Learning","headline":"Flash-DMD：通过高效蒸馏与联合强化学习实现高保真快速图像生成","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120549v1-flash-dmd-towards-high-fidelity-few-step-image-generation-with-effic.html"},{"id":"2511.20351v2","title":"Thinking in 360°: Humanoid Visual Search in the Wild","headline":"提出H* Bench基准，研究具身智能体在360°全景图像中的视觉搜索能力。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120351v2-thinking-in-360-humanoid-visual-search-in-the-wild.html"},{"id":"2511.20095v1","title":"WPT: World-to-Policy Transfer via Online World Model Distillation","headline":"提出WPT：通过在线世界模型蒸馏实现世界到策略的迁移，提升规划性能。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120095v1-wpt-world-to-policy-transfer-via-online-world-model-distillation.html"},{"id":"2511.20065v1","title":"FLaTEC: Frequency-Disentangled Latent Triplanes for Efficient Compression of LiDAR Point Clouds","headline":"FLaTEC：提出频率解耦的隐式三平面表示，高效压缩LiDAR点云。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120065v1-flatec-frequency-disentangled-latent-triplanes-for-efficient-compres.html"},{"id":"2511.19963v1","title":"MambaEye: A Size-Agnostic Visual Encoder with Causal Sequential Processing","headline":"MambaEye：基于因果序列处理的尺寸无关视觉编码器","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119963v1-mambaeye-a-size-agnostic-visual-encoder-with-causal-sequential-proce.html"},{"id":"2511.20415v2","title":"MajutsuCity: Language-driven Aesthetic-adaptive City Generation with Controllable 3D Assets and Layouts","headline":"MajutsuCity：提出语言驱动的美学自适应城市生成框架，可控3D资产与布局。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120415v2-majutsucity-language-driven-aesthetic-adaptive-city-generation-with-.html"},{"id":"2511.20270v1","title":"DRL-Guided Neural Batch Sampling for Semi-Supervised Pixel-Level Anomaly Detection","headline":"提出基于DRL引导的神经批量采样半监督像素级异常检测方法","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120270v1-drl-guided-neural-batch-sampling-for-semi-supervised-pixel-level-ano.html"},{"id":"2511.19827v1","title":"ReDirector: Creating Any-Length Video Retakes with Rotary Camera Encoding","headline":"ReDirector：利用旋转相机编码生成任意长度的视频重拍","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119827v1-redirector-creating-any-length-video-retakes-with-rotary-camera-enco.html"},{"id":"2511.20151v1","title":"Hybrid Convolution and Frequency State Space Network for Image Compression","headline":"提出HCFSSNet，一种混合卷积和频率状态空间网络的图像压缩方法","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120151v1-hybrid-convolution-and-frequency-state-space-network-for-image-compr.html"},{"id":"2511.20366v2","title":"VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild","headline":"VGGTFace：利用3D基础模型实现拓扑一致的人脸几何重建","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120366v2-vggtface-topologically-consistent-facial-geometry-reconstruction-in-.html"},{"id":"2511.20343v1","title":"AMB3R: Accurate Feed-forward Metric-scale 3D Reconstruction with Backend","headline":"AMB3R：利用紧凑体素后端实现精确的度量尺度三维重建","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120343v1-amb3r-accurate-feed-forward-metric-scale-3d-reconstruction-with-back.html"},{"id":"2511.19854v2","title":"STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction","headline":"STAvatar：提出软绑定与时序密度控制的单目3D头部Avatar重建方法","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119854v2-stavatar-soft-binding-and-temporal-density-control-for-monocular-3d-.html"},{"id":"2511.19972v2","title":"Boosting Reasoning in Large Multimodal Models via Activation Replay","headline":"提出Activation Replay，通过激活重放提升大型多模态模型推理能力，无需额外训练。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251119972v2-boosting-reasoning-in-large-multimodal-models-via-activation-replay.html"},{"id":"2511.20784v1","title":"One Patch is All You Need: Joint Surface Material Reconstruction and Classification from Minimal Visual Cues","headline":"SMARC：仅需图像10%区域，即可实现表面材质重建与分类","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120784v1-one-patch-is-all-you-need-joint-surface-material-reconstruction-and-.html"},{"id":"2511.20716v1","title":"Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?","headline":"针对移动边缘网络视频目标识别，提出基于深度强化学习的自适应跟踪与检测算法","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120716v1-video-object-recognition-in-mobile-edge-networks-local-tracking-or-e.html"},{"id":"2511.20865v1","title":"Estimating Fog Parameters from a Sequence of Stereo Images","headline":"提出一种基于立体图像序列的雾参数动态估计方法，适用于视觉SLAM和里程计系统。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120865v1-estimating-fog-parameters-from-a-sequence-of-stereo-images.html"},{"id":"2511.20615v1","title":"Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities","headline":"提出基于Transformer的深度学习模型，用于预测负重活动中全身动态3D姿态。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120615v1-evaluating-the-performance-of-deep-learning-models-in-whole-body-dyn.html"},{"id":"2511.20525v1","title":"Mistake Attribution: Fine-Grained Mistake Understanding in Egocentric Videos","headline":"提出Mistake Attribution (MATT)任务，用于细粒度理解以自我为中心的视频中的人类错误。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120525v1-mistake-attribution-fine-grained-mistake-understanding-in-egocentric.html"},{"id":"2511.20253v1","title":"Zoo3D: Zero-Shot 3D Object Detection at Scene Level","headline":"Zoo3D：提出一种场景级零样本3D目标检测框架，无需训练即可实现SOTA性能。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120253v1-zoo3d-zero-shot-3d-object-detection-at-scene-level.html"},{"id":"2511.20223v1","title":"V-Attack: Targeting Disentangled Value Features for Controllable Adversarial Attacks on LVLMs","headline":"V-Attack通过操控解耦的Value特征，实现对LVLM的可控对抗攻击。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120223v1-v-attack-targeting-disentangled-value-features-for-controllable-adve.html"},{"id":"2511.20157v3","title":"SKEL-CF: Coarse-to-Fine Biomechanical Skeleton and Surface Mesh Recovery","headline":"提出SKEL-CF框架，用于从图像中恢复生物力学骨骼和表面网格，提升人体运动分析的真实性。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120157v3-skel-cf-coarse-to-fine-biomechanical-skeleton-and-surface-mesh-recov.html"},{"id":"2511.20088v1","title":"Explainable Visual Anomaly Detection via Concept Bottleneck Models","headline":"提出基于概念瓶颈模型的可解释视觉异常检测方法CONVAD","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120088v1-explainable-visual-anomaly-detection-via-concept-bottleneck-models.html"},{"id":"2511.20032v1","title":"Tell Model Where to Look: Mitigating Hallucinations in MLLMs by Vision-Guided Attention","headline":"提出视觉引导注意力机制（VGA），缓解多模态大语言模型中的幻觉问题","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120032v1-tell-model-where-to-look-mitigating-hallucinations-in-mllms-by-visio.html"},{"id":"2511.20721v1","title":"Foundry: Distilling 3D Foundation Models for the Edge","headline":"Foundry：边缘设备3D基础模型蒸馏，保持通用性的同时实现高效压缩","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120721v1-foundry-distilling-3d-foundation-models-for-the-edge.html"},{"id":"2511.20011v1","title":"Multi-Context Fusion Transformer for Pedestrian Crossing Intention Prediction in Urban Environments","headline":"提出多上下文融合Transformer（MFT）用于城市环境中行人意图预测。","tag":"cs.CV","date":"2025-11-25","url":"cs-CV/2025-11-25/papers/251120011v1-multi-context-fusion-transformer-for-pedestrian-crossing-intention-p.html"},{"id":"2511.20216v1","title":"CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents","headline":"提出CostNav以解决导航任务经济可行性评估问题","tag":"cs.AI","date":"2025-11-25","url":"cs-AI/2025-11-25/papers/251120216v1-costnav-a-navigation-benchmark-for-cost-aware-evaluation-of-embodied.html"},{"id":"2511.20422v1","title":"VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning","headline":"VibraVerse：构建大规模几何-声学对齐数据集，实现物理一致的多模态学习","tag":"cs.AI","date":"2025-11-25","url":"cs-AI/2025-11-25/papers/251120422v1-vibraverse-a-large-scale-geometry-acoustics-alignment-dataset-for-ph.html"},{"id":"2512.11811v2","title":"Enhancing Geo-localization for Crowdsourced Flood Imagery via LLM-Guided Attention","headline":"VPR-AttLLM：利用LLM引导的注意力增强众包洪水图像的地理定位","tag":"cs.CL","date":"2025-11-25","url":"cs-CL/2025-11-25/papers/251211811v2-enhancing-geo-localization-for-crowdsourced-flood-imagery-via-llm-gu.html"},{"id":"2511.19709v1","title":"Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation","headline":"提出基于全身逆动力学MPC的腿式机器人Loco-manipulation方法，实现运动与力规划的统一优化。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119709v1-whole-body-inverse-dynamics-mpc-for-legged-loco-manipulation.html"},{"id":"2511.18857v1","title":"AutoOdom: Learning Auto-regressive Proprioceptive Odometry for Legged Locomotion","headline":"AutoOdom：用于足式机器人运动的自回归本体系里程计学习方法","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118857v1-autoodom-learning-auto-regressive-proprioceptive-odometry-for-legged.html"},{"id":"2511.19204v1","title":"Reference-Free Sampling-Based Model Predictive Control","headline":"提出一种无参考采样模型预测控制框架，实现四足和人形机器人的涌现式运动控制。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119204v1-reference-free-sampling-based-model-predictive-control.html"},{"id":"2511.19236v1","title":"SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control","headline":"SENTINEL：用于人形机器人全身控制的端到端语言-动作模型","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119236v1-sentinel-a-fully-end-to-end-language-action-model-for-humanoid-whole.html"},{"id":"2511.19543v1","title":"A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers","headline":"提出基于虚拟机械交互层的机器人控制方法，提升人机物体递送的鲁棒性","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119543v1-a-virtual-mechanical-interaction-layer-enables-resilient-human-to-ro.html"},{"id":"2511.18712v1","title":"Head Stabilization for Wheeled Bipedal Robots via Force-Estimation-Based Admittance Control","headline":"提出基于力估计的导纳控制，用于轮式双足机器人头部稳定","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118712v1-head-stabilization-for-wheeled-bipedal-robots-via-force-estimation-b.html"},{"id":"2511.18756v1","title":"SP-VINS: A Hybrid Stereo Visual Inertial Navigation System based on Implicit Environmental Map","headline":"提出基于隐式环境地图的立体视觉惯性导航系统SP-VINS，提升长时高精度定位性能。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118756v1-sp-vins-a-hybrid-stereo-visual-inertial-navigation-system-based-on-i.html"},{"id":"2511.18878v1","title":"Accelerating Reinforcement Learning via Error-Related Human Brain Signals","headline":"通过脑电信号加速复杂机器人操作中的强化学习","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118878v1-accelerating-reinforcement-learning-via-error-related-human-brain-si.html"},{"id":"2511.18950v1","title":"Compressor-VLA: Instruction-Guided Visual Token Compression for Efficient Robotic Manipulation","headline":"提出Compressor-VLA，通过指令引导的视觉Token压缩提升机器人操作效率。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118950v1-compressor-vla-instruction-guided-visual-token-compression-for-effic.html"},{"id":"2511.19655v2","title":"Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection","headline":"提出基于单目视觉车道线检测与MPC控制的自动驾驶车辆测试平台","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119655v2-development-of-a-testbed-for-autonomous-vehicles-integrating-mpc-con.html"},{"id":"2511.19031v2","title":"Multi-Agent Monocular Dense SLAM With 3D Reconstruction Priors","headline":"提出基于3D重建先验的多智能体单目稠密SLAM系统，提升计算效率。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119031v2-multi-agent-monocular-dense-slam-with-3d-reconstruction-priors.html"},{"id":"2511.18703v1","title":"Asynchronous Distributed Multi-Robot Motion Planning Under Imperfect Communication","headline":"提出延迟感知ADMM算法，解决非完美通信下多机器人异步分布式运动规划问题","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118703v1-asynchronous-distributed-multi-robot-motion-planning-under-imperfect.html"},{"id":"2511.19315v1","title":"Rethinking Intermediate Representation for VLM-based Robot Manipulation","headline":"提出基于VLM的机器人操作语义组装表示SEAM，提升泛化性和可理解性。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119315v1-rethinking-intermediate-representation-for-vlm-based-robot-manipulat.html"},{"id":"2512.00072v1","title":"Reconfigurable Auxetic Devices (RADs) for Robotic Surface Manipulation","headline":"提出可重构负泊松比设备(RADs)用于机器人表面操作，实现可变形界面","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251200072v1-reconfigurable-auxetic-devices-rads-for-robotic-surface-manipulation.html"},{"id":"2511.18910v2","title":"An Efficient Closed-Form Solution to Full Visual-Inertial State Initialization","headline":"提出一种高效的视觉惯性状态初始化闭式解法，无需非线性优化。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118910v2-an-efficient-closed-form-solution-to-full-visual-inertial-state-init.html"},{"id":"2511.18702v1","title":"CNN-Based Camera Pose Estimation and Localisation of Scan Images for Aircraft Visual Inspection","headline":"提出基于CNN的飞机视觉检测相机位姿估计与定位方法，无需额外基础设施。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118702v1-cnn-based-camera-pose-estimation-and-localisation-of-scan-images-for.html"},{"id":"2511.18694v1","title":"Stable Multi-Drone GNSS Tracking System for Marine Robots","headline":"提出一种基于多无人机GNSS的稳定水面机器人跟踪系统","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118694v1-stable-multi-drone-gnss-tracking-system-for-marine-robots.html"},{"id":"2511.18683v1","title":"Online Learning-Enhanced Lie Algebraic MPC for Robust Trajectory Tracking of Autonomous Surface Vehicles","headline":"提出基于李群误差状态MPC与在线学习的自主水面艇鲁棒轨迹跟踪方法","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251118683v1-online-learning-enhanced-lie-algebraic-mpc-for-robust-trajectory-tra.html"},{"id":"2511.19528v1","title":"Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories","headline":"提出DLR框架，通过强化学习生成多样化轨迹，提升VLA模型预训练效果。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119528v1-discover-learn-and-reinforce-scaling-vision-language-action-pretrain.html"},{"id":"2512.00062v1","title":"SpeedAug: Policy Acceleration via Tempo-Enriched Policy and RL Fine-Tuning","headline":"SpeedAug：通过速度增强策略和强化学习微调加速机器人策略学习","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251200062v1-speedaug-policy-acceleration-via-tempo-enriched-policy-and-rl-fine-t.html"},{"id":"2511.19433v1","title":"Mixture of Horizons in Action Chunking","headline":"提出混合视野动作分块（MoH）策略，提升机器人操作中VLA模型的性能和泛化性。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119433v1-mixture-of-horizons-in-action-chunking.html"},{"id":"2511.19094v1","title":"Analysis of Deep-Learning Methods in an ISO/TS 15066-Compliant Human-Robot Safety Framework","headline":"提出基于深度学习的人机安全框架，动态调整机器人速度以优化协作效率。","tag":"cs.RO","date":"2025-11-24","url":"cs-RO/2025-11-24/papers/251119094v1-analysis-of-deep-learning-methods-in-an-isots-15066-compliant-human-.html"},{"id":"2511.19294v1","title":"DensifyBeforehand: LiDAR-assisted Content-aware Densification for Efficient and Quality 3D Gaussian Splatting","headline":"提出LiDAR辅助的内容感知稠密化方法，提升3D高斯溅射效率与质量","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119294v1-densifybeforehand-lidar-assisted-content-aware-densification-for-eff.html"},{"id":"2511.18873v1","title":"Neural Texture Splatting: Expressive 3D Gaussian Splatting for View Synthesis, Geometry, and Dynamic Reconstruction","headline":"提出神经纹理溅射（NTS），提升3D高斯溅射在视图合成、几何及动态重建任务上的性能。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118873v1-neural-texture-splatting-expressive-3d-gaussian-splatting-for-view-s.html"},{"id":"2511.19217v1","title":"ReAlign: Text-to-Motion Generation via Step-Aware Reward-Guided Alignment","headline":"提出ReAlign，通过步进式奖励引导对齐实现高质量文本到动作生成","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119217v1-realign-text-to-motion-generation-via-step-aware-reward-guided-align.html"},{"id":"2511.19235v1","title":"IDSplat: Instance-Decomposed 3D Gaussian Splatting for Driving Scenes","headline":"IDSplat：面向自动驾驶场景的实例分解3D高斯溅射重建","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119235v1-idsplat-instance-decomposed-3d-gaussian-splatting-for-driving-scenes.html"},{"id":"2511.19202v1","title":"NVGS: Neural Visibility for Occlusion Culling in 3D Gaussian Splatting","headline":"提出基于神经可见性的3D高斯溅射遮挡剔除方法，提升复杂场景渲染效率。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119202v1-nvgs-neural-visibility-for-occlusion-culling-in-3d-gaussian-splattin.html"},{"id":"2511.18927v1","title":"FineXtrol: Controllable Motion Generation via Fine-Grained Text","headline":"FineXtrol：通过细粒度文本控制实现可控的运动生成","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118927v1-finextrol-controllable-motion-generation-via-fine-grained-text.html"},{"id":"2511.18811v1","title":"Mitigating Long-Tail Bias in HOI Detection via Adaptive Diversity Cache","headline":"提出自适应多样性缓存模块，无需额外训练即可缓解HOI检测中的长尾偏差。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118811v1-mitigating-long-tail-bias-in-hoi-detection-via-adaptive-diversity-ca.html"},{"id":"2511.18993v1","title":"AuViRe: Audio-visual Speech Representation Reconstruction for Deepfake Temporal Localization","headline":"提出AuViRe，通过音视频语音表征重建实现Deepfake视频的时间定位","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118993v1-auvire-audio-visual-speech-representation-reconstruction-for-deepfak.html"},{"id":"2511.19527v1","title":"MapRF: Weakly Supervised Online HD Map Construction via NeRF-Guided Self-Training","headline":"MapRF：基于NeRF引导自训练的弱监督在线高清地图构建","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119527v1-maprf-weakly-supervised-online-hd-map-construction-via-nerf-guided-s.html"},{"id":"2511.18672v1","title":"Sphinx: Efficiently Serving Novel View Synthesis using Regression-Guided Selective Refinement","headline":"Sphinx：提出一种基于回归引导选择性优化的高效新视角合成框架","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118672v1-sphinx-efficiently-serving-novel-view-synthesis-using-regression-gui.html"},{"id":"2511.18983v1","title":"UMCL: Unimodal-generated Multimodal Contrastive Learning for Cross-compression-rate Deepfake Detection","headline":"提出UMCL框架，通过单模态生成多模态对比学习，解决跨压缩率深度伪造检测难题。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118983v1-umcl-unimodal-generated-multimodal-contrastive-learning-for-cross-co.html"},{"id":"2511.18729v2","title":"GuideFlow: Constraint-Guided Flow Matching for Planning in End-to-End Autonomous Driving","headline":"GuideFlow：一种约束引导的Flow Matching方法，用于端到端自动驾驶规划。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118729v2-guideflow-constraint-guided-flow-matching-for-planning-in-end-to-end.html"},{"id":"2511.19172v1","title":"MetroGS: Efficient and Stable Reconstruction of Geometrically Accurate High-Fidelity Large-Scale Scenes","headline":"MetroGS：高效稳定地重建几何精确的高保真大规模场景","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119172v1-metrogs-efficient-and-stable-reconstruction-of-geometrically-accurat.html"},{"id":"2511.19105v1","title":"Graph-based 3D Human Pose Estimation using WiFi Signals","headline":"提出GraphPose-Fi，利用WiFi信号和图神经网络进行3D人体姿态估计","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119105v1-graph-based-3d-human-pose-estimation-using-wifi-signals.html"},{"id":"2511.19057v1","title":"LAA3D: A Benchmark of Detecting and Tracking Low-Altitude Aircraft in 3D Space","headline":"LAA3D：构建低空飞行器三维感知基准数据集与单目3D检测基线。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119057v1-laa3d-a-benchmark-of-detecting-and-tracking-low-altitude-aircraft-in.html"},{"id":"2511.18851v1","title":"Robust Long-term Test-Time Adaptation for 3D Human Pose Estimation through Motion Discretization","headline":"提出基于运动离散化的鲁棒长期测试时自适应3D人体姿态估计方法","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118851v1-robust-long-term-test-time-adaptation-for-3d-human-pose-estimation-t.html"},{"id":"2511.19033v1","title":"ReEXplore: Improving MLLMs for Embodied Exploration with Contextualized Retrospective Experience Replay","headline":"ReEXplore：利用情境化回顾经验回放改进MLLM在具身探索中的性能","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119033v1-reexplore-improving-mllms-for-embodied-exploration-with-contextualiz.html"},{"id":"2511.19524v1","title":"VideoChat-M1: Collaborative Policy Planning for Video Understanding via Multi-Agent Reinforcement Learning","headline":"提出VideoChat-M1，通过多智能体强化学习实现视频理解的协同策略规划。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119524v1-videochat-m1-collaborative-policy-planning-for-video-understanding-v.html"},{"id":"2511.19515v1","title":"Fewer Tokens, Greater Scaling: Self-Adaptive Visual Bases for Efficient and Expansive Representation Learning","headline":"提出自适应视觉基，减少视觉Token数量，提升视觉表征学习的效率和可扩展性","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119515v1-fewer-tokens-greater-scaling-self-adaptive-visual-bases-for-efficien.html"},{"id":"2511.19542v1","title":"Proxy-Free Gaussian Splats Deformation with Splat-Based Surface Estimation","headline":"提出无代理高斯斑点变形方法以解决表面信息捕捉不足问题","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119542v1-proxy-free-gaussian-splats-deformation-with-splat-based-surface-esti.html"},{"id":"2511.19511v1","title":"The Determinant Ratio Matrix Approach to Solving 3D Matching and 2D Orthographic Projection Alignment Tasks","headline":"提出基于行列式比率矩阵（DRaM）的EnP和OnP问题求解方法","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119511v1-the-determinant-ratio-matrix-approach-to-solving-3d-matching-and-2d-.html"},{"id":"2511.18886v1","title":"MagicWorld: Interactive Geometry-driven Video World Exploration","headline":"MagicWorld：提出几何引导的交互式视频世界探索模型，提升场景稳定性和连续性。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118886v1-magicworld-interactive-geometry-driven-video-world-exploration.html"},{"id":"2511.18766v1","title":"Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment","headline":"提出ViewSense-AD，通过同构变换引导对齐实现无监督多视角异常检测。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118766v1-unsupervised-multi-view-visual-anomaly-detection-via-progressive-hom.html"},{"id":"2511.19319v1","title":"SyncMV4D: Synchronized Multi-view Joint Diffusion of Appearance and Motion for Hand-Object Interaction Synthesis","headline":"SyncMV4D：同步多视角联合扩散生成手-物交互视频与4D运动","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119319v1-syncmv4d-synchronized-multi-view-joint-diffusion-of-appearance-and-m.html"},{"id":"2511.18976v1","title":"Peregrine: One-Shot Fine-Tuning for FHE Inference of General Deep CNNs","headline":"Peregrine：用于通用深度CNN的FHE推理的单次微调方法","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118976v1-peregrine-one-shot-fine-tuning-for-fhe-inference-of-general-deep-cnn.html"},{"id":"2511.18775v1","title":"Rethinking Garment Conditioning in Diffusion-based Virtual Try-On","headline":"提出Re-CatVTON，高效单UNet扩散模型实现高性能虚拟试穿","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118775v1-rethinking-garment-conditioning-in-diffusion-based-virtual-try-on.html"},{"id":"2511.19768v1","title":"Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering","headline":"Prune-Then-Plan：通过步级校准实现具身问答中稳定的边界探索","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119768v1-prune-then-plan-step-level-calibration-for-stable-frontier-explorati.html"},{"id":"2511.19760v1","title":"A Storage-Efficient Feature for 3D Concrete Defect Segmentation to Replace Normal Vector","headline":"提出基于相对角度的3D混凝土缺陷分割特征，实现存储效率提升。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119760v1-a-storage-efficient-feature-for-3d-concrete-defect-segmentation-to-r.html"},{"id":"2511.19684v1","title":"IndEgo: A Dataset of Industrial Scenarios and Collaborative Work for Egocentric Assistants","headline":"IndEgo：用于第一人称视角工业助手协作任务的多模态数据集","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119684v1-indego-a-dataset-of-industrial-scenarios-and-collaborative-work-for-.html"},{"id":"2511.19436v1","title":"VDC-Agent: When Video Detailed Captioners Evolve Themselves via Agentic Self-Reflection","headline":"VDC-Agent：通过Agent自反思进化视频详细描述模型，无需人工标注和大型教师模型。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119436v1-vdc-agent-when-video-detailed-captioners-evolve-themselves-via-agent.html"},{"id":"2511.19326v1","title":"MonoMSK: Monocular 3D Musculoskeletal Dynamics Estimation","headline":"MonoMSK：单目视频中基于物理的3D人体骨骼肌肉动力学估计","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119326v1-monomsk-monocular-3d-musculoskeletal-dynamics-estimation.html"},{"id":"2511.19149v1","title":"From Pixels to Posts: Retrieval-Augmented Fashion Captioning and Hashtag Generation","headline":"提出检索增强的时尚描述与标签生成框架，提升属性保真度和领域泛化性。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119149v1-from-pixels-to-posts-retrieval-augmented-fashion-captioning-and-hash.html"},{"id":"2511.19111v2","title":"DiffSeg30k: A Multi-Turn Diffusion Editing Benchmark for Localized AIGC Detection","headline":"DiffSeg30k：用于AIGC精细化检测的多轮扩散编辑基准数据集","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119111v2-diffseg30k-a-multi-turn-diffusion-editing-benchmark-for-localized-ai.html"},{"id":"2511.19062v1","title":"Granular Computing-driven SAM: From Coarse-to-Fine Guidance for Prompt-Free Segmentation","headline":"提出基于粒计算的Grc-SAM，实现无提示图像分割的粗到细精度提升。","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119062v1-granular-computing-driven-sam-from-coarse-to-fine-guidance-for-promp.html"},{"id":"2511.19526v1","title":"Perceptual Taxonomy: Evaluating and Guiding Hierarchical Scene Reasoning in Vision-Language Models","headline":"提出感知分类法，用于评估和指导视觉-语言模型中的分层场景推理","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251119526v1-perceptual-taxonomy-evaluating-and-guiding-hierarchical-scene-reason.html"},{"id":"2511.18806v1","title":"TPG-INR: Target Prior-Guided Implicit 3D CT Reconstruction for Enhanced Sparse-view Imaging","headline":"提出TPG-INR以解决超稀视图下3D CT重建精度不足问题","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118806v1-tpg-inr-target-prior-guided-implicit-3d-ct-reconstruction-for-enhanc.html"},{"id":"2511.18801v1","title":"PartDiffuser: Part-wise 3D Mesh Generation via Discrete Diffusion","headline":"PartDiffuser：通过离散扩散实现分部件的三维网格生成","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118801v1-partdiffuser-part-wise-3d-mesh-generation-via-discrete-diffusion.html"},{"id":"2511.18787v1","title":"Understanding Task Transfer in Vision-Language Models","headline":"提出Perfection Gap Factor，系统研究视觉-语言模型中的任务迁移现象","tag":"cs.CV","date":"2025-11-24","url":"cs-CV/2025-11-24/papers/251118787v1-understanding-task-transfer-in-vision-language-models.html"},{"id":"2511.19189v1","title":"AvatarBrush: Monocular Reconstruction of Gaussian Avatars with Intuitive Local Editing","headline":"AvatarBrush：单目视频重建可局部编辑的高斯人像模型","tag":"cs.GR","date":"2025-11-24","url":"cs-GR/2025-11-24/papers/251119189v1-avatarbrush-monocular-reconstruction-of-gaussian-avatars-with-intuit.html"},{"id":"2511.18680v1","title":"Inverse Rendering for High-Genus Surface Meshes from Multi-View Images","headline":"提出一种拓扑感知的逆渲染方法，用于重建高亏格曲面网格","tag":"cs.GR","date":"2025-11-24","url":"cs-GR/2025-11-24/papers/251118680v1-inverse-rendering-for-high-genus-surface-meshes-from-multi-view-imag.html"},{"id":"2511.19165v1","title":"First-order Sobolev Reinforcement Learning","headline":"提出一阶Sobolev强化学习，通过梯度一致性加速critic收敛并稳定策略梯度。","tag":"cs.LG","date":"2025-11-24","url":"cs-LG/2025-11-24/papers/251119165v1-first-order-sobolev-reinforcement-learning.html"},{"id":"2511.19584v2","title":"Learning Massively Multitask World Models for Continuous Control","headline":"提出Newt：一种大规模多任务世界模型，用于连续控制任务","tag":"cs.LG","date":"2025-11-24","url":"cs-LG/2025-11-24/papers/251119584v2-learning-massively-multitask-world-models-for-continuous-control.html"},{"id":"2511.19355v1","title":"Leveraging LLMs for reward function design in reinforcement learning control tasks","headline":"提出LEARN-Opt，利用LLM自主设计强化学习控制任务的奖励函数，无需人工干预。","tag":"cs.LG","date":"2025-11-24","url":"cs-LG/2025-11-24/papers/251119355v1-leveraging-llms-for-reward-function-design-in-reinforcement-learning.html"},{"id":"2511.18960v2","title":"AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention","headline":"AVA-VLA：通过主动视觉注意力提升视觉-语言-动作模型在具身智能任务中的性能。","tag":"cs.LG","date":"2025-11-24","url":"cs-LG/2025-11-24/papers/251118960v2-ava-vla-improving-vision-language-action-models-with-active-visual-a.html"},{"id":"2511.19773v1","title":"Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs","headline":"VISTA-Gym：通过强化学习提升视觉语言模型在工具集成推理方面的能力","tag":"cs.AI","date":"2025-11-24","url":"cs-AI/2025-11-24/papers/251119773v1-scaling-agentic-reinforcement-learning-for-tool-integrated-reasoning.html"},{"id":"2511.19396v1","title":"Real-Time Object Tracking with On-Device Deep Learning for Adaptive Beamforming in Dynamic Acoustic Environments","headline":"提出一种基于设备端深度学习的目标跟踪与波束成形实时嵌入式系统","tag":"cs.AI","date":"2025-11-24","url":"cs-AI/2025-11-24/papers/251119396v1-real-time-object-tracking-with-on-device-deep-learning-for-adaptive-.html"},{"id":"2511.18525v1","title":"Splatblox: Traversability-Aware Gaussian Splatting for Outdoor Robot Navigation","headline":"提出Splatblox以解决户外机器人导航中的可通行性问题","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118525v1-splatblox-traversability-aware-gaussian-splatting-for-outdoor-robot-.html"},{"id":"2511.18509v1","title":"SafeFall: Learning Protective Control for Humanoid Robots","headline":"SafeFall：学习人形机器人保护性控制，降低跌倒损伤","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118509v1-safefall-learning-protective-control-for-humanoid-robots.html"},{"id":"2511.18293v1","title":"AIA-UltraNeRF:Acoustic-Impedance-Aware Neural Radiance Field with Hash Encodings for Robotic Ultrasound Reconstruction and Localization","headline":"AIA-UltraNeRF：声阻抗感知神经辐射场用于机器人超声重建与定位","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118293v1-aia-ultranerfacoustic-impedance-aware-neural-radiance-field-with-has.html"},{"id":"2511.18486v1","title":"Expanding the Workspace of Electromagnetic Navigation Systems Using Dynamic Feedback for Single- and Multi-agent Control","headline":"利用动态反馈扩展电磁导航系统工作空间，实现单/多智能体控制","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118486v1-expanding-the-workspace-of-electromagnetic-navigation-systems-using-.html"},{"id":"2511.18617v2","title":"AutoFocus-IL: VLM-based Saliency Maps for Data-Efficient Visual Imitation Learning without Extra Human Annotations","headline":"AutoFocus-IL：基于VLM显著性图的数据高效视觉模仿学习，无需额外人工标注","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118617v2-autofocus-il-vlm-based-saliency-maps-for-data-efficient-visual-imita.html"},{"id":"2511.18236v2","title":"APULSE: A Scalable Hybrid Algorithm for the RCSPP on Large-Scale Dense Graphs","headline":"APULSE：一种可扩展的混合算法，用于求解大规模稠密图上的资源约束最短路径问题","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118236v2-apulse-a-scalable-hybrid-algorithm-for-the-rcspp-on-large-scale-dens.html"},{"id":"2511.18243v1","title":"Dreaming Falcon: Physics-Informed Model-Based Reinforcement Learning for Quadcopters","headline":"Dreaming Falcon：基于物理信息的四旋翼飞行器模型预测强化学习","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118243v1-dreaming-falcon-physics-informed-model-based-reinforcement-learning-.html"},{"id":"2511.18563v1","title":"Object-centric Task Representation and Transfer using Diffused Orientation Fields","headline":"提出基于扩散方向场的物体中心任务表示与迁移方法，解决机器人曲面物体操作难题。","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118563v1-object-centric-task-representation-and-transfer-using-diffused-orien.html"},{"id":"2511.18606v1","title":"How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints","headline":"提出LatentCBF，解决难建模约束下的平滑安全滤波问题，提升视觉运动控制任务完成率。","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118606v1-how-to-train-your-latent-control-barrier-function-smooth-safety-filt.html"},{"id":"2511.18299v1","title":"MicCheck: Repurposing Off-the-Shelf Pin Microphones for Easy and Low-Cost Contact Sensing","headline":"MicCheck：利用现成领夹麦克风实现简易低成本的接触感知","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118299v1-miccheck-repurposing-off-the-shelf-pin-microphones-for-easy-and-low-.html"},{"id":"2511.18604v1","title":"An Analysis of Constraint-Based Multi-Agent Pathfinding Algorithms","headline":"通过约束分类指导多智能体路径规划算法设计，提升问题求解效率与方案质量","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118604v1-an-analysis-of-constraint-based-multi-agent-pathfinding-algorithms.html"},{"id":"2511.18374v1","title":"Explicit Bounds on the Hausdorff Distance for Truncated mRPI Sets via Norm-Dependent Contraction Rates","headline":"提出显式界限以解决截断mRPI集的Hausdorff距离问题","tag":"cs.RO","date":"2025-11-23","url":"cs-RO/2025-11-23/papers/251118374v1-explicit-bounds-on-the-hausdorff-distance-for-truncated-mrpi-sets-vi.html"},{"id":"2511.18441v1","title":"ReCoGS: Real-time ReColoring for Gaussian Splatting scenes","headline":"ReCoGS：高斯溅射场景的实时重新着色方法","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118441v1-recogs-real-time-recoloring-for-gaussian-splatting-scenes.html"},{"id":"2511.18570v1","title":"PhysGS: Bayesian-Inferred Gaussian Splatting for Physical Property Estimation","headline":"PhysGS：基于贝叶斯推断的高斯溅射实现物理属性估计","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118570v1-physgs-bayesian-inferred-gaussian-splatting-for-physical-property-es.html"},{"id":"2511.18386v1","title":"SegSplat: Feed-forward Gaussian Splatting and Open-Set Semantic Segmentation","headline":"SegSplat：提出一种前馈高斯溅射和开放集语义分割框架","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118386v1-segsplat-feed-forward-gaussian-splatting-and-open-set-semantic-segme.html"},{"id":"2511.18367v1","title":"Alias-free 4D Gaussian Splatting","headline":"提出4D尺度自适应滤波与尺度损失，解决4D高斯溅射动态场景重建中的混叠伪影问题。","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118367v1-alias-free-4d-gaussian-splatting.html"},{"id":"2511.18424v1","title":"CrossJEPA: Cross-Modal Joint-Embedding Predictive Architecture for Efficient 3D Representation Learning from 2D Images","headline":"提出CrossJEPA以解决3D表示学习中的2D图像数据稀缺问题","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118424v1-crossjepa-cross-modal-joint-embedding-predictive-architecture-for-ef.html"},{"id":"2511.18627v1","title":"Functional Localization Enforced Deep Anomaly Detection Using Fundus Images","headline":"利用眼底图像和功能定位增强的深度异常检测方法","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118627v1-functional-localization-enforced-deep-anomaly-detection-using-fundus.html"},{"id":"2511.18470v1","title":"Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span","headline":"EgoSpanLift：预测第一人称视角下的3D视觉范围，提升AR/VR体验。","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118470v1-gaze-beyond-the-frame-forecasting-egocentric-3d-visual-span.html"},{"id":"2511.18416v1","title":"4D-VGGT: A General Foundation Model with SpatioTemporal Awareness for Dynamic Scene Geometry Estimation","headline":"提出4D-VGGT，用于动态场景几何估计的时空感知通用基础模型","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118416v1-4d-vggt-a-general-foundation-model-with-spatiotemporal-awareness-for.html"},{"id":"2511.18380v1","title":"RNN as Linear Transformer: A Closer Investigation into Representational Potentials of Visual Mamba Models","headline":"分析Mamba视觉模型表征能力，揭示其与线性Transformer的关联","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118380v1-rnn-as-linear-transformer-a-closer-investigation-into-representation.html"},{"id":"2511.18534v1","title":"HiFi-MambaV2: Hierarchical Shared-Routed MoE for High-Fidelity MRI Reconstruction","headline":"HiFi-MambaV2：用于高保真MRI重建的分层共享路由MoE Mamba架构","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118534v1-hifi-mambav2-hierarchical-shared-routed-moe-for-high-fidelity-mri-re.html"},{"id":"2511.18370v1","title":"MimiCAT: Mimic with Correspondence-Aware Cascade-Transformer for Category-Free 3D Pose Transfer","headline":"MimiCAT：基于对应感知级联Transformer的无类别3D姿态迁移","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118370v1-mimicat-mimic-with-correspondence-aware-cascade-transformer-for-cate.html"},{"id":"2511.18290v1","title":"SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes","headline":"SwiftVGGT：一种可扩展的视觉几何约束Transformer，用于大规模场景三维重建。","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118290v1-swiftvggt-a-scalable-visual-geometry-grounded-transformer-for-large-.html"},{"id":"2511.18254v1","title":"UniFlow: Towards Zero-Shot LiDAR Scene Flow for Autonomous Vehicles via Cross-Domain Generalization","headline":"UniFlow：通过跨域泛化实现自动驾驶车辆的零样本LiDAR场景流估计","tag":"cs.CV","date":"2025-11-23","url":"cs-CV/2025-11-23/papers/251118254v1-uniflow-towards-zero-shot-lidar-scene-flow-for-autonomous-vehicles-v.html"},{"id":"2511.18140v1","title":"Observer Actor: Active Vision Imitation Learning with Sparse View Gaussian Splatting","headline":"提出Observer Actor框架，通过主动视觉模仿学习提升双臂机器人的操作性能。","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118140v1-observer-actor-active-vision-imitation-learning-with-sparse-view-gau.html"},{"id":"2511.17925v2","title":"Switch-JustDance: Benchmarking Whole Body Motion Tracking Policies Using a Commercial Console Game","headline":"提出Switch-JustDance：利用商业游戏评估全身运动跟踪策略的低成本基准测试方案","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251117925v2-switch-justdance-benchmarking-whole-body-motion-tracking-policies-us.html"},{"id":"2511.18183v1","title":"Off-Road Navigation via Implicit Neural Representation of Terrain Traversability","headline":"提出TRAIL：利用隐式神经表示进行地形可通行性评估的越野导航框架","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118183v1-off-road-navigation-via-implicit-neural-representation-of-terrain-tr.html"},{"id":"2511.18112v1","title":"EchoVLA: Robotic Vision-Language-Action Model with Synergistic Declarative Memory for Mobile Manipulation","headline":"EchoVLA：面向移动操作的协同声明式记忆机器人视觉-语言-动作模型","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118112v1-echovla-robotic-vision-language-action-model-with-synergistic-declar.html"},{"id":"2511.17992v1","title":"Unobservable Subspace Evolution and Alignment for Consistent Visual-Inertial Navigation","headline":"提出基于不可观子空间演化与对齐的VINS一致性解决方案","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251117992v1-unobservable-subspace-evolution-and-alignment-for-consistent-visual-.html"},{"id":"2511.18153v1","title":"A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies","headline":"提出SnapNet与双臂协调框架，解决精密卡扣装配中的力控与检测问题","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118153v1-a-coordinated-dual-arm-framework-for-delicate-snap-fit-assemblies.html"},{"id":"2511.18170v1","title":"Time-aware Motion Planning in Dynamic Environments with Conformal Prediction","headline":"提出基于Conformal Prediction的时间感知运动规划框架，解决动态环境中安全导航问题。","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118170v1-time-aware-motion-planning-in-dynamic-environments-with-conformal-pr.html"},{"id":"2511.17961v1","title":"RoboArmGS: High-Quality Robotic Arm Splatting via Bézier Curve Refinement","headline":"RoboArmGS：基于贝塞尔曲线优化的高质量机械臂高斯溅射","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251117961v1-roboarmgs-high-quality-robotic-arm-splatting-via-bézier-curve-refine.html"},{"id":"2511.18085v2","title":"Continually Evolving Skill Knowledge in Vision Language Action Model","headline":"Stellar VLA：面向视觉-语言-动作模型的知识驱动持续学习框架","tag":"cs.RO","date":"2025-11-22","url":"cs-RO/2025-11-22/papers/251118085v2-continually-evolving-skill-knowledge-in-vision-language-action-model.html"},{"id":"2511.17918v1","title":"Frequency-Adaptive Sharpness Regularization for Improving 3D Gaussian Splatting Generalization","headline":"提出频率自适应锐度正则化(FASR)以提升3D高斯溅射在少样本视角合成中的泛化能力","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117918v1-frequency-adaptive-sharpness-regularization-for-improving-3d-gaussia.html"},{"id":"2511.17932v1","title":"Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion","headline":"提出基于视频扩散模型的零样本新视角合成方法，解决稀疏视角下的场景重建问题。","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117932v1-novel-view-synthesis-from-a-few-glimpses-via-test-time-natural-video.html"},{"id":"2511.17952v1","title":"Multi-speaker Attention Alignment for Multimodal Social Interaction","headline":"提出多说话人注意力对齐方法，提升MLLM在多模态社交互动中的理解能力","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117952v1-multi-speaker-attention-alignment-for-multimodal-social-interaction.html"},{"id":"2511.18192v2","title":"ARIAL: An Agentic Framework for Document VQA with Precise Answer Localization","headline":"提出ARIAL框架，通过Agentic方式实现文档VQA的精确答案定位与抽取。","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118192v2-arial-an-agentic-framework-for-document-vqa-with-precise-answer-loca.html"},{"id":"2511.18127v1","title":"SFHand: A Streaming Framework for Language-guided 3D Hand Forecasting and Embodied Manipulation","headline":"SFHand：用于语言引导的3D手部预测和具身操作的流式框架","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118127v1-sfhand-a-streaming-framework-for-language-guided-3d-hand-forecasting.html"},{"id":"2511.17967v1","title":"CADTrack: Learning Contextual Aggregation with Deformable Alignment for Robust RGBT Tracking","headline":"CADTrack：面向鲁棒RGBT跟踪，提出基于可变形对齐的上下文聚合方法","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117967v1-cadtrack-learning-contextual-aggregation-with-deformable-alignment-f.html"},{"id":"2511.17986v1","title":"Plan-X: Instruct Video Generation via Semantic Planning","headline":"Plan-X通过语义规划指导视频生成，显著减少视觉幻觉并提升指令对齐。","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117986v1-plan-x-instruct-video-generation-via-semantic-planning.html"},{"id":"2511.17929v1","title":"MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection","headline":"MambaTAD：结合状态空间模型的长程时序动作检测方法","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117929v1-mambatad-when-state-space-models-meet-long-range-temporal-action-det.html"},{"id":"2511.17927v1","title":"PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning","headline":"提出PA-FAS，通过路径增强强化学习提升多模态人脸反欺骗的泛化性和可解释性","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251117927v1-pa-fas-towards-interpretable-and-generalizable-multimodal-face-anti-.html"},{"id":"2511.18200v2","title":"InfiniBench: Infinite Benchmarking for Visual Spatial Reasoning with Customizable Scene Complexity","headline":"InfiniBench：提出可定制场景复杂度的无限视觉空间推理评测基准。","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118200v2-infinibench-infinite-benchmarking-for-visual-spatial-reasoning-with-.html"},{"id":"2511.18115v1","title":"Muskie: Multi-view Masked Image Modeling for 3D Vision Pre-training","headline":"Muskie：面向3D视觉预训练的多视角掩码图像建模","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118115v1-muskie-multi-view-masked-image-modeling-for-3d-vision-pre-training.html"},{"id":"2511.18105v1","title":"AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens","headline":"AdaPerceiver：提出首个在深度、宽度和tokens上自适应的Transformer架构。","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118105v1-adaperceiver-transformers-with-adaptive-width-depth-and-tokens.html"},{"id":"2511.18102v1","title":"Spotlight: Identifying and Localizing Video Generation Errors Using VLMs","headline":"Spotlight：利用视觉语言模型识别和定位视频生成错误","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118102v1-spotlight-identifying-and-localizing-video-generation-errors-using-v.html"},{"id":"2511.18082v1","title":"ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models","headline":"ActDistill：面向高效VLA模型的动作引导自蒸馏框架","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118082v1-actdistill-general-action-guided-self-derived-distillation-for-effic.html"},{"id":"2511.18075v1","title":"VK-Det: Visual Knowledge Guided Prototype Learning for Open-Vocabulary Aerial Object Detection","headline":"VK-Det：视觉知识引导的原型学习用于开放词汇空中目标检测","tag":"cs.CV","date":"2025-11-22","url":"cs-CV/2025-11-22/papers/251118075v1-vk-det-visual-knowledge-guided-prototype-learning-for-open-vocabular.html"},{"id":"2511.18209v1","title":"MotionDuet: Dual-Conditioned 3D Human Motion Generation with Video-Regularized Text Learning","headline":"MotionDuet：提出一种视频正则化的文本学习框架，用于双重条件下的3D人体运动生成。","tag":"cs.GR","date":"2025-11-22","url":"cs-GR/2025-11-22/papers/251118209v1-motionduet-dual-conditioned-3d-human-motion-generation-with-video-re.html"},{"id":"2511.16898v1","title":"Single-Pixel Tactile Skin via Compressive Sampling","headline":"提出基于压缩感知的单像素触觉皮肤，解决大面积触觉传感的数据瓶颈问题","tag":"cs.RO","date":"2025-11-21","url":"cs-RO/2025-11-21/papers/251116898v1-single-pixel-tactile-skin-via-compressive-sampling.html"},{"id":"2511.16860v1","title":"Parts-Mamba: Augmenting Joint Context with Part-Level Scanning for Occluded Human Skeleton","headline":"提出Parts-Mamba模型，增强骨骼动作识别在遮挡场景下的性能","tag":"cs.CV","date":"2025-11-21","url":"cs-CV/2025-11-21/papers/251116860v1-parts-mamba-augmenting-joint-context-with-part-level-scanning-for-oc.html"},{"id":"2511.16948v1","title":"Flow-Guided Implicit Neural Representation for Motion-Aware Dynamic MRI Reconstruction","headline":"提出基于光流引导的隐式神经表示，用于运动感知动态磁共振重建","tag":"cs.CV","date":"2025-11-21","url":"cs-CV/2025-11-21/papers/251116948v1-flow-guided-implicit-neural-representation-for-motion-aware-dynamic-.html"},{"id":"2511.16920v1","title":"DeltaDeno: Zero-Shot Anomaly Generation via Delta-Denoising Attribution","headline":"DeltaDeno：提出一种基于Delta去噪归因的零样本异常生成方法。","tag":"cs.CV","date":"2025-11-21","url":"cs-CV/2025-11-21/papers/251116920v1-deltadeno-zero-shot-anomaly-generation-via-delta-denoising-attributi.html"},{"id":"2511.16887v2","title":"Glass Surface Detection: Leveraging Reflection Dynamics in Flash/No-flash Imagery","headline":"提出NFGlassNet，利用闪光/非闪光图像中的反射动态特性进行玻璃表面检测","tag":"cs.CV","date":"2025-11-21","url":"cs-CV/2025-11-21/papers/251116887v2-glass-surface-detection-leveraging-reflection-dynamics-in-flashno-fl.html"},{"id":"2511.16306v1","title":"InEKFormer: A Hybrid State Estimator for Humanoid Robots","headline":"提出InEKFormer混合状态估计器，提升人型机器人运动控制精度与鲁棒性","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116306v1-inekformer-a-hybrid-state-estimator-for-humanoid-robots.html"},{"id":"2511.16661v1","title":"Dexterity from Smart Lenses: Multi-Fingered Robot Manipulation with In-the-Wild Human Demonstrations","headline":"AINA框架：利用智能眼镜和人类演示学习多指机器人灵巧操作","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116661v1-dexterity-from-smart-lenses-multi-fingered-robot-manipulation-with-i.html"},{"id":"2511.16407v1","title":"LAOF: Robust Latent Action Learning with Optical Flow Constraints","headline":"提出LAOF：利用光流约束学习鲁棒的潜在动作表示，提升具身智能预训练效果","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116407v1-laof-robust-latent-action-learning-with-optical-flow-constraints.html"},{"id":"2511.16158v1","title":"MagBotSim: Physics-Based Simulation and Reinforcement Learning Environments for Magnetic Robotics","headline":"MagBotSim：用于磁力机器人控制的物理仿真与强化学习环境","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116158v1-magbotsim-physics-based-simulation-and-reinforcement-learning-enviro.html"},{"id":"2511.16050v1","title":"Bi-AQUA: Bilateral Control-Based Imitation Learning for Underwater Robot Arms via Lighting-Aware Action Chunking with Transformers","headline":"Bi-AQUA：基于双边控制的水下机器人臂光照感知模仿学习框架","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116050v1-bi-aqua-bilateral-control-based-imitation-learning-for-underwater-ro.html"},{"id":"2511.16330v1","title":"Safe and Optimal Variable Impedance Control via Certified Reinforcement Learning","headline":"提出C-GMS框架，通过认证强化学习实现安全且优化的变阻抗控制","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116330v1-safe-and-optimal-variable-impedance-control-via-certified-reinforcem.html"},{"id":"2511.16651v1","title":"InternData-A1: Pioneering High-Fidelity Synthetic Data for Pre-training Generalist Policy","headline":"InternData-A1：用于预训练通用策略的高保真合成数据集","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116651v1-interndata-a1-pioneering-high-fidelity-synthetic-data-for-pre-traini.html"},{"id":"2511.16406v1","title":"Homogeneous Proportional-Integral-Derivative Controller in Mobile Robotic Manipulators","headline":"提出一种用于移动机器人机械臂的齐次比例-积分-微分(hPID)控制策略，提升其运动控制的鲁棒性和协调性。","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116406v1-homogeneous-proportional-integral-derivative-controller-in-mobile-ro.html"},{"id":"2511.16048v1","title":"Semantic Glitch: Agency and Artistry in an Autonomous Pixel Cloud","headline":"提出基于多模态大语言模型的低精度自主导航框架，用于软体飞行机器人艺术装置。","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116048v1-semantic-glitch-agency-and-artistry-in-an-autonomous-pixel-cloud.html"},{"id":"2511.16372v2","title":"Flow-Aided Flight Through Dynamic Clutters From Point To Motion","headline":"提出基于点流辅助的强化学习方法，解决动态复杂环境中无人机自主飞行问题。","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116372v2-flow-aided-flight-through-dynamic-clutters-from-point-to-motion.html"},{"id":"2511.16223v1","title":"DynaMimicGen: A Data Generation Framework for Robot Learning of Dynamic Tasks","headline":"DynaMimicGen：一种用于动态任务机器人学习的数据生成框架","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116223v1-dynamimicgen-a-data-generation-framework-for-robot-learning-of-dynam.html"},{"id":"2511.16262v1","title":"How Robot Dogs See the Unseeable","headline":"机器人狗通过模仿动物Peering运动，实现合成孔径成像，克服遮挡问题","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251116262v1-how-robot-dogs-see-the-unseeable.html"},{"id":"2511.15995v1","title":"PushingBots: Collaborative Pushing via Neural Accelerated Combinatorial Hybrid Optimization","headline":"提出基于神经加速组合混合优化的多机器人协同推箱方法，解决复杂环境下的物体搬运问题。","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251115995v1-pushingbots-collaborative-pushing-via-neural-accelerated-combinatori.html"},{"id":"2511.15956v2","title":"The Role of Consequential and Functional Sound in Human-Robot Interaction: Toward Audio Augmented Reality Interfaces","headline":"探索声音在人机交互中的作用，为音频增强现实界面设计提供指导","tag":"cs.RO","date":"2025-11-20","url":"cs-RO/2025-11-20/papers/251115956v2-the-role-of-consequential-and-functional-sound-in-human-robot-intera.html"},{"id":"2511.16091v1","title":"Rad-GS: Radar-Vision Integration for 3D Gaussian Splatting SLAM in Outdoor Environments","headline":"Rad-GS：用于室外环境的雷达-视觉融合3D高斯溅射SLAM","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116091v1-rad-gs-radar-vision-integration-for-3d-gaussian-splatting-slam-in-ou.html"},{"id":"2511.16282v2","title":"Building temporally coherent 3D maps with VGGT for memory-efficient Semantic SLAM","headline":"提出基于VGGT的时序一致性3D地图构建方法，用于内存高效的语义SLAM","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116282v2-building-temporally-coherent-3d-maps-with-vggt-for-memory-efficient-.html"},{"id":"2511.16542v1","title":"EOGS++: Earth Observation Gaussian Splatting with Internal Camera Refinement and Direct Panchromatic Rendering","headline":"EOGS++：结合内部相机优化的地球观测高斯溅射，实现直接全色渲染","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116542v1-eogs-earth-observation-gaussian-splatting-with-internal-camera-refin.html"},{"id":"2511.16030v1","title":"CuriGS: Curriculum-Guided Gaussian Splatting for Sparse View Synthesis","headline":"CuriGS：面向稀疏视图合成的课程引导高斯溅射方法","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116030v1-curigs-curriculum-guided-gaussian-splatting-for-sparse-view-synthesi.html"},{"id":"2511.16144v1","title":"LEGO-SLAM: Language-Embedded Gaussian Optimization SLAM","headline":"LEGO-SLAM：基于语言嵌入高斯优化的实时开放词汇SLAM系统","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116144v1-lego-slam-language-embedded-gaussian-optimization-slam.html"},{"id":"2511.16555v1","title":"Lite Any Stereo: Efficient Zero-Shot Stereo Matching","headline":"提出Lite Any Stereo，实现高效的零样本立体匹配深度估计","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116555v1-lite-any-stereo-efficient-zero-shot-stereo-matching.html"},{"id":"2511.16494v1","title":"Physics-Informed Machine Learning for Efficient Sim-to-Real Data Augmentation in Micro-Object Pose Estimation","headline":"提出物理信息GAN，用于微型物体位姿估计的高效Sim-to-Real数据增强","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116494v1-physics-informed-machine-learning-for-efficient-sim-to-real-data-aug.html"},{"id":"2511.16567v2","title":"POMA-3D: The Point Map Way to 3D Scene Understanding","headline":"POMA-3D：提出基于点图的自监督3D场景理解模型，提升多项下游任务性能。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116567v2-poma-3d-the-point-map-way-to-3d-scene-understanding.html"},{"id":"2511.16349v1","title":"CRISTAL: Real-time Camera Registration in Static LiDAR Scans using Neural Rendering","headline":"CRISTAL：利用神经渲染在静态激光雷达扫描中进行实时相机注册","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116349v1-cristal-real-time-camera-registration-in-static-lidar-scans-using-ne.html"},{"id":"2511.16264v1","title":"Mem-MLP: Real-Time 3D Human Motion Generation from Sparse Inputs","headline":"Mem-MLP：基于稀疏输入的实时3D人体动作生成","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116264v1-mem-mlp-real-time-3d-human-motion-generation-from-sparse-inputs.html"},{"id":"2511.16711v1","title":"Motion Transfer-Enhanced StyleGAN for Generating Diverse Macaque Facial Expressions","headline":"提出基于运动迁移增强的StyleGAN，用于生成多样化的猕猴面部表情","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116711v1-motion-transfer-enhanced-stylegan-for-generating-diverse-macaque-fac.html"},{"id":"2511.16298v1","title":"Optimizing 3D Gaussian Splattering for Mobile GPUs","headline":"Texture3dgs：针对移动GPU优化的3D高斯溅射算法，提升排序效率与整体性能。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116298v1-optimizing-3d-gaussian-splattering-for-mobile-gpus.html"},{"id":"2511.16666v1","title":"SceneDesigner: Controllable Multi-Object Image Generation with 9-DoF Pose Manipulation","headline":"SceneDesigner：提出基于CNOCS Map和强化学习的两阶段训练方法，实现多物体9自由度姿态精确控制的图像生成。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116666v1-scenedesigner-controllable-multi-object-image-generation-with-9-dof-.html"},{"id":"2511.16221v1","title":"Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions","headline":"提出MIDA基准测试，评估多模态大语言模型在多人社交互动中识别欺骗的能力。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116221v1-can-mllms-read-the-room-a-multimodal-benchmark-for-assessing-decepti.html"},{"id":"2511.16161v1","title":"Simba: Towards High-Fidelity and Geometrically-Consistent Point Cloud Completion via Transformation Diffusion","headline":"Simba：基于变换扩散的高保真几何一致性点云补全","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116161v1-simba-towards-high-fidelity-and-geometrically-consistent-point-cloud.html"},{"id":"2511.16049v1","title":"LiSTAR: Ray-Centric World Models for 4D LiDAR Sequences in Autonomous Driving","headline":"LiSTAR：面向自动驾驶，提出基于射线中心世界模型的4D激光雷达序列生成方法","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116049v1-listar-ray-centric-world-models-for-4d-lidar-sequences-in-autonomous.html"},{"id":"2511.16857v2","title":"BOP-ASK: Object-Interaction Reasoning for Vision-Language Models","headline":"BOP-ASK：用于视觉-语言模型的目标交互推理数据集与基准","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116857v2-bop-ask-object-interaction-reasoning-for-vision-language-models.html"},{"id":"2511.16535v1","title":"Investigating Optical Flow Computation: From Local Methods to a Multiresolution Horn-Schunck Implementation with Bilinear Interpolation","headline":"研究光流计算：从局部方法到多分辨率Horn-Schunck算法与双线性插值","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116535v1-investigating-optical-flow-computation-from-local-methods-to-a-multi.html"},{"id":"2511.16524v1","title":"BoxingVI: A Multi-Modal Benchmark for Boxing Action Recognition and Localization","headline":"BoxingVI：一个用于拳击动作识别与定位的多模态基准数据集","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116524v1-boxingvi-a-multi-modal-benchmark-for-boxing-action-recognition-and-l.html"},{"id":"2511.16454v1","title":"LLaVA$^3$: Representing 3D Scenes like a Cubist Painter to Boost 3D Scene Understanding of VLMs","headline":"LLaVA$^3$：借鉴立体画派，提升VLM对3D场景的理解能力","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116454v1-llava3-representing-3d-scenes-like-a-cubist-painter-to-boost-3d-scen.html"},{"id":"2511.16428v1","title":"CylinderDepth: Cylindrical Spatial Attention for Multi-View Consistent Self-Supervised Surround Depth Estimation","headline":"CylinderDepth：利用柱面空间注意力实现多视角一致的自监督环视深度估计","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116428v1-cylinderdepth-cylindrical-spatial-attention-for-multi-view-consisten.html"},{"id":"2511.16140v1","title":"Real-Time 3D Object Detection with Inference-Aligned Learning","headline":"提出SR3D框架，通过推理对齐学习实现室内点云实时3D目标检测","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116140v1-real-time-3d-object-detection-with-inference-aligned-learning.html"},{"id":"2511.16112v1","title":"Clustered Error Correction with Grouped 4D Gaussian Splatting","headline":"提出基于聚类误差校正的分组4D高斯溅射方法，提升动态场景重建质量。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116112v1-clustered-error-correction-with-grouped-4d-gaussian-splatting.html"},{"id":"2511.16166v1","title":"EvoVLA: Self-Evolving Vision-Language-Action Model","headline":"EvoVLA：一种自进化视觉-语言-动作模型，解决长时程机器人操作中的阶段幻觉问题。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116166v1-evovla-self-evolving-vision-language-action-model.html"},{"id":"2511.16595v2","title":"TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding","headline":"TimeViper：一种混合Mamba-Transformer视觉-语言模型，用于高效长视频理解","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116595v2-timeviper-a-hybrid-mamba-transformer-vision-language-model-for-effic.html"},{"id":"2511.16541v2","title":"Supervised Contrastive Learning for Few-Shot AI-Generated Image Detection and Attribution","headline":"提出基于监督对比学习的框架，用于少样本AI生成图像检测与溯源。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116541v2-supervised-contrastive-learning-for-few-shot-ai-generated-image-dete.html"},{"id":"2511.16077v1","title":"VideoSeg-R1:Reasoning Video Object Segmentation via Reinforcement Learning","headline":"提出VideoSeg-R1，首个基于强化学习的视频推理分割框架，提升复杂场景泛化性。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116077v1-videoseg-r1reasoning-video-object-segmentation-via-reinforcement-lea.html"},{"id":"2511.16418v1","title":"End-to-End Motion Capture from Rigid Body Markers with Geodesic Loss","headline":"提出基于刚体标记和测地线损失的端到端人体运动捕捉方法","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116418v1-end-to-end-motion-capture-from-rigid-body-markers-with-geodesic-loss.html"},{"id":"2511.16301v2","title":"Upsample Anything: A Simple and Hard to Beat Baseline for Feature Upsampling","headline":"提出Upsample Anything，一种无需训练的特征上采样通用基线方法","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116301v2-upsample-anything-a-simple-and-hard-to-beat-baseline-for-feature-ups.html"},{"id":"2511.16020v2","title":"Physically Realistic Sequence-Level Adversarial Clothing for Robust Human-Detection Evasion","headline":"提出序列级对抗服装生成方法，提升人体检测规避在真实场景下的鲁棒性","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116020v2-physically-realistic-sequence-level-adversarial-clothing-for-robust-.html"},{"id":"2511.16807v1","title":"Mesh RAG: Retrieval Augmentation for Autoregressive Mesh Generation","headline":"Mesh RAG：用于自回归网格生成的检索增强框架，提升质量与速度。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116807v1-mesh-rag-retrieval-augmentation-for-autoregressive-mesh-generation.html"},{"id":"2511.16719v1","title":"SAM 3: Segment Anything with Concepts","headline":"SAM 3：基于概念提示的图像和视频通用分割模型","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116719v1-sam-3-segment-anything-with-concepts.html"},{"id":"2511.16650v1","title":"Late-decoupled 3D Hierarchical Semantic Segmentation with Semantic Prototype Discrimination based Bi-branch Supervision","headline":"提出基于语义原型判别的解耦3D层级语义分割框架，解决跨层级冲突和类别不平衡问题。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116650v1-late-decoupled-3d-hierarchical-semantic-segmentation-with-semantic-p.html"},{"id":"2511.16521v1","title":"YOWO: You Only Walk Once to Jointly Map An Indoor Scene and Register Ceiling-mounted Cameras","headline":"提出YOWO，单次行走即可完成室内场景地图构建与天花板相机注册","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116521v1-yowo-you-only-walk-once-to-jointly-map-an-indoor-scene-and-register-.html"},{"id":"2511.16449v2","title":"VLA-Pruner: Temporal-Aware Dual-Level Visual Token Pruning for Efficient Vision-Language-Action Inference","headline":"VLA-Pruner：面向高效视觉-语言-动作推理的时序感知双层视觉Token剪枝","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116449v2-vla-pruner-temporal-aware-dual-level-visual-token-pruning-for-effici.html"},{"id":"2511.16317v1","title":"NaTex: Seamless Texture Generation as Latent Color Diffusion","headline":"NaTex：提出一种基于潜在颜色扩散的无缝纹理生成框架，直接在3D空间预测纹理颜色。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116317v1-natex-seamless-texture-generation-as-latent-color-diffusion.html"},{"id":"2511.16203v3","title":"When Alignment Fails: Multimodal Adversarial Attacks on Vision-Language-Action Models","headline":"VLA-Fool：针对具身视觉-语言-动作模型的多模态对抗攻击研究","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116203v3-when-alignment-fails-multimodal-adversarial-attacks-on-vision-langua.html"},{"id":"2511.16175v1","title":"Mantis: A Versatile Vision-Language-Action Model with Disentangled Visual Foresight","headline":"Mantis：一种具有解耦视觉预测的多功能视觉-语言-动作模型","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116175v1-mantis-a-versatile-vision-language-action-model-with-disentangled-vi.html"},{"id":"2511.16712v2","title":"PairHuman: A High-Fidelity Photographic Dataset for Customized Dual-Person Generation","headline":"提出PairHuman数据集，用于高质量定制双人肖像生成，并提出DHumanDiff基线模型。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251116712v2-pairhuman-a-high-fidelity-photographic-dataset-for-customized-dual-p.html"},{"id":"2511.15948v2","title":"Click2Graph: Interactive Panoptic Video Scene Graphs from a Single Click","headline":"提出Click2Graph，通过单次点击实现交互式全景视频场景图生成。","tag":"cs.CV","date":"2025-11-20","url":"cs-CV/2025-11-20/papers/251115948v2-click2graph-interactive-panoptic-video-scene-graphs-from-a-single-cl.html"},{"id":"2511.16831v1","title":"Vorion: A RISC-V GPU with Hardware-Accelerated 3D Gaussian Rendering and Training","headline":"Vorion：首个硬件加速3D高斯渲染与训练的RISC-V GPU原型","tag":"cs.GR","date":"2025-11-20","url":"cs-GR/2025-11-20/papers/251116831v1-vorion-a-risc-v-gpu-with-hardware-accelerated-3d-gaussian-rendering-.html"},{"id":"2511.16520v1","title":"Saving Foundation Flow-Matching Priors for Inverse Problems","headline":"提出FMPlug框架，提升Flow-Matching模型在逆问题中的性能","tag":"cs.LG","date":"2025-11-20","url":"cs-LG/2025-11-20/papers/251116520v1-saving-foundation-flow-matching-priors-for-inverse-problems.html"},{"id":"2511.17656v1","title":"Multi-Agent Coordination in Autonomous Vehicle Routing: A Simulation-Based Study of Communication, Memory, and Routing Loops","headline":"提出对象记忆管理机制以解决自主车辆路由中的循环问题","tag":"cs.LG","date":"2025-11-20","url":"cs-LG/2025-11-20/papers/251117656v1-multi-agent-coordination-in-autonomous-vehicle-routing-a-simulation-.html"},{"id":"2511.16183v1","title":"FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos","headline":"提出FOOTPASS数据集，用于足球广播视频中基于战术上下文的多模态多智能体行为定位","tag":"cs.AI","date":"2025-11-20","url":"cs-AI/2025-11-20/papers/251116183v1-footpass-a-multi-modal-multi-agent-tactical-context-dataset-for-play.html"},{"id":"2511.15200v2","title":"VIRAL: Visual Sim-to-Real at Scale for Humanoid Loco-Manipulation","headline":"VIRAL：面向人形机器人loco-manipulation的大规模视觉Sim-to-Real框架","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115200v2-viral-visual-sim-to-real-at-scale-for-humanoid-loco-manipulation.html"},{"id":"2511.15239v1","title":"Symmetry-Breaking in Multi-Agent Navigation: Winding Number-Aware MPC with a Learned Topological Strategy","headline":"提出基于绕数感知的MPC方法，解决多智能体导航中的对称性破缺问题","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115239v1-symmetry-breaking-in-multi-agent-navigation-winding-number-aware-mpc.html"},{"id":"2511.15532v1","title":"NMPC-based Motion Planning with Adaptive Weighting for Dynamic Object Interception","headline":"提出基于自适应权重NMPC的运动规划方法，用于双臂协作机器人动态目标拦截","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115532v1-nmpc-based-motion-planning-with-adaptive-weighting-for-dynamic-objec.html"},{"id":"2511.15704v1","title":"In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data","headline":"利用真实场景和任务数据，扩展第一视角操作策略学习。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115704v1-in-n-on-scaling-egocentric-manipulation-with-in-the-wild-and-on-task.html"},{"id":"2511.15194v1","title":"Eq.Bot: Enhance Robotic Manipulation Learning via Group Equivariant Canonicalization","headline":"Eq.Bot：通过群等变规范化增强机器人操作学习","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115194v1-eqbot-enhance-robotic-manipulation-learning-via-group-equivariant-ca.html"},{"id":"2511.15414v1","title":"RRT*former: Environment-Aware Sampling-Based Motion Planning using Transformer","headline":"RRT*former：利用Transformer进行环境感知采样的机器人运动规划","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115414v1-rrtformer-environment-aware-sampling-based-motion-planning-using-tra.html"},{"id":"2511.15358v1","title":"Platform-Agnostic Reinforcement Learning Framework for Safe Exploration of Cluttered Environments with Graph Attention","headline":"提出一种平台无关的强化学习框架，结合图注意力机制实现复杂环境安全探索。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115358v1-platform-agnostic-reinforcement-learning-framework-for-safe-explorat.html"},{"id":"2511.14994v1","title":"Communication-Aware Asynchronous Distributed Trajectory Optimization for UAV Swarm","headline":"提出通信感知异步分布式轨迹优化算法，解决无人机集群在通信受限环境下的轨迹规划问题。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251114994v1-communication-aware-asynchronous-distributed-trajectory-optimization.html"},{"id":"2511.15605v2","title":"SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models","headline":"提出SRPO，利用自参照策略优化视觉-语言-动作模型，解决奖励稀疏问题。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115605v2-srpo-self-referential-policy-optimization-for-vision-language-action.html"},{"id":"2511.15520v1","title":"Theoretical Closed-loop Stability Bounds for Dynamical System Coupled with Diffusion Policies","headline":"提出扩散策略闭环稳定性理论边界，加速机器人实时控制","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115520v1-theoretical-closed-loop-stability-bounds-for-dynamical-system-couple.html"},{"id":"2511.15284v1","title":"Path Planning through Multi-Agent Reinforcement Learning in Dynamic Environments","headline":"提出一种基于多智能体强化学习的动态环境路径规划方法","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115284v1-path-planning-through-multi-agent-reinforcement-learning-in-dynamic-.html"},{"id":"2511.15274v1","title":"Behavior Trees vs Executable Ontologies: a Comparative Analysis of Robot Control Paradigms","headline":"提出基于可执行本体的机器人控制框架，解决传统机器人控制的语义鸿沟问题。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115274v1-behavior-trees-vs-executable-ontologies-a-comparative-analysis-of-ro.html"},{"id":"2511.15279v1","title":"Look, Zoom, Understand: The Robotic Eyeball for Embodied Perception","headline":"提出EyeVLA：一种用于具身感知的机器人眼球，实现主动视觉信息获取。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115279v1-look-zoom-understand-the-robotic-eyeball-for-embodied-perception.html"},{"id":"2511.15614v1","title":"Optimus-Q: Utilizing Federated Learning in Adaptive Robots for Intelligent Nuclear Power Plant Operations through Quantum Cryptography","headline":"Optimus-Q：利用联邦学习和量子密码技术，提升核电站自适应机器人的智能化水平。","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115614v1-optimus-q-utilizing-federated-learning-in-adaptive-robots-for-intell.html"},{"id":"2511.15513v1","title":"Discovering Optimal Natural Gaits of Dissipative Systems via Virtual Energy Injection","headline":"提出基于虚拟能量注入的框架，用于发现耗散系统中能量最优的自然步态","tag":"cs.RO","date":"2025-11-19","url":"cs-RO/2025-11-19/papers/251115513v1-discovering-optimal-natural-gaits-of-dissipative-systems-via-virtual.html"},{"id":"2511.15102v1","title":"Gaussian Blending: Rethinking Alpha Blending in 3D Gaussian Splatting","headline":"提出高斯混合：重新思考3D高斯溅射中的Alpha混合，提升新视角合成质量","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115102v1-gaussian-blending-rethinking-alpha-blending-in-3d-gaussian-splatting.html"},{"id":"2511.15308v1","title":"Text2Loc++: Generalizing 3D Point Cloud Localization from Natural Language","headline":"Text2Loc++：提出一种基于自然语言的通用3D点云定位方法","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115308v1-text2loc-generalizing-3d-point-cloud-localization-from-natural-langu.html"},{"id":"2511.15077v1","title":"MambaTrack3D: A State Space Model Framework for LiDAR-Based Object Tracking under High Temporal Variation","headline":"MambaTrack3D：基于状态空间模型的LiDAR高时间变化目标跟踪框架","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115077v1-mambatrack3d-a-state-space-model-framework-for-lidar-based-object-tr.html"},{"id":"2511.15046v1","title":"UniHOI: Unified Human-Object Interaction Understanding via Unified Token Space","headline":"UniHOI：通过统一Token空间实现统一的人-物交互理解","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115046v1-unihoi-unified-human-object-interaction-understanding-via-unified-to.html"},{"id":"2511.15705v1","title":"GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization","headline":"提出GeoVista，一个基于Web增强的Agentic视觉推理模型，用于地理定位任务。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115705v1-geovista-web-augmented-agentic-visual-reasoning-for-geolocalization.html"},{"id":"2511.15884v1","title":"Box6D : Zero-shot Category-level 6D Pose Estimation of Warehouse Boxes","headline":"Box6D：面向仓库箱体的零样本类别级6D位姿估计","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115884v1-box6d-zero-shot-category-level-6d-pose-estimation-of-warehouse-boxes.html"},{"id":"2511.15874v1","title":"WALDO: Where Unseen Model-based 6D Pose Estimation Meets Occlusion","headline":"WALDO：提出一种新颖的基于模型的6D位姿估计方法，提升遮挡场景下的鲁棒性。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115874v1-waldo-where-unseen-model-based-6d-pose-estimation-meets-occlusion.html"},{"id":"2511.15580v3","title":"CompTrack: Information Bottleneck-Guided Low-Rank Dynamic Token Compression for Point Cloud Tracking","headline":"CompTrack：信息瓶颈引导的低秩动态Token压缩，用于点云单目标跟踪。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115580v3-comptrack-information-bottleneck-guided-low-rank-dynamic-token-compr.html"},{"id":"2511.15167v1","title":"Learning Depth from Past Selves: Self-Evolution Contrast for Robust Depth Estimation","headline":"提出自进化对比学习框架SEC-Depth，提升恶劣天气下自监督深度估计的鲁棒性","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115167v1-learning-depth-from-past-selves-self-evolution-contrast-for-robust-d.html"},{"id":"2511.15645v1","title":"MambaIO: Global-Coordinate Inertial Odometry for Pedestrians via Multi-Scale Frequency-Decoupled Modeling","headline":"MambaIO：面向行人惯性里程计的多尺度解耦建模方法","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115645v1-mambaio-global-coordinate-inertial-odometry-for-pedestrians-via-mult.html"},{"id":"2511.15706v2","title":"RoMa v2: Harder Better Faster Denser Feature Matching","headline":"RoMa v2：通过架构、训练和优化，显著提升密集特征匹配的精度与速度。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115706v2-roma-v2-harder-better-faster-denser-feature-matching.html"},{"id":"2511.15201v1","title":"Towards Unbiased Cross-Modal Representation Learning for Food Image-to-Recipe Retrieval","headline":"提出基于因果推断的解偏方法，提升食物图像-菜谱跨模态检索性能","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115201v1-towards-unbiased-cross-modal-representation-learning-for-food-image-.html"},{"id":"2511.15066v1","title":"BokehFlow: Depth-Free Controllable Bokeh Rendering via Flow Matching","headline":"提出BokehFlow，一种基于Flow Matching的无深度信息可控焦外成像方法","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115066v1-bokehflow-depth-free-controllable-bokeh-rendering-via-flow-matching.html"},{"id":"2511.15153v1","title":"SceneEdited: A City-Scale Benchmark for 3D HD Map Updating via Image-Guided Change Detection","headline":"SceneEdited：提出城市级3D高清地图更新基准，通过图像引导的变更检测。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115153v1-sceneedited-a-city-scale-benchmark-for-3d-hd-map-updating-via-image-.html"},{"id":"2511.15567v1","title":"Computer-Use Agents as Judges for Generative User Interface","headline":"提出Coder-CUA协同框架，利用计算机代理辅助代码生成GUI的设计，提升任务解决能力。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115567v1-computer-use-agents-as-judges-for-generative-user-interface.html"},{"id":"2511.15396v1","title":"ShelfOcc: Native 3D Supervision beyond LiDAR for Vision-Based Occupancy Estimation","headline":"ShelfOcc：提出一种纯视觉的3D体素占据估计方法，无需激光雷达即可实现原生3D监督。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115396v1-shelfocc-native-3d-supervision-beyond-lidar-for-vision-based-occupan.html"},{"id":"2511.15322v1","title":"Adaptive thresholding pattern for fingerprint forgery detection","headline":"提出基于自适应阈值模式的指纹伪造检测算法，提升抗干扰能力。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115322v1-adaptive-thresholding-pattern-for-fingerprint-forgery-detection.html"},{"id":"2511.15311v2","title":"Adapt-As-You-Walk Through the Clouds: Training-Free Online Test-Time Adaptation of 3D Vision-Language Foundation Models","headline":"提出Uni-Adapter，一种免训练的3D视觉-语言模型在线测试时自适应方法。","tag":"cs.CV","date":"2025-11-19","url":"cs-CV/2025-11-19/papers/251115311v2-adapt-as-you-walk-through-the-clouds-training-free-online-test-time-.html"},{"id":"2511.15908v1","title":"SPHaptics: A Real-Time Bidirectional Haptic Interaction Framework for Coupled Rigid-Soft Body and Lagrangian Fluid Simulation in Virtual Environments","headline":"SPHaptics：用于虚拟环境中刚体-软体耦合及拉格朗日流体实时双向触觉交互框架","tag":"cs.GR","date":"2025-11-19","url":"cs-GR/2025-11-19/papers/251115908v1-sphaptics-a-real-time-bidirectional-haptic-interaction-framework-for.html"},{"id":"2511.15398v1","title":"One algebra for all : Geometric Algebra methods for neurosymbolic XR scene authoring, animation and neural rendering","headline":"利用几何代数统一神经符号XR场景创作、动画与神经渲染","tag":"cs.GR","date":"2025-11-19","url":"cs-GR/2025-11-19/papers/251115398v1-one-algebra-for-all-geometric-algebra-methods-for-neurosymbolic-xr-s.html"},{"id":"2511.15256v1","title":"GRPO-RM: Fine-Tuning Representation Models via GRPO-Driven Reinforcement Learning","headline":"提出GRPO-RM，通过GRPO驱动的强化学习微调表征模型","tag":"cs.LG","date":"2025-11-19","url":"cs-LG/2025-11-19/papers/251115256v1-grpo-rm-fine-tuning-representation-models-via-grpo-driven-reinforcem.html"},{"id":"2511.15055v1","title":"Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization","headline":"提出基于轨迹优化的动作量化方法MAQ，提升强化学习Agent的人类相似度","tag":"cs.AI","date":"2025-11-19","url":"cs-AI/2025-11-19/papers/251115055v1-learning-human-like-rl-agents-through-trajectory-optimization-with-a.html"},{"id":"2511.15351v2","title":"Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration","headline":"Octopus：基于六大能力编排的Agentic多模态推理框架","tag":"cs.AI","date":"2025-11-19","url":"cs-AI/2025-11-19/papers/251115351v2-octopus-agentic-multimodal-reasoning-with-six-capability-orchestrati.html"},{"id":"2511.15090v1","title":"BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer","headline":"提出BBox DocVQA数据集，增强文档视觉问答中空间推理能力。","tag":"cs.AI","date":"2025-11-19","url":"cs-AI/2025-11-19/papers/251115090v1-bbox-docvqa-a-large-scale-bounding-box-grounded-dataset-for-enhancin.html"},{"id":"2511.19451v1","title":"Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control","headline":"提出基于强对偶和对偶上升的连续时间随机最优控制方法","tag":"eess.SY","date":"2025-11-19","url":"eess-SY/2025-11-19/papers/251119451v1-strong-duality-and-dual-ascent-approach-to-continuous-time-chance-co.html"},{"id":"2511.14625v1","title":"Gallant: Voxel Grid-based Humanoid Locomotion and Local-navigation across 3D Constrained Terrains","headline":"Gallant：基于体素栅格的人形机器人三维约束地形运动与局部导航","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114625v1-gallant-voxel-grid-based-humanoid-locomotion-and-local-navigation-ac.html"},{"id":"2511.14161v2","title":"RoboTidy : A 3D Gaussian Splatting Household Tidying Benchmark for Embodied Navigation and Action","headline":"RoboTidy：用于具身导航与操作的3D高斯溅射家庭整理基准","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114161v2-robotidy-a-3d-gaussian-splatting-household-tidying-benchmark-for-emb.html"},{"id":"2512.00049v1","title":"Socially aware navigation for mobile robots: a survey on deep reinforcement learning approaches","headline":"综述深度强化学习在社会意识导航中的应用与挑战","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251200049v1-socially-aware-navigation-for-mobile-robots-a-survey-on-deep-reinfor.html"},{"id":"2511.14756v1","title":"HMC: Learning Heterogeneous Meta-Control for Contact-Rich Loco-Manipulation","headline":"提出异构元控制HMC框架，解决接触丰富的移动操作任务","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114756v1-hmc-learning-heterogeneous-meta-control-for-contact-rich-loco-manipu.html"},{"id":"2511.14330v1","title":"MA-SLAM: Active SLAM in Large-Scale Unknown Environment using Map Aware Deep Reinforcement Learning","headline":"MA-SLAM：基于地图感知的深度强化学习，用于大规模未知环境的主动SLAM","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114330v1-ma-slam-active-slam-in-large-scale-unknown-environment-using-map-awa.html"},{"id":"2511.14335v2","title":"Simultaneous Localization and 3D-Semi Dense Mapping for Micro Drones Using Monocular Camera and Inertial Sensors","headline":"提出一种轻量级单目视觉惯性SLAM系统，用于微型无人机同时定位与半稠密地图构建。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114335v2-simultaneous-localization-and-3d-semi-dense-mapping-for-micro-drones.html"},{"id":"2511.14427v1","title":"Self-Supervised Multisensory Pretraining for Contact-Rich Robot Reinforcement Learning","headline":"提出MSDP，用于接触式机器人强化学习的多模态自监督预训练。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114427v1-self-supervised-multisensory-pretraining-for-contact-rich-robot-rein.html"},{"id":"2511.17603v1","title":"Translating Cultural Choreography from Humanoid Forms to Robotic Arm","headline":"提出ROPERA框架，实现六自由度机械臂对昆曲文化动作的语义保真复现","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251117603v1-translating-cultural-choreography-from-humanoid-forms-to-robotic-arm.html"},{"id":"2512.00050v1","title":"Reinforcement Learning from Implicit Neural Feedback for Human-Aligned Robot Control","headline":"提出基于隐式神经反馈的强化学习方法，用于人机协作机器人控制","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251200050v1-reinforcement-learning-from-implicit-neural-feedback-for-human-align.html"},{"id":"2511.14148v1","title":"AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models","headline":"AsyncVLA：面向视觉-语言-动作模型的异步流匹配，提升长时任务的稳定性和自纠错能力","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114148v1-asyncvla-asynchronous-flow-matching-for-vision-language-action-model.html"},{"id":"2511.14659v1","title":"NORA-1.5: A Vision-Language-Action Model Trained using World Model- and Action-based Preference Rewards","headline":"NORA-1.5：基于世界模型和动作偏好奖励训练的视觉-语言-动作模型，提升具身智能体的可靠性。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114659v1-nora-15-a-vision-language-action-model-trained-using-world-model-and.html"},{"id":"2511.14396v3","title":"Continuous Vision-Language-Action Co-Learning with Semantic-Physical Alignment for Behavioral Cloning","headline":"提出CCoL框架，通过语义-物理对齐的连续视觉-语言-动作协同学习提升行为克隆性能","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114396v3-continuous-vision-language-action-co-learning-with-semantic-physical.html"},{"id":"2511.14139v1","title":"FlexiCup: Wireless Multimodal Suction Cup with Dual-Zone Vision-Tactile Sensing","headline":"FlexiCup：集成双区视觉-触觉传感的无线多模态吸盘，用于非结构化环境下的接触感知操作。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114139v1-flexicup-wireless-multimodal-suction-cup-with-dual-zone-vision-tacti.html"},{"id":"2511.14037v1","title":"BIM-Discrepancy-Driven Active Sensing for Risk-Aware UAV-UGV Navigation","headline":"提出基于BIM差异驱动的主动感知框架，用于风险感知的无人机-无人车协同导航","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114037v1-bim-discrepancy-driven-active-sensing-for-risk-aware-uav-ugv-navigat.html"},{"id":"2511.14910v1","title":"Z-Merge: Multi-Agent Reinforcement Learning for On-Ramp Merging with Zone-Specific V2X Traffic Information","headline":"Z-Merge：利用区域V2X交通信息的多智能体强化学习匝道汇流","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114910v1-z-merge-multi-agent-reinforcement-learning-for-on-ramp-merging-with-.html"},{"id":"2511.14341v1","title":"Going Places: Place Recognition in Artificial and Natural Systems","headline":"综述：人工与自然系统中的地点识别研究","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114341v1-going-places-place-recognition-in-artificial-and-natural-systems.html"},{"id":"2511.14565v1","title":"Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language","headline":"提出Masked IRL以解决机器人奖励函数模糊问题","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114565v1-masked-irl-llm-guided-reward-disambiguation-from-demonstrations-and-.html"},{"id":"2511.14755v1","title":"Robust Verification of Controllers under State Uncertainty via Hamilton-Jacobi Reachability Analysis","headline":"提出RoVer-CoRe框架，通过Hamilton-Jacobi可达性分析实现状态不确定性下控制器的鲁棒验证。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114755v1-robust-verification-of-controllers-under-state-uncertainty-via-hamil.html"},{"id":"2511.14178v1","title":"Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion","headline":"提出VLA-Pilot，无需微调即可实现VLA模型在机器人操作任务中的即插即用策略引导。","tag":"cs.RO","date":"2025-11-18","url":"cs-RO/2025-11-18/papers/251114178v1-towards-deploying-vla-without-fine-tuning-plug-and-play-inference-ti.html"},{"id":"2511.14149v1","title":"iGaussian: Real-Time Camera Pose Estimation via Feed-Forward 3D Gaussian Splatting Inversion","headline":"提出iGaussian以解决实时相机位姿估计问题","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114149v1-igaussian-real-time-camera-pose-estimation-via-feed-forward-3d-gauss.html"},{"id":"2511.14633v1","title":"SparseSurf: Sparse-View 3D Gaussian Splatting for Surface Reconstruction","headline":"SparseSurf：稀疏视图下基于3D高斯溅射的表面重建","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114633v1-sparsesurf-sparse-view-3d-gaussian-splatting-for-surface-reconstruct.html"},{"id":"2511.14107v1","title":"RTS-Mono: A Real-Time Self-Supervised Monocular Depth Estimation Method for Real-World Deployment","headline":"RTS-Mono：一种用于真实世界部署的实时自监督单目深度估计方法","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114107v1-rts-mono-a-real-time-self-supervised-monocular-depth-estimation-meth.html"},{"id":"2511.14848v1","title":"Gaussian See, Gaussian Do: Semantic 3D Motion Transfer from Multiview Video","headline":"提出Gaussian See, Gaussian Do，实现多视角视频的语义3D动作迁移","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114848v1-gaussian-see-gaussian-do-semantic-3d-motion-transfer-from-multiview-.html"},{"id":"2511.14970v1","title":"EGSA-PT:Edge-Guided Spatial Attention with Progressive Training for Monocular Depth Estimation and Segmentation of Transparent Objects","headline":"提出EGSA-PT，通过边缘引导空间注意力和渐进式训练提升透明物体深度估计与分割性能","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114970v1-egsa-ptedge-guided-spatial-attention-with-progressive-training-for-m.html"},{"id":"2511.14386v3","title":"Cheating Stereo Matching in Full-scale: Physical Adversarial Attack against Binocular Depth Estimation in Autonomous Driving","headline":"提出纹理增强的3D物理对抗攻击，欺骗自动驾驶双目深度估计","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114386v3-cheating-stereo-matching-in-full-scale-physical-adversarial-attack-a.html"},{"id":"2511.14357v1","title":"IBGS: Image-Based Gaussian Splatting","headline":"提出基于图像的高斯溅射，提升新视角合成质量，无需增加存储。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114357v1-ibgs-image-based-gaussian-splatting.html"},{"id":"2511.14259v2","title":"ManipShield: A Unified Framework for Image Manipulation Detection, Localization and Explanation","headline":"提出ManipShield，一个统一的图像篡改检测、定位和解释框架，并构建大规模基准测试集ManipBench。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114259v2-manipshield-a-unified-framework-for-image-manipulation-detection-loc.html"},{"id":"2511.14315v1","title":"Dental3R: Geometry-Aware Pairing for Intraoral 3D Reconstruction from Sparse-View Photographs","headline":"Dental3R：针对稀疏视角口腔照片，提出几何感知配对的3D重建方法","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114315v1-dental3r-geometry-aware-pairing-for-intraoral-3d-reconstruction-from.html"},{"id":"2511.14238v1","title":"Enhancing Generalization of Depth Estimation Foundation Model via Weakly-Supervised Adaptation with Regularization","headline":"提出WeSTAR框架，通过弱监督自训练和正则化提升深度估计基础模型泛化能力","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114238v1-enhancing-generalization-of-depth-estimation-foundation-model-via-we.html"},{"id":"2511.14540v1","title":"Interaction-Aware 4D Gaussian Splatting for Dynamic Hand-Object Interaction Reconstruction","headline":"提出交互感知4D高斯溅射，用于动态手-物交互重建","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114540v1-interaction-aware-4d-gaussian-splatting-for-dynamic-hand-object-inte.html"},{"id":"2511.19448v1","title":"PuzzlePoles: Cylindrical Fiducial Markers Based on the PuzzleBoard Pattern","headline":"提出PuzzlePole圆柱形标志物，用于自主系统中的精确标定与定位","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251119448v1-puzzlepoles-cylindrical-fiducial-markers-based-on-the-puzzleboard-pa.html"},{"id":"2511.14179v2","title":"DoGCLR: Dominance-Game Contrastive Learning Network for Skeleton-Based Action Recognition","headline":"提出DoGCLR，通过支配博弈对比学习提升骨骼动作识别性能。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114179v2-dogclr-dominance-game-contrastive-learning-network-for-skeleton-base.html"},{"id":"2511.14918v1","title":"X-WIN: Building Chest Radiograph World Model via Predictive Sensing","headline":"X-WIN：通过预测感知构建胸部X光片世界模型","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114918v1-x-win-building-chest-radiograph-world-model-via-predictive-sensing.html"},{"id":"2511.14639v1","title":"SLAM-AGS: Slide-Label Aware Multi-Task Pretraining Using Adaptive Gradient Surgery in Computational Cytology","headline":"SLAM-AGS：计算细胞学中基于自适应梯度手术的Slide-Label感知多任务预训练","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114639v1-slam-ags-slide-label-aware-multi-task-pretraining-using-adaptive-gra.html"},{"id":"2511.17619v1","title":"Rethinking the Encoding and Annotating of 3D Bounding Box: Corner-Aware 3D Object Detection from Point Clouds","headline":"提出角点对齐回归的3D目标检测方法，解决中心对齐回归在LiDAR点云中的不稳定性问题","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251117619v1-rethinking-the-encoding-and-annotating-of-3d-bounding-box-corner-awa.html"},{"id":"2511.14503v1","title":"Parameter Aware Mamba Model for Multi-task Dense Prediction","headline":"提出参数感知Mamba模型PAMM，用于多任务密集预测，提升任务间互联性。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114503v1-parameter-aware-mamba-model-for-multi-task-dense-prediction.html"},{"id":"2511.14270v2","title":"Gaussian Splatting-based Low-Rank Tensor Representation for Multi-Dimensional Image Recovery","headline":"提出基于高斯溅射的低秩张量表示GSLR，用于多维图像恢复，提升局部高频信息捕捉能力。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114270v2-gaussian-splatting-based-low-rank-tensor-representation-for-multi-di.html"},{"id":"2511.14247v1","title":"V2VLoc: Robust GNSS-Free Collaborative Perception via LiDAR Localization","headline":"提出V2VLoc框架，通过激光雷达定位实现GNSS拒止环境下的鲁棒协同感知。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114247v1-v2vloc-robust-gnss-free-collaborative-perception-via-lidar-localizat.html"},{"id":"2511.14093v1","title":"SMGeo: Cross-View Object Geo-Localization with Grid-Level Mixture-of-Experts","headline":"SMGeo：提出基于网格级混合专家模型的跨视角目标地理定位方法","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114093v1-smgeo-cross-view-object-geo-localization-with-grid-level-mixture-of-.html"},{"id":"2511.14086v1","title":"Error-Driven Scene Editing for 3D Grounding in Large Language Models","headline":"提出DEER-3D框架，通过误差驱动的场景编辑提升3D-LLM的空间理解能力","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114086v1-error-driven-scene-editing-for-3d-grounding-in-large-language-models.html"},{"id":"2511.14019v1","title":"RISE: Single Static Radar-based Indoor Scene Understanding","headline":"RISE：基于单静态雷达的室内场景理解，利用多径反射提升几何推理能力","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114019v1-rise-single-static-radar-based-indoor-scene-understanding.html"},{"id":"2511.14291v1","title":"GEN3D: Generating Domain-Free 3D Scenes from a Single Image","headline":"GEN3D：提出一种从单张图像生成无领域限制的3D场景的方法","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114291v1-gen3d-generating-domain-free-3d-scenes-from-a-single-image.html"},{"id":"2511.14100v1","title":"Text-Driven Reasoning Video Editing via Reinforcement Learning on Digital Twin Representations","headline":"提出RIVER模型，通过数字孪生和强化学习解决文本驱动的推理视频编辑任务。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114100v1-text-driven-reasoning-video-editing-via-reinforcement-learning-on-di.html"},{"id":"2511.17609v1","title":"3D Ground Truth Reconstruction from Multi-Camera Annotations Using UKF","headline":"提出一种基于UKF的多相机2D标注融合3D重建方法，用于自动驾驶等场景。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251117609v1-3d-ground-truth-reconstruction-from-multi-camera-annotations-using-u.html"},{"id":"2511.14716v1","title":"Diffusion As Self-Distillation: End-to-End Latent Diffusion In One Model","headline":"提出DSD框架，实现端到端潜在扩散模型单网络训练，解决多阶段训练低效问题。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114716v1-diffusion-as-self-distillation-end-to-end-latent-diffusion-in-one-mo.html"},{"id":"2511.14927v1","title":"CPSL: Representing Volumetric Video via Content-Promoted Scene Layers","headline":"提出内容驱动的场景层CPSL，用于高效表示和渲染体积视频。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114927v1-cpsl-representing-volumetric-video-via-content-promoted-scene-layers.html"},{"id":"2511.14751v1","title":"Co-Me: Confidence-Guided Token Merging for Visual Geometric Transformers","headline":"提出Co-Me，加速视觉几何Transformer，无需重训练即可实现高达11.3倍的加速。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114751v1-co-me-confidence-guided-token-merging-for-visual-geometric-transform.html"},{"id":"2511.14654v1","title":"Improving segmentation of retinal arteries and veins using cardiac signal in doppler holograms","headline":"利用心动信号增强多普勒全息图中视网膜动静脉分割","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114654v1-improving-segmentation-of-retinal-arteries-and-veins-using-cardiac-s.html"},{"id":"2511.14376v1","title":"A Quantitative Method for Shoulder Presentation Evaluation in Biometric Identity Documents","headline":"提出肩部姿态评估算法SPE，用于生物特征身份文件中肩部合规性自动检查。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114376v1-a-quantitative-method-for-shoulder-presentation-evaluation-in-biomet.html"},{"id":"2511.14368v1","title":"O3SLM: Open Weight, Open Data, and Open Vocabulary Sketch-Language Model","headline":"O3SLM：开放权重、数据和词汇的草图-语言模型，提升抽象视觉输入理解能力。","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114368v1-o3slm-open-weight-open-data-and-open-vocabulary-sketch-language-mode.html"},{"id":"2511.14283v1","title":"NeuralSSD: A Neural Solver for Signed Distance Surface Reconstruction","headline":"NeuralSSD：一种基于神经求解器的有向距离场表面重建方法","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114283v1-neuralssd-a-neural-solver-for-signed-distance-surface-reconstruction.html"},{"id":"2511.14210v2","title":"Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution","headline":"Orion：一个用于多模态感知、高级视觉推理和执行的统一视觉Agent","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114210v2-orion-a-unified-visual-agent-for-multimodal-perception-advanced-visu.html"},{"id":"2511.14152v2","title":"Wave-Former: Through-Occlusion 3D Reconstruction via Wireless Shape Completion","headline":"Wave-Former：利用无线信号形状补全实现穿透遮挡的三维重建","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114152v2-wave-former-through-occlusion-3d-reconstruction-via-wireless-shape-c.html"},{"id":"2511.14120v1","title":"Multi-view Phase-aware Pedestrian-Vehicle Incident Reasoning Framework with Vision-Language Models","headline":"提出MP-PVIR框架，利用多视角和视觉-语言模型解决行人-车辆事故的推理问题","tag":"cs.CV","date":"2025-11-18","url":"cs-CV/2025-11-18/papers/251114120v1-multi-view-phase-aware-pedestrian-vehicle-incident-reasoning-framewo.html"},{"id":"2511.14205v1","title":"FreeMusco: Motion-Free Learning of Latent Control for Morphology-Adaptive Locomotion in Musculoskeletal Characters","headline":"FreeMusco：用于肌肉骨骼角色形态自适应运动的无运动数据潜在控制学习","tag":"cs.GR","date":"2025-11-18","url":"cs-GR/2025-11-18/papers/251114205v1-freemusco-motion-free-learning-of-latent-control-for-morphology-adap.html"},{"id":"2511.14515v2","title":"IMSE: Efficient U-Net-based Speech Enhancement using Inception Depthwise Convolution and Amplitude-Aware Linear Attention","headline":"IMSE：利用Inception深度可分离卷积和幅度感知线性注意力的高效U-Net语音增强","tag":"cs.AI","date":"2025-11-18","url":"cs-AI/2025-11-18/papers/251114515v2-imse-efficient-u-net-based-speech-enhancement-using-inception-depthw.html"},{"id":"2511.14311v1","title":"Multi-Timescale Model Predictive Control for Slow-Fast Systems","headline":"针对快慢混合系统，提出多时间尺度模型预测控制方法，提升计算效率。","tag":"eess.SY","date":"2025-11-18","url":"eess-SY/2025-11-18/papers/251114311v1-multi-timescale-model-predictive-control-for-slow-fast-systems.html"},{"id":"2511.12972v1","title":"SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models","headline":"SplatSearch：利用3D高斯溅射和扩散模型实现移动机器人实例图像目标导航","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112972v1-splatsearch-instance-image-goal-navigation-for-mobile-robots-using-3.html"},{"id":"2511.12912v1","title":"DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping","headline":"DiffuDepGrasp：基于扩散模型的深度噪声建模实现Sim2Real机器人抓取","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112912v1-diffudepgrasp-diffusion-based-depth-noise-modeling-empowers-sim2real.html"},{"id":"2511.13188v1","title":"Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control","headline":"提出基于四叉树和模型预测控制的移动机器人无碰撞导航方法","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113188v1-collision-free-navigation-of-mobile-robots-via-quadtree-based-model-.html"},{"id":"2511.13327v1","title":"ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning","headline":"ZeroDexGrasp：基于提示的多阶段语义推理零样本灵巧抓取合成","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113327v1-zerodexgrasp-zero-shot-task-oriented-dexterous-grasp-synthesis-with-.html"},{"id":"2511.13985v1","title":"LIO-MARS: Non-uniform Continuous-time Trajectories for Real-time LiDAR-Inertial-Odometry","headline":"LIO-MARS：基于非均匀连续时间轨迹的实时激光雷达惯性里程计","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113985v1-lio-mars-non-uniform-continuous-time-trajectories-for-real-time-lida.html"},{"id":"2511.13710v1","title":"From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands","headline":"联合优化控制与指尖几何，提升多指灵巧手精细操作能力","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113710v1-from-power-to-precision-learning-fine-grained-dexterity-for-multi-fi.html"},{"id":"2511.13216v1","title":"GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry","headline":"GaRLILEO：一种重力对齐的雷达-腿-惯性增强里程计，用于腿式机器人。","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113216v1-garlileo-gravity-aligned-radar-leg-inertial-enhanced-odometry.html"},{"id":"2511.13459v1","title":"Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness","headline":"提出基于ProMP重参数化和能量感知的接触安全强化学习框架","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113459v1-contact-safe-reinforcement-learning-with-promp-reparameterization-an.html"},{"id":"2511.12848v1","title":"Structured Imitation Learning of Interactive Policies through Inverse Games","headline":"通过逆向博弈的结构化模仿学习交互策略","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112848v1-structured-imitation-learning-of-interactive-policies-through-invers.html"},{"id":"2511.13207v1","title":"PIGEON: VLM-Driven Object Navigation via Points of Interest Selection","headline":"PIGEON：基于视觉语言模型和兴趣点选择的物体导航方法","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113207v1-pigeon-vlm-driven-object-navigation-via-points-of-interest-selection.html"},{"id":"2511.12882v2","title":"Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos","headline":"提出MTV-World，利用多视角轨迹视频实现高一致性的具身世界模型","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112882v2-towards-high-consistency-embodied-world-model-with-multi-view-trajec.html"},{"id":"2511.13963v1","title":"Hessians in Birkhoff-Theoretic Trajectory Optimization","headline":"推导Birkhoff理论轨迹优化中的Hessian矩阵，揭示其特征值分布规律","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113963v1-hessians-in-birkhoff-theoretic-trajectory-optimization.html"},{"id":"2511.13312v1","title":"EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation","headline":"EL3DD：扩展潜在3D扩散模型，用于语言条件下的多任务操作","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113312v1-el3dd-extended-latent-3d-diffusion-for-language-conditioned-multitas.html"},{"id":"2511.12984v1","title":"CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner","headline":"CUTE-Planner：面向不平坦地形探索的置信度感知规划器","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112984v1-cute-planner-confidence-aware-uneven-terrain-exploration-planner.html"},{"id":"2511.13071v1","title":"Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers","headline":"提出一种无需姿态信息的神经网络方法，用于低成本静止加速度计的偏差估计","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113071v1-orientation-free-neural-network-based-bias-estimation-for-low-cost-s.html"},{"id":"2511.13048v1","title":"Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments","headline":"提出基于单向道路网络的全局路径规划方法，提升半结构化环境中清洁机器人的导航效率。","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113048v1-unidirectional-road-network-based-global-path-planning-for-cleaning-.html"},{"id":"2511.13042v1","title":"APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation","headline":"提出APP算法，通过双向捷径和路径扰动优化A*等图搜索算法生成的机器人路径。","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251113042v1-app-a-post-processing-algorithm-for-robots-with-bidirectional-shortc.html"},{"id":"2511.12910v1","title":"TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints","headline":"提出TOPP-DWR算法，解决差速轮式机器人时间最优路径规划中角速度约束问题","tag":"cs.RO","date":"2025-11-17","url":"cs-RO/2025-11-17/papers/251112910v1-topp-dwr-time-optimal-path-parameterization-of-differential-driven-w.html"},{"id":"2511.13011v1","title":"Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis","headline":"提出DTGS：一种热监督3D高斯溅射方法，用于低光照下的新视角合成。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113011v1-beyond-darkness-thermal-supervised-3d-gaussian-splatting-for-low-lig.html"},{"id":"2511.13571v1","title":"Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation","headline":"Opt3DGS：通过自适应探索和曲率感知利用优化3D高斯溅射","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113571v1-opt3dgs-optimizing-3d-gaussian-splatting-with-adaptive-exploration-a.html"},{"id":"2511.13278v2","title":"SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting","headline":"SF-Recon：通过3D高斯溅射实现免简化的轻量级建筑重建","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113278v2-sf-recon-simplification-free-lightweight-building-reconstruction-via.html"},{"id":"2511.13264v2","title":"SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression","headline":"SymGS：利用局部对称性压缩3D高斯溅射模型","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113264v2-symgs-leveraging-local-symmetries-for-3d-gaussian-splatting-compress.html"},{"id":"2511.13259v1","title":"GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models","headline":"GeoX-Bench：用于评估大模型跨视角地理定位与姿态估计能力的基准测试。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113259v1-geox-bench-benchmarking-cross-view-geo-localization-and-pose-estimat.html"},{"id":"2511.12930v1","title":"Neo: Real-Time On-Device 3D Gaussian Splatting with Reuse-and-Update Sorting Acceleration","headline":"Neo：基于重用-更新排序加速的实时端侧3D高斯溅射","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112930v1-neo-real-time-on-device-3d-gaussian-splatting-with-reuse-and-update-.html"},{"id":"2511.13864v1","title":"GRLoc: Geometric Representation Regression for Visual Localization","headline":"提出GRLoc：通过几何表示回归实现更鲁棒的视觉定位","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113864v1-grloc-geometric-representation-regression-for-visual-localization.html"},{"id":"2511.13032v1","title":"Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts","headline":"提出Uni-Inter框架以解决多种交互场景下的人类动作生成问题","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113032v1-uni-inter-unifying-3d-human-motion-synthesis-across-diverse-interact.html"},{"id":"2511.12935v2","title":"PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos","headline":"PFAvatar：从日常照片中进行姿态融合的个性化3D头像重建","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112935v2-pfavatar-pose-fusion-3d-personalized-avatar-reconstruction-from-real.html"},{"id":"2511.13138v1","title":"WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection","headline":"WinMamba：面向3D目标检测，提出基于多尺度移位窗口的状态空间模型","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113138v1-winmamba-multi-scale-shifted-windows-in-state-space-model-for-3d-obj.html"},{"id":"2511.13857v1","title":"RSPose: Ranking Based Losses for Human Pose Estimation","headline":"RSPose：提出基于排序损失的人体姿态估计方法，显著提升mAP","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113857v1-rspose-ranking-based-losses-for-human-pose-estimation.html"},{"id":"2511.13269v1","title":"Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation","headline":"提出SpatialSky-Bench以评估无人机导航中的空间智能能力","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113269v1-is-your-vlm-sky-ready-a-comprehensive-spatial-intelligence-benchmark.html"},{"id":"2511.13121v1","title":"CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model","headline":"提出CloseUpShot，通过点云条件扩散模型实现稀疏视角下的近距离新视角合成","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113121v1-closeupshot-close-up-novel-view-synthesis-from-sparse-views-via-poin.html"},{"id":"2511.12895v1","title":"Reconstructing 3D Scenes in Native High Dynamic Range","headline":"提出NH-3DGS，直接从原生HDR数据重建高质量3D场景","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112895v1-reconstructing-3d-scenes-in-native-high-dynamic-range.html"},{"id":"2511.13713v1","title":"Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine","headline":"提出FFSE，实现3D引擎般的多轮物体操作图像编辑","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113713v1-free-form-scene-editor-enabling-multi-round-object-manipulation-like.html"},{"id":"2511.13282v2","title":"Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space","headline":"提出深度条件平移优化与度量感知网络，实现相机空间多人网格重建","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113282v2-towards-metric-aware-multi-person-mesh-recovery-by-jointly-optimizin.html"},{"id":"2511.13208v2","title":"End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer","headline":"提出PAVE-Net，一种端到端姿态感知视频Transformer网络，用于多人视频姿态估计。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113208v2-end-to-end-multi-person-pose-estimation-with-pose-aware-video-transf.html"},{"id":"2511.13102v2","title":"CapeNext: Rethinking and Refining Dynamic Support Information for Category-Agnostic Pose Estimation","headline":"CapeNext：通过优化动态支持信息，改进类别无关的姿态估计","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113102v2-capenext-rethinking-and-refining-dynamic-support-information-for-cat.html"},{"id":"2511.13065v1","title":"RobustGait: Robustness Analysis for Appearance Based Gait Recognition","headline":"RobustGait：针对基于外观的步态识别的鲁棒性分析框架","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113065v1-robustgait-robustness-analysis-for-appearance-based-gait-recognition.html"},{"id":"2511.13039v1","title":"MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization","headline":"提出MGCA-Net，通过多粒度类别感知解决开放词汇时序动作定位问题。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113039v1-mgca-net-multi-grained-category-aware-network-for-open-vocabulary-te.html"},{"id":"2511.12961v1","title":"Inertia-Informed Orientation Priors for Event-Based Optical Flow Estimation","headline":"提出一种融合惯性信息的事件相机光流估计方法，提升鲁棒性和收敛性。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112961v1-inertia-informed-orientation-priors-for-event-based-optical-flow-est.html"},{"id":"2511.12919v3","title":"CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation","headline":"CoordAR：基于自回归坐标图生成的单参考新物体6D位姿估计","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112919v3-coordar-one-reference-6d-pose-estimation-of-novel-objects-via-autore.html"},{"id":"2511.17596v1","title":"Reconstruction-Driven Multimodal Representation Learning for Automated Media Understanding","headline":"提出基于重构驱动的多模态自编码器，用于自动化媒体内容理解。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251117596v1-reconstruction-driven-multimodal-representation-learning-for-automat.html"},{"id":"2511.13649v3","title":"Distribution Matching Distillation Meets Reinforcement Learning","headline":"提出DMDR框架，结合强化学习与分布匹配蒸馏，提升少步扩散模型的生成质量。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113649v3-distribution-matching-distillation-meets-reinforcement-learning.html"},{"id":"2511.13545v1","title":"Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks","headline":"提出一种高效微调策略，增强多模态对比学习模型抵抗后门攻击的鲁棒性","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113545v1-robust-defense-strategies-for-multimodal-contrastive-learning-effici.html"},{"id":"2511.13222v1","title":"Hybrid-Domain Adaptative Representation Learning for Gaze Estimation","headline":"提出混合领域自适应表示学习以解决注视估计中的跨域问题","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113222v1-hybrid-domain-adaptative-representation-learning-for-gaze-estimation.html"},{"id":"2511.13168v1","title":"SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration","headline":"SOMA：通过特征梯度增强的仿射流匹配实现SAR-光学图像配准","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113168v1-soma-feature-gradient-enhanced-affine-flow-matching-for-sar-optical-.html"},{"id":"2511.12976v1","title":"MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning","headline":"提出MCAQ-YOLO，通过形态复杂度感知量化提升目标检测效率，适用于资源受限场景。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112976v1-mcaq-yolo-morphological-complexity-aware-quantization-for-efficient-.html"},{"id":"2511.12908v1","title":"DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning","headline":"DeepSport：基于Agent强化学习的多模态大语言模型，用于全面的体育视频推理","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112908v1-deepsport-a-multimodal-large-language-model-for-comprehensive-sports.html"},{"id":"2511.13794v1","title":"FusionFM: All-in-One Multi-Modal Image Fusion with Flow Matching","headline":"提出FusionFM，利用Flow Matching实现高效多模态图像融合","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113794v1-fusionfm-all-in-one-multi-modal-image-fusion-with-flow-matching.html"},{"id":"2511.13684v1","title":"Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting","headline":"GS-Light：基于高斯溅射的文本引导、无训练多视角场景重光照方法","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113684v1-training-free-multi-view-extension-of-ic-light-for-textual-position-.html"},{"id":"2511.13924v1","title":"Start Small, Think Big: Curriculum-based Relative Policy Optimization for Visual Grounding","headline":"提出基于课程学习的相对策略优化CuRPO，提升视觉定位任务中CoT推理的性能。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113924v1-start-small-think-big-curriculum-based-relative-policy-optimization-.html"},{"id":"2511.13431v1","title":"FUSE: A Flow-based Mapping Between Shapes","headline":"提出基于Flow-Matching的形状映射方法，高效支持跨表示形状匹配。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113431v1-fuse-a-flow-based-mapping-between-shapes.html"},{"id":"2511.12909v1","title":"CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection","headline":"提出CASL：一种曲率增强的自监督学习框架，用于提升3D异常检测性能。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112909v1-casl-curvature-augmented-self-supervised-learning-for-3d-anomaly-det.html"},{"id":"2511.13648v1","title":"PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image","headline":"PhysX-Anything：首个单图生成可用于仿真的物理3D资产框架","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113648v1-physx-anything-simulation-ready-physical-3d-assets-from-single-image.html"},{"id":"2511.12940v1","title":"Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention","headline":"提出RAD框架，通过循环自回归扩散模型解决长视频生成中的记忆和时空一致性问题","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112940v1-recurrent-autoregressive-diffusion-global-memory-meets-local-attenti.html"},{"id":"2511.13647v1","title":"Part-X-MLLM: Part-aware 3D Multimodal Large Language Model","headline":"Part-X-MLLM：提出基于部件感知的3D多模态大语言模型，统一解决多种3D任务。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113647v1-part-x-mllm-part-aware-3d-multimodal-large-language-model.html"},{"id":"2511.13315v1","title":"Computer Vision based group activity detection and action spotting","headline":"提出基于计算机视觉的群体活动检测与行为定位框架，融合深度学习与图推理。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113315v1-computer-vision-based-group-activity-detection-and-action-spotting.html"},{"id":"2511.13132v1","title":"Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack","headline":"提出基于室内光照对抗攻击的VLN鲁棒性黑盒评估框架","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113132v1-shedding-light-on-vln-robustness-a-black-box-framework-for-indoor-li.html"},{"id":"2511.13115v2","title":"A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features","headline":"提出基于旋转不变特征的轻量级3D异常检测方法，提升点云数据处理的鲁棒性。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113115v2-a-lightweight-3d-anomaly-detection-method-with-rotationally-invarian.html"},{"id":"2511.13047v1","title":"DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation","headline":"提出DiffPixelFormer，用于提升RGB-D室内场景分割的精度和效率。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251113047v1-diffpixelformer-differential-pixel-aware-transformer-for-rgb-d-indoo.html"},{"id":"2511.12977v2","title":"ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes","headline":"ArtiWorld：提出LLM驱动的3D场景物体可动性自动生成方法","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112977v2-artiworld-llm-driven-articulation-of-3d-objects-in-scenes.html"},{"id":"2511.12921v1","title":"Generative Photographic Control for Scene-Consistent Video Cinematic Editing","headline":"CineCtrl：提出一种生成式视频电影编辑框架，实现对专业相机参数的精细控制。","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112921v1-generative-photographic-control-for-scene-consistent-video-cinematic.html"},{"id":"2511.12878v3","title":"Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views","headline":"Uni-Hand：用于第一人称视角的通用手部运动预测框架","tag":"cs.CV","date":"2025-11-17","url":"cs-CV/2025-11-17/papers/251112878v3-uni-hand-universal-hand-motion-forecasting-in-egocentric-views.html"},{"id":"2511.13009v1","title":"TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting","headline":"提出TR-Gaussians，用于平面透射与反射的高保真实时渲染","tag":"cs.GR","date":"2025-11-17","url":"cs-GR/2025-11-17/papers/251113009v1-tr-gaussians-high-fidelity-real-time-rendering-of-planar-transmissio.html"},{"id":"2511.13988v1","title":"B2F: End-to-End Body-to-Face Motion Generation with Style Reference","headline":"提出B2F模型，通过风格参考实现端到端身体到面部动作生成","tag":"cs.GR","date":"2025-11-17","url":"cs-GR/2025-11-17/papers/251113988v1-b2f-end-to-end-body-to-face-motion-generation-with-style-reference.html"},{"id":"2511.13247v1","title":"Force-Aware 3D Contact Modeling for Stable Grasp Generation","headline":"提出力感知的3D接触建模方法，提升机械臂稳定抓取生成效果","tag":"cs.GR","date":"2025-11-17","url":"cs-GR/2025-11-17/papers/251113247v1-force-aware-3d-contact-modeling-for-stable-grasp-generation.html"},{"id":"2511.13306v1","title":"DAP: A Discrete-token Autoregressive Planner for Autonomous Driving","headline":"DAP：一种用于自动驾驶的离散token自回归规划器，实现BEV语义和轨迹联合预测。","tag":"cs.AI","date":"2025-11-17","url":"cs-AI/2025-11-17/papers/251113306v1-dap-a-discrete-token-autoregressive-planner-for-autonomous-driving.html"},{"id":"2511.13798v1","title":"KANGURA: Kolmogorov-Arnold Network-Based Geometry-Aware Learning with Unified Representation Attention for 3D Modeling of Complex Structures","headline":"KANGURA：基于KAN的几何感知学习框架，用于复杂结构的三维建模","tag":"cs.AI","date":"2025-11-17","url":"cs-AI/2025-11-17/papers/251113798v1-kangura-kolmogorov-arnold-network-based-geometry-aware-learning-with.html"},{"id":"2511.13458v1","title":"Trust in Vision-Language Models: Insights from a Participatory User Workshop","headline":"通过用户参与式研讨会洞察视觉-语言模型中的用户信任问题","tag":"cs.AI","date":"2025-11-17","url":"cs-AI/2025-11-17/papers/251113458v1-trust-in-vision-language-models-insights-from-a-participatory-user-w.html"},{"id":"2511.12436v1","title":"RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation","headline":"RoboAfford++：一个生成式AI增强的多模态可供性学习数据集，用于机器人操作和导航","tag":"cs.RO","date":"2025-11-16","url":"cs-RO/2025-11-16/papers/251112436v1-roboafford-a-generative-ai-enhanced-dataset-for-multimodal-affordanc.html"},{"id":"2511.12795v1","title":"ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model","headline":"提出基于校准能量模型的ActiveGrasp，解决杂乱环境中信息引导的主动抓取问题","tag":"cs.RO","date":"2025-11-16","url":"cs-RO/2025-11-16/papers/251112795v1-activegrasp-information-guided-active-grasping-with-calibrated-energ.html"},{"id":"2511.12778v1","title":"DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation","headline":"DR. Nav：面向主动死胡同恢复和导航的语义-几何表示方法","tag":"cs.RO","date":"2025-11-16","url":"cs-RO/2025-11-16/papers/251112778v1-dr-nav-semantic-geometric-representations-for-proactive-dead-end-rec.html"},{"id":"2511.12650v1","title":"Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning","headline":"提出基于强化学习的平面机械臂形态优化方法，无需解析表达式。","tag":"cs.RO","date":"2025-11-16","url":"cs-RO/2025-11-16/papers/251112650v1-task-aware-morphology-optimization-of-planar-manipulators-via-reinfo.html"},{"id":"2511.12526v2","title":"Botany Meets Robotics in Alpine Scree Monitoring","headline":"利用ANYmal C四足机器人和深度学习进行高山碎石坡生境监测","tag":"cs.RO","date":"2025-11-16","url":"cs-RO/2025-11-16/papers/251112526v2-botany-meets-robotics-in-alpine-scree-monitoring.html"},{"id":"2511.12653v1","title":"DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry","headline":"DPVO-QAT++：异构量化感知训练与CUDA核融合，提升深度Patch视觉里程计性能。","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112653v1-dpvo-qat-heterogeneous-qat-and-cuda-kernel-fusion-for-high-performan.html"},{"id":"2511.12671v1","title":"DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality","headline":"提出DensePercept-NCSSD，利用非因果选择性状态空间Mamba实现实时稠密视觉感知。","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112671v1-densepercept-ncssd-vision-mamba-towards-real-time-dense-visual-perce.html"},{"id":"2511.12614v1","title":"OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding","headline":"OPFormer：利用几何编码和基础模型进行物体姿态估计","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112614v1-opformer-object-pose-estimation-leveraging-foundation-model-with-geo.html"},{"id":"2511.12694v1","title":"X-VMamba: Explainable Vision Mamba","headline":"X-VMamba：基于可控性的Vision Mamba可解释性框架，应用于医学影像","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112694v1-x-vmamba-explainable-vision-mamba.html"},{"id":"2511.12740v1","title":"Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests","headline":"提出基于KPConv的深度不平衡多目标回归方法，用于模拟森林中三维点云体素内容估计。","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112740v1-deep-imbalanced-multi-target-regression-3d-point-cloud-voxel-content.html"},{"id":"2511.12675v1","title":"Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis","headline":"提出任务感知的新视角合成评估框架，解决现有指标与人类感知不一致问题","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112675v1-appreciate-the-view-a-task-aware-evaluation-framework-for-novel-view.html"},{"id":"2511.12658v1","title":"Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis","headline":"提出基于傅里叶级数的篡改合成方法以解决文本图像篡改定位问题","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112658v1-toward-real-world-text-image-forgery-localization-structured-and-int.html"},{"id":"2511.12449v1","title":"MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding","headline":"提出MOON2.0以解决电商产品理解中的多模态不平衡问题","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112449v1-moon20-dynamic-modality-balanced-multimodal-representation-learning-.html"},{"id":"2511.12547v4","title":"HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models","headline":"HiGFA：利用扩散模型和分层引导进行细粒度数据增强","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112547v4-higfa-hierarchical-guidance-for-fine-grained-data-augmentation-with-.html"},{"id":"2511.12676v1","title":"BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections","headline":"提出BridgeEQA桥梁检测基准与EMVR模型，解决具身环境问答中的多尺度推理难题。","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112676v1-bridgeeqa-virtual-embodied-agents-for-real-bridge-inspections.html"},{"id":"2511.12627v1","title":"C3Net: Context-Contrast Network for Camouflaged Object Detection","headline":"C3Net：上下文对比网络用于伪装目标检测，显著提升检测精度。","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112627v1-c3net-context-contrast-network-for-camouflaged-object-detection.html"},{"id":"2511.12503v1","title":"Visible Structure Retrieval for Lightweight Image-Based Relocalisation","headline":"提出可见结构检索网络，实现轻量级图像重定位","tag":"cs.CV","date":"2025-11-16","url":"cs-CV/2025-11-16/papers/251112503v1-visible-structure-retrieval-for-lightweight-image-based-relocalisati.html"},{"id":"2511.12751v1","title":"Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving","headline":"探索LLM辅助强化学习在分散式自动驾驶中的应用：奖励塑造的案例研究","tag":"cs.LG","date":"2025-11-16","url":"cs-LG/2025-11-16/papers/251112751v1-are-llms-the-way-forward-a-case-study-on-llm-guided-reinforcement-le.html"},{"id":"2511.12507v1","title":"Hierarchical Frequency-Decomposition Graph Neural Networks for Road Network Representation Learning","headline":"提出HiFiNet，用于道路网络表征学习，融合空间和频谱信息。","tag":"cs.LG","date":"2025-11-16","url":"cs-LG/2025-11-16/papers/251112507v1-hierarchical-frequency-decomposition-graph-neural-networks-for-road-.html"},{"id":"2511.12390v1","title":"Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control","headline":"提出基于强化学习的自适应神经遥操作框架，提升人形机器人控制的自然性和鲁棒性","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112390v1-learning-adaptive-neural-teleoperation-for-humanoid-robots-from-inve.html"},{"id":"2511.12361v1","title":"SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty","headline":"提出SAC-MoE，利用混合专家模型强化学习控制不确定性混合动力系统","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112361v1-sac-moe-reinforcement-learning-with-mixture-of-experts-for-control-o.html"},{"id":"2511.12184v1","title":"Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance","headline":"针对步态辅助外骨骼，提出变阻抗控制以提升人机交互安全性和适应性","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112184v1-variable-impedance-control-for-floating-base-supernumerary-robotic-l.html"},{"id":"2511.12232v2","title":"SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation","headline":"SocialNav-Map：结合动态地图与轨迹预测的零样本社交导航","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112232v2-socialnav-map-dynamic-mapping-with-human-trajectory-prediction-for-z.html"},{"id":"2511.12383v1","title":"Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks","headline":"评估MAML在MetaWorld ML10上的性能：机器人操作任务中的快速适应","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112383v1-evaluating-model-agnostic-meta-learning-on-metaworld-ml10-benchmark-.html"},{"id":"2511.12186v1","title":"Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization","headline":"提出基于椭球工作空间优化的多功能外骨骼机器人创新设计","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112186v1-innovative-design-of-multi-functional-supernumerary-robotic-limbs-wi.html"},{"id":"2511.12160v1","title":"Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)","headline":"提出RE-DPG框架以解决动态不确定环境中的多智能体安全运动规划问题","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112160v1-game-theoretic-safe-multi-agent-motion-planning-with-reachability-an.html"},{"id":"2511.12101v1","title":"Decoupled Action Head: Confining Task Knowledge to Conditioning Layers","headline":"提出解耦行为克隆训练方法，提升机器人操作任务的训练效率与泛化性。","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112101v1-decoupled-action-head-confining-task-knowledge-to-conditioning-layer.html"},{"id":"2511.12380v1","title":"Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots","headline":"多层压电PVDF驱动器提升软体微型机器人性能","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112380v1-multilaminate-piezoelectric-pvdf-actuators-to-enhance-performance-of.html"},{"id":"2511.12148v1","title":"Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies","headline":"利用神经进化拓扑结构，实现平面蛇形机器人在复杂环境下的避障控制","tag":"cs.RO","date":"2025-11-15","url":"cs-RO/2025-11-15/papers/251112148v1-towards-obstacle-avoiding-control-of-planar-snake-robots-exploring-n.html"},{"id":"2511.12304v1","title":"LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors","headline":"LiDAR-GS++：利用扩散先验改进LiDAR高斯重建，提升新视角合成质量","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112304v1-lidar-gsimproving-lidar-gaussian-reconstruction-via-diffusion-priors.html"},{"id":"2511.12370v2","title":"Changes in Real Time: Online Scene Change Detection with Multi-View Fusion","headline":"提出一种基于多视角融合的在线场景变化检测方法，达到SOTA性能。","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112370v2-changes-in-real-time-online-scene-change-detection-with-multi-view-f.html"},{"id":"2511.12170v2","title":"Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective","headline":"提出Completion-by-Correction方法以解决点云补全中的结构不一致问题","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112170v2-rethinking-multimodal-point-cloud-completion-a-completion-by-correct.html"},{"id":"2511.12079v2","title":"Point Cloud Quantization through Multimodal Prompting for 3D Understanding","headline":"提出基于多模态Prompt的点云量化方法，用于提升3D理解能力","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112079v2-point-cloud-quantization-through-multimodal-prompting-for-3d-underst.html"},{"id":"2511.12054v1","title":"UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization","headline":"提出UniABG，通过对抗视角桥接和图对应校准实现无监督跨视角地理定位","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112054v1-uniabg-unified-adversarial-view-bridging-and-graph-correspondence-fo.html"},{"id":"2511.12040v1","title":"SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images","headline":"SRSplat：基于稀疏多视角图像的前馈超分辨率高斯溅射重建","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112040v1-srsplat-feed-forward-super-resolution-gaussian-splatting-from-sparse.html"},{"id":"2511.12365v1","title":"Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning","headline":"提出基于强化学习的DT-R1框架，利用数字孪生表示统一解决视觉推理任务。","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112365v1-constructing-and-interpreting-digital-twin-representations-for-visua.html"},{"id":"2511.12061v1","title":"MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity","headline":"提出MovSemCL框架，通过运动语义对比学习提升轨迹相似度计算性能。","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112061v1-movsemcl-movement-semantics-contrastive-learning-for-trajectory-simi.html"},{"id":"2511.12034v1","title":"Calibrated Multimodal Representation Learning with Missing Modalities","headline":"提出CalMRL，通过校准不完整对齐解决缺失模态下的多模态表征学习问题。","tag":"cs.CV","date":"2025-11-15","url":"cs-CV/2025-11-15/papers/251112034v1-calibrated-multimodal-representation-learning-with-missing-modalitie.html"},{"id":"2511.12251v1","title":"Locomotion in CAVE: Enhancing Immersion through Full-Body Motion","headline":"提出一种基于全身动作识别的CAVE沉浸式漫游框架，提升用户体验","tag":"cs.GR","date":"2025-11-15","url":"cs-GR/2025-11-15/papers/251112251v1-locomotion-in-cave-enhancing-immersion-through-full-body-motion.html"},{"id":"2511.17581v1","title":"EgoCogNav: Cognition-aware Human Egocentric Navigation","headline":"EgoCogNav：提出认知感知的自中心导航框架，融合场景与感知信息预测人类行为。","tag":"cs.LG","date":"2025-11-15","url":"cs-LG/2025-11-15/papers/251117581v1-egocognav-cognition-aware-human-egocentric-navigation.html"},{"id":"2511.17583v1","title":"Learning Straight Flows: Variational Flow Matching for Efficient Generation","headline":"提出S-VFM，通过变分流匹配实现高效的单步生成","tag":"cs.LG","date":"2025-11-15","url":"cs-LG/2025-11-15/papers/251117583v1-learning-straight-flows-variational-flow-matching-for-efficient-gene.html"},{"id":"2511.12149v1","title":"AttackVLA: Benchmarking Adversarial and Backdoor Attacks on Vision-Language-Action Models","headline":"AttackVLA提出统一框架，评估并提升视觉-语言-动作模型的对抗鲁棒性。","tag":"cs.AI","date":"2025-11-15","url":"cs-AI/2025-11-15/papers/251112149v1-attackvla-benchmarking-adversarial-and-backdoor-attacks-on-vision-la.html"},{"id":"2511.10874v1","title":"Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation","headline":"提出基于Flow-Matching Co-Generation的多机器人协同非抓取操作框架","tag":"cs.RO","date":"2025-11-14","url":"cs-RO/2025-11-14/papers/251110874v1-collaborative-multi-robot-non-prehensile-manipulation-via-flow-match.html"},{"id":"2511.10864v1","title":"WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot","headline":"WetExplorer：一种用于湿地温室气体自动调查的自主移动机器人","tag":"cs.RO","date":"2025-11-14","url":"cs-RO/2025-11-14/papers/251110864v1-wetexplorer-automating-wetland-greenhouse-gas-surveys-with-an-autono.html"},{"id":"2511.10953v1","title":"Language-Guided Graph Representation Learning for Video Summarization","headline":"提出语言引导的图表示学习网络LGRLN，用于解决视频摘要中全局依赖建模和多模态定制问题。","tag":"cs.CV","date":"2025-11-14","url":"cs-CV/2025-11-14/papers/251110953v1-language-guided-graph-representation-learning-for-video-summarizatio.html"},{"id":"2511.10948v1","title":"DEFT-LLM: Disentangled Expert Feature Tuning for Micro-Expression Recognition","headline":"提出DEFT-LLM以解决微表情识别中的运动语义对齐问题","tag":"cs.CV","date":"2025-11-14","url":"cs-CV/2025-11-14/papers/251110948v1-deft-llm-disentangled-expert-feature-tuning-for-micro-expression-rec.html"},{"id":"2511.10021v1","title":"DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion","headline":"提出一种解耦驱动的人形机器人腿部DecARt Leg，用于敏捷运动","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110021v1-decart-leg-design-and-evaluation-of-a-novel-humanoid-robot-leg-with-.html"},{"id":"2512.00037v1","title":"ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM","headline":"ICD-Net：用于无人机视觉惯性SLAM的惯性协方差位移网络","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251200037v1-icd-net-inertial-covariance-displacement-network-for-drone-visual-in.html"},{"id":"2511.10635v1","title":"Robot Crash Course: Learning Soft and Stylized Falling","headline":"提出一种基于强化学习的机器人软着陆方法，控制末端姿态并减少物理损伤","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110635v1-robot-crash-course-learning-soft-and-stylized-falling.html"},{"id":"2511.10087v1","title":"Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning","headline":"提出UEPO，用于解决机器人离线到在线强化学习中的多模态行为覆盖和分布偏移问题","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110087v1-opinion-towards-unified-expressive-policy-optimization-for-robust-ro.html"},{"id":"2511.09958v1","title":"Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation","headline":"Audio-VLA：利用接触音频感知增强机器人操作的视觉-语言-动作模型","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251109958v1-audio-vla-adding-contact-audio-perception-to-vision-language-action-.html"},{"id":"2511.09885v1","title":"PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion","headline":"PuffyBot：一种用于多环境运动的无束缚变形机器人","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251109885v1-puffybot-an-untethered-shape-morphing-robot-for-multi-environment-lo.html"},{"id":"2511.09932v1","title":"A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation","headline":"通过数据增强提升视觉运动策略泛化能力，实现零样本Sim2Real迁移","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251109932v1-a-study-on-enhancing-the-generalization-ability-of-visuomotor-polici.html"},{"id":"2511.10110v1","title":"Learning a Thousand Tasks in a Day","headline":"提出MT3，通过分解和检索实现单样本模仿学习，一天内教会机器人上千种任务。","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110110v1-learning-a-thousand-tasks-in-a-day.html"},{"id":"2511.10816v2","title":"Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios","headline":"提出一种动态伸缩腿式连杆机构，用于搜索救援机器人执行多任务","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110816v2-dynamically-extensible-and-retractable-robotic-leg-linkages-for-mult.html"},{"id":"2511.10276v1","title":"RoboBenchMart: Benchmarking Robots in Retail Environment","headline":"RoboBenchMart：面向零售环境的机器人操作基准测试平台","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251110276v1-robobenchmart-benchmarking-robots-in-retail-environment.html"},{"id":"2511.09836v1","title":"Provably Safe Stein Variational Clarity-Aware Informative Planning","headline":"提出基于Stein变分清晰度感知的安全信息规划方法，解决非均匀衰减环境下的信息收集任务。","tag":"cs.RO","date":"2025-11-13","url":"cs-RO/2025-11-13/papers/251109836v1-provably-safe-stein-variational-clarity-aware-informative-planning.html"},{"id":"2511.10316v1","title":"Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and Multi-View Geometric Supervision","headline":"提出基于物理散焦建模和多视角几何监督的深度一致性3D高斯溅射方法","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110316v1-depth-consistent-3d-gaussian-splatting-via-physical-defocus-modeling.html"},{"id":"2511.09827v1","title":"AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting","headline":"提出基于高斯溅射的人体动画框架，实现场景中逼真的人体自由视角渲染。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109827v1-aha-animating-human-avatars-in-diverse-scenes-with-gaussian-splattin.html"},{"id":"2511.10647v1","title":"Depth Anything 3: Recovering the Visual Space from Any Views","headline":"Depth Anything 3：从任意视角恢复空间几何信息，无需架构特化。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110647v1-depth-anything-3-recovering-the-visual-space-from-any-views.html"},{"id":"2511.09944v1","title":"TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting","headline":"TSPE-GS：基于3D高斯溅射的半透明表面概率深度提取方法","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109944v1-tspe-gs-probabilistic-depth-extraction-for-semi-transparent-surface-.html"},{"id":"2511.10560v2","title":"OmniVGGT: Omni-Modality Driven Visual Geometry Grounded Transformer","headline":"OmniVGGT：多模态驱动的视觉几何对齐Transformer，提升3D视觉任务性能","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110560v2-omnivggt-omni-modality-driven-visual-geometry-grounded-transformer.html"},{"id":"2511.10212v1","title":"Next-Frame Feature Prediction for Multimodal Deepfake Detection and Temporal Localization","headline":"提出基于下一帧特征预测的多模态Deepfake检测与时序定位方法","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110212v1-next-frame-feature-prediction-for-multimodal-deepfake-detection-and-.html"},{"id":"2511.10076v1","title":"Mitigating Error Accumulation in Co-Speech Motion Generation via Global Rotation Diffusion and Multi-Level Constraints","headline":"提出GlobalDiff，通过全局旋转扩散和多级约束缓解共语运动生成中的误差累积","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110076v1-mitigating-error-accumulation-in-co-speech-motion-generation-via-glo.html"},{"id":"2511.10799v2","title":"GFT: Graph Feature Tuning for Efficient Point Cloud Analysis","headline":"提出图特征调优(GFT)方法，高效分析点云数据并显著降低参数量。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110799v2-gft-graph-feature-tuning-for-efficient-point-cloud-analysis.html"},{"id":"2511.10518v1","title":"SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation","headline":"SemanticVLA：面向高效机器人操作的语义对齐稀疏化与增强","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110518v1-semanticvla-semantic-aligned-sparsification-and-enhancement-for-effi.html"},{"id":"2511.10376v2","title":"MSGNav: Unleashing the Power of Multi-modal 3D Scene Graph for Zero-Shot Embodied Navigation","headline":"提出多模态3D场景图MSGNav，用于零样本具身导航","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110376v2-msgnav-unleashing-the-power-of-multi-modal-3d-scene-graph-for-zero-s.html"},{"id":"2511.09878v1","title":"RWKV-PCSSC: Exploring RWKV Model for Point Cloud Semantic Scene Completion","headline":"提出RWKV-PCSSC，利用RWKV机制实现轻量高效的点云语义场景补全。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109878v1-rwkv-pcssc-exploring-rwkv-model-for-point-cloud-semantic-scene-compl.html"},{"id":"2511.09866v1","title":"IPCD: Intrinsic Point-Cloud Decomposition","headline":"提出IPCD，用于点云的本征分解，实现光照编辑和纹理修改等应用","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109866v1-ipcd-intrinsic-point-cloud-decomposition.html"},{"id":"2511.10615v1","title":"Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals","headline":"针对视障人士，评估轻量级VLM在视频理解中的可访问性，并提出定制化评估框架。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110615v1-towards-blind-and-low-vision-accessibility-of-lightweight-vlms-and-c.html"},{"id":"2511.10604v1","title":"Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping","headline":"提出多任务GLocal OBIA-Mamba模型，提升Sentinel-2土地覆盖分类精度。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110604v1-multitask-glocal-obia-mamba-for-sentinel-2-landcover-mapping.html"},{"id":"2511.10279v1","title":"PROPA: Toward Process-level Optimization in Visual Reasoning via Reinforcement Learning","headline":"提出PROPA框架，通过强化学习优化视觉推理中的过程级依赖问题","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110279v1-propa-toward-process-level-optimization-in-visual-reasoning-via-rein.html"},{"id":"2511.10107v1","title":"RobIA: Robust Instance-aware Continual Test-time Adaptation for Deep Stereo","headline":"提出RobIA框架，用于深度立体匹配中鲁棒的、实例感知的持续测试时自适应","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110107v1-robia-robust-instance-aware-continual-test-time-adaptation-for-deep-.html"},{"id":"2511.11725v1","title":"Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video","headline":"提出基于盲点感知的自监督视觉表征学习方法，用于提升婴儿视角视频中的词-物映射","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251111725v1-do-blind-spots-matter-for-word-referent-mapping-a-computational-stud.html"},{"id":"2511.10539v1","title":"Dynamic Avatar-Scene Rendering from Human-centric Context","headline":"提出Separate-then-Map策略，解决单目视频中动态人与场景交互的神经渲染问题","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110539v1-dynamic-avatar-scene-rendering-from-human-centric-context.html"},{"id":"2511.10203v1","title":"VISTA: A Vision and Intent-Aware Social Attention Framework for Multi-Agent Trajectory Prediction","headline":"VISTA：一种用于多智能体轨迹预测的视觉和意图感知社交注意力框架","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110203v1-vista-a-vision-and-intent-aware-social-attention-framework-for-multi.html"},{"id":"2511.10209v2","title":"LiNeXt: Revisiting LiDAR Completion with Efficient Non-Diffusion Architectures","headline":"LiNeXt：提出高效非扩散架构，加速LiDAR点云补全并提升精度。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110209v2-linext-revisiting-lidar-completion-with-efficient-non-diffusion-arch.html"},{"id":"2511.10142v1","title":"Split-Layer: Enhancing Implicit Neural Representation by Maximizing the Dimensionality of Feature Space","headline":"提出Split-Layer以提升隐式神经表示的特征空间维度，增强表征能力","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110142v1-split-layer-enhancing-implicit-neural-representation-by-maximizing-t.html"},{"id":"2511.11735v1","title":"Toward bilipshiz geometric models","headline":"提出保持双利普希茨几何结构的3D点云神经网络模型","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251111735v1-toward-bilipshiz-geometric-models.html"},{"id":"2511.10040v2","title":"LoG3D: Ultra-High-Resolution 3D Shape Modeling via Local-to-Global Partitioning","headline":"LoG3D：通过局部到全局分割实现超高分辨率3D形状建模","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110040v2-log3d-ultra-high-resolution-3d-shape-modeling-via-local-to-global-pa.html"},{"id":"2511.10017v1","title":"AffordBot: 3D Fine-grained Embodied Reasoning via Multimodal Large Language Models","headline":"AffordBot：利用多模态大语言模型实现细粒度3D具身推理","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110017v1-affordbot-3d-fine-grained-embodied-reasoning-via-multimodal-large-la.html"},{"id":"2511.10003v2","title":"DBGroup: Dual-Branch Point Grouping for Weakly Supervised 3D Semantic Instance Segmentation","headline":"提出DBGroup：双分支点云分组网络，用于弱监督3D语义实例分割","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251110003v2-dbgroup-dual-branch-point-grouping-for-weakly-supervised-3d-semantic.html"},{"id":"2511.09919v1","title":"MosaicDoc: A Large-Scale Bilingual Benchmark for Visually Rich Document Understanding","headline":"提出MosaicDoc：一个大规模双语视觉文档理解基准，解决现有基准的局限性。","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109919v1-mosaicdoc-a-large-scale-bilingual-benchmark-for-visually-rich-docume.html"},{"id":"2511.09883v1","title":"HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models","headline":"提出HCC-3D，通过分层补偿压缩实现3D视觉语言模型中98%的Token缩减","tag":"cs.CV","date":"2025-11-13","url":"cs-CV/2025-11-13/papers/251109883v1-hcc-3d-hierarchical-compensatory-compression-for-98-3d-token-reducti.html"},{"id":"2511.09923v2","title":"Harnessing Bounded-Support Evolution Strategies for Policy Refinement","headline":"提出三角分布ES算法，用于提升机器人策略的稳定性和性能","tag":"cs.LG","date":"2025-11-13","url":"cs-LG/2025-11-13/papers/251109923v2-harnessing-bounded-support-evolution-strategies-for-policy-refinemen.html"},{"id":"2511.10627v1","title":"Querying Labeled Time Series Data with Scenario Programs","headline":"提出基于场景程序的时序数据查询方法，用于验证仿真环境中自动驾驶系统的失效场景。","tag":"cs.AI","date":"2025-11-13","url":"cs-AI/2025-11-13/papers/251110627v1-querying-labeled-time-series-data-with-scenario-programs.html"},{"id":"2511.09302v1","title":"UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning","headline":"UMIGen：用于自中心点云生成和跨具身机器人模仿学习的统一框架","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109302v1-umigen-a-unified-framework-for-egocentric-point-cloud-generation-and.html"},{"id":"2511.09141v1","title":"RGMP: Recurrent Geometric-prior Multimodal Policy for Generalizable Humanoid Robot Manipulation","headline":"提出RGMP，融合几何先验与递归高斯过程，提升人形机器人操作的泛化性和数据效率。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109141v1-rgmp-recurrent-geometric-prior-multimodal-policy-for-generalizable-h.html"},{"id":"2511.09072v1","title":"SMF-VO: Direct Ego-Motion Estimation via Sparse Motion Fields","headline":"提出基于稀疏运动场的直接视觉里程计SMF-VO，适用于资源受限设备。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109072v1-smf-vo-direct-ego-motion-estimation-via-sparse-motion-fields.html"},{"id":"2511.09091v2","title":"APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots","headline":"APEX：利用动作先验实现腿式机器人稳健运动跟踪的高效探索","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109091v2-apex-action-priors-enable-efficient-exploration-for-robust-motion-tr.html"},{"id":"2511.09241v2","title":"Unveiling the Impact of Data and Model Scaling on High-Level Control for Humanoid Robots","headline":"提出SCHUR框架与Humanoid-Union数据集，提升人形机器人高层控制的数据与模型可扩展性。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109241v2-unveiling-the-impact-of-data-and-model-scaling-on-high-level-control.html"},{"id":"2511.09558v1","title":"IFG: Internet-Scale Guidance for Functional Grasping Generation","headline":"IFG：利用互联网规模指导的功能性抓取生成","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109558v1-ifg-internet-scale-guidance-for-functional-grasping-generation.html"},{"id":"2511.09602v1","title":"ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset","headline":"提出ScaleADFG框架，解决机器人灵巧手对多尺度工具的功能性抓取问题。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109602v1-scaleadfg-affordance-based-dexterous-functional-grasping-via-scalabl.html"},{"id":"2511.08865v1","title":"MirrorLimb: Implementing hand pose acquisition and robot teleoperation based on RealMirror","headline":"提出基于RealMirror的MirrorLimb框架，实现低成本手部姿态获取和机器人遥操作","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251108865v1-mirrorlimb-implementing-hand-pose-acquisition-and-robot-teleoperatio.html"},{"id":"2511.09695v1","title":"A Shared-Autonomy Construction Robotic System for Overhead Works","headline":"提出一种共享自主的建筑机器人系统，用于高空作业场景","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109695v1-a-shared-autonomy-construction-robotic-system-for-overhead-works.html"},{"id":"2511.09515v1","title":"WMPO: World Model-based Policy Optimization for Vision-Language-Action Models","headline":"提出WMPO，用于视觉-语言-动作模型的基于世界模型的策略优化","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109515v1-wmpo-world-model-based-policy-optimization-for-vision-language-actio.html"},{"id":"2511.09142v1","title":"LODESTAR: Degeneracy-Aware LiDAR-Inertial Odometry with Adaptive Schmidt-Kalman Filter and Data Exploitation","headline":"LODESTAR：基于自适应Schmidt-Kalman滤波和数据利用的抗退化LiDAR惯性里程计","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109142v1-lodestar-degeneracy-aware-lidar-inertial-odometry-with-adaptive-schm.html"},{"id":"2511.09484v1","title":"SPIDER: Scalable Physics-Informed Dexterous Retargeting","headline":"SPIDER：可扩展的基于物理信息的灵巧重定向框架，用于生成机器人控制策略。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109484v1-spider-scalable-physics-informed-dexterous-retargeting.html"},{"id":"2511.09555v1","title":"SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation","headline":"SpatialActor：探索解耦空间表征，提升机器人操作的鲁棒性","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109555v1-spatialactor-exploring-disentangled-spatial-representations-for-robu.html"},{"id":"2511.09516v1","title":"MAP-VLA: Memory-Augmented Prompting for Vision-Language-Action Model in Robotic Manipulation","headline":"MAP-VLA：利用记忆增强提示，提升VLA模型在机器人操作中的长时任务性能","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109516v1-map-vla-memory-augmented-prompting-for-vision-language-action-model-.html"},{"id":"2511.08942v1","title":"Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning","headline":"提出基于VLM推理的零样本物体目标导航方法，提升导航效率。","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251108942v1-think-remember-navigate-zero-shot-object-goal-navigation-with-vlm-po.html"},{"id":"2511.08935v1","title":"Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation","headline":"提出SCOPE框架以提升具身视觉导航的决策能力","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251108935v1-expand-your-scope-semantic-cognition-over-potential-based-exploratio.html"},{"id":"2511.08912v1","title":"A Shared Control Framework for Mobile Robots with Planning-Level Intention Prediction","headline":"提出基于意图域预测的移动机器人共享控制框架，提升人机协作效率与安全性","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251108912v1-a-shared-control-framework-for-mobile-robots-with-planning-level-int.html"},{"id":"2511.09331v1","title":"CoRL-MPPI: Enhancing MPPI With Learnable Behaviours For Efficient And Provably-Safe Multi-Robot Collision Avoidance","headline":"CoRL-MPPI：融合强化学习与MPPI，提升多机器人避障效率与安全性","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109331v1-corl-mppi-enhancing-mppi-with-learnable-behaviours-for-efficient-and.html"},{"id":"2511.09727v1","title":"Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard","headline":"Baby Sophia：基于强化学习和自触摸、手部观察的机器人自主探索","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251109727v1-baby-sophia-a-developmental-approach-to-self-exploration-through-sel.html"},{"id":"2511.08863v1","title":"XPRESS: X-Band Radar Place Recognition via Elliptical Scan Shaping","headline":"XPRESS：基于椭圆扫描整形X波段雷达的地点识别方法，用于海事自主导航","tag":"cs.RO","date":"2025-11-12","url":"cs-RO/2025-11-12/papers/251108863v1-xpress-x-band-radar-place-recognition-via-elliptical-scan-shaping.html"},{"id":"2511.08872v1","title":"SasMamba: A Lightweight Structure-Aware Stride State Space Model for 3D Human Pose Estimation","headline":"SasMamba：轻量级结构感知步幅状态空间模型，用于3D人体姿态估计","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251108872v1-sasmamba-a-lightweight-structure-aware-stride-state-space-model-for-.html"},{"id":"2511.10699v1","title":"DualVision ArthroNav: Investigating Opportunities to Enhance Localization and Reconstruction in Image-based Arthroscopy Navigation via External Cameras","headline":"DualVision ArthroNav：利用外部相机增强图像引导关节镜导航的定位与重建","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251110699v1-dualvision-arthronav-investigating-opportunities-to-enhance-localiza.html"},{"id":"2511.09147v2","title":"PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery","headline":"PressTrack-HMR：提出基于压力感知的多人全局人体网格重建方法","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109147v2-presstrack-hmr-pressure-based-top-down-multi-person-global-human-mes.html"},{"id":"2511.09724v1","title":"PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model","headline":"提出PALMS+以解决室内定位精度不足问题","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109724v1-palms-modular-image-based-floor-plan-localization-leveraging-depth-f.html"},{"id":"2511.11713v1","title":"Understanding the Representation of Older Adults in Motion Capture Locomotion Datasets","headline":"分析MoCap老年人运动数据集，揭示现有数据集对老年人步态表征的不足","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251111713v1-understanding-the-representation-of-older-adults-in-motion-capture-l.html"},{"id":"2511.09397v2","title":"OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS","headline":"OUGS：基于对象感知不确定性估计的3DGS主动视角选择","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109397v2-ougs-active-view-selection-via-object-aware-uncertainty-estimation-i.html"},{"id":"2511.09771v2","title":"STORM: Segment, Track, and Object Re-Localization from a Single Image","headline":"提出STORM，无需人工标注，实现单图像的物体分割、跟踪和重定位。","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109771v2-storm-segment-track-and-object-re-localization-from-a-single-image.html"},{"id":"2511.09502v1","title":"DreamPose3D: Hallucinative Diffusion with Prompt Learning for 3D Human Pose Estimation","headline":"DreamPose3D：结合提示学习的幻觉扩散模型用于3D人体姿态估计","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109502v1-dreampose3d-hallucinative-diffusion-with-prompt-learning-for-3d-huma.html"},{"id":"2511.09443v1","title":"BronchOpt : Vision-Based Pose Optimization with Fine-Tuned Foundation Models for Accurate Bronchoscopy Navigation","headline":"BronchOpt：基于视觉和微调基础模型的支气管镜导航位姿优化","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109443v1-bronchopt-vision-based-pose-optimization-with-fine-tuned-foundation-.html"},{"id":"2511.08978v1","title":"Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding","headline":"提出ST-CLIP模型，利用时空信息增强视觉-语言模型，用于交通场景理解。","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251108978v1-spatio-temporal-data-enhanced-vision-language-model-for-traffic-scen.html"},{"id":"2511.11700v1","title":"EPSegFZ: Efficient Point Cloud Semantic Segmentation for Few- and Zero-Shot Scenarios with Language Guidance","headline":"提出EPSegFZ，利用语言引导实现高效的点云少样本/零样本语义分割","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251111700v1-epsegfz-efficient-point-cloud-semantic-segmentation-for-few-and-zero.html"},{"id":"2511.09057v3","title":"PAN: A World Model for General, Interactable, and Long-Horizon World Simulation","headline":"PAN：通用、可交互、长时程世界模拟的世界模型","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109057v3-pan-a-world-model-for-general-interactable-and-long-horizon-world-si.html"},{"id":"2511.08910v1","title":"OG-PCL: Efficient Sparse Point Cloud Processing for Human Activity Recognition","headline":"提出OG-PCL网络，用于高效处理稀疏雷达点云的人体活动识别","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251108910v1-og-pcl-efficient-sparse-point-cloud-processing-for-human-activity-re.html"},{"id":"2511.09388v1","title":"Learning by Neighbor-Aware Semantics, Deciding by Open-form Flows: Towards Robust Zero-Shot Skeleton Action Recognition","headline":"提出Flora，通过邻域感知语义和开放式流解决鲁棒的零样本骨骼动作识别问题","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109388v1-learning-by-neighbor-aware-semantics-deciding-by-open-form-flows-tow.html"},{"id":"2511.09055v1","title":"4KDehazeFlow: Ultra-High-Definition Image Dehazing via Flow Matching","headline":"提出4KDehazeFlow，通过Flow Matching实现超高清图像去雾，提升色彩保真度。","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109055v1-4kdehazeflow-ultra-high-definition-image-dehazing-via-flow-matching.html"},{"id":"2511.11702v1","title":"Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement","headline":"提出TASA框架，融合2D引导与几何优化，实现任务感知的3D可交互区域分割","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251111702v1-task-aware-3d-affordance-segmentation-via-2d-guidance-and-geometric-.html"},{"id":"2511.09022v1","title":"RadHARSimulator V2: Video to Doppler Generator","headline":"RadHARSimulator V2：提出一种视频到多普勒谱的雷达人体活动识别模拟器。","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109022v1-radharsimulator-v2-video-to-doppler-generator.html"},{"id":"2511.09554v1","title":"RF-DETR: Neural Architecture Search for Real-Time Detection Transformers","headline":"RF-DETR：面向实时目标检测Transformer的神经架构搜索","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109554v1-rf-detr-neural-architecture-search-for-real-time-detection-transform.html"},{"id":"2511.09286v1","title":"Enriching Knowledge Distillation with Cross-Modal Teacher Fusion","headline":"提出RichKD，通过跨模态CLIP知识融合提升知识蒸馏效果","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109286v1-enriching-knowledge-distillation-with-cross-modal-teacher-fusion.html"},{"id":"2511.09170v1","title":"HOTFLoc++: End-to-End Hierarchical LiDAR Place Recognition, Re-Ranking, and 6-DoF Metric Localisation in Forests","headline":"HOTFLoc++：森林环境下端到端分层LiDAR定位与重排序","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109170v1-hotfloc-end-to-end-hierarchical-lidar-place-recognition-re-ranking-a.html"},{"id":"2511.09130v1","title":"PIFF: A Physics-Informed Generative Flow Model for Real-Time Flood Depth Mapping","headline":"提出PIFF模型以解决实时洪水深度映射问题","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251109130v1-piff-a-physics-informed-generative-flow-model-for-real-time-flood-de.html"},{"id":"2511.08938v1","title":"Neural B-frame Video Compression with Bi-directional Reference Harmonization","headline":"提出BRHVC，通过双向参考帧协调优化神经B帧视频压缩性能","tag":"cs.CV","date":"2025-11-12","url":"cs-CV/2025-11-12/papers/251108938v1-neural-b-frame-video-compression-with-bi-directional-reference-harmo.html"},{"id":"2511.11681v1","title":"MPCM-Net: Multi-scale network integrates partial attention convolution with Mamba for ground-based cloud image segmentation","headline":"提出MPCM-Net，融合部分注意力卷积与Mamba，用于地基云图像分割，提升精度与效率。","tag":"cs.LG","date":"2025-11-12","url":"cs-LG/2025-11-12/papers/251111681v1-mpcm-net-multi-scale-network-integrates-partial-attention-convolutio.html"},{"id":"2511.08922v1","title":"Diffusion Policies with Value-Conditional Optimization for Offline Reinforcement Learning","headline":"提出DIVO，通过价值条件优化扩散策略解决离线强化学习中的过估计问题。","tag":"cs.LG","date":"2025-11-12","url":"cs-LG/2025-11-12/papers/251108922v1-diffusion-policies-with-value-conditional-optimization-for-offline-r.html"},{"id":"2511.11703v1","title":"Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom","headline":"提出基于语义分割的强化学习方法，降低3D环境内存消耗并提升智能体性能","tag":"cs.LG","date":"2025-11-12","url":"cs-LG/2025-11-12/papers/251111703v1-enhancing-reinforcement-learning-in-3d-environments-through-semantic.html"},{"id":"2511.08778v1","title":"Dual-Arm Whole-Body Motion Planning: Leveraging Overlapping Kinematic Chains","headline":"利用重叠运动链，为双臂机器人提出快速全身运动规划方法","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108778v1-dual-arm-whole-body-motion-planning-leveraging-overlapping-kinematic.html"},{"id":"2511.07921v1","title":"Dual-MPC Footstep Planning for Robust Quadruped Locomotion","headline":"提出基于双重MPC的足端规划策略，增强四足机器人运动的鲁棒性。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107921v1-dual-mpc-footstep-planning-for-robust-quadruped-locomotion.html"},{"id":"2511.07820v2","title":"SONIC: Supersizing Motion Tracking for Natural Humanoid Whole-Body Control","headline":"SONIC：通过大规模运动跟踪实现自然的人形全身控制","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107820v2-sonic-supersizing-motion-tracking-for-natural-humanoid-whole-body-co.html"},{"id":"2511.08299v1","title":"Learning Omnidirectional Locomotion for a Salamander-Like Quadruped Robot","headline":"提出基于学习的框架，使类蝾螈四足机器人获得全向运动能力","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108299v1-learning-omnidirectional-locomotion-for-a-salamander-like-quadruped-.html"},{"id":"2511.07727v1","title":"LLM-GROP: Visually Grounded Robot Task and Motion Planning with Large Language Models","headline":"LLM-GROP：利用大语言模型实现视觉引导的机器人任务与运动规划","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107727v1-llm-grop-visually-grounded-robot-task-and-motion-planning-with-large.html"},{"id":"2511.07732v1","title":"ViPRA: Video Prediction for Robot Actions","headline":"ViPRA：利用视频预测模型学习机器人动作控制策略","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107732v1-vipra-video-prediction-for-robot-actions.html"},{"id":"2511.07761v1","title":"High-Altitude Balloon Station-Keeping with First Order Model Predictive Control","headline":"提出基于一阶模型预测控制的高空气球定点方法，优于强化学习。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107761v1-high-altitude-balloon-station-keeping-with-first-order-model-predict.html"},{"id":"2511.08822v1","title":"Low-cost Multi-agent Fleet for Acoustic Cooperative Localization Research","headline":"提出低成本可配置水下机器人集群CoUGARs，用于水声协同定位研究","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108822v1-low-cost-multi-agent-fleet-for-acoustic-cooperative-localization-res.html"},{"id":"2511.08583v1","title":"SeFA-Policy: Fast and Accurate Visuomotor Policy Learning with Selective Flow Alignment","headline":"提出SeFA-Policy，通过选择性流对齐实现快速准确的视觉运动策略学习","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108583v1-sefa-policy-fast-and-accurate-visuomotor-policy-learning-with-select.html"},{"id":"2511.15677v1","title":"Real-time Point Cloud Data Transmission via L4S for 5G-Edge-Assisted Robotics","headline":"提出一种基于L4S的实时LiDAR点云传输框架，用于5G边缘辅助机器人。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251115677v1-real-time-point-cloud-data-transmission-via-l4s-for-5g-edge-assisted.html"},{"id":"2511.08019v1","title":"Model Predictive Control via Probabilistic Inference: A Tutorial","headline":"提出基于概率推断的MPC教程，解决机器人非线性控制难题。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108019v1-model-predictive-control-via-probabilistic-inference-a-tutorial.html"},{"id":"2511.07811v1","title":"Virtual Traffic Lights for Multi-Robot Navigation: Decentralized Planning with Centralized Conflict Resolution","headline":"提出基于虚拟交通灯的多机器人导航方法，实现去中心化规划与集中式冲突消解","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107811v1-virtual-traffic-lights-for-multi-robot-navigation-decentralized-plan.html"},{"id":"2511.07720v1","title":"A QP Framework for Improving Data Collection: Quantifying Device-Controller Performance in Robot Teleoperation","headline":"提出基于QP优化的遥操作框架，提升机器人数据收集质量","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107720v1-a-qp-framework-for-improving-data-collection-quantifying-device-cont.html"},{"id":"2511.08732v1","title":"Intuitive Programming, Adaptive Task Planning, and Dynamic Role Allocation in Human-Robot Collaboration","headline":"综述人机协作中直观编程、自适应任务规划和动态角色分配的关键技术。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108732v1-intuitive-programming-adaptive-task-planning-and-dynamic-role-alloca.html"},{"id":"2511.08377v1","title":"Human Motion Intent Inferencing in Teleoperation Through a SINDy Paradigm","headline":"Psychic：利用SINDy范式进行遥操作中人类运动意图推断","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108377v1-human-motion-intent-inferencing-in-teleoperation-through-a-sindy-par.html"},{"id":"2511.08277v1","title":"X-IONet: Cross-Platform Inertial Odometry Network with Dual-Stage Attention","headline":"X-IONet：基于双阶段注意力的跨平台惯性里程计网络，提升行人和四足机器人导航精度。","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108277v1-x-ionet-cross-platform-inertial-odometry-network-with-dual-stage-att.html"},{"id":"2511.08001v1","title":"Effective Game-Theoretic Motion Planning via Nested Search","headline":"提出博弈论嵌套搜索算法，高效解决动态系统中纳什均衡的运动规划问题","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108001v1-effective-game-theoretic-motion-planning-via-nested-search.html"},{"id":"2511.08454v1","title":"Intuitive control of supernumerary robotic limbs through a tactile-encoded neural interface","headline":"提出一种触觉编码神经接口，实现对额外机械肢的直观控制","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108454v1-intuitive-control-of-supernumerary-robotic-limbs-through-a-tactile-e.html"},{"id":"2511.08741v2","title":"ATOM-CBF: Adaptive Safe Perception-Based Control under Out-of-Distribution Measurements","headline":"提出ATOM-CBF，解决感知不确定性下的机器人安全控制问题","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108741v2-atom-cbf-adaptive-safe-perception-based-control-under-out-of-distrib.html"},{"id":"2511.08502v1","title":"Safe and Optimal Learning from Preferences via Weighted Temporal Logic with Applications in Robotics and Formula 1","headline":"提出基于加权时序逻辑的安全最优偏好学习方法，应用于机器人和F1赛车","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251108502v1-safe-and-optimal-learning-from-preferences-via-weighted-temporal-log.html"},{"id":"2511.07950v1","title":"USV Obstacles Detection and Tracking in Marine Environments","headline":"针对无人水面艇，提出融合激光雷达与视觉信息的障碍物检测与跟踪方法","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107950v1-usv-obstacles-detection-and-tracking-in-marine-environments.html"},{"id":"2511.07750v1","title":"Navigating the Wild: Pareto-Optimal Visual Decision-Making in Image Space","headline":"提出基于图像空间的Pareto最优视觉导航框架，解决复杂环境下的实时导航问题","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107750v1-navigating-the-wild-pareto-optimal-visual-decision-making-in-image-s.html"},{"id":"2511.07717v1","title":"RoboTAG: End-to-end Robot Configuration Estimation via Topological Alignment Graph","headline":"RoboTAG：通过拓扑对齐图实现端到端机器人配置估计","tag":"cs.RO","date":"2025-11-11","url":"cs-RO/2025-11-11/papers/251107717v1-robotag-end-to-end-robot-configuration-estimation-via-topological-al.html"},{"id":"2511.08032v1","title":"Perceptual Quality Assessment of 3D Gaussian Splatting: A Subjective Dataset and Prediction Metric","headline":"提出3DGS-QA数据集与无参考质量评估模型，解决3D高斯溅射感知质量评估问题","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108032v1-perceptual-quality-assessment-of-3d-gaussian-splatting-a-subjective-.html"},{"id":"2511.07823v1","title":"CloudMamba: Grouped Selective State Spaces for Point Cloud Analysis","headline":"CloudMamba：面向点云分析的分组选择性状态空间模型，显著降低计算复杂度并提升性能。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107823v1-cloudmamba-grouped-selective-state-spaces-for-point-cloud-analysis.html"},{"id":"2511.08387v1","title":"RAPTR: Radar-based 3D Pose Estimation using Transformer","headline":"RAPTR：利用Transformer的雷达3D人体姿态估计，使用弱监督学习。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108387v1-raptr-radar-based-3d-pose-estimation-using-transformer.html"},{"id":"2511.08036v1","title":"WEDepth: Efficient Adaptation of World Knowledge for Monocular Depth Estimation","headline":"WEDepth：高效利用世界知识自适应单目深度估计","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108036v1-wedepth-efficient-adaptation-of-world-knowledge-for-monocular-depth-.html"},{"id":"2511.07743v1","title":"UltraGS: Gaussian Splatting for Ultrasound Novel View Synthesis","headline":"UltraGS：用于超声新视角合成的高斯溅射方法","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107743v1-ultrags-gaussian-splatting-for-ultrasound-novel-view-synthesis.html"},{"id":"2511.08545v1","title":"RePose-NeRF: Robust Radiance Fields for Mesh Reconstruction under Noisy Camera Poses","headline":"RePose-NeRF：提出一种鲁棒的辐射场方法，用于在噪声相机位姿下进行网格重建","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108545v1-repose-nerf-robust-radiance-fields-for-mesh-reconstruction-under-noi.html"},{"id":"2511.08294v2","title":"SkelSplat: Robust Multi-view 3D Human Pose Estimation with Differentiable Gaussian Rendering","headline":"SkelSplat：基于可微高斯渲染的鲁棒多视角3D人体姿态估计","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108294v2-skelsplat-robust-multi-view-3d-human-pose-estimation-with-differenti.html"},{"id":"2511.07948v1","title":"ReIDMamba: Learning Discriminative Features with Visual State Space Model for Person Re-Identification","headline":"提出ReIDMamba，利用视觉状态空间模型学习判别性特征，实现高效行人重识别","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107948v1-reidmamba-learning-discriminative-features-with-visual-state-space-m.html"},{"id":"2511.08031v1","title":"Multi-modal Deepfake Detection and Localization with FPN-Transformer","headline":"提出基于FPN-Transformer的多模态深度伪造检测与定位框架，提升跨模态泛化能力和时序边界回归精度。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108031v1-multi-modal-deepfake-detection-and-localization-with-fpn-transformer.html"},{"id":"2511.08007v2","title":"EAGLE: Episodic Appearance- and Geometry-aware Memory for Unified 2D-3D Visual Query Localization in Egocentric Vision","headline":"EAGLE：基于情景外观和几何感知的记忆，用于以自我为中心的视觉查询定位","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108007v2-eagle-episodic-appearance-and-geometry-aware-memory-for-unified-2d-3.html"},{"id":"2511.08240v1","title":"Hierarchical Direction Perception via Atomic Dot-Product Operators for Rotation-Invariant Point Clouds Learning","headline":"提出DiPVNet，通过原子点积算子实现旋转不变的点云分层方向感知学习","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108240v1-hierarchical-direction-perception-via-atomic-dot-product-operators-f.html"},{"id":"2511.08155v1","title":"Non-Aligned Reference Image Quality Assessment for Novel View Synthesis","headline":"提出NAR-IQA框架，用于解决新视角合成中非对齐参考图像的质量评估问题","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108155v1-non-aligned-reference-image-quality-assessment-for-novel-view-synthe.html"},{"id":"2511.07966v1","title":"Multi-Modal Assistance for Unsupervised Domain Adaptation on Point Cloud 3D Object Detection","headline":"提出MMAssist，利用多模态信息辅助LiDAR点云3D目标检测的无监督域自适应。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107966v1-multi-modal-assistance-for-unsupervised-domain-adaptation-on-point-c.html"},{"id":"2511.07819v1","title":"Human Motion Synthesis in 3D Scenes via Unified Scene Semantic Occupancy","headline":"提出SSOMotion，利用统一场景语义占据表示进行3D场景中的人体运动合成。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107819v1-human-motion-synthesis-in-3d-scenes-via-unified-scene-semantic-occup.html"},{"id":"2511.08823v1","title":"DT-NVS: Diffusion Transformers for Novel View Synthesis","headline":"提出DT-NVS，利用Transformer的3D扩散模型实现真实场景的新视角合成","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108823v1-dt-nvs-diffusion-transformers-for-novel-view-synthesis.html"},{"id":"2511.08809v1","title":"Adaptive graph Kolmogorov-Arnold network for 3D human pose estimation","headline":"提出PoseKAN：一种自适应图Kolmogorov-Arnold网络，用于3D人体姿态估计。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108809v1-adaptive-graph-kolmogorov-arnold-network-for-3d-human-pose-estimatio.html"},{"id":"2511.08233v1","title":"Accurate and Efficient Surface Reconstruction from Point Clouds via Geometry-Aware Local Adaptation","headline":"提出基于几何感知的局部自适应点云表面重建方法，提升精度与效率","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108233v1-accurate-and-efficient-surface-reconstruction-from-point-clouds-via-.html"},{"id":"2511.07978v2","title":"DANCE: Density-agnostic and Class-aware Network for Point Cloud Completion","headline":"DANCE：一种密度无关且类别感知的点云补全网络","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107978v2-dance-density-agnostic-and-class-aware-network-for-point-cloud-compl.html"},{"id":"2511.07889v1","title":"Generating Sketches in a Hierarchical Auto-Regressive Process for Flexible Sketch Drawing Manipulation at Stroke-Level","headline":"提出一种分层自回归草图生成方法，实现笔画级灵活操控","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107889v1-generating-sketches-in-a-hierarchical-auto-regressive-process-for-fl.html"},{"id":"2511.08536v1","title":"3D4D: An Interactive, Editable, 4D World Model via 3D Video Generation","headline":"3D4D：通过3D视频生成实现交互式、可编辑的4D世界模型","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108536v1-3d4d-an-interactive-editable-4d-world-model-via-3d-video-generation.html"},{"id":"2511.07808v2","title":"DI3CL: Contrastive Learning With Dynamic Instances and Contour Consistency for SAR Land-Cover Classification Foundation Model","headline":"提出DI3CL框架，利用动态实例和轮廓一致性对比学习，构建SAR地物分类基础模型。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107808v2-di3cl-contrastive-learning-with-dynamic-instances-and-contour-consis.html"},{"id":"2511.07940v1","title":"Is It Truly Necessary to Process and Fit Minutes-Long Reference Videos for Personalized Talking Face Generation?","headline":"提出ISExplore策略，加速个性化说话人脸生成，减少参考视频处理时长。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107940v1-is-it-truly-necessary-to-process-and-fit-minutes-long-reference-vide.html"},{"id":"2511.08480v1","title":"Compression then Matching: An Efficient Pre-training Paradigm for Multimodal Embedding","headline":"提出CoMa：一种高效的多模态嵌入预训练范式，提升视觉-语言模型性能。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108480v1-compression-then-matching-an-efficient-pre-training-paradigm-for-mul.html"},{"id":"2511.08833v1","title":"Enhancing Rotation-Invariant 3D Learning with Global Pose Awareness and Attention Mechanisms","headline":"提出SiPF和RIAttnConv，增强旋转不变3D学习的全局姿态感知和区分能力","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108833v1-enhancing-rotation-invariant-3d-learning-with-global-pose-awareness-.html"},{"id":"2511.08365v1","title":"Retrospective motion correction in MRI using disentangled embeddings","headline":"提出基于解耦嵌入的MRI运动伪影矫正方法，提升模型泛化性。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108365v1-retrospective-motion-correction-in-mri-using-disentangled-embeddings.html"},{"id":"2511.08258v1","title":"Top2Ground: A Height-Aware Dual Conditioning Diffusion Model for Robust Aerial-to-Ground View Generation","headline":"提出Top2Ground，一种高程感知双重条件扩散模型，用于稳健的航拍图到地视图生成。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108258v1-top2ground-a-height-aware-dual-conditioning-diffusion-model-for-robu.html"},{"id":"2511.08186v1","title":"Pixel-level Quality Assessment for Oriented Object Detection","headline":"提出像素级质量评估PQA，解决有向目标检测中IoU预测的结构耦合问题。","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108186v1-pixel-level-quality-assessment-for-oriented-object-detection.html"},{"id":"2511.08178v1","title":"WarpGAN: Warping-Guided 3D GAN Inversion with Style-Based Novel View Inpainting","headline":"WarpGAN：基于形变引导和风格化视角补全的3D GAN反演","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108178v1-warpgan-warping-guided-3d-gan-inversion-with-style-based-novel-view-.html"},{"id":"2511.08173v1","title":"VLMDiff: Leveraging Vision-Language Models for Multi-Class Anomaly Detection with Diffusion","headline":"VLMDiff：利用视觉-语言模型和扩散模型进行多类别异常检测","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108173v1-vlmdiff-leveraging-vision-language-models-for-multi-class-anomaly-de.html"},{"id":"2511.08065v1","title":"I2E: Real-Time Image-to-Event Conversion for High-Performance Spiking Neural Networks","headline":"I2E：用于高性能脉冲神经网络的实时图像到事件转换框架","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108065v1-i2e-real-time-image-to-event-conversion-for-high-performance-spiking.html"},{"id":"2511.08048v1","title":"Generalized-Scale Object Counting with Gradual Query Aggregation","headline":"GECO2：通过渐进式查询聚合实现广义尺度目标计数","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251108048v1-generalized-scale-object-counting-with-gradual-query-aggregation.html"},{"id":"2511.07813v1","title":"Sparse3DPR: Training-Free 3D Hierarchical Scene Parsing and Task-Adaptive Subgraph Reasoning from Sparse RGB Views","headline":"Sparse3DPR：一种基于稀疏RGB视图的无训练3D场景分层解析与任务自适应子图推理框架","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107813v1-sparse3dpr-training-free-3d-hierarchical-scene-parsing-and-task-adap.html"},{"id":"2511.07710v3","title":"Cross Modal Fine-Grained Alignment via Granularity-Aware and Region-Uncertain Modeling","headline":"提出粒度感知和区域不确定性建模的跨模态细粒度对齐方法","tag":"cs.CV","date":"2025-11-11","url":"cs-CV/2025-11-11/papers/251107710v3-cross-modal-fine-grained-alignment-via-granularity-aware-and-region-.html"},{"id":"2511.07860v1","title":"TouchWalker: Real-Time Avatar Locomotion from Touchscreen Finger Walking","headline":"TouchWalker：提出一种基于触摸屏手指行走的实时全身Avatar运动控制系统","tag":"cs.GR","date":"2025-11-11","url":"cs-GR/2025-11-11/papers/251107860v1-touchwalker-real-time-avatar-locomotion-from-touchscreen-finger-walk.html"},{"id":"2511.08086v2","title":"Dynamic Sparsity: Challenging Common Sparsity Assumptions for Learning World Models in Robotic Reinforcement Learning Benchmarks","headline":"揭示机器人强化学习环境动态稀疏性的挑战与特性，为世界模型学习提供新视角","tag":"cs.LG","date":"2025-11-11","url":"cs-LG/2025-11-11/papers/251108086v2-dynamic-sparsity-challenging-common-sparsity-assumptions-for-learnin.html"},{"id":"2511.07730v2","title":"Multistep Quasimetric Learning for Scalable Goal-conditioned Reinforcement Learning","headline":"提出多步准度量学习，解决可扩展的、长时程目标条件强化学习问题","tag":"cs.LG","date":"2025-11-11","url":"cs-LG/2025-11-11/papers/251107730v2-multistep-quasimetric-learning-for-scalable-goal-conditioned-reinfor.html"},{"id":"2511.08399v1","title":"Aligning by Misaligning: Boundary-aware Curriculum Learning for Multimodal Alignment","headline":"提出边界感知课程学习方法BACL，提升多模态对齐性能。","tag":"cs.LG","date":"2025-11-11","url":"cs-LG/2025-11-11/papers/251108399v1-aligning-by-misaligning-boundary-aware-curriculum-learning-for-multi.html"},{"id":"2511.08752v1","title":"Information-Driven Fault Detection and Identification for Multi-Agent Spacecraft Systems: Collaborative On-Orbit Inspection Mission","headline":"提出信息驱动的容错框架，用于多智能体航天器协同在轨检测任务","tag":"eess.SY","date":"2025-11-11","url":"eess-SY/2025-11-11/papers/251108752v1-information-driven-fault-detection-and-identification-for-multi-agen.html"},{"id":"2511.06919v1","title":"Integration of Visual SLAM into Consumer-Grade Automotive Localization","headline":"融合视觉SLAM与车辆动力学模型，提升消费级汽车定位精度","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106919v1-integration-of-visual-slam-into-consumer-grade-automotive-localizati.html"},{"id":"2511.07081v1","title":"HDCNet: A Hybrid Depth Completion Network for Grasping Transparent and Reflective Objects","headline":"HDCNet：用于抓取透明和反射物体的混合深度补全网络","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107081v1-hdcnet-a-hybrid-depth-completion-network-for-grasping-transparent-an.html"},{"id":"2511.06749v1","title":"Semi-distributed Cross-modal Air-Ground Relative Localization","headline":"提出半分布式跨模态空地相对定位框架，提升协同任务的灵活性和精度。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106749v1-semi-distributed-cross-modal-air-ground-relative-localization.html"},{"id":"2511.07407v1","title":"Unified Humanoid Fall-Safety Policy from a Few Demonstrations","headline":"提出融合人类演示与强化学习的通用人形机器人防摔策略","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107407v1-unified-humanoid-fall-safety-policy-from-a-few-demonstrations.html"},{"id":"2511.07155v1","title":"Dynamics-Decoupled Trajectory Alignment for Sim-to-Real Transfer in Reinforcement Learning for Autonomous Driving","headline":"提出动力学解耦的轨迹对齐方法，实现自动驾驶RL Sim-to-Real零样本迁移","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107155v1-dynamics-decoupled-trajectory-alignment-for-sim-to-real-transfer-in-.html"},{"id":"2511.07654v1","title":"Time-Aware Policy Learning for Adaptive and Punctual Robot Control","headline":"提出时间感知策略学习，提升机器人控制的自适应性和准时性","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107654v1-time-aware-policy-learning-for-adaptive-and-punctual-robot-control.html"},{"id":"2511.07418v1","title":"Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields","headline":"提出Lightning Grasp，通过接触场实现高性能程序化抓取合成，加速机械臂操作。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107418v1-lightning-grasp-high-performance-procedural-grasp-synthesis-with-con.html"},{"id":"2511.07416v1","title":"Robot Learning from a Physical World Model","headline":"PhysWorld：通过物理世界建模实现机器人从视频生成中学习","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107416v1-robot-learning-from-a-physical-world-model.html"},{"id":"2511.06796v1","title":"Human-Level Actuation for Humanoids","headline":"提出人形机器人的人体水平驱动评估框架，实现可量化、可比较的性能基准。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106796v1-human-level-actuation-for-humanoids.html"},{"id":"2511.07375v1","title":"Exact Smooth Reformulations for Trajectory Optimization Under Signal Temporal Logic Specifications","headline":"提出基于精确平滑重构的轨迹优化方法，解决信号时序逻辑约束下的运动规划问题","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107375v1-exact-smooth-reformulations-for-trajectory-optimization-under-signal.html"},{"id":"2511.06745v1","title":"Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning","headline":"提出物理信息增强的变分自编码器，提升自监督强化学习中目标生成的物理合理性。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106745v1-physically-grounded-goal-imagination-physics-informed-variational-au.html"},{"id":"2511.07275v1","title":"Robotic versus Human Teleoperation for Remote Ultrasound","headline":"对比机器人与人工遥操作超声，评估其在远程医疗中的可行性","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107275v1-robotic-versus-human-teleoperation-for-remote-ultrasound.html"},{"id":"2511.07071v1","title":"Multi-Agent Reinforcement Learning for Deadlock Handling among Autonomous Mobile Robots","headline":"提出基于多智能体强化学习的死锁处理方法，提升AMR物流系统效率","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107071v1-multi-agent-reinforcement-learning-for-deadlock-handling-among-auton.html"},{"id":"2511.06801v1","title":"Vision-Aided Online A* Path Planning for Efficient and Safe Navigation of Service Robots","headline":"提出视觉辅助的在线A*路径规划，用于服务机器人高效安全导航","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106801v1-vision-aided-online-a-path-planning-for-efficient-and-safe-navigatio.html"},{"id":"2511.06754v2","title":"SlotVLA: Towards Modeling of Object-Relation Representations in Robotic Manipulation","headline":"提出SlotVLA框架，用于建模机器人操作中的对象关系表示，并构建LIBERO+基准数据集。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106754v2-slotvla-towards-modeling-of-object-relation-representations-in-robot.html"},{"id":"2511.06673v1","title":"Programmable Telescopic Soft Pneumatic Actuators for Deployable and Shape Morphing Soft Robots","headline":"提出可编程伸缩软气动执行器，用于可展开和变形软体机器人","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106673v1-programmable-telescopic-soft-pneumatic-actuators-for-deployable-and-.html"},{"id":"2511.07381v2","title":"Residual Rotation Correction using Tactile Equivariance","headline":"EquiTac：利用触觉等变性进行残差旋转校正，提升操作策略学习的样本效率。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107381v2-residual-rotation-correction-using-tactile-equivariance.html"},{"id":"2511.07619v1","title":"CAVER: Curious Audiovisual Exploring Robot","headline":"CAVER: 一种好奇心驱动的视听探索机器人，用于构建丰富的物体视听表征。","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251107619v1-caver-curious-audiovisual-exploring-robot.html"},{"id":"2511.06619v1","title":"How Do VLAs Effectively Inherit from VLMs?","headline":"提出GrinningFace基准，诊断VLA模型从VLM有效继承知识的能力","tag":"cs.RO","date":"2025-11-10","url":"cs-RO/2025-11-10/papers/251106619v1-how-do-vlas-effectively-inherit-from-vlms.html"},{"id":"2511.06765v1","title":"Robust and High-Fidelity 3D Gaussian Splatting: Fusing Pose Priors and Geometry Constraints for Texture-Deficient Outdoor Scenes","headline":"针对纹理缺失的室外场景，提出融合位姿先验和几何约束的鲁棒高保真3D高斯溅射方法","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106765v1-robust-and-high-fidelity-3d-gaussian-splatting-fusing-pose-priors-an.html"},{"id":"2511.07321v1","title":"YoNoSplat: You Only Need One Model for Feedforward 3D Gaussian Splatting","headline":"YoNoSplat：仅需单模型的前馈3D高斯溅射重建，适用于各种相机内外参场景","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107321v1-yonosplat-you-only-need-one-model-for-feedforward-3d-gaussian-splatt.html"},{"id":"2511.07122v1","title":"Sparse4DGS: 4D Gaussian Splatting for Sparse-Frame Dynamic Scene Reconstruction","headline":"Sparse4DGS：提出纹理感知正则化与优化，解决稀疏帧动态场景的4D高斯重建问题。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107122v1-sparse4dgs-4d-gaussian-splatting-for-sparse-frame-dynamic-scene-reco.html"},{"id":"2511.06817v3","title":"TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning","headline":"提出TiS-TSL，通过时序可切换的师生学习解决手术视频立体匹配中的时序一致性问题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106817v3-tis-tsl-image-label-supervised-surgical-video-stereo-matching-via-ti.html"},{"id":"2511.06953v1","title":"GFix: Perceptually Enhanced Gaussian Splatting Video Compression","headline":"GFix：提出感知增强的高斯溅射视频压缩方法，提升视觉质量和压缩率。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106953v1-gfix-perceptually-enhanced-gaussian-splatting-video-compression.html"},{"id":"2511.06958v2","title":"Learning from the Right Patches: A Two-Stage Wavelet-Driven Masked Autoencoder for Histopathology Representation Learning","headline":"WISE-MAE：一种基于小波变换的双阶段掩码自编码器，用于病理图像表征学习","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106958v2-learning-from-the-right-patches-a-two-stage-wavelet-driven-masked-au.html"},{"id":"2511.07007v1","title":"TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding","headline":"TrueCity：提出城市三维场景理解的真实与模拟跨域数据集","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107007v1-truecity-real-and-simulated-urban-data-for-cross-domain-3d-scene-und.html"},{"id":"2511.06734v1","title":"Rethinking Rainy 3D Scene Reconstruction via Perspective Transforming and Brightness Tuning","headline":"提出REVR-GSNet以解决雨天3D场景重建问题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106734v1-rethinking-rainy-3d-scene-reconstruction-via-perspective-transformin.html"},{"id":"2511.06830v1","title":"MUGSQA: Novel Multi-Uncertainty-Based Gaussian Splatting Quality Assessment Method, Dataset, and Benchmarks","headline":"提出MUGSQA数据集与评测方法，用于评估高斯溅射重建三维物体的感知质量。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106830v1-mugsqa-novel-multi-uncertainty-based-gaussian-splatting-quality-asse.html"},{"id":"2511.06810v1","title":"ConeGS: Error-Guided Densification Using Pixel Cones for Improved Reconstruction with Fewer Primitives","headline":"ConeGS：利用像素锥误差引导稠密化，以更少图元实现更优重建","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106810v1-conegs-error-guided-densification-using-pixel-cones-for-improved-rec.html"},{"id":"2511.06632v1","title":"DIAL-GS: Dynamic Instance Aware Reconstruction for Label-free Street Scenes with 4D Gaussian Splatting","headline":"DIAL-GS：用于无标签街景的动态实例感知4D高斯溅射重建","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106632v1-dial-gs-dynamic-instance-aware-reconstruction-for-label-free-street-.html"},{"id":"2511.07409v1","title":"DIMO: Diverse 3D Motion Generation for Arbitrary Objects","headline":"提出DIMO以生成任意物体的多样化3D运动","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107409v1-dimo-diverse-3d-motion-generation-for-arbitrary-objects.html"},{"id":"2511.07051v1","title":"Improving Deepfake Detection with Reinforcement Learning-Based Adaptive Data Augmentation","headline":"提出基于强化学习的自适应数据增强方法CRDA，提升Deepfake检测器的泛化能力。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107051v1-improving-deepfake-detection-with-reinforcement-learning-based-adapt.html"},{"id":"2511.07696v1","title":"FlowFeat: Pixel-Dense Embedding of Motion Profiles","headline":"提出FlowFeat，通过运动轮廓嵌入实现像素级密集图像表征，提升多种视觉任务性能。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107696v1-flowfeat-pixel-dense-embedding-of-motion-profiles.html"},{"id":"2511.07552v1","title":"LiveNeRF: Efficient Face Replacement Through Neural Radiance Fields Integration","headline":"LiveNeRF：通过神经辐射场集成实现高效人脸替换","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107552v1-livenerf-efficient-face-replacement-through-neural-radiance-fields-i.html"},{"id":"2511.07067v1","title":"RaLD: Generating High-Resolution 3D Radar Point Clouds with Latent Diffusion","headline":"提出RaLD，利用潜在扩散模型从雷达频谱生成高分辨率3D点云。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107067v1-rald-generating-high-resolution-3d-radar-point-clouds-with-latent-di.html"},{"id":"2511.07040v2","title":"3D-ANC: Adaptive Neural Collapse for Robust 3D Point Cloud Recognition","headline":"提出3D-ANC，利用神经崩溃机制提升3D点云识别的鲁棒性，对抗恶意攻击。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107040v2-3d-anc-adaptive-neural-collapse-for-robust-3d-point-cloud-recognitio.html"},{"id":"2511.07029v1","title":"Certified L2-Norm Robustness of 3D Point Cloud Recognition in the Frequency Domain","headline":"FreqCert：提出频域认证框架，提升3D点云识别对L2范数扰动的鲁棒性","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107029v1-certified-l2-norm-robustness-of-3d-point-cloud-recognition-in-the-fr.html"},{"id":"2511.06947v1","title":"FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection","headline":"提出FoCLIP框架，通过特征空间错位攻击和防御CLIP模型，提升图像篡改检测能力。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106947v1-foclip-a-feature-space-misalignment-framework-for-clip-based-image-m.html"},{"id":"2511.06840v1","title":"PanoNav: Mapless Zero-Shot Object Navigation with Panoramic Scene Parsing and Dynamic Memory","headline":"PanoNav：基于全景场景解析与动态记忆的无地图零样本物体导航","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106840v1-panonav-mapless-zero-shot-object-navigation-with-panoramic-scene-par.html"},{"id":"2511.06744v1","title":"PointCubeNet: 3D Part-level Reasoning with 3x3x3 Point Cloud Blocks","headline":"PointCubeNet：提出一种基于3x3x3点云块的无监督3D部件级推理框架","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106744v1-pointcubenet-3d-part-level-reasoning-with-3x3x3-point-cloud-blocks.html"},{"id":"2511.06721v1","title":"AvatarTex: High-Fidelity Facial Texture Reconstruction from Single-Image Stylized Avatars","headline":"AvatarTex：单图像生成高保真风格化头像纹理，解决几何一致性难题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106721v1-avatartex-high-fidelity-facial-texture-reconstruction-from-single-im.html"},{"id":"2511.11644v1","title":"Slow - Motion Video Synthesis for Basketball Using Frame Interpolation","headline":"通过微调RIFE网络，实现高质量篮球赛事慢动作视频合成","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251111644v1-slow-motion-video-synthesis-for-basketball-using-frame-interpolation.html"},{"id":"2511.06716v1","title":"MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos","headline":"MirrorMamba：提出一种可扩展且鲁棒的视频镜像检测方法","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106716v1-mirrormamba-towards-scalable-and-robust-mirror-detection-in-videos.html"},{"id":"2511.06593v1","title":"Spatial-Frequency Enhanced Mamba for Multi-Modal Image Fusion","headline":"提出空间-频率增强Mamba融合网络，提升多模态图像融合性能","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106593v1-spatial-frequency-enhanced-mamba-for-multi-modal-image-fusion.html"},{"id":"2511.07222v1","title":"Omni-View: Unlocking How Generation Facilitates Understanding in Unified 3D Model based on Multiview images","headline":"Omni-View：提出基于多视角图像的统一3D模型，探索生成促进理解的原理。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107222v1-omni-view-unlocking-how-generation-facilitates-understanding-in-unif.html"},{"id":"2511.07078v1","title":"LeCoT: revisiting network architecture for two-view correspondence pruning","headline":"LeCoT：通过空间-通道融合Transformer改进双视图对应关系剪枝","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107078v1-lecot-revisiting-network-architecture-for-two-view-correspondence-pr.html"},{"id":"2511.06833v1","title":"ConsistTalk: Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search","headline":"ConsistTalk：提出基于扩散噪声搜索的、强度可控且时序一致的说话人头部生成框架","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106833v1-consisttalk-intensity-controllable-temporally-consistent-talking-hea.html"},{"id":"2511.06717v2","title":"MRT: Learning Compact Representations with Mixed RWKV-Transformer for Extreme Image Compression","headline":"提出混合RWKV-Transformer的MRT模型，用于极低码率图像压缩，显著提升压缩性能。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106717v2-mrt-learning-compact-representations-with-mixed-rwkv-transformer-for.html"},{"id":"2511.06702v1","title":"SPAN: Spatial-Projection Alignment for Monocular 3D Object Detection","headline":"提出SPAN，通过空间投影对齐解决单目3D目标检测中的几何不一致问题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106702v1-span-spatial-projection-alignment-for-monocular-3d-object-detection.html"},{"id":"2511.06611v1","title":"On Accurate and Robust Estimation of 3D and 2D Circular Center: Method and Application to Camera-Lidar Calibration","headline":"提出基于共形几何代数的鲁棒圆形标靶中心估计方法，用于相机-激光雷达标定","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106611v1-on-accurate-and-robust-estimation-of-3d-and-2d-circular-center-metho.html"},{"id":"2511.07241v1","title":"4DSTR: Advancing Generative 4D Gaussians with Spatial-Temporal Rectification for High-Quality and Consistent 4D Generation","headline":"提出4DSTR网络，通过时空校正生成高质量、时序一致的4D高斯模型。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107241v1-4dstr-advancing-generative-4d-gaussians-with-spatial-temporal-rectif.html"},{"id":"2511.07210v2","title":"Breaking the Stealth-Potency Trade-off in Clean-Image Backdoors with Generative Trigger Optimization","headline":"提出GCB框架，通过生成式触发器优化解决clean-image后门攻击的隐蔽性与效力权衡问题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107210v2-breaking-the-stealth-potency-trade-off-in-clean-image-backdoors-with.html"},{"id":"2511.07206v1","title":"Geometric implicit neural representations for signed distance functions","headline":"提出几何隐式神经表示，用于有向距离函数的表面重建","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251107206v1-geometric-implicit-neural-representations-for-signed-distance-functi.html"},{"id":"2511.06908v1","title":"Mono3DVG-EnSD: Enhanced Spatial-aware and Dimension-decoupled Text Encoding for Monocular 3D Visual Grounding","headline":"提出Mono3DVG-EnSD框架，增强单目3D视觉定位中空间感知和维度解耦的文本编码。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106908v1-mono3dvg-ensd-enhanced-spatial-aware-and-dimension-decoupled-text-en.html"},{"id":"2511.06846v1","title":"Gaussian-Augmented Physics Simulation and System Identification with Complex Colliders","headline":"提出AS-DiffMPM，解决复杂碰撞体下基于视频的物理属性辨识难题","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106846v1-gaussian-augmented-physics-simulation-and-system-identification-with.html"},{"id":"2511.06823v1","title":"Integrating Reweighted Least Squares with Plug-and-Play Diffusion Priors for Noisy Image Restoration","headline":"提出基于重加权最小二乘与即插即用扩散先验的图像恢复框架，用于去除噪声。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106823v1-integrating-reweighted-least-squares-with-plug-and-play-diffusion-pr.html"},{"id":"2511.06644v1","title":"UniADC: A Unified Framework for Anomaly Detection and Classification","headline":"提出UniADC，统一异常检测与分类框架，解决信息孤岛问题。","tag":"cs.CV","date":"2025-11-10","url":"cs-CV/2025-11-10/papers/251106644v1-uniadc-a-unified-framework-for-anomaly-detection-and-classification.html"},{"id":"2511.07329v1","title":"Preparation of Fractal-Inspired Computational Architectures for Advanced Large Language Model Analysis","headline":"提出FractalNet，一种分形架构用于高效探索大规模语言模型分析","tag":"cs.LG","date":"2025-11-10","url":"cs-LG/2025-11-10/papers/251107329v1-preparation-of-fractal-inspired-computational-architectures-for-adva.html"},{"id":"2511.07085v1","title":"Achieving Effective Virtual Reality Interactions via Acoustic Gesture Recognition based on Large Language Models","headline":"提出基于大语言模型的声学手势识别框架，用于高效虚拟现实交互","tag":"cs.AI","date":"2025-11-10","url":"cs-AI/2025-11-10/papers/251107085v1-achieving-effective-virtual-reality-interactions-via-acoustic-gestur.html"},{"id":"2511.06465v1","title":"Sim-to-Real Transfer in Deep Reinforcement Learning for Bipedal Locomotion","headline":"针对双足机器人步态，提出基于深度强化学习的Sim-to-Real迁移方法","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106465v1-sim-to-real-transfer-in-deep-reinforcement-learning-for-bipedal-loco.html"},{"id":"2511.06397v1","title":"Whole-Body Control With Terrain Estimation of A 6-DoF Wheeled Bipedal Robot","headline":"针对6自由度轮式双足机器人，提出融合地形估计的全身控制框架","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106397v1-whole-body-control-with-terrain-estimation-of-a-6-dof-wheeled-bipeda.html"},{"id":"2511.06371v2","title":"Towards Adaptive Humanoid Control via Multi-Behavior Distillation and Reinforced Fine-Tuning","headline":"提出AHC框架，通过多行为蒸馏和强化微调实现人形机器人自适应控制","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106371v2-towards-adaptive-humanoid-control-via-multi-behavior-distillation-an.html"},{"id":"2511.06515v1","title":"Koopman global linearization of contact dynamics for robot locomotion and manipulation enables elaborate control","headline":"利用Koopman算子全局线性化接触动力学，实现机器人复杂控制策略","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106515v1-koopman-global-linearization-of-contact-dynamics-for-robot-locomotio.html"},{"id":"2511.06240v1","title":"Affordance-Guided Coarse-to-Fine Exploration for Base Placement in Open-Vocabulary Mobile Manipulation","headline":"提出Affordance引导的粗到细探索方法，解决开放词汇移动操作中的基座放置问题","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106240v1-affordance-guided-coarse-to-fine-exploration-for-base-placement-in-o.html"},{"id":"2511.06500v1","title":"Adaptive PID Control for Robotic Systems via Hierarchical Meta-Learning and Reinforcement Learning with Physics-Based Data Augmentation","headline":"提出基于层级元学习与强化学习的自适应PID控制框架，提升机器人系统性能。","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106500v1-adaptive-pid-control-for-robotic-systems-via-hierarchical-meta-learn.html"},{"id":"2511.06378v1","title":"ArtReg: Visuo-Tactile based Pose Tracking and Manipulation of Unseen Articulated Objects","headline":"提出ArtReg，用于未知铰接物体的视觉-触觉融合位姿跟踪与操作","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106378v1-artreg-visuo-tactile-based-pose-tracking-and-manipulation-of-unseen-.html"},{"id":"2511.06182v2","title":"OpenVLN: Open-world Aerial Vision-Language Navigation","headline":"提出OpenVLN框架，解决开放世界空中视觉-语言导航中的长程规划问题。","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106182v2-openvln-open-world-aerial-vision-language-navigation.html"},{"id":"2511.06434v2","title":"Real Garment Benchmark (RGBench): A Comprehensive Benchmark for Robotic Garment Manipulation featuring a High-Fidelity Scalable Simulator","headline":"提出RGBench：一个用于机器人服装操作的高保真可扩展模拟器基准","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106434v2-real-garment-benchmark-rgbench-a-comprehensive-benchmark-for-robotic.html"},{"id":"2511.06267v1","title":"Robust Differentiable Collision Detection for General Objects","headline":"提出鲁棒可微碰撞检测框架，支持复杂物体抓取与操作的梯度优化。","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106267v1-robust-differentiable-collision-detection-for-general-objects.html"},{"id":"2511.06385v1","title":"From Demonstrations to Safe Deployment: Path-Consistent Safety Filtering for Diffusion Policies","headline":"提出路径一致性安全过滤(PACS)方法，保障Diffusion策略在人机交互中的安全部署。","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106385v1-from-demonstrations-to-safe-deployment-path-consistent-safety-filter.html"},{"id":"2511.06311v1","title":"External Photoreflective Tactile Sensing Based on Surface Deformation Measurement","headline":"提出一种基于表面形变测量的外置光反射触觉传感方法，用于软体机器人。","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106311v1-external-photoreflective-tactile-sensing-based-on-surface-deformatio.html"},{"id":"2511.06202v1","title":"ExpReS-VLA: Specializing Vision-Language-Action Models Through Experience Replay and Retrieval","headline":"ExpReS-VLA：通过经验回放与检索实现VLA模型在机器人操作任务中的高效特化","tag":"cs.RO","date":"2025-11-09","url":"cs-RO/2025-11-09/papers/251106202v1-expres-vla-specializing-vision-language-action-models-through-experi.html"},{"id":"2511.06457v1","title":"Inpaint360GS: Efficient Object-Aware 3D Inpainting via Gaussian Splatting for 360° Scenes","headline":"提出Inpaint360GS，通过高斯溅射实现高效的360°场景物体感知3D修复。","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106457v1-inpaint360gs-efficient-object-aware-3d-inpainting-via-gaussian-splat.html"},{"id":"2511.06408v1","title":"VDNeRF: Vision-only Dynamic Neural Radiance Field for Urban Scenes","headline":"提出VDNeRF以解决动态城市场景中的相机姿态估计问题","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106408v1-vdnerf-vision-only-dynamic-neural-radiance-field-for-urban-scenes.html"},{"id":"2511.06299v3","title":"Physics-Informed Deformable Gaussian Splatting: Towards Unified Constitutive Laws for Time-Evolving Material Field","headline":"提出物理信息可变形高斯溅射，统一时变材料场的本构定律，提升动态场景重建质量。","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106299v3-physics-informed-deformable-gaussian-splatting-towards-unified-const.html"},{"id":"2511.06245v1","title":"Gait Recognition via Collaborating Discriminative and Generative Diffusion Models","headline":"提出CoD$^2$框架，结合判别与生成扩散模型提升步态识别性能","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106245v1-gait-recognition-via-collaborating-discriminative-and-generative-dif.html"},{"id":"2511.06422v1","title":"DiffusionUavLoc: Visually Prompted Diffusion for Cross-View UAV Localization","headline":"DiffusionUavLoc：基于视觉提示扩散的跨视角无人机定位方法","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106422v1-diffusionuavloc-visually-prompted-diffusion-for-cross-view-uav-local.html"},{"id":"2511.06325v1","title":"CINEMAE: Leveraging Frozen Masked Autoencoders for Cross-Generator AI Image Detection","headline":"CINEMAE：利用冻结的掩码自编码器进行跨生成器AI图像检测","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106325v1-cinemae-leveraging-frozen-masked-autoencoders-for-cross-generator-ai.html"},{"id":"2511.06261v2","title":"Robust Nearest Neighbour Retrieval Using Targeted Manifold Manipulation","headline":"提出TMM-NN，通过目标流形操控实现鲁棒的近邻检索，提升噪声环境下的性能。","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106261v2-robust-nearest-neighbour-retrieval-using-targeted-manifold-manipulat.html"},{"id":"2511.06281v1","title":"VideoSSR: Video Self-Supervised Reinforcement Learning","headline":"提出VideoSSR，利用视频自监督强化学习提升多模态大语言模型的视频理解能力。","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106281v1-videossr-video-self-supervised-reinforcement-learning.html"},{"id":"2511.06337v1","title":"BuildingWorld: A Structured 3D Building Dataset for Urban Foundation Models","headline":"BuildingWorld：构建用于城市基础模型的结构化3D建筑数据集","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106337v1-buildingworld-a-structured-3d-building-dataset-for-urban-foundation-.html"},{"id":"2511.06331v1","title":"Label-Efficient 3D Forest Mapping: Self-Supervised and Transfer Learning for Individual, Structural, and Species Analysis","headline":"利用自监督和迁移学习实现标签高效的3D森林测绘","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106331v1-label-efficient-3d-forest-mapping-self-supervised-and-transfer-learn.html"},{"id":"2511.06310v1","title":"Adaptive 3D Reconstruction via Diffusion Priors and Forward Curvature-Matching Likelihood Updates","headline":"提出基于扩散先验和前向曲率匹配的自适应3D重建方法，提升重建质量和效率。","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106310v1-adaptive-3d-reconstruction-via-diffusion-priors-and-forward-curvatur.html"},{"id":"2511.06238v1","title":"Temporal-Guided Visual Foundation Models for Event-Based Vision","headline":"提出TGVFM，利用时序引导的视觉基础模型解决事件相机视觉任务","tag":"cs.CV","date":"2025-11-09","url":"cs-CV/2025-11-09/papers/251106238v1-temporal-guided-visual-foundation-models-for-event-based-vision.html"},{"id":"2511.06471v2","title":"GHOST: Solving the Traveling Salesman Problem on Graphs of Convex Sets","headline":"GHOST：求解凸集图上的旅行商问题，用于轨迹规划","tag":"cs.AI","date":"2025-11-09","url":"cs-AI/2025-11-09/papers/251106471v2-ghost-solving-the-traveling-salesman-problem-on-graphs-of-convex-set.html"},{"id":"2511.05858v2","title":"ViTaMIn-B: A Reliable and Efficient Visuo-Tactile Bimanual Manipulation Interface","headline":"ViTaMIn-B：一种可靠高效的双手视觉触觉操作交互界面","tag":"cs.RO","date":"2025-11-08","url":"cs-RO/2025-11-08/papers/251105858v2-vitamin-b-a-reliable-and-efficient-visuo-tactile-bimanual-manipulati.html"},{"id":"2511.05855v1","title":"Gentle Manipulation Policy Learning via Demonstrations from VLM Planned Atomic Skills","headline":"提出基于VLM规划原子技能的柔性操作策略学习框架，无需人工演示。","tag":"cs.RO","date":"2025-11-08","url":"cs-RO/2025-11-08/papers/251105855v1-gentle-manipulation-policy-learning-via-demonstrations-from-vlm-plan.html"},{"id":"2511.05889v1","title":"From Words to Safety: Language-Conditioned Safety Filtering for Robot Navigation","headline":"提出一种基于语言条件的安全过滤框架，用于机器人导航中的安全约束。","tag":"cs.RO","date":"2025-11-08","url":"cs-RO/2025-11-08/papers/251105889v1-from-words-to-safety-language-conditioned-safety-filtering-for-robot.html"},{"id":"2511.06115v1","title":"DiLO: Disentangled Latent Optimization for Learning Shape and Deformation in Grouped Deforming 3D Objects","headline":"DiLO：解耦潜在空间优化，用于学习分组形变3D对象的形状和形变","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251106115v1-dilo-disentangled-latent-optimization-for-learning-shape-and-deforma.html"},{"id":"2511.05965v1","title":"Adaptive Agent Selection and Interaction Network for Image-to-point cloud Registration","headline":"提出自适应Agent选择与交互网络，用于图像到点云的精确配准","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105965v1-adaptive-agent-selection-and-interaction-network-for-image-to-point-.html"},{"id":"2511.06046v1","title":"StreamSTGS: Streaming Spatial and Temporal Gaussian Grids for Real-Time Free-Viewpoint Video","headline":"提出StreamSTGS，用于实时自由视点视频的流式传输，兼顾性能与效率。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251106046v1-streamstgs-streaming-spatial-and-temporal-gaussian-grids-for-real-ti.html"},{"id":"2511.05876v3","title":"MoEGCL: Mixture of Ego-Graphs Contrastive Representation Learning for Multi-View Clustering","headline":"提出MoEGCL，通过混合自 Ego 图对比学习提升多视图聚类性能","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105876v3-moegcl-mixture-of-ego-graphs-contrastive-representation-learning-for.html"},{"id":"2511.05866v1","title":"Light-Field Dataset for Disparity Based Depth Estimation","headline":"提出用于视差深度估计的光场数据集，解决现有数据集的局限性。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105866v1-light-field-dataset-for-disparity-based-depth-estimation.html"},{"id":"2511.05853v1","title":"Point Cloud Segmentation of Integrated Circuits Package Substrates Surface Defects Using Causal Inference: Dataset Construction and Methodology","headline":"针对集成电路封装基板表面缺陷，提出基于因果推理的点云分割方法CINet。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105853v1-point-cloud-segmentation-of-integrated-circuits-package-substrates-s.html"},{"id":"2511.06138v1","title":"Latent Refinement via Flow Matching for Training-free Linear Inverse Problem Solving","headline":"提出LFlow：基于Flow Matching的免训练线性逆问题隐空间优化方法","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251106138v1-latent-refinement-via-flow-matching-for-training-free-linear-inverse.html"},{"id":"2511.05996v1","title":"Exploring Category-level Articulated Object Pose Tracking on SE(3) Manifolds","headline":"提出PPF-Tracker以解决关节物体姿态跟踪问题","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105996v1-exploring-category-level-articulated-object-pose-tracking-on-se3-man.html"},{"id":"2511.05929v1","title":"CoMA: Complementary Masking and Hierarchical Dynamic Multi-Window Self-Attention in a Unified Pre-training Framework","headline":"CoMA：互补掩码与分层动态多窗口自注意力，提升MAE预训练效率。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105929v1-coma-complementary-masking-and-hierarchical-dynamic-multi-window-sel.html"},{"id":"2511.06019v1","title":"MiVID: Multi-Strategic Self-Supervision for Video Frame Interpolation using Diffusion Model","headline":"MiVID：基于扩散模型的多策略自监督视频帧插值","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251106019v1-mivid-multi-strategic-self-supervision-for-video-frame-interpolation.html"},{"id":"2511.05946v1","title":"Reperio-rPPG: Relational Temporal Graph Neural Networks for Periodicity Learning in Remote Physiological Measurement","headline":"提出Reperio-rPPG，利用关系时序图神经网络学习远程生理信号的周期性，实现更鲁棒的心率估计。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105946v1-reperio-rppg-relational-temporal-graph-neural-networks-for-periodici.html"},{"id":"2511.05894v1","title":"Open-World 3D Scene Graph Generation for Retrieval-Augmented Reasoning","headline":"提出基于检索增强推理的开放世界3D场景图生成框架，用于通用和交互式3D场景理解。","tag":"cs.CV","date":"2025-11-08","url":"cs-CV/2025-11-08/papers/251105894v1-open-world-3d-scene-graph-generation-for-retrieval-augmented-reasoni.html"},{"id":"2511.05900v2","title":"Disentangled Control of Multi-Agent Systems","headline":"提出解耦多智能体系统控制框架，解决复杂拓扑和时变目标下的控制问题","tag":"eess.SY","date":"2025-11-08","url":"eess-SY/2025-11-08/papers/251105900v2-disentangled-control-of-multi-agent-systems.html"},{"id":"2511.04951v1","title":"CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting","headline":"CLM：通过CPU卸载解决3D高斯溅射的GPU内存瓶颈","tag":"cs.CV","date":"2025-11-07","url":"cs-CV/2025-11-07/papers/251104951v1-clm-removing-the-gpu-memory-barrier-for-3d-gaussian-splatting.html"},{"id":"2511.04949v1","title":"DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning","headline":"提出DeepForgeSeal，利用潜空间水印和对抗强化学习进行深度伪造检测。","tag":"cs.CV","date":"2025-11-07","url":"cs-CV/2025-11-07/papers/251104949v1-deepforgeseal-latent-space-driven-semi-fragile-watermarking-for-deep.html"},{"id":"2511.04131v1","title":"BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning","headline":"BFM-Zero：基于无监督强化学习的可提示人形机器人行为基础模型","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104131v1-bfm-zero-a-promptable-behavioral-foundation-model-for-humanoid-contr.html"},{"id":"2511.04199v1","title":"GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments","headline":"GraspView：面向杂乱环境的基于主动感知评分和最佳视角优化的机器人抓取","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104199v1-graspview-active-perception-scoring-and-best-view-optimization-for-r.html"},{"id":"2511.03996v1","title":"Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots","headline":"提出基于视觉的强化学习方法，用于人形机器人足球技能的反应式控制","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251103996v1-learning-vision-driven-reactive-soccer-skills-for-humanoid-robots.html"},{"id":"2511.04009v1","title":"Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration","headline":"提出一种人机双臂协同搬运姿态优化方法，兼顾人体工效学与操作灵活性。","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104009v1-integrating-ergonomics-and-manipulability-for-upper-limb-postural-op.html"},{"id":"2511.04679v1","title":"GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction","headline":"GentleHumanoid：学习上肢柔顺性，实现人机和人机交互中的丰富接触","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104679v1-gentlehumanoid-learning-upper-body-compliance-for-contact-rich-human.html"},{"id":"2511.04831v1","title":"Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning","headline":"Isaac Lab：用于大规模多模态机器人学习的GPU加速仿真框架","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104831v1-isaac-lab-a-gpu-accelerated-simulation-framework-for-multi-modal-rob.html"},{"id":"2511.04758v1","title":"ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling","headline":"提出ScheduleStream框架，通过GPU加速采样实现多臂机器人任务和运动规划与调度","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104758v1-schedulestream-temporal-planning-with-samplers-for-gpu-accelerated-m.html"},{"id":"2511.04671v1","title":"X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations","headline":"X-Diffusion：利用跨具身人类演示训练扩散策略，提升机器人操作性能","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104671v1-x-diffusion-training-diffusion-policies-on-cross-embodiment-human-de.html"},{"id":"2511.04665v2","title":"Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions","headline":"提出基于高斯溅射的软体交互机器人策略Real2Sim评估框架","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104665v2-real-to-sim-robot-policy-evaluation-with-gaussian-splatting-simulati.html"},{"id":"2511.04320v1","title":"MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments","headline":"MacroNav：多任务上下文表征学习实现未知环境高效导航","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104320v1-macronav-multi-task-context-representation-learning-enables-efficien.html"},{"id":"2511.04381v1","title":"ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation","headline":"ForeRobo：利用生成式模拟数据驱动3D目标导向机器人操作","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104381v1-forerobo-unlocking-infinite-simulation-data-for-3d-goal-driven-robot.html"},{"id":"2511.04249v1","title":"Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies","headline":"提出上下文感知策略，提升强化学习中仿真到真实环境的迁移性能","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104249v1-can-context-bridge-the-reality-gap-sim-to-real-transfer-of-context-a.html"},{"id":"2511.04180v2","title":"PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration","headline":"PUL-SLAM：基于路径不确定性协同优化与轻量级停滞检测的高效机器人探索","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104180v2-pul-slam-path-uncertainty-co-optimization-with-lightweight-stagnatio.html"},{"id":"2511.04052v1","title":"Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors","headline":"针对深空探测，论文提出基于多核处理器的容错GNC/LVS系统，加速并保障计算可靠性。","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104052v1-enhancing-fault-tolerant-space-computing-guidance-navigation-and-con.html"},{"id":"2511.04812v1","title":"Unified Multimodal Diffusion Forcing for Forceful Manipulation","headline":"提出多模态扩散强制（MDF）框架，用于力觉操作中的多模态轨迹学习与重建。","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104812v1-unified-multimodal-diffusion-forcing-for-forceful-manipulation.html"},{"id":"2511.04357v1","title":"GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies","headline":"GraSP-VLA：基于图的符号动作表示用于VLA策略的长程规划","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104357v1-grasp-vla-graph-based-symbolic-action-representation-for-long-horizo.html"},{"id":"2511.04109v1","title":"CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN","headline":"提出基于SNN的CBMC-V3控制框架，提升机器人手臂在复杂环境中的操作灵活性。","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104109v1-cbmc-v3-a-cns-inspired-control-framework-towards-manipulation-agilit.html"},{"id":"2511.04835v1","title":"Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning","headline":"提出基于保角预测的非均匀采样策略，加速采样运动规划","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251104835v1-conformalized-non-uniform-sampling-strategies-for-accelerated-sampli.html"},{"id":"2512.00027v1","title":"A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation","headline":"综述视觉语言导航在人机协作中的应用，探索多机器人协同的未来方向","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251200027v1-a-survey-on-improving-human-robot-collaboration-through-vision-and-l.html"},{"id":"2511.03931v1","title":"Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction","headline":"提出基于数据驱动模型降阶的软体机器人动态形状控制方法","tag":"cs.RO","date":"2025-11-06","url":"cs-RO/2025-11-06/papers/251103931v1-dynamic-shape-control-of-soft-robots-enabled-by-data-driven-model-re.html"},{"id":"2511.04283v3","title":"FastGS: Training 3D Gaussian Splatting in 100 Seconds","headline":"FastGS：基于多视角一致性的3D高斯溅射加速训练框架","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104283v3-fastgs-training-3d-gaussian-splatting-in-100-seconds.html"},{"id":"2511.03992v1","title":"CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation","headline":"CaRF：通过增强多视角一致性改进Referring 3D高斯溅射分割","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251103992v1-carf-enhancing-multi-view-consistency-in-referring-3d-gaussian-splat.html"},{"id":"2511.04388v1","title":"BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems","headline":"提出BoRe-Depth模型，在嵌入式系统上实现高精度、高效率的单目深度估计，并提升边界质量。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104388v1-bore-depth-self-supervised-monocular-depth-estimation-with-boundary-.html"},{"id":"2511.04281v1","title":"DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification","headline":"提出DinoGRL框架，利用DINOv2驱动的步态特征学习，解决视频可见光-红外行人重识别问题。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104281v1-dinov2-driven-gait-representation-learning-for-video-based-visible-i.html"},{"id":"2511.03988v1","title":"Simple 3D Pose Features Support Human and Machine Social Scene Understanding","headline":"提出基于3D姿态特征的人机社交场景理解方法，超越现有AI模型。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251103988v1-simple-3d-pose-features-support-human-and-machine-social-scene-under.html"},{"id":"2511.04797v1","title":"3D Gaussian Point Encoders","headline":"提出基于3D高斯点编码器的点云表示方法，加速3D识别任务。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104797v1-3d-gaussian-point-encoders.html"},{"id":"2511.05609v1","title":"Walking the Schrödinger Bridge: A Direct Trajectory for Text-to-3D Generation","headline":"提出基于Schrödinger桥的直接轨迹以解决文本到3D生成中的伪影问题","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251105609v1-walking-the-schrödinger-bridge-a-direct-trajectory-for-text-to-3d-ge.html"},{"id":"2511.04595v1","title":"UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction","headline":"UniSplat：通过3D潜在支架实现动态驾驶场景的统一时空融合重建","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104595v1-unisplat-unified-spatio-temporal-fusion-via-3d-latent-scaffolds-for-.html"},{"id":"2511.05623v1","title":"Registration-Free Monitoring of Unstructured Point Cloud Data via Intrinsic Geometrical Properties","headline":"提出一种免配准的点云数据监控方法，用于检测3D物体几何精度。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251105623v1-registration-free-monitoring-of-unstructured-point-cloud-data-via-in.html"},{"id":"2511.04864v2","title":"Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction","headline":"提出自监督隐式注意力先验，用于点云重建，提升细节保持和鲁棒性。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104864v2-self-supervised-implicit-attention-priors-for-point-cloud-reconstruc.html"},{"id":"2511.03943v3","title":"Temporal Zoom Networks: Distance Regression and Continuous Depth for Efficient Action Localization","headline":"提出边界距离回归与自适应时间细化以提升动作定位效率","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251103943v3-temporal-zoom-networks-distance-regression-and-continuous-depth-for-.html"},{"id":"2511.04394v1","title":"DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale","headline":"DORAEMON：一个用于大规模视觉对象建模和表征学习的统一库","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104394v1-doraemon-a-unified-library-for-visual-object-modeling-and-representa.html"},{"id":"2511.04779v1","title":"EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear","headline":"EETnet：为智能眼镜设计的基于事件的低功耗注视检测与跟踪CNN","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104779v1-eetnet-a-cnn-for-gaze-detection-and-tracking-for-smart-eyewear.html"},{"id":"2511.04128v2","title":"DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms","headline":"DMSORT：一种高效的并行海事多目标跟踪架构，适用于无人船平台","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104128v2-dmsort-an-efficient-parallel-maritime-multi-object-tracking-architec.html"},{"id":"2511.04029v3","title":"Faithful Contouring: Near-Lossless 3D Voxel Representation Free from Iso-surface","headline":"提出 Faithful Contouring，实现近乎无损的3D体素表示，无需等值面提取。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251104029v3-faithful-contouring-near-lossless-3d-voxel-representation-free-from-.html"},{"id":"2511.03970v1","title":"Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images","headline":"提出Room Envelopes数据集，用于图像室内布局重建，提升场景理解能力。","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251103970v1-room-envelopes-a-synthetic-dataset-for-indoor-layout-reconstruction-.html"},{"id":"2511.03950v1","title":"Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization","headline":"提出纹理引导的高斯-网格联合优化方法，提升多视角重建质量","tag":"cs.CV","date":"2025-11-06","url":"cs-CV/2025-11-06/papers/251103950v1-improving-multi-view-reconstruction-via-texture-guided-gaussian-mesh.html"},{"id":"2511.03167v1","title":"Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning","headline":"提出基于运动先验的深度强化学习方法，实现六足机器人复杂地形自然稳健的运动","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103167v1-learning-natural-and-robust-hexapod-locomotion-over-complex-terrains.html"},{"id":"2511.03691v1","title":"Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping","headline":"提出一种无源双稳态流体夹爪，实现尺寸选择性和刚度自适应抓取","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103691v1-source-free-bistable-fluidic-gripper-for-size-selective-and-stiffnes.html"},{"id":"2511.03571v1","title":"OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera","headline":"OneOcc：针对腿足机器人，利用单目全景相机进行语义占据预测","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103571v1-oneocc-semantic-occupancy-prediction-for-legged-robots-with-a-single.html"},{"id":"2511.03591v1","title":"Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning","headline":"提出流形约束Hamilton-Jacobi可达性学习，用于分散式多智能体运动规划","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103591v1-manifold-constrained-hamilton-jacobi-reachability-learning-for-decen.html"},{"id":"2511.03481v2","title":"Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control","headline":"提出基于本体感受顺应控制的肌腱驱动灵巧手DexHand 021，提升操作性能。","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103481v2-development-of-the-bioinspired-tendon-driven-dexhand-021-with-propri.html"},{"id":"2511.03652v1","title":"Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments","headline":"针对语义未知环境，提出基于时序逻辑规范的运动规划方法","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103652v1-motion-planning-under-temporal-logic-specifications-in-semantically-.html"},{"id":"2511.03189v1","title":"Collaborative Assembly Policy Learning of a Sightless Robot","headline":"提出基于强化学习的协作式装配策略，提升无视觉机器人人机协作效率","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103189v1-collaborative-assembly-policy-learning-of-a-sightless-robot.html"},{"id":"2511.03181v1","title":"Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control","headline":"提出基于学习的协作机器人纸张包装方法，结合残差力控制实现高成功率。","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103181v1-learning-based-cooperative-robotic-paper-wrapping-a-unified-control-.html"},{"id":"2511.03400v2","title":"GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement","headline":"GUIDES：利用Instructor蒸馏嵌入增强预训练机器人策略，提升语义感知能力。","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103400v2-guides-guidance-using-instructor-distilled-embeddings-for-pre-traine.html"},{"id":"2511.03165v1","title":"SENT Map -- Semantically Enhanced Topological Maps with Foundation Models","headline":"提出SENT-Map，利用基础模型增强拓扑地图，支持室内自主导航与操作","tag":"cs.RO","date":"2025-11-05","url":"cs-RO/2025-11-05/papers/251103165v1-sent-map-semantically-enhanced-topological-maps-with-foundation-mode.html"},{"id":"2511.03099v1","title":"DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs","headline":"提出DentalSplat以解决稀疏口腔影像下的牙齿咬合重建问题","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103099v1-dentalsplat-dental-occlusion-novel-view-synthesis-from-sparse-intra-.html"},{"id":"2511.03882v1","title":"Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures","headline":"提出基于模仿学习的机器人控制策略，用于X射线引导的脊柱手术","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103882v1-investigating-robot-control-policy-learning-for-autonomous-x-ray-gui.html"},{"id":"2511.03666v1","title":"Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection","headline":"提出Part-Aware自底向上群体推理框架，用于细粒度社交互动检测","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103666v1-part-aware-bottom-up-group-reasoning-for-fine-grained-social-interac.html"},{"id":"2511.03325v2","title":"SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding","headline":"SurgViVQA：面向手术场景理解的时序视频问答模型","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103325v2-surgvivqa-temporally-grounded-video-question-answering-for-surgical-.html"},{"id":"2511.03267v1","title":"IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection","headline":"提出IEC3D-AD工业零件3D异常检测数据集及GMANet异常检测方法","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103267v1-iec3d-ad-a-3d-dataset-of-industrial-equipment-components-for-unsuper.html"},{"id":"2511.03163v1","title":"Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation","headline":"提出SRFT-GaLore，用于深度驱动的肝脏地标分割中高效自适应基础模型。","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103163v1-subsampled-randomized-fourier-galore-for-adapting-foundation-models-.html"},{"id":"2511.03589v1","title":"Human Mesh Modeling for Anny Body","headline":"提出Anny：一个基于人体测量学知识的可微、无扫描的人体网格建模方法","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103589v1-human-mesh-modeling-for-anny-body.html"},{"id":"2511.03334v1","title":"UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions","headline":"UniAVGen：提出一种非对称跨模态交互的统一音视频生成框架","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103334v1-uniavgen-unified-audio-and-video-generation-with-asymmetric-cross-mo.html"},{"id":"2511.03876v1","title":"Computed Tomography (CT)-derived Cardiovascular Flow Estimation Using Physics-Informed Neural Networks Improves with Sinogram-based Training: A Simulation Study","headline":"提出SinoFlow：利用Sinogram数据训练的物理信息神经网络提升CT血流估计精度","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251103876v1-computed-tomography-ct-derived-cardiovascular-flow-estimation-using-.html"},{"id":"2511.05590v1","title":"Beyond Softmax: Dual-Branch Sigmoid Architecture for Accurate Class Activation Maps","headline":"提出双分支Sigmoid架构，解决CAM中logit偏移和符号坍塌问题，提升定位精度。","tag":"cs.CV","date":"2025-11-05","url":"cs-CV/2025-11-05/papers/251105590v1-beyond-softmax-dual-branch-sigmoid-architecture-for-accurate-class-a.html"},{"id":"2511.03147v1","title":"Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models","headline":"针对CAD模型神经SDF，提出ODW损失调度策略，提升重建精度。","tag":"cs.GR","date":"2025-11-05","url":"cs-GR/2025-11-05/papers/251103147v1-scheduling-the-off-diagonal-weingarten-loss-of-neural-sdfs-for-cad-m.html"},{"id":"2511.03187v3","title":"Periodic Skill Discovery","headline":"提出周期性技能发现（PSD）框架，用于无监督地学习机器人周期性运动技能。","tag":"cs.LG","date":"2025-11-05","url":"cs-LG/2025-11-05/papers/251103187v3-periodic-skill-discovery.html"},{"id":"2511.03173v1","title":"Optimizing Earth-Moon Transfer and Cislunar Navigation: Integrating Low-Energy Trajectories, AI Techniques and GNSS-R Technologies","headline":"融合低能轨道、AI与GNSS-R技术，优化地月转移和月球导航","tag":"cs.AI","date":"2025-11-05","url":"cs-AI/2025-11-05/papers/251103173v1-optimizing-earth-moon-transfer-and-cislunar-navigation-integrating-l.html"},{"id":"2511.02832v1","title":"TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System","headline":"TWIST2：一种可扩展、便携、整体的人形机器人数据收集系统","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102832v1-twist2-scalable-portable-and-holistic-humanoid-data-collection-syste.html"},{"id":"2511.02342v2","title":"Whole-body motion planning and safety-critical control for aerial manipulation","headline":"提出基于超二次曲面的无人机操作臂全身运动规划与安全控制框架","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102342v2-whole-body-motion-planning-and-safety-critical-control-for-aerial-ma.html"},{"id":"2511.03077v1","title":"WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models","headline":"WorldPlanner：基于动作条件视觉世界模型的MCTS和MPC机器人规划","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251103077v1-worldplanner-monte-carlo-tree-search-and-mpc-with-action-conditioned.html"},{"id":"2511.02504v1","title":"Dexterous Robotic Piano Playing at Scale","headline":"OmniPianist：通过大规模无监督学习实现高灵巧度机器人钢琴演奏","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102504v1-dexterous-robotic-piano-playing-at-scale.html"},{"id":"2511.02192v1","title":"A Quantitative Comparison of Centralised and Distributed Reinforcement Learning-Based Control for Soft Robotic Arms","headline":"对比集中式与分布式强化学习控制软体机械臂，为软体机器人控制提供设计指导。","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102192v1-a-quantitative-comparison-of-centralised-and-distributed-reinforceme.html"},{"id":"2511.02776v1","title":"XR-1: Towards Versatile Vision-Language-Action Models via Learning Unified Vision-Motion Representations","headline":"XR-1：通过学习统一视觉-运动表征，实现通用视觉-语言-动作模型","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102776v1-xr-1-towards-versatile-vision-language-action-models-via-learning-un.html"},{"id":"2511.02761v1","title":"Non-Contact Manipulation of Induced Magnetic Dipoles","headline":"提出基于感应磁偶极子的非接触式闭环位置控制方法，应用于空间碎片回收。","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102761v1-non-contact-manipulation-of-induced-magnetic-dipoles.html"},{"id":"2511.02239v1","title":"LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation","headline":"LACY：基于视觉-语言模型的语言-动作循环，用于自提升的机器人操作","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102239v1-lacy-a-vision-language-model-based-language-action-cycle-for-self-im.html"},{"id":"2511.02294v1","title":"SuckTac: Camera-based Tactile Sucker for Unstructured Surface Perception and Interaction","headline":"SuckTac：用于非结构化表面感知与交互的相机触觉吸盘","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251102294v1-sucktac-camera-based-tactile-sucker-for-unstructured-surface-percept.html"},{"id":"2511.03078v2","title":"3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors","headline":"3D Cal：开源触觉传感器标定库，利用3D打印机实现自动化标定。","tag":"cs.RO","date":"2025-11-04","url":"cs-RO/2025-11-04/papers/251103078v2-3d-cal-an-open-source-software-library-for-calibrating-tactile-senso.html"},{"id":"2511.02207v1","title":"Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction and Phenotyping","headline":"提出对象中心3D高斯溅射方法，用于草莓植株重建与表型分析","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102207v1-object-centric-3d-gaussian-splatting-for-strawberry-plant-reconstruc.html"},{"id":"2511.02395v1","title":"Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar Point Clouds","headline":"提出一种自监督雷达点云移动物体分割方法，提升稀疏噪声数据的分割性能。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102395v1-self-supervised-moving-object-segmentation-of-sparse-and-noisy-radar.html"},{"id":"2511.02247v1","title":"Monocular absolute depth estimation from endoscopy via domain-invariant feature learning and latent consistency","headline":"提出基于特征对齐和潜在一致性的单目内窥镜绝对深度估计方法","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102247v1-monocular-absolute-depth-estimation-from-endoscopy-via-domain-invari.html"},{"id":"2511.03053v1","title":"From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth","headline":"提出一种基于学习的MLS点云不确定性评估框架，无需大量真值数据。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251103053v1-from-propagation-to-prediction-point-level-uncertainty-evaluation-of.html"},{"id":"2511.02953v1","title":"EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation","headline":"EvtSlowTV：用于事件相机深度估计的大规模多样化数据集","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102953v1-evtslowtv-a-large-and-diverse-dataset-for-event-based-depth-estimati.html"},{"id":"2511.02489v1","title":"Object Detection as an Optional Basis: A Graph Matching Network for Cross-View UAV Localization","headline":"提出基于对象检测和图匹配网络的跨视角无人机定位方法，解决异构图像匹配问题。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102489v1-object-detection-as-an-optional-basis-a-graph-matching-network-for-c.html"},{"id":"2511.02397v1","title":"A Novel Grouping-Based Hybrid Color Correction Algorithm for Color Point Clouds","headline":"提出一种基于分组的混合颜色校正算法，用于彩色点云的颜色一致性校正。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102397v1-a-novel-grouping-based-hybrid-color-correction-algorithm-for-color-p.html"},{"id":"2511.02329v1","title":"Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization","headline":"Cycle-Sync：通过增强的循环一致性同步实现稳健的全局相机位姿估计","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102329v1-cycle-sync-robust-global-camera-pose-estimation-through-enhanced-cyc.html"},{"id":"2511.02293v1","title":"3D Point Cloud Object Detection on Edge Devices for Split Computing","headline":"针对边缘设备，提出基于Split Computing的3D点云目标检测方法，降低计算负担。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102293v1-3d-point-cloud-object-detection-on-edge-devices-for-split-computing.html"},{"id":"2511.02277v1","title":"Are Euler angles a useful rotation parameterisation for pose estimation with Normalizing Flows?","headline":"探索欧拉角在Normalizing Flows姿态估计中的有效性，对比复杂参数化模型。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102277v1-are-euler-angles-a-useful-rotation-parameterisation-for-pose-estimat.html"},{"id":"2511.05564v1","title":"M2S2L: Mamba-based Multi-Scale Spatial-temporal Learning for Video Anomaly Detection","headline":"提出基于Mamba的多尺度时空学习框架M2S2L，用于提升视频异常检测的精度和效率。","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251105564v1-m2s2l-mamba-based-multi-scale-spatial-temporal-learning-for-video-an.html"},{"id":"2511.02541v2","title":"Unsupervised Learning for Industrial Defect Detection: A Case Study on Shearographic Data","headline":"提出无监督学习方法以解决工业缺陷检测问题","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102541v2-unsupervised-learning-for-industrial-defect-detection-a-case-study-o.html"},{"id":"2511.02510v1","title":"LiteVoxel: Low-memory Intelligent Thresholding for Efficient Voxel Rasterization","headline":"提出LiteVoxel以解决稀疏体素光栅化中的低频内容不足问题","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102510v1-litevoxel-low-memory-intelligent-thresholding-for-efficient-voxel-ra.html"},{"id":"2511.05575v1","title":"DiffSwap++: 3D Latent-Controlled Diffusion for Identity-Preserving Face Swapping","headline":"DiffSwap++：利用3D人脸先验的身份保持型人脸交换扩散模型","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251105575v1-diffswap-3d-latent-controlled-diffusion-for-identity-preserving-face.html"},{"id":"2511.02777v1","title":"PercHead: Perceptual Head Model for Single-Image 3D Head Reconstruction & Editing","headline":"PercHead：提出基于感知的头部模型，用于单图像3D头部重建与编辑","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102777v1-perchead-perceptual-head-model-for-single-image-3d-head-reconstructi.html"},{"id":"2511.02483v3","title":"OLATverse: A Large-scale Real-world Object Dataset with Precise Lighting Control","headline":"提出OLATverse数据集以解决真实世界物体渲染的局限性","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102483v3-olatverse-a-large-scale-real-world-object-dataset-with-precise-light.html"},{"id":"2511.02215v1","title":"Can Foundation Models Revolutionize Mobile AR Sparse Sensing?","headline":"利用Foundation Model革新移动AR稀疏感知，提升几何图像扭曲与3D重建","tag":"cs.CV","date":"2025-11-04","url":"cs-CV/2025-11-04/papers/251102215v1-can-foundation-models-revolutionize-mobile-ar-sparse-sensing.html"},{"id":"2511.02526v1","title":"Many-vs-Many Missile Guidance via Virtual Targets","headline":"提出基于虚拟目标的导弹制导方法，解决多对多导弹拦截问题。","tag":"eess.SY","date":"2025-11-04","url":"eess-SY/2025-11-04/papers/251102526v1-many-vs-many-missile-guidance-via-virtual-targets.html"},{"id":"2511.01774v1","title":"MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll","headline":"MOBIUS：一种可步行、爬行、攀爬和滚动的多模态双足机器人","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101774v1-mobius-a-multi-modal-bipedal-robot-that-can-walk-crawl-climb-and-rol.html"},{"id":"2511.01177v2","title":"Scaling Cross-Embodiment World Models for Dexterous Manipulation","headline":"提出基于粒子位移的跨形态世界模型，实现灵巧操作的泛化。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101177v2-scaling-cross-embodiment-world-models-for-dexterous-manipulation.html"},{"id":"2511.01770v1","title":"Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping","headline":"提出基于流匹配的轻量级驱动空间学习方法，用于全身软体机器人抓取","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101770v1-lightweight-learning-from-actuation-space-demonstrations-via-flow-ma.html"},{"id":"2511.01224v1","title":"Embodiment Transfer Learning for Vision-Language-Action Models","headline":"提出ET-VLA框架，通过具身迁移学习提升VLA模型在多机器人协作中的性能","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101224v1-embodiment-transfer-learning-for-vision-language-action-models.html"},{"id":"2511.01186v1","title":"LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping","headline":"提出LiDAR-VGGT，通过跨模态融合实现全局一致和度量尺度稠密地图重建","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101186v1-lidar-vggt-cross-modal-coarse-to-fine-fusion-for-globally-consistent.html"},{"id":"2511.01520v1","title":"Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals","headline":"提出基于物理约束触觉目标的力最优稳定抓取方法Phy-Tac","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101520v1-phy-tac-toward-human-like-grasping-via-physics-conditioned-tactile-g.html"},{"id":"2511.02036v1","title":"TurboMap: GPU-Accelerated Local Mapping for Visual SLAM","headline":"TurboMap：面向视觉SLAM的GPU加速局部地图构建模块","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251102036v1-turbomap-gpu-accelerated-local-mapping-for-visual-slam.html"},{"id":"2511.01493v2","title":"Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues","headline":"提出GlocDiff，融合楼层平面图与深度信息的视觉导航方法","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101493v2-floor-plan-guided-visual-navigation-incorporating-depth-and-directio.html"},{"id":"2511.01379v1","title":"CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels","headline":"CM-LIUW-Odometry：面向极端退化煤矿巷道的鲁棒高精度激光-惯性-UWB-轮速里程计","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101379v1-cm-liuw-odometry-robust-and-high-precision-lidar-inertial-uwb-wheel-.html"},{"id":"2511.01791v1","title":"GenDexHand: Generative Simulation for Dexterous Hands","headline":"GenDexHand：面向灵巧手的生成式仿真，解决数据稀缺问题","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101791v1-gendexhand-generative-simulation-for-dexterous-hands.html"},{"id":"2512.00024v1","title":"Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos","headline":"提出一种基于视频理解和点追踪的操纵轨迹提取方法，用于从人类视频中学习","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251200024v1-learning-from-watching-scalable-extraction-of-manipulation-trajector.html"},{"id":"2511.01219v2","title":"Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference","headline":"提出基于稀疏可行假设采样和可靠批处理多阶段推理的框架，解决机器人重定位问题。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101219v2-tackling-the-kidnapped-robot-problem-via-sparse-feasible-hypothesis-.html"},{"id":"2511.01407v1","title":"FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths","headline":"FoldPath：通过调制隐式路径实现端到端面向对象的运动生成","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101407v1-foldpath-end-to-end-object-centric-motion-generation-via-modulated-i.html"},{"id":"2511.02015v1","title":"Stein-based Optimization of Sampling Distributions in Model Predictive Path Integral Control","headline":"提出基于Stein变分梯度下降的MPPI控制，优化采样分布以提升轨迹规划性能。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251102015v1-stein-based-optimization-of-sampling-distributions-in-model-predicti.html"},{"id":"2511.01476v1","title":"MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments","headline":"MO-SeGMan：面向约束环境的多目标序列引导操作重排规划框架","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101476v1-mo-segman-rearrangement-planning-framework-for-multi-objective-seque.html"},{"id":"2511.01472v1","title":"AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models","headline":"AERMANI-VLM：基于结构化提示和推理的视觉语言模型在无人机操作中的应用","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101472v1-aermani-vlm-structured-prompting-and-reasoning-for-aerial-manipulati.html"},{"id":"2511.01276v1","title":"Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation","headline":"提出基于条件扩散模型的接触图传递方法，实现通用灵巧抓取生成。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101276v1-contact-map-transfer-with-conditional-diffusion-model-for-generaliza.html"},{"id":"2511.01999v1","title":"TRACE: Textual Reasoning for Affordance Coordinate Extraction","headline":"TRACE：利用文本推理提升视觉语言模型在机器人操作中的空间定位精度","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101999v1-trace-textual-reasoning-for-affordance-coordinate-extraction.html"},{"id":"2511.01383v1","title":"CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation","headline":"CaRLi-V：提出相机-雷达-激光雷达融合的点云级三维速度估计方法","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101383v1-carli-v-camera-radar-lidar-point-wise-3d-velocity-estimation.html"},{"id":"2511.01331v2","title":"RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models","headline":"RobustVLA：面向视觉-语言-动作模型的鲁棒性强化后训练","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101331v2-robustvla-robustness-aware-reinforcement-post-training-for-vision-la.html"},{"id":"2511.01294v2","title":"Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects","headline":"Kinematify：开放词汇高自由度铰接物体自动合成框架","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101294v2-kinematify-open-vocabulary-synthesis-of-high-dof-articulated-objects.html"},{"id":"2511.01797v1","title":"Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator","headline":"提出一种基于混合神经网络的室内定位系统，利用CSI数据为移动机器人实现精准定位。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101797v1-hybrid-neural-network-based-indoor-localisation-system-for-mobile-ro.html"},{"id":"2511.01369v1","title":"Lateral Velocity Model for Vehicle Parking Applications","headline":"提出基于实车数据的横向速度模型，提升自动泊车定位精度","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101369v1-lateral-velocity-model-for-vehicle-parking-applications.html"},{"id":"2511.01347v1","title":"Design and development of an electronics-free earthworm robot","headline":"提出一种无需电子元件的蠕虫机器人，适用于受限和非结构化环境。","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101347v1-design-and-development-of-an-electronics-free-earthworm-robot.html"},{"id":"2511.01272v1","title":"Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics","headline":"提出一种基于针织面料的折纸结构软体机器人设计与制造方法","tag":"cs.RO","date":"2025-11-03","url":"cs-RO/2025-11-03/papers/251101272v1-design-and-fabrication-of-origami-inspired-knitted-fabrics-for-soft-.html"},{"id":"2511.01501v1","title":"SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation","headline":"提出SE(3)-PoseFlow，用于估计6D位姿分布，实现不确定性感知的机器人操作","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101501v1-se3-poseflow-estimating-6d-pose-distributions-for-uncertainty-aware-.html"},{"id":"2511.01315v1","title":"MVSMamba: Multi-View Stereo with State Space Model","headline":"MVSMamba：利用状态空间模型实现高效多视角立体视觉重建","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101315v1-mvsmamba-multi-view-stereo-with-state-space-model.html"},{"id":"2511.01200v1","title":"MoSa: Motion Generation with Scalable Autoregressive Modeling","headline":"MoSa：基于可扩展自回归建模的运动生成框架，提升文本驱动3D人体运动生成质量与效率。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101200v1-mosa-motion-generation-with-scalable-autoregressive-modeling.html"},{"id":"2511.01502v1","title":"Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning","headline":"提出DiMoDE框架，通过区分运动分量提升深度和自运动联合学习效果","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101502v1-discriminately-treating-motion-components-evolves-joint-depth-and-eg.html"},{"id":"2511.01756v1","title":"HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain","headline":"提出HGFreNet，利用Hop-hybrid GraphFomer解决单目视频3D人体姿态估计中的轨迹不一致问题。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101756v1-hgfrenet-hop-hybrid-graphfomer-for-3d-human-pose-estimation-with-tra.html"},{"id":"2511.01210v2","title":"OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation","headline":"OmniVLA：面向机器人操作的物理 grounding 多模态 VLA 模型，统一多传感器感知","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101210v2-omnivla-physically-grounded-multimodal-vla-with-unified-multi-sensor.html"},{"id":"2511.02065v1","title":"Opto-Electronic Convolutional Neural Network Design Via Direct Kernel Optimization","headline":"提出光电卷积神经网络两阶段设计，通过直接核优化提升单目深度估计精度。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251102065v1-opto-electronic-convolutional-neural-network-design-via-direct-kerne.html"},{"id":"2511.01833v2","title":"TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning","headline":"提出TIR-Bench，用于评估Agentic图像推理中模型利用工具进行图像处理的能力","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101833v2-tir-bench-a-comprehensive-benchmark-for-agentic-thinking-with-images.html"},{"id":"2511.01571v1","title":"PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model","headline":"PixelVLA：通过像素级理解和多模态提示，提升视觉-语言-动作模型的性能","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101571v1-pixelvla-advancing-pixel-level-understanding-in-vision-language-acti.html"},{"id":"2511.01169v1","title":"Web-Scale Collection of Video Data for 4D Animal Reconstruction","headline":"提出AiM数据集与基线方法，用于野生环境下的动物4D重建","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101169v1-web-scale-collection-of-video-data-for-4d-animal-reconstruction.html"},{"id":"2511.01618v1","title":"Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models","headline":"Actial：通过视角学习激活多模态大语言模型的空间推理能力","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101618v1-actial-activate-spatial-reasoning-ability-of-multimodal-large-langua.html"},{"id":"2511.01610v1","title":"DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning","headline":"DINO-MX：一个模块化自监督学习框架，降低计算成本并提升灵活性。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101610v1-dino-mx-a-modular-flexible-framework-for-self-supervised-learning.html"},{"id":"2511.05553v1","title":"EVLP:Learning Unified Embodied Vision-Language Planner with Reinforced Supervised Fine-Tuning","headline":"提出EVLP，通过强化监督微调学习统一具身视觉-语言规划器，解决长程操作任务中的多模态规划问题。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251105553v1-evlplearning-unified-embodied-vision-language-planner-with-reinforce.html"},{"id":"2511.01399v1","title":"Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction","headline":"提出Fire-ART数据集，并设计基于全景图像的3D重建方法，用于消防资产的BIM语义增强。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101399v1-semantic-bim-enrichment-for-firefighting-assets-fire-art-dataset-and.html"},{"id":"2511.01317v2","title":"A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model","headline":"提出基于对比语言-图像预训练模型的生成对抗攻击方法，提升攻击效果与视觉保真度。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101317v2-a-generative-adversarial-approach-to-adversarial-attacks-guided-by-c.html"},{"id":"2511.01250v2","title":"Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop","headline":"提出几何感知点丢弃适配器，提升LiDAR在恶劣天气下的语义分割性能。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101250v2-source-only-cross-weather-lidar-via-geometry-aware-point-drop.html"},{"id":"2511.01237v1","title":"Eyes on Target: Gaze-Aware Object Detection in Egocentric Video","headline":"Eyes on Target：提出深度感知和注视引导的目标检测框架，用于以自我为中心的视频分析。","tag":"cs.CV","date":"2025-11-03","url":"cs-CV/2025-11-03/papers/251101237v1-eyes-on-target-gaze-aware-object-detection-in-egocentric-video.html"},{"id":"2511.01259v1","title":"An Adjoint Method for Differentiable Fluid Simulation on Flow Maps","headline":"提出基于流映射的可微流体模拟伴随方法，实现精确涡旋动力学控制","tag":"cs.GR","date":"2025-11-03","url":"cs-GR/2025-11-03/papers/251101259v1-an-adjoint-method-for-differentiable-fluid-simulation-on-flow-maps.html"},{"id":"2511.00840v2","title":"Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches","headline":"提出基于启发式步态规划的动态双足运动学习框架，提升鲁棒性","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100840v2-heuristic-step-planning-for-learning-dynamic-bipedal-locomotion-a-co.html"},{"id":"2511.01083v1","title":"Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment","headline":"提出SPAR-H算法，通过人机协同偏好对齐实现视觉驱动的无人机河流导航","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251101083v1-deployable-vision-driven-uav-river-navigation-via-human-in-the-loop-.html"},{"id":"2511.00998v1","title":"GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies","headline":"GauDP：通过高斯图像协同的扩散策略重塑多智能体协作","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100998v1-gaudp-reinventing-multi-agent-collaboration-through-gaussian-image-s.html"},{"id":"2511.00814v1","title":"Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning","headline":"提出一种基于Hankel-DMD的实时动态障碍物预测模型，用于机器人运动规划。","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100814v1-real-time-learning-of-predictive-dynamic-obstacle-models-for-robotic.html"},{"id":"2511.00933v1","title":"Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation","headline":"提出Fast-SmartWay，解决零样本视觉语言导航中实时性和全局规划问题","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100933v1-fast-smartway-panoramic-free-end-to-end-zero-shot-vision-and-languag.html"},{"id":"2511.00783v2","title":"When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage","headline":"提出基于LLM的模糊控制框架，解决水下多机器人协同覆盖问题","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100783v2-when-semantics-connect-the-swarm-llm-driven-fuzzy-control-for-cooper.html"},{"id":"2511.00940v1","title":"URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model","headline":"URDF-Anything：基于3D多模态语言模型构建可动对象","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100940v1-urdf-anything-constructing-articulated-objects-with-3d-multimodal-la.html"},{"id":"2511.00917v2","title":"Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots","headline":"Maestro：利用视觉-语言模型编排机器人模块，实现零样本通用机器人","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100917v2-maestro-orchestrating-robotics-modules-with-vision-language-models-f.html"},{"id":"2511.01107v1","title":"SLAP: Shortcut Learning for Abstract Planning","headline":"SLAP：通过学习抽象规划捷径，提升机器人长时程决策能力","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251101107v1-slap-shortcut-learning-for-abstract-planning.html"},{"id":"2512.00022v1","title":"XFlowMP: Task-Conditioned Motion Fields for Generative Robot Planning with Schrodinger Bridges","headline":"提出XFlowMP，利用薛定谔桥解决任务条件下的生成式机器人运动规划问题。","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251200022v1-xflowmp-task-conditioned-motion-fields-for-generative-robot-planning.html"},{"id":"2511.00934v1","title":"pacSTL: PAC-Bounded Signal Temporal Logic from Data-Driven Reachability Analysis","headline":"提出pacSTL框架，结合PAC界定集合预测与STL区间扩展，解决不确定性下的机器人系统安全需求问题","tag":"cs.RO","date":"2025-11-02","url":"cs-RO/2025-11-02/papers/251100934v1-pacstl-pac-bounded-signal-temporal-logic-from-data-driven-reachabili.html"},{"id":"2511.01082v1","title":"GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction","headline":"GeoToken：通过预测地理位置Token序列实现图像的层级地理定位","tag":"cs.CV","date":"2025-11-02","url":"cs-CV/2025-11-02/papers/251101082v1-geotoken-hierarchical-geolocalization-of-images-via-next-token-predi.html"},{"id":"2511.00908v1","title":"GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with Heterogeneous Graph Neural Networks","headline":"提出GraphGeo框架，利用异构图神经网络进行多智能体辩论，提升视觉地理定位精度","tag":"cs.CV","date":"2025-11-02","url":"cs-CV/2025-11-02/papers/251100908v1-graphgeo-multi-agent-debate-framework-for-visual-geo-localization-wi.html"},{"id":"2511.00962v1","title":"A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis","headline":"提出统一推理框架，实现零样本视频异常事件的整体分析","tag":"cs.CV","date":"2025-11-02","url":"cs-CV/2025-11-02/papers/251100962v1-a-unified-reasoning-framework-for-holistic-zero-shot-video-anomaly-a.html"},{"id":"2511.00858v1","title":"Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction","headline":"提出遮挡感知扩散模型，解决行人意图预测中遮挡场景下的不完整观测问题。","tag":"cs.CV","date":"2025-11-02","url":"cs-CV/2025-11-02/papers/251100858v1-occlusion-aware-diffusion-model-for-pedestrian-intention-prediction.html"},{"id":"2511.00512v1","title":"Descriptive Model-based Learning and Control for Bipedal Locomotion","headline":"提出基于描述性模型的双足机器人学习与控制方法，提升步态效率和鲁棒性","tag":"cs.RO","date":"2025-11-01","url":"cs-RO/2025-11-01/papers/251100512v1-descriptive-model-based-learning-and-control-for-bipedal-locomotion.html"},{"id":"2511.00555v1","title":"Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy","headline":"提出D3P算法，通过深度Koopman增强扩散策略提升模仿学习在分布外状态的鲁棒性","tag":"cs.RO","date":"2025-11-01","url":"cs-RO/2025-11-01/papers/251100555v1-improving-robustness-to-out-of-distribution-states-in-imitation-lear.html"},{"id":"2511.00516v1","title":"Adaptive and Multi-object Grasping via Deformable Origami Modules","headline":"提出基于可变形折纸模块的自适应多物体抓取器，用于提升工业和家庭场景下的操作效率。","tag":"cs.RO","date":"2025-11-01","url":"cs-RO/2025-11-01/papers/251100516v1-adaptive-and-multi-object-grasping-via-deformable-origami-modules.html"},{"id":"2511.00635v1","title":"Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles","headline":"提出Multi-Mapcher，一种无需回环检测的异构LiDAR多会话SLAM，用于自动驾驶。","tag":"cs.RO","date":"2025-11-01","url":"cs-RO/2025-11-01/papers/251100635v1-multi-mapcher-loop-closure-detection-free-heterogeneous-lidar-multi-.html"},{"id":"2511.00412v1","title":"Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory","headline":"提出基于龙格-库塔法的直接锥体误差补偿算法，应用于捷联惯导系统。","tag":"cs.RO","date":"2025-11-01","url":"cs-RO/2025-11-01/papers/251100412v1-runge-kutta-approximations-for-direct-coning-compensation-applying-l.html"},{"id":"2511.00389v1","title":"Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond","headline":"提出UniFER-7B，提升多模态大语言模型在面部表情识别中的推理和可解释性。","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100389v1-rethinking-facial-expression-recognition-in-the-era-of-multimodal-la.html"},{"id":"2511.00362v1","title":"Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery","headline":"Oitijjo-3D：利用街景图像的快速3D遗产重建生成式AI框架","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100362v1-oitijjo-3d-generative-ai-framework-for-rapid-3d-heritage-reconstruct.html"},{"id":"2511.00510v1","title":"OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback","headline":"OmniTrack++：通过学习大视场轨迹反馈实现全向多目标跟踪","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100510v1-omnitrack-omnidirectional-multi-object-tracking-by-learning-large-fo.html"},{"id":"2511.00738v2","title":"Towards classification-based representation learning for place recognition on LiDAR scans","headline":"提出基于分类的LiDAR点云表征学习方法，用于解决定位识别问题","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100738v2-towards-classification-based-representation-learning-for-place-recog.html"},{"id":"2511.00560v1","title":"4D Neural Voxel Splatting: Dynamic Scene Rendering with Voxelized Guassian Splatting","headline":"提出4D神经体素溅射，高效动态场景渲染与新视角合成","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100560v1-4d-neural-voxel-splatting-dynamic-scene-rendering-with-voxelized-gua.html"},{"id":"2511.00456v4","title":"Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations","headline":"提出基于弱监督深度学习和Grad-CAM的肺炎定位方法，提升胸部X光片诊断效率。","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100456v4-weakly-supervised-pneumonia-localization-from-chest-x-rays-using-dee.html"},{"id":"2511.01914v1","title":"iFlyBot-VLA Technical Report","headline":"提出iFlyBot-VLA，一种基于双层动作表示的视觉-语言-动作大模型，提升机器人操作能力。","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251101914v1-iflybot-vla-technical-report.html"},{"id":"2511.00396v3","title":"Saliency-R1: Incentivizing Unified Saliency Reasoning Capability in MLLM with Confidence-Guided Reinforcement Learning","headline":"Saliency-R1：利用置信度引导强化学习，提升MLLM的统一显著性推理能力","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100396v3-saliency-r1-incentivizing-unified-saliency-reasoning-capability-in-m.html"},{"id":"2511.00391v2","title":"VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning","headline":"VinciCoder：通过粗到细视觉强化学习统一多模态代码生成","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100391v2-vincicoder-unifying-multimodal-code-generation-via-coarse-to-fine-vi.html"},{"id":"2511.00653v1","title":"Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset","headline":"FGI-EMIT：多光谱激光雷达树木分割基准数据集与深度学习方法性能评估","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100653v1-benchmarking-individual-tree-segmentation-using-multispectral-airbor.html"},{"id":"2511.00503v1","title":"Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models","headline":"Diff4Splat：基于动态重建模型的单图可控4D场景生成","tag":"cs.CV","date":"2025-11-01","url":"cs-CV/2025-11-01/papers/251100503v1-diff4splat-controllable-4d-scene-generation-with-latent-dynamic-reco.html"},{"id":"2511.00423v2","title":"Bootstrap Off-policy with World Model","headline":"BOOM：通过世界模型引导的离策略强化学习，提升样本效率和性能。","tag":"cs.LG","date":"2025-11-01","url":"cs-LG/2025-11-01/papers/251100423v2-bootstrap-off-policy-with-world-model.html"},{"id":"2511.00139v2","title":"End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection","headline":"提出基于共享自主的灵巧臂手VLA策略，用于高效数据收集。","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251100139v2-end-to-end-dexterous-arm-hand-vla-policies-via-shared-autonomy-vr-te.html"},{"id":"2511.00153v1","title":"EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations","headline":"EgoMI：从以自我为中心的人类演示中学习主动视觉和全身操作","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251100153v1-egomi-learning-active-vision-and-whole-body-manipulation-from-egocen.html"},{"id":"2510.27558v1","title":"Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs","headline":"提出基于场景图的语言到动作框架，利用预训练模型实现精确的长时程机器人操作","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027558v1-toward-accurate-long-horizon-robotic-manipulation-language-to-action.html"},{"id":"2512.00021v1","title":"Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges","headline":"综述：自动驾驶轨迹规划中的Foundation Model进展与挑战","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251200021v1-foundation-models-for-trajectory-planning-in-autonomous-driving-a-re.html"},{"id":"2510.27545v1","title":"EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities","headline":"提出EBT-Policy，利用能量模型提升机器人物理推理能力，解决泛化性问题。","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027545v1-ebt-policy-energy-unlocks-emergent-physical-reasoning-capabilities.html"},{"id":"2511.02097v2","title":"A Step Toward World Models: A Survey on Robotic Manipulation","headline":"针对机器人操作，综述了迈向世界模型的关键技术与方法。","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251102097v2-a-step-toward-world-models-a-survey-on-robotic-manipulation.html"},{"id":"2511.00193v1","title":"Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach","headline":"利用时序基础模型，在保证精度的前提下，缩短机器人上肢评估时间","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251100193v1-reducing-robotic-upper-limb-assessment-time-while-maintaining-precis.html"},{"id":"2510.27114v1","title":"Learning Generalizable Visuomotor Policy through Dynamics-Alignment","headline":"提出动力学对齐的Flow Matching策略，提升机器人操作策略的泛化性","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027114v1-learning-generalizable-visuomotor-policy-through-dynamics-alignment.html"},{"id":"2510.27178v1","title":"MobiDock: Design and Control of A Modular Self Reconfigurable Bimanual Mobile Manipulator via Robotic Docking","headline":"MobiDock：基于机器人对接的模块化自重构双臂移动操作机器人设计与控制","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027178v1-mobidock-design-and-control-of-a-modular-self-reconfigurable-bimanua.html"},{"id":"2510.27666v1","title":"Whole-Body Proprioceptive Morphing: A Modular Soft Gripper for Robust Cross-Scale Grasping","headline":"提出一种具有全身本体感受形变的模块化软体夹爪，用于稳健的跨尺度抓取","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027666v1-whole-body-proprioceptive-morphing-a-modular-soft-gripper-for-robust.html"},{"id":"2510.27420v1","title":"Towards a Multi-Embodied Grasping Agent","headline":"提出一种数据高效的、基于流的、等变抓取合成架构，用于多具身抓取任务。","tag":"cs.RO","date":"2025-10-31","url":"cs-RO/2025-10-31/papers/251027420v1-towards-a-multi-embodied-grasping-agent.html"},{"id":"2510.27607v2","title":"Dual-Stream Diffusion for World-Model Augmented Vision-Language-Action Model","headline":"提出双流扩散模型DUST，增强世界模型在视觉-语言-动作模型中的性能","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027607v2-dual-stream-diffusion-for-world-model-augmented-vision-language-acti.html"},{"id":"2511.00248v1","title":"Object-Aware 4D Human Motion Generation","headline":"提出MSDI框架，利用运动扩散先验生成逼真且符合物理规律的4D人体运动","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100248v1-object-aware-4d-human-motion-generation.html"},{"id":"2510.27318v1","title":"SAGS: Self-Adaptive Alias-Free Gaussian Splatting for Dynamic Surgical Endoscopic Reconstruction","headline":"提出SAGS，解决动态手术内窥镜重建中的伪影和混叠问题。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027318v1-sags-self-adaptive-alias-free-gaussian-splatting-for-dynamic-surgica.html"},{"id":"2510.27481v1","title":"NAUTILUS: A Large Multimodal Model for Underwater Scene Understanding","headline":"NAUTILUS：用于水下场景理解的大型多模态模型，提升水下任务鲁棒性","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027481v1-nautilus-a-large-multimodal-model-for-underwater-scene-understanding.html"},{"id":"2510.27350v1","title":"RzenEmbed: Towards Comprehensive Multimodal Retrieval","headline":"RzenEmbed：提出统一多模态嵌入框架，显著提升视频和文档检索性能","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027350v1-rzenembed-towards-comprehensive-multimodal-retrieval.html"},{"id":"2510.27584v2","title":"Image Hashing via Cross-View Code Alignment in the Age of Foundation Models","headline":"提出CroVCA，通过跨视图编码对齐实现高效图像哈希检索","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027584v2-image-hashing-via-cross-view-code-alignment-in-the-age-of-foundation.html"},{"id":"2510.27335v1","title":"Understanding the Implicit User Intention via Reasoning with Large Language Model for Image Editing","headline":"提出CIELR，通过LLM推理将复杂图像编辑指令分解为简单动作，无需联合微调。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027335v1-understanding-the-implicit-user-intention-via-reasoning-with-large-l.html"},{"id":"2510.27195v2","title":"Can MLLMs Read the Room? A Multimodal Benchmark for Verifying Truthfulness in Multi-Party Social Interactions","headline":"提出MIVA基准，评估多模态大语言模型在多人社交互动中识别谎言的能力","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027195v2-can-mllms-read-the-room-a-multimodal-benchmark-for-verifying-truthfu.html"},{"id":"2510.27219v1","title":"SpecAware: A Spectral-Content Aware Foundation Model for Unifying Multi-Sensor Learning in Hyperspectral Remote Sensing Mapping","headline":"SpecAware：一种光谱内容感知的基础模型，用于统一高光谱遥感多传感器学习。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027219v1-specaware-a-spectral-content-aware-foundation-model-for-unifying-mul.html"},{"id":"2510.27237v2","title":"Fusion of Multi-scale Heterogeneous Pathology Foundation Models for Whole Slide Image Analysis","headline":"FuseCPath：融合多尺度异构病理学基础模型用于全切片图像分析","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027237v2-fusion-of-multi-scale-heterogeneous-pathology-foundation-models-for-.html"},{"id":"2511.00114v1","title":"End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning","headline":"提出集成生成对抗网络与深度强化学习的端到端框架，实现自主超声扫描。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100114v1-end-to-end-framework-integrating-generative-ai-and-deep-reinforcemen.html"},{"id":"2510.27632v1","title":"Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation","headline":"提出Sketch-to-Layout框架，利用草图引导多模态布局生成，提升设计体验。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027632v1-sketch-to-layout-sketch-guided-multimodal-layout-generation.html"},{"id":"2510.27599v1","title":"ANCHOR: Integrating Adversarial Training with Hard-mined Supervised Contrastive Learning for Robust Representation Learning","headline":"提出ANCHOR框架，结合对抗训练与难例监督对比学习，提升表征学习的鲁棒性。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027599v1-anchor-integrating-adversarial-training-with-hard-mined-supervised-c.html"},{"id":"2510.27571v1","title":"Towards Universal Video Retrieval: Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum","headline":"提出通用视频检索框架，通过合成多模态金字塔课程泛化视频嵌入","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027571v1-towards-universal-video-retrieval-generalizing-video-embedding-via-s.html"},{"id":"2510.27135v1","title":"E-MMDiT: Revisiting Multimodal Diffusion Transformer Design for Fast Image Synthesis under Limited Resources","headline":"提出E-MMDiT，一种轻量级多模态扩散Transformer，用于资源受限下的快速图像合成。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027135v1-e-mmdit-revisiting-multimodal-diffusion-transformer-design-for-fast-.html"},{"id":"2510.27133v1","title":"WildfireX-SLAM: A Large-scale Low-altitude RGB-D Dataset for Wildfire SLAM and Beyond","headline":"WildfireX-SLAM：用于野火SLAM及其他应用的大规模低空RGB-D数据集","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027133v1-wildfirex-slam-a-large-scale-low-altitude-rgb-d-dataset-for-wildfire.html"},{"id":"2511.00260v1","title":"MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba","headline":"MambaNetLK：利用Mamba SSM增强结肠镜点云配准精度与鲁棒性","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100260v1-mambanetlk-enhancing-colonoscopy-point-cloud-registration-with-mamba.html"},{"id":"2511.00231v2","title":"Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior","headline":"提出基于VQ-VAE与Transformer先验的电镜图像压缩方法，实现高达1000倍的压缩比。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100231v2-towards-1000-fold-electron-microscopy-image-compression-for-connecto.html"},{"id":"2510.27508v1","title":"Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung Tumor Segmentation","headline":"提出vMambaX，利用上下文门控跨模态感知和视觉Mamba进行PET-CT肺肿瘤分割","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027508v1-context-gated-cross-modal-perception-with-visual-mamba-for-pet-ct-lu.html"},{"id":"2511.00171v2","title":"CompAgent: An Agentic Framework for Visual Compliance Verification","headline":"提出CompAgent，用于视觉合规性验证的Agent框架，提升细粒度推理能力。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100171v2-compagent-an-agentic-framework-for-visual-compliance-verification.html"},{"id":"2510.27280v2","title":"FOCUS: Efficient Keyframe Selection for Long Video Understanding","headline":"提出FOCUS，一种高效的关键帧选择方法，用于提升长视频理解中多模态大语言模型的性能。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027280v2-focus-efficient-keyframe-selection-for-long-video-understanding.html"},{"id":"2510.27164v1","title":"Generating Accurate and Detailed Captions for High-Resolution Images","headline":"提出一种多阶段流程，融合视觉-语言模型、大型语言模型和目标检测，为高分辨率图像生成更准确、详细的描述。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027164v1-generating-accurate-and-detailed-captions-for-high-resolution-images.html"},{"id":"2510.27148v1","title":"HiGS: Hierarchical Generative Scene Framework for Multi-Step Associative Semantic Spatial Composition","headline":"HiGS：用于多步关联语义空间组合的分层生成场景框架","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027148v1-higs-hierarchical-generative-scene-framework-for-multi-step-associat.html"},{"id":"2510.27684v1","title":"Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals","headline":"提出Phased DMD，通过子区间内的分数匹配蒸馏提升多步生成模型的性能和多样性","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027684v1-phased-dmd-few-step-distribution-matching-distillation-via-score-mat.html"},{"id":"2510.27249v1","title":"C-LEAD: Contrastive Learning for Enhanced Adversarial Defense","headline":"C-LEAD：利用对比学习增强对抗防御能力","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027249v1-c-lead-contrastive-learning-for-enhanced-adversarial-defense.html"},{"id":"2511.00255v1","title":"BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing","headline":"BeetleFlow：用于甲虫图像处理的集成深度学习流水线","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100255v1-beetleflow-an-integrative-deep-learning-pipeline-for-beetle-image-pr.html"},{"id":"2511.00191v1","title":"A Retrospect to Multi-prompt Learning across Vision and Language","headline":"提出能量驱动的多提示学习方法，提升视觉-语言预训练模型在下游任务的泛化能力。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100191v1-a-retrospect-to-multi-prompt-learning-across-vision-and-language.html"},{"id":"2511.00141v1","title":"FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding","headline":"FLoC：基于设施选址的长视频高效视觉Token压缩方法","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251100141v1-floc-facility-location-based-efficient-visual-token-compression-for-.html"},{"id":"2510.27647v1","title":"NegoCollab: A Common Representation Negotiation Approach for Heterogeneous Collaborative Perception","headline":"NegoCollab：一种面向异构协作感知的协商式通用表征方法","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027647v1-negocollab-a-common-representation-negotiation-approach-for-heteroge.html"},{"id":"2510.27547v1","title":"MapSAM2: Adapting SAM2 for Automatic Segmentation of Historical Map Images and Time Series","headline":"MapSAM2：通过自适应SAM2实现历史地图图像和时间序列的自动分割","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027547v1-mapsam2-adapting-sam2-for-automatic-segmentation-of-historical-map-i.html"},{"id":"2510.27432v1","title":"Mitigating Semantic Collapse in Partially Relevant Video Retrieval","headline":"提出文本相关性保持学习与跨分支视频对齐，缓解部分相关视频检索中的语义坍塌问题。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027432v1-mitigating-semantic-collapse-in-partially-relevant-video-retrieval.html"},{"id":"2510.27234v1","title":"MoRE: 3D Visual Geometry Reconstruction Meets Mixture-of-Experts","headline":"提出MoRE：基于混合专家模型的3D视觉几何重建框架，提升可扩展性和适应性。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027234v1-more-3d-visual-geometry-reconstruction-meets-mixture-of-experts.html"},{"id":"2510.27208v1","title":"Multi-Modal Feature Fusion for Spatial Morphology Analysis of Traditional Villages via Hierarchical Graph Neural Networks","headline":"提出基于分层图神经网络的多模态特征融合方法，用于传统村落空间形态分析。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027208v1-multi-modal-feature-fusion-for-spatial-morphology-analysis-of-tradit.html"},{"id":"2510.27364v1","title":"Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A Small-Data Pipeline with LoRA and Wan2.1 I2V","headline":"提出LoRA微调的视频生成管线，用于电影场景合成，解决小数据集难题。","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027364v1-fine-tuning-open-video-generators-for-cinematic-scene-synthesis-a-sm.html"},{"id":"2510.27179v1","title":"SilhouetteTell: Practical Video Identification Leveraging Blurred Recordings of Video Subtitles","headline":"SilhouetteTell：利用模糊视频字幕记录实现视频识别攻击","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027179v1-silhouettetell-practical-video-identification-leveraging-blurred-rec.html"},{"id":"2510.27166v1","title":"M^3Detection: Multi-Frame Multi-Level Feature Fusion for Multi-Modal 3D Object Detection with Camera and 4D Imaging Radar","headline":"M^3Detection：多帧多层特征融合的相机-4D雷达多模态3D目标检测","tag":"cs.CV","date":"2025-10-31","url":"cs-CV/2025-10-31/papers/251027166v1-m3detection-multi-frame-multi-level-feature-fusion-for-multi-modal-3.html"},{"id":"2511.21697v1","title":"Detail Enhanced Gaussian Splatting for Large-Scale Volumetric Capture","headline":"提出基于高斯溅射和扩散增强的细节增强方法，用于大规模体绘制。","tag":"cs.GR","date":"2025-10-31","url":"cs-GR/2025-10-31/papers/251121697v1-detail-enhanced-gaussian-splatting-for-large-scale-volumetric-captur.html"},{"id":"2511.15669v1","title":"DeepThinkVLA: Enhancing Reasoning Capability of Vision-Language-Action Models","headline":"DeepThinkVLA通过混合注意力机制和两阶段训练提升VLA模型推理能力","tag":"cs.LG","date":"2025-10-31","url":"cs-LG/2025-10-31/papers/251115669v1-deepthinkvla-enhancing-reasoning-capability-of-vision-language-actio.html"},{"id":"2510.27222v1","title":"Soft Task-Aware Routing of Experts for Equivariant Representation Learning","headline":"提出软任务感知路由专家（STAR）方法，提升等变表征学习效果。","tag":"cs.LG","date":"2025-10-31","url":"cs-LG/2025-10-31/papers/251027222v1-soft-task-aware-routing-of-experts-for-equivariant-representation-le.html"},{"id":"2510.27210v1","title":"GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation","headline":"GUI-Rise：提出一种融合结构化推理和历史总结的GUI导航框架，提升跨领域泛化能力。","tag":"cs.AI","date":"2025-10-31","url":"cs-AI/2025-10-31/papers/251027210v1-gui-rise-structured-reasoning-and-history-summarization-for-gui-navi.html"},{"id":"2510.27623v1","title":"Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning","headline":"提出BEAT框架，通过对比触发学习实现MLLM具身智能体的视觉后门攻击","tag":"cs.AI","date":"2025-10-31","url":"cs-AI/2025-10-31/papers/251027623v1-visual-backdoor-attacks-on-mllm-embodied-decision-making-via-contras.html"},{"id":"2511.05542v1","title":"ConnectomeBench: Can LLMs Proofread the Connectome?","headline":"ConnectomeBench：评估LLM在神经连接体校对中的能力，探索AI辅助神经科学","tag":"cs.AI","date":"2025-10-31","url":"cs-AI/2025-10-31/papers/251105542v1-connectomebench-can-llms-proofread-the-connectome.html"},{"id":"2510.27048v1","title":"SpikeATac: A Multimodal Tactile Finger with Taxelized Dynamic Sensing for Dexterous Manipulation","headline":"SpikeATac：用于灵巧操作的多模态触觉手指，具有可分割的动态传感","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251027048v1-spikeatac-a-multimodal-tactile-finger-with-taxelized-dynamic-sensing.html"},{"id":"2510.26236v1","title":"PHUMA: Physically-Grounded Humanoid Locomotion Dataset","headline":"提出PHUMA：一个物理约束的人形机器人运动数据集，提升运动模仿性能。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026236v1-phuma-physically-grounded-humanoid-locomotion-dataset.html"},{"id":"2510.26358v1","title":"AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM","headline":"AgriGS-SLAM：基于多视角高斯溅射的果园跨季节建图SLAM","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026358v1-agrigs-slam-orchard-mapping-across-seasons-via-multi-view-gaussian-s.html"},{"id":"2510.26139v1","title":"Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling","headline":"提出基于VLM引导和交错采样的运动学任务与运动规划方法","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026139v1-kinodynamic-task-and-motion-planning-using-vlm-guided-and-interleave.html"},{"id":"2510.26362v1","title":"Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations","headline":"提出基于相似变换的协作任务空间，用于多臂操作控制","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026362v1-cooperative-task-spaces-for-multi-arm-manipulation-control-based-on-.html"},{"id":"2510.26670v1","title":"Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation","headline":"提出混合一致性策略HCP，解耦机器人操作中的多模态多样性和实时效率。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026670v1-hybrid-consistency-policy-decoupling-multi-modal-diversity-and-real-.html"},{"id":"2510.26406v1","title":"Human-in-the-loop Online Rejection Sampling for Robotic Manipulation","headline":"提出Hi-ORS，通过在线拒绝采样提升机器人操作的强化学习稳定性与鲁棒性","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026406v1-human-in-the-loop-online-rejection-sampling-for-robotic-manipulation.html"},{"id":"2510.27033v1","title":"A Multi-Modal Neuro-Symbolic Approach for Spatial Reasoning-Based Visual Grounding in Robotics","headline":"提出一种多模态神经符号方法，用于机器人中基于空间推理的视觉定位","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251027033v1-a-multi-modal-neuro-symbolic-approach-for-spatial-reasoning-based-vi.html"},{"id":"2510.26067v1","title":"Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion","headline":"提出一种形态感知图强化学习方法，用于张拉整体机器人运动控制。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026067v1-morphology-aware-graph-reinforcement-learning-for-tensegrity-robot-l.html"},{"id":"2511.00112v1","title":"Real-DRL: Teach and Learn in Reality","headline":"Real-DRL框架：在真实环境中安全地训练深度强化学习智能体","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251100112v1-real-drl-teach-and-learn-in-reality.html"},{"id":"2510.26855v1","title":"Leveraging Foundation Models for Enhancing Robot Perception and Action","headline":"利用Foundation模型增强机器人感知与行动能力","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026855v1-leveraging-foundation-models-for-enhancing-robot-perception-and-acti.html"},{"id":"2510.26646v1","title":"Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments","headline":"提出混合DQN-TD3强化学习方法，用于动态环境中自主导航。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026646v1-hybrid-dqn-td3-reinforcement-learning-for-autonomous-navigation-in-d.html"},{"id":"2511.00088v1","title":"Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail","headline":"提出Alpamayo-R1，通过因果推理和轨迹规划提升长尾场景下自动驾驶的泛化能力。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251100088v1-alpamayo-r1-bridging-reasoning-and-action-prediction-for-generalizab.html"},{"id":"2512.02022v1","title":"Reinforcement Learning for Robotic Safe Control with Force Sensing","headline":"提出基于力感知的强化学习方法，提升机器人安全控制和Sim2Real迁移能力","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251202022v1-reinforcement-learning-for-robotic-safe-control-with-force-sensing.html"},{"id":"2510.26280v2","title":"Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments","headline":"Thor框架：实现人型机器人在强接触环境中类人全身反应","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026280v2-thor-towards-human-level-whole-body-reactions-for-intense-contact-ri.html"},{"id":"2510.26551v1","title":"Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics","headline":"提出自适应逆运动学框架，用于机器人学习变长工具操作","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026551v1-adaptive-inverse-kinematics-framework-for-learning-variable-length-t.html"},{"id":"2510.26536v1","title":"RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration","headline":"RoboOS-NeXT：面向终身学习、可扩展和鲁棒多机器人协作的统一内存框架","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026536v1-roboos-next-a-unified-memory-based-framework-for-lifelong-scalable-a.html"},{"id":"2510.26363v1","title":"Towards Reinforcement Learning Based Log Loading Automation","headline":"提出基于强化学习的木材装载自动化方法，提升林业作业效率","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026363v1-towards-reinforcement-learning-based-log-loading-automation.html"},{"id":"2510.26082v2","title":"Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse","headline":"研究类人机器人受虐待时，不同程度的拟人化如何影响人类的保护反应。","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026082v2-beyond-the-uncanny-valley-a-mixed-method-investigation-of-anthropomo.html"},{"id":"2510.26909v2","title":"NaviTrace: Evaluating Embodied Navigation of Vision-Language Models","headline":"NaviTrace：提出视觉-语言模型具身导航评测基准，解决真实机器人导航评估难题","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026909v2-navitrace-evaluating-embodied-navigation-of-vision-language-models.html"},{"id":"2510.26040v1","title":"Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods","headline":"提出基于强化学习的F1TENTH赛车超车算法，提升真实场景超车成功率","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026040v1-accelerating-real-world-overtaking-in-f1tenth-racing-employing-reinf.html"},{"id":"2510.26656v2","title":"Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems","headline":"提出三种启发式LFI变体，自适应调整领域支持，提升随机动力系统中的无似然推理性能","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026656v2-heuristic-adaptation-of-potentially-misspecified-domain-support-for-.html"},{"id":"2510.26742v1","title":"Running VLAs at Real-time Speed","headline":"提出加速策略，单GPU实现30Hz多视角VLA实时运行，赋能动态机器人任务","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026742v1-running-vlas-at-real-time-speed.html"},{"id":"2510.26142v1","title":"Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages","headline":"提出自适应轨迹优化算法，解决移动机器人在狭窄通道中的局部规划问题","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026142v1-adaptive-trajectory-refinement-for-optimization-based-local-planning.html"},{"id":"2510.26132v1","title":"Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights","headline":"基于具身智能的微型机器人设计，实现高效自主运动与导航","tag":"cs.RO","date":"2025-10-30","url":"cs-RO/2025-10-30/papers/251026132v1-embodied-intelligence-for-advanced-bioinspired-microrobotics-example.html"},{"id":"2510.26117v1","title":"JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting","headline":"提出JOGS，联合优化位姿估计和3D高斯溅射，无需预校准输入。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026117v1-jogs-joint-optimization-of-pose-estimation-and-3d-gaussian-splatting.html"},{"id":"2510.27492v2","title":"ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning","headline":"ThinkMorph：通过多模态交错CoT推理涌现视觉操作能力","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251027492v2-thinkmorph-emergent-properties-in-multimodal-interleaved-chain-of-th.html"},{"id":"2510.26694v1","title":"The Impact and Outlook of 3D Gaussian Splatting","headline":"3D高斯溅射技术综述：回顾进展、洞察方向、展望未来应用","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026694v1-the-impact-and-outlook-of-3d-gaussian-splatting.html"},{"id":"2510.26921v1","title":"DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting","headline":"提出方向一致性驱动的自适应密度控制方法DC4GS，提升3D高斯 Splatting的重建质量和效率。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026921v1-dc4gs-directional-consistency-driven-adaptive-density-control-for-3d.html"},{"id":"2510.27020v1","title":"Incremental Human-Object Interaction Detection with Invariant Relation Representation Learning","headline":"提出增量关系蒸馏框架IRD，解决开放世界中人-物交互的持续学习问题","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251027020v1-incremental-human-object-interaction-detection-with-invariant-relati.html"},{"id":"2510.26583v1","title":"Emu3.5: Native Multimodal Models are World Learners","headline":"Emu3.5：原生多模态模型，通过预测视觉和语言的下一个状态实现世界理解。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026583v1-emu35-native-multimodal-models-are-world-learners.html"},{"id":"2511.00091v1","title":"Self-Improving Vision-Language-Action Models with Data Generation via Residual RL","headline":"提出PLD框架，通过残差强化学习和数据生成自提升视觉-语言-动作模型","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251100091v1-self-improving-vision-language-action-models-with-data-generation-vi.html"},{"id":"2510.26794v1","title":"The Quest for Generalizable Motion Generation: Data, Model, and Evaluation","headline":"提出ViMoGen框架，通过迁移视频生成知识，提升3D人体动作生成模型的泛化能力。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026794v1-the-quest-for-generalizable-motion-generation-data-model-and-evaluat.html"},{"id":"2510.26641v2","title":"All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles","headline":"面向自动驾驶，综述融合LLM/VLM的新一代多模态目标检测技术","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026641v2-all-you-need-for-object-detection-from-pixels-points-and-prompts-to-.html"},{"id":"2510.26114v1","title":"OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research","headline":"OracleAgent：用于甲骨文研究的多模态推理Agent系统","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026114v1-oracleagent-a-multimodal-reasoning-agent-for-oracle-bone-script-rese.html"},{"id":"2510.27047v1","title":"AD-SAM: Fine-Tuning the Segment Anything Vision Foundation Model for Autonomous Driving Perception","headline":"AD-SAM：微调SAM视觉基础模型，用于自动驾驶感知","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251027047v1-ad-sam-fine-tuning-the-segment-anything-vision-foundation-model-for-.html"},{"id":"2510.26703v1","title":"ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection","headline":"ProstNFound+：利用医学基础模型实现前列腺癌微超声检测的前瞻性研究","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026703v1-prostnfound-a-prospective-study-using-medical-foundation-models-for-.html"},{"id":"2511.00095v1","title":"SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation","headline":"SpinalSAM-R1：用于脊柱CT分割的视觉-语言多模态交互系统","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251100095v1-spinalsam-r1-a-vision-language-multimodal-interactive-system-for-spi.html"},{"id":"2510.26292v1","title":"Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving","headline":"提出CATG，利用约束流匹配进行端到端自动驾驶轨迹生成，解决模仿学习模式崩塌问题。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026292v1-beyond-imitation-constraint-aware-trajectory-generation-with-flow-ma.html"},{"id":"2510.26996v1","title":"MoME: Mixture of Visual Language Medical Experts for Medical Imaging Segmentation","headline":"提出MoME：一种用于医学影像分割的视觉语言混合专家模型","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026996v1-mome-mixture-of-visual-language-medical-experts-for-medical-imaging-.html"},{"id":"2510.26786v1","title":"HEIR: Learning Graph-Based Motion Hierarchies","headline":"提出HEIR，学习基于图的运动层次结构，实现数据驱动的运动建模。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026786v1-heir-learning-graph-based-motion-hierarchies.html"},{"id":"2510.26653v1","title":"Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2","headline":"利用深度学习光流法，提升RADARSAT-2卫星图像海冰漂移估计的可靠性","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026653v1-towards-reliable-sea-ice-drift-estimation-in-the-arctic-deep-learnin.html"},{"id":"2510.26125v3","title":"WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios","headline":"WOD-E2E：针对端到端驾驶中长尾场景的Waymo开放数据集","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026125v3-wod-e2e-waymo-open-dataset-for-end-to-end-driving-in-challenging-lon.html"},{"id":"2511.00107v1","title":"AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency","headline":"MOVAI：提出一种时序一致的AI驱动高质量文本到视频生成框架","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251100107v1-ai-powered-high-quality-text-to-video-generation-with-enhanced-tempo.html"},{"id":"2510.26113v1","title":"EgoExo-Con: Exploring View-Invariant Video Temporal Understanding","headline":"提出EgoExo-Con基准与View-GRPO框架，提升视频LLM视角不变的时间理解能力","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026113v1-egoexo-con-exploring-view-invariant-video-temporal-understanding.html"},{"id":"2510.26978v1","title":"Semantic Frame Aggregation-based Transformer for Live Video Comment Generation","headline":"提出基于语义帧聚合Transformer的SFAT模型，用于生成直播视频评论。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026978v1-semantic-frame-aggregation-based-transformer-for-live-video-comment-.html"},{"id":"2510.26800v1","title":"OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes","headline":"OmniX：利用全景生成与感知，生成可用于图形渲染的3D场景","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026800v1-omnix-from-unified-panoramic-generation-and-perception-to-graphics-r.html"},{"id":"2510.26769v1","title":"SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models","headline":"提出SteerVLM以增强视觉语言模型的控制能力","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026769v1-steervlm-robust-model-control-through-lightweight-activation-steerin.html"},{"id":"2510.26466v2","title":"Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition","headline":"提出表征级反事实校准方法，解决零样本识别中的上下文偏差问题","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026466v2-representation-level-counterfactual-calibration-for-debiased-zero-sh.html"},{"id":"2510.26241v2","title":"Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models","headline":"提出AoT-PsyPhyBENCH基准，评估视觉-语言模型对视频时间方向的理解能力","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026241v2-which-way-does-time-flow-a-psychophysics-grounded-evaluation-for-vis.html"},{"id":"2510.26186v1","title":"ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts","headline":"ConceptScope：通过解耦视觉概念表征来量化和识别数据集偏差。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026186v1-conceptscope-characterizing-dataset-bias-via-disentangled-visual-con.html"},{"id":"2510.26802v1","title":"Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark","headline":"评估视频模型零样本推理能力：提出MME-CoF基准并分析Veo-3的推理局限性","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026802v1-are-video-models-ready-as-zero-shot-reasoners-an-empirical-study-wit.html"},{"id":"2510.26173v1","title":"MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models","headline":"MoTDiff：利用扩散模型从单张模糊图像中估计高分辨率运动轨迹","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026173v1-motdiff-high-resolution-motion-trajectory-estimation-from-a-single-b.html"},{"id":"2510.26160v1","title":"CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark","headline":"提出CRAG-MM：一个用于可穿戴设备场景的多模态多轮对话RAG综合基准。","tag":"cs.CV","date":"2025-10-30","url":"cs-CV/2025-10-30/papers/251026160v1-crag-mm-multi-modal-multi-turn-comprehensive-rag-benchmark.html"},{"id":"2511.00108v2","title":"Pelican-VL 1.0: A Foundation Brain Model for Embodied Intelligence","headline":"Pelican-VL 1.0：用于具身智能的开源基础大脑模型","tag":"cs.LG","date":"2025-10-30","url":"cs-LG/2025-10-30/papers/251100108v2-pelican-vl-10-a-foundation-brain-model-for-embodied-intelligence.html"},{"id":"2510.26782v2","title":"Clone Deterministic 3D Worlds","headline":"提出几何正则化世界模型(GRWM)，用于高保真克隆确定性3D世界。","tag":"cs.LG","date":"2025-10-30","url":"cs-LG/2025-10-30/papers/251026782v2-clone-deterministic-3d-worlds.html"},{"id":"2510.26967v1","title":"Using Salient Object Detection to Identify Manipulative Cookie Banners that Circumvent GDPR","headline":"利用显著性目标检测识别规避GDPR的操纵性Cookie横幅","tag":"cs.AI","date":"2025-10-30","url":"cs-AI/2025-10-30/papers/251026967v1-using-salient-object-detection-to-identify-manipulative-cookie-banne.html"},{"id":"2510.26531v1","title":"Efficient Collision-Avoidance Constraints for Ellipsoidal Obstacles in Optimal Control: Application to Path-Following MPC and UAVs","headline":"提出高效椭球避障约束，用于路径跟踪MPC和无人机控制","tag":"eess.SY","date":"2025-10-30","url":"eess-SY/2025-10-30/papers/251026531v1-efficient-collision-avoidance-constraints-for-ellipsoidal-obstacles-.html"},{"id":"2510.25754v1","title":"GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions","headline":"GeT-USE：通过模拟具身扩展学习通用双臂移动操作工具使用","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025754v1-get-use-learning-generalized-tool-usage-for-bimanual-mobile-manipula.html"},{"id":"2510.25548v1","title":"Using VLM Reasoning to Constrain Task and Motion Planning","headline":"VIZ-COAST：利用视觉语言模型推理约束任务与运动规划，提升规划效率。","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025548v1-using-vlm-reasoning-to-constrain-task-and-motion-planning.html"},{"id":"2510.25268v1","title":"SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation","headline":"SynHLMA：合成用于操作铰接物体的带离散人-物交互表示的手语","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025268v1-synhlmasynthesizing-hand-language-manipulation-for-articulated-objec.html"},{"id":"2510.25405v1","title":"Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning","headline":"提出基于应力引导强化学习的柔性物体轻柔操作方法，实现Sim-to-Real迁移","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025405v1-sim-to-real-gentle-manipulation-of-deformable-and-fragile-objects-wi.html"},{"id":"2510.25850v1","title":"Debate2Create: Robot Co-design via Large Language Model Debates","headline":"Debate2Create：通过大语言模型辩论实现机器人协同设计","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025850v1-debate2create-robot-co-design-via-large-language-model-debates.html"},{"id":"2510.25713v1","title":"Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models","headline":"提出基于视觉-语言-动作模型的机器人助手，用于灵巧的人机协作任务","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025713v1-robotic-assistant-completing-collaborative-tasks-with-dexterous-visi.html"},{"id":"2510.25634v1","title":"Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills","headline":"提出基于强化学习双臂机器人技能库的规划与调度框架，解决复杂操作任务。","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025634v1-learning-to-plan-schedule-with-reinforcement-learned-bimanual-robot-.html"},{"id":"2510.25211v1","title":"RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis","headline":"RoadSens-4M：提出一个多模态智能手机与相机数据集，用于整体道路分析。","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025211v1-roadsens-4m-a-multimodal-smartphone-camera-dataset-for-holistic-road.html"},{"id":"2510.25241v1","title":"One-shot Humanoid Whole-body Motion Learning","headline":"提出基于单样本学习的人形机器人全身运动策略训练方法","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025241v1-one-shot-humanoid-whole-body-motion-learning.html"},{"id":"2510.26837v1","title":"Force Characterization of Insect-Scale Aquatic Propulsion Based on Fluid-Structure Interaction","headline":"基于流固耦合，研究人员对昆虫尺度水下推进器的推力特性进行了表征","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251026837v1-force-characterization-of-insect-scale-aquatic-propulsion-based-on-f.html"},{"id":"2510.25335v1","title":"An approach for combining transparency and motion assistance of a lower body exoskeleton","headline":"提出一种结合透明模式与运动辅助的下肢外骨骼控制方法","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025335v1-an-approach-for-combining-transparency-and-motion-assistance-of-a-lo.html"},{"id":"2510.25280v1","title":"Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance","headline":"提出基于隐式-显式控制的蜈蚣型两栖机器人，并评估其移动性能","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025280v1-development-of-implicit-explicit-control-based-amphibious-centipede-.html"},{"id":"2510.25233v1","title":"Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery","headline":"提出一种混合视觉伺服方法，结合深度对齐和GRU的遮挡恢复，提升机器人操作的鲁棒性。","tag":"cs.RO","date":"2025-10-29","url":"cs-RO/2025-10-29/papers/251025233v1-hybrid-vision-servoing-with-depp-alignment-and-gru-based-occlusion-r.html"},{"id":"2510.25332v1","title":"StreamingCoT: A Dataset for Temporal Dynamics and Multimodal Chain-of-Thought Reasoning in Streaming VideoQA","headline":"提出StreamingCoT数据集，用于流视频问答中的时序动态理解和多模态思维链推理。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025332v1-streamingcot-a-dataset-for-temporal-dynamics-and-multimodal-chain-of.html"},{"id":"2510.25760v2","title":"Multimodal Spatial Reasoning in the Large Model Era: A Survey and Benchmarks","headline":"综述多模态空间推理大模型，并构建开放基准评测","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025760v2-multimodal-spatial-reasoning-in-the-large-model-era-a-survey-and-ben.html"},{"id":"2510.25173v2","title":"D$^2$GS: Dense Depth Regularization for LiDAR-free Urban Scene Reconstruction","headline":"提出D$^2$GS以解决无LiDAR城市场景重建问题","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025173v2-d2gs-dense-depth-regularization-for-lidar-free-urban-scene-reconstru.html"},{"id":"2510.25263v2","title":"LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part Segmentation","headline":"LangHOPS：提出一种基于多模态大语言模型的开放词汇分层部件分割框架。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025263v2-langhops-language-grounded-hierarchical-open-vocabulary-part-segment.html"},{"id":"2510.25463v1","title":"SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time, Monocular Depth Estimation in Underwater Environments","headline":"SPADE：一种水下零样本、实时、单目深度估计的稀疏自适应深度估计器","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025463v1-spade-sparsity-adaptive-depth-estimator-for-zero-shot-real-time-mono.html"},{"id":"2510.25257v1","title":"RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision Foundation Models","headline":"RT-DETRv4：利用视觉基础模型，无痛提升实时目标检测性能","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025257v1-rt-detrv4-painlessly-furthering-real-time-object-detection-with-visi.html"},{"id":"2510.25327v5","title":"MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding","headline":"MMEdge：通过流水线式感知与编码加速设备端多模态推理","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025327v5-mmedge-accelerating-on-device-multimodal-inference-via-pipelined-sen.html"},{"id":"2510.25175v1","title":"Test-Time Adaptive Object Detection with Foundation Model","headline":"提出基于基础模型的测试时自适应目标检测方法以解决源数据依赖问题","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025175v1-test-time-adaptive-object-detection-with-foundation-model.html"},{"id":"2510.25976v1","title":"Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer","headline":"提出Brain-IT，通过脑交互Transformer实现基于fMRI的图像重建，提升重建图像的真实性。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025976v1-brain-it-image-reconstruction-from-fmri-via-brain-interaction-transf.html"},{"id":"2510.26027v1","title":"Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders","headline":"提出STAVE，通过在视觉编码器中堆叠时间注意力增强Video-LLM的时间理解能力","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251026027v1-enhancing-temporal-understanding-in-video-llms-through-stacked-tempo.html"},{"id":"2511.00073v1","title":"Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures","headline":"对比AI架构，解决高山保护区生境和土地覆盖变化检测难题","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251100073v1-habitat-and-land-cover-change-detection-in-alpine-protected-areas-a-.html"},{"id":"2510.25279v1","title":"Diffusion-Driven Progressive Target Manipulation for Source-Free Domain Adaptation","headline":"提出扩散驱动的渐进式目标域操控方法，解决无源域自适应中的域差异问题。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025279v1-diffusion-driven-progressive-target-manipulation-for-source-free-dom.html"},{"id":"2510.26001v2","title":"Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement","headline":"提出基于Hilbert扫描Mamba的低光图像增强方法，提升细节表现","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251026001v2-larger-hausdorff-dimension-in-scanning-pattern-facilitates-mamba-bas.html"},{"id":"2510.26006v1","title":"CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments","headline":"CAVE：提出用于检测和解释视觉环境中常识异常的基准数据集。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251026006v1-cave-detecting-and-explaining-commonsense-anomalies-in-visual-enviro.html"},{"id":"2510.25238v2","title":"VADB: A Large-Scale Video Aesthetic Database with Professional and Multi-Dimensional Annotations","headline":"提出VADB数据库与VADB-Net框架以解决视频美学评估问题","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025238v2-vadb-a-large-scale-video-aesthetic-database-with-professional-and-mu.html"},{"id":"2510.25345v1","title":"Informative Sample Selection Model for Skeleton-based Action Recognition with Limited Training Samples","headline":"提出基于MDP的骨骼动作识别信息样本选择模型，提升有限样本下的识别精度。","tag":"cs.CV","date":"2025-10-29","url":"cs-CV/2025-10-29/papers/251025345v1-informative-sample-selection-model-for-skeleton-based-action-recogni.html"},{"id":"2511.01894v1","title":"LGCC: Enhancing Flow Matching Based Text-Guided Image Editing with Local Gaussian Coupling and Context Consistency","headline":"LGCC：通过局部高斯耦合和上下文一致性增强Flow Matching文本引导图像编辑","tag":"cs.GR","date":"2025-10-29","url":"cs-GR/2025-10-29/papers/251101894v1-lgcc-enhancing-flow-matching-based-text-guided-image-editing-with-lo.html"},{"id":"2510.25616v1","title":"Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization","headline":"提出视觉表征对齐方法，解决VLA模型OOD泛化能力退化问题","tag":"cs.LG","date":"2025-10-29","url":"cs-LG/2025-10-29/papers/251025616v1-dont-blind-your-vla-aligning-visual-representations-for-ood-generali.html"},{"id":"2510.25512v1","title":"FaCT: Faithful Concept Traces for Explaining Neural Network Decisions","headline":"FaCT：提出可信的概念追踪方法，用于解释神经网络决策过程","tag":"cs.LG","date":"2025-10-29","url":"cs-LG/2025-10-29/papers/251025512v1-fact-faithful-concept-traces-for-explaining-neural-network-decisions.html"},{"id":"2510.26023v2","title":"Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization","headline":"提出StuckSolver，利用大语言模型辅助自动驾驶车辆脱困","tag":"cs.AI","date":"2025-10-29","url":"cs-AI/2025-10-29/papers/251026023v2-large-language-model-assisted-autonomous-vehicle-recovery-from-immob.html"},{"id":"2510.25597v1","title":"Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach","headline":"提出一种社会感知时空管道方法，用于控制未知多智能体系统，实现规定时间内到达目标。","tag":"eess.SY","date":"2025-10-29","url":"eess-SY/2025-10-29/papers/251025597v1-incorporating-social-awareness-into-control-of-unknown-multi-agent-s.html"},{"id":"2510.23988v1","title":"A Survey on Collaborative SLAM with 3D Gaussian Splatting","headline":"综述：基于3D高斯溅射的多机器人协同SLAM技术","tag":"cs.RO","date":"2025-10-28","url":"cs-RO/2025-10-28/papers/251023988v1-a-survey-on-collaborative-slam-with-3d-gaussian-splatting.html"},{"id":"2510.23997v1","title":"VOCALoco: Viability-Optimized Cost-aware Adaptive Locomotion","headline":"VOCALoco：面向四足机器人，提出一种基于可行性优化的、成本感知的自适应步态选择框架。","tag":"cs.RO","date":"2025-10-28","url":"cs-RO/2025-10-28/papers/251023997v1-vocaloco-viability-optimized-cost-aware-adaptive-locomotion.html"},{"id":"2511.00041v1","title":"Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World","headline":"BiBo：赋予GPT-4人形躯体，连接VLM与物理世界","tag":"cs.RO","date":"2025-10-28","url":"cs-RO/2025-10-28/papers/251100041v1-endowing-gpt-4-with-a-humanoid-body-building-the-bridge-between-off-.html"},{"id":"2510.24010v1","title":"Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks","headline":"Mars-Bench：火星科学任务的深度学习基础模型评估基准","tag":"cs.CV","date":"2025-10-28","url":"cs-CV/2025-10-28/papers/251024010v1-mars-bench-a-benchmark-for-evaluating-foundation-models-for-mars-sci.html"},{"id":"2510.24034v1","title":"AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts","headline":"提出AutoPrompt，利用LLM自动生成对抗性提示，实现对文本到图像模型的黑盒红队测试。","tag":"cs.CV","date":"2025-10-28","url":"cs-CV/2025-10-28/papers/251024034v1-autoprompt-automated-red-teaming-of-text-to-image-models-via-llm-dri.html"},{"id":"2510.23981v4","title":"TeleEgo: Benchmarking Egocentric AI Assistants in the Wild","headline":"提出TeleEgo基准以评估现实场景中的自我中心AI助手","tag":"cs.CV","date":"2025-10-28","url":"cs-CV/2025-10-28/papers/251023981v4-teleego-benchmarking-egocentric-ai-assistants-in-the-wild.html"},{"id":"2510.23016v1","title":"ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation","headline":"ManiDP：一种可操作性感知的扩散策略，用于姿态相关的双臂操作","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023016v1-manidp-manipulability-aware-diffusion-policy-for-posture-dependent-b.html"},{"id":"2510.23521v1","title":"Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation","headline":"利用在线3D高斯溅射显式记忆提升类别无关视频分割","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023521v1-explicit-memory-through-online-3d-gaussian-splatting-improves-class-.html"},{"id":"2510.23763v3","title":"RoboOmni: Proactive Robot Manipulation in Omni-modal Context","headline":"RoboOmni：提出一种全模态上下文中的主动机器人操作框架，解决机器人意图理解问题。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023763v3-roboomni-proactive-robot-manipulation-in-omni-modal-context.html"},{"id":"2510.23509v1","title":"Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model","headline":"提出NaviWM，结合世界模型与逻辑推理增强社交机器人导航","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023509v1-deductive-chain-of-thought-augmented-socially-aware-robot-navigation.html"},{"id":"2510.23902v1","title":"Stand, Walk, Navigate: Recovery-Aware Visual Navigation on a Low-Cost Wheeled Quadruped","headline":"低成本轮腿机器人上基于视觉的稳健导航与跌倒恢复","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023902v1-stand-walk-navigate-recovery-aware-visual-navigation-on-a-low-cost-w.html"},{"id":"2510.23511v1","title":"Dexbotic: Open-Source Vision-Language-Action Toolbox","headline":"Dexbotic：开源视觉-语言-动作工具箱，助力具身智能研究","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023511v1-dexbotic-open-source-vision-language-action-toolbox.html"},{"id":"2510.23119v1","title":"OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback","headline":"OmniDexGrasp：基于Foundation Model和力反馈的通用灵巧抓取框架","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023119v1-omnidexgrasp-generalizable-dexterous-grasping-via-foundation-model-a.html"},{"id":"2510.23576v1","title":"UrbanVLA: A Vision-Language-Action Model for Urban Micromobility","headline":"提出UrbanVLA，用于城市微出行场景下基于视觉-语言-动作的导航。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023576v1-urbanvla-a-vision-language-action-model-for-urban-micromobility.html"},{"id":"2510.23357v1","title":"Large language model-based task planning for service robots: A review","headline":"综述：基于大语言模型的服务机器人任务规划研究进展","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023357v1-large-language-model-based-task-planning-for-service-robots-a-review.html"},{"id":"2510.23329v1","title":"Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon","headline":"提出基于DRL的跨域迁移导航方法，实现从农田到月球的零样本泛化","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023329v1-transferable-deep-reinforcement-learning-for-cross-domain-navigation.html"},{"id":"2510.23258v1","title":"Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation","headline":"提出基于扩散策略和多时间尺度世界模型的深度主动推理框架，用于真实环境探索和导航。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023258v1-deep-active-inference-with-diffusion-policy-and-multiple-timescale-w.html"},{"id":"2510.23057v1","title":"Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation","headline":"Seq-DeepIPC：用于腿式机器人导航的端到端时序感知控制模型","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023057v1-seq-deepipc-sequential-sensing-for-end-to-end-control-in-legged-robo.html"},{"id":"2510.22892v1","title":"Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning","headline":"提出基于LLM和Lyapunov强化学习的自适应虚拟模型控制，提升机器人臂在不确定环境下的适应性。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251022892v1-never-too-rigid-to-reach-adaptive-virtual-model-control-with-llm-and.html"},{"id":"2510.23928v2","title":"Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments","headline":"提出自适应关键帧选择方法，提升动态环境下可扩展3D场景重建效果。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023928v2-adaptive-keyframe-selection-for-scalable-3d-scene-reconstruction-in-.html"},{"id":"2510.23386v1","title":"Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks","headline":"提出一种重型液压机械臂全动力学实时非线性模型预测控制方法，用于轨迹跟踪任务。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023386v1-full-dynamics-real-time-nonlinear-model-predictive-control-of-heavy-.html"},{"id":"2510.23176v1","title":"TARC: Time-Adaptive Robotic Control","headline":"提出时间自适应机器人控制（TARC），通过强化学习实现机器人控制频率的自主调节。","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023176v1-tarc-time-adaptive-robotic-control.html"},{"id":"2510.23571v1","title":"RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation","headline":"RobotArena ∞：通过真实到模拟的转换实现可扩展的机器人基准测试","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023571v1-robotarena-infty-scalable-robot-benchmarking-via-real-to-sim-transla.html"},{"id":"2510.23129v2","title":"Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots","headline":"提出高层调度与低层控制结合框架，解决工业环境移动机器人集群的动态协调问题","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023129v2-combining-high-level-scheduling-and-low-level-control-to-manage-flee.html"},{"id":"2510.23059v1","title":"Awakening Facial Emotional Expressions in Human-Robot","headline":"提出基于KAN和注意力机制的端到端学习框架，用于人形机器人自主生成面部表情","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023059v1-awakening-facial-emotional-expressions-in-human-robot.html"},{"id":"2511.00033v1","title":"STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization","headline":"STRIDER：通过指令对齐的结构化决策空间优化实现导航","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251100033v1-strider-navigation-via-instruction-aligned-structural-decision-space.html"},{"id":"2510.23227v1","title":"Workspace Registration and Collision Detection for Industrial Robotics Applications","headline":"针对工业机器人应用，提出工作空间注册与碰撞检测方案","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023227v1-workspace-registration-and-collision-detection-for-industrial-roboti.html"},{"id":"2510.23021v1","title":"Planning Oriented Integrated Sensing and Communication","headline":"提出面向规划的集成感知与通信框架，提升自动驾驶安全性和效率","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251023021v1-planning-oriented-integrated-sensing-and-communication.html"},{"id":"2510.22917v2","title":"HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment","headline":"HyPerNav：利用混合感知实现未知环境中面向对象的导航","tag":"cs.RO","date":"2025-10-27","url":"cs-RO/2025-10-27/papers/251022917v2-hypernav-hybrid-perception-for-object-oriented-navigation-in-unknown.html"},{"id":"2510.23184v1","title":"Finding 3D Scene Analogies with Multimodal Foundation Models","headline":"利用多模态基础模型实现零样本三维场景类比，用于机器人轨迹和路径点迁移。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023184v1-finding-3d-scene-analogies-with-multimodal-foundation-models.html"},{"id":"2510.23930v1","title":"PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors","headline":"PlanarGS：利用视觉-语言平面先验实现高保真室内3D高斯溅射","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023930v1-planargs-high-fidelity-indoor-3d-gaussian-splatting-guided-by-vision.html"},{"id":"2510.23205v1","title":"VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D Gaussian Splatting","headline":"VR-Drive：利用前馈3D高斯溅射实现视角鲁棒的端到端自动驾驶","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023205v1-vr-drive-viewpoint-robust-end-to-end-driving-with-feed-forward-3d-ga.html"},{"id":"2510.22936v1","title":"Positional Preservation Embedding for Multimodal Large Language Models","headline":"提出位置保持嵌入（PPE）以提升多模态大语言模型在视觉-语言任务中的效率和性能。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022936v1-positional-preservation-embedding-for-multimodal-large-language-mode.html"},{"id":"2510.22964v1","title":"Survey of Multimodal Geospatial Foundation Models: Techniques, Applications, and Challenges","headline":"综述多模态地理空间基础模型，应对遥感图像分析的挑战。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022964v1-survey-of-multimodal-geospatial-foundation-models-techniques-applica.html"},{"id":"2510.22930v1","title":"Gen-LangSplat: Generalized Language Gaussian Splatting with Pre-Trained Feature Compression","headline":"Gen-LangSplat：利用预训练特征压缩实现通用语言高斯溅射，提升效率。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022930v1-gen-langsplat-generalized-language-gaussian-splatting-with-pre-train.html"},{"id":"2510.23087v1","title":"EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic Reconstruction","headline":"EndoWave：用于内窥镜重建的Rational-Wavelet 4D高斯溅射","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023087v1-endowave-rational-wavelet-4d-gaussian-splatting-for-endoscopic-recon.html"},{"id":"2510.23569v1","title":"EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT","headline":"EgoThinker：利用时空CoT揭示以自我为中心的推理能力","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023569v1-egothinker-unveiling-egocentric-reasoning-with-spatio-temporal-cot.html"},{"id":"2510.23473v1","title":"Video-Thinker: Sparking \"Thinking with Videos\" via Reinforcement Learning","headline":"提出Video-Thinker，通过强化学习赋能MLLM进行视频推理","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023473v1-video-thinker-sparking-thinking-with-videos-via-reinforcement-learni.html"},{"id":"2510.23894v1","title":"Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation","headline":"提出LHT-CLIP，无需训练即可提升CLIP在开放词汇语义分割中的视觉区分性","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023894v1-improving-visual-discriminability-of-clip-for-training-free-open-voc.html"},{"id":"2510.24795v1","title":"A Survey on Efficient Vision-Language-Action Models","headline":"对高效视觉-语言-动作模型（Efficient VLA）的综述，旨在降低计算和数据需求。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251024795v1-a-survey-on-efficient-vision-language-action-models.html"},{"id":"2510.23415v1","title":"Towards Generalisable Foundation Models for 3D Brain MRI","headline":"BrainFound：面向3D脑部MRI的通用Foundation模型，提升疾病检测与分割性能。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023415v1-towards-generalisable-foundation-models-for-3d-brain-mri.html"},{"id":"2510.24792v2","title":"PISA-Bench: The PISA Index as a Multilingual and Multimodal Metric for the Evaluation of Vision-Language Models","headline":"PISA-Bench：一个多语言多模态基准，用于评估视觉-语言模型","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251024792v2-pisa-bench-the-pisa-index-as-a-multilingual-and-multimodal-metric-fo.html"},{"id":"2510.23397v1","title":"VideoTG-R1: Boosting Video Temporal Grounding via Curriculum Reinforcement Learning on Reflected Boundary Annotations","headline":"VideoTG-R1：通过反射边界标注的课程强化学习提升视频时序定位性能","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023397v1-videotg-r1-boosting-video-temporal-grounding-via-curriculum-reinforc.html"},{"id":"2510.23224v1","title":"Accurate and Scalable Multimodal Pathology Retrieval via Attentive Vision-Language Alignment","headline":"PathSearch：基于注意力视觉-语言对齐的精准可扩展多模态病理图像检索框架","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023224v1-accurate-and-scalable-multimodal-pathology-retrieval-via-attentive-v.html"},{"id":"2510.23594v4","title":"PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection","headline":"PRISM-Bench：一个基于谜题的可解释多模态推理评测基准","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023594v4-prism-bench-a-benchmark-of-puzzle-based-visual-tasks-with-cot-error-.html"},{"id":"2510.23325v1","title":"Multitask Multimodal Self-Supervised Learning for Medical Images","headline":"提出Medformer，用于医学图像多任务多模态自监督学习，减少对标注数据的依赖。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023325v1-multitask-multimodal-self-supervised-learning-for-medical-images.html"},{"id":"2510.23299v1","title":"MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm Detection","headline":"提出MMSD3.0多图讽刺检测基准和CIRM模型，解决真实场景多图线索讽刺识别问题","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023299v1-mmsd30-a-multi-image-benchmark-for-real-world-multimodal-sarcasm-det.html"},{"id":"2510.23151v1","title":"AG-Fusion: adaptive gated multimodal fusion for 3d object detection in complex scenes","headline":"提出自适应门控融合方法以解决复杂场景中的3D物体检测问题","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023151v1-ag-fusion-adaptive-gated-multimodal-fusion-for-3d-object-detection-i.html"},{"id":"2510.23145v1","title":"Implicit Modeling for Transferability Estimation of Vision Foundation Models","headline":"提出隐式迁移建模(ITM)，高效评估视觉基础模型在下游任务的迁移能力。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023145v1-implicit-modeling-for-transferability-estimation-of-vision-foundatio.html"},{"id":"2510.23095v2","title":"Revisiting Multimodal Positional Encoding in Vision-Language Models","headline":"提出多头旋转位置编码MHRoPE及其变体MRoPE-I，提升视觉-语言模型的多模态位置编码能力。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023095v2-revisiting-multimodal-positional-encoding-in-vision-language-models.html"},{"id":"2510.22946v4","title":"LightFusion: A Light-weighted, Double Fusion Framework for Unified Multimodal Understanding and Generation","headline":"LightFusion：轻量级双重融合框架，用于统一多模态理解与生成","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022946v4-lightfusion-a-light-weighted-double-fusion-framework-for-unified-mul.html"},{"id":"2510.23043v1","title":"HieraMamba: Video Temporal Grounding via Hierarchical Anchor-Mamba Pooling","headline":"HieraMamba：通过分层Anchor-Mamba池化实现视频时序定位","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023043v1-hieramamba-video-temporal-grounding-via-hierarchical-anchor-mamba-po.html"},{"id":"2510.23588v2","title":"FARMER: Flow AutoRegressive Transformer over Pixels","headline":"FARMER：提出一种基于流自回归Transformer的像素生成模型，实现精确似然估计和高质量图像合成。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023588v2-farmer-flow-autoregressive-transformer-over-pixels.html"},{"id":"2510.23907v2","title":"DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning","headline":"DynaStride：结合MMCoT的动态步长窗口化方法，用于生成教学视频的多场景字幕。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023907v2-dynastride-dynamic-stride-windowing-with-mmcot-for-instructional-mul.html"},{"id":"2510.23603v2","title":"PixelRefer: A Unified Framework for Spatio-Temporal Object Referring with Arbitrary Granularity","headline":"提出PixelRefer，一个统一的区域级MLLM框架，用于任意粒度的时空对象指代理解。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023603v2-pixelrefer-a-unified-framework-for-spatio-temporal-object-referring-.html"},{"id":"2510.23574v1","title":"More Than Generation: Unifying Generation and Depth Estimation via Text-to-Image Diffusion Models","headline":"提出MERGE，通过文本到图像扩散模型统一图像生成与深度估计","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023574v1-more-than-generation-unifying-generation-and-depth-estimation-via-te.html"},{"id":"2510.23497v2","title":"VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation","headline":"提出VOLD框架，通过策略蒸馏将LLM的推理能力迁移到视觉-语言模型","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023497v2-vold-reasoning-transfer-from-llms-to-vision-language-models-via-on-p.html"},{"id":"2510.23482v1","title":"On the Faithfulness of Visual Thinking: Measurement and Enhancement","headline":"提出SCCM学习策略，提升视觉语言模型多模态推理中视觉信息的可靠性和充分性。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023482v1-on-the-faithfulness-of-visual-thinking-measurement-and-enhancement.html"},{"id":"2510.23479v1","title":"MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding","headline":"提出MergeMix，统一视觉和多模态理解的增强范式，提升效率和对齐质量。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023479v1-mergemix-a-unified-augmentation-paradigm-for-visual-and-multi-modal-.html"},{"id":"2510.22937v1","title":"Bi-Encoder Contrastive Learning for Fingerprint and Iris Biometrics","headline":"提出基于Bi-Encoder对比学习的指纹和虹膜跨模态生物特征识别方法","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022937v1-bi-encoder-contrastive-learning-for-fingerprint-and-iris-biometrics.html"},{"id":"2510.23607v1","title":"Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations","headline":"Concerto：融合2D-3D自监督学习，涌现空间表征","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023607v1-concerto-joint-2d-3d-self-supervised-learning-emerges-spatial-repres.html"},{"id":"2510.23785v1","title":"CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting","headline":"CountFormer：Transformer框架学习视觉重复与结构，实现类别无关的目标计数","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023785v1-countformer-a-transformer-framework-for-learning-visual-repetition-a.html"},{"id":"2510.23253v1","title":"A Video Is Not Worth a Thousand Words","headline":"提出基于Shapley值的特征归因和模态评分方法，评估VLM在VQA任务中的文本依赖性。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023253v1-a-video-is-not-worth-a-thousand-words.html"},{"id":"2510.24788v1","title":"The Underappreciated Power of Vision Models for Graph Structural Understanding","headline":"利用视觉模型进行图结构理解，性能媲美图神经网络，并揭示其全局感知优势","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251024788v1-the-underappreciated-power-of-vision-models-for-graph-structural-und.html"},{"id":"2510.23203v1","title":"DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification","headline":"提出DecoDINO以解决人类与场景接触预测问题","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023203v1-decodino-3d-human-scene-contact-prediction-with-semantic-classificat.html"},{"id":"2510.22975v1","title":"VoMP: Predicting Volumetric Mechanical Property Fields","headline":"VoMP：预测三维物体体积机械属性场，加速物理仿真。","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251022975v1-vomp-predicting-volumetric-mechanical-property-fields.html"},{"id":"2510.23494v1","title":"Yesnt: Are Diffusion Relighting Models Ready for Capture Stage Compositing? A Hybrid Alternative to Bridge the Gap","headline":"提出混合框架Yesnt，提升扩散模型在动态体积视频光照重构中的时序稳定性","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023494v1-yesnt-are-diffusion-relighting-models-ready-for-capture-stage-compos.html"},{"id":"2510.23478v1","title":"UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset Across Multiple Intersections for Cooperative Perception","headline":"UrbanIng-V2X：用于协同感知的多路口大规模多车辆多基础设施数据集","tag":"cs.CV","date":"2025-10-27","url":"cs-CV/2025-10-27/papers/251023478v1-urbaning-v2x-a-large-scale-multi-vehicle-multi-infrastructure-datase.html"},{"id":"2510.22990v2","title":"USF-MAE: Ultrasound Self-Supervised Foundation Model with Masked Autoencoding","headline":"USF-MAE：基于掩码自编码器的超声自监督预训练模型","tag":"cs.AI","date":"2025-10-27","url":"cs-AI/2025-10-27/papers/251022990v2-usf-mae-ultrasound-self-supervised-foundation-model-with-masked-auto.html"},{"id":"2510.23807v4","title":"Beyond the Failures: Rethinking Foundation Models in Pathology","headline":"病理学领域需重新思考基础模型，避免盲目套用自然图像方法","tag":"cs.AI","date":"2025-10-27","url":"cs-AI/2025-10-27/papers/251023807v4-beyond-the-failures-rethinking-foundation-models-in-pathology.html"},{"id":"2510.23538v1","title":"JanusCoder: Towards a Foundational Visual-Programmatic Interface for Code Intelligence","headline":"JanusCoder：构建用于代码智能的基础视觉-程序化接口","tag":"cs.AI","date":"2025-10-27","url":"cs-AI/2025-10-27/papers/251023538v1-januscoder-towards-a-foundational-visual-programmatic-interface-for-.html"},{"id":"2510.23451v1","title":"Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences","headline":"提出Omni-Reward，用于支持自由形式偏好的通用全模态奖励建模。","tag":"cs.CL","date":"2025-10-27","url":"cs-CL/2025-10-27/papers/251023451v1-omni-reward-towards-generalist-omni-modal-reward-modeling-with-free-.html"},{"id":"2510.22789v1","title":"Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning","headline":"提出基于学习的神经观测器-预测器模型，用于腿足机器人基于采样的腿部级运动规划。","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022789v1-learning-neural-observer-predictor-models-for-limb-level-sampling-ba.html"},{"id":"2510.22600v1","title":"RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience","headline":"RoGER-SLAM：面向噪声和低光环境的鲁棒高斯溅射SLAM系统","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022600v1-roger-slam-a-robust-gaussian-splatting-slam-system-for-noisy-and-low.html"},{"id":"2510.22699v1","title":"RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets","headline":"提出RL-AVIST框架，用于航天器目标自主视觉检测的强化学习控制。","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022699v1-rl-avist-reinforcement-learning-for-autonomous-visual-inspection-of-.html"},{"id":"2510.22740v1","title":"Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM","headline":"提出基于强化学习的分布式位姿图优化方法，用于多机器人SLAM。","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022740v1-policies-over-poses-reinforcement-learning-based-distributed-pose-gr.html"},{"id":"2510.22524v1","title":"Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines","headline":"受蚂蚁启发，提出基于有限状态机和强化学习的可扩展集群分离墙策略","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022524v1-ant-inspired-walling-strategies-for-scalable-swarm-separation-reinfo.html"},{"id":"2510.22784v1","title":"PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language","headline":"PIP-LLM：融合PDDL与整数规划，利用自然语言协调多机器人团队","tag":"cs.RO","date":"2025-10-26","url":"cs-RO/2025-10-26/papers/251022784v1-pip-llm-integrating-pddl-integer-programming-with-llms-for-coordinat.html"},{"id":"2510.22669v1","title":"LVD-GS: Gaussian Splatting SLAM for Dynamic Scenes via Hierarchical Explicit-Implicit Representation Collaboration Rendering","headline":"LVD-GS：面向动态场景，基于分层显隐式表达协同渲染的Gaussian Splatting SLAM","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022669v1-lvd-gs-gaussian-splatting-slam-for-dynamic-scenes-via-hierarchical-e.html"},{"id":"2510.22672v2","title":"Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views","headline":"提出Look and Tell数据集，用于研究以自我为中心和以外部为中心视角下的多模态指示交流。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022672v2-look-and-tell-a-dataset-for-multimodal-grounding-across-egocentric-a.html"},{"id":"2510.22718v1","title":"Edge Collaborative Gaussian Splatting with Integrated Rendering and Communication","headline":"提出ECO-GS，通过边缘协同高斯溅射提升低成本设备渲染质量","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022718v1-edge-collaborative-gaussian-splatting-with-integrated-rendering-and-.html"},{"id":"2510.22694v1","title":"Windsock is Dancing: Adaptive Multimodal Retrieval-Augmented Generation","headline":"Windsock：自适应多模态检索增强生成方法，提升多模态大语言模型性能。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022694v1-windsock-is-dancing-adaptive-multimodal-retrieval-augmented-generati.html"},{"id":"2510.22665v2","title":"SARVLM: A Vision Language Foundation Model for Semantic Understanding and Target Recognition in SAR Imagery","headline":"提出SARVLM：面向SAR图像语义理解和目标识别的视觉语言基础模型","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022665v2-sarvlm-a-vision-language-foundation-model-for-semantic-understanding.html"},{"id":"2510.22622v1","title":"DeepfakeBench-MM: A Comprehensive Benchmark for Multimodal Deepfake Detection","headline":"构建多模态深度伪造检测基准，应对伪造音视频内容带来的社会风险。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022622v1-deepfakebench-mm-a-comprehensive-benchmark-for-multimodal-deepfake-d.html"},{"id":"2510.22521v1","title":"Open Multimodal Retrieval-Augmented Factual Image Generation","headline":"提出ORIG框架，通过开放多模态检索增强，解决事实性图像生成中知识不准确问题","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022521v1-open-multimodal-retrieval-augmented-factual-image-generation.html"},{"id":"2510.22507v1","title":"GateFuseNet: An Adaptive 3D Multimodal Neuroimaging Fusion Network for Parkinson's Disease Diagnosis","headline":"GateFuseNet：一种自适应3D多模态神经影像融合网络，用于帕金森病诊断","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022507v1-gatefusenet-an-adaptive-3d-multimodal-neuroimaging-fusion-network-fo.html"},{"id":"2510.22473v1","title":"DynaPose4D: High-Quality 4D Dynamic Content Generation via Pose Alignment Loss","headline":"DynaPose4D：提出基于姿态对齐损失的高质量4D动态内容生成方法","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022473v1-dynapose4d-high-quality-4d-dynamic-content-generation-via-pose-align.html"},{"id":"2510.22868v1","title":"Seeing the Unseen: Towards Zero-Shot Inspection for Wind Turbine Blades using Knowledge-Augmented Vision Language Models","headline":"提出基于知识增强视觉语言模型的零样本风力涡轮机叶片缺陷检测方法","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022868v1-seeing-the-unseen-towards-zero-shot-inspection-for-wind-turbine-blad.html"},{"id":"2510.22827v2","title":"FairJudge: MLLM Judging for Social Attributes and Prompt Image Alignment","headline":"FairJudge：利用多模态LLM评估社会属性和提示图像对齐，提升公平性审计。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022827v2-fairjudge-mllm-judging-for-social-attributes-and-prompt-image-alignm.html"},{"id":"2511.00028v1","title":"Mutual Information guided Visual Contrastive Learning","headline":"提出互信息引导的视觉对比学习，提升表征学习在开放环境下的泛化性","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251100028v1-mutual-information-guided-visual-contrastive-learning.html"},{"id":"2510.22603v2","title":"Mitigating Attention Sinks and Massive Activations in Audio-Visual Speech Recognition with LLMs","headline":"针对AVSR中LLM的Attention Sink问题，提出解耦损失以提升识别精度","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022603v2-mitigating-attention-sinks-and-massive-activations-in-audio-visual-s.html"},{"id":"2510.22673v1","title":"Alias-Free ViT: Fractional Shift Invariance via Linear Attention","headline":"提出Alias-Free ViT，通过线性注意力实现分数平移不变性，提升ViT的鲁棒性。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022673v1-alias-free-vit-fractional-shift-invariance-via-linear-attention.html"},{"id":"2510.22480v1","title":"Single-Teacher View Augmentation: Boosting Knowledge Distillation via Angular Diversity","headline":"提出基于单教师视角增强的知识蒸馏方法，通过角度多样性提升学生模型性能。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022480v1-single-teacher-view-augmentation-boosting-knowledge-distillation-via.html"},{"id":"2510.22829v1","title":"LLM-based Fusion of Multi-modal Features for Commercial Memorability Prediction","headline":"提出基于LLM的多模态融合方法，用于提升商业广告记忆度预测的鲁棒性和泛化性。","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022829v1-llm-based-fusion-of-multi-modal-features-for-commercial-memorability.html"},{"id":"2510.22693v2","title":"VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree","headline":"VADTree：通过分层粒度感知树实现可解释的无训练视频异常检测","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022693v2-vadtree-explainable-training-free-video-anomaly-detection-via-hierar.html"},{"id":"2510.22684v1","title":"RoboSVG: A Unified Framework for Interactive SVG Generation with Multi-modal Guidance","headline":"RoboSVG：多模态引导的交互式SVG统一生成框架","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022684v1-robosvg-a-unified-framework-for-interactive-svg-generation-with-mult.html"},{"id":"2510.22589v2","title":"PSScreen V2: Partially Supervised Multiple Retinal Disease Screening","headline":"PSScreen V2：一种用于多视网膜疾病筛查的半监督自训练框架","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022589v2-psscreen-v2-partially-supervised-multiple-retinal-disease-screening.html"},{"id":"2510.22571v1","title":"STATUS Bench: A Rigorous Benchmark for Evaluating Object State Understanding in Vision-Language Models","headline":"STATUS Bench：用于评估视觉-语言模型物体状态理解能力的严格基准","tag":"cs.CV","date":"2025-10-26","url":"cs-CV/2025-10-26/papers/251022571v1-status-bench-a-rigorous-benchmark-for-evaluating-object-state-unders.html"},{"id":"2510.22632v1","title":"Environment-aware Motion Matching","headline":"提出环境感知运动匹配，解决角色与动态环境自然交互的难题","tag":"cs.GR","date":"2025-10-26","url":"cs-GR/2025-10-26/papers/251022632v1-environment-aware-motion-matching.html"},{"id":"2510.22712v1","title":"Step2Motion: Locomotion Reconstruction from Pressure Sensing Insoles","headline":"Step2Motion：提出一种基于压力感应鞋垫的步态运动重建方法","tag":"cs.GR","date":"2025-10-26","url":"cs-GR/2025-10-26/papers/251022712v1-step2motion-locomotion-reconstruction-from-pressure-sensing-insoles.html"},{"id":"2510.22728v1","title":"S-Chain: Structured Visual Chain-of-Thought For Medicine","headline":"提出S-Chain数据集，用于提升医学视觉语言模型的可解释性和视觉 grounding 准确性。","tag":"cs.LG","date":"2025-10-26","url":"cs-LG/2025-10-26/papers/251022728v1-s-chain-structured-visual-chain-of-thought-for-medicine.html"},{"id":"2510.22201v1","title":"ACG: Action Coherence Guidance for Flow-based VLA models","headline":"提出动作连贯性引导（ACG）方法，提升基于流的VLA模型在机器人操作任务中的性能","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022201v1-acg-action-coherence-guidance-for-flow-based-vla-models.html"},{"id":"2510.22126v1","title":"EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control","headline":"EasyUUV：基于LLM的通用轻量级UUV姿态控制Sim-to-Real强化学习框架","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022126v1-easyuuv-an-llm-enhanced-universal-and-lightweight-sim-to-real-reinfo.html"},{"id":"2510.22336v2","title":"Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery","headline":"提出RoboCraft框架，联合优化人形机器人控制与形态，提升跌倒恢复能力。","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022336v2-toward-humanoid-brain-body-co-design-joint-optimization-of-control-a.html"},{"id":"2510.22370v1","title":"BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles","headline":"提出BLIP-FusePPO框架以解决自动驾驶车辆的车道保持问题","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022370v1-blip-fuseppo-a-vision-language-deep-reinforcement-learning-framework.html"},{"id":"2510.22113v1","title":"RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation","headline":"RaycastGrasp：基于眼动追踪与可穿戴设备的机器人操作交互","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022113v1-raycastgrasp-eye-gaze-interaction-with-wearable-devices-for-robotic-.html"},{"id":"2510.22339v1","title":"Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks","headline":"提出时空神经网络，融合多模态数据，精确估计受载连续体机器人的形状","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022339v1-estimating-continuum-robot-shape-under-external-loading-using-spatio.html"},{"id":"2510.22313v1","title":"Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis","headline":"提出基于时空法线分析的动态感知LIO框架，解决动态环境下定位难题","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022313v1-breaking-the-static-assumption-a-dynamic-aware-lio-framework-via-spa.html"},{"id":"2510.22204v1","title":"Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments","headline":"NeuroSymLand：结合神经符号推理，提升无人机在复杂环境下的自主着陆能力","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022204v1-bridging-perception-and-reasoning-dual-pipeline-neuro-symbolic-landi.html"},{"id":"2510.22420v1","title":"A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems","headline":"提出多时间尺度稳定性保持的层次强化学习控制框架以解决高维动态系统控制问题","tag":"cs.RO","date":"2025-10-25","url":"cs-RO/2025-10-25/papers/251022420v1-a-novel-multi-timescale-stability-preserving-hierarchical-reinforcem.html"},{"id":"2510.22443v1","title":"Benchmarking Egocentric Multimodal Goal Inference for Assistive Wearable Agents","headline":"WAGIBench：用于辅助可穿戴代理的自中心多模态目标推断基准","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022443v1-benchmarking-egocentric-multimodal-goal-inference-for-assistive-wear.html"},{"id":"2510.22359v1","title":"EndoSfM3D: Learning to 3D Reconstruct Any Endoscopic Surgery Scene using Self-supervised Foundation Model","headline":"EndoSfM3D：利用自监督基础模型学习内窥镜手术场景的3D重建","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022359v1-endosfm3d-learning-to-3d-reconstruct-any-endoscopic-surgery-scene-us.html"},{"id":"2510.22161v1","title":"I2-NeRF: Learning Neural Radiance Fields Under Physically-Grounded Media Interactions","headline":"I2-NeRF：提出一种物理可信的神经辐射场，增强介质退化下的三维重建。","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022161v1-i2-nerf-learning-neural-radiance-fields-under-physically-grounded-me.html"},{"id":"2510.22129v1","title":"egoEMOTION: Egocentric Vision and Physiological Signals for Emotion and Personality Recognition in Real-World Tasks","headline":"egoEMOTION：结合第一人称视觉与生理信号的情感与人格识别数据集","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022129v1-egoemotion-egocentric-vision-and-physiological-signals-for-emotion-a.html"},{"id":"2510.24777v1","title":"Cross-Enhanced Multimodal Fusion of Eye-Tracking and Facial Features for Alzheimer's Disease Diagnosis","headline":"提出一种交叉增强的多模态融合框架，用于眼动追踪和面部特征的阿尔茨海默病诊断。","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251024777v1-cross-enhanced-multimodal-fusion-of-eye-tracking-and-facial-features.html"},{"id":"2510.22119v1","title":"CogStereo: Neural Stereo Matching with Implicit Spatial Cognition Embedding","headline":"CogStereo：利用隐式空间认知嵌入的神经立体匹配，提升零样本泛化能力。","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022119v1-cogstereo-neural-stereo-matching-with-implicit-spatial-cognition-emb.html"},{"id":"2510.22319v2","title":"GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping","headline":"GRPO-Guard：通过调节裁剪缓解Flow Matching中的隐式过度优化","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022319v2-grpo-guard-mitigating-implicit-over-optimization-in-flow-matching-vi.html"},{"id":"2510.22282v1","title":"CityRiSE: Reasoning Urban Socio-Economic Status in Vision-Language Models via Reinforcement Learning","headline":"提出CityRiSE，利用强化学习提升视觉-语言模型在城市社会经济地位推理中的能力","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022282v1-cityrise-reasoning-urban-socio-economic-status-in-vision-language-mo.html"},{"id":"2510.22213v2","title":"DynamicTree: Interactive Real Tree Animation via Sparse Voxel Spectrum","headline":"DynamicTree：利用稀疏体素谱实现交互式真实树木动画","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022213v2-dynamictree-interactive-real-tree-animation-via-sparse-voxel-spectru.html"},{"id":"2510.22102v1","title":"Mitigating Coordinate Prediction Bias from Positional Encoding Failures","headline":"针对MLLM坐标预测偏差，提出Vision-PE Shuffle Guidance方法提升定位精度","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022102v1-mitigating-coordinate-prediction-bias-from-positional-encoding-failu.html"},{"id":"2510.22199v1","title":"MOGRAS: Human Motion with Grasping in 3D Scenes","headline":"MOGRAS：提出大规模3D场景中人体抓取交互运动数据集与基准方法。","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022199v1-mogras-human-motion-with-grasping-in-3d-scenes.html"},{"id":"2510.22141v1","title":"LOC: A General Language-Guided Framework for Open-Set 3D Occupancy Prediction","headline":"LOC：一种通用的语言引导框架，用于开放集3D occupancy预测","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022141v1-loc-a-general-language-guided-framework-for-open-set-3d-occupancy-pr.html"},{"id":"2510.22322v1","title":"Beyond Augmentation: Leveraging Inter-Instance Relation in Self-Supervised Representation Learning","headline":"提出基于图神经网络的自监督学习方法，利用实例间关系提升表征质量","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022322v1-beyond-augmentation-leveraging-inter-instance-relation-in-self-super.html"},{"id":"2510.22140v1","title":"STG-Avatar: Animatable Human Avatars via Spacetime Gaussian","headline":"提出STG-Avatar，通过时空高斯优化实现高保真可动画人体化身重建","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022140v1-stg-avatar-animatable-human-avatars-via-spacetime-gaussian.html"},{"id":"2510.22200v2","title":"LongCat-Video Technical Report","headline":"LongCat-Video：基于扩散Transformer的高效长视频生成模型","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022200v2-longcat-video-technical-report.html"},{"id":"2510.22171v2","title":"HARMONY: Hidden Activation Representations and Model Output-Aware Uncertainty Estimation for Vision-Language Models","headline":"提出HARMONY，利用隐层激活和模型输出来提升视觉-语言模型的不确定性估计。","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022171v2-harmony-hidden-activation-representations-and-model-output-aware-unc.html"},{"id":"2510.22118v2","title":"GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation","headline":"GRAID：通过高质量数据生成增强视觉语言模型空间推理能力","tag":"cs.CV","date":"2025-10-25","url":"cs-CV/2025-10-25/papers/251022118v2-graid-enhancing-spatial-reasoning-of-vlms-through-high-fidelity-data.html"},{"id":"2510.22340v2","title":"DynaSolidGeo: A Dynamic Benchmark for Genuine Spatial Mathematical Reasoning of VLMs in Solid Geometry","headline":"提出DynaSolidGeo以解决空间数学推理评估问题","tag":"cs.AI","date":"2025-10-25","url":"cs-AI/2025-10-25/papers/251022340v2-dynasolidgeo-a-dynamic-benchmark-for-genuine-spatial-mathematical-re.html"},{"id":"2510.22373v1","title":"VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations","headline":"提出VisJudge-Bench，用于评估MLLM在可视化美学和质量评估中的性能，并提出VisJudge模型。","tag":"cs.CL","date":"2025-10-25","url":"cs-CL/2025-10-25/papers/251022373v1-visjudge-bench-aesthetics-and-quality-assessment-of-visualizations.html"},{"id":"2510.21571v1","title":"Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos","headline":"提出基于大规模真实人类活动视频的机器人操作VLA模型预训练方法","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021571v1-scalable-vision-language-action-model-pretraining-for-robotic-manipu.html"},{"id":"2510.21369v1","title":"Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain","headline":"提出一种基于力感知的四足机器人可塌陷地形安全导航框架","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021369v1-load-bearing-assessment-for-safe-locomotion-of-quadruped-robots-on-c.html"},{"id":"2510.22030v1","title":"Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems","headline":"提出一种预测二足系统额状面稳定所需最小步频的方法，用于优化步态控制。","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251022030v1-estimation-of-minimum-stride-frequency-for-the-frontal-plane-stabili.html"},{"id":"2510.21991v1","title":"Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising","headline":"提出基于遗传去噪的两步扩散策略，提升机器人操作任务性能。","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021991v1-two-steps-diffusion-policy-for-robotic-manipulation-via-genetic-deno.html"},{"id":"2510.21609v1","title":"Enhancing Tactile-based Reinforcement Learning for Robotic Control","headline":"提出自监督学习方法以增强机器人触觉强化学习","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021609v1-enhancing-tactile-based-reinforcement-learning-for-robotic-control.html"},{"id":"2510.21121v1","title":"Generalizable Hierarchical Skill Learning via Object-Centric Representation","headline":"提出基于对象中心表示的通用分层技能学习框架，提升机器人操作泛化性","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021121v1-generalizable-hierarchical-skill-learning-via-object-centric-represe.html"},{"id":"2510.21438v1","title":"PREVENT: Proactive Risk Evaluation and Vigilant Execution of Tasks for Mobile Robotic Chemists using Multi-Modal Behavior Trees","headline":"PREVENT：多模态行为树驱动的移动机器人化学家风险评估与主动任务执行系统","tag":"cs.RO","date":"2025-10-24","url":"cs-RO/2025-10-24/papers/251021438v1-prevent-proactive-risk-evaluation-and-vigilant-execution-of-tasks-fo.html"},{"id":"2510.21111v1","title":"PhysVLM-AVR: Active Visual Reasoning for Multimodal Large Language Models in Physical Environments","headline":"提出PhysVLM-AVR以解决动态环境中的视觉推理问题","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021111v1-physvlm-avr-active-visual-reasoning-for-multimodal-large-language-mo.html"},{"id":"2510.21441v1","title":"OpenHype: Hyperbolic Embeddings for Hierarchical Open-Vocabulary Radiance Fields","headline":"OpenHype：提出基于双曲嵌入的开放词汇神经辐射场，用于建模场景层级结构。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021441v1-openhype-hyperbolic-embeddings-for-hierarchical-open-vocabulary-radi.html"},{"id":"2510.21122v2","title":"NoisyGRPO: Incentivizing Multimodal CoT Reasoning via Noise Injection and Bayesian Estimation","headline":"NoisyGRPO：通过噪声注入和贝叶斯估计激励多模态CoT推理","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021122v2-noisygrpo-incentivizing-multimodal-cot-reasoning-via-noise-injection.html"},{"id":"2510.21307v2","title":"Towards Physically Executable 3D Gaussian for Embodied Navigation","headline":"提出SAGE-3D，增强3D高斯表达的语义和物理可执行性，用于具身导航。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021307v2-towards-physically-executable-3d-gaussian-for-embodied-navigation.html"},{"id":"2510.21182v1","title":"KBE-DME: Dynamic Multimodal Evaluation via Knowledge Enhanced Benchmark Evolution","headline":"提出KBE，通过知识增强基准演化实现多模态大模型的动态评估","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021182v1-kbe-dme-dynamic-multimodal-evaluation-via-knowledge-enhanced-benchma.html"},{"id":"2510.21664v1","title":"Foundation Models in Dermatopathology: Skin Tissue Classification","headline":"利用皮肤病理学Foundation Model进行皮肤组织分类，提升诊断效率","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021664v1-foundation-models-in-dermatopathology-skin-tissue-classification.html"},{"id":"2510.21069v1","title":"ZING-3D: Zero-shot Incremental 3D Scene Graphs via Vision-Language Models","headline":"ZING-3D：利用视觉-语言模型实现零样本增量式3D场景图构建","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021069v1-zing-3d-zero-shot-incremental-3d-scene-graphs-via-vision-language-mo.html"},{"id":"2510.21635v1","title":"DAP-MAE: Domain-Adaptive Point Cloud Masked Autoencoder for Effective Cross-Domain Learning","headline":"DAP-MAE：领域自适应点云掩码自编码器，提升跨域学习效果","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021635v1-dap-mae-domain-adaptive-point-cloud-masked-autoencoder-for-effective.html"},{"id":"2510.21518v1","title":"Head Pursuit: Probing Attention Specialization in Multimodal Transformers","headline":"提出一种基于信号处理的注意力头分析方法，用于理解和编辑多模态Transformer模型。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021518v1-head-pursuit-probing-attention-specialization-in-multimodal-transfor.html"},{"id":"2510.21449v1","title":"MoniTor: Exploiting Large Language Models with Instruction for Online Video Anomaly Detection","headline":"MoniTor：利用指令驱动的大语言模型进行在线视频异常检测。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021449v1-monitor-exploiting-large-language-models-with-instruction-for-online.html"},{"id":"2510.21512v1","title":"Towards a Golden Classifier-Free Guidance Path via Foresight Fixed Point Iterations","headline":"提出基于前瞻定点迭代的黄金无分类器引导路径，提升文图生成质量与效率","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021512v1-towards-a-golden-classifier-free-guidance-path-via-foresight-fixed-p.html"},{"id":"2510.21432v1","title":"ArtiLatent: Realistic Articulated 3D Object Generation via Structured Latents","headline":"ArtiLatent：通过结构化隐空间生成逼真可动3D物体","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021432v1-artilatent-realistic-articulated-3d-object-generation-via-structured.html"},{"id":"2510.21311v1","title":"FineRS: Fine-grained Reasoning and Segmentation of Small Objects with Reinforcement Learning","headline":"提出FineRS，基于强化学习解决MLLM在高分辨率图像中小目标精细推理与分割难题。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021311v1-finers-fine-grained-reasoning-and-segmentation-of-small-objects-with.html"},{"id":"2510.21447v1","title":"PhysWorld: From Real Videos to World Models of Deformable Objects via Physics-Aware Demonstration Synthesis","headline":"PhysWorld：通过物理感知演示合成，从真实视频构建可变形对象的交互式世界模型","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021447v1-physworld-from-real-videos-to-world-models-of-deformable-objects-via.html"},{"id":"2510.21682v1","title":"WorldGrow: Generating Infinite 3D World","headline":"WorldGrow：提出无限3D世界生成框架，解决场景级生成难题","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021682v1-worldgrow-generating-infinite-3d-world.html"},{"id":"2510.21649v1","title":"A Dynamic Knowledge Distillation Method Based on the Gompertz Curve","headline":"提出Gompertz-CNN，利用Gompertz曲线动态调整知识蒸馏，提升学生模型性能。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021649v1-a-dynamic-knowledge-distillation-method-based-on-the-gompertz-curve.html"},{"id":"2510.21356v1","title":"Gaze-VLM:Bridging Gaze and VLMs through Attention Regularization for Egocentric Understanding","headline":"Gaze-VLM：通过注视正则化增强VLM的以自我为中心的理解能力","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021356v1-gaze-vlmbridging-gaze-and-vlms-through-attention-regularization-for-.html"},{"id":"2510.21160v1","title":"Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study","headline":"提出SIG结构化空间智能网格，提升自动驾驶场景下多模态大模型的空间推理能力。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021160v1-towards-physics-informed-spatial-intelligence-with-human-priors-an-a.html"},{"id":"2510.21167v1","title":"Blockwise Flow Matching: Improving Flow Matching Models For Efficient High-Quality Generation","headline":"提出Blockwise Flow Matching，提升Flow Matching模型生成效率和质量。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021167v1-blockwise-flow-matching-improving-flow-matching-models-for-efficient.html"},{"id":"2510.21079v1","title":"WaveSeg: Enhancing Segmentation Precision via High-Frequency Prior and Mamba-Driven Spectrum Decomposition","headline":"WaveSeg：利用高频先验和Mamba驱动的频谱分解增强分割精度","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021079v1-waveseg-enhancing-segmentation-precision-via-high-frequency-prior-an.html"},{"id":"2510.22045v1","title":"VLM-SlideEval: Evaluating VLMs on Structured Comprehension and Perturbation Sensitivity in PPT","headline":"VLM-SlideEval：评估VLM在PPT结构化理解和扰动敏感性上的性能","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251022045v1-vlm-slideeval-evaluating-vlms-on-structured-comprehension-and-pertur.html"},{"id":"2510.21114v1","title":"Controllable-LPMoE: Adapting to Challenging Object Segmentation via Dynamic Local Priors from Mixture-of-Experts","headline":"Controllable-LPMoE：通过动态局部先验混合专家网络提升目标分割性能","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251021114v1-controllable-lpmoe-adapting-to-challenging-object-segmentation-via-d.html"},{"id":"2510.24767v1","title":"Towards Fine-Grained Human Motion Video Captioning","headline":"提出运动增强的字幕模型(M-ACM)，用于生成细粒度的人体运动视频描述。","tag":"cs.CV","date":"2025-10-24","url":"cs-CV/2025-10-24/papers/251024767v1-towards-fine-grained-human-motion-video-captioning.html"},{"id":"2510.21402v2","title":"Disentangled Representation Learning via Modular Compositional Bias","headline":"提出基于模块化组合偏置的解耦表示学习方法，实现属性、对象及其联合解耦。","tag":"cs.LG","date":"2025-10-24","url":"cs-LG/2025-10-24/papers/251021402v2-disentangled-representation-learning-via-modular-compositional-bias.html"},{"id":"2510.21302v1","title":"Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning","headline":"提出神经符号框架，提升具身任务规划中代码策略的可靠性","tag":"cs.AI","date":"2025-10-24","url":"cs-AI/2025-10-24/papers/251021302v1-towards-reliable-code-as-policies-a-neuro-symbolic-framework-for-emb.html"},{"id":"2510.24770v2","title":"DMVFC: Deep Learning Based Functionally Consistent Tractography Fiber Clustering Using Multimodal Diffusion MRI and Functional MRI","headline":"提出DMVFC，利用多模态MRI数据进行功能一致的纤维束聚类","tag":"cs.AI","date":"2025-10-24","url":"cs-AI/2025-10-24/papers/251024770v2-dmvfc-deep-learning-based-functionally-consistent-tractography-fiber.html"},{"id":"2511.00020v1","title":"Multimodal Detection of Fake Reviews using BERT and ResNet-50","headline":"提出基于BERT和ResNet-50的多模态虚假评论检测方法，提升电商平台信任度。","tag":"cs.AI","date":"2025-10-24","url":"cs-AI/2025-10-24/papers/251100020v1-multimodal-detection-of-fake-reviews-using-bert-and-resnet-50.html"},{"id":"2510.21445v1","title":"REMONI: An Autonomous System Integrating Wearables and Multimodal Large Language Models for Enhanced Remote Health Monitoring","headline":"REMONI：集成可穿戴设备与多模态大语言模型的自主远程健康监测系统","tag":"cs.CL","date":"2025-10-24","url":"cs-CL/2025-10-24/papers/251021445v1-remoni-an-autonomous-system-integrating-wearables-and-multimodal-lar.html"},{"id":"2510.21270v1","title":"Sparser Block-Sparse Attention via Token Permutation","headline":"提出基于Token置换的稀疏块注意力机制PBS-Attn，加速长文本LLM预填充。","tag":"cs.CL","date":"2025-10-24","url":"cs-CL/2025-10-24/papers/251021270v1-sparser-block-sparse-attention-via-token-permutation.html"},{"id":"2510.20706v2","title":"Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning","headline":"结合MPC与强化学习，实现四足机器人实时步态自适应","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020706v2-real-time-gait-adaptation-for-quadrupeds-using-model-predictive-cont.html"},{"id":"2510.21026v1","title":"HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation","headline":"HRT1：用于移动操作的单样本人-机器人轨迹迁移系统","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251021026v1-hrt1-one-shot-human-to-robot-trajectory-transfer-for-mobile-manipula.html"},{"id":"2510.20813v1","title":"GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation","headline":"GSWorld：结合3D高斯溅射与物理引擎的机器人操作闭环仿真平台","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020813v1-gsworld-closed-loop-photo-realistic-simulation-suite-for-robotic-man.html"},{"id":"2510.20174v1","title":"Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment","headline":"提出基于强化学习的四足磁吸附壁面攀爬鲁棒控制器","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020174v1-reinforcement-learning-based-robust-wall-climbing-locomotion-control.html"},{"id":"2510.20818v1","title":"VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation","headline":"提出VAMOS以解决机器人导航中的环境适应性问题","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020818v1-vamos-a-hierarchical-vision-language-action-model-for-capability-mod.html"},{"id":"2510.20965v1","title":"SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing","headline":"SutureBot：用于自主端到端缝合的精准框架与基准测试","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020965v1-suturebot-a-precision-framework-benchmark-for-autonomous-end-to-end-.html"},{"id":"2510.20390v1","title":"NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control","headline":"NeuralTouch：融合神经描述符和触觉反馈，实现精确的Sim2Real机器人控制","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020390v1-neuraltouch-neural-descriptors-for-precise-sim-to-real-tactile-robot.html"},{"id":"2510.20335v1","title":"Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking","headline":"Dino-Diffusion Parking：利用视觉基础模型和扩散模型实现跨域自动泊车","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020335v1-dino-diffusion-modular-designs-bridge-the-cross-domain-gap-in-autono.html"},{"id":"2510.20774v2","title":"FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation","headline":"提出FieldGen以解决机器人操作数据收集的多样性与质量问题","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020774v2-fieldgen-from-teleoperated-pre-manipulation-trajectories-to-field-gu.html"},{"id":"2510.20347v1","title":"Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots","headline":"提出多模态分散式强化学习，用于模块化可重构月球机器人。","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020347v1-multi-modal-decentralized-reinforcement-learning-for-modular-reconfi.html"},{"id":"2510.20406v2","title":"PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning","headline":"PointMapPolicy：用于多模态模仿学习的结构化点云处理方法","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020406v2-pointmappolicy-structured-point-cloud-processing-for-multi-modal-imi.html"},{"id":"2510.21860v1","title":"Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence","headline":"Butter-Bench：评估LLM控制机器人在实际环境中的智能水平","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251021860v1-butter-bench-evaluating-llm-controlled-robots-for-practical-intellig.html"},{"id":"2510.20808v1","title":"The Reality Gap in Robotics: Challenges, Solutions, and Best Practices","headline":"综述机器人领域现实差距问题，分析原因、解决方案与最佳实践","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020808v1-the-reality-gap-in-robotics-challenges-solutions-and-best-practices.html"},{"id":"2510.20328v1","title":"MemER: Scaling Up Memory for Robot Control via Experience Retrieval","headline":"MemER：通过经验检索扩展机器人控制的记忆能力","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020328v1-memer-scaling-up-memory-for-robot-control-via-experience-retrieval.html"},{"id":"2510.20974v2","title":"Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization","headline":"提出基于PCA的规范化方法PPC，提升点云强化学习在未知视角下的鲁棒性","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020974v2-robust-point-cloud-reinforcement-learning-via-pca-based-canonicaliza.html"},{"id":"2510.21046v1","title":"Sequentially Teaching Sequential Tasks $(ST)^2$: Teaching Robots Long-horizon Manipulation Skills","headline":"提出(ST)^2，通过分段教学提升机器人长时程操作技能学习效率","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251021046v1-sequentially-teaching-sequential-tasks-st2-teaching-robots-long-hori.html"},{"id":"2510.20490v1","title":"Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators","headline":"针对SEA驱动并联机器人，提出刚度和轨迹同步优化方法以最小化能量消耗","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020490v1-simultaneous-stiffness-and-trajectory-optimization-for-energy-minimi.html"},{"id":"2510.20407v1","title":"MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control","headline":"MR-UBi：基于混合现实的水下机器人臂遥操作系统，通过双边控制实现反应扭矩指示","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020407v1-mr-ubi-mixed-reality-based-underwater-robot-arm-teleoperation-system.html"},{"id":"2510.20884v1","title":"ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning","headline":"ROPES：基于打分模型的因果表征学习实现机器人位姿估计","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020884v1-ropes-robotic-pose-estimation-via-score-based-causal-representation-.html"},{"id":"2510.20161v1","title":"PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation","headline":"PathFormer：结合3D网格约束的Transformer用于数字孪生机器人手臂轨迹生成","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020161v1-pathformer-a-transformer-with-3d-grid-constraints-for-digital-twin-r.html"},{"id":"2510.20483v1","title":"Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty","headline":"提出双重控制参考轨迹生成方法，解决有效载荷不确定性下的最优抓取放置问题","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020483v1-dual-control-reference-generation-for-optimal-pick-and-place-executi.html"},{"id":"2510.20177v1","title":"A Contact-Driven Framework for Manipulating in the Blind","headline":"提出基于接触驱动的框架，解决机器人盲操作中的物体操作问题。","tag":"cs.RO","date":"2025-10-23","url":"cs-RO/2025-10-23/papers/251020177v1-a-contact-driven-framework-for-manipulating-in-the-blind.html"},{"id":"2510.20238v1","title":"COS3D: Collaborative Open-Vocabulary 3D Segmentation","headline":"提出COS3D，通过协同提示分割框架解决开放词汇3D分割中的语言与分割融合问题。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020238v1-cos3d-collaborative-open-vocabulary-3d-segmentation.html"},{"id":"2510.20095v2","title":"BioCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models","headline":"BioCAP：利用合成字幕增强生物学基础模型，超越标签监督","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020095v2-biocap-exploiting-synthetic-captions-beyond-labels-in-biological-fou.html"},{"id":"2510.20578v1","title":"EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence","headline":"EmbodiedBrain：通过Step-GRPO提升具身智能任务规划性能","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020578v1-embodiedbrain-expanding-performance-boundaries-of-task-planning-for-.html"},{"id":"2510.21000v1","title":"BioDet: Boosting Industrial Object Detection with Image Preprocessing Strategies","headline":"BioDet：利用图像预处理策略提升工业目标检测性能","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251021000v1-biodet-boosting-industrial-object-detection-with-image-preprocessing.html"},{"id":"2510.20994v1","title":"VESSA: Video-based objEct-centric Self-Supervised Adaptation for Visual Foundation Models","headline":"提出VESSA：一种基于视频对象中心的自监督视觉基础模型适应方法","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020994v1-vessa-video-based-object-centric-self-supervised-adaptation-for-visu.html"},{"id":"2510.20470v2","title":"Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence","headline":"Conan：提出基于多尺度视觉证据的渐进式学习框架，提升多模态大语言模型在视频推理任务上的性能。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020470v2-conan-progressive-learning-to-reason-like-a-detective-over-multi-sca.html"},{"id":"2510.20196v1","title":"A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development","headline":"针对脑MRI基础模型，论文系统评估了公开数据集的多样性与一致性问题。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020196v1-a-structured-review-and-quantitative-profiling-of-public-brain-mri-d.html"},{"id":"2510.20807v1","title":"Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers","headline":"提出基于像素空间时空Transformer的物理模拟视频预测方法","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020807v1-video-prediction-of-dynamic-physical-simulations-with-pixel-space-sp.html"},{"id":"2510.20696v1","title":"Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward","headline":"提出基于Agent的架构，提升多模态大语言模型在视觉推理任务上的性能","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020696v1-diagnosing-visual-reasoning-challenges-insights-and-a-path-forward.html"},{"id":"2510.20519v2","title":"Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning","headline":"提出Metis-HOME，通过混合专家模型解决多模态推理中的效率与泛化难题","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020519v2-metis-home-hybrid-optimized-mixture-of-experts-for-multimodal-reason.html"},{"id":"2510.20322v2","title":"HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models","headline":"HyperET：通过双曲空间高效训练多模态大语言模型，提升跨模态对齐。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020322v2-hyperet-efficient-training-in-hyperbolic-space-for-multi-modal-large.html"},{"id":"2510.20256v1","title":"Calibrating Multimodal Consensus for Emotion Recognition","headline":"提出校准多模态共识模型以解决情感识别中的语义不一致问题","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020256v1-calibrating-multimodal-consensus-for-emotion-recognition.html"},{"id":"2510.20803v1","title":"ARGenSeg: Image Segmentation with Autoregressive Image Generation Model","headline":"ARGenSeg：提出基于自回归图像生成模型的图像分割方法","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020803v1-argenseg-image-segmentation-with-autoregressive-image-generation-mod.html"},{"id":"2510.20285v2","title":"DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering","headline":"提出DMC$^3$框架以解决第一人称视频问答中的挑战","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020285v2-dmc3-dual-modal-counterfactual-contrastive-construction-for-egocentr.html"},{"id":"2510.21501v1","title":"GranViT: A Fine-Grained Vision Model With Autoregressive Perception For MLLMs","headline":"GranViT：面向MLLM的细粒度视觉模型，通过自回归感知提升性能","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251021501v1-granvit-a-fine-grained-vision-model-with-autoregressive-perception-f.html"},{"id":"2510.21867v1","title":"Addressing Corner Cases in Autonomous Driving: A World Model-based Approach with Mixture of Experts and LLMs","headline":"提出WM-MoE框架，利用世界模型和混合专家模型解决自动驾驶Corner Case问题","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251021867v1-addressing-corner-cases-in-autonomous-driving-a-world-model-based-ap.html"},{"id":"2510.20549v1","title":"Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation","headline":"提出SELM-SLAM3，利用深度学习增强视觉SLAM，辅助视障人士导航。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020549v1-deep-learning-powered-visual-slam-aimed-at-assisting-visually-impair.html"},{"id":"2510.20531v1","title":"Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis","headline":"提出Fake-in-Facext框架，实现细粒度、可解释的DeepFake人脸分析。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020531v1-fake-in-facext-towards-fine-grained-explainable-deepfake-analysis.html"},{"id":"2510.20214v1","title":"Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection","headline":"提出CURL框架，利用对比学习进行胎儿超声视频中的胎动检测。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020214v1-towards-objective-obstetric-ultrasound-assessment-contrastive-repres.html"},{"id":"2510.20206v1","title":"RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling","headline":"RAPO++：通过数据对齐和测试时缩放优化文本到视频生成中的跨阶段Prompt","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020206v1-rapo-cross-stage-prompt-optimization-for-text-to-video-generation-vi.html"},{"id":"2510.20951v1","title":"Generative Point Tracking with Flow Matching","headline":"提出基于Flow Matching的生成式点跟踪器GenPT，解决视觉遮挡下的多模态轨迹预测问题。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020951v1-generative-point-tracking-with-flow-matching.html"},{"id":"2510.21879v1","title":"TernaryCLIP: Efficiently Compressing Vision-Language Models with Ternary Weights and Distilled Knowledge","headline":"TernaryCLIP：通过三元权重和知识蒸馏高效压缩视觉-语言模型","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251021879v1-ternaryclip-efficiently-compressing-vision-language-models-with-tern.html"},{"id":"2510.20165v1","title":"IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks","headline":"提出IB-GAN，利用信息瓶颈改进GAN的解耦表示学习。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020165v1-ib-gan-disentangled-representation-learning-with-information-bottlen.html"},{"id":"2510.20162v1","title":"TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning","headline":"提出TOMCAT，通过测试时知识累积解决组合零样本学习中的分布偏移问题。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020162v1-tomcat-test-time-comprehensive-knowledge-accumulation-for-compositio.html"},{"id":"2510.20155v1","title":"PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding","headline":"提出PartNeXt数据集，用于细粒度分层3D部件理解，提升模型性能。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020155v1-partnext-a-next-generation-dataset-for-fine-grained-and-hierarchical.html"},{"id":"2510.20812v3","title":"Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation","headline":"提出Speculative Verdict框架，解决信息密集型图像的视觉推理难题。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020812v3-small-drafts-big-verdict-information-intensive-visual-reasoning-via-.html"},{"id":"2510.20726v1","title":"AutoScape: Geometry-Consistent Long-Horizon Scene Generation","headline":"AutoScape：提出几何一致的长时程驾驶场景生成框架","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020726v1-autoscape-geometry-consistent-long-horizon-scene-generation.html"},{"id":"2510.20622v1","title":"SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding","headline":"提出SeViCES框架，通过语义-视觉共识提升长视频理解能力","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020622v1-sevices-unifying-semantic-visual-evidence-consensus-for-long-video-u.html"},{"id":"2510.20287v1","title":"Breakdance Video classification in the age of Generative AI","headline":"针对霹雳舞视频分类，分析了生成式AI时代下视频基础模型（编码器和解码器）的适用性。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020287v1-breakdance-video-classification-in-the-age-of-generative-ai.html"},{"id":"2510.20794v1","title":"Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature","headline":"提出一种雷达-相机融合的多目标跟踪框架，实现在线标定和通用特征利用。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020794v1-radar-camera-fused-multi-object-tracking-online-calibration-and-comm.html"},{"id":"2510.20558v1","title":"From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail","headline":"研究不同细节层次下人群表征的感知质量，优化人群渲染策略。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020558v1-from-far-and-near-perceptual-evaluation-of-crowd-representations-acr.html"},{"id":"2510.20178v1","title":"PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching","headline":"提出PPMStereo，通过Pick-and-Play记忆构建实现动态立体匹配中的时序一致性。","tag":"cs.CV","date":"2025-10-23","url":"cs-CV/2025-10-23/papers/251020178v1-ppmstereo-pick-and-play-memory-construction-for-consistent-dynamic-s.html"},{"id":"2510.20955v1","title":"Safety Assessment in Reinforcement Learning via Model Predictive Control","headline":"提出基于模型预测控制的强化学习安全评估方法，保障训练过程安全性","tag":"cs.LG","date":"2025-10-23","url":"cs-LG/2025-10-23/papers/251020955v1-safety-assessment-in-reinforcement-learning-via-model-predictive-con.html"},{"id":"2510.20875v1","title":"CC-GRMAS: A Multi-Agent Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia","headline":"提出CC-GRMAS，用于高山亚洲地区时空滑坡风险评估","tag":"cs.LG","date":"2025-10-23","url":"cs-LG/2025-10-23/papers/251020875v1-cc-grmas-a-multi-agent-graph-neural-system-for-spatiotemporal-landsl.html"},{"id":"2510.20809v1","title":"Real Deep Research for AI, Robotics and Beyond","headline":"提出Real Deep Research框架，系统分析AI与机器人领域的研究趋势与机遇。","tag":"cs.AI","date":"2025-10-23","url":"cs-AI/2025-10-23/papers/251020809v1-real-deep-research-for-ai-robotics-and-beyond.html"},{"id":"2510.19430v3","title":"GigaBrain-0: A World Model-Powered Vision-Language-Action Model","headline":"GigaBrain-0：基于世界模型赋能的视觉-语言-动作通用机器人模型","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019430v3-gigabrain-0-a-world-model-powered-vision-language-action-model.html"},{"id":"2510.19495v2","title":"Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning","headline":"利用离线强化学习，通过非专家数据增强模仿学习的鲁棒性","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019495v2-using-non-expert-data-to-robustify-imitation-learning-via-offline-re.html"},{"id":"2510.19752v1","title":"Learning Affordances at Inference-Time for Vision-Language-Action Models","headline":"提出LITEN，通过推理时学习能力提升VLA模型在复杂机器人任务中的表现","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019752v1-learning-affordances-at-inference-time-for-vision-language-action-mo.html"},{"id":"2510.19655v1","title":"LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments","headline":"LaViRA：用于连续环境零样本视觉语言导航的语言-视觉-机器人动作翻译框架","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019655v1-lavira-language-vision-robot-actions-translation-for-zero-shot-visio.html"},{"id":"2510.19974v1","title":"Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC","headline":"提出C3+算法，通过接触隐式MPC实现对多种物体的单/多目标精准推移操作。","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019974v1-push-anything-single-and-multi-object-pushing-from-first-sight-with-.html"},{"id":"2510.19541v1","title":"Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach","headline":"提出基于模型预测控制的义肢腕部运动优化方案，提升灵活性和用户控制。","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019541v1-optimizing-prosthetic-wrist-movement-a-model-predictive-control-appr.html"},{"id":"2510.19766v2","title":"SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas","headline":"SEA：基于语义地图预测的主动探索不确定区域方法","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019766v2-sea-semantic-map-prediction-for-active-exploration-of-uncertain-area.html"},{"id":"2510.19356v1","title":"Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model","headline":"提出基于多步一致性积分捷径模型的模仿学习策略，加速机器人策略推理。","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019356v1-imitation-learning-policy-based-on-multi-step-consistent-integration.html"},{"id":"2510.19364v1","title":"ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling","headline":"ProTerrain：提出概率物理信息粗糙地形建模方法，提升机器人轨迹预测精度。","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019364v1-proterrain-probabilistic-physics-informed-rough-terrain-world-modeli.html"},{"id":"2510.19289v1","title":"TARMAC: A Taxonomy for Robot Manipulation in Chemistry","headline":"提出TARMAC以解决化学实验室机器人操作技能缺乏的问题","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019289v1-tarmac-a-taxonomy-for-robot-manipulation-in-chemistry.html"},{"id":"2510.19268v1","title":"Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models","headline":"提出基于强化学习和视觉语言模型的层级DLO路径规划方法","tag":"cs.RO","date":"2025-10-22","url":"cs-RO/2025-10-22/papers/251019268v1-hierarchical-dlo-routing-with-reinforcement-learning-and-in-context-.html"},{"id":"2510.19789v1","title":"OmniMotion-X: Versatile Multimodal Whole-Body Motion Generation","headline":"OmniMotion-X：多功能多模态全身运动生成框架，实现逼真可控的交互式长时运动。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019789v1-omnimotion-x-versatile-multimodal-whole-body-motion-generation.html"},{"id":"2510.19451v1","title":"Reasoning Like Experts: Leveraging Multimodal Large Language Models for Drawing-based Psychoanalysis","headline":"提出PICK框架，利用多模态大语言模型进行基于绘画的心理分析，提升专家级推理能力。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019451v1-reasoning-like-experts-leveraging-multimodal-large-language-models-f.html"},{"id":"2510.19578v1","title":"VGD: Visual Geometry Gaussian Splatting for Feed-Forward Surround-view Driving Reconstruction","headline":"VGD：用于前馈环视驾驶场景重建的视觉几何高斯溅射","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019578v1-vgd-visual-geometry-gaussian-splatting-for-feed-forward-surround-vie.html"},{"id":"2510.20027v1","title":"Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses","headline":"提出基于梯度的3DGS滤波方法，解决极端视角下新视角合成的伪影问题","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251020027v1-extreme-views-3dgs-filter-for-novel-view-synthesis-from-out-of-distr.html"},{"id":"2510.19255v1","title":"Advances in 4D Representation: Geometry, Motion, and Interaction","headline":"针对4D生成与重建，提出基于几何、运动和交互的4D表征方法综述。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019255v1-advances-in-4d-representation-geometry-motion-and-interaction.html"},{"id":"2510.19336v1","title":"DaMo: Data Mixing Optimizer in Fine-tuning Multimodal LLMs for Mobile Phone Agents","headline":"DaMo：用于手机Agent多模态LLM微调的数据混合优化器","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019336v1-damo-data-mixing-optimizer-in-fine-tuning-multimodal-llms-for-mobile.html"},{"id":"2510.19333v2","title":"A Training-Free Framework for Open-Vocabulary Image Segmentation and Recognition with EfficientNet and CLIP","headline":"提出一种基于EfficientNet和CLIP的无训练开放词汇图像分割与识别框架","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019333v2-a-training-free-framework-for-open-vocabulary-image-segmentation-and.html"},{"id":"2510.19400v1","title":"Seeing Across Views: Benchmarking Spatial Reasoning of Vision-Language Models in Robotic Scenes","headline":"提出MV-RoboBench基准，评估视觉-语言模型在机器人场景中的多视角空间推理能力","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019400v1-seeing-across-views-benchmarking-spatial-reasoning-of-vision-languag.html"},{"id":"2510.21842v1","title":"Modal Aphasia: Can Unified Multimodal Models Describe Images From Memory?","headline":"揭示多模态模型中的“模态失语症”现象，即视觉记忆准确但文本描述失败","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251021842v1-modal-aphasia-can-unified-multimodal-models-describe-images-from-mem.html"},{"id":"2510.19273v1","title":"MobiAct: Efficient MAV Action Recognition Using MobileNetV4 with Contrastive Learning and Knowledge Distillation","headline":"提出MobiAct：一种基于MobileNetV4、对比学习和知识蒸馏的高效MAV动作识别框架","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019273v1-mobiact-efficient-mav-action-recognition-using-mobilenetv4-with-cont.html"},{"id":"2510.19944v1","title":"Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets","headline":"Seed3D 1.0：提出从单张图像生成高质量、可用于物理仿真的3D资产的框架。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019944v1-seed3d-10-from-images-to-high-fidelity-simulation-ready-3d-assets.html"},{"id":"2510.19814v3","title":"Toward A Better Understanding of Monocular Depth Evaluation","headline":"提出单目深度估计评估新指标，提升与人类感知的对齐性","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019814v3-toward-a-better-understanding-of-monocular-depth-evaluation.html"},{"id":"2510.19371v1","title":"AegisRF: Adversarial Perturbations Guided with Sensitivity for Protecting Intellectual Property of Neural Radiance Fields","headline":"AegisRF：利用敏感度引导的对抗扰动保护NeRF的知识产权","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019371v1-aegisrf-adversarial-perturbations-guided-with-sensitivity-for-protec.html"},{"id":"2510.19559v1","title":"A Matter of Time: Revealing the Structure of Time in Vision-Language Models","headline":"提出TIME10k基准，揭示视觉-语言模型中时间信息的低维非线性结构，并构建时间轴表示。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019559v1-a-matter-of-time-revealing-the-structure-of-time-in-vision-language-.html"},{"id":"2510.19955v1","title":"Transformed Multi-view 3D Shape Features with Contrastive Learning","headline":"提出基于对比学习的Transformer多视角3D形状特征提取方法","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019955v1-transformed-multi-view-3d-shape-features-with-contrastive-learning.html"},{"id":"2510.19678v1","title":"I Spy With My Model's Eye: Visual Search as a Behavioural Test for MLLMs","headline":"利用视觉搜索行为测试评估多模态大语言模型(MLLM)的视觉感知能力","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019678v1-i-spy-with-my-models-eye-visual-search-as-a-behavioural-test-for-mll.html"},{"id":"2510.19592v1","title":"Decomposed Attention Fusion in MLLMs for Training-Free Video Reasoning Segmentation","headline":"提出Decomposed Attention Fusion (DecAF)，用于MLLM的免训练视频推理分割","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019592v1-decomposed-attention-fusion-in-mllms-for-training-free-video-reasoni.html"},{"id":"2510.19307v1","title":"Unified Reinforcement and Imitation Learning for Vision-Language Models","headline":"提出统一强化与模仿学习(RIL)算法，用于训练轻量级视觉-语言模型。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019307v1-unified-reinforcement-and-imitation-learning-for-vision-language-mod.html"},{"id":"2510.21850v1","title":"SCoPE VLM: Selective Context Processing for Efficient Document Navigation in Vision-Language Models","headline":"SCoPE VLM：面向高效文档导航的视觉语言模型选择性上下文处理","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251021850v1-scope-vlm-selective-context-processing-for-efficient-document-naviga.html"},{"id":"2510.19654v2","title":"From Forecasting to Planning: Policy World Model for Collaborative State-Action Prediction","headline":"提出策略世界模型PWM，用于协同状态-动作预测，提升自动驾驶规划能力","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019654v2-from-forecasting-to-planning-policy-world-model-for-collaborative-st.html"},{"id":"2510.19560v1","title":"HAD: Hierarchical Asymmetric Distillation to Bridge Spatio-Temporal Gaps in Event-Based Object Tracking","headline":"提出分层非对称蒸馏（HAD）框架，弥合事件相机目标跟踪中的时空差异。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019560v1-had-hierarchical-asymmetric-distillation-to-bridge-spatio-temporal-g.html"},{"id":"2510.19475v1","title":"PRGCN: A Graph Memory Network for Cross-Sequence Pattern Reuse in 3D Human Pose Estimation","headline":"提出PRGCN，利用图记忆网络实现跨序列人体姿态模式复用，提升3D人体姿态估计精度。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019475v1-prgcn-a-graph-memory-network-for-cross-sequence-pattern-reuse-in-3d-.html"},{"id":"2510.19986v1","title":"Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts","headline":"利用LLM和RAG自动化宗教木刻图像的Iconclass大规模分类","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019986v1-automating-iconclass-llms-and-rag-for-large-scale-classification-of-.html"},{"id":"2510.19981v2","title":"FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking","headline":"FutrTrack：一种用于3D多目标跟踪的相机-激光雷达融合Transformer","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019981v2-futrtrack-a-camera-lidar-fusion-transformer-for-3d-multiple-object-t.html"},{"id":"2510.19808v1","title":"Pico-Banana-400K: A Large-Scale Dataset for Text-Guided Image Editing","headline":"提出Pico-Banana-400K大规模数据集，促进文本引导图像编辑研究","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019808v1-pico-banana-400k-a-large-scale-dataset-for-text-guided-image-editing.html"},{"id":"2510.19622v2","title":"Augmenting Moment Retrieval: Zero-Dependency Two-Stage Learning","headline":"提出零外部依赖的增强时刻检索框架AMR，解决数据稀疏、边界模糊和语义区分不足问题。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019622v2-augmenting-moment-retrieval-zero-dependency-two-stage-learning.html"},{"id":"2510.19496v1","title":"CARES: Context-Aware Resolution Selector for VLMs","headline":"提出CARES上下文感知分辨率选择器，降低VLM计算成本并保持性能","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019496v1-cares-context-aware-resolution-selector-for-vlms.html"},{"id":"2510.19819v1","title":"Is This Tracker On? A Benchmark Protocol for Dynamic Tracking","headline":"提出ITTO：一个用于动态点跟踪的全新基准测试协议，聚焦真实场景挑战。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019819v1-is-this-tracker-on-a-benchmark-protocol-for-dynamic-tracking.html"},{"id":"2510.19527v1","title":"PoseCrafter: Extreme Pose Estimation with Hybrid Video Synthesis","headline":"PoseCrafter：利用混合视频合成增强极端位姿估计","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019527v1-posecrafter-extreme-pose-estimation-with-hybrid-video-synthesis.html"},{"id":"2510.19330v1","title":"Exploring Scale Shift in Crowd Localization under the Context of Domain Generalization","headline":"针对人群定位中尺度偏移问题，提出因果特征解耦和异构处理方法，提升领域泛化能力。","tag":"cs.CV","date":"2025-10-22","url":"cs-CV/2025-10-22/papers/251019330v1-exploring-scale-shift-in-crowd-localization-under-the-context-of-dom.html"},{"id":"2510.19305v1","title":"FrogDeepSDM: Improving Frog Counting and Occurrence Prediction Using Multimodal Data and Pseudo-Absence Imputation","headline":"FrogDeepSDM：利用多模态数据和伪缺失值插补提升青蛙计数和分布预测","tag":"cs.LG","date":"2025-10-22","url":"cs-LG/2025-10-22/papers/251019305v1-frogdeepsdm-improving-frog-counting-and-occurrence-prediction-using-.html"},{"id":"2510.21835v1","title":"A Multimodal, Multitask System for Generating E Commerce Text Listings from Images","headline":"提出一种多模态多任务系统，用于从图像生成电商文本列表，显著降低幻觉率。","tag":"cs.LG","date":"2025-10-22","url":"cs-LG/2025-10-22/papers/251021835v1-a-multimodal-multitask-system-for-generating-e-commerce-text-listing.html"},{"id":"2510.19818v1","title":"Semantic World Models","headline":"提出基于视觉语言模型的语义世界模型，提升机器人控制泛化性","tag":"cs.LG","date":"2025-10-22","url":"cs-LG/2025-10-22/papers/251019818v1-semantic-world-models.html"},{"id":"2510.19755v3","title":"A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation","headline":"综述扩散模型缓存方法，加速高效多模态生成。","tag":"cs.LG","date":"2025-10-22","url":"cs-LG/2025-10-22/papers/251019755v3-a-survey-on-cache-methods-in-diffusion-models-toward-efficient-multi.html"},{"id":"2510.19732v2","title":"Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning","headline":"提出Memo：一种内存高效的强化学习具身智能体训练方法","tag":"cs.AI","date":"2025-10-22","url":"cs-AI/2025-10-22/papers/251019732v2-memo-training-memory-efficient-embodied-agents-with-reinforcement-le.html"},{"id":"2510.19585v2","title":"Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark","headline":"提出多模态基准数据集，评估大语言模型在历史文献拉丁语检测中的性能。","tag":"cs.CL","date":"2025-10-22","url":"cs-CL/2025-10-22/papers/251019585v2-detecting-latin-in-historical-books-with-large-language-models-a-mul.html"},{"id":"2510.18253v1","title":"OpenInsGaussian: Open-vocabulary Instance Gaussian Segmentation with Context-aware Cross-view Fusion","headline":"提出OpenInsGaussian，通过上下文感知跨视角融合实现开放词汇实例高斯分割。","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018253v1-openinsgaussian-open-vocabulary-instance-gaussian-segmentation-with-.html"},{"id":"2510.18244v1","title":"BlendCLIP: Bridging Synthetic and Real Domains for Zero-Shot 3D Object Classification with Multimodal Pretraining","headline":"BlendCLIP：通过多模态预训练桥接合成与真实域，实现零样本3D物体分类","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018244v1-blendclip-bridging-synthetic-and-real-domains-for-zero-shot-3d-objec.html"},{"id":"2510.18214v2","title":"VLSU: Mapping the Limits of Joint Multimodal Understanding for AI Safety","headline":"VLSU：构建多模态AI安全评估框架，揭示视觉-语言联合理解的局限性","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018214v2-vlsu-mapping-the-limits-of-joint-multimodal-understanding-for-ai-saf.html"},{"id":"2510.18262v1","title":"UWBench: A Comprehensive Vision-Language Benchmark for Underwater Understanding","headline":"UWBench：用于水下环境理解的综合性视觉-语言基准数据集","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018262v1-uwbench-a-comprehensive-vision-language-benchmark-for-underwater-und.html"},{"id":"2510.18267v1","title":"Latent-Info and Low-Dimensional Learning for Human Mesh Recovery and Parallel Optimization","headline":"提出基于潜在信息和低维学习的人体网格恢复与并行优化方法","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018267v1-latent-info-and-low-dimensional-learning-for-human-mesh-recovery-and.html"},{"id":"2510.18256v1","title":"Hyperbolic Space Learning Method Leveraging Temporal Motion Priors for Human Mesh Recovery","headline":"提出一种利用时序运动先验的 hyperbolic 空间学习方法，用于人体网格重建。","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018256v1-hyperbolic-space-learning-method-leveraging-temporal-motion-priors-f.html"},{"id":"2510.18187v1","title":"VelocityNet: Real-Time Crowd Anomaly Detection via Person-Specific Velocity Analysis","headline":"VelocityNet：基于个体速度分析的实时人群异常检测","tag":"cs.CV","date":"2025-10-21","url":"cs-CV/2025-10-21/papers/251018187v1-velocitynet-real-time-crowd-anomaly-detection-via-person-specific-ve.html"},{"id":"2510.18263v1","title":"From Competition to Synergy: Unlocking Reinforcement Learning for Subject-Driven Image Generation","headline":"提出Customized-GRPO，解决主体驱动图像生成中保真度和可编辑性的trade-off问题","tag":"cs.LG","date":"2025-10-21","url":"cs-LG/2025-10-21/papers/251018263v1-from-competition-to-synergy-unlocking-reinforcement-learning-for-sub.html"},{"id":"2510.17801v1","title":"Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain","headline":"RoboBench：用于评估多模态大语言模型作为具身智能大脑的综合基准","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017801v1-robobench-a-comprehensive-evaluation-benchmark-for-multimodal-large-.html"},{"id":"2510.17369v1","title":"Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots","headline":"提出将视觉-语言-动作模型应用于软机器人以解决安全交互问题","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017369v1-bridging-embodiment-gaps-deploying-vision-language-action-models-on-.html"},{"id":"2510.17111v3","title":"Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey","headline":"综述高效视觉-语言-动作模型，解决具身操作中计算资源受限问题","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017111v3-efficient-vision-language-action-models-for-embodied-manipulation-a-.html"},{"id":"2510.18002v1","title":"Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints","headline":"提出基于位置条件任务-运动约束的人形机器人守门员强化学习框架","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251018002v1-humanoid-goalkeeper-learning-from-position-conditioned-task-motion-c.html"},{"id":"2510.17640v2","title":"RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation","headline":"RESample：探索式采样增强机器人操作的鲁棒数据增强框架","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017640v2-resample-a-robust-data-augmentation-framework-via-exploratory-sampli.html"},{"id":"2510.17439v1","title":"From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors","headline":"FALCON：利用空间基础先验增强视觉-语言-动作模型的3D环境泛化能力","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017439v1-from-spatial-to-actions-grounding-vision-language-action-model-in-sp.html"},{"id":"2510.17792v1","title":"SoftMimic: Learning Compliant Whole-body Control from Examples","headline":"SoftMimic：从示例中学习柔顺的人形机器人全身控制","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017792v1-softmimic-learning-compliant-whole-body-control-from-examples.html"},{"id":"2510.17143v1","title":"Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning","headline":"提出基于模仿学习的无人机协同操作分散式实时规划方法","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017143v1-decentralized-real-time-planning-for-multi-uav-cooperative-manipulat.html"},{"id":"2510.17148v4","title":"DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment","headline":"DiffVLA++：通过度量引导对齐桥接认知推理与端到端驾驶","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017148v4-diffvla-bridging-cognitive-reasoning-and-end-to-end-driving-through-.html"},{"id":"2510.17249v1","title":"An adaptive hierarchical control framework for quadrupedal robots in planetary exploration","headline":"提出一种自适应分层控制框架，用于行星探测四足机器人未知环境导航。","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017249v1-an-adaptive-hierarchical-control-framework-for-quadrupedal-robots-in.html"},{"id":"2510.17270v1","title":"Floating-Base Deep Lagrangian Networks","headline":"提出FeLaN，结合深度学习与拉格朗日力学，解决浮动基座系统物理约束建模问题","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017270v1-floating-base-deep-lagrangian-networks.html"},{"id":"2510.18085v1","title":"R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations","headline":"R2BC：从单智能体演示中学习多智能体协作策略","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251018085v1-r2bc-multi-agent-imitation-learning-from-single-agent-demonstrations.html"},{"id":"2510.17541v1","title":"Distributed Spatial-Temporal Trajectory Optimization for Unmanned-Aerial-Vehicle Swarm","headline":"提出基于ADMM和DDP的分布式时空轨迹优化框架，解决无人机集群轨迹规划问题","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017541v1-distributed-spatial-temporal-trajectory-optimization-for-unmanned-ae.html"},{"id":"2510.17150v2","title":"OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation","headline":"OmniVIC：基于视觉语言上下文学习的自提升变阻抗控制器，用于安全机器人操作","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017150v2-omnivic-a-self-improving-variable-impedance-controller-with-vision-l.html"},{"id":"2510.17576v1","title":"Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries","headline":"提出意图驱动的LLM集成规划方法，用于柔性多机器人拆卸电动汽车电池。","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017576v1-intent-driven-llm-ensemble-planning-for-flexible-multi-robot-disasse.html"},{"id":"2510.17525v1","title":"HumanMPC - Safe and Efficient MAV Navigation among Humans","headline":"HumanMPC：面向人机共存环境的安全高效无人机导航","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017525v1-humanmpc-safe-and-efficient-mav-navigation-among-humans.html"},{"id":"2510.17315v1","title":"Implicit State Estimation via Video Replanning","headline":"提出基于视频重规划的隐式状态估计框架，提升交互式操作任务的适应性。","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017315v1-implicit-state-estimation-via-video-replanning.html"},{"id":"2510.17950v1","title":"RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies","headline":"RoboChallenge：大规模真实机器人环境下的具身策略评估系统","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017950v1-robochallenge-large-scale-real-robot-evaluation-of-embodied-policies.html"},{"id":"2510.18137v1","title":"Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning","headline":"提出基于接触感知的机器人数据筛选方法，提升机器人学习效率与确定性","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251018137v1-quality-over-quantity-curating-contact-based-robot-datasets-improves.html"},{"id":"2510.17335v3","title":"DDBot: Differentiable Physics-based Digging Robot for Unknown Granular Materials","headline":"DDBot：用于未知颗粒材料的可微物理挖掘机器人","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017335v3-ddbot-differentiable-physics-based-digging-robot-for-unknown-granula.html"},{"id":"2510.17086v1","title":"Learning to Design Soft Hands using Reward Models","headline":"提出基于奖励模型的交叉熵方法，高效优化柔性手爪设计。","tag":"cs.RO","date":"2025-10-20","url":"cs-RO/2025-10-20/papers/251017086v1-learning-to-design-soft-hands-using-reward-models.html"},{"id":"2510.18101v1","title":"From Volume Rendering to 3D Gaussian Splatting: Theory and Applications","headline":"综述3D高斯溅射：从体渲染到应用，解决实时渲染与高质量重建难题","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018101v1-from-volume-rendering-to-3d-gaussian-splatting-theory-and-applicatio.html"},{"id":"2510.17719v1","title":"Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions","headline":"Raindrop GS：提出雨滴环境下3D高斯溅射重建的综合评测基准","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017719v1-raindrop-gs-a-benchmark-for-3d-gaussian-splatting-under-raindrop-con.html"},{"id":"2510.17274v1","title":"Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models","headline":"提出PnF，利用多模态大语言模型增强现有运动预测模型，无需微调。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017274v1-enhanced-motion-forecasting-with-plug-and-play-multimodal-large-lang.html"},{"id":"2510.17479v1","title":"Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS","headline":"提出更强的初始化流程ItG-GS，显著提升稀疏视角3DGS的渲染质量。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017479v1-initialize-to-generalize-a-stronger-initialization-pipeline-for-spar.html"},{"id":"2510.17722v1","title":"MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues","headline":"提出MT-Video-Bench，用于评估多模态LLM在多轮对话中的视频理解能力","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017722v1-mt-video-bench-a-holistic-video-understanding-benchmark-for-evaluati.html"},{"id":"2510.17205v1","title":"$\\mathcal{V}isi\\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs","headline":"VisiPruner：解码多模态LLM中的非连续跨模态动态，实现高效剪枝","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017205v1-mathcalvisimathcalpruner-decoding-discontinuous-cross-modal-dynamics.html"},{"id":"2510.18014v1","title":"ManzaiSet: A Multimodal Dataset of Viewer Responses to Japanese Manzai Comedy","headline":"ManzaiSet：一个用于分析观众对日本漫才反应的多模态数据集","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018014v1-manzaiset-a-multimodal-dataset-of-viewer-responses-to-japanese-manza.html"},{"id":"2510.17790v2","title":"UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action","headline":"UltraCUA：融合GUI操作与高级工具的计算机使用Agent基础模型","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017790v2-ultracua-a-foundation-model-for-computer-use-agents-with-hybrid-acti.html"},{"id":"2510.17684v1","title":"Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model","headline":"提出IC-MoE模型，通过智能通信混合专家网络提升医学图像分割基础模型性能。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017684v1-intelligent-communication-mixture-of-experts-boosted-medical-image-s.html"},{"id":"2510.17384v1","title":"Closed-Loop Transfer for Weakly-supervised Affordance Grounding","headline":"提出LoopTrans闭环框架，用于弱监督可供性区域定位，提升复杂交互场景性能。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017384v1-closed-loop-transfer-for-weakly-supervised-affordance-grounding.html"},{"id":"2510.17318v1","title":"CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference","headline":"CausalMamba：用于神经因果推断的可扩展条件状态空间模型","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017318v1-causalmamba-scalable-conditional-state-space-models-for-neural-causa.html"},{"id":"2510.17095v1","title":"GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation","headline":"GSPlane：通过结构化表示实现简洁而精确的平面重建","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017095v1-gsplane-concise-and-accurate-planar-reconstruction-via-structured-re.html"},{"id":"2510.17078v1","title":"Towards a Generalizable Fusion Architecture for Multimodal Object Detection","headline":"提出FMCAF架构，提升多模态目标检测的泛化能力与鲁棒性","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017078v1-towards-a-generalizable-fusion-architecture-for-multimodal-object-de.html"},{"id":"2510.17568v3","title":"PAGE-4D: Disentangled Pose and Geometry Estimation for VGGT-4D Perception","headline":"PAGE-4D：解耦姿态与几何信息的动态场景VGGT-4D感知","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017568v3-page-4d-disentangled-pose-and-geometry-estimation-for-vggt-4d-percep.html"},{"id":"2510.17686v1","title":"Towards 3D Objectness Learning in an Open World","headline":"提出OP3Det，解决开放世界中无文本提示的通用3D目标检测问题","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017686v1-towards-3d-objectness-learning-in-an-open-world.html"},{"id":"2510.18054v1","title":"HouseTour: A Virtual Real Estate A(I)gent","headline":"HouseTour：提出一种利用扩散模型生成空间感知三维相机轨迹和自然语言摘要的方法，用于房地产场景。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018054v1-housetour-a-virtual-real-estate-aigent.html"},{"id":"2510.18016v2","title":"ViBED-Net: Video Based Engagement Detection Network Using Face-Aware and Scene-Aware Spatiotemporal Cues","headline":"ViBED-Net：利用人脸和场景时空线索进行视频参与度检测","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018016v2-vibed-net-video-based-engagement-detection-network-using-face-aware-.html"},{"id":"2510.17800v2","title":"Glyph: Scaling Context Windows via Visual-Text Compression","headline":"Glyph：通过视觉-文本压缩扩展大语言模型的上下文窗口","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017800v2-glyph-scaling-context-windows-via-visual-text-compression.html"},{"id":"2510.17434v2","title":"Leveraging AV1 motion vectors for Fast and Dense Feature Matching","headline":"利用AV1运动矢量实现快速密集特征匹配，提升SfM效率","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017434v2-leveraging-av1-motion-vectors-for-fast-and-dense-feature-matching.html"},{"id":"2510.21795v1","title":"Xihe: Scalable Zero-Shot Time Series Learner Via Hierarchical Interleaved Block Attention","headline":"提出基于分层交错块注意力（HIBA）的Xihe，用于可扩展的零样本时间序列学习。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251021795v1-xihe-scalable-zero-shot-time-series-learner-via-hierarchical-interle.html"},{"id":"2510.21794v1","title":"Token-Level Inference-Time Alignment for Vision-Language Models","headline":"提出TITA：一种用于视觉-语言模型Token级推理时对齐的轻量级框架","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251021794v1-token-level-inference-time-alignment-for-vision-language-models.html"},{"id":"2510.17332v1","title":"iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA","headline":"提出iDETEX，赋能多模态大语言模型实现智能、详细、可解释的图像质量评估","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017332v1-idetex-empowering-mllms-for-intelligent-detailed-explainable-iqa.html"},{"id":"2510.17181v1","title":"Capturing Head Avatar with Hand Contacts from a Monocular Video","headline":"提出一种单目视频头部Avatar重建方法，解决手部交互形变建模问题","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017181v1-capturing-head-avatar-with-hand-contacts-from-a-monocular-video.html"},{"id":"2510.18135v1","title":"World-in-World: World Models in a Closed-Loop World","headline":"World-in-World：首个闭环世界模型基准平台，用于评估具身智能体的预测感知能力。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018135v1-world-in-world-world-models-in-a-closed-loop-world.html"},{"id":"2510.18117v1","title":"Online In-Context Distillation for Low-Resource Vision Language Models","headline":"提出在线上下文蒸馏方法，提升低资源视觉语言模型性能。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018117v1-online-in-context-distillation-for-low-resource-vision-language-mode.html"},{"id":"2510.17482v3","title":"SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries","headline":"SparseWorld：基于稀疏动态查询的灵活高效4D Occupancy世界模型","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017482v3-sparseworld-a-flexible-adaptive-and-efficient-4d-occupancy-world-mod.html"},{"id":"2510.17157v1","title":"GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image","headline":"GACO-CAD：通过几何增强与简洁性优化，从单张图像生成CAD模型","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017157v1-gaco-cad-geometry-augmented-and-conciseness-optimized-cad-model-gene.html"},{"id":"2510.17777v1","title":"SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference","headline":"SparseVILA：解耦视觉稀疏性，加速高效VLM推理","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017777v1-sparsevila-decoupling-visual-sparsity-for-efficient-vlm-inference.html"},{"id":"2510.17700v1","title":"Elastic ViTs from Pretrained Models without Retraining","headline":"提出SnapViT，无需重训练即可从预训练ViT模型中获得弹性计算能力。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017700v1-elastic-vits-from-pretrained-models-without-retraining.html"},{"id":"2510.17617v1","title":"ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input","headline":"ImaGGen：基于语言和图像输入的零样本共语语义手势生成","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017617v1-imaggen-zero-shot-generation-of-co-speech-semantic-gestures-grounded.html"},{"id":"2510.17603v1","title":"ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling","headline":"ShapeCraft：利用LLM Agent生成结构化、纹理化和交互式3D模型","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017603v1-shapecraft-llm-agents-for-structured-textured-and-interactive-3d-mod.html"},{"id":"2510.17501v3","title":"Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization","headline":"提出一种上下文感知伪标签评分的零样本视频摘要框架，提升LLM在视频摘要任务中的性能。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017501v3-context-aware-pseudo-label-scoring-for-zero-shot-video-summarization.html"},{"id":"2510.17409v1","title":"Monitoring Horses in Stalls: From Object to Event Detection","headline":"提出基于YOLOv11和BoT-SORT的马厩马匹行为监测系统，实现事件自动检测。","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017409v1-monitoring-horses-in-stalls-from-object-to-event-detection.html"},{"id":"2510.17364v1","title":"Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs","headline":"提出基于循环注意力的Token选择方法，用于高效的流式视频-LLM","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017364v1-recurrent-attention-based-token-selection-for-efficient-streaming-vi.html"},{"id":"2510.17347v1","title":"Exploring The Missing Semantics In Event Modality","headline":"提出Semantic-E2VID，利用视觉语义知识增强事件到视频的重建效果","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017347v1-exploring-the-missing-semantics-in-event-modality.html"},{"id":"2510.18123v1","title":"SafeCoop: Unravelling Full Stack Safety in Agentic Collaborative Driving","headline":"SafeCoop：针对基于自然语言协同驾驶的全栈安全防御框架","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251018123v1-safecoop-unravelling-full-stack-safety-in-agentic-collaborative-driv.html"},{"id":"2510.17803v1","title":"ConsistEdit: Highly Consistent and Precise Training-free Visual Editing","headline":"ConsistEdit：提出一种高一致性和精确性的免训练视觉编辑方法","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017803v1-consistedit-highly-consistent-and-precise-training-free-visual-editi.html"},{"id":"2510.17519v2","title":"MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models","headline":"MUG-V 10B：面向大规模视频生成模型的高效训练框架","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017519v2-mug-v-10b-high-efficiency-training-pipeline-for-large-video-generati.html"},{"id":"2510.17422v2","title":"DeepDetect: Learning All-in-One Dense Keypoints","headline":"DeepDetect：提出一种融合经典检测器优势的端到端密集关键点检测方法","tag":"cs.CV","date":"2025-10-20","url":"cs-CV/2025-10-20/papers/251017422v2-deepdetect-learning-all-in-one-dense-keypoints.html"},{"id":"2510.17101v1","title":"Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors","headline":"提出SAIP，解决稀疏惯性传感器人体动作捕捉中体型差异泛化难题","tag":"cs.GR","date":"2025-10-20","url":"cs-GR/2025-10-20/papers/251017101v1-shape-aware-inertial-poser-motion-tracking-for-humans-with-diverse-s.html"},{"id":"2510.17394v1","title":"MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning","headline":"提出MILES：一种模态感知学习率调度器，用于平衡多模态学习。","tag":"cs.LG","date":"2025-10-20","url":"cs-LG/2025-10-20/papers/251017394v1-miles-modality-informed-learning-rate-scheduler-for-balancing-multim.html"},{"id":"2510.18082v1","title":"Provably Optimal Reinforcement Learning under Safety Filtering","headline":"提出安全过滤下的可证明最优强化学习方法，解决安全约束下的性能损失问题","tag":"cs.LG","date":"2025-10-20","url":"cs-LG/2025-10-20/papers/251018082v1-provably-optimal-reinforcement-learning-under-safety-filtering.html"},{"id":"2510.17991v1","title":"Demystifying Transition Matching: When and Why It Can Beat Flow Matching","headline":"揭示Transition Matching优势：在高斯分布及混合模型中超越Flow Matching","tag":"cs.LG","date":"2025-10-20","url":"cs-LG/2025-10-20/papers/251017991v1-demystifying-transition-matching-when-and-why-it-can-beat-flow-match.html"},{"id":"2510.17564v1","title":"An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning","headline":"研究安全强化学习中拉格朗日方法的λ敏感性与自动更新策略的鲁棒性。","tag":"cs.LG","date":"2025-10-20","url":"cs-LG/2025-10-20/papers/251017564v1-an-empirical-study-of-lagrangian-methods-in-safe-reinforcement-learn.html"},{"id":"2510.17590v1","title":"MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning","headline":"MIRAGE：利用Web检索推理的多模态信息检测Agent框架","tag":"cs.AI","date":"2025-10-20","url":"cs-AI/2025-10-20/papers/251017590v1-mirage-agentic-framework-for-multimodal-misinformation-detection-wit.html"},{"id":"2510.17771v1","title":"Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs","headline":"揭示视觉语言模型“视而不信”现象，提出无需训练的注意力干预方法","tag":"cs.AI","date":"2025-10-20","url":"cs-AI/2025-10-20/papers/251017771v1-seeing-but-not-believing-probing-the-disconnect-between-visual-atten.html"},{"id":"2510.17759v1","title":"VERA-V: Variational Inference Framework for Jailbreaking Vision-Language Models","headline":"提出VERA-V框架以解决多模态模型的漏洞发现问题","tag":"cs.CL","date":"2025-10-20","url":"cs-CL/2025-10-20/papers/251017759v1-vera-v-variational-inference-framework-for-jailbreaking-vision-langu.html"},{"id":"2510.17038v1","title":"DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation","headline":"DINO-CVA：用于自主导管导航的多模态目标条件视觉-动作模型","tag":"cs.RO","date":"2025-10-19","url":"cs-RO/2025-10-19/papers/251017038v1-dino-cva-a-multimodal-goal-conditioned-vision-to-action-model-for-au.html"},{"id":"2510.16755v1","title":"Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation","headline":"提出自适应不变扩展卡尔曼滤波，提升腿足机器人状态估计精度与鲁棒性","tag":"cs.RO","date":"2025-10-19","url":"cs-RO/2025-10-19/papers/251016755v1-adaptive-invariant-extended-kalman-filter-for-legged-robot-state-est.html"},{"id":"2510.16767v1","title":"T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic","headline":"提出T3 Planner，利用LLM和形式化方法实现机器人运动规划的自校正。","tag":"cs.RO","date":"2025-10-19","url":"cs-RO/2025-10-19/papers/251016767v1-t3-planner-a-self-correcting-llm-framework-for-robotic-motion-planni.html"},{"id":"2510.16931v2","title":"RAPID Hand Prototype: Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation","headline":"RAPID Hand：低成本、全驱动仿生手，用于灵巧遥操作","tag":"cs.RO","date":"2025-10-19","url":"cs-RO/2025-10-19/papers/251016931v2-rapid-hand-prototype-design-of-an-affordable-fully-actuated-biomimet.html"},{"id":"2510.16692v2","title":"First Responders' Perceptions of Semantic Information for Situational Awareness in Robot-Assisted Emergency Response","headline":"调研语义信息对机器人辅助应急响应中情境感知的影响","tag":"cs.RO","date":"2025-10-19","url":"cs-RO/2025-10-19/papers/251016692v2-first-responders-perceptions-of-semantic-information-for-situational.html"},{"id":"2510.16926v3","title":"Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input","headline":"提出Res-Bench，评估多模态大语言模型在动态分辨率输入下的鲁棒性","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016926v3-res-bench-benchmarking-the-robustness-of-multimodal-large-language-m.html"},{"id":"2510.16714v2","title":"SceneCOT: Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes","headline":"SceneCOT：提出3D场景中基于常识链的推理框架，提升具身问答性能","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016714v2-scenecot-eliciting-grounded-chain-of-thought-reasoning-in-3d-scenes.html"},{"id":"2510.16837v1","title":"2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting","headline":"2DGS-R：通过分层训练和原位克隆提升2D高斯溅射的渲染质量和几何精度","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016837v1-2dgs-r-revisiting-the-normal-consistency-regularization-in-2d-gaussi.html"},{"id":"2510.16777v1","title":"GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation","headline":"GS2POSE：结合高斯溅射的6D物体姿态估计方法","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016777v1-gs2pose-marry-gaussian-splatting-to-6d-object-pose-estimation.html"},{"id":"2510.16973v1","title":"Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis","headline":"综述性分析医学影像领域中的Foundation Model，系统性地归纳架构、训练范式和临床应用。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016973v1-foundation-models-in-medical-image-analysis-a-systematic-review-and-.html"},{"id":"2510.16732v2","title":"A Comprehensive Survey on World Models for Embodied AI","headline":"对具身智能中世界模型的全面综述，涵盖功能、时序建模和空间表示三个维度。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016732v2-a-comprehensive-survey-on-world-models-for-embodied-ai.html"},{"id":"2510.17023v1","title":"Enrich and Detect: Video Temporal Grounding with Multimodal LLMs","headline":"提出ED-VTG，利用多模态LLM进行细粒度视频时序定位","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251017023v1-enrich-and-detect-video-temporal-grounding-with-multimodal-llms.html"},{"id":"2510.16785v1","title":"Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs","headline":"LENS：为冻结多模态LLM提供即插即用的分割能力","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016785v1-segmentation-as-a-plug-and-play-capability-for-frozen-multimodal-llm.html"},{"id":"2510.16776v1","title":"EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation","headline":"EMRRG：高效微调预训练Mamba X射线网络，用于放射报告生成","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016776v1-emrrg-efficient-fine-tuning-pre-trained-x-ray-mamba-networks-for-rad.html"},{"id":"2510.17045v1","title":"Video Reasoning without Training","headline":"提出V-Reason，无需训练即可提升大模型在视频推理任务中的性能。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251017045v1-video-reasoning-without-training.html"},{"id":"2510.16888v3","title":"Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback","headline":"Uniworld-V2：利用扩散负感知微调和MLLM隐式反馈增强图像编辑能力","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016888v3-uniworld-v2-reinforce-image-editing-with-diffusion-negative-aware-fi.html"},{"id":"2510.16989v1","title":"Training-free Online Video Step Grounding","headline":"提出BaGLM，利用大模型零样本能力在线视频步骤定位，超越离线训练方法。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016989v1-training-free-online-video-step-grounding.html"},{"id":"2510.17034v1","title":"Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding","headline":"提出W2R2框架，解决视频LLM中3D grounding的2D语义偏见问题。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251017034v1-where-not-what-compelling-video-llms-to-learn-geometric-causality-fo.html"},{"id":"2510.16870v1","title":"Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding","headline":"通过fMRI神经编码揭示视觉-语言模型中类脑分层模式","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016870v1-uncovering-brain-like-hierarchical-patterns-in-vision-language-model.html"},{"id":"2510.21786v1","title":"EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction","headline":"提出EventFormer，用于解决动作中心视频事件预测任务，并构建大规模数据集AVEP。","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251021786v1-eventformer-a-node-graph-hierarchical-attention-transformer-for-acti.html"},{"id":"2510.17051v1","title":"How Universal Are SAM2 Features?","headline":"量化通用视觉模型与分割专用模型特征的泛化能力差异","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251017051v1-how-universal-are-sam2-features.html"},{"id":"2510.16709v2","title":"HumanCM: One Step Human Motion Prediction","headline":"提出HumanCM，一种基于一致性模型的人体运动单步预测框架","tag":"cs.CV","date":"2025-10-19","url":"cs-CV/2025-10-19/papers/251016709v2-humancm-one-step-human-motion-prediction.html"},{"id":"2510.17914v1","title":"NeuCo-Bench: A Novel Benchmark Framework for Neural Embeddings in Earth Observation","headline":"NeuCo-Bench：面向地球观测的神经嵌入评估基准框架，解决表征学习的标准化评估问题","tag":"cs.LG","date":"2025-10-19","url":"cs-LG/2025-10-19/papers/251017914v1-neuco-bench-a-novel-benchmark-framework-for-neural-embeddings-in-ear.html"},{"id":"2510.16877v1","title":"Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning","headline":"Fly-CL：受果蝇启发的持续表征学习框架，提升去相关性并加速训练。","tag":"cs.LG","date":"2025-10-19","url":"cs-LG/2025-10-19/papers/251016877v1-fly-cl-a-fly-inspired-framework-for-enhancing-efficient-decorrelatio.html"},{"id":"2510.16756v1","title":"End-to-end Listen, Look, Speak and Act","headline":"提出ELLSA，首个端到端全双工多模态模型，实现类人交互。","tag":"cs.AI","date":"2025-10-19","url":"cs-AI/2025-10-19/papers/251016756v1-end-to-end-listen-look-speak-and-act.html"},{"id":"2510.16953v1","title":"Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model Predictive Control Approach","headline":"提出基于鲁棒MPC的船载起重机安全有效载荷转移方法","tag":"eess.SY","date":"2025-10-19","url":"eess-SY/2025-10-19/papers/251016953v1-safe-payload-transfer-with-ship-mounted-cranes-a-robust-model-predic.html"},{"id":"2510.16518v1","title":"DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation","headline":"DIV-Nav：利用开放词汇空间关系进行多目标导航","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016518v1-div-nav-open-vocabulary-spatial-relationships-for-multi-object-navig.html"},{"id":"2510.16617v1","title":"MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation","headline":"MoS-VLA：基于技能组合的视觉-语言-动作模型，实现机器人单样本技能迁移","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016617v1-mos-vla-a-vision-language-action-model-with-one-shot-skill-adaptatio.html"},{"id":"2510.16281v1","title":"Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification","headline":"提出基于运行时推理-行动对齐验证的策略引导方法，提升VLA模型在机器人任务中的泛化性。","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016281v1-do-what-you-say-steering-vision-language-action-models-via-runtime-r.html"},{"id":"2510.16524v1","title":"Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping","headline":"提出SP-Diff平行夹爪系统，通过半反演连杆和差动机构实现线性夹取和自适应抓取。","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016524v1-semi-peaucellier-linkage-and-differential-mechanism-for-linear-pinch.html"},{"id":"2510.16435v1","title":"What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics","headline":"构建面向可解释机器人的用户问题数据集，助力提升人机交互能力","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016435v1-what-questions-should-robots-be-able-to-answer-a-dataset-of-user-que.html"},{"id":"2510.16308v1","title":"SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling","headline":"SPOT：基于障碍物威胁建模的感知增强无人机轨迹规划","tag":"cs.RO","date":"2025-10-18","url":"cs-RO/2025-10-18/papers/251016308v1-spot-sensing-augmented-trajectory-planning-via-obstacle-threat-model.html"},{"id":"2510.16442v1","title":"EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning","headline":"提出EDVD-LLaMA框架，通过多模态大语言模型推理实现可解释的Deepfake视频检测。","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016442v1-edvd-llama-explainable-deepfake-video-detection-via-multimodal-large.html"},{"id":"2510.16624v1","title":"Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs","headline":"提出一种基于语义分割和单目深度估计的低成本无人机自主飞行方法。","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016624v1-self-supervised-learning-to-fly-using-efficient-semantic-segmentatio.html"},{"id":"2510.16410v2","title":"REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting","headline":"提出REALM框架以解决复杂人类指令下的3D对象分割问题","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016410v2-realm-an-mllm-agent-framework-for-open-world-3d-reasoning-segmentati.html"},{"id":"2510.16598v1","title":"VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs","headline":"VisionSelector：端到端可学习的视觉Token压缩，提升多模态LLM效率","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016598v1-visionselector-end-to-end-learnable-visual-token-compression-for-eff.html"},{"id":"2510.16463v1","title":"HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars","headline":"提出HGC-Avatar，用于可流式传输的动态3D头像的高效高斯压缩。","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016463v1-hgc-avatar-hierarchical-gaussian-compression-for-streamable-dynamic-.html"},{"id":"2510.16660v1","title":"Universal and Transferable Attacks on Pathology Foundation Models","headline":"提出通用可迁移对抗扰动UTAP，揭示病理学基础模型的脆弱性","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016660v1-universal-and-transferable-attacks-on-pathology-foundation-models.html"},{"id":"2510.16505v2","title":"PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies","headline":"PRISMM-Bench：首个基于同行评审的多模态不一致性基准，用于评估LMMs的科学推理能力","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016505v2-prismm-bench-a-benchmark-of-peer-review-grounded-multimodal-inconsis.html"},{"id":"2510.16556v2","title":"Fit for Purpose? Deepfake Detection in the Real World","headline":"构建真实政治Deepfake基准，揭示现有检测器泛化能力不足","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016556v2-fit-for-purpose-deepfake-detection-in-the-real-world.html"},{"id":"2510.16416v1","title":"SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning","headline":"SSL4RL：利用自监督学习作为视觉-语言推理的内在奖励","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016416v1-ssl4rl-revisiting-self-supervised-learning-as-intrinsic-reward-for-v.html"},{"id":"2510.16664v1","title":"HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications","headline":"提出HYDRA，通过混合知识蒸馏和光谱重建算法实现高通道高光谱相机应用","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016664v1-hydra-hybrid-knowledge-distillation-and-spectral-reconstruction-algo.html"},{"id":"2510.16643v1","title":"Structured Interfaces for Automated Reasoning with 3D Scene Graphs","headline":"提出基于结构化接口的3D场景图推理方法，提升LLM在机器人自然语言理解中的性能。","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016643v1-structured-interfaces-for-automated-reasoning-with-3d-scene-graphs.html"},{"id":"2510.16450v1","title":"Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy","headline":"针对电子显微镜图像，提出实例感知伪标签和类别聚焦对比学习的弱监督域自适应分割方法","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016450v1-instance-aware-pseudo-labeling-and-class-focused-contrastive-learnin.html"},{"id":"2510.16444v1","title":"RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba","headline":"RefAtomNet++：利用语义检索的多轨迹Mamba推进指代表达式原子视频动作识别","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016444v1-refatomnet-advancing-referring-atomic-video-action-recognition-using.html"},{"id":"2510.16333v1","title":"RL makes MLLMs see better than SFT","headline":"提出PIVOT，利用强化学习优化MLLM视觉编码器，显著提升视觉感知能力","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016333v1-rl-makes-mllms-see-better-than-sft.html"},{"id":"2510.16457v1","title":"NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation","headline":"NavQ：学习Q模型以实现具有前瞻性的视觉-语言导航","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016457v1-navq-learning-a-q-model-for-foresighted-vision-and-language-navigati.html"},{"id":"2510.16446v1","title":"VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion","headline":"VIPAMIN：通过嵌入选择和子空间扩展实现视觉Prompt初始化，提升自监督模型在下游任务的性能。","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016446v1-vipamin-visual-prompt-initialization-via-embedding-selection-and-sub.html"},{"id":"2510.16290v1","title":"Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models","headline":"Cerberus：基于级联视觉-语言模型的实时视频异常检测系统","tag":"cs.CV","date":"2025-10-18","url":"cs-CV/2025-10-18/papers/251016290v1-cerberus-real-time-video-anomaly-detection-via-cascaded-vision-langu.html"},{"id":"2510.16376v1","title":"Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization","headline":"提出基于反馈的保形预测框架，用于轨迹优化中的不确定性建模与风险控制","tag":"cs.AI","date":"2025-10-18","url":"cs-AI/2025-10-18/papers/251016376v1-conformal-prediction-in-the-loop-a-feedback-based-uncertainty-model-.html"},{"id":"2510.15626v2","title":"Adaptive Legged Locomotion via Online Learning for Model Predictive Control","headline":"提出基于在线学习的自适应腿足机器人运动控制算法，应对未知扰动。","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015626v2-adaptive-legged-locomotion-via-online-learning-for-model-predictive-.html"},{"id":"2510.15446v1","title":"VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving","headline":"VDRive：利用强化VLA和扩散策略实现端到端自动驾驶","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015446v1-vdrive-leveraging-reinforced-vla-and-diffusion-policy-for-end-to-end.html"},{"id":"2510.21773v2","title":"Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots","headline":"针对腿足机器人，对实时二次规划求解器进行综述与实践指导","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251021773v2-real-time-qp-solvers-a-concise-review-and-practical-guide-towards-le.html"},{"id":"2510.15530v4","title":"VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation","headline":"提出VO-DP：一种基于视觉的语义-几何自适应扩散策略，用于机器人操作","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015530v4-vo-dp-semantic-geometric-adaptive-diffusion-policy-for-vision-only-r.html"},{"id":"2510.15786v2","title":"DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation","headline":"DexCanvas：桥接人类演示与机器人学习的灵巧操作数据集","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015786v2-dexcanvas-bridging-human-demonstrations-and-robot-learning-for-dexte.html"},{"id":"2510.16240v2","title":"Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning","headline":"Cosmos-Surg-dVRK：基于世界基础模型的机器人手术策略在线自动评估","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251016240v2-cosmos-surg-dvrk-world-foundation-model-based-automated-online-evalu.html"},{"id":"2510.16263v2","title":"NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?","headline":"NEBULA：用于诊断和可复现评估VLA智能体的统一生态系统","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251016263v2-nebula-do-we-evaluate-vision-language-action-agents-correctly.html"},{"id":"2510.15352v1","title":"GaussGym: An open-source real-to-sim framework for learning locomotion from pixels","headline":"GaussGym：一种基于像素学习机器人运动的开源实-虚框架","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015352v1-gaussgym-an-open-source-real-to-sim-framework-for-learning-locomotio.html"},{"id":"2510.15679v1","title":"HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward","headline":"HEADER：基于注意力深度强化学习和专家引导奖励的分层机器人探索方法","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015679v1-header-hierarchical-robot-exploration-via-attention-based-deep-reinf.html"},{"id":"2510.21771v1","title":"Improving the performance of AI-powered Affordable Robotics for Assistive Tasks","headline":"提出基于模仿学习的低成本机器人臂，用于辅助任务并显著提升性能。","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251021771v1-improving-the-performance-of-ai-powered-affordable-robotics-for-assi.html"},{"id":"2510.15639v1","title":"Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation","headline":"集成变刚度连接件，实现长臂空中操作的灵活性与精确性","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015639v1-integration-of-a-variable-stiffness-link-for-long-reach-aerial-manip.html"},{"id":"2510.15220v1","title":"LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization","headline":"提出LVI-Q：一种鲁棒的激光雷达-视觉-惯性-运动学里程计，用于四足机器人。","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015220v1-lvi-q-robust-lidar-visual-inertial-kinematic-odometry-for-quadruped-.html"},{"id":"2510.15319v1","title":"Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping","headline":"提出可通行性感知的场景图构建方法，提升室内定位与地图构建一致性。","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015319v1-traversability-aware-consistent-situational-graphs-for-indoor-locali.html"},{"id":"2510.15376v1","title":"Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting","headline":"提出基于学习的动态自适应六自由度多材质切割方法，实现自动化鸡肩剔骨","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251015376v1-towards-automated-chicken-deboning-via-learning-based-dynamically-ad.html"},{"id":"2510.16205v1","title":"VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments","headline":"VAR-SLAM：面向动态环境的视觉自适应鲁棒SLAM","tag":"cs.RO","date":"2025-10-17","url":"cs-RO/2025-10-17/papers/251016205v1-var-slam-visual-adaptive-and-robust-slam-for-dynamic-environments.html"},{"id":"2510.15386v1","title":"PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction","headline":"提出PFGS，通过姿态融合3D高斯溅射实现完整的多姿态物体重建","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015386v1-pfgs-pose-fused-3d-gaussian-splatting-for-complete-multi-pose-object.html"},{"id":"2510.15398v2","title":"MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment","headline":"提出MARIS水下开放词汇实例分割基准，并设计GPEM和SAIM模块提升分割性能。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015398v2-maris-marine-open-vocabulary-instance-segmentation-with-geometric-en.html"},{"id":"2510.16258v1","title":"Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset","headline":"Meta发布Embody 3D：大规模多模态人体运动与行为数据集","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251016258v1-embody-3d-a-large-scale-multimodal-motion-and-behavior-dataset.html"},{"id":"2510.21769v1","title":"H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows","headline":"H2OFlow：利用3D生成模型和稠密扩散流学习人-物交互行为","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251021769v1-h2oflow-grounding-human-object-affordances-with-3d-generative-models.html"},{"id":"2510.15857v1","title":"BLIP3o-NEXT: Next Frontier of Native Image Generation","headline":"BLIP3o-NEXT：原生图像生成的新前沿，统一文本到图像生成与图像编辑","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015857v1-blip3o-next-next-frontier-of-native-image-generation.html"},{"id":"2510.15710v2","title":"UniMedVL: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis","headline":"提出UniMedVL，统一医学多模态理解与生成，提升医疗诊断应用性能。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015710v2-unimedvl-unifying-medical-multimodal-understanding-and-generation-th.html"},{"id":"2510.15304v1","title":"Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation","headline":"提出CoMe：通过层拼接压缩大语言模型，在显著剪枝的同时保持性能。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015304v1-layer-as-puzzle-pieces-compressing-large-language-models-through-lay.html"},{"id":"2510.16220v1","title":"VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction","headline":"VM-BeautyNet：融合Vision Transformer与Mamba的面部美学预测模型","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251016220v1-vm-beautynet-a-synergistic-ensemble-of-vision-transformer-and-mamba-.html"},{"id":"2510.15684v1","title":"Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI","headline":"提出基于多模态MRI的无监督脑肿瘤分割方法，解决标注数据稀缺问题。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015684v1-towards-label-free-brain-tumor-segmentation-unsupervised-learning-wi.html"},{"id":"2510.15371v1","title":"Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding","headline":"提出Cortical-SSM，利用深度状态空间模型解码脑电和皮层脑电运动想象信号","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015371v1-cortical-ssm-a-deep-state-space-model-for-eeg-and-ecog-motor-imagery.html"},{"id":"2510.16272v1","title":"Proactive Scene Decomposition and Reconstruction","headline":"提出主动场景分解与重建方法，利用人机交互动态优化场景理解。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251016272v1-proactive-scene-decomposition-and-reconstruction.html"},{"id":"2510.16209v1","title":"StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales","headline":"StretchySnake：灵活的SSM训练解锁跨时空尺度的动作识别","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251016209v1-stretchysnake-flexible-ssm-training-unlocks-action-recognition-acros.html"},{"id":"2510.15564v1","title":"Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation","headline":"Imaginarium：提出视觉引导的高质量3D场景布局生成方法，提升场景丰富度和质量。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015564v1-imaginarium-vision-guided-high-quality-3d-scene-layout-generation.html"},{"id":"2510.15471v1","title":"A Novel Combined Optical Flow Approach for Comprehensive Micro-Expression Recognition","headline":"提出结合起始到峰值与峰值到结束阶段光流的微表情识别方法","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015471v1-a-novel-combined-optical-flow-approach-for-comprehensive-micro-expre.html"},{"id":"2510.16134v1","title":"Aria Gen 2 Pilot Dataset","headline":"发布Aria Gen 2 Pilot Dataset，用于可穿戴设备的第一人称视角多模态感知研究","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251016134v1-aria-gen-2-pilot-dataset.html"},{"id":"2510.15264v1","title":"DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion","headline":"DriveGen3D：通过高效视频扩散加速前馈式驾驶场景生成","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015264v1-drivegen3d-boosting-feed-forward-driving-scene-generation-with-effic.html"},{"id":"2510.15742v1","title":"Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset","headline":"提出Ditto框架，通过高质量合成数据集Editto-1M，显著提升指令驱动的视频编辑能力。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015742v1-scaling-instruction-based-video-editing-with-a-high-quality-syntheti.html"},{"id":"2510.15440v1","title":"Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning","headline":"提出基于证据优先的自适应框架EARL，解决视频LLM长视频推理中信息稀释问题。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015440v1-select-less-reason-more-prioritizing-evidence-purity-for-video-reaso.html"},{"id":"2510.15841v1","title":"Neuro-Symbolic Spatial Reasoning in Segmentation","headline":"提出RelateSeg，通过神经符号空间推理提升开放词汇语义分割性能","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015841v1-neuro-symbolic-spatial-reasoning-in-segmentation.html"},{"id":"2510.15467v1","title":"MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes","headline":"MRASfM：提出多相机SfM框架，解决自动驾驶场景重建难题。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015467v1-mrasfm-multi-camera-reconstruction-and-aggregation-through-structure.html"},{"id":"2510.15775v1","title":"SANR: Scene-Aware Neural Representation for Light Field Image Compression with Rate-Distortion Optimization","headline":"提出SANR：一种场景感知神经表示光场图像压缩框架，实现率失真优化。","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015775v1-sanr-scene-aware-neural-representation-for-light-field-image-compres.html"},{"id":"2510.15725v1","title":"DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification","headline":"提出DGME-T，通过方向网格运动编码增强Transformer在历史影像镜头运动分类中的鲁棒性","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015725v1-dgme-t-directional-grid-motion-encoding-for-transformer-based-histor.html"},{"id":"2510.15392v1","title":"LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding","headline":"LILAC：基于流式VAE-Diffusion和因果解码的长序列增量低延迟任意动作风格化","tag":"cs.CV","date":"2025-10-17","url":"cs-CV/2025-10-17/papers/251015392v1-lilac-long-sequence-incremental-low-latency-arbitrary-motion-styliza.html"},{"id":"2510.15736v1","title":"Fix False Transparency by Noise Guided Splatting","headline":"提出噪声引导Splatting，解决3DGS重建中虚假透明问题","tag":"cs.GR","date":"2025-10-17","url":"cs-GR/2025-10-17/papers/251015736v1-fix-false-transparency-by-noise-guided-splatting.html"},{"id":"2510.16147v1","title":"Procedural Scene Programs for Open-Universe Scene Generation: LLM-Free Error Correction via Program Search","headline":"提出基于程序搜索的场景程序生成方法，无需LLM即可进行错误校正，用于开放域场景生成。","tag":"cs.GR","date":"2025-10-17","url":"cs-GR/2025-10-17/papers/251016147v1-procedural-scene-programs-for-open-universe-scene-generation-llm-fre.html"},{"id":"2510.15382v2","title":"Towards Robust Zero-Shot Reinforcement Learning","headline":"提出BREEZE框架，增强零样本强化学习的鲁棒性和泛化能力","tag":"cs.LG","date":"2025-10-17","url":"cs-LG/2025-10-17/papers/251015382v2-towards-robust-zero-shot-reinforcement-learning.html"},{"id":"2510.15202v2","title":"Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection","headline":"提出径向缩放的ℓ2归一化以提升OOD检测性能","tag":"cs.LG","date":"2025-10-17","url":"cs-LG/2025-10-17/papers/251015202v2-dissecting-mahalanobis-how-feature-geometry-and-normalization-shape-.html"},{"id":"2510.16187v1","title":"Zero-Shot Coordination in Ad Hoc Teams with Generalized Policy Improvement and Difference Rewards","headline":"提出GPAT算法，利用广义策略提升和差异奖励实现Ad Hoc团队零样本协作","tag":"cs.AI","date":"2025-10-17","url":"cs-AI/2025-10-17/papers/251016187v1-zero-shot-coordination-in-ad-hoc-teams-with-generalized-policy-impro.html"},{"id":"2510.15253v1","title":"Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding","headline":"多模态RAG综述：提升文档理解能力，超越上下文限制","tag":"cs.CL","date":"2025-10-17","url":"cs-CL/2025-10-17/papers/251015253v1-scaling-beyond-context-a-survey-of-multimodal-retrieval-augmented-ge.html"},{"id":"2510.15842v1","title":"Paper2Web: Let's Make Your Paper Alive!","headline":"Paper2Web：提出学术网页自动生成框架PWAgent，提升论文传播效果","tag":"cs.CL","date":"2025-10-17","url":"cs-CL/2025-10-17/papers/251015842v1-paper2web-lets-make-your-paper-alive.html"},{"id":"2510.14952v2","title":"From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance","headline":"RoboGhost：提出一种无重定向的语言引导人形机器人运动控制框架","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014952v2-from-language-to-locomotion-retargeting-free-humanoid-control-via-mo.html"},{"id":"2510.14902v1","title":"VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation","headline":"VLA^2：利用Agent框架增强VLA模型处理未见概念操作的能力","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014902v1-vla2-empowering-vision-language-action-models-with-an-agentic-framew.html"},{"id":"2510.14771v1","title":"Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation","headline":"Open TeleDex：一个硬件无关的灵巧操作模仿学习遥操作系统","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014771v1-open-teledex-a-hardware-agnostic-teleoperation-system-for-imitation-.html"},{"id":"2510.14454v1","title":"Towards Adaptable Humanoid Control via Adaptive Motion Tracking","headline":"AdaMimic：基于自适应运动跟踪的通用人形机器人控制方法","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014454v1-towards-adaptable-humanoid-control-via-adaptive-motion-tracking.html"},{"id":"2510.14947v2","title":"Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion","headline":"提出分层控制架构，提升人形机器人复杂地形的鲁棒运动性能","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014947v2-architecture-is-all-you-need-diversity-enabled-sweet-spots-for-robus.html"},{"id":"2510.14643v1","title":"Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation","headline":"提出生成预测控制框架以提升接触丰富操作的采样效率","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014643v1-generative-models-from-and-for-sampling-based-mpc-a-bootstrapped-app.html"},{"id":"2510.14338v1","title":"Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion","headline":"提出基于Bandit自适应的风险感知强化学习，提升四足机器人运动鲁棒性","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014338v1-risk-aware-reinforcement-learning-with-bandit-based-adaptation-for-q.html"},{"id":"2510.14647v1","title":"Spatially anchored Tactile Awareness for Robust Dexterous Manipulation","headline":"提出SaTA框架，通过空间锚定的触觉感知实现鲁棒的灵巧操作","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014647v1-spatially-anchored-tactile-awareness-for-robust-dexterous-manipulati.html"},{"id":"2510.15189v1","title":"RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation","headline":"RM-RL：面向精准机器人操作的角色模型强化学习","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251015189v1-rm-rl-role-model-reinforcement-learning-for-precise-robot-manipulati.html"},{"id":"2510.14783v1","title":"SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning","headline":"SkyDreamer：基于模型强化学习的可解释端到端视觉无人机竞速","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014783v1-skydreamer-interpretable-end-to-end-vision-based-drone-racing-with-m.html"},{"id":"2510.14300v1","title":"Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning","headline":"提出AdaMoE，一种动作专用混合专家模型，提升VLA模型在机器人操作任务中的性能和效率。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014300v1-expertise-need-not-monopolize-action-specialized-mixture-of-experts-.html"},{"id":"2510.14830v3","title":"RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning","headline":"RL-100：基于真实世界强化学习的高性能机器人操作框架","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014830v3-rl-100-performant-robotic-manipulation-with-real-world-reinforcement.html"},{"id":"2510.14768v1","title":"Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery","headline":"提出CADRE框架，利用神经描述场学习接触感知的动态恢复，提升灵巧操作的鲁棒性。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014768v1-leveraging-neural-descriptor-fields-for-learning-contact-aware-dynam.html"},{"id":"2510.14930v2","title":"VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tuning","headline":"VT-Refine：通过模拟微调学习基于视觉-触觉反馈的双臂装配","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014930v2-vt-refine-learning-bimanual-assembly-with-visuo-tactile-feedback-via.html"},{"id":"2510.14959v2","title":"CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions","headline":"提出CBF-RL框架，通过控制屏障函数在训练中安全过滤强化学习策略","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014959v2-cbf-rl-safety-filtering-reinforcement-learning-in-training-with-cont.html"},{"id":"2510.14467v1","title":"Restoring Noisy Demonstration for Imitation Learning With Diffusion Models","headline":"提出基于扩散模型的模仿学习框架，用于恢复含噪声的专家演示数据。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014467v1-restoring-noisy-demonstration-for-imitation-learning-with-diffusion-.html"},{"id":"2510.23615v1","title":"Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning","headline":"提出基于逻辑的任务表示和奖励塑造方法，加速多智能体强化学习。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251023615v1-logic-based-task-representation-and-reward-shaping-in-multiagent-rei.html"},{"id":"2510.14612v1","title":"Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning","headline":"提出一种基于本体感受图像的四足机器人接触估计学习方法","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014612v1-proprioceptive-image-an-image-representation-of-proprioceptive-data-.html"},{"id":"2510.14511v2","title":"Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots","headline":"针对时延触觉人机交互，提出机器人调解下的稳定性判据","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014511v2-stability-criteria-and-motor-performance-in-delayed-haptic-dyadic-in.html"},{"id":"2510.14293v1","title":"Learning Human-Humanoid Coordination for Collaborative Object Carrying","headline":"提出COLA算法，实现基于本体感觉的人形机器人协同搬运，提升人机协作效率。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014293v1-learning-human-humanoid-coordination-for-collaborative-object-carryi.html"},{"id":"2510.14946v1","title":"EdgeNavMamba: Mamba Optimized Object Detection for Energy Efficient Edge Devices","headline":"EdgeNavMamba：面向边缘设备的节能Mamba优化目标检测","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014946v1-edgenavmamba-mamba-optimized-object-detection-for-energy-efficient-e.html"},{"id":"2510.14615v1","title":"Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models","headline":"提出CAMPD，利用上下文条件扩散模型加速多模态运动规划，提升泛化性。","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014615v1-accelerated-multi-modal-motion-planning-using-context-conditioned-di.html"},{"id":"2510.14546v1","title":"QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps","headline":"QuASH：利用自然语言启发式方法查询视觉-语言机器人地图","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014546v1-quash-using-natural-language-heuristics-to-query-visual-language-rob.html"},{"id":"2510.14234v1","title":"Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space","headline":"提出一种基于空间潜在空间的柔性物体操作预定性能控制方法","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014234v1-prescribed-performance-control-of-deformable-object-manipulation-in-.html"},{"id":"2510.14968v1","title":"RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks","headline":"提出RDD：一种基于检索的分解器，用于长时任务中规划器对齐","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014968v1-rdd-retrieval-based-demonstration-decomposer-for-planner-alignment-i.html"},{"id":"2510.14627v2","title":"GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement","headline":"GOPLA：通过合成增强人类布置数据，学习可泛化的物体放置","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014627v2-gopla-generalizable-object-placement-learning-via-synthetic-augmenta.html"},{"id":"2510.14851v1","title":"SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time","headline":"SADCHER：基于注意力机制的异构多机器人实时动态联盟调度","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014851v1-sadcher-scheduling-using-attention-based-dynamic-coalitions-of-heter.html"},{"id":"2510.14357v1","title":"SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation","headline":"提出SUM-AgriVLN，利用空间记忆提升农业视觉语言导航性能","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014357v1-sum-agrivln-spatial-understanding-memory-for-agricultural-vision-and.html"},{"id":"2510.14584v1","title":"A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning","headline":"提出一种广义可放置性指标，用于无模型统一抓取放置推理","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014584v1-a-generalized-placeability-metric-for-model-free-unified-pick-and-pl.html"},{"id":"2510.14677v1","title":"When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks","headline":"引入SMART智能体，提升nuPlan自动驾驶规划器评估的真实性和可靠性","tag":"cs.RO","date":"2025-10-16","url":"cs-RO/2025-10-16/papers/251014677v1-when-planners-meet-reality-how-learned-reactive-traffic-agents-shift.html"},{"id":"2510.14958v1","title":"MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning","headline":"MathCanvas：用于多模态数学推理的内在视觉思维链","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014958v1-mathcanvas-intrinsic-visual-chain-of-thought-for-multimodal-mathemat.html"},{"id":"2510.14836v1","title":"QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models","headline":"QDepth-VLA：利用量化深度预测辅助视觉-语言-动作模型，提升空间感知能力","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014836v1-qdepth-vla-quantized-depth-prediction-as-auxiliary-supervision-for-v.html"},{"id":"2510.14792v1","title":"CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection","headline":"提出CoT-PL框架，通过视觉链式推理和伪标签提升开放词汇目标检测在复杂场景下的性能。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014792v1-cot-pl-visual-chain-of-thought-reasoning-meets-pseudo-labeling-for-o.html"},{"id":"2510.14349v3","title":"Vision-Centric Activation and Coordination for Multimodal Large Language Models","headline":"提出VaCo，通过视觉中心激活与协调提升多模态大语言模型的视觉理解能力","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014349v3-vision-centric-activation-and-coordination-for-multimodal-large-lang.html"},{"id":"2510.14270v3","title":"GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering","headline":"GauSSmart：融合2D基础模型与几何滤波增强3D高斯溅射重建","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014270v3-gaussmart-enhanced-3d-reconstruction-through-2d-foundation-models-an.html"},{"id":"2510.16036v1","title":"IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection","headline":"提出IAD-GPT，利用多模态大语言模型提升工业异常检测的视觉知识。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251016036v1-iad-gpt-advancing-visual-knowledge-in-multimodal-large-language-mode.html"},{"id":"2510.14954v1","title":"OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression","headline":"OmniMotion：提出连续掩码自回归Transformer，用于多模态全身人体运动生成。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014954v1-omnimotion-multimodal-motion-generation-with-continuous-masked-autor.html"},{"id":"2510.14564v1","title":"BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU","headline":"BalanceGS：面向GPU的3D高斯溅射高效训练的算法-系统协同设计","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014564v1-balancegs-algorithm-system-co-design-for-efficient-3d-gaussian-splat.html"},{"id":"2510.14885v2","title":"You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction","headline":"提出nlg2choice方法，提升多模态大语言模型在细粒度视觉识别中的分类与检索能力。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014885v2-you-may-speak-freely-improving-the-fine-grained-visual-recognition-c.html"},{"id":"2510.14866v1","title":"Benchmarking Multimodal Large Language Models for Face Recognition","headline":"系统性评测多模态大语言模型在人脸识别任务上的性能表现。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014866v1-benchmarking-multimodal-large-language-models-for-face-recognition.html"},{"id":"2510.14668v2","title":"WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging","headline":"提出WeCKD：一种弱监督链式蒸馏网络，用于高效多模态医学影像分析。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014668v2-weckd-weakly-supervised-chained-distillation-network-for-efficient-m.html"},{"id":"2510.15162v1","title":"Train a Unified Multimodal Data Quality Classifier with Synthetic Data","headline":"提出UniFilter：一种基于合成数据的统一多模态数据质量分类器","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015162v1-train-a-unified-multimodal-data-quality-classifier-with-synthetic-da.html"},{"id":"2510.14896v1","title":"Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection","headline":"提出基于多模态LLM描述的半监督视频异常检测框架，提升复杂异常检测能力和可解释性。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014896v1-leveraging-multimodal-llm-descriptions-of-activity-for-explainable-s.html"},{"id":"2510.14605v2","title":"Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering","headline":"提出Wiki-PRF框架，解决知识库VQA中多模态查询质量和检索结果相关性问题","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014605v2-knowledge-based-visual-question-answer-with-multimodal-processing-re.html"},{"id":"2510.15072v1","title":"SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images","headline":"SaLon3R：结构感知的长期通用3D重建，解决冗余和几何不一致问题","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015072v1-salon3r-structure-aware-long-term-generalizable-3d-reconstruction-fr.html"},{"id":"2510.14819v2","title":"Capturing Context-Aware Route Choice Semantics for Trajectory Representation Learning","headline":"提出CORE框架，融合上下文感知的路径选择语义，提升轨迹表示学习效果","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014819v2-capturing-context-aware-route-choice-semantics-for-trajectory-repres.html"},{"id":"2510.14965v1","title":"ChangingGrounding: 3D Visual Grounding in Changing Scenes","headline":"提出ChangingGrounding基准与Mem-ChangingGrounder方法，解决动态场景下的3D视觉定位问题","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014965v1-changinggrounding-3d-visual-grounding-in-changing-scenes.html"},{"id":"2510.14672v1","title":"VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning","headline":"VTimeCoT：通过绘制视频进度条进行视频时序定位与推理","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014672v1-vtimecot-thinking-by-drawing-for-video-temporal-grounding-and-reason.html"},{"id":"2510.14532v1","title":"Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology","headline":"提出DentVFM：用于口腔颌面放射学的通用视觉基础模型","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014532v1-towards-generalist-intelligence-in-dentistry-vision-foundation-model.html"},{"id":"2510.14203v1","title":"Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition","headline":"提出Big Five和HEXACO联合建模方法，用于多模态表观人格特质识别","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014203v1-joint-modeling-of-big-five-and-hexaco-for-multimodal-apparent-person.html"},{"id":"2510.14705v1","title":"Leveraging Learned Image Prior for 3D Gaussian Compression","headline":"利用图像先验知识提升3D高斯压缩率与渲染质量","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014705v1-leveraging-learned-image-prior-for-3d-gaussian-compression.html"},{"id":"2510.15050v1","title":"Directional Reasoning Injection for Fine-Tuning MLLMs","headline":"提出DRIFT，通过梯度空间注入方向性推理知识，高效微调多模态大语言模型","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015050v1-directional-reasoning-injection-for-fine-tuning-mllms.html"},{"id":"2510.15040v1","title":"Composition-Grounded Instruction Synthesis for Visual Reasoning","headline":"提出COGS框架以提升多模态大语言模型的推理能力","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015040v1-composition-grounded-instruction-synthesis-for-visual-reasoning.html"},{"id":"2510.14374v1","title":"Spatial Preference Rewarding for MLLMs Spatial Understanding","headline":"提出空间偏好奖励SPR，提升MLLM在细粒度空间理解上的能力","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014374v1-spatial-preference-rewarding-for-mllms-spatial-understanding.html"},{"id":"2510.14955v2","title":"RealDPO: Real or Not Real, that is the Preference","headline":"RealDPO：利用真实数据偏好学习，提升视频生成模型运动真实性","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014955v2-realdpo-real-or-not-real-that-is-the-preference.html"},{"id":"2510.15018v1","title":"UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos","headline":"UrbanVerse：通过城市漫游视频扩展城市模拟规模，用于具身智能体训练。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015018v1-urbanverse-scaling-urban-simulation-by-watching-city-tour-videos.html"},{"id":"2510.14977v1","title":"Terra: Explorable Native 3D World Model with Point Latents","headline":"Terra：基于点潜变量的可探索原生3D世界模型","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014977v1-terra-explorable-native-3d-world-model-with-point-latents.html"},{"id":"2510.14661v1","title":"EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)","headline":"EuroMineNet：欧盟多时相Sentinel-2矿区时空足迹分析基准数据集","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014661v1-eurominenet-a-multitemporal-sentinel-2-benchmark-for-spatiotemporal-.html"},{"id":"2510.14383v2","title":"DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights","headline":"提出DRBD-Mamba模型，用于鲁棒高效的脑肿瘤分割，并提供分析性见解","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014383v2-drbd-mamba-for-robust-and-efficient-brain-tumor-segmentation-with-an.html"},{"id":"2510.14874v1","title":"TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions","headline":"提出TOUCH框架，实现文本引导的可控自由手部-物体交互生成。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014874v1-touch-text-guided-controllable-generation-of-free-form-hand-object-i.html"},{"id":"2510.15041v1","title":"Generalized Dynamics Generation towards Scannable Physical World Model","headline":"GDGen：基于势能的通用动力学生成框架，用于可扫描物理世界建模","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015041v1-generalized-dynamics-generation-towards-scannable-physical-world-mod.html"},{"id":"2510.14516v2","title":"Vision Mamba for Permeability Prediction of Porous Media","headline":"提出基于Vision Mamba的多孔介质渗透率预测模型，提升计算效率和内存利用率。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014516v2-vision-mamba-for-permeability-prediction-of-porous-media.html"},{"id":"2510.14256v2","title":"Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning","headline":"提出Identity-GRPO，通过强化学习优化多人视频生成中的身份保持问题。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014256v2-identity-grpo-optimizing-multi-human-identity-preserving-video-gener.html"},{"id":"2510.14960v1","title":"C4D: 4D Made from 3D through Dual Correspondences","headline":"C4D：通过双重对应关系从3D重建4D动态场景","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014960v1-c4d-4d-made-from-3d-through-dual-correspondences.html"},{"id":"2510.14179v1","title":"Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures","headline":"提出基于多视角表演捕捉的视频扩散模型定制框架，实现相机可控和角色一致性。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014179v1-virtually-being-customizing-camera-controllable-video-diffusion-mode.html"},{"id":"2510.14862v1","title":"Multi-modal video data-pipelines for machine learning with minimal human supervision","headline":"提出一种基于弱监督多模态视频数据管道的机器学习方法","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014862v1-multi-modal-video-data-pipelines-for-machine-learning-with-minimal-h.html"},{"id":"2510.15026v1","title":"MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning","headline":"MOBIUS：通过多模态瓶颈融合与校准解码器剪枝实现Big-to-Mobile通用实例分割","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015026v1-mobius-big-to-mobile-universal-instance-segmentation-via-multi-modal.html"},{"id":"2510.14904v2","title":"MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos","headline":"提出MaskCaptioner，通过联合学习分割和描述视频中的物体轨迹，实现端到端的密集视频物体描述。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014904v2-maskcaptioner-learning-to-jointly-segment-and-caption-object-traject.html"},{"id":"2510.14741v2","title":"DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models","headline":"DEXTER：利用扩散模型和文本推理实现视觉模型的可解释性，无需数据。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014741v2-dexter-diffusion-guided-explanations-with-textual-reasoning-for-visi.html"},{"id":"2510.14657v2","title":"Decorrelation Speeds Up Vision Transformers","headline":"提出DBP-MAE加速ViT预训练，降低计算成本和碳排放，提升下游任务性能。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014657v2-decorrelation-speeds-up-vision-transformers.html"},{"id":"2510.14648v1","title":"In-Context Learning with Unpaired Clips for Instruction-based Video Editing","headline":"提出基于非配对视频片段的上下文学习方法，用于指令驱动的视频编辑。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014648v1-in-context-learning-with-unpaired-clips-for-instruction-based-video-.html"},{"id":"2510.14624v1","title":"Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference","headline":"提出高效视频采样EVS，通过剪枝时序冗余token加速VLM推理。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014624v1-efficient-video-sampling-pruning-temporally-redundant-tokens-for-fas.html"},{"id":"2510.14304v1","title":"Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding","headline":"提出基于水印的三层对比解码方法，提升视觉-语言模型的事实性和视觉 grounding。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014304v1-watermarking-for-factuality-guiding-vision-language-models-toward-tr.html"},{"id":"2510.14427v1","title":"Deep Compositional Phase Diffusion for Long Motion Sequence Generation","headline":"提出组合相位扩散方法，解决长运动序列生成中片段衔接不流畅问题。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014427v1-deep-compositional-phase-diffusion-for-long-motion-sequence-generati.html"},{"id":"2510.15060v1","title":"A solution to generalized learning from small training sets found in everyday infant experiences","headline":"分析婴儿视觉经验的“块状”相似性，提升小样本学习泛化能力","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251015060v1-a-solution-to-generalized-learning-from-small-training-sets-found-in.html"},{"id":"2510.14588v2","title":"STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding","headline":"STANCE：通过稀疏到稠密锚定编码实现运动连贯的视频生成","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014588v2-stance-motion-coherent-video-generation-via-sparse-to-dense-anchored.html"},{"id":"2510.14245v1","title":"Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication","headline":"提出事件间隔调制(EIM)方案，提升事件相机光通信的传输速率。","tag":"cs.CV","date":"2025-10-16","url":"cs-CV/2025-10-16/papers/251014245v1-event-interval-modulation-a-novel-scheme-for-event-based-optical-cam.html"},{"id":"2510.14974v2","title":"pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation","headline":"提出π-Flow以解决少步生成模型的质量与多样性权衡问题","tag":"cs.LG","date":"2025-10-16","url":"cs-LG/2025-10-16/papers/251014974v2-pi-flow-policy-based-few-step-generation-via-imitation-distillation.html"},{"id":"2510.14845v1","title":"Backdoor Unlearning by Linear Task Decomposition","headline":"提出基于线性任务分解的后门攻击解学习方法，有效移除模型后门并保持模型性能。","tag":"cs.LG","date":"2025-10-16","url":"cs-LG/2025-10-16/papers/251014845v1-backdoor-unlearning-by-linear-task-decomposition.html"},{"id":"2510.14980v2","title":"Agentic Design of Compositional Machines","headline":"提出基于LLM智能体的组合机器设计方法，并构建BesiegeField测试平台。","tag":"cs.AI","date":"2025-10-16","url":"cs-AI/2025-10-16/papers/251014980v2-agentic-design-of-compositional-machines.html"},{"id":"2510.14828v2","title":"RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning","headline":"RoboGPT-R1：强化学习增强机器人规划能力，提升长时程操作任务性能","tag":"cs.AI","date":"2025-10-16","url":"cs-AI/2025-10-16/papers/251014828v2-robogpt-r1-enhancing-robot-planning-with-reinforcement-learning.html"},{"id":"2510.14340v1","title":"A Density-Informed Multimodal Artificial Intelligence Framework for Improving Breast Cancer Detection Across All Breast Densities","headline":"提出多模态人工智能框架以改善乳腺癌检测效果","tag":"cs.AI","date":"2025-10-16","url":"cs-AI/2025-10-16/papers/251014340v1-a-density-informed-multimodal-artificial-intelligence-framework-for-.html"},{"id":"2510.14359v1","title":"AI for Service: Proactive Assistance with AI Glasses","headline":"提出Alpha-Service框架，利用AI眼镜实现主动式实时AI服务","tag":"cs.AI","date":"2025-10-16","url":"cs-AI/2025-10-16/papers/251014359v1-ai-for-service-proactive-assistance-with-ai-glasses.html"},{"id":"2510.14824v1","title":"Supervised Fine-Tuning or Contrastive Learning? Towards Better Multimodal LLM Reranking","headline":"针对多模态LLM重排序，对比监督微调与对比学习的优劣","tag":"cs.CL","date":"2025-10-16","url":"cs-CL/2025-10-16/papers/251014824v1-supervised-fine-tuning-or-contrastive-learning-towards-better-multim.html"},{"id":"2510.14949v1","title":"DialectGen: Benchmarking and Improving Dialect Robustness in Multimodal Generation","headline":"DialectGen：构建方言鲁棒性基准，并提出编码器方法提升多模态生成模型方言处理能力。","tag":"cs.CL","date":"2025-10-16","url":"cs-CL/2025-10-16/papers/251014949v1-dialectgen-benchmarking-and-improving-dialect-robustness-in-multimod.html"},{"id":"2510.14065v1","title":"Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning","headline":"提出基于乐观强化学习的技能插入方法，解决任务和运动规划中概率动作的挑战。","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251014065v1-optimistic-reinforcement-learning-based-skill-insertions-for-task-an.html"},{"id":"2510.13488v1","title":"Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations","headline":"提出基于强化学习的四足机器人控制方法，提升其在垂直地面扰动下的运动能力","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013488v1-bridge-the-gap-enhancing-quadruped-locomotion-with-vertical-ground-p.html"},{"id":"2510.13594v1","title":"Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots","headline":"为人形机器人非专家遥操作设计直观图形用户界面","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013594v1-development-of-an-intuitive-gui-for-non-expert-teleoperation-of-huma.html"},{"id":"2510.13626v2","title":"LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models","headline":"LIBERO-Plus：对视觉-语言-动作模型进行深度鲁棒性分析","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013626v2-libero-plus-in-depth-robustness-analysis-of-vision-language-action-m.html"},{"id":"2510.13284v1","title":"ALOHA2 Robot Kitchen Application Scenario Reproduction Report","headline":"ALOHA2：一种高性能、高鲁棒性且更符合人体工程学的双臂遥操作机器人","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013284v1-aloha2-robot-kitchen-application-scenario-reproduction-report.html"},{"id":"2510.13778v1","title":"InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy","headline":"InternVLA-M1：面向通用机器人策略的空间引导视觉-语言-动作框架","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013778v1-internvla-m1-a-spatially-guided-vision-language-action-framework-for.html"},{"id":"2510.13625v1","title":"A Modular Object Detection System for Humanoid Robots Using YOLO","headline":"针对人型机器人，提出基于YOLOv9的模块化目标检测系统，提升计算效率和鲁棒性","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013625v1-a-modular-object-detection-system-for-humanoid-robots-using-yolo.html"},{"id":"2510.13324v1","title":"Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation","headline":"提出FARM框架，利用触觉信息和力控制实现力感知的机器人操作","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013324v1-tactile-conditioned-diffusion-policy-for-force-aware-robotic-manipul.html"},{"id":"2510.13149v1","title":"RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation","headline":"提出RoboHiMan，用于评估长时程操作中组合泛化的分层评估范式。","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013149v1-robohiman-a-hierarchical-evaluation-paradigm-for-compositional-gener.html"},{"id":"2510.13358v1","title":"Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control","headline":"提出离线到在线的对抗微调方法，提升机器人控制对扰动的鲁棒性","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013358v1-adversarial-fine-tuning-in-offline-to-online-reinforcement-learning-.html"},{"id":"2510.14117v2","title":"ViTacGen: Robotic Pushing with Vision-to-Touch Generation","headline":"ViTacGen：基于视觉到触觉生成的机器人推物操作框架","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251014117v2-vitacgen-robotic-pushing-with-vision-to-touch-generation.html"},{"id":"2510.14000v1","title":"A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking","headline":"提出DRIP以解决受限空间停车规划问题","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251014000v1-a-diffusion-refined-planner-with-reinforcement-learning-priors-for-c.html"},{"id":"2510.13595v1","title":"Active Tactile Exploration for Rigid Body Pose and Shape Estimation","headline":"提出基于主动触觉探索的刚体位姿与形状估计方法","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013595v1-active-tactile-exploration-for-rigid-body-pose-and-shape-estimation.html"},{"id":"2510.13553v2","title":"Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping","headline":"提出Hoecken-D手爪，实现线性平行夹持和自适应抓取的机器人手","tag":"cs.RO","date":"2025-10-15","url":"cs-RO/2025-10-15/papers/251013553v2-hoecken-d-hand-a-novel-robotic-hand-for-linear-parallel-pinching-and.html"},{"id":"2510.13243v1","title":"FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding","headline":"FlyAwareV2：用于城市场景理解的多模态跨域无人机数据集","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013243v1-flyawarev2-a-multimodal-cross-domain-uav-dataset-for-urban-scene-und.html"},{"id":"2510.13698v2","title":"Risk-adaptive Activation Steering for Safe Multimodal Large Language Models","headline":"提出风险自适应激活引导(RAS)方法，提升多模态大语言模型安全性并加速推理。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013698v2-risk-adaptive-activation-steering-for-safe-multimodal-large-language.html"},{"id":"2510.17864v1","title":"InsideOut: Integrated RGB-Radiative Gaussian Splatting for Comprehensive 3D Object Representation","headline":"InsideOut：集成RGB与辐射高斯溅射的综合3D物体表示","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251017864v1-insideout-integrated-rgb-radiative-gaussian-splatting-for-comprehens.html"},{"id":"2510.13375v1","title":"DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning","headline":"DepthVLA：通过深度感知的空间推理增强视觉-语言-动作模型","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013375v1-depthvla-enhancing-vision-language-action-models-with-depth-aware-sp.html"},{"id":"2510.13186v4","title":"STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control","headline":"提出STT-GS边缘高斯溅射方法，联合优化客户端选择和功率控制，提升低空场景重建质量。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013186v4-stt-gs-sample-then-transmit-edge-gaussian-splatting-with-joint-clien.html"},{"id":"2510.13809v1","title":"PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning","headline":"提出PhysMaster，通过强化学习物理表征，提升视频生成模型的物理合理性。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013809v1-physmaster-mastering-physical-representation-for-video-generation-vi.html"},{"id":"2510.13565v1","title":"XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation","headline":"XD-RCDepth：面向自动驾驶，提出轻量级雷达-相机深度估计与可解释性对齐的知识蒸馏方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013565v1-xd-rcdepth-lightweight-radar-camera-depth-estimation-with-explainabi.html"},{"id":"2510.13237v1","title":"Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models","headline":"提出针对视觉-语言-动作模型的模型无关对抗攻击与防御方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013237v1-model-agnostic-adversarial-attack-and-defense-for-vision-language-ac.html"},{"id":"2510.13804v1","title":"Generative Universal Verifier as Multimodal Meta-Reasoner","headline":"提出生成式通用验证器，赋能多模态模型进行视觉结果反思与优化。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013804v1-generative-universal-verifier-as-multimodal-meta-reasoner.html"},{"id":"2510.13515v3","title":"UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning","headline":"UniME-V2：利用MLLM作为判别器进行通用多模态嵌入学习","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013515v3-unime-v2-mllm-as-a-judge-for-universal-multimodal-embedding-learning.html"},{"id":"2510.13381v1","title":"Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering","headline":"提出结合2D先验与SDF引导的动态城市场景渲染方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013381v1-leveraging-2d-priors-and-sdf-guidance-for-dynamic-urban-scene-render.html"},{"id":"2510.13795v3","title":"Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs","headline":"提出Honey-Data-15M数据集和Bee-8B模型，提升全开源多模态大语言模型性能。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013795v3-bee-a-high-quality-corpus-and-full-stack-suite-to-unlock-advanced-fu.html"},{"id":"2510.13759v1","title":"Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark","headline":"提出Uni-MMMU：一个大规模多学科多模态统一基准，用于评估视觉理解与生成模型的双向协同能力。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013759v1-uni-mmmu-a-massive-multi-discipline-multimodal-unified-benchmark.html"},{"id":"2510.13620v1","title":"Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues","headline":"提出一种条件感知的动态融合方法，用于解决无人机多模态目标检测在复杂场景下的鲁棒性问题。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013620v1-fusion-meets-diverse-conditions-a-high-diversity-benchmark-and-basel.html"},{"id":"2510.13390v1","title":"Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment","headline":"提出GLSDA框架，利用大模型语义知识提升WiFi手势识别泛化能力","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013390v1-generalizing-wifi-gesture-recognition-via-large-model-aware-semantic.html"},{"id":"2510.13364v1","title":"Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity","headline":"利用语言标签进行零样本多模态分类，解决数据稀缺下的日常姿态识别问题","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013364v1-language-as-a-label-zero-shot-multimodal-classification-of-everyday-.html"},{"id":"2510.13131v1","title":"OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment","headline":"提出OS-HGAdapter，利用大语言模型增强图像-文本对齐，显著提升跨模态检索性能。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013131v1-os-hgadapter-open-semantic-hypergraph-adapter-for-large-language-mod.html"},{"id":"2510.13253v1","title":"End-to-End Multi-Modal Diffusion Mamba","headline":"提出多模态扩散Mamba（MDM），用于统一多模态处理并提升生成性能。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013253v1-end-to-end-multi-modal-diffusion-mamba.html"},{"id":"2510.13768v1","title":"Scaling Vision Transformers for Functional MRI with Flat Maps","headline":"利用平面图和视觉Transformer扩展功能磁共振成像研究","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013768v1-scaling-vision-transformers-for-functional-mri-with-flat-maps.html"},{"id":"2510.13235v1","title":"EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking","headline":"EPIPTrack：利用显式和隐式提示进行多目标跟踪的提示建模新方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013235v1-epiptrack-rethinking-prompt-modeling-with-explicit-and-implicit-prom.html"},{"id":"2510.13208v1","title":"MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation","headline":"MimicParts：用于语音驱动3D人体动作生成的部件感知风格注入方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013208v1-mimicparts-part-aware-style-injection-for-speech-driven-3d-motion-ge.html"},{"id":"2510.13800v2","title":"Reasoning in Space via Grounding in the World","headline":"提出基于世界感知的Grounded-Spatial Reasoner，用于提升3D空间推理能力。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013800v2-reasoning-in-space-via-grounding-in-the-world.html"},{"id":"2510.13756v1","title":"RECODE: Reasoning Through Code Generation for Visual Question Answering","headline":"提出RECODE框架，通过代码生成实现视觉问答中更精确的可验证推理。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013756v1-recode-reasoning-through-code-generation-for-visual-question-answeri.html"},{"id":"2510.13660v2","title":"OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild","headline":"OmniGaze：提出奖励驱动的通用凝视估计框架，解决野外场景泛化性问题","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013660v2-omnigaze-reward-inspired-generalizable-gaze-estimation-in-the-wild.html"},{"id":"2510.13546v1","title":"Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU","headline":"对比FPGA与GPU加速的特征检测器在视觉SLAM中的性能与能效","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013546v1-accelerated-feature-detectors-for-visual-slam-a-comparative-study-of.html"},{"id":"2510.17858v1","title":"Shortcutting Pre-trained Flow Matching Diffusion Models is Almost Free Lunch","headline":"提出基于速度场自蒸馏的Flow Matching模型加速方法，实现高效少步采样","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251017858v1-shortcutting-pre-trained-flow-matching-diffusion-models-is-almost-fr.html"},{"id":"2510.13317v1","title":"Removing Cost Volumes from Optical Flow Estimators","headline":"提出一种训练策略，可在光流估计中移除代价体，显著提升推理速度并降低内存占用。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013317v1-removing-cost-volumes-from-optical-flow-estimators.html"},{"id":"2510.13251v1","title":"Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs","headline":"揭示VideoLLM信息流动路径：通过机制可解释性分析时序推理过程","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013251v1-map-the-flow-revealing-hidden-pathways-of-information-in-videollms.html"},{"id":"2510.13675v2","title":"Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning","headline":"提出知识引导对比学习框架以解决开放域视觉实体识别问题","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013675v2-seeing-and-knowing-in-the-wild-open-domain-visual-entity-recognition.html"},{"id":"2510.14081v3","title":"Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images","headline":"提出Capture, Canonicalize, Splat零样本3D高斯头像生成方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251014081v3-capture-canonicalize-splat-zero-shot-3d-gaussian-avatars-from-unstru.html"},{"id":"2510.14032v1","title":"Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding","headline":"提出Vgent，通过图结构检索-推理增强生成，提升长视频理解能力。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251014032v1-vgent-graph-based-retrieval-reasoning-augmented-generation-for-long-.html"},{"id":"2510.13787v1","title":"Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation","headline":"提出AVC框架，自适应视觉条件控制扩散模型，提升故事延续生成语义一致性。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013787v1-adaptive-visual-conditioning-for-semantic-consistency-in-diffusion-b.html"},{"id":"2510.13747v2","title":"InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue","headline":"提出InteractiveOmni，一个用于音视频多轮交互的统一全模态大语言模型。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013747v2-interactiveomni-a-unified-omni-modal-model-for-audio-visual-multi-tu.html"},{"id":"2510.13702v1","title":"MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion","headline":"MVCustom：通过几何潜在渲染和补全实现多视角定制化扩散模型","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013702v1-mvcustom-multi-view-customized-diffusion-via-geometric-latent-render.html"},{"id":"2510.13643v1","title":"Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection","headline":"研究DINOv2在少样本异常检测中的对抗鲁棒性和不确定性量化问题","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013643v1-towards-adversarial-robustness-and-uncertainty-quantification-in-din.html"},{"id":"2510.13316v1","title":"Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests","headline":"探索GPT-4o对视觉趣味性的理解，并用于提升学习排序模型","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013316v1-visual-interestingness-decoded-how-gpt-4o-mirrors-human-interests.html"},{"id":"2510.13315v1","title":"Self-Augmented Visual Contrastive Decoding","headline":"提出自增强视觉对比解码，提升大型视觉语言模型的事实一致性","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013315v1-self-augmented-visual-contrastive-decoding.html"},{"id":"2510.13276v1","title":"MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models","headline":"提出MMLongCite基准，评估长上下文视觉语言模型的信息保真度","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013276v1-mmlongcite-a-benchmark-for-evaluating-fidelity-of-long-context-visio.html"},{"id":"2510.13232v1","title":"What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging","headline":"提出NegToMe模块和CoVAND数据集，提升VLM在否定描述对象检测中的性能","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013232v1-what-not-to-detect-negation-aware-vlms-via-structured-reasoning-and-.html"},{"id":"2510.13669v1","title":"CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas","headline":"CanvasMAR：通过画布机制改进掩码自回归视频生成，解决慢启动和误差累积问题。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013669v1-canvasmar-improving-masked-autoregressive-video-generation-with-canv.html"},{"id":"2510.13331v2","title":"Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models","headline":"提出Group-VQ，通过分组优化自扩展码书解决VQ-VAE中的码书坍塌问题","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013331v2-group-wise-optimization-for-self-extensible-codebooks-in-vector-quan.html"},{"id":"2510.13808v1","title":"VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models","headline":"VisCoP：通过视觉探针实现视觉语言模型在视频领域的域自适应","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013808v1-viscop-visual-probing-for-video-domain-adaptation-of-vision-language.html"},{"id":"2510.13802v1","title":"Trace Anything: Representing Any Video in 4D via Trajectory Fields","headline":"Trace Anything：提出基于轨迹场的视频4D表示方法，实现高效时空建模。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013802v1-trace-anything-representing-any-video-in-4d-via-trajectory-fields.html"},{"id":"2510.13793v1","title":"NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models","headline":"提出NoisePrints，一种用于私有扩散模型中无失真水印的作者身份验证方法","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013793v1-noiseprints-distortion-free-watermarks-for-authorship-in-private-dif.html"},{"id":"2510.13310v1","title":"InstantSfM: Fully Sparse and Parallel Structure-from-Motion","headline":"InstantSfM：全稀疏并行Structure-from-Motion，加速大规模场景重建。","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013310v1-instantsfm-fully-sparse-and-parallel-structure-from-motion.html"},{"id":"2510.13137v2","title":"Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN","headline":"对比LSTM与3D CNN，实现实时手语到文本的深度学习翻译","tag":"cs.CV","date":"2025-10-15","url":"cs-CV/2025-10-15/papers/251013137v2-real-time-sign-language-to-text-translation-using-deep-learning-a-co.html"},{"id":"2510.13794v2","title":"MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control","headline":"MimicKit：用于动作模仿和控制的强化学习开源框架","tag":"cs.GR","date":"2025-10-15","url":"cs-GR/2025-10-15/papers/251013794v2-mimickit-a-reinforcement-learning-framework-for-motion-imitation-and.html"},{"id":"2510.13774v1","title":"UrbanFusion: Stochastic Multimodal Fusion for Contrastive Learning of Robust Spatial Representations","headline":"UrbanFusion：基于随机多模态融合的对比学习，用于稳健的空间表征","tag":"cs.LG","date":"2025-10-15","url":"cs-LG/2025-10-15/papers/251013774v1-urbanfusion-stochastic-multimodal-fusion-for-contrastive-learning-of.html"},{"id":"2510.13704v1","title":"Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents","headline":"提出基于单纯形嵌入的强化学习方法，提升Actor-Critic算法的样本效率。","tag":"cs.LG","date":"2025-10-15","url":"cs-LG/2025-10-15/papers/251013704v1-simplicial-embeddings-improve-sample-efficiency-in-actor-critic-agen.html"},{"id":"2510.13367v1","title":"A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control","headline":"探索Transformer在在线强化学习中的应用，实现连续控制","tag":"cs.LG","date":"2025-10-15","url":"cs-LG/2025-10-15/papers/251013367v1-a-new-perspective-on-transformers-in-online-reinforcement-learning-f.html"},{"id":"2510.13721v2","title":"NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching","headline":"NExT-OMNI：基于离散流匹配的任意到任意全模态统一建模","tag":"cs.CL","date":"2025-10-15","url":"cs-CL/2025-10-15/papers/251013721v2-next-omni-towards-any-to-any-omnimodal-foundation-models-with-discre.html"},{"id":"2510.13796v2","title":"The Mechanistic Emergence of Symbol Grounding in Language Models","headline":"提出可控评估框架，揭示语言模型中符号 grounding 的涌现机制。","tag":"cs.CL","date":"2025-10-15","url":"cs-CL/2025-10-15/papers/251013796v2-the-mechanistic-emergence-of-symbol-grounding-in-language-models.html"},{"id":"2510.24734v1","title":"DrivingScene: A Multi-Task Online Feed-Forward 3D Gaussian Splatting Method for Dynamic Driving Scenes","headline":"提出DrivingScene，用于动态驾驶场景的多任务在线前馈3D高斯溅射重建。","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251024734v1-drivingscene-a-multi-task-online-feed-forward-3d-gaussian-splatting-.html"},{"id":"2510.12099v1","title":"G4Splat: Geometry-Guided Gaussian Splatting with Generative Prior","headline":"G4Splat：利用生成先验和几何引导的高质量高斯溅射场景重建","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251012099v1-g4splat-geometry-guided-gaussian-splatting-with-generative-prior.html"},{"id":"2510.12107v1","title":"DRL: Discriminative Representation Learning with Parallel Adapters for Class Incremental Learning","headline":"提出DRL框架以解决增量学习中的表示转移问题","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251012107v1-drl-discriminative-representation-learning-with-parallel-adapters-fo.html"},{"id":"2510.15991v3","title":"CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection","headline":"CrossRay3D：通过几何与分布引导提升多模态3D检测效率","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251015991v3-crossray3d-geometry-and-distribution-guidance-for-efficient-multimod.html"},{"id":"2510.12089v2","title":"Playmate2: Training-Free Multi-Character Audio-Driven Animation via Diffusion Transformer with Reward Feedback","headline":"Playmate2：基于扩散Transformer和奖励反馈的免训练多角色音频驱动动画","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251012089v2-playmate2-training-free-multi-character-audio-driven-animation-via-d.html"},{"id":"2510.12095v1","title":"IL3D: A Large-Scale Indoor Layout Dataset for LLM-Driven 3D Scene Generation","headline":"IL3D：用于LLM驱动的3D场景生成的大规模室内布局数据集","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251012095v1-il3d-a-large-scale-indoor-layout-dataset-for-llm-driven-3d-scene-gen.html"},{"id":"2510.13889v1","title":"MultiFoodhat: A potential new paradigm for intelligent food quality inspection","headline":"提出MultiFoodChat，用于零样本食物识别的对话驱动多智能体推理框架。","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251013889v1-multifoodhat-a-potential-new-paradigm-for-intelligent-food-quality-i.html"},{"id":"2510.12123v1","title":"Hardware-aware Coding Function Design for Compressive Single-Photon 3D Cameras","headline":"针对单光子3D相机硬件约束，提出硬件感知的编码函数设计方法","tag":"cs.CV","date":"2025-10-14","url":"cs-CV/2025-10-14/papers/251012123v1-hardware-aware-coding-function-design-for-compressive-single-photon-.html"},{"id":"2510.12087v1","title":"Can Representation Gaps Be the Key to Enhancing Robustness in Graph-Text Alignment?","headline":"提出LLM4GTA框架，通过保持表征差异提升图文对齐的鲁棒性","tag":"cs.GR","date":"2025-10-14","url":"cs-GR/2025-10-14/papers/251012087v1-can-representation-gaps-be-the-key-to-enhancing-robustness-in-graph-.html"},{"id":"2510.12085v1","title":"GraphShaper: Geometry-aware Alignment for Improving Transfer Learning in Text-Attributed Graphs","headline":"GraphShaper提出几何感知对齐框架，提升文本属性图的迁移学习性能。","tag":"cs.LG","date":"2025-10-14","url":"cs-LG/2025-10-14/papers/251012085v1-graphshaper-geometry-aware-alignment-for-improving-transfer-learning.html"},{"id":"2510.12072v1","title":"EmboMatrix: A Scalable Training-Ground for Embodied Decision-Making","headline":"提出EmboMatrix：一个可扩展的具身决策训练平台，提升LLM的具身智能。","tag":"cs.AI","date":"2025-10-14","url":"cs-AI/2025-10-14/papers/251012072v1-embomatrix-a-scalable-training-ground-for-embodied-decision-making.html"},{"id":"2510.12845v1","title":"VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages","headline":"VLURes：提出多语种视觉语言理解基准，评估低资源语言环境下VLM的细粒度能力。","tag":"cs.CL","date":"2025-10-14","url":"cs-CL/2025-10-14/papers/251012845v1-vlures-benchmarking-vlm-visual-and-linguistic-understanding-in-low-r.html"},{"id":"2510.11258v1","title":"DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation","headline":"DemoHLM：基于单次演示实现通用人形机器人移动操作","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011258v1-demohlm-from-one-demonstration-to-generalizable-humanoid-loco-manipu.html"},{"id":"2510.11689v1","title":"Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation","headline":"Phys2Real：融合VLM先验与交互式在线自适应，实现不确定性感知的Sim-to-Real操作","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011689v1-phys2real-fusing-vlm-priors-with-interactive-online-adaptation-for-u.html"},{"id":"2510.11542v1","title":"NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning","headline":"NaviGait：利用深度强化学习导航动态可行步态库，实现鲁棒双足运动控制","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011542v1-navigait-navigating-dynamically-feasible-gait-libraries-using-deep-r.html"},{"id":"2510.11682v1","title":"Ego-Vision World Model for Humanoid Contact Planning","headline":"提出基于自中心视觉世界模型的类人机器人接触规划方法","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011682v1-ego-vision-world-model-for-humanoid-contact-planning.html"},{"id":"2510.11401v1","title":"Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots","headline":"提出一种高效的人形机器人多点巡检路径与运动优化框架","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011401v1-path-and-motion-optimization-for-efficient-multi-location-inspection.html"},{"id":"2510.11103v1","title":"A Primer on SO(3) Action Representations in Deep Reinforcement Learning","headline":"研究SO(3)作用表示对深度强化学习的影响，提出基于局部坐标系切向量的动作表示方法。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011103v1-a-primer-on-so3-action-representations-in-deep-reinforcement-learnin.html"},{"id":"2510.10903v1","title":"Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey","headline":"机器人操作的统一理解：全面的综述性研究，涵盖方法、瓶颈与应用。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010903v1-towards-a-unified-understanding-of-robot-manipulation-a-comprehensiv.html"},{"id":"2510.11660v2","title":"ManiAgent: An Agentic Framework for General Robotic Manipulation","headline":"ManiAgent：一种用于通用机器人操作的Agent框架","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011660v2-maniagent-an-agentic-framework-for-general-robotic-manipulation.html"},{"id":"2510.11539v2","title":"Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization","headline":"提出双层优化框架，同步标定腿式机器人状态估计中的噪声协方差与运动学参数","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011539v2-simultaneous-calibration-of-noise-covariance-and-kinematics-for-stat.html"},{"id":"2510.10975v2","title":"RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model","headline":"RoVer：提出基于奖励模型的机器人测试时验证框架，提升VLA模型性能","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010975v2-rover-robot-reward-model-as-test-time-verifier-for-vision-language-a.html"},{"id":"2510.21761v1","title":"J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception","headline":"J-ORA：用于机器人感知的日语物体识别、指代和动作预测的多模态数据集与框架","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251021761v1-j-ora-a-framework-and-multimodal-dataset-for-japanese-object-identif.html"},{"id":"2510.11491v1","title":"Constraint-Aware Reinforcement Learning via Adaptive Action Scaling","headline":"提出基于自适应动作缩放的约束感知强化学习方法，提升安全性和性能。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011491v1-constraint-aware-reinforcement-learning-via-adaptive-action-scaling.html"},{"id":"2510.11072v1","title":"PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System","headline":"提出PhysHSI以解决人形机器人与真实场景交互的挑战","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011072v1-physhsi-towards-a-real-world-generalizable-and-natural-humanoid-scen.html"},{"id":"2510.11083v1","title":"Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling","headline":"Flow Planner：基于流匹配的自动驾驶规划，提升交互行为建模能力","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011083v1-flow-matching-based-autonomous-driving-planning-with-advanced-intera.html"},{"id":"2510.11421v1","title":"A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities","headline":"提出基于AIoT的模块化低延迟机器人遥操作框架，用于智慧城市应用","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011421v1-a-modular-aiot-framework-for-low-latency-real-time-robotic-teleopera.html"},{"id":"2510.11094v1","title":"Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation","headline":"提出基于折纸气动软体外骨骼的Koopman模型预测控制方法，用于膝关节康复。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011094v1-design-and-koopman-model-predictive-control-of-a-soft-exoskeleton-ba.html"},{"id":"2510.10912v2","title":"More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks","headline":"RoboMAP：利用自适应可供性热图捕获不确定性，提升机器人空间定位能力","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010912v2-more-than-a-point-capturing-uncertainty-with-adaptive-affordance-hea.html"},{"id":"2510.11321v2","title":"HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data","headline":"HiMaCon：从无标注多模态数据中发现分层操作概念，提升机器人操作泛化性","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011321v2-himacon-discovering-hierarchical-manipulation-concepts-from-unlabele.html"},{"id":"2510.11041v1","title":"Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy","headline":"提出基于不确定性感知的自主协同学习规划策略，提升多车交互的安全性和有效性。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011041v1-unveiling-uncertainty-aware-autonomous-cooperative-learning-based-pl.html"},{"id":"2510.11566v1","title":"SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy","headline":"SCOOP'D：通过Sim2Real生成策略学习混合液体-固体抓取","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011566v1-scoopd-learning-mixed-liquid-solid-scooping-via-sim2real-generative-.html"},{"id":"2510.11474v2","title":"Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning","headline":"提出基于分层多智能体强化学习的空战协同策略，解决复杂空战环境下的决策难题。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011474v2-coordinated-strategies-in-realistic-air-combat-by-hierarchical-multi.html"},{"id":"2510.10960v1","title":"Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving","headline":"提出游戏理论风险塑形强化学习以解决安全自动驾驶问题","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010960v1-game-theoretic-risk-shaped-reinforcement-learning-for-safe-autonomou.html"},{"id":"2510.10865v1","title":"GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments","headline":"GRIP：动态环境中基于网格的中继与共现感知统一规划框架","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010865v1-grip-a-unified-framework-for-grid-based-relay-and-co-occurrence-awar.html"},{"id":"2510.11036v1","title":"XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation","headline":"XGrasp：提出一种支持多夹爪的实时、可泛化抓取检测框架。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011036v1-xgrasp-gripper-aware-grasp-detection-with-multi-gripper-data-generat.html"},{"id":"2510.11552v1","title":"Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education","headline":"提出一种基于外部跟踪系统的全向轮足球机器人教育套件","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011552v1-robot-soccer-kit-omniwheel-tracked-soccer-robots-for-education.html"},{"id":"2510.11014v1","title":"Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces","headline":"提出基于生成模型的采样方法，为配置空间规划提供环境不确定性的先验信息。","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251011014v1-into-the-unknown-towards-using-generative-models-for-sampling-priors.html"},{"id":"2510.10893v1","title":"An Adaptive Transition Framework for Game-Theoretic Based Takeover","headline":"提出自适应过渡策略以解决自动驾驶系统接管问题","tag":"cs.RO","date":"2025-10-13","url":"cs-RO/2025-10-13/papers/251010893v1-an-adaptive-transition-framework-for-game-theoretic-based-takeover.html"},{"id":"2510.11649v1","title":"PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image","headline":"PhySIC：从单张图像重建物理上合理的3D人-场景交互与接触","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011649v1-physic-physically-plausible-3d-human-scene-interaction-and-contact-f.html"},{"id":"2510.11509v1","title":"Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model","headline":"提出Situat3DChange数据集，用于多模态大语言模型理解情境化3D场景变化","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011509v1-situat3dchange-situated-3d-change-understanding-dataset-for-multimod.html"},{"id":"2510.11473v2","title":"VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment","headline":"VA-GS：通过视角对齐增强高斯溅射的几何表示，提升表面重建精度。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011473v2-va-gs-enhancing-the-geometric-representation-of-gaussian-splatting-v.html"},{"id":"2510.11496v2","title":"AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model","headline":"AndesVL：面向移动端的高效多模态大语言模型，实现性能与效率的平衡","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011496v2-andesvl-technical-report-an-efficient-mobile-side-multimodal-large-l.html"},{"id":"2510.11341v2","title":"InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models","headline":"InternSVG：利用多模态大语言模型实现统一的SVG任务处理","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011341v2-internsvg-towards-unified-svg-tasks-with-multimodal-large-language-m.html"},{"id":"2510.11190v3","title":"FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models","headline":"FlexAC：面向多模态大语言模型中联想推理的灵活控制","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011190v3-flexac-towards-flexible-control-of-associative-reasoning-in-multimod.html"},{"id":"2510.10991v1","title":"A Survey on Agentic Multimodal Large Language Models","headline":"综述Agentic多模态大语言模型，探索自主智能体在动态环境中的应用与发展。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010991v1-a-survey-on-agentic-multimodal-large-language-models.html"},{"id":"2510.11112v1","title":"Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment","headline":"DiPro：时空解耦与多尺度对齐的多模态疾病进展建模框架","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011112v1-multimodal-disease-progression-modeling-via-spatiotemporal-disentang.html"},{"id":"2510.11176v1","title":"G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation","headline":"提出G2L框架，通过知识蒸馏将千亿级病理模型能力迁移至癌症特异性大型模型。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011176v1-g2lfrom-giga-scale-to-cancer-specific-large-scale-pathology-foundati.html"},{"id":"2510.11027v1","title":"Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning","headline":"Vlaser：提出具有协同具身推理能力的视觉-语言-动作模型，弥合VLM推理与VLA策略学习的鸿沟。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011027v1-vlaser-vision-language-action-model-with-synergistic-embodied-reason.html"},{"id":"2510.11387v2","title":"MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference","headline":"提出MaterialRefGS，通过多视角一致材质推断实现高质量反射高斯溅射渲染","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011387v2-materialrefgs-reflective-gaussian-splatting-with-multi-view-consiste.html"},{"id":"2510.11178v1","title":"BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models","headline":"BLEnD-Vis：构建多模态文化理解基准，评估视觉语言模型中的文化知识鲁棒性。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011178v1-blend-vis-benchmarking-multimodal-cultural-understanding-in-vision-l.html"},{"id":"2510.11017v1","title":"High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation","headline":"提出基于全局-局部状态空间模型的高分辨率时空建模方法，用于视频人体姿态估计。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011017v1-high-resolution-spatiotemporal-modeling-with-global-local-state-spac.html"},{"id":"2510.11718v1","title":"CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images","headline":"提出CodePlot-CoT，通过代码驱动图像的思维链解决数学视觉推理难题","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011718v1-codeplot-cot-mathematical-visual-reasoning-by-thinking-with-code-dri.html"},{"id":"2510.11606v1","title":"ExpVid: A Benchmark for Experiment Video Understanding & Reasoning","headline":"ExpVid：用于实验视频理解与推理的基准数据集，挑战多模态大语言模型在科学实验中的应用。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011606v1-expvid-a-benchmark-for-experiment-video-understanding-reasoning.html"},{"id":"2510.11579v1","title":"MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis","headline":"提出MS-Mix以解决多模态情感分析中的数据稀缺问题","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011579v1-ms-mix-unveiling-the-power-of-mixup-for-multimodal-sentiment-analysi.html"},{"id":"2510.11576v2","title":"Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping","headline":"评估基础模型在 hyperspectral 图像分类中的性能，应用于谷类作物类型识别。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011576v2-benchmarking-foundation-models-for-hyperspectral-image-classificatio.html"},{"id":"2510.11553v2","title":"How many samples to label for an application given a foundation model? Chest X-ray classification study","headline":"研究胸部X光片分类任务中，如何利用预训练模型减少标注样本需求","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011553v2-how-many-samples-to-label-for-an-application-given-a-foundation-mode.html"},{"id":"2510.11260v1","title":"A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images","headline":"提出基于大语言模型的扫描电镜图像比例尺自动检测与提取框架","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011260v1-a-large-language-model-assisted-automated-scale-bar-detection-and-ex.html"},{"id":"2510.11173v2","title":"CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation","headline":"CoPRS：提出基于思维链的位置先验学习方法，用于提升推理分割任务的性能与可解释性","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011173v2-coprs-learning-positional-prior-from-chain-of-thought-for-reasoning-.html"},{"id":"2510.11115v1","title":"Connecting Giants: Synergistic Knowledge Transfer of Large Multimodal Models for Few-Shot Learning","headline":"提出SynTrans框架，利用大型多模态模型协同知识迁移提升少样本学习性能","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011115v1-connecting-giants-synergistic-knowledge-transfer-of-large-multimodal.html"},{"id":"2510.10986v1","title":"Mixup Helps Understanding Multimodal Video Better","headline":"提出多模态Mixup方法，提升多模态视频理解模型的泛化性和鲁棒性","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010986v1-mixup-helps-understanding-multimodal-video-better.html"},{"id":"2510.11687v1","title":"Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View","headline":"提出一种类别无关的单视图物体位姿、尺寸和形状估计框架。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011687v1-beyond-templates-category-agnostic-object-pose-size-and-shape-estima.html"},{"id":"2510.11096v1","title":"CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization","headline":"提出CoDefend，通过扩散净化和提示优化协同防御多模态大语言模型的对抗攻击。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011096v1-codefend-cross-modal-collaborative-defense-via-diffusion-purificatio.html"},{"id":"2510.10868v1","title":"FastHMR: Accelerating Human Mesh Recovery via Token and Layer Merging with Diffusion Decoding","headline":"FastHMR：通过Token和层合并及扩散解码加速人体网格重建","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010868v1-fasthmr-accelerating-human-mesh-recovery-via-token-and-layer-merging.html"},{"id":"2510.11204v1","title":"Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos","headline":"提出基于类原型对比学习的多标签细粒度教育视频分类方法","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011204v1-class-prototypes-based-contrastive-learning-for-classifying-multi-la.html"},{"id":"2510.11107v1","title":"MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps","headline":"提出基于运动地图（MoMap）的语义感知场景运动生成方法，实现从单张图像预测未来3D场景运动。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011107v1-momaps-semantics-aware-scene-motion-generation-with-motion-maps.html"},{"id":"2510.10973v1","title":"Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning","headline":"提出Chart-RVR框架，通过可验证奖励的强化学习提升图表推理的可解释性和鲁棒性","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010973v1-chart-rvr-reinforcement-learning-with-verifiable-rewards-for-explain.html"},{"id":"2510.11717v1","title":"Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams","headline":"提出Ev4DGS以解决单目事件流下非刚性物体的新视角渲染问题","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011717v1-ev4dgs-novel-view-rendering-of-non-rigid-objects-from-monocular-even.html"},{"id":"2510.11647v1","title":"IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment","headline":"IVEBench：用于指令引导视频编辑评估的现代基准套件","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011647v1-ivebench-modern-benchmark-suite-for-instruction-guided-video-editing.html"},{"id":"2510.11549v1","title":"ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?","headline":"提出ODI-Bench，评估MLLM在全景图像理解中的能力并提出Omni-CoT方法。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011549v1-odi-bench-can-mllms-understand-immersive-omnidirectional-environment.html"},{"id":"2510.11369v1","title":"Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment","headline":"提出RALI算法，通过对比学习对齐图像和文本表征，实现高效图像质量评估。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011369v1-reasoning-as-representation-rethinking-visual-reinforcement-learning.html"},{"id":"2510.11305v1","title":"Evaluating the effects of preprocessing, method selection, and hyperparameter tuning on SAR-based flood mapping and water depth estimation","headline":"研究预处理、方法选择和超参数调整对SAR洪水制图和水深估计的影响","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011305v1-evaluating-the-effects-of-preprocessing-method-selection-and-hyperpa.html"},{"id":"2510.11026v1","title":"GIR-Bench: Versatile Benchmark for Generating Images with Reasoning","headline":"提出GIR-Bench以解决多模态模型评估不足问题","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011026v1-gir-bench-versatile-benchmark-for-generating-images-with-reasoning.html"},{"id":"2510.11012v1","title":"COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models","headline":"提出COCO-Tree，利用神经符号概念树增强视觉语言模型中的组合推理能力","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011012v1-coco-tree-compositional-hierarchical-concept-trees-for-enhanced-reas.html"},{"id":"2510.10933v1","title":"DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects","headline":"DKPMV：基于多视角RGB图像的稠密关键点融合，用于无纹理物体6D位姿估计","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010933v1-dkpmv-dense-keypoints-fusion-from-multi-view-rgb-frames-for-6d-pose-.html"},{"id":"2510.10889v1","title":"Topological Alignment of Shared Vision-Language Embedding Space","headline":"提出ToMCLIP，通过拓扑对齐增强多语言视觉-语言模型的共享嵌入空间。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010889v1-topological-alignment-of-shared-vision-language-embedding-space.html"},{"id":"2510.11567v1","title":"A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation","headline":"提出基于扩散模型的低成本训练数据生成框架，提升城市语义分割性能。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011567v1-a-framework-for-low-effort-training-data-generation-for-urban-semant.html"},{"id":"2510.11565v1","title":"SNAP: Towards Segmenting Anything in Any Point Cloud","headline":"提出SNAP，一个通用的点云交互式分割模型，支持跨域和多种提示方式。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011565v1-snap-towards-segmenting-anything-in-any-point-cloud.html"},{"id":"2510.11631v1","title":"EvoCAD: Evolutionary CAD Code Generation with Vision Language Models","headline":"EvoCAD：利用视觉语言模型与进化算法生成CAD代码","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011631v1-evocad-evolutionary-cad-code-generation-with-vision-language-models.html"},{"id":"2510.11090v1","title":"Source-Free Object Detection with Detection Transformer","headline":"提出FRANCK框架，通过查询中心特征增强实现DETR的无源域目标检测。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011090v1-source-free-object-detection-with-detection-transformer.html"},{"id":"2510.11028v1","title":"Enhancing Zero-Shot Anomaly Detection: CLIP-SAM Collaboration with Cascaded Prompts","headline":"提出CLIP-SAM协同与级联提示的两阶段框架，提升零样本异常检测性能。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011028v1-enhancing-zero-shot-anomaly-detection-clip-sam-collaboration-with-ca.html"},{"id":"2510.10969v1","title":"IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation","headline":"提出IUT-Plug插件，通过显式结构化推理增强多模态图文生成中上下文一致性。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010969v1-iut-plug-a-plug-in-tool-for-interleaved-image-text-generation.html"},{"id":"2510.10921v2","title":"FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model","headline":"提出FG-CLIP 2，用于提升英汉双语环境下的细粒度视觉-语言对齐能力","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251010921v2-fg-clip-2-a-bilingual-fine-grained-vision-language-alignment-model.html"},{"id":"2510.11538v2","title":"Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers","headline":"提出Detail Guidance，通过调控Diffusion Transformer中的大规模激活提升图像细节生成质量","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011538v2-massive-activations-are-the-key-to-local-detail-synthesis-in-diffusi.html"},{"id":"2510.11512v2","title":"LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference","headline":"提出LikePhys，通过似然偏好评估视频扩散模型中的直观物理理解能力","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011512v2-likephys-evaluating-intuitive-physics-understanding-in-video-diffusi.html"},{"id":"2510.11605v1","title":"ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training","headline":"ACE-G：通过查询预训练提升场景坐标回归的泛化能力","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011605v1-ace-g-improving-generalization-of-scene-coordinate-regression-throug.html"},{"id":"2510.11520v2","title":"mmWalk: Towards Multi-modal Multi-view Walking Assistance","headline":"mmWalk：面向盲人或低视力人群的多模态多视角步行辅助数据集与方法","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011520v2-mmwalk-towards-multi-modal-multi-view-walking-assistance.html"},{"id":"2510.11417v1","title":"Robust Ego-Exo Correspondence with Long-Term Memory","headline":"提出基于长时记忆的LM-EEC框架，解决Ego-Exo视角对应中的特征融合和记忆容量问题。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011417v1-robust-ego-exo-correspondence-with-long-term-memory.html"},{"id":"2510.11340v2","title":"REACT3D: Recovering Articulations for Interactive Physical 3D Scenes","headline":"REACT3D：用于交互式物理3D场景的铰接结构恢复框架","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011340v2-react3d-recovering-articulations-for-interactive-physical-3d-scenes.html"},{"id":"2510.11050v1","title":"Zero-shot Face Editing via ID-Attribute Decoupled Inversion","headline":"提出基于ID-属性解耦反演的零样本人脸编辑方法，解决ID保持和结构一致性问题。","tag":"cs.CV","date":"2025-10-13","url":"cs-CV/2025-10-13/papers/251011050v1-zero-shot-face-editing-via-id-attribute-decoupled-inversion.html"},{"id":"2510.11878v2","title":"GS-Verse: Mesh-based Gaussian Splatting for Physics-aware Interaction in Virtual Reality","headline":"GS-Verse：基于网格的高斯溅射，用于虚拟现实中具有物理感知交互","tag":"cs.GR","date":"2025-10-13","url":"cs-GR/2025-10-13/papers/251011878v2-gs-verse-mesh-based-gaussian-splatting-for-physics-aware-interaction.html"},{"id":"2510.11696v1","title":"QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs","headline":"QeRL：量化增强的LLM强化学习框架，提升效率并增强探索能力","tag":"cs.LG","date":"2025-10-13","url":"cs-LG/2025-10-13/papers/251011696v1-qerl-beyond-efficiency-quantization-enhanced-reinforcement-learning-.html"},{"id":"2510.10932v1","title":"TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models","headline":"TabVLA：针对视觉-语言-动作模型的有目标后门攻击框架","tag":"cs.AI","date":"2025-10-13","url":"cs-AI/2025-10-13/papers/251010932v1-tabvla-targeted-backdoor-attacks-on-vision-language-action-models.html"},{"id":"2510.11693v1","title":"Scaling Language-Centric Omnimodal Representation Learning","headline":"提出LCO-Emb框架，通过语言中心的多模态表征学习，提升跨模态检索性能。","tag":"cs.CL","date":"2025-10-13","url":"cs-CL/2025-10-13/papers/251011693v1-scaling-language-centric-omnimodal-representation-learning.html"},{"id":"2510.11196v2","title":"Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations","headline":"提出基于多模态扰动的医学VQA模型推理忠实性评估框架，用于评估胸部X光片问答。","tag":"cs.CL","date":"2025-10-13","url":"cs-CL/2025-10-13/papers/251011196v2-evaluating-reasoning-faithfulness-in-medical-vision-language-models-.html"},{"id":"2510.11583v1","title":"Smooth Spatiotemporal Tube Synthesis for Prescribed-Time Reach-Avoid-Stay Control","headline":"提出平滑时空管道合成方法，解决规定时间内非线性系统的Reach-Avoid-Stay控制问题","tag":"eess.SY","date":"2025-10-13","url":"eess-SY/2025-10-13/papers/251011583v1-smooth-spatiotemporal-tube-synthesis-for-prescribed-time-reach-avoid.html"},{"id":"2510.10637v1","title":"High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting","headline":"RoboSimGS：利用高斯溅射生成高保真模拟数据，实现零样本机器人操作学习","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010637v1-high-fidelity-simulated-data-generation-for-real-world-zero-shot-rob.html"},{"id":"2510.10851v1","title":"Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion","headline":"提出偏好条件的多目标强化学习以解决人形机器人运动中的指令跟踪与力反馈问题","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010851v1-preference-conditioned-multi-objective-rl-for-integrated-command-tra.html"},{"id":"2510.10455v1","title":"Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds","headline":"提出一种对称性引导的强化学习框架，实现四足机器人不同速度下的自由步态转换。","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010455v1-towards-dynamic-quadrupedal-gaits-a-symmetry-guided-rl-hierarchy-ena.html"},{"id":"2510.10778v1","title":"Real2USD: Scene Representations in Universal Scene Description Language","headline":"提出Real2USD系统，利用通用场景描述语言USD赋能LLM机器人场景理解与规划","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010778v1-real2usd-scene-representations-in-universal-scene-description-langua.html"},{"id":"2510.10642v2","title":"UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning","headline":"UniCoD：通过统一连续和离散表示学习增强机器人策略","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010642v2-unicod-enhancing-robot-policy-via-unified-continuous-and-discrete-re.html"},{"id":"2510.10567v1","title":"Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving","headline":"提出基于强化学习的动态自适应采样运动规划，用于敏捷自主驾驶","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010567v1-reinforcement-learning-based-dynamic-adaptation-for-sampling-based-m.html"},{"id":"2510.10759v1","title":"Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning","headline":"提出ROGER算法，通过在线调整奖励增益实现约束下的机器人运动学习","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010759v1-gain-tuning-is-not-what-you-need-reward-gain-adaptation-for-constrai.html"},{"id":"2510.10516v1","title":"Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control","headline":"提出基于Population-coded SNN的DRL框架，用于高维机器人控制中的节能问题。","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010516v1-population-coded-spiking-neural-networks-for-high-dimensional-roboti.html"},{"id":"2510.10843v1","title":"Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots","headline":"提出基于力矩传感器融合的腿式机器人接触感知方法","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010843v1-contact-sensing-via-joint-torque-sensors-and-a-forcetorque-sensor-fo.html"},{"id":"2510.10731v1","title":"Controllable Generative Trajectory Prediction via Weak Preference Alignment","headline":"提出PrefCVAE以解决可控多样性轨迹预测问题","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010731v1-controllable-generative-trajectory-prediction-via-weak-preference-al.html"},{"id":"2510.10520v2","title":"AI-Agents for Culturally Diverse Online Higher Education Environments","headline":"提出利用生成式AI驱动的文化感知AI-Agent，以提升在线高等教育环境中的学生参与度和学习效果。","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010520v2-ai-agents-for-culturally-diverse-online-higher-education-environment.html"},{"id":"2510.10602v1","title":"SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams","headline":"SpikeGrasp：基于立体脉冲事件流的6自由度抓取姿态检测基准","tag":"cs.RO","date":"2025-10-12","url":"cs-RO/2025-10-12/papers/251010602v1-spikegrasp-a-benchmark-for-6-dof-grasp-pose-detection-from-stereo-sp.html"},{"id":"2510.10691v3","title":"Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos","headline":"提出动态高斯溅射框架，解决散焦和运动模糊视频的新视角合成问题","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010691v3-dynamic-gaussian-splatting-from-defocused-and-motion-blurred-monocul.html"},{"id":"2510.10671v1","title":"Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey","headline":"首个基于图像-语言预训练模型的图像到视频迁移学习的综述","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010671v1-image-to-video-transfer-learning-based-on-image-language-foundation-.html"},{"id":"2510.10650v1","title":"DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis","headline":"DEMO：解耦运动潜在流匹配，实现细粒度可控的说话人像合成","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010650v1-demo-disentangled-motion-latent-flow-matching-for-fine-grained-contr.html"},{"id":"2510.10464v1","title":"Post-TIPS Prediction via Multimodal Interaction: A Multi-Center Dataset and Framework for Survival, Complication, and Portal Pressure Assessment","headline":"提出MultiTIPS数据集和多模态交互框架，用于TIPS术后生存、并发症和门静脉压力评估。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010464v1-post-tips-prediction-via-multimodal-interaction-a-multi-center-datas.html"},{"id":"2510.10765v1","title":"EGD-YOLO: A Lightweight Multimodal Framework for Robust Drone-Bird Discrimination via Ghost-Enhanced YOLOv8n and EMA Attention under Adverse Condition","headline":"EGD-YOLO：轻量级多模态框架，通过Ghost增强YOLOv8n和EMA注意力实现恶劣条件下无人机-鸟类稳健区分","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010765v1-egd-yolo-a-lightweight-multimodal-framework-for-robust-drone-bird-di.html"},{"id":"2510.10663v1","title":"Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection","headline":"提出FS-VFM，通过自监督学习提升人脸安全任务的泛化能力","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010663v1-scalable-face-security-vision-foundation-model-for-deepfake-diffusio.html"},{"id":"2510.10426v1","title":"Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs","headline":"提出HuLiRAG框架，通过模拟人类视觉处理方式增强多模态大语言模型的生成能力","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010426v1-taming-a-retrieval-framework-to-read-images-in-humanlike-manner-for-.html"},{"id":"2510.10478v2","title":"MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition","headline":"提出MSF-Mamba，通过运动感知状态融合提升Mamba在微手势识别中的效率与精度。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010478v2-msf-mamba-motion-aware-state-fusion-mamba-for-efficient-micro-gestur.html"},{"id":"2510.10587v1","title":"A Simple and Better Baseline for Visual Grounding","headline":"提出基于特征选择的视觉定位基线FSVG，提升精度与效率","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010587v1-a-simple-and-better-baseline-for-visual-grounding.html"},{"id":"2510.10584v1","title":"Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection","headline":"提出MoFE模块和动态Mixup策略，提升视觉基础模型在OOD检测中的性能","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010584v1-equipping-vision-foundation-model-with-mixture-of-experts-for-out-of.html"},{"id":"2510.10546v1","title":"GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction","headline":"GLOFNet：用于冰湖溃决洪水监测与预测的多模态数据集","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010546v1-glofnet-a-multimodal-dataset-for-glof-monitoring-and-prediction.html"},{"id":"2510.10524v1","title":"Unified Open-World Segmentation with Multi-Modal Prompts","headline":"COSINE：多模态提示下的统一开放世界分割模型","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010524v1-unified-open-world-segmentation-with-multi-modal-prompts.html"},{"id":"2510.10577v1","title":"Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes","headline":"提出Diff-ABFlow，融合帧-事件互补信息，解决恶劣场景光流估计难题","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010577v1-injecting-frame-event-complementary-fusion-into-diffusion-for-optica.html"},{"id":"2510.10779v2","title":"Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans","headline":"提出基于结构化谱图表示学习的3D CT多标签异常分析方法","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010779v2-structured-spectral-graph-representation-learning-for-multi-label-ab.html"},{"id":"2510.10518v3","title":"VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning","headline":"VR-Thinker：通过图像推理增强视频奖励模型，提升长视频偏好判断。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010518v3-vr-thinker-boosting-video-reward-models-through-thinking-with-image-.html"},{"id":"2510.10492v1","title":"Towards Efficient 3D Gaussian Human Avatar Compression: A Prior-Guided Framework","headline":"提出一种先验引导的3D高斯人体Avatar高效压缩框架，用于超低码率高质量的元宇宙应用。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010492v1-towards-efficient-3d-gaussian-human-avatar-compression-a-prior-guide.html"},{"id":"2510.10414v1","title":"Guided Image Feature Matching using Feature Spatial Order","headline":"提出一种利用特征空间顺序引导的图像特征匹配方法，提升匹配效率和准确性。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010414v1-guided-image-feature-matching-using-feature-spatial-order.html"},{"id":"2510.10609v1","title":"OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment","headline":"OmniQuality-R：通过全方位质量评估提升奖励模型性能","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010609v1-omniquality-r-advancing-reward-models-through-all-encompassing-quali.html"},{"id":"2510.10406v1","title":"Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes","headline":"Mesh-Gait：提出一种基于2D轮廓多模态表征学习的统一步态识别框架","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010406v1-mesh-gait-a-unified-framework-for-gait-recognition-through-multi-mod.html"},{"id":"2510.10487v1","title":"Towards Self-Refinement of Vision-Language Models with Triangular Consistency","headline":"提出基于三角一致性的自精炼框架，提升视觉-语言模型性能。","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010487v1-towards-self-refinement-of-vision-language-models-with-triangular-co.html"},{"id":"2510.10466v1","title":"When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance","headline":"提出跨模态引导（CMG）方法，缓解视觉语言模型中的语言偏见导致的幻觉问题","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010466v1-when-images-speak-louder-mitigating-language-bias-induced-hallucinat.html"},{"id":"2510.10422v1","title":"Towards Cybersickness Severity Classification from VR Gameplay Videos Using Transfer Learning and Temporal Modeling","headline":"提出基于迁移学习和时序建模的VR游戏视频晕动症严重程度分类方法","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010422v1-towards-cybersickness-severity-classification-from-vr-gameplay-video.html"},{"id":"2510.10793v1","title":"ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling","headline":"提出imHead：一种用于局部头部建模的大规模隐式可变形模型","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010793v1-imhead-a-large-scale-implicit-morphable-model-for-localized-head-mod.html"},{"id":"2510.10612v1","title":"UltraScatter: Ray-Based Simulation of Ultrasound Scattering","headline":"UltraScatter：提出基于射线追踪的超声散射快速模拟方法","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010612v1-ultrascatter-ray-based-simulation-of-ultrasound-scattering.html"},{"id":"2510.10417v1","title":"Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis","headline":"提出Combo-Gait，用于多模态步态识别和属性分析的统一Transformer框架","tag":"cs.CV","date":"2025-10-12","url":"cs-CV/2025-10-12/papers/251010417v1-combo-gait-unified-transformer-framework-for-multi-modal-gait-recogn.html"},{"id":"2510.10611v1","title":"HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication","headline":"HyperAgent：利用超图优化多智能体通信拓扑，提升协作效率与任务适应性","tag":"cs.GR","date":"2025-10-12","url":"cs-GR/2025-10-12/papers/251010611v1-hyperagent-leveraging-hypergraphs-for-topology-optimization-in-multi.html"},{"id":"2510.10585v1","title":"D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems","headline":"D3MAS：通过分解、推导与分发增强多智能体系统中的知识共享","tag":"cs.GR","date":"2025-10-12","url":"cs-GR/2025-10-12/papers/251010585v1-d3mas-decompose-deduce-and-distribute-for-enhanced-knowledge-sharing.html"},{"id":"2510.10581v1","title":"GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search","headline":"GraphTracer：基于图引导的LLM Agent故障追踪，提升多轮深度搜索的鲁棒性","tag":"cs.GR","date":"2025-10-12","url":"cs-GR/2025-10-12/papers/251010581v1-graphtracer-graph-guided-failure-tracing-in-llm-agents-for-robust-mu.html"},{"id":"2510.11754v1","title":"Zero-Shot Large Language Model Agents for Fully Automated Radiotherapy Treatment Planning","headline":"提出基于零样本大语言模型的全自动放射治疗计划方法，提升计划质量。","tag":"cs.AI","date":"2025-10-12","url":"cs-AI/2025-10-12/papers/251011754v1-zero-shot-large-language-model-agents-for-fully-automated-radiothera.html"},{"id":"2510.10823v1","title":"The Irrational Machine: Neurosis and the Limits of Algorithmic Safety","headline":"提出神经症框架以解决嵌入式AI的行为不一致问题","tag":"cs.AI","date":"2025-10-12","url":"cs-AI/2025-10-12/papers/251010823v1-the-irrational-machine-neurosis-and-the-limits-of-algorithmic-safety.html"},{"id":"2510.13856v1","title":"Multimodal Retrieval-Augmented Generation with Large Language Models for Medical VQA","headline":"MasonNLP提出基于检索增强生成和通用大语言模型的医疗VQA方法，在MEDIQA-WV 2025竞赛中排名第三。","tag":"cs.CL","date":"2025-10-12","url":"cs-CL/2025-10-12/papers/251013856v1-multimodal-retrieval-augmented-generation-with-large-language-models.html"},{"id":"2510.10560v1","title":"BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices","headline":"BitMar：面向边缘设备的低比特多模态融合与情景记忆模型","tag":"cs.CL","date":"2025-10-12","url":"cs-CL/2025-10-12/papers/251010560v1-bitmar-low-bit-multimodal-fusion-with-episodic-memory-for-edge-devic.html"},{"id":"2510.10206v1","title":"It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots","headline":"Harmanoid：提出双人形机器人交互控制框架，实现高保真和物理真实的动作模仿。","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010206v1-it-takes-two-learning-interactive-whole-body-control-between-humanoi.html"},{"id":"2510.10274v1","title":"X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model","headline":"X-VLA：基于软提示Transformer的可扩展跨具身视觉-语言-动作模型","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010274v1-x-vla-soft-prompted-transformer-as-scalable-cross-embodiment-vision-.html"},{"id":"2510.09980v1","title":"ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots","headline":"ATRos：一种基于强化学习的轮腿机器人高效敏捷混合运动控制框架","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251009980v1-atros-learning-energy-efficient-agile-locomotion-for-wheeled-legged-.html"},{"id":"2510.21758v3","title":"Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review","headline":"综述强化学习在机器人与控制系统中的应用：分类、趋势与结构化回顾","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251021758v3-taxonomy-and-trends-in-reinforcement-learning-for-robotics-and-contr.html"},{"id":"2510.10125v2","title":"Ctrl-World: A Controllable Generative World Model for Robot Manipulation","headline":"提出Ctrl-World，用于机器人操作的可控生成世界模型，提升策略学习。","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010125v2-ctrl-world-a-controllable-generative-world-model-for-robot-manipulat.html"},{"id":"2510.10217v1","title":"UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction","headline":"提出UF-RNN，通过不确定性驱动的预测提升机器人实时自适应运动生成能力","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010217v1-uf-rnn-real-time-adaptive-motion-generation-using-uncertainty-driven.html"},{"id":"2510.09962v1","title":"VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping","headline":"VG-Mapping：面向半静态场景的变异感知3D高斯在线建图","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251009962v1-vg-mapping-variation-aware-3d-gaussians-for-online-semi-static-scene.html"},{"id":"2510.10181v2","title":"Dejavu: Towards Experience Feedback Learning for Embodied Intelligence","headline":"Dejavu：面向具身智能的经验反馈学习框架，提升部署后智能体性能","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010181v2-dejavu-towards-experience-feedback-learning-for-embodied-intelligenc.html"},{"id":"2510.10346v1","title":"sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking","headline":"提出基于平方根滤波的sqrtVINS，实现快速、鲁棒的三维运动跟踪。","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010346v1-sqrtvins-robust-and-ultrafast-square-root-filter-based-3d-motion-tra.html"},{"id":"2510.09963v1","title":"LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots","headline":"提出动态行为树构建框架以解决异构机器人协调问题","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251009963v1-llm-hbt-dynamic-behavior-tree-construction-for-adaptive-coordination.html"},{"id":"2510.10332v2","title":"Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework","headline":"提出基于SAC的深度强化学习框架，用于双阿克曼转向机器人的安全操控","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010332v2-towards-safe-maneuvering-of-double-ackermann-steering-robots-with-a-.html"},{"id":"2510.10357v1","title":"Learning to Throw-Flip","headline":"提出一种基于学习的投掷翻转方法，实现机器人对物体精确的姿态控制","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010357v1-learning-to-throw-flip.html"},{"id":"2510.10221v1","title":"A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots","headline":"提出A3RNN模型，通过双向融合自下而上和自上而下过程，实现机器人发育视觉注意力。","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010221v1-a3rnn-bi-directional-fusion-of-bottom-up-and-top-down-process-for-de.html"},{"id":"2510.10337v1","title":"Rise of the Robochemist","headline":"机器人化学家：融合机器人与AI，革新化学实验范式","tag":"cs.RO","date":"2025-10-11","url":"cs-RO/2025-10-11/papers/251010337v1-rise-of-the-robochemist.html"},{"id":"2510.10097v2","title":"Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting","headline":"Gesplat：基于几何引导高斯溅射的鲁棒无姿态3D重建","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010097v2-gesplat-robust-pose-free-3d-reconstruction-via-geometry-guided-gauss.html"},{"id":"2510.10257v1","title":"Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting","headline":"提出基于不透明度梯度的密度控制方法，提升少样本3D高斯溅射的效率和紧凑性。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010257v1-opacity-gradient-driven-density-control-for-compact-and-efficient-fe.html"},{"id":"2510.10104v1","title":"Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models","headline":"提出ACRE，通过一致性强化学习提升多模态大模型在视觉问答任务中的推理一致性。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010104v1-answer-consistent-chain-of-thought-reinforcement-learning-for-multi-.html"},{"id":"2510.10030v1","title":"P-4DGS: Predictive 4D Gaussian Splatting with 90$\\times$ Compression","headline":"提出P-4DGS以解决动态场景建模中的高内存消耗问题","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010030v1-p-4dgs-predictive-4d-gaussian-splatting-with-90times-compression.html"},{"id":"2510.10084v1","title":"Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework","headline":"提出基于视觉基础模型的滑坡疤痕时空演化追踪框架，实现连续监测与预警。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010084v1-tracking-the-spatiotemporal-evolution-of-landslide-scars-using-a-vis.html"},{"id":"2510.10011v1","title":"MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output","headline":"MIMO：一种具有视觉指代多模态输入和像素级定位多模态输出的医学视觉语言模型","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010011v1-mimo-a-medical-vision-language-model-with-visual-referring-multimoda.html"},{"id":"2510.10287v1","title":"Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking","headline":"提出DualViewDistill，利用基础模型引导的BEV地图提升3D目标检测与跟踪性能。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010287v1-bridging-perspectives-foundation-model-guided-bev-maps-for-3d-object.html"},{"id":"2510.10366v1","title":"Vision4PPG: Emergent PPG Analysis Capability of Vision Foundation Models for Vital Signs like Blood Pressure","headline":"Vision4PPG：利用视觉基础模型进行PPG分析，实现血压等生命体征的预测","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010366v1-vision4ppg-emergent-ppg-analysis-capability-of-vision-foundation-mod.html"},{"id":"2510.10111v2","title":"Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization","headline":"提出免训练的上下文取证链ICFC，用于图像篡改检测与定位","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010111v2-training-free-in-context-forensic-chain-for-image-manipulation-detec.html"},{"id":"2510.10068v2","title":"Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning","headline":"提出PHG-MAE模型，结合神经图和掩码自编码器，用于半监督多模态多任务学习。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010068v2-probabilistic-hyper-graphs-using-multiple-randomly-masked-autoencode.html"},{"id":"2510.10051v1","title":"Complementary and Contrastive Learning for Audio-Visual Segmentation","headline":"提出CCFormer，通过互补对比学习实现更精准的音视频分割","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010051v1-complementary-and-contrastive-learning-for-audio-visual-segmentation.html"},{"id":"2510.10342v1","title":"Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis","headline":"提出多模态融合框架，用于序数尺度下的交通拥堵等级分类","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010342v1-ordinal-scale-traffic-congestion-classification-with-multi-modal-vis.html"},{"id":"2510.10360v1","title":"Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation","headline":"Ortho-Fuse：通过光流估计为稀疏高分辨率作物健康地图生成正射影像","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010360v1-ortho-fuse-orthomosaic-generation-for-sparse-high-resolution-crop-he.html"},{"id":"2510.15963v2","title":"ESCA: Contextualizing Embodied Agents via Scene-Graph Generation","headline":"提出ESCA框架，通过场景图生成增强具身智能体的上下文感知能力","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251015963v2-esca-contextualizing-embodied-agents-via-scene-graph-generation.html"},{"id":"2510.10196v1","title":"From Generic to Specialized: A Subspecialty Diagnostic System Powered by Self-Supervised Learning for Cervical Histopathology","headline":"CerS-Path：基于自监督学习的宫颈组织病理亚专科诊断系统","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010196v1-from-generic-to-specialized-a-subspecialty-diagnostic-system-powered.html"},{"id":"2510.17847v1","title":"CoIDO: Efficient Data Selection for Visual Instruction Tuning via Coupled Importance-Diversity Optimization","headline":"CoIDO：通过耦合重要性-多样性优化实现视觉指令调优的高效数据选择","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251017847v1-coido-efficient-data-selection-for-visual-instruction-tuning-via-cou.html"},{"id":"2510.10022v1","title":"Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning","headline":"提出Q-Adapter，通过可学习查询token高效提取视频字幕相关视觉特征，实现参数高效的视频字幕生成。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010022v1-q-adapter-visual-query-adapter-for-extracting-textually-related-feat.html"},{"id":"2510.09981v1","title":"Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making","headline":"提出基于AI和语言模型的交通摄像头系统，用于大规模交通洞察和数据驱动的决策","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251009981v1-scaling-traffic-insights-with-ai-and-language-model-powered-camera-s.html"},{"id":"2510.09936v1","title":"Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification","headline":"提出一种半解耦时空隐式神经表示方法，用于纵向神经影像数据的轨迹分类。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251009936v1-semi-disentangled-spatiotemporal-implicit-neural-representations-of-.html"},{"id":"2510.10194v2","title":"B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding","headline":"提出B2N3D框架，通过二元到N元关系渐进学习实现更精确的3D物体定位","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010194v2-b2n3d-progressive-learning-from-binary-to-n-ary-relationships-for-3d.html"},{"id":"2510.10160v2","title":"SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation","headline":"提出SaFiRe框架，利用Mamba解决指代图像分割中复杂表达式的难题。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010160v2-safire-saccade-fixation-reiteration-with-mamba-for-referring-image-s.html"},{"id":"2510.10152v1","title":"Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer","headline":"Color3D：基于个性化着色器的可控一致3D着色框架","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010152v1-color3d-controllable-and-consistent-3d-colorization-with-personalize.html"},{"id":"2510.13652v1","title":"EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection","headline":"EditCast3D：利用视频传播和视图选择实现单帧引导的3D编辑","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251013652v1-editcast3d-single-frame-guided-3d-editing-with-video-propagation-and.html"},{"id":"2510.10292v1","title":"From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries","headline":"FactoredScenes：通过学习程序库生成可分解的真实世界场景，解决数据稀缺问题。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010292v1-from-programs-to-poses-factored-real-world-scene-generation-via-lear.html"},{"id":"2510.10073v1","title":"SecureWebArena: A Holistic Security Evaluation Benchmark for LVLM-based Web Agents","headline":"SecureWebArena：LVLM Web Agent安全评估的综合基准","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251010073v1-securewebarena-a-holistic-security-evaluation-benchmark-for-lvlm-bas.html"},{"id":"2510.09996v1","title":"BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes","headline":"提出BurstDeflicker数据集，用于动态场景下图像闪烁消除研究。","tag":"cs.CV","date":"2025-10-11","url":"cs-CV/2025-10-11/papers/251009996v1-burstdeflicker-a-benchmark-dataset-for-flicker-removal-in-dynamic-sc.html"},{"id":"2510.09997v1","title":"CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting","headline":"CLoD-GS：提出基于3D高斯溅射的连续细节层次方法，解决离散LoD的存储和伪影问题。","tag":"cs.GR","date":"2025-10-11","url":"cs-GR/2025-10-11/papers/251009997v1-clod-gs-continuous-level-of-detail-via-3d-gaussian-splatting.html"},{"id":"2510.09976v1","title":"Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models","headline":"提出Flow Policy Optimization (FPO)算法，用于强化微调视觉-语言-动作模型的Flow-Matching策略。","tag":"cs.LG","date":"2025-10-11","url":"cs-LG/2025-10-11/papers/251009976v1-reinforcement-fine-tuning-of-flow-matching-policies-for-vision-langu.html"},{"id":"2510.10188v1","title":"INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction","headline":"提出INR-Bench：多领域回归与重建的隐式神经表示统一基准","tag":"cs.LG","date":"2025-10-11","url":"cs-LG/2025-10-11/papers/251010188v1-inr-bench-a-unified-benchmark-for-implicit-neural-representations-in.html"},{"id":"2510.10281v1","title":"ArtPerception: ASCII Art-based Jailbreak on LLMs with Recognition Pre-test","headline":"ArtPerception：提出基于ASCII艺术的LLM越狱框架，通过识别预测试提升攻击效率。","tag":"cs.AI","date":"2025-10-11","url":"cs-AI/2025-10-11/papers/251010281v1-artperception-ascii-art-based-jailbreak-on-llms-with-recognition-pre.html"},{"id":"2510.08884v2","title":"Model-Based Lookahead Reinforcement Learning for in-hand manipulation","headline":"提出基于模型的预测强化学习方法，提升灵巧手操作性能","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251008884v2-model-based-lookahead-reinforcement-learning-for-in-hand-manipulatio.html"},{"id":"2510.09221v1","title":"HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation","headline":"提出HANDO框架，实现腿式机器人自主导航与灵巧全方位移动操作","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009221v1-hando-hierarchical-autonomous-navigation-and-dexterous-omni-loco-man.html"},{"id":"2510.09229v1","title":"Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System","headline":"Glovity：基于空间力/力矩反馈遥操作系统学习灵巧的接触丰富操作","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009229v1-glovity-learning-dexterous-contact-rich-manipulation-via-spatial-wre.html"},{"id":"2510.09786v1","title":"Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks","headline":"提出基于无分类器引导的扩散策略CFG-DP，提升时序机器人任务性能","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009786v1-enhancing-diffusion-policy-with-classifier-free-guidance-for-tempora.html"},{"id":"2510.09526v1","title":"Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing","headline":"提出一种基于结构重用的动态四足腿式与飞行运动融合方案","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009526v1-dynamic-quadrupedal-legged-and-aerial-locomotion-via-structure-repur.html"},{"id":"2510.09209v1","title":"PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation","headline":"PLEXUS Hand：轻量化四电机假肢手，实现精确横向灵巧操作","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009209v1-plexus-hand-lightweight-four-motor-prosthetic-hand-enabling-precisio.html"},{"id":"2510.09036v1","title":"iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation","headline":"提出iMoWM，利用交互式多模态世界模型提升机器人操作能力","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009036v1-imowm-taming-interactive-multi-modal-world-model-for-robotic-manipul.html"},{"id":"2510.09543v2","title":"Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards","headline":"通过冲击缓解奖励引导能量高效的机器人运动","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009543v2-guiding-energy-efficient-locomotion-through-impact-mitigation-reward.html"},{"id":"2510.09204v1","title":"Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization","headline":"Flow-Opt：基于流匹配和可微优化的可扩展集中式多机器人轨迹优化","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009204v1-flow-opt-scalable-centralized-multi-robot-trajectory-optimization-wi.html"},{"id":"2510.09254v1","title":"Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning","headline":"提出基于DMP和强化学习的避障方法，仅需单次演示即可快速生成平滑轨迹。","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009254v1-obstacle-avoidance-using-dynamic-movement-primitives-and-reinforceme.html"},{"id":"2510.09459v2","title":"Failure Prediction at Runtime for Generative Robot Policies","headline":"FIPER：为生成式机器人策略提供运行时的故障预测框架","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009459v2-failure-prediction-at-runtime-for-generative-robot-policies.html"},{"id":"2510.09396v1","title":"Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems","headline":"Surrealist框架：基于仿真的工业机器人导航系统测试与验证","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009396v1-bridging-research-and-practice-in-simulation-based-testing-of-indust.html"},{"id":"2510.21751v1","title":"Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning","headline":"提出基于MIQP的实时轨迹规划方法，解决自动驾驶车辆通过减速带时的舒适性问题。","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251021751v1-real-time-mixed-integer-quadratic-programming-for-driving-behavior-i.html"},{"id":"2510.09096v1","title":"When a Robot is More Capable than a Human: Learning from Constrained Demonstrators","headline":"利用受限示教者数据，机器人学习超越人类能力的策略","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009096v1-when-a-robot-is-more-capable-than-a-human-learning-from-constrained-.html"},{"id":"2510.09483v1","title":"FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents","headline":"提出FOGMACHINE以解决部分观察下的动态环境建模问题","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009483v1-fogmachine-leveraging-discrete-event-simulation-and-scene-graphs-for.html"},{"id":"2510.09267v1","title":"Placeit! A Framework for Learning Robot Object Placement Skills","headline":"Placeit!：用于学习机器人物体放置技能的进化计算框架","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009267v1-placeit-a-framework-for-learning-robot-object-placement-skills.html"},{"id":"2510.09323v1","title":"Parametrized Topological Complexity for a Multi-Robot System with Variable Tasks","headline":"针对多机器人变任务系统，提出参数化拓扑复杂度的运动规划方法","tag":"cs.RO","date":"2025-10-10","url":"cs-RO/2025-10-10/papers/251009323v1-parametrized-topological-complexity-for-a-multi-robot-system-with-va.html"},{"id":"2510.09364v1","title":"Visibility-Aware Densification for 3D Gaussian Splatting in Dynamic Urban Scenes","headline":"VAD-GS：面向动态城市场景，基于可见性推理的3D高斯溅射稠密化方法","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009364v1-visibility-aware-densification-for-3d-gaussian-splatting-in-dynamic-.html"},{"id":"2510.09607v2","title":"VITA-VLA: Efficiently Teaching Vision-Language Models to Act via Action Expert Distillation","headline":"提出VITA-VLA，通过动作专家蒸馏高效训练视觉-语言模型以执行机器人动作","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009607v2-vita-vla-efficiently-teaching-vision-language-models-to-act-via-acti.html"},{"id":"2510.09230v1","title":"Diagnosing Shoulder Disorders Using Multimodal Large Language Models and Consumer-Grade Cameras","headline":"提出多模态大语言模型以解决肩部疾病诊断问题","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009230v1-diagnosing-shoulder-disorders-using-multimodal-large-language-models.html"},{"id":"2510.09285v1","title":"Spotlight on Token Perception for Multimodal Reinforcement Learning","headline":"提出VPPO，通过关注token感知优化多模态强化学习，提升LVLM的推理能力。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009285v1-spotlight-on-token-perception-for-multimodal-reinforcement-learning.html"},{"id":"2510.09507v1","title":"PhysToolBench: Benchmarking Physical Tool Understanding for MLLMs","headline":"PhysToolBench：首个面向MLLM的物理工具理解能力评测基准","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009507v1-phystoolbench-benchmarking-physical-tool-understanding-for-mllms.html"},{"id":"2510.09320v1","title":"Hybrid-grained Feature Aggregation with Coarse-to-fine Language Guidance for Self-supervised Monocular Depth Estimation","headline":"提出Hybrid-depth框架，利用粗细粒度特征融合和语言引导提升自监督单目深度估计性能","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009320v1-hybrid-grained-feature-aggregation-with-coarse-to-fine-language-guid.html"},{"id":"2510.09269v1","title":"Goal-oriented Backdoor Attack against Vision-Language-Action Models via Physical Objects","headline":"提出面向视觉-语言-动作模型的物理对象后门攻击GoBA，实现目标导向的恶意行为。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009269v1-goal-oriented-backdoor-attack-against-vision-language-action-models-.html"},{"id":"2510.09361v1","title":"BLINK-Twice: You see, but do you observe? A Reasoning Benchmark on Visual Perception","headline":"BLINK-Twice：提出视觉感知推理基准，强调细粒度观察与分析，挑战多模态大语言模型。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009361v1-blink-twice-you-see-but-do-you-observe-a-reasoning-benchmark-on-visu.html"},{"id":"2510.09586v1","title":"Vision Language Models: A Survey of 26K Papers","headline":"大规模视觉语言模型研究趋势分析：基于2.6万篇论文的综合调研","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009586v1-vision-language-models-a-survey-of-26k-papers.html"},{"id":"2510.09182v1","title":"Online Video Depth Anything: Temporally-Consistent Depth Prediction with Low Memory Consumption","headline":"提出oVDA，通过缓存和掩码技术实现低内存、在线视频深度估计","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009182v1-online-video-depth-anything-temporally-consistent-depth-prediction-w.html"},{"id":"2510.09367v1","title":"Minkowski-MambaNet: A Point Cloud Framework with Selective State Space Models for Forest Biomass Quantification","headline":"提出Minkowski-MambaNet，利用选择性状态空间模型进行森林生物量量化。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009367v1-minkowski-mambanet-a-point-cloud-framework-with-selective-state-spac.html"},{"id":"2510.08964v1","title":"Unleashing Perception-Time Scaling to Multimodal Reasoning Models","headline":"提出感知时间尺度调整(PTS)，提升多模态推理模型在视觉感知任务中的精度。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251008964v1-unleashing-perception-time-scaling-to-multimodal-reasoning-models.html"},{"id":"2510.09822v1","title":"Task-Aware Resolution Optimization for Visual Large Language Models","headline":"提出任务感知分辨率优化方法，提升视觉大语言模型在不同任务上的性能","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009822v1-task-aware-resolution-optimization-for-visual-large-language-models.html"},{"id":"2510.09815v1","title":"Towards Understanding Ambiguity Resolution in Multimodal Inference of Meaning","headline":"研究多模态语境下外语学习者对词义歧义消解的推理能力","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009815v1-towards-understanding-ambiguity-resolution-in-multimodal-inference-o.html"},{"id":"2510.09358v1","title":"Boosting Multi-modal Keyphrase Prediction with Dynamic Chain-of-Thought in Vision-Language Models","headline":"提出动态链式思考方法，提升视觉-语言模型在多模态关键短语预测任务上的性能","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009358v1-boosting-multi-modal-keyphrase-prediction-with-dynamic-chain-of-thou.html"},{"id":"2510.09224v2","title":"Tag-Enriched Multi-Attention with Large Language Models for Cross-Domain Sequential Recommendation","headline":"提出TEMA-LLM，利用LLM增强的多注意力机制解决跨域序列推荐问题","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009224v2-tag-enriched-multi-attention-with-large-language-models-for-cross-do.html"},{"id":"2510.09203v1","title":"Cattle-CLIP: A Multimodal Framework for Cattle Behaviour Recognition","headline":"Cattle-CLIP：利用多模态学习框架进行牛行为识别，提升数据稀缺场景下的性能。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009203v1-cattle-clip-a-multimodal-framework-for-cattle-behaviour-recognition.html"},{"id":"2510.09121v2","title":"MSDM: Generating Task-Specific Pathology Images with a Multimodal Conditioned Diffusion Model for Cell and Nuclei Segmentation","headline":"提出MSDM，一种多模态条件扩散模型，用于生成细胞和细胞核分割任务的病理图像。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009121v2-msdm-generating-task-specific-pathology-images-with-a-multimodal-con.html"},{"id":"2510.09088v1","title":"MambaH-Fit: Rethinking Hyper-surface Fitting-based Point Cloud Normal Estimation via State Space Modelling","headline":"提出MambaH-Fit，利用状态空间模型提升点云法向量估计精度","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009088v1-mambah-fit-rethinking-hyper-surface-fitting-based-point-cloud-normal.html"},{"id":"2510.09110v3","title":"Synthetic Object Compositions for Scalable and Accurate Learning in Detection, Segmentation, and Grounding","headline":"提出SOC：一种可扩展、精确的合成对象组合方法，用于提升检测、分割和定位任务性能。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009110v3-synthetic-object-compositions-for-scalable-and-accurate-learning-in-.html"},{"id":"2510.09299v1","title":"Foraging with the Eyes: Dynamics in Human Visual Gaze and Deep Predictive Modeling","headline":"揭示人类视觉搜寻模式：基于眼动数据的Levy行走与深度预测模型","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009299v1-foraging-with-the-eyes-dynamics-in-human-visual-gaze-and-deep-predic.html"},{"id":"2510.09741v1","title":"Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping","headline":"提出AttWarp，利用注意力引导图像扭曲提升多模态大语言模型性能","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009741v1-constructive-distortion-improving-mllms-with-attention-guided-image-.html"},{"id":"2510.09302v1","title":"CapGeo: A Caption-Assisted Approach to Geometric Reasoning","headline":"CapGeo：一种基于图文描述的几何推理方法","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009302v1-capgeo-a-caption-assisted-approach-to-geometric-reasoning.html"},{"id":"2510.08978v1","title":"HandEval: Taking the First Step Towards Hand Quality Evaluation in Generated Images","headline":"提出HandEval，用于评估生成图像中手部质量，提升AIGC应用效果。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251008978v1-handeval-taking-the-first-step-towards-hand-quality-evaluation-in-ge.html"},{"id":"2510.08976v1","title":"Hierarchical Scheduling for Multi-Vector Image Retrieval","headline":"HiMIR：面向多向量图像检索的分层调度框架，提升精度和效率","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251008976v1-hierarchical-scheduling-for-multi-vector-image-retrieval.html"},{"id":"2510.09903v1","title":"An uncertainty-aware framework for data-efficient multi-view animal pose estimation","headline":"提出不确定性感知框架，高效解决数据稀缺下的多视角动物姿态估计问题","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009903v1-an-uncertainty-aware-framework-for-data-efficient-multi-view-animal-.html"},{"id":"2510.09314v1","title":"RadioFlow: Efficient Radio Map Construction Framework with Flow Matching","headline":"提出RadioFlow以解决无线电图生成效率低的问题","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009314v1-radioflow-efficient-radio-map-construction-framework-with-flow-match.html"},{"id":"2510.09171v1","title":"Instance-Level Generation for Representation Learning","headline":"提出一种实例级别生成方法，无需真实图像即可提升实例识别表征学习。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009171v1-instance-level-generation-for-representation-learning.html"},{"id":"2510.08919v1","title":"PHyCLIP: $\\ell_1$-Product of Hyperbolic Factors Unifies Hierarchy and Compositionality in Vision-Language Representation Learning","headline":"提出PHyCLIP以解决视觉语言表示学习中的层次与组合性问题","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251008919v1-phyclip-ell-1-product-of-hyperbolic-factors-unifies-hierarchy-and-co.html"},{"id":"2510.09881v1","title":"LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates","headline":"LTGS：基于稀疏视图更新的长时高斯场景时间线建模","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009881v1-ltgs-long-term-gaussian-scene-chronology-from-sparse-view-updates.html"},{"id":"2510.09880v1","title":"Geometry-Aware Scene Configurations for Novel View Synthesis","headline":"提出几何感知场景配置方法，提升室内场景新视角合成效果","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009880v1-geometry-aware-scene-configurations-for-novel-view-synthesis.html"},{"id":"2510.09537v1","title":"FLOWING: Implicit Neural Flows for Structure-Preserving Morphing","headline":"FLOWING：提出隐式神经流方法，实现结构保持的形变","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009537v1-flowing-implicit-neural-flows-for-structure-preserving-morphing.html"},{"id":"2510.09867v1","title":"Cluster-Aware Prompt Ensemble Learning for Few-Shot Vision-Language Model Adaptation","headline":"提出聚类感知的提示集成学习框架，提升少样本视觉-语言模型的适应性","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009867v1-cluster-aware-prompt-ensemble-learning-for-few-shot-vision-language-.html"},{"id":"2510.09008v1","title":"On Epistemic Uncertainty of Visual Tokens for Object Hallucinations in Large Vision-Language Models","headline":"针对大视觉语言模型中的对象幻觉，提出基于视觉token认知不确定性的缓解方法","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009008v1-on-epistemic-uncertainty-of-visual-tokens-for-object-hallucinations-.html"},{"id":"2510.08936v1","title":"RO-Bench: Large-scale robustness evaluation of MLLMs with text-driven counterfactual videos","headline":"提出RO-Bench，用于大规模评估MLLM在文本驱动对抗视频上的鲁棒性","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251008936v1-ro-bench-large-scale-robustness-evaluation-of-mllms-with-text-driven.html"},{"id":"2510.09450v1","title":"Dynamic Weight-based Temporal Aggregation for Low-light Video Enhancement","headline":"提出DWTA-Net，通过动态权重时序聚合增强低光视频质量，有效抑制噪声。","tag":"cs.CV","date":"2025-10-10","url":"cs-CV/2025-10-10/papers/251009450v1-dynamic-weight-based-temporal-aggregation-for-low-light-video-enhanc.html"},{"id":"2510.09489v1","title":"Two-Stage Gaussian Splatting Optimization for Outdoor Scene Reconstruction","headline":"提出双阶段高斯溅射优化框架，提升户外场景重建质量。","tag":"cs.GR","date":"2025-10-10","url":"cs-GR/2025-10-10/papers/251009489v1-two-stage-gaussian-splatting-optimization-for-outdoor-scene-reconstr.html"},{"id":"2510.08938v1","title":"Bi-level Meta-Policy Control for Dynamic Uncertainty Calibration in Evidential Deep Learning","headline":"提出双层元策略控制以解决动态不确定性校准问题","tag":"cs.LG","date":"2025-10-10","url":"cs-LG/2025-10-10/papers/251008938v1-bi-level-meta-policy-control-for-dynamic-uncertainty-calibration-in-.html"},{"id":"2510.09722v1","title":"Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation","headline":"提出布局感知的高效LLM框架，用于简历信息抽取与评估。","tag":"cs.CL","date":"2025-10-10","url":"cs-CL/2025-10-10/papers/251009722v1-layout-aware-parsing-meets-efficient-llms-a-unified-scalable-framewo.html"},{"id":"2510.08475v1","title":"DexMan: Learning Bimanual Dexterous Manipulation from Human and Generated Videos","headline":"DexMan：从人类和生成视频中学习双手动灵巧操作","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008475v1-dexman-learning-bimanual-dexterous-manipulation-from-human-and-gener.html"},{"id":"2510.07882v2","title":"Towards Proprioception-Aware Embodied Planning for Dual-Arm Humanoid Robots","headline":"提出Proprio-MLLM，增强双臂人形机器人具身规划的本体感知能力","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007882v2-towards-proprioception-aware-embodied-planning-for-dual-arm-humanoid.html"},{"id":"2510.08807v1","title":"Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation","headline":"Humanoid Everyday：一个面向开放世界人型机器人操作的综合数据集","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008807v1-humanoid-everyday-a-comprehensive-robotic-dataset-for-open-world-hum.html"},{"id":"2510.07725v1","title":"Probabilistically-Safe Bipedal Navigation over Uncertain Terrain via Conformal Prediction and Contraction Analysis","headline":"提出基于一致性预测和收缩分析的概率安全双足机器人导航方法，解决地形不确定性下的稳健行走问题。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007725v1-probabilistically-safe-bipedal-navigation-over-uncertain-terrain-via.html"},{"id":"2510.07869v3","title":"USIM and U0: A Vision-Language-Action Dataset and Model for General Underwater Robots","headline":"提出USIM和U0以解决水下机器人多任务智能问题","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007869v3-usim-and-u0-a-vision-language-action-dataset-and-model-for-general-u.html"},{"id":"2510.08464v1","title":"Don't Run with Scissors: Pruning Breaks VLA Models but They Can Be Recovered","headline":"提出GLUESTICK，用于恢复剪枝后VLA模型性能，提升机器人操作和导航安全性","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008464v1-dont-run-with-scissors-pruning-breaks-vla-models-but-they-can-be-rec.html"},{"id":"2510.08754v1","title":"Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis","headline":"提出基于全身模型预测控制的四足机器人乒乓球系统，实现高速高精度回球","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008754v1-whole-body-model-predictive-control-for-spin-aware-quadrupedal-table.html"},{"id":"2510.07773v1","title":"Trajectory Conditioned Cross-embodiment Skill Transfer","headline":"TrajSkill：基于轨迹条件的跨具身操作技能迁移框架","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007773v1-trajectory-conditioned-cross-embodiment-skill-transfer.html"},{"id":"2510.08568v1","title":"NovaFlow: Zero-Shot Manipulation via Actionable Flow from Generated Videos","headline":"NovaFlow：通过生成视频中的可执行光流实现机器人零样本操作","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008568v1-novaflow-zero-shot-manipulation-via-actionable-flow-from-generated-v.html"},{"id":"2510.08547v1","title":"R2RGEN: Real-to-Real 3D Data Generation for Spatially Generalized Manipulation","headline":"提出R2RGen，用于生成真实3D数据，提升机器人空间泛化操作能力。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008547v1-r2rgen-real-to-real-3d-data-generation-for-spatially-generalized-man.html"},{"id":"2510.07975v1","title":"Executable Analytic Concepts as the Missing Link Between VLM Insight and Precise Manipulation","headline":"提出GRACE框架以解决机器人精确操作与语义理解之间的鸿沟","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007975v1-executable-analytic-concepts-as-the-missing-link-between-vlm-insight.html"},{"id":"2510.07778v1","title":"IntentionVLA: Generalizable and Efficient Embodied Intention Reasoning for Human-Robot Interaction","headline":"IntentionVLA：面向人机交互的可泛化高效具身意图推理框架","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007778v1-intentionvla-generalizable-and-efficient-embodied-intention-reasonin.html"},{"id":"2510.08811v1","title":"Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration","headline":"提出基于接触意图推断的自适应运动规划，用于人机协作。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008811v1-adaptive-motion-planning-via-contact-based-intent-inference-for-huma.html"},{"id":"2510.08173v1","title":"NavSpace: How Navigation Agents Follow Spatial Intelligence Instructions","headline":"提出NavSpace基准测试，评估并提升导航Agent的空间智能","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008173v1-navspace-how-navigation-agents-follow-spatial-intelligence-instructi.html"},{"id":"2510.08022v1","title":"FastUMI-100K: Advancing Data-driven Robotic Manipulation with a Large-scale UMI-style Dataset","headline":"FastUMI-100K：大规模UMI风格数据集，推进数据驱动的机器人操作学习","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008022v1-fastumi-100k-advancing-data-driven-robotic-manipulation-with-a-large.html"},{"id":"2510.08556v1","title":"DexNDM: Closing the Reality Gap for Dexterous In-Hand Rotation via Joint-Wise Neural Dynamics Model","headline":"提出DexNDM，通过关节级神经动力学模型弥合灵巧手内旋转的现实差距","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008556v1-dexndm-closing-the-reality-gap-for-dexterous-in-hand-rotation-via-jo.html"},{"id":"2510.07674v2","title":"Differentiable Particle Optimization for Fast Sequential Manipulation","headline":"提出SPaSM以解决实时顺序机器人操作问题","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007674v2-differentiable-particle-optimization-for-fast-sequential-manipulatio.html"},{"id":"2510.07865v1","title":"DM1: MeanFlow with Dispersive Regularization for 1-Step Robotic Manipulation","headline":"DM1：通过分散正则化的MeanFlow实现单步机器人操作，解决表示崩溃问题。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007865v1-dm1-meanflow-with-dispersive-regularization-for-1-step-robotic-manip.html"},{"id":"2510.08851v1","title":"CDE: Concept-Driven Exploration for Reinforcement Learning","headline":"提出概念驱动探索(CDE)方法，解决视觉强化学习中高效探索问题","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008851v1-cde-concept-driven-exploration-for-reinforcement-learning.html"},{"id":"2510.08044v1","title":"Towards Reliable LLM-based Robot Planning via Combined Uncertainty Estimation","headline":"提出CURE，结合不确定性估计，提升LLM机器人规划的可靠性","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008044v1-towards-reliable-llm-based-robot-planning-via-combined-uncertainty-e.html"},{"id":"2510.08572v1","title":"BLAZER: Bootstrapping LLM-based Manipulation Agents with Zero-Shot Data Generation","headline":"BLAZER：利用零样本数据生成引导基于LLM的机器人操作代理","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008572v1-blazer-bootstrapping-llm-based-manipulation-agents-with-zero-shot-da.html"},{"id":"2510.07700v1","title":"EB-MBD: Emerging-Barrier Model-Based Diffusion for Safe Trajectory Optimization in Highly Constrained Environments","headline":"提出基于新兴障碍函数的模型扩散方法，用于高约束环境下的安全轨迹优化。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007700v1-eb-mbd-emerging-barrier-model-based-diffusion-for-safe-trajectory-op.html"},{"id":"2510.08787v1","title":"Geometry-aware Policy Imitation","headline":"提出几何感知策略模仿(GPI)，解决机器人模仿学习中效率和泛化性问题。","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008787v1-geometry-aware-policy-imitation.html"},{"id":"2510.07871v3","title":"Learning to Navigate Socially Through Proactive Risk Perception","headline":"提出基于主动风险感知的社交导航方法，提升动态人群环境下的机器人导航能力","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251007871v3-learning-to-navigate-socially-through-proactive-risk-perception.html"},{"id":"2510.08705v1","title":"ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing","headline":"ConPoSe：基于LLM引导的接触点选择，实现可扩展的协作物体推移","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008705v1-conpose-llm-guided-contact-point-selection-for-scalable-cooperative-.html"},{"id":"2510.08270v1","title":"Evaluation of a Robust Control System in Real-World Cable-Driven Parallel Robots","headline":"TRPO在欠驱动缆索驱动并联机器人控制中表现出卓越的鲁棒性","tag":"cs.RO","date":"2025-10-09","url":"cs-RO/2025-10-09/papers/251008270v1-evaluation-of-a-robust-control-system-in-real-world-cable-driven-par.html"},{"id":"2510.08096v1","title":"Efficient Label Refinement for Face Parsing Under Extreme Poses Using 3D Gaussian Splatting","headline":"利用3D高斯溅射进行人脸解析标签优化，提升极端姿态下的解析精度","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008096v1-efficient-label-refinement-for-face-parsing-under-extreme-poses-usin.html"},{"id":"2510.07830v1","title":"PrismGS: Physically-Grounded Anti-Aliasing for High-Fidelity Large-Scale 3D Gaussian Splatting","headline":"PrismGS：面向大规模高保真3D高斯溅射的物理约束抗锯齿方法","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007830v1-prismgs-physically-grounded-anti-aliasing-for-high-fidelity-large-sc.html"},{"id":"2510.07752v2","title":"DEGS: Deformable Event-based 3D Gaussian Splatting from RGB and Event Stream","headline":"提出DEGS，结合RGB和事件流实现可变形的动态3D高斯溅射","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007752v2-degs-deformable-event-based-3d-gaussian-splatting-from-rgb-and-event.html"},{"id":"2510.08480v1","title":"Video-STAR: Reinforcing Open-Vocabulary Action Recognition with Tools","headline":"Video-STAR：利用工具增强的强化学习进行开放词汇动作识别","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008480v1-video-star-reinforcing-open-vocabulary-action-recognition-with-tools.html"},{"id":"2510.08565v1","title":"NaViL: Rethinking Scaling Properties of Native Multimodal Large Language Models under Data Constraints","headline":"NaViL：数据约束下原生多模态大语言模型缩放特性的再思考","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008565v1-navil-rethinking-scaling-properties-of-native-multimodal-large-langu.html"},{"id":"2510.07856v2","title":"XYZCylinder: Towards Compatible Feed-Forward 3D Gaussian Splatting for Driving Scenes via Unified Cylinder Lifting Method","headline":"XYZCylinder：通过统一柱面提升方法实现兼容的驾驶场景3D高斯溅射","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007856v2-xyzcylinder-towards-compatible-feed-forward-3d-gaussian-splatting-fo.html"},{"id":"2510.08849v1","title":"FOLK: Fast Open-Vocabulary 3D Instance Segmentation via Label-guided Knowledge Distillation","headline":"提出FOLK，通过标签引导的知识蒸馏实现快速开放词汇3D实例分割","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008849v1-folk-fast-open-vocabulary-3d-instance-segmentation-via-label-guided-.html"},{"id":"2510.08566v1","title":"D$^2$GS: Depth-and-Density Guided Gaussian Splatting for Stable and Accurate Sparse-View Reconstruction","headline":"D$^2$GS：深度与密度引导的高斯溅射，用于稳定且精确的稀疏视角重建","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008566v1-d2gs-depth-and-density-guided-gaussian-splatting-for-stable-and-accu.html"},{"id":"2510.08003v1","title":"CIR-CoT: Towards Interpretable Composed Image Retrieval via End-to-End Chain-of-Thought Reasoning","headline":"提出CIR-CoT，通过端到端思维链推理实现可解释的组合图像检索","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008003v1-cir-cot-towards-interpretable-composed-image-retrieval-via-end-to-en.html"},{"id":"2510.08559v1","title":"SciVideoBench: Benchmarking Scientific Video Reasoning in Large Multimodal Models","headline":"SciVideoBench：提出科学视频推理基准，评估大型多模态模型在科学领域的认知能力。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008559v1-scivideobench-benchmarking-scientific-video-reasoning-in-large-multi.html"},{"id":"2510.08316v1","title":"Unlocking 3D Affordance Segmentation with 2D Semantic Knowledge","headline":"提出CMAT和CAST，利用2D语义知识提升3D可供性分割性能","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008316v1-unlocking-3d-affordance-segmentation-with-2d-semantic-knowledge.html"},{"id":"2510.08540v2","title":"MM-HELIX: Boosting Multimodal Long-Chain Reflective Reasoning with Holistic Platform and Adaptive Hybrid Policy Optimization","headline":"MM-HELIX：通过整体平台和自适应混合策略优化提升多模态长链反思推理能力","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008540v2-mm-helix-boosting-multimodal-long-chain-reflective-reasoning-with-ho.html"},{"id":"2510.08278v2","title":"A Multimodal Depth-Aware Method For Embodied Reference Understanding","headline":"提出一种多模态深度感知方法，用于具身引用理解任务。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008278v2-a-multimodal-depth-aware-method-for-embodied-reference-understanding.html"},{"id":"2510.08759v1","title":"BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities","headline":"BEAR：原子具身能力的多模态语言模型基准测试与增强","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008759v1-bear-benchmarking-and-enhancing-multimodal-language-models-for-atomi.html"},{"id":"2510.08157v1","title":"Beyond Textual CoT: Interleaved Text-Image Chains with Deep Confidence Reasoning for Image Editing","headline":"提出MURE框架，利用交错文本-图像链和深度置信推理进行图像编辑","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008157v1-beyond-textual-cot-interleaved-text-image-chains-with-deep-confidenc.html"},{"id":"2510.08567v3","title":"MATRIX: Multimodal Agent Tuning for Robust Tool-Use Reasoning","headline":"提出MATRIX框架，通过多模态Agent调优实现稳健的工具使用推理","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008567v3-matrix-multimodal-agent-tuning-for-robust-tool-use-reasoning.html"},{"id":"2510.08260v1","title":"Fine-grained text-driven dual-human motion generation via dynamic hierarchical interaction","headline":"提出FineDual，通过动态分层交互生成细粒度文本驱动的双人运动","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008260v1-fine-grained-text-driven-dual-human-motion-generation-via-dynamic-hi.html"},{"id":"2510.07944v2","title":"CVD-STORM: Cross-View Video Diffusion with Spatial-Temporal Reconstruction Model for Autonomous Driving","headline":"提出CVD-STORM，利用时空重建扩散模型生成自动驾驶多视角长视频，并具备4D重建能力。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007944v2-cvd-storm-cross-view-video-diffusion-with-spatial-temporal-reconstru.html"},{"id":"2510.08673v1","title":"Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation","headline":"Puffin：提出统一的多模态模型，实现相机视角的理解与生成","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008673v1-thinking-with-camera-a-unified-multimodal-model-for-camera-centric-u.html"},{"id":"2510.07915v1","title":"MARC: Memory-Augmented RL Token Compression for Efficient Video Understanding","headline":"提出MARC：一种基于记忆增强强化学习的视频token压缩方法，用于高效视频理解。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007915v1-marc-memory-augmented-rl-token-compression-for-efficient-video-under.html"},{"id":"2510.07636v1","title":"PIT-QMM: A Large Multimodal Model For No-Reference Point Cloud Quality Assessment","headline":"提出PIT-QMM，一种用于无参考点云质量评估的大型多模态模型","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007636v1-pit-qmm-a-large-multimodal-model-for-no-reference-point-cloud-qualit.html"},{"id":"2510.08553v1","title":"Dream to Recall: Imagination-Guided Experience Retrieval for Memory-Persistent Vision-and-Language Navigation","headline":"Memoir：提出基于想象引导的经验检索方法，提升记忆持久性视觉语言导航性能。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008553v1-dream-to-recall-imagination-guided-experience-retrieval-for-memory-p.html"},{"id":"2510.08555v1","title":"VideoCanvas: Unified Video Completion from Arbitrary Spatiotemporal Patches via In-Context Conditioning","headline":"VideoCanvas：通过上下文条件反射实现任意时空补丁的统一视频补全","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008555v1-videocanvas-unified-video-completion-from-arbitrary-spatiotemporal-p.html"},{"id":"2510.08508v1","title":"MoA-VR: A Mixture-of-Agents System Towards All-in-One Video Restoration","headline":"提出MoA-VR，一个混合Agent的通用视频修复系统，有效处理复杂退化。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008508v1-moa-vr-a-mixture-of-agents-system-towards-all-in-one-video-restorati.html"},{"id":"2510.08485v1","title":"InstructX: Towards Unified Visual Editing with MLLM Guidance","headline":"InstructX：基于MLLM指导的统一视觉编辑框架，实现图像和视频编辑","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008485v1-instructx-towards-unified-visual-editing-with-mllm-guidance.html"},{"id":"2510.08482v2","title":"The Visual Iconicity Challenge: Evaluating Vision-Language Models on Sign Language Form-Meaning Mapping","headline":"提出视觉标志性挑战，评估视觉-语言模型在手语形式-意义映射上的能力。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008482v2-the-visual-iconicity-challenge-evaluating-vision-language-models-on-.html"},{"id":"2510.08442v2","title":"Gaze on the Prize: Shaping Visual Attention with Return-Guided Contrastive Learning","headline":"提出基于回报引导对比学习的视觉注意力机制，提升强化学习样本效率","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008442v2-gaze-on-the-prize-shaping-visual-attention-with-return-guided-contra.html"},{"id":"2510.08377v2","title":"UniVideo: Unified Understanding, Generation, and Editing for Videos","headline":"UniVideo：统一视频理解、生成与编辑的多模态框架","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008377v2-univideo-unified-understanding-generation-and-editing-for-videos.html"},{"id":"2510.08073v1","title":"Physics-Driven Spatiotemporal Modeling for AI-Generated Video Detection","headline":"提出基于物理驱动的时空建模方法，用于检测AI生成视频","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008073v1-physics-driven-spatiotemporal-modeling-for-ai-generated-video-detect.html"},{"id":"2510.07817v1","title":"An End-to-End Room Geometry Constrained Depth Estimation Framework for Indoor Panorama Images","headline":"提出一种室内全景图像的端到端、基于房间几何约束的深度估计框架","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007817v1-an-end-to-end-room-geometry-constrained-depth-estimation-framework-f.html"},{"id":"2510.07810v3","title":"FMANet: A Novel Dual-Phase Optical Flow Approach with Fusion Motion Attention Network for Robust Micro-expression Recognition","headline":"提出FMANet，利用双阶段光流和融合运动注意力网络提升微表情识别鲁棒性","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007810v3-fmanet-a-novel-dual-phase-optical-flow-approach-with-fusion-motion-a.html"},{"id":"2510.08543v1","title":"VideoNorms: Benchmarking Cultural Awareness of Video Language Models","headline":"VideoNorms：构建视频语言模型文化意识基准，揭示模型在跨文化理解上的不足。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008543v1-videonorms-benchmarking-cultural-awareness-of-video-language-models.html"},{"id":"2510.07940v1","title":"TTOM: Test-Time Optimization and Memorization for Compositional Video Generation","headline":"提出TTOM：一种测试时优化与记忆框架，用于组合视频生成。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007940v1-ttom-test-time-optimization-and-memorization-for-compositional-video.html"},{"id":"2510.07828v3","title":"MMHOI: Modeling Complex 3D Multi-Human Multi-Object Interactions","headline":"提出MMHOI数据集和MMHOI-Net，用于建模复杂3D多人多物交互","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007828v3-mmhoi-modeling-complex-3d-multi-human-multi-object-interactions.html"},{"id":"2510.08531v1","title":"SpatialLadder: Progressive Training for Spatial Reasoning in Vision-Language Models","headline":"SpatialLadder：通过渐进式训练提升视觉语言模型中的空间推理能力","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008531v1-spatialladder-progressive-training-for-spatial-reasoning-in-vision-l.html"},{"id":"2510.08398v2","title":"VideoVerse: How Far is Your T2V Generator from a World Model?","headline":"VideoVerse：构建更全面的文本到视频生成模型评估基准，衡量模型与世界模型的差距","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008398v2-videoverse-how-far-is-your-t2v-generator-from-a-world-model.html"},{"id":"2510.07953v1","title":"SimCast: Enhancing Precipitation Nowcasting with Short-to-Long Term Knowledge Distillation","headline":"SimCast：利用短时到长时知识蒸馏增强降水临近预报","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007953v1-simcast-enhancing-precipitation-nowcasting-with-short-to-long-term-k.html"},{"id":"2510.07878v3","title":"FlowLensing: Simulating Gravitational Lensing with Flow Matching","headline":"FlowLensing：利用Flow Matching加速引力透镜模拟，助力暗物质研究","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007878v3-flowlensing-simulating-gravitational-lensing-with-flow-matching.html"},{"id":"2510.08575v2","title":"ReSplat: Learning Recurrent Gaussian Splats","headline":"提出ReSplat，一种迭代优化高斯splatting的循环模型，提升渲染质量和效率。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008575v2-resplat-learning-recurrent-gaussian-splats.html"},{"id":"2510.07729v1","title":"ComGS: Efficient 3D Object-Scene Composition via Surface Octahedral Probes","headline":"ComGS：通过表面八面体探针实现高效的3D物体-场景合成","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007729v1-comgs-efficient-3d-object-scene-composition-via-surface-octahedral-p.html"},{"id":"2510.08318v2","title":"LinVideo: A Post-Training Framework towards O(n) Attention in Efficient Video Generation","headline":"LinVideo：一种后训练框架，实现高效视频生成中O(n)复杂度Attention","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008318v2-linvideo-a-post-training-framework-towards-on-attention-in-efficient.html"},{"id":"2510.08818v1","title":"D-CoDe: Scaling Image-Pretrained VLMs to Video via Dynamic Compression and Question Decomposition","headline":"D-CoDe：通过动态压缩和问题分解，将图像预训练的VLM扩展到视频领域","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008818v1-d-code-scaling-image-pretrained-vlms-to-video-via-dynamic-compressio.html"},{"id":"2510.08551v1","title":"ARTDECO: Towards Efficient and High-Fidelity On-the-Fly 3D Reconstruction with Structured Scene Representation","headline":"ARTDECO：基于结构化场景表示的高效高保真即时3D重建","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008551v1-artdeco-towards-efficient-and-high-fidelity-on-the-fly-3d-reconstruc.html"},{"id":"2510.08510v1","title":"To Sink or Not to Sink: Visual Information Pathways in Large Vision-Language Models","headline":"针对大型视觉语言模型，论文提出利用ViT注意力汇聚增强视觉推理能力。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008510v1-to-sink-or-not-to-sink-visual-information-pathways-in-large-vision-l.html"},{"id":"2510.08138v1","title":"Improving Temporal Understanding Logic Consistency in Video-Language Models via Attention Enhancement","headline":"提出时序条件注意力锐化(TCAS)方法，提升视频语言模型时序理解逻辑一致性","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008138v1-improving-temporal-understanding-logic-consistency-in-video-language.html"},{"id":"2510.07839v1","title":"AlignGS: Aligning Geometry and Semantics for Robust Indoor Reconstruction from Sparse Views","headline":"AlignGS：对齐几何与语义，实现稀疏视角下鲁棒的室内重建","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007839v1-aligngs-aligning-geometry-and-semantics-for-robust-indoor-reconstruc.html"},{"id":"2510.08789v2","title":"Q-Router: Agentic Video Quality Assessment with Expert Model Routing and Artifact Localization","headline":"Q-Router：基于专家模型路由和伪影定位的Agentic视频质量评估","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008789v2-q-router-agentic-video-quality-assessment-with-expert-model-routing-.html"},{"id":"2510.08449v1","title":"Hierarchical Spatial Algorithms for High-Resolution Image Quantization and Feature Extraction","headline":"提出一种用于高分辨率图像量化和特征提取的分层空间算法框架","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251008449v1-hierarchical-spatial-algorithms-for-high-resolution-image-quantizati.html"},{"id":"2510.07976v1","title":"The impact of abstract and object tags on image privacy classification","headline":"研究抽象和对象标签对图像隐私分类的影响，揭示标签类型与数量的关键作用。","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007976v1-the-impact-of-abstract-and-object-tags-on-image-privacy-classificati.html"},{"id":"2510.07723v2","title":"SyncHuman: Synchronizing 2D and 3D Generative Models for Single-view Human Reconstruction","headline":"SyncHuman：同步2D和3D生成模型，实现单视角人体重建","tag":"cs.CV","date":"2025-10-09","url":"cs-CV/2025-10-09/papers/251007723v2-synchuman-synchronizing-2d-and-3d-generative-models-for-single-view-.html"},{"id":"2510.08530v1","title":"X2Video: Adapting Diffusion Models for Multimodal Controllable Neural Video Rendering","headline":"提出X2Video以解决多模态视频渲染控制问题","tag":"cs.GR","date":"2025-10-09","url":"cs-GR/2025-10-09/papers/251008530v1-x2video-adapting-diffusion-models-for-multimodal-controllable-neural.html"},{"id":"2510.08491v1","title":"Splat the Net: Radiance Fields with Splattable Neural Primitives","headline":"提出可splatting的神经基元，兼顾神经辐射场的表达能力和splatting的渲染效率。","tag":"cs.GR","date":"2025-10-09","url":"cs-GR/2025-10-09/papers/251008491v1-splat-the-net-radiance-fields-with-splattable-neural-primitives.html"},{"id":"2510.07638v1","title":"Differentiable Variable Fonts","headline":"提出可微变量字体框架，实现字体设计的自动化与优化。","tag":"cs.GR","date":"2025-10-09","url":"cs-GR/2025-10-09/papers/251007638v1-differentiable-variable-fonts.html"},{"id":"2510.07730v1","title":"DEAS: DEtached value learning with Action Sequence for Scalable Offline RL","headline":"DEAS：利用动作序列和解耦价值学习实现可扩展的离线强化学习","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251007730v1-deas-detached-value-learning-with-action-sequence-for-scalable-offli.html"},{"id":"2510.08492v1","title":"Better Together: Leveraging Unpaired Multimodal Data for Stronger Unimodal Models","headline":"提出UML，利用非配对多模态数据增强单模态模型表示学习","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251008492v1-better-together-leveraging-unpaired-multimodal-data-for-stronger-uni.html"},{"id":"2510.08768v1","title":"Zero-Shot Policy Transfer in Reinforcement Learning using Buckingham's Pi Theorem","headline":"利用白金汉π定理实现强化学习中的零样本策略迁移","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251008768v1-zero-shot-policy-transfer-in-reinforcement-learning-using-buckingham.html"},{"id":"2510.07910v1","title":"MMM: Quantum-Chemical Molecular Representation Learning for Combinatorial Drug Recommendation","headline":"MMM：利用量子化学分子表示学习进行组合药物推荐，提升DDI预测。","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251007910v1-mmm-quantum-chemical-molecular-representation-learning-for-combinato.html"},{"id":"2510.08839v1","title":"Reinforcement Learning-Driven Edge Management for Reliable Multi-view 3D Reconstruction","headline":"提出基于强化学习的边缘管理框架，提升多视角3D重建在动态环境下的可靠性。","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251008839v1-reinforcement-learning-driven-edge-management-for-reliable-multi-vie.html"},{"id":"2510.08425v1","title":"Reinforcing Diffusion Models by Direct Group Preference Optimization","headline":"提出直接群体偏好优化(DGPO)，加速并提升扩散模型的强化学习训练。","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251008425v1-reinforcing-diffusion-models-by-direct-group-preference-optimization.html"},{"id":"2510.08179v1","title":"Dual-granularity Sinkhorn Distillation for Enhanced Learning from Long-tailed Noisy Data","headline":"提出双粒度Sinkhorn蒸馏(D-SINK)框架，提升长尾噪声数据下的模型学习能力。","tag":"cs.LG","date":"2025-10-09","url":"cs-LG/2025-10-09/papers/251008179v1-dual-granularity-sinkhorn-distillation-for-enhanced-learning-from-lo.html"},{"id":"2510.07632v1","title":"Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models","headline":"提出测试时匹配(TTM)算法，提升多模态模型在组合推理任务上的性能","tag":"cs.AI","date":"2025-10-09","url":"cs-AI/2025-10-09/papers/251007632v1-test-time-matching-unlocking-compositional-reasoning-in-multimodal-m.html"},{"id":"2510.08713v1","title":"Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation","headline":"UniWM：统一的、记忆增强的世界模型，用于视觉导航中的规划与预测","tag":"cs.AI","date":"2025-10-09","url":"cs-AI/2025-10-09/papers/251008713v1-unified-world-models-memory-augmented-planning-and-foresight-for-vis.html"},{"id":"2510.08564v1","title":"How to Teach Large Multimodal Models New Skills","headline":"提出两种高效微调策略，提升大型多模态模型新技能学习能力并缓解灾难性遗忘","tag":"cs.AI","date":"2025-10-09","url":"cs-AI/2025-10-09/papers/251008564v1-how-to-teach-large-multimodal-models-new-skills.html"},{"id":"2510.07681v2","title":"Curriculum Learning with Synthetic Data for Enhanced Pulmonary Nodule Detection in Chest Radiographs","headline":"结合课程学习与合成数据增强，提升胸部X光片肺结节检测性能","tag":"cs.AI","date":"2025-10-09","url":"cs-AI/2025-10-09/papers/251007681v2-curriculum-learning-with-synthetic-data-for-enhanced-pulmonary-nodul.html"},{"id":"2510.07152v2","title":"DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction","headline":"提出DPL框架，通过深度信息实现类人机器人在复杂地形上的稳健运动","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007152v2-dpl-depth-only-perceptive-humanoid-locomotion-via-realistic-depth-sy.html"},{"id":"2510.06710v1","title":"RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training","headline":"RLinf-VLA：用于VLA+RL训练的统一高效框架","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251006710v1-rlinf-vla-a-unified-and-efficient-framework-for-vlarl-training.html"},{"id":"2510.07067v1","title":"Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models","headline":"研究无关上下文对具身AI中VLA模型指令理解的影响，并提出LLM过滤框架。","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007067v1-bring-the-apple-not-the-sofa-impact-of-irrelevant-context-in-embodie.html"},{"id":"2510.07134v1","title":"TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking","headline":"TrackVLA++：利用VLA模型中的推理和记忆能力实现具身视觉跟踪","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007134v1-trackvla-unleashing-reasoning-and-memory-capabilities-in-vla-models-.html"},{"id":"2510.07094v1","title":"Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies","headline":"提出基于配置采样的通用四足机器人鲁棒运动策略，实现零样本迁移","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007094v1-sampling-strategies-for-robust-universal-quadrupedal-locomotion-poli.html"},{"id":"2510.07077v1","title":"Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications","headline":"综述：面向真实机器人应用的视觉-语言-动作模型研究进展","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007077v1-vision-language-action-models-for-robotics-a-review-towards-real-wor.html"},{"id":"2510.07625v1","title":"GATO: GPU-Accelerated and Batched Trajectory Optimization for Scalable Edge Model Predictive Control","headline":"GATO：用于可扩展边缘模型预测控制的GPU加速批量轨迹优化","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007625v1-gato-gpu-accelerated-and-batched-trajectory-optimization-for-scalabl.html"},{"id":"2510.07030v1","title":"Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation","headline":"提出基于扩散模型的轨迹优化方法，用于多指灵巧操作中的恢复行为","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007030v1-diffusing-trajectory-optimization-problems-for-recovery-during-multi.html"},{"id":"2510.07548v1","title":"AVO: Amortized Value Optimization for Contact Mode Switching in Multi-Finger Manipulation","headline":"AVO：基于值函数优化的多指灵巧操作接触模式切换方法","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007548v1-avo-amortized-value-optimization-for-contact-mode-switching-in-multi.html"},{"id":"2510.06717v1","title":"SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis","headline":"SanDRA：基于可达性分析的自动驾驶车辆安全大语言模型决策框架","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251006717v1-sandra-safe-large-language-model-based-decision-making-for-automated.html"},{"id":"2510.06633v1","title":"Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care","headline":"提出Assist-As-Needed自适应多模态机器人辅助系统，用于痴呆症患者的药物管理。","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251006633v1-assist-as-needed-adaptive-multimodal-robotic-assistance-for-medicati.html"},{"id":"2510.06754v1","title":"UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene","headline":"UniFField：通用、统一且能感知不确定性的神经特征场，适用于任意场景","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251006754v1-uniffield-a-generalizable-unified-neural-feature-field-for-visual-se.html"},{"id":"2510.07417v1","title":"FLEET: Formal Language-Grounded Scheduling for Heterogeneous Robot Teams","headline":"FLEET：面向异构机器人团队的基于形式语言的调度方法","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007417v1-fleet-formal-language-grounded-scheduling-for-heterogeneous-robot-te.html"},{"id":"2510.07181v2","title":"TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics","headline":"TIGeR：通过工具集成几何推理，提升视觉-语言模型在机器人领域的精度","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007181v2-tiger-tool-integrated-geometric-reasoning-in-vision-language-models-.html"},{"id":"2510.07611v1","title":"Inspection Planning Primitives with Implicit Models","headline":"提出IPIM，利用隐式模型高效进行复杂结构巡检规划，显著降低内存占用。","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007611v1-inspection-planning-primitives-with-implicit-models.html"},{"id":"2510.07027v1","title":"Tailoring materials into kirigami robots","headline":"利用剪纸工艺定制材料，实现多功能轻量化机器人","tag":"cs.RO","date":"2025-10-08","url":"cs-RO/2025-10-08/papers/251007027v1-tailoring-materials-into-kirigami-robots.html"},{"id":"2510.06988v1","title":"No MoCap Needed: Post-Training Motion Diffusion Models with Reinforcement Learning using Only Textual Prompts","headline":"提出基于强化学习的后训练运动扩散模型，仅用文本提示即可实现动作迁移。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006988v1-no-mocap-needed-post-training-motion-diffusion-models-with-reinforce.html"},{"id":"2510.07313v1","title":"WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation","headline":"提出WristWorld，利用4D世界模型从Anchor视角生成腕部视角视频，提升机器人操作性能。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007313v1-wristworld-generating-wrist-views-via-4d-world-models-for-robotic-ma.html"},{"id":"2510.06967v1","title":"Generating Surface for Text-to-3D using 2D Gaussian Splatting","headline":"提出DirectGaussian以解决3D内容生成中的几何一致性问题","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006967v1-generating-surface-for-text-to-3d-using-2d-gaussian-splatting.html"},{"id":"2510.06638v2","title":"Implicit-Knowledge Visual Question Answering with Structured Reasoning Traces","headline":"提出MODELNAME框架，通过结构化推理轨迹提升隐式知识视觉问答性能。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006638v2-implicit-knowledge-visual-question-answering-with-structured-reasoni.html"},{"id":"2510.07277v1","title":"Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection","headline":"评估眼底特有的基础模型在糖尿病黄斑水肿检测中的性能","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007277v1-evaluating-fundus-specific-foundation-models-for-diabetic-macular-ed.html"},{"id":"2510.06809v1","title":"VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance","headline":"提出VA-Adapter，将超声基础模型应用于超声心动图探头引导，提升图像质量。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006809v1-va-adapter-adapting-ultrasound-foundation-model-to-echocardiography-.html"},{"id":"2510.06746v1","title":"DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement for Image Deraining","headline":"提出DeRainMamba，结合频域感知和细节增强的图像去雨方法","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006746v1-derainmamba-a-frequency-aware-state-space-model-with-detail-enhancem.html"},{"id":"2510.06679v1","title":"DreamOmni2: Multimodal Instruction-based Editing and Generation","headline":"DreamOmni2：提出多模态指令驱动的图像编辑与生成框架，扩展应用场景。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006679v1-dreamomni2-multimodal-instruction-based-editing-and-generation.html"},{"id":"2510.08618v1","title":"Look before Transcription: End-to-End SlideASR with Visually-Anchored Policy Optimization","headline":"提出VAPO，通过视觉锚定的策略优化，提升SlideASR中领域术语的识别精度。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251008618v1-look-before-transcription-end-to-end-slideasr-with-visually-anchored.html"},{"id":"2510.07316v2","title":"Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers","headline":"提出基于语义提示扩散Transformer的像素级单目深度估计模型，生成高质量点云。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007316v2-pixel-perfect-depth-with-semantics-prompted-diffusion-transformers.html"},{"id":"2510.07249v2","title":"TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation","headline":"提出TalkCuts大规模数据集，用于多镜头人声视频生成研究","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007249v2-talkcuts-a-large-scale-dataset-for-multi-shot-human-speech-video-gen.html"},{"id":"2510.07143v1","title":"Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods","headline":"提出VTC-Bench，用于更准确评估多模态大模型中视觉Token压缩方法的性能。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007143v1-are-we-using-the-right-benchmark-an-evaluation-framework-for-visual-.html"},{"id":"2510.06743v1","title":"Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities","headline":"提出历史文档OCR的LLM评估框架，解决时序偏差和特定时期错误问题","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006743v1-evaluating-llms-for-historical-document-ocr-a-methodological-framewo.html"},{"id":"2510.06694v1","title":"SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis","headline":"SCas4D：结构化级联优化加速持久动态场景的4D新视角合成","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006694v1-scas4d-structural-cascaded-optimization-for-boosting-persistent-4d-n.html"},{"id":"2510.07119v2","title":"MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency","headline":"提出MoRe，通过图优化单目几何体，提升跨视角一致性和尺度对齐。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007119v2-more-monocular-geometry-refinement-via-graph-optimization-for-cross-.html"},{"id":"2510.09679v1","title":"Knowledge-Aware Mamba for Joint Change Detection and Classification from MODIS Times Series","headline":"提出知识驱动的Mamba以解决MODIS时间序列变化检测问题","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251009679v1-knowledge-aware-mamba-for-joint-change-detection-and-classification-.html"},{"id":"2510.07319v1","title":"Temporal Prompting Matters: Rethinking Referring Video Object Segmentation","headline":"提出Tenet框架，利用时序Prompt高效解决Referring Video Object Segmentation问题","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007319v1-temporal-prompting-matters-rethinking-referring-video-object-segment.html"},{"id":"2510.06783v2","title":"TTRV: Test-Time Reinforcement Learning for Vision Language Models","headline":"提出TTRV：一种用于视觉语言模型的测试时强化学习方法，无需标注数据。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006783v2-ttrv-test-time-reinforcement-learning-for-vision-language-models.html"},{"id":"2510.08638v1","title":"Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry","headline":"通过SAE分析DINOv2，揭示其表征的功能专业化和Minkowski几何特性。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251008638v1-into-the-rabbit-hull-from-task-relevant-concepts-in-dino-to-minkowsk.html"},{"id":"2510.07190v1","title":"MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis","headline":"MV-Performer：提出一种用于生成逼真同步多视角表演者视频的扩散模型","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007190v1-mv-performer-taming-video-diffusion-model-for-faithful-and-synchroni.html"},{"id":"2510.07550v1","title":"TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility","headline":"TRAVL：提升视频-语言模型对物理合理性判断能力的方案","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251007550v1-travl-a-recipe-for-making-video-language-models-better-judges-of-phy.html"},{"id":"2510.06820v1","title":"Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking","headline":"提出EDJE：一种高效判别式联合编码器，用于大规模视觉-语言重排序。","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251006820v1-efficient-discriminative-joint-encoders-for-large-scale-vision-langu.html"},{"id":"2510.08631v1","title":"Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs","headline":"提出基于分层GMM不确定性的LiDAR语义分割OOD检测方法","tag":"cs.CV","date":"2025-10-08","url":"cs-CV/2025-10-08/papers/251008631v1-out-of-distribution-detection-in-lidar-semantic-segmentation-using-e.html"},{"id":"2510.06802v1","title":"Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity","headline":"提出基于3D高斯溅射的快速3D物体获取与Unity实时渲染管线","tag":"cs.GR","date":"2025-10-08","url":"cs-GR/2025-10-08/papers/251006802v1-capture-and-interact-rapid-3d-object-acquisition-and-rendering-with-.html"},{"id":"2510.07092v1","title":"Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report","headline":"针对人形机器人，提出基于生成模型的通用世界建模方法，并在1X World Model Challenge中获得双料冠军。","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251007092v1-generative-world-modelling-for-humanoids-1x-world-model-challenge-te.html"},{"id":"2510.07513v1","title":"MLLM4TS: Leveraging Vision and Multimodal Language Models for General Time-Series Analysis","headline":"MLLM4TS：利用视觉和多模态语言模型进行通用时间序列分析","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251007513v1-mllm4ts-leveraging-vision-and-multimodal-language-models-for-general.html"},{"id":"2510.06871v2","title":"SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models","headline":"SaFeR-VLM：面向安全的多模态模型细粒度推理框架","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251006871v2-safer-vlm-toward-safety-aware-fine-grained-reasoning-in-multimodal-m.html"},{"id":"2510.06913v1","title":"DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning","headline":"提出DecompGAIL，通过分解交互关系提升多智能体模仿学习的交通行为真实性。","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251006913v1-decompgail-learning-realistic-traffic-behaviors-with-decomposed-mult.html"},{"id":"2510.06982v1","title":"Revisiting Mixout: An Overlooked Path to Robust Finetuning","headline":"提出GMixout，通过自适应权重混合提升微调模型在分布偏移下的鲁棒性","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251006982v1-revisiting-mixout-an-overlooked-path-to-robust-finetuning.html"},{"id":"2510.07151v1","title":"ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL","headline":"ELMUR：利用外部层记忆和更新/重写机制，解决长时程强化学习问题。","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251007151v1-elmur-external-layer-memory-with-updaterewrite-for-long-horizon-rl.html"},{"id":"2510.06637v1","title":"Control-Augmented Autoregressive Diffusion for Data Assimilation","headline":"提出控制增强自回归扩散模型，用于解决数据同化中预测漂移问题。","tag":"cs.LG","date":"2025-10-08","url":"cs-LG/2025-10-08/papers/251006637v1-control-augmented-autoregressive-diffusion-for-data-assimilation.html"},{"id":"2510.06782v1","title":"GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting","headline":"GPT-5无需提示即可修正GPT-4V在图表阅读中的错误","tag":"cs.CL","date":"2025-10-08","url":"cs-CL/2025-10-08/papers/251006782v1-gpt-5-model-corrected-gpt-4vs-chart-reading-errors-not-prompting.html"},{"id":"2510.05547v1","title":"ARRC: Advanced Reasoning Robot Control - Knowledge-Driven Autonomous Manipulation Using Retrieval-Augmented Generation","headline":"ARRC：基于检索增强生成实现知识驱动的自主机器人操作","tag":"cs.RO","date":"2025-10-07","url":"cs-RO/2025-10-07/papers/251005547v1-arrc-advanced-reasoning-robot-control-knowledge-driven-autonomous-ma.html"},{"id":"2510.05536v1","title":"Correlation-Aware Dual-View Pose and Velocity Estimation for Dynamic Robotic Manipulation","headline":"提出一种去中心化的双视角姿态与速度估计方法以解决动态机器人操作问题","tag":"cs.RO","date":"2025-10-07","url":"cs-RO/2025-10-07/papers/251005536v1-correlation-aware-dual-view-pose-and-velocity-estimation-for-dynamic.html"},{"id":"2510.05538v1","title":"Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work","headline":"评估多模态LLM在手写学生作业判阅中的能力","tag":"cs.CV","date":"2025-10-07","url":"cs-CV/2025-10-07/papers/251005538v1-seeing-the-big-picture-evaluating-multimodal-llms-ability-to-interpr.html"},{"id":"2510.05488v1","title":"ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars","headline":"ArchitectHead：提出首个支持连续细节层次控制的3D高斯头部头像框架","tag":"cs.CV","date":"2025-10-07","url":"cs-CV/2025-10-07/papers/251005488v1-architecthead-continuous-level-of-detail-control-for-3d-gaussian-hea.html"},{"id":"2510.05506v3","title":"Human Action Recognition from Point Clouds over Time","headline":"提出一种基于点云序列的人体动作识别框架，结合点云和稀疏卷积网络。","tag":"cs.CV","date":"2025-10-07","url":"cs-CV/2025-10-07/papers/251005506v3-human-action-recognition-from-point-clouds-over-time.html"},{"id":"2510.05070v2","title":"ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning","headline":"ResMimic：通过残差学习实现从通用运动跟踪到人形机器人全身Loco-Manipulation","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005070v2-resmimic-from-general-motion-tracking-to-humanoid-whole-body-loco-ma.html"},{"id":"2510.04898v1","title":"HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks","headline":"HyperVLA：通过超网络实现视觉-语言-动作模型的高效推理","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004898v1-hypervla-efficient-inference-in-vision-language-action-models-via-hy.html"},{"id":"2510.05001v1","title":"Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot","headline":"基于第一性原理与强化学习，探索TARS机器人新型运动模式","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005001v1-walking-rolling-and-beyond-first-principles-and-rl-locomotion-on-a-t.html"},{"id":"2510.04592v1","title":"MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation","headline":"MobRT：基于数字孪生的移动操作可扩展学习框架","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004592v1-mobrt-a-digital-twin-based-framework-for-scalable-learning-in-mobile.html"},{"id":"2510.04696v2","title":"Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly","headline":"提出一种分散式梯度能量函数，用于双臂机器人装配中的快速重规划。","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004696v2-building-gradient-by-gradient-decentralised-energy-functions-for-bim.html"},{"id":"2512.00005v1","title":"DREAMer-VXS: A Latent World Model for Sample-Efficient AGV Exploration in Stochastic, Unobserved Environments","headline":"提出DREAMer-VXS以解决AGV在随机未知环境中的样本效率问题","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251200005v1-dreamer-vxs-a-latent-world-model-for-sample-efficient-agv-exploratio.html"},{"id":"2510.05382v1","title":"A multi-modal tactile fingertip design for robotic hands to enhance dexterous manipulation","headline":"提出一种低成本多模态触觉指尖设计，增强机器人灵巧操作能力","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005382v1-a-multi-modal-tactile-fingertip-design-for-robotic-hands-to-enhance-.html"},{"id":"2510.05213v1","title":"VER: Vision Expert Transformer for Robot Learning via Foundation Distillation and Dynamic Routing","headline":"提出VER，通过专家蒸馏和动态路由实现机器人学习的视觉知识迁移。","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005213v1-ver-vision-expert-transformer-for-robot-learning-via-foundation-dist.html"},{"id":"2510.05057v1","title":"StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation","headline":"StaMo：基于紧凑状态表征无监督学习通用机器人运动","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005057v1-stamo-unsupervised-learning-of-generalizable-robot-motion-from-compa.html"},{"id":"2510.04585v1","title":"Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation","headline":"提出Everything-Grasping (EG) Gripper，实现跨尺度和跨状态物体的通用抓取","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004585v1-everything-grasping-eg-gripper-a-universal-gripper-with-synergistic-.html"},{"id":"2510.04436v1","title":"PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization","headline":"提出PAD-TRO，通过投影增强扩散模型实现直接轨迹优化，解决动态可行性约束难题。","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004436v1-pad-tro-projection-augmented-diffusion-for-direct-trajectory-optimiz.html"},{"id":"2510.05430v1","title":"Active Semantic Perception","headline":"提出基于语义场景图的主动语义感知方法，用于高效探索复杂室内环境。","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005430v1-active-semantic-perception.html"},{"id":"2510.05443v1","title":"AD-NODE: Adaptive Dynamics Learning with Neural ODEs for Mobile Robots Control","headline":"提出基于神经ODE的自适应动力学学习方法，用于移动机器人控制。","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251005443v1-ad-node-adaptive-dynamics-learning-with-neural-odes-for-mobile-robot.html"},{"id":"2510.04991v2","title":"Efficient Navigation in Unknown Indoor Environments with Vision-Language Models","headline":"提出基于视觉-语言模型的高效导航框架，解决未知室内环境探索问题","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004991v2-efficient-navigation-in-unknown-indoor-environments-with-vision-lang.html"},{"id":"2510.04509v1","title":"Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads","headline":"提出基于速度形式数据的软体机器人预测控制，解决未知载荷下的鲁棒控制问题","tag":"cs.RO","date":"2025-10-06","url":"cs-RO/2025-10-06/papers/251004509v1-velocity-form-data-enabled-predictive-control-of-soft-robots-under-u.html"},{"id":"2510.04723v1","title":"Benchmark on Monocular Metric Depth Estimation in Wildlife Setting","headline":"构建野生动物场景下单目深度估计基准，评估现有方法性能。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004723v1-benchmark-on-monocular-metric-depth-estimation-in-wildlife-setting.html"},{"id":"2510.05034v6","title":"Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large Multimodal Models","headline":"全面剖析视频大模型后训练方法，提升视频推理能力","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005034v6-video-lmm-post-training-a-deep-dive-into-video-reasoning-with-large-.html"},{"id":"2510.04759v2","title":"Progressive Gaussian Transformer with Anisotropy-aware Sampling for Open Vocabulary Occupancy Prediction","headline":"提出PG-Occ框架，通过渐进式高斯Transformer实现开放词汇三维 occupancy 预测。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004759v2-progressive-gaussian-transformer-with-anisotropy-aware-sampling-for-.html"},{"id":"2510.04770v1","title":"Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning","headline":"提出基于有界分布估计的开放词汇学习方法，通过生成未见类数据提升泛化能力。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004770v1-beyond-the-seen-bounded-distribution-estimation-for-open-vocabulary-.html"},{"id":"2510.04587v2","title":"Pathology-CoT: Learning Visual Chain-of-Thought Agent from Expert Whole Slide Image Diagnosis Behavior","headline":"提出Pathology-CoT框架，从专家WSI诊断行为中学习视觉链式推理Agent","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004587v2-pathology-cot-learning-visual-chain-of-thought-agent-from-expert-who.html"},{"id":"2510.06277v1","title":"General and Efficient Visual Goal-Conditioned Reinforcement Learning using Object-Agnostic Masks","headline":"提出基于对象无关掩码的视觉目标条件强化学习方法，提升泛化性和效率","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251006277v1-general-and-efficient-visual-goal-conditioned-reinforcement-learning.html"},{"id":"2510.04966v1","title":"ActiveMark: on watermarking of visual foundation models via massive activations","headline":"提出ActiveMark以解决视觉基础模型的水印保护问题","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004966v1-activemark-on-watermarking-of-visual-foundation-models-via-massive-a.html"},{"id":"2510.04628v1","title":"A Spatial-Spectral-Frequency Interactive Network for Multimodal Remote Sensing Classification","headline":"提出空间-光谱-频率交互网络S²Fin，用于提升多模态遥感图像分类精度。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004628v1-a-spatial-spectral-frequency-interactive-network-for-multimodal-remo.html"},{"id":"2510.04714v1","title":"Object-Centric Representation Learning for Enhanced 3D Scene Graph Prediction","headline":"提出面向对象的表征学习方法，提升3D场景图预测精度","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004714v1-object-centric-representation-learning-for-enhanced-3d-scene-graph-p.html"},{"id":"2510.04854v1","title":"Read the Room: Inferring Social Context Through Dyadic Interaction Recognition in Cyber-physical-social Infrastructure Systems","headline":"提出基于深度传感器的群体交互识别方法，用于增强网络物理社会基础设施系统中的社会感知。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004854v1-read-the-room-inferring-social-context-through-dyadic-interaction-re.html"},{"id":"2510.04564v2","title":"Conditional Representation Learning for Customized Tasks","headline":"提出条件表示学习(CRL)，为定制任务提取特定语义的图像表征。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004564v2-conditional-representation-learning-for-customized-tasks.html"},{"id":"2510.04794v1","title":"A Comparative Study of Vision Transformers and CNNs for Few-Shot Rigid Transformation and Fundamental Matrix Estimation","headline":"对比ViT与CNN在少样本刚性变换和本质矩阵估计中的性能，揭示不同数据规模下的架构选择策略。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004794v1-a-comparative-study-of-vision-transformers-and-cnns-for-few-shot-rig.html"},{"id":"2510.05408v1","title":"See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models","headline":"提出基于视觉语言模型的时序逆转场景重建方法，利用热成像痕迹推断过去场景状态。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005408v1-see-the-past-time-reversed-scene-reconstruction-from-thermal-traces-.html"},{"id":"2510.05091v1","title":"Factuality Matters: When Image Generation and Editing Meet Structured Visuals","headline":"针对结构化视觉生成与编辑的事实性问题，提出StructBench基准和多模态融合模型。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005091v1-factuality-matters-when-image-generation-and-editing-meet-structured.html"},{"id":"2510.04802v1","title":"Did you just see that? Arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensors","headline":"EgoSurg：基于环境传感器，为手术室工作流程重建任意视角的自我中心回放。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004802v1-did-you-just-see-that-arbitrary-view-synthesis-for-egocentric-replay.html"},{"id":"2510.04477v1","title":"MedCLM: Learning to Localize and Reason via a CoT-Curriculum in Medical Vision-Language Models","headline":"MedCLM：通过CoT课程学习医学视觉语言模型中的定位和推理","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004477v1-medclm-learning-to-localize-and-reason-via-a-cot-curriculum-in-medic.html"},{"id":"2510.05051v2","title":"SegMASt3R: Geometry Grounded Segment Matching","headline":"SegMASt3R：利用3D基础模型实现几何感知的图像分割匹配","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005051v2-segmast3r-geometry-grounded-segment-matching.html"},{"id":"2510.04856v1","title":"ERDE: Entropy-Regularized Distillation for Early-exit","headline":"提出基于熵正则化的知识蒸馏早期退出方法，提升边缘设备图像分类效率。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004856v1-erde-entropy-regularized-distillation-for-early-exit.html"},{"id":"2510.04838v1","title":"Beyond Random: Automatic Inner-loop Optimization in Dataset Distillation","headline":"提出AT-BPTT，通过自动内循环优化提升数据集蒸馏性能。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004838v1-beyond-random-automatic-inner-loop-optimization-in-dataset-distillat.html"},{"id":"2510.04648v1","title":"EduPersona: Benchmarking Subjective Ability Boundaries of Virtual Student Agents","headline":"EduPersona：评估虚拟学生Agent主观能力的基准测试","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004648v1-edupersona-benchmarking-subjective-ability-boundaries-of-virtual-stu.html"},{"id":"2510.04781v2","title":"Hands-Free Heritage: Automated 3D Scanning for Cultural Heritage Digitization","headline":"提出一种自动化双机器人扫描系统，用于文化遗产高精度三维数字化","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004781v2-hands-free-heritage-automated-3d-scanning-for-cultural-heritage-digi.html"},{"id":"2510.05094v1","title":"VChain: Chain-of-Visual-Thought for Reasoning in Video Generation","headline":"VChain：用于视频生成中推理的视觉思维链","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005094v1-vchain-chain-of-visual-thought-for-reasoning-in-video-generation.html"},{"id":"2510.05093v1","title":"Character Mixing for Video Generation","headline":"提出CCE和CCA框架，实现跨世界观角色融合的视频生成，解决风格退化问题。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251005093v1-character-mixing-for-video-generation.html"},{"id":"2510.04819v1","title":"Visual Representations inside the Language Model","headline":"分析多模态大语言模型内部视觉表征，揭示其感知能力瓶颈与改进方向","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004819v1-visual-representations-inside-the-language-model.html"},{"id":"2510.04753v1","title":"Beyond Appearance: Transformer-based Person Identification from Conversational Dynamics","headline":"提出基于Transformer的对话动态人体识别方法，提升自然交互场景下身份识别精度。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004753v1-beyond-appearance-transformer-based-person-identification-from-conve.html"},{"id":"2510.04706v1","title":"ID-Consistent, Precise Expression Generation with Blendshape-Guided Diffusion","headline":"提出Blendshape引导的扩散模型，实现身份保持和精准表情生成。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004706v1-id-consistent-precise-expression-generation-with-blendshape-guided-d.html"},{"id":"2510.04479v2","title":"VaseVQA-3D: Benchmarking 3D VLMs on Ancient Greek Pottery","headline":"提出VaseVQA-3D数据集和VaseVLM模型，解决3D文物领域视觉问答的数据稀缺和知识不足问题。","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004479v2-vasevqa-3d-benchmarking-3d-vlms-on-ancient-greek-pottery.html"},{"id":"2510.04401v1","title":"Your Vision-Language Model Can't Even Count to 20: Exposing the Failures of VLMs in Compositional Counting","headline":"VLMCountBench揭示视觉语言模型在组合计数任务上的显著缺陷","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004401v1-your-vision-language-model-cant-even-count-to-20-exposing-the-failur.html"},{"id":"2510.04822v1","title":"AvatarVTON: 4D Virtual Try-On for Animatable Avatars","headline":"AvatarVTON：提出首个用于可动画Avatar的4D虚拟试穿框架","tag":"cs.CV","date":"2025-10-06","url":"cs-CV/2025-10-06/papers/251004822v1-avatarvton-4d-virtual-try-on-for-animatable-avatars.html"},{"id":"2510.05097v1","title":"Pulp Motion: Framing-aware multimodal camera and human motion generation","headline":"提出多模态联合生成方法以解决人类动作与摄像机轨迹生成问题","tag":"cs.GR","date":"2025-10-06","url":"cs-GR/2025-10-06/papers/251005097v1-pulp-motion-framing-aware-multimodal-camera-and-human-motion-generat.html"},{"id":"2510.04637v1","title":"Social Agent: Mastering Dyadic Nonverbal Behavior Generation via Conversational LLM Agents","headline":"Social Agent：基于对话LLM智能体实现双人非语言行为生成","tag":"cs.GR","date":"2025-10-06","url":"cs-GR/2025-10-06/papers/251004637v1-social-agent-mastering-dyadic-nonverbal-behavior-generation-via-conv.html"},{"id":"2510.04417v1","title":"Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions","headline":"提出基于归一化流的高斯潜在空间部分信息分解方法，提升多模态数据分析效率。","tag":"cs.LG","date":"2025-10-06","url":"cs-LG/2025-10-06/papers/251004417v1-partial-information-decomposition-via-normalizing-flows-in-latent-ga.html"},{"id":"2510.04547v3","title":"Activation Quantization of Vision Encoders Needs Prefixing Registers","headline":"提出RegCache，通过前缀寄存器实现视觉编码器激活量化的无训练优化","tag":"cs.LG","date":"2025-10-06","url":"cs-LG/2025-10-06/papers/251004547v3-activation-quantization-of-vision-encoders-needs-prefixing-registers.html"},{"id":"2510.04514v1","title":"ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in Complex Chart Question Answering","headline":"提出ChartAgent，通过视觉推理解决复杂图表问答中未标注图表的理解难题。","tag":"cs.AI","date":"2025-10-06","url":"cs-AI/2025-10-06/papers/251004514v1-chartagent-a-multimodal-agent-for-visually-grounded-reasoning-in-com.html"},{"id":"2510.05283v1","title":"Beyond Monolithic Rewards: A Hybrid and Multi-Aspect Reward Optimization for MLLM Alignment","headline":"提出混合多维度奖励优化框架，提升多模态大语言模型对齐效果","tag":"cs.AI","date":"2025-10-06","url":"cs-AI/2025-10-06/papers/251005283v1-beyond-monolithic-rewards-a-hybrid-and-multi-aspect-reward-optimizat.html"},{"id":"2510.04807v1","title":"Efficient Probabilistic Planning with Maximum-Coverage Distributionally Robust Backward Reachable Trees","headline":"提出一种高效的多查询运动规划算法以解决高概率到达问题","tag":"eess.SY","date":"2025-10-06","url":"eess-SY/2025-10-06/papers/251004807v1-efficient-probabilistic-planning-with-maximum-coverage-distributiona.html"},{"id":"2510.04353v1","title":"Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation","headline":"提出基于质心稳定性的重定向方法，增强人型机器人遥操作的稳定性。","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004353v1-stability-aware-retargeting-for-humanoid-multi-contact-teleoperation.html"},{"id":"2510.04234v1","title":"Flexible Locomotion Learning with Diffusion Model Predictive Control","headline":"提出Diffusion-MPC，利用扩散模型预测控制实现腿式机器人灵活运动学习。","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004234v1-flexible-locomotion-learning-with-diffusion-model-predictive-control.html"},{"id":"2510.04076v1","title":"From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents","headline":"提出八种方法以提升数据驱动控制策略的安全性与效率","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004076v1-from-shadow-to-light-toward-safe-and-efficient-policy-learning-acros.html"},{"id":"2510.04171v1","title":"VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs","headline":"VBM-NET：利用等变TransporterNet和GNN学习移动操作的视觉基座位姿","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004171v1-vbm-net-visual-base-pose-learning-for-mobile-manipulation-using-equi.html"},{"id":"2510.04246v1","title":"ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context","headline":"ContextVLA：通过分摊多帧上下文的视觉-语言-动作模型，提升机器人任务性能。","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004246v1-contextvla-vision-language-action-model-with-amortized-multi-frame-c.html"},{"id":"2510.04168v2","title":"Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation","headline":"提出基于强化学习的挖掘机抓取石块方法，无需显式建模。","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004168v2-learning-to-capture-rocks-using-an-excavator-a-reinforcement-learnin.html"},{"id":"2510.04041v1","title":"SITCOM: Scaling Inference-Time COMpute for VLAs","headline":"SITCOM：通过扩展推理时计算能力提升VLA模型在机器人控制中的性能","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004041v1-sitcom-scaling-inference-time-compute-for-vlas.html"},{"id":"2510.04190v1","title":"Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification","headline":"提出基于多模态深度学习的Zenbo巡逻机器人，用于实时识别和通知违章停车。","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004190v1-zenbo-patrol-a-social-assistive-robot-based-on-multimodal-deep-learn.html"},{"id":"2510.04354v1","title":"Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators","headline":"提出SureSim框架以解决机器人策略评估的可靠性问题","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004354v1-reliable-and-scalable-robot-policy-evaluation-with-imperfect-simulat.html"},{"id":"2510.04278v1","title":"Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit","headline":"提出FactorMPC：基于因子图的流形上集成规划与控制工具包","tag":"cs.RO","date":"2025-10-05","url":"cs-RO/2025-10-05/papers/251004278v1-integrated-planning-and-control-on-manifolds-factor-graph-representa.html"},{"id":"2510.04039v1","title":"\\textsc{GUI-Spotlight}: Adaptive Iterative Focus Refinement for Enhanced GUI Visual Grounding","headline":"GUI-Spotlight：自适应迭代聚焦优化，增强GUI视觉定位","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004039v1-textscgui-spotlight-adaptive-iterative-focus-refinement-for-enhanced.html"},{"id":"2510.04142v1","title":"Learning from All: Concept Alignment for Autonomous Distillation from Multiple Drifting MLLMs","headline":"提出概念对齐的自主蒸馏方法，解决多漂移MLLM的知识蒸馏问题","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004142v1-learning-from-all-concept-alignment-for-autonomous-distillation-from.html"},{"id":"2510.04125v1","title":"Joint Learning of Pose Regression and Denoising Diffusion with Score Scaling Sampling for Category-level 6D Pose Estimation","headline":"提出基于姿态回归和去噪扩散联合学习的类别级6D姿态估计方法","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004125v1-joint-learning-of-pose-regression-and-denoising-diffusion-with-score.html"},{"id":"2510.04111v1","title":"Learning Efficient Meshflow and Optical Flow from Event Cameras","headline":"提出EEMFlow网络，解决事件相机Meshflow和光流高效估计问题，并构建高分辨率数据集HREM。","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004111v1-learning-efficient-meshflow-and-optical-flow-from-event-cameras.html"},{"id":"2510.04390v1","title":"MorphoSim: An Interactive, Controllable, and Editable Language-guided 4D World Simulator","headline":"MorphoSim：一种可交互、可控、可编辑的语言引导4D世界模拟器","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004390v1-morphosim-an-interactive-controllable-and-editable-language-guided-4.html"},{"id":"2510.04333v1","title":"RAP: 3D Rasterization Augmented End-to-End Planning","headline":"提出RAP：基于光栅化的端到端规划，提升驾驶策略的闭环鲁棒性和长尾泛化能力。","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004333v1-rap-3d-rasterization-augmented-end-to-end-planning.html"},{"id":"2510.04145v1","title":"Automating construction safety inspections using a multi-modal vision-language RAG framework","headline":"提出SiteShield，利用多模态RAG框架自动化建筑安全检查报告生成。","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004145v1-automating-construction-safety-inspections-using-a-multi-modal-visio.html"},{"id":"2510.04057v1","title":"MetaFind: Scene-Aware 3D Asset Retrieval for Coherent Metaverse Scene Generation","headline":"MetaFind：提出场景感知的3D资产检索框架，用于生成一致的元宇宙场景","tag":"cs.CV","date":"2025-10-05","url":"cs-CV/2025-10-05/papers/251004057v1-metafind-scene-aware-3d-asset-retrieval-for-coherent-metaverse-scene.html"},{"id":"2510.04280v1","title":"A KL-regularization framework for learning to plan with adaptive priors","headline":"提出PO-MPC框架，通过KL正则化学习自适应先验的规划策略，提升MBRL性能。","tag":"cs.LG","date":"2025-10-05","url":"cs-LG/2025-10-05/papers/251004280v1-a-kl-regularization-framework-for-learning-to-plan-with-adaptive-pri.html"},{"id":"2510.04331v1","title":"DoRAN: Stabilizing Weight-Decomposed Low-Rank Adaptation via Noise Injection and Auxiliary Networks","headline":"DoRAN：通过噪声注入和辅助网络稳定权重分解低秩适应","tag":"cs.LG","date":"2025-10-05","url":"cs-LG/2025-10-05/papers/251004331v1-doran-stabilizing-weight-decomposed-low-rank-adaptation-via-noise-in.html"},{"id":"2510.04010v1","title":"Visual Lifelog Retrieval through Captioning-Enhanced Interpretation","headline":"提出CIVIL系统以解决个人视觉生活日志检索问题","tag":"cs.CL","date":"2025-10-05","url":"cs-CL/2025-10-05/papers/251004010v1-visual-lifelog-retrieval-through-captioning-enhanced-interpretation.html"},{"id":"2510.03885v1","title":"Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning","headline":"提出基于3D隐空间地图的移动操作策略学习方法，增强空间和时间推理能力。","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003885v1-seeing-the-bigger-picture-3d-latent-mapping-for-mobile-manipulation-.html"},{"id":"2510.03599v1","title":"Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning","headline":"提出基于接触的统一多任务机器人学习框架，实现通用运动与操作策略","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003599v1-learning-to-act-through-contact-a-unified-view-of-multi-task-robot-l.html"},{"id":"2510.03895v1","title":"NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation","headline":"提出NoTVLA框架，通过稀疏轨迹学习解决VLA模型中的灾难性遗忘问题，提升机器人操作的泛化性。","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003895v1-notvla-narrowing-of-dense-action-trajectories-for-generalizable-robo.html"},{"id":"2510.03660v1","title":"An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion","headline":"提出一种新型无束缚磁驱动尺蠖软体机器人，实现快速爬行运动","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003660v1-an-amphibious-untethered-inchworm-soft-robot-for-fast-crawling-locom.html"},{"id":"2510.03706v1","title":"EmbodiSwap for Zero-Shot Robot Imitation Learning","headline":"EmbodiSwap：利用合成数据实现机器人零样本模仿学习","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003706v1-embodiswap-for-zero-shot-robot-imitation-learning.html"},{"id":"2510.03919v1","title":"TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry","headline":"提出TCB-VIO，一种基于焦平面传感器的高帧率紧耦合视觉惯性里程计","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003919v1-tcb-vio-tightly-coupled-focal-plane-binary-enhanced-visual-inertial-.html"},{"id":"2510.03875v1","title":"COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments","headline":"COVER：面向半静态环境固定时间运动规划的覆盖验证路径图","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003875v1-covercoverage-verified-roadmaps-for-fixed-time-motion-planning-in-co.html"},{"id":"2510.03768v1","title":"Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics","headline":"提出基于模型的自适应精度控制方法，解决不确定动力学下的桌面平面推移任务。","tag":"cs.RO","date":"2025-10-04","url":"cs-RO/2025-10-04/papers/251003768v1-model-based-adaptive-precision-control-for-tabletop-planar-pushing-u.html"},{"id":"2510.03858v1","title":"Cross-View Open-Vocabulary Object Detection in Aerial Imagery","headline":"提出跨视角开放词汇目标检测框架，解决航拍图像目标识别难题","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003858v1-cross-view-open-vocabulary-object-detection-in-aerial-imagery.html"},{"id":"2510.03857v1","title":"Optimized Minimal 4D Gaussian Splatting","headline":"OMG4：优化最小4D高斯溅射，显著降低动态场景表示的存储开销。","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003857v1-optimized-minimal-4d-gaussian-splatting.html"},{"id":"2510.03827v1","title":"LIBERO-PRO: Towards Robust and Fair Evaluation of Vision-Language-Action Models Beyond Memorization","headline":"提出LIBERO-PRO以解决现有VLA模型评估不公正问题","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003827v1-libero-pro-towards-robust-and-fair-evaluation-of-vision-language-act.html"},{"id":"2510.03853v1","title":"UGround: Towards Unified Visual Grounding with Unrolled Transformers","headline":"UGround：提出基于解缠Transformer的统一视觉定位框架，解决误差累积和缺乏空间信息问题。","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003853v1-uground-towards-unified-visual-grounding-with-unrolled-transformers.html"},{"id":"2510.03896v1","title":"Bridge Thinking and Acting: Unleashing Physical Potential of VLM with Generalizable Action Expert","headline":"提出基于可泛化动作专家的框架，提升VLM在物理世界的动作执行能力","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003896v1-bridge-thinking-and-acting-unleashing-physical-potential-of-vlm-with.html"},{"id":"2510.03880v1","title":"Exploring Instruction Data Quality for Explainable Image Quality Assessment","headline":"针对可解释图像质量评估，提出基于聚类的数据选择方法IQA-Select，提升数据效率。","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003880v1-exploring-instruction-data-quality-for-explainable-image-quality-ass.html"},{"id":"2510.03909v1","title":"Generating Human Motion Videos using a Cascaded Text-to-Video Framework","headline":"提出CAMEO级联框架，用于从文本生成逼真的人体运动视频","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003909v1-generating-human-motion-videos-using-a-cascaded-text-to-video-framew.html"},{"id":"2510.03821v1","title":"Contrastive-SDE: Guiding Stochastic Differential Equations with Contrastive Learning for Unpaired Image-to-Image Translation","headline":"提出Contrastive-SDE，利用对比学习引导随机微分方程，解决非配对图像转换问题。","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003821v1-contrastive-sde-guiding-stochastic-differential-equations-with-contr.html"},{"id":"2510.06254v1","title":"Enhanced Self-Distillation Framework for Efficient Spiking Neural Network Training","headline":"提出增强型自蒸馏框架，用于高效脉冲神经网络训练","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251006254v1-enhanced-self-distillation-framework-for-efficient-spiking-neural-ne.html"},{"id":"2510.03606v1","title":"Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops","headline":"DINOv2深度解读：非监督Transformer预训练，自蒸馏与均值教师方法","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003606v1-unsupervised-transformer-pre-training-for-images-self-distillation-m.html"},{"id":"2510.03955v1","title":"Harnessing Synthetic Preference Data for Enhancing Temporal Understanding of Video-LLMs","headline":"TimeWarp：利用合成偏好数据增强视频大语言模型的时间理解能力","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003955v1-harnessing-synthetic-preference-data-for-enhancing-temporal-understa.html"},{"id":"2510.03921v1","title":"Talking Tennis: Language Feedback from 3D Biomechanical Action Recognition","headline":"提出基于3D生物力学动作识别的网球动作语言反馈框架，提升训练效果。","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003921v1-talking-tennis-language-feedback-from-3d-biomechanical-action-recogn.html"},{"id":"2510.03874v1","title":"DHQA-4D: Perceptual Quality Assessment of Dynamic 4D Digital Human","headline":"提出DHQA-4D数据集与DynaMesh-Rater模型，用于动态4D数字人感知质量评估","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003874v1-dhqa-4d-perceptual-quality-assessment-of-dynamic-4d-digital-human.html"},{"id":"2510.03751v1","title":"The Overlooked Value of Test-time Reference Sets in Visual Place Recognition","headline":"提出参考集微调方法，提升视觉定位在跨域场景下的泛化性能","tag":"cs.CV","date":"2025-10-04","url":"cs-CV/2025-10-04/papers/251003751v1-the-overlooked-value-of-test-time-reference-sets-in-visual-place-rec.html"},{"id":"2510.03964v1","title":"Enhancing Foveated Rendering with Weighted Reservoir Sampling","headline":"提出加权水库抽样方法，提升注视点渲染的感知质量和效率","tag":"cs.GR","date":"2025-10-04","url":"cs-GR/2025-10-04/papers/251003964v1-enhancing-foveated-rendering-with-weighted-reservoir-sampling.html"},{"id":"2510.03592v1","title":"Deep Reinforcement Learning for Multi-Agent Coordination","headline":"提出基于虚拟信息素的S-MADRL框架，解决拥挤环境中多智能体高效协同问题","tag":"cs.LG","date":"2025-10-04","url":"cs-LG/2025-10-04/papers/251003592v1-deep-reinforcement-learning-for-multi-agent-coordination.html"},{"id":"2510.03823v1","title":"Distributed Area Coverage with High Altitude Balloons Using Multi-Agent Reinforcement Learning","headline":"提出基于多智能体强化学习的高空气球分布式区域覆盖方法","tag":"cs.LG","date":"2025-10-04","url":"cs-LG/2025-10-04/papers/251003823v1-distributed-area-coverage-with-high-altitude-balloons-using-multi-ag.html"},{"id":"2510.03727v1","title":"Bridging the Gap Between Multimodal Foundation Models and World Models","headline":"弥合多模态基础模型与世界模型之间的差距，提升推理与生成能力","tag":"cs.AI","date":"2025-10-04","url":"cs-AI/2025-10-04/papers/251003727v1-bridging-the-gap-between-multimodal-foundation-models-and-world-mode.html"},{"id":"2511.00004v1","title":"Multimodal Learning with Augmentation Techniques for Natural Disaster Assessment","headline":"针对自然灾害评估，提出基于增强技术的多模态学习方法","tag":"cs.AI","date":"2025-10-04","url":"cs-AI/2025-10-04/papers/251100004v1-multimodal-learning-with-augmentation-techniques-for-natural-disaste.html"},{"id":"2510.03663v2","title":"UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG","headline":"提出UniDoc-Bench，用于评估文档型多模态RAG系统的统一基准","tag":"cs.CL","date":"2025-10-04","url":"cs-CL/2025-10-04/papers/251003663v2-unidoc-bench-a-unified-benchmark-for-document-centric-multimodal-rag.html"},{"id":"2510.03142v1","title":"MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning","headline":"提出MM-Nav：一种基于多视角VLA模型和多专家学习的鲁棒视觉导航方法","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003142v1-mm-nav-multi-view-vla-model-for-robust-visual-navigation-via-multi-e.html"},{"id":"2510.03022v1","title":"HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton","headline":"HumanoidExo：通过可穿戴外骨骼实现可扩展的全身人形机器人操作","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003022v1-humanoidexo-scalable-whole-body-humanoid-manipulation-via-wearable-e.html"},{"id":"2510.03081v1","title":"Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot","headline":"提出共设计机制以提升人形机器人智能与适应性","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003081v1-embracing-evolution-a-call-for-body-control-co-design-in-embodied-hu.html"},{"id":"2510.03460v1","title":"Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching","headline":"提出基于点云条件Flow Matching的优化型机器人运动规划快速启动方法","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003460v1-warm-starting-optimization-based-motion-planning-for-robotic-manipul.html"},{"id":"2510.03529v1","title":"LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy","headline":"LapSurgie：提出基于人型机器人的遥操作腹腔镜手术框架","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003529v1-lapsurgie-humanoid-robots-performing-surgery-via-teleoperated-handhe.html"},{"id":"2510.02738v2","title":"Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data","headline":"提出力场引导的3D柔顺流匹配策略，解决接触密集型任务中的力控问题","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002738v2-flow-with-the-force-field-learning-3d-compliant-flow-matching-polici.html"},{"id":"2510.02728v2","title":"Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4","headline":"提出Caption引导的检索系统，提升跨模态无人机导航中图文检索的精度。","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002728v2-team-xiaomi-ev-ad-vla-caption-guided-retrieval-system-for-cross-moda.html"},{"id":"2510.03504v1","title":"Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning","headline":"提出基于高阶控制障碍函数的多无人机分布式连接维持与恢复框架","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003504v1-distributed-connectivity-maintenance-and-recovery-for-quadrotor-moti.html"},{"id":"2510.02885v1","title":"Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots","headline":"提出基于点云和控制障碍函数的模型预测控制算法，用于自主移动机器人的安全导航。","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002885v1-point-cloud-based-control-barrier-functions-for-model-predictive-con.html"},{"id":"2510.02851v2","title":"Action Deviation-Aware Inference for Low-Latency Wireless Robots","headline":"提出ADAHI，通过动作偏差感知推理降低无线机器人低延迟需求。","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002851v2-action-deviation-aware-inference-for-low-latency-wireless-robots.html"},{"id":"2510.02976v1","title":"Real-Time Nonlinear Model Predictive Control of Heavy-Duty Skid-Steered Mobile Platform for Trajectory Tracking Tasks","headline":"提出重型滑移转向移动平台实时非线性模型预测控制，用于轨迹跟踪任务","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002976v1-real-time-nonlinear-model-predictive-control-of-heavy-duty-skid-stee.html"},{"id":"2510.03011v1","title":"3D-CovDiffusion: 3D-Aware Diffusion Policy for Coverage Path Planning","headline":"提出3D-CovDiffusion，用于生成高覆盖率的工业表面处理轨迹","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003011v1-3d-covdiffusion-3d-aware-diffusion-policy-for-coverage-path-planning.html"},{"id":"2510.02716v2","title":"A $1000\\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps","headline":"提出iLLM-A*算法，加速LLM增强的大规模栅格地图路径规划超1000倍","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251002716v2-a-1000times-faster-llm-enhanced-algorithm-for-path-planning-in-large.html"},{"id":"2510.03457v2","title":"Optimal swimming with body compliance in an overdamped medium","headline":"提出基于几何力学的柔顺游泳机器人优化框架，实现颗粒介质中的高效运动控制。","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003457v2-optimal-swimming-with-body-compliance-in-an-overdamped-medium.html"},{"id":"2510.03031v1","title":"Long-Term Human Motion Prediction Using Spatio-Temporal Maps of Dynamics","headline":"提出基于动态时空地图的长时程人体运动预测方法，提升机器人应用中的安全性。","tag":"cs.RO","date":"2025-10-03","url":"cs-RO/2025-10-03/papers/251003031v1-long-term-human-motion-prediction-using-spatio-temporal-maps-of-dyna.html"},{"id":"2510.02732v1","title":"From Tokens to Nodes: Semantic-Guided Motion Control for Dynamic 3D Gaussian Splatting","headline":"提出语义引导的动态3D高斯溅射运动控制方法，解决单目视频动态重建中的控制点分配难题。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002732v1-from-tokens-to-nodes-semantic-guided-motion-control-for-dynamic-3d-g.html"},{"id":"2510.02722v1","title":"MoGIC: Boosting Motion Generation via Intention Understanding and Visual Context","headline":"MoGIC：通过意图理解和视觉上下文增强运动生成","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002722v1-mogic-boosting-motion-generation-via-intention-understanding-and-vis.html"},{"id":"2510.03232v1","title":"LEAML: Label-Efficient Adaptation to Out-of-Distribution Visual Tasks for Multimodal Large Language Models","headline":"LEAML：面向多模态大语言模型，实现标签高效的领域外视觉任务自适应","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003232v1-leaml-label-efficient-adaptation-to-out-of-distribution-visual-tasks.html"},{"id":"2510.03104v1","title":"Geometry Meets Vision: Revisiting Pretrained Semantics in Distilled Fields","headline":"研究几何信息在神经辐射场语义蒸馏中的作用，并提出SPINE框架实现无初始猜测的辐射场反演。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003104v1-geometry-meets-vision-revisiting-pretrained-semantics-in-distilled-f.html"},{"id":"2510.03555v1","title":"GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis","headline":"提出GAS-MIL框架，用于数字病理图像分析中集成多个预训练模型。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003555v1-gas-mil-group-aggregative-selection-multi-instance-learning-for-ense.html"},{"id":"2510.02909v1","title":"Training-Free Out-Of-Distribution Segmentation With Foundation Models","headline":"提出一种免训练的异常分割方法，利用预训练模型进行域外检测。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002909v1-training-free-out-of-distribution-segmentation-with-foundation-model.html"},{"id":"2510.02745v2","title":"Retrv-R1: A Reasoning-Driven MLLM Framework for Universal and Efficient Multimodal Retrieval","headline":"提出Retrv-R1，一种基于推理驱动的多模态大语言模型框架，用于通用且高效的多模态检索。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002745v2-retrv-r1-a-reasoning-driven-mllm-framework-for-universal-and-efficie.html"},{"id":"2510.03545v1","title":"SketchPlan: Diffusion Based Drone Planning From Human Sketches","headline":"SketchPlan：基于扩散模型的无人机规划，从人类草图生成飞行路径","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003545v1-sketchplan-diffusion-based-drone-planning-from-human-sketches.html"},{"id":"2510.03455v1","title":"PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology","headline":"PEaRL：通过通路增强表示学习，从组织学图像预测基因和通路表达","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003455v1-pearl-pathway-enhanced-representation-learning-for-gene-and-pathway-.html"},{"id":"2510.02922v1","title":"Multimodal Carotid Risk Stratification with Large Vision-Language Models: Benchmarking, Fine-Tuning, and Clinical Insights","headline":"利用大型视觉-语言模型进行多模态颈动脉风险分层","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002922v1-multimodal-carotid-risk-stratification-with-large-vision-language-mo.html"},{"id":"2510.02876v1","title":"ELMF4EggQ: Ensemble Learning with Multimodal Feature Fusion for Non-Destructive Egg Quality Assessment","headline":"ELMF4EggQ：多模态特征融合的集成学习用于鸡蛋无损质量评估","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002876v1-elmf4eggq-ensemble-learning-with-multimodal-feature-fusion-for-non-d.html"},{"id":"2510.02789v1","title":"Align Your Query: Representation Alignment for Multimodality Medical Object Detection","headline":"提出多模态上下文注意力机制以解决医学目标检测中的表示对齐问题","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002789v1-align-your-query-representation-alignment-for-multimodality-medical-.html"},{"id":"2510.03135v2","title":"Mask2IV: Interaction-Centric Video Generation via Mask Trajectories","headline":"Mask2IV：通过Mask轨迹实现交互中心视频生成，无需密集Mask标注。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003135v2-mask2iv-interaction-centric-video-generation-via-mask-trajectories.html"},{"id":"2510.03550v2","title":"Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!","headline":"提出DragStream，实现基于拖拽的流式交互视频编辑，支持任意对象、任意时刻的精细控制。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003550v2-streaming-drag-oriented-interactive-video-manipulation-drag-anything.html"},{"id":"2510.03152v1","title":"ReeMark: Reeb Graphs for Simulating Patterns of Life in Spatiotemporal Trajectories","headline":"提出ReeMark，利用Reeb图模拟时空轨迹中的生活模式，用于城市规划等。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003152v1-reemark-reeb-graphs-for-simulating-patterns-of-life-in-spatiotempora.html"},{"id":"2510.02987v1","title":"TIT-Score: Evaluating Long-Prompt Based Text-to-Image Alignment via Text-to-Image-to-Text Consistency","headline":"提出TIT-Score，通过文本-图像-文本一致性评估长文本提示下的文图对齐质量","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002987v1-tit-score-evaluating-long-prompt-based-text-to-image-alignment-via-t.html"},{"id":"2510.02912v2","title":"Don't Just Chase \"Highlighted Tokens\" in MLLMs: Revisiting Visual Holistic Context Retention","headline":"HoloV：一种视觉token剪枝框架，通过全局上下文保留提升多模态大语言模型效率。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002912v2-dont-just-chase-highlighted-tokens-in-mllms-revisiting-visual-holist.html"},{"id":"2510.02778v1","title":"AdaRD-key: Adaptive Relevance-Diversity Keyframe Sampling for Long-form Video understanding","headline":"提出AdaRD-Key，用于查询驱动的长视频关键帧自适应采样，提升视频理解性能。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002778v1-adard-key-adaptive-relevance-diversity-keyframe-sampling-for-long-fo.html"},{"id":"2510.02654v1","title":"Smart-GRPO: Smartly Sampling Noise for Efficient RL of Flow-Matching Models","headline":"Smart-GRPO：优化噪声采样，提升Flow-Matching模型强化学习效率","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002654v1-smart-grpo-smartly-sampling-noise-for-efficient-rl-of-flow-matching-.html"},{"id":"2510.08589v1","title":"Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes","headline":"利用多模态LLM高效微调，解决低数据量下的目标检测问题","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251008589v1-beyond-cnns-efficient-fine-tuning-of-multi-modal-llms-for-object-det.html"},{"id":"2510.02790v1","title":"MaskCD: Mitigating LVLM Hallucinations by Image Head Masked Contrastive Decoding","headline":"提出MaskCD，通过图像头掩码对比解码缓解LVLM幻觉问题","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002790v1-maskcd-mitigating-lvlm-hallucinations-by-image-head-masked-contrasti.html"},{"id":"2510.03163v3","title":"ROGR: Relightable 3D Objects using Generative Relighting","headline":"ROGR：利用生成式光照重构可重新光照的3D物体模型","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003163v3-rogr-relightable-3d-objects-using-generative-relighting.html"},{"id":"2510.02691v2","title":"FSFSplatter: Build Surface and Novel Views with Sparse-Views within 2min","headline":"FSFSplatter：提出快速表面重建方法，仅用稀疏视图在2分钟内构建场景。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002691v2-fsfsplatter-build-surface-and-novel-views-with-sparse-views-within-2.html"},{"id":"2510.03540v1","title":"Domain Generalization for Semantic Segmentation: A Survey","headline":"领域泛化语义分割综述：分析方法与性能，强调基础模型的影响","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003540v1-domain-generalization-for-semantic-segmentation-a-survey.html"},{"id":"2510.03441v1","title":"Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning","headline":"Spatial-ViLT通过多任务学习增强视觉空间推理能力","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003441v1-spatial-vilt-enhancing-visual-spatial-reasoning-through-multi-task-l.html"},{"id":"2510.03110v1","title":"GeoComplete: Geometry-Aware Diffusion for Reference-Driven Image Completion","headline":"GeoComplete：提出几何感知扩散模型，用于参考图像驱动的图像补全，显著提升几何一致性。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003110v1-geocomplete-geometry-aware-diffusion-for-reference-driven-image-comp.html"},{"id":"2510.03376v1","title":"Visual Language Model as a Judge for Object Detection in Industrial Diagrams","headline":"提出基于视觉语言模型的工业图纸对象检测质量评估框架","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003376v1-visual-language-model-as-a-judge-for-object-detection-in-industrial-.html"},{"id":"2510.02994v1","title":"Towards Scalable and Consistent 3D Editing","headline":"提出3DEditFormer，实现可扩展且一致的3D编辑，并构建大规模数据集3DEditVerse。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002994v1-towards-scalable-and-consistent-3d-editing.html"},{"id":"2510.02780v1","title":"Reasoning Riddles: How Explainability Reveals Cognitive Limits in Vision-Language Models","headline":"通过可解释性分析揭示视觉-语言模型在谜题推理中的认知局限","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251002780v1-reasoning-riddles-how-explainability-reveals-cognitive-limits-in-vis.html"},{"id":"2510.03224v1","title":"Test-Time Defense Against Adversarial Attacks via Stochastic Resonance of Latent Ensembles","headline":"提出基于潜空间集成的随机共振对抗攻击防御方法，无需训练且适用多种任务。","tag":"cs.CV","date":"2025-10-03","url":"cs-CV/2025-10-03/papers/251003224v1-test-time-defense-against-adversarial-attacks-via-stochastic-resonan.html"},{"id":"2510.02884v1","title":"GS-Share: Enabling High-fidelity Map Sharing with Incremental Gaussian Splatting","headline":"GS-Share：通过增量高斯溅射实现高保真地图共享","tag":"cs.GR","date":"2025-10-03","url":"cs-GR/2025-10-03/papers/251002884v1-gs-share-enabling-high-fidelity-map-sharing-with-incremental-gaussia.html"},{"id":"2510.02651v1","title":"Visualizing Spatial Point Clouds: A Task-Oriented Taxonomy","headline":"提出面向任务的三维点云可视化分类法，提升可视化效果与可解释性","tag":"cs.GR","date":"2025-10-03","url":"cs-GR/2025-10-03/papers/251002651v1-visualizing-spatial-point-clouds-a-task-oriented-taxonomy.html"},{"id":"2510.03375v1","title":"Conditional Pseudo-Supervised Contrast for Data-Free Knowledge Distillation","headline":"提出条件伪监督对比学习，用于解决无数据知识蒸馏中的样本模糊和多样性不足问题","tag":"cs.LG","date":"2025-10-03","url":"cs-LG/2025-10-03/papers/251003375v1-conditional-pseudo-supervised-contrast-for-data-free-knowledge-disti.html"},{"id":"2510.03569v2","title":"Longitudinal Flow Matching for Trajectory Modeling","headline":"提出插值多边际流匹配(IMMFM)用于解决轨迹建模中稀疏采样和高维问题","tag":"cs.LG","date":"2025-10-03","url":"cs-LG/2025-10-03/papers/251003569v2-longitudinal-flow-matching-for-trajectory-modeling.html"},{"id":"2510.03153v1","title":"Improving Cooperation in Collaborative Embodied AI","headline":"通过提示工程优化，提升具身AI协作环境中的智能体合作性能","tag":"cs.AI","date":"2025-10-03","url":"cs-AI/2025-10-03/papers/251003153v1-improving-cooperation-in-collaborative-embodied-ai.html"},{"id":"2510.02252v1","title":"Retargeting Matters: General Motion Retargeting for Humanoid Motion Tracking","headline":"提出通用运动重定向(GMR)方法，提升人型机器人运动跟踪策略的鲁棒性和真实性。","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002252v1-retargeting-matters-general-motion-retargeting-for-humanoid-motion-t.html"},{"id":"2510.01708v3","title":"PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via Multi-Simulator Dynamics Randomization","headline":"PolySim：通过多模拟器动态随机化弥合人形机器人控制的Sim-to-Real差距","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001708v3-polysim-bridging-the-sim-to-real-gap-for-humanoid-control-via-multi-.html"},{"id":"2510.01843v1","title":"Like Playing a Video Game: Spatial-Temporal Optimization of Foot Trajectories for Controlled Football Kicking in Bipedal Robots","headline":"针对双足机器人足球踢球，提出时空优化足部轨迹规划方法","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001843v1-like-playing-a-video-game-spatial-temporal-optimization-of-foot-traj.html"},{"id":"2510.02538v1","title":"A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models","headline":"提出基于世界模型的在线模仿预训练方法，提升机械臂操作的Sim-to-Real迁移效率","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002538v1-a-recipe-for-efficient-sim-to-real-transfer-in-manipulation-with-onl.html"},{"id":"2510.01642v2","title":"FailSafe: Reasoning and Recovery from Failures in Vision-Language-Action Models","headline":"FailSafe：为视觉-语言-动作模型构建失败推理与恢复系统","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001642v2-failsafe-reasoning-and-recovery-from-failures-in-vision-language-act.html"},{"id":"2510.01607v1","title":"ActiveUMI: Robotic Manipulation with Active Perception from Robot-Free Human Demonstrations","headline":"ActiveUMI：通过机器人自由的人类演示进行主动感知的机器人操作","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001607v1-activeumi-robotic-manipulation-with-active-perception-from-robot-fre.html"},{"id":"2510.01711v2","title":"Contrastive Representation Regularization for Vision-Language-Action Models","headline":"提出机器人状态感知对比损失，提升视觉-语言-动作模型在机器人操作中的性能。","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001711v2-contrastive-representation-regularization-for-vision-language-action.html"},{"id":"2510.02469v1","title":"SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting","headline":"SIMSplat：提出基于语言对齐4D高斯溅射的预测性驾驶场景编辑方法","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002469v1-simsplat-predictive-driving-scene-editing-with-language-aligned-4d-g.html"},{"id":"2510.02248v1","title":"Performance-Guided Refinement for Visual Aerial Navigation using Editable Gaussian Splatting in FalconGym 2.0","headline":"提出基于可编辑高斯溅射和性能引导优化的视觉无人机导航方法","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002248v1-performance-guided-refinement-for-visual-aerial-navigation-using-edi.html"},{"id":"2510.01592v1","title":"Real-time Multi-Plane Segmentation Based on GPU Accelerated High-Resolution 3D Voxel Mapping for Legged Robot Locomotion","headline":"提出基于GPU加速高分辨率3D体素地图的实时多平面分割方法，用于提升腿式机器人运动性能。","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001592v1-real-time-multi-plane-segmentation-based-on-gpu-accelerated-high-res.html"},{"id":"2510.01661v1","title":"Symskill: Symbol and Skill Co-Invention for Data-Efficient and Real-Time Long-Horizon Manipulation","headline":"SymSkill：用于数据高效和实时长时程操作的符号与技能协同发明","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001661v1-symskill-symbol-and-skill-co-invention-for-data-efficient-and-real-t.html"},{"id":"2510.01603v2","title":"MiniBEE: A New Form Factor for Compact Bimanual Dexterity","headline":"提出MiniBEE以解决双手灵巧操作的复杂性问题","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001603v2-minibee-a-new-form-factor-for-compact-bimanual-dexterity.html"},{"id":"2510.02268v1","title":"Do You Know Where Your Camera Is? View-Invariant Policy Learning with Camera Conditioning","headline":"提出相机条件View-Invariant策略学习，提升机器人操作任务中视角泛化能力","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002268v1-do-you-know-where-your-camera-is-view-invariant-policy-learning-with.html"},{"id":"2510.01984v1","title":"SPARC: Spine with Prismatic and Revolute Compliance for Quadruped Robot","headline":"SPARC：用于四足机器人的具有棱柱和旋转柔顺性的脊柱模块","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001984v1-sparc-spine-with-prismatic-and-revolute-compliance-for-quadruped-rob.html"},{"id":"2510.02526v1","title":"U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation","headline":"提出U-LAG，解决机器人操作中感知滞后和不确定性下的目标重定位问题","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002526v1-u-lag-uncertainty-aware-lag-adaptive-goal-retargeting-for-robotic-ma.html"},{"id":"2510.02584v1","title":"Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC","headline":"提出基于Koopman MPC的高效动态环境最优路径规划方法","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002584v1-efficient-optimal-path-planning-in-dynamic-environments-using-koopma.html"},{"id":"2510.02298v1","title":"ARMADA: Autonomous Online Failure Detection and Human Shared Control Empower Scalable Real-world Deployment and Adaptation","headline":"ARMADA：结合自主故障检测与人机共享控制，实现机器人部署与自适应的扩展","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002298v1-armada-autonomous-online-failure-detection-and-human-shared-control-.html"},{"id":"2510.02616v1","title":"RSV-SLAM: Toward Real-Time Semantic Visual SLAM in Indoor Dynamic Environments","headline":"提出RSV-SLAM，用于室内动态环境中实时语义视觉SLAM","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002616v1-rsv-slam-toward-real-time-semantic-visual-slam-in-indoor-dynamic-env.html"},{"id":"2510.03342v3","title":"Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer","headline":"Gemini Robotics 1.5：通过具身推理、思考和运动迁移推进通用机器人前沿","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251003342v3-gemini-robotics-15-pushing-the-frontier-of-generalist-robots-with-ad.html"},{"id":"2510.02104v1","title":"LangGrasp: Leveraging Fine-Tuned LLMs for Language Interactive Robot Grasping with Ambiguous Instructions","headline":"LangGrasp：利用微调LLM实现语言交互式机器人抓取，解决指令歧义问题","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002104v1-langgrasp-leveraging-fine-tuned-llms-for-language-interactive-robot-.html"},{"id":"2510.01648v1","title":"Statistical Uncertainty Learning for Robust Visual-Inertial State Estimation","headline":"提出基于统计不确定性学习的鲁棒视觉惯性状态估计方法","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001648v1-statistical-uncertainty-learning-for-robust-visual-inertial-state-es.html"},{"id":"2510.02464v1","title":"ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in Extended Reality","headline":"ERUPT：用于扩展现实中机器人运动规划交互的开放工具包","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002464v1-erupt-an-open-toolkit-for-interfacing-with-robot-motion-planners-in-.html"},{"id":"2510.02129v1","title":"Stand Up, NAO! Increasing the Reliability of Stand-Up Motions Through Error Compensation in Position Control","headline":"针对NAO机器人，提出基于误差补偿的站立运动可靠性提升方案","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002129v1-stand-up-nao-increasing-the-reliability-of-stand-up-motions-through-.html"},{"id":"2510.01986v1","title":"Reducing Discomfort in Driving Simulators: Motion Cueing for Motion Sickness Mitigation","headline":"提出基于MPC的运动提示算法，降低驾驶模拟器中的晕动症","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001986v1-reducing-discomfort-in-driving-simulators-motion-cueing-for-motion-s.html"},{"id":"2510.01848v1","title":"GreenhouseSplat: A Dataset of Photorealistic Greenhouse Simulations for Mobile Robotics","headline":"GreenhouseSplat：用于移动机器人的光照逼真温室模拟数据集","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001848v1-greenhousesplat-a-dataset-of-photorealistic-greenhouse-simulations-f.html"},{"id":"2510.02614v2","title":"UMI-on-Air: Embodiment-Aware Guidance for Embodiment-Agnostic Visuomotor Policies","headline":"UMI-on-Air：提出具身感知引导的通用操作策略，解决空中机器人操作难题。","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251002614v2-umi-on-air-embodiment-aware-guidance-for-embodiment-agnostic-visuomo.html"},{"id":"2510.01675v2","title":"Geometric Backstepping Control of Omnidirectional Tiltrotors Incorporating Servo-Rotor Dynamics for Robustness against Sudden Disturbances","headline":"针对倾转旋翼飞行器，提出考虑伺服-旋翼动态特性的几何反步控制，提升抗扰动能力。","tag":"cs.RO","date":"2025-10-02","url":"cs-RO/2025-10-02/papers/251001675v2-geometric-backstepping-control-of-omnidirectional-tiltrotors-incorpo.html"},{"id":"2510.01623v1","title":"VLA-R1: Enhancing Reasoning in Vision-Language-Action Models","headline":"提出VLA-R1以解决视觉-语言-行动模型推理不足问题","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001623v1-vla-r1-enhancing-reasoning-in-vision-language-action-models.html"},{"id":"2510.01767v1","title":"LOBE-GS: Load-Balanced and Efficient 3D Gaussian Splatting for Large-Scale Scene Reconstruction","headline":"LoBE-GS：面向大规模场景重建的负载均衡高效3D高斯溅射","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001767v1-lobe-gs-load-balanced-and-efficient-3d-gaussian-splatting-for-large-.html"},{"id":"2510.02314v1","title":"StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions","headline":"StealthAttack：提出一种基于密度引导的3D高斯溅射隐蔽投毒攻击方法","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002314v1-stealthattack-robust-3d-gaussian-splatting-poisoning-via-density-gui.html"},{"id":"2510.02566v1","title":"PhysHMR: Learning Humanoid Control Policies from Vision for Physically Plausible Human Motion Reconstruction","headline":"PhysHMR：从视觉学习人形控制策略，实现物理上合理的人体运动重建","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002566v1-physhmr-learning-humanoid-control-policies-from-vision-for-physicall.html"},{"id":"2510.01576v1","title":"Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations","headline":"利用盲人和低视力人群视觉问题引导多模态大语言模型，实现主动视觉解读","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001576v1-guiding-multimodal-large-language-models-with-blind-and-low-vision-p.html"},{"id":"2510.02186v1","title":"GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation","headline":"GeoPurify通过几何蒸馏，以数据高效的方式实现开放词汇3D分割。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002186v1-geopurify-a-data-efficient-geometric-distillation-framework-for-open.html"},{"id":"2510.01991v1","title":"4DGS-Craft: Consistent and Interactive 4D Gaussian Splatting Editing","headline":"提出4DGS-Craft以解决4D高斯点云编辑一致性问题","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001991v1-4dgs-craft-consistent-and-interactive-4d-gaussian-splatting-editing.html"},{"id":"2510.02311v1","title":"Inferring Dynamic Physical Properties from Video Foundation Models","headline":"利用视频基础模型推断视频中的动态物理属性","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002311v1-inferring-dynamic-physical-properties-from-video-foundation-models.html"},{"id":"2510.02240v1","title":"RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via Multi-Stage Reinforcement Learning","headline":"提出RewardMap，通过多阶段强化学习解决细粒度视觉推理中的稀疏奖励问题","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002240v1-rewardmap-tackling-sparse-rewards-in-fine-grained-visual-reasoning-v.html"},{"id":"2510.03348v2","title":"Visual Odometry with Transformers","headline":"提出基于Transformer的视觉里程计VoT，实现端到端单目位姿回归。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251003348v2-visual-odometry-with-transformers.html"},{"id":"2510.02287v1","title":"MultiModal Action Conditioned Video Generation","headline":"提出多模态动作条件视频生成模型，提升机器人精细操作的模拟精度","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002287v1-multimodal-action-conditioned-video-generation.html"},{"id":"2510.02034v1","title":"GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing","headline":"GaussianMorphing：提出网格引导的3D高斯方法，实现语义感知的物体形变。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002034v1-gaussianmorphing-mesh-guided-3d-gaussians-for-semantic-aware-object-.html"},{"id":"2510.01582v1","title":"ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models","headline":"提出ImageNet-Think-250K，用于提升视觉语言模型多模态推理能力。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001582v1-imagenet-think-250k-a-large-scale-synthetic-dataset-for-multimodal-r.html"},{"id":"2510.02253v2","title":"DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing","headline":"DragFlow：利用区域监督释放DiT先验，实现卓越的拖拽编辑效果","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002253v2-dragflow-unleashing-dit-priors-with-region-based-supervision-for-dra.html"},{"id":"2510.01912v1","title":"Flow-Matching Guided Deep Unfolding for Hyperspectral Image Reconstruction","headline":"提出Flow-Matching引导的深度展开网络FMU，用于高光谱图像重建。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001912v1-flow-matching-guided-deep-unfolding-for-hyperspectral-image-reconstr.html"},{"id":"2510.02270v1","title":"microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for Fine-Grained Image Classification","headline":"microCLIP：通过粗细粒度Token融合实现无监督CLIP微调，提升细粒度图像分类性能","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002270v1-microclip-unsupervised-clip-adaptation-via-coarse-fine-token-fusion-.html"},{"id":"2510.02001v2","title":"Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output (SLSO) Framework","headline":"利用GPT-4o和SLSO框架自动生成牙科全景片中颌骨囊肿的诊断结果","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002001v2-generating-findings-for-jaw-cysts-in-dental-panoramic-radiographs-us.html"},{"id":"2510.01954v1","title":"Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs","headline":"提出Patch-as-Decodable-Token (PaDT)，实现MLLM中统一的多模态视觉任务处理。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001954v1-patch-as-decodable-token-towards-unified-multi-modal-vision-tasks-in.html"},{"id":"2510.01546v1","title":"Growing Visual Generative Capacity for Pre-Trained MLLMs","headline":"提出Bridge：一种基于混合Transformer架构的纯自回归统一多模态大语言模型，提升视觉生成能力。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001546v1-growing-visual-generative-capacity-for-pre-trained-mllms.html"},{"id":"2510.01540v1","title":"Towards Better Optimization For Listwise Preference in Diffusion Models","headline":"提出Diffusion-LPO，用于扩散模型中基于列表偏好的优化，提升图像质量和偏好对齐。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001540v1-towards-better-optimization-for-listwise-preference-in-diffusion-mod.html"},{"id":"2510.01662v1","title":"Discrete Facial Encoding: : A Framework for Data-driven Facial Display Discovery","headline":"提出离散面部编码(DFE)，用于数据驱动的面部表情发现，替代FACS。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001662v1-discrete-facial-encoding-a-framework-for-data-driven-facial-display-.html"},{"id":"2510.02313v1","title":"Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions","headline":"提出基于真实世界交互学习物体声音的检测框架，解决声音与物体的关联问题。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002313v1-clink-chop-thud-learning-object-sounds-from-real-world-interactions.html"},{"id":"2510.02561v1","title":"Oracle-RLAIF: An Improved Fine-Tuning Framework for Multi-modal Video Models through Reinforcement Learning from Ranking Feedback","headline":"提出Oracle-RLAIF框架，通过排序反馈强化学习提升多模态视频模型性能。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002561v1-oracle-rlaif-an-improved-fine-tuning-framework-for-multi-modal-video.html"},{"id":"2510.01681v1","title":"Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning","headline":"提出基于Rollout引导的自适应像素空间推理框架，提升VLM在细粒度视觉任务上的效率和准确性。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001681v1-look-less-reason-more-rollout-guided-adaptive-pixel-space-reasoning.html"},{"id":"2510.02571v1","title":"How Confident are Video Models? Empowering Video Models to Express their Uncertainty","headline":"提出一种框架以量化视频模型的不确定性","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002571v1-how-confident-are-video-models-empowering-video-models-to-express-th.html"},{"id":"2510.02295v1","title":"VideoNSA: Native Sparse Attention Scales Video Understanding","headline":"提出VideoNSA，通过原生稀疏注意力有效扩展视频理解模型的上下文长度。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002295v1-videonsa-native-sparse-attention-scales-video-understanding.html"},{"id":"2510.02282v2","title":"VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL","headline":"VidGuard-R1：利用推理MLLM和强化学习进行AI生成视频检测与解释","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002282v2-vidguard-r1-ai-generated-video-detection-and-explanation-via-reasoni.html"},{"id":"2510.02262v1","title":"From Frames to Clips: Efficient Key Clip Selection for Long-Form Video Understanding","headline":"提出F2C：通过高效关键片段选择提升长视频理解能力","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002262v1-from-frames-to-clips-efficient-key-clip-selection-for-long-form-vide.html"},{"id":"2510.02114v1","title":"FRIEREN: Federated Learning with Vision-Language Regularization for Segmentation","headline":"提出FRIEREN框架，利用视觉-语言正则化进行联邦学习语义分割，解决无标签数据下的领域泛化问题。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002114v1-frieren-federated-learning-with-vision-language-regularization-for-s.html"},{"id":"2510.03341v1","title":"OpusAnimation: Code-Based Dynamic Chart Generation","headline":"提出DCG-Bench基准和Qwen2.5-VL-DCG-3B模型，用于解决动态图表生成任务。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251003341v1-opusanimation-code-based-dynamic-chart-generation.html"},{"id":"2510.02284v2","title":"Learning to Generate Rigid Body Interactions with Video Diffusion Models","headline":"KineMask：利用视频扩散模型生成具有刚体交互的视频","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002284v2-learning-to-generate-rigid-body-interactions-with-video-diffusion-mo.html"},{"id":"2510.02601v1","title":"Ego-Exo 3D Hand Tracking in the Wild with a Mobile Multi-Camera Rig","headline":"提出一种移动多相机系统，用于在真实场景中进行ego-exo 3D手部追踪。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251002601v1-ego-exo-3d-hand-tracking-in-the-wild-with-a-mobile-multi-camera-rig.html"},{"id":"2510.01665v1","title":"Non-Rigid Structure-from-Motion via Differential Geometry with Recoverable Conformal Scale","headline":"提出Con-NRSfM，通过可恢复共形尺度微分几何解决非刚性结构重建问题。","tag":"cs.CV","date":"2025-10-02","url":"cs-CV/2025-10-02/papers/251001665v1-non-rigid-structure-from-motion-via-differential-geometry-with-recov.html"},{"id":"2510.01978v2","title":"ROI-GS: Interest-based Local Quality 3D Gaussian Splatting","headline":"提出ROI-GS，通过对象感知优化3D高斯溅射局部质量，提升感兴趣区域重建效果。","tag":"cs.GR","date":"2025-10-02","url":"cs-GR/2025-10-02/papers/251001978v2-roi-gs-interest-based-local-quality-3d-gaussian-splatting.html"},{"id":"2510.01690v1","title":"Multimodal Feedback for Task Guidance in Augmented Reality","headline":"提出结合触觉反馈的增强现实任务指导方法，提升空间精度和可用性","tag":"cs.GR","date":"2025-10-02","url":"cs-GR/2025-10-02/papers/251001690v1-multimodal-feedback-for-task-guidance-in-augmented-reality.html"},{"id":"2510.01619v1","title":"MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics","headline":"MPMAvatar：提出基于物理的精确鲁棒3D高斯Avatar学习框架","tag":"cs.GR","date":"2025-10-02","url":"cs-GR/2025-10-02/papers/251001619v1-mpmavatar-learning-3d-gaussian-avatars-with-accurate-and-robust-phys.html"},{"id":"2510.02069v3","title":"Spec-Gloss Surfels and Normal-Diffuse Priors for Relightable Glossy Objects","headline":"提出基于Spec-Gloss Surfels和法向-漫反射先验的可重光泽物体重建方法","tag":"cs.GR","date":"2025-10-02","url":"cs-GR/2025-10-02/papers/251002069v3-spec-gloss-surfels-and-normal-diffuse-priors-for-relightable-glossy-.html"},{"id":"2510.01677v1","title":"Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal Sentiment Analysis","headline":"提出自适应门控融合网络，解决多模态情感分析中模态质量差异问题","tag":"cs.LG","date":"2025-10-02","url":"cs-LG/2025-10-02/papers/251001677v1-beyond-simple-fusion-adaptive-gated-fusion-for-robust-multimodal-sen.html"},{"id":"2510.01545v2","title":"Predictive Preference Learning from Human Interventions","headline":"提出PPL：一种基于人类干预的预测偏好学习方法，提升交互式模仿学习效率。","tag":"cs.LG","date":"2025-10-02","url":"cs-LG/2025-10-02/papers/251001545v2-predictive-preference-learning-from-human-interventions.html"},{"id":"2510.02291v1","title":"Test-Time Anchoring for Discrete Diffusion Posterior Sampling","headline":"提出Anchored Posterior Sampling (APS)，用于离散扩散后验采样，解决逆问题。","tag":"cs.LG","date":"2025-10-02","url":"cs-LG/2025-10-02/papers/251002291v1-test-time-anchoring-for-discrete-diffusion-posterior-sampling.html"},{"id":"2510.02230v1","title":"The Reasoning Boundary Paradox: How Reinforcement Learning Constrains Language Models","headline":"揭示RLVR约束语言模型推理边界的悖论，并提出数据策展算法提升性能","tag":"cs.AI","date":"2025-10-02","url":"cs-AI/2025-10-02/papers/251002230v1-the-reasoning-boundary-paradox-how-reinforcement-learning-constrains.html"},{"id":"2510.06235v1","title":"Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)","headline":"利用多模态堆叠回归预测电影刺激下fMRI脑活动，Seinfeld团队Algonauts 2025挑战赛第十名","tag":"cs.AI","date":"2025-10-02","url":"cs-AI/2025-10-02/papers/251006235v1-stacked-regression-using-off-the-shelf-stimulus-tuned-and-fine-tuned.html"},{"id":"2510.01531v1","title":"Information Seeking for Robust Decision Making under Partial Observability","headline":"InfoSeeker：结合信息搜寻的LLM决策框架，提升部分可观测环境下的决策鲁棒性","tag":"cs.AI","date":"2025-10-02","url":"cs-AI/2025-10-02/papers/251001531v1-information-seeking-for-robust-decision-making-under-partial-observa.html"},{"id":"2510.01700v1","title":"VaPR -- Vision-language Preference alignment for Reasoning","headline":"VaPR：通过视觉-语言偏好对齐提升大型视觉语言模型的推理能力","tag":"cs.AI","date":"2025-10-02","url":"cs-AI/2025-10-02/papers/251001700v1-vapr-vision-language-preference-alignment-for-reasoning.html"},{"id":"2510.01845v1","title":"Model Merging to Maintain Language-Only Performance in Developmentally Plausible Multimodal Models","headline":"提出模型融合方法，提升多模态模型在语言任务中的性能表现","tag":"cs.CL","date":"2025-10-02","url":"cs-CL/2025-10-02/papers/251001845v1-model-merging-to-maintain-language-only-performance-in-developmental.html"},{"id":"2510.02425v1","title":"Words That Make Language Models Perceive","headline":"通过感官提示激活纯文本语言模型中的潜在多模态表征","tag":"cs.CL","date":"2025-10-02","url":"cs-CL/2025-10-02/papers/251002425v1-words-that-make-language-models-perceive.html"},{"id":"2510.00600v1","title":"Hybrid Training for Vision-Language-Action Models","headline":"提出混合训练HyT框架，加速视觉-语言-动作模型推理，兼顾性能与效率。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000600v1-hybrid-training-for-vision-language-action-models.html"},{"id":"2510.00695v2","title":"HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy","headline":"HAMLET：将视觉-语言-动作模型转化为历史感知策略，提升机器人操作性能","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000695v2-hamlet-switch-your-vision-language-action-model-into-a-history-aware.html"},{"id":"2510.00682v1","title":"Shared Object Manipulation with a Team of Collaborative Quadrupeds","headline":"提出基于腿式机器人团队的共享物体操作方法，解决复杂环境下的物体搬运问题","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000682v1-shared-object-manipulation-with-a-team-of-collaborative-quadrupeds.html"},{"id":"2510.01433v1","title":"AFFORD2ACT: Affordance-Guided Automatic Keypoint Selection for Generalizable and Lightweight Robotic Manipulation","headline":"AFFORD2ACT：提出基于可供性的自动关键点选择方法，用于通用且轻量级的机器人操作","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001433v1-afford2act-affordance-guided-automatic-keypoint-selection-for-genera.html"},{"id":"2510.01483v1","title":"VL-KnG: Visual Scene Understanding for Navigation Goal Identification using Spatiotemporal Knowledge Graphs","headline":"VL-KnG：利用时空知识图谱进行视觉场景理解，实现导航目标识别","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001483v1-vl-kng-visual-scene-understanding-for-navigation-goal-identification.html"},{"id":"2510.01389v1","title":"INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models","headline":"INSIGHT：提出一种基于序列内省的VLA模型帮助触发生成框架","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001389v1-insight-inference-time-sequence-introspection-for-generating-help-tr.html"},{"id":"2510.00491v1","title":"From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment","headline":"Traj2Action：通过轨迹对齐实现人手操作技能向机器人手臂的迁移","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000491v1-from-human-hands-to-robot-arms-manipulation-skills-transfer-via-traj.html"},{"id":"2510.01357v1","title":"Safe Motion Planning and Control Using Predictive and Adaptive Barrier Methods for Autonomous Surface Vessels","headline":"提出基于预测和自适应控制屏障函数的自主水面艇安全运动规划方法","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001357v1-safe-motion-planning-and-control-using-predictive-and-adaptive-barri.html"},{"id":"2510.00814v1","title":"RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator","headline":"提出RTFF策略，利用双臂机器人实现任意褶皱织物到目标平整状态的对齐","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000814v1-rtff-random-to-target-fabric-flattening-policy-using-dual-arm-manipu.html"},{"id":"2510.00703v1","title":"MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration","headline":"MultiPhysio-HRC：用于工业人机协作的多模态生理信号数据集","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000703v1-multiphysio-hrc-multimodal-physiological-signals-dataset-for-industr.html"},{"id":"2510.01438v2","title":"Differentiable Skill Optimisation for Powder Manipulation in Laboratory Automation","headline":"提出基于可微技能优化的粉末操作方法，用于实验室自动化。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001438v2-differentiable-skill-optimisation-for-powder-manipulation-in-laborat.html"},{"id":"2510.01068v1","title":"Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition","headline":"提出通用策略组合（GPC），无需额外训练即可提升扩散或Flow模型机器人策略性能。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001068v1-compose-your-policies-improving-diffusion-based-or-flow-based-robot-.html"},{"id":"2510.01023v1","title":"Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning","headline":"Prometheus：基于动捕和力反馈的通用开源遥操作系统，用于机器人学习数据集采集","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001023v1-prometheus-universal-open-source-mocap-based-teleoperation-system-wi.html"},{"id":"2510.00573v1","title":"GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks","headline":"GRITS：一种用于机器人食物舀取任务的防溢出引导扩散策略","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000573v1-grits-a-spillage-aware-guided-diffusion-policy-for-robot-food-scoopi.html"},{"id":"2510.01519v1","title":"Online Hierarchical Policy Learning using Physics Priors for Robot Navigation in Unknown Environments","headline":"提出基于物理先验的在线分层策略学习方法，用于未知环境下的机器人导航。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001519v1-online-hierarchical-policy-learning-using-physics-priors-for-robot-n.html"},{"id":"2510.01348v1","title":"Kilometer-Scale GNSS-Denied UAV Navigation via Heightmap Gradients: A Winning System from the SPRIN-D Challenge","headline":"提出基于高度图梯度的GNSS拒止无人机导航系统，赢得SPRIN-D挑战赛。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001348v1-kilometer-scale-gnss-denied-uav-navigation-via-heightmap-gradients-a.html"},{"id":"2510.00726v1","title":"CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation","headline":"提出Cross-State Transition Attention Transformer以解决机器人操作中的执行变异问题","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000726v1-crostata-cross-state-transition-attention-transformer-for-robotic-ma.html"},{"id":"2510.00783v1","title":"Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions","headline":"综述语义视觉SLAM技术，分析现状、挑战与未来方向","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251000783v1-semantic-visual-simultaneous-localization-and-mapping-a-survey-on-st.html"},{"id":"2510.01388v1","title":"VENTURA: Adapting Image Diffusion Models for Unified Task Conditioned Navigation","headline":"提出VENTURA以解决机器人导航任务中的适应性问题","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001388v1-ventura-adapting-image-diffusion-models-for-unified-task-conditioned.html"},{"id":"2510.01404v1","title":"How Well do Diffusion Policies Learn Kinematic Constraint Manifolds?","headline":"研究扩散策略学习运动学约束流形的能力，揭示数据集质量和大小的影响。","tag":"cs.RO","date":"2025-10-01","url":"cs-RO/2025-10-01/papers/251001404v1-how-well-do-diffusion-policies-learn-kinematic-constraint-manifolds.html"},{"id":"2510.00506v1","title":"Affordance-Guided Diffusion Prior for 3D Hand Reconstruction","headline":"提出基于可供性的扩散先验，用于解决3D手部重建中严重遮挡问题","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000506v1-affordance-guided-diffusion-prior-for-3d-hand-reconstruction.html"},{"id":"2510.00681v1","title":"Adaptive Event Stream Slicing for Open-Vocabulary Event-Based Object Detection via Vision-Language Knowledge Distillation","headline":"提出自适应事件流切片与知识蒸馏框架，实现开放词汇事件相机目标检测","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000681v1-adaptive-event-stream-slicing-for-open-vocabulary-event-based-object.html"},{"id":"2510.00818v1","title":"PhraseStereo: The First Open-Vocabulary Stereo Image Segmentation Dataset","headline":"提出PhraseStereo：首个开放词汇立体图像分割数据集，促进多模态语义理解。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000818v1-phrasestereo-the-first-open-vocabulary-stereo-image-segmentation-dat.html"},{"id":"2510.01119v1","title":"Instant4D: 4D Gaussian Splatting in Minutes","headline":"Instant4D：分钟级实现基于单目视频的4D高斯溅射动态场景重建","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001119v1-instant4d-4d-gaussian-splatting-in-minutes.html"},{"id":"2510.00515v1","title":"Efficient Multi-modal Large Language Models via Progressive Consistency Distillation","headline":"提出EPIC框架，通过渐进一致性蒸馏提升多模态大模型的效率","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000515v1-efficient-multi-modal-large-language-models-via-progressive-consiste.html"},{"id":"2510.00797v1","title":"Solar PV Installation Potential Assessment on Building Facades Based on Vision and Language Foundation Models","headline":"提出SF-SPA框架，利用视觉-语言模型评估建筑立面的光伏安装潜力","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000797v1-solar-pv-installation-potential-assessment-on-building-facades-based.html"},{"id":"2510.01513v1","title":"From Videos to Indexed Knowledge Graphs -- Framework to Marry Methods for Multimodal Content Analysis and Understanding","headline":"提出视频到索引知识图谱框架，融合多模态内容分析与理解方法","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001513v1-from-videos-to-indexed-knowledge-graphs-framework-to-marry-methods-f.html"},{"id":"2510.01370v1","title":"SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs","headline":"SPUS：一种轻量级且参数高效的偏微分方程基础模型","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001370v1-spus-a-lightweight-and-parameter-efficient-foundation-model-for-pdes.html"},{"id":"2510.00862v1","title":"Gather-Scatter Mamba: Accelerating Propagation with Efficient State Space Model","headline":"提出Gather-Scatter Mamba，结合注意力机制与选择性SSM加速视频超分中的时序传播。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000862v1-gather-scatter-mamba-accelerating-propagation-with-efficient-state-s.html"},{"id":"2510.00701v1","title":"Graph Integrated Multimodal Concept Bottleneck Model","headline":"提出MoE-SGT，通过图Transformer和混合专家模型增强多模态概念瓶颈模型，提升复杂概念推理能力。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000701v1-graph-integrated-multimodal-concept-bottleneck-model.html"},{"id":"2510.00561v1","title":"Assessing Foundation Models for Mold Colony Detection with Limited Training Data","headline":"利用少量训练数据，评估真菌菌落检测的基础模型性能","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000561v1-assessing-foundation-models-for-mold-colony-detection-with-limited-t.html"},{"id":"2510.00520v1","title":"CardioBench: Do Echocardiography Foundation Models Generalize Beyond the Lab?","headline":"CardioBench：评估心动超声影像基础模型泛化能力的标准化基准","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000520v1-cardiobench-do-echocardiography-foundation-models-generalize-beyond-.html"},{"id":"2510.00974v1","title":"JEPA-T: Joint-Embedding Predictive Architecture with Text Fusion for Image Generation","headline":"提出JEPA-T，通过文本融合的联合嵌入预测架构提升图像生成效果","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000974v1-jepa-t-joint-embedding-predictive-architecture-with-text-fusion-for-.html"},{"id":"2510.00855v1","title":"Can World Models Benefit VLMs for World Dynamics?","headline":"提出WorldLM，利用世界模型先验增强视觉语言模型的世界动态理解能力","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000855v1-can-world-models-benefit-vlms-for-world-dynamics.html"},{"id":"2510.00705v1","title":"Training-free Uncertainty Guidance for Complex Visual Tasks with MLLMs","headline":"提出一种免训练的MLLM不确定性引导框架，用于复杂视觉任务。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000705v1-training-free-uncertainty-guidance-for-complex-visual-tasks-with-mll.html"},{"id":"2510.01183v1","title":"EvoWorld: Evolving Panoramic World Generation with Explicit 3D Memory","headline":"EvoWorld：利用显式3D记忆演化的全景世界生成模型","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001183v1-evoworld-evolving-panoramic-world-generation-with-explicit-3d-memory.html"},{"id":"2510.00837v1","title":"Feature Identification for Hierarchical Contrastive Learning","headline":"提出两种层级对比学习方法，利用层级关系提升细粒度分类性能。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000837v1-feature-identification-for-hierarchical-contrastive-learning.html"},{"id":"2510.00652v1","title":"OTTER: Open-Tagging via Text-Image Representation for Multi-modal Understanding","headline":"OTTER：通过文本-图像表征进行开放标签多模态理解","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000652v1-otter-open-tagging-via-text-image-representation-for-multi-modal-und.html"},{"id":"2510.01454v1","title":"Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories","headline":"提出XMAS方法，通过跨模态对齐轨迹进行视觉语言模型高效数据选择。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001454v1-data-selection-for-fine-tuning-vision-language-models-via-cross-moda.html"},{"id":"2510.01186v1","title":"IMAGEdit: Let Any Subject Transform","headline":"IMAGEdit：提出一种免训练框架，实现任意数量视频主体的外观变换。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001186v1-imagedit-let-any-subject-transform.html"},{"id":"2510.01049v1","title":"KeySG: Hierarchical Keyframe-Based 3D Scene Graphs","headline":"KeySG：基于分层关键帧的3D场景图构建，提升语义丰富性和可扩展性","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001049v1-keysg-hierarchical-keyframe-based-3d-scene-graphs.html"},{"id":"2510.01009v1","title":"POVQA: Preference-Optimized Video Question Answering with Rationales for Data Efficiency","headline":"提出POVQA：一种数据高效的偏好优化视频问答方法，利用理由提升性能。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001009v1-povqa-preference-optimized-video-question-answering-with-rationales-.html"},{"id":"2510.00683v1","title":"ProtoMask: Segmentation-Guided Prototype Learning","headline":"ProtoMask：提出一种基于分割引导的原型学习方法，提升原型可解释性。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000683v1-protomask-segmentation-guided-prototype-learning.html"},{"id":"2510.06231v1","title":"CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation","headline":"CML-Bench：用于评估和提升大语言模型生成电影剧本的框架","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251006231v1-cml-bench-a-framework-for-evaluating-and-enhancing-llm-powered-movie.html"},{"id":"2510.00604v1","title":"Disentangling Foreground and Background for vision-Language Navigation via Online Augmentation","headline":"提出COFA，通过在线增强解耦前景与背景特征，提升视觉语言导航泛化性","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000604v1-disentangling-foreground-and-background-for-vision-language-navigati.html"},{"id":"2510.01362v1","title":"EvoStruggle: A Dataset Capturing the Evolution of Struggle across Activities and Skill Levels","headline":"EvoStruggle：构建技能学习过程中挣扎演变数据集，用于提升辅助系统性能。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001362v1-evostruggle-a-dataset-capturing-the-evolution-of-struggle-across-act.html"},{"id":"2510.01174v1","title":"Code2Video: A Code-centric Paradigm for Educational Video Generation","headline":"提出Code2Video框架，通过可执行代码生成专业教育视频，提升可控性和教学质量。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251001174v1-code2video-a-code-centric-paradigm-for-educational-video-generation.html"},{"id":"2510.00578v1","title":"Arbitrary Generative Video Interpolation","headline":"提出ArbInterp，实现任意时间戳和长度的生成式视频插帧。","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000578v1-arbitrary-generative-video-interpolation.html"},{"id":"2510.00570v1","title":"Adaptive Shared Experts with LoRA-Based Mixture of Experts for Multi-Task Learning","headline":"提出基于LoRA的自适应共享专家混合模型，提升多任务学习性能","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000570v1-adaptive-shared-experts-with-lora-based-mixture-of-experts-for-multi.html"},{"id":"2510.00483v1","title":"MathSticks: A Benchmark for Visual Symbolic Compositional Reasoning with Matchstick Puzzles","headline":"提出MathSticks：一个用于视觉符号组合推理的火柴棍谜题基准","tag":"cs.CV","date":"2025-10-01","url":"cs-CV/2025-10-01/papers/251000483v1-mathsticks-a-benchmark-for-visual-symbolic-compositional-reasoning-w.html"},{"id":"2510.01176v2","title":"Audio Driven Real-Time Facial Animation for Social Telepresence","headline":"提出一种基于音频驱动的实时面部动画系统，用于社交远程呈现。","tag":"cs.GR","date":"2025-10-01","url":"cs-GR/2025-10-01/papers/251001176v2-audio-driven-real-time-facial-animation-for-social-telepresence.html"},{"id":"2510.00824v1","title":"Virtual Reality Alters Perceived Functional Body Size","headline":"虚拟现实通过深度压缩改变感知到的功能性身体尺寸","tag":"cs.GR","date":"2025-10-01","url":"cs-GR/2025-10-01/papers/251000824v1-virtual-reality-alters-perceived-functional-body-size.html"},{"id":"2510.02403v1","title":"Glaucoma Detection and Structured OCT Report Generation via a Fine-tuned Multimodal Large Language Model","headline":"微调多模态大语言模型用于青光眼检测和结构化OCT报告生成","tag":"cs.AI","date":"2025-10-01","url":"cs-AI/2025-10-01/papers/251002403v1-glaucoma-detection-and-structured-oct-report-generation-via-a-fine-t.html"},{"id":"2510.00523v1","title":"VIRTUE: Visual-Interactive Text-Image Universal Embedder","headline":"提出VIRTUE：一种视觉交互式文本-图像通用嵌入模型，提升多模态表征能力。","tag":"cs.AI","date":"2025-10-01","url":"cs-AI/2025-10-01/papers/251000523v1-virtue-visual-interactive-text-image-universal-embedder.html"},{"id":"2510.01489v1","title":"A Robust Neural Control Design for Multi-drone Slung Payload Manipulation with Control Contraction Metrics","headline":"提出一种基于控制收缩度量的多无人机吊索负载操纵鲁棒神经控制方法","tag":"eess.SY","date":"2025-10-01","url":"eess-SY/2025-10-01/papers/251001489v1-a-robust-neural-control-design-for-multi-drone-slung-payload-manipul.html"}]