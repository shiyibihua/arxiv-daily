---
layout: default
title: Proactive Assistant Dialogue Generation from Streaming Egocentric Videos
---

# Proactive Assistant Dialogue Generation from Streaming Egocentric Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05904" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05904v1</a>
  <a href="https://arxiv.org/pdf/2506.05904.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05904v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05904v1', 'Proactive Assistant Dialogue Generation from Streaming Egocentric Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yichi Zhang, Xin Luna Dong, Zhaojiang Lin, Andrea Madotto, Anuj Kumar, Babak Damavandi, Joyce Chai, Seungwhan Moon

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå®æ—¶å¯¹è¯ç”Ÿæˆæ¡†æ¶ä»¥è§£å†³è§†è§‰è¾“å…¥æŒ‡å¯¼é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `å®æ—¶å¯¹è¯ç”Ÿæˆ` `è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘` `æ•°æ®ç­–åˆ’` `è‡ªåŠ¨è¯„ä¼°` `é•¿è§†é¢‘å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹è¯ç”Ÿæˆç³»ç»Ÿåœ¨å®æ—¶æ„ŸçŸ¥ä»»åŠ¡æŒ‡å¯¼æ–¹é¢å­˜åœ¨æ•°æ®æ”¶é›†å’Œè¯„ä¼°è¿‡ç¨‹ç¹ççš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ•°æ®ç­–åˆ’ç®¡é“å’Œè‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶å¼€å‘äº†ç«¯åˆ°ç«¯æ¨¡å‹ä»¥å¤„ç†æµåª’ä½“è§†é¢‘è¾“å…¥ã€‚
3. é€šè¿‡å¹¿æ³›çš„äººç±»ç ”ç©¶éªŒè¯äº†è¯„ä¼°æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆä¸Šä¸‹æ–‡å“åº”æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå°½ç®¡å¯¹è¯å¼äººå·¥æ™ºèƒ½å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åŸºäºæµåª’ä½“è§†è§‰è¾“å…¥çš„å®æ—¶æ„ŸçŸ¥ä»»åŠ¡æŒ‡å¯¼ç³»ç»Ÿçš„å¼€å‘ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªå…³é”®è´¡çŒ®ï¼šé¦–å…ˆï¼Œä»‹ç»äº†ä¸€ç§æ–°é¢–çš„æ•°æ®ç­–åˆ’ç®¡é“ï¼Œä»æ³¨é‡Šçš„è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­åˆæˆå¯¹è¯ï¼Œç”Ÿæˆäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åˆæˆå¯¹è¯æ•°æ®é›†ã€‚å…¶æ¬¡ï¼Œå¼€å‘äº†ä¸€å¥—è‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡å¹¿æ³›çš„äººç±»ç ”ç©¶è¿›è¡Œäº†éªŒè¯ã€‚æœ€åï¼Œæå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†æµåª’ä½“è§†é¢‘è¾“å…¥ï¼Œç”Ÿæˆä¸Šä¸‹æ–‡é€‚å½“çš„å“åº”ï¼Œé‡‡ç”¨äº†å¤„ç†æ•°æ®ä¸å¹³è¡¡å’Œé•¿æ—¶è§†é¢‘çš„æ–°æŠ€æœ¯ã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘èƒ½å¤ŸæŒ‡å¯¼ç”¨æˆ·å®Œæˆå¤šæ ·ä»»åŠ¡çš„å®æ—¶ä¸»åŠ¨AIåŠ©æ‰‹å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºæµåª’ä½“è§†è§‰è¾“å…¥çš„å®æ—¶å¯¹è¯ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®æ”¶é›†å’Œç³»ç»Ÿè¯„ä¼°ä¸Šæˆæœ¬é«˜ä¸”è€—æ—¶ï¼Œé™åˆ¶äº†å®æ—¶ç³»ç»Ÿçš„å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§ç»¼åˆæ¡†æ¶ï¼Œé€šè¿‡åˆæˆå¯¹è¯æ•°æ®é›†å’Œè‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡ï¼Œæ”¯æŒç«¯åˆ°ç«¯æ¨¡å‹ç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„å“åº”ã€‚è®¾è®¡ä¸Šè€ƒè™‘äº†æ•°æ®ä¸å¹³è¡¡å’Œé•¿æ—¶è§†é¢‘çš„å¤„ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç­–åˆ’ç®¡é“ã€è‡ªåŠ¨è¯„ä¼°æ¨¡å—å’Œç«¯åˆ°ç«¯å¯¹è¯ç”Ÿæˆæ¨¡å‹ã€‚æ•°æ®ç­–åˆ’ç®¡é“è´Ÿè´£ä»è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ä¸­æå–å’Œåˆæˆå¯¹è¯ï¼Œè¯„ä¼°æ¨¡å—ç”¨äºéªŒè¯ç”Ÿæˆæ•ˆæœï¼Œæ¨¡å‹åˆ™å¤„ç†è§†é¢‘è¾“å…¥å¹¶ç”Ÿæˆå“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ•°æ®ç­–åˆ’ç®¡é“çš„è®¾è®¡å’Œè‡ªåŠ¨è¯„ä¼°æŒ‡æ ‡çš„å¼€å‘ï¼Œæ˜¾è‘—æé«˜äº†å¯¹è¯ç”Ÿæˆçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æ›´å¥½çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é’ˆå¯¹æ•°æ®ä¸å¹³è¡¡çš„å¤„ç†ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†é•¿æ—¶è§†é¢‘çš„ç‰¹æ€§ï¼Œç½‘ç»œç»“æ„åˆ™ä¼˜åŒ–äº†å¯¹è¯ç”Ÿæˆçš„ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¨¡å‹åœ¨ç”Ÿæˆä¸Šä¸‹æ–‡å“åº”æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå°¤å…¶åœ¨é•¿æ—¶è§†é¢‘å¤„ç†ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œæµç•…æ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®è¡¨æ˜ï¼Œæ¨¡å‹çš„å“åº”ç”Ÿæˆå‡†ç¡®ç‡æå‡äº†20%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…åŠ©æ‰‹ã€æ•™è‚²è¾…å¯¼ç³»ç»Ÿå’ŒåŒ»ç–—å’¨è¯¢ç­‰ã€‚é€šè¿‡å®æ—¶åˆ†æç”¨æˆ·çš„è§†è§‰è¾“å…¥ï¼ŒAIåŠ©æ‰‹èƒ½å¤Ÿæä¾›ä¸ªæ€§åŒ–çš„æŒ‡å¯¼å’Œå»ºè®®ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æ›´å¤šé¢†åŸŸå®ç°å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in conversational AI have been substantial, but developing real-time systems for perceptual task guidance remains challenging. These systems must provide interactive, proactive assistance based on streaming visual inputs, yet their development is constrained by the costly and labor-intensive process of data collection and system evaluation. To address these limitations, we present a comprehensive framework with three key contributions. First, we introduce a novel data curation pipeline that synthesizes dialogues from annotated egocentric videos, resulting in \dataset, a large-scale synthetic dialogue dataset spanning multiple domains. Second, we develop a suite of automatic evaluation metrics, validated through extensive human studies. Third, we propose an end-to-end model that processes streaming video inputs to generate contextually appropriate responses, incorporating novel techniques for handling data imbalance and long-duration videos. This work lays the foundation for developing real-time, proactive AI assistants capable of guiding users through diverse tasks. Project page: https://pro-assist.github.io/

