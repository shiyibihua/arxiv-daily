---
layout: default
title: APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning
---

# APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25196" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25196v1</a>
  <a href="https://arxiv.org/pdf/2509.25196.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25196v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25196v1', 'APRIL: API Synthesis with Automatic Prompt Optimization and Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hua Zhong, Shan Jiang, Sarfraz Khurshid

**åˆ†ç±»**: cs.SE, cs.AI, cs.LG, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAPRILä»¥è§£å†³APIåˆæˆä¸­çš„æœç´¢ç©ºé—´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `APIåˆæˆ` `è‡ªåŠ¨æç¤ºä¼˜åŒ–` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è½¯ä»¶å¼€å‘` `åŠŸèƒ½æ­£ç¡®æ€§` `ä»£ç ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨APIåˆæˆä¸­é¢ä¸´æŒ‡æ•°çº§æœç´¢ç©ºé—´çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´ç”Ÿæˆçš„ä»£ç å¸¸å¸¸ä¸æ­£ç¡®ã€‚
2. APRILé€šè¿‡ç»“åˆè‡ªåŠ¨æç¤ºä¼˜åŒ–å’Œå¼ºåŒ–å­¦ä¹ ï¼Œä¼˜åŒ–æç¤ºå¹¶å¾®è°ƒç­–ç•¥ï¼Œä»è€Œæé«˜APIåˆæˆçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚
3. åœ¨å¯¹çœŸå®ä¸–ç•ŒAPIçš„è¯„ä¼°ä¸­ï¼ŒAPRILæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠŸèƒ½æ­£ç¡®æ€§å’Œåˆæˆæ•ˆç‡ä¸Šçš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

APIåœ¨ç°ä»£è½¯ä»¶å¼€å‘ä¸­è‡³å…³é‡è¦ï¼Œä½†ä»å¤§å‹åº“ä¸­ç»„åˆæ–°APIé¢ä¸´æŒ‡æ•°çº§æœç´¢ç©ºé—´çš„æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„ç»„ä»¶åˆæˆæ–¹æ³•ä¾èµ–äºæ˜‚è´µçš„æ¢ç´¢å’Œæ‰‹å·¥ç¼–å†™çš„è§„èŒƒã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿä»è‡ªç„¶è¯­è¨€ç”Ÿæˆå®ç°ï¼Œä½†ç”±äºå¹»è§‰å’Œå¯¹æœ€æ–°ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æœ‰é™è®¿é—®ï¼Œå¾€å¾€ä¼šäº§ç”Ÿé”™è¯¯çš„ä»£ç ã€‚æœ¬æ–‡æå‡ºAPRILï¼Œä¸€ç§ç»“åˆäº†åŸºäºLLMçš„åˆæˆã€è‡ªåŠ¨æç¤ºä¼˜åŒ–ï¼ˆAPOï¼‰å’ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰çš„æ–¹æ³•ã€‚APOå¯¹å†»ç»“æ¨¡å‹çš„æç¤ºè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œè€ŒRLVRåˆ™å¾®è°ƒç­–ç•¥ä»¥å®ç°åŠŸèƒ½æ­£ç¡®æ€§ï¼Œå½¢æˆé«˜æ•ˆçš„åˆæˆç®¡é“ã€‚é€šè¿‡å¯¹81ä¸ªæ¥è‡ªå¹¿æ³›ä½¿ç”¨çš„ç§‘å­¦Pythonåº“çš„çœŸå®APIè¿›è¡Œè¯„ä¼°ï¼Œå¹¶ä¸ä¸“å®¶æç¤ºæŒ‡å¯¼ä¸‹çš„æœªå¾®è°ƒæŒ‡ä»¤è°ƒä¼˜LLMsè¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼ŒAPRILå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé›†æˆAPOå’ŒRLVRä¸ºå¤§å‹åº“ä¸­çš„ç»„ä»¶APIåˆæˆæä¾›äº†ä¸€æ¡ç¨³å¥ã€å¯æ‰©å±•çš„è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»å¤§å‹APIåº“ä¸­åˆæˆæ–°APIæ—¶é¢ä¸´çš„æŒ‡æ•°çº§æœç´¢ç©ºé—´é—®é¢˜ã€‚ç°æœ‰çš„ç»„ä»¶åˆæˆæ–¹æ³•å¾€å¾€ä¾èµ–äºæ˜‚è´µçš„æ¢ç´¢è¿‡ç¨‹å’Œæ‰‹å·¥ç¼–å†™çš„è§„èŒƒï¼Œå¯¼è‡´ç”Ÿæˆçš„ä»£ç å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAPRILçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸è‡ªåŠ¨æç¤ºä¼˜åŒ–ï¼ˆAPOï¼‰å’ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ã€‚APOé€šè¿‡è¿­ä»£ä¼˜åŒ–æç¤ºæ¥æé«˜æ¨¡å‹çš„è¾“å‡ºè´¨é‡ï¼Œè€ŒRLVRåˆ™é€šè¿‡å¾®è°ƒç­–ç•¥æ¥ç¡®ä¿ç”Ÿæˆä»£ç çš„åŠŸèƒ½æ­£ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAPRILçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šAPOå’ŒRLVRã€‚APOè´Ÿè´£å¯¹è¾“å…¥æç¤ºè¿›è¡Œä¼˜åŒ–ï¼ŒRLVRåˆ™åœ¨ç”Ÿæˆçš„ä»£ç ä¸Šè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥ç¡®ä¿å…¶åŠŸèƒ½çš„æ­£ç¡®æ€§ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä¸€ä¸ªè¿­ä»£çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œæ—¨åœ¨æé«˜åˆæˆçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šAPRILçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†APOä¸RLVRç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„åˆæˆç®¡é“ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™çš„åˆæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåè€…å¾€å¾€ä¾èµ–äºæ‰‹å·¥è§„èŒƒå’Œå›ºå®šçš„æœç´¢ç­–ç•¥ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨APRILä¸­ï¼ŒAPOçš„å‚æ•°è®¾ç½®å’Œæç¤ºä¼˜åŒ–ç­–ç•¥æ˜¯å…³é”®è®¾è®¡ä¹‹ä¸€ã€‚æ­¤å¤–ï¼ŒRLVRçš„æŸå¤±å‡½æ•°è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„ä»£ç ä¸ä»…ç¬¦åˆè¯­æ³•ï¼Œè¿˜èƒ½å®ç°é¢„æœŸçš„åŠŸèƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¯¹81ä¸ªçœŸå®ä¸–ç•ŒAPIçš„è¯„ä¼°ä¸­ï¼ŒAPRILæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æœªå¾®è°ƒæŒ‡ä»¤è°ƒä¼˜LLMsï¼Œå±•ç¤ºäº†åœ¨åŠŸèƒ½æ­£ç¡®æ€§å’Œåˆæˆæ•ˆç‡ä¸Šçš„æ˜¾è‘—æå‡ã€‚è¿™è¡¨æ˜é›†æˆAPOå’ŒRLVRçš„ç­–ç•¥åœ¨APIåˆæˆä¸­å…·æœ‰å¼ºå¤§çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

APRILçš„ç ”ç©¶æˆæœåœ¨è½¯ä»¶å¼€å‘ã€APIè®¾è®¡å’Œè‡ªåŠ¨åŒ–ç¼–ç¨‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜APIåˆæˆçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼ŒAPRILå¯ä»¥å¸®åŠ©å¼€å‘è€…æ›´å¿«é€Ÿåœ°æ„å»ºå’Œç»´æŠ¤å¤æ‚çš„è½¯ä»¶ç³»ç»Ÿï¼Œé™ä½å¼€å‘æˆæœ¬ï¼Œå¹¶æå‡è½¯ä»¶çš„å¯é æ€§ã€‚æœªæ¥ï¼ŒAPRILå¯èƒ½ä¼šåœ¨æ›´å¤§è§„æ¨¡çš„APIåº“ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ç¼–ç¨‹å·¥å…·çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> APIs are central to modern software development, yet composing new APIs from large libraries is difficult due to the exponential search space; traditional component-based synthesis relies on costly exploration and hand-crafted specifications. While large language models (LLMs) can generate implementations from natural language, hallucinations and limited access to up-to-date contextual information often yield incorrect code. In this paper, we present APRIL, an approach that combines LLM-based synthesis with Automatic Prompt Optimization (APO) and Reinforcement Learning from Verifiable Rewards (RLVR): APO iteratively refines prompts for a frozen model, while RLVR fine-tunes the policy toward functional correctness, producing an efficient synthesis pipeline. Evaluated on 81 real-world APIs from widely used scientific Python libraries and benchmarked against instruction-tuned but unfine-tuned LLMs guided by expert prompts, APRIL achieves substantial improvements. These results indicate that integrating APO and RLVR provides a robust, scalable path for component-based API synthesis in large libraries.

