---
layout: default
title: Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding
---

# Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22661" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22661v1</a>
  <a href="https://arxiv.org/pdf/2509.22661.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22661v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22661v1', 'Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingyu Zhang, Guobin Wu, Yan Wang, Pengfei Xu, Jian Liang, Xuan Song, Yunhai Wang

**åˆ†ç±»**: cs.IR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥æ¨¡å‹ä»¥æå‡POIæ¨èå‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `POIæ¨è` `å¤šæ¨¡æ€èåˆ` `æ—¶ç©ºç‰¹å¾` `è‡ªæ³¨æ„åŠ›æœºåˆ¶` `åŠ¨æ€åŠ æƒ` `æ™ºèƒ½äº¤é€š` `ç”¨æˆ·åå¥½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰POIæ¨èæ¨¡å‹ä¸»è¦ä¾èµ–çŸ­æœŸäº¤é€šä¿¡æ¯ï¼Œå¿½è§†äº†é•¿æœŸåå¥½å’Œæ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œå¯¼è‡´é¢„æµ‹å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥çš„POIæ¨èæ¨¡å‹ï¼Œç»“åˆé•¿æœŸåå¥½å’Œæ—¶ç©ºç‰¹å¾è¿›è¡ŒåŠ¨æ€åŠ æƒèåˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ¨¡å‹åœ¨å¤šä¸ªäº¤é€šæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸‹ä¸€æ­¥å…´è¶£ç‚¹ï¼ˆPOIï¼‰æ¨èä¸»è¦åŸºäºé¡ºåºäº¤é€šä¿¡æ¯æ¥é¢„æµ‹ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªä¸Šè½¦ç‚¹ä½ç½®ã€‚è¿™æ˜¯æ™ºèƒ½äº¤é€šé¢†åŸŸå¤‡å—å…³æ³¨å’Œå¹¿æ³›åº”ç”¨çš„ç ”ç©¶ä»»åŠ¡ã€‚ä¼ ç»Ÿçš„POIé¢„æµ‹æ¨¡å‹ä¸»è¦ä¾èµ–çŸ­æœŸäº¤é€šåºåˆ—ä¿¡æ¯ï¼Œå¾€å¾€å¿½è§†äº†é•¿æœŸå’ŒçŸ­æœŸåå¥½æ•°æ®ä»¥åŠç”¨æˆ·è¡Œä¸ºä¸­çš„å…³é”®æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥ç”¨æˆ·çš„é•¿æœŸåå¥½ä¿¡æ¯å’Œå…³é”®æ—¶ç©ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥çš„POIæ¨èæ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡æ—¶ç©ºç‰¹å¾å¤„ç†ã€å¤šæ¨¡æ€åµŒå…¥å’Œè‡ªæ³¨æ„åŠ›èšåˆç­‰æ¨¡å—ï¼Œä»äº¤é€šæ•°æ®ä¸­æå–é•¿æœŸåå¥½ç‰¹å¾å’Œå…³é”®æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œå¹¶åˆ©ç”¨åŠ æƒèåˆæ–¹æ³•åŠ¨æ€è°ƒæ•´é•¿æœŸå’ŒçŸ­æœŸç‰¹å¾çš„æƒé‡ã€‚æœ€åï¼Œä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶åŒ¹é…èåˆç‰¹å¾ï¼Œå¹¶è®¡ç®—æ¯ä¸ªä½ç½®å€™é€‰æˆä¸ºä¸‹ä¸€ä¸ªä½ç½®çš„æ¦‚ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šä¸ªäº¤é€šæ•°æ®é›†ä¸Šå…·æœ‰æ¯”ç°æœ‰SOTAæ¨¡å‹æ›´é«˜çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»ŸPOIæ¨èæ¨¡å‹åœ¨çŸ­æœŸäº¤é€šåºåˆ—ä¿¡æ¯ä¾èµ–ä¸‹ï¼Œå¿½è§†é•¿æœŸåå¥½å’Œæ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾çš„é—®é¢˜ï¼Œå¯¼è‡´é¢„æµ‹å‡†ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å¼•å…¥ç”¨æˆ·çš„é•¿æœŸåå¥½ä¿¡æ¯å’Œå…³é”®æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œæ„å»ºä¸€ä¸ªå¤šæ¨¡æ€æ—¶ç©ºä¸Šä¸‹æ–‡ç‰¹å¾åµŒå…¥æ¨¡å‹ï¼Œä»¥å®ç°å¯¹ç”¨æˆ·è¡Œä¸ºçš„æ›´å…¨é¢ç†è§£å’Œå‡†ç¡®é¢„æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ—¶ç©ºç‰¹å¾å¤„ç†æ¨¡å—ã€å¤šæ¨¡æ€åµŒå…¥æ¨¡å—å’Œè‡ªæ³¨æ„åŠ›èšåˆæ¨¡å—ï¼Œé¦–å…ˆæå–é•¿æœŸåå¥½å’Œæ—¶ç©ºç‰¹å¾ï¼Œç„¶åé€šè¿‡åŠ æƒèåˆåŠ¨æ€è°ƒæ•´ç‰¹å¾æƒé‡ï¼Œæœ€ååˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œç‰¹å¾åŒ¹é…å’Œæ¦‚ç‡è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºåŠ¨æ€åŠ æƒèåˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·å†å²è¡Œä¸ºæ¨¡å¼å’Œå½“å‰ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´é•¿æœŸå’ŒçŸ­æœŸç‰¹å¾çš„æƒé‡ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä¸­é‡‡ç”¨äº†è‡ªæ³¨æ„åŠ›æœºåˆ¶æ¥èšåˆç‰¹å¾ï¼Œå¹¶é€šè¿‡åŠ æƒèåˆç­–ç•¥æ¥ä¼˜åŒ–ç‰¹å¾ç»„åˆï¼Œå…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ç¡®ä¿äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æPOIæ¨èæ¨¡å‹åœ¨å¤šä¸ªäº¤é€šæ•°æ®é›†ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œé¢„æµ‹å‡†ç¡®æ€§æé«˜äº†çº¦15%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†å¤šæ¨¡æ€ç‰¹å¾èåˆçš„æœ‰æ•ˆæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šç³»ç»Ÿã€ç§»åŠ¨å¯¼èˆªåº”ç”¨å’Œä¸ªæ€§åŒ–æ¨èæœåŠ¡ã€‚é€šè¿‡æé«˜POIæ¨èçš„å‡†ç¡®æ€§ï¼Œå¯ä»¥ä¼˜åŒ–ç”¨æˆ·çš„å‡ºè¡Œä½“éªŒï¼Œæå‡äº¤é€šæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹è¿˜å¯æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚æ—…æ¸¸æ¨èå’ŒåŸå¸‚è§„åˆ’ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The next Point-of-interest (POI) recommendation is mainly based on sequential traffic information to predict the user's next boarding point location. This is a highly regarded and widely applied research task in the field of intelligent transportation, and there have been many research results to date. Traditional POI prediction models primarily rely on short-term traffic sequence information, often neglecting both long-term and short-term preference data, as well as crucial spatiotemporal context features in user behavior. To address this issue, this paper introduces user long-term preference information and key spatiotemporal context information, and proposes a POI recommendation model based on multimodal spatiotemporal context feature embedding. The model extracts long-term preference features and key spatiotemporal context features from traffic data through modules such as spatiotemporal feature processing, multimodal embedding, and self-attention aggregation. It then uses a weighted fusion method to dynamically adjust the weights of long-term and short-term features based on users' historical behavior patterns and the current context. Finally, the fused features are matched using attention, and the probability of each location candidate becoming the next location is calculated. This paper conducts experimental verification on multiple transportation datasets, and the results show that the POI prediction model combining multiple types of features has higher prediction accuracy than existing SOTA models and methods.

