---
layout: default
title: The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management
---

# The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21433" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21433v3</a>
  <a href="https://arxiv.org/pdf/2508.21433.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21433v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21433v3', 'The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tobias Lindenbauer, Igor Slinko, Ludwig Felder, Egor Bogomolov, Yaroslav Zharov

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-10-27)

**å¤‡æ³¨**: v3: DL4C camera-ready version to be presented at the 4th DL4C workshop co-located with NeurIPS '25; added OpenHands generality probe, added hybrid context management strategy

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç®€å•è§‚å¯Ÿæ©è”½ç­–ç•¥ä»¥ä¼˜åŒ–LLMä»£ç†çš„ä¸Šä¸‹æ–‡ç®¡ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡ç®¡ç†` `è½¯ä»¶å·¥ç¨‹` `è§‚å¯Ÿæ©è”½` `æˆæœ¬ä¼˜åŒ–` `ä»£ç†ç³»ç»Ÿ` `æ··åˆæ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMæ‘˜è¦æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶å¯èƒ½å¯¼è‡´ä¸å¿…è¦çš„å¤æ‚æ€§å’Œé«˜æˆæœ¬ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç®€å•çš„è§‚å¯Ÿæ©è”½ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡çœç•¥æ—§çš„è§‚å¯Ÿæ¥é™ä½æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒè§£å†³ç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè§‚å¯Ÿæ©è”½ç­–ç•¥åœ¨æˆæœ¬å’Œæ€§èƒ½ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„LLMæ‘˜è¦æ–¹æ³•ï¼Œä¸”æ··åˆæ–¹æ³•è¿›ä¸€æ­¥æå‡äº†æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„ä»£ç†é€šè¿‡è¿­ä»£æ¨ç†ã€æ¢ç´¢å’Œå·¥å…·ä½¿ç”¨æ¥è§£å†³å¤æ‚ä»»åŠ¡ï¼Œè¿™ä¸€è¿‡ç¨‹å¯èƒ½å¯¼è‡´é•¿ä¸”æ˜‚è´µçš„ä¸Šä¸‹æ–‡å†å²ã€‚å°½ç®¡ç°æœ‰çš„å…ˆè¿›è½¯ä»¶å·¥ç¨‹ä»£ç†å¦‚OpenHandså’ŒCursoré‡‡ç”¨LLMæ‘˜è¦æ¥åº”å¯¹è¿™ä¸€é—®é¢˜ï¼Œä½†å…¶å¤æ‚æ€§æ˜¯å¦å¸¦æ¥äº†å®é™…çš„æ€§èƒ½æå‡å°šä¸æ˜ç¡®ã€‚æœ¬æ–‡ç³»ç»Ÿæ¯”è¾ƒäº†åœ¨SWE-agentä¸Šä½¿ç”¨ç®€å•ç¯å¢ƒè§‚å¯Ÿæ©è”½ç­–ç•¥ä¸LLMæ‘˜è¦çš„æ•ˆæœï¼Œå‘ç°å‰è€…åœ¨æˆæœ¬ä¸Šå‡å°‘äº†ä¸€åŠï¼ŒåŒæ—¶åœ¨è§£å†³ç‡ä¸Šä¸LLMæ‘˜è¦ç›¸å½“ï¼Œç”šè‡³ç•¥æœ‰è¶…è¶Šã€‚æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„æ··åˆæ–¹æ³•ï¼Œè¿›ä¸€æ­¥é™ä½äº†7%è‡³11%çš„æˆæœ¬ã€‚æˆ‘ä»¬çš„ç ”ç©¶å¯¹çº¯LLMæ‘˜è¦çš„è¶‹åŠ¿æå‡ºäº†è´¨ç–‘ï¼Œå¹¶æä¾›äº†æ¨åŠ¨æ•ˆç‡ä¸æ•ˆæœè¾¹ç•Œçš„åˆæ­¥è¯æ®ã€‚æˆ‘ä»¬è¿˜å‘å¸ƒäº†ä»£ç å’Œæ•°æ®ä»¥æ”¯æŒå¯é‡å¤æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMä»£ç†åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶äº§ç”Ÿçš„é«˜æˆæœ¬å’Œé•¿ä¸Šä¸‹æ–‡å†å²é—®é¢˜ã€‚ç°æœ‰çš„LLMæ‘˜è¦æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†å…¶å¤æ‚æ€§å’Œè®¡ç®—å¼€é”€ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§ç®€å•çš„ç¯å¢ƒè§‚å¯Ÿæ©è”½ç­–ç•¥ï¼Œé€šè¿‡çœç•¥æ—§çš„è§‚å¯Ÿä¿¡æ¯æ¥é™ä½è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶ä¿æŒæˆ–æå‡ä»»åŠ¡è§£å†³ç‡ã€‚è¿™ç§æ–¹æ³•çš„è®¾è®¡åŸºäºå¯¹ç°æœ‰æ–¹æ³•çš„æ€§èƒ½åˆ†æï¼Œæ—¨åœ¨ç®€åŒ–ä¸Šä¸‹æ–‡ç®¡ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¯å¢ƒè§‚å¯Ÿæ”¶é›†ã€è§‚å¯Ÿæ©è”½å¤„ç†å’Œä»»åŠ¡è§£å†³ã€‚é¦–å…ˆæ”¶é›†ç¯å¢ƒè§‚å¯Ÿï¼Œç„¶ååº”ç”¨æ©è”½ç­–ç•¥ï¼Œæœ€åé€šè¿‡ä»£ç†è¿›è¡Œä»»åŠ¡è§£å†³ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ç®€å•è§‚å¯Ÿæ©è”½ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æˆæœ¬å’Œæ€§èƒ½ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„LLMæ‘˜è¦æ–¹æ³•ï¼ŒæŒ‘æˆ˜äº†å¯¹å¤æ‚æ€§ä¾èµ–çš„å¸¸è§„æ€ç»´ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè§‚å¯Ÿæ©è”½ç­–ç•¥çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿åœ¨é™ä½æˆæœ¬çš„åŒæ—¶ä¸å½±å“è§£å†³ç‡ã€‚æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„çš„è®¾è®¡ä¹Ÿç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”æ–°çš„å¤„ç†æµç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç®€å•è§‚å¯Ÿæ©è”½ç­–ç•¥ç›¸è¾ƒäºåŸå§‹ä»£ç†æˆæœ¬é™ä½äº†50%ï¼Œå¹¶åœ¨è§£å†³ç‡ä¸Šä¸LLMæ‘˜è¦ç›¸å½“ï¼Œç”šè‡³ç•¥æœ‰è¶…è¶Šã€‚æ­¤å¤–ï¼Œæ··åˆæ–¹æ³•åœ¨æˆæœ¬ä¸Šè¿›ä¸€æ­¥é™ä½äº†7%è‡³11%ï¼Œå±•ç¤ºäº†å…¶åœ¨æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å·¥ç¨‹ã€æ™ºèƒ½ä»£ç†ç³»ç»Ÿå’Œå¤æ‚ä»»åŠ¡ç®¡ç†ã€‚é€šè¿‡ä¼˜åŒ–ä¸Šä¸‹æ–‡ç®¡ç†ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜ç³»ç»Ÿçš„æ•´ä½“æ•ˆç‡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLM)-based agents solve complex tasks through iterative reasoning, exploration, and tool-use, a process that can result in long, expensive context histories. While state-of-the-art Software Engineering (SE) agents like OpenHands or Cursor use LLM-based summarization to tackle this issue, it is unclear whether the increased complexity offers tangible performance benefits compared to simply omitting older observations. We present a systematic comparison of these approaches within SWE-agent on SWE-bench Verified across five diverse model configurations. Moreover, we show initial evidence of our findings generalizing to the OpenHands agent scaffold. We find that a simple environment observation masking strategy halves cost relative to the raw agent while matching, and sometimes slightly exceeding, the solve rate of LLM summarization. Additionally, we introduce a novel hybrid approach that further reduces costs by 7% and 11% compared to just observation masking or LLM summarization, respectively. Our findings raise concerns regarding the trend towards pure LLM summarization and provide initial evidence of untapped cost reductions by pushing the efficiency-effectiveness frontier. We release code and data for reproducibility.

