---
layout: default
title: Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions
---

# Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.08576" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.08576v2</a>
  <a href="https://arxiv.org/pdf/2510.08576.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.08576v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.08576v2', 'Comparative Analysis of Large Language Models for the Machine-Assisted Resolution of User Intentions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Justus Flerlage, Alexander Acker, Odej Kao

**åˆ†ç±»**: cs.SE, cs.AI, cs.CL, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-11-11)

**å¤‡æ³¨**: Accepted at First International Workshop on Human-AI Collaborative Systems (HAIC), published in CEUR-WS.org Vol-4072 (2025). URN: urn:nbn:de:0074-4072-x

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¯”è¾ƒåˆ†æå¤§å‹è¯­è¨€æ¨¡å‹ä»¥è§£å†³ç”¨æˆ·æ„å›¾é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç”¨æˆ·æ„å›¾è§£æ` `å¼€æºæ¨¡å‹` `è‡ªç„¶è¯­è¨€å¤„ç†` `éšç§ä¿æŠ¤` `æœ¬åœ°éƒ¨ç½²` `æ™ºèƒ½åŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äº‘ç«¯ä¸“æœ‰æ¨¡å‹åœ¨éšç§å’Œè‡ªæ²»æ–¹é¢å­˜åœ¨å±€é™ï¼Œæ— æ³•æ»¡è¶³ç”¨æˆ·å¯¹æœ¬åœ°éƒ¨ç½²çš„éœ€æ±‚ã€‚
2. æœ¬ç ”ç©¶æå‡ºè¯„ä¼°å¼€æºå’Œå¼€æ”¾è®¿é—®çš„LLMsï¼Œä»¥å®ç°ç”¨æˆ·æ„å›¾çš„æœ¬åœ°è§£æï¼Œå¼ºè°ƒå…¶åœ¨æœªæ¥æ“ä½œç³»ç»Ÿä¸­çš„é‡è¦æ€§ã€‚
3. é€šè¿‡ä¸GPT-4ç³»ç»Ÿçš„æ¯”è¾ƒï¼Œç ”ç©¶å‘ç°å¼€æºLLMsåœ¨ç”Ÿæˆç”¨æˆ·å·¥ä½œæµæ–¹é¢å…·æœ‰å¯è¡Œæ€§å’Œæ½œåŠ›ï¼Œæä¾›äº†å®è¯æ”¯æŒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²æˆä¸ºè‡ªç„¶è¯­è¨€ç†è§£å’Œç”¨æˆ·æ„å›¾è§£æçš„å˜é©æ€§å·¥å…·ï¼Œæ”¯æŒç¿»è¯‘ã€æ‘˜è¦ç­‰ä»»åŠ¡ï¼Œå¹¶é€æ¸å®ç°å¤æ‚å·¥ä½œæµçš„åè°ƒã€‚è¿™ä¸€å‘å±•æ ‡å¿—ç€ä»ä¼ ç»Ÿçš„å›¾å½¢ç”¨æˆ·ç•Œé¢å‘ç›´è§‚çš„è¯­è¨€ä¼˜å…ˆäº¤äº’èŒƒå¼çš„è½¬å˜ã€‚ç„¶è€Œï¼Œç°æœ‰å®ç°å¾€å¾€ä¾èµ–äºäº‘ç«¯ä¸“æœ‰æ¨¡å‹ï¼Œå¸¦æ¥äº†éšç§ã€è‡ªæ²»å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„é™åˆ¶ã€‚ä¸ºå®ç°è¯­è¨€ä¼˜å…ˆäº¤äº’çš„ç¨³å¥æ€§ï¼Œæœ¬ç ”ç©¶è¯„ä¼°äº†å¤šä¸ªå¼€æºå’Œå¼€æ”¾è®¿é—®æ¨¡å‹åœ¨ç”¨æˆ·æ„å›¾è§£æä¸­çš„èƒ½åŠ›ï¼Œå¹¶ä¸OpenAIçš„GPT-4ç³»ç»Ÿè¿›è¡Œäº†æ¯”è¾ƒåˆ†æï¼Œæä¾›äº†å…³äºå¼€æºLLMsä½œä¸ºæœªæ¥æ„å›¾é©±åŠ¨æ“ä½œç³»ç»ŸåŸºç¡€ç»„ä»¶çš„å®è¯è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰äº‘ç«¯ä¸“æœ‰æ¨¡å‹åœ¨éšç§å’Œè‡ªæ²»æ–¹é¢çš„ä¸è¶³ï¼Œæ¢ç´¢æœ¬åœ°éƒ¨ç½²çš„å¼€æºLLMsåœ¨ç”¨æˆ·æ„å›¾è§£æä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è¯„ä¼°å¼€æºå’Œå¼€æ”¾è®¿é—®çš„LLMsï¼Œä»¥å®ç°ç”¨æˆ·æ„å›¾çš„æœ¬åœ°è§£æï¼Œå¼ºè°ƒå…¶åœ¨æœªæ¥æ“ä½œç³»ç»Ÿä¸­çš„é‡è¦æ€§ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç”¨æˆ·å¯ä»¥åœ¨ä¸ä¾èµ–äº‘æœåŠ¡çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨LLMsè¿›è¡Œè‡ªç„¶è¯­è¨€äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šç”¨æˆ·è¾“å…¥è§£æã€æ„å›¾è¯†åˆ«ã€å·¥ä½œæµç”Ÿæˆå’Œæ‰§è¡Œã€‚ç”¨æˆ·é€šè¿‡è‡ªç„¶è¯­è¨€è¾“å…¥å…¶æ„å›¾ï¼Œç³»ç»Ÿè§£æåç”Ÿæˆç›¸åº”çš„å·¥ä½œæµï¼Œå¹¶åè°ƒå¤šä¸ªåº”ç”¨ç¨‹åºçš„æ“ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¯¹å¼€æºLLMsçš„è¯„ä¼°ä¸æ¯”è¾ƒï¼Œæä¾›äº†ä¸ä¸“æœ‰æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰åœ¨æ€§èƒ½ä¸Šçš„å®è¯å¯¹æ¯”ï¼Œå¼ºè°ƒäº†å¼€æºæ¨¡å‹åœ¨éšç§å’Œè‡ªæ²»æ–¹é¢çš„ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ç”¨æˆ·æ„å›¾è§£æä¸­çš„è¡¨ç°ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒæ–¹æ³•æœªè¯¦ç»†æŠ«éœ²ï¼Œéœ€è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¼€æºLLMsåœ¨ç”Ÿæˆç”¨æˆ·å·¥ä½œæµæ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸OpenAIçš„GPT-4ç³»ç»Ÿç›¸æ¯”ï¼Œå¼€æºæ¨¡å‹åœ¨éšç§å’Œè‡ªæ²»æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œä½†ç ”ç©¶æä¾›äº†å®è¯æ”¯æŒï¼Œè¡¨æ˜å¼€æºæ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å·¥ä½œæµç®¡ç†å’Œä¸ªæ€§åŒ–ç”¨æˆ·ä½“éªŒç­‰ã€‚é€šè¿‡æœ¬åœ°éƒ¨ç½²çš„å¼€æºLLMsï¼Œç”¨æˆ·å¯ä»¥åœ¨æ›´å®‰å…¨å’Œè‡ªä¸»çš„ç¯å¢ƒä¸­è¿›è¡Œè‡ªç„¶è¯­è¨€äº¤äº’ï¼Œæå‡å·¥ä½œæ•ˆç‡å’Œéšç§ä¿æŠ¤ã€‚æœªæ¥ï¼Œè¿™ç§æŠ€æœ¯å¯èƒ½ä¼šæ¨åŠ¨æ™ºèƒ½è®¾å¤‡çš„æ™®åŠå’Œæ™ºèƒ½å®¶å±…çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have emerged as transformative tools for natural language understanding and user intent resolution, enabling tasks such as translation, summarization, and, increasingly, the orchestration of complex workflows. This development signifies a paradigm shift from conventional, GUI-driven user interfaces toward intuitive, language-first interaction paradigms. Rather than manually navigating applications, users can articulate their objectives in natural language, enabling LLMs to orchestrate actions across multiple applications in a dynamic and contextual manner. However, extant implementations frequently rely on cloud-based proprietary models, which introduce limitations in terms of privacy, autonomy, and scalability. For language-first interaction to become a truly robust and trusted interface paradigm, local deployment is not merely a convenience; it is an imperative. This limitation underscores the importance of evaluating the feasibility of locally deployable, open-source, and open-access LLMs as foundational components for future intent-based operating systems. In this study, we examine the capabilities of several open-source and open-access models in facilitating user intention resolution through machine assistance. A comparative analysis is conducted against OpenAI's proprietary GPT-4-based systems to assess performance in generating workflows for various user intentions. The present study offers empirical insights into the practical viability, performance trade-offs, and potential of open LLMs as autonomous, locally operable components in next-generation operating systems. The results of this study inform the broader discussion on the decentralization and democratization of AI infrastructure and point toward a future where user-device interaction becomes more seamless, adaptive, and privacy-conscious through locally embedded intelligence.

