---
layout: default
title: Tree-Guided Diffusion Planner
---

# Tree-Guided Diffusion Planner

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21800" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21800v2</a>
  <a href="https://arxiv.org/pdf/2508.21800.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21800v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21800v2', 'Tree-Guided Diffusion Planner')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hyeonseong Jeon, Cheolhong Min, Jaesik Park

**åˆ†ç±»**: cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-29 (æ›´æ–°: 2025-11-09)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ ‘å¯¼å‘æ‰©æ•£è§„åˆ’å™¨ä»¥è§£å†³éå‡¸ä¼˜åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `è§„åˆ’ç®—æ³•` `æ ‘æœç´¢` `æœºå™¨äººæ§åˆ¶` `é›¶-shotå­¦ä¹ ` `å¤šç›®æ ‡ä¼˜åŒ–` `è½¨è¿¹ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§„åˆ’æ–¹æ³•åœ¨å¤„ç†éå‡¸ç›®æ ‡å’Œå¤æ‚çº¦æŸæ—¶æ•ˆæœä¸ä½³ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„çµæ´»æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„æ ‘å¯¼å‘æ‰©æ•£è§„åˆ’å™¨ï¼ˆTDPï¼‰é€šè¿‡åŒå±‚é‡‡æ ·è¿‡ç¨‹å®ç°äº†æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡ï¼Œæ”¯æŒé›¶-shotæµ‹è¯•æ—¶è§„åˆ’ã€‚
3. TDPåœ¨è¿·å®«é‡‘å—é‡‡é›†ã€æœºå™¨äººæ‰‹è‡‚å—æ“ä½œå’ŒAntMazeå¤šç›®æ ‡æ¢ç´¢ç­‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä½¿ç”¨é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œè§„åˆ’å·²æˆä¸ºè§£å†³æµ‹è¯•æ—¶å¼•å¯¼æ§åˆ¶é—®é¢˜çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œæ ‡å‡†çš„æ¢¯åº¦å¼•å¯¼åœ¨éå‡¸ç›®æ ‡ã€éå¯å¾®çº¦æŸå’Œå¤šå¥–åŠ±ç»“æ„çš„å®é™…åœºæ™¯ä¸­æ•ˆæœæ˜¾è‘—é™ä½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é›¶-shotæµ‹è¯•æ—¶è§„åˆ’æ¡†æ¶â€”â€”æ ‘å¯¼å‘æ‰©æ•£è§„åˆ’å™¨ï¼ˆTDPï¼‰ï¼Œé€šè¿‡ç»“æ„åŒ–è½¨è¿¹ç”Ÿæˆå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨ã€‚TDPå°†æµ‹è¯•æ—¶è§„åˆ’è§†ä¸ºæ ‘æœç´¢é—®é¢˜ï¼Œé‡‡ç”¨åŒå±‚é‡‡æ ·è¿‡ç¨‹ç”Ÿæˆå¤šæ ·çš„çˆ¶è½¨è¿¹ï¼Œå¹¶é€šè¿‡å¿«é€Ÿæ¡ä»¶å»å™ªç²¾ç‚¼å­è½¨è¿¹ã€‚TDPåœ¨ä¸‰ä¸ªå¤šæ ·åŒ–ä»»åŠ¡ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œå‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨éå‡¸ã€éå¯å¾®çš„å¥–åŠ±ç»“æ„ä¸‹è¿›è¡Œæœ‰æ•ˆè§„åˆ’çš„é—®é¢˜ã€‚ç°æœ‰çš„æ¢¯åº¦å¼•å¯¼æ–¹æ³•åœ¨è¿™äº›å¤æ‚åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œä¸”éœ€è¦ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œé›¶-shotæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„TDPé€šè¿‡å°†æµ‹è¯•æ—¶è§„åˆ’è§†ä¸ºæ ‘æœç´¢é—®é¢˜ï¼Œé‡‡ç”¨åŒå±‚é‡‡æ ·ç­–ç•¥ï¼Œé¦–å…ˆç”Ÿæˆå¤šæ ·çš„çˆ¶è½¨è¿¹ä»¥ä¿ƒè¿›å¹¿æ³›æ¢ç´¢ï¼Œç„¶åæ ¹æ®ä»»åŠ¡ç›®æ ‡å¿«é€Ÿç²¾ç‚¼å­è½¨è¿¹ï¼Œä»è€Œå®ç°æœ‰æ•ˆçš„è§„åˆ’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTDPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯é€šè¿‡æ— è®­ç»ƒçš„ç²’å­å¼•å¯¼ç”Ÿæˆå¤šæ ·çš„çˆ¶è½¨è¿¹ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯é€šè¿‡æ¡ä»¶å»å™ªå¿«é€Ÿä¼˜åŒ–å­è½¨è¿¹ã€‚è¯¥æ¡†æ¶åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹å’Œæµ‹è¯•æ—¶å¥–åŠ±ä¿¡å·ï¼Œé¿å…äº†å¯¹ç‰¹å®šä»»åŠ¡çš„ä¾èµ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šTDPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åŒå±‚é‡‡æ ·è¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨æ‰©å±•çš„è§£ç©ºé—´ä¸­æ¢ç´¢å¤šæ ·çš„è½¨è¿¹åŒºåŸŸï¼Œå¹¶åˆ©ç”¨æ¢¯åº¦ä¿¡æ¯è¿›è¡Œä¼˜åŒ–ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—å…‹æœäº†ä¼ ç»Ÿæ¢¯åº¦å¼•å¯¼çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒTDPé‡‡ç”¨äº†æ— è®­ç»ƒçš„ç²’å­å¼•å¯¼æœºåˆ¶ï¼Œç¡®ä¿äº†æ¢ç´¢çš„å¤šæ ·æ€§ï¼ŒåŒæ—¶åœ¨æ¡ä»¶å»å™ªé˜¶æ®µä½¿ç”¨äº†ä¸ä»»åŠ¡ç›®æ ‡ç›¸ç»“åˆçš„å¿«é€Ÿä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æé«˜æ•ˆç‡å’Œæ•ˆæœã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒTDPåœ¨è¿·å®«é‡‘å—é‡‡é›†ã€æœºå™¨äººæ‰‹è‡‚å—æ“ä½œå’ŒAntMazeå¤šç›®æ ‡æ¢ç´¢ç­‰ä»»åŠ¡ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œ consistently outperforming state-of-the-art approachesï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¯¦ç»†åˆ—å‡ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–è§„åˆ’ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿç­‰ã€‚é€šè¿‡æä¾›ä¸€ç§çµæ´»çš„é›¶-shotè§„åˆ’æ¡†æ¶ï¼ŒTDPèƒ½å¤Ÿåœ¨å¤šç§å¤æ‚ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„å†³ç­–åˆ¶å®šï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Planning with pretrained diffusion models has emerged as a promising approach for solving test-time guided control problems. Standard gradient guidance typically performs optimally under convex, differentiable reward landscapes. However, it shows substantially reduced effectiveness in real-world scenarios with non-convex objectives, non-differentiable constraints, and multi-reward structures. Furthermore, recent supervised planning approaches require task-specific training or value estimators, which limits test-time flexibility and zero-shot generalization. We propose a Tree-guided Diffusion Planner (TDP), a zero-shot test-time planning framework that balances exploration and exploitation through structured trajectory generation. We frame test-time planning as a tree search problem using a bi-level sampling process: (1) diverse parent trajectories are produced via training-free particle guidance to encourage broad exploration, and (2) sub-trajectories are refined through fast conditional denoising guided by task objectives. TDP addresses the limitations of gradient guidance by exploring diverse trajectory regions and harnessing gradient information across this expanded solution space using only pretrained models and test-time reward signals. We evaluate TDP on three diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze multi-goal exploration. TDP consistently outperforms state-of-the-art approaches on all tasks. The project page can be found at: https://tree-diffusion-planner.github.io.

