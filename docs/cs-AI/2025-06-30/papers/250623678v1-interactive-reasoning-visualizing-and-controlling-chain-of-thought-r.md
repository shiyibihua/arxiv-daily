---
layout: default
title: Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models
---

# Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23678" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23678v1</a>
  <a href="https://arxiv.org/pdf/2506.23678.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23678v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23678v1', 'Interactive Reasoning: Visualizing and Controlling Chain-of-Thought Reasoning in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rock Yuren Pang, K. J. Kevin Feng, Shangbin Feng, Chu Li, Weijia Shi, Yulia Tsvetkov, Jeffrey Heer, Katharina Reinecke

**åˆ†ç±»**: cs.HC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäº¤äº’æ¨ç†ä»¥ä¼˜åŒ–å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€ç»´é“¾è¾“å‡º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ€ç»´é“¾æ¨ç†` `ç”¨æˆ·äº¤äº’` `å¯è§†åŒ–æŠ€æœ¯` `AIè¾…åŠ©å†³ç­–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ç¼ºä¹ç”¨æˆ·åé¦ˆï¼Œå¯¼è‡´è¾“å‡ºå†—é•¿ä¸”éš¾ä»¥ç»„ç»‡ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚
2. æœ¬æ–‡æå‡ºäº¤äº’æ¨ç†ï¼Œé€šè¿‡å¯è§†åŒ–æ€ç»´é“¾è¾“å‡ºï¼Œå…è®¸ç”¨æˆ·å¯¹å†…å®¹è¿›è¡Œå®¡æŸ¥å’Œä¿®æ”¹ï¼Œæå‡æ¨¡å‹çš„å“åº”è´¨é‡ã€‚
3. ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œäº¤äº’æ¨ç†æ˜¾è‘—æé«˜äº†ç”¨æˆ·è¯†åˆ«é”™è¯¯ç”Ÿæˆçš„æ•ˆç‡ï¼Œå¹¶å¢å¼ºäº†å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„ç†è§£ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¾“å‡ºè´¨é‡å¯ä»¥é€šè¿‡â€œæ¨ç†â€æ¥æå‡ï¼Œå³ç”Ÿæˆæ€ç»´é“¾ï¼ˆCoTï¼‰å†…å®¹ç‰‡æ®µä»¥è¿›ä¸€æ­¥æ¡ä»¶åŒ–æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ€ç»´é“¾ä¿¡æ¯å†—é•¿ä¸”ç¼ºä¹æ˜ç¡®çš„ç»„ç»‡ï¼Œå®¡æŸ¥è¿‡ç¨‹ç¹çã€‚æ­¤å¤–ï¼Œç”¨æˆ·åé¦ˆçš„æœºä¼šæœ‰é™ã€‚æœ¬æ–‡æå‡ºäº¤äº’æ¨ç†ï¼Œé€šè¿‡å°†æ€ç»´é“¾è¾“å‡ºå¯è§†åŒ–ä¸ºä¸»é¢˜å±‚æ¬¡ç»“æ„ï¼Œå…è®¸ç”¨æˆ·å®¡æŸ¥å’Œä¿®æ”¹ã€‚æˆ‘ä»¬åœ¨Hippoä¸­å®ç°äº†äº¤äº’æ¨ç†ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºä¸ç¡®å®šæƒè¡¡çš„AIè¾…åŠ©å†³ç­–åŸå‹ã€‚åœ¨å¯¹16åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å‘ç°Hippoä¸­çš„äº¤äº’æ¨ç†ä½¿ç”¨æˆ·èƒ½å¤Ÿå¿«é€Ÿè¯†åˆ«å’Œä¸­æ–­é”™è¯¯ç”Ÿæˆï¼Œæœ‰æ•ˆå¼•å¯¼æ¨¡å‹æœå‘å®šåˆ¶åŒ–å“åº”ï¼Œå¹¶æ›´å¥½åœ°ç†è§£æ¨¡å‹æ¨ç†å’Œè¾“å‡ºã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºå°†ç”¨æˆ·ç›‘ç£çº³å…¥LLMæ¨ç†è¿‡ç¨‹å¼€è¾Ÿäº†æ–°èŒƒå¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ€ç»´é“¾æ—¶ç¼ºä¹ç”¨æˆ·åé¦ˆå’Œç»„ç»‡æ€§çš„é—®é¢˜ï¼Œå¯¼è‡´è¾“å‡ºå†…å®¹å†—é•¿ä¸”éš¾ä»¥å®¡æŸ¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šäº¤äº’æ¨ç†çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ€ç»´é“¾è¾“å‡ºå¯è§†åŒ–ä¸ºå±‚æ¬¡ç»“æ„ï¼Œå…è®¸ç”¨æˆ·å¯¹å†…å®¹è¿›è¡Œå®¡æŸ¥å’Œä¿®æ”¹ï¼Œä»è€Œæé«˜è¾“å‡ºçš„ç›¸å…³æ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ€ç»´é“¾ç”Ÿæˆæ¨¡å—ã€å¯è§†åŒ–å±‚æ¬¡ç»“æ„æ¨¡å—å’Œç”¨æˆ·äº¤äº’æ¨¡å—ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡äº¤äº’ç•Œé¢å¯¹æ€ç»´é“¾è¿›è¡Œä¿®æ”¹ï¼Œå½±å“æœ€ç»ˆè¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†ç”¨æˆ·åé¦ˆæœºåˆ¶æ•´åˆåˆ°æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä¸»åŠ¨å‚ä¸åˆ°æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæ˜¾è‘—æ”¹å–„äº†è¾“å‡ºè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å±‚æ¬¡åŒ–çš„ä¸»é¢˜ç»“æ„æ¥ç»„ç»‡æ€ç»´é“¾ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç®€å•çš„ç•Œé¢è¿›è¡Œä¿®æ”¹ï¼Œä¸”ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶æ›´æ–°ç”Ÿæˆçš„å†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œäº¤äº’æ¨ç†æ˜¾è‘—æé«˜äº†ç”¨æˆ·è¯†åˆ«é”™è¯¯ç”Ÿæˆçš„é€Ÿåº¦ï¼Œç”¨æˆ·èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¼•å¯¼æ¨¡å‹ç”Ÿæˆå®šåˆ¶åŒ–å“åº”ã€‚ç”¨æˆ·å¯¹æ¨¡å‹æ¨ç†è¿‡ç¨‹çš„ç†è§£ä¹Ÿå¾—åˆ°äº†å¢å¼ºï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨æå‡ç”¨æˆ·ä½“éªŒæ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€æ•™è‚²å·¥å…·å’Œå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡å¼•å…¥ç”¨æˆ·äº¤äº’ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„å¯ç”¨æ€§å’Œç”¨æˆ·æ»¡æ„åº¦ï¼Œæœªæ¥å¯èƒ½åœ¨å¤šç§äººæœºäº¤äº’åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The output quality of large language models (LLMs) can be improved via "reasoning": generating segments of chain-of-thought (CoT) content to further condition the model prior to producing user-facing output. While these chains contain valuable information, they are verbose and lack explicit organization, making them tedious to review. Moreover, they lack opportunities for user feedback, such as to remove unwanted considerations, add desired ones, or clarify unclear assumptions. We introduce Interactive Reasoning, an interaction design that visualizes chain-of-thought outputs as a hierarchy of topics and enables user review and modification. We implement interactive reasoning in Hippo, a prototype for AI-assisted decision making in the face of uncertain trade-offs. In a user study with 16 participants, we find that interactive reasoning in Hippo allows users to quickly identify and interrupt erroneous generations, efficiently steer the model towards customized responses, and better understand both model reasoning and model outputs. Our work contributes to a new paradigm that incorporates user oversight into LLM reasoning processes.

