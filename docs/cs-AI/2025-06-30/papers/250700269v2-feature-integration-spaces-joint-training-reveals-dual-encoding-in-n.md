---
layout: default
title: Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations
---

# Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00269" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00269v2</a>
  <a href="https://arxiv.org/pdf/2507.00269.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00269v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00269v2', 'Feature Integration Spaces: Joint Training Reveals Dual Encoding in Neural Network Representations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Omar Claflin

**åˆ†ç±»**: q-bio.NC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-12-09)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒé‡ç¼–ç æœºåˆ¶ä»¥æå‡ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `ç¥ç»ç½‘ç»œ` `ç¨€ç–è‡ªç¼–ç å™¨` `å¯è§£é‡Šæ€§` `åŒé‡ç¼–ç ` `ç‰¹å¾æ•´åˆ` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¨€ç–è‡ªç¼–ç å™¨æ–¹æ³•åœ¨æ¶ˆé™¤å¤šä¹‰æ€§å’Œè¡Œä¸ºé”™è¯¯æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå½±å“äº†ç¥ç»ç½‘ç»œçš„å¯è§£é‡Šæ€§ã€‚
2. æœ¬æ–‡æå‡ºåŒé‡ç¼–ç æœºåˆ¶ï¼Œåˆ©ç”¨è”åˆè®­ç»ƒæ¶æ„åŒæ—¶æ•æ‰ç‰¹å¾èº«ä»½å’Œæ•´åˆæ¨¡å¼ï¼Œä»¥æå‡æ¨¡å‹çš„é‡å»ºèƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè”åˆè®­ç»ƒå®ç°41.3%çš„é‡å»ºæ”¹è¿›å’Œ51.6%çš„KLæ•£åº¦å‡å°‘ï¼Œä¸”å°å‹éçº¿æ€§ç»„ä»¶æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„ç¨€ç–è‡ªç¼–ç å™¨(SAE)æ–¹æ³•åœ¨ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§æ–¹é¢å‡è®¾æ¿€æ´»å¯ä»¥é€šè¿‡çº¿æ€§å åŠ åˆ†è§£ä¸ºç¨€ç–ã€å¯è§£é‡Šçš„ç‰¹å¾ã€‚å°½ç®¡é‡å»ºç²¾åº¦é«˜ï¼ŒSAEä»ç„¶æ— æ³•æ¶ˆé™¤å¤šä¹‰æ€§ï¼Œå¹¶è¡¨ç°å‡ºç—…æ€çš„è¡Œä¸ºé”™è¯¯ã€‚æœ¬æ–‡æå‡ºç¥ç»ç½‘ç»œåœ¨åŒä¸€åŸºè´¨ä¸­ä»¥ä¸¤ç§äº’è¡¥ç©ºé—´ç¼–ç ä¿¡æ¯ï¼šç‰¹å¾èº«ä»½å’Œç‰¹å¾æ•´åˆã€‚ä¸ºéªŒè¯è¿™ä¸€åŒé‡ç¼–ç å‡è®¾ï¼Œå¼€å‘äº†é¡ºåºå’Œè”åˆè®­ç»ƒæ¶æ„ä»¥åŒæ—¶æ•æ‰èº«ä»½å’Œæ•´åˆæ¨¡å¼ã€‚è”åˆè®­ç»ƒå®ç°äº†41.3%çš„é‡å»ºæ”¹è¿›å’Œ51.6%çš„KLæ•£åº¦é”™è¯¯å‡å°‘ã€‚è¯¥æ¶æ„è‡ªå‘å‘å±•å‡ºåŒæ¨¡æ€ç‰¹å¾ç»„ç»‡ï¼Œä½å¹³æ–¹èŒƒæ•°ç‰¹å¾è´¡çŒ®äºæ•´åˆè·¯å¾„ï¼Œå…¶ä½™ç‰¹å¾ç›´æ¥è´¡çŒ®äºæ®‹å·®ã€‚å°å‹éçº¿æ€§ç»„ä»¶ï¼ˆå å‚æ•°çš„3%ï¼‰å®ç°äº†16.5%çš„ç‹¬ç«‹æ”¹è¿›ï¼Œå±•ç¤ºäº†å‚æ•°é«˜æ•ˆæ•æ‰å¯¹è¡Œä¸ºè‡³å…³é‡è¦çš„è®¡ç®—å…³ç³»çš„èƒ½åŠ›ã€‚å¹²é¢„å®éªŒè¡¨æ˜ï¼Œæ•´åˆç‰¹å¾å¯¹å®éªŒæ“æ§è¡¨ç°å‡ºé€‰æ‹©æ€§æ•æ„Ÿæ€§ï¼Œå¹¶å¯¹æ¨¡å‹è¾“å‡ºäº§ç”Ÿç³»ç»Ÿæ€§è¡Œä¸ºæ•ˆåº”ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç¨€ç–è‡ªç¼–ç å™¨åœ¨ç¥ç»ç½‘ç»œå¯è§£é‡Šæ€§æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯å¤šä¹‰æ€§å’Œè¡Œä¸ºé”™è¯¯çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŒé‡ç¼–ç æœºåˆ¶ï¼Œè®¤ä¸ºç¥ç»ç½‘ç»œåœ¨åŒä¸€åŸºè´¨ä¸­åŒæ—¶ç¼–ç ç‰¹å¾èº«ä»½å’Œç‰¹å¾æ•´åˆï¼Œé€šè¿‡è”åˆè®­ç»ƒæ¥æ•æ‰è¿™ä¸¤ç§æ¨¡å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é¡ºåºè®­ç»ƒå’Œè”åˆè®­ç»ƒä¸¤ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«ç”¨äºæ•æ‰ç‰¹å¾èº«ä»½å’Œæ•´åˆæ¨¡å¼ã€‚è”åˆè®­ç»ƒé˜¶æ®µé€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥å®ç°ç‰¹å¾çš„æœ‰æ•ˆæ•´åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†åŒé‡ç¼–ç çš„æ¦‚å¿µï¼Œå¹¶é€šè¿‡è”åˆè®­ç»ƒæ¶æ„å®ç°äº†ç‰¹å¾çš„åŒæ¨¡æ€ç»„ç»‡ï¼Œè¿™ä¸ä¼ ç»Ÿçš„çº¿æ€§å åŠ å‡è®¾å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥å°å‹éçº¿æ€§ç»„ä»¶ï¼Œå‚æ•°å æ¯”ä»…ä¸º3%ï¼Œé€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°å’Œç‰¹å¾æ•´åˆç­–ç•¥ï¼Œå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè”åˆè®­ç»ƒå®ç°äº†41.3%çš„é‡å»ºç²¾åº¦æå‡å’Œ51.6%çš„KLæ•£åº¦å‡å°‘ã€‚æ­¤å¤–ï¼Œ3%çš„å°å‹éçº¿æ€§ç»„ä»¶ç‹¬ç«‹å®ç°äº†16.5%çš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å‚æ•°æ•ˆç‡ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§æå‡ã€è®¡ç®—æœºè§†è§‰ä»»åŠ¡ä¸­çš„ç‰¹å¾æå–å’Œæ•´åˆã€ä»¥åŠæœºå™¨äººå†³ç­–ç³»ç»Ÿä¸­çš„è¡Œä¸ºä¼˜åŒ–ã€‚é€šè¿‡æä¾›æ›´æ¸…æ™°çš„ç‰¹å¾ç†è§£ï¼Œæœªæ¥å¯ä»¥æ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current sparse autoencoder (SAE) approaches to neural network interpretability assume that activations can be decomposed through linear superposition into sparse, interpretable features. Despite high reconstruction fidelity, SAEs consistently fail to eliminate polysemanticity and exhibit pathological behavioral errors. We propose that neural networks encode information in two complementary spaces compressed into the same substrate: feature identity and feature integration. To test this dual encoding hypothesis, we develop sequential and joint-training architectures to capture identity and integration patterns simultaneously. Joint training achieves 41.3% reconstruction improvement and 51.6% reduction in KL divergence errors. This architecture spontaneously develops bimodal feature organization: low squared norm features contributing to integration pathways and the rest contributing directly to the residual. Small nonlinear components (3% of parameters) achieve 16.5% standalone improvements, demonstrating parameter-efficient capture of computational relationships crucial for behavior. Additionally, intervention experiments using 2x2 factorial stimulus designs demonstrated that integration features exhibit selective sensitivity to experimental manipulations and produce systematic behavioral effects on model outputs, including significant statistical interaction effects across semantic dimensions. This work provides systematic evidence for (1) dual encoding in neural representations, (2) meaningful nonlinearly encoded feature interactions, and (3) introduces an architectural paradigm shift from post-hoc feature analysis to integrated computational design, establishing foundations for next-generation SAEs.

