---
layout: default
title: Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System
---

# Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16575" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16575v1</a>
  <a href="https://arxiv.org/pdf/2506.16575.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16575v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16575v1', 'Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mustafa Akben, Aaron Satko

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**å¤‡æ³¨**: Submitted for HICSS 2025 (Hawaii International Conference on System Sciences); under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºEloè¯„åˆ†ç³»ç»Ÿçš„æ–¹æ³•ä»¥æå‡æœ‰å®³å†…å®¹æ£€æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœ‰å®³å†…å®¹æ£€æµ‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `Eloè¯„åˆ†ç³»ç»Ÿ` `å¾®ä¾µå®³` `ä»‡æ¨è¨€è®º` `ç»„ç»‡ç ”ç©¶` `æœºå™¨å­¦ä¹ ` `æ–‡æœ¬åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMåœ¨åˆ†ææœ‰å®³å†…å®¹æ—¶å­˜åœ¨æ‹’ç»æŒ‡ä»¤å’Œè¿‡äºè°¨æ…çš„å“åº”ï¼Œå½±å“ç»“æœæœ‰æ•ˆæ€§ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºEloè¯„åˆ†ç³»ç»Ÿçš„æ–¹æ³•ï¼Œæ—¨åœ¨æå‡LLMåœ¨æœ‰å®³å†…å®¹åˆ†æä¸­çš„æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¾®ä¾µå®³å’Œä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­æ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§å’ŒF1åˆ†æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºç»„ç»‡ç ”ç©¶æä¾›äº†æœ‰å‰æ™¯çš„æœºä¼šã€‚ç„¶è€Œï¼Œå…¶å†…ç½®çš„å†…å®¹å®¡æ ¸ç³»ç»Ÿåœ¨åˆ†ææœ‰å®³å†…å®¹æ—¶å¯èƒ½ä¼šäº§ç”Ÿé—®é¢˜ï¼Œå¸¸å¸¸æ‹’ç»éµå¾ªæŸäº›æŒ‡ä»¤æˆ–äº§ç”Ÿè¿‡äºè°¨æ…çš„å“åº”ï¼Œä»è€Œå‰Šå¼±ç»“æœçš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºEloè¯„åˆ†çš„æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†LLMåœ¨æœ‰å®³å†…å®¹åˆ†æä¸­çš„è¡¨ç°ã€‚åœ¨é’ˆå¯¹å¾®ä¾µå®³å’Œä»‡æ¨è¨€è®ºçš„ä¸¤ä¸ªæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬å‘ç°è¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§ã€ç²¾ç¡®åº¦å’ŒF1åˆ†æ•°ç­‰å…³é”®æŒ‡æ ‡ä¸Šä¼˜äºä¼ ç»Ÿçš„LLMæç¤ºæŠ€æœ¯å’Œå¸¸è§„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ–¹æ³•çš„ä¼˜åŠ¿åŒ…æ‹¬åœ¨åˆ†ææœ‰å®³å†…å®¹æ—¶æ›´é«˜çš„å¯é æ€§ã€æ›´å°‘çš„è¯¯æŠ¥ä»¥åŠå¯¹å¤§è§„æ¨¡æ•°æ®é›†çš„æ›´å¥½æ‰©å±•æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ†ææœ‰å®³å†…å®¹æ—¶çš„å±€é™æ€§ï¼Œå°¤å…¶æ˜¯å…¶å†…ç½®å®¡æ ¸ç³»ç»Ÿå¯¼è‡´çš„æ‹’ç»æŒ‡ä»¤å’Œè¿‡äºè°¨æ…çš„å“åº”ï¼Œè¿™äº›é—®é¢˜å½±å“äº†åˆ†æç»“æœçš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºEloè¯„åˆ†ç³»ç»Ÿçš„æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥è¯„åˆ†æœºåˆ¶æ¥ä¼˜åŒ–LLMçš„å“åº”ï¼Œä½¿å…¶åœ¨å¤„ç†æœ‰å®³å†…å®¹æ—¶æ›´åŠ å‡†ç¡®å’Œå¯é ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æé«˜æ¨¡å‹çš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„ç»„ç»‡å†²çªæƒ…å¢ƒä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€Eloè¯„åˆ†è®¡ç®—ã€LLMè®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µè´Ÿè´£æ¸…æ´—å’Œæ ‡æ³¨æ•°æ®ï¼ŒEloè¯„åˆ†è®¡ç®—æ¨¡å—åˆ™æ ¹æ®æ¨¡å‹çš„è¡¨ç°åŠ¨æ€è°ƒæ•´è¯„åˆ†ï¼ŒLLMè®­ç»ƒæ¨¡å—åˆ©ç”¨ä¼˜åŒ–åçš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œæœ€ååœ¨è¯„ä¼°é˜¶æ®µå¯¹æ¨¡å‹æ€§èƒ½è¿›è¡ŒéªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†Eloè¯„åˆ†ç³»ç»Ÿä¸LLMç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„æœ‰å®³å†…å®¹åˆ†ææ–¹æ³•ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„æç¤ºæŠ€æœ¯å’Œæœºå™¨å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‡å°‘è¯¯æŠ¥å¹¶æé«˜åˆ†æçš„å¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒEloè¯„åˆ†çš„åˆå§‹å€¼å’Œæ›´æ–°è§„åˆ™ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä¹Ÿè€ƒè™‘äº†æœ‰å®³å†…å®¹çš„ç‰¹æ€§ï¼Œä»¥æå‡æ¨¡å‹åœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºEloè¯„åˆ†çš„æ–¹æ³•åœ¨å¾®ä¾µå®³å’Œä»‡æ¨è¨€è®ºæ£€æµ‹ä¸­ï¼Œå‡†ç¡®ç‡å’ŒF1åˆ†æ•°å‡æ˜¾è‘—é«˜äºä¼ ç»ŸLLMæç¤ºæŠ€æœ¯å’Œå¸¸è§„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤„ç†æœ‰å®³å†…å®¹æ—¶å…·æœ‰æ›´é«˜çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬èŒåœºéªšæ‰°æ£€æµ‹ã€æ¯’æ€§æ²Ÿé€šè¯„ä¼°ä»¥åŠä¿ƒè¿›æ›´å®‰å…¨å’ŒåŒ…å®¹çš„å·¥ä½œç¯å¢ƒã€‚é€šè¿‡æå‡æœ‰å®³å†…å®¹æ£€æµ‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©ç»„ç»‡æ›´æœ‰æ•ˆåœ°åº”å¯¹å†…éƒ¨å†²çªå’Œæ”¹å–„å‘˜å·¥å…³ç³»ï¼Œä»è€Œæå‡æ•´ä½“å·¥ä½œæ°›å›´ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) offer promising opportunities for organizational research. However, their built-in moderation systems can create problems when researchers try to analyze harmful content, often refusing to follow certain instructions or producing overly cautious responses that undermine validity of the results. This is particularly problematic when analyzing organizational conflicts such as microaggressions or hate speech. This paper introduces an Elo rating-based method that significantly improves LLM performance for harmful content analysis In two datasets, one focused on microaggression detection and the other on hate speech, we find that our method outperforms traditional LLM prompting techniques and conventional machine learning models on key measures such as accuracy, precision, and F1 scores. Advantages include better reliability when analyzing harmful content, fewer false positives, and greater scalability for large-scale datasets. This approach supports organizational applications, including detecting workplace harassment, assessing toxic communication, and fostering safer and more inclusive work environments.

