---
layout: default
title: PPMI: Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases
---

# PPMI: Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17336" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17336v3</a>
  <a href="https://arxiv.org/pdf/2506.17336.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17336v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17336v3', 'PPMI: Privacy-Preserving LLM Interaction with Socratic Chain-of-Thought Reasoning and Homomorphically Encrypted Vector Databases')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yubeen Bae, Minchan Kim, Jaejin Lee, Sangbum Kim, Jaehyung Kim, Yejin Choi, Niloofar Mireshghallah

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-11-01)

**å¤‡æ³¨**: 29 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPPMIä»¥è§£å†³ç”¨æˆ·éšç§ä¿æŠ¤ä¸LLMäº¤äº’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒæ€åŠ å¯†` `Socraticæ¨ç†` `æ•°æ®å®‰å…¨` `è¯­ä¹‰æœç´¢` `æœ¬åœ°æ¨¡å‹` `ç”¨æˆ·æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç”¨æˆ·æ•æ„Ÿæ•°æ®æ—¶é¢ä¸´éšç§é£é™©ï¼Œç”¨æˆ·ä¸å¾—ä¸åœ¨å¼ºå¤§æ¨¡å‹ä¸æœ¬åœ°å¼±æ¨¡å‹ä¹‹é—´åšå‡ºé€‰æ‹©ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„Socratic Chain-of-Thought Reasoningæ–¹æ³•ï¼Œç»“åˆåŒæ€åŠ å¯†æŠ€æœ¯ï¼Œå®ç°äº†éšç§ä¿æŠ¤çš„LLMäº¤äº’ã€‚
3. åœ¨LoCoMoé•¿ä¸Šä¸‹æ–‡é—®ç­”åŸºå‡†ä¸Šï¼Œæ··åˆæ¡†æ¶çš„è¡¨ç°ä¼˜äºå•ä¸€ä½¿ç”¨GPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°7.1ä¸ªç™¾åˆ†ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°ä½œä¸ºä¸ªäººä»£ç†ä½¿ç”¨ï¼Œè®¿é—®æ•æ„Ÿç”¨æˆ·æ•°æ®ï¼Œå¦‚æ—¥å†ã€ç”µå­é‚®ä»¶å’ŒåŒ»ç–—è®°å½•ã€‚ç”¨æˆ·é¢ä¸´ç€ä¸€ä¸ªæƒè¡¡ï¼šè¦ä¹ˆå°†ç§äººè®°å½•å‘é€ç»™å¼ºå¤§ä½†ä¸å¯ä¿¡çš„LLMæä¾›å•†ï¼Œä»è€Œå¢åŠ æš´éœ²é£é™©ï¼›è¦ä¹ˆåœ¨å¯ä¿¡è®¾å¤‡ä¸Šè¿è¡Œè¾ƒå¼±çš„æœ¬åœ°æ¨¡å‹ã€‚æœ¬æ–‡æå‡ºçš„Socratic Chain-of-Thought Reasoningæ–¹æ³•ï¼Œé¦–å…ˆå‘å¼ºå¤§çš„ä¸å¯ä¿¡LLMå‘é€é€šç”¨çš„éç§å¯†ç”¨æˆ·æŸ¥è¯¢ï¼Œç”ŸæˆChain-of-Thoughtï¼ˆCoTï¼‰æç¤ºå’Œè¯¦ç»†çš„å­æŸ¥è¯¢ï¼Œè€Œä¸è®¿é—®ç”¨æˆ·æ•°æ®ã€‚æ¥ç€ï¼Œåˆ©ç”¨åŒæ€åŠ å¯†å‘é‡æ•°æ®åº“å¯¹ç”¨æˆ·çš„ç§äººæ•°æ®è¿›è¡ŒåŠ å¯†çš„è¯­ä¹‰æœç´¢ã€‚æœ€åï¼Œå°†CoTæç¤ºå’Œè§£å¯†åçš„è®°å½•è¾“å…¥æœ¬åœ°è¯­è¨€æ¨¡å‹ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ··åˆæ¡†æ¶åœ¨LoCoMoé•¿ä¸Šä¸‹æ–‡é—®ç­”åŸºå‡†ä¸Šï¼Œæ€§èƒ½æ¯”å•ç‹¬ä½¿ç”¨GPT-4oæå‡äº†7.1ä¸ªç™¾åˆ†ç‚¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ—¶é¢ä¸´çš„éšç§ä¿æŠ¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€éœ€è¦å°†æ•æ„Ÿæ•°æ®å‘é€ç»™ä¸å¯ä¿¡çš„LLMæä¾›å•†ï¼Œå¢åŠ äº†ç”¨æˆ·æ•°æ®æ³„éœ²çš„é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡Socratic Chain-of-Thought Reasoningï¼Œé¦–å…ˆç”Ÿæˆéç§å¯†çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œç„¶åé€šè¿‡åŒæ€åŠ å¯†æŠ€æœ¯å¯¹ç”¨æˆ·çš„ç§äººæ•°æ®è¿›è¡Œå®‰å…¨å¤„ç†ï¼Œä»è€Œåœ¨ä¸æš´éœ²ç”¨æˆ·éšç§çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å¼ºå¤§çš„LLMè¿›è¡Œæ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œå‘ä¸å¯ä¿¡çš„LLMå‘é€é€šç”¨æŸ¥è¯¢ä»¥ç”ŸæˆCoTæç¤ºï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨åŒæ€åŠ å¯†å‘é‡æ•°æ®åº“å¯¹ç”¨æˆ·çš„ç§äººæ•°æ®è¿›è¡ŒåŠ å¯†çš„è¯­ä¹‰æœç´¢ï¼›æœ€åï¼Œå°†CoTæç¤ºå’Œè§£å¯†åçš„è®°å½•è¾“å…¥æœ¬åœ°æ¨¡å‹ç”Ÿæˆæœ€ç»ˆå“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¼ºå¤§çš„LLMä¸æœ¬åœ°å¼±æ¨¡å‹ç»“åˆï¼Œé€šè¿‡åˆ†è§£ä»»åŠ¡å®ç°éšç§ä¿æŠ¤ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç›´æ¥å‘é€ç”¨æˆ·æ•°æ®ç»™LLMçš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨åŒæ€åŠ å¯†æŠ€æœ¯ç¡®ä¿æ•°æ®åœ¨å¤„ç†è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§ï¼Œè®¾ç½®äº†é«˜æ•ˆçš„æœç´¢ç®—æ³•ä»¥æ”¯æŒå¯¹ç™¾ä¸‡æ¡ç§äººè®°å½•çš„å¿«é€Ÿæ£€ç´¢ï¼ŒåŒæ—¶ä¼˜åŒ–äº†CoTæç¤ºç”Ÿæˆçš„ç­–ç•¥ä»¥æé«˜å“åº”çš„å‡†ç¡®æ€§å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ··åˆæ¡†æ¶åœ¨LoCoMoé•¿ä¸Šä¸‹æ–‡é—®ç­”åŸºå‡†ä¸Šçš„è¡¨ç°ä¼˜äºå•ç‹¬ä½¿ç”¨GPT-4oï¼Œæå‡å¹…åº¦è¾¾åˆ°7.1ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œç»“åˆå¼ºå¤§LLMä¸æœ¬åœ°æ¨¡å‹çš„ç­–ç•¥åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¸ªäººåŠ©ç†ã€åŒ»ç–—è®°å½•ç®¡ç†å’Œæ•æ„Ÿä¿¡æ¯å¤„ç†ç­‰åœºæ™¯ã€‚é€šè¿‡ä¿æŠ¤ç”¨æˆ·éšç§ï¼ŒPPMIå¯ä»¥åœ¨ä¸ç‰ºç‰²æ¨¡å‹æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œä¿ƒè¿›ç”¨æˆ·å¯¹AIæŠ€æœ¯çš„ä¿¡ä»»å’Œæ¥å—ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„éšç§ä¿æŠ¤æŠ€æœ¯åœ¨å„è¡Œä¸šçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used as personal agents, accessing sensitive user data such as calendars, emails, and medical records. Users currently face a trade-off: They can send private records, many of which are stored in remote databases, to powerful but untrusted LLM providers, increasing their exposure risk. Alternatively, they can run less powerful models locally on trusted devices. We bridge this gap. Our Socratic Chain-of-Thought Reasoning first sends a generic, non-private user query to a powerful, untrusted LLM, which generates a Chain-of-Thought (CoT) prompt and detailed sub-queries without accessing user data. Next, we embed these sub-queries and perform encrypted sub-second semantic search using our Homomorphically Encrypted Vector Database across one million entries of a single user's private data. This represents a realistic scale of personal documents, emails, and records accumulated over years of digital activity. Finally, we feed the CoT prompt and the decrypted records to a local language model and generate the final response. On the LoCoMo long-context QA benchmark, our hybrid framework, combining GPT-4o with a local Llama-3.2-1B model, outperforms using GPT-4o alone by up to 7.1 percentage points. This demonstrates a first step toward systems where tasks are decomposed and split between untrusted strong LLMs and weak local ones, preserving user privacy.

