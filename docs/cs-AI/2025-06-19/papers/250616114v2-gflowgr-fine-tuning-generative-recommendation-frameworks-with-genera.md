---
layout: default
title: GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks
---

# GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16114" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16114v2</a>
  <a href="https://arxiv.org/pdf/2506.16114.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16114v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16114v2', 'GFlowGR: Fine-tuning Generative Recommendation Frameworks with Generative Flow Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yejing Wang, Shengyu Zhou, Jinyu Lu, Qidong Liu, Xinhang Li, Wenlin Zhang, Feng Li, Pengjie Wang, Jian Xu, Bo Zheng, Xiangyu Zhao

**åˆ†ç±»**: cs.IR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-11-24)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGFlowGRæ¡†æ¶ä»¥è§£å†³ç”Ÿæˆæ¨èä¸­çš„æ›å…‰åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”Ÿæˆæ¨è` `æ›å…‰åå·®` `GFlowNets` `å¾®è°ƒæ¡†æ¶` `æ¨èç³»ç»Ÿ` `å¤šæ­¥éª¤ç”Ÿæˆ` `ç”¨æˆ·ä½“éªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç”Ÿæˆæ¨èæ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é¡¹ç›®æ ‡è®°å™¨å’Œè§£ç ç­–ç•¥çš„æ”¹è¿›ï¼Œå¾®è°ƒæ­¥éª¤çš„ç ”ç©¶ç›¸å¯¹åŒ®ä¹ï¼Œå¯¼è‡´æ¨èæ¨¡å‹æ— æ³•æœ‰æ•ˆé€‚åº”æ¨èæ•°æ®ã€‚
2. æœ¬æ–‡æå‡ºGFlowGRæ¡†æ¶ï¼Œå°†ç”Ÿæˆæ¨èè§†ä¸ºå¤šæ­¥éª¤ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡GFlowNetsè¿›è¡Œå¾®è°ƒï¼Œæ•´åˆä¼ ç»Ÿæ¨èç³»ç»Ÿçš„çŸ¥è¯†ä»¥ç¼“è§£æ›å…‰åå·®é—®é¢˜ã€‚
3. åœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGFlowGRåœ¨æ€§èƒ½å’Œé²æ£’æ€§ä¸Šå‡ä¼˜äºç°æœ‰çš„ç”Ÿæˆæ¨èæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”Ÿæˆæ¨èï¼ˆGRï¼‰é€šå¸¸åŒ…æ‹¬é¡¹ç›®æ ‡è®°å™¨å’Œç”Ÿæˆæ€§å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œåœ¨å¤šä¸ªåœºæ™¯ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å¼€å‘å¼ºå¤§çš„é¡¹ç›®æ ‡è®°å™¨æˆ–æ”¹è¿›LLMè§£ç ç­–ç•¥ä¸Šï¼Œè€Œå¯¹GRæ¡†æ¶ä¸­çš„å…³é”®å¾®è°ƒæ­¥éª¤å…³æ³¨ä¸è¶³ã€‚å½“å‰æ–¹æ³•ä¸»è¦ä¾èµ–äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹æŸå¤±æˆ–æ¨èç‰¹å®šçš„ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ç­–ç•¥ï¼Œè¿™ä¸¤è€…éƒ½å¿½ç•¥äº†å¯¹æœªè§‚å¯Ÿåˆ°çš„æ­£æ ·æœ¬çš„æ¢ç´¢ï¼Œå¯¼è‡´æ›å…‰åå·®é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡å°†GRè§†ä¸ºå¤šæ­¥éª¤ç”Ÿæˆä»»åŠ¡ï¼Œæ„å»ºäº†åŸºäºGFlowNetsçš„å¾®è°ƒæ¡†æ¶ï¼ˆGFlowGRï¼‰ï¼Œå¹¶é€šè¿‡æ•´åˆä¼ ç»Ÿæ¨èç³»ç»Ÿçš„åä½œçŸ¥è¯†ï¼Œåˆ›å»ºäº†è‡ªé€‚åº”è½¨è¿¹é‡‡æ ·å™¨å’Œå…¨é¢çš„å¥–åŠ±æ¨¡å‹ã€‚é€šè¿‡GFlowNetsçš„å¤šæ ·ç”Ÿæˆç‰¹æ€§åŠé‡‡æ ·å’Œå¯å‘å¼åŠ æƒæŠ€æœ¯ï¼ŒGFlowGRæœ‰æ•ˆç¼“è§£äº†æ›å…‰åå·®é—®é¢˜ã€‚å¤§é‡å®è¯ç»“æœè¡¨æ˜ï¼ŒGFlowGRåœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå±•ç°äº†å…¶æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”Ÿæˆæ¨èæ¡†æ¶ä¸­çš„æ›å…‰åå·®é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹æŸå¤±æˆ–ç›´æ¥åå¥½ä¼˜åŒ–ï¼Œæœªèƒ½æœ‰æ•ˆæ¢ç´¢æœªè§‚å¯Ÿåˆ°çš„æ­£æ ·æœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºå°†ç”Ÿæˆæ¨èè§†ä¸ºå¤šæ­¥éª¤ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡GFlowNetsæ„å»ºå¾®è°ƒæ¡†æ¶ï¼Œåˆ©ç”¨å…¶å¤šæ ·ç”Ÿæˆç‰¹æ€§æ¥ç¼“è§£æ›å…‰åå·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGFlowGRæ¡†æ¶åŒ…æ‹¬è‡ªé€‚åº”è½¨è¿¹é‡‡æ ·å™¨å’Œå…¨é¢çš„å¥–åŠ±æ¨¡å‹ï¼Œæ•´åˆäº†ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„åä½œçŸ¥è¯†ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„å¾®è°ƒæµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šGFlowGRçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ç”Ÿæˆæ¨èè§†ä¸ºå¤šæ­¥éª¤ç”Ÿæˆä»»åŠ¡ï¼Œå¹¶é€šè¿‡GFlowNetsçš„ç‰¹æ€§æœ‰æ•ˆç¼“è§£äº†æ›å…‰åå·®é—®é¢˜ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨çš„åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒGFlowGRé‡‡ç”¨äº†å¯å‘å¼åŠ æƒæŠ€æœ¯å’Œå¤šæ ·æ€§é‡‡æ ·ç­–ç•¥ï¼Œå…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒä¸­è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æå‡æ¨¡å‹çš„æ¨èæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGFlowGRåœ¨ä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œæå‡å¹…åº¦è¾¾åˆ°15%-20%ã€‚é€šè¿‡å¯¹æ¯”ä¸åŒçš„ç”Ÿæˆæ¨èéª¨å¹²ï¼ŒéªŒè¯äº†GFlowGRçš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ï¼Œå±•ç°äº†å…¶åœ¨è§£å†³æ›å…‰åå·®é—®é¢˜ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­å•†åŠ¡ã€ç¤¾äº¤åª’ä½“å’Œå†…å®¹æ¨èç­‰å¤šä¸ªåœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨èç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼ŒGFlowGRæ¡†æ¶æœ‰æœ›åœ¨ä¸ªæ€§åŒ–æ¨èå’Œç”¨æˆ·è¡Œä¸ºé¢„æµ‹ç­‰é¢†åŸŸå‘æŒ¥æ›´å¤§ä½œç”¨ï¼Œæ¨åŠ¨ç”Ÿæˆæ¨èæŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Generative recommendations (GR), which usually include item tokenizers and generative Large Language Models (LLMs), have demonstrated remarkable success across a wide range of scenarios. The majority of existing research efforts primarily concentrate on developing powerful item tokenizers or advancing LLM decoding strategies to attain superior performance. However, the critical fine-tuning step in GR frameworks, which is essential for adapting LLMs to recommendation data, remains largely unexplored. Current approaches predominantly rely on either the next-token prediction loss of supervised fine-tuning (SFT) or recommendationspecific direct preference optimization (DPO) strategies. Both methods ignore the exploration of possible positive unobserved samples, which is commonly referred to as the exposure bias problem. To mitigate this problem, this paper treats the GR as a multi-step generation task and constructs a GFlowNets-based fine-tuning framework (GFlowGR). The proposed framework integrates collaborative knowledge from traditional recommender systems to create an adaptive trajectory sampler and a comprehensive reward model. Leveraging the diverse generation property of GFlowNets, along with sampling and heuristic weighting techniques, GFlowGR emerges as a promising approach to mitigate the exposure bias problem. Extensive empirical results on two real-world datasets and with two different GR backbones highlight the effectiveness and robustness of GFlowGR.

