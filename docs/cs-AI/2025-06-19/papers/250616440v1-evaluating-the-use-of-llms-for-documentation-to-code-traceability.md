---
layout: default
title: Evaluating the Use of LLMs for Documentation to Code Traceability
---

# Evaluating the Use of LLMs for Documentation to Code Traceability

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16440" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16440v1</a>
  <a href="https://arxiv.org/pdf/2506.16440.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16440v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16440v1', 'Evaluating the Use of LLMs for Documentation to Code Traceability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ebube Alor, SayedHassan Khatoonabadi, Emad Shihab

**åˆ†ç±»**: cs.SE, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ–‡æ¡£ä¸ä»£ç è¿½è¸ªä¸­çš„åº”ç”¨æ½œåŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æ¡£ä¸ä»£ç è¿½è¸ª` `è‡ªåŠ¨åŒ–å·¥å…·` `è½¯ä»¶å·¥ç¨‹` `æ•°æ®é›†æ„å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ–‡æ¡£ä¸ä»£ç ä¹‹é—´çš„è¿½è¸ªå‡†ç¡®æ€§å’Œè§£é‡Šè´¨é‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶åœ¨å¤šæ­¥é“¾é‡æ„æ–¹é¢è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡è¯„ä¼°å¤šç§å¤§å‹è¯­è¨€æ¨¡å‹æ¥è‡ªåŠ¨åŒ–æ–‡æ¡£ä¸ä»£ç çš„è¿½è¸ªï¼Œåˆ©ç”¨æ–°åˆ›å»ºçš„æ•°æ®é›†è¿›è¡Œç³»ç»Ÿæ€§å®éªŒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€ä½³LLMåœ¨è¿½è¸ªé“¾æ¥è¯†åˆ«ä¸Šå–å¾—79.4%å’Œ80.4%çš„F1åˆ†æ•°ï¼Œéƒ¨åˆ†å‡†ç¡®æ€§è¶…è¿‡97%ï¼Œæ˜¾ç¤ºå‡ºLLMsåœ¨è¿½è¸ªå‘ç°ä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ºè‡ªåŠ¨åŒ–æ–‡æ¡£ä¸ä»£ç è¿½è¸ªæä¾›äº†æ–°çš„å¯èƒ½æ€§ï¼Œä½†å…¶èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡å…¨é¢è¯„ä¼°äº†LLMsï¼ˆClaude 3.5 Sonnetã€GPT-4oå’Œo3-miniï¼‰åœ¨å»ºç«‹è½¯ä»¶æ–‡æ¡£ï¼ˆåŒ…æ‹¬APIå‚è€ƒå’Œç”¨æˆ·æŒ‡å—ï¼‰ä¸æºä»£ç ä¹‹é—´çš„è¿½è¸ªé“¾æ¥çš„èƒ½åŠ›ã€‚æˆ‘ä»¬ä»ä¸¤ä¸ªå¼€æºé¡¹ç›®ï¼ˆUnity Catalogå’ŒCrawl4AIï¼‰åˆ›å»ºäº†ä¸¤ä¸ªæ–°æ•°æ®é›†ã€‚é€šè¿‡ç³»ç»Ÿå®éªŒï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸‰ä¸ªå…³é”®èƒ½åŠ›ï¼šè¿½è¸ªé“¾æ¥è¯†åˆ«å‡†ç¡®æ€§ã€å…³ç³»è§£é‡Šè´¨é‡å’Œå¤šæ­¥é“¾é‡æ„ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¡¨ç°æœ€ä½³çš„LLMåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°åˆ†åˆ«ä¸º79.4%å’Œ80.4%ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ˆTF-IDFã€BM25å’ŒCodeBERTï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æ¡£ä¸ä»£ç ä¹‹é—´è¿½è¸ªé“¾æ¥çš„è¯†åˆ«å’Œè§£é‡Šé—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œå¤šæ­¥é“¾é‡æ„æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒçš„LLMsï¼Œæ¢ç´¢å…¶åœ¨æ–‡æ¡£ä¸ä»£ç è¿½è¸ªä¸­çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯å¦‚ä½•æé«˜è¿½è¸ªé“¾æ¥çš„è¯†åˆ«å’Œè§£é‡Šè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸¤ä¸ªæ–°åˆ›å»ºçš„æ•°æ®é›†ï¼Œåˆ†åˆ«æ¥è‡ªUnity Catalogå’ŒCrawl4AIé¡¹ç›®ï¼Œå®éªŒåˆ†ä¸ºè¿½è¸ªé“¾æ¥è¯†åˆ«ã€å…³ç³»è§£é‡Šå’Œå¤šæ­¥é“¾é‡æ„ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†å¤šç§LLMsåœ¨è¿½è¸ªä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯é€šè¿‡ä»»åŠ¡æ¡†æ¶è®¾è®¡ï¼ˆå¦‚ä¸€å¯¹å¤šåŒ¹é…ç­–ç•¥ï¼‰æ¥æå‡æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†F1åˆ†æ•°ä½œä¸ºä¸»è¦è¯„ä¼°æŒ‡æ ‡ï¼Œåˆ†æäº†é”™è¯¯æ¥æºï¼ŒåŒ…æ‹¬å‘½åå‡è®¾ã€è™šå‡é“¾æ¥å’Œæ¶æ„æ¨¡å¼çš„è¿‡åº¦æ³›åŒ–ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ€ä½³è¡¨ç°çš„LLMåœ¨ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°åˆ†åˆ«ä¸º79.4%å’Œ80.4%ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ˆTF-IDFã€BM25å’ŒCodeBERTï¼‰ã€‚æ­¤å¤–ï¼Œéƒ¨åˆ†å‡†ç¡®æ€§è¶…è¿‡97%ï¼Œè¡¨æ˜LLMsåœ¨æ•æ‰åŸºæœ¬è¿æ¥æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€ç»´æŠ¤å’Œæ–‡æ¡£ç”Ÿæˆç­‰ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å¼€å‘è€…åœ¨ç†è§£å’Œç»´æŠ¤ä»£ç æ—¶çš„æ•ˆç‡ã€‚æœªæ¥ï¼Œéšç€LLMsçš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šåœ¨è‡ªåŠ¨åŒ–æ–‡æ¡£ç”Ÿæˆå’Œä»£ç å®¡æŸ¥ç­‰æ–¹é¢å‘æŒ¥æ›´å¤§ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) offer new potential for automating documentation-to-code traceability, yet their capabilities remain underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5 Sonnet, GPT-4o, and o3-mini) in establishing trace links between various software documentation (including API references and user guides) and source code. We create two novel datasets from two open-source projects (Unity Catalog and Crawl4AI). Through systematic experiments, we assess three key capabilities: (1) trace link identification accuracy, (2) relationship explanation quality, and (3) multi-step chain reconstruction. Results show that the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two datasets, substantially outperforming our baselines (TF-IDF, BM25, and CodeBERT). While fully correct relationship explanations range from 42.9% to 71.1%, partial accuracy exceeds 97%, indicating that fundamental connections are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy but vary in capturing precise intermediate links. Error analysis reveals that many false positives stem from naming-based assumptions, phantom links, or overgeneralization of architectural patterns. We demonstrate that task-framing, such as a one-to-many matching strategy, is critical for performance. These findings position LLMs as powerful assistants for trace discovery, but their limitations could necessitate human-in-the-loop tool design and highlight specific error patterns for future research.

