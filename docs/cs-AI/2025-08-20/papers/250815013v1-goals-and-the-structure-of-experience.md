---
layout: default
title: Goals and the Structure of Experience
---

# Goals and the Structure of Experience

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15013" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15013v1</a>
  <a href="https://arxiv.org/pdf/2508.15013.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15013v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15013v1', 'Goals and the Structure of Experience')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nadav Amir, Stas Tiomkin, Angela Langdon

**åˆ†ç±»**: cs.AI, q-bio.NC

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**DOI**: [10.1098/RSTA-2025-0004](https://doi.org/10.1098/RSTA-2025-0004)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç›®æ ‡å¯¼å‘çŠ¶æ€è¡¨å¾ä»¥è§£å†³æ™ºèƒ½ä½“è¡Œä¸ºå»ºæ¨¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç›®æ ‡å¯¼å‘å­¦ä¹ ` `æ™ºèƒ½ä½“å»ºæ¨¡` `è¡Œä¸ºç­–ç•¥` `ç»éªŒåˆ†å¸ƒ` `ç»Ÿè®¡å­¦ä¹ ` `äººå·¥æ™ºèƒ½` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›®çš„æ€§è¡Œä¸ºæ¨¡å‹å¾€å¾€å°†æè¿°æ€§å’Œè§„èŒƒæ€§è§†ä¸ºç‹¬ç«‹éƒ¨åˆ†ï¼Œéš¾ä»¥è§£é‡Šå…¶ç›¸äº’å…³ç³»ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç›®æ ‡å¯¼å‘çš„çŠ¶æ€è¡¨å¾æ¡†æ¶ï¼Œè®¤ä¸ºæè¿°æ€§å’Œè§„èŒƒæ€§å¯ä»¥ä»æ™ºèƒ½ä½“çš„ç›®æ ‡ä¸­å…±ç”Ÿã€‚
3. é€šè¿‡ç†è®ºå’Œå®è¯æ–‡çŒ®çš„æ”¯æŒï¼Œæœ¬æ–‡å±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨ç›®çš„æ€§è¡Œä¸ºç†è§£ä¸Šçš„æ½œåŠ›ï¼Œæä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®çš„æ€§è¡Œä¸ºæ˜¯è‡ªç„¶å’Œäººå·¥æ™ºèƒ½çš„æ ‡å¿—ï¼Œå…¶è·å–é€šå¸¸ä¾èµ–äºä¸–ç•Œæ¨¡å‹ï¼ŒåŒ…æ‹¬æè¿°æ€§ï¼ˆç°å®æ˜¯ä»€ä¹ˆï¼‰å’Œè§„èŒƒæ€§ï¼ˆç†æƒ³æ˜¯ä»€ä¹ˆï¼‰ä¸¤ä¸ªæ–¹é¢ã€‚ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ ç­‰è®¡ç®—æ¨¡å‹å°†è¿™ä¸¤ä¸ªæ–¹é¢è§†ä¸ºç‹¬ç«‹çš„ç»„æˆéƒ¨åˆ†ã€‚ç„¶è€Œï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è®¡ç®—æ¡†æ¶ï¼Œè®¤ä¸ºè¿™ä¸¤ä¸ªæ–¹é¢å¯ä»¥ä»æ™ºèƒ½ä½“çš„ç›®æ ‡ä¸­ç›¸äº’å…±ç”Ÿã€‚é€šè¿‡å¼•å…¥ç›®æ ‡å¯¼å‘çŠ¶æ€çš„æ¦‚å¿µï¼Œæœ¬æ–‡ä¸ºç›®çš„æ€§å­¦ä¹ æä¾›äº†ä¸€ç§ç®€æ´çš„ç»Ÿè®¡å­¦è§£é‡Šï¼Œå¹¶æ¢è®¨äº†å…¶åœ¨è¡Œä¸ºã€ç°è±¡å­¦å’Œç¥ç»ç»´åº¦ä¸Šçš„ç»Ÿä¸€æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç›®çš„æ€§è¡Œä¸ºæ¨¡å‹ä¸­æè¿°æ€§å’Œè§„èŒƒæ€§ä¹‹é—´çš„ç‹¬ç«‹æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥è§£é‡Šæ™ºèƒ½ä½“å¦‚ä½•ä»ç»éªŒä¸­å­¦ä¹ å’Œé€‚åº”ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºç›®æ ‡å¯¼å‘çŠ¶æ€çš„æ¦‚å¿µï¼Œè®¤ä¸ºæè¿°æ€§å’Œè§„èŒƒæ€§å¯ä»¥é€šè¿‡æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’ç»éªŒå…±åŒç”Ÿæˆï¼Œä»è€Œå½¢æˆä¸€ä¸ªç»Ÿä¸€çš„ä¸–ç•Œæ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº¤äº’è¿‡ç¨‹ï¼Œé€šè¿‡ç»éªŒåºåˆ—ç”Ÿæˆç›®æ ‡å¯¼å‘çŠ¶æ€ï¼Œè¿›è€Œå½±å“è¡Œä¸ºç­–ç•¥å’Œå¥–åŠ±å‡½æ•°çš„è®¾è®¡ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬çŠ¶æ€è¡¨å¾ã€ç»éªŒåˆ†å¸ƒå’Œè¡Œä¸ºç­–ç•¥ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†æè¿°æ€§å’Œè§„èŒƒæ€§è§†ä¸ºå…±ç”Ÿçš„ç›®æ ‡å¯¼å‘çŠ¶æ€ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿæ¨¡å‹çš„å±€é™ï¼Œæä¾›äº†ä¸€ç§æ–°çš„å­¦ä¹ æœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç»Ÿè®¡å­¦æ–¹æ³•æ¥é‡åŒ–è¡Œä¸ºç­–ç•¥ä¸ç†æƒ³ç»éªŒç‰¹å¾ä¹‹é—´çš„ç»Ÿè®¡åå·®ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨æœ€å°åŒ–è¿™ç§åå·®ï¼Œç¡®ä¿å­¦ä¹ è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨ç›®æ ‡å¯¼å‘çŠ¶æ€çš„æ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”åœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›æ˜¾è‘—å¢å¼ºï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ä½“çš„è‡ªä¸»å­¦ä¹ ã€æœºå™¨äººæ§åˆ¶å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£ç›®çš„æ€§è¡Œä¸ºï¼Œæœªæ¥å¯ä»¥å¼€å‘å‡ºæ›´æ™ºèƒ½çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­è‡ªä¸»é€‚åº”å’Œä¼˜åŒ–è¡Œä¸ºï¼Œæå‡äººå·¥æ™ºèƒ½çš„å®ç”¨æ€§å’Œçµæ´»æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Purposeful behavior is a hallmark of natural and artificial intelligence. Its acquisition is often believed to rely on world models, comprising both descriptive (what is) and prescriptive (what is desirable) aspects that identify and evaluate state of affairs in the world, respectively. Canonical computational accounts of purposeful behavior, such as reinforcement learning, posit distinct components of a world model comprising a state representation (descriptive aspect) and a reward function (prescriptive aspect). However, an alternative possibility, which has not yet been computationally formulated, is that these two aspects instead co-emerge interdependently from an agent's goal. Here, we describe a computational framework of goal-directed state representation in cognitive agents, in which the descriptive and prescriptive aspects of a world model co-emerge from agent-environment interaction sequences, or experiences. Drawing on Buddhist epistemology, we introduce a construct of goal-directed, or telic, states, defined as classes of goal-equivalent experience distributions. Telic states provide a parsimonious account of goal-directed learning in terms of the statistical divergence between behavioral policies and desirable experience features. We review empirical and theoretical literature supporting this novel perspective and discuss its potential to provide a unified account of behavioral, phenomenological and neural dimensions of purposeful behaviors across diverse substrates.

