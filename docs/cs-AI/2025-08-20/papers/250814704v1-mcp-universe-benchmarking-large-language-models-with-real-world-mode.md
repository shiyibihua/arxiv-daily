---
layout: default
title: MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers
---

# MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14704" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.14704v1</a>
  <a href="https://arxiv.org/pdf/2508.14704.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14704v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14704v1', 'MCP-Universe: Benchmarking Large Language Models with Real-World Model Context Protocol Servers')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ziyang Luo, Zhiqi Shen, Wenzhuo Yang, Zirui Zhao, Prathyusha Jwalapuram, Amrita Saha, Doyen Sahoo, Silvio Savarese, Caiming Xiong, Junnan Li

**ÂàÜÁ±ª**: cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-20

**Â§áÊ≥®**: Website: https://mcp-universe.github.io

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫MCP-Universe‰ª•Ëß£ÂÜ≥Áé∞ÊúâLLMÂü∫ÂáÜËØÑ‰º∞‰∏çË∂≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ê®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ` `Âü∫ÂáÜËØÑ‰º∞` `ÈïøÊó∂Èó¥Êé®ÁêÜ` `Êú™Áü•Â∑•ÂÖ∑` `AIÂ∫îÁî®` `ÂºÄÊ∫êÊ°ÜÊû∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑLLMÂü∫ÂáÜËØÑ‰º∞ÊñπÊ≥ïËøá‰∫éÁÆÄÂçïÔºåÊó†Ê≥ïÂ∫îÂØπÈïøÊó∂Èó¥Êé®ÁêÜÂíåÂ§çÊùÇÂ∑•ÂÖ∑ÁöÑÊåëÊàò„ÄÇ
2. MCP-UniverseÈÄöËøá‰∏éÁúüÂÆûÁöÑMCPÊúçÂä°Âô®‰∫§‰∫íÔºåÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÂÖ®Èù¢ÁöÑÂü∫ÂáÜËØÑ‰º∞Ê°ÜÊû∂ÔºåÊ∂µÁõñÂ§ö‰∏™Â∫îÁî®È¢ÜÂüü„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÈ¢ÜÂÖàÁöÑLLMÊ®°ÂûãÂú®Â§çÊùÇ‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩÈôêÂà∂ÔºåÂ∞§ÂÖ∂ÊòØÂú®Èïø‰∏ä‰∏ãÊñáÂíåÊú™Áü•Â∑•ÂÖ∑ÁöÑÊåëÊàò‰∏ã„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ê®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆÔºàMCPÔºâÂ∑≤Êàê‰∏∫ËøûÊé•Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰∏éÂ§ñÈÉ®Êï∞ÊçÆÊ∫êÂíåÂ∑•ÂÖ∑ÁöÑÂèòÈù©ÊÄßÊ†áÂáÜ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÂü∫ÂáÜËøá‰∫éÁÆÄÂçïÔºåÊó†Ê≥ïÊçïÊçâÂÆûÈôÖÂ∫îÁî®‰∏≠ÁöÑÊåëÊàòÔºåÂ¶ÇÈïøÊó∂Èó¥Êé®ÁêÜÂíåÂ§ßÂûã‰∏çÁÜüÊÇâÂ∑•ÂÖ∑Á©∫Èó¥„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫MCP-UniverseÔºåËøôÊòØÁ¨¨‰∏Ä‰∏™‰∏ìÈó®ËÆæËÆ°Áî®‰∫éÈÄöËøá‰∏éÁúüÂÆûMCPÊúçÂä°Âô®‰∫§‰∫íÊù•ËØÑ‰º∞LLMÂú®Áé∞ÂÆûÂíåÂõ∞Èöæ‰ªªÂä°‰∏≠ÁöÑÁªºÂêàÂü∫ÂáÜ„ÄÇÊàë‰ª¨ÁöÑÂü∫ÂáÜÊ∂µÁõñ6‰∏™Ê†∏ÂøÉÈ¢ÜÂüüÔºåÊ∂âÂèä11‰∏™‰∏çÂêåÁöÑMCPÊúçÂä°Âô®„ÄÇÈÄöËøáÂØπÈ¢ÜÂÖàLLMÁöÑÂπøÊ≥õËØÑ‰º∞ÔºåÊàë‰ª¨ÂèëÁé∞Âç≥‰ΩøÊòØÊúÄÂÖàËøõÁöÑÊ®°Âûã‰πüÂ≠òÂú®ÊòæËëóÁöÑÊÄßËÉΩÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ÂºÄÊ∫ê‰∫ÜÂèØÊâ©Â±ïÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÊîØÊåÅÁ†îÁ©∂‰∫∫ÂëòÂíå‰ªé‰∏öËÄÖÊó†ÁºùÈõÜÊàêÊñ∞‰ª£ÁêÜÂíåMCPÊúçÂä°Âô®ÔºåÊé®Âä®MCPÁîüÊÄÅÁ≥ªÁªüÁöÑÂàõÊñ∞„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑLLMÂü∫ÂáÜËØÑ‰º∞ÊñπÊ≥ïÊú™ËÉΩÊúâÊïàÊçïÊçâÁúüÂÆûÂ∫îÁî®‰∏≠ÁöÑÂ§çÊùÇÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈïøÊó∂Èó¥Êé®ÁêÜÂíå‰∏çÁÜüÊÇâÂ∑•ÂÖ∑ÁöÑ‰ΩøÁî®ÊñπÈù¢Â≠òÂú®ÊòæËëó‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöMCP-UniverseÈÄöËøáËÆæËÆ°‰∏Ä‰∏™‰∏éÁúüÂÆûMCPÊúçÂä°Âô®‰∫§‰∫íÁöÑÁªºÂêàÂü∫ÂáÜÔºåÊó®Âú®ËØÑ‰º∞LLMÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÁ°Æ‰øùËØÑ‰º∞ÁöÑÁúüÂÆûÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•Ê°ÜÊû∂ÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºåÊ∂µÁõñ6‰∏™Ê†∏ÂøÉÈ¢ÜÂüüÂíå11‰∏™MCPÊúçÂä°Âô®ÔºåÈááÁî®ÊâßË°åÂü∫Á°ÄËØÑ‰º∞Âô®ÔºåÂåÖÊã¨Ê†ºÂºèËØÑ‰º∞Âô®„ÄÅÈùôÊÄÅËØÑ‰º∞Âô®ÂíåÂä®ÊÄÅËØÑ‰º∞Âô®Ôºå‰ª•Á°Æ‰øùËØÑ‰º∞ÁöÑÂÖ®Èù¢ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöMCP-UniverseÊòØÈ¶ñ‰∏™‰∏ìÈó®ÈíàÂØπLLMÂú®ÁúüÂÆûÂ∫îÁî®‰∏≠Ë°®Áé∞ÁöÑÁªºÂêàÂü∫ÂáÜÔºåÂº∫Ë∞É‰∫ÜÈïø‰∏ä‰∏ãÊñáÂíåÊú™Áü•Â∑•ÂÖ∑ÁöÑÊåëÊàòÔºå‰∏é‰º†ÁªüÂü∫ÂáÜÁöÑÁÆÄÂçïÊÄßÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËØÑ‰º∞ËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÂ§öÁßçËØÑ‰º∞Âô®ÔºåÁ°Æ‰øùÂØπÊó∂Èó¥ÊïèÊÑü‰ªªÂä°ÁöÑÂÆûÊó∂ÁúüÁõ∏Ê£ÄÁ¥¢ÔºåËÆæËÆ°‰∫ÜÈÄÇÂ∫îÈïøËæìÂÖ•ÁöÑÂ§ÑÁêÜÊú∫Âà∂Ôºå‰ª•Â∫îÂØπËæìÂÖ•Ê†áËÆ∞Êï∞ÈáèÈöè‰∫§‰∫íÊ≠•È™§Â¢ûÂä†ÁöÑÊåëÊàò„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂç≥‰ΩøÊòØÊúÄÂÖàËøõÁöÑÊ®°ÂûãÔºåÂ¶ÇGPT-5„ÄÅGrok-4ÂíåClaude-4.0-SonnetÔºåÂú®MCP-UniverseÂü∫ÂáÜ‰∏ãÁöÑË°®Áé∞ÂàÜÂà´‰∏∫43.72%„ÄÅ33.33%Âíå29.44%ÔºåÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊÄßËÉΩÈôêÂà∂„ÄÇÊ≠§Â§ñÔºå‰ºÅ‰∏öÁ∫ß‰ª£ÁêÜÂ¶ÇCursorÂú®ËØ•Âü∫ÂáÜ‰∏ãÁöÑË°®Áé∞Êú™ËÉΩË∂ÖË∂äÊ†áÂáÜÁöÑReActÊ°ÜÊû∂ÔºåÁ™ÅÊòæ‰∫ÜÈïø‰∏ä‰∏ãÊñáÂíåÊú™Áü•Â∑•ÂÖ∑ÁöÑÊåëÊàò„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MCP-UniverseÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éAIÂºÄÂèëÂíåËØÑ‰º∞È¢ÜÂüüÔºåÁâπÂà´ÊòØÂú®ÈúÄË¶Å‰∏éÂ§ñÈÉ®Êï∞ÊçÆÊ∫êÂíåÂ∑•ÂÖ∑‰∫§‰∫íÁöÑÂ∫îÁî®Âú∫ÊôØ‰∏≠ÔºåÂ¶ÇÈáëËûçÂàÜÊûê„ÄÅ‰ΩçÁΩÆÂØºËà™ÂíåÊµèËßàÂô®Ëá™Âä®ÂåñÁ≠â„ÄÇÈÄöËøáÊèê‰æõ‰∏Ä‰∏™Ê†áÂáÜÂåñÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÁ†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖÂèØ‰ª•Êõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÊèêÂçáLLMÂú®Â§çÊùÇ‰ªªÂä°‰∏≠ÁöÑË°®Áé∞ÔºåÊé®Âä®AIÊäÄÊúØÁöÑËøõÊ≠•ÂíåÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The Model Context Protocol has emerged as a transformative standard for connecting large language models to external data sources and tools, rapidly gaining adoption across major AI providers and development platforms. However, existing benchmarks are overly simplistic and fail to capture real application challenges such as long-horizon reasoning and large, unfamiliar tool spaces. To address this critical gap, we introduce MCP-Universe, the first comprehensive benchmark specifically designed to evaluate LLMs in realistic and hard tasks through interaction with real-world MCP servers. Our benchmark encompasses 6 core domains spanning 11 different MCP servers: Location Navigation, Repository Management, Financial Analysis, 3D Design, Browser Automation, and Web Searching. To ensure rigorous evaluation, we implement execution-based evaluators, including format evaluators for agent format compliance, static evaluators for time-invariant content matching, and dynamic evaluators that automatically retrieve real-time ground truth for temporally sensitive tasks. Through extensive evaluation of leading LLMs, we find that even SOTA models such as GPT-5 (43.72%), Grok-4 (33.33%) and Claude-4.0-Sonnet (29.44%) exhibit significant performance limitations. In addition, our benchmark poses a significant long-context challenge for LLM agents, as the number of input tokens increases rapidly with the number of interaction steps. Moreover, it introduces an unknown-tools challenge, as LLM agents often lack familiarity with the precise usage of the MCP servers. Notably, enterprise-level agents like Cursor cannot achieve better performance than standard ReAct frameworks. Beyond evaluation, we open-source our extensible evaluation framework with UI support, enabling researchers and practitioners to seamlessly integrate new agents and MCP servers while fostering innovation in the rapidly evolving MCP ecosystem.

