---
layout: default
title: Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions
---

# Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14556" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14556v1</a>
  <a href="https://arxiv.org/pdf/2508.14556.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14556v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14556v1', 'Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Euiyeon Kim, Yong-Hoon Choi

**åˆ†ç±»**: cs.SD, cs.AI, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMamba2æ¨¡å‹ä»¥è§£å†³ç¨€ç–åŒºåŸŸçš„å£°æºåˆ†ç¦»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å£°æºåˆ†ç¦»` `éŸ³é¢‘å¤„ç†` `Mamba2æ¨¡å‹` `é•¿æ—¶é—´åºåˆ—` `éŸ³ä¹æŠ€æœ¯` `æ·±åº¦å­¦ä¹ ` `çŠ¶æ€ç©ºé—´æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å£°æºåˆ†ç¦»æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºTransformerçš„æ¨¡å‹ï¼Œå¸¸å¸¸æ— æ³•æœ‰æ•ˆæ•æ‰é—´æ­‡æ€§å‡ºç°çš„å£°ä¹ï¼Œå¯¼è‡´åˆ†ç¦»æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºMamba2çš„æ¨¡å‹ï¼Œé€šè¿‡ç»“åˆå¸¦åˆ†å‰²ç­–ç•¥å’ŒåŒè·¯å¾„æ¶æ„ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†é•¿æ—¶é—´åºåˆ—çš„å£°ä¹åˆ†ç¦»é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨cSDRä¸Šè¾¾åˆ°äº†11.03 dBï¼Œè¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›çš„æ¨¡å‹ï¼Œå¹¶åœ¨ä¸åŒè¾“å…¥æ¡ä»¶ä¸‹è¡¨ç°å‡ºç¨³å®šæ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°å‹éŸ³ä¹æºåˆ†ç¦»æ¨¡å‹ï¼Œæ—¨åœ¨å®ç°å‡†ç¡®çš„å£°ä¹éš”ç¦»ã€‚ä¸åŸºäºTransformerçš„æ–¹æ³•ä¸åŒï¼Œè¯¥æ¨¡å‹åˆ©ç”¨Mamba2è¿™ä¸€æœ€æ–°çš„çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼Œæ›´å¥½åœ°æ•æ‰é•¿æ—¶é—´çš„æ—¶é—´ä¾èµ–æ€§ã€‚ä¸ºé«˜æ•ˆå¤„ç†é•¿è¾“å…¥åºåˆ—ï¼Œæœ¬æ–‡ç»“åˆäº†å¸¦åˆ†å‰²ç­–ç•¥ä¸åŒè·¯å¾„æ¶æ„ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨cSDRä¸Šè¾¾åˆ°äº†11.03 dBï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œå¹¶åœ¨uSDRä¸Šä¹Ÿå–å¾—äº†æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨ä¸åŒè¾“å…¥é•¿åº¦å’Œå£°ä¹å‡ºç°æ¨¡å¼ä¸‹è¡¨ç°ç¨³å®šä¸€è‡´ï¼Œå±•ç¤ºäº†åŸºäºMambaçš„æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡éŸ³é¢‘å¤„ç†ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸ºéŸ³é¢‘ç ”ç©¶çš„æ›´å¹¿æ³›åº”ç”¨å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å£°æºåˆ†ç¦»ä¸­çš„å£°ä¹éš”ç¦»é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é—´æ­‡æ€§å£°ä¹æ—¶è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´åˆ†ç¦»æ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Mamba2æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œç»“åˆå¸¦åˆ†å‰²ç­–ç•¥å’ŒåŒè·¯å¾„æ¶æ„ï¼Œä»¥æ›´å¥½åœ°æ•æ‰é•¿æ—¶é—´çš„æ—¶é—´ä¾èµ–æ€§ï¼Œä»è€Œæé«˜å£°ä¹åˆ†ç¦»çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥éŸ³é¢‘çš„å¸¦åˆ†å‰²å¤„ç†ï¼Œéšåé€šè¿‡åŒè·¯å¾„ç½‘ç»œè¿›è¡Œç‰¹å¾æå–å’Œå£°æºåˆ†ç¦»ï¼Œæœ€åè¾“å‡ºåˆ†ç¦»åçš„å£°ä¹å’Œä¼´å¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé‡‡ç”¨Mamba2æ¨¡å‹ï¼Œè¿™ä¸€çŠ¶æ€ç©ºé—´æ¨¡å‹åœ¨å¤„ç†é•¿åºåˆ—æ—¶è¡¨ç°ä¼˜è¶Šï¼Œæ˜¾è‘—æ”¹å–„äº†å£°ä¹çš„åˆ†ç¦»æ•ˆæœï¼Œä¸ä¼ ç»Ÿçš„Transformeræ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å£°ä¹ä¸ä¼´å¥çš„åˆ†ç¦»æ•ˆæœï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥é€‚åº”é•¿è¾“å…¥åºåˆ—çš„å¤„ç†éœ€æ±‚ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œå±‚æ•°åœ¨å®éªŒä¸­ç»è¿‡è°ƒä¼˜ï¼Œä»¥è¾¾åˆ°æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ¨¡å‹åœ¨cSDRä¸Šè¾¾åˆ°äº†11.03 dBï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ï¼Œå¹¶åœ¨uSDRä¸Šä¹Ÿå–å¾—äº†æ˜¾è‘—æå‡ã€‚è¿™ä¸€æ€§èƒ½æå‡å±•ç¤ºäº†Mamba2æ¨¡å‹åœ¨é«˜åˆ†è¾¨ç‡éŸ³é¢‘å¤„ç†ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ä¸åŒè¾“å…¥é•¿åº¦å’Œå£°ä¹å‡ºç°æ¨¡å¼æ—¶è¡¨ç°å‡ºç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éŸ³ä¹åˆ¶ä½œã€éŸ³é¢‘åæœŸå¤„ç†ä»¥åŠè¯­éŸ³è¯†åˆ«ç­‰ã€‚é€šè¿‡æé«˜å£°ä¹åˆ†ç¦»çš„å‡†ç¡®æ€§ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿä¸ºéŸ³ä¹åˆ›ä½œå’ŒéŸ³é¢‘åˆ†ææä¾›æ›´é«˜è´¨é‡çš„éŸ³é¢‘ç´ æï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce a new music source separation model tailored for accurate vocal isolation. Unlike Transformer-based approaches, which often fail to capture intermittently occurring vocals, our model leverages Mamba2, a recent state space model, to better capture long-range temporal dependencies. To handle long input sequences efficiently, we combine a band-splitting strategy with a dual-path architecture. Experiments show that our approach outperforms recent state-of-the-art models, achieving a cSDR of 11.03 dB-the best reported to date-and delivering substantial gains in uSDR. Moreover, the model exhibits stable and consistent performance across varying input lengths and vocal occurrence patterns. These results demonstrate the effectiveness of Mamba-based models for high-resolution audio processing and open up new directions for broader applications in audio research.

