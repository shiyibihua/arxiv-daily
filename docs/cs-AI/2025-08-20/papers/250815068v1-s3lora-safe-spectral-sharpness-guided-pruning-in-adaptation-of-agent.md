---
layout: default
title: S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner
---

# S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15068" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15068v1</a>
  <a href="https://arxiv.org/pdf/2508.15068.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15068v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15068v1', 'S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuang Ao, Gopal Rumchurn

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: 9 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºS3LoRAä»¥è§£å†³LLMé€‚åº”è¿‡ç¨‹ä¸­çš„å®‰å…¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®‰å…¨æ€§é€‚åº”` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç†è§„åˆ’` `è°±é”åº¦` `æ¨¡å‹ä¿®å‰ª` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®‰å…¨æ„ŸçŸ¥é€‚åº”æ–¹æ³•ä¾èµ–äºåŸºç¡€å’ŒæŒ‡ä»¤è°ƒä¼˜æ¨¡å‹çš„æ£€æŸ¥ç‚¹ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚
2. S3LoRAé€šè¿‡ä»…åˆ†æå¾®è°ƒçš„æƒé‡æ›´æ–°ï¼Œåˆ©ç”¨MAS-SVDå’ŒSSIæ¥é™ä½å®‰å…¨é£é™©ï¼Œé¿å…äº†å¯¹å®Œæ•´æ¨¡å‹çš„ä¾èµ–ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒS3LoRAåœ¨ä»£ç†è§„åˆ’å’Œè¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå®‰å…¨æ€§æŒ‡æ ‡æ˜¾è‘—æå‡ï¼ŒåŒæ—¶æ•ˆç”¨æŒ‡æ ‡ä¿æŒä¸å˜æˆ–æœ‰æ‰€æé«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æŠ€æœ¯ä¸­ï¼ŒLoRAçš„åº”ç”¨å¢å¼ºäº†LLMä»£ç†çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›é€‚åº”å¯èƒ½ä¼šæ— æ„ä¸­å¦¥åå®‰å…¨æ€§ï¼Œå¯¼è‡´ä¸å®‰å…¨æˆ–ä¸ç¨³å®šçš„è¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨ä»£ç†è§„åˆ’ä»»åŠ¡ä¸­ã€‚ç°æœ‰çš„å®‰å…¨æ„ŸçŸ¥é€‚åº”æ–¹æ³•é€šå¸¸éœ€è¦è®¿é—®åŸºç¡€å’ŒæŒ‡ä»¤è°ƒä¼˜æ¨¡å‹çš„æ£€æŸ¥ç‚¹ï¼Œè¿™åœ¨å®é™…ä¸­å¾€å¾€ä¸å¯ç”¨ï¼Œé™åˆ¶äº†å…¶é€‚ç”¨æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†S3LoRAï¼ˆå®‰å…¨è°±é”åº¦å¼•å¯¼ä¿®å‰ªLoRAï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ã€æ— æ•°æ®ä¸”ä¸æ¨¡å‹æ— å…³çš„æ¡†æ¶ï¼Œé€šè¿‡ä»…æ£€æŸ¥å¾®è°ƒçš„æƒé‡æ›´æ–°æ¥é™ä½LoRAé€‚åº”æ¨¡å‹çš„å®‰å…¨é£é™©ã€‚æˆ‘ä»¬é¦–å…ˆå¼•å…¥äº†å¹…åº¦æ„ŸçŸ¥çƒé¢å½’ä¸€åŒ–å¥‡å¼‚å€¼åˆ†è§£ï¼ˆMAS-SVDï¼‰ï¼Œå®ƒåœ¨ä¿ç•™å…¨å±€å¹…åº¦ä¿¡æ¯çš„åŒæ—¶ï¼Œç¨³å¥åœ°åˆ†æLoRAæ›´æ–°çš„ç»“æ„ç‰¹æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†è°±é”åº¦æŒ‡æ•°ï¼ˆSSIï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ„ŸçŸ¥é”åº¦çš„æŒ‡æ ‡ï¼Œç”¨äºæ£€æµ‹å…·æœ‰é«˜åº¦é›†ä¸­ä¸”å¯èƒ½ä¸å®‰å…¨æ›´æ–°çš„å±‚ã€‚è¿™äº›å±‚åœ¨åå¤„ç†æ—¶è¢«ä¿®å‰ªï¼Œä»¥é™ä½é£é™©è€Œä¸ç‰ºç‰²ä»»åŠ¡æ€§èƒ½ã€‚å¤§é‡å®éªŒå’Œæ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒS3LoRAåœ¨æé«˜å®‰å…¨æ€§æŒ‡æ ‡çš„åŒæ—¶ï¼Œä¿æŒæˆ–æå‡äº†æ•ˆç”¨æŒ‡æ ‡ï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤§å‹è¯­è¨€æ¨¡å‹é€‚åº”è¿‡ç¨‹ä¸­ï¼Œå®‰å…¨æ€§ä¸æ€§èƒ½ä¹‹é—´çš„çŸ›ç›¾ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å®Œæ•´çš„æ¨¡å‹æ£€æŸ¥ç‚¹ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šS3LoRAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†æå¾®è°ƒçš„æƒé‡æ›´æ–°ï¼Œè¯†åˆ«å¹¶ä¿®å‰ªæ½œåœ¨ä¸å®‰å…¨çš„å±‚ï¼Œä»è€Œé™ä½å®‰å…¨é£é™©ï¼Œè€Œæ— éœ€ä¾èµ–å®Œæ•´æ¨¡å‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šS3LoRAæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼š1) MAS-SVDï¼Œç”¨äºåˆ†æLoRAæ›´æ–°çš„ç»“æ„ç‰¹æ€§ï¼›2) SSIï¼Œç”¨äºè¯„ä¼°å±‚çš„é”åº¦å¹¶è¯†åˆ«éœ€è¦ä¿®å‰ªçš„å±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†MAS-SVDå’ŒSSIï¼Œå‰è€…åœ¨ä¿ç•™å…¨å±€å¹…åº¦ä¿¡æ¯çš„åŒæ—¶åˆ†ææ›´æ–°çš„ç»“æ„ï¼Œåè€…åˆ™æä¾›äº†ä¸€ç§æ–°çš„é”åº¦æ„ŸçŸ¥æŒ‡æ ‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«ä¸å®‰å…¨çš„æ›´æ–°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨MAS-SVDä¸­ï¼Œé‡‡ç”¨äº†çƒé¢å½’ä¸€åŒ–çš„å¥‡å¼‚å€¼åˆ†è§£æ–¹æ³•ï¼Œä»¥ç¡®ä¿åˆ†æçš„ç¨³å¥æ€§ï¼›åœ¨SSIçš„è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†æ›´æ–°çš„é›†ä¸­åº¦ï¼Œä»¥ä¾¿å‡†ç¡®è¯†åˆ«æ½œåœ¨é£é™©å±‚ã€‚å®éªŒä¸­è¿˜è¿›è¡Œäº†æ¶ˆèç ”ç©¶ï¼Œä»¥éªŒè¯å„ä¸ªæ¨¡å—çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒS3LoRAåœ¨ä»£ç†è§„åˆ’å’Œè¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå®‰å…¨æ€§æŒ‡æ ‡æ˜¾è‘—æé«˜ï¼Œå…·ä½“è¡¨ç°ä¸ºå®‰å…¨æ€§æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒåŒæ—¶æ•ˆç”¨æŒ‡æ ‡ä¿æŒä¸å˜æˆ–æœ‰æ‰€æå‡ï¼Œæ¨ç†æˆæœ¬é™ä½äº†15%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

S3LoRAçš„ç ”ç©¶æˆæœåœ¨å®‰å…¨å…³é”®çš„ç¯å¢ƒä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„å®é™…åœºæ™¯ä¸­ã€‚å®ƒä¸ºå¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨éƒ¨ç½²æä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆé™ä½ä¸å®‰å…¨è¡Œä¸ºçš„é£é™©ï¼Œæå‡ä»£ç†çš„å¯é æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning (PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based agents. However, these adaptations can unintentionally compromise safety alignment, leading to unsafe or unstable behaviors, particularly in agent planning tasks. Existing safety-aware adaptation methods often require access to both base and instruction-tuned model checkpoints, which are frequently unavailable in practice, limiting their applicability. We propose S3LoRA (Safe Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and model-independent framework that mitigates safety risks in LoRA-adapted models by inspecting only the fine-tuned weight updates. We first introduce Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes the structural properties of LoRA updates while preserving global magnitude information. We then design the Spectral Sharpness Index (SSI), a sharpness-aware metric to detect layers with highly concentrated and potentially unsafe updates. These layers are pruned post-hoc to reduce risk without sacrificing task performance. Extensive experiments and ablation studies across agent planning and language generation tasks show that S3LoRA consistently improves safety metrics while maintaining or improving utility metrics and significantly reducing inference cost. These results establish S3LoRA as a practical and scalable solution for safely deploying LLM-based agents in real-world, resource-constrained, and safety-critical environments.

