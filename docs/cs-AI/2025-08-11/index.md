---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-08-11
---

# cs.AIï¼ˆ2025-08-11ï¼‰

ğŸ“Š å…± **13** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (11 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (11 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250808237v3-vggsounder-audio-visual-evaluations-for-foundation-models.html">VGGSounder: Audio-Visual Evaluations for Foundation Models</a></td>
  <td>æå‡ºVGGSounderä»¥è§£å†³VGGSoundæ•°æ®é›†çš„è¯„ä¼°å±€é™æ€§</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08237v3" data-paper-url="./papers/250808237v3-vggsounder-audio-visual-evaluations-for-foundation-models.html" onclick="toggleFavorite(this, '2508.08237v3', 'VGGSounder: Audio-Visual Evaluations for Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250808180v2-reddino-a-foundation-model-for-red-blood-cell-analysis.html">RedDino: A foundation model for red blood cell analysis</a></td>
  <td>æå‡ºRedDinoä»¥è§£å†³çº¢ç»†èƒåˆ†æçš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08180v2" data-paper-url="./papers/250808180v2-reddino-a-foundation-model-for-red-blood-cell-analysis.html" onclick="toggleFavorite(this, '2508.08180v2', 'RedDino: A foundation model for red blood cell analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250807950v1-feat-a-multi-agent-forensic-ai-system-with-domain-adapted-large-lang.html">FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis</a></td>
  <td>æå‡ºFEATç³»ç»Ÿä»¥è§£å†³æ³•åŒ»æ­»äº¡åŸå› åˆ†æä¸­çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.07950v1" data-paper-url="./papers/250807950v1-feat-a-multi-agent-forensic-ai-system-with-domain-adapted-large-lang.html" onclick="toggleFavorite(this, '2508.07950v1', 'FEAT: A Multi-Agent Forensic AI System with Domain-Adapted Large Language Model for Automated Cause-of-Death Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250808529v1-synllm-a-comparative-analysis-of-large-language-models-for-medical-t.html">SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering</a></td>
  <td>æå‡ºSynLLMæ¡†æ¶ä»¥ç”Ÿæˆé«˜è´¨é‡åŒ»ç–—åˆæˆæ•°æ®</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08529v1" data-paper-url="./papers/250808529v1-synllm-a-comparative-analysis-of-large-language-models-for-medical-t.html" onclick="toggleFavorite(this, '2508.08529v1', 'SynLLM: A Comparative Analysis of Large Language Models for Medical Tabular Synthetic Data Generation via Prompt Engineering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250808524v4-streetreaderai-making-street-view-accessible-using-context-aware-mul.html">StreetReaderAI: Making Street View Accessible Using Context-Aware Multimodal AI</a></td>
  <td>æå‡ºStreetReaderAIä»¥è§£å†³ç›²äººç”¨æˆ·æ— æ³•è®¿é—®è¡—æ™¯çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08524v4" data-paper-url="./papers/250808524v4-streetreaderai-making-street-view-accessible-using-context-aware-mul.html" onclick="toggleFavorite(this, '2508.08524v4', 'StreetReaderAI: Making Street View Accessible Using Context-Aware Multimodal AI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250808501v2-gvgai-llm-evaluating-large-language-model-agents-with-infinite-games.html">GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games</a></td>
  <td>æå‡ºGVGAI-LLMä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ— é™æ¸¸æˆä¸­çš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08501v2" data-paper-url="./papers/250808501v2-gvgai-llm-evaluating-large-language-model-agents-with-infinite-games.html" onclick="toggleFavorite(this, '2508.08501v2', 'GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250808500v1-large-language-models-as-oracles-for-ontology-alignment.html">Large Language Models as Oracles for Ontology Alignment</a></td>
  <td>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è§£å†³æœ¬ä½“å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08500v1" data-paper-url="./papers/250808500v1-large-language-models-as-oracles-for-ontology-alignment.html" onclick="toggleFavorite(this, '2508.08500v1', 'Large Language Models as Oracles for Ontology Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250808454v1-temporal-user-profiling-with-llms-balancing-short-term-and-long-term.html">Temporal User Profiling with LLMs: Balancing Short-Term and Long-Term Preferences for Recommendations</a></td>
  <td>æå‡ºLLM-TUPä»¥è§£å†³ç”¨æˆ·åå¥½å»ºæ¨¡ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">TAMP</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08454v1" data-paper-url="./papers/250808454v1-temporal-user-profiling-with-llms-balancing-short-term-and-long-term.html" onclick="toggleFavorite(this, '2508.08454v1', 'Temporal User Profiling with LLMs: Balancing Short-Term and Long-Term Preferences for Recommendations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250808446v1-overfill-two-stage-models-for-efficient-language-model-decoding.html">OverFill: Two-Stage Models for Efficient Language Model Decoding</a></td>
  <td>æå‡ºOverFillä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹è§£ç æ•ˆç‡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08446v1" data-paper-url="./papers/250808446v1-overfill-two-stage-models-for-efficient-language-model-decoding.html" onclick="toggleFavorite(this, '2508.08446v1', 'OverFill: Two-Stage Models for Efficient Language Model Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250808343v3-a-data-driven-ml-approach-for-maximizing-performance-in-llm-adapter-.html">A Data-driven ML Approach for Maximizing Performance in LLM-Adapter Serving</a></td>
  <td>æå‡ºæ•°æ®é©±åŠ¨çš„æœºå™¨å­¦ä¹ æ–¹æ³•ä»¥ä¼˜åŒ–LLMé€‚é…å™¨æœåŠ¡æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08343v3" data-paper-url="./papers/250808343v3-a-data-driven-ml-approach-for-maximizing-performance-in-llm-adapter-.html" onclick="toggleFavorite(this, '2508.08343v3', 'A Data-driven ML Approach for Maximizing Performance in LLM-Adapter Serving')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250807642v2-breaking-down-and-building-up-mixture-of-skill-based-vision-and-lang.html">Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents</a></td>
  <td>æå‡ºSkillNavæ¡†æ¶ä»¥è§£å†³è§†è§‰è¯­è¨€å¯¼èˆªä¸­çš„æŠ€èƒ½æ³›åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VLN</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.07642v2" data-paper-url="./papers/250807642v2-breaking-down-and-building-up-mixture-of-skill-based-vision-and-lang.html" onclick="toggleFavorite(this, '2508.07642v2', 'Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>12</td>
  <td><a href="./papers/250808404v1-generating-query-relevant-document-summaries-via-reinforcement-learn.html">Generating Query-Relevant Document Summaries via Reinforcement Learning</a></td>
  <td>æå‡ºReLSumä»¥è§£å†³ç”µå•†æœç´¢å¼•æ“æ–‡æ¡£æ‘˜è¦ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.08404v1" data-paper-url="./papers/250808404v1-generating-query-relevant-document-summaries-via-reinforcement-learn.html" onclick="toggleFavorite(this, '2508.08404v1', 'Generating Query-Relevant Document Summaries via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250807616v2-thinktuning-instilling-cognitive-reflections-without-distillation.html">ThinkTuning: Instilling Cognitive Reflections without Distillation</a></td>
  <td>æå‡ºThinkTuningä»¥æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.07616v2" data-paper-url="./papers/250807616v2-thinktuning-instilling-cognitive-reflections-without-distillation.html" onclick="toggleFavorite(this, '2508.07616v2', 'ThinkTuning: Instilling Cognitive Reflections without Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)