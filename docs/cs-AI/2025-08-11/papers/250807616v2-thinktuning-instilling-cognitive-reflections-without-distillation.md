---
layout: default
title: ThinkTuning: Instilling Cognitive Reflections without Distillation
---

# ThinkTuning: Instilling Cognitive Reflections without Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07616" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07616v2</a>
  <a href="https://arxiv.org/pdf/2508.07616.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07616v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07616v2', 'ThinkTuning: Instilling Cognitive Reflections without Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aswin RRV, Jacob Dineen, Divij Handa, Md Nayem Uddin, Mihir Parmar, Chitta Baral, Ben Zhou

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-08-21)

**å¤‡æ³¨**: EMNLP 2025 (Main Conference)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/3rdAT/ThinkTuning)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºThinkTuningä»¥æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ€è€ƒå‹æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `æ•™å¸ˆæ¨¡å‹` `å­¦ç”Ÿæ¨¡å‹` `åé¦ˆæœºåˆ¶` `å¼ºåŒ–å­¦ä¹ ` `GRPO` `äº’åŠ¨è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ— æ³•çœŸæ­£èµ‹äºˆæ¨¡å‹æ–°çš„æ¨ç†èƒ½åŠ›ï¼Œä»…èƒ½æŒ–æ˜å·²æœ‰è¡Œä¸ºï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›çš„æå‡å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„ThinkTuningæ–¹æ³•é€šè¿‡æ•™å¸ˆæ¨¡å‹çš„åé¦ˆæ¥æŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»è€Œæå‡å…¶æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒThinkTuningåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¡¨ç°ï¼Œå¹³å‡æé«˜3.85%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œæµ‹è¯•æ—¶æ‰©å±•çš„è¿›å±•ä¿ƒä½¿äº†æ€è€ƒå‹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œè¿™äº›æ¨¡å‹å±•ç°äº†è‡ªæˆ‘åæ€è¡Œä¸ºå’Œå¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚å°½ç®¡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¨åŠ¨äº†è¿™ä¸€è‡ªæˆ‘æ”¹è¿›çš„èŒƒå¼ï¼Œä½†ç ”ç©¶è¡¨æ˜ï¼ŒRLå¹¶æœªçœŸæ­£èµ‹äºˆæ¨¡å‹æ–°çš„æ¨ç†èƒ½åŠ›ï¼Œè€Œæ˜¯ä»…ä»…æŒ–æ˜äº†åŸºç¡€æ¨¡å‹ä¸­å·²æœ‰çš„è¡Œä¸ºã€‚å› æ­¤ï¼Œå¦‚ä½•è®­ç»ƒé‚£äº›ä¸å…·å¤‡æ€è€ƒè¡Œä¸ºçš„æ¨¡å‹ä»¥å‘å±•è¿™ç§èƒ½åŠ›æˆä¸ºä¸€ä¸ªé‡è¦é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ThinkTuningï¼Œä¸€ç§åŸºäºGRPOçš„äº’åŠ¨è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡æ•™å¸ˆæ¨¡å‹çš„æŒ‡å¯¼å¢å¼ºå­¦ç”Ÿæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡äº†3.85%çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨MATH-500ã€AIMEå’ŒGPQA-Diamondä¸Šåˆ†åˆ«æå‡äº†2.08%ã€2.23%å’Œ3.99%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•è®­ç»ƒä¸å…·å¤‡æ€è€ƒè¡Œä¸ºçš„æ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿå‘å±•å‡ºè‡ªæˆ‘åæ€å’Œå¤šæ­¥æ¨ç†èƒ½åŠ›ã€‚ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•æœªèƒ½æœ‰æ•ˆå®ç°è¿™ä¸€ç›®æ ‡ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›æå‡æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šThinkTuningæ–¹æ³•å€Ÿé‰´è¯¾å ‚æ•™å­¦ä¸­çš„åé¦ˆæœºåˆ¶ï¼Œé€šè¿‡æ•™å¸ˆæ¨¡å‹çš„æŒ‡å¯¼ï¼Œå¸®åŠ©å­¦ç”Ÿæ¨¡å‹åœ¨å°è¯•è§£ç­”åè·å¾—çº æ­£åé¦ˆï¼Œä»è€Œå¼•å¯¼å…¶æ€è€ƒå¹¶æ‰¾åˆ°æ­£ç¡®ç­”æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ä¸¤ä¸ªä¸»è¦æ¨¡å—ã€‚æ•™å¸ˆæ¨¡å‹è´Ÿè´£æä¾›é—®é¢˜å’Œåé¦ˆï¼Œè€Œå­¦ç”Ÿæ¨¡å‹åˆ™åœ¨æ•™å¸ˆçš„æŒ‡å¯¼ä¸‹è¿›è¡Œå°è¯•å’Œå­¦ä¹ ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ•™å¸ˆæ¨¡å‹ä¸å­¦ç”Ÿæ¨¡å‹çš„äº¤äº’ä¸æ–­è¿›è¡Œï¼Œä»¥å¢å¼ºå­¦ç”Ÿæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šThinkTuningçš„åˆ›æ–°åœ¨äºé€šè¿‡åŒç­‰è§„æ¨¡çš„æ•™å¸ˆæ¨¡å‹æä¾›éšæ€§ç›‘ç£ï¼Œæ˜¾è‘—æ”¹å–„å­¦ç”Ÿæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œå¼ºè°ƒäº†åé¦ˆåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒThinkTuningé‡‡ç”¨äº†GRPOæ¡†æ¶ï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡æ•™å¸ˆåé¦ˆä¸å­¦ç”Ÿæ¨¡å‹çš„è‡ªä¸»å­¦ä¹ ï¼Œç¡®ä¿åé¦ˆèƒ½å¤Ÿæœ‰æ•ˆå¼•å¯¼å­¦ç”Ÿæ¨¡å‹çš„æ€è€ƒè¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒThinkTuningåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹³å‡æå‡äº†3.85%çš„æ€§èƒ½ã€‚åœ¨MATH-500ã€AIMEå’ŒGPQA-Diamondä¸Šï¼Œåˆ†åˆ«å®ç°äº†2.08%ã€2.23%å’Œ3.99%çš„æå‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„vanilla-GRPOåŸºçº¿ï¼Œå±•ç°äº†æ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒThinkTuningå¯ä»¥å¸®åŠ©å¼€å‘æ›´æ™ºèƒ½çš„å­¦ä¹ å·¥å…·ï¼Œä¿ƒè¿›ä¸ªæ€§åŒ–å­¦ä¹ å’Œè‡ªä¸»å­¦ä¹ çš„å®ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in test-time scaling have led to the emergence of thinking LLMs that exhibit self-reflective behaviors and multi-step reasoning. While RL drives this self-improvement paradigm, a recent study (Gandhi et al., 2025) shows that RL alone does not truly instill these new reasoning abilities - it merely draws out behaviors already present in the base models. This raises a question: How can we train the models that don't exhibit such thinking behavior to develop it in the first place? To this end, we propose ThinkTuning, a GRPO-based interactive training approach where we augment the rollouts of a student model with the guidance from a teacher model. A simple idea from classroom practice inspires our method: a teacher poses a problem, lets the student try an answer, then gives corrective feedback -- enough to point the mind in the right direction and then show the solution. Each piece of feedback reshapes the student's thoughts, leading them to arrive at the correct solution. Similarly, we find that this type of implicit supervision through feedback from a teacher model of the same size improves the reasoning capabilities of the student model. In particular, on average, our method shows a 3.85% improvement over zero-shot baselines across benchmarks, and on MATH-500, AIME and GPQA-Diamond it shows 2.08%, 2.23% and 3.99% improvements over the vanilla-GRPO baseline. Source code is available at https://github.com/3rdAT/ThinkTuning.

