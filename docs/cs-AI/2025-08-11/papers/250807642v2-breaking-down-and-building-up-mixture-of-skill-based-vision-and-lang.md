---
layout: default
title: Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents
---

# Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07642" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07642v2</a>
  <a href="https://arxiv.org/pdf/2508.07642.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07642v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07642v2', 'Breaking Down and Building Up: Mixture of Skill-Based Vision-and-Language Navigation Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianyi Ma, Yue Zhang, Zehao Wang, Parisa Kordjamshidi

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-10-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSkillNavæ¡†æ¶ä»¥è§£å†³è§†è§‰è¯­è¨€å¯¼èˆªä¸­çš„æŠ€èƒ½æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€å¯¼èˆª` `æŠ€èƒ½å­¦ä¹ ` `æ¨¡å—åŒ–æ¡†æ¶` `åˆæˆæ•°æ®é›†` `åŠ¨æ€è·¯ç”±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€å¯¼èˆªæ–¹æ³•åœ¨å¤æ‚ç©ºé—´å’Œæ—¶é—´æ¨ç†æ—¶ï¼Œéš¾ä»¥åœ¨æœªè§åœºæ™¯ä¸­æœ‰æ•ˆæ³›åŒ–ï¼Œè¡¨ç°å‡ºæ˜æ˜¾çš„å±€é™æ€§ã€‚
2. æœ¬æ–‡æå‡ºSkillNavæ¡†æ¶ï¼Œé€šè¿‡å°†å¯¼èˆªä»»åŠ¡åˆ†è§£ä¸ºå¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼Œæå‡äº†åŸºäºæŠ€èƒ½çš„æ¨ç†èƒ½åŠ›ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. SkillNavåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨GSA-R2RåŸºå‡†ä¸Šï¼Œå±•ç¤ºäº†å¯¹æ–°æŒ‡ä»¤é£æ ¼å’Œæœªè§ç¯å¢ƒçš„å¼ºå¤§é€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰è¯­è¨€å¯¼èˆªï¼ˆVLNï¼‰é¢ä¸´ç€ç†è§£è‡ªç„¶è¯­è¨€æŒ‡ä»¤å’Œåœ¨å¤æ‚3Dç¯å¢ƒä¸­å¯¼èˆªçš„é‡å¤§æŒ‘æˆ˜ã€‚å°½ç®¡è¿‘æœŸé€šè¿‡å¤§è§„æ¨¡é¢„è®­ç»ƒå’Œæ•°æ®å¢å¼ºå–å¾—äº†ä¸€å®šè¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹å¤æ‚çš„ç©ºé—´å’Œæ—¶é—´æ¨ç†æ—¶ï¼Œä»ç„¶éš¾ä»¥åœ¨æœªè§åœºæ™¯ä¸­è¿›è¡Œæœ‰æ•ˆæ³›åŒ–ã€‚æœ¬æ–‡æå‡ºäº†SkillNavï¼Œä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå°†ç»“æ„åŒ–çš„åŸºäºæŠ€èƒ½çš„æ¨ç†å¼•å…¥åˆ°åŸºäºTransformerçš„VLNä»£ç†ä¸­ã€‚è¯¥æ–¹æ³•å°†å¯¼èˆªåˆ†è§£ä¸ºä¸€ç»„å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼ˆå¦‚å‚ç›´ç§»åŠ¨ã€åŒºåŸŸè¯†åˆ«ã€åœæ­¢ä¸æš‚åœï¼‰ï¼Œæ¯é¡¹æŠ€èƒ½ç”±ä¸“é—¨çš„ä»£ç†å¤„ç†ã€‚ä¸ºäº†æ”¯æŒæœ‰é’ˆå¯¹æ€§çš„æŠ€èƒ½è®­ç»ƒè€Œæ— éœ€æ‰‹åŠ¨æ•°æ®æ ‡æ³¨ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåˆæˆæ•°æ®é›†ç®¡é“ï¼Œç”Ÿæˆå¤šæ ·åŒ–ã€è¯­è¨€è‡ªç„¶çš„æŠ€èƒ½ç‰¹å®šæŒ‡ä»¤-è½¨è¿¹å¯¹ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„æ— è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰è·¯ç”±å™¨ï¼Œèƒ½å¤Ÿåœ¨æ¯ä¸ªæ—¶é—´æ­¥åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†ï¼Œé€šè¿‡å¯¹é½å­ç›®æ ‡ä¸è§†è§‰è§‚å¯Ÿå’Œå†å²åŠ¨ä½œæ¥å®ç°ã€‚SkillNavåœ¨å¸¸ç”¨åŸºå‡†ä¸Šå–å¾—äº†ç«äº‰æ€§ç»“æœï¼Œå¹¶åœ¨GSA-R2RåŸºå‡†ä¸Šå»ºç«‹äº†æœ€å…ˆè¿›çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯¥åŸºå‡†å…·æœ‰æ–°é¢–çš„æŒ‡ä»¤é£æ ¼å’Œæœªè§ç¯å¢ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€å¯¼èˆªä¸­ä»£ç†åœ¨å¤æ‚åœºæ™¯ä¸‹çš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æœªè§åœºæ™¯æ—¶ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå¤æ‚ç©ºé—´å’Œæ—¶é—´æ¨ç†æ—¶ï¼Œè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSkillNavæ¡†æ¶é€šè¿‡å°†å¯¼èˆªä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯è§£é‡Šçš„åŸå­æŠ€èƒ½ï¼Œå…è®¸æ¯ä¸ªæŠ€èƒ½ç”±ä¸“é—¨çš„ä»£ç†å¤„ç†ï¼Œä»è€Œå®ç°æ›´é«˜æ•ˆçš„æŠ€èƒ½è®­ç»ƒå’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSkillNavçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯æŠ€èƒ½åˆ†è§£æ¨¡å—ï¼Œå°†å¯¼èˆªä»»åŠ¡åˆ†è§£ä¸ºåŸå­æŠ€èƒ½ï¼›å…¶æ¬¡æ˜¯åˆæˆæ•°æ®é›†ç”Ÿæˆæ¨¡å—ï¼Œè‡ªåŠ¨ç”ŸæˆæŠ€èƒ½ç‰¹å®šçš„æŒ‡ä»¤-è½¨è¿¹å¯¹ï¼›æœ€åæ˜¯VLMè·¯ç”±å™¨ï¼Œæ ¹æ®å½“å‰çŠ¶æ€åŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„ä»£ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†æ— è®­ç»ƒçš„VLMè·¯ç”±å™¨ï¼Œå®ƒèƒ½å¤Ÿåœ¨æ¯ä¸ªæ—¶é—´æ­¥æ ¹æ®è§†è§‰è§‚å¯Ÿå’Œå†å²åŠ¨ä½œåŠ¨æ€é€‰æ‹©ä»£ç†ï¼Œè¿™ä¸€è®¾è®¡æ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æŠ€èƒ½å­¦ä¹ æ•ˆæœï¼ŒåŒæ—¶é€šè¿‡åˆæˆæ•°æ®é›†çš„æ„å»ºï¼Œç¡®ä¿äº†è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’Œè‡ªç„¶æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒSkillNavåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ç«äº‰æ€§ç»“æœï¼Œå°¤å…¶åœ¨GSA-R2RåŸºå‡†ä¸Šï¼Œå±•ç¤ºäº†å¯¹æ–°æŒ‡ä»¤é£æ ¼å’Œæœªè§ç¯å¢ƒçš„æœ€å…ˆè¿›æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœºå™¨äººå¯¼èˆªå’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æœºå™¨åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å¯¼èˆªèƒ½åŠ›ã€‚æœªæ¥ï¼ŒSkillNavæ¡†æ¶æœ‰æœ›æ¨åŠ¨æ›´é«˜çº§çš„å¤šæ¨¡æ€äº¤äº’ç³»ç»Ÿçš„å‘å±•ï¼Œä½¿å¾—äººæœºåä½œæ›´åŠ é«˜æ•ˆå’Œè‡ªç„¶ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision-and-Language Navigation (VLN) poses significant challenges for agents to interpret natural language instructions and navigate complex 3D environments. While recent progress has been driven by large-scale pre-training and data augmentation, current methods still struggle to generalize to unseen scenarios, particularly when complex spatial and temporal reasoning is required. In this work, we propose SkillNav, a modular framework that introduces structured, skill-based reasoning into Transformer-based VLN agents. Our method decomposes navigation into a set of interpretable atomic skills (e.g., Vertical Movement, Area and Region Identification, Stop and Pause), each handled by a specialized agent. To support targeted skill training without manual data annotation, we construct a synthetic dataset pipeline that generates diverse, linguistically natural, skill-specific instruction-trajectory pairs. We then introduce a novel training-free Vision-Language Model (VLM)-based router, which dynamically selects the most suitable agent at each time step by aligning sub-goals with visual observations and historical actions. SkillNav obtains competitive results on commonly used benchmarks and establishes state-of-the-art generalization to the GSA-R2R, a benchmark with novel instruction styles and unseen environments.

