---
layout: default
title: GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games
---

# GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08501" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08501v2</a>
  <a href="https://arxiv.org/pdf/2508.08501.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08501v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08501v2', 'GVGAI-LLM: Evaluating Large Language Model Agents with Infinite Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuchen Li, Cong Lin, Muhammad Umair Nasir, Philip Bontrager, Jialin Liu, Julian Togelius

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-11-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGVGAI-LLMä»¥è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨æ— é™æ¸¸æˆä¸­çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è§†é¢‘æ¸¸æˆåŸºå‡†` `æ¨ç†èƒ½åŠ›` `é—®é¢˜è§£å†³` `ç©ºé—´æ¨ç†` `æ¸¸æˆæè¿°è¯­è¨€` `è¯„ä¼°æŒ‡æ ‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç©ºé—´æ¨ç†å’ŒåŸºæœ¬è§„åˆ’æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†å¤æ‚çš„æ¸¸æˆä»»åŠ¡ã€‚
2. GVGAI-LLMåŸºäºé€šç”¨è§†é¢‘æ¸¸æˆAIæ¡†æ¶ï¼Œè®¾è®¡äº†ä¸€ç³»åˆ—å¤šæ ·åŒ–çš„è¡—æœºæ¸¸æˆï¼Œä»¥æµ‹è¯•æ¨¡å‹çš„æ¨ç†å’Œé—®é¢˜è§£å†³èƒ½åŠ›ã€‚
3. é€šè¿‡é›¶-shotè¯„ä¼°ï¼Œå‘ç°å½“å‰æ¨¡å‹åœ¨å¤šç§æ¸¸æˆä¸­å­˜åœ¨ç©ºé—´å’Œé€»è¾‘é”™è¯¯ï¼Œæ¨åŠ¨äº†å¯¹ç»“æ„åŒ–æç¤ºå’Œç©ºé—´åŸºç¡€æŠ€æœ¯çš„æ¢ç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†GVGAI-LLMï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†å’Œé—®é¢˜è§£å†³èƒ½åŠ›çš„è§†é¢‘æ¸¸æˆåŸºå‡†ã€‚è¯¥åŸºå‡†å»ºç«‹åœ¨é€šç”¨è§†é¢‘æ¸¸æˆAIæ¡†æ¶ä¸Šï¼ŒåŒ…å«å¤šç§è¡—æœºé£æ ¼çš„æ¸¸æˆï¼Œæ—¨åœ¨æµ‹è¯•æ¨¡å‹å¤„ç†ä¸ç°æœ‰LLMåŸºå‡†ä¸åŒçš„ä»»åŠ¡çš„èƒ½åŠ›ã€‚åŸºå‡†åˆ©ç”¨æ¸¸æˆæè¿°è¯­è¨€å¿«é€Ÿåˆ›å»ºæ–°æ¸¸æˆå’Œå…³å¡ï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆã€‚æ¯ä¸ªæ¸¸æˆåœºæ™¯é€šè¿‡ç´§å‡‘çš„ASCIIå­—ç¬¦é›†è¡¨ç¤ºï¼Œä¾¿äºè¯­è¨€æ¨¡å‹é«˜æ•ˆå¤„ç†ã€‚GVGAI-LLMå®šä¹‰äº†å¯è§£é‡Šçš„è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æœ‰æ„ä¹‰çš„æ­¥éª¤æ¯”ä¾‹ã€æ­¥éª¤æ•ˆç‡å’Œæ•´ä½“å¾—åˆ†ï¼Œä»¥è¯„ä¼°æ¨¡å‹è¡Œä¸ºã€‚é€šè¿‡åœ¨å¤šæ ·åŒ–æŒ‘æˆ˜å’ŒæŠ€èƒ½æ·±åº¦çš„å¹¿æ³›æ¸¸æˆå’Œå…³å¡ä¸Šè¿›è¡Œé›¶-shotè¯„ä¼°ï¼Œæˆ‘ä»¬æ­ç¤ºäº†LLMsåœ¨ç©ºé—´æ¨ç†å’ŒåŸºæœ¬è§„åˆ’æ–¹é¢çš„æŒç»­å±€é™æ€§ã€‚å½“å‰æ¨¡å‹åœ¨ç©ºé—´å’Œé€»è¾‘ä¸Šè¡¨ç°å‡ºä¸€è‡´çš„é”™è¯¯ï¼Œä¿ƒä½¿æˆ‘ä»¬æ¢ç´¢ç»“æ„åŒ–æç¤ºå’Œç©ºé—´åŸºç¡€æŠ€æœ¯ã€‚å°½ç®¡è¿™äº›å¹²é¢„æªæ–½å¸¦æ¥äº†éƒ¨åˆ†æ”¹è¿›ï¼Œä½†åŸºå‡†ä»ç„¶è¿œæœªè§£å†³ã€‚GVGAI-LLMä¸ºæ¨è¿›è¯­è¨€æ¨¡å‹èƒ½åŠ›ç ”ç©¶æä¾›äº†å¯é‡å¤çš„æµ‹è¯•å¹³å°ï¼Œç‰¹åˆ«å¼ºè°ƒä»£ç†è¡Œä¸ºå’Œä¸Šä¸‹æ–‡æ¨ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¸¸æˆä»»åŠ¡ä¸­çš„æ¨ç†å’Œé—®é¢˜è§£å†³èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•æœ‰æ•ˆè¯„ä¼°æ¨¡å‹åœ¨ç©ºé—´æ¨ç†å’Œè§„åˆ’æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºGVGAI-LLMåŸºå‡†ï¼Œé€šè¿‡è®¾è®¡å¤šæ ·åŒ–çš„è¡—æœºæ¸¸æˆï¼Œåˆ©ç”¨æ¸¸æˆæè¿°è¯­è¨€å¿«é€Ÿåˆ›å»ºæ–°å…³å¡ï¼Œä»è€Œæœ‰æ•ˆæµ‹è¯•å’Œè¯„ä¼°LLMsçš„èƒ½åŠ›ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ¸¸æˆç”Ÿæˆæ¨¡å—ã€è¯„ä¼°æŒ‡æ ‡æ¨¡å—å’Œæ¨¡å‹è¯„ä¼°æ¨¡å—ã€‚æ¸¸æˆç”Ÿæˆæ¨¡å—ä½¿ç”¨æ¸¸æˆæè¿°è¯­è¨€åˆ›å»ºæ–°æ¸¸æˆï¼Œè¯„ä¼°æŒ‡æ ‡æ¨¡å—å®šä¹‰äº†æœ‰æ„ä¹‰çš„è¯„ä¼°æ ‡å‡†ï¼Œæ¨¡å‹è¯„ä¼°æ¨¡å—è´Ÿè´£æ‰§è¡Œé›¶-shotè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†æ¸¸æˆæè¿°è¯­è¨€å’Œå¯è§£é‡Šçš„è¯„ä¼°æŒ‡æ ‡ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤šæ ·åŒ–çš„æ¸¸æˆç¯å¢ƒä¸­è¿›è¡Œæœ‰æ•ˆè¯„ä¼°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…¨é¢çš„èƒ½åŠ›æµ‹è¯•ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ä½¿ç”¨ASCIIå­—ç¬¦é›†è¡¨ç¤ºæ¸¸æˆåœºæ™¯ï¼Œä»¥æé«˜å¤„ç†æ•ˆç‡ï¼›å®šä¹‰æœ‰æ„ä¹‰çš„æ­¥éª¤æ¯”ä¾‹å’Œæ­¥éª¤æ•ˆç‡ç­‰è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆ†ææ¨¡å‹è¡Œä¸ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šç§æ¸¸æˆä¸­æ™®éå­˜åœ¨ç©ºé—´å’Œé€»è¾‘é”™è¯¯ï¼Œå°¤å…¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚å°½ç®¡å¼•å…¥ç»“æ„åŒ–æç¤ºå’Œç©ºé—´åŸºç¡€æŠ€æœ¯æœ‰æ‰€æ”¹å–„ï¼Œä½†æ•´ä½“æ€§èƒ½ä»è¿œæœªè¾¾åˆ°ç†æƒ³æ°´å¹³ï¼Œè¡¨æ˜è¯¥åŸºå‡†ä»æœ‰å¾…æ·±å…¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¸¸æˆAIã€æ•™è‚²å’Œè®­ç»ƒæ¨¡æ‹Ÿç­‰ã€‚é€šè¿‡è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ŒGVGAI-LLMå¯ä»¥ä¸ºå¼€å‘æ›´æ™ºèƒ½çš„AIä»£ç†æä¾›é‡è¦å‚è€ƒï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce GVGAI-LLM, a video game benchmark for evaluating the reasoning and problem-solving capabilities of large language models (LLMs). Built on the General Video Game AI framework, it features a diverse collection of arcade-style games designed to test a model's ability to handle tasks that differ from most existing LLM benchmarks. The benchmark leverages a game description language that enables rapid creation of new games and levels, helping to prevent overfitting over time. Each game scene is represented by a compact set of ASCII characters, allowing for efficient processing by language models. GVGAI-LLM defines interpretable metrics, including the meaningful step ratio, step efficiency, and overall score, to assess model behavior. Through zero-shot evaluations across a broad set of games and levels with diverse challenges and skill depth, we reveal persistent limitations of LLMs in spatial reasoning and basic planning. Current models consistently exhibit spatial and logical errors, motivating structured prompting and spatial grounding techniques. While these interventions lead to partial improvements, the benchmark remains very far from solved. GVGAI-LLM provides a reproducible testbed for advancing research on language model capabilities, with a particular emphasis on agentic behavior and contextual reasoning.

