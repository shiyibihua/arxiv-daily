---
layout: default
title: Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization
---

# Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.24609" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.24609v1</a>
  <a href="https://arxiv.org/pdf/2512.24609.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.24609v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.24609v1', 'Reinforcement Learning-Augmented LLM Agents for Collaborative Decision Making and Performance Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dong Qiu, Duo Xu, Limengxi Yue

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-31

**å¤‡æ³¨**: Accepted by IEEE ICFTIC 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¼ºåŒ–å­¦ä¹ å¢å¼ºçš„LLMæ™ºèƒ½ä½“æ¡†æ¶ï¼Œä¼˜åŒ–ååŒå†³ç­–ä¸æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“åä½œ` `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `Dec-POMDP` `CTDE` `ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `ååŒå†™ä½œ` `ä»£ç ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å¤šæ™ºèƒ½ä½“åä½œä¸­ç¼ºä¹å…¨å±€ä¼˜åŒ–èƒ½åŠ›ï¼Œéš¾ä»¥å…¼é¡¾ä»»åŠ¡è´¨é‡ã€é€Ÿåº¦å’Œåè°ƒæˆæœ¬ã€‚
2. è®ºæ–‡æå‡ºå¼ºåŒ–å­¦ä¹ å¢å¼ºçš„LLMæ™ºèƒ½ä½“æ¡†æ¶ï¼Œåˆ©ç”¨é›†ä¸­å¼è®­ç»ƒåˆ†æ•£å¼æ‰§è¡Œ(CTDE)ä¼˜åŒ–åä½œç­–ç•¥ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å†™ä½œå’Œç¼–ç ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†ä»»åŠ¡é€Ÿåº¦ã€ä¸€è‡´æ€§å’Œæµ‹è¯•é€šè¿‡ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­è¨€ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†é€šå¸¸ç¼ºä¹åä½œæ„è¯†ï¼Œéš¾ä»¥ä¼˜åŒ–å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„å…¨å±€æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¼ºåŒ–å­¦ä¹ å¢å¼ºçš„LLMæ™ºèƒ½ä½“æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†åä½œå»ºæ¨¡ä¸ºå»ä¸­å¿ƒåŒ–éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Dec-POMDP)ï¼Œå¹¶é‡‡ç”¨é›†ä¸­å¼è®­ç»ƒå’Œåˆ†æ•£å¼æ‰§è¡Œ(CTDE)ã€‚æˆ‘ä»¬å¼•å…¥äº†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ï¼Œä»¥åœ¨è®­ç»ƒæœŸé—´åˆ©ç”¨å…¨å±€ä¿¡å·è”åˆä¼˜åŒ–æ™ºèƒ½ä½“ç­–ç•¥ï¼Œå¹¶é‡‡ç”¨ç®€åŒ–çš„è”åˆå¥–åŠ±æ¥å¹³è¡¡ä»»åŠ¡è´¨é‡ã€é€Ÿåº¦å’Œåè°ƒæˆæœ¬ã€‚åœ¨åä½œå†™ä½œå’Œç¼–ç åŸºå‡†æµ‹è¯•ä¸­ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æ¯”å•æ™ºèƒ½ä½“åŸºçº¿æé«˜äº†3å€çš„ä»»åŠ¡å¤„ç†é€Ÿåº¦ï¼Œå†™ä½œç»“æ„/é£æ ¼ä¸€è‡´æ€§è¾¾åˆ°98.7%ï¼Œç¼–ç æµ‹è¯•é€šè¿‡ç‡è¾¾åˆ°74.6%ã€‚è¯¥æ–¹æ³•å§‹ç»ˆä¼˜äºå¼ºå¤§çš„å¤šæ™ºèƒ½ä½“LLMåŸºçº¿ï¼Œå¹¶ä¸ºå¤æ‚å·¥ä½œæµç¨‹ä¸­çš„å¯é åä½œæä¾›äº†ä¸€æ¡å®ç”¨é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯ä¸‹ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹(LLM)éš¾ä»¥æœ‰æ•ˆåä½œå¹¶ä¼˜åŒ–å…¨å±€æ€§èƒ½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ç›´æ¥ä½¿ç”¨LLMè¿›è¡Œå¤šæ™ºèƒ½ä½“åä½œï¼Œå¾€å¾€ç¼ºä¹å¯¹å…¨å±€ä¿¡æ¯çš„åˆ©ç”¨ï¼Œå¯¼è‡´åä½œæ•ˆç‡ä½ä¸‹ã€ä»»åŠ¡è´¨é‡éš¾ä»¥ä¿è¯ï¼Œå¹¶ä¸”éš¾ä»¥å¹³è¡¡ä»»åŠ¡é€Ÿåº¦ã€è´¨é‡å’Œåè°ƒæˆæœ¬ç­‰å¤šä¸ªç›®æ ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤šæ™ºèƒ½ä½“åä½œé—®é¢˜å»ºæ¨¡ä¸ºå»ä¸­å¿ƒåŒ–éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Dec-POMDP)ï¼Œå¹¶åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡é›†ä¸­å¼è®­ç»ƒåˆ†æ•£å¼æ‰§è¡Œ(CTDE)çš„æ¡†æ¶ï¼Œæ™ºèƒ½ä½“å¯ä»¥åœ¨è®­ç»ƒé˜¶æ®µåˆ©ç”¨å…¨å±€ä¿¡æ¯è¿›è¡Œå­¦ä¹ ï¼Œè€Œåœ¨æ‰§è¡Œé˜¶æ®µåˆ™ç‹¬ç«‹è¡ŒåŠ¨ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„åä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) LLMæ™ºèƒ½ä½“ï¼šæ¯ä¸ªæ™ºèƒ½ä½“ç”±ä¸€ä¸ªLLMé©±åŠ¨ï¼Œè´Ÿè´£ç”ŸæˆåŠ¨ä½œã€‚2) å¼ºåŒ–å­¦ä¹ æ¨¡å—ï¼šä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¼˜åŒ–LLMæ™ºèƒ½ä½“çš„ç­–ç•¥ã€‚3) é›†ä¸­å¼è®­ç»ƒæ¨¡å—ï¼šåœ¨è®­ç»ƒé˜¶æ®µï¼Œæ‰€æœ‰æ™ºèƒ½ä½“å…±äº«å…¨å±€ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ç®—æ³•è¿›è¡Œè”åˆä¼˜åŒ–ã€‚4) åˆ†æ•£å¼æ‰§è¡Œæ¨¡å—ï¼šåœ¨æ‰§è¡Œé˜¶æ®µï¼Œæ¯ä¸ªæ™ºèƒ½ä½“ç‹¬ç«‹è¡ŒåŠ¨ï¼Œæ ¹æ®è‡ªèº«è§‚æµ‹å’Œå­¦ä¹ åˆ°çš„ç­–ç•¥ç”ŸæˆåŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)ç®—æ³•ã€‚GRPOå…è®¸æ™ºèƒ½ä½“åœ¨è®­ç»ƒæœŸé—´è®¿é—®å…¨å±€ä¿¡å·ï¼Œä»è€Œæ›´å¥½åœ°å­¦ä¹ åä½œç­–ç•¥ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†ä¸€ä¸ªç®€åŒ–çš„è”åˆå¥–åŠ±å‡½æ•°ï¼Œç”¨äºå¹³è¡¡ä»»åŠ¡è´¨é‡ã€é€Ÿåº¦å’Œåè°ƒæˆæœ¬ï¼Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´å¥½åœ°ä¼˜åŒ–å…¨å±€æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šGRPOç®—æ³•é€šè¿‡å¼•å…¥ä¸€ä¸ªç»„ç›¸å¯¹ä»·å€¼å‡½æ•°æ¥æŒ‡å¯¼æ™ºèƒ½ä½“çš„ç­–ç•¥æ›´æ–°ã€‚è¯¥ä»·å€¼å‡½æ•°è€ƒè™‘äº†æ‰€æœ‰æ™ºèƒ½ä½“çš„è”åˆè¡ŒåŠ¨å¯¹å…¨å±€å¥–åŠ±çš„å½±å“ï¼Œä»è€Œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åä½œçš„é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œç®€åŒ–çš„è”åˆå¥–åŠ±å‡½æ•°è¢«è®¾è®¡ä¸ºä»»åŠ¡è´¨é‡ã€é€Ÿåº¦å’Œåè°ƒæˆæœ¬çš„åŠ æƒå’Œï¼Œæƒé‡å‚æ•°å¯ä»¥æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨åä½œå†™ä½œå’Œç¼–ç åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚åœ¨å†™ä½œä»»åŠ¡ä¸­ï¼Œä»»åŠ¡å¤„ç†é€Ÿåº¦æé«˜äº†3å€ï¼Œç»“æ„/é£æ ¼ä¸€è‡´æ€§è¾¾åˆ°98.7%ã€‚åœ¨ç¼–ç ä»»åŠ¡ä¸­ï¼Œæµ‹è¯•é€šè¿‡ç‡è¾¾åˆ°74.6%ã€‚è¯¥æ–¹æ³•å§‹ç»ˆä¼˜äºå¼ºå¤§çš„å¤šæ™ºèƒ½ä½“LLMåŸºçº¿ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§å¤šæ™ºèƒ½ä½“åä½œåœºæ™¯ï¼Œä¾‹å¦‚ï¼šååŒå†™ä½œã€ä»£ç ç”Ÿæˆã€æœºå™¨äººåä½œã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºLLMæ™ºèƒ½ä½“çš„åä½œèƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å·¥ä½œæ•ˆç‡ã€é™ä½æˆæœ¬ï¼Œå¹¶å®ç°æ›´æ™ºèƒ½åŒ–çš„è‡ªåŠ¨åŒ–æµç¨‹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„ä»»åŠ¡å’Œæ›´å¤§è§„æ¨¡çš„æ™ºèƒ½ä½“ç¾¤ä½“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.

