---
layout: default
title: ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents
---

# ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14040" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14040v2</a>
  <a href="https://arxiv.org/pdf/2508.14040.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14040v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14040v2', 'ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanyu Lai, Xiao Liu, Yanxiao Zhao, Han Xu, Hanchen Zhang, Bohao Jing, Yanyu Ren, Shuntian Yao, Yuxiao Dong, Jie Tang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-10-21)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/thudm/ComputerRL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºComputerRLä»¥è§£å†³æ¡Œé¢æ™ºèƒ½ä»£ç†çš„è®­ç»ƒæ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æ¡Œé¢æ™ºèƒ½` `å¼ºåŒ–å­¦ä¹ ` `åˆ†å¸ƒå¼è®­ç»ƒ` `API-GUIäº¤äº’` `Entropulseç­–ç•¥` `è‡ªåŠ¨åŒ–` `äººæœºäº¤äº’`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¡Œé¢æ™ºèƒ½ä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œæ•ˆç‡ä½ä¸‹ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚
2. è®ºæ–‡æå‡ºäº†ComputerRLæ¡†æ¶ï¼Œç»“åˆAPI-GUIèŒƒå¼å’Œåˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½ï¼Œæå‡è®­ç»ƒçš„å¯æ‰©å±•æ€§å’Œç¨³å¥æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒAutoGLM-OS-9Båœ¨OSWorldåŸºå‡†ä¸Šè¾¾åˆ°äº†48.9%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†ComputerRLï¼Œä¸€ä¸ªç”¨äºè‡ªä¸»æ¡Œé¢æ™ºèƒ½çš„æ¡†æ¶ï¼Œä½¿ä»£ç†èƒ½å¤Ÿç†Ÿç»ƒæ“ä½œå¤æ‚çš„æ•°å­—å·¥ä½œç©ºé—´ã€‚ComputerRLé‡‡ç”¨API-GUIèŒƒå¼ï¼Œç»Ÿä¸€äº†ç¨‹åºåŒ–APIè°ƒç”¨å’Œç›´æ¥GUIäº¤äº’ï¼Œä»¥è§£å†³æœºå™¨ä»£ç†ä¸äººç±»ä¸­å¿ƒæ¡Œé¢ç¯å¢ƒä¹‹é—´çš„å›ºæœ‰ä¸åŒ¹é…ã€‚ä¸ºæ”¯æŒå¯æ‰©å±•å’Œç¨³å¥çš„è®­ç»ƒï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªåˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½ï¼Œèƒ½å¤Ÿåè°ƒæ•°åƒä¸ªå¹¶è¡Œè™šæ‹Ÿæ¡Œé¢ç¯å¢ƒï¼ŒåŠ é€Ÿå¤§è§„æ¨¡åœ¨çº¿å¼ºåŒ–å­¦ä¹ ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†Entropulseè®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡äº¤æ›¿è¿›è¡Œå¼ºåŒ–å­¦ä¹ å’Œç›‘ç£å¾®è°ƒï¼Œæœ‰æ•ˆç¼“è§£äº†åœ¨é•¿æ—¶é—´è®­ç»ƒä¸­å‡ºç°çš„ç†µå´©æºƒã€‚æˆ‘ä»¬åœ¨å¼€æ”¾æ¨¡å‹GLM-4-9B-0414å’ŒGLM-4.1V-9B-Thinkingä¸Šåº”ç”¨ComputerRLï¼Œå¹¶åœ¨OSWorldåŸºå‡†ä¸Šè¿›è¡Œè¯„ä¼°ã€‚AutoGLM-OS-9Bè¾¾åˆ°äº†48.9%çš„æ–°çŠ¶æ€-of-the-artå‡†ç¡®ç‡ï¼Œæ˜¾è‘—æå‡äº†æ¡Œé¢è‡ªåŠ¨åŒ–ä¸­çš„é€šç”¨ä»£ç†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æ¡Œé¢æ™ºèƒ½ä»£ç†åœ¨å¤æ‚æ•°å­—å·¥ä½œç©ºé—´ä¸­è¿›è¡Œé«˜æ•ˆåœ¨çº¿å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¯å¢ƒæ•ˆç‡å’Œè®­ç»ƒç¨³å®šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆæœä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥API-GUIèŒƒå¼ï¼Œç»Ÿä¸€ç¨‹åºåŒ–APIè°ƒç”¨ä¸GUIäº¤äº’ï¼Œè§£å†³æœºå™¨ä»£ç†ä¸äººç±»ç”¨æˆ·ä¹‹é—´çš„äº¤äº’ä¸åŒ¹é…é—®é¢˜ã€‚åŒæ—¶ï¼Œå¼€å‘åˆ†å¸ƒå¼å¼ºåŒ–å­¦ä¹ åŸºç¡€è®¾æ–½ä»¥æ”¯æŒå¤§è§„æ¨¡è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šComputerRLæ¡†æ¶åŒ…æ‹¬å¤šä¸ªä¸»è¦æ¨¡å—ï¼šAPI-GUIäº¤äº’æ¨¡å—ã€åˆ†å¸ƒå¼è®­ç»ƒåŸºç¡€è®¾æ–½ã€Entropulseè®­ç»ƒç­–ç•¥ç­‰ã€‚é€šè¿‡åè°ƒæ•°åƒä¸ªè™šæ‹Ÿæ¡Œé¢ç¯å¢ƒï¼Œå®ç°é«˜æ•ˆçš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯Entropulseè®­ç»ƒç­–ç•¥ï¼Œå®ƒé€šè¿‡äº¤æ›¿è¿›è¡Œå¼ºåŒ–å­¦ä¹ å’Œç›‘ç£å¾®è°ƒï¼Œæœ‰æ•ˆç¼“è§£äº†é•¿æ—¶é—´è®­ç»ƒä¸­çš„ç†µå´©æºƒç°è±¡ã€‚è¿™ä¸€ç­–ç•¥æ˜¾è‘—æé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åˆ†å¸ƒå¼æ¶æ„ä»¥æ”¯æŒå¹¶è¡Œè®­ç»ƒï¼Œè®¾ç½®äº†é€‚å½“çš„è¶…å‚æ•°ä»¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œå¹¶è®¾è®¡äº†æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å¼ºåŒ–å­¦ä¹ ä¸ç›‘ç£å­¦ä¹ çš„ç›®æ ‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAutoGLM-OS-9Båœ¨OSWorldåŸºå‡†ä¸Šè¾¾åˆ°äº†48.9%çš„å‡†ç¡®ç‡ï¼Œåˆ›ä¸‹äº†æ–°çš„çŠ¶æ€-of-the-artè¡¨ç°ï¼Œç›¸è¾ƒäºä¹‹å‰çš„åŸºçº¿æœ‰æ˜¾è‘—æå‡ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†ComputerRLåœ¨æ¡Œé¢è‡ªåŠ¨åŒ–é¢†åŸŸçš„æœ‰æ•ˆæ€§å’Œæ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¡Œé¢è‡ªåŠ¨åŒ–ã€æ™ºèƒ½åŠ©æ‰‹å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜æ¡Œé¢æ™ºèƒ½ä»£ç†çš„è®­ç»ƒæ•ˆç‡ï¼ŒComputerRLèƒ½å¤Ÿåœ¨å®é™…å·¥ä½œç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„ä»»åŠ¡æ‰§è¡Œï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½åº”ç”¨çš„å¼€å‘ä¸æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce ComputerRL, a framework for autonomous desktop intelligence that enables agents to operate complex digital workspaces skillfully. ComputerRL features the API-GUI paradigm, which unifies programmatic API calls and direct GUI interaction to address the inherent mismatch between machine agents and human-centric desktop environments. Scaling end-to-end RL training is crucial for improvement and generalization across diverse desktop tasks; however, it remains challenging due to environmental inefficiency and instability during extended training. To support scalable and robust training, we develop a distributed RL infrastructure capable of orchestrating thousands of parallel virtual desktop environments to accelerate large-scale online RL. Furthermore, we propose Entropulse, a training strategy that alternates reinforcement learning with supervised fine-tuning, effectively mitigating entropy collapse during extended training runs. We employ ComputerRL on open models GLM-4-9B-0414 and GLM-4.1V-9B-Thinking, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B achieves a new state-of-the-art accuracy of 48.9%, demonstrating significant improvements for general agents in desktop automation. Our code and the new OfficeWorld benchmark are available at https://github.com/thudm/ComputerRL. The algorithm and framework are adopted in building AutoGLM (Liu et al., 2024b).

