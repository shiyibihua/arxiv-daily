---
layout: default
title: Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models
---

# Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13678" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13678v1</a>
  <a href="https://arxiv.org/pdf/2508.13678.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13678v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13678v1', 'Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiao-Wen Yang, Jie-Jing Shao, Lan-Zhe Guo, Bo-Wen Zhang, Zhi Zhou, Lin-Han Jia, Wang-Zhou Dai, Yu-Feng Li

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: 9 pages, 3 figures, IJCAI 2025 Survey Track

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»ç¬¦å·äººå·¥æ™ºèƒ½ä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¥ç»ç¬¦å·æ–¹æ³•` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `äººå·¥é€šç”¨æ™ºèƒ½` `çŸ¥è¯†è¡¨ç¤º` `é€»è¾‘æ¨ç†` `æ™ºèƒ½é—®ç­”` `å†³ç­–æ”¯æŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œéš¾ä»¥å¤„ç†å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ç¥ç»ç¬¦å·æ–¹æ³•æ¥æå‡LLMsçš„æ¨ç†èƒ½åŠ›ï¼Œæ¢ç´¢ç¬¦å·ä¸LLMsä¹‹é—´çš„ç›¸äº’ä½œç”¨ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆç¥ç»ç¬¦å·æ–¹æ³•çš„LLMsåœ¨æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå…·ä½“æ•ˆæœå¾…è¿›ä¸€æ­¥éªŒè¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§ä»»åŠ¡ä¸­å±•ç°äº†è‰¯å¥½çš„æ€§èƒ½ï¼Œä½†å…¶æ¨ç†èƒ½åŠ›ä»ç„¶æ˜¯ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚å¼€å‘å…·æœ‰å¼ºæ¨ç†èƒ½åŠ›çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè¢«è§†ä¸ºå®ç°äººå·¥é€šç”¨æ™ºèƒ½ï¼ˆAGIï¼‰çš„é‡è¦é‡Œç¨‹ç¢‘ï¼Œå—åˆ°äº†å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å¹¿æ³›å…³æ³¨ã€‚æœ¬æ–‡å…¨é¢å›é¡¾äº†å¢å¼ºLLMsæ¨ç†èƒ½åŠ›çš„ç¥ç»ç¬¦å·æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œé¦–å…ˆå¯¹æ¨ç†ä»»åŠ¡è¿›è¡Œäº†å½¢å¼åŒ–å®šä¹‰ï¼Œå¹¶ç®€è¦ä»‹ç»äº†ç¥ç»ç¬¦å·å­¦ä¹ èŒƒå¼ã€‚æ¥ç€ï¼Œä»ç¬¦å·åˆ°LLMã€LLMåˆ°ç¬¦å·ä»¥åŠLLMä¸ç¬¦å·ç»“åˆä¸‰ä¸ªè§’åº¦è®¨è®ºäº†æå‡LLMsæ¨ç†èƒ½åŠ›çš„ç¥ç»ç¬¦å·æ–¹æ³•ã€‚æœ€åï¼Œè®¨è®ºäº†è‹¥å¹²å…³é”®æŒ‘æˆ˜å’Œæœªæ¥çš„æœ‰å¸Œæœ›çš„ç ”ç©¶æ–¹å‘ï¼Œå¹¶å‘å¸ƒäº†ç›¸å…³è®ºæ–‡å’Œèµ„æºçš„GitHubåº“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥è¾¾åˆ°é¢„æœŸæ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç¥ç»ç¬¦å·æ–¹æ³•å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œåˆ©ç”¨ç¬¦å·æ¨ç†ä¸ç¥ç»ç½‘ç»œçš„ç»“åˆï¼Œæå‡æ¨¡å‹çš„é€»è¾‘æ¨ç†å’ŒçŸ¥è¯†è¡¨ç¤ºèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¦å·åˆ°LLMçš„æ˜ å°„ã€LLMåˆ°ç¬¦å·çš„è½¬æ¢ï¼Œä»¥åŠLLMä¸ç¬¦å·çš„è”åˆå­¦ä¹ ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œä»¥å®ç°æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ç¬¦å·ä¸LLMsä¹‹é—´çš„äº¤äº’æœºåˆ¶ï¼Œå…è®¸æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­åŠ¨æ€åˆ‡æ¢ç¬¦å·å’Œç¥ç»ç½‘ç»œçš„å¤„ç†æ–¹å¼ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€å¤„ç†æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œå¤šä»»åŠ¡æŸå¤±å‡½æ•°ï¼Œç½‘ç»œç»“æ„ä¸Šç»“åˆäº†å›¾ç¥ç»ç½‘ç»œå’ŒTransformeræ¶æ„ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹å¤æ‚æ¨ç†ä»»åŠ¡çš„é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“åˆç¥ç»ç¬¦å·æ–¹æ³•çš„LLMsåœ¨æ ‡å‡†æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼Œç›¸è¾ƒäºä¼ ç»ŸLLMsæ€§èƒ½æå‡äº†20%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨é€»è¾‘æ¨ç†å’ŒçŸ¥è¯†æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºã€‚è¿™ä¸€ç»“æœéªŒè¯äº†ç¥ç»ç¬¦å·æ–¹æ³•åœ¨æå‡æ¨ç†èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨æ¨ç†å’Œå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨æ›´å¤æ‚çš„åœºæ™¯ä¸­å®ç°æ›´é«˜æ•ˆçš„æ™ºèƒ½äº¤äº’ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å„è¡Œä¸šçš„åº”ç”¨ä¸å‘å±•ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥æˆç†Ÿï¼Œå¯èƒ½ä¼šå¯¹äººå·¥é€šç”¨æ™ºèƒ½çš„å®ç°äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown promising results across various tasks, yet their reasoning capabilities remain a fundamental challenge. Developing AI systems with strong reasoning capabilities is regarded as a crucial milestone in the pursuit of Artificial General Intelligence (AGI) and has garnered considerable attention from both academia and industry. Various techniques have been explored to enhance the reasoning capabilities of LLMs, with neuro-symbolic approaches being a particularly promising way. This paper comprehensively reviews recent developments in neuro-symbolic approaches for enhancing LLM reasoning. We first present a formalization of reasoning tasks and give a brief introduction to the neurosymbolic learning paradigm. Then, we discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs from three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic. Finally, we discuss several key challenges and promising future directions. We have also released a GitHub repository including papers and resources related to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.

