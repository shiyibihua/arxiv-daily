---
layout: default
title: UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion
---

# UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13843" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.13843v1</a>
  <a href="https://arxiv.org/pdf/2508.13843.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13843v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13843v1', 'UniECS: Unified Multimodal E-Commerce Search Framework with Gated Cross-modal Fusion')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zihan Liang, Yufei Ma, ZhiPeng Qian, Huangyu Dai, Zihan Wang, Ben Chen, Chenyi Lei, Yuqing Ding, Han Li

**ÂàÜÁ±ª**: cs.IR, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-19

**Â§áÊ≥®**: Accepted at CIKM2025 as a long paper

**DOI**: [10.1145/3746252.3761170](https://doi.org/10.1145/3746252.3761170)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/qzp2018/UniECS)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫UniECS‰ª•Ëß£ÂÜ≥ÁîµÂïÜÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Á≥ªÁªüÁöÑÂ±ÄÈôêÊÄß**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊ£ÄÁ¥¢` `ÁîµÂïÜÊêúÁ¥¢` `Èó®ÊéßËûçÂêà` `Ëá™ÈÄÇÂ∫îÂ≠¶‰π†` `Âü∫ÂáÜËØÑ‰º∞` `Ë∑®Ê®°ÊÄÅÂØπÈΩê` `‰∫ßÂìÅÊé®Ëçê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁîµÂïÜÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Á≥ªÁªüÂú®‰ªªÂä°‰ºòÂåñÂíåÊ®°ÊÄÅÈÖçÂØπ‰∏äÂ≠òÂú®Â±ÄÈôêÔºåÁº∫‰πèÁªü‰∏ÄÁöÑËØÑ‰º∞Âü∫ÂáÜ„ÄÇ
2. UniECSÊ°ÜÊû∂ÈÄöËøáÈó®ÊéßÂ§öÊ®°ÊÄÅÁºñÁ†ÅÂô®ÂíåËá™ÈÄÇÂ∫îËûçÂêàÊú∫Âà∂ÔºåÁÅµÊ¥ªÂ§ÑÁêÜ‰∏çÂêåÊ®°ÊÄÅÁöÑÁªÑÂêà‰∏éÁº∫Â§±„ÄÇ
3. Âú®M-BEERÂü∫ÂáÜ‰∏äÔºåUniECSÂú®Ë∑®Ê®°ÊÄÅ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÈ´ò28%ÁöÑR@10ÊèêÂçáÔºåÂêåÊó∂‰øùÊåÅÂèÇÊï∞ÊïàÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂΩìÂâçÁöÑÁîµÂïÜÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Á≥ªÁªüÈù¢‰∏¥‰∏§‰∏™‰∏ªË¶ÅÈôêÂà∂Ôºö‰∏ÄÊòØÈíàÂØπÁâπÂÆö‰ªªÂä°‰ºòÂåñ‰∏îÂõ∫ÂÆöÊ®°ÊÄÅÈÖçÂØπÔºå‰∫åÊòØÁº∫‰πèÂÖ®Èù¢ÁöÑÂü∫ÂáÜÊù•ËØÑ‰º∞Áªü‰∏ÄÊ£ÄÁ¥¢ÊñπÊ≥ï„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜUniECSÔºå‰∏Ä‰∏™Áªü‰∏ÄÁöÑÂ§öÊ®°ÊÄÅÁîµÂïÜÊêúÁ¥¢Ê°ÜÊû∂ÔºåËÉΩÂ§üÂ§ÑÁêÜÂõæÂÉè„ÄÅÊñáÊú¨ÂèäÂÖ∂ÁªÑÂêàÁöÑÊâÄÊúâÊ£ÄÁ¥¢Âú∫ÊôØ„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊúâ‰∏â‰∏™‰∏ªË¶ÅË¥°ÁåÆÔºöÈ¶ñÂÖàÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÁÅµÊ¥ªÁöÑÊû∂ÊûÑÔºåÈááÁî®Êñ∞È¢ñÁöÑÈó®ÊéßÂ§öÊ®°ÊÄÅÁºñÁ†ÅÂô®Ôºå‰ΩøÁî®Ëá™ÈÄÇÂ∫îËûçÂêàÊú∫Âà∂Êù•Êï¥Âêà‰∏çÂêåÊ®°ÊÄÅÁöÑË°®Á§∫„ÄÇÂÖ∂Ê¨°ÔºåÂºÄÂèë‰∫Ü‰∏ÄÁßçÂÖ®Èù¢ÁöÑËÆ≠ÁªÉÁ≠ñÁï•ÔºåÁªìÂêà‰∫ÜË∑®Ê®°ÊÄÅÂØπÈΩêÊçüÂ§±„ÄÅÂ±ÄÈÉ®‰∏ÄËá¥ÊÄßÂØπÈΩêÊçüÂ§±„ÄÅÂÜÖÊ®°ÊÄÅÂØπÊØîÊçüÂ§±ÂíåËá™ÈÄÇÂ∫îÊçüÂ§±Âä†ÊùÉ„ÄÇÊúÄÂêéÔºåÂàõÂª∫‰∫ÜM-BEERÔºå‰∏Ä‰∏™ÂåÖÂê´50K‰∫ßÂìÅÂØπÁöÑÂ§öÊ®°ÊÄÅÂü∫ÂáÜÔºåÁî®‰∫éÁîµÂïÜÊêúÁ¥¢ËØÑ‰º∞„ÄÇÂÆûÈ™åË°®ÊòéÔºåUniECSÂú®Âõõ‰∏™ÁîµÂïÜÂü∫ÂáÜ‰∏äÂùá‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂπ∂Âú®ÂÆûÈôÖÂ∫îÁî®‰∏≠ÊòæËëóÊèêÂçá‰∫ÜÁÇπÂáªÁéáÂíåÊî∂ÂÖ•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÁîµÂïÜÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢Á≥ªÁªüÂú®‰ªªÂä°ÁâπÂÆö‰ºòÂåñÂíåÊ®°ÊÄÅÈÖçÂØπÂõ∫ÂÆöÊñπÈù¢ÁöÑÂ±ÄÈôêÊÄßÔºåÂêåÊó∂Áº∫‰πèÁªü‰∏ÄÁöÑËØÑ‰º∞Âü∫ÂáÜ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫UniECSÊ°ÜÊû∂ÔºåÈÄöËøáÁÅµÊ¥ªÁöÑÈó®ÊéßÂ§öÊ®°ÊÄÅÁºñÁ†ÅÂô®ÂíåËá™ÈÄÇÂ∫îËûçÂêàÊú∫Âà∂ÔºåËÉΩÂ§üÊúâÊïàÊï¥Âêà‰∏çÂêåÊ®°ÊÄÅÁöÑË°®Á§∫ÔºåÂ§ÑÁêÜÊ®°ÊÄÅÁº∫Â§±ÈóÆÈ¢ò„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöUniECSÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Èó®ÊéßÂ§öÊ®°ÊÄÅÁºñÁ†ÅÂô®„ÄÅËÆ≠ÁªÉÁ≠ñÁï•ÂíåËØÑ‰º∞Âü∫ÂáÜ‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÁºñÁ†ÅÂô®Ë¥üË¥£Ê®°ÊÄÅËûçÂêàÔºåËÆ≠ÁªÉÁ≠ñÁï•‰ºòÂåñÂ≠¶‰π†ËøáÁ®ãÔºåM-BEERÂü∫ÂáÜÁî®‰∫éËØÑ‰º∞ÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÈó®ÊéßÂ§öÊ®°ÊÄÅÁºñÁ†ÅÂô®ÁöÑËÆæËÆ°ÔºåËÉΩÂ§üËá™ÈÄÇÂ∫îÂú∞ËûçÂêà‰∏çÂêåÊ®°ÊÄÅÁöÑÁâπÂæÅÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ£ÄÁ¥¢ÊïàÊûú„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈááÁî®‰∫ÜË∑®Ê®°ÊÄÅÂØπÈΩêÊçüÂ§±„ÄÅÂ±ÄÈÉ®‰∏ÄËá¥ÊÄßÂØπÈΩêÊçüÂ§±„ÄÅÂÜÖÊ®°ÊÄÅÂØπÊØîÊçüÂ§±ÂíåËá™ÈÄÇÂ∫îÊçüÂ§±Âä†ÊùÉÁ≠âÂ§öÁßçÊçüÂ§±ÂáΩÊï∞ÔºåÁ°Æ‰øù‰∫ÜÊ®°ÂûãÂú®Â§öÊ®°ÊÄÅÂ≠¶‰π†‰∏≠ÁöÑÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®M-BEERÂü∫ÂáÜ‰∏äÔºåUniECSÂú®Ë∑®Ê®°ÊÄÅ‰ªªÂä°‰∏≠ÂÆûÁé∞‰∫ÜÊúÄÈ´ò28%ÁöÑR@10ÊèêÂçáÔºå‰∏îÂú®ÂèÇÊï∞ÊïàÁéá‰∏äË°®Áé∞‰ºòÂºÇÔºå‰ΩøÁî®0.2BÂèÇÊï∞Áõ∏ÊØî‰∫éGME-Qwen2VLÂíåMM-EmbedÁ≠âÊõ¥Â§ßÊ®°ÂûãÊòæËëóÂáèÂ∞ë‰∫ÜËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄó„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÁîµÂïÜÂπ≥Âè∞ÁöÑÊêúÁ¥¢ÂºïÊìé‰ºòÂåñ„ÄÅ‰∫ßÂìÅÊé®ËçêÁ≥ªÁªüÂèäÁî®Êà∑‰ΩìÈ™åÊèêÂçá„ÄÇÈÄöËøáÂÆûÁé∞Êõ¥È´òÊïàÁöÑÂ§öÊ®°ÊÄÅÊ£ÄÁ¥¢ÔºåUniECSËÉΩÂ§ü‰∏∫ÁîµÂïÜ‰ºÅ‰∏öÂ∏¶Êù•Êõ¥È´òÁöÑËΩ¨ÂåñÁéáÂíåÊî∂ÂÖ•ÔºåÊú™Êù•ÂèØËÉΩÂú®ÂÖ∂‰ªñÈ¢ÜÂüüÂ¶ÇÁ§æ‰∫§Â™í‰ΩìÂíåÂÜÖÂÆπÊé®Ëçê‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Current e-commerce multimodal retrieval systems face two key limitations: they optimize for specific tasks with fixed modality pairings, and lack comprehensive benchmarks for evaluating unified retrieval approaches. To address these challenges, we introduce UniECS, a unified multimodal e-commerce search framework that handles all retrieval scenarios across image, text, and their combinations. Our work makes three key contributions. First, we propose a flexible architecture with a novel gated multimodal encoder that uses adaptive fusion mechanisms. This encoder integrates different modality representations while handling missing modalities. Second, we develop a comprehensive training strategy to optimize learning. It combines cross-modal alignment loss (CMAL), cohesive local alignment loss (CLAL), intra-modal contrastive loss (IMCL), and adaptive loss weighting. Third, we create M-BEER, a carefully curated multimodal benchmark containing 50K product pairs for e-commerce search evaluation. Extensive experiments demonstrate that UniECS consistently outperforms existing methods across four e-commerce benchmarks with fine-tuning or zero-shot evaluation. On our M-BEER bench, UniECS achieves substantial improvements in cross-modal tasks (up to 28\% gain in R@10 for text-to-image retrieval) while maintaining parameter efficiency (0.2B parameters) compared to larger models like GME-Qwen2VL (2B) and MM-Embed (8B). Furthermore, we deploy UniECS in the e-commerce search platform of Kuaishou Inc. across two search scenarios, achieving notable improvements in Click-Through Rate (+2.74\%) and Revenue (+8.33\%). The comprehensive evaluation demonstrates the effectiveness of our approach in both experimental and real-world settings. Corresponding codes, models and datasets will be made publicly available at https://github.com/qzp2018/UniECS.

