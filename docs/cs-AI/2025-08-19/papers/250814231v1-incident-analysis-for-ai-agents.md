---
layout: default
title: Incident Analysis for AI Agents
---

# Incident Analysis for AI Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14231" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14231v1</a>
  <a href="https://arxiv.org/pdf/2508.14231.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14231v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14231v1', 'Incident Analysis for AI Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Carson Ezell, Xavier Roberts-Gaal, Alan Chan

**åˆ†ç±»**: cs.CY, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

**å¤‡æ³¨**: 16 pages (10 pages main text), 4 figures, 3 tables. To be published in the Proceedings of the 2025 AAAI/ACM Conference on AI, Ethics, & Society (AIES)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAIä»£ç†äº‹ä»¶åˆ†ææ¡†æ¶ä»¥è§£å†³å®‰å…¨éšæ‚£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIä»£ç†` `äº‹ä»¶åˆ†æ` `å®‰å…¨ç®¡ç†` `ç³»ç»Ÿå®‰å…¨` `é£é™©è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äº‹ä»¶æŠ¥å‘Šæµç¨‹ä¸»è¦ä¾èµ–å…¬å¼€æ•°æ®ï¼Œæ— æ³•è·å–æ•æ„Ÿä¿¡æ¯ï¼Œå¯¼è‡´å¯¹AIä»£ç†äº‹ä»¶çš„ç†è§£ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§äº‹ä»¶åˆ†ææ¡†æ¶ï¼Œè¯†åˆ«ç³»ç»Ÿç›¸å…³ã€ä¸Šä¸‹æ–‡å’Œè®¤çŸ¥ç­‰å› ç´ ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å’Œé¢„é˜²äº‹ä»¶ã€‚
3. é€šè¿‡ç»“æ„åŒ–çš„ä¿¡æ¯æ”¶é›†å’Œåˆ†æï¼Œæœ¬æ–‡ä¸ºæœªæ¥AIä»£ç†çš„å®‰å…¨ç®¡ç†æä¾›äº†æ–°çš„æ€è·¯å’Œå»ºè®®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€AIä»£ç†çš„å¹¿æ³›åº”ç”¨ï¼Œäº‹ä»¶å‘ç”Ÿçš„é¢‘ç‡å¯èƒ½ä¼šå¢åŠ ï¼Œè¿™äº›äº‹ä»¶å¯èƒ½ç›´æ¥æˆ–é—´æ¥é€ æˆä¼¤å®³ã€‚ç°æœ‰çš„äº‹ä»¶æŠ¥å‘Šæµç¨‹æ— æ³•å……åˆ†ç†è§£AIä»£ç†äº‹ä»¶ï¼Œå°¤å…¶æ˜¯ç¼ºä¹æ•æ„Ÿä¿¡æ¯çš„æ”¶é›†ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§äº‹ä»¶åˆ†ææ¡†æ¶ï¼Œè¯†åˆ«å‡ºç³»ç»Ÿç›¸å…³ã€ä¸Šä¸‹æ–‡å’Œè®¤çŸ¥ç­‰ä¸‰ç±»å› ç´ ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–çš„ä¿¡æ¯æ”¶é›†æ¥é¢„é˜²æœªæ¥äº‹ä»¶çš„å‘ç”Ÿã€‚æˆ‘ä»¬è¿˜æä¾›äº†å…³äºäº‹ä»¶æŠ¥å‘Šåº”åŒ…å«çš„ä¿¡æ¯å’Œå¼€å‘è€…åº”ä¿ç•™çš„ä¿¡æ¯çš„å»ºè®®ï¼Œä»¥å¸®åŠ©äº‹ä»¶è°ƒæŸ¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰AIä»£ç†äº‹ä»¶æŠ¥å‘Šæµç¨‹ä¸è¶³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯ç¼ºä¹å¯¹æ•æ„Ÿä¿¡æ¯çš„æ”¶é›†å’Œåˆ†æï¼Œå¯¼è‡´æ— æ³•å…¨é¢ç†è§£äº‹ä»¶çš„æˆå› ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åŸºäºç³»ç»Ÿå®‰å…¨æ–¹æ³•çš„äº‹ä»¶åˆ†ææ¡†æ¶ï¼Œè¯†åˆ«å‡ºå¯¼è‡´äº‹ä»¶çš„ä¸‰ç±»å› ç´ ï¼šç³»ç»Ÿç›¸å…³å› ç´ ã€ä¸Šä¸‹æ–‡å› ç´ å’Œè®¤çŸ¥å› ç´ ï¼Œä»¥ä¾¿æ›´å…¨é¢åœ°åˆ†æäº‹ä»¶åŸå› ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) äº‹ä»¶æ•°æ®æ”¶é›†ï¼Œæ¶µç›–ç”¨æˆ·æç¤ºã€æ´»åŠ¨æ—¥å¿—ç­‰ï¼›2) äº‹ä»¶åˆ†æï¼ŒåŸºäºè¯†åˆ«çš„å› ç´ è¿›è¡Œæ·±å…¥åˆ†æï¼›3) äº‹ä»¶æŠ¥å‘Šç”Ÿæˆï¼Œæä¾›ç»“æ„åŒ–çš„æŠ¥å‘Šä»¥ä¾›è°ƒæŸ¥ä½¿ç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ç³»ç»Ÿç›¸å…³ã€ä¸Šä¸‹æ–‡å’Œè®¤çŸ¥ä¸‰ç±»å› ç´ çš„åˆ†ç±»æ–¹æ³•ï¼Œå¡«è¡¥äº†ç°æœ‰æ–¹æ³•åœ¨äº‹ä»¶åˆ†æä¸­çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æ¶ä¸­å¼ºè°ƒäº†æ´»åŠ¨æ—¥å¿—ã€ç³»ç»Ÿæ–‡æ¡£å’Œå·¥å…·ä¿¡æ¯çš„æ”¶é›†ï¼Œç¡®ä¿èƒ½å¤Ÿæä¾›å…¨é¢çš„äº‹ä»¶èƒŒæ™¯ä¿¡æ¯ï¼Œä»¥æ”¯æŒåç»­çš„äº‹ä»¶è°ƒæŸ¥å’Œåˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æœ¬æ–‡æå‡ºçš„äº‹ä»¶åˆ†ææ¡†æ¶ä¸ºAIä»£ç†äº‹ä»¶çš„ç†è§£æä¾›äº†æ–°çš„è§†è§’ï¼Œå¼ºè°ƒäº†ç³»ç»Ÿç›¸å…³ã€ä¸Šä¸‹æ–‡å’Œè®¤çŸ¥å› ç´ çš„é‡è¦æ€§ã€‚é€šè¿‡ç»“æ„åŒ–çš„ä¿¡æ¯æ”¶é›†ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜äº‹ä»¶è°ƒæŸ¥çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œä¸ºæœªæ¥çš„AIä»£ç†å®‰å…¨ç®¡ç†å¥ å®šåŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIä»£ç†çš„å®‰å…¨å®¡è®¡ã€äº‹ä»¶å“åº”å’Œé£é™©ç®¡ç†ã€‚é€šè¿‡å»ºç«‹æœ‰æ•ˆçš„äº‹ä»¶åˆ†ææ¡†æ¶ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…å’Œéƒ¨ç½²è€…æ›´å¥½åœ°ç†è§£å’Œåº”å¯¹AIä»£ç†ä½¿ç”¨ä¸­çš„å®‰å…¨éšæ‚£ï¼Œæå‡æ•´ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As AI agents become more widely deployed, we are likely to see an increasing number of incidents: events involving AI agent use that directly or indirectly cause harm. For example, agents could be prompt-injected to exfiltrate private information or make unauthorized purchases. Structured information about such incidents (e.g., user prompts) can help us understand their causes and prevent future occurrences. However, existing incident reporting processes are not sufficient for understanding agent incidents. In particular, such processes are largely based on publicly available data, which excludes useful, but potentially sensitive, information such as an agent's chain of thought or browser history. To inform the development of new, emerging incident reporting processes, we propose an incident analysis framework for agents. Drawing on systems safety approaches, our framework proposes three types of factors that can cause incidents: system-related (e.g., CBRN training data), contextual (e.g., prompt injections), and cognitive (e.g., misunderstanding a user request). We also identify specific information that could help clarify which factors are relevant to a given incident: activity logs, system documentation and access, and information about the tools an agent uses. We provide recommendations for 1) what information incident reports should include and 2) what information developers and deployers should retain and make available to incident investigators upon request. As we transition to a world with more agents, understanding agent incidents will become increasingly crucial for managing risks.

