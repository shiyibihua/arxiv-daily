---
layout: default
title: Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli
---

# Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14214" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14214v1</a>
  <a href="https://arxiv.org/pdf/2508.14214.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14214v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14214v1', 'Large Language Models are Highly Aligned with Human Ratings of Emotional Stimuli')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mattson Ogg, Chace Ashcraft, Ritwik Bose, Raphael Norman-Tenazas, Michael Wolmetz

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»æƒ…æ„Ÿè¯„ä¼°çš„é«˜åº¦ä¸€è‡´æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æƒ…æ„Ÿè®¡ç®—` `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæœºäº¤äº’` `æƒ…æ„Ÿè¯„ä¼°` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿè¯„ä¼°ä¸­çš„ä¸€è‡´æ€§ç¼ºä¹æ·±å…¥ç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨é«˜å‹æƒ…å¢ƒä¸‹çš„è¡¨ç°ã€‚
2. è®ºæ–‡é€šè¿‡å¯¹å¤šç§æµè¡ŒLLMsè¿›è¡Œæƒ…æ„Ÿè¯„åˆ†ï¼Œæ¢è®¨å…¶ä¸äººç±»æƒ…æ„Ÿè¯„ä¼°çš„ä¸€è‡´æ€§ï¼Œå°¤å…¶å…³æ³¨å¿«ä¹ã€æ„¤æ€’ã€æ‚²ä¼¤ç­‰æƒ…æ„Ÿç±»åˆ«ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4oåœ¨æƒ…æ„Ÿè¯„åˆ†ä»»åŠ¡ä¸­ä¸äººç±»è¯„åˆ†é«˜åº¦ä¸€è‡´ï¼Œå°¤å…¶åœ¨å¿«ä¹æƒ…æ„Ÿçš„è¯„ä¼°ä¸­ï¼Œç›¸å…³æ€§è¾¾åˆ°0.9ä»¥ä¸Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æƒ…æ„Ÿå¯¹äººç±»è¡Œä¸ºå’Œè®¤çŸ¥æœ‰ç€æ·±è¿œçš„å½±å“ï¼Œå°¤å…¶åœ¨æ—¥å¸¸å’Œé«˜å‹ä»»åŠ¡ä¸­ã€‚æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚ä½•è¯„ä¼°æƒ…æ„Ÿåˆºæ¿€ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬ä¸äººç±»åœ¨æƒ…æ„Ÿå†…å®¹è¯„ä¼°ä¸Šçš„ä¸€è‡´æ€§ã€‚é€šè¿‡å¯¹å¤šç§æµè¡ŒLLMsè¿›è¡Œæƒ…æ„Ÿè¯„åˆ†ï¼Œå‘ç°GPT-4oåœ¨å¤šä¸ªæ¨¡æ€å’Œåˆºæ¿€ä¸Šä¸äººç±»å‚ä¸è€…çš„è¯„åˆ†é«˜åº¦ä¸€è‡´ï¼Œå°¤å…¶åœ¨å¿«ä¹æƒ…æ„Ÿçš„è¯„ä¼°ä¸­è¡¨ç°æœ€ä½³ã€‚ç ”ç©¶ç»“æœä¸ºç†è§£LLMsåœ¨æƒ…æ„Ÿäº¤äº’ä¸­çš„æœ‰æ•ˆæ€§æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æƒ…æ„Ÿåˆºæ¿€è¯„ä¼°ä¸­çš„ä¸€è‡´æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†æ¢è®¨LLMsåœ¨æƒ…æ„Ÿäº¤äº’ä¸­çš„æœ‰æ•ˆæ€§ä¸å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹å¤šç§æµè¡ŒLLMsè¿›è¡Œæƒ…æ„Ÿè¯„åˆ†ï¼Œä¸äººç±»è¯„åˆ†è¿›è¡Œå¯¹æ¯”ï¼Œåˆ†æå…¶åœ¨ä¸åŒæƒ…æ„Ÿç±»åˆ«ä¸­çš„ä¸€è‡´æ€§ï¼Œç‰¹åˆ«æ˜¯å¿«ä¹ã€æ„¤æ€’ã€æ‚²ä¼¤ç­‰æƒ…æ„Ÿçš„è¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¤šæ¨¡æ€æ•°æ®é›†ï¼ŒåŒ…æ‹¬è¯æ±‡å’Œå›¾åƒï¼Œåˆ†åˆ«ç”±äººç±»å’ŒLLMsè¿›è¡Œæƒ…æ„Ÿè¯„åˆ†ï¼Œæ„å»ºäº†ä¸€ä¸ªå¯¹æ¯”åˆ†ææ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°LLMsä¸äººç±»åœ¨æƒ…æ„Ÿè¯„åˆ†ä¸Šçš„ä¸€è‡´æ€§ï¼Œå°¤å…¶æ˜¯åœ¨äº”ç±»æƒ…æ„Ÿæ¡†æ¶ä¸‹çš„è¡¨ç°ï¼Œæä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒä¸­ä½¿ç”¨äº†å¤šç§è¯„åˆ†æ ‡å‡†ï¼Œç‰¹åˆ«å…³æ³¨æ„¤æ€’ã€æ‚²ä¼¤ã€ææƒ§ã€åŒæ¶å’Œå¿«ä¹äº”ç±»æƒ…æ„Ÿçš„è¯„ä¼°ï¼Œè®¾è®¡äº†ç›¸åº”çš„è¯„åˆ†æœºåˆ¶ä»¥ç¡®ä¿æ•°æ®çš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oåœ¨æƒ…æ„Ÿè¯„åˆ†ä»»åŠ¡ä¸­ä¸äººç±»è¯„åˆ†çš„ç›¸å…³æ€§é«˜è¾¾0.9ï¼Œå°¤å…¶åœ¨å¿«ä¹æƒ…æ„Ÿçš„è¯„ä¼°ä¸­è¡¨ç°æœ€ä½³ã€‚åŒæ—¶ï¼ŒLLMsçš„è¯„åˆ†ä¸€è‡´æ€§æ˜æ˜¾é«˜äºäººç±»è¯„åˆ†ï¼Œæ­ç¤ºäº†å…¶åœ¨æƒ…æ„Ÿç†è§£ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æƒ…æ„Ÿè®¡ç®—ã€å¿ƒç†å¥åº·ç›‘æµ‹å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡ç†è§£LLMsåœ¨æƒ…æ„Ÿè¯„ä¼°ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥æ›´å¥½åœ°å°†å…¶åº”ç”¨äºéœ€è¦æƒ…æ„Ÿç†è§£çš„åœºæ™¯ï¼Œå¦‚å®¢æœæœºå™¨äººå’Œç¤¾äº¤åª’ä½“åˆ†æï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œäº¤äº’è´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Emotions exert an immense influence over human behavior and cognition in both commonplace and high-stress tasks. Discussions of whether or how to integrate large language models (LLMs) into everyday life (e.g., acting as proxies for, or interacting with, human agents), should be informed by an understanding of how these tools evaluate emotionally loaded stimuli or situations. A model's alignment with human behavior in these cases can inform the effectiveness of LLMs for certain roles or interactions. To help build this understanding, we elicited ratings from multiple popular LLMs for datasets of words and images that were previously rated for their emotional content by humans. We found that when performing the same rating tasks, GPT-4o responded very similarly to human participants across modalities, stimuli and most rating scales (r = 0.9 or higher in many cases). However, arousal ratings were less well aligned between human and LLM raters, while happiness ratings were most highly aligned. Overall LLMs aligned better within a five-category (happiness, anger, sadness, fear, disgust) emotion framework than within a two-dimensional (arousal and valence) organization. Finally, LLM ratings were substantially more homogenous than human ratings. Together these results begin to describe how LLM agents interpret emotional stimuli and highlight similarities and differences among biological and artificial intelligence in key behavioral domains.

