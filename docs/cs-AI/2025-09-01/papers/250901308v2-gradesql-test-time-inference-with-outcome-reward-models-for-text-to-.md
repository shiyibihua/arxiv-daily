---
layout: default
title: GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL Generation from Large Language Models
---

# GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL Generation from Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01308" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01308v2</a>
  <a href="https://arxiv.org/pdf/2509.01308.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01308v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01308v2', 'GradeSQL: Test-Time Inference with Outcome Reward Models for Text-to-SQL Generation from Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mattia Tritto, Giuseppe Farano, Dario Di Palma, Gaetano Rossiello, Fedelucio Narducci, Dharmashankar Subramanian, Tommaso Di Noia

**åˆ†ç±»**: cs.AI, cs.CL, cs.DB

**å‘å¸ƒæ—¥æœŸ**: 2025-09-01 (æ›´æ–°: 2025-10-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGradeSQLï¼šåˆ©ç”¨Outcome Reward Modelsæå‡å¤§è¯­è¨€æ¨¡å‹Text-to-SQLç”Ÿæˆæ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Text-to-SQL` `å¤§è¯­è¨€æ¨¡å‹` `Outcome Reward Model` `æµ‹è¯•æ—¶æ¨ç†` `è¯­ä¹‰æ­£ç¡®æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Text-to-SQLæ–¹æ³•åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶å­˜åœ¨å›°éš¾ï¼Œä¼ ç»Ÿçš„Best-of-Nå’ŒMajority Votingç­‰æ–¹æ³•ä¾èµ–äºè¡¨é¢å¯å‘å¼ï¼Œæ•ˆæœæœ‰é™ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨Outcome Reward Models (ORMs) ä½œä¸ºæµ‹è¯•æ—¶å¯å‘å¼æ–¹æ³•ï¼Œé€šè¿‡è¯­ä¹‰æ­£ç¡®æ€§è¯„ä¼°ç”ŸæˆSQLçš„æ•ˆç”¨ï¼Œæå‡æ¨¡å‹å¯¹é½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒORMsåœ¨BIRDå’ŒSpideræ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ‰§è¡Œå‡†ç¡®ç‡åˆ†åˆ«æå‡äº†+4.33%å’Œ+2.10%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨Text-to-SQLä»»åŠ¡ä¸­å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºOutcome Reward Models (ORMs)çš„æµ‹è¯•æ—¶æ¨ç†æ¡†æ¶GradeSQLã€‚å°½ç®¡LLMsåœ¨ç”Ÿæˆæœ‰æ•ˆSQLæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•å¦‚Best-of-N (BoN)å’ŒMajority Voting (Maj)ä¾èµ–äºè¡¨é¢å¯å‘å¼æ–¹æ³•ã€‚æœ¬æ–‡æå‡ºå°†ORMsä½œä¸ºä¸€ç§æ–°çš„æµ‹è¯•æ—¶å¯å‘å¼æ–¹æ³•ï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥è®­ç»ƒé’ˆå¯¹Text-to-SQLä»»åŠ¡å®šåˆ¶çš„ORMsã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒORMsåœ¨BIRDå’ŒSpideræ•°æ®é›†ä¸Šä¼˜äºex-BoNå’ŒMajï¼Œåœ¨æ‰§è¡Œå‡†ç¡®ç‡æ–¹é¢åˆ†åˆ«æå‡äº†+4.33%å’Œ+2.10%ã€‚æ­¤å¤–ï¼Œå¯¹OmniSQLç­‰å·²å¯¹é½SQLç”Ÿæˆçš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¯è·å¾—æ›´ä¼˜çš„ORMæ€§èƒ½ã€‚ORMsåœ¨ç®€å•æŸ¥è¯¢ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå¹¶ä¸”ç›¸æ¯”ex-BoNå’ŒMajï¼Œèƒ½ä»æ›´å¤šçš„å€™é€‰æŸ¥è¯¢ä¸­è·ç›Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šText-to-SQLä»»åŠ¡æ—¨åœ¨å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ã€‚ç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶ï¼Œç”Ÿæˆçš„SQLæŸ¥è¯¢çš„å‡†ç¡®ç‡ä»ç„¶è¾ƒä½ã€‚ä¼ ç»Ÿçš„Best-of-N (BoN) å’Œ Majority Voting (Maj) ç­‰æµ‹è¯•æ—¶ç­–ç•¥ï¼Œä¾èµ–äºè¯­æ³•æ­£ç¡®æ€§æˆ–é¢‘ç‡ç­‰è¡¨é¢ä¿¡æ¯ï¼Œæ— æ³•æœ‰æ•ˆåŒºåˆ†è¯­ä¹‰ä¸Šæ­£ç¡®çš„æŸ¥è¯¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Outcome Reward Models (ORMs) æ¥è¯„ä¼°ç”Ÿæˆçš„SQLæŸ¥è¯¢çš„è¯­ä¹‰æ­£ç¡®æ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºä¸€ç§æ–°çš„æµ‹è¯•æ—¶å¯å‘å¼æ–¹æ³•ã€‚é€šè¿‡è®­ç»ƒORMsï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®SQLæŸ¥è¯¢çš„æ‰§è¡Œç»“æœï¼ˆoutcomeï¼‰æ¥é¢„æµ‹å…¶å¥–åŠ±ï¼ˆrewardï¼‰ï¼Œä»è€Œé€‰æ‹©æ›´ä¼˜çš„æŸ¥è¯¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç”ŸæˆNä¸ªå€™é€‰SQLæŸ¥è¯¢ï¼›2) ä½¿ç”¨æ•°æ®åº“æ‰§è¡Œè¿™äº›æŸ¥è¯¢ï¼Œè·å–æ‰§è¡Œç»“æœï¼›3) ä½¿ç”¨è®­ç»ƒå¥½çš„ORMæ¨¡å‹å¯¹æ¯ä¸ªæŸ¥è¯¢çš„æ‰§è¡Œç»“æœè¿›è¡Œè¯„åˆ†ï¼›4) é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æŸ¥è¯¢ä½œä¸ºæœ€ç»ˆç»“æœã€‚è¯¥æ¡†æ¶å¯ä»¥ä¸ä¸åŒçš„åŸºç¡€å¤§è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œå¹¶åˆ©ç”¨Best-of-Nç­–ç•¥è¿›è¡Œæµ‹è¯•æ—¶æ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†Outcome Reward Modelsåº”ç”¨äºText-to-SQLä»»åŠ¡çš„æµ‹è¯•æ—¶æ¨ç†ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè¡¨é¢ä¿¡æ¯çš„å¯å‘å¼æ–¹æ³•ä¸åŒï¼ŒORMèƒ½å¤Ÿå­¦ä¹ SQLæŸ¥è¯¢çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä¼°æŸ¥è¯¢çš„æ­£ç¡®æ€§ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶æ¥è®­ç»ƒé’ˆå¯¹Text-to-SQLä»»åŠ¡å®šåˆ¶çš„ORMsã€‚

**å…³é”®è®¾è®¡**ï¼šORMæ¨¡å‹çš„è®­ç»ƒéœ€è¦æ„é€ æ­£è´Ÿæ ·æœ¬ã€‚æ­£æ ·æœ¬é€šå¸¸æ˜¯ä¸è‡ªç„¶è¯­è¨€é—®é¢˜å¯¹åº”çš„æ­£ç¡®SQLæŸ¥è¯¢åŠå…¶æ‰§è¡Œç»“æœï¼Œè´Ÿæ ·æœ¬å¯ä»¥æ˜¯éšæœºç”Ÿæˆçš„SQLæŸ¥è¯¢æˆ–ç”±å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„é”™è¯¯æŸ¥è¯¢åŠå…¶æ‰§è¡Œç»“æœã€‚æŸå¤±å‡½æ•°å¯ä»¥ä½¿ç”¨äºŒå…ƒäº¤å‰ç†µæŸå¤±æˆ–æ’åºæŸå¤±ç­‰ã€‚æ¨¡å‹çš„è¾“å…¥å¯ä»¥æ˜¯SQLæŸ¥è¯¢çš„æ‰§è¡Œç»“æœçš„å‘é‡åŒ–è¡¨ç¤ºï¼Œè¾“å‡ºæ˜¯è¯¥æŸ¥è¯¢çš„å¥–åŠ±å¾—åˆ†ã€‚å…³é”®å‚æ•°åŒ…æ‹¬ORMæ¨¡å‹çš„ç»“æ„ï¼ˆä¾‹å¦‚ï¼ŒTransformeræ¨¡å‹ï¼‰å’Œè®­ç»ƒæ•°æ®è§„æ¨¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„åŸºäºORMsçš„æµ‹è¯•æ—¶æ¨ç†æ–¹æ³•åœ¨BIRDå’ŒSpideræ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„ex-BoNå’ŒMajæ–¹æ³•ã€‚åœ¨BIRDæ•°æ®é›†ä¸Šï¼ŒORMsçš„æ‰§è¡Œå‡†ç¡®ç‡æ¯”ex-BoNæé«˜äº†4.33%ï¼Œæ¯”Majæé«˜äº†2.91%ã€‚åœ¨Spideræ•°æ®é›†ä¸Šï¼ŒORMsçš„æ‰§è¡Œå‡†ç¡®ç‡æ¯”ex-BoNæé«˜äº†2.10%ï¼Œæ¯”Majæé«˜äº†0.93%ã€‚æ­¤å¤–ï¼Œå¯¹OmniSQLç­‰å·²å¯¹é½SQLç”Ÿæˆçš„æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¯è·å¾—æ›´ä¼˜çš„ORMæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å°†è‡ªç„¶è¯­è¨€è½¬æ¢ä¸ºSQLæŸ¥è¯¢çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½æ•°æ®åº“åŠ©æ‰‹ã€æ•°æ®åˆ†æå¹³å°ç­‰ã€‚é€šè¿‡æé«˜Text-to-SQLçš„å‡†ç¡®ç‡ï¼Œå¯ä»¥é™ä½ç”¨æˆ·ä½¿ç”¨æ•°æ®åº“çš„é—¨æ§›ï¼Œä½¿æ›´å¤šç”¨æˆ·èƒ½å¤Ÿæ–¹ä¾¿åœ°è®¿é—®å’Œåˆ†ææ•°æ®ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–è‡ªç„¶è¯­è¨€ç”Ÿæˆä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text-to-SQL, the task of translating natural language questions into SQL queries, has significantly advanced with the introduction of Large Language Models (LLMs), broadening database accessibility for a wide range of users. Despite substantial progress in generating valid SQL, current LLMs still struggle with complex queries. To address this limitation, test-time strategies such as Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the assumption that LLMs can produce correct answers after multiple attempts. However, these methods rely on surface-level heuristics, selecting the syntactically correct query through execution-based BoN (ex-BoN) or the most frequently generated one through Majority Voting. Recently, Outcome Reward Models (ORMs), which assign utility scores to generated outputs based on semantic correctness, have emerged as a promising reinforcement learning approach for improving model alignment. We argue that ORMs could serve as an effective new test-time heuristic, although their application in this context remains largely underexplored.
>   In this work, we propose a unified framework for training ORMs tailored to the Text-to-SQL task and assess their effectiveness as a test-time heuristic within the BoN strategy. We benchmark ORMs against ex-BoN and Maj across the BIRD and Spider datasets, fine-tuning diverse open-source LLMs from the Qwen2, Granite3, and Llama3 families. Results show that ORMs outperform ex-BoN and Maj, achieving execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and +2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that finetuning models already aligned with SQL generation, such as OmniSQL, yields superior ORM performance. Additionally, we observe that ORMs achieve competitive results on simple queries and benefit more from an increased number of candidates compared to ex-BoN and Maj.

