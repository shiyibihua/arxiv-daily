---
layout: default
title: VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use
---

# VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01055" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.01055v3</a>
  <a href="https://arxiv.org/pdf/2509.01055.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01055v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01055v3', 'VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Dongfu Jiang, Yi Lu, Zhuofeng Li, Zhiheng Lyu, Ping Nie, Haozhe Wang, Alex Su, Hui Chen, Kai Zou, Chao Du, Tianyu Pang, Wenhu Chen

**ÂàÜÁ±ª**: cs.AI, cs.CL, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-01 (Êõ¥Êñ∞: 2025-10-17)

**Â§áÊ≥®**: 32 pages, 5 figures, 13 tables

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/TIGER-AI-Lab/verl-tool)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫VerlTool‰ª•Ëß£ÂÜ≥Â§öËΩÆÂ∑•ÂÖ∑‰∫§‰∫íÁöÑÂº∫ÂåñÂ≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `Â∑•ÂÖ∑‰ΩøÁî®` `Â§öÊ®°ÊÄÅ‰∫§‰∫í` `Ê®°ÂùóÂåñËÆæËÆ°` `ÂºÇÊ≠•ÊâßË°å`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑARLTÊñπÊ≥ïÂú®Â§öËΩÆÂ∑•ÂÖ∑‰∫§‰∫í‰∏≠Â≠òÂú®Á¢éÁâáÂåñÂíåÊâßË°åÁì∂È¢àÔºåÈôêÂà∂‰∫ÜÂÖ∂Êâ©Â±ïÊÄßÂíåÁ§æÂå∫ÈááÁî®„ÄÇ
2. VerlToolÈÄöËøáÁªü‰∏ÄÁöÑÊ®°ÂùóÂåñÊ°ÜÊû∂ÔºåÊèê‰æõÊ†áÂáÜÂåñAPIÂíåÂºÇÊ≠•ÊâßË°åÔºåËß£ÂÜ≥‰∫ÜÁé∞ÊúâÊñπÊ≥ïÁöÑ‰∏çË∂≥„ÄÇ
3. Âú®Êï∞Â≠¶Êé®ÁêÜ„ÄÅÁü•ËØÜÈóÆÁ≠î„ÄÅSQLÁîüÊàêÁ≠â6‰∏™È¢ÜÂüüÁöÑÂÆûÈ™å‰∏≠ÔºåVerlToolË°®Áé∞Âá∫‰∏é‰∏ìÁî®Á≥ªÁªüÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºå‰∏îËÆ≠ÁªÉÂü∫Á°ÄËÆæÊñΩÁªü‰∏Ä„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âº∫ÂåñÂ≠¶‰π†‰∏éÂèØÈ™åËØÅÂ•ñÂä±ÔºàRLVRÔºâÂú®Â¢ûÂº∫Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊé®ÁêÜËÉΩÂäõÊñπÈù¢ÂèñÂæó‰∫Ü‰∏ÄÂÆöÊàêÂäüÔºå‰ΩÜ‰ªçÂ±ÄÈôê‰∫éÂçïËΩÆ‰∫§‰∫í‰∏îÊú™Êï¥ÂêàÂ∑•ÂÖ∑„ÄÇËøëÊúüÁöÑ‰ª£ÁêÜÂº∫ÂåñÂ≠¶‰π†‰∏éÂ∑•ÂÖ∑‰ΩøÁî®ÔºàARLTÔºâÊñπÊ≥ïËôΩÁÑ∂Â∫îËøêËÄåÁîüÔºå‰ΩÜÂ≠òÂú®‰ªªÂä°ÁâπÂÆö‰ª£Á†ÅÂ∫ìÁöÑÁ¢éÁâáÂåñ„ÄÅÂêåÊ≠•ÊâßË°åÁì∂È¢àÂíåË∑®È¢ÜÂüüÊâ©Â±ïÊÄßÊúâÈôêÁ≠âÈóÆÈ¢òÔºåÈòªÁ¢ç‰∫ÜÊõ¥ÂπøÊ≥õÁöÑÁ§æÂå∫ÈááÁî®ÂíåÁÆóÊ≥ïÂàõÊñ∞„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜVerlToolÔºå‰∏Ä‰∏™Áªü‰∏Ä‰∏îÊ®°ÂùóÂåñÁöÑÊ°ÜÊû∂ÔºåÈÄöËøáÁ≥ªÁªüËÆæËÆ°ÂéüÂàôËß£ÂÜ≥Ëøô‰∫õÂ±ÄÈôêÊÄß„ÄÇVerlToolÁöÑÂõõÂ§ßË¥°ÁåÆÂåÖÊã¨Ôºö‰∏éVeRLÁöÑ‰∏äÊ∏∏ÂØπÈΩê„ÄÅÁªü‰∏ÄÁöÑÂ∑•ÂÖ∑ÁÆ°ÁêÜ„ÄÅÂºÇÊ≠•ÊâßË°åÂÆûÁé∞Ëøë2ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºå‰ª•ÂèäÂú®6‰∏™ARLTÈ¢ÜÂüüÁöÑÁ´û‰∫âÊÄßËØÑ‰º∞„ÄÇÊàë‰ª¨ÁöÑ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫ê‰∫éhttps://github.com/TIGER-AI-Lab/verl-tool„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâARLTÊñπÊ≥ïÂú®Â§öËΩÆÂ∑•ÂÖ∑‰∫§‰∫í‰∏≠ÁöÑÁ¢éÁâáÂåñ„ÄÅÂêåÊ≠•ÊâßË°åÁì∂È¢àÂèäÊâ©Â±ïÊÄß‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇËøô‰∫õÈóÆÈ¢òÈôêÂà∂‰∫ÜÁÆóÊ≥ïÁöÑÂàõÊñ∞ÂíåÁ§æÂå∫ÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöVerlToolÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÁªü‰∏ÄÂíåÊ®°ÂùóÂåñÁöÑËÆæËÆ°ÔºåÊèê‰æõÊ†áÂáÜÂåñÁöÑAPIÂíåÂºÇÊ≠•ÊâßË°åÊú∫Âà∂Ôºå‰ªéËÄåÊèêÈ´òÂ∑•ÂÖ∑‰ΩøÁî®ÁöÑÊïàÁéáÂíåÁÅµÊ¥ªÊÄß„ÄÇËøôÊ†∑ÁöÑËÆæËÆ°‰ΩøÂæó‰∏çÂêåÂ∑•ÂÖ∑ÁöÑÈõÜÊàêÂèòÂæóÊõ¥Âä†ÁÆÄÂçïÂíåÈ´òÊïà„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöVerlToolÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂ∑•ÂÖ∑ÁÆ°ÁêÜÊ®°Âùó„ÄÅÂºÇÊ≠•ÊâßË°åÊ®°Âùó„ÄÅËØÑ‰º∞Ê®°ÂùóÂíåËÆ≠ÁªÉÊ®°Âùó„ÄÇÂ∑•ÂÖ∑ÁÆ°ÁêÜÊ®°ÂùóË¥üË¥£‰∏çÂêåÂ∑•ÂÖ∑ÁöÑÁªü‰∏ÄÁÆ°ÁêÜÔºåÂºÇÊ≠•ÊâßË°åÊ®°ÂùóÊ∂àÈô§ÂêåÊ≠•Áì∂È¢àÔºåËØÑ‰º∞Ê®°ÂùóÁî®‰∫éÊÄßËÉΩÊØîËæÉÔºåËÆ≠ÁªÉÊ®°ÂùóÂàôÊèê‰æõÁªü‰∏ÄÁöÑËÆ≠ÁªÉÂü∫Á°ÄËÆæÊñΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöVerlToolÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Ê®°ÂùóÂåñÊèí‰ª∂Êû∂ÊûÑÔºåÂÖÅËÆ∏Âø´ÈÄüÈõÜÊàêÊñ∞Â∑•ÂÖ∑Ôºå‰∏îÂè™ÈúÄËΩªÈáèÁ∫ßÁöÑPythonÂÆö‰πâ„ÄÇËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÂõ∫ÂÆöÂíåÂ§çÊùÇÈõÜÊàêÊñπÂºèÂΩ¢ÊàêÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂèÇÊï∞ËÆæÁΩÆ‰∏äÔºåVerlToolÈááÁî®‰∫ÜÊ†áÂáÜÂåñÁöÑAPIËÆæËÆ°ÔºåÊîØÊåÅÂ§öÁßçÊ®°ÊÄÅÁöÑÂ∑•ÂÖ∑‰ΩøÁî®ÔºåÂ¶Ç‰ª£Á†ÅÊâßË°å„ÄÅÊêúÁ¥¢„ÄÅSQLÊï∞ÊçÆÂ∫ìÂíåËßÜËßâÂ§ÑÁêÜ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåÂÖ∑‰ΩìÁªÜËäÇÂú®ËÆ∫Êñá‰∏≠ËøõË°å‰∫ÜËØ¶ÁªÜÊèèËø∞„ÄÇÊï¥‰ΩìËÆæËÆ°Êó®Âú®Èôç‰ΩéÂºÄÂèëÂºÄÈîÄÂπ∂Êèê‰æõÂèØÊâ©Â±ïÁöÑÂü∫Á°Ä„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåVerlToolÂú®Êï∞Â≠¶Êé®ÁêÜ„ÄÅÁü•ËØÜÈóÆÁ≠î„ÄÅSQLÁîüÊàê„ÄÅËßÜËßâÊé®ÁêÜ„ÄÅÁΩëÈ°µÊêúÁ¥¢ÂíåËΩØ‰ª∂Â∑•Á®ãÁ≠â6‰∏™È¢ÜÂüüË°®Áé∞Âá∫Ëâ≤ÔºåËææÂà∞‰∫Ü‰∏é‰∏ìÁî®Á≥ªÁªüÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºå‰∏îÈÄöËøáÂºÇÊ≠•ÊâßË°åÂÆûÁé∞‰∫ÜËøë2ÂÄçÁöÑÈÄüÂ∫¶ÊèêÂçáÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

VerlToolÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÂä©Êâã„ÄÅËá™Âä®ÂåñËΩØ‰ª∂ÂºÄÂèë„ÄÅÊï∞ÊçÆÂàÜÊûêÂíåÂ§öÊ®°ÊÄÅ‰∫§‰∫íÁ≥ªÁªüÁ≠â„ÄÇÂÖ∂Ê®°ÂùóÂåñËÆæËÆ°ÂíåÈ´òÊïàÁöÑÂ∑•ÂÖ∑ÈõÜÊàêËÉΩÂäõÔºå‰ΩøÂæóÁ†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖËÉΩÂ§üÂø´ÈÄüÊûÑÂª∫ÂíåÊµãËØïÊñ∞ÁöÑÂ∑•ÂÖ∑Â¢ûÂº∫ÂûãÂº∫ÂåñÂ≠¶‰π†Ê®°ÂûãÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•ÂíåÂ∫îÁî®ËêΩÂú∞„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated success in enhancing LLM reasoning capabilities, but remains limited to single-turn interactions without tool integration. While recent Agentic Reinforcement Learning with Tool use (ARLT) approaches have emerged to address multi-turn tool interactions, existing works develop task-specific codebases that suffer from fragmentation, synchronous execution bottlenecks, and limited extensibility across domains. These inefficiencies hinder broader community adoption and algorithmic innovation. We introduce VerlTool, a unified and modular framework that addresses these limitations through systematic design principles. VerlTool provides four key contributions: (1) upstream alignment with VeRL ensuring compatibility and simplified maintenance, (2) unified tool management via standardized APIs supporting diverse modalities including code execution, search, SQL databases, and vision processing, (3) asynchronous rollout execution achieving near 2$\times$ speedup by eliminating synchronization bottlenecks, and (4) comprehensive evaluation demonstrating competitive performance across 6 ARLT domains. Our framework formalizes ARLT as multi-turn trajectories with multi-modal observation tokens (text/image/video), extending beyond single-turn RLVR paradigms. We train and evaluate models on mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web search, and software engineering tasks, achieving results comparable to specialized systems while providing unified training infrastructure. The modular plugin architecture enables rapid tool integration requiring only lightweight Python definitions, significantly reducing development overhead and providing a scalable foundation for tool-augmented RL research. Our code is open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.

