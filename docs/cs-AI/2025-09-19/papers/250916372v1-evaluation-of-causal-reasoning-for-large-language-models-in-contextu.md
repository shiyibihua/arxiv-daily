---
layout: default
title: Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation
---

# Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16372" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16372v1</a>
  <a href="https://arxiv.org/pdf/2509.16372.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16372v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16372v1', 'Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Balu Bhasuran, Mattia Prosperi, Karim Hanna, John Petrilli, Caretia JeLayne Washington, Zhe He

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å®éªŒå®¤æµ‹è¯•è§£è¯»æƒ…å¢ƒä¸‹çš„å› æœæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å› æœæ¨ç†` `ä¸´åºŠåŒ»å­¦` `å®éªŒå®¤æµ‹è¯•` `åŒ»å­¦è¯Šæ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠåœºæ™¯ä¸‹çš„å› æœæ¨ç†èƒ½åŠ›å°šä¸æ˜ç¡®ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„è¯„ä¼°æ–¹æ³•ã€‚
2. æœ¬ç ”ç©¶æ„å»ºäº†ä¸Pearlå› æœé˜¶æ¢¯å¯¹é½çš„ä¸´åºŠåœºæ™¯ï¼Œç”¨äºè¯„ä¼°LLMåœ¨å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†ä¸Šçš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜GPT-o1åœ¨å› æœæ¨ç†æ–¹é¢ä¼˜äºLlama-3.2-8b-instructï¼Œä½†åœ¨åäº‹å®æ¨ç†ä¸Šä»æœ‰æå‡ç©ºé—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶ä½¿ç”¨99ä¸ªä¸´åºŠå®éªŒå®¤æµ‹è¯•åœºæ™¯è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å› æœæ¨ç†èƒ½åŠ›ï¼Œè¿™äº›åœºæ™¯ä¸Pearlçš„å› æœå…³ç³»é˜¶æ¢¯å¯¹é½ï¼Œæ¶µç›–å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†ã€‚æˆ‘ä»¬è€ƒå¯Ÿäº†å¸¸è§çš„å®éªŒå®¤æµ‹è¯•ï¼Œå¦‚ç³–åŒ–è¡€çº¢è›‹ç™½ã€è‚Œé…å’Œç»´ç”Ÿç´ Dï¼Œå¹¶å°†å®ƒä»¬ä¸ç›¸å…³çš„å› æœå› ç´ é…å¯¹ï¼ŒåŒ…æ‹¬å¹´é¾„ã€æ€§åˆ«ã€è‚¥èƒ–å’Œå¸çƒŸã€‚æµ‹è¯•äº†ä¸¤ä¸ªLLMâ€”â€”GPT-o1å’ŒLlama-3.2-8b-instructï¼Œå¹¶ç”±å››ä½å—è¿‡åŒ»å­¦è®­ç»ƒçš„äººç±»ä¸“å®¶è¯„ä¼°äº†å›å¤ã€‚GPT-o1è¡¨ç°å‡ºæ›´å¼ºçš„åˆ¤åˆ«æ€§èƒ½ï¼ˆæ€»ä½“AUROC = 0.80 +/- 0.12ï¼‰ï¼Œè€ŒLlama-3.2-8b-instructä¸ºï¼ˆ0.73 +/- 0.15ï¼‰ï¼ŒGPT-o1åœ¨å…³è”ï¼ˆ0.75 vs 0.72ï¼‰ã€å¹²é¢„ï¼ˆ0.84 vs 0.70ï¼‰å’Œåäº‹å®æ¨ç†ï¼ˆ0.84 vs 0.69ï¼‰æ–¹é¢å¾—åˆ†æ›´é«˜ã€‚GPT-o1çš„æ•æ„Ÿæ€§ï¼ˆ0.90 vs 0.84ï¼‰å’Œç‰¹å¼‚æ€§ï¼ˆ0.93 vs 0.80ï¼‰ä¹Ÿæ›´é«˜ï¼Œæ¨ç†è¯„åˆ†æ˜¾ç¤ºå‡ºç±»ä¼¼çš„è¶‹åŠ¿ã€‚ä¸¤ç§æ¨¡å‹åœ¨å¹²é¢„é—®é¢˜ä¸Šè¡¨ç°æœ€ä½³ï¼Œåœ¨åäº‹å®é—®é¢˜ä¸Šè¡¨ç°æœ€å·®ï¼Œå°¤å…¶æ˜¯åœ¨æ”¹å˜ç»“æœçš„åœºæ™¯ä¸­ã€‚è¿™äº›å‘ç°è¡¨æ˜GPT-o1æä¾›äº†æ›´ä¸€è‡´çš„å› æœæ¨ç†ï¼Œä½†åœ¨é«˜é£é™©ä¸´åºŠåº”ç”¨ä¸­é‡‡ç”¨ä¹‹å‰éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸´åºŠèƒŒæ™¯ä¸‹ï¼Œç‰¹åˆ«æ˜¯å®éªŒå®¤æµ‹è¯•ç»“æœè§£è¯»ä¸­çš„å› æœæ¨ç†èƒ½åŠ›ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹LLMå› æœæ¨ç†èƒ½åŠ›çš„ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠä¸´åºŠåŒ»å­¦çŸ¥è¯†çš„å¤æ‚åœºæ™¯ä¸­ã€‚ç°æœ‰çš„LLMå¯èƒ½æ— æ³•å‡†ç¡®æ•æ‰ä¸´åºŠå˜é‡ä¹‹é—´çš„å› æœå…³ç³»ï¼Œå¯¼è‡´é”™è¯¯çš„è¯Šæ–­æˆ–æ²»ç–—å»ºè®®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Pearlçš„å› æœé˜¶æ¢¯ï¼ˆå…³è”ã€å¹²é¢„ã€åäº‹å®ï¼‰æ„å»ºä¸€ç³»åˆ—ä¸´åºŠåœºæ™¯ï¼Œå¹¶ä»¥æ­¤æ¥æµ‹è¯•LLMçš„å› æœæ¨ç†èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ä¸åŒç±»å‹çš„å› æœé—®é¢˜ï¼Œå¯ä»¥æ›´å…¨é¢åœ°è¯„ä¼°LLMåœ¨ç†è§£å’Œåº”ç”¨ä¸´åºŠå› æœå…³ç³»æ–¹é¢çš„èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿé‡åŒ–LLMåœ¨ä¸åŒå› æœæ¨ç†å±‚æ¬¡ä¸Šçš„è¡¨ç°ï¼Œä»è€Œå‘ç°å…¶ä¼˜åŠ¿å’Œä¸è¶³ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) æ„å»ºä¸´åºŠåœºæ™¯ï¼šåŸºäºå¸¸è§çš„å®éªŒå®¤æµ‹è¯•ï¼ˆå¦‚ç³–åŒ–è¡€çº¢è›‹ç™½ã€è‚Œé…ã€ç»´ç”Ÿç´ Dï¼‰å’Œç›¸å…³çš„å› æœå› ç´ ï¼ˆå¦‚å¹´é¾„ã€æ€§åˆ«ã€è‚¥èƒ–ã€å¸çƒŸï¼‰ï¼Œè®¾è®¡99ä¸ªä¸´åºŠåœºæ™¯ã€‚2) è®¾è®¡å› æœé—®é¢˜ï¼šæ¯ä¸ªåœºæ™¯éƒ½åŒ…å«å…³è”ã€å¹²é¢„å’Œåäº‹å®ä¸‰ç§ç±»å‹çš„å› æœé—®é¢˜ï¼Œä»¥è¯„ä¼°LLMåœ¨ä¸åŒå› æœæ¨ç†å±‚æ¬¡ä¸Šçš„è¡¨ç°ã€‚3) æ¨¡å‹æµ‹è¯•ï¼šä½¿ç”¨GPT-o1å’ŒLlama-3.2-8b-instructä¸¤ç§LLMå¯¹è¿™äº›é—®é¢˜è¿›è¡Œå›ç­”ã€‚4) äººå·¥è¯„ä¼°ï¼šç”±å››ä½åŒ»å­¦ä¸“å®¶å¯¹LLMçš„å›ç­”è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è®¡ç®—AUROCã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§ç­‰æŒ‡æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ç³»ç»Ÿæ€§åœ°å°†Pearlçš„å› æœé˜¶æ¢¯åº”ç”¨äºè¯„ä¼°LLMåœ¨ä¸´åºŠåœºæ™¯ä¸‹çš„å› æœæ¨ç†èƒ½åŠ›ã€‚2) æ„å»ºäº†ä¸€ä¸ªåŒ…å«99ä¸ªä¸´åºŠåœºæ™¯çš„æµ‹è¯•æ•°æ®é›†ï¼Œæ¶µç›–äº†å¸¸è§çš„å®éªŒå®¤æµ‹è¯•å’Œç›¸å…³çš„å› æœå› ç´ ã€‚3) é€šè¿‡äººå·¥è¯„ä¼°å’Œé‡åŒ–æŒ‡æ ‡ï¼Œå…¨é¢è¯„ä¼°äº†GPT-o1å’ŒLlama-3.2-8b-instructä¸¤ç§LLMåœ¨ä¸åŒå› æœæ¨ç†å±‚æ¬¡ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åœºæ™¯è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡è€ƒè™‘äº†å¤šç§ä¸´åºŠå› ç´ ï¼Œå¹¶ç¡®ä¿æ¯ä¸ªåœºæ™¯éƒ½ä¸çœŸå®çš„ä¸´åºŠå®è·µç›¸å…³ã€‚åœ¨é—®é¢˜è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡æ ¹æ®Pearlçš„å› æœé˜¶æ¢¯ï¼Œè®¾è®¡äº†å…³è”ã€å¹²é¢„å’Œåäº‹å®ä¸‰ç§ç±»å‹çš„å› æœé—®é¢˜ï¼Œä»¥è¯„ä¼°LLMåœ¨ä¸åŒå› æœæ¨ç†å±‚æ¬¡ä¸Šçš„è¡¨ç°ã€‚åœ¨æ¨¡å‹è¯„ä¼°æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†AUROCã€æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§ç­‰æŒ‡æ ‡ï¼Œä»¥é‡åŒ–LLMçš„å› æœæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¿˜ä½¿ç”¨äº†äººå·¥è¯„ä¼°æ¥éªŒè¯LLMçš„å›ç­”æ˜¯å¦ç¬¦åˆåŒ»å­¦å¸¸è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-o1åœ¨å› æœæ¨ç†æ–¹é¢ä¼˜äºLlama-3.2-8b-instructï¼Œå…¶æ€»ä½“AUROCä¸º0.80 +/- 0.12ï¼Œè€ŒLlama-3.2-8b-instructä¸º0.73 +/- 0.15ã€‚GPT-o1åœ¨å…³è”ã€å¹²é¢„å’Œåäº‹å®æ¨ç†æ–¹é¢çš„å¾—åˆ†å‡é«˜äºLlama-3.2-8b-instructã€‚ä¸¤ç§æ¨¡å‹åœ¨å¹²é¢„é—®é¢˜ä¸Šè¡¨ç°æœ€ä½³ï¼Œåœ¨åäº‹å®é—®é¢˜ä¸Šè¡¨ç°æœ€å·®ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGPT-o1åœ¨ä¸´åºŠå› æœæ¨ç†æ–¹é¢å…·æœ‰ä¸€å®šçš„æ½œåŠ›ï¼Œä½†ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›ï¼Œå°¤å…¶æ˜¯åœ¨åäº‹å®æ¨ç†æ–¹é¢ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¾…åŠ©ä¸´åºŠå†³ç­–ã€åŒ»å­¦æ•™è‚²å’Œæ‚£è€…å’¨è¯¢ã€‚é€šè¿‡è¯„ä¼°LLMçš„å› æœæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å¥½åœ°ç†è§£å®éªŒå®¤æµ‹è¯•ç»“æœï¼Œå¹¶åšå‡ºæ›´å‡†ç¡®çš„è¯Šæ–­å’Œæ²»ç–—å†³ç­–ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ç”¨äºå¼€å‘åŒ»å­¦æ•™è‚²å·¥å…·ï¼Œå¸®åŠ©åŒ»å­¦ç”Ÿå­¦ä¹ å’ŒæŒæ¡ä¸´åºŠå› æœå…³ç³»ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨LLMåœ¨åŒ»ç–—é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ï¼Œæé«˜åŒ»ç–—æœåŠ¡çš„è´¨é‡å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study evaluates causal reasoning in large language models (LLMs) using 99 clinically grounded laboratory test scenarios aligned with Pearl's Ladder of Causation: association, intervention, and counterfactual reasoning. We examined common laboratory tests such as hemoglobin A1c, creatinine, and vitamin D, and paired them with relevant causal factors including age, gender, obesity, and smoking. Two LLMs - GPT-o1 and Llama-3.2-8b-instruct - were tested, with responses evaluated by four medically trained human experts. GPT-o1 demonstrated stronger discriminative performance (AUROC overall = 0.80 +/- 0.12) compared to Llama-3.2-8b-instruct (0.73 +/- 0.15), with higher scores across association (0.75 vs 0.72), intervention (0.84 vs 0.70), and counterfactual reasoning (0.84 vs 0.69). Sensitivity (0.90 vs 0.84) and specificity (0.93 vs 0.80) were also greater for GPT-o1, with reasoning ratings showing similar trends. Both models performed best on intervention questions and worst on counterfactuals, particularly in altered outcome scenarios. These findings suggest GPT-o1 provides more consistent causal reasoning, but refinement is required before adoption in high-stakes clinical applications.

