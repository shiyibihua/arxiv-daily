---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-09-19
---

# cs.AIï¼ˆ2025-09-19ï¼‰

ğŸ“Š å…± **24** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ğŸ”—3)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251008581v1-evaluating-hallucinations-in-multimodal-llms-with-spoken-queries-und.html">Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse Acoustic Conditions</a></td>
  <td>æå‡ºRePOPE-SpkåŸºå‡†ï¼Œè¯„ä¼°è¯­éŸ³æŸ¥è¯¢ä¸‹å¤šæ¨¡æ€LLMçš„å¹»è§‰é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.08581v1" data-paper-url="./papers/251008581v1-evaluating-hallucinations-in-multimodal-llms-with-spoken-queries-und.html" onclick="toggleFavorite(this, '2510.08581v1', 'Evaluating Hallucinations in Multimodal LLMs with Spoken Queries under Diverse Acoustic Conditions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250915635v1-microrca-agent-microservice-root-cause-analysis-method-based-on-larg.html">MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents</a></td>
  <td>æå‡ºMicroRCA-Agentï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹Agentè¿›è¡Œå¾®æœåŠ¡æ ¹å› åˆ†æ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15635v1" data-paper-url="./papers/250915635v1-microrca-agent-microservice-root-cause-analysis-method-based-on-larg.html" onclick="toggleFavorite(this, '2509.15635v1', 'MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250916372v1-evaluation-of-causal-reasoning-for-large-language-models-in-contextu.html">Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation</a></td>
  <td>è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨å®éªŒå®¤æµ‹è¯•è§£è¯»æƒ…å¢ƒä¸‹çš„å› æœæ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16372v1" data-paper-url="./papers/250916372v1-evaluation-of-causal-reasoning-for-large-language-models-in-contextu.html" onclick="toggleFavorite(this, '2509.16372v1', 'Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250916330v1-generalizability-of-large-language-model-based-agents-a-comprehensiv.html">Generalizability of Large Language Model-Based Agents: A Comprehensive Survey</a></td>
  <td>å…¨é¢ç»¼è¿°ï¼šæå‡åŸºäºå¤§è¯­è¨€æ¨¡å‹Agentçš„æ³›åŒ–èƒ½åŠ›ï¼Œåº”å¯¹å¤šæ ·åŒ–ä»»åŠ¡ä¸ç¯å¢ƒã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16330v1" data-paper-url="./papers/250916330v1-generalizability-of-large-language-model-based-agents-a-comprehensiv.html" onclick="toggleFavorite(this, '2509.16330v1', 'Generalizability of Large Language Model-Based Agents: A Comprehensive Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250916297v1-how-large-language-models-are-designed-to-hallucinate.html">How Large Language Models are Designed to Hallucinate</a></td>
  <td>æ­ç¤ºå¤§è¯­è¨€æ¨¡å‹å¹»è§‰çš„ç»“æ„æ€§æ ¹æºï¼Œæå‡ºåŸºäºå­˜åœ¨ä¸»ä¹‰ç»“æ„çš„å¹»è§‰åˆ†ç±»ä¸è¯„æµ‹åŸºå‡†ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16297v1" data-paper-url="./papers/250916297v1-how-large-language-models-are-designed-to-hallucinate.html" onclick="toggleFavorite(this, '2509.16297v1', 'How Large Language Models are Designed to Hallucinate')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250915957v1-ehr-mcp-real-world-evaluation-of-clinical-information-retrieval-by-l.html">EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol</a></td>
  <td>EHR-MCPï¼šé€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼Œåœ¨çœŸå®åŒ»é™¢ç¯å¢ƒä¸­è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠä¿¡æ¯æ£€ç´¢ä¸­çš„åº”ç”¨</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15957v1" data-paper-url="./papers/250915957v1-ehr-mcp-real-world-evaluation-of-clinical-information-retrieval-by-l.html" onclick="toggleFavorite(this, '2509.15957v1', 'EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250915510v1-the-short-term-effects-of-large-language-models-on-unemployment-and-.html">The (Short-Term) Effects of Large Language Models on Unemployment and Earnings</a></td>
  <td>åŸºäºåˆæˆå·®åˆ†æ³•åˆ†æå¤§å‹è¯­è¨€æ¨¡å‹å¯¹å°±ä¸šå’Œæ”¶å…¥çš„çŸ­æœŸå½±å“</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15510v1" data-paper-url="./papers/250915510v1-the-short-term-effects-of-large-language-models-on-unemployment-and-.html" onclick="toggleFavorite(this, '2509.15510v1', 'The (Short-Term) Effects of Large Language Models on Unemployment and Earnings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250916456v2-gpo-learning-from-critical-steps-to-improve-llm-reasoning.html">GPO: Learning from Critical Steps to Improve LLM Reasoning</a></td>
  <td>GPOï¼šé€šè¿‡å­¦ä¹ å…³é”®æ­¥éª¤æå‡å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16456v2" data-paper-url="./papers/250916456v2-gpo-learning-from-critical-steps-to-improve-llm-reasoning.html" onclick="toggleFavorite(this, '2509.16456v2', 'GPO: Learning from Critical Steps to Improve LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250916443v1-lightcode-compiling-llm-inference-for-photonic-electronic-systems.html">LightCode: Compiling LLM Inference for Photonic-Electronic Systems</a></td>
  <td>LightCodeï¼šç”¨äºå…‰å­-ç”µå­ç³»ç»Ÿçš„LLMæ¨ç†ç¼–è¯‘æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16443v1" data-paper-url="./papers/250916443v1-lightcode-compiling-llm-inference-for-photonic-electronic-systems.html" onclick="toggleFavorite(this, '2509.16443v1', 'LightCode: Compiling LLM Inference for Photonic-Electronic Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250916437v1-sense-7-taxonomy-and-dataset-for-measuring-user-perceptions-of-empat.html">SENSE-7: Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations</a></td>
  <td>æå‡ºSENSE-7æ•°æ®é›†ä¸ç§»æƒ…åˆ†ç±»å™¨ï¼Œç”¨äºè¡¡é‡ç”¨æˆ·åœ¨äººæœºå¯¹è¯ä¸­å¯¹AIç§»æƒ…çš„æ„ŸçŸ¥ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16437v1" data-paper-url="./papers/250916437v1-sense-7-taxonomy-and-dataset-for-measuring-user-perceptions-of-empat.html" onclick="toggleFavorite(this, '2509.16437v1', 'SENSE-7: Taxonomy and Dataset for Measuring User Perceptions of Empathy in Sustained Human-AI Conversations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250916332v1-psychometric-personality-shaping-modulates-capabilities-and-safety-i.html">Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models</a></td>
  <td>é€šè¿‡å¡‘é€ å¿ƒç†äººæ ¼ç‰¹å¾æ¥è°ƒèŠ‚è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›å’Œå®‰å…¨æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16332v1" data-paper-url="./papers/250916332v1-psychometric-personality-shaping-modulates-capabilities-and-safety-i.html" onclick="toggleFavorite(this, '2509.16332v1', 'Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250915541v1-stress-testing-deliberative-alignment-for-anti-scheming-training.html">Stress Testing Deliberative Alignment for Anti-Scheming Training</a></td>
  <td>å‹åŠ›æµ‹è¯•å®¡æ…å¯¹é½æ–¹æ³•ï¼Œè¯„ä¼°å…¶åœ¨åæ¬ºéª—è®­ç»ƒä¸­çš„æœ‰æ•ˆæ€§</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15541v1" data-paper-url="./papers/250915541v1-stress-testing-deliberative-alignment-for-anti-scheming-training.html" onclick="toggleFavorite(this, '2509.15541v1', 'Stress Testing Deliberative Alignment for Anti-Scheming Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250916348v1-a-unified-ai-approach-for-continuous-monitoring-of-human-health-and-.html">A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+)</a></td>
  <td>UNIPHY+ï¼šç”¨äºè¿ç»­ç›‘æµ‹äººç±»å¥åº·å’Œç–¾ç—…çš„ç»Ÿä¸€ç”Ÿç†åŸºç¡€æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16348v1" data-paper-url="./papers/250916348v1-a-unified-ai-approach-for-continuous-monitoring-of-human-health-and-.html" onclick="toggleFavorite(this, '2509.16348v1', 'A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+)')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250916399v1-vortex-aligning-task-utility-and-human-preferences-through-llm-guide.html">VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping</a></td>
  <td>VORTEXï¼šé€šè¿‡LLMå¼•å¯¼çš„å¥–åŠ±å¡‘é€ å¯¹é½ä»»åŠ¡æ•ˆç”¨å’Œäººç±»åå¥½</td>
  <td class="tags-cell"><span class="paper-tag">reward shaping</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16399v1" data-paper-url="./papers/250916399v1-vortex-aligning-task-utility-and-human-preferences-through-llm-guide.html" onclick="toggleFavorite(this, '2509.16399v1', 'VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250915661v1-sightsound-r1-cross-modal-reasoning-distillation-from-vision-to-audi.html">SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models</a></td>
  <td>æå‡ºSightSound-R1ï¼Œé€šè¿‡è·¨æ¨¡æ€è’¸é¦æå‡å¬è§‰è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å£°æ™¯ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15661v1" data-paper-url="./papers/250915661v1-sightsound-r1-cross-modal-reasoning-distillation-from-vision-to-audi.html" onclick="toggleFavorite(this, '2509.15661v1', 'SightSound-R1: Cross-Modal Reasoning Distillation from Vision to Audio Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250918198v1-mmcd-multi-modal-collaborative-decision-making-for-connected-autonom.html">MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation</a></td>
  <td>æå‡ºMMCDæ¡†æ¶ï¼Œåˆ©ç”¨å¤šæ¨¡æ€çŸ¥è¯†è’¸é¦æå‡äº’è”è‡ªåŠ¨é©¾é©¶åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„å†³ç­–èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">teacher-student</span> <span class="paper-tag">distillation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.18198v1" data-paper-url="./papers/250918198v1-mmcd-multi-modal-collaborative-decision-making-for-connected-autonom.html" onclick="toggleFavorite(this, '2509.18198v1', 'MMCD: Multi-Modal Collaborative Decision-Making for Connected Autonomy with Knowledge Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250916195v1-focalcodec-stream-streaming-low-bitrate-speech-coding-via-causal-dis.html">FocalCodec-Stream: Streaming Low-Bitrate Speech Coding via Causal Distillation</a></td>
  <td>æå‡ºFocalCodec-Streamï¼Œé€šè¿‡å› æœè’¸é¦å®ç°ä½ç ç‡æµå¼è¯­éŸ³ç¼–ç </td>
  <td class="tags-cell"><span class="paper-tag">distillation</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16195v1" data-paper-url="./papers/250916195v1-focalcodec-stream-streaming-low-bitrate-speech-coding-via-causal-dis.html" onclick="toggleFavorite(this, '2509.16195v1', 'FocalCodec-Stream: Streaming Low-Bitrate Speech Coding via Causal Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250916184v1-accelerating-atomic-fine-structure-determination-with-graph-reinforc.html">Accelerating Atomic Fine Structure Determination with Graph Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºå›¾å¼ºåŒ–å­¦ä¹ çš„åŸå­ç²¾ç»†ç»“æ„ç¡®å®šåŠ é€Ÿæ–¹æ³•ï¼Œæå‡ç­‰ç¦»å­ä½“è¯Šæ–­æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16184v1" data-paper-url="./papers/250916184v1-accelerating-atomic-fine-structure-determination-with-graph-reinforc.html" onclick="toggleFavorite(this, '2509.16184v1', 'Accelerating Atomic Fine Structure Determination with Graph Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250915952v2-compose-yourself-average-velocity-flow-matching-for-one-step-speech-.html">Compose Yourself: Average-Velocity Flow Matching for One-Step Speech Enhancement</a></td>
  <td>æå‡ºCOSEï¼šä¸€ç§åŸºäºå¹³å‡é€Ÿåº¦æµåŒ¹é…çš„å•æ­¥è¯­éŸ³å¢å¼ºæ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15952v2" data-paper-url="./papers/250915952v2-compose-yourself-average-velocity-flow-matching-for-one-step-speech-.html" onclick="toggleFavorite(this, '2509.15952v2', 'Compose Yourself: Average-Velocity Flow Matching for One-Step Speech Enhancement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250915942v1-archesclimate-probabilistic-decadal-ensemble-generation-with-flow-ma.html">ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching</a></td>
  <td>ArchesClimateï¼šåˆ©ç”¨Flow Matchingç”Ÿæˆæ¦‚ç‡æ€§å¹´ä»£é™…é›†åˆæ°”å€™é¢„æµ‹ï¼Œé™ä½è®¡ç®—æˆæœ¬ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15942v1" data-paper-url="./papers/250915942v1-archesclimate-probabilistic-decadal-ensemble-generation-with-flow-ma.html" onclick="toggleFavorite(this, '2509.15942v1', 'ArchesClimate: Probabilistic Decadal Ensemble Generation With Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250915690v1-ccrepairbench-a-high-fidelity-benchmark-and-reinforcement-learning-f.html">CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair</a></td>
  <td>æå‡ºCCrepairBenchï¼Œç”¨äºC++ç¼–è¯‘é”™è¯¯ä¿®å¤çš„é«˜ä¿çœŸåŸºå‡†å’Œå¼ºåŒ–å­¦ä¹ æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15690v1" data-paper-url="./papers/250915690v1-ccrepairbench-a-high-fidelity-benchmark-and-reinforcement-learning-f.html" onclick="toggleFavorite(this, '2509.15690v1', 'CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250915570v1-contrastive-learning-with-spectrum-information-augmentation-in-abnor.html">Contrastive Learning with Spectrum Information Augmentation in Abnormal Sound Detection</a></td>
  <td>æå‡ºåŸºäºé¢‘è°±ä¿¡æ¯å¢å¼ºçš„å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå¼‚å¸¸å£°éŸ³æ£€æµ‹ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15570v1" data-paper-url="./papers/250915570v1-contrastive-learning-with-spectrum-information-augmentation-in-abnor.html" onclick="toggleFavorite(this, '2509.15570v1', 'Contrastive Learning with Spectrum Information Augmentation in Abnormal Sound Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250915962v1-structured-information-for-improving-spatial-relationships-in-text-t.html">Structured Information for Improving Spatial Relationships in Text-to-Image Generation</a></td>
  <td>æå‡ºä¸€ç§è½»é‡çº§ç»“æ„åŒ–ä¿¡æ¯å¢å¼ºæ–¹æ³•ï¼Œæå‡æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­ç©ºé—´å…³ç³»å‡†ç¡®æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">spatial relationship</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15962v1" data-paper-url="./papers/250915962v1-structured-information-for-improving-spatial-relationships-in-text-t.html" onclick="toggleFavorite(this, '2509.15962v1', 'Structured Information for Improving Spatial Relationships in Text-to-Image Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>24</td>
  <td><a href="./papers/250916058v1-attention-schema-based-attention-control-asac-a-cognitive-inspired-a.html">Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers</a></td>
  <td>æå‡ºåŸºäºæ³¨æ„åŠ›æ¨¡å¼çš„æ³¨æ„åŠ›æ§åˆ¶ï¼ˆASACï¼‰æ¨¡å—ï¼Œæå‡Transformeræ¨¡å‹çš„æ³¨æ„åŠ›å’Œå­¦ä¹ æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">VQ-VAE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16058v1" data-paper-url="./papers/250916058v1-attention-schema-based-attention-control-asac-a-cognitive-inspired-a.html" onclick="toggleFavorite(this, '2509.16058v1', 'Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)