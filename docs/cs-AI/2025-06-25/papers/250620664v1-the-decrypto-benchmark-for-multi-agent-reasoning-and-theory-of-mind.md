---
layout: default
title: The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind
---

# The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20664" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20664v1</a>
  <a href="https://arxiv.org/pdf/2506.20664.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20664v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20664v1', 'The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrei Lupu, Timon Willi, Jakob Foerster

**åˆ†ç±»**: cs.AI, cs.CL, cs.HC, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: 41 pages, 19 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDecryptoåŸºå‡†ä»¥è§£å†³å¤šæ™ºèƒ½ä½“æ¨ç†ä¸å¿ƒæ™ºç†è®ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“æ¨ç†` `å¿ƒæ™ºç†è®º` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¸¸æˆåŸºå‡†` `è®¤çŸ¥ç§‘å­¦` `å¼ºåŒ–å­¦ä¹ ` `äººå·¥æ™ºèƒ½ä»£ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ™ºèƒ½ä½“æ¨ç†å’Œå¿ƒæ™ºç†è®ºè¯„ä¼°åŸºå‡†å­˜åœ¨èŒƒå›´ç‹­çª„ã€æ•°æ®æ³„éœ²å’Œç¼ºä¹äº’åŠ¨ç­‰é—®é¢˜ã€‚
2. DecryptoåŸºå‡†é€šè¿‡æ¸¸æˆåŒ–è®¾è®¡ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªæ¸…æ™°ã€æ— æ··æ·†å› ç´ çš„å¤šæ™ºèƒ½ä½“æ¨ç†ä¸ToMè¯„ä¼°å¹³å°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æœ€å…ˆè¿›çš„æ¨ç†æ¨¡å‹åœ¨ToMä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸å¦‚æ—©æœŸæ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºDecryptoçš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å…·å¤‡ä»£ç†èƒ½åŠ›ï¼Œå®ƒä»¬éœ€è¦åœ¨å¤æ‚çš„å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­ä¸äººç±»ç”¨æˆ·åŠå…¶ä»–æ™ºèƒ½ä½“è¿›è¡Œäº’åŠ¨ã€‚è¿™è¦æ±‚æ–°çš„æ¨ç†æŠ€èƒ½ï¼Œå°¤å…¶æ˜¯å¿ƒæ™ºç†è®ºï¼ˆToMï¼‰ï¼Œå³æ¨ç†å…¶ä»–æ™ºèƒ½ä½“â€œå¿ƒç†â€çŠ¶æ€çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºå‡†åœ¨ToMåŠå…¶ä»–å¤šæ™ºèƒ½ä½“èƒ½åŠ›çš„è¯„ä¼°ä¸Šå­˜åœ¨ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Decryptoï¼Œä¸€ä¸ªåŸºäºæ¸¸æˆçš„å¤šæ™ºèƒ½ä½“æ¨ç†ä¸ToMåŸºå‡†ï¼Œæ—¨åœ¨æ¶ˆé™¤ç°æœ‰åŸºå‡†ä¸­çš„æ··æ·†å› ç´ ã€‚é€šè¿‡å¯¹å‰æ²¿LLMsçš„å…¨é¢è¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°å…¶æ¸¸æˆèƒ½åŠ›è½åäºäººç±»å’Œç®€å•çš„è¯åµŒå…¥åŸºçº¿ã€‚Decryptoå¡«è¡¥äº†å½“å‰æ¨ç†ä¸ToMè¯„ä¼°ä¸­çš„é‡è¦ç©ºç™½ï¼Œä¸ºæ›´å¥½çš„äººå·¥æ™ºèƒ½ä»£ç†é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ™ºèƒ½ä½“åœºæ™¯ä¸­æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰åŸºå‡†å­˜åœ¨èŒƒå›´ç‹­çª„ã€æ•°æ®æ³„éœ²å’Œç¼ºä¹äº’åŠ¨ç­‰ç—›ç‚¹ï¼Œå¯¼è‡´å¯¹ToMèƒ½åŠ›çš„è¯„ä¼°ä¸å¤Ÿå…¨é¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDecryptoåŸºå‡†é€šè¿‡æ¸¸æˆåŒ–çš„æ–¹å¼è®¾è®¡ï¼Œçµæ„Ÿæ¥æºäºè®¤çŸ¥ç§‘å­¦å’Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼Œæ—¨åœ¨æä¾›ä¸€ä¸ªæ˜“äºè¯„ä¼°çš„ç¯å¢ƒï¼Œæ¶ˆé™¤å…¶ä»–åŸºå‡†ä¸­çš„æ··æ·†å› ç´ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDecryptoçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯æ¸¸æˆç¯å¢ƒçš„è®¾è®¡ï¼Œå…¶æ¬¡æ˜¯æ™ºèƒ½ä½“ä¸ç¯å¢ƒçš„äº’åŠ¨ï¼Œæœ€åæ˜¯è¯„ä¼°æ™ºèƒ½ä½“åœ¨æ¨ç†å’ŒToMä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šDecryptoæ˜¯é¦–ä¸ªä¸“é—¨ä¸ºè®¾è®¡äº’åŠ¨æ€§ToMå®éªŒè€Œæ„å»ºçš„å¹³å°ï¼Œå¡«è¡¥äº†ç°æœ‰è¯„ä¼°ä¸­çš„é‡è¦ç©ºç™½ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå®ƒæä¾›äº†æ›´ä¸ºæ¸…æ™°å’Œå¯æ§çš„è¯„ä¼°ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒDecryptoé‡‡ç”¨äº†ç‰¹å®šçš„æ¸¸æˆè§„åˆ™å’Œä»»åŠ¡è®¾ç½®ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ï¼ŒåŒæ—¶é¿å…äº†å¸¸è§çš„è¯„ä¼°æ··æ·†å› ç´ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„LLMsåœ¨DecryptoåŸºå‡†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä½äºäººç±»å’Œç®€å•çš„è¯åµŒå…¥åŸºçº¿ï¼Œè¡¨æ˜å…¶åœ¨å¤šæ™ºèƒ½ä½“æ¨ç†å’Œå¿ƒæ™ºç†è®ºä»»åŠ¡ä¸­çš„èƒ½åŠ›ä»æœ‰å¾…æå‡ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†Decryptoåœ¨æ¨åŠ¨äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DecryptoåŸºå‡†çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººå·¥æ™ºèƒ½ä»£ç†çš„å¼€å‘ã€æ™ºèƒ½ä½“é—´çš„åä½œä¸ç«äº‰ç ”ç©¶ï¼Œä»¥åŠå¿ƒæ™ºç†è®ºç›¸å…³çš„è®¤çŸ¥ç§‘å­¦å®éªŒã€‚å…¶è®¾è®¡ç†å¿µå’Œè¯„ä¼°æ–¹æ³•å¯ä»¥ä¸ºæœªæ¥çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæä¾›é‡è¦çš„å‚è€ƒï¼Œæ¨åŠ¨æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°æå‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) gain agentic abilities, they will have to navigate complex multi-agent scenarios, interacting with human users and other agents in cooperative and competitive settings. This will require new reasoning skills, chief amongst them being theory of mind (ToM), or the ability to reason about the "mental" states of other agents. However, ToM and other multi-agent abilities in LLMs are poorly understood, since existing benchmarks suffer from narrow scope, data leakage, saturation, and lack of interactivity. We thus propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM drawing inspiration from cognitive science, computational pragmatics and multi-agent reinforcement learning. It is designed to be as easy as possible in all other dimensions, eliminating confounding factors commonly found in other benchmarks. To our knowledge, it is also the first platform for designing interactive ToM experiments.
>   We validate the benchmark design through comprehensive empirical evaluations of frontier LLMs, robustness studies, and human-AI cross-play experiments. We find that LLM game-playing abilities lag behind humans and simple word-embedding baselines. We then create variants of two classic cognitive science experiments within Decrypto to evaluate three key ToM abilities. Surprisingly, we find that state-of-the-art reasoning models are significantly worse at those tasks than their older counterparts. This demonstrates that Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and paves the path towards better artificial agents.

