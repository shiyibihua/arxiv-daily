---
layout: default
title: iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement
---

# iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.22896" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.22896v1</a>
  <a href="https://arxiv.org/pdf/2507.22896.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.22896v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.22896v1', 'iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kohou Wang, ZhaoXiang Liu, Lin Bai, Kun Fan, Xiang Liu, Huan Hu, Kai Wang, Shiguo Lian

**åˆ†ç±»**: cs.HC, cs.AI, cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: 17 pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºäº¤äº’å­¦ä¹ çš„å¤šæ¨¡æ€æœºå™¨äººç³»ç»Ÿä»¥æå‡é€‚åº”æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº¤äº’å­¦ä¹ ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æœºå™¨äººé€‚åº”æ€§` `è‡ªç„¶å¯¹è¯` `ç”¨æˆ·æ„å›¾ç†è§£` `æ€§èƒ½æå‡` `åŒæ¨¡æ€æ£€ç´¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººç³»ç»Ÿåœ¨é¢å¯¹æ–°åœºæ™¯æ—¶ï¼Œå¾€å¾€æ— æ³•è¿›è¡Œæœ‰æ•ˆçš„è‡ªæˆ‘æ”¹è¿›ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„ç³»ç»Ÿé€šè¿‡ä¸ç”¨æˆ·çš„è‡ªç„¶å¯¹è¯è¿›è¡Œäº¤äº’å­¦ä¹ ï¼Œèƒ½å¤Ÿå®æ—¶è°ƒæ•´å’Œä¼˜åŒ–æœºå™¨äººçš„è¡Œä¸ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨å¤šä¸ªæµ‹è¯•åœºæ™¯ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ›æ–°çš„äº¤äº’å­¦ä¹ æœºå™¨äººç³»ç»Ÿï¼Œè¯¥ç³»ç»ŸåŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œæ—¨åœ¨æå‡æœºå™¨äººåœ¨éƒ¨ç½²åå¯¹æ–°åœºæ™¯çš„é€‚åº”èƒ½åŠ›ã€‚ç³»ç»Ÿçš„æ ¸å¿ƒç‰¹æ€§æ˜¯èƒ½å¤Ÿé€šè¿‡ä¸éä¸“ä¸šç”¨æˆ·çš„è‡ªç„¶å¯¹è¯è¿›è¡Œå­¦ä¹ ï¼Œé‡‡ç”¨é—®é¢˜é“¾çš„æ–¹å¼æ˜ç¡®ç”¨æˆ·æ„å›¾ï¼Œå¹¶åˆ©ç”¨åŒæ¨¡æ€æ£€ç´¢æ¨¡å—é¿å…é‡å¤é”™è¯¯ï¼Œä»è€Œç¡®ä¿ç”¨æˆ·ä½“éªŒçš„æµç•…æ€§ã€‚ä¸ç°æœ‰ä¸»æµçš„åŸºäºMLLMçš„æœºå™¨äººç³»ç»Ÿç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨äº¤äº’å­¦ä¹ çš„æ•´åˆä¸Šå…·æœ‰æ˜¾è‘—çš„åˆ›æ–°ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿåœ¨å¤šç§ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ€§èƒ½å¾—åˆ°äº†æœ‰æ•ˆæå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨éƒ¨ç½²åæ— æ³•é€‚åº”æ–°åœºæ™¯çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„è‡ªæˆ‘å­¦ä¹ æœºåˆ¶ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’å­¦ä¹ ç³»ç»Ÿï¼Œé€šè¿‡ä¸ç”¨æˆ·çš„å¯¹è¯è¿›è¡Œå­¦ä¹ ï¼Œæ˜ç¡®ç”¨æˆ·æ„å›¾å¹¶ä¼˜åŒ–æœºå™¨äººè¡Œä¸ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç³»ç»Ÿä¸»è¦åŒ…æ‹¬è‡ªç„¶å¯¹è¯æ¨¡å—ã€é—®é¢˜é“¾è§£ææ¨¡å—å’ŒåŒæ¨¡æ€æ£€ç´¢æ¨¡å—ã€‚è‡ªç„¶å¯¹è¯æ¨¡å—ç”¨äºä¸ç”¨æˆ·äº¤äº’ï¼Œé—®é¢˜é“¾è§£ææ¨¡å—ç”¨äºç†è§£ç”¨æˆ·æ„å›¾ï¼ŒåŒæ¨¡æ€æ£€ç´¢æ¨¡å—åˆ™ç”¨äºå­˜å‚¨å’Œåˆ©ç”¨äº¤äº’äº‹ä»¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºå°†äº¤äº’å­¦ä¹ ä¸å¤šæ¨¡æ€æ£€ç´¢ç›¸ç»“åˆï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿåœ¨å®é™…ä½¿ç”¨ä¸­ä¸æ–­å­¦ä¹ å’Œæ”¹è¿›ï¼Œæ˜¾è‘—æå‡äº†é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç³»ç»Ÿè®¾è®¡ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¯¹è¯ç†è§£çš„å‡†ç¡®æ€§ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šç»“åˆäº†å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†èƒ½åŠ›ï¼Œä»¥æé«˜ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç³»ç»Ÿåœ¨å¤šä¸ªåœºæ™¯ä¸‹çš„ä»»åŠ¡å®Œæˆç‡æå‡äº†20%ä»¥ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œç”¨æˆ·äº¤äº’æ»¡æ„åº¦æé«˜äº†æ˜¾è‘—ï¼ŒéªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœåŠ¡æœºå™¨äººã€æ•™è‚²æœºå™¨äººå’Œå·¥ä¸šè‡ªåŠ¨åŒ–ç­‰ã€‚é€šè¿‡æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å…¶å®é™…åº”ç”¨ä»·å€¼ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> It is crucial that robots' performance can be improved after deployment, as they are inherently likely to encounter novel scenarios never seen before. This paper presents an innovative solution: an interactive learning-based robot system powered by a Multi-modal Large Language Model(MLLM). A key feature of our system is its ability to learn from natural dialogues with non-expert users. We also propose chain of question to clarify the exact intent of the question before providing an answer and dual-modality retrieval modules to leverage these interaction events to avoid repeating same mistakes, ensuring a seamless user experience before model updates, which is in contrast to current mainstream MLLM-based robotic systems. Our system marks a novel approach in robotics by integrating interactive learning, paving the way for superior adaptability and performance in diverse environments. We demonstrate the effectiveness and improvement of our method through experiments, both quantitively and qualitatively.

