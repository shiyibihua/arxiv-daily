---
layout: default
title: SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec
---

# SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02849" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.02849v1</a>
  <a href="https://arxiv.org/pdf/2508.02849.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02849v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02849v1', 'SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Chunyu Qiang, Haoyu Wang, Cheng Gong, Tianrui Wang, Ruibo Fu, Tao Wang, Ruilong Chen, Jiangyan Yi, Zhengqi Wen, Chen Zhang, Longbiao Wang, Jianwu Dang, Jianhua Tao

**ÂàÜÁ±ª**: eess.AS, cs.AI, cs.CL, cs.SD

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-04

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SecoustiCodec‰ª•Ëß£ÂÜ≥ËØ≠Èü≥ÁºñÁ†Å‰∏≠ÁöÑËØ≠‰πâ‰∏éÂâØËØ≠Ë®Ä‰ø°ÊÅØÂàÜÁ¶ªÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËØ≠Èü≥ÁºñËß£Á†Å` `Ë∑®Ê®°ÊÄÅÂØπÈΩê` `‰ΩéÊØîÁâπÁéá` `ËØ≠‰πâËß£ËÄ¶` `ÂØπÊØîÂ≠¶‰π†` `Â§öÈò∂ÊÆµ‰ºòÂåñ` `ÊµÅÂ™í‰ΩìÊäÄÊúØ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâËØ≠Èü≥ÁºñËß£Á†ÅÊñπÊ≥ïÂú®ËØ≠‰πâÁºñÁ†Å‰∏≠Èù¢‰∏¥ÂâØËØ≠Ë®Ä‰ø°ÊÅØÊÆãÁïô„ÄÅËØ≠‰πâÂÆåÊï¥ÊÄß‰∏çË∂≥Á≠âÂ§öÈáçÊåëÊàò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫SecoustiCodecÔºåÈÄöËøáËß£ËÄ¶ËØ≠‰πâ‰∏éÂâØËØ≠Ë®Ä‰ø°ÊÅØÔºåÈááÁî®ÂØπÊØîÂ≠¶‰π†ÂíåÂ§öÈò∂ÊÆµ‰ºòÂåñÁ≠ñÁï•ÊèêÂçáÁºñÁ†ÅË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåSecoustiCodecÂú®0.27/1 kbps‰∏ãÂÆûÁé∞‰∫Ü1.77/2.58ÁöÑÈáçÊûÑË¥®ÈáèÔºåËææÂà∞ÂΩìÂâçÊúÄ‰ºòÊ∞¥Âπ≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËØ≠Èü≥ÁºñËß£Á†ÅÂô®Âú®Áªü‰∏ÄËØ≠Èü≥ÂíåÊñáÊú¨ËØ≠Ë®ÄÊ®°Âûã‰∏≠Ëµ∑ÁùÄÂÖ≥ÈîÆ‰ΩúÁî®„ÄÇÁé∞ÊúâÁºñËß£Á†ÅÊñπÊ≥ïÈù¢‰∏¥ËØ∏Â§öÊåëÊàòÔºåÂ¶ÇÊÆã‰ΩôÁöÑÂâØËØ≠Ë®Ä‰ø°ÊÅØÔºàÂ¶ÇÈü≥Ëâ≤„ÄÅÊÉÖÊÑüÔºâ„ÄÅËØ≠‰πâÂÆåÊï¥ÊÄß‰∏çË∂≥„ÄÅÈáçÊûÑËÉΩÂäõÊúâÈôê‰ª•ÂèäÁº∫‰πèÊµÅÂ™í‰ΩìÊîØÊåÅ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜSecoustiCodecÔºåËøôÊòØ‰∏ÄÁßçË∑®Ê®°ÊÄÅÂØπÈΩêÁöÑ‰ΩéÊØîÁâπÁéáÊµÅÂ™í‰ΩìËØ≠Èü≥ÁºñËß£Á†ÅÂô®ÔºåËÉΩÂ§üÂú®Âçï‰∏Ä‰ª£Á†ÅÊú¨Á©∫Èó¥‰∏≠Ëß£ËÄ¶ËØ≠‰πâÂíåÂâØËØ≠Ë®Ä‰ø°ÊÅØ„ÄÇÈÄöËøáÂºïÂÖ•ÂâØËØ≠Ë®ÄÁºñÁ†ÅÔºåÂº•Ë°•ËØ≠‰πâ‰∏éÂ£∞Â≠¶ÁºñÁ†Å‰πãÈó¥ÁöÑ‰ø°ÊÅØÂ∑ÆË∑ùÔºåÁ°Æ‰øùËØ≠‰πâÂÆåÊï¥ÊÄßÂíåÈáçÊûÑ‰øùÁúüÂ∫¶„ÄÇÊú¨ÊñáËøòÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÂíåÊúâÈôêÊ†áÈáèÈáèÂåñÔºàFSQÔºâÁöÑÈ´òÊïàËØ≠‰πâÈáèÂåñÊñπÊ≥ïÔºåÁºìËß£‰∫Ü‰ª§ÁâåÁöÑÈïøÂ∞æÂàÜÂ∏ÉÈóÆÈ¢òÔºåÂêåÊó∂‰øùÊåÅÈ´ò‰ª£Á†ÅÊú¨Âà©Áî®Áéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËØ≠Èü≥ÁºñËß£Á†ÅÂô®Âú®ËØ≠‰πâ‰∏éÂâØËØ≠Ë®Ä‰ø°ÊÅØÁºñÁ†Å‰∏≠ÁöÑ‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂ¶Ç‰ΩïÊúâÊïàÂàÜÁ¶ªÂíåÈáçÊûÑËøô‰∫õ‰ø°ÊÅØÔºå‰ª•ÊèêÈ´òËØ≠Èü≥Ë¥®ÈáèÂíåËØ≠‰πâÂÆåÊï¥ÊÄß„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÊúâÊïàÂ§ÑÁêÜÂâØËØ≠Ë®Ä‰ø°ÊÅØÔºåÂØºËá¥ÈáçÊûÑÊïàÊûú‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSecoustiCodecÈÄöËøáÂºïÂÖ•ÂâØËØ≠Ë®ÄÁºñÁ†ÅÊù•Âº•Ë°•ËØ≠‰πâ‰∏éÂ£∞Â≠¶ÁºñÁ†Å‰πãÈó¥ÁöÑ‰ø°ÊÅØÂ∑ÆË∑ùÔºåÁ°Æ‰øùËØ≠‰πâÁöÑÂÆåÊï¥ÊÄßÂíåÈáçÊûÑÁöÑ‰øùÁúüÂ∫¶„ÄÇÈááÁî®ÂØπÊØîÂ≠¶‰π†ÊñπÊ≥ïÂÆûÁé∞ËØ≠‰πâÁöÑËß£ËÄ¶ÔºåÁ°Æ‰øùÊñáÊú¨‰∏éËØ≠Èü≥Âú®Â§öÊ®°ÊÄÅÊ°ÜÊû∂‰∏ãÁöÑÂØπÈΩê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSecoustiCodecÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Â§ö‰∏™Ê®°ÂùóÔºöÈ¶ñÂÖàÊòØËØ≠‰πâÁºñÁ†ÅÊ®°ÂùóÔºåÈááÁî®VAEÂíåFSQËøõË°åÈ´òÊïàÈáèÂåñÔºõÂÖ∂Ê¨°ÊòØÂâØËØ≠Ë®ÄÁºñÁ†ÅÊ®°ÂùóÔºåË¥üË¥£ÊèêÂèñÂíåÁºñÁ†ÅÂâØËØ≠Ë®Ä‰ø°ÊÅØÔºõÊúÄÂêéÊòØÂ§öÈò∂ÊÆµ‰ºòÂåñÁ≠ñÁï•ÔºåÁ°Æ‰øùÊ®°ÂûãÁöÑÁ®≥ÂÆöÊî∂Êïõ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑËØ≠‰πâËß£ËÄ¶ÊñπÊ≥ïÔºåÂà©Áî®ÂØπÊØîÂ≠¶‰π†ÊúâÊïàÂéªÈô§ÂâØËØ≠Ë®Ä‰ø°ÊÅØÔºåÂπ∂Âú®Âçï‰∏Ä‰ª£Á†ÅÊú¨Á©∫Èó¥‰∏≠ÂÆûÁé∞ËØ≠‰πâ‰∏éÂâØËØ≠Ë®ÄÁöÑÂàÜÁ¶ªÔºåËøôÂú®Áé∞ÊúâÊñπÊ≥ï‰∏≠Â∞öÂ±ûÈ¶ñÊ¨°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÂíåÊúâÈôêÊ†áÈáèÈáèÂåñÔºàFSQÔºâÁõ∏ÁªìÂêàÁöÑÈáèÂåñÊñπÊ≥ïÔºåËß£ÂÜ≥‰∫ÜÈïøÂ∞æÂàÜÂ∏ÉÈóÆÈ¢òÔºåÂêåÊó∂‰øùÊåÅÈ´ò‰ª£Á†ÅÊú¨Âà©Áî®Áéá„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüËÄÉËôë‰∫ÜËØ≠‰πâÂÆåÊï¥ÊÄß‰∏éÈáçÊûÑ‰øùÁúüÂ∫¶ÁöÑÂπ≥Ë°°„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

SecoustiCodecÂú®0.27/1 kbps‰∏ãÂàÜÂà´ÂÆûÁé∞‰∫Ü1.77/2.58ÁöÑÈáçÊûÑË¥®ÈáèÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®‰ΩéÊØîÁâπÁéáÊù°‰ª∂‰∏ãÁöÑÂçìË∂äÊÄßËÉΩ„ÄÇËØ•Á†îÁ©∂‰∏ç‰ªÖÊèêÂçá‰∫ÜËØ≠Èü≥ÁºñÁ†ÅÁöÑË¥®ÈáèÔºåËøò‰∏∫Êú™Êù•ÁöÑÊµÅÂ™í‰ΩìÂ∫îÁî®Êèê‰æõ‰∫ÜÊñ∞ÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SecoustiCodecÁöÑÁ†îÁ©∂ÊàêÊûúÂú®ËØ≠Èü≥ÈÄö‰ø°„ÄÅËØ≠Èü≥ËØÜÂà´ÂíåËØ≠Èü≥ÂêàÊàêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òËØ≠Èü≥ÁºñÁ†ÅÁöÑË¥®ÈáèÂíåÊïàÁéáÔºåËØ•ÊäÄÊúØËÉΩÂ§üÊîπÂñÑËØ≠Èü≥‰∫§‰∫íÁöÑÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂Êé®Âä®Êô∫ËÉΩÂä©ÊâãÂíåËá™Âä®ËØ≠Èü≥ËØÜÂà´Á≥ªÁªüÁöÑÂèëÂ±ï„ÄÇÊú™Êù•ÔºåÈöèÁùÄÊäÄÊúØÁöÑËøõ‰∏ÄÊ≠•ÊàêÁÜüÔºåSecoustiCodecÂèØËÉΩ‰ºöÂú®ÂÆûÊó∂ËØ≠Èü≥ÊµÅÂ™í‰Ωì‰º†Ëæì‰∏≠ÂèëÊå•ÈáçË¶Å‰ΩúÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Speech codecs serve as a crucial bridge in unifying speech and text language models. Existing codec methods face several challenges in semantic encoding, such as residual paralinguistic information (e.g., timbre, emotion), insufficient semantic completeness, limited reconstruction capability, and lack of support for streaming. To address these challenges, we propose SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that disentangles semantic and paralinguistic information in a single-codebook space. To ensure semantic completeness and reconstruction fidelity, paralinguistic encoding is introduced to bridge the information gap between semantic and acoustic encoding. A semantic-only efficient quantization method based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is proposed. This approach alleviates the long-tail distribution problem of tokens while maintaining high codebook utilization. A semantic disentanglement method based on contrastive learning is proposed, which aligns text and speech in a joint multimodal frame-level space, effectively removing paralinguistic information from semantic encoding. An acoustic-constrained multi-stage optimization strategy is proposed to ensure robust and stable convergence. Figure~\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA (state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps. The code and model weights for SecoustiCodec will be open-sourced upon the completion of the peer-review process. We've open-sourced SecoustiCodec's demo, code, and model weights.

