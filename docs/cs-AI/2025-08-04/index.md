---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-08-04
---

# cs.AIï¼ˆ2025-08-04ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250802961v2-defend-llms-through-self-consciousness.html">Defend LLMs Through Self-Consciousness</a></td>
  <td>æå‡ºè‡ªæˆ‘æ„è¯†é˜²å¾¡æœºåˆ¶ä»¥åº”å¯¹å¤§è¯­è¨€æ¨¡å‹çš„æç¤ºæ³¨å…¥æ”»å‡»</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02961v2" data-paper-url="./papers/250802961v2-defend-llms-through-self-consciousness.html" onclick="toggleFavorite(this, '2508.02961v2', 'Defend LLMs Through Self-Consciousness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250802622v2-noosemia-toward-a-cognitive-and-phenomenological-account-of-intentio.html">Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction</a></td>
  <td>æå‡ºNoosemiaæ¡†æ¶ä»¥è§£é‡Šäººæœºäº¤äº’ä¸­çš„æ„å‘æ€§å½’å±</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02622v2" data-paper-url="./papers/250802622v2-noosemia-toward-a-cognitive-and-phenomenological-account-of-intentio.html" onclick="toggleFavorite(this, '2508.02622v2', 'Noosemia: toward a Cognitive and Phenomenological Account of Intentionality Attribution in Human-Generative AI Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250802511v2-test-time-prompt-intervention.html">Test-time Prompt Intervention</a></td>
  <td>æå‡ºæµ‹è¯•æ—¶æç¤ºå¹²é¢„æ¡†æ¶ä»¥è§£å†³æ¨ç†å†—ä½™é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02511v2" data-paper-url="./papers/250802511v2-test-time-prompt-intervention.html" onclick="toggleFavorite(this, '2508.02511v2', 'Test-time Prompt Intervention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250802279v1-dialogue-systems-engineering-a-survey-and-future-directions.html">Dialogue Systems Engineering: A Survey and Future Directions</a></td>
  <td>æå‡ºå¯¹è¯ç³»ç»Ÿå·¥ç¨‹ä»¥æå‡å¯¹è¯ç³»ç»Ÿçš„å¼€å‘ä¸åº”ç”¨æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02279v1" data-paper-url="./papers/250802279v1-dialogue-systems-engineering-a-survey-and-future-directions.html" onclick="toggleFavorite(this, '2508.02279v1', 'Dialogue Systems Engineering: A Survey and Future Directions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250802124v6-trainable-dynamic-mask-sparse-attention.html">Trainable Dynamic Mask Sparse Attention</a></td>
  <td>æå‡ºå¯è®­ç»ƒåŠ¨æ€æ©ç ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡å»ºæ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02124v6" data-paper-url="./papers/250802124v6-trainable-dynamic-mask-sparse-attention.html" onclick="toggleFavorite(this, '2508.02124v6', 'Trainable Dynamic Mask Sparse Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>6</td>
  <td><a href="./papers/250802912v4-communicating-plans-not-percepts-scalable-multi-agent-coordination-w.html">Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models</a></td>
  <td>æå‡ºåŸºäºä¸–ç•Œæ¨¡å‹çš„é€šä¿¡ç­–ç•¥ä»¥è§£å†³å¤šæ™ºèƒ½ä½“åè°ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">world model</span> <span class="paper-tag">predictive model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02912v4" data-paper-url="./papers/250802912v4-communicating-plans-not-percepts-scalable-multi-agent-coordination-w.html" onclick="toggleFavorite(this, '2508.02912v4', 'Communicating Plans, Not Percepts: Scalable Multi-Agent Coordination with Embodied World Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250802849v1-secousticodec-cross-modal-aligned-streaming-single-codecbook-speech-.html">SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec</a></td>
  <td>æå‡ºSecoustiCodecä»¥è§£å†³è¯­éŸ³ç¼–ç ä¸­çš„è¯­ä¹‰ä¸å‰¯è¯­è¨€ä¿¡æ¯åˆ†ç¦»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.02849v1" data-paper-url="./papers/250802849v1-secousticodec-cross-modal-aligned-streaming-single-codecbook-speech-.html" onclick="toggleFavorite(this, '2508.02849v1', 'SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)