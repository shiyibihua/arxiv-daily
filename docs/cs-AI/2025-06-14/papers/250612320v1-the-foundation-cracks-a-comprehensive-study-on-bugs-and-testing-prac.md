---
layout: default
title: The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries
---

# The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.12320" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.12320v1</a>
  <a href="https://arxiv.org/pdf/2506.12320.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.12320v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.12320v1', 'The Foundation Cracks: A Comprehensive Study on Bugs and Testing Practices in LLM Libraries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weipeng Jiang, Xiaoyu Zhang, Xiaofei Xie, Jiongchi Yu, Yuhan Zhi, Shiqing Ma, Chao Shen

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-14

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¨é¢ç ”ç©¶ä»¥è§£å†³LLMåº“ä¸­çš„ç¼ºé™·ä¸æµ‹è¯•å®è·µé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¼ºé™·åˆ†æ` `æµ‹è¯•å®è·µ` `APIè¯¯ç”¨` `è´¨é‡ä¿è¯` `HuggingFace` `vLLM`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåº“é¢‘ç¹å‡ºç°è´¨é‡é—®é¢˜ï¼Œå¯¼è‡´AIç³»ç»Ÿçš„å¯é æ€§å—åˆ°å¨èƒï¼Œå°¤å…¶æ˜¯APIè¯¯ç”¨æˆä¸ºä¸»è¦ç¼ºé™·åŸå› ã€‚
2. é€šè¿‡å¯¹HuggingFace Transformerså’ŒvLLMåº“çš„ç¼ºé™·è¿›è¡Œåˆ†æï¼Œå»ºç«‹äº†ç¼ºé™·åˆ†ç±»ä½“ç³»ï¼Œå¹¶è¯„ä¼°äº†ç°æœ‰æµ‹è¯•æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
3. ç ”ç©¶å‘ç°41.73%çš„ç¼ºé™·å› æµ‹è¯•ç”¨ä¾‹ä¸è¶³è€Œæœªè¢«æ£€æµ‹ï¼Œæå‡ºäº†æ”¹è¿›LLMåº“è´¨é‡ä¿è¯çš„å»ºè®®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº“ä½œä¸ºå½“ä»ŠAIé©å‘½çš„åŸºç¡€è®¾æ–½ï¼Œæ”¯æ’‘ç€LLMçš„éƒ¨ç½²ã€æ¨ç†ä¼˜åŒ–ã€å¾®è°ƒå’Œç”Ÿäº§æœåŠ¡ã€‚ç„¶è€Œï¼Œè¿™äº›åº“é¢ä¸´é¢‘ç¹çš„è´¨é‡é—®é¢˜å’Œç¼ºé™·ï¼Œå¨èƒåˆ°åŸºäºå®ƒä»¬æ„å»ºçš„AIç³»ç»Ÿçš„å¯é æ€§ã€‚ä¸ºå¡«è¡¥è¿™ä¸€çŸ¥è¯†ç©ºç™½ï¼Œæœ¬æ–‡é¦–æ¬¡å¯¹ç°ä»£LLMåº“ä¸­çš„ç¼ºé™·ç‰¹å¾å’Œæµ‹è¯•å®è·µè¿›è¡Œäº†å…¨é¢çš„å®è¯ç ”ç©¶ã€‚æˆ‘ä»¬åˆ†æäº†313ä¸ªä¿®å¤ç¼ºé™·çš„æäº¤ï¼Œå»ºç«‹äº†ç¼ºé™·ç—‡çŠ¶å’Œæ ¹æœ¬åŸå› çš„åˆ†ç±»ä½“ç³»ã€‚ç ”ç©¶å‘ç°ï¼ŒAPIè¯¯ç”¨æ˜¯ä¸»è¦æ ¹æœ¬åŸå› ï¼Œä¸”ç°æœ‰æµ‹è¯•æ–¹æ³•çš„æœ‰æ•ˆæ€§ä¸è¶³ï¼Œå¯¼è‡´å¤§éƒ¨åˆ†ç¼ºé™·æœªèƒ½è¢«æ£€æµ‹åˆ°ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€äº›æå‡LLMåº“è´¨é‡ä¿è¯çš„å»ºè®®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åº“ä¸­çš„ç¼ºé™·åŠå…¶æµ‹è¯•å®è·µé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç¼ºé™·æ£€æµ‹å’Œæµ‹è¯•æœ‰æ•ˆæ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå¯¼è‡´è®¸å¤šç¼ºé™·æœªèƒ½è¢«åŠæ—¶å‘ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹LLMåº“ä¸­ç¼ºé™·çš„å…¨é¢å®è¯ç ”ç©¶ï¼Œå»ºç«‹ç¼ºé™·ç‰¹å¾çš„åˆ†ç±»ä½“ç³»ï¼Œå¹¶åˆ†æç°æœ‰æµ‹è¯•æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œä»¥æå‡ºæ”¹è¿›å»ºè®®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¼ºé™·åˆ†æå’Œæµ‹è¯•æœ‰æ•ˆæ€§è¯„ä¼°ã€‚ç¼ºé™·åˆ†æåŒ…æ‹¬å¯¹313ä¸ªä¿®å¤æäº¤çš„æ‰‹åŠ¨åˆ†æï¼Œæµ‹è¯•æœ‰æ•ˆæ€§è¯„ä¼°åˆ™åŸºäº7,748ä¸ªæµ‹è¯•å‡½æ•°çš„åˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§åœ°åˆ†ç±»äº†LLMåº“ä¸­çš„ç¼ºé™·ç—‡çŠ¶å’Œæ ¹æœ¬åŸå› ï¼Œç‰¹åˆ«æ˜¯APIè¯¯ç”¨çš„æ˜¾è‘—æ€§ï¼Œæ ‡å¿—ç€ä»ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¡†æ¶çš„ç®—æ³•ç¼ºé™·å‘æ¥å£é—®é¢˜çš„è½¬å˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç¼ºé™·åˆ†ç±»ä¸­ï¼Œç—‡çŠ¶åˆ†ä¸º5ç±»ï¼Œæ ¹æœ¬åŸå› åˆ†ä¸º14ç±»ï¼›æµ‹è¯•æ–¹æ³•ä¸­ï¼Œå®šä¹‰äº†7ç§æµ‹è¯•oracleç±»åˆ«ï¼Œå¼ºè°ƒäº†é¢„å®šä¹‰æœŸæœ›è¾“å‡ºçš„ä½¿ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶è¡¨æ˜ï¼ŒAPIè¯¯ç”¨æ˜¯LLMåº“ä¸­æœ€ä¸»è¦çš„ç¼ºé™·æ ¹æœ¬åŸå› ï¼Œå æ¯”é«˜è¾¾32.17%-48.19%ã€‚æ­¤å¤–ï¼Œ41.73%çš„ç¼ºé™·å› æµ‹è¯•ç”¨ä¾‹ä¸è¶³è€Œæœªè¢«æ£€æµ‹ï¼Œæ˜¾ç¤ºå‡ºç°æœ‰æµ‹è¯•æ–¹æ³•çš„æœ‰æ•ˆæ€§äºŸå¾…æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹åº“çš„å¼€å‘å’Œç»´æŠ¤æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…è¯†åˆ«å’Œä¿®å¤æ½œåœ¨ç¼ºé™·ï¼Œæé«˜LLMåº“çš„è´¨é‡å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œéšç€LLMæŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œæœ¬æ–‡çš„å‘ç°å’Œå»ºè®®å°†å¯¹æ•´ä¸ªAIç”Ÿæ€ç³»ç»Ÿäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLM) libraries have emerged as the foundational infrastructure powering today's AI revolution, serving as the backbone for LLM deployment, inference optimization, fine-tuning, and production serving across diverse applications. Despite their critical role in the LLM ecosystem, these libraries face frequent quality issues and bugs that threaten the reliability of AI systems built upon them. To address this knowledge gap, we present the first comprehensive empirical investigation into bug characteristics and testing practices in modern LLM libraries. We examine 313 bug-fixing commits extracted across two widely-adopted LLM libraries: HuggingFace Transformers and vLLM.Through rigorous manual analysis, we establish comprehensive taxonomies categorizing bug symptoms into 5 types and root causes into 14 distinct categories.Our primary discovery shows that API misuse has emerged as the predominant root cause (32.17%-48.19%), representing a notable transition from algorithm-focused defects in conventional deep learning frameworks toward interface-oriented problems. Additionally, we examine 7,748 test functions to identify 7 distinct test oracle categories employed in current testing approaches, with predefined expected outputs (such as specific tensors and text strings) being the most common strategy. Our assessment of existing testing effectiveness demonstrates that the majority of bugs escape detection due to inadequate test cases (41.73%), lack of test drivers (32.37%), and weak test oracles (25.90%). Drawing from these findings, we offer some recommendations for enhancing LLM library quality assurance.

