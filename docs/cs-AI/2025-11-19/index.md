---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-11-19
---

# cs.AIï¼ˆ2025-11-19ï¼‰

ğŸ“Š å…± **3** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251115055v1-learning-human-like-rl-agents-through-trajectory-optimization-with-a.html">Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization</a></td>
  <td>æå‡ºåŸºäºè½¨è¿¹ä¼˜åŒ–çš„åŠ¨ä½œé‡åŒ–æ–¹æ³•MAQï¼Œæå‡å¼ºåŒ–å­¦ä¹ Agentçš„äººç±»ç›¸ä¼¼åº¦</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15055v1" onclick="toggleFavorite(this, '2511.15055v1', 'Learning Human-Like RL Agents Through Trajectory Optimization With Action Quantization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251115351v2-octopus-agentic-multimodal-reasoning-with-six-capability-orchestrati.html">Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration</a></td>
  <td>Octopusï¼šåŸºäºå…­å¤§èƒ½åŠ›ç¼–æ’çš„Agenticå¤šæ¨¡æ€æ¨ç†æ¡†æ¶</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15351v2" onclick="toggleFavorite(this, '2511.15351v2', 'Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥-perception-slam">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/251115090v1-bbox-docvqa-a-large-scale-bounding-box-grounded-dataset-for-enhancin.html">BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer</a></td>
  <td>æå‡ºBBox DocVQAæ•°æ®é›†ï¼Œå¢å¼ºæ–‡æ¡£è§†è§‰é—®ç­”ä¸­ç©ºé—´æ¨ç†èƒ½åŠ›ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.15090v1" onclick="toggleFavorite(this, '2511.15090v1', 'BBox DocVQA: A Large Scale Bounding Box Grounded Dataset for Enhancing Reasoning in Document Visual Question Answer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)