---
layout: default
title: Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness
---

# Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13332" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13332v1</a>
  <a href="https://arxiv.org/pdf/2509.13332.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13332v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13332v1', 'Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pratik Jayarao, Himanshu Gupta, Neeraj Varshney, Chaitanya Dwivedi

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¡¨æ˜ï¼Œåœ¨LLMè¯„åˆ¤ä»»åŠ¡ä¸­ï¼Œæ˜¾å¼æ¨ç†æ¨¡å‹åœ¨å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§ä¸Šæ›´ä¼˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ˜¾å¼æ¨ç†` `è‡ªåŠ¨è¯„åˆ¤` `é²æ£’æ€§` `åå·®åˆ†æ` `RewardBench` `Qwen 3`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè¯„åˆ¤æ–¹æ³•ç¼ºä¹æ•ˆç‡å’Œé²æ£’æ€§ï¼Œéš¾ä»¥ä¿è¯åœ¨å„ç§åå·®æ¡ä»¶ä¸‹çš„è¯„åˆ¤ä¸€è‡´æ€§ã€‚
2. è®ºæ–‡æå‡ºé‡‡ç”¨æ˜¾å¼æ¨ç†çš„LLMä½œä¸ºè¯„åˆ¤å™¨ï¼Œæ—¨åœ¨æå‡è¯„åˆ¤çš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ˜¾å¼æ¨ç†æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šæå‡æ˜¾è‘—ï¼Œä¸”åœ¨å¤šç§åå·®æ¡ä»¶ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œåŸºå‡†æµ‹è¯•å’Œå¥–åŠ±å»ºæ¨¡ä¸­çš„è‡ªåŠ¨è¯„åˆ¤å™¨ï¼Œç¡®ä¿å…¶å¯é æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§è‡³å…³é‡è¦ã€‚æœ¬æ–‡å¯¹â€œæ€è€ƒå‹â€å’Œâ€œéæ€è€ƒå‹â€LLMåœ¨LLM-as-a-judgeèŒƒå¼ä¸­è¿›è¡Œäº†ç³»ç»Ÿæ¯”è¾ƒï¼Œä½¿ç”¨äº†ç›¸å¯¹è¾ƒå°è§„æ¨¡çš„å¼€æºQwen 3æ¨¡å‹ï¼ˆ0.6Bã€1.7Bå’Œ4Bå‚æ•°ï¼‰ã€‚æˆ‘ä»¬è¯„ä¼°äº†RewardBenchä»»åŠ¡ä¸Šçš„å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ï¼ˆFLOPsï¼‰ï¼Œå¹¶è¿›ä¸€æ­¥ç ”ç©¶äº†éæ€è€ƒå‹æ¨¡å‹çš„å¢å¼ºç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡å­¦ä¹ ã€è§„åˆ™å¼•å¯¼è¯„åˆ¤ã€åŸºäºå‚è€ƒçš„è¯„ä¼°å’Œn-bestèšåˆã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¿›è¡Œäº†è¿™äº›å¢å¼ºï¼Œéæ€è€ƒå‹æ¨¡å‹é€šå¸¸ä¸å¦‚æ€è€ƒå‹æ¨¡å‹ã€‚æ€è€ƒå‹æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šæé«˜äº†çº¦10ä¸ªç™¾åˆ†ç‚¹ï¼Œè®¡ç®—å¼€é”€å¾ˆå°ï¼ˆä½äº2å€ï¼‰ï¼Œè€Œåƒå°‘æ ·æœ¬å­¦ä¹ è¿™æ ·çš„å¢å¼ºç­–ç•¥ä»¥æ›´é«˜çš„æˆæœ¬ï¼ˆ>8å€ï¼‰æä¾›äº†é€‚åº¦çš„æ”¶ç›Šã€‚åå·®å’Œé²æ£’æ€§åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ€è€ƒå‹æ¨¡å‹åœ¨å„ç§åå·®æ¡ä»¶ä¸‹ï¼ˆå¦‚ä½ç½®åå·®ã€ä»ä¼—åå·®ã€èº«ä»½åå·®ã€å¤šæ ·æ€§åå·®å’Œéšæœºåå·®ï¼‰ä¿æŒäº†æ˜¾è‘—æ›´é«˜çš„ä¸€è‡´æ€§ï¼ˆå¹³å‡é«˜6%ï¼‰ã€‚æˆ‘ä»¬è¿˜å°†å®éªŒæ‰©å±•åˆ°å¤šè¯­è¨€ç¯å¢ƒï¼Œç»“æœè¯å®æ˜¾å¼æ¨ç†çš„ä¼˜åŠ¿è¶…è¶Šäº†è‹±è¯­ã€‚æ€»çš„æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œå¾—å‡ºäº†ä¸€äº›é‡è¦çš„å‘ç°ï¼Œè¿™äº›å‘ç°æä¾›äº†ç³»ç»Ÿçš„è¯æ®ï¼Œè¡¨æ˜æ˜¾å¼æ¨ç†åœ¨LLM-as-a-judgeèŒƒå¼ä¸­ä¸ä»…åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡æ–¹é¢ï¼Œè€Œä¸”åœ¨é²æ£’æ€§æ–¹é¢éƒ½æä¾›äº†æ˜æ˜¾çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè‡ªåŠ¨è¯„åˆ¤å™¨æ—¶ï¼Œåœ¨å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§æ–¹é¢å­˜åœ¨çš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯â€œéæ€è€ƒå‹â€æ¨¡å‹ï¼Œåœ¨é¢å¯¹å„ç§åå·®æ—¶ï¼Œè¯„åˆ¤ç»“æœçš„ä¸€è‡´æ€§è¾ƒå·®ï¼Œä¸”è®¡ç®—æˆæœ¬è¾ƒé«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨â€œæ€è€ƒå‹â€LLMï¼Œå³å…·æœ‰æ˜¾å¼æ¨ç†èƒ½åŠ›çš„LLMï¼Œæ¥æå‡è¯„åˆ¤çš„è´¨é‡ã€‚é€šè¿‡è®©æ¨¡å‹åœ¨ç»™å‡ºæœ€ç»ˆåˆ¤æ–­ä¹‹å‰è¿›è¡Œæ˜¾å¼çš„æ¨ç†è¿‡ç¨‹ï¼Œå¯ä»¥å‡å°‘åå·®çš„å½±å“ï¼Œæé«˜è¯„åˆ¤çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é‡‡ç”¨LLM-as-a-judgeèŒƒå¼ï¼Œä½¿ç”¨å¼€æºçš„Qwen 3æ¨¡å‹ä½œä¸ºè¯„åˆ¤å™¨ã€‚ä¸»è¦åˆ†ä¸ºä¸¤ä¸ªç±»å‹çš„æ¨¡å‹ï¼šæ€è€ƒå‹å’Œéæ€è€ƒå‹ã€‚å¯¹éæ€è€ƒå‹æ¨¡å‹ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†å¤šç§å¢å¼ºç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸Šä¸‹æ–‡å­¦ä¹ ã€è§„åˆ™å¼•å¯¼è¯„åˆ¤ã€åŸºäºå‚è€ƒçš„è¯„ä¼°å’Œn-bestèšåˆã€‚å®éªŒåœ¨RewardBenchä»»åŠ¡ä¸Šè¿›è¡Œï¼Œè¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ï¼ˆFLOPsï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†â€œæ€è€ƒå‹â€å’Œâ€œéæ€è€ƒå‹â€LLMåœ¨è¯„åˆ¤ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶è¯æ˜äº†æ˜¾å¼æ¨ç†åœ¨å‡†ç¡®æ€§ã€æ•ˆç‡å’Œé²æ£’æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ·±å…¥ç ”ç©¶äº†å„ç§åå·®å¯¹è¯„åˆ¤ç»“æœçš„å½±å“ï¼Œå¹¶éªŒè¯äº†æ˜¾å¼æ¨ç†æ¨¡å‹åœ¨åº”å¯¹è¿™äº›åå·®æ—¶çš„ä¼˜è¶Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨äº†ä¸åŒè§„æ¨¡çš„Qwen 3æ¨¡å‹ï¼ˆ0.6Bã€1.7Bå’Œ4Bå‚æ•°ï¼‰è¿›è¡Œå®éªŒã€‚å¯¹äºæ€è€ƒå‹æ¨¡å‹ï¼Œå…³é”®åœ¨äºè®¾è®¡åˆé€‚çš„promptï¼Œå¼•å¯¼æ¨¡å‹è¿›è¡Œæ˜¾å¼æ¨ç†ã€‚å¯¹äºéæ€è€ƒå‹æ¨¡å‹ï¼Œè®ºæ–‡å°è¯•äº†å¤šç§å¢å¼ºç­–ç•¥ï¼Œä¾‹å¦‚ï¼Œä¸Šä¸‹æ–‡å­¦ä¹ é€šè¿‡æä¾›å°‘é‡çš„ç¤ºä¾‹æ¥å¼•å¯¼æ¨¡å‹è¿›è¡Œè¯„åˆ¤ï¼›è§„åˆ™å¼•å¯¼è¯„åˆ¤åˆ™é€šè¿‡æä¾›æ˜ç¡®çš„è¯„åˆ¤æ ‡å‡†æ¥å‡å°‘åå·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ€è€ƒå‹æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šæ¯”éæ€è€ƒå‹æ¨¡å‹é«˜å‡ºçº¦10ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸”è®¡ç®—å¼€é”€å¢åŠ è¾ƒå°ï¼ˆä½äº2å€ï¼‰ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œå³ä½¿é‡‡ç”¨å°‘æ ·æœ¬å­¦ä¹ ç­‰å¢å¼ºç­–ç•¥ï¼Œéæ€è€ƒå‹æ¨¡å‹åœ¨å‡†ç¡®æ€§ä¸Šçš„æå‡ä¹Ÿç›¸å¯¹æœ‰é™ï¼Œä¸”è®¡ç®—æˆæœ¬æ›´é«˜ï¼ˆ>8å€ï¼‰ã€‚æ­¤å¤–ï¼Œæ€è€ƒå‹æ¨¡å‹åœ¨å„ç§åå·®æ¡ä»¶ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œå¹³å‡ä¸€è‡´æ€§é«˜å‡º6%ã€‚å¤šè¯­è¨€å®éªŒä¹ŸéªŒè¯äº†æ˜¾å¼æ¨ç†çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªåŠ¨åŒ–è¯„ä¼°ç³»ç»Ÿã€å¥–åŠ±æ¨¡å‹æ„å»ºã€ä»¥åŠå…¶ä»–éœ€è¦é«˜è´¨é‡ã€é«˜å¯é æ€§è¯„åˆ¤çš„åœºæ™¯ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºè‡ªåŠ¨è¯„ä¼°å­¦ç”Ÿçš„ä½œä¸šã€è¯„ä¼°æœºå™¨ç¿»è¯‘çš„è´¨é‡ã€æˆ–è€…åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ä½œä¸ºå¥–åŠ±å‡½æ•°ï¼Œæå‡æ™ºèƒ½ä½“çš„å­¦ä¹ æ•ˆç‡å’Œæ•ˆæœã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•ä¼˜åŒ–æ˜¾å¼æ¨ç†è¿‡ç¨‹ï¼Œä»¥åŠå¦‚ä½•å°†è¯¥æ–¹æ³•åº”ç”¨äºæ›´å¤æ‚çš„è¯„åˆ¤ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) are increasingly adopted as automated judges in benchmarking and reward modeling, ensuring their reliability, efficiency, and robustness has become critical. In this work, we present a systematic comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B parameters). We evaluate both accuracy and computational efficiency (FLOPs) on RewardBench tasks, and further examine augmentation strategies for non-thinking models, including in-context learning, rubric-guided judging, reference-based evaluation, and n-best aggregation. Our results show that despite these enhancements, non-thinking models generally fall short of their thinking counterparts. Our results show that thinking models achieve approximately 10% points higher accuracy with little overhead (under 2x), in contrast to augmentation strategies like few-shot learning, which deliver modest gains at a higher cost (>8x). Bias and robustness analyses further demonstrate that thinking models maintain significantly greater consistency under a variety of bias conditions such as positional, bandwagon, identity, diversity, and random biases (6% higher on average). We further extend our experiments to the multilingual setting and our results confirm that explicit reasoning extends its benefits beyond English. Overall, our work results in several important findings that provide systematic evidence that explicit reasoning offers clear advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency but also in robustness.

