---
layout: default
title: Astra: A Multi-Agent System for GPU Kernel Performance Optimization
---

# Astra: A Multi-Agent System for GPU Kernel Performance Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07506" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07506v2</a>
  <a href="https://arxiv.org/pdf/2509.07506.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07506v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07506v2', 'Astra: A Multi-Agent System for GPU Kernel Performance Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anjiang Wei, Tianran Sun, Yogesh Seenichamy, Hang Song, Anne Ouyang, Azalia Mirhoseini, Ke Wang, Alex Aiken

**åˆ†ç±»**: cs.DC, cs.AI, cs.CL, cs.LG, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-09-09 (æ›´æ–°: 2025-12-02)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Anjiang-Wei/Astra)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Astraï¼šåŸºäºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„GPU Kernelæ€§èƒ½ä¼˜åŒ–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `GPU Kernelä¼˜åŒ–` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `å¤§å‹è¯­è¨€æ¨¡å‹` `CUDA` `æ€§èƒ½ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. GPU kernelä¼˜åŒ–æ˜¯é«˜æ€§èƒ½è®¡ç®—å’Œæœºå™¨å­¦ä¹ äº¤å‰é¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ‰‹åŠ¨è°ƒæ•´å’Œå·¥ç¨‹è®¾è®¡ã€‚
2. Astraæå‡ºä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä»ç°æœ‰CUDAå®ç°å‡ºå‘ï¼Œé€šè¿‡æ™ºèƒ½ä½“åä½œè¿›è¡Œkernelä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAstraåœ¨SGLangçš„kernelä¸Šå®ç°äº†å¹³å‡1.32å€çš„åŠ é€Ÿï¼Œè¯æ˜äº†LLMåœ¨kernelä¼˜åŒ–æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»Astraï¼Œä¸€ç§åŸºäºLLMçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºGPU kernelä¼˜åŒ–ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒAstraä»SGLangï¼ˆä¸€ç§å¹¿æ³›éƒ¨ç½²çš„LLMæœåŠ¡æ¡†æ¶ï¼‰ä¸­æå–çš„ç°æœ‰CUDAå®ç°å¼€å§‹ï¼Œè€Œä¸æ˜¯å°†PyTorchæ¨¡å—ä½œä¸ºè§„èŒƒã€‚åœ¨Astraä¸­ï¼Œä¸“é—¨çš„LLMæ™ºèƒ½ä½“é€šè¿‡è¿­ä»£çš„ä»£ç ç”Ÿæˆã€æµ‹è¯•ã€åˆ†æå’Œè§„åˆ’è¿›è¡Œåä½œï¼Œä»¥ç”Ÿæˆæ—¢æ­£ç¡®åˆé«˜æ€§èƒ½çš„kernelã€‚åœ¨æ¥è‡ªSGLangçš„kernelä¸Šï¼ŒAstraä½¿ç”¨å¸¦æœ‰OpenAI o4-miniçš„é›¶æ ·æœ¬æç¤ºå®ç°äº†å¹³å‡1.32å€çš„åŠ é€Ÿã€‚è¯¦ç»†çš„æ¡ˆä¾‹ç ”ç©¶è¿›ä¸€æ­¥è¡¨æ˜ï¼ŒLLMå¯ä»¥è‡ªä¸»åº”ç”¨å¾ªç¯è½¬æ¢ã€ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼ã€åˆ©ç”¨CUDA intrinsicsä»¥åŠåˆ©ç”¨å¿«é€Ÿæ•°å­¦è¿ç®—æ¥äº§ç”Ÿæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿä½œä¸ºGPU kernelä¼˜åŒ–çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–°èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šGPU kernelçš„ä¼˜åŒ–å¯¹äºåŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è®­ç»ƒå’Œæ¨ç†è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå®ç°é«˜æ€§èƒ½é€šå¸¸éœ€è¦å¤§é‡çš„æ‰‹åŠ¨è°ƒæ•´ï¼Œè¿™æ—¢è€—æ—¶åˆéœ€è¦ä¸“ä¸šçš„çŸ¥è¯†ã€‚ç°æœ‰çš„åŸºäºç¼–è¯‘å™¨çš„ç³»ç»Ÿè™½ç„¶å‡è½»äº†ä¸€äº›è´Ÿæ‹…ï¼Œä½†ä»ç„¶éœ€è¦å¤§é‡çš„äººå·¥è®¾è®¡å’Œå·¥ç¨‹å·¥ä½œã€‚å› æ­¤ï¼Œå¦‚ä½•è‡ªåŠ¨åŒ–ä¸”é«˜æ•ˆåœ°ä¼˜åŒ–GPU kernelæ€§èƒ½æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAstraçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºæ™ºèƒ½ä½“ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“åä½œçš„æ–¹å¼ï¼Œè‡ªåŠ¨åŒ–åœ°æ¢ç´¢å’Œä¼˜åŒ–GPU kernelã€‚ä¸ä»¥å¾€å°†PyTorchæ¨¡å—ç¿»è¯‘æˆCUDAä»£ç çš„æ–¹æ³•ä¸åŒï¼ŒAstraç›´æ¥ä»ç°æœ‰çš„ã€ç»è¿‡å®é™…éƒ¨ç½²çš„CUDAä»£ç ï¼ˆä¾‹å¦‚SGLangä¸­çš„kernelï¼‰å…¥æ‰‹ï¼Œé¿å…äº†ä»é«˜çº§æŠ½è±¡åˆ°ä½çº§å®ç°çš„è½¬æ¢è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æŸå¤±ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAstraé‡‡ç”¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ¶æ„ï¼ŒåŒ…å«å¤šä¸ªä¸“é—¨çš„LLMæ™ºèƒ½ä½“ï¼Œè¿™äº›æ™ºèƒ½ä½“ååŒå·¥ä½œä»¥ä¼˜åŒ–GPU kernelã€‚ä¸»è¦æµç¨‹åŒ…æ‹¬ï¼š1) ä»£ç ç”Ÿæˆï¼šLLMæ™ºèƒ½ä½“æ ¹æ®å½“å‰kernelä»£ç ç”Ÿæˆæ–°çš„ä¼˜åŒ–ç‰ˆæœ¬ã€‚2) æµ‹è¯•ï¼šå¯¹ç”Ÿæˆçš„ä»£ç è¿›è¡ŒåŠŸèƒ½æµ‹è¯•ï¼Œç¡®ä¿æ­£ç¡®æ€§ã€‚3) æ€§èƒ½åˆ†æï¼šä½¿ç”¨profileråˆ†ækernelçš„æ€§èƒ½ç“¶é¢ˆã€‚4) è§„åˆ’ï¼šæ ¹æ®æµ‹è¯•å’Œåˆ†æç»“æœï¼Œåˆ¶å®šä¸‹ä¸€æ­¥ä¼˜åŒ–ç­–ç•¥ã€‚è¿™äº›æ­¥éª¤è¿­ä»£è¿›è¡Œï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„æ€§èƒ½ç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šAstraçš„å…³é”®åˆ›æ–°åœ¨äºå…¶å¤šæ™ºèƒ½ä½“åä½œçš„æ¶æ„å’Œç›´æ¥ä»ç°æœ‰CUDAä»£ç å‡ºå‘çš„ä¼˜åŒ–ç­–ç•¥ã€‚å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå…è®¸ä¸åŒçš„æ™ºèƒ½ä½“ä¸“æ³¨äºä¸åŒçš„ä¼˜åŒ–æ–¹é¢ï¼ˆä¾‹å¦‚å¾ªç¯ä¼˜åŒ–ã€å†…å­˜è®¿é—®ä¼˜åŒ–ï¼‰ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æ¢ç´¢ä¼˜åŒ–ç©ºé—´ã€‚ç›´æ¥ä»ç°æœ‰CUDAä»£ç å‡ºå‘é¿å…äº†ä»é«˜çº§æŠ½è±¡åˆ°ä½çº§å®ç°çš„è½¬æ¢è¿‡ç¨‹ä¸­çš„ä¿¡æ¯æŸå¤±ï¼Œä½¿å¾—LLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œä¼˜åŒ–ä»£ç ã€‚

**å…³é”®è®¾è®¡**ï¼šAstraçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ™ºèƒ½ä½“çš„è§’è‰²åˆ’åˆ†å’Œåä½œæœºåˆ¶ï¼šä¸åŒçš„æ™ºèƒ½ä½“è´Ÿè´£ä¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚ä»£ç ç”Ÿæˆã€æµ‹è¯•ã€æ€§èƒ½åˆ†æå’Œè§„åˆ’ã€‚æ™ºèƒ½ä½“ä¹‹é—´é€šè¿‡å…±äº«ä¿¡æ¯å’Œåä½œæ¥å…±åŒä¼˜åŒ–kernelã€‚2) LLMçš„æç¤ºå·¥ç¨‹ï¼šè®¾è®¡åˆé€‚çš„æç¤ºè¯­ï¼Œå¼•å¯¼LLMç”Ÿæˆé«˜è´¨é‡çš„ä¼˜åŒ–ä»£ç ã€‚3) è¿­ä»£ä¼˜åŒ–ç­–ç•¥ï¼šé€šè¿‡è¿­ä»£çš„ä»£ç ç”Ÿæˆã€æµ‹è¯•ã€åˆ†æå’Œè§„åˆ’ï¼Œé€æ­¥æ”¹è¿›kernelçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Astraåœ¨æ¥è‡ªSGLangçš„kernelä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼Œä½¿ç”¨å¸¦æœ‰OpenAI o4-miniçš„é›¶æ ·æœ¬æç¤ºï¼ŒAstraå®ç°äº†å¹³å‡1.32å€çš„åŠ é€Ÿã€‚æ­¤å¤–ï¼Œæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼ŒLLMå¯ä»¥è‡ªä¸»åº”ç”¨å¾ªç¯è½¬æ¢ã€ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼ã€åˆ©ç”¨CUDA intrinsicsä»¥åŠåˆ©ç”¨å¿«é€Ÿæ•°å­¦è¿ç®—æ¥äº§ç”Ÿæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿåœ¨GPU kernelä¼˜åŒ–æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Astraå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ç”¨äºåŠ é€Ÿå„ç§GPUåŠ é€Ÿçš„åº”ç”¨ï¼Œç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œæ¨ç†ã€‚é€šè¿‡è‡ªåŠ¨åŒ–kernelä¼˜åŒ–ï¼ŒAstraå¯ä»¥é™ä½å¼€å‘æˆæœ¬ï¼Œæé«˜æ€§èƒ½ï¼Œå¹¶ä½¿å¾—æ›´å¤šå¼€å‘è€…èƒ½å¤Ÿå……åˆ†åˆ©ç”¨GPUçš„å¼ºå¤§è®¡ç®—èƒ½åŠ›ã€‚æœªæ¥ï¼ŒAstraå¯ä»¥æ‰©å±•åˆ°æ”¯æŒæ›´å¤šçš„ç¡¬ä»¶å¹³å°å’Œç¼–ç¨‹è¯­è¨€ï¼Œè¿›ä¸€æ­¥æå‡å…¶é€šç”¨æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization. Our code is publicly available at https://github.com/Anjiang-Wei/Astra.

