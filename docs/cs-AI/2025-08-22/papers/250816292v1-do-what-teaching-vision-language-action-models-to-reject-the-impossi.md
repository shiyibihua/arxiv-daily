---
layout: default
title: Do What? Teaching Vision-Language-Action Models to Reject the Impossible
---

# Do What? Teaching Vision-Language-Action Models to Reject the Impossible

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16292" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16292v1</a>
  <a href="https://arxiv.org/pdf/2508.16292.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16292v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16292v1', 'Do What? Teaching Vision-Language-Action Models to Reject the Impossible')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wen-Han Hsieh, Elvis Hsieh, Dantong Niu, Trevor Darrell, Roei Herzig, David M. Chan

**åˆ†ç±»**: cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-22

**å¤‡æ³¨**: 9 pages, 2 figures, 1 table

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºInstruct-Verify-and-Actæ¡†æ¶ä»¥åº”å¯¹è™šå‡å‰ææŒ‡ä»¤é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-è¡ŒåŠ¨` `è™šå‡å‰ææŒ‡ä»¤` `è¯­è¨€æ¾„æ¸…` `æœºå™¨äººä»»åŠ¡` `å¤šæ¨¡æ€è¾“å…¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„VLAæ¨¡å‹åœ¨å¤„ç†è™šå‡å‰ææŒ‡ä»¤æ—¶å­˜åœ¨å±€é™ï¼Œæ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œå“åº”ç”¨æˆ·çš„é”™è¯¯è¯·æ±‚ã€‚
2. æœ¬æ–‡æå‡ºçš„IVAæ¡†æ¶é€šè¿‡æ£€æµ‹è™šå‡å‰æã€è¿›è¡Œè¯­è¨€æ¾„æ¸…å’Œæä¾›æ›¿ä»£æ–¹æ¡ˆï¼Œè§£å†³äº†è¿™ä¸€é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIVAåœ¨è™šå‡å‰ææ£€æµ‹å‡†ç¡®ç‡ä¸Šæå‡äº†97.56%ï¼Œå¹¶åœ¨ç›¸å…³åœºæ™¯ä¸­çš„æˆåŠŸå“åº”ç‡æé«˜äº†50.78%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè§†è§‰-è¯­è¨€-è¡ŒåŠ¨ï¼ˆVLAï¼‰æ¨¡å‹åœ¨å¤šç§æœºå™¨äººä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ã€‚è¿™äº›æ¨¡å‹ä¾èµ–äºå¤šæ¨¡æ€è¾“å…¥ï¼Œå…¶ä¸­è¯­è¨€æŒ‡ä»¤åœ¨é¢„æµ‹åŠ¨ä½œå’Œè§£é‡Šç”¨æˆ·æ„å›¾æ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ã€‚æœ¬æ–‡ç ”ç©¶äº†VLAå¦‚ä½•è¯†åˆ«ã€è§£é‡Šå’Œå“åº”è™šå‡å‰ææŒ‡ä»¤ï¼Œå³å¼•ç”¨ç¯å¢ƒä¸­ç¼ºå¤±å¯¹è±¡æˆ–æ¡ä»¶çš„è‡ªç„¶è¯­è¨€å‘½ä»¤ã€‚æˆ‘ä»¬æå‡ºäº†Instruct-Verify-and-Actï¼ˆIVAï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ£€æµ‹æŒ‡ä»¤æ˜¯å¦å› è™šå‡å‰æè€Œæ— æ³•æ‰§è¡Œï¼Œå¹¶è¿›è¡Œè¯­è¨€ä¸Šçš„æ¾„æ¸…æˆ–ä¿®æ­£ï¼ŒåŒæ—¶åœ¨æ„ŸçŸ¥å’Œè¡ŒåŠ¨ä¸­æ‰¾åˆ°åˆç†çš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡æ„å»ºå¤§è§„æ¨¡æŒ‡ä»¤è°ƒä¼˜è®¾ç½®å¹¶è®­ç»ƒVLAæ¨¡å‹ï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒIVAåœ¨è™šå‡å‰ææ£€æµ‹å‡†ç¡®ç‡ä¸Šæé«˜äº†97.56%ï¼Œåœ¨è™šå‡å‰æåœºæ™¯ä¸­çš„æˆåŠŸå“åº”ç‡æå‡äº†50.78%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³VLAæ¨¡å‹åœ¨é¢å¯¹è™šå‡å‰ææŒ‡ä»¤æ—¶çš„è¯†åˆ«å’Œå“åº”èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æœ‰æ•ˆå¤„ç†ç”¨æˆ·çš„é”™è¯¯è¯·æ±‚ï¼Œå¯¼è‡´æ‰§è¡Œå¤±è´¥å’Œç”¨æˆ·ä½“éªŒä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„IVAæ¡†æ¶é€šè¿‡ä¸‰ä¸ªæ­¥éª¤æ¥è§£å†³è¿™ä¸€é—®é¢˜ï¼šé¦–å…ˆæ£€æµ‹æŒ‡ä»¤æ˜¯å¦å› è™šå‡å‰æè€Œæ— æ³•æ‰§è¡Œï¼›å…¶æ¬¡è¿›è¡Œè¯­è¨€ä¸Šçš„æ¾„æ¸…æˆ–ä¿®æ­£ï¼›æœ€ååœ¨æ„ŸçŸ¥å’Œè¡ŒåŠ¨ä¸­æ‰¾åˆ°åˆç†çš„æ›¿ä»£æ–¹æ¡ˆã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾å¹¶æä¾›æœ‰æ•ˆåé¦ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIVAæ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæŒ‡ä»¤æ£€æµ‹æ¨¡å—ã€è¯­è¨€æ¾„æ¸…æ¨¡å—å’Œæ›¿ä»£æ–¹æ¡ˆç”Ÿæˆæ¨¡å—ã€‚æŒ‡ä»¤æ£€æµ‹æ¨¡å—è´Ÿè´£è¯†åˆ«è™šå‡å‰æï¼Œè¯­è¨€æ¾„æ¸…æ¨¡å—ä¸ç”¨æˆ·è¿›è¡Œäº¤äº’ï¼Œè€Œæ›¿ä»£æ–¹æ¡ˆç”Ÿæˆæ¨¡å—åˆ™åŸºäºç¯å¢ƒæ„ŸçŸ¥æä¾›å¯è¡Œçš„è¡ŒåŠ¨å»ºè®®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†è™šå‡å‰ææ£€æµ‹å’Œè¯­è¨€æ¾„æ¸…çš„ç»“åˆï¼Œä½¿å¾—VLAæ¨¡å‹ä¸ä»…èƒ½æ‰§è¡Œä»»åŠ¡ï¼Œè¿˜èƒ½æœ‰æ•ˆå¤„ç†æ— æ³•æ‰§è¡Œçš„æƒ…å†µã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ä»…ä¾èµ–äºæŒ‡ä»¤æ‰§è¡Œçš„æ¨¡å‹æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åŠåˆæˆæ•°æ®é›†ï¼ŒåŒ…å«æ­£å‘å’Œè™šå‡å‰ææŒ‡ä»¤çš„é…å¯¹ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚æ­¤å¤–ï¼Œé‡‡ç”¨äº†ç»“æ„åŒ–çš„è¯­è¨€æç¤ºå’Œç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIVAæ¡†æ¶åœ¨è™šå‡å‰ææ£€æµ‹çš„å‡†ç¡®ç‡ä¸Šè¾¾åˆ°äº†97.56%ï¼Œç›¸æ¯”åŸºçº¿æ¨¡å‹æœ‰æ˜¾è‘—æå‡ã€‚åŒæ—¶ï¼Œåœ¨è™šå‡å‰æåœºæ™¯ä¸­çš„æˆåŠŸå“åº”ç‡æé«˜äº†50.78%ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœåŠ¡æœºå™¨äººå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚é€šè¿‡æå‡VLAæ¨¡å‹å¯¹è™šå‡å‰ææŒ‡ä»¤çš„å¤„ç†èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æ”¹å–„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„å¯é æ€§ï¼Œæœªæ¥å¯èƒ½åœ¨æ›´å¤šå¤æ‚ç¯å¢ƒä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, Vision-Language-Action (VLA) models have demonstrated strong performance on a range of robotic tasks. These models rely on multimodal inputs, with language instructions playing a crucial role -- not only in predicting actions, but also in robustly interpreting user intent, even when the requests are impossible to fulfill. In this work, we investigate how VLAs can recognize, interpret, and respond to false-premise instructions: natural language commands that reference objects or conditions absent from the environment. We propose Instruct-Verify-and-Act (IVA), a unified framework that (i) detects when an instruction cannot be executed due to a false premise, (ii) engages in language-based clarification or correction, and (iii) grounds plausible alternatives in perception and action. Towards this end, we construct a large-scale instruction tuning setup with structured language prompts and train a VLA model capable of handling both accurate and erroneous requests. Our approach leverages a contextually augmented, semi-synthetic dataset containing paired positive and false-premise instructions, enabling robust detection and natural language correction. Our experiments show that IVA improves false premise detection accuracy by 97.56% over baselines, while increasing successful responses in false-premise scenarios by 50.78%.

