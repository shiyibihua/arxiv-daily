---
layout: default
title: Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation
---

# Clone What You Can't Steal: Black-Box LLM Replication via Logit Leakage and Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00973" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00973v1</a>
  <a href="https://arxiv.org/pdf/2509.00973.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00973v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00973v1', 'Clone What You Can\'t Steal: Black-Box LLM Replication via Logit Leakage and Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kanchon Gharami, Hansaka Aluvihare, Shafika Showkat Moni, Berker PekÃ¶z

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

**å¤‡æ³¨**: 8 pages. Accepted for publication in the proceedings of 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (IEEE TPS 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé»‘ç®±LLMå¤åˆ¶æ–¹æ³•ä»¥åº”å¯¹APIå®‰å…¨æ¼æ´**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é»‘ç®±æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `logitæ³„æ¼` `æ¨¡å‹è’¸é¦` `APIå®‰å…¨` `å¥‡å¼‚å€¼åˆ†è§£` `æ¨ç†é€Ÿåº¦æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é‡å»ºè¾“å‡ºå±‚æˆ–è’¸é¦è¡¨é¢è¡Œä¸ºï¼Œä½†åœ¨ä¸¥æ ¼æŸ¥è¯¢é™åˆ¶ä¸‹é‡å»ºé»‘ç®±æ¨¡å‹çš„ç ”ç©¶ä»ç„¶ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å—é™å¤åˆ¶ç®¡é“ï¼Œå°†éƒ¨åˆ†logitæ³„æ¼è½¬åŒ–ä¸ºåŠŸèƒ½æ€§å¯éƒ¨ç½²çš„æ›¿ä»£æ¨¡å‹ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•è¿›è¡Œå¤„ç†ã€‚
3. å®éªŒæ˜¾ç¤ºï¼Œ6å±‚å­¦ç”Ÿæ¨¡å‹é‡ç°äº†æ•™å¸ˆæ¨¡å‹çš„é«˜è¾¾97.6%çš„æ€§èƒ½ï¼Œä¸”åœ¨æ¨ç†é€Ÿåº¦å’Œå‚æ•°é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å…³é”®ä»»åŠ¡ç³»ç»Ÿä¸­çš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†å…¶APIçš„å®‰å…¨æ€§å¸¸å¸¸ä¸è¶³ï¼Œå¯èƒ½å¯¼è‡´é‡è¦ä¿¡æ¯æ³„éœ²ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å—é™å¤åˆ¶ç®¡é“ï¼Œé€šè¿‡éƒ¨åˆ†logitæ³„æ¼ç”Ÿæˆå¯éƒ¨ç½²çš„æ›¿ä»£æ¨¡å‹ã€‚è¯¥æ–¹æ³•åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆé€šè¿‡å¥‡å¼‚å€¼åˆ†è§£é‡å»ºè¾“å‡ºæŠ•å½±çŸ©é˜µï¼Œç„¶åå°†å‰©ä½™æ¶æ„è’¸é¦ä¸ºç´§å‡‘çš„å­¦ç”Ÿæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ6å±‚å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿé‡ç°97.6%çš„æ•™å¸ˆæ¨¡å‹éšè—çŠ¶æ€å‡ ä½•ï¼Œä¸”ä»…å¢åŠ 7.31%çš„å›°æƒ‘åº¦ï¼Œå±•ç¤ºäº†åœ¨æœ‰é™æŸ¥è¯¢æ¡ä»¶ä¸‹å¿«é€Ÿå…‹éš†LLMçš„å¯èƒ½æ€§ï¼Œå¼ºè°ƒäº†åŠ å¼ºæ¨ç†APIå®‰å…¨çš„ç´§è¿«æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨APIå®‰å…¨æ€§ä¸è¶³çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•åœ¨ä¸¥æ ¼æŸ¥è¯¢é™åˆ¶ä¸‹æœ‰æ•ˆå¤åˆ¶é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è¾“å‡ºå±‚é‡å»ºæˆ–è¡¨é¢è¡Œä¸ºè’¸é¦ï¼Œç¼ºä¹å¯¹é»‘ç®±æ¨¡å‹çš„æ·±å…¥å¤åˆ¶ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡éƒ¨åˆ†logitæ³„æ¼ï¼Œåˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰é‡å»ºè¾“å‡ºæŠ•å½±çŸ©é˜µï¼Œå¹¶å°†å‰©ä½™çš„æ¨¡å‹æ¶æ„è’¸é¦ä¸ºç´§å‡‘çš„å­¦ç”Ÿæ¨¡å‹ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨åœ¨æœ‰é™çš„æŸ¥è¯¢æ¬¡æ•°å†…å®ç°é«˜æ•ˆçš„æ¨¡å‹å¤åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡æ”¶é›†å°‘äº10kçš„é»‘ç®±æŸ¥è¯¢çš„top-k logitsï¼Œä½¿ç”¨SVDé‡å»ºè¾“å‡ºæŠ•å½±çŸ©é˜µï¼›ç¬¬äºŒé˜¶æ®µï¼Œåˆ©ç”¨å¼€æºæ•°æ®é›†å¯¹ä¸åŒæ·±åº¦çš„å­¦ç”Ÿæ¨¡å‹è¿›è¡Œè’¸é¦è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å—é™å¤åˆ¶ç®¡é“ï¼Œèƒ½å¤Ÿåœ¨ä¸¥æ ¼çš„æŸ¥è¯¢é™åˆ¶ä¸‹æœ‰æ•ˆé‡å»ºé»‘ç®±æ¨¡å‹çš„è¾“å‡ºå±‚ï¼Œå¹¶æˆåŠŸè’¸é¦å‡ºç´§å‡‘çš„å­¦ç”Ÿæ¨¡å‹ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶å¯¹æŸ¥è¯¢æ¬¡æ•°çš„é«˜æ•ˆåˆ©ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œ6å±‚å­¦ç”Ÿæ¨¡å‹é‡ç°äº†æ•™å¸ˆæ¨¡å‹çš„97.6%éšè—çŠ¶æ€å‡ ä½•ï¼Œä¸”å›°æƒ‘åº¦ä»…å¢åŠ 7.31%ã€‚æ­¤å¤–ï¼Œ4å±‚å˜ä½“åœ¨æ¨ç†é€Ÿåº¦ä¸Šæå‡äº†17.1%ï¼Œå‚æ•°é‡å‡å°‘äº†18.1%ï¼Œå±•ç¤ºäº†æ¨¡å‹å‹ç¼©çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ6å±‚å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿé‡ç°æ•™å¸ˆæ¨¡å‹çš„97.6%æ€§èƒ½ï¼Œå›°æƒ‘åº¦ä»…å¢åŠ 7.31%ã€‚4å±‚å˜ä½“åœ¨æ¨ç†é€Ÿåº¦ä¸Šæå‡17.1%ï¼Œå‚æ•°é‡å‡å°‘18.1%ã€‚æ•´ä¸ªæ”»å‡»è¿‡ç¨‹åœ¨24å°æ—¶å†…å®Œæˆï¼Œä¸”æœªè§¦å‘APIé€Ÿç‡é™åˆ¶ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•çš„é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å†›äº‹å†³ç­–æ”¯æŒã€å«æ˜Ÿæ“ä½œå’Œç½‘ç»œé˜²å¾¡ç­‰å…³é”®ä»»åŠ¡ç³»ç»Ÿã€‚é€šè¿‡æé«˜APIçš„å®‰å…¨æ€§å’Œé˜²å¾¡èƒ½åŠ›ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½é»‘ç®±æ¨¡å‹è¢«å¤åˆ¶çš„é£é™©ï¼Œä»è€Œä¿æŠ¤æ•æ„Ÿä¿¡æ¯å’Œç³»ç»Ÿå®‰å…¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å®‰å…¨çš„æ¨¡å‹éƒ¨ç½²å’ŒAPIè®¾è®¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly deployed in mission-critical systems, facilitating tasks such as satellite operations, command-and-control, military decision support, and cyber defense. Many of these systems are accessed through application programming interfaces (APIs). When such APIs lack robust access controls, they can expose full or top-k logits, creating a significant and often overlooked attack surface. Prior art has mainly focused on reconstructing the output projection layer or distilling surface-level behaviors. However, regenerating a black-box model under tight query constraints remains underexplored. We address that gap by introducing a constrained replication pipeline that transforms partial logit leakage into a functional deployable substitute model clone. Our two-stage approach (i) reconstructs the output projection matrix by collecting top-k logits from under 10k black-box queries via singular value decomposition (SVD) over the logits, then (ii) distills the remaining architecture into compact student models with varying transformer depths, trained on an open source dataset. A 6-layer student recreates 97.6% of the 6-layer teacher model's hidden-state geometry, with only a 7.31% perplexity increase, and a 7.58 Negative Log-Likelihood (NLL). A 4-layer variant achieves 17.1% faster inference and 18.1% parameter reduction with comparable performance. The entire attack completes in under 24 graphics processing unit (GPU) hours and avoids triggering API rate-limit defenses. These results demonstrate how quickly a cost-limited adversary can clone an LLM, underscoring the urgent need for hardened inference APIs and secure on-premise defense deployments.

