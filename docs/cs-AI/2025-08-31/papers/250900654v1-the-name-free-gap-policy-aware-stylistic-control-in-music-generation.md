---
layout: default
title: The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation
---

# The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00654" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00654v1</a>
  <a href="https://arxiv.org/pdf/2509.00654.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00654v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00654v1', 'The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ashwin Nagarajan, Hao-Wen Dong

**åˆ†ç±»**: cs.SD, cs.AI, cs.LG, cs.MM, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

**å¤‡æ³¨**: 10 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— åé—´éš™ä»¥å®ç°éŸ³ä¹ç”Ÿæˆä¸­çš„é£æ ¼æ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³ä¹ç”Ÿæˆ` `é£æ ¼æ§åˆ¶` `æ–‡æœ¬åˆ°éŸ³ä¹` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ”¿ç­–åˆè§„æ€§` `ç»†ç²’åº¦æ§åˆ¶` `è‰ºæœ¯å®¶é£æ ¼` `æ— åé—´éš™`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³ä¹ç”Ÿæˆæ–¹æ³•åœ¨ç»†ç²’åº¦é£æ ¼æ§åˆ¶ä¸Šå­˜åœ¨æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è‰ºæœ¯å®¶åç§°å—é™çš„æƒ…å†µä¸‹ã€‚
2. è®ºæ–‡æå‡ºä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è½»é‡çº§ä¿®é¥°ç¬¦ä½œä¸ºé£æ ¼æ§åˆ¶çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé¿å…äº†é‡æ–°è®­ç»ƒçš„å¤æ‚æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè‰ºæœ¯å®¶åç§°æ˜¯æœ€å¼ºçš„æ§åˆ¶ä¿¡å·ï¼Œè€Œæ— åä¿®é¥°ç¬¦èƒ½å¤Ÿæœ‰æ•ˆæ¢å¤é£æ ¼æ§åˆ¶ï¼Œå®šä¹‰äº†æ— åé—´éš™çš„æ¦‚å¿µã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬åˆ°éŸ³ä¹æ¨¡å‹èƒ½å¤Ÿæ•æ‰ä¹å™¨æˆ–æƒ…ç»ªç­‰å¹¿æ³›å±æ€§ï¼Œä½†ç»†ç²’åº¦çš„é£æ ¼æ§åˆ¶ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„é£æ ¼åŒ–æ–¹æ³•é€šå¸¸éœ€è¦é‡æ–°è®­ç»ƒæˆ–ä¸“é—¨çš„æ¡ä»¶ï¼Œè¿™ä½¿å¾—å¯é‡å¤æ€§å˜å¾—å¤æ‚ï¼Œå¹¶åœ¨è‰ºæœ¯å®¶åç§°å—é™æ—¶é™åˆ¶äº†æ”¿ç­–åˆè§„æ€§ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä»å¤§å‹è¯­è¨€æ¨¡å‹ä¸­é‡‡æ ·çš„è½»é‡çº§ã€äººç±»å¯è¯»çš„ä¿®é¥°ç¬¦æ˜¯å¦å¯ä»¥æä¾›ä¸€ç§æ”¿ç­–ç¨³å¥çš„é£æ ¼æ§åˆ¶æ›¿ä»£æ–¹æ¡ˆã€‚ä½¿ç”¨MusicGen-smallï¼Œæˆ‘ä»¬è¯„ä¼°äº†ä¸¤ä½è‰ºæœ¯å®¶ï¼šBillie Eilishï¼ˆæµè¡Œæ­Œï¼‰å’ŒLudovico Einaudiï¼ˆå™¨ä¹é’¢ç´ï¼‰ã€‚ç»“æœè¡¨æ˜ï¼Œè‰ºæœ¯å®¶åç§°æ˜¯æœ€å¼ºçš„æ§åˆ¶ä¿¡å·ï¼Œè€Œæ— åä¿®é¥°ç¬¦åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ¢å¤äº†è¿™ç§æ•ˆæœã€‚è¿™çªæ˜¾äº†ç°æœ‰çš„ä¿æŠ¤æªæ–½ï¼Œå¦‚é™åˆ¶è‰ºæœ¯å®¶åç§°ï¼Œå¯èƒ½æ— æ³•å®Œå…¨é˜²æ­¢é£æ ¼æ¨¡ä»¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³éŸ³ä¹ç”Ÿæˆä¸­ç»†ç²’åº¦é£æ ¼æ§åˆ¶çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨è‰ºæœ¯å®¶åç§°å—é™æ—¶ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å®ç°æœ‰æ•ˆçš„é£æ ¼æ§åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è½»é‡çº§ä¿®é¥°ç¬¦ï¼Œæä¾›ä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒçš„æ”¿ç­–ç¨³å¥çš„é£æ ¼æ§åˆ¶æ–¹æ³•ï¼Œæ—¨åœ¨ç®€åŒ–é£æ ¼æ§åˆ¶çš„è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆç”ŸæˆåŸºäºè‰ºæœ¯å®¶çš„æç¤ºï¼›å…¶æ¬¡ä½¿ç”¨ä¸åŒçš„ä¿®é¥°ç¬¦è¿›è¡Œé£æ ¼æ§åˆ¶ï¼›æœ€åé€šè¿‡VGGishå’ŒCLAPåµŒå…¥è¿›è¡Œè¯„ä¼°ï¼Œæ¯”è¾ƒä¸åŒæç¤ºçš„æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†æ— åé—´éš™çš„æ¦‚å¿µï¼Œæ­ç¤ºäº†è‰ºæœ¯å®¶åç§°ä¸æ— åä¿®é¥°ç¬¦ä¹‹é—´çš„é£æ ¼æ§åˆ¶å·®å¼‚ï¼Œå¼ºè°ƒäº†ç°æœ‰ä¿æŠ¤æªæ–½çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†15ä¸ªå‚è€ƒç‰‡æ®µå’Œä¸‰ç§æ¡ä»¶ï¼ˆåŸºçº¿æç¤ºã€è‰ºæœ¯å®¶åç§°æç¤ºå’Œäº”ç»„æè¿°ç¬¦ï¼‰ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°çš„æœ€å°è·ç¦»å½’å› åº¦é‡æ¥è¯„ä¼°é£æ ¼ç›¸ä¼¼æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ— åä¿®é¥°ç¬¦åœ¨é£æ ¼æ§åˆ¶ä¸Šè¡¨ç°å‡ºè‰²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè‰ºæœ¯å®¶åç§°æ˜¯æœ€å¼ºçš„æ§åˆ¶ä¿¡å·ï¼Œè€Œæ— åä¿®é¥°ç¬¦èƒ½å¤Ÿæ¢å¤å¤§éƒ¨åˆ†é£æ ¼æ§åˆ¶æ•ˆæœã€‚å…·ä½“è€Œè¨€ï¼Œè·¨è‰ºæœ¯å®¶çš„è½¬ç§»å‡å°‘äº†å¯¹é½ï¼Œè¡¨æ˜æè¿°ç¬¦ç¼–ç äº†é’ˆå¯¹æ€§çš„é£æ ¼çº¿ç´¢ã€‚è¿™ä¸€å‘ç°ä¸ºéŸ³ä¹ç”Ÿæˆä¸­çš„é£æ ¼æ§åˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éŸ³ä¹åˆ›ä½œã€æ¸¸æˆéŸ³æ•ˆç”Ÿæˆå’Œå½±è§†é…ä¹ç­‰ã€‚é€šè¿‡æä¾›ä¸€ç§æ”¿ç­–ç¨³å¥çš„é£æ ¼æ§åˆ¶æ–¹æ³•ï¼Œå¯ä»¥å¸®åŠ©åˆ›ä½œè€…åœ¨ä¸ä¾µçŠ¯ç‰ˆæƒçš„æƒ…å†µä¸‹ï¼Œçµæ´»åœ°ç”Ÿæˆç¬¦åˆç‰¹å®šé£æ ¼çš„éŸ³ä¹ä½œå“ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Text-to-music models capture broad attributes such as instrumentation or mood, but fine-grained stylistic control remains an open challenge. Existing stylization methods typically require retraining or specialized conditioning, which complicates reproducibility and limits policy compliance when artist names are restricted. We study whether lightweight, human-readable modifiers sampled from a large language model can provide a policy-robust alternative for stylistic control. Using MusicGen-small, we evaluate two artists: Billie Eilish (vocal pop) and Ludovico Einaudi (instrumental piano). For each artist, we use fifteen reference excerpts and evaluate matched seeds under three conditions: baseline prompts, artist-name prompts, and five descriptor sets. All prompts are generated using a large language model. Evaluation uses both VGGish and CLAP embeddings with distributional and per-clip similarity measures, including a new min-distance attribution metric. Results show that artist names are the strongest control signal across both artists, while name-free descriptors recover much of this effect. This highlights that existing safeguards such as the restriction of artist names in music generation prompts may not fully prevent style imitation. Cross-artist transfers reduce alignment, showing that descriptors encode targeted stylistic cues. We also present a descriptor table across ten contemporary artists to illustrate the breadth of the tokens. Together these findings define the name-free gap, the controllability difference between artist-name prompts and policy-compliant descriptors, shown through a reproducible evaluation protocol for prompt-level controllability.

