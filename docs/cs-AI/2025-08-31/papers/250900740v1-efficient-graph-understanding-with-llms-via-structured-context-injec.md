---
layout: default
title: Efficient Graph Understanding with LLMs via Structured Context Injection
---

# Efficient Graph Understanding with LLMs via Structured Context Injection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00740" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00740v1</a>
  <a href="https://arxiv.org/pdf/2509.00740.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00740v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00740v1', 'Efficient Graph Understanding with LLMs via Structured Context Injection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Govind Waghmare, Sumedh BG, Sonia Gupta, Srikanta Bedathur

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥ä»¥æå‡å›¾ç†è§£èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å›¾æ¨ç†` `ç»“æ„åŒ–ä¸Šä¸‹æ–‡` `è¾“å…¥æ³¨å…¥` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å›¾æ¨ç†ä»»åŠ¡æ—¶ï¼ŒLLMsé¢ä¸´æ¦‚å¿µæ˜ å°„çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. æå‡ºçš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥æ–¹æ³•ï¼Œé€šè¿‡ç›´æ¥åœ¨è¾“å…¥ä¸­åµŒå…¥ä»»åŠ¡ç‰¹å®šä¿¡æ¯ï¼ŒæŒ‡å¯¼LLMsè¿›è¡Œå›¾é—®é¢˜æ±‚è§£ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå›¾ä»»åŠ¡ä¸Šè¡¨ç°å‡ºä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œä¸”è®¡ç®—æˆæœ¬è¾ƒä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³å¤šä¸ªé¢†åŸŸçš„é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬ä¼ ç»Ÿä¸Šç”±ç¬¦å·æˆ–ç®—æ³•æ–¹æ³•å¤„ç†çš„å›¾ç›¸å…³ä»»åŠ¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥æ¡†æ¶ï¼Œå°†ä»»åŠ¡ç‰¹å®šä¿¡æ¯ç³»ç»Ÿæ€§åœ°åµŒå…¥è¾“å…¥ä¸­ï¼Œä»¥æŒ‡å¯¼LLMsè§£å†³å¹¿æ³›çš„å›¾é—®é¢˜ã€‚è¯¥æ–¹æ³•æ— éœ€å¯¹LLMsè¿›è¡Œå¾®è°ƒï¼Œå…·æœ‰æˆæœ¬æ•ˆç›Šå’Œè½»é‡åŒ–çš„ä¼˜åŠ¿ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒæŸäº›å›¾æ¨ç†ä»»åŠ¡å¯¹LLMsä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œé™¤éå°†å…¶æ˜ å°„åˆ°æ¦‚å¿µä¸Šæ‰æ ¹çš„è¡¨ç¤ºã€‚ç„¶è€Œï¼Œé€šè¿‡å¾®è°ƒæˆ–é‡å¤å¤šæ­¥æŸ¥è¯¢å®ç°è¿™ç§æ˜ å°„å¯èƒ½ä»£ä»·é«˜æ˜‚ä¸”æ•ˆç‡ä½ä¸‹ã€‚æˆ‘ä»¬çš„ç ”ç©¶æä¾›äº†ä¸€ç§å®ç”¨çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡ç›´æ¥å°†ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥è¾“å…¥ï¼Œä½¿LLMèƒ½å¤Ÿéšå¼åœ°å°†ä»»åŠ¡ä¸æ‰æ ¹çš„æ¦‚å¿µç©ºé—´å¯¹é½ã€‚æˆ‘ä»¬åœ¨å¤šä¸ªå›¾ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œçªå‡ºäº†å‡†ç¡®æ€§ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡ï¼Œç»“æœæ˜¾ç¤ºç»“æ„åŒ–è¾“å…¥ä¸Šä¸‹æ–‡çš„æ€§èƒ½æå‡ä¸æ›´å¤æ‚çš„æ–¹æ³•ç›¸å½“æˆ–æ›´ä¼˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å›¾æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç¼ºä¹æ¦‚å¿µæ˜ å°„æ—¶çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºå¾®è°ƒæˆ–å¤æ‚çš„æŸ¥è¯¢è¿‡ç¨‹ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œé«˜æˆæœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥ï¼Œç›´æ¥åœ¨è¾“å…¥ä¸­åµŒå…¥ä»»åŠ¡ç‰¹å®šçš„ä¿¡æ¯ï¼Œä»è€Œå¼•å¯¼LLMsè¿›è¡Œæ›´æœ‰æ•ˆçš„æ¨ç†ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹æ¨¡å‹çš„å¾®è°ƒï¼Œé™ä½äº†æˆæœ¬å’Œå¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥æ•°æ®çš„é¢„å¤„ç†ã€ç»“æ„åŒ–ä¸Šä¸‹æ–‡çš„ç”Ÿæˆå’Œæ³¨å…¥ã€ä»¥åŠLLMsçš„æ¨ç†è¿‡ç¨‹ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ä¸Šä¸‹æ–‡ç”Ÿæˆå™¨å’Œæ¨ç†å¼•æ“ï¼Œç¡®ä¿ä¿¡æ¯çš„æœ‰æ•ˆä¼ é€’ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç»“æ„åŒ–ä¸Šä¸‹æ–‡çš„æ³¨å…¥æ–¹å¼ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œç›´æ¥åˆ©ç”¨åµŒå…¥çš„ä¿¡æ¯è¿›è¡Œæ¨ç†ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ ¹æœ¬åŒºåˆ«åœ¨äºä¸ä¾èµ–äºæ¨¡å‹çš„é‡è®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„ä¸Šä¸‹æ–‡ç”Ÿæˆç­–ç•¥ï¼Œç¡®ä¿åµŒå…¥ä¿¡æ¯çš„ç›¸å…³æ€§å’Œæœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œä¼˜åŒ–äº†è¾“å…¥æ ¼å¼ï¼Œä»¥æé«˜æ¨¡å‹çš„ç†è§£èƒ½åŠ›å’Œæ¨ç†æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»“æ„åŒ–ä¸Šä¸‹æ–‡æ³¨å…¥æ–¹æ³•åœ¨å¤šä¸ªå›¾ä»»åŠ¡ä¸Šå®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å‡†ç¡®æ€§å’Œè®¡ç®—æˆæœ¬ä¹‹é—´çš„å¹³è¡¡æ–¹é¢ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°10%-20%ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤ç½‘ç»œåˆ†æã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œç”Ÿç‰©ä¿¡æ¯å­¦ç­‰ã€‚é€šè¿‡æå‡LLMsåœ¨å›¾ç†è§£ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥ä¸ºå¤æ‚æ•°æ®çš„åˆ†æå’Œå†³ç­–æä¾›æ›´å¼ºå¤§çš„æ”¯æŒï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have shown strong capabilities in solving problems across domains, including graph-related tasks traditionally addressed by symbolic or algorithmic methods. In this work, we present a framework for structured context injection, where task-specific information is systematically embedded in the input to guide LLMs in solving a wide range of graph problems. Our method does not require fine-tuning of LLMs, making it cost-efficient and lightweight. We observe that certain graph reasoning tasks remain challenging for LLMs unless they are mapped to conceptually grounded representations. However, achieving such mappings through fine-tuning or repeated multi-step querying can be expensive and inefficient. Our approach offers a practical alternative by injecting structured context directly into the input, enabling the LLM to implicitly align the task with grounded conceptual spaces. We evaluate the approach on multiple graph tasks using both lightweight and large models, highlighting the trade-offs between accuracy and computational cost. The results demonstrate consistent performance improvements, showing that structured input context can rival or surpass more complex approaches. Our findings underscore the value of structured context injection as an effective and scalable strategy for graph understanding with LLMs.

