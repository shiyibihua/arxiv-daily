---
layout: default
title: A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants
---

# A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.06223" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.06223v2</a>
  <a href="https://arxiv.org/pdf/2510.06223.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.06223v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.06223v2', 'A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hans G. W. van Dam

**åˆ†ç±»**: cs.HC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31 (æ›´æ–°: 2025-10-09)

**å¤‡æ³¨**: 24 pages, 19 figures, code available at https://github.com/hansvdam/langbar

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/hansvdam/langbar)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€GUIæ¶æ„ä»¥å®ç°ä¸LLMå¯¹è¯åŠ©æ‰‹çš„äº¤äº’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€äº¤äº’` `å›¾å½¢ç”¨æˆ·ç•Œé¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­éŸ³è¯†åˆ«` `æ¨¡å‹ä¸Šä¸‹æ–‡åè®®` `MVVMæ¨¡å¼` `å¼€æºLLM`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å›¾å½¢ç”¨æˆ·ç•Œé¢åº”ç”¨å¤§å¤šæœªè€ƒè™‘è¯­éŸ³äº¤äº’ï¼Œå¯¼è‡´ç”¨æˆ·ä½“éªŒä¸ä½³ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨LLMçš„èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€GUIæ¶æ„ï¼Œé€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰å®ç°è¯­éŸ³åŠ©æ‰‹ä¸åº”ç”¨çš„æœ‰æ•ˆäº¤äº’ï¼Œç¡®ä¿è¯­éŸ³è¾“å…¥ä¸è§†è§‰ç•Œé¢çš„å¯¹é½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æœ¬åœ°å¼€æºLLMçš„å¤šæ¨¡æ€ç”¨æˆ·ç•Œé¢åœ¨å‡†ç¡®æ€§ä¸Šæ¥è¿‘é¢†å…ˆçš„ä¸“æœ‰æ¨¡å‹ï¼Œä¸”å“åº”é€Ÿåº¦è‰¯å¥½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå®æ—¶è¯­éŸ³è¯†åˆ«æŠ€æœ¯çš„è¿›æ­¥ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è‡ªç„¶è¯­è¨€å‘å‡ºå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ“ä½œï¼Œå¹¶ç›´æ¥é€šè¿‡GUIæ¥æ”¶ç›¸åº”çš„ç³»ç»Ÿåé¦ˆã€‚å¤§å¤šæ•°ç°æœ‰åº”ç”¨å¹¶æœªè€ƒè™‘è¯­éŸ³äº¤äº’ã€‚æœ¬æ–‡æä¾›äº†ä¸€ç§å…·ä½“æ¶æ„ï¼Œä½¿å¾—GUIèƒ½å¤Ÿä¸åŸºäºLLMçš„è¯­éŸ³åŠ©æ‰‹è¿›è¡Œæœ‰æ•ˆäº¤äº’ã€‚è¯¥æ¶æ„é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä½¿åº”ç”¨çš„å¯¼èˆªå›¾å’Œè¯­ä¹‰å¯ç”¨ï¼Œç¡®ä¿è¯­éŸ³è¾“å…¥ä¸è§†è§‰ç•Œé¢çš„å¯é å¯¹é½ï¼Œå¹¶åœ¨ä¸åŒæ¨¡æ€ä¹‹é—´æä¾›ä¸€è‡´çš„åé¦ˆã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜è¯„ä¼°äº†æœ¬åœ°å¯éƒ¨ç½²çš„å¼€æºLLMåœ¨è¯­éŸ³å¤šæ¨¡æ€ç”¨æˆ·ç•Œé¢ä¸­çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜ï¼Œè¿‘æœŸçš„å°å‹å¼€æºæ¨¡å‹åœ¨æ•´ä½“å‡†ç¡®æ€§ä¸Šæ¥è¿‘é¢†å…ˆçš„ä¸“æœ‰æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾å½¢ç”¨æˆ·ç•Œé¢åº”ç”¨æœªè€ƒè™‘è¯­éŸ³äº¤äº’çš„é—®é¢˜ï¼Œå¯¼è‡´ç”¨æˆ·æ— æ³•é€šè¿‡è‡ªç„¶è¯­è¨€é«˜æ•ˆæ“ä½œåº”ç”¨ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹è¯­éŸ³è¾“å…¥ä¸è§†è§‰ç•Œé¢çš„æœ‰æ•ˆå¯¹é½ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¶æ„é€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ä½¿å¾—åº”ç”¨çš„å¯¼èˆªå›¾å’Œè¯­ä¹‰å¯ç”¨ï¼Œä»è€Œå®ç°è¯­éŸ³åŠ©æ‰‹ä¸åº”ç”¨çš„æœ‰æ•ˆäº¤äº’ã€‚è¯¥è®¾è®¡ç¡®ä¿äº†è¯­éŸ³è¾“å…¥ä¸è§†è§‰ç•Œé¢çš„å¯é å¯¹é½ï¼Œå¹¶æä¾›ä¸€è‡´çš„åé¦ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰ã€è§†å›¾æ¨¡å‹ï¼ˆViewModelï¼‰å’Œå›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰æ ‘è·¯ç”±å™¨ã€‚MCPè´Ÿè´£æä¾›åº”ç”¨çš„å¯¼èˆªä¿¡æ¯ï¼ŒViewModelåˆ™å°†åº”ç”¨çš„èƒ½åŠ›æš´éœ²ç»™åŠ©æ‰‹ï¼Œç¡®ä¿è¯­éŸ³è¾“å…¥çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†MCPä¸MVVMæ¨¡å¼ç»“åˆï¼Œä½¿å¾—åº”ç”¨èƒ½å¤Ÿåœ¨è¯­éŸ³äº¤äº’ä¸­ä¿æŒé«˜æ•ˆæ€§å’Œä¸€è‡´æ€§ã€‚è¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå…¶å…¨é¢æ”¯æŒè¯­éŸ³äº¤äº’ï¼Œæå‡äº†ç”¨æˆ·ä½“éªŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¶æ„ä¸­ï¼Œè§†å›¾æ¨¡å‹éœ€è¦æä¾›å½“å‰å¯è§è§†å›¾çš„å·¥å…·å’Œåº”ç”¨å…¨å±€å·¥å…·ï¼Œç¡®ä¿åŠ©æ‰‹èƒ½å¤Ÿè·å–å¿…è¦çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†æœ¬åœ°å¯éƒ¨ç½²çš„å¼€æºLLMçš„æœ‰æ•ˆæ€§ï¼Œå¼ºè°ƒäº†å¯¹éšç§å’Œæ•°æ®å®‰å…¨çš„å…³æ³¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿‘æœŸçš„å°å‹å¼€æºLLMåœ¨æ•´ä½“å‡†ç¡®æ€§ä¸Šæ¥è¿‘é¢†å…ˆçš„ä¸“æœ‰æ¨¡å‹ï¼Œä¸”åœ¨å“åº”é€Ÿåº¦ä¸Šè¡¨ç°è‰¯å¥½ï¼Œé€‚åˆä¼ä¸šçº§ç¡¬ä»¶ä½¿ç”¨ã€‚è¿™ä¸€å‘ç°ä¸ºå¤šæ¨¡æ€ç”¨æˆ·ç•Œé¢çš„å®ç°æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€è½¦è½½ç³»ç»Ÿå’Œå„ç§éœ€è¦è¯­éŸ³äº¤äº’çš„åº”ç”¨ç¨‹åºã€‚é€šè¿‡å®ç°ä¸LLMçš„æœ‰æ•ˆäº¤äº’ï¼Œç”¨æˆ·èƒ½å¤Ÿæ›´è‡ªç„¶åœ°æ§åˆ¶åº”ç”¨ï¼Œæå‡ä½¿ç”¨ä½“éªŒã€‚æœªæ¥ï¼Œéšç€æ“ä½œç³»ç»Ÿè¶…çº§åŠ©æ‰‹çš„å‘å±•ï¼Œè¯¥æ¶æ„å°†ä¸ºåº”ç”¨æä¾›æ›´å¼ºçš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Advances in large language models (LLMs) and real-time speech recognition now make it possible to issue any graphical user interface (GUI) action through natural language and receive the corresponding system response directly through the GUI. Most production applications were never designed with speech in mind. This article provides a concrete architecture that enables GUIs to interface with LLM-based speech-enabled assistants.
>   The architecture makes an application's navigation graph and semantics available through the Model Context Protocol (MCP). The ViewModel, part of the MVVM (Model-View-ViewModel) pattern, exposes the application's capabilities to the assistant by supplying both tools applicable to a currently visible view and application-global tools extracted from the GUI tree router. This architecture facilitates full voice accessibility while ensuring reliable alignment between spoken input and the visual interface, accompanied by consistent feedback across modalities. It future-proofs apps for upcoming OS super assistants that employ computer use agents (CUAs) and natively consume MCP if an application provides it.
>   To address concerns about privacy and data security, the practical effectiveness of locally deployable, open-weight LLMs for speech-enabled multimodal UIs is evaluated. Findings suggest that recent smaller open-weight models approach the performance of leading proprietary models in overall accuracy and require enterprise-grade hardware for fast responsiveness.
>   A demo implementation of the proposed architecture can be found at https://github.com/hansvdam/langbar

