---
layout: default
title: OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination
---

# OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00723" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00723v1</a>
  <a href="https://arxiv.org/pdf/2509.00723.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00723v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00723v1', 'OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junzhe Chen, Tianshu Zhang, Shiyu Huang, Yuwei Niu, Chao Sun, Rongzhou Zhang, Guanyu Zhou, Lijie Wen, Xuming Hu

**åˆ†ç±»**: cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniDPOæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹` `å¹»è§‰é—®é¢˜` `éŸ³è§†é¢‘ç†è§£` `åå¥½å¯¹é½` `æ¨ç†èƒ½åŠ›æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éŸ³è§†é¢‘ä¿¡æ¯æ—¶ï¼Œå¸¸å¸¸å—åˆ°æ–‡æœ¬æ¨¡æ€çš„å½±å“ï¼Œå¯¼è‡´å¹»è§‰ç°è±¡çš„å‡ºç°ã€‚
2. æœ¬æ–‡æå‡ºçš„OmniDPOæ¡†æ¶é€šè¿‡æ„å»ºåå¥½æ ·æœ¬å¯¹ï¼Œå¢å¼ºæ¨¡å‹å¯¹éŸ³è§†é¢‘äº¤äº’çš„ç†è§£ï¼Œä»è€Œå‡è½»å¹»è§‰é—®é¢˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOmniDPOä¸ä»…æœ‰æ•ˆå‡å°‘äº†å¤šæ¨¡æ€å¹»è§‰ï¼Œè¿˜æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å„æ¨¡æ€é—´çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆOLLMsï¼‰åœ¨éŸ³è§†é¢‘ç†è§£å’Œå®æ—¶ç¯å¢ƒæ„ŸçŸ¥ç­‰ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆæœã€‚ç„¶è€Œï¼Œå¹»è§‰é—®é¢˜ä¾ç„¶å­˜åœ¨ï¼Œæ–‡æœ¬æ¨¡æ€çš„å…ˆéªŒä¿¡æ¯å¾€å¾€ä¸»å¯¼æ¨¡å‹çš„å†³ç­–ï¼Œå¯¼è‡´å…¶å¿½è§†è§†è§‰å’ŒéŸ³é¢‘ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç°æœ‰æ¨¡å‹åœ¨è®­ç»ƒæ—¶ç‹¬ç«‹å¯¹é½è§†è§‰æˆ–å¬è§‰æ¨¡æ€ä¸æ–‡æœ¬ï¼Œå¿½ç•¥äº†è§†é¢‘ä¸å…¶å¯¹åº”éŸ³é¢‘ä¹‹é—´çš„å†…åœ¨å…³è”ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†OmniDPOï¼Œä¸€ä¸ªæ—¨åœ¨å‡è½»OLLMså¹»è§‰çš„åå¥½å¯¹é½æ¡†æ¶ã€‚OmniDPOé€šè¿‡æ„å»ºæ–‡æœ¬åå¥½æ ·æœ¬å¯¹å’Œå¤šæ¨¡æ€åå¥½æ ·æœ¬å¯¹ï¼Œå¢å¼ºæ¨¡å‹å¯¹éŸ³è§†é¢‘äº¤äº’çš„ç†è§£å’Œå¯¹è§†è§‰ã€å¬è§‰ä¿¡æ¯çš„å…³æ³¨ï¼Œä»è€Œæœ‰æ•ˆæ”¹å–„å¤šæ¨¡æ€åŸºç¡€å’Œå‡å°‘å¹»è§‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniDPOæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆOLLMsï¼‰åœ¨éŸ³è§†é¢‘ç†è§£ä¸­å‡ºç°çš„å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†è§†é¢‘ä¸éŸ³é¢‘ä¹‹é—´çš„å†…åœ¨å…³è”ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ¨ç†æ—¶ä¾èµ–æ–‡æœ¬ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOmniDPOæ¡†æ¶é€šè¿‡æ„å»ºæ–‡æœ¬åå¥½æ ·æœ¬å¯¹å’Œå¤šæ¨¡æ€åå¥½æ ·æœ¬å¯¹ï¼Œå¢å¼ºæ¨¡å‹å¯¹éŸ³è§†é¢‘äº¤äº’çš„ç†è§£ï¼Œæ—¨åœ¨æå‡æ¨¡å‹å¯¹è§†è§‰å’Œå¬è§‰ä¿¡æ¯çš„å…³æ³¨åº¦ï¼Œä»è€Œå‡è½»å¹»è§‰ç°è±¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOmniDPOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬åå¥½æ ·æœ¬å¯¹çš„æ„å»ºå’Œå¤šæ¨¡æ€åå¥½æ ·æœ¬å¯¹çš„æ„å»ºã€‚å‰è€…å¸®åŠ©æ¨¡å‹ç†è§£éŸ³è§†é¢‘ä¹‹é—´çš„å…³ç³»ï¼Œåè€…åˆ™å¼ºåŒ–æ¨¡å‹å¯¹å¤šæ¨¡æ€ä¿¡æ¯çš„å…³æ³¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šOmniDPOçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåŒæ—¶è€ƒè™‘æ–‡æœ¬ä¸å¤šæ¨¡æ€åå¥½æ ·æœ¬å¯¹çš„æ„å»ºï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•ä¸­å¯¹æ¨¡æ€ç‹¬ç«‹å¯¹é½çš„ä¸è¶³ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–åå¥½å¯¹çš„æ„å»ºï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°éŸ³è§†é¢‘ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æå‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOmniDPOæ˜¾è‘—å‡å°‘äº†å¤šæ¨¡æ€å¹»è§‰ï¼Œæå‡äº†æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€é—´çš„æ¨ç†èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†å‡†ç¡®ç‡æé«˜äº†15%ï¼Œåœ¨éŸ³è§†é¢‘ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å°¤ä¸ºçªå‡ºï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

OmniDPOæ¡†æ¶åœ¨éŸ³è§†é¢‘ç†è§£ã€å®æ—¶ç¯å¢ƒæ„ŸçŸ¥ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡å‡è½»å¹»è§‰é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¯ä»¥æå‡å¤šæ¨¡æ€ç³»ç»Ÿçš„å¯é æ€§å’Œå‡†ç¡®æ€§ï¼Œä¿ƒè¿›æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€ç›‘æ§ç³»ç»Ÿç­‰æŠ€æœ¯çš„å‘å±•ï¼Œæœªæ¥å¯èƒ½åœ¨æ›´å¤æ‚çš„å¤šæ¨¡æ€äº¤äº’åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, Omni-modal large language models (OLLMs) have sparked a new wave of research, achieving impressive results in tasks such as audio-video understanding and real-time environment perception. However, hallucination issues still persist. Similar to the bimodal setting, the priors from the text modality tend to dominate, leading OLLMs to rely more heavily on textual cues while neglecting visual and audio information. In addition, fully multimodal scenarios introduce new challenges. Most existing models align visual or auditory modalities with text independently during training, while ignoring the intrinsic correlations between video and its corresponding audio. This oversight results in hallucinations when reasoning requires interpreting hidden audio cues embedded in video content. To address these challenges, we propose OmniDPO, a preference-alignment framework designed to mitigate hallucinations in OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing text-preference sample pairs to enhance the model's understanding of audio-video interactions; and (2) constructing multimodal-preference sample pairs to strengthen the model's attention to visual and auditory information. By tackling both challenges, OmniDPO effectively improves multimodal grounding and reduces hallucination. Experiments conducted on two OLLMs demonstrate that OmniDPO not only effectively mitigates multimodal hallucinations but also significantly enhances the models' reasoning capabilities across modalities. All code and datasets will be released upon paper acceptance.

