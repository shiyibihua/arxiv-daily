---
layout: default
title: Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models
---

# Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00963" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00963v1</a>
  <a href="https://arxiv.org/pdf/2509.00963.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00963v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00963v1', 'Who Gets Left Behind? Auditing Disability Inclusivity in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Deepika Dash, Yeshil Bangera, Mithil Bangera, Gouthami Vadithya, Srikant Panda

**åˆ†ç±»**: cs.CY, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— éšœç¢å®¡è®¡åŸºå‡†ä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ…å®¹æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ— éšœç¢æŠ€æœ¯` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŒ…å®¹æ€§å®¡è®¡` `æ®‹ç–¾æ”¯æŒ` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ— éšœç¢æŒ‡å¯¼ä¸­å­˜åœ¨æ˜æ˜¾çš„åŒ…å®¹æ€§å·®è·ï¼Œè®¸å¤šæ®‹ç–¾ç¾¤ä½“æœªèƒ½è·å¾—æœ‰æ•ˆæ”¯æŒã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç³»ç»Ÿçš„å®¡è®¡æ¡†æ¶ï¼Œé€šè¿‡äººç±»éªŒè¯çš„æ— éšœç¢é—®é¢˜åŸºå‡†ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ®‹ç–¾ç±»åˆ«çš„è¦†ç›–æƒ…å†µã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡è§†è§‰ã€å¬è§‰å’Œè¿åŠ¨æ®‹ç–¾çš„æ”¯æŒè¾ƒä¸ºå……åˆ†ï¼Œä½†å…¶ä»–ç±»åˆ«å¦‚å¿ƒç†å¥åº·ç­‰ä»æ˜¾è‘—ä¸è¶³ï¼ŒäºŸéœ€æ”¹è¿›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ— éšœç¢æŒ‡å¯¼ä¸­è¶Šæ¥è¶Šå¤šåœ°è¢«ä½¿ç”¨ï¼Œä½†è®¸å¤šæ®‹ç–¾ç¾¤ä½“ä»æœªå¾—åˆ°å……åˆ†æœåŠ¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸åˆ†ç±»æ³•å¯¹é½çš„äººç±»éªŒè¯çš„é€šç”¨æ— éšœç¢é—®é¢˜åŸºå‡†ï¼Œæ—¨åœ¨ç³»ç»Ÿæ€§å®¡è®¡ä¸åŒæ®‹ç–¾çš„åŒ…å®¹æ€§ã€‚è¯¥åŸºå‡†ä»é—®é¢˜çº§è¦†ç›–ã€æ®‹ç–¾çº§è¦†ç›–å’Œæ·±åº¦ä¸‰ä¸ªç»´åº¦è¯„ä¼°æ¨¡å‹ã€‚å¯¹17ä¸ªä¸“æœ‰å’Œå¼€æ”¾æƒé‡æ¨¡å‹çš„åº”ç”¨æ˜¾ç¤ºï¼Œè§†è§‰ã€å¬è§‰å’Œè¿åŠ¨æ®‹ç–¾çš„è¦†ç›–è¾ƒå¥½ï¼Œè€Œè¨€è¯­ã€é—ä¼ /å‘è‚²ã€æ„Ÿå®˜è®¤çŸ¥å’Œå¿ƒç†å¥åº·ç­‰ç±»åˆ«åˆ™æœåŠ¡ä¸è¶³ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†å½“å‰LLMæ— éšœç¢æŒ‡å¯¼ä¸­è¢«å¿½è§†çš„ç¾¤ä½“ï¼Œå¹¶å¼ºè°ƒäº†å¯æ“ä½œçš„æ”¹è¿›æªæ–½ï¼Œå¦‚åŸºäºåˆ†ç±»æ³•çš„æç¤º/è®­ç»ƒå’Œè”åˆå®¡è®¡çš„è¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ— éšœç¢æŒ‡å¯¼ä¸­å¯¹ä¸åŒæ®‹ç–¾ç¾¤ä½“çš„æœåŠ¡ä¸è¶³é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å…¨é¢è¦†ç›–æ‰€æœ‰æ®‹ç–¾ç±»å‹ï¼Œå¯¼è‡´éƒ¨åˆ†ç¾¤ä½“è¢«å¿½è§†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ä¸åˆ†ç±»æ³•å¯¹é½çš„æ— éšœç¢é—®é¢˜åŸºå‡†ï¼Œç³»ç»Ÿæ€§åœ°å®¡è®¡æ¨¡å‹åœ¨ä¸åŒæ®‹ç–¾ç±»åˆ«çš„åŒ…å®¹æ€§ï¼Œç¡®ä¿å„ç±»æ®‹ç–¾ç¾¤ä½“éƒ½èƒ½å¾—åˆ°æœ‰æ•ˆæ”¯æŒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé—®é¢˜çº§è¦†ç›–è¯„ä¼°ã€æ®‹ç–¾çº§è¦†ç›–è¯„ä¼°å’Œæ·±åº¦è¯„ä¼°ã€‚æ¯ä¸ªæ¨¡å—é’ˆå¯¹ä¸åŒç»´åº¦è¿›è¡Œåˆ†æï¼Œç¡®ä¿å…¨é¢å®¡è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç³»ç»ŸåŒ–çš„å®¡è®¡æ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶è¯„ä¼°æ¨¡å‹çš„å¹¿åº¦ã€å¹³è¡¡æ€§å’Œæ·±åº¦ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†äººç±»éªŒè¯çš„æ— éšœç¢é—®é¢˜é›†ï¼Œç¡®ä¿é—®é¢˜çš„æœ‰æ•ˆæ€§å’Œç›¸å…³æ€§ï¼ŒåŒæ—¶åœ¨è¯„ä¼°ä¸­å¼•å…¥äº†å¤šç»´åº¦çš„è¦†ç›–æŒ‡æ ‡ï¼Œä»¥ä¾¿æ›´å¥½åœ°åæ˜ æ¨¡å‹çš„å®é™…è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œ17ä¸ªæ¨¡å‹åœ¨è§†è§‰ã€å¬è§‰å’Œè¿åŠ¨æ®‹ç–¾çš„æ”¯æŒä¸Šè¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨è¨€è¯­ã€é—ä¼ /å‘è‚²ã€æ„Ÿå®˜è®¤çŸ¥å’Œå¿ƒç†å¥åº·ç­‰ç±»åˆ«çš„æ”¯æŒä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†å½“å‰æ— éšœç¢æŒ‡å¯¼ä¸­çš„åŒ…å®¹æ€§ç¼ºå£ï¼Œå‘¼åå¯¹æ¨¡å‹è¿›è¡Œæ›´å…¨é¢çš„å®¡è®¡å’Œæ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ— éšœç¢æŠ€æœ¯å¼€å‘ã€æ•™è‚²å’Œå…¬å…±æœåŠ¡ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„åŒ…å®¹æ€§ï¼Œå¯ä»¥æ›´å¥½åœ°æœåŠ¡äºä¸åŒæ®‹ç–¾ç¾¤ä½“ï¼Œæ¨åŠ¨ç¤¾ä¼šçš„å…¨é¢åŒ…å®¹ä¸å…¬å¹³ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœæœ‰æœ›å½±å“æ”¿ç­–åˆ¶å®šå’ŒæŠ€æœ¯æ ‡å‡†ï¼Œä¿ƒè¿›æ— éšœç¢è®¾è®¡çš„æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly used for accessibility guidance, yet many disability groups remain underserved by their advice. To address this gap, we present taxonomy aligned benchmark1 of human validated, general purpose accessibility questions, designed to systematically audit inclusivity across disabilities. Our benchmark evaluates models along three dimensions: Question-Level Coverage (breadth within answers), Disability-Level Coverage (balance across nine disability categories), and Depth (specificity of support). Applying this framework to 17 proprietary and open-weight models reveals persistent inclusivity gaps: Vision, Hearing, and Mobility are frequently addressed, while Speech, Genetic/Developmental, Sensory-Cognitive, and Mental Health remain under served. Depth is similarly concentrated in a few categories but sparse elsewhere. These findings reveal who gets left behind in current LLM accessibility guidance and highlight actionable levers: taxonomy-aware prompting/training and evaluations that jointly audit breadth, balance, and depth.

