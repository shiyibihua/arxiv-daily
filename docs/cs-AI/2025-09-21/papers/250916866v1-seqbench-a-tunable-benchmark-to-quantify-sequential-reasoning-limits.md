---
layout: default
title: seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs
---

# seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16866" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16866v1</a>
  <a href="https://arxiv.org/pdf/2509.16866.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16866v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16866v1', 'seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammad Ramezanali, Mo Vazifeh, Paolo Santi

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-21

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**seqBenchï¼šå¯è°ƒåŸºå‡†æµ‹è¯•ï¼Œé‡åŒ–LLMçš„åºåˆ—æ¨ç†èƒ½åŠ›æé™**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åºåˆ—æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•` `é€»è¾‘æ·±åº¦` `å›æº¯` `å™ªå£°æ¯”` `å¸¸è¯†æ¨ç†` `å‚æ•°åŒ–æ§åˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåŸºå‡†æµ‹è¯•ç¼ºä¹å¯¹åºåˆ—æ¨ç†èƒ½åŠ›æé™çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œéš¾ä»¥ç³»ç»Ÿæ€§åœ°åˆ†ææ¨ç†å¤±è´¥çš„åŸå› ã€‚
2. seqBenché€šè¿‡å‚æ•°åŒ–æ§åˆ¶é€»è¾‘æ·±åº¦ã€å›æº¯æ­¥æ•°å’Œå™ªå£°æ¯”ï¼Œå®ç°äº†å¯¹LLMåºåˆ—æ¨ç†èƒ½åŠ›çš„ç²¾ç¡®è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMåœ¨è¶…è¿‡ç‰¹å®šé€»è¾‘æ·±åº¦åå‡†ç¡®ç‡æ€¥å‰§ä¸‹é™ï¼Œå³ä½¿åœ¨ä½æœç´¢å¤æ‚åº¦ä¸‹ä¹Ÿå­˜åœ¨æ¨ç†å¤±è´¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºseqBenchï¼Œä¸€ä¸ªå‚æ•°åŒ–çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨é€šè¿‡ç²¾ç¡®çš„å¤šç»´åº¦æ§åˆ¶å…³é”®å¤æ‚æ€§ç»´åº¦ï¼Œæ¥æ¢ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åºåˆ—æ¨ç†èƒ½åŠ›æé™ã€‚seqBenchå…è®¸ç³»ç»Ÿæ€§åœ°æ”¹å˜ï¼šï¼ˆ1ï¼‰é€»è¾‘æ·±åº¦ï¼Œå®šä¹‰ä¸ºè§£å†³ä»»åŠ¡æ‰€éœ€çš„è¿ç»­åŠ¨ä½œæ•°é‡ï¼›ï¼ˆ2ï¼‰æœ€ä¼˜è·¯å¾„ä¸Šçš„å›æº¯æ­¥æ•°ï¼Œé‡åŒ–æ™ºèƒ½ä½“ä¸ºäº†æ»¡è¶³å»¶è¿Ÿçš„å…ˆå†³æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œé‡åˆ°é”ç€çš„é—¨åå–å›é’¥åŒ™ï¼‰è€Œå¿…é¡»é‡æ–°è®¿é—®å…ˆå‰çŠ¶æ€çš„é¢‘ç‡ï¼›ï¼ˆ3ï¼‰å™ªå£°æ¯”ï¼Œå®šä¹‰ä¸ºå…³äºç¯å¢ƒçš„æ”¯æŒæ€§äº‹å®å’Œå¹²æ‰°æ€§äº‹å®ä¹‹é—´çš„æ¯”ç‡ã€‚å¯¹æœ€å…ˆè¿›çš„LLMçš„è¯„ä¼°æ­ç¤ºäº†ä¸€ç§æ™®éçš„å¤±è´¥æ¨¡å¼ï¼šå‡†ç¡®ç‡åœ¨è¶…è¿‡æ¨¡å‹ç‰¹å®šçš„é€»è¾‘æ·±åº¦åå‘ˆæŒ‡æ•°çº§ä¸‹é™ã€‚ä¸ç°æœ‰åŸºå‡†æµ‹è¯•ä¸åŒï¼ŒseqBenchçš„ç»†ç²’åº¦æ§åˆ¶æœ‰åŠ©äºå¯¹è¿™äº›æ¨ç†å¤±è´¥è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„åˆ†æï¼Œé˜æ˜æ™®éçš„ç¼©æ”¾è§„å¾‹å’Œç»Ÿè®¡é™åˆ¶ã€‚ç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯æ€§èƒ½æœ€ä½³çš„æ¨¡å‹åœ¨seqBenchçš„ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ä¸Šä¹Ÿç³»ç»Ÿæ€§åœ°å¤±è´¥ï¼Œå°½ç®¡æœç´¢å¤æ‚åº¦å¾ˆå°ï¼Œè¿™çªæ˜¾äº†å®ƒä»¬å¸¸è¯†æ¨ç†èƒ½åŠ›çš„å…³é”®å±€é™æ€§ã€‚seqBenchæ•°æ®é›†å·²å…¬å¼€å‘å¸ƒï¼Œæ—¨åœ¨æ¿€å‘å¯¹LLMæ¨ç†çš„æ›´æ·±å…¥ç§‘å­¦æ¢ç©¶ï¼Œä»¥æœŸæ›´æ¸…æ¥šåœ°äº†è§£å…¶åœ¨é²æ£’çš„å®é™…åº”ç”¨ä¸­çš„çœŸæ­£æ½œåŠ›å’Œå½“å‰è¾¹ç•Œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å¸¸è¯†æ¨ç†æ–¹é¢è¡¨ç°å‡ºä¸€å®šçš„èƒ½åŠ›ï¼Œä½†å…¶åºåˆ—æ¨ç†èƒ½åŠ›ï¼Œå³å¤„ç†éœ€è¦æŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªæ­¥éª¤çš„ä»»åŠ¡çš„èƒ½åŠ›ï¼Œä»ç„¶å­˜åœ¨å±€é™æ€§ã€‚ç°æœ‰çš„åŸºå‡†æµ‹è¯•å¾€å¾€ç¼ºä¹å¯¹ä»»åŠ¡å¤æ‚åº¦çš„ç»†ç²’åº¦æ§åˆ¶ï¼Œéš¾ä»¥ç³»ç»Ÿæ€§åœ°åˆ†æLLMåœ¨åºåˆ—æ¨ç†ä¸­å¤±è´¥çš„åŸå› ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªå¯æ§çš„åŸºå‡†æµ‹è¯•æ¥é‡åŒ–LLMçš„åºåˆ—æ¨ç†èƒ½åŠ›æé™ï¼Œå¹¶æ·±å…¥äº†è§£å…¶æ¨ç†å¤±è´¥çš„æ¨¡å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šseqBenchçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å‚æ•°åŒ–æ§åˆ¶ä»»åŠ¡çš„å¤šä¸ªå…³é”®ç»´åº¦ï¼ˆé€»è¾‘æ·±åº¦ã€å›æº¯æ­¥æ•°å’Œå™ªå£°æ¯”ï¼‰ï¼Œæ¥æ„å»ºä¸€ç³»åˆ—å…·æœ‰ä¸åŒå¤æ‚åº¦çš„åºåˆ—æ¨ç†ä»»åŠ¡ã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°æ”¹å˜è¿™äº›å‚æ•°ï¼Œå¯ä»¥ç²¾ç¡®åœ°è¯„ä¼°LLMåœ¨ä¸åŒæ¡ä»¶ä¸‹çš„æ¨ç†æ€§èƒ½ï¼Œå¹¶è¯†åˆ«å¯¼è‡´æ¨ç†å¤±è´¥çš„å…³é”®å› ç´ ã€‚è¿™ç§æ–¹æ³•å…è®¸ç ”ç©¶äººå‘˜æ·±å…¥äº†è§£LLMçš„åºåˆ—æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸ºæ”¹è¿›LLMçš„æ¨ç†èƒ½åŠ›æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šseqBenchçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä»»åŠ¡ç”Ÿæˆå™¨ï¼šæ ¹æ®è®¾å®šçš„å‚æ•°ï¼ˆé€»è¾‘æ·±åº¦ã€å›æº¯æ­¥æ•°ã€å™ªå£°æ¯”ï¼‰è‡ªåŠ¨ç”Ÿæˆåºåˆ—æ¨ç†ä»»åŠ¡ã€‚2) LLMæ¥å£ï¼šå°†ç”Ÿæˆçš„ä»»åŠ¡è¾“å…¥åˆ°å¾…è¯„ä¼°çš„LLMä¸­ï¼Œå¹¶è·å–LLMçš„è¾“å‡ºç»“æœã€‚3) è¯„ä¼°æŒ‡æ ‡ï¼šè®¾è®¡äº†ä¸€ç³»åˆ—è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¡¡é‡LLMåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ¨ç†æ€§èƒ½ï¼Œä¾‹å¦‚å‡†ç¡®ç‡ã€æˆåŠŸç‡ç­‰ã€‚4) åˆ†æå·¥å…·ï¼šæä¾›äº†ä¸€ç³»åˆ—åˆ†æå·¥å…·ï¼Œç”¨äºåˆ†æLLMçš„æ¨ç†å¤±è´¥æ¨¡å¼ï¼Œä¾‹å¦‚é”™è¯¯ç±»å‹åˆ†æã€é”™è¯¯åŸå› åˆ†æç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šseqBenchçš„æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå…¶å‚æ•°åŒ–çš„ä»»åŠ¡ç”Ÿæˆæ–¹æ³•ï¼Œå®ƒå…è®¸ç ”ç©¶äººå‘˜å¯¹ä»»åŠ¡çš„å¤æ‚åº¦è¿›è¡Œç²¾ç¡®æ§åˆ¶ã€‚ä¸ç°æœ‰çš„åŸºå‡†æµ‹è¯•ç›¸æ¯”ï¼ŒseqBenchå¯ä»¥æ›´å…¨é¢ã€æ›´æ·±å…¥åœ°è¯„ä¼°LLMçš„åºåˆ—æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒseqBenchè¿˜æä¾›äº†ä¸€ç³»åˆ—åˆ†æå·¥å…·ï¼Œå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜æ·±å…¥äº†è§£LLMçš„æ¨ç†å¤±è´¥æ¨¡å¼ï¼Œå¹¶ä¸ºæ”¹è¿›LLMçš„æ¨ç†èƒ½åŠ›æä¾›æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šseqBenchçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€»è¾‘æ·±åº¦çš„å®šä¹‰ï¼šé€»è¾‘æ·±åº¦æ˜¯æŒ‡è§£å†³ä»»åŠ¡æ‰€éœ€çš„è¿ç»­åŠ¨ä½œæ•°é‡ï¼Œå®ƒåæ˜ äº†ä»»åŠ¡çš„å¤æ‚ç¨‹åº¦ã€‚2) å›æº¯æ­¥æ•°çš„å®šä¹‰ï¼šå›æº¯æ­¥æ•°æ˜¯æŒ‡æ™ºèƒ½ä½“ä¸ºäº†æ»¡è¶³å»¶è¿Ÿçš„å…ˆå†³æ¡ä»¶è€Œå¿…é¡»é‡æ–°è®¿é—®å…ˆå‰çŠ¶æ€çš„é¢‘ç‡ï¼Œå®ƒåæ˜ äº†ä»»åŠ¡çš„è§„åˆ’éš¾åº¦ã€‚3) å™ªå£°æ¯”çš„å®šä¹‰ï¼šå™ªå£°æ¯”æ˜¯æŒ‡å…³äºç¯å¢ƒçš„æ”¯æŒæ€§äº‹å®å’Œå¹²æ‰°æ€§äº‹å®ä¹‹é—´çš„æ¯”ç‡ï¼Œå®ƒåæ˜ äº†ä»»åŠ¡çš„ä¿¡æ¯å¹²æ‰°ç¨‹åº¦ã€‚4) è¯„ä¼°æŒ‡æ ‡çš„è®¾è®¡ï¼šè¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®ç‡ã€æˆåŠŸç‡ç­‰ï¼Œç”¨äºè¡¡é‡LLMåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ¨ç†æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯æ€§èƒ½æœ€ä½³çš„LLMåœ¨seqBenchçš„ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ä¸Šä¹Ÿç³»ç»Ÿæ€§åœ°å¤±è´¥ï¼Œå°¤å…¶æ˜¯åœ¨é€»è¾‘æ·±åº¦å¢åŠ æ—¶ï¼Œå‡†ç¡®ç‡å‘ˆæŒ‡æ•°çº§ä¸‹é™ã€‚è¿™è¡¨æ˜LLMåœ¨å¸¸è¯†æ¨ç†æ–¹é¢ä»ç„¶å­˜åœ¨å±€é™æ€§ï¼Œéœ€è¦è¿›ä¸€æ­¥çš„ç ”ç©¶å’Œæ”¹è¿›ã€‚seqBenchæä¾›äº†ä¸€ä¸ªæœ‰ä»·å€¼çš„å¹³å°ï¼Œç”¨äºæ·±å…¥ç ”ç©¶LLMçš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

seqBenchå¯ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMçš„åºåˆ—æ¨ç†èƒ½åŠ›ï¼ŒæŒ‡å¯¼LLMçš„æ”¹è¿›å’Œä¼˜åŒ–ã€‚å®ƒè¿˜å¯ç”¨äºç ”ç©¶LLMçš„æ¨ç†å¤±è´¥æ¨¡å¼ï¼Œå¹¶ä¸ºå¼€å‘æ›´é²æ£’çš„LLMæä¾›ç†è®ºåŸºç¡€ã€‚æ­¤å¤–ï¼ŒseqBenchå¯ä»¥åº”ç”¨äºéœ€è¦å¤æ‚æ¨ç†èƒ½åŠ›çš„å®é™…åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½åŠ©æ‰‹ã€æœºå™¨äººå¯¼èˆªå’Œæ¸¸æˆAIç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce seqBench, a parametrized benchmark for probing sequential reasoning limits in Large Language Models (LLMs) through precise, multi-dimensional control over several key complexity dimensions. seqBench allows systematic variation of (1) the logical depth, defined as the number of sequential actions required to solve the task; (2) the number of backtracking steps along the optimal path, quantifying how often the agent must revisit prior states to satisfy deferred preconditions (e.g., retrieving a key after encountering a locked door); and (3) the noise ratio, defined as the ratio between supporting and distracting facts about the environment. Our evaluations on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses exponentially beyond a model-specific logical depth. Unlike existing benchmarks, seqBench's fine-grained control facilitates targeted analyses of these reasoning failures, illuminating universal scaling laws and statistical limits, as detailed in this paper alongside its generation methodology and evaluation metrics. We find that even top-performing models systematically fail on seqBench's structured reasoning tasks despite minimal search complexity, underscoring key limitations in their commonsense reasoning capabilities. Designed for future evolution to keep pace with advancing models, the seqBench datasets are publicly released to spur deeper scientific inquiry into LLM reasoning, aiming to establish a clearer understanding of their true potential and current boundaries for robust real-world application.

