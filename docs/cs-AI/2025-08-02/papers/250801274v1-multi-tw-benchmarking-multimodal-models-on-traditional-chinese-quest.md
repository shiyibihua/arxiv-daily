---
layout: default
title: Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan
---

# Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01274" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01274v1</a>
  <a href="https://arxiv.org/pdf/2508.01274.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01274v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01274v1', 'Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jui-Ming Yao, Bing-Cheng Xie, Sheng-Wei Peng, Hao-Yuan Chen, He-Rong Zheng, Bing-Jia Tan, Peter Shaojui Wang, Shun-Feng Su

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMulti-TWåŸºå‡†ä»¥è§£å†³å°æ¹¾ä¼ ç»Ÿä¸­æ–‡å¤šæ¨¡æ€é—®ç­”è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨¡å‹` `ä¼ ç»Ÿä¸­æ–‡` `é—®ç­”ç³»ç»Ÿ` `æ€§èƒ½è¯„ä¼°` `æ¨ç†å»¶è¿Ÿ` `éŸ³é¢‘è½¬å½•` `è§†è§‰è¯­è¨€æ¨¡å‹` `åŸºå‡†æµ‹è¯•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°åŸºå‡†æœªèƒ½è¦†ç›–ä¼ ç»Ÿä¸­æ–‡çš„ä¸‰æ¨¡æ€è¯„ä¼°ï¼Œä¸”ç¼ºä¹å¯¹æ¨ç†å»¶è¿Ÿçš„è€ƒè™‘ã€‚
2. è®ºæ–‡æå‡ºMulti-TWåŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°ä»»ä½•å¯¹ä»»ä½•å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¼ ç»Ÿä¸­æ–‡é—®ç­”ä¸­çš„æ€§èƒ½ä¸å»¶è¿Ÿã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé—­æºæ¨¡å‹åœ¨å„æ¨¡æ€ä¸Šæ™®éä¼˜äºå¼€æºæ¨¡å‹ï¼Œè€Œç«¯åˆ°ç«¯ç®¡é“åœ¨å»¶è¿Ÿä¸Šå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰èƒ½å¤Ÿå¤„ç†è§†è§‰ã€éŸ³é¢‘å’Œæ–‡æœ¬è¾“å…¥ï¼Œå…‹æœäº†å•ä¸€æ¨¡æ€æ¨¡å‹çš„å±€é™æ€§ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºå‡†å¾€å¾€å¿½è§†äº†ä¼ ç»Ÿä¸­æ–‡çš„ä¸‰æ¨¡æ€è¯„ä¼°ï¼Œå¹¶æœªè€ƒè™‘æ¨ç†å»¶è¿Ÿã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Multi-TWï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºè¯„ä¼°ä»»ä½•å¯¹ä»»ä½•å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¼ ç»Ÿä¸­æ–‡é—®ç­”ä¸­çš„æ€§èƒ½å’Œå»¶è¿Ÿçš„åŸºå‡†ã€‚Multi-TWåŒ…å«900ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼ˆå›¾åƒä¸æ–‡æœ¬ã€éŸ³é¢‘ä¸æ–‡æœ¬å¯¹ï¼‰ï¼Œæ•°æ®æ¥æºäºä¸åè¯­èƒ½åŠ›æµ‹éªŒæŒ‡å¯¼å§”å‘˜ä¼šï¼ˆSC-TOPï¼‰åˆä½œå¼€å‘çš„å®˜æ–¹èƒ½åŠ›æµ‹è¯•ã€‚æˆ‘ä»¬è¯„ä¼°äº†å¤šç§ä»»ä½•å¯¹ä»»ä½•æ¨¡å‹å’Œå¸¦éŸ³é¢‘è½¬å½•çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œç»“æœæ˜¾ç¤ºé—­æºæ¨¡å‹åœ¨å„æ¨¡æ€ä¸Šé€šå¸¸ä¼˜äºå¼€æºæ¨¡å‹ï¼Œå°½ç®¡å¼€æºæ¨¡å‹åœ¨éŸ³é¢‘ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ã€‚ç«¯åˆ°ç«¯çš„ä»»ä½•å¯¹ä»»ä½•ç®¡é“åœ¨å»¶è¿Ÿä¸Šæ˜æ˜¾ä¼˜äºä½¿ç”¨å•ç‹¬éŸ³é¢‘è½¬å½•çš„VLMsã€‚Multi-TWå…¨é¢å±•ç¤ºäº†æ¨¡å‹èƒ½åŠ›ï¼Œå¹¶å¼ºè°ƒäº†ä¼ ç»Ÿä¸­æ–‡å¾®è°ƒå’Œé«˜æ•ˆå¤šæ¨¡æ€æ¶æ„çš„å¿…è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€æ¨¡å‹è¯„ä¼°åŸºå‡†åœ¨ä¼ ç»Ÿä¸­æ–‡é—®ç­”ä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯ç¼ºä¹å¯¹ä¸‰æ¨¡æ€è¯„ä¼°å’Œæ¨ç†å»¶è¿Ÿçš„å…³æ³¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMulti-TWåŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹åœ¨ä¼ ç»Ÿä¸­æ–‡ç¯å¢ƒä¸‹çš„æ€§èƒ½ï¼Œæ¶µç›–å›¾åƒã€éŸ³é¢‘å’Œæ–‡æœ¬çš„ç»„åˆè¾“å…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMulti-TWåŸºå‡†åŒ…å«900ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ•°æ®æ¥æºäºå®˜æ–¹èƒ½åŠ›æµ‹è¯•ï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€ä¸‹çš„è¡¨ç°å’Œæ¨ç†å»¶è¿Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šMulti-TWæ˜¯é¦–ä¸ªé’ˆå¯¹ä¼ ç»Ÿä¸­æ–‡çš„å¤šæ¨¡æ€è¯„ä¼°åŸºå‡†ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ï¼Œå¼ºè°ƒäº†å¤šæ¨¡æ€æ¨¡å‹åœ¨ç‰¹å®šè¯­è¨€ç¯å¢ƒä¸‹çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ä»»ä½•å¯¹ä»»ä½•æ¨¡å‹å’Œè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼Œå¹¶å¯¹éŸ³é¢‘è½¬å½•è¿›è¡Œäº†æ•´åˆï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé—­æºæ¨¡å‹åœ¨å›¾åƒå’Œæ–‡æœ¬ã€éŸ³é¢‘å’Œæ–‡æœ¬ä»»åŠ¡ä¸­æ™®éä¼˜äºå¼€æºæ¨¡å‹ï¼Œå°¤å…¶åœ¨éŸ³é¢‘ä»»åŠ¡ä¸­å¼€æºæ¨¡å‹è¡¨ç°è‰¯å¥½ã€‚ç«¯åˆ°ç«¯çš„ä»»ä½•å¯¹ä»»ä½•ç®¡é“åœ¨æ¨ç†å»¶è¿Ÿä¸Šå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€æ™ºèƒ½å®¢æœå’Œä¿¡æ¯æ£€ç´¢ç­‰ï¼Œèƒ½å¤Ÿä¸ºä¼ ç»Ÿä¸­æ–‡ç¯å¢ƒä¸‹çš„å¤šæ¨¡æ€äº¤äº’æä¾›æœ‰æ•ˆæ”¯æŒã€‚æœªæ¥ï¼ŒMulti-TWåŸºå‡†å¯èƒ½æ¨åŠ¨å¤šæ¨¡æ€æ¨¡å‹åœ¨å…¶ä»–è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹çš„åº”ç”¨ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) process visual, acoustic, and textual inputs, addressing the limitations of single-modality LLMs. However, existing benchmarks often overlook tri-modal evaluation in Traditional Chinese and do not consider inference latency. To address this, we introduce Multi-TW, the first Traditional Chinese benchmark for evaluating the performance and latency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice questions (image and text, audio and text pairs) sourced from official proficiency tests developed with the Steering Committee for the Test of Proficiency-Huayu (SC-TOP). We evaluated various any-to-any models and vision-language models (VLMs) with audio transcription. Our results show that closed-source models generally outperform open-source ones across modalities, although open-source models can perform well in audio tasks. End-to-end any-to-any pipelines offer clear latency advantages compared to VLMs using separate audio transcription. Multi-TW presents a comprehensive view of model capabilities and highlights the need for Traditional Chinese fine-tuning and efficient multimodal architectures.

