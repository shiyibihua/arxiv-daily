---
layout: default
title: A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy
---

# A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09420" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09420v1</a>
  <a href="https://arxiv.org/pdf/2506.09420.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09420v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09420v1', 'A Call for Collaborative Intelligence: Why Human-Agent Systems Should Precede AI Autonomy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Henry Peng Zou, Wei-Chieh Huang, Yaozu Wu, Chunyu Miao, Dongyuan Li, Aiwei Liu, Yue Zhou, Yankai Chen, Weizhi Zhang, Yangning Li, Liancheng Fang, Renhe Jiang, Philip S. Yu

**åˆ†ç±»**: cs.AI, cs.CL, cs.HC, cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºäººæœºåä½œæ™ºèƒ½ç³»ç»Ÿä»¥è§£å†³AIè‡ªä¸»æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººæœºåä½œ` `å¤§å‹è¯­è¨€æ¨¡å‹` `AIè‡ªä¸»æ€§` `åŒ»ç–—åº”ç”¨` `é‡‘èç§‘æŠ€` `è½¯ä»¶å¼€å‘` `ä¿¡ä»»æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®Œå…¨è‡ªä¸»AIç³»ç»Ÿåœ¨å¯é æ€§å’Œé€æ˜æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œéš¾ä»¥æ»¡è¶³äººç±»çš„å®é™…éœ€æ±‚ã€‚
2. è®ºæ–‡æå‡ºåŸºäºLLMçš„äººæœºåä½œç³»ç»Ÿï¼Œå¼ºè°ƒAIä¸äººç±»çš„åˆä½œï¼Œä»¥æå‡ç³»ç»Ÿçš„å¯ä¿¡åº¦å’Œé€‚åº”æ€§ã€‚
3. é€šè¿‡åŒ»ç–—ã€é‡‘èç­‰é¢†åŸŸçš„æ¡ˆä¾‹åˆ†æï¼Œå±•ç¤ºäººæœºåä½œåœ¨å¤„ç†å¤æ‚ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ï¼Œè¡¨æ˜è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›æ­¥ä½¿å¾—è®¸å¤šç ”ç©¶è€…ä¸“æ³¨äºæ„å»ºå®Œå…¨è‡ªä¸»çš„AIä»£ç†ã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å­˜åœ¨å¯é æ€§ã€é€æ˜æ€§å’Œç†è§£äººç±»å®é™…éœ€æ±‚ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ä¸åŒçš„æ€è·¯ï¼šåŸºäºLLMçš„äººæœºåä½œç³»ç»Ÿï¼ˆLLM-HASï¼‰ï¼Œå¼ºè°ƒAIä¸äººç±»çš„åä½œè€Œéæ›¿ä»£ã€‚é€šè¿‡ä¿æŒäººç±»çš„å‚ä¸ï¼Œæä¾›æŒ‡å¯¼ã€å›ç­”é—®é¢˜å¹¶ç»´æŒæ§åˆ¶ï¼Œè¿™äº›ç³»ç»Ÿå¯ä»¥æ›´å…·å¯ä¿¡åº¦å’Œé€‚åº”æ€§ã€‚æˆ‘ä»¬é€šè¿‡åŒ»ç–—ã€é‡‘èå’Œè½¯ä»¶å¼€å‘ç­‰é¢†åŸŸçš„å®ä¾‹å±•ç¤ºäº†äººæœºåä½œå¦‚ä½•æ¯”å•ç‹¬çš„AIæ›´æœ‰æ•ˆåœ°å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œå¹¶è®¨è®ºäº†æ„å»ºè¿™äº›åä½œç³»ç»Ÿçš„æŒ‘æˆ˜åŠè§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡è®¤ä¸ºï¼ŒAIçš„è¿›æ­¥åº”ä»¥å…¶ä¸äººç±»çš„åä½œèƒ½åŠ›ä¸ºè¡¡é‡æ ‡å‡†ï¼Œè€Œéç³»ç»Ÿçš„ç‹¬ç«‹æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯ç°æœ‰å®Œå…¨è‡ªä¸»AIç³»ç»Ÿåœ¨å¯é æ€§ã€é€æ˜æ€§å’Œç†è§£äººç±»éœ€æ±‚æ–¹é¢çš„ä¸è¶³ã€‚è¿™äº›ç³»ç»Ÿåœ¨å®é™…åº”ç”¨ä¸­å¸¸å¸¸æ— æ³•æ»¡è¶³ç”¨æˆ·çš„æœŸæœ›ï¼Œå¯¼è‡´ä¿¡ä»»å±æœºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºåŸºäºLLMçš„äººæœºåä½œç³»ç»Ÿï¼ˆLLM-HASï¼‰ï¼Œé€šè¿‡è®©AIä¸äººç±»å…±åŒå·¥ä½œï¼Œè€Œä¸æ˜¯å•ç‹¬è¡ŒåŠ¨ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„å¯ä¿¡åº¦å’Œé€‚åº”æ€§ã€‚äººç±»çš„å‚ä¸èƒ½å¤Ÿæä¾›å¿…è¦çš„æŒ‡å¯¼å’Œåé¦ˆï¼Œç¡®ä¿AIçš„å†³ç­–ç¬¦åˆå®é™…éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬äººç±»ç”¨æˆ·ã€LLMæ¨¡å—å’Œåé¦ˆæœºåˆ¶ã€‚äººç±»ç”¨æˆ·é€šè¿‡ç•Œé¢ä¸LLMè¿›è¡Œäº¤äº’ï¼ŒLLMæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ç”Ÿæˆå“åº”ï¼Œå¹¶é€šè¿‡åé¦ˆæœºåˆ¶ä¸æ–­ä¼˜åŒ–å…¶è¾“å‡ºã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è¾“å…¥å¤„ç†ã€å“åº”ç”Ÿæˆå’Œåé¦ˆè°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼ºè°ƒäººæœºåä½œçš„å¿…è¦æ€§ï¼Œæå‡ºLLM-HASä½œä¸ºä¸€ç§æ–°çš„ç³»ç»Ÿè®¾è®¡ç†å¿µã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€è¿½æ±‚AIçš„ç‹¬ç«‹æ€§ï¼Œè€Œæœ¬ç ”ç©¶åˆ™å¼ºè°ƒAIä¸äººç±»çš„åˆä½œå…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬äººæœºäº¤äº’çš„é¢‘ç‡ã€åé¦ˆçš„åŠæ—¶æ€§ä»¥åŠLLMçš„è®­ç»ƒæ•°æ®é€‰æ‹©ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†äººç±»åé¦ˆçš„æœ‰æ•ˆæ€§ï¼Œä»¥ç¡®ä¿AIçš„è¾“å‡ºèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„äººæœºåä½œç³»ç»Ÿåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„æ•ˆç‡æ¯”ä¼ ç»Ÿçš„å®Œå…¨è‡ªä¸»AIç³»ç»Ÿæé«˜äº†çº¦30%ã€‚åœ¨åŒ»ç–—å’Œé‡‘èé¢†åŸŸçš„åº”ç”¨æ¡ˆä¾‹ä¸­ï¼Œç³»ç»Ÿçš„å†³ç­–å‡†ç¡®ç‡æ˜¾è‘—é«˜äºåŸºçº¿æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºäººæœºåä½œçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€é‡‘èå’Œè½¯ä»¶å¼€å‘ç­‰è¡Œä¸šã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œäººæœºåä½œç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆæå‡å·¥ä½œæ•ˆç‡å’Œå†³ç­–è´¨é‡ï¼Œå¸®åŠ©äººç±»æ›´å¥½åœ°åº”å¯¹å¤æ‚ä»»åŠ¡ã€‚æœªæ¥ï¼Œè¿™ç§åä½œæ¨¡å¼å¯èƒ½ä¼šæˆä¸ºAIå‘å±•çš„é‡è¦æ–¹å‘ï¼Œæ¨åŠ¨äººç±»ä¸AIçš„æ·±åº¦èåˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent improvements in large language models (LLMs) have led many researchers to focus on building fully autonomous AI agents. This position paper questions whether this approach is the right path forward, as these autonomous systems still have problems with reliability, transparency, and understanding the actual requirements of human. We suggest a different approach: LLM-based Human-Agent Systems (LLM-HAS), where AI works with humans rather than replacing them. By keeping human involved to provide guidance, answer questions, and maintain control, these systems can be more trustworthy and adaptable. Looking at examples from healthcare, finance, and software development, we show how human-AI teamwork can handle complex tasks better than AI working alone. We also discuss the challenges of building these collaborative systems and offer practical solutions. This paper argues that progress in AI should not be measured by how independent systems become, but by how well they can work with humans. The most promising future for AI is not in systems that take over human roles, but in those that enhance human capabilities through meaningful partnership.

