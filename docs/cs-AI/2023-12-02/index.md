---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2023-12-02
---

# cs.AIï¼ˆ2023-12-02ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/231201090v2-self-generated-wargame-ai-double-layer-agent-task-planning-based-on-.html">Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model</a></td>
  <td>æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŒå±‚Agentä»»åŠ¡è§„åˆ’ï¼Œç”¨äºæ™ºèƒ½å†³ç­–</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01090v2" data-paper-url="./papers/231201090v2-self-generated-wargame-ai-double-layer-agent-task-planning-based-on-.html" onclick="toggleFavorite(this, '2312.01090v2', 'Self Generated Wargame AI: Double Layer Agent Task Planning Based on Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/231202206v1-axiomatic-preference-modeling-for-longform-question-answering.html">Axiomatic Preference Modeling for Longform Question Answering</a></td>
  <td>æå‡ºåŸºäºå…¬ç†åŒ–åå¥½å»ºæ¨¡çš„é•¿æ–‡æœ¬é—®ç­”æ–¹æ³•ï¼Œå°æ¨¡å‹æ€§èƒ½è¶…è¶ŠGPT-4ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2312.02206v1" data-paper-url="./papers/231202206v1-axiomatic-preference-modeling-for-longform-question-answering.html" onclick="toggleFavorite(this, '2312.02206v1', 'Axiomatic Preference Modeling for Longform Question Answering')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/231201241v3-just-in-time-detection-of-silent-security-patches.html">Just-in-Time Detection of Silent Security Patches</a></td>
  <td>LLMDAï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹åŠæ—¶æ£€æµ‹é™é»˜å®‰å…¨è¡¥ä¸ï¼Œé˜²èŒƒN-dayæ”»å‡»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">contrastive learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01241v3" data-paper-url="./papers/231201241v3-just-in-time-detection-of-silent-security-patches.html" onclick="toggleFavorite(this, '2312.01241v3', 'Just-in-Time Detection of Silent Security Patches')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/231201081v1-adaptive-resource-allocation-for-semantic-communication-networks.html">Adaptive Resource Allocation for Semantic Communication Networks</a></td>
  <td>æå‡ºè‡ªé€‚åº”è¯­ä¹‰èµ„æºåˆ†é…æ–¹æ¡ˆï¼Œå…¼å®¹ä¼ ç»Ÿæ— çº¿é€šä¿¡å¹¶æå‡è¯­ä¹‰é€šä¿¡æœåŠ¡è´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01081v1" data-paper-url="./papers/231201081v1-adaptive-resource-allocation-for-semantic-communication-networks.html" onclick="toggleFavorite(this, '2312.01081v1', 'Adaptive Resource Allocation for Semantic Communication Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/231201202v1-from-voices-to-validity-leveraging-large-language-models-llms-for-te.html">From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews</a></td>
  <td>åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ”¿ç­–åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬åˆ†æï¼Œæå‡æ•ˆç‡ä¸ä¿¡åº¦</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01202v1" data-paper-url="./papers/231201202v1-from-voices-to-validity-leveraging-large-language-models-llms-for-te.html" onclick="toggleFavorite(this, '2312.01202v1', 'From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/231201109v1-kattis-vs-chatgpt-assessment-and-evaluation-of-programming-tasks-in-.html">Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence</a></td>
  <td>è¯„ä¼°ChatGPTåœ¨Kattisç¼–ç¨‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶åœ¨ä¸åŒéš¾åº¦ç¼–ç¨‹é—®é¢˜ä¸Šçš„èƒ½åŠ›å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01109v1" data-paper-url="./papers/231201109v1-kattis-vs-chatgpt-assessment-and-evaluation-of-programming-tasks-in-.html" onclick="toggleFavorite(this, '2312.01109v1', 'Kattis vs. ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/231201045v1-profl-a-privacy-preserving-federated-learning-method-with-stringent-.html">PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks</a></td>
  <td>PROFLï¼šä¸€ç§å…·æœ‰ä¸¥æ ¼é˜²å¾¡æŠ•æ¯’æ”»å‡»çš„éšç§ä¿æŠ¤è”é‚¦å­¦ä¹ æ–¹æ³•</td>
  <td class="tags-cell"><span class="paper-tag">OMOMO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2312.01045v1" data-paper-url="./papers/231201045v1-profl-a-privacy-preserving-federated-learning-method-with-stringent-.html" onclick="toggleFavorite(this, '2312.01045v1', 'PROFL: A Privacy-Preserving Federated Learning Method with Stringent Defense Against Poisoning Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)