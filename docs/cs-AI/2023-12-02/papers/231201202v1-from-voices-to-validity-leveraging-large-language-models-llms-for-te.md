---
layout: default
title: From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews
---

# From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.01202" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.01202v1</a>
  <a href="https://arxiv.org/pdf/2312.01202.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.01202v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.01202v1', 'From Voices to Validity: Leveraging Large Language Models (LLMs) for Textual Analysis of Policy Stakeholder Interviews')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alex Liu, Min Sun

**åˆ†ç±»**: cs.HC, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2023-12-02

**æœŸåˆŠ**: AERA OPEN Volume 11, January-December 2025

**DOI**: [10.1177/23328584251374595](https://doi.org/10.1177/23328584251374595)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œæ”¿ç­–åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬åˆ†æï¼Œæå‡æ•ˆç‡ä¸ä¿¡åº¦**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ–‡æœ¬åˆ†æ` `æ”¿ç­–åˆ†æ` `åˆ©ç›Šç›¸å…³è€…è®¿è°ˆ` `äººæœºååŒ` `ä¸»é¢˜å»ºæ¨¡` `æƒ…æ„Ÿåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. äººå·¥ç¼–ç åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬è€—æ—¶è´¹åŠ›ï¼Œéš¾ä»¥å¿«é€Ÿè·å–æ”¿ç­–åé¦ˆï¼Œé˜»ç¢äº†åŠæ—¶æœ‰æ•ˆçš„æ”¿ç­–åˆ¶å®šã€‚
2. ç»“åˆäººç±»ä¸“å®¶çŸ¥è¯†ä¸GPT-4ç­‰LLMï¼Œè®¾è®¡æç¤ºå·¥ç¨‹ï¼Œè¿­ä»£ä¼˜åŒ–LLMåœ¨ä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æä¸­çš„è¡¨ç°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGPT-4åœ¨ä¸»é¢˜ç¼–ç ä¸Šè¶…è¶Šä¼ ç»ŸNLPæ–¹æ³•25%ä»¥ä¸Šï¼Œæƒ…æ„Ÿåˆ†ææ›´æ¥è¿‘ä¸“å®¶æ°´å¹³ï¼Œæå‡äº†åˆ†ææ•ˆç‡å’Œä¿¡åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢ç´¢äº†å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå¦‚GPT-4ï¼Œä¸äººç±»ä¸“ä¸šçŸ¥è¯†ç›¸ç»“åˆï¼Œä»¥å¢å¼ºå¯¹ç¾å›½æŸå·K-12æ•™è‚²æ”¿ç­–åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬çš„åˆ†æã€‚é€šè¿‡æ··åˆæ–¹æ³•ï¼Œäººç±»ä¸“å®¶åŸºäºé¢†åŸŸçŸ¥è¯†å’Œæ— ç›‘ç£ä¸»é¢˜å»ºæ¨¡ç»“æœï¼Œå¼€å‘äº†ç¼–ç æ‰‹å†Œå’Œç¼–ç æµç¨‹ã€‚ä»–ä»¬è®¾è®¡äº†æç¤ºæ¥æŒ‡å¯¼GPT-4åˆ†æï¼Œå¹¶è¿­ä»£è¯„ä¼°ä¸åŒæç¤ºçš„æ€§èƒ½ã€‚è¿™ç§äººæœºç»“åˆçš„æ–¹æ³•å®ç°äº†ç»†è‡´çš„ä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æã€‚ç»“æœè¡¨æ˜ï¼ŒGPT-4çš„ä¸»é¢˜ç¼–ç åœ¨ç‰¹å®šä¸»é¢˜ä¸Šä¸äººç±»ç¼–ç çš„å¯¹é½åº¦ä¸º77.89%ï¼Œæ‰©å±•åˆ°æ›´å¹¿æ³›çš„ä¸»é¢˜æ—¶ï¼Œä¸€è‡´æ€§æé«˜åˆ°96.02%ï¼Œè¶…è¿‡äº†ä¼ ç»Ÿè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰æ–¹æ³•25%ä»¥ä¸Šã€‚æ­¤å¤–ï¼ŒGPT-4çš„æƒ…æ„Ÿåˆ†æä¸ä¸“å®¶æƒ…æ„Ÿåˆ†æçš„åŒ¹é…åº¦é«˜äºåŸºäºè¯å…¸çš„æ–¹æ³•ã€‚å®šé‡æµ‹é‡å’Œå®šæ€§è¯„ä¼°çš„ç»“æœå¼ºè°ƒäº†äººç±»é¢†åŸŸä¸“ä¸šçŸ¥è¯†å’Œè‡ªåŠ¨åŒ–åˆ†æçš„äº’è¡¥ä½œç”¨ï¼ŒLLMæä¾›äº†æ–°çš„è§†è§’å’Œç¼–ç ä¸€è‡´æ€§ã€‚äººæœºäº¤äº’æ–¹æ³•æé«˜äº†æ•™è‚²æ”¿ç­–ç ”ç©¶çš„æ•ˆç‡ã€æœ‰æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ”¿ç­–åˆ¶å®šè€…éš¾ä»¥é«˜æ•ˆåˆ†æå¤§é‡åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬çš„é—®é¢˜ã€‚ç°æœ‰çš„äººå·¥ç¼–ç æ–¹æ³•è€—æ—¶è´¹åŠ›ï¼Œä¸”å®¹æ˜“å—åˆ°ä¸»è§‚åå·®çš„å½±å“ã€‚ä¼ ç»Ÿçš„è‡ªç„¶è¯­è¨€å¤„ç†æ–¹æ³•åœ¨ç†è§£ç»†å¾®è¯­ä¹‰å’Œé¢†åŸŸçŸ¥è¯†æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å‡†ç¡®æ•æ‰åˆ©ç›Šç›¸å…³è€…çš„è§‚ç‚¹å’Œæƒ…æ„Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†äººç±»ä¸“å®¶çš„é¢†åŸŸçŸ¥è¯†ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼ºå¤§æ–‡æœ¬å¤„ç†èƒ½åŠ›ç›¸ç»“åˆï¼Œæ„å»ºä¸€ä¸ªäººæœºååŒçš„åˆ†ææ¡†æ¶ã€‚é€šè¿‡äººç±»ä¸“å®¶è®¾è®¡æç¤ºï¼ˆpromptsï¼‰æ¥å¼•å¯¼LLMè¿›è¡Œä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æï¼Œå¹¶è¿­ä»£è¯„ä¼°å’Œä¼˜åŒ–æç¤ºçš„æ€§èƒ½ï¼Œä»è€Œæé«˜åˆ†æçš„å‡†ç¡®æ€§ã€æ•ˆç‡å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶é‡‡ç”¨æ··åˆæ–¹æ³•ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) äººç±»ä¸“å®¶åŸºäºé¢†åŸŸçŸ¥è¯†å’Œæ— ç›‘ç£ä¸»é¢˜å»ºæ¨¡ç»“æœï¼Œåˆ¶å®šç¼–ç æ‰‹å†Œå’Œç¼–ç æµç¨‹ã€‚2) äººç±»ä¸“å®¶è®¾è®¡ä¸åŒçš„æç¤ºï¼Œç”¨äºæŒ‡å¯¼GPT-4è¿›è¡Œä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æã€‚3) ä½¿ç”¨è®¾è®¡çš„æç¤ºï¼Œåˆ©ç”¨GPT-4å¯¹è®¿è°ˆæ–‡æœ¬è¿›è¡Œåˆ†æã€‚4) äººç±»ä¸“å®¶è¯„ä¼°GPT-4çš„åˆ†æç»“æœï¼Œå¹¶ä¸äººå·¥ç¼–ç ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚5) åŸºäºè¯„ä¼°ç»“æœï¼Œè¿­ä»£ä¼˜åŒ–æç¤ºï¼Œæé«˜GPT-4çš„åˆ†ææ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åº”ç”¨äºæ”¿ç­–åˆ©ç›Šç›¸å…³è€…è®¿è°ˆæ–‡æœ¬çš„åˆ†æï¼Œå¹¶æ¢ç´¢äº†äººæœºååŒçš„åˆ†ææ¨¡å¼ã€‚é€šè¿‡æç¤ºå·¥ç¨‹ï¼Œå¼•å¯¼LLMè¿›è¡Œä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æï¼Œå…‹æœäº†ä¼ ç»ŸNLPæ–¹æ³•åœ¨ç†è§£ç»†å¾®è¯­ä¹‰å’Œé¢†åŸŸçŸ¥è¯†æ–¹é¢çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) æç¤ºçš„è®¾è®¡ï¼šè®¾è®¡ä¸åŒçš„æç¤ºï¼Œä»¥å¼•å¯¼GPT-4è¿›è¡Œä¸»é¢˜å’Œæƒ…æ„Ÿåˆ†æï¼Œå¹¶è¿­ä»£ä¼˜åŒ–æç¤ºçš„æ€§èƒ½ã€‚2) è¯„ä¼°æŒ‡æ ‡çš„é€‰æ‹©ï¼šé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°GPT-4çš„åˆ†æç»“æœï¼Œå¹¶ä¸äººå·¥ç¼–ç ç»“æœè¿›è¡Œæ¯”è¾ƒã€‚3) è¿­ä»£ä¼˜åŒ–ï¼šåŸºäºè¯„ä¼°ç»“æœï¼Œè¿­ä»£ä¼˜åŒ–æç¤ºï¼Œæé«˜GPT-4çš„åˆ†ææ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4åœ¨ä¸»é¢˜ç¼–ç æ–¹é¢ä¸äººç±»ç¼–ç çš„å¯¹é½åº¦æœ€é«˜å¯è¾¾96.02%ï¼Œè¶…è¿‡ä¼ ç»ŸNLPæ–¹æ³•25%ä»¥ä¸Šã€‚GPT-4çš„æƒ…æ„Ÿåˆ†æç»“æœä¸ä¸“å®¶æƒ…æ„Ÿåˆ†æçš„åŒ¹é…åº¦ä¹Ÿé«˜äºåŸºäºè¯å…¸çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMåœ¨æ”¿ç­–æ–‡æœ¬åˆ†æä¸­å…·æœ‰å·¨å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æ˜¾è‘—æé«˜åˆ†æçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ•™è‚²æ”¿ç­–ã€å…¬å…±å«ç”Ÿã€ç¤¾ä¼šç¦åˆ©ç­‰å¤šä¸ªé¢†åŸŸï¼Œå¸®åŠ©æ”¿ç­–åˆ¶å®šè€…å¿«é€Ÿã€å‡†ç¡®åœ°äº†è§£åˆ©ç›Šç›¸å…³è€…çš„è§‚ç‚¹å’Œæƒ…æ„Ÿï¼Œä»è€Œåˆ¶å®šæ›´åŠ ç§‘å­¦ã€åˆç†çš„æ”¿ç­–ã€‚è¯¥æ–¹æ³•è¿˜å¯ç”¨äºåˆ†æå¤§è§„æ¨¡çš„æ–‡æœ¬æ•°æ®ï¼Œä¾‹å¦‚ç¤¾äº¤åª’ä½“è¯„è®ºã€åœ¨çº¿è®ºå›å¸–å­ç­‰ï¼Œä¸ºèˆ†æƒ…åˆ†æã€å¸‚åœºè°ƒç ”ç­‰æä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Obtaining stakeholders' diverse experiences and opinions about current policy in a timely manner is crucial for policymakers to identify strengths and gaps in resource allocation, thereby supporting effective policy design and implementation. However, manually coding even moderately sized interview texts or open-ended survey responses from stakeholders can often be labor-intensive and time-consuming. This study explores the integration of Large Language Models (LLMs)--like GPT-4--with human expertise to enhance text analysis of stakeholder interviews regarding K-12 education policy within one U.S. state. Employing a mixed-methods approach, human experts developed a codebook and coding processes as informed by domain knowledge and unsupervised topic modeling results. They then designed prompts to guide GPT-4 analysis and iteratively evaluate different prompts' performances. This combined human-computer method enabled nuanced thematic and sentiment analysis. Results reveal that while GPT-4 thematic coding aligned with human coding by 77.89% at specific themes, expanding to broader themes increased congruence to 96.02%, surpassing traditional Natural Language Processing (NLP) methods by over 25%. Additionally, GPT-4 is more closely matched to expert sentiment analysis than lexicon-based methods. Findings from quantitative measures and qualitative reviews underscore the complementary roles of human domain expertise and automated analysis as LLMs offer new perspectives and coding consistency. The human-computer interactive approach enhances efficiency, validity, and interpretability of educational policy research.

