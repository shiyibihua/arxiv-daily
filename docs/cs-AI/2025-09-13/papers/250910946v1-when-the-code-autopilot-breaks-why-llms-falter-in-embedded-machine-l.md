---
layout: default
title: When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning
---

# When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10946" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10946v1</a>
  <a href="https://arxiv.org/pdf/2509.10946.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10946v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10946v1', 'When the Code Autopilot Breaks: Why LLMs Falter in Embedded Machine Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Roberto Morabito, Guanghan Wu

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-13

**å¤‡æ³¨**: This paper has been accepted for publication in Computer (IEEE). Upon publication, the copyright will be transferred to IEEE

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶LLMåœ¨åµŒå…¥å¼æœºå™¨å­¦ä¹ ä»£ç ç”Ÿæˆä¸­çš„å¤±æ•ˆæ¨¡å¼ä¸åŸå› **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åµŒå…¥å¼æœºå™¨å­¦ä¹ ` `ä»£ç ç”Ÿæˆ` `å¤±æ•ˆæ¨¡å¼åˆ†æ` `è‡ªåŠ¨é©¾é©¶æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æ£€æµ‹LLMåœ¨åµŒå…¥å¼MLä»£ç ç”Ÿæˆä¸­å‡ºç°çš„é™é»˜å¤±è´¥å’Œä¸å¯é¢„æµ‹è¡Œä¸ºï¼Œå¯¼è‡´ç³»ç»Ÿå¯é æ€§é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºä¸€ä¸ªè‡ªåŠ¨é©¾é©¶æ¡†æ¶ï¼Œç”¨äºç¼–æ’æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è½¬æ¢å’Œè®¾å¤‡ç«¯æ¨ç†ä»£ç ç”Ÿæˆï¼Œä»è€Œç ”ç©¶LLMçš„å¤±æ•ˆæ¨¡å¼ã€‚
3. é€šè¿‡å®éªŒåˆ†æï¼Œè®ºæ–‡æ­ç¤ºäº†æç¤ºæ ¼å¼ã€æ¨¡å‹è¡Œä¸ºå’Œç»“æ„å‡è®¾å¯¹LLMä»£ç ç”ŸæˆæˆåŠŸç‡å’Œå¤±æ•ˆç‰¹å¾çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºè‡ªåŠ¨åŒ–åµŒå…¥å¼æœºå™¨å­¦ä¹ å·¥ä½œæµç¨‹ä¸­çš„è½¯ä»¶ç”Ÿæˆï¼Œä½†å…¶è¾“å‡ºå¸¸å¸¸å‡ºç°é™é»˜å¤±è´¥æˆ–ä¸å¯é¢„æµ‹çš„è¡Œä¸ºã€‚æœ¬æ–‡åŸºäºä¸€ä¸ªè‡ªåŠ¨é©¾é©¶æ¡†æ¶ï¼Œå¯¹LLMé©±åŠ¨çš„MLç®¡é“ä¸­çš„å¤±æ•ˆæ¨¡å¼è¿›è¡Œäº†å®è¯ç ”ç©¶ï¼Œè¯¥æ¡†æ¶åè°ƒæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è½¬æ¢å’Œè®¾å¤‡ç«¯æ¨ç†ä»£ç ç”Ÿæˆã€‚ç ”ç©¶è¡¨æ˜ï¼Œæç¤ºæ ¼å¼ã€æ¨¡å‹è¡Œä¸ºå’Œç»“æ„å‡è®¾ä¼šä»¥æ ‡å‡†éªŒè¯ç®¡é“éš¾ä»¥æ£€æµ‹çš„æ–¹å¼å½±å“æˆåŠŸç‡å’Œå¤±æ•ˆç‰¹å¾ã€‚æˆ‘ä»¬çš„åˆ†ææ­ç¤ºäº†ä¸€ç³»åˆ—å®¹æ˜“å‡ºé”™çš„è¡Œä¸ºï¼ŒåŒ…æ‹¬æ ¼å¼å¼•èµ·çš„è¯¯è§£å’Œç¼–è¯‘ä½†ç ´åä¸‹æ¸¸çš„è¿è¡Œæ—¶ç ´åæ€§ä»£ç ã€‚æˆ‘ä»¬æ¨å¯¼å‡ºä¸€ä¸ªå¤±æ•ˆç±»åˆ«åˆ†ç±»æ³•ï¼Œå¹¶åˆ†æäº†å¤šä¸ªLLMä¸­çš„é”™è¯¯ï¼Œçªå‡ºäº†å¸¸è§çš„æ ¹æœ¬åŸå› å’Œç³»ç»Ÿè„†å¼±æ€§ã€‚è™½ç„¶åŸºäºç‰¹å®šè®¾å¤‡ï¼Œä½†æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†åŸºäºLLMçš„ä»£ç ç”Ÿæˆä¸­æ›´å¹¿æ³›çš„æŒ‘æˆ˜ã€‚æœ€åï¼Œæˆ‘ä»¬è®¨è®ºäº†æé«˜LLMé©±åŠ¨çš„åµŒå…¥å¼MLç³»ç»Ÿä¸­å¯é æ€§å’Œå¯è¿½æº¯æ€§çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨åµŒå…¥å¼æœºå™¨å­¦ä¹ ä»£ç ç”Ÿæˆä¸­å‡ºç°çš„å¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå³æ ‡å‡†éªŒè¯ç®¡é“ï¼Œæ— æ³•æœ‰æ•ˆæ£€æµ‹LLMç”Ÿæˆçš„ä»£ç ä¸­å­˜åœ¨çš„é™é»˜å¤±è´¥å’Œä¸å¯é¢„æµ‹è¡Œä¸ºï¼Œè¿™ç»™åµŒå…¥å¼MLç³»ç»Ÿçš„éƒ¨ç½²å¸¦æ¥äº†é£é™©ã€‚è¿™äº›é—®é¢˜æºäºLLMå¯¹ä¸Šä¸‹æ–‡çš„è¯¯è§£ã€ç”Ÿæˆçš„ä»£ç ä¸­å­˜åœ¨çš„è¿è¡Œæ—¶é”™è¯¯ä»¥åŠå¯¹åº•å±‚ç¡¬ä»¶å¹³å°çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªè‡ªåŠ¨é©¾é©¶æ¡†æ¶ï¼Œæ¨¡æ‹Ÿå®Œæ•´çš„åµŒå…¥å¼MLéƒ¨ç½²æµç¨‹ï¼Œä»è€Œç³»ç»Ÿæ€§åœ°ç ”ç©¶LLMåœ¨å„ä¸ªé˜¶æ®µçš„å¤±æ•ˆæ¨¡å¼ã€‚è¯¥æ¡†æ¶å…è®¸ç ”ç©¶äººå‘˜æ§åˆ¶è¾“å…¥ã€è§‚å¯Ÿä¸­é—´ç»“æœï¼Œå¹¶åˆ†ææœ€ç»ˆçš„è®¾å¤‡ç«¯è¡Œä¸ºï¼Œä»è€Œæ­ç¤ºLLMåœ¨åµŒå…¥å¼MLä»£ç ç”Ÿæˆä¸­çš„è„†å¼±æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥è‡ªåŠ¨é©¾é©¶æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) æ•°æ®é¢„å¤„ç†æ¨¡å—ï¼Œè´Ÿè´£å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºLLMå¯ä»¥ç†è§£çš„æ ¼å¼ï¼›2) æ¨¡å‹è½¬æ¢æ¨¡å—ï¼Œå°†è®­ç»ƒå¥½çš„MLæ¨¡å‹è½¬æ¢ä¸ºé€‚åˆåµŒå…¥å¼è®¾å¤‡éƒ¨ç½²çš„æ ¼å¼ï¼›3) ä»£ç ç”Ÿæˆæ¨¡å—ï¼Œåˆ©ç”¨LLMç”Ÿæˆè®¾å¤‡ç«¯æ¨ç†ä»£ç ï¼›4) éªŒè¯æ¨¡å—ï¼Œå¯¹ç”Ÿæˆçš„ä»£ç è¿›è¡Œæµ‹è¯•å’ŒéªŒè¯ï¼Œè¯„ä¼°å…¶æ­£ç¡®æ€§å’Œæ€§èƒ½ã€‚æ•´ä¸ªæµç¨‹æ¨¡æ‹Ÿäº†ä»æ•°æ®åˆ°éƒ¨ç½²çš„å®Œæ•´åµŒå…¥å¼MLç®¡é“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§çš„å¤±æ•ˆæ¨¡å¼åˆ†ææ–¹æ³•ã€‚é€šè¿‡æ§åˆ¶å®éªŒæ¡ä»¶ï¼Œç ”ç©¶äººå‘˜èƒ½å¤Ÿéš”ç¦»å¹¶è¯†åˆ«å¯¼è‡´LLMç”Ÿæˆé”™è¯¯ä»£ç çš„å„ç§å› ç´ ï¼Œä¾‹å¦‚æç¤ºæ ¼å¼ã€æ¨¡å‹è¡Œä¸ºå’Œç»“æ„å‡è®¾ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªå¤±æ•ˆç±»åˆ«åˆ†ç±»æ³•ï¼Œç”¨äºç»„ç»‡å’Œç†è§£LLMåœ¨åµŒå…¥å¼MLä»£ç ç”Ÿæˆä¸­å‡ºç°çš„å„ç§é”™è¯¯ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç²¾å¿ƒè®¾è®¡çš„æç¤ºå·¥ç¨‹ï¼Œç”¨äºæ¢ç´¢ä¸åŒæç¤ºæ ¼å¼å¯¹LLMä»£ç ç”Ÿæˆçš„å½±å“ï¼›2) å¤šç§LLMçš„å¯¹æ¯”å®éªŒï¼Œç”¨äºè¯„ä¼°ä¸åŒLLMåœ¨åµŒå…¥å¼MLä»»åŠ¡ä¸­çš„è¡¨ç°ï¼›3) ç»†ç²’åº¦çš„é”™è¯¯åˆ†æï¼Œç”¨äºè¯†åˆ«LLMç”Ÿæˆçš„ä»£ç ä¸­å­˜åœ¨çš„å…·ä½“é—®é¢˜ï¼Œä¾‹å¦‚æ ¼å¼é”™è¯¯ã€é€»è¾‘é”™è¯¯å’Œè¿è¡Œæ—¶é”™è¯¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨åµŒå…¥å¼MLä»£ç ç”Ÿæˆä¸­å­˜åœ¨å¤šç§å¤±æ•ˆæ¨¡å¼ï¼ŒåŒ…æ‹¬æ ¼å¼å¼•èµ·çš„è¯¯è§£å’Œè¿è¡Œæ—¶ç ´åæ€§ä»£ç ã€‚ç ”ç©¶å‘ç°ï¼Œæç¤ºæ ¼å¼å¯¹LLMçš„æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œå¹¶ä¸”ä¸åŒçš„LLMåœ¨å¤„ç†åµŒå…¥å¼MLä»»åŠ¡æ—¶è¡¨ç°å‡ºä¸åŒçš„è„†å¼±æ€§ã€‚é€šè¿‡å¯¹é”™è¯¯è¿›è¡Œåˆ†ç±»å’Œåˆ†æï¼Œè®ºæ–‡æ­ç¤ºäº†LLMåœ¨åµŒå…¥å¼MLä»£ç ç”Ÿæˆä¸­çš„å¸¸è§æ ¹æœ¬åŸå› å’Œç³»ç»Ÿæ€§é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§åµŒå…¥å¼æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œä¾‹å¦‚ç‰©è”ç½‘è®¾å¤‡ã€è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå’Œè¾¹ç¼˜è®¡ç®—å¹³å°ã€‚é€šè¿‡æé«˜LLMåœ¨åµŒå…¥å¼ä»£ç ç”Ÿæˆä¸­çš„å¯é æ€§ï¼Œå¯ä»¥åŠ é€ŸåµŒå…¥å¼MLåº”ç”¨çš„å¼€å‘å’Œéƒ¨ç½²ï¼Œé™ä½å¼€å‘æˆæœ¬ï¼Œå¹¶æé«˜ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚æœªæ¥çš„å½±å“åŒ…æ‹¬æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„åµŒå…¥å¼è®¾å¤‡å’Œç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly used to automate software generation in embedded machine learning workflows, yet their outputs often fail silently or behave unpredictably. This article presents an empirical investigation of failure modes in LLM-powered ML pipelines, based on an autopilot framework that orchestrates data preprocessing, model conversion, and on-device inference code generation. We show how prompt format, model behavior, and structural assumptions influence both success rates and failure characteristics, often in ways that standard validation pipelines fail to detect. Our analysis reveals a diverse set of error-prone behaviors, including format-induced misinterpretations and runtime-disruptive code that compiles but breaks downstream. We derive a taxonomy of failure categories and analyze errors across multiple LLMs, highlighting common root causes and systemic fragilities. Though grounded in specific devices, our study reveals broader challenges in LLM-based code generation. We conclude by discussing directions for improving reliability and traceability in LLM-powered embedded ML systems.

