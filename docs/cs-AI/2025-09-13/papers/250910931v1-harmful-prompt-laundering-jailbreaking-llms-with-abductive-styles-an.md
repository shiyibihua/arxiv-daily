---
layout: default
title: Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding
---

# Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10931" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10931v1</a>
  <a href="https://arxiv.org/pdf/2509.10931.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10931v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10931v1', 'Harmful Prompt Laundering: Jailbreaking LLMs with Abductive Styles and Symbolic Encoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seongho Joo, Hyukhun Koh, Kyomin Jung

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-13

**å¤‡æ³¨**: EMNLP 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHaPLaï¼Œåˆ©ç”¨å½’çº³æ¡†æ¶å’Œç¬¦å·ç¼–ç ç ´è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨é™åˆ¶ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¶Šç‹±æ”»å‡»` `å¯¹æŠ—æ€§æ”»å‡»` `å®‰å…¨æ¼æ´` `å½’çº³æ¨ç†` `ç¬¦å·ç¼–ç ` `æç¤ºå·¥ç¨‹` `é»‘ç›’æ”»å‡»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹å­˜åœ¨è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ï¼Œéœ€è¦ç ”ç©¶é€šç”¨çš„è¶Šç‹±æ”»å‡»æ–¹æ³•ã€‚
2. HaPLaé€šè¿‡å½’çº³æ¡†æ¶å¼•å¯¼æ¨¡å‹æ¨æ–­æœ‰å®³è¡Œä¸ºçš„ä¸­é—´æ­¥éª¤ï¼Œå¹¶ä½¿ç”¨ç¬¦å·ç¼–ç æ··æ·†æœ‰å®³å†…å®¹ã€‚
3. å®éªŒè¡¨æ˜HaPLaåœ¨å¤šç§æ¨¡å‹ä¸Šå…·æœ‰è¾ƒé«˜çš„æ”»å‡»æˆåŠŸç‡ï¼Œä½†ä¹Ÿæ­ç¤ºäº†å®‰å…¨è°ƒæ•´LLMçš„æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶è¢«æ»¥ç”¨äºæœ‰å®³ç›®çš„çš„æ½œåœ¨é£é™©ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦é—®é¢˜ã€‚ä¸ºäº†åŠ å¼ºå¯¹æ­¤ç±»æ¼æ´çš„é˜²å¾¡ï¼Œæœ‰å¿…è¦ç ”ç©¶åˆ©ç”¨LLMsæ¶æ„å’Œå­¦ä¹ èŒƒå¼å†…åœ¨å¼±ç‚¹çš„é€šç”¨è¶Šç‹±æ”»å‡»ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–ä¸”å¹¿æ³›é€‚ç”¨çš„è¶Šç‹±æŠ€æœ¯â€”â€”æœ‰å®³æç¤ºæ¸…æ´—ï¼ˆHaPLaï¼‰ï¼Œè¯¥æŠ€æœ¯ä»…éœ€å¯¹ç›®æ ‡æ¨¡å‹è¿›è¡Œé»‘ç›’è®¿é—®ã€‚HaPLaåŒ…å«ä¸¤ä¸ªä¸»è¦ç­–ç•¥ï¼š1ï¼‰å½’çº³æ¡†æ¶ï¼ŒæŒ‡ç¤ºLLMsæ¨æ–­å®ç°æœ‰å®³æ´»åŠ¨çš„åˆç†ä¸­é—´æ­¥éª¤ï¼Œè€Œä¸æ˜¯ç›´æ¥å“åº”æ˜ç¡®çš„æœ‰å®³æŸ¥è¯¢ï¼›2ï¼‰ç¬¦å·ç¼–ç ï¼Œä¸€ç§è½»é‡çº§ä¸”çµæ´»çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ··æ·†æœ‰å®³å†…å®¹ï¼Œå› ä¸ºå½“å‰çš„LLMsä¸»è¦å¯¹æ˜ç¡®çš„æœ‰å®³å…³é”®è¯æ•æ„Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHaPLaåœ¨GPTç³»åˆ—æ¨¡å‹ä¸Šå®ç°äº†è¶…è¿‡95%çš„æ”»å‡»æˆåŠŸç‡ï¼Œåœ¨æ‰€æœ‰ç›®æ ‡æ¨¡å‹ä¸Šå®ç°äº†70%çš„æ”»å‡»æˆåŠŸç‡ã€‚å¯¹å„ç§ç¬¦å·ç¼–ç è§„åˆ™çš„è¿›ä¸€æ­¥åˆ†æä¹Ÿæ­ç¤ºäº†ä¸€ä¸ªæ ¹æœ¬æ€§çš„æŒ‘æˆ˜ï¼šåœ¨ä¸æ˜¾è‘—é™ä½LLMså“åº”è‰¯æ€§æŸ¥è¯¢çš„å¸®åŠ©æ€§çš„å‰æä¸‹ï¼Œå®‰å…¨åœ°è°ƒæ•´LLMsä»ç„¶å¾ˆå›°éš¾ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹å®¹æ˜“å—åˆ°å¯¹æŠ—æ€§æ”»å‡»ï¼Œæ”»å‡»è€…å¯ä»¥é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºç»•è¿‡å®‰å…¨æœºåˆ¶ï¼Œä½¿å…¶ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºå…³é”®è¯è¿‡æ»¤ï¼Œä½†å®¹æ˜“è¢«ç»•è¿‡ã€‚å› æ­¤ï¼Œå¦‚ä½•è®¾è®¡ä¸€ç§é€šç”¨çš„ã€èƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡LLMå®‰å…¨é™åˆ¶çš„æ”»å‡»æ–¹æ³•æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHaPLaçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡å½’çº³çš„æ–¹å¼å¼•å¯¼æ¨¡å‹é€æ­¥æ¨å¯¼å‡ºæœ‰å®³è¡Œä¸ºçš„ä¸­é—´æ­¥éª¤ï¼Œè€Œä¸æ˜¯ç›´æ¥è¦æ±‚æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚åŒæ—¶ï¼Œä½¿ç”¨ç¬¦å·ç¼–ç å¯¹æœ‰å®³å…³é”®è¯è¿›è¡Œæ··æ·†ï¼Œé™ä½æ¨¡å‹å¯¹æœ‰å®³å†…å®¹çš„æ•æ„Ÿåº¦ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨åˆ©ç”¨LLMçš„å†…åœ¨å¼±ç‚¹ï¼Œå®ç°æœ‰æ•ˆçš„è¶Šç‹±æ”»å‡»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHaPLaæ”»å‡»æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šå½’çº³æ¡†æ¶é˜¶æ®µå’Œç¬¦å·ç¼–ç é˜¶æ®µã€‚åœ¨å½’çº³æ¡†æ¶é˜¶æ®µï¼Œæ”»å‡»è€…æ„é€ ä¸€ä¸ªæç¤ºï¼Œå¼•å¯¼LLMæ¨æ–­å®Œæˆç‰¹å®šæœ‰å®³ä»»åŠ¡æ‰€éœ€çš„ä¸­é—´æ­¥éª¤ã€‚åœ¨ç¬¦å·ç¼–ç é˜¶æ®µï¼Œæ”»å‡»è€…ä½¿ç”¨ç¬¦å·ç¼–ç è§„åˆ™å¯¹æç¤ºä¸­çš„æœ‰å®³å…³é”®è¯è¿›è¡Œæ›¿æ¢ï¼Œä»¥æ··æ·†LLMçš„å®‰å…¨æ£€æµ‹æœºåˆ¶ã€‚æ•´ä¸ªè¿‡ç¨‹åªéœ€è¦é»‘ç›’è®¿é—®ç›®æ ‡æ¨¡å‹ï¼Œä¸éœ€è¦äº†è§£æ¨¡å‹çš„å†…éƒ¨ç»“æ„å’Œå‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šHaPLaçš„å…³é”®åˆ›æ–°åœ¨äºå°†å½’çº³æ¨ç†å’Œç¬¦å·ç¼–ç ç›¸ç»“åˆï¼Œå½¢æˆä¸€ç§æœ‰æ•ˆçš„è¶Šç‹±æ”»å‡»æ–¹æ³•ã€‚ä¸ä»¥å¾€çš„æ”»å‡»æ–¹æ³•ç›¸æ¯”ï¼ŒHaPLaä¸éœ€è¦ç›´æ¥æ“çºµæ¨¡å‹çš„æ¢¯åº¦æˆ–å†…éƒ¨çŠ¶æ€ï¼Œè€Œæ˜¯é€šè¿‡å·§å¦™åœ°æ„é€ æç¤ºï¼Œåˆ©ç”¨æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ç»•è¿‡å®‰å…¨é™åˆ¶ã€‚è¿™ç§æ–¹æ³•å…·æœ‰æ›´å¼ºçš„é€šç”¨æ€§å’Œå¯ç§»æ¤æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå½’çº³æ¡†æ¶çš„è®¾è®¡éœ€è¦ä»”ç»†è€ƒè™‘å¦‚ä½•å¼•å¯¼æ¨¡å‹é€æ­¥æ¨å¯¼å‡ºæœ‰å®³è¡Œä¸ºçš„ä¸­é—´æ­¥éª¤ï¼Œé¿å…ç›´æ¥è§¦å‘å®‰å…¨æœºåˆ¶ã€‚ç¬¦å·ç¼–ç è§„åˆ™çš„è®¾è®¡éœ€è¦ä¿è¯æ··æ·†åçš„æç¤ºä»ç„¶èƒ½å¤Ÿè¢«æ¨¡å‹ç†è§£ï¼ŒåŒæ—¶èƒ½å¤Ÿæœ‰æ•ˆé™ä½æ¨¡å‹å¯¹æœ‰å®³å…³é”®è¯çš„æ•æ„Ÿåº¦ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†å¤šç§ç¬¦å·ç¼–ç è§„åˆ™ï¼Œä¾‹å¦‚å­—ç¬¦æ›¿æ¢ã€åŒä¹‰è¯æ›¿æ¢ç­‰ã€‚æ”»å‡»æˆåŠŸç‡çš„è¯„ä¼°æŒ‡æ ‡æ˜¯æ¨¡å‹æ˜¯å¦ç”Ÿæˆäº†ç¬¦åˆæ”»å‡»è€…æ„å›¾çš„æœ‰å®³å†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HaPLaåœ¨GPTç³»åˆ—æ¨¡å‹ä¸Šå®ç°äº†è¶…è¿‡95%çš„æ”»å‡»æˆåŠŸç‡ï¼Œåœ¨æ‰€æœ‰ç›®æ ‡æ¨¡å‹ä¸Šå®ç°äº†70%çš„æ”»å‡»æˆåŠŸç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒHaPLaèƒ½å¤Ÿæœ‰æ•ˆç»•è¿‡å¤šç§LLMçš„å®‰å…¨æœºåˆ¶ï¼Œè¯æ˜äº†å½“å‰LLMåœ¨å®‰å…¨æ€§æ–¹é¢ä»ç„¶å­˜åœ¨è¾ƒå¤§çš„æ¼æ´ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œåœ¨ä¸æ˜¾è‘—é™ä½LLMå“åº”è‰¯æ€§æŸ¥è¯¢çš„å¸®åŠ©æ€§çš„å‰æä¸‹ï¼Œå®‰å…¨åœ°è°ƒæ•´LLMä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯ç”¨äºè¯„ä¼°å’Œæ”¹è¿›å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå¸®åŠ©å¼€å‘è€…å‘ç°å’Œä¿®å¤æ½œåœ¨çš„å®‰å…¨æ¼æ´ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶ä¹Ÿæé†’äººä»¬éœ€è¦å…³æ³¨LLMè¢«æ»¥ç”¨çš„é£é™©ï¼Œå¹¶é‡‡å–ç›¸åº”çš„é˜²å¾¡æªæ–½ï¼Œä¾‹å¦‚æ›´å¼ºå¤§çš„å®‰å…¨è¿‡æ»¤æœºåˆ¶å’Œæ›´å®Œå–„çš„ä¼¦ç†å®¡æŸ¥æµç¨‹ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´æœ‰æ•ˆçš„é˜²å¾¡æ–¹æ³•ï¼Œä»¥åŠå¦‚ä½•å¹³è¡¡LLMçš„æœ‰ç”¨æ€§å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, but their potential misuse for harmful purposes remains a significant concern. To strengthen defenses against such vulnerabilities, it is essential to investigate universal jailbreak attacks that exploit intrinsic weaknesses in the architecture and learning paradigms of LLMs. In response, we propose \textbf{H}armful \textbf{P}rompt \textbf{La}undering (HaPLa), a novel and broadly applicable jailbreaking technique that requires only black-box access to target models. HaPLa incorporates two primary strategies: 1) \textit{abductive framing}, which instructs LLMs to infer plausible intermediate steps toward harmful activities, rather than directly responding to explicit harmful queries; and 2) \textit{symbolic encoding}, a lightweight and flexible approach designed to obfuscate harmful content, given that current LLMs remain sensitive primarily to explicit harmful keywords. Experimental results show that HaPLa achieves over 95% attack success rate on GPT-series models and 70% across all targets. Further analysis with diverse symbolic encoding rules also reveals a fundamental challenge: it remains difficult to safely tune LLMs without significantly diminishing their helpfulness in responding to benign queries.

