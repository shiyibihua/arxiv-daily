---
layout: default
title: LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering
---

# LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10818" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.10818v1</a>
  <a href="https://arxiv.org/pdf/2509.10818.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10818v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10818v1', 'LLM Enhancement with Domain Expert Mental Model to Reduce LLM Hallucination with Causal Prompt Engineering')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Boris Kovalerchuk, Brent D. Fegley

**ÂàÜÁ±ª**: cs.AI, cs.HC

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-13

**Â§áÊ≥®**: 25 pages,4 figures, 2 tables

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÈ¢ÜÂüü‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãÁöÑÂõ†ÊûúÊèêÁ§∫Â∑•Á®ãÔºåÂáèÂ∞ëLLMÂπªËßâ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `È¢ÜÂüü‰∏ìÂÆ∂Áü•ËØÜ` `ÂøÉÊô∫Ê®°Âûã` `ÊèêÁ§∫Â∑•Á®ã` `ÂÜ≥Á≠ñÊîØÊåÅ` `‰∫∫Êú∫ÂØπËØù` `Áü•ËØÜË°®Á§∫`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâLLMÂú®ÂÜ≥Á≠ñÊîØÊåÅ‰∏≠Èù¢‰∏¥ÂπªËßâÈóÆÈ¢òÔºåÊ∫ê‰∫éËÆ≠ÁªÉÊï∞ÊçÆÁº∫Â§±ÂíåÊó†Ê≥ïÊúâÊïàÂà©Áî®È¢ÜÂüü‰∏ìÂÆ∂Áü•ËØÜ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÂü∫‰∫é‰∫∫Êú∫ÂØπËØùÂíåÂçïË∞ÉÂáΩÊï∞‰ºòÂåñÁöÑ‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãÔºàEMMÔºâÊûÑÂª∫ÊñπÊ≥ïÔºåÁî®‰∫éLLMÊèêÁ§∫Â∑•Á®ã„ÄÇ
3. ËØ•ÊñπÊ≥ïÈÄöËøáÁªìÊûÑÂåñÈ¢ÜÂüüÁü•ËØÜÔºåÁîüÊàêÊõ¥ÊúâÊïàÁöÑÊèêÁ§∫ÔºåÊó®Âú®ÂáèÂ∞ëLLMÂú®ÂÜ≥Á≠ñ‰ªªÂä°‰∏≠ÁöÑÂπªËßâÁé∞Ë±°„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂêÑÁßçÂ≠¶ÁßëÂíåÈ¢ÜÂüüÈÉΩÂ≠òÂú®Âõ∞ÈöæÁöÑÂÜ≥Á≠ñÈóÆÈ¢ò„ÄÇÁîüÊàêÊäÄÊúØÔºåÁâπÂà´ÊòØÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÊôÆÂèäÔºåÊøÄÂèë‰∫Ü‰∫∫‰ª¨‰ΩøÁî®ÂÆÉ‰ª¨ËøõË°åÂÜ≥Á≠ñÊîØÊåÅÁöÑÂÖ¥Ë∂£„ÄÇÁÑ∂ËÄåÔºåLLMÊó†Ê≥ïËß£ÂÜ≥ËÆ≠ÁªÉÊï∞ÊçÆ‰∏≠ÁöÑÁº∫Â§±ÈóÆÈ¢òÔºåÂØºËá¥ÂπªËßâ„ÄÇÊ£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÔºàRAGÔºâÈÄöËøáÊï¥ÂêàÂ§ñÈÉ®‰ø°ÊÅØÊ£ÄÁ¥¢Êù•Â¢ûÂº∫LLMÔºåÂáèÂ∞ëÂπªËßâÂπ∂ÊèêÈ´òÂáÜÁ°ÆÊÄß„ÄÇÁÑ∂ËÄåÔºåRAGÂèäÁõ∏ÂÖ≥ÊñπÊ≥ïÂè™ÊòØÈÉ®ÂàÜËß£ÂÜ≥ÊñπÊ°àÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂèØËÉΩÊó†Ê≥ïËÆøÈóÆÊâÄÊúâÂøÖË¶ÅÁöÑÊù•Ê∫êÊàñÂÖ≥ÈîÆÁöÑÁº∫Â§±‰ø°ÊÅØ„ÄÇÂç≥‰ΩøÊòØÊó•Â∏∏ÈóÆÈ¢ò‰πüÂ∏∏Â∏∏ÊåëÊàòLLMÁöÑËÉΩÂäõ„ÄÇÊèê‰∫§ÂåÖÂê´‰∏ä‰∏ãÊñáÂíåÁ§∫‰æãÁöÑÊõ¥ÈïøÊèêÁ§∫ÊòØËß£ÂÜ≥Áü•ËØÜÂ∑ÆË∑ùÁöÑ‰∏ÄÁßçÊñπÊ≥ïÔºå‰ΩÜËÆæËÆ°ÊúâÊïàÁöÑÊèêÁ§∫Âπ∂ÈùûÊòì‰∫ãÔºåÂπ∂‰∏îÂèØËÉΩÊó†Ê≥ïÊçïÊçâÈ¢ÜÂüü‰∏ìÂÆ∂ÁöÑÂ§çÊùÇÂøÉÊô∫Ê®°Âûã„ÄÇÂØπ‰∫éÁº∫Â∞ëÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑ‰ªªÂä°ÔºåLLMÊòØ‰∏çÂ§üÁöÑÔºåËÆ∏Â§öÁé∞ÊúâÁ≥ªÁªüÂú®ÂèØÁî®ÊñáÊ°£‰∏≠ÁöÑË°®Á§∫‰πüÂæàÂ∑Æ„ÄÇÊú¨ÊñáÊé¢ËÆ®‰∫ÜLLMÂ¶Ç‰Ωï‰ΩøÂÜ≥Á≠ñÊõ¥ÊúâÊïàÁéáÔºå‰ΩøÁî®ËØÑ‰º∞ÊòØÂê¶ÂõûÂ∫îÂæÅÈõÜÂª∫ËÆÆ‰π¶ÁöÑËøêË°åÁ§∫‰æã„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ºòÂåñ‰∫∫Êú∫ÂØπËØù‰ª•ÂèäÂçïË∞ÉÂ∏ÉÂ∞îÂíåkÂÄºÂáΩÊï∞ÁöÑÊäÄÊúØÔºå‰ª•ÂèëÁé∞ËÆ°ÁÆó‰∏äÊòì‰∫éÂ§ÑÁêÜÁöÑ‰∏™‰∫∫‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãÔºàEMMÔºâÁî®‰∫éÂÜ≥Á≠ñ„ÄÇÊàë‰ª¨ÁöÑÁî®‰∫éLLMÊèêÁ§∫Â∑•Á®ãÁöÑEMMÁÆóÊ≥ïÊúâÂõõ‰∏™Ê≠•È™§ÔºöÔºà1ÔºâÂõ†Á¥†ËØÜÂà´ÔºåÔºà2ÔºâÂõ†Á¥†ÁöÑÂ±ÇÊ¨°ÁªìÊûÑÂåñÔºåÔºà3ÔºâÁîüÊàêÂπø‰πâ‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãËßÑËåÉÔºå‰ª•ÂèäÔºà4Ôºâ‰ªéËØ•ËßÑËåÉÁîüÊàêËØ¶ÁªÜÁöÑÂπø‰πâ‰∏ìÂÆ∂ÂøÉÊô∫Ê®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöLLMÂú®Â§çÊùÇÂÜ≥Á≠ñÈóÆÈ¢ò‰∏≠ÔºåÁî±‰∫éËÆ≠ÁªÉÊï∞ÊçÆ‰∏çÂÆåÊï¥ÂíåÁº∫‰πèÈ¢ÜÂüüÁü•ËØÜÔºåÂÆπÊòì‰∫ßÁîüÂπªËßâÔºåÂØºËá¥ÂÜ≥Á≠ñË¥®Èáè‰∏ãÈôç„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ¶ÇRAGËôΩÁÑ∂ËÉΩÂºïÂÖ•Â§ñÈÉ®‰ø°ÊÅØÔºå‰ΩÜÊó†Ê≥ïÂÆåÂÖ®Ëß£ÂÜ≥Áü•ËØÜÁº∫Â§±Âíå‰∏ìÂÆ∂Áü•ËØÜÈöæ‰ª•ÊúâÊïàËûçÂÖ•ÁöÑÈóÆÈ¢ò„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂà©Áî®È¢ÜÂüü‰∏ìÂÆ∂ÁöÑÁü•ËØÜÊù•ÊåáÂØºLLMËøõË°åÊõ¥ÂáÜÁ°ÆÁöÑÂÜ≥Á≠ñÊòØ‰∏Ä‰∏™ÂÖ≥ÈîÆÈóÆÈ¢ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊûÑÂª∫È¢ÜÂüü‰∏ìÂÆ∂ÁöÑÂøÉÊô∫Ê®°ÂûãÔºàEMMÔºâÔºåÂπ∂Â∞ÜÂÖ∂ËΩ¨Âåñ‰∏∫LLMÂèØ‰ª•ÁêÜËß£ÂíåÂà©Áî®ÁöÑÊèêÁ§∫‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òLLMÂú®ÂÜ≥Á≠ñ‰ªªÂä°‰∏≠ÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇËøôÁßçÊñπÊ≥ïÊó®Âú®Âº•ÂêàLLMÁöÑÁü•ËØÜÂ∑ÆË∑ùÔºåÂπ∂‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞Ê®°Êãü‰∏ìÂÆ∂ÁöÑÂÜ≥Á≠ñËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ïÂåÖÂê´Âõõ‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) Âõ†Á¥†ËØÜÂà´ÔºöÁ°ÆÂÆöÂΩ±ÂìçÂÜ≥Á≠ñÁöÑÂÖ≥ÈîÆÂõ†Á¥†Ôºõ2) Âõ†Á¥†ÁöÑÂ±ÇÊ¨°ÁªìÊûÑÂåñÔºöÂ∞ÜÂõ†Á¥†ÁªÑÁªáÊàêÂ±ÇÊ¨°ÁªìÊûÑÔºåÂèçÊò†ÂÆÉ‰ª¨‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºõ3) ÁîüÊàêÂπø‰πâ‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãËßÑËåÉÔºöÂü∫‰∫éÂõ†Á¥†ÂíåÁªìÊûÑÔºåÁîüÊàêEMMÁöÑËßÑËåÉÔºõ4) ÁîüÊàêËØ¶ÁªÜÁöÑÂπø‰πâ‰∏ìÂÆ∂ÂøÉÊô∫Ê®°ÂûãÔºö‰ªéËßÑËåÉ‰∏≠ÁîüÊàêÂÖ∑‰ΩìÁöÑEMMÔºåÁî®‰∫éLLMÊèêÁ§∫Â∑•Á®ã„ÄÇÊï¥‰∏™ÊµÅÁ®ãÊó®Âú®Â∞Ü‰∏ìÂÆ∂ÁöÑÈöêÊÄßÁü•ËØÜÊòæÊÄßÂåñÔºåÂπ∂ËΩ¨Âåñ‰∏∫LLMÂèØÁî®ÁöÑÂΩ¢Âºè„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂ∞ÜÈ¢ÜÂüü‰∏ìÂÆ∂ÁöÑÂøÉÊô∫Ê®°ÂûãÊòæÂºèÂú∞ÊûÑÂª∫Âá∫Êù•ÔºåÂπ∂Áî®‰∫éÊåáÂØºLLMÁöÑÊèêÁ§∫Â∑•Á®ã„ÄÇ‰∏é‰º†ÁªüÁöÑÊèêÁ§∫Â∑•Á®ãÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊõ¥Âä†ÁªìÊûÑÂåñÂíåÁ≥ªÁªüÂåñÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÊçïÊçâ‰∏ìÂÆ∂ÁöÑÂÜ≥Á≠ñÈÄªËæëÂíåÁü•ËØÜ„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂà©Áî®‰∫∫Êú∫ÂØπËØùÂíåÂçïË∞ÉÂáΩÊï∞‰ºòÂåñÊäÄÊúØÔºåÊèêÈ´ò‰∫ÜEMMÊûÑÂª∫ÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫Êñá‰∏≠ÊèêÂà∞ÁöÑÂçïË∞ÉÂ∏ÉÂ∞îÂíåkÂÄºÂáΩÊï∞Âú®EMMÁöÑÊûÑÂª∫ËøáÁ®ã‰∏≠Ëµ∑ÁùÄÂÖ≥ÈîÆ‰ΩúÁî®ÔºåÁî®‰∫éË°®Á§∫Âõ†Á¥†‰πãÈó¥ÁöÑÈÄªËæëÂÖ≥Á≥ªÂíåÂΩ±ÂìçÁ®ãÂ∫¶„ÄÇÂÖ∑‰ΩìÁöÑÊäÄÊúØÁªÜËäÇÔºå‰æãÂ¶ÇÂèÇÊï∞ËÆæÁΩÆ„ÄÅÊçüÂ§±ÂáΩÊï∞Á≠âÔºåÂú®ÊëòË¶Å‰∏≠Ê≤°ÊúâËØ¶ÁªÜËØ¥ÊòéÔºåÂ±û‰∫éÊú™Áü•‰ø°ÊÅØ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÊëòË¶Å‰∏≠Ê≤°ÊúâÊèê‰æõÂÖ∑‰ΩìÁöÑÂÆûÈ™åÁªìÊûúÂíåÊÄßËÉΩÊï∞ÊçÆÔºåÂõ†Ê≠§Êó†Ê≥ïÊÄªÁªìÂÆûÈ™å‰∫ÆÁÇπ„ÄÇÂÖ∑‰ΩìÁöÑÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶„ÄÅÂØπÊØîÂü∫Á∫øÁ≠â‰ø°ÊÅØÊú™Áü•„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶Å‰∏ìÂÆ∂Áü•ËØÜÁöÑÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªüÔºå‰æãÂ¶ÇÈ£éÈô©ËØÑ‰º∞„ÄÅÊäïËµÑÂÜ≥Á≠ñ„ÄÅÂåªÁñóËØäÊñ≠Á≠â„ÄÇÈÄöËøáÂ∞ÜÈ¢ÜÂüü‰∏ìÂÆ∂ÁöÑÁü•ËØÜËûçÂÖ•LLMÔºåÂèØ‰ª•ÊèêÈ´òÂÜ≥Á≠ñÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåÂπ∂‰∏∫Áî®Êà∑Êèê‰æõÊõ¥ÂèØÈù†ÁöÑÂÜ≥Á≠ñÂª∫ËÆÆ„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÊâ©Â±ïÂà∞Êõ¥ÂπøÊ≥õÁöÑÈ¢ÜÂüüÔºåÂπ∂‰∏éÂÖ∂‰ªñÊäÄÊúØÁõ∏ÁªìÂêàÔºåÊûÑÂª∫Êõ¥Êô∫ËÉΩÂåñÁöÑÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Difficult decision-making problems abound in various disciplines and domains. The proliferation of generative techniques, especially large language models (LLMs), has excited interest in using them for decision support. However, LLMs cannot yet resolve missingness in their training data, leading to hallucinations. Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external information retrieval, reducing hallucinations and improving accuracy. Yet, RAG and related methods are only partial solutions, as they may lack access to all necessary sources or key missing information. Even everyday issues often challenge LLMs' abilities. Submitting longer prompts with context and examples is one approach to address knowledge gaps, but designing effective prompts is non-trivial and may not capture complex mental models of domain experts. For tasks with missing critical information, LLMs are insufficient, as are many existing systems poorly represented in available documents. This paper explores how LLMs can make decision-making more efficient, using a running example of evaluating whether to respond to a call for proposals. We propose a technology based on optimized human-machine dialogue and monotone Boolean and k-valued functions to discover a computationally tractable personal expert mental model (EMM) of decision-making. Our EMM algorithm for LLM prompt engineering has four steps: (1) factor identification, (2) hierarchical structuring of factors, (3) generating a generalized expert mental model specification, and (4) generating a detailed generalized expert mental model from that specification.

