---
layout: default
title: NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks
---

# NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00446" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00446v1</a>
  <a href="https://arxiv.org/pdf/2509.00446.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00446v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00446v1', 'NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yen-Che Chien, Kuang-Da Wang, Wei-Yao Wang, Wen-Chih Peng

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºNEWSAGENTä»¥è¯„ä¼°å¤šæ¨¡æ€æ™ºèƒ½ä½“åœ¨æ–°é—»å†™ä½œä¸­çš„åº”ç”¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ™ºèƒ½ä½“` `æ–°é—»å†™ä½œ` `ä¿¡æ¯æ£€ç´¢` `å™äº‹æ•´åˆ` `è‡ªåŠ¨åŒ–å†™ä½œ` `åŸºå‡†è¯„ä¼°` `çœŸå®ä¸–ç•Œåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ™ºèƒ½ä½“åœ¨å¤šæ¨¡æ€æ•°æ®å¤„ç†ä¸­çš„èƒ½åŠ›å°šæœªå¾—åˆ°å……åˆ†è¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨æ–°é—»å†™ä½œé¢†åŸŸçš„å®é™…åº”ç”¨ä¸­ã€‚
2. è®ºæ–‡æå‡ºNEWSAGENTåŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°æ™ºèƒ½ä½“å¦‚ä½•ä»å¤šæ¨¡æ€åŸå§‹å†…å®¹ä¸­è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æ–°é—»ï¼Œå¼ºè°ƒä¿¡æ¯æ£€ç´¢ä¸å™äº‹æ•´åˆçš„èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ™ºèƒ½ä½“åœ¨ä¿¡æ¯æ£€ç´¢æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è§„åˆ’å’Œå™äº‹æ•´åˆä¸Šä»é¢ä¸´æŒ‘æˆ˜ï¼Œæ˜¾ç¤ºå‡ºè¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è‡ªä¸»æ•°å­—æ™ºèƒ½ä½“çš„è¿›æ­¥ï¼Œå¦‚ä½•æé«˜å¤šæ¨¡æ€ç½‘ç»œæ•°æ®çš„ç”Ÿäº§åŠ›ä»ä¸æ˜ç¡®ã€‚æœ¬æ–‡ç ”ç©¶äº†æ–°é—»å†™ä½œé¢†åŸŸï¼Œæå‡ºäº†NEWSAGENTåŸºå‡†ï¼Œè¯„ä¼°æ™ºèƒ½ä½“å¦‚ä½•è‡ªåŠ¨æœç´¢ã€é€‰æ‹©ä¿¡æ¯å¹¶ç”Ÿæˆæ–°é—»æ–‡ç« ã€‚è¯¥åŸºå‡†åŒ…å«6000ä¸ªç»è¿‡äººå·¥éªŒè¯çš„çœŸå®æ–°é—»ç¤ºä¾‹ï¼Œè¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œæ™ºèƒ½ä½“åœ¨æ£€ç´¢ç›¸å…³äº‹å®æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨è§„åˆ’å’Œå™äº‹æ•´åˆä¸Šå­˜åœ¨å›°éš¾ã€‚NEWSAGENTä¸ºè¯„ä¼°æ™ºèƒ½ä½“åœ¨å¤šæ¨¡æ€æ•°æ®å¤„ç†ä¸­çš„èƒ½åŠ›æä¾›äº†ç°å®çš„æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ™ºèƒ½ä½“åœ¨æ–°é—»å†™ä½œä¸­å¦‚ä½•æœ‰æ•ˆå¤„ç†å¤šæ¨¡æ€æ•°æ®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¿¡æ¯æ£€ç´¢å’Œå™äº‹æ•´åˆæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³çœŸå®æ–°é—»å†™ä½œçš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡NEWSAGENTåŸºå‡†è¯„ä¼°æ™ºèƒ½ä½“åœ¨æ–°é—»å†™ä½œä¸­çš„èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ä»å¤šæ¨¡æ€å†…å®¹ä¸­æå–ä¿¡æ¯å¹¶ç”Ÿæˆç»“æ„åŒ–æ–‡ç« ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ¨¡æ‹ŸçœŸå®æ–°é—»å†™ä½œè¿‡ç¨‹ä¸­çš„å¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¿¡æ¯æ£€ç´¢ã€å™äº‹è§„åˆ’å’Œæ–‡ç« ç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ™ºèƒ½ä½“é¦–å…ˆæ ¹æ®å†™ä½œæŒ‡ä»¤è¿›è¡Œä¿¡æ¯æ£€ç´¢ï¼Œç„¶åè¿›è¡Œå™äº‹è§„åˆ’ï¼Œæœ€åç”Ÿæˆå®Œæ•´çš„æ–°é—»æ–‡ç« ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ä¸€ä¸ªçœŸå®çš„æ–°é—»å†™ä½œåŸºå‡†ï¼ŒåŒ…å«6000ä¸ªç»è¿‡éªŒè¯çš„å®ä¾‹ï¼Œå¼ºè°ƒäº†ä¿¡æ¯æ£€ç´¢ä¸å™äº‹æ•´åˆçš„æŒ‘æˆ˜ï¼Œè¿™ä¸ç°æœ‰çš„ç®€å•æ‘˜è¦æˆ–æ£€ç´¢ä»»åŠ¡æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æ™ºèƒ½ä½“åœ¨ä¿¡æ¯æ£€ç´¢å’Œå™äº‹æ•´åˆæ–¹é¢çš„è¡¨ç°ï¼Œç¡®ä¿ç”Ÿæˆçš„æ–°é—»æ–‡ç« ç¬¦åˆå®é™…æ–°é—»å†™ä½œçš„æ ‡å‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ™ºèƒ½ä½“åœ¨ä¿¡æ¯æ£€ç´¢æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè·å–ç›¸å…³äº‹å®ã€‚ç„¶è€Œï¼Œåœ¨è§„åˆ’å’Œå™äº‹æ•´åˆæ–¹é¢ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œè¡¨æ˜è¯¥é¢†åŸŸä»éœ€è¿›ä¸€æ­¥ç ”ç©¶ä¸æ”¹è¿›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿å°šæœªè¯¦ç»†æŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ–°é—»è‡ªåŠ¨åŒ–å†™ä½œã€ä¿¡æ¯æ£€ç´¢ç³»ç»Ÿå’Œæ™ºèƒ½å†…å®¹ç”Ÿæˆã€‚é€šè¿‡æå‡æ™ºèƒ½ä½“åœ¨å¤šæ¨¡æ€æ•°æ®å¤„ç†ä¸­çš„èƒ½åŠ›ï¼Œæœªæ¥å¯å®ç°æ›´é«˜æ•ˆçš„æ–°é—»ç”Ÿäº§å’Œä¿¡æ¯ä¼ æ’­ï¼Œæ¨åŠ¨æ–°é—»è¡Œä¸šçš„æ•°å­—åŒ–è½¬å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in autonomous digital agents from industry (e.g., Manus AI and Gemini's research mode) highlight potential for structured tasks by autonomous decision-making and task decomposition; however, it remains unclear to what extent the agent-based systems can improve multimodal web data productivity. We study this in the realm of journalism, which requires iterative planning, interpretation, and contextual reasoning from multimodal raw contents to form a well structured news. We introduce NEWSAGENT, a benchmark for evaluating how agents can automatically search available raw contents, select desired information, and edit and rephrase to form a news article by accessing core journalistic functions. Given a writing instruction and firsthand data as how a journalist initiates a news draft, agents are tasked to identify narrative perspectives, issue keyword-based queries, retrieve historical background, and generate complete articles. Unlike typical summarization or retrieval tasks, essential context is not directly available and must be actively discovered, reflecting the information gaps faced in real-world news writing. NEWSAGENT includes 6k human-verified examples derived from real news, with multimodal contents converted to text for broad model compatibility. We evaluate open- and closed-sourced LLMs with commonly-used agentic frameworks on NEWSAGENT, which shows that agents are capable of retrieving relevant facts but struggling with planning and narrative integration. We believe that NEWSAGENT serves a realistic testbed for iterating and evaluating agent capabilities in terms of multimodal web data manipulation to real-world productivity.

