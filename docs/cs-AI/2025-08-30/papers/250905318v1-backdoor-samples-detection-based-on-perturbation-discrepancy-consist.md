---
layout: default
title: Backdoor Samples Detection Based on Perturbation Discrepancy Consistency in Pre-trained Language Models
---

# Backdoor Samples Detection Based on Perturbation Discrepancy Consistency in Pre-trained Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05318" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05318v1</a>
  <a href="https://arxiv.org/pdf/2509.05318.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05318v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05318v1', 'Backdoor Samples Detection Based on Perturbation Discrepancy Consistency in Pre-trained Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zuquan Peng, Jianming Fu, Lixin Zou, Li Zheng, Yanzhen Ren, Guojun Peng

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: 13 pages, 9 figures, 8 tables, journal

**æœŸåˆŠ**: Neural Networks 193(2026) 108025

**DOI**: [10.1016/j.neunet.2025.108025](https://doi.org/10.1016/j.neunet.2025.108025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ‰°åŠ¨å·®å¼‚ä¸€è‡´æ€§çš„åé—¨æ ·æœ¬æ£€æµ‹æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åé—¨æ”»å‡»` `æ ·æœ¬æ£€æµ‹` `é¢„è®­ç»ƒæ¨¡å‹` `æ‰°åŠ¨ä¸€è‡´æ€§` `ç½‘ç»œå®‰å…¨` `æœºå™¨å­¦ä¹ ` `å¯¹æŠ—æ€§æ ·æœ¬`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åé—¨æ ·æœ¬æ£€æµ‹æ–¹æ³•é€šå¸¸éœ€è¦è®¿é—®è¢«æ±¡æŸ“çš„æ¨¡å‹æˆ–é¢å¤–çš„å¹²å‡€æ ·æœ¬ï¼Œé™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åé—¨æ ·æœ¬æ£€æµ‹æ–¹æ³•ï¼ŒåŸºäºæ‰°åŠ¨å·®å¼‚çš„ä¸€è‡´æ€§è¯„ä¼°ï¼Œèƒ½å¤Ÿåœ¨é¢„è®­ç»ƒå’Œåè®­ç»ƒé˜¶æ®µä½¿ç”¨ã€‚
3. åœ¨å››ç§å…¸å‹çš„åé—¨æ”»å‡»å’Œäº”ç§å¤§å‹è¯­è¨€æ¨¡å‹åé—¨æ”»å‡»çš„å®éªŒä¸­ï¼Œæ‰€ææ–¹æ³•è¡¨ç°ä¼˜äºç°æœ‰çš„é›¶æ ·æœ¬é»‘ç›’æ£€æµ‹æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€æœªç»è¿‡å®¡æŸ¥çš„ç¬¬ä¸‰æ–¹å’Œäº’è”ç½‘æ•°æ®çš„ä½¿ç”¨ï¼Œé¢„è®­ç»ƒæ¨¡å‹å˜å¾—å®¹æ˜“å—åˆ°åé—¨æ”»å‡»ã€‚æ£€æµ‹åé—¨æ ·æœ¬å¯¹äºé˜²æ­¢æ¨ç†æœŸé—´çš„åé—¨æ¿€æ´»æˆ–è®­ç»ƒæœŸé—´çš„æ³¨å…¥è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ£€æµ‹æ–¹æ³•é€šå¸¸è¦æ±‚é˜²å¾¡è€…è®¿é—®è¢«æ±¡æŸ“çš„æ¨¡å‹ã€é¢å¤–çš„å¹²å‡€æ ·æœ¬æˆ–æ˜¾è‘—çš„è®¡ç®—èµ„æºï¼Œè¿™é™åˆ¶äº†å…¶å®ç”¨æ€§ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ‰°åŠ¨å·®å¼‚ä¸€è‡´æ€§è¯„ä¼°çš„åé—¨æ ·æœ¬æ£€æµ‹æ–¹æ³•ï¼ˆNETEï¼‰ï¼Œè¯¥æ–¹æ³•å¯åœ¨é¢„è®­ç»ƒå’Œåè®­ç»ƒé˜¶æ®µä½¿ç”¨ã€‚åœ¨æ£€æµ‹è¿‡ç¨‹ä¸­ï¼Œä»…éœ€ä¸€ä¸ªç°æˆçš„é¢„è®­ç»ƒæ¨¡å‹æ¥è®¡ç®—æ ·æœ¬çš„å¯¹æ•°æ¦‚ç‡ï¼Œå¹¶åŸºäºæ©ç å¡«å……ç­–ç•¥ç”Ÿæˆæ‰°åŠ¨ã€‚æˆ‘ä»¬çš„ç ”ç©¶åŸºäºä¸€ä¸ªæœ‰è¶£çš„ç°è±¡ï¼šåé—¨æ ·æœ¬çš„æ‰°åŠ¨å·®å¼‚å˜åŒ–å°äºå¹²å‡€æ ·æœ¬ã€‚é€šè¿‡ä½¿ç”¨æ›²ç‡æ¥æµ‹é‡ä¸åŒæ‰°åŠ¨æ ·æœ¬ä¸è¾“å…¥æ ·æœ¬ä¹‹é—´çš„å¯¹æ•°æ¦‚ç‡å·®å¼‚ï¼Œä»è€Œè¯„ä¼°æ‰°åŠ¨å·®å¼‚çš„ä¸€è‡´æ€§ï¼Œä»¥ç¡®å®šè¾“å…¥æ ·æœ¬æ˜¯å¦ä¸ºåé—¨æ ·æœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ£€æµ‹ç­–ç•¥ä¼˜äºç°æœ‰çš„é›¶æ ·æœ¬é»‘ç›’æ£€æµ‹æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åé—¨æ ·æœ¬æ£€æµ‹ä¸­çš„å®ç”¨æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºå¯¹è¢«æ±¡æŸ“æ¨¡å‹çš„è®¿é—®æˆ–é¢å¤–çš„å¹²å‡€æ ·æœ¬ï¼Œå¯¼è‡´æ£€æµ‹è¿‡ç¨‹å¤æ‚ä¸”èµ„æºæ¶ˆè€—å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„NETEæ–¹æ³•åˆ©ç”¨æ‰°åŠ¨å·®å¼‚çš„ä¸€è‡´æ€§ç°è±¡ï¼Œè®¤ä¸ºåé—¨æ ·æœ¬çš„æ‰°åŠ¨å·®å¼‚å˜åŒ–å°äºå¹²å‡€æ ·æœ¬ï¼Œä»è€Œé€šè¿‡è®¡ç®—å¯¹æ•°æ¦‚ç‡çš„æ›²ç‡æ¥è¿›è¡Œæ£€æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä½¿ç”¨ç°æˆçš„é¢„è®­ç»ƒæ¨¡å‹è®¡ç®—æ ·æœ¬çš„å¯¹æ•°æ¦‚ç‡ï¼Œåº”ç”¨æ©ç å¡«å……ç­–ç•¥ç”Ÿæˆæ‰°åŠ¨ï¼Œå¹¶é€šè¿‡è¯„ä¼°æ‰°åŠ¨å·®å¼‚çš„ä¸€è‡´æ€§æ¥åˆ¤æ–­æ ·æœ¬æ˜¯å¦ä¸ºåé—¨æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åŸºäºæ‰°åŠ¨å·®å¼‚ä¸€è‡´æ€§çš„æ£€æµ‹æ–¹æ³•ï¼Œæ˜¾è‘—é™ä½äº†å¯¹é¢å¤–èµ„æºçš„ä¾èµ–ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„çµæ´»æ€§å’Œé€‚ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œé‡‡ç”¨äº†æ›²ç‡ä½œä¸ºæµ‹é‡æ ‡å‡†ï¼Œå¹¶è®¾è®¡äº†è‡ªåŠ¨åŒ–çš„æ‰°åŠ¨ç”Ÿæˆå‡½æ•°ï¼Œç¡®ä¿æ£€æµ‹è¿‡ç¨‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ–¹æ³•èƒ½å¤Ÿåœ¨å¤šç§æ”»å‡»åœºæ™¯ä¸‹ä¿æŒè‰¯å¥½çš„æ£€æµ‹æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å››ç§å…¸å‹åé—¨æ”»å‡»å’Œäº”ç§å¤§å‹è¯­è¨€æ¨¡å‹åé—¨æ”»å‡»ä¸­å‡è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºç°æœ‰çš„é›¶æ ·æœ¬é»‘ç›’æ£€æµ‹æ–¹æ³•ï¼Œæ£€æµ‹å‡†ç¡®ç‡æå‡æ˜¾è‘—ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç½‘ç»œå®‰å…¨ã€æœºå™¨å­¦ä¹ æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°ä»¥åŠå¯¹æŠ—æ€§æ ·æœ¬æ£€æµ‹ç­‰ã€‚é€šè¿‡æœ‰æ•ˆè¯†åˆ«åé—¨æ ·æœ¬ï¼Œå¯ä»¥æå‡æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œé˜²æ­¢æ½œåœ¨çš„æ”»å‡»ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The use of unvetted third-party and internet data renders pre-trained models susceptible to backdoor attacks. Detecting backdoor samples is critical to prevent backdoor activation during inference or injection during training. However, existing detection methods often require the defender to have access to the poisoned models, extra clean samples, or significant computational resources to detect backdoor samples, limiting their practicality. To address this limitation, we propose a backdoor sample detection method based on perturbatio\textbf{N} discr\textbf{E}pancy consis\textbf{T}ency \textbf{E}valuation (\NETE). This is a novel detection method that can be used both pre-training and post-training phases. In the detection process, it only requires an off-the-shelf pre-trained model to compute the log probability of samples and an automated function based on a mask-filling strategy to generate perturbations. Our method is based on the interesting phenomenon that the change in perturbation discrepancy for backdoor samples is smaller than that for clean samples. Based on this phenomenon, we use curvature to measure the discrepancy in log probabilities between different perturbed samples and input samples, thereby evaluating the consistency of the perturbation discrepancy to determine whether the input sample is a backdoor sample. Experiments conducted on four typical backdoor attacks and five types of large language model backdoor attacks demonstrate that our detection strategy outperforms existing zero-shot black-box detection methods.

