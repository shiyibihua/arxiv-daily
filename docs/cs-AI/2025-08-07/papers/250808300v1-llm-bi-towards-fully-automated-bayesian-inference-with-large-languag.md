---
layout: default
title: LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models
---

# LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08300" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08300v1</a>
  <a href="https://arxiv.org/pdf/2508.08300.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08300v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08300v1', 'LLM-BI: Towards Fully Automated Bayesian Inference with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yongchao Huang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-07

**å¤‡æ³¨**: 6 pages

**DOI**: [10.5281/zenodo.16756724](https://doi.org/10.5281/zenodo.16756724)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM-BIä»¥å®ç°å…¨è‡ªåŠ¨è´å¶æ–¯æ¨æ–­**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è´å¶æ–¯æ¨æ–­` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–å»ºæ¨¡` `æ¦‚ç‡ç¼–ç¨‹` `ç»Ÿè®¡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è´å¶æ–¯æ¨æ–­çš„åº”ç”¨å—åˆ°å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶æŒ‡å®šçš„é™åˆ¶ï¼Œé€šå¸¸éœ€è¦ä¸“ä¸šçš„ç»Ÿè®¡çŸ¥è¯†ã€‚
2. æœ¬æ–‡æå‡ºLLM-BIï¼Œé€šè¿‡å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–è´å¶æ–¯æ¨æ–­è¿‡ç¨‹ï¼Œé™ä½äº†å¯¹ç»Ÿè®¡ä¸“ä¸šçŸ¥è¯†çš„ä¾èµ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMèƒ½å¤Ÿæœ‰æ•ˆå¼•å‡ºå…ˆéªŒåˆ†å¸ƒå¹¶æŒ‡å®šå®Œæ•´æ¨¡å‹ç»“æ„ï¼Œå±•ç¤ºäº†å…¶åœ¨è´å¶æ–¯å»ºæ¨¡ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è´å¶æ–¯æ¨æ–­çš„å¹¿æ³›åº”ç”¨é¢ä¸´ä¸€ä¸ªé‡è¦éšœç¢ï¼Œå³å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶çš„æŒ‡å®šï¼Œè¿™é€šå¸¸éœ€è¦ä¸“ä¸šçš„ç»Ÿè®¡çŸ¥è¯†ã€‚æœ¬æ–‡æ¢è®¨äº†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªåŠ¨åŒ–è¿™ä¸€è¿‡ç¨‹çš„å¯è¡Œæ€§ã€‚æˆ‘ä»¬æå‡ºäº†LLM-BIï¼ˆåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„è´å¶æ–¯æ¨æ–­ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªè‡ªåŠ¨åŒ–è´å¶æ–¯å·¥ä½œæµçš„æ¦‚å¿µæ€§ç®¡é“ã€‚ä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸¤é¡¹å®éªŒï¼Œé‡ç‚¹å…³æ³¨è´å¶æ–¯çº¿æ€§å›å½’ã€‚åœ¨å®éªŒä¸€ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†LLMèƒ½å¤ŸæˆåŠŸä»è‡ªç„¶è¯­è¨€ä¸­å¼•å‡ºå…ˆéªŒåˆ†å¸ƒã€‚åœ¨å®éªŒäºŒä¸­ï¼Œæˆ‘ä»¬è¡¨æ˜LLMå¯ä»¥ä»å•ä¸€é«˜å±‚æ¬¡é—®é¢˜æè¿°ä¸­æŒ‡å®šæ•´ä¸ªæ¨¡å‹ç»“æ„ï¼ŒåŒ…æ‹¬å…ˆéªŒå’Œä¼¼ç„¶ã€‚æˆ‘ä»¬çš„ç»“æœéªŒè¯äº†LLMåœ¨è‡ªåŠ¨åŒ–è´å¶æ–¯å»ºæ¨¡å…³é”®æ­¥éª¤ä¸­çš„æ½œåŠ›ï¼Œä¸ºæ¦‚ç‡ç¼–ç¨‹çš„è‡ªåŠ¨æ¨æ–­ç®¡é“æä¾›äº†å¯èƒ½æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è´å¶æ–¯æ¨æ–­ä¸­å…ˆéªŒåˆ†å¸ƒå’Œä¼¼ç„¶æŒ‡å®šçš„å›°éš¾ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦ä¸“ä¸šçš„ç»Ÿè®¡çŸ¥è¯†ï¼Œé™åˆ¶äº†å…¶å¹¿æ³›åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œè‡ªåŠ¨åŒ–è´å¶æ–¯æ¨æ–­çš„å…³é”®æ­¥éª¤ï¼Œé™ä½å¯¹ç”¨æˆ·ç»Ÿè®¡çŸ¥è¯†çš„è¦æ±‚ï¼Œä½¿å¾—éä¸“ä¸šäººå£«ä¹Ÿèƒ½è¿›è¡Œè´å¶æ–¯å»ºæ¨¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLM-BIçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯ä»è‡ªç„¶è¯­è¨€ä¸­æå–å…ˆéªŒåˆ†å¸ƒï¼Œå…¶æ¬¡æ˜¯ä»é«˜å±‚æ¬¡é—®é¢˜æè¿°ä¸­æ„å»ºå®Œæ•´çš„æ¨¡å‹ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåˆ©ç”¨LLMè‡ªåŠ¨åŒ–å…ˆéªŒå’Œä¼¼ç„¶çš„æŒ‡å®šè¿‡ç¨‹ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºç”¨æˆ·çš„ç»Ÿè®¡çŸ¥è¯†å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼ŒLLMçš„è®­ç»ƒæ•°æ®å’Œæ¨¡å‹å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿å…¶èƒ½å¤Ÿå‡†ç¡®ç†è§£å’Œç”Ÿæˆä¸è´å¶æ–¯æ¨æ–­ç›¸å…³çš„å†…å®¹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMæˆåŠŸä»è‡ªç„¶è¯­è¨€ä¸­å¼•å‡ºå…ˆéªŒåˆ†å¸ƒï¼Œå¹¶èƒ½å¤Ÿä»å•ä¸€é«˜å±‚æ¬¡é—®é¢˜æè¿°ä¸­æ„å»ºå®Œæ•´çš„è´å¶æ–¯æ¨¡å‹ç»“æ„ã€‚è¿™ä¸€è¿‡ç¨‹çš„è‡ªåŠ¨åŒ–æ˜¾è‘—æé«˜äº†å»ºæ¨¡æ•ˆç‡ï¼Œå±•ç¤ºäº†LLMåœ¨è´å¶æ–¯æ¨æ–­ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’Œç»Ÿè®¡åˆ†æç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©éä¸“ä¸šäººå£«æ›´å®¹æ˜“åœ°è¿›è¡Œè´å¶æ–¯æ¨æ–­ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶å’Œåº”ç”¨ã€‚æœªæ¥ï¼ŒLLM-BIæœ‰æœ›æˆä¸ºè‡ªåŠ¨åŒ–æ¦‚ç‡ç¼–ç¨‹çš„é‡è¦å·¥å…·ï¼Œé™ä½æŠ€æœ¯é—¨æ§›ï¼Œä¿ƒè¿›æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A significant barrier to the widespread adoption of Bayesian inference is the specification of prior distributions and likelihoods, which often requires specialized statistical expertise. This paper investigates the feasibility of using a Large Language Model (LLM) to automate this process. We introduce LLM-BI (Large Language Model-driven Bayesian Inference), a conceptual pipeline for automating Bayesian workflows. As a proof-of-concept, we present two experiments focused on Bayesian linear regression. In Experiment I, we demonstrate that an LLM can successfully elicit prior distributions from natural language. In Experiment II, we show that an LLM can specify the entire model structure, including both priors and the likelihood, from a single high-level problem description. Our results validate the potential of LLMs to automate key steps in Bayesian modeling, enabling the possibility of an automated inference pipeline for probabilistic programming.

