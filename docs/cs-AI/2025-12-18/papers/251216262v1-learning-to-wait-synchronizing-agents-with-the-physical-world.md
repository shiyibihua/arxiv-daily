---
layout: default
title: Learning to Wait: Synchronizing Agents with the Physical World
---

# Learning to Wait: Synchronizing Agents with the Physical World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16262" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16262v1</a>
  <a href="https://arxiv.org/pdf/2512.16262.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16262v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16262v1', 'Learning to Wait: Synchronizing Agents with the Physical World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifei She, Ping Zhang, He Liu, Yanmin Jia, Yang Jing, Zijun Liu, Peng Sun, Xiangbin Li, Xiaohe Hu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentç«¯æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œè§£å†³LLMåœ¨å¼‚æ­¥ç¯å¢ƒä¸­ä¸ç‰©ç†ä¸–ç•Œäº¤äº’çš„æ—¶å»¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Agentæ—¶é—´åŒæ­¥` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `å¼‚æ­¥ç¯å¢ƒ` `ä»£ç å³åŠ¨ä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°å®Agentä»»åŠ¡ä¸­ï¼ŒåŠ¨ä½œå®Œæˆå­˜åœ¨æ—¶å»¶ï¼Œå¯¼è‡´Agentä¸ç¯å¢ƒäº¤äº’å‡ºç°æ—¶é—´é—´éš”ï¼Œç°æœ‰ç¯å¢ƒä¾§è§£å†³æ–¹æ¡ˆå­˜åœ¨å¯æ‰©å±•æ€§æˆ–ä¸Šä¸‹æ–‡ç¨€é‡Šé—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºAgentç«¯æ–¹æ³•ï¼Œé€šè¿‡è®©LLMé¢„æµ‹ç­‰å¾…æ—¶é•¿ï¼ˆ`time.sleep(t)`ï¼‰ï¼Œä¸»åŠ¨å°†å…¶è®¤çŸ¥æ—¶é—´çº¿ä¸ç‰©ç†ä¸–ç•Œå¯¹é½ï¼Œå®ç°æ—¶é—´åŒæ­¥ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAgentèƒ½å¤Ÿç²¾ç¡®æ ¡å‡†å†…éƒ¨æ—¶é’Ÿï¼Œæœ€å°åŒ–æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼ŒéªŒè¯äº†æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›å¯¹äºå¼€æ”¾ç¯å¢ƒè‡ªä¸»è¿›åŒ–çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸åŒæ­¥é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸åŒï¼Œç°å®ä¸–ç•Œçš„Agentä»»åŠ¡é€šå¸¸æ¶‰åŠå…·æœ‰å¯å˜å»¶è¿Ÿçš„éé˜»å¡åŠ¨ä½œï¼Œä»è€Œåœ¨åŠ¨ä½œå‘èµ·å’Œå®Œæˆä¹‹é—´äº§ç”Ÿæ ¹æœ¬æ€§çš„â€œæ—¶é—´é—´éš”â€ã€‚ç°æœ‰çš„ç¯å¢ƒä¾§è§£å†³æ–¹æ¡ˆï¼Œå¦‚é˜»å¡åŒ…è£…å™¨æˆ–é¢‘ç¹è½®è¯¢ï¼Œè¦ä¹ˆé™åˆ¶äº†å¯æ‰©å±•æ€§ï¼Œè¦ä¹ˆç”¨å†—ä½™çš„è§‚å¯Ÿç¨€é‡Šäº†Agentçš„ä¸Šä¸‹æ–‡çª—å£ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§Agentç«¯æ–¹æ³•ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿä¸»åŠ¨å°†å…¶â€œè®¤çŸ¥æ—¶é—´çº¿â€ä¸ç‰©ç†ä¸–ç•Œå¯¹é½ã€‚é€šè¿‡å°†ä»£ç å³åŠ¨ä½œèŒƒå¼æ‰©å±•åˆ°æ—¶é—´åŸŸï¼ŒAgentåˆ©ç”¨è¯­ä¹‰å…ˆéªŒå’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥é¢„æµ‹ç²¾ç¡®çš„ç­‰å¾…æ—¶é•¿ï¼ˆ`time.sleep(t)`ï¼‰ï¼Œä»è€Œæœ‰æ•ˆåœ°ä¸å¼‚æ­¥ç¯å¢ƒåŒæ­¥ï¼Œè€Œæ— éœ€è¯¦å°½çš„æ£€æŸ¥ã€‚åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒAgentå¯ä»¥ç²¾ç¡®åœ°æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼Œä»è€ŒéªŒè¯äº†æ—¶é—´æ„ŸçŸ¥æ˜¯åœ¨å¼€æ”¾ç¯å¢ƒä¸­è‡ªä¸»è¿›åŒ–å¿…ä¸å¯å°‘çš„ã€å¯å­¦ä¹ çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°å®ä¸–ç•ŒAgentä»»åŠ¡ä¸­ï¼Œç”±äºåŠ¨ä½œæ‰§è¡Œå­˜åœ¨æ—¶å»¶ï¼Œå¯¼è‡´Agentä¸ç¯å¢ƒäº¤äº’å¼‚æ­¥çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚é˜»å¡åŒ…è£…å™¨å’Œé¢‘ç¹è½®è¯¢ï¼Œè¦ä¹ˆé™åˆ¶äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§ï¼Œè¦ä¹ˆå¼•å…¥äº†å¤§é‡çš„å†—ä½™è§‚å¯Ÿï¼Œç¨€é‡Šäº†Agentçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå½±å“å†³ç­–æ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯èµ‹äºˆAgentæ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿä¸»åŠ¨é¢„æµ‹å¹¶ç­‰å¾…åŠ¨ä½œå®Œæˆæ‰€éœ€çš„æ—¶é—´ï¼Œä»è€Œå®ç°ä¸å¼‚æ­¥ç¯å¢ƒçš„åŒæ­¥ã€‚é€šè¿‡è®©Agentå­¦ä¹ ä½•æ—¶ä»¥åŠç­‰å¾…å¤šä¹…ï¼Œé¿å…äº†ä¸å¿…è¦çš„è½®è¯¢å’Œé˜»å¡ï¼Œæé«˜äº†äº¤äº’æ•ˆç‡å’Œå†³ç­–è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡å°†ä»£ç å³åŠ¨ä½œèŒƒå¼æ‰©å±•åˆ°æ—¶é—´åŸŸï¼ŒAgenté€šè¿‡ç”ŸæˆåŒ…å«`time.sleep(t)`æŒ‡ä»¤çš„ä»£ç æ¥æ§åˆ¶ç­‰å¾…æ—¶é—´ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) Agentæ¥æ”¶ç¯å¢ƒè§‚æµ‹ï¼›2) Agentåˆ©ç”¨LLMç”ŸæˆåŒ…å«`time.sleep(t)`çš„åŠ¨ä½œä»£ç ï¼›3) æ‰§è¡ŒåŠ¨ä½œä»£ç ï¼ŒAgentè¿›å…¥ä¼‘çœ çŠ¶æ€ï¼›4) ä¼‘çœ ç»“æŸåï¼ŒAgentå†æ¬¡æ¥æ”¶ç¯å¢ƒè§‚æµ‹ï¼Œè¿›å…¥ä¸‹ä¸€è½®äº¤äº’ã€‚è®ºæ–‡åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥å¼•å¯¼LLMå­¦ä¹ æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ—¶é—´åŒæ­¥é—®é¢˜ä»ç¯å¢ƒä¾§è½¬ç§»åˆ°Agentä¾§ï¼Œèµ‹äºˆAgentä¸»åŠ¨æ§åˆ¶ç­‰å¾…æ—¶é—´çš„èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„è¢«åŠ¨ç­‰å¾…æˆ–é¢‘ç¹è½®è¯¢æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨Agentçš„è®¡ç®—èµ„æºï¼Œå¹¶å‡å°‘ä¸å¿…è¦çš„ç¯å¢ƒäº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨LLMä½œä¸ºAgentçš„å†³ç­–æ ¸å¿ƒï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼›2) é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æä¾›æ—¶é—´ç›¸å…³çš„ç¤ºä¾‹ï¼Œå¼•å¯¼LLMå­¦ä¹ é¢„æµ‹åˆé€‚çš„ç­‰å¾…æ—¶é—´ï¼›3) ä½¿ç”¨`time.sleep(t)`ä½œä¸ºæ§åˆ¶ç­‰å¾…æ—¶é—´çš„æŒ‡ä»¤ï¼Œç®€å•è€Œæœ‰æ•ˆï¼›4) åœ¨Kubernetesé›†ç¾¤æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œå®éªŒï¼ŒéªŒè¯æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„Agentç«¯æ—¶é—´åŒæ­¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—å‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿã€‚åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ç¯å¢ƒä¸­ï¼ŒAgentèƒ½å¤Ÿç²¾ç¡®æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œå®ç°ä¸å¼‚æ­¥ç¯å¢ƒçš„é«˜æ•ˆåŒæ­¥ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯¥æ–¹æ³•åœ¨æœ€å°åŒ–æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ä¸å¼‚æ­¥ç¯å¢ƒäº¤äº’çš„Agentç³»ç»Ÿï¼Œä¾‹å¦‚æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–è¿ç»´ã€æ™ºèƒ½å®¶å±…ç­‰ã€‚é€šè¿‡èµ‹äºˆAgentæ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¯ä»¥æé«˜å…¶åœ¨å¤æ‚ã€åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªä¸»æ€§å’Œæ•ˆç‡ï¼Œé™ä½äººå·¥å¹²é¢„çš„éœ€æ±‚ï¼Œå¹¶ä¸ºæ„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é çš„è‡ªåŠ¨åŒ–ç³»ç»Ÿå¥ å®šåŸºç¡€ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.

