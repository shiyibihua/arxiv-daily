---
layout: default
title: Learning to Wait: Synchronizing Agents with the Physical World
---

# Learning to Wait: Synchronizing Agents with the Physical World

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16262" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16262v1</a>
  <a href="https://arxiv.org/pdf/2512.16262.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16262v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16262v1', 'Learning to Wait: Synchronizing Agents with the Physical World')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifei She, Ping Zhang, He Liu, Yanmin Jia, Yang Jing, Zijun Liu, Peng Sun, Xiangbin Li, Xiaohe Hu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgentä¾§æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œè§£å†³LLMåœ¨å¼‚æ­¥ç¯å¢ƒä¸­çš„æ—¶åºè®¤çŸ¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ—¶é—´æ„ŸçŸ¥` `å¼‚æ­¥ç¯å¢ƒ` `Agent` `ä¸Šä¸‹æ–‡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†çœŸå®ä¸–ç•ŒAgentä»»åŠ¡æ—¶ï¼Œç”±äºåŠ¨ä½œå»¶è¿Ÿçš„ä¸ç¡®å®šæ€§ï¼Œå¯¼è‡´Agentä¸ç¯å¢ƒæ—¶åºä¸åŒæ­¥ï¼Œå½±å“æ•ˆç‡ã€‚
2. è®ºæ–‡æå‡ºAgentä¾§çš„æ—¶é—´åŒæ­¥æ–¹æ³•ï¼Œé€šè¿‡è®©LLMé¢„æµ‹ç­‰å¾…æ—¶é—´ï¼Œä¸»åŠ¨ä¸å¼‚æ­¥ç¯å¢ƒå¯¹é½è®¤çŸ¥æ—¶é—´çº¿ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼ŒéªŒè¯äº†Agentå­¦ä¹ æ—¶é—´æ„ŸçŸ¥çš„å¯è¡Œæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸åŒæ­¥é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ä¸åŒï¼Œç°å®ä¸–ç•Œçš„Agentä»»åŠ¡é€šå¸¸æ¶‰åŠå…·æœ‰å¯å˜å»¶è¿Ÿçš„éé˜»å¡åŠ¨ä½œï¼Œä»è€Œåœ¨åŠ¨ä½œå‘èµ·å’Œå®Œæˆä¹‹é—´äº§ç”Ÿæ ¹æœ¬æ€§çš„â€œæ—¶é—´å·®â€ã€‚ç°æœ‰çš„ç¯å¢ƒä¾§è§£å†³æ–¹æ¡ˆï¼Œå¦‚é˜»å¡åŒ…è£…å™¨æˆ–é¢‘ç¹è½®è¯¢ï¼Œè¦ä¹ˆé™åˆ¶äº†å¯æ‰©å±•æ€§ï¼Œè¦ä¹ˆç”¨å†—ä½™çš„è§‚å¯Ÿç¨€é‡Šäº†Agentçš„ä¸Šä¸‹æ–‡çª—å£ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§â€œAgentä¾§æ–¹æ³•â€ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰èƒ½å¤Ÿä¸»åŠ¨å°†å…¶â€œè®¤çŸ¥æ—¶é—´çº¿â€ä¸ç‰©ç†ä¸–ç•Œå¯¹é½ã€‚é€šè¿‡å°†ä»£ç å³åŠ¨ä½œèŒƒå¼æ‰©å±•åˆ°æ—¶é—´åŸŸï¼ŒAgentåˆ©ç”¨è¯­ä¹‰å…ˆéªŒå’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥é¢„æµ‹ç²¾ç¡®çš„ç­‰å¾…æ—¶é—´ï¼ˆ`time.sleep(t)`ï¼‰ï¼Œä»è€Œæœ‰æ•ˆåœ°ä¸å¼‚æ­¥ç¯å¢ƒåŒæ­¥ï¼Œè€Œæ— éœ€è¯¦å°½çš„æ£€æŸ¥ã€‚åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒAgentå¯ä»¥ç²¾ç¡®åœ°æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œä»¥æœ€å¤§é™åº¦åœ°å‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿï¼Œä»è€ŒéªŒè¯äº†æ—¶é—´æ„ŸçŸ¥æ˜¯åœ¨å¼€æ”¾ç¯å¢ƒä¸­è‡ªä¸»è¿›åŒ–å¿…ä¸å¯å°‘çš„ã€å¯å­¦ä¹ çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°å®ä¸–ç•Œçš„Agentä»»åŠ¡é€šå¸¸æ˜¯å¼‚æ­¥çš„ï¼ŒåŠ¨ä½œçš„å®Œæˆæ—¶é—´ä¸ç¡®å®šï¼Œè¿™å¯¼è‡´Agentçš„è®¤çŸ¥å’Œç‰©ç†ä¸–ç•Œä¹‹é—´å­˜åœ¨æ—¶é—´å·®ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆï¼Œå¦‚é˜»å¡å¼ç­‰å¾…æˆ–é¢‘ç¹è½®è¯¢ï¼Œè¦ä¹ˆé™åˆ¶äº†Agentçš„å¹¶å‘èƒ½åŠ›ï¼Œè¦ä¹ˆå¼•å…¥äº†å¤§é‡çš„å†—ä½™ä¿¡æ¯ï¼Œé™ä½äº†æ•ˆç‡ã€‚å› æ­¤ï¼Œå¦‚ä½•è®©Agentåœ¨å¼‚æ­¥ç¯å¢ƒä¸­é«˜æ•ˆåœ°æ‰§è¡Œä»»åŠ¡æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®©Agentå…·å¤‡æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œé€šè¿‡é¢„æµ‹åŠ¨ä½œçš„å®Œæˆæ—¶é—´ï¼Œä¸»åŠ¨åœ°ä¸ç¯å¢ƒè¿›è¡ŒåŒæ­¥ã€‚å…·ä½“æ¥è¯´ï¼ŒAgenté€šè¿‡å­¦ä¹ æ¥é¢„æµ‹åˆé€‚çš„ç­‰å¾…æ—¶é—´ï¼ˆ`time.sleep(t)`ï¼‰ï¼Œä»è€Œé¿å…ä¸å¿…è¦çš„ç­‰å¾…æˆ–è¿‡æ—©åœ°è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œã€‚è¿™ç§Agentä¾§çš„æ–¹æ³•é¿å…äº†å¯¹ç¯å¢ƒçš„ä¿®æ”¹ï¼Œå…·æœ‰æ›´å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŸºäºCode-as-ActionèŒƒå¼ï¼Œå°†ç­‰å¾…æ—¶é—´é¢„æµ‹è§†ä¸ºä¸€ä¸ªä»£ç ç”Ÿæˆä»»åŠ¡ã€‚Agenté¦–å…ˆæ¥æ”¶ç¯å¢ƒçš„è§‚å¯Ÿï¼Œç„¶ååˆ©ç”¨LLMç”ŸæˆåŒ…å«`time.sleep(t)`çš„åŠ¨ä½œä»£ç ã€‚LLMé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥å­¦ä¹ å¦‚ä½•æ ¹æ®ç¯å¢ƒçŠ¶æ€é¢„æµ‹åˆé€‚çš„ç­‰å¾…æ—¶é—´ã€‚Agentæ‰§è¡Œç”Ÿæˆçš„ä»£ç ï¼Œå¹¶åœ¨ç­‰å¾…æ—¶é—´ç»“æŸåæ¥æ”¶æ–°çš„è§‚å¯Ÿï¼Œä»è€Œå½¢æˆä¸€ä¸ªé—­ç¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›èµ‹äºˆAgentæœ¬èº«ï¼Œè€Œä¸æ˜¯ä¾èµ–äºç¯å¢ƒçš„åŒæ­¥æœºåˆ¶ã€‚é€šè¿‡è®©Agentå­¦ä¹ é¢„æµ‹ç­‰å¾…æ—¶é—´ï¼Œå®ç°äº†Agentä¸å¼‚æ­¥ç¯å¢ƒçš„æœ‰æ•ˆåŒæ­¥ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç¯å¢ƒçš„ä¾µå…¥å¼ä¿®æ”¹ï¼Œå…·æœ‰æ›´å¥½çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Code-as-ActionèŒƒå¼ï¼Œå°†ç­‰å¾…æ—¶é—´é¢„æµ‹è½¬åŒ–ä¸ºä»£ç ç”Ÿæˆä»»åŠ¡ï¼›2) åˆ©ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰æ¥æé«˜LLMçš„é¢„æµ‹ç²¾åº¦ï¼›3) è®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±Agentå­¦ä¹ ç²¾ç¡®çš„ç­‰å¾…æ—¶é—´ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16262v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡æ‹Ÿçš„Kubernetesé›†ç¾¤ä¸­èƒ½å¤Ÿæœ‰æ•ˆåœ°å‡å°‘æŸ¥è¯¢å¼€é”€å’Œæ‰§è¡Œå»¶è¿Ÿã€‚Agentèƒ½å¤Ÿç²¾ç¡®åœ°æ ¡å‡†å…¶å†…éƒ¨æ—¶é’Ÿï¼Œä»è€Œé¿å…ä¸å¿…è¦çš„ç­‰å¾…æˆ–è¿‡æ—©åœ°è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦Agentä¸å¼‚æ­¥ç¯å¢ƒäº¤äº’çš„åœºæ™¯ï¼Œä¾‹å¦‚æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨åŒ–è¿ç»´ã€æ™ºèƒ½å®¶å±…ç­‰ã€‚é€šè¿‡è®©Agentå…·å¤‡æ—¶é—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œå¯ä»¥æé«˜ä»»åŠ¡æ‰§è¡Œæ•ˆç‡ï¼Œé™ä½èµ„æºæ¶ˆè€—ï¼Œå¹¶å®ç°æ›´æ™ºèƒ½åŒ–çš„è‡ªä¸»å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨Agentåœ¨å¼€æ”¾ç¯å¢ƒä¸­å®ç°æ›´é«˜çº§åˆ«çš„è‡ªä¸»è¿›åŒ–ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.

