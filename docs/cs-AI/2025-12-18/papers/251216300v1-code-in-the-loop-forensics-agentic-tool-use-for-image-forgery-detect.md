---
layout: default
title: Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection
---

# Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16300" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16300v1</a>
  <a href="https://arxiv.org/pdf/2512.16300.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16300v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16300v1', 'Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fanrui Zhang, Qiang Zhang, Sizhuo Zhou, Jianwen Sun, Chuanhao Li, Jiaxin Ai, Yukang Feng, Yujie Zhang, Wenjie Li, Zizhen Li, Yifan Chang, Jiawei Liu, Kaipeng Zhang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: 11 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºForenAgentä»¥è§£å†³å›¾åƒä¼ªé€ æ£€æµ‹ä¸­çš„ä¿¡æ¯æµä¸ç»Ÿä¸€é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾åƒä¼ªé€ æ£€æµ‹` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `åŠ¨æ€æ¨ç†å¾ªç¯` `å·¥å…·äº¤äº’` `å†·å¯åŠ¨` `å¼ºåŒ–å¾®è°ƒ` `æ•°æ®é›†æ„å»º` `åæ€æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾åƒä¼ªé€ æ£€æµ‹æ–¹æ³•åœ¨ä¿¡æ¯æµçš„ç»Ÿä¸€æ€§å’Œäº¤äº’å»ºæ¨¡ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆç»“åˆä½çº§ç‰¹å¾ä¸é«˜çº§è¯­ä¹‰çŸ¥è¯†ã€‚
2. æœ¬æ–‡æå‡ºForenAgentæ¡†æ¶ï¼Œé€šè¿‡å¤šè½®äº¤äº’ä½¿MLLMsèƒ½å¤Ÿç”Ÿæˆå’Œä¼˜åŒ–ä½çº§å·¥å…·ï¼Œä»è€Œå®ç°çµæ´»çš„ä¼ªé€ æ£€æµ‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒForenAgentåœ¨å¤æ‚çš„å›¾åƒä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…·å¤‡å·¥å…·ä½¿ç”¨èƒ½åŠ›å’Œåæ€æ¨ç†èƒ½åŠ›ï¼Œæ¨åŠ¨äº†è¯¥é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å›¾åƒä¼ªé€ æ£€æµ‹æ–¹æ³•è¦ä¹ˆåˆ©ç”¨ä½çº§ã€æ— è¯­ä¹‰çš„ä¼ªé€ ç‰¹å¾ï¼Œè¦ä¹ˆä¾èµ–äºå…·æœ‰é«˜çº§è¯­ä¹‰çŸ¥è¯†çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ã€‚è¿™ä¸¤ç§ä¿¡æ¯æµåœ¨èŒƒå¼å’Œæ¨ç†ä¸Šé«˜åº¦å¼‚è´¨ï¼Œä½¿å¾—ç°æœ‰æ–¹æ³•éš¾ä»¥ç»Ÿä¸€æˆ–æœ‰æ•ˆå»ºæ¨¡å®ƒä»¬çš„è·¨å±‚æ¬¡äº¤äº’ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ForenAgentï¼Œä¸€ä¸ªå¤šè½®äº¤äº’çš„å›¾åƒä¼ªé€ æ£€æµ‹æ¡†æ¶ï¼Œèƒ½å¤Ÿè‡ªä¸»ç”Ÿæˆã€æ‰§è¡Œå¹¶è¿­ä»£ä¼˜åŒ–åŸºäºPythonçš„ä½çº§å·¥å…·ï¼Œä»è€Œå®ç°æ›´çµæ´»å’Œå¯è§£é‡Šçš„ä¼ªé€ åˆ†æã€‚ForenAgenté‡‡ç”¨äº†ç»“åˆå†·å¯åŠ¨å’Œå¼ºåŒ–å¾®è°ƒçš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œé€æ­¥å¢å¼ºå…¶å·¥å…·äº¤äº’èƒ½åŠ›å’Œæ¨ç†é€‚åº”æ€§ã€‚é€šè¿‡æ„å»ºFABenchæ•°æ®é›†ï¼Œå®éªŒè¡¨æ˜ForenAgentåœ¨ä½çº§å·¥å…·çš„è¾…åŠ©ä¸‹ï¼Œå±•ç°å‡ºå·¥å…·ä½¿ç”¨èƒ½åŠ›å’Œåæ€æ¨ç†èƒ½åŠ›ï¼Œä¸ºé€šç”¨å›¾åƒä¼ªé€ æ£€æµ‹å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾åƒä¼ªé€ æ£€æµ‹æ–¹æ³•åœ¨ä½çº§ç‰¹å¾ä¸é«˜çº§è¯­ä¹‰çŸ¥è¯†ä¹‹é—´çš„å¼‚è´¨æ€§é—®é¢˜ï¼Œå¯¼è‡´ä¿¡æ¯æµéš¾ä»¥ç»Ÿä¸€å’Œäº¤äº’å»ºæ¨¡çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šForenAgentæ¡†æ¶é€šè¿‡å¤šè½®äº¤äº’ï¼Œä½¿å¾—å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹èƒ½å¤Ÿè‡ªä¸»ç”Ÿæˆã€æ‰§è¡Œå’Œä¼˜åŒ–ä½çº§å·¥å…·ï¼Œä»è€Œå®ç°æ›´çµæ´»å’Œå¯è§£é‡Šçš„ä¼ªé€ åˆ†æã€‚è¯¥è®¾è®¡çµæ„Ÿæ¥æºäºäººç±»çš„æ¨ç†è¿‡ç¨‹ï¼Œå¼ºè°ƒåŠ¨æ€æ¨ç†å¾ªç¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šForenAgenté‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬å†·å¯åŠ¨å’Œå¼ºåŒ–å¾®è°ƒï¼Œå¢å¼ºå·¥å…·äº¤äº’èƒ½åŠ›å’Œæ¨ç†é€‚åº”æ€§ã€‚åŠ¨æ€æ¨ç†å¾ªç¯åŒ…å«å…¨çƒæ„ŸçŸ¥ã€å±€éƒ¨èšç„¦ã€è¿­ä»£æ¢æµ‹å’Œæ•´ä½“è£å†³ï¼Œä½œä¸ºæ•°æ®é‡‡æ ·ç­–ç•¥å’Œä»»åŠ¡å¯¹é½è¿‡ç¨‹å¥–åŠ±çš„å®ä¾‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†åŠ¨æ€æ¨ç†å¾ªç¯å’Œå¤šè½®äº¤äº’æœºåˆ¶ï¼Œä½¿å¾—ä½çº§å·¥å…·ä¸é«˜çº§è¯­ä¹‰çŸ¥è¯†èƒ½å¤Ÿæœ‰æ•ˆç»“åˆï¼Œæå‡äº†å›¾åƒä¼ªé€ æ£€æµ‹çš„çµæ´»æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒFABenchæ•°æ®é›†çš„æ„å»ºæä¾›äº†100kå¼ å›¾åƒå’Œçº¦200kä¸ªä»£ç†äº¤äº’é—®ç­”å¯¹ï¼Œç¡®ä¿äº†ç³»ç»Ÿçš„ç³»ç»Ÿæ€§è®­ç»ƒå’Œè¯„ä¼°ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16300v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16300v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16300v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒForenAgentåœ¨å›¾åƒä¼ªé€ æ£€æµ‹ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨ä½çº§å·¥å…·çš„è¾…åŠ©ä¸‹ï¼Œè¡¨ç°å‡ºå·¥å…·ä½¿ç”¨èƒ½åŠ›å’Œåæ€æ¨ç†èƒ½åŠ›ã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œä½†å®éªŒè¡¨æ˜å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºé€šç”¨å›¾åƒä¼ªé€ æ£€æµ‹æä¾›äº†æ–°çš„å¯èƒ½æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°å­—å›¾åƒå–è¯ã€ç¤¾äº¤åª’ä½“å†…å®¹éªŒè¯ä»¥åŠæ–°é—»æŠ¥é“çš„çœŸå®æ€§æ£€æŸ¥ç­‰ã€‚é€šè¿‡æå‡å›¾åƒä¼ªé€ æ£€æµ‹çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ï¼ŒForenAgentèƒ½å¤Ÿåœ¨æ‰“å‡»è™šå‡ä¿¡æ¯å’Œä¿æŠ¤æ•°å­—å†…å®¹çš„çœŸå®æ€§æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ï¼Œå…·æœ‰æ˜¾è‘—çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing image forgery detection (IFD) methods either exploit low-level, semantics-agnostic artifacts or rely on multimodal large language models (MLLMs) with high-level semantic knowledge. Although naturally complementary, these two information streams are highly heterogeneous in both paradigm and reasoning, making it difficult for existing methods to unify them or effectively model their cross-level interactions. To address this gap, we propose ForenAgent, a multi-round interactive IFD framework that enables MLLMs to autonomously generate, execute, and iteratively refine Python-based low-level tools around the detection objective, thereby achieving more flexible and interpretable forgery analysis. ForenAgent follows a two-stage training pipeline combining Cold Start and Reinforcement Fine-Tuning to enhance its tool interaction capability and reasoning adaptability progressively. Inspired by human reasoning, we design a dynamic reasoning loop comprising global perception, local focusing, iterative probing, and holistic adjudication, and instantiate it as both a data-sampling strategy and a task-aligned process reward. For systematic training and evaluation, we construct FABench, a heterogeneous, high-quality agent-forensics dataset comprising 100k images and approximately 200k agent-interaction question-answer pairs. Experiments show that ForenAgent exhibits emergent tool-use competence and reflective reasoning on challenging IFD tasks when assisted by low-level tools, charting a promising route toward general-purpose IFD. The code will be released after the review process is completed.

