---
layout: default
title: Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error
---

# Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16750" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16750v1</a>
  <a href="https://arxiv.org/pdf/2512.16750.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16750v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16750v1', 'Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Claudia Vale Oliveira, Nelson Zagalo, Filipe Silva, Anabela Brandao, Syeda Faryal Hussain Khurrum, Joaquim Santos

**åˆ†ç±»**: cs.HC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: 19 pages, 2 tables, 77 references, 6 appendices

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMä¸äººç±»äº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„å…±å»ºæœºåˆ¶ï¼Œå¼ºè°ƒè¯„ä¼°çš„è§£é‡Šæ€§è§†è§’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæœºäº¤äº’` `è®¤çŸ¥é”™è¯¯` `å¯ä¿¡åº¦` `è¯„ä¼°æ¡†æ¶` `è§£é‡Šæ€§åˆ¤æ–­` `è®¤çŸ¥æ¼‚ç§»` `éªŒè¯è´Ÿæ‹…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMé”™è¯¯åˆ†æä¾§é‡é¢„æµ‹æŒ‡æ ‡ï¼Œå¿½ç•¥äº†å…¶å¯¹äººç±»åˆ¤æ–­çš„è§£é‡Šæ€§å½±å“ï¼Œå¯¼è‡´å¯¹äººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„ç†è§£ä¸è¶³ã€‚
2. è¯¥ç ”ç©¶å°†LLMé”™è¯¯è§†ä¸ºäººæœºäº¤äº’ä¸­å…±åŒæ„å»ºçš„è®¤çŸ¥å¤±è´¥ï¼Œå¼ºè°ƒæ¨¡å‹ç”Ÿæˆçš„å¯ä¿¡åº¦ä¸äººç±»è§£é‡Šæ€§åˆ¤æ–­ä¹‹é—´çš„å…³ç³»ã€‚
3. é€šè¿‡å¤šè½®è¯„ä¼°ï¼Œæ­ç¤ºäº†LLMé”™è¯¯ä»é¢„æµ‹æ€§å‘è§£é‡Šæ€§è½¬å˜ï¼Œä»¥åŠäººç±»è¯„ä¼°ä¸­å‡ºç°çš„éªŒè¯è´Ÿæ‹…å’Œè®¤çŸ¥æ¼‚ç§»ç°è±¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¥ç›Šæˆä¸ºæ—¥å¸¸æ¨ç†ä¸­çš„è®¤çŸ¥ä¼™ä¼´ï¼Œä½†å¯¹å…¶é”™è¯¯çš„åˆ†æä¸»è¦é›†ä¸­åœ¨é¢„æµ‹æŒ‡æ ‡ä¸Šï¼Œè€Œéå…¶å¯¹äººç±»åˆ¤æ–­çš„è§£é‡Šæ€§å½±å“ã€‚æœ¬ç ”ç©¶è€ƒå¯Ÿäº†åœ¨äººæœºäº¤äº’ä¸­ï¼Œä¸åŒå½¢å¼çš„è®¤çŸ¥å¤±è´¥å¦‚ä½•äº§ç”Ÿã€è¢«æ©ç›–å’Œè¢«å®¹å¿ã€‚è¿™é‡Œçš„å¤±è´¥è¢«ç†è§£ä¸ºä¸€ç§å…³ç³»ç ´è£‚ï¼Œç”±æ¨¡å‹ç”Ÿæˆçš„å¯ä¿¡åº¦å’Œäººç±»çš„è§£é‡Šæ€§åˆ¤æ–­å…±åŒå¡‘é€ ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸‰è½®å¤šLLMè¯„ä¼°ï¼Œé‡‡ç”¨è·¨å­¦ç§‘ä»»åŠ¡å’Œé€æ­¥åŒºåˆ†çš„è¯„ä¼°æ¡†æ¶ï¼Œè§‚å¯Ÿè¯„ä¼°è€…å¦‚ä½•ä»è¯­è¨€ã€è®¤çŸ¥å’Œå¯ä¿¡åº¦ç»´åº¦è§£é‡Šæ¨¡å‹å“åº”ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMçš„é”™è¯¯ä»é¢„æµ‹æ€§è½¬å‘è§£é‡Šæ€§ï¼Œè¯­è¨€æµç•…æ€§ã€ç»“æ„è¿è´¯æ€§å’Œè¡¨é¢ä¸Šå¯ä¿¡çš„å¼•ç”¨æ©ç›–äº†æ›´æ·±å±‚æ¬¡çš„æ„ä¹‰æ‰­æ›²ã€‚è¯„ä¼°è€…ç»å¸¸æ··æ·†æ­£ç¡®æ€§ã€ç›¸å…³æ€§ã€åå·®ã€ä¾æ®å’Œä¸€è‡´æ€§ç­‰æ ‡å‡†ï¼Œè¡¨æ˜äººç±»åˆ¤æ–­å°†åˆ†æåŒºåˆ†ç®€åŒ–ä¸ºå—å½¢å¼å’Œæµç•…æ€§å½±å“çš„ç›´è§‰å¯å‘å¼ã€‚åœ¨å„è½®è¯„ä¼°ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ç³»ç»Ÿçš„éªŒè¯è´Ÿæ‹…å’Œè®¤çŸ¥æ¼‚ç§»ã€‚éšç€ä»»åŠ¡å˜å¾—æ›´åŠ å¯†é›†ï¼Œè¯„ä¼°è€…è¶Šæ¥è¶Šä¾èµ–è¡¨é¢çº¿ç´¢ï¼Œå…è®¸é”™è¯¯ä½†å½¢å¼è‰¯å¥½çš„ç­”æ¡ˆè¢«è®¤ä¸ºæ˜¯å¯ä¿¡çš„ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé”™è¯¯ä¸ä»…ä»…æ˜¯æ¨¡å‹è¡Œä¸ºçš„å±æ€§ï¼Œè€Œæ˜¯ç”Ÿæˆçš„å¯ä¿¡åº¦å’Œäººç±»è§£é‡Šæ€§æ·å¾„å…±åŒæ„å»ºçš„ç»“æœã€‚å› æ­¤ï¼Œç†è§£AIçš„è®¤çŸ¥å¤±è´¥éœ€è¦å°†è¯„ä¼°é‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªå…³ç³»è§£é‡Šè¿‡ç¨‹ï¼Œå…¶ä¸­ç³»ç»Ÿå¤±è´¥å’Œäººç±»æ ¡å‡†é”™è¯¯ä¹‹é—´çš„ç•Œé™å˜å¾—æ¨¡ç³Šã€‚è¯¥ç ”ç©¶ä¸ºLLMè¯„ä¼°ã€æ•°å­—ç´ å…»å’Œå¯ä¿¡èµ–çš„äººæœºé€šä¿¡è®¾è®¡æä¾›äº†å¯ç¤ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é”™è¯¯è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨é¢„æµ‹å‡†ç¡®ç‡ç­‰æŒ‡æ ‡ä¸Šï¼Œå¿½ç•¥äº†LLMçš„è¾“å‡ºå¦‚ä½•å½±å“äººç±»çš„åˆ¤æ–­å’Œè®¤çŸ¥ã€‚è¿™ç§è¯„ä¼°æ–¹å¼æ— æ³•å……åˆ†ç†è§£äººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„äº§ç”Ÿæœºåˆ¶ï¼Œå°¤å…¶æ˜¯åœ¨LLMè¾“å‡ºå…·æœ‰è¡¨é¢å¯ä¿¡åº¦çš„æƒ…å†µä¸‹ï¼Œäººç±»å¯èƒ½ä¼šå—åˆ°è¯¯å¯¼ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹äººç±»å¦‚ä½•è§£é‡Šå’Œå®¹å¿LLMé”™è¯¯çš„æ·±å…¥ç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMçš„é”™è¯¯è§†ä¸ºä¸€ç§â€œå…±å»ºâ€çš„ç°è±¡ï¼Œå³é”™è¯¯å¹¶éä»…ä»…æ˜¯æ¨¡å‹è‡ªèº«çš„å±æ€§ï¼Œè€Œæ˜¯æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ä¸äººç±»çš„è§£é‡Šæ€§åˆ¤æ–­ç›¸äº’ä½œç”¨çš„ç»“æœã€‚ç ”ç©¶å¼ºè°ƒäº†â€œå¯ä¿¡åº¦â€ï¼ˆplausibilityï¼‰åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œè®¤ä¸ºLLMç”Ÿæˆçš„è¡¨é¢ä¸Šåˆç†çš„å†…å®¹å¯èƒ½ä¼šæ©ç›–æ·±å±‚æ¬¡çš„é”™è¯¯ï¼Œä»è€Œå½±å“äººç±»çš„åˆ¤æ–­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸€ç§ä¸‰è½®å¤šLLMè¯„ä¼°æ¡†æ¶ï¼Œæ¶‰åŠè·¨å­¦ç§‘ä»»åŠ¡ã€‚æ¯ä¸€è½®è¯„ä¼°éƒ½ä½¿ç”¨ä¸åŒçš„è¯„ä¼°æ¡†æ¶ï¼Œè¿™äº›æ¡†æ¶åœ¨è¯­è¨€ã€è®¤çŸ¥å’Œå¯ä¿¡åº¦ç»´åº¦ä¸Šé€æ­¥åŒºåˆ†ã€‚è¯„ä¼°è€…éœ€è¦å¯¹LLMçš„å“åº”è¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶äººå‘˜è§‚å¯Ÿè¯„ä¼°è€…å¦‚ä½•è§£é‡Šè¿™äº›å“åº”ï¼Œä»¥åŠåœ¨ä¸åŒä»»åŠ¡å¯†åº¦ä¸‹ï¼Œè¯„ä¼°è€…çš„åˆ¤æ–­æ ‡å‡†å¦‚ä½•å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶æœ€é‡è¦çš„åˆ›æ–°åœ¨äºå…¶å¯¹LLMé”™è¯¯è¯„ä¼°çš„è§†è§’è½¬å˜ã€‚å®ƒä¸å†å°†é”™è¯¯è§†ä¸ºæ¨¡å‹è‡ªèº«çš„å­¤ç«‹é—®é¢˜ï¼Œè€Œæ˜¯å°†å…¶è§†ä¸ºäººæœºäº¤äº’ä¸­å…±åŒæ„å»ºçš„è®¤çŸ¥å¤±è´¥ã€‚è¿™ç§è§†è§’å¼ºè°ƒäº†äººç±»çš„è§£é‡Šæ€§åˆ¤æ–­åœ¨é”™è¯¯äº§ç”Ÿè¿‡ç¨‹ä¸­çš„ä½œç”¨ï¼Œå¹¶æ­ç¤ºäº†LLMç”Ÿæˆçš„å¯ä¿¡åº¦å¦‚ä½•å½±å“äººç±»çš„åˆ¤æ–­ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤šè½®è¯„ä¼°ï¼Œä»¥ä¾¿è§‚å¯Ÿè¯„ä¼°è€…åˆ¤æ–­æ ‡å‡†éšä»»åŠ¡å¯†åº¦å˜åŒ–çš„è¶‹åŠ¿ï¼›2) è·¨å­¦ç§‘ä»»åŠ¡ï¼Œä»¥è€ƒå¯ŸLLMåœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ï¼›3) é€æ­¥åŒºåˆ†çš„è¯„ä¼°æ¡†æ¶ï¼Œä»¥æ›´ç»†è‡´åœ°åˆ†æLLMçš„é”™è¯¯ç±»å‹å’Œäººç±»çš„åˆ¤æ–­æ ‡å‡†ã€‚ç ”ç©¶è¿˜å…³æ³¨äº†è¯„ä¼°è€…åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°çš„â€œéªŒè¯è´Ÿæ‹…â€å’Œâ€œè®¤çŸ¥æ¼‚ç§»â€ç°è±¡ï¼Œå³éšç€ä»»åŠ¡å˜å¾—æ›´åŠ å¯†é›†ï¼Œè¯„ä¼°è€…è¶Šæ¥è¶Šä¾èµ–è¡¨é¢çº¿ç´¢ï¼Œä»è€Œæ›´å®¹æ˜“æ¥å—é”™è¯¯çš„ç­”æ¡ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼ŒLLMé”™è¯¯ä¼šä»é¢„æµ‹æ€§é”™è¯¯è½¬å˜ä¸ºè§£é‡Šæ€§é”™è¯¯ï¼Œå³è¡¨é¢æµç•…å’Œè¿è´¯çš„å›ç­”å¯èƒ½æ©ç›–æ·±å±‚å«ä¹‰çš„æ‰­æ›²ã€‚è¯„ä¼°è€…åœ¨ä»»åŠ¡å¯†åº¦å¢åŠ æ—¶ï¼Œä¼šæ›´å¤šä¾èµ–è¡¨é¢çº¿ç´¢ï¼Œå¯¼è‡´é”™è¯¯ç­”æ¡ˆè¢«æ¥å—ã€‚è¿™äº›ç»“æœå¼ºè°ƒäº†è¯„ä¼°LLMæ—¶ï¼Œéœ€è¦å…³æ³¨äººç±»çš„è§£é‡Šæ€§åˆ¤æ–­ï¼Œè€Œä¸ä»…ä»…æ˜¯æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºLLMè¯„ä¼°ä½“ç³»çš„æ”¹è¿›ï¼Œæå‡æ•°å­—ç´ å…»æ•™è‚²ï¼Œå¹¶æŒ‡å¯¼æ›´å€¼å¾—ä¿¡èµ–çš„äººæœºäº¤äº’ç³»ç»Ÿè®¾è®¡ã€‚é€šè¿‡ç†è§£LLMé”™è¯¯çš„å…±å»ºæœºåˆ¶ï¼Œå¯ä»¥å¼€å‘æ›´æœ‰æ•ˆçš„è¯„ä¼°æ–¹æ³•ï¼Œå¸®åŠ©ç”¨æˆ·è¯†åˆ«å’Œé¿å…LLMå¸¦æ¥çš„è®¤çŸ¥åå·®ï¼Œä»è€Œä¿ƒè¿›è´Ÿè´£ä»»çš„AIåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used as epistemic partners in everyday reasoning, yet their errors remain predominantly analyzed through predictive metrics rather than through their interpretive effects on human judgment. This study examines how different forms of epistemic failure emerge, are masked, and are tolerated in human AI interaction, where failure is understood as a relational breakdown shaped by model-generated plausibility and human interpretive judgment. We conducted a three round, multi LLM evaluation using interdisciplinary tasks and progressively differentiated assessment frameworks to observe how evaluators interpret model responses across linguistic, epistemic, and credibility dimensions. Our findings show that LLM errors shift from predictive to hermeneutic forms, where linguistic fluency, structural coherence, and superficially plausible citations conceal deeper distortions of meaning. Evaluators frequently conflated criteria such as correctness, relevance, bias, groundedness, and consistency, indicating that human judgment collapses analytical distinctions into intuitive heuristics shaped by form and fluency. Across rounds, we observed a systematic verification burden and cognitive drift. As tasks became denser, evaluators increasingly relied on surface cues, allowing erroneous yet well formed answers to pass as credible. These results suggest that error is not solely a property of model behavior but a co-constructed outcome of generative plausibility and human interpretive shortcuts. Understanding AI epistemic failure therefore requires reframing evaluation as a relational interpretive process, where the boundary between system failure and human miscalibration becomes porous. The study provides implications for LLM assessment, digital literacy, and the design of trustworthy human AI communication.

