---
layout: default
title: Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error
---

# Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16750" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16750v1</a>
  <a href="https://arxiv.org/pdf/2512.16750.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16750v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16750v1', 'Plausibility as Failure: How LLMs and Humans Co-Construct Epistemic Error')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Claudia Vale Oliveira, Nelson Zagalo, Filipe Silva, Anabela Brandao, Syeda Faryal Hussain Khurrum, Joaquim Santos

**åˆ†ç±»**: cs.HC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: 19 pages, 2 tables, 77 references, 6 appendices

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMä¸äººç±»äº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„å…±å»ºæœºåˆ¶ï¼Œå¼ºè°ƒè¯„ä¼°çš„è§£é‡Šæ€§è§†è§’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººæœºäº¤äº’` `è®¤çŸ¥é”™è¯¯` `å¯ä¿¡åº¦` `è§£é‡Šæ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMé”™è¯¯åˆ†æä¾§é‡äºé¢„æµ‹æŒ‡æ ‡ï¼Œå¿½ç•¥äº†å…¶å¯¹äººç±»åˆ¤æ–­çš„è§£é‡Šæ€§å½±å“ï¼Œå¯¼è‡´å¯¹äººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„ç†è§£ä¸è¶³ã€‚
2. è¯¥ç ”ç©¶å°†LLMé”™è¯¯è§†ä¸ºä¸€ç§å…³ç³»ç ´è£‚ï¼Œç”±æ¨¡å‹ç”Ÿæˆçš„å¯ä¿¡åº¦å’Œäººç±»çš„è§£é‡Šæ€§åˆ¤æ–­å…±åŒå¡‘é€ ï¼Œå¼ºè°ƒè¯„ä¼°çš„è§£é‡Šæ€§è§†è§’ã€‚
3. é€šè¿‡å¤šè½®è¯„ä¼°å‘ç°ï¼ŒLLMé”™è¯¯ä¼šä»é¢„æµ‹å½¢å¼è½¬å˜ä¸ºè§£é‡Šå½¢å¼ï¼Œä¸”äººç±»è¯„ä¼°æ˜“å—è¡¨é¢çº¿ç´¢å½±å“ï¼Œå¯¼è‡´è®¤çŸ¥æ¼‚ç§»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¥ç›Šæˆä¸ºæ—¥å¸¸æ¨ç†ä¸­çš„è®¤çŸ¥ä¼™ä¼´ï¼Œä½†å¯¹å…¶é”™è¯¯çš„åˆ†æä¸»è¦é›†ä¸­åœ¨é¢„æµ‹æŒ‡æ ‡ä¸Šï¼Œè€Œéå…¶å¯¹äººç±»åˆ¤æ–­çš„è§£é‡Šæ€§å½±å“ã€‚æœ¬ç ”ç©¶è€ƒå¯Ÿäº†åœ¨äººæœºäº¤äº’ä¸­ï¼Œä¸åŒå½¢å¼çš„è®¤çŸ¥å¤±è´¥å¦‚ä½•äº§ç”Ÿã€è¢«æ©ç›–å’Œè¢«å®¹å¿ã€‚è¿™é‡Œçš„å¤±è´¥è¢«ç†è§£ä¸ºä¸€ç§å…³ç³»ç ´è£‚ï¼Œç”±æ¨¡å‹ç”Ÿæˆçš„å¯ä¿¡åº¦å’Œäººç±»çš„è§£é‡Šæ€§åˆ¤æ–­å…±åŒå¡‘é€ ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸‰è½®å¤šLLMè¯„ä¼°ï¼Œä½¿ç”¨è·¨å­¦ç§‘ä»»åŠ¡å’Œé€æ­¥åŒºåˆ†çš„è¯„ä¼°æ¡†æ¶ï¼Œè§‚å¯Ÿè¯„ä¼°è€…å¦‚ä½•è§£é‡Šæ¨¡å‹åœ¨è¯­è¨€ã€è®¤çŸ¥å’Œå¯ä¿¡åº¦ç»´åº¦ä¸Šçš„å“åº”ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒLLMçš„é”™è¯¯ä»é¢„æµ‹å½¢å¼è½¬å˜ä¸ºè§£é‡Šå½¢å¼ï¼Œå…¶ä¸­è¯­è¨€æµç•…æ€§ã€ç»“æ„è¿è´¯æ€§å’Œè¡¨é¢ä¸Šå¯ä¿¡çš„å¼•ç”¨æ©ç›–äº†æ›´æ·±å±‚æ¬¡çš„æ„ä¹‰æ‰­æ›²ã€‚è¯„ä¼°è€…ç»å¸¸æ··æ·†æ­£ç¡®æ€§ã€ç›¸å…³æ€§ã€åå·®ã€ä¾æ®æ€§å’Œä¸€è‡´æ€§ç­‰æ ‡å‡†ï¼Œè¡¨æ˜äººç±»åˆ¤æ–­å°†åˆ†æåŒºåˆ†ç®€åŒ–ä¸ºå—å½¢å¼å’Œæµç•…æ€§å½±å“çš„ç›´è§‰å¯å‘å¼ã€‚åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ç³»ç»Ÿçš„éªŒè¯è´Ÿæ‹…å’Œè®¤çŸ¥æ¼‚ç§»ã€‚éšç€ä»»åŠ¡å˜å¾—æ›´åŠ å¯†é›†ï¼Œè¯„ä¼°è€…è¶Šæ¥è¶Šä¾èµ–è¡¨é¢çº¿ç´¢ï¼Œå…è®¸é”™è¯¯ä½†å½¢å¼è‰¯å¥½çš„ç­”æ¡ˆè¢«è®¤ä¸ºæ˜¯å¯ä¿¡çš„ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œé”™è¯¯ä¸ä»…ä»…æ˜¯æ¨¡å‹è¡Œä¸ºçš„å±æ€§ï¼Œè€Œæ˜¯ç”Ÿæˆå¯ä¿¡åº¦å’Œäººç±»è§£é‡Šæ€§æ·å¾„å…±åŒæ„å»ºçš„ç»“æœã€‚å› æ­¤ï¼Œç†è§£AIçš„è®¤çŸ¥å¤±è´¥éœ€è¦å°†è¯„ä¼°é‡æ–°å®šä¹‰ä¸ºä¸€ä¸ªå…³ç³»è§£é‡Šè¿‡ç¨‹ï¼Œå…¶ä¸­ç³»ç»Ÿå¤±è´¥å’Œäººç±»æ ¡å‡†é”™è¯¯ä¹‹é—´çš„ç•Œé™å˜å¾—æ¨¡ç³Šã€‚è¯¥ç ”ç©¶ä¸ºLLMè¯„ä¼°ã€æ•°å­—ç´ å…»å’Œå¯ä¿¡çš„äººæœºé€šä¿¡è®¾è®¡æä¾›äº†å¯ç¤ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é”™è¯¯è¯„ä¼°ä¸»è¦é›†ä¸­åœ¨é¢„æµ‹å‡†ç¡®æ€§ç­‰æŒ‡æ ‡ä¸Šï¼Œå¿½ç•¥äº†LLMçš„è¾“å‡ºå¦‚ä½•å½±å“äººç±»çš„ç†è§£å’Œåˆ¤æ–­ã€‚è¿™ç§ç‰‡é¢çš„è¯„ä¼°æ–¹å¼æ— æ³•å……åˆ†æ­ç¤ºäººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„å¤æ‚æ€§ï¼Œå°¤å…¶æ˜¯åœ¨LLMç”Ÿæˆçœ‹ä¼¼åˆç†ä½†å®é™…ä¸Šé”™è¯¯çš„ç­”æ¡ˆæ—¶ï¼Œäººç±»å¯èƒ½ä¼šå—åˆ°è¯¯å¯¼ã€‚å› æ­¤ï¼Œéœ€è¦æ›´æ·±å…¥åœ°ç†è§£LLMçš„é”™è¯¯å¦‚ä½•è¢«äººç±»æ„ŸçŸ¥å’Œè§£é‡Šï¼Œä»¥åŠè¿™ç§äº¤äº’å¦‚ä½•å…±åŒæ„å»ºè®¤çŸ¥é”™è¯¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMçš„é”™è¯¯è§†ä¸ºä¸€ç§â€œå…³ç³»ç ´è£‚â€ï¼Œå³LLMçš„è¾“å‡ºä¸äººç±»çš„ç†è§£ä¹‹é—´å‡ºç°åå·®ã€‚è¿™ç§åå·®å¹¶éä»…ä»…ç”±LLMçš„é¢„æµ‹é”™è¯¯å¼•èµ·ï¼Œè€Œæ˜¯ç”±LLMç”Ÿæˆå†…å®¹çš„å¯ä¿¡åº¦ï¼ˆplausibilityï¼‰å’Œäººç±»çš„è§£é‡Šæ€§åˆ¤æ–­å…±åŒå¡‘é€ ã€‚é€šè¿‡è€ƒå¯Ÿäººç±»å¦‚ä½•è§£é‡Šå’Œå®¹å¿LLMçš„é”™è¯¯ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£äººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„äº§ç”Ÿæœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶é‡‡ç”¨äº†ä¸€ä¸ªä¸‰è½®çš„å¤šLLMè¯„ä¼°æ¡†æ¶ã€‚ç¬¬ä¸€è½®ä½¿ç”¨è·¨å­¦ç§‘ä»»åŠ¡ï¼Œæ—¨åœ¨è¯†åˆ«ä¸åŒç±»å‹çš„LLMé”™è¯¯ã€‚ç¬¬äºŒè½®å’Œç¬¬ä¸‰è½®é€æ­¥ç»†åŒ–è¯„ä¼°æ¡†æ¶ï¼Œæ›´åŠ å…³æ³¨è¯„ä¼°è€…å¦‚ä½•è§£é‡ŠLLMçš„å“åº”ï¼Œå¹¶è€ƒå¯Ÿè¯­è¨€ã€è®¤çŸ¥å’Œå¯ä¿¡åº¦ç­‰ç»´åº¦ã€‚è¯„ä¼°è€…éœ€è¦å¯¹LLMçš„è¾“å‡ºè¿›è¡Œå¤šæ–¹é¢çš„è¯„ä¼°ï¼ŒåŒ…æ‹¬æ­£ç¡®æ€§ã€ç›¸å…³æ€§ã€åå·®ã€ä¾æ®æ€§å’Œä¸€è‡´æ€§ç­‰ã€‚ç ”ç©¶è€…é€šè¿‡åˆ†æè¯„ä¼°è€…çš„åé¦ˆï¼Œæ­ç¤ºäººç±»åˆ¤æ–­ä¸­çš„è®¤çŸ¥åå·®å’Œå¯å‘å¼æ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†LLMçš„é”™è¯¯è¯„ä¼°ä»å•çº¯çš„é¢„æµ‹å‡†ç¡®æ€§è½¬å‘äº†å¯¹äººæœºäº¤äº’çš„è§£é‡Šæ€§åˆ†æã€‚å®ƒå¼ºè°ƒäº†LLMç”Ÿæˆå†…å®¹çš„å¯ä¿¡åº¦å¯¹äººç±»åˆ¤æ–­çš„å½±å“ï¼Œå¹¶æ­ç¤ºäº†äººç±»åœ¨è¯„ä¼°LLMè¾“å‡ºæ—¶å­˜åœ¨çš„è®¤çŸ¥åå·®ã€‚è¿™ç§æ–°çš„è¯„ä¼°è§†è§’æœ‰åŠ©äºæ›´å…¨é¢åœ°ç†è§£äººæœºäº¤äº’ä¸­è®¤çŸ¥é”™è¯¯çš„äº§ç”Ÿæœºåˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œç ”ç©¶è€…è®¾è®¡äº†è·¨å­¦ç§‘çš„ä»»åŠ¡ï¼Œä»¥è€ƒå¯ŸLLMåœ¨ä¸åŒé¢†åŸŸçš„è¡¨ç°ã€‚åŒæ—¶ï¼Œä»–ä»¬é€æ­¥ç»†åŒ–è¯„ä¼°æ¡†æ¶ï¼Œæ›´åŠ å…³æ³¨è¯„ä¼°è€…å¯¹LLMè¾“å‡ºçš„è§£é‡Šã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜é‡‡ç”¨äº†å¤šç§LLMï¼Œä»¥è€ƒå¯Ÿä¸åŒæ¨¡å‹çš„é”™è¯¯æ¨¡å¼ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œç ”ç©¶è€…èƒ½å¤Ÿæ›´å…¨é¢åœ°äº†è§£LLMçš„é”™è¯¯ä»¥åŠäººç±»å¯¹è¿™äº›é”™è¯¯çš„ååº”ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼ŒLLMçš„é”™è¯¯ä¼šä»é¢„æµ‹å½¢å¼è½¬å˜ä¸ºè§£é‡Šå½¢å¼ï¼Œå³è¯­è¨€æµç•…ã€ç»“æ„è¿è´¯ä½†æ„ä¹‰æ‰­æ›²ã€‚è¯„ä¼°è€…æ˜“å—è¡¨é¢çº¿ç´¢å½±å“ï¼Œå¯¼è‡´è®¤çŸ¥æ¼‚ç§»ï¼Œä½¿å¾—é”™è¯¯ç­”æ¡ˆè¢«è¯¯è®¤ä¸ºå¯ä¿¡ã€‚è¿™è¡¨æ˜é”™è¯¯å¹¶éä»…æ˜¯æ¨¡å‹å±æ€§ï¼Œè€Œæ˜¯äººæœºäº¤äº’çš„å…±å»ºç»“æœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºLLMè¯„ä¼°ä½“ç³»çš„æ”¹è¿›ï¼Œæå‡æ•°å­—ç´ å…»æ•™è‚²ï¼Œå¹¶æŒ‡å¯¼æ›´å€¼å¾—ä¿¡èµ–çš„äººæœºäº¤äº’ç³»ç»Ÿè®¾è®¡ã€‚é€šè¿‡ç†è§£LLMè®¤çŸ¥é”™è¯¯çš„å…±å»ºæœºåˆ¶ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´ç†æ€§åœ°ä½¿ç”¨LLMï¼Œé¿å…ç›²ç›®ä¿¡ä»»ï¼Œä»è€Œå‡å°‘è¯¯å¯¼ä¿¡æ¯çš„ä¼ æ’­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used as epistemic partners in everyday reasoning, yet their errors remain predominantly analyzed through predictive metrics rather than through their interpretive effects on human judgment. This study examines how different forms of epistemic failure emerge, are masked, and are tolerated in human AI interaction, where failure is understood as a relational breakdown shaped by model-generated plausibility and human interpretive judgment. We conducted a three round, multi LLM evaluation using interdisciplinary tasks and progressively differentiated assessment frameworks to observe how evaluators interpret model responses across linguistic, epistemic, and credibility dimensions. Our findings show that LLM errors shift from predictive to hermeneutic forms, where linguistic fluency, structural coherence, and superficially plausible citations conceal deeper distortions of meaning. Evaluators frequently conflated criteria such as correctness, relevance, bias, groundedness, and consistency, indicating that human judgment collapses analytical distinctions into intuitive heuristics shaped by form and fluency. Across rounds, we observed a systematic verification burden and cognitive drift. As tasks became denser, evaluators increasingly relied on surface cues, allowing erroneous yet well formed answers to pass as credible. These results suggest that error is not solely a property of model behavior but a co-constructed outcome of generative plausibility and human interpretive shortcuts. Understanding AI epistemic failure therefore requires reframing evaluation as a relational interpretive process, where the boundary between system failure and human miscalibration becomes porous. The study provides implications for LLM assessment, digital literacy, and the design of trustworthy human AI communication.

