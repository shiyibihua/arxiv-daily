---
layout: default
title: TORSO: Template-Oriented Reasoning Towards General Tasks
---

# TORSO: Template-Oriented Reasoning Towards General Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09448" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09448v3</a>
  <a href="https://arxiv.org/pdf/2509.09448.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09448v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09448v3', 'TORSO: Template-Oriented Reasoning Towards General Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Minhyuk Kim, Seungyoon Lee, Heuiseok Lim

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11 (æ›´æ–°: 2025-09-15)

**å¤‡æ³¨**: Accepted to EMNLP 2025 Main Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTORSOï¼šé¢å‘æ¨¡æ¿æ¨ç†ï¼Œæ— éœ€äººå·¥æ ·æœ¬å³å¯æå‡LLMåœ¨é€šç”¨ä»»åŠ¡ä¸Šçš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨¡æ¿æ¨ç†` `é›¶æ ·æœ¬å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥æ„å»ºçš„å°‘é‡æ ·æœ¬æç¤ºï¼Œæˆæœ¬é«˜ä¸”é™åˆ¶äº†LLMçš„å†…åœ¨æ¨ç†èƒ½åŠ›ã€‚
2. TORSOé€šè¿‡æ¨¡æ¿å¼•å¯¼LLMè¿›è¡Œæ¨ç†ï¼Œæ— éœ€äººå·¥æ ‡æ³¨çš„å°‘é‡æ ·æœ¬ï¼Œé™ä½äº†æˆæœ¬ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTORSOåœ¨å¤šä¸ªLLMåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå¹¶èƒ½ç”Ÿæˆåˆç†çš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ç”Ÿæˆå“åº”æ—¶æ¨¡ä»¿äººç±»æ¨ç†è¿‡ç¨‹çš„æ–¹æ³•ï¼Œå·²ç»æˆä¸ºä¸€ç§æœ‰æ•ˆé€”å¾„ï¼Œä½¿å…¶èƒ½å¤Ÿé€æ­¥è§£å†³å¤æ‚é—®é¢˜ï¼Œä»è€Œè·å¾—å“è¶Šçš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•ä½¿ç”¨å°‘é‡æ ·æœ¬æç¤ºæ¥ç”Ÿæˆå“åº”ï¼Œä¸¥é‡ä¾èµ–äºæä¾›çš„ç¤ºä¾‹ï¼Œé™åˆ¶äº†æ¨¡å‹å›ºæœ‰æ¨ç†èƒ½åŠ›çš„åˆ©ç”¨ã€‚æ­¤å¤–ï¼Œæ„å»ºç‰¹å®šäºä»»åŠ¡çš„å°‘é‡æ ·æœ¬æç¤ºé€šå¸¸æˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”å¯èƒ½å¯¼è‡´ä¸åŒä»»åŠ¡ä¹‹é—´å‡ºç°ä¸ä¸€è‡´ã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§åä¸ºæ¨¡æ¿å¯¼å‘æ¨ç†ï¼ˆTORSOï¼‰çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨æ¿€å‘æ¨¡å‹åˆ©ç”¨å…¶å†…éƒ¨æ¨ç†èƒ½åŠ›ï¼Œä»è€Œåœ¨å„ç§ä»»åŠ¡ä¸­ç”Ÿæˆé€‚å½“çš„å“åº”ï¼Œè€Œæ— éœ€æ‰‹åŠ¨åˆ¶ä½œçš„å°‘é‡æ ·æœ¬ç¤ºä¾‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTORSOåœ¨å„ç§LLMåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†å¼ºå¤§çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰åˆç†çš„ç†ç”±ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è§£å†³å¤æ‚é—®é¢˜æ—¶ï¼Œä¾èµ–äºäººå·¥è®¾è®¡çš„å°‘é‡æ ·æœ¬æç¤ºï¼ˆfew-shot promptsï¼‰ã€‚è¿™ç§æ–¹æ³•å­˜åœ¨ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯æ„å»ºé«˜è´¨é‡çš„few-shot promptséœ€è¦å¤§é‡çš„äººå·¥æˆæœ¬ï¼›äºŒæ˜¯æ¨¡å‹è¿‡åº¦ä¾èµ–æä¾›çš„ç¤ºä¾‹ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨è‡ªèº«å›ºæœ‰çš„æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æ³›åŒ–æ€§èƒ½å—é™ã€‚å› æ­¤ï¼Œå¦‚ä½•è®©LLMåœ¨æ²¡æœ‰æˆ–å¾ˆå°‘äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œå……åˆ†å‘æŒ¥å…¶æ¨ç†èƒ½åŠ›ï¼Œæ˜¯æœ¬æ–‡è¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTORSOçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„å®šä¹‰çš„æ¨¡æ¿ï¼ˆtemplateï¼‰æ¥å¼•å¯¼LLMè¿›è¡Œæ¨ç†ã€‚è¿™äº›æ¨¡æ¿å®šä¹‰äº†æ¨ç†çš„ç»“æ„å’Œæ­¥éª¤ï¼Œä½†å¹¶ä¸åŒ…å«å…·ä½“çš„ç¤ºä¾‹ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥æ ¹æ®æ¨¡æ¿çš„æŒ‡å¯¼ï¼Œåˆ©ç”¨è‡ªèº«çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›æ¥ç”Ÿæˆå“åº”ï¼Œè€Œæ— éœ€ä¾èµ–äººå·¥æä¾›çš„ç¤ºä¾‹ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨æ¿€å‘LLMçš„å†…åœ¨æ¨ç†èƒ½åŠ›ï¼Œæé«˜å…¶åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ³›åŒ–æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTORSOçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1. å®šä¹‰ä»»åŠ¡ç›¸å…³çš„æ¨ç†æ¨¡æ¿ã€‚è¿™äº›æ¨¡æ¿æè¿°äº†è§£å†³ç‰¹å®šä»»åŠ¡æ‰€éœ€çš„æ¨ç†æ­¥éª¤å’Œç»“æ„ã€‚2. å°†ä»»åŠ¡æè¿°å’Œæ¨ç†æ¨¡æ¿è¾“å…¥åˆ°LLMä¸­ã€‚3. LLMæ ¹æ®æ¨¡æ¿çš„æŒ‡å¯¼ï¼Œç”Ÿæˆç›¸åº”çš„æ¨ç†è¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆã€‚4. å¯¹ç”Ÿæˆçš„æ¨ç†è¿‡ç¨‹è¿›è¡Œè¯„ä¼°å’Œä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰ã€‚æ•´ä¸ªæ¡†æ¶çš„å…³é”®åœ¨äºè®¾è®¡åˆé€‚çš„æ¨ç†æ¨¡æ¿ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å¼•å¯¼LLMè¿›è¡Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šTORSOæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶æ¨¡æ¿å¯¼å‘çš„æ¨ç†æ–¹å¼ã€‚ä¸ä¼ ç»Ÿçš„few-shot learningæ–¹æ³•ç›¸æ¯”ï¼ŒTORSOæ— éœ€äººå·¥æ„å»ºç¤ºä¾‹ï¼Œè€Œæ˜¯é€šè¿‡é¢„å®šä¹‰çš„æ¨¡æ¿æ¥å¼•å¯¼LLMè¿›è¡Œæ¨ç†ã€‚è¿™ç§æ–¹æ³•é™ä½äº†äººå·¥æˆæœ¬ï¼Œå¹¶èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨LLMè‡ªèº«çš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒTORSOçš„æ¨¡æ¿å…·æœ‰ä¸€å®šçš„é€šç”¨æ€§ï¼Œå¯ä»¥åº”ç”¨äºä¸åŒçš„ä»»åŠ¡ï¼Œæé«˜äº†æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šTORSOçš„å…³é”®è®¾è®¡åœ¨äºæ¨ç†æ¨¡æ¿çš„è®¾è®¡ã€‚æ¨¡æ¿éœ€è¦è¶³å¤Ÿé€šç”¨ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„ä»»åŠ¡ï¼ŒåŒæ—¶åˆéœ€è¦è¶³å¤Ÿå…·ä½“ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¼•å¯¼LLMè¿›è¡Œæ¨ç†ã€‚æ¨¡æ¿çš„è®¾è®¡éœ€è¦è€ƒè™‘ä»»åŠ¡çš„ç‰¹ç‚¹å’ŒLLMçš„æ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒTORSOè¿˜å¯ä»¥ç»“åˆä¸€äº›å…¶ä»–çš„æŠ€æœ¯ï¼Œä¾‹å¦‚å¼ºåŒ–å­¦ä¹ ï¼Œæ¥ä¼˜åŒ–æ¨¡æ¿çš„è®¾è®¡å’ŒLLMçš„æ¨ç†è¿‡ç¨‹ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°ã€ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒéªŒè¯äº†TORSOåœ¨å¤šä¸ªLLMåŸºå‡†æµ‹è¯•ä¸­çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTORSOåœ¨æ— éœ€äººå·¥æ„å»ºç¤ºä¾‹çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿå–å¾—ä¸few-shot learningæ–¹æ³•ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿ã€æå‡å¹…åº¦ç­‰ä¿¡æ¯åœ¨æ‘˜è¦ä¸­æœªæåŠï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TORSOå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦æ¨ç†èƒ½åŠ›çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚è¯¥æ–¹æ³•å¯ä»¥é™ä½äººå·¥æˆæœ¬ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ï¼Œå¹¶ä¿ƒè¿›LLMåœ¨å®é™…åº”ç”¨ä¸­çš„éƒ¨ç½²ã€‚æœªæ¥ï¼ŒTORSOè¿˜å¯ä»¥ä¸å…¶ä»–æŠ€æœ¯ç›¸ç»“åˆï¼Œä¾‹å¦‚çŸ¥è¯†å›¾è°±ã€å¼ºåŒ–å­¦ä¹ ç­‰ï¼Œè¿›ä¸€æ­¥æå‡LLMçš„æ¨ç†èƒ½åŠ›å’Œåº”ç”¨èŒƒå›´ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The approaches that guide Large Language Models (LLMs) to emulate human reasoning during response generation have emerged as an effective method for enabling them to solve complex problems in a step-by-step manner, thereby achieving superior performance. However, most existing approaches using few-shot prompts to generate responses heavily depend on the provided examples, limiting the utilization of the model's inherent reasoning capabilities. Moreover, constructing task-specific few-shot prompts is often costly and may lead to inconsistencies across different tasks. In this work, we introduce Template-Oriented Reasoning (TORSO), which elicits the model to utilize internal reasoning abilities to generate proper responses across various tasks without the need for manually crafted few-shot examples. Our experimental results demonstrate that TORSO achieves strong performance on diverse LLMs benchmarks with reasonable rationales.

