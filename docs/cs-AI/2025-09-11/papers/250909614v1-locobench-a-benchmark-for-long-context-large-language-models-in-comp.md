---
layout: default
title: LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering
---

# LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09614" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.09614v1</a>
  <a href="https://arxiv.org/pdf/2509.09614.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09614v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09614v1', 'LoCoBench: A Benchmark for Long-Context Large Language Models in Complex Software Engineering')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jielin Qiu, Zuxin Liu, Zhiwei Liu, Rithesh Murthy, Jianguo Zhang, Haolin Chen, Shiyu Wang, Ming Zhu, Liangwei Yang, Juntao Tan, Zhepeng Cen, Cheng Qian, Shelby Heinecke, Weiran Yao, Silvio Savarese, Caiming Xiong, Huan Wang

**ÂàÜÁ±ª**: cs.SE, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-11

**Â§áÊ≥®**: 53 pages

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/SalesforceAIResearch/LoCoBench)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫LoCoBenchÔºåÁî®‰∫éËØÑ‰º∞Èïø‰∏ä‰∏ãÊñáLLMÂú®Â§çÊùÇËΩØ‰ª∂Â∑•Á®ã‰∏≠ÁöÑËÉΩÂäõ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Èïø‰∏ä‰∏ãÊñáLLM` `ËΩØ‰ª∂Â∑•Á®ã` `Âü∫ÂáÜÊµãËØï` `‰ª£Á†ÅÁêÜËß£` `‰ª£Á†ÅÁîüÊàê` `Êû∂ÊûÑÁêÜËß£` `Ë∑®Êñá‰ª∂Êé®ÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞Êúâ‰ª£Á†ÅËØÑ‰º∞Âü∫ÂáÜ‰æßÈáç‰∫éÂçïÂáΩÊï∞ÊàñÁü≠‰∏ä‰∏ãÊñáÔºåÁº∫‰πèÂØπLLMÂú®Â§çÊùÇËΩØ‰ª∂Â∑•Á®ã‰∏≠Èïø‰∏ä‰∏ãÊñáÁêÜËß£ËÉΩÂäõÁöÑÂÖ®Èù¢ËØÑ‰º∞„ÄÇ
2. LoCoBenchÈÄöËøáÊûÑÂª∫ÂåÖÂê´8000‰∏™Ë∑®10ÁßçÁºñÁ®ãËØ≠Ë®ÄÁöÑÂ§çÊùÇÂú∫ÊôØÔºåÁ≥ªÁªüÊÄßÂú∞ËØÑ‰º∞LLMÂú®Èïø‰∏ä‰∏ãÊñá‰∏ãÁöÑ‰ª£Á†ÅÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁé∞ÊúâÈïø‰∏ä‰∏ãÊñáLLMÂú®LoCoBench‰∏äË°®Áé∞Âá∫ÊòæËëóÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåÊè≠Á§∫‰∫ÜÂ§çÊùÇËΩØ‰ª∂ÂºÄÂèë‰∏≠Èïø‰∏ä‰∏ãÊñáÁêÜËß£ÁöÑÊåëÊàò„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫LoCoBenchÔºå‰∏Ä‰∏™ÁªºÂêàÊÄßÁöÑÂü∫ÂáÜÊµãËØïÔºå‰∏ìÈó®Áî®‰∫éËØÑ‰º∞Èïø‰∏ä‰∏ãÊñáÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®ÁúüÂÆû„ÄÅÂ§çÊùÇÁöÑËΩØ‰ª∂ÂºÄÂèëÂú∫ÊôØ‰∏≠ÁöÑËÉΩÂäõ„ÄÇ‰∏éÁé∞Êúâ‰æßÈáç‰∫éÂçïÂáΩÊï∞Ë°•ÂÖ®ÊàñÁü≠‰∏ä‰∏ãÊñá‰ªªÂä°ÁöÑ‰ª£Á†ÅËØÑ‰º∞Âü∫ÂáÜ‰∏çÂêåÔºåLoCoBenchÊó®Âú®Ëß£ÂÜ≥Èïø‰∏ä‰∏ãÊñáËÉΩÂäõÁöÑÂÖ≥ÈîÆËØÑ‰º∞Áº∫Âè£ÔºåËøô‰∫õËÉΩÂäõÈúÄË¶ÅÁêÜËß£Êï¥‰∏™‰ª£Á†ÅÂ∫ì„ÄÅË∑®Â§ö‰∏™Êñá‰ª∂ËøõË°åÊé®ÁêÜÔºåÂπ∂Âú®Â§ßÂûãËΩØ‰ª∂Á≥ªÁªü‰∏≠‰øùÊåÅÊû∂ÊûÑ‰∏ÄËá¥ÊÄß„ÄÇËØ•Âü∫ÂáÜÊµãËØïÊèê‰æõË∑®10ÁßçÁºñÁ®ãËØ≠Ë®ÄÁ≥ªÁªüÁîüÊàêÁöÑ8000‰∏™ËØÑ‰º∞Âú∫ÊôØÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶Ë∑®Ë∂ä10KÂà∞1M‰∏™tokenÔºåÂÆûÁé∞‰∫Ü100ÂÄçÁöÑÂèòÂåñÔºå‰ªéËÄåËÉΩÂ§üÁ≤æÁ°ÆËØÑ‰º∞Âú®ÂÆûÈôÖËΩØ‰ª∂ÂºÄÂèëÁéØÂ¢É‰∏≠Èïø‰∏ä‰∏ãÊñáÊÄßËÉΩÁöÑ‰∏ãÈôç„ÄÇLoCoBenchÂºïÂÖ•‰∫Ü8‰∏™‰ªªÂä°Á±ªÂà´ÔºåÊ∂µÁõñ‰∫ÜÂøÖË¶ÅÁöÑÈïø‰∏ä‰∏ãÊñáËÉΩÂäõÔºöÊû∂ÊûÑÁêÜËß£„ÄÅË∑®Êñá‰ª∂ÈáçÊûÑ„ÄÅÂ§ö‰ºöËØùÂºÄÂèë„ÄÅÁº∫Èô∑Ë∞ÉÊü•„ÄÅÂäüËÉΩÂÆûÁé∞„ÄÅ‰ª£Á†ÅÁêÜËß£„ÄÅÈõÜÊàêÊµãËØïÂíåÂÆâÂÖ®ÂàÜÊûê„ÄÇÈÄöËøá‰∏Ä‰∏™‰∫îÈò∂ÊÆµÁöÑÊµÅÁ®ãÔºåÊàë‰ª¨ÂàõÂª∫‰∫ÜÂ§öÊ†∑Âåñ„ÄÅÈ´òË¥®ÈáèÁöÑÂú∫ÊôØÔºåÊåëÊàòLLM‰ª•ÂâçÊâÄÊú™ÊúâÁöÑËßÑÊ®°Êé®ÁêÜÂ§çÊùÇÁöÑ‰ª£Á†ÅÂ∫ì„ÄÇÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂåÖÂê´17‰∏™ÊåáÊ†áÔºàÂåÖÊã¨8‰∏™Êñ∞ËØÑ‰º∞ÊåáÊ†áÔºâÁöÑÁªºÂêàËØÑ‰º∞Ê°ÜÊû∂ÔºåËøô‰∫õÊåáÊ†áÂàÜÂ∏ÉÂú®4‰∏™Áª¥Â∫¶‰∏äÔºåÂπ∂ÁªÑÂêàÊàê‰∏Ä‰∏™LoCoBench Score (LCBS)„ÄÇÂØπÊúÄÂÖàËøõÁöÑÈïø‰∏ä‰∏ãÊñáÊ®°ÂûãÁöÑËØÑ‰º∞Êè≠Á§∫‰∫ÜÂ∑®Â§ßÁöÑÊÄßËÉΩÂ∑ÆË∑ùÔºåË°®ÊòéÂú®Â§çÊùÇËΩØ‰ª∂ÂºÄÂèë‰∏≠Èïø‰∏ä‰∏ãÊñáÁêÜËß£ÊòØ‰∏Ä‰∏™Â∞öÊú™Ëß£ÂÜ≥ÁöÑÈáçÂ§ßÊåëÊàòÔºåÈúÄË¶ÅÊõ¥Â§öÂÖ≥Ê≥®„ÄÇLoCoBenchÂ∑≤Âú®https://github.com/SalesforceAIResearch/LoCoBenchÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞Êúâ‰ª£Á†ÅËØÑ‰º∞Âü∫ÂáÜ‰∏ªË¶ÅÂÖ≥Ê≥®ÂçïÂáΩÊï∞Ë°•ÂÖ®ÊàñÁü≠‰∏ä‰∏ãÊñá‰ªªÂä°ÔºåÊó†Ê≥ïÊúâÊïàËØÑ‰º∞LLMÂú®Â§çÊùÇËΩØ‰ª∂Â∑•Á®ãÂú∫ÊôØ‰∏ãÁöÑÈïø‰∏ä‰∏ãÊñáÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÂú®ÂÆûÈôÖËΩØ‰ª∂ÂºÄÂèë‰∏≠ÔºåÁêÜËß£Êï¥‰∏™‰ª£Á†ÅÂ∫ì„ÄÅË∑®Êñá‰ª∂Êé®ÁêÜ‰ª•Âèä‰øùÊåÅÊû∂ÊûÑ‰∏ÄËá¥ÊÄßËá≥ÂÖ≥ÈáçË¶ÅÔºåËÄåÁé∞ÊúâÂü∫ÂáÜÊµãËØïÊó†Ê≥ïÂÖÖÂàÜË¶ÜÁõñËøô‰∫õËÉΩÂäõ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöLoCoBenchÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊûÑÂª∫‰∏Ä‰∏™ÂåÖÂê´Â§öÊ†∑Âåñ„ÄÅÈ´òË¥®Èáè„ÄÅÈïø‰∏ä‰∏ãÊñáÁöÑËΩØ‰ª∂Â∑•Á®ãÂú∫ÊôØÁöÑÂü∫ÂáÜÊµãËØïÔºå‰ª•Á≥ªÁªüÊÄßÂú∞ËØÑ‰º∞LLMÂú®Â§çÊùÇ‰ª£Á†ÅÂ∫ì‰∏äÁöÑÁêÜËß£ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÈÄöËøáÊ®°ÊãüÁúüÂÆûÁöÑËΩØ‰ª∂ÂºÄÂèë‰ªªÂä°Ôºå‰æãÂ¶ÇÊû∂ÊûÑÁêÜËß£„ÄÅË∑®Êñá‰ª∂ÈáçÊûÑÂíåÁº∫Èô∑Ë∞ÉÊü•ÔºåÊù•ÊåëÊàòLLMÁöÑÈïø‰∏ä‰∏ãÊñáÂ§ÑÁêÜËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöLoCoBenchÁöÑÊûÑÂª∫ÂåÖÂê´‰∏Ä‰∏™‰∫îÈò∂ÊÆµÁöÑÊµÅÁ®ãÔºö(1) Âú∫ÊôØÂÆö‰πâÔºöÁ°ÆÂÆö8‰∏™ÂÖ≥ÈîÆÁöÑËΩØ‰ª∂Â∑•Á®ã‰ªªÂä°Á±ªÂà´„ÄÇ(2) Êï∞ÊçÆÊî∂ÈõÜÔºöÊî∂ÈõÜÊù•Ëá™ÂºÄÊ∫êÈ°πÁõÆÁöÑ‰ª£Á†ÅÂ∫ì„ÄÇ(3) Âú∫ÊôØÁîüÊàêÔºöÂü∫‰∫é‰ª£Á†ÅÂ∫ìÁîüÊàêÂÖ∑‰ΩìÁöÑËØÑ‰º∞Âú∫ÊôØ„ÄÇ(4) ËØÑ‰º∞ÊåáÊ†áËÆæËÆ°ÔºöËÆæËÆ°17‰∏™ËØÑ‰º∞ÊåáÊ†áÔºåÊ∂µÁõñ‰ª£Á†ÅË¥®Èáè„ÄÅÂäüËÉΩÊ≠£Á°ÆÊÄßÁ≠âÂ§ö‰∏™Áª¥Â∫¶„ÄÇ(5) Âü∫ÂáÜÊµãËØïÊâßË°åÔºö‰ΩøÁî®LLMÂú®ÁîüÊàêÁöÑÂú∫ÊôØ‰∏äÊâßË°å‰ªªÂä°ÔºåÂπ∂‰ΩøÁî®ËØÑ‰º∞ÊåáÊ†áËøõË°åËØÑ‰º∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöLoCoBenchÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ÂØπÈïø‰∏ä‰∏ãÊñáËΩØ‰ª∂Â∑•Á®ãÂú∫ÊôØÁöÑÁ≥ªÁªüÊÄßÊûÑÂª∫ÂíåËØÑ‰º∞„ÄÇÂÆÉ‰∏ç‰ªÖÂÖ≥Ê≥®‰ª£Á†ÅÁöÑËØ≠Ê≥ïÊ≠£Á°ÆÊÄßÔºåÊõ¥ÂÖ≥Ê≥®LLMÂØπ‰ª£Á†ÅÊû∂ÊûÑ„ÄÅË∑®Êñá‰ª∂‰æùËµñÂÖ≥Á≥ªÂíåËΩØ‰ª∂Â∑•Á®ãÂéüÂàôÁöÑÁêÜËß£„ÄÇÊ≠§Â§ñÔºåLoCoBenchËøòÂºïÂÖ•‰∫ÜÊñ∞ÁöÑËØÑ‰º∞ÊåáÊ†áÔºå‰æãÂ¶ÇÊû∂ÊûÑ‰∏ÄËá¥ÊÄßÔºå‰ª•Êõ¥ÂÖ®Èù¢Âú∞ËØÑ‰º∞LLMÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöLoCoBenchÂåÖÂê´8‰∏™‰ªªÂä°Á±ªÂà´ÔºåÂàÜÂà´ÊòØÊû∂ÊûÑÁêÜËß£„ÄÅË∑®Êñá‰ª∂ÈáçÊûÑ„ÄÅÂ§ö‰ºöËØùÂºÄÂèë„ÄÅÁº∫Èô∑Ë∞ÉÊü•„ÄÅÂäüËÉΩÂÆûÁé∞„ÄÅ‰ª£Á†ÅÁêÜËß£„ÄÅÈõÜÊàêÊµãËØïÂíåÂÆâÂÖ®ÂàÜÊûê„ÄÇÊØè‰∏™‰ªªÂä°Á±ªÂà´ÈÉΩÂåÖÂê´Â§ö‰∏™ËØÑ‰º∞Âú∫ÊôØÔºå‰∏ä‰∏ãÊñáÈïøÂ∫¶‰ªé10KÂà∞1M‰∏™token‰∏çÁ≠â„ÄÇËØÑ‰º∞ÊåáÊ†áÂåÖÊã¨‰ª£Á†ÅË¥®Èáè„ÄÅÂäüËÉΩÊ≠£Á°ÆÊÄß„ÄÅÊû∂ÊûÑ‰∏ÄËá¥ÊÄßÁ≠â„ÄÇLoCoBench Score (LCBS) ÊòØ‰∏Ä‰∏™ÁªºÂêàÊåáÊ†áÔºåÁî®‰∫éË°°ÈáèLLMÂú®ÊâÄÊúâ‰ªªÂä°‰∏äÁöÑÊï¥‰ΩìÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂØπÁé∞ÊúâÈïø‰∏ä‰∏ãÊñáLLMÂú®LoCoBench‰∏äÁöÑËØÑ‰º∞Ë°®ÊòéÔºåÂÆÉ‰ª¨Âú®Â§çÊùÇËΩØ‰ª∂Â∑•Á®ã‰ªªÂä°‰∏äÁöÑÊÄßËÉΩËøúÊú™ËææÂà∞ÁêÜÊÉ≥Ê∞¥Âπ≥ÔºåÂ≠òÂú®ÊòæËëóÁöÑÊÄßËÉΩÂ∑ÆË∑ù„ÄÇ‰æãÂ¶ÇÔºåÂú®Êû∂ÊûÑÁêÜËß£ÂíåË∑®Êñá‰ª∂ÈáçÊûÑÁ≠â‰ªªÂä°‰∏äÔºåLLMÁöÑÂáÜÁ°ÆÁéáÂíåÂè¨ÂõûÁéáÈÉΩËæÉ‰ΩéÔºåË°®ÊòéÈïø‰∏ä‰∏ãÊñáÁêÜËß£‰ªçÁÑ∂ÊòØ‰∏Ä‰∏™Â∑®Â§ßÁöÑÊåëÊàò„ÄÇLoCoBenchÁöÑËØÑ‰º∞ÁªìÊûú‰∏∫Êú™Êù•ÁöÑÁ†îÁ©∂ÊñπÂêëÊèê‰æõ‰∫ÜÈáçË¶ÅÂèÇËÄÉ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

LoCoBenchÂèØÁî®‰∫éËØÑ‰º∞ÂíåÊîπËøõLLMÂú®ËΩØ‰ª∂ÂºÄÂèëÈ¢ÜÂüüÁöÑÂ∫îÁî®Ôºå‰æãÂ¶ÇËá™Âä®Âåñ‰ª£Á†ÅÂÆ°Êü•„ÄÅÊô∫ËÉΩ‰ª£Á†ÅË°•ÂÖ®„ÄÅÁº∫Èô∑È¢ÑÊµãÂíå‰øÆÂ§ç„ÄÅ‰ª•ÂèäËΩØ‰ª∂Êû∂ÊûÑËÆæËÆ°„ÄÇÈÄöËøáLoCoBenchÁöÑËØÑ‰º∞ÔºåÂèØ‰ª•Êé®Âä®LLMÂú®ËΩØ‰ª∂Â∑•Á®ãÈ¢ÜÂüüÁöÑÊõ¥ÂπøÊ≥õÂ∫îÁî®ÔºåÊèêÈ´òËΩØ‰ª∂ÂºÄÂèëÊïàÁéáÂíåË¥®Èáè„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The emergence of long-context language models with context windows extending to millions of tokens has created new opportunities for sophisticated code understanding and software development evaluation. We propose LoCoBench, a comprehensive benchmark specifically designed to evaluate long-context LLMs in realistic, complex software development scenarios. Unlike existing code evaluation benchmarks that focus on single-function completion or short-context tasks, LoCoBench addresses the critical evaluation gap for long-context capabilities that require understanding entire codebases, reasoning across multiple files, and maintaining architectural consistency across large-scale software systems. Our benchmark provides 8,000 evaluation scenarios systematically generated across 10 programming languages, with context lengths spanning 10K to 1M tokens, a 100x variation that enables precise assessment of long-context performance degradation in realistic software development settings. LoCoBench introduces 8 task categories that capture essential long-context capabilities: architectural understanding, cross-file refactoring, multi-session development, bug investigation, feature implementation, code comprehension, integration testing, and security analysis. Through a 5-phase pipeline, we create diverse, high-quality scenarios that challenge LLMs to reason about complex codebases at unprecedented scale. We introduce a comprehensive evaluation framework with 17 metrics across 4 dimensions, including 8 new evaluation metrics, combined in a LoCoBench Score (LCBS). Our evaluation of state-of-the-art long-context models reveals substantial performance gaps, demonstrating that long-context understanding in complex software development represents a significant unsolved challenge that demands more attention. LoCoBench is released at: https://github.com/SalesforceAIResearch/LoCoBench.

