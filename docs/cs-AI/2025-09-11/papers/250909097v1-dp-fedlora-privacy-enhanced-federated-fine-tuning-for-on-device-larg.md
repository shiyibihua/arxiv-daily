---
layout: default
title: DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models
---

# DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09097" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09097v1</a>
  <a href="https://arxiv.org/pdf/2509.09097.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09097v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09097v1', 'DP-FedLoRA: Privacy-Enhanced Federated Fine-Tuning for On-Device Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Honghui Xu, Shiva Shrestha, Wei Chen, Zhiyuan Li, Zhipeng Cai

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDP-FedLoRAï¼Œå¢å¼ºè®¾å¤‡ç«¯LLMè”é‚¦å¾®è°ƒçš„éšç§ä¿æŠ¤ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `å·®åˆ†éšç§` `å¤§å‹è¯­è¨€æ¨¡å‹` `è®¾å¤‡ç«¯å­¦ä¹ ` `LoRA` `éšç§ä¿æŠ¤` `æ¨¡å‹å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è®¾å¤‡ç«¯LLMçš„è”é‚¦å¾®è°ƒé¢ä¸´ç”¨æˆ·æ•°æ®éšç§æ³„éœ²çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨ä¿æŠ¤éšç§çš„åŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚
2. DP-FedLoRAæ¡†æ¶ç»“åˆLoRAå’Œå·®åˆ†éšç§ï¼Œé€šè¿‡åœ¨æœ¬åœ°è£å‰ªå’Œæ‰°åŠ¨LoRAçŸ©é˜µï¼Œå®ç°éšç§ä¿æŠ¤çš„è”é‚¦å¾®è°ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDP-FedLoRAåœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†å¼ºå¤§çš„éšç§ä¿è¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è®¾å¤‡ç«¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç³»ç»Ÿæ—¥ç›Šæ™®åŠï¼Œè”é‚¦å¾®è°ƒå¯ä»¥ç›´æ¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°é«˜çº§è¯­è¨€ç†è§£å’Œç”Ÿæˆï¼›ç„¶è€Œï¼Œè¿™ä¹Ÿæ¶‰åŠåˆ°å¤„ç†æ•æ„Ÿçš„ã€ç”¨æˆ·ç‰¹å®šçš„æ•°æ®ï¼Œä»è€Œåœ¨è”é‚¦å­¦ä¹ æ¡†æ¶å†…å¼•å‘äº†ä¸¥é‡çš„éšç§é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§éšç§å¢å¼ºçš„è”é‚¦å¾®è°ƒæ¡†æ¶DP-FedLoRAï¼Œè¯¥æ¡†æ¶é›†æˆäº†åŸºäºLoRAçš„é€‚é…ä¸å·®åˆ†éšç§ï¼Œå¹¶å…·æœ‰é€šä¿¡æ•ˆç‡ã€‚æ¯ä¸ªå®¢æˆ·ç«¯åœ¨æœ¬åœ°ä½¿ç”¨é«˜æ–¯å™ªå£°è£å‰ªå’Œæ‰°åŠ¨å…¶LoRAçŸ©é˜µï¼Œä»¥æ»¡è¶³($Îµ$, $Î´$)-å·®åˆ†éšç§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æä¾›äº†ç†è®ºåˆ†æï¼Œè¯æ˜äº†æ›´æ–°çš„æ— åæ€§ï¼Œå¹¶æ¨å¯¼äº†å™ªå£°å¼•å…¥çš„æ–¹å·®çš„ç•Œé™ï¼Œä¸ºéšç§é¢„ç®—æ ¡å‡†æä¾›äº†å®è·µæŒ‡å¯¼ã€‚åœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒDP-FedLoRAåœ¨æä¾›å¼ºå¤§éšç§ä¿è¯çš„åŒæ—¶ï¼Œå®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œä¸ºè®¾å¤‡ç«¯ç¯å¢ƒä¸­å¯æ‰©å±•ä¸”ä¿æŠ¤éšç§çš„LLMéƒ¨ç½²é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è®¾å¤‡ç«¯è”é‚¦å­¦ä¹ ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¾®è°ƒè¿‡ç¨‹ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è”é‚¦å­¦ä¹ ä¸­ç›´æ¥å…±äº«æ¨¡å‹å‚æ•°æˆ–æ¢¯åº¦ï¼Œå®¹æ˜“å—åˆ°éšç§æ”»å‡»ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†ç”¨æˆ·æ•æ„Ÿæ•°æ®æ—¶ã€‚å¦‚ä½•åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„å‰æä¸‹ï¼Œé«˜æ•ˆåœ°è¿›è¡ŒLLMçš„è”é‚¦å¾®è°ƒæ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LoRAï¼ˆLow-Rank Adaptationï¼‰ä¸å·®åˆ†éšç§ï¼ˆDifferential Privacyï¼‰ç›¸ç»“åˆã€‚LoRAé€šè¿‡å¾®è°ƒä½ç§©çŸ©é˜µæ¥é€‚åº”LLMï¼Œå‡å°‘äº†éœ€è¦ä¼ è¾“çš„å‚æ•°é‡ï¼Œä»è€Œé™ä½äº†é€šä¿¡æˆæœ¬ã€‚å·®åˆ†éšç§åˆ™é€šè¿‡åœ¨æœ¬åœ°æ·»åŠ å™ªå£°æ¥ä¿æŠ¤ç”¨æˆ·æ•°æ®çš„éšç§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDP-FedLoRAæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š1) å®¢æˆ·ç«¯åœ¨æœ¬åœ°ä½¿ç”¨LoRAå¯¹LLMè¿›è¡Œå¾®è°ƒã€‚2) å®¢æˆ·ç«¯å¯¹LoRAçŸ©é˜µè¿›è¡Œè£å‰ªï¼Œé™åˆ¶å…¶æ•°å€¼èŒƒå›´ã€‚3) å®¢æˆ·ç«¯å‘è£å‰ªåçš„LoRAçŸ©é˜µæ·»åŠ é«˜æ–¯å™ªå£°ï¼Œä»¥æ»¡è¶³å·®åˆ†éšç§ã€‚4) å®¢æˆ·ç«¯å°†æ·»åŠ å™ªå£°çš„LoRAçŸ©é˜µä¸Šä¼ åˆ°æœåŠ¡å™¨ã€‚5) æœåŠ¡å™¨å¯¹æ¥æ”¶åˆ°çš„LoRAçŸ©é˜µè¿›è¡Œèšåˆï¼Œæ›´æ–°å…¨å±€æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LoRAä¸å·®åˆ†éšç§ç›¸ç»“åˆï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæä¾›äº†å¼ºå¤§çš„éšç§ä¿æŠ¤ã€‚é€šè¿‡LoRAé™ä½äº†éœ€è¦ä¿æŠ¤çš„å‚æ•°é‡ï¼Œä»è€Œé™ä½äº†å·®åˆ†éšç§æ‰€éœ€çš„å™ªå£°é‡ï¼Œæé«˜äº†æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æä¾›äº†ç†è®ºåˆ†æï¼Œè¯æ˜äº†æ›´æ–°çš„æ— åæ€§ï¼Œå¹¶æ¨å¯¼äº†å™ªå£°å¼•å…¥çš„æ–¹å·®çš„ç•Œé™ï¼Œä¸ºéšç§é¢„ç®—æ ¡å‡†æä¾›äº†å®è·µæŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é«˜æ–¯å™ªå£°å®ç°å·®åˆ†éšç§ã€‚2) å¯¹LoRAçŸ©é˜µè¿›è¡Œè£å‰ªï¼Œé™åˆ¶å…¶æ•°å€¼èŒƒå›´ï¼Œä»è€Œé™ä½å™ªå£°çš„å½±å“ã€‚3) ç†è®ºåˆ†æå™ªå£°å¯¹æ–¹å·®çš„å½±å“ï¼ŒæŒ‡å¯¼éšç§é¢„ç®—çš„æ ¡å‡†ã€‚4) å®¢æˆ·ç«¯æœ¬åœ°å¾®è°ƒæ—¶é‡‡ç”¨åˆé€‚çš„å­¦ä¹ ç‡å’Œè¿­ä»£æ¬¡æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDP-FedLoRAåœ¨ä¸»æµåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†ä¸ééšç§ä¿æŠ¤æ–¹æ³•å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶æä¾›äº†å¼ºå¤§çš„éšç§ä¿è¯ã€‚å…·ä½“æ¥è¯´ï¼ŒDP-FedLoRAåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ¥è¿‘ç”šè‡³è¶…è¿‡baselineçš„æ€§èƒ½ï¼ŒåŒæ—¶æ»¡è¶³äº†é¢„è®¾çš„å·®åˆ†éšç§é¢„ç®—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DP-FedLoRAå¯åº”ç”¨äºå„ç§éœ€è¦ä¿æŠ¤ç”¨æˆ·éšç§çš„è®¾å¤‡ç«¯LLMè”é‚¦å¾®è°ƒåœºæ™¯ï¼Œä¾‹å¦‚ä¸ªæ€§åŒ–æ¨èã€æ™ºèƒ½åŠ©æ‰‹ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ¨åŠ¨åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²å¯æ‰©å±•ä¸”ä¿æŠ¤éšç§çš„LLMï¼Œä»è€Œå®ç°æ›´å®‰å…¨ã€æ›´æ™ºèƒ½çš„è®¾å¤‡ç«¯åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As on-device large language model (LLM) systems become increasingly prevalent, federated fine-tuning enables advanced language understanding and generation directly on edge devices; however, it also involves processing sensitive, user-specific data, raising significant privacy concerns within the federated learning framework. To address these challenges, we propose DP-FedLoRA, a privacy-enhanced federated fine-tuning framework that integrates LoRA-based adaptation with differential privacy in a communication-efficient setting. Each client locally clips and perturbs its LoRA matrices using Gaussian noise to satisfy ($Îµ$, $Î´$)-differential privacy. We further provide a theoretical analysis demonstrating the unbiased nature of the updates and deriving bounds on the variance introduced by noise, offering practical guidance for privacy-budget calibration. Experimental results across mainstream benchmarks show that DP-FedLoRA delivers competitive performance while offering strong privacy guarantees, paving the way for scalable and privacy-preserving LLM deployment in on-device environments.

