---
layout: default
title: Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining
---

# Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09071" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09071v3</a>
  <a href="https://arxiv.org/pdf/2509.09071.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09071v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09071v3', 'Strategic Tradeoffs Between Humans and AI in Multi-Agent Bargaining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Crystal Qian, Kehang Zhu, John Horton, Benjamin S. Manning, Vivian Tsai, James Wexler, Nithum Thain

**åˆ†ç±»**: cs.AI, cs.GT, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11 (æ›´æ–°: 2025-10-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”äººç±»ã€LLMå’Œè´å¶æ–¯æ™ºèƒ½ä½“åœ¨å¤šæ™ºèƒ½ä½“è®®ä»·ä¸­çš„ç­–ç•¥æƒè¡¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“è®®ä»·` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¡Œä¸ºç»æµå­¦` `äººæœºåä½œ` `ç­–ç•¥æƒè¡¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨åŠ¨æ€å¤šæ™ºèƒ½ä½“è®®ä»·ç¯å¢ƒä¸­æœ‰æ•ˆè¯„ä¼°LLMçš„ç­–ç•¥å’Œè¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨ä¸äººç±»è¡Œä¸ºå¯¹æ¯”æ—¶ã€‚
2. è®ºæ–‡é€šè¿‡å¯¹æ¯”äººç±»ã€LLMå’Œè´å¶æ–¯æ™ºèƒ½ä½“åœ¨ç›¸åŒè®®ä»·æ¡ä»¶ä¸‹çš„è¡Œä¸ºï¼Œæ­ç¤ºäº†ä¸åŒæ™ºèƒ½ä½“ç±»å‹çš„ç­–ç•¥æƒè¡¡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLMå’Œäººç±»åœ¨å‰©ä½™ä»·å€¼ä¸Šè¡¨ç°ç›¸è¿‘ï¼Œä½†è¡Œä¸ºæ¨¡å¼è¿¥å¼‚ï¼ŒLLMæ›´ä¿å®ˆï¼Œäººç±»æ›´å…·æˆ˜ç•¥æ€§å’Œå…¬å¹³æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°åµŒå…¥åˆ°å•†ä¸šè°ˆåˆ¤å’Œç¾¤ä½“åè°ƒç­‰åä½œæ€§äººç±»æ´»åŠ¨ä¸­ï¼Œè¯„ä¼°å®ƒä»¬èƒ½å¤Ÿå®ç°çš„æ€§èƒ½æå‡ä»¥åŠå®ƒä»¬å¦‚ä½•åœ¨åŠ¨æ€ã€å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­äº¤äº’å˜å¾—è‡³å…³é‡è¦ã€‚ä¸åœ¨è‰¯å¥½æŒ‡å®šæ¡ä»¶ä¸‹è¡¨ç°å‡ºè‰²çš„ä¼ ç»Ÿç»Ÿè®¡æ™ºèƒ½ä½“ï¼ˆå¦‚è´å¶æ–¯æ¨¡å‹ï¼‰ä¸åŒï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥æ¨å¹¿åˆ°å„ç§çœŸå®åœºæ™¯ï¼Œä»è€Œå¼•å‘å…³äºå®ƒä»¬çš„ç­–ç•¥å’Œè¡Œä¸ºä¸äººç±»å’Œå…¶ä»–æ™ºèƒ½ä½“ç±»å‹ç›¸æ¯”å¦‚ä½•çš„æ–°é—®é¢˜ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨ç›¸åŒçš„æ¡ä»¶ä¸‹æ¯”è¾ƒäº†äººç±»ï¼ˆN = 216ï¼‰ã€LLMï¼ˆGPT-4oã€Gemini 1.5 Proï¼‰å’Œè´å¶æ–¯æ™ºèƒ½ä½“åœ¨åŠ¨æ€è°ˆåˆ¤ç¯å¢ƒä¸­çš„ç»“æœå’Œè¡Œä¸ºåŠ¨æ€ã€‚è´å¶æ–¯æ™ºèƒ½ä½“é€šè¿‡æ¿€è¿›çš„ä¼˜åŒ–æå–äº†æœ€é«˜çš„å‰©ä½™ä»·å€¼ï¼Œä½†ä»£ä»·æ˜¯é¢‘ç¹çš„äº¤æ˜“æ‹’ç»ã€‚äººç±»å’ŒLLMå®ç°äº†ç›¸ä¼¼çš„æ€»ä½“å‰©ä½™ä»·å€¼ï¼Œä½†é€šè¿‡ä¸åŒçš„è¡Œä¸ºï¼šLLMå€¾å‘äºä¿å®ˆçš„ã€è®©æ­¥æ€§çš„äº¤æ˜“ï¼Œå¾ˆå°‘æ‹’ç»ï¼Œè€Œäººç±»åˆ™é‡‡ç”¨æ›´å…·æˆ˜ç•¥æ€§ã€å†’é™©æ€§å’Œå…¬å¹³å¯¼å‘çš„è¡Œä¸ºã€‚å› æ­¤ï¼Œæˆ‘ä»¬å‘ç°æ€§èƒ½å‡ç­‰â€”â€”æ™ºèƒ½ä½“è¯„ä¼°ä¸­çš„ä¸€ä¸ªå¸¸è§åŸºå‡†â€”â€”å¯èƒ½ä¼šæ©ç›–è¿‡ç¨‹å’Œå¯¹é½æ–¹é¢çš„æ ¹æœ¬å·®å¼‚ï¼Œè¿™å¯¹äºåœ¨å®é™…åè°ƒä»»åŠ¡ä¸­çš„å®é™…éƒ¨ç½²è‡³å…³é‡è¦ã€‚é€šè¿‡åœ¨åŒ¹é…çš„æ¡ä»¶ä¸‹å»ºç«‹åŸºç¡€è¡Œä¸ºåŸºçº¿ï¼Œè¿™é¡¹å·¥ä½œä¸ºæœªæ¥åœ¨æ›´åº”ç”¨åŒ–ã€å˜é‡ä¸°å¯Œçš„ç¯å¢ƒä¸­çš„ç ”ç©¶æä¾›äº†åŸºçº¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶åœ¨å¤šæ™ºèƒ½ä½“è®®ä»·åœºæ™¯ä¸­ï¼Œäººç±»ã€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œè´å¶æ–¯æ™ºèƒ½ä½“ä¹‹é—´çš„ç­–ç•¥å·®å¼‚å’Œæ€§èƒ½è¡¨ç°ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿçš„ç»Ÿè®¡æ™ºèƒ½ä½“ï¼ˆä¾‹å¦‚è´å¶æ–¯æ¨¡å‹ï¼‰ï¼Œè™½ç„¶åœ¨ç‰¹å®šæ¡ä»¶ä¸‹è¡¨ç°è‰¯å¥½ï¼Œä½†ç¼ºä¹åœ¨å¤æ‚ã€çœŸå®çš„è®®ä»·ç¯å¢ƒä¸­ä¸äººç±»è¡Œä¸ºè¿›è¡Œæœ‰æ•ˆå¯¹æ¯”çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œä»…ä»…å…³æ³¨æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚å‰©ä½™ä»·å€¼ï¼‰å¯èƒ½æ— æ³•æ­ç¤ºä¸åŒæ™ºèƒ½ä½“åœ¨è®®ä»·è¿‡ç¨‹ä¸­çš„è¡Œä¸ºæ¨¡å¼å’Œç­–ç•¥é€‰æ‹©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åœ¨ç›¸åŒçš„åŠ¨æ€è®®ä»·ç¯å¢ƒä¸‹ï¼Œå¯¹æ¯”äººç±»ã€LLMå’Œè´å¶æ–¯æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œç»“æœï¼Œä»è€Œæ­ç¤ºä¸åŒæ™ºèƒ½ä½“ç±»å‹åœ¨ç­–ç•¥é€‰æ‹©ä¸Šçš„æƒè¡¡ã€‚é€šè¿‡åˆ†æä¸åŒæ™ºèƒ½ä½“çš„è®®ä»·ç­–ç•¥ã€æ¥å—/æ‹’ç»äº¤æ˜“çš„é¢‘ç‡ä»¥åŠæœ€ç»ˆè·å¾—çš„å‰©ä½™ä»·å€¼ï¼Œè®ºæ–‡æ—¨åœ¨ç†è§£LLMåœ¨å¤šæ™ºèƒ½ä½“åä½œä¸­çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„æ™ºèƒ½ä½“è®¾è®¡æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é‡‡ç”¨å®éªŒç ”ç©¶çš„æ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªåŠ¨æ€è®®ä»·ç¯å¢ƒï¼Œå…¶ä¸­äººç±»ã€GPT-4oã€Gemini 1.5 Proå’Œè´å¶æ–¯æ™ºèƒ½ä½“ä½œä¸ºè®®ä»·å‚ä¸è€…ã€‚å®éªŒæµç¨‹åŒ…æ‹¬ï¼š1) å®šä¹‰è®®ä»·è§„åˆ™å’Œå¥–åŠ±æœºåˆ¶ï¼›2) æ‹›å‹Ÿäººç±»å‚ä¸è€…å¹¶è®¾ç½®å®éªŒæ¡ä»¶ï¼›3) ä½¿ç”¨LLMå’Œè´å¶æ–¯æ¨¡å‹æ„å»ºæ™ºèƒ½ä½“ï¼›4) åœ¨ç›¸åŒçš„è®®ä»·ç¯å¢ƒä¸‹è¿è¡Œå®éªŒï¼›5) æ”¶é›†å’Œåˆ†æå®éªŒæ•°æ®ï¼ŒåŒ…æ‹¬è®®ä»·ç»“æœã€äº¤æ˜“æ¥å—/æ‹’ç»æƒ…å†µå’Œæ™ºèƒ½ä½“çš„è¡Œä¸ºæ¨¡å¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) åœ¨ç›¸åŒçš„å®éªŒæ¡ä»¶ä¸‹ï¼Œå¯¹äººç±»ã€LLMå’Œè´å¶æ–¯æ™ºèƒ½ä½“è¿›è¡Œäº†å…¨é¢çš„å¯¹æ¯”ç ”ç©¶ï¼Œæ­ç¤ºäº†ä¸åŒæ™ºèƒ½ä½“ç±»å‹åœ¨è®®ä»·ç­–ç•¥ä¸Šçš„å·®å¼‚ï¼›2) å¼ºè°ƒäº†ä»…ä»…å…³æ³¨æ€§èƒ½æŒ‡æ ‡ï¼ˆå¦‚å‰©ä½™ä»·å€¼ï¼‰çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†éœ€è¦å…³æ³¨æ™ºèƒ½ä½“çš„è¡Œä¸ºæ¨¡å¼å’Œç­–ç•¥é€‰æ‹©ï¼›3) ä¸ºæœªæ¥åœ¨æ›´å¤æ‚ã€çœŸå®çš„è®®ä»·ç¯å¢ƒä¸­ç ”ç©¶æ™ºèƒ½ä½“è¡Œä¸ºæä¾›äº†åŸºçº¿ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åŠ¨æ€è®®ä»·ç¯å¢ƒçš„è®¾è®¡ï¼Œå…è®¸æ™ºèƒ½ä½“åœ¨å¤šè½®è®®ä»·ä¸­è°ƒæ•´ç­–ç•¥ï¼›2) å¥–åŠ±æœºåˆ¶çš„è®¾è®¡ï¼Œé¼“åŠ±æ™ºèƒ½ä½“æœ€å¤§åŒ–å‰©ä½™ä»·å€¼ï¼›3) å®éªŒæ¡ä»¶çš„æ§åˆ¶ï¼Œç¡®ä¿ä¸åŒæ™ºèƒ½ä½“åœ¨ç›¸åŒçš„æ¡ä»¶ä¸‹è¿›è¡Œè®®ä»·ï¼›4) è¡Œä¸ºæŒ‡æ ‡çš„é€‰å–ï¼Œç”¨äºé‡åŒ–æ™ºèƒ½ä½“çš„è®®ä»·ç­–ç•¥ï¼Œä¾‹å¦‚äº¤æ˜“æ¥å—/æ‹’ç»é¢‘ç‡ã€è®©æ­¥å¹…åº¦ç­‰ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ï¼ˆå¦‚æœæ¶‰åŠï¼‰åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè´å¶æ–¯æ™ºèƒ½ä½“é€šè¿‡æ¿€è¿›ä¼˜åŒ–è·å¾—æœ€é«˜å‰©ä½™ä»·å€¼ï¼Œä½†äº¤æ˜“æ‹’ç»ç‡é«˜ã€‚äººç±»å’ŒLLMçš„å‰©ä½™ä»·å€¼ç›¸è¿‘ï¼Œä½†è¡Œä¸ºæ¨¡å¼ä¸åŒï¼šLLMå€¾å‘äºä¿å®ˆè®©æ­¥ï¼Œäººç±»æ›´å…·æˆ˜ç•¥æ€§å’Œå…¬å¹³æ€§ã€‚è¿™è¡¨æ˜ï¼Œä»…å‡­æ€§èƒ½å‡ç­‰æ— æ³•å…¨é¢è¯„ä¼°æ™ºèƒ½ä½“çš„è¡Œä¸ºå’Œå¯¹é½ç¨‹åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´æ™ºèƒ½ã€æ›´äººæ€§åŒ–çš„AIåä½œç³»ç»Ÿï¼Œä¾‹å¦‚åœ¨å•†ä¸šè°ˆåˆ¤ã€ä¾›åº”é“¾ç®¡ç†ã€èµ„æºåˆ†é…ç­‰é¢†åŸŸã€‚é€šè¿‡ç†è§£LLMä¸äººç±»åœ¨ç­–ç•¥ä¸Šçš„å·®å¼‚ï¼Œå¯ä»¥è®¾è®¡å‡ºä¸äººç±»æ›´æœ‰æ•ˆåä½œçš„AIæ™ºèƒ½ä½“ï¼Œæå‡åä½œæ•ˆç‡å’Œæ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºè¯„ä¼°å’Œæ”¹è¿›AIæ™ºèƒ½ä½“çš„è¡Œä¸ºæ¨¡å¼æä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) are increasingly embedded in collaborative human activities such as business negotiations and group coordination, it becomes critical to evaluate both the performance gains they can achieve and how they interact in dynamic, multi-agent environments. Unlike traditional statistical agents such as Bayesian models, which may excel under well-specified conditions, large language models (LLMs) can generalize across diverse, real-world scenarios, raising new questions about how their strategies and behaviors compare to those of humans and other agent types. In this work, we compare outcomes and behavioral dynamics across humans (N = 216), LLMs (GPT-4o, Gemini 1.5 Pro), and Bayesian agents in a dynamic negotiation setting under identical conditions. Bayesian agents extract the highest surplus through aggressive optimization, at the cost of frequent trade rejections. Humans and LLMs achieve similar overall surplus, but through distinct behaviors: LLMs favor conservative, concessionary trades with few rejections, while humans employ more strategic, risk-taking, and fairness-oriented behaviors. Thus, we find that performance parity -- a common benchmark in agent evaluation -- can conceal fundamental differences in process and alignment, which are critical for practical deployment in real-world coordination tasks. By establishing foundational behavioral baselines under matched conditions, this work provides a baseline for future studies in more applied, variable-rich environments.

