---
layout: default
title: Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization
---

# Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09321" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09321v1</a>
  <a href="https://arxiv.org/pdf/2509.09321.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09321v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09321v1', 'Towards Adaptive ML Benchmarks: Web-Agent-Driven Construction, Domain Expansion, and Metric Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hangyi Jia, Yuxi Qian, Hanwen Tong, Xinhui Wu, Lin Chen, Feng Wei

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTAM Benchï¼Œä¸€ä¸ªåŸºäºWeb Agenté©±åŠ¨çš„è‡ªé€‚åº”æœºå™¨å­¦ä¹ åŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMåœ¨ç«¯åˆ°ç«¯MLä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æœºå™¨å­¦ä¹ åŸºå‡†` `LLM Agent` `è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ` `Web Agent` `éš¾åº¦å»ºæ¨¡` `å¤šæ¨¡æ€æ•°æ®` `ç«¯åˆ°ç«¯ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰MLåŸºå‡†æµ‹è¯•åœ¨ä»»åŠ¡è¦†ç›–ã€é¢†åŸŸå¤šæ ·æ€§å’Œéš¾åº¦å»ºæ¨¡æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å……åˆ†è¯„ä¼°LLMä»£ç†åœ¨çœŸå®åœºæ™¯ä¸‹çš„èƒ½åŠ›ã€‚
2. TAM Benchåˆ©ç”¨Web Agentè‡ªåŠ¨ä»å¤šä¸ªå¹³å°æ”¶é›†å’Œæ„å»ºMLä»»åŠ¡ï¼Œå¹¶é‡‡ç”¨æ’è¡Œæ¦œé©±åŠ¨çš„æœºåˆ¶è¿›è¡Œéš¾åº¦å»ºæ¨¡ã€‚
3. TAM Benchæä¾›å¤šç»´åº¦è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«æ€§èƒ½ã€æ ¼å¼åˆè§„æ€§ã€çº¦æŸéµå®ˆå’Œä»»åŠ¡æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æ„å»ºäº†ä¸åŒè§„æ¨¡çš„åŸºå‡†å­é›†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æœ€æ–°è¿›å±•å‚¬ç”Ÿäº†é€šç”¨ä»£ç†ï¼Œèƒ½å¤Ÿè‡ªåŠ¨åŒ–ç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®åˆ†æã€ç‰¹å¾å·¥ç¨‹ã€æ¨¡å‹è®­ç»ƒå’Œç«èµ›è§£å†³ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†åœ¨ä»»åŠ¡è¦†ç›–èŒƒå›´ã€é¢†åŸŸå¤šæ ·æ€§ã€éš¾åº¦å»ºæ¨¡å’Œè¯„ä¼°ä¸¥æ ¼æ€§æ–¹é¢ä»ç„¶æœ‰é™ï¼Œæ— æ³•æ•æ‰æ­¤ç±»ä»£ç†åœ¨å®é™…ç¯å¢ƒä¸­çš„å…¨éƒ¨èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†TAM Benchï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ ·åŒ–ã€çœŸå®ä¸”ç»“æ„åŒ–çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°åŸºäºLLMçš„ä»£ç†åœ¨ç«¯åˆ°ç«¯MLä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚TAM Benchå…·æœ‰ä¸‰ä¸ªå…³é”®åˆ›æ–°ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªåŸºäºæµè§ˆå™¨è‡ªåŠ¨åŒ–å’ŒLLMçš„ä»»åŠ¡è·å–ç³»ç»Ÿï¼Œå¯ä»¥è‡ªåŠ¨ä»Kaggleã€AIcrowdå’ŒBiendataç­‰å¹³å°æ”¶é›†å’Œæ„å»ºMLæŒ‘æˆ˜ï¼Œæ¶µç›–å¤šç§ä»»åŠ¡ç±»å‹å’Œæ•°æ®æ¨¡æ€ï¼ˆä¾‹å¦‚ï¼Œè¡¨æ ¼ã€æ–‡æœ¬ã€å›¾åƒã€å›¾å½¢ã€éŸ³é¢‘ï¼‰ï¼›ï¼ˆ2ï¼‰ä¸€ç§åŸºäºæ’è¡Œæ¦œçš„éš¾åº¦å»ºæ¨¡æœºåˆ¶ï¼Œä½¿ç”¨å‚ä¸è€…æ•°é‡å’Œåˆ†æ•°åˆ†å¸ƒæ¥ä¼°è®¡ä»»åŠ¡å¤æ‚åº¦ï¼Œä»è€Œå®ç°å¯æ‰©å±•ä¸”å®¢è§‚çš„ä»»åŠ¡æ ¡å‡†ï¼›ï¼ˆ3ï¼‰ä¸€ä¸ªå¤šç»´åº¦è¯„ä¼°æ¡†æ¶ï¼ŒåŒ…å«æ€§èƒ½ã€æ ¼å¼åˆè§„æ€§ã€çº¦æŸéµå®ˆå’Œä»»åŠ¡æ³›åŒ–ã€‚åŸºäº150ä¸ªç²¾é€‰çš„AutoMLä»»åŠ¡ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸‰ä¸ªä¸åŒå¤§å°çš„åŸºå‡†å­é›†â€”â€”Liteã€Mediumå’ŒFullâ€”â€”ä¸“ä¸ºä¸åŒçš„è¯„ä¼°åœºæ™¯è€Œè®¾è®¡ã€‚Liteç‰ˆæœ¬åŒ…å«18ä¸ªä»»åŠ¡ï¼Œå¹¶åœ¨æ¨¡æ€å’Œéš¾åº¦çº§åˆ«ä¹‹é—´å®ç°äº†å¹³è¡¡è¦†ç›–ï¼Œå¯ä½œä¸ºæ—¥å¸¸åŸºå‡†æµ‹è¯•å’Œæ¯”è¾ƒç ”ç©¶çš„å®ç”¨æµ‹è¯•å¹³å°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æœºå™¨å­¦ä¹ åŸºå‡†æµ‹è¯•æ— æ³•å……åˆ†è¯„ä¼°LLMé©±åŠ¨çš„Agentåœ¨ç«¯åˆ°ç«¯MLä»»åŠ¡ä¸­çš„èƒ½åŠ›ã€‚è¿™äº›åŸºå‡†åœ¨ä»»åŠ¡è¦†ç›–èŒƒå›´ã€é¢†åŸŸå¤šæ ·æ€§ã€éš¾åº¦å»ºæ¨¡å’Œè¯„ä¼°ä¸¥æ ¼æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œæ— æ³•çœŸå®åæ˜ å®é™…åº”ç”¨åœºæ™¯ï¼Œé˜»ç¢äº†å¯¹LLM Agentèƒ½åŠ›çš„å…¨é¢è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTAM Benchçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨Web Agentè‡ªåŠ¨ä»å¤šä¸ªåœ¨çº¿å¹³å°æŠ“å–å’Œæ„å»ºMLä»»åŠ¡ï¼Œå¹¶ç»“åˆæ’è¡Œæ¦œä¿¡æ¯è¿›è¡Œéš¾åº¦å»ºæ¨¡ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªå¤šæ ·åŒ–ã€çœŸå®ä¸”ç»“æ„åŒ–çš„åŸºå‡†ã€‚é€šè¿‡å¤šç»´åº¦è¯„ä¼°æ¡†æ¶ï¼Œæ›´å…¨é¢åœ°è¯„ä¼°LLM Agentåœ¨ä¸åŒæ–¹é¢çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTAM Benchçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š(1) **ä»»åŠ¡è·å–ç³»ç»Ÿ**ï¼šåˆ©ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–å’ŒLLMä»Kaggleã€AIcrowdç­‰å¹³å°è‡ªåŠ¨æ”¶é›†å’Œæ„å»ºMLæŒ‘æˆ˜ï¼Œæ¶µç›–å¤šç§æ•°æ®æ¨¡æ€ã€‚(2) **éš¾åº¦å»ºæ¨¡æœºåˆ¶**ï¼šåŸºäºæ’è¡Œæ¦œæ•°æ®ï¼ˆå‚ä¸è€…æ•°é‡ã€åˆ†æ•°åˆ†å¸ƒï¼‰ä¼°è®¡ä»»åŠ¡å¤æ‚åº¦ï¼Œå®ç°å¯æ‰©å±•çš„ä»»åŠ¡éš¾åº¦æ ¡å‡†ã€‚(3) **å¤šç»´åº¦è¯„ä¼°æ¡†æ¶**ï¼šä»æ€§èƒ½ã€æ ¼å¼åˆè§„æ€§ã€çº¦æŸéµå®ˆå’Œä»»åŠ¡æ³›åŒ–å››ä¸ªç»´åº¦è¯„ä¼°LLM Agentçš„èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šTAM Benchçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è‡ªåŠ¨åŒ–ä»»åŠ¡è·å–å’Œéš¾åº¦å»ºæ¨¡æœºåˆ¶ã€‚ä¼ ç»Ÿçš„åŸºå‡†æµ‹è¯•é€šå¸¸éœ€è¦äººå·¥æ”¶é›†å’Œæ ‡æ³¨æ•°æ®ï¼Œè€—æ—¶ä¸”éš¾ä»¥æ‰©å±•ã€‚TAM Benché€šè¿‡Web Agentè‡ªåŠ¨å®Œæˆè¿™ä¸€è¿‡ç¨‹ï¼Œå¤§å¤§æé«˜äº†æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œåˆ©ç”¨æ’è¡Œæ¦œæ•°æ®è¿›è¡Œéš¾åº¦å»ºæ¨¡ï¼Œé¿å…äº†ä¸»è§‚åˆ¤æ–­ï¼Œå®ç°äº†æ›´å®¢è§‚çš„ä»»åŠ¡éš¾åº¦è¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ä»»åŠ¡è·å–æ–¹é¢ï¼Œä½¿ç”¨äº†LLMæ¥è§£æç½‘é¡µç»“æ„ï¼Œæå–ä»»åŠ¡æè¿°ã€æ•°æ®ä¸‹è½½é“¾æ¥ç­‰ä¿¡æ¯ã€‚åœ¨éš¾åº¦å»ºæ¨¡æ–¹é¢ï¼Œä½¿ç”¨äº†å‚ä¸è€…æ•°é‡å’Œåˆ†æ•°åˆ†å¸ƒçš„ç»Ÿè®¡é‡ï¼ˆå¦‚æ ‡å‡†å·®ï¼‰æ¥ä¼°è®¡ä»»åŠ¡çš„éš¾åº¦ã€‚åœ¨è¯„ä¼°æ–¹é¢ï¼Œè®¾è®¡äº†é’ˆå¯¹ä¸åŒç»´åº¦çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨æ ‡å‡†MLæŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ã€F1å€¼ï¼‰è¯„ä¼°æ€§èƒ½ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…è¯„ä¼°æ ¼å¼åˆè§„æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TAM Benchæ„å»ºäº†åŒ…å«150ä¸ªAutoMLä»»åŠ¡çš„åŸºå‡†ï¼Œå¹¶åˆ’åˆ†æˆLiteã€Mediumå’ŒFullä¸‰ä¸ªå­é›†ã€‚Liteç‰ˆæœ¬åŒ…å«18ä¸ªä»»åŠ¡ï¼Œè¦†ç›–å¤šç§æ¨¡æ€å’Œéš¾åº¦çº§åˆ«ï¼Œé€‚åˆæ—¥å¸¸åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœï¼ˆè®ºæ–‡ä¸­æœªæ˜ç¡®ç»™å‡ºå…·ä½“æ•°å€¼ï¼Œæ­¤å¤„ä¸ºæ¨æµ‹ï¼‰è¡¨æ˜ï¼ŒåŸºäºLLMçš„Agentåœ¨TAM Benchä¸Šè¡¨ç°å‡ºä¸€å®šçš„èƒ½åŠ›ï¼Œä½†ä»æœ‰æå‡ç©ºé—´ï¼Œå°¤å…¶æ˜¯åœ¨ä»»åŠ¡æ³›åŒ–å’Œçº¦æŸéµå®ˆæ–¹é¢ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TAM Benchå¯ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMé©±åŠ¨çš„Agentåœ¨ç«¯åˆ°ç«¯æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„èƒ½åŠ›ï¼Œä¾‹å¦‚AutoMLç³»ç»Ÿã€æ•°æ®ç§‘å­¦å®¶åŠ©æ‰‹ç­‰ã€‚è¯¥åŸºå‡†å¯ä»¥ä¿ƒè¿›ç›¸å…³ç®—æ³•çš„å¼€å‘å’Œæ”¹è¿›ï¼ŒåŠ é€ŸLLMåœ¨å®é™…MLåº”ç”¨ä¸­çš„è½åœ°ã€‚æ­¤å¤–ï¼ŒTAM Benchçš„è‡ªåŠ¨åŒ–ä»»åŠ¡æ„å»ºæ–¹æ³•ä¹Ÿå¯ä»¥æ¨å¹¿åˆ°å…¶ä»–é¢†åŸŸçš„åŸºå‡†æµ‹è¯•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in large language models (LLMs) have enabled the emergence of general-purpose agents for automating end-to-end machine learning (ML) workflows, including data analysis, feature engineering, model training, and competition solving. However, existing benchmarks remain limited in task coverage, domain diversity, difficulty modeling, and evaluation rigor, failing to capture the full capabilities of such agents in realistic settings. We present TAM Bench, a diverse, realistic, and structured benchmark for evaluating LLM-based agents on end-to-end ML tasks. TAM Bench features three key innovations: (1) A browser automation and LLM-based task acquisition system that automatically collects and structures ML challenges from platforms such as Kaggle, AIcrowd, and Biendata, spanning multiple task types and data modalities (e.g., tabular, text, image, graph, audio); (2) A leaderboard-driven difficulty modeling mechanism that estimates task complexity using participant counts and score dispersion, enabling scalable and objective task calibration; (3) A multi-dimensional evaluation framework incorporating performance, format compliance, constraint adherence, and task generalization. Based on 150 curated AutoML tasks, we construct three benchmark subsets of different sizes -- Lite, Medium, and Full -- designed for varying evaluation scenarios. The Lite version, with 18 tasks and balanced coverage across modalities and difficulty levels, serves as a practical testbed for daily benchmarking and comparative studies.

