---
layout: default
title: Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation
---

# Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15210" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15210v1</a>
  <a href="https://arxiv.org/pdf/2509.15210.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15210v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15210v1', 'Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chen Si, Qianyi Wu, Chaitanya Amballa, Romit Roy Choudhury

**åˆ†ç±»**: cs.SD, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMesh-infused Neural Acoustic Field (MiNAF)ï¼Œåˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯æå‡é«˜ä¿çœŸRIRç”Ÿæˆæ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æˆ¿é—´è„‰å†²å“åº”ç”Ÿæˆ` `ç¥ç»å£°å­¦å»ºæ¨¡` `æ˜¾å¼å‡ ä½•ä¿¡æ¯` `ç¥ç»éšå¼è¡¨ç¤º` `å£°éŸ³æ¨¡æ‹Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¥ç»éšå¼å£°å­¦å»ºæ¨¡æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨ç¯å¢ƒä¸­çš„æ˜¾å¼å‡ ä½•ä¿¡æ¯ï¼Œé™åˆ¶äº†RIRç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚
2. MiNAFé€šè¿‡æŸ¥è¯¢æˆ¿é—´ç½‘æ ¼æå–è·ç¦»åˆ†å¸ƒä½œä¸ºæ˜¾å¼å±€éƒ¨å‡ ä½•è¡¨ç¤ºï¼ŒæŒ‡å¯¼ç¥ç»ç½‘ç»œæ›´å‡†ç¡®åœ°é¢„æµ‹RIRã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMiNAFåœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œå¹¶åœ¨æœ‰é™è®­ç»ƒæ ·æœ¬ä¸‹å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€¼çœŸçš„å£°éŸ³æ¨¡æ‹Ÿåœ¨è®¸å¤šåº”ç”¨ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚æˆ¿é—´è„‰å†²å“åº”(RIR)æ˜¯å£°éŸ³æ¨¡æ‹Ÿä¸­çš„ä¸€ä¸ªå…³é”®è¦ç´ ï¼Œå®ƒæè¿°äº†å£°éŸ³åœ¨ç»™å®šç©ºé—´å†…ä»å£°æºä¼ æ’­åˆ°å¬è€…çš„è¿‡ç¨‹ã€‚æœ€è¿‘çš„ç ”ç©¶å·²ç»åº”ç”¨ç¥ç»éšå¼æ–¹æ³•ï¼Œåˆ©ç”¨ä»ç¯å¢ƒä¸­æ”¶é›†çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚åœºæ™¯å›¾åƒï¼‰æ¥å­¦ä¹ RIRã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å¹¶æ²¡æœ‰æœ‰æ•ˆåœ°åˆ©ç”¨ç¯å¢ƒä¸­çš„æ˜¾å¼å‡ ä½•ä¿¡æ¯ã€‚ä¸ºäº†è¿›ä¸€æ­¥æŒ–æ˜ç¥ç»éšå¼æ¨¡å‹åœ¨ç›´æ¥å‡ ä½•ç‰¹å¾æ–¹é¢çš„æ½œåŠ›ï¼Œæˆ‘ä»¬æå‡ºäº†Mesh-infused Neural Acoustic Field (MiNAF)ï¼Œå®ƒåœ¨ç»™å®šä½ç½®æŸ¥è¯¢ç²—ç³™çš„æˆ¿é—´ç½‘æ ¼ï¼Œå¹¶æå–è·ç¦»åˆ†å¸ƒä½œä¸ºå±€éƒ¨ä¸Šä¸‹æ–‡çš„æ˜¾å¼è¡¨ç¤ºã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨æ˜ï¼Œç»“åˆæ˜¾å¼çš„å±€éƒ¨å‡ ä½•ç‰¹å¾å¯ä»¥æ›´å¥½åœ°æŒ‡å¯¼ç¥ç»ç½‘ç»œç”Ÿæˆæ›´å‡†ç¡®çš„RIRé¢„æµ‹ã€‚é€šè¿‡ä¸ä¼ ç»Ÿæ–¹æ³•å’Œæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•è¿›è¡Œæ¯”è¾ƒï¼Œæˆ‘ä»¬è¡¨æ˜MiNAFåœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½è¡¨ç°å‡ºç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬éªŒè¯äº†MiNAFåœ¨è®­ç»ƒæ ·æœ¬æœ‰é™çš„æ•°æ®é›†ä¸­çš„é²æ£’æ€§ï¼Œå±•ç¤ºäº†åœ¨é«˜ä¿çœŸå£°éŸ³æ¨¡æ‹Ÿæ–¹é¢çš„è¿›æ­¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é«˜ä¿çœŸæˆ¿é—´è„‰å†²å“åº”(RIR)ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰åŸºäºç¥ç»éšå¼è¡¨ç¤ºçš„æ–¹æ³•ï¼Œè™½ç„¶åˆ©ç”¨äº†ç¯å¢ƒä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚åœºæ™¯å›¾åƒï¼‰ï¼Œä½†æœªèƒ½å……åˆ†åˆ©ç”¨æ˜¾å¼çš„å‡ ä½•ä¿¡æ¯ï¼Œå¯¼è‡´RIRç”Ÿæˆç²¾åº¦å—é™ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥å‡†ç¡®æ•æ‰å£°éŸ³åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ä¼ æ’­ç‰¹æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ˜¾å¼çš„å‡ ä½•ä¿¡æ¯èå…¥åˆ°ç¥ç»éšå¼å£°å­¦å»ºæ¨¡ä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æŸ¥è¯¢æˆ¿é—´çš„ç²—ç³™ç½‘æ ¼ï¼Œæå–å£°æºå’Œæ¥æ”¶å™¨å‘¨å›´çš„è·ç¦»åˆ†å¸ƒï¼Œä½œä¸ºå±€éƒ¨å‡ ä½•ä¸Šä¸‹æ–‡çš„æ˜¾å¼è¡¨ç¤ºã€‚è¿™ç§æ˜¾å¼å‡ ä½•ä¿¡æ¯èƒ½å¤Ÿæ›´å¥½åœ°æŒ‡å¯¼ç¥ç»ç½‘ç»œå­¦ä¹ å£°éŸ³ä¼ æ’­çš„ç‰©ç†è§„å¾‹ï¼Œä»è€Œæé«˜RIRç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMiNAF (Mesh-infused Neural Acoustic Field) çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æˆ¿é—´ç½‘æ ¼æ„å»ºï¼šåˆ©ç”¨åœºæ™¯ä¿¡æ¯æ„å»ºæˆ¿é—´çš„ç²—ç³™ç½‘æ ¼æ¨¡å‹ã€‚2) å±€éƒ¨å‡ ä½•ç‰¹å¾æå–ï¼šåœ¨ç»™å®šå£°æºå’Œæ¥æ”¶å™¨ä½ç½®ï¼ŒæŸ¥è¯¢æˆ¿é—´ç½‘æ ¼ï¼Œæå–è·ç¦»åˆ†å¸ƒä½œä¸ºå±€éƒ¨å‡ ä½•ç‰¹å¾ã€‚3) ç¥ç»éšå¼å£°å­¦åœºå»ºæ¨¡ï¼šåˆ©ç”¨ç¥ç»ç½‘ç»œå­¦ä¹ ä»å±€éƒ¨å‡ ä½•ç‰¹å¾åˆ°RIRçš„æ˜ å°„å…³ç³»ã€‚4) RIRç”Ÿæˆï¼šæ ¹æ®è¾“å…¥çš„å£°æºå’Œæ¥æ”¶å™¨ä½ç½®ï¼Œç”Ÿæˆç›¸åº”çš„RIRã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†æ˜¾å¼çš„å±€éƒ¨å‡ ä½•ç‰¹å¾ï¼ˆè·ç¦»åˆ†å¸ƒï¼‰èå…¥åˆ°ç¥ç»éšå¼å£°å­¦å»ºæ¨¡ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMiNAFä¸å†ä»…ä»…ä¾èµ–éšå¼çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨å‡ ä½•ä¿¡æ¯æ¥æŒ‡å¯¼RIRç”Ÿæˆã€‚è¿™ç§æ˜¾å¼å‡ ä½•ä¿¡æ¯çš„å¼•å…¥ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰å£°éŸ³ä¼ æ’­çš„ç‰©ç†è§„å¾‹ï¼Œä»è€Œæé«˜RIRç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è·ç¦»åˆ†å¸ƒçš„è¡¨ç¤ºæ–¹å¼ï¼šè®ºæ–‡é‡‡ç”¨ä¸€ç§æœ‰æ•ˆçš„è·ç¦»åˆ†å¸ƒè¡¨ç¤ºæ–¹æ³•ï¼Œèƒ½å¤Ÿæ•æ‰å£°æºå’Œæ¥æ”¶å™¨å‘¨å›´çš„å‡ ä½•ç»“æ„ã€‚2) ç¥ç»ç½‘ç»œç»“æ„ï¼šè®ºæ–‡è®¾è®¡äº†ä¸€ç§é€‚åˆå¤„ç†å±€éƒ¨å‡ ä½•ç‰¹å¾çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ ä»è·ç¦»åˆ†å¸ƒåˆ°RIRçš„æ˜ å°„å…³ç³»ã€‚3) æŸå¤±å‡½æ•°ï¼šè®ºæ–‡é‡‡ç”¨åˆé€‚çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä½¿å¾—ç”Ÿæˆçš„RIRèƒ½å¤Ÿå°½å¯èƒ½åœ°é€¼è¿‘çœŸå®çš„RIRã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMiNAFåœ¨å„ç§è¯„ä¼°æŒ‡æ ‡ä¸Šéƒ½ä¼˜äºä¼ ç»Ÿçš„å’Œæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨è®­ç»ƒæ ·æœ¬æœ‰é™çš„æƒ…å†µä¸‹ï¼ŒMiNAFä»ç„¶èƒ½å¤Ÿä¿æŒè‰¯å¥½çš„æ€§èƒ½ï¼Œå±•ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§ã€‚è¿™è¡¨æ˜MiNAFèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯ï¼Œä»è€Œå‡å°‘å¯¹å¤§é‡è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆå¼€å‘ã€å£°å­¦è®¾è®¡ç­‰é¢†åŸŸã€‚é€šè¿‡ç”Ÿæˆé€¼çœŸçš„RIRï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„å¬è§‰ä½“éªŒï¼Œæé«˜è™šæ‹Ÿç¯å¢ƒçš„çœŸå®æ„Ÿã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºå£°å­¦ç¯å¢ƒçš„æ¨¡æ‹Ÿå’Œä¼˜åŒ–ï¼Œä¾‹å¦‚åœ¨å»ºç­‘è®¾è®¡ä¸­é¢„æµ‹æˆ¿é—´çš„å£°å­¦æ•ˆæœï¼Œæˆ–åœ¨éŸ³é¢‘åæœŸåˆ¶ä½œä¸­è°ƒæ•´å£°éŸ³çš„ç©ºé—´æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Realistic sound simulation plays a critical role in many applications. A key element in sound simulation is the room impulse response (RIR), which characterizes how sound propagates from a source to a listener within a given space. Recent studies have applied neural implicit methods to learn RIR using context information collected from the environment, such as scene images. However, these approaches do not effectively leverage explicit geometric information from the environment. To further exploit the potential of neural implicit models with direct geometric features, we present Mesh-infused Neural Acoustic Field (MiNAF), which queries a rough room mesh at given locations and extracts distance distributions as an explicit representation of local context. Our approach demonstrates that incorporating explicit local geometric features can better guide the neural network in generating more accurate RIR predictions. Through comparisons with conventional and state-of-the-art baseline methods, we show that MiNAF performs competitively across various evaluation metrics. Furthermore, we verify the robustness of MiNAF in datasets with limited training samples, demonstrating an advance in high-fidelity sound simulation.

