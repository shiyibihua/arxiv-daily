---
layout: default
title: Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling
---

# Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15336" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15336v1</a>
  <a href="https://arxiv.org/pdf/2509.15336.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15336v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15336v1', 'Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Humam Kourani, Anton Antonov, Alessandro Berti, Wil M. P. van der Aalst

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: The Version of Record of this contribution will be published in the proceedings of the 2nd International Workshop on Generative AI for Process Mining (GenAI4PM 2025). This preprint has not undergone peer review or any post-submission improvements or corrections

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶LLMåœ¨è¿‡ç¨‹å»ºæ¨¡ä¸­çŸ¥è¯†é©±åŠ¨çš„å¹»è§‰ç°è±¡ï¼Œæ­ç¤ºå…¶å›ºæœ‰çŸ¥è¯†ä¸è¯æ®å†²çªæ—¶çš„å¯é æ€§é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†é©±åŠ¨å¹»è§‰` `ä¸šåŠ¡æµç¨‹å»ºæ¨¡` `è¯æ®é©±åŠ¨æ¨ç†` `å¯é æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. LLMåœ¨åˆ†æä»»åŠ¡ä¸­ä¾èµ–é¢„è®­ç»ƒçŸ¥è¯†ï¼Œä½†ä¹Ÿå› æ­¤å­˜åœ¨çŸ¥è¯†é©±åŠ¨çš„å¹»è§‰é£é™©ï¼Œå³è¾“å‡ºä¸è¾“å…¥è¯æ®å†²çªã€‚
2. è¯¥ç ”ç©¶é€šè¿‡åœ¨ä¸šåŠ¡æµç¨‹å»ºæ¨¡ä»»åŠ¡ä¸­è¯„ä¼°LLMï¼Œæ¢ç©¶å…¶åœ¨è¯æ®ä¸é¢„è®­ç»ƒçŸ¥è¯†å†²çªæ—¶çš„å¯é æ€§ã€‚
3. å®éªŒè®¾è®¡äº†æ ‡å‡†å’Œéå…¸å‹æµç¨‹åœºæ™¯ï¼Œè¡¡é‡LLMå¯¹è¯æ®çš„å¿ å®åº¦ï¼Œå¹¶æå‡ºè¯„ä¼°æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨åˆ†æä»»åŠ¡ä¸­çš„æ•ˆç”¨æºäºå…¶æµ·é‡çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œè¿™ä½¿å…¶èƒ½å¤Ÿè§£é‡Šæ¨¡ç³Šçš„è¾“å…¥å¹¶æ¨æ–­ç¼ºå¤±çš„ä¿¡æ¯ã€‚ç„¶è€Œï¼Œè¿™ç§èƒ½åŠ›ä¹Ÿå¸¦æ¥äº†ä¸€ç§å…³é”®é£é™©ï¼Œæˆ‘ä»¬ç§°ä¹‹ä¸ºçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰ï¼šå³æ¨¡å‹çš„è¾“å‡ºä¸æ˜ç¡®çš„æºè¯æ®ç›¸çŸ›ç›¾ï¼Œå› ä¸ºå®ƒè¢«æ¨¡å‹å¹¿ä¹‰çš„å†…éƒ¨çŸ¥è¯†æ‰€è¦†ç›–ã€‚æœ¬æ–‡é€šè¿‡è¯„ä¼°LLMåœ¨è‡ªåŠ¨åŒ–è¿‡ç¨‹å»ºæ¨¡ä»»åŠ¡ä¸­çš„è¡¨ç°æ¥ç ”ç©¶è¿™ç§ç°è±¡ï¼Œè¯¥ä»»åŠ¡çš„ç›®æ ‡æ˜¯ä»ç»™å®šçš„æºå·¥ä»¶ç”Ÿæˆæ­£å¼çš„ä¸šåŠ¡æµç¨‹æ¨¡å‹ã€‚ä¸šåŠ¡æµç¨‹ç®¡ç†ï¼ˆBPMï¼‰é¢†åŸŸä¸ºè¿™é¡¹ç ”ç©¶æä¾›äº†ä¸€ä¸ªç†æƒ³çš„èƒŒæ™¯ï¼Œå› ä¸ºè®¸å¤šæ ¸å¿ƒä¸šåŠ¡æµç¨‹éµå¾ªæ ‡å‡†åŒ–æ¨¡å¼ï¼Œä½¿å¾—LLMå¾ˆå¯èƒ½æ‹¥æœ‰å¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å¼ã€‚æˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹å—æ§å®éªŒï¼Œæ—¨åœ¨åˆ›å»ºæä¾›çš„è¯æ®ä¸LLMçš„èƒŒæ™¯çŸ¥è¯†ä¹‹é—´å­˜åœ¨æ•…æ„å†²çªçš„åœºæ™¯ã€‚æˆ‘ä»¬ä½¿ç”¨æè¿°æ ‡å‡†å’Œæ•…æ„éå…¸å‹è¿‡ç¨‹ç»“æ„çš„è¾“å…¥æ¥è¡¡é‡LLMå¯¹æ‰€æä¾›è¯æ®çš„å¿ å®åº¦ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ç§è¯„ä¼°è¿™ç§å…³é”®å¯é æ€§é—®é¢˜çš„æ–¹æ³•ï¼Œå¹¶æé«˜äº†äººä»¬å¯¹åœ¨ä»»ä½•åŸºäºè¯æ®çš„é¢†åŸŸä¸­ä¸¥æ ¼éªŒè¯AIç”Ÿæˆå·¥ä»¶çš„å¿…è¦æ€§çš„è®¤è¯†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªåŠ¨åŒ–ä¸šåŠ¡æµç¨‹å»ºæ¨¡ä»»åŠ¡ä¸­å‡ºç°çš„â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åˆ©ç”¨LLMè¿›è¡Œæ­¤ç±»ä»»åŠ¡æ—¶ï¼Œå¾€å¾€å¿½ç•¥äº†LLMå¯èƒ½å­˜åœ¨çš„å…ˆéªŒçŸ¥è¯†ä¸è¾“å…¥è¯æ®ä¹‹é—´çš„å†²çªï¼Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆä¸è¯æ®ä¸ç¬¦çš„é”™è¯¯æ¨¡å‹ã€‚è¿™ç§å¹»è§‰ç°è±¡é™ä½äº†LLMåœ¨è¯æ®é©±åŠ¨å‹é¢†åŸŸçš„å¯é æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è®¾è®¡å—æ§å®éªŒï¼Œäººä¸ºåœ°åˆ¶é€ LLMçš„å…ˆéªŒçŸ¥è¯†ä¸è¾“å…¥è¯æ®ä¹‹é—´çš„å†²çªï¼Œä»è€Œé‡åŒ–å’Œåˆ†æLLMçš„â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€ç°è±¡ã€‚é€šè¿‡å¯¹æ¯”LLMåœ¨å¤„ç†æ ‡å‡†å’Œéæ ‡å‡†ä¸šåŠ¡æµç¨‹æ—¶çš„è¡¨ç°ï¼Œè¯„ä¼°å…¶å¯¹è¾“å…¥è¯æ®çš„å¿ å®ç¨‹åº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶é‡‡ç”¨å®éªŒæ–¹æ³•ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1.  **åœºæ™¯è®¾è®¡**ï¼šè®¾è®¡åŒ…å«æ ‡å‡†å’Œéæ ‡å‡†ä¸šåŠ¡æµç¨‹æè¿°çš„è¾“å…¥æ•°æ®ï¼Œå…¶ä¸­éæ ‡å‡†æµç¨‹ä¸LLMå¯èƒ½å­˜åœ¨çš„å¸¸è§æµç¨‹æ¨¡å¼ç›¸æ‚–ã€‚
2.  **æ¨¡å‹æ¨ç†**ï¼šå°†è®¾è®¡çš„è¾“å…¥æ•°æ®è¾“å…¥åˆ°LLMä¸­ï¼Œè®©å…¶ç”Ÿæˆä¸šåŠ¡æµç¨‹æ¨¡å‹ã€‚
3.  **ç»“æœè¯„ä¼°**ï¼šå¯¹æ¯”LLMç”Ÿæˆçš„æ¨¡å‹ä¸è¾“å…¥è¯æ®ï¼Œè¯„ä¼°æ¨¡å‹æ˜¯å¦å¿ å®äºè¯æ®ï¼Œå¹¶é‡åŒ–â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€ç¨‹åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š
1.  é¦–æ¬¡æ˜ç¡®æå‡ºäº†â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€è¿™ä¸€æ¦‚å¿µï¼Œå¹¶å°†å…¶åº”ç”¨äºLLMåœ¨ä¸šåŠ¡æµç¨‹å»ºæ¨¡é¢†åŸŸçš„åˆ†æã€‚
2.  è®¾è®¡äº†ä¸€ç§å—æ§å®éªŒæ–¹æ³•ï¼Œç”¨äºé‡åŒ–å’Œåˆ†æLLMçš„â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€ç°è±¡ã€‚
3.  å¼ºè°ƒäº†åœ¨è¯æ®é©±åŠ¨å‹é¢†åŸŸä¸­ï¼Œå¯¹AIç”Ÿæˆå·¥ä»¶è¿›è¡Œä¸¥æ ¼éªŒè¯çš„å¿…è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå®éªŒçš„å…³é”®è®¾è®¡åœ¨äºï¼š
1.  é€‰æ‹©ä¸šåŠ¡æµç¨‹å»ºæ¨¡ä½œä¸ºç ”ç©¶åœºæ™¯ï¼Œå› ä¸ºè¯¥é¢†åŸŸå­˜åœ¨å¤§é‡æ ‡å‡†åŒ–çš„æµç¨‹æ¨¡å¼ï¼ŒLLMå¾ˆå¯èƒ½å…·å¤‡ç›¸å…³çš„å…ˆéªŒçŸ¥è¯†ã€‚
2.  è®¾è®¡éæ ‡å‡†æµç¨‹æ—¶ï¼Œæ•…æ„è¿åå¸¸è§çš„æµç¨‹æ¨¡å¼ï¼Œä»è€Œåˆ¶é€ LLMçš„å…ˆéªŒçŸ¥è¯†ä¸è¾“å…¥è¯æ®ä¹‹é—´çš„å†²çªã€‚
3.  è¯„ä¼°æŒ‡æ ‡ä¸»è¦å…³æ³¨LLMç”Ÿæˆçš„æ¨¡å‹æ˜¯å¦å¿ å®äºè¾“å…¥è¯æ®ï¼Œä¾‹å¦‚æ˜¯å¦æ­£ç¡®è¯†åˆ«æµç¨‹ä¸­çš„æ´»åŠ¨ã€é¡ºåºå’Œåˆ†æ”¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥ç ”ç©¶é€šè¿‡å—æ§å®éªŒï¼Œé‡åŒ–äº†LLMåœ¨ä¸šåŠ¡æµç¨‹å»ºæ¨¡ä»»åŠ¡ä¸­â€œçŸ¥è¯†é©±åŠ¨çš„å¹»è§‰â€ç°è±¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“è¾“å…¥è¯æ®ä¸LLMçš„é¢„è®­ç»ƒçŸ¥è¯†å†²çªæ—¶ï¼ŒLLMå€¾å‘äºç”Ÿæˆç¬¦åˆå…¶é¢„è®­ç»ƒçŸ¥è¯†çš„æ¨¡å‹ï¼Œè€Œå¿½ç•¥è¾“å…¥è¯æ®ã€‚è¿™è¡¨æ˜LLMåœ¨è¯æ®é©±åŠ¨å‹ä»»åŠ¡ä¸­å­˜åœ¨ä¸€å®šçš„å¯é æ€§é£é™©ï¼Œéœ€è¦è¿›è¡Œä¸¥æ ¼çš„éªŒè¯å’Œæ ¡å‡†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦LLMè¿›è¡Œè¯æ®é©±åŠ¨å‹æ¨ç†å’Œå†³ç­–çš„é¢†åŸŸï¼Œä¾‹å¦‚æ³•å¾‹æ–‡ä»¶åˆ†æã€åŒ»ç–—è¯Šæ–­è¾…åŠ©ã€é‡‘èé£é™©è¯„ä¼°ç­‰ã€‚é€šè¿‡è¯†åˆ«å’Œç¼“è§£LLMçš„çŸ¥è¯†é©±åŠ¨å¹»è§‰ï¼Œå¯ä»¥æé«˜AIç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œä¿ƒè¿›å…¶åœ¨å…³é”®é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The utility of Large Language Models (LLMs) in analytical tasks is rooted in their vast pre-trained knowledge, which allows them to interpret ambiguous inputs and infer missing information. However, this same capability introduces a critical risk of what we term knowledge-driven hallucination: a phenomenon where the model's output contradicts explicit source evidence because it is overridden by the model's generalized internal knowledge. This paper investigates this phenomenon by evaluating LLMs on the task of automated process modeling, where the goal is to generate a formal business process model from a given source artifact. The domain of Business Process Management (BPM) provides an ideal context for this study, as many core business processes follow standardized patterns, making it likely that LLMs possess strong pre-trained schemas for them. We conduct a controlled experiment designed to create scenarios with deliberate conflict between provided evidence and the LLM's background knowledge. We use inputs describing both standard and deliberately atypical process structures to measure the LLM's fidelity to the provided evidence. Our work provides a methodology for assessing this critical reliability issue and raises awareness of the need for rigorous validation of AI-generated artifacts in any evidence-based domain.

