---
layout: default
title: Spatial Audio Motion Understanding and Reasoning
---

# Spatial Audio Motion Understanding and Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14666" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14666v1</a>
  <a href="https://arxiv.org/pdf/2509.14666.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14666v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14666v1', 'Spatial Audio Motion Understanding and Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arvind Krishna Sridhar, Yinyi Guo, Erik Visser

**åˆ†ç±»**: cs.SD, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: 5 pages, 2 figures, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£ä¸æ¨ç†æ¡†æ¶ï¼Œè§£å†³åŠ¨æ€å£°æºåœºæ™¯ç†è§£éš¾é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç©ºé—´éŸ³é¢‘` `è¿åŠ¨ç†è§£` `éŸ³é¢‘æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `éŸ³é¢‘Grounding` `åˆ°è¾¾æ–¹å‘ä¼°è®¡` `å£°æºå®šä½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®ç†è§£åŠ¨æ€å£°æºåœºæ™¯ï¼Œç¼ºä¹å¯¹äº‹ä»¶ç©ºé—´å±æ€§å’Œè¿åŠ¨æ¨¡å¼çš„æœ‰æ•ˆå»ºæ¨¡ã€‚
2. æå‡ºä¸€ç§ç»“åˆç©ºé—´éŸ³é¢‘ç¼–ç å™¨å’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¡†æ¶ï¼Œåˆ©ç”¨ç»“æ„åŒ–ç©ºé—´å±æ€§è¿›è¡Œæ¨ç†ã€‚
3. æ„å»ºæ–°çš„ç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£ä¸æ¨ç†æ•°æ®é›†ï¼Œå®éªŒè¯æ˜è¯¥æ¡†æ¶ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡è‡´åŠ›äºç©ºé—´éŸ³é¢‘ç†è§£ï¼Œé‡ç‚¹å…³æ³¨å¯¹ç§»åŠ¨å£°æºçš„æ¨ç†ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç©ºé—´éŸ³é¢‘ç¼–ç å™¨ï¼Œç”¨äºå¤„ç†ç©ºé—´éŸ³é¢‘ï¼Œä»¥æ£€æµ‹å¤šä¸ªé‡å äº‹ä»¶ï¼Œå¹¶ä¼°è®¡å®ƒä»¬çš„ç©ºé—´å±æ€§ï¼Œå³åˆ°è¾¾æ–¹å‘ï¼ˆDoAï¼‰å’Œå£°æºè·ç¦»ã€‚ä¸ºäº†æ¨å¹¿åˆ°æœªè§è¿‡çš„äº‹ä»¶ï¼Œæˆ‘ä»¬ç»“åˆäº†ä¸€ä¸ªéŸ³é¢‘ grounding æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶å°†éŸ³é¢‘ç‰¹å¾ä¸è¯­ä¹‰éŸ³é¢‘ç±»æ–‡æœ¬åµŒå…¥å¯¹é½ã€‚å…¶æ¬¡ï¼Œä¸ºäº†å›ç­”å…³äºæ¶‰åŠç§»åŠ¨å£°æºçš„åŠ¨æ€éŸ³é¢‘åœºæ™¯çš„å¤æ‚æŸ¥è¯¢ï¼Œæˆ‘ä»¬ä»¥æ¨¡å‹æå–çš„ç»“æ„åŒ–ç©ºé—´å±æ€§ä¸ºæ¡ä»¶ï¼Œä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚æœ€åï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£å’Œæ¨ç†åŸºå‡†æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†æˆ‘ä»¬çš„æ¡†æ¶ç›¸å¯¹äºåŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç©ºé—´éŸ³é¢‘åœºæ™¯ä¸­ï¼Œç‰¹åˆ«æ˜¯å­˜åœ¨ç§»åŠ¨å£°æºæ—¶ï¼Œæœºå™¨éš¾ä»¥ç†è§£å’Œæ¨ç†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ã€åŠ¨æ€çš„éŸ³é¢‘ç¯å¢ƒæ—¶ï¼Œæ— æ³•å‡†ç¡®åœ°æ£€æµ‹å’Œå®šä½å¤šä¸ªé‡å äº‹ä»¶ï¼Œä¹Ÿéš¾ä»¥å¯¹è¿™äº›äº‹ä»¶çš„ç©ºé—´å±æ€§ï¼ˆå¦‚DoAå’Œè·ç¦»ï¼‰è¿›è¡Œæœ‰æ•ˆå»ºæ¨¡ï¼Œæ›´æ— æ³•è¿›è¡Œé«˜å±‚æ¬¡çš„æ¨ç†å’Œç†è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç©ºé—´éŸ³é¢‘å¤„ç†ä¸è‡ªç„¶è¯­è¨€å¤„ç†ç›¸ç»“åˆï¼Œåˆ©ç”¨ç©ºé—´éŸ³é¢‘ç¼–ç å™¨æå–ç»“æ„åŒ–çš„ç©ºé—´å±æ€§ï¼Œç„¶ååˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œæ¨ç†ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£éŸ³é¢‘åœºæ™¯ä¸­çš„äº‹ä»¶åŠå…¶ç©ºé—´å…³ç³»ï¼Œå¹¶å›ç­”å…³äºåŠ¨æ€éŸ³é¢‘åœºæ™¯çš„å¤æ‚é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š1) ç©ºé—´éŸ³é¢‘ç¼–ç é˜¶æ®µï¼šä½¿ç”¨ç©ºé—´éŸ³é¢‘ç¼–ç å™¨å¤„ç†è¾“å…¥éŸ³é¢‘ï¼Œæ£€æµ‹å¤šä¸ªé‡å äº‹ä»¶ï¼Œå¹¶ä¼°è®¡æ¯ä¸ªäº‹ä»¶çš„åˆ°è¾¾æ–¹å‘ï¼ˆDoAï¼‰å’Œå£°æºè·ç¦»ã€‚åŒæ—¶ï¼Œåˆ©ç”¨éŸ³é¢‘ grounding æ¨¡å‹å°†éŸ³é¢‘ç‰¹å¾ä¸è¯­ä¹‰éŸ³é¢‘ç±»æ–‡æœ¬åµŒå…¥å¯¹é½ï¼Œä»¥æé«˜å¯¹æœªè§äº‹ä»¶çš„æ³›åŒ–èƒ½åŠ›ã€‚2) æ¨ç†é˜¶æ®µï¼šå°†æå–çš„ç»“æ„åŒ–ç©ºé—´å±æ€§ä½œä¸ºæ¡ä»¶ï¼Œè¾“å…¥åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­ï¼ŒLLMæ ¹æ®è¿™äº›ä¿¡æ¯å›ç­”å…³äºåŠ¨æ€éŸ³é¢‘åœºæ™¯çš„å¤æ‚æŸ¥è¯¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆæå–ç©ºé—´éŸ³é¢‘å±æ€§ï¼ˆDoAå’Œè·ç¦»ï¼‰çš„ç¼–ç å™¨ï¼Œå¹¶ç»“åˆéŸ³é¢‘ grounding æ¨¡å‹æé«˜æ³›åŒ–èƒ½åŠ›ã€‚2) å°†æå–çš„ç»“æ„åŒ–ç©ºé—´å±æ€§ä¸å¤§å‹è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œå®ç°äº†å¯¹åŠ¨æ€éŸ³é¢‘åœºæ™¯çš„å¤æ‚æ¨ç†ã€‚3) æ„å»ºäº†ä¸€ä¸ªæ–°çš„ç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£å’Œæ¨ç†åŸºå‡†æ•°æ®é›†ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„èµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šç©ºé—´éŸ³é¢‘ç¼–ç å™¨å¯èƒ½é‡‡ç”¨äº†æ·±åº¦ç¥ç»ç½‘ç»œç»“æ„ï¼Œä¾‹å¦‚å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼Œç”¨äºæå–éŸ³é¢‘ç‰¹å¾å¹¶ä¼°è®¡DoAå’Œè·ç¦»ã€‚éŸ³é¢‘ grounding æ¨¡å‹å¯èƒ½ä½¿ç”¨äº†äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œå°†éŸ³é¢‘ç‰¹å¾ä¸æ–‡æœ¬åµŒå…¥è¿›è¡Œå¯¹é½ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é€‰æ‹©å’Œå¾®è°ƒä¹Ÿæ˜¯å…³é”®ï¼Œéœ€è¦æ ¹æ®ä»»åŠ¡çš„ç‰¹ç‚¹è¿›è¡Œé€‰æ‹©ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡å¯èƒ½åŒ…æ‹¬DoAå’Œè·ç¦»ä¼°è®¡çš„å›å½’æŸå¤±ï¼Œä»¥åŠéŸ³é¢‘ grounding çš„å¯¹æ¯”å­¦ä¹ æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æ„å»ºäº†ä¸€ä¸ªæ–°çš„ç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£ä¸æ¨ç†åŸºå‡†æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤æ•°æ®é›†ä¸ŠéªŒè¯äº†æ‰€æå‡ºæ¡†æ¶çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç©ºé—´éŸ³é¢‘ç†è§£å’Œæ¨ç†ä»»åŠ¡ä¸Šä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°æ£€æµ‹å’Œå®šä½å¤šä¸ªé‡å äº‹ä»¶ï¼Œå¹¶è¿›è¡Œæ›´æœ‰æ•ˆçš„æ¨ç†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®‰é˜²ã€æœºå™¨äººå¯¼èˆªã€è™šæ‹Ÿç°å®/å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å®‰é˜²ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æŠ€æœ¯è¯†åˆ«å¼‚å¸¸å£°éŸ³äº‹ä»¶å¹¶ç¡®å®šå…¶ç©ºé—´ä½ç½®ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„å®‰å…¨ç›‘æ§ã€‚åœ¨æœºå™¨äººå¯¼èˆªä¸­ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººç†è§£å‘¨å›´ç¯å¢ƒä¸­çš„å£°éŸ³äº‹ä»¶ï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œå¯¼èˆªå’Œäº¤äº’ã€‚åœ¨VR/ARä¸­ï¼Œå¯ä»¥æä¾›æ›´é€¼çœŸçš„ç©ºé—´éŸ³é¢‘ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spatial audio reasoning enables machines to interpret auditory scenes by understanding events and their spatial attributes. In this work, we focus on spatial audio understanding with an emphasis on reasoning about moving sources. First, we introduce a spatial audio encoder that processes spatial audio to detect multiple overlapping events and estimate their spatial attributes, Direction of Arrival (DoA) and source distance, at the frame level. To generalize to unseen events, we incorporate an audio grounding model that aligns audio features with semantic audio class text embeddings via a cross-attention mechanism. Second, to answer complex queries about dynamic audio scenes involving moving sources, we condition a large language model (LLM) on structured spatial attributes extracted by our model. Finally, we introduce a spatial audio motion understanding and reasoning benchmark dataset and demonstrate our framework's performance against the baseline model.

