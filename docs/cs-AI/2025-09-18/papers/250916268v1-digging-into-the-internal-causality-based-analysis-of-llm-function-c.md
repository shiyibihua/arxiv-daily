---
layout: default
title: Digging Into the Internal: Causality-Based Analysis of LLM Function Calling
---

# Digging Into the Internal: Causality-Based Analysis of LLM Function Calling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16268" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16268v1</a>
  <a href="https://arxiv.org/pdf/2509.16268.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16268v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16268v1', 'Digging Into the Internal: Causality-Based Analysis of LLM Function Calling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenlan Ji, Daoyuan Wu, Wenxuan Wang, Pingchuan Ma, Shuai Wang, Lei Ma

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºå› æœåˆ†æçš„å¤§è¯­è¨€æ¨¡å‹å‡½æ•°è°ƒç”¨æœºåˆ¶ç ”ç©¶ï¼Œæ˜¾è‘—æå‡LLMå®‰å…¨æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å‡½æ•°è°ƒç”¨` `å› æœåˆ†æ` `å®‰å…¨é²æ£’æ€§` `æ¶æ„è¾“å…¥æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰å¯¹å‡½æ•°è°ƒç”¨å¦‚ä½•å½±å“LLMå†…éƒ¨è¡Œä¸ºçš„æœºåˆ¶ç†è§£ä¸è¶³ï¼Œé™åˆ¶äº†å…¶æ›´å¹¿æ³›çš„åº”ç”¨ã€‚
2. åˆ©ç”¨å› æœåˆ†ææ–¹æ³•ï¼Œé€šè¿‡å±‚çº§å’Œtokençº§çš„å¹²é¢„ï¼Œæ·±å…¥å‰–æå‡½æ•°è°ƒç”¨å¯¹LLMè®¡ç®—é€»è¾‘çš„å½±å“ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå‡½æ•°è°ƒç”¨åœ¨æé«˜LLMå®‰å…¨é²æ£’æ€§æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œæ¶æ„è¾“å…¥æ£€æµ‹æ€§èƒ½å¹³å‡æå‡135%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡½æ•°è°ƒç”¨(FC)å·²æˆä¸ºä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œèƒ½å¤Ÿä¿ƒè¿›å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’å¹¶æ‰§è¡Œç»“æ„åŒ–ä»»åŠ¡ã€‚ç„¶è€Œï¼Œå®ƒå½±å“æ¨¡å‹è¡Œä¸ºçš„æœºåˆ¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°é™¤äº†FCçš„å¸¸è§„ç”¨æ³•å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥æ˜¾è‘—æé«˜LLMå¯¹ç”¨æˆ·æŒ‡ä»¤çš„ä¾ä»æ€§ã€‚è¿™äº›è§‚å¯Ÿä¿ƒä½¿æˆ‘ä»¬åˆ©ç”¨å› æœå…³ç³»è¿™ä¸€ç»å…¸åˆ†ææ–¹æ³•æ¥ç ”ç©¶FCåœ¨LLMå†…éƒ¨çš„å·¥ä½œåŸç†ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å±‚çº§å’Œtokençº§çš„å› æœå¹²é¢„ï¼Œä»¥å‰–æFCåœ¨å“åº”ç”¨æˆ·æŸ¥è¯¢æ—¶å¯¹æ¨¡å‹å†…éƒ¨è®¡ç®—é€»è¾‘çš„å½±å“ã€‚æˆ‘ä»¬çš„åˆ†æè¯å®äº†FCçš„å·¨å¤§å½±å“ï¼Œå¹¶æ­ç¤ºäº†å¯¹å…¶æœºåˆ¶çš„å‡ ä¸ªæ·±å…¥è§è§£ã€‚ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯æˆ‘ä»¬çš„å‘ç°ï¼Œæˆ‘ä»¬è¿›è¡Œäº†å¹¿æ³›çš„å®éªŒï¼Œæ¯”è¾ƒäº†åŸºäºFCçš„æŒ‡ä»¤ä¸ä¼ ç»Ÿæç¤ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬ä¸“æ³¨äºå¢å¼ºLLMå®‰å…¨é²æ£’æ€§è¿™ä¸€å…³é”®çš„LLMåº”ç”¨åœºæ™¯ï¼Œå¹¶åœ¨ä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¯„ä¼°äº†å››ä¸ªä¸»æµLLMã€‚ç»“æœéå¸¸æ˜¾è‘—ï¼šåœ¨æ£€æµ‹æ¶æ„è¾“å…¥æ–¹é¢ï¼ŒFCæ˜¾ç¤ºå‡ºæ¯”ä¼ ç»Ÿæç¤ºæ–¹æ³•å¹³å‡çº¦135%çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶åœ¨æé«˜LLMåœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œèƒ½åŠ›æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨æ·±å…¥ç†è§£å‡½æ•°è°ƒç”¨ï¼ˆFunction Calling, FCï¼‰æŠ€æœ¯å¦‚ä½•å½±å“å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å†…éƒ¨è¿ä½œæœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨å“åº”ç”¨æˆ·æŸ¥è¯¢æ—¶ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹FCåœ¨LLMå†…éƒ¨è®¡ç®—é€»è¾‘ä¸­ä½œç”¨çš„ç»†ç²’åº¦åˆ†æï¼Œå¯¼è‡´æ— æ³•å……åˆ†å‘æŒ¥FCçš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ€§å’Œå¯é æ€§è‡³å…³é‡è¦çš„åº”ç”¨åœºæ™¯ä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å› æœåˆ†ææ–¹æ³•ï¼Œé€šè¿‡å¯¹LLMå†…éƒ¨çŠ¶æ€è¿›è¡Œå¹²é¢„ï¼Œè§‚å¯ŸFCå¯¹æ¨¡å‹è¡Œä¸ºçš„å½±å“ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æ­ç¤ºFCåœ¨ä¸åŒå±‚çº§å’Œtokençº§åˆ«ä¸Šçš„ä½œç”¨ï¼Œä»è€Œæ›´æ·±å…¥åœ°ç†è§£å…¶å·¥ä½œåŸç†ã€‚è¿™ç§å› æœåˆ†ææ–¹æ³•èƒ½å¤Ÿå…‹æœä¼ ç»Ÿé»‘ç›’åˆ†æçš„å±€é™æ€§ï¼Œæä¾›æ›´å…·è§£é‡Šæ€§çš„ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è®¾è®¡å®éªŒï¼Œä½¿ç”¨æˆ·æŸ¥è¯¢åŒ…å«æˆ–ä¸åŒ…å«å‡½æ•°è°ƒç”¨ï¼›2) å¯¹LLMçš„ä¸åŒå±‚çº§å’Œtokenè¿›è¡Œå› æœå¹²é¢„ï¼Œä¾‹å¦‚ï¼Œæ”¹å˜ç‰¹å®šå±‚çº§çš„æ¿€æ´»å€¼æˆ–å±è”½æŸäº›tokenï¼›3) è§‚å¯Ÿå¹²é¢„åLLMçš„è¾“å‡ºå˜åŒ–ï¼Œå¹¶åˆ†æè¿™äº›å˜åŒ–ä¸FCä¹‹é—´çš„å› æœå…³ç³»ï¼›4) é€šè¿‡å¯¹æ¯”å®éªŒï¼ŒéªŒè¯FCåœ¨æé«˜LLMå®‰å…¨é²æ£’æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å› æœåˆ†ææ–¹æ³•åº”ç”¨äºç ”ç©¶LLMçš„å‡½æ•°è°ƒç”¨æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„é»‘ç›’åˆ†ææ–¹æ³•ç›¸æ¯”ï¼Œå› æœåˆ†æèƒ½å¤Ÿæ›´æ¸…æ™°åœ°æ­ç¤ºFCå¯¹LLMå†…éƒ¨è®¡ç®—é€»è¾‘çš„å½±å“ï¼Œä»è€Œä¸ºä¼˜åŒ–FCçš„ä½¿ç”¨æä¾›æ›´å¯é çš„ä¾æ®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å‘ç°FCä¸ä»…å¯ä»¥ç”¨äºä¸å¤–éƒ¨ç³»ç»Ÿäº¤äº’ï¼Œè¿˜å¯ä»¥æ˜¾è‘—æé«˜LLMå¯¹ç”¨æˆ·æŒ‡ä»¤çš„ä¾ä»æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„å› æœå¹²é¢„æ–¹æ³•ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨Do-calculusè¿›è¡Œå› æœæ¨æ–­ï¼›2) è®¾è®¡ç»†ç²’åº¦çš„å¹²é¢„ç­–ç•¥ï¼Œä¾‹å¦‚ï¼Œåœ¨ä¸åŒçš„å±‚çº§å’Œtokençº§åˆ«è¿›è¡Œå¹²é¢„ï¼›3) ä½¿ç”¨åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼Œå‡†ç¡®ç‡ã€å¬å›ç‡å’ŒF1å€¼ï¼Œæ¥è¡¡é‡LLMçš„å®‰å…¨é²æ£’æ€§ï¼›4) é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„LLMå’Œæ•°æ®é›†è¿›è¡Œå®éªŒï¼Œä»¥ç¡®ä¿ç»“æœçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºå‡½æ•°è°ƒç”¨çš„æŒ‡ä»¤åœ¨æ£€æµ‹æ¶æ„è¾“å…¥æ–¹é¢ï¼Œæ¯”ä¼ ç»Ÿæç¤ºæ–¹æ³•å¹³å‡æå‡äº†çº¦135%ã€‚è¿™ä¸€æ˜¾è‘—çš„æ€§èƒ½æå‡è¡¨æ˜ï¼Œå‡½æ•°è°ƒç”¨åœ¨æé«˜LLMå®‰å…¨é²æ£’æ€§æ–¹é¢å…·æœ‰å·¨å¤§çš„æ½œåŠ›ã€‚è¯¥ç ”ç©¶åœ¨å››ä¸ªä¸»æµLLMå’Œä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœå…·æœ‰è¾ƒå¼ºçš„è¯´æœåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œä¾‹å¦‚ï¼šæ¶æ„ä»£ç æ£€æµ‹ã€è™šå‡ä¿¡æ¯è¯†åˆ«ã€æœ‰å®³å†…å®¹è¿‡æ»¤ç­‰ã€‚é€šè¿‡ä¼˜åŒ–å‡½æ•°è°ƒç”¨æœºåˆ¶ï¼Œå¯ä»¥ä½¿LLMæ›´å¥½åœ°ç†è§£ç”¨æˆ·æ„å›¾ï¼Œå¹¶é¿å…äº§ç”Ÿä¸å®‰å…¨æˆ–ä¸é€‚å½“çš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¸ºå¼€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„LLMæä¾›ç†è®ºæŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Function calling (FC) has emerged as a powerful technique for facilitating large language models (LLMs) to interact with external systems and perform structured tasks. However, the mechanisms through which it influences model behavior remain largely under-explored. Besides, we discover that in addition to the regular usage of FC, this technique can substantially enhance the compliance of LLMs with user instructions. These observations motivate us to leverage causality, a canonical analysis method, to investigate how FC works within LLMs. In particular, we conduct layer-level and token-level causal interventions to dissect FC's impact on the model's internal computational logic when responding to user queries. Our analysis confirms the substantial influence of FC and reveals several in-depth insights into its mechanisms. To further validate our findings, we conduct extensive experiments comparing the effectiveness of FC-based instructions against conventional prompting methods. We focus on enhancing LLM safety robustness, a critical LLM application scenario, and evaluate four mainstream LLMs across two benchmark datasets. The results are striking: FC shows an average performance improvement of around 135% over conventional prompting methods in detecting malicious inputs, demonstrating its promising potential to enhance LLM reliability and capability in practical applications.

