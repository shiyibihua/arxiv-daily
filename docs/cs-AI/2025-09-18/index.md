---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-09-18
---

# cs.AIï¼ˆ2025-09-18ï¼‰

ğŸ“Š å…± **16** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (13 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (13 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250915151v2-exploring-how-audio-effects-alter-emotion-with-foundation-models.html">Exploring How Audio Effects Alter Emotion with Foundation Models</a></td>
  <td>åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹æ¢ç´¢éŸ³é¢‘æ•ˆæœå¯¹æƒ…æ„Ÿçš„å½±å“</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15151v2" data-paper-url="./papers/250915151v2-exploring-how-audio-effects-alter-emotion-with-foundation-models.html" onclick="toggleFavorite(this, '2509.15151v2', 'Exploring How Audio Effects Alter Emotion with Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250915336v1-knowledge-driven-hallucination-in-large-language-models-an-empirical.html">Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling</a></td>
  <td>ç ”ç©¶LLMåœ¨è¿‡ç¨‹å»ºæ¨¡ä¸­çŸ¥è¯†é©±åŠ¨çš„å¹»è§‰ç°è±¡ï¼Œæ­ç¤ºå…¶å›ºæœ‰çŸ¥è¯†ä¸è¯æ®å†²çªæ—¶çš„å¯é æ€§é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15336v1" data-paper-url="./papers/250915336v1-knowledge-driven-hallucination-in-large-language-models-an-empirical.html" onclick="toggleFavorite(this, '2509.15336v1', 'Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250914627v1-towards-human-like-multimodal-conversational-agent-by-generating-eng.html">Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech</a></td>
  <td>æå‡ºåŸºäºå¤šæ¨¡æ€LLMçš„å¯¹è¯Agentï¼Œé€šè¿‡ç”Ÿæˆæ›´å…·è¡¨ç°åŠ›çš„è¯­éŸ³æå‡äººæœºäº¤äº’ä½“éªŒã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14627v1" data-paper-url="./papers/250914627v1-towards-human-like-multimodal-conversational-agent-by-generating-eng.html" onclick="toggleFavorite(this, '2509.14627v1', 'Towards Human-like Multimodal Conversational Agent by Generating Engaging Speech')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250914623v1-automating-modelica-module-generation-using-large-language-models-a-.html">Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language</a></td>
  <td>åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨åŒ–ç”ŸæˆModelicaæ¨¡å—ï¼Œæå‡å»ºç­‘æ§åˆ¶æè¿°è¯­è¨€å¼€å‘æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14623v1" data-paper-url="./papers/250914623v1-automating-modelica-module-generation-using-large-language-models-a-.html" onclick="toggleFavorite(this, '2509.14623v1', 'Automating Modelica Module Generation Using Large Language Models: A Case Study on Building Control Description Language')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250916275v1-securefixagent-a-hybrid-llm-agent-for-automated-python-static-vulner.html">SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair</a></td>
  <td>SecureFixAgentï¼šä¸€ç§æ··åˆLLM Agentï¼Œç”¨äºè‡ªåŠ¨åŒ–Pythoné™æ€æ¼æ´ä¿®å¤ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16275v1" data-paper-url="./papers/250916275v1-securefixagent-a-hybrid-llm-agent-for-automated-python-static-vulner.html" onclick="toggleFavorite(this, '2509.16275v1', 'SecureFixAgent: A Hybrid LLM Agent for Automated Python Static Vulnerability Repair')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250914956v1-sentinel-agents-for-secure-and-trustworthy-agentic-ai-in-multi-agent.html">Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems</a></td>
  <td>æå‡ºå“¨å…µä»£ç†ä»¥å¢å¼ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å®‰å…¨æ€§ä¸å¯ä¿¡æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14956v1" data-paper-url="./papers/250914956v1-sentinel-agents-for-secure-and-trustworthy-agentic-ai-in-multi-agent.html" onclick="toggleFavorite(this, '2509.14956v1', 'Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250914803v2-onlinemate-an-llm-based-multi-agent-companion-system-for-cognitive-s.html">OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning</a></td>
  <td>OnlineMateï¼šåŸºäºLLMçš„å¤šæ™ºèƒ½ä½“åŒä¼´ç³»ç»Ÿï¼Œç”¨äºåœ¨çº¿å­¦ä¹ ä¸­çš„è®¤çŸ¥æ”¯æŒ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14803v2" data-paper-url="./papers/250914803v2-onlinemate-an-llm-based-multi-agent-companion-system-for-cognitive-s.html" onclick="toggleFavorite(this, '2509.14803v2', 'OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250916268v1-digging-into-the-internal-causality-based-analysis-of-llm-function-c.html">Digging Into the Internal: Causality-Based Analysis of LLM Function Calling</a></td>
  <td>åŸºäºå› æœåˆ†æçš„å¤§è¯­è¨€æ¨¡å‹å‡½æ•°è°ƒç”¨æœºåˆ¶ç ”ç©¶ï¼Œæ˜¾è‘—æå‡LLMå®‰å…¨æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.16268v1" data-paper-url="./papers/250916268v1-digging-into-the-internal-causality-based-analysis-of-llm-function-c.html" onclick="toggleFavorite(this, '2509.16268v1', 'Digging Into the Internal: Causality-Based Analysis of LLM Function Calling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250914666v1-spatial-audio-motion-understanding-and-reasoning.html">Spatial Audio Motion Understanding and Reasoning</a></td>
  <td>æå‡ºç©ºé—´éŸ³é¢‘è¿åŠ¨ç†è§£ä¸æ¨ç†æ¡†æ¶ï¼Œè§£å†³åŠ¨æ€å£°æºåœºæ™¯ç†è§£éš¾é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14666v1" data-paper-url="./papers/250914666v1-spatial-audio-motion-understanding-and-reasoning.html" onclick="toggleFavorite(this, '2509.14666v1', 'Spatial Audio Motion Understanding and Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250914662v1-understanding-the-thinking-process-of-reasoning-models-a-perspective.html">Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld's Episode Theory</a></td>
  <td>åº”ç”¨Schoenfeldæƒ…æ™¯ç†è®ºåˆ†æå¤§å‹æ¨ç†æ¨¡å‹ï¼Œæ­ç¤ºå…¶æ€ç»´è¿‡ç¨‹ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14662v1" data-paper-url="./papers/250914662v1-understanding-the-thinking-process-of-reasoning-models-a-perspective.html" onclick="toggleFavorite(this, '2509.14662v1', 'Understanding the Thinking Process of Reasoning Models: A Perspective from Schoenfeld&#39;s Episode Theory')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250914647v1-agentcompass-towards-reliable-evaluation-of-agentic-workflows-in-pro.html">AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production</a></td>
  <td>AgentCompassï¼šé¢å‘ç”Ÿäº§ç¯å¢ƒä¸­Agentå·¥ä½œæµçš„å¯é è¯„ä¼°æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14647v1" data-paper-url="./papers/250914647v1-agentcompass-towards-reliable-evaluation-of-agentic-workflows-in-pro.html" onclick="toggleFavorite(this, '2509.14647v1', 'AgentCompass: Towards Reliable Evaluation of Agentic Workflows in Production')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250914558v1-llm-jailbreak-detection-for-almost-free.html">LLM Jailbreak Detection for (Almost) Free!</a></td>
  <td>æå‡ºè¿‘ä¹é›¶æˆæœ¬çš„FJDæ–¹æ³•ï¼Œç”¨äºæ£€æµ‹å¤§è¯­è¨€æ¨¡å‹çš„è¶Šç‹±æ”»å‡»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14558v1" data-paper-url="./papers/250914558v1-llm-jailbreak-detection-for-almost-free.html" onclick="toggleFavorite(this, '2509.14558v1', 'LLM Jailbreak Detection for (Almost) Free!')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250914507v1-dekeynlu-enhancing-natural-language-to-sql-generation-through-task-d.html">DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction</a></td>
  <td>DeKeyNLUï¼šé€šè¿‡ä»»åŠ¡åˆ†è§£å’Œå…³é”®è¯æå–å¢å¼ºè‡ªç„¶è¯­è¨€åˆ°SQLçš„ç”Ÿæˆ</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.14507v1" data-paper-url="./papers/250914507v1-dekeynlu-enhancing-natural-language-to-sql-generation-through-task-d.html" onclick="toggleFavorite(this, '2509.14507v1', 'DeKeyNLU: Enhancing Natural Language to SQL Generation through Task Decomposition and Keyword Extraction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>14</td>
  <td><a href="./papers/250915217v1-generalizable-geometric-image-caption-synthesis.html">Generalizable Geometric Image Caption Synthesis</a></td>
  <td>æå‡ºRLVRæ–¹æ³•ä»¥è§£å†³å‡ ä½•å›¾åƒæè¿°ç”Ÿæˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15217v1" data-paper-url="./papers/250915217v1-generalizable-geometric-image-caption-synthesis.html" onclick="toggleFavorite(this, '2509.15217v1', 'Generalizable Geometric Image Caption Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250915103v2-vulnerable-agent-identification-in-large-scale-multi-agent-reinforce.html">Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning</a></td>
  <td>æå‡ºHAD-MFCæ¡†æ¶ï¼Œç”¨äºå¤§è§„æ¨¡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­è„†å¼±æ™ºèƒ½ä½“çš„è¯†åˆ«ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15103v2" data-paper-url="./papers/250915103v2-vulnerable-agent-identification-in-large-scale-multi-agent-reinforce.html" onclick="toggleFavorite(this, '2509.15103v2', 'Vulnerable Agent Identification in Large-Scale Multi-Agent Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>16</td>
  <td><a href="./papers/250915210v1-explicit-context-driven-neural-acoustic-modeling-for-high-fidelity-r.html">Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation</a></td>
  <td>æå‡ºMesh-infused Neural Acoustic Field (MiNAF)ï¼Œåˆ©ç”¨æ˜¾å¼å‡ ä½•ä¿¡æ¯æå‡é«˜ä¿çœŸRIRç”Ÿæˆæ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15210v1" data-paper-url="./papers/250915210v1-explicit-context-driven-neural-acoustic-modeling-for-high-fidelity-r.html" onclick="toggleFavorite(this, '2509.15210v1', 'Explicit Context-Driven Neural Acoustic Modeling for High-Fidelity RIR Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)