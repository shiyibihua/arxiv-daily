---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-12-23
---

# cs.AIï¼ˆ2025-12-23ï¼‰

ğŸ“Š å…± **29** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (18 ğŸ”—1)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
<a href="#æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics" class="interest-badge">æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (18 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251220168v1-odysseus-jailbreaking-commercial-multimodal-llm-integrated-systems-v.html">Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography</a></td>
  <td>Odysseusï¼šåˆ©ç”¨åŒé‡éšå†™æœ¯ç ´è§£å•†ä¸šå¤šæ¨¡æ€LLMé›†æˆç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20168v1" data-paper-url="./papers/251220168v1-odysseus-jailbreaking-commercial-multimodal-llm-integrated-systems-v.html" onclick="toggleFavorite(this, '2512.20168v1', 'Odysseus: Jailbreaking Commercial Multimodal LLM-integrated Systems via Dual Steganography')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251220586v1-automated-stereotactic-radiosurgery-planning-using-a-human-in-the-lo.html">Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent</a></td>
  <td>SAGEï¼šåŸºäºäººæœºååŒæ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç«‹ä½“å®šå‘æ”¾å°„å¤–ç§‘è®¡åˆ’ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20586v1" data-paper-url="./papers/251220586v1-automated-stereotactic-radiosurgery-planning-using-a-human-in-the-lo.html" onclick="toggleFavorite(this, '2512.20586v1', 'Automated stereotactic radiosurgery planning using a human-in-the-loop reasoning large language model agent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251220436v1-dual-encoder-transformer-based-multimodal-learning-for-ischemic-stro.html">Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI</a></td>
  <td>æå‡ºåŸºäºåŒç¼–ç å™¨Transformerçš„Ischemic Strokeç—…ç¶åˆ†å‰²æ–¹æ³•ï¼Œæå‡DWIå’ŒADCå›¾åƒçš„åˆ†å‰²ç²¾åº¦ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20436v1" data-paper-url="./papers/251220436v1-dual-encoder-transformer-based-multimodal-learning-for-ischemic-stro.html" onclick="toggleFavorite(this, '2512.20436v1', 'Dual-Encoder Transformer-Based Multimodal Learning for Ischemic Stroke Lesion Segmentation Using Diffusion MRI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/251220328v1-toward-explaining-large-language-models-in-software-engineering-task.html">Toward Explaining Large Language Models in Software Engineering Tasks</a></td>
  <td>æå‡ºFeatureSHAPï¼Œç”¨äºè§£é‡Šè½¯ä»¶å·¥ç¨‹ä»»åŠ¡ä¸­çš„å¤§å‹è¯­è¨€æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20328v1" data-paper-url="./papers/251220328v1-toward-explaining-large-language-models-in-software-engineering-task.html" onclick="toggleFavorite(this, '2512.20328v1', 'Toward Explaining Large Language Models in Software Engineering Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251220548v1-advancing-multimodal-teacher-sentiment-analysisthe-large-scale-t-med.html">Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model</a></td>
  <td>æ„å»ºT-MEDæ•°æ®é›†ä¸AAM-TSAæ¨¡å‹ä»¥æå‡æ•™å¸ˆæƒ…æ„Ÿåˆ†æå‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20548v1" data-paper-url="./papers/251220548v1-advancing-multimodal-teacher-sentiment-analysisthe-large-scale-t-med.html" onclick="toggleFavorite(this, '2512.20548v1', 'Advancing Multimodal Teacher Sentiment Analysis:The Large-Scale T-MED Dataset & The Effective AAM-TSA Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251220333v1-syncraft-guiding-large-language-models-to-predict-edit-sequences-for.html">SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization</a></td>
  <td>SynCraftï¼šå¼•å¯¼å¤§è¯­è¨€æ¨¡å‹é¢„æµ‹ç¼–è¾‘åºåˆ—ï¼Œä¼˜åŒ–åˆ†å­åˆæˆå¯è¡Œæ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20333v1" data-paper-url="./papers/251220333v1-syncraft-guiding-large-language-models-to-predict-edit-sequences-for.html" onclick="toggleFavorite(this, '2512.20333v1', 'SynCraft: Guiding Large Language Models to Predict Edit Sequences for Molecular Synthesizability Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/251220206v1-tongsim-a-general-platform-for-simulating-intelligent-machines.html">TongSIM: A General Platform for Simulating Intelligent Machines</a></td>
  <td>TongSIMï¼šé€šç”¨æ™ºèƒ½æœºå™¨æ¨¡æ‹Ÿå¹³å°ï¼Œæ”¯æŒå…·èº«æ™ºèƒ½ä½“è®­ç»ƒä¸è¯„ä¼°</td>
  <td class="tags-cell"><span class="paper-tag">embodied AI</span> <span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20206v1" data-paper-url="./papers/251220206v1-tongsim-a-general-platform-for-simulating-intelligent-machines.html" onclick="toggleFavorite(this, '2512.20206v1', 'TongSIM: A General Platform for Simulating Intelligent Machines')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251220162v1-concept-generalization-in-humans-and-large-language-models-insights-.html">Concept Generalization in Humans and Large Language Models: Insights from the Number Game</a></td>
  <td>é€šè¿‡æ•°å­—æ¸¸æˆå¯¹æ¯”äººç±»ä¸å¤§è¯­è¨€æ¨¡å‹åœ¨æ¦‚å¿µæ³›åŒ–ä¸Šçš„å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20162v1" data-paper-url="./papers/251220162v1-concept-generalization-in-humans-and-large-language-models-insights-.html" onclick="toggleFavorite(this, '2512.20162v1', 'Concept Generalization in Humans and Large Language Models: Insights from the Number Game')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/251220344v1-a-deepseek-powered-ai-system-for-automated-chest-radiograph-interpre.html">A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice</a></td>
  <td>DeepSeekèµ‹èƒ½çš„AIç³»ç»ŸJanus-Pro-CXRï¼Œç”¨äºä¸´åºŠèƒ¸éƒ¨Xå…‰ç‰‡è‡ªåŠ¨åˆ¤è¯»</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20344v1" data-paper-url="./papers/251220344v1-a-deepseek-powered-ai-system-for-automated-chest-radiograph-interpre.html" onclick="toggleFavorite(this, '2512.20344v1', 'A DeepSeek-Powered AI System for Automated Chest Radiograph Interpretation in Clinical Practice')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/251220074v1-reason2decide-rationale-driven-multi-task-learning.html">Reason2Decide: Rationale-Driven Multi-Task Learning</a></td>
  <td>Reason2Decideï¼šä¸€ç§åŸºäºç†ç”±é©±åŠ¨çš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œæå‡ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿçš„é¢„æµ‹ç²¾åº¦å’Œè§£é‡Šä¸€è‡´æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20074v1" data-paper-url="./papers/251220074v1-reason2decide-rationale-driven-multi-task-learning.html" onclick="toggleFavorite(this, '2512.20074v1', 'Reason2Decide: Rationale-Driven Multi-Task Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/251220387v1-generative-digital-twins-vision-language-simulation-models-for-execu.html">Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems</a></td>
  <td>æå‡ºè§†è§‰-è¯­è¨€æ¨¡æ‹Ÿæ¨¡å‹ï¼Œä»è‰å›¾å’Œæ–‡æœ¬ç”Ÿæˆå¯æ‰§è¡Œçš„å·¥ä¸šç³»ç»Ÿæ•°å­—å­ªç”Ÿã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20387v1" data-paper-url="./papers/251220387v1-generative-digital-twins-vision-language-simulation-models-for-execu.html" onclick="toggleFavorite(this, '2512.20387v1', 'Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/251220278v1-synthesizing-procedural-memory-challenges-and-architectures-in-autom.html">Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation</a></td>
  <td>æå‡ºä¸€ç§è‡ªåŠ¨å·¥ä½œæµç”Ÿæˆæ–¹æ³•ï¼Œè§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä»å·¥å…·ä½¿ç”¨è€…åˆ°å·¥ä½œæµæ¶æ„å¸ˆçš„è½¬å˜éš¾é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20278v1" data-paper-url="./papers/251220278v1-synthesizing-procedural-memory-challenges-and-architectures-in-autom.html" onclick="toggleFavorite(this, '2512.20278v1', 'Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251220245v1-memory-as-resonance-a-biomimetic-architecture-for-infinite-context-m.html">Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds</a></td>
  <td>æå‡ºåŸºäºéå†è¯­éŸ³æµå½¢çš„å…±æŒ¯è®°å¿†æ¶æ„PTMï¼Œè§£å†³å¤§è¯­è¨€æ¨¡å‹æ— é™ä¸Šä¸‹æ–‡è®°å¿†é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20245v1" data-paper-url="./papers/251220245v1-memory-as-resonance-a-biomimetic-architecture-for-infinite-context-m.html" onclick="toggleFavorite(this, '2512.20245v1', 'Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251220237v1-memr3-memory-retrieval-via-reflective-reasoning-for-llm-agents.html">MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents</a></td>
  <td>MemRÂ³ï¼šé€šè¿‡åæ€æ¨ç†å®ç°LLM Agentçš„è®°å¿†æ£€ç´¢ï¼Œæå‡é—®ç­”è´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20237v1" data-paper-url="./papers/251220237v1-memr3-memory-retrieval-via-reflective-reasoning-for-llm-agents.html" onclick="toggleFavorite(this, '2512.20237v1', 'MemR$^3$: Memory Retrieval via Reflective Reasoning for LLM Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/251220159v1-axiom-benchmarking-llm-as-a-judge-for-code-via-rule-based-perturbati.html">AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration</a></td>
  <td>AXIOMï¼šé€šè¿‡è§„åˆ™æ‰°åŠ¨å’Œå¤šæºè´¨é‡æ ¡å‡†ï¼ŒåŸºå‡†æµ‹è¯•LLMä½œä¸ºä»£ç è¯„ä¼°åˆ¤å®˜çš„èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20159v1" data-paper-url="./papers/251220159v1-axiom-benchmarking-llm-as-a-judge-for-code-via-rule-based-perturbati.html" onclick="toggleFavorite(this, '2512.20159v1', 'AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/251220140v1-enhancing-zero-shot-time-series-forecasting-in-off-the-shelf-llms-vi.html">Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection</a></td>
  <td>é€šè¿‡å™ªå£°æ³¨å…¥å¢å¼ºå³ç”¨å‹LLMçš„é›¶æ ·æœ¬æ—¶é—´åºåˆ—é¢„æµ‹èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20140v1" data-paper-url="./papers/251220140v1-enhancing-zero-shot-time-series-forecasting-in-off-the-shelf-llms-vi.html" onclick="toggleFavorite(this, '2512.20140v1', 'Enhancing Zero-Shot Time Series Forecasting in Off-the-Shelf LLMs via Noise Injection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/251220062v1-on-the-effectiveness-of-instruction-tuning-local-llms-for-identifyin.html">On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities</a></td>
  <td>æŒ‡ä»¤è°ƒä¼˜æœ¬åœ°LLMï¼Œæœ‰æ•ˆè¯†åˆ«è½¯ä»¶æ¼æ´ç±»å‹ï¼Œæå‡å®‰å…¨æ€§å’Œå®ç”¨æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20062v1" data-paper-url="./papers/251220062v1-on-the-effectiveness-of-instruction-tuning-local-llms-for-identifyin.html" onclick="toggleFavorite(this, '2512.20062v1', 'On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/251219992v1-s3it-a-benchmark-for-spatially-situated-social-intelligence-test.html">S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test</a></td>
  <td>æå‡ºS$^3$ITåŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°å…·èº«æ™ºèƒ½ä½“åœ¨å¤æ‚ç¤¾äº¤ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.19992v1" data-paper-url="./papers/251219992v1-s3it-a-benchmark-for-spatially-situated-social-intelligence-test.html" onclick="toggleFavorite(this, '2512.19992v1', 'S$^3$IT: A Benchmark for Spatially Situated Social Intelligence Test')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>19</td>
  <td><a href="./papers/251220061v1-scaling-reinforcement-learning-for-content-moderation-with-large-lan.html">Scaling Reinforcement Learning for Content Moderation with Large Language Models</a></td>
  <td>åˆ©ç”¨å¼ºåŒ–å­¦ä¹ å’Œå¤§å‹è¯­è¨€æ¨¡å‹æå‡å¤§è§„æ¨¡å†…å®¹å®¡æ ¸çš„æ•ˆç‡ä¸å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward shaping</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20061v1" data-paper-url="./papers/251220061v1-scaling-reinforcement-learning-for-content-moderation-with-large-lan.html" onclick="toggleFavorite(this, '2512.20061v1', 'Scaling Reinforcement Learning for Content Moderation with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/251220381v1-identifying-appropriately-sized-services-with-deep-reinforcement-lea.html">Identifying Appropriately-Sized Services with Deep Reinforcement Learning</a></td>
  <td>æå‡ºRakeï¼Œåˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ä»å®ç°å·¥ä»¶ä¸­è¯†åˆ«åˆé€‚å¤§å°çš„æœåŠ¡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20381v1" data-paper-url="./papers/251220381v1-identifying-appropriately-sized-services-with-deep-reinforcement-lea.html" onclick="toggleFavorite(this, '2512.20381v1', 'Identifying Appropriately-Sized Services with Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/251220082v1-adaptive-financial-sentiment-analysis-for-nifty-50-via-instruction-t.html">Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches</a></td>
  <td>æå‡ºåŸºäºæŒ‡ä»¤è°ƒä¼˜LLMã€RAGå’Œå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”é‡‘èæƒ…æ„Ÿåˆ†ææ¡†æ¶ï¼Œç”¨äºNIFTY 50æŒ‡æ•°é¢„æµ‹ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20082v1" data-paper-url="./papers/251220082v1-adaptive-financial-sentiment-analysis-for-nifty-50-via-instruction-t.html" onclick="toggleFavorite(this, '2512.20082v1', 'Adaptive Financial Sentiment Analysis for NIFTY 50 via Instruction-Tuned LLMs , RAG and Reinforcement Learning Approaches')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/251220275v1-graph-symbolic-policy-enforcement-and-control-g-spec-a-neuro-symboli.html">Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks</a></td>
  <td>æå‡ºG-SPECç¥ç»ç¬¦å·æ¡†æ¶ï¼Œä¿éšœ5Gè‡ªæ²»ç½‘ç»œä¸­LLMä»£ç†çš„å®‰å…¨ç­–ç•¥æ‰§è¡Œã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20275v1" data-paper-url="./papers/251220275v1-graph-symbolic-policy-enforcement-and-control-g-spec-a-neuro-symboli.html" onclick="toggleFavorite(this, '2512.20275v1', 'Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/251220618v1-longvideoagent-multi-agent-reasoning-with-long-videos.html">LongVideoAgent: Multi-Agent Reasoning with Long Videos</a></td>
  <td>LongVideoAgentï¼šæå‡ºä¸€ç§åŸºäºå¤šæ™ºèƒ½ä½“æ¨ç†çš„é•¿è§†é¢‘é—®ç­”æ¡†æ¶ï¼Œæå‡æ—¶åºå®šä½å’Œç»†èŠ‚æ•æ‰èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20618v1" data-paper-url="./papers/251220618v1-longvideoagent-multi-agent-reasoning-with-long-videos.html" onclick="toggleFavorite(this, '2512.20618v1', 'LongVideoAgent: Multi-Agent Reasoning with Long Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/251220589v1-leveraging-high-fidelity-digital-models-and-reinforcement-learning-f.html">Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information</a></td>
  <td>åˆ©ç”¨é«˜ä¿çœŸæ•°å­—æ¨¡å‹ä¸å¼ºåŒ–å­¦ä¹ è¿›è¡Œä»»åŠ¡å·¥ç¨‹ï¼šä»¥å®Œç¾ä¿¡æ¯ä¸‹çš„ç©ºä¸­æ¶ˆé˜²ä¸ºä¾‹</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20589v1" data-paper-url="./papers/251220589v1-leveraging-high-fidelity-digital-models-and-reinforcement-learning-f.html" onclick="toggleFavorite(this, '2512.20589v1', 'Leveraging High-Fidelity Digital Models and Reinforcement Learning for Mission Engineering: A Case Study of Aerial Firefighting Under Perfect Information')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/251220173v1-offline-safe-policy-optimization-from-heterogeneous-feedback.html">Offline Safe Policy Optimization From Heterogeneous Feedback</a></td>
  <td>æå‡ºPreSaæ¡†æ¶ï¼Œé€šè¿‡å¼‚æ„åé¦ˆç›´æ¥ä¼˜åŒ–å®‰å…¨ç­–ç•¥ï¼Œè§£å†³ç¦»çº¿å®‰å…¨ç­–ç•¥ä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">preference learning</span> <span class="paper-tag">RLHF</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20173v1" data-paper-url="./papers/251220173v1-offline-safe-policy-optimization-from-heterogeneous-feedback.html" onclick="toggleFavorite(this, '2512.20173v1', 'Offline Safe Policy Optimization From Heterogeneous Feedback')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/251220112v1-evolutionary-neural-architecture-search-with-dual-contrastive-learni.html">Evolutionary Neural Architecture Search with Dual Contrastive Learning</a></td>
  <td>æå‡ºDCL-ENASï¼Œåˆ©ç”¨åŒé‡å¯¹æ¯”å­¦ä¹ æå‡è¿›åŒ–ç¥ç»æ¶æ„æœç´¢çš„æ•ˆç‡å’Œç²¾åº¦ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20112v1" data-paper-url="./papers/251220112v1-evolutionary-neural-architecture-search-with-dual-contrastive-learni.html" onclick="toggleFavorite(this, '2512.20112v1', 'Evolutionary Neural Architecture Search with Dual Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/251220043v1-discovering-lie-groups-with-flow-matching.html">Discovering Lie Groups with Flow Matching</a></td>
  <td>æå‡ºæµåŒ¹é…æ–¹æ³•ä»¥å‘ç°æç¾¤çš„å¯¹ç§°æ€§</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20043v1" data-paper-url="./papers/251220043v1-discovering-lie-groups-with-flow-matching.html" onclick="toggleFavorite(this, '2512.20043v1', 'Discovering Lie Groups with Flow Matching')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/251220276v1-actionflow-a-pipelined-action-acceleration-for-vision-language-model.html">ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge</a></td>
  <td>ActionFlowï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šè§†è§‰è¯­è¨€æ¨¡å‹æµæ°´çº¿å¼åŠ¨ä½œåŠ é€Ÿæ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span> <span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20276v1" data-paper-url="./papers/251220276v1-actionflow-a-pipelined-action-acceleration-for-vision-language-model.html" onclick="toggleFavorite(this, '2512.20276v1', 'ActionFlow: A Pipelined Action Acceleration for Vision Language Models on Edge')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸‰ç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰-perception-semantics">ğŸ”¬ æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>29</td>
  <td><a href="./papers/251220052v1-learning-skills-from-action-free-videos.html">Learning Skills from Action-Free Videos</a></td>
  <td>æå‡ºåŸºäºå…‰æµçš„æŠ€èƒ½æŠ½è±¡æ¡†æ¶SOFï¼Œä»æ— åŠ¨ä½œè§†é¢‘ä¸­å­¦ä¹ æœºå™¨äººæŠ€èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">optical flow</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2512.20052v1" data-paper-url="./papers/251220052v1-learning-skills-from-action-free-videos.html" onclick="toggleFavorite(this, '2512.20052v1', 'Learning Skills from Action-Free Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)