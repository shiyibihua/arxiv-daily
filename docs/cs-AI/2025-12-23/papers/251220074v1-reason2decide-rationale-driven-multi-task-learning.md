---
layout: default
title: Reason2Decide: Rationale-Driven Multi-Task Learning
---

# Reason2Decide: Rationale-Driven Multi-Task Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.20074" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.20074v1</a>
  <a href="https://arxiv.org/pdf/2512.20074.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.20074v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.20074v1', 'Reason2Decide: Rationale-Driven Multi-Task Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: H M Quamran Hasan, Housam Khalifa Bashier, Jiayi Dai, Mi-Young Kim, Randy Goebel

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Reason2Decideï¼šä¸€ç§åŸºäºç†ç”±é©±åŠ¨çš„å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œæå‡ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿçš„é¢„æµ‹ç²¾åº¦å’Œè§£é‡Šä¸€è‡´æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸´åºŠå†³ç­–æ”¯æŒ` `å¤šä»»åŠ¡å­¦ä¹ ` `ç†ç”±ç”Ÿæˆ` `å¯è§£é‡Šæ€§` `æš´éœ²åå·®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿéš¾ä»¥å…¼é¡¾é¢„æµ‹ç²¾åº¦å’Œè§£é‡Šä¸€è‡´æ€§ï¼Œå­˜åœ¨æš´éœ²åå·®å¯¼è‡´è§£é‡Šä¸é¢„æµ‹ä¸ç¬¦ã€‚
2. Reason2Decideé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå…ˆç”Ÿæˆç†ç”±ï¼Œå†è”åˆè®­ç»ƒé¢„æµ‹å’Œç†ç”±ï¼Œåˆ©ç”¨scheduled samplingç¼“è§£æš´éœ²åå·®ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒReason2Decideåœ¨åŒ»ç–—æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–å¾®è°ƒåŸºçº¿ï¼Œä¸”å¯¹ä¸åŒæ¥æºçš„ç†ç”±å…·æœ‰é²æ£’æ€§ï¼Œæ¨¡å‹è§„æ¨¡æ›´å°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¹¿æ³›åº”ç”¨ï¼Œä½†ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿé¢ä¸´ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼šåœ¨å®ç°é«˜é¢„æµ‹ç²¾åº¦çš„åŒæ—¶ï¼Œç”Ÿæˆä¸é¢„æµ‹ç»“æœä¸€è‡´çš„è§£é‡Šã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨æš´éœ²åå·®ï¼Œå¯¼è‡´è§£é‡Šé”™ä½ã€‚æˆ‘ä»¬æå‡ºäº†Reason2Decideï¼Œä¸€ä¸ªä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œè§£å†³è‡ªè§£é‡Šä¸­çš„å…³é”®æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æš´éœ²åå·®å’Œä»»åŠ¡åˆ†ç¦»ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œæ¨¡å‹è®­ç»ƒç”Ÿæˆç†ç”±ï¼›åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¨¡å‹è”åˆè®­ç»ƒæ ‡ç­¾é¢„æµ‹å’Œç†ç”±ç”Ÿæˆï¼Œåº”ç”¨scheduled samplingé€æ­¥ä»ä¾èµ–çœŸå®æ ‡ç­¾è¿‡æ¸¡åˆ°ä¾èµ–æ¨¡å‹é¢„æµ‹ã€‚æˆ‘ä»¬åœ¨ä¸‰ä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šè¯„ä¼°Reason2Decideï¼ŒåŒ…æ‹¬ä¸€ä¸ªä¸“æœ‰çš„åˆ†è¯Šæ•°æ®é›†å’Œå…¬å¼€çš„ç”Ÿç‰©åŒ»å­¦é—®ç­”æ•°æ®é›†ã€‚åœ¨ä¸åŒæ¨¡å‹è§„æ¨¡ä¸‹ï¼ŒReason2Decideåœ¨é¢„æµ‹ï¼ˆF1ï¼‰å’Œç†ç”±ä¿çœŸåº¦ï¼ˆBERTScoreã€BLEUã€LLM-as-a-Judgeï¼‰æ–¹é¢ä¼˜äºå…¶ä»–å¾®è°ƒåŸºçº¿å’Œä¸€äº›é›¶æ ·æœ¬LLMã€‚åœ¨åˆ†è¯Šä»»åŠ¡ä¸­ï¼ŒReason2Decideå¯¹LLMç”Ÿæˆã€æŠ¤å£«æ’°å†™å’ŒæŠ¤å£«åå¤„ç†çš„ç†ç”±å…·æœ‰é²æ£’æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œä»…åœ¨ç¬¬ä¸€é˜¶æ®µä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±ï¼ŒReason2Decideå°±ä¼˜äºå…¶ä»–å¾®è°ƒå˜ä½“ï¼Œè¡¨æ˜LLMç”Ÿæˆçš„ç†ç”±é€‚åˆé¢„è®­ç»ƒæ¨¡å‹ï¼Œå‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒReason2Decideä»¥æ¯”ç°æœ‰åŸºç¡€æ¨¡å‹å°40å€çš„æ¨¡å‹å®ç°äº†è¿™äº›æ”¹è¿›ï¼Œä½¿ä¸´åºŠæ¨ç†æ›´æ˜“äºåœ¨èµ„æºå—é™çš„éƒ¨ç½²ä¸­ä½¿ç”¨ï¼ŒåŒæ—¶ä»æä¾›å¯è§£é‡Šçš„å†³ç­–æ”¯æŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿéœ€è¦é«˜é¢„æµ‹ç²¾åº¦å’Œä¸é¢„æµ‹ä¸€è‡´çš„è§£é‡Šï¼Œä½†ç°æœ‰æ–¹æ³•å­˜åœ¨æš´éœ²åå·®ï¼Œå³è®­ç»ƒæ—¶ä¾èµ–çœŸå®æ ‡ç­¾ï¼Œæ¨ç†æ—¶ä¾èµ–æ¨¡å‹é¢„æµ‹ï¼Œå¯¼è‡´è§£é‡Šä¸é¢„æµ‹ä¸ä¸€è‡´ã€‚æ­¤å¤–ï¼Œç†ç”±ç”Ÿæˆå’Œæ ‡ç­¾é¢„æµ‹ä¸¤ä¸ªä»»åŠ¡è€¦åˆåº¦ä¸é«˜ï¼Œç›´æ¥è”åˆè®­ç»ƒæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šReason2Decideçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç†ç”±ç”Ÿæˆå’Œæ ‡ç­¾é¢„æµ‹è§£è€¦ï¼Œåˆ†é˜¶æ®µè®­ç»ƒã€‚é¦–å…ˆè®­ç»ƒæ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„ç†ç”±ï¼Œç„¶ååˆ©ç”¨ç”Ÿæˆçš„ç†ç”±è¾…åŠ©æ ‡ç­¾é¢„æµ‹ï¼Œå¹¶ä½¿ç”¨scheduled samplingç¼“è§£æš´éœ²åå·®ã€‚è¿™æ ·å¯ä»¥æé«˜æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦å’Œè§£é‡Šä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šReason2Decideæ˜¯ä¸€ä¸ªä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶ã€‚ç¬¬ä¸€é˜¶æ®µï¼Œä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œä½¿å…¶å…·å¤‡ç”Ÿæˆåˆç†ç†ç”±çš„èƒ½åŠ›ã€‚ç¬¬äºŒé˜¶æ®µï¼Œè”åˆè®­ç»ƒæ ‡ç­¾é¢„æµ‹å’Œç†ç”±ç”Ÿæˆä»»åŠ¡ï¼Œä½¿ç”¨scheduled samplingç­–ç•¥ï¼Œé€æ¸ä»ä¾èµ–çœŸå®æ ‡ç­¾è¿‡æ¸¡åˆ°ä¾èµ–æ¨¡å‹é¢„æµ‹ï¼Œä»è€Œç¼“è§£æš´éœ²åå·®ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆé¢„è®­ç»ƒç†ç”±ç”Ÿæˆï¼Œå†å¾®è°ƒé¢„æµ‹å’Œç†ç”±ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šReason2Decideçš„å…³é”®åˆ›æ–°åœ¨äºä¸¤é˜¶æ®µè®­ç»ƒæ¡†æ¶å’Œscheduled samplingç­–ç•¥ã€‚ä¸¤é˜¶æ®µè®­ç»ƒè§£è€¦äº†ç†ç”±ç”Ÿæˆå’Œæ ‡ç­¾é¢„æµ‹ä»»åŠ¡ï¼Œæé«˜äº†è®­ç»ƒæ•ˆç‡å’Œæ•ˆæœã€‚Scheduled samplingç¼“è§£äº†æš´éœ²åå·®ï¼Œæé«˜äº†æ¨¡å‹åœ¨æ¨ç†æ—¶çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±è¿›è¡Œé¢„è®­ç»ƒï¼Œå‡å°‘äº†å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šç¬¬ä¸€é˜¶æ®µä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®­ç»ƒç†ç”±ç”Ÿæˆæ¨¡å‹ã€‚ç¬¬äºŒé˜¶æ®µï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°è®­ç»ƒæ ‡ç­¾é¢„æµ‹æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–BERTScoreç­‰æŒ‡æ ‡ä½œä¸ºç†ç”±ç”Ÿæˆæ¨¡å‹çš„æŸå¤±å‡½æ•°ã€‚Scheduled samplingç­–ç•¥é€šè¿‡è°ƒæ•´ä½¿ç”¨çœŸå®æ ‡ç­¾çš„æ¦‚ç‡ï¼Œé€æ­¥è¿‡æ¸¡åˆ°ä½¿ç”¨æ¨¡å‹é¢„æµ‹ï¼Œå…·ä½“æ¦‚ç‡ç”±ä¸€ä¸ªscheduleå‡½æ•°æ§åˆ¶ã€‚æ¨¡å‹ç»“æ„å¯ä»¥æ˜¯Transformerç­‰åºåˆ—åˆ°åºåˆ—æ¨¡å‹ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20074v1/x1.png" alt="fig_0" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

Reason2Decideåœ¨ä¸‰ä¸ªåŒ»ç–—æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼ŒåŒ…æ‹¬ä¸€ä¸ªä¸“æœ‰çš„åˆ†è¯Šæ•°æ®é›†å’Œå…¬å¼€çš„ç”Ÿç‰©åŒ»å­¦é—®ç­”æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReason2Decideåœ¨é¢„æµ‹ï¼ˆF1ï¼‰å’Œç†ç”±ä¿çœŸåº¦ï¼ˆBERTScoreã€BLEUã€LLM-as-a-Judgeï¼‰æ–¹é¢ä¼˜äºå…¶ä»–å¾®è°ƒåŸºçº¿å’Œä¸€äº›é›¶æ ·æœ¬LLMã€‚åœ¨åˆ†è¯Šä»»åŠ¡ä¸­ï¼ŒReason2Decideå¯¹LLMç”Ÿæˆã€æŠ¤å£«æ’°å†™å’ŒæŠ¤å£«åå¤„ç†çš„ç†ç”±å…·æœ‰é²æ£’æ€§ã€‚ä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±è¿›è¡Œé¢„è®­ç»ƒï¼ŒReason2Decideä»ç„¶ä¼˜äºå…¶ä»–å¾®è°ƒå˜ä½“ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Reason2Decideå¯åº”ç”¨äºå„ç§ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿï¼Œä¾‹å¦‚ç–¾ç—…è¯Šæ–­ã€æ²»ç–—æ–¹æ¡ˆé€‰æ‹©ã€é£é™©è¯„ä¼°ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæä¾›é«˜ç²¾åº¦çš„é¢„æµ‹ç»“æœï¼Œå¹¶ç”Ÿæˆä¸é¢„æµ‹ä¸€è‡´çš„è§£é‡Šï¼Œæœ‰åŠ©äºåŒ»ç”Ÿç†è§£æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ï¼Œæé«˜ä¿¡ä»»åº¦ï¼Œå¹¶è¾…åŠ©ä¸´åºŠå†³ç­–ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä½¿ç”¨LLMç”Ÿæˆçš„ç†ç”±è¿›è¡Œé¢„è®­ç»ƒï¼Œé™ä½äº†å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the wide adoption of Large Language Models (LLM)s, clinical decision support systems face a critical challenge: achieving high predictive accuracy while generating explanations aligned with the predictions. Current approaches suffer from exposure bias leading to misaligned explanations. We propose Reason2Decide, a two-stage training framework that addresses key challenges in self-rationalization, including exposure bias and task separation. In Stage-1, our model is trained on rationale generation, while in Stage-2, we jointly train on label prediction and rationale generation, applying scheduled sampling to gradually transition from conditioning on gold labels to model predictions. We evaluate Reason2Decide on three medical datasets, including a proprietary triage dataset and public biomedical QA datasets. Across model sizes, Reason2Decide outperforms other fine-tuning baselines and some zero-shot LLMs in prediction (F1) and rationale fidelity (BERTScore, BLEU, LLM-as-a-Judge). In triage, Reason2Decide is rationale source-robust across LLM-generated, nurse-authored, and nurse-post-processed rationales. In our experiments, while using only LLM-generated rationales in Stage-1, Reason2Decide outperforms other fine-tuning variants. This indicates that LLM-generated rationales are suitable for pretraining models, reducing reliance on human annotations. Remarkably, Reason2Decide achieves these gains with models 40x smaller than contemporary foundation models, making clinical reasoning more accessible for resource-constrained deployments while still providing explainable decision support.

