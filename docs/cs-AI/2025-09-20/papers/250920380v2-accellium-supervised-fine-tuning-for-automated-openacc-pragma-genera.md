---
layout: default
title: ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation
---

# ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.20380" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.20380v2</a>
  <a href="https://arxiv.org/pdf/2509.20380.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.20380v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.20380v2', 'ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Samyak Jhaveri, Vanessa Klotzmann, Crista Lopes

**åˆ†ç±»**: cs.SE, cs.AI, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20 (æ›´æ–°: 2025-09-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ACCeLLiuMï¼šç”¨äºè‡ªåŠ¨ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥çš„ç›‘ç£å¼å¾®è°ƒæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `OpenACC` `GPUç¼–ç¨‹` `ç¼–è¯‘æŒ‡å¯¼è¯­å¥ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç›‘ç£å¼å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. GPUç¼–ç¨‹å¤æ‚æ€§é«˜ï¼ŒOpenACCç­‰æŒ‡ä»¤å¼ç¼–ç¨‹è™½ç®€åŒ–äº†æµç¨‹ï¼Œä½†ä»éœ€ä¸“ä¸šçŸ¥è¯†ã€‚
2. ACCeLLiuMé€šè¿‡å¾®è°ƒLLMï¼Œä½¿å…¶èƒ½ä¸ºæ•°æ®å¹¶è¡Œå¾ªç¯è‡ªåŠ¨ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¾®è°ƒåçš„LLMåœ¨ç”Ÿæˆæ­£ç¡®OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºç¡€LLMã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€GPUæ—¥ç›Šæ™®åŠï¼Œå…¶ç¡¬ä»¶å’Œå¹¶è¡Œç¼–ç¨‹æ¡†æ¶çš„å¤æ‚æ€§ä¹Ÿéšä¹‹å¢åŠ ã€‚åŸºäºæŒ‡ä»¤çš„å¹¶è¡Œç¼–ç¨‹æ ‡å‡†ï¼ˆå¦‚OpenACCï¼‰é€šè¿‡æŠ½è±¡åº•å±‚å¤æ‚æ€§ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šç®€åŒ–äº†GPUç¼–ç¨‹ï¼Œä½†æœ‰æ•ˆä½¿ç”¨è¿™äº›æŒ‡ä»¤ä»ç„¶éœ€è¦ç›¸å½“å¤šçš„ä¸“ä¸šçŸ¥è¯†ã€‚æˆ‘ä»¬ä»‹ç»äº†ACCeLLiuMï¼Œè¿™æ˜¯ä¸¤ä¸ªå¼€æ”¾æƒé‡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¸“é—¨é’ˆå¯¹ä¸ºæ•°æ®å¹¶è¡Œå¾ªç¯ç”Ÿæˆä¸“å®¶çº§OpenACCæŒ‡ä»¤è¿›è¡Œå¾®è°ƒï¼Œä»¥åŠç”¨äºè®­ç»ƒå®ƒä»¬çš„ç›‘ç£å¼å¾®è°ƒæ•°æ®é›†ã€‚ACCeLLiuM SFTæ•°æ®é›†åŒ…å«ä»å…¬å…±GitHub C/C++å­˜å‚¨åº“ä¸­æŒ–æ˜çš„4,033ä¸ªOpenACC pragma-loopå¯¹ï¼Œå…¶ä¸­3,223å¯¹ç”¨äºè®­ç»ƒï¼Œ810å¯¹ç”¨äºæµ‹è¯•ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒåŸºç¡€LLMå’Œæˆ‘ä»¬å¾®è°ƒç‰ˆæœ¬åœ¨ç”Ÿæˆæ­£ç¡®çš„OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥æ–¹é¢å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚åœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šï¼ŒåŸºç¡€LLMæ— æ³•å§‹ç»ˆå¦‚ä¸€åœ°ç”Ÿæˆæœ‰æ•ˆçš„ç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼Œè€ŒåŸºäºACCeLLiuMæ•°æ®é›†å¾®è°ƒçš„LLMèƒ½å¤Ÿä¸º87%çš„æ•°æ®å¹¶è¡Œå¾ªç¯ç”Ÿæˆå…·æœ‰æ­£ç¡®æŒ‡ä»¤ç±»å‹çš„æœ‰æ•ˆç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼Œå¹¶åœ¨50%çš„æƒ…å†µä¸‹ç”Ÿæˆç²¾ç¡®çš„ç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼ˆåŒ…æ‹¬æŒ‡ä»¤ã€å­å¥ã€å­å¥é¡ºåºå’Œå­å¥å˜é‡ï¼‰ã€‚å³ä½¿ä¸å®Œå…¨åŒ¹é…ï¼Œç”Ÿæˆçš„ç¼–è¯‘æŒ‡å¯¼è¯­å¥ä¹Ÿç»å¸¸ä»¥ä¸åŒäºground-truthæ ‡ç­¾çš„é¡ºåºåŒ…å«æ­£ç¡®çš„å­å¥ï¼Œæˆ–è€…åŒ…å«é¢å¤–çš„å­å¥ï¼Œä»è€Œå¯ä»¥æ›´å¥½åœ°æ§åˆ¶å¹¶è¡Œæ‰§è¡Œã€æ•°æ®ç§»åŠ¨å’Œå¹¶å‘æ€§ï¼Œä»è€Œæä¾›è¶…å‡ºä¸¥æ ¼å­—ç¬¦ä¸²åŒ¹é…çš„å®é™…ä»·å€¼ã€‚é€šè¿‡å…¬å¼€å‘å¸ƒä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†ACCeLLiuMï¼Œæˆ‘ä»¬å¸Œæœ›ä¸ºLLMé©±åŠ¨çš„OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ç”Ÿæˆå»ºç«‹ä¸€ä¸ªå¯å¤ç°çš„åŸºå‡†ï¼Œå¹¶é™ä½è‡ªåŠ¨å°†ä¸²è¡Œç¼–å†™çš„ç¨‹åºå¸è½½åˆ°GPUçš„é—¨æ§›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³GPUç¼–ç¨‹ä¸­OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ç”Ÿæˆéœ€è¦ä¸“ä¸šçŸ¥è¯†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äººå·¥ç¼–å†™ï¼Œæ•ˆç‡ä½ä¸”æ˜“å‡ºé”™ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨GPUçš„å¹¶è¡Œè®¡ç®—èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼ºå¤§çš„ä»£ç ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡ç›‘ç£å¼å¾®è°ƒï¼Œä½¿LLMèƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ã€‚è¿™æ ·å¯ä»¥é™ä½GPUç¼–ç¨‹çš„é—¨æ§›ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šACCeLLiuMçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) æ„å»ºOpenACC pragma-loopå¯¹çš„ç›‘ç£å¼å¾®è°ƒæ•°æ®é›†ï¼›2) é€‰æ‹©åˆé€‚çš„LLMä½œä¸ºåŸºç¡€æ¨¡å‹ï¼›3) ä½¿ç”¨ç›‘ç£å¼å­¦ä¹ æ–¹æ³•ï¼Œåœ¨æ„å»ºçš„æ•°æ®é›†ä¸Šå¯¹LLMè¿›è¡Œå¾®è°ƒï¼›4) å¯¹å¾®è°ƒåçš„LLMè¿›è¡Œè¯„ä¼°ï¼ŒéªŒè¯å…¶ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„OpenACC pragma-loopå¯¹æ•°æ®é›†ï¼Œä¸ºLLMçš„å¾®è°ƒæä¾›äº†æ•°æ®åŸºç¡€ï¼›2) æå‡ºäº†ä¸€ç§åŸºäºç›‘ç£å¼å¾®è°ƒçš„OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥è‡ªåŠ¨ç”Ÿæˆæ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆç¼–è¯‘æŒ‡å¯¼è¯­å¥çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼›3) å…¬å¼€äº†ä»£ç ã€æ¨¡å‹å’Œæ•°æ®é›†ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†å¯å¤ç°çš„åŸºå‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šACCeLLiuMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æ•°æ®é›†çš„æ„å»ºï¼šä»GitHubç­‰å…¬å…±ä»£ç ä»“åº“ä¸­æŒ–æ˜C/C++ä»£ç ï¼Œæå–æ•°æ®å¹¶è¡Œå¾ªç¯å’Œå¯¹åº”çš„OpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼Œå¹¶è¿›è¡Œæ¸…æ´—å’Œé¢„å¤„ç†ï¼›2) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©äº†å…·æœ‰è¾ƒå¼ºä»£ç ç†è§£å’Œç”Ÿæˆèƒ½åŠ›çš„LLMä½œä¸ºåŸºç¡€æ¨¡å‹ï¼ˆå…·ä½“æ¨¡å‹æœªçŸ¥ï¼‰ï¼›3) å¾®è°ƒç­–ç•¥ï¼šé‡‡ç”¨ç›‘ç£å¼å­¦ä¹ æ–¹æ³•ï¼Œä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ç­‰ï¼ˆå…·ä½“æŸå¤±å‡½æ•°æœªçŸ¥ï¼‰å¯¹LLMè¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–æ¨¡å‹ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¿ç•™çš„æµ‹è¯•é›†ä¸Šï¼ŒåŸºäºACCeLLiuMæ•°æ®é›†å¾®è°ƒçš„LLMèƒ½å¤Ÿä¸º87%çš„æ•°æ®å¹¶è¡Œå¾ªç¯ç”Ÿæˆå…·æœ‰æ­£ç¡®æŒ‡ä»¤ç±»å‹çš„æœ‰æ•ˆç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼Œå¹¶åœ¨50%çš„æƒ…å†µä¸‹ç”Ÿæˆç²¾ç¡®çš„ç¼–è¯‘æŒ‡å¯¼è¯­å¥ã€‚è¿™è¡¨æ˜ACCeLLiuMåœ¨è‡ªåŠ¨ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥æ–¹é¢å…·æœ‰æ˜¾è‘—çš„æ€§èƒ½ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ACCeLLiuMå¯åº”ç”¨äºé«˜æ€§èƒ½è®¡ç®—ã€ç§‘å­¦è®¡ç®—ã€å›¾åƒå¤„ç†ç­‰é¢†åŸŸï¼Œé€šè¿‡è‡ªåŠ¨ç”ŸæˆOpenACCç¼–è¯‘æŒ‡å¯¼è¯­å¥ï¼Œç®€åŒ–GPUç¼–ç¨‹ï¼ŒåŠ é€Ÿåº”ç”¨ç¨‹åºçš„å¼€å‘å’Œä¼˜åŒ–ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºé™ä½GPUç¼–ç¨‹é—¨æ§›ï¼Œä¿ƒè¿›GPUåœ¨æ›´å¤šé¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶æ¨åŠ¨å¹¶è¡Œè®¡ç®—æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increasing ubiquity of GPUs is accompanied by the increasing complexity of their hardware and parallel programming frameworks. Directive-based parallel programming standards like OpenACC simplify GPU programming to some extent by abstracting away low-level complexities, but a fair amount of expertise is still required in order to use those directives effectively.
>   We introduce ACCeLLiuM, two open weights Large Language Models specifically fine-tuned for generating expert OpenACC directives for data-parallel loops, along with the supervised fine-tuning dataset that was used to train them. The ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for testing. Experimental evaluations show a pronounced performance gap in generating correct OpenACC pragmas between base LLMs and our fine-tuned versions. On the held-out test set, base LLMs fail to consistently generate valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid pragmas with the correct directive type for $87\%$ of the data-parallel loops, and exact pragmas--including directives, clauses, clause order, and clause variables--for $50\%$ of the cases. Even when not exact, generated pragmas frequently incorporate the correct clauses in a different order than the ground-truth label, or include additional clauses that enable finer control over parallel execution, data movement, and concurrency, offering practical value beyond strict string-matching. By publicly releasing the code, models, and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU offloading of serially written programs.

