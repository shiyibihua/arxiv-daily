---
layout: default
title: Think Clearly: Improving Reasoning via Redundant Token Pruning
---

# Think Clearly: Improving Reasoning via Redundant Token Pruning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.08806" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.08806v1</a>
  <a href="https://arxiv.org/pdf/2507.08806.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.08806v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.08806v1', 'Think Clearly: Improving Reasoning via Redundant Token Pruning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daewon Choi, Jimin Lee, Jihoon Tack, Woomin Song, Saket Dingliwal, Sai Muralidhar Jayanthi, Bhavana Ganesh, Jinwoo Shin, Aram Galstyan, Sravan Babu Bodapati

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å†—ä½™æ ‡è®°ä¿®å‰ªæå‡æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†èƒ½åŠ›` `å†—ä½™ä¿®å‰ª` `æ³¨æ„åŠ›æœºåˆ¶` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°å­¦ç«èµ›` `ç»“æ„æ„ŸçŸ¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨æ˜¾è‘—çš„å†—ä½™ï¼Œå¯¼è‡´æ³¨æ„åŠ›åˆ†æ•£ï¼Œå½±å“æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å†—ä½™æ ‡è®°ä¿®å‰ªçš„æ–¹æ³•ï¼Œç³»ç»Ÿè¯†åˆ«å¹¶å»é™¤æ¨ç†è¿‡ç¨‹ä¸­çš„å†—ä½™ï¼Œä»¥æå‡æ¨ç†æ¸…æ™°åº¦å’Œå‡†ç¡®æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†å‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨æ•°å­¦ç«èµ›åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨é•¿ç¯‡æ¨ç†æ–¹é¢å±•ç°å‡ºè‰¯å¥½çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿéµå¾ªç»“æ„åŒ–çš„æ€ç»´é“¾æ¡å¾—å‡ºæœ€ç»ˆç­”æ¡ˆã€‚ç„¶è€Œï¼Œç ”ç©¶å‘ç°è¿™äº›æ¨ç†è·¯å¾„å¾€å¾€å­˜åœ¨æ˜¾è‘—çš„å†—ä½™ï¼Œå°¤å…¶åœ¨é”™è¯¯ç­”æ¡ˆä¸­ï¼Œæ³¨æ„åŠ›åˆ†å¸ƒè¾ƒä¸ºåˆ†æ•£ã€‚æœ¬æ–‡æå‡ºé€šè¿‡ç³»ç»Ÿæ€§åœ°è¯†åˆ«å¹¶å»é™¤æ¨ç†è¿‡ç¨‹ä¸­çš„å†—ä½™ï¼Œæ˜¾è‘—æå‡æ¨ç†æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œä½œè€…é€šè¿‡æµ‹é‡ä¸ç‰¹æ®Šçš„æ€ç»´ç»“æŸæ ‡è®°çš„æ ‡è®°çº§æ³¨æ„åŠ›åˆ†æ•°ï¼Œè¯†åˆ«æ¨ç†å†—ä½™ï¼Œå¹¶æå‡ºç»“æ„æ„ŸçŸ¥ä¿®å‰ªæ–¹æ³•ï¼Œä¼˜å…ˆå»é™¤ä½è´¡çŒ®çš„æ¨ç†å—ä¸­çš„æ ‡è®°ã€‚ç»è¿‡å†—ä½™æ ‡è®°çš„å‰”é™¤ï¼Œæ¢å¤æ¨ç†ç”Ÿæˆï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ¨ç†å¯†é›†å‹åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ•´ä½“å‡†ç¡®æ€§ï¼Œå°¤å…¶åœ¨æ•°å­¦ç«èµ›åŸºå‡†å¦‚AIMEå’ŒAMCä¸­è¡¨ç°çªå‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å­˜åœ¨çš„å†—ä½™é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†æ—¶ï¼Œæ³¨æ„åŠ›åˆ†å¸ƒä¸å‡ï¼Œå¯¼è‡´é”™è¯¯ç­”æ¡ˆçš„äº§ç”Ÿã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§åœ°è¯†åˆ«å’Œå»é™¤æ¨ç†è¿‡ç¨‹ä¸­çš„å†—ä½™æ ‡è®°ï¼Œæå‡æ¨ç†çš„æ¸…æ™°åº¦å’Œå‡†ç¡®æ€§ã€‚å…·ä½“æ–¹æ³•æ˜¯æµ‹é‡ä¸ç‰¹æ®Šçš„æ€ç»´ç»“æŸæ ‡è®°çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œè¯†åˆ«å‡ºå†—ä½™éƒ¨åˆ†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆï¼Œæ’å…¥æ€ç»´ç»“æŸæ ‡è®°ä»¥æ”¶é›†æ³¨æ„åŠ›åˆ†æ•°ï¼›å…¶æ¬¡ï¼ŒåŸºäºæ³¨æ„åŠ›åˆ†æ•°è¯†åˆ«å†—ä½™æ ‡è®°å¹¶è¿›è¡Œä¿®å‰ªï¼›æœ€åï¼Œå»é™¤æ€ç»´ç»“æŸæ ‡è®°ï¼Œæ¢å¤æ¨ç†ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°åœ¨äºæå‡ºäº†ç»“æ„æ„ŸçŸ¥ä¿®å‰ªæ–¹æ³•ï¼Œä¼˜å…ˆå»é™¤ä½è´¡çŒ®çš„æ¨ç†å—ä¸­çš„æ ‡è®°ï¼Œè€Œéå•ä¸ªæ ‡è®°ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°æå‡æ¨ç†è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡è®¾è®¡äº†ç‰¹å®šçš„æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—æ–¹æ³•ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†ä¸åŒæ ‡è®°çš„è´¡çŒ®åº¦ï¼Œä»¥æŒ‡å¯¼å†—ä½™æ ‡è®°çš„å»é™¤ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨å†—ä½™æ ‡è®°ä¿®å‰ªæ–¹æ³•åï¼Œæ¨¡å‹åœ¨AIMEå’ŒAMCç­‰æ•°å­¦ç«èµ›åŸºå‡†æµ‹è¯•ä¸­å‡†ç¡®ç‡æ˜¾è‘—æå‡ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œæ˜¾ç¤ºå‡ºè¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æå‡æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æ•°å­¦ã€ç§‘å­¦ç­‰é¢†åŸŸçš„æ™ºèƒ½è¾…å¯¼å’Œå†³ç­–æ”¯æŒä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„æ™ºèƒ½åŠ©æ‰‹å’Œè‡ªåŠ¨åŒ–å·¥å…·çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent large language models have shown promising capabilities in long-form reasoning, following structured chains of thought before arriving at a final answer. However, we observe that these reasoning paths tend to include substantial redundancy; analyzing attention patterns reveals that attention scores are widely scattered, particularly incorrect answers exhibit greater attention sparsity. In this paper, we demonstrate that deliberately removing this redundancy in the reasoning process significantly improves performance through clear thinking, i.e., removing distraction. Specifically, we systematically identify reasoning redundancy by measuring token-level attention scores to a special end-of-thinking token, which is appended to an explicit instruction inserted to conclude each intermediate reasoning step. Furthermore, we propose structure-aware pruning that prioritizes removing tokens in low-contributing reasoning chunks over individual tokens. After evicting redundant tokens, we remove the injected end-of-thinking instruction, then resume the reasoning generation. We demonstrate that our method significantly improves overall accuracy across reasoning-intensive benchmarks without any training involved. In particular, our method shows strong performance on challenging mathematical competition benchmarks such as AIME and AMC, where reasoning redundancy is more prevalent.

