---
layout: default
title: Multimodal Political Bias Identification and Neutralization
---

# Multimodal Political Bias Identification and Neutralization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17372" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17372v1</a>
  <a href="https://arxiv.org/pdf/2506.17372.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17372v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17372v1', 'Multimodal Political Bias Identification and Neutralization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Cedric Bernard, Xavier Pleimling, Amun Kharel, Chase Vickery

**åˆ†ç±»**: cs.CY, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ”¿æ²»åè§è¯†åˆ«ä¸ä¸­å’Œæ–¹æ³•ä»¥è§£å†³åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€èåˆ` `æ”¿æ²»åè§` `æ–‡æœ¬å»åè§` `å›¾åƒå¤„ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬åè§çš„è¯†åˆ«ï¼Œå¿½è§†äº†å›¾åƒä½œä¸ºä¿¡æ¯ä¼ é€’åª’ä»‹çš„é‡è¦æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¨¡å‹é€šè¿‡ç»“åˆæ–‡æœ¬å’Œå›¾åƒçš„åè§è¯†åˆ«ï¼Œé‡‡ç”¨äº†å›¾åƒæ–‡æœ¬å¯¹é½ã€å›¾åƒåè§è¯„åˆ†å’Œæ–‡æœ¬å»åè§ç­‰æ­¥éª¤ã€‚
3. åˆæ­¥å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ–‡æœ¬å»åè§ç­–ç•¥æœ‰æ•ˆè¯†åˆ«åè§è¯æ±‡ï¼ŒViTæ¨¡å‹è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œè¯­ä¹‰å¯¹é½æ¨¡å‹é«˜æ•ˆï¼Œä½†ä»éœ€æ›´å¤šèµ„æºå’Œæ—¶é—´ä¼˜åŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºæ”¿æ²»å›éŸ³å®¤çš„å­˜åœ¨ï¼Œæ£€æµ‹å’Œæ¶ˆé™¤æ”¿æ²»æ–‡ç« ä¸­ä¸»è§‚åè§å’Œæƒ…æ„ŸåŒ–è¯­è¨€å˜å¾—è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ–‡æœ¬åè§ä¸Šï¼Œè€Œå¿½è§†äº†å›¾åƒéƒ¨åˆ†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¨¡å‹ï¼Œç»“åˆæ–‡æœ¬å’Œå›¾åƒçš„åè§è¯†åˆ«ï¼ŒåŒ…å«å››ä¸ªæ­¥éª¤ï¼šå›¾åƒæ–‡æœ¬å¯¹é½ã€å›¾åƒåè§è¯„åˆ†ã€æ–‡æœ¬å»åè§å’Œæœ€ç»ˆçš„å»åè§å¤„ç†ã€‚åˆæ­¥ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ–‡æœ¬å»åè§ç­–ç•¥ä¸Šèƒ½å¤Ÿè¯†åˆ«å‡ºè®¸å¤šæ½œåœ¨çš„åè§è¯æ±‡ï¼ŒViTæ¨¡å‹å±•ç¤ºäº†æœ‰æ•ˆçš„è®­ç»ƒæ•ˆæœï¼Œè¯­ä¹‰å¯¹é½æ¨¡å‹ä¹Ÿè¡¨ç°å‡ºé«˜æ•ˆæ€§ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä»éœ€æ›´å¤šçš„æ—¶é—´å’Œèµ„æºä»¥è·å¾—æ›´å¥½çš„ç»“æœï¼Œå¹¶å»ºè®®è¿›è¡Œäººå·¥è¯„ä¼°ä»¥ç¡®ä¿æ–°ç”Ÿæˆæ–‡æœ¬å’Œå›¾åƒçš„è¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ”¿æ²»æ–‡ç« ä¸­å­˜åœ¨çš„ä¸»è§‚åè§å’Œæƒ…æ„ŸåŒ–è¯­è¨€é—®é¢˜ï¼Œç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºæ–‡æœ¬ï¼Œæœªèƒ½å……åˆ†è€ƒè™‘å›¾åƒçš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆæ–‡æœ¬å’Œå›¾åƒçš„åè§è¯†åˆ«ï¼Œæå‡ºä¸€ç§å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ—¨åœ¨å…¨é¢è¯†åˆ«å’Œä¸­å’Œåè§ï¼Œå¢å¼ºä¿¡æ¯ä¼ é€’çš„å®¢è§‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¨¡å‹åˆ†ä¸ºå››ä¸ªä¸»è¦æ­¥éª¤ï¼š1) å›¾åƒæ–‡æœ¬å¯¹é½ï¼Œåˆ©ç”¨CLIPæ¨¡å‹å¯¹å›¾åƒè¿›è¡Œè¯­ä¹‰å¯¹é½ï¼›2) å›¾åƒåè§è¯„åˆ†ï¼Œé€šè¿‡ViTåˆ†ç±»å™¨è¯„ä¼°å›¾åƒçš„åè§åˆ†æ•°ï¼›3) æ–‡æœ¬å»åè§ï¼Œä½¿ç”¨BERTæ¨¡å‹æ£€æµ‹å¹¶ä¸­å’Œåè§è¯æ±‡ï¼›4) æœ€ç»ˆå»åè§å¤„ç†ï¼Œæ›¿æ¢æ–‡æœ¬å’Œå›¾åƒä¸ºä¸­ç«‹æˆ–é™ä½åè§çš„ç‰ˆæœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„åˆ›æ–°åœ¨äºåŒæ—¶è€ƒè™‘æ–‡æœ¬å’Œå›¾åƒçš„åè§ï¼Œæå‡ºäº†ä¸€ä¸ªç»¼åˆçš„å¤šæ¨¡æ€å¤„ç†æ¡†æ¶ï¼ŒåŒºåˆ«äºä»¥å¾€ä»…å…³æ³¨æ–‡æœ¬çš„å•ä¸€æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†CLIPå’ŒViTç­‰å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åè§è¯„åˆ†å’Œå»åè§æ•ˆæœï¼Œç¡®ä¿æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ–‡æœ¬å»åè§ç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¤§é‡åè§è¯æ±‡ï¼ŒViTæ¨¡å‹åœ¨å›¾åƒåè§è¯„åˆ†ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„è®­ç»ƒæ•ˆæœã€‚è¯­ä¹‰å¯¹é½æ¨¡å‹çš„æ•ˆç‡ä¹Ÿå¾—åˆ°äº†éªŒè¯ï¼Œæ•´ä½“æ–¹æ³•åœ¨å»åè§ä»»åŠ¡ä¸­å±•ç°å‡ºè¾ƒå¼ºçš„æ½œåŠ›ï¼Œå°½ç®¡ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨æ”¿æ²»æ–°é—»ã€ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸å’Œä¿¡æ¯ä¼ æ’­ç­‰é¢†åŸŸã€‚é€šè¿‡æœ‰æ•ˆè¯†åˆ«å’Œä¸­å’Œåè§ï¼Œèƒ½å¤Ÿæå‡å…¬ä¼—å¯¹ä¿¡æ¯çš„å®¢è§‚ç†è§£ï¼Œå‡å°‘è¯¯å¯¼æ€§ä¿¡æ¯çš„ä¼ æ’­ï¼Œä¿ƒè¿›æ›´å¥åº·çš„èˆ†è®ºç¯å¢ƒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œå¦‚å¹¿å‘Šå’Œå¸‚åœºè¥é”€ä¸­çš„æƒ…æ„Ÿåˆ†æã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Due to the presence of political echo chambers, it becomes imperative to detect and remove subjective bias and emotionally charged language from both the text and images of political articles. However, prior work has focused on solely the text portion of the bias rather than both the text and image portions. This is a problem because the images are just as powerful of a medium to communicate information as text is. To that end, we present a model that leverages both text and image bias which consists of four different steps. Image Text Alignment focuses on semantically aligning images based on their bias through CLIP models. Image Bias Scoring determines the appropriate bias score of images via a ViT classifier. Text De-Biasing focuses on detecting biased words and phrases and neutralizing them through BERT models. These three steps all culminate to the final step of debiasing, which replaces the text and the image with neutralized or reduced counterparts, which for images is done by comparing the bias scores. The results so far indicate that this approach is promising, with the text debiasing strategy being able to identify many potential biased words and phrases, and the ViT model showcasing effective training. The semantic alignment model also is efficient. However, more time, particularly in training, and resources are needed to obtain better results. A human evaluation portion was also proposed to ensure semantic consistency of the newly generated text and images.

