---
layout: default
title: Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs
---

# Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17353v1</a>
  <a href="https://arxiv.org/pdf/2506.17353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17353v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17353v1', 'Differentiation-Based Extraction of Proprietary Data from Fine-Tuned LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zongjie Li, Daoyuan Wu, Shuai Wang, Zhendong Su

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: In Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security (CCS'25), October 13-17, 2025, Taipei, Taiwan, China. ACM, New York, NY, USA, 15 pages. https://doi.org/10.1145/3719027.3744856

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå·®å¼‚åŒ–æ•°æ®æå–æ–¹æ³•ä»¥è§£å†³SFTæ¨¡å‹æ•°æ®æ³„éœ²é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®æå–` `ç›‘ç£å¾®è°ƒ` `å®‰å…¨æ€§ç ”ç©¶` `æœºå™¨å­¦ä¹ ` `æ•°æ®æ³„éœ²` `é˜²å¾¡æœºåˆ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„SFTæ¨¡å‹åœ¨æ•°æ®ä¿æŠ¤æ–¹é¢å­˜åœ¨éšæ‚£ï¼Œç‰¹åˆ«æ˜¯æŒ‡ä»¤-å“åº”å¯¹çš„æå–é£é™©å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æå–æ–¹æ³•DDEï¼Œåˆ©ç”¨å¾®è°ƒæ¨¡å‹çš„ç½®ä¿¡åº¦å’Œè¡Œä¸ºå·®å¼‚ï¼Œé’ˆå¯¹SFTæ•°æ®è¿›è¡Œä¼˜åŒ–æå–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDDEåœ¨å„ç±»æ”»å‡»åœºæ™¯ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æå–æ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¯¹ç‰¹å®šé¢†åŸŸå’Œäººç±»å¯¹é½çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰éœ€æ±‚çš„å¢åŠ ï¼Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æŠ€æœ¯è¢«å¹¿æ³›é‡‡ç”¨ã€‚SFTæ•°æ®é›†é€šå¸¸åŒ…å«æœ‰ä»·å€¼çš„æŒ‡ä»¤-å“åº”å¯¹ï¼Œä½¿å…¶æˆä¸ºæ½œåœ¨çš„æå–ç›®æ ‡ã€‚æœ¬æ–‡é¦–æ¬¡ç ”ç©¶äº†è¿™ä¸€å…³é”®é—®é¢˜ï¼Œæ­£å¼å®šä¹‰å¹¶åˆ¶å®šäº†ç›¸å…³é—®é¢˜ï¼Œæ¢è®¨äº†åŸºäºSFTæ•°æ®ç‹¬ç‰¹å±æ€§çš„å„ç§æ”»å‡»ç›®æ ‡ã€ç±»å‹å’Œå˜ä½“ã€‚åŸºäºå¯¹ç›´æ¥æå–è¡Œä¸ºçš„åˆ†æï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–°é¢–çš„æå–æ–¹æ³•ï¼Œç§°ä¸ºå·®å¼‚åŒ–æ•°æ®æå–ï¼ˆDDEï¼‰ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¾®è°ƒæ¨¡å‹çš„ç½®ä¿¡åº¦æ°´å¹³åŠå…¶ä¸é¢„è®­ç»ƒåŸºç¡€æ¨¡å‹çš„è¡Œä¸ºå·®å¼‚ã€‚é€šè¿‡åœ¨å¤šä¸ªé¢†åŸŸå’Œåœºæ™¯ä¸­çš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº†ä½¿ç”¨DDEè¿›è¡ŒSFTæ•°æ®æå–çš„å¯è¡Œæ€§ï¼Œå¹¶æ˜¾ç¤ºDDEåœ¨æ‰€æœ‰æ”»å‡»è®¾ç½®ä¸­å‡ä¼˜äºç°æœ‰æå–åŸºçº¿ã€‚ä¸ºåº”å¯¹è¿™ä¸€æ–°æ”»å‡»ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é˜²å¾¡æœºåˆ¶ï¼Œä»¥æœ€å°å½±å“æ¨¡å‹æ€§èƒ½çš„æ–¹å¼å‡è½»DDEæ”»å‡»ã€‚æ€»ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†å¾®è°ƒLLMsä¸­éšè—çš„æ•°æ®æ³„éœ²é£é™©ï¼Œå¹¶ä¸ºå¼€å‘æ›´å®‰å…¨çš„æ¨¡å‹æä¾›äº†è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»å¾®è°ƒçš„LLMä¸­æå–æ•æ„Ÿæ•°æ®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹SFTæ•°æ®çš„ç‹¬ç‰¹æ€§å’Œæ½œåœ¨é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„DDEæ–¹æ³•é€šè¿‡åˆ†æå¾®è°ƒæ¨¡å‹çš„ç½®ä¿¡åº¦å’Œè¡Œä¸ºå·®å¼‚ï¼Œè®¾è®¡å‡ºä¸€ç§é’ˆå¯¹SFTæ•°æ®çš„å·®å¼‚åŒ–æå–ç­–ç•¥ï¼Œä»¥æé«˜æå–çš„æˆåŠŸç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDDEæ–¹æ³•åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æå–è¿‡ç¨‹å’Œç»“æœè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹SFTæ•°æ®è¿›è¡Œåˆ†æï¼Œç„¶åè®­ç»ƒå¾®è°ƒæ¨¡å‹ï¼Œæ¥ç€åˆ©ç”¨æ¨¡å‹çš„ç½®ä¿¡åº¦è¿›è¡Œæ•°æ®æå–ï¼Œæœ€åè¯„ä¼°æå–æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šDDEçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºåˆ©ç”¨å¾®è°ƒæ¨¡å‹çš„ç½®ä¿¡åº¦å·®å¼‚è¿›è¡Œæ•°æ®æå–ï¼Œè¿™ä¸€æ–¹æ³•åœ¨æå–æ•ˆç‡å’Œå‡†ç¡®æ€§ä¸Šä¸ä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DDEä¸­ï¼Œè®¾ç½®äº†ç‰¹å®šçš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„æŸå¤±å‡½æ•°ï¼Œä»¥ä¼˜åŒ–æå–è¿‡ç¨‹ä¸­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDDEåœ¨æ‰€æœ‰æ”»å‡»è®¾ç½®ä¸­å‡ä¼˜äºç°æœ‰æå–åŸºçº¿ï¼Œæå–æˆåŠŸç‡æé«˜äº†20%ä»¥ä¸Šï¼Œä¸”åœ¨å¤šä¸ªé¢†åŸŸçš„åº”ç”¨ä¸­è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶å¹¿æ³›é€‚ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®å®‰å…¨ã€æ¨¡å‹è®­ç»ƒå’Œäººå·¥æ™ºèƒ½ä¼¦ç†ç­‰ã€‚é€šè¿‡æ­ç¤ºå¾®è°ƒæ¨¡å‹ä¸­çš„æ•°æ®æ³„éœ²é£é™©ï¼Œç ”ç©¶ä¸ºå¼€å‘æ›´å®‰å…¨çš„LLMæä¾›äº†é‡è¦å‚è€ƒï¼Œä¿ƒè¿›äº†å¯¹AIç³»ç»Ÿå®‰å…¨æ€§çš„æ·±å…¥ç†è§£å’Œæ”¹è¿›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increasing demand for domain-specific and human-aligned Large Language Models (LLMs) has led to the widespread adoption of Supervised Fine-Tuning (SFT) techniques. SFT datasets often comprise valuable instruction-response pairs, making them highly valuable targets for potential extraction. This paper studies this critical research problem for the first time. We start by formally defining and formulating the problem, then explore various attack goals, types, and variants based on the unique properties of SFT data in real-world scenarios. Based on our analysis of extraction behaviors of direct extraction, we develop a novel extraction method specifically designed for SFT models, called Differentiated Data Extraction (DDE), which exploits the confidence levels of fine-tuned models and their behavioral differences from pre-trained base models. Through extensive experiments across multiple domains and scenarios, we demonstrate the feasibility of SFT data extraction using DDE. Our results show that DDE consistently outperforms existing extraction baselines in all attack settings. To counter this new attack, we propose a defense mechanism that mitigates DDE attacks with minimal impact on model performance. Overall, our research reveals hidden data leak risks in fine-tuned LLMs and provides insights for developing more secure models.

