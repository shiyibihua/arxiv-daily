---
layout: default
title: Are Bias Evaluation Methods Biased ?
---

# Are Bias Evaluation Methods Biased ?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17111" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17111v1</a>
  <a href="https://arxiv.org/pdf/2506.17111.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17111v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17111v1', 'Are Bias Evaluation Methods Biased ?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lina Berrayana, Sean Rooney, Luis GarcÃ©s-Erice, Ioana Giurgiu

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20

**å¤‡æ³¨**: Accepted to ACL 2025 Workshop GEM

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**è¯„ä¼°åè§æ–¹æ³•çš„åè§é—®é¢˜åŠå…¶å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åè§è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨¡å‹æ’å` `å¯ä¿¡AI` `å®‰å…¨æ€§è¯„ä¼°` `è¯„ä¼°åŸºå‡†` `æœ‰å®³è¡Œä¸º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åè§è¯„ä¼°æ–¹æ³•åœ¨æ¨¡å‹æ’åä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„ä¸ä¸€è‡´æ€§ã€‚
2. æœ¬æ–‡é€šè¿‡æ¯”è¾ƒä¸åŒçš„åè§è¯„ä¼°æ–¹æ³•ï¼Œæ¢è®¨å…¶å¯¹æ¨¡å‹æ’åçš„å½±å“ï¼Œæ—¨åœ¨æé«˜è¯„ä¼°åŸºå‡†çš„å¯é æ€§ã€‚
3. ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œä¸åŒçš„è¯„ä¼°æ–¹æ³•å¯¼è‡´æ¨¡å‹æ’åå·®å¼‚ï¼Œæå‡ºäº†æ”¹è¿›å»ºè®®ä»¥å¢å¼ºåŸºå‡†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¯ä¿¡AIç¤¾åŒºä¸­ï¼Œåˆ›å»ºç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹å®‰å…¨æ€§çš„åŸºå‡†æ˜¯å…³é”®æ´»åŠ¨ä¹‹ä¸€ã€‚è¿™äº›åŸºå‡†å…è®¸å¯¹æ¨¡å‹åœ¨æ¯’æ€§ã€åè§å’Œæœ‰å®³è¡Œä¸ºç­‰ä¸åŒå®‰å…¨æ–¹é¢è¿›è¡Œæ¯”è¾ƒã€‚ç‹¬ç«‹åŸºå‡†é‡‡ç”¨ä¸åŒçš„æ–¹æ³•ã€æ•°æ®é›†å’Œè¯„ä¼°æ–¹å¼ã€‚æœ¬æ–‡ç ”ç©¶äº†è¿™äº›åŸºå‡†çš„ç¨³å¥æ€§ï¼Œé€šè¿‡ä¸åŒçš„æ–¹æ³•å¯¹ä¸€ç»„ä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œåè§æ’åï¼Œå¹¶æ¯”è¾ƒæ•´ä½“æ’åçš„ç›¸ä¼¼æ€§ã€‚ç»“æœè¡¨æ˜ï¼Œå°½ç®¡å¹¿æ³›ä½¿ç”¨çš„åè§è¯„ä¼°æ–¹æ³•äº§ç”Ÿäº†ä¸åŒçš„æ¨¡å‹æ’åã€‚æœ€åï¼Œæœ¬æ–‡ä¸ºç¤¾åŒºåœ¨ä½¿ç”¨è¿™äº›åŸºå‡†æ—¶æå‡ºäº†å»ºè®®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰åè§è¯„ä¼°åŸºå‡†åœ¨æ¨¡å‹æ’åä¸Šçš„ä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç”±äºé‡‡ç”¨ä¸åŒçš„æ•°æ®é›†å’Œè¯„ä¼°æ–¹å¼ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœçš„å¯é æ€§å—åˆ°è´¨ç–‘ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹ä¸€ç»„ä»£è¡¨æ€§æ¨¡å‹è¿›è¡Œä¸åŒåè§è¯„ä¼°æ–¹æ³•çš„æ¯”è¾ƒï¼Œåˆ†æå…¶å¯¹æ¨¡å‹æ’åçš„å½±å“ï¼Œä»è€Œæå‡ºæ”¹è¿›å»ºè®®ï¼Œå¢å¼ºè¯„ä¼°åŸºå‡†çš„ç¨³å¥æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆé€‰æ‹©å¤šä¸ªåè§è¯„ä¼°æ–¹æ³•ï¼Œç„¶åå¯¹ä¸€ç»„æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œæœ€åæ¯”è¾ƒä¸åŒæ–¹æ³•ä¸‹çš„æ¨¡å‹æ’åã€‚æ•´ä¸ªæµç¨‹åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è¯„ä¼°å’Œç»“æœåˆ†æä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†å¤šç§åè§è¯„ä¼°æ–¹æ³•çš„ç»“æœï¼Œæ­ç¤ºäº†å®ƒä»¬åœ¨æ¨¡å‹æ’åä¸Šçš„å·®å¼‚æ€§ï¼Œå¼ºè°ƒäº†è¯„ä¼°åŸºå‡†çš„é€‰æ‹©å¯¹ç»“æœçš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé€‰æ‹©äº†å¤šç§å…·æœ‰ä»£è¡¨æ€§çš„æ¨¡å‹å’Œåè§è¯„ä¼°æ–¹æ³•ï¼Œç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œå¤šæ ·æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ ‡å‡†åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†è¯´æ˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒçš„åè§è¯„ä¼°æ–¹æ³•å¯¼è‡´æ¨¡å‹æ’åå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ŒæŸäº›æ–¹æ³•çš„æ’åä¸å…¶ä»–æ–¹æ³•ç›¸å·®é«˜è¾¾30%ã€‚è¿™è¡¨æ˜è¯„ä¼°åŸºå‡†çš„é€‰æ‹©å¯¹æ¨¡å‹çš„å®‰å…¨æ€§è¯„ä¼°è‡³å…³é‡è¦ï¼Œæå‡ºäº†æ”¹è¿›å»ºè®®ä»¥æé«˜è¯„ä¼°çš„æœ‰æ•ˆæ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘å’Œè¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ç¡®ä¿æ¨¡å‹å®‰å…¨æ€§å’Œå…¬å¹³æ€§çš„åœºæ™¯ä¸­ã€‚é€šè¿‡æ”¹è¿›è¯„ä¼°åŸºå‡†ï¼Œç ”ç©¶å¯ä»¥å¸®åŠ©å¼€å‘æ›´å¯é çš„AIç³»ç»Ÿï¼Œå‡å°‘åè§å’Œæœ‰å®³è¡Œä¸ºçš„å‘ç”Ÿã€‚æœªæ¥ï¼Œéšç€AIæŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œç›¸å…³è¯„ä¼°æ–¹æ³•çš„æ ‡å‡†åŒ–å°†å¯¹è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.

