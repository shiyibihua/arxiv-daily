---
layout: default
title: Combining TSL and LLM to Automate REST API Testing: A Comparative Study
---

# Combining TSL and LLM to Automate REST API Testing: A Comparative Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05540" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05540v1</a>
  <a href="https://arxiv.org/pdf/2509.05540.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05540v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05540v1', 'Combining TSL and LLM to Automate REST API Testing: A Comparative Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thiago Barradas, Aline Paes, VÃ¢nia de Oliveira Neves

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: 10 pages, article computer science, software engineering, software testing, ia, llm

**æœŸåˆŠ**: SBES 2025 39th Brazilian Symposium on Software Engineering

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRestTSLLMï¼Œç»“åˆTSLä¸LLMè‡ªåŠ¨åŒ–REST APIæµ‹è¯•ç”¨ä¾‹ç”Ÿæˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `REST APIæµ‹è¯•` `è‡ªåŠ¨åŒ–æµ‹è¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ` `æç¤ºå·¥ç¨‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. REST APIæµ‹è¯•é¢ä¸´åˆ†å¸ƒå¼ç³»ç»Ÿå¤æ‚ã€æµ‹è¯•åœºæ™¯å¤šæ ·å’Œæ—¶é—´æœ‰é™ç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´æµ‹è¯•ä¸å……åˆ†å’Œäººå·¥æˆæœ¬é«˜ã€‚
2. RestTSLLMç»“åˆTSLå’ŒLLMï¼Œé€šè¿‡æç¤ºå·¥ç¨‹å’Œè‡ªåŠ¨åŒ–æµç¨‹ï¼Œä»OpenAPIè§„èŒƒç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œè§£å†³æµ‹è¯•åœºæ™¯å’Œè¾“å…¥æ•°æ®å®šä¹‰é—®é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒClaude 3.5 Sonnetç­‰LLMèƒ½æœ‰æ•ˆç”ŸæˆREST APIæµ‹è¯•ï¼ŒClaude 3.5 Sonnetåœ¨æˆåŠŸç‡ã€è¦†ç›–ç‡å’Œå˜å¼‚å¾—åˆ†ä¸Šè¡¨ç°æœ€ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹REST APIæµ‹è¯•ä¸­åˆ†å¸ƒå¼ç³»ç»Ÿå¤æ‚æ€§ã€åœºæ™¯å¤šæ ·æ€§å’Œæµ‹è¯•æ—¶é—´æœ‰é™ç­‰æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºRestTSLLMæ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆæµ‹è¯•è§„çº¦è¯­è¨€ï¼ˆTSLï¼‰å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è‡ªåŠ¨åŒ–ç”ŸæˆREST APIçš„æµ‹è¯•ç”¨ä¾‹ã€‚è¯¥æ–¹æ³•ä¸»è¦è§£å†³ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šæµ‹è¯•åœºæ™¯çš„åˆ›å»ºå’Œé€‚å½“è¾“å…¥æ•°æ®çš„å®šä¹‰ã€‚æå‡ºçš„è§£å†³æ–¹æ¡ˆé›†æˆäº†æç¤ºå·¥ç¨‹æŠ€æœ¯å’Œä¸€ä¸ªè‡ªåŠ¨åŒ–æµç¨‹ï¼Œä»¥è¯„ä¼°å„ç§LLMä»OpenAPIè§„èŒƒç”Ÿæˆæµ‹è¯•çš„èƒ½åŠ›ã€‚è¯„ä¼°ä¾§é‡äºæˆåŠŸç‡ã€æµ‹è¯•è¦†ç›–ç‡å’Œå˜å¼‚å¾—åˆ†ç­‰æŒ‡æ ‡ï¼Œä»è€Œç³»ç»Ÿåœ°æ¯”è¾ƒæ¨¡å‹æ€§èƒ½ã€‚ç»“æœè¡¨æ˜ï¼Œè¡¨ç°æœ€ä½³çš„LLMï¼ˆClaude 3.5 Sonnetã€Deepseek R1ã€Qwen 2.5 32bå’ŒSabia 3ï¼‰èƒ½å¤ŸæŒç»­ç”Ÿæˆç¨³å¥ä¸”ä¸Šä¸‹æ–‡è¿è´¯çš„REST APIæµ‹è¯•ã€‚å…¶ä¸­ï¼ŒClaude 3.5 Sonnetåœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œæˆä¸ºæœ¬ç ”ç©¶ä¸­æœ€é€‚åˆæ­¤ä»»åŠ¡çš„æ¨¡å‹ã€‚è¿™äº›å‘ç°çªæ˜¾äº†LLMåœ¨åŸºäºAPIè§„èŒƒè‡ªåŠ¨åŒ–ç”Ÿæˆæµ‹è¯•æ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³REST APIæµ‹è¯•è‡ªåŠ¨åŒ–ç¨‹åº¦ä½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åº”å¯¹åˆ†å¸ƒå¼ç³»ç»Ÿçš„å¤æ‚æ€§ï¼Œæ— æ³•è¦†ç›–æ‰€æœ‰å¯èƒ½çš„è¾“å…¥ç»„åˆï¼Œå¯¼è‡´æµ‹è¯•è¦†ç›–ç‡ä½ï¼Œéœ€è¦å¤§é‡çš„äººå·¥å¹²é¢„ï¼Œå¹¶ä¸”å®¹æ˜“é—æ¼æ½œåœ¨çš„æ•…éšœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç”Ÿæˆèƒ½åŠ›ï¼Œç»“åˆæµ‹è¯•è§„çº¦è¯­è¨€ï¼ˆTSLï¼‰çš„è§„èŒƒæ€§ï¼Œè‡ªåŠ¨åŒ–ç”ŸæˆREST APIçš„æµ‹è¯•ç”¨ä¾‹ã€‚é€šè¿‡æç¤ºå·¥ç¨‹ï¼Œå¼•å¯¼LLMç†è§£APIè§„èŒƒï¼Œå¹¶ç”Ÿæˆç¬¦åˆè§„èŒƒçš„æµ‹è¯•åœºæ™¯å’Œè¾“å…¥æ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRestTSLLMæ–¹æ³•åŒ…å«ä»¥ä¸‹ä¸»è¦é˜¶æ®µï¼š1) è¾“å…¥OpenAPIè§„èŒƒï¼›2) ä½¿ç”¨æç¤ºå·¥ç¨‹æŠ€æœ¯ï¼Œè®¾è®¡åˆé€‚çš„promptï¼Œå¼•å¯¼LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼›3) åˆ©ç”¨TSLå¯¹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œè§„èŒƒåŒ–å’ŒéªŒè¯ï¼›4) æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶è¯„ä¼°æµ‹è¯•ç»“æœï¼ŒåŒ…æ‹¬æˆåŠŸç‡ã€æµ‹è¯•è¦†ç›–ç‡å’Œå˜å¼‚å¾—åˆ†ï¼›5) å¯¹æ¯”ä¸åŒLLMçš„æ€§èƒ½ï¼Œé€‰æ‹©æœ€é€‚åˆè¯¥ä»»åŠ¡çš„æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMåº”ç”¨äºREST APIæµ‹è¯•ç”¨ä¾‹çš„è‡ªåŠ¨åŒ–ç”Ÿæˆã€‚ä¸ä¼ ç»Ÿçš„åŸºäºè§„åˆ™æˆ–æ¨¡æ¿çš„æµ‹è¯•ç”Ÿæˆæ–¹æ³•ç›¸æ¯”ï¼ŒLLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£APIçš„è¯­ä¹‰ï¼Œç”Ÿæˆæ›´å¤æ‚ã€æ›´å…·ä¸Šä¸‹æ–‡ç›¸å…³æ€§çš„æµ‹è¯•ç”¨ä¾‹ï¼Œä»è€Œæé«˜æµ‹è¯•è¦†ç›–ç‡å’Œå‘ç°æ½œåœ¨ç¼ºé™·çš„èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) Promptå·¥ç¨‹ï¼šè®¾è®¡æœ‰æ•ˆçš„promptï¼Œå¼•å¯¼LLMç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚Promptéœ€è¦åŒ…å«APIçš„æè¿°ã€è¾“å…¥å‚æ•°çš„ç±»å‹å’ŒèŒƒå›´ã€ä»¥åŠæœŸæœ›çš„è¾“å‡ºç»“æœç­‰ä¿¡æ¯ã€‚2) TSLè§„èŒƒï¼šä½¿ç”¨TSLå¯¹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œè§„èŒƒåŒ–ï¼Œç¡®ä¿æµ‹è¯•ç”¨ä¾‹çš„æ ¼å¼æ­£ç¡®ã€è¯­ä¹‰æ¸…æ™°ã€‚3) è¯„ä¼°æŒ‡æ ‡ï¼šä½¿ç”¨æˆåŠŸç‡ã€æµ‹è¯•è¦†ç›–ç‡å’Œå˜å¼‚å¾—åˆ†ç­‰æŒ‡æ ‡ï¼Œå…¨é¢è¯„ä¼°LLMç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒClaude 3.5 Sonnetåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå‡ä¼˜äºå…¶ä»–LLMï¼ŒåŒ…æ‹¬Deepseek R1ã€Qwen 2.5 32bå’ŒSabia 3ã€‚Claude 3.5 Sonnetèƒ½å¤Ÿç”Ÿæˆæ›´ç¨³å¥ã€æ›´å…·ä¸Šä¸‹æ–‡è¿è´¯æ€§çš„REST APIæµ‹è¯•ç”¨ä¾‹ï¼Œè¯æ˜äº†LLMåœ¨è‡ªåŠ¨åŒ–APIæµ‹è¯•æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè½¯ä»¶å¼€å‘å’Œæµ‹è¯•é¢†åŸŸï¼Œå¸®åŠ©å¼€å‘å›¢é˜Ÿè‡ªåŠ¨åŒ–ç”ŸæˆREST APIçš„æµ‹è¯•ç”¨ä¾‹ï¼Œæé«˜æµ‹è¯•æ•ˆç‡å’Œè¦†ç›–ç‡ï¼Œé™ä½äººå·¥æµ‹è¯•æˆæœ¬ï¼Œå¹¶å°½æ—©å‘ç°æ½œåœ¨çš„ç¼ºé™·ã€‚æœªæ¥å¯æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„APIæµ‹è¯•ï¼Œå¹¶é›†æˆåˆ°æŒç»­é›†æˆ/æŒç»­äº¤ä»˜ï¼ˆCI/CDï¼‰æµç¨‹ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The effective execution of tests for REST APIs remains a considerable challenge for development teams, driven by the inherent complexity of distributed systems, the multitude of possible scenarios, and the limited time available for test design. Exhaustive testing of all input combinations is impractical, often resulting in undetected failures, high manual effort, and limited test coverage. To address these issues, we introduce RestTSLLM, an approach that uses Test Specification Language (TSL) in conjunction with Large Language Models (LLMs) to automate the generation of test cases for REST APIs. The approach targets two core challenges: the creation of test scenarios and the definition of appropriate input data. The proposed solution integrates prompt engineering techniques with an automated pipeline to evaluate various LLMs on their ability to generate tests from OpenAPI specifications. The evaluation focused on metrics such as success rate, test coverage, and mutation score, enabling a systematic comparison of model performance. The results indicate that the best-performing LLMs - Claude 3.5 Sonnet (Anthropic), Deepseek R1 (Deepseek), Qwen 2.5 32b (Alibaba), and Sabia 3 (Maritaca) - consistently produced robust and contextually coherent REST API tests. Among them, Claude 3.5 Sonnet outperformed all other models across every metric, emerging in this study as the most suitable model for this task. These findings highlight the potential of LLMs to automate the generation of tests based on API specifications.

