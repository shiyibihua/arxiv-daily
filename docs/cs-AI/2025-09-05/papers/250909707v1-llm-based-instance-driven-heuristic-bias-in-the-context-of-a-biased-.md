---
layout: default
title: LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm
---

# LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09707" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09707v1</a>
  <a href="https://arxiv.org/pdf/2509.09707.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09707v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09707v1', 'LLM-Based Instance-Driven Heuristic Bias In the Context of a Biased Random Key Genetic Algorithm')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Camilo ChacÃ³n Sartori, MartÃ­n Isla Pino, Pedro Pinacho-Davidson, Christian Blum

**åˆ†ç±»**: cs.NE, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: Submitted to a journal for review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºLLMçš„å®ä¾‹é©±åŠ¨å¯å‘å¼åç½®BRKGAç®—æ³•ï¼Œè§£å†³NPéš¾çš„æœ€é•¿è¿è¡Œå­åºåˆ—é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å…ƒå¯å‘å¼ç®—æ³•` `é—ä¼ ç®—æ³•` `ç»„åˆä¼˜åŒ–` `å¯å‘å¼åç½®` `å®ä¾‹é©±åŠ¨` `æœ€é•¿è¿è¡Œå­åºåˆ—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¿½ç•¥äº†é—®é¢˜å®ä¾‹çš„ç»“æ„å±æ€§ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨LLMåœ¨å…ƒå¯å‘å¼ç®—æ³•ä¸­çš„æ½œåŠ›ã€‚
2. æå‡ºä¸€ç§äººä¸LLMåä½œçš„æ–¹æ³•ï¼Œå…±åŒè®¾è®¡å®ä¾‹ç›¸å…³çš„åº¦é‡ï¼Œå¹¶åˆ©ç”¨LLMç”Ÿæˆå¯å‘å¼åç½®ï¼Œå¼•å¯¼BRKGAæœç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚å®ä¾‹ä¸Šæ˜¾è‘—ä¼˜äºæ ‡å‡†BRKGAåŸºçº¿ï¼ŒéªŒè¯äº†LLMé©±åŠ¨çš„å¯å‘å¼åç½®çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é›†æˆåˆ°å…ƒå¯å‘å¼ç®—æ³•ä¸­ï¼Œä»¥è§£å†³å¤æ‚çš„ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨LLMä¸å¸¦åå¥½çš„éšæœºå¯†é’¥é—ä¼ ç®—æ³•ï¼ˆBRKGAï¼‰ç›¸ç»“åˆï¼Œè§£å†³NPéš¾çš„æœ€é•¿è¿è¡Œå­åºåˆ—é—®é¢˜ã€‚é€šè¿‡äººä¸LLMçš„åä½œï¼Œå…±åŒè®¾è®¡å¹¶å®ç°äº†ä¸€ç»„è®¡ç®—é«˜æ•ˆçš„åº¦é‡ã€‚LLMåˆ†æè¿™äº›ç‰¹å®šäºå®ä¾‹çš„åº¦é‡ï¼Œç”Ÿæˆå®šåˆ¶çš„å¯å‘å¼åç½®ï¼Œå¼•å¯¼BRKGAæœç´¢æœ‰å¸Œæœ›çš„åŒºåŸŸã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä¸æ ‡å‡†BRKGAåŸºçº¿ç›¸æ¯”ï¼Œæœ€ä½³æ··åˆæ–¹æ³•BRKGA+Llama-4-Maverickåœ¨æœ€å¤æ‚çš„å®ä¾‹ä¸Šå®ç°äº†æ˜¾è‘—çš„ç»Ÿè®¡æ”¹è¿›ã€‚ç ”ç©¶ç»“æœè¯å®ï¼Œåˆ©ç”¨LLMç”Ÿæˆå…ˆéªŒçš„ã€å®ä¾‹é©±åŠ¨çš„å¯å‘å¼åç½®æ˜¯å¢å¼ºå¤æ‚ä¼˜åŒ–é¢†åŸŸå…ƒå¯å‘å¼ç®—æ³•çš„æœ‰æ•ˆæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³NPéš¾çš„æœ€é•¿è¿è¡Œå­åºåˆ—ï¼ˆLongest Run Subsequenceï¼‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºå…ƒå¯å‘å¼ç®—æ³•çš„æ–¹æ³•ï¼Œé€šå¸¸ç¼ºä¹å¯¹é—®é¢˜å®ä¾‹ç‰¹æ€§çš„è‡ªé€‚åº”æ€§ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨LLMçš„çŸ¥è¯†æ¥æŒ‡å¯¼æœç´¢è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„å¼ºå¤§åˆ†æèƒ½åŠ›ï¼Œæ ¹æ®ç‰¹å®šé—®é¢˜å®ä¾‹çš„ç‰¹å¾ï¼Œç”Ÿæˆå®šåˆ¶åŒ–çš„å¯å‘å¼åç½®ã€‚è¿™ç§åç½®èƒ½å¤Ÿå¼•å¯¼BRKGAç®—æ³•æ›´æœ‰é’ˆå¯¹æ€§åœ°æœç´¢è§£ç©ºé—´ï¼Œä»è€Œæé«˜æ±‚è§£æ•ˆç‡å’Œè´¨é‡ã€‚é€šè¿‡äººä¸LLMçš„åä½œï¼Œå…±åŒè®¾è®¡èƒ½å¤Ÿåæ˜ å®ä¾‹ç‰¹å¾çš„åº¦é‡ï¼Œä½¿å¾—LLMèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£é—®é¢˜å®ä¾‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) äººå·¥ä¸LLMåä½œï¼Œè®¾è®¡å¹¶å®ç°ä¸€ç»„è®¡ç®—é«˜æ•ˆçš„ã€æè¿°é—®é¢˜å®ä¾‹ç‰¹å¾çš„åº¦é‡ï¼›2) LLMåˆ†æè¿™äº›åº¦é‡ï¼Œç”Ÿæˆé’ˆå¯¹è¯¥å®ä¾‹çš„å¯å‘å¼åç½®ï¼›3) å°†è¯¥å¯å‘å¼åç½®èå…¥BRKGAç®—æ³•ä¸­ï¼ŒæŒ‡å¯¼å…¶æœç´¢è¿‡ç¨‹ã€‚BRKGAç®—æ³•ä½¿ç”¨éšæœºå¯†é’¥ç¼–ç è§£ï¼Œå¹¶é€šè¿‡é—ä¼ æ“ä½œè¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†LLMç”¨äºç”Ÿæˆå®ä¾‹é©±åŠ¨çš„å¯å‘å¼åç½®ã€‚ä¸ä¼ ç»Ÿçš„å¯å‘å¼ç®—æ³•æˆ–åŸºäºLLMçš„ä»£ç ç”Ÿæˆæ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸æ˜¯ç›´æ¥ç”Ÿæˆä»£ç æˆ–è§„åˆ™ï¼Œè€Œæ˜¯åˆ©ç”¨LLMçš„æ¨ç†èƒ½åŠ›ï¼Œæ ¹æ®å®ä¾‹ç‰¹å¾ç”Ÿæˆä¸€ä¸ªåç½®ï¼Œä»è€Œæ›´çµæ´»åœ°æŒ‡å¯¼å…ƒå¯å‘å¼ç®—æ³•çš„æœç´¢ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆåæ˜ é—®é¢˜å®ä¾‹ç‰¹å¾çš„åº¦é‡ï¼›2) å¦‚ä½•åˆ©ç”¨LLMå°†è¿™äº›åº¦é‡è½¬åŒ–ä¸ºæœ‰æ•ˆçš„å¯å‘å¼åç½®ï¼›3) å¦‚ä½•å°†å¯å‘å¼åç½®èå…¥BRKGAç®—æ³•ä¸­ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥é€šè¿‡è°ƒæ•´é€‰æ‹©æ¦‚ç‡æˆ–äº¤å‰æ¦‚ç‡æ¥å®ç°ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†Llama-4-Maverickä½œä¸ºLLMï¼Œå¹¶é’ˆå¯¹æœ€é•¿è¿è¡Œå­åºåˆ—é—®é¢˜è®¾è®¡äº†ç‰¹å®šçš„åº¦é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBRKGA+Llama-4-Maverickæ–¹æ³•åœ¨è§£å†³æœ€é•¿è¿è¡Œå­åºåˆ—é—®é¢˜ä¸Šï¼Œæ˜¾è‘—ä¼˜äºæ ‡å‡†BRKGAåŸºçº¿ã€‚ç‰¹åˆ«æ˜¯åœ¨æœ€å¤æ‚çš„å®ä¾‹ä¸Šï¼Œè¯¥æ–¹æ³•å–å¾—äº†ç»Ÿè®¡æ„ä¹‰ä¸Šçš„æ˜¾è‘—æ”¹è¿›ï¼ŒéªŒè¯äº†LLMé©±åŠ¨çš„å®ä¾‹é©±åŠ¨å¯å‘å¼åç½®çš„æœ‰æ•ˆæ€§ã€‚å®éªŒæ¶µç›–äº†1050ä¸ªä¸åŒå¤æ‚åº¦çš„ç”Ÿæˆå®ä¾‹ï¼Œä¿è¯äº†ç»“æœçš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é—®é¢˜å®ä¾‹å…·æœ‰æ˜¾è‘—å·®å¼‚æ€§çš„åœºæ™¯ä¸‹ã€‚ä¾‹å¦‚ï¼Œåœ¨ç”Ÿäº§è°ƒåº¦ã€èµ„æºåˆ†é…ã€è·¯å¾„è§„åˆ’ç­‰é¢†åŸŸï¼Œå¯ä»¥åˆ©ç”¨LLMåˆ†æå…·ä½“å®ä¾‹çš„ç‰¹å¾ï¼Œç”Ÿæˆå®šåˆ¶åŒ–çš„å¯å‘å¼åç½®ï¼Œä»è€Œæé«˜ä¼˜åŒ–ç®—æ³•çš„æ•ˆç‡å’Œæ•ˆæœã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„ä¼˜åŒ–é—®é¢˜å’Œæ›´å¼ºå¤§çš„LLMæ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Integrating Large Language Models (LLMs) within metaheuristics opens a novel path for solving complex combinatorial optimization problems. While most existing approaches leverage LLMs for code generation to create or refine specific heuristics, they often overlook the structural properties of individual problem instances. In this work, we introduce a novel framework that integrates LLMs with a Biased Random-Key Genetic Algorithm (BRKGA) to solve the NP-hard Longest Run Subsequence problem. Our approach extends the instance-driven heuristic bias paradigm by introducing a human-LLM collaborative process to co-design and implement a set of computationally efficient metrics. The LLM analyzes these instance-specific metrics to generate a tailored heuristic bias, which steers the BRKGA toward promising areas of the search space. We conduct a comprehensive experimental evaluation, including rigorous statistical tests, convergence and behavioral analyses, and targeted ablation studies, comparing our method against a standard BRKGA baseline across 1,050 generated instances of varying complexity. Results show that our top-performing hybrid, BRKGA+Llama-4-Maverick, achieves statistically significant improvements over the baseline, particularly on the most complex instances. Our findings confirm that leveraging an LLM to produce an a priori, instance-driven heuristic bias is a valuable approach for enhancing metaheuristics in complex optimization domains.

