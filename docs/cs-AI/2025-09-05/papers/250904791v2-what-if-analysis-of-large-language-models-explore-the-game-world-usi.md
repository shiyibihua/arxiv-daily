---
layout: default
title: What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking
---

# What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04791" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04791v2</a>
  <a href="https://arxiv.org/pdf/2509.04791.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04791v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04791v2', 'What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuan Sui, Yanming Zhang, Yi Liao, Yu Gu, Guohua Tang, Zhongqian Sun, Wei Yang, Bryan Hooi

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05 (æ›´æ–°: 2025-12-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWiA-LLMï¼Œåˆ©ç”¨ä¸»åŠ¨æ€è€ƒè¿›è¡Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨MOBAæ¸¸æˆä¸­çš„å‡è®¾åˆ†æã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åäº‹å®æ¨ç†` `ä¸–ç•Œæ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¸¸æˆAI`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨åŠ¨æ€æ¸¸æˆä¸­å†³ç­–æ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„åäº‹å®æ¨ç†èƒ½åŠ›ï¼Œéš¾ä»¥å‡†ç¡®é¢„æµ‹åŠ¨ä½œçš„æœªæ¥å½±å“ã€‚
2. WiA-LLMå°†LLMè®­ç»ƒä¸ºæ˜¾å¼çš„ã€åŸºäºè¯­è¨€çš„ä¸–ç•Œæ¨¡å‹ï¼Œé€šè¿‡è¯­è¨€å»ºæ¨¡æ¸¸æˆçŠ¶æ€æ¼”å˜å’Œæä¾›æ–‡æœ¬è§£é‡Šã€‚
3. å®éªŒè¡¨æ˜ï¼ŒWiA-LLMåœ¨ç‹è€…è£è€€ä¸­é¢„æµ‹æ¸¸æˆçŠ¶æ€å˜åŒ–çš„å‡†ç¡®ç‡æ˜¾è‘—æå‡ï¼Œä¸”ç­–ç•¥è¡Œä¸ºæ›´æ¥è¿‘ä¸“å®¶ç©å®¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ¨ç†å’Œä¿¡æ¯æ£€ç´¢æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åŠ¨æ€ã€éƒ¨åˆ†å¯è§‚å¯Ÿã€é«˜é£é™©çš„ç¯å¢ƒï¼ˆå¦‚MOBAæ¸¸æˆï¼‰ä¸­è¿›è¡Œå†³ç­–æ—¶ä»ç„¶ä¸å¯é ã€‚ä¸€ä¸ªå…³é”®é™åˆ¶æ˜¯åäº‹å®æ¨ç†èƒ½åŠ›è–„å¼±ï¼šLLMséš¾ä»¥å¯¹å€™é€‰åŠ¨ä½œåŠå…¶æœªæ¥åæœè¿›è¡Œç²¾ç¡®çš„å‡è®¾åˆ†æã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†å‡è®¾åˆ†æLLM (WiA-LLM)ï¼Œè¯¥æ¡†æ¶å°†LLMè®­ç»ƒæˆä¸€ä¸ªæ˜¾å¼çš„ã€åŸºäºè¯­è¨€çš„ä¸–ç•Œæ¨¡å‹ã€‚WiA-LLMä¸æ˜¯ç”¨æ½œåœ¨å‘é‡è¡¨ç¤ºç¯å¢ƒï¼Œè€Œæ˜¯ä½¿ç”¨è¯­è¨€æ¥å»ºæ¨¡æ¸¸æˆçŠ¶æ€å¦‚ä½•éšæ—¶é—´å’Œå€™é€‰åŠ¨ä½œæ¼”å˜ï¼Œå¹¶ä¸ºè¿™äº›é¢„æµ‹ç»“æœæä¾›æ–‡æœ¬è§£é‡Šã€‚è¿™ç§æ˜¾å¼å»ºæ¨¡æ”¯æŒï¼ˆ1ï¼‰å¯è§£é‡Šæ€§ï¼Œå› ä¸ºæ¨¡å‹çš„é¢„æµ‹å’Œåº•å±‚åŸç†æ˜¯äººç±»å¯è¯»çš„ï¼Œä»¥åŠï¼ˆ2ï¼‰è¯­ä¹‰æ³›åŒ–ï¼Œå› ä¸ºæ¨¡å‹å¯ä»¥åœ¨å…±äº«ç›¸ä¼¼æ¸¸æˆæ¦‚å¿µï¼ˆä¾‹å¦‚ï¼Œè§’è‰²ã€ç›®æ ‡æˆ–æˆ˜æœ¯ï¼‰çš„æƒ…å†µä¸‹è¿ç§»çŸ¥è¯†ã€‚WiA-LLMçš„è®­ç»ƒåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šåœ¨ç±»äººæ¨ç†è½¨è¿¹ä¸Šè¿›è¡Œç›‘ç£å¼å¾®è°ƒï¼Œç„¶åé€šè¿‡åŸºäºç»“æœçš„å¼ºåŒ–å­¦ä¹ ï¼Œæ ¹æ®é¢„æµ‹å’ŒçœŸå®æœªæ¥çŠ¶æ€ä¹‹é—´çš„å·®å¼‚æ¥è·å¾—å¥–åŠ±ã€‚åœ¨ç‹è€…è£è€€(HoK)ç¯å¢ƒä¸­ï¼ŒWiA-LLMåœ¨é¢„æµ‹æ¸¸æˆçŠ¶æ€å˜åŒ–æ–¹é¢çš„å‡†ç¡®ç‡è¾¾åˆ°74.2%ï¼ˆæ¯”åŸºç¡€æ¨¡å‹æé«˜27%ï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°å…·æœ‰WiA-LLMçš„æ™ºèƒ½ä½“æ¯”çº¯ç²¹ååº”å¼çš„LLMæ™ºèƒ½ä½“è¡¨ç°å‡ºæ›´æ¥è¿‘ä¸“å®¶ç©å®¶çš„æˆ˜ç•¥è¡Œä¸ºï¼Œè¡¨æ˜å…¶å†³ç­–æ›´å…·å‰ç»æ€§å’Œä¸ä¸“å®¶å¯¹é½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åŠ¨æ€ã€éƒ¨åˆ†å¯è§‚å¯Ÿçš„æ¸¸æˆç¯å¢ƒä¸­è¿›è¡Œå†³ç­–æ—¶ï¼Œåäº‹å®æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºéšå‘é‡è¡¨ç¤ºç¯å¢ƒï¼Œéš¾ä»¥è¿›è¡Œç²¾ç¡®çš„å‡è®¾åˆ†æï¼Œå¹¶ä¸”ç¼ºä¹å¯è§£é‡Šæ€§ã€‚è¿™å¯¼è‡´LLMsåœ¨å¤æ‚æ¸¸æˆåœºæ™¯ä¸­éš¾ä»¥åšå‡ºå¯é çš„å†³ç­–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMè®­ç»ƒæˆä¸€ä¸ªæ˜¾å¼çš„ã€åŸºäºè¯­è¨€çš„ä¸–ç•Œæ¨¡å‹ã€‚é€šè¿‡ä½¿ç”¨è¯­è¨€æ¥å»ºæ¨¡æ¸¸æˆçŠ¶æ€éšæ—¶é—´å’Œå€™é€‰åŠ¨ä½œçš„æ¼”å˜ï¼ŒWiA-LLMèƒ½å¤Ÿæä¾›å¯è§£é‡Šçš„é¢„æµ‹ç»“æœï¼Œå¹¶æ”¯æŒè¯­ä¹‰æ³›åŒ–ã€‚è¿™ç§æ˜¾å¼å»ºæ¨¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¸¸æˆæ¦‚å¿µï¼Œå¹¶åœ¨ä¸åŒåœºæ™¯ä¸­è¿ç§»çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWiA-LLMçš„è®­ç»ƒåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚ç¬¬ä¸€é˜¶æ®µæ˜¯ç›‘ç£å¼å¾®è°ƒï¼Œä½¿ç”¨ç±»äººæ¨ç†è½¨è¿¹æ•°æ®å¯¹LLMè¿›è¡Œè®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ¨¡ä»¿äººç±»ç©å®¶çš„æ¨ç†è¿‡ç¨‹ã€‚ç¬¬äºŒé˜¶æ®µæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨åŸºäºç»“æœçš„å¥–åŠ±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œå¥–åŠ±å‡½æ•°åŸºäºé¢„æµ‹çš„æ¸¸æˆçŠ¶æ€ä¸çœŸå®æ¸¸æˆçŠ¶æ€ä¹‹é—´çš„å·®å¼‚ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šè¾“å…¥å½“å‰æ¸¸æˆçŠ¶æ€å’Œå€™é€‰åŠ¨ä½œï¼ŒWiA-LLMé¢„æµ‹æœªæ¥çš„æ¸¸æˆçŠ¶æ€ï¼Œå¹¶æä¾›æ–‡æœ¬è§£é‡Šï¼Œç„¶åæ ¹æ®é¢„æµ‹ç»“æœå’ŒçœŸå®ç»“æœè®¡ç®—å¥–åŠ±ï¼Œç”¨äºæ›´æ–°æ¨¡å‹å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨è¯­è¨€ä½œä¸ºä¸–ç•Œæ¨¡å‹çš„è¡¨ç¤ºå½¢å¼ã€‚ä¸ä¼ ç»Ÿçš„éšå‘é‡è¡¨ç¤ºç›¸æ¯”ï¼Œè¯­è¨€å…·æœ‰æ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼ŒWiA-LLMé€šè¿‡æ˜¾å¼åœ°å»ºæ¨¡æ¸¸æˆçŠ¶æ€çš„æ¼”å˜è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¿›è¡Œåäº‹å®æ¨ç†ï¼Œå¹¶æ”¯æŒè¯­ä¹‰æ³›åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šWiA-LLMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) ä½¿ç”¨Transformeræ¶æ„ä½œä¸ºLLMçš„åŸºç¡€æ¨¡å‹ï¼›(2) è®¾è®¡åˆé€‚çš„æç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰æ¥æŒ‡å¯¼LLMè¿›è¡Œæ¨ç†ï¼›(3) ä½¿ç”¨åŸºäºç»“æœçš„å¥–åŠ±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹é¢„æµ‹å‡†ç¡®çš„æœªæ¥æ¸¸æˆçŠ¶æ€ï¼›(4) ä½¿ç”¨ç›‘ç£å¼å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆçš„è®­ç»ƒæ–¹æ³•ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒWiA-LLMåœ¨ç‹è€…è£è€€(HoK)ç¯å¢ƒä¸­ï¼Œé¢„æµ‹æ¸¸æˆçŠ¶æ€å˜åŒ–çš„å‡†ç¡®ç‡è¾¾åˆ°74.2%ï¼Œç›¸æ¯”äºåŸºç¡€æ¨¡å‹æå‡äº†27%ã€‚æ­¤å¤–ï¼Œé…å¤‡WiA-LLMçš„æ™ºèƒ½ä½“åœ¨æ¸¸æˆä¸­çš„ç­–ç•¥è¡Œä¸ºæ›´æ¥è¿‘ä¸“å®¶ç©å®¶ï¼Œè¡¨æ˜å…¶å†³ç­–æ›´å…·å‰ç»æ€§å’Œä¸ä¸“å®¶å¯¹é½ã€‚è¿™äº›ç»“æœéªŒè¯äº†WiA-LLMåœ¨æé«˜LLMåäº‹å®æ¨ç†èƒ½åŠ›å’Œå†³ç­–æ°´å¹³æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WiA-LLMçš„ç ”ç©¶æˆæœå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦å¤æ‚å†³ç­–å’Œæ¨ç†çš„åŠ¨æ€ç¯å¢ƒä¸­ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººå¯¼èˆªã€é‡‘èäº¤æ˜“ç­‰ã€‚é€šè¿‡æé«˜LLMçš„åäº‹å®æ¨ç†èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ï¼Œå¯ä»¥ä½¿å…¶åœ¨è¿™äº›é¢†åŸŸä¸­åšå‡ºæ›´å¯é ã€æ›´åˆç†çš„å†³ç­–ï¼Œä»è€Œæé«˜æ•ˆç‡å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›äººæœºåä½œï¼Œä½¿äººç±»èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»AIç³»ç»Ÿçš„å†³ç­–è¿‡ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are effective at reasoning and information retrieval, but remain unreliable for decision-making in dynamic, partially observable, high-stakes environments such as MOBA games. One key limitation is weak counterfactual reasoning: LLMs struggle to conduct precise what-if analysis over candidate actions and their future consequences. We address this limitation with What-if Analysis LLM (WiA-LLM), a framework that trains an LLM as an explicit language-based world model. Instead of representing the environment in latent vectors, WiA-LLM models how the game state evolves over time with candidate actions using language, and provides textual justifications for these predicted outcomes. This explicit modeling supports (1) interpretability, since the model's predictions and underlying rationales are human-readable, and (2) semantic generalization, as the model can transfer knowledge across situations that share similar game concepts (e.g., roles, objectives, or tactics). WiA-LLM is trained in two stages: supervised fine-tuning on human-like reasoning traces, followed by reinforcement learning with outcome-based rewards that depend on the discrepancy between predicted and ground-truth future states. In the Honor of Kings (HoK) environment, WiA-LLM attains 74.2\% accuracy (27\%$\uparrow$ vs. base model) in forecasting game-state changes. In addition, we find that agents with WiA-LLM exhibit closer strategic behavior to expert players than purely reactive LLM agents, indicating more foresight-aware and expert-aligned decision-making.

