---
layout: default
title: Authorship Without Writing: Large Language Models and the Senior Author Analogy
---

# Authorship Without Writing: Large Language Models and the Senior Author Analogy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05390" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05390v1</a>
  <a href="https://arxiv.org/pdf/2509.05390.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05390v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05390v1', 'Authorship Without Writing: Large Language Models and the Senior Author Analogy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Clint Hurshman, Sebastian Porsdam Mann, Julian Savulescu, Brian D. Earp

**åˆ†ç±»**: cs.CY, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: 28 pages, 0 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç±»æ¯”èµ„æ·±ä½œè€…ï¼šæ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å­¦æœ¯å†™ä½œä¸­çš„ä½œè€…èº«ä»½é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä½œè€…èº«ä»½` `å­¦æœ¯å†™ä½œ` `ç”Ÿç‰©ä¼¦ç†å­¦` `äººå·¥æ™ºèƒ½ä¼¦ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å­¦æœ¯å†™ä½œä¸­çš„è§’è‰²å’Œä½œè€…èº«ä»½å½’å±é—®é¢˜ï¼Œç°æœ‰è§‚ç‚¹å­˜åœ¨äº‰è®®ã€‚
2. è®ºæ–‡æå‡ºå°†LLMçš„ä½¿ç”¨ç±»æ¯”äºèµ„æ·±ä½œè€…ï¼Œè®¤ä¸ºåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼ŒLLMå¯ä»¥è¢«è§†ä¸ºä½œè€…ã€‚
3. è®ºæ–‡é€šè¿‡è®ºè¯LLMåœ¨å­¦æœ¯å†™ä½œä¸­çš„ä½œç”¨ï¼Œå‘¼åé‡æ–°å®¡è§†æˆ–ä¿®è®¢ç°æœ‰çš„ä½œè€…èº«ä»½æ ‡å‡†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†åœ¨ç”Ÿç‰©ä¼¦ç†å­¦ã€ç§‘å­¦å’ŒåŒ»å­¦å†™ä½œä¸­ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„äº‰è®®ã€‚å°½ç®¡åœ¨æŸäº›åœˆå­é‡Œæ™®éè®¤ä¸ºLLMsä¸èƒ½è¢«è§†ä¸ºä½œè€…ï¼Œä½†å¯¹äºä½¿ç”¨LLMsçš„äººç±»æ˜¯å¦ä»¥åŠå¦‚ä½•è¢«è§†ä¸ºä½œè€…ï¼Œå°šæœªè¾¾æˆå…±è¯†ã€‚åœ¨è®¸å¤šé¢†åŸŸï¼Œä½œè€…èº«ä»½åˆ†å¸ƒåœ¨å¤§å‹ç ”ç©¶å›¢é˜Ÿä¸­ï¼Œå…¶ä¸­ä¸€äº›äººï¼ŒåŒ…æ‹¬æŒ‡å¯¼å’Œå†³å®šé¡¹ç›®èŒƒå›´å¹¶æœ€ç»ˆä¿è¯å…¶å®Œæ•´æ€§çš„èµ„æ·±ä½œè€…ï¼Œå¯èƒ½æ²¡æœ‰å†™ä¸€ä¸ªå­—ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è®¤ä¸ºï¼ˆåœ¨ç‰¹å®šæ¡ä»¶ä¸‹ï¼‰ä½¿ç”¨LLMsç±»ä¼¼äºä¸€ç§èµ„æ·±ä½œè€…èº«ä»½ã€‚åŸºäºæ­¤è§‚ç‚¹ï¼Œå³ä½¿ä½¿ç”¨LLMsç”Ÿæˆç ”ç©¶è®ºæ–‡çš„å®Œæ•´è‰ç¨¿ï¼Œä¹Ÿå¯ä»¥æ ¹æ®è®¸å¤šé¢†åŸŸå…¬è®¤çš„æ ‡å‡†ï¼Œè¢«è®¤ä¸ºæ˜¯åˆæ³•çš„ä½œè€…èº«ä»½ã€‚æˆ‘ä»¬çš„ç»“è®ºæ˜¯ï¼Œè¦ä¹ˆè¿™ç§ä½¿ç”¨åº”è¯¥è¢«è®¤ä¸ºæ˜¯åˆæ³•çš„ï¼Œè¦ä¹ˆå½“å‰çš„ä½œè€…èº«ä»½æ ‡å‡†éœ€è¦è¿›è¡Œæ ¹æœ¬æ€§çš„ä¿®è®¢ã€‚å£°æ˜ï¼šGPT-5ç”¨äºå¸®åŠ©æ ¼å¼åŒ–Box 1ã€‚AIæœªç”¨äºæœ¬æ–‡ç¨¿å‡†å¤‡æˆ–å†™ä½œçš„ä»»ä½•å…¶ä»–éƒ¨åˆ†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‚ä¸å­¦æœ¯å†™ä½œæ—¶ï¼Œå…¶ä½œè€…èº«ä»½çš„å½’å±é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦äº‰è®®åœ¨äºï¼Œç›´æ¥å¦å®šLLMsçš„ä½œè€…èº«ä»½ï¼Œæˆ–è€…å¿½ç•¥LLMsåœ¨å†™ä½œè¿‡ç¨‹ä¸­çš„å®é™…è´¡çŒ®ã€‚è¿™ç§äº‰è®®çš„æ ¸å¿ƒåœ¨äºï¼Œå¦‚ä½•å®šä¹‰å’Œè¡¡é‡ä½œè€…èº«ä»½ï¼Œä»¥åŠå¦‚ä½•çœ‹å¾…LLMsåœ¨å†™ä½œè¿‡ç¨‹ä¸­çš„ä½œç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMsçš„ä½¿ç”¨ç±»æ¯”äºèµ„æ·±ä½œè€…ã€‚èµ„æ·±ä½œè€…é€šå¸¸è´Ÿè´£é¡¹ç›®çš„æ•´ä½“æ–¹å‘ã€ç ”ç©¶è®¾è®¡å’Œæœ€ç»ˆæˆæœçš„è´¨é‡ï¼Œä½†å¯èƒ½å¹¶ä¸ç›´æ¥å‚ä¸å†™ä½œã€‚ç±»ä¼¼åœ°ï¼Œè®ºæ–‡è®¤ä¸ºï¼Œå¦‚æœäººç±»ç ”ç©¶è€…èƒ½å¤Ÿæœ‰æ•ˆåœ°æŒ‡å¯¼å’Œæ§åˆ¶LLMsçš„å†™ä½œè¿‡ç¨‹ï¼Œå¹¶å¯¹æœ€ç»ˆæˆæœè´Ÿè´£ï¼Œé‚£ä¹ˆLLMsçš„ä½¿ç”¨å¯ä»¥è¢«è§†ä¸ºä¸€ç§èµ„æ·±ä½œè€…èº«ä»½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡å¹¶æ²¡æœ‰æå‡ºä¸€ä¸ªå…·ä½“çš„æŠ€æœ¯æ¡†æ¶ï¼Œè€Œæ˜¯ä¸€ç§æ¦‚å¿µæ€§çš„æ¡†æ¶ã€‚å…¶æ ¸å¿ƒåœ¨äºï¼Œå°†LLMsè§†ä¸ºä¸€ç§å†™ä½œå·¥å…·ï¼Œç±»ä¼¼äºèµ„æ·±ä½œè€…ä½¿ç”¨çš„å…¶ä»–å·¥å…·ã€‚å…³é”®åœ¨äºï¼Œäººç±»ç ”ç©¶è€…éœ€è¦å¯¹LLMsçš„è¾“å‡ºè¿›è¡Œä¸¥æ ¼çš„å®¡æŸ¥ã€ä¿®æ”¹å’ŒéªŒè¯ï¼Œä»¥ç¡®ä¿æœ€ç»ˆæˆæœçš„è´¨é‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼Œæå‡ºäº†å°†LLMsçš„ä½¿ç”¨ç±»æ¯”äºèµ„æ·±ä½œè€…çš„è§‚ç‚¹ã€‚è¿™ç§è§‚ç‚¹æŒ‘æˆ˜äº†ä¼ ç»Ÿçš„ä½œè€…èº«ä»½å®šä¹‰ï¼Œå¹¶ä¸ºLLMsåœ¨å­¦æœ¯å†™ä½œä¸­çš„åº”ç”¨æä¾›äº†æ–°çš„è§†è§’ã€‚é€šè¿‡ç±»æ¯”èµ„æ·±ä½œè€…ï¼Œè®ºæ–‡è¯•å›¾ä¸ºLLMsåœ¨å­¦æœ¯å†™ä½œä¸­æ‰¾åˆ°ä¸€ä¸ªåˆç†çš„å®šä½ï¼Œå¹¶ä¸ºæœªæ¥çš„ä½œè€…èº«ä»½æ ‡å‡†åˆ¶å®šæä¾›å‚è€ƒã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡å¹¶æ²¡æœ‰æ¶‰åŠå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚ï¼Œè€Œæ˜¯ä¾§é‡äºæ¦‚å¿µæ€§çš„è®ºè¯ã€‚å…³é”®åœ¨äºï¼Œè®ºæ–‡å¼ºè°ƒäº†äººç±»ç ”ç©¶è€…åœ¨LLMsä½¿ç”¨è¿‡ç¨‹ä¸­çš„ä¸»å¯¼ä½œç”¨å’Œè´£ä»»ã€‚è¿™æ„å‘³ç€ï¼Œäººç±»ç ”ç©¶è€…éœ€è¦å…·å¤‡æ‰¹åˆ¤æ€§æ€ç»´ã€ä¸“ä¸šçŸ¥è¯†å’Œä¼¦ç†æ„è¯†ï¼Œä»¥ç¡®ä¿LLMsçš„è¾“å‡ºç¬¦åˆå­¦æœ¯è§„èŒƒå’Œä¼¦ç†æ ‡å‡†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡çš„æ ¸å¿ƒäº®ç‚¹åœ¨äºæå‡ºäº†LLMä½¿ç”¨ç±»æ¯”äºèµ„æ·±ä½œè€…çš„è§‚ç‚¹ï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿä½œè€…èº«ä»½çš„å®šä¹‰ã€‚è™½ç„¶æ²¡æœ‰æä¾›å…·ä½“çš„å®éªŒæ•°æ®ï¼Œä½†é€šè¿‡ç±»æ¯”è®ºè¯ï¼Œä¸ºLLMåœ¨å­¦æœ¯å†™ä½œä¸­çš„åº”ç”¨æä¾›äº†æ–°çš„è§†è§’ï¼Œå¹¶å¼•å‘äº†å¯¹ç°æœ‰ä½œè€…èº«ä»½æ ‡å‡†çš„æ·±åˆ»åæ€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå­¦æœ¯å‡ºç‰ˆé¢†åŸŸï¼Œæœ‰åŠ©äºé‡æ–°è¯„ä¼°å’Œå®šä¹‰åœ¨äººå·¥æ™ºèƒ½è¾…åŠ©å†™ä½œèƒŒæ™¯ä¸‹çš„ä½œè€…èº«ä»½æ ‡å‡†ã€‚å®ƒèƒ½ä¿ƒè¿›æ›´åˆç†åœ°ä½¿ç”¨LLMsè¿›è¡Œç§‘ç ”ï¼Œå¹¶ä¸ºå­¦æœ¯ç•Œåˆ¶å®šç›¸å…³ä¼¦ç†è§„èŒƒæä¾›ç†è®ºåŸºç¡€ï¼Œä»è€Œæ¨åŠ¨ç§‘ç ”æ•ˆç‡å’Œåˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The use of large language models (LLMs) in bioethical, scientific, and medical writing remains controversial. While there is broad agreement in some circles that LLMs cannot count as authors, there is no consensus about whether and how humans using LLMs can count as authors. In many fields, authorship is distributed among large teams of researchers, some of whom, including paradigmatic senior authors who guide and determine the scope of a project and ultimately vouch for its integrity, may not write a single word. In this paper, we argue that LLM use (under specific conditions) is analogous to a form of senior authorship. On this view, the use of LLMs, even to generate complete drafts of research papers, can be considered a legitimate form of authorship according to the accepted criteria in many fields. We conclude that either such use should be recognized as legitimate, or current criteria for authorship require fundamental revision. AI use declaration: GPT-5 was used to help format Box 1. AI was not used for any other part of the preparation or writing of this manuscript.

