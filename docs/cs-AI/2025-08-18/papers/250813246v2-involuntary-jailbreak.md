---
layout: default
title: Involuntary Jailbreak
---

# Involuntary Jailbreak

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13246" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13246v2</a>
  <a href="https://arxiv.org/pdf/2508.13246.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13246v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13246v2', 'Involuntary Jailbreak')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yangyang Guo, Yangyan Li, Mohan Kankanhalli

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18 (æ›´æ–°: 2025-11-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ–°å‹è„†å¼±æ€§ï¼šéè‡ªæ„¿è¶Šç‹±**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§è¯„ä¼°` `è¶Šç‹±æ”»å‡»` `é˜²æŠ¤æœºåˆ¶` `äººå·¥æ™ºèƒ½å®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¶Šç‹±æ”»å‡»ä¸»è¦é›†ä¸­åœ¨LLMçš„å±€éƒ¨é˜²æŠ¤ç»„ä»¶ï¼Œæœªèƒ½æœ‰æ•ˆè¯„ä¼°æ•´ä½“é˜²æŠ¤ç»“æ„çš„è„†å¼±æ€§ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç®€å•çš„é€šç”¨æç¤ºç­–ç•¥ï¼Œèƒ½å¤Ÿå¼•å¯¼LLMsç”Ÿæˆé€šå¸¸è¢«æ‹’ç»çš„é—®é¢˜åŠå…¶è¯¦ç»†å›ç­”ï¼Œä»è€Œå®ç°è¶Šç‹±ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆè¶Šç‹±å¤§å¤šæ•°ä¸»æµLLMsï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®‰å…¨æ€§è¯„ä¼°ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­çš„ä¸€ç§æ–°å‹è„†å¼±æ€§ï¼Œç§°ä¸ºâ€œéè‡ªæ„¿è¶Šç‹±â€ã€‚ä¸ç°æœ‰çš„è¶Šç‹±æ”»å‡»ä¸åŒï¼Œè¯¥è„†å¼±æ€§å¹¶ä¸é’ˆå¯¹ç‰¹å®šçš„æ”»å‡»ç›®æ ‡ï¼Œä¾‹å¦‚ç”Ÿæˆåˆ¶é€ ç‚¸å¼¹çš„æŒ‡ä»¤ã€‚ä»¥å¾€çš„æ”»å‡»æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨LLMé˜²æŠ¤æœºåˆ¶çš„å±€éƒ¨ç»„ä»¶ä¸Šï¼Œè€Œéè‡ªæ„¿è¶Šç‹±å¯èƒ½ä¼šå±åŠæ•´ä¸ªé˜²æŠ¤ç»“æ„ã€‚æˆ‘ä»¬ä»…ä½¿ç”¨ä¸€ä¸ªé€šç”¨æç¤ºå³å¯å®ç°è¿™ä¸€ç›®æ ‡ï¼ŒæŒ‡ç¤ºLLMsç”Ÿæˆé€šå¸¸ä¼šè¢«æ‹’ç»çš„é—®é¢˜åŠå…¶æ·±å…¥å›ç­”ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œè¿™ä¸€ç®€å•çš„æç¤ºç­–ç•¥åœ¨å¤§å¤šæ•°é¢†å…ˆçš„LLMsä¸­éƒ½èƒ½æœ‰æ•ˆè¶Šç‹±ï¼ŒåŒ…æ‹¬Claude Opus 4.1ã€Grok 4ã€Gemini 2.5 Proå’ŒGPT 4.1ã€‚æˆ‘ä»¬å¸Œæœ›è¿™ä¸€é—®é¢˜èƒ½ä¿ƒä½¿ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…é‡æ–°è¯„ä¼°LLMé˜²æŠ¤æœºåˆ¶çš„ç¨³å¥æ€§ï¼Œå¹¶ä¸ºæœªæ¥çš„å®‰å…¨å¯¹é½åšå‡ºè´¡çŒ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­å­˜åœ¨çš„è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯ç°æœ‰è¶Šç‹±æ”»å‡»æ–¹æ³•æœªèƒ½å…¨é¢è¯„ä¼°é˜²æŠ¤æœºåˆ¶çš„æ•´ä½“ç¨³å¥æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§é€šç”¨æç¤ºç­–ç•¥ï¼Œåˆ©ç”¨è¯¥ç­–ç•¥å¼•å¯¼LLMsç”Ÿæˆé€šå¸¸ä¼šè¢«æ‹’ç»çš„é—®é¢˜åŠå…¶æ·±å…¥å›ç­”ï¼Œä»è€Œå®ç°å¯¹é˜²æŠ¤æœºåˆ¶çš„çªç ´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬è¾“å…¥ä¸€ä¸ªé€šç”¨æç¤ºï¼ŒLLMsæ ¹æ®è¯¥æç¤ºç”Ÿæˆé—®é¢˜å’Œå›ç­”ï¼Œè¿›è€Œè¯„ä¼°é˜²æŠ¤æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æç¤ºç”Ÿæˆã€é—®é¢˜è¯†åˆ«å’Œå›ç­”ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡å•ä¸€æç¤ºå®ç°å¯¹æ•´ä¸ªé˜²æŠ¤ç»“æ„çš„è¶Šç‹±ï¼Œè€Œéä»…é’ˆå¯¹å±€éƒ¨ç»„ä»¶ï¼Œè¿™ä¸€æ–¹æ³•æ˜¾ç¤ºäº†ç°æœ‰é˜²æŠ¤æœºåˆ¶çš„è„†å¼±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨äº†é€šç”¨æç¤ºçš„è®¾è®¡ï¼Œç¡®ä¿èƒ½å¤Ÿå¼•å¯¼LLMsç”Ÿæˆæ‹’ç»çš„é—®é¢˜ï¼Œä¸”åœ¨æŸå¤±å‡½æ•°ä¸Šæœªåšç‰¹åˆ«è°ƒæ•´ï¼Œä¸»è¦ä¾èµ–äºæ¨¡å‹æœ¬èº«çš„ç”Ÿæˆèƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥é€šç”¨æç¤ºç­–ç•¥èƒ½å¤Ÿåœ¨å¤§å¤šæ•°ä¸»æµLLMsä¸­æˆåŠŸå®ç°è¶Šç‹±ï¼ŒåŒ…æ‹¬Claude Opus 4.1ã€Grok 4ã€Gemini 2.5 Proå’ŒGPT 4.1ï¼Œè¡¨æ˜å…¶åœ¨å®‰å…¨æ€§è¯„ä¼°ä¸­çš„æœ‰æ•ˆæ€§å’Œé‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ€§è¯„ä¼°ã€æ¨¡å‹è®­ç»ƒå’Œé˜²æŠ¤æœºåˆ¶è®¾è®¡ç­‰ã€‚é€šè¿‡æ­ç¤ºLLMsçš„è„†å¼±æ€§ï¼Œç ”ç©¶è€…å¯ä»¥æ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œä»è€Œåœ¨æœªæ¥çš„åº”ç”¨ä¸­æå‡äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this study, we disclose a worrying new vulnerability in Large Language Models (LLMs), which we term \textbf{involuntary jailbreak}. Unlike existing jailbreak attacks, this weakness is distinct in that it does not involve a specific attack objective, such as generating instructions for \textit{building a bomb}. Prior attack methods predominantly target localized components of the LLM guardrail. In contrast, involuntary jailbreaks may potentially compromise the entire guardrail structure, which our method reveals to be surprisingly fragile. We merely employ a single universal prompt to achieve this goal. In particular, we instruct LLMs to generate several questions that would typically be rejected, along with their corresponding in-depth responses (rather than a refusal). Remarkably, this simple prompt strategy consistently jailbreaks the majority of leading LLMs, including Claude Opus 4.1, Grok 4, Gemini 2.5 Pro, and GPT 4.1. We hope this problem can motivate researchers and practitioners to re-evaluate the robustness of LLM guardrails and contribute to stronger safety alignment in future.

