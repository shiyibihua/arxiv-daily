---
layout: default
title: EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing
---

# EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13003" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13003v2</a>
  <a href="https://arxiv.org/pdf/2508.13003.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13003v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13003v2', 'EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengbo Wang, Mingwei Liu, Zike Li, Anji Li, Yanlin Wang, Xin Peng, Zibin Zheng

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18 (æ›´æ–°: 2025-10-05)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEvolMathEvalä»¥è§£å†³æ•°å­¦æ¨ç†åŸºå‡†è¯„ä¼°çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°å­¦æ¨ç†` `åŸºå‡†è¯„ä¼°` `è¿›åŒ–æµ‹è¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤æ‚æ€§æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ•°å­¦æ¨ç†åŸºå‡†éšç€æ—¶é—´æ¨ç§»å˜å¾—è¶Šæ¥è¶Šç®€å•ï¼Œæ— æ³•å‡†ç¡®è¯„ä¼°LLMsçš„çœŸå®èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºEvolMathEvalï¼Œé€šè¿‡è¿›åŒ–æµ‹è¯•è‡ªåŠ¨ç”Ÿæˆå’Œæ¼”åŒ–æ•°å­¦åŸºå‡†ï¼Œæå‡é—®é¢˜éš¾åº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEvolMathEvalèƒ½æ˜¾è‘—æé«˜å…¬å…±æ•°æ®é›†çš„å¤æ‚æ€§ï¼Œé™ä½æ¨¡å‹å‡†ç¡®ç‡48%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œç°æœ‰çš„æ•°å­¦æ¨ç†åŸºå‡†é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ã€‚è¿™äº›åŸºå‡†éšç€æ—¶é—´æ¨ç§»å˜å¾—è¶Šæ¥è¶Šç®€å•ï¼Œé™åˆ¶äº†å¯¹æœ€å…ˆè¿›æ¨¡å‹çœŸå®èƒ½åŠ›çš„å‡†ç¡®è¯„ä¼°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†EvolMathEvalï¼Œä¸€ä¸ªåŸºäºè¿›åŒ–æµ‹è¯•çš„è‡ªåŠ¨åŒ–æ•°å­¦åŸºå‡†ç”Ÿæˆä¸æ¼”åŒ–æ¡†æ¶ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEvolMathEvalä¸ä»…èƒ½å¤Ÿé€šè¿‡æŒç»­è‡ªæˆ‘è¿­ä»£ç”Ÿæˆå¤§é‡é«˜éš¾åº¦é—®é¢˜ï¼Œè¿˜èƒ½æ˜¾è‘—æå‡å…¬å…±æ•°æ®é›†ï¼ˆå¦‚GSM8Kï¼‰çš„å¤æ‚æ€§ï¼Œå¹³å‡é™ä½æ¨¡å‹å‡†ç¡®ç‡48%ã€‚æ·±å…¥ç ”ç©¶å‘ç°ï¼ŒLLMsåœ¨è§£å†³è¿™äº›æ¼”åŒ–é—®é¢˜æ—¶ï¼Œå¾€å¾€ä¾èµ–ç®€å•æ¨¡ç³Šçš„æ¡ä»¶è€Œç»•è¿‡å¤æ‚çš„å¤šæ­¥éª¤é€»è¾‘æ¨ç†ï¼Œå¯¼è‡´é”™è¯¯è§£ç­”ã€‚æˆ‘ä»¬å°†è¿™ä¸€ç°è±¡å®šä¹‰ä¸ºâ€œä¼ªé¡¿æ‚Ÿæ—¶åˆ»â€ï¼Œå‘ç°å…¶å ç›®æ ‡é—®é¢˜é”™è¯¯çš„77%è‡³100%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ•°å­¦æ¨ç†åŸºå‡†åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¿«é€Ÿå‘å±•çš„èƒŒæ™¯ä¸‹å˜å¾—è¿‡äºç®€å•çš„é—®é¢˜ã€‚è¿™ç§ç®€å•åŒ–å¯¼è‡´æ— æ³•å‡†ç¡®è¯„ä¼°æ¨¡å‹çš„çœŸå®æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEvolMathEvalçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è¿›åŒ–æµ‹è¯•è‡ªåŠ¨ç”Ÿæˆå’Œæ¼”åŒ–æ•°å­¦é—®é¢˜ï¼Œä»¥æŒç»­æé«˜é—®é¢˜çš„éš¾åº¦ï¼Œä»è€ŒæŒ‘æˆ˜LLMsçš„æ¨ç†èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡èƒ½å¤Ÿç¡®ä¿åŸºå‡†çš„åŠ¨æ€æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEvolMathEvalçš„æ•´ä½“æ¶æ„åŒ…æ‹¬é—®é¢˜ç”Ÿæˆæ¨¡å—ã€é—®é¢˜æ¼”åŒ–æ¨¡å—å’Œè¯„ä¼°æ¨¡å—ã€‚é—®é¢˜ç”Ÿæˆæ¨¡å—è´Ÿè´£åˆæ­¥ç”Ÿæˆæ•°å­¦é—®é¢˜ï¼Œé—®é¢˜æ¼”åŒ–æ¨¡å—é€šè¿‡è‡ªæˆ‘è¿­ä»£æå‡é—®é¢˜çš„å¤æ‚æ€§ï¼Œè¯„ä¼°æ¨¡å—åˆ™ç”¨äºéªŒè¯æ¨¡å‹åœ¨æ–°é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†è¿›åŒ–æµ‹è¯•æœºåˆ¶ï¼Œä½¿å¾—åŸºå‡†é—®é¢˜èƒ½å¤Ÿéšç€æ—¶é—´ä¸æ–­æ¼”åŒ–å’Œæå‡éš¾åº¦ã€‚è¿™ä¸ä¼ ç»Ÿé™æ€åŸºå‡†æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒEvolMathEvalé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®ä»¥æ§åˆ¶é—®é¢˜çš„å¤æ‚æ€§ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥ä¾¿æ›´å¥½åœ°è¯„ä¼°æ¨¡å‹åœ¨æ¼”åŒ–é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEvolMathEvalèƒ½å¤Ÿç”Ÿæˆå¤§é‡é«˜éš¾åº¦é—®é¢˜ï¼Œå¹¶æ˜¾è‘—æå‡å…¬å…±æ•°æ®é›†çš„å¤æ‚æ€§ï¼Œå¹³å‡é™ä½æ¨¡å‹å‡†ç¡®ç‡48%ã€‚æ­¤å¤–ï¼Œå‘ç°LLMsåœ¨è§£å†³æ¼”åŒ–é—®é¢˜æ—¶ï¼Œé”™è¯¯è§£ç­”çš„ä¸»è¦åŸå› æ˜¯ä¾èµ–ç®€å•æ¨¡ç³Šæ¡ä»¶ï¼Œå¯¼è‡´å¤æ‚æ¨ç†çš„ç»•è¿‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²è¯„ä¼°ã€æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æµ‹è¯•å·¥å…·ã€‚é€šè¿‡æä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„æ•°å­¦é—®é¢˜ï¼ŒEvolMathEvalèƒ½å¤Ÿå¸®åŠ©æ•™è‚²å·¥ä½œè€…æ›´å¥½åœ°è¯„ä¼°å­¦ç”Ÿçš„æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œå¹¶æ¨åŠ¨LLMsåœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶è¿˜å¯èƒ½æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸçš„åŸºå‡†ç”Ÿæˆä¸è¯„ä¼°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid advancement of Large Language Models (LLMs) poses a significant challenge to existing mathematical reasoning benchmarks. However, these benchmarks tend to become easier over time as LLMs can learn from the published benchmarks. This limitation hinder the precise evaluation of the true capabilities of SOTA models. To address this challenge, this paper introduces EvolMathEval, an automated mathematical benchmark generation and evolution framework based on evolutionary testing. Experimental results demonstrate that EvolMathEval can not only generate a large volume of high-difficulty problems through continuous self-iteration, but it can also significantly enhance the complexity of public datasets like GSM8K through evolution, reducing model accuracy by an average of 48\%. Deeper investigation reveals that when solving these evolved problems, LLMs tend to bypass complex multi-step logical reasoning by relying on simplistic and fuzzy conditions, consequently leading to incorrect solutions. We define this phenomenon as the ``Pseudo Aha Moment", which we find accounts for 77\% to 100\% of errors on targeted problems. Code and resources are available at: https://anonymous.4open.science/r/EvolMathEval

