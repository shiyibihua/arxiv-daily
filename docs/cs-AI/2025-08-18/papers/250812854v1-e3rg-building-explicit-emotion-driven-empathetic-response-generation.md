---
layout: default
title: E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model
---

# E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12854" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12854v1</a>
  <a href="https://arxiv.org/pdf/2508.12854.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12854v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12854v1', 'E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ronghao Lin, Shuai Shen, Weipeng Hu, Qiaolin He, Aolin Xiong, Li Huang, Haifeng Hu, Yap-peng Tan

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV, cs.HC, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-08-18

**å¤‡æ³¨**: Accepted at ACM MM 2025 Grand Challenge

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/RH-Lin/E3RG)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºE3RGä»¥è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿé©±åŠ¨çš„åŒç†å¿ƒå“åº”ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€åŒç†å¿ƒç”Ÿæˆ` `æƒ…æ„Ÿæ™ºèƒ½` `å¤§å‹è¯­è¨€æ¨¡å‹` `å“åº”ç”Ÿæˆ` `è™šæ‹ŸåŠ©æ‰‹` `ç¤¾äº¤æœºå™¨äºº` `æƒ…æ„Ÿç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šæ¨¡æ€æƒ…æ„Ÿå†…å®¹å’Œä¿æŒèº«ä»½ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå½±å“äº†åŒç†å¿ƒå“åº”çš„ç”Ÿæˆæ•ˆæœã€‚
2. E3RGé€šè¿‡å°†MERGä»»åŠ¡åˆ†è§£ä¸ºå¤šæ¨¡æ€åŒç†å¿ƒç†è§£ã€åŒç†å¿ƒè®°å¿†æ£€ç´¢å’Œå¤šæ¨¡æ€å“åº”ç”Ÿæˆä¸‰ä¸ªéƒ¨åˆ†ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒE3RGåœ¨é›¶-shotå’Œå°‘-shotè®¾ç½®ä¸‹å‡è¡¨ç°ä¼˜å¼‚ï¼Œåœ¨ç›¸å…³æŒ‘æˆ˜ä¸­å–å¾—äº†Top-1çš„æˆç»©ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€åŒç†å¿ƒå“åº”ç”Ÿæˆï¼ˆMERGï¼‰å¯¹äºæ„å»ºæƒ…æ„Ÿæ™ºèƒ½çš„äººæœºäº¤äº’è‡³å…³é‡è¦ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ–‡æœ¬åŸºç¡€çš„å“åº”ç”Ÿæˆä¸Šæœ‰æ‰€æ”¹å–„ï¼Œä½†åœ¨å¤„ç†å¤šæ¨¡æ€æƒ…æ„Ÿå†…å®¹å’Œä¿æŒèº«ä»½ä¸€è‡´æ€§æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†E3RGï¼Œä¸€ä¸ªåŸºäºå¤šæ¨¡æ€LLMsçš„æ˜¾å¼æƒ…æ„Ÿé©±åŠ¨åŒç†å¿ƒå“åº”ç”Ÿæˆç³»ç»Ÿï¼Œå°†MERGä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šå¤šæ¨¡æ€åŒç†å¿ƒç†è§£ã€åŒç†å¿ƒè®°å¿†æ£€ç´¢å’Œå¤šæ¨¡æ€å“åº”ç”Ÿæˆã€‚é€šè¿‡æ•´åˆå…ˆè¿›çš„è¡¨è¾¾æ€§è¯­éŸ³å’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼ŒE3RGèƒ½å¤Ÿåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æä¾›è‡ªç„¶ã€æƒ…æ„Ÿä¸°å¯Œä¸”èº«ä»½ä¸€è‡´çš„å“åº”ã€‚å®éªŒéªŒè¯äº†æˆ‘ä»¬ç³»ç»Ÿåœ¨é›¶-shotå’Œå°‘-shotè®¾ç½®ä¸‹çš„ä¼˜è¶Šæ€§ï¼Œå¹¶åœ¨ACM MM 25çš„åŸºäºè™šæ‹Ÿå½¢è±¡çš„å¤šæ¨¡æ€åŒç†å¿ƒæŒ‘æˆ˜ä¸­è·å¾—äº†ç¬¬ä¸€åã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/RH-Lin/E3RGè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€åŒç†å¿ƒå“åº”ç”Ÿæˆï¼ˆMERGï¼‰ä¸­çš„æƒ…æ„Ÿå†…å®¹å¤„ç†å’Œèº«ä»½ä¸€è‡´æ€§ç»´æŠ¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸¤ä¸ªæ–¹é¢çš„è¡¨ç°ä¸å°½å¦‚äººæ„ï¼Œé™åˆ¶äº†äººæœºäº¤äº’çš„æƒ…æ„Ÿæ™ºèƒ½åŒ–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šE3RGçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†MERGä»»åŠ¡åˆ†è§£ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼šé¦–å…ˆæ˜¯å¤šæ¨¡æ€åŒç†å¿ƒç†è§£ï¼Œå…¶æ¬¡æ˜¯åŒç†å¿ƒè®°å¿†æ£€ç´¢ï¼Œæœ€åæ˜¯å¤šæ¨¡æ€å“åº”ç”Ÿæˆã€‚é€šè¿‡è¿™ç§åˆ†è§£ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†å¤šæ¨¡æ€è¾“å…¥å¹¶ç”Ÿæˆæƒ…æ„Ÿä¸°å¯Œçš„å“åº”ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šE3RGçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¤šæ¨¡æ€åŒç†å¿ƒç†è§£æ¨¡å—è´Ÿè´£è§£æè¾“å…¥çš„æƒ…æ„Ÿä¿¡æ¯ï¼›åŒç†å¿ƒè®°å¿†æ£€ç´¢æ¨¡å—ç”¨äºæå–ç›¸å…³çš„æƒ…æ„Ÿè®°å¿†ï¼›å¤šæ¨¡æ€å“åº”ç”Ÿæˆæ¨¡å—åˆ™ç»“åˆå‰ä¸¤ä¸ªæ¨¡å—çš„è¾“å‡ºç”Ÿæˆæœ€ç»ˆçš„å“åº”ã€‚

**å…³é”®åˆ›æ–°**ï¼šE3RGçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ˜¾å¼æƒ…æ„Ÿé©±åŠ¨çš„è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å…ˆè¿›çš„è¡¨è¾¾æ€§è¯­éŸ³å’Œè§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œæä¾›è‡ªç„¶ä¸”èº«ä»½ä¸€è‡´çš„å“åº”ã€‚è¿™ä¸€è®¾è®¡ä¸ç°æœ‰æ–¹æ³•çš„æ ¹æœ¬åŒºåˆ«åœ¨äºå…¶å¯¹å¤šæ¨¡æ€è¾“å…¥çš„æ·±åº¦ç†è§£å’Œå¤„ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒE3RGé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¤šæ¨¡æ€å“åº”çš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒæƒ…æ„ŸçŠ¶æ€çš„ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„å“åº”åœ¨æƒ…æ„Ÿè¡¨è¾¾ä¸Šæ›´åŠ ä¸°å¯Œå’Œä¸€è‡´ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„çš„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒE3RGåœ¨é›¶-shotå’Œå°‘-shotè®¾ç½®ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ACM MM 25çš„åŸºäºè™šæ‹Ÿå½¢è±¡çš„å¤šæ¨¡æ€åŒç†å¿ƒæŒ‘æˆ˜ä¸­è·å¾—äº†Top-1çš„æˆç»©ï¼Œè¯æ˜äº†å…¶åœ¨å¤šæ¨¡æ€æƒ…æ„Ÿå“åº”ç”Ÿæˆä¸­çš„ä¼˜è¶Šæ€§ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†åˆ—å‡ºï¼Œå±•ç¤ºäº†ç›¸è¾ƒäºç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

E3RGçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨æƒ…æ„Ÿæ™ºèƒ½çš„è™šæ‹ŸåŠ©æ‰‹ã€ç¤¾äº¤æœºå™¨äººå’Œåœ¨çº¿å®¢æœç­‰é¢†åŸŸã€‚é€šè¿‡å®ç°æ›´è‡ªç„¶çš„æƒ…æ„Ÿäº¤äº’ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›äººæœºå…³ç³»çš„å’Œè°å‘å±•ã€‚æ­¤å¤–ï¼Œæœªæ¥å¯èƒ½åœ¨æ•™è‚²ã€å¿ƒç†å¥åº·ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°è¡¨è¾¾å’Œç†è§£æƒ…æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Empathetic Response Generation (MERG) is crucial for building emotionally intelligent human-computer interactions. Although large language models (LLMs) have improved text-based ERG, challenges remain in handling multimodal emotional content and maintaining identity consistency. Thus, we propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System based on multimodal LLMs which decomposes MERG task into three parts: multimodal empathy understanding, empathy memory retrieval, and multimodal response generation. By integrating advanced expressive speech and video generative models, E3RG delivers natural, emotionally rich, and identity-consistent responses without extra training. Experiments validate the superiority of our system on both zero-shot and few-shot settings, securing Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25. Our code is available at https://github.com/RH-Lin/E3RG.

