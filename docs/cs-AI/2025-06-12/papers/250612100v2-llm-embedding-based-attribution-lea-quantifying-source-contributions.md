---
layout: default
title: LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model's Response for Vulnerability Analysis
---

# LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model's Response for Vulnerability Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.12100" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.12100v2</a>
  <a href="https://arxiv.org/pdf/2506.12100.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.12100v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.12100v2', 'LLM Embedding-based Attribution (LEA): Quantifying Source Contributions to Generative Model\'s Response for Vulnerability Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Reza Fayyazi, Michael Zuzak, Shanchieh Jay Yang

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12 (æ›´æ–°: 2025-09-03)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLEAä»¥é‡åŒ–ç”Ÿæˆæ¨¡å‹å“åº”ä¸­çš„æºè´¡çŒ®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç½‘ç»œå®‰å…¨` `æ¼æ´åˆ†æ` `ç”Ÿæˆæ¨¡å‹` `ä¿¡æ¯æ£€ç´¢` `å¯ä¿¡AI` `å®‰å…¨å®¡è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç½‘ç»œå®‰å…¨ä¸­çš„æ–°å…´æ¼æ´æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯LLMsçš„è®­ç»ƒæˆªæ­¢æ—¥æœŸé™åˆ¶äº†å…¶å¯¹æœ€æ–°ä¿¡æ¯çš„å“åº”èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºLLMåµŒå…¥åŸºç¡€å½’å› ï¼ˆLEAï¼‰ï¼Œé€šè¿‡é‡åŒ–å†…éƒ¨çŸ¥è¯†ä¸æ£€ç´¢å†…å®¹åœ¨ç”Ÿæˆå“åº”ä¸­çš„è´¡çŒ®ï¼Œå¸®åŠ©åˆ†æç”Ÿæˆå†…å®¹çš„å¯é æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLEAåœ¨ä¸åŒæ£€ç´¢åœºæ™¯ä¸‹çš„å‡†ç¡®ç‡è¶…è¿‡95%ï¼Œæœ‰æ•ˆæå‡äº†å¯¹ç”Ÿæˆå†…å®¹çš„ç†è§£å’Œåˆ†æèƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç½‘ç»œå®‰å…¨å¨èƒåˆ†æä¸­çš„åº”ç”¨æ—¥ç›Šå¢åŠ ï¼Œä½†åœ¨å®‰å…¨æ•æ„Ÿç¯å¢ƒä¸­çš„éƒ¨ç½²å¼•å‘äº†ä¿¡ä»»å’Œå®‰å…¨é—®é¢˜ã€‚éšç€2025å¹´æŠ«éœ²çš„æ¼æ´è¶…è¿‡21,000ä¸ªï¼Œæ‰‹åŠ¨åˆ†æå·²ä¸å¯è¡Œï¼Œå› æ­¤å¯æ‰©å±•ä¸”å¯éªŒè¯çš„AIæ”¯æŒå˜å¾—è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºLLMåµŒå…¥åŸºç¡€å½’å› ï¼ˆLEAï¼‰ï¼Œç”¨äºåˆ†æç”Ÿæˆå“åº”ä¸­çš„å†…éƒ¨çŸ¥è¯†ä¸æ£€ç´¢å†…å®¹çš„ç›¸å¯¹è´¡çŒ®ã€‚é€šè¿‡å¯¹2016è‡³2025å¹´é—´500ä¸ªå…³é”®æ¼æ´çš„è¯„ä¼°ï¼ŒLEAåœ¨æœ‰æ•ˆã€é€šç”¨å’Œé”™è¯¯çš„æ£€ç´¢è®¾ç½®ä¸‹ï¼Œå±•ç¤ºäº†è¶…è¿‡95%çš„å‡†ç¡®ç‡ï¼Œèƒ½å¤Ÿæ¸…æ™°åŒºåˆ†ä¸åŒçš„æ£€ç´¢åœºæ™¯ã€‚æœ€åï¼Œæœ¬æ–‡æé†’ç½‘ç»œå®‰å…¨ç¤¾åŒºå¯¹LLMså’ŒRAGçš„ç›²ç›®ä¿¡ä»»ï¼Œå¼ºè°ƒLEAåœ¨æå‡AIé€æ˜æ€§å’Œå¯ä¿¡æ€§æ–¹é¢çš„ä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç½‘ç»œå®‰å…¨æ¼æ´åˆ†æä¸­å¯¹æ£€ç´¢ä¿¡æ¯ä¸å†…éƒ¨çŸ¥è¯†è´¡çŒ®çš„ä¸ç¡®å®šæ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†è¿™ä¸¤è€…çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLEAé€šè¿‡é‡åŒ–ç”Ÿæˆå“åº”ä¸­å†…éƒ¨çŸ¥è¯†ä¸æ£€ç´¢å†…å®¹çš„ç›¸å¯¹è´¡çŒ®ï¼Œæä¾›äº†ä¸€ç§æ–°çš„åˆ†æå·¥å…·ï¼Œä»¥å¸®åŠ©å®‰å…¨åˆ†æå¸ˆç†è§£ç”Ÿæˆå†…å®¹çš„æ¥æºå’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLEAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è®­ç»ƒã€å“åº”ç”Ÿæˆå’Œè´¡çŒ®é‡åŒ–å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†ç›¸å…³æ¼æ´æ•°æ®ï¼Œç„¶åè®­ç»ƒLLMsï¼Œæ¥ç€ç”Ÿæˆå“åº”ï¼Œæœ€åé‡åŒ–å„éƒ¨åˆ†çš„è´¡çŒ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šLEAçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿæ¸…æ™°åŒºåˆ†éæ£€ç´¢ã€é€šç”¨æ£€ç´¢å’Œæœ‰æ•ˆæ£€ç´¢åœºæ™¯çš„å“åº”è´¡çŒ®ï¼Œæä¾›äº†ä¸€ç§æ–°çš„è¯„ä¼°æ ‡å‡†ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æé«˜äº†åˆ†æçš„é€æ˜åº¦å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒLEAä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶é€šè¿‡å¯¹æ¯”å®éªŒéªŒè¯äº†ä¸åŒæ£€ç´¢è®¾ç½®ä¸‹çš„å“åº”è´¨é‡ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLEAåœ¨å¤„ç†500ä¸ªå…³é”®æ¼æ´æ—¶ï¼Œèƒ½å¤Ÿä»¥è¶…è¿‡95%çš„å‡†ç¡®ç‡åŒºåˆ†ä¸åŒçš„æ£€ç´¢åœºæ™¯ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚è¿™ä¸€æˆæœä¸ä»…éªŒè¯äº†LEAçš„æœ‰æ•ˆæ€§ï¼Œè¿˜å¼ºè°ƒäº†å¯¹æ£€ç´¢ä¿¡æ¯çš„å‡†ç¡®ç†è§£åœ¨ç½‘ç»œå®‰å…¨åˆ†æä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LEAçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºç½‘ç»œå®‰å…¨é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨æ¼æ´åˆ†æå’Œå®‰å…¨å®¡è®¡ä¸­ã€‚é€šè¿‡æä¾›å¯¹ç”Ÿæˆå†…å®¹æ¥æºçš„é€æ˜åˆ†æï¼ŒLEAèƒ½å¤Ÿå¸®åŠ©å®‰å…¨åˆ†æå¸ˆåšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ï¼Œé™ä½å®‰å…¨é£é™©ï¼Œå¹¶æé«˜AIåœ¨å®‰å…¨æ•æ„Ÿç¯å¢ƒä¸­çš„å¯ä¿¡åº¦ã€‚æœªæ¥ï¼ŒLEAå¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šåŸºäºAIçš„å®‰å…¨å·¥å…·çš„å¼€å‘ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly used for cybersecurity threat analysis, but their deployment in security-sensitive environments raises trust and safety concerns. With over 21,000 vulnerabilities disclosed in 2025, manual analysis is infeasible, making scalable and verifiable AI support critical. When querying LLMs, dealing with emerging vulnerabilities is challenging as they have a training cut-off date. While Retrieval-Augmented Generation (RAG) can inject up-to-date context to alleviate the cut-off date limitation, it remains unclear how much LLMs rely on retrieved evidence versus the model's internal knowledge, and whether the retrieved information is meaningful or even correct. This uncertainty could mislead security analysts, mis-prioritize patches, and increase security risks. Therefore, this work proposes LLM Embedding-based Attribution (LEA) to analyze the generated responses for vulnerability exploitation analysis. More specifically, LEA quantifies the relative contribution of internal knowledge vs. retrieved content in the generated responses. We evaluate LEA on 500 critical vulnerabilities disclosed between 2016 and 2025, across three RAG settings -- valid, generic, and incorrect -- using three state-of-the-art LLMs. Our results demonstrate LEA's ability to detect clear distinctions between non-retrieval, generic-retrieval, and valid-retrieval scenarios with over 95% accuracy on larger models. Finally, we demonstrate the limitations posed by incorrect retrieval of vulnerability information and raise a cautionary note to the cybersecurity community regarding the blind reliance on LLMs and RAG for vulnerability analysis. LEA offers security analysts with a metric to audit RAG-enhanced workflows, improving the transparent and trustworthy deployment of AI in cybersecurity threat analysis.

