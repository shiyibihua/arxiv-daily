---
layout: default
title: WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models
---

# WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10264" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10264v1</a>
  <a href="https://arxiv.org/pdf/2506.10264.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10264v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10264v1', 'WGSR-Bench: Wargame-based Game-theoretic Strategic Reasoning Benchmark for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qiyue Yin, Pei Xu, Qiaozhe Li, Shengda Liu, Shengqi Shen, Tong Wang, Yihong Han, Xiaonan Zhao, Likun Yang, Shiyue Cao, Shiyu Qiu, Yuxuan Liu, Shizhao Yu, Lei Cui, Chengxin Yan, Jie Sun, Xiangquan Tang, Kaiqi Huang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: 15 pages, 17 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWGSR-Benchä»¥è§£å†³æˆ˜ç•¥æ¨ç†è¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æˆ˜ç•¥æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `æˆ˜äº‰æ¸¸æˆ` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `å†³ç­–è¯„ä¼°` `æ„å›¾æ¨æ–­` `åäº‹å®æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æˆ˜ç•¥æ¨ç†æ–¹é¢ç¼ºä¹ç³»ç»Ÿè¯„ä¼°ï¼Œå°¤å…¶æ˜¯åœ¨åŠ¨æ€ç¯å¢ƒä¸­å¤šæ™ºèƒ½ä½“è¡Œä¸ºçš„åˆ†æèƒ½åŠ›ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºWGSR-Benchï¼Œåˆ©ç”¨æˆ˜äº‰æ¸¸æˆä½œä¸ºè¯„ä¼°ç¯å¢ƒï¼Œè®¾è®¡äº†å›´ç»•ç¯å¢ƒæ„è¯†ã€å¯¹æ‰‹å»ºæ¨¡å’Œç­–ç•¥ç”Ÿæˆçš„æµ‹è¯•æ ·æœ¬ã€‚
3. é€šè¿‡æ„å»ºLLMé©±åŠ¨çš„æˆ˜äº‰æ¸¸æˆä»£ç†ï¼Œç³»ç»Ÿè¯„ä¼°äº†å½“å‰æœ€å…ˆè¿›çš„LLMsåœ¨æˆ˜ç•¥æ¨ç†ä¸­çš„ä¼˜ç¼ºç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çªç ´ï¼Œå°¤å…¶åœ¨æ•°å­¦ã€ç¬¦å·å’Œå¸¸è¯†æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œä½œä¸ºé«˜çº§äººç±»è®¤çŸ¥çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œæˆ˜ç•¥æ¨ç†çš„ç³»ç»Ÿè¯„ä¼°å’Œå»ºæ¨¡ä»ç„¶ç¼ºä¹ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºWGSR-Benchï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºæˆ˜äº‰æ¸¸æˆçš„æˆ˜ç•¥æ¨ç†åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°LLMsåœ¨å¤šæ™ºèƒ½ä½“å†³ç­–ã€æ„å›¾æ¨æ–­å’Œåäº‹å®æ¨ç†ä¸­çš„èƒ½åŠ›ã€‚WGSR-Benchå›´ç»•ç¯å¢ƒæƒ…å†µæ„è¯†ã€å¯¹æ‰‹é£é™©å»ºæ¨¡å’Œç­–ç•¥ç”Ÿæˆä¸‰ä¸ªæ ¸å¿ƒä»»åŠ¡è®¾è®¡æµ‹è¯•æ ·æœ¬ï¼Œæ„å»ºäº†æ ¸å¿ƒçš„S-POEæ¶æ„ï¼Œå…¨é¢è¯„ä¼°æˆ˜ç•¥æ¨ç†çš„ä¸»è¦èƒ½åŠ›ã€‚æœ€åï¼Œè®¾è®¡äº†åŸºäºLLMçš„æˆ˜äº‰æ¸¸æˆä»£ç†ï¼Œä»¥å®ç°å…¨é¢çš„æˆ˜ç•¥æ¨ç†è¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æˆ˜ç•¥æ¨ç†é¢†åŸŸçš„è¯„ä¼°ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†å¤šæ™ºèƒ½ä½“å¤æ‚è¡Œä¸ºçš„åŠ¨æ€ç¯å¢ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥æˆ˜äº‰æ¸¸æˆä½œä¸ºè¯„ä¼°ç¯å¢ƒï¼ŒWGSR-Benchç³»ç»Ÿæ€§åœ°è®¾è®¡äº†æµ‹è¯•ä»»åŠ¡ï¼Œä»¥å…¨é¢è¯„ä¼°LLMsåœ¨æˆ˜ç•¥æ¨ç†ä¸­çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWGSR-Benchçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç¯å¢ƒæƒ…å†µæ„è¯†ã€å¯¹æ‰‹é£é™©å»ºæ¨¡å’Œç­–ç•¥ç”Ÿæˆï¼Œå½¢æˆæ ¸å¿ƒçš„S-POEæ¶æ„ï¼Œæ”¯æŒå¤šç»´åº¦çš„èƒ½åŠ›è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šWGSR-Benchæ˜¯é¦–ä¸ªé’ˆå¯¹æˆ˜ç•¥æ¨ç†çš„åŸºå‡†ï¼Œç»“åˆäº†ç¯å¢ƒä¸ç¡®å®šæ€§å’Œå¯¹æŠ—åŠ¨æ€ï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨å¤æ‚å†³ç­–åœºæ™¯ä¸­çš„è¯„ä¼°èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ï¼Œç½‘ç»œç»“æ„åˆ™ä¼˜åŒ–äº†å¯¹å¤æ‚ç­–ç•¥çš„å­¦ä¹ èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºWGSR-Benchçš„è¯„ä¼°æ–¹æ³•æ˜¾è‘—æå‡äº†LLMsåœ¨æˆ˜ç•¥æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œç›¸è¾ƒäºä¼ ç»ŸåŸºçº¿ï¼Œæ¨¡å‹åœ¨ç¯å¢ƒæƒ…å†µæ„è¯†å’Œå¯¹æ‰‹é£é™©å»ºæ¨¡ä»»åŠ¡ä¸Šæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚å†³ç­–åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WGSR-Benchçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ¸¸æˆå¼€å‘ã€æ™ºèƒ½å†³ç­–ç³»ç»Ÿå’Œæœºå™¨äººé¢†åŸŸï¼Œå¸®åŠ©æå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æˆ˜ç•¥æ™ºèƒ½æ°´å¹³ã€‚æœªæ¥ï¼Œéšç€LLMsçš„ä¸æ–­å‘å±•ï¼Œè¯¥åŸºå‡†å°†æ¨åŠ¨æˆ˜ç•¥æ¨ç†ç›¸å…³ç ”ç©¶çš„æ·±å…¥ï¼Œä¿ƒè¿›æ›´å¤æ‚æ™ºèƒ½ä½“çš„è®¾è®¡ä¸å®ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent breakthroughs in Large Language Models (LLMs) have led to a qualitative leap in artificial intelligence' s performance on reasoning tasks, particularly demonstrating remarkable capabilities in mathematical, symbolic, and commonsense reasoning. However, as a critical component of advanced human cognition, strategic reasoning, i.e., the ability to assess multi-agent behaviors in dynamic environments, formulate action plans, and adapt strategies, has yet to be systematically evaluated or modeled. To address this gap, this paper introduces WGSR-Bench, the first strategy reasoning benchmark for LLMs using wargame as its evaluation environment. Wargame, a quintessential high-complexity strategic scenario, integrates environmental uncertainty, adversarial dynamics, and non-unique strategic choices, making it an effective testbed for assessing LLMs' capabilities in multi-agent decision-making, intent inference, and counterfactual reasoning. WGSR-Bench designs test samples around three core tasks, i.e., Environmental situation awareness, Opponent risk modeling and Policy generation, which serve as the core S-POE architecture, to systematically assess main abilities of strategic reasoning. Finally, an LLM-based wargame agent is designed to integrate these parts for a comprehensive strategy reasoning assessment. With WGSR-Bench, we hope to assess the strengths and limitations of state-of-the-art LLMs in game-theoretic strategic reasoning and to advance research in large model-driven strategic intelligence.

