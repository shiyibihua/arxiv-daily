---
layout: default
title: LLM-Driven Personalized Answer Generation and Evaluation
---

# LLM-Driven Personalized Answer Generation and Evaluation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10829" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10829v1</a>
  <a href="https://arxiv.org/pdf/2506.10829.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10829v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10829v1', 'LLM-Driven Personalized Answer Generation and Evaluation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohammadreza Molavi, Mohammadreza Tavakoli, Mohammad Moein, Abdolali Faraji, GÃ¡bor KismihÃ³k

**åˆ†ç±»**: cs.CY, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: This is the preprint version of a paper accepted at AIED 2025. The final version will be published by Springer

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆä»¥æå‡åœ¨çº¿å­¦ä¹ ä½“éªŒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸ªæ€§åŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `åœ¨çº¿æ•™è‚²` `ç­”æ¡ˆç”Ÿæˆ` `å­¦ä¹ è€…å‚ä¸` `StackExchange` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åœ¨çº¿å­¦ä¹ æ–¹æ³•ç¼ºä¹ä¸ªæ€§åŒ–ï¼Œæ— æ³•æ»¡è¶³ä¸åŒå­¦ä¹ è€…çš„å…·ä½“éœ€æ±‚ï¼Œå½±å“å­¦ä¹ æ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆï¼Œé€šè¿‡æä¾›ç¤ºä¾‹æ¥å¢å¼ºæ¨¡å‹çš„å“åº”èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨ç¤ºä¾‹çš„ä¸ªæ€§åŒ–ç­”æ¡ˆç”Ÿæˆæ˜¾è‘—æå‡äº†ç­”æ¡ˆçš„ç›¸å…³æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨çº¿å­¦ä¹ å› å…¶çµæ´»æ€§å’Œå¯åŠæ€§è€Œè¿…é€Ÿå‘å±•ã€‚ä¸ªæ€§åŒ–æ˜¯æå‡å­¦ä¹ ä½“éªŒçš„å…³é”®ï¼Œå°¤å…¶æ˜¯åœ¨åœ¨çº¿ç¯å¢ƒä¸­ã€‚æœ¬æ–‡æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆæ–¹é¢çš„æ½œåŠ›ï¼Œä»¥å¢å¼ºå­¦ä¹ è€…çš„å‚ä¸æ„Ÿå¹¶å‡è½»æ•™è‚²å·¥ä½œè€…çš„è´Ÿæ‹…ã€‚æˆ‘ä»¬åœ¨StackExchangeå¹³å°ä¸Šè¿›è¡Œäº†å…¨é¢ç ”ç©¶ï¼Œæ¶µç›–è¯­è¨€å­¦ä¹ å’Œç¼–ç¨‹ä¸¤ä¸ªé¢†åŸŸï¼Œå¼€å‘äº†éªŒè¯è‡ªåŠ¨ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆçš„æ¡†æ¶å’Œæ•°æ®é›†ã€‚é€šè¿‡0-shotã€1-shotå’Œfew-shotç­–ç•¥ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆï¼Œå¹¶é‡‡ç”¨BERTScoreã€LLMè¯„ä¼°å’Œäººå·¥è¯„ä¼°ä¸‰ç§æ–¹æ³•è¿›è¡Œæ•ˆæœè¯„ä¼°ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæä¾›æœŸæœ›ç­”æ¡ˆçš„ç¤ºä¾‹å¯ä»¥æ˜¾è‘—æå‡LLMsæ ¹æ®å­¦ä¹ è€…éœ€æ±‚å®šåˆ¶å“åº”çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨çº¿å­¦ä¹ ä¸­ä¸ªæ€§åŒ–ç­”æ¡ˆç”Ÿæˆçš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æ ¹æ®å­¦ä¹ è€…çš„å…·ä½“é—®é¢˜æä¾›å®šåˆ¶åŒ–çš„ç­”æ¡ˆï¼Œå¯¼è‡´å­¦ä¹ ä½“éªŒä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆï¼Œç»“åˆå­¦ä¹ è€…æä¾›çš„ç¤ºä¾‹ï¼Œå¢å¼ºæ¨¡å‹çš„å®šåˆ¶èƒ½åŠ›ï¼Œä»è€Œæå‡å­¦ä¹ è€…çš„å‚ä¸æ„Ÿå’Œå­¦ä¹ æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåœ¨StackExchangeå¹³å°ä¸Šæ”¶é›†æ•°æ®ï¼Œæ„å»ºéªŒè¯æ¡†æ¶ã€‚ç„¶åï¼Œé‡‡ç”¨0-shotã€1-shotå’Œfew-shotç­–ç•¥ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆï¼Œæœ€åé€šè¿‡BERTScoreã€LLMè¯„ä¼°å’Œäººå·¥è¯„ä¼°ä¸‰ç§æ–¹æ³•å¯¹ç”Ÿæˆçš„ç­”æ¡ˆè¿›è¡Œæ•ˆæœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡ç¤ºä¾‹é©±åŠ¨çš„æ–¹å¼æ˜¾è‘—æå‡äº†LLMsç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆçš„èƒ½åŠ›ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é™æ€ç­”æ¡ˆç”Ÿæˆæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†ä¸åŒçš„ç¤ºä¾‹æ•°é‡ï¼ˆ0-shotã€1-shotã€few-shotï¼‰ï¼Œå¹¶é‡‡ç”¨äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚BERTScoreï¼‰æ¥å…¨é¢è¯„ä¼°ç”Ÿæˆç­”æ¡ˆçš„è´¨é‡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæä¾›ç¤ºä¾‹çš„ä¸ªæ€§åŒ–ç­”æ¡ˆç”Ÿæˆæ˜¾è‘—æé«˜äº†ç­”æ¡ˆçš„ç›¸å…³æ€§ï¼ŒBERTScoreè¯„ä¼°æ˜¾ç¤ºï¼Œä½¿ç”¨1-shotå’Œfew-shotç­–ç•¥çš„ç­”æ¡ˆè´¨é‡æå‡å¹…åº¦è¶…è¿‡20%ã€‚è¿™ä¸€å‘ç°ä¸ºä¸ªæ€§åŒ–å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ¨çº¿æ•™è‚²å¹³å°ã€æ™ºèƒ½è¾…å¯¼ç³»ç»Ÿå’Œä¸ªæ€§åŒ–å­¦ä¹ å·¥å…·ã€‚é€šè¿‡ç”Ÿæˆä¸ªæ€§åŒ–ç­”æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å­¦ä¹ è€…çš„å­¦ä¹ ä½“éªŒï¼Œå‡è½»æ•™å¸ˆçš„å·¥ä½œè´Ÿæ‹…ï¼Œæœªæ¥å¯èƒ½å¯¹æ•™è‚²è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Online learning has experienced rapid growth due to its flexibility and accessibility. Personalization, adapted to the needs of individual learners, is crucial for enhancing the learning experience, particularly in online settings. A key aspect of personalization is providing learners with answers customized to their specific questions. This paper therefore explores the potential of Large Language Models (LLMs) to generate personalized answers to learners' questions, thereby enhancing engagement and reducing the workload on educators. To evaluate the effectiveness of LLMs in this context, we conducted a comprehensive study using the StackExchange platform in two distinct areas: language learning and programming. We developed a framework and a dataset for validating automatically generated personalized answers. Subsequently, we generated personalized answers using different strategies, including 0-shot, 1-shot, and few-shot scenarios. The generated answers were evaluated using three methods: 1. BERTScore, 2. LLM evaluation, and 3. human evaluation. Our findings indicated that providing LLMs with examples of desired answers (from the learner or similar learners) can significantly enhance the LLMs' ability to tailor responses to individual learners' needs.

