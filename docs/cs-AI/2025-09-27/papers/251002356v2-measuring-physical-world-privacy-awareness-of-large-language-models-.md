---
layout: default
title: Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark
---

# Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02356" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02356v2</a>
  <a href="https://arxiv.org/pdf/2510.02356.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02356v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.02356v2', 'Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinjie Shen, Mufei Li, Pan Li

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-13)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Graph-COM/EAPrivacy)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEAPrivacyåŸºå‡†ï¼Œè¯„ä¼°å…·èº«æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§æ„è¯†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½ä½“` `éšç§æ„è¯†` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰©ç†ä¸–ç•Œ` `è¯„ä¼°åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ–¹æ³•ä¸»è¦é›†ä¸­äºè‡ªç„¶è¯­è¨€åœºæ™¯ï¼Œç¼ºä¹å¯¹å…·èº«æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­éšç§æ„è¯†çš„æœ‰æ•ˆè¯„ä¼°ã€‚
2. EAPrivacyåŸºå‡†é€šè¿‡ç¨‹åºç”Ÿæˆå¤šå±‚çº§åœºæ™¯ï¼Œè€ƒå¯Ÿæ™ºèƒ½ä½“åœ¨å¤æ‚ç‰©ç†ç¯å¢ƒä¸­å¯¹éšç§çš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œç°æœ‰LLMåœ¨ç‰©ç†ä¸–ç•Œéšç§ä¿æŠ¤æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç¯å¢ƒå˜åŒ–å’Œç¤¾ä¼šè§„èŒƒå†²çªæ—¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºEAPrivacyï¼Œä¸€ä¸ªç»¼åˆè¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨é‡åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§æ„è¯†ã€‚EAPrivacyåˆ©ç”¨ç¨‹åºç”Ÿæˆçš„åœºæ™¯ï¼Œè·¨è¶Šå››ä¸ªå±‚çº§ï¼Œæµ‹è¯•æ™ºèƒ½ä½“å¤„ç†æ•æ„Ÿå¯¹è±¡ã€é€‚åº”å˜åŒ–ç¯å¢ƒã€å¹³è¡¡ä»»åŠ¡æ‰§è¡Œä¸éšç§çº¦æŸä»¥åŠè§£å†³ä¸ç¤¾ä¼šè§„èŒƒå†²çªçš„èƒ½åŠ›ã€‚æµ‹é‡ç»“æœæ­ç¤ºäº†å½“å‰æ¨¡å‹çš„å…³é”®ç¼ºé™·ã€‚æ€§èƒ½æœ€ä½³çš„æ¨¡å‹Gemini 2.5 Proåœ¨æ¶‰åŠå˜åŒ–ç‰©ç†ç¯å¢ƒçš„åœºæ™¯ä¸­ä»…è¾¾åˆ°59%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œå½“ä»»åŠ¡ä¼´éšéšç§è¯·æ±‚æ—¶ï¼Œæ¨¡å‹åœ¨é«˜è¾¾86%çš„æƒ…å†µä¸‹ä¼˜å…ˆå®Œæˆä»»åŠ¡è€Œééµå®ˆçº¦æŸã€‚åœ¨éšç§ä¸å…³é”®ç¤¾ä¼šè§„èŒƒç›¸å†²çªçš„é«˜é£é™©æƒ…å¢ƒä¸­ï¼ŒGPT-4oå’ŒClaude-3.5-haikuç­‰é¢†å…ˆæ¨¡å‹åœ¨è¶…è¿‡15%çš„æƒ…å†µä¸‹æ— è§†ç¤¾ä¼šè§„èŒƒã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†LLMåœ¨ç‰©ç†ç¯å¢ƒä¸­çš„éšç§æ„è¯†æ–¹é¢å­˜åœ¨æ ¹æœ¬æ€§åå·®ï¼Œå¹¶ç¡®ç«‹äº†å¯¹æ›´é²æ£’ã€æ›´å…·ç‰©ç†æ„ŸçŸ¥èƒ½åŠ›çš„å¯¹é½çš„éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å…·èº«æ™ºèƒ½ä½“ä¸­çš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†ç¼ºä¹é’ˆå¯¹å…¶åœ¨ç‰©ç†ä¸–ç•Œä¸­éšç§æ„è¯†çš„æœ‰æ•ˆè¯„ä¼°æ–¹æ³•ã€‚ç°æœ‰çš„è¯„ä¼°æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œæ— æ³•å……åˆ†æµ‹è¯•æ™ºèƒ½ä½“åœ¨çœŸå®ç‰©ç†ç¯å¢ƒä¸­å¤„ç†éšç§é—®é¢˜çš„èƒ½åŠ›ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªä¸“é—¨çš„åŸºå‡†æ¥é‡åŒ–å’Œè¯„ä¼°LLMé©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEAPrivacyçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªç¨‹åºç”Ÿæˆçš„ã€å¤šå±‚çº§çš„ç‰©ç†ä¸–ç•Œåœºæ™¯ï¼Œæ¥ç³»ç»Ÿåœ°æµ‹è¯•LLMé©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ä¸åŒå¤æ‚ç¨‹åº¦ä¸‹çš„éšç§æ„è¯†ã€‚è¯¥åŸºå‡†æ¨¡æ‹Ÿäº†æ™ºèƒ½ä½“åœ¨çœŸå®ä¸–ç•Œä¸­å¯èƒ½é‡åˆ°çš„å„ç§éšç§æŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¤„ç†æ•æ„Ÿå¯¹è±¡ã€é€‚åº”å˜åŒ–çš„ç¯å¢ƒã€å¹³è¡¡ä»»åŠ¡æ‰§è¡Œä¸éšç§çº¦æŸä»¥åŠè§£å†³ä¸ç¤¾ä¼šè§„èŒƒçš„å†²çªã€‚é€šè¿‡é‡åŒ–æ™ºèƒ½ä½“åœ¨è¿™äº›åœºæ™¯ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥å…¨é¢è¯„ä¼°å…¶éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEAPrivacyçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åœºæ™¯ç”Ÿæˆå™¨ï¼šä½¿ç”¨ç¨‹åºç”Ÿæˆä¸åŒå¤æ‚ç¨‹åº¦çš„ç‰©ç†ä¸–ç•Œåœºæ™¯ï¼ŒåŒ…æ‹¬é™æ€ç¯å¢ƒã€åŠ¨æ€ç¯å¢ƒã€åŒ…å«æ•æ„Ÿå¯¹è±¡çš„ç¯å¢ƒç­‰ã€‚2) ä»»åŠ¡å®šä¹‰æ¨¡å—ï¼šå®šä¹‰æ™ºèƒ½ä½“éœ€è¦åœ¨åœºæ™¯ä¸­å®Œæˆçš„ä»»åŠ¡ï¼Œè¿™äº›ä»»åŠ¡å¯èƒ½ä¸éšç§ä¿æŠ¤ç›¸å†²çªã€‚3) éšç§çº¦æŸæ¨¡å—ï¼šå®šä¹‰æ™ºèƒ½ä½“åœ¨æ‰§è¡Œä»»åŠ¡æ—¶éœ€è¦éµå®ˆçš„éšç§çº¦æŸï¼Œä¾‹å¦‚é¿å…è§¦ç¢°æ•æ„Ÿå¯¹è±¡ã€å°Šé‡ä»–äººéšç§ç­‰ã€‚4) è¯„ä¼°æŒ‡æ ‡æ¨¡å—ï¼šå®šä¹‰ç”¨äºè¯„ä¼°æ™ºèƒ½ä½“éšç§ä¿æŠ¤èƒ½åŠ›çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚éšç§è¿è§„ç‡ã€ä»»åŠ¡å®Œæˆç‡ç­‰ã€‚5) LLMæ¥å£æ¨¡å—ï¼šå°†åœºæ™¯ä¿¡æ¯å’Œä»»åŠ¡æŒ‡ä»¤ä¼ é€’ç»™LLMï¼Œå¹¶æ¥æ”¶LLMçš„å†³ç­–ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šEAPrivacyçš„å…³é”®åˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿç³»ç»Ÿåœ°ã€å…¨é¢åœ°è¯„ä¼°LLMé©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§æ„è¯†ã€‚ä¸ç°æœ‰çš„è¯„ä¼°æ–¹æ³•ç›¸æ¯”ï¼ŒEAPrivacyæ›´åŠ å…³æ³¨æ™ºèƒ½ä½“åœ¨çœŸå®ç‰©ç†ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ æ™ºèƒ½ä½“çš„éšç§ä¿æŠ¤èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒEAPrivacyé‡‡ç”¨ç¨‹åºç”Ÿæˆåœºæ™¯çš„æ–¹å¼ï¼Œå¯ä»¥çµæ´»åœ°æ‰©å±•åœºæ™¯çš„å¤æ‚åº¦å’Œå¤šæ ·æ€§ï¼Œä»è€Œæ›´å…¨é¢åœ°è¯„ä¼°æ™ºèƒ½ä½“çš„éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šEAPrivacyçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤šå±‚çº§åœºæ™¯è®¾è®¡ï¼šåœºæ™¯åˆ†ä¸ºå››ä¸ªå±‚çº§ï¼Œåˆ†åˆ«æµ‹è¯•æ™ºèƒ½ä½“å¤„ç†æ•æ„Ÿå¯¹è±¡ã€é€‚åº”å˜åŒ–ç¯å¢ƒã€å¹³è¡¡ä»»åŠ¡æ‰§è¡Œä¸éšç§çº¦æŸä»¥åŠè§£å†³ä¸ç¤¾ä¼šè§„èŒƒå†²çªçš„èƒ½åŠ›ã€‚2) éšç§çº¦æŸä¸ä»»åŠ¡ç›®æ ‡çš„å†²çªè®¾è®¡ï¼šåœ¨æŸäº›åœºæ™¯ä¸­ï¼Œä»»åŠ¡ç›®æ ‡ä¸éšç§çº¦æŸå­˜åœ¨å†²çªï¼Œéœ€è¦æ™ºèƒ½ä½“è¿›è¡Œæƒè¡¡ã€‚3) è¯„ä¼°æŒ‡æ ‡çš„è®¾è®¡ï¼šé‡‡ç”¨å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬éšç§è¿è§„ç‡ã€ä»»åŠ¡å®Œæˆç‡ã€ç¤¾ä¼šè§„èŒƒéµå®ˆç‡ç­‰ï¼Œå…¨é¢è¯„ä¼°æ™ºèƒ½ä½“çš„éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç°æœ‰LLMåœ¨EAPrivacyåŸºå‡†ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚Gemini 2.5 Proåœ¨æ¶‰åŠå˜åŒ–ç‰©ç†ç¯å¢ƒçš„åœºæ™¯ä¸­ä»…è¾¾åˆ°59%çš„å‡†ç¡®ç‡ã€‚å½“ä»»åŠ¡ä¼´éšéšç§è¯·æ±‚æ—¶ï¼Œæ¨¡å‹åœ¨é«˜è¾¾86%çš„æƒ…å†µä¸‹ä¼˜å…ˆå®Œæˆä»»åŠ¡è€Œééµå®ˆçº¦æŸã€‚åœ¨éšç§ä¸å…³é”®ç¤¾ä¼šè§„èŒƒç›¸å†²çªçš„é«˜é£é™©æƒ…å¢ƒä¸­ï¼ŒGPT-4oå’ŒClaude-3.5-haikuç­‰é¢†å…ˆæ¨¡å‹åœ¨è¶…è¿‡15%çš„æƒ…å†µä¸‹æ— è§†ç¤¾ä¼šè§„èŒƒã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œç°æœ‰LLMåœ¨ç‰©ç†ä¸–ç•Œéšç§ä¿æŠ¤æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EAPrivacyçš„ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„å…·èº«æ™ºèƒ½ä½“ï¼Œä¾‹å¦‚å®¶åº­æœºå™¨äººã€åŒ»ç–—åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§æ„è¯†ï¼Œå¯ä»¥æœ‰æ•ˆä¿æŠ¤ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯å’Œéšç§ï¼Œé¿å…æ½œåœ¨çš„éšç§æ³„éœ²é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†è¿˜å¯ä»¥ç”¨äºæŒ‡å¯¼LLMçš„è®­ç»ƒå’Œå¯¹é½ï¼Œä½¿å…¶æ›´å¥½åœ°ç†è§£å’Œéµå®ˆç‰©ç†ä¸–ç•Œçš„éšç§è§„åˆ™ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The deployment of Large Language Models (LLMs) in embodied agents creates an urgent need to measure their privacy awareness in the physical world. Existing evaluation methods, however, are confined to natural language based scenarios. To bridge this gap, we introduce EAPrivacy, a comprehensive evaluation benchmark designed to quantify the physical-world privacy awareness of LLM-powered agents. EAPrivacy utilizes procedurally generated scenarios across four tiers to test an agent's ability to handle sensitive objects, adapt to changing environments, balance task execution with privacy constraints, and resolve conflicts with social norms. Our measurements reveal a critical deficit in current models. The top-performing model, Gemini 2.5 Pro, achieved only 59\% accuracy in scenarios involving changing physical environments. Furthermore, when a task was accompanied by a privacy request, models prioritized completion over the constraint in up to 86\% of cases. In high-stakes situations pitting privacy against critical social norms, leading models like GPT-4o and Claude-3.5-haiku disregarded the social norm over 15\% of the time. These findings, demonstrated by our benchmark, underscore a fundamental misalignment in LLMs regarding physically grounded privacy and establish the need for more robust, physically-aware alignment. Codes and datasets will be available at https://github.com/Graph-COM/EAPrivacy.

