---
layout: default
title: VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts
---

# VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.15914" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.15914v1</a>
  <a href="https://arxiv.org/pdf/2510.15914.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15914v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.15914v1', 'VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiayu Zhao, Song Chen

**åˆ†ç±»**: cs.AR, cs.AI, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

**å¤‡æ³¨**: 9 pages, 5 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**VeriGRAGï¼šåˆ©ç”¨ç»“æ„æ„ŸçŸ¥è½¯æç¤ºå¢å¼ºLLMçš„Verilogä»£ç ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `Verilogä»£ç ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å›¾ç¥ç»ç½‘ç»œ` `ç»“æ„æ„ŸçŸ¥` `è½¯æç¤º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨Verilogä»£ç ä¸­è•´å«çš„ç¡¬ä»¶ç”µè·¯ç»“æ„ä¿¡æ¯ï¼Œå¯¼è‡´LLMç”Ÿæˆçš„ä»£ç åœ¨åŠŸèƒ½å’Œè¯­æ³•ä¸Šå­˜åœ¨ä¸è¶³ã€‚
2. VeriGRAGçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œæå–Verilogä»£ç çš„ç»“æ„å›¾åµŒå…¥ï¼Œå¹¶å°†å…¶èå…¥åˆ°LLMçš„æç¤ºä¸­ï¼Œä»è€Œå¼•å¯¼ä»£ç ç”Ÿæˆã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVeriGRAGåœ¨VerilogEvalå’ŒRTLLMåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨ä»è‡ªç„¶è¯­è¨€æè¿°ç”ŸæˆVerilogä»£ç æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒVerilogä»£ç æœ¬èº«ç¼–ç äº†ç¡¬ä»¶ç”µè·¯çš„ç»“æ„ä¿¡æ¯ã€‚å¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨è¿™ç§ç»“æ„ä¿¡æ¯æ¥æé«˜LLMç”Ÿæˆçš„Verilogä»£ç çš„åŠŸèƒ½å’Œè¯­æ³•æ­£ç¡®æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†VeriGRAGï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒä½¿ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä»Verilogä»£ç ä¸­æå–ç»“æ„å›¾åµŒå…¥ã€‚ç„¶åï¼Œå¤šæ¨¡æ€æ£€ç´¢å™¨é€‰æ‹©ä¸ç»™å®šç”Ÿæˆä»»åŠ¡æœ€ç›¸å…³çš„å›¾åµŒå…¥ï¼Œå¹¶é€šè¿‡VeriFormeræ¨¡å—å°†å…¶ä¸ä»£ç æ¨¡æ€å¯¹é½ï¼Œä»¥ç”Ÿæˆç»“æ„æ„ŸçŸ¥çš„è½¯æç¤ºã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒVeriGRAGæ˜¾è‘—æé«˜äº†Verilogä»£ç ç”Ÿæˆçš„æ­£ç¡®æ€§ï¼Œåœ¨VerilogEvalå’ŒRTLLMåŸºå‡†æµ‹è¯•ä¸­å‡å®ç°äº†æœ€å…ˆè¿›æˆ–æ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ç”ŸæˆVerilogä»£ç æ—¶ï¼Œç”±äºç¼ºä¹å¯¹ç¡¬ä»¶ç”µè·¯ç»“æ„ä¿¡æ¯çš„æœ‰æ•ˆåˆ©ç”¨ï¼Œå¯¼è‡´ç”Ÿæˆçš„ä»£ç åœ¨åŠŸèƒ½å’Œè¯­æ³•ä¸Šå­˜åœ¨ç¼ºé™·çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç›´æ¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æè¿°ä½œä¸ºLLMçš„è¾“å…¥ï¼Œå¿½ç•¥äº†Verilogä»£ç æœ¬èº«æ‰€è•´å«çš„ç»“æ„ä¿¡æ¯ï¼Œè¿™é™åˆ¶äº†LLMç”Ÿæˆé«˜è´¨é‡ä»£ç çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ä»Verilogä»£ç ä¸­æå–ç»“æ„å›¾åµŒå…¥ï¼Œå¹¶å°†è¿™äº›åµŒå…¥ä½œä¸ºè½¯æç¤ºï¼ˆsoft promptsï¼‰èå…¥åˆ°LLMçš„è¾“å…¥ä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒLLMå¯ä»¥æ„ŸçŸ¥åˆ°ç¡¬ä»¶ç”µè·¯çš„ç»“æ„ä¿¡æ¯ï¼Œä»è€Œç”Ÿæˆæ›´å‡†ç¡®ã€æ›´ç¬¦åˆè§„èŒƒçš„Verilogä»£ç ã€‚è¿™ç§è®¾è®¡æ€è·¯çš„å…³é”®åœ¨äºå°†ç»“æ„ä¿¡æ¯ä»¥ä¸€ç§å¯å­¦ä¹ çš„æ–¹å¼èå…¥åˆ°LLMä¸­ï¼Œè€Œä¸æ˜¯ç®€å•åœ°å°†ç»“æ„ä¿¡æ¯ä½œä¸ºé¢å¤–çš„è¾“å…¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVeriGRAGæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ï¼šç”¨äºä»Verilogä»£ç ä¸­æå–ç»“æ„å›¾åµŒå…¥ã€‚2) å¤šæ¨¡æ€æ£€ç´¢å™¨ï¼šç”¨äºé€‰æ‹©ä¸ç»™å®šç”Ÿæˆä»»åŠ¡æœ€ç›¸å…³çš„å›¾åµŒå…¥ã€‚3) VeriFormeræ¨¡å—ï¼šç”¨äºå°†å›¾åµŒå…¥ä¸ä»£ç æ¨¡æ€å¯¹é½ï¼Œç”Ÿæˆç»“æ„æ„ŸçŸ¥çš„è½¯æç¤ºã€‚4) LLMï¼šä½¿ç”¨ç»“æ„æ„ŸçŸ¥çš„è½¯æç¤ºç”ŸæˆVerilogä»£ç ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šé¦–å…ˆï¼ŒGNNæå–Verilogä»£ç çš„ç»“æ„å›¾åµŒå…¥ï¼›ç„¶åï¼Œå¤šæ¨¡æ€æ£€ç´¢å™¨æ ¹æ®ä»»åŠ¡é€‰æ‹©ç›¸å…³çš„åµŒå…¥ï¼›æ¥ç€ï¼ŒVeriFormerå°†åµŒå…¥ä¸ä»£ç æ¨¡æ€å¯¹é½ï¼Œç”Ÿæˆè½¯æç¤ºï¼›æœ€åï¼ŒLLMåˆ©ç”¨è½¯æç¤ºç”Ÿæˆä»£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šVeriGRAGæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†åˆ©ç”¨ç»“æ„å›¾åµŒå…¥ä½œä¸ºè½¯æç¤ºæ¥å¼•å¯¼LLMç”ŸæˆVerilogä»£ç çš„æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒVeriGRAGèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨Verilogä»£ç ä¸­è•´å«çš„ç»“æ„ä¿¡æ¯ï¼Œä»è€Œæé«˜ä»£ç ç”Ÿæˆçš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒVeriFormeræ¨¡å—çš„è®¾è®¡ä¹Ÿä½¿å¾—ç»“æ„ä¿¡æ¯èƒ½å¤Ÿæ›´å¥½åœ°èå…¥åˆ°LLMä¸­ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­GNNçš„å…·ä½“é€‰æ‹©ã€å¤šæ¨¡æ€æ£€ç´¢å™¨çš„ç›¸ä¼¼åº¦åº¦é‡æ–¹å¼ã€VeriFormeræ¨¡å—çš„ç½‘ç»œç»“æ„ä»¥åŠLLMçš„é€‰æ‹©éƒ½æ˜¯å…³é”®çš„è®¾è®¡ç»†èŠ‚ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦ç¡®ä¿LLMèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨ç»“æ„æ„ŸçŸ¥çš„è½¯æç¤ºæ¥ç”Ÿæˆä»£ç ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„åœ¨è®ºæ–‡ä¸­åº”è¯¥æœ‰è¯¦ç»†çš„æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

VeriGRAGåœ¨VerilogEvalå’ŒRTLLMåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼ŒVeriGRAGåœ¨ä¸¤ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›æˆ–æ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¡¨æ˜å…¶èƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜Verilogä»£ç ç”Ÿæˆçš„æ­£ç¡®æ€§ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VeriGRAGçš„ç ”ç©¶æˆæœå¯ä»¥åº”ç”¨äºè‡ªåŠ¨åŒ–ç¡¬ä»¶è®¾è®¡æµç¨‹ï¼Œæé«˜Verilogä»£ç ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ã€‚è¯¥æŠ€æœ¯å¯ä»¥å¸®åŠ©ç¡¬ä»¶å·¥ç¨‹å¸ˆå¿«é€Ÿç”Ÿæˆç¬¦åˆè§„èŒƒçš„Verilogä»£ç ï¼Œä»è€Œç¼©çŸ­äº§å“å¼€å‘å‘¨æœŸã€‚æ­¤å¤–ï¼ŒVeriGRAGè¿˜å¯ä»¥ç”¨äºæ•™è‚²é¢†åŸŸï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ç†è§£ç¡¬ä»¶ç”µè·¯çš„ç»“æ„å’ŒVerilogä»£ç çš„ç¼–å†™ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have demonstrated strong capabilities in generating Verilog code from natural language descriptions. However, Verilog code inherently encodes structural information of hardware circuits. Effectively leveraging this structural information to enhance the functional and syntactic correctness of LLM-generated Verilog code remains a significant challenge. To address this challenge, we propose VeriGRAG , a novel framework that extracts structural graph embeddings from Verilog code using graph neural networks (GNNs). A multimodal retriever then selects the graph embeddings most relevant to the given generation task, which are aligned with the code modality through the VeriFormer module to generate structure-aware soft prompts. Our experiments demonstrate that VeriGRAG substantially improves the correctness of Verilog code generation, achieving state-of-the-art or superior performance across both VerilogEval and RTLLM benchmarks.

