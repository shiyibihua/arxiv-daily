---
layout: default
title: p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding
---

# p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23234" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23234v4</a>
  <a href="https://arxiv.org/pdf/2509.23234.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23234v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23234v4', 'p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Runyan Tan, Shuang Wu, Phillip Howard

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-28)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ryttry/p-less)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºp-lessé‡‡æ ·æ–¹æ³•ï¼Œä¸€ç§æ— éœ€è¶…å‚æ•°çš„é²æ£’LLMè§£ç ç­–ç•¥ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLMè§£ç ` `é‡‡æ ·ç­–ç•¥` `æ— è¶…å‚æ•°` `ä¿¡æ¯è®º` `æ–‡æœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè§£ç é‡‡æ ·æ–¹æ³•ä¾èµ–è¶…å‚æ•°è°ƒæ•´ï¼Œå¯¹ä¸åŒä»»åŠ¡å’Œæ¸©åº¦é…ç½®æ•æ„Ÿï¼Œå½±å“ç”Ÿæˆè´¨é‡ã€‚
2. p-lessé‡‡æ ·åŸºäºä¿¡æ¯è®ºåŠ¨æ€è®¾ç½®æˆªæ–­é˜ˆå€¼ï¼Œæ— éœ€è¶…å‚æ•°ï¼Œæå‡äº†é‡‡æ ·æ–¹æ³•çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œp-lessé‡‡æ ·åœ¨æ•°å­¦ã€æ¨ç†å’Œå†™ä½œä»»åŠ¡ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨é«˜æ¸©åº¦ä¸‹æ–‡æœ¬è´¨é‡ä¸‹é™æ›´å°‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è·å¾—é«˜è´¨é‡è¾“å‡ºé€šå¸¸å–å†³äºåŸºäºé‡‡æ ·çš„è§£ç ç­–ç•¥ï¼Œè¯¥ç­–ç•¥åœ¨æ¯ä¸ªç”Ÿæˆæ­¥éª¤ä¸­æ¦‚ç‡æ€§åœ°é€‰æ‹©ä¸‹ä¸€ä¸ªtokenã€‚è™½ç„¶å·²ç»æå‡ºäº†å„ç§è¿™æ ·çš„é‡‡æ ·æ–¹æ³•ï¼Œä½†å®ƒä»¬çš„æ€§èƒ½å¯èƒ½å¯¹è¶…å‚æ•°çš„é€‰æ‹©å¾ˆæ•æ„Ÿï¼Œè¿™å¯èƒ½éœ€è¦æ ¹æ®ç”Ÿæˆä»»åŠ¡å’Œæ¸©åº¦é…ç½®è¿›è¡Œä¸åŒçš„è®¾ç½®ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä»‹ç»$p$-lessé‡‡æ ·ï¼šä¸€ç§ä¿¡æ¯è®ºçš„é‡‡æ ·æ–¹æ³•ï¼Œå®ƒåŸºäºæ•´ä¸ªtokenæ¦‚ç‡åˆ†å¸ƒåœ¨æ¯ä¸ªè§£ç æ­¥éª¤åŠ¨æ€è®¾ç½®æˆªæ–­é˜ˆå€¼ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼Œ$p$-lessé‡‡æ ·æ²¡æœ‰è¶…å‚æ•°ï¼Œå¹¶ä¸”éšç€æ¸©åº¦çš„å‡é«˜ï¼Œå§‹ç»ˆå¦‚ä¸€åœ°äº§ç”Ÿé«˜è´¨é‡çš„è¾“å‡ºã€‚æˆ‘ä»¬æä¾›äº†å…³äº$p$-lessé‡‡æ ·çš„ç†è®ºè§†è§’ï¼Œä»¥æ”¯æŒæˆ‘ä»¬æå‡ºçš„æ–¹æ³•ï¼Œå¹¶è¿›è¡Œå®éªŒä»¥å®è¯éªŒè¯å…¶åœ¨æ•°å­¦ã€é€»è¾‘æ¨ç†å’Œåˆ›é€ æ€§å†™ä½œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œ$p$-lessé‡‡æ ·å§‹ç»ˆä¼˜äºç°æœ‰çš„é‡‡æ ·æ–¹æ³•ï¼ŒåŒæ—¶åœ¨è¾ƒé«˜çš„æ¸©åº¦å€¼ä¸‹æ–‡æœ¬è´¨é‡çš„ä¸‹é™è¦å°å¾—å¤šã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†$p$-lesså¦‚ä½•é€šè¿‡æ›´ä½çš„å¹³å‡tokené‡‡æ ·æ—¶é—´å’Œæ›´çŸ­çš„ç”Ÿæˆé•¿åº¦æ¥å®ç°æ¯”æ›¿ä»£æ–¹æ³•æ›´é«˜çš„æ¨ç†æ—¶é—´æ•ˆç‡ï¼Œè€Œåˆä¸ç‰ºç‰²å‡†ç¡®æ€§ã€‚æœ€åï¼Œæˆ‘ä»¬æä¾›äº†åˆ†æï¼Œé€šè¿‡å®šæ€§ç¤ºä¾‹ã€æ¡ˆä¾‹ç ”ç©¶å’Œå¤šæ ·æ€§è¯„ä¼°æ¥çªå‡º$p$-lessçš„ä¼˜åŠ¿ã€‚ä»£ç å¯åœ¨https://github.com/ryttry/p-less è·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºé‡‡æ ·çš„LLMè§£ç æ–¹æ³•ï¼Œå¦‚Top-ké‡‡æ ·ã€Nucleusé‡‡æ ·ç­‰ï¼Œå…¶æ€§èƒ½é«˜åº¦ä¾èµ–äºè¶…å‚æ•°çš„é€‰æ‹©ã€‚é’ˆå¯¹ä¸åŒçš„ç”Ÿæˆä»»åŠ¡å’Œæ¸©åº¦è®¾ç½®ï¼Œéœ€è¦æ‰‹åŠ¨è°ƒæ•´è¿™äº›è¶…å‚æ•°ï¼Œè¿‡ç¨‹ç¹çä¸”éš¾ä»¥ä¿è¯æœ€ä½³æ€§èƒ½ã€‚æ­¤å¤–ï¼Œåœ¨é«˜æ¸©åº¦è®¾ç½®ä¸‹ï¼Œè¿™äº›æ–¹æ³•å®¹æ˜“äº§ç”Ÿä½è´¨é‡æˆ–ä¸è¿è´¯çš„æ–‡æœ¬ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šp-lessé‡‡æ ·çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨ä¿¡æ¯è®ºåŸç†ï¼ŒåŠ¨æ€åœ°ç¡®å®šä¸€ä¸ªæˆªæ–­é˜ˆå€¼ï¼Œè¯¥é˜ˆå€¼åŸºäºæ•´ä¸ªtokenæ¦‚ç‡åˆ†å¸ƒã€‚è¿™æ„å‘³ç€åœ¨æ¯ä¸ªè§£ç æ­¥éª¤ï¼Œæ¨¡å‹ä¼šè‡ªé€‚åº”åœ°é€‰æ‹©ä¸€ä¸ªæ¦‚ç‡è¾ƒé«˜çš„tokenå­é›†ï¼Œè€Œä¸æ˜¯åƒä¼ ç»Ÿæ–¹æ³•é‚£æ ·ä¾èµ–å›ºå®šçš„è¶…å‚æ•°ã€‚è¿™ç§è‡ªé€‚åº”æ€§ä½¿å¾—p-lessé‡‡æ ·èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹ä¸åŒçš„ä»»åŠ¡å’Œæ¸©åº¦è®¾ç½®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šp-lessé‡‡æ ·çš„æ•´ä½“æµç¨‹å¦‚ä¸‹ï¼š1. è·å–LLMé¢„æµ‹çš„tokenæ¦‚ç‡åˆ†å¸ƒï¼›2. åŸºäºè¯¥åˆ†å¸ƒï¼Œè®¡ç®—ä¸€ä¸ªåŠ¨æ€æˆªæ–­é˜ˆå€¼ï¼›3. ä»…ä»æ¦‚ç‡é«˜äºè¯¥é˜ˆå€¼çš„tokenä¸­è¿›è¡Œé‡‡æ ·ï¼›4. å°†é‡‡æ ·çš„tokenä½œä¸ºä¸‹ä¸€ä¸ªè¾“å…¥ï¼Œé‡å¤ä¸Šè¿°æ­¥éª¤ç›´åˆ°ç”Ÿæˆç»“æŸã€‚è¯¥æ–¹æ³•ä¸éœ€è¦é¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºç°æœ‰çš„LLMã€‚

**å…³é”®åˆ›æ–°**ï¼šp-lessé‡‡æ ·çš„å…³é”®åˆ›æ–°åœ¨äºå…¶åŠ¨æ€æˆªæ–­é˜ˆå€¼çš„è®¡ç®—æ–¹å¼ã€‚ä¸ç°æœ‰æ–¹æ³•ä½¿ç”¨å›ºå®šçš„è¶…å‚æ•°ä¸åŒï¼Œp-lessé‡‡æ ·ä½¿ç”¨ä¿¡æ¯è®ºåŸç†ï¼ŒåŸºäºæ•´ä¸ªtokenæ¦‚ç‡åˆ†å¸ƒè‡ªé€‚åº”åœ°ç¡®å®šé˜ˆå€¼ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰tokenä¹‹é—´çš„å…³ç³»ï¼Œå¹¶é¿å…é€‰æ‹©ä½æ¦‚ç‡çš„tokenï¼Œä»è€Œæé«˜ç”Ÿæˆè´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šp-lessé‡‡æ ·æ²¡æœ‰éœ€è¦æ‰‹åŠ¨è°ƒæ•´çš„è¶…å‚æ•°ã€‚å…¶æ ¸å¿ƒåœ¨äºåŠ¨æ€æˆªæ–­é˜ˆå€¼çš„è®¡ç®—ã€‚å…·ä½“è€Œè¨€ï¼Œè®ºæ–‡å¯èƒ½ä½¿ç”¨è¯¸å¦‚ç†µã€KLæ•£åº¦ç­‰ä¿¡æ¯è®ºæŒ‡æ ‡æ¥è¡¡é‡tokenæ¦‚ç‡åˆ†å¸ƒçš„ä¸ç¡®å®šæ€§ï¼Œå¹¶åŸºäºæ­¤ç¡®å®šæˆªæ–­é˜ˆå€¼ã€‚å…·ä½“çš„è®¡ç®—å…¬å¼å’Œå®ç°ç»†èŠ‚éœ€è¦åœ¨è®ºæ–‡ä¸­è¿›ä¸€æ­¥æŸ¥æ‰¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œp-lessé‡‡æ ·åœ¨æ•°å­¦ã€é€»è¾‘æ¨ç†å’Œåˆ›é€ æ€§å†™ä½œä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰çš„é‡‡æ ·æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨é«˜æ¸©åº¦è®¾ç½®ä¸‹ï¼Œp-lessé‡‡æ ·èƒ½å¤Ÿæ˜¾è‘—é™ä½æ–‡æœ¬è´¨é‡çš„ä¸‹é™ã€‚æ­¤å¤–ï¼Œp-lessé‡‡æ ·è¿˜å®ç°äº†æ›´é«˜çš„æ¨ç†æ•ˆç‡ï¼Œé€šè¿‡æ›´ä½çš„å¹³å‡tokené‡‡æ ·æ—¶é—´å’Œæ›´çŸ­çš„ç”Ÿæˆé•¿åº¦ï¼Œåœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹æå‡äº†æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

p-lessé‡‡æ ·å¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦é«˜è´¨é‡æ–‡æœ¬ç”Ÿæˆçš„åœºæ™¯ï¼Œå¦‚æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ã€å¯¹è¯ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ã€‚å…¶æ— éœ€è¶…å‚æ•°çš„ç‰¹æ€§ï¼Œé™ä½äº†ä½¿ç”¨é—¨æ§›ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥æ›´ä¾¿æ·åœ°åˆ©ç”¨LLMç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€‚è¯¥æ–¹æ³•è¿˜æœ‰åŠ©äºæå‡LLMåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„åº”ç”¨æ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Obtaining high-quality outputs from Large Language Models (LLMs) often depends upon the choice of a sampling-based decoding strategy to probabilistically choose the next token at each generation step. While a variety of such sampling methods have been proposed, their performance can be sensitive to the selection of hyperparameters which may require different settings depending upon the generation task and temperature configuration. In this work, we introduce $p$-less sampling: an information-theoretic approach to sampling which dynamically sets a truncation threshold at each decoding step based on the entire token probability distribution. Unlike existing methods, $p$-less sampling has no hyperparameters and consistently produces high-quality outputs as temperature increases. We provide theoretical perspectives on $p$-less sampling to ground our proposed method and conduct experiments to empirically validate its effectiveness across a range of math, logical reasoning, and creative writing tasks. Our results demonstrate how $p$-less sampling consistently outperforms existing sampling approaches while exhibiting much less degradation in text quality at higher temperature values. We further show how $p$-less achieves greater inference-time efficiency than alternative methods through lower average token sampling times and shorter generation lengths, without sacrificing accuracy. Finally, we provide analyses to highlight the benefits of $p$-less through qualitative examples, case studies, and diversity assessments. The code is available at https://github.com/ryttry/p-less .

