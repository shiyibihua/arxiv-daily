---
layout: default
title: AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models
---

# AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23435" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23435v1</a>
  <a href="https://arxiv.org/pdf/2509.23435.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23435v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23435v1', 'AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenyu Li, Xiaoqi Jiao, Yi Chang, Guangyan Zhang, Yiwen Guo

**åˆ†ç±»**: cs.SD, cs.AI, cs.MM, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAudioRoleæ•°æ®é›†ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”ä¸­çš„éŸ³é¢‘ä¸ªæ€§åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³é¢‘è§’è‰²æ‰®æ¼”` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é›†` `è¯­éŸ³ä¸ªæ€§åŒ–` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§’è‰²æ‰®æ¼”å¤§è¯­è¨€æ¨¡å‹ä¸»è¦é›†ä¸­äºæ–‡æœ¬ï¼Œç¼ºä¹å¯¹éŸ³é¢‘ç‰¹å¾çš„åŒæ­¥å»ºæ¨¡ï¼Œå¯¼è‡´éŸ³é¢‘è§’è‰²æ‰®æ¼”æ•ˆæœä¸ä½³ã€‚
2. AudioRoleæ•°æ®é›†é€šè¿‡æä¾›å¤§è§„æ¨¡ã€é«˜è´¨é‡çš„åŒæ­¥éŸ³é¢‘-æ–‡æœ¬æ•°æ®ï¼Œä»¥åŠè¯´è¯äººèº«ä»½å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œå¼¥è¡¥äº†è¿™ä¸€ä¸è¶³ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºAudioRoleè®­ç»ƒçš„æ¨¡å‹åœ¨å£°å­¦å’Œå†…å®¹ä¸ªæ€§åŒ–æ–¹é¢å‡ä¼˜äºç°æœ‰æ¨¡å‹ï¼ŒéªŒè¯äº†æ•°æ®é›†çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è§’è‰²æ‰®æ¼”èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éŸ³é¢‘è§’è‰²æ‰®æ¼”ï¼ˆARPï¼‰æ–¹é¢ï¼Œæœ¬æ–‡æå‡ºäº†AudioRoleæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ä»13ä¸ªç”µè§†å‰§ä¸­ç²¾é€‰äº†è¶…è¿‡1000å°æ—¶çš„éŸ³é¢‘ï¼ŒåŒ…å«100ä¸‡+ä¸ªåŸºäºè§’è‰²çš„å¯¹è¯ï¼Œå¹¶æä¾›äº†åŒæ­¥çš„éŸ³é¢‘-æ–‡æœ¬å¯¹ï¼Œä»¥åŠè¯´è¯äººèº«ä»½å’Œä¸Šä¸‹æ–‡å…ƒæ•°æ®æ ‡æ³¨ã€‚ä¸ºäº†éªŒè¯æ•°æ®é›†çš„æœ‰æ•ˆæ€§ï¼Œä½œè€…è¿˜æå‡ºäº†ARP-Evalï¼Œä¸€ä¸ªåŒé‡è¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°å›å¤è´¨é‡å’Œè§’è‰²ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºAudioRoleè®­ç»ƒçš„GLM-4-Voiceæ¨¡å‹ï¼ˆç§°ä¸ºARP-Modelï¼‰åœ¨å£°å­¦ä¸ªæ€§åŒ–æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹³å‡å£°å­¦ä¸ªæ€§åŒ–å¾—åˆ†è¾¾åˆ°0.31ï¼Œä¼˜äºåŸå§‹GLM-4-voiceå’Œæ›´å¼ºå¤§çš„MiniCPM-O-2.6æ¨¡å‹ã€‚åœ¨å†…å®¹ä¸ªæ€§åŒ–æ–¹é¢ï¼ŒARP-Modelçš„å¾—åˆ†ä¹Ÿè¾¾åˆ°äº†0.36ï¼Œæ¯”æœªç»è®­ç»ƒçš„åŸå§‹æ¨¡å‹æé«˜äº†çº¦38%ï¼Œå¹¶ä¸MiniCPM-O-2.6æ¨¡å‹æŒå¹³ã€‚AudioRoleåŒ…å«è¶…è¿‡115ä¸ªä¸»è¦è§’è‰²çš„å¯¹è¯ï¼Œ6ä¸ªè®­ç»ƒå¥½çš„ARP-Modelï¼Œä»¥åŠè¯„ä¼°åè®®ï¼Œä¸ºæ¨è¿›éŸ³é¢‘è§’è‰²æ‰®æ¼”ç ”ç©¶æä¾›äº†é‡è¦èµ„æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”ä»»åŠ¡ä¸­ï¼Œä¸»è¦å…³æ³¨æ–‡æœ¬ä¿¡æ¯ï¼Œå¿½ç•¥äº†è¯­éŸ³ä¸­çš„å£°å­¦ç‰¹å¾ï¼Œå¯¼è‡´åœ¨éŸ³é¢‘è§’è‰²æ‰®æ¼”åœºæ™¯ä¸‹ï¼Œæ— æ³•å‡†ç¡®æ¨¡æ‹Ÿè§’è‰²çš„å£°éŸ³ç‰¹ç‚¹å’Œæƒ…æ„Ÿè¡¨è¾¾ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹é«˜è´¨é‡çš„ã€åŒ…å«åŒæ­¥éŸ³é¢‘-æ–‡æœ¬å¯¹ä»¥åŠè¯´è¯äººä¿¡æ¯çš„è®­ç»ƒæ•°æ®ï¼Œéš¾ä»¥æå‡æ¨¡å‹åœ¨éŸ³é¢‘è§’è‰²æ‰®æ¼”æ–¹é¢çš„æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„éŸ³é¢‘è§’è‰²æ‰®æ¼”æ•°æ®é›†AudioRoleï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸°å¯Œçš„è§’è‰²å¯¹è¯éŸ³é¢‘å’Œå¯¹åº”çš„æ–‡æœ¬ï¼Œå¹¶æ ‡æ³¨äº†è¯´è¯äººèº«ä»½å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚é€šè¿‡åœ¨è¯¥æ•°æ®é›†ä¸Šè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯ä»¥ä½¿æ¨¡å‹å­¦ä¹ åˆ°è§’è‰²å£°éŸ³çš„ä¸ªæ€§åŒ–ç‰¹å¾ï¼Œä»è€Œæå‡å…¶åœ¨éŸ³é¢‘è§’è‰²æ‰®æ¼”ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAudioRoleæ•°æ®é›†çš„æ„å»ºæµç¨‹ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) æ•°æ®æ”¶é›†ï¼šä»13ä¸ªç”µè§†å‰§ä¸­æ”¶é›†éŸ³é¢‘å’Œæ–‡æœ¬æ•°æ®ã€‚2) æ•°æ®æ¸…æ´—ï¼šå¯¹æ”¶é›†åˆ°çš„æ•°æ®è¿›è¡Œæ¸…æ´—å’Œè¿‡æ»¤ï¼Œå»é™¤å™ªå£°å’Œé”™è¯¯ä¿¡æ¯ã€‚3) æ•°æ®æ ‡æ³¨ï¼šå¯¹æ¸…æ´—åçš„æ•°æ®è¿›è¡Œæ ‡æ³¨ï¼ŒåŒ…æ‹¬è¯´è¯äººèº«ä»½ã€å¯¹è¯å†…å®¹å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚4) æ•°æ®åˆ’åˆ†ï¼šå°†æ ‡æ³¨åçš„æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ARP-Evalè¯„ä¼°æ¡†æ¶ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹çš„å›å¤è´¨é‡å’Œè§’è‰²ä¿çœŸåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡ã€é«˜è´¨é‡çš„éŸ³é¢‘è§’è‰²æ‰®æ¼”æ•°æ®é›†AudioRoleï¼Œè¯¥æ•°æ®é›†åŒ…å«äº†ä¸°å¯Œçš„è§’è‰²å¯¹è¯éŸ³é¢‘å’Œå¯¹åº”çš„æ–‡æœ¬ï¼Œå¹¶æ ‡æ³¨äº†è¯´è¯äººèº«ä»½å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚è¿™æ˜¯é¦–ä¸ªä¸“é—¨ä¸ºéŸ³é¢‘è§’è‰²æ‰®æ¼”ä»»åŠ¡è®¾è®¡çš„æ•°æ®é›†ï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦èµ„æºã€‚

**å…³é”®è®¾è®¡**ï¼šAudioRoleæ•°æ®é›†åŒ…å«è¶…è¿‡1000å°æ—¶çš„éŸ³é¢‘ï¼Œ100ä¸‡+ä¸ªåŸºäºè§’è‰²çš„å¯¹è¯ï¼Œä»¥åŠè¶…è¿‡115ä¸ªä¸»è¦è§’è‰²ã€‚æ•°æ®é›†ä¸­çš„éŸ³é¢‘å’Œæ–‡æœ¬æ•°æ®æ˜¯åŒæ­¥çš„ï¼Œå¹¶ä¸”æ ‡æ³¨äº†è¯´è¯äººèº«ä»½å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ARP-Evalè¯„ä¼°æ¡†æ¶åŒ…å«å£°å­¦ä¸ªæ€§åŒ–å’Œå†…å®¹ä¸ªæ€§åŒ–ä¸¤ä¸ªæ–¹é¢ï¼Œç”¨äºå…¨é¢è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºAudioRoleè®­ç»ƒçš„ARP-Modelåœ¨å£°å­¦ä¸ªæ€§åŒ–æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå¹³å‡å£°å­¦ä¸ªæ€§åŒ–å¾—åˆ†è¾¾åˆ°0.31ï¼Œä¼˜äºåŸå§‹GLM-4-voiceå’Œæ›´å¼ºå¤§çš„MiniCPM-O-2.6æ¨¡å‹ã€‚åœ¨å†…å®¹ä¸ªæ€§åŒ–æ–¹é¢ï¼ŒARP-Modelçš„å¾—åˆ†ä¹Ÿè¾¾åˆ°äº†0.36ï¼Œæ¯”æœªç»è®­ç»ƒçš„åŸå§‹æ¨¡å‹æé«˜äº†çº¦38%ï¼Œå¹¶ä¸MiniCPM-O-2.6æ¨¡å‹æŒå¹³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½å®¢æœã€è™šæ‹ŸåŠ©æ‰‹ã€æ¸¸æˆè§’è‰²æ‰®æ¼”ç­‰é¢†åŸŸã€‚é€šè¿‡ä½¿ç”¨AudioRoleæ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ï¼Œå¯ä»¥åˆ›å»ºæ›´å…·ä¸ªæ€§åŒ–å’ŒçœŸå®æ„Ÿçš„è¯­éŸ³äº¤äº’ä½“éªŒï¼Œæå‡ç”¨æˆ·æ»¡æ„åº¦å’Œæ²‰æµ¸æ„Ÿã€‚æœªæ¥ï¼Œè¯¥æ•°æ®é›†è¿˜å¯ä»¥ç”¨äºç ”ç©¶è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ã€è¯´è¯äººè¯†åˆ«ç­‰ç›¸å…³ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The creation of high-quality multimodal datasets remains fundamental for advancing role-playing capabilities in large language models (LLMs). While existing works predominantly focus on text-based persona simulation, Audio Role-Playing (ARP) presents unique challenges due to the need for synchronized alignment of semantic content and vocal characteristics. To address this gap, we propose AudioRole, a meticulously curated dataset from 13 TV series spanning 1K+ hours with 1M+ character-grounded dialogues, providing synchronized audio-text pairs annotated with speaker identities and contextual metadata. In addition, to demonstrate the effectiveness of the dataset, we introduced ARP-Eval, a dual-aspect evaluation framework that assesses both response quality and role fidelity. Empirical validation showing GLM-4-Voice trained on AudioRole (which we called ARP-Model) achieve an average Acoustic Personalization score of 0.31, significantly outperforming the original GLM-4-voice and the more powerful model MiniCPM-O-2.6, which specifically supports role-playing in one-shot scenarios. The ARP-Model also achieves a Content Personalization score of 0.36, surpassing the untrained original model by about 38% and maintaining the same level as MiniCPM-O-2.6.
>   AudioRole features dialogues from over 115 main characters, 6 trained ARP-Models that role-play different characters, and evaluation protocols. Together, they provide an essential resource for advancing audio-grounded role-playing research.

