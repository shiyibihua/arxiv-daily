---
layout: default
title: Risk Profiling and Modulation for LLMs
---

# Risk Profiling and Modulation for LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23058" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23058v3</a>
  <a href="https://arxiv.org/pdf/2509.23058.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23058v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23058v3', 'Risk Profiling and Modulation for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yikai Wang, Xiaocheng Li, Guanting Chen

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMé£é™©ç”»åƒä¸è°ƒæ§æ¡†æ¶ï¼Œæ­ç¤ºä¸åŒè®­ç»ƒé˜¶æ®µæ¨¡å‹çš„é£é™©åå¥½å·®å¼‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é£é™©åå¥½` `è¡Œä¸ºç»æµå­¦` `æ•ˆç”¨ç†è®º` `æŒ‡ä»¤å¾®è°ƒ` `RLHF` `é£é™©è°ƒæ§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹LLMåœ¨ä¸ç¡®å®šæ€§å†³ç­–ä¸­çš„é£é™©åå¥½æ¢ç´¢ä¸è¶³ï¼Œå°¤å…¶ç¼ºä¹å¯¹åè®­ç»ƒå½±å“çš„æ·±å…¥ç†è§£ã€‚
2. è®ºæ–‡æå‡ºä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡è¡Œä¸ºç»æµå­¦å’Œé‡‘èå­¦å·¥å…·ï¼Œå¯¹LLMçš„é£é™©åå¥½è¿›è¡Œå¼•å‡ºã€å¼•å¯¼å’Œè°ƒæ§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒæŒ‡ä»¤å¾®è°ƒæ¨¡å‹æ›´ç¬¦åˆæ•ˆç”¨ç†è®ºï¼Œè€Œåè®­ç»ƒæ˜¯è°ƒæ§LLMé£é™©åå¥½çš„æœ€æœ‰æ•ˆæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨äºä¸ç¡®å®šæ€§ä¸‹çš„å†³ç­–ä»»åŠ¡ï¼Œä½†å…¶é£é™©åå¥½ä»¥åŠæç¤ºå’Œå¯¹é½æ–¹æ³•å¦‚ä½•å½±å“è¿™äº›åå¥½ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºäººæ ¼æç¤ºæˆ–å¤šæ™ºèƒ½ä½“äº¤äº’ï¼Œåè®­ç»ƒå¦‚ä½•å½±å“LLMçš„é£é™©è¡Œä¸ºä»æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æµç¨‹ï¼Œå€Ÿé‰´è¡Œä¸ºç»æµå­¦å’Œé‡‘èå­¦çš„å·¥å…·ï¼Œç”¨äºå¼•å‡ºã€å¼•å¯¼å’Œè°ƒæ§LLMçš„é£é™©åå¥½ã€‚åˆ©ç”¨æ•ˆç”¨ç†è®ºæ¨¡å‹ï¼Œæˆ‘ä»¬æ¯”è¾ƒäº†é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’ŒRLHFå¯¹é½çš„LLMï¼Œå‘ç°æŒ‡ä»¤å¾®è°ƒæ¨¡å‹è¡¨ç°å‡ºä¸æŸäº›æ ‡å‡†æ•ˆç”¨å…¬å¼ä¸€è‡´çš„è¡Œä¸ºï¼Œè€Œé¢„è®­ç»ƒå’ŒRLHFå¯¹é½çš„æ¨¡å‹ä¸ä»»ä½•æ‹Ÿåˆçš„æ•ˆç”¨æ¨¡å‹éƒ½æœ‰æ›´å¤§çš„åå·®ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†è°ƒæ§ç­–ç•¥ï¼ŒåŒ…æ‹¬æç¤ºå·¥ç¨‹ã€ä¸Šä¸‹æ–‡å­¦ä¹ å’Œåè®­ç»ƒï¼Œå¹¶è¡¨æ˜åè®­ç»ƒæä¾›äº†æœ€ç¨³å®šå’Œæœ‰æ•ˆçš„é£é™©åå¥½è°ƒæ§ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ·±å…¥äº†è§£äº†ä¸åŒç±»åˆ«å’Œé˜¶æ®µçš„LLMçš„é£é™©åå¥½ï¼Œå¹¶å±•ç¤ºäº†åè®­ç»ƒå¦‚ä½•è°ƒæ§è¿™äº›åå¥½ï¼Œä¸ºæœªæ¥è¡Œä¸ºå¯¹é½å’Œé£é™©æ„ŸçŸ¥çš„LLMè®¾è®¡å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ä¸ç¡®å®šæ€§å†³ç­–ä»»åŠ¡ä¸­çš„é£é™©åå¥½é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºäººæ ¼æç¤ºæˆ–å¤šæ™ºèƒ½ä½“äº¤äº’ï¼Œå¿½ç•¥äº†åè®­ç»ƒé˜¶æ®µï¼ˆå¦‚æŒ‡ä»¤å¾®è°ƒå’ŒRLHFï¼‰å¯¹LLMé£é™©è¡Œä¸ºçš„å½±å“ã€‚å› æ­¤ï¼Œå¦‚ä½•ç†è§£å’Œè°ƒæ§ä¸åŒè®­ç»ƒé˜¶æ®µLLMçš„é£é™©åå¥½æˆä¸ºä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´è¡Œä¸ºç»æµå­¦å’Œé‡‘èå­¦çš„æ•ˆç”¨ç†è®ºï¼Œå°†LLMçš„å†³ç­–è¡Œä¸ºå»ºæ¨¡ä¸ºæ•ˆç”¨æœ€å¤§åŒ–çš„è¿‡ç¨‹ã€‚é€šè¿‡è®¾è®¡ç‰¹å®šçš„å®éªŒåœºæ™¯ï¼Œå¼•å‡ºLLMåœ¨ä¸åŒé£é™©æ°´å¹³ä¸‹çš„é€‰æ‹©ï¼Œå¹¶æ‹Ÿåˆç›¸åº”çš„æ•ˆç”¨å‡½æ•°ï¼Œä»è€Œåˆ»ç”»å…¶é£é™©åå¥½ã€‚ç„¶åï¼Œç ”ç©¶ä¸åŒçš„è°ƒæ§ç­–ç•¥ï¼ˆå¦‚æç¤ºå·¥ç¨‹ã€ä¸Šä¸‹æ–‡å­¦ä¹ å’Œåè®­ç»ƒï¼‰å¯¹LLMé£é™©åå¥½çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) **é£é™©åå¥½å¼•å‡º**ï¼šè®¾è®¡ä¸€ç³»åˆ—å†³ç­–åœºæ™¯ï¼Œè®©LLMåœ¨ä¸åŒé£é™©æ°´å¹³ä¸‹åšå‡ºé€‰æ‹©ï¼›2) **æ•ˆç”¨å‡½æ•°æ‹Ÿåˆ**ï¼šåˆ©ç”¨LLMçš„é€‰æ‹©æ•°æ®ï¼Œæ‹Ÿåˆä¸åŒçš„æ•ˆç”¨å‡½æ•°ï¼ˆå¦‚CRRAã€CARAç­‰ï¼‰ï¼Œè¯„ä¼°LLMçš„é£é™©åå¥½ç±»å‹ï¼›3) **é£é™©åå¥½è°ƒæ§**ï¼šå°è¯•ä¸åŒçš„è°ƒæ§ç­–ç•¥ï¼ˆæç¤ºå·¥ç¨‹ã€ä¸Šä¸‹æ–‡å­¦ä¹ ã€åè®­ç»ƒï¼‰ï¼Œè§‚å¯Ÿå…¶å¯¹LLMé£é™©åå¥½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å°†è¡Œä¸ºç»æµå­¦å’Œé‡‘èå­¦çš„æ•ˆç”¨ç†è®ºå¼•å…¥LLMé£é™©åå¥½ç ”ç©¶ï¼›2) ç³»ç»Ÿåœ°æ¯”è¾ƒäº†é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’ŒRLHFå¯¹é½çš„LLMçš„é£é™©åå¥½å·®å¼‚ï¼›3) è¯„ä¼°äº†å¤šç§é£é™©åå¥½è°ƒæ§ç­–ç•¥çš„æ•ˆæœï¼Œå¹¶å‘ç°åè®­ç»ƒæ˜¯æœ€æœ‰æ•ˆçš„è°ƒæ§æ‰‹æ®µã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç ”ç©¶æ›´å…¨é¢åœ°è€ƒè™‘äº†LLMè®­ç»ƒçš„ä¸åŒé˜¶æ®µï¼Œå¹¶æä¾›äº†æ›´æœ‰æ•ˆçš„é£é™©åå¥½è°ƒæ§æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é£é™©åå¥½å¼•å‡ºé˜¶æ®µï¼Œè®¾è®¡äº†ä¸€ç³»åˆ—äºŒå…ƒå½©ç¥¨é€‰æ‹©é¢˜ï¼Œæ¯ä¸ªé—®é¢˜åŒ…å«ä¸€ä¸ªé«˜é£é™©é«˜å›æŠ¥çš„é€‰é¡¹å’Œä¸€ä¸ªä½é£é™©ä½å›æŠ¥çš„é€‰é¡¹ã€‚LLMéœ€è¦é€‰æ‹©å…¶ä¸­ä¸€ä¸ªé€‰é¡¹ã€‚é€šè¿‡è°ƒæ•´å½©ç¥¨çš„æ¦‚ç‡å’Œå›æŠ¥ï¼Œå¯ä»¥æ§åˆ¶é£é™©æ°´å¹³ã€‚åœ¨æ•ˆç”¨å‡½æ•°æ‹Ÿåˆé˜¶æ®µï¼Œä½¿ç”¨äº†CRRAï¼ˆConstant Relative Risk Aversionï¼‰å’ŒCARAï¼ˆConstant Absolute Risk Aversionï¼‰ç­‰å¸¸è§çš„æ•ˆç”¨å‡½æ•°ï¼Œå¹¶ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ–¹æ³•æ‹Ÿåˆå‚æ•°ã€‚åœ¨åè®­ç»ƒè°ƒæ§é˜¶æ®µï¼Œä½¿ç”¨äº†åŸºäºå¥–åŠ±æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡è°ƒæ•´å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼LLMçš„é£é™©åå¥½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒæŒ‡ä»¤å¾®è°ƒåçš„LLMè¡¨ç°å‡ºä¸CRRAæ•ˆç”¨å‡½æ•°æ›´ä¸€è‡´çš„è¡Œä¸ºï¼Œè€Œåè®­ç»ƒï¼ˆç‰¹åˆ«æ˜¯åŸºäºå¥–åŠ±æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ï¼‰èƒ½å¤Ÿæœ‰æ•ˆåœ°è°ƒæ§LLMçš„é£é™©åå¥½ã€‚ç›¸æ¯”äºæç¤ºå·¥ç¨‹å’Œä¸Šä¸‹æ–‡å­¦ä¹ ï¼Œåè®­ç»ƒæä¾›äº†æ›´ç¨³å®šå’Œå¯æ§çš„é£é™©åå¥½è°ƒæ•´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé£é™©æ•æ„Ÿå‹LLMåº”ç”¨çš„è®¾è®¡ï¼Œä¾‹å¦‚é‡‘èæŠ•èµ„é¡¾é—®ã€åŒ»ç–—è¯Šæ–­è¾…åŠ©ç­‰ã€‚é€šè¿‡ç†è§£å’Œè°ƒæ§LLMçš„é£é™©åå¥½ï¼Œå¯ä»¥ä½¿å…¶åœ¨ä¸åŒåœºæ™¯ä¸‹åšå‡ºæ›´ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„å†³ç­–ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºè¡Œä¸ºå¯¹é½å’Œå®‰å…¨LLMçš„å¼€å‘æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly used for decision-making tasks under uncertainty; however, their risk profiles and how they are influenced by prompting and alignment methods remain underexplored. Existing studies have primarily examined personality prompting or multi-agent interactions, leaving open the question of how post-training influences the risk behavior of LLMs. In this work, we propose a new pipeline for eliciting, steering, and modulating LLMs' risk profiles, drawing on tools from behavioral economics and finance. Using utility-theoretic models, we compare pre-trained, instruction-tuned, and RLHF-aligned LLMs, and find that while instruction-tuned models exhibit behaviors consistent with some standard utility formulations, pre-trained and RLHF-aligned models deviate more from any utility models fitted. We further evaluate modulation strategies, including prompt engineering, in-context learning, and post-training, and show that post-training provides the most stable and effective modulation of risk preference. Our findings provide insights into the risk profiles of different classes and stages of LLMs and demonstrate how post-training modulates these profiles, laying the groundwork for future research on behavioral alignment and risk-aware LLM design.

