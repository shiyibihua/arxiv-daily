---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-09-27
---

# cs.AIï¼ˆ2025-09-27ï¼‰

ğŸ“Š å…± **32** ç¯‡è®ºæ–‡
 | ğŸ”— **4** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (27 ğŸ”—3)</a>
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (27 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250923350v1-abc-eval-benchmarking-large-language-models-on-symbolic-music-unders.html">ABC-Eval: Benchmarking Large Language Models on Symbolic Music Understanding and Instruction Following</a></td>
  <td>æå‡ºABC-EvalåŸºå‡†ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨ç¬¦å·éŸ³ä¹ç†è§£å’ŒæŒ‡ä»¤è·Ÿéšæ–¹é¢çš„èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23350v1" data-paper-url="./papers/250923350v1-abc-eval-benchmarking-large-language-models-on-symbolic-music-unders.html" onclick="toggleFavorite(this, '2509.23350v1', 'ABC-Eval: Benchmarking Large Language Models on Symbolic Music Understanding and Instruction Following')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250923250v3-training-vision-language-process-reward-models-for-test-time-scaling.html">Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned</a></td>
  <td>æå‡ºæ··åˆæ•°æ®åˆæˆæ¡†æ¶å’Œæ„ŸçŸ¥èšç„¦ç›‘ç£ï¼Œæå‡è§†è§‰è¯­è¨€æ¨¡å‹å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span> <span class="paper-tag">visual grounding</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23250v3" data-paper-url="./papers/250923250v3-training-vision-language-process-reward-models-for-test-time-scaling.html" onclick="toggleFavorite(this, '2509.23250v3', 'Training Vision-Language Process Reward Models for Test-Time Scaling in Multimodal Reasoning: Key Insights and Lessons Learned')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250923435v1-audiorole-an-audio-dataset-for-character-role-playing-in-large-langu.html">AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models</a></td>
  <td>æå‡ºAudioRoleæ•°æ®é›†ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹åœ¨è§’è‰²æ‰®æ¼”ä¸­çš„éŸ³é¢‘ä¸ªæ€§åŒ–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23435v1" data-paper-url="./papers/250923435v1-audiorole-an-audio-dataset-for-character-role-playing-in-large-langu.html" onclick="toggleFavorite(this, '2509.23435v1', 'AudioRole: An Audio Dataset for Character Role-Playing in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250923121v1-transferring-vision-language-action-models-to-industry-applications-.html">Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges</a></td>
  <td>è¯„ä¼°è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„æ€§èƒ½ä¸æŒ‘æˆ˜ï¼Œå¹¶åˆ†æå…¶éƒ¨ç½²å¯è¡Œæ€§</td>
  <td class="tags-cell"><span class="paper-tag">vision-language-action</span> <span class="paper-tag">VLA</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23121v1" data-paper-url="./papers/250923121v1-transferring-vision-language-action-models-to-industry-applications-.html" onclick="toggleFavorite(this, '2509.23121v1', 'Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/251002356v2-measuring-physical-world-privacy-awareness-of-large-language-models-.html">Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark</a></td>
  <td>æå‡ºEAPrivacyåŸºå‡†ï¼Œè¯„ä¼°å…·èº«æ™ºèƒ½ä½“åœ¨ç‰©ç†ä¸–ç•Œä¸­çš„éšç§æ„è¯†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02356v2" data-paper-url="./papers/251002356v2-measuring-physical-world-privacy-awareness-of-large-language-models-.html" onclick="toggleFavorite(this, '2510.02356v2', 'Measuring Physical-World Privacy Awareness of Large Language Models: An Evaluation Benchmark')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250925252v2-fact-grounded-attention-eliminating-hallucination-in-large-language-.html">Fact Grounded Attention: Eliminating Hallucination in Large Language Models Through Attention Level Knowledge Integration</a></td>
  <td>æå‡ºFact Grounded Attentionï¼Œé€šè¿‡çŸ¥è¯†æ³¨å…¥æ³¨æ„åŠ›æœºåˆ¶æ¶ˆé™¤å¤§è¯­è¨€æ¨¡å‹çš„äº‹å®å¹»è§‰ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25252v2" data-paper-url="./papers/250925252v2-fact-grounded-attention-eliminating-hallucination-in-large-language-.html" onclick="toggleFavorite(this, '2509.25252v2', 'Fact Grounded Attention: Eliminating Hallucination in Large Language Models Through Attention Level Knowledge Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250923108v1-artificial-phantasia-evidence-for-propositional-reasoning-based-ment.html">Artificial Phantasia: Evidence for Propositional Reasoning-Based Mental Imagery in Large Language Models</a></td>
  <td>æå‡ºåŸºäºå‘½é¢˜æ¨ç†çš„å¿ƒæ™ºæ„è±¡ä»»åŠ¡ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹å¤æ‚è®¤çŸ¥èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23108v1" data-paper-url="./papers/250923108v1-artificial-phantasia-evidence-for-propositional-reasoning-based-ment.html" onclick="toggleFavorite(this, '2509.23108v1', 'Artificial Phantasia: Evidence for Propositional Reasoning-Based Mental Imagery in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/251002342v1-catmark-a-context-aware-thresholding-framework-for-robust-cross-task.html">CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models</a></td>
  <td>æå‡ºCATMarkï¼Œä¸€ç§ä¸Šä¸‹æ–‡æ„ŸçŸ¥é˜ˆå€¼æ¡†æ¶ï¼Œç”¨äºå¤§è¯­è¨€æ¨¡å‹ä¸­é²æ£’çš„è·¨ä»»åŠ¡æ°´å°åµŒå…¥ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.02342v1" data-paper-url="./papers/251002342v1-catmark-a-context-aware-thresholding-framework-for-robust-cross-task.html" onclick="toggleFavorite(this, '2510.02342v1', 'CATMark: A Context-Aware Thresholding Framework for Robust Cross-Task Watermarking in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250923061v1-local-success-does-not-compose-benchmarking-large-language-models-fo.html">Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification</a></td>
  <td>DafnyCOMPï¼šç”¨äºè¯„æµ‹å¤§è¯­è¨€æ¨¡å‹åœ¨ç»„åˆå¼å½¢å¼åŒ–éªŒè¯ä¸­æ€§èƒ½çš„åŸºå‡†</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23061v1" data-paper-url="./papers/250923061v1-local-success-does-not-compose-benchmarking-large-language-models-fo.html" onclick="toggleFavorite(this, '2509.23061v1', 'Local Success Does Not Compose: Benchmarking Large Language Models for Compositional Formal Verification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250923023v1-deceive-detect-and-disclose-large-language-models-play-mini-mafia.html">Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia</a></td>
  <td>æå‡ºMini-MafiaåŸºå‡†æµ‹è¯•LLMçš„ç¤¾ä¼šæ™ºèƒ½ï¼Œè¯„ä¼°æ¬ºéª—ã€æ£€æµ‹å’Œä¿¡æ¯æŠ«éœ²èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23023v1" data-paper-url="./papers/250923023v1-deceive-detect-and-disclose-large-language-models-play-mini-mafia.html" onclick="toggleFavorite(this, '2509.23023v1', 'Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250923263v2-gui-pra-process-reward-agent-for-gui-tasks.html">GUI-PRA: Process Reward Agent for GUI Tasks</a></td>
  <td>æå‡ºGUI-PRAï¼Œé€šè¿‡åŠ¨æ€è®°å¿†å’ŒUIæ„ŸçŸ¥æå‡GUIä»»åŠ¡ä¸­è¿›ç¨‹å¥–åŠ±æ¨¡å‹çš„æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23263v2" data-paper-url="./papers/250923263v2-gui-pra-process-reward-agent-for-gui-tasks.html" onclick="toggleFavorite(this, '2509.23263v2', 'GUI-PRA: Process Reward Agent for GUI Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250923248v1-agentic-ai-reasoning-for-mobile-edge-general-intelligence-fundamenta.html">Agentic AI Reasoning for Mobile Edge General Intelligence: Fundamentals, Approaches, and Directions</a></td>
  <td>æå‡ºé¢å‘ç§»åŠ¨è¾¹ç¼˜é€šç”¨æ™ºèƒ½çš„Agentic AIæ¨ç†æ¡†æ¶ï¼Œä¼˜åŒ–èµ„æºæ•ˆç‡ä¸æ¨ç†è´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23248v1" data-paper-url="./papers/250923248v1-agentic-ai-reasoning-for-mobile-edge-general-intelligence-fundamenta.html" onclick="toggleFavorite(this, '2509.23248v1', 'Agentic AI Reasoning for Mobile Edge General Intelligence: Fundamentals, Approaches, and Directions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/251015914v1-verigrag-enhancing-llm-based-verilog-code-generation-with-structure-.html">VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts</a></td>
  <td>VeriGRAGï¼šåˆ©ç”¨ç»“æ„æ„ŸçŸ¥è½¯æç¤ºå¢å¼ºLLMçš„Verilogä»£ç ç”Ÿæˆ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.15914v1" data-paper-url="./papers/251015914v1-verigrag-enhancing-llm-based-verilog-code-generation-with-structure-.html" onclick="toggleFavorite(this, '2510.15914v1', 'VeriGRAG: Enhancing LLM-Based Verilog Code Generation with Structure-Aware Soft Prompts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/251021727v2-your-dense-retriever-is-secretly-an-expeditious-reasoner.html">Your Dense Retriever is Secretly an Expeditious Reasoner</a></td>
  <td>æå‡ºAdaQRï¼Œè‡ªé€‚åº”æ··åˆæŸ¥è¯¢é‡å†™æ¡†æ¶ï¼Œæå‡æ¨ç†æ£€ç´¢æ•ˆç‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.21727v2" data-paper-url="./papers/251021727v2-your-dense-retriever-is-secretly-an-expeditious-reasoner.html" onclick="toggleFavorite(this, '2510.21727v2', 'Your Dense Retriever is Secretly an Expeditious Reasoner')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250923338v1-parrot-a-benchmark-for-evaluating-llms-in-cross-system-sql-translati.html">PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation</a></td>
  <td>PARROTï¼šç”¨äºè¯„ä¼°LLMè·¨ç³»ç»ŸSQLè½¬æ¢èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23338v1" data-paper-url="./papers/250923338v1-parrot-a-benchmark-for-evaluating-llms-in-cross-system-sql-translati.html" onclick="toggleFavorite(this, '2509.23338v1', 'PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250923186v1-understanding-and-enhancing-the-planning-capability-of-language-mode.html">Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction</a></td>
  <td>é€šè¿‡å¤šTokené¢„æµ‹å¢å¼ºè¯­è¨€æ¨¡å‹åœ¨å¤æ‚è§„åˆ’ä¸­çš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23186v1" data-paper-url="./papers/250923186v1-understanding-and-enhancing-the-planning-capability-of-language-mode.html" onclick="toggleFavorite(this, '2509.23186v1', 'Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250923143v4-mathbode-measuring-the-stability-of-llm-reasoning-using-frequency-re.html">MathBode: Measuring the Stability of LLM Reasoning using Frequency Response</a></td>
  <td>MathBodeï¼šåˆ©ç”¨é¢‘ç‡å“åº”æµ‹é‡LLMæ•°å­¦æ¨ç†çš„ç¨³å®šæ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23143v4" data-paper-url="./papers/250923143v4-mathbode-measuring-the-stability-of-llm-reasoning-using-frequency-re.html" onclick="toggleFavorite(this, '2509.23143v4', 'MathBode: Measuring the Stability of LLM Reasoning using Frequency Response')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250923519v1-reliabilityrag-effective-and-provably-robust-defense-for-rag-based-w.html">ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search</a></td>
  <td>æå‡ºReliabilityRAGï¼Œåˆ©ç”¨æ–‡æ¡£å¯é æ€§ä¿¡æ¯å¢å¼ºRAGåœ¨Webæœç´¢ä¸­çš„é²æ£’æ€§ï¼Œé˜²å¾¡æ£€ç´¢è¯­æ–™åº“æ”»å‡»ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23519v1" data-paper-url="./papers/250923519v1-reliabilityrag-effective-and-provably-robust-defense-for-rag-based-w.html" onclick="toggleFavorite(this, '2509.23519v1', 'ReliabilityRAG: Effective and Provably Robust Defense for RAG-based Web-Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250923510v1-model-consistency-as-a-cheap-yet-predictive-proxy-for-llm-elo-scores.html">Model Consistency as a Cheap yet Predictive Proxy for LLM Elo Scores</a></td>
  <td>æå‡ºåŸºäºæ¨¡å‹ä¸€è‡´æ€§çš„LLM Eloè¯„åˆ†ä»£ç†ï¼Œæ— éœ€äººå·¥è¯„ä¼°ä¸”é«˜æ•ˆ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23510v1" data-paper-url="./papers/250923510v1-model-consistency-as-a-cheap-yet-predictive-proxy-for-llm-elo-scores.html" onclick="toggleFavorite(this, '2509.23510v1', 'Model Consistency as a Cheap yet Predictive Proxy for LLM Elo Scores')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250923482v1-geobs-information-theoretic-quantification-of-geographic-bias-in-ai-.html">GeoBS: Information-Theoretic Quantification of Geographic Bias in AI Models</a></td>
  <td>æå‡ºGeoBSæ¡†æ¶ï¼Œé€šè¿‡ä¿¡æ¯è®ºé‡åŒ–AIæ¨¡å‹ä¸­çš„åœ°ç†åå·®ï¼Œå¹¶è€ƒè™‘ç©ºé—´å› ç´ ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23482v1" data-paper-url="./papers/250923482v1-geobs-information-theoretic-quantification-of-geographic-bias-in-ai-.html" onclick="toggleFavorite(this, '2509.23482v1', 'GeoBS: Information-Theoretic Quantification of Geographic Bias in AI Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250923434v1-neurobridge-using-generative-ai-to-bridge-cross-neurotype-communicat.html">NeuroBridge: Using Generative AI to Bridge Cross-neurotype Communication Differences through Neurotypical Perspective-taking</a></td>
  <td>NeuroBridgeï¼šåˆ©ç”¨ç”Ÿæˆå¼AIå’Œç¥ç»å…¸å‹è§†è§’å¼¥åˆè·¨ç¥ç»ç±»å‹æ²Ÿé€šå·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23434v1" data-paper-url="./papers/250923434v1-neurobridge-using-generative-ai-to-bridge-cross-neurotype-communicat.html" onclick="toggleFavorite(this, '2509.23434v1', 'NeuroBridge: Using Generative AI to Bridge Cross-neurotype Communication Differences through Neurotypical Perspective-taking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250923324v1-scaling-llm-test-time-compute-with-mobile-npu-on-smartphones.html">Scaling LLM Test-Time Compute with Mobile NPU on Smartphones</a></td>
  <td>æå‡ºé¢å‘ç§»åŠ¨NPUçš„LLMæµ‹è¯•æ—¶å¹¶è¡Œæ‰©å±•æ–¹æ³•ï¼Œæå‡å°æ¨¡å‹æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23324v1" data-paper-url="./papers/250923324v1-scaling-llm-test-time-compute-with-mobile-npu-on-smartphones.html" onclick="toggleFavorite(this, '2509.23324v1', 'Scaling LLM Test-Time Compute with Mobile NPU on Smartphones')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250923234v4-p-less-sampling-a-robust-hyperparameter-free-approach-for-llm-decodi.html">p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding</a></td>
  <td>æå‡ºp-lessé‡‡æ ·æ–¹æ³•ï¼Œä¸€ç§æ— éœ€è¶…å‚æ•°çš„é²æ£’LLMè§£ç ç­–ç•¥ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23234v4" data-paper-url="./papers/250923234v4-p-less-sampling-a-robust-hyperparameter-free-approach-for-llm-decodi.html" onclick="toggleFavorite(this, '2509.23234v4', 'p-less Sampling: A Robust Hyperparameter-Free Approach for LLM Decoding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250923189v1-autoep-llms-driven-automation-of-hyperparameter-evolution-for-metahe.html">AutoEP: LLMs-Driven Automation of Hyperparameter Evolution for Metaheuristic Algorithms</a></td>
  <td>AutoEPï¼šåˆ©ç”¨LLMé©±åŠ¨çš„è¶…å‚æ•°è¿›åŒ–è‡ªåŠ¨ä¼˜åŒ–å…ƒå¯å‘å¼ç®—æ³•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23189v1" data-paper-url="./papers/250923189v1-autoep-llms-driven-automation-of-hyperparameter-evolution-for-metahe.html" onclick="toggleFavorite(this, '2509.23189v1', 'AutoEP: LLMs-Driven Automation of Hyperparameter Evolution for Metaheuristic Algorithms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250925248v1-buildbench-benchmarking-llm-agents-on-compiling-real-world-open-sour.html">BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software</a></td>
  <td>BuildBenchï¼šåŸºå‡†æµ‹è¯•LLM Agentåœ¨ç¼–è¯‘çœŸå®ä¸–ç•Œå¼€æºè½¯ä»¶ä¸Šçš„èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25248v1" data-paper-url="./papers/250925248v1-buildbench-benchmarking-llm-agents-on-compiling-real-world-open-sour.html" onclick="toggleFavorite(this, '2509.25248v1', 'BuildBench: Benchmarking LLM Agents on Compiling Real-World Open-Source Software')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250923045v3-kimi-dev-agentless-training-as-skill-prior-for-swe-agents.html">Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents</a></td>
  <td>Kimi-Devï¼šåŸºäºæ— Agentè®­ç»ƒçš„æŠ€èƒ½å…ˆéªŒæå‡è½¯ä»¶å·¥ç¨‹Agentæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23045v3" data-paper-url="./papers/250923045v3-kimi-dev-agentless-training-as-skill-prior-for-swe-agents.html" onclick="toggleFavorite(this, '2509.23045v3', 'Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250923019v2-llm-watermark-evasion-via-bias-inversion.html">LLM Watermark Evasion via Bias Inversion</a></td>
  <td>æå‡ºBias-Inversion Rewriting Attackï¼Œå®ç°LLMæ°´å°çš„æœ‰æ•ˆè§„é¿</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23019v2" data-paper-url="./papers/250923019v2-llm-watermark-evasion-via-bias-inversion.html" onclick="toggleFavorite(this, '2509.23019v2', 'LLM Watermark Evasion via Bias Inversion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/250923285v2-toward-effective-tool-integrated-reasoning-via-self-evolved-preferen.html">Toward Effective Tool-Integrated Reasoning via Self-Evolved Preference Learning</a></td>
  <td>æå‡ºTool-Lightæ¡†æ¶ï¼Œé€šè¿‡è‡ªè¿›åŒ–åå¥½å­¦ä¹ æå‡LLMå·¥å…·é›†æˆæ¨ç†çš„æ•ˆç‡ä¸å‡†ç¡®æ€§</td>
  <td class="tags-cell"><span class="paper-tag">preference learning</span> <span class="paper-tag">DPO</span> <span class="paper-tag">direct preference optimization</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23285v2" data-paper-url="./papers/250923285v2-toward-effective-tool-integrated-reasoning-via-self-evolved-preferen.html" onclick="toggleFavorite(this, '2509.23285v2', 'Toward Effective Tool-Integrated Reasoning via Self-Evolved Preference Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250923102v1-multiplayer-nash-preference-optimization.html">Multiplayer Nash Preference Optimization</a></td>
  <td>æå‡ºå¤šç©å®¶çº³ä»€åå¥½ä¼˜åŒ–ï¼ˆMNPOï¼‰ï¼Œæå‡LLMåœ¨å¤æ‚åå¥½ä¸‹çš„å¯¹é½æ•ˆæœã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23102v1" data-paper-url="./papers/250923102v1-multiplayer-nash-preference-optimization.html" onclick="toggleFavorite(this, '2509.23102v1', 'Multiplayer Nash Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250923488v3-mapping-overlaps-in-benchmarks-through-perplexity-in-the-wild.html">Mapping Overlaps in Benchmarks through Perplexity in the Wild</a></td>
  <td>é€šè¿‡å›°æƒ‘åº¦åˆ†æåŸºå‡†æµ‹è¯•é›†çš„é‡å åº¦ï¼Œæ­ç¤ºLLMèƒ½åŠ›é—´çš„å…³è”</td>
  <td class="tags-cell"><span class="paper-tag">world model</span> <span class="paper-tag">large language model</span> <span class="paper-tag">instruction following</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23488v3" data-paper-url="./papers/250923488v3-mapping-overlaps-in-benchmarks-through-perplexity-in-the-wild.html" onclick="toggleFavorite(this, '2509.23488v3', 'Mapping Overlaps in Benchmarks through Perplexity in the Wild')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>31</td>
  <td><a href="./papers/250923058v3-risk-profiling-and-modulation-for-llms.html">Risk Profiling and Modulation for LLMs</a></td>
  <td>æå‡ºLLMé£é™©ç”»åƒä¸è°ƒæ§æ¡†æ¶ï¼Œæ­ç¤ºä¸åŒè®­ç»ƒé˜¶æ®µæ¨¡å‹çš„é£é™©åå¥½å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23058v3" data-paper-url="./papers/250923058v3-risk-profiling-and-modulation-for-llms.html" onclick="toggleFavorite(this, '2509.23058v3', 'Risk Profiling and Modulation for LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>32</td>
  <td><a href="./papers/250923144v3-coordination-requires-simplification-thermodynamic-bounds-on-multi-o.html">Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence</a></td>
  <td>æå‡ºçƒ­åŠ›å­¦åè°ƒç†è®ºä»¥è§£å†³å¤šç›®æ ‡åè°ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.23144v3" data-paper-url="./papers/250923144v3-coordination-requires-simplification-thermodynamic-bounds-on-multi-o.html" onclick="toggleFavorite(this, '2509.23144v3', 'Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)