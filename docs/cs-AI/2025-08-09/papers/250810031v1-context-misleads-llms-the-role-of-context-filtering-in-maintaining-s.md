---
layout: default
title: Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs
---

# Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10031" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10031v1</a>
  <a href="https://arxiv.org/pdf/2508.10031.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10031v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10031v1', 'Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinhwa Kim, Ian G. Harris

**åˆ†ç±»**: cs.CR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-09

**å¤‡æ³¨**: 13 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹ä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡è¿‡æ»¤` `å®‰å…¨æ€§` `è¶Šç‹±æ”»å‡»` `è¾“å…¥é¢„å¤„ç†` `ç”¨æˆ·æ„å›¾è¯†åˆ«` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§ä¸Šé¢ä¸´è¶Šç‹±æ”»å‡»çš„æŒ‘æˆ˜ï¼Œæ¶æ„ä¸Šä¸‹æ–‡å¯èƒ½å¯¼è‡´æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚
2. è®ºæ–‡æå‡ºçš„ä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹é€šè¿‡é¢„å¤„ç†è¾“å…¥ï¼Œè¿‡æ»¤ä¸å¯ä¿¡çš„ä¸Šä¸‹æ–‡ï¼Œè¯†åˆ«çœŸå®ç”¨æˆ·æ„å›¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨é˜²å¾¡è¶Šç‹±æ”»å‡»æ—¶ï¼Œæ”»å‡»æˆåŠŸç‡é™ä½äº†88%ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„åŸå§‹æ€§èƒ½ï¼Œå±•ç°å‡ºå“è¶Šçš„å®‰å…¨æ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å„ç§è¶Šç‹±æ”»å‡»å¸¦æ¥äº†æ—¥ç›Šä¸¥é‡çš„å®‰å…¨å’Œä¼¦ç†é£é™©ã€‚æ¶æ„ç”¨æˆ·å¸¸å¸¸åˆ©ç”¨å¯¹æŠ—æ€§ä¸Šä¸‹æ–‡æ¥æ¬ºéª—LLMsï¼Œä½¿å…¶ç”Ÿæˆå¯¹æœ‰å®³æŸ¥è¯¢çš„å“åº”ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„é˜²å¾¡æœºåˆ¶â€”â€”ä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§è¾“å…¥é¢„å¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨è¿‡æ»¤æ‰ä¸å¯ä¿¡å’Œä¸å¯é çš„ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶è¯†åˆ«åŒ…å«çœŸå®ç”¨æˆ·æ„å›¾çš„ä¸»è¦æç¤ºï¼Œä»¥æ­ç¤ºéšè—çš„æ¶æ„æ„å›¾ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨é˜²å¾¡è¶Šç‹±æ”»å‡»æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿå°†æ”»å‡»æˆåŠŸç‡é™ä½å¤šè¾¾88%ï¼ŒåŒæ—¶ä¿æŒLLMsçš„åŸå§‹æ€§èƒ½ã€‚è¯¥æ¨¡å‹ä¸ºå³æ’å³ç”¨ï¼Œé€‚ç”¨äºæ‰€æœ‰LLMsï¼ŒåŒ…æ‹¬ç™½ç›’å’Œé»‘ç›’æ¨¡å‹ï¼Œå¢å¼ºå…¶å®‰å…¨æ€§è€Œæ— éœ€å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬å°†å…¬å¼€è¯¥æ¨¡å‹ä»¥ä¾›ç ”ç©¶ä½¿ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹æ¶æ„ä¸Šä¸‹æ–‡æ—¶çš„å®‰å…¨æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆè¯†åˆ«å’Œè¿‡æ»¤è¿™äº›ä¸å¯ä¿¡çš„ä¸Šä¸‹æ–‡ï¼Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆæœ‰å®³å†…å®¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„ä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œé¢„å¤„ç†ï¼Œè¿‡æ»¤æ‰ä¸å¯é çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºçœŸå®çš„ç”¨æˆ·æ„å›¾ï¼Œä»è€Œé™ä½è¢«æ¬ºéª—çš„é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥é¢„å¤„ç†æ¨¡å—ã€ä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å—å’Œç”¨æˆ·æ„å›¾è¯†åˆ«æ¨¡å—ã€‚è¾“å…¥é¢„å¤„ç†æ¨¡å—è´Ÿè´£æ¥æ”¶ç”¨æˆ·è¾“å…¥å¹¶è¿›è¡Œåˆæ­¥å¤„ç†ï¼Œè¿‡æ»¤æ¨¡å—åˆ™æ ¹æ®è®¾å®šçš„æ ‡å‡†ç­›é€‰ä¸Šä¸‹æ–‡ï¼Œæœ€åç”¨æˆ·æ„å›¾è¯†åˆ«æ¨¡å—æå–ä¸»è¦æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ¨¡å‹çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å³æ’å³ç”¨çš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿé€‚ç”¨äºæ‰€æœ‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ— è®ºæ˜¯ç™½ç›’è¿˜æ˜¯é»‘ç›’æ¨¡å‹ï¼Œä¸”æ— éœ€å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—å®‰å…¨æ€§æå‡å˜å¾—æ›´åŠ çµæ´»å’Œé«˜æ•ˆã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹åœ¨ä¸Šä¸‹æ–‡è¿‡æ»¤è¿‡ç¨‹ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿è¿‡æ»¤çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œæ¨¡å‹ç»“åˆäº†å¤šç§æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œä»¥å¢å¼ºå…¶å¯¹ä¸Šä¸‹æ–‡çš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹åœ¨é˜²å¾¡è¶Šç‹±æ”»å‡»æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ”»å‡»æˆåŠŸç‡é™ä½äº†é«˜è¾¾88%ã€‚ä¸ç°æœ‰æœ€å…ˆè¿›çš„é˜²å¾¡æœºåˆ¶ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹åœ¨å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ã€åœ¨çº¿å®¢æœå’Œå†…å®¹ç”Ÿæˆç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§ï¼Œå‡å°‘æ¶æ„å†…å®¹ç”Ÿæˆçš„é£é™©ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„å¹¿æ³›åº”ç”¨å¯èƒ½ä¼šæ¨åŠ¨æ›´å®‰å…¨çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Large Language Models (LLMs) have shown significant advancements in performance, various jailbreak attacks have posed growing safety and ethical risks. Malicious users often exploit adversarial context to deceive LLMs, prompting them to generate responses to harmful queries. In this study, we propose a new defense mechanism called Context Filtering model, an input pre-processing method designed to filter out untrustworthy and unreliable context while identifying the primary prompts containing the real user intent to uncover concealed malicious intent. Given that enhancing the safety of LLMs often compromises their helpfulness, potentially affecting the experience of benign users, our method aims to improve the safety of the LLMs while preserving their original performance. We evaluate the effectiveness of our model in defending against jailbreak attacks through comparative analysis, comparing our approach with state-of-the-art defense mechanisms against six different attacks and assessing the helpfulness of LLMs under these defenses. Our model demonstrates its ability to reduce the Attack Success Rates of jailbreak attacks by up to 88% while maintaining the original LLMs' performance, achieving state-of-the-art Safety and Helpfulness Product results. Notably, our model is a plug-and-play method that can be applied to all LLMs, including both white-box and black-box models, to enhance their safety without requiring any fine-tuning of the models themselves. We will make our model publicly available for research purposes.

