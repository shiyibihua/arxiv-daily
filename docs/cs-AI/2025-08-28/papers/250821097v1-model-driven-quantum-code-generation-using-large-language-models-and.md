---
layout: default
title: Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation
---

# Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.21097" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.21097v1</a>
  <a href="https://arxiv.org/pdf/2508.21097.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.21097v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.21097v1', 'Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nazanin Siavash, Armin Moin

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-28

**å¤‡æ³¨**: This paper is accepted to the New Ideas and Emerging Results (NIER) track of the ACM/IEEE 28th International Conference on Model Driven Engineering Languages and Systems (MODELS)

**DOI**: [10.1109/MODELS67397.2025.00031](https://doi.org/10.1109/MODELS67397.2025.00031)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„é‡å­ä»£ç ç”Ÿæˆæ–¹æ³•ä»¥åº”å¯¹å¼€å‘è€…æŠ€èƒ½ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é‡å­è®¡ç®—` `ä»£ç ç”Ÿæˆ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¢å¼ºæ£€ç´¢ç”Ÿæˆ` `UMLæ¨¡å‹` `è½¯ä»¶å·¥ç¨‹` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é‡å­è½¯ä»¶å¼€å‘ä¸­é¢ä¸´å¼€å‘è€…æŠ€èƒ½ä¸è¶³å’Œå¼‚æ„å¹³å°ç¯å¢ƒå¸¦æ¥çš„é«˜æˆæœ¬ä¸é£é™©ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œå¢å¼ºæ£€ç´¢ç”ŸæˆæŠ€æœ¯ï¼Œæ¥å®ç°ä»UMLæ¨¡å‹å®ä¾‹ç”Ÿæˆé‡å­ä»£ç çš„è§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–æç¤ºè®¾è®¡å¯ä»¥ä½¿CodeBLEUåˆ†æ•°æé«˜å››å€ï¼Œæ˜¾è‘—æå‡é‡å­ä»£ç çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œé€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œå¢å¼ºæ£€ç´¢ç”Ÿæˆï¼ˆRAGï¼‰ç®¡é“ï¼Œå®ç°æ¨¡å‹åˆ°æ–‡æœ¬/ä»£ç çš„è½¬æ¢ï¼Œç‰¹åˆ«å…³æ³¨é‡å­åŠæ··åˆé‡å­-ç»å…¸è½¯ä»¶ç³»ç»Ÿã€‚è¯¥æ–¹æ³•æ—¨åœ¨é™ä½å¼‚æ„å¹³å°ç¯å¢ƒä¸‹çš„å¼€å‘æˆæœ¬å’Œé£é™©ï¼Œå¹¶éªŒè¯äº†ä»UMLæ¨¡å‹å®ä¾‹ç”Ÿæˆä»£ç çš„å¯è¡Œæ€§ã€‚ä½¿ç”¨Qiskitåº“ç”Ÿæˆçš„Pythonä»£ç å¯åœ¨é‡å­è®¡ç®—æœºä¸Šæ‰§è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºå¯ä»¥å°†CodeBLEUåˆ†æ•°æé«˜å››å€ï¼Œç”Ÿæˆæ›´å‡†ç¡®å’Œä¸€è‡´çš„é‡å­ä»£ç ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢è®¨å…¶ä»–ç ”ç©¶é—®é¢˜ï¼Œå¦‚å°†è½¯ä»¶ç³»ç»Ÿæ¨¡å‹å®ä¾‹ä½œä¸ºRAGç®¡é“çš„ä¿¡æ¯æºç­‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é‡å­è½¯ä»¶å¼€å‘ä¸­ç”±äºå¼€å‘è€…æŠ€èƒ½ä¸è¶³å’Œå¼‚æ„å¹³å°ç¯å¢ƒå¯¼è‡´çš„é«˜æˆæœ¬å’Œé£é™©é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹å’Œå¢å¼ºæ£€ç´¢ç”ŸæˆæŠ€æœ¯ï¼Œé€šè¿‡ä»UMLæ¨¡å‹å®ä¾‹ç”Ÿæˆé‡å­ä»£ç ï¼Œæ¥æé«˜ä»£ç ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨åˆ©ç”¨ç°æœ‰çš„å¼€æºèµ„æºå’Œæ¨¡å‹èƒ½åŠ›ï¼Œé™ä½å¼€å‘é—¨æ§›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨UMLæ¨¡å‹å®ä¾‹ä½œä¸ºè¾“å…¥ï¼›å…¶æ¬¡ï¼Œé€šè¿‡RAGç®¡é“æ£€ç´¢ç›¸å…³çš„Qiskitä»£ç ç¤ºä¾‹ï¼›æœ€åï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæœ€ç»ˆçš„é‡å­ä»£ç ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†RAGä¸å¤§å‹è¯­è¨€æ¨¡å‹ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„ä»£ç ç”Ÿæˆæ–¹æ³•ã€‚è¿™ç§æ–¹æ³•ä¸ä¼ ç»Ÿçš„ä»£ç ç”ŸæˆæŠ€æœ¯ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“ï¼Œæé«˜ç”Ÿæˆä»£ç çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾è®¡äº†å¤šç§æç¤ºç­–ç•¥ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹çš„è¾“å‡ºè´¨é‡ã€‚ä½¿ç”¨çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„åŸºäºç°æœ‰çš„LLMæ¶æ„ï¼Œç¡®ä¿ç”Ÿæˆçš„ä»£ç ç¬¦åˆé‡å­è®¡ç®—çš„ç‰¹å®šè¦æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡ä¼˜åŒ–æç¤ºè®¾è®¡ï¼ŒCodeBLEUåˆ†æ•°æé«˜äº†å››å€ï¼Œè¡¨æ˜ç”Ÿæˆçš„é‡å­ä»£ç åœ¨å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ä¸Šæœ‰æ˜¾è‘—æå‡ã€‚è¿™ä¸€æˆæœä¸ºé‡å­è½¯ä»¶å¼€å‘æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡å­è½¯ä»¶å¼€å‘ã€æ•™è‚²åŸ¹è®­ä»¥åŠè½¯ä»¶å·¥ç¨‹å·¥å…·çš„è‡ªåŠ¨åŒ–ã€‚é€šè¿‡é™ä½å¼€å‘é—¨æ§›å’Œæé«˜ä»£ç ç”Ÿæˆçš„æ•ˆç‡ï¼Œèƒ½å¤Ÿæ¨åŠ¨é‡å­è®¡ç®—æŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces a novel research direction for model-to-text/code transformations by leveraging Large Language Models (LLMs) that can be enhanced with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum and hybrid quantum-classical software systems, where model-driven approaches can help reduce the costs and mitigate the risks associated with the heterogeneous platform landscape and lack of developers' skills. We validate one of the proposed ideas regarding generating code out of UML model instances of software systems. This Python code uses a well-established library, called Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG pipeline that we deploy incorporates sample Qiskit code from public GitHub repositories. Experimental results show that well-engineered prompts can improve CodeBLEU scores by up to a factor of four, yielding more accurate and consistent quantum code. However, the proposed research direction can go beyond this through further investigation in the future by conducting experiments to address our other research questions and ideas proposed here, such as deploying software system model instances as the source of information in the RAG pipelines, or deploying LLMs for code-to-code transformations, for instance, for transpilation use cases.

