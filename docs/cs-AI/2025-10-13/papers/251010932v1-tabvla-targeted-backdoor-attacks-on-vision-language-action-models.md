---
layout: default
title: TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models
---

# TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10932" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10932v1</a>
  <a href="https://arxiv.org/pdf/2510.10932.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10932v1" onclick="toggleFavorite(this, '2510.10932v1', 'TabVLA: Targeted Backdoor Attacks on Vision-Language-Action Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zonghuan Xu, Xiang Zheng, Xingjun Ma, Yu-Gang Jiang

**åˆ†ç±»**: cs.CR, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-13

**å¤‡æ³¨**: 8 pages, 8 tables, 1 figure. Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TabVLAï¼šé’ˆå¯¹è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹çš„æœ‰ç›®æ ‡åé—¨æ”»å‡»æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `åé—¨æ”»å‡»` `æœ‰ç›®æ ‡æ”»å‡»` `é»‘ç›’å¾®è°ƒ` `å…·èº«æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰VLAåé—¨æ”»å‡»ç ”ç©¶ä¸»è¦é›†ä¸­äºæ— ç›®æ ‡æ”»å‡»ï¼Œå¿½ç•¥äº†æ›´å…·å¨èƒæ€§çš„æœ‰ç›®æ ‡æ“çºµåœºæ™¯ã€‚
2. TabVLAæ¡†æ¶é€šè¿‡é»‘ç›’å¾®è°ƒå®ç°æœ‰ç›®æ ‡åé—¨æ”»å‡»ï¼Œå¹¶ä¼˜åŒ–ä¸­æ¯’æ•°æ®ç”Ÿæˆä»¥æé«˜æ”»å‡»æ•ˆæœã€‚
3. å®éªŒè¡¨æ˜è§†è§‰é€šé“æ˜¯ä¸»è¦æ”»å‡»é¢ï¼Œæ”»å‡»åœ¨è§¦å‘å™¨å˜åŒ–ä¸­ä¿æŒé²æ£’æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºæ£€æµ‹çš„é˜²å¾¡æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹åœ¨ç°å®å…·èº«æ™ºèƒ½ç³»ç»Ÿä¸­çš„æ—¥ç›Šæ™®åŠï¼Œå®ƒä»¬å¯¹åé—¨æ”»å‡»çš„è„†å¼±æ€§æ—¥ç›Šå¢åŠ ï¼Œæ„æˆäº†ä¸¥é‡çš„å®‰å…¨å¨èƒã€‚æ¤å…¥åé—¨çš„VLAæ™ºèƒ½ä½“å¯èƒ½è¢«é¢„å…ˆæ³¨å…¥çš„åé—¨éšè”½åœ°è§¦å‘ï¼Œä»è€Œæ‰§è¡Œå¯¹æŠ—æ€§åŠ¨ä½œï¼Œå¯èƒ½å¯¼è‡´ç³»ç»Ÿæ•…éšœç”šè‡³äººèº«ä¼¤å®³ã€‚è™½ç„¶å¯¹VLAæ¨¡å‹çš„åé—¨æ”»å‡»å·²æœ‰ç ”ç©¶ï¼Œä½†å…ˆå‰çš„å·¥ä½œä»…å…³æ³¨æ— ç›®æ ‡æ”»å‡»ï¼Œè€Œå¿½ç•¥äº†æ›´å…·å®é™…å¨èƒçš„æœ‰ç›®æ ‡æ“çºµåœºæ™¯ã€‚æœ¬æ–‡ç ”ç©¶äº†VLAæ¨¡å‹ä¸Šçš„æœ‰ç›®æ ‡åé—¨æ”»å‡»ï¼Œå¹¶æå‡ºäº†TabVLAï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é»‘ç›’å¾®è°ƒå®ç°æ­¤ç±»æ”»å‡»çš„æ–°æ¡†æ¶ã€‚TabVLAæ¢ç´¢äº†ä¸¤ç§ä¸éƒ¨ç½²ç›¸å…³çš„æ¨ç†æ—¶å¨èƒæ¨¡å‹ï¼šè¾“å…¥æµç¼–è¾‘å’Œåœºæ™¯å†…è§¦å‘ã€‚å®ƒå°†ä¸­æ¯’æ•°æ®ç”Ÿæˆå…¬å¼åŒ–ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œä»¥æé«˜æ”»å‡»æ•ˆæœã€‚åœ¨LIBEROåŸºå‡†ä¸Šä½¿ç”¨OpenVLA-7Bè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè§†è§‰é€šé“æ˜¯ä¸»è¦çš„æ”»å‡»é¢ï¼šæœ‰ç›®æ ‡åé—¨ä»¥æœ€å°çš„ä¸­æ¯’æˆåŠŸï¼Œåœ¨è§¦å‘å™¨è®¾è®¡çš„å˜åŒ–ä¸­ä¿æŒé²æ£’æ€§ï¼Œå¹¶ä¸”ä»…å› å¾®è°ƒå’Œæ¨ç†è§¦å‘å™¨ä¹‹é—´çš„ä½ç½®ä¸åŒ¹é…è€Œé™ä½ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†ä¸€ç§æ½œåœ¨çš„åŸºäºæ£€æµ‹çš„é˜²å¾¡TabVLAçš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ä»è¾“å…¥æµé‡å»ºæ½œåœ¨çš„è§†è§‰è§¦å‘å™¨ï¼Œä»¥æ ‡è®°æ¿€æ´»æ¡ä»¶åé—¨æ ·æœ¬ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†VLAæ¨¡å‹å¯¹æœ‰ç›®æ ‡åé—¨æ“çºµçš„è„†å¼±æ€§ï¼Œå¹¶å¼ºè°ƒäº†å¯¹æ›´é«˜çº§é˜²å¾¡çš„éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³VLAæ¨¡å‹åœ¨æœ‰ç›®æ ‡åé—¨æ”»å‡»ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰çš„åé—¨æ”»å‡»æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ— ç›®æ ‡æ”»å‡»ï¼Œå³æ”»å‡»è€…åªèƒ½æ§åˆ¶æ¨¡å‹äº§ç”Ÿé”™è¯¯çš„è¡Œä¸ºï¼Œè€Œæ— æ³•æŒ‡å®šå…·ä½“çš„é”™è¯¯è¡Œä¸ºã€‚è¿™ç§æ”»å‡»çš„å¨èƒæ€§ç›¸å¯¹è¾ƒä½ï¼Œå› ä¸ºæ”»å‡»è€…æ— æ³•åˆ©ç”¨åé—¨æ¥è¾¾åˆ°ç‰¹å®šçš„ç›®çš„ã€‚æœ‰ç›®æ ‡åé—¨æ”»å‡»åˆ™å…è®¸æ”»å‡»è€…æ§åˆ¶æ¨¡å‹äº§ç”Ÿç‰¹å®šçš„é”™è¯¯è¡Œä¸ºï¼Œä¾‹å¦‚è®©æœºå™¨äººæ‰§è¡Œç‰¹å®šçš„é”™è¯¯åŠ¨ä½œï¼Œä»è€Œé€ æˆæ›´å¤§çš„å±å®³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡é»‘ç›’å¾®è°ƒçš„æ–¹å¼ï¼Œåœ¨VLAæ¨¡å‹ä¸­æ¤å…¥æœ‰ç›®æ ‡åé—¨ã€‚æ”»å‡»è€…ä¸éœ€è¦äº†è§£æ¨¡å‹çš„å†…éƒ¨ç»“æ„å’Œå‚æ•°ï¼Œåªéœ€è¦é€šè¿‡å°‘é‡ä¸­æ¯’æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå°±å¯ä»¥å®ç°å¯¹æ¨¡å‹çš„æ§åˆ¶ã€‚è¿™ç§æ”»å‡»æ–¹å¼æ›´åŠ éšè”½å’Œé«˜æ•ˆï¼Œä¹Ÿæ›´éš¾ä»¥é˜²å¾¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTabVLAæ¡†æ¶ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šä¸­æ¯’æ•°æ®ç”Ÿæˆé˜¶æ®µå’Œæ¨¡å‹å¾®è°ƒé˜¶æ®µã€‚åœ¨ä¸­æ¯’æ•°æ®ç”Ÿæˆé˜¶æ®µï¼Œæ”»å‡»è€…éœ€è¦è®¾è®¡ç‰¹å®šçš„è§¦å‘å™¨å’Œç›®æ ‡è¡Œä¸ºï¼Œå¹¶ç”ŸæˆåŒ…å«è§¦å‘å™¨å’Œç›®æ ‡è¡Œä¸ºçš„ä¸­æ¯’æ•°æ®ã€‚åœ¨æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œæ”»å‡»è€…ä½¿ç”¨ä¸­æ¯’æ•°æ®å¯¹VLAæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿æ¨¡å‹åœ¨æ£€æµ‹åˆ°è§¦å‘å™¨æ—¶äº§ç”Ÿç›®æ ‡è¡Œä¸ºã€‚è®ºæ–‡è€ƒè™‘äº†ä¸¤ç§æ¨ç†æ—¶å¨èƒæ¨¡å‹ï¼šè¾“å…¥æµç¼–è¾‘å’Œåœºæ™¯å†…è§¦å‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šTabVLAçš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æœ‰ç›®æ ‡åé—¨æ”»å‡»æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥é€šè¿‡é»‘ç›’å¾®è°ƒçš„æ–¹å¼ï¼Œåœ¨VLAæ¨¡å‹ä¸­æ¤å…¥æœ‰ç›®æ ‡åé—¨ã€‚ä¸ç°æœ‰çš„æ— ç›®æ ‡åé—¨æ”»å‡»æ–¹æ³•ç›¸æ¯”ï¼ŒTabVLAå¯ä»¥å®ç°å¯¹æ¨¡å‹çš„æ›´ç²¾ç¡®æ§åˆ¶ï¼Œä»è€Œé€ æˆæ›´å¤§çš„å±å®³ã€‚æ­¤å¤–ï¼ŒTabVLAè¿˜æå‡ºäº†ä¸€ç§æ–°çš„ä¸­æ¯’æ•°æ®ç”Ÿæˆæ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°æé«˜æ”»å‡»çš„æˆåŠŸç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡å°†ä¸­æ¯’æ•°æ®ç”Ÿæˆå…¬å¼åŒ–ä¸ºä¸€ä¸ªä¼˜åŒ–é—®é¢˜ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–æ”»å‡»çš„æˆåŠŸç‡ã€‚æ”»å‡»è€…éœ€è¦è®¾è®¡ç‰¹å®šçš„è§¦å‘å™¨å’Œç›®æ ‡è¡Œä¸ºï¼Œå¹¶ç”ŸæˆåŒ…å«è§¦å‘å™¨å’Œç›®æ ‡è¡Œä¸ºçš„ä¸­æ¯’æ•°æ®ã€‚è§¦å‘å™¨å¯ä»¥æ˜¯å›¾åƒä¸­çš„ç‰¹å®šç‰©ä½“æˆ–æ¨¡å¼ï¼Œç›®æ ‡è¡Œä¸ºå¯ä»¥æ˜¯æœºå™¨äººæ‰§è¡Œçš„ç‰¹å®šåŠ¨ä½œã€‚è®ºæ–‡è¿˜ç ”ç©¶äº†ä¸åŒçš„è§¦å‘å™¨è®¾è®¡å’Œä½ç½®å¯¹æ”»å‡»æ•ˆæœçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTabVLAæ¡†æ¶èƒ½å¤ŸæˆåŠŸåœ°åœ¨OpenVLA-7Bæ¨¡å‹ä¸­æ¤å…¥æœ‰ç›®æ ‡åé—¨ï¼Œå¹¶ä¸”åªéœ€è¦å°‘é‡ä¸­æ¯’æ•°æ®å³å¯å®ç°ã€‚æ”»å‡»åœ¨è§¦å‘å™¨è®¾è®¡å˜åŒ–æ—¶ä¿æŒé²æ£’æ€§ï¼Œä½†å¯¹è§¦å‘å™¨ä½ç½®çš„æ•æ„Ÿæ€§è¾ƒé«˜ã€‚ç ”ç©¶è¿˜åˆæ­¥æ¢ç´¢äº†ä¸€ç§åŸºäºæ£€æµ‹çš„é˜²å¾¡æ–¹æ³•ï¼Œé€šè¿‡é‡å»ºæ½œåœ¨çš„è§†è§‰è§¦å‘å™¨æ¥è¯†åˆ«åé—¨æ ·æœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè¯„ä¼°å’Œæå‡å…·èº«æ™ºèƒ½ç³»ç»Ÿçš„å®‰å…¨æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ç­‰å…³é”®é¢†åŸŸã€‚é€šè¿‡æ¨¡æ‹Ÿå’Œåˆ†ææœ‰ç›®æ ‡åé—¨æ”»å‡»ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…å‘ç°VLAæ¨¡å‹ä¸­çš„æ½œåœ¨æ¼æ´ï¼Œå¹¶å¼€å‘æ›´æœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ï¼Œä»è€Œç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œé¿å…æ¶æ„æ“çºµå¸¦æ¥çš„æ½œåœ¨é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the growing deployment of Vision-Language-Action (VLA) models in real-world embodied AI systems, their increasing vulnerability to backdoor attacks poses a serious safety threat. A backdoored VLA agent can be covertly triggered by a pre-injected backdoor to execute adversarial actions, potentially causing system failures or even physical harm. Although backdoor attacks on VLA models have been explored, prior work has focused only on untargeted attacks, leaving the more practically threatening scenario of targeted manipulation unexamined. In this paper, we study targeted backdoor attacks on VLA models and introduce TabVLA, a novel framework that enables such attacks via black-box fine-tuning. TabVLA explores two deployment-relevant inference-time threat models: input-stream editing and in-scene triggering. It formulates poisoned data generation as an optimization problem to improve attack effectivess. Experiments with OpenVLA-7B on the LIBERO benchmark reveal that the vision channel is the principal attack surface: targeted backdoors succeed with minimal poisoning, remain robust across variations in trigger design, and are degraded only by positional mismatches between fine-tuning and inference triggers. We also investigate a potential detection-based defense against TabVLA, which reconstructs latent visual triggers from the input stream to flag activation-conditioned backdoor samples. Our work highlights the vulnerability of VLA models to targeted backdoor manipulation and underscores the need for more advanced defenses.

