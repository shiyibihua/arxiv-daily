---
layout: default
title: TaoSR1: The Thinking Model for E-commerce Relevance Search
---

# TaoSR1: The Thinking Model for E-commerce Relevance Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12365" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12365v3</a>
  <a href="https://arxiv.org/pdf/2508.12365.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12365v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12365v3', 'TaoSR1: The Thinking Model for E-commerce Relevance Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenhe Dong, Shaowei Yao, Pengkun Jiao, Jianhui Yang, Yiming Jin, Zerui Huang, Xiaojiang Zhou, Dan Ou, Haihong Tang, Bo Zheng

**åˆ†ç±»**: cs.IR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17 (æ›´æ–°: 2025-12-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTaoSR1ä»¥è§£å†³ç”µå•†ç›¸å…³æ€§æœç´¢ä¸­çš„æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç”µå•†æœç´¢` `æŸ¥è¯¢ç›¸å…³æ€§` `æ¨ç†èƒ½åŠ›` `é“¾å¼æ€ç»´` `åŠ¨æ€é‡‡æ ·` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç”Ÿæˆè´¨é‡` `åˆ¤åˆ«æ€§å¹»è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºBERTçš„æ¨¡å‹åœ¨ç”µå•†æœç´¢ä¸­ç¼ºä¹å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æŸ¥è¯¢ä¸äº§å“çš„ç›¸å…³æ€§é¢„æµ‹æ•ˆæœä¸ä½³ã€‚
2. è®ºæ–‡æå‡ºçš„TaoSR1æ¡†æ¶é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’ŒåŠ¨æ€é‡‡æ ·ç­–ç•¥ï¼Œå¢å¼ºäº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œç”Ÿæˆè´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTaoSR1åœ¨ç¦»çº¿æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œå¹¶åœ¨åœ¨çº¿è¯„ä¼°ä¸­è·å¾—äº†æ˜¾è‘—çš„ç”¨æˆ·æ»¡æ„åº¦æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŸ¥è¯¢ä¸äº§å“ç›¸å…³æ€§é¢„æµ‹æ˜¯ç”µå•†æœç´¢ä¸­çš„æ ¸å¿ƒä»»åŠ¡ã€‚å°½ç®¡åŸºäºBERTçš„æ¨¡å‹åœ¨è¯­ä¹‰åŒ¹é…ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å¤æ‚æ¨ç†èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¢«æ¢ç´¢ï¼Œä½†å¤§å¤šæ•°ä»é‡‡ç”¨åˆ¤åˆ«æ€§å¾®è°ƒæˆ–è’¸é¦ä¸ºå°æ¨¡å‹è¿›è¡Œéƒ¨ç½²ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œç›´æ¥å°†LLMsåº”ç”¨äºæ­¤ä»»åŠ¡ï¼Œè§£å†³äº†é“¾å¼æ€ç»´ï¼ˆCoTï¼‰é”™è¯¯ç´¯ç§¯ã€åˆ¤åˆ«æ€§å¹»è§‰å’Œéƒ¨ç½²å¯è¡Œæ€§ç­‰å…³é”®æŒ‘æˆ˜ã€‚TaoSR1æ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨CoTè¿›è¡Œç›‘ç£å¾®è°ƒï¼Œä»¥å¢å¼ºæ¨ç†èƒ½åŠ›ï¼›2) é‡‡ç”¨pass@Nç­–ç•¥å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¿›è¡Œç¦»çº¿é‡‡æ ·ï¼Œä»¥æé«˜ç”Ÿæˆè´¨é‡ï¼›3) åŸºäºéš¾åº¦çš„åŠ¨æ€é‡‡æ ·ä¸ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ä»¥å‡è½»åˆ¤åˆ«æ€§å¹»è§‰ã€‚æ­¤å¤–ï¼ŒåCoTå¤„ç†å’ŒåŸºäºç´¯ç§¯æ¦‚ç‡çš„åˆ†åŒºæ–¹æ³•ä½¿åœ¨çº¿éƒ¨ç½²æ›´åŠ é«˜æ•ˆã€‚TaoSR1åœ¨ç¦»çº¿æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶ŠåŸºçº¿ï¼Œå¹¶åœ¨åœ¨çº¿å¯¹æ¯”çš„äººç±»è¯„ä¼°ä¸­å–å¾—äº†æ˜¾è‘—æå‡ï¼Œæå‡ºäº†ä¸€ç§å°†CoTæ¨ç†åº”ç”¨äºç›¸å…³æ€§åˆ†ç±»çš„æ–°èŒƒå¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç”µå•†æœç´¢ä¸­æŸ¥è¯¢ä¸äº§å“ç›¸å…³æ€§é¢„æµ‹çš„æ¨ç†ä¸è¶³é—®é¢˜ã€‚ç°æœ‰çš„BERTæ¨¡å‹è™½ç„¶åœ¨è¯­ä¹‰åŒ¹é…ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤æ‚æ¨ç†å’Œç”Ÿæˆè´¨é‡ä¸Šå­˜åœ¨æ˜æ˜¾çŸ­æ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTaoSR1æ¡†æ¶é€šè¿‡å¼•å…¥é“¾å¼æ€ç»´ï¼ˆCoTï¼‰å’ŒåŠ¨æ€é‡‡æ ·ç­–ç•¥ï¼Œæ—¨åœ¨å¢å¼ºæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå‡å°‘åˆ¤åˆ«æ€§å¹»è§‰ï¼Œå¹¶æé«˜åœ¨çº¿éƒ¨ç½²çš„å¯è¡Œæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTaoSR1æ¡†æ¶åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰é˜¶æ®µï¼Œé€šè¿‡CoTå¢å¼ºæ¨ç†èƒ½åŠ›ï¼›2) ç¦»çº¿é‡‡æ ·é˜¶æ®µï¼Œé‡‡ç”¨pass@Nç­–ç•¥å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰æå‡ç”Ÿæˆè´¨é‡ï¼›3) åŠ¨æ€é‡‡æ ·é˜¶æ®µï¼Œåˆ©ç”¨ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å‡è½»åˆ¤åˆ«æ€§å¹»è§‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šTaoSR1çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†CoTæ¨ç†ç›´æ¥åº”ç”¨äºç›¸å…³æ€§åˆ†ç±»ï¼Œå¹¶é€šè¿‡åŠ¨æ€é‡‡æ ·ç­–ç•¥æœ‰æ•ˆé™ä½äº†åˆ¤åˆ«æ€§å¹»è§‰çš„å½±å“ï¼Œè¿™ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ä¼˜åŒ–CoTæ¨ç†çš„æ•ˆæœï¼Œå¹¶é€šè¿‡åCoTå¤„ç†å’ŒåŸºäºç´¯ç§¯æ¦‚ç‡çš„åˆ†åŒºæ–¹æ³•å®ç°é«˜æ•ˆçš„åœ¨çº¿éƒ¨ç½²ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒTaoSR1åœ¨ç¦»çº¿æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼Œå¹¶åœ¨åœ¨çº¿è¯„ä¼°ä¸­è·å¾—äº†ç”¨æˆ·æ»¡æ„åº¦çš„æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TaoSR1æ¡†æ¶åœ¨ç”µå•†æœç´¢å¼•æ“ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå¯ä»¥æ˜¾è‘—æå‡ç”¨æˆ·æŸ¥è¯¢ä¸äº§å“åŒ¹é…çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚å…¶åˆ›æ–°çš„æ¨ç†æœºåˆ¶å’ŒåŠ¨æ€é‡‡æ ·ç­–ç•¥ä¸ºæœªæ¥çš„ç”µå•†æ¨èç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ï¼Œå¯èƒ½ä¼šå¯¹ç”¨æˆ·ä½“éªŒå’Œé”€å”®è½¬åŒ–ç‡äº§ç”Ÿç§¯æå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Query-product relevance prediction is a core task in e-commerce search. BERT-based models excel at semantic matching but lack complex reasoning capabilities. While Large Language Models (LLMs) are explored, most still use discriminative fine-tuning or distill to smaller models for deployment. We propose a framework to directly deploy LLMs for this task, addressing key challenges: Chain-of-Thought (CoT) error accumulation, discriminative hallucination, and deployment feasibility. Our framework, TaoSR1, involves three stages: (1) Supervised Fine-Tuning (SFT) with CoT to instill reasoning; (2) Offline sampling with a pass@N strategy and Direct Preference Optimization (DPO) to improve generation quality; and (3) Difficulty-based dynamic sampling with Group Relative Policy Optimization (GRPO) to mitigate discriminative hallucination. Additionally, post-CoT processing and a cumulative probability-based partitioning method enable efficient online deployment. TaoSR1 significantly outperforms baselines on offline datasets and achieves substantial gains in online side-by-side human evaluations, introducing a novel paradigm for applying CoT reasoning to relevance classification.

