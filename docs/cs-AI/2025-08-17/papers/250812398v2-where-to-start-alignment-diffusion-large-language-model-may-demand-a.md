---
layout: default
title: Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position
---

# Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12398" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12398v2</a>
  <a href="https://arxiv.org/pdf/2508.12398.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12398v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12398v2', 'Where to Start Alignment? Diffusion Large Language Model May Demand a Distinct Position')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhixin Xie, Xurui Song, Jun Luo

**åˆ†ç±»**: cs.CR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17 (æ›´æ–°: 2025-11-26)

**å¤‡æ³¨**: Accepted for oral presentation at AAAI 2026

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸­é—´ä»¤ç‰Œå®‰å…¨å¯¹é½æ–¹æ³•ä»¥æå‡æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹` `å®‰å…¨å¯¹é½` `ä¸­é—´ä»¤ç‰Œ` `å¼ºåŒ–å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `å®‰å…¨æ€§ç ”ç©¶` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§ç ”ç©¶ä¸Šå­˜åœ¨ä¸è¶³ï¼Œç¼ºä¹é’ˆå¯¹å…¶ç‹¬ç‰¹ç”Ÿæˆç‰¹æ€§çš„å®‰å…¨å¯¹é½æ–¹æ³•ã€‚
2. æœ¬æ–‡æå‡ºä¸­é—´ä»¤ç‰Œå®‰å…¨å¯¹é½ï¼ˆMOSAï¼‰æ–¹æ³•ï¼Œä¸“æ³¨äºå¯¹é½ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸­é—´ä»¤ç‰Œï¼Œä»¥æå‡æ¨¡å‹çš„å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMOSAåœ¨å®‰å…¨æ€§è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå¹¶åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå±•ç°å‡ºæ›´é«˜çš„å®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰å› å…¶ç‹¬ç‰¹çš„è®­ç»ƒå’Œæ¨ç†æ–¹æ³•è€Œæˆä¸ºä¸€ç§ç«äº‰æ€§çš„éè‡ªå›å½’èŒƒå¼ã€‚ç„¶è€Œï¼Œç›®å‰å¯¹è¿™ä¸€æ–°æ¶æ„çš„å®‰å…¨æ€§ç ”ç©¶ä»ç„¶ç¼ºä¹ã€‚æœ¬æ–‡é¦–æ¬¡åˆ†æäº†dLLMsçš„å®‰å…¨æ€§èƒ½ï¼Œå¹¶æå‡ºäº†ä¸€ç§é’ˆå¯¹å…¶ç”Ÿæˆç‰¹æ€§çš„æ–°å‹å®‰å…¨å¯¹é½æ–¹æ³•ã€‚ç ”ç©¶å‘ç°ï¼Œé˜²å¾¡è€…åœ¨å®‰å…¨æ€§æ–¹é¢ä¸æ”»å‡»è€…ä¹‹é—´å­˜åœ¨å…³é”®çš„ä¸å¯¹ç§°æ€§ï¼Œé˜²å¾¡è€…åº”å…³æ³¨å“åº”çš„ä¸­é—´ä»¤ç‰Œï¼Œè€Œéåˆå§‹ä»¤ç‰Œã€‚åŸºäºè¿™ä¸€ä¸å¯¹ç§°æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸­é—´ä»¤ç‰Œå®‰å…¨å¯¹é½ï¼ˆMOSAï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ç›´æ¥å¯¹é½æ¨¡å‹çš„ä¸­é—´ç”Ÿæˆä¸å®‰å…¨æ‹’ç»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMOSAåœ¨å®‰å…¨æ€§è¡¨ç°ä¸Šä¼˜äºå…«ç§æ”»å‡»æ–¹æ³•ï¼Œå¹¶åœ¨ç¼–ç ã€æ•°å­¦å’Œä¸€èˆ¬æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºè‰¯å¥½çš„å®ç”¨æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰åœ¨å®‰å…¨æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆè€ƒè™‘ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸­é—´ä»¤ç‰Œçš„é‡è¦æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸­é—´ä»¤ç‰Œå®‰å…¨å¯¹é½ï¼ˆMOSAï¼‰æ–¹æ³•ï¼Œä¸“æ³¨äºå¯¹é½ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸­é—´ä»¤ç‰Œï¼Œä»¥æ­¤å¢å¼ºé˜²å¾¡è€…çš„å®‰å…¨æ€§ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ŒMOSAç›´æ¥å¯¹é½æ¨¡å‹çš„ä¸­é—´ç”Ÿæˆä¸å®‰å…¨æ‹’ç»ï¼Œåˆ©ç”¨ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸å¯¹ç§°æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMOSAæ–¹æ³•åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œè¯†åˆ«ç”Ÿæˆè¿‡ç¨‹ä¸­çš„ä¸­é—´ä»¤ç‰Œï¼›å…¶æ¬¡ï¼Œè®¾è®¡å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä»¥å¯¹é½è¿™äº›ä¸­é—´ä»¤ç‰Œï¼›æœ€åï¼Œè¯„ä¼°å¯¹é½åçš„æ¨¡å‹åœ¨å®‰å…¨æ€§å’Œå®ç”¨æ€§ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šMOSAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºè¯†åˆ«å¹¶åˆ©ç”¨é˜²å¾¡è€…ä¸æ”»å‡»è€…ä¹‹é—´çš„ç”Ÿæˆä¸å¯¹ç§°æ€§ï¼Œå¼ºè°ƒä¸­é—´ä»¤ç‰Œçš„å®‰å…¨å¯¹é½ï¼Œè€Œéä¼ ç»Ÿæ–¹æ³•å…³æ³¨çš„åˆå§‹ä»¤ç‰Œã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨MOSAä¸­ï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¥ä¼˜åŒ–ä¸­é—´ä»¤ç‰Œçš„å¯¹é½è¿‡ç¨‹ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ç¡®ä¿ç”Ÿæˆçš„å®‰å…¨æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†é€‚å½“è°ƒæ•´ä»¥æ”¯æŒä¸­é—´ä»¤ç‰Œçš„å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMOSAåœ¨å®‰å…¨æ€§è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºå…«ç§æ”»å‡»æ–¹æ³•ï¼Œå°¤å…¶åœ¨ç¼–ç ã€æ•°å­¦å’Œä¸€èˆ¬æ¨ç†ä»»åŠ¡ä¸­ï¼ŒMOSAå¯¹é½çš„dLLMå±•ç°å‡ºæ›´é«˜çš„å®‰å…¨æ€§å’Œå®ç”¨æ€§ï¼Œæå‡å¹…åº¦è¾¾åˆ°XX%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„å®‰å…¨ç”Ÿæˆä»»åŠ¡ï¼Œå¦‚å¯¹è¯ç³»ç»Ÿã€ä»£ç ç”Ÿæˆå’Œæ•°å­¦æ¨ç†ç­‰ã€‚é€šè¿‡æå‡æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼ŒMOSAæ–¹æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å‡å°‘æ½œåœ¨çš„å®‰å…¨é£é™©ï¼Œå¢å¼ºç”¨æˆ·ä¿¡ä»»ï¼Œæ¨åŠ¨AIæŠ€æœ¯çš„å®‰å…¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Diffusion Large Language Models (dLLMs) have recently emerged as a competitive non-autoregressive paradigm due to their unique training and inference approach. However, there is currently a lack of safety study on this novel architecture. In this paper, we present the first analysis of dLLMs' safety performance and propose a novel safety alignment method tailored to their unique generation characteristics. Specifically, we identify a critical asymmetry between the defender and attacker in terms of security. For the defender, we reveal that the middle tokens of the response, rather than the initial ones, are more critical to the overall safety of dLLM outputs; this seems to suggest that aligning middle tokens can be more beneficial to the defender. The attacker, on the contrary, may have limited power to manipulate middle tokens, as we find dLLMs have a strong tendency towards a sequential generation order in practice, forcing the attack to meet this distribution and diverting it from influencing the critical middle tokens. Building on this asymmetry, we introduce Middle-tOken Safety Alignment (MOSA), a novel method that directly aligns the model's middle generation with safe refusals exploiting reinforcement learning. We implement MOSA and compare its security performance against eight attack methods on two benchmarks. We also test the utility of MOSA-aligned dLLM on coding, math, and general reasoning. The results strongly prove the superiority of MOSA.

