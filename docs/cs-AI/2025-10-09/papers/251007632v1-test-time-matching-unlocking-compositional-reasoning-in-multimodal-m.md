---
layout: default
title: Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models
---

# Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.07632" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.07632v1</a>
  <a href="https://arxiv.org/pdf/2510.07632.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.07632v1" onclick="toggleFavorite(this, '2510.07632v1', 'Test-Time Matching: Unlocking Compositional Reasoning in Multimodal Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yinglun Zhu, Jiancheng Zhang, Fuzhi Tang

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-09

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæµ‹è¯•æ—¶åŒ¹é…(TTM)ç®—æ³•ï¼Œæå‡å¤šæ¨¡æ€æ¨¡å‹åœ¨ç»„åˆæ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç»„åˆæ¨ç†` `æµ‹è¯•æ—¶è‡ªé€‚åº”` `è§†è§‰è¯­è¨€æ¨¡å‹` `æ¨¡å‹è¯„ä¼°` `è‡ªç›‘ç£å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æŒ‡æ ‡ä½ä¼°äº†å¤šæ¨¡æ€æ¨¡å‹åœ¨ç»„åˆæ¨ç†ä¸Šçš„èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½è¢«é”™è¯¯è¯„ä¼°ã€‚
2. æå‡ºæµ‹è¯•æ—¶åŒ¹é…(TTM)ç®—æ³•ï¼Œé€šè¿‡è¿­ä»£ä¼˜åŒ–æ¨¡å‹åœ¨ç‰¹å®šæµ‹è¯•é›†ä¸Šçš„è¡¨ç°ï¼ŒæŒ–æ˜æ¨¡å‹æ½œåŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTTMåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œç”šè‡³è¶…è¶Šäº†GPT-4.1ç­‰å…ˆè¿›æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‰æ²¿AIæ¨¡å‹å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†æœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œå®ƒä»¬åœ¨ç»„åˆæ¨ç†æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œåœ¨å·²å»ºç«‹çš„åŸºå‡†æµ‹è¯•ä¸­é€šå¸¸è¡¨ç°å¾—ä¸éšæœºæ°´å¹³ç›¸å½“ç”šè‡³æ›´ä½ã€‚æœ¬æ–‡é‡æ–°å®¡è§†äº†è¿™ä¸ªé—®é¢˜ï¼Œå¹¶è¡¨æ˜å¹¿æ³›ä½¿ç”¨çš„è¯„ä¼°æŒ‡æ ‡ç³»ç»Ÿæ€§åœ°ä½ä¼°äº†æ¨¡å‹çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæœ¬æ–‡å¼•å…¥äº†ä¸€ç§ç»„åŒ¹é…å¾—åˆ†ï¼Œæ›´å¥½åœ°åˆ©ç”¨äº†ç»„ç»“æ„ï¼Œæ­ç¤ºäº†å¯¹æ¯”è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ä¸­å¤§é‡çš„éšè—èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç®€å•åœ°åœ¨æµ‹è¯•æ—¶è¿‡æ‹Ÿåˆåˆ°è¯±å¯¼çš„ç»„åŒ¹é…ï¼Œå°±å¯ä»¥å°†è¿™ç§éšè—çš„èƒ½åŠ›è½¬åŒ–ä¸ºæ ‡å‡†è¯„ä¼°æŒ‡æ ‡ä¸‹çš„æ›´é«˜åˆ†æ•°ï¼Œä»è€Œç¼©å°äº†æŠ¥å‘Šä¸­çš„å¤§éƒ¨åˆ†å·®è·ã€‚è¿™ç§è°ƒæ•´ä½¿SigLIP-B16è¶…è¶Šäº†æ‰€æœ‰å…ˆå‰çš„ç»“æœï¼ŒGPT-4.1åœ¨Winogroundä¸Šäº§ç”Ÿäº†ç¬¬ä¸€ä¸ªè¶…è¿‡ä¼°è®¡äººç±»æ€§èƒ½çš„ç»“æœã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æµ‹è¯•æ—¶åŒ¹é…ï¼ˆTTMï¼‰ç®—æ³•ï¼Œè¿™æ˜¯ä¸€ç§è¿­ä»£çš„ã€è‡ªæˆ‘æ”¹è¿›çš„ç®—æ³•ï¼Œå¯ä»¥åœ¨æ²¡æœ‰ä»»ä½•å¤–éƒ¨ç›‘ç£çš„æƒ…å†µä¸‹è¿›ä¸€æ­¥å¼•å¯¼æ¨¡å‹æ€§èƒ½ã€‚TTMæä¾›äº†é¢å¤–çš„ã€é‡è¦çš„æ”¹è¿›ï¼šä¾‹å¦‚ï¼ŒTTMä½¿SigLIP-B16åœ¨MMVP-VLMä¸Šè¶…è¶Šäº†GPT-4.1ï¼Œå»ºç«‹äº†ä¸€ä¸ªæ–°çš„state of the artã€‚é‡è¦çš„æ˜¯ï¼ŒTTMå³ä½¿åœ¨æ²¡æœ‰åº¦é‡è¯±å¯¼æ•ˆåº”æˆ–ç»„ç»“æ„çš„åŸºå‡†æµ‹è¯•ä¸­ä»ç„¶å¹¿æ³›æœ‰æ•ˆï¼Œåœ¨WhatsUpç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾85.7%çš„ç›¸å¯¹æ”¶ç›Šã€‚åœ¨è·¨è¶Šä¸åŒè®¾ç½®çš„16ä¸ªæ•°æ®é›†å˜ä½“ä¸­ï¼Œå®éªŒè¡¨æ˜TTMå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†æ¨¡å‹æ€§èƒ½ï¼Œå¹¶æ¨è¿›äº†ç»„åˆæ¨ç†çš„å‰æ²¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è¯„ä¼°æ–¹æ³•åœ¨è¯„ä¼°å¤šæ¨¡æ€æ¨¡å‹ç»„åˆæ¨ç†èƒ½åŠ›æ—¶å­˜åœ¨åå·®ï¼Œå¯¼è‡´æ¨¡å‹çœŸå®æ€§èƒ½è¢«ä½ä¼°ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥å……åˆ†åˆ©ç”¨æ¨¡å‹ä¸­è•´å«çš„ç»„åˆæ¨ç†èƒ½åŠ›ï¼Œåœ¨å¤æ‚åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åœ¨æµ‹è¯•é˜¶æ®µå¯¹æ¨¡å‹è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”å½“å‰æµ‹è¯•æ•°æ®çš„åˆ†å¸ƒï¼Œä»è€ŒæŒ–æ˜æ¨¡å‹ä¸­éšè—çš„ç»„åˆæ¨ç†èƒ½åŠ›ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æµ‹è¯•æ•°æ®æœ¬èº«çš„ä¿¡æ¯æ¥æå‡æ¨¡å‹æ€§èƒ½ï¼Œæ— éœ€é¢å¤–çš„è®­ç»ƒæ•°æ®æˆ–ç›‘ç£ä¿¡å·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTTMç®—æ³•æ˜¯ä¸€ä¸ªè¿­ä»£çš„ä¼˜åŒ–è¿‡ç¨‹ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š1. åˆå§‹åŒ–ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„å¤šæ¨¡æ€æ¨¡å‹ã€‚2. æ¨ç†ï¼šä½¿ç”¨å½“å‰æ¨¡å‹å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œæ¨ç†ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœã€‚3. åŒ¹é…ï¼šæ ¹æ®é¢„æµ‹ç»“æœå’Œæµ‹è¯•æ•°æ®çš„ç»„ç»“æ„ï¼Œè®¡ç®—ç»„åŒ¹é…å¾—åˆ†ã€‚4. ä¼˜åŒ–ï¼šæ ¹æ®ç»„åŒ¹é…å¾—åˆ†ï¼Œè°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿å…¶æ›´å¥½åœ°é€‚åº”å½“å‰æµ‹è¯•æ•°æ®ã€‚5. è¿­ä»£ï¼šé‡å¤æ­¥éª¤2-4ï¼Œç›´åˆ°æ¨¡å‹æ€§èƒ½æ”¶æ•›ã€‚

**å…³é”®åˆ›æ–°**ï¼šTTMç®—æ³•çš„å…³é”®åˆ›æ–°åœ¨äºå…¶æµ‹è¯•æ—¶è‡ªé€‚åº”è°ƒæ•´çš„èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿçš„ç¦»çº¿è®­ç»ƒæ–¹æ³•ä¸åŒï¼ŒTTMç®—æ³•èƒ½å¤Ÿåœ¨æµ‹è¯•é˜¶æ®µåˆ©ç”¨æµ‹è¯•æ•°æ®çš„ä¿¡æ¯æ¥ä¼˜åŒ–æ¨¡å‹ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”å½“å‰åœºæ™¯ã€‚è¿™ç§è‡ªé€‚åº”è°ƒæ•´èƒ½å¤ŸæŒ–æ˜æ¨¡å‹ä¸­éšè—çš„ç»„åˆæ¨ç†èƒ½åŠ›ï¼Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šTTMç®—æ³•çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1. ç»„åŒ¹é…å¾—åˆ†ï¼šç”¨äºè¡¡é‡æ¨¡å‹é¢„æµ‹ç»“æœä¸æµ‹è¯•æ•°æ®ç»„ç»“æ„çš„ä¸€è‡´æ€§ã€‚2. ä¼˜åŒ–ç­–ç•¥ï¼šç”¨äºæ ¹æ®ç»„åŒ¹é…å¾—åˆ†è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä¾‹å¦‚ä½¿ç”¨æ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–ç®—æ³•ã€‚3. è¿­ä»£æ¬¡æ•°ï¼šæ§åˆ¶TTMç®—æ³•çš„è¿­ä»£æ¬¡æ•°ï¼Œä»¥å¹³è¡¡æ¨¡å‹æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ã€‚å…·ä½“å‚æ•°è®¾ç½®å¯èƒ½å› æ•°æ®é›†å’Œæ¨¡å‹è€Œå¼‚ï¼Œéœ€è¦åœ¨å®éªŒä¸­è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

TTMç®—æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨MMVP-VLMæ•°æ®é›†ä¸Šï¼ŒTTMä½¿SigLIP-B16è¶…è¶Šäº†GPT-4.1ï¼Œå»ºç«‹äº†æ–°çš„state of the artã€‚åœ¨WhatsUpæ•°æ®é›†ä¸Šï¼ŒTTMå®ç°äº†é«˜è¾¾85.7%çš„ç›¸å¯¹æ”¶ç›Šã€‚æ­¤å¤–ï¼ŒTTMè¿˜ä½¿GPT-4.1åœ¨Winogroundä¸Šäº§ç”Ÿäº†ç¬¬ä¸€ä¸ªè¶…è¿‡ä¼°è®¡äººç±»æ€§èƒ½çš„ç»“æœã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒTTMç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆæå‡å¤šæ¨¡æ€æ¨¡å‹åœ¨ç»„åˆæ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ç»„åˆæ¨ç†èƒ½åŠ›çš„å¤šæ¨¡æ€ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒæè¿°ç”Ÿæˆã€è§†è§‰é—®ç­”ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡TTMç®—æ³•ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨å¤æ‚åœºæ™¯ä¸‹çš„ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œä»è€Œæé«˜ç›¸å…³åº”ç”¨çš„æ€§èƒ½å’Œå¯é æ€§ã€‚è¯¥æ–¹æ³•å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™æˆ–æ— æ³•è·å–å¤§é‡è®­ç»ƒæ•°æ®çš„åœºæ™¯ä¸‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Frontier AI models have achieved remarkable progress, yet recent studies suggest they struggle with compositional reasoning, often performing at or below random chance on established benchmarks. We revisit this problem and show that widely used evaluation metrics systematically underestimate model capability. To address this, we introduce a group matching score that better exploits group structure and reveals substantial hidden capability in both contrastive vision-language models (VLMs) and multimodal large language models (MLLMs). Moreover, simply overfitting to the induced group matchings at test time transfers this hidden capability into higher scores under standard evaluation metrics, closing much of the reported gap. This adjustment enables SigLIP-B16 to surpass all previous results and GPT-4.1 to yield the first result surpassing estimated human performance on Winoground.
>   Building on this insight, we propose Test-Time Matching (TTM), an iterative, self-improving algorithm that further bootstraps model performance without any external supervision. TTM delivers additional, non-trivial improvements: for example, TTM enables SigLIP-B16 to surpass GPT-4.1 on MMVP-VLM, establishing a new state of the art. Importantly, TTM remains broadly effective even on benchmarks without metric-induced effects or group structures, achieving relative gains up to 85.7% on challenging datasets such as WhatsUp. Across 16 dataset variants spanning diverse setups, our experiments demonstrate that TTM consistently improves model performance and advances the frontier of compositional reasoning.

