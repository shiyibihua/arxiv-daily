---
layout: default
title: VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning
---

# VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09049" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09049v2</a>
  <a href="https://arxiv.org/pdf/2506.09049.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09049v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09049v2', 'VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Li Kang, Xiufeng Song, Heng Zhou, Yiran Qin, Jie Yang, Xiaohong Liu, Philip Torr, Lei Bai, Zhenfei Yin

**åˆ†ç±»**: cs.AI, cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-10-21)

**å¤‡æ³¨**: Project page: https://faceong.github.io/VIKI-R/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVIKI-Rä»¥è§£å†³å¤šæ™ºèƒ½ä½“åˆä½œä¸­çš„è§†è§‰æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“åˆä½œ` `è§†è§‰æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `æœºå™¨äººæŠ€æœ¯` `åŠ¨æ€ç¯å¢ƒ` `åˆ†å±‚åŸºå‡†` `ç»„åˆåˆä½œæ¨¡å¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­åè°ƒå¤šæ™ºèƒ½ä½“æ—¶é¢ä¸´æ„ŸçŸ¥å’Œåˆä½œç­–ç•¥çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯è§†è§‰æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. æœ¬ç ”ç©¶æå‡ºVIKI-Benchå’ŒVIKI-Rï¼Œé€šè¿‡åˆ†å±‚åŸºå‡†å’Œå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæå‡å¤šæ™ºèƒ½ä½“çš„è§†è§‰é©±åŠ¨åˆä½œèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVIKI-Råœ¨å„ä»»åŠ¡å±‚çº§ä¸Šå‡æ˜¾è‘—è¶…è¶ŠåŸºçº¿æ–¹æ³•ï¼Œå¼ºåŒ–å­¦ä¹ ä¿ƒè¿›äº†æ™ºèƒ½ä½“é—´çš„æœ‰æ•ˆåˆä½œæ¨¡å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åŠ¨æ€ç¯å¢ƒä¸­åè°ƒå¤šä¸ªå…·èº«æ™ºèƒ½ä½“ä»ç„¶æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œè¦æ±‚å…·å¤‡æ„ŸçŸ¥é©±åŠ¨çš„æ¨ç†èƒ½åŠ›å’Œå¯æ‰©å±•çš„åˆä½œç­–ç•¥ã€‚å°½ç®¡è¿‘æœŸç ”ç©¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå¤šæ™ºèƒ½ä½“è§„åˆ’ï¼Œä½†åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„ç ”ç©¶ä»ç„¶æœ‰é™ã€‚æœ¬ç ”ç©¶æå‡ºäº†VIKI-Benchï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹å…·èº«å¤šæ™ºèƒ½ä½“åˆä½œçš„åˆ†å±‚åŸºå‡†ï¼ŒåŒ…å«æ™ºèƒ½ä½“æ¿€æ´»ã€ä»»åŠ¡è§„åˆ’å’Œè½¨è¿¹æ„ŸçŸ¥ä¸‰ä¸ªç»“æ„åŒ–å±‚çº§ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†VIKI-Rï¼Œä¸€ä¸ªä¸¤é˜¶æ®µæ¡†æ¶ï¼Œé€šè¿‡Chain-of-Thoughtæ³¨é‡Šç¤ºä¾‹å¾®è°ƒé¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨å¤šå±‚æ¬¡å¥–åŠ±ä¿¡å·ä¸‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVIKI-Råœ¨æ‰€æœ‰ä»»åŠ¡å±‚çº§ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¼ºåŒ–å­¦ä¹ ä¿ƒè¿›äº†å¼‚æ„æ™ºèƒ½ä½“ä¹‹é—´çš„ç»„åˆåˆä½œæ¨¡å¼çš„å‡ºç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨åŠ¨æ€ç¯å¢ƒä¸­åè°ƒå¤šä¸ªå…·èº«æ™ºèƒ½ä½“çš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è§†è§‰æ¨ç†å’Œåˆä½œç­–ç•¥ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æ”¯æŒå¤šæ ·åŒ–çš„å…·èº«ç±»å‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºVIKI-Benchä½œä¸ºåˆ†å±‚åŸºå‡†ï¼Œç»“åˆVIKI-Ræ¡†æ¶ï¼Œé€šè¿‡å¾®è°ƒè§†è§‰è¯­è¨€æ¨¡å‹å¹¶åº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œå¢å¼ºæ™ºèƒ½ä½“çš„åˆä½œèƒ½åŠ›å’Œè§†è§‰æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVIKI-Ræ¡†æ¶åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯å¾®è°ƒé¢„è®­ç»ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯åœ¨å¤šå±‚æ¬¡å¥–åŠ±ä¿¡å·ä¸‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚VIKI-Benchæä¾›äº†å¤šæ ·åŒ–çš„æœºå™¨äººå…·èº«ã€è§†è§‰è§‚å¯Ÿå’Œç›‘ç£ä¿¡å·ã€‚

**å…³é”®åˆ›æ–°**ï¼šVIKI-Benchæ˜¯é¦–ä¸ªä¸“ä¸ºå…·èº«å¤šæ™ºèƒ½ä½“åˆä½œè®¾è®¡çš„åˆ†å±‚åŸºå‡†ï¼ŒVIKI-Ré€šè¿‡å¼ºåŒ–å­¦ä¹ ä¿ƒè¿›äº†å¼‚æ„æ™ºèƒ½ä½“ä¹‹é—´çš„ç»„åˆåˆä½œæ¨¡å¼ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—çš„åˆ›æ–°æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VIKI-Rä¸­ï¼Œä½¿ç”¨Chain-of-Thoughtæ³¨é‡Šç¤ºä¾‹è¿›è¡Œå¾®è°ƒï¼Œå¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­é‡‡ç”¨å¤šå±‚æ¬¡å¥–åŠ±ä¿¡å·ï¼Œç¡®ä¿æ™ºèƒ½ä½“åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆåˆä½œã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVIKI-Råœ¨æ‰€æœ‰ä»»åŠ¡å±‚çº§ä¸Šå‡æ˜¾è‘—è¶…è¶ŠåŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå¼ºåŒ–å­¦ä¹ çš„åº”ç”¨ä¿ƒè¿›äº†å¼‚æ„æ™ºèƒ½ä½“ä¹‹é—´çš„æœ‰æ•ˆåˆä½œæ¨¡å¼çš„å½¢æˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ— äººæœºç¼–é˜Ÿç­‰ï¼Œèƒ½å¤Ÿæå‡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„åä½œèƒ½åŠ›ã€‚æœªæ¥ï¼ŒVIKI-Benchå’ŒVIKI-Rå¯èƒ½æˆä¸ºå…·èº«äººå·¥æ™ºèƒ½é¢†åŸŸçš„æ ‡å‡†å·¥å…·ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Coordinating multiple embodied agents in dynamic environments remains a core challenge in artificial intelligence, requiring both perception-driven reasoning and scalable cooperation strategies. While recent works have leveraged large language models (LLMs) for multi-agent planning, a few have begun to explore vision-language models (VLMs) for visual reasoning. However, these VLM-based approaches remain limited in their support for diverse embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical benchmark tailored for embodied multi-agent cooperation, featuring three structured levels: agent activation, task planning, and trajectory perception. VIKI-Bench includes diverse robot embodiments, multi-view visual observations, and structured supervision signals to evaluate reasoning grounded in visual inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a two-stage framework that fine-tunes a pretrained vision-language model (VLM) using Chain-of-Thought annotated demonstrations, followed by reinforcement learning under multi-level reward signals. Our extensive experiments show that VIKI-R significantly outperforms baselines method across all task levels. Furthermore, we show that reinforcement learning enables the emergence of compositional cooperation patterns among heterogeneous agents. Together, VIKI-Bench and VIKI-R offer a unified testbed and method for advancing multi-agent, visual-driven cooperation in embodied AI systems.

