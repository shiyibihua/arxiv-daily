---
layout: default
title: Error Detection and Correction for Interpretable Mathematics in Large Language Models
---

# Error Detection and Correction for Interpretable Mathematics in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03500" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03500v1</a>
  <a href="https://arxiv.org/pdf/2508.03500.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03500v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03500v1', 'Error Detection and Correction for Interpretable Mathematics in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yijin Yang, Cristina Cornelio, Mario Leiva, Paulo Shakarian

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEDCIMä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†ä¸­çš„é”™è¯¯æ£€æµ‹ä¸ä¿®æ­£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é”™è¯¯æ£€æµ‹` `æ•°å­¦æ¨ç†` `å¯è§£é‡Šæ€§` `ç¬¦å·æ£€æµ‹` `æˆæœ¬ä¼˜åŒ–` `é¢„æµ‹å‡†ç¡®æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šæ­¥éª¤æ¨ç†ä¸­å­˜åœ¨ä¸­é—´æ­¥éª¤é”™è¯¯ï¼Œå¯¼è‡´æœ€ç»ˆç»“æœä¸å‡†ç¡®ã€‚
2. EDCIMæ–¹æ³•é€šè¿‡ç”Ÿæˆæ–¹ç¨‹ç»„å¹¶ä½¿ç”¨ç¬¦å·é”™è¯¯æ£€æµ‹æ¡†æ¶æ¥è¯†åˆ«å’Œä¿®æ­£é”™è¯¯ï¼Œæå‡å¯è§£é‡Šæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEDCIMåœ¨é™ä½æˆæœ¬çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¡¨ç°ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ­¥éª¤æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶ç”Ÿæˆçš„ä¸­é—´æ­¥éª¤å¸¸å¸¸åŒ…å«é”™è¯¯ï¼Œå¯¼è‡´æœ€ç»ˆé¢„æµ‹ä¸å‡†ç¡®ã€‚æ­¤å¤–ï¼ŒLLMsåœ¨ç”Ÿæˆæ•°å­¦è¡¨è¾¾å¼æˆ–æºä»£ç æ—¶ä»é¢ä¸´å¹»è§‰é—®é¢˜ï¼Œä¸”éš¾ä»¥éµå¾ªè§„å®šçš„è¾“å‡ºæ ¼å¼ã€‚æœ¬æ–‡æå‡ºäº†EDCIMï¼ˆå¯è§£é‡Šæ•°å­¦ä¸­çš„é”™è¯¯æ£€æµ‹ä¸ä¿®æ­£ï¼‰ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨æ£€æµ‹å’Œä¿®æ­£å¯è§£é‡Šæ•°å­¦ä»»åŠ¡ä¸­çš„é”™è¯¯ã€‚EDCIMåˆ©ç”¨LLMsç”Ÿæˆæ–¹ç¨‹ç»„ï¼Œå¹¶é€šè¿‡ç¬¦å·é”™è¯¯æ£€æµ‹æ¡†æ¶è¯†åˆ«é”™è¯¯ï¼Œæä¾›é’ˆå¯¹æ€§çš„åé¦ˆä»¥è¿›è¡Œä¿®æ­£ã€‚è¯¥æ–¹æ³•ç»“åˆè½»é‡çº§å¼€æºLLMsä¸æ›´å¼ºå¤§çš„ä¸“æœ‰æ¨¡å‹ï¼Œä»¥ä¼˜åŒ–æ•ˆç‡ï¼Œç”¨æˆ·å¯é€šè¿‡å•ä¸€è¶…å‚æ•°æ§åˆ¶æˆæœ¬ä¸å‡†ç¡®æ€§çš„å¹³è¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEDCIMåœ¨ä¸åŒæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œè´¢åŠ¡æˆæœ¬ï¼ŒåŒæ—¶åœ¨é€‚å½“é…ç½®ä¸‹æé«˜äº†é¢„æµ‹å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¯è§£é‡Šæ•°å­¦ä»»åŠ¡ä¸­ç”Ÿæˆé”™è¯¯çš„ä¸­é—´æ­¥éª¤é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¸¸å¸¸å¯¼è‡´æœ€ç»ˆé¢„æµ‹ä¸å‡†ç¡®ï¼Œä¸”éš¾ä»¥éµå¾ªè¾“å‡ºæ ¼å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEDCIMé€šè¿‡ç”Ÿæˆæ–¹ç¨‹ç»„å¹¶ç»“åˆç¬¦å·é”™è¯¯æ£€æµ‹æ¡†æ¶ï¼Œè¯†åˆ«å¹¶ä¿®æ­£é”™è¯¯ï¼Œç¡®ä¿æ¨¡å‹ç”Ÿæˆçš„æ•°å­¦è¡¨è¾¾å¼å‡†ç¡®ä¸”å¯è§£é‡Šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨LLMsç”Ÿæˆä¸é—®é¢˜å¯¹åº”çš„æ–¹ç¨‹ç»„ï¼›å…¶æ¬¡ï¼Œåº”ç”¨ç¬¦å·é”™è¯¯æ£€æµ‹æ¡†æ¶è¯†åˆ«é”™è¯¯å¹¶æä¾›åé¦ˆï¼Œæœ€ç»ˆå®ç°ä¿®æ­£ã€‚

**å…³é”®åˆ›æ–°**ï¼šEDCIMçš„ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆè½»é‡çº§å¼€æºLLMsä¸å¼ºå¤§çš„ä¸“æœ‰æ¨¡å‹ï¼Œé€šè¿‡å•ä¸€è¶…å‚æ•°æ§åˆ¶æˆæœ¬ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å¹³è¡¡ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒEDCIMé‡‡ç”¨äº†ç¬¦å·é”™è¯¯æ£€æµ‹æœºåˆ¶ï¼Œå¹¶é€šè¿‡è¶…å‚æ•°è°ƒèŠ‚å®ç°äº†æˆæœ¬ä¸å‡†ç¡®æ€§çš„çµæ´»å¹³è¡¡ï¼Œç¡®ä¿åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEDCIMåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†è®¡ç®—å’Œè´¢åŠ¡æˆæœ¬ï¼Œå‡†ç¡®æ€§åœ¨é€‚å½“é…ç½®ä¸‹æé«˜äº†10%ä»¥ä¸Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EDCIMçš„ç ”ç©¶æˆæœåœ¨æ•™è‚²ã€ç§‘å­¦è®¡ç®—å’Œè½¯ä»¶å¼€å‘ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨æ¨¡å‹ç”Ÿæˆçš„ç»“æœï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›æ­¥ä¸åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent large language models (LLMs) have demonstrated the ability to perform explicit multi-step reasoning such as chain-of-thought prompting. However, their intermediate steps often contain errors that can propagate leading to inaccurate final predictions. Additionally, LLMs still struggle with hallucinations and often fail to adhere to prescribed output formats, which is particularly problematic for tasks like generating mathematical expressions or source code. This work introduces EDCIM (Error Detection and Correction for Interpretable Mathematics), a method for detecting and correcting these errors in interpretable mathematics tasks, where the model must generate the exact functional form that explicitly solve the problem (expressed in natural language) rather than a black-box solution. EDCIM uses LLMs to generate a system of equations for a given problem, followed by a symbolic error-detection framework that identifies errors and provides targeted feedback for LLM-based correction. To optimize efficiency, EDCIM integrates lightweight, open-source LLMs with more powerful proprietary models, balancing cost and accuracy. This balance is controlled by a single hyperparameter, allowing users to control the trade-off based on their cost and accuracy requirements. Experimental results across different datasets show that EDCIM significantly reduces both computational and financial costs, while maintaining, and even improving, prediction accuracy when the balance is properly configured.

