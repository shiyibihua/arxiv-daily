---
layout: default
title: Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?
---

# Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03963" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03963v3</a>
  <a href="https://arxiv.org/pdf/2508.03963.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03963v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03963v3', 'Can Large Language Models Adequately Perform Symbolic Reasoning Over Time Series?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zewen Liu, Juntong Ni, Xianfeng Tang, Max S. Y. Lau, Wenpeng Yin, Wei Jin

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-10-21)

**å¤‡æ³¨**: version2

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSymbolBenchåŸºå‡†ä»¥è¯„ä¼°æ—¶é—´åºåˆ—çš„ç¬¦å·æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¬¦å·æ¨ç†` `æ—¶é—´åºåˆ—` `å¤§å‹è¯­è¨€æ¨¡å‹` `é—ä¼ ç¼–ç¨‹` `ç§‘å­¦å‘ç°` `åŸºå‡†è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æå–ç¬¦å·ç»“æ„æ—¶ç¼ºä¹ç³»ç»Ÿæ€§è¯„ä¼°ï¼Œä¸”é€šå¸¸ä»…é™äºç®€å•çš„ä»£æ•°æ–¹ç¨‹ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºSymbolBenchåŸºå‡†ï¼Œæ¶µç›–å¤šç§å¤æ‚ç¬¦å·å½¢å¼ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹ä¸é—ä¼ ç¼–ç¨‹å½¢æˆé—­ç¯æ¨ç†ç³»ç»Ÿã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®è¯ç»“æœæ˜¾ç¤ºå½“å‰æ¨¡å‹åœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿ä¸å±€é™ï¼Œå¼ºè°ƒç»“åˆé¢†åŸŸçŸ¥è¯†çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æ­ç¤ºéšè—çš„ç¬¦å·æ³•åˆ™ï¼Œä¸€ç›´ä»¥æ¥æ˜¯ç§‘å­¦å‘ç°å’Œäººå·¥æ™ºèƒ½é¢†åŸŸçš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»“æ„åŒ–æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬ä»æ—¶é—´åºåˆ—æ•°æ®ä¸­æ¨æ–­å¯è§£é‡Šçš„ã€ä¸ä¸Šä¸‹æ–‡å¯¹é½çš„ç¬¦å·ç»“æ„çš„èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚ä¸ºç³»ç»Ÿè¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæœ¬æ–‡å¼•å…¥äº†SymbolBenchï¼Œä¸€ä¸ªå…¨é¢çš„åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°åœ¨å¤šå˜é‡ç¬¦å·å›å½’ã€å¸ƒå°”ç½‘ç»œæ¨æ–­å’Œå› æœå‘ç°ç­‰ä¸‰é¡¹ä»»åŠ¡ä¸Šçš„ç¬¦å·æ¨ç†èƒ½åŠ›ã€‚ä¸ä»¥å¾€ä»…é™äºç®€å•ä»£æ•°æ–¹ç¨‹çš„åŠªåŠ›ä¸åŒï¼ŒSymbolBenchæ¶µç›–äº†å¤šç§å¤æ‚åº¦çš„ç¬¦å·å½¢å¼ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸é—ä¼ ç¼–ç¨‹ç»“åˆï¼Œå½¢æˆä¸€ä¸ªé—­ç¯ç¬¦å·æ¨ç†ç³»ç»Ÿï¼Œå…¶ä¸­å¤§å‹è¯­è¨€æ¨¡å‹æ—¢ä½œä¸ºé¢„æµ‹è€…åˆä½œä¸ºè¯„ä¼°è€…ã€‚å®è¯ç»“æœæ­ç¤ºäº†å½“å‰æ¨¡å‹çš„å…³é”®ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œå¼ºè°ƒäº†ç»“åˆé¢†åŸŸçŸ¥è¯†ã€ä¸Šä¸‹æ–‡å¯¹é½å’Œæ¨ç†ç»“æ„çš„é‡è¦æ€§ï¼Œä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªåŠ¨åŒ–ç§‘å­¦å‘ç°ä¸­çš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ—¶é—´åºåˆ—æ•°æ®ä¸­è¿›è¡Œç¬¦å·æ¨ç†çš„èƒ½åŠ›ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºç®€å•çš„ä»£æ•°æ–¹ç¨‹ï¼Œç¼ºä¹å¯¹å¤æ‚ç¬¦å·ç»“æ„çš„è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥SymbolBenchåŸºå‡†ï¼Œç³»ç»Ÿè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šå˜é‡ç¬¦å·å›å½’ã€å¸ƒå°”ç½‘ç»œæ¨æ–­å’Œå› æœå‘ç°ç­‰ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå¹¶ç»“åˆé—ä¼ ç¼–ç¨‹å½¢æˆé—­ç¯æ¨ç†ç³»ç»Ÿï¼Œä»¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) SymbolBenchåŸºå‡†ï¼Œæä¾›å¤šæ ·åŒ–çš„ç¬¦å·æ¨ç†ä»»åŠ¡ï¼›2) å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä½œä¸ºé¢„æµ‹è€…å’Œè¯„ä¼°è€…ï¼›3) é—ä¼ ç¼–ç¨‹ï¼Œä¼˜åŒ–ç¬¦å·ç»“æ„çš„ç”Ÿæˆä¸è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸é—ä¼ ç¼–ç¨‹ç»“åˆï¼Œå½¢æˆé—­ç¯æ¨ç†ç³»ç»Ÿï¼Œä½¿å¾—æ¨¡å‹ä¸ä»…èƒ½å¤Ÿç”Ÿæˆç¬¦å·ç»“æ„ï¼Œè¿˜èƒ½è¿›è¡Œæœ‰æ•ˆè¯„ä¼°ï¼Œçªç ´äº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç¬¦å·ç»“æ„çš„å‡†ç¡®æ€§ï¼Œå¹¶é€šè¿‡ä¸Šä¸‹æ–‡å¯¹é½æŠ€æœ¯æå‡æ¨¡å‹çš„æ¨ç†æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆé¢†åŸŸçŸ¥è¯†å’Œä¸Šä¸‹æ–‡å¯¹é½çš„æ¨¡å‹åœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜è¶Šï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œæ¨ç†å‡†ç¡®ç‡æå‡äº†20%ä»¥ä¸Šï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨è‡ªåŠ¨åŒ–ç§‘å­¦å‘ç°ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç§‘å­¦å‘ç°ã€é‡‘èå¸‚åœºåˆ†æå’ŒåŒ»ç–—æ•°æ®è§£è¯»ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç¬¦å·æ¨ç†æ–¹é¢çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ä»å¤æ‚æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Uncovering hidden symbolic laws from time series data, as an aspiration dating back to Kepler's discovery of planetary motion, remains a core challenge in scientific discovery and artificial intelligence. While Large Language Models show promise in structured reasoning tasks, their ability to infer interpretable, context-aligned symbolic structures from time series data is still underexplored. To systematically evaluate this capability, we introduce SymbolBench, a comprehensive benchmark designed to assess symbolic reasoning over real-world time series across three tasks: multivariate symbolic regression, Boolean network inference, and causal discovery. Unlike prior efforts limited to simple algebraic equations, SymbolBench spans a diverse set of symbolic forms with varying complexity. We further propose a unified framework that integrates LLMs with genetic programming to form a closed-loop symbolic reasoning system, where LLMs act both as predictors and evaluators. Our empirical results reveal key strengths and limitations of current models, highlighting the importance of combining domain knowledge, context alignment, and reasoning structure to improve LLMs in automated scientific discovery.

