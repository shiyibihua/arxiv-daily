---
layout: default
title: Compressing Chain-of-Thought in LLMs via Step Entropy
---

# Compressing Chain-of-Thought in LLMs via Step Entropy

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03346" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03346v1</a>
  <a href="https://arxiv.org/pdf/2508.03346.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03346v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03346v1', 'Compressing Chain-of-Thought in LLMs via Step Entropy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeju Li, Jianyuan Zhong, Ziyang Zheng, Xiangyu Wen, Zhijian Xu, Yingying Cheng, Fan Zhang, Qiang Xu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ­¥éª¤ç†µçš„é“¾å¼æ€ç»´å‹ç¼©æ–¹æ³•ä»¥æé«˜LLMæ¨ç†æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é“¾å¼æ€ç»´` `æ­¥éª¤ç†µ` `æ¨ç†æ•ˆç‡` `æ¨¡å‹å‹ç¼©` `å¼ºåŒ–å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é“¾å¼æ€ç»´æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿå¤§é‡å†—ä½™æ­¥éª¤ï¼Œå¯¼è‡´æ¨ç†æ•ˆç‡ä½ä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ­¥éª¤ç†µçš„å‹ç¼©æ¡†æ¶ï¼Œé€šè¿‡è¯†åˆ«ä½ç†µæ­¥éª¤æ¥å‡å°‘å†—ä½™ï¼Œä¼˜åŒ–æ¨ç†è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œ80%çš„ä½ç†µæ­¥éª¤å¯ä»¥è¢«æœ‰æ•ˆä¿®å‰ªï¼Œä¸”å¯¹æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§å½±å“å¾®ä¹å…¶å¾®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æç¤ºç”Ÿæˆçš„æ¨ç†è¿‡ç¨‹å†—é•¿ä¸”å­˜åœ¨æ˜¾è‘—å†—ä½™ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬å¢åŠ å’Œæ•ˆç‡é™ä½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ­¥éª¤ç†µçš„æ–°å‹CoTå‹ç¼©æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡é‡åŒ–ä¸ªåˆ«æ¨ç†æ­¥éª¤çš„ä¿¡æ¯è´¡çŒ®æ¥è¯†åˆ«å†—ä½™ã€‚ç†è®ºåˆ†æå’Œå¤§é‡å®éªŒè¯æ˜ï¼Œä½ç†µæ­¥éª¤é«˜åº¦å†—ä½™ï¼Œå®éªŒæ˜¾ç¤ºåœ¨DeepSeek-R1-7Bã€14Bå’ŒQwen3-8Bä¸Šï¼Œ80%çš„ä½ç†µä¸­é—´æ­¥éª¤å¯ä»¥è¢«ä¿®å‰ªï¼Œä¸”æœ€ç»ˆç­”æ¡ˆå‡†ç¡®æ€§ä»…æœ‰è½»å¾®ä¸‹é™ã€‚æ­¤å¤–ï¼Œæå‡ºçš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ç»“åˆäº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰å¼ºåŒ–å­¦ä¹ ï¼Œä½¿LLMsèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­è‡ªä¸»å­¦ä¹ ç”Ÿæˆå‹ç¼©çš„CoTsï¼Œæ˜¾è‘—æé«˜æ¨ç†æ•ˆç‡å¹¶ä¸¥æ ¼ä¿æŒå‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½¿ç”¨é“¾å¼æ€ç»´æç¤ºæ—¶äº§ç”Ÿçš„å†—ä½™æ¨ç†æ­¥éª¤é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¾€å¾€ç”Ÿæˆå†—é•¿ä¸”ä½æ•ˆçš„æ€ç»´è¿‡ç¨‹ï¼Œå¯¼è‡´æ¨ç†æˆæœ¬å¢åŠ å’Œæ•ˆç‡é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ­¥éª¤ç†µè¿™ä¸€æŒ‡æ ‡æ¥é‡åŒ–æ¨ç†æ­¥éª¤çš„ä¿¡æ¯è´¡çŒ®ï¼Œä»è€Œè¯†åˆ«å¹¶å»é™¤å†—ä½™æ­¥éª¤ã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®éªŒè¯æ˜ï¼Œä½ç†µæ­¥éª¤é€šå¸¸å…·æœ‰è¾ƒé«˜çš„å†—ä½™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯é€šè¿‡æ­¥éª¤ç†µåˆ†æè¯†åˆ«å†—ä½™æ­¥éª¤ï¼Œç¬¬äºŒé˜¶æ®µæ˜¯ç»“åˆç›‘ç£å¾®è°ƒå’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ ï¼Œè®­ç»ƒæ¨¡å‹ç”Ÿæˆå‹ç¼©çš„é“¾å¼æ€ç»´ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åŸºäºæ­¥éª¤ç†µçš„å‹ç¼©æ¡†æ¶ï¼Œå¹¶é€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ä½¿æ¨¡å‹èƒ½å¤Ÿè‡ªä¸»å­¦ä¹ ç”Ÿæˆå‹ç¼©çš„æ¨ç†è¿‡ç¨‹ï¼Œè¿™ä¸ä¼ ç»Ÿçš„éšæœºæˆ–é«˜ç†µä¿®å‰ªæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ­¥éª¤ç†µçš„è®¡ç®—æ–¹æ³•ï¼ŒæŸå¤±å‡½æ•°çš„è®¾ç½®ï¼Œä»¥åŠåœ¨å¼ºåŒ–å­¦ä¹ é˜¶æ®µå¦‚ä½•æœ‰æ•ˆåœ°å¼•å…¥[SKIP]æ ‡è®°ä»¥å®ç°æ¨ç†æ­¥éª¤çš„å‹ç¼©ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè®­ç»ƒæµç¨‹ä¹Ÿç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨å‹ç¼©æ¨ç†çš„åŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨DeepSeek-R1-7Bã€14Bå’ŒQwen3-8Bæ¨¡å‹ä¸Šï¼Œ80%çš„ä½ç†µä¸­é—´æ­¥éª¤å¯ä»¥è¢«æœ‰æ•ˆä¿®å‰ªï¼Œä¸”æœ€ç»ˆç­”æ¡ˆçš„å‡†ç¡®æ€§ä»…æœ‰è½»å¾®ä¸‹é™ã€‚è¿™ä¸€å‘ç°ä¸éšæœºæˆ–é«˜ç†µä¿®å‰ªæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œåè€…ä¼šä¸¥é‡å½±å“æ¨ç†æ€§èƒ½ï¼Œè¯æ˜äº†æœ¬æ–‡æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨åŒ–æ¨ç†å·¥å…·ä»¥åŠå„ç±»éœ€è¦é«˜æ•ˆæ¨ç†çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚é€šè¿‡æé«˜æ¨ç†æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­é™ä½è®¡ç®—æˆæœ¬ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶ä¸ºæœªæ¥çš„LLMéƒ¨ç½²æä¾›é‡è¦çš„ç†è®ºæ”¯æŒå’Œå®è·µæŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at complex reasoning but generate verbose thought processes with considerable redundancy, leading to increased inference costs and reduced efficiency. We introduce a novel CoT compression framework based on step entropy, a metric that quantifies the informational contribution of individual reasoning steps to identify redundancy. Through theoretical analysis and extensive empirical validation on mathematical reasoning benchmarks, we demonstrate that steps with low entropy are indeed highly redundant. Our experiments reveal that an astonishing 80\% of low-entropy intermediate steps can be pruned with minor degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning, which severely impairs reasoning performance. Building on this, we propose a novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and Group Relative Policy Optimization (GRPO) reinforcement learning. This approach enables LLMs to autonomously learn to generate compressed COTs during inference by strategically incorporating [SKIP] tokens. Our method significantly enhances LLM inference efficiency while rigorously preserving accuracy, offering profound implications for practical LLM deployment and a deeper understanding of reasoning structures.

