---
layout: default
title: Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach
---

# Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03329v2</a>
  <a href="https://arxiv.org/pdf/2508.03329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03329v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03329v2', 'Industrial LLM-based Code Optimization under Regulation: A Mixture-of-Agents Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mari Ashiga, Vardan Voskanyan, Fateme Dinmohammadi, Jingzhi Gong, Paul Brookes, Matthew Truscott, Rafail Giavrimis, Mike Basios, Leslie Kanthan, Wei Jie

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-08-06)

**å¤‡æ³¨**: Submitted to ASE'25 Industry Showcase

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆä»£ç†æ–¹æ³•ä»¥è§£å†³å—ç›‘ç®¡ç¯å¢ƒä¸‹çš„ä»£ç ä¼˜åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç ä¼˜åŒ–` `æ··åˆä»£ç†` `é—ä¼ ç®—æ³•` `å—ç›‘ç®¡ç¯å¢ƒ` `è½¯ä»¶æ€§èƒ½å·¥ç¨‹` `å¼€æºæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä»£ç ä¼˜åŒ–æ–¹æ³•åœ¨å—ç›‘ç®¡ç¯å¢ƒä¸­å—åˆ°æ•°æ®éšç§å’Œåˆè§„æ€§çš„é™åˆ¶ï¼Œéš¾ä»¥å®ç°é«˜æ•ˆçš„ä»£ç ä¼˜åŒ–ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆä»£ç†ï¼ˆMoAï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨å¤šä¸ªä¸“é—¨çš„LLMsåˆæˆä»£ç ï¼Œæ—¨åœ¨æé«˜ä¼˜åŒ–æ•ˆæœå’Œæ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMoAåœ¨å¼€æ”¾æºä»£ç æ¨¡å‹ä¸­å®ç°äº†14.3%è‡³22.2%çš„æˆæœ¬èŠ‚çº¦å’Œ28.6%è‡³32.2%çš„ä¼˜åŒ–æ—¶é—´æå‡ï¼Œä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ä¼˜åŒ–æ–¹é¢çš„è¿›å±•ä½¿å¾—å·¥ä¸šå¹³å°èƒ½å¤Ÿä»¥å‰æ‰€æœªæœ‰çš„è§„æ¨¡å’Œé€Ÿåº¦è‡ªåŠ¨åŒ–è½¯ä»¶æ€§èƒ½å·¥ç¨‹ã€‚ç„¶è€Œï¼Œå—ç›‘ç®¡è¡Œä¸šçš„ç»„ç»‡é¢ä¸´ä¸¥æ ¼çš„æ•°æ®éšç§å’Œåˆè§„è¦æ±‚ï¼Œé™åˆ¶äº†å¯ä½¿ç”¨çš„LLMsï¼Œç»™é«˜è´¨é‡ä»£ç ä¼˜åŒ–å¸¦æ¥äº†æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆä»£ç†ï¼ˆMoAï¼‰æ–¹æ³•ï¼Œé€šè¿‡å¤šä¸ªä¸“é—¨çš„LLMsç›´æ¥åˆæˆä»£ç ï¼Œå¹¶ä¸åŸºäºé—ä¼ ç®—æ³•çš„ç³»ç»Ÿè¿›è¡Œæ¯”è¾ƒã€‚ç ”ç©¶è¡¨æ˜ï¼ŒMoAåœ¨å¼€æ”¾æºä»£ç æ¨¡å‹ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œèƒ½å¤Ÿå®ç°14.3%è‡³22.2%çš„æˆæœ¬èŠ‚çº¦å’Œ28.6%è‡³32.2%çš„ä¼˜åŒ–æ—¶é—´æå‡ï¼Œä¸ºåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¹³è¡¡åˆè§„æ€§ä¸ä¼˜åŒ–æ€§èƒ½æä¾›äº†å¯è¡Œçš„æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å—ç›‘ç®¡ç¯å¢ƒä¸‹çš„ä»£ç ä¼˜åŒ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å› åˆè§„æ€§é™åˆ¶è€Œæ— æ³•æœ‰æ•ˆåˆ©ç”¨å•†ä¸šLLMsï¼Œå¯¼è‡´ä¼˜åŒ–æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºæ··åˆä»£ç†ï¼ˆMoAï¼‰æ–¹æ³•ï¼Œé€šè¿‡æ•´åˆå¤šä¸ªä¸“é—¨çš„LLMsæ¥åˆæˆä»£ç ï¼Œå…‹æœå•ä¸€æ¨¡å‹çš„å±€é™æ€§ï¼Œä»è€Œæé«˜ä¼˜åŒ–è´¨é‡å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªLLMsçš„ç»„åˆä¸ååŒå·¥ä½œï¼Œé¦–å…ˆå¯¹è¾“å…¥ä»£ç è¿›è¡Œåˆ†æï¼Œç„¶åé€šè¿‡ä¸åŒæ¨¡å‹ç”Ÿæˆä»£ç å˜ä½“ï¼Œæœ€åé€‰æ‹©æœ€ä½³æ–¹æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡å°†MoAåº”ç”¨äºå·¥ä¸šä»£ç ä¼˜åŒ–ï¼Œæä¾›äº†å®è¯æ•°æ®ï¼Œæ˜¾ç¤ºåœ¨å¼€æ”¾æºä»£ç æ¨¡å‹ä¸­æ˜¾è‘—æå‡äº†ä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹é€‰æ‹©ä¸Šï¼Œç»“åˆäº†å¤šä¸ªå¼€æºLLMsï¼Œå¹¶é€šè¿‡é—ä¼ ç®—æ³•ä¼˜åŒ–ç»„åˆï¼Œç¡®ä¿åœ¨åˆè§„æ€§ä¸æ€§èƒ½ä¹‹é—´å–å¾—å¹³è¡¡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æ—¨åœ¨æœ€å¤§åŒ–ä¼˜åŒ–æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMoAæ–¹æ³•åœ¨å¼€æ”¾æºä»£ç æ¨¡å‹ä¸­å®ç°äº†14.3%è‡³22.2%çš„æˆæœ¬èŠ‚çº¦å’Œ28.6%è‡³32.2%çš„ä¼˜åŒ–æ—¶é—´æå‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„é—ä¼ ç®—æ³•å’Œå•ä¸€LLMä¼˜åŒ–å™¨è¡¨ç°æ›´ä¸ºä¼˜è¶Šï¼Œç”Ÿæˆäº†è¶…è¿‡8700ä¸ªä»£ç å˜ä½“ï¼ŒéªŒè¯äº†å…¶åœ¨å·¥ä¸šåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€äº‘è®¡ç®—å’Œé‡‘èç§‘æŠ€ç­‰å—ç›‘ç®¡è¡Œä¸šã€‚é€šè¿‡æä¾›é«˜æ•ˆçš„ä»£ç ä¼˜åŒ–æ–¹æ¡ˆï¼Œå¸®åŠ©ä¼ä¸šåœ¨éµå¾ªåˆè§„è¦æ±‚çš„åŒæ—¶æå‡è½¯ä»¶æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in Large Language Models (LLMs) for code optimization have enabled industrial platforms to automate software performance engineering at unprecedented scale and speed. Yet, organizations in regulated industries face strict constraints on which LLMs they can use - many cannot utilize commercial models due to data privacy regulations and compliance requirements, creating a significant challenge for achieving high-quality code optimization while maintaining cost-effectiveness. We address this by implementing a Mixture-of-Agents (MoA) approach that directly synthesizes code from multiple specialized LLMs, comparing it against TurinTech AI's vanilla Genetic Algorithm (GA)-based ensemble system and individual LLM optimizers using real-world industrial codebases. Our key contributions include: (1) First MoA application to industrial code optimization using real-world codebases; (2) Empirical evidence that MoA excels with open-source models, achieving 14.3% to 22.2% cost savings and 28.6% to 32.2% faster optimization times for regulated environments; (3) Deployment guidelines demonstrating GA's advantage with commercial models while both ensembles outperform individual LLMs; and (4) Real-world validation across 50 code snippets and seven LLM combinations, generating over 8,700 variants, addresses gaps in industrial LLM ensemble evaluation. This provides actionable guidance for organizations balancing regulatory compliance with optimization performance in production environments.

