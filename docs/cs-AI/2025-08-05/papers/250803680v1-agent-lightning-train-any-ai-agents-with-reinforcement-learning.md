---
layout: default
title: Agent Lightning: Train ANY AI Agents with Reinforcement Learning
---

# Agent Lightning: Train ANY AI Agents with Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03680" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03680v1</a>
  <a href="https://arxiv.org/pdf/2508.03680.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03680v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03680v1', 'Agent Lightning: Train ANY AI Agents with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xufang Luo, Yuge Zhang, Zhiyuan He, Zilong Wang, Siyun Zhao, Dongsheng Li, Luna K. Qiu, Yuqing Yang

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAgent Lightningæ¡†æ¶ä»¥å®ç°çµæ´»çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `ä»£ç†è®­ç»ƒ` `å¤§è¯­è¨€æ¨¡å‹` `å¤šä»£ç†åœºæ™¯` `åŠ¨æ€å·¥ä½œæµ` `å±‚æ¬¡åŒ–ç®—æ³•` `æ•°æ®æ¥å£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¾€å¾€å°†å¼ºåŒ–å­¦ä¹ è®­ç»ƒä¸ä»£ç†ç´§å¯†è€¦åˆï¼Œç¼ºä¹çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚
2. Agent Lightningé€šè¿‡è§£è€¦ä»£ç†æ‰§è¡Œä¸è®­ç»ƒï¼Œæå‡ºäº†ç»Ÿä¸€çš„æ•°æ®æ¥å£å’ŒLightningRLç®—æ³•ï¼Œæ”¯æŒå¤šç§ä»£ç†çš„è®­ç»ƒã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†ç¨³å®šçš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†Agent Lightningï¼Œä¸€ä¸ªçµæ´»ä¸”å¯æ‰©å±•çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è®­ç»ƒï¼Œé€‚ç”¨äºä»»ä½•AIä»£ç†ã€‚ä¸ç°æœ‰æ–¹æ³•ç´§å¯†è€¦åˆRLè®­ç»ƒæˆ–ä¾èµ–åºåˆ—æ‹¼æ¥å’Œæ©ç ä¸åŒï¼ŒAgent Lightningå®ç°äº†ä»£ç†æ‰§è¡Œä¸è®­ç»ƒçš„å®Œå…¨è§£è€¦ï¼Œå…è®¸ä¸é€šè¿‡å¤šç§æ–¹å¼å¼€å‘çš„ç°æœ‰ä»£ç†æ— ç¼é›†æˆï¼Œå‡ ä¹æ— éœ€ä»£ç ä¿®æ”¹ã€‚é€šè¿‡å°†ä»£ç†æ‰§è¡Œå½¢å¼åŒ–ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œæˆ‘ä»¬å®šä¹‰äº†ç»Ÿä¸€çš„æ•°æ®æ¥å£ï¼Œå¹¶æå‡ºäº†å±‚æ¬¡åŒ–çš„RLç®—æ³•LightningRLï¼ŒåŒ…å«ä¿¡ç”¨åˆ†é…æ¨¡å—ï¼Œèƒ½å¤Ÿå°†ä»»ä½•ä»£ç†ç”Ÿæˆçš„è½¨è¿¹åˆ†è§£ä¸ºè®­ç»ƒè½¬ç§»ã€‚è¿™ä½¿å¾—RLèƒ½å¤Ÿå¤„ç†å¤æ‚çš„äº¤äº’é€»è¾‘ï¼Œå¦‚å¤šä»£ç†åœºæ™¯å’ŒåŠ¨æ€å·¥ä½œæµã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ–‡æœ¬åˆ°SQLã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ•°å­¦å·¥å…·ä½¿ç”¨ä»»åŠ¡ä¸­ï¼Œæ¡†æ¶å±•ç¤ºäº†ç¨³å®šçš„æŒç»­æ”¹è¿›ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ç°å®ä¸–ç•Œä»£ç†è®­ç»ƒå’Œéƒ¨ç½²ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæ–¹æ³•é€šå¸¸ä¸ä»£ç†çš„å®ç°ç´§å¯†è€¦åˆï¼Œå¯¼è‡´çµæ´»æ€§ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”ä¸åŒçš„ä»£ç†å¼€å‘æ–¹å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAgent Lightningæ¡†æ¶é€šè¿‡å°†ä»£ç†æ‰§è¡Œä¸è®­ç»ƒè§£è€¦ï¼Œå…è®¸å‡ ä¹é›¶ä»£ç ä¿®æ”¹åœ°é›†æˆç°æœ‰ä»£ç†ï¼Œå¹¶é€šè¿‡ç»Ÿä¸€çš„æ•°æ®æ¥å£å’Œå±‚æ¬¡åŒ–çš„RLç®—æ³•æ¥å¤„ç†å¤æ‚çš„äº¤äº’é€»è¾‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ¡†æ¶åŒ…æ‹¬ä»£ç†æ‰§è¡Œæ¨¡å—ã€è®­ç»ƒä»£ç†è§£è€¦æ¶æ„å’Œä¿¡ç”¨åˆ†é…æ¨¡å—ï¼Œæ•´ä½“æµç¨‹é€šè¿‡é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹æ¥å®šä¹‰ä»£ç†æ‰§è¡Œï¼Œå¹¶å°†ç”Ÿæˆçš„è½¨è¿¹åˆ†è§£ä¸ºè®­ç»ƒè½¬ç§»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå®ç°äº†ä»£ç†æ‰§è¡Œä¸è®­ç»ƒçš„å®Œå…¨è§£è€¦ï¼Œæå‡ºäº†LightningRLç®—æ³•ï¼Œèƒ½å¤Ÿå¤„ç†å¤šä»£ç†åœºæ™¯å’ŒåŠ¨æ€å·¥ä½œæµçš„å¤æ‚äº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æ¶è®¾è®¡ä¸­å¼•å…¥äº†æ ‡å‡†åŒ–çš„ä»£ç†å¾®è°ƒæ¥å£ï¼Œç»“åˆäº†ä»£ç†å¯è§‚å¯Ÿæ€§æ¡†æ¶ï¼Œç¡®ä¿äº†è®­ç»ƒè¿‡ç¨‹çš„é«˜æ•ˆæ€§å’Œå¯æ§æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAgent Lightningåœ¨æ–‡æœ¬åˆ°SQLã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œæ•°å­¦å·¥å…·ä½¿ç”¨ä»»åŠ¡ä¸­ï¼Œå‡å®ç°äº†ç¨³å®šçš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨ä¸åŒä»»åŠ¡åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Agent Lightningæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œé€‚ç”¨äºæ–‡æœ¬ç”Ÿæˆã€æ•°æ®æ£€ç´¢å’Œå¤æ‚ä»»åŠ¡å¤„ç†ç­‰é¢†åŸŸã€‚å…¶çµæ´»çš„è®¾è®¡ä½¿å¾—å¼€å‘è€…èƒ½å¤Ÿå¿«é€Ÿé€‚åº”ä¸åŒçš„AIä»£ç†éœ€æ±‚ï¼Œæ¨åŠ¨æ™ºèƒ½ä»£ç†çš„å®é™…åº”ç”¨å’Œéƒ¨ç½²ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½åœ¨å¤šä»£ç†åä½œå’ŒåŠ¨æ€ç¯å¢ƒé€‚åº”ç­‰æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present Agent Lightning, a flexible and extensible framework that enables Reinforcement Learning (RL)-based training of Large Language Models (LLMs) for any AI agent. Unlike existing methods that tightly couple RL training with agent or rely on sequence concatenation with masking, Agent Lightning achieves complete decoupling between agent execution and training, allowing seamless integration with existing agents developed via diverse ways (e.g., using frameworks like LangChain, OpenAI Agents SDK, AutoGen, and building from scratch) with almost ZERO code modifications. By formulating agent execution as Markov decision process, we define an unified data interface and propose a hierarchical RL algorithm, LightningRL, which contains a credit assignment module, allowing us to decompose trajectories generated by ANY agents into training transition. This enables RL to handle complex interaction logic, such as multi-agent scenarios and dynamic workflows. For the system design, we introduce a Training-Agent Disaggregation architecture, and brings agent observability frameworks into agent runtime, providing a standardized agent finetuning interface. Experiments across text-to-SQL, retrieval-augmented generation, and math tool-use tasks demonstrate stable, continuous improvements, showcasing the framework's potential for real-world agent training and deployment.

