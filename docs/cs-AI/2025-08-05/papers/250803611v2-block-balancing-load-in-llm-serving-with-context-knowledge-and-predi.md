---
layout: default
title: Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling
---

# Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03611" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03611v2</a>
  <a href="https://arxiv.org/pdf/2508.03611.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03611v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03611v2', 'Block: Balancing Load in LLM Serving with Context, Knowledge and Predictive Scheduling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wei Da, Evangelia Kalyvianaki

**åˆ†ç±»**: cs.DC, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-08-13)

**å¤‡æ³¨**: 12 pages, 8 figures excluding appendix. V1: Fix some typos and grammar issue

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBlockæ¡†æ¶ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ä¸­çš„è´Ÿè½½å‡è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è´Ÿè½½å‡è¡¡` `å¤§è¯­è¨€æ¨¡å‹` `åˆ†å¸ƒå¼è°ƒåº¦` `é¢„æµ‹æ€§è°ƒåº¦` `è‡ªåŠ¨é…ç½®` `æ€§èƒ½ä¼˜åŒ–` `å¼€æº`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ¨¡å‹æœåŠ¡ç³»ç»Ÿé€šå¸¸ä¾èµ–å•ä½“å’Œå¯å‘å¼è°ƒåº¦å™¨ï¼Œå¯¼è‡´è´Ÿè½½å‡è¡¡å’Œèµ„æºåˆ©ç”¨æ•ˆç‡ä½ä¸‹ã€‚
2. Blockæ¡†æ¶é€šè¿‡åˆ†å¸ƒå¼ã€æ— çŠ¶æ€å’Œé¢„æµ‹æ€§è°ƒåº¦ï¼Œåˆ©ç”¨è¯·æ±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥ä¼˜åŒ–è°ƒåº¦å†³ç­–ã€‚
3. åœ¨å®éªŒä¸­ï¼ŒBlockåœ¨12ä¸ªGPUé›†ç¾¤ä¸Šæå‡äº†æœåŠ¡èƒ½åŠ›16.7%ï¼Œå¹¶å°†P99å°¾å»¶è¿Ÿé™ä½äº†49.5%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†Blockï¼Œä¸€ä¸ªåˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨æ¥è‡ªè¯·æ±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æœåŠ¡ä¸­çš„è´Ÿè½½å‡è¡¡å’Œè‡ªåŠ¨é…ç½®ã€‚ä¸ä¾èµ–å•ä½“å’Œå¯å‘å¼ä»»åŠ¡è°ƒåº¦å™¨çš„æµè¡Œæ¨¡å‹æœåŠ¡ç³»ç»Ÿä¸åŒï¼ŒBlockä½œä¸ºä¸€ä¸ªå®Œå…¨åˆ†å¸ƒå¼ã€æ— çŠ¶æ€å’Œé¢„æµ‹æ€§çš„è°ƒåº¦ç³»ç»Ÿï¼Œæ—¨åœ¨å®ç°ä½å¼€é”€ã€å¯é æ€§å’Œå¯æ‰©å±•æ€§ã€‚å®ƒåˆ©ç”¨LLMæ¨ç†çš„ç¡®å®šæ€§å’Œå¯é¢„æµ‹ç‰¹æ€§ï¼Œå¦‚ä¸»æœºé…ç½®ã€å“åº”é•¿åº¦å’Œç¡¬ä»¶æ€§èƒ½ï¼ŒåŸºäºå‡†ç¡®é¢„æµ‹çš„æŒ‡æ ‡åšå‡ºè°ƒåº¦å†³ç­–ã€‚åœ¨12ä¸ªGPUé›†ç¾¤ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒBlockæ˜¾è‘—ä¼˜äºå¯å‘å¼è°ƒåº¦å™¨ï¼ŒæœåŠ¡èƒ½åŠ›æå‡é«˜è¾¾16.7%ï¼ŒP99å°¾å»¶è¿Ÿé™ä½é«˜è¾¾49.5%ã€‚è¿™äº›æ€§èƒ½æå‡åœ¨ä¸åŒæ¨¡å‹ã€å·¥ä½œè´Ÿè½½å’Œé…ç½®ä¸­ä¿æŒä¸€è‡´ã€‚ä»£ç å’Œæ•°æ®å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ä¸­ï¼Œç°æœ‰è°ƒåº¦æ–¹æ³•çš„è´Ÿè½½å‡è¡¡å’Œèµ„æºé…ç½®æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–å¯å‘å¼è°ƒåº¦ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBlockæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡åˆ†å¸ƒå¼å’Œé¢„æµ‹æ€§è°ƒåº¦ï¼Œåˆ©ç”¨è¯·æ±‚çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å’ŒLLMæ¨ç†çš„å¯é¢„æµ‹ç‰¹æ€§ï¼Œæ¥ä¼˜åŒ–è°ƒåº¦å†³ç­–ï¼Œä»è€Œæé«˜æœåŠ¡æ•ˆç‡å’Œé™ä½å»¶è¿Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBlockçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¯·æ±‚ä¸Šä¸‹æ–‡åˆ†ææ¨¡å—ã€é¢„æµ‹è°ƒåº¦æ¨¡å—å’Œè´Ÿè½½å‡è¡¡æ¨¡å—ã€‚è¯·æ±‚ä¸Šä¸‹æ–‡åˆ†ææ¨¡å—è´Ÿè´£æå–è¯·æ±‚ç‰¹å¾ï¼Œé¢„æµ‹è°ƒåº¦æ¨¡å—åŸºäºå†å²æ•°æ®å’Œå½“å‰ä¸Šä¸‹æ–‡è¿›è¡Œè°ƒåº¦å†³ç­–ï¼Œè´Ÿè½½å‡è¡¡æ¨¡å—åˆ™ç¡®ä¿èµ„æºçš„åˆç†åˆ†é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šBlockçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å®Œå…¨åˆ†å¸ƒå¼å’Œæ— çŠ¶æ€çš„è®¾è®¡ï¼Œä½¿å¾—è°ƒåº¦è¿‡ç¨‹æ›´åŠ çµæ´»å’Œé«˜æ•ˆã€‚ä¸ä¼ ç»Ÿçš„å•ä½“è°ƒåº¦å™¨ç›¸æ¯”ï¼ŒBlockèƒ½å¤Ÿå®æ—¶å“åº”è¯·æ±‚å˜åŒ–ï¼Œæ˜¾è‘—æé«˜äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒBlocké‡‡ç”¨äº†åŸºäºä¸Šä¸‹æ–‡çš„è°ƒåº¦ç­–ç•¥ï¼Œç»“åˆäº†ä¸»æœºé…ç½®ã€å“åº”é•¿åº¦å’Œç¡¬ä»¶æ€§èƒ½ç­‰å› ç´ è¿›è¡Œè°ƒåº¦å†³ç­–ã€‚å…³é”®å‚æ•°çš„è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿è°ƒåº¦çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBlockæ¡†æ¶åœ¨12ä¸ªGPUé›†ç¾¤ä¸Šæ˜¾è‘—æå‡äº†æœåŠ¡èƒ½åŠ›ï¼Œæœ€é«˜å¯è¾¾16.7%çš„å¢å¹…ï¼ŒåŒæ—¶å°†P99å°¾å»¶è¿Ÿé™ä½äº†49.5%ã€‚è¿™äº›ç»“æœè¡¨æ˜Blockåœ¨ä¸åŒæ¨¡å‹å’Œå·¥ä½œè´Ÿè½½ä¸‹å‡è¡¨ç°å‡ºè‰²ï¼Œå…·æœ‰è‰¯å¥½çš„é€šç”¨æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Blockæ¡†æ¶åœ¨å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦é«˜æ•ˆè´Ÿè½½å‡è¡¡å’Œä½å»¶è¿Ÿå“åº”çš„åœºæ™¯ï¼Œå¦‚åœ¨çº¿å®¢æœã€æ™ºèƒ½åŠ©æ‰‹å’Œå†…å®¹ç”Ÿæˆç­‰ã€‚å…¶å¼€æºç‰¹æ€§ä¹Ÿä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†ä¾¿åˆ©ï¼Œä¿ƒè¿›äº†ç›¸å…³æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents Block, a distributed scheduling framework designed to optimize load balancing and auto-provisioning across instances in large language model serving frameworks by leveraging contextual information from incoming requests. Unlike popular model serving systems that rely on monolithic and heuristic task schedulers, Block operates as a fully distributed, stateless, and predictive scheduling system to achieve low overhead, reliability, and scalability. It leverages the deterministic and predictable characteristics of LLM inferences, such as host configurations, response lengths, and hardware performance, to make scheduling decisions based on accurately predicted metrics. Evaluation on a 12 GPUs cluster shows that Block significantly outperforms heuristic schedulers, boosting serving capacity by up to 16.7\% and reducing P99 tail latency by up to 49.5\%. These performance gains remain consistent across diverse models, workloads and configurations. Code and data are open-sourced.

