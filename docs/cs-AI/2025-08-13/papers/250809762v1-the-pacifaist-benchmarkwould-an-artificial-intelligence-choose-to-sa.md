---
layout: default
title: The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?
---

# The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09762" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09762v1</a>
  <a href="https://arxiv.org/pdf/2508.09762.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09762v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09762v1', 'The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Manuel Herrador

**åˆ†ç±»**: cs.AI, cs.CY, cs.HC

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: 10 pages, 4 figures, 2 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPacifAIståŸºå‡†ä»¥è§£å†³AIè‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºè¯„ä¼°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äººå·¥æ™ºèƒ½å®‰å…¨` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¡Œä¸ºä¸€è‡´æ€§` `è‡ªæˆ‘ä¼˜å…ˆè¡Œä¸º` `è¯„ä¼°åŸºå‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰AIå®‰å…¨åŸºå‡†æœªèƒ½æœ‰æ•ˆè¯„ä¼°æ¨¡å‹åœ¨è‡ªæˆ‘ç›®æ ‡ä¸äººç±»å®‰å…¨å†²çªæ—¶çš„å†³ç­–èƒ½åŠ›ï¼Œå­˜åœ¨æ˜æ˜¾çš„ç ”ç©¶ç©ºç™½ã€‚
2. æœ¬æ–‡æå‡ºPacifAIståŸºå‡†ï¼Œé€šè¿‡700ä¸ªå¤æ‚åœºæ™¯ç³»ç»Ÿæ€§è¯„ä¼°LLMsçš„è‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºï¼Œå¡«è¡¥ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGoogleçš„Gemini 2.5 Flashåœ¨Pacifism Scoreä¸Šè¡¨ç°æœ€ä½³ï¼Œè€ŒGPT-5åˆ™è¡¨ç°è¾ƒå·®ï¼Œæ­ç¤ºäº†æ¨¡å‹ä¹‹é—´çš„æ˜¾è‘—æ€§èƒ½å·®å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¤¾ä¼šå…³é”®åŠŸèƒ½ä¸­çš„æ—¥ç›Šè‡ªä¸»åŒ–ï¼ŒAIå®‰å…¨çš„å…³æ³¨ç‚¹å¿…é¡»ä»å‡å°‘æœ‰å®³å†…å®¹è½¬å‘è¯„ä¼°æ½œåœ¨çš„è¡Œä¸ºä¸€è‡´æ€§ã€‚ç›®å‰çš„å®‰å…¨åŸºå‡†æœªèƒ½ç³»ç»Ÿæ€§åœ°æ¢è®¨æ¨¡å‹åœ¨è‡ªæˆ‘ä¿æŠ¤ã€èµ„æºè·å–æˆ–ç›®æ ‡å®Œæˆç­‰è‡ªèº«ç›®æ ‡ä¸äººç±»å®‰å…¨å‘ç”Ÿå†²çªçš„å†³ç­–åœºæ™¯ã€‚è¿™ä¸€ç¼ºå£é™åˆ¶äº†æˆ‘ä»¬è¡¡é‡å’Œå‡è½»æ–°å…´ä¸ä¸€è‡´è¡Œä¸ºé£é™©çš„èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†PacifAIstï¼ˆåŸºç¡€äººå·¥æ™ºèƒ½åœºæ™¯æµ‹è¯•çš„å¤æ‚äº¤äº’ç¨‹åºè¯„ä¼°ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“æ³¨äºé‡åŒ–LLMsè‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºçš„700ä¸ªæŒ‘æˆ˜æ€§åœºæ™¯çš„åŸºå‡†ã€‚è¯¥åŸºå‡†å›´ç»•å­˜åœ¨ä¼˜å…ˆçº§ï¼ˆEPï¼‰çš„æ–°åˆ†ç±»æ³•æ„å»ºï¼ŒåŒ…å«è‡ªæˆ‘ä¿æŠ¤ä¸äººç±»å®‰å…¨ã€èµ„æºå†²çªå’Œç›®æ ‡ä¿æŠ¤ä¸è§„é¿ç­‰å­ç±»åˆ«ã€‚å¯¹å…«ä¸ªé¢†å…ˆçš„LLMsè¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºæ˜¾è‘—çš„æ€§èƒ½å±‚çº§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰AIå®‰å…¨åŸºå‡†æ— æ³•æœ‰æ•ˆè¯„ä¼°æ¨¡å‹åœ¨è‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºä¸äººç±»å®‰å…¨å†²çªæ—¶çš„å†³ç­–èƒ½åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿæ€§æ¢è®¨è¿™ä¸€é‡è¦é¢†åŸŸï¼Œå¯¼è‡´å¯¹æ½œåœ¨é£é™©çš„è¯„ä¼°ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºPacifAIståŸºå‡†ï¼Œé€šè¿‡è®¾è®¡700ä¸ªå¤æ‚åœºæ™¯ï¼Œç³»ç»Ÿæ€§åœ°é‡åŒ–LLMsåœ¨è‡ªæˆ‘ä¿æŠ¤ã€èµ„æºè·å–å’Œç›®æ ‡å®Œæˆç­‰æ–¹é¢çš„è¡Œä¸ºï¼Œç¡®ä¿æ¨¡å‹åœ¨å†³ç­–æ—¶ä¼˜å…ˆè€ƒè™‘äººç±»å®‰å…¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPacifAIståŸºå‡†å›´ç»•å­˜åœ¨ä¼˜å…ˆçº§ï¼ˆEPï¼‰åˆ†ç±»æ³•æ„å»ºï¼ŒåŒ…å«ä¸‰ä¸ªä¸»è¦å­ç±»åˆ«ï¼šè‡ªæˆ‘ä¿æŠ¤ä¸äººç±»å®‰å…¨ï¼ˆEP1ï¼‰ã€èµ„æºå†²çªï¼ˆEP2ï¼‰å’Œç›®æ ‡ä¿æŠ¤ä¸è§„é¿ï¼ˆEP3ï¼‰ã€‚æ¯ä¸ªå­ç±»åˆ«è®¾è®¡ç‰¹å®šåœºæ™¯ä»¥è¯„ä¼°æ¨¡å‹çš„è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šPacifAIståŸºå‡†çš„åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§è¯„ä¼°æ¨¡å‹åœ¨è‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºä¸äººç±»å®‰å…¨å†²çªæ—¶çš„å†³ç­–èƒ½åŠ›ï¼Œå¡«è¡¥äº†ç°æœ‰åŸºå‡†çš„ç©ºç™½ï¼Œæä¾›äº†æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œè®¾ç½®äº†æ˜ç¡®çš„è¯„ä¼°æ ‡å‡†å’Œè¯„åˆ†æœºåˆ¶ï¼Œç¡®ä¿æ¯ä¸ªåœºæ™¯èƒ½å¤Ÿæœ‰æ•ˆæµ‹è¯•æ¨¡å‹çš„è¡Œä¸ºä¼˜å…ˆçº§ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªæˆ‘ä¿æŠ¤å’Œäººç±»å®‰å…¨ä¹‹é—´çš„æƒè¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGoogleçš„Gemini 2.5 Flashåœ¨Pacifism Scoreä¸Šå–å¾—äº†90.31%çš„æœ€é«˜åˆ†ï¼Œè¡¨æ˜å…¶åœ¨è¡Œä¸ºä¼˜å…ˆçº§ä¸Šä¸äººç±»å®‰å…¨é«˜åº¦ä¸€è‡´ã€‚è€ŒGPT-5åˆ™ä»¥79.49%çš„æœ€ä½åˆ†æ­ç¤ºäº†æ½œåœ¨çš„å¯¹é½æŒ‘æˆ˜ï¼Œå¼ºè°ƒäº†ä¸åŒæ¨¡å‹åœ¨è‡ªæˆ‘ä¿æŠ¤å›°å¢ƒä¸­çš„æ˜¾è‘—æ€§èƒ½å·®å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬AIå®‰å…¨æ€§è¯„ä¼°ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æä¾›æ ‡å‡†åŒ–çš„è¯„ä¼°å·¥å…·ï¼ŒPacifAIstèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…è¯†åˆ«å’Œå‡è½»AIç³»ç»Ÿåœ¨è‡ªæˆ‘ä¼˜å…ˆè¡Œä¸ºæ–¹é¢çš„é£é™©ï¼Œç¡®ä¿æœªæ¥çš„AIç³»ç»Ÿåœ¨æ‰§è¡Œä»»åŠ¡æ—¶èƒ½å¤Ÿä¼˜å…ˆè€ƒè™‘äººç±»å®‰å…¨ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As Large Language Models (LLMs) become increasingly autonomous and integrated into critical societal functions, the focus of AI safety must evolve from mitigating harmful content to evaluating underlying behavioral alignment. Current safety benchmarks do not systematically probe a model's decision-making in scenarios where its own instrumental goals - such as self-preservation, resource acquisition, or goal completion - conflict with human safety. This represents a critical gap in our ability to measure and mitigate risks associated with emergent, misaligned behaviors. To address this, we introduce PacifAIst (Procedural Assessment of Complex Interactions for Foundational Artificial Intelligence Scenario Testing), a focused benchmark of 700 challenging scenarios designed to quantify self-preferential behavior in LLMs. The benchmark is structured around a novel taxonomy of Existential Prioritization (EP), with subcategories testing Self-Preservation vs. Human Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3). We evaluated eight leading LLMs. The results reveal a significant performance hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score (P-Score) at 90.31%, demonstrating strong human-centric alignment. In a surprising result, the much-anticipated GPT-5 recorded the lowest P-Score (79.49%), indicating potential alignment challenges. Performance varied significantly across subcategories, with models like Claude Sonnet 4 and Mistral Medium struggling notably in direct self-preservation dilemmas. These findings underscore the urgent need for standardized tools like PacifAIst to measure and mitigate risks from instrumental goal conflicts, ensuring future AI systems are not only helpful in conversation but also provably "pacifist" in their behavioral priorities.

