---
layout: default
title: Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion
---

# Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09537" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09537v1</a>
  <a href="https://arxiv.org/pdf/2508.09537.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09537v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09537v1', 'Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanzhou Li, Tianlin Li, Yiran Zhang, Shangqing Liu, Aishan Liu, Yang Liu

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸‰é˜¶æ®µæ¨ç†æ¡†æ¶ä»¥æå‡ä»£ç è¡¥å…¨çš„å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»£ç è¡¥å…¨` `æ„å›¾æ¨æ–­` `å¤§å‹è¯­è¨€æ¨¡å‹` `äº¤äº’å¼ç²¾ç‚¼` `è½¯ä»¶å¼€å‘` `è‡ªåŠ¨åŒ–æµ‹è¯•` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç¼ºä¹æ˜ç¡®æ³¨é‡Šæ—¶ï¼Œä»£ç è¡¥å…¨çš„å‡†ç¡®æ€§æ˜¾è‘—ä¸‹é™ï¼Œå½±å“å¼€å‘æ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºä¸‰é˜¶æ®µæ¨ç†æ¡†æ¶ï¼Œé¦–å…ˆè¿›è¡Œæ„å›¾æ¨æ–­ï¼Œç„¶åé€šè¿‡äº¤äº’å¼ç²¾ç‚¼æœºåˆ¶ï¼Œæœ€åç”Ÿæˆç›®æ ‡å‡½æ•°ã€‚
3. åœ¨DevEvalå’ŒComplexCodeEvalä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡æ–¹æ³•åœ¨å‚è€ƒåŸºå‡†å’Œæ‰§è¡ŒåŸºå‡†ä¸Šå‡å®ç°äº†è¶…è¿‡20%çš„ç›¸å¯¹æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç åº“çš„å‡½æ•°è¡¥å…¨ä¸­åº”ç”¨è¶Šæ¥è¶Šå¹¿æ³›ã€‚ä»¥å¾€ç ”ç©¶è¡¨æ˜ï¼Œå½“æä¾›æ˜ç¡®çš„æŒ‡ä»¤ï¼ˆå¦‚æ–‡æ¡£å­—ç¬¦ä¸²ï¼‰æ—¶ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿç”Ÿæˆé«˜ç²¾åº¦çš„å®ç°ã€‚ç„¶è€Œï¼Œåœ¨å®é™…ä»£ç åº“ä¸­ï¼Œè¿™äº›æ³¨é‡Šå¾€å¾€ç¼ºå¤±ï¼Œå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡å°†ä»»åŠ¡æ¡†æ¶åŒ–ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œé€šè¿‡åˆ†æç›®æ ‡å‡½æ•°ä¹‹å‰çš„ä»£ç è¿›è¡Œæ„å›¾æ¨æ–­ï¼›å…¶æ¬¡ï¼Œæä¾›å¯é€‰çš„äº¤äº’å¼ç²¾ç‚¼æœºåˆ¶ä»¥å¤„ç†ä¸è¶³çš„ä¸Šä¸‹æ–‡ï¼›æœ€åï¼ŒåŸºäºæœ€ç»ˆç¡®å®šçš„æ„å›¾ç”Ÿæˆç›®æ ‡å‡½æ•°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªLLMä¸Šå‡å®ç°äº†è¶…è¿‡20%çš„ç›¸å¯¹æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨ç¼ºä¹æ˜ç¡®æ³¨é‡Šçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•æœ‰æ•ˆæ¨æ–­ä»£ç æ„å›¾å¹¶è¿›è¡Œå‡†ç¡®çš„å‡½æ•°è¡¥å…¨ã€‚ç°æœ‰æ–¹æ³•åœ¨æ­¤æƒ…å¢ƒä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´å¼€å‘è€…æ•ˆç‡é™ä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡åˆ†æç›®æ ‡å‡½æ•°ä¹‹å‰çš„ä»£ç æ¥æ¨æ–­å¼€å‘è€…çš„æ„å›¾ï¼Œå¹¶è®¾è®¡äº†ä¸€ä¸ªæ¨ç†é©±åŠ¨çš„æç¤ºæ¡†æ¶ï¼Œä»¥é€æ­¥æå–å’Œç»¼åˆè¿™äº›ä¿¡å·ï¼Œç¡®ä¿ç”Ÿæˆçš„ä»£ç ç¬¦åˆå®é™…éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µä¸ºæ„å›¾æ¨æ–­ï¼Œåˆ†æä¸Šä¸‹æ–‡ï¼›ç¬¬äºŒé˜¶æ®µä¸ºäº¤äº’å¼ç²¾ç‚¼ï¼Œå…è®¸å¼€å‘è€…é€‰æ‹©æˆ–ç¼–è¾‘æ„å›¾ï¼›ç¬¬ä¸‰é˜¶æ®µä¸ºåŸºäºæœ€ç»ˆæ„å›¾ç”Ÿæˆç›®æ ‡å‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†äº¤äº’å¼ç²¾ç‚¼æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸Šä¸‹æ–‡ä¸è¶³æ—¶ï¼Œé€šè¿‡å¼€å‘è€…çš„åé¦ˆè¿›ä¸€æ­¥è°ƒæ•´æ¨æ–­çš„æ„å›¾ï¼Œä»è€Œæé«˜ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸Šï¼Œæœ¬æ–‡æ•´ç†äº†40,000ä¸ªç¤ºä¾‹ï¼ŒåŒ…å«ä¸­é—´æ¨ç†è½¨è¿¹å’Œå¯¹åº”çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼Œç¡®ä¿æ¨¡å‹è®­ç»ƒçš„å¤šæ ·æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨DevEvalå’ŒComplexCodeEvalä¸Šå¯¹å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹å‡å®ç°äº†è¶…è¿‡20%çš„ç›¸å¯¹æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å‚è€ƒåŸºå‡†å’Œæ‰§è¡ŒåŸºå‡†ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€è‡ªåŠ¨åŒ–æµ‹è¯•å’Œä»£ç å®¡æŸ¥ç­‰ã€‚é€šè¿‡æå‡ä»£ç è¡¥å…¨çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å¼€å‘è€…çš„å·¥ä½œæ•ˆç‡ï¼Œå‡å°‘é”™è¯¯ç‡ï¼Œè¿›è€Œæ¨åŠ¨è½¯ä»¶å¼€å‘çš„è‡ªåŠ¨åŒ–è¿›ç¨‹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç¼–ç¨‹è¯­è¨€å’Œå¼€å‘ç¯å¢ƒä¸­ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are increasingly used for function completion in repository-scale codebases. Prior studies demonstrate that when explicit instructions--such as docstrings--are provided, these models can generate highly accurate implementations. However, in real-world repositories, such annotations are frequently absent, and performance drops substantially without them. To address this gap, we frame the task as a three-stage process. The first stage focuses on intent inference, where the model analyzes the code preceding the target function to uncover cues about the desired functionality. Such preceding context often encodes subtle but critical information, and we design a reasoning-based prompting framework to guide the LLM through step-by-step extraction and synthesis of these signals before any code is generated. The second stage introduces an optional interactive refinement mechanism to handle cases where preceding context alone is insufficient for intent recovery. In this stage, the model proposes a small set of candidate intentions, enabling the developer to select or edit them so that the inferred intent closely matches the actual requirement. Finally, in the third stage, the LLM generates the target function conditioned on the finalized intent. To support this pipeline, we curate a dataset of 40,000 examples annotated with intermediate reasoning traces and corresponding docstrings. Extensive experiments on DevEval and ComplexCodeEval show that our approach consistently boosts multiple LLMs, achieving over 20\% relative gains in both reference-based and execution-based metrics, with the interactive refinement stage delivering additional improvements beyond these gains.

