---
layout: default
title: EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making
---

# EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09586" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09586v2</a>
  <a href="https://arxiv.org/pdf/2508.09586.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09586v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09586v2', 'EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yang Cheng, Zilai Wang, Weiyu Ma, Wenhui Zhu, Yue Deng, Jian Zhao

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13 (æ›´æ–°: 2025-08-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEvoCurrä»¥è§£å†³å¤æ‚å†³ç­–é—®é¢˜çš„å­¦ä¹ æ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯¾ç¨‹å­¦ä¹ ` `å¤æ‚å†³ç­–` `è‡ªæˆ‘è¿›åŒ–` `åŠ¨æ€è°ƒæ•´` `è‡ªåŠ¨æ¨ç†` `Pythonè„šæœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚å†³ç­–ä»»åŠ¡æ—¶ï¼Œå¾€å¾€ç¼ºä¹ç»“æ„åŒ–çš„ä¸­é—´æŒ‡å¯¼ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹æˆ–å¤±è´¥ã€‚
2. EvoCurræ¡†æ¶é€šè¿‡åŠ¨æ€ç”Ÿæˆé€‚åº”æ±‚è§£è€…å­¦ä¹ è¿›åº¦çš„è¯¾ç¨‹ï¼Œé€æ­¥å¢åŠ é—®é¢˜éš¾åº¦ï¼Œä»è€Œæå‡å­¦ä¹ æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEvoCurråœ¨å¤æ‚å†³ç­–åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†ä»»åŠ¡æˆåŠŸç‡å’Œè§£å†³æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç¼–ç¨‹ã€è§„åˆ’å’Œå†³ç­–ç­‰å¤šä¸ªé¢†åŸŸå±•ç°äº†å“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå½“é¢ä¸´éœ€è¦æ·±åº¦æ¨ç†çš„å¤æ‚é—®é¢˜æ—¶ï¼Œå…¶æ€§èƒ½å¾€å¾€ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è‡ªæˆ‘è¿›åŒ–æ¡†æ¶EvoCurrï¼Œè¯¥æ¡†æ¶é€šè¿‡ä¸“é—¨çš„è¯¾ç¨‹ç”ŸæˆLLMæ„å»ºé€æ­¥å¢åŠ éš¾åº¦çš„é—®é¢˜å®ä¾‹åºåˆ—ï¼Œé€‚åº”æ±‚è§£è€…LLMçš„å­¦ä¹ è¿›åº¦ã€‚è¯¥è¯¾ç¨‹èƒ½å¤ŸåŠ¨æ€è°ƒæ•´æŒ‘æˆ˜çš„éš¾åº¦ï¼Œä»è€Œä¿æŒæœ€ä½³å­¦ä¹ è½¨è¿¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ç›´æ¥æ±‚è§£åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†ä»»åŠ¡æˆåŠŸç‡å’Œè§£å†³æ•ˆç‡ï¼Œæ˜¾ç¤ºå‡ºLLMé©±åŠ¨çš„è¯¾ç¨‹å­¦ä¹ åœ¨é«˜å¤æ‚åº¦é¢†åŸŸå¢å¼ºè‡ªåŠ¨æ¨ç†çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„ä¸­é—´æŒ‡å¯¼ï¼Œå¯¼è‡´æ±‚è§£æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEvoCurræ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è¯¾ç¨‹ç”ŸæˆLLMåŠ¨æ€æ„å»ºé€æ­¥å¢åŠ éš¾åº¦çš„é—®é¢˜å®ä¾‹ï¼Œé€‚åº”æ±‚è§£è€…çš„å­¦ä¹ è¿›åº¦ï¼Œä»è€Œä¼˜åŒ–å­¦ä¹ è·¯å¾„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEvoCurrçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¯¾ç¨‹ç”Ÿæˆæ¨¡å—å’Œæ±‚è§£è€…æ¨¡å—ã€‚è¯¾ç¨‹ç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆé€‚åº”æ€§é—®é¢˜å®ä¾‹ï¼Œè€Œæ±‚è§£è€…æ¨¡å—åˆ™åˆ©ç”¨ç”Ÿæˆçš„å®ä¾‹è¿›è¡Œå­¦ä¹ å’Œå†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šEvoCurrçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è‡ªæˆ‘è¿›åŒ–çš„è¯¾ç¨‹ç”Ÿæˆæœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®æ±‚è§£è€…çš„è¡¨ç°åŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ï¼Œè¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„é™æ€è¯¾ç¨‹å­¦ä¹ æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒEvoCurrä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è¯„ä¼°æ±‚è§£è€…çš„è¡¨ç°ï¼Œå¹¶æ ¹æ®è¡¨ç°è°ƒæ•´è¯¾ç¨‹éš¾åº¦ã€‚æ­¤å¤–ï¼Œæ±‚è§£è€…é‡‡ç”¨äº†åŸºäºPythonçš„å†³ç­–æ ‘è„šæœ¬ç”Ÿæˆæ¨¡å‹ï¼Œä»¥å®ç°å¤æ‚å†³ç­–çš„è‡ªåŠ¨åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEvoCurråœ¨å¤æ‚å†³ç­–åŸºå‡†æµ‹è¯•ä¸­ï¼Œä»»åŠ¡æˆåŠŸç‡æé«˜äº†æ˜¾è‘—çš„XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œè§£å†³æ•ˆç‡ä¹Ÿæœ‰æ˜æ˜¾æå‡ï¼Œç›¸è¾ƒäºç›´æ¥æ±‚è§£åŸºçº¿ï¼Œè¡¨ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ã€‚è¿™äº›ç»“æœéªŒè¯äº†LLMé©±åŠ¨çš„è¯¾ç¨‹å­¦ä¹ åœ¨é«˜å¤æ‚åº¦é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

EvoCurrçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤æ‚å†³ç­–å’Œæ·±åº¦æ¨ç†çš„åœºæ™¯ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€é‡‘èå†³ç­–å’Œæ™ºèƒ½åˆ¶é€ ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æ”¹å–„å®é™…åº”ç”¨ä¸­çš„å†³ç­–è´¨é‡å’Œæ•ˆç‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šæ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse domains, including programming, planning, and decision-making. However, their performance often degrades when faced with highly complex problem instances that require deep reasoning over long horizons. In such cases, direct problem-solving approaches can lead to inefficiency or failure due to the lack of structured intermediate guidance. To address this, we propose a novel self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM constructs a sequence of problem instances with gradually increasing difficulty, tailored to the solver LLM's learning progress. The curriculum dynamically adapts easing challenges when the solver struggles and escalating them when success is consistent, thus maintaining an optimal learning trajectory. This approach enables the solver LLM, implemented as a code-generation model producing Python decision-tree scripts, to progressively acquire the skills needed for complex decision-making tasks. Experimental results on challenging decision-making benchmarks show that our method significantly improves task success rates and solution efficiency compared to direct-solving baselines. These findings suggest that LLM-driven curriculum learning holds strong potential for enhancing automated reasoning in real-world, high-complexity domains.

