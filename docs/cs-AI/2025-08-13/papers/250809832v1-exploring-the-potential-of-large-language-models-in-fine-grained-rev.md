---
layout: default
title: Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification
---

# Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09832" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09832v1</a>
  <a href="https://arxiv.org/pdf/2508.09832.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09832v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09832v1', 'Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linh Nguyen, Chunhua Liu, Hong Yi Lin, Patanamon Thongtanunam

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

**å¤‡æ³¨**: Accepted at 2025 IEEE International Conference on Source Code Analysis & Manipulation (SCAM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æå‡ä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»çš„å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç å®¡æŸ¥` `è¯„è®ºåˆ†ç±»` `è‡ªåŠ¨åŒ–æŠ€æœ¯` `æ·±åº¦å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†` `è½¯ä»¶å¼€å‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨ä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»ä¸­ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨ï¼Œå¯¼è‡´è®­ç»ƒæ¨¡å‹çš„æˆæœ¬é«˜ä¸”æ•ˆç‡ä½ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œä»£ç å®¡æŸ¥è¯„è®ºçš„åˆ†ç±»ï¼Œæ—¨åœ¨å‡å°‘å¯¹äººå·¥æ ‡æ³¨çš„ä¾èµ–ï¼Œæé«˜åˆ†ç±»æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMsåœ¨åˆ†ç±»17ä¸ªè¯„è®ºç±»åˆ«æ—¶è¡¨ç°ä¼˜äºç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå°¤å…¶åœ¨ä½é¢‘ç±»åˆ«çš„åˆ†ç±»ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»£ç å®¡æŸ¥æ˜¯è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦å®è·µã€‚éšç€ä»£ç å®¡æŸ¥çš„è½»é‡åŒ–ï¼Œèƒ½å¤Ÿè¯†åˆ«å‡ºå¤šç§é—®é¢˜ï¼Œç”šè‡³æœ‰äº›é—®é¢˜å¯èƒ½æ˜¯å¾®ä¸è¶³é“çš„ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦ä¾èµ–äºç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œè¿™éœ€è¦å¤§é‡çš„äººå·¥æ ‡æ³¨æ¥æœ‰æ•ˆè®­ç»ƒæ¨¡å‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æ¢ç´¢äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹ä»£ç å®¡æŸ¥è¯„è®ºè¿›è¡Œåˆ†ç±»çš„æ½œåŠ›ã€‚ç ”ç©¶è¯„ä¼°äº†LLMsåœ¨17ä¸ªç±»åˆ«çš„ä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»ä¸­çš„è¡¨ç°ï¼Œç»“æœæ˜¾ç¤ºLLMsçš„åˆ†ç±»æ•ˆæœä¼˜äºç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå°¤å…¶åœ¨åˆ†ç±»äº”ä¸ªæœ€æœ‰ç”¨çš„ç±»åˆ«æ—¶è¡¨ç°æ›´ä½³ã€‚è¿™è¡¨æ˜LLMsèƒ½å¤Ÿæä¾›ä¸€ç§å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œä»¥æå‡ä»£ç å®¡æŸ¥è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»ä¸­å¯¹äººå·¥æ ‡æ³¨ä¾èµ–è¿‡é‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä½é¢‘ç±»åˆ«æ—¶è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œæœ¬æ–‡å¸Œæœ›åˆ©ç”¨å…¶å¼ºå¤§çš„è‡ªç„¶è¯­è¨€å¤„ç†èƒ½åŠ›ï¼Œå‡å°‘å¯¹ç‰¹å®šå°è®­ç»ƒæ•°æ®åˆ†å¸ƒçš„ä¾èµ–ï¼Œä»è€Œå®ç°æ›´å‡è¡¡çš„åˆ†ç±»æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆå¯¹17ä¸ªç±»åˆ«çš„ä»£ç å®¡æŸ¥è¯„è®ºè¿›è¡Œæ•°æ®æ”¶é›†ï¼Œç„¶åä½¿ç”¨LLMsè¿›è¡Œè®­ç»ƒå’Œåˆ†ç±»ï¼Œæœ€åè¯„ä¼°å…¶åˆ†ç±»æ•ˆæœä¸ç°æœ‰æ–¹æ³•çš„å¯¹æ¯”ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºä½¿ç”¨LLMsè¿›è¡Œä»£ç å®¡æŸ¥è¯„è®ºåˆ†ç±»ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨ä½é¢‘ç±»åˆ«ä¸Šçš„ä¸è¶³ï¼Œå±•ç°å‡ºæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†é€‚å½“çš„è¶…å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ï¼Œä»¥ç¡®ä¿LLMsèƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ ä¸åŒç±»åˆ«çš„ç‰¹å¾ï¼Œå…·ä½“ç»†èŠ‚åŒ…æ‹¬ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨17ä¸ªä»£ç å®¡æŸ¥è¯„è®ºç±»åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡ä¸Šè¶…è¿‡äº†ç°æœ‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨äº”ä¸ªæœ€æœ‰ç”¨çš„ç±»åˆ«ä¸­ï¼ŒLLMsçš„åˆ†ç±»å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼Œè¡¨æ˜å…¶åœ¨å¤„ç†ä½é¢‘æ•°æ®æ—¶çš„ä¼˜åŠ¿ã€‚è¿™ä¸€å‘ç°ä¸ºä»£ç å®¡æŸ¥åˆ†ææä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ä¸­çš„ä»£ç å®¡æŸ¥è‡ªåŠ¨åŒ–ã€ä»£ç è´¨é‡åˆ†æå’Œå¼€å‘è€…åä½œå·¥å…·ã€‚é€šè¿‡æå‡è¯„è®ºåˆ†ç±»çš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©å›¢é˜Ÿæ›´é«˜æ•ˆåœ°è¯†åˆ«å’Œè§£å†³ä»£ç é—®é¢˜ï¼Œä»è€Œæé«˜è½¯ä»¶å¼€å‘çš„æ•´ä½“è´¨é‡å’Œæ•ˆç‡ã€‚æœªæ¥ï¼ŒLLMsçš„åº”ç”¨å¯èƒ½ä¼šæ‰©å±•åˆ°å…¶ä»–é¢†åŸŸçš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Code review is a crucial practice in software development. As code review nowadays is lightweight, various issues can be identified, and sometimes, they can be trivial. Research has investigated automated approaches to classify review comments to gauge the effectiveness of code reviews. However, previous studies have primarily relied on supervised machine learning, which requires extensive manual annotation to train the models effectively. To address this limitation, we explore the potential of using Large Language Models (LLMs) to classify code review comments. We assess the performance of LLMs to classify 17 categories of code review comments. Our results show that LLMs can classify code review comments, outperforming the state-of-the-art approach using a trained deep learning model. In particular, LLMs achieve better accuracy in classifying the five most useful categories, which the state-of-the-art approach struggles with due to low training examples. Rather than relying solely on a specific small training data distribution, our results show that LLMs provide balanced performance across high- and low-frequency categories. These results suggest that the LLMs could offer a scalable solution for code review analytics to improve the effectiveness of the code review process.

