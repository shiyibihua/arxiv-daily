---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-06-23
---

# cs.AIï¼ˆ2025-06-23ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (7)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250618902v3-jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-.html">jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval</a></td>
  <td>æå‡ºjina-embeddings-v4ä»¥è§£å†³å¤šæ¨¡æ€å¤šè¯­è¨€æ£€ç´¢é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18902v3" data-paper-url="./papers/250618902v3-jina-embeddings-v4-universal-embeddings-for-multimodal-multilingual-.html" onclick="toggleFavorite(this, '2506.18902v3', 'jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250618777v1-programming-by-backprop-llms-acquire-reusable-algorithmic-abstractio.html">Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training</a></td>
  <td>æå‡ºç¼–ç¨‹åå‘ä¼ æ’­æ–¹æ³•ä»¥æå‡LLMsçš„ç®—æ³•æŠ½è±¡èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18777v1" data-paper-url="./papers/250618777v1-programming-by-backprop-llms-acquire-reusable-algorithmic-abstractio.html" onclick="toggleFavorite(this, '2506.18777v1', 'Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250618510v1-smooth-operators-llms-translating-imperfect-hints-into-disfluency-ri.html">Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts</a></td>
  <td>æå‡ºä¸€ç§æ–°æ–¹æ³•å°†ä¸å®Œç¾æç¤ºè½¬åŒ–ä¸ºä¸°å¯Œçš„å£è¯­è½¬å½•</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">TAMP</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18510v1" data-paper-url="./papers/250618510v1-smooth-operators-llms-translating-imperfect-hints-into-disfluency-ri.html" onclick="toggleFavorite(this, '2506.18510v1', 'Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250618957v1-a-comment-on-the-illusion-of-thinking-reframing-the-reasoning-cliff-.html">A Comment On "The Illusion of Thinking": Reframing the Reasoning Cliff as an Agentic Gap</a></td>
  <td>é‡æ–°æ¡†æ¶åŒ–æ¨ç†å´–ï¼Œæ­ç¤ºæ™ºèƒ½æ¨¡å‹çš„æ‰§è¡Œé™åˆ¶</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18957v1" data-paper-url="./papers/250618957v1-a-comment-on-the-illusion-of-thinking-reframing-the-reasoning-cliff-.html" onclick="toggleFavorite(this, '2506.18957v1', 'A Comment On &quot;The Illusion of Thinking&quot;: Reframing the Reasoning Cliff as an Agentic Gap')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250618810v3-concisehint-boosting-efficient-reasoning-via-continuous-concise-hint.html">ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation</a></td>
  <td>æå‡ºConciseHintä»¥è§£å†³é•¿æ¨ç†è¿‡ç¨‹å†—é•¿é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18810v3" data-paper-url="./papers/250618810v3-concisehint-boosting-efficient-reasoning-via-continuous-concise-hint.html" onclick="toggleFavorite(this, '2506.18810v3', 'ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250618628v1-aggtruth-contextual-hallucination-detection-using-aggregated-attenti.html">AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs</a></td>
  <td>æå‡ºAggTruthä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¹»è§‰æ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.18628v1" data-paper-url="./papers/250618628v1-aggtruth-contextual-hallucination-detection-using-aggregated-attenti.html" onclick="toggleFavorite(this, '2506.18628v1', 'AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250701042v1-can-argus-judge-them-all-comparing-vlms-across-domains.html">Can Argus Judge Them All? Comparing VLMs Across Domains</a></td>
  <td>æ¯”è¾ƒå¤šæ¨¡æ€æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°ä»¥æå‡åº”ç”¨æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.01042v1" data-paper-url="./papers/250701042v1-can-argus-judge-them-all-comparing-vlms-across-domains.html" onclick="toggleFavorite(this, '2507.01042v1', 'Can Argus Judge Them All? Comparing VLMs Across Domains')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)