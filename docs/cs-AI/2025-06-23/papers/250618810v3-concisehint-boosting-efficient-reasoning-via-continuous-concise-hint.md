---
layout: default
title: ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation
---

# ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18810" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18810v3</a>
  <a href="https://arxiv.org/pdf/2506.18810.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18810v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18810v3', 'ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siao Tang, Xinyin Ma, Gongfan Fang, Xinchao Wang

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23 (æ›´æ–°: 2025-10-01)

**å¤‡æ³¨**: Compare with more baselines, add more in-depth analysis, and re-evaluate the GPQA-D benchmark. Codes are available at https://github.com/tsa18/ConciseHint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºConciseHintä»¥è§£å†³é•¿æ¨ç†è¿‡ç¨‹å†—é•¿é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨ç†æ¨¡å‹` `é“¾å¼æ€ç»´` `ç”Ÿæˆä¼˜åŒ–` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ•ˆç‡æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹æ¨ç†æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¾€å¾€ç”Ÿæˆå†—é•¿çš„å†…å®¹ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ï¼Œå½±å“å®é™…åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºConciseHintæ¡†æ¶ï¼Œé€šè¿‡åœ¨æ¨ç†ç”Ÿæˆè¿‡ç¨‹ä¸­æ³¨å…¥å¯å­¦ä¹ çš„æç¤ºï¼Œé¼“åŠ±æ¨¡å‹ç®€æ´è¡¨è¾¾ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒConciseHintåœ¨DeepSeek-R1å’ŒQwen-3ç³»åˆ—æ¨¡å‹ä¸Šæœ‰æ•ˆæå‡äº†æ¨ç†çš„ç®€æ´æ€§ä¸æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåƒDeepSeek-R1å’ŒOpenAI o1ç³»åˆ—ç­‰å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä¸»è¦å¾—ç›Šäºé“¾å¼æ€ç»´ï¼ˆCoTï¼‰ç”Ÿæˆé•¿åº¦çš„å¢åŠ ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å¾€å¾€ç”Ÿæˆå†—é•¿çš„æ¨ç†è¿‡ç¨‹ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚ç°æœ‰æ–‡çŒ®ä¸»è¦é›†ä¸­åœ¨æ¨ç†å‰çš„æ”¹è¿›æ–¹æ³•ï¼Œå¦‚æç¤ºå’Œæ¨ç†æˆ–å¾®è°ƒå’Œæ¨ç†ï¼Œä½†å¿½è§†äº†åœ¨æ¨ç†ç”Ÿæˆè¿‡ç¨‹ä¸­ç›´æ¥é¼“åŠ±æ¨¡å‹ç®€æ´è¡¨è¾¾çš„æ–¹å‘ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºConciseHintçš„æ¡†æ¶ï¼Œé€šè¿‡åœ¨æ¨ç†ç”Ÿæˆè¿‡ç¨‹ä¸­æ³¨å…¥å¯å­¦ä¹ çš„æç¤ºï¼ˆæ‰‹åŠ¨è®¾è®¡æˆ–åœ¨ç®€æ´æ•°æ®ä¸Šå­¦ä¹ ï¼‰æ¥æŒç»­é¼“åŠ±æ¨ç†æ¨¡å‹ç®€æ´è¡¨è¾¾ã€‚æ­¤å¤–ï¼ŒConciseHintèƒ½å¤Ÿæ ¹æ®æŸ¥è¯¢çš„å¤æ‚æ€§è‡ªé€‚åº”è°ƒæ•´æç¤ºå¼ºåº¦ï¼Œç¡®ä¿ä¸ä¼šå½±å“æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆç”Ÿæˆç®€æ´çš„æ¨ç†ï¼ŒåŒæ—¶ä¿æŒè‰¯å¥½çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹æ¨ç†æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­äº§ç”Ÿå†—é•¿æ¨ç†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æ¨ç†å‰çš„æ”¹è¿›ï¼Œæœªèƒ½æœ‰æ•ˆè§£å†³ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å†—é•¿ç°è±¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºConciseHintæ¡†æ¶ï¼Œé€šè¿‡åœ¨æ¨ç†ç”Ÿæˆè¿‡ç¨‹ä¸­æ³¨å…¥å¯å­¦ä¹ çš„æç¤ºï¼ŒæŒç»­é¼“åŠ±æ¨¡å‹ç”Ÿæˆç®€æ´çš„æ¨ç†å†…å®¹ã€‚æ­¤è®¾è®¡æ—¨åœ¨æé«˜æ¨ç†æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šConciseHintæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæç¤ºç”Ÿæˆæ¨¡å—å’Œæ¨ç†ç”Ÿæˆæ¨¡å—ã€‚æç¤ºç”Ÿæˆæ¨¡å—è´Ÿè´£ç”Ÿæˆé€‚åº”æ€§æç¤ºï¼Œè€Œæ¨ç†ç”Ÿæˆæ¨¡å—åˆ™åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åº”ç”¨è¿™äº›æç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šConciseHintçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶åœ¨æ¨ç†ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ¨æ€æ³¨å…¥æç¤ºï¼Œç›´æ¥å½±å“ç”Ÿæˆå†…å®¹çš„ç®€æ´æ€§ã€‚è¿™ä¸ä¼ ç»Ÿçš„æ¨ç†å‰æ”¹è¿›æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºç”Ÿæˆæ¨¡å—ä¸­ï¼Œæç¤ºçš„å¼ºåº¦æ˜¯æ ¹æ®æŸ¥è¯¢çš„å¤æ‚æ€§è‡ªé€‚åº”è°ƒæ•´çš„ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†ç”Ÿæˆå†…å®¹çš„ç®€æ´æ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒConciseHintåœ¨DeepSeek-R1å’ŒQwen-3ç³»åˆ—æ¨¡å‹ä¸Šç”Ÿæˆçš„æ¨ç†å†…å®¹æ˜¾è‘—æ›´ä¸ºç®€æ´ï¼Œä¸”åœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶ï¼Œæ¨ç†æ•ˆç‡æå‡äº†çº¦20%ã€‚ä¸åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒConciseHintå±•ç°å‡ºæ›´ä¼˜çš„ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–æ¨ç†ç­‰ã€‚é€šè¿‡æé«˜æ¨ç†æ•ˆç‡ï¼ŒConciseHintèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­èŠ‚çœè®¡ç®—èµ„æºï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and OpenAI o1 series have achieved notable performance enhancements on complex reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT). However, a critical issue is their tendency to produce excessively verbose reasoning processes, leading to the inefficiency problem. Existing literature on improving efficiency mainly adheres to the before-reasoning paradigms such as prompting and reasoning or fine-tuning and reasoning, but ignores the promising direction of directly encouraging the model to speak concisely by intervening during the generation of reasoning. In order to fill the blank, we propose a framework dubbed ConciseHint, which continuously encourages the reasoning model to speak concisely by injecting learnable hints (manually designed or learned on concise data) during the generation of the reasoning. Besides, ConciseHint is adaptive to the complexity of the query by adaptively adjusting the hint intensity, which ensures it will not undermine model performance. Experiments on the state-of-the-art LRMs, including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can effectively produce concise reasoning while maintaining the performance well. Moreover, we show that ConciseHint is flexible and can be seamlessly integrated with existing methods to further push the upper bound of the efficiency.

