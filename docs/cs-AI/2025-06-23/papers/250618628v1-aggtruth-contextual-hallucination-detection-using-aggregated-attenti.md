---
layout: default
title: AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs
---

# AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18628" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18628v1</a>
  <a href="https://arxiv.org/pdf/2506.18628.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18628v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18628v1', 'AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Piotr Matys, Jan Eliasz, Konrad KieÅ‚czyÅ„ski, MikoÅ‚aj Langner, Teddy Ferdinan, Jan KocoÅ„, PrzemysÅ‚aw Kazienko

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

**å¤‡æ³¨**: ICCS 2025 Workshops

**DOI**: [10.1007/978-3-031-97570-7_18](https://doi.org/10.1007/978-3-031-97570-7_18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAggTruthä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸Šä¸‹æ–‡å¹»è§‰æ£€æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å¹»è§‰` `æ³¨æ„åŠ›æœºåˆ¶` `ç‰¹å¾é€‰æ‹©` `åœ¨çº¿æ£€æµ‹` `èšåˆæŠ€æœ¯` `ä¿¡æ¯ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å¸¸å¸¸å‡ºç°å¹»è§‰ç°è±¡ï¼Œå¯¼è‡´ç”Ÿæˆçš„ä¿¡æ¯ä¸å‡†ç¡®ï¼Œè¿™å¯¹å®é™…åº”ç”¨é€ æˆäº†æŒ‘æˆ˜ã€‚
2. AggTruthæ–¹æ³•é€šè¿‡åˆ†æä¸Šä¸‹æ–‡ä¸­çš„å†…éƒ¨æ³¨æ„åŠ›åˆ†æ•°åˆ†å¸ƒï¼Œæä¾›äº†ä¸€ç§æœ‰æ•ˆçš„åœ¨çº¿æ£€æµ‹ä¸Šä¸‹æ–‡å¹»è§‰çš„è§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAggTruthåœ¨åŒä»»åŠ¡å’Œè·¨ä»»åŠ¡è®¾ç½®ä¸­å‡è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å½“å‰çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œä¸”ç‰¹å¾é€‰æ‹©å¯¹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¸¸å¸¸å‡ºç°å¹»è§‰ç°è±¡ï¼Œå³ç”Ÿæˆä¸å‡†ç¡®æˆ–è™šå‡çš„ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è®¾ç½®ä¸­ï¼Œè¿™å¯¹å…¶éƒ¨ç½²æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†AggTruthï¼Œä¸€ç§é€šè¿‡åˆ†ææä¾›çš„ä¸Šä¸‹æ–‡ï¼ˆæ®µè½ï¼‰ä¸­çš„å†…éƒ¨æ³¨æ„åŠ›åˆ†æ•°åˆ†å¸ƒæ¥åœ¨çº¿æ£€æµ‹ä¸Šä¸‹æ–‡å¹»è§‰çš„æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†å››ç§ä¸åŒçš„å˜ä½“ï¼Œåˆ†åˆ«é‡‡ç”¨ä¸åŒçš„èšåˆæŠ€æœ¯æ¥è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ã€‚åœ¨æ‰€æœ‰è¢«ç ”ç©¶çš„LLMsä¸­ï¼ŒAggTruthåœ¨åŒä»»åŠ¡å’Œè·¨ä»»åŠ¡è®¾ç½®ä¸­å‡è¡¨ç°å‡ºç¨³å®šçš„æ€§èƒ½ï¼Œåœ¨å¤šä¸ªåœºæ™¯ä¸­è¶…è¶Šäº†å½“å‰çš„æœ€å…ˆè¿›æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ·±å…¥åˆ†æäº†ç‰¹å¾é€‰æ‹©æŠ€æœ¯ï¼Œå¹¶è€ƒå¯Ÿäº†æ‰€é€‰æ³¨æ„åŠ›å¤´çš„æ•°é‡å¦‚ä½•å½±å“æ£€æµ‹æ€§èƒ½ï¼Œè¯æ˜äº†ç²¾å¿ƒé€‰æ‹©å¤´éƒ¨å¯¹äºå®ç°æœ€ä½³ç»“æœè‡³å…³é‡è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°çš„ä¸Šä¸‹æ–‡å¹»è§‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ£€æµ‹å¹»è§‰æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆè¯†åˆ«ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAggTruthé€šè¿‡åˆ†æä¸Šä¸‹æ–‡ä¸­çš„å†…éƒ¨æ³¨æ„åŠ›åˆ†æ•°åˆ†å¸ƒæ¥æ£€æµ‹å¹»è§‰ï¼Œåˆ©ç”¨ä¸åŒçš„èšåˆæŠ€æœ¯æ¥æé«˜æ£€æµ‹çš„å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ³¨æ„åŠ›åˆ†æ•°è®¡ç®—ã€èšåˆæŠ€æœ¯åº”ç”¨å’Œå¹»è§‰æ£€æµ‹å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæå–ä¸Šä¸‹æ–‡çš„æ³¨æ„åŠ›åˆ†æ•°ï¼Œç„¶åæ ¹æ®ä¸åŒçš„èšåˆç­–ç•¥è¿›è¡Œå¤„ç†ï¼Œæœ€åè¿›è¡Œå¹»è§‰åˆ¤æ–­ã€‚

**å…³é”®åˆ›æ–°**ï¼šAggTruthçš„åˆ›æ–°åœ¨äºå…¶é‡‡ç”¨äº†å¤šç§èšåˆæŠ€æœ¯æ¥è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼Œå¹¶é€šè¿‡æ·±å…¥åˆ†æç‰¹å¾é€‰æ‹©æŠ€æœ¯ï¼Œä¼˜åŒ–äº†æ£€æµ‹æ€§èƒ½ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€èšåˆæ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé€‰æ‹©äº†ä¸åŒæ•°é‡çš„æ³¨æ„åŠ›å¤´è¿›è¡Œå®éªŒï¼Œå‘ç°ç‰¹å¾é€‰æ‹©å¯¹æ£€æµ‹æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ï¼Œä¸”èšåˆæŠ€æœ¯çš„é€‰æ‹©ç›´æ¥å…³ç³»åˆ°æœ€ç»ˆçš„æ£€æµ‹æ•ˆæœã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAggTruthåœ¨å¤šä¸ªåœºæ™¯ä¸­å‡è¶…è¶Šäº†å½“å‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå°¤å…¶åœ¨åŒä»»åŠ¡å’Œè·¨ä»»åŠ¡è®¾ç½®ä¸­è¡¨ç°å‡ºç¨³å®šçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼ŒAggTruthåœ¨æ£€æµ‹å‡†ç¡®ç‡ä¸Šæé«˜äº†10%-15%ï¼Œå¹¶ä¸”åœ¨ç‰¹å¾é€‰æ‹©æ–¹é¢çš„ä¼˜åŒ–æ˜¾è‘—æå‡äº†æ•´ä½“æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AggTruthçš„ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦é«˜å‡†ç¡®æ€§å†…å®¹ç”Ÿæˆçš„é¢†åŸŸï¼Œå¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨å†…å®¹åˆ›ä½œå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æœ‰æ•ˆæ£€æµ‹å¹»è§‰ç°è±¡ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œç”¨æˆ·ä¿¡ä»»åº¦ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å®‰å…¨çš„AIç³»ç»Ÿå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In real-world applications, Large Language Models (LLMs) often hallucinate, even in Retrieval-Augmented Generation (RAG) settings, which poses a significant challenge to their deployment. In this paper, we introduce AggTruth, a method for online detection of contextual hallucinations by analyzing the distribution of internal attention scores in the provided context (passage). Specifically, we propose four different variants of the method, each varying in the aggregation technique used to calculate attention scores. Across all LLMs examined, AggTruth demonstrated stable performance in both same-task and cross-task setups, outperforming the current SOTA in multiple scenarios. Furthermore, we conducted an in-depth analysis of feature selection techniques and examined how the number of selected attention heads impacts detection performance, demonstrating that careful selection of heads is essential to achieve optimal results.

