---
layout: default
title: On the Fundamental Impossibility of Hallucination Control in Large Language Models
---

# On the Fundamental Impossibility of Hallucination Control in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06382" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06382v7</a>
  <a href="https://arxiv.org/pdf/2506.06382.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06382v7" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06382v7', 'On the Fundamental Impossibility of Hallucination Control in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: MichaÅ‚ P. Karpowicz

**åˆ†ç±»**: stat.ML, cs.AI, cs.CL, cs.GT, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04 (æ›´æ–°: 2025-10-15)

**å¤‡æ³¨**: Mathematics debugged: added examples, corrected transformer example, re-edited, typos removed

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸å¯é¿å…çš„å¹»è§‰æ§åˆ¶æƒè¡¡ç†è®ºä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `çŸ¥è¯†èšåˆ` `å¹»è§‰æ§åˆ¶` `ä¿¡æ¯ä¿ç•™` `æ¨ç†æ¨¡å‹` `è¯­ä¹‰ä¿¡æ¯åº¦é‡` `æœºåˆ¶è®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†èšåˆæ—¶é¢ä¸´çœŸå®æ€§ä¸åˆ›é€ æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œæ— æ³•åŒæ—¶æ»¡è¶³æ‰€æœ‰åŸºæœ¬å±æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡é€šè¿‡å»ºç«‹æ•°å­¦æ¨¡å‹ï¼Œåˆ†ææ¨ç†è¿‡ç¨‹ä¸­çš„ä¿¡æ¯èšåˆï¼Œæå‡ºäº†æ–°çš„è¯­ä¹‰ä¿¡æ¯åº¦é‡å’Œå‡ºç°ç®—å­ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶ç»“æœæ­ç¤ºäº†å¹»è§‰ä¸æƒ³è±¡çš„æ•°å­¦åŒè´¨æ€§ï¼Œå¹¶ä¸ºä¼˜åŒ–AIç³»ç»Ÿä¸­çš„å¹»è§‰æƒè¡¡æä¾›äº†ç†è®ºåŸºç¡€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡å»ºç«‹äº†ä¸€ä¸ªåŸºæœ¬çš„ä¸å¯èƒ½æ€§å®šç†ï¼šä»»ä½•æ‰§è¡Œéå¹³å‡¡çŸ¥è¯†èšåˆçš„å¤§è¯­è¨€æ¨¡å‹æ— æ³•åŒæ—¶å®ç°çœŸå®çŸ¥è¯†è¡¨ç¤ºã€è¯­ä¹‰ä¿¡æ¯ä¿ç•™ã€ç›¸å…³çŸ¥è¯†çš„å®Œå…¨æ­ç¤ºå’ŒçŸ¥è¯†çº¦æŸçš„æœ€ä¼˜æ€§ã€‚è¿™ä¸€ä¸å¯èƒ½æ€§æºäºä¿¡æ¯èšåˆçš„æ•°å­¦ç»“æ„ï¼Œè€Œéå·¥ç¨‹é™åˆ¶ã€‚æˆ‘ä»¬é€šè¿‡å°†æ¨ç†å»ºæ¨¡ä¸ºæ€æƒ³çš„æ‹å–ï¼Œè¯æ˜äº†è¿™ä¸€ç‚¹ã€‚è®ºæ–‡å¼•å…¥äº†è¯­ä¹‰ä¿¡æ¯åº¦é‡å’Œå‡ºç°ç®—å­ï¼Œä»¥åˆ†æè®¡ç®—å—é™å’Œä¸å—é™çš„æ¨ç†ï¼Œæå‡ºäº†ä¿å®ˆæ¨ç†ä¸ä¿¡æ¯ä¿ç•™çš„äºŒåˆ†æ³•ã€‚æˆ‘ä»¬çš„æ¡†æ¶è¡¨æ˜å¹»è§‰ä¸æƒ³è±¡åœ¨æ•°å­¦ä¸Šæ˜¯ç›¸åŒçš„ï¼Œä¸”å‡è¿åè‡³å°‘ä¸€ä¸ªåŸºæœ¬å±æ€§ã€‚è¿™äº›ç»“æœä¸ºç®¡ç†AIç³»ç»Ÿä¸­çš„å¹»è§‰æƒè¡¡æä¾›äº†åŸåˆ™åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†èšåˆè¿‡ç¨‹ä¸­æ— æ³•åŒæ—¶å®ç°çœŸå®æ€§ã€ä¿¡æ¯ä¿ç•™ã€çŸ¥è¯†æ­ç¤ºå’Œæœ€ä¼˜æ€§çš„æ ¹æœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›å±æ€§æ—¶å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å°†æ¨ç†è§†ä¸ºæ€æƒ³çš„æ‹å–ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£ä¿¡æ¯èšåˆçš„æ•°å­¦ç»“æ„ï¼Œå¼ºè°ƒäº†å¹»è§‰ä¸æƒ³è±¡çš„æ•°å­¦åŒè´¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæœºåˆ¶è®¾è®¡ï¼ˆä½¿ç”¨Green-Laffontå®šç†ï¼‰ã€é€‚å½“è¯„åˆ†è§„åˆ™ï¼ˆSavageç†è®ºï¼‰å’Œå˜æ¢å™¨æ¶æ„åˆ†æï¼ˆlog-sum-expå‡¸æ€§ï¼‰ã€‚è¿™äº›æ¨¡å—å…±åŒæ”¯æŒå¯¹æ¨ç†è¿‡ç¨‹çš„æ·±å…¥åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†è¯­ä¹‰ä¿¡æ¯åº¦é‡å’Œå‡ºç°ç®—å­ï¼Œæ­ç¤ºäº†ä¿å®ˆæ¨ç†ä¸ä¿¡æ¯ä¿ç•™ä¹‹é—´çš„äºŒåˆ†æ³•ï¼Œæä¾›äº†å¯¹å¹»è§‰ä¸æƒ³è±¡çš„ç»Ÿä¸€ç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡æ¢è®¨äº†æ¨ç†è¿‡ç¨‹ä¸­çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•é‡åŒ–å˜æ¢å™¨æ³¨æ„åŠ›ä¸­çš„Jensenå·®è·ï¼Œä»¥è¯„ä¼°è¶…å‡ºæ„æˆè¯æ®çš„è¿‡åº¦ä¿¡å¿ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå¹»è§‰ä¸æƒ³è±¡åœ¨æ•°å­¦ä¸Šæ˜¯ç­‰åŒçš„ï¼Œä¸”å‡è¿åè‡³å°‘ä¸€ä¸ªåŸºæœ¬å±æ€§ã€‚é€šè¿‡å¼•å…¥æ–°çš„è¯­ä¹‰ä¿¡æ¯åº¦é‡ï¼Œè®ºæ–‡ä¸ºAIç³»ç»Ÿä¸­çš„å¹»è§‰æƒè¡¡æä¾›äº†ç†è®ºåŸºç¡€ï¼Œæ¨åŠ¨äº†ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’ŒçŸ¥è¯†ç®¡ç†ç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¹»è§‰æ§åˆ¶çš„æƒè¡¡ï¼ŒAIç³»ç»Ÿå¯ä»¥åœ¨ç‰¹å®šåº”ç”¨ä¸­å®ç°æ›´é«˜çš„åˆ›é€ æ€§ä¸çœŸå®æ€§å¹³è¡¡ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ•ˆèƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper establishes a fundamental Impossibility Theorem: no LLM performing non-trivial knowledge aggregation can simultaneously achieve truthful knowledge representation, semantic information conservation, complete revelation of relevant knowledge, and knowledge-constrained optimality. This impossibility stems from the mathematical structure of information aggregation, not from engineering limitations.
>   We prove this by modeling inference as an auction of ideas, where distributed components compete to influence responses using their encoded knowledge. The proof employs three independent approaches: mechanism design (Green-Laffont theorem), proper scoring rules (Savage), and transformer architecture analysis (log-sum-exp convexity).
>   We introduce the semantic information measure and the emergence operator to analyze computationally bounded and unbounded reasoning. Bounded reasoning makes latent information accessible, enabling gradual insights and creativity, while unbounded reasoning makes all derivable knowledge immediately accessible while preserving the semantic content. We prove the conservation-reasoning dichotomy: meaningful reasoning necessarily violates information conservation.
>   Our framework suggests that hallucination and imagination are mathematically identical, and both violate at least one of the four essential properties. The Jensen gap in transformer attention quantifies this violation as excess confidence beyond constituent evidence. This unified view explains why capable models must balance truthfulness against creativity.
>   These results provide principled foundations for managing hallucination trade-offs in AI systems. Rather than eliminating hallucination, we should optimize these inevitable trade-offs for specific applications. We conclude with philosophical implications connecting the impossibility to fundamental limits of reason.

