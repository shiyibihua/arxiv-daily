---
layout: default
title: Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification
---

# Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23298" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.23298v3</a>
  <a href="https://arxiv.org/pdf/2506.23298.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23298v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23298v3', 'Exposing and Mitigating Calibration Biases and Demographic Unfairness in MLLM Few-Shot In-Context Learning for Medical Image Classification')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xing Shen, Justin Szeto, Mingyang Li, Hengguan Huang, Tal Arbel

**ÂàÜÁ±ª**: eess.IV, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-29 (Êõ¥Êñ∞: 2025-07-17)

**Â§áÊ≥®**: Preprint version. The peer-reviewed version of this paper has been accepted to MICCAI 2025 main conference

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/xingbpshen/medical-calibration-fairness-mllm)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CALIN‰ª•Ëß£ÂÜ≥ÂåªÁñóÂõæÂÉèÂàÜÁ±ª‰∏≠ÁöÑÊ†°ÂáÜÂÅèÂ∑Æ‰∏é‰∫∫Âè£‰∏çÂÖ¨Âπ≥ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂåªÁñóÂõæÂÉèÂàÜÁ±ª` `Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Ê†°ÂáÜÂÅèÂ∑Æ` `‰∫∫Âè£‰∏çÂÖ¨Âπ≥ÊÄß` `Â∞ëÊ†∑Êú¨Â≠¶‰π†` `Êé®ÁêÜÊó∂Ê†°ÂáÜ` `ÂÖ¨Âπ≥ÊÄß` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÁñóÂõæÂÉèÂàÜÁ±ª‰∏≠Â≠òÂú®Ê†°ÂáÜÂÅèÂ∑ÆÂíå‰∫∫Âè£‰∏çÂÖ¨Âπ≥ÊÄßÁöÑÈóÆÈ¢òÔºåÂΩ±Âìç‰∫ÜÂÖ∂‰∏¥Â∫äÂ∫îÁî®ÁöÑÂÆâÂÖ®ÊÄß„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫ÁöÑCALINÊñπÊ≥ïÈÄöËøáÂèåÂ±ÇÁ®ãÂ∫èÂú®Êé®ÁêÜÊó∂Ê†°ÂáÜÁΩÆ‰ø°ÂàÜÊï∞ÔºåÊó®Âú®ÂáèËΩªÊ®°ÂûãÁöÑÂÅèÂ∑ÆÂπ∂ÊèêÈ´òÈ¢ÑÊµãÂáÜÁ°ÆÊÄß„ÄÇ
3. Âú®‰∏â‰∏™ÂåªÁñóÂΩ±ÂÉèÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåCALINÊúâÊïàÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÔºåÂπ∂Á°Æ‰øù‰∫ÜÂÖ¨Âπ≥ÁöÑÁΩÆ‰ø°Ê†°ÂáÜ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®ÂåªÁñóÂõæÂÉèÂàÜÊûê‰∏≠ÁöÑÂ∞ëÊ†∑Êú¨‰∏ä‰∏ãÊñáÂ≠¶‰π†‰∏≠Â±ïÁé∞Âá∫Â∑®Â§ßÊΩúÂäõ„ÄÇÁÑ∂ËÄåÔºåÂ∞ÜËøô‰∫õÊ®°ÂûãÂÆâÂÖ®Âú∞Â∫îÁî®‰∫é‰∏¥Â∫äÂÆûË∑µÈúÄË¶ÅÊ∑±ÂÖ•ÂàÜÊûêÂÖ∂È¢ÑÊµãÂáÜÁ°ÆÊÄßÂèäÁõ∏ÂÖ≥ÁöÑÊ†°ÂáÜËØØÂ∑ÆÔºåÂ∞§ÂÖ∂ÊòØÂú®‰∏çÂêå‰∫∫Âè£Â≠êÁæ§‰Ωì‰∏≠„ÄÇÊú¨Á†îÁ©∂È¶ñÊ¨°Êé¢ËÆ®‰∫ÜMLLMsÂú®ÂåªÁñóÂõæÂÉèÂàÜÁ±ª‰∏≠ÁöÑÊ†°ÂáÜÂÅèÂ∑ÆÂíå‰∫∫Âè£‰∏çÂÖ¨Âπ≥ÊÄß„ÄÇÊàë‰ª¨ÊèêÂá∫‰∫ÜCALINÔºå‰∏ÄÁßçÊé®ÁêÜÊó∂Ê†°ÂáÜÊñπÊ≥ïÔºåÊó®Âú®ÂáèËΩªÁõ∏ÂÖ≥ÂÅèÂ∑Æ„ÄÇCALINÈÄöËøáÂèåÂ±ÇÁ®ãÂ∫è‰º∞ËÆ°ÊâÄÈúÄÁöÑÊ†°ÂáÜÈáèÔºåÂπ∂Âú®Êé®ÁêÜËøáÁ®ã‰∏≠Â∫îÁî®ËØ•‰º∞ËÆ°‰ª•Ê†°ÂáÜÈ¢ÑÊµãÁöÑÁΩÆ‰ø°ÂàÜÊï∞„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCALINÂú®Á°Æ‰øùÂÖ¨Âπ≥ÁΩÆ‰ø°Ê†°ÂáÜÁöÑÂêåÊó∂ÔºåÊèêÈ´ò‰∫ÜÊï¥‰ΩìÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÔºåÂπ∂Â±ïÁé∞Âá∫ÊúÄÂ∞èÁöÑÂÖ¨Âπ≥-ÊïàÁî®ÊùÉË°°„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÁñóÂõæÂÉèÂàÜÁ±ª‰∏≠Â≠òÂú®ÁöÑÊ†°ÂáÜÂÅèÂ∑ÆÂíå‰∫∫Âè£‰∏çÂÖ¨Âπ≥ÊÄßÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÊúâÊïàÂ§ÑÁêÜ‰∏çÂêå‰∫∫Âè£Â≠êÁæ§‰ΩìÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÁΩÆ‰ø°Â∫¶Ê†°ÂáÜÔºåÂØºËá¥‰∏¥Â∫äÂ∫îÁî®ÁöÑÂÆâÂÖ®ÊÄßÂèóÂà∞ÂΩ±Âìç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöCALINÊñπÊ≥ïÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊé®ÁêÜÊó∂ÁöÑÊ†°ÂáÜÊù•ÂáèËΩªÊ®°ÂûãÁöÑÂÅèÂ∑Æ„ÄÇÂÆÉÈááÁî®ÂèåÂ±ÇÁ®ãÂ∫èÔºåÈ¶ñÂÖàÂú®Áæ§‰ΩìÂ±ÇÈù¢‰º∞ËÆ°ÊâÄÈúÄÁöÑÊ†°ÂáÜÈáèÔºåÁÑ∂ÂêéÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Â∫îÁî®ËØ•Ê†°ÂáÜÔºå‰ª•ÊèêÈ´òÁΩÆ‰ø°ÂàÜÊï∞ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöCALINÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÈ¶ñÂÖàÊòØ‰ªé‰∫∫Âè£Â±ÇÈù¢Âà∞Â≠êÁæ§‰ΩìÂ±ÇÈù¢ÁöÑÊ†°ÂáÜÈáè‰º∞ËÆ°ÔºåÂÖ∂Ê¨°ÊòØÂú®Êé®ÁêÜËøáÁ®ã‰∏≠Â∫îÁî®ËØ•‰º∞ËÆ°ËøõË°åÁΩÆ‰ø°ÂàÜÊï∞ÁöÑÊ†°ÂáÜ„ÄÇËØ•ÊñπÊ≥ïÁ°Æ‰øù‰∫Ü‰∏çÂêåÂ≠êÁæ§‰ΩìÁöÑÂÖ¨Âπ≥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöCALINÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ÂèåÂ±ÇÊ†°ÂáÜÁ®ãÂ∫èÔºåËÉΩÂ§üÂú®Êé®ÁêÜÊó∂Âä®ÊÄÅË∞ÉÊï¥ÁΩÆ‰ø°ÂàÜÊï∞ÁöÑÊ†°ÂáÜÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊ®°ÂûãÂú®‰∏çÂêå‰∫∫Âè£Â≠êÁæ§‰Ωì‰∏≠ÁöÑÂÖ¨Âπ≥ÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÈùôÊÄÅÊ†°ÂáÜÁ≠ñÁï•ÂΩ¢Êàê‰∫ÜÈ≤úÊòéÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏äÔºåCALIN‰ΩøÁî®‰∫ÜÊ†°ÂáÜÁü©ÈòµÊù•Ë°®Á§∫ÊâÄÈúÄÁöÑÊ†°ÂáÜÈáèÔºåÂπ∂ÈÄöËøá‰ºòÂåñÁÆóÊ≥ïËøõË°åÂèÇÊï∞ËÆæÁΩÆ„ÄÇÊ≠§Â§ñÔºåÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ËÄÉËôë‰∫ÜÂÖ¨Âπ≥ÊÄß‰∏éÊïàÁî®‰πãÈó¥ÁöÑÊùÉË°°ÔºåÁ°Æ‰øù‰∫ÜÊ®°ÂûãÂú®‰∏çÂêåÂ≠êÁæ§‰Ωì‰∏≠ÁöÑË°®Áé∞‰∏ÄËá¥ÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåCALINÂú®‰∏â‰∏™ÂåªÁñóÂΩ±ÂÉèÊï∞ÊçÆÈõÜ‰∏äÂùáÊòæËëóÊèêÈ´ò‰∫ÜÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÔºåÂÖ∑‰ΩìË°®Áé∞‰∏∫Âú®PAPILAÊï∞ÊçÆÈõÜ‰∏äÂáÜÁ°ÆÁéáÊèêÂçá‰∫ÜX%ÔºåÂú®HAM10000Êï∞ÊçÆÈõÜ‰∏äÊèêÂçá‰∫ÜY%ÔºåÂú®MIMIC-CXRÊï∞ÊçÆÈõÜ‰∏äÊèêÂçá‰∫ÜZ%„ÄÇÂêåÊó∂ÔºåCALINÁ°Æ‰øù‰∫ÜÁΩÆ‰ø°Ê†°ÂáÜÁöÑÂÖ¨Âπ≥ÊÄßÔºåÊúÄÂ∞èÂåñ‰∫ÜÂÖ¨Âπ≥-ÊïàÁî®ÁöÑÊùÉË°°„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÁñóÂõæÂÉèÂàÜÊûê„ÄÅ‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü‰ª•ÂèäÂÖ∂‰ªñÈúÄË¶ÅÈ´òÂáÜÁ°ÆÊÄßÂíåÂÖ¨Âπ≥ÊÄßÁöÑAIÂ∫îÁî®„ÄÇÈÄöËøáÊèêÈ´òÊ®°ÂûãÁöÑÊ†°ÂáÜÊÄßÂíåÂÖ¨Âπ≥ÊÄßÔºåCALINËÉΩÂ§ü‰øÉËøõÂ§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂÆûÈôÖÂåªÁñóÂú∫ÊôØ‰∏≠ÁöÑÂÆâÂÖ®ÈÉ®ÁΩ≤ÔºåËøõËÄåÊèêÂçáÊÇ£ËÄÖÁöÑËØäÁñó‰ΩìÈ™åÂíåÁªìÊûú„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal large language models (MLLMs) have enormous potential to perform few-shot in-context learning in the context of medical image analysis. However, safe deployment of these models into real-world clinical practice requires an in-depth analysis of the accuracies of their predictions, and their associated calibration errors, particularly across different demographic subgroups. In this work, we present the first investigation into the calibration biases and demographic unfairness of MLLMs' predictions and confidence scores in few-shot in-context learning for medical image classification. We introduce CALIN, an inference-time calibration method designed to mitigate the associated biases. Specifically, CALIN estimates the amount of calibration needed, represented by calibration matrices, using a bi-level procedure: progressing from the population level to the subgroup level prior to inference. It then applies this estimation to calibrate the predicted confidence scores during inference. Experimental results on three medical imaging datasets: PAPILA for fundus image classification, HAM10000 for skin cancer classification, and MIMIC-CXR for chest X-ray classification demonstrate CALIN's effectiveness at ensuring fair confidence calibration in its prediction, while improving its overall prediction accuracies and exhibiting minimum fairness-utility trade-off. Our codebase can be found at https://github.com/xingbpshen/medical-calibration-fairness-mllm.

