---
layout: default
title: From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows
---

# From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23260" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23260v2</a>
  <a href="https://arxiv.org/pdf/2506.23260.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23260v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23260v2', 'From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohamed Amine Ferrag, Norbert Tihanyi, Djallel Hamouda, Leandros Maglaras, Abderrahmane Lakas, Merouane Debbah

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-12-14)

**å¤‡æ³¨**: The paper is published in ICT Express (Elsevier)

**DOI**: [10.1016/j.icte.2025.12.001](https://doi.org/10.1016/j.icte.2025.12.001)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€å¨èƒæ¨¡å‹ä»¥è§£å†³LLMä»£ç†ç³»ç»Ÿçš„å®‰å…¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å®‰å…¨å¨èƒ` `ä»£ç†ç³»ç»Ÿ` `æ”»å‡»åˆ†ç±»` `åŠ¨æ€ä¿¡ä»»ç®¡ç†` `åŠ å¯†è¿½è¸ª` `åè®®æ¼æ´` `AIå®‰å…¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMä»£ç†ç³»ç»Ÿåœ¨å®‰å…¨æ€§ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ’ä»¶å’Œåè®®çš„å¿«é€Ÿå‘å±•ä¸‹ï¼Œå¯¼è‡´é›†æˆè„†å¼±ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¨èƒæ¨¡å‹ï¼Œç³»ç»Ÿåˆ†ç±»äº†å¤šç§æ”»å‡»æŠ€æœ¯ï¼Œå¹¶ä¸ºæ¯ç§æ”»å‡»æä¾›äº†æ­£å¼çš„å¨èƒè¡¨è¿°ã€‚
3. é€šè¿‡ä¸“å®¶è¯„å®¡å’Œä¸çœŸå®äº‹ä»¶çš„å¯¹æ¯”ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè®¾è®¡å®‰å…¨çš„AIä»£ç†ç³»ç»Ÿæä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªä¸»AIä»£ç†åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å’Œç»“æ„åŒ–åŠŸèƒ½è°ƒç”¨æ¥å£å®ç°å®æ—¶æ•°æ®æ£€ç´¢ã€è®¡ç®—å’Œå¤šæ­¥éª¤ç¼–æ’ã€‚ç„¶è€Œï¼Œæ’ä»¶ã€è¿æ¥å™¨å’Œä»£ç†é—´åè®®çš„å¿«é€Ÿå¢é•¿è¶…å‡ºäº†å®‰å…¨å®è·µçš„é€‚åº”èƒ½åŠ›ï¼Œå¯¼è‡´äº†ä¾èµ–ä¸´æ—¶èº«ä»½éªŒè¯ã€ä¸ä¸€è‡´æ¨¡å¼å’Œå¼±éªŒè¯çš„è„†å¼±é›†æˆã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„ç«¯åˆ°ç«¯å¨èƒæ¨¡å‹ï¼Œæ¶µç›–äº†ä¸»æœºåˆ°å·¥å…·å’Œä»£ç†é—´é€šä¿¡ï¼Œç³»ç»Ÿåœ°åˆ†ç±»äº†è¶…è¿‡ä¸‰åç§æ”»å‡»æŠ€æœ¯ï¼Œå¹¶æä¾›äº†æ­£å¼çš„å¨èƒè¡¨è¿°ã€‚é€šè¿‡ä¸“å®¶è¯„å®¡å’Œä¸çœŸå®äº‹ä»¶çš„äº¤å‰æ˜ å°„ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæä¾›äº†è®¾è®¡å®‰å…¨å’Œå¼¹æ€§ä»£ç†AIç³»ç»Ÿçš„å¯æ“ä½œæŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³LLMä»£ç†ç”Ÿæ€ç³»ç»Ÿä¸­å­˜åœ¨çš„å®‰å…¨å¨èƒï¼Œç°æœ‰æ–¹æ³•åœ¨åº”å¯¹å¿«é€Ÿå‘å±•çš„æ’ä»¶å’Œåè®®æ—¶æ˜¾å¾—åŠ›ä¸ä»å¿ƒï¼Œå¯¼è‡´äº†è„†å¼±çš„é›†æˆå’Œå®‰å…¨æ¼æ´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ä¸ªç»Ÿä¸€çš„ç«¯åˆ°ç«¯å¨èƒæ¨¡å‹ï¼Œæ¶µç›–ä¸»æœºåˆ°å·¥å…·å’Œä»£ç†é—´çš„é€šä¿¡ï¼Œç³»ç»Ÿåˆ†ç±»æ”»å‡»æŠ€æœ¯ï¼Œå¹¶æä¾›æ­£å¼çš„å¨èƒè¡¨è¿°ï¼Œå¸®åŠ©è¯†åˆ«å’Œç¼“è§£æ½œåœ¨é£é™©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ”»å‡»æŠ€æœ¯åˆ†ç±»ã€å¨èƒè¡¨è¿°ã€ç°æœ‰é˜²å¾¡è¯„ä¼°å’Œç¼“è§£ç­–ç•¥è®¨è®ºï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬è¾“å…¥æ“æ§ã€æ¨¡å‹å¦¥åå’Œåè®®å±‚æ¼æ´åˆ†æã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡æå‡ºäº†ä¸€ä¸ªæ•´åˆè¾“å…¥çº§æ”»å‡»ä¸åè®®å±‚æ¼æ´çš„åˆ†ç±»æ³•ï¼Œä¸ºLLMä»£ç†ç”Ÿæ€ç³»ç»Ÿçš„å®‰å…¨è®¾è®¡æä¾›äº†æ–°çš„è§†è§’å’ŒæŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ”»å‡»åˆ†ç±»ä¸­ï¼Œå®šä¹‰äº†æ”»å‡»è€…çš„èƒ½åŠ›ã€ç›®æ ‡å’Œå—å½±å“çš„ç³»ç»Ÿå±‚ï¼Œé‡‡ç”¨åŠ¨æ€ä¿¡ä»»ç®¡ç†å’ŒåŠ å¯†æ¥æºè¿½è¸ªç­‰ç­–ç•¥æ¥å¢å¼ºå®‰å…¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„å¨èƒæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å’Œåˆ†ç±»å¤šç§æ”»å‡»æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯åœ¨Prompt-to-SQLæ³¨å…¥å’Œåè®®å±‚æ¼æ´æ–¹é¢ï¼Œæ˜¾è‘—æé«˜äº†å¯¹ç°æœ‰é˜²å¾¡æªæ–½çš„è¯„ä¼°èƒ½åŠ›ï¼Œä¸ºè®¾è®¡å®‰å…¨çš„AIä»£ç†ç³»ç»Ÿæä¾›äº†å®ç”¨çš„æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èã€åŒ»ç–—å’Œæ™ºèƒ½å®¶å±…ç­‰éœ€è¦é«˜å®‰å…¨æ€§çš„AIä»£ç†ç³»ç»Ÿã€‚é€šè¿‡æä¾›ç³»ç»Ÿçš„å®‰å…¨æ¡†æ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡è¿™äº›é¢†åŸŸä¸­AIä»£ç†çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œé™ä½æ½œåœ¨çš„å®‰å…¨é£é™©ã€‚æœªæ¥ï¼Œéšç€AIæŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼Œè¯¥æ¨¡å‹å°†å¯¹å®‰å…¨è®¾è®¡äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Autonomous AI agents powered by large language models (LLMs) with structured function-calling interfaces enable real-time data retrieval, computation, and multi-step orchestration. However, the rapid growth of plugins, connectors, and inter-agent protocols has outpaced security practices, leading to brittle integrations that rely on ad-hoc authentication, inconsistent schemas, and weak validation. This survey introduces a unified end-to-end threat model for LLM-agent ecosystems, covering host-to-tool and agent-to-agent communications. We systematically categorize more than thirty attack techniques spanning input manipulation, model compromise, system and privacy attacks, and protocol-level vulnerabilities. For each category, we provide a formal threat formulation defining attacker capabilities, objectives, and affected system layers. Representative examples include Prompt-to-SQL injections and the Toxic Agent Flow exploit in GitHub MCP servers. We analyze attack feasibility, review existing defenses, and discuss mitigation strategies such as dynamic trust management, cryptographic provenance tracking, and sandboxed agent interfaces. The framework is validated through expert review and cross-mapping with real-world incidents and public vulnerability repositories, including CVE and NIST NVD. Compared to prior surveys, this work presents the first integrated taxonomy bridging input-level exploits and protocol-layer vulnerabilities in LLM-agent ecosystems, offering actionable guidance for designing secure and resilient agentic AI systems.

