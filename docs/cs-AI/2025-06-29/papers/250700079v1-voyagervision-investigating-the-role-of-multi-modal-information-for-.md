---
layout: default
title: VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems
---

# VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00079" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00079v1</a>
  <a href="https://arxiv.org/pdf/2507.00079.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00079v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00079v1', 'VoyagerVision: Investigating the Role of Multi-modal Information for Open-ended Learning Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ethan Smyth, Alessandro Suglia

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: website: https://esmyth-dev.github.io/VoyagerVision.github.io/

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://esmyth-dev.github.io/VoyagerVision.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVoyagerVisionä»¥å¢å¼ºå¼€æ”¾å¼å­¦ä¹ ç³»ç»Ÿçš„å¤šæ¨¡æ€èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼€æ”¾å¼å­¦ä¹ ` `å¤šæ¨¡æ€ä¿¡æ¯` `è§†è§‰è¾“å…¥` `ç»“æ„ç”Ÿæˆ` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç©ºé—´ç¯å¢ƒç†è§£å’Œä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ä¸Šå­˜åœ¨å±€é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç»“æ„çš„æ„å»ºä¸­è¡¨ç°ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºVoyagerVisionï¼Œé€šè¿‡ç»“åˆè§†è§‰è¾“å…¥å’Œè¯­è¨€æ¨¡å‹ï¼Œå¢å¼ºæ¨¡å‹åœ¨Minecraftä¸­åˆ›å»ºç»“æ„çš„èƒ½åŠ›ï¼Œæ‰©å±•å…¶å¼€æ”¾å¼å­¦ä¹ çš„æ½œåŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVoyagerVisionåœ¨å¹³å¦ä¸–ç•Œçš„æ„å»ºå•å…ƒæµ‹è¯•ä¸­æˆåŠŸç‡è¾¾åˆ°50%ï¼Œåœ¨å¤æ‚ç»“æ„ä¸­ä»æœ‰æå‡ç©ºé—´ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼€æ”¾å¼å­¦ä¹ æ˜¯è¿½æ±‚é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„ä¸€ä¸ªæ´»è·ƒç ”ç©¶é¢†åŸŸï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè‡ªä¸»é€‰æ‹©ä»»åŠ¡ã€‚è¿‘æœŸå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¦‚GPT-4oçš„è¿›å±•ï¼Œä½¿å¾—è¿™äº›æ¨¡å‹èƒ½å¤Ÿè§£è¯»å›¾åƒè¾“å…¥ã€‚æœ¬æ–‡æå‡ºVoyagerVisionï¼Œä¸€ä¸ªå¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿåˆ©ç”¨Minecraftä¸­çš„æˆªå›¾ä½œä¸ºè§†è§‰åé¦ˆåˆ›å»ºç»“æ„ï¼Œå±•ç¤ºäº†è§†è§‰è¾“å…¥åœ¨ç©ºé—´ç¯å¢ƒç†è§£ä¸­çš„é‡è¦æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVoyagerVisionåœ¨50æ¬¡è¿­ä»£ä¸­å¹³å‡åˆ›å»ºäº†2.75ä¸ªç‹¬ç‰¹ç»“æ„ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å¼€æ”¾å¼æ½œåŠ›ä¸Šçš„æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼€æ”¾å¼å­¦ä¹ ç³»ç»Ÿåœ¨ç©ºé—´ç¯å¢ƒç†è§£å’Œä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚ç»“æ„æ„å»ºæ–¹é¢çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¤šæ¨¡æ€ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯è§†è§‰è¾“å…¥ï¼Œå¢å¼ºæ¨¡å‹å¯¹ç¯å¢ƒçš„ç†è§£èƒ½åŠ›ï¼Œä»è€Œæå‡å…¶è‡ªä¸»é€‰æ‹©å’Œæ‰§è¡Œä»»åŠ¡çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVoyagerVisionçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰è¾“å…¥å¤„ç†æ¨¡å—ã€è¯­è¨€æ¨¡å‹è§£ææ¨¡å—å’Œç»“æ„ç”Ÿæˆæ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯åé¦ˆç³»ç»Ÿã€‚æ¨¡å‹é¦–å…ˆæ¥æ”¶Minecraftä¸­çš„æˆªå›¾ï¼Œç„¶åè§£æç¯å¢ƒä¿¡æ¯ï¼Œæœ€åç”Ÿæˆç›¸åº”çš„ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šVoyagerVisionçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†è§‰è¾“å…¥ä¸è¯­è¨€æ¨¡å‹ç»“åˆï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç»“æ„ç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œå¹¶è°ƒæ•´äº†ç½‘ç»œç»“æ„ä»¥é€‚åº”å¤šæ¨¡æ€è¾“å…¥çš„å¤„ç†éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVoyagerVisionåœ¨50æ¬¡è¿­ä»£ä¸­å¹³å‡æˆåŠŸåˆ›å»º2.75ä¸ªç‹¬ç‰¹ç»“æ„ï¼Œä¸”åœ¨å¹³å¦ä¸–ç•Œçš„æ„å»ºå•å…ƒæµ‹è¯•ä¸­æˆåŠŸç‡è¾¾åˆ°50%ã€‚ä¸ä¹‹å‰çš„Voyageræ¨¡å‹ç›¸æ¯”ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨å¤æ‚ç»“æ„çš„æ„å»ºä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®å’Œæœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹çš„å¤šæ¨¡æ€ç†è§£èƒ½åŠ›ï¼ŒVoyagerVisionå¯ä»¥åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Open-endedness is an active field of research in the pursuit of capable Artificial General Intelligence (AGI), allowing models to pursue tasks of their own choosing. Simultaneously, recent advancements in Large Language Models (LLMs) such as GPT-4o [9] have allowed such models to be capable of interpreting image inputs. Implementations such as OMNI-EPIC [4] have made use of such features, providing an LLM with pixel data of an agent's POV to parse the environment and allow it to solve tasks. This paper proposes that providing these visual inputs to a model gives it greater ability to interpret spatial environments, and as such, can increase the number of tasks it can successfully perform, extending its open-ended potential. To this aim, this paper proposes VoyagerVision -- a multi-modal model capable of creating structures within Minecraft using screenshots as a form of visual feedback, building on the foundation of Voyager. VoyagerVision was capable of creating an average of 2.75 unique structures within fifty iterations of the system, as Voyager was incapable of this, it is an extension in an entirely new direction. Additionally, in a set of building unit tests VoyagerVision was successful in half of all attempts in flat worlds, with most failures arising in more complex structures. Project website is available at https://esmyth-dev.github.io/VoyagerVision.github.io/

