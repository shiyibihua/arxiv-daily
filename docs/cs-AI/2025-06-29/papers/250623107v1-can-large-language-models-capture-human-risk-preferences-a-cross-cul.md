---
layout: default
title: Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study
---

# Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23107" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23107v1</a>
  <a href="https://arxiv.org/pdf/2506.23107.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23107v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23107v1', 'Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bing Song, Jianing Liu, Sisi Jian, Chenyang Wu, Vinayak Dixit

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

**å¤‡æ³¨**: 20 pages, 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿäººç±»é£é™©åå¥½ä¸­çš„æœ‰æ•ˆæ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é£é™©åå¥½` `å†³ç­–æ¨¡æ‹Ÿ` `è·¨æ–‡åŒ–ç ”ç©¶` `CRRAæ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿå¤æ‚å†³ç­–è¡Œä¸ºæ—¶å­˜åœ¨å¯é æ€§ä¸è¶³çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é£é™©å†³ç­–åœºæ™¯ä¸­ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡å¯¹æ¯”æ¨¡å‹ç”Ÿæˆçš„å†³ç­–ä¸äººç±»ååº”ï¼Œæ¢è®¨LLMsåœ¨é£é™©åå¥½æ¨¡æ‹Ÿä¸­çš„è¡¨ç°ï¼Œé‡‡ç”¨CRRAæ¡†æ¶è¿›è¡Œåˆ†æã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹è¡¨ç°å‡ºæ›´å¼ºçš„é£é™©åŒæ¶å€¾å‘ï¼Œä¸”o1-miniæ¨¡å‹çš„å†³ç­–ä¸äººç±»æ›´ä¸ºä¸€è‡´ï¼Œæç¤ºè¯­è¨€å½±å“æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¯¹è¯ç³»ç»Ÿã€è‡ªåŠ¨å†…å®¹åˆ›ä½œå’Œç‰¹å®šé¢†åŸŸå’¨è¯¢ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œéšç€å…¶åº”ç”¨çš„å¢åŠ ï¼Œå…³äºå…¶åœ¨å¤æ‚å†³ç­–è¡Œä¸ºæ¨¡æ‹Ÿä¸­çš„å¯é æ€§é—®é¢˜é€æ¸æ˜¾ç°ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†LLMsåœ¨æ¨¡æ‹Ÿé£é™©å†³ç­–åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚é€šè¿‡å¯¹æ‚‰å°¼ã€è¾¾å¡ã€é¦™æ¸¯å’Œå—äº¬å‚ä¸è€…çš„æŠ½æ ·è°ƒæŸ¥æ•°æ®è¿›è¡Œåˆ†æï¼Œæ¯”è¾ƒäº†æ¨¡å‹ç”Ÿæˆçš„å†³ç­–ä¸å®é™…äººç±»ååº”ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸¤ç§æ¨¡å‹è¡¨ç°å‡ºæ¯”äººç±»å‚ä¸è€…æ›´ä¸ºé£é™©åŒæ¶çš„è¡Œä¸ºï¼Œå…¶ä¸­o1-miniæ¨¡å‹ä¸è§‚å¯Ÿåˆ°çš„äººç±»å†³ç­–æ›´ä¸ºä¸€è‡´ã€‚æ­¤å¤–ï¼Œæ¥è‡ªå—äº¬å’Œé¦™æ¸¯çš„å¤šè¯­è¨€æ•°æ®åˆ†æè¡¨æ˜ï¼Œä¸­æ–‡æ¨¡å‹é¢„æµ‹ä¸å®é™…ååº”çš„åå·®å¤§äºè‹±æ–‡ï¼Œæç¤ºæç¤ºè¯­è¨€å¯èƒ½å½±å“æ¨¡æ‹Ÿæ€§èƒ½ã€‚è¿™äº›å‘ç°çªæ˜¾äº†LLMsåœ¨å¤åˆ¶äººç±»é£é™©è¡Œä¸ºæ–¹é¢çš„æ½œåŠ›ä¸å½“å‰å±€é™æ€§ï¼Œå°¤å…¶æ˜¯åœ¨è¯­è¨€å’Œæ–‡åŒ–èƒŒæ™¯ä¸‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿäººç±»é£é™©åå¥½æ—¶çš„å¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚å†³ç­–è¡Œä¸ºçš„æ¨¡æ‹Ÿä¸Šå­˜åœ¨ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ä¸åŒæ–‡åŒ–å’Œè¯­è¨€èƒŒæ™¯ä¸‹çš„è¡¨ç°ä¸ä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å¯¹æ¯”æ¨¡å‹ç”Ÿæˆçš„å†³ç­–ä¸å®é™…äººç±»ååº”ï¼Œè¯„ä¼°LLMsåœ¨é£é™©å†³ç­–åœºæ™¯ä¸­çš„èƒ½åŠ›ï¼Œé‡‡ç”¨CRRAæ¡†æ¶åˆ†æé£é™©åå¥½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶è®¾è®¡åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ¨¡å‹è¾“å…¥ã€å†³ç­–ç”Ÿæˆå’Œç»“æœåˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ¥è‡ªä¸åŒæ–‡åŒ–èƒŒæ™¯çš„å‚ä¸è€…ï¼Œæ¨¡å‹è¾“å…¥åŒ…æ‹¬äººå£ç»Ÿè®¡ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†ä¸åŒè¯­è¨€æ¨¡å‹åœ¨æ¨¡æ‹Ÿäººç±»é£é™©åå¥½æ—¶çš„è¡¨ç°ï¼Œæ­ç¤ºäº†è¯­è¨€å¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šä½¿ç”¨äº†ä¸¤ç§ä¸åŒçš„LLMsï¼ˆChatGPT 4oå’ŒChatGPT o1-miniï¼‰ï¼Œå¹¶åœ¨æ¨¡å‹è¾“å…¥ä¸­è€ƒè™‘äº†å‚ä¸è€…çš„æ–‡åŒ–èƒŒæ™¯å’Œè¯­è¨€ï¼Œé‡‡ç”¨CRRAæ¡†æ¶è¿›è¡Œé£é™©åå¥½åˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨æ¨¡æ‹Ÿé£é™©å†³ç­–æ—¶è¡¨ç°å‡ºæ›´å¼ºçš„é£é™©åŒæ¶å€¾å‘ï¼Œo1-miniæ¨¡å‹çš„å†³ç­–ä¸äººç±»ååº”æ›´ä¸ºä¸€è‡´ã€‚æ­¤å¤–ï¼Œä¸­æ–‡æ¨¡å‹çš„é¢„æµ‹ä¸å®é™…ååº”çš„åå·®å¤§äºè‹±æ–‡ï¼Œæç¤ºè¯­è¨€å¯èƒ½æ˜¾è‘—å½±å“æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå†³ç­–æ”¯æŒã€å¸‚åœºè¥é”€ç­–ç•¥è®¾è®¡ä»¥åŠè·¨æ–‡åŒ–äº¤æµä¸­çš„å†³ç­–æ¨¡æ‹Ÿã€‚é€šè¿‡æ›´å¥½åœ°ç†è§£LLMsåœ¨é£é™©å†³ç­–ä¸­çš„è¡¨ç°ï¼Œå¯ä»¥æå‡å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ï¼Œæ¨åŠ¨æ™ºèƒ½å†³ç­–ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have made significant strides, extending their applications to dialogue systems, automated content creation, and domain-specific advisory tasks. However, as their use grows, concerns have emerged regarding their reliability in simulating complex decision-making behavior, such as risky decision-making, where a single choice can lead to multiple outcomes. This study investigates the ability of LLMs to simulate risky decision-making scenarios. We compare model-generated decisions with actual human responses in a series of lottery-based tasks, using transportation stated preference survey data from participants in Sydney, Dhaka, Hong Kong, and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk preferences were analyzed using the Constant Relative Risk Aversion (CRRA) framework. Results show that both models exhibit more risk-averse behavior than human participants, with o1-mini aligning more closely with observed human decisions. Further analysis of multilingual data from Nanjing and Hong Kong indicates that model predictions in Chinese deviate more from actual responses compared to English, suggesting that prompt language may influence simulation performance. These findings highlight both the promise and the current limitations of LLMs in replicating human-like risk behavior, particularly in linguistic and cultural settings.

