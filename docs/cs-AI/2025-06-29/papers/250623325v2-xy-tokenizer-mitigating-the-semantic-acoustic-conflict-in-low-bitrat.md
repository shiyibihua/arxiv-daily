---
layout: default
title: XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs
---

# XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23325" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23325v2</a>
  <a href="https://arxiv.org/pdf/2506.23325.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23325v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23325v2', 'XY-Tokenizer: Mitigating the Semantic-Acoustic Conflict in Low-Bitrate Speech Codecs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yitian Gong, Luozhijie Jin, Ruifan Deng, Dong Zhang, Xin Zhang, Qinyuan Cheng, Zhaoye Fei, Shimin Li, Xipeng Qiu

**åˆ†ç±»**: cs.SD, cs.AI, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-07-09)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/gyt1145028706/XY-Tokenizer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºXY-Tokenizerä»¥è§£å†³ä½æ¯”ç‰¹ç‡è¯­éŸ³ç¼–è§£ç ä¸­çš„è¯­ä¹‰ä¸å£°å­¦å†²çªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­éŸ³ç¼–è§£ç ` `å¤šä»»åŠ¡å­¦ä¹ ` `å£°å­¦ä¿çœŸåº¦` `è¯­ä¹‰å»ºæ¨¡` `ä½æ¯”ç‰¹ç‡` `è¯­éŸ³ä¿¡å·å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³ç¼–è§£ç å™¨åœ¨è¯­ä¹‰ä¸°å¯Œæ€§ä¸å£°å­¦ä¿çœŸåº¦ä¹‹é—´éš¾ä»¥å–å¾—å¹³è¡¡ï¼Œå¯¼è‡´è¯­éŸ³ä¿¡å·çš„æœ‰æ•ˆä¼ é€’å—åˆ°é™åˆ¶ã€‚
2. XY-Tokenizeré€šè¿‡å¤šé˜¶æ®µã€å¤šä»»åŠ¡å­¦ä¹ çš„æ–¹å¼ï¼Œæ—¨åœ¨åŒæ—¶æå‡è¯­éŸ³çš„å£°å­¦è´¨é‡å’Œè¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ï¼Œè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•çš„ä¸è¶³ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒXY-Tokenizeråœ¨è¯­ä¹‰å’Œå£°å­¦ä»»åŠ¡ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œæ–‡æœ¬å¯¹é½èƒ½åŠ›è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œé‡å»ºéŸ³é¢‘çš„è¯´è¯äººç›¸ä¼¼åº¦è¯„åˆ†æ¥è¿‘æœ€å…ˆè¿›çš„å£°å­¦ç¼–è§£ç å™¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­éŸ³ç¼–è§£ç å™¨ä½œä¸ºè¯­éŸ³ä¿¡å·ä¸å¤§å‹è¯­è¨€æ¨¡å‹ä¹‹é—´çš„æ¡¥æ¢ï¼Œç†æƒ³çš„ç¼–è§£ç å™¨åº”åŒæ—¶ä¿ç•™å£°å­¦ä¿¡æ¯å’Œä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚ç„¶è€Œï¼Œç°æœ‰ç¼–è§£ç å™¨åœ¨é«˜è´¨é‡éŸ³é¢‘é‡å»ºä¸è¯­è¨€æ¨¡å‹å»ºæ¨¡çš„å¹³è¡¡ä¸Šå­˜åœ¨å›°éš¾ã€‚æœ¬ç ”ç©¶åˆ†æäº†ç°æœ‰ç¼–è§£ç å™¨åœ¨è¯­ä¹‰ä¸°å¯Œæ€§ä¸å£°å­¦ä¿çœŸåº¦ä¹‹é—´çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†XY-Tokenizerï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å¤šé˜¶æ®µã€å¤šä»»åŠ¡å­¦ä¹ æ¥ç¼“è§£è¯­ä¹‰ä¸å£°å­¦èƒ½åŠ›å†²çªçš„æ–°å‹ç¼–è§£ç å™¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒXY-Tokenizeråœ¨è¯­ä¹‰å’Œå£°å­¦ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸åŒç±»æ¯”ç‰¹ç‡çš„æœ€å…ˆè¿›ç¼–è§£ç å™¨ç›¸å½“ï¼Œä¸”åœ¨æ–‡æœ¬å¯¹é½æ–¹é¢è¶…è¶Šäº†åŸºäºè’¸é¦çš„è¯­ä¹‰å»ºæ¨¡æ–¹æ³•ï¼ŒåŒæ—¶åœ¨é‡å»ºéŸ³é¢‘çš„è¯´è¯äººç›¸ä¼¼åº¦è¯„åˆ†ä¸Šä¿æŒåœ¨0.83ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ä½æ¯”ç‰¹ç‡è¯­éŸ³ç¼–è§£ç å™¨åœ¨è¯­ä¹‰ä¸å£°å­¦ä¿¡æ¯ä¼ é€’ä¸­çš„å†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åœ¨å£°å­¦ä¿çœŸåº¦æˆ–è¯­ä¹‰ä¸°å¯Œæ€§ä¸Šè¡¨ç°çªå‡ºï¼Œä½†éš¾ä»¥å…¼é¡¾ä¸¤è€…ï¼Œå¯¼è‡´ä¿¡æ¯æŸå¤±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šXY-Tokenizerçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤šé˜¶æ®µã€å¤šä»»åŠ¡å­¦ä¹ æ¡†æ¶ï¼Œåˆ†åˆ«ä¼˜åŒ–å£°å­¦å’Œè¯­ä¹‰ä»»åŠ¡ï¼Œä»è€Œå®ç°ä¸¤è€…çš„æœ‰æ•ˆç»“åˆï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•é‡‡ç”¨åˆ†é˜¶æ®µçš„å­¦ä¹ ç­–ç•¥ï¼Œé¦–å…ˆè¿›è¡Œå£°å­¦ç‰¹å¾æå–ï¼Œç„¶åé€šè¿‡å¤šä»»åŠ¡å­¦ä¹ åŒæ—¶ä¼˜åŒ–è¯­ä¹‰å»ºæ¨¡å’Œå£°å­¦é‡å»ºï¼Œç¡®ä¿ä¿¡æ¯çš„å®Œæ•´æ€§ä¸å‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šXY-Tokenizerçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å¤šä»»åŠ¡å­¦ä¹ æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨åŒä¸€æ¨¡å‹ä¸­å¹³è¡¡å£°å­¦ä¸è¯­ä¹‰ä»»åŠ¡çš„ä¼˜åŒ–ï¼Œè€Œç°æœ‰æ–¹æ³•å¾€å¾€åªèƒ½ä¸“æ³¨äºå…¶ä¸­ä¸€æ–¹é¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒXY-Tokenizerä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å£°å­¦å’Œè¯­ä¹‰ä»»åŠ¡çš„æƒé‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šé‡‡ç”¨äº†é€‚åº”æ€§æ¨¡å—ï¼Œä»¥ä¾¿åœ¨ä¸åŒä»»åŠ¡é—´çµæ´»è°ƒæ•´å‚æ•°è®¾ç½®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒXY-Tokenizeråœ¨è¯­ä¹‰ä»»åŠ¡ä¸Šè¶…è¶Šäº†åŸºäºè’¸é¦çš„è¯­ä¹‰å»ºæ¨¡æ–¹æ³•ï¼Œå¦‚SpeechTokenizerå’ŒMimiï¼Œä¸”åœ¨å£°å­¦é‡å»ºæ–¹é¢ï¼Œå…¶è¯´è¯äººç›¸ä¼¼åº¦è¯„åˆ†è¾¾åˆ°0.83ï¼Œæ¥è¿‘å½“å‰å£°å­¦ç¼–è§£ç å™¨BigCodecçš„0.84ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

XY-Tokenizerçš„ç ”ç©¶æˆæœåœ¨è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆå’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æå‡è¯­éŸ³ä¿¡å·çš„è¯­ä¹‰è¡¨è¾¾ä¸å£°å­¦è´¨é‡ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿæ”¹å–„è¯­éŸ³åŠ©æ‰‹ã€ç¿»è¯‘ç³»ç»ŸåŠå…¶ä»–åŸºäºè¯­éŸ³çš„åº”ç”¨çš„ç”¨æˆ·ä½“éªŒï¼Œæ¨åŠ¨æ™ºèƒ½è¯­éŸ³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Speech codecs serve as bridges between speech signals and large language models. An ideal codec for speech language models should not only preserve acoustic information but also capture rich semantic information. However, existing speech codecs struggle to balance high-quality audio reconstruction with ease of modeling by language models. In this study, we analyze the limitations of previous codecs in balancing semantic richness and acoustic fidelity. We propose XY-Tokenizer, a novel codec that mitigates the conflict between semantic and acoustic capabilities through multi-stage, multi-task learning. Experimental results demonstrate that XY-Tokenizer achieves performance in both semantic and acoustic tasks comparable to that of state-of-the-art codecs operating at similar bitrates, even though those existing codecs typically excel in only one aspect. Specifically, XY-Tokenizer achieves strong text alignment, surpassing distillation-based semantic modeling methods such as SpeechTokenizer and Mimi, while maintaining a speaker similarity score of 0.83 between reconstructed and original audio. The reconstruction performance of XY-Tokenizer is comparable to that of BigCodec, the current state-of-the-art among acoustic-only codecs, which achieves a speaker similarity score of 0.84 at a similar bitrate. Code and models are available at https://github.com/gyt1145028706/XY-Tokenizer.

