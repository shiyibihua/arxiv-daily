---
layout: default
title: Communication Bias in Large Language Models: A Regulatory Perspective
---

# Communication Bias in Large Language Models: A Regulatory Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.21075" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.21075v1</a>
  <a href="https://arxiv.org/pdf/2509.21075.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.21075v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.21075v1', 'Communication Bias in Large Language Models: A Regulatory Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Adrian Kuenzler, Stefan Schmid

**åˆ†ç±»**: cs.CY, cs.AI, cs.CL, cs.DC, cs.HC, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„é€šä¿¡åå·®é£é™©åˆ†æä¸ç›‘ç®¡æ¡†æ¶æ¢è®¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é€šä¿¡åå·®` `äººå·¥æ™ºèƒ½ç›‘ç®¡` `å…¬å¹³æ€§` `æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹æ—¥ç›Šæ™®åŠï¼Œä½†å…¶è¾“å‡ºç»“æœå¯èƒ½å­˜åœ¨åå·®ï¼Œå¯¹ç¤¾ä¼šå…¬å¹³é€ æˆæ½œåœ¨å¨èƒã€‚
2. æœ¬æ–‡ä»ç›‘ç®¡è§’åº¦å‡ºå‘ï¼Œåˆ†æäº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å­˜åœ¨çš„é€šä¿¡åå·®é£é™©ï¼Œå¹¶æ¢è®¨äº†ç›¸åº”çš„ç›‘ç®¡æ¡†æ¶ã€‚
3. ç ”ç©¶å¼ºè°ƒï¼Œé™¤äº†æŒç»­ç›‘ç®¡å¤–ï¼Œè¿˜éœ€è¦åŠ å¼ºç«äº‰å’Œè®¾è®¡æ²»ç†ï¼Œä»¥ç¡®ä¿AIçš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¶Šæ¥è¶Šå¤šçš„åº”ç”¨ä¸­å æ®æ ¸å¿ƒåœ°ä½ï¼Œå¼•å‘äº†å¯¹åå·®ã€å…¬å¹³æ€§å’Œç›‘ç®¡åˆè§„æ€§çš„æ‹…å¿§ã€‚æœ¬æ–‡å›é¡¾äº†LLMè¾“å‡ºä¸­å­˜åœ¨çš„åå·®é£é™©åŠå…¶ç¤¾ä¼šå½±å“ï¼Œé‡ç‚¹å…³æ³¨äº†æ¬§ç›Ÿçš„ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹å’Œã€Šæ•°å­—æœåŠ¡æ³•æ¡ˆã€‹ç­‰ç›‘ç®¡æ¡†æ¶ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œé™¤äº†æŒç»­çš„ç›‘ç®¡ä¹‹å¤–ï¼Œè¿˜éœ€è¦æ›´åŠ é‡è§†ç«äº‰å’Œè®¾è®¡æ²»ç†ï¼Œä»¥ç¡®ä¿å…¬å¹³ã€å¯ä¿¡èµ–çš„äººå·¥æ™ºèƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­å­˜åœ¨çš„åå·®é—®é¢˜ï¼Œä»¥åŠè¿™äº›åå·®å¯èƒ½å¯¹ç¤¾ä¼šé€ æˆçš„è´Ÿé¢å½±å“ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨æŠ€æœ¯å±‚é¢ï¼Œä¾‹å¦‚é€šè¿‡æ•°æ®é›†æ¸…æ´—æˆ–æ¨¡å‹å¾®è°ƒæ¥å‡å°‘åå·®ï¼Œä½†ç¼ºä¹å¯¹æ›´æ·±å±‚æ¬¡çš„ç«äº‰å’Œè®¾è®¡æ²»ç†çš„å…³æ³¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä»ç›‘ç®¡çš„è§’åº¦å‡ºå‘ï¼Œåˆ†æç°æœ‰çš„ç›‘ç®¡æ¡†æ¶ï¼ˆå¦‚æ¬§ç›Ÿçš„ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹å’Œã€Šæ•°å­—æœåŠ¡æ³•æ¡ˆã€‹ï¼‰å¦‚ä½•åº”å¯¹LLMä¸­çš„åå·®é—®é¢˜ã€‚åŒæ—¶ï¼Œå¼ºè°ƒé™¤äº†ç›‘ç®¡ä¹‹å¤–ï¼Œè¿˜éœ€è¦ä»ç«äº‰å’Œè®¾è®¡æ²»ç†çš„è§’åº¦æ¥è§£å†³åå·®é—®é¢˜ï¼Œä¾‹å¦‚é¼“åŠ±æ›´å¤šå‚ä¸è€…è¿›å…¥å¸‚åœºï¼Œä»¥åŠåœ¨æ¨¡å‹è®¾è®¡é˜¶æ®µå°±è€ƒè™‘åˆ°å…¬å¹³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡ä¸»è¦æ˜¯ä¸€ä¸ªç»¼è¿°æ€§çš„ç ”ç©¶ï¼Œå¹¶æ²¡æœ‰æå‡ºæ–°çš„æŠ€æœ¯æ¡†æ¶ã€‚å®ƒä¸»è¦é€šè¿‡åˆ†æç°æœ‰çš„æ–‡çŒ®å’Œç›‘ç®¡æ”¿ç­–ï¼Œæ¥æ¢è®¨LLMä¸­çš„åå·®é—®é¢˜ã€‚æ–‡ç« è®¨è®ºäº†ä¸åŒç±»å‹çš„åå·®ï¼Œä¾‹å¦‚æ•°æ®é›†åå·®ã€ç®—æ³•åå·®å’Œç”¨æˆ·äº¤äº’åå·®ï¼Œå¹¶åˆ†æäº†è¿™äº›åå·®å¯èƒ½å¯¹ç¤¾ä¼šé€ æˆçš„æ½œåœ¨å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°ä¹‹å¤„åœ¨äºå®ƒä»ç›‘ç®¡çš„è§’åº¦æ¥å®¡è§†LLMä¸­çš„åå·®é—®é¢˜ï¼Œå¹¶å¼ºè°ƒäº†ç«äº‰å’Œè®¾è®¡æ²»ç†çš„é‡è¦æ€§ã€‚ä¸ä»¥å¾€ä¸»è¦å…³æ³¨æŠ€æœ¯å±‚é¢çš„ç ”ç©¶ä¸åŒï¼Œæœ¬æ–‡è®¤ä¸ºè§£å†³LLMä¸­çš„åå·®é—®é¢˜éœ€è¦ä¸€ä¸ªæ›´å…¨é¢çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ç›‘ç®¡ã€ç«äº‰å’Œè®¾è®¡æ²»ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬æ–‡æ²¡æœ‰æ¶‰åŠå…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚å®ƒä¸»è¦å…³æ³¨çš„æ˜¯ç›‘ç®¡æ¡†æ¶çš„è®¾è®¡ï¼Œä¾‹å¦‚å¦‚ä½•å®šä¹‰åå·®ã€å¦‚ä½•è¯„ä¼°æ¨¡å‹çš„å…¬å¹³æ€§ï¼Œä»¥åŠå¦‚ä½•å¯¹è¿åè§„å®šçš„è¡Œä¸ºè¿›è¡Œæƒ©ç½šã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æœ¬æ–‡æ˜¯ä¸€ç¯‡ç»¼è¿°æ€§æ–‡ç« ï¼Œä¸»è¦äº®ç‚¹åœ¨äºä»ç›‘ç®¡è§†è§’åˆ†æäº†å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„åå·®é—®é¢˜ï¼Œå¹¶å¼ºè°ƒäº†ç«äº‰å’Œè®¾è®¡æ²»ç†çš„é‡è¦æ€§ã€‚æ–‡ç« å¹¶æœªæä¾›å…·ä½“çš„å®éªŒæ•°æ®ï¼Œè€Œæ˜¯é€šè¿‡åˆ†æç°æœ‰æ–‡çŒ®å’Œç›‘ç®¡æ”¿ç­–ï¼Œæå‡ºäº†å¯¹LLMåå·®é—®é¢˜çš„æ·±åˆ»è§è§£ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæŒ‡å¯¼äººå·¥æ™ºèƒ½ç›‘ç®¡æ”¿ç­–çš„åˆ¶å®šï¼Œå¸®åŠ©ç›‘ç®¡æœºæ„æ›´å¥½åœ°ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å­˜åœ¨çš„åå·®é£é™©ï¼Œå¹¶åˆ¶å®šç›¸åº”çš„ç›‘ç®¡æªæ–½ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶ä¹Ÿå¯ä»¥å¸®åŠ©å¼€å‘è€…åœ¨è®¾è®¡å’Œè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹æ—¶æ›´åŠ æ³¨é‡å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ï¼Œä»è€Œå‡å°‘åå·®çš„äº§ç”Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly central to many applications, raising concerns about bias, fairness, and regulatory compliance. This paper reviews risks of biased outputs and their societal impact, focusing on frameworks like the EU's AI Act and the Digital Services Act. We argue that beyond constant regulation, stronger attention to competition and design governance is needed to ensure fair, trustworthy AI. This is a preprint of the Communications of the ACM article of the same title.

