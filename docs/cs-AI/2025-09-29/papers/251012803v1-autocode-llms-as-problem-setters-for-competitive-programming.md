---
layout: default
title: AutoCode: LLMs as Problem Setters for Competitive Programming
---

# AutoCode: LLMs as Problem Setters for Competitive Programming

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.12803" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.12803v1</a>
  <a href="https://arxiv.org/pdf/2510.12803.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.12803v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.12803v1', 'AutoCode: LLMs as Problem Setters for Competitive Programming')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shang Zhou, Zihan Zheng, Kaiyuan Liu, Zeyu Shen, Zerui Cheng, Zexing Chen, Hansen He, Jianzhu Yao, Huanzhi Mao, Qiuyang Mang, Tianfu Fu, Beichen Li, Dongruixuan Li, Wenhao Chai, Zhuang Liu, Aleksandra Korolova, Peter Henderson, Natasha Jaques, Pramod Viswanath, Saining Xie, Jingbo Shang

**åˆ†ç±»**: cs.SE, cs.AI, cs.CL, cs.PL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**å¤‡æ³¨**: Project page: https://livecodebenchpro.com/projects/autocode/overview

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AutoCodeï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆç«èµ›çº§ç¼–ç¨‹é¢˜ç›®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¼–ç¨‹ç«èµ›` `è‡ªåŠ¨å‡ºé¢˜` `æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ` `å¤šè½®éªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç«èµ›ç¼–ç¨‹é¢˜ç›®ç”Ÿæˆæ–¹æ³•éš¾ä»¥å…¼é¡¾çº¦æŸæ¡ä»¶ã€ç®—æ³•é’ˆå¯¹æ€§å’Œéš¾åº¦æ ¡å‡†ï¼Œå¯¹å‡ºé¢˜è€…è¦æ±‚æé«˜ã€‚
2. AutoCodeåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å¤šè½®éªŒè¯ç”Ÿæˆé«˜è´¨é‡é¢˜ç›®æè¿°å’Œæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶èƒ½ç”Ÿæˆå‚è€ƒå’Œæš´åŠ›è§£æ³•ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAutoCodeç”Ÿæˆçš„æµ‹è¯•å¥—ä»¶ä¸å®˜æ–¹åˆ¤å®šçš„ç»“æœä¸€è‡´æ€§æ¥è¿‘99%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¼–å†™ç«èµ›ç¼–ç¨‹é¢˜ç›®æå…·æŒ‘æˆ˜æ€§ã€‚å‡ºé¢˜è€…å¿…é¡»è®¾å®šçº¦æŸæ¡ä»¶ã€è¾“å…¥åˆ†å¸ƒå’Œæ’é™¤ä½œå¼Šçš„è¾¹ç•Œæƒ…å†µï¼›é’ˆå¯¹ç‰¹å®šç®—æ³•ï¼ˆå¦‚æœ€å¤§æµã€åŠ¨æ€è§„åˆ’ã€æ•°æ®ç»“æ„ï¼‰ï¼›å¹¶æ ¡å‡†éš¾åº¦ï¼Œä½¿å…¶è¶…å‡ºå¤§å¤šæ•°å‚èµ›è€…çš„èƒ½åŠ›èŒƒå›´ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™éå¸¸é€‚åˆæµ‹è¯•é€šç”¨å¤§å‹è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ï¼Œå¹¶ç ”ç©¶å®ƒä»¬æ˜¯å¦èƒ½å¯é åœ°å®Œæˆè¿™é¡¹ä»»åŠ¡ã€‚æˆ‘ä»¬ä»‹ç»äº†AutoCodeï¼Œå®ƒä½¿ç”¨å¤šè½®éªŒè¯æ¥ç”Ÿæˆç«èµ›çº§çš„é¢˜ç›®æè¿°å’Œæµ‹è¯•ç”¨ä¾‹ã€‚åœ¨ä¿ç•™é—®é¢˜ä¸Šï¼ŒAutoCodeæµ‹è¯•å¥—ä»¶ä¸å®˜æ–¹åˆ¤å®šçš„ç»“æœä¸€è‡´æ€§æ¥è¿‘99%ï¼Œä¸å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ˆå¦‚HardTestsï¼Œä¸€è‡´æ€§ä½äº81%ï¼‰ç›¸æ¯”ï¼Œæœ‰äº†æ˜¾è‘—æé«˜ã€‚æ­¤å¤–ï¼Œä»éšæœºç§å­é—®é¢˜å¼€å§‹ï¼ŒAutoCodeå¯ä»¥åˆ›å»ºå…·æœ‰å‚è€ƒè§£å†³æ–¹æ¡ˆå’Œæš´åŠ›ç ´è§£è§£å†³æ–¹æ¡ˆçš„æ–°å˜ä½“ã€‚é€šè¿‡äº¤å‰éªŒè¯è¿™äº›ç”Ÿæˆçš„è§£å†³æ–¹æ¡ˆä¸æµ‹è¯•ç”¨ä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥è¿‡æ»¤æ‰æ ¼å¼é”™è¯¯çš„é—®é¢˜ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿç¡®ä¿äº†é«˜æ­£ç¡®æ€§ï¼Œå¹¶ç»è¿‡äº†äººç±»ä¸“å®¶çš„éªŒè¯ã€‚AutoCodeæˆåŠŸåœ°ç”Ÿæˆäº†ç”±Grandmasterçº§åˆ«ï¼ˆå‰0.3%ï¼‰çš„ç«èµ›ç¨‹åºå‘˜åˆ¤æ–­ä¸ºç«èµ›è´¨é‡çš„æ–°é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡ã€ç«èµ›çº§åˆ«çš„ç¼–ç¨‹é¢˜ç›®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚HardTestsï¼Œåœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶ï¼Œä¸å®˜æ–¹åˆ¤å®šçš„ç»“æœä¸€è‡´æ€§è¾ƒä½ï¼Œæ— æ³•ä¿è¯é¢˜ç›®çš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚äººå·¥å‡ºé¢˜æˆæœ¬é«˜æ˜‚ï¼Œä¸”éœ€è¦å‡ºé¢˜è€…å…·å¤‡æ·±åšçš„ç®—æ³•åŠŸåº•å’Œä¸°å¯Œçš„ç«èµ›ç»éªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¼ºå¤§ç”Ÿæˆèƒ½åŠ›å’Œç†è§£èƒ½åŠ›ï¼Œè‡ªåŠ¨ç”Ÿæˆé¢˜ç›®æè¿°ã€æµ‹è¯•ç”¨ä¾‹ä»¥åŠå‚è€ƒè§£æ³•ã€‚é€šè¿‡å¤šè½®éªŒè¯å’Œäº¤å‰éªŒè¯ï¼Œç­›é€‰å‡ºé«˜è´¨é‡çš„é¢˜ç›®ï¼Œå¹¶ç¡®ä¿å…¶éš¾åº¦å’ŒåŒºåˆ†åº¦ç¬¦åˆç«èµ›è¦æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAutoCodeç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) é¢˜ç›®ç”Ÿæˆï¼šåˆ©ç”¨LLMç”Ÿæˆåˆå§‹çš„é¢˜ç›®æè¿°ï¼›2) æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆï¼šåˆ©ç”¨LLMç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼ŒåŒ…æ‹¬æ­£å¸¸æƒ…å†µå’Œè¾¹ç•Œæƒ…å†µï¼›3) è§£æ³•ç”Ÿæˆï¼šåˆ©ç”¨LLMç”Ÿæˆå‚è€ƒè§£æ³•å’Œæš´åŠ›è§£æ³•ï¼›4) éªŒè¯ä¸ç­›é€‰ï¼šé€šè¿‡äº¤å‰éªŒè¯æµ‹è¯•ç”¨ä¾‹å’Œè§£æ³•ï¼Œç­›é€‰å‡ºé«˜è´¨é‡çš„é¢˜ç›®ã€‚äººç±»ä¸“å®¶ä¼šå¯¹æœ€ç»ˆç”Ÿæˆçš„é¢˜ç›®è¿›è¡Œè¯„ä¼°å’Œç¡®è®¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šAutoCodeçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨LLMè¿›è¡Œå¤šè½®éªŒè¯å’Œäº¤å‰éªŒè¯ï¼Œä»è€Œæœ‰æ•ˆåœ°ç­›é€‰å‡ºé«˜è´¨é‡çš„é¢˜ç›®ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒAutoCodeèƒ½å¤Ÿç”Ÿæˆæ›´å¤æ‚ã€æ›´å…·æŒ‘æˆ˜æ€§çš„é¢˜ç›®ï¼Œå¹¶ä¸”èƒ½å¤Ÿä¿è¯é¢˜ç›®çš„æ­£ç¡®æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼ŒAutoCodeè¿˜èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆå‚è€ƒè§£æ³•å’Œæš´åŠ›è§£æ³•ï¼Œæ–¹ä¾¿å‡ºé¢˜è€…è¿›è¡ŒéªŒè¯å’Œè¯„ä¼°ã€‚

**å…³é”®è®¾è®¡**ï¼šAutoCodeåœ¨é¢˜ç›®ç”Ÿæˆé˜¶æ®µï¼Œä¼šä½¿ç”¨ç‰¹å®šçš„promptæ¥å¼•å¯¼LLMç”Ÿæˆç¬¦åˆç«èµ›è¦æ±‚çš„é¢˜ç›®æè¿°ã€‚åœ¨æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆé˜¶æ®µï¼Œä¼šè€ƒè™‘å„ç§è¾¹ç•Œæƒ…å†µå’Œç‰¹æ®Šæƒ…å†µï¼Œä»¥ç¡®ä¿é¢˜ç›®çš„é²æ£’æ€§ã€‚åœ¨éªŒè¯ä¸ç­›é€‰é˜¶æ®µï¼Œä¼šä½¿ç”¨å¤šç§æŒ‡æ ‡æ¥è¯„ä¼°é¢˜ç›®çš„è´¨é‡ï¼Œä¾‹å¦‚æµ‹è¯•ç”¨ä¾‹çš„è¦†ç›–ç‡ã€è§£æ³•çš„æ­£ç¡®ç‡ç­‰ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

AutoCodeåœ¨ä¿ç•™é—®é¢˜ä¸Šï¼Œæµ‹è¯•å¥—ä»¶ä¸å®˜æ–¹åˆ¤å®šçš„ç»“æœä¸€è‡´æ€§æ¥è¿‘99%ï¼Œæ˜¾è‘—ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•HardTestsï¼ˆä¸€è‡´æ€§ä½äº81%ï¼‰ã€‚ç”±Grandmasterçº§åˆ«ï¼ˆå‰0.3%ï¼‰çš„ç«èµ›ç¨‹åºå‘˜åˆ¤æ–­ï¼ŒAutoCodeæˆåŠŸç”Ÿæˆäº†ç«èµ›è´¨é‡çš„æ–°é—®é¢˜ï¼Œè¯æ˜äº†å…¶ç”Ÿæˆé«˜è´¨é‡ç«èµ›é¢˜ç›®çš„èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AutoCodeå¯åº”ç”¨äºå„ç§ç¼–ç¨‹ç«èµ›å’Œåœ¨çº¿è¯„æµ‹ç³»ç»Ÿï¼Œé™ä½å‡ºé¢˜æˆæœ¬ï¼Œæé«˜é¢˜ç›®è´¨é‡å’Œå¤šæ ·æ€§ã€‚å®ƒè¿˜å¯ä»¥ç”¨äºæ•™è‚²é¢†åŸŸï¼Œè¾…åŠ©æ•™å¸ˆç”Ÿæˆç»ƒä¹ é¢˜å’Œè€ƒè¯•é¢˜ï¼Œå¸®åŠ©å­¦ç”Ÿæé«˜ç¼–ç¨‹èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ç”¨äºè‡ªåŠ¨åŒ–æµ‹è¯•å’Œè½¯ä»¶è´¨é‡è¯„ä¼°ï¼Œç”Ÿæˆæ›´å…¨é¢çš„æµ‹è¯•ç”¨ä¾‹ï¼Œæé«˜è½¯ä»¶çš„å¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Writing competitive programming problems is exacting. Authors must: set constraints, input distributions, and edge cases that rule out shortcuts; target specific algorithms (e.g., max-flow, dynamic programming, data structures); and calibrate complexity beyond the reach of most competitors. We argue that this makes for an ideal test of general large language model capabilities and study whether they can do this reliably. We introduce AutoCode, which uses multiple rounds of validation to yield competition-grade problem statements and test cases. On held-out problems, AutoCode test suites approach 99% consistency with official judgments, a significant improvement over current state-of-the-art methods like HardTests, which achieve less than 81%. Furthermore, starting with a random seed problem, AutoCode can create novel variants with reference and brute-force solutions. By cross-verifying these generated solutions against test cases, we can further filter out malformed problems. Our system ensures high correctness, as verified by human experts. AutoCode successfully produces novel problems judged by Grandmaster-level (top 0.3%) competitive programmers to be of contest quality.

