---
layout: default
title: AdvChain: Adversarial Chain-of-Thought Tuning for Robust Safety Alignment of Large Reasoning Models
---

# AdvChain: Adversarial Chain-of-Thought Tuning for Robust Safety Alignment of Large Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24269" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24269v1</a>
  <a href="https://arxiv.org/pdf/2509.24269.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24269v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24269v1', 'AdvChain: Adversarial Chain-of-Thought Tuning for Robust Safety Alignment of Large Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zihao Zhu, Xinyu Wu, Gehan Hu, Siwei Lyu, Ke Xu, Baoyuan Wu

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AdvChainï¼šå¯¹æŠ—æ€§æ€ç»´é“¾å¾®è°ƒï¼Œæå‡å¤§å‹æ¨ç†æ¨¡å‹å®‰å…¨å¯¹é½çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹æ¨ç†æ¨¡å‹` `æ€ç»´é“¾` `å®‰å…¨å¯¹é½` `å¯¹æŠ—æ€§è®­ç»ƒ` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å®‰å…¨CoTå¾®è°ƒæ–¹æ³•å­˜åœ¨â€œæ»šé›ªçƒæ•ˆåº”â€ï¼Œæ¨ç†è¿‡ç¨‹ä¸­çš„å¾®å°åå·®ä¼šè¢«æ”¾å¤§ï¼Œå¯¼è‡´å®‰å…¨é—®é¢˜ã€‚
2. AdvChainé€šè¿‡å¯¹æŠ—æ€§CoTå¾®è°ƒï¼Œä½¿æ¨¡å‹å­¦ä¹ ä»æœ‰å®³æ¨ç†æ¼‚ç§»å’Œä¸å¿…è¦çš„è°¨æ…ä¸­åŠ¨æ€è‡ªæˆ‘çº æ­£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒAdvChainæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹è¶Šç‹±æ”»å‡»çš„é²æ£’æ€§ï¼Œå¹¶å‡å°‘äº†è¿‡åº¦æ‹’ç»ï¼Œå®ç°äº†æ›´å¥½çš„å®‰å…¨-æ•ˆç”¨å¹³è¡¡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹æ¨ç†æ¨¡å‹(LRMs)é€šè¿‡æ€ç»´é“¾(CoT)æ¨ç†åœ¨å¤æ‚é—®é¢˜è§£å†³ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒCoTçš„å¤šæ­¥éª¤ç‰¹æ€§å¸¦æ¥äº†è¶…è¶Šä¼ ç»Ÿè¯­è¨€æ¨¡å‹å¯¹é½çš„æ–°å®‰å…¨æŒ‘æˆ˜ã€‚æˆ‘ä»¬å‘ç°å½“å‰å®‰å…¨CoTå¾®è°ƒæ–¹æ³•å­˜åœ¨ä¸€ä¸ªå¤±æ•ˆæ¨¡å¼ï¼šæ»šé›ªçƒæ•ˆåº”ï¼Œå³å¾®å°çš„æ¨ç†åå·®åœ¨æ•´ä¸ªæ€è€ƒè¿‡ç¨‹ä¸­é€æ¸æ”¾å¤§ï¼Œå¯¼è‡´æœ‰å®³çš„é¡ºä»æˆ–è¿‡åº¦æ‹’ç»ã€‚è¿™ç§æ•ˆåº”æºäºæ¨¡å‹è¢«è®­ç»ƒæˆæ¨¡ä»¿å®Œç¾çš„æ¨ç†è„šæœ¬ï¼Œè€Œæ²¡æœ‰å­¦ä¼šè‡ªæˆ‘çº æ­£ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªå±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†AdvChainï¼Œä¸€ç§å¯¹é½èŒƒå¼ï¼Œé€šè¿‡å¯¹æŠ—æ€§CoTå¾®è°ƒæ¥æ•™å¯¼æ¨¡å‹åŠ¨æ€è‡ªæˆ‘çº æ­£ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬æ„å»ºä¸€ä¸ªåŒ…å«è¯±æƒ‘-çº æ­£å’ŒçŠ¹è±«-çº æ­£æ ·æœ¬çš„æ•°æ®é›†ï¼Œæ¨¡å‹å­¦ä¹ ä»æœ‰å®³çš„æ¨ç†æ¼‚ç§»å’Œä¸å¿…è¦çš„è°¨æ…ä¸­æ¢å¤ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒAdvChainæ˜¾è‘—å¢å¼ºäº†é’ˆå¯¹è¶Šç‹±æ”»å‡»å’ŒCoTåŠ«æŒçš„é²æ£’æ€§ï¼ŒåŒæ—¶å¤§å¹…å‡å°‘äº†å¯¹è‰¯æ€§æç¤ºçš„è¿‡åº¦æ‹’ç»ï¼Œåœ¨ä¸å½±å“æ¨ç†èƒ½åŠ›çš„æƒ…å†µä¸‹å®ç°äº†å“è¶Šçš„å®‰å…¨-æ•ˆç”¨å¹³è¡¡ã€‚æˆ‘ä»¬çš„å·¥ä½œä¸ºæ„å»ºæ›´é²æ£’å’Œå¯é çš„æ¨ç†æ¨¡å‹å»ºç«‹äº†ä¸€ä¸ªæ–°çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹æ¨ç†æ¨¡å‹åœ¨ä½¿ç”¨æ€ç»´é“¾(CoT)æ¨ç†æ—¶ï¼Œç”±äºå¤šæ­¥éª¤æ¨ç†è¿‡ç¨‹ä¸­çš„â€œæ»šé›ªçƒæ•ˆåº”â€è€Œäº§ç”Ÿçš„å®‰å…¨å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è®­ç»ƒæ¨¡å‹æ¨¡ä»¿å®Œç¾çš„æ¨ç†è„šæœ¬ï¼Œç¼ºä¹è‡ªæˆ‘çº æ­£èƒ½åŠ›ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶å®¹æ˜“äº§ç”Ÿæœ‰å®³çš„é¡ºä»æˆ–è¿‡åº¦æ‹’ç»ï¼Œå½±å“æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šAdvChainçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹æŠ—æ€§å¾®è°ƒï¼Œä½¿æ¨¡å‹å­¦ä¹ åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡ŒåŠ¨æ€çš„è‡ªæˆ‘çº æ­£ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯è®©æ¨¡å‹æ¥è§¦åˆ°åŒ…å«é”™è¯¯æˆ–åå·®çš„æ¨ç†è¿‡ç¨‹ï¼Œå¹¶å­¦ä¹ å¦‚ä½•ä»è¿™äº›é”™è¯¯ä¸­æ¢å¤ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚è¿™ç§æ–¹æ³•æ¨¡æ‹Ÿäº†äººç±»åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¸æ–­ä¿®æ­£é”™è¯¯çš„è¿‡ç¨‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹çœŸå®ä¸–ç•Œä¸­çš„å¤æ‚æƒ…å†µã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAdvChainçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ„å»ºåŒ…å«â€œè¯±æƒ‘-çº æ­£â€å’Œâ€œçŠ¹è±«-çº æ­£â€æ ·æœ¬çš„æ•°æ®é›†ã€‚ â€œè¯±æƒ‘-çº æ­£â€æ ·æœ¬æ—¨åœ¨æ¨¡æ‹Ÿæ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å—åˆ°æœ‰å®³ä¿¡æ¯è¯±å¯¼çš„æƒ…å†µï¼Œå¹¶å­¦ä¹ å¦‚ä½•çº æ­£è¿™äº›é”™è¯¯ã€‚â€œçŠ¹è±«-çº æ­£â€æ ·æœ¬æ—¨åœ¨æ¨¡æ‹Ÿæ¨¡å‹è¿‡åº¦è°¨æ…çš„æƒ…å†µï¼Œå¹¶å­¦ä¹ å¦‚ä½•é¿å…ä¸å¿…è¦çš„æ‹’ç»ã€‚2) ä½¿ç”¨æ„å»ºçš„æ•°æ®é›†å¯¹æ¨¡å‹è¿›è¡Œå¯¹æŠ—æ€§å¾®è°ƒï¼Œä½¿æ¨¡å‹å­¦ä¹ è‡ªæˆ‘çº æ­£çš„èƒ½åŠ›ã€‚3) è¯„ä¼°æ¨¡å‹åœ¨é¢å¯¹å„ç§æ”»å‡»æ—¶çš„é²æ£’æ€§å’Œå®‰å…¨-æ•ˆç”¨å¹³è¡¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šAdvChainæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†å¯¹æŠ—æ€§æ€ç»´é“¾å¾®è°ƒçš„æ¦‚å¿µï¼Œå¹¶è®¾è®¡äº†ç›¸åº”çš„è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒAdvChainä¸æ˜¯ç®€å•åœ°è®©æ¨¡å‹æ¨¡ä»¿å®Œç¾çš„æ¨ç†è„šæœ¬ï¼Œè€Œæ˜¯è®©æ¨¡å‹å­¦ä¹ åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡ŒåŠ¨æ€çš„è‡ªæˆ‘çº æ­£ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œå®‰å…¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šAdvChainçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è®¾è®¡äº†â€œè¯±æƒ‘-çº æ­£â€å’Œâ€œçŠ¹è±«-çº æ­£â€ä¸¤ç§ç±»å‹çš„è®­ç»ƒæ ·æœ¬ï¼Œåˆ†åˆ«ç”¨äºæ¨¡æ‹Ÿæ¨¡å‹å—åˆ°æœ‰å®³ä¿¡æ¯è¯±å¯¼å’Œè¿‡åº¦è°¨æ…çš„æƒ…å†µã€‚2) ä½¿ç”¨å¯¹æŠ—æ€§æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿›è¡Œè‡ªæˆ‘çº æ­£ã€‚3) åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨ä¸åŒçš„æ”»å‡»ç­–ç•¥æ¥æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­çš„å¯¹æŠ—æ€§æ”»å‡»ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAdvChainæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹è¶Šç‹±æ”»å‡»çš„é²æ£’æ€§ï¼Œåœ¨æŸäº›æ”»å‡»åœºæ™¯ä¸‹ï¼ŒæˆåŠŸç‡é™ä½äº†è¶…è¿‡50%ã€‚åŒæ—¶ï¼ŒAdvChainè¿˜å¤§å¹…å‡å°‘äº†æ¨¡å‹å¯¹è‰¯æ€§æç¤ºçš„è¿‡åº¦æ‹’ç»ï¼Œåœ¨ä¸å½±å“æ¨ç†èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†æ›´å¥½çš„å®‰å…¨-æ•ˆç”¨å¹³è¡¡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒAdvChainæ˜¯ä¸€ç§æœ‰æ•ˆçš„å®‰å…¨å¯¹é½æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

AdvChainæŠ€æœ¯å¯åº”ç”¨äºå„ç§éœ€è¦å®‰å…¨å¯é çš„å¤§å‹æ¨ç†æ¨¡å‹ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€é‡‘èé£æ§ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜æ¨¡å‹å¯¹å¯¹æŠ—æ€§æ”»å‡»çš„é²æ£’æ€§å’Œå®‰å…¨-æ•ˆç”¨å¹³è¡¡ï¼Œå¯ä»¥å‡å°‘æ¨¡å‹äº§ç”Ÿæœ‰å®³æˆ–ä¸å‡†ç¡®è¾“å‡ºçš„é£é™©ï¼Œæå‡ç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå¹¶ä¿ƒè¿›å¤§å‹æ¨ç†æ¨¡å‹åœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Reasoning Models (LRMs) have demonstrated remarkable capabilities in complex problem-solving through Chain-of-Thought (CoT) reasoning. However, the multi-step nature of CoT introduces new safety challenges that extend beyond conventional language model alignment. We identify a failure mode in current safety CoT tuning methods: the \textit{snowball effect}, where minor reasoning deviations progressively amplify throughout the thought process, leading to either harmful compliance or excessive refusal. This effect stems from models being trained to imitate perfect reasoning scripts without learning to self-correct. To address this limitation, we propose AdvChain, an alignment paradigm that teaches models dynamic self-correction through adversarial CoT tuning. Our method involves constructing a dataset containing Temptation-Correction and Hesitation-Correction samples, where models learn to recover from harmful reasoning drifts and unnecessary cautions. Extensive experiments show that AdvChain significantly enhances robustness against jailbreak attacks and CoT hijacking while substantially reducing over-refusal on benign prompts, achieving a superior safety-utility balance without compromising reasoning capabilities. Our work establishes a new direction for building more robust and reliable reasoning models.

