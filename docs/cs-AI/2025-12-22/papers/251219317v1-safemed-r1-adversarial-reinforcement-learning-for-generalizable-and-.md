---
layout: default
title: SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models
---

# SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19317" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.19317v1</a>
  <a href="https://arxiv.org/pdf/2512.19317.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19317v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19317v1', 'SafeMed-R1: Adversarial Reinforcement Learning for Generalizable and Robust Medical Reasoning in Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: A. A. Gde Yogi Pramana, Jason Ray, Anthony Jaya, Michael Wijaya

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SafeMed-R1ï¼šç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹ä¸­å¯æ³›åŒ–å’Œé²æ£’åŒ»å­¦æ¨ç†çš„å¯¹æŠ—å¼ºåŒ–å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŒ»å­¦è§†è§‰é—®ç­”` `å¯¹æŠ—æ”»å‡»` `å¯¹æŠ—è®­ç»ƒ` `å¼ºåŒ–å­¦ä¹ ` `é²æ£’æ€§` `è§†è§‰-è¯­è¨€æ¨¡å‹` `ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–` `éšæœºå¹³æ»‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨åŒ»å­¦è§†è§‰é—®ç­”ä¸­æ˜“å—å¯¹æŠ—æ”»å‡»ï¼Œæ ‡å‡†å¯¹æŠ—è®­ç»ƒé™ä½äº†æ³›åŒ–æ€§å’Œæ¨ç†è´¨é‡ã€‚
2. SafeMed-R1é€šè¿‡ç»“åˆå¯¹æŠ—è®­ç»ƒä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼Œå¹¶åœ¨æ¨ç†æ—¶ä½¿ç”¨éšæœºå¹³æ»‘ï¼Œå¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSafeMed-R1åœ¨å¯¹æŠ—æ”»å‡»ä¸‹æ¯”æ ‡å‡†å¾®è°ƒVLMçš„é²æ£’æ€§æé«˜äº†59ä¸ªç™¾åˆ†ç‚¹ï¼Œä¸”æ€ç»´é“¾æ¨ç†æ¨¡å‹æ›´é²æ£’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)åœ¨åŒ»å­¦è§†è§‰é—®ç­”(VQA)æ–¹é¢æ˜¾ç¤ºå‡ºå·¨å¤§çš„æ½œåŠ›ï¼Œä½†å…¶åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„éƒ¨ç½²å—åˆ°å¯¹æŠ—æ”»å‡»ä¸¥é‡è„†å¼±æ€§çš„é˜»ç¢ã€‚æ ‡å‡†çš„å¯¹æŠ—è®­ç»ƒè™½ç„¶å¯¹ç®€å•çš„ä»»åŠ¡æœ‰æ•ˆï¼Œä½†é€šå¸¸ä¼šé™ä½æ³›åŒ–æ€§èƒ½å’Œç”Ÿæˆçš„ä¸´åºŠæ¨ç†è´¨é‡ã€‚æˆ‘ä»¬å¼•å…¥äº†SafeMed-R1ï¼Œä¸€ä¸ªæ··åˆé˜²å¾¡æ¡†æ¶ï¼Œå®ƒç¡®ä¿äº†é²æ£’çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡ã€å¯è§£é‡Šçš„åŒ»å­¦æ¨ç†ã€‚SafeMed-R1é‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼šåœ¨è®­ç»ƒæ—¶ï¼Œæˆ‘ä»¬å°†å¯¹æŠ—è®­ç»ƒä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(AT-GRPO)ç›¸ç»“åˆï¼Œä»¥æ˜¾å¼åœ°å¢å¼ºæ¨ç†è¿‡ç¨‹ï¼Œä½¿å…¶å…å—æœ€åæƒ…å†µçš„æ‰°åŠ¨ï¼›åœ¨æ¨ç†æ—¶ï¼Œæˆ‘ä»¬ä½¿ç”¨éšæœºå¹³æ»‘æ¥å¢å¼ºæ¨¡å‹ï¼Œä»¥æä¾›ç»è¿‡è®¤è¯çš„$L_2$-èŒƒæ•°é²æ£’æ€§ä¿è¯ã€‚æˆ‘ä»¬åœ¨OmniMedVQAåŸºå‡†ä¸Šè¯„ä¼°äº†SafeMed-R1ï¼Œè¯¥åŸºå‡†æ¶µç›–äº†å…«ç§åŒ»å­¦æˆåƒæ¨¡å¼ï¼ŒåŒ…å«è¶…è¿‡88,000ä¸ªæ ·æœ¬ã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼Œæ ‡å‡†çš„å¾®è°ƒVLMè™½ç„¶åœ¨å¹²å‡€çš„è¾“å…¥ä¸Šè¾¾åˆ°äº†95%çš„å‡†ç¡®ç‡ï¼Œä½†åœ¨PGDæ”»å‡»ä¸‹ä¼šå´©æºƒåˆ°å¤§çº¦25%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒSafeMed-R1åœ¨ç›¸åŒçš„å¯¹æŠ—æ¡ä»¶ä¸‹ä¿æŒäº†84.45%çš„å‡†ç¡®ç‡ï¼Œä»£è¡¨äº†é²æ£’æ€§æé«˜äº†59ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜äº†ä½¿ç”¨æ˜¾å¼æ€ç»´é“¾æ¨ç†è®­ç»ƒçš„æ¨¡å‹æ¯”ä»…ä½¿ç”¨æŒ‡ä»¤çš„å˜ä½“è¡¨ç°å‡ºæ›´å¼ºçš„å¯¹æŠ—é²æ£’æ€§ï¼Œè¿™è¡¨æ˜åŒ»å­¦äººå·¥æ™ºèƒ½ç³»ç»Ÿä¸­å¯è§£é‡Šæ€§å’Œå®‰å…¨æ€§ä¹‹é—´å­˜åœ¨ååŒä½œç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŒ»å­¦è§†è§‰é—®ç­”ï¼ˆMedical VQAï¼‰ä¸­ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰å®¹æ˜“å—åˆ°å¯¹æŠ—æ”»å‡»çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚æ ‡å‡†å¯¹æŠ—è®­ç»ƒï¼Œè™½ç„¶èƒ½æé«˜é²æ£’æ€§ï¼Œä½†ä¼šç‰ºç‰²æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†è´¨é‡ï¼Œå¯¼è‡´åœ¨å®é™…ä¸´åºŠåº”ç”¨ä¸­æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå¯¹æŠ—è®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œè®¾è®¡ä¸€ä¸ªæ··åˆé˜²å¾¡æ¡†æ¶SafeMed-R1ï¼Œåœ¨è®­ç»ƒé˜¶æ®µå¢å¼ºæ¨¡å‹å¯¹å¯¹æŠ—æ ·æœ¬çš„é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒå…¶æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†è´¨é‡ã€‚æ­¤å¤–ï¼Œåœ¨æ¨ç†é˜¶æ®µä½¿ç”¨éšæœºå¹³æ»‘æŠ€æœ¯ï¼Œæä¾›ç»è¿‡è®¤è¯çš„é²æ£’æ€§ä¿è¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSafeMed-R1æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè®­ç»ƒé˜¶æ®µå’Œæ¨ç†é˜¶æ®µã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨å¯¹æŠ—è®­ç»ƒä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆAT-GRPOï¼‰ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œæ˜¾å¼åœ°å¢å¼ºæ¨ç†è¿‡ç¨‹ï¼Œä½¿å…¶å…å—æœ€åæƒ…å†µçš„æ‰°åŠ¨ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨éšæœºå¹³æ»‘æŠ€æœ¯æ¥å¢å¼ºæ¨¡å‹ï¼Œä»¥æä¾›ç»è¿‡è®¤è¯çš„$L_2$-èŒƒæ•°é²æ£’æ€§ä¿è¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¯¹æŠ—è®­ç»ƒä¸ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ç›¸ç»“åˆï¼Œç”¨äºå¢å¼ºåŒ»å­¦è§†è§‰é—®ç­”æ¨¡å‹çš„é²æ£’æ€§ã€‚ä¸ä¼ ç»Ÿçš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒAT-GRPOèƒ½å¤Ÿæ›´å¥½åœ°å¹³è¡¡æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒé«˜è´¨é‡çš„ä¸´åºŠæ¨ç†ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¯æ˜äº†ä½¿ç”¨æ˜¾å¼æ€ç»´é“¾æ¨ç†è®­ç»ƒçš„æ¨¡å‹å…·æœ‰æ›´å¼ºçš„å¯¹æŠ—é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šAT-GRPOçš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹å…¶ç›®æ ‡æ˜¯ä¼˜åŒ–ç­–ç•¥ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¯¹æŠ—æ ·æœ¬ä¸Šçš„è¡¨ç°å°½å¯èƒ½æ¥è¿‘åœ¨å¹²å‡€æ ·æœ¬ä¸Šçš„è¡¨ç°ã€‚éšæœºå¹³æ»‘çš„å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ï¼Œä½†å…¶ç›®çš„æ˜¯é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œéšæœºæ‰°åŠ¨ï¼Œå¹¶å¯¹æ¨¡å‹çš„è¾“å‡ºè¿›è¡Œå¹³å‡ï¼Œä»è€Œæé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚è®ºæ–‡ä¸­ä½¿ç”¨çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19317v1/general_ovvw.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19317v1/example.png" alt="fig_1" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

SafeMed-R1åœ¨OmniMedVQAåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨PGDæ”»å‡»ä¸‹ï¼Œæ ‡å‡†å¾®è°ƒVLMçš„å‡†ç¡®ç‡ä»95%ä¸‹é™åˆ°25%ï¼Œè€ŒSafeMed-R1ä¿æŒäº†84.45%çš„å‡†ç¡®ç‡ï¼Œé²æ£’æ€§æé«˜äº†59ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜è¡¨æ˜ï¼Œä½¿ç”¨æ˜¾å¼æ€ç»´é“¾æ¨ç†è®­ç»ƒçš„æ¨¡å‹æ¯”ä»…ä½¿ç”¨æŒ‡ä»¤çš„å˜ä½“è¡¨ç°å‡ºæ›´å¼ºçš„å¯¹æŠ—é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SafeMed-R1çš„ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»ç–—å½±åƒè¯Šæ–­ã€è¾…åŠ©å†³ç­–ç­‰é¢†åŸŸï¼Œæé«˜åŒ»å­¦äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹å¯¹å¯¹æŠ—æ”»å‡»çš„é˜²å¾¡èƒ½åŠ›ï¼Œå¯ä»¥é¿å…æ¶æ„æ”»å‡»è€…ç¯¡æ”¹è¯Šæ–­ç»“æœï¼Œä¿éšœæ‚£è€…çš„æƒç›Šã€‚è¯¥ç ”ç©¶è¿˜æœ‰åŠ©äºæ¨åŠ¨åŒ»å­¦äººå·¥æ™ºèƒ½åœ¨ä¸´åºŠç¯å¢ƒä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œæå‡åŒ»ç–—æœåŠ¡çš„è´¨é‡å’Œæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Vision--Language Models (VLMs) show significant promise for Medical Visual Question Answering (VQA), yet their deployment in clinical settings is hindered by severe vulnerability to adversarial attacks. Standard adversarial training, while effective for simpler tasks, often degrades both generalization performance and the quality of generated clinical reasoning. We introduce SafeMed-R1, a hybrid defense framework that ensures robust performance while preserving high-quality, interpretable medical reasoning. SafeMed-R1 employs a two-stage approach: at training time, we integrate Adversarial Training with Group Relative Policy Optimization (AT-GRPO) to explicitly robustify the reasoning process against worst-case perturbations; at inference time, we augment the model with Randomized Smoothing to provide certified $L_2$-norm robustness guarantees. We evaluate SafeMed-R1 on the OmniMedVQA benchmark across eight medical imaging modalities comprising over 88,000 samples. Our experiments reveal that standard fine-tuned VLMs, despite achieving 95\% accuracy on clean inputs, collapse to approximately 25\% under PGD attacks. In contrast, SafeMed-R1 maintains 84.45\% accuracy under the same adversarial conditions, representing a 59 percentage point improvement in robustness. Furthermore, we demonstrate that models trained with explicit chain-of-thought reasoning exhibit superior adversarial robustness compared to instruction-only variants, suggesting a synergy between interpretability and security in medical AI systems.

