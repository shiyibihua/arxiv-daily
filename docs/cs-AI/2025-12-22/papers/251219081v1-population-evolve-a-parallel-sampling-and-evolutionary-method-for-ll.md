---
layout: default
title: Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning
---

# Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19081" class="toolbar-btn" target="_blank">📄 arXiv: 2512.19081v1</a>
  <a href="https://arxiv.org/pdf/2512.19081.pdf" class="toolbar-btn" target="_blank">📥 PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19081v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19081v1', 'Population-Evolve: a Parallel Sampling and Evolutionary Method for LLM Math Reasoning')" title="添加到收藏夹">☆ 收藏</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">🔗 分享</button>
</div>


**作者**: Yanzhi Zhang, Yitong Duan, Zhaoxi Zhang, Jiyan He, Shuxin Zheng

**分类**: cs.AI

**发布日期**: 2025-12-22

---

## 💡 一句话要点

**提出Population-Evolve，一种基于遗传算法的LLM数学推理优化方法**

🎯 **匹配领域**: **支柱九：具身大模型 (Embodied Foundation Models)**

**关键词**: `大型语言模型` `数学推理` `遗传算法` `测试时扩展` `进化提示`

## 📋 核心要点

1. 现有LLM推理方法在复杂问题上表现不足，且缺乏有效的优化策略，限制了其推理能力的充分发挥。
2. Population-Evolve借鉴遗传算法思想，维护候选解种群，并通过进化提示引导LLM自我进化，提升推理质量。
3. 实验表明，Population-Evolve在数学推理任务上取得了更高的准确率，同时降低了性能方差，提升了计算效率。

## 📝 摘要（中文）

近年来，测试时扩展已成为增强大型语言模型推理能力的一个有前景的方向。本文提出Population-Evolve，一种受遗传算法启发的免训练方法，用于优化LLM推理。该方法通过并行推理，为每个问题维护一个候选解的动态种群。通过引入进化提示，LLM在所有迭代中自我进化其种群。收敛后，最终答案通过多数投票得出。此外，我们建立了一个统一框架，通过遗传算法的视角解释现有的测试时扩展策略。实验结果表明，Population-Evolve以较低的性能方差和计算效率实现了卓越的准确性。我们的发现突出了进化策略在推理过程中释放LLM推理能力的潜力。

## 🔬 方法详解

**问题定义**：论文旨在解决大型语言模型（LLM）在数学推理任务中准确率不高的问题。现有的测试时扩展策略虽然能提升性能，但缺乏统一的理论框架，且可能存在性能方差较大、计算效率不高等问题。

**核心思路**：论文的核心思路是借鉴遗传算法的思想，将LLM的推理过程视为一个种群进化过程。通过维护一个候选解的种群，并利用LLM自身的能力进行种群的迭代和优化，最终得到更准确的答案。这种方法旨在通过模拟自然选择的过程，提升LLM的推理能力。

**技术框架**：Population-Evolve方法包含以下几个主要阶段：1) 初始化：为每个问题生成一个候选解的初始种群，每个解代表一个可能的答案或推理路径。2) 进化：通过“进化提示”引导LLM对种群进行迭代更新。进化提示指示LLM根据当前种群的质量，生成新的候选解，或者对现有解进行改进。3) 选择：在每次迭代后，根据某种评价标准（例如，LLM对解的置信度）对种群中的解进行评估。4) 收敛：当种群达到收敛状态（例如，种群中的解的相似度达到一定阈值，或者迭代次数达到上限）时，停止迭代。5) 投票：通过多数投票的方式，从最终种群中选择最可能的答案。

**关键创新**：该方法最重要的创新点在于将遗传算法的思想引入到LLM的推理过程中，并设计了“进化提示”来引导LLM进行自我进化。与传统的测试时扩展策略相比，Population-Evolve能够更有效地利用LLM自身的能力，进行推理路径的探索和优化。此外，论文还提出了一个统一框架，将现有的测试时扩展策略纳入到遗传算法的视角下进行解释。

**关键设计**：进化提示的设计是关键。它需要能够有效地引导LLM生成高质量的候选解，并避免陷入局部最优。论文中可能使用了特定的提示工程技巧，例如，提供一些高质量的推理示例，或者使用一些鼓励探索和创新的语言。此外，种群大小、迭代次数、收敛阈值等参数的设置也会影响最终的性能。

## 🖼️ 关键图片

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19081v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19081v1/images/Variance.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19081v1/images/Population_Evolving.png" alt="fig_2" loading="lazy">
</figure>
</div>

## 📊 实验亮点

实验结果表明，Population-Evolve在数学推理任务上取得了显著的性能提升。具体而言，该方法在多个基准数据集上超越了现有的测试时扩展策略，并且降低了性能方差。此外，实验还验证了Population-Evolve的计算效率，表明该方法能够在合理的时间内完成推理任务。

## 🎯 应用场景

Population-Evolve方法可应用于各种需要复杂推理的场景，如数学问题求解、代码生成、逻辑推理等。该方法能够提升LLM在这些任务上的准确性和可靠性，具有广泛的应用前景。未来，该方法可以进一步扩展到其他类型的推理任务，并与其他技术（如知识图谱、符号推理）相结合，以实现更强大的推理能力。

## 📄 摘要（原文）

> Test-time scaling has emerged as a promising direction for enhancing the reasoning capabilities of Large Language Models in last few years. In this work, we propose Population-Evolve, a training-free method inspired by Genetic Algorithms to optimize LLM reasoning. Our approach maintains a dynamic population of candidate solutions for each problem via parallel reasoning. By incorporating an evolve prompt, the LLM self-evolves its population in all iterations. Upon convergence, the final answer is derived via majority voting. Furthermore, we establish a unification framework that interprets existing test-time scaling strategies through the lens of genetic algorithms. Empirical results demonstrate that Population-Evolve achieves superior accuracy with low performance variance and computational efficiency. Our findings highlight the potential of evolutionary strategies to unlock the reasoning power of LLMs during inference.

