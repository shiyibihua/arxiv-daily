---
layout: default
title: Can abstract concepts from LLM improve SLM performance?
---

# Can abstract concepts from LLM improve SLM performance?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19069" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.19069v1</a>
  <a href="https://arxiv.org/pdf/2512.19069.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19069v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19069v1', 'Can abstract concepts from LLM improve SLM performance?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Siddharth Tandon

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨LLMæŠ½è±¡æ¦‚å¿µæå‡SLMæ€§èƒ½ï¼Œå®ç°æ¨ç†æ—¶åŠ¨æ€è°ƒæ•´**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å°å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è¿ç§»` `steering vectors` `æ¨ç†ä¼˜åŒ–` `æ¨¡å‹å‹ç¼©` `èµ„æºå—é™è®¾å¤‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼ˆé‡åŒ–ã€å‰ªæç­‰ï¼‰éƒ¨ç½²å¤æ‚ï¼Œéœ€è¦å¤§é‡å®éªŒå’ŒåŸºç¡€è®¾æ–½æ”¯æŒã€‚
2. è®ºæ–‡æå‡ºå°†LLMä¸­çš„é«˜çº§æ¦‚å¿µï¼ˆsteering vectorsï¼‰è¿ç§»åˆ°SLMï¼Œæå‡SLMçš„æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯æœ‰æ•ˆæå‡ä¸åŒSLMå®¶æ—ï¼ˆPhi, Llama, Qwenï¼‰çš„æ€§èƒ½ï¼ŒQwen3-0.6Bå‡†ç¡®ç‡æå‡7-15%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å°†å…¶éƒ¨ç½²åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚é‡åŒ–ã€å‰ªæå’Œè’¸é¦ç­‰ç°æœ‰æ–¹æ³•å¯ä»¥å‡å°‘å†…å­˜å ç”¨ï¼Œä½†é€šå¸¸éœ€è¦å¤§é‡çš„å®éªŒå’Œä»”ç»†çš„åŸºç¡€è®¾æ–½è®¾è®¡ã€‚æœ¬æ–‡åˆ©ç”¨ç°æœ‰çš„ä»å¤§å‹æ¨¡å‹ä¸­æå–é«˜çº§æ¦‚å¿µï¼ˆè¡¨ç¤ºä¸ºsteering vectorsï¼‰çš„æŠ€æœ¯ï¼Œç ”ç©¶å®ƒä»¬åœ¨æ¨ç†æ—¶å¯¹å°å‹è¯­è¨€æ¨¡å‹(SLM)çš„å¯è¿ç§»æ€§ã€‚é€šè¿‡å¤§é‡çš„å®éªŒè¯æ˜ï¼Œè¿™äº›æ¦‚å¿µå¯ä»¥æœ‰æ•ˆåœ°è½¬ç§»åˆ°æ›´å°çš„æ¨¡å‹ï¼Œè€Œä¸ç®¡å®ƒä»¬çš„å®¶æ—ï¼ˆä¾‹å¦‚ï¼ŒPhiï¼ŒLlamaï¼ŒQwenï¼‰ï¼Œä»è€Œæé«˜å„ç§ä»»åŠ¡çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å¼•å…¥äº†æ¨ç†æ—¶ç¼©æ”¾ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´steering intensityæ¥å¢å¼ºæ€§èƒ½ï¼Œä»è€Œä½¿Qwen3-0.6Bçš„å‡†ç¡®ç‡æé«˜äº†7-15%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰éš¾ä»¥åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²çš„é—®é¢˜ã€‚ç°æœ‰æ¨¡å‹å‹ç¼©æ–¹æ³•ï¼Œå¦‚é‡åŒ–ã€å‰ªæå’Œè’¸é¦ï¼Œè™½ç„¶å¯ä»¥å‡å°æ¨¡å‹ä½“ç§¯ï¼Œä½†é€šå¸¸éœ€è¦å¤§é‡çš„å®éªŒå’Œå¤æ‚çš„å·¥ç¨‹è®¾è®¡ï¼Œéƒ¨ç½²æˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMä¸­å­¦ä¹ åˆ°çš„é«˜çº§æŠ½è±¡æ¦‚å¿µï¼ˆsteering vectorsï¼‰è¿ç§»åˆ°å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰ä¸­ï¼Œä»è€Œæå‡SLMçš„æ€§èƒ½ï¼Œè€Œæ— éœ€å¯¹SLMè¿›è¡Œé¢å¤–çš„è®­ç»ƒæˆ–å¾®è°ƒã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨åˆ©ç”¨LLMçš„çŸ¥è¯†ï¼Œä»¥ä¸€ç§æ›´è½»é‡çº§çš„æ–¹å¼å¢å¼ºSLMçš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼š1) ä»LLMä¸­æå–steering vectorsï¼Œè¿™äº›vectorsä»£è¡¨äº†LLMå­¦ä¹ åˆ°çš„é«˜çº§æ¦‚å¿µã€‚2) åœ¨SLMçš„æ¨ç†è¿‡ç¨‹ä¸­ï¼Œå°†è¿™äº›steering vectorsæ³¨å…¥åˆ°SLMçš„æ¿€æ´»ä¸­ï¼Œä»è€Œå¼•å¯¼SLMçš„è¾“å‡ºã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼•å…¥äº†æ¨ç†æ—¶ç¼©æ”¾ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´steering intensityæ¥è¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMçš„æŠ½è±¡æ¦‚å¿µä»¥steering vectorsçš„å½¢å¼è¿ç§»åˆ°SLMï¼Œå®ç°çŸ¥è¯†è¿ç§»ã€‚ä¸ä¼ ç»Ÿçš„æ¨¡å‹è’¸é¦æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦è®­ç»ƒSLMï¼Œè€Œæ˜¯ç›´æ¥åœ¨æ¨ç†æ—¶æ³¨å…¥çŸ¥è¯†ï¼Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œæ¨ç†æ—¶ç¼©æ”¾æœºåˆ¶å…è®¸åŠ¨æ€è°ƒæ•´steering intensityï¼Œè¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šsteering vectorsçš„æå–æ–¹å¼æœªçŸ¥ï¼Œè®ºæ–‡ä¸­æ²¡æœ‰è¯¦ç»†æè¿°ã€‚æ¨ç†æ—¶ç¼©æ”¾çš„å…³é”®åœ¨äºç¡®å®šåˆé€‚çš„steering intensityã€‚è®ºæ–‡é€šè¿‡å®éªŒç¡®å®šäº†æœ€ä½³çš„ç¼©æ”¾å› å­ï¼Œä½†å…·ä½“çš„ä¼˜åŒ–ç®—æ³•æœªçŸ¥ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19069v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19069v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19069v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å°†LLMçš„æŠ½è±¡æ¦‚å¿µè¿ç§»åˆ°SLMï¼Œå¹¶æ˜¾è‘—æå‡SLMåœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å¯¹äºQwen3-0.6Bæ¨¡å‹ï¼Œé€šè¿‡å¼•å…¥æ¨ç†æ—¶ç¼©æ”¾ï¼Œå‡†ç¡®ç‡æé«˜äº†7-15%ã€‚è¯¥æ–¹æ³•é€‚ç”¨äºä¸åŒçš„SLMå®¶æ—ï¼Œä¾‹å¦‚Phi, Llamaå’ŒQwenï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§èµ„æºå—é™çš„åœºæ™¯ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡ã€åµŒå…¥å¼ç³»ç»Ÿå’Œè¾¹ç¼˜è®¡ç®—è®¾å¤‡ã€‚é€šè¿‡å°†LLMçš„çŸ¥è¯†è¿ç§»åˆ°SLMï¼Œå¯ä»¥åœ¨è¿™äº›è®¾å¤‡ä¸Šéƒ¨ç½²æ›´æ™ºèƒ½çš„åº”ç”¨ï¼Œä¾‹å¦‚æ™ºèƒ½åŠ©æ‰‹ã€æœºå™¨ç¿»è¯‘å’Œæ–‡æœ¬ç”Ÿæˆã€‚è¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæå‡ç°æœ‰SLMçš„æ€§èƒ½ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) excel at diverse tasks, but their deployment on resource-constrained devices remains challenging. Existing methods like quantization, pruning, and distillation can reduce memory footprint but often demand extensive experimentation and careful infrastructure design. Leveraging existing techniques for extracting high-level concepts (represented as steering vectors) from larger models, we investigate their transferability to smaller language models (SLM) during inference. We demonstrate through extensive experimentation that these concepts can be effectively transferred to smaller models, irrespective of their family (e.g., Phi, Llama, Qwen), leading to performance improvements across a wide range of tasks. Furthermore, we introduce inference-time scaling to enhance performance by dynamically adjusting the steering intensity which has resulted in a 7-15\% of accuracy improvement for Qwen3-0.6B.

