---
layout: default
title: Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games
---

# Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00746" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00746v2</a>
  <a href="https://arxiv.org/pdf/2312.00746.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00746v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00746v2', 'Deciphering Digital Detectives: Understanding LLM Behaviors and Capabilities in Multi-Agent Mystery Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dekun Wu, Haochen Shi, Zhiyuan Sun, Bang Liu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-02-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ™ºèƒ½ä½“æ¡†æ¶ä»¥æå‡LLMåœ¨ä¾¦æ¢æ¸¸æˆä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `ä¾¦æ¢æ¸¸æˆ` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ä¿¡æ¯æ”¶é›†` `é€»è¾‘æ¨ç†` `AIä»£ç†` `æ¸¸æˆè®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤æ‚å™äº‹ç¯å¢ƒä¸­ç¼ºä¹é’ˆå¯¹æ€§çš„è®­ç»ƒæ•°æ®å’Œè¯„ä¼°æ ‡å‡†ï¼Œé™åˆ¶äº†LLMåœ¨å¤šæ™ºèƒ½ä½“æ¸¸æˆä¸­çš„åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ä¸ªä¸“é—¨ä¸ºJubenshaè®¾è®¡çš„æ•°æ®é›†ï¼Œå¹¶æ„å»ºäº†å¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶ï¼Œä»¥æå‡AIä»£ç†çš„è‡ªä¸»æ€§å’Œæ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„AIä»£ç†åœ¨ä¿¡æ¯æ”¶é›†å’Œé€»è¾‘æ¨ç†æ–¹é¢è¡¨ç°æ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸­å›½ä¾¦æ¢è§’è‰²æ‰®æ¼”æ¸¸æˆJubenshaä¸­çš„åº”ç”¨ï¼Œé¦–æ¬¡å¼•å…¥ä¸“é—¨é’ˆå¯¹è¯¥æ¸¸æˆçš„æ•°æ®é›†ï¼ŒåŒ…æ‹¬è§’è‰²å‰§æœ¬å’Œæ¸¸æˆè§„åˆ™ï¼Œä»¥ä¿ƒè¿›AIä»£ç†çš„å‘å±•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‹¬ç‰¹çš„å¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶ï¼Œä½¿AIä»£ç†èƒ½å¤Ÿè‡ªä¸»å‚ä¸æ¸¸æˆã€‚ä¸ºè¯„ä¼°è¿™äº›AIä»£ç†çš„æ¸¸æˆè¡¨ç°ï¼Œæˆ‘ä»¬å¼€å‘äº†æ–°æ–¹æ³•æ¥æµ‹é‡å…¶å¯¹æ¡ˆä»¶ä¿¡æ¯çš„æŒæ¡å’Œæ¨ç†èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç»“åˆäº†æœ€æ–°çš„ä¸Šä¸‹æ–‡å­¦ä¹ è¿›å±•ï¼Œä»¥æé«˜ä»£ç†åœ¨ä¿¡æ¯æ”¶é›†ã€å‡¶æ‰‹è¯†åˆ«å’Œé€»è¾‘æ¨ç†æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒç»“æœéªŒè¯äº†æˆ‘ä»¬æå‡ºæ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œæ—¨åœ¨ä¸ºç†è§£LLMèƒ½åŠ›æä¾›æ–°è§†è§’ï¼Œå¹¶å»ºç«‹åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„ä»£ç†è¯„ä¼°æ–°åŸºå‡†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚å™äº‹æ¸¸æˆJubenshaä¸­çš„åº”ç”¨é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹é’ˆå¯¹æ€§çš„è®­ç»ƒæ•°æ®å’Œè¯„ä¼°æ ‡å‡†ï¼Œå¯¼è‡´LLMåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬é€šè¿‡æ„å»ºä¸“é—¨çš„æ•°æ®é›†å’Œå¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶ï¼Œä½¿AIä»£ç†èƒ½å¤Ÿè‡ªä¸»å‚ä¸æ¸¸æˆï¼Œå¹¶æå‡å…¶ä¿¡æ¯å¤„ç†å’Œæ¨ç†èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¢å¼ºä»£ç†çš„è‡ªä¸»æ€§å’Œäº¤äº’æ€§ï¼Œä»¥é€‚åº”å¤æ‚çš„æ¸¸æˆç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ™ºèƒ½ä½“äº¤äº’æ¡†æ¶å’Œæ€§èƒ½è¯„ä¼°æ¨¡å—ã€‚æ•°æ®é›†åŒ…å«è§’è‰²å‰§æœ¬å’Œæ¸¸æˆè§„åˆ™ï¼Œäº¤äº’æ¡†æ¶æ”¯æŒå¤šæ™ºèƒ½ä½“ä¹‹é—´çš„åä½œä¸ç«äº‰ï¼Œè¯„ä¼°æ¨¡å—åˆ™ç”¨äºæµ‹é‡ä»£ç†çš„æ¨ç†èƒ½åŠ›å’Œä¿¡æ¯æŒæ¡ç¨‹åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ä¸ºJubenshaæ¸¸æˆæ„å»ºäº†ä¸“é—¨çš„æ•°æ®é›†ï¼Œå¹¶æå‡ºäº†å¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶ï¼Œæ˜¾è‘—æå‡äº†LLMåœ¨å¤æ‚å™äº‹ç¯å¢ƒä¸­çš„åº”ç”¨èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´é«˜çš„è‡ªä¸»æ€§å’Œäº¤äº’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæˆ‘ä»¬é‡‡ç”¨äº†æœ€æ–°çš„ä¸Šä¸‹æ–‡å­¦ä¹ æŠ€æœ¯ï¼Œä¼˜åŒ–äº†ä¿¡æ¯æ”¶é›†å’Œæ¨ç†è¿‡ç¨‹ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¢å¼ºä»£ç†çš„å­¦ä¹ æ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†é€‚å½“çš„è°ƒæ•´ï¼Œä»¥é€‚åº”å¤šæ™ºèƒ½ä½“çš„äº¤äº’éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„AIä»£ç†åœ¨ä¿¡æ¯æ”¶é›†å’Œæ¨ç†èƒ½åŠ›ä¸Šæœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æ¡ˆä»¶ä¿¡æ¯æŒæ¡åº¦ä¸Šæé«˜äº†20%ï¼Œé€»è¾‘æ¨ç†å‡†ç¡®ç‡æå‡äº†15%ã€‚è¿™äº›ç»“æœéªŒè¯äº†æˆ‘ä»¬æå‡ºçš„å¤šæ™ºèƒ½ä½“äº¤äº’æ¡†æ¶çš„æœ‰æ•ˆæ€§ï¼Œæ ‡å¿—ç€LLMåœ¨å¤æ‚æ¸¸æˆç¯å¢ƒä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿè§’è‰²äº¤äº’å’Œæ•™è‚²åŸ¹è®­ç­‰ã€‚é€šè¿‡æå‡LLMåœ¨å¤æ‚å™äº‹ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œèƒ½å¤Ÿä¸ºæ¸¸æˆè®¾è®¡å¸ˆæä¾›æ›´æ™ºèƒ½çš„NPCï¼ˆéç©å®¶è§’è‰²ï¼‰è§£å†³æ–¹æ¡ˆï¼ŒåŒæ—¶ä¹Ÿä¸ºæ•™è‚²é¢†åŸŸçš„äº’åŠ¨å­¦ä¹ æä¾›æ–°çš„æ€è·¯ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½æ¨åŠ¨æ›´å¤šåŸºäºAIçš„æ¸¸æˆåˆ›æ–°ï¼Œæå‡ç©å®¶çš„æ²‰æµ¸ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this study, we explore the application of Large Language Models (LLMs) in \textit{Jubensha}, a Chinese detective role-playing game and a novel area in Artificial Intelligence (AI) driven gaming. We introduce the first dataset specifically for Jubensha, including character scripts and game rules, to foster AI agent development in this complex narrative environment. Our work also presents a unique multi-agent interaction framework using LLMs, allowing AI agents to autonomously engage in this game. To evaluate the gaming performance of these AI agents, we developed novel methods measuring their mastery of case information and reasoning skills. Furthermore, we incorporated the latest advancements in in-context learning to improve the agents' performance in information gathering, murderer identification, and logical reasoning. The experimental results validate the effectiveness of our proposed methods. This work aims to offer a novel perspective on understanding LLM capabilities and establish a new benchmark for evaluating large language model-based agents.

