---
layout: default
title: LLM-TAKE: Theme Aware Keyword Extraction Using Large Language Models
---

# LLM-TAKE: Theme Aware Keyword Extraction Using Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00909" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00909v1</a>
  <a href="https://arxiv.org/pdf/2312.00909.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00909v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00909v1', 'LLM-TAKE: Theme Aware Keyword Extraction Using Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Reza Yousefi Maragheh, Chenhao Fang, Charan Chand Irugu, Parth Parikh, Jason Cho, Jianpeng Xu, Saranyan Sukumar, Malay Patel, Evren Korpeoglu, Sushant Kumar, Kannan Achan

**åˆ†ç±»**: cs.IR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM-TAKEä»¥è§£å†³å…³é”®è¯æå–ä¸­çš„ä¸»é¢˜æ„ŸçŸ¥é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…³é”®è¯æå–` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸»é¢˜æ„ŸçŸ¥` `è‡ªç„¶è¯­è¨€å¤„ç†` `ç”µå­å•†åŠ¡` `ä¿¡æ¯æ£€ç´¢` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å…³é”®è¯æå–æ¨¡å‹ç”±äºçŸ­æ³¨æ„åŠ›èŒƒå›´ï¼Œéš¾ä»¥æ•æ‰é•¿è·ç¦»çš„è¯è¯­å…³ç³»ï¼Œé™åˆ¶äº†å…¶ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºçš„LLM-TAKEæ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡å¤šé˜¶æ®µå¤„ç†ç”Ÿæˆä¸»é¢˜æ„ŸçŸ¥çš„å…³é”®è¯ï¼Œæå‡æå–è´¨é‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-TAKEåœ¨å‡†ç¡®æ€§å’Œå¤šæ ·æ€§æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºå‡†æ¨¡å‹ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…³é”®è¯æå–æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æ ¸å¿ƒä»»åŠ¡ã€‚ä¼ ç»Ÿçš„æå–æ¨¡å‹ç”±äºæ³¨æ„åŠ›èŒƒå›´çŸ­ï¼Œéš¾ä»¥æ•æ‰è¿œè·ç¦»è¯è¯­å’Œå¥å­ä¹‹é—´çš„å…³ç³»ï¼Œé™åˆ¶äº†å…¶åœ¨ç”ŸæˆåŸºäºä¸Šä¸‹æ–‡çš„å…³é”®è¯æ—¶çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æ¢è®¨äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”ŸæˆåŸºäºæ–‡æœ¬å…ƒæ•°æ®çš„å…³é”®è¯ã€‚æˆ‘ä»¬æå‡ºçš„LLM-TAKEæ¡†æ¶é€šè¿‡å¤šä¸ªé˜¶æ®µç»†åŒ–ç»“æœï¼Œé¿å…è¾“å‡ºæ— ä¿¡æ¯æˆ–æ•æ„Ÿçš„å…³é”®è¯ï¼Œå¹¶å‡å°‘LLMå¸¸è§çš„å¹»è§‰ç°è±¡ã€‚æˆ‘ä»¬ä¸ºç”µå­å•†åŠ¡ç¯å¢ƒä¸­çš„äº§å“ç”Ÿæˆäº†æå–æ€§å’ŒæŠ½è±¡æ€§ä¸»é¢˜çš„ä¸¤ç§æ¡†æ¶å˜ä½“ï¼Œå¹¶åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºè¯¥æ¡†æ¶åœ¨å‡†ç¡®æ€§å’Œå¤šæ ·æ€§æŒ‡æ ‡ä¸Šä¼˜äºåŸºå‡†æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå…³é”®è¯æå–ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ¨¡å‹å› çŸ­æ³¨æ„åŠ›èŒƒå›´éš¾ä»¥æ•æ‰é•¿è·ç¦»è¯è¯­å…³ç³»ï¼Œå¯¼è‡´ç”Ÿæˆçš„å…³é”®è¯ç¼ºä¹ä¸Šä¸‹æ–‡ç›¸å…³æ€§å’Œä¿¡æ¯é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLLM-TAKEæ¡†æ¶é€šè¿‡ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç»“åˆå¤šé˜¶æ®µå¤„ç†ï¼Œæ—¨åœ¨ç”Ÿæˆæ›´å…·ä¸»é¢˜æ„ŸçŸ¥çš„å…³é”®è¯ï¼Œé¿å…æ— ä¿¡æ¯æˆ–æ•æ„Ÿå†…å®¹çš„è¾“å‡ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆé€šè¿‡LLMç”Ÿæˆåˆæ­¥å…³é”®è¯ï¼Œç„¶åè¿›è¡Œä¸»é¢˜æå–å’Œä¿¡æ¯ç­›é€‰ï¼Œæœ€åä¼˜åŒ–è¾“å‡ºä»¥å‡å°‘å¹»è§‰ç°è±¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šLLM-TAKEçš„åˆ›æ–°åœ¨äºå…¶ä¸»é¢˜æ„ŸçŸ¥èƒ½åŠ›ï¼Œé€šè¿‡ç»“åˆæå–æ€§å’ŒæŠ½è±¡æ€§ä¸»é¢˜ç”Ÿæˆæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å…³é”®è¯æå–çš„è´¨é‡å’Œç›¸å…³æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å…³é”®è¯çš„ç›¸å…³æ€§ï¼Œå¹¶è®¾ç½®äº†å¤šå±‚æ¬¡çš„ç­›é€‰æœºåˆ¶ï¼Œä»¥ç¡®ä¿è¾“å‡ºå…³é”®è¯çš„æœ‰æ•ˆæ€§å’Œå¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ä¸‰ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLM-TAKEåœ¨å‡†ç¡®æ€§å’Œå¤šæ ·æ€§æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºå‡†æ¨¡å‹ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨å…³é”®è¯æå–ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­å•†åŠ¡ã€å†…å®¹æ¨èå’Œä¿¡æ¯æ£€ç´¢ç­‰ã€‚é€šè¿‡æé«˜å…³é”®è¯æå–çš„å‡†ç¡®æ€§å’Œä¸»é¢˜æ„ŸçŸ¥èƒ½åŠ›ï¼ŒLLM-TAKEèƒ½å¤Ÿå¸®åŠ©å•†å®¶æ›´å¥½åœ°ç†è§£ç”¨æˆ·éœ€æ±‚ï¼Œæå‡äº§å“çš„å¯å‘ç°æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½æœç´¢å’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Keyword extraction is one of the core tasks in natural language processing. Classic extraction models are notorious for having a short attention span which make it hard for them to conclude relational connections among the words and sentences that are far from each other. This, in turn, makes their usage prohibitive for generating keywords that are inferred from the context of the whole text. In this paper, we explore using Large Language Models (LLMs) in generating keywords for items that are inferred from the items textual metadata. Our modeling framework includes several stages to fine grain the results by avoiding outputting keywords that are non informative or sensitive and reduce hallucinations common in LLM. We call our LLM-based framework Theme-Aware Keyword Extraction (LLM TAKE). We propose two variations of framework for generating extractive and abstractive themes for products in an E commerce setting. We perform an extensive set of experiments on three real data sets and show that our modeling framework can enhance accuracy based and diversity based metrics when compared with benchmark models.

