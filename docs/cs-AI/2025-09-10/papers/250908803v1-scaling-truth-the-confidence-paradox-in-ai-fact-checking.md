---
layout: default
title: Scaling Truth: The Confidence Paradox in AI Fact-Checking
---

# Scaling Truth: The Confidence Paradox in AI Fact-Checking

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08803" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08803v1</a>
  <a href="https://arxiv.org/pdf/2509.08803.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08803v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08803v1', 'Scaling Truth: The Confidence Paradox in AI Fact-Checking')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ihsan A. Qazi, Zohaib Khan, Abdullah Ghani, Agha A. Raza, Zafar A. Qazi, Wassay Sajjad, Ayesha Ali, Asher Javaid, Muhammad Abdullah Sohail, Abdul H. Azeemi

**åˆ†ç±»**: cs.SI, cs.AI, cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: 65 pages, 26 figures, 6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºAIäº‹å®æ ¸æŸ¥ä¸­çš„ç½®ä¿¡åº¦æ‚–è®ºï¼šå°æ¨¡å‹é«˜ç½®ä¿¡åº¦ä½†ä½å‡†ç¡®ç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `äº‹å®æ ¸æŸ¥` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç½®ä¿¡åº¦æ‚–è®º` `å¤šè¯­è¨€` `ä¿¡æ¯å…¬å¹³`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰äº‹å®æ ¸æŸ¥æ–¹æ³•éš¾ä»¥è§„æ¨¡åŒ–ï¼Œä¸”å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…¨çƒèŒƒå›´å†…çš„æœ‰æ•ˆæ€§å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚
2. è®ºæ–‡é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒè§„æ¨¡å’Œæ¶æ„çš„LLMï¼Œæ­ç¤ºäº†æ¨¡å‹ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡ä¹‹é—´çš„æ‚–è®ºç°è±¡ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå°æ¨¡å‹é«˜ç½®ä¿¡åº¦ä½†ä½å‡†ç¡®ç‡ï¼Œä¸”éè‹±è¯­å’Œå…¨çƒå—æ–¹å†…å®¹æ€§èƒ½å·®è·æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é”™è¯¯ä¿¡æ¯çš„æ³›æ»¥å‡¸æ˜¾äº†å¯¹å¯æ‰©å±•ä¸”å¯é çš„äº‹å®æ ¸æŸ¥è§£å†³æ–¹æ¡ˆçš„éœ€æ±‚ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨åŒ–äº‹å®éªŒè¯æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œä½†å®ƒä»¬åœ¨å…¨çƒèŒƒå›´å†…çš„æœ‰æ•ˆæ€§ä»ä¸ç¡®å®šã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¹ä¸ªå·²å»ºç«‹çš„LLMï¼ˆåŒ…æ‹¬å¼€æº/é—­æºã€ä¸åŒè§„æ¨¡ã€å¤šæ ·æ¶æ„ã€åŸºäºæ¨ç†çš„æ¨¡å‹ï¼‰ï¼Œä½¿ç”¨äº†æ¥è‡ª47ç§è¯­è¨€çš„174ä¸ªä¸“ä¸šäº‹å®æ ¸æŸ¥ç»„ç»‡å…ˆå‰è¯„ä¼°çš„5000æ¡å£°æ˜ã€‚è¯¥æ–¹æ³•æµ‹è¯•äº†æ¨¡å‹åœ¨è®­ç»ƒæˆªæ­¢æ—¥æœŸä¹‹åå‘å¸ƒçš„å£°æ˜ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä»¥åŠæ¨¡ä»¿å…¬æ°‘å’Œä¸“ä¸šäº‹å®æ ¸æŸ¥å‘˜äº¤äº’çš„å››ç§æç¤ºç­–ç•¥ï¼Œå¹¶ä»¥è¶…è¿‡24ä¸‡æ¡äººå·¥æ ‡æ³¨ä½œä¸ºground truthã€‚ç ”ç©¶ç»“æœæ­ç¤ºäº†ä¸€ç§ç±»ä¼¼äºé‚“å®-å…‹é²æ ¼æ•ˆåº”çš„ä»¤äººæ‹…å¿§çš„æ¨¡å¼ï¼šè¾ƒå°çš„ã€æ˜“äºè®¿é—®çš„æ¨¡å‹è¡¨ç°å‡ºé«˜ç½®ä¿¡åº¦ï¼Œä½†å‡†ç¡®ç‡è¾ƒä½ï¼Œè€Œè¾ƒå¤§çš„æ¨¡å‹è¡¨ç°å‡ºè¾ƒé«˜çš„å‡†ç¡®ç‡ï¼Œä½†ç½®ä¿¡åº¦è¾ƒä½ã€‚è¿™å¯èƒ½ä¼šå¯¼è‡´ä¿¡æ¯éªŒè¯ä¸­çš„ç³»ç»Ÿæ€§åå·®ï¼Œå› ä¸ºèµ„æºå—é™çš„ç»„ç»‡é€šå¸¸ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ã€‚éè‹±è¯­è¯­è¨€å’Œæ¥è‡ªå…¨çƒå—æ–¹çš„ä¸»å¼ çš„æ€§èƒ½å·®è·æœ€ä¸ºæ˜æ˜¾ï¼Œæœ‰å¯èƒ½æ‰©å¤§ç°æœ‰çš„ä¿¡æ¯ä¸å¹³ç­‰ã€‚è¿™äº›ç»“æœä¸ºæœªæ¥çš„ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªå¤šè¯­è¨€åŸºå‡†ï¼Œå¹¶ä¸ºæ—¨åœ¨ç¡®ä¿å…¬å¹³è·å¾—å¯ä¿¡çš„AIè¾…åŠ©äº‹å®æ ¸æŸ¥çš„æ”¿ç­–æä¾›äº†è¯æ®åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸‹è¿›è¡Œäº‹å®æ ¸æŸ¥æ—¶ï¼Œå‡†ç¡®æ€§å’Œç½®ä¿¡åº¦ä¸åŒ¹é…çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–å°å‹æ¨¡å‹çš„ç»„ç»‡ï¼Œå¯èƒ½å› ä¸ºæ¨¡å‹çš„é«˜ç½®ä¿¡åº¦è€Œè¯¯åˆ¤ï¼Œå¯¼è‡´ä¿¡æ¯åå·®å’Œä¸å¹³ç­‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤§è§„æ¨¡ã€å¤šè¯­è¨€çš„å®éªŒè¯„ä¼°ï¼Œæ­ç¤ºä¸åŒè§„æ¨¡å’Œç±»å‹çš„LLMåœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸­çš„ç½®ä¿¡åº¦ä¸å‡†ç¡®ç‡ä¹‹é—´çš„å…³ç³»ï¼Œç‰¹åˆ«æ˜¯å…³æ³¨å°æ¨¡å‹çš„é«˜ç½®ä¿¡åº¦ä½å‡†ç¡®ç‡ç°è±¡ã€‚é€šè¿‡åˆ†ææ¨¡å‹åœ¨ä¸åŒè¯­è¨€å’Œæ¥æºæ•°æ®ä¸Šçš„è¡¨ç°ï¼Œæ‰¾å‡ºæ½œåœ¨çš„åå·®å’Œå±€é™æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†æ¥è‡ª47ç§è¯­è¨€çš„5000æ¡å·²ç”±ä¸“ä¸šäº‹å®æ ¸æŸ¥ç»„ç»‡è¯„ä¼°çš„å£°æ˜ã€‚2) æ¨¡å‹é€‰æ‹©ï¼šé€‰æ‹©ä¹ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„LLMï¼Œæ¶µç›–å¼€æº/é—­æºã€ä¸åŒè§„æ¨¡å’Œæ¶æ„ã€‚3) æç¤ºç­–ç•¥ï¼šè®¾è®¡å››ç§æç¤ºç­–ç•¥ï¼Œæ¨¡æ‹Ÿå…¬æ°‘å’Œä¸“ä¸šäº‹å®æ ¸æŸ¥å‘˜çš„äº¤äº’æ–¹å¼ã€‚4) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨24ä¸‡æ¡äººå·¥æ ‡æ³¨ä½œä¸ºground truthï¼Œè¯„ä¼°æ¨¡å‹åœ¨ä¸åŒè¯­è¨€å’Œæ¥æºæ•°æ®ä¸Šçš„å‡†ç¡®ç‡å’Œç½®ä¿¡åº¦ã€‚5) ç»“æœåˆ†æï¼šåˆ†ææ¨¡å‹æ€§èƒ½ä¸è§„æ¨¡ã€è¯­è¨€ã€æ•°æ®æ¥æºç­‰å› ç´ ä¹‹é—´çš„å…³ç³»ï¼Œæ­ç¤ºç½®ä¿¡åº¦æ‚–è®ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†AIäº‹å®æ ¸æŸ¥ä¸­çš„â€œç½®ä¿¡åº¦æ‚–è®ºâ€ï¼Œå³å°å‹æ¨¡å‹å¾€å¾€è¡¨ç°å‡ºé«˜ç½®ä¿¡åº¦ä½†å‡†ç¡®ç‡è¾ƒä½ï¼Œè€Œå¤§å‹æ¨¡å‹åˆ™ç›¸åã€‚è¿™ç§ç°è±¡å¯èƒ½ä¼šå¯¼è‡´ä¿¡æ¯éªŒè¯ä¸­çš„ç³»ç»Ÿæ€§åå·®ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºæœ‰é™çš„ç»„ç»‡ä¸­ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ„å»ºäº†ä¸€ä¸ªå¤šè¯­è¨€çš„äº‹å®æ ¸æŸ¥åŸºå‡†ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ•°æ®åŸºç¡€ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤šè¯­è¨€æ•°æ®é›†ï¼šæ¶µç›–47ç§è¯­è¨€ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§ã€‚2) å¤šæ ·åŒ–çš„æ¨¡å‹é€‰æ‹©ï¼šåŒ…æ‹¬ä¸åŒè§„æ¨¡ã€æ¶æ„å’Œæ¥æºçš„LLMï¼Œä»¥è¯„ä¼°ä¸åŒæ¨¡å‹çš„æ€§èƒ½ã€‚3) å¤šç§æç¤ºç­–ç•¥ï¼šæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„äº‹å®æ ¸æŸ¥åœºæ™¯ï¼Œæé«˜è¯„ä¼°çš„å¯é æ€§ã€‚4) å¤§è§„æ¨¡äººå·¥æ ‡æ³¨ï¼šæä¾›é«˜è´¨é‡çš„ground truthï¼Œç¡®ä¿è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼Œå°å‹æ¨¡å‹åœ¨äº‹å®æ ¸æŸ¥ä»»åŠ¡ä¸­è¡¨ç°å‡ºé«˜ç½®ä¿¡åº¦ä½†ä½å‡†ç¡®ç‡ï¼Œå¤§å‹æ¨¡å‹åˆ™ç›¸åã€‚éè‹±è¯­è¯­è¨€å’Œæ¥è‡ªå…¨çƒå—æ–¹çš„ä¸»å¼ çš„æ€§èƒ½å·®è·æœ€ä¸ºæ˜æ˜¾ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå½“å‰AIäº‹å®æ ¸æŸ¥ç³»ç»Ÿå¯èƒ½å­˜åœ¨åå·®ï¼Œéœ€è¦è¿›ä¸€æ­¥æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¼€å‘æ›´å¯é ã€å…¬å¹³çš„AIè¾…åŠ©äº‹å®æ ¸æŸ¥ç³»ç»Ÿï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºæœ‰é™çš„åœ°åŒºå’Œéè‹±è¯­è¯­ç§ç¯å¢ƒä¸­ã€‚æœ‰åŠ©äºæé«˜å…¬ä¼—å¯¹ä¿¡æ¯çš„è¾¨åˆ«èƒ½åŠ›ï¼Œå‡å°‘è™šå‡ä¿¡æ¯ä¼ æ’­ï¼Œä¿ƒè¿›ä¿¡æ¯å…¬å¹³ã€‚æœªæ¥å¯ç”¨äºæŒ‡å¯¼æ”¿ç­–åˆ¶å®šï¼Œç¡®ä¿AIæŠ€æœ¯åœ¨ä¿¡æ¯éªŒè¯é¢†åŸŸçš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rise of misinformation underscores the need for scalable and reliable fact-checking solutions. Large language models (LLMs) hold promise in automating fact verification, yet their effectiveness across global contexts remains uncertain. We systematically evaluate nine established LLMs across multiple categories (open/closed-source, multiple sizes, diverse architectures, reasoning-based) using 5,000 claims previously assessed by 174 professional fact-checking organizations across 47 languages. Our methodology tests model generalizability on claims postdating training cutoffs and four prompting strategies mirroring both citizen and professional fact-checker interactions, with over 240,000 human annotations as ground truth. Findings reveal a concerning pattern resembling the Dunning-Kruger effect: smaller, accessible models show high confidence despite lower accuracy, while larger models demonstrate higher accuracy but lower confidence. This risks systemic bias in information verification, as resource-constrained organizations typically use smaller models. Performance gaps are most pronounced for non-English languages and claims originating from the Global South, threatening to widen existing information inequalities. These results establish a multilingual benchmark for future research and provide an evidence base for policy aimed at ensuring equitable access to trustworthy, AI-assisted fact-checking.

