---
layout: default
title: Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making
---

# Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08785" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08785v1</a>
  <a href="https://arxiv.org/pdf/2509.08785.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08785v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08785v1', 'Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anup Tuladhar, Araz Minhas, Adam Kirton, Eli Kinney-Lang

**åˆ†ç±»**: cs.AI, cs.MA, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

**å¤‡æ³¨**: Extended Abstract for RLDM 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ä¸ªç»“åˆå¼ºåŒ–å­¦ä¹ ä¸è¯­è¨€æ¨¡å‹çš„å¹³å°ï¼Œç ”ç©¶å™äº‹æ¡†æ¶å¯¹AIå†³ç­–çš„å½±å“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è¯­è¨€æ¨¡å‹` `å™äº‹æ¡†æ¶` `AIå†³ç­–` `åŒç³»ç»Ÿæ¶æ„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰AIç³»ç»Ÿå†³ç­–ä¸å™äº‹èƒ½åŠ›åˆ†ç¦»ï¼Œç¼ºä¹å¯¹å™äº‹å¦‚ä½•å½±å“å†³ç­–çš„ç ”ç©¶ã€‚
2. æå‡ºåŒç³»ç»Ÿæ¶æ„ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ ç­–ç•¥å’Œè¯­è¨€æ¨¡å‹ï¼Œæ¢ç´¢å™äº‹æ¡†æ¶å¯¹å†³ç­–çš„å½±å“ã€‚
3. æ„å»ºå¯é…ç½®ç½‘æ ¼ä¸–ç•Œç¯å¢ƒï¼Œè®°å½•å†³ç­–æŒ‡æ ‡ï¼Œä¸ºç ”ç©¶å™äº‹å½±å“æä¾›åŸºç¡€å¹³å°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ä¸ªåˆæ­¥çš„å®éªŒå¹³å°ï¼Œæ—¨åœ¨é€šè¿‡ç»“åˆå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸è¯­è¨€æ¨¡å‹æ¨ç†ï¼Œæ¢ç´¢å™äº‹å…ƒç´ å¦‚ä½•å½±å“AIå†³ç­–ã€‚å°½ç®¡AIç³»ç»Ÿç°åœ¨æ—¢èƒ½åšå‡ºå†³ç­–ï¼Œåˆèƒ½è¿›è¡Œå™äº‹æ¨ç†ï¼Œä½†è¿™äº›èƒ½åŠ›å¤§å¤šæ˜¯ç‹¬ç«‹ç ”ç©¶çš„ã€‚æˆ‘ä»¬çš„å¹³å°è¯•å›¾é€šè¿‡ä¸€ä¸ªåŒç³»ç»Ÿæ¶æ„æ¥å¼¥åˆè¿™ä¸€å·®è·ï¼Œç ”ç©¶å™äº‹æ¡†æ¶å¦‚ä½•å½±å“åŸºäºå¥–åŠ±çš„å­¦ä¹ ã€‚è¯¥ç³»ç»ŸåŒ…æ‹¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œè¯¥ç­–ç•¥æ ¹æ®è¿‡å»çš„ç»éªŒæå‡ºè¡ŒåŠ¨å»ºè®®ï¼Œä»¥åŠä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡ä¸åŒçš„å™äº‹æ¡†æ¶å¤„ç†è¿™äº›å»ºè®®ä»¥æŒ‡å¯¼å†³ç­–ã€‚è¿™ç§è®¾ç½®å¯ä»¥åœ¨ä¿æŒä¸€è‡´çš„ç¯å¢ƒå’Œå¥–åŠ±ç»“æ„çš„åŒæ—¶ï¼Œå¯¹å™äº‹å…ƒç´ è¿›è¡Œåˆæ­¥å®éªŒã€‚æˆ‘ä»¬åœ¨ä¸€ä¸ªå¯é…ç½®çš„ç½‘æ ¼ä¸–ç•Œç¯å¢ƒä¸­å®ç°äº†è¿™ç§æ¶æ„ï¼Œåœ¨è¯¥ç¯å¢ƒä¸­ï¼Œæ™ºèƒ½ä½“æ¥æ”¶ç­–ç•¥å»ºè®®å’Œå…³äºå…¶å‘¨å›´ç¯å¢ƒçš„ä¿¡æ¯ã€‚è¯¥å¹³å°çš„æ¨¡å—åŒ–è®¾è®¡æœ‰åŠ©äºå¯¹ç¯å¢ƒå¤æ‚æ€§ã€å™äº‹å‚æ•°ä»¥åŠå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºå™äº‹çš„å†³ç­–ä¹‹é—´çš„äº¤äº’è¿›è¡Œå—æ§æµ‹è¯•ã€‚æˆ‘ä»¬çš„æ—¥å¿—ç³»ç»Ÿæ•è·åŸºæœ¬çš„å†³ç­–æŒ‡æ ‡ï¼Œä»RLç­–ç•¥å€¼åˆ°è¯­è¨€æ¨¡å‹æ¨ç†å†åˆ°è¡ŒåŠ¨é€‰æ‹©æ¨¡å¼ã€‚è™½ç„¶æ˜¯åˆæ­¥çš„ï¼Œä½†è¯¥å®ç°ä¸ºç ”ç©¶ä¸åŒçš„å™äº‹æ¡†æ¶å¦‚ä½•å½±å“åŸºäºå¥–åŠ±çš„å†³ç­–ï¼Œä»¥åŠæ¢ç´¢åŸºäºä¼˜åŒ–çš„å­¦ä¹ å’ŒAIç³»ç»Ÿä¸­çš„ç¬¦å·æ¨ç†ä¹‹é—´æ½œåœ¨çš„äº¤äº’å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰AIç³»ç»Ÿåœ¨å†³ç­–å’Œå™äº‹æ¨ç†æ–¹é¢é€šå¸¸æ˜¯ç‹¬ç«‹ç ”ç©¶çš„ï¼Œç¼ºä¹å¯¹å™äº‹å…ƒç´ å¦‚ä½•å½±å“AIå†³ç­–çš„æ·±å…¥ç†è§£ã€‚ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•é€šå¸¸åªå…³æ³¨å¥–åŠ±æœ€å¤§åŒ–ï¼Œè€Œå¿½ç•¥äº†äººç±»å†³ç­–ä¸­é‡è¦çš„å™äº‹å› ç´ ã€‚å› æ­¤ï¼Œå¦‚ä½•å°†å™äº‹æ¡†æ¶èå…¥åˆ°AIå†³ç­–è¿‡ç¨‹ä¸­ï¼Œå¹¶ç ”ç©¶å…¶å½±å“ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¸è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œæ„å»ºä¸€ä¸ªåŒç³»ç»Ÿæ¶æ„ã€‚å¼ºåŒ–å­¦ä¹ ç­–ç•¥è´Ÿè´£æ ¹æ®è¿‡å»çš„ç»éªŒæå‡ºè¡ŒåŠ¨å»ºè®®ï¼Œè€Œè¯­è¨€æ¨¡å‹åˆ™è´Ÿè´£é€šè¿‡ä¸åŒçš„å™äº‹æ¡†æ¶å¤„ç†è¿™äº›å»ºè®®ï¼Œä»è€ŒæŒ‡å¯¼æœ€ç»ˆçš„å†³ç­–ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥ç ”ç©¶ä¸åŒçš„å™äº‹æ¡†æ¶å¦‚ä½•å½±å“åŸºäºå¥–åŠ±çš„å­¦ä¹ ï¼Œå¹¶æ¢ç´¢ä¼˜åŒ–å­¦ä¹ å’Œç¬¦å·æ¨ç†ä¹‹é—´çš„æ½œåœ¨äº¤äº’ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥å¹³å°é‡‡ç”¨åŒç³»ç»Ÿæ¶æ„ï¼Œä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šå¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¨¡å—å’Œè¯­è¨€æ¨¡å‹æ¨¡å—ã€‚å¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¨¡å—è´Ÿè´£æ ¹æ®ç¯å¢ƒçŠ¶æ€å’Œå¥–åŠ±ä¿¡å·å­¦ä¹ æœ€ä¼˜ç­–ç•¥ï¼Œå¹¶ç”Ÿæˆè¡ŒåŠ¨å»ºè®®ã€‚è¯­è¨€æ¨¡å‹æ¨¡å—åˆ™æ¥æ”¶æ¥è‡ªå¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¨¡å—çš„è¡ŒåŠ¨å»ºè®®ï¼Œå¹¶æ ¹æ®é¢„è®¾çš„å™äº‹æ¡†æ¶å¯¹è¿™äº›å»ºè®®è¿›è¡Œå¤„ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„è¡ŒåŠ¨å†³ç­–ã€‚è¿™ä¸¤ä¸ªæ¨¡å—åœ¨ä¸€ä¸ªå¯é…ç½®çš„ç½‘æ ¼ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œäº¤äº’ï¼Œæ™ºèƒ½ä½“æ¥æ”¶ç­–ç•¥å»ºè®®å’Œç¯å¢ƒä¿¡æ¯ï¼Œå¹¶æ ¹æ®è¯­è¨€æ¨¡å‹çš„è¾“å‡ºæ‰§è¡Œè¡ŒåŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥å¹³å°çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ ä¸è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ç”¨äºç ”ç©¶å™äº‹æ¡†æ¶å¯¹AIå†³ç­–å½±å“çš„å®éªŒå¹³å°ã€‚è¯¥å¹³å°é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå¯ä»¥çµæ´»é…ç½®ç¯å¢ƒå¤æ‚æ€§ã€å™äº‹å‚æ•°ä»¥åŠå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºå™äº‹çš„å†³ç­–ä¹‹é—´çš„äº¤äº’ã€‚æ­¤å¤–ï¼Œè¯¥å¹³å°è¿˜æä¾›äº†ä¸€ä¸ªæ—¥å¿—ç³»ç»Ÿï¼Œç”¨äºæ•è·åŸºæœ¬çš„å†³ç­–æŒ‡æ ‡ï¼Œä»è€Œæ–¹ä¾¿ç ”ç©¶äººå‘˜åˆ†æå’Œç†è§£å™äº‹æ¡†æ¶å¯¹AIå†³ç­–çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥å¹³å°ä½¿ç”¨å¯é…ç½®çš„ç½‘æ ¼ä¸–ç•Œç¯å¢ƒï¼Œå…è®¸ç”¨æˆ·è‡ªå®šä¹‰ç¯å¢ƒçš„å¤§å°ã€éšœç¢ç‰©çš„ä½ç½®ä»¥åŠå¥–åŠ±å‡½æ•°ã€‚å¼ºåŒ–å­¦ä¹ ç­–ç•¥æ¨¡å—å¯ä»¥ä½¿ç”¨ä¸åŒçš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚Q-learningæˆ–SARSAã€‚è¯­è¨€æ¨¡å‹æ¨¡å—å¯ä»¥ä½¿ç”¨ä¸åŒçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä¾‹å¦‚GPT-2æˆ–BERTï¼Œå¹¶æ ¹æ®ä¸åŒçš„å™äº‹æ¡†æ¶è¿›è¡Œå¾®è°ƒã€‚æ­¤å¤–ï¼Œè¯¥å¹³å°è¿˜æä¾›äº†ä¸€ç»„å‚æ•°ï¼Œç”¨äºæ§åˆ¶å™äº‹æ¡†æ¶çš„å¼ºåº¦å’Œç±»å‹ï¼Œä¾‹å¦‚æƒ…æ„Ÿå€¾å‘ã€é“å¾·å‡†åˆ™ç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥å¹³å°æˆåŠŸåœ°å°†å¼ºåŒ–å­¦ä¹ ä¸è¯­è¨€æ¨¡å‹ç›¸ç»“åˆï¼Œæ„å»ºäº†ä¸€ä¸ªå¯ç”¨äºç ”ç©¶å™äº‹æ¡†æ¶å¯¹AIå†³ç­–å½±å“çš„å®éªŒå¹³å°ã€‚é€šè¿‡åœ¨å¯é…ç½®çš„ç½‘æ ¼ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œå®éªŒï¼Œç ”ç©¶äººå‘˜å¯ä»¥è§‚å¯Ÿåˆ°ä¸åŒçš„å™äº‹æ¡†æ¶å¦‚ä½•å½±å“æ™ºèƒ½ä½“çš„è¡ŒåŠ¨é€‰æ‹©å’Œå­¦ä¹ è¿‡ç¨‹ã€‚è¯¥å¹³å°è¿˜æä¾›äº†ä¸€ä¸ªæ—¥å¿—ç³»ç»Ÿï¼Œç”¨äºæ•è·åŸºæœ¬çš„å†³ç­–æŒ‡æ ‡ï¼Œä¾‹å¦‚RLç­–ç•¥å€¼ã€è¯­è¨€æ¨¡å‹æ¨ç†ç»“æœå’Œè¡ŒåŠ¨é€‰æ‹©æ¨¡å¼ï¼Œä»è€Œæ–¹ä¾¿ç ”ç©¶äººå‘˜è¿›è¡Œæ·±å…¥åˆ†æã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œä¾‹å¦‚æ¸¸æˆAIã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡å¼•å…¥å™äº‹æ¡†æ¶ï¼Œå¯ä»¥ä½¿AIç³»ç»Ÿåœ¨å†³ç­–æ—¶æ›´åŠ ç¬¦åˆäººç±»çš„ä»·å€¼è§‚å’Œé“å¾·å‡†åˆ™ï¼Œä»è€Œæé«˜AIç³»ç»Ÿçš„å¯ä¿¡åº¦å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£äººç±»å†³ç­–è¿‡ç¨‹ä¸­çš„å™äº‹å› ç´ ï¼Œä¸ºå¼€å‘æ›´æ™ºèƒ½ã€æ›´äººæ€§åŒ–çš„AIç³»ç»Ÿæä¾›ç†è®ºæŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a preliminary experimental platform that explores how narrative elements might shape AI decision-making by combining reinforcement learning (RL) with language model reasoning. While AI systems can now both make decisions and engage in narrative reasoning, these capabilities have mostly been studied separately. Our platform attempts to bridge this gap using a dual-system architecture to examine how narrative frameworks could influence reward-based learning. The system comprises a reinforcement learning policy that suggests actions based on past experience, and a language model that processes these suggestions through different narrative frameworks to guide decisions. This setup enables initial experimentation with narrative elements while maintaining consistent environment and reward structures. We implement this architecture in a configurable gridworld environment, where agents receive both policy suggestions and information about their surroundings. The platform's modular design facilitates controlled testing of environmental complexity, narrative parameters, and the interaction between reinforcement learning and narrative-based decisions. Our logging system captures basic decision metrics, from RL policy values to language model reasoning to action selection patterns. While preliminary, this implementation provides a foundation for studying how different narrative frameworks might affect reward-based decisions and exploring potential interactions between optimization-based learning and symbolic reasoning in AI systems.

