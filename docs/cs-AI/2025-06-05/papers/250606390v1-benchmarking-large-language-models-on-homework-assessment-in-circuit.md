---
layout: default
title: Benchmarking Large Language Models on Homework Assessment in Circuit Analysis
---

# Benchmarking Large Language Models on Homework Assessment in Circuit Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06390" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06390v1</a>
  <a href="https://arxiv.org/pdf/2506.06390.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06390v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06390v1', 'Benchmarking Large Language Models on Homework Assessment in Circuit Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liangliang Chen, Zhihao Qin, Yiming Guo, Jacqueline Rohde, Ying Zhang

**åˆ†ç±»**: cs.CY, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç”µè·¯åˆ†æä½œä¸šè¯„ä¼°åŸºå‡†ç ”ç©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç”µè·¯åˆ†æ` `ä½œä¸šè¯„ä¼°` `å·¥ç¨‹æ•™è‚²` `æ•°æ®é›†æ„å»º` `è¯„ä¼°æŒ‡æ ‡` `ä¸ªæ€§åŒ–è¾…å¯¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”µè·¯åˆ†æä½œä¸šè¯„ä¼°ä¸­å­˜åœ¨å‡†ç¡®æ€§ä¸è¶³å’Œå¯é æ€§é—®é¢˜ï¼Œå¯èƒ½è¯¯å¯¼å­¦ç”Ÿã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ„å»ºåŒ…å«çœŸå®å­¦ç”Ÿè§£å’Œå‚è€ƒè§£çš„æ•°æ®é›†ï¼Œåˆ©ç”¨LLMsè¯„ä¼°ä½œä¸šï¼Œè®¾è®¡äº†é’ˆå¯¹äº”ä¸ªè¯„ä¼°æŒ‡æ ‡çš„æç¤ºæ¨¡æ¿ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oå’ŒLlama 3 70Båœ¨è¯„ä¼°æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºGPT-3.5 Turboï¼Œæä¾›äº†å¯é çš„åŸºå‡†å’Œæ´å¯Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç å¼€å‘ã€æœºå™¨äººã€é‡‘èå’Œæ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸå…·æœ‰é©å‘½æ€§æ½œåŠ›ã€‚æœ¬æ–‡æ¢è®¨äº†å¦‚ä½•åœ¨å·¥ç¨‹æ•™è‚²ä¸­åˆ©ç”¨LLMsï¼Œç‰¹åˆ«æ˜¯è¯„ä¼°æœ¬ç§‘ç”µè·¯åˆ†æè¯¾ç¨‹çš„ä½œä¸šèƒ½åŠ›ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªæ–°æ•°æ®é›†ï¼ŒåŒ…å«å®˜æ–¹å‚è€ƒè§£å’ŒçœŸå®å­¦ç”Ÿè§£ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºLaTeXæ ¼å¼ï¼Œä»¥å…‹æœç°æœ‰LLMsåœ¨å›¾åƒè¯†åˆ«æ–¹é¢çš„å±€é™æ€§ã€‚é€šè¿‡è®¾è®¡æç¤ºæ¨¡æ¿ï¼Œæˆ‘ä»¬æµ‹è¯•äº†å­¦ç”Ÿè§£çš„äº”ä¸ªè¯„ä¼°æŒ‡æ ‡ã€‚ç»“æœè¡¨æ˜ï¼ŒGPT-4oå’ŒLlama 3 70Båœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šè¡¨ç°æ˜¾è‘—ä¼˜äºGPT-3.5 Turboï¼Œå¹¶ä¸”å„è‡ªå…·æœ‰ä¸åŒçš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æ¢è®¨äº†å½“å‰LLMsåœ¨ç”µè·¯åˆ†æä¸­çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥å¼€å‘å¯é çš„ä¸ªæ€§åŒ–è¾…å¯¼ç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ç”µè·¯åˆ†æä½œä¸šè¯„ä¼°ä¸­çš„å‡†ç¡®æ€§å’Œå¯é æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å›¾åƒè¯†åˆ«å’Œè¯„ä¼°æ ‡å‡†ä¸Šå­˜åœ¨å±€é™ï¼Œå¯èƒ½å¯¼è‡´è¯„ä¼°ç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å®˜æ–¹å‚è€ƒè§£å’ŒçœŸå®å­¦ç”Ÿè§£çš„æ•°æ®é›†ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºLaTeXæ ¼å¼ï¼Œè®ºæ–‡è®¾è®¡äº†ä¸€ä¸ªæç¤ºæ¨¡æ¿æ¥è¯„ä¼°å­¦ç”Ÿè§£çš„å®Œæ•´æ€§ã€æ–¹æ³•ã€æœ€ç»ˆç­”æ¡ˆã€ç®—æœ¯é”™è¯¯å’Œå•ä½ç­‰äº”ä¸ªæŒ‡æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æç¤ºæ¨¡æ¿è®¾è®¡å’Œè¯„ä¼°æŒ‡æ ‡æµ‹è¯•ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é›†é€šè¿‡çœŸå®æ¡ˆä¾‹å’Œå‚è€ƒè§£çš„ç»“åˆï¼Œç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å­¦ç”Ÿè§£è½¬åŒ–ä¸ºLaTeXæ ¼å¼ï¼Œä»¥å…‹æœç°æœ‰LLMsåœ¨å›¾åƒè¯†åˆ«æ–¹é¢çš„ä¸è¶³ï¼Œå¹¶é€šè¿‡äº”ä¸ªå…·ä½“æŒ‡æ ‡è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œæä¾›äº†æ›´ä¸ºç»†è‡´çš„åé¦ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºæ¨¡æ¿ä¸­ï¼Œè®¾ç½®äº†é’ˆå¯¹æ¯ä¸ªè¯„ä¼°æŒ‡æ ‡çš„å…·ä½“è¦æ±‚ï¼Œå¹¶é€šè¿‡å¯¹æ¯”ä¸åŒLLMsçš„è¡¨ç°ï¼Œåˆ†æäº†å„è‡ªçš„ä¼˜åŠ¿å’Œå±€é™æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4oå’ŒLlama 3 70Båœ¨å®Œæ•´æ€§ã€æ–¹æ³•ã€æœ€ç»ˆç­”æ¡ˆã€ç®—æœ¯é”™è¯¯å’Œå•ä½ç­‰äº”ä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºGPT-3.5 Turboï¼Œæå‡å¹…åº¦æ˜æ˜¾ï¼ŒéªŒè¯äº†æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å·¥ç¨‹æ•™è‚²ä¸­çš„ä½œä¸šè¯„ä¼°å’Œä¸ªæ€§åŒ–å­¦ä¹ è¾…å¯¼ã€‚é€šè¿‡å»ºç«‹å¯é çš„è¯„ä¼°åŸºå‡†ï¼Œæœªæ¥å¯ä»¥å¼€å‘å‡ºæ›´æ™ºèƒ½çš„æ•™è‚²å·¥å…·ï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ç†è§£ç”µè·¯åˆ†æç­‰å¤æ‚ä¸»é¢˜ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have the potential to revolutionize various fields, including code development, robotics, finance, and education, due to their extensive prior knowledge and rapid advancements. This paper investigates how LLMs can be leveraged in engineering education. Specifically, we benchmark the capabilities of different LLMs, including GPT-3.5 Turbo, GPT-4o, and Llama 3 70B, in assessing homework for an undergraduate-level circuit analysis course. We have developed a novel dataset consisting of official reference solutions and real student solutions to problems from various topics in circuit analysis. To overcome the limitations of image recognition in current state-of-the-art LLMs, the solutions in the dataset are converted to LaTeX format. Using this dataset, a prompt template is designed to test five metrics of student solutions: completeness, method, final answer, arithmetic error, and units. The results show that GPT-4o and Llama 3 70B perform significantly better than GPT-3.5 Turbo across all five metrics, with GPT-4o and Llama 3 70B each having distinct advantages in different evaluation aspects. Additionally, we present insights into the limitations of current LLMs in several aspects of circuit analysis. Given the paramount importance of ensuring reliability in LLM-generated homework assessment to avoid misleading students, our results establish benchmarks and offer valuable insights for the development of a reliable, personalized tutor for circuit analysis -- a focus of our future work. Furthermore, the proposed evaluation methods can be generalized to a broader range of courses for engineering education in the future.

