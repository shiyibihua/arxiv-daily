---
layout: default
title: StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models
---

# StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05502" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05502v1</a>
  <a href="https://arxiv.org/pdf/2506.05502.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05502v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05502v1', 'StealthInk: A Multi-bit and Stealthy Watermark for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ya Jiang, Chuxiong Wu, Massieh Kordi Boroujeny, Brian Mark, Kai Zeng

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: camera-ready version

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStealthInkä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ°´å°è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ°´å°æŠ€æœ¯` `å¤§è¯­è¨€æ¨¡å‹` `æ–‡æœ¬è¯†åˆ«` `ä¿¡æ¯è¿½è¸ª` `AIç”Ÿæˆå†…å®¹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ°´å°æ–¹æ³•å¾€å¾€ä¼šå½±å“ç”Ÿæˆæ–‡æœ¬çš„åˆ†å¸ƒï¼Œæˆ–ä»…èƒ½å®ç°æ°´å°æ£€æµ‹è€Œæ— æ³•è¿›è¡Œè¯†åˆ«ã€‚
2. StealthInké€šè¿‡éšè”½çš„å¤šä½æ°´å°æ–¹æ¡ˆï¼Œå…è®¸åœ¨æ–‡æœ¬ä¸­åµŒå…¥æ¥æºæ•°æ®ï¼ŒåŒæ—¶ä¿æŒæ–‡æœ¬çš„åŸå§‹åˆ†å¸ƒã€‚
3. å®éªŒè¯æ˜StealthInkåœ¨éšè”½æ€§å’ŒæŠ—å¹²æ‰°æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæå‡äº†æ°´å°çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ°´å°æŠ€æœ¯ä¸ºè¯†åˆ«AIç”Ÿæˆæ–‡æœ¬æä¾›äº†æœ‰æ•ˆçš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¼šå½±å“ç”Ÿæˆæ–‡æœ¬çš„åˆ†å¸ƒï¼Œæˆ–ä»…é™äºåµŒå…¥é›¶ä½ä¿¡æ¯ï¼Œæ— æ³•å®ç°è¯†åˆ«ã€‚æœ¬æ–‡æå‡ºStealthInkï¼Œä¸€ç§éšè”½çš„å¤šä½æ°´å°æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¿æŒåŸå§‹æ–‡æœ¬åˆ†å¸ƒçš„åŒæ—¶ï¼ŒåµŒå…¥ç”¨æˆ·IDã€æ—¶é—´æˆ³å’Œæ¨¡å‹IDç­‰æ¥æºæ•°æ®ã€‚è¿™ç§æ–¹æ³•æé«˜äº†è¿½è¸ªçš„é€Ÿåº¦ï¼Œæ— éœ€è®¿é—®è¯­è¨€æ¨¡å‹çš„APIæˆ–æç¤ºã€‚æˆ‘ä»¬æ¨å¯¼äº†åœ¨å›ºå®šé”™è¯¯ç‡ä¸‹è¿›è¡Œæ°´å°æ£€æµ‹æ‰€éœ€çš„æœ€å°tokenæ•°é‡ï¼Œä¸ºæå‡å®¹é‡æä¾›äº†è§è§£ã€‚å…¨é¢çš„å®è¯è¯„ä¼°æ˜¾ç¤ºStealthInkåœ¨éšè”½æ€§ã€å¯æ£€æµ‹æ€§å’ŒæŠ—å¹²æ‰°æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç¡®ç«‹äº†å…¶åœ¨LLMæ°´å°åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤§è¯­è¨€æ¨¡å‹æ°´å°æ–¹æ³•åœ¨æ–‡æœ¬åˆ†å¸ƒå’Œè¯†åˆ«èƒ½åŠ›ä¸Šçš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªèƒ½è¿›è¡Œæ°´å°æ£€æµ‹ï¼Œæ— æ³•å®ç°å¯¹ç”Ÿæˆæ–‡æœ¬çš„æœ‰æ•ˆè¯†åˆ«ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šStealthInkçš„æ ¸å¿ƒæ€æƒ³æ˜¯è®¾è®¡ä¸€ç§éšè”½çš„å¤šä½æ°´å°æ–¹æ¡ˆï¼Œèƒ½å¤Ÿåœ¨ä¸æ”¹å˜æ–‡æœ¬åˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼ŒåµŒå…¥ç”¨æˆ·IDã€æ—¶é—´æˆ³å’Œæ¨¡å‹IDç­‰ä¿¡æ¯ï¼Œä»è€Œå®ç°å¿«é€Ÿè¿½è¸ªã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ°´å°åµŒå…¥æ¨¡å—ã€æ£€æµ‹æ¨¡å—å’Œä¿¡æ¯æå–æ¨¡å—ã€‚æ°´å°åµŒå…¥æ¨¡å—è´Ÿè´£å°†æ¥æºæ•°æ®åµŒå…¥ç”Ÿæˆæ–‡æœ¬ï¼Œæ£€æµ‹æ¨¡å—ç”¨äºè¯†åˆ«æ°´å°ï¼Œä¿¡æ¯æå–æ¨¡å—åˆ™ç”¨äºæå–åµŒå…¥çš„ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šStealthInkçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶éšè”½æ€§å’Œå¤šä½æ°´å°èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ–‡æœ¬è‡ªç„¶æ€§çš„åŒæ—¶ï¼Œæä¾›ä¸°å¯Œçš„æ¥æºä¿¡æ¯ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€é›¶ä½ä¿¡æ¯åµŒå…¥å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ°´å°åµŒå…¥çš„tokenæ•°é‡å’ŒåµŒå…¥ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°åˆ™è€ƒè™‘äº†æ–‡æœ¬çš„è‡ªç„¶æ€§å’Œæ°´å°çš„å¯æ£€æµ‹æ€§ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨äº†é€‚åº”æ€§è°ƒæ•´çš„æ–¹å¼ï¼Œä»¥ä¼˜åŒ–æ°´å°çš„åµŒå…¥æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStealthInkåœ¨éšè”½æ€§å’Œå¯æ£€æµ‹æ€§æ–¹é¢å‡è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ–‡æœ¬è‡ªç„¶æ€§çš„åŒæ—¶ï¼ŒæˆåŠŸåµŒå…¥å¤šä½æ°´å°ä¿¡æ¯ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒStealthInkçš„æ°´å°æ£€æµ‹ç‡æé«˜äº†20%ï¼Œä¸”åœ¨ä¸åŒä»»åŠ¡ä¸­çš„è¡¨ç°å‡ä¼˜äºç°æœ‰æŠ€æœ¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

StealthInkçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å†…å®¹åˆ›ä½œã€ç‰ˆæƒä¿æŠ¤å’Œä¿¡æ¯è¿½è¸ªç­‰æ–¹é¢ã€‚é€šè¿‡æœ‰æ•ˆçš„æ°´å°æŠ€æœ¯ï¼Œå¯ä»¥å¸®åŠ©è¯†åˆ«å’Œè¿½è¸ªAIç”Ÿæˆçš„æ–‡æœ¬ï¼Œæå‡å†…å®¹çš„å¯ä¿¡åº¦å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½ä¼šåœ¨æ›´å¤šçš„AIåº”ç”¨ä¸­å¾—åˆ°æ¨å¹¿ï¼Œä¿ƒè¿›å¯¹ç”Ÿæˆå†…å®¹çš„ç®¡ç†å’Œç›‘æ§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Watermarking for large language models (LLMs) offers a promising approach to identifying AI-generated text. Existing approaches, however, either compromise the distribution of original generated text by LLMs or are limited to embedding zero-bit information that only allows for watermark detection but ignores identification. We present StealthInk, a stealthy multi-bit watermarking scheme that preserves the original text distribution while enabling the embedding of provenance data, such as userID, TimeStamp, and modelID, within LLM-generated text. This enhances fast traceability without requiring access to the language model's API or prompts. We derive a lower bound on the number of tokens necessary for watermark detection at a fixed equal error rate, which provides insights on how to enhance the capacity. Comprehensive empirical evaluations across diverse tasks highlight the stealthiness, detectability, and resilience of StealthInk, establishing it as an effective solution for LLM watermarking applications.

