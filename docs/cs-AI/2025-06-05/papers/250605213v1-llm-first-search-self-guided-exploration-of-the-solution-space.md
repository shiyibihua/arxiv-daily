---
layout: default
title: LLM-First Search: Self-Guided Exploration of the Solution Space
---

# LLM-First Search: Self-Guided Exploration of the Solution Space

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05213" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05213v1</a>
  <a href="https://arxiv.org/pdf/2506.05213.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05213v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05213v1', 'LLM-First Search: Self-Guided Exploration of the Solution Space')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nathan Herr, Tim RocktÃ¤schel, Roberta Raileanu

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: 9 main pages, 2 figures, 2 tables, 36 appendix pages

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/NathanHerr/LLM-First-Search)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM-First Searchä»¥è§£å†³æœç´¢ç­–ç•¥å›ºå®šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªå¯¼å‘æœç´¢` `è’™ç‰¹å¡æ´›æ ‘æœç´¢` `æ¨ç†ä¸è§„åˆ’` `è®¡ç®—æ•ˆç‡` `æœç´¢ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœç´¢æ–¹æ³•å¦‚MCTSä¾èµ–å›ºå®šçš„è¶…å‚æ•°ï¼Œé™åˆ¶äº†å…¶åœ¨ä¸åŒä»»åŠ¡ä¸­çš„é€‚åº”æ€§å’Œæ•ˆç‡ã€‚
2. LLM-First Searchï¼ˆLFSï¼‰é€šè¿‡è‡ªæˆ‘å¼•å¯¼æ¢ç´¢ï¼Œä½¿LLMèƒ½å¤Ÿè‡ªä¸»å†³å®šæœç´¢è·¯å¾„ï¼Œæå‡äº†çµæ´»æ€§å’Œä¸Šä¸‹æ–‡æ•æ„Ÿæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLFSåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œä¸”è®¡ç®—æ•ˆç‡é«˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨å¼ºæ¨¡å‹æ”¯æŒä¸‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†å’Œè§„åˆ’æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œé€šå¸¸é€šè¿‡å°†é—®é¢˜è§£å†³è§†ä¸ºæœç´¢è¿‡ç¨‹æ¥å®ç°ã€‚ç°æœ‰æ–¹æ³•å¦‚è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰åœ¨æŸäº›é¢†åŸŸæœ‰æ•ˆï¼Œä½†å…¶å¯¹å›ºå®šæ¢ç´¢è¶…å‚æ•°çš„ä¾èµ–é™åˆ¶äº†å…¶åœ¨ä¸åŒéš¾åº¦ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ã€‚æœ¬æ–‡æå‡ºäº†LLM-First Searchï¼ˆLFSï¼‰ï¼Œä¸€ç§æ–°é¢–çš„LLMè‡ªå¯¼å‘æœç´¢æ–¹æ³•ï¼Œæ¶ˆé™¤äº†é¢„å®šä¹‰æœç´¢ç­–ç•¥çš„éœ€æ±‚ï¼Œä½¿LLMèƒ½å¤Ÿé€šè¿‡è‡ªæˆ‘å¼•å¯¼æ¢ç´¢è‡ªä¸»æ§åˆ¶æœç´¢è¿‡ç¨‹ã€‚LFSåœ¨Countdownå’Œæ•°ç‹¬ä»»åŠ¡ä¸Šä¸ä¸‰ç§ç»å…¸æœç´¢ç®—æ³•è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜LFSåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°æ›´ä½³ï¼Œè®¡ç®—æ•ˆç‡æ›´é«˜ï¼Œä¸”åœ¨å¼ºæ¨¡å‹ä¸‹å…·æœ‰æ›´å¥½çš„æ‰©å±•æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æœç´¢æ–¹æ³•åœ¨ä¸åŒä»»åŠ¡ä¸­é€‚åº”æ€§å·®ã€æ•ˆç‡ä½çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯å›ºå®šè¶…å‚æ•°å¯¼è‡´çš„å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLFSé€šè¿‡èµ‹äºˆLLMè‡ªä¸»æ§åˆ¶æœç´¢è¿‡ç¨‹çš„èƒ½åŠ›ï¼Œæ¶ˆé™¤äº†å¯¹å¤–éƒ¨å¯å‘å¼æˆ–ç¡¬ç¼–ç ç­–ç•¥çš„ä¾èµ–ï¼Œå…è®¸æ¨¡å‹æ ¹æ®å†…éƒ¨è¯„åˆ†æœºåˆ¶è‡ªæˆ‘å¼•å¯¼æ¢ç´¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLFSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å¤„ç†ã€å†…éƒ¨è¯„åˆ†æœºåˆ¶å’Œæœç´¢è·¯å¾„é€‰æ‹©ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚è¾“å…¥å¤„ç†æ¨¡å—è´Ÿè´£æ¥æ”¶ä»»åŠ¡ä¿¡æ¯ï¼Œå†…éƒ¨è¯„åˆ†æœºåˆ¶ç”¨äºè¯„ä¼°å½“å‰è·¯å¾„çš„æœ‰æ•ˆæ€§ï¼Œæœç´¢è·¯å¾„é€‰æ‹©æ¨¡å—åˆ™å†³å®šæ˜¯ç»§ç»­å½“å‰è·¯å¾„è¿˜æ˜¯æ¢ç´¢æ–°åˆ†æ”¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šLFSçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶è‡ªæˆ‘å¼•å¯¼çš„æœç´¢æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æœç´¢ç­–ç•¥ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•çš„å›ºå®šç­–ç•¥å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šLFSåœ¨è®¾è®¡ä¸Šä¸éœ€è¦æ‰‹åŠ¨è°ƒä¼˜å‚æ•°ï¼Œä¸”é€šè¿‡å¼ºå¤§çš„LLMæ¨¡å‹æå‡äº†è®¡ç®—æ•ˆç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨è®¡ç®—é¢„ç®—å¢åŠ æ—¶ï¼Œè¡¨ç°å‡ºæ›´å¥½çš„æ‰©å±•æ€§ã€‚è¯¥æ–¹æ³•çš„ä»£ç å·²å…¬å¼€ï¼Œä¾¿äºåç»­ç ”ç©¶å’Œåº”ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLFSåœ¨æ›´å…·æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜äºä¼ ç»Ÿç®—æ³•ï¼Œå¦‚Tree-of-Thoughtsçš„å¹¿åº¦ä¼˜å…ˆæœç´¢å’Œè’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼Œä¸”åœ¨è®¡ç®—æ•ˆç‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå°¤å…¶æ˜¯åœ¨å¼ºæ¨¡å‹æ”¯æŒä¸‹ï¼Œæå‡å¹…åº¦æ˜æ˜¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤æ‚é—®é¢˜æ±‚è§£ã€æ¸¸æˆç­–ç•¥ä¼˜åŒ–å’Œè‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡æœç´¢æ•ˆç‡å’Œçµæ´»æ€§ï¼ŒLFSèƒ½å¤Ÿåœ¨å¤šç§å®é™…åœºæ™¯ä¸­æä¾›æ›´ä¼˜çš„è§£å†³æ–¹æ¡ˆï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated remarkable improvements in reasoning and planning through increased test-time compute, often by framing problem-solving as a search process. While methods like Monte Carlo Tree Search (MCTS) have proven effective in some domains, their reliance on fixed exploration hyperparameters limits their adaptability across tasks of varying difficulty, rendering them impractical or expensive in certain settings. In this paper, we propose \textbf{LLM-First Search (LFS)}, a novel \textit{LLM Self-Guided Search} method that removes the need for pre-defined search strategies by empowering the LLM to autonomously control the search process via self-guided exploration. Rather than relying on external heuristics or hardcoded policies, the LLM evaluates whether to pursue the current search path or explore alternative branches based on its internal scoring mechanisms. This enables more flexible and context-sensitive reasoning without requiring manual tuning or task-specific adaptation. We evaluate LFS on Countdown and Sudoku against three classic widely-used search algorithms, Tree-of-Thoughts' Breadth First Search (ToT-BFS), Best First Search (BestFS), and MCTS, each of which have been used to achieve SotA results on a range of challenging reasoning tasks. We found that LFS (1) performs better on more challenging tasks without additional tuning, (2) is more computationally efficient compared to the other methods, especially when powered by a stronger model, (3) scales better with stronger models, due to its LLM-First design, and (4) scales better with increased compute budget. Our code is publicly available at \href{https://github.com/NathanHerr/LLM-First-Search}{LLM-First-Search}.

