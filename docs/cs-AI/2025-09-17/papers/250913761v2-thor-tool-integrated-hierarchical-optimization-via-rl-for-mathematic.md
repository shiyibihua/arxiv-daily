---
layout: default
title: THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning
---

# THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13761" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.13761v2</a>
  <a href="https://arxiv.org/pdf/2509.13761.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13761v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13761v2', 'THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Qikai Chang, Zhenrong Zhang, Pengfei Hu, Jun Du, Jiefeng Ma, Yicheng Pan, Jianshu Zhang, Quan Liu, Jianqing Gao

**ÂàÜÁ±ª**: cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-17 (Êõ¥Êñ∞: 2025-10-03)

**Â§áÊ≥®**: 22 pages, 13 figures

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/JingMog/THOR)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**THORÔºöÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÂ±ÇÊ¨°‰ºòÂåñÔºåÁî®‰∫éÊï∞Â≠¶Êé®ÁêÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Êï∞Â≠¶Êé®ÁêÜ` `Â∑•ÂÖ∑ÈõÜÊàê` `Âº∫ÂåñÂ≠¶‰π†` `Â±ÇÊ¨°‰ºòÂåñ` `Ëá™ÊàëÁ∫†Ê≠£` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `‰ª£Á†ÅÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÊûÑÂª∫È´òË¥®ÈáèÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜÊï∞ÊçÆ„ÄÅËøõË°åÁªÜÁ≤íÂ∫¶‰ºòÂåñ‰ª•ÂèäÂ¢ûÂº∫Êé®ÁêÜËÉΩÂäõÊñπÈù¢Â≠òÂú®‰∏çË∂≥„ÄÇ
2. THORÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°åÂ∑•ÂÖ∑ÈõÜÊàêÂ±ÇÊ¨°‰ºòÂåñÔºåËÅîÂêà‰ºòÂåñÈóÆÈ¢òËß£ÂÜ≥Âíå‰ª£Á†ÅÁîüÊàêÔºåÂπ∂ÂºïÂÖ•Ëá™ÊàëÁ∫†Ê≠£Êú∫Âà∂„ÄÇ
3. THORÂú®Êï∞Â≠¶Âíå‰ª£Á†ÅÂü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂπ∂Âú®‰∏çÂêåÊ®°Âûã‰∏≠Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®Êï∞Â≠¶Êé®ÁêÜÊñπÈù¢ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜÂú®Êï∞ÂÄºËÆ°ÁÆóÂíåÂΩ¢ÂºèÁ¨¶Âè∑Êìç‰ΩúÁ≠âÈ´òÁ≤æÂ∫¶‰ªªÂä°‰∏≠‰ªçÁÑ∂Èù¢‰∏¥ÊåëÊàò„ÄÇÈõÜÊàêÂ§ñÈÉ®Â∑•ÂÖ∑Â∑≤Êàê‰∏∫Âº•ÂêàËøô‰∏ÄÂ∑ÆË∑ùÁöÑ‰∏ÄÁßçÊúâÂâçÊôØÁöÑÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÊûÑÂª∫Â∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜÊï∞ÊçÆ„ÄÅÊâßË°åÁªÜÁ≤íÂ∫¶‰ºòÂåñÂíåÂ¢ûÂº∫Êé®ÁêÜÊñπÈù¢Â≠òÂú®Âõ∞Èöæ„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∫õÈôêÂà∂ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜTHORÔºàTool-Integrated Hierarchical Optimization via RLÔºâ„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜTIRGenÔºåËøôÊòØ‰∏Ä‰∏™Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìActor-CriticÁöÑpipelineÔºåÁî®‰∫éÊûÑÂª∫È´òË¥®ÈáèÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜË∑ØÂæÑÊï∞ÊçÆÈõÜÔºå‰∏éÁ≠ñÁï•ÂØπÈΩêÂπ∂Âú®‰∏çÂêåÊ®°Âûã‰∏≠Ê≥õÂåñ„ÄÇÂÖ∂Ê¨°Ôºå‰∏∫‰∫ÜÊâßË°åÁªÜÁ≤íÂ∫¶ÁöÑÂ±ÇÊ¨°‰ºòÂåñÔºåÊàë‰ª¨ÂºïÂÖ•‰∫Ü‰∏ÄÁßçRLÁ≠ñÁï•ÔºåËØ•Á≠ñÁï•ËÅîÂêà‰ºòÂåñepisodeÁ∫ßÂà´ÁöÑÈóÆÈ¢òËß£ÂÜ≥ÂíåstepÁ∫ßÂà´ÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÇËøôÊòØÂü∫‰∫éÊàë‰ª¨ÁöÑÂÖ≥ÈîÆÊ¥ûÂØüÔºåÂç≥‰∏≠Èó¥Â∑•ÂÖ∑Ë∞ÉÁî®ÁöÑÊàêÂäüÊòØÊúÄÁªàÁ≠îÊ°àÊ≠£Á°ÆÊÄßÁöÑÊúâÂäõÈ¢ÑÊµãÊåáÊ†á„ÄÇÊúÄÂêéÔºåTHORÁªìÂêà‰∫Ü‰∏ÄÁßçËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂ÔºåËØ•Êú∫Âà∂Âà©Áî®Âç≥Êó∂Â∑•ÂÖ∑ÂèçÈ¶àÊù•Âä®ÊÄÅ‰øÆÊîπÊé®ÁêÜËøáÁ®ã‰∏≠ÁöÑÈîôËØØÊé®ÁêÜË∑ØÂæÑ„ÄÇÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®‰∏çÂêåÁöÑÊ®°Âûã‰∏≠Ë°®Áé∞Âá∫Âº∫Â§ßÁöÑÊ≥õÂåñËÉΩÂäõÔºåÂú®Êé®ÁêÜÂíåÈùûÊé®ÁêÜÊ®°Âûã‰∏≠ÂùáË°®Áé∞ÊúâÊïà„ÄÇÂÆÉËøòÂú®Â§ö‰∏™Êï∞Â≠¶Âü∫ÂáÜÊµãËØï‰∏≠‰∏∫Á±ª‰ººËßÑÊ®°ÁöÑÊ®°ÂûãÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂêåÊó∂Âú®‰ª£Á†ÅÂü∫ÂáÜÊµãËØï‰∏≠‰πüÊèê‰æõ‰∫ÜÊåÅÁª≠ÁöÑÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÁöÑÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®Êï∞Â≠¶Êé®ÁêÜ‰ªªÂä°‰∏≠ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÈ´òÁ≤æÂ∫¶ËÆ°ÁÆóÂíåÁ¨¶Âè∑Êìç‰ΩúÁöÑ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏çË∂≥„ÄÇÁé∞ÊúâÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÊñπÊ≥ïÂú®Êï∞ÊçÆÊûÑÂª∫„ÄÅ‰ºòÂåñÁ≤íÂ∫¶ÂíåÊé®ÁêÜËÉΩÂäõ‰∏äÂ≠òÂú®Áì∂È¢àÔºåÈöæ‰ª•ÂÖÖÂàÜÂà©Áî®Â§ñÈÉ®Â∑•ÂÖ∑ÁöÑ‰ºòÂäø„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöTHORÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Êù•‰ºòÂåñÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜËøáÁ®ãÔºåÂ∞ÜÈóÆÈ¢òÂàÜËß£‰∏∫Â±ÇÊ¨°ÂåñÁöÑÊ≠•È™§ÔºåÂπ∂Âà©Áî®‰∏≠Èó¥Ê≠•È™§ÁöÑÊàêÂäü‰∏éÂê¶Êù•ÊåáÂØºÊï¥‰Ωì‰ºòÂåñ„ÄÇÈÄöËøáËÅîÂêà‰ºòÂåñepisodeÁ∫ßÂà´ÁöÑÈóÆÈ¢òËß£ÂÜ≥ÂíåstepÁ∫ßÂà´ÁöÑ‰ª£Á†ÅÁîüÊàêÔºåÂÆûÁé∞Êõ¥ÁªÜÁ≤íÂ∫¶ÁöÑÊéßÂà∂ÂíåÊõ¥È´òÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöTHORÂåÖÂê´‰∏â‰∏™‰∏ªË¶ÅÁªÑÊàêÈÉ®ÂàÜÔºöTIRGenÔºàÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜÊï∞ÊçÆÁîüÊàêÂô®Ôºâ„ÄÅÂ±ÇÊ¨°‰ºòÂåñRLÁ≠ñÁï•ÂíåËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂„ÄÇTIRGen‰ΩøÁî®Â§öÊô∫ËÉΩ‰ΩìActor-CriticÊ°ÜÊû∂ÁîüÊàêÈ´òË¥®ÈáèÁöÑÂ∑•ÂÖ∑ÈõÜÊàêÊé®ÁêÜË∑ØÂæÑÊï∞ÊçÆÈõÜ„ÄÇÂ±ÇÊ¨°‰ºòÂåñRLÁ≠ñÁï•ÂêåÊó∂‰ºòÂåñepisodeÁ∫ßÂà´ÁöÑÈóÆÈ¢òËß£ÂÜ≥ÂíåstepÁ∫ßÂà´ÁöÑ‰ª£Á†ÅÁîüÊàê„ÄÇËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂Âà©Áî®Â∑•ÂÖ∑ÁöÑÂç≥Êó∂ÂèçÈ¶àÂä®ÊÄÅ‰øÆÊ≠£Êé®ÁêÜË∑ØÂæÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöTHORÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Â±ÇÊ¨°ÂåñÁöÑ‰ºòÂåñÁ≠ñÁï•ÂíåËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂„ÄÇÂ±ÇÊ¨°‰ºòÂåñÂÖÅËÆ∏Ê®°ÂûãÊõ¥ÁªÜÁ≤íÂ∫¶Âú∞ÊéßÂà∂Êé®ÁêÜËøáÁ®ãÔºåËÄåËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂ÂàôËÉΩÂ§üÂà©Áî®Â∑•ÂÖ∑ÁöÑÂèçÈ¶à‰ø°ÊÅØÂä®ÊÄÅÂú∞‰øÆÊ≠£ÈîôËØØÔºå‰ªéËÄåÊèêÈ´òÊï¥‰ΩìÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöTIRGen‰ΩøÁî®Â§öÊô∫ËÉΩ‰ΩìActor-CriticÊ°ÜÊû∂ÔºåÂÖ∂‰∏≠ÊØè‰∏™Êô∫ËÉΩ‰ΩìË¥üË¥£ÁîüÊàêÊé®ÁêÜË∑ØÂæÑ‰∏≠ÁöÑ‰∏Ä‰∏™Ê≠•È™§„ÄÇRLÁ≠ñÁï•‰ΩøÁî®Â•ñÂä±ÂáΩÊï∞Êù•ÈºìÂä±Ê≠£Á°ÆÁöÑÂ∑•ÂÖ∑Ë∞ÉÁî®ÂíåÊúÄÁªàÁ≠îÊ°àÁöÑÊ≠£Á°ÆÊÄß„ÄÇËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂‰ΩøÁî®Â∑•ÂÖ∑ÁöÑÂèçÈ¶à‰ø°ÊÅØÊù•Âà§Êñ≠ÂΩìÂâçÊ≠•È™§ÊòØÂê¶Ê≠£Á°ÆÔºåÂπ∂Ê†πÊçÆÈúÄË¶ÅÈáçÊñ∞ÁîüÊàêËØ•Ê≠•È™§„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

THORÂú®Â§ö‰∏™Êï∞Â≠¶Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåË∂ÖË∂ä‰∫ÜÂêåÁ≠âËßÑÊ®°ÁöÑÊ®°Âûã„ÄÇÊ≠§Â§ñÔºåTHORÂú®‰ª£Á†ÅÂü∫ÂáÜÊµãËØï‰∏≠‰πüÂèñÂæó‰∫ÜÊåÅÁª≠ÁöÑÊîπËøõÔºåËØÅÊòé‰∫ÜÂÖ∂Âú®‰∏çÂêåÈ¢ÜÂüüÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåTHORÁöÑÂ±ÇÊ¨°‰ºòÂåñÁ≠ñÁï•ÂíåËá™ÊàëÁ∫†Ê≠£Êú∫Âà∂ËÉΩÂ§üÊòæËëóÊèêÈ´òÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

THORÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂèØ‰ª•Â∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÂ§çÊùÇÊé®ÁêÜÂíåËÆ°ÁÆóÁöÑ‰ªªÂä°Ôºå‰æãÂ¶ÇÁßëÂ≠¶Á†îÁ©∂„ÄÅÈáëËûçÂàÜÊûê„ÄÅËΩØ‰ª∂ÂºÄÂèëÁ≠â„ÄÇÈÄöËøáÈõÜÊàêÂ§ñÈÉ®Â∑•ÂÖ∑ÔºåTHORÂèØ‰ª•ÊòæËëóÊèêÈ´òËøô‰∫õ‰ªªÂä°ÁöÑËá™Âä®ÂåñÁ®ãÂ∫¶ÂíåÂáÜÁ°ÆÊÄßÔºå‰ªéËÄåÊèêÈ´òÂ∑•‰ΩúÊïàÁéáÂíåÈôç‰ΩéÊàêÊú¨„ÄÇÊú™Êù•ÔºåTHORÂèØ‰ª•Ëøõ‰∏ÄÊ≠•Êâ©Â±ïÂà∞ÂÖ∂‰ªñÈ¢ÜÂüüÔºå‰æãÂ¶ÇËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜ„ÄÅÂõæÂÉèËØÜÂà´Á≠âÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÂåñÁöÑÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs) have made remarkable progress in mathematical reasoning, but still continue to struggle with high-precision tasks like numerical computation and formal symbolic manipulation. Integrating external tools has emerged as a promising approach to bridge this gap. Despite recent advances, existing methods struggle with three key challenges: constructing tool-integrated reasoning data, performing fine-grained optimization, and enhancing inference. To overcome these limitations, we propose THOR (Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen, a multi-agent actor-critic-based pipeline for constructing high-quality datasets of tool-integrated reasoning paths, aligning with the policy and generalizing well across diverse models. Second, to perform fine-grained hierarchical optimization, we introduce an RL strategy that jointly optimizes for both episode-level problem solving and step-level code generation. This is motivated by our key insight that the success of an intermediate tool call is a strong predictor of the final answer's correctness. Finally, THOR incorporates a self-correction mechanism that leverages immediate tool feedback to dynamically revise erroneous reasoning paths during inference. Our approach demonstrates strong generalization across diverse models, performing effectively in both reasoning and non-reasoning models. It further achieves state-of-the-art performance for models of a similar scale on multiple mathematical benchmarks, while also delivering consistent improvements on code benchmarks. Our code will be publicly available at https://github.com/JingMog/THOR.

