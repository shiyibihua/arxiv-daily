---
layout: default
title: Why Cannot Large Language Models Ever Make True Correct Reasoning?
---

# Why Cannot Large Language Models Ever Make True Correct Reasoning?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10265" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10265v2</a>
  <a href="https://arxiv.org/pdf/2508.10265.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10265v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10265v2', 'Why Cannot Large Language Models Ever Make True Correct Reasoning?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingde Cheng

**åˆ†ç±»**: cs.AI, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-14 (æ›´æ–°: 2025-08-16)

**å¤‡æ³¨**: 8 pages. arXiv admin note: substantial text overlap with arXiv:2412.12408

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹æ— æ³•å®ç°çœŸå®æ¨ç†èƒ½åŠ›çš„åŸå› **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `AIGCå·¥å…·` `é€»è¾‘æ¨ç†` `ç»Ÿè®¡æ¨¡å¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„è¿‡åº¦å®£ä¼ ï¼Œæ©ç›–äº†å…¶åœ¨çœŸå®æ¨ç†æ–¹é¢çš„æ ¹æœ¬ç¼ºé™·ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡é€šè¿‡åˆ†æLLMsçš„å·¥ä½œåŸç†ï¼ŒæŒ‡å‡ºå…¶æ¨ç†èƒ½åŠ›çš„å±€é™æ€§ï¼Œå¼ºè°ƒè¿™äº›æ¨¡å‹æ— æ³•è¿›è¡ŒçœŸæ­£çš„é€»è¾‘æ¨ç†ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šè™½ç„¶è®ºæ–‡æœªæä¾›å…·ä½“å®éªŒæ•°æ®ï¼Œä½†å¼ºè°ƒäº†LLMsåœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„å›ºæœ‰ç¼ºé™·ï¼Œæœªèƒ½æå‡ºæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„AIGCå·¥å…·çš„åº”ç”¨è¿›å±•ï¼Œè®¸å¤šAIä¸“å®¶å’Œéä¸“ä¸šäººå£«å¼€å§‹çƒ­è®®LLMsçš„â€œæ¨ç†èƒ½åŠ›â€ã€‚ä½œè€…è®¤ä¸ºï¼Œè¿™ç§æ‰€è°“çš„â€œæ¨ç†èƒ½åŠ›â€åªæ˜¯å¯¹æ¨¡ç³Šæ¦‚å¿µçš„è¯¯è§£ã€‚æœ¬æ–‡æ—¨åœ¨é˜æ˜ï¼Œç”±äºå…¶å·¥ä½œåŸç†çš„æ ¹æœ¬é™åˆ¶ï¼ŒLLMsæ°¸è¿œæ— æ³•å…·å¤‡çœŸå®çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•è¿‡äºä¾èµ–æ¨¡å‹çš„è¡¨é¢è¡¨ç°ï¼Œæœªèƒ½æ·±å…¥åˆ†æå…¶å†…åœ¨æœºåˆ¶çš„ç¼ºé™·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ­ç¤ºLLMsçš„å·¥ä½œåŸç†ï¼Œè®ºè¯å…¶æ— æ³•å®ç°çœŸæ­£çš„æ¨ç†èƒ½åŠ›ã€‚ä½œè€…è®¤ä¸ºï¼ŒLLMsçš„æ¨ç†èƒ½åŠ›æ˜¯åŸºäºç»Ÿè®¡æ¨¡å¼ï¼Œè€Œéé€»è¾‘æ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¯¹LLMsçš„å·¥ä½œåŸç†çš„åˆ†æï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹çš„è¾“å…¥å¤„ç†ã€è¾“å‡ºç”ŸæˆåŠå…¶å†…éƒ¨æœºåˆ¶çš„æ¢è®¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹LLMsæ¨ç†èƒ½åŠ›çš„æ‰¹åˆ¤æ€§åˆ†æï¼ŒæŒ‡å‡ºå…¶åœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„æ ¹æœ¬ç¼ºé™·ï¼Œä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¯¹æ¨ç†èƒ½åŠ›çš„é‡æ–°å®šä¹‰ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æœªæ¶‰åŠå…·ä½“çš„å‚æ•°è®¾ç½®æˆ–ç½‘ç»œç»“æ„ï¼Œè€Œæ˜¯é›†ä¸­äºç†è®ºåˆ†æï¼Œå¼ºè°ƒäº†å¯¹æ¨ç†èƒ½åŠ›çš„è¯¯è§£å’Œæ¨¡å‹çš„ç»Ÿè®¡æ€§è´¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡å¼ºè°ƒäº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„å›ºæœ‰ç¼ºé™·ï¼ŒæŒ‡å‡ºå…¶æ— æ³•è¿›è¡ŒçœŸæ­£çš„é€»è¾‘æ¨ç†ï¼Œå°½ç®¡æœªæä¾›å…·ä½“çš„å®éªŒæ•°æ®ï¼Œä½†ä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„ç†è®ºåŸºç¡€ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯¹ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„å±€é™æ€§å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é€»è¾‘æ¨ç†çš„åº”ç”¨åœºæ™¯ä¸­ï¼Œå¦‚æ³•å¾‹ã€åŒ»å­¦å’Œç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸã€‚æœªæ¥ï¼Œç ”ç©¶è€…å¯ä»¥åŸºäºæ­¤åˆ†æï¼Œæ¢ç´¢æ›´å…·æ¨ç†èƒ½åŠ›çš„æ¨¡å‹è®¾è®¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recently, with the application progress of AIGC tools based on large language models (LLMs), led by ChatGPT, many AI experts and more non-professionals are trumpeting the "reasoning ability" of the LLMs. The present author considers that the so-called "reasoning ability" of LLMs are just illusions of those people who with vague concepts. In fact, the LLMs can never have the true reasoning ability. This paper intents to explain that, because the essential limitations of their working principle, the LLMs can never have the ability of true correct reasoning.

