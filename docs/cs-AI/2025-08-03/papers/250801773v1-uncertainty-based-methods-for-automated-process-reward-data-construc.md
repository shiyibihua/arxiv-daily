---
layout: default
title: Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning
---

# Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.01773" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.01773v1</a>
  <a href="https://arxiv.org/pdf/2508.01773.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.01773v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.01773v1', 'Uncertainty-Based Methods for Automated Process Reward Data Construction and Output Aggregation in Mathematical Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiuzhou Han, Wray Buntine, Ehsan Shareghi

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-03

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Jiuzhouh/UnPRM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºä¸ç¡®å®šæ€§çš„æ¡†æ¶ä»¥è‡ªåŠ¨æ„å»ºè¿‡ç¨‹å¥–åŠ±æ•°æ®**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¿‡ç¨‹å¥–åŠ±æ¨¡å‹` `ä¸ç¡®å®šæ€§è¯„ä¼°` `è‡ªåŠ¨åŒ–æ•°æ®æ„å»º` `æ•°å­¦æ¨ç†` `è¾“å‡ºèšåˆæ–¹æ³•` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¿‡ç¨‹å¥–åŠ±æ•°æ®æ„å»ºæ–¹æ³•å¾€å¾€åŠ³åŠ¨å¯†é›†ä¸”æ•ˆç‡ä½ä¸‹ï¼Œé™åˆ¶äº†è¿‡ç¨‹çº§å¥–åŠ±æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„æ¡†æ¶ï¼Œè‡ªåŠ¨åŒ–è¿‡ç¨‹å¥–åŠ±æ•°æ®çš„ç”Ÿæˆå’Œæ³¨é‡Šï¼Œæå‡äº†æ•°æ®æ„å»ºçš„æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸”æ–°æå‡ºçš„èšåˆæ–¹æ³•æ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­å±•ç°äº†æ˜¾è‘—èƒ½åŠ›ï¼Œä½†åœ¨å¤šæ­¥éª¤è§£å†³æ–¹æ¡ˆä¸­ä¸å¯é¿å…åœ°ä¼šäº§ç”Ÿé”™è¯¯ã€‚è¿‡ç¨‹çº§å¥–åŠ±æ¨¡å‹ï¼ˆPRMsï¼‰é€šè¿‡åœ¨æ¯ä¸ªä¸­é—´æ­¥éª¤æä¾›ç›‘ç£å’Œè¯„ä¼°ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè®­ç»ƒæœ‰æ•ˆçš„PRMséœ€è¦é«˜è´¨é‡çš„è¿‡ç¨‹å¥–åŠ±æ•°æ®ï¼Œç°æœ‰æ„å»ºæ–¹æ³•å¾€å¾€åŠ³åŠ¨å¯†é›†æˆ–æ•ˆç‡ä½ä¸‹ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„è‡ªåŠ¨è¿‡ç¨‹å¥–åŠ±æ•°æ®æ„å»ºæ¡†æ¶ï¼Œæ¶µç›–æ•°æ®ç”Ÿæˆå’Œæ³¨é‡Šè¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¯†åˆ«äº†å¤šæ•°æŠ•ç¥¨å’ŒPRMsçš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸¤ç§é€šç”¨çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¾“å‡ºèšåˆæ–¹æ³•ï¼šæ··åˆå¤šæ•°å¥–åŠ±æŠ•ç¥¨å’ŒåŠ æƒå¥–åŠ±é¢‘ç‡æŠ•ç¥¨ï¼Œç»“åˆäº†å¤šæ•°æŠ•ç¥¨ä¸PRMsçš„ä¼˜åŠ¿ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæ‰€ææ¡†æ¶åœ¨ProcessBenchã€MATHå’ŒGSMPlusä¸Šæœ‰æ•ˆä¸”é«˜æ•ˆï¼Œä¸”ä¸¤ç§è¾“å‡ºèšåˆæ–¹æ³•è¿›ä¸€æ­¥æå‡äº†å¤šæ ·åŒ–PRMsçš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è¿‡ç¨‹å¥–åŠ±æ•°æ®æ„å»ºæ–¹æ³•çš„ä½æ•ˆå’ŒåŠ³åŠ¨å¯†é›†é—®é¢˜ï¼Œé™åˆ¶äº†è¿‡ç¨‹çº§å¥–åŠ±æ¨¡å‹çš„æœ‰æ•ˆè®­ç»ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§åŸºäºä¸ç¡®å®šæ€§çš„è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œé€šè¿‡ä¼˜åŒ–æ•°æ®ç”Ÿæˆå’Œæ³¨é‡Šè¿‡ç¨‹ï¼Œæå‡è¿‡ç¨‹å¥–åŠ±æ•°æ®çš„è´¨é‡å’Œæ„å»ºæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆæ¨¡å—å’Œæ³¨é‡Šæ¨¡å—ï¼Œåˆ©ç”¨ä¸ç¡®å®šæ€§è¯„ä¼°æ¥æŒ‡å¯¼æ•°æ®çš„é€‰æ‹©å’Œæ ‡æ³¨ï¼Œç¡®ä¿ç”Ÿæˆé«˜è´¨é‡çš„è¿‡ç¨‹å¥–åŠ±æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥äº†æ··åˆå¤šæ•°å¥–åŠ±æŠ•ç¥¨å’ŒåŠ æƒå¥–åŠ±é¢‘ç‡æŠ•ç¥¨ä¸¤ç§ä¸ç¡®å®šæ€§æ„ŸçŸ¥è¾“å‡ºèšåˆæ–¹æ³•ï¼Œç»“åˆäº†ä¼ ç»Ÿå¤šæ•°æŠ•ç¥¨å’ŒPRMsçš„ä¼˜ç‚¹ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¡†æ¶ä¸­ï¼Œè®¾ç½®äº†ä¸ç¡®å®šæ€§é˜ˆå€¼æ¥ç­›é€‰æ•°æ®ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹è®­ç»ƒï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§ç½‘ç»œç»“æ„ä»¥æ”¯æŒå¤šæ ·åŒ–çš„è¾“å…¥æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ¡†æ¶åœ¨ProcessBenchã€MATHå’ŒGSMPlusæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æé«˜äº†çº¦15%-20%çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†æ–°æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²æŠ€æœ¯ã€è‡ªåŠ¨åŒ–è¯„ä¼°ç³»ç»Ÿå’Œæ™ºèƒ½è¾…å¯¼å·¥å…·ç­‰ã€‚é€šè¿‡æå‡æ•°å­¦æ¨ç†èƒ½åŠ›ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä¸ºå­¦ç”Ÿæä¾›æ›´ç²¾å‡†çš„å­¦ä¹ åé¦ˆï¼Œå¸®åŠ©ä»–ä»¬åœ¨å¤æ‚é—®é¢˜è§£å†³ä¸­å–å¾—æ›´å¥½çš„æˆç»©ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨å…¶ä»–é¢†åŸŸçš„æ™ºèƒ½ç³»ç»Ÿä¸­å¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œæ¨åŠ¨æ•™è‚²å’Œè‡ªåŠ¨åŒ–è¯„ä¼°çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models have demonstrated remarkable capabilities in complex mathematical reasoning tasks, but they inevitably generate errors throughout multi-step solutions. Process-level Reward Models (PRMs) have shown great promise by providing supervision and evaluation at each intermediate step, thereby effectively improving the models' reasoning abilities. However, training effective PRMs requires high-quality process reward data, yet existing methods for constructing such data are often labour-intensive or inefficient. In this paper, we propose an uncertainty-driven framework for automated process reward data construction, encompassing both data generation and annotation processes for PRMs. Additionally, we identify the limitations of both majority vote and PRMs, and introduce two generic uncertainty-aware output aggregation methods: Hybrid Majority Reward Vote and Weighted Reward Frequency Vote, which combine the strengths of majority vote with PRMs. Extensive experiments on ProcessBench, MATH, and GSMPlus show the effectiveness and efficiency of the proposed PRM data construction framework, and demonstrate that the two output aggregation methods further improve the mathematical reasoning abilities across diverse PRMs. The code and data will be publicly available at https://github.com/Jiuzhouh/UnPRM.

