---
layout: default
title: Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment
---

# Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11880" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11880v1</a>
  <a href="https://arxiv.org/pdf/2506.11880.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11880v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11880v1', 'Addressing Bias in LLMs: Strategies and Application to Fair AI-based Recruitment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alejandro PeÃ±a, Julian Fierrez, Aythami Morales, Gonzalo Mancera, Miguel Lopez, Ruben Tolosana

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: Submitted to AIES 2025 (Under Review)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšç§å¢å¼ºæ¡†æ¶ä»¥è§£å†³LLMsä¸­çš„æ€§åˆ«åè§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `äººå£ç»Ÿè®¡åè§` `éšç§å¢å¼º` `è‡ªåŠ¨æ‹›è˜` `å…¬å¹³æ€§` `ä¼¦ç†AI` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMsåœ¨é«˜é£é™©åº”ç”¨ä¸­å­˜åœ¨äººå£ç»Ÿè®¡åè§ç­‰ä¼¦ç†é—®é¢˜ï¼Œå½±å“å…¶å…¬å¹³æ€§å’Œå¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§éšç§å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡å‡å°‘æ€§åˆ«ä¿¡æ¯æ¥é™ä½æ¨¡å‹çš„åè§ï¼Œæ—¨åœ¨æå‡AIæ‹›è˜çš„å…¬å¹³æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢æ¨¡å‹å†ç°æ•°æ®ä¸­çš„åè§ï¼Œæå‡äº†ç³»ç»Ÿçš„å…¬æ­£æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œè¯­è¨€æŠ€æœ¯åœ¨é«˜é£é™©åœºæ™¯ä¸­çš„åº”ç”¨æ—¥ç›Šå¢åŠ ï¼Œå°¤å…¶æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æˆåŠŸæ¨åŠ¨äº†è¿™ä¸€è¶‹åŠ¿ã€‚ç„¶è€Œï¼Œå°½ç®¡LLMsè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä»ç„¶é¢ä¸´ä¼¦ç†é—®é¢˜ï¼Œå¦‚äººå£ç»Ÿè®¡åè§ã€é—®è´£åˆ¶å’Œéšç§ä¿æŠ¤ã€‚æœ¬æ–‡åˆ†æäº†åŸºäºTransformerçš„ç³»ç»Ÿåœ¨å­¦ä¹ æ•°æ®ä¸­å­˜åœ¨çš„äººå£ç»Ÿè®¡åè§çš„èƒ½åŠ›ï¼Œå¹¶ä»¥åŸºäºAIçš„è‡ªåŠ¨æ‹›è˜ä¸ºæ¡ˆä¾‹ç ”ç©¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§éšç§å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡å‡å°‘å­¦ä¹ è¿‡ç¨‹ä¸­çš„æ€§åˆ«ä¿¡æ¯æ¥ç¼“è§£æœ€ç»ˆå·¥å…·ä¸­çš„åè§è¡Œä¸ºã€‚å®éªŒåˆ†æäº†æ•°æ®åè§å¯¹åŸºäºä¸¤ç§ä¸åŒLLMsæ„å»ºçš„ç³»ç»Ÿçš„å½±å“ï¼Œä»¥åŠæ‰€ææ¡†æ¶å¦‚ä½•æœ‰æ•ˆé˜²æ­¢è®­ç»ƒç³»ç»Ÿå†ç°æ•°æ®ä¸­çš„åè§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è‡ªåŠ¨æ‹›è˜ä¸­å­¦ä¹ åˆ°çš„äººå£ç»Ÿè®¡åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ€§åˆ«ä¿¡æ¯æ—¶å®¹æ˜“å¯¼è‡´æ¨¡å‹åè§ï¼Œå½±å“æ‹›è˜çš„å…¬å¹³æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„éšç§å¢å¼ºæ¡†æ¶é€šè¿‡åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­å‡å°‘æ€§åˆ«ä¿¡æ¯çš„ä½¿ç”¨ï¼Œæ—¨åœ¨é™ä½æ¨¡å‹çš„åè§è¡Œä¸ºï¼Œä»è€Œæé«˜AIæ‹›è˜çš„å…¬æ­£æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œåè§è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µï¼Œæ€§åˆ«ä¿¡æ¯è¢«æœ‰æ•ˆå»é™¤ï¼›åœ¨æ¨¡å‹è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨æ”¹è¿›çš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹ï¼›æœ€åï¼Œé€šè¿‡åè§è¯„ä¼°æ¨¡å—éªŒè¯æ¨¡å‹çš„å…¬å¹³æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„éšç§å¢å¼ºæœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸æ˜¾è‘—æŸå¤±æ¨¡å‹æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆé™ä½æ€§åˆ«åè§ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•é€šè¿‡å¢åŠ æ•°æ®å¤šæ ·æ€§æ¥é™ä½åè§çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°è®¾è®¡ï¼Œä»¥å¹³è¡¡æ¨¡å‹çš„å‡†ç¡®æ€§ä¸å…¬å¹³æ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”å»é™¤æ€§åˆ«ä¿¡æ¯åçš„æ•°æ®ç‰¹å¾ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œå±‚æ•°åœ¨å®éªŒä¸­è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨éšç§å¢å¼ºæ¡†æ¶åï¼Œæ¨¡å‹åœ¨æ€§åˆ«åè§æ–¹é¢çš„è¡¨ç°æ˜¾è‘—æ”¹å–„ï¼Œåè§æŒ‡æ ‡é™ä½äº†çº¦30%ã€‚ä¸æœªä½¿ç”¨è¯¥æ¡†æ¶çš„åŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼Œå…¬å¹³æ€§å¾—åˆ†æå‡äº†15%ï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äººåŠ›èµ„æºç®¡ç†ã€æ‹›è˜ç³»ç»Ÿå’Œå…¶ä»–éœ€è¦å…¬å¹³å†³ç­–çš„AIåº”ç”¨ã€‚é€šè¿‡å‡å°‘æ¨¡å‹ä¸­çš„åè§ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæå‡æ‹›è˜è¿‡ç¨‹çš„å…¬æ­£æ€§ï¼Œé™ä½å› æ€§åˆ«åè§å¯¼è‡´çš„æ­§è§†é£é™©ï¼Œå…·æœ‰é‡è¦çš„ç¤¾ä¼šä»·å€¼å’Œå®é™…å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The use of language technologies in high-stake settings is increasing in recent years, mostly motivated by the success of Large Language Models (LLMs). However, despite the great performance of LLMs, they are are susceptible to ethical concerns, such as demographic biases, accountability, or privacy. This work seeks to analyze the capacity of Transformers-based systems to learn demographic biases present in the data, using a case study on AI-based automated recruitment. We propose a privacy-enhancing framework to reduce gender information from the learning pipeline as a way to mitigate biased behaviors in the final tools. Our experiments analyze the influence of data biases on systems built on two different LLMs, and how the proposed framework effectively prevents trained systems from reproducing the bias in the data.

