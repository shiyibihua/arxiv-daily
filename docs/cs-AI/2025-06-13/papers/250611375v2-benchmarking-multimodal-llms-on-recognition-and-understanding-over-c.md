---
layout: default
title: Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables
---

# Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11375" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11375v2</a>
  <a href="https://arxiv.org/pdf/2506.11375.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11375v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11375v2', 'Benchmarking Multimodal LLMs on Recognition and Understanding over Chemical Tables')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yitong Zhou, Mingyue Cheng, Qingyang Mao, Yucong Luo, Qi Liu, Yupeng Li, Xiaohan Zhang, Deguang Liu, Xin Li, Enhong Chen

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-12-11)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChemTableåŸºå‡†ä»¥è§£å†³åŒ–å­¦è¡¨æ ¼ç†è§£ä¸è¯†åˆ«é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `åŒ–å­¦è¡¨æ ¼` `çŸ¥è¯†è¡¨ç¤º` `ç§‘å­¦æ™ºèƒ½` `è¡¨æ ¼ç†è§£` `è¯„ä¼°åŸºå‡†` `é¢†åŸŸç‰¹å®šè¯­ä¹‰` `æ¨ç†èƒ½åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°åŸºå‡†ä¸»è¦é›†ä¸­åœ¨ä¸€èˆ¬é¢†åŸŸï¼Œæœªèƒ½åæ˜ ç§‘å­¦ç ”ç©¶ä¸­åŒ–å­¦è¡¨æ ¼çš„ç»“æ„å¤æ‚æ€§å’Œé¢†åŸŸç‰¹å®šè¯­ä¹‰ã€‚
2. æå‡ºChemTableåŸºå‡†ï¼ŒåŸºäºçœŸå®æ–‡çŒ®æ„å»ºï¼ŒåŒ…å«ä¸“å®¶æ³¨é‡Šçš„å¸ƒå±€å’Œé€»è¾‘ç»“æ„ï¼Œæ”¯æŒè¡¨æ ¼è¯†åˆ«ä¸ç†è§£ä»»åŠ¡ã€‚
3. è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œä¸»æµå¤šæ¨¡æ€æ¨¡å‹åœ¨å¸ƒå±€è§£æä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†åŒ–å­¦è¡¨æ ¼çš„å…³é”®å…ƒç´ æ—¶ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦æ™ºèƒ½ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œè¿«åˆ‡éœ€è¦æ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°åŸºå‡†æ¥è¯„ä¼°å…¶ç†è§£å¤æ‚ç§‘å­¦æ•°æ®çš„èƒ½åŠ›ã€‚ç§‘å­¦è¡¨æ ¼ä½œä¸ºçŸ¥è¯†è¡¨ç¤ºçš„æ ¸å¿ƒè½½ä½“ï¼Œç»“åˆäº†æ–‡æœ¬ã€ç¬¦å·å’Œå›¾å½¢ï¼Œå½¢æˆäº†å…¸å‹çš„å¤šæ¨¡æ€æ¨ç†åœºæ™¯ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºå‡†ä¸»è¦é›†ä¸­åœ¨ä¸€èˆ¬é¢†åŸŸï¼Œæœªèƒ½åæ˜ ç§‘å­¦ç ”ç©¶ä¸­å›ºæœ‰çš„ç»“æ„å¤æ‚æ€§å’Œé¢†åŸŸç‰¹å®šè¯­ä¹‰ã€‚åŒ–å­¦è¡¨æ ¼å°¤å…¶å…·æœ‰ä»£è¡¨æ€§ï¼šå®ƒä»¬å°†ååº”ç‰©ã€æ¡ä»¶å’Œäº§é‡ç­‰ç»“æ„åŒ–å˜é‡ä¸åˆ†å­ç»“æ„å’ŒåŒ–å­¦å…¬å¼ç­‰è§†è§‰ç¬¦å·äº¤ç»‡åœ¨ä¸€èµ·ï¼Œç»™æ¨¡å‹åœ¨è·¨æ¨¡æ€å¯¹é½å’Œè¯­ä¹‰è§£æä¸Šå¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºChemTableâ€”â€”ä¸€ä¸ªåŸºäºçœŸå®æ–‡çŒ®æ„å»ºçš„å¤§è§„æ¨¡åŒ–å­¦è¡¨æ ¼åŸºå‡†ï¼ŒåŒ…å«ä¸“å®¶æ³¨é‡Šçš„å•å…ƒæ ¼å¸ƒå±€ã€é€»è¾‘ç»“æ„å’Œé¢†åŸŸç‰¹å®šæ ‡ç­¾ã€‚è¯¥åŸºå‡†æ”¯æŒä¸¤ä¸ªæ ¸å¿ƒä»»åŠ¡ï¼šè¡¨æ ¼è¯†åˆ«ï¼ˆç»“æ„å’Œå†…å®¹æå–ï¼‰å’Œè¡¨æ ¼ç†è§£ï¼ˆæè¿°æ€§å’ŒåŸºäºæ¨ç†çš„é—®é¢˜å›ç­”ï¼‰ã€‚åœ¨ChemTableä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå°½ç®¡ä¸»æµå¤šæ¨¡æ€æ¨¡å‹åœ¨å¸ƒå±€è§£æä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†åˆ†å­ç»“æ„å’Œç¬¦å·çº¦å®šç­‰å…³é”®å…ƒç´ æ—¶ä»é¢ä¸´æ˜¾è‘—é™åˆ¶ã€‚å°é—­æºæ¨¡å‹æ•´ä½“è¡¨ç°é¢†å…ˆï¼Œä½†ä»æœªè¾¾åˆ°äººç±»æ°´å¹³çš„è¡¨ç°ã€‚è¿™é¡¹å·¥ä½œä¸ºè¯„ä¼°ç§‘å­¦å¤šæ¨¡æ€ç†è§£æä¾›äº†ç°å®çš„æµ‹è¯•å¹³å°ï¼Œæ­ç¤ºäº†é¢†åŸŸç‰¹å®šæ¨ç†çš„å½“å‰ç“¶é¢ˆï¼Œæ¨åŠ¨äº†ç§‘å­¦ç ”ç©¶æ™ºèƒ½ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç†è§£å’Œè¯†åˆ«åŒ–å­¦è¡¨æ ¼æ—¶çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚çš„ç»“æ„åŒ–å˜é‡å’Œè§†è§‰ç¬¦å·æ—¶çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹åŒ–å­¦è¡¨æ ¼çš„é¢†åŸŸç‰¹å®šè¯­ä¹‰å’Œç»“æ„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºChemTableåŸºå‡†ï¼Œé€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«çœŸå®æ–‡çŒ®çš„åŒ–å­¦è¡¨æ ¼æ•°æ®é›†ï¼Œæä¾›æ›´å…·æŒ‘æˆ˜æ€§çš„è¯„ä¼°ä»»åŠ¡ï¼Œä»¥ä¿ƒè¿›å¤šæ¨¡æ€æ¨¡å‹åœ¨ç§‘å­¦æ•°æ®ç†è§£ä¸Šçš„èƒ½åŠ›æå‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šChemTableçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä¸“å®¶æ³¨é‡Šã€ä»»åŠ¡è®¾è®¡å’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é˜¶æ®µä»çœŸå®æ–‡çŒ®ä¸­æå–åŒ–å­¦è¡¨æ ¼ï¼Œä¸“å®¶æ³¨é‡Šé˜¶æ®µå¯¹è¡¨æ ¼è¿›è¡Œç»“æ„å’Œå†…å®¹çš„æ ‡æ³¨ï¼Œä»»åŠ¡è®¾è®¡é˜¶æ®µå®šä¹‰è¡¨æ ¼è¯†åˆ«å’Œç†è§£çš„å…·ä½“ä»»åŠ¡ï¼Œè¯„ä¼°é˜¶æ®µåˆ™å¯¹æ¨¡å‹æ€§èƒ½è¿›è¡Œæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šChemTableçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶é’ˆå¯¹åŒ–å­¦è¡¨æ ¼çš„ä¸“é—¨è®¾è®¡ï¼Œç»“åˆäº†ç»“æ„åŒ–å˜é‡ä¸è§†è§‰ç¬¦å·çš„å¤æ‚æ€§ï¼Œæä¾›äº†ä¸€ä¸ªçœŸå®ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯„ä¼°å¹³å°ï¼Œä¸ç°æœ‰çš„é€šç”¨åŸºå‡†ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ é¢†åŸŸç‰¹å®šçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®é›†æ„å»ºä¸­ï¼Œè®¾ç½®äº†è¯¦ç»†çš„å•å…ƒæ ¼å¸ƒå±€å’Œé€»è¾‘ç»“æ„ï¼Œé‡‡ç”¨äº†é¢†åŸŸç‰¹å®šæ ‡ç­¾ï¼Œç¡®ä¿æ¨¡å‹åœ¨è¯„ä¼°æ—¶èƒ½å¤Ÿå‡†ç¡®ç†è§£å’Œè§£æåŒ–å­¦è¡¨æ ¼ä¸­çš„ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ChemTableä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œä¸»æµå¤šæ¨¡æ€æ¨¡å‹åœ¨å¸ƒå±€è§£æä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†åˆ†å­ç»“æ„å’Œç¬¦å·çº¦å®šç­‰å…³é”®å…ƒç´ æ—¶ä»å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚å°é—­æºæ¨¡å‹çš„æ•´ä½“è¡¨ç°é¢†å…ˆï¼Œä½†ä»æœªè¾¾åˆ°äººç±»æ°´å¹³çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å½“å‰é¢†åŸŸç‰¹å®šæ¨ç†çš„ç“¶é¢ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ–å­¦ä¿¡æ¯æå–ã€ç§‘å­¦æ–‡çŒ®åˆ†æå’Œæ™ºèƒ½é—®ç­”ç³»ç»Ÿç­‰ã€‚é€šè¿‡æä¾›ä¸€ä¸ªä¸“é—¨çš„è¯„ä¼°åŸºå‡†ï¼ŒChemTableèƒ½å¤Ÿæ¨åŠ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨ç§‘å­¦ç ”ç©¶ä¸­çš„åº”ç”¨ï¼Œæå‡å…¶åœ¨å¤æ‚æ•°æ®ç†è§£æ–¹é¢çš„èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the widespread application of multimodal large language models in scientific intelligence, there is an urgent need for more challenging evaluation benchmarks to assess their ability to understand complex scientific data. Scientific tables, as core carriers of knowledge representation, combine text, symbols, and graphics, forming a typical multimodal reasoning scenario. However, existing benchmarks are mostly focused on general domains, failing to reflect the unique structural complexity and domain-specific semantics inherent in scientific research. Chemical tables are particularly representative: they intertwine structured variables such as reagents, conditions, and yields with visual symbols like molecular structures and chemical formulas, posing significant challenges to models in cross-modal alignment and semantic parsing. To address this, we propose ChemTable-a large scale benchmark of chemical tables constructed from real-world literature, containing expert-annotated cell layouts, logical structures, and domain-specific labels. It supports two core tasks: (1) table recognition (structure and content extraction); and (2) table understanding (descriptive and reasoning-based question answering). Evaluation on ChemTable shows that while mainstream multimodal models perform reasonably well in layout parsing, they still face significant limitations when handling critical elements such as molecular structures and symbolic conventions. Closed-source models lead overall but still fall short of human-level performance. This work provides a realistic testing platform for evaluating scientific multimodal understanding, revealing the current bottlenecks in domain-specific reasoning and advancing the development of intelligent systems for scientific research.

