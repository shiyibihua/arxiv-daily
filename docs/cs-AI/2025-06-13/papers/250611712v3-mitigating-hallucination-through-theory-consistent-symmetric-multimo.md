---
layout: default
title: Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization
---

# Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11712" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11712v3</a>
  <a href="https://arxiv.org/pdf/2506.11712.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11712v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11712v3', 'Mitigating Hallucination Through Theory-Consistent Symmetric Multimodal Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wenqi Liu, Xuemeng Song, Jiaxi Li, Yinwei Wei, Na Zheng, Jianhua Yin, Liqiang Nie

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-12-22)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯¹ç§°å¤šæ¨¡æ€åå¥½ä¼˜åŒ–ä»¥è§£å†³å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `åå¥½ä¼˜åŒ–` `å¹»è§‰å‡è½»` `è§†è§‰ç†è§£` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¼˜åŒ–ç›®æ ‡å‡½æ•°çš„ä¸¥è°¨æ€§å’Œåå¥½ç›‘ç£çš„é—´æ¥æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå½±å“äº†å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚
2. æœ¬æ–‡æå‡ºå¯¹ç§°å¤šæ¨¡æ€åå¥½ä¼˜åŒ–ï¼ˆSymMPOï¼‰ï¼Œé€šè¿‡ç›´æ¥åå¥½ç›‘ç£è¿›è¡Œå¯¹ç§°åå¥½å­¦ä¹ ï¼Œå¢å¼ºè§†è§‰ç†è§£èƒ½åŠ›ã€‚
3. åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSymMPOè¡¨ç°ä¼˜è¶Šï¼ŒéªŒè¯äº†å…¶åœ¨å‡è½»å¹»è§‰æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰å·²æˆä¸ºå‡è½»å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å¹»è§‰çš„æœ‰æ•ˆæ–¹æ³•ã€‚å°½ç®¡ç°æœ‰æ–¹æ³•é€šè¿‡è§†è§‰å¯¼å‘çš„å¯¹æ¯”ç›®æ ‡æ˜¾è‘—æå‡äº†MLLMså¯¹è§†è§‰è¾“å…¥çš„å…³æ³¨ï¼Œä»è€Œå‡å°‘äº†å¹»è§‰ï¼Œä½†å®ƒä»¬åœ¨ä¼˜åŒ–ç›®æ ‡å‡½æ•°çš„ä¸¥è°¨æ€§å’Œåå¥½ç›‘ç£çš„é—´æ¥æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†å¯¹ç§°å¤šæ¨¡æ€åå¥½ä¼˜åŒ–ï¼ˆSymMPOï¼‰ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç›´æ¥åå¥½ç›‘ç£ï¼ˆå³å“åº”å¯¹ï¼‰è¿›è¡Œå¯¹ç§°åå¥½å­¦ä¹ ï¼Œä»¥å¢å¼ºè§†è§‰ç†è§£ï¼ŒåŒæ—¶ä¿æŒä¸æ ‡å‡†DPOçš„ä¸¥æ ¼ç†è®ºä¸€è‡´æ€§ã€‚é™¤äº†ä¼ ç»Ÿçš„åºæ•°åå¥½å­¦ä¹ å¤–ï¼ŒSymMPOè¿˜å¼•å…¥äº†åå¥½è¾¹é™…ä¸€è‡´æ€§æŸå¤±ï¼Œä»¥å®šé‡è°ƒèŠ‚å¯¹ç§°åå¥½å¯¹ä¹‹é—´çš„åå¥½å·®è·ã€‚ç»¼åˆè¯„ä¼°æ˜¾ç¤ºï¼ŒSymMPOåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ä¼˜è¶Šï¼ŒéªŒè¯äº†å…¶åœ¨å‡è½»MLLMså¹»è§‰æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­çš„å¹»è§‰é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ä¼˜åŒ–ç›®æ ‡çš„ä¸¥è°¨æ€§å’Œåå¥½ç›‘ç£çš„é—´æ¥æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ¨¡å‹å¯¹è§†è§‰è¾“å…¥çš„ç†è§£ä¸å¤Ÿå‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¯¹ç§°å¤šæ¨¡æ€åå¥½ä¼˜åŒ–ï¼ˆSymMPOï¼‰ï¼Œé€šè¿‡ç›´æ¥åå¥½ç›‘ç£è¿›è¡Œå¯¹ç§°åå¥½å­¦ä¹ ï¼Œç¡®ä¿æ¨¡å‹åœ¨è§†è§‰ç†è§£ä¸Šä¸æ ‡å‡†DPOä¿æŒä¸€è‡´æ€§ï¼Œä»è€Œæœ‰æ•ˆå‡è½»å¹»è§‰ç°è±¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSymMPOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬åå¥½å­¦ä¹ æ¨¡å—å’Œåå¥½è¾¹é™…ä¸€è‡´æ€§æŸå¤±æ¨¡å—ã€‚åå¥½å­¦ä¹ æ¨¡å—é€šè¿‡å“åº”å¯¹è¿›è¡Œç›´æ¥ç›‘ç£ï¼Œè€Œä¸€è‡´æ€§æŸå¤±æ¨¡å—åˆ™è°ƒèŠ‚å¯¹ç§°åå¥½å¯¹ä¹‹é—´çš„åå¥½å·®è·ã€‚

**å…³é”®åˆ›æ–°**ï¼šSymMPOçš„æœ€å¤§åˆ›æ–°åœ¨äºå¼•å…¥äº†åå¥½è¾¹é™…ä¸€è‡´æ€§æŸå¤±ï¼Œå®šé‡è°ƒèŠ‚åå¥½å¯¹ä¹‹é—´çš„å·®è·ï¼Œä»è€Œåœ¨ç†è®ºä¸Šä¸DPOä¿æŒä¸€è‡´ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼ŒSymMPOç»“åˆäº†ä¼ ç»Ÿçš„åºæ•°åå¥½å­¦ä¹ å’Œæ–°çš„åå¥½è¾¹é™…ä¸€è‡´æ€§æŸå¤±ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°è§†è§‰è¾“å…¥çš„åå¥½ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒSymMPOçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¹»è§‰å‡è½»æ–¹é¢çš„æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒåˆ†æç­‰å¤šæ¨¡æ€äº¤äº’åœºæ™¯ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„è§†è§‰ç†è§£èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ”¯æŒäººæœºäº¤äº’å’Œå†³ç­–åˆ¶å®šï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Direct Preference Optimization (DPO) has emerged as an effective approach for mitigating hallucination in Multimodal Large Language Models (MLLMs). Although existing methods have achieved significant progress by utilizing vision-oriented contrastive objectives for enhancing MLLMs' attention to visual inputs and hence reducing hallucination, they suffer from non-rigorous optimization objective function and indirect preference supervision. To address these limitations, we propose a Symmetric Multimodal Preference Optimization (SymMPO), which conducts symmetric preference learning with direct preference supervision (i.e., response pairs) for visual understanding enhancement, while maintaining rigorous theoretical alignment with standard DPO. In addition to conventional ordinal preference learning, SymMPO introduces a preference margin consistency loss to quantitatively regulate the preference gap between symmetric preference pairs. Comprehensive evaluation across five benchmarks demonstrate SymMPO's superior performance, validating its effectiveness in hallucination mitigation of MLLMs.

