---
layout: default
title: Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models
---

# Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11487" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11487v1</a>
  <a href="https://arxiv.org/pdf/2506.11487.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11487v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11487v1', 'Reviving DSP for Advanced Theorem Proving in the Era of Reasoning Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenrui Cao, Liangcheng Song, Zenan Li, Xinyi Le, Xian Zhang, Hui Xue, Fan Yang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 31 pages. Associated code and results are available at https://github.com/microsoft/DSP-Plus

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDSP+ä»¥æå‡è‡ªåŠ¨å®šç†è¯æ˜çš„æ•ˆç‡ä¸å‡†ç¡®æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `è‡ªåŠ¨å®šç†è¯æ˜` `ç¥ç»ç¬¦å·åè°ƒ` `å¼ºåŒ–å­¦ä¹ ` `å½¢å¼åŒ–éªŒè¯` `æ¨ç†æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªåŠ¨å®šç†è¯æ˜æ–¹æ³•ä¾èµ–äºå¤§è§„æ¨¡çš„æ¨¡å‹è®­ç»ƒï¼Œé¢ä¸´ç€è®­ç»ƒæˆæœ¬é«˜å’Œæ•ˆæœä¸ç¨³å®šçš„é—®é¢˜ã€‚
2. DSP+é€šè¿‡ç¥ç»ç¬¦å·åè°ƒï¼Œä¼˜åŒ–äº†å®šç†è¯æ˜çš„å„ä¸ªé˜¶æ®µï¼Œç‰¹åˆ«æ˜¯åœ¨è‰æ‹Ÿã€è‰å›¾å’Œè¯æ˜é˜¶æ®µçš„å¤„ç†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDSP+åœ¨å¤šä¸ªé—®é¢˜é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„è§£å†³ç‡ï¼Œä¸”æ— éœ€é¢å¤–çš„æ¨¡å‹è®­ç»ƒï¼Œè¡¨ç°å‡ºæ›´é«˜çš„æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¤§è§„æ¨¡è®­ç»ƒåœ¨è‡ªåŠ¨å®šç†è¯æ˜ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œæœ¬ç ”ç©¶å‘ç°ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç¥ç»ç¬¦å·åè°ƒï¼Œç°æœ‰æ¨ç†æ¨¡å‹ä¸ç­–ç•¥æ­¥éª¤è¯æ˜å™¨çš„ç»“åˆèƒ½å¤Ÿåœ¨æ²¡æœ‰ä»»ä½•è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°å¯æ¯”çš„æ€§èƒ½ã€‚æœ¬æ–‡æå‡ºäº†DSP+ï¼Œè¿™æ˜¯Draft, Sketch, and Proveæ¡†æ¶çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œé’ˆå¯¹æ¯ä¸ªé˜¶æ®µè¿›è¡Œäº†ç»†ç²’åº¦çš„ç¥ç»ç¬¦å·å¢å¼ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDSP+åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè§£å†³äº†80.7%ã€32.8%å’Œ644ä¸ªé—®é¢˜ä¸­çš„24ä¸ªï¼Œä¸”æ‰€éœ€é¢„ç®—ä½äºç°æœ‰æŠ€æœ¯ã€‚æ­¤å¤–ï¼ŒDSP+ç”Ÿæˆçš„è¯æ˜æ¨¡å¼æ˜“äºäººç±»ä¸“å®¶ç†è§£ï¼Œæœ‰åŠ©äºè¯†åˆ«å½¢å¼åŒ–é”™è¯¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³è‡ªåŠ¨å®šç†è¯æ˜ä¸­å¯¹å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„ä¾èµ–ï¼Œç°æœ‰æ–¹æ³•åœ¨è®­ç»ƒæˆæœ¬å’Œæ•ˆæœä¸Šå­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDSP+é€šè¿‡ç²¾ç»†çš„ç¥ç»ç¬¦å·åè°ƒï¼Œä¼˜åŒ–äº†å®šç†è¯æ˜çš„è‰æ‹Ÿã€è‰å›¾å’Œè¯æ˜ä¸‰ä¸ªé˜¶æ®µï¼Œæ—¨åœ¨æé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDSP+æ¡†æ¶åˆ†ä¸ºä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šè‰æ‹Ÿé˜¶æ®µç”Ÿæˆè‡ªç„¶è¯­è¨€å­ç›®æ ‡ï¼Œè‰å›¾é˜¶æ®µè¿›è¡Œè‡ªåŠ¨å½¢å¼åŒ–ï¼Œè¯æ˜é˜¶æ®µç»“åˆç¬¦å·æœç´¢æ–¹æ³•ä¸æ­¥éª¤è¯æ˜å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šDSP+çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ— è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡ç¥ç»ç¬¦å·å¢å¼ºå®ç°äº†ä¸ç°æœ‰æ–¹æ³•çš„æ˜¾è‘—æ€§èƒ½å¯¹æ¯”ï¼Œç‰¹åˆ«æ˜¯åœ¨è‰å›¾å’Œè¯æ˜é˜¶æ®µçš„é›†æˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è‰æ‹Ÿé˜¶æ®µï¼Œå»é™¤äº†æ€ç»´æ ‡è®°å’Œäººç±»è¯æ˜çš„å¼•ç”¨ï¼›è‰å›¾é˜¶æ®µæ ¹æ®é¢„å®šä¹‰è§„åˆ™å±è”½è¯­æ³•é”™è¯¯ï¼›è¯æ˜é˜¶æ®µç´§å¯†ç»“åˆç¬¦å·æœç´¢æ–¹æ³•å¦‚Aesopä¸æ­¥éª¤è¯æ˜å™¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DSP+åœ¨miniF2Fã€ProofNetå’ŒPutnamBenchä¸‰ä¸ªé—®é¢˜é›†ä¸Šåˆ†åˆ«è§£å†³äº†80.7%ã€32.8%å’Œ24ä¸ªé—®é¢˜ï¼Œä¸”åœ¨ä¸è¿›è¡Œä»»ä½•é¢å¤–æ¨¡å‹è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œè¡¨ç°å‡ºæ¯”ç°æœ‰æŠ€æœ¯æ›´ä½çš„é¢„ç®—éœ€æ±‚ã€‚æ­¤å¤–ï¼ŒDSP+æˆåŠŸè§£å†³äº†ä¸€ä¸ªä»¥å¾€æœªè¢«è§£å†³çš„IMOé—®é¢˜ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DSP+çš„ç ”ç©¶æˆæœåœ¨è‡ªåŠ¨å®šç†è¯æ˜ã€å½¢å¼åŒ–éªŒè¯å’Œäººå·¥æ™ºèƒ½æ¨ç†ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„è¯æ˜ç”Ÿæˆèƒ½åŠ›å¯ä»¥ä¸ºè½¯ä»¶éªŒè¯ã€æ•°å­¦å®šç†è¯æ˜ç­‰æä¾›æ”¯æŒï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advancements, such as DeepSeek-Prover-V2-671B and Kimina-Prover-Preview-72B, demonstrate a prevailing trend in leveraging reinforcement learning (RL)-based large-scale training for automated theorem proving. Surprisingly, we discover that even without any training, careful neuro-symbolic coordination of existing off-the-shelf reasoning models and tactic step provers can achieve comparable performance. This paper introduces \textbf{DSP+}, an improved version of the Draft, Sketch, and Prove framework, featuring a \emph{fine-grained and integrated} neuro-symbolic enhancement for each phase: (1) In the draft phase, we prompt reasoning models to generate concise natural-language subgoals to benefit the sketch phase, removing thinking tokens and references to human-written proofs; (2) In the sketch phase, subgoals are autoformalized with hypotheses to benefit the proving phase, and sketch lines containing syntactic errors are masked according to predefined rules; (3) In the proving phase, we tightly integrate symbolic search methods like Aesop with step provers to establish proofs for the sketch subgoals. Experimental results show that, without any additional model training or fine-tuning, DSP+ solves 80.7\%, 32.8\%, and 24 out of 644 problems from miniF2F, ProofNet, and PutnamBench, respectively, while requiring fewer budgets compared to state-of-the-arts. DSP+ proves \texttt{imo\_2019\_p1}, an IMO problem in miniF2F that is not solved by any prior work. Additionally, DSP+ generates proof patterns comprehensible by human experts, facilitating the identification of formalization errors; For example, eight wrongly formalized statements in miniF2F are discovered. Our results highlight the potential of classical reasoning patterns besides the RL-based training. All components will be open-sourced.

