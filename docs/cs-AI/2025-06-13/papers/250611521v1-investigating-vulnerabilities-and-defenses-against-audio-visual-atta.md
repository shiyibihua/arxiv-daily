---
layout: default
title: Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models
---

# Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11521" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11521v1</a>
  <a href="https://arxiv.org/pdf/2506.11521.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11521v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11521v1', 'Investigating Vulnerabilities and Defenses Against Audio-Visual Attacks: A Comprehensive Survey Emphasizing Multimodal Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jinming Wen, Xinyi Wu, Shuai Zhao, Yanhao Jia, Yuwen Li

**åˆ†ç±»**: cs.CR, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå…¨é¢è°ƒæŸ¥ä»¥åº”å¯¹éŸ³è§†é¢‘æ”»å‡»çš„è„†å¼±æ€§ä¸é˜²å¾¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `éŸ³è§†é¢‘æ”»å‡»` `å¯¹æŠ—æ€§æ”»å‡»` `åé—¨æ”»å‡»` `å®‰å…¨æ€§ç ”ç©¶` `é˜²å¾¡ç­–ç•¥` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éŸ³è§†é¢‘æ”»å‡»è°ƒæŸ¥å¤šé›†ä¸­äºç‰¹å®šæ”»å‡»ç±»å‹ï¼Œç¼ºä¹å¯¹å¤šç§æ”»å‡»çš„ç»Ÿä¸€è¯„ä¼°ï¼Œå¯¼è‡´å¯¹å®‰å…¨é£é™©çš„ç†è§£ä¸è¶³ã€‚
2. æœ¬æ–‡é€šè¿‡å…¨é¢çš„æ–‡çŒ®ç»¼è¿°ï¼Œç³»ç»Ÿæ€§åœ°åˆ†æäº†éŸ³è§†é¢‘æ”»å‡»çš„å¤šç§å½¢å¼ï¼Œæå‡ºäº†å¯¹æŠ—æ€§æ”»å‡»ã€åé—¨æ”»å‡»å’Œè¶Šç‹±æ”»å‡»çš„åˆ†ç±»ä¸åˆ†æã€‚
3. ç ”ç©¶æŒ‡å‡ºï¼Œæœ€æ–°çš„MLLMsåœ¨é¢å¯¹è¿™äº›æ”»å‡»æ—¶å­˜åœ¨æ˜¾è‘—çš„è„†å¼±æ€§ï¼Œä¸ºæœªæ¥çš„é˜²å¾¡ç ”ç©¶æä¾›äº†é‡è¦çš„æ–¹å‘å’ŒæŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨éŸ³è§†é¢‘ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶ä¾èµ–ç¬¬ä¸‰æ–¹æ•°æ®å’Œå¼€æºæ¨¡å‹çš„è¶‹åŠ¿å¸¦æ¥äº†æ˜¾è‘—çš„å®‰å…¨é£é™©ã€‚ç ”ç©¶è¡¨æ˜ï¼Œæœ€æ–°çš„MLLMså¯ä»¥é€šè¿‡å¯¹æŠ—æ€§æ‰°åŠ¨å’Œæ¶æ„æŸ¥è¯¢ç­‰è¾“å…¥è¢«æ“æ§ï¼Œç»•è¿‡æ¨¡å‹å†…éƒ¨çš„å®‰å…¨æœºåˆ¶ã€‚æœ¬æ–‡å¯¹éŸ³è§†é¢‘æ”»å‡»è¿›è¡Œäº†ç³»ç»Ÿçš„ç»¼è¿°ï¼Œæ¶µç›–å¯¹æŠ—æ€§æ”»å‡»ã€åé—¨æ”»å‡»å’Œè¶Šç‹±æ”»å‡»ï¼Œå¹¶æ¢è®¨äº†å½“å‰ç ”ç©¶ä¸­çš„æŒ‘æˆ˜ä¸æœªæ¥è¶‹åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³éŸ³è§†é¢‘å¤šæ¨¡æ€æ¨¡å‹åœ¨é¢å¯¹å„ç§æ”»å‡»æ—¶çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºç‰¹å®šæ”»å‡»ç±»å‹ï¼Œç¼ºä¹å¯¹å¤šç§æ”»å‡»çš„å…¨é¢ç†è§£ä¸è¯„ä¼°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç³»ç»Ÿæ€§ç»¼è¿°éŸ³è§†é¢‘æ”»å‡»çš„ä¸åŒç±»å‹ï¼Œæœ¬æ–‡æä¾›äº†å¯¹å½“å‰ç ”ç©¶ç°çŠ¶çš„å…¨é¢æ´å¯Ÿï¼Œå¼ºè°ƒäº†å¤šæ¨¡æ€æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåˆ†ç±»éŸ³è§†é¢‘æ”»å‡»ï¼ŒåŒ…æ‹¬å¯¹æŠ—æ€§æ”»å‡»ã€åé—¨æ”»å‡»å’Œè¶Šç‹±æ”»å‡»ï¼Œç„¶ååˆ†æè¿™äº›æ”»å‡»å¯¹MLLMsçš„å½±å“ï¼Œæœ€åæå‡ºæœªæ¥ç ”ç©¶çš„æ–¹å‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºé¦–æ¬¡å¯¹éŸ³è§†é¢‘æ”»å‡»è¿›è¡Œå…¨é¢çš„åˆ†ç±»ä¸ç»¼è¿°ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­å¯¹å¤šç§æ”»å‡»ç¼ºä¹ç»Ÿä¸€è¯„ä¼°çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åˆ†æè¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡å…³æ³¨äº†ä¸åŒæ”»å‡»çš„ç‰¹å¾ã€å½±å“åŠå…¶å¯¹æ¨¡å‹å®‰å…¨æ€§çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†æœªæ¥ç ”ç©¶ä¸­éœ€è¦å…³æ³¨çš„å…³é”®é—®é¢˜ä¸é˜²å¾¡ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ€æ–°çš„MLLMsåœ¨é¢å¯¹å¯¹æŠ—æ€§å’Œåé—¨æ”»å‡»æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„è„†å¼±æ€§ï¼Œæ”»å‡»æˆåŠŸç‡é«˜è¾¾70%ä»¥ä¸Šã€‚é€šè¿‡å¯¹æ¯”ä¸åŒæ”»å‡»ç±»å‹ï¼Œæœ¬æ–‡æ­ç¤ºäº†æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„å…³é”®ç¼ºé™·ï¼Œä¸ºåç»­é˜²å¾¡ç ”ç©¶æä¾›äº†é‡è¦ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬éŸ³è§†é¢‘å†…å®¹ç”Ÿæˆã€æ™ºèƒ½ç›‘æ§å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢æ¶æ„æ”»å‡»ï¼Œä¿éšœç”¨æˆ·æ•°æ®å®‰å…¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¥åº·å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models (MLLMs), which bridge the gap between audio-visual and natural language processing, achieve state-of-the-art performance on several audio-visual tasks. Despite the superior performance of MLLMs, the scarcity of high-quality audio-visual training data and computational resources necessitates the utilization of third-party data and open-source MLLMs, a trend that is increasingly observed in contemporary research. This prosperity masks significant security risks. Empirical studies demonstrate that the latest MLLMs can be manipulated to produce malicious or harmful content. This manipulation is facilitated exclusively through instructions or inputs, including adversarial perturbations and malevolent queries, effectively bypassing the internal security mechanisms embedded within the models. To gain a deeper comprehension of the inherent security vulnerabilities associated with audio-visual-based multimodal models, a series of surveys investigates various types of attacks, including adversarial and backdoor attacks. While existing surveys on audio-visual attacks provide a comprehensive overview, they are limited to specific types of attacks, which lack a unified review of various types of attacks. To address this issue and gain insights into the latest trends in the field, this paper presents a comprehensive and systematic review of audio-visual attacks, which include adversarial attacks, backdoor attacks, and jailbreak attacks. Furthermore, this paper also reviews various types of attacks in the latest audio-visual-based MLLMs, a dimension notably absent in existing surveys. Drawing upon comprehensive insights from a substantial review, this paper delineates both challenges and emergent trends for future research on audio-visual attacks and defense.

