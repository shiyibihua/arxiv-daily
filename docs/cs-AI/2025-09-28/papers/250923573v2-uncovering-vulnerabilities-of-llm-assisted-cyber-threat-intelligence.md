---
layout: default
title: Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence
---

# Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23573" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23573v2</a>
  <a href="https://arxiv.org/pdf/2509.23573.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23573v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23573v2', 'Uncovering Vulnerabilities of LLM-Assisted Cyber Threat Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuqiao Meng, Luoxi Tang, Feiyang Yu, Jinyuan Jia, Guanhua Yan, Ping Yang, Zhaohan Xi

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-28 (æ›´æ–°: 2025-10-01)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºLLMè¾…åŠ©ç½‘ç»œå¨èƒæƒ…æŠ¥çš„è„†å¼±æ€§ï¼Œæå‡ºé’ˆå¯¹æ€§åˆ†ææ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç½‘ç»œå¨èƒæƒ…æŠ¥` `è„†å¼±æ€§åˆ†æ` `é”™è¯¯åˆ†ç±»` `äººæœºåä½œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨ç½‘ç»œå¨èƒæƒ…æŠ¥ä»»åŠ¡ä¸­å­˜åœ¨æ€§èƒ½å·®è·ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚å¤šå˜çš„ç½‘ç»œå¨èƒç¯å¢ƒã€‚
2. æå‡ºä¸€ç§æ–°é¢–çš„åˆ†ç±»æ–¹æ³•ï¼Œç»“åˆåˆ†å±‚ã€è‡ªå›å½’ç»†åŒ–å’Œäººæœºåä½œï¼Œå¯é åˆ†æLLMçš„å¤±è´¥æ¡ˆä¾‹ã€‚
3. å®éªŒæ­ç¤ºäº†LLMåœ¨CTIä¸­å­˜åœ¨çš„è™šå‡ç›¸å…³æ€§ã€çŸ›ç›¾çŸ¥è¯†å’Œå—é™æ³›åŒ–ä¸‰ç§åŸºæœ¬è„†å¼±æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¢«å¹¿æ³›åº”ç”¨äºè¾…åŠ©å®‰å…¨åˆ†æå¸ˆåº”å¯¹å¿«é€Ÿæ¼”å˜çš„ç½‘ç»œå¨èƒï¼Œä¸ºæ¼æ´è¯„ä¼°å’Œäº‹ä»¶å“åº”æä¾›ç½‘ç»œå¨èƒæƒ…æŠ¥ï¼ˆCTIï¼‰ã€‚å°½ç®¡ç°æœ‰ç ”ç©¶è¡¨æ˜LLMå¯ä»¥æ”¯æŒå¤šç§CTIä»»åŠ¡ï¼Œå¦‚å¨èƒåˆ†æã€æ¼æ´æ£€æµ‹å’Œå…¥ä¾µé˜²å¾¡ï¼Œä½†åœ¨å®é™…éƒ¨ç½²ä¸­ä»ç„¶å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·ã€‚æœ¬æ–‡ç ”ç©¶äº†LLMåœ¨CTIä¸­çš„å†…åœ¨è„†å¼±æ€§ï¼Œé‡ç‚¹å…³æ³¨å¨èƒç¯å¢ƒæœ¬èº«è€Œéæ¨¡å‹æ¶æ„æ‰€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹å¤šä¸ªCTIåŸºå‡†å’ŒçœŸå®å¨èƒæŠ¥å‘Šçš„å¤§è§„æ¨¡è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åˆ†ç±»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é›†æˆäº†åˆ†å±‚ã€è‡ªå›å½’ç»†åŒ–å’Œäººæœºåä½œç›‘ç£ï¼Œä»¥å¯é åœ°åˆ†æå¤±è´¥æ¡ˆä¾‹ã€‚é€šè¿‡å¹¿æ³›çš„å®éªŒå’Œäººå·¥æ£€æŸ¥ï¼Œæˆ‘ä»¬æ­ç¤ºäº†ä¸‰ç§åŸºæœ¬è„†å¼±æ€§ï¼šè™šå‡ç›¸å…³æ€§ã€çŸ›ç›¾çŸ¥è¯†å’Œå—é™æ³›åŒ–ï¼Œè¿™äº›å› ç´ é™åˆ¶äº†LLMæœ‰æ•ˆæ”¯æŒCTIçš„èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬ä¸ºè®¾è®¡æ›´å¼ºå¤§çš„LLMé©±åŠ¨çš„CTIç³»ç»Ÿæä¾›äº†å¯æ“ä½œçš„è§è§£ï¼Œä»¥ä¿ƒè¿›æœªæ¥çš„ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³LLMåœ¨ç½‘ç»œå¨èƒæƒ…æŠ¥ï¼ˆCTIï¼‰åº”ç”¨ä¸­å­˜åœ¨çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘å¨èƒç¯å¢ƒæœ¬èº«çš„å¤æ‚æ€§å’ŒåŠ¨æ€æ€§ï¼Œå¯¼è‡´LLMåœ¨å®é™…éƒ¨ç½²ä¸­æ€§èƒ½ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆæ”¯æŒå®‰å…¨åˆ†æå¸ˆè¿›è¡Œæ¼æ´è¯„ä¼°å’Œäº‹ä»¶å“åº”ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¤§è§„æ¨¡è¯„ä¼°å’Œç»†è‡´çš„é”™è¯¯åˆ†æï¼Œæ­ç¤ºLLMåœ¨CTIä»»åŠ¡ä¸­å­˜åœ¨çš„å†…åœ¨ç¼ºé™·ã€‚é€šè¿‡æ„å»ºåŒ…å«åˆ†å±‚ã€è‡ªå›å½’ç»†åŒ–å’Œäººæœºåä½œçš„åˆ†ç±»æ–¹æ³•ï¼Œå¯¹LLMçš„å¤±è´¥æ¡ˆä¾‹è¿›è¡Œæ·±å…¥åˆ†æï¼Œä»è€Œè¯†åˆ«å‡ºé™åˆ¶LLMæ€§èƒ½çš„å…³é”®å› ç´ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®æ”¶é›†ï¼šæ„å»ºå¤§è§„æ¨¡çš„CTIæ•°æ®é›†ï¼ŒåŒ…æ‹¬å¤šä¸ªCTIåŸºå‡†å’ŒçœŸå®å¨èƒæŠ¥å‘Šã€‚2) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨LLMåœ¨CTIæ•°æ®é›†ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œè®°å½•æ€§èƒ½æŒ‡æ ‡å’Œå¤±è´¥æ¡ˆä¾‹ã€‚3) é”™è¯¯åˆ†ç±»ï¼šåº”ç”¨æå‡ºçš„åˆ†ç±»æ–¹æ³•ï¼Œå¯¹å¤±è´¥æ¡ˆä¾‹è¿›è¡Œåˆ†å±‚ã€è‡ªå›å½’ç»†åŒ–å’Œäººæœºåä½œåˆ†æï¼Œè¯†åˆ«å‡ºLLMçš„è„†å¼±æ€§ã€‚4) è„†å¼±æ€§åˆ†æï¼šå¯¹è¯†åˆ«å‡ºçš„è„†å¼±æ€§è¿›è¡Œæ·±å…¥åˆ†æï¼Œæ¢è®¨å…¶äº§ç”Ÿçš„åŸå› å’Œå½±å“ã€‚5) æ”¹è¿›å»ºè®®ï¼šåŸºäºè„†å¼±æ€§åˆ†æçš„ç»“æœï¼Œæå‡ºæ”¹è¿›LLMé©±åŠ¨çš„CTIç³»ç»Ÿçš„å»ºè®®ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°é¢–çš„åˆ†ç±»æ–¹æ³•ï¼Œç”¨äºåˆ†æLLMåœ¨CTIä»»åŠ¡ä¸­çš„å¤±è´¥æ¡ˆä¾‹ã€‚è¯¥æ–¹æ³•é›†æˆäº†åˆ†å±‚ã€è‡ªå›å½’ç»†åŒ–å’Œäººæœºåä½œï¼Œèƒ½å¤Ÿæ›´å…¨é¢ã€æ›´å‡†ç¡®åœ°è¯†åˆ«å‡ºLLMçš„è„†å¼±æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ æ³¨é‡å¯¹é”™è¯¯åŸå› çš„æ·±å…¥åˆ†æï¼Œè€Œéä»…ä»…å…³æ³¨æ•´ä½“æ€§èƒ½æŒ‡æ ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) åˆ†å±‚åˆ†ç±»ï¼šå°†é”™è¯¯æ¡ˆä¾‹æŒ‰ç…§ä¸åŒçš„ç»´åº¦è¿›è¡Œåˆ†å±‚ï¼Œä¾‹å¦‚æŒ‰ç…§å¨èƒç±»å‹ã€æ¼æ´ç±»å‹ç­‰è¿›è¡Œåˆ†ç±»ã€‚2) è‡ªå›å½’ç»†åŒ–ï¼šä½¿ç”¨LLMå¯¹é”™è¯¯æ¡ˆä¾‹è¿›è¡Œè‡ªå›å½’åˆ†æï¼Œé€æ­¥ç»†åŒ–é”™è¯¯åŸå› ã€‚3) äººæœºåä½œï¼šå¼•å…¥äººå·¥ä¸“å®¶å¯¹LLMçš„åˆ†æç»“æœè¿›è¡Œå®¡æ ¸å’Œä¿®æ­£ï¼Œæé«˜åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®¾è®¡äº†é’ˆå¯¹ä¸åŒè„†å¼±æ€§çš„è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ä½¿ç”¨ä¸€è‡´æ€§æŒ‡æ ‡è¯„ä¼°LLMçš„çŸ›ç›¾çŸ¥è¯†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å¤§è§„æ¨¡å®éªŒæ­ç¤ºäº†LLMåœ¨CTIä¸­å­˜åœ¨çš„è™šå‡ç›¸å…³æ€§ã€çŸ›ç›¾çŸ¥è¯†å’Œå—é™æ³›åŒ–ä¸‰ç§åŸºæœ¬è„†å¼±æ€§ã€‚ä¾‹å¦‚ï¼Œå®éªŒå‘ç°LLMåœ¨å¤„ç†åŒ…å«è™šå‡ç›¸å…³æ€§çš„å¨èƒæŠ¥å‘Šæ—¶ï¼Œå®¹æ˜“äº§ç”Ÿé”™è¯¯çš„åˆ¤æ–­ã€‚æ­¤å¤–ï¼ŒLLMåœ¨å¤„ç†æ¶‰åŠå¤šä¸ªçŸ¥è¯†é¢†åŸŸçš„å¨èƒæƒ…æŠ¥æ—¶ï¼Œå®¹æ˜“å‡ºç°çŸ¥è¯†å†²çªï¼Œå¯¼è‡´æ¨ç†é”™è¯¯ã€‚è¿™äº›å‘ç°ä¸ºæ”¹è¿›LLMåœ¨CTIä¸­çš„åº”ç”¨æä¾›äº†é‡è¦çš„ä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæå‡LLMåœ¨ç½‘ç»œå®‰å…¨é¢†åŸŸçš„åº”ç”¨æ•ˆæœï¼Œä¾‹å¦‚æ”¹è¿›å¨èƒæƒ…æŠ¥åˆ†æã€æ¼æ´æ£€æµ‹å’Œå…¥ä¾µé˜²å¾¡ç³»ç»Ÿã€‚é€šè¿‡è§£å†³LLMåœ¨CTIä¸­å­˜åœ¨çš„è„†å¼±æ€§ï¼Œå¯ä»¥æé«˜å®‰å…¨åˆ†æå¸ˆçš„å·¥ä½œæ•ˆç‡ï¼Œé™ä½ç½‘ç»œå®‰å…¨é£é™©ï¼Œå¹¶ä¸ºæœªæ¥çš„LLMé©±åŠ¨çš„CTIç³»ç»Ÿè®¾è®¡æä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) are intensively used to assist security analysts in counteracting the rapid exploitation of cyber threats, wherein LLMs offer cyber threat intelligence (CTI) to support vulnerability assessment and incident response. While recent work has shown that LLMs can support a wide range of CTI tasks such as threat analysis, vulnerability detection, and intrusion defense, significant performance gaps persist in practical deployments. In this paper, we investigate the intrinsic vulnerabilities of LLMs in CTI, focusing on challenges that arise from the nature of the threat landscape itself rather than the model architecture. Using large-scale evaluations across multiple CTI benchmarks and real-world threat reports, we introduce a novel categorization methodology that integrates stratification, autoregressive refinement, and human-in-the-loop supervision to reliably analyze failure instances. Through extensive experiments and human inspections, we reveal three fundamental vulnerabilities: spurious correlations, contradictory knowledge, and constrained generalization, that limit LLMs in effectively supporting CTI. Subsequently, we provide actionable insights for designing more robust LLM-powered CTI systems to facilitate future research.

