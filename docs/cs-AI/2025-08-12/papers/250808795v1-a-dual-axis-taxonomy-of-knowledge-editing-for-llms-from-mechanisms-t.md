---
layout: default
title: A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions
---

# A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08795" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08795v1</a>
  <a href="https://arxiv.org/pdf/2508.08795.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08795v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08795v1', 'A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amir Mohammad Salehoof, Ali Ramezani, Yadollah Yaghoobzadeh, Majid Nili Ahmadabadi

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: 13 pages, 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒè½´åˆ†ç±»æ³•ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†ç¼–è¾‘**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†ç¼–è¾‘` `å¤§è¯­è¨€æ¨¡å‹` `åŠŸèƒ½åˆ†ç±»` `æœºåˆ¶åˆ†æ` `æ¨¡å‹æ›´æ–°` `è¯„ä¼°ä»»åŠ¡` `æ•°æ®é›†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•å¤šé›†ä¸­äºæœºåˆ¶ï¼Œå¿½è§†äº†çŸ¥è¯†åŠŸèƒ½çš„å¤šæ ·æ€§ï¼Œå¯¼è‡´ç¼–è¾‘æ•ˆæœä¸ç†æƒ³ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠŸèƒ½çš„åŒè½´åˆ†ç±»æ³•ï¼Œæ—¨åœ¨å…¨é¢è¯„ä¼°çŸ¥è¯†ç¼–è¾‘çš„æœ‰æ•ˆæ€§ä¸é€‚ç”¨æ€§ã€‚
3. é€šè¿‡å¯¹ä¸åŒçŸ¥è¯†ç±»å‹çš„ç¼–è¾‘æ•ˆæœè¿›è¡Œåˆ†æï¼Œæ˜ç¡®äº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹åŠæœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»å¤§é‡æ–‡æœ¬è¯­æ–™ä¸­è·å–çŸ¥è¯†ï¼Œä½†è¿™äº›ä¿¡æ¯å¯èƒ½ä¼šè¿‡æ—¶æˆ–ä¸å‡†ç¡®ã€‚ç”±äºé‡æ–°è®­ç»ƒè®¡ç®—æˆæœ¬é«˜ï¼ŒçŸ¥è¯†ç¼–è¾‘æä¾›äº†ä¸€ç§é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆâ€”â€”åœ¨ä¸è¿›è¡Œå…¨é¢é‡æ–°è®­ç»ƒçš„æƒ…å†µä¸‹ä¿®æ”¹å†…éƒ¨çŸ¥è¯†ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨ç¼–è¾‘æœºåˆ¶ï¼Œå¾€å¾€å¿½è§†äº†è¢«ç¼–è¾‘çŸ¥è¯†çš„åŠŸèƒ½ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„ã€äº’è¡¥çš„åŸºäºåŠŸèƒ½çš„åˆ†ç±»æ³•ï¼Œä»¥æä¾›æ›´å…¨é¢çš„è§†è§’ã€‚æˆ‘ä»¬è€ƒå¯Ÿäº†ä¸åŒæœºåˆ¶å¦‚ä½•åº”ç”¨äºå„ç§çŸ¥è¯†ç±»å‹ï¼Œå¼ºè°ƒç¼–è¾‘æ•ˆæœä¾èµ–äºç›®æ ‡çŸ¥è¯†çš„æ€§è´¨ã€‚é€šè¿‡æ²¿è¿™ä¸¤ä¸ªè½´ç»„ç»‡æˆ‘ä»¬çš„ç»¼è¿°ï¼Œæˆ‘ä»¬æç»˜äº†å½“å‰çš„ç ”ç©¶ç°çŠ¶ï¼Œæ¦‚è¿°äº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œæ­£å¼å®šä¹‰äº†é—®é¢˜ï¼Œè°ƒæŸ¥äº†è¯„ä¼°ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œå¹¶æ€»ç»“äº†å¼€æ”¾æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çŸ¥è¯†ç¼–è¾‘ä¸­å­˜åœ¨çš„æ•ˆç‡ä½ä¸‹å’Œæ•ˆæœä¸ç†æƒ³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åªå…³æ³¨å‚æ•°è°ƒæ•´æˆ–å¤–éƒ¨è®°å¿†ï¼Œæœªèƒ½å……åˆ†è€ƒè™‘çŸ¥è¯†çš„åŠŸèƒ½æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŒè½´åˆ†ç±»æ³•ï¼Œç»“åˆçŸ¥è¯†ç¼–è¾‘çš„æœºåˆ¶ä¸åŠŸèƒ½ï¼Œæä¾›æ›´å…¨é¢çš„è§†è§’ï¼Œä»¥ä¾¿æ›´æœ‰æ•ˆåœ°æ›´æ–°æ¨¡å‹çŸ¥è¯†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ç»´åº¦ï¼šä¸€æ˜¯çŸ¥è¯†ç¼–è¾‘çš„æœºåˆ¶ï¼ˆå¦‚å‚æ•°å˜åŒ–ä¸å¤–éƒ¨è®°å¿†ï¼‰ï¼ŒäºŒæ˜¯çŸ¥è¯†çš„åŠŸèƒ½ç±»å‹ï¼ˆå¦‚äº‹å®æ€§ã€æ—¶é—´æ€§ã€æ¦‚å¿µæ€§ç­‰ï¼‰ã€‚é€šè¿‡è¿™ä¸¤ä¸ªç»´åº¦çš„äº¤å‰åˆ†æï¼Œå½¢æˆäº†ä¸€ä¸ªç³»ç»Ÿçš„çŸ¥è¯†ç¼–è¾‘æ¡†æ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†åŠŸèƒ½æ€§åˆ†ç±»ï¼Œä½¿å¾—çŸ¥è¯†ç¼–è¾‘ä¸ä»…å…³æ³¨å¦‚ä½•ç¼–è¾‘ï¼Œè¿˜è€ƒè™‘äº†ç¼–è¾‘çš„ç›®æ ‡å’Œæ•ˆæœï¼Œä»è€Œæå‡äº†ç¼–è¾‘çš„é’ˆå¯¹æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡è¿‡ç¨‹ä¸­ï¼Œé‡ç‚¹è€ƒè™‘äº†ä¸åŒçŸ¥è¯†ç±»å‹çš„ç‰¹æ€§ï¼Œåˆ¶å®šäº†ç›¸åº”çš„è¯„ä¼°ä»»åŠ¡å’Œæ•°æ®é›†ï¼Œä»¥ä¾¿æ›´å¥½åœ°éªŒè¯ç¼–è¾‘æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºåŠŸèƒ½çš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•åœ¨å¤šç§çŸ¥è¯†ç±»å‹ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—çš„æå‡ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œç¼–è¾‘æ•ˆæœæé«˜äº†20%-30%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†åŠŸèƒ½æ€§åˆ†ç±»æ³•åœ¨çŸ¥è¯†ç¼–è¾‘ä¸­çš„æœ‰æ•ˆæ€§å’Œå¿…è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€çŸ¥è¯†ç®¡ç†ç³»ç»Ÿå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡ä¼˜åŒ–çŸ¥è¯†ç¼–è¾‘è¿‡ç¨‹ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„å®æ—¶æ›´æ–°èƒ½åŠ›ï¼Œç¡®ä¿å…¶æä¾›çš„ä¿¡æ¯å‡†ç¡®ä¸”åŠæ—¶ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œå†³ç­–æ”¯æŒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) acquire vast knowledge from large text corpora, but this information can become outdated or inaccurate. Since retraining is computationally expensive, knowledge editing offers an efficient alternative -- modifying internal knowledge without full retraining. These methods aim to update facts precisely while preserving the model's overall capabilities. While existing surveys focus on the mechanism of editing (e.g., parameter changes vs. external memory), they often overlook the function of the knowledge being edited. This survey introduces a novel, complementary function-based taxonomy to provide a more holistic view. We examine how different mechanisms apply to various knowledge types -- factual, temporal, conceptual, commonsense, and social -- highlighting how editing effectiveness depends on the nature of the target knowledge. By organizing our review along these two axes, we map the current landscape, outline the strengths and limitations of existing methods, define the problem formally, survey evaluation tasks and datasets, and conclude with open challenges and future directions.

