---
layout: default
title: Attacks and Defenses Against LLM Fingerprinting
---

# Attacks and Defenses Against LLM Fingerprinting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09021" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09021v1</a>
  <a href="https://arxiv.org/pdf/2508.09021.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09021v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09021v1', 'Attacks and Defenses Against LLM Fingerprinting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kevin Kurian, Ethan Holland, Sean Oesch

**åˆ†ç±»**: cs.CR, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„LLMæŒ‡çº¹æ”»å‡»ä¸é˜²å¾¡æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒ‡çº¹æ”»å‡»` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `éšç§ä¿æŠ¤` `è¾“å‡ºè¿‡æ»¤` `è¯­ä¹‰å®Œæ•´æ€§` `é˜²å¾¡ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„æŒ‡çº¹æ”»å‡»æ–¹æ³•åœ¨éšç§ä¿æŠ¤æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå®¹æ˜“è¢«è¯†åˆ«å’Œè¿½è¸ªã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºçš„æ”»å‡»æ–¹æ³•é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æŸ¥è¯¢é€‰æ‹©ï¼Œé˜²å¾¡æ–¹æ³•åˆ™åˆ©ç”¨æ¬¡çº§LLMè¿›è¡Œè¾“å‡ºè¿‡æ»¤ä»¥ä¿æŠ¤æ¨¡å‹èº«ä»½ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–åçš„æ”»å‡»æ–¹æ³•åœ¨ä»…ä½¿ç”¨3ä¸ªæŸ¥è¯¢çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æé«˜äº†æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•æ„Ÿç¯å¢ƒä¸­çš„å¹¿æ³›åº”ç”¨ï¼ŒæŒ‡çº¹æ”»å‡»å¸¦æ¥äº†æ˜¾è‘—çš„éšç§å’Œå®‰å…¨é£é™©ã€‚æœ¬æ–‡ä»æ”»å‡»å’Œé˜²å¾¡ä¸¤ä¸ªè§’åº¦ç ”ç©¶äº†LLMæŒ‡çº¹è¯†åˆ«ã€‚æ”»å‡»æ–¹æ³•åˆ©ç”¨å¼ºåŒ–å­¦ä¹ è‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢é€‰æ‹©ï¼Œä»…éœ€3ä¸ªæŸ¥è¯¢å³å¯å®ç°æ›´é«˜çš„æŒ‡çº¹è¯†åˆ«å‡†ç¡®ç‡ã€‚é˜²å¾¡æ–¹æ³•åˆ™é€šè¿‡æ¬¡çº§LLMè¿›è¡Œè¯­ä¹‰ä¿æŒçš„è¾“å‡ºè¿‡æ»¤ï¼Œæ¨¡ç³Šæ¨¡å‹èº«ä»½ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰å®Œæ•´æ€§ã€‚è¯¥é˜²å¾¡æ–¹æ³•åœ¨æµ‹è¯•æ¨¡å‹ä¸­é™ä½äº†æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒäº†è¾“å‡ºè´¨é‡ã€‚è¿™äº›è´¡çŒ®å±•ç¤ºäº†æå‡æŒ‡çº¹è¯†åˆ«å·¥å…·èƒ½åŠ›çš„æ½œåŠ›ï¼Œå¹¶æä¾›äº†é’ˆå¯¹æŒ‡çº¹æ”»å‡»çš„å®é™…ç¼“è§£ç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•æ„Ÿç¯å¢ƒä¸­é¢ä¸´çš„æŒ‡çº¹æ”»å‡»é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨éšç§ä¿æŠ¤æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå®¹æ˜“è¢«æ”»å‡»è€…è¯†åˆ«å’Œåˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ”»å‡»æ–¹æ³•åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œè‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢é€‰æ‹©ï¼Œä»è€Œæé«˜æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚é˜²å¾¡æ–¹æ³•åˆ™é€šè¿‡æ¬¡çº§LLMå¯¹è¾“å‡ºè¿›è¡Œè¿‡æ»¤ï¼Œæ¨¡ç³Šæ¨¡å‹èº«ä»½ï¼ŒåŒæ—¶ä¿æŒè¯­ä¹‰çš„å®Œæ•´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæ”»å‡»æ¨¡å—å’Œé˜²å¾¡æ¨¡å—ã€‚æ”»å‡»æ¨¡å—é€šè¿‡å¼ºåŒ–å­¦ä¹ é€‰æ‹©æœ€ä¼˜æŸ¥è¯¢ï¼Œé˜²å¾¡æ¨¡å—åˆ™ä½¿ç”¨æ¬¡çº§LLMè¿›è¡Œè¾“å‡ºè¿‡æ»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºä½¿ç”¨å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æŸ¥è¯¢é€‰æ‹©ï¼Œç›¸è¾ƒäºéšæœºé€‰æ‹©æŸ¥è¯¢ï¼Œæ˜¾è‘—æé«˜äº†æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚é˜²å¾¡æ–¹æ³•çš„åˆ›æ–°åœ¨äºé€šè¿‡è¯­ä¹‰ä¿æŒçš„è¾“å‡ºè¿‡æ»¤ï¼Œæœ‰æ•ˆé™ä½äº†æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ”»å‡»æ¨¡å—ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å‡½æ•°è®¾è®¡ä¸ºåŸºäºæŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®æ€§ï¼›åœ¨é˜²å¾¡æ¨¡å—ä¸­ï¼Œæ¬¡çº§LLMçš„è®­ç»ƒç›®æ ‡æ˜¯ä¿æŒè¾“å‡ºçš„è¯­ä¹‰å®Œæ•´æ€§ï¼ŒåŒæ—¶æ¨¡ç³Šæ¨¡å‹èº«ä»½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–åçš„æ”»å‡»æ–¹æ³•åœ¨ä»…ä½¿ç”¨3ä¸ªæŸ¥è¯¢çš„æƒ…å†µä¸‹ï¼ŒæŒ‡çº¹è¯†åˆ«å‡†ç¡®ç‡æ˜¾è‘—æé«˜ï¼Œç›¸è¾ƒäºéšæœºé€‰æ‹©çš„æŸ¥è¯¢ï¼Œå‡†ç¡®æ€§æå‡äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ã€‚é˜²å¾¡æ–¹æ³•æœ‰æ•ˆé™ä½äº†å¤šç§æ¨¡å‹çš„æŒ‡çº¹è¯†åˆ«å‡†ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒäº†è¾“å‡ºè´¨é‡ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„å®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä¿æŠ¤å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é‡‘èã€åŒ»ç–—ç­‰æ•æ„Ÿè¡Œä¸šä¸­çš„éšç§å®‰å…¨ã€‚é€šè¿‡æœ‰æ•ˆçš„æŒ‡çº¹æ”»å‡»é˜²å¾¡ç­–ç•¥ï¼Œå¯ä»¥é™ä½æ¨¡å‹è¢«æ»¥ç”¨çš„é£é™©ï¼Œæå‡ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models are increasingly deployed in sensitive environments, fingerprinting attacks pose significant privacy and security risks. We present a study of LLM fingerprinting from both offensive and defensive perspectives. Our attack methodology uses reinforcement learning to automatically optimize query selection, achieving better fingerprinting accuracy with only 3 queries compared to randomly selecting 3 queries from the same pool. Our defensive approach employs semantic-preserving output filtering through a secondary LLM to obfuscate model identity while maintaining semantic integrity. The defensive method reduces fingerprinting accuracy across tested models while preserving output quality. These contributions show the potential to improve fingerprinting tools capabilities while providing practical mitigation strategies against fingerprinting attacks.

