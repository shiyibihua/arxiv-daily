---
layout: default
title: Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning
---

# Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10057" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10057v1</a>
  <a href="https://arxiv.org/pdf/2508.10057.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10057v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10057v1', 'Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Christopher Pinier, Sonia AcuÃ±a Vargas, Mariia Steeghs-Turchina, Dora Matzke, Claire E. Stevenson, Michael D. Nunez

**åˆ†ç±»**: q-bio.NC, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: Presented at the 8th Annual Conference on Cognitive Computational Neuroscience (August 12-15, 2025; Amsterdam, The Netherlands); 20 pages, 11 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ä¸äººç±»æŠ½è±¡æ¨ç†çš„ç¥ç»è®¤çŸ¥å¯¹é½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æŠ½è±¡æ¨ç†` `ç¥ç»è®¤çŸ¥` `è„‘ç”µå›¾` `è¡¨å¾å­¦ä¹ ` `äººå·¥æ™ºèƒ½` `äººæœºå¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­ï¼ŒLLMsçš„è¡¨ç°ä¸äººç±»ç¥ç»è®¤çŸ¥ä¹‹é—´çš„å…³ç³»å°šä¸æ˜ç¡®ï¼Œç¼ºä¹ç³»ç»Ÿæ€§æ¯”è¾ƒã€‚
2. æœ¬ç ”ç©¶é€šè¿‡æ¯”è¾ƒäººç±»ä¸LLMsåœ¨æŠ½è±¡æ¨¡å¼å®Œæˆä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ¢è®¨å…¶ç¥ç»è¡¨å¾çš„ç›¸ä¼¼æ€§ï¼Œæ­ç¤ºæ½œåœ¨çš„å¯¹é½æœºåˆ¶ã€‚
3. ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåªæœ‰æœ€å¤§çš„LLMsåœ¨å‡†ç¡®æ€§ä¸Šä¸äººç±»ç›¸å½“ï¼Œå¹¶ä¸”åœ¨ç¥ç»è¡¨å¾ä¸Šæ˜¾ç¤ºå‡ºä¸äººç±»çš„ç›¸ä¼¼æ€§ï¼Œæä¾›äº†æ–°çš„ç†è§£è§†è§’ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¯å¦åæ˜ äººç±»ç¥ç»è®¤çŸ¥ã€‚æˆ‘ä»¬æ¯”è¾ƒäº†äººç±»å‚ä¸è€…ä¸å…«ä¸ªå¼€æºLLMsåœ¨æŠ½è±¡æ¨¡å¼å®Œæˆä»»åŠ¡ä¸­çš„è¡¨ç°å’Œç¥ç»è¡¨å¾ã€‚ç ”ç©¶å‘ç°ï¼Œåªæœ‰æœ€å¤§çš„LLMsï¼ˆçº¦700äº¿å‚æ•°ï¼‰è¾¾åˆ°äº†ä¸äººç±»ç›¸å½“çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¸”åœ¨æ¨¡å¼ç‰¹å®šçš„éš¾åº¦ç‰¹å¾ä¸Šæ˜¾ç¤ºå‡ºä¸äººç±»çš„ç›¸ä¼¼æ€§ã€‚æ‰€æœ‰æµ‹è¯•çš„LLMsåœ¨å…¶ä¸­é—´å±‚ä¸­å½¢æˆäº†æ˜æ˜¾èšç±»çš„æŠ½è±¡æ¨¡å¼ç±»åˆ«ï¼Œä¸”è¿™ç§èšç±»çš„å¼ºåº¦ä¸ä»»åŠ¡è¡¨ç°ç›¸å…³ã€‚ä»»åŠ¡æœ€ä¼˜LLMå±‚çš„è¡¨å¾å‡ ä½•ä¸äººç±»å‰é¢è„‘ç”µä½ï¼ˆFRPsï¼‰ä¹‹é—´å­˜åœ¨ä¸­ç­‰æ­£ç›¸å…³ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒLLMså¯èƒ½åœ¨æŠ½è±¡æ¨ç†ä¸­åæ˜ äººç±»å¤§è„‘æœºåˆ¶ï¼Œæä¾›äº†ç”Ÿç‰©æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½ä¹‹é—´å…±äº«åŸåˆ™çš„åˆæ­¥è¯æ®ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­ä¸äººç±»ç¥ç»è®¤çŸ¥çš„å¯¹é½é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½ç³»ç»Ÿæ¯”è¾ƒLLMsä¸äººç±»åœ¨æ­¤ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°åŠå…¶ç¥ç»æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ¯”è¾ƒäººç±»å‚ä¸è€…ä¸å¤šä¸ªLLMsåœ¨æŠ½è±¡æ¨¡å¼å®Œæˆä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œåˆ†æå…¶ç¥ç»è¡¨å¾çš„ç›¸ä¼¼æ€§ï¼Œæ¢ç´¢LLMsæ˜¯å¦èƒ½å¤Ÿåæ˜ äººç±»çš„æŠ½è±¡æ¨ç†æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ç”µç”Ÿç†å­¦æŠ€æœ¯ï¼ˆEEGï¼‰è®°å½•äººç±»çš„è„‘ç”µä½ï¼Œå¹¶ä¸LLMsçš„ä¸­é—´å±‚è¡¨å¾è¿›è¡Œæ¯”è¾ƒã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬ä»»åŠ¡è®¾è®¡ã€æ•°æ®æ”¶é›†ã€ç¥ç»è¡¨å¾åˆ†æå’Œç»“æœå¯¹æ¯”ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¯”è¾ƒäº†LLMsä¸äººç±»åœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°åŠå…¶ç¥ç»è¡¨å¾ï¼Œæ­ç¤ºäº†ä¸¤è€…ä¹‹é—´çš„æ½œåœ¨å¯¹é½å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ä¸åŒç±»å‹çš„æŠ½è±¡æ¨¡å¼ä»»åŠ¡ï¼Œè®°å½•äº†å‚ä¸è€…çš„è„‘ç”µä½ï¼Œå¹¶åˆ†æäº†LLMsä¸­é—´å±‚çš„èšç±»ç‰¹å¾ã€‚å‚æ•°è®¾ç½®åŒ…æ‹¬LLMsçš„è§„æ¨¡ï¼ˆå¦‚700äº¿å‚æ•°ï¼‰å’Œä»»åŠ¡éš¾åº¦çš„è®¾è®¡ï¼Œä»¥ç¡®ä¿ç»“æœçš„å¯é æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåªæœ‰çº¦700äº¿å‚æ•°çš„LLMsï¼ˆå¦‚Qwen-2.5-72Bå’ŒDeepSeek-R1-70Bï¼‰åœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­è¾¾åˆ°äº†ä¸äººç±»ç›¸å½“çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒLLMsçš„ä¸­é—´å±‚è¡¨å¾åœ¨æŠ½è±¡æ¨¡å¼ç±»åˆ«çš„èšç±»ä¸Šè¡¨ç°å‡ºæ˜æ˜¾çš„ç›¸ä¼¼æ€§ï¼Œä¸äººç±»çš„è„‘ç”µä½æ•°æ®å­˜åœ¨ä¸­ç­‰æ­£ç›¸å…³ï¼Œè¡¨æ˜æ½œåœ¨çš„å…±äº«è¡¨å¾ç©ºé—´ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€å¿ƒç†å­¦å’Œäººå·¥æ™ºèƒ½çš„äº¤å‰ç ”ç©¶ã€‚é€šè¿‡ç†è§£LLMsä¸äººç±»è®¤çŸ¥çš„ç›¸ä¼¼æ€§ï¼Œå¯ä»¥ä¸ºå¼€å‘æ›´æ™ºèƒ½çš„æ•™è‚²å·¥å…·å’Œè®¤çŸ¥è¾…åŠ©ç³»ç»Ÿæä¾›ç†è®ºåŸºç¡€ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.

