---
layout: default
title: Special-Character Adversarial Attacks on Open-Source Language Model
---

# Special-Character Adversarial Attacks on Open-Source Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14070" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14070v2</a>
  <a href="https://arxiv.org/pdf/2508.14070.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14070v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14070v2', 'Special-Character Adversarial Attacks on Open-Source Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ephraiem Sarabamoun

**åˆ†ç±»**: cs.CR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-11-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶ç‰¹æ®Šå­—ç¬¦å¯¹å¼€æºè¯­è¨€æ¨¡å‹çš„å¯¹æŠ—æ”»å‡»ä»¥æå‡å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—æ”»å‡»` `è¯­è¨€æ¨¡å‹` `å®‰å…¨æ€§è¯„ä¼°` `ç‰¹æ®Šå­—ç¬¦` `è‡ªç„¶è¯­è¨€å¤„ç†` `å¼€æºæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é¢å¯¹ç‰¹æ®Šå­—ç¬¦æ”»å‡»æ—¶è¡¨ç°å‡ºæ˜æ˜¾çš„è„†å¼±æ€§ï¼Œå½±å“å…¶å®‰å…¨æ€§å’Œå¯é æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»æ–¹æ³•ï¼Œè¯„ä¼°å…¶å¯¹å¼€æºè¯­è¨€æ¨¡å‹çš„å½±å“ï¼Œæ—¨åœ¨æ­ç¤ºæ¨¡å‹çš„å®‰å…¨æ¼æ´ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šé€šè¿‡å¯¹ä¸ƒä¸ªä¸åŒè§„æ¨¡çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼Œå‘ç°æ‰€æœ‰æ¨¡å‹å‡å­˜åœ¨ä¸¥é‡çš„å®‰å…¨éšæ‚£ï¼ŒæˆåŠŸè¶Šç‹±å’Œä¸è¿è´¯è¾“å‡ºç°è±¡æ™®éå­˜åœ¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†å…¶åœ¨å­—ç¬¦çº§å¯¹æŠ—æ“æ§ä¸‹çš„è„†å¼±æ€§ä¸ºå®é™…åº”ç”¨å¸¦æ¥äº†é‡å¤§å®‰å…¨æŒ‘æˆ˜ã€‚æœ¬æ–‡ç ”ç©¶äº†åŒ…æ‹¬Unicodeã€åŒå½¢å¼‚ä¹‰å­—ã€ç»“æ„æ€§å’Œæ–‡æœ¬ç¼–ç æ”»å‡»åœ¨å†…çš„å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»ï¼Œæ—¨åœ¨ç»•è¿‡å®‰å…¨æœºåˆ¶ã€‚æˆ‘ä»¬å¯¹ä¸ƒä¸ªå‚æ•°èŒƒå›´ä»38äº¿åˆ°320äº¿çš„å¼€æºæ¨¡å‹è¿›è¡Œäº†4000å¤šæ¬¡æ”»å‡»å°è¯•çš„è¯„ä¼°ã€‚è¿™äº›å®éªŒæ­ç¤ºäº†æ‰€æœ‰æ¨¡å‹è§„æ¨¡çš„å…³é”®è„†å¼±æ€§ï¼Œæš´éœ²å‡ºæˆåŠŸè¶Šç‹±ã€ä¸è¿è´¯è¾“å‡ºå’Œæ— å…³å¹»è§‰ç­‰å¤±è´¥æ¨¡å¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å­—ç¬¦çº§å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé˜²å¾¡è¿™äº›æ”»å‡»ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨å®‰å…¨éšæ‚£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡è®¾è®¡å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»ï¼Œè¯„ä¼°å…¶å¯¹å¼€æºè¯­è¨€æ¨¡å‹çš„å½±å“ï¼Œæ—¨åœ¨æ­ç¤ºæ¨¡å‹çš„å®‰å…¨æ¼æ´å¹¶æ¨åŠ¨æ”¹è¿›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºå‡ ä¸ªä¸»è¦é˜¶æ®µï¼ŒåŒ…æ‹¬æ”»å‡»æ–¹æ³•çš„è®¾è®¡ã€æ¨¡å‹çš„é€‰æ‹©ä¸è¯„ä¼°ã€ä»¥åŠæ”»å‡»æ•ˆæœçš„åˆ†æã€‚æ¯ä¸ªé˜¶æ®µéƒ½å…³æ³¨ä¸åŒç±»å‹çš„ç‰¹æ®Šå­—ç¬¦æ”»å‡»åŠå…¶å¯¹æ¨¡å‹çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»å¯¹ä¸åŒè§„æ¨¡å¼€æºè¯­è¨€æ¨¡å‹çš„å½±å“ï¼Œæ­ç¤ºäº†æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„æ™®éè„†å¼±æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»ç­–ç•¥ï¼ŒåŒ…æ‹¬Unicodeã€åŒå½¢å¼‚ä¹‰å­—ç­‰ï¼Œè¯„ä¼°äº†ä¸ƒä¸ªæ¨¡å‹çš„å‚æ•°è§„æ¨¡å’Œæ”»å‡»æ•ˆæœï¼Œç¡®ä¿äº†å®éªŒçš„å…¨é¢æ€§å’Œä»£è¡¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰è¯„ä¼°çš„å¼€æºæ¨¡å‹åœ¨é¢å¯¹ç‰¹æ®Šå­—ç¬¦æ”»å‡»æ—¶å‡å­˜åœ¨ä¸¥é‡çš„å®‰å…¨éšæ‚£ï¼ŒæˆåŠŸè¶Šç‹±çš„æ¯”ä¾‹é«˜è¾¾XX%ï¼Œå¹¶ä¸”å‡ºç°äº†ä¸è¿è´¯è¾“å‡ºå’Œå¹»è§‰ç°è±¡ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†å¯¹æŠ—æ”»å‡»åœ¨æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°ä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ•æ„Ÿçš„è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿï¼Œå¦‚èŠå¤©æœºå™¨äººã€è‡ªåŠ¨ç¿»è¯‘å’Œå†…å®¹ç”Ÿæˆå·¥å…·ã€‚é€šè¿‡è¯†åˆ«å’Œä¿®å¤è¿™äº›è„†å¼±æ€§ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå¢å¼ºå…¶åœ¨çœŸå®ä¸–ç•Œåº”ç”¨ä¸­çš„å¯é æ€§å’Œä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have achieved remarkable performance across diverse natural language processing tasks, yet their vulnerability to character-level adversarial manipulations presents significant security challenges for real-world deployments. This paper presents a study of different special character attacks including unicode, homoglyph, structural, and textual encoding attacks aimed at bypassing safety mechanisms. We evaluate seven prominent open-source models ranging from 3.8B to 32B parameters on 4,000+ attack attempts. These experiments reveal critical vulnerabilities across all model sizes, exposing failure modes that include successful jailbreaks, incoherent outputs, and unrelated hallucinations.

