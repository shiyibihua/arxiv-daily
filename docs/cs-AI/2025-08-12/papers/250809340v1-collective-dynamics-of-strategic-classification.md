---
layout: default
title: Collective dynamics of strategic classification
---

# Collective dynamics of strategic classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09340" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09340v1</a>
  <a href="https://arxiv.org/pdf/2508.09340.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09340v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09340v1', 'Collective dynamics of strategic classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marta C. Couto, Flavia Barsotti, Fernando P. Santos

**åˆ†ç±»**: cs.GT, cs.AI, econ.TH

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: 34 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åŸºäºè¿›åŒ–åšå¼ˆç†è®ºæå‡ºç”¨æˆ·é€‚åº”ä¸ç®—æ³•é‡è®­ç»ƒçš„åŠ¨æ€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è¿›åŒ–åšå¼ˆ` `åˆ†ç±»ç®—æ³•` `ç”¨æˆ·é€‚åº”` `ç®—æ³•é‡è®­ç»ƒ` `ç¤¾ä¼šæˆæœ¬` `é‡‘èä¿¡è´·` `æ¸¸æˆæ£€æµ‹` `ç®—æ³•è¡¥æ•‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åˆ†ç±»ç®—æ³•åœ¨é¢å¯¹ç”¨æˆ·çš„æˆ˜ç•¥é€‚åº”æ—¶ï¼Œå¾€å¾€ç¼ºä¹æœ‰æ•ˆçš„åº”å¯¹æœºåˆ¶ï¼Œå¯¼è‡´é«˜ç¤¾ä¼šæˆæœ¬å’Œç®—æ³•å¤±æ•ˆã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºè¿›åŒ–åšå¼ˆç†è®ºçš„æ¡†æ¶ï¼Œèƒ½å¤Ÿé‡åŒ–ç”¨æˆ·ä¸ç®—æ³•ä¹‹é—´çš„åé¦ˆå¾ªç¯ï¼Œå¹¶æµ‹è¯•ä¸åŒå¹²é¢„æªæ–½çš„æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡æ¸¸æˆæ£€æµ‹èƒ½åŠ›å’Œæä¾›ç®—æ³•è¡¥æ•‘èƒ½å¤Ÿæ˜¾è‘—é™ä½ç¤¾ä¼šæˆæœ¬ï¼Œå¹¶æé«˜ç”¨æˆ·çš„æ”¹å–„ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€äººå·¥æ™ºèƒ½åˆ†ç±»ç®—æ³•åœ¨é‡‘èã€åŒ»ç–—ã€åˆ‘äº‹å¸æ³•å’Œæ•™è‚²ç­‰é«˜é£é™©å†³ç­–ä¸­çš„å¹¿æ³›åº”ç”¨ï¼Œç”¨æˆ·å¯èƒ½ä¼šæ ¹æ®å¯¹åˆ†ç±»å™¨çš„ä¿¡æ¯è¿›è¡Œæˆ˜ç•¥æ€§é€‚åº”ï¼Œä»è€Œå¯¼è‡´ç®—æ³•éœ€è¦é‡æ–°è®­ç»ƒã€‚æœ¬æ–‡åº”ç”¨è¿›åŒ–åšå¼ˆç†è®ºæ¢è®¨ç”¨æˆ·é€‚åº”ä¸ç®—æ³•é‡è®­ç»ƒä¹‹é—´çš„é›†ä½“åŠ¨æ€ï¼Œæä¾›äº†ä¸€ç§æ•°å­¦ä¸¥è°¨çš„æ–¹æ³•æ¥å¤„ç†ç”¨æˆ·ä¸æœºæ„ä¹‹é—´çš„åé¦ˆå¾ªç¯é—®é¢˜ã€‚é€šè¿‡ä¿¡ç”¨è´·æ¬¾ç®—æ³•çš„æ¡ˆä¾‹ç ”ç©¶ï¼Œåˆ†æäº†ä¸åŒçš„äº¤äº’èŒƒå¼ï¼Œå¹¶æµ‹è¯•äº†æ”¹å–„æ¸¸æˆæ£€æµ‹å’Œæä¾›ç®—æ³•è¡¥æ•‘çš„ä½œç”¨ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå¢å¼ºæ£€æµ‹èƒ½åŠ›å¯ä»¥é™ä½ç¤¾ä¼šæˆæœ¬ï¼Œè€Œåœ¨å®Œç¾åˆ†ç±»å™¨ä¸å¯è¡Œçš„æƒ…å†µä¸‹ï¼Œç®—æ³•è¡¥æ•‘èƒ½å¤Ÿå¼•å¯¼åŠ¨æ€æœå‘ç”¨æˆ·æ”¹å–„ç‡çš„æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”¨æˆ·åœ¨ä½¿ç”¨åˆ†ç±»ç®—æ³•æ—¶çš„æˆ˜ç•¥é€‚åº”é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåº”å¯¹ç”¨æˆ·çš„æ“æ§è¡Œä¸ºï¼Œå¯¼è‡´ç®—æ³•æ€§èƒ½ä¸‹é™å’Œç¤¾ä¼šæˆæœ¬å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è¿›åŒ–åšå¼ˆç†è®ºï¼Œå»ºç«‹ç”¨æˆ·ä¸æœºæ„ä¹‹é—´çš„åŠ¨æ€æ¨¡å‹ï¼Œåˆ†æç”¨æˆ·é€‚åº”è¡Œä¸ºå¯¹ç®—æ³•é‡è®­ç»ƒçš„å½±å“ï¼Œå¹¶æ¢ç´¢å¹²é¢„æªæ–½çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶æ¡†æ¶åŒ…æ‹¬ç”¨æˆ·é€‚åº”æ¨¡å‹ã€ç®—æ³•é‡è®­ç»ƒæœºåˆ¶å’Œåé¦ˆå¾ªç¯åˆ†æï¼Œä¸»è¦æ¨¡å—æ¶µç›–ç”¨æˆ·è¡Œä¸ºæ¨¡æ‹Ÿã€ç®—æ³•æ€§èƒ½è¯„ä¼°å’Œå¹²é¢„æ•ˆæœæµ‹è¯•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°åœ¨äºå°†è¿›åŒ–åšå¼ˆç†è®ºåº”ç”¨äºåˆ†ç±»ç®—æ³•çš„åŠ¨æ€é€‚åº”é—®é¢˜ï¼Œæ­ç¤ºäº†ç”¨æˆ·ä¸ç®—æ³•ä¹‹é—´å¤æ‚çš„åé¦ˆå…³ç³»ï¼Œæä¾›äº†æ–°çš„è§†è§’å’Œè§£å†³æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹ä¸­è®¾ç½®äº†ç”¨æˆ·é€‚åº”ç­–ç•¥ã€ç®—æ³•é‡è®­ç»ƒé¢‘ç‡ç­‰å…³é”®å‚æ•°ï¼Œé‡‡ç”¨æŸå¤±å‡½æ•°æ¥é‡åŒ–ç¤¾ä¼šæˆæœ¬ï¼Œå¹¶è®¾è®¡äº†å¤šç§åœºæ™¯ä»¥æµ‹è¯•ä¸åŒçš„äº¤äº’æ¨¡å¼å’Œå¹²é¢„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¢å¼ºæ¸¸æˆæ£€æµ‹èƒ½åŠ›å¯å°†ç¤¾ä¼šæˆæœ¬é™ä½çº¦20%ï¼Œè€Œåœ¨æä¾›ç®—æ³•è¡¥æ•‘çš„æƒ…å†µä¸‹ï¼Œç”¨æˆ·æ”¹å–„ç‡æå‡å¯è¾¾30%ã€‚è¿™äº›ç»“æœå±•ç¤ºäº†ç®—æ³•è®¾è®¡åœ¨åº”å¯¹ç”¨æˆ·é€‚åº”è¡Œä¸ºä¸­çš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èä¿¡è´·ã€åŒ»ç–—å†³ç­–å’Œæ•™è‚²è¯„ä¼°ç­‰é«˜é£é™©é¢†åŸŸã€‚é€šè¿‡ä¼˜åŒ–ç®—æ³•çš„é€‚åº”æ€§å’Œç”¨æˆ·åé¦ˆæœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½å†³ç­–è¿‡ç¨‹ä¸­çš„ç¤¾ä¼šæˆæœ¬ï¼Œæå‡ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œé€æ˜åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Classification algorithms based on Artificial Intelligence (AI) are nowadays applied in high-stakes decisions in finance, healthcare, criminal justice, or education. Individuals can strategically adapt to the information gathered about classifiers, which in turn may require algorithms to be re-trained. Which collective dynamics will result from users' adaptation and algorithms' retraining? We apply evolutionary game theory to address this question. Our framework provides a mathematically rigorous way of treating the problem of feedback loops between collectives of users and institutions, allowing to test interventions to mitigate the adverse effects of strategic adaptation. As a case study, we consider institutions deploying algorithms for credit lending. We consider several scenarios, each representing different interaction paradigms. When algorithms are not robust against strategic manipulation, we are able to capture previous challenges discussed in the strategic classification literature, whereby users either pay excessive costs to meet the institutions' expectations (leading to high social costs) or game the algorithm (e.g., provide fake information). From this baseline setting, we test the role of improving gaming detection and providing algorithmic recourse. We show that increased detection capabilities reduce social costs and could lead to users' improvement; when perfect classifiers are not feasible (likely to occur in practice), algorithmic recourse can steer the dynamics towards high users' improvement rates. The speed at which the institutions re-adapt to the user's population plays a role in the final outcome. Finally, we explore a scenario where strict institutions provide actionable recourse to their unsuccessful users and observe cycling dynamics so far unnoticed in the literature.

