---
layout: default
title: Hierarchical Reasoning Model
---

# Hierarchical Reasoning Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21734" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21734v3</a>
  <a href="https://arxiv.org/pdf/2506.21734.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21734v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21734v3', 'Hierarchical Reasoning Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guan Wang, Jin Li, Yuhao Sun, Xing Chen, Changling Liu, Yue Wu, Meng Lu, Sen Song, Yasin Abbasi Yadkori

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-08-04)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå±‚æ¬¡æ¨ç†æ¨¡å‹ä»¥è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å±‚æ¬¡æ¨ç†` `å¤æ‚æ¨ç†` `é€’å½’ç¥ç»ç½‘ç»œ` `äººå·¥æ™ºèƒ½` `é€šç”¨è®¡ç®—` `æ ·æœ¬æ•ˆç‡` `æ™ºèƒ½ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­é¢ä¸´ä»»åŠ¡åˆ†è§£è„†å¼±å’Œé«˜å»¶è¿Ÿç­‰æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºçš„å±‚æ¬¡æ¨ç†æ¨¡å‹é€šè¿‡é«˜ä½å±‚æ¬¡çš„é€’å½’æ¨¡å—å®ç°é«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹ï¼Œçµæ„Ÿæ¥æºäºäººè„‘çš„å¤„ç†æ–¹å¼ã€‚
3. HRMåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šä»…ä½¿ç”¨1000ä¸ªæ ·æœ¬ï¼Œä¸”æ— éœ€é¢„è®­ç»ƒï¼Œè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†æ›´å¤§æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨ç†æ˜¯åˆ¶å®šå’Œæ‰§è¡Œå¤æ‚ç›®æ ‡å¯¼å‘è¡ŒåŠ¨åºåˆ—çš„è¿‡ç¨‹ï¼Œä»ç„¶æ˜¯äººå·¥æ™ºèƒ½ä¸­çš„ä¸€é¡¹å…³é”®æŒ‘æˆ˜ã€‚ç›®å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸»è¦é‡‡ç”¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æŠ€æœ¯ï¼Œä½†å­˜åœ¨ä»»åŠ¡åˆ†è§£è„†å¼±ã€æ•°æ®éœ€æ±‚åºå¤§å’Œå»¶è¿Ÿé«˜ç­‰é—®é¢˜ã€‚å—åˆ°äººè„‘å±‚æ¬¡å’Œå¤šæ—¶é—´å°ºåº¦å¤„ç†çš„å¯å‘ï¼Œæœ¬æ–‡æå‡ºäº†å±‚æ¬¡æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„é€’å½’æ¶æ„ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒè®­ç»ƒç¨³å®šæ€§å’Œæ•ˆç‡çš„åŒæ—¶å®ç°æ˜¾è‘—çš„è®¡ç®—æ·±åº¦ã€‚HRMé€šè¿‡ä¸¤ä¸ªç›¸äº’ä¾èµ–çš„é€’å½’æ¨¡å—æ‰§è¡Œé¡ºåºæ¨ç†ä»»åŠ¡ï¼šé«˜å±‚æ¨¡å—è´Ÿè´£ç¼“æ…¢çš„æŠ½è±¡è§„åˆ’ï¼Œä½å±‚æ¨¡å—å¤„ç†å¿«é€Ÿçš„è¯¦ç»†è®¡ç®—ã€‚HRMä»…ç”¨2700ä¸‡å‚æ•°ï¼Œåœ¨ä»…1000ä¸ªè®­ç»ƒæ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚è¯¥æ¨¡å‹æ— éœ€é¢„è®­ç»ƒæˆ–CoTæ•°æ®ï¼Œä»åœ¨å¤æ‚æ•°ç‹¬å’Œå¤§å‹è¿·å®«çš„æœ€ä¼˜è·¯å¾„å¯»æ‰¾ç­‰æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸Šå‡ ä¹å®Œç¾åœ°å®Œæˆã€‚HRMåœ¨æŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼ˆARCï¼‰ä¸Šè¶…è¶Šäº†æ›´å¤§æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨é€šç”¨è®¡ç®—å’Œé€šç”¨æ¨ç†ç³»ç»Ÿæ–¹é¢çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ•ˆç‡å’Œç¨³å®šæ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¦‚é“¾å¼æ€ç»´ï¼ˆCoTï¼‰å­˜åœ¨è„†å¼±æ€§å’Œé«˜æ•°æ®éœ€æ±‚çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šå±‚æ¬¡æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰é€šè¿‡è®¾è®¡ä¸¤ä¸ªç›¸äº’ä¾èµ–çš„é€’å½’æ¨¡å—ï¼Œåˆ†åˆ«è´Ÿè´£é«˜å±‚çš„æŠ½è±¡è§„åˆ’å’Œä½å±‚çš„å¿«é€Ÿè®¡ç®—ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHRMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬é«˜å±‚æ¨¡å—å’Œä½å±‚æ¨¡å—ã€‚é«˜å±‚æ¨¡å—è¿›è¡Œç¼“æ…¢çš„æŠ½è±¡æ€è€ƒï¼Œè€Œä½å±‚æ¨¡å—åˆ™å¿«é€Ÿå¤„ç†å…·ä½“ç»†èŠ‚ï¼ŒäºŒè€…ååŒå·¥ä½œä»¥å®Œæˆæ¨ç†ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šHRMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å±‚æ¬¡åŒ–çš„é€’å½’ç»“æ„ï¼Œèƒ½å¤Ÿåœ¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­æ‰§è¡Œå¤æ‚æ¨ç†ï¼Œè€Œä¸éœ€è¦æ˜¾å¼ç›‘ç£ä¸­é—´è¿‡ç¨‹ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šHRMä»…ä½¿ç”¨2700ä¸‡å‚æ•°ï¼Œä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸ä¾èµ–äºé¢„è®­ç»ƒæˆ–é“¾å¼æ€ç»´æ•°æ®ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ ·æœ¬æ•ˆç‡å’Œè®¡ç®—èƒ½åŠ›ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HRMåœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šä»…ä½¿ç”¨1000ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä¸”æ— éœ€é¢„è®­ç»ƒï¼Œå‡ ä¹å®Œç¾åœ°è§£å†³äº†å¤æ‚æ•°ç‹¬å’Œå¤§å‹è¿·å®«çš„æœ€ä¼˜è·¯å¾„é—®é¢˜ã€‚æ­¤å¤–ï¼ŒHRMåœ¨æŠ½è±¡ä¸æ¨ç†è¯­æ–™åº“ï¼ˆARCï¼‰ä¸Šè¶…è¶Šäº†æ›´å¤§æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

å±‚æ¬¡æ¨ç†æ¨¡å‹ï¼ˆHRMï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„ä¼˜å¼‚è¡¨ç°ä½¿å…¶åœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚æœªæ¥ï¼ŒHRMæœ‰æœ›æ¨åŠ¨é€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œæå‡æœºå™¨åœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning, the process of devising and executing complex goal-oriented action sequences, remains a critical challenge in AI. Current large language models (LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from brittle task decomposition, extensive data requirements, and high latency. Inspired by the hierarchical and multi-timescale processing in the human brain, we propose the Hierarchical Reasoning Model (HRM), a novel recurrent architecture that attains significant computational depth while maintaining both training stability and efficiency. HRM executes sequential reasoning tasks in a single forward pass without explicit supervision of the intermediate process, through two interdependent recurrent modules: a high-level module responsible for slow, abstract planning, and a low-level module handling rapid, detailed computations. With only 27 million parameters, HRM achieves exceptional performance on complex reasoning tasks using only 1000 training samples. The model operates without pre-training or CoT data, yet achieves nearly perfect performance on challenging tasks including complex Sudoku puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms much larger models with significantly longer context windows on the Abstraction and Reasoning Corpus (ARC), a key benchmark for measuring artificial general intelligence capabilities. These results underscore HRM's potential as a transformative advancement toward universal computation and general-purpose reasoning systems.

