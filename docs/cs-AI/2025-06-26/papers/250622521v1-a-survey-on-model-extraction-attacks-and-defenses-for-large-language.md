---
layout: default
title: A Survey on Model Extraction Attacks and Defenses for Large Language Models
---

# A Survey on Model Extraction Attacks and Defenses for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22521" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22521v1</a>
  <a href="https://arxiv.org/pdf/2506.22521.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22521v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22521v1', 'A Survey on Model Extraction Attacks and Defenses for Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaixiang Zhao, Lincan Li, Kaize Ding, Neil Zhenqiang Gong, Yue Zhao, Yushun Dong

**åˆ†ç±»**: cs.CR, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¨¡å‹æå–æ”»å‡»ä¸é˜²å¾¡çš„å…¨é¢åˆ†ç±»ä»¥ä¿æŠ¤è¯­è¨€æ¨¡å‹å®‰å…¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å‹æå–æ”»å‡»` `é˜²å¾¡æœºåˆ¶` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†äº§æƒä¿æŠ¤` `ç”¨æˆ·éšç§` `è‡ªç„¶è¯­è¨€å¤„ç†` `å®‰å…¨æ€§è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡å‹æå–æ”»å‡»æ–¹æ³•åœ¨ä¿æŠ¤çŸ¥è¯†äº§æƒå’Œç”¨æˆ·éšç§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼ŒäºŸéœ€ç³»ç»Ÿæ€§åˆ†æä¸é˜²å¾¡ç­–ç•¥ã€‚
2. æœ¬æ–‡æå‡ºäº†é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æ”»å‡»ä¸é˜²å¾¡åˆ†ç±»ï¼Œåˆ†æäº†å¤šç§æ”»å‡»æ–¹æ³•åŠå…¶é˜²å¾¡æœºåˆ¶ï¼Œæ—¨åœ¨æé«˜æ¨¡å‹å®‰å…¨æ€§ã€‚
3. é€šè¿‡è¯„ä¼°ä¸åŒé˜²å¾¡ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œæœ¬æ–‡è¯†åˆ«äº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶æå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œæ¨åŠ¨é¢†åŸŸè¿›æ­¥ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡å‹æå–æ”»å‡»å¯¹éƒ¨ç½²çš„è¯­è¨€æ¨¡å‹æ„æˆäº†é‡å¤§å®‰å…¨å¨èƒï¼Œå¯èƒ½å±åŠçŸ¥è¯†äº§æƒå’Œç”¨æˆ·éšç§ã€‚æœ¬æ–‡æä¾›äº†é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç‰¹å®šæå–æ”»å‡»å’Œé˜²å¾¡çš„å…¨é¢åˆ†ç±»ï¼Œæ”»å‡»åˆ†ä¸ºåŠŸèƒ½æå–ã€è®­ç»ƒæ•°æ®æå–å’Œé’ˆå¯¹æç¤ºçš„æ”»å‡»ã€‚æˆ‘ä»¬åˆ†æäº†å¤šç§æ”»å‡»æ–¹æ³•ï¼ŒåŒ…æ‹¬åŸºäºAPIçš„çŸ¥è¯†è’¸é¦ã€ç›´æ¥æŸ¥è¯¢ã€å‚æ•°æ¢å¤å’Œæç¤ºçªƒå–ç­‰æŠ€æœ¯ï¼Œè¿™äº›æ–¹æ³•åˆ©ç”¨äº†å˜æ¢å™¨æ¶æ„ã€‚æ¥ç€ï¼Œæˆ‘ä»¬å®¡è§†äº†é˜²å¾¡æœºåˆ¶ï¼Œåˆ†ä¸ºæ¨¡å‹ä¿æŠ¤ã€æ•°æ®éšç§ä¿æŠ¤å’Œé’ˆå¯¹æç¤ºçš„ç­–ç•¥ï¼Œå¹¶è¯„ä¼°äº†å®ƒä»¬åœ¨ä¸åŒéƒ¨ç½²åœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸“é—¨çš„æŒ‡æ ‡æ¥è¯„ä¼°æ”»å‡»æ•ˆæœå’Œé˜²å¾¡æ€§èƒ½ï¼Œè§£å†³ç”Ÿæˆè¯­è¨€æ¨¡å‹ç‰¹æœ‰çš„æŒ‘æˆ˜ã€‚é€šè¿‡åˆ†æï¼Œæˆ‘ä»¬è¯†åˆ«äº†å½“å‰æ–¹æ³•çš„å…³é”®å±€é™ï¼Œå¹¶æå‡ºäº†æœ‰å‰æ™¯çš„ç ”ç©¶æ–¹å‘ï¼ŒåŒ…æ‹¬é›†æˆæ”»å‡»æ–¹æ³•å’Œè‡ªé€‚åº”é˜²å¾¡æœºåˆ¶ï¼Œä»¥å¹³è¡¡å®‰å…¨æ€§ä¸æ¨¡å‹å®ç”¨æ€§ã€‚è¯¥ç ”ç©¶ä¸ºNLPç ”ç©¶äººå‘˜ã€æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆå’Œå®‰å…¨ä¸“ä¸šäººå£«æä¾›äº†ä¿æŠ¤ç”Ÿäº§ç¯å¢ƒä¸­è¯­è¨€æ¨¡å‹çš„å‚è€ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆé˜²å¾¡é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„æå–æ”»å‡»ï¼Œç°æœ‰æ–¹æ³•åœ¨åº”å¯¹å¤šæ ·åŒ–æ”»å‡»æ‰‹æ®µæ—¶å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å…¨é¢ä¿æŠ¤æ¨¡å‹çš„å®‰å…¨æ€§å’Œç”¨æˆ·éšç§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å…¨é¢åˆ†ç±»å’Œåˆ†ææ”»å‡»ä¸é˜²å¾¡æœºåˆ¶ï¼Œæå‡ºé’ˆå¯¹æ€§è§£å†³æ–¹æ¡ˆï¼Œæ—¨åœ¨æå‡è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§å’Œå®ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ”»å‡»åˆ†ç±»ã€æ”»å‡»æ–¹æ³•åˆ†æã€é˜²å¾¡æœºåˆ¶è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œåˆ†åˆ«é’ˆå¯¹åŠŸèƒ½æå–ã€è®­ç»ƒæ•°æ®æå–å’Œæç¤ºæ”»å‡»è¿›è¡Œæ·±å…¥æ¢è®¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸“é—¨çš„è¯„ä¼°æŒ‡æ ‡ï¼Œé’ˆå¯¹ç”Ÿæˆè¯­è¨€æ¨¡å‹çš„ç‰¹æ€§ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°æ”»å‡»æ•ˆæœä¸é˜²å¾¡æ€§èƒ½ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨é˜²å¾¡æœºåˆ¶è®¾è®¡ä¸­ï¼Œè€ƒè™‘äº†æ¨¡å‹ä¿æŠ¤ã€æ•°æ®éšç§ä¿æŠ¤å’Œé’ˆå¯¹æç¤ºçš„ç­–ç•¥ï¼Œå…³é”®å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©å‡åŸºäºå¯¹æ”»å‡»æ–¹æ³•çš„æ·±å…¥ç†è§£ï¼Œç¡®ä¿é˜²å¾¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„é˜²å¾¡æœºåˆ¶åœ¨å¤šç§æ”»å‡»åœºæ™¯ä¸‹æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œé˜²å¾¡æ•ˆæœç›¸æ¯”åŸºçº¿æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€äººå·¥æ™ºèƒ½å®‰å…¨å’Œæ•°æ®éšç§ä¿æŠ¤ç­‰ã€‚é€šè¿‡æä¾›ç³»ç»Ÿçš„æ”»å‡»ä¸é˜²å¾¡åˆ†ç±»ï¼Œç ”ç©¶ä¸ºå¼€å‘æ›´å®‰å…¨çš„è¯­è¨€æ¨¡å‹æä¾›äº†ç†è®ºåŸºç¡€ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Model extraction attacks pose significant security threats to deployed language models, potentially compromising intellectual property and user privacy. This survey provides a comprehensive taxonomy of LLM-specific extraction attacks and defenses, categorizing attacks into functionality extraction, training data extraction, and prompt-targeted attacks. We analyze various attack methodologies including API-based knowledge distillation, direct querying, parameter recovery, and prompt stealing techniques that exploit transformer architectures. We then examine defense mechanisms organized into model protection, data privacy protection, and prompt-targeted strategies, evaluating their effectiveness across different deployment scenarios. We propose specialized metrics for evaluating both attack effectiveness and defense performance, addressing the specific challenges of generative language models. Through our analysis, we identify critical limitations in current approaches and propose promising research directions, including integrated attack methodologies and adaptive defense mechanisms that balance security with model utility. This work serves NLP researchers, ML engineers, and security professionals seeking to protect language models in production environments.

