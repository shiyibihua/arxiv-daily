---
layout: default
title: Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?
---

# Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21215" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21215v1</a>
  <a href="https://arxiv.org/pdf/2506.21215.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21215v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21215v1', 'Unveiling Causal Reasoning in Large Language Models: Reality or Mirage?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoang Chi, He Li, Wenjing Yang, Feng Liu, Long Lan, Xiaoguang Ren, Tongliang Liu, Bo Han

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

**å¤‡æ³¨**: 24 pages, accepted at NeurIPS 2024

**æœŸåˆŠ**: Advances in Neural Information Processing Systems, 2024, 37: 96640-96670

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºG^2-Reasonerä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å› æœæ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `G^2-Reasoner` `æ·±åº¦å­¦ä¹ ` `äººå·¥æ™ºèƒ½` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å› æœæ¨ç†æ–¹é¢å­˜åœ¨å±€é™ï¼Œä¸»è¦åªèƒ½è¿›è¡Œä¸€çº§å› æœæ¨ç†ï¼Œç¼ºä¹äººç±»çº§çš„æ·±å±‚å› æœæ¨ç†èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºG^2-Reasonerï¼Œé€šè¿‡ç»“åˆé€šç”¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘çš„æç¤ºï¼Œæ¥å¢å¼ºLLMsçš„å› æœæ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒG^2-Reasoneråœ¨CausalProbe-2024åŸºå‡†ä¸Šæ˜¾è‘—æå‡äº†LLMsçš„å› æœæ¨ç†è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨æ–°é²œå’Œåäº‹å®æƒ…å¢ƒä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å› æœæ¨ç†èƒ½åŠ›å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å‘å¼ºäººå·¥æ™ºèƒ½çš„å‘å±•è‡³å…³é‡è¦ã€‚å°½ç®¡å¤šåŠŸèƒ½LLMsä¼¼ä¹åœ¨ç†è§£ä¸Šä¸‹æ–‡å› æœå…³ç³»å’Œæä¾›ç¬¦åˆå› æœæ³•åˆ™çš„å“åº”æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬æ˜¯å¦èƒ½å¤Ÿè¿›è¡Œç±»ä¼¼äººç±»çš„çœŸæ­£å› æœæ¨ç†ä»ä¸æ˜ç¡®ã€‚ç°æœ‰è¯æ®è¡¨æ˜ï¼ŒLLMsä»…èƒ½è¿›è¡Œæµ…å±‚ï¼ˆä¸€çº§ï¼‰å› æœæ¨ç†ï¼Œä¸»è¦å½’å› äºå…¶å‚æ•°ä¸­åµŒå…¥çš„å› æœçŸ¥è¯†ï¼Œè€Œç¼ºä¹çœŸæ­£çš„äººç±»çº§ï¼ˆçº§åˆ«äºŒï¼‰å› æœæ¨ç†èƒ½åŠ›ã€‚ä¸ºæ”¯æŒè¿™ä¸€å‡è®¾ï¼Œæœ¬æ–‡æ·±å…¥æ¢è®¨äº†åŸºäºå˜æ¢å™¨çš„LLMsçš„è‡ªå›å½’æœºåˆ¶ï¼Œæ­ç¤ºå…¶å¹¶éå›ºæœ‰çš„å› æœæœºåˆ¶ã€‚æˆ‘ä»¬å¼•å…¥äº†æ–°çš„å› æœé—®ç­”åŸºå‡†CausalProbe-2024ï¼ŒLLMsåœ¨è¯¥åŸºå‡†ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¸‹é™ï¼Œè¡¨æ˜å®ƒä»¬ä¸»è¦å‚ä¸ä¸€çº§å› æœæ¨ç†ã€‚ä¸ºç¼©å°ä¸äºŒçº§å› æœæ¨ç†çš„å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†G^2-Reasonerï¼Œç»“åˆäº†é€šç”¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘æç¤ºï¼Œæ˜¾è‘—æå‡äº†LLMsåœ¨æ–°é²œå’Œåäº‹å®ä¸Šä¸‹æ–‡ä¸­çš„å› æœæ¨ç†èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å› æœæ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯å®ƒä»¬åªèƒ½è¿›è¡Œæµ…å±‚å› æœæ¨ç†è€Œç¼ºä¹æ·±å±‚å› æœæ¨ç†èƒ½åŠ›çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥é€šç”¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘æç¤ºï¼Œå¸®åŠ©LLMsåœ¨å› æœæ¨ç†è¿‡ç¨‹ä¸­æ›´å¥½åœ°æ¨¡æ‹Ÿäººç±»çš„æ¨ç†æ–¹å¼ï¼Œä»è€Œæå‡å…¶å› æœæ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºæ–°çš„å› æœé—®ç­”åŸºå‡†CausalProbe-2024ï¼›å…¶æ¬¡ï¼Œè®¾è®¡G^2-Reasoneræ¨¡å‹ï¼Œç»“åˆé€šç”¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘æç¤ºï¼›æœ€åï¼Œé€šè¿‡å¯¹æ¯”å®éªŒè¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºG^2-Reasonerçš„è®¾è®¡ï¼Œå®ƒé€šè¿‡å¼•å…¥å¤–éƒ¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘çš„æç¤ºï¼Œæ˜¾è‘—æå‡äº†LLMsçš„å› æœæ¨ç†èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æ¥è¿‘äººç±»çš„æ¨ç†æ–¹å¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒG^2-Reasoneré‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å› æœæ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨äº†æ–°é²œçš„ã€æœªè§è¿‡çš„æ•°æ®é›†ï¼Œä»¥ç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒG^2-Reasoneråœ¨CausalProbe-2024åŸºå‡†ä¸Šç›¸æ¯”äºä¼ ç»Ÿæ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºå› æœæ¨ç†èƒ½åŠ›æé«˜äº†çº¦30%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œç»“åˆé€šç”¨çŸ¥è¯†å’Œç›®æ ‡å¯¼å‘æç¤ºçš„ç­–ç•¥åœ¨æå‡å› æœæ¨ç†èƒ½åŠ›æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€è‡ªåŠ¨åŒ–æ¨ç†å·¥å…·å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å› æœæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­è¡¨ç°å¾—æ›´åŠ æ™ºèƒ½å’Œäººæ€§åŒ–ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Causal reasoning capability is critical in advancing large language models (LLMs) toward strong artificial intelligence. While versatile LLMs appear to have demonstrated capabilities in understanding contextual causality and providing responses that obey the laws of causality, it remains unclear whether they perform genuine causal reasoning akin to humans. However, current evidence indicates the contrary. Specifically, LLMs are only capable of performing shallow (level-1) causal reasoning, primarily attributed to the causal knowledge embedded in their parameters, but they lack the capacity for genuine human-like (level-2) causal reasoning. To support this hypothesis, methodologically, we delve into the autoregression mechanism of transformer-based LLMs, revealing that it is not inherently causal. Empirically, we introduce a new causal Q&A benchmark called CausalProbe-2024, whose corpora are fresh and nearly unseen for the studied LLMs. The LLMs exhibit a significant performance drop on CausalProbe-2024 compared to earlier benchmarks, indicating the fact that they primarily engage in level-1 causal reasoning. To bridge the gap towards level-2 causal reasoning, we draw inspiration from the fact that human reasoning is usually facilitated by general knowledge and intended goals. We propose G^2-Reasoner, a method that incorporates general knowledge and goal-oriented prompts into LLMs' causal reasoning processes. Experiments demonstrate that G^2-Reasoner significantly enhances LLMs' causal reasoning capability, particularly in fresh and counterfactual contexts. This work sheds light on a new path for LLMs to advance towards genuine causal reasoning, going beyond level-1 and making strides towards level-2.

