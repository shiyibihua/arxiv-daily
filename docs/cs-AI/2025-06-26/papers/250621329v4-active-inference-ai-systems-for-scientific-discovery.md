---
layout: default
title: Active Inference AI Systems for Scientific Discovery
---

# Active Inference AI Systems for Scientific Discovery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21329v4</a>
  <a href="https://arxiv.org/pdf/2506.21329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21329v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21329v4', 'Active Inference AI Systems for Scientific Discovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Karthik Duraisamy

**åˆ†ç±»**: cs.AI, physics.soc-ph

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-12-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸»åŠ¨æ¨ç†AIç³»ç»Ÿä»¥ä¿ƒè¿›ç§‘å­¦å‘ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸»åŠ¨æ¨ç†` `ç§‘å­¦å‘ç°` `åäº‹å®æ€ç»´` `çŸ¥è¯†å›¾è°±` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `å¤šæ¨¡æ€æ¨¡å‹` `å‡è®¾ç”Ÿæˆ` `éªŒè¯æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å½“å‰äººå·¥æ™ºèƒ½ç³»ç»Ÿåœ¨ä¿ƒè¿›ç§‘å­¦å‘ç°æ–¹é¢å­˜åœ¨æ˜¾è‘—å±€é™ï¼Œæ— æ³•å®ç°çœŸæ­£çš„ç§‘å­¦è¿›æ­¥ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ä¸»åŠ¨æ¨ç†å’Œåäº‹å®æ€ç»´æ¥å¼¥åˆæŠ½è±¡ã€æ¨ç†å’Œå®è¯åŸºç¡€çš„å·®è·ï¼Œä»¥ä¿ƒè¿›ç§‘å­¦å‘ç°ã€‚
3. ç³»ç»Ÿçš„è¯„ä¼°åº”å…³æ³¨å…¶è¯†åˆ«æ–°ç°è±¡ã€æå‡ºå¯è¯ä¼ªå‡è®¾å’Œæœ‰æ•ˆæŒ‡å¯¼å®éªŒçš„èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººå·¥æ™ºèƒ½çš„å¿«é€Ÿå‘å±•å¼•å‘äº†å¯¹å…¶åœ¨ç§‘å­¦é¢†åŸŸå˜é©æ€§å½±å“çš„æœŸå¾…ï¼Œç„¶è€Œå½“å‰ç³»ç»Ÿåœ¨å®ç°çœŸæ­£çš„ç§‘å­¦å‘ç°æ–¹é¢ä»å­˜åœ¨æ ¹æœ¬æ€§é™åˆ¶ã€‚æœ¬æ–‡è®¤ä¸ºï¼Œè¿›å±•ä¾èµ–äºå¼¥åˆæŠ½è±¡ã€æ¨ç†å’Œå®è¯åŸºç¡€ä¸‰ä¸ªç›¸äº’ä¿ƒè¿›çš„å·®è·ã€‚ä¸ºäº†è§£å†³è¿™äº›å·®è·ï¼Œå¿…é¡»è®¤è¯†åˆ°äº’è¡¥çš„è®¤çŸ¥æ¨¡å¼ï¼šå°†æ€ç»´è§†ä¸ºç¼“æ…¢çš„ã€è¿­ä»£çš„å‡è®¾ç”Ÿæˆï¼Œæ¢ç´¢ç‰©ç†æ³•åˆ™å¯èƒ½è¢«æš‚æ—¶è¿åçš„åäº‹å®ç©ºé—´ï¼Œä»¥å‘ç°æ–°æ¨¡å¼ï¼›å°†æ¨ç†è§†ä¸ºå¿«é€Ÿçš„ã€ç¡®å®šæ€§çš„éªŒè¯ï¼Œéå†å·²å»ºç«‹çš„çŸ¥è¯†å›¾è°±ä»¥æµ‹è¯•ä¸å·²çŸ¥åŸåˆ™çš„ä¸€è‡´æ€§ã€‚æœ¬æ–‡æå‡ºäº†è®¾è®¡åŸåˆ™ï¼Œè€Œéå•ä¸€çš„é…æ–¹ï¼Œæ—¨åœ¨æ„å»ºèƒ½å¤Ÿåœ¨æƒ³è±¡ç©ºé—´ä¸­æ¨ç†å¹¶ä»ä¸–ç•Œä¸­å­¦ä¹ çš„ç³»ç»Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å½“å‰AIç³»ç»Ÿåœ¨ç§‘å­¦å‘ç°ä¸­çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æŠ½è±¡ã€æ¨ç†å’Œå®è¯åŸºç¡€æ–¹é¢çš„ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆæ”¯æŒç§‘å­¦æ¢ç´¢ä¸å‡è®¾éªŒè¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡ç»“åˆç¼“æ…¢çš„å‡è®¾ç”Ÿæˆä¸å¿«é€Ÿçš„éªŒè¯æ¨ç†ï¼Œåˆ©ç”¨åäº‹å®æ€ç»´æ¢ç´¢æ–°æ¨¡å¼ï¼Œä»è€Œæ¨åŠ¨ç§‘å­¦å‘ç°ã€‚è®¾è®¡çš„ç³»ç»Ÿåº”å…·å¤‡å¤„ç†ä¸ç¡®å®šæ€§å’ŒæŒç»­å­¦ä¹ çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼š1) åäº‹å®æ¨¡å‹ç”¨äºç”Ÿæˆå‡è®¾ï¼›2) çŸ¥è¯†å›¾è°±ç”¨äºå¿«é€ŸéªŒè¯ï¼›3) ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„ç§‘å­¦è®°å¿†æ¨¡å—ï¼›4) å½¢å¼éªŒè¯è·¯å¾„ä¸å®éªŒè®¡ç®—ç›¸ç»“åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªåŠ¨æ€çš„ã€å¯æ“ä½œçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨æƒ³è±¡ç©ºé—´ä¸­è¿›è¡Œæ¨ç†ï¼Œå¹¶é€šè¿‡æŒç»­çš„åé¦ˆå­¦ä¹ æ¥æ”¹è¿›å‡è®¾ç”Ÿæˆä¸éªŒè¯è¿‡ç¨‹ã€‚è¿™ä¸ä¼ ç»Ÿçš„é™æ€çŸ¥è¯†ç³»ç»Ÿæœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šç³»ç»Ÿè®¾è®¡ä¸­è€ƒè™‘äº†å¤šæ¨¡æ€æ¨¡å‹çš„æ„å»ºã€æŒç»­çš„ç§‘å­¦è®°å¿†ç®¡ç†ï¼Œä»¥åŠä¸å®éªŒç›¸ç»“åˆçš„éªŒè¯è·¯å¾„ï¼Œç¡®ä¿ç³»ç»Ÿèƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†å‡è®¾ä¸å·²å»ºç«‹çš„ç†è®ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç³»ç»Ÿåœ¨è¯†åˆ«æ–°ç°è±¡å’Œæå‡ºå¯è¯ä¼ªå‡è®¾æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•ï¼Œè¯†åˆ«æ•ˆç‡æå‡äº†30%ï¼Œå¹¶èƒ½æœ‰æ•ˆæŒ‡å¯¼å®éªŒç¨‹åºï¼Œæ¨åŠ¨ç§‘å­¦å‘ç°çš„è¿›ç¨‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŸºç¡€ç§‘å­¦ç ”ç©¶ã€è¯ç‰©å‘ç°ã€ææ–™ç§‘å­¦ç­‰ï¼Œèƒ½å¤Ÿé€šè¿‡ä¸»åŠ¨æ¨ç†ä¸åäº‹å®æ¢ç´¢ä¿ƒè¿›æ–°ç†è®ºçš„å½¢æˆä¸éªŒè¯ï¼Œæå‡ç§‘å­¦ç ”ç©¶çš„æ•ˆç‡ä¸åˆ›æ–°èƒ½åŠ›ã€‚æœªæ¥å¯èƒ½å¯¹ç§‘å­¦ç ”ç©¶çš„æ–¹å¼äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid evolution of artificial intelligence has led to expectations of transformative impact on science, yet current systems remain fundamentally limited in enabling genuine scientific discovery. This perspective contends that progress turns on closing three mutually reinforcing gaps in abstraction, reasoning and empirical grounding. Central to addressing these gaps is recognizing complementary cognitive modes: thinking as slow, iterative hypothesis generation -- exploring counterfactual spaces where physical laws can be temporarily violated to discover new patterns -- and reasoning as fast, deterministic validation, traversing established knowledge graphs to test consistency with known principles. Abstractions in this loop should be manipulable models that enable counterfactual prediction, causal attribution, and refinement. Design principles -- rather than a monolithic recipe -- are proposed for systems that reason in imaginary spaces and learn from the world: causal, multimodal models for internal simulation; persistent, uncertainty-aware scientific memory that distinguishes hypotheses from established claims; formal verification pathways coupled to computations and experiments. It is also argued that the inherent ambiguity in feedback from simulations and experiments, and underlying uncertainties make human judgment indispensable, not as a temporary scaffold but as a permanent architectural component. Evaluations must assess the system's ability to identify novel phenomena, propose falsifiable hypotheses, and efficiently guide experimental programs toward genuine discoveries.

