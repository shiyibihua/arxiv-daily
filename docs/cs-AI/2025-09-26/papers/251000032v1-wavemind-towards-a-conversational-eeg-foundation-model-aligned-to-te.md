---
layout: default
title: WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities
---

# WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00032" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00032v1</a>
  <a href="https://arxiv.org/pdf/2510.00032.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00032v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00032v1', 'WaveMind: Towards a Conversational EEG Foundation Model Aligned to Textual and Visual Modalities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziyi Zeng, Zhenyang Cai, Yixi Cai, Xidong Wang, Junying Chen, Rongsheng Wang, Yipeng Liu, Siqi Cai, Benyou Wang, Zhiguo Zhang, Haizhou Li

**åˆ†ç±»**: eess.SP, cs.AI, cs.CL, cs.LG, q-bio.NC

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**WaveMindï¼šé¢å‘æ–‡æœ¬å’Œè§†è§‰æ¨¡æ€å¯¹é½çš„ä¼šè¯å¼è„‘ç”µå›¾åŸºç¡€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è„‘ç”µå›¾` `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `è·¨æ¨¡æ€å¯¹é½` `æŒ‡ä»¤è°ƒä¼˜` `è„‘æœºæ¥å£` `ç¥ç»ç§‘å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆå­¦ä¹ è„‘ç”µä¿¡å·çš„è·¨æ¨¡æ€è¡¨å¾ï¼Œå› ä¸ºè„‘ç”µä¿¡å·åŒæ—¶ç¼–ç è®¤çŸ¥è¿‡ç¨‹å’Œå†…åœ¨ç¥ç»çŠ¶æ€ï¼Œå¯¼è‡´æ¨¡æ€ä¸åŒ¹é…ã€‚
2. è®ºæ–‡æ ¸å¿ƒæ€æƒ³æ˜¯å°†è„‘ç”µä¿¡å·åŠå…¶å¯¹åº”çš„æ¨¡æ€æ˜ å°„åˆ°ç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ï¼Œä»è€Œå®ç°æ³›åŒ–çš„è„‘ç”µå›¾è§£è¯»ã€‚
3. è®ºæ–‡æ„å»ºäº†WaveMind-Instruct-338kæ•°æ®é›†ï¼Œå¹¶è®­ç»ƒäº†WaveMindæ¨¡å‹ï¼Œå®éªŒè¡¨æ˜è¯¥æ¨¡å‹å…·æœ‰é²æ£’çš„åˆ†ç±»ç²¾åº¦å’Œçµæ´»çš„ä¼šè¯èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è¿›è¡Œè„‘ç”µå›¾ï¼ˆEEGï¼‰åˆ†æçš„æ–°æ–¹æ³•ã€‚è„‘ç”µæ´»åŠ¨å¤æ‚ï¼ŒåŒæ—¶ç¼–ç è®¤çŸ¥è¿‡ç¨‹å’Œå†…åœ¨ç¥ç»çŠ¶æ€ï¼Œå¯¼è‡´è„‘ç”µå›¾é…å¯¹æ•°æ®æ¨¡æ€ä¸åŒ¹é…ï¼Œé˜»ç¢äº†æœ‰æ•ˆçš„è·¨æ¨¡æ€è¡¨å¾å­¦ä¹ ã€‚é€šè¿‡æ·±å…¥ç ”ç©¶ï¼Œæˆ‘ä»¬å‘ç°äº†è¿™äº›æ¨¡æ€ä¹‹é—´çš„äº’è¡¥å…³ç³»ã€‚åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºå°†è„‘ç”µä¿¡å·åŠå…¶å¯¹åº”çš„æ¨¡æ€æ˜ å°„åˆ°ç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ï¼Œä»¥å®ç°æ³›åŒ–çš„è„‘ç”µå›¾è§£è¯»ã€‚ä¸ºäº†å……åˆ†å®ç°ä¼šè¯èƒ½åŠ›ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥äº†WaveMind-Instruct-338kï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç”¨äºæŒ‡ä»¤è°ƒä¼˜çš„è·¨ä»»åŠ¡è„‘ç”µå›¾æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨ä¿æŒé²æ£’åˆ†ç±»ç²¾åº¦çš„åŒæ—¶ï¼Œæ”¯æŒè·¨å››ä¸ªä¸‹æ¸¸ä»»åŠ¡çš„çµæ´»ã€å¼€æ”¾å¼å¯¹è¯ï¼Œä¸ºç¥ç»ç§‘å­¦ç ”ç©¶å’Œé€šç”¨è„‘ç”µå›¾æ¨¡å‹çš„å¼€å‘æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè„‘ç”µå›¾ï¼ˆEEGï¼‰ä¿¡å·çš„è§£è¯»é¢ä¸´ç€è·¨æ¨¡æ€è¡¨å¾å­¦ä¹ çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥å¤„ç†è„‘ç”µä¿¡å·ä¸­åŒæ—¶å­˜åœ¨çš„è®¤çŸ¥è¿‡ç¨‹å’Œå†…åœ¨ç¥ç»çŠ¶æ€ï¼Œå¯¼è‡´è„‘ç”µå›¾é…å¯¹æ•°æ®æ¨¡æ€ä¸åŒ¹é…ï¼Œä»è€Œå½±å“äº†æ¨¡å‹çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„è·¨æ¨¡æ€å¯¹é½æœºåˆ¶ï¼Œéš¾ä»¥å®ç°å¯¹è„‘ç”µä¿¡å·çš„å…¨é¢ç†è§£å’Œåº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è„‘ç”µä¿¡å·åŠå…¶å¯¹åº”çš„æ–‡æœ¬å’Œè§†è§‰æ¨¡æ€æ˜ å°„åˆ°ä¸€ä¸ªç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°è„‘ç”µä¿¡å·ä¸å…¶ä»–æ¨¡æ€ä¹‹é—´çš„å…³è”ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£è„‘ç”µä¿¡å·çš„å«ä¹‰ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº’è¡¥å…³ç³»ï¼Œä»è€Œå…‹æœäº†è„‘ç”µä¿¡å·æœ¬èº«çš„å¤æ‚æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šWaveMindæ¨¡å‹çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è„‘ç”µä¿¡å·ç¼–ç å™¨ï¼šç”¨äºå°†è„‘ç”µä¿¡å·è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚2) æ–‡æœ¬ç¼–ç å™¨ï¼šç”¨äºå°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚3) è§†è§‰ç¼–ç å™¨ï¼šç”¨äºå°†è§†è§‰ä¿¡æ¯è½¬æ¢ä¸ºå‘é‡è¡¨ç¤ºã€‚4) è·¨æ¨¡æ€å¯¹é½æ¨¡å—ï¼šç”¨äºå°†ä¸åŒæ¨¡æ€çš„å‘é‡è¡¨ç¤ºæ˜ å°„åˆ°ç»Ÿä¸€çš„è¯­ä¹‰ç©ºé—´ã€‚5) æŒ‡ä»¤è°ƒä¼˜æ¨¡å—ï¼šä½¿ç”¨WaveMind-Instruct-338kæ•°æ®é›†è¿›è¡ŒæŒ‡ä»¤è°ƒä¼˜ï¼Œæå‡æ¨¡å‹çš„ä¼šè¯èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†å°†è„‘ç”µä¿¡å·ä¸å…¶ä»–æ¨¡æ€å¯¹é½çš„æ¡†æ¶ï¼Œå¹¶æ„å»ºäº†å¤§è§„æ¨¡çš„è·¨ä»»åŠ¡è„‘ç”µå›¾æ•°æ®é›†WaveMind-Instruct-338kã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨ä¸åŒæ¨¡æ€ä¹‹é—´çš„äº’è¡¥ä¿¡æ¯ï¼Œä»è€Œæé«˜è„‘ç”µä¿¡å·çš„è§£è¯»ç²¾åº¦å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å…·å¤‡ä¼šè¯èƒ½åŠ›ï¼Œå¯ä»¥è¿›è¡Œå¼€æ”¾å¼çš„è„‘ç”µå›¾ç›¸å…³å¯¹è¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è„‘ç”µä¿¡å·ç¼–ç å™¨æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æˆ–å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ç­‰ç»“æ„æ¥æå–è„‘ç”µä¿¡å·çš„ç‰¹å¾ã€‚åœ¨è·¨æ¨¡æ€å¯¹é½æ¨¡å—æ–¹é¢ï¼Œè®ºæ–‡å¯èƒ½é‡‡ç”¨äº†å¯¹æ¯”å­¦ä¹ æˆ–æ³¨æ„åŠ›æœºåˆ¶ç­‰æ–¹æ³•æ¥å®ç°ä¸åŒæ¨¡æ€ä¹‹é—´çš„å¯¹é½ã€‚WaveMind-Instruct-338kæ•°æ®é›†åŒ…å«äº†å¤šä¸ªè„‘ç”µå›¾ç›¸å…³çš„ä»»åŠ¡ï¼Œä¾‹å¦‚è„‘ç”µä¿¡å·åˆ†ç±»ã€äº‹ä»¶ç›¸å…³ç”µä½åˆ†æç­‰ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

WaveMindæ¨¡å‹åœ¨å››ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å‡ºé²æ£’çš„åˆ†ç±»ç²¾åº¦ï¼Œå¹¶æ”¯æŒçµæ´»ã€å¼€æ”¾å¼çš„å¯¹è¯ã€‚è¯¥æ¨¡å‹åœ¨è·¨ä»»åŠ¡è„‘ç”µå›¾æ•°æ®é›†WaveMind-Instruct-338kä¸Šè¿›è¡Œäº†æŒ‡ä»¤è°ƒä¼˜ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„ä¼šè¯èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¥ç»ç§‘å­¦ç ”ç©¶ã€è„‘æœºæ¥å£ã€ç²¾ç¥ç–¾ç—…è¯Šæ–­ç­‰é¢†åŸŸã€‚é€šè¿‡æ„å»ºé€šç”¨è„‘ç”µå›¾æ¨¡å‹ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°åˆ†æè„‘ç”µä¿¡å·ï¼Œä»è€Œæ·±å…¥äº†è§£å¤§è„‘æ´»åŠ¨ï¼Œå¼€å‘æ–°å‹è„‘æœºæ¥å£è®¾å¤‡ï¼Œå¹¶è¾…åŠ©ç²¾ç¥ç–¾ç—…çš„è¯Šæ–­å’Œæ²»ç–—ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„é¢†åŸŸï¼Œä¾‹å¦‚æ™ºèƒ½åº·å¤ã€æ•™è‚²ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Electroencephalography (EEG) interpretation using multimodal large language models (MLLMs) offers a novel approach for analyzing brain signals. However, the complex nature of brain activity introduces critical challenges: EEG signals simultaneously encode both cognitive processes and intrinsic neural states, creating a mismatch in EEG paired-data modality that hinders effective cross-modal representation learning. Through a pivot investigation, we uncover complementary relationships between these modalities. Leveraging this insight, we propose mapping EEG signals and their corresponding modalities into a unified semantic space to achieve generalized interpretation. To fully enable conversational capabilities, we further introduce WaveMind-Instruct-338k, the first cross-task EEG dataset for instruction tuning. The resulting model demonstrates robust classification accuracy while supporting flexible, open-ended conversations across four downstream tasks, thereby offering valuable insights for both neuroscience research and the development of general-purpose EEG models.

