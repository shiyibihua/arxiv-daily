---
layout: default
title: The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs through Model Merging
---

# The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs through Model Merging

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22034" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22034v2</a>
  <a href="https://arxiv.org/pdf/2509.22034.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22034v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22034v2', 'The Thinking Spectrum: An Empirical Study of Tunable Reasoning in LLMs through Model Merging')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaochong Lan, Yu Zheng, Shiteng Cao, Yong Li

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æ¨¡å‹èåˆå®ç°LLMå¯è°ƒæ¨ç†èƒ½åŠ›ï¼šå¤§è§„æ¨¡å®è¯ç ”ç©¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨¡å‹èåˆ` `å¯è°ƒæ¨ç†` `æ¨ç†èƒ½åŠ›` `tokenæ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMéš¾ä»¥åœ¨æ¨ç†æ·±åº¦å’Œè®¡ç®—æˆæœ¬é—´çµæ´»è°ƒæ•´ï¼Œç¼ºä¹é’ˆå¯¹ç‰¹å®šåº”ç”¨åœºæ™¯çš„å®šåˆ¶èƒ½åŠ›ã€‚
2. é€šè¿‡æ¨¡å‹èåˆï¼Œå°†é€šç”¨æ¨¡å‹ä¸ä¸“ç”¨æ¨ç†æ¨¡å‹æƒé‡èåˆï¼Œæ— éœ€è®­ç»ƒå³å¯è°ƒèŠ‚æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæ¨¡å‹èåˆèƒ½æœ‰æ•ˆå¹³è¡¡æ¨ç†ç²¾åº¦å’Œtokenæ•ˆç‡ï¼Œç”šè‡³å®ç°å¸•ç´¯æ‰˜æ”¹è¿›ï¼Œå³ç²¾åº¦æ›´é«˜ã€æ•ˆç‡æ›´é«˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æ»¡è¶³å®é™…åº”ç”¨ä¸­å¯¹å…·å¤‡å¯è°ƒæ¨ç†èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¥ç›Šå¢é•¿çš„éœ€æ±‚ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ–¹æ³•ï¼Œæ—¨åœ¨ç”Ÿæˆä¸€ç³»åˆ—åœ¨æ¨ç†æ·±åº¦å’Œè®¡ç®—æˆæœ¬ä¹‹é—´å–å¾—å¹³è¡¡çš„æ¨¡å‹ã€‚æ¨¡å‹èåˆæ˜¯ä¸€ç§æœ‰å‰æ™¯çš„å…è®­ç»ƒæŠ€æœ¯ï¼Œå®ƒé€šè¿‡ç®—æœ¯ç»„åˆé€šç”¨æ¨¡å‹å’Œä¸“ç”¨æ¨ç†æ¨¡å‹çš„æƒé‡æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚å°½ç®¡å­˜åœ¨å¤šç§èåˆæŠ€æœ¯ï¼Œä½†å®ƒä»¬åœ¨åˆ›å»ºèƒ½å¤Ÿå¯¹æ¨ç†èƒ½åŠ›è¿›è¡Œç»†ç²’åº¦æ§åˆ¶çš„æ¨¡å‹æ–¹é¢çš„æ½œåŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡è¿›è¡Œäº†ä¸€é¡¹å¤§è§„æ¨¡å®è¯ç ”ç©¶ï¼Œè¯„ä¼°äº†å„ç§æ¨¡å‹èåˆæŠ€æœ¯åœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šçš„è¡¨ç°ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°æ”¹å˜èåˆå¼ºåº¦ï¼Œæ„å»ºäº†ç²¾åº¦-æ•ˆç‡æ›²çº¿ï¼Œé¦–æ¬¡å…¨é¢å±•ç¤ºäº†å¯è°ƒæ€§èƒ½çš„æ ¼å±€ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå³ä½¿çˆ¶æ¨¡å‹çš„æƒé‡ç©ºé—´å·®å¼‚å¾ˆå¤§ï¼Œæ¨¡å‹èåˆä¹Ÿæä¾›äº†ä¸€ç§æœ‰æ•ˆä¸”å¯æ§çš„æ–¹æ³•æ¥æ ¡å‡†æ¨ç†ç²¾åº¦å’Œtokenæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬å‘ç°äº†å¸•ç´¯æ‰˜æ”¹è¿›çš„å®ä¾‹ï¼Œå³èåˆæ¨¡å‹å®ç°äº†æ¯”å…¶çˆ¶æ¨¡å‹æ›´é«˜çš„ç²¾åº¦å’Œæ›´ä½çš„tokenæ¶ˆè€—ã€‚æˆ‘ä»¬çš„ç ”ç©¶é¦–æ¬¡å¯¹è¿™ç§å¯è°ƒç©ºé—´è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œä¸ºåˆ›å»ºå…·æœ‰ç‰¹å®šæ¨ç†é…ç½®çš„LLMä»¥æ»¡è¶³ä¸åŒçš„åº”ç”¨éœ€æ±‚æä¾›äº†å®ç”¨çš„æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•é«˜æ•ˆåœ°æ„å»ºä¸€ç³»åˆ—å…·æœ‰å¯è°ƒæ¨ç†èƒ½åŠ›çš„å¤§è¯­è¨€æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰çš„æ–¹æ³•è¦ä¹ˆéœ€è¦é’ˆå¯¹æ¯ä¸ªæ¨ç†æ·±åº¦è¿›è¡Œå•ç‹¬è®­ç»ƒï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼›è¦ä¹ˆéš¾ä»¥åœ¨æ¨ç†ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œæ— æ³•æ»¡è¶³ä¸åŒåº”ç”¨åœºæ™¯çš„éœ€æ±‚ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨ç°æœ‰æ¨¡å‹ï¼Œå¿«é€Ÿç”Ÿæˆä¸€ç³»åˆ—å…·æœ‰ä¸åŒæ¨ç†èƒ½åŠ›çš„æ¨¡å‹ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ¨¡å‹èåˆæŠ€æœ¯ï¼Œé€šè¿‡ç®—æœ¯ç»„åˆé€šç”¨æ¨¡å‹å’Œä¸“ç”¨æ¨ç†æ¨¡å‹çš„æƒé‡ï¼Œä»è€Œåœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œè·å¾—å…·æœ‰ä¸åŒæ¨ç†èƒ½åŠ›çš„æ¨¡å‹ã€‚é€šè¿‡è°ƒæ•´èåˆçš„å¼ºåº¦ï¼Œå¯ä»¥æ§åˆ¶æ¨¡å‹çš„æ¨ç†æ·±åº¦å’Œè®¡ç®—æˆæœ¬ï¼Œä»è€Œå®ç°å¯è°ƒçš„æ¨ç†èƒ½åŠ›ã€‚è¿™ç§æ–¹æ³•é¿å…äº†ä»å¤´è®­ç»ƒå¤šä¸ªæ¨¡å‹çš„å·¨å¤§å¼€é”€ï¼Œå¹¶æä¾›äº†ä¸€ç§çµæ´»çš„æ–¹å¼æ¥å®šåˆ¶LLMçš„æ¨ç†è¡Œä¸ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©ä¸€ä¸ªé€šç”¨çš„å¤§è¯­è¨€æ¨¡å‹å’Œä¸€ä¸ªæˆ–å¤šä¸ªä¸“é—¨ç”¨äºæ¨ç†çš„æ¨¡å‹ï¼›2) é€‰æ‹©ä¸€ç§æ¨¡å‹èåˆæŠ€æœ¯ï¼Œä¾‹å¦‚çº¿æ€§æ’å€¼ï¼›3) é€šè¿‡è°ƒæ•´èåˆçš„æƒé‡ï¼Œç”Ÿæˆä¸€ç³»åˆ—èåˆæ¨¡å‹ï¼›4) åœ¨å¤šä¸ªæ¨ç†åŸºå‡†ä¸Šè¯„ä¼°è¿™äº›èåˆæ¨¡å‹çš„æ€§èƒ½ï¼ŒåŒ…æ‹¬æ¨ç†ç²¾åº¦å’Œtokenæ•ˆç‡ï¼›5) åˆ†æèåˆæ¨¡å‹çš„æ€§èƒ½æ›²çº¿ï¼Œæ‰¾åˆ°åœ¨ç²¾åº¦å’Œæ•ˆç‡ä¹‹é—´æœ€ä½³å¹³è¡¡ç‚¹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹æ¨¡å‹èåˆæŠ€æœ¯åœ¨å¯è°ƒæ¨ç†èƒ½åŠ›æ–¹é¢çš„æ½œåŠ›è¿›è¡Œäº†å…¨é¢çš„å®è¯ç ”ç©¶ã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦å…³æ³¨æ¨¡å‹èåˆåœ¨æå‡æ¨¡å‹æ€§èƒ½æ–¹é¢çš„åº”ç”¨ï¼Œè€Œå¿½ç•¥äº†å…¶åœ¨æ§åˆ¶æ¨¡å‹æ¨ç†è¡Œä¸ºæ–¹é¢çš„æ½œåŠ›ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿåœ°ç ”ç©¶äº†æ¨¡å‹èåˆçš„å¼ºåº¦ä¸æ¨ç†ç²¾åº¦å’Œtokenæ•ˆç‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶å‘ç°äº†å¸•ç´¯æ‰˜æ”¹è¿›çš„å®ä¾‹ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç³»ç»Ÿåœ°æ”¹å˜èåˆçš„æƒé‡ï¼Œæ„å»ºç²¾åº¦-æ•ˆç‡æ›²çº¿ï¼›2) ä½¿ç”¨å¤šä¸ªæ¨ç†åŸºå‡†æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼›3) é‡‡ç”¨tokenæ•ˆç‡ä½œä¸ºè¡¡é‡è®¡ç®—æˆæœ¬çš„æŒ‡æ ‡ï¼›4) æ¢ç´¢ä¸åŒçš„æ¨¡å‹èåˆæŠ€æœ¯ï¼Œä¾‹å¦‚çº¿æ€§æ’å€¼å’ŒTask Vector averaging (TVA)ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡å‹èåˆæ˜¯ä¸€ç§æœ‰æ•ˆä¸”å¯æ§çš„æ–¹æ³•ï¼Œå¯ä»¥æ ¡å‡†æ¨ç†ç²¾åº¦å’Œtokenæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œç ”ç©¶å‘ç°äº†å¸•ç´¯æ‰˜æ”¹è¿›çš„å®ä¾‹ï¼Œå³èåˆæ¨¡å‹å®ç°äº†æ¯”å…¶çˆ¶æ¨¡å‹æ›´é«˜çš„ç²¾åº¦å’Œæ›´ä½çš„tokenæ¶ˆè€—ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æ¨ç†ä»»åŠ¡ä¸Šï¼Œèåˆæ¨¡å‹åœ¨ç²¾åº¦æå‡5%çš„åŒæ—¶ï¼Œtokenæ¶ˆè€—é™ä½äº†10%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹èåˆä¸ä»…å¯ä»¥æé«˜æ¨¡å‹çš„æ€§èƒ½ï¼Œè¿˜å¯ä»¥é™ä½è®¡ç®—æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦ä¸åŒæ¨ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨é—®ç­”ã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡é€‰æ‹©åˆé€‚çš„èåˆæ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®å…·ä½“çš„åº”ç”¨éœ€æ±‚ï¼Œåœ¨æ¨ç†ç²¾åº¦å’Œè®¡ç®—æˆæœ¬ä¹‹é—´è¿›è¡Œæƒè¡¡ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¼€å‘æ›´çµæ´»ã€æ›´å¯å®šåˆ¶çš„å¤§è¯­è¨€æ¨¡å‹æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing demand for large language models (LLMs) with tunable reasoning capabilities in many real-world applications highlights a critical need for methods that can efficiently produce a spectrum of models balancing reasoning depth and computational cost. Model merging has emerged as a promising, training-free technique to address this challenge by arithmetically combining the weights of a general-purpose model with a specialized reasoning model. While various merging techniques exist, their potential to create a spectrum of models with fine-grained control over reasoning abilities remains largely unexplored. This work presents a large-scale empirical study evaluating a range of model merging techniques across multiple reasoning benchmarks. We systematically vary merging strengths to construct accuracy-efficiency curves, providing the first comprehensive view of the tunable performance landscape. Our findings reveal that model merging offers an effective and controllable method for calibrating the trade-off between reasoning accuracy and token efficiency, even when parent models have highly divergent weight spaces. Crucially, we identify instances of Pareto Improvement, where a merged model achieves both higher accuracy and lower token consumption than one of its parents. Our study provides the first comprehensive analysis of this tunable space, offering practical guidelines for creating LLMs with specific reasoning profiles to meet diverse application demands.

