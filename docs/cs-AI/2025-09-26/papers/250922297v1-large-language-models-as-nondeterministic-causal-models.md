---
layout: default
title: Large Language Models as Nondeterministic Causal Models
---

# Large Language Models as Nondeterministic Causal Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22297" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22297v1</a>
  <a href="https://arxiv.org/pdf/2509.22297.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22297v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22297v1', 'Large Language Models as Nondeterministic Causal Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sander Beckers

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

**å¤‡æ³¨**: Preprint: under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºéç¡®å®šæ€§å› æœæ¨¡å‹çš„å¤§è¯­è¨€æ¨¡å‹åäº‹å®ç”Ÿæˆæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `åäº‹å®ç”Ÿæˆ` `å› æœæ¨¡å‹` `éç¡®å®šæ€§` `è§£é‡Šæ€§` `é»‘ç›’æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåäº‹å®ç”Ÿæˆæ–¹æ³•å¯¹LLMçš„è§£é‡Šå­˜åœ¨æ­§ä¹‰ï¼Œæœªèƒ½å……åˆ†ä½“ç°LLMçš„éç¡®å®šæ€§æœ¬è´¨ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§æ›´ç®€å•çš„åäº‹å®ç”Ÿæˆæ–¹æ³•ï¼Œå°†LLMè§†ä¸ºéç¡®å®šæ€§å› æœæ¨¡å‹ï¼Œæ›´ç¬¦åˆLLMçš„é¢„æœŸè¯­ä¹‰ã€‚
3. æ–°æ–¹æ³•å¯ç›´æ¥åº”ç”¨äºä»»ä½•é»‘ç›’LLMï¼Œæ— éœ€ä¿®æ”¹ï¼Œä¸”ä¸ºç‰¹å®šåº”ç”¨çš„åäº‹å®ç”Ÿæˆå¥ å®šç†è®ºåŸºç¡€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Chatziç­‰äººå’ŒRavfogelç­‰äººæœ€è¿‘çš„å·¥ä½œé¦–æ¬¡å¼€å‘äº†ä¸€ç§ç”Ÿæˆæ¦‚ç‡å¤§è¯­è¨€æ¨¡å‹åäº‹å®çš„æ–¹æ³•ã€‚è¿™äº›åäº‹å®å‘Šè¯‰æˆ‘ä»¬ï¼Œå¦‚æœæŸä¸ªå®é™…æç¤º${f x}$å˜ä¸º${f x}^*$ï¼ŒLLMçš„è¾“å‡ºå°†ä¼šæ˜¯ä»€ä¹ˆæˆ–å¯èƒ½æ˜¯ä»€ä¹ˆã€‚ç”Ÿæˆæ­¤ç±»åäº‹å®çš„èƒ½åŠ›æ˜¯è§£é‡Šã€è¯„ä¼°å’Œæ¯”è¾ƒLLMè¡Œä¸ºçš„é‡è¦å¿…è¦æ­¥éª¤ã€‚ç„¶è€Œï¼Œæˆ‘è®¤ä¸ºç°æœ‰æ–¹æ³•å¯¹LLMçš„è§£é‡Šå­˜åœ¨æ­§ä¹‰ï¼šå®ƒæ²¡æœ‰ä»å­—é¢ä¸Šè§£é‡ŠLLMï¼Œå› ä¸ºå®ƒå‡è®¾å¯ä»¥æ”¹å˜LLMé‡‡æ ·è¿‡ç¨‹çš„å®ç°è€Œä¸æ”¹å˜LLMæœ¬èº«ï¼›å®ƒä¹Ÿæ²¡æœ‰æŒ‰ç…§é¢„æœŸè§£é‡ŠLLMï¼Œå› ä¸ºå®ƒæ˜ç¡®åœ°å°†éç¡®å®šæ€§LLMè¡¨ç¤ºä¸ºç¡®å®šæ€§å› æœæ¨¡å‹ã€‚æˆ‘åœ¨è¿™é‡Œæå‡ºäº†ä¸€ç§æ›´ç®€å•çš„ç”Ÿæˆåäº‹å®çš„æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŸºäºLLMçš„é¢„æœŸè§£é‡Šï¼Œå°†å…¶è¡¨ç¤ºä¸ºéç¡®å®šæ€§å› æœæ¨¡å‹ã€‚æˆ‘çš„æ›´ç®€å•æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å®ƒå¯ä»¥ç›´æ¥åº”ç”¨äºä»»ä½•é»‘ç›’LLMè€Œæ— éœ€ä¿®æ”¹ï¼Œå› ä¸ºå®ƒä¸ä»»ä½•å®ç°ç»†èŠ‚æ— å…³ã€‚å¦ä¸€æ–¹é¢ï¼Œç°æœ‰æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å®ƒç›´æ¥å®ç°äº†ç‰¹å®šç±»å‹åäº‹å®çš„ç”Ÿæˆï¼Œè¿™ç§åäº‹å®å¯¹äºæŸäº›ç›®çš„æœ‰ç”¨ï¼Œä½†å¯¹äºå…¶ä»–ç›®çš„åˆ™ä¸ç„¶ã€‚æˆ‘é€šè¿‡æä¾›ä¸€ä¸ªåŸºäºLLMé¢„æœŸè¯­ä¹‰çš„æ¨ç†åäº‹å®çš„ç†è®ºåŸºç¡€æ¥é˜æ˜è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œä¸ºç”Ÿæˆåäº‹å®çš„æ–°å‹ç‰¹å®šåº”ç”¨æ–¹æ³•å¥ å®šåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨ç”ŸæˆLLMçš„åäº‹å®æ—¶ï¼Œè¦ä¹ˆå‡è®¾å¯ä»¥æ”¹å˜LLMçš„å®ç°ç»†èŠ‚è€Œä¸æ”¹å˜LLMæœ¬èº«ï¼Œè¦ä¹ˆå°†éç¡®å®šæ€§çš„LLMè¡¨ç¤ºä¸ºç¡®å®šæ€§çš„å› æœæ¨¡å‹ï¼Œè¿™ä¸¤ç§æ–¹å¼éƒ½æœªèƒ½å‡†ç¡®åæ˜ LLMçš„æœ¬è´¨ç‰¹æ€§ï¼Œå¯¼è‡´åäº‹å®ç”Ÿæˆç»“æœå¯èƒ½å­˜åœ¨åå·®ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¯¹LLMå†…éƒ¨æœºåˆ¶çš„å‡è®¾ï¼Œé™åˆ¶äº†å…¶é€šç”¨æ€§å’Œé€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMè§†ä¸ºä¸€ä¸ªéç¡®å®šæ€§çš„å› æœæ¨¡å‹ã€‚è¿™æ„å‘³ç€LLMçš„è¾“å‡ºä¸ä»…ä»…ç”±è¾“å…¥å†³å®šï¼Œè¿˜å—åˆ°å†…åœ¨éšæœºæ€§çš„å½±å“ã€‚é€šè¿‡ç›´æ¥å¯¹è¿™ç§éç¡®å®šæ€§è¿›è¡Œå»ºæ¨¡ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°ç”Ÿæˆåäº‹å®ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£LLMçš„è¡Œä¸ºã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹LLMå†…éƒ¨å®ç°çš„å‡è®¾ï¼Œä½¿å…¶æ›´å…·é€šç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå°†LLMè§†ä¸ºä¸€ä¸ªé»‘ç›’ï¼Œå¹¶é€šè¿‡å¯¹å…¶è¾“å…¥å’Œè¾“å‡ºè¿›è¡Œè§‚å¯Ÿæ¥æ¨æ–­å…¶å› æœå…³ç³»ã€‚å…·ä½“æµç¨‹åŒ…æ‹¬ï¼š1) ç»™å®šä¸€ä¸ªè¾“å…¥æç¤ºï¼›2) LLMç”Ÿæˆä¸€ä¸ªè¾“å‡ºï¼›3) å¯¹è¾“å…¥æç¤ºè¿›è¡Œåäº‹å®ä¿®æ”¹ï¼›4) LLMç”Ÿæˆæ–°çš„è¾“å‡ºï¼›5) åˆ†æä¸¤ä¸ªè¾“å‡ºä¹‹é—´çš„å·®å¼‚ï¼Œä»è€Œç†è§£è¾“å…¥ä¿®æ”¹å¯¹è¾“å‡ºçš„å½±å“ã€‚æ•´ä¸ªè¿‡ç¨‹æ— éœ€è®¿é—®LLMçš„å†…éƒ¨å‚æ•°æˆ–ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMè§†ä¸ºéç¡®å®šæ€§å› æœæ¨¡å‹ï¼Œå¹¶åŸºäºæ­¤æå‡ºäº†ä¸€ç§ç®€å•ä¸”é€šç”¨çš„åäº‹å®ç”Ÿæˆæ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦å¯¹LLMçš„å†…éƒ¨å®ç°è¿›è¡Œå‡è®¾ï¼Œå› æ­¤å¯ä»¥åº”ç”¨äºä»»ä½•é»‘ç›’LLMã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¸ºåŸºäºLLMé¢„æœŸè¯­ä¹‰çš„åäº‹å®æ¨ç†æä¾›äº†ç†è®ºåŸºç¡€ï¼Œä¸ºå¼€å‘ç‰¹å®šåº”ç”¨çš„åäº‹å®ç”Ÿæˆæ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚

**å…³é”®è®¾è®¡**ï¼šç”±äºè¯¥æ–¹æ³•å°†LLMè§†ä¸ºé»‘ç›’ï¼Œå› æ­¤ä¸éœ€è¦ç‰¹å®šçš„å‚æ•°è®¾ç½®æˆ–ç½‘ç»œç»“æ„ã€‚å…³é”®åœ¨äºå¦‚ä½•è®¾è®¡åäº‹å®ä¿®æ”¹ï¼Œä»¥åŠå¦‚ä½•åˆ†æä¿®æ”¹åçš„è¾“å‡ºä¸åŸå§‹è¾“å‡ºä¹‹é—´çš„å·®å¼‚ã€‚å…·ä½“çš„è®¾è®¡å–å†³äºå…·ä½“çš„åº”ç”¨åœºæ™¯å’Œéœ€è¦åˆ†æçš„å› æœå…³ç³»ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥é‡‡ç”¨ä¸åŒçš„åäº‹å®ä¿®æ”¹ç­–ç•¥ï¼Œå¦‚è¯è¯­æ›¿æ¢ã€å¥å­åˆ é™¤ç­‰ï¼Œå¹¶ä½¿ç”¨ä¸åŒçš„æŒ‡æ ‡æ¥è¡¡é‡è¾“å‡ºçš„å·®å¼‚ï¼Œå¦‚BLEU scoreã€ROUGE scoreç­‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ä¸€ç§æ›´ç®€å•ã€æ›´é€šç”¨çš„åäº‹å®ç”Ÿæˆæ–¹æ³•ï¼Œæ— éœ€ä¿®æ”¹å³å¯åº”ç”¨äºä»»ä½•é»‘ç›’LLMã€‚è¯¥æ–¹æ³•åŸºäºLLMçš„é¢„æœŸè¯­ä¹‰ï¼Œå°†å…¶è¡¨ç¤ºä¸ºéç¡®å®šæ€§å› æœæ¨¡å‹ï¼Œé¿å…äº†å¯¹LLMå†…éƒ¨å®ç°çš„å‡è®¾ã€‚è™½ç„¶è®ºæ–‡æ²¡æœ‰æä¾›å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†å¼ºè°ƒäº†è¯¥æ–¹æ³•ä¸ºç‰¹å®šåº”ç”¨çš„åäº‹å®ç”Ÿæˆå¥ å®šäº†ç†è®ºåŸºç¡€ï¼Œå¹¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºLLMçš„è§£é‡Šæ€§åˆ†æã€å®‰å…¨æ€§è¯„ä¼°å’Œå…¬å¹³æ€§æ”¹è¿›ã€‚é€šè¿‡ç”Ÿæˆåäº‹å®ï¼Œå¯ä»¥ç†è§£LLMåœ¨ä¸åŒè¾“å…¥ä¸‹çš„è¡Œä¸ºï¼Œå‘ç°æ½œåœ¨çš„åè§å’Œæ¼æ´ï¼Œå¹¶é’ˆå¯¹æ€§åœ°è¿›è¡Œæ”¹è¿›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæ¯”è¾ƒä¸åŒLLMçš„æ€§èƒ½å’Œè¡Œä¸ºå·®å¼‚ï¼Œä¸ºLLMçš„é€‰å‹å’Œä¼˜åŒ–æä¾›ä¾æ®ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ›´å¹¿æ³›çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first time, a method for generating counterfactuals of probabilistic Large Language Models. Such counterfactuals tell us what would - or might - have been the output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead. The ability to generate such counterfactuals is an important necessary step towards explaining, evaluating, and comparing, the behavior of LLMs. I argue, however, that the existing method rests on an ambiguous interpretation of LLMs: it does not interpret LLMs literally, for the method involves the assumption that one can change the implementation of an LLM's sampling process without changing the LLM itself, nor does it interpret LLMs as intended, for the method involves explicitly representing a nondeterministic LLM as a deterministic causal model. I here present a much simpler method for generating counterfactuals that is based on an LLM's intended interpretation by representing it as a nondeterministic causal model instead. The advantage of my simpler method is that it is directly applicable to any black-box LLM without modification, as it is agnostic to any implementation details. The advantage of the existing method, on the other hand, is that it directly implements the generation of a specific type of counterfactuals that is useful for certain purposes, but not for others. I clarify how both methods relate by offering a theoretical foundation for reasoning about counterfactuals in LLMs based on their intended semantics, thereby laying the groundwork for novel application-specific methods for generating counterfactuals.

