---
layout: default
title: REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model
---

# REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22518" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22518v1</a>
  <a href="https://arxiv.org/pdf/2509.22518.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22518v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22518v1', 'REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bo Li, Guanzhi Deng, Ronghao Chen, Junrong Yue, Shuo Zhang, Qinghua Zhao, Linqi Song, Lijie Wen

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**REMAï¼šç»Ÿä¸€çš„æ¨ç†æµå½¢æ¡†æ¶ï¼Œç”¨äºè§£é‡Šå¤§å‹è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¯è§£é‡Šæ€§` `æ¨ç†æµå½¢` `å‡ ä½•åˆ†æ` `æ¨ç†å¤±è´¥åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†è¿‡ç¨‹å¤æ‚ä¸”éš¾ä»¥ç†è§£ï¼Œç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„å‡ ä½•åˆ†æè§†è§’ã€‚
2. REMAæ¡†æ¶é€šè¿‡æ„å»ºâ€œæ¨ç†æµå½¢â€æ¦‚å¿µï¼Œå°†æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å‡ ä½•ç»“æ„ä¸æ¨ç†æˆåŠŸä¸å¦è”ç³»èµ·æ¥ã€‚
3. å®éªŒè¯æ˜REMAèƒ½æœ‰æ•ˆå®šä½æ¨ç†å¤±è´¥çš„èµ·å§‹å±‚ï¼Œæ­ç¤ºé”™è¯¯æ¨ç†çš„æ ¹æºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ‰§è¡Œå¤æ‚æ¨ç†çš„æ–¹å¼åŠå…¶å¤±è´¥æœºåˆ¶æ˜¯å¯è§£é‡Šæ€§ç ”ç©¶ä¸­çš„ä¸€é¡¹æŒ‘æˆ˜ã€‚ä¸ºäº†æä¾›å¯æµ‹é‡çš„å‡ ä½•åˆ†æè§†è§’ï¼Œæˆ‘ä»¬å®šä¹‰äº†æ¨ç†æµå½¢çš„æ¦‚å¿µï¼Œè¿™æ˜¯ä¸€ç§ç”±ä¸æ‰€æœ‰æ­£ç¡®æ¨ç†ç”Ÿæˆç›¸å¯¹åº”çš„å†…éƒ¨è¡¨ç¤ºå½¢æˆçš„æ½œåœ¨ä½ç»´å‡ ä½•ç»“æ„ã€‚è¿™ç§ç»“æ„å¯ä»¥è¢«æ¦‚å¿µåŒ–ä¸ºæ¨¡å‹å·²å­¦ä¹ æˆåŠŸè§£å†³ç»™å®šä»»åŠ¡çš„æœ‰æ•ˆæ€ç»´è·¯å¾„çš„ä½“ç°ã€‚åŸºäºæ­¤æ¦‚å¿µï¼Œæˆ‘ä»¬æ„å»ºäº†REMAæ¡†æ¶ï¼Œé€šè¿‡å®šé‡æ¯”è¾ƒä¸é”™è¯¯å’Œæ­£ç¡®æ¨ç†æ ·æœ¬ç›¸å¯¹åº”çš„å†…éƒ¨æ¨¡å‹è¡¨ç¤ºçš„ç©ºé—´å…³ç³»æ¥è§£é‡Šå¤±è´¥çš„æ ¹æºã€‚å…·ä½“æ¥è¯´ï¼ŒREMAé¦–å…ˆé€šè¿‡è®¡ç®—æ¯ä¸ªé”™è¯¯è¡¨ç¤ºåˆ°ç”±æ­£ç¡®è¡¨ç¤ºè¿‘ä¼¼å½¢æˆçš„æµå½¢çš„kè¿‘é‚»è·ç¦»æ¥é‡åŒ–å…¶å‡ ä½•åå·®ï¼Œä»è€Œæä¾›ç»Ÿä¸€çš„å¤±è´¥ä¿¡å·ã€‚ç„¶åï¼Œé€šè¿‡è·Ÿè¸ªæ¨¡å‹å„å±‚ä¸­çš„è¿™ç§åå·®æŒ‡æ ‡ï¼Œå¹¶å°†å…¶ä¸æ¥è‡ªæ­£ç¡®è¡¨ç¤ºçš„å†…éƒ¨æ³¢åŠ¨åŸºçº¿è¿›è¡Œæ¯”è¾ƒï¼Œæ¥å®šä½è¿™äº›åå·®é¦–æ¬¡å˜å¾—æ˜¾è‘—çš„å‘æ•£ç‚¹ï¼Œä»è€Œè¯†åˆ«æ¨ç†é“¾å¼€å§‹åç¦»æ­£è½¨çš„ä½ç½®ã€‚æˆ‘ä»¬åœ¨å„ç§è¯­è¨€å’Œå¤šæ¨¡æ€æ¨¡å‹åŠä»»åŠ¡ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æ¨ç†æµå½¢çš„ä½ç»´æ€§è´¨ä»¥åŠé”™è¯¯å’Œæ­£ç¡®æ¨ç†è¡¨ç¤ºä¹‹é—´çš„é«˜åº¦å¯åˆ†ç¦»æ€§ã€‚ç»“æœè¿˜éªŒè¯äº†REMAæ¡†æ¶åœ¨åˆ†ææ¨ç†å¤±è´¥æ ¹æºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¿™é¡¹ç ”ç©¶å°†æŠ½è±¡çš„æ¨ç†å¤±è´¥ä¸è¡¨ç¤ºä¸­å¯æµ‹é‡çš„å‡ ä½•åå·®è”ç³»èµ·æ¥ï¼Œä¸ºæ·±å…¥ç†è§£å’Œè¯Šæ–­é»‘ç›’æ¨¡å‹çš„å†…éƒ¨è®¡ç®—è¿‡ç¨‹æä¾›äº†æ–°çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¤æ‚æ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥ç†è§£LLMså¦‚ä½•è¿›è¡Œæ¨ç†ä»¥åŠæ¨ç†å¤±è´¥çš„åŸå› ï¼Œç¼ºä¹ä¸€ç§æœ‰æ•ˆçš„ã€å¯é‡åŒ–çš„åˆ†ææ¡†æ¶æ¥è¯Šæ–­å’Œå®šä½æ¨ç†é”™è¯¯ã€‚ç°æœ‰æ–¹æ³•æ— æ³•å°†æŠ½è±¡çš„æ¨ç†è¿‡ç¨‹ä¸æ¨¡å‹å†…éƒ¨çš„è¡¨ç¤ºè”ç³»èµ·æ¥ï¼Œéš¾ä»¥æ·±å…¥ç†è§£LLMsçš„å†…éƒ¨è®¡ç®—è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMsçš„æ¨ç†è¿‡ç¨‹æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ä¸­çš„å‡ ä½•ç»“æ„ï¼Œå³â€œæ¨ç†æµå½¢â€ã€‚å‡è®¾æ­£ç¡®çš„æ¨ç†è¿‡ç¨‹å¯¹åº”äºæµå½¢ä¸Šçš„ç‚¹ï¼Œè€Œé”™è¯¯çš„æ¨ç†è¿‡ç¨‹åˆ™åç¦»è¯¥æµå½¢ã€‚é€šè¿‡åˆ†æé”™è¯¯æ¨ç†è¡¨ç¤ºä¸æ­£ç¡®æ¨ç†æµå½¢çš„å‡ ä½•åå·®ï¼Œå¯ä»¥é‡åŒ–æ¨ç†é”™è¯¯çš„ç¨‹åº¦ï¼Œå¹¶å®šä½æ¨ç†é“¾ä¸­å¼€å§‹å‡ºé”™çš„ä½ç½®ã€‚è¿™ç§å‡ ä½•åˆ†ææ–¹æ³•æä¾›äº†ä¸€ç§æ–°çš„è§†è§’æ¥ç†è§£LLMsçš„æ¨ç†è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šREMAæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ­¥éª¤ï¼š1) æ„å»ºæ¨ç†æµå½¢ï¼šæ”¶é›†LLMåœ¨ç‰¹å®šä»»åŠ¡ä¸Šæ­£ç¡®æ¨ç†çš„å†…éƒ¨è¡¨ç¤ºï¼Œå¹¶ä½¿ç”¨é™ç»´æŠ€æœ¯ï¼ˆå¦‚PCAï¼‰è¿‘ä¼¼æ„å»ºæ¨ç†æµå½¢ã€‚2) è®¡ç®—å‡ ä½•åå·®ï¼šå¯¹äºæ¯ä¸ªé”™è¯¯æ¨ç†çš„å†…éƒ¨è¡¨ç¤ºï¼Œè®¡ç®—å…¶åˆ°æ¨ç†æµå½¢çš„kè¿‘é‚»è·ç¦»ï¼Œä½œä¸ºå‡ ä½•åå·®çš„åº¦é‡ã€‚3) å®šä½å‘æ•£ç‚¹ï¼šåœ¨LLMçš„å„å±‚ä¸­è·Ÿè¸ªå‡ ä½•åå·®çš„å˜åŒ–ï¼Œå¹¶ä¸æ­£ç¡®æ¨ç†çš„å†…éƒ¨æ³¢åŠ¨åŸºçº¿è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®å®šåå·®é¦–æ¬¡å˜å¾—æ˜¾è‘—çš„å±‚ï¼Œå³æ¨ç†é“¾å¼€å§‹åç¦»æ­£è½¨çš„ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šREMAæ¡†æ¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†â€œæ¨ç†æµå½¢â€çš„æ¦‚å¿µï¼Œå°†æŠ½è±¡çš„æ¨ç†è¿‡ç¨‹ä¸æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å‡ ä½•ç»“æ„è”ç³»èµ·æ¥ã€‚2) æä¾›äº†ä¸€ç§é‡åŒ–æ¨ç†é”™è¯¯ç¨‹åº¦çš„å‡ ä½•åå·®åº¦é‡ã€‚3) å¼€å‘äº†ä¸€ç§å®šä½æ¨ç†é“¾ä¸­é”™è¯¯èµ·å§‹ä½ç½®çš„æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒREMAæä¾›äº†ä¸€ç§æ›´ç›´è§‚ã€æ›´å¯è§£é‡Šçš„æ–¹å¼æ¥ç†è§£LLMsçš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šREMAæ¡†æ¶çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨kè¿‘é‚»è·ç¦»ä½œä¸ºå‡ ä½•åå·®çš„åº¦é‡ï¼Œå¯ä»¥æœ‰æ•ˆæ•æ‰é”™è¯¯æ¨ç†è¡¨ç¤ºä¸æ­£ç¡®æ¨ç†æµå½¢çš„å·®å¼‚ã€‚2) é€šè¿‡æ¯”è¾ƒå„å±‚çš„å‡ ä½•åå·®ä¸å†…éƒ¨æ³¢åŠ¨åŸºçº¿ï¼Œå¯ä»¥æœ‰æ•ˆå®šä½æ¨ç†é“¾ä¸­é”™è¯¯èµ·å§‹ä½ç½®ã€‚3) ä½¿ç”¨PCAç­‰é™ç»´æŠ€æœ¯æ¥è¿‘ä¼¼æ„å»ºæ¨ç†æµå½¢ï¼Œé™ä½è®¡ç®—å¤æ‚åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼š1) æ¨ç†æµå½¢å…·æœ‰ä½ç»´æ€§è´¨ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶çš„ç†è®ºåŸºç¡€ã€‚2) é”™è¯¯å’Œæ­£ç¡®æ¨ç†è¡¨ç¤ºä¹‹é—´å…·æœ‰é«˜åº¦å¯åˆ†ç¦»æ€§ï¼Œè¡¨æ˜å‡ ä½•åå·®å¯ä»¥æœ‰æ•ˆåŒºåˆ†ä¸¤è€…ã€‚3) REMAæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå®šä½æ¨ç†å¤±è´¥çš„èµ·å§‹å±‚ï¼Œä¸ºè¯Šæ–­å’Œæ”¹è¿›LLMæä¾›äº†æœ‰åŠ›çš„å·¥å…·ã€‚è¯¥æ¡†æ¶åœ¨å¤šç§è¯­è¨€å’Œå¤šæ¨¡æ€æ¨¡å‹åŠä»»åŠ¡ä¸Šéƒ½å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

REMAæ¡†æ¶å¯åº”ç”¨äºå„ç§LLMçš„è¯Šæ–­å’Œæ”¹è¿›ï¼Œä¾‹å¦‚ï¼š1) è¯„ä¼°LLMåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚2) è¯Šæ–­LLMçš„æ¨ç†ç¼ºé™·ï¼Œå¹¶æŒ‡å¯¼æ¨¡å‹æ”¹è¿›ã€‚3) å¼€å‘æ›´å¯é ã€æ›´å¯ä¿¡èµ–çš„LLMã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜å¯ä»¥ç”¨äºç ”ç©¶LLMçš„å†…éƒ¨å·¥ä½œæœºåˆ¶ï¼Œä¿ƒè¿›å¯è§£é‡Šæ€§AIçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding how Large Language Models (LLMs) perform complex reasoning and their failure mechanisms is a challenge in interpretability research. To provide a measurable geometric analysis perspective, we define the concept of the Reasoning Manifold, a latent low-dimensional geometric structure formed by the internal representations corresponding to all correctly reasoned generations. This structure can be conceptualized as the embodiment of the effective thinking paths that the model has learned to successfully solve a given task. Based on this concept, we build REMA, a framework that explains the origins of failures by quantitatively comparing the spatial relationships of internal model representations corresponding to both erroneous and correct reasoning samples. Specifically, REMA first quantifies the geometric deviation of each erroneous representation by calculating its k-nearest neighbors distance to the approximated manifold formed by correct representations, thereby providing a unified failure signal. It then localizes the divergence points where these deviations first become significant by tracking this deviation metric across the model's layers and comparing it against a baseline of internal fluctuations from correct representations, thus identifying where the reasoning chain begins to go off-track. Our extensive experiments on diverse language and multimodal models and tasks demonstrate the low-dimensional nature of the reasoning manifold and the high separability between erroneous and correct reasoning representations. The results also validate the effectiveness of the REMA framework in analyzing the origins of reasoning failures. This research connects abstract reasoning failures to measurable geometric deviations in representations, providing new avenues for in-depth understanding and diagnosis of the internal computational processes of black-box models.

