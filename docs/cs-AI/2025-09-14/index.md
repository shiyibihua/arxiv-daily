---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.AI - 2025-09-14
---

# cs.AIï¼ˆ2025-09-14ï¼‰

ğŸ“Š å…± **7** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (7)</a>
</div>

---


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (7 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250913351v1-teaching-llms-to-plan-logical-chain-of-thought-instruction-tuning-fo.html">Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning</a></td>
  <td>æå‡ºPDDL-Instructæ¡†æ¶ï¼Œé€šè¿‡é€»è¾‘é“¾å¼æ€ç»´æŒ‡ä»¤è°ƒä¼˜æå‡LLMçš„ç¬¦å·è§„åˆ’èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.13351v1" data-paper-url="./papers/250913351v1-teaching-llms-to-plan-logical-chain-of-thought-instruction-tuning-fo.html" onclick="toggleFavorite(this, '2509.13351v1', 'Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250919330v2-libemer-a-novel-benchmark-and-algorithms-library-for-eeg-based-multi.html">LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition</a></td>
  <td>LibEMERï¼šç”¨äºè„‘ç”µå¤šæ¨¡æ€æƒ…æ„Ÿè¯†åˆ«çš„åŸºå‡†æµ‹è¯•ä¸ç®—æ³•åº“</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.19330v2" data-paper-url="./papers/250919330v2-libemer-a-novel-benchmark-and-algorithms-library-for-eeg-based-multi.html" onclick="toggleFavorite(this, '2509.19330v2', 'LibEMER: A novel benchmark and algorithms library for EEG-based Multimodal Emotion Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250911068v1-tractable-asymmetric-verification-for-large-language-models-via-dete.html">Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability</a></td>
  <td>æå‡ºåŸºäºç¡®å®šæ€§å¯å¤åˆ¶æ€§çš„LLMéå¯¹ç§°éªŒè¯æ¡†æ¶ï¼Œé™ä½éªŒè¯æˆæœ¬ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.11068v1" data-paper-url="./papers/250911068v1-tractable-asymmetric-verification-for-large-language-models-via-dete.html" onclick="toggleFavorite(this, '2509.11068v1', 'Tractable Asymmetric Verification for Large Language Models via Deterministic Replicability')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250912273v1-llmap-llm-assisted-multi-objective-route-planning-with-user-preferen.html">LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences</a></td>
  <td>LLMAPï¼šåŸºäºLLMè¾…åŠ©çš„å¤šç›®æ ‡ä¸ªæ€§åŒ–è·¯çº¿è§„åˆ’ç³»ç»Ÿ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.12273v1" data-paper-url="./papers/250912273v1-llmap-llm-assisted-multi-objective-route-planning-with-user-preferen.html" onclick="toggleFavorite(this, '2509.12273v1', 'LLMAP: LLM-Assisted Multi-Objective Route Planning with User Preferences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250911079v4-difficulty-aware-agentic-orchestration-for-query-specific-multi-agen.html">Difficulty-Aware Agentic Orchestration for Query-Specific Multi-Agent Workflows</a></td>
  <td>æå‡ºéš¾åº¦æ„ŸçŸ¥Agentç¼–æ’æ¡†æ¶ï¼Œä¸ºæŸ¥è¯¢å®šåˆ¶é«˜æ•ˆå¤šAgentå·¥ä½œæµ</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.11079v4" data-paper-url="./papers/250911079v4-difficulty-aware-agentic-orchestration-for-query-specific-multi-agen.html" onclick="toggleFavorite(this, '2509.11079v4', 'Difficulty-Aware Agentic Orchestration for Query-Specific Multi-Agent Workflows')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251021715v1-beyond-ivr-touch-tones-customer-intent-routing-using-llms.html">Beyond IVR Touch-Tones: Customer Intent Routing using LLMs</a></td>
  <td>æå‡ºåŸºäºLLMçš„IVRå®¢æˆ·æ„å›¾è·¯ç”±æ–¹æ³•ï¼Œè§£å†³æ•°æ®ç¨€ç¼ºé—®é¢˜å¹¶æå‡ç”¨æˆ·ä½“éªŒã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.21715v1" data-paper-url="./papers/251021715v1-beyond-ivr-touch-tones-customer-intent-routing-using-llms.html" onclick="toggleFavorite(this, '2510.21715v1', 'Beyond IVR Touch-Tones: Customer Intent Routing using LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250911035v1-free-mad-consensus-free-multi-agent-debate.html">Free-MAD: Consensus-Free Multi-Agent Debate</a></td>
  <td>æå‡ºFree-MADï¼Œä¸€ç§æ— éœ€å…±è¯†çš„å¤šæ™ºèƒ½ä½“è¾©è®ºæ¡†æ¶ï¼Œæå‡LLMæ¨ç†èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.11035v1" data-paper-url="./papers/250911035v1-free-mad-consensus-free-multi-agent-debate.html" onclick="toggleFavorite(this, '2509.11035v1', 'Free-MAD: Consensus-Free Multi-Agent Debate')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.AI é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)