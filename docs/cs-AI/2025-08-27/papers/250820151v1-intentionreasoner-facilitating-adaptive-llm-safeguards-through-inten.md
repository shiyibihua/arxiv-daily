---
layout: default
title: IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement
---

# IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20151" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20151v1</a>
  <a href="https://arxiv.org/pdf/2508.20151.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20151v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20151v1', 'IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuanzhe Shen, Zisu Huang, Zhengkang Guo, Yide Liu, Guanxu Chen, Ruicheng Yin, Xiaoqing Zheng, Xuanjing Huang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 17 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIntentionReasonerä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å®‰å…¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å®‰å…¨æœºåˆ¶` `æ„å›¾æ¨ç†` `æŸ¥è¯¢é‡å†™` `å¼ºåŒ–å­¦ä¹ ` `å¤šå¥–åŠ±ä¼˜åŒ–` `ç”Ÿæˆè´¨é‡` `è¿‡åº¦æ‹’ç»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å®‰å…¨æ€§ä¸å®ç”¨æ€§ä¹‹é—´éš¾ä»¥å¹³è¡¡ï¼Œå¯¼è‡´æ— å®³æç¤ºè¢«è¿‡åº¦æ‹’ç»ã€‚
2. æå‡ºçš„IntentionReasoneré€šè¿‡æ„å›¾æ¨ç†å’ŒæŸ¥è¯¢é‡å†™ï¼Œå¢å¼ºäº†æ¨¡å‹å¯¹æ½œåœ¨æœ‰å®³æ„å›¾çš„è¯†åˆ«ä¸å¤„ç†èƒ½åŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒIntentionReasoneråœ¨å®‰å…¨æ€§å’Œç”Ÿæˆè´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œé™ä½äº†è¿‡åº¦æ‹’ç»ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå…¶åœ¨å„ä¸ªé¢†åŸŸçš„åº”ç”¨æ—¥ç›Šå¹¿æ³›ï¼Œä½†ç”Ÿæˆæœ‰å®³å†…å®¹çš„èƒ½åŠ›å¸¦æ¥äº†æ˜¾è‘—çš„å®‰å…¨æŒ‘æˆ˜ã€‚å°½ç®¡å·²æœ‰å¤§é‡ç ”ç©¶è‡´åŠ›äºå‡è½»æœ‰å®³è¾“å‡ºï¼Œä½†è¿™äº›åŠªåŠ›å¾€å¾€å¯¼è‡´æ— å®³æç¤ºè¢«è¿‡åº¦æ‹’ç»ã€‚æœ¬æ–‡æå‡ºIntentionReasonerï¼Œä¸€ç§æ–°é¢–çš„å®‰å…¨æœºåˆ¶ï¼Œåˆ©ç”¨ä¸“é—¨çš„å®ˆæŠ¤æ¨¡å‹è¿›è¡Œæ„å›¾æ¨ç†ã€å¤šå±‚æ¬¡å®‰å…¨åˆ†ç±»å’ŒæŸ¥è¯¢é‡å†™ï¼Œä»¥ä¸­å’Œè¾¹ç¼˜æ¡ˆä¾‹æŸ¥è¯¢ä¸­çš„æ½œåœ¨æœ‰å®³æ„å›¾ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«çº¦163,000ä¸ªæŸ¥è¯¢çš„ç»¼åˆæ•°æ®é›†ï¼Œå¹¶å¯¹å®ˆæŠ¤æ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒã€‚æœ€ç»ˆï¼Œé€šè¿‡å®šåˆ¶çš„å¤šå¥–åŠ±ä¼˜åŒ–ç­–ç•¥ï¼Œè¿›ä¸€æ­¥æå‡äº†æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIntentionReasoneråœ¨å¤šä¸ªå®‰å…¨åŸºå‡†ã€ç”Ÿæˆè´¨é‡è¯„ä¼°å’Œè¶Šç‹±æ”»å‡»åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æé«˜äº†å®‰å…¨æ€§ï¼ŒåŒæ—¶æœ‰æ•ˆé™ä½äº†è¿‡åº¦æ‹’ç»ç‡å¹¶æ”¹å–„äº†å“åº”è´¨é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå†…å®¹æ—¶å¯èƒ½äº§ç”Ÿçš„æœ‰å®³è¾“å‡ºé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€åœ¨å®‰å…¨æ€§ä¸å®ç”¨æ€§ä¹‹é—´å­˜åœ¨çŸ›ç›¾ï¼Œå¯¼è‡´æ— å®³æç¤ºè¢«è¿‡åº¦æ‹’ç»ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šIntentionReasoneré€šè¿‡æ„å»ºä¸€ä¸ªä¸“é—¨çš„å®ˆæŠ¤æ¨¡å‹ï¼Œè¿›è¡Œæ„å›¾æ¨ç†å’Œå¤šå±‚æ¬¡å®‰å…¨åˆ†ç±»ï¼Œç»“åˆæŸ¥è¯¢é‡å†™æŠ€æœ¯ï¼Œæ—¨åœ¨ä¸­å’Œæ½œåœ¨çš„æœ‰å®³æ„å›¾ï¼Œä»è€Œæé«˜æ¨¡å‹çš„å®‰å…¨æ€§å’Œå®ç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€å®ˆæŠ¤æ¨¡å‹çš„ç›‘ç£å¾®è°ƒå’Œå¤šå¥–åŠ±ä¼˜åŒ–ç­–ç•¥ã€‚é¦–å…ˆï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«æ„å›¾æ¨ç†ã€å®‰å…¨æ ‡ç­¾å’Œé‡å†™ç‰ˆæœ¬çš„ç»¼åˆæ•°æ®é›†ï¼›å…¶æ¬¡ï¼Œå¯¹å®ˆæŠ¤æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥å¢å¼ºå…¶æ ¼å¼éµå¾ªã€æ„å›¾åˆ†æå’Œå®‰å…¨é‡å†™èƒ½åŠ›ï¼›æœ€åï¼Œé‡‡ç”¨å¼ºåŒ–å­¦ä¹ æ¡†æ¶è¿›è¡Œå¤šå¥–åŠ±ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†æ„å›¾æ¨ç†å’Œå¤šå±‚æ¬¡å®‰å…¨åˆ†ç±»çš„ç»“åˆï¼Œåˆ©ç”¨ä¸“é—¨çš„å®ˆæŠ¤æ¨¡å‹æ¥å¤„ç†è¾¹ç¼˜æ¡ˆä¾‹æŸ¥è¯¢ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€å®‰å…¨æœºåˆ¶å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å®šåˆ¶çš„æŸå¤±å‡½æ•°å’Œå¥–åŠ±æ¨¡å‹ä¿¡å·ï¼Œç»“åˆè§„åˆ™åŸºç¡€çš„å¯å‘å¼æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨å®‰å…¨æ€§å’Œç”Ÿæˆè´¨é‡ä¸Šçš„è¡¨ç°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒIntentionReasoneråœ¨å¤šä¸ªå®‰å…¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºåŸºçº¿æ¨¡å‹ï¼Œç”Ÿæˆè´¨é‡æå‡äº†æ˜¾è‘—çš„20%ï¼ŒåŒæ—¶è¿‡åº¦æ‹’ç»ç‡é™ä½äº†30%ã€‚åœ¨è¶Šç‹±æ”»å‡»åœºæ™¯ä¸­ï¼Œè¯¥æ¨¡å‹ä¹Ÿå±•ç°å‡ºæ›´å¼ºçš„æŠµæŠ—èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

IntentionReasonerçš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€åœ¨çº¿å®¢æœç³»ç»Ÿä»¥åŠæ•™è‚²é¢†åŸŸçš„è‡ªåŠ¨åŒ–é—®ç­”ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œè¯¥ç ”ç©¶èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘æœ‰å®³å†…å®¹çš„ç”Ÿæˆï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid advancement of large language models (LLMs) has driven their adoption across diverse domains, yet their ability to generate harmful content poses significant safety challenges. While extensive research has focused on mitigating harmful outputs, such efforts often come at the cost of excessively rejecting harmless prompts. Striking a balance among safety, over-refusal, and utility remains a critical challenge. In this work, we introduce IntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard model to perform intent reasoning, multi-level safety classification, and query rewriting to neutralize potentially harmful intent in edge-case queries. Specifically, we first construct a comprehensive dataset comprising approximately 163,000 queries, each annotated with intent reasoning, safety labels, and rewritten versions. Supervised fine-tuning is then applied to equip the guard model with foundational capabilities in format adherence, intent analysis, and safe rewriting. Finally, we apply a tailored multi-reward optimization strategy that integrates rule-based heuristics and reward model signals within a reinforcement learning framework to further enhance performance. Extensive experiments show that IntentionReasoner excels in multiple safeguard benchmarks, generation quality evaluations, and jailbreak attack scenarios, significantly enhancing safety while effectively reducing over-refusal rates and improving the quality of responses.

