---
layout: default
title: Safety Alignment Should Be Made More Than Just A Few Attention Heads
---

# Safety Alignment Should Be Made More Than Just A Few Attention Heads

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19697" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19697v1</a>
  <a href="https://arxiv.org/pdf/2508.19697.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19697v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19697v1', 'Safety Alignment Should Be Made More Than Just A Few Attention Heads')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chao Huang, Zefeng Zhang, Juewei Yue, Quangang Li, Chuang Zhang, Tingwen Liu

**åˆ†ç±»**: cs.CR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºRDSHAä¸AHDä»¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®‰å…¨å¯¹é½` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³¨æ„åŠ›æœºåˆ¶` `æ¶æ„æ”»å‡»` `è®­ç»ƒç­–ç•¥` `é²æ£’æ€§` `æ¶ˆèå®éªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹å®‰å…¨å¯¹é½æ–¹æ³•å­˜åœ¨è„†å¼±æ€§ï¼Œå®¹æ˜“è¢«æ¶æ„æç¤ºæ”»å‡»ç»•è¿‡ã€‚
2. æå‡ºRDSHAå’ŒAHDï¼Œå‰è€…ç”¨äºè¯†åˆ«å®‰å…¨å…³é”®æ³¨æ„åŠ›å¤´ï¼Œåè€…ä¿ƒè¿›å®‰å…¨è¡Œä¸ºåœ¨å¤šä¸ªæ³¨æ„åŠ›å¤´é—´çš„åˆ†å¸ƒã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨AHDè®­ç»ƒçš„æ¨¡å‹åœ¨å®‰å…¨æ€§å’ŒåŠŸèƒ½æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼ŒæŠµå¾¡è¶Šç‹±æ”»å‡»çš„èƒ½åŠ›å¢å¼ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨å¯¹é½ä»å­˜åœ¨è„†å¼±æ€§ï¼Œæ¶æ„æç¤ºå¯ä»¥æœ‰æ•ˆç»•è¿‡å…¶å®‰å…¨æªæ–½ã€‚æˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜ï¼Œè¿™äº›å®‰å…¨æœºåˆ¶ä¸»è¦ä¾èµ–äºæœ‰é™çš„æ³¨æ„åŠ›å¤´ï¼šç§»é™¤æˆ–æ¶ˆèè¿™äº›å¤´ä¼šä¸¥é‡å½±å“æ¨¡å‹å®‰å…¨ã€‚ä¸ºè¯†åˆ«å’Œè¯„ä¼°è¿™äº›å®‰å…¨å…³é”®ç»„ä»¶ï¼Œæˆ‘ä»¬æå‡ºäº†RDSHAï¼Œä¸€ç§åˆ©ç”¨æ¨¡å‹æ‹’ç»æ–¹å‘çš„é’ˆå¯¹æ€§æ¶ˆèæ–¹æ³•ï¼Œèƒ½å¤Ÿç²¾å‡†å®šä½ä¸å®‰å…¨è¡Œä¸ºå¯†åˆ‡ç›¸å…³çš„æ³¨æ„åŠ›å¤´ã€‚è¿›ä¸€æ­¥åˆ†ææ˜¾ç¤ºï¼Œç°æœ‰çš„è¶Šç‹±æ”»å‡»åˆ©ç”¨äº†è¿™ç§é›†ä¸­æ€§ï¼Œé€šè¿‡é€‰æ‹©æ€§ç»•è¿‡æˆ–æ“æ§è¿™äº›å…³é”®æ³¨æ„åŠ›å¤´ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†AHDï¼Œä¸€ç§æ–°é¢–çš„è®­ç»ƒç­–ç•¥ï¼Œæ—¨åœ¨ä¿ƒè¿›å®‰å…¨ç›¸å…³è¡Œä¸ºåœ¨å¤šä¸ªæ³¨æ„åŠ›å¤´ä¹‹é—´çš„åˆ†å¸ƒç¼–ç ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAHDæˆåŠŸåœ°å°†å®‰å…¨ç›¸å…³èƒ½åŠ›åˆ†æ•£åˆ°æ›´å¤šçš„æ³¨æ„åŠ›å¤´ä¸Šï¼Œå¹¶ä¸”åœ¨å¤šç§ä¸»æµè¶Šç‹±æ”»å‡»ä¸‹ï¼Œé‡‡ç”¨AHDè®­ç»ƒçš„æ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—æ›´å¼ºçš„å®‰å…¨é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒæ•´ä½“åŠŸèƒ½æ•ˆç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå½“å‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨å¯¹é½æœºåˆ¶ä¾èµ–äºå°‘æ•°æ³¨æ„åŠ›å¤´ï¼Œå¯¼è‡´æ¨¡å‹åœ¨é¢å¯¹æ¶æ„æ”»å‡»æ—¶è„†å¼±æ€§æ˜¾è‘—ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ†æ•£å®‰å…¨è¡Œä¸ºï¼Œå®¹æ˜“è¢«æ”»å‡»è€…åˆ©ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶æå‡ºRDSHAå’ŒAHDï¼ŒRDSHAç”¨äºè¯†åˆ«ä¸å®‰å…¨è¡Œä¸ºç›¸å…³çš„å…³é”®æ³¨æ„åŠ›å¤´ï¼ŒAHDåˆ™é€šè¿‡æ–°é¢–çš„è®­ç»ƒç­–ç•¥ä¿ƒè¿›å®‰å…¨è¡Œä¸ºçš„åˆ†å¸ƒå¼ç¼–ç ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å®‰å…¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆé€šè¿‡RDSHAæ–¹æ³•è¿›è¡Œæ¶ˆèå®éªŒï¼Œè¯†åˆ«å‡ºå®‰å…¨å…³é”®æ³¨æ„åŠ›å¤´ï¼›ç„¶åé‡‡ç”¨AHDè®­ç»ƒç­–ç•¥ï¼Œè°ƒæ•´æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ï¼Œä½¿å¾—å®‰å…¨èƒ½åŠ›åœ¨å¤šä¸ªæ³¨æ„åŠ›å¤´ä¹‹é—´å‡åŒ€åˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šRDSHAæ–¹æ³•çš„æå‡ºä½¿å¾—èƒ½å¤Ÿç²¾å‡†å®šä½å®‰å…¨å…³é”®ç»„ä»¶ï¼Œè€ŒAHDè®­ç»ƒç­–ç•¥åˆ™æ˜¯é€šè¿‡åˆ†æ•£å®‰å…¨èƒ½åŠ›æ¥å¢å¼ºæ¨¡å‹çš„æ•´ä½“é²æ£’æ€§ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨AHDä¸­ï¼Œè®¾è®¡äº†æ–°çš„æŸå¤±å‡½æ•°ä»¥é¼“åŠ±å®‰å…¨è¡Œä¸ºçš„åˆ†æ•£ï¼ŒåŒæ—¶è°ƒæ•´äº†æ¨¡å‹çš„è®­ç»ƒè¶…å‚æ•°ï¼Œä»¥ä¼˜åŒ–æ³¨æ„åŠ›å¤´çš„ä½¿ç”¨æ•ˆç‡ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨é¢å¯¹æ”»å‡»æ—¶èƒ½å¤Ÿä¿æŒæ›´é«˜çš„å®‰å…¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨AHDè®­ç»ƒçš„æ¨¡å‹åœ¨å¤šç§ä¸»æµè¶Šç‹±æ”»å‡»ä¸‹è¡¨ç°å‡ºæ˜¾è‘—çš„å®‰å…¨é²æ£’æ€§ï¼Œç›¸è¾ƒäºæœªé‡‡ç”¨AHDçš„åŸºçº¿æ¨¡å‹ï¼Œå®‰å…¨æ€§æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„åŠŸèƒ½æ•ˆç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ•æ„Ÿçš„å¯¹è¯ç³»ç»Ÿã€å†…å®¹ç”Ÿæˆå¹³å°å’Œè‡ªåŠ¨åŒ–å®¢æœç­‰ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹çš„å®‰å…¨æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½æ¶æ„æ”»å‡»çš„é£é™©ï¼Œæé«˜ç”¨æˆ·ä¿¡ä»»åº¦å’Œç³»ç»Ÿçš„å¯é æ€§ã€‚æœªæ¥ï¼Œéšç€æ¨¡å‹åœ¨æ›´å¤šå®é™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œå®‰å…¨æ€§å°†æˆä¸ºå…³é”®è€ƒé‡å› ç´ ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current safety alignment for large language models(LLMs) continues to present vulnerabilities, given that adversarial prompting can effectively bypass their safety measures.Our investigation shows that these safety mechanisms predominantly depend on a limited subset of attention heads: removing or ablating these heads can severely compromise model safety. To identify and evaluate these safety-critical components, we introduce RDSHA, a targeted ablation method that leverages the model's refusal direction to pinpoint attention heads mostly responsible for safety behaviors. Further analysis shows that existing jailbreak attacks exploit this concentration by selectively bypassing or manipulating these critical attention heads. To address this issue, we propose AHD, a novel training strategy designed to promote the distributed encoding of safety-related behaviors across numerous attention heads. Experimental results demonstrate that AHD successfully distributes safety-related capabilities across more attention heads. Moreover, evaluations under several mainstream jailbreak attacks show that models trained with AHD exhibit considerably stronger safety robustness, while maintaining overall functional utility.

