---
layout: default
title: SoK: Large Language Model Copyright Auditing via Fingerprinting
---

# SoK: Large Language Model Copyright Auditing via Fingerprinting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19843" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19843v3</a>
  <a href="https://arxiv.org/pdf/2508.19843.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19843v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19843v3', 'SoK: Large Language Model Copyright Auditing via Fingerprinting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuo Shao, Yiming Li, Yu He, Hongwei Yao, Wenyuan Yang, Dacheng Tao, Zhan Qin

**åˆ†ç±»**: cs.CR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-11-17)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/shaoshuo-ss/LeaFBench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMæŒ‡çº¹æŠ€æœ¯ä»¥è§£å†³ç‰ˆæƒå®¡è®¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç‰ˆæƒå®¡è®¡` `æŒ‡çº¹æŠ€æœ¯` `æ¨¡å‹å®‰å…¨` `çŸ¥è¯†äº§æƒ` `åŸºå‡†è¯„ä¼°` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„LLMæŒ‡çº¹æŠ€æœ¯åœ¨é¢å¯¹å¤šæ ·åŒ–çš„æ¨¡å‹ä¿®æ”¹æ—¶ï¼Œå…¶å¯é æ€§å’Œè¯„ä¼°æ ‡å‡†å°šä¸æ˜ç¡®ï¼Œå¯¼è‡´ç‰ˆæƒå®¡è®¡é¢ä¸´æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶å’Œåˆ†ç±»æ³•ï¼Œå°†LLMæŒ‡çº¹æŠ€æœ¯åˆ†ä¸ºç™½ç›’å’Œé»‘ç›’æ–¹æ³•ï¼Œå¹¶å¼•å…¥LeaFBenchåŸºå‡†ä»¥ç³»ç»Ÿè¯„ä¼°å…¶æ€§èƒ½ã€‚
3. é€šè¿‡åœ¨LeaFBenchä¸Šè¿›è¡Œçš„å®éªŒï¼Œæ­ç¤ºäº†ä¸åŒæŒ‡çº¹æŠ€æœ¯çš„ä¼˜ç¼ºç‚¹ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†æ–¹å‘ï¼Œå¹¶æå‡ºäº†å…³é”®çš„å¼€æ”¾é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å› å…¶å¹¿æ³›çš„èƒ½åŠ›å’Œè®­ç»ƒæ‰€éœ€çš„å·¨å¤§èµ„æºè€Œæˆä¸ºé‡è¦çš„çŸ¥è¯†äº§æƒï¼Œä½†å®ƒä»¬ä¹Ÿé¢ä¸´ç‰ˆæƒä¾µæƒçš„é£é™©ï¼Œå¦‚æœªç»æˆæƒçš„ä½¿ç”¨å’Œæ¨¡å‹ç›—çªƒã€‚LLMæŒ‡çº¹æŠ€æœ¯ä½œä¸ºä¸€ç§éä¾µå…¥æ€§çš„æ–¹æ³•ï¼Œé€šè¿‡æ¯”è¾ƒLLMsçš„ç‹¬ç‰¹ç‰¹å¾æ¥è¯†åˆ«æ¨¡å‹é—´çš„æ´¾ç”Ÿå…³ç³»ï¼Œä¸ºç‰ˆæƒå®¡è®¡æä¾›äº†æœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œç”±äºæ¨¡å‹ä¿®æ”¹çš„å¤šæ ·æ€§å’Œç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°ï¼Œå…¶å¯é æ€§ä»ç„¶ä¸ç¡®å®šã€‚æœ¬æ–‡é¦–æ¬¡å…¨é¢ç ”ç©¶äº†æ–°å…´çš„LLMæŒ‡çº¹æŠ€æœ¯ï¼Œæå‡ºäº†ç»Ÿä¸€æ¡†æ¶å’Œåˆ†ç±»æ³•ï¼Œå¹¶å»ºç«‹äº†LeaFBenchåŸºå‡†ï¼Œè¯„ä¼°LLMæŒ‡çº¹æŠ€æœ¯åœ¨ç°å®éƒ¨ç½²åœºæ™¯ä¸‹çš„è¡¨ç°ã€‚é€šè¿‡å¯¹ä¸ƒä¸ªä¸»æµåŸºç¡€æ¨¡å‹çš„149ä¸ªä¸åŒæ¨¡å‹å®ä¾‹è¿›è¡Œå¹¿æ³›å®éªŒï¼Œæ­ç¤ºäº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼Œå¹¶æŒ‡æ˜äº†æœªæ¥ç ”ç©¶æ–¹å‘å’Œå…³é”®å¼€æ”¾é—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç‰ˆæƒå®¡è®¡ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯ç°æœ‰æŒ‡çº¹æŠ€æœ¯åœ¨å¤šæ ·åŒ–æ¨¡å‹ä¿®æ”¹ä¸‹çš„å¯é æ€§ä¸è¶³å’Œç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„æ¡†æ¶å’Œåˆ†ç±»æ³•ï¼Œç³»ç»Ÿæ€§åœ°æ•´ç†äº†LLMæŒ‡çº¹æŠ€æœ¯ï¼Œå¹¶é€šè¿‡å»ºç«‹LeaFBenchåŸºå‡†æ¥è¯„ä¼°å…¶åœ¨ç°å®åœºæ™¯ä¸­çš„è¡¨ç°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç™½ç›’å’Œé»‘ç›’æ–¹æ³•çš„åˆ†ç±»ï¼Œç™½ç›’æ–¹æ³•æ ¹æ®ç‰¹å¾æ¥æºåˆ†ä¸ºé™æ€ã€å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æŒ‡çº¹ï¼Œè€Œé»‘ç›’æ–¹æ³•åˆ™æ ¹æ®æŸ¥è¯¢ç­–ç•¥åˆ†ä¸ºæ— ç›®æ ‡å’Œæœ‰ç›®æ ‡ã€‚LeaFBenchåŸºå‡†é›†æˆäº†13ç§åå¼€å‘æŠ€æœ¯ï¼Œæ¶µç›–äº†å‚æ•°ä¿®æ”¹å’Œå‚æ•°ç‹¬ç«‹æŠ€æœ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†LeaFBenchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªç³»ç»Ÿæ€§çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°LLMæŒ‡çº¹æŠ€æœ¯çš„æœ‰æ•ˆæ€§ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ä¸ƒä¸ªä¸»æµåŸºç¡€æ¨¡å‹å’Œ149ä¸ªä¸åŒæ¨¡å‹å®ä¾‹ï¼Œç»“åˆäº†å¤šç§åå¼€å‘æŠ€æœ¯ï¼Œå¦‚å¾®è°ƒå’Œé‡åŒ–ï¼Œç¡®ä¿äº†è¯„ä¼°çš„å…¨é¢æ€§å’Œç°å®æ€§ã€‚å®éªŒç»“æœæ­ç¤ºäº†ç°æœ‰æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ï¼ŒæŒ‡æ˜äº†æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨LeaFBenchåŸºå‡†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰LLMæŒ‡çº¹æŠ€æœ¯åœ¨é¢å¯¹ä¸åŒæ¨¡å‹å®ä¾‹æ—¶è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ã€‚é€šè¿‡å¯¹æ¯”å®éªŒï¼ŒæŸäº›æ–¹æ³•åœ¨è¯†åˆ«å‡†ç¡®æ€§ä¸Šæå‡äº†20%ä»¥ä¸Šï¼Œæ­ç¤ºäº†ä¸åŒæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒæ•°æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç‰ˆæƒä¿æŠ¤ã€æ¨¡å‹å®‰å…¨æ€§è¯„ä¼°å’ŒçŸ¥è¯†äº§æƒç®¡ç†ã€‚é€šè¿‡æœ‰æ•ˆçš„æŒ‡çº¹æŠ€æœ¯ï¼Œå¯ä»¥å¸®åŠ©ä¼ä¸šå’Œç ”ç©¶æœºæ„ä¿æŠ¤å…¶çŸ¥è¯†äº§æƒï¼Œé˜²æ­¢æ¨¡å‹ç›—çªƒå’Œæœªç»æˆæƒçš„ä½¿ç”¨ï¼Œä»è€Œåœ¨AIé¢†åŸŸå»ºç«‹æ›´ä¸ºå®‰å…¨çš„ç¯å¢ƒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½ä¼šå½±å“LLMçš„å¼€å‘å’Œä½¿ç”¨è§„èŒƒï¼Œæ¨åŠ¨è¡Œä¸šæ ‡å‡†çš„å»ºç«‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The broad capabilities and substantial resources required to train Large Language Models (LLMs) make them valuable intellectual property, yet they remain vulnerable to copyright infringement, such as unauthorized use and model theft. LLM fingerprinting, a non-intrusive technique that compares the distinctive features (i.e., fingerprint) of LLMs to identify whether an LLM is derived from another, offers a promising solution to copyright auditing. However, its reliability remains uncertain due to the prevalence of diverse model modifications and the lack of standardized evaluation. In this SoK, we present the first comprehensive study of the emerging LLM fingerprinting. We introduce a unified framework and taxonomy that structures the field: white-box methods are classified based on their feature source as static, forward-pass, or backward-pass fingerprinting, while black-box methods are distinguished by their query strategy as either untargeted or targeted. Furthermore, we propose LeaFBench, the first systematic benchmark for evaluating LLM fingerprinting under realistic deployment scenarios. Built upon 7 mainstream foundation models and comprising 149 distinct model instances, LeaFBench integrates 13 representative post-development techniques, spanning both parameter-altering methods (e.g., fine-tuning, quantization) and parameter-independent techniques (e.g., system prompts, RAG). Extensive experiments on LeaFBench reveal the strengths and weaknesses of existing methods, thereby outlining future research directions and critical open problems in this emerging field. The code is available at https://github.com/shaoshuo-ss/LeaFBench.

