---
layout: default
title: AI reasoning effort predicts human decision time in content moderation
---

# AI reasoning effort predicts human decision time in content moderation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20262" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20262v2</a>
  <a href="https://arxiv.org/pdf/2508.20262.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20262v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20262v2', 'AI reasoning effort predicts human decision time in content moderation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thomas Davidson

**åˆ†ç±»**: cs.AI, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-12-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æ¨ç†åŠªåŠ›é¢„æµ‹äººç±»å†…å®¹å®¡æ ¸å†³ç­–æ—¶é—´**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å†…å®¹å®¡æ ¸` `æ¨ç†æœºåˆ¶` `é“¾å¼æ€ç»´` `äººæœºåä½œ` `å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å†…å®¹å®¡æ ¸æ–¹æ³•åœ¨å¤„ç†å¤æ‚å†³ç­–æ—¶ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†æœºåˆ¶ï¼Œå¯¼è‡´å†³ç­–æ—¶é—´ä¸ç¨³å®šã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡åˆ†æé“¾å¼æ€ç»´ï¼ˆCoTï¼‰çš„é•¿åº¦æ¥é¢„æµ‹äººç±»å†³ç­–æ—¶é—´ï¼Œä»è€Œå»ºç«‹äººç±»ä¸AIæ¨ç†ä¹‹é—´çš„è”ç³»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCoTé•¿åº¦ä¸äººç±»å†³ç­–æ—¶é—´é«˜åº¦ç›¸å…³ï¼Œä¸”åœ¨æ§åˆ¶å˜é‡æ—¶ï¼Œæ¨¡å‹å’Œäººç±»çš„ååº”æ—¶é—´å‡æ˜¾è‘—å¢åŠ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ç°åœ¨å¯ä»¥åœ¨ç”Ÿæˆç­”æ¡ˆä¹‹å‰ç”Ÿæˆä¸­é—´æ¨ç†æ­¥éª¤ï¼Œé€šè¿‡äº’åŠ¨å¼€å‘è§£å†³æ–¹æ¡ˆæ¥æé«˜åœ¨å›°éš¾é—®é¢˜ä¸Šçš„è¡¨ç°ã€‚æœ¬ç ”ç©¶ä½¿ç”¨å†…å®¹å®¡æ ¸ä»»åŠ¡æ¥è€ƒå¯Ÿäººç±»å†³ç­–æ—¶é—´ä¸æ¨¡å‹æ¨ç†åŠªåŠ›ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæ¨ç†åŠªåŠ›é€šè¿‡é“¾å¼æ€ç»´ï¼ˆCoTï¼‰çš„é•¿åº¦æ¥è¡¡é‡ã€‚åœ¨ä¸‰ä¸ªå‰æ²¿æ¨¡å‹ä¸­ï¼ŒCoTé•¿åº¦å§‹ç»ˆèƒ½é¢„æµ‹äººç±»å†³ç­–æ—¶é—´ã€‚æ­¤å¤–ï¼Œå½“é‡è¦å˜é‡ä¿æŒä¸å˜æ—¶ï¼Œäººç±»èŠ±è´¹çš„æ—¶é—´æ›´é•¿ï¼Œæ¨¡å‹ç”Ÿæˆçš„CoTä¹Ÿæ›´é•¿ï¼Œè¡¨æ˜å¯¹ä»»åŠ¡éš¾åº¦çš„æ•æ„Ÿæ€§ç›¸ä¼¼ã€‚å¯¹CoTå†…å®¹çš„åˆ†ææ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨åšå‡ºå†³ç­–æ—¶æ›´é¢‘ç¹åœ°å‚è€ƒå„ç§ä¸Šä¸‹æ–‡å› ç´ ã€‚è¿™äº›å‘ç°å±•ç¤ºäº†äººç±»ä¸AIåœ¨å®é™…ä»»åŠ¡ä¸Šçš„æ¨ç†ç›¸ä¼¼æ€§ï¼Œå¹¶å¼ºè°ƒäº†æ¨ç†è½¨è¿¹åœ¨å¢å¼ºå¯è§£é‡Šæ€§å’Œå†³ç­–ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å†…å®¹å®¡æ ¸ä»»åŠ¡ä¸­äººç±»å†³ç­–æ—¶é—´é¢„æµ‹çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†æœºåˆ¶ï¼Œå¯¼è‡´å†³ç­–æ—¶é—´çš„ä¸ç¡®å®šæ€§å’Œä¸ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é“¾å¼æ€ç»´ï¼ˆCoTï¼‰çš„é•¿åº¦ä½œä¸ºæ¨ç†åŠªåŠ›çš„åº¦é‡ï¼Œä»è€Œé¢„æµ‹äººç±»åœ¨å†…å®¹å®¡æ ¸ä¸­çš„å†³ç­–æ—¶é—´ã€‚è¿™ç§è®¾è®¡åŸºäºäººç±»å’ŒAIåœ¨é¢å¯¹å¤æ‚ä»»åŠ¡æ—¶çš„ç›¸ä¼¼æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œæ¨¡å‹ç”Ÿæˆé“¾å¼æ€ç»´ï¼›å…¶æ¬¡ï¼Œæµ‹é‡CoTçš„é•¿åº¦ï¼›æœ€åï¼Œåˆ†æCoTä¸äººç±»å†³ç­–æ—¶é—´çš„å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡å°†CoTé•¿åº¦ä¸äººç±»å†³ç­–æ—¶é—´è¿›è¡Œç³»ç»Ÿæ€§å…³è”ï¼Œæ­ç¤ºäº†AIæ¨ç†ä¸äººç±»æ€ç»´çš„ç›¸ä¼¼æ€§ï¼Œæ¨åŠ¨äº†å¯è§£é‡Šæ€§ç ”ç©¶çš„å‘å±•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§å‰æ²¿è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€šè¿‡æ§åˆ¶å®éªŒå˜é‡æ¥ç¡®ä¿ç»“æœçš„å¯é æ€§ã€‚æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé“¾å¼æ€ç»´ï¼ˆCoTï¼‰é•¿åº¦ä¸äººç±»å†³ç­–æ—¶é—´ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„æ­£ç›¸å…³å…³ç³»ã€‚åœ¨æ§åˆ¶é‡è¦å˜é‡çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹ç”Ÿæˆçš„CoTé•¿åº¦å¹³å‡å¢åŠ äº†20%ï¼Œè€Œäººç±»å†³ç­–æ—¶é—´ä¹Ÿç›¸åº”å»¶é•¿ï¼Œè¡¨æ˜ä¸¤è€…å¯¹ä»»åŠ¡éš¾åº¦çš„æ•æ„Ÿæ€§ç›¸ä¼¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€åœ¨çº¿å¹³å°çš„è‡ªåŠ¨åŒ–å†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜AIåœ¨å¤æ‚å†³ç­–ä¸­çš„å¯è§£é‡Šæ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©äººç±»å®¡æ ¸å‘˜æ›´å¥½åœ°ç†è§£å’Œä¿¡ä»»AIçš„å†³ç­–è¿‡ç¨‹ï¼Œè¿›è€Œæå‡å†…å®¹å®¡æ ¸çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models can now generate intermediate reasoning steps before producing answers, improving performance on difficult problems by interactively developing solutions. This study uses a content moderation task to examine parallels between human decision times and model reasoning effort, measured using the length of the chain-of-thought (CoT). Across three frontier models, CoT length consistently predicts human decision time. Moreover, humans took longer and models produced longer CoTs when important variables were held constant, suggesting similar sensitivity to task difficulty. Analyses of the CoT content shows that models reference various contextual factors more frequently when making such decisions. These findings show parallels between human and AI reasoning on practical tasks and underscore the potential of reasoning traces for enhancing interpretability and decision-making.

