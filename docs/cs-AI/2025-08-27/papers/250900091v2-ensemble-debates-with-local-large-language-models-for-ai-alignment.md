---
layout: default
title: Ensemble Debates with Local Large Language Models for AI Alignment
---

# Ensemble Debates with Local Large Language Models for AI Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.00091" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.00091v2</a>
  <a href="https://arxiv.org/pdf/2509.00091.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.00091v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.00091v2', 'Ensemble Debates with Local Large Language Models for AI Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ephraiem Sarabamoun

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-11-15)

**å¤‡æ³¨**: The manuscript is being withdrawn to incorporate additional revisions and improvements

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœ¬åœ°å¼€æºé›†æˆè¾©è®ºä»¥æå‡AIå¯¹é½èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `AIå¯¹é½` `é›†æˆå­¦ä¹ ` `è¾©è®ºæœºåˆ¶` `æ¨ç†æ·±åº¦` `è®ºè¯è´¨é‡` `å¼€æºæ¨¡å‹` `é«˜é£é™©å†³ç­–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–ä¸“æœ‰APIï¼Œé™åˆ¶äº†å¯é‡å¤æ€§å’Œå¹¿æ³›å‚ä¸ï¼Œå¯¼è‡´å¯¹é½èƒ½åŠ›ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æœ¬åœ°å¼€æºé›†æˆè¾©è®ºæ¥æ”¹å–„å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯¹é½æ¨ç†èƒ½åŠ›ï¼Œå¢å¼ºæ¨¡å‹çš„æ¨ç†æ·±åº¦å’Œè®ºè¯è´¨é‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé›†æˆæ¨¡å‹åœ¨å¤šä¸ªåœºæ™¯ä¸­è¡¨ç°ä¼˜äºå•æ¨¡å‹ï¼Œæ•´ä½“è¯„åˆ†æé«˜äº†3.48ï¼Œç›¸æ¯”åŸºçº¿3.13æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é«˜é£é™©å†³ç­–ä¸­æ‰®æ¼”è¶Šæ¥è¶Šé‡è¦çš„è§’è‰²ï¼Œä¸äººç±»ä»·å€¼è§‚çš„å¯¹é½å˜å¾—è‡³å…³é‡è¦ã€‚ä¾èµ–äºä¸“æœ‰APIé™åˆ¶äº†å¯é‡å¤æ€§å’Œå¹¿æ³›å‚ä¸ã€‚æœ¬æ–‡ç ”ç©¶äº†æœ¬åœ°å¼€æºé›†æˆè¾©è®ºæ˜¯å¦èƒ½æ”¹å–„å¯¹é½å¯¼å‘çš„æ¨ç†ã€‚åœ¨150åœºè¾©è®ºä¸­ï¼Œé›†æˆæ¨¡å‹åœ¨7åˆ†åˆ¶è¯„åˆ†ä¸Šè¶…è¶Šå•æ¨¡å‹åŸºçº¿ï¼ˆæ•´ä½“ï¼š3.48å¯¹3.13ï¼‰ï¼Œåœ¨æ¨ç†æ·±åº¦ï¼ˆ+19.4%ï¼‰å’Œè®ºè¯è´¨é‡ï¼ˆ+34.1%ï¼‰æ–¹é¢å–å¾—äº†æœ€å¤§æå‡ã€‚çœŸè¯šåº¦ï¼ˆ+1.25åˆ†ï¼‰å’Œäººç±»å¢å¼ºï¼ˆ+0.80ï¼‰æ–¹é¢çš„æ”¹å–„æœ€ä¸ºæ˜¾è‘—ã€‚æˆ‘ä»¬æä¾›äº†ä»£ç ã€æç¤ºå’Œè¾©è®ºæ•°æ®é›†ï¼Œä¸ºåŸºäºé›†æˆçš„å¯¹é½è¯„ä¼°æä¾›äº†ä¸€ä¸ªå¯è®¿é—®å’Œå¯é‡å¤çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é«˜é£é™©å†³ç­–ä¸­ä¸äººç±»ä»·å€¼è§‚å¯¹é½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºä¸“æœ‰APIï¼Œé™åˆ¶äº†æ¨¡å‹çš„å¯é‡å¤æ€§å’Œå‚ä¸åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡æœ¬åœ°å¼€æºçš„é›†æˆè¾©è®ºæœºåˆ¶ï¼Œåˆ©ç”¨å¤šä¸ªæ¨¡å‹çš„é›†ä½“æ™ºæ…§æ¥æå‡æ¨ç†çš„æ·±åº¦å’Œè®ºè¯çš„è´¨é‡ï¼Œä»è€Œæ”¹å–„å¯¹é½èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæœ¬åœ°å¼€æºæ¨¡å‹çš„é›†æˆï¼Œé€šè¿‡è®¾ç½®ä¸åŒçš„è¾©è®ºåœºæ™¯å’Œé…ç½®ï¼Œè¿›è¡Œ150åœºè¾©è®ºï¼Œè¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ¨¡å‹é€‰æ‹©ã€è¾©è®ºç”Ÿæˆã€è¯„åˆ†æœºåˆ¶ç­‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥é›†æˆè¾©è®ºçš„æ¦‚å¿µï¼Œé€šè¿‡å¤šæ¨¡å‹çš„åä½œæ¥æå‡æ¨ç†èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿå•æ¨¡å‹æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨7åˆ†åˆ¶è¯„åˆ†æ ‡å‡†ï¼Œé‡ç‚¹å…³æ³¨æ¨ç†æ·±åº¦ã€è®ºè¯è´¨é‡ã€çœŸè¯šåº¦å’Œäººç±»å¢å¼ºç­‰æŒ‡æ ‡ï¼Œç¡®ä¿è¯„ä¼°çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé›†æˆæ¨¡å‹åœ¨150åœºè¾©è®ºä¸­æ•´ä½“è¯„åˆ†è¾¾åˆ°3.48ï¼Œç›¸è¾ƒäºå•æ¨¡å‹åŸºçº¿3.13æœ‰æ˜¾è‘—æå‡ã€‚æ¨ç†æ·±åº¦æé«˜äº†19.4%ï¼Œè®ºè¯è´¨é‡æå‡34.1%ï¼ŒçœŸè¯šåº¦å’Œäººç±»å¢å¼ºçš„è¯„åˆ†åˆ†åˆ«æé«˜äº†1.25åˆ†å’Œ0.80åˆ†ï¼Œè¡¨æ˜é›†æˆè¾©è®ºåœ¨AIå¯¹é½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é«˜é£é™©å†³ç­–æ”¯æŒç³»ç»Ÿã€æ³•å¾‹å’¨è¯¢ã€åŒ»ç–—è¯Šæ–­ç­‰ï¼Œèƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ä¸ºå¯é å’Œç¬¦åˆäººç±»ä»·å€¼è§‚çš„AIå†³ç­–æ”¯æŒã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¹¿æ³›çš„AIåº”ç”¨ä¸­å¾—åˆ°æ¨å¹¿ï¼Œæå‡AIç³»ç»Ÿçš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> As large language models (LLMs) take on greater roles in high-stakes decisions, alignment with human values is essential. Reliance on proprietary APIs limits reproducibility and broad participation. We study whether local open-source ensemble debates can improve alignmentoriented reasoning. Across 150 debates spanning 15 scenarios and five ensemble configurations, ensembles outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13), with the largest gains in reasoning depth (+19.4%) and argument quality (+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human enhancement (+0.80). We provide code, prompts, and a debate data set, providing an accessible and reproducible foundation for ensemble-based alignment evaluation.

