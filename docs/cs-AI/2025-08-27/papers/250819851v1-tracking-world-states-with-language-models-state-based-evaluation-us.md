---
layout: default
title: Tracking World States with Language Models: State-Based Evaluation Using Chess
---

# Tracking World States with Language Models: State-Based Evaluation Using Chess

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19851" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19851v1</a>
  <a href="https://arxiv.org/pdf/2508.19851.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19851v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19851v1', 'Tracking World States with Language Models: State-Based Evaluation Using Chess')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Romain Harang, Jason Naradowsky, Yaswitha Gujju, Yusuke Miyao

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: Spotlight presentation at ICML 2025 Workshop on Assessing World Models

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§çŠ¶æ€åŸºç¡€è¯„ä¼°æ¡†æ¶ä»¥æå‡è¯­è¨€æ¨¡å‹åœ¨æ£‹ç±»æ¸¸æˆä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹` `çŠ¶æ€è·Ÿè¸ª` `å›½é™…è±¡æ£‹` `æ¨¡å‹è¯„ä¼°` `è¯­ä¹‰ä¿çœŸåº¦` `ç»“æ„åŒ–ç¯å¢ƒ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¾èµ–æ¨¡å‹ç‰¹å®šçš„å†…éƒ¨æ¿€æ´»ï¼Œé™åˆ¶äº†å¯¹è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ™®é€‚æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¨¡å‹æ— å…³çš„çŠ¶æ€åŸºç¡€è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡åˆ†æå›½é™…è±¡æ£‹çš„åˆæ³•ç§»åŠ¨åˆ†å¸ƒæ¥è¯„ä¼°è¯­ä¹‰ä¿çœŸåº¦ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰LLMsåœ¨çŠ¶æ€è·Ÿè¸ªä¸­çš„ä¸è¶³ï¼Œæ­ç¤ºå…¶åœ¨é•¿åºåˆ—ä¸­çš„å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ç»“æ„åŒ–é¢†åŸŸå±•ç°å‡ºæ–°å…´èƒ½åŠ›ï¼Œæš—ç¤ºå®ƒä»¬å¯èƒ½éšå«é«˜ä¿çœŸåº¦çš„ä¸–ç•Œæ¨¡å‹è¡¨ç¤ºã€‚å°½ç®¡æ¢æµ‹æŠ€æœ¯åœ¨ç§‘å­¦å’Œæ¸¸æˆç¯å¢ƒä¸­æ˜¾ç¤ºå‡ºè‰¯å¥½è¿¹è±¡ï¼Œä½†ä¾èµ–äºæ¨¡å‹ç‰¹å®šçš„å†…éƒ¨æ¿€æ´»ï¼Œé™åˆ¶äº†å¯è§£é‡Šæ€§å’Œæ™®é€‚æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¨¡å‹æ— å…³çš„çŠ¶æ€åŸºç¡€è¯„ä¼°æ¡†æ¶ï¼Œä»¥å›½é™…è±¡æ£‹ä½œä¸ºåŸºå‡†ï¼Œè¯„ä¼°LLMsæ˜¯å¦ä¿ç•™ç»“æ„åŒ–ç¯å¢ƒçš„è¯­ä¹‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•åˆ†æä¸‹æ¸¸åˆæ³•ç§»åŠ¨åˆ†å¸ƒï¼ˆçŠ¶æ€å¯ä¾›æ€§ï¼‰ï¼Œä»¥ä¼°è®¡é¢„æµ‹ä¸å®é™…æ¸¸æˆçŠ¶æ€ä¹‹é—´çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„è¯„ä¼°æŒ‡æ ‡æ•æ‰åˆ°äº†çŠ¶æ€è·Ÿè¸ªä¸­çš„ä¸è¶³ï¼Œçªæ˜¾äº†LLMsåœ¨é•¿åºåˆ—ä¸­ä¿æŒä¸€è‡´å†…éƒ¨æ¨¡å‹çš„å±€é™æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»“æ„åŒ–ç¯å¢ƒä¸­çŠ¶æ€è·Ÿè¸ªçš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºç¼ºä¹å¯è§£é‡Šæ€§å’Œæ™®é€‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§æ¨¡å‹æ— å…³çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡åˆ†æåˆæ³•ç§»åŠ¨åˆ†å¸ƒæ¥è¯„ä¼°æ¨¡å‹å¯¹æ¸¸æˆçŠ¶æ€çš„ç†è§£å’Œä¿çœŸåº¦ï¼Œæ—¨åœ¨æä¾›æ›´å…·æˆ˜ç•¥æ€§å’Œè§„åˆ™å¯¼å‘çš„è¯„ä¼°æ–¹å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€çŠ¶æ€åˆ†æå’Œè¯„ä¼°æŒ‡æ ‡è®¡ç®—ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å›½é™…è±¡æ£‹çš„æ¸¸æˆæ•°æ®ï¼Œç„¶ååˆ†æåˆæ³•ç§»åŠ¨çš„åˆ†å¸ƒï¼Œæœ€åè®¡ç®—é¢„æµ‹çŠ¶æ€ä¸å®é™…çŠ¶æ€ä¹‹é—´çš„è¯­ä¹‰ä¿çœŸåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§ä¸ä¾èµ–äºæ¨¡å‹å†…éƒ¨æ¿€æ´»çš„è¯„ä¼°æ–¹æ³•ï¼Œä½¿å¾—è¯„ä¼°è¿‡ç¨‹æ›´åŠ é€æ˜å’Œæ™®é€‚ï¼Œèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå„ç§ç¬¦å·ç¯å¢ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥é‡åŒ–é¢„æµ‹ä¸å®é™…çŠ¶æ€ä¹‹é—´çš„å·®å¼‚ï¼Œå¹¶è®¾è®¡äº†é€‚åº”ä¸åŒæ¸¸æˆçŠ¶æ€çš„å‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿è¯„ä¼°çš„å‡†ç¡®æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰LLMsåœ¨çŠ¶æ€è·Ÿè¸ªä¸­çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨é•¿åºåˆ—ä¸­ï¼Œæ˜¾ç¤ºå‡ºä¸ä¼ ç»Ÿå­—ç¬¦ä¸²åŸºç¡€æŒ‡æ ‡ç›¸æ¯”ï¼Œæå‡äº†å¯¹æ¨¡å‹è¯­ä¹‰ä¿çœŸåº¦çš„è¯„ä¼°èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¸¸æˆAIã€æ•™è‚²å·¥å…·å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æä¾›ä¸€ç§æœ‰æ•ˆçš„è¯„ä¼°æ¡†æ¶ï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…æ›´å¥½åœ°ç†è§£å’Œæ”¹è¿›è¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œä»è€Œæå‡å…¶å®é™…åº”ç”¨ä»·å€¼å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) exhibit emergent capabilities in structured domains, suggesting they may implicitly internalize high-fidelity representations of world models. While probing techniques have shown promising signs of this in scientific and game-based settings, they rely on model-specific internal activations, which limit interpretability and generalizability. In this work, we propose a model-agnostic, state-based evaluation framework using chess as a benchmark to assess whether LLMs preserve the semantics of structured environments. Our method analyzes the downstream legal move distributions (state affordances) to estimate semantic fidelity between predicted and actual game states. This approach offers a more meaningful evaluation than conventional string-based metrics by aligning more closely with the strategic and rule-governed nature of chess. Experimental results demonstrate that our metrics capture deficiencies in state-tracking, highlighting limitations of LLMs in maintaining coherent internal models over long sequences. Our framework provides a robust tool for evaluating structured reasoning in LLMs without requiring internal model access, and generalizes to a wide class of symbolic environments.

