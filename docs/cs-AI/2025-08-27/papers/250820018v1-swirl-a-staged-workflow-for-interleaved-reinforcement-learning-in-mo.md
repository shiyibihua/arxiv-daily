---
layout: default
title: SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control
---

# SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20018" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20018v1</a>
  <a href="https://arxiv.org/pdf/2508.20018.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20018v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20018v1', 'SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Quanfeng Lu, Zhantao Ma, Shuai Zhong, Jin Wang, Dahai Yu, Michael K. Ng, Ping Luo

**åˆ†ç±»**: cs.AI, cs.CL, cs.CV, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

**å¤‡æ³¨**: 28 pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSWIRLä»¥è§£å†³ç§»åŠ¨GUIæ§åˆ¶ä¸­çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç§»åŠ¨GUIæ§åˆ¶` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `å¼ºåŒ–å­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡å‹` `æ™ºèƒ½ä½“åè°ƒ` `æ•°å­¦æ¨ç†` `å®éªŒéªŒè¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å•æ™ºèƒ½ä½“æ–¹æ³•åœ¨ç§»åŠ¨GUIæ§åˆ¶ä¸­å—åˆ°ç»“æ„é™åˆ¶ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†å¤æ‚çš„ç•Œé¢æ“ä½œã€‚
2. SWIRLé€šè¿‡å°†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è½¬åŒ–ä¸ºå•æ™ºèƒ½ä½“ä»»åŠ¡ï¼Œé€ä¸ªæ›´æ–°æ™ºèƒ½ä½“ï¼Œä»è€Œå®ç°ç¨³å®šè®­ç»ƒå’Œé«˜æ•ˆåè°ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSWIRLåœ¨é«˜å±‚å’Œä½å±‚GUIåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜è¶Šï¼Œå¹¶åœ¨å¤šæ™ºèƒ½ä½“æ•°å­¦æ¨ç†ä¸­å±•ç°å‡ºå¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰å’Œæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¿«é€Ÿå‘å±•ï¼Œç§»åŠ¨GUIæ™ºèƒ½ä½“çš„ç ”ç©¶å—åˆ°å…³æ³¨ï¼Œç„¶è€Œç°æœ‰çš„å•æ™ºèƒ½ä½“æ–¹æ³•å—åˆ°ç»“æ„é™åˆ¶ã€‚å°½ç®¡å¤šæ™ºèƒ½ä½“ç³»ç»Ÿèƒ½å¤Ÿè‡ªç„¶åœ°è§£è€¦ä¸åŒçš„èƒ½åŠ›ï¼Œä½†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰çš„æ•ˆç‡é—®é¢˜å’Œä¸ç°æœ‰LVLMæ¶æ„çš„ä¸å…¼å®¹æ€§ä»ç„¶å­˜åœ¨ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†SWIRLï¼Œä¸€ä¸ªä¸ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿè®¾è®¡çš„äº¤é”™å¼ºåŒ–å­¦ä¹ çš„åˆ†é˜¶æ®µå·¥ä½œæµã€‚SWIRLå°†MARLé‡æ–°è¡¨è¿°ä¸ºä¸€ç³»åˆ—å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ï¼Œé€ä¸ªæ›´æ–°æ™ºèƒ½ä½“ï¼ŒåŒæ—¶ä¿æŒå…¶ä»–æ™ºèƒ½ä½“å›ºå®šã€‚è¿™ç§æ–¹æ³•ä¿ƒè¿›äº†ç¨³å®šçš„è®­ç»ƒå’Œé«˜æ•ˆçš„åè°ƒã€‚é€šè¿‡å¤§é‡å®éªŒï¼ŒSWIRLåœ¨é«˜å±‚å’Œä½å±‚GUIåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ï¼Œå¹¶åœ¨å¤šæ™ºèƒ½ä½“æ•°å­¦æ¨ç†ä¸­å±•ç°å‡ºå¼ºå¤§çš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç§»åŠ¨GUIæ§åˆ¶ä¸­å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶å­˜åœ¨ç»“æ„é™åˆ¶å’Œåè°ƒå›°éš¾ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSWIRLçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ è½¬åŒ–ä¸ºä¸€ç³»åˆ—å•æ™ºèƒ½ä½“ä»»åŠ¡ï¼Œé€ä¸ªæ›´æ–°æ™ºèƒ½ä½“ï¼Œä¿æŒå…¶ä»–æ™ºèƒ½ä½“å›ºå®šï¼Œä»è€Œå®ç°ç¨³å®šçš„è®­ç»ƒè¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSWIRLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šNavigatorå’ŒInteractorã€‚Navigatorè´Ÿè´£å°†è‡ªç„¶è¯­è¨€å’Œå±å¹•ä¸Šä¸‹æ–‡è½¬åŒ–ä¸ºç»“æ„åŒ–è®¡åˆ’ï¼Œè€ŒInteractoråˆ™å°†è¿™äº›è®¡åˆ’è½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„åŸå­åŠ¨ä½œã€‚

**å…³é”®åˆ›æ–°**ï¼šSWIRLçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å°†MARLé‡æ„ä¸ºå•æ™ºèƒ½ä½“ä»»åŠ¡çš„æ–¹å¼ï¼Œè¿™ç§æ–¹æ³•æé«˜äº†è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ï¼Œä¸ä¼ ç»Ÿçš„å¤šæ™ºèƒ½ä½“æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åè°ƒæ™ºèƒ½ä½“ä¹‹é—´çš„äº¤äº’ã€‚

**å…³é”®è®¾è®¡**ï¼šSWIRLè®¾è®¡äº†é€æ­¥å®‰å…¨ç•Œé™ã€è·¨è½®å•è°ƒæ”¹è¿›å®šç†å’Œæ”¶ç›Šæ”¶æ•›ä¿è¯ç­‰ç†è®ºæ¡†æ¶ï¼Œç¡®ä¿äº†ä¼˜åŒ–è¿‡ç¨‹çš„ç¨³å¥æ€§å’ŒåŸåˆ™æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SWIRLåœ¨é«˜å±‚å’Œä½å±‚GUIåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶æ€§èƒ½ä¼˜äºç°æœ‰åŸºçº¿ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®æœªæä¾›ï¼‰ã€‚æ­¤å¤–ï¼ŒSWIRLåœ¨å¤šæ™ºèƒ½ä½“æ•°å­¦æ¨ç†ä»»åŠ¡ä¸­ä¹Ÿå±•ç°äº†å¼ºå¤§çš„èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SWIRLåœ¨ç§»åŠ¨GUIæ§åˆ¶ä¸­çš„åº”ç”¨æ½œåŠ›å·¨å¤§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†è‡ªç„¶è¯­è¨€è½¬åŒ–ä¸ºç•Œé¢æ“ä½œï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æ­¤å¤–ï¼Œå…¶åœ¨å¤šæ™ºèƒ½ä½“æ•°å­¦æ¨ç†ä¸­çš„è¡¨ç°ä¹Ÿè¡¨æ˜äº†å…¶ä½œä¸ºé€šç”¨æ¡†æ¶çš„æ½œåŠ›ï¼Œèƒ½å¤Ÿå¹¿æ³›åº”ç”¨äºå…¶ä»–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid advancement of large vision language models (LVLMs) and agent systems has heightened interest in mobile GUI agents that can reliably translate natural language into interface operations. Existing single-agent approaches, however, remain limited by structural constraints. Although multi-agent systems naturally decouple different competencies, recent progress in multi-agent reinforcement learning (MARL) has often been hindered by inefficiency and remains incompatible with current LVLM architectures. To address these challenges, we introduce SWIRL, a staged workflow for interleaved reinforcement learning designed for multi-agent systems. SWIRL reformulates MARL into a sequence of single-agent reinforcement learning tasks, updating one agent at a time while keeping the others fixed. This formulation enables stable training and promotes efficient coordination across agents. Theoretically, we provide a stepwise safety bound, a cross-round monotonic improvement theorem, and convergence guarantees on return, ensuring robust and principled optimization. In application to mobile GUI control, SWIRL instantiates a Navigator that converts language and screen context into structured plans, and an Interactor that grounds these plans into executable atomic actions. Extensive experiments demonstrate superior performance on both high-level and low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong capability in multi-agent mathematical reasoning, underscoring its potential as a general framework for developing efficient and robust multi-agent systems.

