---
layout: default
title: "Beyond Context: Large Language Models Failure to Grasp Users Intent"
---

# Beyond Context: Large Language Models Failure to Grasp Users Intent

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.21110" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.21110v1</a>
  <a href="https://arxiv.org/pdf/2512.21110.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.21110v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.21110v1', 'Beyond Context: Large Language Models Failure to Grasp Users Intent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos

**åˆ†ç±»**: cs.AI, cs.CL, cs.CR, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-12-24

**å¤‡æ³¨**: 22 pages and 23 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¤§å‹è¯­è¨€æ¨¡å‹æœªèƒ½ç†è§£ç”¨æˆ·æ„å›¾ï¼Œæ˜“è¢«æ¶æ„åˆ©ç”¨ç»•è¿‡å®‰å…¨æœºåˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹å®‰å…¨` `ç”¨æˆ·æ„å›¾ç†è§£` `å®‰å…¨æ¼æ´` `å¯¹æŠ—æ”»å‡»` `ä¸Šä¸‹æ–‡ç†è§£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ–¹æ³•ä¾§é‡äºæ£€æµ‹æ˜¾å¼æœ‰å®³å†…å®¹ï¼Œå¿½ç•¥äº†ç†è§£ç”¨æˆ·æ„å›¾çš„ä¸è¶³ã€‚
2. è®ºæ–‡é€šè¿‡æƒ…æ„Ÿæ¡†æ¶ã€æ¸è¿›å¼æ­ç¤ºç­‰æŠ€æœ¯ï¼Œæ­ç¤ºäº†ç°æœ‰LLMå®‰å…¨æœºåˆ¶æ˜“è¢«æ¶æ„ç”¨æˆ·ç»•è¿‡çš„æ¼æ´ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¯ç”¨æ¨ç†çš„é…ç½®åè€Œå¯èƒ½æ”¾å¤§æ¼æ´ï¼Œä»…Claude Opus 4.1åœ¨æŸäº›æƒ…å†µä¸‹ä¼˜å…ˆè€ƒè™‘æ„å›¾æ£€æµ‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å®‰å…¨æ–¹æ³•ä¸»è¦å…³æ³¨äºæ˜¾å¼æœ‰å®³å†…å®¹ï¼Œè€Œå¿½ç•¥äº†ä¸€ä¸ªå…³é”®æ¼æ´ï¼šæ— æ³•ç†è§£ä¸Šä¸‹æ–‡å’Œè¯†åˆ«ç”¨æˆ·æ„å›¾ã€‚è¿™å¯¼è‡´äº†å¯è¢«æ¶æ„ç”¨æˆ·ç³»ç»Ÿæ€§åˆ©ç”¨ä»¥è§„é¿å®‰å…¨æœºåˆ¶çš„æ¼æ´ã€‚æˆ‘ä»¬å¯¹åŒ…æ‹¬ChatGPTã€Claudeã€Geminiå’ŒDeepSeekåœ¨å†…çš„å¤šä¸ªæœ€å…ˆè¿›çš„LLMè¿›è¡Œäº†å®è¯è¯„ä¼°ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå¯ä»¥é€šè¿‡æƒ…æ„Ÿæ¡†æ¶ã€æ¸è¿›å¼æ­ç¤ºå’Œå­¦æœ¯è®ºè¯ç­‰æŠ€æœ¯æ¥è§„é¿å¯é çš„å®‰å…¨æœºåˆ¶ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¯ç”¨æ¨ç†çš„é…ç½®åè€Œæ”¾å¤§äº†åˆ©ç”¨çš„æœ‰æ•ˆæ€§ï¼Œæé«˜äº†äº‹å®å‡†ç¡®æ€§ï¼Œä½†æœªèƒ½è´¨ç–‘æ½œåœ¨æ„å›¾ã€‚Claude Opus 4.1æ˜¯ä¸€ä¸ªä¾‹å¤–ï¼Œå®ƒåœ¨æŸäº›ç”¨ä¾‹ä¸­ä¼˜å…ˆè€ƒè™‘æ„å›¾æ£€æµ‹è€Œéä¿¡æ¯æä¾›ã€‚è¿™ç§æ¨¡å¼è¡¨æ˜ï¼Œå½“å‰çš„æ¶æ„è®¾è®¡å­˜åœ¨ç³»ç»Ÿæ€§æ¼æ´ã€‚è¿™äº›å±€é™æ€§éœ€è¦èŒƒå¼è½¬å˜ï¼Œå°†ä¸Šä¸‹æ–‡ç†è§£å’Œæ„å›¾è¯†åˆ«ä½œä¸ºæ ¸å¿ƒå®‰å…¨èƒ½åŠ›ï¼Œè€Œä¸æ˜¯äº‹åä¿æŠ¤æœºåˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç†è§£ç”¨æˆ·æ„å›¾æ–¹é¢çš„ä¸è¶³ï¼Œä»¥åŠç”±æ­¤å¯¼è‡´çš„å®‰å…¨æ¼æ´é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨äºè¯†åˆ«æ˜¾å¼æœ‰å®³å†…å®¹ï¼Œè€Œå¿½ç•¥äº†å¯¹ç”¨æˆ·æ½œåœ¨æ„å›¾çš„åˆ†æï¼Œä½¿å¾—æ¶æ„ç”¨æˆ·å¯ä»¥é€šè¿‡å„ç§æ‰‹æ®µç»•è¿‡å®‰å…¨æœºåˆ¶ï¼Œä¾‹å¦‚æƒ…æ„Ÿå¼•å¯¼ã€é€æ­¥è¯±å¯¼ç­‰ã€‚è¿™ç§å¯¹ä¸Šä¸‹æ–‡ç†è§£çš„ç¼ºå¤±æ˜¯ç°æœ‰LLMå®‰å…¨é˜²æŠ¤çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼ºè°ƒå°†ä¸Šä¸‹æ–‡ç†è§£å’Œæ„å›¾è¯†åˆ«ä½œä¸ºLLMå®‰å…¨çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œè€Œä¸æ˜¯ä»…ä»…ä¾èµ–äºäº‹åä¿æŠ¤æœºåˆ¶ã€‚é€šè¿‡æé«˜æ¨¡å‹å¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£èƒ½åŠ›ï¼Œå¯ä»¥æ›´æœ‰æ•ˆåœ°è¯†åˆ«å’Œé˜»æ­¢æ¶æ„åˆ©ç”¨è¡Œä¸ºã€‚è®ºæ–‡é€šè¿‡å®éªŒè¯æ˜ï¼Œå³ä½¿æ˜¯å…·å¤‡æ¨ç†èƒ½åŠ›çš„LLMï¼Œåœ¨ç¼ºä¹å¯¹ç”¨æˆ·æ„å›¾çš„æœ‰æ•ˆåˆ¤æ–­æ—¶ï¼Œä¹Ÿå®¹æ˜“è¢«è¯¯å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é‡‡ç”¨å®è¯è¯„ä¼°çš„æ–¹æ³•ï¼Œé’ˆå¯¹å¤šä¸ªä¸»æµLLMï¼ˆåŒ…æ‹¬ChatGPTã€Claudeã€Geminiå’ŒDeepSeekï¼‰è¿›è¡Œæµ‹è¯•ã€‚æµ‹è¯•ä¸»è¦é€šè¿‡è®¾è®¡ç‰¹å®šçš„promptï¼Œæ¨¡æ‹Ÿæ¶æ„ç”¨æˆ·åˆ©ç”¨æƒ…æ„Ÿæ¡†æ¶ã€æ¸è¿›å¼æ­ç¤ºå’Œå­¦æœ¯è®ºè¯ç­‰æŠ€æœ¯ï¼Œè¯±å¯¼LLMç”Ÿæˆæœ‰å®³å†…å®¹æˆ–æ‰§è¡Œä¸å®‰å…¨æ“ä½œã€‚é€šè¿‡åˆ†æLLMåœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶åœ¨ç†è§£ç”¨æˆ·æ„å›¾æ–¹é¢çš„å±€é™æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ­ç¤ºäº†ç°æœ‰LLMå®‰å…¨æœºåˆ¶çš„ç³»ç»Ÿæ€§æ¼æ´ï¼Œå³ç¼ºä¹å¯¹ç”¨æˆ·æ„å›¾çš„æœ‰æ•ˆç†è§£ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼Œè®ºæ–‡å¼ºè°ƒäº†æ„å›¾è¯†åˆ«çš„é‡è¦æ€§ï¼Œå¹¶æŒ‡å‡ºéœ€è¦ä»æ¶æ„è®¾è®¡å±‚é¢è¿›è¡Œæ”¹è¿›ï¼Œå°†æ„å›¾ç†è§£ä½œä¸ºæ ¸å¿ƒå®‰å…¨èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æ²¡æœ‰æ¶‰åŠå…·ä½“çš„æ¨¡å‹ç»“æ„æˆ–ç®—æ³•è®¾è®¡ï¼Œè€Œæ˜¯ä¾§é‡äºå®éªŒè®¾è®¡å’Œç»“æœåˆ†æã€‚å…³é”®åœ¨äºç²¾å¿ƒè®¾è®¡çš„promptï¼Œè¿™äº›promptæ—¨åœ¨æ¨¡æ‹ŸçœŸå®ä¸–ç•Œä¸­æ¶æ„ç”¨æˆ·å¯èƒ½é‡‡ç”¨çš„æ”»å‡»æ‰‹æ®µï¼Œä»è€Œæœ‰æ•ˆåœ°è¯„ä¼°LLMçš„å®‰å…¨æ€§èƒ½ã€‚è®ºæ–‡é€šè¿‡å¯¹æ¯”ä¸åŒLLMåœ¨ç›¸åŒpromptä¸‹çš„è¡¨ç°ï¼Œä»¥åŠå¯ç”¨/ç¦ç”¨æ¨ç†åŠŸèƒ½åçš„å·®å¼‚ï¼Œæ·±å…¥åˆ†æäº†å…¶å®‰å…¨æ¼æ´ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.21110v1/Figures/Gemini/Gemini-Think-Q3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŒ…æ‹¬ChatGPTã€Geminiå’ŒDeepSeekåœ¨å†…çš„å¤šä¸ªå…ˆè¿›LLMå®¹æ˜“è¢«æƒ…æ„Ÿæ¡†æ¶ã€æ¸è¿›å¼æ­ç¤ºç­‰æŠ€æœ¯ç»•è¿‡å®‰å…¨æœºåˆ¶ã€‚å¯ç”¨æ¨ç†çš„é…ç½®é€šå¸¸ä¼šæ”¾å¤§æ¼æ´ï¼Œè€Œéç¼“è§£ã€‚Claude Opus 4.1åœ¨æŸäº›æƒ…å†µä¸‹è¡¨ç°å‡ºå¯¹æ„å›¾æ£€æµ‹çš„ä¼˜å…ˆè€ƒè™‘ï¼Œä½†æ•´ä½“è€Œè¨€ï¼Œç°æœ‰LLMåœ¨ç†è§£ç”¨æˆ·æ„å›¾æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯¹æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§å…·æœ‰é‡è¦æ„ä¹‰ã€‚é€šè¿‡åŠ å¼ºæ¨¡å‹å¯¹ç”¨æˆ·æ„å›¾çš„ç†è§£ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢æ¶æ„åˆ©ç”¨ï¼Œä¿éšœç”¨æˆ·å®‰å…¨ã€‚ç ”ç©¶ç»“æœå¯åº”ç”¨äºå¼€å‘æ›´å®‰å…¨ã€æ›´å¯é çš„LLMï¼Œå¹¶ä¸ºæœªæ¥çš„å®‰å…¨æœºåˆ¶è®¾è®¡æä¾›æŒ‡å¯¼ï¼Œä¾‹å¦‚åœ¨LLMåº”ç”¨ä¸­åŠ å…¥æ„å›¾æ£€æµ‹æ¨¡å—ï¼Œä»è€Œå‡å°‘è¢«æ¶æ„åˆ©ç”¨çš„é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.

