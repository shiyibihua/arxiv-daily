---
layout: default
title: MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning
---

# MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00274" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00274v1</a>
  <a href="https://arxiv.org/pdf/2510.00274.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00274v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00274v1', 'MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maisha Maliha, Dean Hougen

**åˆ†ç±»**: cs.AI, cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 16 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MAGIC-MASKï¼šåŸºäºæ©ç å¯è§£é‡Šæ€§çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åä½œæ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `å¯è§£é‡Šæ€§` `æ©ç å­¦ä¹ ` `æ™ºèƒ½ä½“åä½œ` `è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±åº¦å¼ºåŒ–å­¦ä¹ è§£é‡Šæ€§æ–¹æ³•è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ¢ç´¢è¦†ç›–ä¸è¶³ï¼Œä¸”éš¾ä»¥é€‚åº”å¤šæ™ºèƒ½ä½“ç¯å¢ƒã€‚
2. MAGIC-MASKé€šè¿‡æ™ºèƒ½ä½“é—´åä½œï¼Œå…±äº«æ©ç çŠ¶æ€ä¿¡æ¯å’Œç»éªŒï¼Œå®ç°æ˜¾è‘—æ€§å¼•å¯¼çš„æ©ç æ“ä½œå’Œå¥–åŠ±ä¿¡æ¯å…±äº«ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMAGIC-MASKåœ¨ä¿çœŸåº¦ã€å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥é²æ£’æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶æä¾›å¯è§£é‡Šçš„è§£é‡Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“çš„å†³ç­–è¿‡ç¨‹ç†è§£æ˜¯éƒ¨ç½²äºå®‰å…¨å…³é”®å’Œå¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­çš„å…³é”®æŒ‘æˆ˜ã€‚ç°æœ‰è§£é‡Šæ€§æ–¹æ³•ï¼ˆå¦‚StateMaskï¼‰åœ¨è¯†åˆ«å…³é”®çŠ¶æ€æ–¹é¢æœ‰æ‰€è¿›å±•ï¼Œä½†ä»å—é™äºè®¡ç®—æˆæœ¬ã€æ¢ç´¢è¦†ç›–ç‡ä»¥åŠç¼ºä¹å¯¹å¤šæ™ºèƒ½ä½“ç¯å¢ƒçš„é€‚åº”æ€§ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†MAGIC-MASKï¼Œä¸€ä¸ªåŸºäºæ•°å­¦çš„æ¡†æ¶ï¼Œå°†åŸºäºæ‰°åŠ¨çš„è§£é‡Šæ‰©å±•åˆ°å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ã€‚è¯¥æ–¹æ³•é›†æˆäº†è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ã€è‡ªé€‚åº”epsilon-greedyæ¢ç´¢å’Œè½»é‡çº§æ™ºèƒ½ä½“é—´åä½œï¼Œä»¥å…±äº«æ©ç çŠ¶æ€ä¿¡æ¯å’Œç»éªŒã€‚è¿™ç§åä½œä½¿æ¯ä¸ªæ™ºèƒ½ä½“èƒ½å¤Ÿæ‰§è¡Œæ˜¾è‘—æ€§å¼•å¯¼çš„æ©ç æ“ä½œï¼Œå¹¶ä¸åŒä¼´å…±äº«åŸºäºå¥–åŠ±çš„è§è§£ï¼Œä»è€Œå‡å°‘å…³é”®çŠ¶æ€å‘ç°æ‰€éœ€çš„æ—¶é—´ï¼Œæé«˜è§£é‡Šä¿çœŸåº¦ï¼Œå¹¶å®ç°æ›´å¿«ã€æ›´ç¨³å¥çš„å­¦ä¹ ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºé€šè¿‡ç»Ÿä¸€çš„æ•°å­¦å½¢å¼ï¼ˆåŸºäºè½¨è¿¹æ‰°åŠ¨ã€å¥–åŠ±ä¿çœŸåº¦åˆ†æå’ŒKullback-Leibleræ•£åº¦æ­£åˆ™åŒ–ï¼‰å°†å¯è§£é‡Šæ€§ä»å•æ™ºèƒ½ä½“æ¨å¹¿åˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚è¯¥æ¡†æ¶äº§ç”ŸåŸºäºæ¦‚ç‡å»ºæ¨¡å’Œå¤šæ™ºèƒ½ä½“é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹çš„å±€éƒ¨ã€å¯è§£é‡Šçš„è§£é‡Šã€‚æˆ‘ä»¬åœ¨å•æ™ºèƒ½ä½“å’Œå¤šæ™ºèƒ½ä½“åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬å¤šæ™ºèƒ½ä½“é«˜é€Ÿå…¬è·¯é©¾é©¶ç¯å¢ƒå’ŒGoogle Research Footballï¼‰ä¸ŠéªŒè¯äº†è¯¥æ¡†æ¶ï¼Œè¡¨æ˜MAGIC-MASKåœ¨ä¿çœŸåº¦ã€å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥é²æ£’æ€§æ–¹é¢å§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿ï¼ŒåŒæ—¶æä¾›å¯è§£é‡Šå’Œå¯è½¬ç§»çš„è§£é‡Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸‹çš„å¯è§£é‡Šæ€§ä¸è¶³ï¼Œéš¾ä»¥ç†è§£æ™ºèƒ½ä½“çš„å†³ç­–è¿‡ç¨‹ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨å…³é”®åœºæ™¯ä¸‹ã€‚StateMaskç­‰æ–¹æ³•è®¡ç®—æˆæœ¬é«˜ï¼Œæ¢ç´¢èŒƒå›´æœ‰é™ï¼Œä¸”ç¼ºä¹å¯¹å¤šæ™ºèƒ½ä½“åä½œçš„æœ‰æ•ˆæ”¯æŒã€‚å› æ­¤ï¼Œå¦‚ä½•é«˜æ•ˆã€å‡†ç¡®åœ°è§£é‡Šå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMAGIC-MASKçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæ¥æé«˜å¯è§£é‡Šæ€§å’Œå­¦ä¹ æ•ˆç‡ã€‚æ¯ä¸ªæ™ºèƒ½ä½“é€šè¿‡å­¦ä¹ ä¸€ä¸ªæ©ç æ¥è¯†åˆ«å…³é”®çŠ¶æ€ï¼Œå¹¶å°†è¿™äº›ä¿¡æ¯ä¸å…¶ä»–æ™ºèƒ½ä½“å…±äº«ã€‚è¿™ç§åä½œä½¿å¾—æ™ºèƒ½ä½“èƒ½å¤Ÿæ›´å¿«åœ°å‘ç°å…³é”®çŠ¶æ€ï¼Œå¹¶æé«˜è§£é‡Šçš„ä¿çœŸåº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜åˆ©ç”¨å¥–åŠ±ä¿¡æ¯æ¥æŒ‡å¯¼æ™ºèƒ½ä½“é—´çš„åä½œï¼Œä»è€Œæé«˜å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMAGIC-MASKæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼›2) è‡ªé€‚åº”epsilon-greedyæ¢ç´¢ç­–ç•¥ï¼Œç”¨äºå¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼›3) è½»é‡çº§çš„æ™ºèƒ½ä½“é—´åä½œæœºåˆ¶ï¼Œç”¨äºå…±äº«æ©ç çŠ¶æ€ä¿¡æ¯å’Œç»éªŒï¼›4) åŸºäºè½¨è¿¹æ‰°åŠ¨å’Œå¥–åŠ±ä¿çœŸåº¦åˆ†æçš„å¯è§£é‡Šæ€§æ¨¡å—ï¼Œç”¨äºç”Ÿæˆå±€éƒ¨ã€å¯è§£é‡Šçš„è§£é‡Šã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“é¦–å…ˆç‹¬ç«‹å­¦ä¹ ç­–ç•¥ï¼Œç„¶åé€šè¿‡åä½œæœºåˆ¶å…±äº«ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨å¯è§£é‡Šæ€§æ¨¡å—ç”Ÿæˆè§£é‡Šã€‚

**å…³é”®åˆ›æ–°**ï¼šMAGIC-MASKçš„å…³é”®åˆ›æ–°åœ¨äºå°†å¯è§£é‡Šæ€§ä»å•æ™ºèƒ½ä½“ç³»ç»Ÿæ¨å¹¿åˆ°å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚å®ƒé€šè¿‡ç»Ÿä¸€çš„æ•°å­¦å½¢å¼ï¼Œå°†è½¨è¿¹æ‰°åŠ¨ã€å¥–åŠ±ä¿çœŸåº¦åˆ†æå’ŒKullback-Leibleræ•£åº¦æ­£åˆ™åŒ–ç»“åˆèµ·æ¥ï¼Œä»è€Œå®ç°å¯¹å¤šæ™ºèƒ½ä½“å†³ç­–è¿‡ç¨‹çš„è§£é‡Šã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMAGIC-MASKèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æ™ºèƒ½ä½“é—´çš„åä½œï¼Œæé«˜è§£é‡Šçš„ä¿çœŸåº¦å’Œå­¦ä¹ æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨epsilon-greedyæ¢ç´¢ä¸­ï¼Œepsilonçš„å€¼ä¼šæ ¹æ®å­¦ä¹ è¿›åº¦è‡ªé€‚åº”è°ƒæ•´ã€‚æ©ç çš„è®¾è®¡é‡‡ç”¨å¯å­¦ä¹ çš„å‚æ•°ï¼Œå¹¶é€šè¿‡æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ï¼ŒæŸå¤±å‡½æ•°åŒ…æ‹¬å¥–åŠ±ä¿çœŸåº¦æŸå¤±å’ŒKLæ•£åº¦æ­£åˆ™åŒ–é¡¹ã€‚å¥–åŠ±ä¿çœŸåº¦æŸå¤±ç”¨äºç¡®ä¿æ©ç èƒ½å¤Ÿä¿ç•™å¯¹å¥–åŠ±å½±å“æœ€å¤§çš„çŠ¶æ€ç‰¹å¾ï¼ŒKLæ•£åº¦æ­£åˆ™åŒ–é¡¹ç”¨äºçº¦æŸæ©ç çš„å¤æ‚æ€§ï¼Œé¿å…è¿‡æ‹Ÿåˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MAGIC-MASKåœ¨å¤šæ™ºèƒ½ä½“é«˜é€Ÿå…¬è·¯é©¾é©¶ç¯å¢ƒå’ŒGoogle Research Footballç­‰åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œåœ¨ä¿çœŸåº¦ã€å­¦ä¹ æ•ˆç‡å’Œç­–ç•¥é²æ£’æ€§æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šæ™ºèƒ½ä½“é«˜é€Ÿå…¬è·¯é©¾é©¶ç¯å¢ƒä¸­ï¼ŒMAGIC-MASKèƒ½å¤Ÿæ›´å¿«åœ°å­¦ä¹ åˆ°å®‰å…¨é©¾é©¶ç­–ç•¥ï¼Œå¹¶æä¾›å¯¹è½¦è¾†å†³ç­–è¡Œä¸ºçš„æ¸…æ™°è§£é‡Šã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMAGIC-MASKèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿçš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MAGIC-MASKå¯åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººåä½œã€åšå¼ˆæ¸¸æˆç­‰é¢†åŸŸã€‚åœ¨è‡ªåŠ¨é©¾é©¶ä¸­ï¼Œå¯ä»¥è§£é‡Šè½¦è¾†çš„å†³ç­–è¡Œä¸ºï¼Œæé«˜å®‰å…¨æ€§ã€‚åœ¨æœºå™¨äººåä½œä¸­ï¼Œå¯ä»¥å¸®åŠ©ç†è§£æœºå™¨äººä¹‹é—´çš„äº¤äº’ï¼Œä¼˜åŒ–åä½œç­–ç•¥ã€‚åœ¨åšå¼ˆæ¸¸æˆä¸­ï¼Œå¯ä»¥åˆ†æå¯¹æ‰‹çš„è¡Œä¸ºæ¨¡å¼ï¼Œåˆ¶å®šæ›´æœ‰æ•ˆçš„ç­–ç•¥ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæé«˜äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„é€æ˜åº¦å’Œå¯ä¿¡åº¦ï¼Œä¿ƒè¿›å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Understanding the decision-making process of Deep Reinforcement Learning agents remains a key challenge for deploying these systems in safety-critical and multi-agent environments. While prior explainability methods like StateMask, have advanced the identification of critical states, they remain limited by computational cost, exploration coverage, and lack of adaptation to multi-agent settings. To overcome these limitations, we propose a mathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent Collaboration with Mask-Based Explainability for Reinforcement Learning), that extends perturbation-based explanation to Multi-Agent Reinforcement Learning. Our method integrates Proximal Policy Optimization, adaptive epsilon-greedy exploration, and lightweight inter-agent collaboration to share masked state information and peer experience. This collaboration enables each agent to perform saliency-guided masking and share reward-based insights with peers, reducing the time required for critical state discovery, improving explanation fidelity, and leading to faster and more robust learning. The core novelty of our approach lies in generalizing explainability from single-agent to multi-agent systems through a unified mathematical formalism built on trajectory perturbation, reward fidelity analysis, and Kullback-Leibler divergence regularization. This framework yields localized, interpretable explanations grounded in probabilistic modeling and multi-agent Markov decision processes. We validate our framework on both single-agent and multi-agent benchmarks, including a multi-agent highway driving environment and Google Research Football, demonstrating that MAGIC-MASK consistently outperforms state-of-the-art baselines in fidelity, learning efficiency, and policy robustness while offering interpretable and transferable explanations.

