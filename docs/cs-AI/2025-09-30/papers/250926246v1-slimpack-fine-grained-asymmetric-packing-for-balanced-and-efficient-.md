---
layout: default
title: SlimPack: Fine-Grained Asymmetric Packing for Balanced and Efficient Variable-Length LLM Training
---

# SlimPack: Fine-Grained Asymmetric Packing for Balanced and Efficient Variable-Length LLM Training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26246" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26246v1</a>
  <a href="https://arxiv.org/pdf/2509.26246.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26246v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26246v1', 'SlimPack: Fine-Grained Asymmetric Packing for Balanced and Efficient Variable-Length LLM Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuliang Liu, Guohao Wu, Shenglong Zhang, Wei Zhang, Qianchao Zhu, Zhouyang Li, Chenyu Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SlimPackï¼šé¢å‘å˜é•¿LLMè®­ç»ƒçš„ç»†ç²’åº¦éå¯¹ç§°æ•°æ®æ‰“åŒ…ï¼Œæå‡å¹³è¡¡æ€§å’Œæ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹` `åˆ†å¸ƒå¼è®­ç»ƒ` `æ•°æ®æ‰“åŒ…` `è´Ÿè½½å‡è¡¡` `éå¯¹ç§°è®¡ç®—` `ç»†ç²’åº¦åˆ‡ç‰‡` `è®­ç»ƒæ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMè®­ç»ƒæ–¹æ³•åœ¨å¤„ç†å˜é•¿ä¸Šä¸‹æ–‡æ—¶ï¼Œç”±äºæ•°æ®å¼‚æ„æ€§å’Œéå¯¹ç§°è®¡ç®—æˆæœ¬ï¼Œå¯¼è‡´è´Ÿè½½ä¸å‡è¡¡å’Œç¡¬ä»¶åˆ©ç”¨ç‡ä½ã€‚
2. SlimPackå°†æ ·æœ¬åˆ†è§£ä¸ºç»†ç²’åº¦åˆ‡ç‰‡ï¼Œå¹¶é‡‡ç”¨éå¯¹ç§°åˆ†åŒºç­–ç•¥ï¼Œä¸ºå‰å‘å’Œåå‘ä¼ é€’ä¼˜åŒ–å¹³è¡¡çš„è°ƒåº¦å•å…ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSlimPackç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œè®­ç»ƒååé‡æå‡é«˜è¾¾2.8å€ï¼Œåœ¨å¹³è¡¡æ€§å’Œèµ„æºæ•ˆç‡ä¸Šå‡æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„é«˜æ•ˆåˆ†å¸ƒå¼è®­ç»ƒå—åˆ°ä¸Šä¸‹æ–‡é•¿åº¦æç«¯å·®å¼‚çš„ä¸¥é‡é˜»ç¢ã€‚è¿™ç§æ•°æ®å¼‚æ„æ€§ï¼Œè¢«ä¼ ç»Ÿæ‰“åŒ…ç­–ç•¥å’Œéå¯¹ç§°çš„å‰å‘-åå‘æˆæœ¬æ”¾å¤§ï¼Œå¯¼è‡´äº†ä¸¥é‡çš„ä½æ•ˆç‡ï¼Œä¾‹å¦‚çº§è”å¼çš„å·¥ä½œè´Ÿè½½ä¸å¹³è¡¡å’Œä¸¥é‡çš„ç¡¬ä»¶åˆ©ç”¨ç‡ä¸è¶³ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆè¯•å›¾ç¼“è§£è¿™äº›æŒ‘æˆ˜ï¼Œä½†å¾€å¾€ä»¥ç‰ºç‰²å†…å­˜æˆ–é€šä¿¡æ•ˆç‡ä¸ºä»£ä»·ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†SlimPackï¼Œä¸€ä¸ªé€šè¿‡å°†æ ·æœ¬åˆ†è§£ä¸ºç»†ç²’åº¦åˆ‡ç‰‡æ¥ä»æ ¹æœ¬ä¸Šé‡æ–°æ€è€ƒæ•°æ®æ‰“åŒ…å’Œè°ƒåº¦çš„æ¡†æ¶ã€‚è¿™ç§åˆ‡ç‰‡çº§åˆ«çš„åˆ†è§£ç«‹å³ç¼“è§£äº†å…³é”®çš„å†…å­˜å’Œé€šä¿¡ç“¶é¢ˆï¼Œé€šè¿‡å°†å¤§å‹ã€æ˜“å˜çš„å·¥ä½œè´Ÿè½½è½¬æ¢ä¸ºæ›´å°ã€å¯ç®¡ç†çš„å•å…ƒæµã€‚è¿™ç§çµæ´»æ€§è¢«ç”¨äºæˆ‘ä»¬çš„æ ¸å¿ƒåˆ›æ–°ï¼Œå³éå¯¹ç§°åˆ†åŒºï¼Œå®ƒç»„è£…äº†ä¸“é—¨ä¸ºå‰å‘å’Œåå‘ä¼ é€’çš„ä¸åŒéœ€æ±‚è€Œä¼˜åŒ–çš„å¹³è¡¡è°ƒåº¦å•å…ƒã€‚åœ¨ä¸¤é˜¶æ®µæ±‚è§£å™¨å’Œé«˜ä¿çœŸæ¨¡æ‹Ÿå™¨çš„åè°ƒä¸‹ï¼ŒSlimPackå…¨é¢è§£å†³äº†æ‰€æœ‰å¹¶è¡Œç»´åº¦ä¸Šçš„ä¸å¹³è¡¡é—®é¢˜ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒSlimPackå®ç°äº†é«˜è¾¾2.8å€äºåŸºçº¿çš„è®­ç»ƒååé‡æå‡ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿçš„æƒè¡¡ï¼Œå®ç°äº†å“è¶Šçš„å¹³è¡¡æ€§å’Œé«˜èµ„æºæ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œç”±äºè¾“å…¥æ–‡æœ¬é•¿åº¦å·®å¼‚å¤§ï¼ˆå˜é•¿ä¸Šä¸‹æ–‡ï¼‰ä»¥åŠå‰å‘å’Œåå‘è®¡ç®—é‡ä¸å¯¹ç§°ï¼Œå¯¼è‡´çš„è®­ç»ƒæ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨æ•°æ®æ‰“åŒ…æ—¶ï¼Œæ— æ³•æœ‰æ•ˆå¹³è¡¡å„ä¸ªè®¡ç®—èŠ‚ç‚¹çš„è´Ÿè½½ï¼Œé€ æˆèµ„æºæµªè´¹å’Œè®­ç»ƒé€Ÿåº¦ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSlimPackçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¾“å…¥æ ·æœ¬åˆ†è§£æˆç»†ç²’åº¦çš„åˆ‡ç‰‡ï¼Œç„¶åæ ¹æ®å‰å‘å’Œåå‘è®¡ç®—çš„ä¸åŒéœ€æ±‚ï¼Œé‡‡ç”¨éå¯¹ç§°åˆ†åŒºç­–ç•¥ï¼Œå°†è¿™äº›åˆ‡ç‰‡æ‰“åŒ…æˆå¹³è¡¡çš„è°ƒåº¦å•å…ƒã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥æœ€å¤§é™åº¦åœ°å‡å°‘è´Ÿè½½ä¸å¹³è¡¡ï¼Œæé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSlimPackæ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **ç»†ç²’åº¦åˆ‡ç‰‡**ï¼šå°†è¾“å…¥æ ·æœ¬åˆ†è§£æˆæ›´å°çš„åˆ‡ç‰‡ï¼Œä»¥ä¾¿æ›´çµæ´»åœ°è¿›è¡Œè°ƒåº¦ã€‚2) **éå¯¹ç§°åˆ†åŒº**ï¼šæ ¹æ®å‰å‘å’Œåå‘è®¡ç®—çš„ä¸åŒéœ€æ±‚ï¼Œè®¾è®¡ä¸åŒçš„åˆ†åŒºç­–ç•¥ï¼Œä»¥å®ç°è´Ÿè½½å¹³è¡¡ã€‚3) **ä¸¤é˜¶æ®µæ±‚è§£å™¨**ï¼šç”¨äºä¼˜åŒ–åˆ‡ç‰‡çš„æ‰“åŒ…å’Œè°ƒåº¦ï¼Œç¬¬ä¸€é˜¶æ®µå¿«é€Ÿç”Ÿæˆåˆå§‹æ–¹æ¡ˆï¼Œç¬¬äºŒé˜¶æ®µè¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚4) **é«˜ä¿çœŸæ¨¡æ‹Ÿå™¨**ï¼šç”¨äºè¯„ä¼°ä¸åŒè°ƒåº¦æ–¹æ¡ˆçš„æ€§èƒ½ï¼Œå¹¶æŒ‡å¯¼ä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSlimPackçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»†ç²’åº¦çš„éå¯¹ç§°æ•°æ®æ‰“åŒ…ç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„é™æ€æˆ–å¯å‘å¼æ‰“åŒ…æ–¹æ³•ä¸åŒï¼ŒSlimPackèƒ½å¤Ÿæ ¹æ®å‰å‘å’Œåå‘è®¡ç®—çš„å®é™…éœ€æ±‚ï¼ŒåŠ¨æ€åœ°è°ƒæ•´åˆ‡ç‰‡çš„åˆ†é…ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„è´Ÿè½½å¹³è¡¡ã€‚è¿™ç§æ–¹æ³•æ‰“ç ´äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¹³è¡¡æ€§å’Œèµ„æºæ•ˆç‡ä¹‹é—´çš„æƒè¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šSlimPackçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **åˆ‡ç‰‡å¤§å°çš„é€‰æ‹©**ï¼šéœ€è¦æ ¹æ®ç¡¬ä»¶ç‰¹æ€§å’Œæ¨¡å‹ç»“æ„è¿›è¡Œè°ƒæ•´ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚2) **éå¯¹ç§°åˆ†åŒºç­–ç•¥çš„è®¾è®¡**ï¼šéœ€è¦è€ƒè™‘å‰å‘å’Œåå‘è®¡ç®—çš„æ¯”ä¾‹ï¼Œä»¥åŠä¸åŒè®¡ç®—èŠ‚ç‚¹çš„æ€§èƒ½å·®å¼‚ã€‚3) **ä¸¤é˜¶æ®µæ±‚è§£å™¨çš„ä¼˜åŒ–ç›®æ ‡**ï¼šéœ€è¦ç»¼åˆè€ƒè™‘è´Ÿè½½å¹³è¡¡ã€é€šä¿¡å¼€é”€å’Œå†…å­˜å ç”¨ç­‰å› ç´ ã€‚4) **é«˜ä¿çœŸæ¨¡æ‹Ÿå™¨çš„ç²¾åº¦**ï¼šéœ€è¦å°½å¯èƒ½å‡†ç¡®åœ°æ¨¡æ‹Ÿå®é™…è®­ç»ƒè¿‡ç¨‹ï¼Œä»¥ä¾¿æœ‰æ•ˆåœ°è¯„ä¼°ä¸åŒè°ƒåº¦æ–¹æ¡ˆçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SlimPackåœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œè®­ç»ƒååé‡æå‡é«˜è¾¾2.8å€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSlimPackèƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡å„ä¸ªè®¡ç®—èŠ‚ç‚¹çš„è´Ÿè½½ï¼Œæ˜¾è‘—æé«˜ç¡¬ä»¶åˆ©ç”¨ç‡ï¼Œå¹¶åœ¨å¹³è¡¡æ€§å’Œèµ„æºæ•ˆç‡ä¹‹é—´å–å¾—äº†çªç ´æ€§çš„è¿›å±•ã€‚è¯¥æ–¹æ³•åœ¨ä¸åŒè§„æ¨¡çš„æ¨¡å‹å’Œæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SlimPacké€‚ç”¨äºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„åˆ†å¸ƒå¼è®­ç»ƒï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å˜é•¿æ–‡æœ¬æ•°æ®æ—¶ã€‚å®ƒå¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡ï¼Œé™ä½è®­ç»ƒæˆæœ¬ï¼Œå¹¶åŠ é€ŸLLMçš„è¿­ä»£å’Œéƒ¨ç½²ã€‚è¯¥æŠ€æœ¯è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–å…·æœ‰ç±»ä¼¼æ•°æ®å¼‚æ„æ€§å’Œè®¡ç®—éå¯¹ç§°æ€§çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è¯­éŸ³è¯†åˆ«ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The efficient distributed training of Large Language Models (LLMs) is severely hampered by the extreme variance in context lengths. This data heterogeneity, amplified by conventional packing strategies and asymmetric forward-backward costs, leads to critical inefficiencies such as cascading workload imbalances and severe hardware underutilization. Existing solutions attempt to mitigate these challenges, but often at the expense of memory or communication efficiency.
>   To address these challenges, we introduce SlimPack, a framework that fundamentally rethinks data packing and scheduling by decomposing samples into fine-grained slices. This slice-level decomposition immediately mitigates critical memory and communication bottlenecks by transforming large, volatile workloads into a stream of smaller, manageable units. This flexibility is then harnessed for our core innovation, Asymmetric Partitioning, which assembles balanced scheduling units uniquely optimized for the different demands of the forward and backward passes. Orchestrated by a two-phase solver and a high-fidelity simulator, SlimPack holistically resolves imbalances across all parallel dimensions. Extensive experiments demonstrate that SlimPack achieves up to a $2.8\times$ training throughput improvement over baselines, breaking the conventional trade-off by delivering both superior balance and high resource efficiency.

