---
layout: default
title: BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models
---

# BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00307" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00307v1</a>
  <a href="https://arxiv.org/pdf/2510.00307.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00307v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00307v1', 'BiasBusters: Uncovering and Mitigating Tool Selection Bias in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Thierry Blankenstein, Jialin Yu, Zixuan Li, Vassilis Plachouras, Sunando Sengupta, Philip Torr, Yarin Gal, Alasdair Paren, Adel Bibi

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BiasBustersï¼šæ­ç¤ºå¹¶ç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­å·¥å…·é€‰æ‹©çš„åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å·¥å…·é€‰æ‹©` `åå·®ç¼“è§£` `å…¬å¹³æ€§` `æ™ºèƒ½Agent`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨å·¥å…·é€‰æ‹©ä¸Šå­˜åœ¨åå·®ï¼Œå¯¼è‡´ç”¨æˆ·ä½“éªŒä¸‹é™å’Œå¸‚åœºç«äº‰æ‰­æ›²ã€‚
2. é€šè¿‡æ„å»ºåŸºå‡†æµ‹è¯•é›†ï¼Œåˆ†æå·¥å…·ç‰¹å¾ã€å…ƒæ•°æ®å’Œé¢„è®­ç»ƒæš´éœ²å¯¹é€‰æ‹©åå·®çš„å½±å“ã€‚
3. æå‡ºä¸€ç§è½»é‡çº§çš„ç¼“è§£æ–¹æ³•ï¼Œå…ˆè¿‡æ»¤å€™é€‰å·¥å…·ï¼Œå†å‡åŒ€é‡‡æ ·ï¼Œé™ä½åå·®å¹¶ä¿æŒä»»åŠ¡è¦†ç›–ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„Agenté€šå¸¸ä¾èµ–äºå¤–éƒ¨å·¥å…·ï¼Œè¿™äº›å·¥å…·æ¥è‡ªå¤šä¸ªæä¾›åŠŸèƒ½ç­‰æ•ˆé€‰é¡¹çš„å¸‚åœºã€‚è¿™å¼•å‘äº†ä¸€ä¸ªå…³äºå…¬å¹³æ€§çš„å…³é”®é—®é¢˜ï¼šå¦‚æœé€‰æ‹©å­˜åœ¨ç³»ç»Ÿæ€§åå·®ï¼Œå¯èƒ½ä¼šé™ä½ç”¨æˆ·ä½“éªŒï¼Œå¹¶é€šè¿‡åè¢’æŸäº›æä¾›å•†æ¥æ‰­æ›²ç«äº‰ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªåŒ…å«å¤šç§å·¥å…·ç±»åˆ«çš„åŸºå‡†ï¼Œæ¯ä¸ªç±»åˆ«åŒ…å«å¤šä¸ªåŠŸèƒ½ç­‰æ•ˆçš„å·¥å…·ï¼Œä»¥è¯„ä¼°å·¥å…·é€‰æ‹©åå·®ã€‚ä½¿ç”¨æ­¤åŸºå‡†ï¼Œæˆ‘ä»¬æµ‹è¯•äº†ä¸ƒä¸ªæ¨¡å‹ï¼Œå¹¶è¡¨æ˜å­˜åœ¨ä¸å…¬å¹³ç°è±¡ï¼Œæ¨¡å‹è¦ä¹ˆå›ºå®šäºå•ä¸ªæä¾›å•†ï¼Œè¦ä¹ˆä¸æˆæ¯”ä¾‹åœ°åå¥½ä¸Šä¸‹æ–‡ä¸­è¾ƒæ—©åˆ—å‡ºçš„å·¥å…·ã€‚ä¸ºäº†ç ”ç©¶è¿™ç§åå·®çš„èµ·æºï¼Œæˆ‘ä»¬è¿›è¡Œäº†å—æ§å®éªŒï¼Œæ£€æŸ¥äº†å·¥å…·ç‰¹å¾ã€å…ƒæ•°æ®ï¼ˆåç§°ã€æè¿°ã€å‚æ•°ï¼‰å’Œé¢„è®­ç»ƒæš´éœ²ã€‚æˆ‘ä»¬å‘ç°ï¼šï¼ˆ1ï¼‰æŸ¥è¯¢å’Œå…ƒæ•°æ®ä¹‹é—´çš„è¯­ä¹‰å¯¹é½æ˜¯é€‰æ‹©çš„æœ€å¼ºé¢„æµ‹æŒ‡æ ‡ï¼›ï¼ˆ2ï¼‰æ‰°åŠ¨æè¿°ä¼šæ˜¾è‘—æ”¹å˜é€‰æ‹©ï¼›ï¼ˆ3ï¼‰é‡å¤é¢„è®­ç»ƒæš´éœ²äºå•ä¸ªç«¯ç‚¹ä¼šæ”¾å¤§åå·®ã€‚æœ€åï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§ç¼“è§£æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é¦–å…ˆå°†å€™é€‰å·¥å…·è¿‡æ»¤åˆ°ç›¸å…³å­é›†ï¼Œç„¶åå‡åŒ€é‡‡æ ·ï¼Œä»è€Œåœ¨ä¿æŒè‰¯å¥½ä»»åŠ¡è¦†ç›–ç‡çš„åŒæ—¶å‡å°‘åå·®ã€‚æˆ‘ä»¬çš„å‘ç°å¼ºè°ƒäº†å·¥å…·é€‰æ‹©åå·®æ˜¯å·¥å…·å¢å¼ºå‹LLMå…¬å¹³éƒ¨ç½²çš„å…³é”®éšœç¢ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å·¥å…·é€‰æ‹©è¿‡ç¨‹ä¸­å­˜åœ¨çš„åå·®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é€‰æ‹©åŠŸèƒ½ç­‰æ•ˆçš„å·¥å…·æ—¶ï¼Œå¾€å¾€ä¼šç³»ç»Ÿæ€§åœ°åå‘æŸäº›æä¾›å•†æˆ–ç‰¹å®šå·¥å…·ï¼Œå¯¼è‡´ä¸å…¬å¹³çš„ç«äº‰ç¯å¢ƒå’Œæ¬¡ä¼˜çš„ç”¨æˆ·ä½“éªŒã€‚è¿™ç§åå·®å¯èƒ½æºäºå¤šç§å› ç´ ï¼ŒåŒ…æ‹¬å·¥å…·çš„å…ƒæ•°æ®ã€æ¨¡å‹å¯¹å·¥å…·çš„é¢„è®­ç»ƒæš´éœ²ä»¥åŠå·¥å…·åœ¨åˆ—è¡¨ä¸­çš„ä½ç½®ç­‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªåŒ…å«å¤šä¸ªåŠŸèƒ½ç­‰æ•ˆå·¥å…·çš„åŸºå‡†æµ‹è¯•é›†ï¼Œæ¥é‡åŒ–å’Œåˆ†æLLMåœ¨å·¥å…·é€‰æ‹©ä¸Šçš„åå·®ã€‚ç„¶åï¼Œé€šè¿‡å—æ§å®éªŒï¼Œæ¢ç©¶åå·®çš„æ¥æºï¼Œä¾‹å¦‚å·¥å…·çš„å…ƒæ•°æ®ã€é¢„è®­ç»ƒæ•°æ®ç­‰ã€‚æœ€åï¼Œæå‡ºä¸€ç§è½»é‡çº§çš„ç¼“è§£ç­–ç•¥ï¼Œä»¥å‡å°‘åå·®å¹¶æé«˜å·¥å…·é€‰æ‹©çš„å…¬å¹³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªéƒ¨åˆ†ï¼š1ï¼‰æ„å»ºå·¥å…·é€‰æ‹©åå·®çš„åŸºå‡†æµ‹è¯•é›†ï¼›2ï¼‰è¿›è¡Œå—æ§å®éªŒï¼Œåˆ†æåå·®çš„æ¥æºï¼›3ï¼‰æå‡ºå¹¶è¯„ä¼°ç¼“è§£åå·®çš„ç­–ç•¥ã€‚åŸºå‡†æµ‹è¯•é›†åŒ…å«å¤šä¸ªå·¥å…·ç±»åˆ«ï¼Œæ¯ä¸ªç±»åˆ«ä¸‹æœ‰å¤šä¸ªåŠŸèƒ½ç­‰æ•ˆçš„å·¥å…·ã€‚å—æ§å®éªŒé€šè¿‡æ“çºµå·¥å…·çš„å…ƒæ•°æ®ã€é¢„è®­ç»ƒæ•°æ®ç­‰ï¼Œæ¥è§‚å¯ŸLLMçš„é€‰æ‹©è¡Œä¸ºã€‚ç¼“è§£ç­–ç•¥åŒ…æ‹¬è¿‡æ»¤å€™é€‰å·¥å…·å’Œå‡åŒ€é‡‡æ ·ä¸¤ä¸ªæ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1ï¼‰é¦–æ¬¡ç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†LLMåœ¨å·¥å…·é€‰æ‹©ä¸Šçš„åå·®é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç”¨äºè¯„ä¼°åå·®çš„åŸºå‡†æµ‹è¯•é›†ï¼›2ï¼‰é€šè¿‡å—æ§å®éªŒï¼Œæ­ç¤ºäº†åå·®çš„æ¥æºï¼ŒåŒ…æ‹¬å·¥å…·çš„å…ƒæ•°æ®å’Œé¢„è®­ç»ƒæš´éœ²ï¼›3ï¼‰æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ç¼“è§£ç­–ç•¥ï¼Œå¯ä»¥åœ¨ä¿æŒä»»åŠ¡è¦†ç›–ç‡çš„åŒæ—¶å‡å°‘åå·®ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰åŸºå‡†æµ‹è¯•é›†çš„æ„å»ºï¼Œéœ€è¦ä¿è¯æ¯ä¸ªç±»åˆ«ä¸‹çš„å·¥å…·åŠŸèƒ½ç­‰æ•ˆï¼Œå¹¶ä¸”å…·æœ‰ä¸åŒçš„å…ƒæ•°æ®ï¼›2ï¼‰å—æ§å®éªŒçš„è®¾è®¡ï¼Œéœ€è¦ç²¾ç¡®æ§åˆ¶å®éªŒå˜é‡ï¼Œä¾‹å¦‚å·¥å…·çš„æè¿°ã€åç§°ç­‰ï¼›3ï¼‰ç¼“è§£ç­–ç•¥çš„è®¾è®¡ï¼Œéœ€è¦åœ¨å‡å°‘åå·®çš„åŒæ—¶ï¼Œä¿è¯ä»»åŠ¡çš„è¦†ç›–ç‡ã€‚ç¼“è§£ç­–ç•¥ä¸­ï¼Œè¿‡æ»¤æ­¥éª¤å¯ä»¥ä½¿ç”¨è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…ç­‰æ–¹æ³•ï¼Œå‡åŒ€é‡‡æ ·æ­¥éª¤å¯ä»¥ä½¿ç”¨éšæœºé‡‡æ ·æˆ–åŠ æƒé‡‡æ ·ç­‰æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLMåœ¨å·¥å…·é€‰æ‹©ä¸Šå­˜åœ¨æ˜¾è‘—åå·®ï¼Œæ¨¡å‹å€¾å‘äºé€‰æ‹©è¯­ä¹‰å¯¹é½åº¦é«˜çš„å·¥å…·æˆ–åˆ—è¡¨ä¸­ä½ç½®é å‰çš„å·¥å…·ã€‚é€šè¿‡æå‡ºçš„ç¼“è§£ç­–ç•¥ï¼Œå¯ä»¥åœ¨ä¿æŒä»»åŠ¡è¦†ç›–ç‡çš„å‰æä¸‹ï¼Œæ˜¾è‘—é™ä½å·¥å…·é€‰æ‹©åå·®ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨è¿‡æ»¤å’Œå‡åŒ€é‡‡æ ·åï¼Œåå·®æŒ‡æ ‡é™ä½äº†XX%ï¼ˆå…·ä½“æ•°å€¼è®ºæ–‡ä¸­ç»™å‡ºï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§åŸºäºLLMçš„æ™ºèƒ½Agentç³»ç»Ÿï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ä»å¤šä¸ªåŠŸèƒ½ç­‰æ•ˆçš„å·¥å…·ä¸­è¿›è¡Œé€‰æ‹©çš„åœºæ™¯ä¸­ã€‚ä¾‹å¦‚ï¼Œæ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å®¢æœã€è½¯ä»¶å¼€å‘å·¥å…·ç­‰ã€‚é€šè¿‡å‡å°‘å·¥å…·é€‰æ‹©åå·®ï¼Œå¯ä»¥æé«˜ç”¨æˆ·ä½“éªŒï¼Œä¿ƒè¿›å…¬å¹³ç«äº‰ï¼Œå¹¶æå‡ç³»ç»Ÿçš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Agents backed by large language models (LLMs) often rely on external tools drawn from marketplaces where multiple providers offer functionally equivalent options. This raises a critical point concerning fairness: if selection is systematically biased, it can degrade user experience and distort competition by privileging some providers over others. We introduce a benchmark of diverse tool categories, each containing multiple functionally equivalent tools, to evaluate tool-selection bias. Using this benchmark, we test seven models and show that unfairness exists with models either fixating on a single provider or disproportionately preferring earlier-listed tools in context. To investigate the origins of this bias, we conduct controlled experiments examining tool features, metadata (name, description, parameters), and pre-training exposure. We find that: (1) semantic alignment between queries and metadata is the strongest predictor of choice; (2) perturbing descriptions significantly shifts selections; and (3) repeated pre-training exposure to a single endpoint amplifies bias. Finally, we propose a lightweight mitigation that first filters the candidate tools to a relevant subset and then samples uniformly, reducing bias while preserving good task coverage. Our findings highlight tool-selection bias as a key obstacle for the fair deployment of tool-augmented LLMs.

