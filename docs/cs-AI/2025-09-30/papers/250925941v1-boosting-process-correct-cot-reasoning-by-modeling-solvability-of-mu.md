---
layout: default
title: Boosting Process-Correct CoT Reasoning by Modeling Solvability of Multiple-Choice QA
---

# Boosting Process-Correct CoT Reasoning by Modeling Solvability of Multiple-Choice QA

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25941" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25941v1</a>
  <a href="https://arxiv.org/pdf/2509.25941.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25941v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25941v1', 'Boosting Process-Correct CoT Reasoning by Modeling Solvability of Multiple-Choice QA')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Raphael Schumann, Stefan Riezler

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡å»ºæ¨¡å¤šé€‰é¢˜å¯è§£æ€§ï¼Œæå‡è¿‡ç¨‹æ­£ç¡®çš„CoTæ¨ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ€ç»´é“¾æ¨ç†` `å¯è§£æ€§å»ºæ¨¡` `å¤šé€‰é¢˜é—®ç­”` `å¥–åŠ±æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨å¤šé€‰é¢˜é—®ç­”ä¸­æ˜“äº§ç”Ÿè™šå‡CoTï¼Œå¯¼è‡´é”™è¯¯ç­”æ¡ˆï¼Œå°¤å…¶åœ¨é—®é¢˜ä¸å¯è§£æ—¶ã€‚
2. é€šè¿‡ä¼°è®¡é—®é¢˜çš„å¯è§£æ€§ï¼Œå¹¶å°†å…¶èå…¥å¥–åŠ±æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼Œä¼˜åŒ–æ¨¡å‹å­¦ä¹ è¿‡ç¨‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æ˜¾è‘—æé«˜è¿‡ç¨‹æ­£ç¡®çš„æ¨ç†ç‡ï¼Œå¹¶æå‡å¼ºåŒ–å­¦ä¹ ä¸­çš„ç­”æ¡ˆå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è´¨é‡ä¸ä»…å–å†³äºç”Ÿæˆæ­£ç¡®ç­”æ¡ˆï¼Œè¿˜å–å†³äºç”Ÿæˆæœ‰æ•ˆçš„ä¸­é—´æ­¥éª¤ã€‚æœ¬æ–‡é€šè¿‡å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ï¼ˆMCQAï¼‰ç ”ç©¶äº†è¿™ä¸€ç‚¹ï¼ŒMCQAæä¾›äº†ä¸€ä¸ªå…·æœ‰å›ºå®šç­”æ¡ˆé€‰é¡¹çš„å—æ§ç¯å¢ƒã€‚åˆ†æè¡¨æ˜ï¼Œå½“é—®é¢˜å¯¹äºæ¨¡å‹è€Œè¨€å®é™…ä¸Šæ˜¯æ— æ³•è§£å†³æ—¶ï¼Œè™šå‡çš„æ€ç»´é“¾ï¼ˆCoTï¼‰æ›´æœ‰å¯èƒ½å‡ºç°ï¼Œä»è€Œå¯¼è‡´å‡é˜³æ€§ã€‚é€šè¿‡ä¼°è®¡æ¯ä¸ªé—®é¢˜çš„å¯è§£æ€§ï¼Œæ­ç¤ºäº†ä¸€ä¸ªå­¦ä¹ æœ€æœ‰æ•ˆçš„ä¸­é—´çŠ¶æ€ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè°ƒæ•´äº†ç»“æœç›‘ç£å¥–åŠ±æ¨¡å‹å’Œå…·æœ‰ç¾¤ä½“ç›¸å¯¹ä¼˜åŠ¿çš„å¼ºåŒ–å­¦ä¹ ï¼Œå°†å¯è§£æ€§çº³å…¥å…¶ç›®æ ‡ã€‚åœ¨æ•°å­¦å’Œå¤šæ¨¡æ€æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¿™äº›ä¿®æ”¹å§‹ç»ˆäº§ç”Ÿæ›´é«˜çš„è¿‡ç¨‹æ­£ç¡®æ¨ç†ç‡ï¼Œå¹¶ä¸”åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç­”æ¡ˆå‡†ç¡®æ€§ä¹Ÿå¾—åˆ°äº†æé«˜ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†å¯è§£æ€§æ˜¯å‡å°‘å¹»è§‰å’Œæé«˜CoTæ¨ç†å¯é æ€§çš„å…³é”®å› ç´ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è¿›è¡Œå¤šé¡¹é€‰æ‹©é¢˜é—®ç­”æ—¶ï¼Œå³ä½¿æœ€ç»ˆç­”æ¡ˆæ­£ç¡®ï¼Œå…¶æ¨ç†è¿‡ç¨‹ï¼ˆChain-of-Thought, CoTï¼‰ä¹Ÿå¯èƒ½æ˜¯ä¸æ­£ç¡®çš„ï¼Œå³æ¨¡å‹ç»™å‡ºçš„æ¨ç†æ­¥éª¤æ˜¯è™šå‡çš„ã€‚å°¤å…¶å½“é—®é¢˜æœ¬èº«å¯¹äºæ¨¡å‹æ¥è¯´æ˜¯éš¾ä»¥è§£å†³æˆ–è€…æ— æ³•è§£å†³çš„æ—¶å€™ï¼Œæ¨¡å‹æ›´å®¹æ˜“äº§ç”Ÿè¿™ç§è™šå‡çš„æ¨ç†è¿‡ç¨‹ï¼Œä»è€Œå¯¼è‡´æœ€ç»ˆç­”æ¡ˆçš„é”™è¯¯ã€‚ç°æœ‰çš„æ–¹æ³•ç¼ºä¹å¯¹é—®é¢˜å¯è§£æ€§çš„è€ƒè™‘ï¼Œå®¹æ˜“åœ¨ä¸å¯è§£çš„é—®é¢˜ä¸Šè¿›è¡Œæ— æ•ˆçš„å­¦ä¹ ï¼Œç”šè‡³äº§ç”Ÿè´Ÿé¢å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å»ºæ¨¡é—®é¢˜çš„å¯è§£æ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºä¼˜åŒ–ç›®æ ‡çš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹åœ¨å¯è§£çš„é—®é¢˜ä¸Šè¿›è¡Œæ›´æœ‰æ•ˆçš„å­¦ä¹ ï¼Œå¹¶å‡å°‘åœ¨ä¸å¯è§£é—®é¢˜ä¸Šäº§ç”Ÿè™šå‡æ¨ç†é“¾çš„å¯èƒ½æ€§ã€‚é€šè¿‡ä¼°è®¡æ¯ä¸ªé—®é¢˜çš„å¯è§£æ€§ï¼Œå¯ä»¥åŒºåˆ†å“ªäº›é—®é¢˜æ˜¯æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ çš„ï¼Œå“ªäº›é—®é¢˜æ˜¯æ¨¡å‹éš¾ä»¥è§£å†³çš„ï¼Œä»è€Œæœ‰é’ˆå¯¹æ€§åœ°è¿›è¡Œè®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”ŸæˆCoTæ¨ç†è¿‡ç¨‹å’Œç­”æ¡ˆï¼›2) ä¼°è®¡é—®é¢˜çš„å¯è§£æ€§ï¼Œå¯ä»¥ä½¿ç”¨æ¨¡å‹è‡ªèº«çš„é¢„æµ‹ç½®ä¿¡åº¦æˆ–è€…å…¶ä»–å¤–éƒ¨ä¿¡æ¯ï¼›3) æ„å»ºå¥–åŠ±æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸ä»…è€ƒè™‘ç­”æ¡ˆçš„æ­£ç¡®æ€§ï¼Œè¿˜è€ƒè™‘æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§å’Œé—®é¢˜çš„å¯è§£æ€§ï¼›4) ä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚PPOï¼ˆProximal Policy Optimizationï¼‰ï¼Œæ ¹æ®å¥–åŠ±æ¨¡å‹çš„åé¦ˆæ¥ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†ç­–ç•¥ã€‚æ¡†æ¶çš„å…³é”®åœ¨äºå°†å¯è§£æ€§ä¿¡æ¯èå…¥åˆ°å¥–åŠ±å‡½æ•°ä¸­ï¼Œä»è€Œå¼•å¯¼æ¨¡å‹å­¦ä¹ æ›´å¯é çš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†é—®é¢˜çš„å¯è§£æ€§å»ºæ¨¡å¹¶èå…¥åˆ°CoTæ¨ç†çš„è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚ä¸ç°æœ‰æ–¹æ³•åªå…³æ³¨ç­”æ¡ˆçš„æ­£ç¡®æ€§ä¸åŒï¼Œè¯¥æ–¹æ³•åŒæ—¶è€ƒè™‘äº†æ¨ç†è¿‡ç¨‹çš„æ­£ç¡®æ€§å’Œé—®é¢˜çš„å¯è§£æ€§ï¼Œä»è€Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å‡å°‘å¹»è§‰å’Œæé«˜æ¨ç†çš„å¯é æ€§ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿè®©æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­æ›´åŠ å…³æ³¨é‚£äº›èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ çš„é—®é¢˜ï¼Œé¿å…åœ¨ä¸å¯è§£çš„é—®é¢˜ä¸Šæµªè´¹è®¡ç®—èµ„æºï¼Œç”šè‡³äº§ç”Ÿè´Ÿé¢å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¥–åŠ±æ¨¡å‹çš„è®¾è®¡ä¸­ï¼Œéœ€è¦è€ƒè™‘å¦‚ä½•æœ‰æ•ˆåœ°å°†å¯è§£æ€§ä¿¡æ¯èå…¥åˆ°å¥–åŠ±å‡½æ•°ä¸­ã€‚ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨å¯è§£æ€§ä½œä¸ºå¥–åŠ±çš„æƒé‡ï¼Œå³å¯¹äºå¯è§£æ€§é«˜çš„é—®é¢˜ï¼Œç»™äºˆæ›´é«˜çš„å¥–åŠ±ï¼Œåä¹‹åˆ™ç»™äºˆè¾ƒä½çš„å¥–åŠ±ã€‚å¦ä¸€ç§æ–¹æ³•æ˜¯å°†å¯è§£æ€§ä½œä¸ºå¥–åŠ±çš„åç§»é‡ï¼Œå³å¯¹äºå¯è§£æ€§é«˜çš„é—®é¢˜ï¼Œå¥–åŠ±å€¼ä¼šç›¸åº”å¢åŠ ï¼Œåä¹‹åˆ™ä¼šå‡å°‘ã€‚åœ¨å¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä½¿ç”¨group-relative advantageæ¥æ›´å¥½åœ°åˆ©ç”¨å¯è§£æ€§ä¿¡æ¯ï¼Œå³æ ¹æ®é—®é¢˜çš„å¯è§£æ€§å°†é—®é¢˜åˆ†æˆä¸åŒçš„ç»„ï¼Œç„¶åè®¡ç®—æ¯ä¸ªé—®é¢˜ç›¸å¯¹äºå…¶æ‰€åœ¨ç»„çš„å¹³å‡è¡¨ç°çš„ä¼˜åŠ¿ï¼Œä»è€Œæ›´å¥½åœ°å¼•å¯¼æ¨¡å‹çš„å­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å°†å¯è§£æ€§çº³å…¥å¥–åŠ±æ¨¡å‹å’Œå¼ºåŒ–å­¦ä¹ ç›®æ ‡ï¼Œè¯¥æ–¹æ³•åœ¨æ•°å­¦å’Œå¤šæ¨¡æ€æ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œè¿‡ç¨‹æ­£ç¡®çš„æ¨ç†ç‡å¾—åˆ°äº†æé«˜ï¼Œå¹¶ä¸”åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œç­”æ¡ˆçš„å‡†ç¡®æ€§ä¹Ÿå¾—åˆ°äº†æ”¹å–„ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œå¯è§£æ€§æ˜¯å½±å“CoTæ¨ç†è´¨é‡çš„å…³é”®å› ç´ ï¼Œå¹¶ä¸”é€šè¿‡å»ºæ¨¡å¯è§£æ€§å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘å¹»è§‰å’Œæé«˜æ¨ç†çš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¯ä¿¡èµ–æ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ç­‰ã€‚é€šè¿‡æé«˜CoTæ¨ç†çš„å¯é æ€§ï¼Œå¯ä»¥å‡å°‘æ¨¡å‹äº§ç”Ÿé”™è¯¯ç»“è®ºçš„é£é™©ï¼Œæå‡ç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæå‡æ¨¡å‹çš„é²æ£’æ€§ï¼Œä½¿å…¶åœ¨é¢å¯¹å¤æ‚æˆ–æ¨¡ç³Šçš„é—®é¢˜æ—¶ï¼Œèƒ½å¤Ÿç»™å‡ºæ›´å‡†ç¡®å’Œå¯é çš„ç­”æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reasoning quality in large language models depends not only on producing correct answers but also on generating valid intermediate steps. We study this through multiple-choice question answering (MCQA), which provides a controlled setting with fixed answer options. Our analysis shows that when questions are effectively unsolvable for a model, spurious chains of thought (CoTs) are more likely to appear, leading to false positives. By estimating the solvability of each question, we uncover an intermediate regime where learning is most effective. Building on this insight, we adapt outcome-supervised reward models and reinforcement learning with group-relative advantage to incorporate solvability into their objectives. Across experiments on math and multimodal datasets, these modifications consistently yield higher rates of process-correct reasoning and, in reinforcement learning, improved answer accuracy as well. Our results highlight solvability as a key factor for reducing hallucinations and increasing reliability in CoT reasoning.

