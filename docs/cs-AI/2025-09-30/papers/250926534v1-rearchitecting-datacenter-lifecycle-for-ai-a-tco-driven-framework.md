---
layout: default
title: Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework
---

# Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26534" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26534v1</a>
  <a href="https://arxiv.org/pdf/2509.26534.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26534v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26534v1', 'Rearchitecting Datacenter Lifecycle for AI: A TCO-Driven Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jovan Stojkovic, Chaojie Zhang, ÃÃ±igo Goiri, Ricardo Bianchini

**åˆ†ç±»**: cs.AI, cs.AR, cs.DC

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé¢å‘AIæ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸçš„TCOé©±åŠ¨æ¡†æ¶ï¼Œä¼˜åŒ–æ„å»ºã€åˆ·æ–°å’Œè¿è¥é˜¶æ®µ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIæ•°æ®ä¸­å¿ƒ` `æ€»æ‹¥æœ‰æˆæœ¬(TCO)` `ç”Ÿå‘½å‘¨æœŸç®¡ç†` `ç¡¬ä»¶åˆ·æ–°` `è¿è¥ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†æ— æ³•æ»¡è¶³AIæ¨¡å‹å¿«é€Ÿå‘å±•ã€èµ„æºéœ€æ±‚å¢é•¿å’Œç¡¬ä»¶å¤šæ ·åŒ–çš„éœ€æ±‚ï¼Œå¯¼è‡´AIæ•°æ®ä¸­å¿ƒTCOé«˜æ˜‚ã€‚
2. æå‡ºä¸€ä¸ªæ•´ä½“çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶ï¼Œåè°ƒå’Œå…±åŒä¼˜åŒ–æ•°æ®ä¸­å¿ƒæ„å»ºã€ç¡¬ä»¶åˆ·æ–°å’Œè¿è¥ä¸‰ä¸ªé˜¶æ®µçš„å†³ç­–ï¼Œé™ä½TCOã€‚
3. é€šè¿‡å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—é™ä½AIæ•°æ®ä¸­å¿ƒçš„æ€»æ‹¥æœ‰æˆæœ¬ï¼ˆTCOï¼‰ï¼Œæœ€é«˜å¯è¾¾40%ï¼Œå¹¶ä¸ºæœªæ¥ç®¡ç†æä¾›æŒ‡å¯¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¿«é€Ÿå‘å±•æ¨åŠ¨äº†å¯¹AIæ¨ç†åŸºç¡€è®¾æ–½çš„å·¨å¤§éœ€æ±‚ï¼Œè€Œè¿™äº›åŸºç¡€è®¾æ–½ä¸»è¦ç”±é«˜ç«¯GPUæä¾›æ”¯æŒã€‚è™½ç„¶è¿™äº›åŠ é€Ÿå™¨æä¾›äº†å¼ºå¤§çš„è®¡ç®—èƒ½åŠ›ï¼Œä½†ç”±äºé¢‘ç¹çš„å‡çº§ã€å¯†é›†çš„åŠŸè€—å’Œæ•£çƒ­éœ€æ±‚ï¼Œå®ƒä»¬ä¹Ÿå¸¦æ¥äº†é«˜æ˜‚çš„èµ„æœ¬å’Œè¿è¥æˆæœ¬ï¼Œä½¿å¾—AIæ•°æ®ä¸­å¿ƒçš„æ€»æ‹¥æœ‰æˆæœ¬ï¼ˆTCOï¼‰æˆä¸ºäº‘æä¾›å•†å…³æ³¨çš„å…³é”®é—®é¢˜ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„æ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆä¸ºé€šç”¨å·¥ä½œè´Ÿè½½è®¾è®¡ï¼‰éš¾ä»¥è·Ÿä¸ŠAIå¿«é€Ÿå‘å±•çš„æ¨¡å‹ã€ä¸æ–­å¢é•¿çš„èµ„æºéœ€æ±‚å’Œå¤šæ ·åŒ–çš„ç¡¬ä»¶é…ç½®ã€‚æœ¬æ–‡é‡æ–°æ€è€ƒäº†AIæ•°æ®ä¸­å¿ƒçš„ç”Ÿå‘½å‘¨æœŸæ–¹æ¡ˆï¼Œæ¶µç›–æ„å»ºã€ç¡¬ä»¶åˆ·æ–°å’Œè¿è¥ä¸‰ä¸ªé˜¶æ®µã€‚å±•ç¤ºäº†ç”µæºã€æ•£çƒ­å’Œç½‘ç»œé…ç½®çš„è®¾è®¡é€‰æ‹©å¦‚ä½•å½±å“é•¿æœŸTCOã€‚è¿˜æ¢è®¨äº†ä¸ç¡¬ä»¶è¶‹åŠ¿ç›¸ç¬¦çš„åˆ·æ–°ç­–ç•¥ã€‚æœ€åï¼Œåˆ©ç”¨è¿è¥è½¯ä»¶ä¼˜åŒ–æ¥é™ä½æˆæœ¬ã€‚è™½ç„¶æ¯ä¸ªé˜¶æ®µçš„ä¼˜åŒ–éƒ½èƒ½å¸¦æ¥å¥½å¤„ï¼Œä½†è¦å……åˆ†å‘æŒ¥æ½œåŠ›ï¼Œéœ€è¦é‡æ–°æ€è€ƒæ•´ä¸ªç”Ÿå‘½å‘¨æœŸã€‚å› æ­¤ï¼Œæå‡ºäº†ä¸€ä¸ªæ•´ä½“çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶ï¼Œåè°ƒå’Œå…±åŒä¼˜åŒ–æ‰€æœ‰ä¸‰ä¸ªé˜¶æ®µçš„å†³ç­–ï¼ŒåŒæ—¶è€ƒè™‘å·¥ä½œè´Ÿè½½åŠ¨æ€ã€ç¡¬ä»¶æ¼”è¿›å’Œç³»ç»Ÿè€åŒ–ã€‚è¯¥ç³»ç»Ÿæ¯”ä¼ ç»Ÿæ–¹æ³•é™ä½äº†é«˜è¾¾40%çš„TCOã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œä¸ºæœªæ¥å¦‚ä½•ç®¡ç†AIæ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸæä¾›äº†æŒ‡å¯¼ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³AIæ•°æ®ä¸­å¿ƒæ€»æ‹¥æœ‰æˆæœ¬ï¼ˆTCOï¼‰è¿‡é«˜çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”å¯¹AIå·¥ä½œè´Ÿè½½çš„ç‰¹æ®Šéœ€æ±‚ï¼Œä¾‹å¦‚å¿«é€Ÿè¿­ä»£çš„æ¨¡å‹ã€ä¸æ–­å¢é•¿çš„è®¡ç®—éœ€æ±‚ä»¥åŠå¤šæ ·åŒ–çš„ç¡¬ä»¶é…ç½®ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”µæºã€æ•£çƒ­ã€ç¡¬ä»¶åˆ·æ–°å’Œè¿è¥ä¼˜åŒ–ç­‰æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´èµ„æºåˆ©ç”¨ç‡ä½ã€èƒ½æºæ¶ˆè€—é«˜ï¼Œæœ€ç»ˆå¢åŠ äº†TCOã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨æ•´ä½“çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æ–¹æ³•ï¼Œå°†AIæ•°æ®ä¸­å¿ƒçš„æ„å»ºã€ç¡¬ä»¶åˆ·æ–°å’Œè¿è¥ä¸‰ä¸ªé˜¶æ®µè§†ä¸ºä¸€ä¸ªæ•´ä½“è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡åè°ƒå’Œå…±åŒä¼˜åŒ–è¿™ä¸‰ä¸ªé˜¶æ®µçš„å†³ç­–ï¼Œå……åˆ†è€ƒè™‘å·¥ä½œè´Ÿè½½åŠ¨æ€ã€ç¡¬ä»¶æ¼”è¿›å’Œç³»ç»Ÿè€åŒ–ç­‰å› ç´ ï¼Œä»è€Œå®ç°TCOçš„æœ€å°åŒ–ã€‚è¿™ç§æ–¹æ³•å¼ºè°ƒè·¨é˜¶æ®µçš„ååŒæ•ˆåº”ï¼Œé¿å…äº†å­¤ç«‹åœ°ä¼˜åŒ–å•ä¸ªé˜¶æ®µå¯èƒ½å¯¼è‡´çš„æ¬¡ä¼˜ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šæ„å»ºé˜¶æ®µã€ç¡¬ä»¶åˆ·æ–°é˜¶æ®µå’Œè¿è¥é˜¶æ®µã€‚åœ¨æ„å»ºé˜¶æ®µï¼Œéœ€è¦è€ƒè™‘ç”µæºã€æ•£çƒ­å’Œç½‘ç»œé…ç½®ç­‰å› ç´ ï¼Œä»¥æ”¯æŒæœªæ¥çš„AIå·¥ä½œè´Ÿè½½ã€‚åœ¨ç¡¬ä»¶åˆ·æ–°é˜¶æ®µï¼Œéœ€è¦æ ¹æ®ç¡¬ä»¶å‘å±•è¶‹åŠ¿åˆ¶å®šåˆç†çš„åˆ·æ–°ç­–ç•¥ï¼Œä»¥ä¿æŒè®¡ç®—èƒ½åŠ›çš„ç«äº‰åŠ›ã€‚åœ¨è¿è¥é˜¶æ®µï¼Œéœ€è¦åˆ©ç”¨è½¯ä»¶ä¼˜åŒ–æŠ€æœ¯æ¥æé«˜èµ„æºåˆ©ç”¨ç‡ã€é™ä½èƒ½æºæ¶ˆè€—ã€‚æ¡†æ¶é€šè¿‡ä¸€ä¸ªä¸­å¤®æ§åˆ¶å™¨åè°ƒè¿™ä¸‰ä¸ªé˜¶æ®µçš„å†³ç­–ï¼Œå¹¶æ ¹æ®å®æ—¶æ•°æ®è¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªæ•´ä½“çš„AIæ•°æ®ä¸­å¿ƒç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å„ä¸ªé˜¶æ®µç›¸äº’ç‹¬ç«‹çš„å±€é¢ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç»¼åˆè€ƒè™‘å„ä¸ªé˜¶æ®µçš„å› ç´ ï¼Œå®ç°å…¨å±€ä¼˜åŒ–ï¼Œä»è€Œæ˜¾è‘—é™ä½TCOã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½å¤Ÿæ ¹æ®ç¡¬ä»¶å‘å±•è¶‹åŠ¿å’Œå·¥ä½œè´Ÿè½½åŠ¨æ€è¿›è¡Œè‡ªé€‚åº”è°ƒæ•´ï¼Œä»¥ä¿æŒæ•°æ®ä¸­å¿ƒçš„ç«äº‰åŠ›å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ„å»ºé˜¶æ®µï¼Œè®ºæ–‡è€ƒè™‘äº†ä¸åŒç”µæºå’Œæ•£çƒ­æ–¹æ¡ˆå¯¹é•¿æœŸTCOçš„å½±å“ï¼Œå¹¶æå‡ºäº†ç›¸åº”çš„ä¼˜åŒ–ç­–ç•¥ã€‚åœ¨ç¡¬ä»¶åˆ·æ–°é˜¶æ®µï¼Œè®ºæ–‡ç ”ç©¶äº†ä¸åŒåˆ·æ–°é¢‘ç‡å’Œç¡¬ä»¶é…ç½®å¯¹TCOçš„å½±å“ï¼Œå¹¶æå‡ºäº†åŸºäºç¡¬ä»¶è¶‹åŠ¿çš„åˆ·æ–°ç­–ç•¥ã€‚åœ¨è¿è¥é˜¶æ®µï¼Œè®ºæ–‡åˆ©ç”¨è½¯ä»¶ä¼˜åŒ–æŠ€æœ¯ï¼Œä¾‹å¦‚åŠ¨æ€èµ„æºåˆ†é…å’ŒåŠŸè€—ç®¡ç†ï¼Œæ¥æé«˜èµ„æºåˆ©ç”¨ç‡å’Œé™ä½èƒ½æºæ¶ˆè€—ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œä¼˜åŒ–ç®—æ³•åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†æ¡†æ¶èƒ½å¤Ÿæ˜¾è‘—é™ä½AIæ•°æ®ä¸­å¿ƒçš„TCOï¼Œæœ€é«˜å¯è¾¾40%ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶åœ¨ç”µæºã€æ•£çƒ­å’Œç¡¬ä»¶åˆ·æ–°ç­‰æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æ­¤å¤–ï¼Œå®éªŒè¿˜éªŒè¯äº†è¯¥æ¡†æ¶çš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ ¹æ®ç¡¬ä»¶å‘å±•è¶‹åŠ¿å’Œå·¥ä½œè´Ÿè½½åŠ¨æ€è¿›è¡Œè°ƒæ•´ï¼Œä»¥ä¿æŒæ•°æ®ä¸­å¿ƒçš„ç«äº‰åŠ›å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç±»AIæ•°æ®ä¸­å¿ƒï¼Œç‰¹åˆ«æ˜¯éœ€è¦å¤„ç†å¤§è§„æ¨¡AIæ¨¡å‹è®­ç»ƒå’Œæ¨ç†çš„äº‘æœåŠ¡æä¾›å•†ã€‚é€šè¿‡é‡‡ç”¨è¯¥æ¡†æ¶ï¼Œå¯ä»¥æ˜¾è‘—é™ä½æ•°æ®ä¸­å¿ƒçš„TCOï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›æ›´å…·æˆæœ¬æ•ˆç›Šçš„AIæœåŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¸ºæœªæ¥AIæ•°æ®ä¸­å¿ƒçš„è®¾è®¡å’Œç®¡ç†æä¾›æŒ‡å¯¼ï¼Œä¿ƒè¿›AIæŠ€æœ¯çš„æ™®åŠå’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid rise of large language models (LLMs) has been driving an enormous demand for AI inference infrastructure, mainly powered by high-end GPUs. While these accelerators offer immense computational power, they incur high capital and operational costs due to frequent upgrades, dense power consumption, and cooling demands, making total cost of ownership (TCO) for AI datacenters a critical concern for cloud providers. Unfortunately, traditional datacenter lifecycle management (designed for general-purpose workloads) struggles to keep pace with AI's fast-evolving models, rising resource needs, and diverse hardware profiles. In this paper, we rethink the AI datacenter lifecycle scheme across three stages: building, hardware refresh, and operation. We show how design choices in power, cooling, and networking provisioning impact long-term TCO. We also explore refresh strategies aligned with hardware trends. Finally, we use operation software optimizations to reduce cost. While these optimizations at each stage yield benefits, unlocking the full potential requires rethinking the entire lifecycle. Thus, we present a holistic lifecycle management framework that coordinates and co-optimizes decisions across all three stages, accounting for workload dynamics, hardware evolution, and system aging. Our system reduces the TCO by up to 40\% over traditional approaches. Using our framework we provide guidelines on how to manage AI datacenter lifecycle for the future.

