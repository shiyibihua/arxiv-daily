---
layout: default
title: Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline
---

# Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25991" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25991v2</a>
  <a href="https://arxiv.org/pdf/2509.25991.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25991v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25991v2', 'Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haiyang Li, Yaxiong Wang, Shengeng Tang, Lianwei Wu, Lechao Cheng, Zhun Zhong

**åˆ†ç±»**: cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-15)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOmniFakeæ•°æ®é›†ä¸UMFDetæ¡†æ¶ï¼Œç»Ÿä¸€è§£å†³ç¤¾äº¤åª’ä½“ä¸­äººå·¥ä¸AIç”Ÿæˆçš„å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹` `ç»Ÿä¸€æ¡†æ¶` `è§†è§‰-è¯­è¨€æ¨¡å‹` `æ··åˆä¸“å®¶ç½‘ç»œ` `å½’å› é“¾å¼æ€è€ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹äººå·¥æˆ–AIç”Ÿæˆçš„å¤šæ¨¡æ€è™šå‡ä¿¡æ¯è¿›è¡Œç‹¬ç«‹ç ”ç©¶ï¼Œç¼ºä¹ç»Ÿä¸€å¤„ç†ä¸¤ç§ç±»å‹æ¬ºéª—çš„èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºUMFDetæ¡†æ¶ï¼Œåˆ©ç”¨VLMéª¨å¹²ç½‘ç»œã€ç±»åˆ«æ„ŸçŸ¥MoEé€‚é…å™¨å’Œå½’å› é“¾å¼æ€è€ƒæœºåˆ¶ï¼Œå®ç°å¯¹ä¸¤ç§ç±»å‹è™šå‡ä¿¡æ¯çš„ç»Ÿä¸€æ£€æµ‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒUMFDetåœ¨OmniFakeæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¼˜äºä¸“é—¨çš„åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œç¤¾äº¤åª’ä½“ä¸Šå¤šæ¨¡æ€è™šå‡å†…å®¹çš„æ£€æµ‹æ—¥ç›Šå—åˆ°å…³æ³¨ã€‚ä¸»è¦å­˜åœ¨ä¸¤ç§æ¬ºéª—å½¢å¼ï¼šäººä¸ºåˆ¶é€ çš„è™šå‡ä¿¡æ¯ï¼ˆå¦‚è°£è¨€å’Œè¯¯å¯¼æ€§å¸–å­ï¼‰å’Œç”±å›¾åƒåˆæˆæ¨¡å‹æˆ–è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ç”Ÿæˆçš„AIå†…å®¹ã€‚å°½ç®¡ä¸¤è€…éƒ½å…·æœ‰æ¬ºéª—æ„å›¾ï¼Œä½†é€šå¸¸æ˜¯å­¤ç«‹åœ°è¿›è¡Œç ”ç©¶ã€‚è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶ä¾§é‡äºäººä¸ºæ’°å†™çš„è™šå‡ä¿¡æ¯ï¼Œè€Œè®¡ç®—æœºè§†è§‰é¢†åŸŸåˆ™é’ˆå¯¹AIç”Ÿæˆçš„ä¼ªé€ å†…å®¹ã€‚å› æ­¤ï¼Œç°æœ‰æ¨¡å‹é€šå¸¸åªä¸“ç”¨äºä¸€ç§ç±»å‹çš„è™šå‡å†…å®¹ã€‚ç„¶è€Œï¼Œåœ¨å®é™…åœºæ™¯ä¸­ï¼Œå¤šæ¨¡æ€å¸–å­çš„ç±»å‹é€šå¸¸æ˜¯æœªçŸ¥çš„ï¼Œè¿™é™åˆ¶äº†æ­¤ç±»ä¸“ç”¨ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†å¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æ„å»ºäº†å¤šæ¨¡æ€æ–°é—»æ¬ºéª—ç»¼åˆæ•°æ®é›†ï¼ˆOmniFakeï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«12.7ä¸‡ä¸ªæ ·æœ¬çš„ç»¼åˆåŸºå‡†ï¼Œå®ƒå°†æ¥è‡ªç°æœ‰èµ„æºçš„äººå·¥è™šå‡ä¿¡æ¯ä¸æ–°åˆæˆçš„AIç”Ÿæˆç¤ºä¾‹ç›¸ç»“åˆã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œæˆ‘ä»¬æå‡ºäº†ç»Ÿä¸€å¤šæ¨¡æ€è™šå‡å†…å®¹æ£€æµ‹ï¼ˆUMFDetï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨å¤„ç†è¿™ä¸¤ç§æ¬ºéª—å½¢å¼ã€‚UMFDetåˆ©ç”¨VLMéª¨å¹²ç½‘ç»œï¼Œå¹¶è¾…ä»¥ç±»åˆ«æ„ŸçŸ¥çš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰é€‚é…å™¨æ¥æ•è·ç±»åˆ«ç‰¹å®šçš„çº¿ç´¢ï¼Œä»¥åŠå½’å› é“¾å¼æ€è€ƒæœºåˆ¶ï¼Œä¸ºå®šä½æ˜¾è‘—çš„æ¬ºéª—ä¿¡å·æä¾›éšå¼æ¨ç†æŒ‡å¯¼ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒUMFDetåœ¨ä¸¤ç§è™šå‡ä¿¡æ¯ç±»å‹ä¸Šéƒ½å®ç°äº†ç¨³å¥ä¸”ä¸€è‡´çš„æ€§èƒ½ï¼Œä¼˜äºä¸“é—¨çš„åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸ºå®é™…çš„å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹æä¾›äº†ä¸€ç§å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¤¾äº¤åª’ä½“ä¸­å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•ç»Ÿä¸€å¤„ç†äººå·¥åˆ¶é€ å’ŒAIç”Ÿæˆä¸¤ç§ç±»å‹çš„æ¬ºéª—å†…å®¹ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é’ˆå¯¹å…¶ä¸­ä¸€ç§ç±»å‹è¿›è¡Œä¼˜åŒ–ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å®é™…åœºæ™¯ä¸­ç±»å‹æœªçŸ¥çš„å¤šæ¨¡æ€å¸–å­ï¼Œæ³›åŒ–èƒ½åŠ›è¾ƒå·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ï¼Œä½¿å…¶èƒ½å¤ŸåŒæ—¶å­¦ä¹ å’ŒåŒºåˆ†äººå·¥å’ŒAIç”Ÿæˆçš„å¤šæ¨¡æ€è™šå‡ä¿¡æ¯ã€‚é€šè¿‡åˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰çš„å¼ºå¤§è¡¨ç¤ºèƒ½åŠ›ï¼Œå¹¶å¼•å…¥ç±»åˆ«æ„ŸçŸ¥çš„æ··åˆä¸“å®¶ï¼ˆMoEï¼‰é€‚é…å™¨å’Œå½’å› é“¾å¼æ€è€ƒæœºåˆ¶ï¼Œæ¥å¢å¼ºæ¨¡å‹å¯¹ä¸åŒç±»å‹æ¬ºéª—ä¿¡å·çš„è¯†åˆ«èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUMFDetæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) VLMéª¨å¹²ç½‘ç»œï¼šç”¨äºæå–å¤šæ¨¡æ€ç‰¹å¾ï¼›2) ç±»åˆ«æ„ŸçŸ¥MoEé€‚é…å™¨ï¼šæ ¹æ®è¾“å…¥æ ·æœ¬çš„ç±»åˆ«ï¼ˆäººå·¥æˆ–AIç”Ÿæˆï¼‰é€‰æ‹©ä¸åŒçš„ä¸“å®¶ç½‘ç»œï¼Œä»¥æ•è·ç±»åˆ«ç‰¹å®šçš„çº¿ç´¢ï¼›3) å½’å› é“¾å¼æ€è€ƒæœºåˆ¶ï¼šé€šè¿‡ç”Ÿæˆä¸€ç³»åˆ—ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ä¸æ¬ºéª—ç›¸å…³çš„å…³é”®åŒºåŸŸï¼Œæä¾›éšå¼æ¨ç†æŒ‡å¯¼ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡ç«¯åˆ°ç«¯çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹æ¡†æ¶ï¼Œèƒ½å¤ŸåŒæ—¶å¤„ç†äººå·¥å’ŒAIç”Ÿæˆçš„æ¬ºéª—å†…å®¹ã€‚ç±»åˆ«æ„ŸçŸ¥MoEé€‚é…å™¨å’Œå½’å› é“¾å¼æ€è€ƒæœºåˆ¶æ˜¯ä¸¤ä¸ªé‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹ï¼Œå‰è€…èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†ä¸åŒç±»å‹çš„æ¬ºéª—ä¿¡å·ï¼Œåè€…èƒ½å¤Ÿæä¾›éšå¼æ¨ç†æŒ‡å¯¼ï¼Œå¸®åŠ©æ¨¡å‹å®šä½å…³é”®çš„æ¬ºéª—åŒºåŸŸã€‚

**å…³é”®è®¾è®¡**ï¼šç±»åˆ«æ„ŸçŸ¥MoEé€‚é…å™¨ç”±å¤šä¸ªä¸“å®¶ç½‘ç»œç»„æˆï¼Œæ¯ä¸ªä¸“å®¶ç½‘ç»œè´Ÿè´£å¤„ç†ç‰¹å®šç±»åˆ«çš„æ ·æœ¬ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ ¹æ®è¾“å…¥æ ·æœ¬çš„ç±»åˆ«ï¼Œé€‰æ‹©ç›¸åº”çš„ä¸“å®¶ç½‘ç»œè¿›è¡Œæ¿€æ´»ã€‚å½’å› é“¾å¼æ€è€ƒæœºåˆ¶é€šè¿‡ç”Ÿæˆä¸€ç³»åˆ—ä¸­é—´æ¨ç†æ­¥éª¤ï¼Œä¾‹å¦‚â€œå›¾åƒä¸­æ˜¯å¦å­˜åœ¨ä¸è‡ªç„¶çš„é˜´å½±ï¼Ÿâ€ã€â€œæ–‡æœ¬æè¿°æ˜¯å¦ä¸å›¾åƒå†…å®¹ä¸€è‡´ï¼Ÿâ€ç­‰ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ä¸æ¬ºéª—ç›¸å…³çš„å…³é”®åŒºåŸŸã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åˆ†ç±»æŸå¤±å’Œå½’å› æŸå¤±ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹çš„åˆ†ç±»æ€§èƒ½å’Œå½’å› èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

UMFDetåœ¨OmniFakeæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨äººå·¥è™šå‡ä¿¡æ¯å’ŒAIç”Ÿæˆè™šå‡ä¿¡æ¯ä¸¤ç§ç±»å‹ä¸Šå‡ä¼˜äºä¸“é—¨çš„åŸºçº¿æ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUMFDetèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ç±»åˆ«æ„ŸçŸ¥çš„MoEé€‚é…å™¨å’Œå½’å› é“¾å¼æ€è€ƒæœºåˆ¶ï¼Œæé«˜æ¨¡å‹å¯¹ä¸åŒç±»å‹æ¬ºéª—ä¿¡å·çš„è¯†åˆ«èƒ½åŠ›ï¼Œå®ç°æ›´é²æ£’å’Œä¸€è‡´çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°çš„å†…å®¹å®¡æ ¸ã€æ–°é—»çœŸå®æ€§éªŒè¯ç­‰é¢†åŸŸï¼Œæœ‰åŠ©äºè¯†åˆ«å’Œè¿‡æ»¤è™šå‡ä¿¡æ¯ï¼Œç»´æŠ¤ç½‘ç»œç©ºé—´çš„å¥åº·ç”Ÿæ€ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯æ‰©å±•åˆ°å…¶ä»–å¤šæ¨¡æ€æ¬ºéª—æ£€æµ‹åœºæ™¯ï¼Œä¾‹å¦‚æ·±åº¦ä¼ªé€ è§†é¢‘æ£€æµ‹ã€æ¶æ„è½¯ä»¶è¯†åˆ«ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, detecting fake multimodal content on social media has drawn increasing attention. Two major forms of deception dominate: human-crafted misinformation (e.g., rumors and misleading posts) and AI-generated content produced by image synthesis models or vision-language models (VLMs). Although both share deceptive intent, they are typically studied in isolation. NLP research focuses on human-written misinformation, while the CV community targets AI-generated artifacts. As a result, existing models are often specialized for only one type of fake content. In real-world scenarios, however, the type of a multimodal post is usually unknown, limiting the effectiveness of such specialized systems. To bridge this gap, we construct the Omnibus Dataset for Multimodal News Deception (OmniFake), a comprehensive benchmark of 127K samples that integrates human-curated misinformation from existing resources with newly synthesized AI-generated examples. Based on this dataset, we propose Unified Multimodal Fake Content Detection (UMFDet), a framework designed to handle both forms of deception. UMFDet leverages a VLM backbone augmented with a Category-aware Mixture-of-Experts (MoE) Adapter to capture category-specific cues, and an attribution chain-of-thought mechanism that provides implicit reasoning guidance for locating salient deceptive signals. Extensive experiments demonstrate that UMFDet achieves robust and consistent performance across both misinformation types, outperforming specialized baselines and offering a practical solution for real-world multimodal deception detection.

