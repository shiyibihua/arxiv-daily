---
layout: default
title: CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora
---

# CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21729" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21729v2</a>
  <a href="https://arxiv.org/pdf/2510.21729.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21729v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.21729v2', 'CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nathan Paull

**åˆ†ç±»**: cs.IR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-10-28)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CustomIRï¼šåˆ©ç”¨æ— ç›‘ç£å¾®è°ƒæå‡é¢†åŸŸæ–‡æ¡£è¯­æ–™åº“çš„ç¨ å¯†åµŒå…¥æ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨ å¯†åµŒå…¥` `æ— ç›‘ç£å­¦ä¹ ` `é¢†åŸŸè‡ªé€‚åº”` `ä¿¡æ¯æ£€ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¨ å¯†åµŒå…¥æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸè¯­æ–™åº“ä¸Šçš„æ£€ç´¢æ€§èƒ½ä¸‹é™ï¼Œç¼ºä¹é¢†åŸŸé€‚åº”æ€§ã€‚
2. CustomIRåˆ©ç”¨LLMç”ŸæˆåˆæˆæŸ¥è¯¢-æ–‡æ¡£å¯¹è¿›è¡Œæ— ç›‘ç£å¾®è°ƒï¼Œæ— éœ€äººå·¥æ ‡æ³¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒCustomIRèƒ½æœ‰æ•ˆæå‡å°å‹æ¨¡å‹åœ¨ä¼ä¸šæ•°æ®ä¸Šçš„æ£€ç´¢æ€§èƒ½ï¼Œé™ä½RAGæˆæœ¬ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨ å¯†åµŒå…¥æ¨¡å‹åœ¨ç°ä»£ä¿¡æ¯æ£€ç´¢ä¸­è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æµç¨‹ä¸­ã€‚ç„¶è€Œï¼Œå½“åº”ç”¨äºé¢„è®­ç»ƒåˆ†å¸ƒä¹‹å¤–çš„ç‰¹å®šé¢†åŸŸè¯­æ–™åº“æ—¶ï¼Œå®ƒä»¬çš„æ€§èƒ½é€šå¸¸ä¼šä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†CustomIRï¼Œä¸€ä¸ªç”¨äºæ— ç›‘ç£åœ°å°†é¢„è®­ç»ƒè¯­è¨€åµŒå…¥æ¨¡å‹é€‚é…åˆ°ç‰¹å®šé¢†åŸŸè¯­æ–™åº“çš„æ¡†æ¶ï¼Œå®ƒä½¿ç”¨åˆæˆç”Ÿæˆçš„æŸ¥è¯¢-æ–‡æ¡£å¯¹ã€‚CustomIRåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥åˆ›å»ºåŸºäºå·²çŸ¥ç›®æ ‡è¯­æ–™åº“çš„å¤šæ ·åŒ–æŸ¥è¯¢ï¼Œå¹¶ä¸LLMéªŒè¯çš„éš¾è´Ÿæ ·æœ¬é…å¯¹ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹æ˜‚è´µçš„äººå·¥æ ‡æ³¨çš„éœ€æ±‚ã€‚åœ¨ä¼ä¸šç”µå­é‚®ä»¶å’Œæ¶ˆæ¯ä¼ é€’æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCustomIRå§‹ç»ˆå¦‚ä¸€åœ°æé«˜äº†æ£€ç´¢æ•ˆæœï¼Œå°å‹æ¨¡å‹çš„Recall@10æœ€å¤šæé«˜äº†2.3ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™ç§æ€§èƒ½æå‡ä½¿å¾—è¿™äº›å°å‹æ¨¡å‹èƒ½å¤Ÿä¸æ›´å¤§çš„æ›¿ä»£æ–¹æ¡ˆç›¸åª²ç¾ï¼Œä»è€Œé™ä½äº†RAGéƒ¨ç½²çš„æˆæœ¬ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæœ‰é’ˆå¯¹æ€§çš„åˆæˆå¾®è°ƒä¸ºæé«˜é¢†åŸŸç‰¹å®šæ€§èƒ½æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”ç»æµé«˜æ•ˆçš„ç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¨ å¯†åµŒå…¥æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸè¯­æ–™åº“ä¸Šçš„æ£€ç´¢æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºäººå·¥æ ‡æ³¨æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œæˆæœ¬é«˜æ˜‚ä¸”éš¾ä»¥æ‰©å±•ã€‚æ­¤å¤–ï¼Œé€šç”¨é¢„è®­ç»ƒæ¨¡å‹éš¾ä»¥æ•æ‰ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ£€ç´¢æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆåˆæˆçš„æŸ¥è¯¢-æ–‡æ¡£å¯¹ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ•°æ®å¯¹é¢„è®­ç»ƒçš„ç¨ å¯†åµŒå…¥æ¨¡å‹è¿›è¡Œæ— ç›‘ç£å¾®è°ƒã€‚é€šè¿‡LLMç”Ÿæˆå¤šæ ·åŒ–çš„æŸ¥è¯¢å’Œéš¾è´Ÿæ ·æœ¬ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ¨¡æ‹ŸçœŸå®åœºæ™¯ï¼Œæé«˜æ¨¡å‹åœ¨ç‰¹å®šé¢†åŸŸçš„æ£€ç´¢æ€§èƒ½ã€‚è¿™ç§æ–¹æ³•é¿å…äº†äººå·¥æ ‡æ³¨çš„æˆæœ¬ï¼Œå¹¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ç‰¹å®šé¢†åŸŸçš„è¯­ä¹‰ç‰¹å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCustomIRæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **è¯­æ–™åº“åˆ†æ**ï¼šåˆ†æç›®æ ‡è¯­æ–™åº“çš„ç‰¹å¾ï¼Œä¾‹å¦‚ä¸»é¢˜ã€é£æ ¼ç­‰ã€‚2) **æŸ¥è¯¢ç”Ÿæˆ**ï¼šä½¿ç”¨LLMæ ¹æ®è¯­æ–™åº“ä¸­çš„æ–‡æ¡£ç”Ÿæˆå¤šæ ·åŒ–çš„æŸ¥è¯¢ã€‚3) **éš¾è´Ÿæ ·æœ¬æŒ–æ˜**ï¼šä½¿ç”¨LLMéªŒè¯å¹¶é€‰æ‹©ä¸æŸ¥è¯¢ç›¸ä¼¼ä½†è¯­ä¹‰ä¸åŒçš„æ–‡æ¡£ä½œä¸ºéš¾è´Ÿæ ·æœ¬ã€‚4) **æ¨¡å‹å¾®è°ƒ**ï¼šä½¿ç”¨ç”Ÿæˆçš„æŸ¥è¯¢-æ–‡æ¡£å¯¹å¯¹é¢„è®­ç»ƒçš„ç¨ å¯†åµŒå…¥æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä¼˜åŒ–æ¨¡å‹çš„æ£€ç´¢æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨LLMè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ï¼Œç”¨äºæ— ç›‘ç£åœ°å¾®è°ƒç¨ å¯†åµŒå…¥æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿçš„æœ‰ç›‘ç£å¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ— éœ€äººå·¥æ ‡æ³¨ï¼Œé™ä½äº†æˆæœ¬å¹¶æé«˜äº†å¯æ‰©å±•æ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨LLMè¿›è¡Œéš¾è´Ÿæ ·æœ¬æŒ–æ˜ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æé«˜æ¨¡å‹çš„åŒºåˆ†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸ¥è¯¢ç”Ÿæˆé˜¶æ®µï¼Œä½¿ç”¨ä¸åŒçš„promptå¼•å¯¼LLMç”Ÿæˆå¤šæ ·åŒ–çš„æŸ¥è¯¢ï¼Œä¾‹å¦‚é‡Šä¹‰ã€æ‰©å±•ã€æ€»ç»“ç­‰ã€‚åœ¨éš¾è´Ÿæ ·æœ¬æŒ–æ˜é˜¶æ®µï¼Œä½¿ç”¨LLMå¯¹å€™é€‰è´Ÿæ ·æœ¬è¿›è¡Œæ’åºï¼Œé€‰æ‹©ä¸æŸ¥è¯¢è¯­ä¹‰ç›¸ä¼¼ä½†å†…å®¹ä¸åŒçš„æ–‡æ¡£ä½œä¸ºéš¾è´Ÿæ ·æœ¬ã€‚åœ¨æ¨¡å‹å¾®è°ƒé˜¶æ®µï¼Œå¯ä»¥ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚InfoNCE lossï¼Œæ¥ä¼˜åŒ–æ¨¡å‹çš„åµŒå…¥è¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCustomIRåœ¨ä¼ä¸šç”µå­é‚®ä»¶å’Œæ¶ˆæ¯ä¼ é€’æ•°æ®é›†ä¸Šæ˜¾è‘—æé«˜äº†æ£€ç´¢æ•ˆæœï¼Œå°å‹æ¨¡å‹çš„Recall@10æœ€å¤šæé«˜äº†2.3ä¸ªç™¾åˆ†ç‚¹ã€‚ç»è¿‡CustomIRå¾®è°ƒçš„å°å‹æ¨¡å‹èƒ½å¤Ÿè¾¾åˆ°ç”šè‡³è¶…è¿‡å¤§å‹æ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œé™ä½äº†RAGç³»ç»Ÿçš„è®¡ç®—æˆæœ¬å’Œéƒ¨ç½²éš¾åº¦ã€‚è¿™äº›ç»“æœéªŒè¯äº†CustomIRåœ¨é¢†åŸŸç‰¹å®šæ£€ç´¢ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CustomIRå¯åº”ç”¨äºä¼ä¸šå†…éƒ¨çŸ¥è¯†åº“ã€å®¢æˆ·æœåŠ¡ç³»ç»Ÿã€æ³•å¾‹æ–‡æ¡£æ£€ç´¢ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡é¢†åŸŸæ–‡æ¡£çš„æ£€ç´¢æ•ˆæœï¼Œå¯ä»¥æé«˜ä¿¡æ¯è·å–æ•ˆç‡ï¼Œæ”¹å–„ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½RAGç³»ç»Ÿçš„éƒ¨ç½²æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é¢†åŸŸï¼Œä¾‹å¦‚åŒ»ç–—ã€é‡‘èç­‰ï¼Œä¸ºç‰¹å®šé¢†åŸŸçš„çŸ¥è¯†æ£€ç´¢æä¾›æ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dense embedding models have become critical for modern information retrieval, particularly in RAG pipelines, but their performance often degrades when applied to specialized corpora outside their pre-training distribution. To address thi we introduce CustomIR, a framework for unsupervised adaptation of pre-trained language embedding models to domain-specific corpora using synthetically generated query-document pairs. CustomIR leverages large language models (LLMs) to create diverse queries grounded in a known target corpus, paired with LLM-verified hard negatives, eliminating the need for costly human annotation. Experiments on enterprise email and messaging datasets show that CustomIR consistently improves retrieval effectiveness with small models gaining up to 2.3 points in Recall@10. This performance increase allows these small models to rival the performance of much larger alternatives, allowing for cheaper RAG deployments. These results highlight that targeted synthetic fine-tuning offers a scalable and cost-efficient strategy for increasing domain-specific performance.

