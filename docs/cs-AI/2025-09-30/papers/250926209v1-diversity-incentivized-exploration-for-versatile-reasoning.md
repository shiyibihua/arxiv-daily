---
layout: default
title: Diversity-Incentivized Exploration for Versatile Reasoning
---

# Diversity-Incentivized Exploration for Versatile Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26209" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26209v1</a>
  <a href="https://arxiv.org/pdf/2509.26209.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26209v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26209v1', 'Diversity-Incentivized Exploration for Versatile Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zican Hu, Shilin Zhang, Yafu Li, Jianhao Yan, Xuyang Hu, Leyang Cui, Xiaoye Qu, Chunlin Chen, Yu Cheng, Zhi Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 26 pages, 10 figures

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/NJU-RL/DIVER)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DIVERï¼šé€šè¿‡å¤šæ ·æ€§æ¿€åŠ±æ¢ç´¢æå‡LLMçš„é€šç”¨æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `å¤šæ ·æ€§æ¿€åŠ±` `æ¢ç´¢ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰RLVRæ–¹æ³•åœ¨LLMæ¨ç†ä»»åŠ¡ä¸­é¢ä¸´æ¢ç´¢ä¸è¶³å’Œæ ·æœ¬æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ï¼Œä¸»è¦åŸå› æ˜¯çŠ¶æ€-åŠ¨ä½œç©ºé—´å·¨å¤§å’Œå¥–åŠ±ç¨€ç–ã€‚
2. DIVERæ¡†æ¶é€šè¿‡å¼•å…¥å…¨å±€åºåˆ—çº§åˆ«å¤šæ ·æ€§ä½œä¸ºå†…åœ¨å¥–åŠ±ï¼Œæ¿€åŠ±LLMåœ¨è¯­ä¹‰ç»“æ„åŒ–ç©ºé—´ä¸­è¿›è¡Œæ·±åº¦æ¢ç´¢ï¼Œæå‡æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDIVERåœ¨é¢†åŸŸå†…å’Œé¢†åŸŸå¤–ä»»åŠ¡ä¸Šå‡ä¼˜äºç°æœ‰RLVRåŸºçº¿ï¼Œå¹¶åœ¨Pass@1å’ŒPass@kè¯„ä¼°ä¸­å–å¾—äº†æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰å·²æˆä¸ºæ¿€åŠ±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›çš„å…³é”®èŒƒä¾‹ã€‚ç”±äºæ¨ç†ä»»åŠ¡ä¸­å·¨å¤§çš„çŠ¶æ€-åŠ¨ä½œç©ºé—´å’Œå¥–åŠ±ç¨€ç–æ€§ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸é¢ä¸´æ¢ç´¢ä¸è¶³å’Œæ ·æœ¬æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†DIVERï¼ˆç”¨äºé€šç”¨æ¨ç†çš„å¤šæ ·æ€§æ¿€åŠ±æ¢ç´¢ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ›æ–°çš„æ¡†æ¶ï¼Œå¼ºè°ƒå…¨å±€åºåˆ—çº§åˆ«å¤šæ ·æ€§çš„å…³é”®ä½œç”¨ï¼Œä»¥æ¿€åŠ±å¯¹é€šç”¨æ¨ç†çš„æ·±åº¦æ¢ç´¢ã€‚æˆ‘ä»¬é¦–å…ˆè¿›è¡Œäº†ä¸€é¡¹åˆæ­¥çš„å®è¯ç ”ç©¶ï¼Œæ­ç¤ºäº†å…¨å±€å¤šæ ·æ€§ä¸æ¨ç†èƒ½åŠ›ä¹‹é—´å­˜åœ¨å¾ˆå¼ºçš„æ­£ç›¸å…³å…³ç³»ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼•å…¥å…¨å±€å¤šæ ·æ€§æ¿€åŠ±ä½œä¸ºå†…åœ¨å¥–åŠ±ï¼Œä»¥ä¿ƒè¿›åœ¨è¯­ä¹‰ç»“æ„åŒ–ç©ºé—´ä¸­çš„æ·±åº¦æ¢ç´¢ã€‚ç»“åˆå†…åœ¨å¥–åŠ±ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ç§åŸºäºåŠ¿çš„å¥–åŠ±å¡‘é€ æœºåˆ¶ï¼Œä»¥ä¿æŒæœ€ä¼˜ç­–ç•¥ä¸å˜æ€§ï¼Œå¹¶è®¾è®¡äº†ç®€å•çš„å¯å‘å¼æ–¹æ³•æ¥ç¼“è§£å¯èƒ½çš„å¥–åŠ±é»‘å®¢è¡Œä¸ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDIVERåœ¨é¢†åŸŸå†…å’Œé¢†åŸŸå¤–ä»»åŠ¡ä¸Šéƒ½ä¼˜äºå…·æœ‰å„ç§æ¢ç´¢ç­–ç•¥çš„ç«äº‰æ€§RLVRåŸºçº¿ï¼Œåœ¨Pass@1å’ŒPass@kè¯„ä¼°ä¸­è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/NJU-RL/DIVERä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ï¼Œç”±äºçŠ¶æ€ç©ºé—´å·¨å¤§å’Œå¥–åŠ±ç¨€ç–å¯¼è‡´çš„æ¢ç´¢ä¸è¶³é—®é¢˜ã€‚ç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ¢ç´¢ï¼Œå¯¼è‡´æ ·æœ¬æ•ˆç‡ä½ä¸‹ï¼Œæœ€ç»ˆå½±å“æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å…¨å±€åºåˆ—çº§åˆ«çš„å¤šæ ·æ€§æ¥æ¿€åŠ±æ¨¡å‹è¿›è¡Œæ›´æ·±å…¥çš„æ¢ç´¢ã€‚ä½œè€…å‘ç°å…¨å±€å¤šæ ·æ€§ä¸æ¨ç†èƒ½åŠ›ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ï¼Œå› æ­¤å°†å¤šæ ·æ€§ä½œä¸ºä¸€ç§å†…åœ¨å¥–åŠ±ï¼Œå¼•å¯¼æ¨¡å‹æ¢ç´¢æ›´å¤šä¸åŒçš„æ¨ç†è·¯å¾„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDIVERæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å¥–åŠ±å‡½æ•°è®¾è®¡ï¼ŒåŒ…å«å¤–éƒ¨å¥–åŠ±ï¼ˆæ¥è‡ªç¯å¢ƒï¼‰å’Œå†…åœ¨å¥–åŠ±ï¼ˆåŸºäºå…¨å±€å¤šæ ·æ€§ï¼‰ï¼›2) åŸºäºåŠ¿çš„å¥–åŠ±å¡‘é€ æœºåˆ¶ï¼Œç”¨äºä¿è¯ç­–ç•¥çš„æœ€ä¼˜æ€§ï¼›3) å¯å‘å¼æ–¹æ³•ï¼Œç”¨äºç¼“è§£å¥–åŠ±é»‘å®¢é—®é¢˜ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œæ¨¡å‹åœ¨ç¯å¢ƒä¸­è¿›è¡Œæ¢ç´¢ï¼Œæ ¹æ®å¤–éƒ¨å¥–åŠ±å’Œå†…åœ¨å¥–åŠ±æ›´æ–°ç­–ç•¥ï¼Œå¹¶é€šè¿‡å¥–åŠ±å¡‘é€ å’Œå¯å‘å¼æ–¹æ³•è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å…¨å±€åºåˆ—çº§åˆ«çš„å¤šæ ·æ€§å¼•å…¥ä½œä¸ºå†…åœ¨å¥–åŠ±ï¼Œç”¨äºæ¿€åŠ±LLMè¿›è¡Œæ·±åº¦æ¢ç´¢ã€‚ä¸ä¼ ç»Ÿçš„æ¢ç´¢æ–¹æ³•ä¸åŒï¼ŒDIVERå…³æ³¨çš„æ˜¯æ•´ä¸ªæ¨ç†åºåˆ—çš„å¤šæ ·æ€§ï¼Œè€Œä¸æ˜¯å•ä¸ªåŠ¨ä½œçš„å¤šæ ·æ€§ï¼Œä»è€Œæ›´å¥½åœ°å¼•å¯¼æ¨¡å‹æ¢ç´¢æ›´æœ‰æ•ˆçš„æ¨ç†è·¯å¾„ã€‚

**å…³é”®è®¾è®¡**ï¼šå†…åœ¨å¥–åŠ±çš„è®¾è®¡æ˜¯å…³é”®ï¼Œè®ºæ–‡ä¸­é‡‡ç”¨æŸç§æ–¹å¼ï¼ˆå…·ä½“æ–¹å¼æœªçŸ¥ï¼Œéœ€è¦æŸ¥çœ‹è®ºæ–‡ç»†èŠ‚ï¼‰æ¥è¡¡é‡å…¨å±€åºåˆ—çš„å¤šæ ·æ€§ï¼Œå¹¶å°†å…¶ä½œä¸ºå†…åœ¨å¥–åŠ±æ·»åŠ åˆ°æ€»å¥–åŠ±ä¸­ã€‚æ­¤å¤–ï¼ŒåŸºäºåŠ¿çš„å¥–åŠ±å¡‘é€ æœºåˆ¶çš„å…·ä½“å®ç°æ–¹å¼ï¼ˆå…·ä½“å…¬å¼æœªçŸ¥ï¼Œéœ€è¦æŸ¥çœ‹è®ºæ–‡ç»†èŠ‚ï¼‰ä»¥åŠå¯å‘å¼æ–¹æ³•çš„å…·ä½“è®¾è®¡ï¼ˆå…·ä½“æ–¹æ³•æœªçŸ¥ï¼Œéœ€è¦æŸ¥çœ‹è®ºæ–‡ç»†èŠ‚ï¼‰ä¹Ÿæ˜¯é‡è¦çš„æŠ€æœ¯ç»†èŠ‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DIVERåœ¨é¢†åŸŸå†…å’Œé¢†åŸŸå¤–ä»»åŠ¡ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨Pass@1å’ŒPass@kè¯„ä¼°ä¸­ï¼ŒDIVERä¼˜äºå„ç§å…·æœ‰ä¸åŒæ¢ç´¢ç­–ç•¥çš„ç«äº‰æ€§RLVRåŸºçº¿ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒDIVERèƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶ä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤æ‚æ¨ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡æå‡LLMçš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æé«˜è¿™äº›åº”ç”¨åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„å•†ä¸šå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a crucial paradigm for incentivizing reasoning capabilities in Large Language Models (LLMs). Due to vast state-action spaces and reward sparsity in reasoning tasks, existing methods often struggle with deficient exploration and poor sample efficiency. In the paper, we propose \textbf{DIVER} (\textbf{D}iversity-\textbf{I}ncentivized Exploration for \textbf{V}ersatil\textbf{E} \textbf{R}easoning), an innovative framework that highlights the pivotal role of global sequence-level diversity to incentivize deep exploration for versatile reasoning. We first conduct a primary empirical study to reveal a strong positive correlation between global diversity and reasoning capacity. Building on this insight, we introduce global diversity incentives as an intrinsic reward to promote deep exploration in a semantically structured space. Incorporating the intrinsic reward, we develop a potential-based reward shaping mechanism to preserve optimal policy invariance and design simple heuristics to mitigate possible reward hacking. Experimental results show that DIVER outperforms competitive RLVR baselines with various exploration strategies on both in-domain and out-of-domain tasks, excelling in both Pass@1 and Pass@k evaluations. Our code is available at https://github.com/NJU-RL/DIVER.

