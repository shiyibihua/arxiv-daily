---
layout: default
title: Iterative Residual Cross-Attention Mechanism: An Integrated Approach for Audio-Visual Navigation Tasks
---

# Iterative Residual Cross-Attention Mechanism: An Integrated Approach for Audio-Visual Navigation Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25652" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25652v1</a>
  <a href="https://arxiv.org/pdf/2509.25652.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25652v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25652v1', 'Iterative Residual Cross-Attention Mechanism: An Integrated Approach for Audio-Visual Navigation Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hailong Zhang, Yinfeng Yu, Liejun Wang, Fuchun Sun, Wendong Zheng

**åˆ†ç±»**: cs.AI, cs.MM, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: Accepted for publication by IEEE International Conference on Systems, Man, and Cybernetics 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIRCAM-AVNï¼Œç”¨äºè§£å†³éŸ³é¢‘-è§†è§‰å¯¼èˆªä»»åŠ¡ä¸­ä¿¡æ¯èåˆä¸åºåˆ—å»ºæ¨¡çš„å†—ä½™å’Œä¸ä¸€è‡´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éŸ³é¢‘-è§†è§‰å¯¼èˆª` `å¤šæ¨¡æ€èåˆ` `äº¤å‰æ³¨æ„åŠ›æœºåˆ¶` `æ®‹å·®å­¦ä¹ ` `åºåˆ—å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸéŸ³é¢‘-è§†è§‰å¯¼èˆªæ–¹æ³•é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œåœ¨ç‰¹å¾èåˆå’Œåºåˆ—å»ºæ¨¡é˜¶æ®µå­˜åœ¨ä¿¡æ¯å†—ä½™å’Œä¼ é€’ä¸ä¸€è‡´çš„é—®é¢˜ã€‚
2. IRCAM-AVNæ¡†æ¶å°†å¤šæ¨¡æ€ä¿¡æ¯èåˆå’Œåºåˆ—å»ºæ¨¡é›†æˆåˆ°ç»Ÿä¸€çš„IRCAMæ¨¡å—ä¸­ï¼Œå®ç°ç«¯åˆ°ç«¯çš„å­¦ä¹ ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨IRCAM-AVNçš„æ™ºèƒ½ä½“åœ¨éŸ³é¢‘-è§†è§‰å¯¼èˆªä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºéŸ³é¢‘-è§†è§‰å¯¼èˆªï¼ˆAVNï¼‰ä»»åŠ¡çš„è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆIRCAM-AVNï¼‰æ¡†æ¶ã€‚ä¼ ç»Ÿçš„AVNæ–¹æ³•é€šå¸¸é‡‡ç”¨åˆ†é˜¶æ®µçš„æ¨¡å—åŒ–è®¾è®¡ï¼Œå³å…ˆè¿›è¡Œç‰¹å¾èåˆï¼Œç„¶åä½¿ç”¨é—¨æ§å¾ªç¯å•å…ƒï¼ˆGRUï¼‰è¿›è¡Œåºåˆ—å»ºæ¨¡ï¼Œæœ€åé€šè¿‡å¼ºåŒ–å­¦ä¹ åšå‡ºå†³ç­–ã€‚è¿™ç§æ–¹æ³•è™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨ç‰¹å¾èåˆå’ŒGRUåºåˆ—å»ºæ¨¡é˜¶æ®µå¯èƒ½å¯¼è‡´å†—ä½™ä¿¡æ¯å¤„ç†å’Œä¿¡æ¯ä¼ é€’ä¸ä¸€è‡´ã€‚IRCAM-AVNæ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå®ƒå°†å¤šæ¨¡æ€ä¿¡æ¯èåˆå’Œåºåˆ—å»ºæ¨¡é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„IRCAMæ¨¡å—ä¸­ï¼Œä»è€Œå–ä»£äº†ä¼ ç»Ÿçš„ç‹¬ç«‹èåˆå’ŒGRUç»„ä»¶ã€‚è¯¥æœºåˆ¶é‡‡ç”¨å¤šçº§æ®‹å·®è®¾è®¡ï¼Œå°†åˆå§‹å¤šæ¨¡æ€åºåˆ—ä¸å¤„ç†åçš„ä¿¡æ¯åºåˆ—è¿æ¥èµ·æ¥ï¼Œé€æ­¥ä¼˜åŒ–ç‰¹å¾æå–è¿‡ç¨‹ï¼Œå‡å°‘æ¨¡å‹åå·®ï¼Œå¢å¼ºæ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶çš„æ™ºèƒ½ä½“è¡¨ç°å‡ºå“è¶Šçš„å¯¼èˆªæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šéŸ³é¢‘-è§†è§‰å¯¼èˆªä»»åŠ¡æ—¨åœ¨è®©æ™ºèƒ½ä½“åˆ©ç”¨è§†è§‰å’Œå¬è§‰ä¿¡æ¯æ‰¾åˆ°å£°éŸ³ç›®æ ‡ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†ç‰¹å¾èåˆã€åºåˆ—å»ºæ¨¡å’Œå†³ç­–åˆ†ä¸ºç‹¬ç«‹é˜¶æ®µã€‚è¿™ç§è®¾è®¡å¯èƒ½å¯¼è‡´å†—ä½™ä¿¡æ¯å¤„ç†ï¼Œå¹¶ä¸”å„æ¨¡å—é—´çš„ä¿¡æ¯ä¼ é€’å¯èƒ½å­˜åœ¨ä¸ä¸€è‡´æ€§ï¼Œé™åˆ¶äº†æ•´ä½“æ€§èƒ½çš„æå‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤šæ¨¡æ€ä¿¡æ¯èåˆå’Œåºåˆ—å»ºæ¨¡æ•´åˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å—ä¸­ï¼Œä»è€Œé¿å…ä¼ ç»Ÿæ¨¡å—åŒ–è®¾è®¡å¸¦æ¥çš„ä¿¡æ¯å†—ä½™å’Œä¼ é€’ä¸ä¸€è‡´é—®é¢˜ã€‚é€šè¿‡è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€æ­¥ä¼˜åŒ–ç‰¹å¾æå–è¿‡ç¨‹ï¼Œå‡å°‘æ¨¡å‹åå·®ï¼Œæé«˜æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIRCAM-AVNæ¡†æ¶æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¶æ„ï¼Œå®ƒä½¿ç”¨ä¸€ä¸ªç»Ÿä¸€çš„IRCAMæ¨¡å—æ¥å¤„ç†éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯ã€‚è¯¥æ¨¡å—æ¥æ”¶æ¥è‡ªç¯å¢ƒçš„éŸ³é¢‘å’Œè§†è§‰è¾“å…¥ï¼Œé€šè¿‡è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œç‰¹å¾èåˆå’Œåºåˆ—å»ºæ¨¡ï¼Œç„¶åç›´æ¥è¾“å‡ºå¯¼èˆªå†³ç­–ã€‚æ•´ä¸ªæ¡†æ¶é€šè¿‡å¼ºåŒ–å­¦ä¹ è¿›è¡Œè®­ç»ƒï¼Œä»¥ä¼˜åŒ–æ™ºèƒ½ä½“çš„å¯¼èˆªç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯è¿­ä»£æ®‹å·®äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼ˆIRCAMï¼‰ã€‚ä¸ä¼ ç»Ÿçš„ç‹¬ç«‹ç‰¹å¾èåˆå’Œåºåˆ—å»ºæ¨¡æ–¹æ³•ä¸åŒï¼ŒIRCAMå°†è¿™ä¸¤ä¸ªè¿‡ç¨‹é›†æˆåˆ°ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å—ä¸­ï¼Œå¹¶é€šè¿‡å¤šçº§æ®‹å·®è¿æ¥é€æ­¥ä¼˜åŒ–ç‰¹å¾æå–ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œå‡å°‘ä¿¡æ¯æŸå¤±ï¼Œå¹¶æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šIRCAMæ¨¡å—çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤šçº§æ®‹å·®è¿æ¥ï¼Œå°†åˆå§‹å¤šæ¨¡æ€åºåˆ—ä¸å¤„ç†åçš„ä¿¡æ¯åºåˆ—è¿æ¥èµ·æ¥ï¼Œé€æ­¥ä¼˜åŒ–ç‰¹å¾æå–ï¼›2) äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºåœ¨éŸ³é¢‘å’Œè§†è§‰ç‰¹å¾ä¹‹é—´å»ºç«‹å…³è”ï¼Œä»è€Œæ›´å¥½åœ°èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼›3) è¿­ä»£å¤„ç†ï¼Œé€šè¿‡å¤šæ¬¡è¿­ä»£æ¥é€æ­¥æç‚¼ç‰¹å¾ï¼Œæé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å¼ºåŒ–å­¦ä¹ ä¸­çš„æ ‡å‡†æŸå¤±å‡½æ•°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºçš„IRCAM-AVNæ¡†æ¶åœ¨éŸ³é¢‘-è§†è§‰å¯¼èˆªä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ã€å¯¹æ¯”åŸºçº¿å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIRCAM-AVNèƒ½å¤Ÿæœ‰æ•ˆåœ°èåˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œæé«˜æ™ºèƒ½ä½“çš„å¯¼èˆªç²¾åº¦å’Œæ•ˆç‡ã€‚è¯¥ç ”ç©¶ä¸ºéŸ³é¢‘-è§†è§‰å¯¼èˆªé¢†åŸŸçš„ç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€æ™ºèƒ½å®¶å±…ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨å¤æ‚ç¯å¢ƒä¸­ï¼Œæœºå™¨äººå¯ä»¥åˆ©ç”¨è§†è§‰å’Œå¬è§‰ä¿¡æ¯æ¥å®šä½ç›®æ ‡ï¼Œå¹¶è§„åˆ’æœ€ä¼˜è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºå¼€å‘æ›´æ™ºèƒ½çš„è¯­éŸ³åŠ©æ‰‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„æŒ‡ä»¤ï¼Œå¹¶æä¾›æ›´å‡†ç¡®çš„æœåŠ¡ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶æœ‰æœ›æ¨åŠ¨å¤šæ¨¡æ€èåˆæŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºæ™ºèƒ½ç³»ç»Ÿçš„è®¾è®¡æä¾›æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Audio-visual navigation represents a significant area of research in which intelligent agents utilize egocentric visual and auditory perceptions to identify audio targets. Conventional navigation methodologies typically adopt a staged modular design, which involves first executing feature fusion, then utilizing Gated Recurrent Unit (GRU) modules for sequence modeling, and finally making decisions through reinforcement learning. While this modular approach has demonstrated effectiveness, it may also lead to redundant information processing and inconsistencies in information transmission between the various modules during the feature fusion and GRU sequence modeling phases. This paper presents IRCAM-AVN (Iterative Residual Cross-Attention Mechanism for Audiovisual Navigation), an end-to-end framework that integrates multimodal information fusion and sequence modeling within a unified IRCAM module, thereby replacing the traditional separate components for fusion and GRU. This innovative mechanism employs a multi-level residual design that concatenates initial multimodal sequences with processed information sequences. This methodological shift progressively optimizes the feature extraction process while reducing model bias and enhancing the model's stability and generalization capabilities. Empirical results indicate that intelligent agents employing the iterative residual cross-attention mechanism exhibit superior navigation performance.

