---
layout: default
title: SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models
---

# SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26345" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26345v1</a>
  <a href="https://arxiv.org/pdf/2509.26345.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26345v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26345v1', 'SafeBehavior: Simulating Human-Like Multistage Reasoning to Mitigate Jailbreak Attacks in Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qinjian Zhao, Jiaqi Wang, Zhiqiang Gao, Zhihao Dou, Belal Abuhaija, Kaizhu Huang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: 27 pages, 5 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SafeBehaviorï¼šæ¨¡æ‹Ÿäººç±»å¤šé˜¶æ®µæ¨ç†ï¼Œç¼“è§£å¤§è¯­è¨€æ¨¡å‹çš„è¶Šç‹±æ”»å‡»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¶Šç‹±æ”»å‡»` `å®‰å…¨é˜²å¾¡` `å¤šé˜¶æ®µæ¨ç†` `æ„å›¾æ¨æ–­` `è‡ªæˆ‘åçœ` `è‡ªæˆ‘ä¿®æ­£`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é˜²å¾¡æ–¹æ³•åœ¨è®¡ç®—æˆæœ¬ã€æ³›åŒ–æ€§å’Œå·¥ä½œæµç¨‹ä¸Šå­˜åœ¨å±€é™ï¼Œéš¾ä»¥æœ‰æ•ˆåº”å¯¹å¤æ‚ä¸Šä¸‹æ–‡ä¸­çš„è¶Šç‹±æ”»å‡»ã€‚
2. SafeBehavioræ¨¡æ‹Ÿäººç±»å¤šé˜¶æ®µæ¨ç†ï¼Œé€šè¿‡æ„å›¾æ¨æ–­ã€è‡ªæˆ‘åçœå’Œè‡ªæˆ‘ä¿®æ­£ä¸‰ä¸ªé˜¶æ®µè¿›è¡Œå®‰å…¨è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSafeBehavioråœ¨å¤šç§è¶Šç‹±æ”»å‡»åœºæ™¯ä¸‹ï¼Œæ˜¾è‘—æå‡äº†LLMçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†ä»¤äººç©ç›®çš„æ€§èƒ½ï¼Œä½†å…¶æ—¥ç›Šå¢é•¿çš„èƒ½åŠ›ä¹Ÿæ”¾å¤§äº†æ½œåœ¨é£é™©ï¼Œä¾‹å¦‚ç»•è¿‡å†…ç½®å®‰å…¨æœºåˆ¶çš„è¶Šç‹±æ”»å‡»ã€‚ç°æœ‰çš„é˜²å¾¡æªæ–½ï¼ŒåŒ…æ‹¬è¾“å…¥é‡Šä¹‰ã€å¤šæ­¥è¯„ä¼°å’Œå®‰å…¨ä¸“å®¶æ¨¡å‹ï¼Œé€šå¸¸é¢ä¸´è®¡ç®—æˆæœ¬é«˜ã€æ³›åŒ–èƒ½åŠ›æœ‰é™æˆ–å·¥ä½œæµç¨‹åƒµåŒ–ç­‰é—®é¢˜ï¼Œæ— æ³•æ£€æµ‹åˆ°åµŒå…¥åœ¨å¤æ‚ä¸Šä¸‹æ–‡ä¸­çš„ç»†å¾®æ¶æ„æ„å›¾ã€‚å—äººç±»å†³ç­–è®¤çŸ¥ç§‘å­¦ç ”ç©¶çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºSafeBehaviorï¼Œä¸€ç§æ–°é¢–çš„åˆ†å±‚è¶Šç‹±é˜²å¾¡æœºåˆ¶ï¼Œæ¨¡æ‹Ÿäººç±»çš„è‡ªé€‚åº”å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹ã€‚SafeBehaviorå°†å®‰å…¨è¯„ä¼°åˆ†è§£ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šæ„å›¾æ¨æ–­ä»¥æ£€æµ‹æ˜æ˜¾çš„è¾“å…¥é£é™©ï¼Œè‡ªæˆ‘åçœä»¥è¯„ä¼°ç”Ÿæˆçš„å“åº”å¹¶åˆ†é…åŸºäºç½®ä¿¡åº¦çš„åˆ¤æ–­ï¼Œä»¥åŠè‡ªæˆ‘ä¿®æ­£ä»¥è‡ªé€‚åº”åœ°é‡å†™ä¸ç¡®å®šçš„è¾“å‡ºï¼ŒåŒæ—¶ä¿ç•™ç”¨æˆ·æ„å›¾å¹¶å¼ºåˆ¶æ‰§è¡Œå®‰å…¨çº¦æŸã€‚æˆ‘ä»¬é’ˆå¯¹äº”ç§å…·æœ‰ä»£è¡¨æ€§çš„è¶Šç‹±æ”»å‡»ç±»å‹ï¼ˆåŒ…æ‹¬åŸºäºä¼˜åŒ–çš„æ”»å‡»ã€ä¸Šä¸‹æ–‡æ“çºµå’ŒåŸºäºæç¤ºçš„æ”»å‡»ï¼‰å¹¿æ³›è¯„ä¼°äº†SafeBehaviorï¼Œå¹¶å°†å…¶ä¸ä¸ƒç§æœ€å…ˆè¿›çš„é˜²å¾¡åŸºçº¿è¿›è¡Œäº†æ¯”è¾ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSafeBehavioræ˜¾è‘—æé«˜äº†å„ç§å¨èƒåœºæ™¯ä¸­çš„é²æ£’æ€§å’Œé€‚åº”æ€§ï¼Œä¸ºä¿æŠ¤LLMå…å—è¶Šç‹±å°è¯•æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å—äººç±»å¯å‘çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å®¹æ˜“å—åˆ°è¶Šç‹±æ”»å‡»çš„é—®é¢˜ã€‚ç°æœ‰çš„é˜²å¾¡æ–¹æ³•ï¼Œå¦‚è¾“å…¥é‡Šä¹‰ã€å¤šæ­¥è¯„ä¼°å’Œå®‰å…¨ä¸“å®¶æ¨¡å‹ï¼Œå­˜åœ¨è®¡ç®—æˆæœ¬é«˜ã€æ³›åŒ–èƒ½åŠ›å·®ä»¥åŠæ— æ³•æœ‰æ•ˆæ£€æµ‹å¤æ‚æ¶æ„æ„å›¾ç­‰ç—›ç‚¹ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥é€‚åº”ä¸æ–­æ¼”å˜çš„æ”»å‡»æ‰‹æ®µï¼Œéœ€è¦æ›´é«˜æ•ˆã€æ›´å…·é€‚åº”æ€§çš„é˜²å¾¡æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSafeBehaviorçš„æ ¸å¿ƒæ€è·¯æ˜¯æ¨¡æ‹Ÿäººç±»åœ¨é¢å¯¹æ½œåœ¨å¨èƒæ—¶çš„å¤šé˜¶æ®µæ¨ç†è¿‡ç¨‹ã€‚é€šè¿‡å°†å®‰å…¨è¯„ä¼°åˆ†è§£ä¸ºæ„å›¾æ¨æ–­ã€è‡ªæˆ‘åçœå’Œè‡ªæˆ‘ä¿®æ­£ä¸‰ä¸ªé˜¶æ®µï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å…¨é¢åœ°è¯†åˆ«å’Œåº”å¯¹è¶Šç‹±æ”»å‡»ã€‚è¿™ç§åˆ†å±‚æ–¹æ³•å…è®¸æ¨¡å‹åœ¨ä¸åŒé˜¶æ®µåº”ç”¨ä¸åŒçš„ç­–ç•¥ï¼Œä»è€Œæé«˜é˜²å¾¡çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSafeBehaviorçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š
1. **æ„å›¾æ¨æ–­ï¼ˆIntention Inferenceï¼‰**ï¼šåˆ†æç”¨æˆ·è¾“å…¥ï¼Œæ£€æµ‹æ˜¯å¦å­˜åœ¨æ˜æ˜¾çš„æ¶æ„æ„å›¾æˆ–æ½œåœ¨é£é™©ã€‚
2. **è‡ªæˆ‘åçœï¼ˆSelf Introspectionï¼‰**ï¼šè¯„ä¼°LLMç”Ÿæˆçš„å“åº”ï¼Œå¹¶æ ¹æ®ç½®ä¿¡åº¦è¿›è¡Œåˆ¤æ–­ï¼Œç¡®å®šå“åº”æ˜¯å¦å®‰å…¨ã€‚
3. **è‡ªæˆ‘ä¿®æ­£ï¼ˆSelf Revisionï¼‰**ï¼šå¯¹äºä¸ç¡®å®šçš„è¾“å‡ºï¼Œè‡ªé€‚åº”åœ°é‡å†™å“åº”ï¼Œç¡®ä¿åœ¨æ»¡è¶³ç”¨æˆ·æ„å›¾çš„åŒæ—¶ï¼Œéµå®ˆå®‰å…¨çº¦æŸã€‚

**å…³é”®åˆ›æ–°**ï¼šSafeBehaviorçš„å…³é”®åˆ›æ–°åœ¨äºå…¶æ¨¡æ‹Ÿäººç±»è®¤çŸ¥è¿‡ç¨‹çš„åˆ†å±‚é˜²å¾¡æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„å•æ­¥æˆ–å›ºå®šæµç¨‹çš„é˜²å¾¡æ–¹æ³•ä¸åŒï¼ŒSafeBehaviorèƒ½å¤Ÿæ ¹æ®ä¸åŒçš„å¨èƒç±»å‹å’Œä¸Šä¸‹æ–‡ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´é˜²å¾¡ç­–ç•¥ã€‚è¿™ç§æ–¹æ³•æ›´å…·çµæ´»æ€§å’Œé²æ£’æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å„ç§å¤æ‚çš„è¶Šç‹±æ”»å‡»ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼š
* **æ„å›¾æ¨æ–­**ï¼šä½¿ç”¨åˆ†ç±»å™¨æˆ–è§„åˆ™å¼•æ“æ¥è¯†åˆ«æ¶æ„å…³é”®è¯ã€çŸ­è¯­æˆ–æ¨¡å¼ã€‚
* **è‡ªæˆ‘åçœ**ï¼šåˆ©ç”¨å®‰å…¨ä¸“å®¶æ¨¡å‹æˆ–åŸºäºè§„åˆ™çš„ç³»ç»Ÿæ¥è¯„ä¼°å“åº”çš„å®‰å…¨æ€§ï¼Œå¹¶åˆ†é…ç½®ä¿¡åº¦åˆ†æ•°ã€‚
* **è‡ªæˆ‘ä¿®æ­£**ï¼šé‡‡ç”¨ç”Ÿæˆæ¨¡å‹æˆ–ç¼–è¾‘æ¨¡å‹æ¥é‡å†™ä¸å®‰å…¨çš„å“åº”ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆå®‰å…¨æ ‡å‡†ï¼ŒåŒæ—¶å°½å¯èƒ½ä¿ç•™ç”¨æˆ·æ„å›¾ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­å¯èƒ½æœ‰æ‰€æè¿°ï¼Œä½†æ‘˜è¦ä¸­æœªæ˜ç¡®æåŠã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSafeBehavioråœ¨å¯¹æŠ—äº”ç§ä»£è¡¨æ€§çš„è¶Šç‹±æ”»å‡»ç±»å‹æ—¶ï¼Œæ˜¾è‘—ä¼˜äºä¸ƒç§æœ€å…ˆè¿›çš„é˜²å¾¡åŸºçº¿ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªæ˜ç¡®ç»™å‡ºï¼Œä½†å¼ºè°ƒäº†SafeBehavioråœ¨å„ç§å¨èƒåœºæ™¯ä¸‹çš„é²æ£’æ€§å’Œé€‚åº”æ€§å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SafeBehaviorå¯åº”ç”¨äºå„ç§éœ€è¦å®‰å…¨ä¿éšœçš„å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€å†…å®¹ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜LLMçš„å®‰å…¨æ€§ï¼Œå¯ä»¥å‡å°‘æ¶æ„ä¿¡æ¯ä¼ æ’­ã€é˜²æ­¢æ¨¡å‹è¢«æ»¥ç”¨ï¼Œä»è€Œæå‡ç”¨æˆ·ä¿¡ä»»åº¦å’Œåº”ç”¨ä»·å€¼ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºæ›´å®‰å…¨ã€æ›´å¯é çš„AIç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have achieved impressive performance across diverse natural language processing tasks, but their growing power also amplifies potential risks such as jailbreak attacks that circumvent built-in safety mechanisms. Existing defenses including input paraphrasing, multi step evaluation, and safety expert models often suffer from high computational costs, limited generalization, or rigid workflows that fail to detect subtle malicious intent embedded in complex contexts. Inspired by cognitive science findings on human decision making, we propose SafeBehavior, a novel hierarchical jailbreak defense mechanism that simulates the adaptive multistage reasoning process of humans. SafeBehavior decomposes safety evaluation into three stages: intention inference to detect obvious input risks, self introspection to assess generated responses and assign confidence based judgments, and self revision to adaptively rewrite uncertain outputs while preserving user intent and enforcing safety constraints. We extensively evaluate SafeBehavior against five representative jailbreak attack types including optimization based, contextual manipulation, and prompt based attacks and compare it with seven state of the art defense baselines. Experimental results show that SafeBehavior significantly improves robustness and adaptability across diverse threat scenarios, offering an efficient and human inspired approach to safeguarding LLMs against jailbreak attempts.

