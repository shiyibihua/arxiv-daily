---
layout: default
title: SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From
---

# SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26404" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26404v1</a>
  <a href="https://arxiv.org/pdf/2509.26404.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26404v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26404v1', 'SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yao Tong, Haonan Wang, Siquan Li, Kenji Kawaguchi, Tianyang Hu

**åˆ†ç±»**: cs.CR, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSeedPrintsä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å½’å±éªŒè¯é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æŒ‡çº¹è¯†åˆ«` `æ¨¡å‹å½’å±` `éšæœºåˆå§‹åŒ–` `èº«ä»½éªŒè¯` `ç»Ÿè®¡æ£€æµ‹` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æŒ‡çº¹è¯†åˆ«æ–¹æ³•åœ¨æ¨¡å‹æ”¶æ•›å‰ä¸å¯é ï¼Œä¸”å¯¹æ•°æ®åˆ†å¸ƒå˜åŒ–æ•æ„Ÿï¼Œéš¾ä»¥è¿›è¡Œæœ‰æ•ˆçš„æ¨¡å‹å½’å±éªŒè¯ã€‚
2. æœ¬æ–‡æå‡ºSeedPrintsæ–¹æ³•ï¼Œåˆ©ç”¨éšæœºåˆå§‹åŒ–åå·®ä½œä¸ºç§å­ä¾èµ–çš„æ ‡è¯†ç¬¦ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒå‰å°±è¯†åˆ«æ¨¡å‹çš„èº«ä»½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSeedPrintsåœ¨LLaMAå’ŒQwenæ¨¡å‹ä¸Šå®ç°äº†é«˜æ•ˆçš„ç§å­çº§åˆ«åŒºåˆ†ï¼Œèƒ½å¤Ÿæä¾›ä»å‡ºç”Ÿåˆ°ç”Ÿå‘½å‘¨æœŸçš„èº«ä»½éªŒè¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒ‡çº¹è¯†åˆ«å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹äºæ¥æºéªŒè¯å’Œæ¨¡å‹å½’å±è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºè®­ç»ƒåŠ¨æ€ã€æ•°æ®æš´éœ²æˆ–è¶…å‚æ•°ç­‰åéªŒç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾åœ¨è®­ç»ƒå¼€å§‹åæ‰ä¼šæ˜¾ç°ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ›´å¼ºå¤§ä¸”å†…åœ¨çš„LLMæŒ‡çº¹è¯†åˆ«æ–¹æ³•ï¼šSeedPrintsï¼Œè¯¥æ–¹æ³•åˆ©ç”¨éšæœºåˆå§‹åŒ–åå·®ä½œä¸ºæŒä¹…çš„ã€ä¾èµ–äºç§å­çš„æ ‡è¯†ç¬¦ï¼Œç”šè‡³åœ¨è®­ç»ƒä¹‹å‰å°±å­˜åœ¨ã€‚æˆ‘ä»¬å±•ç¤ºäº†æœªè®­ç»ƒæ¨¡å‹åœ¨åˆå§‹åŒ–æ—¶ä»…åŸºäºå…¶å‚æ•°è¡¨ç°å‡ºå¯é‡å¤çš„æ ‡è®°é€‰æ‹©åå·®ã€‚è¿™äº›åå·®åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ç¨³å®šä¸”å¯æµ‹é‡ï¼Œä½¿æˆ‘ä»¬çš„ç»Ÿè®¡æ£€æµ‹æ–¹æ³•èƒ½å¤Ÿé«˜ç½®ä¿¡åº¦åœ°æ¢å¤æ¨¡å‹çš„è¡€ç»Ÿã€‚ä¸ä¹‹å‰çš„æŠ€æœ¯ä¸åŒï¼ŒSeedPrintsåœ¨æ‰€æœ‰è®­ç»ƒé˜¶æ®µéƒ½æœ‰æ•ˆï¼Œå¹¶ä¸”åœ¨é¢†åŸŸè½¬ç§»æˆ–å‚æ•°ä¿®æ”¹ä¸‹å…·æœ‰é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSeedPrintså®ç°äº†ç§å­çº§åˆ«çš„å¯åŒºåˆ†æ€§ï¼Œèƒ½å¤Ÿæä¾›ç±»ä¼¼ç”Ÿç‰©ç‰¹å¾æŒ‡çº¹çš„èº«ä»½éªŒè¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹æŒ‡çº¹è¯†åˆ«ä¸­çš„å½’å±éªŒè¯é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ¨¡å‹è®­ç»ƒåˆæœŸä¸å¯é ï¼Œä¸”å¯¹æ•°æ®åˆ†å¸ƒå˜åŒ–æ•æ„Ÿï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆè¯†åˆ«æ¨¡å‹æ¥æºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºSeedPrintsæ–¹æ³•ï¼Œé€šè¿‡åˆ©ç”¨æ¨¡å‹åˆå§‹åŒ–æ—¶çš„éšæœºåå·®ï¼Œä½œä¸ºæŒä¹…çš„ã€ç§å­ä¾èµ–çš„æ ‡è¯†ç¬¦ï¼Œèƒ½å¤Ÿåœ¨è®­ç»ƒå‰å°±å®ç°æ¨¡å‹èº«ä»½çš„è¯†åˆ«ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬åˆå§‹åŒ–é˜¶æ®µçš„å‚æ•°è®¾ç½®ã€è®­ç»ƒè¿‡ç¨‹ä¸­çš„åå·®æµ‹é‡ï¼Œä»¥åŠåç»­çš„ç»Ÿè®¡æ£€æµ‹æ¨¡å—ï¼Œç¡®ä¿åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µå‡èƒ½æœ‰æ•ˆè¯†åˆ«æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSeedPrintsçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶åˆ©ç”¨äº†æ¨¡å‹åˆå§‹åŒ–çš„éšæœºæ€§ï¼Œå½¢æˆäº†ä¸€ç§ç¨³å®šä¸”å¯æµ‹é‡çš„æŒ‡çº¹ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒSeedPrintsåœ¨è®­ç»ƒåˆæœŸå°±èƒ½æä¾›å¯é çš„èº«ä»½éªŒè¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSeedPrintså…³æ³¨äºåˆå§‹åŒ–å‚æ•°çš„é€‰æ‹©å’Œåå·®çš„ç»Ÿè®¡åˆ†æï¼Œç¡®ä¿åœ¨ä¸åŒæ¨¡å‹æ¶æ„å’Œè®­ç»ƒæ¡ä»¶ä¸‹å‡èƒ½ä¿æŒå…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSeedPrintsåœ¨LLaMAå’ŒQwenæ¨¡å‹ä¸Šå®ç°äº†ç§å­çº§åˆ«çš„å¯åŒºåˆ†æ€§ï¼Œèƒ½å¤Ÿåœ¨ä¸åŒè®­ç»ƒé˜¶æ®µä¿æŒé«˜æ•ˆçš„èº«ä»½éªŒè¯èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒSeedPrintsåœ¨æ¨¡å‹è®­ç»ƒåˆæœŸçš„æœ‰æ•ˆæ€§æ˜¾è‘—æå‡ï¼Œç¡®ä¿äº†åœ¨é¢†åŸŸè½¬ç§»å’Œå‚æ•°ä¿®æ”¹ä¸‹çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ¨¡å‹ç›‘ç®¡ã€ç‰ˆæƒä¿æŠ¤å’Œå®‰å…¨å®¡è®¡ç­‰ï¼Œèƒ½å¤Ÿä¸ºå¤§è¯­è¨€æ¨¡å‹çš„æ¥æºéªŒè¯æä¾›å¯é çš„æŠ€æœ¯æ”¯æŒï¼Œæå‡æ¨¡å‹ä½¿ç”¨çš„é€æ˜åº¦å’Œå¯è¿½æº¯æ€§ã€‚æœªæ¥ï¼ŒSeedPrintså¯èƒ½åœ¨å¤šç§AIåº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œç¡®ä¿æ¨¡å‹çš„åˆæ³•æ€§å’Œå¯ä¿¡åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Fingerprinting Large Language Models (LLMs) is essential for provenance verification and model attribution. Existing methods typically extract post-hoc signatures based on training dynamics, data exposure, or hyperparameters -- properties that only emerge after training begins. In contrast, we propose a stronger and more intrinsic notion of LLM fingerprinting: SeedPrints, a method that leverages random initialization biases as persistent, seed-dependent identifiers present even before training. We show that untrained models exhibit reproducible token selection biases conditioned solely on their parameters at initialization. These biases are stable and measurable throughout training, enabling our statistical detection method to recover a model's lineage with high confidence. Unlike prior techniques, unreliable before convergence and vulnerable to distribution shifts, SeedPrints remains effective across all training stages and robust under domain shifts or parameter modifications. Experiments on LLaMA-style and Qwen-style models show that SeedPrints achieves seed-level distinguishability and can provide birth-to-lifecycle identity verification akin to a biometric fingerprint. Evaluations on large-scale pretrained models and fingerprinting benchmarks further confirm its effectiveness under practical deployment scenarios. These results suggest that initialization itself imprints a unique and persistent identity on neural language models, forming a true ''Galtonian'' fingerprint.

