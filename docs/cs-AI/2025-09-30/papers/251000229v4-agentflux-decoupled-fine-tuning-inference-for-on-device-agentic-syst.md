---
layout: default
title: AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems
---

# AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00229" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00229v4</a>
  <a href="https://arxiv.org/pdf/2510.00229.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00229v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00229v4', 'AgentFlux: Decoupled Fine-Tuning & Inference for On-Device Agentic Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rohan Kadekodi, Zhan Jin, Keisuke Kamahori, Yile Gu, Sean Khatiri, Noah H. Bayindirli, Sergey Gorbunov, Baris Kasikci

**åˆ†ç±»**: cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30 (æ›´æ–°: 2025-11-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**AgentFluxï¼šè§£è€¦å¾®è°ƒä¸æ¨ç†ï¼Œç”¨äºç«¯ä¾§Agentç³»ç»Ÿï¼Œæå‡å·¥å…·è°ƒç”¨å‡†ç¡®ç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç«¯ä¾§Agent` `å·¥å…·è°ƒç”¨` `è§£è€¦å¾®è°ƒ` `LoRA` `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `åˆ†å±‚ç¼–æ’` `æœ¬åœ°LLM`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœ¬åœ°LLMåœ¨å·¥å…·è°ƒç”¨åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥è¿›è¡Œå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆï¼Œé™åˆ¶äº†ç«¯ä¾§Agentç³»ç»Ÿçš„åº”ç”¨ã€‚
2. æå‡ºè§£è€¦å¾®è°ƒæ–¹æ³•ï¼Œå°†å·¥å…·è°ƒç”¨ä»»åŠ¡åˆ†è§£ä¸ºå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆï¼Œå¹¶ä¸ºæ¯ä¸ªå­ä»»åŠ¡è®­ç»ƒç‹¬ç«‹çš„LoRAé€‚é…å™¨ã€‚
3. AgentFluxæ¨ç†æ¡†æ¶åˆ©ç”¨è§£è€¦å¾®è°ƒçš„LoRAé€‚é…å™¨ï¼Œç»“åˆåˆ†å±‚ç¼–æ’ï¼Œåœ¨ç«¯ä¾§è®¾å¤‡ä¸Šå®ç°äº†é«˜æ•ˆçš„Agentç¼–æ’ï¼Œæ˜¾è‘—æå‡äº†å·¥å…·è°ƒç”¨å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºagentç¼–æ’å™¨çš„éƒ¨ç½²å½»åº•æ”¹å˜äº†ä»»åŠ¡è‡ªåŠ¨åŒ–ï¼Œä½†å¯¹ä¿æŠ¤éšç§ã€ç»æµé«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆçš„éœ€æ±‚æ¨åŠ¨äº†ç«¯ä¾§æ¨ç†èƒ½åŠ›çš„å‘å±•ã€‚ç„¶è€Œï¼Œåœ¨å·¥å…·è°ƒç”¨åœºæ™¯ä¸­ï¼Œæœ¬åœ°LLMçš„è¡¨ç°å§‹ç»ˆä¸å¦‚å‰æ²¿æ¨¡å‹ï¼Œéš¾ä»¥ä»å¤§å‹å·¥å…·é›†ä¸­é€‰æ‹©å·¥å…·ï¼Œä¹Ÿéš¾ä»¥ç”Ÿæˆå¤æ‚å‚æ•°ç»“æ„çš„å‡†ç¡®å‚æ•°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œå°†å·¥å…·è°ƒç”¨ä»»åŠ¡åˆ†è§£ä¸ºä¸¤ä¸ªä¸åŒçš„å­ä»»åŠ¡ï¼šå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆã€‚æˆ‘ä»¬æå‡ºâ€œè§£è€¦å¾®è°ƒâ€ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„åè®­ç»ƒæ–¹æ³•ï¼Œé‡‡ç”¨LoRAå¾®è°ƒæ¥åˆ›å»ºä¸“ç”¨çš„LoRAé€‚é…å™¨ï¼Œç”¨äºå·¥å…·é€‰æ‹©å’Œç‰¹å®šäºå·¥å…·çš„å‚æ•°ç”Ÿæˆï¼Œå¹¶ä¸ºæ¯ä¸ªå­ä»»åŠ¡ä½¿ç”¨å•ç‹¬çš„æŸå¤±æ©ç ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†AgentFluxï¼Œä¸€ä¸ªæ¨ç†æ¡†æ¶ï¼Œå®ƒåˆ©ç”¨ä½¿ç”¨è§£è€¦å¾®è°ƒåˆ›å»ºçš„LoRAé€‚é…å™¨ï¼Œåœ¨ç»ˆç«¯ç”¨æˆ·è®¾å¤‡ä¸Šå€ŸåŠ©æœ¬åœ°æ¨¡å‹æ‰§è¡Œé«˜æ•ˆçš„agentç¼–æ’ã€‚AgentFluxå°†å·¥å…·è°ƒç”¨ç”Ÿæˆæ­¥éª¤åˆ†è§£ä¸ºå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆï¼Œå¹¶åŠ¨æ€åŠ è½½ç›¸åº”çš„LoRAé€‚é…å™¨ä»¥ç”Ÿæˆå·¥å…·è°ƒç”¨ã€‚æ­¤å¤–ï¼ŒAgentFluxå®ç°äº†åˆ†å±‚ç¼–æ’ï¼Œä»¥é™åˆ¶å·¥å…·é€‰æ‹©æ‰€éœ€çš„å·¥å…·æ•°é‡ã€‚æˆ‘ä»¬åœ¨MCP-BenchåŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œä½¿ç”¨è§£è€¦å¾®è°ƒè®­ç»ƒçš„Qwen-2.5-7Bæ¨¡å‹å°†åŸºç¡€æ¨¡å‹çš„å·¥å…·è°ƒç”¨å‡†ç¡®ç‡æé«˜äº†46%ï¼Œå¹¶ä¸”åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½ä¼˜äºå…¶ä»–ç±»ä¼¼å¤§å°çš„æœ¬åœ°æ¨ç†ã€éæ¨ç†å’Œå¾®è°ƒæ¨¡å‹ï¼Œå¹¶ä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºå¤§2å€çš„æ¨¡å‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœ¬åœ°LLMåœ¨ç«¯ä¾§Agentç³»ç»Ÿä¸­å·¥å…·è°ƒç”¨èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆæ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¯¼è‡´æ•´ä½“æ€§èƒ½ä¸‹é™ï¼Œæ— æ³•æ»¡è¶³éšç§ä¿æŠ¤å’Œæˆæœ¬æ•ˆç›Šçš„éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å·¥å…·è°ƒç”¨ä»»åŠ¡è§£è€¦ä¸ºå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆä¸¤ä¸ªå­ä»»åŠ¡ï¼Œå¹¶åˆ†åˆ«è¿›è¡Œä¼˜åŒ–ã€‚é€šè¿‡é’ˆå¯¹æ¯ä¸ªå­ä»»åŠ¡è¿›è¡Œä¸“é—¨çš„å¾®è°ƒï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAgentFluxæ¡†æ¶åŒ…å«ç¦»çº¿å¾®è°ƒå’Œåœ¨çº¿æ¨ç†ä¸¤ä¸ªé˜¶æ®µã€‚ç¦»çº¿é˜¶æ®µï¼Œä½¿ç”¨è§£è€¦å¾®è°ƒæ–¹æ³•è®­ç»ƒLoRAé€‚é…å™¨ï¼Œåˆ†åˆ«ç”¨äºå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆã€‚åœ¨çº¿æ¨ç†é˜¶æ®µï¼ŒAgentFluxé¦–å…ˆè¿›è¡Œå·¥å…·é€‰æ‹©ï¼Œç„¶ååŠ è½½ç›¸åº”çš„LoRAé€‚é…å™¨ç”Ÿæˆå‚æ•°ï¼Œæœ€åæ‰§è¡Œå·¥å…·è°ƒç”¨ã€‚æ­¤å¤–ï¼ŒAgentFluxè¿˜é‡‡ç”¨äº†åˆ†å±‚ç¼–æ’æ¥å‡å°‘å·¥å…·é€‰æ‹©çš„å¤æ‚åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºè§£è€¦å¾®è°ƒæ–¹æ³•ï¼Œå®ƒé€šè¿‡ç‹¬ç«‹çš„LoRAé€‚é…å™¨å’ŒæŸå¤±æ©ç ï¼Œå®ç°äº†å¯¹å·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆçš„ç²¾ç»†åŒ–ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæå‡æœ¬åœ°LLMåœ¨å¤æ‚å·¥å…·è°ƒç”¨åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šè§£è€¦å¾®è°ƒçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒï¼›2) ä¸ºå·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆè®¾è®¡ç‹¬ç«‹çš„æŸå¤±å‡½æ•°ï¼Œå¹¶ä½¿ç”¨æŸå¤±æ©ç æ¥åŒºåˆ†ä¸åŒçš„å­ä»»åŠ¡ï¼›3) AgentFluxæ¨ç†æ¡†æ¶åŠ¨æ€åŠ è½½LoRAé€‚é…å™¨ï¼Œå¹¶é‡‡ç”¨åˆ†å±‚ç¼–æ’æ¥é™åˆ¶å·¥å…·é€‰æ‹©çš„èŒƒå›´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è§£è€¦å¾®è°ƒè®­ç»ƒçš„Qwen-2.5-7Bæ¨¡å‹åœ¨MCP-BenchåŸºå‡†æµ‹è¯•ä¸­ï¼Œå·¥å…·è°ƒç”¨å‡†ç¡®ç‡æ¯”åŸºç¡€æ¨¡å‹æé«˜äº†46%ã€‚è¯¥æ¨¡å‹åœ¨æ‰€æœ‰æƒ…å†µä¸‹éƒ½ä¼˜äºå…¶ä»–ç±»ä¼¼å¤§å°çš„æœ¬åœ°æ¨ç†ã€éæ¨ç†å’Œå¾®è°ƒæ¨¡å‹ï¼Œå¹¶ä¸”åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ä¼˜äºå¤§2å€çš„æ¨¡å‹ï¼Œè¯æ˜äº†è§£è€¦å¾®è°ƒæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦ç«¯ä¾§æ™ºèƒ½çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¶å±…ã€ç§»åŠ¨åŠå…¬ã€è½¦è½½ç³»ç»Ÿç­‰ã€‚é€šè¿‡åœ¨æœ¬åœ°è®¾å¤‡ä¸Šéƒ¨ç½²AgentFluxï¼Œå¯ä»¥å®ç°éšç§ä¿æŠ¤ã€ä½å»¶è¿Ÿå’Œé«˜å¯é æ€§çš„ä»»åŠ¡è‡ªåŠ¨åŒ–ï¼Œæå‡ç”¨æˆ·ä½“éªŒå¹¶é™ä½è¿è¥æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨Agentç³»ç»Ÿåœ¨æ›´å¹¿æ³›é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The deployment of Large Language Models (LLMs) as agentic orchestrators has revolutionized task automation, but the need for privacy-preserving, cost-effective solutions demands on-device inference capabilities. However, local LLMs consistently underperform compared to frontier models in tool calling scenarios, struggling with both tool selection from large tool sets and accurate argument generation for complex parameter structures. We introduce a methodology that disaggregates a tool-calling task into two distinct subtasks: tool selection and argument generation. We propose "decoupled fine-tuning", a novel post-training approach that employs LoRA fine-tuning to create dedicated LoRA adapters for tool selection and tool-specific argument generation using separate loss masking for each of the subtasks. Furthermore, we present AgentFlux, an inference framework that leverages the LoRA adapters created using decoupled fine-tuning to perform efficient agent orchestration with the help of local models on end-user devices. AgentFlux decomposes the tool-call generation step into tool selection and argument generation, and dynamically loads the corresponding LoRA adapters to generate tool calls. Additionally, AgentFlux implements hierarchical orchestration to restrict the number of tools required for tool selection. Our experiments on the MCP-Bench benchmark demonstrate that the Qwen-2.5-7B model trained using decoupled fine-tuning improves the tool calling accuracy of the base model by 46%, and outperforms other local reasoning, non-reasoning and fine-tuned models of similar size in all cases, and models that are 2x larger, in most cases.

