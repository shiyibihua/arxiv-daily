---
layout: default
title: Memo2496: Expert-Annotated Dataset and Dual-View Adaptive Framework for Music Emotion Recognition
---

# Memo2496: Expert-Annotated Dataset and Dual-View Adaptive Framework for Music Emotion Recognition

**arXiv**: [2512.13998v1](https://arxiv.org/abs/2512.13998) | [PDF](https://arxiv.org/pdf/2512.13998.pdf)

**ä½œè€…**: Qilin Li, C. L. Philip Chen, TongZhang

**åˆ†ç±»**: cs.SD, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMemo2496æ•°æ®é›†å’ŒDAMERæ¡†æž¶ä»¥è§£å†³éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«ä¸­æ•°æ®è´¨é‡ä½Žå’Œè·¨æ›²ç›®ç‰¹å¾æ¼‚ç§»é—®é¢˜**

**å…³é”®è¯**: `éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«` `å¤šæ¨¡æ€èžåˆ` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `ç‰¹å¾æ¼‚ç§»ç¼“è§£` `å¯¹æ¯”å­¦ä¹ ` `æ³¨æ„åŠ›æœºåˆ¶` `æ•°æ®é›†æž„å»º` `è‡ªé€‚åº”å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«é¢ä¸´é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œè·¨æ›²ç›®ç‰¹å¾æ¼‚ç§»çš„æŒ‘æˆ˜ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥ç¨³å®šå¤„ç†ä¸åŒéŸ³ä¹é£Žæ ¼çš„æƒ…æ„Ÿè¡¨è¾¾ã€‚
2. æå‡ºDAMERæ¡†æž¶ï¼Œé›†æˆåŒæµæ³¨æ„åŠ›èžåˆã€æ¸è¿›ç½®ä¿¡åº¦æ ‡æ³¨å’Œé£Žæ ¼é”šå®šè®°å¿†å­¦ä¹ æ¨¡å—ï¼ŒååŒæå‡ç‰¹å¾äº¤äº’å’Œæ³›åŒ–èƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®žçŽ°æ˜¾è‘—æ€§èƒ½æå‡ï¼Œå”¤é†’ç»´åº¦å‡†ç¡®çŽ‡æœ€é«˜æå‡3.43%ï¼Œå¹¶é€šè¿‡æ¶ˆèžå®žéªŒéªŒè¯å„æ¨¡å—æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«ç ”ç©¶é¢ä¸´é«˜è´¨é‡æ ‡æ³¨æ•°æ®é›†æœ‰é™å’Œè·¨æ›²ç›®ç‰¹å¾æ¼‚ç§»çš„æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºä¸¤é¡¹ä¸»è¦è´¡çŒ®ï¼šMemo2496æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®é›†ï¼ŒåŒ…å«2496é¦–å™¨ä¹æ›²ç›®ï¼Œç”±30ä½è®¤è¯éŸ³ä¹ä¸“å®¶æ ‡æ³¨è¿žç»­æ•ˆä»·-å”¤é†’åº¦æ ‡ç­¾ï¼Œé€šè¿‡æžç«¯æƒ…æ„Ÿç¤ºä¾‹æ ¡å‡†å’Œæ•ˆä»·-å”¤é†’ç©ºé—´æ¬§æ°è·ç¦»ä¸€è‡´æ€§é˜ˆå€¼0.25ç¡®ä¿æ ‡æ³¨è´¨é‡ï¼›åŒæ—¶æå‡ºåŒè§†å›¾è‡ªé€‚åº”éŸ³ä¹æƒ…æ„Ÿè¯†åˆ«å™¨ï¼Œé›†æˆä¸‰ä¸ªååŒæ¨¡å—ï¼šåŒæµæ³¨æ„åŠ›èžåˆé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¿ƒè¿›æ¢…å°”é¢‘è°±å›¾å’Œè€³èœ—å›¾ä¹‹é—´çš„ä»¤ç‰Œçº§åŒå‘äº¤äº’ï¼Œæ¸è¿›ç½®ä¿¡åº¦æ ‡æ³¨é‡‡ç”¨è¯¾ç¨‹å¼æ¸©åº¦è°ƒåº¦å’ŒJensen-Shannonæ•£åº¦ä¸€è‡´æ€§é‡åŒ–ç”Ÿæˆå¯é ä¼ªæ ‡ç­¾ï¼Œé£Žæ ¼é”šå®šè®°å¿†å­¦ä¹ ç»´æŠ¤å¯¹æ¯”è®°å¿†é˜Ÿåˆ—ä»¥ç¼“è§£è·¨æ›²ç›®ç‰¹å¾æ¼‚ç§»ã€‚åœ¨Memo2496ã€1000songså’ŒPMEmoæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®žéªŒè¡¨æ˜ŽDAMERè¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œå”¤é†’ç»´åº¦å‡†ç¡®çŽ‡åˆ†åˆ«æå‡3.43%ã€2.25%å’Œ0.17%ï¼Œæ¶ˆèžç ”ç©¶å’Œå¯è§†åŒ–åˆ†æžéªŒè¯äº†å„æ¨¡å—è´¡çŒ®ã€‚æ•°æ®é›†å’Œæºä»£ç å·²å…¬å¼€ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

DAMERæ¡†æž¶é‡‡ç”¨åŒè§†å›¾è‡ªé€‚åº”æž¶æž„ï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºŽä¸‰ä¸ªæ¨¡å—ï¼šåŒæµæ³¨æ„åŠ›èžåˆå®žçŽ°æ¢…å°”é¢‘è°±å›¾å’Œè€³èœ—å›¾çš„ä»¤ç‰Œçº§åŒå‘äº¤äº’ï¼Œå¢žå¼ºå¤šæ¨¡æ€ç‰¹å¾èžåˆï¼›æ¸è¿›ç½®ä¿¡åº¦æ ‡æ³¨é€šè¿‡è¯¾ç¨‹å¼æ¸©åº¦è°ƒåº¦å’ŒJensen-Shannonæ•£åº¦é‡åŒ–ç”Ÿæˆé«˜è´¨é‡ä¼ªæ ‡ç­¾ï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼›é£Žæ ¼é”šå®šè®°å¿†å­¦ä¹ åˆ©ç”¨å¯¹æ¯”è®°å¿†é˜Ÿåˆ—ç¼“è§£è·¨æ›²ç›®ç‰¹å¾æ¼‚ç§»ï¼Œæé«˜æ¨¡åž‹æ³›åŒ–æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒDAMERé¦–æ¬¡ç³»ç»Ÿæ•´åˆå¤šæ¨¡æ€äº¤äº’ã€ä¼ªæ ‡ç­¾ä¼˜åŒ–å’Œç‰¹å¾æ¼‚ç§»ç¼“è§£ï¼Œå½¢æˆç«¯åˆ°ç«¯çš„è‡ªé€‚åº”å­¦ä¹ ç³»ç»Ÿã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DAMERåœ¨Memo2496ã€1000songså’ŒPMEmoæ•°æ®é›†ä¸Šå”¤é†’ç»´åº¦å‡†ç¡®çŽ‡åˆ†åˆ«æå‡3.43%ã€2.25%å’Œ0.17%ï¼Œè¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼›æ¶ˆèžç ”ç©¶è¯å®žå„æ¨¡å—å‡è´¡çŒ®æ˜¾è‘—ï¼Œå¯è§†åŒ–åˆ†æžè¿›ä¸€æ­¥éªŒè¯äº†ç‰¹å¾æ¼‚ç§»ç¼“è§£æ•ˆæžœã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽæ™ºèƒ½éŸ³ä¹æŽ¨èç³»ç»Ÿã€æƒ…æ„ŸåŒ–éŸ³ä¹æ²»ç–—ã€å½±è§†é…ä¹è‡ªåŠ¨ç”Ÿæˆç­‰é¢†åŸŸï¼Œé€šè¿‡ç²¾å‡†è¯†åˆ«éŸ³ä¹æƒ…æ„Ÿï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œä¸ªæ€§åŒ–æœåŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„å¨±ä¹ã€åŒ»ç–—å’Œåˆ›ä½œä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Music Emotion Recogniser (MER) research faces challenges due to limited high-quality annotated datasets and difficulties in addressing cross-track feature drift. This work presents two primary contributions to address these issues. Memo2496, a large-scale dataset, offers 2496 instrumental music tracks with continuous valence arousal labels, annotated by 30 certified music specialists. Annotation quality is ensured through calibration with extreme emotion exemplars and a consistency threshold of 0.25, measured by Euclidean distance in the valence arousal space. Furthermore, the Dual-view Adaptive Music Emotion Recogniser (DAMER) is introduced. DAMER integrates three synergistic modules: Dual Stream Attention Fusion (DSAF) facilitates token-level bidirectional interaction between Mel spectrograms and cochleagrams via cross attention mechanisms; Progressive Confidence Labelling (PCL) generates reliable pseudo labels employing curriculum-based temperature scheduling and consistency quantification using Jensen Shannon divergence; and Style Anchored Memory Learning (SAML) maintains a contrastive memory queue to mitigate cross-track feature drift. Extensive experiments on the Memo2496, 1000songs, and PMEmo datasets demonstrate DAMER's state-of-the-art performance, improving arousal dimension accuracy by 3.43%, 2.25%, and 0.17%, respectively. Ablation studies and visualisation analyses validate each module's contribution. Both the dataset and source code are publicly available.

