---
layout: default
title: CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning
---

# CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning

**arXiv**: [2512.14540v1](https://arxiv.org/abs/2512.14540) | [PDF](https://arxiv.org/pdf/2512.14540.pdf)

**ä½œè€…**: Andreas Lolos, Theofilos Christodoulou, Aris L. Moustakas, Stergios Christodoulidis, Maria Vakalopoulou

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 24 pages, 12 Figures, 4 Tables

**ðŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/mandlos/CAPRMIL)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAPRMILæ¡†æž¶ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è¡¥ä¸è¡¨ç¤ºç®€åŒ–å¤šç¤ºä¾‹å­¦ä¹ ï¼Œæå‡è®¡ç®—ç—…ç†å­¦ä¸­çš„å¼±ç›‘ç£åˆ†æžæ•ˆçŽ‡ã€‚**

**å…³é”®è¯**: `å¤šç¤ºä¾‹å­¦ä¹ ` `è®¡ç®—ç—…ç†å­¦` `å¼±ç›‘ç£å­¦ä¹ ` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¡¨ç¤º` `å…¨åˆ‡ç‰‡å›¾åƒåˆ†æž` `é«˜æ•ˆèšåˆ` `çº¿æ€§å¤æ‚åº¦` `åŒ»ç–—å›¾åƒå¤„ç†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰MILæ–¹æ³•ä¾èµ–å¤æ‚æ³¨æ„åŠ›èšåˆï¼Œè®¡ç®—å¼€é”€å¤§ï¼Œéš¾ä»¥é«˜æ•ˆå¤„ç†å¤§è§„æ¨¡WSIæ•°æ®ã€‚
2. æå‡ºCAPRMILæ¡†æž¶ï¼Œé€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¡¥ä¸åµŒå…¥å’Œçº¿æ€§å¤æ‚åº¦å…¨å±€ä¸Šä¸‹æ–‡æ³¨å…¥ï¼Œç®€åŒ–èšåˆè¿‡ç¨‹ã€‚
3. åœ¨å¤šä¸ªç—…ç†åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…SOTAæ€§èƒ½ï¼Œæ˜¾è‘—é™ä½Žå‚æ•°ã€FLOPså’Œå†…å­˜éœ€æ±‚ï¼Œæå‡è®­ç»ƒæ•ˆçŽ‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è®¡ç®—ç—…ç†å­¦ä¸­ï¼Œç”±äºŽå…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„åƒå…†åƒç´ å°ºåº¦å’Œåƒç´ çº§æ ‡æ³¨çš„ç¨€ç¼ºæ€§ï¼Œå¼±ç›‘ç£å·²æˆä¸ºæ·±åº¦å­¦ä¹ çš„æ ‡å‡†æ–¹æ³•ï¼Œå…¶ä¸­å¤šç¤ºä¾‹å­¦ä¹ ï¼ˆMILï¼‰è¢«ç¡®ç«‹ä¸ºåˆ‡ç‰‡çº§æ¨¡åž‹è®­ç»ƒçš„ä¸»è¦æ¡†æž¶ã€‚æœ¬æ–‡å—ç¥žç»åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰æ±‚è§£å™¨çš„å¯å‘ï¼Œä¸ºMILæ–¹æ³•å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„è®¾ç½®ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆã€èšåˆå™¨æ— å…³çš„æ¡†æž¶ï¼Œæ— éœ€ä¾èµ–å¤æ‚çš„åŸºäºŽæ³¨æ„åŠ›çš„èšåˆï¼Œè€Œæ˜¯ä»ŽMILèšåˆå™¨ä¸­ç§»é™¤äº†ç›¸å…³æ€§å­¦ä¹ çš„å¤æ‚æ€§ã€‚CAPRMILç”Ÿæˆä¸°å¯Œçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥è¡¥ä¸åµŒå…¥ï¼Œä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æœ‰æ•ˆç›¸å…³æ€§å­¦ä¹ ã€‚é€šè¿‡å°†ä½¿ç”¨å†»ç»“è¡¥ä¸ç¼–ç å™¨æå–çš„è¡¥ä¸ç‰¹å¾æŠ•å½±åˆ°ä¸€å°ç»„å…¨å±€ä¸Šä¸‹æ–‡/å½¢æ€æ„ŸçŸ¥ä»¤ç‰Œä¸­ï¼Œå¹¶åˆ©ç”¨å¤šå¤´è‡ªæ³¨æ„åŠ›ï¼ŒCAPRMILä»¥ç›¸å¯¹äºŽåŒ…å¤§å°çš„çº¿æ€§è®¡ç®—å¤æ‚åº¦æ³¨å…¥å…¨å±€ä¸Šä¸‹æ–‡ã€‚ç»“åˆç®€å•çš„å¹³å‡MILèšåˆå™¨ï¼ŒCAPRMILåœ¨å¤šä¸ªå…¬å…±ç—…ç†å­¦åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…äº†æœ€å…ˆè¿›çš„åˆ‡ç‰‡çº§æ€§èƒ½ï¼ŒåŒæ—¶ä¸Žæœ€å…ˆè¿›çš„MILæ–¹æ³•ç›¸æ¯”ï¼Œå¯è®­ç»ƒå‚æ•°æ€»æ•°å‡å°‘äº†48%-92.8%ï¼ŒæŽ¨ç†æœŸé—´çš„FLOPsé™ä½Žäº†52%-99%ï¼Œå¹¶åœ¨GPUå†…å­˜æ•ˆçŽ‡å’Œè®­ç»ƒæ—¶é—´æ–¹é¢æŽ’åæœ€ä½³æ¨¡åž‹ä¹‹åˆ—ã€‚æˆ‘ä»¬çš„ç»“æžœè¡¨æ˜Žï¼Œåœ¨èšåˆä¹‹å‰å­¦ä¹ ä¸°å¯Œçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥å®žä¾‹è¡¨ç¤ºæ˜¯å¤æ‚æ± åŒ–æ–¹æ³•åœ¨å…¨åˆ‡ç‰‡åˆ†æžä¸­çš„ä¸€ç§æœ‰æ•ˆä¸”å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨https://github.com/mandlos/CAPRMILèŽ·å–ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

CAPRMILçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ï¼šä½¿ç”¨å†»ç»“çš„è¡¥ä¸ç¼–ç å™¨æå–è¡¥ä¸ç‰¹å¾ï¼Œç„¶åŽå°†å…¶æŠ•å½±åˆ°å°‘é‡å…¨å±€ä¸Šä¸‹æ–‡/å½¢æ€æ„ŸçŸ¥ä»¤ç‰Œä¸­ï¼Œé€šè¿‡å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶æ³¨å…¥å…¨å±€ä¸Šä¸‹æ–‡ï¼Œè®¡ç®—å¤æ‚åº¦ä¸ŽåŒ…å¤§å°å‘ˆçº¿æ€§å…³ç³»ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå°†ç›¸å…³æ€§å­¦ä¹ ä»Žèšåˆå™¨è½¬ç§»åˆ°è¡¥ä¸è¡¨ç¤ºé˜¶æ®µï¼Œç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„åµŒå…¥ï¼Œä»Žè€Œå…è®¸ä½¿ç”¨ç®€å•çš„å¹³å‡èšåˆå™¨ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒé¿å…äº†å¤æ‚çš„æ³¨æ„åŠ›èšåˆæœºåˆ¶ï¼Œé€šè¿‡é«˜æ•ˆçš„ä¸Šä¸‹æ–‡æ³¨å…¥å®žçŽ°é«˜æ€§èƒ½ï¼Œå‡å°‘äº†æ¨¡åž‹å¤æ‚æ€§å’Œè®¡ç®—èµ„æºéœ€æ±‚ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

CAPRMILåœ¨å¤šä¸ªå…¬å…±ç—…ç†å­¦åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…æœ€å…ˆè¿›æ€§èƒ½ï¼ŒåŒæ—¶å¯è®­ç»ƒå‚æ•°å‡å°‘48%-92.8%ï¼ŒæŽ¨ç†FLOPsé™ä½Ž52%-99%ï¼Œåœ¨GPUå†…å­˜æ•ˆçŽ‡å’Œè®­ç»ƒæ—¶é—´æ–¹é¢è¡¨çŽ°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆçŽ‡ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽè®¡ç®—ç—…ç†å­¦é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å…¨åˆ‡ç‰‡å›¾åƒï¼ˆWSIï¼‰çš„å¼±ç›‘ç£åˆ†æžï¼Œå¦‚ç™Œç—‡è¯Šæ–­ã€ç»„ç»‡åˆ†ç±»å’Œé¢„åŽé¢„æµ‹ã€‚å…¶é«˜æ•ˆæ€§ä½¿å…¶é€‚åˆå¤§è§„æ¨¡åŒ»ç–—å›¾åƒå¤„ç†ï¼Œé™ä½Žè®¡ç®—æˆæœ¬ï¼Œä¿ƒè¿›ä¸´åºŠéƒ¨ç½²å’Œå®žæ—¶åˆ†æžã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In computational pathology, weak supervision has become the standard for deep learning due to the gigapixel scale of WSIs and the scarcity of pixel-level annotations, with Multiple Instance Learning (MIL) established as the principal framework for slide-level model training. In this paper, we introduce a novel setting for MIL methods, inspired by proceedings in Neural Partial Differential Equation (PDE) Solvers. Instead of relying on complex attention-based aggregation, we propose an efficient, aggregator-agnostic framework that removes the complexity of correlation learning from the MIL aggregator. CAPRMIL produces rich context-aware patch embeddings that promote effective correlation learning on downstream tasks. By projecting patch features -- extracted using a frozen patch encoder -- into a small set of global context/morphology-aware tokens and utilizing multi-head self-attention, CAPRMIL injects global context with linear computational complexity with respect to the bag size. Paired with a simple Mean MIL aggregator, CAPRMIL matches state-of-the-art slide-level performance across multiple public pathology benchmarks, while reducing the total number of trainable parameters by 48%-92.8% versus SOTA MILs, lowering FLOPs during inference by 52%-99%, and ranking among the best models on GPU memory efficiency and training time. Our results indicate that learning rich, context-aware instance representations before aggregation is an effective and scalable alternative to complex pooling for whole-slide analysis. Our code is available at https://github.com/mandlos/CAPRMIL

