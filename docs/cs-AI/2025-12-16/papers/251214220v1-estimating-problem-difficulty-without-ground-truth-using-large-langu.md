---
layout: default
title: Estimating problem difficulty without ground truth using Large Language Model comparisons
---

# Estimating problem difficulty without ground truth using Large Language Model comparisons

**arXiv**: [2512.14220v1](https://arxiv.org/abs/2512.14220) | [PDF](https://arxiv.org/pdf/2512.14220.pdf)

**ä½œè€…**: Marthe Ballon, Andres Algaba, Brecht Verbeken, Vincent Ginis

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 19 pages, 10 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¤§è¯­è¨€æ¨¡å‹æ¯”è¾ƒçš„LLM compareæ–¹æ³•ï¼Œä»¥æ— ç›‘ç£æ–¹å¼ä¼°è®¡é—®é¢˜éš¾åº¦ï¼Œè§£å†³åˆ†å¸ƒå¤–é—®é¢˜è¯„ä¼°éš¾é¢˜ã€‚**

**å…³é”®è¯**: `é—®é¢˜éš¾åº¦ä¼°è®¡` `å¤§è¯­è¨€æ¨¡å‹` `æ— ç›‘ç£å­¦ä¹ ` `åˆ†å¸ƒå¤–æ³›åŒ–` `Bradley-Terryæ¨¡å‹` `åˆæˆæ•°æ®ç”Ÿæˆ` `è¯¾ç¨‹è®¾è®¡` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰éš¾åº¦ä¼°è®¡æ–¹æ³•ï¼ˆå¦‚äººå·¥æ ¡å‡†ï¼‰ä¾èµ–çœŸå®æ ‡ç­¾ä¸”ä¸å¯æ‰©å±•ï¼Œæ— æ³•è¯„ä¼°åˆ†å¸ƒå¤–é—®é¢˜ï¼Œé™åˆ¶äº†åˆæˆæ•°æ®ç”Ÿæˆã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œç»“åˆBradley-Terryæ¨¡å‹è®¡ç®—è¿ç»­åˆ†æ•°ï¼Œå®ç°æ— ç›‘ç£ã€æ¨¡å‹æ— å…³çš„éš¾åº¦ä¼°è®¡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šä¸äººå·¥æ ‡æ³¨é«˜åº¦ç›¸å…³ï¼ˆPearson râ‰¥0.80ï¼‰ï¼Œå¯¹å™ªå£°é²æ£’ï¼ˆæ€§èƒ½ä¸‹é™<6%ï¼‰ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¾®è°ƒçš„è¿›å±•æ˜¾è‘—æå‡äº†å…¶åœ¨åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½ï¼Œè¿™å‡¸æ˜¾äº†å¯¹æ›´å›°éš¾åˆæˆæ•°æ®çš„éœ€æ±‚ã€‚æ•°æ®ç”Ÿæˆæµç¨‹ä¸­çš„å…³é”®æ­¥éª¤æ˜¯ä¼°è®¡é—®é¢˜éš¾åº¦çš„æ–¹æ³•ã€‚å½“å‰æ–¹æ³•ï¼ˆå¦‚äººå·¥æ ¡å‡†æˆ–åŸºäºæ€§èƒ½çš„è¯„åˆ†ï¼‰ç”±äºä¸å¯æ‰©å±•ã€è€—æ—¶ä¸”ä¾èµ–çœŸå®æ ‡ç­¾ï¼Œæ— æ³•æ³›åŒ–åˆ°åˆ†å¸ƒå¤–é—®é¢˜ï¼ˆå³å½“å‰äººç±»å’ŒLLMsæ— æ³•è§£å†³çš„é—®é¢˜ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é—®é¢˜éš¾åº¦ä¼°è®¡æ–¹æ³•LLM compareï¼Œä»¥è§£å†³è¿™äº›é™åˆ¶ã€‚è¯¥æ–¹æ³•åˆ©ç”¨LLMè¿›è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œç„¶ååŸºäºç»“æœè®¡ç®—Bradley-Terryåˆ†æ•°ã€‚ä¸ºéªŒè¯æ–¹æ³•ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº†ä¸€ä¸ªæ¦‚å¿µæ¡†æ¶ï¼Œå°†ç°æœ‰æ–¹æ³•å®šä½åœ¨ä¸‰ä¸ªæ­£äº¤å¹³é¢â€”â€”æ„å»ºã€è§„æ¨¡å’Œä¾èµ–æ€§ä¸Šï¼Œè¯†åˆ«å‡ºè¯„ä¼°åˆ†å¸ƒå¤–é—®é¢˜æ‰€éœ€å æ®çš„è±¡é™ã€‚LLM compareè‡ªç„¶å æ®äº†æ‰€æœ‰ç†æƒ³è±¡é™ï¼Œæˆä¸ºé¦–ä¸ªè¿ç»­åŠ¨æ€ã€æ¨¡å‹æ— å…³ä¸”ç‹¬ç«‹äºçœŸå®æ ‡ç­¾ä¿¡æ¯çš„åº¦é‡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å±•ç¤ºäº†LLM compareä¸äººå·¥æ ‡æ³¨é«˜åº¦ä¸€è‡´ï¼šåœ¨n=1876æ—¶ï¼ŒPearsonç›¸å…³ç³»æ•°râ‰¥0.80ã€‚ç¬¬ä¸‰ï¼Œæˆ‘ä»¬è¯æ˜LLM compareå¯¹å¹»è§‰å…·æœ‰é²æ£’æ€§ï¼Œåœ¨10%å™ªå£°æ³¨å…¥ä¸‹ï¼ŒPearsonç›¸å…³ç³»æ•°ä¸‹é™å°äº6%ã€‚æˆ‘ä»¬çš„å·¥ä½œä»£è¡¨äº†åœ¨æ›¿ä»£è€—æ—¶çš„äººå·¥æ ‡æ³¨å’Œåˆæˆæ•°æ®ç”Ÿæˆæ–¹é¢çš„é‡è¦ä¸€æ­¥ï¼Œå¹¶å°†æˆä¸ºè¯¾ç¨‹è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’ŒAIè¾…åŠ©ç ”ç©¶æ„æ€çš„é‡è¦æ¨åŠ¨åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

LLM compareæ–¹æ³•çš„æ ¸å¿ƒæ¡†æ¶åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æˆå¯¹æ¯”è¾ƒèƒ½åŠ›ã€‚é¦–å…ˆï¼ŒLLMå¯¹é—®é¢˜å¯¹è¿›è¡Œéš¾åº¦æ¯”è¾ƒï¼Œç”Ÿæˆç›¸å¯¹éš¾åº¦çš„åˆ¤æ–­ç»“æœï¼›ç„¶åï¼Œåˆ©ç”¨Bradley-Terryæ¨¡å‹å°†è¿™äº›æ¯”è¾ƒç»“æœè½¬åŒ–ä¸ºè¿ç»­çš„éš¾åº¦åˆ†æ•°ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé¦–æ¬¡å®ç°äº†å®Œå…¨æ— ç›‘ç£çš„éš¾åº¦ä¼°è®¡ï¼Œä¸ä¾èµ–çœŸå®æ ‡ç­¾æˆ–äººç±»æ ‡æ³¨ï¼Œé€šè¿‡LLMçš„æ¨ç†èƒ½åŠ›æ³›åŒ–åˆ°æœªçŸ¥é—®é¢˜ã€‚ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼šç°æœ‰æ–¹æ³•é€šå¸¸åŸºäºæ€§èƒ½è¯„åˆ†ï¼ˆå¦‚æ¨¡å‹å‡†ç¡®ç‡ï¼‰æˆ–äººå·¥è¯„ä¼°ï¼Œå—é™äºå¯è§£é—®é¢˜å’Œæ ‡æ³¨æˆæœ¬ï¼›è€ŒLLM compareé€šè¿‡æ¨¡å‹æ— å…³çš„æ¯”è¾ƒæœºåˆ¶ï¼Œèƒ½å¤Ÿå¤„ç†åˆ†å¸ƒå¤–é—®é¢˜ï¼Œå¹¶å…·æœ‰è¿ç»­åŠ¨æ€å’Œå¯æ‰©å±•çš„ä¼˜åŠ¿ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒæ˜¾ç¤ºLLM compareä¸äººå·¥æ ‡æ³¨çš„Pearsonç›¸å…³ç³»æ•°é«˜è¾¾0.80ä»¥ä¸Šï¼ˆn=1876ï¼‰ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼›åœ¨10%å™ªå£°æ³¨å…¥ä¸‹ï¼Œç›¸å…³æ€§ä¸‹é™å°äº6%ï¼Œè¯æ˜äº†æ–¹æ³•å¯¹å¹»è§‰å’Œå™ªå£°çš„å¼ºé²æ£’æ€§ï¼Œä¸ºæ— ç›‘ç£éš¾åº¦ä¼°è®¡æä¾›äº†å¯é åŸºå‡†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥æ–¹æ³•å¯åº”ç”¨äºè¯¾ç¨‹è®¾è®¡ä¸­è‡ªé€‚åº”å­¦ä¹ è·¯å¾„çš„ç”Ÿæˆï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´é—®é¢˜éš¾åº¦ä¼˜åŒ–æ•™å­¦åºåˆ—ï¼›åœ¨æ¨¡å‹è¯„ä¼°ä¸­ï¼Œä¸ºåŸºå‡†æµ‹è¯•æä¾›æ›´ç»†ç²’åº¦çš„éš¾åº¦åˆ†æï¼Œè¾…åŠ©æ€§èƒ½è¯Šæ–­ï¼›åœ¨AIè¾…åŠ©ç ”ç©¶æ„æ€ä¸­ï¼Œå¸®åŠ©ç”ŸæˆæŒ‘æˆ˜æ€§åˆæˆæ•°æ®ï¼Œæ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹çš„å‰æ²¿å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\%$ degradation in Pearson correlation for $10\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.

