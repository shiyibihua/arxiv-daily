---
layout: default
title: OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value
---

# OpenDataArena: A Fair and Open Arena for Benchmarking Post-Training Dataset Value

**arXiv**: [2512.14051v1](https://arxiv.org/abs/2512.14051) | [PDF](https://arxiv.org/pdf/2512.14051.pdf)

**ä½œè€…**: Mengzhang Cai, Xin Gao, Yu Li, Honglin Lin, Zheng Liu, Zhuoshi Pan, Qizhi Pei, Xiaoran Shang, Mengyuan Sun, Zinan Tang, Xiaoyang Wang, Zhanping Zhong, Yun Zhu, Dahua Lin, Conghui He, Lijun Wu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOpenDataArenaä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹åŽè®­ç»ƒæ•°æ®é›†è¯„ä¼°ä¸é€æ˜Žå’Œç¼ºä¹å…¬å¹³åŸºå‡†çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡åž‹` `åŽè®­ç»ƒæ•°æ®é›†` `æ•°æ®è¯„ä¼°` `åŸºå‡†æµ‹è¯•` `æ•°æ®è°±ç³»` `å¼€æºå¹³å°` `æ•°æ®ä¸ºä¸­å¿ƒAI` `æ¨¡åž‹æ€§èƒ½åˆ†æž`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤§è¯­è¨€æ¨¡åž‹åŽè®­ç»ƒæ•°æ®é›†è¯„ä¼°ä¸é€æ˜Žï¼Œç¼ºä¹å…¬å¹³åŸºå‡†ï¼Œé˜»ç¢å¯é‡å¤æ€§å’Œæ•°æ®-æ¨¡åž‹å› æžœåˆ†æžã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºOpenDataArenaå¹³å°ï¼Œé›†æˆç»Ÿä¸€è®­ç»ƒ-è¯„ä¼°ç®¡é“ã€å¤šç»´è¯„åˆ†æ¡†æž¶ã€æ•°æ®è°±ç³»æŽ¢ç´¢å™¨å’Œå¼€æºå·¥å…·åŒ…ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¦†ç›–120+æ•°æ®é›†å’Œ22ä¸ªåŸºå‡†ï¼Œæ­ç¤ºæ•°æ®å¤æ‚æ€§-æ€§èƒ½æƒè¡¡ï¼Œè¯†åˆ«å†—ä½™ï¼Œå¹¶æ˜ å°„æ•°æ®é›†è°±ç³»å…³ç³»ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡åž‹çš„å¿«é€Ÿå‘å±•ä¾èµ–äºŽåŽè®­ç»ƒæ•°æ®é›†çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼Œä½†å½“å‰å­˜åœ¨ä¸€ä¸ªå…³é”®çŸ›ç›¾ï¼šæ¨¡åž‹è¢«ä¸¥æ ¼åŸºå‡†æµ‹è¯•ï¼Œè€Œæ•°æ®æœ¬èº«å´æ˜¯ä¸€ä¸ªé»‘ç®±ï¼Œè¡¨çŽ°ä¸ºç»„æˆä¸é€æ˜Žã€æ¥æºä¸ç¡®å®šä¸”ç¼ºä¹ç³»ç»Ÿè¯„ä¼°ã€‚è¿™ç§ä¸é€æ˜Žæ€§é˜»ç¢äº†å¯é‡å¤æ€§ï¼Œå¹¶æ¨¡ç³Šäº†æ•°æ®ç‰¹æ€§ä¸Žæ¨¡åž‹è¡Œä¸ºä¹‹é—´çš„å› æžœå…³ç³»ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº†OpenDataArenaï¼Œè¿™æ˜¯ä¸€ä¸ªå…¨é¢å¼€æ”¾çš„å¹³å°ï¼Œæ—¨åœ¨åŸºå‡†æµ‹è¯•åŽè®­ç»ƒæ•°æ®çš„å†…åœ¨ä»·å€¼ã€‚ODAå»ºç«‹äº†ä¸€ä¸ªç»¼åˆç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬å››ä¸ªå…³é”®æ”¯æŸ±ï¼š(i) ä¸€ä¸ªç»Ÿä¸€çš„è®­ç»ƒ-è¯„ä¼°ç®¡é“ï¼Œç¡®ä¿åœ¨ä¸åŒæ¨¡åž‹å’Œé¢†åŸŸé—´è¿›è¡Œå…¬å¹³ã€å¼€æ”¾çš„æ¯”è¾ƒï¼›(ii) ä¸€ä¸ªå¤šç»´è¯„åˆ†æ¡†æž¶ï¼Œæ²¿æ•°åä¸ªä¸åŒç»´åº¦åˆ†æžæ•°æ®è´¨é‡ï¼›(iii) ä¸€ä¸ªäº¤äº’å¼æ•°æ®è°±ç³»æŽ¢ç´¢å™¨ï¼Œå¯è§†åŒ–æ•°æ®é›†è°±ç³»å¹¶å‰–æžç»„ä»¶æ¥æºï¼›(iv) ä¸€ä¸ªå®Œå…¨å¼€æºçš„å·¥å…·åŒ…ï¼Œç”¨äºŽè®­ç»ƒã€è¯„ä¼°å’Œè¯„åˆ†ï¼Œä»¥ä¿ƒè¿›æ•°æ®ç ”ç©¶ã€‚åœ¨ODAä¸Šè¿›è¡Œçš„å¹¿æ³›å®žéªŒâ€”â€”è¦†ç›–å¤šä¸ªé¢†åŸŸçš„120å¤šä¸ªè®­ç»ƒæ•°æ®é›†ã€22ä¸ªåŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡è¶…è¿‡600æ¬¡è®­ç»ƒè¿è¡Œå’Œ4000ä¸‡ä¸ªå¤„ç†æ•°æ®ç‚¹éªŒè¯â€”â€”æ­ç¤ºäº†éžå¹³å‡¡çš„è§è§£ã€‚æˆ‘ä»¬çš„åˆ†æžæ­ç¤ºäº†æ•°æ®å¤æ‚æ€§ä¸Žä»»åŠ¡æ€§èƒ½ä¹‹é—´çš„å†…åœ¨æƒè¡¡ï¼Œé€šè¿‡è°±ç³»è¿½è¸ªè¯†åˆ«äº†æµè¡ŒåŸºå‡†ä¸­çš„å†—ä½™ï¼Œå¹¶æ˜ å°„äº†æ•°æ®é›†é—´çš„è°±ç³»å…³ç³»ã€‚æˆ‘ä»¬å‘å¸ƒæ‰€æœ‰ç»“æžœã€å·¥å…·å’Œé…ç½®ï¼Œä»¥æ°‘ä¸»åŒ–é«˜è´¨é‡æ•°æ®è¯„ä¼°çš„è®¿é—®ã€‚ODAä¸ä»…æ—¨åœ¨æ‰©å±•æŽ’è¡Œæ¦œï¼Œæ›´è®¾æƒ³ä»Žè¯•é”™å¼æ•°æ®ç­–å±•è½¬å‘ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½åŽŸåˆ™ç§‘å­¦ï¼Œä¸ºæ•°æ®æ··åˆè§„å¾‹å’ŒåŸºç¡€æ¨¡åž‹æˆ˜ç•¥ç»„æˆçš„ç ”ç©¶é“ºå¹³é“è·¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

OpenDataArenaæ˜¯ä¸€ä¸ªå…¨é¢å¼€æ”¾çš„å¹³å°ï¼Œæ ¸å¿ƒæ¡†æž¶åŒ…æ‹¬å››ä¸ªæ”¯æŸ±ï¼šç»Ÿä¸€è®­ç»ƒ-è¯„ä¼°ç®¡é“ã€å¤šç»´è¯„åˆ†æ¡†æž¶ã€äº¤äº’å¼æ•°æ®è°±ç³»æŽ¢ç´¢å™¨å’Œå¼€æºå·¥å…·åŒ…ã€‚æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽæ•´åˆäº†å…¬å¹³æ¯”è¾ƒæœºåˆ¶ã€å¤šç»´åº¦æ•°æ®è´¨é‡åˆ†æžå’Œå¯è§†åŒ–è°±ç³»è¿½è¸ªã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒODAä¸ä»…æä¾›åŸºå‡†æµ‹è¯•ï¼Œè¿˜é€šè¿‡å¼€æ”¾ç”Ÿæ€ç³»ç»Ÿä¿ƒè¿›æ•°æ®ç ”ç©¶çš„é€æ˜Žåº¦å’Œå¯é‡å¤æ€§ï¼Œè§£å†³äº†æ•°æ®é»‘ç®±é—®é¢˜ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€åªå…³æ³¨æ¨¡åž‹æ€§èƒ½è¯„ä¼°ï¼Œå¿½è§†æ•°æ®æœ¬èº«çš„ç³»ç»Ÿåˆ†æžã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒè¦†ç›–120å¤šä¸ªè®­ç»ƒæ•°æ®é›†å’Œ22ä¸ªåŸºå‡†ï¼Œé€šè¿‡600+è®­ç»ƒè¿è¡ŒéªŒè¯ï¼Œæ­ç¤ºäº†æ•°æ®å¤æ‚æ€§ä¸Žä»»åŠ¡æ€§èƒ½çš„æƒè¡¡ï¼Œè¯†åˆ«äº†æµè¡ŒåŸºå‡†ä¸­çš„å†—ä½™ï¼Œå¹¶æˆåŠŸæ˜ å°„äº†æ•°æ®é›†é—´çš„è°±ç³»å…³ç³»ï¼Œä¸ºæ•°æ®æ··åˆè§„å¾‹æä¾›äº†å®žè¯åŸºç¡€ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå¤§è¯­è¨€æ¨¡åž‹å¼€å‘ã€æ•°æ®ç­–å±•ä¼˜åŒ–å’Œäººå·¥æ™ºèƒ½ä¼¦ç†è¯„ä¼°ç­‰é¢†åŸŸï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æ›´ç§‘å­¦åœ°é€‰æ‹©å’Œç»„åˆè®­ç»ƒæ•°æ®ï¼Œæå‡æ¨¡åž‹æ€§èƒ½ä¸Žå¯è§£é‡Šæ€§ï¼ŒæŽ¨åŠ¨æ•°æ®ä¸ºä¸­å¿ƒçš„äººå·¥æ™ºèƒ½å‘å±•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The rapid evolution of Large Language Models (LLMs) is predicated on the quality and diversity of post-training datasets. However, a critical dichotomy persists: while models are rigorously benchmarked, the data fueling them remains a black box--characterized by opaque composition, uncertain provenance, and a lack of systematic evaluation. This opacity hinders reproducibility and obscures the causal link between data characteristics and model behaviors. To bridge this gap, we introduce OpenDataArena (ODA), a holistic and open platform designed to benchmark the intrinsic value of post-training data. ODA establishes a comprehensive ecosystem comprising four key pillars: (i) a unified training-evaluation pipeline that ensures fair, open comparisons across diverse models (e.g., Llama, Qwen) and domains; (ii) a multi-dimensional scoring framework that profiles data quality along tens of distinct axes; (iii) an interactive data lineage explorer to visualize dataset genealogy and dissect component sources; and (iv) a fully open-source toolkit for training, evaluation, and scoring to foster data research. Extensive experiments on ODA--covering over 120 training datasets across multiple domains on 22 benchmarks, validated by more than 600 training runs and 40 million processed data points--reveal non-trivial insights. Our analysis uncovers the inherent trade-offs between data complexity and task performance, identifies redundancy in popular benchmarks through lineage tracing, and maps the genealogical relationships across datasets. We release all results, tools, and configurations to democratize access to high-quality data evaluation. Rather than merely expanding a leaderboard, ODA envisions a shift from trial-and-error data curation to a principled science of Data-Centric AI, paving the way for rigorous studies on data mixing laws and the strategic composition of foundation models.

