---
layout: default
title: Massive Editing for Large Language Models Based on Dynamic Weight Generation
---

# Massive Editing for Large Language Models Based on Dynamic Weight Generation

**arXiv**: [2512.14395v1](https://arxiv.org/abs/2512.14395) | [PDF](https://arxiv.org/pdf/2512.14395.pdf)

**ä½œè€…**: Wentao Wan, Qiqing Lao, Zhiwei Xie, Hefeng Wu, Runnan Lin, Liang Lin, Keze Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 27 pages, 8 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽåŠ¨æ€æƒé‡ç”Ÿæˆçš„å¤§è§„æ¨¡ç¼–è¾‘æ–¹æ³•MeGï¼Œä»¥è§£å†³å¤§è¯­è¨€æ¨¡åž‹çŸ¥è¯†ç¼–è¾‘ä¸­çš„å¤§è§„æ¨¡ä¿®æ”¹æŒ‘æˆ˜ã€‚**

**å…³é”®è¯**: `çŸ¥è¯†ç¼–è¾‘` `å¤§è¯­è¨€æ¨¡åž‹` `åŠ¨æ€æƒé‡ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `å¤§è§„æ¨¡ç¼–è¾‘` `æ¨¡åž‹å¾®è°ƒ` `äººå·¥æ™ºèƒ½ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•éš¾ä»¥åœ¨å¤§è§„æ¨¡ä¿®æ”¹å¤§è¯­è¨€æ¨¡åž‹æ—¶ï¼ŒåŒæ—¶ä¿è¯ç¼–è¾‘çš„å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡é™„åŠ åŠ¨æ€æƒé‡ç¥žç»å…ƒï¼Œå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡åž‹åŸºäºŽè¾“å…¥æŸ¥è¯¢æ¡ä»¶ç”Ÿæˆæƒé‡ï¼Œå®žçŽ°é«˜æ•ˆçš„å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šMeGåœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå±€éƒ¨æ€§æŒ‡æ ‡æå‡å°¤ä¸ºçªå‡ºã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†ç¼–è¾‘ï¼ˆKEï¼‰æ˜¯ç ”ç©¶å¦‚ä½•ä»¥ä½Žæˆæœ¬ï¼ˆç›¸æ¯”é¢„è®­ç»ƒï¼‰ä¿®æ”¹å¤§è¯­è¨€æ¨¡åž‹ï¼ˆLLMsï¼‰ä¸­æŸäº›çŸ¥è¯†çš„é¢†åŸŸã€‚ç›®å‰ï¼Œåœ¨å¤§è§„æ¨¡ç¼–è¾‘LLMsçš„åŒæ—¶ç¡®ä¿ç¼–è¾‘çš„å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡ä»æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽåŠ¨æ€æƒé‡ç”Ÿæˆçš„å¤§è§„æ¨¡ç¼–è¾‘æ–¹æ³•ï¼ˆMeGï¼‰ã€‚æˆ‘ä»¬çš„MeGæ¶‰åŠåœ¨LLMsçš„ç‰¹å®šå±‚é™„åŠ ä¸€ä¸ªåŠ¨æ€æƒé‡ç¥žç»å…ƒï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡åž‹æ ¹æ®çŸ¥è¯†æ‰€éœ€çš„è¾“å…¥æŸ¥è¯¢æ¡ä»¶ç”Ÿæˆè¯¥ç¥žç»å…ƒçš„æƒé‡ã€‚è¿™ä½¿å¾—é€šè¿‡æ·»åŠ å•ä¸ªåŠ¨æ€æƒé‡ç¥žç»å…ƒå³å¯å®žçŽ°å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘çš„ç›®æ ‡ã€‚å®žéªŒè¡¨æ˜Žï¼Œä¸ŽçŽ°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„MeGåœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡æ–¹é¢èƒ½æ˜¾è‘—æå‡å¤§è§„æ¨¡KEçš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯å±€éƒ¨æ€§æŒ‡æ ‡çš„ç»å¯¹å€¼æŒ‡æ•°æœ‰è¾ƒé«˜çš„ç™¾åˆ†ç‚¹å¢žé•¿ï¼Œè¯æ˜Žäº†æˆ‘ä»¬æå‡ºæ–¹æ³•çš„ä¼˜åŠ¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

MeGçš„æ•´ä½“æ¡†æž¶æ˜¯åœ¨å¤§è¯­è¨€æ¨¡åž‹çš„ç‰¹å®šå±‚é™„åŠ ä¸€ä¸ªåŠ¨æ€æƒé‡ç¥žç»å…ƒï¼Œè¯¥ç¥žç»å…ƒçš„æƒé‡ç”±æ‰©æ•£æ¨¡åž‹æ¡ä»¶ç”Ÿæˆï¼Œç”Ÿæˆè¿‡ç¨‹åŸºäºŽè¾“å…¥æŸ¥è¯¢æ‰€éœ€çš„çŸ¥è¯†ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽä½¿ç”¨æ‰©æ•£æ¨¡åž‹åŠ¨æ€ç”Ÿæˆæƒé‡ï¼Œè€Œéžå›ºå®šä¿®æ”¹æ¨¡åž‹å‚æ•°ï¼Œè¿™å…è®¸é€šè¿‡å•ä¸ªç¥žç»å…ƒå®žçŽ°å¤§è§„æ¨¡ç¼–è¾‘ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸ç›´æŽ¥ä¿®æ”¹æ¨¡åž‹æƒé‡æˆ–æ·»åŠ é™æ€æ¨¡å—ï¼Œè€ŒMeGé€šè¿‡åŠ¨æ€æƒé‡ç”Ÿæˆå®žçŽ°äº†æ›´çµæ´»ã€å¯æ‰©å±•çš„ç¼–è¾‘ï¼Œæé«˜äº†ç¼–è¾‘æ•ˆçŽ‡å’Œæ€§èƒ½ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœæ˜¾ç¤ºï¼ŒMeGåœ¨å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘ä»»åŠ¡ä¸­ï¼Œå¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡å‡æ˜¾è‘—æå‡ï¼Œç‰¹åˆ«æ˜¯å±€éƒ¨æ€§æŒ‡æ ‡çš„ç»å¯¹å€¼æŒ‡æ•°æœ‰è¾ƒé«˜ç™¾åˆ†ç‚¹å¢žé•¿ï¼Œè¯æ˜Žäº†å…¶åœ¨ä¿æŒæ¨¡åž‹åŽŸæœ‰çŸ¥è¯†çš„åŒæ—¶é«˜æ•ˆç¼–è¾‘æ–°çŸ¥è¯†çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå¤§è¯­è¨€æ¨¡åž‹çš„æŒç»­å­¦ä¹ å’ŒçŸ¥è¯†æ›´æ–°ï¼Œä¾‹å¦‚åœ¨AIåŠ©æ‰‹ã€å†…å®¹ç”Ÿæˆç³»ç»Ÿä¸­å¿«é€Ÿä¿®æ­£é”™è¯¯çŸ¥è¯†æˆ–æ·»åŠ æ–°ä¿¡æ¯ï¼Œæå‡æ¨¡åž‹çš„é€‚åº”æ€§å’Œå‡†ç¡®æ€§ï¼Œé™ä½Žé‡æ–°è®­ç»ƒçš„æˆæœ¬ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.

