---
layout: default
title: Massive Editing for Large Language Models Based on Dynamic Weight Generation
---

# Massive Editing for Large Language Models Based on Dynamic Weight Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14395" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14395v1</a>
  <a href="https://arxiv.org/pdf/2512.14395.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14395v1" onclick="toggleFavorite(this, '2512.14395v1', 'Massive Editing for Large Language Models Based on Dynamic Weight Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wentao Wan, Qiqing Lao, Zhiwei Xie, Hefeng Wu, Runnan Lin, Liang Lin, Keze Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 27 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåŠ¨æ€æƒé‡ç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹æ‰¹é‡çŸ¥è¯†ç¼–è¾‘æ–¹æ³•MeG**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†ç¼–è¾‘` `å¤§è¯­è¨€æ¨¡å‹` `åŠ¨æ€æƒé‡ç”Ÿæˆ` `æ‰©æ•£æ¨¡å‹` `æ‰¹é‡ç¼–è¾‘` `å¯é æ€§` `é€šç”¨æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•éš¾ä»¥å…¼é¡¾å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§ï¼Œæ— æ³•æœ‰æ•ˆæ”¯æŒå¤§è¯­è¨€æ¨¡å‹çš„å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘ã€‚
2. MeGçš„æ ¸å¿ƒæ€æƒ³æ˜¯ä¸ºLLMç‰¹å®šå±‚æ·»åŠ åŠ¨æ€æƒé‡ç¥ç»å…ƒï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆç¥ç»å…ƒæƒé‡ï¼Œå®ç°çŸ¥è¯†çš„æ‰¹é‡ç¼–è¾‘ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMeGåœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å±€éƒ¨æ€§æ–¹é¢æå‡æ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŸ¥è¯†ç¼–è¾‘(KE)æ—¨åœ¨ä»¥ä½æˆæœ¬ï¼ˆç›¸å¯¹äºé¢„è®­ç»ƒï¼‰ä¿®æ”¹å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸­çš„çŸ¥è¯†ã€‚ç›®å‰ï¼Œå¯¹LLMè¿›è¡Œå¤§è§„æ¨¡ç¼–è¾‘ï¼ŒåŒæ—¶ç¡®ä¿ç¼–è¾‘çš„å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåŠ¨æ€æƒé‡ç”Ÿæˆçš„å¤§è¯­è¨€æ¨¡å‹æ‰¹é‡ç¼–è¾‘æ–¹æ³•(MeG)ã€‚MeGé€šè¿‡åœ¨LLMçš„ç‰¹å®šå±‚é™„åŠ ä¸€ä¸ªåŠ¨æ€æƒé‡ç¥ç»å…ƒï¼Œå¹¶ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ ¹æ®çŸ¥è¯†æ‰€éœ€çš„è¾“å…¥æŸ¥è¯¢æœ‰æ¡ä»¶åœ°ç”Ÿæˆè¯¥ç¥ç»å…ƒçš„æƒé‡ã€‚è¿™ä½¿å¾—ä»…æ·»åŠ ä¸€ä¸ªåŠ¨æ€æƒé‡ç¥ç»å…ƒå³å¯å®ç°å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘çš„ç›®æ ‡ã€‚å®éªŒè¡¨æ˜ï¼Œä¸ç°æœ‰çš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ç›¸æ¯”ï¼ŒMeGåœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡æ–¹é¢æ˜¾è‘—æé«˜äº†å¤§è§„æ¨¡KEçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å±€éƒ¨æ€§æŒ‡æ ‡çš„ç»å¯¹å€¼æ–¹é¢æœ‰å¾ˆé«˜çš„ç™¾åˆ†ç‚¹æå‡ï¼Œè¯æ˜äº†æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¤§è§„æ¨¡çŸ¥è¯†ç¼–è¾‘çš„é—®é¢˜ã€‚ç°æœ‰çš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•åœ¨è¿›è¡Œå¤§è§„æ¨¡ç¼–è¾‘æ—¶ï¼Œéš¾ä»¥åŒæ—¶ä¿è¯ç¼–è¾‘çš„å¯é æ€§ï¼ˆReliabilityï¼Œç¼–è¾‘åçš„çŸ¥è¯†æ˜¯æ­£ç¡®çš„ï¼‰ã€é€šç”¨æ€§ï¼ˆGeneralityï¼Œç¼–è¾‘åçš„æ¨¡å‹åœ¨ç›¸å…³ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼‰å’Œå±€éƒ¨æ€§ï¼ˆLocalityï¼Œç¼–è¾‘åªå½±å“ç›®æ ‡çŸ¥è¯†ï¼Œä¸å½±å“å…¶ä»–çŸ¥è¯†ï¼‰ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥åŠ¨æ€æƒé‡ç”Ÿæˆæœºåˆ¶ï¼Œé€šè¿‡åœ¨LLMçš„ç‰¹å®šå±‚æ·»åŠ åŠ¨æ€æƒé‡ç¥ç»å…ƒï¼Œå¹¶åˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆè¿™äº›ç¥ç»å…ƒçš„æƒé‡ã€‚è¿™æ ·ï¼Œæ¯ä¸ªåŠ¨æ€æƒé‡ç¥ç»å…ƒå¯ä»¥å­¦ä¹ åˆ°ç‰¹å®šçŸ¥è¯†çš„è¡¨ç¤ºï¼Œä»è€Œå®ç°å¤§è§„æ¨¡çŸ¥è¯†çš„æ‰¹é‡ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨é€šè¿‡å°‘é‡å‚æ•°çš„ä¿®æ”¹ï¼Œå®ç°å¯¹å¤§é‡çŸ¥è¯†çš„ç¼–è¾‘ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMeGçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) åœ¨LLMçš„ç‰¹å®šå±‚é€‰æ‹©ä½ç½®æ’å…¥åŠ¨æ€æƒé‡ç¥ç»å…ƒï¼›2) ä½¿ç”¨æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ‰©æ•£æ¨¡å‹ä»¥çŸ¥è¯†ç¼–è¾‘æ‰€éœ€çš„è¾“å…¥æŸ¥è¯¢ä¸ºæ¡ä»¶ï¼Œç”ŸæˆåŠ¨æ€æƒé‡ç¥ç»å…ƒçš„æƒé‡ï¼›3) ä½¿ç”¨ç¼–è¾‘åçš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æ•´ä¸ªæ¡†æ¶çš„å…³é”®åœ¨äºæ‰©æ•£æ¨¡å‹çš„è®¾è®¡å’Œè®­ç»ƒï¼Œä»¥åŠåŠ¨æ€æƒé‡ç¥ç»å…ƒåœ¨LLMä¸­çš„æ’å…¥ä½ç½®ã€‚

**å…³é”®åˆ›æ–°**ï¼šMeGçš„æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåŠ¨æ€æƒé‡ç”Ÿæˆæœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ç›´æ¥ä¿®æ”¹LLMçš„ç°æœ‰æƒé‡ä¸åŒï¼ŒMeGé€šè¿‡ç”Ÿæˆæ–°çš„æƒé‡æ¥å®ç°çŸ¥è¯†çš„ç¼–è¾‘ã€‚è¿™ç§æ–¹æ³•çš„ä¼˜åŠ¿åœ¨äºï¼š1) å¯ä»¥å®ç°å¤§è§„æ¨¡çš„çŸ¥è¯†ç¼–è¾‘ï¼Œå› ä¸ºæ¯ä¸ªåŠ¨æ€æƒé‡ç¥ç»å…ƒå¯ä»¥å­¦ä¹ åˆ°å¤šä¸ªçŸ¥è¯†çš„è¡¨ç¤ºï¼›2) å¯ä»¥æ›´å¥½åœ°ä¿æŒæ¨¡å‹çš„å±€éƒ¨æ€§ï¼Œå› ä¸ºç¼–è¾‘åªå½±å“åŠ¨æ€æƒé‡ç¥ç»å…ƒï¼Œè€Œä¸å½±å“LLMçš„å…¶ä»–éƒ¨åˆ†ï¼›3) å¯ä»¥é€šè¿‡æ‰©æ•£æ¨¡å‹æ§åˆ¶ç”Ÿæˆæƒé‡çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³äºåŠ¨æ€æƒé‡ç¥ç»å…ƒçš„æ’å…¥ä½ç½®ï¼Œè®ºæ–‡å¯èƒ½éœ€è¦è®¨è®ºé€‰æ‹©å“ªäº›å±‚è¿›è¡Œæ’å…¥ï¼Œä»¥åŠæ’å…¥çš„å…·ä½“ä½ç½®ã€‚å…³äºæ‰©æ•£æ¨¡å‹ï¼Œéœ€è¦æ˜ç¡®å…¶è¾“å…¥ï¼ˆä¾‹å¦‚ï¼ŒçŸ¥è¯†ç¼–è¾‘æ‰€éœ€çš„è¾“å…¥æŸ¥è¯¢ï¼‰ã€è¾“å‡ºï¼ˆåŠ¨æ€æƒé‡ç¥ç»å…ƒçš„æƒé‡ï¼‰ã€ç½‘ç»œç»“æ„å’Œè®­ç»ƒç›®æ ‡ã€‚æ­¤å¤–ï¼Œå¯èƒ½è¿˜éœ€è¦è®¾è®¡æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼Œå¹¶ç¡®ä¿ç¼–è¾‘åçš„æ¨¡å‹åœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æ–¹é¢è¡¨ç°è‰¯å¥½ã€‚å…·ä½“çš„è¶…å‚æ•°è®¾ç½®ï¼ˆä¾‹å¦‚ï¼Œæ‰©æ•£æ¨¡å‹çš„è¿­ä»£æ¬¡æ•°ã€å­¦ä¹ ç‡ç­‰ï¼‰ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMeGåœ¨å¯é æ€§ã€é€šç”¨æ€§å’Œå±€éƒ¨æ€§æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰çŸ¥è¯†ç¼–è¾‘æ–¹æ³•ã€‚å°¤å…¶æ˜¯åœ¨å±€éƒ¨æ€§æŒ‡æ ‡ä¸Šï¼ŒMeGå–å¾—äº†æ˜¾è‘—çš„æå‡ï¼Œè¡¨æ˜è¯¥æ–¹æ³•åœ¨è¿›è¡ŒçŸ¥è¯†ç¼–è¾‘æ—¶ï¼Œå¯¹æ¨¡å‹å…¶ä»–çŸ¥è¯†çš„å½±å“è¾ƒå°ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šçš„å‡†ç¡®ç‡æå‡ï¼‰éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºéœ€è¦é¢‘ç¹æ›´æ–°çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹åº”ç”¨åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å®¢æœã€çŸ¥è¯†é—®ç­”ç³»ç»Ÿã€æœç´¢å¼•æ“ç­‰ã€‚é€šè¿‡MeGï¼Œå¯ä»¥å¿«é€Ÿã€é«˜æ•ˆåœ°æ›´æ–°LLMçš„çŸ¥è¯†åº“ï¼Œæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå®ç”¨æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºä¿®å¤LLMä¸­çš„é”™è¯¯çŸ¥è¯†ï¼Œæé«˜æ¨¡å‹çš„å¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ¨¡å‹å’Œä»»åŠ¡ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Knowledge Editing (KE) is a field that studies how to modify some knowledge in Large Language Models (LLMs) at a low cost (compared to pre-training). Currently, performing large-scale edits on LLMs while ensuring the Reliability, Generality, and Locality metrics of the edits remain a challenge. This paper proposes a Massive editing approach for LLMs based on dynamic weight Generation (MeG). Our MeG involves attaching a dynamic weight neuron to specific layers of the LLMs and using a diffusion model to conditionally generate the weights of this neuron based on the input query required for the knowledge. This allows the use of adding a single dynamic weight neuron to achieve the goal of large-scale knowledge editing. Experiments show that our MeG can significantly improve the performance of large-scale KE in terms of Reliability, Generality, and Locality metrics compared to existing knowledge editing methods, particularly with a high percentage point increase in the absolute value index for the Locality metric, demonstrating the advantages of our proposed method.

