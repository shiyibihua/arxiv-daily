---
layout: default
title: Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence
---

# Dynamic Learning Rate Scheduling based on Loss Changes Leads to Faster Convergence

**arXiv**: [2512.14527v1](https://arxiv.org/abs/2512.14527) | [PDF](https://arxiv.org/pdf/2512.14527.pdf)

**ä½œè€…**: Shreyas Subramanian, Bala Krishnamoorthy, Pranav Murthy

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæŸå¤±å˜åŒ–çš„åŠ¨æ€å­¦ä¹ çŽ‡è°ƒåº¦å™¨GreedyLRï¼Œä»¥åŠ é€Ÿæ¨¡åž‹è®­ç»ƒæ”¶æ•›**

**å…³é”®è¯**: `åŠ¨æ€å­¦ä¹ çŽ‡è°ƒåº¦` `è®­ç»ƒä¼˜åŒ–` `æ”¶æ•›åŠ é€Ÿ` `è‡ªé€‚åº”è°ƒæ•´` `æŸå¤±å˜åŒ–` `å¤§è§„æ¨¡æ¨¡åž‹è®­ç»ƒ` `ç†è®ºåˆ†æž` `é²æ£’æ€§éªŒè¯`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•å¤šä¾èµ–å›ºå®šæ¨¡å¼è°ƒåº¦å™¨ï¼ˆå¦‚ä½™å¼¦è¡°å‡ï¼‰ï¼Œç¼ºä¹å¯¹è®­ç»ƒåŠ¨æ€çš„è‡ªé€‚åº”è°ƒæ•´ï¼Œå¯èƒ½å¯¼è‡´æ”¶æ•›é€Ÿåº¦æ…¢æˆ–æ€§èƒ½ä¸ä½³ã€‚
2. æå‡ºGreedyLRè°ƒåº¦å™¨ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯æ ¹æ®æŸå¤±å˜åŒ–åŠ¨æ€è°ƒæ•´å­¦ä¹ çŽ‡ï¼Œé€šè¿‡ç†è®ºæŽ¨å¯¼ç¡®å®šæœ€ä¼˜ç¼©æ”¾å› å­ä»¥åŠ é€Ÿæ”¶æ•›ã€‚
3. åœ¨NLPã€CVå’ŒLLMä»»åŠ¡ä¸Šå®žéªŒæ˜¾ç¤ºï¼ŒGreedyLRåœ¨å‡†ç¡®çŽ‡ã€é€Ÿåº¦å’Œæ”¶æ•›æ€§ä¸Šä¼˜äºŽçŽ°æœ‰è°ƒåº¦å™¨ï¼Œå‚æ•°è§„æ¨¡è¾¾70äº¿ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡è®­ç»ƒä¼˜åŒ–å™¨å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¤§å¤šæ•°ç ”ç©¶å·¥ä½œä»ä½¿ç”¨ä½™å¼¦æˆ–æŒ‡æ•°è¡°å‡ç­‰å¸¸è§è°ƒåº¦å™¨ã€‚æœ¬æ–‡ç ”ç©¶äº†GreedyLRï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„è°ƒåº¦å™¨ï¼Œèƒ½å¤Ÿæ ¹æ®å½“å‰æŸå¤±åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ çŽ‡ã€‚ä¸ºäº†éªŒè¯æ‰€æå‡ºè°ƒåº¦å™¨çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªNLPã€CVå’ŒLLMä»»åŠ¡ä¸Šè¿›è¡Œäº†å®žéªŒï¼Œå‚æ•°è§„æ¨¡é«˜è¾¾70äº¿ï¼ŒåŒ…æ‹¬å¾®è°ƒå’Œé¢„è®­ç»ƒå®žéªŒã€‚ç»“æžœè¡¨æ˜Žï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å‡†ç¡®æ€§ã€é€Ÿåº¦å’Œæ”¶æ•›æ€§æ–¹é¢ä¼˜äºŽå‡ ç§æœ€å…ˆè¿›çš„è°ƒåº¦å™¨ã€‚æˆ‘ä»¬è¿˜æä¾›äº†GreedyLRç®—æ³•çš„ç†è®ºåˆ†æžï¼ŒåŒ…æ‹¬æ”¶æ•›æ€§è¯æ˜Žå’Œæœ€å¤§åŒ–æ”¶æ•›é€ŸçŽ‡çš„æœ€ä¼˜ç¼©æ”¾å› å­Fçš„æŽ¨å¯¼ï¼Œå¹¶é€šè¿‡å®žéªŒå±•ç¤ºäº†ç®—æ³•å¯¹çŽ°å®žå™ªå£°çŽ¯å¢ƒçš„é²æ£’æ€§ã€‚æˆ‘ä»¬çš„è°ƒåº¦å™¨æ˜“äºŽå®žçŽ°ã€è®¡ç®—é«˜æ•ˆï¼Œå¯è¢«è§†ä¸ºè®­ç»ƒçš„è‰¯å¥½é»˜è®¤è°ƒåº¦å™¨ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

GreedyLRæ˜¯ä¸€ç§åŠ¨æ€å­¦ä¹ çŽ‡è°ƒåº¦å™¨ï¼Œæ•´ä½“æ¡†æž¶åŸºäºŽè®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å˜åŒ–æ¥è°ƒæ•´å­¦ä¹ çŽ‡ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽè‡ªé€‚åº”æœºåˆ¶ï¼šç®—æ³•å®žæ—¶ç›‘æŽ§æŸå¤±å€¼ï¼Œæ ¹æ®æŸå¤±çš„å˜åŒ–å¹…åº¦è®¡ç®—å­¦ä¹ çŽ‡è°ƒæ•´å› å­ï¼Œé€šè¿‡ç†è®ºåˆ†æžæŽ¨å¯¼å‡ºæœ€ä¼˜ç¼©æ”¾å› å­Fä»¥æœ€å¤§åŒ–æ”¶æ•›é€ŸçŽ‡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸ä¾èµ–é¢„å®šä¹‰çš„æ—¶é—´è¡¨ï¼ˆå¦‚ä½™å¼¦è¡°å‡ï¼‰ï¼Œè€Œæ˜¯æ ¹æ®è®­ç»ƒåŠ¨æ€è¿›è¡Œå®žæ—¶è°ƒæ•´ï¼Œä»Žè€Œæ›´çµæ´»åœ°é€‚åº”ä¸åŒä»»åŠ¡å’Œæ¨¡åž‹ï¼Œæé«˜äº†å¯¹å™ªå£°çŽ¯å¢ƒçš„é²æ£’æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒåœ¨å¤šä¸ªNLPã€CVå’ŒLLMä»»åŠ¡ä¸Šè¿›è¡Œï¼Œå‚æ•°è§„æ¨¡é«˜è¾¾70äº¿ï¼Œç»“æžœæ˜¾ç¤ºGreedyLRåœ¨å‡†ç¡®çŽ‡ã€è®­ç»ƒé€Ÿåº¦å’Œæ”¶æ•›æ€§æ–¹é¢å‡ä¼˜äºŽçŽ°æœ‰æœ€å…ˆè¿›è°ƒåº¦å™¨ï¼ŒåŒæ—¶ç®—æ³•å¯¹å™ªå£°çŽ¯å¢ƒè¡¨çŽ°å‡ºè‰¯å¥½é²æ£’æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯å¹¿æ³›åº”ç”¨äºŽè‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰å’Œå¤§è¯­è¨€æ¨¡åž‹çš„è®­ç»ƒåœºæ™¯ï¼ŒåŒ…æ‹¬å¾®è°ƒå’Œé¢„è®­ç»ƒä»»åŠ¡ã€‚å…¶å®žé™…ä»·å€¼åœ¨äºŽæä¾›äº†ä¸€ç§é«˜æ•ˆã€è‡ªé€‚åº”çš„å­¦ä¹ çŽ‡è°ƒåº¦æ–¹æ³•ï¼Œèƒ½åŠ é€Ÿæ¨¡åž‹æ”¶æ•›ã€æå‡è®­ç»ƒæ•ˆçŽ‡ï¼Œé€‚ç”¨äºŽå¤§è§„æ¨¡å‚æ•°æ¨¡åž‹ï¼ˆå¦‚70äº¿å‚æ•°ï¼‰çš„è®­ç»ƒä¼˜åŒ–ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Despite significant advances in optimizers for training, most research works use common scheduler choices like Cosine or exponential decay. In this paper, we study \emph{GreedyLR}, a novel scheduler that adaptively adjusts the learning rate during training based on the current loss. To validate the effectiveness of our proposed scheduler, we conduct experiments on several NLP, CV, and LLM tasks with up to $7B$ parameters, including both fine-tuning and pre-training experiments. The results show that our approach outperforms several state-of-the-art schedulers in terms of accuracy, speed, and convergence. We also provide a theoretical analysis of the GreedyLR algorithm, including a proof of convergence and derivation of the optimal scaling factor $F$ that maximizes the convergence rate, along with experiments to show robustness of the algorithm to realistic noisy landscapes. Our scheduler is easy to implement, computationally efficient, and could be considered a good default scheduler for training.

