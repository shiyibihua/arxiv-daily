---
layout: default
title: Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling
---

# Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14474" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14474v1</a>
  <a href="https://arxiv.org/pdf/2512.14474.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14474v1" onclick="toggleFavorite(this, '2512.14474v1', 'Model-First Reasoning LLM Agents: Reducing Hallucinations through Explicit Problem Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Annu Rana, Gaurav Kumar

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºModel-First Reasoningï¼Œé€šè¿‡æ˜¾å¼é—®é¢˜å»ºæ¨¡å‡å°‘LLMå¹»è§‰**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è§„åˆ’ä»»åŠ¡` `æ˜¾å¼å»ºæ¨¡` `çº¦æŸæ»¡è¶³` `AIä»£ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMåœ¨å¤æ‚è§„åˆ’ä»»åŠ¡ä¸­ä¾èµ–éšå¼çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹æ˜¾å¼é—®é¢˜è¡¨ç¤ºï¼Œå¯¼è‡´çº¦æŸè¿åå’Œç»“æœä¸ä¸€è‡´ã€‚
2. Model-First Reasoning (MFR) èŒƒå¼å…ˆè®©LLMæ„å»ºæ˜¾å¼é—®é¢˜æ¨¡å‹ï¼Œå†ç”Ÿæˆè§£å†³æ–¹æ¡ˆï¼Œæ¨¡æ‹Ÿç»å…¸AIè§„åˆ’ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMFRåœ¨å¤šä¸ªè§„åˆ’é¢†åŸŸæ˜¾è‘—å‡å°‘çº¦æŸè¿åï¼Œæå‡è§£å†³æ–¹æ¡ˆè´¨é‡ï¼Œè¯æ˜æ˜¾å¼å»ºæ¨¡çš„é‡è¦æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚çš„å¤šæ­¥éª¤è§„åˆ’ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œç»å¸¸å‡ºç°çº¦æŸè¿åå’Œä¸ä¸€è‡´çš„è§£å†³æ–¹æ¡ˆã€‚ç°æœ‰çš„ç­–ç•¥ï¼Œå¦‚Chain-of-Thoughtå’ŒReActï¼Œä¾èµ–äºéšå¼çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹æ˜¾å¼çš„é—®é¢˜è¡¨ç¤ºã€‚å—ç»å…¸AIè§„åˆ’çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†Model-First Reasoningï¼ˆMFRï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸¤é˜¶æ®µèŒƒå¼ï¼Œå…¶ä¸­LLMé¦–å…ˆæ„å»ºé—®é¢˜çš„æ˜¾å¼æ¨¡å‹ï¼Œå®šä¹‰å®ä½“ã€çŠ¶æ€å˜é‡ã€åŠ¨ä½œå’Œçº¦æŸï¼Œç„¶åå†ç”Ÿæˆè§£å†³æ–¹æ¡ˆè®¡åˆ’ã€‚åœ¨åŒ…æ‹¬åŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€é€»è¾‘è°œé¢˜å’Œç¨‹åºåˆæˆç­‰å¤šä¸ªè§„åˆ’é¢†åŸŸï¼Œä¸Chain-of-Thoughtå’ŒReActç›¸æ¯”ï¼ŒMFRå‡å°‘äº†çº¦æŸè¿åå¹¶æé«˜äº†è§£å†³æ–¹æ¡ˆè´¨é‡ã€‚æ¶ˆèç ”ç©¶è¡¨æ˜ï¼Œæ˜¾å¼å»ºæ¨¡é˜¶æ®µå¯¹äºè¿™äº›æ”¶ç›Šè‡³å…³é‡è¦ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œè®¸å¤šLLMè§„åˆ’å¤±è´¥æºäºè¡¨ç¤ºç¼ºé™·ï¼Œè€Œä¸æ˜¯æ¨ç†é™åˆ¶ï¼Œçªå‡ºäº†æ˜¾å¼å»ºæ¨¡ä½œä¸ºé²æ£’å’Œå¯è§£é‡ŠAIä»£ç†çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚æ‰€æœ‰æç¤ºã€è¯„ä¼°ç¨‹åºå’Œä»»åŠ¡æ•°æ®é›†å‡å·²è®°å½•ï¼Œä»¥æ–¹ä¾¿é‡ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚å¤šæ­¥éª¤è§„åˆ’ä»»åŠ¡ä¸­è¡¨ç°å‡ºçš„çº¦æŸè¿åå’Œä¸ä¸€è‡´æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚Chain-of-Thoughtå’ŒReActï¼Œä¸»è¦ä¾èµ–äºéšå¼çŠ¶æ€è·Ÿè¸ªï¼Œç¼ºä¹å¯¹é—®é¢˜çš„æ˜¾å¼å»ºæ¨¡ï¼Œå¯¼è‡´åœ¨éœ€è¦ä¸¥æ ¼éµå®ˆçº¦æŸæ¡ä»¶çš„è§„åˆ’ä»»åŠ¡ä¸­å®¹æ˜“å‡ºé”™ã€‚è¿™äº›æ–¹æ³•éš¾ä»¥æœ‰æ•ˆç®¡ç†å¤æ‚çš„çŠ¶æ€ç©ºé—´å’Œçº¦æŸå…³ç³»ï¼Œä»è€Œå½±å“æœ€ç»ˆè§£å†³æ–¹æ¡ˆçš„è´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´ç»å…¸AIè§„åˆ’çš„æ€æƒ³ï¼Œå¼•å…¥æ˜¾å¼çš„æ¨¡å‹æ„å»ºé˜¶æ®µã€‚é€šè¿‡è®©LLMé¦–å…ˆæ˜ç¡®åœ°å®šä¹‰é—®é¢˜ä¸­çš„å®ä½“ã€çŠ¶æ€å˜é‡ã€åŠ¨ä½œå’Œçº¦æŸï¼Œå¯ä»¥å¸®åŠ©LLMæ›´å¥½åœ°ç†è§£é—®é¢˜çš„ç»“æ„å’Œçº¦æŸæ¡ä»¶ï¼Œä»è€Œç”Ÿæˆæ›´å¯é å’Œä¸€è‡´çš„è§£å†³æ–¹æ¡ˆã€‚è¿™ç§æ˜¾å¼å»ºæ¨¡çš„è¿‡ç¨‹èƒ½å¤Ÿå‡å°‘LLMåœ¨æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ï¼Œå¹¶æé«˜è§„åˆ’çš„å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šModel-First Reasoning (MFR) åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š1) **æ¨¡å‹æ„å»ºé˜¶æ®µ**ï¼šLLMé¦–å…ˆæ¥æ”¶é—®é¢˜æè¿°ï¼Œç„¶åç”Ÿæˆä¸€ä¸ªæ˜¾å¼çš„æ¨¡å‹ï¼ŒåŒ…æ‹¬å®šä¹‰é—®é¢˜ä¸­çš„å®ä½“ã€çŠ¶æ€å˜é‡ã€å¯æ‰§è¡Œçš„åŠ¨ä½œä»¥åŠéœ€è¦æ»¡è¶³çš„çº¦æŸæ¡ä»¶ã€‚è¿™ä¸ªæ¨¡å‹æ˜¯å¯¹é—®é¢˜çš„ä¸€ä¸ªç»“æ„åŒ–è¡¨ç¤ºã€‚2) **è§„åˆ’ç”Ÿæˆé˜¶æ®µ**ï¼šåŸºäºç¬¬ä¸€é˜¶æ®µæ„å»ºçš„æ¨¡å‹ï¼ŒLLMç”Ÿæˆä¸€ä¸ªè§£å†³æ–¹æ¡ˆè®¡åˆ’ï¼Œè¯¥è®¡åˆ’æ—¨åœ¨æ»¡è¶³æ‰€æœ‰å®šä¹‰çš„çº¦æŸæ¡ä»¶å¹¶è¾¾åˆ°ç›®æ ‡çŠ¶æ€ã€‚æ•´ä¸ªæµç¨‹æ—¨åœ¨å°†å¤æ‚çš„è§„åˆ’ä»»åŠ¡åˆ†è§£ä¸ºæ›´æ˜“äºç®¡ç†å’Œæ¨ç†çš„æ­¥éª¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šMFR çš„æœ€é‡è¦åˆ›æ–°åœ¨äºå…¶æ˜¾å¼çš„é—®é¢˜å»ºæ¨¡é˜¶æ®µã€‚ä¸ä¼ ç»Ÿçš„éšå¼æ¨ç†æ–¹æ³•ä¸åŒï¼ŒMFR å¼ºåˆ¶ LLM åœ¨ç”Ÿæˆè§£å†³æ–¹æ¡ˆä¹‹å‰ï¼Œå…ˆæ„å»ºä¸€ä¸ªå¯¹é—®é¢˜çš„æ¸…æ™°ã€ç»“æ„åŒ–çš„è¡¨ç¤ºã€‚è¿™ç§æ˜¾å¼å»ºæ¨¡èƒ½å¤Ÿæ˜¾è‘—å‡å°‘ LLM åœ¨æ¨ç†è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¹»è§‰ï¼Œå¹¶æé«˜è§„åˆ’çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼ŒMFR çš„ä¸¤é˜¶æ®µè®¾è®¡ä½¿å¾—é—®é¢˜åˆ†è§£æ›´åŠ æ¸…æ™°ï¼Œä¾¿äºè°ƒè¯•å’Œä¼˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šMFR çš„å…³é”®è®¾è®¡åœ¨äºå¦‚ä½•æœ‰æ•ˆåœ°æç¤º LLM æ„å»ºé—®é¢˜æ¨¡å‹ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†ç²¾å¿ƒè®¾è®¡çš„æç¤ºæ¨¡æ¿ï¼Œå¼•å¯¼ LLM é€æ­¥å®šä¹‰å®ä½“ã€çŠ¶æ€å˜é‡ã€åŠ¨ä½œå’Œçº¦æŸã€‚è¿™äº›æç¤ºæ¨¡æ¿éœ€è¦æ ¹æ®ä¸åŒçš„è§„åˆ’é¢†åŸŸè¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿ LLM èƒ½å¤Ÿå‡†ç¡®åœ°æ•æ‰é—®é¢˜çš„å…³é”®ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è¯¦ç»†è®°å½•äº†æ‰€æœ‰æç¤ºã€è¯„ä¼°ç¨‹åºå’Œä»»åŠ¡æ•°æ®é›†ï¼Œä»¥æ–¹ä¾¿å…¶ä»–ç ”ç©¶è€…å¤ç°å’Œæ”¹è¿› MFR æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMFRåœ¨å¤šä¸ªè§„åˆ’é¢†åŸŸæ˜¾è‘—ä¼˜äºChain-of-Thoughtå’ŒReActç­‰åŸºçº¿æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€é€»è¾‘è°œé¢˜å’Œç¨‹åºåˆæˆç­‰ä»»åŠ¡ä¸­ï¼ŒMFRèƒ½å¤Ÿæ˜¾è‘—å‡å°‘çº¦æŸè¿åï¼Œå¹¶æé«˜è§£å†³æ–¹æ¡ˆçš„è´¨é‡ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®äº†æ˜¾å¼å»ºæ¨¡é˜¶æ®µå¯¹äºMFRæ€§èƒ½æå‡çš„å…³é”®ä½œç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªéœ€è¦å¤æ‚è§„åˆ’å’Œå†³ç­–çš„é¢†åŸŸï¼Œå¦‚åŒ»ç–—è°ƒåº¦ã€è·¯çº¿è§„åˆ’ã€èµ„æºåˆ†é…ã€ç‰©æµç®¡ç†å’Œè‡ªåŠ¨åŒ–ç¨‹åºç”Ÿæˆç­‰ã€‚é€šè¿‡æé«˜LLMåœ¨è¿™äº›é¢†åŸŸçš„è§„åˆ’èƒ½åŠ›ï¼Œå¯ä»¥æ˜¾è‘—æå‡æ•ˆç‡ã€é™ä½æˆæœ¬ï¼Œå¹¶å‡å°‘äººä¸ºé”™è¯¯ã€‚æ­¤å¤–ï¼ŒMFRæ–¹æ³•è¿˜æœ‰åŠ©äºå¼€å‘æ›´å¯é å’Œå¯è§£é‡Šçš„AIä»£ç†ï¼Œå¢å¼ºäººæœºåä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) often struggle with complex multi-step planning tasks, showing high rates of constraint violations and inconsistent solutions. Existing strategies such as Chain-of-Thought and ReAct rely on implicit state tracking and lack an explicit problem representation. Inspired by classical AI planning, we propose Model-First Reasoning (MFR), a two-phase paradigm in which the LLM first constructs an explicit model of the problem, defining entities, state variables, actions, and constraints, before generating a solution plan. Across multiple planning domains, including medical scheduling, route planning, resource allocation, logic puzzles, and procedural synthesis, MFR reduces constraint violations and improves solution quality compared to Chain-of-Thought and ReAct. Ablation studies show that the explicit modeling phase is critical for these gains. Our results suggest that many LLM planning failures stem from representational deficiencies rather than reasoning limitations, highlighting explicit modeling as a key component for robust and interpretable AI agents. All prompts, evaluation procedures, and task datasets are documented to facilitate reproducibility.

