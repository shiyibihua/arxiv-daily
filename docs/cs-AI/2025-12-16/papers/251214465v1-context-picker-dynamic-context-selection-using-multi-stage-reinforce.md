---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14465" class="toolbar-btn" target="_blank">üìÑ arXiv: 2512.14465v1</a>
  <a href="https://arxiv.org/pdf/2512.14465.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14465v1" onclick="toggleFavorite(this, '2512.14465v1', 'Context-Picker: Dynamic context selection using multi-stage reinforcement learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**ÂàÜÁ±ª**: cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-12-16

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Context-PickerÔºöÂà©Áî®Â§öÈò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ËøõË°åÂä®ÊÄÅ‰∏ä‰∏ãÊñáÈÄâÊã©ÔºåÊèêÂçáÈïøÊñáÊú¨ÈóÆÁ≠îÂáÜÁ°ÆÁéá„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÈïøÊñáÊú¨ÈóÆÁ≠î` `Âº∫ÂåñÂ≠¶‰π†` `‰∏ä‰∏ãÊñáÈÄâÊã©` `Â§öÈò∂ÊÆµÂ≠¶‰π†` `ËØÅÊçÆÊèêÁÇº`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. ÈïøÊñáÊú¨ÈóÆÁ≠î‰∏≠ÔºåÂ¶Ç‰ΩïÈÄâÊã©ÊúÄ‰Ω≥Êï∞ÈáèÁöÑ‰∏ä‰∏ãÊñáÊÆµËêΩÊòØ‰∏Ä‰∏™ÊåëÊàòÔºåËøáÂ§öÂºïÂÖ•Âô™Â£∞ÔºåËøáÂ∞ëÂàôÈÅóÊºè‰ø°ÊÅØ„ÄÇ
2. Context-PickerÈááÁî®‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†ÔºåÂÖàÂè¨ÂõûÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂÜçÁ≤æÁÆÄÂÜó‰ΩôÔºåÈÄâÊã©ÊúÄÂ∞èÂÖÖÂàÜËØÅÊçÆÂ≠êÈõÜ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåContext-PickerÂú®ÈïøÊñáÊú¨ÈóÆÁ≠î‰ªªÂä°‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâRAGÊ®°ÂûãÔºåÊèêÂçáÁ≠îÊ°àÂáÜÁ°ÆÁéá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÈïøÊñáÊú¨ÈóÆÁ≠îÔºàLCQAÔºâ‰∏≠ÔºåÁ°ÆÂÆöÁªôÂÆöÊü•ËØ¢ÁöÑÊúÄ‰Ω≥‰∏ä‰∏ãÊñáÊï∞ÈáèÊòØ‰∏Ä‰∏™ÈáçË¶ÅÁöÑÊåëÊàò„ÄÇÂåÖÂê´ËøáÂ∞ëÁöÑÊÆµËêΩÂèØËÉΩ‰ºöÈÅóÊºèÂÖ≥ÈîÆ‰ø°ÊÅØÔºåËÄåÂåÖÂê´ËøáÂ§öÁöÑÊÆµËêΩÂèØËÉΩ‰ºöÂºïÂÖ•Âô™Â£∞Âπ∂Èôç‰ΩéÁ≠îÊ°àÁöÑË¥®Èáè„ÄÇ‰º†ÁªüÁöÑTop-$K$Ê£ÄÁ¥¢ÂíåÂçïÈò∂ÊÆµÈáçÊéíÂ∫èÁ≠âÊñπÊ≥ïÈù¢‰∏¥ÁùÄÈÄâÊã©ÂêàÈÄÇÊÆµËêΩÊï∞ÈáèÁöÑÂõ∞Â¢ÉÔºåÂØπ‰∫éÈÄöÂ∏∏Âè™ÈúÄË¶ÅÂ∞ëÈáèÁâπÂÆöËØÅÊçÆÁöÑ‰∫ãÂÆûÊÄßÈóÆÈ¢òÂ∞§ÂÖ∂Â¶ÇÊ≠§„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÂºïÂÖ•‰∫ÜContext-PickerÔºåËøôÊòØ‰∏Ä‰∏™Êé®ÁêÜÊÑüÁü•ÁöÑÊ°ÜÊû∂ÔºåÂÆÉÂ∞ÜËåÉÂºè‰ªéÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊéíÂ∫èËΩ¨Âèò‰∏∫ÊúÄÂ∞èÂÖÖÂàÜÂ≠êÈõÜÈÄâÊã©„ÄÇContext-PickerÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ËßÜ‰∏∫‰∏Ä‰∏™ÂÜ≥Á≠ñËøáÁ®ãÔºåÈÄöËøáÂèó‰∫∫Á±ªÂêØÂèëÁöÑ‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ËøõË°å‰ºòÂåñÔºö‰∏Ä‰∏™‰ª•Âè¨Âõû‰∏∫ÂØºÂêëÁöÑÈò∂ÊÆµÔºå‰ºòÂÖàËÄÉËôëÊé®ÁêÜÈìæÁöÑË¶ÜÁõñÔºõÁÑ∂ÂêéÊòØ‰∏Ä‰∏™‰ª•Á≤æÁ°Æ‰∏∫ÂØºÂêëÁöÑÈò∂ÊÆµÔºåÁßØÊûÅÂú∞‰øÆÂâ™ÂÜó‰Ωô‰ª•ÊèêÁÇº‰∏Ä‰∏™Á¥ßÂáëÁöÑËØÅÊçÆÈõÜ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Â•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏Ä‰∏™Á¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÔºåÈÄöËøáÁïô‰∏ÄÊ≥ïÔºàLOOÔºâÊåñÊéò‚ÄúÊúÄÂ∞èÂÖÖÂàÜÈõÜ‚ÄùÔºåÊèê‰æõÂØÜÈõÜÁöÑ„ÄÅ‰ªªÂä°ÂØπÈΩêÁöÑÁõëÁù£„ÄÇÂú®‰∫î‰∏™ÈïøÊñáÊú¨ÂíåÂ§öË∑≥ÈóÆÁ≠îÂü∫ÂáÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåContext-PickerÊòæËëó‰ºò‰∫éÂº∫Â§ßÁöÑRAGÂü∫Á∫øÔºåÂú®ÂÖ∑ÊúâÂèØÊØîÊàñÊõ¥Áü≠ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶‰∏ãÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÁ≠îÊ°àÂáÜÁ°ÆÊÄß„ÄÇÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÁî±Á≤óÂà∞Á≤æÁöÑ‰ºòÂåñÁ≠ñÁï•„ÄÅÂÜó‰ΩôÊÑüÁü•ÁöÑÂ•ñÂä±Â°ëÈÄ†Âíå‰ª•ÁêÜÁî±‰∏∫ÊåáÂØºÁöÑÊ†ºÂºèÈÉΩÂØπËøô‰∫õÊî∂ÁõäÂÅöÂá∫‰∫ÜÈáçÂ§ßË¥°ÁåÆ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÈïøÊñáÊú¨ÈóÆÁ≠îÔºàLCQAÔºâ‰∏≠‰∏ä‰∏ãÊñáÈÄâÊã©ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÔºåÂ¶ÇÂõ∫ÂÆöTop-KÊ£ÄÁ¥¢ÂíåÂçïÈò∂ÊÆµÈáçÊéíÂ∫èÔºåÈöæ‰ª•Á°ÆÂÆöÊúÄ‰Ω≥ÁöÑ‰∏ä‰∏ãÊñáÊï∞ÈáèÔºåÂÆπÊòìÂºïÂÖ•Âô™Â£∞ÊàñÈÅóÊºèÂÖ≥ÈîÆ‰ø°ÊÅØÔºåÂ∞§ÂÖ∂ÊòØÂú®ÈúÄË¶ÅÂ∞ëÈáèÁ≤æÁ°ÆËØÅÊçÆÁöÑ‰∫ãÂÆûÊÄßÈóÆÈ¢ò‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ËßÜ‰∏∫‰∏Ä‰∏™ÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂‰ΩøÁî®Âº∫ÂåñÂ≠¶‰π†Êù•‰ºòÂåñËøô‰∏™ËøáÁ®ã„ÄÇÈÄöËøáÊ®°‰ªø‰∫∫Á±ªÁöÑÊé®ÁêÜËøáÁ®ãÔºåContext-PickerÈááÁî®‰∏§Èò∂ÊÆµÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÈ¶ñÂÖàÁ°Æ‰øùÂè¨ÂõûÊâÄÊúâÁõ∏ÂÖ≥ÁöÑËØÅÊçÆÔºåÁÑ∂ÂêéÂÜçÂéªÈô§ÂÜó‰Ωô‰ø°ÊÅØÔºåÊúÄÁªàÈÄâÊã©‰∏Ä‰∏™ÊúÄÂ∞è‰∏îÂÖÖÂàÜÁöÑËØÅÊçÆÂ≠êÈõÜ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöContext-PickerÊ°ÜÊû∂ÂåÖÂê´‰∏§‰∏™‰∏ªË¶ÅÁöÑÂº∫ÂåñÂ≠¶‰π†Èò∂ÊÆµÔºöÂè¨ÂõûÈò∂ÊÆµÂíåÁ≤æÁÆÄÈò∂ÊÆµ„ÄÇÂú®Âè¨ÂõûÈò∂ÊÆµÔºåÊ®°ÂûãÁöÑÁõÆÊ†áÊòØÂ∞ΩÂèØËÉΩË¶ÜÁõñÊâÄÊúâÂèØËÉΩÁõ∏ÂÖ≥ÁöÑÊé®ÁêÜÈìæÔºåÁ°Æ‰øù‰∏çÈÅóÊºè‰ªª‰ΩïÂÖ≥ÈîÆ‰ø°ÊÅØ„ÄÇÂú®Á≤æÁÆÄÈò∂ÊÆµÔºåÊ®°ÂûãÂàô‰∏ìÊ≥®‰∫éÂéªÈô§ÂÜó‰ΩôÁöÑ‰∏ä‰∏ãÊñáÊÆµËêΩÔºå‰ª•ÂáèÂ∞ëÂô™Â£∞Âπ∂ÊèêÈ´òÁ≠îÊ°àÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Â•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢òÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰∏Ä‰∏™Á¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÔºåÁî®‰∫éÊåñÊéò‚ÄúÊúÄÂ∞èÂÖÖÂàÜÈõÜ‚ÄùÔºåÂπ∂Êèê‰æõÂØÜÈõÜÁöÑÁõëÁù£‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöContext-PickerÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂‰∏§Èò∂ÊÆµÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÂíåÁ¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ã„ÄÇ‰∏é‰º†ÁªüÁöÑÂü∫‰∫éÁõ∏‰ººÊÄßÁöÑÊéíÂ∫èÊñπÊ≥ï‰∏çÂêåÔºåContext-PickerÂ∞Ü‰∏ä‰∏ãÊñáÈÄâÊã©ËßÜ‰∏∫‰∏Ä‰∏™ÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂ÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Êù•‰ºòÂåñËøô‰∏™ËøáÁ®ãÔºå‰ªéËÄåËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞ÈÄâÊã©ÊúÄÂ∞è‰∏îÂÖÖÂàÜÁöÑËØÅÊçÆÂ≠êÈõÜ„ÄÇÁ¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÂàôËß£ÂÜ≥‰∫ÜÂ•ñÂä±Á®ÄÁñèÊÄßÈóÆÈ¢òÔºå‰∏∫Âº∫ÂåñÂ≠¶‰π†Êèê‰æõ‰∫ÜÊõ¥ÊúâÊïàÁöÑÁõëÁù£‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöContext-Picker‰ΩøÁî®‰∫Ü‰∏§Èò∂ÊÆµÁöÑÂº∫ÂåñÂ≠¶‰π†Á≠ñÁï•ÔºåÊØè‰∏™Èò∂ÊÆµÈÉΩÊúâ‰∏çÂêåÁöÑÂ•ñÂä±ÂáΩÊï∞„ÄÇÂú®Âè¨ÂõûÈò∂ÊÆµÔºåÂ•ñÂä±ÂáΩÊï∞‰æßÈáç‰∫éË¶ÜÁõñÊâÄÊúâÁõ∏ÂÖ≥ÁöÑÊé®ÁêÜÈìæ„ÄÇÂú®Á≤æÁÆÄÈò∂ÊÆµÔºåÂ•ñÂä±ÂáΩÊï∞Âàô‰æßÈáç‰∫éÂéªÈô§ÂÜó‰ΩôÁöÑ‰∏ä‰∏ãÊñáÊÆµËêΩ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøò‰ΩøÁî®‰∫ÜÁïô‰∏ÄÊ≥ïÔºàLOOÔºâÊù•ÊåñÊéò‚ÄúÊúÄÂ∞èÂÖÖÂàÜÈõÜ‚ÄùÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫Á¶ªÁ∫øËØÅÊçÆÊèêÁÇºÊµÅÁ®ãÁöÑÁõëÁù£‰ø°Âè∑„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞Ôºå‰ΩÜÊ≠§Â§ÑÊú™Êèê‰æõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåContext-PickerÂú®‰∫î‰∏™ÈïøÊñáÊú¨ÂíåÂ§öË∑≥ÈóÆÁ≠îÂü∫ÂáÜ‰∏äÊòæËëó‰ºò‰∫éÂº∫Â§ßÁöÑRAGÂü∫Á∫ø„ÄÇÂú®ÂÖ∑ÊúâÂèØÊØîÊàñÊõ¥Áü≠ÁöÑ‰∏ä‰∏ãÊñáÈïøÂ∫¶‰∏ãÔºåContext-PickerÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑÁ≠îÊ°àÂáÜÁ°ÆÊÄß„ÄÇÊ∂àËûçÁ†îÁ©∂Ë°®ÊòéÔºåÁî±Á≤óÂà∞Á≤æÁöÑ‰ºòÂåñÁ≠ñÁï•„ÄÅÂÜó‰ΩôÊÑüÁü•ÁöÑÂ•ñÂä±Â°ëÈÄ†Âíå‰ª•ÁêÜÁî±‰∏∫ÊåáÂØºÁöÑÊ†ºÂºèÈÉΩÂØπËøô‰∫õÊî∂ÁõäÂÅöÂá∫‰∫ÜÈáçÂ§ßË¥°ÁåÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Context-PickerÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶Å‰ªéÈïøÊñáÊú¨‰∏≠ÊèêÂèñ‰ø°ÊÅØÁöÑÂú∫ÊôØÔºåÂ¶ÇÊô∫ËÉΩÂÆ¢Êúç„ÄÅÊ≥ïÂæãÂí®ËØ¢„ÄÅÈáëËûçÂàÜÊûêÁ≠â„ÄÇÈÄöËøáÈÄâÊã©ÊúÄÁõ∏ÂÖ≥ÁöÑ‰∏ä‰∏ãÊñáÔºåÂèØ‰ª•ÊèêÈ´ò‰ø°ÊÅØÊèêÂèñÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåÂáèÂ∞ëÂô™Â£∞Âπ≤Êâ∞ÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å„ÄÇËØ•Á†îÁ©∂ÂØπÊèêÂçáÈïøÊñáÊú¨ÈóÆÁ≠îÁ≥ªÁªüÁöÑÊÄßËÉΩÂÖ∑ÊúâÈáçË¶ÅÊÑè‰πâ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

