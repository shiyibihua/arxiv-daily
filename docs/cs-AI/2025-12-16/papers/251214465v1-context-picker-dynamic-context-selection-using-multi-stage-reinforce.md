---
layout: default
title: Context-Picker: Dynamic context selection using multi-stage reinforcement learning
---

# Context-Picker: Dynamic context selection using multi-stage reinforcement learning

**arXiv**: [2512.14465v1](https://arxiv.org/abs/2512.14465) | [PDF](https://arxiv.org/pdf/2512.14465.pdf)

**ä½œè€…**: Siyuan Zhu, Chengdong Xu, Kaiqiang Ke, Chao Yu

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºContext-Pickeræ¡†æž¶ï¼Œé€šè¿‡å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ åŠ¨æ€é€‰æ‹©æœ€å°å……åˆ†è¯æ®é›†ï¼Œä»¥è§£å†³é•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­çš„ä¸Šä¸‹æ–‡é€‰æ‹©éš¾é¢˜ã€‚**

**å…³é”®è¯**: `é•¿ä¸Šä¸‹æ–‡é—®ç­”` `å¼ºåŒ–å­¦ä¹ ` `è¯æ®é€‰æ‹©` `å¤šé˜¶æ®µä¼˜åŒ–` `æŽ¨ç†æ„ŸçŸ¥` `æœ€å°å……åˆ†é›†` `RAGå¢žå¼º` `é—®ç­”ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿ä¸Šä¸‹æ–‡é—®ç­”ä¸­ï¼Œä¼ ç»Ÿå›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºæ–¹æ³•éš¾ä»¥å¹³è¡¡ä¸Šä¸‹æ–‡è¦†ç›–ä¸Žå™ªå£°æŽ§åˆ¶ï¼Œå°¤å…¶å¯¹äº‹å®žåž‹é—®é¢˜é€ æˆä¿¡æ¯å†—ä½™æˆ–é—æ¼ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºContext-Pickeræ¡†æž¶ï¼Œå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºå†³ç­–è¿‡ç¨‹ï¼Œé‡‡ç”¨ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ï¼ˆå¬å›žå¯¼å‘å’Œç²¾ç¡®å¯¼å‘ï¼‰åŠ¨æ€é€‰æ‹©æœ€å°å……åˆ†è¯æ®é›†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒContext-Pickeræ˜¾è‘—è¶…è¶ŠRAGåŸºçº¿ï¼Œä»¥æ›´çŸ­ä¸Šä¸‹æ–‡å®žçŽ°æ›´é«˜ç­”æ¡ˆå‡†ç¡®æ€§ï¼Œæ¶ˆèžç ”ç©¶éªŒè¯äº†å…³é”®ç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨é•¿ä¸Šä¸‹æ–‡é—®ç­”ï¼ˆLCQAï¼‰ä¸­ï¼Œä¸ºç»™å®šæŸ¥è¯¢ç¡®å®šæœ€ä¼˜çš„ä¸Šä¸‹æ–‡é‡æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åŒ…å«è¿‡å°‘æ®µè½å¯èƒ½é—æ¼å…³é”®ä¿¡æ¯ï¼Œè€ŒåŒ…å«è¿‡å¤šåˆ™ä¼šå¼•å…¥å™ªå£°å¹¶é™ä½Žç­”æ¡ˆè´¨é‡ã€‚ä¼ ç»Ÿæ–¹æ³•ï¼ˆå¦‚å›ºå®šTop-Kæ£€ç´¢å’Œå•é˜¶æ®µé‡æŽ’åºï¼‰é¢ä¸´é€‰æ‹©é€‚å½“æ®µè½æ•°é‡çš„å›°å¢ƒï¼Œè¿™ä¸€é—®é¢˜åœ¨äº‹å®žåž‹é—®é¢˜ä¸Šå°¤ä¸ºçªå‡ºï¼Œè¿™ç±»é—®é¢˜é€šå¸¸åªéœ€è¦å°‘é‡ç‰¹å®šè¯æ®ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†Context-Pickerï¼Œè¿™æ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥æ¡†æž¶ï¼Œå°†èŒƒå¼ä»ŽåŸºäºŽç›¸ä¼¼æ€§çš„æŽ’åºè½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ã€‚Context-Pickerå°†ä¸Šä¸‹æ–‡é€‰æ‹©è§†ä¸ºä¸€ä¸ªå†³ç­–è¿‡ç¨‹ï¼Œé€šè¿‡å—äººç±»å¯å‘çš„ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’è¿›è¡Œä¼˜åŒ–ï¼šä¸€ä¸ªä»¥å¬å›žä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œä¼˜å…ˆè¦†ç›–æŽ¨ç†é“¾ï¼›éšåŽæ˜¯ä¸€ä¸ªä»¥ç²¾ç¡®ä¸ºå¯¼å‘çš„é˜¶æ®µï¼Œç§¯æžå‰ªæžå†—ä½™ä»¥æç‚¼ç´§å‡‘çš„è¯æ®é›†ã€‚ä¸ºè§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•ï¼ˆLOOï¼‰æŒ–æŽ˜â€œæœ€å°å……åˆ†é›†â€ï¼Œæä¾›å¯†é›†ã€ä»»åŠ¡å¯¹é½çš„ç›‘ç£ã€‚åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„RAGåŸºçº¿ï¼Œåœ¨å¯æ¯”æˆ–æ›´çŸ­çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹å®žçŽ°äº†æ›´é«˜çš„ç­”æ¡ˆå‡†ç¡®æ€§ã€‚æ¶ˆèžç ”ç©¶è¡¨æ˜Žï¼Œä»Žç²—åˆ°ç»†çš„ä¼˜åŒ–è®¡åˆ’ã€å†—ä½™æ„ŸçŸ¥çš„å¥–åŠ±å¡‘é€ å’ŒæŽ¨ç†å¼•å¯¼çš„æ ¼å¼éƒ½å¯¹è¿™ä¸€å¢žç›Šæœ‰é‡è¦è´¡çŒ®ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

Context-Pickeræ˜¯ä¸€ä¸ªæŽ¨ç†æ„ŸçŸ¥æ¡†æž¶ï¼Œæ•´ä½“ä¸Šé‡‡ç”¨å¤šé˜¶æ®µå¼ºåŒ–å­¦ä¹ è¿›è¡ŒåŠ¨æ€ä¸Šä¸‹æ–‡é€‰æ‹©ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼š1ï¼‰å°†ä¸Šä¸‹æ–‡é€‰æ‹©ä»Žç›¸ä¼¼æ€§æŽ’åºèŒƒå¼è½¬å‘æœ€å°å……åˆ†å­é›†é€‰æ‹©ï¼›2ï¼‰è®¾è®¡ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ è®¡åˆ’ï¼Œç¬¬ä¸€é˜¶æ®µä»¥å¬å›žä¸ºå¯¼å‘è¦†ç›–æŽ¨ç†é“¾ï¼Œç¬¬äºŒé˜¶æ®µä»¥ç²¾ç¡®ä¸ºå¯¼å‘å‰ªæžå†—ä½™ï¼›3ï¼‰æå‡ºç¦»çº¿è¯æ®è’¸é¦æµç¨‹ï¼Œé€šè¿‡ç•™ä¸€æ³•æŒ–æŽ˜æœ€å°å……åˆ†é›†ï¼Œè§£å†³å¥–åŠ±ç¨€ç–æ€§é—®é¢˜ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œå®ƒä¸å†ä¾èµ–å›ºå®šæ•°é‡çš„æ®µè½æˆ–å•é˜¶æ®µé‡æŽ’åºï¼Œè€Œæ˜¯é€šè¿‡å†³ç­–è¿‡ç¨‹ä¼˜åŒ–ï¼Œå®žçŽ°è‡ªé€‚åº”ã€ä»»åŠ¡å¯¹é½çš„ä¸Šä¸‹æ–‡é€‰æ‹©ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨äº”ä¸ªé•¿ä¸Šä¸‹æ–‡å’Œå¤šè·³é—®ç­”åŸºå‡†æµ‹è¯•ä¸­ï¼ŒContext-Pickeræ˜¾è‘—ä¼˜äºŽRAGåŸºçº¿ï¼Œç­”æ¡ˆå‡†ç¡®æ€§æ›´é«˜ï¼ŒåŒæ—¶ä¸Šä¸‹æ–‡é•¿åº¦å¯æ¯”æˆ–æ›´çŸ­ï¼›æ¶ˆèžç ”ç©¶è¯å®žä¸¤é˜¶æ®µä¼˜åŒ–ã€å†—ä½™æ„ŸçŸ¥å¥–åŠ±å’ŒæŽ¨ç†å¼•å¯¼æ ¼å¼æ˜¯å…³é”®å¢žç›Šæ¥æºã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽé•¿ä¸Šä¸‹æ–‡é—®ç­”å’Œå¤šè·³é—®ç­”åœºæ™¯ï¼Œå¦‚æ–‡æ¡£æ£€ç´¢ã€çŸ¥è¯†åº“é—®ç­”å’Œå¤æ‚æŽ¨ç†ä»»åŠ¡ï¼Œå¯æå‡å¤§åž‹è¯­è¨€æ¨¡åž‹åœ¨ä¿¡æ¯å¯†é›†çŽ¯å¢ƒä¸­çš„å‡†ç¡®æ€§å’Œæ•ˆçŽ‡ï¼Œå‡å°‘è®¡ç®—å¼€é”€ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In long-context question answering (LCQA), determining the optimal amount of context for a given query is a significant challenge. Including too few passages may omit critical information, while including too many can introduce noise and reduce the quality of the answer. Traditional approaches, such as fixed Top-$K$ retrieval and single-stage reranking, face the dilemma of selecting the right number of passages. This problem is particularly pronounced for factoid questions, which often require only a few specific pieces of evidence. To address this issue, we introduce \emph{Context-Picker}, a reasoning-aware framework that shifts the paradigm from similarity-based ranking to minimal sufficient subset selection. Context-Picker treats context selection as a decision-making process optimized via a human-inspired, two-stage reinforcement learning schedule: a \emph{recall-oriented} stage that prioritizes the coverage of reasoning chains, followed by a \emph{precision-oriented} stage that aggressively prunes redundancy to distill a compact evidence set. To resolve reward sparsity, we propose an offline evidence distillation pipeline that mines "minimal sufficient sets" via a Leave-One-Out (LOO) procedure, providing dense, task-aligned supervision. Experiments on five long-context and multi-hop QA benchmarks demonstrate that Context-Picker significantly outperforms strong RAG baselines, achieving superior answer accuracy with comparable or reduced context lengths. Ablation studies indicate that the coarse-to-fine optimization schedule, the redundancy-aware reward shaping, and the rationale-guided format all contribute substantially to these gains.

