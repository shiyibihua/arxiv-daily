---
layout: default
title: Universal Reasoning Model
---

# Universal Reasoning Model

**arXiv**: [2512.14693v1](https://arxiv.org/abs/2512.14693) | [PDF](https://arxiv.org/pdf/2512.14693.pdf)

**ä½œè€…**: Zitian Gao, Lynx Chen, Yihao Xiao, He Xing, Ran Tao, Haoming Luo, Joey Zhou, Bryan Dai

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/zitian-gao/URM)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨æ¨ç†æ¨¡å‹ä»¥æå‡å¤æ‚æ¨ç†ä»»åŠ¡æ€§èƒ½ï¼Œåœ¨ARC-AGIåŸºå‡†ä¸Šå®ç°æ–°çªç ´**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

<<<<<<< HEAD
**å…³é”®è¯**: `é€šç”¨æ¨ç†æ¨¡å‹` `Transformeræ¶æ„` `å¤æ‚æ¨ç†ä»»åŠ¡` `ARC-AGIåŸºå‡†` `çŸ­å·ç§¯` `æˆªæ–­åå‘ä¼ æ’­` `å¾ªç¯å½’çº³åç½®` `éçº¿æ€§ç»„ä»¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨Transformeråœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ€§èƒ½æ¥æºä¸æ˜ï¼Œé™åˆ¶äº†è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
2. é€šè¿‡åˆ†æå‘ç°æ€§èƒ½æå‡æºäºå¾ªç¯å½’çº³åç½®å’Œå¼ºéçº¿æ€§ï¼Œæå‡ºå¢å¼ºé€šç”¨æ¨ç†æ¨¡å‹ã€‚
3. åœ¨ARC-AGIåŸºå‡†ä¸Šå®ç°æ˜¾è‘—æå‡ï¼Œè¾¾åˆ°53.8%å’Œ16.0%çš„pass@1æ–°çºªå½•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€šç”¨Transformerï¼ˆUTsï¼‰å·²å¹¿æ³›åº”ç”¨äºARC-AGIå’Œæ•°ç‹¬ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œä½†å…¶æ€§èƒ½æå‡çš„å…·ä½“æ¥æºå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåˆ†æäº†UTsçš„å˜ä½“ï¼Œå‘ç°ARC-AGIä¸Šçš„æ”¹è¿›ä¸»è¦æºäºTransformerçš„å¾ªç¯å½’çº³åç½®å’Œå¼ºéçº¿æ€§ç»„ä»¶ï¼Œè€Œéå¤æ‚çš„æ¶æ„è®¾è®¡ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†é€šç”¨æ¨ç†æ¨¡å‹ï¼ˆURMï¼‰ï¼Œé€šè¿‡å¼•å…¥çŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­æ¥å¢å¼ºUTã€‚è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨ç†æ€§èƒ½ï¼Œåœ¨ARC-AGI 1ä¸Šè¾¾åˆ°äº†53.8%çš„pass@1ï¼Œåœ¨ARC-AGI 2ä¸Šè¾¾åˆ°äº†16.0%çš„pass@1ï¼Œå®ç°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚ä»£ç å·²å¼€æºï¼šhttps://github.com/zitian-gao/URMã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡ï¼ˆå¦‚ARC-AGIå’Œæ•°ç‹¬ï¼‰ä¸­ï¼Œé€šç”¨Transformeræ€§èƒ½æå‡æ¥æºä¸æ˜ç¡®çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–å¤æ‚æ¶æ„è®¾è®¡ï¼Œä½†å®é™…æ•ˆæœå¯èƒ½æºäºå…¶ä»–å› ç´ ï¼Œå¯¼è‡´ä¼˜åŒ–æ–¹å‘æ¨¡ç³Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç³»ç»Ÿåˆ†æå‘ç°æ€§èƒ½æå‡ä¸»è¦æ¥è‡ªTransformerçš„å¾ªç¯å½’çº³åç½®å’Œå¼ºéçº¿æ€§ç»„ä»¶ï¼Œè€Œéå¤æ‚æ¶æ„ï¼Œå› æ­¤æå‡ºå¢å¼ºé€šç”¨æ¨ç†æ¨¡å‹ï¼Œèšç„¦äºè¿™äº›æ ¸å¿ƒè¦ç´ ï¼Œä»¥æ›´é«˜æ•ˆåœ°æå‡æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŸºäºé€šç”¨Transformerï¼Œé€šè¿‡å¼•å…¥çŸ­å·ç§¯æ¨¡å—æ¥å¢å¼ºå±€éƒ¨ç‰¹å¾æå–ï¼Œå¹¶ç»“åˆæˆªæ–­åå‘ä¼ æ’­æŠ€æœ¯ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œå½¢æˆURMæ¨¡å‹ï¼Œåº”ç”¨äºåºåˆ—æ¨ç†ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°æ˜¯ç»“åˆçŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­æ¥å¢å¼ºé€šç”¨Transformerï¼ŒåŒºåˆ«äºç°æœ‰æ–¹æ³•ä¾èµ–å¤æ‚æ¶æ„è®¾è®¡ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºæ›´ç›´æ¥åœ°åˆ©ç”¨Transformerçš„å†…åœ¨ä¼˜åŠ¿ï¼Œå®ç°æ€§èƒ½çªç ´ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬çŸ­å·ç§¯å±‚çš„å‚æ•°è®¾ç½®ä»¥æ•æ‰å±€éƒ¨æ¨¡å¼ï¼Œæˆªæ–­åå‘ä¼ æ’­ç”¨äºå‡å°‘è®¡ç®—å¼€é”€å’Œæ¢¯åº¦é—®é¢˜ï¼Œç½‘ç»œç»“æ„ä¿æŒTransformeråŸºç¡€ï¼Œä½†é€šè¿‡å¢å¼ºç»„ä»¶æå‡éçº¿æ€§è¡¨è¾¾èƒ½åŠ›ï¼ŒæŸå¤±å‡½æ•°åŸºäºä»»åŠ¡ç›®æ ‡ï¼ˆå¦‚åˆ†ç±»æˆ–åºåˆ—é¢„æµ‹ï¼‰è¿›è¡Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

æœ€é‡è¦çš„å®éªŒç»“æœæ˜¯åœ¨ARC-AGIåŸºå‡†ä¸Šå®ç°æ˜¾è‘—æ€§èƒ½æå‡ï¼šåœ¨ARC-AGI 1ä¸Šè¾¾åˆ°53.8% pass@1ï¼Œåœ¨ARC-AGI 2ä¸Šè¾¾åˆ°16.0% pass@1ï¼Œå¯¹æ¯”åŸºçº¿é€šç”¨Transformerå’Œå…¶ä»–å˜ä½“ï¼Œæå‡å¹…åº¦æ˜æ˜¾ï¼Œç¡®ç«‹äº†æœ€å…ˆè¿›æ°´å¹³ï¼ŒéªŒè¯äº†çŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡å¦‚ARC-AGIå’Œæ•°ç‹¬ä¸­å…·æœ‰ç›´æ¥åº”ç”¨ä»·å€¼ï¼Œå¯æ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨æŠ½è±¡æ¨ç†å’Œé—®é¢˜è§£å†³é¢†åŸŸçš„å‘å±•ã€‚æ½œåœ¨åº”ç”¨åŒ…æ‹¬æ™ºèƒ½æ•™è‚²ç³»ç»Ÿã€è‡ªåŠ¨åŒ–é€»è¾‘æµ‹è¯•å’Œé€šç”¨AIåŸºå‡†è¯„ä¼°ï¼Œæœªæ¥å¯èƒ½å½±å“æ›´å¹¿æ³›çš„è®¤çŸ¥è®¡ç®—å’Œæœºå™¨äººå†³ç­–ç³»ç»Ÿã€‚
=======
**å…³é”®è¯**: `é€šç”¨æ¨ç†æ¨¡å‹` `Transformeræ¶æ„` `å¤æ‚æ¨ç†ä»»åŠ¡` `ARC-AGIåŸºå‡†` `çŸ­å·ç§¯` `æˆªæ–­åå‘ä¼ æ’­` `å½’çº³åç½®` `éçº¿æ€§ç»„ä»¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é€šç”¨Transformeråœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­æ€§èƒ½æå‡æ¥æºä¸æ˜ç¡®ï¼Œé™åˆ¶äº†è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
2. æå‡ºURMæ¨¡å‹ï¼Œé€šè¿‡çŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­å¢å¼ºé€šç”¨Transformerçš„æ¨ç†èƒ½åŠ›ã€‚
3. åœ¨ARC-AGIåŸºå‡†ä¸Šå–å¾—æ˜¾è‘—æå‡ï¼Œè¾¾åˆ°æœ€å…ˆè¿›æ°´å¹³ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€šç”¨Transformerï¼ˆUTï¼‰å·²è¢«å¹¿æ³›åº”ç”¨äºARC-AGIå’Œæ•°ç‹¬ç­‰å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œä½†å…¶æ€§èƒ½æå‡çš„å…·ä½“æ¥æºå°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬ç ”ç©¶ç³»ç»Ÿåˆ†æäº†UTçš„å˜ä½“ï¼Œå‘ç°ARC-AGIä¸Šçš„æ”¹è¿›ä¸»è¦æºäºTransformerçš„å¾ªç¯å½’çº³åç½®å’Œå¼ºéçº¿æ€§ç»„ä»¶ï¼Œè€Œéå¤æ‚çš„æ¶æ„è®¾è®¡ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†é€šç”¨æ¨ç†æ¨¡å‹ï¼ˆURMï¼‰ï¼Œé€šè¿‡å¼•å…¥çŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­æ¥å¢å¼ºUTã€‚è¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†æ¨ç†æ€§èƒ½ï¼Œåœ¨ARC-AGI 1ä¸Šè¾¾åˆ°äº†53.8%çš„pass@1ï¼Œåœ¨ARC-AGI 2ä¸Šè¾¾åˆ°äº†16.0%çš„pass@1ï¼Œå®ç°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚ä»£ç å·²å¼€æºï¼šhttps://github.com/zitian-gao/URMã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

é€šç”¨æ¨ç†æ¨¡å‹ï¼ˆURMï¼‰åŸºäºé€šç”¨Transformerï¼ˆUTï¼‰æ¡†æ¶è¿›è¡Œæ”¹è¿›ã€‚æ•´ä½“æ¡†æ¶ä¿ç•™äº†UTçš„å¾ªç¯å½’çº³åç½®å’Œå¼ºéçº¿æ€§ç»„ä»¶ï¼Œè¿™æ˜¯æ€§èƒ½æå‡çš„å…³é”®åŸºç¡€ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åŒ…æ‹¬å¼•å…¥çŸ­å·ç§¯æ¨¡å—æ¥å¢å¼ºå±€éƒ¨ç‰¹å¾æå–èƒ½åŠ›ï¼Œä»¥åŠé‡‡ç”¨æˆªæ–­åå‘ä¼ æ’­æŠ€æœ¯æ¥ä¼˜åŒ–è®­ç»ƒæ•ˆç‡å’Œç¨³å®šæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼ŒURMä¸ä¾èµ–å¤æ‚çš„æ¶æ„è®¾è®¡ï¼Œè€Œæ˜¯é€šè¿‡ç®€å•æœ‰æ•ˆçš„å¢å¼ºæ‰‹æ®µï¼Œç›´æ¥é’ˆå¯¹æ¨ç†ä»»åŠ¡çš„æ ¸å¿ƒéœ€æ±‚è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œåœ¨ä¿æŒæ¨¡å‹ç®€æ´æ€§çš„åŒæ—¶å¤§å¹…æå‡æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

URMåœ¨ARC-AGIåŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›æ€§èƒ½ï¼šARC-AGI 1è¾¾åˆ°53.8% pass@1ï¼ŒARC-AGI 2è¾¾åˆ°16.0% pass@1ã€‚ç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼ŒéªŒè¯äº†çŸ­å·ç§¯å’Œæˆªæ–­åå‘ä¼ æ’­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¤æ‚æ¨ç†ä»»åŠ¡æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºå¤æ‚æ¨ç†ä»»åŠ¡ï¼Œå¦‚æŠ½è±¡æ¨ç†ï¼ˆARC-AGIï¼‰ã€é€»è¾‘è°œé¢˜ï¼ˆå¦‚æ•°ç‹¬ï¼‰å’Œéœ€è¦é«˜çº§è®¤çŸ¥èƒ½åŠ›çš„AIç³»ç»Ÿã€‚æ½œåœ¨ä»·å€¼åŒ…æ‹¬æ¨åŠ¨é€šç”¨äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œæå‡æ¨¡å‹åœ¨å°‘æ ·æœ¬æˆ–é›¶æ ·æœ¬åœºæ™¯ä¸‹çš„æ¨ç†èƒ½åŠ›ï¼Œä¸ºæ•™è‚²ã€æ¸¸æˆå’Œè‡ªåŠ¨åŒ–å†³ç­–ç­‰é¢†åŸŸæä¾›æŠ€æœ¯æ”¯æŒã€‚
>>>>>>> 1c05e1c356e1f28c2e5e6e14cf6811c0d5120ab7

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Universal transformers (UTs) have been widely used for complex reasoning tasks such as ARC-AGI and Sudoku, yet the specific sources of their performance gains remain underexplored. In this work, we systematically analyze UTs variants and show that improvements on ARC-AGI primarily arise from the recurrent inductive bias and strong nonlinear components of Transformer, rather than from elaborate architectural designs. Motivated by this finding, we propose the Universal Reasoning Model (URM), which enhances the UT with short convolution and truncated backpropagation. Our approach substantially improves reasoning performance, achieving state-of-the-art 53.8% pass@1 on ARC-AGI 1 and 16.0% pass@1 on ARC-AGI 2. Our code is avaliable at https://github.com/zitian-gao/URM.

