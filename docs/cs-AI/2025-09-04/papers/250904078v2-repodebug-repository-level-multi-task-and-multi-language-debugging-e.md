---
layout: default
title: RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models
---

# RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04078" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04078v2</a>
  <a href="https://arxiv.org/pdf/2509.04078.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04078v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04078v2', 'RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jingjing Liu, Zeming Liu, Zihao Cheng, Mengliang He, Xiaoming Shi, Yuhang Guo, Xiangrong Zhu, Yuanfang Guo, Yunhong Wang, Haifeng Wang

**åˆ†ç±»**: cs.SE, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04 (æ›´æ–°: 2025-09-08)

**å¤‡æ³¨**: 30 pages, 12 figures, EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RepoDebugï¼šç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä»“åº“çº§å¤šä»»åŠ¡å¤šè¯­è¨€è°ƒè¯•èƒ½åŠ›çš„æ•°æ®é›†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»£ç è°ƒè¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»“åº“çº§è°ƒè¯•` `å¤šä»»åŠ¡å­¦ä¹ ` `å¤šè¯­è¨€æ”¯æŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä»£ç è°ƒè¯•æ•°æ®é›†ä¸»è¦å…³æ³¨å‡½æ•°çº§åˆ«ï¼Œå¿½ç•¥äº†å®é™…åº”ç”¨ä¸­æ›´å¤æ‚çš„ä»“åº“çº§åˆ«åœºæ™¯ï¼Œå¯¼è‡´å¯¹LLMè°ƒè¯•èƒ½åŠ›çš„è¯„ä¼°ä¸å®Œæ•´ã€‚
2. RepoDebugæ•°æ®é›†æ—¨åœ¨æä¾›ä¸€ä¸ªæ›´å…¨é¢ã€æ›´çœŸå®çš„ä»“åº“çº§ä»£ç è°ƒè¯•è¯„ä¼°å¹³å°ï¼Œæ”¯æŒå¤šä»»åŠ¡ã€å¤šè¯­è¨€å’Œå¤šç§é”™è¯¯ç±»å‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯å½“å‰è¡¨ç°æœ€ä½³çš„LLMï¼Œåœ¨RepoDebugæ•°æ®é›†ä¸Šçš„ä»“åº“çº§è°ƒè¯•èƒ½åŠ›ä»ç„¶æœ‰å¾…æé«˜ï¼Œæ­ç¤ºäº†è¯¥é¢†åŸŸçš„æŒ‘æˆ˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç è°ƒè¯•æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„ç†Ÿç»ƒåº¦ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨ç¨‹åºä¿®å¤æ–¹é¢ï¼Œè¿™å¯ä»¥å¤§å¤§å‡å°‘å¼€å‘äººå‘˜çš„æ—¶é—´æ¶ˆè€—å¹¶æé«˜ä»–ä»¬çš„æ•ˆç‡ã€‚ä¸ºäº†ä¿ƒè¿›ä»£ç è°ƒè¯•çš„å‘å±•ï¼Œè°ƒè¯•æ•°æ®é›†å–å¾—äº†æ˜¾è‘—çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ•°æ®é›†ä¸»è¦ä¾§é‡äºè¯„ä¼°LLMçš„å‡½æ•°çº§ä»£ç ä¿®å¤èƒ½åŠ›ï¼Œè€Œå¿½ç•¥äº†æ›´å¤æ‚å’ŒçœŸå®çš„ä»“åº“çº§åœºæ™¯ï¼Œè¿™å¯¼è‡´å¯¹LLMåœ¨ä»“åº“çº§è°ƒè¯•ä¸­é¢ä¸´çš„æŒ‘æˆ˜çš„ç†è§£ä¸å®Œæ•´ã€‚è™½ç„¶å·²ç»æå‡ºäº†ä¸€äº›ä»“åº“çº§æ•°æ®é›†ï¼Œä½†å®ƒä»¬é€šå¸¸å—åˆ°ä»»åŠ¡ã€è¯­è¨€å’Œé”™è¯¯ç±»å‹å¤šæ ·æ€§æœ‰é™ç­‰é™åˆ¶ã€‚ä¸ºäº†ç¼“è§£è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡ä»‹ç»RepoDebugï¼Œä¸€ä¸ªå¤šä»»åŠ¡å’Œå¤šè¯­è¨€ä»“åº“çº§ä»£ç è°ƒè¯•æ•°æ®é›†ï¼ŒåŒ…å«22ç§é”™è¯¯äºšå‹ï¼Œæ”¯æŒ8ç§å¸¸ç”¨çš„ç¼–ç¨‹è¯­è¨€å’Œ3ç§è°ƒè¯•ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹10ä¸ªLLMè¿›è¡Œäº†è¯„ä¼°å®éªŒï¼Œå…¶ä¸­è¡¨ç°æœ€ä½³çš„æ¨¡å‹Claude 3.5 Sonnectåœ¨ä»“åº“çº§è°ƒè¯•ä¸­ä»ç„¶è¡¨ç°ä¸ä½³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ä»£ç è°ƒè¯•æ•°æ®é›†ä¸»è¦é›†ä¸­åœ¨å‡½æ•°çº§åˆ«ï¼Œç¼ºä¹å¯¹ä»“åº“çº§åˆ«å¤æ‚åœºæ™¯çš„è¦†ç›–ã€‚è¿™äº›æ•°æ®é›†åœ¨ä»»åŠ¡ç±»å‹ã€æ”¯æŒè¯­è¨€å’Œé”™è¯¯ç±»å‹æ–¹é¢å­˜åœ¨å±€é™æ€§ï¼Œæ— æ³•å…¨é¢è¯„ä¼°LLMåœ¨å®é™…è½¯ä»¶å¼€å‘ä¸­çš„è°ƒè¯•èƒ½åŠ›ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ä¸ªæ›´å…¨é¢ã€æ›´çœŸå®çš„ä»“åº“çº§è°ƒè¯•æ•°æ®é›†ï¼Œä»¥æ¨åŠ¨LLMåœ¨è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRepoDebugçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå¤šä»»åŠ¡ã€å¤šè¯­è¨€çš„ä»“åº“çº§ä»£ç è°ƒè¯•æ•°æ®é›†ï¼ŒåŒ…å«å¤šç§é”™è¯¯ç±»å‹ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„è½¯ä»¶å¼€å‘åœºæ™¯ã€‚é€šè¿‡åœ¨è¯¥æ•°æ®é›†ä¸Šè¯„ä¼°LLMçš„è°ƒè¯•èƒ½åŠ›ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°äº†è§£LLMåœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›åŸºå‡†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRepoDebugæ•°æ®é›†åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼š1) å¤šç§ç¼–ç¨‹è¯­è¨€çš„æ”¯æŒï¼ˆ8ç§å¸¸ç”¨è¯­è¨€ï¼‰ï¼›2) å¤šç§è°ƒè¯•ä»»åŠ¡çš„æ”¯æŒï¼ˆ3ç§è°ƒè¯•ä»»åŠ¡ï¼‰ï¼›3) ä¸°å¯Œçš„é”™è¯¯ç±»å‹ï¼ˆ22ç§é”™è¯¯äºšå‹ï¼‰ï¼›4) ä»“åº“çº§åˆ«çš„ä»£ç ç»“æ„ã€‚è¯¥æ•°æ®é›†çš„è®¾è®¡æ—¨åœ¨æ¨¡æ‹ŸçœŸå®çš„è½¯ä»¶å¼€å‘ç¯å¢ƒï¼Œå¹¶æä¾›å¤šæ ·åŒ–çš„è°ƒè¯•åœºæ™¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šRepoDebugçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å…¨é¢æ€§å’ŒçœŸå®æ€§ã€‚ä¸ç°æœ‰çš„ä»£ç è°ƒè¯•æ•°æ®é›†ç›¸æ¯”ï¼ŒRepoDebugæ›´å…³æ³¨ä»“åº“çº§åˆ«çš„è°ƒè¯•ï¼Œæ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ã€è°ƒè¯•ä»»åŠ¡å’Œé”™è¯¯ç±»å‹ã€‚è¿™ä½¿å¾—RepoDebugèƒ½å¤Ÿæ›´å‡†ç¡®åœ°è¯„ä¼°LLMåœ¨å®é™…è½¯ä»¶å¼€å‘ä¸­çš„è°ƒè¯•èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šRepoDebugæ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ä¸­ï¼Œå…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š1) é”™è¯¯ç±»å‹çš„é€‰æ‹©ï¼Œæ¶µç›–äº†å¸¸è§çš„è½¯ä»¶ç¼ºé™·ï¼›2) ç¼–ç¨‹è¯­è¨€çš„é€‰æ‹©ï¼Œè¦†ç›–äº†å¹¿æ³›ä½¿ç”¨çš„ç¼–ç¨‹è¯­è¨€ï¼›3) è°ƒè¯•ä»»åŠ¡çš„è®¾è®¡ï¼Œæ¨¡æ‹Ÿäº†çœŸå®çš„è°ƒè¯•æµç¨‹ï¼›4) æ•°æ®é›†çš„è§„æ¨¡ï¼Œä¿è¯äº†è¯„ä¼°çš„å¯é æ€§ã€‚æ­¤å¤–ï¼ŒRepoDebugè¿˜æä¾›äº†è¯¦ç»†çš„æ–‡æ¡£å’Œè¯„ä¼°å·¥å…·ï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜ä½¿ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å¯¹10ä¸ªLLMåœ¨RepoDebugæ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€ä½³çš„Claude 3.5 Sonnectæ¨¡å‹ï¼Œåœ¨ä»“åº“çº§è°ƒè¯•ä»»åŠ¡ä¸­ä»ç„¶è¡¨ç°ä¸ä½³ã€‚è¿™è¡¨æ˜å½“å‰LLMåœ¨å¤„ç†å¤æ‚çš„ä»“åº“çº§ä»£ç è°ƒè¯•é—®é¢˜æ—¶ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ˜ç¡®çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RepoDebugæ•°æ®é›†å¯ç”¨äºè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒLLMåœ¨ä»“åº“çº§ä»£ç è°ƒè¯•æ–¹é¢çš„èƒ½åŠ›ï¼Œæ¨åŠ¨è‡ªåŠ¨ç¨‹åºä¿®å¤æŠ€æœ¯çš„å‘å±•ã€‚è¯¥æ•°æ®é›†è¿˜å¯ä»¥ç”¨äºè®­ç»ƒå’Œä¼˜åŒ–LLMï¼Œæé«˜å…¶åœ¨å®é™…è½¯ä»¶å¼€å‘ä¸­çš„è°ƒè¯•æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒRepoDebugå¯ä»¥å¸®åŠ©å¼€å‘äººå‘˜æ›´å¥½åœ°äº†è§£LLMçš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMæ¥è¾…åŠ©è½¯ä»¶å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have exhibited significant proficiency in code debugging, especially in automatic program repair, which may substantially reduce the time consumption of developers and enhance their efficiency. Significant advancements in debugging datasets have been made to promote the development of code debugging. However, these datasets primarily focus on assessing the LLM's function-level code repair capabilities, neglecting the more complex and realistic repository-level scenarios, which leads to an incomplete understanding of the LLM's challenges in repository-level debugging. While several repository-level datasets have been proposed, they often suffer from limitations such as limited diversity of tasks, languages, and error types. To mitigate this challenge, this paper introduces RepoDebug, a multi-task and multi-language repository-level code debugging dataset with 22 subtypes of errors that supports 8 commonly used programming languages and 3 debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs, where Claude 3.5 Sonnect, the best-performing model, still cannot perform well in repository-level debugging.

