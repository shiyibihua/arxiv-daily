---
layout: default
title: The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements
---

# The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22419" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22419v2</a>
  <a href="https://arxiv.org/pdf/2506.22419.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22419v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22419v2', 'The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bingchen Zhao, Despoina Magka, Minqi Jiang, Xian Li, Roberta Raileanu, Tatiana Shavrina, Jean-Christophe Gagnon-Audet, Kelvin Niu, Shagun Sodhani, Michael Shvartsman, Andrei Lupu, Alisia Lupidi, Edan Toledo, Karen Hambardzumyan, Martin Josifoski, Thomas Foster, Lucia Cipolina-Kun, Abhishek Charnalia, Derek Dunfield, Alexander H. Miller, Oisin Mac Aodha, Jakob Foerster, Yoram Bachrach

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27 (æ›´æ–°: 2025-06-30)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨åŒ–LLMé€Ÿåº¦ç«èµ›åŸºå‡†ä»¥è§£å†³ç§‘å­¦é‡ç°æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ç§‘å­¦é‡ç°æ€§` `è‡ªåŠ¨åŒ–åŸºå‡†` `NanoGPT` `AIä»£ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„AIä»£ç†åœ¨é‡ç°ç§‘å­¦ç ”ç©¶æˆæœæ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚çš„ç ”ç©¶é¢†åŸŸä¸­ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šè®ºæ–‡æå‡ºäº†è‡ªåŠ¨åŒ–LLMé€Ÿåº¦ç«èµ›åŸºå‡†ï¼Œé€šè¿‡19ä¸ªä»»åŠ¡è¯„ä¼°AIä»£ç†çš„é‡ç°èƒ½åŠ›ï¼Œç»“åˆå¤šç§æç¤ºæ ¼å¼ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶å‘ç°ï¼Œå°½ç®¡æä¾›è¯¦ç»†æç¤ºï¼Œç°æœ‰LLMsåœ¨é‡ç°å·²çŸ¥åˆ›æ–°æ—¶è¡¨ç°ä¸ä½³ï¼Œæ˜¾ç¤ºå‡ºè¯¥é¢†åŸŸçš„ç ”ç©¶ç©ºç™½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¿«é€Ÿè¿›å±•æœ‰åŠ©äºç§‘å­¦è¿›æ­¥ï¼Œè€Œé‡ç°å·²æœ‰ç ”ç©¶æˆæœçš„èƒ½åŠ›æ˜¯å…³é”®ã€‚æœ¬æ–‡å¼•å…¥äº†è‡ªåŠ¨åŒ–LLMé€Ÿåº¦ç«èµ›åŸºå‡†ï¼ŒåŸºäºNanoGPTé€Ÿåº¦ç«èµ›çš„è´¡çŒ®ï¼Œè¯„ä¼°AIä»£ç†åœ¨æ´»è·ƒç ”ç©¶é¢†åŸŸé‡ç°ç»“æœçš„èƒ½åŠ›ã€‚19ä¸ªé€Ÿåº¦ç«èµ›ä»»åŠ¡ä¸ºä»£ç†æä¾›äº†å…ˆå‰è®°å½•çš„è®­ç»ƒè„šæœ¬ï¼Œå¹¶å¯é€‰æ‹©æ€§åœ°é…å¯¹ä¸‰ç§æç¤ºæ ¼å¼ã€‚è®°å½•è®¾è®¡ä¸ºå¿«é€Ÿæ‰§è¡Œï¼Œé€Ÿåº¦ç«èµ›çš„æ”¹è¿›æ¶µç›–äº†ä»é«˜å±‚ç®—æ³•åˆ°ç¡¬ä»¶ä¼˜åŒ–çš„å¤šæ ·åŒ–ä»£ç çº§å˜åŒ–ã€‚ç ”ç©¶å‘ç°ï¼Œå°½ç®¡æä¾›è¯¦ç»†æç¤ºï¼Œè¿‘æœŸçš„æ¨ç†LLMsç»“åˆæœ€å…ˆè¿›çš„æ¡†æ¶åœ¨é‡ç°å·²çŸ¥åˆ›æ–°æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚è¯¥åŸºå‡†ä¸ºè¯„ä¼°LLMsè‡ªåŠ¨åŒ–ç§‘å­¦é‡ç°èƒ½åŠ›æä¾›äº†ç®€å•ä¸”æœ‰æ•ˆçš„åº¦é‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³AIä»£ç†åœ¨ç§‘å­¦ç ”ç©¶ä¸­é‡ç°å·²æœ‰æˆæœçš„èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤æ‚çš„ç ”ç©¶ä»»åŠ¡ä¸­ï¼Œå°¤å…¶æ˜¯æ¶‰åŠå¤šç§ç®—æ³•å’Œä¼˜åŒ–æ—¶ï¼Œè¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥è‡ªåŠ¨åŒ–LLMé€Ÿåº¦ç«èµ›åŸºå‡†ï¼Œåˆ©ç”¨å·²æœ‰çš„NanoGPTé€Ÿåº¦ç«èµ›æˆæœï¼Œè¯„ä¼°AIä»£ç†åœ¨é‡ç°ç ”ç©¶ç»“æœæ–¹é¢çš„èƒ½åŠ›ã€‚è®¾è®¡ä¸Šï¼ŒåŸºå‡†ä»»åŠ¡ç»“åˆäº†å¤šç§æç¤ºæ ¼å¼ï¼Œä»¥å¸®åŠ©ä»£ç†æ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬19ä¸ªé€Ÿåº¦ç«èµ›ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡æä¾›å…ˆå‰çš„è®­ç»ƒè®°å½•å’Œå¯é€‰çš„æç¤ºæ ¼å¼ã€‚ä»»åŠ¡è®¾è®¡ä¸ºå¿«é€Ÿæ‰§è¡Œï¼Œæ¶µç›–äº†ä»ç®—æ³•åˆ°ç¡¬ä»¶ä¼˜åŒ–çš„å¤šæ ·åŒ–æ”¹è¿›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªç®€å•ä¸”éé¥±å’Œçš„åŸºå‡†ï¼Œä¸“æ³¨äºè¯„ä¼°LLMsåœ¨ç§‘å­¦é‡ç°ä¸­çš„è‡ªåŠ¨åŒ–èƒ½åŠ›ï¼Œè¿™ä¸ç°æœ‰çš„é‡ç°æ€§è¯„ä¼°æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œä»»åŠ¡çš„æç¤ºæ ¼å¼åŒ…æ‹¬ä¼ªä»£ç å’Œè®ºæ–‡å¼æè¿°ï¼Œæ—¨åœ¨æä¾›è¶³å¤Ÿçš„ä¿¡æ¯ä»¥å¸®åŠ©ä»£ç†ç†è§£ä»»åŠ¡ï¼ŒåŒæ—¶ä¿æŒä»»åŠ¡çš„å¤šæ ·æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æä¾›äº†è¯¦ç»†çš„æç¤ºï¼Œç°æœ‰çš„æ¨ç†LLMsåœ¨é‡ç°å·²çŸ¥åˆ›æ–°æ–¹é¢ä»ç„¶é¢ä¸´å›°éš¾ã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†å½“å‰æŠ€æœ¯åœ¨ç§‘å­¦é‡ç°æ€§ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç§‘å­¦ç ”ç©¶ã€æ•™è‚²å’ŒAIè¾…åŠ©çš„è‡ªåŠ¨åŒ–å®éªŒå®¤ã€‚é€šè¿‡æé«˜AIåœ¨é‡ç°æ€§æ–¹é¢çš„èƒ½åŠ›ï¼Œå¯ä»¥åŠ é€Ÿç§‘å­¦å‘ç°å’ŒæŠ€æœ¯åˆ›æ–°ï¼Œæ¨åŠ¨å„é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Rapid advancements in large language models (LLMs) have the potential to assist in scientific progress. A critical capability toward this endeavor is the ability to reproduce existing work. To evaluate the ability of AI agents to reproduce results in an active research area, we introduce the Automated LLM Speedrunning Benchmark, leveraging the research community contributions on the NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time. Each of the 19 speedrun tasks provides the agent with the previous records training script, optionally paired with one of three hint formats, ranging from pseudocode to paper-like descriptions of the new records improvements. Records execute quickly by design and speedrun improvements encompass diverse code-level changes, ranging from high-level algorithmic advancements to hardware-aware optimizations. These features make the benchmark both accessible and realistic for the frontier problem of improving LLM training. We find that recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement already-known innovations in our benchmark, even when given detailed hints. Our benchmark thus provides a simple, non-saturated measure of an LLMs ability to automate scientific reproduction, a necessary (but not sufficient) skill for an autonomous research agent.

