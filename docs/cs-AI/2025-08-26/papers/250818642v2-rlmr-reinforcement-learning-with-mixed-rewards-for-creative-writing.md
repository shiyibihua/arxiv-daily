---
layout: default
title: RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing
---

# RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18642" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.18642v2</a>
  <a href="https://arxiv.org/pdf/2508.18642.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18642v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18642v2', 'RLMR: Reinforcement Learning with Mixed Rewards for Creative Writing')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jianxing Liao, Tian Zhang, Xiao Feng, Yusong Zhang, Rui Yang, Haorui Wang, Bosi Wen, Ziying Wang, Runzhi Shi

**ÂàÜÁ±ª**: cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-26 (Êõ¥Êñ∞: 2025-08-28)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫RLMR‰ª•Ëß£ÂÜ≥ÂàõÊÑèÂÜô‰Ωú‰∏≠ÁöÑ‰∏ªËßÇ‰∏éÂÆ¢ËßÇÂπ≥Ë°°ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂàõÊÑèÂÜô‰Ωú` `Âº∫ÂåñÂ≠¶‰π†` `Ê∑∑ÂêàÂ•ñÂä±` `‰∏ªËßÇËØÑ‰º∞` `ÂÆ¢ËßÇÁ∫¶Êùü` `Ëá™Âä®ÂåñËØÑ‰º∞` `ËØ≠Ë®ÄÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ÂàõÊÑèÂÜô‰Ωú‰∏≠Èöæ‰ª•Âπ≥Ë°°‰∏ªËßÇË¥®Èáè‰∏éÂÆ¢ËßÇÁ∫¶ÊùüÔºåÂØºËá¥ÊïàÊûú‰∏ç‰Ω≥„ÄÇ
2. ÊèêÂá∫RLMRÔºåÈÄöËøáÂä®ÊÄÅÊ∑∑ÂêàÂ•ñÂä±Á≥ªÁªüÁªìÂêà‰∏ªËßÇ‰∏éÂÆ¢ËßÇËØÑ‰º∞Ôºå‰ºòÂåñÂÜô‰ΩúË¥®Èáè‰∏éÁ∫¶ÊùüÈÅµÂæ™„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåRLMRÂú®Êåá‰ª§ÈÅµÂæ™ÂíåÂÜô‰ΩúË¥®Èáè‰∏äÂùáÊúâÊòæËëóÊèêÂçáÔºåÊâãÂä®ËØÑ‰º∞‰∏≠ËÉúÁéáËææÂà∞72.75%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂú®ÂàõÊÑèÂÜô‰ΩúÂ∫îÁî®‰∏≠Ë¢´ÂπøÊ≥õ‰ΩøÁî®„ÄÇÂàõÊÑèÂÜô‰ΩúÈúÄË¶ÅÂú®‰∏ªËßÇÂÜô‰ΩúË¥®ÈáèÔºàÂ¶ÇÊñáÂ≠¶ÊÄßÂíåÊÉÖÊÑüË°®ËææÔºâ‰∏éÂÆ¢ËßÇÁ∫¶ÊùüÈÅµÂæ™ÔºàÂ¶ÇÊ†ºÂºèË¶ÅÊ±ÇÂíåÂ≠óÊï∞ÈôêÂà∂Ôºâ‰πãÈó¥ÂèñÂæóÂπ≥Ë°°„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÂêåÊó∂ÊèêÂçáËøô‰∏§ÊñπÈù¢ÔºöÂçï‰∏ÄÂ•ñÂä±Á≠ñÁï•Êó†Ê≥ïÂêåÊó∂ÊîπÂñÑ‰∏§ÁßçËÉΩÂäõÔºåËÄåÂõ∫ÂÆöÊùÉÈáçÁöÑÊ∑∑ÂêàÂ•ñÂä±ÊñπÊ≥ïÁº∫‰πèÈÄÇÂ∫î‰∏çÂêåÂÜô‰ΩúÂú∫ÊôØÁöÑËÉΩÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊ∑∑ÂêàÂ•ñÂä±Âº∫ÂåñÂ≠¶‰π†ÔºàRLMRÔºâÔºåÂà©Áî®Âä®ÊÄÅÊ∑∑ÂêàÂ•ñÂä±Á≥ªÁªüÔºåÁªìÂêàËØÑ‰º∞‰∏ªËßÇÂÜô‰ΩúË¥®ÈáèÁöÑÂÜô‰ΩúÂ•ñÂä±Ê®°ÂûãÂíåËØÑ‰º∞ÂÆ¢ËßÇÁ∫¶ÊùüÈÅµÂæ™ÁöÑÁ∫¶ÊùüÈ™åËØÅÊ®°Âûã„ÄÇÈÄöËøáÂä®ÊÄÅË∞ÉÊï¥Á∫¶ÊùüÈÅµÂæ™Â•ñÂä±ÊùÉÈáçÔºåÁ°Æ‰øùËøùÂèçÁ∫¶ÊùüÁöÑÊ†∑Êú¨Âú®ËÆ≠ÁªÉ‰∏≠ÂèóÂà∞ÊÉ©ÁΩö„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Êåá‰ª§ÈÅµÂæ™ÂíåÂÜô‰ΩúË¥®Èáè‰∏äÂùáÊúâÊòæËëóÊèêÂçá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥ÂàõÊÑèÂÜô‰Ωú‰∏≠‰∏ªËßÇÂÜô‰ΩúË¥®Èáè‰∏éÂÆ¢ËßÇÁ∫¶ÊùüÈÅµÂæ™‰πãÈó¥ÁöÑÂπ≥Ë°°ÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÂêåÊó∂ÊèêÂçáËøô‰∏§ÊñπÈù¢ÁöÑËÉΩÂäõÔºåÂØºËá¥ÂÜô‰ΩúÊïàÊûú‰∏çÁêÜÊÉ≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊàë‰ª¨ÊèêÂá∫ÁöÑRLMRÊñπÊ≥ïÈÄöËøáÂä®ÊÄÅÊ∑∑ÂêàÂ•ñÂä±Á≥ªÁªüÔºåÁªìÂêà‰∏ªËßÇÂÜô‰ΩúË¥®ÈáèËØÑ‰º∞‰∏éÂÆ¢ËßÇÁ∫¶ÊùüÈ™åËØÅÔºåËÉΩÂ§üÊ†πÊçÆÂÜô‰ΩúË¥®ÈáèÂä®ÊÄÅË∞ÉÊï¥Â•ñÂä±ÊùÉÈáçÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Â•ΩÁöÑÂÜô‰ΩúÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöRLMRÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂÜô‰ΩúÂ•ñÂä±Ê®°ÂûãÂíåÁ∫¶ÊùüÈ™åËØÅÊ®°Âûã„ÄÇÂÜô‰ΩúÂ•ñÂä±Ê®°ÂûãËØÑ‰º∞ÊñáÊú¨ÁöÑ‰∏ªËßÇË¥®ÈáèÔºåÁ∫¶ÊùüÈ™åËØÅÊ®°ÂûãÂàôÊ£ÄÊü•ÊñáÊú¨ÊòØÂê¶Á¨¶ÂêàÈ¢ÑËÆæÁöÑÂÆ¢ËßÇÁ∫¶Êùü„ÄÇ‰∏§ËÄÖÁöÑËæìÂá∫ÈÄöËøáÂä®ÊÄÅÊùÉÈáçÁªìÂêàÔºåÂΩ¢ÊàêÊúÄÁªàÁöÑÂ•ñÂä±‰ø°Âè∑„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöRLMRÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÂä®ÊÄÅË∞ÉÊï¥Á∫¶ÊùüÈÅµÂæ™Â•ñÂä±ÊùÉÈáçÔºåÁ°Æ‰øùËøùÂèçÁ∫¶ÊùüÁöÑÊ†∑Êú¨Âú®ËÆ≠ÁªÉ‰∏≠ÂèóÂà∞ÊÉ©ÁΩö„ÄÇËøô‰∏ÄËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®‰∏çÂêåÂÜô‰ΩúÂú∫ÊôØ‰∏≠Ëá™ÈÄÇÂ∫îË∞ÉÊï¥ÔºåÊòæËëóÊèêÂçá‰∫ÜÂÜô‰ΩúË¥®Èáè‰∏éÁ∫¶ÊùüÈÅµÂæ™ÁöÑÂπ≥Ë°°„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠ÔºåÊàë‰ª¨ËÆæËÆ°‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•Âπ≥Ë°°‰∏ªËßÇ‰∏éÂÆ¢ËßÇËØÑ‰º∞ÔºåÂêåÊó∂ÈááÁî®‰∫ÜÂä®ÊÄÅÊùÉÈáçË∞ÉÊï¥Êú∫Âà∂ÔºåÁ°Æ‰øùÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ËÉΩÂ§üÂÆûÊó∂ÂèçÈ¶àÂÜô‰ΩúË¥®ÈáèÁöÑÂèòÂåñ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåRLMRÂú®Êåá‰ª§ÈÅµÂæ™ËØÑ‰º∞‰∏≠‰ªé83.36%ÊèêÂçáËá≥86.65%ÔºåÂú®ÊâãÂä®‰∏ìÂÆ∂ÂØπÊØîËØÑ‰º∞‰∏≠ÔºåÂÜô‰ΩúË¥®ÈáèÁöÑËÉúÁéáËææÂà∞72.75%„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéRLMRÂú®ÂàõÊÑèÂÜô‰Ωú‰ºòÂåñÊñπÈù¢ÁöÑÊòæËëóÊïàÊûú„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ëá™Âä®ÂåñÂàõÊÑèÂÜô‰Ωú„ÄÅÂÜÖÂÆπÁîüÊàêÂíåÊïôËÇ≤Á≠â„ÄÇÈÄöËøá‰ºòÂåñÂÜô‰ΩúË¥®Èáè‰∏éÁ∫¶ÊùüÈÅµÂæ™ÔºåRLMRËÉΩÂ§ü‰∏∫ÂàõÊÑèÂÜô‰ΩúÊèê‰æõÊõ¥È´òÊïàÁöÑÂ∑•ÂÖ∑ÔºåÊèêÂçáÂÜô‰ΩúÊïàÊûúÔºåÂÖ∑ÊúâÂπøÊ≥õÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language models are extensively utilized in creative writing applications. Creative writing requires a balance between subjective writing quality (e.g., literariness and emotional expression) and objective constraint following (e.g., format requirements and word limits). Existing methods find it difficult to balance these two aspects: single reward strategies fail to improve both abilities simultaneously, while fixed-weight mixed-reward methods lack the ability to adapt to different writing scenarios. To address this problem, we propose Reinforcement Learning with Mixed Rewards (RLMR), utilizing a dynamically mixed reward system from a writing reward model evaluating subjective writing quality and a constraint verification model assessing objective constraint following. The constraint following reward weight is adjusted dynamically according to the writing quality within sampled groups, ensuring that samples violating constraints get negative advantage in GRPO and thus penalized during training, which is the key innovation of this proposed method. We conduct automated and manual evaluations across diverse model families from 8B to 72B parameters. Additionally, we construct a real-world writing benchmark named WriteEval for comprehensive evaluation. Results illustrate that our method achieves consistent improvements in both instruction following (IFEval from 83.36% to 86.65%) and writing quality (72.75% win rate in manual expert pairwise evaluations on WriteEval). To the best of our knowledge, RLMR is the first work to combine subjective preferences with objective verification in online RL training, providing an effective solution for multi-dimensional creative writing optimization.

