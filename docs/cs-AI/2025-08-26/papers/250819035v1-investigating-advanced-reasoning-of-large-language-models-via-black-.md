---
layout: default
title: Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction
---

# Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19035" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19035v1</a>
  <a href="https://arxiv.org/pdf/2508.19035.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19035v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19035v1', 'Investigating Advanced Reasoning of Large Language Models via Black-Box Interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Congchi Yin, Tianyi Wu, Yankai Shu, Alex Gu, Yunhan Wang, Jun Shao, Xun Jiang, Piji Li

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé»‘ç®±äº¤äº’è¯„ä¼°èŒƒå¼ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `é»‘ç®±äº¤äº’` `ç»¼åˆæ¨ç†` `è¯„ä¼°èŒƒå¼` `OracleåŸºå‡†` `æ¢ç´¢ç­–ç•¥`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯„ä¼°æ–¹æ³•æ— æ³•å…¨é¢è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹åœ¨äº’åŠ¨ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›çš„å­¤ç«‹è¯„ä¼°ã€‚
2. æœ¬æ–‡æå‡ºé»‘ç®±äº¤äº’è¯„ä¼°èŒƒå¼ï¼Œè¦æ±‚LLMsé€šè¿‡ä¸é»‘ç®±äº¤äº’æ¨æ–­éšè—å‡½æ•°ï¼Œæ•´åˆå¤šç§æ¨ç†æ–¹å¼ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œo3åœ¨å¤§å¤šæ•°ç®€å•é»‘ç®±ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨å›°éš¾ä»»åŠ¡ä¸­ä»å­˜åœ¨æ˜¾è‘—æ€§èƒ½ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰ä»»åŠ¡æ— æ³•æœ‰æ•ˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨äº’åŠ¨æœªçŸ¥ç¯å¢ƒä¸­çš„æ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´æ¼”ç»ã€å½’çº³å’Œæº¯å› æ¨ç†çš„å­¤ç«‹è¯„ä¼°ï¼Œå¿½è§†äº†äººç±»åœ¨çœŸå®ä¸–ç•Œä¸­å‘ç°æ‰€éœ€çš„ç»¼åˆæ¨ç†è¿‡ç¨‹ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è¯„ä¼°èŒƒå¼â€”â€”é»‘ç®±äº¤äº’ï¼Œè¦æ±‚LLMsé€šè¿‡ä¸é»‘ç®±çš„äº¤äº’ï¼Œæ¨æ–­éšè—å‡½æ•°ã€‚æˆ‘ä»¬æ„å»ºäº†åŒ…å«6ç§é»‘ç®±ä»»åŠ¡å’Œ96ä¸ªé»‘ç®±çš„OracleåŸºå‡†ï¼Œè¯„ä¼°äº†19ä¸ªç°ä»£LLMsçš„è¡¨ç°ã€‚ç»“æœæ˜¾ç¤ºï¼Œo3åœ¨6ä¸ªä»»åŠ¡ä¸­æœ‰5ä¸ªæ’åç¬¬ä¸€ï¼Œä½†åœ¨ä¸€äº›å›°éš¾ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå¹³å‡å‡†ç¡®ç‡ä½äº40%ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒLLMsæ™®éç¼ºä¹é«˜æ°´å¹³çš„è§„åˆ’èƒ½åŠ›ï¼Œæ— æ³•æœ‰æ•ˆåˆ¶å®šå‡è®¾ç»†åŒ–çš„æ¢ç´¢ç­–ç•¥ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æ—¶çš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯åœ¨äº’åŠ¨æœªçŸ¥ç¯å¢ƒä¸­çš„ç»¼åˆæ¨ç†è¯„ä¼°ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥é»‘ç®±äº¤äº’çš„è¯„ä¼°èŒƒå¼ï¼ŒLLMséœ€è¦åœ¨ç»™å®šçš„æ¢ç´¢å›åˆä¸­ä¸é»‘ç®±äº¤äº’ï¼Œæ¨æ–­éšè—çš„è¾“å…¥-è¾“å‡ºæ˜ å°„å…³ç³»ï¼Œä»è€Œå®ç°ç»¼åˆæ¨ç†èƒ½åŠ›çš„è¯„ä¼°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é»‘ç®±å®šä¹‰ã€äº¤äº’è¿‡ç¨‹ã€æ¨ç†è¿‡ç¨‹å’Œè¯„ä¼°æ¨¡å—ã€‚LLMsé€šè¿‡è§‚å¯Ÿè¾“å…¥-è¾“å‡ºå¯¹è¿›è¡Œæ¨ç†ï¼Œé€æ­¥æ­ç¤ºé»‘ç®±çš„éšè—å‡½æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºé»‘ç®±äº¤äº’è¯„ä¼°èŒƒå¼çš„æå‡ºï¼Œå¼ºè°ƒäº†æ¨ç†è¿‡ç¨‹çš„ç»¼åˆæ€§ï¼Œä¸ç°æœ‰å­¤ç«‹è¯„ä¼°æ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾ç½®äº†å¤šç§é»‘ç®±ä»»åŠ¡ï¼Œé‡‡ç”¨ä¸åŒçš„è¾“å…¥-è¾“å‡ºå¯¹è¿›è¡Œè¯„ä¼°ï¼Œè®¾è®¡äº†é€‚åº”æ€§æ¢ç´¢ç­–ç•¥ä»¥æé«˜æ¨ç†æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œo3åœ¨6ä¸ªä»»åŠ¡ä¸­æœ‰5ä¸ªä»»åŠ¡æ’åç¬¬ä¸€ï¼Œåœ¨å¤§å¤šæ•°ç®€å•é»‘ç®±ä»»åŠ¡ä¸­å‡†ç¡®ç‡è¶…è¿‡70%ã€‚ç„¶è€Œï¼Œåœ¨ä¸€äº›å›°éš¾çš„é»‘ç®±ä»»åŠ¡ä¸­ï¼Œo3çš„å¹³å‡è¡¨ç°ä½äº40%ï¼Œæ­ç¤ºäº†LLMsåœ¨é«˜æ°´å¹³è§„åˆ’èƒ½åŠ›ä¸Šçš„æ™®éä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥æ›´å¥½åœ°æ”¯æŒå¤æ‚ä»»åŠ¡çš„å¤„ç†ï¼Œæ¨åŠ¨äººæœºäº¤äº’çš„æ™ºèƒ½åŒ–å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing tasks fall short in evaluating reasoning ability of Large Language Models (LLMs) in an interactive, unknown environment. This deficiency leads to the isolated assessment of deductive, inductive, and abductive reasoning, neglecting the integrated reasoning process that is indispensable for humans discovery of real world. We introduce a novel evaluation paradigm, \textit{black-box interaction}, to tackle this challenge. A black-box is defined by a hidden function that maps a specific set of inputs to outputs. LLMs are required to unravel the hidden function behind the black-box by interacting with it in given exploration turns, and reasoning over observed input-output pairs. Leveraging this idea, we build the \textsc{Oracle} benchmark which comprises 6 types of black-box task and 96 black-boxes. 19 modern LLMs are benchmarked. o3 ranks first in 5 of the 6 tasks, achieving over 70\% accuracy on most easy black-boxes. But it still struggles with some hard black-box tasks, where its average performance drops below 40\%. Further analysis indicates a universal difficulty among LLMs: They lack the high-level planning capability to develop efficient and adaptive exploration strategies for hypothesis refinement.

