---
layout: default
title: Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval
---

# Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18724" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18724v1</a>
  <a href="https://arxiv.org/pdf/2508.18724.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18724v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18724v1', 'Bias Mitigation Agent: Optimizing Source Selection for Fair and Balanced Knowledge Retrieval')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Karanbir Singh, Deepak Muppiri, William Ngu

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

**å¤‡æ³¨**: Accepted at KDD'2025 Agent4IR workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåå·®ç¼“è§£ä»£ç†ä»¥ä¼˜åŒ–çŸ¥è¯†æ£€ç´¢ä¸­çš„æºé€‰æ‹©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åå·®ç¼“è§£` `çŸ¥è¯†æ£€ç´¢` `å¤šä»£ç†ç³»ç»Ÿ` `å…¬å¹³æ€§` `ä¿¡æ¯æºé€‰æ‹©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨çŸ¥è¯†æ£€ç´¢ä¸­å­˜åœ¨åè§é—®é¢˜ï¼Œå½±å“ä¿¡æ¯çš„å…¬å¹³æ€§å’Œç”¨æˆ·ä¿¡ä»»ã€‚
2. æœ¬æ–‡æå‡ºçš„åå·®ç¼“è§£ä»£ç†é€šè¿‡å¤šä»£ç†ç³»ç»Ÿä¼˜åŒ–ä¿¡æ¯æºé€‰æ‹©ï¼Œä»¥å‡å°‘åè§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŸºçº¿ç­–ç•¥åè§å‡å°‘äº†81.82%ï¼Œæ˜¾è‘—æå‡äº†ä¿¡æ¯å…¬å¹³æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸå¼•å‘äº†å˜é©ï¼Œå¼€å¯äº†ç”Ÿæˆåº”ç”¨çš„æ–°çºªå…ƒã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ç»§æ‰¿äº†å†…éƒ¨å’Œå¤–éƒ¨ä¿¡æ¯æºä¸­çš„åè§ï¼Œå½±å“äº†æ£€ç´¢ä¿¡æ¯çš„å…¬å¹³æ€§å’Œå‡è¡¡æ€§ï¼Œé™ä½äº†ç”¨æˆ·ä¿¡ä»»ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å…³é”®æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åå·®ç¼“è§£ä»£ç†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡ä¼˜åŒ–æºé€‰æ‹©æ¥åè°ƒåå·®ç¼“è§£çš„å·¥ä½œæµç¨‹ï¼Œä»è€Œç¡®ä¿æ£€ç´¢å†…å®¹æ—¢é«˜åº¦ç›¸å…³åˆå°½é‡å‡å°‘åè§ï¼Œä»¥ä¿ƒè¿›å…¬å¹³å’Œå‡è¡¡çš„çŸ¥è¯†ä¼ æ’­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿çš„ç®€å•æ£€ç´¢ç­–ç•¥ç›¸æ¯”ï¼Œåè§å‡å°‘äº†81.82%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨çŸ¥è¯†æ£€ç´¢ä¸­ç»§æ‰¿çš„åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä¿¡æ¯æºé€‰æ‹©ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ£€ç´¢ç»“æœçš„å…¬å¹³æ€§å’Œå‡è¡¡æ€§å—åˆ°å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„åå·®ç¼“è§£ä»£ç†é€šè¿‡å¤šä»£ç†ç³»ç»Ÿä¼˜åŒ–ä¿¡æ¯æºé€‰æ‹©ï¼Œæ—¨åœ¨å‡å°‘åè§å¹¶æé«˜ä¿¡æ¯çš„ç›¸å…³æ€§å’Œå…¬å¹³æ€§ã€‚è¯¥è®¾è®¡æ—¨åœ¨é€šè¿‡ä¸“é—¨çš„ä»£ç†åè°ƒåå·®ç¼“è§£å·¥ä½œæµç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªä¸“é—¨çš„ä»£ç†ï¼Œæ¯ä¸ªä»£ç†è´Ÿè´£ä¸åŒçš„ä¿¡æ¯æºé€‰æ‹©å’Œåå·®è¯„ä¼°ã€‚ç³»ç»Ÿé€šè¿‡åä½œæ¥ä¼˜åŒ–æœ€ç»ˆçš„çŸ¥è¯†æ£€ç´¢ç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†å¤šä»£ç†ç³»ç»Ÿæ¥åŠ¨æ€ä¼˜åŒ–ä¿¡æ¯æºé€‰æ‹©ï¼Œä»è€Œæœ‰æ•ˆå‡å°‘åè§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€æ£€ç´¢ç­–ç•¥æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œç³»ç»Ÿè®¾ç½®äº†å¤šä¸ªå‚æ•°ä»¥è¯„ä¼°ä¿¡æ¯æºçš„åè§ç¨‹åº¦ï¼Œå¹¶é‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ£€ç´¢ç»“æœçš„å…¬å¹³æ€§å’Œç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåå·®ç¼“è§£ä»£ç†ç›¸æ¯”åŸºçº¿çš„ç®€å•æ£€ç´¢ç­–ç•¥ï¼Œåè§å‡å°‘äº†81.82%ã€‚è¿™ä¸€æ˜¾è‘—æå‡è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¿ƒè¿›å…¬å¹³å’Œå‡è¡¡çŸ¥è¯†ä¼ æ’­æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨åŒ–ä¿¡æ¯æ£€ç´¢ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå†…å®¹æ¨èç­‰ã€‚é€šè¿‡ä¼˜åŒ–ä¿¡æ¯æºé€‰æ‹©ï¼Œèƒ½å¤Ÿæé«˜ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œç”¨æˆ·ä¿¡ä»»ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have transformed the field of artificial intelligence by unlocking the era of generative applications. Built on top of generative AI capabilities, Agentic AI represents a major shift toward autonomous, goal-driven systems that can reason, retrieve, and act. However, they also inherit the bias present in both internal and external information sources. This significantly affects the fairness and balance of retrieved information, and hence reduces user trust. To address this critical challenge, we introduce a novel Bias Mitigation Agent, a multi-agent system designed to orchestrate the workflow of bias mitigation through specialized agents that optimize the selection of sources to ensure that the retrieved content is both highly relevant and minimally biased to promote fair and balanced knowledge dissemination. The experimental results demonstrate an 81.82\% reduction in bias compared to a baseline naive retrieval strategy.

