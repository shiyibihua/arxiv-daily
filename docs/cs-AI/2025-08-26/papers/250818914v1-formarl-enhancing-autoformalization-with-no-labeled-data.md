---
layout: default
title: FormaRL: Enhancing Autoformalization with no Labeled Data
---

# FormaRL: Enhancing Autoformalization with no Labeled Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18914" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.18914v1</a>
  <a href="https://arxiv.org/pdf/2508.18914.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18914v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18914v1', 'FormaRL: Enhancing Autoformalization with no Labeled Data')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yanxing Huang, Xinling Jin, Sijie Liang, Peng Li, Yang Liu

**ÂàÜÁ±ª**: cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-26

**Â§áÊ≥®**: Conference paper at COLM2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/THUNLP-MT/FormaRL)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FormaRL‰ª•Ëß£ÂÜ≥Ëá™Âä®ÂΩ¢ÂºèÂåñÊï∞ÊçÆÁ®ÄÁº∫ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™Âä®ÂΩ¢ÂºèÂåñ` `Âº∫ÂåñÂ≠¶‰π†` `Êï∞ÊçÆÁ®ÄÁº∫` `ÂΩ¢ÂºèÈ™åËØÅ` `ÂÆöÁêÜËØÅÊòé` `Êï∞Â≠¶ÊïôËÇ≤` `Êó†Ê†áÊ≥®Êï∞ÊçÆ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑËá™Âä®ÂΩ¢ÂºèÂåñÊñπÊ≥ïÂèóÈôê‰∫éÊ†áÊ≥®Êï∞ÊçÆÁöÑÁ®ÄÁº∫ÔºåÂØºËá¥ÂÖ∂ÊÄßËÉΩÊèêÂçáÁºìÊÖ¢„ÄÇ
2. FormaRLÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂà©Áî®Â∞ëÈáèÊú™Ê†áËÆ∞Êï∞ÊçÆËøõË°åËá™Âä®ÂΩ¢ÂºèÂåñÔºåÁªìÂêàËØ≠Ê≥ïÂíå‰∏ÄËá¥ÊÄßÊ£ÄÊü•Êù•‰ºòÂåñËøáÁ®ã„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåFormaRLÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÊòæËëóÊèêÂçá‰∫ÜËá™Âä®ÂΩ¢ÂºèÂåñÁöÑÂáÜÁ°ÆÁéáÔºåÂ∞§ÂÖ∂ÊòØÂú®out-of-distributionÊÄßËÉΩ‰∏äË°®Áé∞‰ºòÂºÇ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëá™Âä®ÂΩ¢ÂºèÂåñÊòØÂΩ¢ÂºèÈ™åËØÅ‰∏≠ÁöÑÊ†∏ÂøÉ‰ªªÂä°Ôºå‰ΩÜÁî±‰∫éÊï∞ÊçÆÁ®ÄÁº∫ÂíåÁº∫‰πèÊúâÊïàÊñπÊ≥ïÔºåÂÖ∂ËøõÂ±ïÂèóÂà∞ÈôêÂà∂„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜFormaRLÔºå‰∏Ä‰∏™ÁÆÄÂçïËÄåÈ´òÊïàÁöÑÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂Ôºå‰ªÖÈúÄÂ∞ëÈáèÊú™Ê†áËÆ∞Êï∞ÊçÆ„ÄÇFormaRLÁªìÂêà‰∫ÜLeanÁºñËØëÂô®ÁöÑËØ≠Ê≥ïÊ£ÄÊü•ÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ÄËá¥ÊÄßÊ£ÄÊü•Êù•ËÆ°ÁÆóÂ•ñÂä±ÔºåÂπ∂ÈááÁî®GRPOÁÆóÊ≥ïÊõ¥Êñ∞ÂΩ¢ÂºèÂåñÂô®„ÄÇÊàë‰ª¨Ëøò‰ªéÊú¨ÁßëÊï∞Â≠¶ÊùêÊñô‰∏≠Êï¥ÁêÜ‰∫Ü‰∏Ä‰∏™Âêç‰∏∫uproofÁöÑËØÅÊòéÈóÆÈ¢òÊï∞ÊçÆÈõÜÔºå‰ª•‰øÉËøõËá™Âä®ÂΩ¢ÂºèÂåñÂíåÈ´òÁ∫ßÊï∞Â≠¶‰∏≠ÁöÑÂÆöÁêÜËØÅÊòéÁöÑÊé¢Á¥¢„ÄÇÂÆûÈ™åË°®ÊòéÔºåFormaRLËÉΩÂ∞ÜQwen2.5-Coder-7B-InstructÁöÑpass@1Ëá™Âä®ÂΩ¢ÂºèÂåñÂáÜÁ°ÆÁéáÊèêÈ´ò4Ëá≥6ÂÄç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËá™Âä®ÂΩ¢ÂºèÂåñ‰ªªÂä°Âú®ÂΩ¢ÂºèÈ™åËØÅ‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜÁé∞ÊúâÊñπÊ≥ï‰æùËµñÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆÔºåÂØºËá¥Êï∞ÊçÆÁ®ÄÁº∫Êó∂ÊÄßËÉΩÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöFormaRLÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Ê°ÜÊû∂ÔºåÂà©Áî®Â∞ëÈáèÊú™Ê†áËÆ∞Êï∞ÊçÆÔºåÁªìÂêàLeanÁºñËØëÂô®ÁöÑËØ≠Ê≥ïÊ£ÄÊü•ÂíåÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑ‰∏ÄËá¥ÊÄßÊ£ÄÊü•Êù•ËÆ°ÁÆóÂ•ñÂä±Ôºå‰ªéËÄå‰ºòÂåñËá™Âä®ÂΩ¢ÂºèÂåñËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFormaRLÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆËæìÂÖ•Ê®°Âùó„ÄÅÂ•ñÂä±ËÆ°ÁÆóÊ®°ÂùóÂíåÂΩ¢ÂºèÂåñÂô®Êõ¥Êñ∞Ê®°Âùó„ÄÇÊï∞ÊçÆËæìÂÖ•Ê®°ÂùóË¥üË¥£Â§ÑÁêÜÊú™Ê†áËÆ∞Êï∞ÊçÆÔºåÂ•ñÂä±ËÆ°ÁÆóÊ®°ÂùóÁªìÂêàËØ≠Ê≥ïÂíå‰∏ÄËá¥ÊÄßÊ£ÄÊü•ÔºåÂΩ¢ÂºèÂåñÂô®Êõ¥Êñ∞Ê®°ÂùóÈááÁî®GRPOÁÆóÊ≥ïËøõË°å‰ºòÂåñ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFormaRLÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂÖ∂ËÉΩÂ§üÂú®Ê≤°ÊúâÊ†áÊ≥®Êï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ÊúâÊïàÊèêÂçáËá™Âä®ÂΩ¢ÂºèÂåñÁöÑÂáÜÁ°ÆÁéáÔºåËøô‰∏é‰º†ÁªüÊñπÊ≥ï‰æùËµñÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆÁöÑÊú¨Ë¥®Âå∫Âà´ÊòæËëó„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåFormaRL‰ΩøÁî®‰∫ÜGRPOÁÆóÊ≥ïËøõË°åÁ≠ñÁï•Êõ¥Êñ∞ÔºåÂ•ñÂä±ÂáΩÊï∞ÁªìÂêà‰∫ÜËØ≠Ê≥ïÂíå‰∏ÄËá¥ÊÄßÊ£ÄÊü•ÁöÑÁªìÊûúÔºåÁ°Æ‰øù‰∫ÜÂΩ¢ÂºèÂåñËøáÁ®ãÁöÑÈ´òÊïàÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåFormaRLÂú®ProofNet‰∏äÂ∞ÜQwen2.5-Coder-7B-InstructÁöÑpass@1ÂáÜÁ°ÆÁéá‰ªé4.04%ÊèêÂçáËá≥26.15%ÔºåÂú®uproof‰∏ä‰ªé2.4%ÊèêÂçáËá≥9.6%„ÄÇÊ≠§Â§ñÔºåFormaRLÂú®out-of-distributionÊÄßËÉΩ‰∏ä‰πüË°®Áé∞Âá∫Ëâ≤Ôºåpass@1ÂáÜÁ°ÆÁéá‰ªé6.2%ÊèêÂçáËá≥9.6%Ôºåpass@16ÂáÜÁ°ÆÁéá‰ªé24.4%ÊèêÂçáËá≥33.6%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂΩ¢ÂºèÈ™åËØÅ„ÄÅËá™Âä®ÂÆöÁêÜËØÅÊòéÂíåÊï∞Â≠¶ÊïôËÇ≤Á≠â„ÄÇÈÄöËøáÊèê‰æõ‰∏ÄÁßçÊó†ÈúÄÂ§ßÈáèÊ†áÊ≥®Êï∞ÊçÆÁöÑËá™Âä®ÂΩ¢ÂºèÂåñÊñπÊ≥ïÔºåFormaRLÂèØ‰ª•Â∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂíåÂºÄÂèëËÄÖÂú®Êõ¥ÂπøÊ≥õÁöÑÊï∞Â≠¶ÈóÆÈ¢ò‰∏äËøõË°åÈ™åËØÅÂíåËØÅÊòéÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Autoformalization is one of the central tasks in formal verification, while its advancement remains hindered due to the data scarcity and the absence efficient methods. In this work we propose \textbf{FormaRL}, a simple yet efficient reinforcement learning framework for autoformalization which only requires a small amount of unlabeled data. FormaRL integrates syntax check from Lean compiler and consistency check from large language model to calculate the reward, and adopts GRPO algorithm to update the formalizer. We also curated a proof problem dataset from undergraduate-level math materials, named \textbf{uproof}, in the hope to facilitate the exploration of autoformalization and theorem proving in advanced math. Experiments show that FormaRL can increase the pass@1 autoformalization accuracy of Qwen2.5-Coder-7B-Instruct by 4 $\sim$ 6x (4.04\% $\to$ 26.15\% on ProofNet and 2.4\% $\to$ 9.6\% on uproof) with merely 859 unlabeled data. And on uproof our method also achieved a strong improvement in out-of-distribution performance compared to existing open-source state-of-the-art autoformalizers on both pass@1 accuracy (6.2\% $\to$ 9.6\%) and pass@16 accuracy (24.4\% $\to$ 33.6\%). Training code of FormaRL is open-sourced at https://github.com/THUNLP-MT/FormaRL.

