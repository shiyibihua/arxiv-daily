---
layout: default
title: VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft
---

# VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18722" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18722v2</a>
  <a href="https://arxiv.org/pdf/2508.18722.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18722v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18722v2', 'VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Honghao Fu, Junlong Ren, Qi Chai, Deheng Ye, Yujun Cai, Hao Wang

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-08-30)

**å¤‡æ³¨**: Accepted by EMNLP 2025 main

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVistaWiseä»¥è§£å†³Minecraftä¸­çŸ¥è¯†ç¼ºä¹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è·¨æ¨¡æ€çŸ¥è¯†å›¾` `ç›®æ ‡æ£€æµ‹` `è™šæ‹Ÿç¯å¢ƒ` `æ™ºèƒ½ä½“` `æˆæœ¬æ•ˆç›Š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è™šæ‹Ÿç¯å¢ƒä¸­ç¼ºä¹é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå¯¼è‡´å¤§å‹è¯­è¨€æ¨¡å‹çš„å†³ç­–æ€§èƒ½å—é™ã€‚
2. VistaWiseé€šè¿‡é›†æˆè·¨æ¨¡æ€çŸ¥è¯†å›¾å’Œå¾®è°ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œæ˜¾è‘—å‡å°‘å¯¹é¢†åŸŸç‰¹å®šè®­ç»ƒæ•°æ®çš„éœ€æ±‚ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºVistaWiseåœ¨å¤šä¸ªå¼€æ”¾ä¸–ç•Œä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæå‡äº†ä»£ç†çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è™šæ‹Ÿå¼€æ”¾ä¸–ç•Œç¯å¢ƒä¸­çš„å†³ç­–ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ã€‚ç„¶è€Œï¼Œç”±äºç¼ºä¹é¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼Œå…¶æ€§èƒ½å—åˆ°é™åˆ¶ã€‚æœ¬æ–‡æå‡ºVistaWiseï¼Œä¸€ä¸ªæˆæœ¬æ•ˆç›Šé«˜çš„ä»£ç†æ¡†æ¶ï¼Œé›†æˆè·¨æ¨¡æ€é¢†åŸŸçŸ¥è¯†ï¼Œå¹¶å¾®è°ƒä¸“ç”¨çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ä»¥è¿›è¡Œè§†è§‰åˆ†æã€‚VistaWiseå°†å¯¹é¢†åŸŸç‰¹å®šè®­ç»ƒæ•°æ®çš„éœ€æ±‚ä»æ•°ç™¾ä¸‡æ ·æœ¬å‡å°‘åˆ°å‡ ç™¾ä¸ªã€‚é€šè¿‡æ„å»ºè·¨æ¨¡æ€çŸ¥è¯†å›¾ï¼ŒVistaWiseèƒ½å¤Ÿå…¨é¢å‡†ç¡®åœ°ç†è§£å¤šæ¨¡æ€ç¯å¢ƒã€‚æ­¤å¤–ï¼Œä»£ç†è¿˜é…å¤‡äº†åŸºäºæ£€ç´¢çš„æ± åŒ–ç­–ç•¥ï¼Œä»çŸ¥è¯†å›¾ä¸­æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯ï¼Œå¹¶é€šè¿‡é¼ æ ‡å’Œé”®ç›˜è¾“å…¥ç›´æ¥æ“ä½œMinecraftæ¡Œé¢å®¢æˆ·ç«¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVistaWiseåœ¨å„ç§å¼€æ”¾ä¸–ç•Œä»»åŠ¡ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶åœ¨é™ä½å¼€å‘æˆæœ¬çš„åŒæ—¶æå‡ä»£ç†æ€§èƒ½çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨Minecraftç­‰è™šæ‹Ÿç¯å¢ƒä¸­å› ç¼ºä¹é¢†åŸŸç‰¹å®šçŸ¥è¯†è€Œå¯¼è‡´çš„å†³ç­–æ€§èƒ½ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦å¤§é‡é¢†åŸŸç‰¹å®šæ•°æ®è¿›è¡Œå¾®è°ƒï¼Œå¼€å‘æˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVistaWiseé€šè¿‡æ„å»ºè·¨æ¨¡æ€çŸ¥è¯†å›¾ï¼Œå°†è§†è§‰ä¿¡æ¯ä¸æ–‡æœ¬ä¾èµ–å…³ç³»ç»“åˆï¼Œå‡å°‘å¯¹é¢†åŸŸç‰¹å®šè®­ç»ƒæ•°æ®çš„éœ€æ±‚ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„çŸ¥è¯†æ•´åˆä¸åº”ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVistaWiseçš„æ•´ä½“æ¶æ„åŒ…æ‹¬çŸ¥è¯†å›¾æ„å»ºæ¨¡å—ã€ç›®æ ‡æ£€æµ‹æ¨¡å‹å¾®è°ƒæ¨¡å—å’ŒåŸºäºæ£€ç´¢çš„æ± åŒ–ç­–ç•¥ã€‚çŸ¥è¯†å›¾ç”¨äºæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œç›®æ ‡æ£€æµ‹æ¨¡å‹è´Ÿè´£è§†è§‰åˆ†æï¼Œè€Œæ± åŒ–ç­–ç•¥åˆ™æå–ä»»åŠ¡ç›¸å…³ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šVistaWiseçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶è·¨æ¨¡æ€çŸ¥è¯†å›¾çš„æ„å»ºä¸åº”ç”¨ï¼Œæ˜¾è‘—é™ä½äº†å¯¹å¤§é‡è®­ç»ƒæ•°æ®çš„ä¾èµ–ï¼Œæå‡äº†ä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚æ–¹é¢ï¼ŒVistaWiseé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼Œå¹¶è®¾è®¡äº†é«˜æ•ˆçš„æ£€ç´¢ç®—æ³•ä»¥æ”¯æŒçŸ¥è¯†å›¾çš„ä¿¡æ¯æå–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒVistaWiseåœ¨å¤šä¸ªå¼€æ”¾ä¸–ç•Œä»»åŠ¡ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†å…¶åœ¨é™ä½å¼€å‘æˆæœ¬çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†æ™ºèƒ½ä½“çš„å†³ç­–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

VistaWiseçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ¸¸æˆå¼€å‘ã€è™šæ‹Ÿç°å®å’Œæœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚é€šè¿‡é™ä½å¼€å‘æˆæœ¬å¹¶æå‡ä»£ç†æ€§èƒ½ï¼Œè¯¥æ¡†æ¶å¯ä»¥åŠ é€Ÿæ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown significant promise in embodied decision-making tasks within virtual open-world environments. Nonetheless, their performance is hindered by the absence of domain-specific knowledge. Methods that finetune on large-scale domain-specific data entail prohibitive development costs. This paper introduces VistaWise, a cost-effective agent framework that integrates cross-modal domain knowledge and finetunes a dedicated object detection model for visual analysis. It reduces the requirement for domain-specific training data from millions of samples to a few hundred. VistaWise integrates visual information and textual dependencies into a cross-modal knowledge graph (KG), enabling a comprehensive and accurate understanding of multimodal environments. We also equip the agent with a retrieval-based pooling strategy to extract task-related information from the KG, and a desktop-level skill library to support direct operation of the Minecraft desktop client via mouse and keyboard inputs. Experimental results demonstrate that VistaWise achieves state-of-the-art performance across various open-world tasks, highlighting its effectiveness in reducing development costs while enhancing agent performance.

