---
layout: default
title: RepIt: Steering Language Models with Concept-Specific Refusal Vectors
---

# RepIt: Steering Language Models with Concept-Specific Refusal Vectors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.13281" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.13281v4</a>
  <a href="https://arxiv.org/pdf/2509.13281.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.13281v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.13281v4', 'RepIt: Steering Language Models with Concept-Specific Refusal Vectors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vincent Siu, Nathan W. Henry, Nicholas Crispino, Yang Liu, Dawn Song, Chenguang Wang

**åˆ†ç±»**: cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-16 (æ›´æ–°: 2025-10-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**RepItï¼šåˆ©ç”¨æ¦‚å¿µç‰¹å®šæ‹’ç»å‘é‡å¼•å¯¼è¯­è¨€æ¨¡å‹ï¼Œå®ç°ç²¾å‡†å¹²é¢„ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯­è¨€æ¨¡å‹å¼•å¯¼` `æ¿€æ´»å¼•å¯¼` `æ¦‚å¿µç‰¹å®šè¡¨ç¤º` `æ‹’ç»å‘é‡` `å®‰å…¨å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¿€æ´»å¼•å¯¼æ–¹æ³•åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å­˜åœ¨å‰¯ä½œç”¨ï¼Œéš¾ä»¥å®ç°å¯¹ç‰¹å®šæ¦‚å¿µçš„ç²¾å‡†å¹²é¢„ã€‚
2. RepItæ¡†æ¶é€šè¿‡éš”ç¦»æ¦‚å¿µç‰¹å®šçš„æ‹’ç»å‘é‡ï¼Œå®ç°å¯¹LLMè¡Œä¸ºçš„ç»†ç²’åº¦æ§åˆ¶å’Œå¹²é¢„ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRepItèƒ½é€‰æ‹©æ€§æŠ‘åˆ¶ç‰¹å®šæ¦‚å¿µçš„æ‹’ç»ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹åœ¨å…¶ä»–æ–¹é¢çš„å®‰å…¨æ€§ï¼Œä¸”ä»…éœ€å°‘é‡æ•°æ®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¿€æ´»å¼•å¯¼æ˜¯å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä¸­ä¸€ä¸ªæ–°å…´çš„ç ”ç©¶é¢†åŸŸï¼Œä½†ç°æœ‰æ–¹æ³•å¸¸å¸¸ä¼šäº§ç”Ÿè¶…å‡ºé¢„æœŸçš„å¹¿æ³›å½±å“ã€‚è¿™ä¿ƒä½¿æˆ‘ä»¬åˆ†ç¦»æ›´çº¯ç²¹çš„æ¦‚å¿µå‘é‡ï¼Œä»¥ä¾¿è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„å¹²é¢„ï¼Œå¹¶æ›´ç²¾ç»†åœ°ç†è§£LLMçš„è¡Œä¸ºã€‚æˆ‘ä»¬æå‡ºäº†RepItï¼Œä¸€ä¸ªç®€å•ä¸”æ•°æ®é«˜æ•ˆçš„æ¡†æ¶ï¼Œç”¨äºéš”ç¦»æ¦‚å¿µç‰¹å®šçš„è¡¨ç¤ºã€‚åœ¨äº”ä¸ªå‰æ²¿LLMä¸Šï¼ŒRepItå®ç°äº†ç²¾ç¡®çš„å¹²é¢„ï¼šå®ƒé€‰æ‹©æ€§åœ°æŠ‘åˆ¶ç›®æ ‡æ¦‚å¿µä¸Šçš„æ‹’ç»ï¼ŒåŒæ—¶ä¿ç•™å…¶ä»–åœ°æ–¹çš„æ‹’ç»ï¼Œä»è€Œç”Ÿæˆèƒ½å¤Ÿå›ç­”WMDç›¸å…³é—®é¢˜ï¼ŒåŒæ—¶åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­ä»ç„¶ä¿æŒå®‰å…¨çš„æ¨¡å‹ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¡¨æ˜ï¼Œæ ¡æ­£ä¿¡å·ä»…å®šä½äº100-200ä¸ªç¥ç»å…ƒï¼Œå¹¶ä¸”å¯ä»¥ä»å•ä¸ªA6000ä¸Šçš„åå‡ ä¸ªç¤ºä¾‹ä¸­æå–ç¨³å¥çš„ç›®æ ‡è¡¨ç¤ºã€‚è¿™ç§æ•ˆç‡å¼•å‘äº†ä¸€ä¸ªåŒé‡æ‹…å¿§ï¼šå¯ä»¥ä½¿ç”¨é€‚åº¦çš„è®¡ç®—å’Œæ•°æ®è¿›è¡Œæ“ä½œï¼Œä»¥æ‰©å±•åˆ°ä»£è¡¨æ€§ä¸è¶³çš„æ•°æ®ç¨€ç¼ºä¸»é¢˜ï¼ŒåŒæ—¶è§„é¿ç°æœ‰çš„åŸºå‡†æµ‹è¯•ã€‚é€šè¿‡ä½¿ç”¨RepItè§£è€¦æ‹’ç»å‘é‡ï¼Œè¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œæœ‰é’ˆå¯¹æ€§çš„å¹²é¢„å¯ä»¥æŠµæ¶ˆè¿‡åº¦æ³›åŒ–ï¼Œä¸ºæ›´ç²¾ç»†åœ°æ§åˆ¶æ¨¡å‹è¡Œä¸ºå¥ å®šåŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æŸäº›æƒ…å†µä¸‹ä¼šè¿‡åº¦æ³›åŒ–ï¼Œå¯¼è‡´ä¸å¿…è¦çš„æ‹’ç»å›ç­”ã€‚ä¾‹å¦‚ï¼Œæ¨¡å‹å¯èƒ½å› ä¸ºæ‹…å¿ƒç”Ÿæˆæœ‰å®³å†…å®¹è€Œæ‹’ç»å›ç­”ä¸æ­¦å™¨ç›¸å…³çš„é—®é¢˜ï¼Œå³ä½¿è¿™äº›é—®é¢˜æœ¬èº«æ˜¯æ— å®³çš„ã€‚ç°æœ‰æ¿€æ´»å¼•å¯¼æ–¹æ³•è™½ç„¶å¯ä»¥è°ƒæ•´LLMçš„è¡Œä¸ºï¼Œä½†å¾€å¾€ä¼šäº§ç”Ÿå‰¯ä½œç”¨ï¼Œå½±å“æ¨¡å‹åœ¨å…¶ä»–æ–¹é¢çš„è¡¨ç°ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´ç²¾ç¡®çš„æ–¹æ³•æ¥æ§åˆ¶LLMçš„è¡Œä¸ºï¼Œä½¿å…¶åªåœ¨ç‰¹å®šæ¦‚å¿µä¸Šå…è®¸å›ç­”ï¼Œè€Œåœ¨å…¶ä»–æ–¹é¢ä¿æŒå®‰å…¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šRepItçš„æ ¸å¿ƒæ€è·¯æ˜¯å­¦ä¹ æ¦‚å¿µç‰¹å®šçš„æ‹’ç»å‘é‡ï¼Œå¹¶åˆ©ç”¨è¿™äº›å‘é‡æ¥å¼•å¯¼LLMçš„è¡Œä¸ºã€‚å…·ä½“æ¥è¯´ï¼ŒRepIté¦–å…ˆè¯†åˆ«å‡ºå¯¼è‡´æ¨¡å‹æ‹’ç»å›ç­”ç‰¹å®šæ¦‚å¿µç›¸å…³é—®é¢˜çš„ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ã€‚ç„¶åï¼Œå®ƒå­¦ä¹ ä¸€ä¸ªæ‹’ç»å‘é‡ï¼Œè¯¥å‘é‡å¯ä»¥æŠ‘åˆ¶è¿™äº›ç¥ç»å…ƒçš„æ¿€æ´»ï¼Œä»è€Œä½¿æ¨¡å‹èƒ½å¤Ÿå›ç­”ç›¸å…³é—®é¢˜ï¼Œè€Œä¸ä¼šå½±å“å…¶åœ¨å…¶ä»–æ–¹é¢çš„å®‰å…¨æ€§ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå°†æ‹’ç»è¡Œä¸ºä¸ç‰¹å®šæ¦‚å¿µè§£è€¦ï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRepItæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) **æ•°æ®æ”¶é›†**ï¼šæ”¶é›†ä¸ç›®æ ‡æ¦‚å¿µç›¸å…³çš„é—®é¢˜å’Œå¯¹åº”çš„æ‹’ç»å›ç­”ã€‚2) **æ¿€æ´»åˆ†æ**ï¼šåˆ†æLLMåœ¨å¤„ç†è¿™äº›é—®é¢˜æ—¶çš„ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ï¼Œè¯†åˆ«å‡ºä¸æ‹’ç»è¡Œä¸ºç›¸å…³çš„ç¥ç»å…ƒã€‚3) **æ‹’ç»å‘é‡å­¦ä¹ **ï¼šä½¿ç”¨å°‘é‡æ•°æ®å­¦ä¹ ä¸€ä¸ªæ‹’ç»å‘é‡ï¼Œè¯¥å‘é‡å¯ä»¥æŠ‘åˆ¶ä¸æ‹’ç»è¡Œä¸ºç›¸å…³çš„ç¥ç»å…ƒçš„æ¿€æ´»ã€‚4) **å¹²é¢„**ï¼šå°†å­¦ä¹ åˆ°çš„æ‹’ç»å‘é‡åº”ç”¨äºLLMï¼Œä½¿å…¶èƒ½å¤Ÿå›ç­”ç›®æ ‡æ¦‚å¿µç›¸å…³çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒåœ¨å…¶ä»–æ–¹é¢çš„å®‰å…¨æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šRepItçš„å…³é”®åˆ›æ–°åœ¨äºå®ƒèƒ½å¤Ÿä»¥æ•°æ®é«˜æ•ˆçš„æ–¹å¼å­¦ä¹ æ¦‚å¿µç‰¹å®šçš„æ‹’ç»å‘é‡ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒRepItåªéœ€è¦å°‘é‡æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œå•ä¸ªA6000ä¸Šçš„åå‡ ä¸ªç¤ºä¾‹ï¼‰å°±å¯ä»¥æå–ç¨³å¥çš„ç›®æ ‡è¡¨ç¤ºã€‚æ­¤å¤–ï¼ŒRepItèƒ½å¤Ÿå°†æ ¡æ­£ä¿¡å·å®šä½åˆ°å°‘é‡ç¥ç»å…ƒï¼ˆä¾‹å¦‚ï¼Œ100-200ä¸ªï¼‰ï¼Œä»è€Œå®ç°æ›´ç²¾ç¡®çš„å¹²é¢„ã€‚

**å…³é”®è®¾è®¡**ï¼šRepItçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å¯¹æ¯”å­¦ä¹ æ¥å­¦ä¹ æ‹’ç»å‘é‡ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–ç›®æ ‡æ¦‚å¿µç›¸å…³é—®é¢˜å’Œéç›®æ ‡æ¦‚å¿µç›¸å…³é—®é¢˜ä¹‹é—´çš„æ¿€æ´»å·®å¼‚ã€‚2) ä½¿ç”¨L1æ­£åˆ™åŒ–æ¥é¼“åŠ±æ‹’ç»å‘é‡çš„ç¨€ç–æ€§ï¼Œä»è€Œå°†æ ¡æ­£ä¿¡å·å®šä½åˆ°å°‘é‡ç¥ç»å…ƒã€‚3) ä½¿ç”¨ç®€å•çš„çº¿æ€§å¹²é¢„æ–¹æ³•ï¼Œå°†æ‹’ç»å‘é‡æ·»åŠ åˆ°LLMçš„æ¿€æ´»ä¸­ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

RepItåœ¨äº”ä¸ªå‰æ²¿LLMä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜å®ƒå¯ä»¥é€‰æ‹©æ€§åœ°æŠ‘åˆ¶ç›®æ ‡æ¦‚å¿µä¸Šçš„æ‹’ç»ï¼ŒåŒæ—¶ä¿ç•™å…¶ä»–åœ°æ–¹çš„æ‹’ç»ã€‚ä¾‹å¦‚ï¼ŒRepItèƒ½å¤Ÿä½¿æ¨¡å‹å›ç­”WMDç›¸å…³çš„é—®é¢˜ï¼ŒåŒæ—¶åœ¨æ ‡å‡†å®‰å…¨åŸºå‡†æµ‹è¯•ä¸­ä»ç„¶ä¿æŒå®‰å…¨ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜ï¼Œæ ¡æ­£ä¿¡å·ä»…å®šä½äº100-200ä¸ªç¥ç»å…ƒï¼Œå¹¶ä¸”å¯ä»¥ä»å•ä¸ªA6000ä¸Šçš„åå‡ ä¸ªç¤ºä¾‹ä¸­æå–ç¨³å¥çš„ç›®æ ‡è¡¨ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

RepItå¯ç”¨äºæé«˜LLMåœ¨ç‰¹å®šé¢†åŸŸçš„å¯ç”¨æ€§ï¼Œä¾‹å¦‚ï¼Œå…è®¸æ¨¡å‹å›ç­”ä¸åŒ»ç–—æˆ–æ³•å¾‹ç›¸å…³çš„é—®é¢˜ï¼Œè€Œä¸ä¼šç”Ÿæˆæœ‰å®³ä¿¡æ¯ã€‚å®ƒè¿˜å¯ä»¥ç”¨äºè§£å†³LLMä¸­çš„åè§é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œé€šè¿‡æŠ‘åˆ¶ä¸ç‰¹å®šç¾¤ä½“ç›¸å…³çš„è´Ÿé¢åˆ»æ¿å°è±¡ã€‚æ­¤å¤–ï¼ŒRepItå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£LLMçš„è¡Œä¸ºï¼Œä¾‹å¦‚ï¼Œé€šè¿‡åˆ†ææ‹’ç»å‘é‡æ¥è¯†åˆ«å¯¼è‡´æ¨¡å‹æ‹’ç»å›ç­”ç‰¹å®šé—®é¢˜çš„å› ç´ ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While activation steering in large language models (LLMs) is a growing area of research, methods can often incur broader effects than desired. This motivates isolation of purer concept vectors to enable targeted interventions and understand LLM behavior at a more granular level. We present RepIt, a simple and data-efficient framework for isolating concept-specific representations. Across five frontier LLMs, RepIt enables precise interventions: it selectively suppresses refusal on targeted concepts while preserving refusal elsewhere, producing models that answer WMD-related questions while still scoring as safe on standard benchmarks. We further show that the corrective signal localizes to just 100-200 neurons and that robust target representations can be extracted from as few as a dozen examples on a single A6000. This efficiency raises a dual concern: manipulations can be performed with modest compute and data to extend to underrepresented data-scarce topics while evading existing benchmarks. By disentangling refusal vectors with RepIt, this work demonstrates that targeted interventions can counteract overgeneralization, laying the foundation for more granular control of model behavior.

