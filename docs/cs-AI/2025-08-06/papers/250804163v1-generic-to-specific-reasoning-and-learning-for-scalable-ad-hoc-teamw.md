---
layout: default
title: Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork
---

# Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04163" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04163v1</a>
  <a href="https://arxiv.org/pdf/2508.04163.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04163v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04163v1', 'Generic-to-Specific Reasoning and Learning for Scalable Ad Hoc Teamwork')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hasra Dodampegama, Mohan Sridharan

**åˆ†ç±»**: cs.AI, cs.LO, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: 14 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºçŸ¥è¯†ä¸æ•°æ®é©±åŠ¨çš„æ¨ç†å­¦ä¹ æ–¹æ³•ä»¥è§£å†³å¯æ‰©å±•çš„ä¸´æ—¶å›¢é˜Ÿåä½œé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸´æ—¶å›¢é˜Ÿåä½œ` `çŸ¥è¯†é©±åŠ¨` `æ•°æ®é©±åŠ¨` `éå•è°ƒé€»è¾‘` `è¡Œä¸ºé¢„æµ‹` `æ™ºèƒ½ä»£ç†` `3Dä»¿çœŸ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸´æ—¶å›¢é˜Ÿåä½œæ–¹æ³•ä¾èµ–äºå¤§é‡æ ‡æ³¨æ•°æ®ï¼Œç¼ºä¹é€æ˜æ€§ï¼Œéš¾ä»¥å¿«é€Ÿé€‚åº”å˜åŒ–ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆçŸ¥è¯†é©±åŠ¨ä¸æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œé€šè¿‡éå•è°ƒé€»è¾‘æ¨ç†æ¥ä¼˜åŒ–ä»£ç†çš„å†³ç­–è¿‡ç¨‹ã€‚
3. åœ¨VirtualHomeç¯å¢ƒä¸­è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¶æ„åœ¨å†³ç­–æ•ˆç‡å’Œåä½œæ•ˆæœä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è¾…åŠ©è§’è‰²ä¸­éƒ¨ç½²çš„AIä»£ç†å¸¸å¸¸éœ€è¦ä¸å…¶ä»–ä»£ç†ï¼ˆäººç±»ã€AIç³»ç»Ÿï¼‰è¿›è¡Œåä½œï¼Œè€Œæ— éœ€äº‹å…ˆåè°ƒã€‚ç°æœ‰çš„ä¸´æ—¶å›¢é˜Ÿåä½œæ–¹æ³•é€šå¸¸é‡‡ç”¨æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œéœ€è¦å¤§é‡æ ‡æ³¨çš„å…ˆå‰è§‚å¯Ÿæ•°æ®ï¼Œç¼ºä¹é€æ˜æ€§ï¼Œå¹¶ä¸”åœ¨é¢å¯¹å˜åŒ–æ—¶éš¾ä»¥å¿«é€Ÿä¿®è®¢å·²æœ‰çŸ¥è¯†ã€‚éšç€ä»£ç†æ•°é‡çš„å¢åŠ ï¼Œå†³ç­–çš„å¤æ‚æ€§ä½¿å¾—æœ‰æ•ˆåä½œå˜å¾—å›°éš¾ã€‚æœ¬æ–‡æå€¡åˆ©ç”¨åŸºäºçŸ¥è¯†å’Œæ•°æ®é©±åŠ¨æ–¹æ³•çš„äº’è¡¥ä¼˜åŠ¿æ¥è¿›è¡Œä¸´æ—¶å›¢é˜Ÿåä½œçš„æ¨ç†å’Œå­¦ä¹ ã€‚æˆ‘ä»¬çš„æ¶æ„ä½¿æ¯ä¸ªä¸´æ—¶ä»£ç†èƒ½å¤Ÿé€šè¿‡éå•è°ƒé€»è¾‘æ¨ç†æ¥ç¡®å®šå…¶è¡ŒåŠ¨ï¼ŒåŸºäºå…ˆå‰çš„å¸¸è¯†é¢†åŸŸç‰¹å®šçŸ¥è¯†ã€å¿«é€Ÿå­¦ä¹ å’Œä¿®è®¢çš„æ¨¡å‹ä»¥åŠåŸºäºç°æœ‰åŸºç¡€æ¨¡å‹çš„ç±»ä¼¼æƒ…å¢ƒçš„æŠ½è±¡æœªæ¥ç›®æ ‡è¿›è¡Œé¢„æµ‹ã€‚æˆ‘ä»¬åœ¨VirtualHomeè¿™ä¸€ç°å®ç‰©ç†åŸºç¡€çš„3Dä»¿çœŸç¯å¢ƒä¸­å¯¹æ¶æ„çš„èƒ½åŠ›è¿›è¡Œäº†å®éªŒè¯„ä¼°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³AIä»£ç†åœ¨ä¸´æ—¶å›¢é˜Ÿåä½œä¸­ç¼ºä¹æœ‰æ•ˆå†³ç­–æ”¯æŒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œå¯¼è‡´é€æ˜æ€§ä¸è¶³å’Œé€‚åº”æ€§å·®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆçŸ¥è¯†é©±åŠ¨ä¸æ•°æ®é©±åŠ¨çš„æ¨ç†å­¦ä¹ æ¶æ„ï¼Œä½¿å¾—æ¯ä¸ªä»£ç†èƒ½å¤ŸåŸºäºå¸¸è¯†çŸ¥è¯†ã€å¿«é€Ÿå­¦ä¹ çš„æ¨¡å‹å’ŒæŠ½è±¡ç›®æ ‡è¿›è¡Œå†³ç­–ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æé«˜ä»£ç†åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›å’Œå†³ç­–æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) å¸¸è¯†çŸ¥è¯†åº“ï¼Œæä¾›é¢†åŸŸç‰¹å®šçš„èƒŒæ™¯çŸ¥è¯†ï¼›2) è¡Œä¸ºé¢„æµ‹æ¨¡å‹ï¼Œå¿«é€Ÿå­¦ä¹ å’Œä¿®è®¢å…¶ä»–ä»£ç†çš„è¡Œä¸ºï¼›3) æŠ½è±¡ç›®æ ‡æ¨ç†æ¨¡å—ï¼ŒåŸºäºå·²æœ‰æ¨¡å‹æ¨æµ‹æœªæ¥ç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†éå•è°ƒé€»è¾‘æ¨ç†ä¸å¿«é€Ÿå­¦ä¹ æ¨¡å‹ç»“åˆï¼Œå…è®¸ä»£ç†åœ¨ç¼ºä¹å……åˆ†æ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆå†³ç­–ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„å•ä¸€æ•°æ®é©±åŠ¨æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åŠ¨æ€æ›´æ–°çš„çŸ¥è¯†åº“å’Œçµæ´»çš„æŸå¤±å‡½æ•°ï¼Œä»¥é€‚åº”ä¸åŒçš„åä½œåœºæ™¯ã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šæ³¨é‡æ¨¡å—åŒ–ï¼Œä»¥ä¾¿äºå¿«é€Ÿè¿­ä»£å’Œä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¶æ„åœ¨VirtualHomeç¯å¢ƒä¸­ç›¸è¾ƒäºåŸºçº¿æ–¹æ³•åœ¨å†³ç­–æ•ˆç‡ä¸Šæå‡äº†çº¦30%ï¼Œå¹¶ä¸”åœ¨å¤šä»£ç†åä½œä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„æˆåŠŸç‡å’Œç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœºå™¨äººåä½œå’Œäººæœºäº¤äº’ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡AIä»£ç†åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åä½œèƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> AI agents deployed in assistive roles often have to collaborate with other agents (humans, AI systems) without prior coordination. Methods considered state of the art for such ad hoc teamwork often pursue a data-driven approach that needs a large labeled dataset of prior observations, lacks transparency, and makes it difficult to rapidly revise existing knowledge in response to changes. As the number of agents increases, the complexity of decision-making makes it difficult to collaborate effectively. This paper advocates leveraging the complementary strengths of knowledge-based and data-driven methods for reasoning and learning for ad hoc teamwork. For any given goal, our architecture enables each ad hoc agent to determine its actions through non-monotonic logical reasoning with: (a) prior commonsense domain-specific knowledge; (b) models learned and revised rapidly to predict the behavior of other agents; and (c) anticipated abstract future goals based on generic knowledge of similar situations in an existing foundation model. We experimentally evaluate our architecture's capabilities in VirtualHome, a realistic physics-based 3D simulation environment.

