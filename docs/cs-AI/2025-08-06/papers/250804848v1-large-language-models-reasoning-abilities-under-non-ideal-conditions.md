---
layout: default
title: Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning
---

# Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04848" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04848v1</a>
  <a href="https://arxiv.org/pdf/2508.04848.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04848v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04848v1', 'Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chang Tian, Matthew B. Blaschko, Mingzhe Xing, Xiuxing Li, Yinliang Yue, Marie-Francine Moens

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: large language models, large vision-language model, reasoning, non-ideal conditions, reinforcement learning

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé’ˆå¯¹éç†æƒ³æ¡ä»¶ä¸‹å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ä¸æ”¹è¿›æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `éç†æƒ³åœºæ™¯` `è„‘ç§‘å­¦` `æ€§èƒ½è¯„ä¼°` `è‡ªç„¶è¯­è¨€å¤„ç†` `è§†è§‰è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦åœ¨ç†æƒ³åŒ–ç¯å¢ƒä¸‹è¯„ä¼°å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¿½è§†äº†ç°å®ä¸­çš„éç†æƒ³åœºæ™¯ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›çš„å±€é™æ€§æœªè¢«å……åˆ†æ­ç¤ºã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè„‘ç§‘å­¦çš„ç ”ç©¶æ–¹å‘ï¼Œå®šä¹‰å¹¶è¯„ä¼°äº†æ‘˜è¦æ¨ç†ã€ç»†ç²’åº¦å™ªå£°æŠ‘åˆ¶å’Œä¸Šä¸‹æ–‡è¿‡æ»¤ç­‰éç†æƒ³åœºæ™¯ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡RLå¾®è°ƒåœ¨ç†æƒ³ç¯å¢ƒä¸‹æå‡äº†æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨éç†æƒ³åœºæ™¯ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæ˜¾ç¤ºå‡ºå½“å‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›åœºæ™¯æ—¶çš„ä¸è¶³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºæå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„å…³é”®æŠ€æœ¯ï¼Œå°¤å…¶æ˜¯ç­–ç•¥æ¢¯åº¦ç®—æ³•åœ¨åè®­ç»ƒé˜¶æ®µçš„é«˜æ•ˆæ€§å’Œæœ‰æ•ˆæ€§ã€‚ç„¶è€Œï¼Œç°æœ‰åŸºå‡†å¤§å¤šåœ¨ç†æƒ³åŒ–ç¯å¢ƒä¸‹è¯„ä¼°æ¨¡å‹æ¨ç†ï¼Œå¿½è§†äº†ç°å®ä¸­çš„éç†æƒ³åœºæ™¯ã€‚æœ¬æ–‡è¯†åˆ«äº†ä¸‰ä¸ªå…·æœ‰å®é™…ç›¸å…³æ€§çš„éç†æƒ³åœºæ™¯ï¼šæ‘˜è¦æ¨ç†ã€ç»†ç²’åº¦å™ªå£°æŠ‘åˆ¶å’Œä¸Šä¸‹æ–‡è¿‡æ»¤ã€‚æˆ‘ä»¬å¼•å…¥ä¸€ç§æ–°çš„ç ”ç©¶æ–¹å‘ï¼ŒåŸºäºè„‘ç§‘å­¦å‘ç°äººç±»åœ¨ä¸å®Œç¾è¾“å…¥ä¸‹ä»èƒ½ä¿æŒå¯é æ¨ç†ã€‚é€šè¿‡å¯¹ä¸‰ç§LLMå’Œä¸€ç§å…ˆè¿›çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰è¿›è¡ŒRLå¾®è°ƒï¼Œå¹¶åœ¨å…«ä¸ªå…¬å…±æ•°æ®é›†ä¸Šæµ‹è¯•å…¶æ€§èƒ½ï¼Œç»“æœæ˜¾ç¤ºå°½ç®¡RLå¾®è°ƒåœ¨ç†æƒ³ç¯å¢ƒä¸‹æå‡äº†åŸºçº¿æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ‰€æœ‰éç†æƒ³åœºæ™¯ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œæš´éœ²å‡ºé«˜çº§æ¨ç†èƒ½åŠ›çš„å…³é”®å±€é™æ€§ã€‚å°½ç®¡æå‡ºäº†åœºæ™¯ç‰¹å®šçš„è¡¥æ•‘æ–¹æ³•ï¼Œä½†ç»“æœè¡¨æ˜å½“å‰æ–¹æ³•åœ¨è§£å†³è¿™äº›æ¨ç†ç¼ºé™·æ–¹é¢ä»ç„¶ä¸è¶³ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›çš„å¤¸å¤§ï¼Œå¹¶æŒ‡å‡ºåœ¨éç†æƒ³åœºæ™¯ä¸‹è¯„ä¼°æ¨¡å‹çš„é‡è¦æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨éç†æƒ³æ¡ä»¶ä¸‹æ¨ç†èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨ç†æƒ³åŒ–ç¯å¢ƒä¸‹çš„è¯„ä¼°ï¼Œæœªèƒ½åæ˜ æ¨¡å‹åœ¨ç°å®åº”ç”¨ä¸­çš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„ç ”ç©¶æ–¹å‘ï¼Œå€Ÿé‰´è„‘ç§‘å­¦çš„å‘ç°ï¼Œè®¤ä¸ºäººç±»åœ¨ä¸å®Œç¾è¾“å…¥ä¸‹ä»èƒ½è¿›è¡Œå¯é æ¨ç†ã€‚é€šè¿‡å®šä¹‰å’Œè¯„ä¼°éç†æƒ³åœºæ™¯ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰å¤§æ¨¡å—ï¼šé¦–å…ˆæ˜¯å¯¹ä¸‰ç§å¤§è¯­è¨€æ¨¡å‹å’Œä¸€ç§å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå¼ºåŒ–å­¦ä¹ å¾®è°ƒï¼›å…¶æ¬¡æ˜¯åœ¨å…«ä¸ªå…¬å…±æ•°æ®é›†ä¸Šè¿›è¡Œæ€§èƒ½æµ‹è¯•ï¼›æœ€åæ˜¯æå‡ºåœºæ™¯ç‰¹å®šçš„è¡¥æ•‘æ–¹æ³•ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºè¯†åˆ«å¹¶å®šä¹‰äº†ä¸‰ä¸ªéç†æƒ³æ¨ç†åœºæ™¯ï¼Œå¹¶é€šè¿‡å¼ºåŒ–å­¦ä¹ å¾®è°ƒæ¥è¯„ä¼°æ¨¡å‹åœ¨è¿™äº›åœºæ™¯ä¸‹çš„è¡¨ç°ï¼Œæ­ç¤ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ä»£è¡¨æ€§çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œå¹¶è®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°ï¼Œä»¥é€‚åº”ä¸åŒçš„éç†æƒ³åœºæ™¯ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿåœ¨è¿™äº›åœºæ™¯ä¸­è¿›è¡Œæœ‰æ•ˆæ¨ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡å¼ºåŒ–å­¦ä¹ å¾®è°ƒåœ¨ç†æƒ³ç¯å¢ƒä¸‹æå‡äº†æ¨ç†èƒ½åŠ›ï¼Œä½†åœ¨æ‘˜è¦æ¨ç†ã€ç»†ç²’åº¦å™ªå£°æŠ‘åˆ¶å’Œä¸Šä¸‹æ–‡è¿‡æ»¤ç­‰éç†æƒ³åœºæ™¯ä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå¹³å‡ä¸‹é™å¹…åº¦è¶…è¿‡30%ã€‚è¿™è¡¨æ˜å½“å‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚ç°å®åœºæ™¯æ—¶çš„ä¸è¶³ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹åœ¨éç†æƒ³æ¡ä»¶ä¸‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥å¢å¼ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) has become a key technique for enhancing the reasoning abilities of large language models (LLMs), with policy-gradient algorithms dominating the post-training stage because of their efficiency and effectiveness. However, most existing benchmarks evaluate large-language-model reasoning under idealized settings, overlooking performance in realistic, non-ideal scenarios. We identify three representative non-ideal scenarios with practical relevance: summary inference, fine-grained noise suppression, and contextual filtering. We introduce a new research direction guided by brain-science findings that human reasoning remains reliable under imperfect inputs. We formally define and evaluate these challenging scenarios. We fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM) using RL with a representative policy-gradient algorithm and then test their performance on eight public datasets. Our results reveal that while RL fine-tuning improves baseline reasoning under idealized settings, performance declines significantly across all three non-ideal scenarios, exposing critical limitations in advanced reasoning capabilities. Although we propose a scenario-specific remediation method, our results suggest current methods leave these reasoning deficits largely unresolved. This work highlights that the reasoning abilities of large models are often overstated and underscores the importance of evaluating models under non-ideal scenarios. The code and data will be released at XXXX.

