---
layout: default
title: KG-Augmented Executable CoT for Mathematical Coding
---

# KG-Augmented Executable CoT for Mathematical Coding

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04072" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04072v1</a>
  <a href="https://arxiv.org/pdf/2508.04072.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04072v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04072v1', 'KG-Augmented Executable CoT for Mathematical Coding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xingyu Chen, Junxiu An, Jun Guo, Li Wang, Jingcai Guo

**åˆ†ç±»**: cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: 9 pages,2figures,6 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºKG-Augmented Executable CoTä»¥è§£å†³å¤æ‚æ•°å­¦æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†å›¾è°±` `æ•°å­¦æ¨ç†` `ä»£ç ç”Ÿæˆ` `å¯æ‰§è¡Œä»£ç ` `å›¾ç¥ç»ç½‘ç»œ` `æ·±åº¦å­¦ä¹ ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆæ—¶å­˜åœ¨æ˜¾è‘—çš„å±€é™æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„ä»£ç è´¨é‡å’Œæ¨ç†å‡†ç¡®æ€§ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„KGA-ECoTæ¡†æ¶é€šè¿‡çŸ¥è¯†å›¾è°±å’Œå¯æ‰§è¡Œä»£ç çš„ç»“åˆï¼Œæ—¨åœ¨æå‡ä»£ç ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œæ•°å­¦æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKGA-ECoTåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°å‡ åˆ°åå¤šä¸ªç™¾åˆ†ç‚¹ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨å¤æ‚æ¨ç†ä»»åŠ¡å¦‚æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆæ–¹é¢é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†KG-Augmented Executable Chain-of-Thoughtï¼ˆKGA-ECoTï¼‰æ¡†æ¶ï¼Œé€šè¿‡çŸ¥è¯†å›¾è°±å¢å¼ºä»£ç ç”Ÿæˆï¼Œå¹¶é€šè¿‡å¯æ‰§è¡Œä»£ç æ”¹å–„æ•°å­¦æ¨ç†ã€‚KGA-ECoTå°†é—®é¢˜åˆ†è§£ä¸ºç»“æ„åŒ–ä»»åŠ¡å›¾ï¼Œåˆ©ç”¨é«˜æ•ˆçš„GraphRAGä»æ•°å­¦åº“ä¸­ç²¾ç¡®æ£€ç´¢çŸ¥è¯†ï¼Œå¹¶ç”Ÿæˆå¯éªŒè¯çš„ä»£ç ä»¥ç¡®ä¿è®¡ç®—å‡†ç¡®æ€§ã€‚åœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒKGA-ECoTæ˜¾è‘—ä¼˜äºç°æœ‰æç¤ºæ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦ä»å‡ ä¸ªç™¾åˆ†ç‚¹åˆ°åå¤šä¸ªç™¾åˆ†ç‚¹ä¸ç­‰ã€‚è¿›ä¸€æ­¥åˆ†æç¡®è®¤äº†GraphRAGåœ¨æå‡ä»£ç è´¨é‡å’Œå¤–éƒ¨ä»£ç æ‰§è¡Œç¡®ä¿ç²¾åº¦ä¸­çš„å…³é”®ä½œç”¨ã€‚è¿™äº›å‘ç°å…±åŒç¡®ç«‹äº†KGA-ECoTä½œä¸ºå¤æ‚æ•°å­¦æ¨ç†ä»»åŠ¡çš„å¼ºå¤§ä¸”é«˜åº¦å¯æ¨å¹¿çš„æ¡†æ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ•°å­¦æ¨ç†å’Œä»£ç ç”Ÿæˆä¸­çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œå¯éªŒè¯æ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKGA-ECoTæ¡†æ¶é€šè¿‡å°†é—®é¢˜åˆ†è§£ä¸ºç»“æ„åŒ–ä»»åŠ¡å›¾ï¼Œç»“åˆçŸ¥è¯†å›¾è°±å’Œå¯æ‰§è¡Œä»£ç ï¼Œæå‡æ¨ç†å’Œç”Ÿæˆçš„å‡†ç¡®æ€§ä¸å¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼šç»“æ„åŒ–ä»»åŠ¡å›¾çš„æ„å»ºã€GraphRAGçš„çŸ¥è¯†æ£€ç´¢å’Œå¯æ‰§è¡Œä»£ç çš„ç”Ÿæˆï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„æ¨ç†ä¸ç”Ÿæˆæµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šKGA-ECoTçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥GraphRAGè¿›è¡Œé«˜æ•ˆçš„çŸ¥è¯†æ£€ç´¢ï¼Œå¹¶é€šè¿‡å¯æ‰§è¡Œä»£ç ç¡®ä¿æ•°å­¦æ¨ç†çš„å‡†ç¡®æ€§ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æç¤ºæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒKGA-ECoTé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®ä»¥ä¼˜åŒ–çŸ¥è¯†æ£€ç´¢çš„æ•ˆç‡ï¼Œå¹¶è®¾è®¡äº†æŸå¤±å‡½æ•°ä»¥ç¡®ä¿ç”Ÿæˆä»£ç çš„å¯éªŒè¯æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒKGA-ECoTåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æç¤ºæ–¹æ³•ï¼Œå‡†ç¡®ç‡æå‡å¹…åº¦ä»å‡ ä¸ªç™¾åˆ†ç‚¹åˆ°åå¤šä¸ªç™¾åˆ†ç‚¹ï¼ŒéªŒè¯äº†GraphRAGåœ¨æå‡ä»£ç è´¨é‡å’Œæ‰§è¡Œç²¾åº¦ä¸­çš„å…³é”®ä½œç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ç§‘å­¦è®¡ç®—å’Œè½¯ä»¶å¼€å‘ç­‰ï¼Œèƒ½å¤Ÿä¸ºå¤æ‚æ•°å­¦é—®é¢˜çš„è‡ªåŠ¨æ±‚è§£å’Œä»£ç ç”Ÿæˆæä¾›æœ‰æ•ˆæ”¯æŒã€‚æœªæ¥ï¼ŒKGA-ECoTå¯èƒ½åœ¨æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–ç¼–ç¨‹å’Œåœ¨çº¿æ•™è‚²å¹³å°ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In recent years, large language models (LLMs) have excelled in natural language processing tasks but face significant challenges in complex reasoning tasks such as mathematical reasoning and code generation. To address these limitations, we propose KG-Augmented Executable Chain-of-Thought (KGA-ECoT), a novel framework that enhances code generation through knowledge graphs and improves mathematical reasoning via executable code. KGA-ECoT decomposes problems into a Structured Task Graph, leverages efficient GraphRAG for precise knowledge retrieval from mathematical libraries, and generates verifiable code to ensure computational accuracy. Evaluations on multiple mathematical reasoning benchmarks demonstrate that KGA-ECoT significantly outperforms existing prompting methods, achieving absolute accuracy improvements ranging from several to over ten percentage points. Further analysis confirms the critical roles of GraphRAG in enhancing code quality and external code execution in ensuring precision. These findings collectively establish KGA-ECoT as a robust and highly generalizable framework for complex mathematical reasoning tasks.

