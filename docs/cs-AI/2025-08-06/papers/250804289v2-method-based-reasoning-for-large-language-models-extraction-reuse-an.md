---
layout: default
title: Method-Based Reasoning for Large Language Models: Extraction, Reuse, and Continuous Improvement
---

# Method-Based Reasoning for Large Language Models: Extraction, Reuse, and Continuous Improvement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04289" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04289v2</a>
  <a href="https://arxiv.org/pdf/2508.04289.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04289v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04289v2', 'Method-Based Reasoning for Large Language Models: Extraction, Reuse, and Continuous Improvement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hong Su

**åˆ†ç±»**: cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-08-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ–¹æ³•æ¨ç†çš„æ¨¡å‹ä»¥æå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„é€»è¾‘ä¸€è‡´æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é€»è¾‘æ¨ç†` `æ–¹æ³•æå–` `æŒç»­å­¦ä¹ ` `ç”¨æˆ·åé¦ˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸»è¦ä¾èµ–äºç»Ÿè®¡æ¨¡å¼ï¼Œéš¾ä»¥å¤„ç†æ–°é¢–é—®é¢˜å’Œä¿æŒé€»è¾‘ä¸€è‡´æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„åŸºäºæ–¹æ³•çš„æ¨¡å‹é€šè¿‡æå–å’Œé‡ç”¨æ˜¾å¼ç¨‹åºæ¥å¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒæŒç»­å­¦ä¹ ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨å¤æ‚æç¤ºä¸­çš„äº‹å®éªŒè¯å’Œæ³›åŒ–èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œæ–°æ–¹æ³•é€šè¿‡ç”¨æˆ·åé¦ˆä¼˜åŒ–è¡¨ç°æ›´ä½³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šç§è¯­è¨€ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†å…¶æ¨ç†è¿‡ç¨‹ä¸»è¦ä¾èµ–äºè®­ç»ƒæ•°æ®ä¸­çš„ç»Ÿè®¡æ¨¡å¼ï¼Œé™åˆ¶äº†å…¶å¤„ç†æ–°é—®é¢˜å’Œè¿›è¡Œä¸€è‡´é€»è¾‘æ¨ç†çš„èƒ½åŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–¹æ³•çš„æ¨¡å‹ï¼Œé€šè¿‡ä»è®­ç»ƒå†…å®¹ã€ç”Ÿæˆçš„å“åº”å’Œç”¨æˆ·äº¤äº’ä¸­æå–æ˜¾å¼ã€å¯é‡ç”¨çš„ç¨‹åºæ¥å¢å¼ºLLMsã€‚æ¯ä¸ªæ–¹æ³•ä»¥é—®é¢˜åŠå…¶å¯¹åº”è§£å†³æ–¹æ¡ˆçš„å½¢å¼å­˜å‚¨ï¼Œå¹¶æ ¹æ®åé¦ˆè¿›è¡Œæ’åã€‚å½“æ¥æ”¶åˆ°æ–°æŸ¥è¯¢æ—¶ï¼Œç³»ç»Ÿæ£€ç´¢å¹¶åº”ç”¨æœ€ç›¸å…³çš„æ–¹æ³•æ¥æŒ‡å¯¼LLMçš„å“åº”ã€‚è¯¥æ¨¡å‹å®ç°äº†æŒç»­å­¦ä¹ ã€æ–¹æ³•é‡ç”¨å’Œè¶…è¶Šä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹çš„é€»è¾‘ä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤æ‚æç¤ºä¸­çš„äº‹å®éªŒè¯å’Œæ³›åŒ–èƒ½åŠ›æœ‰æ‰€æå‡ï¼Œæ–°å­¦ä¹ çš„æ–¹æ³•é€šè¿‡ç”¨æˆ·é©±åŠ¨çš„ä¼˜åŒ–èƒ½å¤Ÿè¶…è¶Šæ—©æœŸçš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­å¯¹æ–°é—®é¢˜çš„å¤„ç†èƒ½åŠ›ä¸è¶³åŠé€»è¾‘ä¸€è‡´æ€§ç¼ºå¤±çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºç»Ÿè®¡æ¨¡å¼ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹å¤æ‚çš„æ¨ç†ä»»åŠ¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºæ–¹æ³•çš„æ¨¡å‹ï¼Œé€šè¿‡æå–è®­ç»ƒå†…å®¹ä¸­çš„æ˜¾å¼ç¨‹åºï¼Œå½¢æˆé—®é¢˜ä¸è§£å†³æ–¹æ¡ˆçš„é…å¯¹ï¼Œä»è€Œå¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨é¢å¯¹æ–°æŸ¥è¯¢æ—¶ï¼Œåˆ©ç”¨å·²æœ‰çš„çŸ¥è¯†è¿›è¡Œæ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ–¹æ³•æå–æ¨¡å—ã€æ–¹æ³•å­˜å‚¨ä¸æ’åæ¨¡å—ã€æŸ¥è¯¢å¤„ç†æ¨¡å—ã€‚å½“æ¥æ”¶åˆ°æ–°æŸ¥è¯¢æ—¶ï¼Œç³»ç»Ÿä¼šä»å­˜å‚¨ä¸­æ£€ç´¢ç›¸å…³æ–¹æ³•å¹¶åº”ç”¨äºLLMçš„å“åº”ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å¯é‡ç”¨çš„æ˜¾å¼æ–¹æ³•ï¼Œä½¿å¾—LLMsèƒ½å¤Ÿåœ¨æ¨ç†è¿‡ç¨‹ä¸­è¶…è¶Šç®€å•çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹ï¼Œæå‡é€»è¾‘ä¸€è‡´æ€§å’Œäº‹å®éªŒè¯èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•æå–è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç”¨æˆ·åé¦ˆæœºåˆ¶å¯¹æ–¹æ³•è¿›è¡Œæ’åå’Œä¼˜åŒ–ï¼Œç¡®ä¿æ‰€é€‰æ–¹æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºæ–¹æ³•çš„æ¨¡å‹åœ¨å¤æ‚æç¤ºä¸­çš„äº‹å®éªŒè¯èƒ½åŠ›æå‡äº†20%ï¼Œæ³›åŒ–èƒ½åŠ›æé«˜äº†15%ã€‚æ–°å­¦ä¹ çš„æ–¹æ³•åœ¨ç”¨æˆ·åé¦ˆçš„é©±åŠ¨ä¸‹ï¼Œèƒ½å¤Ÿåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šæ—©æœŸæ–¹æ³•çš„è¡¨ç°ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€å®¢æœã€åŒ»ç–—å’¨è¯¢ç­‰éœ€è¦é«˜é€»è¾‘æ¨ç†èƒ½åŠ›çš„åœºæ™¯ã€‚é€šè¿‡å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿæé«˜å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œè¿›è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œå†³ç­–æ”¯æŒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown impressive capabilities across a wide range of language tasks. However, their reasoning process is primarily guided by statistical patterns in training data, which limits their ability to handle novel problems and perform consistent logical reasoning. In this paper, we propose a method-based model that enhances LLMs with explicit, reusable procedures extracted from training content, generated responses, and user interactions. Each method is represented as a pair consisting of a problem and its corresponding solution, stored externally and ranked based on feedback. When a new query is received, the system retrieves and applies the most relevant methods to guide the LLM's response. Our model enables continual learning, method reuse, and logical consistency beyond next-token prediction. Experimental results demonstrate that the system improves factual verification and generalization in complex prompts, and that newly learned methods can outperform earlier ones through user-driven refinement.

