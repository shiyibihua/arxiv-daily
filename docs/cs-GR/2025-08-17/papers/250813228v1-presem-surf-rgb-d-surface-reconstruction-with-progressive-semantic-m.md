---
layout: default
title: PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism
---

# PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13228" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13228v1</a>
  <a href="https://arxiv.org/pdf/2508.13228.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13228v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13228v1', 'PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuyan Ye, Hang Xu, Yanghang Huang, Jiali Huang, Qian Weng

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV, eess.IV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-17

**å¤‡æ³¨**: 2025 International Joint Conference on Neural Networks (IJCNN 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPreSem-Surfä»¥è§£å†³RGB-Dåœºæ™¯è¡¨é¢é‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `RGB-Dé‡å»º` `ç¥ç»è¾å°„åœº` `å¤šæ¨¡æ€èåˆ` `è¯­ä¹‰å»ºæ¨¡` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨RGB-Dåºåˆ—çš„åœºæ™¯è¡¨é¢é‡å»ºä¸­å­˜åœ¨æ—¶é—´æ•ˆç‡ä½å’Œé‡å»ºè´¨é‡ä¸è¶³çš„é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºçš„PreSem-Surfæ–¹æ³•é€šè¿‡æ•´åˆRGBã€æ·±åº¦å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œåˆ©ç”¨SG-MLPå’ŒPR-MLPç»“æ„ä¼˜åŒ–é‡å»ºè¿‡ç¨‹ã€‚
3. åœ¨ä¸ƒä¸ªåˆæˆåœºæ™¯çš„å®éªŒä¸­ï¼ŒPreSem-Surfåœ¨å¤šä¸ªè¯„ä¼°æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯åœ¨C-L1ã€F-scoreå’ŒIoUä¸Šå–å¾—æœ€ä½³ç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç¥ç»è¾å°„åœºï¼ˆNeRFï¼‰æ¡†æ¶çš„ä¼˜åŒ–æ–¹æ³•PreSem-Surfï¼Œèƒ½å¤Ÿå¿«é€Ÿé‡å»ºé«˜è´¨é‡çš„åœºæ™¯è¡¨é¢ã€‚è¯¥æ–¹æ³•æ•´åˆäº†RGBã€æ·±åº¦å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œä»¥æå‡é‡å»ºæ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„SG-MLPé‡‡æ ·ç»“æ„ä¸PR-MLPï¼ˆé¢„å¤„ç†å¤šå±‚æ„ŸçŸ¥æœºï¼‰ç›¸ç»“åˆï¼Œç”¨äºä½“ç´ é¢„æ¸²æŸ“ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´æ—©åœ°æ•æ‰åœºæ™¯ç›¸å…³ä¿¡æ¯ï¼Œå¹¶æ›´å¥½åœ°åŒºåˆ†å™ªå£°ä¸å±€éƒ¨ç»†èŠ‚ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨æ¸è¿›å¼è¯­ä¹‰å»ºæ¨¡ä»¥é€æ­¥æå–è¯­ä¹‰ä¿¡æ¯ï¼Œä»è€Œå‡å°‘è®­ç»ƒæ—¶é—´å¹¶å¢å¼ºåœºæ™¯ç†è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPreSem-Surfåœ¨C-L1ã€F-scoreå’ŒIoUç­‰æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ï¼ŒåŒæ—¶åœ¨NCã€å‡†ç¡®ç‡å’Œå®Œæ•´æ€§æ–¹é¢ä¿æŒç«äº‰åŠ›ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œå®é™…åº”ç”¨æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³RGB-Dåºåˆ—ä¸­åœºæ™¯è¡¨é¢é‡å»ºçš„æ—¶é—´æ•ˆç‡å’Œè´¨é‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPreSem-Surfé€šè¿‡å¼•å…¥SG-MLPé‡‡æ ·ç»“æ„ä¸PR-MLPç›¸ç»“åˆï¼Œä¼˜åŒ–äº†ä½“ç´ é¢„æ¸²æŸ“è¿‡ç¨‹ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´æ—©åœ°æ•æ‰åœºæ™¯ä¿¡æ¯å¹¶æœ‰æ•ˆåŒºåˆ†å™ªå£°ä¸ç»†èŠ‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥æ¨¡å—ï¼ˆRGB-Dåºåˆ—ï¼‰ã€SG-MLPé‡‡æ ·æ¨¡å—ã€PR-MLPé¢„æ¸²æŸ“æ¨¡å—å’Œæ¸è¿›å¼è¯­ä¹‰å»ºæ¨¡æ¨¡å—ï¼Œé€æ­¥æå–å’Œæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ä»¥å®ç°é«˜æ•ˆé‡å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºSG-MLPä¸PR-MLPçš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†ä¿¡æ¯æ•æ‰çš„æ—¶æ•ˆæ€§å’Œå‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å™ªå£°å’Œç»†èŠ‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºè®¾è®¡ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†é’ˆå¯¹è¯­ä¹‰ä¿¡æ¯çš„ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥æé«˜é‡å»ºçš„ç²¾åº¦å’Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPreSem-Surfåœ¨C-L1ã€F-scoreå’ŒIoUæŒ‡æ ‡ä¸Šå‡è¡¨ç°æœ€ä½³ï¼Œåˆ†åˆ«è¶…è¶Šäº†å…¶ä»–åŸºçº¿æ–¹æ³•ï¼Œæå‡å¹…åº¦æ˜¾è‘—ã€‚åŒæ—¶ï¼Œåœ¨NCã€å‡†ç¡®ç‡å’Œå®Œæ•´æ€§æ–¹é¢ä¹Ÿä¿æŒäº†ç«äº‰åŠ›ï¼Œè¯æ˜äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PreSem-Surfæ–¹æ³•åœ¨æœºå™¨äººè§†è§‰ã€å¢å¼ºç°å®å’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡é«˜æ•ˆçš„åœºæ™¯é‡å»ºèƒ½åŠ›ï¼Œè¯¥æŠ€æœ¯èƒ½å¤Ÿä¸ºå®æ—¶ç¯å¢ƒç†è§£å’Œäº¤äº’æä¾›æ”¯æŒï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper proposes PreSem-Surf, an optimized method based on the Neural Radiance Field (NeRF) framework, capable of reconstructing high-quality scene surfaces from RGB-D sequences in a short time. The method integrates RGB, depth, and semantic information to improve reconstruction performance. Specifically, a novel SG-MLP sampling structure combined with PR-MLP (Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering, allowing the model to capture scene-related information earlier and better distinguish noise from local details. Furthermore, progressive semantic modeling is adopted to extract semantic information at increasing levels of precision, reducing training time while enhancing scene understanding. Experiments on seven synthetic scenes with six evaluation metrics show that PreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while maintaining competitive results in NC, Accuracy, and Completeness, demonstrating its effectiveness and practical applicability.

