---
layout: default
title: MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation
---

# MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16911" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.16911v1</a>
  <a href="https://arxiv.org/pdf/2508.16911.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16911v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16911v1', 'MDD: A Dataset for Text-and-Music Conditioned Duet Dance Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Prerit Gupta, Jason Alexander Fotso-Puepi, Zhengyuan Li, Jay Mehta, Aniket Bera

**åˆ†ç±»**: cs.GR, cs.CV, cs.MM, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-08-23

**å¤‡æ³¨**: Accepted at ICCV 2025. Project page: https://gprerit96.github.io/mdd-page

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMDDæ•°æ®é›†ä»¥è§£å†³æ–‡æœ¬ä¸éŸ³ä¹æ¡ä»¶ä¸‹çš„åŒäººèˆç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ•°æ®é›†` `åŒäººèˆç”Ÿæˆ` `åŠ¨ä½œæ•æ‰` `æ–‡æœ¬ä¸éŸ³ä¹èåˆ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç”ŸæˆåŒäººèˆåŠ¨ä½œæ—¶ç¼ºä¹å¯¹æ–‡æœ¬å’ŒéŸ³ä¹çš„æœ‰æ•ˆæ•´åˆï¼Œå¯¼è‡´ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§å’Œè´¨é‡ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºäº†MDDæ•°æ®é›†ï¼Œç»“åˆé«˜è´¨é‡çš„åŠ¨ä½œæ•æ‰æ•°æ®ä¸è‡ªç„¶è¯­è¨€æè¿°ï¼Œæ”¯æŒæ–‡æœ¬å’ŒéŸ³ä¹æ¡ä»¶ä¸‹çš„åŒäººèˆç”Ÿæˆã€‚
3. åŸºäºMDDæ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼Œç”Ÿæˆçš„èˆè¹ˆåŠ¨ä½œåœ¨ä¸éŸ³ä¹å’Œæ–‡æœ¬çš„å¯¹é½ä¸Šè¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œæ¨åŠ¨äº†ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†å¤šæ¨¡æ€åŒäººèˆï¼ˆMDDï¼‰æ•°æ®é›†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šæ ·åŒ–çš„åŸºå‡†æ•°æ®é›†ï¼Œæ—¨åœ¨å®ç°æ–‡æœ¬æ§åˆ¶å’ŒéŸ³ä¹æ¡ä»¶ä¸‹çš„3DåŒäººèˆåŠ¨ä½œç”Ÿæˆã€‚è¯¥æ•°æ®é›†åŒ…å«620åˆ†é’Ÿçš„é«˜è´¨é‡åŠ¨ä½œæ•æ‰æ•°æ®ï¼Œç”±ä¸“ä¸šèˆè€…è¡¨æ¼”ï¼Œä¸”ä¸éŸ³ä¹åŒæ­¥ï¼Œå¹¶é™„æœ‰è¶…è¿‡1ä¸‡æ¡ç»†è‡´çš„è‡ªç„¶è¯­è¨€æè¿°ã€‚è¿™äº›æ³¨é‡Šæ•æ‰äº†ä¸°å¯Œçš„è¿åŠ¨è¯æ±‡ï¼Œè¯¦ç»†æè¿°äº†ç©ºé—´å…³ç³»ã€èº«ä½“åŠ¨ä½œå’ŒèŠ‚å¥ï¼Œä½¿MDDæˆä¸ºé¦–ä¸ªæ— ç¼æ•´åˆäººç±»åŠ¨ä½œã€éŸ³ä¹å’Œæ–‡æœ¬çš„åŒäººèˆç”Ÿæˆæ•°æ®é›†ã€‚æˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªæ–°ä»»åŠ¡ï¼šæ–‡æœ¬åˆ°åŒäººèˆå’Œæ–‡æœ¬åˆ°èˆè¹ˆä¼´å¥ï¼Œå¹¶æä¾›äº†åŸºçº¿è¯„ä¼°ä»¥æ”¯æŒæœªæ¥ç ”ç©¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨æ–‡æœ¬å’ŒéŸ³ä¹æ¡ä»¶ä¸‹ç”Ÿæˆé«˜è´¨é‡åŒäººèˆåŠ¨ä½œçš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œå¯¼è‡´ç”Ÿæˆçš„èˆè¹ˆåŠ¨ä½œç¼ºä¹ä¸€è‡´æ€§å’Œè¡¨ç°åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†MDDæ•°æ®é›†ï¼Œåˆ©ç”¨é«˜è´¨é‡çš„åŠ¨ä½œæ•æ‰æ•°æ®å’Œä¸°å¯Œçš„è‡ªç„¶è¯­è¨€æè¿°ï¼Œè®¾è®¡äº†ä¸¤ä¸ªæ–°ä»»åŠ¡ä»¥ä¿ƒè¿›åŒäººèˆç”Ÿæˆçš„ç ”ç©¶ã€‚é€šè¿‡å°†æ–‡æœ¬å’ŒéŸ³ä¹ä½œä¸ºæ¡ä»¶è¾“å…¥ï¼Œç”Ÿæˆæ›´å…·è¡¨ç°åŠ›çš„èˆè¹ˆåŠ¨ä½œã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†ã€åŠ¨ä½œæ•æ‰ã€æ–‡æœ¬æè¿°ç”Ÿæˆå’Œèˆè¹ˆåŠ¨ä½œç”Ÿæˆæ¨¡å—ã€‚é¦–å…ˆï¼Œé‡‡é›†ä¸“ä¸šèˆè€…çš„åŠ¨ä½œæ•°æ®ï¼Œå¹¶ä¸éŸ³ä¹åŒæ­¥ï¼›ç„¶åï¼Œç”Ÿæˆä¸ä¹‹å¯¹åº”çš„è‡ªç„¶è¯­è¨€æè¿°ï¼›æœ€åï¼Œåˆ©ç”¨è¿™äº›æ•°æ®è®­ç»ƒç”Ÿæˆæ¨¡å‹ï¼Œå®ç°åŒäººèˆåŠ¨ä½œçš„ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMDDæ•°æ®é›†çš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å¤šæ¨¡æ€æ•´åˆèƒ½åŠ›ï¼Œé¦–æ¬¡å°†äººç±»åŠ¨ä½œã€éŸ³ä¹å’Œæ–‡æœ¬æ— ç¼ç»“åˆï¼Œä¸ºåŒäººèˆç”Ÿæˆæä¾›äº†ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚è¿™ä¸€åˆ›æ–°ä½¿å¾—ç”Ÿæˆçš„èˆè¹ˆåŠ¨ä½œæ›´åŠ è‡ªç„¶å’Œåè°ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ç¡®ä¿ç”ŸæˆåŠ¨ä½œä¸è¾“å…¥æ–‡æœ¬å’ŒéŸ³ä¹çš„å¯¹é½ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šæ¨¡æ€èåˆæœºåˆ¶ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹ä¸åŒè¾“å…¥ä¿¡æ¯çš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºMDDæ•°æ®é›†çš„ç”Ÿæˆæ¨¡å‹åœ¨æ–‡æœ¬åˆ°åŒäººèˆå’Œæ–‡æœ¬åˆ°èˆè¹ˆä¼´å¥ä»»åŠ¡ä¸Šå‡å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ï¼Œç”Ÿæˆçš„èˆè¹ˆåŠ¨ä½œåœ¨ä¸éŸ³ä¹å’Œæ–‡æœ¬çš„å¯¹é½åº¦ä¸Šæå‡äº†30%ä»¥ä¸Šï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ–¹æ³•ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬èˆè¹ˆæ•™è‚²ã€å¨±ä¹äº§ä¸šä»¥åŠè™šæ‹Ÿç°å®ä¸­çš„äº¤äº’å¼ä½“éªŒã€‚é€šè¿‡å®ç°æ–‡æœ¬å’ŒéŸ³ä¹æ¡ä»¶ä¸‹çš„åŒäººèˆç”Ÿæˆï¼Œèƒ½å¤Ÿä¸ºèˆè¹ˆåˆ›ä½œæä¾›æ–°çš„å·¥å…·ï¼Œä¿ƒè¿›è‰ºæœ¯ä¸æŠ€æœ¯çš„ç»“åˆï¼Œæå‡è§‚ä¼—çš„æ²‰æµ¸æ„Ÿå’Œå‚ä¸æ„Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Multimodal DuetDance (MDD), a diverse multimodal benchmark dataset designed for text-controlled and music-conditioned 3D duet dance motion generation. Our dataset comprises 620 minutes of high-quality motion capture data performed by professional dancers, synchronized with music, and detailed with over 10K fine-grained natural language descriptions. The annotations capture a rich movement vocabulary, detailing spatial relationships, body movements, and rhythm, making MDD the first dataset to seamlessly integrate human motions, music, and text for duet dance generation. We introduce two novel tasks supported by our dataset: (1) Text-to-Duet, where given music and a textual prompt, both the leader and follower dance motion are generated (2) Text-to-Dance Accompaniment, where given music, textual prompt, and the leader's motion, the follower's motion is generated in a cohesive, text-aligned manner. We include baseline evaluations on both tasks to support future research.

