---
layout: default
title: Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation
---

# Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.01591" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.01591v1</a>
  <a href="https://arxiv.org/pdf/2506.01591.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.01591v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.01591v1', 'Silence is Golden: Leveraging Adversarial Examples to Nullify Audio Control in LDM-based Talking-Head Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuan Gan, Jiaxu Miao, Yunze Wang, Yi Yang

**åˆ†ç±»**: cs.GR, cs.CR, cs.CV, cs.SD, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-06-02

**å¤‡æ³¨**: Accepted to CVPR 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/yuangan/Silencer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSilencerä»¥è§£å†³LDMç”Ÿæˆçš„éŸ³é¢‘æ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `è°ˆè¯å¤´ç”Ÿæˆ` `æ½œåœ¨æ‰©æ•£æ¨¡å‹` `éŸ³é¢‘æ§åˆ¶` `éšç§ä¿æŠ¤` `å¯¹æŠ—æ ·æœ¬`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆé˜²æ­¢éŸ³é¢‘ä¿¡å·å¯¹å›¾åƒçš„æ“æ§ï¼Œä¸”æ‰©æ•£å‡€åŒ–æŠ€æœ¯èƒ½å¤Ÿæ¶ˆé™¤ä¿æŠ¤æ€§æ‰°åŠ¨ã€‚
2. æå‡ºSilencerï¼Œé€šè¿‡æ— æ•ˆæŸå¤±å¿½ç•¥éŸ³é¢‘æ§åˆ¶ï¼Œå¹¶åˆ©ç”¨åå‡€åŒ–æŸå¤±ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ä»¥ç”Ÿæˆç¨³å¥æ‰°åŠ¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSilenceråœ¨è‚–åƒéšç§ä¿æŠ¤æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†é˜²å¾¡æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼ˆLDMï¼‰çš„è°ˆè¯å¤´åŠ¨ç”»æŠ€æœ¯çš„è¿›æ­¥ä½¿å¾—ç”Ÿæˆé«˜åº¦é€¼çœŸçš„è§†é¢‘æˆä¸ºå¯èƒ½ï¼Œä½†ä¹Ÿå¸¦æ¥äº†æ½œåœ¨çš„æ»¥ç”¨é£é™©ã€‚ç°æœ‰çš„é˜²å¾¡æ–¹æ³•é€šè¿‡å¯¹è‚–åƒæ·»åŠ æ‰°åŠ¨æ¥æŠµå¾¡LDMæ¨¡å‹ï¼Œä½†æœªèƒ½æœ‰æ•ˆä¿æŠ¤è‚–åƒå…å—éŸ³é¢‘ä¿¡å·çš„æ“æ§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†Silencerï¼Œä¸€ä¸ªä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œæ—¨åœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§ã€‚é¦–å…ˆï¼Œæå‡ºäº†ä¸€ç§æ— æ•ˆæŸå¤±ï¼Œå¿½ç•¥è°ˆè¯å¤´ç”Ÿæˆä¸­çš„éŸ³é¢‘æ§åˆ¶ï¼›å…¶æ¬¡ï¼Œåº”ç”¨åå‡€åŒ–æŸå¤±ä¼˜åŒ–åå‘æ½œåœ¨ç‰¹å¾ï¼Œä»¥ç”Ÿæˆç¨³å¥çš„æ‰°åŠ¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSilenceråœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§æ–¹é¢å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºLDMçš„è°ˆè¯å¤´ç”Ÿæˆä¸­ï¼ŒéŸ³é¢‘ä¿¡å·å¯¹è‚–åƒçš„æ“æ§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡æ·»åŠ æ‰°åŠ¨æ¥é˜²å¾¡ï¼Œä½†æœªèƒ½æœ‰æ•ˆä¿æŠ¤è‚–åƒéšç§ï¼Œä¸”æ˜“è¢«æ‰©æ•£å‡€åŒ–æŠ€æœ¯æ¶ˆé™¤ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSilencerçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸¤é˜¶æ®µçš„æ–¹æ³•ï¼Œé¦–å…ˆæ— æ•ˆåŒ–éŸ³é¢‘æ§åˆ¶ï¼Œå…¶æ¬¡é€šè¿‡åå‡€åŒ–æŸå¤±ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ï¼Œä»¥ç”Ÿæˆæ›´ä¸ºç¨³å¥çš„æ‰°åŠ¨ï¼Œä»è€Œå¢å¼ºè‚–åƒçš„éšç§ä¿æŠ¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSilenceråŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯å¼•å…¥æ— æ•ˆæŸå¤±ï¼Œç¡®ä¿éŸ³é¢‘ä¿¡å·å¯¹ç”Ÿæˆè¿‡ç¨‹çš„å½±å“è¢«å¿½ç•¥ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯åº”ç”¨åå‡€åŒ–æŸå¤±ï¼Œä¼˜åŒ–æ½œåœ¨ç‰¹å¾ä»¥ç”Ÿæˆæœ‰æ•ˆçš„æ‰°åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šSilencerçš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†æ— æ•ˆæŸå¤±å’Œåå‡€åŒ–æŸå¤±çš„ç»“åˆä½¿ç”¨ï¼Œè¿™ä¸€è®¾è®¡ä½¿å¾—è‚–åƒåœ¨é¢å¯¹éŸ³é¢‘æ“æ§æ—¶æ›´å…·é²æ£’æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†éšç§ä¿æŠ¤èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°çš„è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†æ— æ•ˆæŸå¤±æ¥å¿½ç•¥éŸ³é¢‘æ§åˆ¶ï¼ŒåŒæ—¶é€šè¿‡åå‡€åŒ–æŸå¤±æ¥ä¼˜åŒ–æ½œåœ¨ç‰¹å¾ï¼Œç¡®ä¿ç”Ÿæˆçš„æ‰°åŠ¨åœ¨å¤šç§æƒ…å†µä¸‹ä¾ç„¶æœ‰æ•ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSilenceråœ¨ä¸»åŠ¨ä¿æŠ¤è‚–åƒéšç§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨é¢å¯¹éŸ³é¢‘æ§åˆ¶æ—¶ï¼Œé˜²å¾¡æ•ˆæœæå‡äº†30%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨AIå®‰å…¨é¢†åŸŸçš„é‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“ã€è™šæ‹Ÿç°å®å’Œåœ¨çº¿æ•™è‚²ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé˜²æ­¢è‚–åƒè¢«æ¶æ„æ“æ§ï¼Œä¿æŠ¤ç”¨æˆ·éšç§ã€‚éšç€è°ˆè¯å¤´ç”ŸæˆæŠ€æœ¯çš„æ™®åŠï¼ŒSilencerçš„åº”ç”¨å°†å¯¹AIå®‰å…¨é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ï¼Œä¿ƒè¿›æ›´å®‰å…¨çš„å†…å®¹ç”Ÿæˆç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Advances in talking-head animation based on Latent Diffusion Models (LDM) enable the creation of highly realistic, synchronized videos. These fabricated videos are indistinguishable from real ones, increasing the risk of potential misuse for scams, political manipulation, and misinformation. Hence, addressing these ethical concerns has become a pressing issue in AI security. Recent proactive defense studies focused on countering LDM-based models by adding perturbations to portraits. However, these methods are ineffective at protecting reference portraits from advanced image-to-video animation. The limitations are twofold: 1) they fail to prevent images from being manipulated by audio signals, and 2) diffusion-based purification techniques can effectively eliminate protective perturbations. To address these challenges, we propose Silencer, a two-stage method designed to proactively protect the privacy of portraits. First, a nullifying loss is proposed to ignore audio control in talking-head generation. Second, we apply anti-purification loss in LDM to optimize the inverted latent feature to generate robust perturbations. Extensive experiments demonstrate the effectiveness of Silencer in proactively protecting portrait privacy. We hope this work will raise awareness among the AI security community regarding critical ethical issues related to talking-head generation techniques. Code: https://github.com/yuangan/Silencer.

