---
layout: default
title: Occlusion-robust Stylization for Drawing-based 3D Animation
---

# Occlusion-robust Stylization for Drawing-based 3D Animation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.00398" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.00398v1</a>
  <a href="https://arxiv.org/pdf/2508.00398.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.00398v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.00398v1', 'Occlusion-robust Stylization for Drawing-based 3D Animation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sunjae Yoon, Gwanhyeong Koo, Younghwan Lee, Ji Woo Hong, Chang D. Yoo

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-01

**å¤‡æ³¨**: 11 pages, 13 figures, ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæŠ—é®æŒ¡é£æ ¼åŒ–æ¡†æ¶ä»¥è§£å†³ç»˜ç”»åŸºç¡€3DåŠ¨ç”»ä¸­çš„é£æ ¼æŸå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3DåŠ¨ç”»` `é£æ ¼åŒ–` `é®æŒ¡å¤„ç†` `å…‰æµæŠ€æœ¯` `è®¡ç®—æœºè§†è§‰` `è‰ºæœ¯é£æ ¼ä¿æŒ` `åŠ¨æ€è¿åŠ¨` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç»˜ç”»åŸºç¡€3DåŠ¨ç”»æ–¹æ³•åœ¨é®æŒ¡æƒ…å†µä¸‹é£æ ¼å±æ€§è´¨é‡ä¸‹é™ï¼Œå¯¼è‡´è½®å»“é—ªçƒå’Œç¬”è§¦æ¨¡ç³Šã€‚
2. æœ¬æ–‡æå‡ºçš„æŠ—é®æŒ¡é£æ ¼åŒ–æ¡†æ¶ï¼ˆOSFï¼‰é€šè¿‡å…‰æµæä¾›æŠ—é®æŒ¡çš„è¾¹ç¼˜å¼•å¯¼ï¼Œç¡®ä¿é£æ ¼ä¸€è‡´æ€§ã€‚
3. OSFåœ¨å•æ¬¡è¿è¡Œä¸­å®Œæˆä»»åŠ¡ï¼Œæ¨ç†é€Ÿåº¦æé«˜2.4å€ï¼Œå†…å­˜ä½¿ç”¨å‡å°‘2.1å€ï¼Œæ˜¾è‘—æå‡äº†æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3DåŠ¨ç”»æ—¨åœ¨ä»è¾“å…¥å›¾åƒå’Œç›®æ ‡3Dè¿åŠ¨åºåˆ—ç”Ÿæˆ3DåŠ¨ç”»è§†é¢‘ã€‚è¿‘å¹´æ¥ï¼Œå›¾åƒåˆ°3Dæ¨¡å‹çš„è¿›å±•ä½¿å¾—ç”¨æˆ·æ‰‹ç»˜å›¾åƒèƒ½å¤Ÿç›´æ¥ç”ŸæˆåŠ¨ç”»ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨é®æŒ¡æƒ…å†µä¸‹ä»ç„¶è¡¨ç°å‡ºé£æ ¼å±æ€§çš„è´¨é‡ä¸‹é™ï¼Œå¯¼è‡´è½®å»“é—ªçƒå’Œç¬”è§¦æ¨¡ç³Šã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†æŠ—é®æŒ¡é£æ ¼åŒ–æ¡†æ¶ï¼ˆOSFï¼‰ï¼Œé€šè¿‡ä½¿ç”¨å…‰æµæä¾›æŠ—é®æŒ¡çš„è¾¹ç¼˜å¼•å¯¼ï¼Œç¡®ä¿åœ¨åŠ¨æ€è¿åŠ¨ä¸‹çš„é£æ ¼ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼ŒOSFåœ¨å•æ¬¡è¿è¡Œä¸­å®Œæˆä»»åŠ¡ï¼Œç›¸æ¯”äºä»¥å¾€çš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œæ¨ç†é€Ÿåº¦æé«˜äº†2.4å€ï¼Œå†…å­˜ä½¿ç”¨å‡å°‘äº†2.1å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç»˜ç”»åŸºç¡€3DåŠ¨ç”»æ–¹æ³•åœ¨å¤„ç†é®æŒ¡æ—¶ï¼Œå› è®­ç»ƒå’Œæ¨ç†é˜¶æ®µçš„å§¿æ€å·®å¼‚ï¼Œå¯¼è‡´é£æ ¼å±æ€§çš„è´¨é‡ä¸‹é™ï¼Œè¡¨ç°ä¸ºè½®å»“é—ªçƒå’Œç¬”è§¦æ¨¡ç³Šã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„æŠ—é®æŒ¡é£æ ¼åŒ–æ¡†æ¶ï¼ˆOSFï¼‰é€šè¿‡å¼•å…¥å…‰æµæŠ€æœ¯ï¼Œæä¾›æŠ—é®æŒ¡çš„è¾¹ç¼˜å¼•å¯¼ï¼Œä»è€Œåœ¨åŠ¨æ€è¿åŠ¨ä¸‹ä¿æŒé£æ ¼ä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOSFçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥å›¾åƒå¤„ç†ã€å…‰æµè®¡ç®—ã€è¾¹ç¼˜å¼•å¯¼ç”Ÿæˆå’Œé£æ ¼åŒ–ç½‘ç»œå››ä¸ªä¸»è¦æ¨¡å—ï¼Œç¡®ä¿åœ¨å•æ¬¡è¿è¡Œä¸­å®Œæˆé£æ ¼åŒ–ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šOSFçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶æŠ—é®æŒ¡çš„è¾¹ç¼˜å¼•å¯¼æœºåˆ¶ï¼Œåˆ©ç”¨å…‰æµæŠ€æœ¯å…‹æœäº†ä¼ ç»Ÿæ–¹æ³•åœ¨é®æŒ¡æƒ…å†µä¸‹çš„ä¸è¶³ï¼Œä¿è¯äº†é£æ ¼åŒ–çš„ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒOSFä¼˜åŒ–äº†å…‰æµè®¡ç®—çš„ç²¾åº¦ï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§æŸå¤±å‡½æ•°ï¼Œä»¥å¹³è¡¡é£æ ¼ä¿æŒä¸è¿åŠ¨åŠ¨æ€ä¹‹é—´çš„å…³ç³»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒOSFåœ¨æ¨ç†é€Ÿåº¦ä¸Šæé«˜äº†2.4å€ï¼Œå†…å­˜ä½¿ç”¨å‡å°‘äº†2.1å€ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†æ•ˆç‡å’Œé£æ ¼ä¿æŒèƒ½åŠ›ï¼Œå°¤å…¶åœ¨åŠ¨æ€é®æŒ¡åœºæ™¯ä¸­è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŠ¨ç”»åˆ¶ä½œã€æ¸¸æˆå¼€å‘å’Œè™šæ‹Ÿç°å®ç­‰ï¼Œèƒ½å¤Ÿä¸ºè‰ºæœ¯å®¶æä¾›æ›´é«˜æ•ˆçš„å·¥å…·ï¼Œå¸®åŠ©ä»–ä»¬åœ¨åŠ¨æ€åœºæ™¯ä¸­ä¿æŒç‹¬ç‰¹çš„è‰ºæœ¯é£æ ¼ã€‚æœªæ¥ï¼ŒOSFå¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„åˆ›æ„äº§ä¸šå‘å±•ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œåˆ›ä½œè‡ªç”±åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D animation aims to generate a 3D animated video from an input image and a target 3D motion sequence. Recent advances in image-to-3D models enable the creation of animations directly from user-hand drawings. Distinguished from conventional 3D animation, drawing-based 3D animation is crucial to preserve artist's unique style properties, such as rough contours and distinct stroke patterns. However, recent methods still exhibit quality deterioration in style properties, especially under occlusions caused by overlapping body parts, leading to contour flickering and stroke blurring. This occurs due to a `stylization pose gap' between training and inference in stylization networks designed to preserve drawing styles in drawing-based 3D animation systems. The stylization pose gap denotes that input target poses used to train the stylization network are always in occlusion-free poses, while target poses encountered in an inference include diverse occlusions under dynamic motions. To this end, we propose Occlusion-robust Stylization Framework (OSF) for drawing-based 3D animation. We found that while employing object's edge can be effective input prior for guiding stylization, it becomes notably inaccurate when occlusions occur at inference. Thus, our proposed OSF provides occlusion-robust edge guidance for stylization network using optical flow, ensuring a consistent stylization even under occlusions. Furthermore, OSF operates in a single run instead of the previous two-stage method, achieving 2.4x faster inference and 2.1x less memory.

