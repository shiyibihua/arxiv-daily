---
layout: default
title: WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance
---

# WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15130" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15130v2</a>
  <a href="https://arxiv.org/pdf/2509.15130.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15130v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15130v2', 'WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenxi Song, Yanming Yang, Tong Zhao, Ruibo Li, Chi Zhang

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-09-27)

**å¤‡æ³¨**: Project Webpage: https://worldforge-agi.github.io/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºWorldForgeä»¥è§£å†³è§†é¢‘æ‰©æ•£æ¨¡å‹çš„æ§åˆ¶æ€§ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `è§†é¢‘æ‰©æ•£æ¨¡å‹` `è½¨è¿¹å¼•å¯¼` `æ—¶ç©ºä¸€è‡´æ€§` `æ— è®­ç»ƒæ¨ç†` `å…‰æµè§£è€¦` `è‡ªé€‚åº”ä¿®æ­£` `3Dç”Ÿæˆ` `å†…å®¹ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨å¯æ§æ€§ã€æ—¶ç©ºä¸€è‡´æ€§å’Œåœºæ™¯åŠ¨æ€å¤„ç†ä¸Šå­˜åœ¨æ˜¾è‘—ä¸è¶³ï¼Œå½±å“å…¶åœ¨ç©ºé—´æ™ºèƒ½ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„WorldForgeæ¡†æ¶é€šè¿‡ä¸‰ä¸ªæ¨¡å—å®ç°æ— è®­ç»ƒçš„æ¨ç†ï¼Œæä¾›ç»†ç²’åº¦çš„è½¨è¿¹å¼•å¯¼ï¼Œç¡®ä¿è¿åŠ¨ä¸ç›®æ ‡è·¯å¾„ä¸€è‡´ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒWorldForgeåœ¨è½¨è¿¹éµå¾ªã€å‡ ä½•ä¸€è‡´æ€§å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºç°æœ‰çš„è®­ç»ƒå¯†é›†å‹å’Œä»…æ¨ç†åŸºçº¿ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸçš„è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨ç©ºé—´æ™ºèƒ½ä»»åŠ¡ä¸­å±•ç°å‡ºå·¨å¤§æ½œåŠ›ï¼Œä½†ç”±äºå¯æ§æ€§æœ‰é™ã€æ—¶ç©ºä¸€è‡´æ€§å·®ä»¥åŠåœºæ™¯ä¸ç›¸æœºåŠ¨æ€çº ç¼ ç­‰é—®é¢˜ï¼Œè¿™ä¸€æ½œåŠ›å—åˆ°å‰Šå¼±ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆå¦‚æ¨¡å‹å¾®è°ƒå’ŒåŸºäºå˜å½¢çš„é‡ç»˜åœ¨å¯æ‰©å±•æ€§ã€æ³›åŒ–èƒ½åŠ›å’ŒæŠ—ä¼ªå½±æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†WorldForgeï¼Œä¸€ä¸ªæ— è®­ç»ƒçš„æ¨ç†æ—¶æ¡†æ¶ï¼Œç”±ä¸‰ä¸ªç´§å¯†è€¦åˆçš„æ¨¡å—ç»„æˆï¼š1) åœ¨å»å™ªæ­¥éª¤ä¸­é€šè¿‡é€’å½’ä¿®æ­£å¾ªç¯æ³¨å…¥ç»†ç²’åº¦è½¨è¿¹å¼•å¯¼ï¼Œç¡®ä¿è¿åŠ¨ä¸ç›®æ ‡è·¯å¾„å¯¹é½ï¼›2) åˆ©ç”¨å…‰æµç›¸ä¼¼æ€§åœ¨æ½œåœ¨ç©ºé—´ä¸­è§£è€¦è¿åŠ¨ä¸å¤–è§‚ï¼Œå¹¶é€‰æ‹©æ€§åœ°å°†è½¨è¿¹å¼•å¯¼æ³¨å…¥ä¸è¿åŠ¨ç›¸å…³çš„é€šé“ï¼›3) æ¯”è¾ƒå¼•å¯¼ä¸æœªå¼•å¯¼çš„å»å™ªè·¯å¾„ï¼Œè‡ªé€‚åº”ä¿®æ­£å› å™ªå£°æˆ–ç»“æ„ä¿¡å·ä¸å¯¹é½é€ æˆçš„è½¨è¿¹æ¼‚ç§»ã€‚é€šè¿‡è¿™äº›ç»„ä»¶ï¼ŒWorldForgeåœ¨ä¸è¿›è¡Œè®­ç»ƒçš„æƒ…å†µä¸‹å®ç°äº†ç²¾ç¡®çš„è¿åŠ¨æ§åˆ¶å’Œé€¼çœŸçš„å†…å®¹ç”Ÿæˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘æ‰©æ•£æ¨¡å‹åœ¨å¯æ§æ€§ã€æ—¶ç©ºä¸€è‡´æ€§å’Œåœºæ™¯åŠ¨æ€å¤„ç†æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¦‚å¾®è°ƒå’Œé‡ç»˜åœ¨å¯æ‰©å±•æ€§å’ŒæŠ—ä¼ªå½±èƒ½åŠ›ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šWorldForgeé€šè¿‡æ— è®­ç»ƒçš„æ¨ç†æ¡†æ¶ï¼Œåˆ©ç”¨ç»†ç²’åº¦çš„è½¨è¿¹å¼•å¯¼æ¥å¢å¼ºæ¨¡å‹çš„è¿åŠ¨æ§åˆ¶èƒ½åŠ›ï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹çš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ç”±ä¸‰ä¸ªä¸»è¦æ¨¡å—ç»„æˆï¼š1) Intra-Step Recursive Refinementç”¨äºåœ¨å»å™ªæ­¥éª¤ä¸­æ³¨å…¥è½¨è¿¹å¼•å¯¼ï¼›2) Flow-Gated Latent Fusioné€šè¿‡å…‰æµç›¸ä¼¼æ€§è§£è€¦è¿åŠ¨ä¸å¤–è§‚ï¼›3) Dual-Path Self-Corrective Guidanceç”¨äºè‡ªé€‚åº”ä¿®æ­£è½¨è¿¹æ¼‚ç§»ã€‚

**å…³é”®åˆ›æ–°**ï¼šWorldForgeçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶æ— è®­ç»ƒçš„è®¾è®¡ï¼Œèƒ½å¤Ÿåœ¨æ¨ç†é˜¶æ®µåŠ¨æ€è°ƒæ•´è½¨è¿¹å¼•å¯¼ï¼Œæ˜¾è‘—æå‡äº†è¿åŠ¨æ§åˆ¶çš„ç²¾åº¦å’Œç”Ÿæˆå†…å®¹çš„çœŸå®æ„Ÿã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é€’å½’ä¿®æ­£å¾ªç¯ã€å…‰æµç›¸ä¼¼æ€§åˆ†æå’Œè·¯å¾„æ¯”è¾ƒæœºåˆ¶ï¼Œç¡®ä¿äº†è¿åŠ¨ä¸å¤–è§‚çš„æœ‰æ•ˆè§£è€¦å’Œè½¨è¿¹çš„ç²¾ç¡®å¼•å¯¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒWorldForgeåœ¨è½¨è¿¹éµå¾ªæ€§ã€å‡ ä½•ä¸€è‡´æ€§å’Œæ„ŸçŸ¥è´¨é‡ä¸Šå‡è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ°´å¹³ï¼Œç›¸è¾ƒäºè®­ç»ƒå¯†é›†å‹å’Œä»…æ¨ç†çš„åŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

WorldForgeçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬è™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿä»¥åŠå½±è§†ç‰¹æ•ˆåˆ¶ä½œç­‰ã€‚å…¶æ— è®­ç»ƒçš„ç‰¹æ€§ä½¿å¾—è¯¥æ¡†æ¶èƒ½å¤Ÿå¿«é€Ÿé€‚åº”ä¸åŒçš„3D/4Dä»»åŠ¡ï¼Œæå‡å†…å®¹ç”Ÿæˆçš„æ•ˆç‡å’Œè´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent video diffusion models show immense potential for spatial intelligence tasks due to their rich world priors, but this is undermined by limited controllability, poor spatial-temporal consistency, and entangled scene-camera dynamics. Existing solutions, such as model fine-tuning and warping-based repainting, struggle with scalability, generalization, and robustness against artifacts. To address this, we propose WorldForge, a training-free, inference-time framework composed of three tightly coupled modules. 1) Intra-Step Recursive Refinement injects fine-grained trajectory guidance at denoising steps through a recursive correction loop, ensuring motion remains aligned with the target path. 2) Flow-Gated Latent Fusion leverages optical flow similarity to decouple motion from appearance in the latent space and selectively inject trajectory guidance into motion-related channels. 3) Dual-Path Self-Corrective Guidance compares guided and unguided denoising paths to adaptively correct trajectory drift caused by noisy or misaligned structural signals. Together, these components inject fine-grained, trajectory-aligned guidance without training, achieving both accurate motion control and photorealistic content generation. Our framework is plug-and-play and model-agnostic, enabling broad applicability across various 3D/4D tasks. Extensive experiments demonstrate that our method achieves state-of-the-art performance in trajectory adherence, geometric consistency, and perceptual quality, outperforming both training-intensive and inference-only baselines.

