---
layout: default
title: MienCap: Realtime Performance-Based Facial Animation with Live Mood Dynamics
---

# MienCap: Realtime Performance-Based Facial Animation with Live Mood Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04687" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04687v1</a>
  <a href="https://arxiv.org/pdf/2508.04687.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04687v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04687v1', 'MienCap: Realtime Performance-Based Facial Animation with Live Mood Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ye Pan, Ruisi Zhang, Jingying Wang, Nengfu Chen, Yilin Qiu, Yu Ding, Kenny Mitchell

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: IEEE VR extended authors version of the article published in 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW). This work was supported by the European Union's Horizon 2020 research and innovation programme under Grant 101017779

**DOI**: [10.1109/VRW55335.2022.00178](https://doi.org/10.1109/VRW55335.2022.00178)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMienCapä»¥è§£å†³å®æ—¶è¡¨æƒ…åŠ¨ç”»çš„è¡¨ç°åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)**

**å…³é”®è¯**: `è¡¨æƒ…åŠ¨ç”»` `3Dè§’è‰²` `æœºå™¨å­¦ä¹ ` `å®æ—¶ç³»ç»Ÿ` `æƒ…æ„Ÿè½¬ç§»` `æ··åˆå½¢çŠ¶åŠ¨ç”»` `åŠ¨ç”»åˆ¶ä½œ` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºæ€§èƒ½çš„åŠ¨ç”»æŠ€æœ¯åœ¨é©±åŠ¨3Dè§’è‰²è¡¨æƒ…æ—¶ï¼Œå¾€å¾€ç¼ºä¹çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ï¼Œéš¾ä»¥æ»¡è¶³åŠ¨ç”»å¸ˆçš„éœ€æ±‚ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†MienCapç³»ç»Ÿï¼Œç»“åˆä¼ ç»Ÿæ··åˆå½¢çŠ¶åŠ¨ç”»ä¸æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæä¾›äº†é«˜æ•ˆçš„å®æ—¶å’Œéå®æ—¶è¡¨æƒ…ç”Ÿæˆæ–¹æ¡ˆã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMienCapåœ¨è¡¨æƒ…è¯†åˆ«ã€å¼ºåº¦å’Œå¸å¼•åŠ›æ–¹é¢çš„è¯„åˆ†å‡æ˜¾è‘—é«˜äºç°æœ‰çš„Facewareäº§å“ï¼Œæå‡äº†åŠ¨ç”»åˆ¶ä½œçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶æ—¨åœ¨æå‡åŸºäºæ€§èƒ½çš„åŠ¨ç”»æŠ€æœ¯ï¼Œä»¥é©±åŠ¨çœŸå®æ„Ÿçš„3Dé£æ ¼åŒ–è§’è‰²è¡¨æƒ…ã€‚é€šè¿‡ç»“åˆä¼ ç»Ÿçš„æ··åˆå½¢çŠ¶åŠ¨ç”»æŠ€æœ¯ä¸å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæå‡ºäº†éå®æ—¶å’Œå®æ—¶è§£å†³æ–¹æ¡ˆï¼Œç¡®ä¿è§’è‰²è¡¨æƒ…åœ¨å‡ ä½•ä¸€è‡´æ€§å’Œæ„ŸçŸ¥æœ‰æ•ˆæ€§ä¸Šçš„è¡¨ç°ã€‚éå®æ—¶ç³»ç»Ÿä¸­ï¼Œæå‡ºäº†ä¸€ä¸ª3Dæƒ…æ„Ÿè½¬ç§»ç½‘ç»œï¼Œåˆ©ç”¨2Däººåƒç”Ÿæˆé£æ ¼åŒ–çš„3Déª¨æ¶å‚æ•°ï¼›å®æ—¶ç³»ç»Ÿä¸­ï¼Œæå‡ºäº†æ··åˆå½¢çŠ¶é€‚åº”ç½‘ç»œï¼Œç”Ÿæˆå…·æœ‰å‡ ä½•ä¸€è‡´æ€§å’Œæ—¶é—´ç¨³å®šæ€§çš„è§’è‰²éª¨æ¶å‚æ•°è¿åŠ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸å•†ä¸šäº§å“Facewareç›¸æ¯”ï¼Œä½¿ç”¨æœ¬ç³»ç»Ÿç”Ÿæˆçš„è§’è‰²è¡¨æƒ…åœ¨è¯†åˆ«åº¦ã€å¼ºåº¦å’Œå¸å¼•åŠ›ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç°æœ‰åŸºäºæ€§èƒ½çš„åŠ¨ç”»æŠ€æœ¯åœ¨ç”Ÿæˆ3Dè§’è‰²è¡¨æƒ…æ—¶ç¼ºä¹çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•åœ¨å‡ ä½•ä¸€è‡´æ€§å’Œæ„ŸçŸ¥æœ‰æ•ˆæ€§ä¸Šè¾¾åˆ°ç†æƒ³æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„MienCapç³»ç»Ÿé€šè¿‡ç»“åˆä¼ ç»Ÿçš„æ··åˆå½¢çŠ¶åŠ¨ç”»æŠ€æœ¯ä¸å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæä¾›äº†é«˜æ•ˆçš„å®æ—¶å’Œéå®æ—¶è¡¨æƒ…ç”Ÿæˆæ–¹æ¡ˆï¼Œä»¥æå‡è§’è‰²è¡¨æƒ…çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMienCapç³»ç»Ÿåˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šéå®æ—¶ç³»ç»Ÿä½¿ç”¨3Dæƒ…æ„Ÿè½¬ç§»ç½‘ç»œï¼Œä»2Däººåƒç”Ÿæˆé£æ ¼åŒ–çš„3Déª¨æ¶å‚æ•°ï¼›å®æ—¶ç³»ç»Ÿåˆ™åˆ©ç”¨æ··åˆå½¢çŠ¶é€‚åº”ç½‘ç»œï¼Œç”Ÿæˆå…·æœ‰å‡ ä½•ä¸€è‡´æ€§å’Œæ—¶é—´ç¨³å®šæ€§çš„è§’è‰²éª¨æ¶å‚æ•°è¿åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†3Dæƒ…æ„Ÿè½¬ç§»ç½‘ç»œå’Œæ··åˆå½¢çŠ¶é€‚åº”ç½‘ç»œï¼Œè¿™äº›ç½‘ç»œèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†2Då›¾åƒä¿¡æ¯è½¬åŒ–ä¸º3DåŠ¨ç”»å‚æ•°ï¼Œæ˜¾è‘—æå‡äº†è¡¨æƒ…ç”Ÿæˆçš„è´¨é‡ä¸æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œè®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ç¡®ä¿ç”Ÿæˆçš„è¡¨æƒ…åœ¨å‡ ä½•å’Œæ—¶é—´ä¸Šçš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ç½‘ç»œç»“æ„ä»¥æé«˜å®æ—¶å¤„ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMienCapç³»ç»Ÿåœ¨è¡¨æƒ…è¯†åˆ«ã€å¼ºåº¦å’Œå¸å¼•åŠ›æ–¹é¢çš„è¯„åˆ†å‡æ˜¾è‘—é«˜äºFacewareï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°ç»Ÿè®¡å­¦æ˜¾è‘—æ€§ï¼ŒéªŒè¯äº†è¯¥ç³»ç»Ÿåœ¨ç”Ÿæˆé«˜è´¨é‡è§’è‰²è¡¨æƒ…æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MienCapç³»ç»Ÿå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨åŠ¨ç”»åˆ¶ä½œã€æ¸¸æˆå¼€å‘å’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸã€‚é€šè¿‡æé«˜è§’è‰²è¡¨æƒ…çš„çœŸå®æ„Ÿå’Œè¡¨ç°åŠ›ï¼ŒåŠ¨ç”»å¸ˆå¯ä»¥æ›´å¿«é€Ÿã€å‡†ç¡®åœ°åˆ›å»ºæ‰€éœ€çš„è¡¨æƒ…ï¼Œæå‡ä½œå“çš„æ•´ä½“è´¨é‡å’Œè§‚ä¼—çš„æ²‰æµ¸æ„Ÿã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯èƒ½æ‰©å±•åˆ°ç¤¾äº¤åª’ä½“å’Œåœ¨çº¿äº¤æµä¸­ï¼Œå¢å¼ºè™šæ‹Ÿè§’è‰²çš„äº’åŠ¨æ€§å’Œè¡¨ç°åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Our purpose is to improve performance-based animation which can drive believable 3D stylized characters that are truly perceptual. By combining traditional blendshape animation techniques with multiple machine learning models, we present both non-real time and real time solutions which drive character expressions in a geometrically consistent and perceptually valid way. For the non-real time system, we propose a 3D emotion transfer network makes use of a 2D human image to generate a stylized 3D rig parameters. For the real time system, we propose a blendshape adaption network which generates the character rig parameter motions with geometric consistency and temporally stability. We demonstrate the effectiveness of our system by comparing to a commercial product Faceware. Results reveal that ratings of the recognition, intensity, and attractiveness of expressions depicted for animated characters via our systems are statistically higher than Faceware. Our results may be implemented into the animation pipeline, and provide animators with a system for creating the expressions they wish to use more quickly and accurately.

