---
layout: default
title: 3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation
---

# 3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26233" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.26233v1</a>
  <a href="https://arxiv.org/pdf/2509.26233.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26233v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26233v1', '3DiFACE: Synthesizing and Editing Holistic 3D Facial Animation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Balamurugan Thambiraja, Malte Prinzler, Sadegh Aliakbarian, Darren Cosker, Justus Thies

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://balamuruganthambiraja.github.io/3DiFACE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡º3DiFACEï¼Œç”¨äºåˆæˆå’Œç¼–è¾‘å…·æœ‰çœŸå®å¤´éƒ¨è¿åŠ¨çš„æ•´ä½“3Dé¢éƒ¨åŠ¨ç”»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `3Dé¢éƒ¨åŠ¨ç”»` `è¯­éŸ³é©±åŠ¨` `æ‰©æ•£æ¨¡å‹` `é£æ ¼ä¸ªæ€§åŒ–` `è¿åŠ¨ç¼–è¾‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³é©±åŠ¨çš„3Dé¢éƒ¨åŠ¨ç”»æ–¹æ³•éš¾ä»¥å®ç°ç²¾ç¡®æ§åˆ¶å’ŒçœŸå®å¤´éƒ¨è¿åŠ¨çš„ä¸ªæ€§åŒ–åŠ¨ç”»ï¼Œä¸”ç¼–è¾‘å¤æ‚è€—æ—¶ã€‚
2. 3DiFACEæå‡ºä¸€ç§å®Œå…¨å·ç§¯æ‰©æ•£æ¨¡å‹ï¼Œåˆ©ç”¨visemeçº§åˆ«çš„å¤šæ ·æ€§ï¼Œå¹¶ç»“åˆè¯´è¯é£æ ¼ä¸ªæ€§åŒ–å’Œç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ ¹æ®å•ä¸ªéŸ³é¢‘è¾“å…¥ç”Ÿæˆå’Œç¼–è¾‘å¤šæ ·åŒ–çš„3Dé¢éƒ¨åŠ¨ç”»ï¼Œå¹¶å¯æ§åˆ¶ä¿çœŸåº¦å’Œå¤šæ ·æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»æ–¹æ³•åœ¨åˆ›å»ºå…·æœ‰ç²¾ç¡®æ§åˆ¶å’ŒçœŸå®å¤´éƒ¨è¿åŠ¨çš„ä¸ªæ€§åŒ–3DåŠ¨ç”»æ–¹é¢ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç¼–è¾‘è¿™äº›åŠ¨ç”»å°¤å…¶å¤æ‚ä¸”è€—æ—¶ï¼Œéœ€è¦ç²¾ç¡®çš„æ§åˆ¶ï¼Œé€šå¸¸ç”±é«˜æŠ€èƒ½åŠ¨ç”»å¸ˆå¤„ç†ã€‚å¤§å¤šæ•°ç°æœ‰å·¥ä½œä¾§é‡äºæ§åˆ¶åˆæˆåŠ¨ç”»çš„é£æ ¼æˆ–æƒ…æ„Ÿï¼Œæ— æ³•ç¼–è¾‘/é‡æ–°ç”Ÿæˆè¾“å…¥åŠ¨ç”»çš„æŸäº›éƒ¨åˆ†ã€‚å®ƒä»¬ä¹Ÿå¿½ç•¥äº†å¤šä¸ªåˆç†çš„å˜´å”‡å’Œå¤´éƒ¨è¿åŠ¨å¯ä»¥åŒ¹é…ç›¸åŒéŸ³é¢‘è¾“å…¥çš„äº‹å®ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºæ•´ä½“è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»çš„æ–°æ–¹æ³•3DiFACEã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºå•ä¸ªéŸ³é¢‘è¾“å…¥ç”Ÿæˆå¤šæ ·ä¸”åˆç†çš„å˜´å”‡å’Œå¤´éƒ¨è¿åŠ¨ï¼Œå¹¶å…è®¸é€šè¿‡å…³é”®å¸§å’Œæ’å€¼è¿›è¡Œç¼–è¾‘ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå®Œå…¨å·ç§¯æ‰©æ•£æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å¯ä»¥åˆ©ç”¨æˆ‘ä»¬è®­ç»ƒè¯­æ–™åº“ä¸­visemeçº§åˆ«çš„å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§è¯´è¯é£æ ¼ä¸ªæ€§åŒ–å’Œä¸€ç§æ–°é¢–çš„ç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£ï¼Œä»¥å®ç°ç²¾ç¡®çš„æ§åˆ¶å’Œç¼–è¾‘ã€‚é€šè¿‡å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†æˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿä¸ºç»™å®šçš„å•ä¸ªéŸ³é¢‘è¾“å…¥ç”Ÿæˆå’Œç¼–è¾‘å¤šæ ·åŒ–çš„æ•´ä½“3Dé¢éƒ¨åŠ¨ç”»ï¼Œå¹¶åœ¨é«˜ä¿çœŸåº¦å’Œå¤šæ ·æ€§ä¹‹é—´è¿›è¡Œæ§åˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è¯­éŸ³é©±åŠ¨3Dé¢éƒ¨åŠ¨ç”»æ–¹æ³•éš¾ä»¥ç”Ÿæˆå…·æœ‰çœŸå®å¤´éƒ¨è¿åŠ¨å’Œå¯æ§é£æ ¼çš„ä¸ªæ€§åŒ–åŠ¨ç”»ï¼Œå¹¶ä¸”ç¼ºä¹çµæ´»çš„ç¼–è¾‘èƒ½åŠ›ï¼Œæ— æ³•é’ˆå¯¹ç‰¹å®šéƒ¨åˆ†è¿›è¡Œä¿®æ”¹æˆ–é‡æ–°ç”Ÿæˆã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å¿½ç•¥äº†åŒä¸€è¯­éŸ³è¾“å…¥å¯ä»¥å¯¹åº”å¤šç§åˆç†çš„å”‡éƒ¨å’Œå¤´éƒ¨è¿åŠ¨çš„å¯èƒ½æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼š3DiFACEçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ‰©æ•£æ¨¡å‹å­¦ä¹ è¯­éŸ³åˆ°é¢éƒ¨åŠ¨ç”»çš„æ˜ å°„ï¼Œå¹¶å¼•å…¥è¯´è¯é£æ ¼ä¸ªæ€§åŒ–å’Œç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£æœºåˆ¶ï¼Œä»è€Œå®ç°å¤šæ ·åŒ–ã€å¯æ§å’Œå¯ç¼–è¾‘çš„3Dé¢éƒ¨åŠ¨ç”»ç”Ÿæˆã€‚é€šè¿‡æ‰©æ•£æ¨¡å‹å­¦ä¹ æ•°æ®åˆ†å¸ƒï¼Œå¯ä»¥ç”Ÿæˆå¤šç§å¯èƒ½çš„é¢éƒ¨è¿åŠ¨ï¼Œè€Œä¸ªæ€§åŒ–å’Œç¨€ç–å¼•å¯¼åˆ™æä¾›äº†å¯¹åŠ¨ç”»é£æ ¼å’Œç‰¹å®šåŒºåŸŸçš„æ§åˆ¶èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼š3DiFACEçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) éŸ³é¢‘ç‰¹å¾æå–æ¨¡å—ï¼Œç”¨äºæå–è¾“å…¥éŸ³é¢‘çš„ç‰¹å¾è¡¨ç¤ºï¼›2) æ‰©æ•£æ¨¡å‹ï¼Œç”¨äºå­¦ä¹ éŸ³é¢‘ç‰¹å¾åˆ°3Dé¢éƒ¨åŠ¨ç”»çš„æ˜ å°„ï¼›3) è¯´è¯é£æ ¼ä¸ªæ€§åŒ–æ¨¡å—ï¼Œç”¨äºæ§åˆ¶ç”ŸæˆåŠ¨ç”»çš„é£æ ¼ï¼›4) ç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£æ¨¡å—ï¼Œç”¨äºå¯¹åŠ¨ç”»çš„ç‰¹å®šåŒºåŸŸè¿›è¡Œç²¾ç¡®æ§åˆ¶å’Œç¼–è¾‘ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼šé¦–å…ˆæå–éŸ³é¢‘ç‰¹å¾ï¼Œç„¶åé€šè¿‡æ‰©æ•£æ¨¡å‹ç”Ÿæˆåˆå§‹åŠ¨ç”»ï¼Œå†é€šè¿‡ä¸ªæ€§åŒ–æ¨¡å—è°ƒæ•´é£æ ¼ï¼Œæœ€åé€šè¿‡ç¨€ç–å¼•å¯¼æ¨¡å—è¿›è¡Œå±€éƒ¨ç¼–è¾‘ã€‚

**å…³é”®åˆ›æ–°**ï¼š3DiFACEçš„å…³é”®åˆ›æ–°åœ¨äºä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) æå‡ºäº†ä¸€ä¸ªå®Œå…¨å·ç§¯æ‰©æ•£æ¨¡å‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨è®­ç»ƒæ•°æ®ä¸­çš„visemeçº§åˆ«å¤šæ ·æ€§ï¼Œç”Ÿæˆæ›´å¤šæ ·åŒ–çš„é¢éƒ¨åŠ¨ç”»ï¼›2) å¼•å…¥äº†è¯´è¯é£æ ¼ä¸ªæ€§åŒ–æ¨¡å—ï¼Œå…è®¸ç”¨æˆ·æ§åˆ¶ç”ŸæˆåŠ¨ç”»çš„é£æ ¼ï¼›3) æå‡ºäº†ç¨€ç–å¼•å¯¼è¿åŠ¨æ‰©æ•£æ¨¡å—ï¼Œå®ç°äº†å¯¹åŠ¨ç”»ç‰¹å®šåŒºåŸŸçš„ç²¾ç¡®æ§åˆ¶å’Œç¼–è¾‘ã€‚è¿™äº›åˆ›æ–°ä½¿å¾—3DiFACEèƒ½å¤Ÿç”Ÿæˆæ›´çœŸå®ã€å¯æ§å’Œå¯ç¼–è¾‘çš„3Dé¢éƒ¨åŠ¨ç”»ã€‚

**å…³é”®è®¾è®¡**ï¼š3DiFACEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨å®Œå…¨å·ç§¯ç½‘ç»œä½œä¸ºæ‰©æ•£æ¨¡å‹çš„ä¸»å¹²ç½‘ç»œï¼Œä»¥æ›´å¥½åœ°æ•æ‰æ—¶åºä¾èµ–å…³ç³»ï¼›2) é‡‡ç”¨visemeçº§åˆ«çš„æ¡ä»¶ä¿¡æ¯ï¼Œå¼•å¯¼æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ï¼›3) è®¾è®¡äº†ç¨€ç–å¼•å¯¼æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±æ¨¡å‹åœ¨æŒ‡å®šåŒºåŸŸç”ŸæˆæœŸæœ›çš„è¿åŠ¨ï¼›4) é€šè¿‡è°ƒæ•´æ‰©æ•£æ¨¡å‹çš„å™ªå£°æ°´å¹³ï¼Œæ§åˆ¶ç”ŸæˆåŠ¨ç”»çš„å¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œ3DiFACEèƒ½å¤Ÿç”Ÿæˆå¤šæ ·ä¸”é«˜è´¨é‡çš„3Dé¢éƒ¨åŠ¨ç”»ï¼Œåœ¨ä¿çœŸåº¦å’Œå¤šæ ·æ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚é€šè¿‡å®šé‡è¯„ä¼°ï¼Œ3DiFACEåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¾‹å¦‚åœ¨å”‡éƒ¨è¿åŠ¨çš„å‡†ç¡®æ€§å’Œå¤´éƒ¨è¿åŠ¨çš„çœŸå®æ€§æ–¹é¢å‡æœ‰æ˜¾è‘—æå‡ã€‚å®šæ€§è¯„ä¼°ä¹Ÿè¡¨æ˜ï¼Œ3DiFACEç”Ÿæˆçš„åŠ¨ç”»æ›´è‡ªç„¶ã€æ›´å…·è¡¨ç°åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°åæ˜ è¯´è¯è€…çš„æƒ…æ„Ÿå’Œé£æ ¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

3DiFACEå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹ŸåŒ–èº«ç”Ÿæˆã€æ¸¸æˆè§’è‰²åŠ¨ç”»ã€ç”µå½±ç‰¹æ•ˆåˆ¶ä½œã€åœ¨çº¿æ•™è‚²ç­‰é¢†åŸŸã€‚è¯¥æŠ€æœ¯å¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸã€æ›´å…·è¡¨ç°åŠ›çš„è™šæ‹Ÿè§’è‰²ï¼Œæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶é™ä½åŠ¨ç”»åˆ¶ä½œçš„æˆæœ¬å’Œéš¾åº¦ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºäººæœºäº¤äº’ã€è¿œç¨‹åä½œç­‰é¢†åŸŸï¼Œå®ç°æ›´è‡ªç„¶ã€æ›´é«˜æ•ˆçš„æ²Ÿé€šã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Creating personalized 3D animations with precise control and realistic head motions remains challenging for current speech-driven 3D facial animation methods. Editing these animations is especially complex and time consuming, requires precise control and typically handled by highly skilled animators. Most existing works focus on controlling style or emotion of the synthesized animation and cannot edit/regenerate parts of an input animation. They also overlook the fact that multiple plausible lip and head movements can match the same audio input. To address these challenges, we present 3DiFACE, a novel method for holistic speech-driven 3D facial animation. Our approach produces diverse plausible lip and head motions for a single audio input and allows for editing via keyframing and interpolation. Specifically, we propose a fully-convolutional diffusion model that can leverage the viseme-level diversity in our training corpus. Additionally, we employ a speaking-style personalization and a novel sparsely-guided motion diffusion to enable precise control and editing. Through quantitative and qualitative evaluations, we demonstrate that our method is capable of generating and editing diverse holistic 3D facial animations given a single audio input, with control between high fidelity and diversity. Code and models are available here: https://balamuruganthambiraja.github.io/3DiFACE

