---
layout: default
title: Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization
---

# Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.07069" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.07069v1</a>
  <a href="https://arxiv.org/pdf/2506.07069.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.07069v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.07069v1', 'Accelerating 3D Gaussian Splatting with Neural Sorting and Axis-Oriented Rasterization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhican Wang, Guanghui He, Dantong Liu, Lingjun Gao, Shell Xu Hu, Chen Zhang, Zhuoran Song, Nicholas Lane, Wayne Luk, Hongxiang Fan

**åˆ†ç±»**: cs.GR, cs.AR, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-08

**å¤‡æ³¨**: Preprint. Under review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè½´å‘å…‰æ …åŒ–ä¸ç¥ç»æ’åºä»¥åŠ é€Ÿ3Dé«˜æ–¯ç‚¹äº‘æ¸²æŸ“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dé«˜æ–¯ç‚¹äº‘` `å®æ—¶æ¸²æŸ“` `ç¥ç»ç½‘ç»œ` `å…‰æ …åŒ–` `æ’åºç®—æ³•` `èƒ½è€—ä¼˜åŒ–` `å¢å¼ºç°å®` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰3Dé«˜æ–¯ç‚¹äº‘æ¸²æŸ“æ–¹æ³•åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šå®ç°å®æ—¶æ¸²æŸ“é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨åŠŸè€—å’Œé¢ç§¯é¢„ç®—ç´§å¼ çš„æƒ…å†µä¸‹ã€‚
2. æœ¬æ–‡æå‡ºäº†è½´å‘å…‰æ …åŒ–å’Œç¥ç»æ’åºç›¸ç»“åˆçš„åˆ›æ–°æ–¹æ³•ï¼Œé€šè¿‡é¢„è®¡ç®—å’Œé‡ç”¨å…±äº«é¡¹æ¥å‡å°‘è®¡ç®—å†—ä½™ï¼Œå¹¶æé«˜æ’åºæ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å®ç°äº†23.4è‡³27.8å€çš„é€Ÿåº¦æå‡å’Œ28.8è‡³51.4å€çš„èƒ½è€—èŠ‚çœï¼ŒåŒæ—¶ä¿æŒäº†æ¸²æŸ“è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Dé«˜æ–¯ç‚¹äº‘æ¸²æŸ“ï¼ˆ3DGSï¼‰å› å…¶é«˜è´¨é‡å’Œé«˜æ•ˆçš„è§†å›¾åˆæˆè€Œå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œåº”ç”¨äºå¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ã€æœºå™¨äººå’Œè‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ç„¶è€Œï¼Œèµ„æºå—é™è®¾å¤‡ä¸Šçš„å®æ—¶æ¸²æŸ“ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ¶æ„ä¸ç®—æ³•çš„ååŒè®¾è®¡ï¼Œé¦–å…ˆé€šè¿‡è½´å‘å…‰æ …åŒ–å‡å°‘é‡å¤è®¡ç®—ï¼Œä»è€Œé™ä½ä¹˜åŠ æ“ä½œçš„æ•°é‡ï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨ç¥ç»æ’åºæ–¹æ³•é¢„æµ‹æ— åºæ··åˆæƒé‡ï¼Œæ¶ˆé™¤æ˜‚è´µçš„ç¡¬ä»¶æ’åºéœ€æ±‚ï¼›æœ€åï¼Œè®¾è®¡äº†é«˜æ•ˆçš„å¯é‡æ„å¤„ç†é˜µåˆ—ä»¥æ”¯æŒå…‰æ …åŒ–å’Œç¥ç»ç½‘ç»œæ¨ç†ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥è®¾è®¡åœ¨ä¿æŒæ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼Œé€Ÿåº¦æå‡è¾¾23.4è‡³27.8å€ï¼Œèƒ½è€—é™ä½28.8è‡³51.4å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³3Dé«˜æ–¯ç‚¹äº‘æ¸²æŸ“åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šå®æ—¶æ¸²æŸ“çš„æ•ˆç‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å­˜åœ¨è®¡ç®—å†—ä½™å’Œæ’åºæ•ˆç‡ä½ä¸‹çš„ç—›ç‚¹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥è½´å‘å…‰æ …åŒ–æŠ€æœ¯ï¼Œé¢„è®¡ç®—å¹¶é‡ç”¨å…±äº«é¡¹ï¼Œå‡å°‘ä¹˜åŠ æ“ä½œï¼ŒåŒæ—¶é‡‡ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ’åºï¼Œé™ä½ç¡¬ä»¶å¼€é”€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è½´å‘å…‰æ …åŒ–æ¨¡å—ã€ç¥ç»æ’åºæ¨¡å—å’Œå¯é‡æ„å¤„ç†é˜µåˆ—ï¼Œæ”¯æŒé«˜æ•ˆçš„æ¸²æŸ“å’Œæ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥è½´å‘å…‰æ …åŒ–å’Œç¥ç»æ’åºçš„ç»“åˆï¼Œæ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†é‡å¤è®¡ç®—å’Œç¡¬ä»¶æ’åºçš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šè®¾è®¡äº†ä¸“ç”¨ç¡¬ä»¶ä»¥æ”¯æŒè½´å‘å…‰æ …åŒ–ï¼Œä¼˜åŒ–äº†ç¥ç»ç½‘ç»œçš„è®­ç»ƒæ¡†æ¶ï¼Œç¡®ä¿ç®—æ³•çš„ç¨³å®šæ€§ï¼Œå¹¶é‡‡ç”¨äº†Ï€è½¨è¿¹ç“¦ç‰‡è°ƒåº¦ä»¥ä¼˜åŒ–é«˜æ–¯é‡ç”¨å’Œå†…å­˜è®¿é—®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨çœŸå®åœºæ™¯ä¸­å®ç°äº†23.4è‡³27.8å€çš„é€Ÿåº¦æå‡å’Œ28.8è‡³51.4å€çš„èƒ½è€—èŠ‚çœï¼Œç›¸è¾ƒäºè¾¹ç¼˜GPUï¼Œæ˜¾è‘—æé«˜äº†æ¸²æŸ“æ•ˆç‡å’Œé™ä½äº†èƒ½è€—ï¼ŒåŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„æ¸²æŸ“æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¢å¼ºç°å®ã€è™šæ‹Ÿç°å®ã€æœºå™¨äººè§†è§‰å’Œè‡ªåŠ¨é©¾é©¶ç­‰ï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„3Dæ¸²æŸ“ï¼Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½æ¨åŠ¨æ›´å¤šå®æ—¶æ¸²æŸ“åº”ç”¨çš„å‘å±•ï¼Œä¿ƒè¿›ç›¸å…³é¢†åŸŸçš„åˆ›æ–°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> 3D Gaussian Splatting (3DGS) has recently gained significant attention for high-quality and efficient view synthesis, making it widely adopted in fields such as AR/VR, robotics, and autonomous driving. Despite its impressive algorithmic performance, real-time rendering on resource-constrained devices remains a major challenge due to tight power and area budgets. This paper presents an architecture-algorithm co-design to address these inefficiencies. First, we reveal substantial redundancy caused by repeated computation of common terms/expressions during the conventional rasterization. To resolve this, we propose axis-oriented rasterization, which pre-computes and reuses shared terms along both the X and Y axes through a dedicated hardware design, effectively reducing multiply-and-add (MAC) operations by up to 63%. Second, by identifying the resource and performance inefficiency of the sorting process, we introduce a novel neural sorting approach that predicts order-independent blending weights using an efficient neural network, eliminating the need for costly hardware sorters. A dedicated training framework is also proposed to improve its algorithmic stability. Third, to uniformly support rasterization and neural network inference, we design an efficient reconfigurable processing array that maximizes hardware utilization and throughput. Furthermore, we introduce a $Ï€$-trajectory tile schedule, inspired by Morton encoding and Hilbert curve, to optimize Gaussian reuse and reduce memory access overhead. Comprehensive experiments demonstrate that the proposed design preserves rendering quality while achieving a speedup of $23.4\sim27.8\times$ and energy savings of $28.8\sim51.4\times$ compared to edge GPUs for real-world scenes. We plan to open-source our design to foster further development in this field.

