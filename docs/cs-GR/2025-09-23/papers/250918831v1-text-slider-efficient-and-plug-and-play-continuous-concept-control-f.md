---
layout: default
title: Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters
---

# Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18831" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18831v1</a>
  <a href="https://arxiv.org/pdf/2509.18831.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18831v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18831v1', 'Text Slider: Efficient and Plug-and-Play Continuous Concept Control for Image/Video Synthesis via LoRA Adapters')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pin-Yen Chiu, I-Sheng Fang, Jun-Cheng Chen

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV, cs.LG, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-09-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Text Sliderï¼šä¸€ç§é«˜æ•ˆå³æ’å³ç”¨çš„LoRAé€‚é…å™¨ï¼Œç”¨äºå›¾åƒ/è§†é¢‘åˆæˆä¸­çš„è¿ç»­æ¦‚å¿µæ§åˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `å›¾åƒåˆæˆ` `è§†é¢‘åˆæˆ` `æ¦‚å¿µæ§åˆ¶` `æ‰©æ•£æ¨¡å‹` `LoRAé€‚é…å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¦‚å¿µæ§åˆ¶æ–¹æ³•è®­ç»ƒæˆæœ¬é«˜æ˜‚ï¼Œéœ€è¦å¤§é‡æ—¶é—´å’ŒGPUèµ„æºæ¥å­¦ä¹ æ»‘å—æˆ–åµŒå…¥ï¼Œä¸”éœ€é’ˆå¯¹ä¸åŒæ‰©æ•£æ¨¡å‹éª¨å¹²ç½‘ç»œè¿›è¡Œé‡æ–°è®­ç»ƒã€‚
2. Text Slideré€šè¿‡åœ¨é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ä¸­å¯»æ‰¾ä½ç§©æ–¹å‘ï¼Œå®ç°è§†è§‰æ¦‚å¿µçš„è¿ç»­æ§åˆ¶ï¼Œæ— éœ€å¤§é‡è®­ç»ƒå’Œé‡æ–°è®­ç»ƒã€‚
3. å®éªŒè¡¨æ˜ï¼ŒText Slideråœ¨æ˜¾è‘—é™ä½è®­ç»ƒæ—¶é—´å’ŒGPUå†…å­˜æ¶ˆè€—çš„åŒæ—¶ï¼Œå®ç°äº†å¯¹å›¾åƒå’Œè§†é¢‘å±æ€§çš„å¹³æ»‘è¿ç»­æ§åˆ¶ï¼Œä¸”æ•ˆç‡è¿œè¶…ç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºText Sliderçš„è½»é‡çº§ã€é«˜æ•ˆä¸”å³æ’å³ç”¨çš„æ¡†æ¶ï¼Œç”¨äºå®ç°å›¾åƒå’Œè§†é¢‘åˆæˆä¸­çš„è¿ç»­æ¦‚å¿µæ§åˆ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡è¯†åˆ«é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ä¸­çš„ä½ç§©æ–¹å‘ï¼Œä»è€Œå®ç°å¯¹è§†è§‰æ¦‚å¿µçš„è¿ç»­æ§åˆ¶ï¼ŒåŒæ—¶æ˜¾è‘—å‡å°‘äº†è®­ç»ƒæ—¶é—´ã€GPUå†…å­˜æ¶ˆè€—å’Œå¯è®­ç»ƒå‚æ•°çš„æ•°é‡ã€‚Text Slideræ”¯æŒå¤šæ¦‚å¿µç»„åˆå’Œè¿ç»­æ§åˆ¶ï¼Œä»è€Œåœ¨å›¾åƒå’Œè§†é¢‘åˆæˆä¸­å®ç°ç»†ç²’åº¦å’Œçµæ´»çš„æ“ä½œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒText Sliderèƒ½å¤Ÿåœ¨ä¿æŒè¾“å…¥å›¾åƒåŸå§‹ç©ºé—´å¸ƒå±€å’Œç»“æ„çš„åŒæ—¶ï¼Œå¯¹ç‰¹å®šå±æ€§è¿›è¡Œå¹³æ»‘å’Œè¿ç»­çš„è°ƒæ•´ã€‚Text Slideråœ¨æ•ˆç‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼šè®­ç»ƒé€Ÿåº¦æ¯”Concept Sliderå¿«5å€ï¼Œæ¯”Attribute Controlå¿«47å€ï¼ŒåŒæ—¶GPUå†…å­˜ä½¿ç”¨é‡åˆ†åˆ«å‡å°‘äº†è¿‘2å€å’Œ4å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ¦‚å¿µæ§åˆ¶æ–¹æ³•åœ¨å›¾åƒå’Œè§†é¢‘åˆæˆä¸­å­˜åœ¨è®­ç»ƒæˆæœ¬é«˜ã€GPUå†…å­˜æ¶ˆè€—å¤§ä»¥åŠæ³›åŒ–èƒ½åŠ›å¼±çš„é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œè¿™äº›æ–¹æ³•éœ€è¦é’ˆå¯¹æ¯ä¸ªæ¦‚å¿µæˆ–å±æ€§è®­ç»ƒç‹¬ç«‹çš„æ»‘å—æˆ–åµŒå…¥ï¼Œå¯¼è‡´è®­ç»ƒæ—¶é—´å’Œè®¡ç®—èµ„æºéœ€æ±‚å·¨å¤§ã€‚æ­¤å¤–ï¼Œè¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºç‰¹å®šçš„æ‰©æ•£æ¨¡å‹éª¨å¹²ç½‘ç»œï¼Œéš¾ä»¥ç›´æ¥åº”ç”¨äºå…¶ä»–æ¨¡å‹ï¼Œé™åˆ¶äº†å…¶å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šText Sliderçš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨çš„æ½œåœ¨ç©ºé—´ä¸­å¯»æ‰¾ä¸ç‰¹å®šæ¦‚å¿µæˆ–å±æ€§ç›¸å…³çš„ä½ç§©æ–¹å‘ã€‚é€šè¿‡æ²¿ç€è¿™äº›ä½ç§©æ–¹å‘ç§»åŠ¨ï¼Œå¯ä»¥å®ç°å¯¹å›¾åƒæˆ–è§†é¢‘ä¸­ç›¸åº”å±æ€§çš„è¿ç»­æ§åˆ¶ã€‚è¿™ç§æ–¹æ³•åˆ©ç”¨äº†é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨å¼ºå¤§çš„è¯­ä¹‰è¡¨ç¤ºèƒ½åŠ›ï¼Œé¿å…äº†ä»å¤´å¼€å§‹è®­ç»ƒçš„éœ€è¦ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è®­ç»ƒæˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šText Sliderçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) é€‰æ‹©ä¸€ä¸ªé¢„è®­ç»ƒçš„æ–‡æœ¬ç¼–ç å™¨ï¼ˆä¾‹å¦‚CLIPï¼‰ã€‚2) é’ˆå¯¹æ¯ä¸ªéœ€è¦æ§åˆ¶çš„æ¦‚å¿µæˆ–å±æ€§ï¼Œé€šè¿‡å°‘é‡æ ·æœ¬æ•°æ®è®­ç»ƒä¸€ä¸ªLoRAé€‚é…å™¨ï¼Œä»¥è¯†åˆ«æ–‡æœ¬ç¼–ç å™¨ä¸­çš„ä½ç§©æ–¹å‘ã€‚3) åœ¨å›¾åƒæˆ–è§†é¢‘åˆæˆè¿‡ç¨‹ä¸­ï¼Œé€šè¿‡è°ƒæ•´LoRAé€‚é…å™¨çš„æƒé‡ï¼Œæ²¿ç€ä½ç§©æ–¹å‘ç§»åŠ¨ï¼Œä»è€Œå®ç°å¯¹ç›¸åº”å±æ€§çš„è¿ç»­æ§åˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šText Sliderçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨LoRAé€‚é…å™¨åœ¨é¢„è®­ç»ƒæ–‡æœ¬ç¼–ç å™¨ä¸­å¯»æ‰¾ä½ç§©æ–¹å‘ï¼Œä»è€Œå®ç°å¯¹è§†è§‰æ¦‚å¿µçš„è¿ç»­æ§åˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒText Slideræ— éœ€è®­ç»ƒç‹¬ç«‹çš„æ»‘å—æˆ–åµŒå…¥ï¼Œè€Œæ˜¯ç›´æ¥åˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„çŸ¥è¯†ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è®­ç»ƒæˆæœ¬å’ŒGPUå†…å­˜æ¶ˆè€—ã€‚æ­¤å¤–ï¼ŒText Sliderå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥è½»æ¾åº”ç”¨äºä¸åŒçš„æ‰©æ•£æ¨¡å‹éª¨å¹²ç½‘ç»œã€‚

**å…³é”®è®¾è®¡**ï¼šText Sliderçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨LoRAé€‚é…å™¨æ¥å­¦ä¹ ä½ç§©æ–¹å‘ï¼ŒLoRAé€šè¿‡å¼•å…¥å°‘é‡å¯è®­ç»ƒå‚æ•°æ¥è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡ï¼Œä»è€Œé¿å…äº†å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚2) ä½¿ç”¨è¿ç»­çš„æƒé‡è°ƒæ•´æ¥å®ç°å¯¹å±æ€§çš„è¿ç»­æ§åˆ¶ï¼Œé€šè¿‡è°ƒæ•´LoRAé€‚é…å™¨çš„æƒé‡ï¼Œå¯ä»¥æ²¿ç€ä½ç§©æ–¹å‘å¹³æ»‘åœ°æ”¹å˜å›¾åƒæˆ–è§†é¢‘ä¸­çš„ç›¸åº”å±æ€§ã€‚3) æ”¯æŒå¤šæ¦‚å¿µç»„åˆï¼Œé€šè¿‡ç»„åˆå¤šä¸ªLoRAé€‚é…å™¨çš„æƒé‡ï¼Œå¯ä»¥åŒæ—¶æ§åˆ¶å›¾åƒæˆ–è§†é¢‘ä¸­çš„å¤šä¸ªå±æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Text Slideråœ¨æ•ˆç‡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè®­ç»ƒé€Ÿåº¦æ¯”Concept Sliderå¿«5å€ï¼Œæ¯”Attribute Controlå¿«47å€ï¼ŒåŒæ—¶GPUå†…å­˜ä½¿ç”¨é‡åˆ†åˆ«å‡å°‘äº†è¿‘2å€å’Œ4å€ã€‚æ­¤å¤–ï¼ŒText Sliderèƒ½å¤Ÿåœ¨ä¿æŒè¾“å…¥å›¾åƒåŸå§‹ç©ºé—´å¸ƒå±€å’Œç»“æ„çš„åŒæ—¶ï¼Œå¯¹ç‰¹å®šå±æ€§è¿›è¡Œå¹³æ»‘å’Œè¿ç»­çš„è°ƒæ•´ï¼Œå®ç°äº†é«˜è´¨é‡çš„å›¾åƒå’Œè§†é¢‘åˆæˆæ•ˆæœã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒText Slideræ˜¯ä¸€ç§é«˜æ•ˆã€çµæ´»ä¸”æ˜“äºä½¿ç”¨çš„æ¦‚å¿µæ§åˆ¶æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Text Sliderå¯å¹¿æ³›åº”ç”¨äºå›¾åƒå’Œè§†é¢‘ç¼–è¾‘ã€å†…å®¹åˆ›ä½œã€é£æ ¼è¿ç§»ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥ä½¿ç”¨Text Sliderè½»æ¾è°ƒæ•´å›¾åƒçš„äº®åº¦ã€å¯¹æ¯”åº¦ã€é¥±å’Œåº¦ç­‰å±æ€§ï¼Œæˆ–è€…æ”¹å˜è§†é¢‘ä¸­äººç‰©çš„è¡¨æƒ…ã€å¹´é¾„ç­‰ç‰¹å¾ã€‚æ­¤å¤–ï¼ŒText Sliderè¿˜å¯ä»¥ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šé£æ ¼æˆ–ä¸»é¢˜çš„å›¾åƒå’Œè§†é¢‘ï¼Œä¸ºåˆ›æ„è®¾è®¡æä¾›æ›´å¤šå¯èƒ½æ€§ã€‚è¯¥ç ”ç©¶çš„æ½œåœ¨ä»·å€¼åœ¨äºé™ä½äº†å›¾åƒå’Œè§†é¢‘ç¼–è¾‘çš„é—¨æ§›ï¼Œä½¿å¾—æ™®é€šç”¨æˆ·ä¹Ÿèƒ½è½»æ¾åˆ›ä½œå‡ºé«˜è´¨é‡çš„å†…å®¹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in diffusion models have significantly improved image and video synthesis. In addition, several concept control methods have been proposed to enable fine-grained, continuous, and flexible control over free-form text prompts. However, these methods not only require intensive training time and GPU memory usage to learn the sliders or embeddings but also need to be retrained for different diffusion backbones, limiting their scalability and adaptability. To address these limitations, we introduce Text Slider, a lightweight, efficient and plug-and-play framework that identifies low-rank directions within a pre-trained text encoder, enabling continuous control of visual concepts while significantly reducing training time, GPU memory consumption, and the number of trainable parameters. Furthermore, Text Slider supports multi-concept composition and continuous control, enabling fine-grained and flexible manipulation in both image and video synthesis. We show that Text Slider enables smooth and continuous modulation of specific attributes while preserving the original spatial layout and structure of the input. Text Slider achieves significantly better efficiency: 5$\times$ faster training than Concept Slider and 47$\times$ faster than Attribute Control, while reducing GPU memory usage by nearly 2$\times$ and 4$\times$, respectively.

