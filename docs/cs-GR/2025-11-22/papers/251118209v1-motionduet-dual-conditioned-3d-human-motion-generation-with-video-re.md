---
layout: default
title: MotionDuet: Dual-Conditioned 3D Human Motion Generation with Video-Regularized Text Learning
---

# MotionDuet: Dual-Conditioned 3D Human Motion Generation with Video-Regularized Text Learning

**arXiv**: [2511.18209v1](https://arxiv.org/abs/2511.18209) | [PDF](https://arxiv.org/pdf/2511.18209.pdf)

**ä½œè€…**: Yi-Yang Zhang, Tengjiao Sun, Pengcheng Fang, Deng-Bao Wang, Xiaohao Cai, Min-Ling Zhang, Hansung Kim

**åˆ†ç±»**: cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MotionDuetï¼šæå‡ºä¸€ç§è§†é¢‘æ­£åˆ™åŒ–çš„æ–‡æœ¬å­¦ä¹ æ¡†æž¶ï¼Œç”¨äºŽåŒé‡æ¡ä»¶ä¸‹çš„3Däººä½“è¿åŠ¨ç”Ÿæˆã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `3Däººä½“è¿åŠ¨ç”Ÿæˆ` `å¤šæ¨¡æ€èžåˆ` `è§†é¢‘æ­£åˆ™åŒ–` `æ–‡æœ¬æ¡ä»¶` `åŒé‡æ¡ä»¶` `åˆ†å¸ƒå¯¹é½` `è¿åŠ¨åˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰3Däººä½“è¿åŠ¨ç”Ÿæˆæ–¹æ³•ä¾èµ–æ˜‚è´µçš„åŠ¨ä½œæ•æ‰æˆ–ä»…ä¾èµ–è§†é¢‘/æ–‡æœ¬ä¿¡æ¯ï¼Œç”Ÿæˆçš„è¿åŠ¨çœŸå®žæ€§å’Œå¯æŽ§æ€§ä¸è¶³ã€‚
2. MotionDuetåˆ©ç”¨åŒé‡æ¡ä»¶èŒƒå¼ï¼Œç»“åˆè§†é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œé€šè¿‡DUETå’ŒDASHæŸå¤±å¯¹é½æ¨¡æ€åˆ†å¸ƒï¼Œæå‡è¿åŠ¨è´¨é‡ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒMotionDuetåœ¨ç”Ÿæˆé€¼çœŸå’Œå¯æŽ§çš„äººä½“è¿åŠ¨æ–¹é¢ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œå®žçŽ°äº†æ€§èƒ½çš„æ˜¾è‘—æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

3Däººä½“è¿åŠ¨ç”Ÿæˆåœ¨ç”µå½±ã€åŠ¨ç”»ã€æ¸¸æˆå’Œå…·èº«æ™ºèƒ½ç­‰é¢†åŸŸè‡³å…³é‡è¦ã€‚ä¼ ç»Ÿçš„3Dè¿åŠ¨åˆæˆä¾èµ–äºŽæ˜‚è´µçš„åŠ¨ä½œæ•æ‰ï¼Œè€Œæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜Žï¼Œ2Dè§†é¢‘æä¾›äº†ä¸°å¯Œä¸”æ—¶é—´ä¸Šè¿žè´¯çš„äººç±»è¡Œä¸ºè§‚å¯Ÿã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•è¦ä¹ˆå°†é«˜å±‚æ–‡æœ¬æè¿°æ˜ å°„åˆ°è¿åŠ¨ï¼Œè¦ä¹ˆä»…ä¾èµ–è§†é¢‘æ¡ä»¶ï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨æ€ä¸ŽçœŸå®žä¸–ç•Œè¿åŠ¨ç»Ÿè®¡ä¹‹é—´å­˜åœ¨å·®è·ã€‚æˆ‘ä»¬å¼•å…¥MotionDuetï¼Œä¸€ä¸ªå¤šæ¨¡æ€æ¡†æž¶ï¼Œä½¿è¿åŠ¨ç”Ÿæˆä¸Žè§†é¢‘æ´¾ç”Ÿçš„è¡¨ç¤ºåˆ†å¸ƒå¯¹é½ã€‚åœ¨è¿™ç§åŒé‡æ¡ä»¶èŒƒå¼ä¸­ï¼Œä»Žé¢„è®­ç»ƒæ¨¡åž‹ï¼ˆä¾‹å¦‚VideoMAEï¼‰æå–çš„è§†é¢‘çº¿ç´¢å¥ å®šäº†ä½Žçº§è¿åŠ¨åŠ¨æ€çš„åŸºç¡€ï¼Œè€Œæ–‡æœ¬æç¤ºæä¾›äº†è¯­ä¹‰æ„å›¾ã€‚ä¸ºäº†å¼¥åˆè·¨æ¨¡æ€çš„åˆ†å¸ƒå·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†åŒæµç»Ÿä¸€ç¼–ç å’Œè½¬æ¢ï¼ˆDUETï¼‰ä»¥åŠåˆ†å¸ƒæ„ŸçŸ¥ç»“æž„åè°ƒï¼ˆDASHï¼‰æŸå¤±ã€‚DUETé€šè¿‡ç»Ÿä¸€ç¼–ç å’ŒåŠ¨æ€æ³¨æ„åŠ›å°†è§†é¢‘ä¿¡æ¯èžåˆåˆ°è¿åŠ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œè€ŒDASHä½¿è¿åŠ¨è½¨è¿¹ä¸Žè§†é¢‘ç‰¹å¾çš„åˆ†å¸ƒå’Œç»“æž„ç»Ÿè®¡å¯¹é½ã€‚è‡ªåŠ¨å¼•å¯¼æœºåˆ¶é€šè¿‡åˆ©ç”¨æ¨¡åž‹çš„å¼±åŒ–å‰¯æœ¬è¿›ä¸€æ­¥å¹³è¡¡æ–‡æœ¬å’Œè§†è§‰ä¿¡å·ï¼Œä»Žè€Œåœ¨ä¸ç‰ºç‰²å¤šæ ·æ€§çš„å‰æä¸‹å¢žå¼ºäº†å¯æŽ§æ€§ã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒMotionDuetç”Ÿæˆé€¼çœŸä¸”å¯æŽ§çš„äººä½“è¿åŠ¨ï¼Œè¶…è¶Šäº†å¼ºå¤§çš„æœ€å…ˆè¿›åŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰3Däººä½“è¿åŠ¨ç”Ÿæˆæ–¹æ³•å­˜åœ¨ä»¥ä¸‹ç—›ç‚¹ï¼šä¸€æ˜¯ä¾èµ–æ˜‚è´µçš„åŠ¨ä½œæ•æ‰è®¾å¤‡ï¼Œæˆæœ¬é«˜æ˜‚ï¼›äºŒæ˜¯ä»…ä¾èµ–æ–‡æœ¬æè¿°æˆ–è§†é¢‘ä¿¡æ¯ï¼Œæ— æ³•åŒæ—¶ä¿è¯ç”Ÿæˆè¿åŠ¨çš„çœŸå®žæ€§å’Œå¯æŽ§æ€§ï¼Œå¯¼è‡´ç”Ÿæˆçš„è¿åŠ¨ä¸ŽçœŸå®žä¸–ç•Œçš„è¿åŠ¨ç»Ÿè®¡å­˜åœ¨å·®è·ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMotionDuetçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨åŒé‡æ¡ä»¶èŒƒå¼ï¼ŒåŒæ—¶ç»“åˆè§†é¢‘å’Œæ–‡æœ¬ä¿¡æ¯æ¥ç”Ÿæˆ3Däººä½“è¿åŠ¨ã€‚è§†é¢‘ä¿¡æ¯æä¾›ä½Žçº§çš„è¿åŠ¨åŠ¨æ€ï¼Œæ–‡æœ¬ä¿¡æ¯æä¾›é«˜çº§çš„è¯­ä¹‰æ„å›¾ã€‚é€šè¿‡å¯¹é½è§†é¢‘å’Œæ–‡æœ¬æ¨¡æ€çš„åˆ†å¸ƒï¼Œå¯ä»¥ç”Ÿæˆæ›´çœŸå®žã€æ›´å¯æŽ§çš„è¿åŠ¨ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šMotionDuetçš„æ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) è§†é¢‘ç‰¹å¾æå–æ¨¡å—ï¼šä½¿ç”¨é¢„è®­ç»ƒçš„VideoMAEæå–è§†é¢‘ç‰¹å¾ï¼›2) æ–‡æœ¬ç‰¹å¾æå–æ¨¡å—ï¼šæå–æ–‡æœ¬æè¿°çš„ç‰¹å¾ï¼›3) åŒæµç»Ÿä¸€ç¼–ç å’Œè½¬æ¢ï¼ˆDUETï¼‰æ¨¡å—ï¼šå°†è§†é¢‘å’Œæ–‡æœ¬ç‰¹å¾èžåˆåˆ°è¿åŠ¨æ½œåœ¨ç©ºé—´ä¸­ï¼›4) è¿åŠ¨ç”Ÿæˆæ¨¡å—ï¼šåŸºäºŽèžåˆåŽçš„ç‰¹å¾ç”Ÿæˆ3Däººä½“è¿åŠ¨ï¼›5) åˆ†å¸ƒæ„ŸçŸ¥ç»“æž„åè°ƒï¼ˆDASHï¼‰æŸå¤±ï¼šç”¨äºŽå¯¹é½è¿åŠ¨è½¨è¿¹ä¸Žè§†é¢‘ç‰¹å¾çš„åˆ†å¸ƒå’Œç»“æž„ç»Ÿè®¡ï¼›6) è‡ªåŠ¨å¼•å¯¼æœºåˆ¶ï¼šå¹³è¡¡æ–‡æœ¬å’Œè§†è§‰ä¿¡å·ï¼Œå¢žå¼ºå¯æŽ§æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šMotionDuetçš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) æå‡ºäº†åŒæµç»Ÿä¸€ç¼–ç å’Œè½¬æ¢ï¼ˆDUETï¼‰æ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°èžåˆè§†é¢‘å’Œæ–‡æœ¬ç‰¹å¾ï¼›2) æå‡ºäº†åˆ†å¸ƒæ„ŸçŸ¥ç»“æž„åè°ƒï¼ˆDASHï¼‰æŸå¤±ï¼Œèƒ½å¤Ÿå¯¹é½è¿åŠ¨è½¨è¿¹ä¸Žè§†é¢‘ç‰¹å¾çš„åˆ†å¸ƒå’Œç»“æž„ç»Ÿè®¡ï¼Œä»Žè€Œæé«˜ç”Ÿæˆè¿åŠ¨çš„çœŸå®žæ€§ï¼›3) æå‡ºäº†è‡ªåŠ¨å¼•å¯¼æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸ç‰ºç‰²å¤šæ ·æ€§çš„å‰æä¸‹å¢žå¼ºå¯æŽ§æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMotionDuetèƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨è§†é¢‘å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œç”Ÿæˆæ›´çœŸå®žã€æ›´å¯æŽ§çš„3Däººä½“è¿åŠ¨ã€‚

**å…³é”®è®¾è®¡**ï¼šDUETæ¨¡å—ä½¿ç”¨åŠ¨æ€æ³¨æ„åŠ›æœºåˆ¶æ¥èžåˆè§†é¢‘å’Œæ–‡æœ¬ç‰¹å¾ã€‚DASHæŸå¤±åŒ…å«ä¸¤éƒ¨åˆ†ï¼šä¸€éƒ¨åˆ†æ˜¯åˆ†å¸ƒå¯¹é½æŸå¤±ï¼Œç”¨äºŽå¯¹é½è¿åŠ¨è½¨è¿¹å’Œè§†é¢‘ç‰¹å¾çš„åˆ†å¸ƒï¼›å¦ä¸€éƒ¨åˆ†æ˜¯ç»“æž„åè°ƒæŸå¤±ï¼Œç”¨äºŽå¯¹é½è¿åŠ¨è½¨è¿¹å’Œè§†é¢‘ç‰¹å¾çš„ç»“æž„ç»Ÿè®¡ã€‚è‡ªåŠ¨å¼•å¯¼æœºåˆ¶é€šè¿‡ä½¿ç”¨æ¨¡åž‹çš„å¼±åŒ–å‰¯æœ¬ï¼Œæ¥å¹³è¡¡æ–‡æœ¬å’Œè§†è§‰ä¿¡å·ã€‚å…·ä½“å®žçŽ°ç»†èŠ‚ï¼ˆå¦‚ç½‘ç»œç»“æž„ã€å‚æ•°è®¾ç½®ç­‰ï¼‰æœªçŸ¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

MotionDuetåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®žéªŒï¼Œç»“æžœè¡¨æ˜Žï¼ŒMotionDuetåœ¨ç”Ÿæˆé€¼çœŸå’Œå¯æŽ§çš„äººä½“è¿åŠ¨æ–¹é¢ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒMotionDuetè¶…è¶Šäº†å¼ºå¤§çš„state-of-the-artåŸºçº¿ï¼Œè¯æ˜Žäº†å…¶æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

MotionDuetåœ¨ç”µå½±åˆ¶ä½œã€åŠ¨ç”»è®¾è®¡ã€æ¸¸æˆå¼€å‘å’Œå…·èº«æ™ºèƒ½ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽç”Ÿæˆé€¼çœŸä¸”å¯æŽ§çš„3Däººä½“è¿åŠ¨ï¼Œä»Žè€Œé™ä½ŽåŠ¨ä½œæ•æ‰çš„æˆæœ¬ï¼Œæé«˜å†…å®¹åˆ›ä½œçš„æ•ˆçŽ‡ã€‚æ­¤å¤–ï¼ŒMotionDuetè¿˜å¯ä»¥åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žã€äººæœºäº¤äº’ç­‰é¢†åŸŸï¼Œä¸ºç”¨æˆ·æä¾›æ›´è‡ªç„¶ã€æ›´çœŸå®žçš„äº¤äº’ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»åž‹çš„è¿åŠ¨ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚åŠ¨ç‰©è¿åŠ¨ç”Ÿæˆã€ç‰©ä½“è¿åŠ¨ç”Ÿæˆç­‰ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> 3D Human motion generation is pivotal across film, animation, gaming, and embodied intelligence. Traditional 3D motion synthesis relies on costly motion capture, while recent work shows that 2D videos provide rich, temporally coherent observations of human behavior. Existing approaches, however, either map high-level text descriptions to motion or rely solely on video conditioning, leaving a gap between generated dynamics and real-world motion statistics. We introduce MotionDuet, a multimodal framework that aligns motion generation with the distribution of video-derived representations. In this dual-conditioning paradigm, video cues extracted from a pretrained model (e.g., VideoMAE) ground low-level motion dynamics, while textual prompts provide semantic intent. To bridge the distribution gap across modalities, we propose Dual-stream Unified Encoding and Transformation (DUET) and a Distribution-Aware Structural Harmonization (DASH) loss. DUET fuses video-informed cues into the motion latent space via unified encoding and dynamic attention, while DASH aligns motion trajectories with both distributional and structural statistics of video features. An auto-guidance mechanism further balances textual and visual signals by leveraging a weakened copy of the model, enhancing controllability without sacrificing diversity. Extensive experiments demonstrate that MotionDuet generates realistic and controllable human motions, surpassing strong state-of-the-art baselines.

