---
layout: default
title: DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions
---

# DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17342" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.17342v1</a>
  <a href="https://arxiv.org/pdf/2508.17342.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17342v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17342v1', 'DanceEditor: Towards Iterative Editable Music-driven Dance Generation with Open-Vocabulary Descriptions')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Hengyuan Zhang, Zhe Li, Xingqun Qi, Mengze Li, Muyi Sun, Man Zhang, Sirui Han

**ÂàÜÁ±ª**: cs.GR, cs.CV, cs.MM, cs.SD

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-24

**ÊúüÂàä**: ICCV 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [PROJECT_PAGE](https://lzvsdy.github.io/DanceEditor/)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫DanceEditor‰ª•Ëß£ÂÜ≥ËàûËπàÁîüÊàê‰∏éÁºñËæëÁöÑÂÆûÈôÖÈúÄÊ±Ç**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `ËàûËπàÁîüÊàê` `ÂèØÁºñËæëËàûËπà` `Â§öÊ®°ÊÄÅËûçÂêà` `Èü≥‰πêÈ©±Âä®` `ËôöÊãüËßíËâ≤Âä®Áîª`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®ËàûËπàÁîüÊàê‰∏≠Êú™ËÄÉËôëÁî®Êà∑ÂØπËàûËπàÂä®‰ΩúÁöÑÁºñËæëÈúÄÊ±ÇÔºå‰∏îÁº∫‰πèÊîØÊåÅËø≠‰ª£ÁºñËæëÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫DanceEditorÊ°ÜÊû∂ÔºåÈÄöËøáÈ¢ÑÊµã-ÂÜçÁºñËæëÁöÑÊñπÂºèÔºåÁªìÂêàÈü≥‰πêÂíåÊñáÊú¨ÊèèËø∞ÔºåÂÆûÁé∞ÂèØÁºñËæëÁöÑËàûËπàÁîüÊàê„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåDanceEditorÂú®DanceRemixÊï∞ÊçÆÈõÜ‰∏äÊòæËëó‰ºò‰∫éÁé∞ÊúâÊ®°ÂûãÔºåÂ±ïÁ§∫‰∫ÜÊõ¥È´òÁöÑÁîüÊàêË¥®ÈáèÂíåÁºñËæëÁÅµÊ¥ªÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰ªéÈü≥‰πê‰ø°Âè∑ÁîüÊàêËøûË¥Ø‰∏îÂ§öÊ†∑ÁöÑ‰∫∫Á±ªËàûËπàÂú®ËôöÊãüËßíËâ≤Âä®Áîª‰∏≠ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ï‰ªÖÊîØÊåÅÁõ¥Êé•ËàûËπàÂêàÊàêÔºåÊú™ËÄÉËôëÂà∞Áî®Êà∑Âú®ÂÆûÈôÖÁºñËàûÂú∫ÊôØ‰∏≠ÂØπËàûËπàÂä®‰ΩúËøõË°åÁºñËæëÁöÑÈúÄÊ±Ç„ÄÇÊ≠§Â§ñÔºåÁº∫‰πèÈ´òË¥®ÈáèÁöÑËàûËπàÊï∞ÊçÆÈõÜ‰ª•ÊîØÊåÅËø≠‰ª£ÁºñËæë‰πüÈôêÂà∂‰∫ÜËøô‰∏ÄÊåëÊàòÁöÑËß£ÂÜ≥„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊûÑÂª∫‰∫ÜDanceRemixÔºå‰∏Ä‰∏™ÂåÖÂê´Ë∂ÖËøá2530‰∏áËàûËπàÂ∏ßÂíå8.45‰∏áÂØπÁöÑÂ§öËΩÆÂèØÁºñËæëËàûËπàÊï∞ÊçÆÈõÜÔºåÂπ∂ÊèêÂá∫‰∫ÜÂêç‰∏∫DanceEditorÁöÑÊñ∞Ê°ÜÊû∂ÔºåÊó®Âú®‰∏éÁªôÂÆöÈü≥‰πê‰ø°Âè∑‰∏ÄËá¥Âú∞ËøõË°åËø≠‰ª£ÂíåÂèØÁºñËæëÁöÑËàûËπàÁîüÊàê„ÄÇËØ•Ê°ÜÊû∂ÈááÁî®È¢ÑÊµã-ÂÜçÁºñËæëÁöÑËåÉÂºèÔºåÁªìÂêàÂ§öÊ®°ÊÄÅÊù°‰ª∂ÔºåÊèêÂçá‰∫ÜÁîüÊàêÁªìÊûúÁöÑÊùÉÂ®ÅÊÄßÔºåÂπ∂ÈÄöËøá‰∫§ÂèâÊ®°ÊÄÅÁºñËæëÊ®°ÂùóÔºàCEMÔºâÂÆûÁé∞‰∫Ü‰∏éÈü≥‰πêÂíåÊñáÊú¨ÊèêÁ§∫ÁöÑÂä®ÊÄÅÊï¥Âêà„ÄÇÂÆûÈ™åË°®ÊòéÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®Êñ∞Êî∂ÈõÜÁöÑDanceRemixÊï∞ÊçÆÈõÜ‰∏ä‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊ®°Âûã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâËàûËπàÁîüÊàêÊñπÊ≥ïÊó†Ê≥ïÊª°Ë∂≥Áî®Êà∑ÂØπËàûËπàÂä®‰ΩúÁºñËæëÈúÄÊ±ÇÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ï‰∏ªË¶ÅÈõÜ‰∏≠‰∫éÁõ¥Êé•ÁîüÊàêËàûËπàÔºåÁº∫‰πèÂØπËø≠‰ª£ÁºñËæëÁöÑÊîØÊåÅÔºå‰∏îÁº∫Â∞ëÈ´òË¥®ÈáèÁöÑËàûËπàÊï∞ÊçÆÈõÜ‰ª•ËøõË°åÊúâÊïàËÆ≠ÁªÉ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑDanceEditorÊ°ÜÊû∂ÈááÁî®È¢ÑÊµã-ÂÜçÁºñËæëÁöÑËåÉÂºèÔºåÈ¶ñÂÖàÊ†πÊçÆÈü≥‰πê‰ø°Âè∑ÁîüÊàêÂàùÊ≠•ËàûËπàÂä®‰ΩúÔºåÁÑ∂ÂêéÈÄöËøáÁî®Êà∑Êèê‰æõÁöÑÊñáÊú¨ÊèèËø∞ËøõË°åËø≠‰ª£ÁºñËæë„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÁîüÊàêÁöÑËàûËπàÊó¢ËÉΩ‰∏éÈü≥‰πêËäÇÂ•èÁõ∏ÂçèË∞ÉÔºåÂèàËÉΩÁÅµÊ¥ªÂìçÂ∫îÁî®Êà∑ÁöÑÁºñËæëÈúÄÊ±Ç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöDanceEditorÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÂàùÊ≠•È¢ÑÊµãÈò∂ÊÆµÂíåËø≠‰ª£ÁºñËæëÈò∂ÊÆµ„ÄÇÂú®ÂàùÊ≠•È¢ÑÊµãÈò∂ÊÆµÔºåÊ°ÜÊû∂Áõ¥Êé•‰ªéÂØπÈΩêÁöÑÈü≥‰πê‰ø°Âè∑‰∏≠Âª∫Ê®°ËàûËπàÂä®‰ΩúÔºõÂú®Ëø≠‰ª£ÁºñËæëÈò∂ÊÆµÔºåÈÄöËøá‰∫§ÂèâÊ®°ÊÄÅÁºñËæëÊ®°ÂùóÔºàCEMÔºâÂ∞ÜÂàùÊ≠•ÁîüÊàêÁöÑËàûËπà‰∏éÈü≥‰πêÂíåÊñáÊú¨ÊèêÁ§∫ÁªìÂêàÔºåÁîüÊàêÂèØÁºñËæëÁöÑËàûËπàÂ∫èÂàó„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫Ü‰∫§ÂèâÊ®°ÊÄÅÁºñËæëÊ®°ÂùóÔºàCEMÔºâÔºåËØ•Ê®°ÂùóËÉΩÂ§üÂä®ÊÄÅÊï¥ÂêàÂàùÊ≠•ÁîüÊàêÁöÑËàûËπà„ÄÅÈü≥‰πêÂíåÊñáÊú¨ÊèêÁ§∫ÔºåÁ°Æ‰øùÁîüÊàêÁªìÊûúÂú®Èü≥‰πêÂíåËØ≠‰πâ‰∏äÈÉΩ‰øùÊåÅ‰∏ÄËá¥„ÄÇËøô‰∏ÄÂàõÊñ∞‰ΩøÂæóDanceEditorÂú®ËàûËπàÁîüÊàêÂíåÁºñËæëÁöÑÁÅµÊ¥ªÊÄß‰∏ä‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇÊñπÈù¢ÔºåCEMÊ®°ÂùóÈÄöËøáÊó∂Èó¥ËøêÂä®Á∫øÁ¥¢Ëá™ÈÄÇÂ∫îÂú∞ÂºïÂØºÂêàÊàêÂ∫èÂàóÔºåÁ°Æ‰øùÁîüÊàêÁöÑËàûËπà‰∏ç‰ªÖÁ¨¶ÂêàÈü≥‰πêÁöÑÂíåÂ£∞ÁâπÂæÅÔºåËøòËÉΩ‰∏éÊñáÊú¨ÊèèËø∞‰øùÊåÅÁªÜÁ≤íÂ∫¶ÁöÑËØ≠‰πâÂØπÈΩê„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®ÂÆûÈ™å‰∏≠ÔºåDanceEditorÂú®Êñ∞Êî∂ÈõÜÁöÑDanceRemixÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÁîüÊàêË¥®ÈáèÊòæËëó‰ºò‰∫éÁé∞ÊúâÊúÄÂÖàËøõÊ®°ÂûãÔºåÂÖ∑‰ΩìÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®ËàûËπàÁîüÊàê‰∏éÁºñËæë‰ªªÂä°‰∏≠ÁöÑÊúâÊïàÊÄßÂíåÁÅµÊ¥ªÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËôöÊãüÁé∞ÂÆû„ÄÅÊ∏∏ÊàèÂºÄÂèëÂíåËàûËπàÊïôËÇ≤Á≠â„ÄÇÈÄöËøáÂÆûÁé∞Èü≥‰πêÈ©±Âä®ÁöÑÂèØÁºñËæëËàûËπàÁîüÊàêÔºåDanceEditorËÉΩÂ§ü‰∏∫Áî®Êà∑Êèê‰æõÊõ¥Áõ¥ËßÇÁöÑËàûËπàÂàõ‰ΩúÂ∑•ÂÖ∑Ôºå‰øÉËøõËàûËπàËâ∫ÊúØÁöÑ‰º†Êí≠‰∏éÂèëÂ±ïÔºåÊú™Êù•ÂèØËÉΩÂú®Â®±‰πêÂíåÊïôËÇ≤Ë°å‰∏ö‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Generating coherent and diverse human dances from music signals has gained tremendous progress in animating virtual avatars. While existing methods support direct dance synthesis, they fail to recognize that enabling users to edit dance movements is far more practical in real-world choreography scenarios. Moreover, the lack of high-quality dance datasets incorporating iterative editing also limits addressing this challenge. To achieve this goal, we first construct DanceRemix, a large-scale multi-turn editable dance dataset comprising the prompt featuring over 25.3M dance frames and 84.5K pairs. In addition, we propose a novel framework for iterative and editable dance generation coherently aligned with given music signals, namely DanceEditor. Considering the dance motion should be both musical rhythmic and enable iterative editing by user descriptions, our framework is built upon a prediction-then-editing paradigm unifying multi-modal conditions. At the initial prediction stage, our framework improves the authority of generated results by directly modeling dance movements from tailored, aligned music. Moreover, at the subsequent iterative editing stages, we incorporate text descriptions as conditioning information to draw the editable results through a specifically designed Cross-modality Editing Module (CEM). Specifically, CEM adaptively integrates the initial prediction with music and text prompts as temporal motion cues to guide the synthesized sequences. Thereby, the results display music harmonics while preserving fine-grained semantic alignment with text descriptions. Extensive experiments demonstrate that our method outperforms the state-of-the-art models on our newly collected DanceRemix dataset. Code is available at https://lzvsdy.github.io/DanceEditor/.

