---
layout: default
title: iTACO: Interactable Digital Twins of Articulated Objects from Casually Captured RGBD Videos
---

# iTACO: Interactable Digital Twins of Articulated Objects from Casually Captured RGBD Videos

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.08334" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.08334v3</a>
  <a href="https://arxiv.org/pdf/2506.08334.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.08334v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.08334v3', 'iTACO: Interactable Digital Twins of Articulated Objects from Casually Captured RGBD Videos')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Weikun Peng, Jun Lv, Cewu Lu, Manolis Savva

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-10 (æ›´æ–°: 2025-11-17)

**å¤‡æ³¨**: 3DV 2026 camera-ready version. Project website can be found at https://3dlg-hcvc.github.io/video2articulation/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºiTACOä»¥è§£å†³ä»RGBDè§†é¢‘è·å–å¯äº¤äº’æ•°å­—åŒèƒèƒçš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ•°å­—åŒèƒèƒ` `å…³èŠ‚ç‰©ä½“` `RGBDè§†é¢‘` `è¿åŠ¨åˆ†æ` `éƒ¨ä»¶åˆ†å‰²` `æœºå™¨äººæŠ€æœ¯` `å…·èº«äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ•°å­—åŒ–å…³èŠ‚ç‰©ä½“æ—¶éœ€è¦ç²¾å¿ƒæ•è·æ•°æ®ï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨å’Œæ‰©å±•æ€§ã€‚
2. æœ¬æ–‡æå‡ºiTACOæ¡†æ¶ï¼Œé€šè¿‡åˆ†æåŠ¨æ€RGBDè§†é¢‘ï¼Œæ¨æ–­å…³èŠ‚å‚æ•°å¹¶è¿›è¡Œéƒ¨ä»¶åˆ†å‰²ï¼Œé€‚åº”éšæ„æ•è·çš„åœºæ™¯ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒiTACOåœ¨åˆæˆå’ŒçœŸå®è§†é¢‘ä¸Šå‡ä¼˜äºç°æœ‰çš„æ•°å­—åŒèƒèƒæ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œå…³èŠ‚ç‰©ä½“æ™®éå­˜åœ¨ã€‚å¯äº¤äº’çš„æ•°å­—åŒèƒèƒåœ¨å…·èº«äººå·¥æ™ºèƒ½å’Œæœºå™¨äººé¢†åŸŸæœ‰ç€å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•éœ€è¦ç²¾å¿ƒæ•è·çš„æ•°æ®ï¼Œé™åˆ¶äº†å®é™…ã€å¯æ‰©å±•å’Œé€šç”¨çš„è·å–æ–¹å¼ã€‚æœ¬æ–‡èšç„¦äºä»æ‰‹æŒæ‘„åƒæœºæ‹æ‘„çš„éšæ„æ•è·çš„RGBDè§†é¢‘ä¸­è¿›è¡Œè¿åŠ¨åˆ†æå’Œéƒ¨ä»¶çº§åˆ†å‰²ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†iTACOï¼šä¸€ä¸ªä»åŠ¨æ€RGBDè§†é¢‘ä¸­æ¨æ–­å…³èŠ‚å‚æ•°å¹¶åˆ†å‰²å¯ç§»åŠ¨éƒ¨ä»¶çš„ç²—åˆ°ç»†æ¡†æ¶ã€‚æˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«784ä¸ªè§†é¢‘å’Œ284ä¸ªç‰©ä½“çš„å…¨æ–°æ•°æ®é›†ï¼Œè§„æ¨¡æ˜¯ç°æœ‰å·¥ä½œçš„20å€ï¼Œå¹¶ä¸ç°æœ‰æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒï¼Œç»“æœè¡¨æ˜iTACOåœ¨åˆæˆå’ŒçœŸå®çš„éšæ„æ•è·RGBDè§†é¢‘ä¸Šå‡è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»éšæ„æ•è·çš„RGBDè§†é¢‘ä¸­æå–å…³èŠ‚ç‰©ä½“çš„æ•°å­—åŒèƒèƒçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç²¾ç¡®æ•è·çš„æ•°æ®ï¼Œéš¾ä»¥åœ¨å®é™…åº”ç”¨ä¸­æ¨å¹¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šiTACOæ¡†æ¶é€šè¿‡ç²—åˆ°ç»†çš„æ–¹å¼å¤„ç†åŠ¨æ€RGBDè§†é¢‘ï¼Œé¦–å…ˆè¿›è¡Œç²—ç•¥çš„å…³èŠ‚å‚æ•°æ¨æ–­ï¼Œç„¶åç»†åŒ–åˆ°éƒ¨ä»¶çº§åˆ«çš„åˆ†å‰²ã€‚è¿™ç§è®¾è®¡ä½¿å¾—åœ¨å¤æ‚çš„äº¤äº’åœºæ™¯ä¸­ä»èƒ½æœ‰æ•ˆæå–ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šiTACOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬è§†é¢‘è¾“å…¥æ¨¡å—ã€è¿åŠ¨åˆ†ææ¨¡å—å’Œåˆ†å‰²æ¨¡å—ã€‚è§†é¢‘è¾“å…¥æ¨¡å—è´Ÿè´£æ¥æ”¶RGBDè§†é¢‘ï¼Œè¿åŠ¨åˆ†ææ¨¡å—æ¨æ–­å…³èŠ‚å‚æ•°ï¼Œåˆ†å‰²æ¨¡å—åˆ™å®ç°éƒ¨ä»¶çš„ç²¾ç¡®åˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šiTACOçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç²—åˆ°ç»†çš„å¤„ç†æµç¨‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹éšæ„æ•è·è§†é¢‘ä¸­çš„ç›¸æœºå’Œç‰©ä½“çš„åŒæ—¶è¿åŠ¨åŠé®æŒ¡é—®é¢˜ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šæœªå®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒiTACOé‡‡ç”¨äº†å¤šå±‚æ¬¡çš„æŸå¤±å‡½æ•°ï¼Œä»¥å¹³è¡¡å…³èŠ‚æ¨æ–­å’Œéƒ¨ä»¶åˆ†å‰²çš„ç²¾åº¦ã€‚åŒæ—¶ï¼Œç½‘ç»œç»“æ„è®¾è®¡ä¸Šç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œå’Œå›¾ç¥ç»ç½‘ç»œï¼Œä»¥å¢å¼ºå¯¹åŠ¨æ€åœºæ™¯çš„ç†è§£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒiTACOåœ¨784ä¸ªè§†é¢‘çš„æµ‹è¯•ä¸­ï¼Œè¾ƒç°æœ‰æ–¹æ³•åœ¨å…³èŠ‚å‚æ•°æ¨æ–­å’Œéƒ¨ä»¶åˆ†å‰²ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨çœŸå®è§†é¢‘ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ•´ä½“æ€§èƒ½æå‡å¹…åº¦è¶…è¿‡20%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰ã€‚é€šè¿‡æä¾›å¯äº¤äº’çš„æ•°å­—åŒèƒèƒï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººä¸äººç±»çš„äº¤äº’èƒ½åŠ›ï¼Œå¢å¼ºè™šæ‹Ÿç¯å¢ƒä¸­çš„çœŸå®æ„Ÿï¼Œæ¨åŠ¨æ™ºèƒ½å®¶å±…å’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ•™è‚²ã€å¨±ä¹å’Œå·¥ä¸šç­‰å¤šä¸ªé¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Articulated objects are prevalent in daily life. Interactable digital twins of such objects have numerous applications in embodied AI and robotics. Unfortunately, current methods to digitize articulated real-world objects require carefully captured data, preventing practical, scalable, and generalizable acquisition. We focus on motion analysis and part-level segmentation of an articulated object from a casually captured RGBD video shot with a hand-held camera. A casually captured video of an interaction with an articulated object is easy to obtain at scale using smartphones. However, this setting is challenging due to simultaneous object and camera motion and significant occlusions as the person interacts with the object. To tackle these challenges, we introduce iTACO: a coarse-to-fine framework that infers joint parameters and segments movable parts of the object from a dynamic RGBD video. To evaluate our method under this new setting, we build a dataset of 784 videos containing 284 objects across 11 categories that is 20$\times$ larger than available in prior work. We then compare our approach with existing methods that also take video as input. Our experiments show that iTACO outperforms existing articulated object digital twin methods on both synthetic and real casually captured RGBD videos.

