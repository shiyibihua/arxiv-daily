---
layout: default
title: Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images
---

# Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09952" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09952v1</a>
  <a href="https://arxiv.org/pdf/2509.09952.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09952v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09952v1', 'Chord: Chain of Rendering Decomposition for PBR Material Estimation from Generated Texture Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhi Ying, Boxiang Rong, Jingyu Wang, Maoyuan Xu

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**å¤‡æ³¨**: Accepted to SIGGRAPH Asia 2025. Project page: https://ubisoft-laforge.github.io/world/chord

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºChordï¼šä¸€ç§é“¾å¼æ¸²æŸ“åˆ†è§£æ–¹æ³•ï¼Œç”¨äºä»ç”Ÿæˆçº¹ç†å›¾åƒä¸­ä¼°è®¡PBRæè´¨**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `PBRæè´¨ä¼°è®¡` `æ‰©æ•£æ¨¡å‹` `é“¾å¼åˆ†è§£` `SVBRDF` `çº¹ç†ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰PBRæè´¨ç”Ÿæˆæ–¹æ³•åœ¨è´¨é‡ã€çµæ´»æ€§å’Œç”¨æˆ·æ§åˆ¶æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆæœã€‚
2. æå‡ºä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œé¦–å…ˆä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆçº¹ç†å›¾åƒï¼Œç„¶åé€šè¿‡é“¾å¼åˆ†è§£æ–¹æ¡ˆä¼°è®¡SVBRDFé€šé“ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æè´¨ç”Ÿæˆå’Œä¼°è®¡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å¤šç§åº”ç”¨ä¸­å±•ç°å‡ºçµæ´»æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æè´¨åˆ›å»ºå’Œé‡å»ºå¯¹äºå¤–è§‚å»ºæ¨¡è‡³å…³é‡è¦ï¼Œä½†ä¼ ç»Ÿä¸Šéœ€è¦è‰ºæœ¯å®¶æŠ•å…¥å¤§é‡æ—¶é—´å’Œä¸“ä¸šçŸ¥è¯†ã€‚è™½ç„¶æœ€è¿‘çš„æ–¹æ³•åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ä»ç”¨æˆ·æä¾›çš„è¾“å…¥åˆæˆPBRæè´¨ï¼Œä½†å®ƒä»¬åœ¨è´¨é‡ã€çµæ´»æ€§å’Œç”¨æˆ·æ§åˆ¶æ–¹é¢å¾€å¾€ä¸è¶³ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤é˜¶æ®µç”Ÿæˆ-ä¼°è®¡æ¡†æ¶ç”¨äºPBRæè´¨ç”Ÿæˆã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œå¾®è°ƒçš„æ‰©æ•£æ¨¡å‹åˆæˆä¸ç”¨æˆ·è¾“å…¥å¯¹é½çš„é˜´å½±ã€å¯å¹³é“ºçš„çº¹ç†å›¾åƒã€‚åœ¨ä¼°è®¡é˜¶æ®µï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§é“¾å¼åˆ†è§£æ–¹æ¡ˆï¼Œé€šè¿‡å°†å…ˆå‰æå–çš„è¡¨ç¤ºä½œä¸ºè¾“å…¥ä¼ é€’åˆ°å•æ­¥å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸­ï¼Œä»è€Œé¡ºåºé¢„æµ‹SVBRDFé€šé“ã€‚æˆ‘ä»¬çš„æ–¹æ³•é«˜æ•ˆã€é«˜è´¨é‡ï¼Œå¹¶æ”¯æŒçµæ´»çš„ç”¨æˆ·æ§åˆ¶ã€‚æˆ‘ä»¬é’ˆå¯¹ç°æœ‰çš„æè´¨ç”Ÿæˆå’Œä¼°è®¡æ–¹æ³•è¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜äº†å…¶å“è¶Šçš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„æè´¨ä¼°è®¡æ–¹æ³•åœ¨ç”Ÿæˆçš„çº¹ç†å’ŒçœŸå®ç…§ç‰‡ä¸Šéƒ½è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼ºè°ƒäº†æˆ‘ä»¬çš„æ¡†æ¶åœ¨å„ç§åº”ç”¨ä¸­çš„çµæ´»æ€§ï¼ŒåŒ…æ‹¬æ–‡æœ¬åˆ°æè´¨ã€å›¾åƒåˆ°æè´¨ã€ç»“æ„å¼•å¯¼ç”Ÿæˆå’Œæè´¨ç¼–è¾‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»ç”Ÿæˆçº¹ç†å›¾åƒä¸­å‡†ç¡®é«˜æ•ˆåœ°ä¼°è®¡PBRæè´¨çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯ä¾èµ–è§†è§‰åŸºç¡€æ¨¡å‹çš„æ–¹æ³•ï¼Œåœ¨æè´¨è´¨é‡ã€ç”¨æˆ·æ§åˆ¶ä»¥åŠå¯¹çœŸå®ç…§ç‰‡çš„é²æ£’æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…ç”Ÿäº§ä¸­çš„åº”ç”¨ã€‚è‰ºæœ¯å®¶éœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´å’Œç²¾åŠ›æ¥åˆ›å»ºé«˜è´¨é‡çš„æè´¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†PBRæè´¨çš„ç”Ÿæˆå’Œä¼°è®¡è¿‡ç¨‹è§£è€¦ä¸ºä¸¤ä¸ªé˜¶æ®µã€‚é¦–å…ˆï¼Œåˆ©ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„çº¹ç†å›¾åƒï¼Œç„¶åé€šè¿‡é“¾å¼åˆ†è§£çš„æ–¹å¼ï¼Œé€æ­¥ä¼°è®¡SVBRDFçš„å„ä¸ªé€šé“ã€‚è¿™ç§è§£è€¦çš„è®¾è®¡å…è®¸é’ˆå¯¹æ¯ä¸ªé˜¶æ®µè¿›è¡Œä¼˜åŒ–ï¼Œå¹¶æé«˜æ•´ä½“çš„çµæ´»æ€§å’Œå¯æ§æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šç”Ÿæˆé˜¶æ®µå’Œä¼°è®¡é˜¶æ®µã€‚åœ¨ç”Ÿæˆé˜¶æ®µï¼Œä½¿ç”¨å¾®è°ƒçš„æ‰©æ•£æ¨¡å‹ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥ï¼ˆä¾‹å¦‚æ–‡æœ¬æˆ–å›¾åƒï¼‰ç”Ÿæˆé˜´å½±å’Œå¯å¹³é“ºçš„çº¹ç†å›¾åƒã€‚åœ¨ä¼°è®¡é˜¶æ®µï¼Œé‡‡ç”¨é“¾å¼åˆ†è§£æ–¹æ¡ˆï¼Œåˆ©ç”¨å•æ­¥å›¾åƒæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œä¾æ¬¡é¢„æµ‹SVBRDFçš„å„ä¸ªé€šé“ï¼ˆä¾‹å¦‚ï¼Œæ¼«åå°„ç‡ã€æ³•çº¿ã€ç²—ç³™åº¦ç­‰ï¼‰ã€‚æ¯ä¸ªé€šé“çš„é¢„æµ‹éƒ½ä¾èµ–äºå…ˆå‰æå–çš„è¡¨ç¤ºï¼Œå½¢æˆä¸€ä¸ªé“¾å¼ç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶é“¾å¼åˆ†è§£çš„ä¼°è®¡æ–¹æ¡ˆã€‚é€šè¿‡å°†SVBRDFé€šé“çš„ä¼°è®¡åˆ†è§£ä¸ºä¸€ç³»åˆ—é¡ºåºé¢„æµ‹ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨å…ˆå‰æå–çš„è¡¨ç¤ºä½œä¸ºè¾“å…¥ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰é€šé“ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œä»è€Œæé«˜ä¼°è®¡çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œä¸¤é˜¶æ®µçš„æ¡†æ¶è®¾è®¡ä¹Ÿæé«˜äº†çµæ´»æ€§ï¼Œå…è®¸ç”¨æˆ·åœ¨ç”Ÿæˆé˜¶æ®µè¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç”Ÿæˆé˜¶æ®µï¼Œæ‰©æ•£æ¨¡å‹é€šè¿‡å¾®è°ƒæ¥é€‚åº”æè´¨ç”Ÿæˆä»»åŠ¡ã€‚åœ¨ä¼°è®¡é˜¶æ®µï¼Œé“¾å¼åˆ†è§£æ–¹æ¡ˆçš„å…³é”®åœ¨äºå¦‚ä½•æœ‰æ•ˆåœ°æå–å’Œä¼ é€’å…ˆå‰é€šé“çš„è¡¨ç¤ºã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†è¯´æ˜ï¼Œä½†å¯ä»¥æ¨æµ‹ä½¿ç”¨äº†å·ç§¯ç¥ç»ç½‘ç»œæˆ–Transformerç­‰ç»“æ„æ¥æå–å›¾åƒç‰¹å¾ï¼Œå¹¶å¯èƒ½ä½¿ç”¨äº†L1æŸå¤±æˆ–æ„ŸçŸ¥æŸå¤±ç­‰æ¥ä¼˜åŒ–SVBRDFé€šé“çš„é¢„æµ‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æè´¨ç”Ÿæˆå’Œä¼°è®¡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•åœ¨ç”Ÿæˆçº¹ç†å’ŒçœŸå®ç…§ç‰‡ä¸Šéƒ½è¡¨ç°å‡ºå¼ºå¤§çš„é²æ£’æ€§ï¼Œå¹¶ä¸”åœ¨æ–‡æœ¬åˆ°æè´¨ã€å›¾åƒåˆ°æè´¨ã€ç»“æ„å¼•å¯¼ç”Ÿæˆå’Œæè´¨ç¼–è¾‘ç­‰å¤šç§åº”ç”¨ä¸­å±•ç°å‡ºçµæ´»æ€§ã€‚è™½ç„¶æ‘˜è¦ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†å¼ºè°ƒäº†å…¶å“è¶Šçš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œã€äº§å“è®¾è®¡ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½æè´¨åˆ›å»ºçš„æˆæœ¬å’Œæ—¶é—´ï¼Œæé«˜ç”Ÿäº§æ•ˆç‡ã€‚é€šè¿‡æ–‡æœ¬æˆ–å›¾åƒè¾“å…¥å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„PBRæè´¨ï¼Œå¹¶æ”¯æŒç”¨æˆ·è¿›è¡Œçµæ´»çš„ç¼–è¾‘å’Œæ§åˆ¶ï¼Œä¸ºè‰ºæœ¯å®¶å’Œè®¾è®¡å¸ˆæä¾›å¼ºå¤§çš„å·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°ä¸‰ç»´æ¨¡å‹çš„è‡ªåŠ¨æè´¨ç”Ÿæˆå’Œç¼–è¾‘ï¼Œå®ç°æ›´æ™ºèƒ½åŒ–çš„å¤–è§‚å»ºæ¨¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Material creation and reconstruction are crucial for appearance modeling but traditionally require significant time and expertise from artists. While recent methods leverage visual foundation models to synthesize PBR materials from user-provided inputs, they often fall short in quality, flexibility, and user control. We propose a novel two-stage generate-and-estimate framework for PBR material generation. In the generation stage, a fine-tuned diffusion model synthesizes shaded, tileable texture images aligned with user input. In the estimation stage, we introduce a chained decomposition scheme that sequentially predicts SVBRDF channels by passing previously extracted representation as input into a single-step image-conditional diffusion model. Our method is efficient, high quality, and enables flexible user control. We evaluate our approach against existing material generation and estimation methods, demonstrating superior performance. Our material estimation method shows strong robustness on both generated textures and in-the-wild photographs. Furthermore, we highlight the flexibility of our framework across diverse applications, including text-to-material, image-to-material, structure-guided generation, and material editing.

