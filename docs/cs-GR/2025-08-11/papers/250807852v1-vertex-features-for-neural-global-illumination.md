---
layout: default
title: Vertex Features for Neural Global Illumination
---

# Vertex Features for Neural Global Illumination

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.07852" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.07852v1</a>
  <a href="https://arxiv.org/pdf/2508.07852.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.07852v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.07852v1', 'Vertex Features for Neural Global Illumination')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rui Su, Honghao Dong, Haojie Jin, Yisong Chen, Guoping Wang, Sheng Li

**åˆ†ç±»**: cs.GR, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

**å¤‡æ³¨**: Accepted by ACM SIGGRAPH Asia'2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»é¡¶ç‚¹ç‰¹å¾ä»¥è§£å†³ä¼ ç»Ÿç‰¹å¾ç½‘æ ¼çš„å†…å­˜ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç¥ç»æ¸²æŸ“` `3Dåœºæ™¯é‡å»º` `ç‰¹å¾è¡¨ç¤º` `å†…å­˜ä¼˜åŒ–` `å‡ ä½•å¯¹é½` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç‰¹å¾ç½‘æ ¼è¡¨ç¤ºåœ¨å†…å­˜å ç”¨ä¸Šå­˜åœ¨æ˜¾è‘—ç“¶é¢ˆï¼Œé™åˆ¶äº†å…¶åœ¨ç°ä»£å¹¶è¡Œè®¡ç®—ç¡¬ä»¶ä¸Šçš„åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºç¥ç»é¡¶ç‚¹ç‰¹å¾ï¼Œé€šè¿‡åœ¨ç½‘æ ¼é¡¶ç‚¹ç›´æ¥å­˜å‚¨å¯å­¦ä¹ ç‰¹å¾ï¼Œä¼˜åŒ–å†…å­˜ä½¿ç”¨å¹¶æ”¹å–„ç‰¹å¾è¡¨ç¤ºã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•çš„å†…å­˜æ¶ˆè€—ä»…ä¸ºä¼ ç»Ÿç½‘æ ¼è¡¨ç¤ºçš„äº”åˆ†ä¹‹ä¸€ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå­¦ä¹ å‹ç¥ç»è¡¨ç¤ºåœ¨3Dåœºæ™¯é‡å»ºå’Œç¥ç»æ¸²æŸ“åº”ç”¨ä¸­å¾—åˆ°äº†å¹¿æ³›åº”ç”¨ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ç‰¹å¾ç½‘æ ¼è¡¨ç¤ºé€šå¸¸å­˜åœ¨æ˜¾è‘—çš„å†…å­˜å ç”¨ï¼Œæˆä¸ºç°ä»£å¹¶è¡Œè®¡ç®—ç¡¬ä»¶çš„ç“¶é¢ˆã€‚æœ¬æ–‡æå‡ºäº†ç¥ç»é¡¶ç‚¹ç‰¹å¾ï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹æ¶‰åŠæ˜¾å¼ç½‘æ ¼è¡¨é¢çš„ç¥ç»æ¸²æŸ“ä»»åŠ¡çš„å­¦ä¹ è¡¨ç¤ºçš„å¹¿ä¹‰å½¢å¼ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç›´æ¥åœ¨ç½‘æ ¼é¡¶ç‚¹å¤„å­˜å‚¨å¯å­¦ä¹ ç‰¹å¾ï¼Œåˆ©ç”¨åº•å±‚å‡ ä½•ç»“æ„ä½œä¸ºç´§å‡‘ä¸”ç»“æ„åŒ–çš„ç¥ç»å¤„ç†è¡¨ç¤ºã€‚è¿™ä¸ä»…ä¼˜åŒ–äº†å†…å­˜æ•ˆç‡ï¼Œè¿˜é€šè¿‡ä¸è¡¨é¢ç´§å¯†å¯¹é½çš„ä»»åŠ¡ç‰¹å®šå‡ ä½•å…ˆéªŒæ”¹å–„äº†ç‰¹å¾è¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†å†…å­˜æ¶ˆè€—é™ä½è‡³ç½‘æ ¼è¡¨ç¤ºçš„äº”åˆ†ä¹‹ä¸€ç”šè‡³æ›´å°‘ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¯”çš„æ¸²æŸ“è´¨é‡å¹¶é™ä½äº†æ¨ç†å¼€é”€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿç‰¹å¾ç½‘æ ¼è¡¨ç¤ºåœ¨å†…å­˜å ç”¨ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨3Dåœºæ™¯é‡å»ºå’Œç¥ç»æ¸²æŸ“ä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•çš„å†…å­˜æ¶ˆè€—è¿‡å¤§ï¼Œå½±å“äº†æ€§èƒ½å’Œæ•ˆç‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºç¥ç»é¡¶ç‚¹ç‰¹å¾ï¼Œé€šè¿‡åœ¨ç½‘æ ¼é¡¶ç‚¹å¤„å­˜å‚¨å¯å­¦ä¹ ç‰¹å¾ï¼Œåˆ©ç”¨å‡ ä½•ç»“æ„çš„ç´§å‡‘æ€§æ¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Œå¹¶é€šè¿‡ä»»åŠ¡ç‰¹å®šçš„å‡ ä½•å…ˆéªŒæ¥æ”¹å–„ç‰¹å¾è¡¨ç¤ºçš„è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–ã€å‡ ä½•å¯¹é½å’Œç¥ç»æ¸²æŸ“ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå‡ ä½•å¯¹é½æ¨¡å—ç¡®ä¿ç‰¹å¾ä¸ç½‘æ ¼è¡¨é¢ç´§å¯†å¯¹é½ï¼Œæœ€åç¥ç»æ¸²æŸ“æ¨¡å—è¿›è¡Œæœ€ç»ˆçš„å›¾åƒç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å¯å­¦ä¹ ç‰¹å¾ç›´æ¥å­˜å‚¨åœ¨ç½‘æ ¼é¡¶ç‚¹ï¼Œè€Œä¸æ˜¯å‡åŒ€åˆ†å¸ƒåœ¨3Dç©ºé—´ä¸­ï¼Œè¿™ç§æ–¹æ³•æ˜¾è‘—æé«˜äº†å†…å­˜æ•ˆç‡å’Œç‰¹å¾è¡¨ç¤ºçš„è´¨é‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç‰¹å¾ä¸å‡ ä½•çš„å¯¹é½ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”é¡¶ç‚¹ç‰¹å¾çš„å­˜å‚¨å’Œå¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œç¥ç»é¡¶ç‚¹ç‰¹å¾æ–¹æ³•çš„å†…å­˜æ¶ˆè€—ä»…ä¸ºä¼ ç»Ÿç½‘æ ¼è¡¨ç¤ºçš„äº”åˆ†ä¹‹ä¸€ï¼Œç”šè‡³æ›´ä½ï¼ŒåŒæ—¶ä¿æŒäº†ç›¸ä¼¼çš„æ¸²æŸ“è´¨é‡ï¼Œæ˜¾è‘—é™ä½äº†æ¨ç†å¼€é”€ï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬3Dåœºæ™¯é‡å»ºã€è™šæ‹Ÿç°å®å’Œæ¸¸æˆå¼€å‘ç­‰ã€‚é€šè¿‡ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œæå‡æ¸²æŸ“è´¨é‡ï¼Œç¥ç»é¡¶ç‚¹ç‰¹å¾å¯ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°æ›´é«˜æ•ˆçš„æ¸²æŸ“ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent research on learnable neural representations has been widely adopted in the field of 3D scene reconstruction and neural rendering applications. However, traditional feature grid representations often suffer from substantial memory footprint, posing a significant bottleneck for modern parallel computing hardware. In this paper, we present neural vertex features, a generalized formulation of learnable representation for neural rendering tasks involving explicit mesh surfaces. Instead of uniformly distributing neural features throughout 3D space, our method stores learnable features directly at mesh vertices, leveraging the underlying geometry as a compact and structured representation for neural processing. This not only optimizes memory efficiency, but also improves feature representation by aligning compactly with the surface using task-specific geometric priors. We validate our neural representation across diverse neural rendering tasks, with a specific emphasis on neural radiosity. Experimental results demonstrate that our method reduces memory consumption to only one-fifth (or even less) of grid-based representations, while maintaining comparable rendering quality and lowering inference overhead.

