---
layout: default
title: MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes
---

# MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15892" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15892v1</a>
  <a href="https://arxiv.org/pdf/2509.15892.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15892v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15892v1', 'MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mohamed Ebbed, Zorah LÃ¤hner

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MoAngeloï¼šç”¨äºåŠ¨æ€åœºæ™¯çš„è¿åŠ¨æ„ŸçŸ¥ç¥ç»è¡¨é¢é‡å»º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `ç¥ç»è¡¨é¢é‡å»º` `å˜å½¢åœº` `å¤šè§†è§’è§†é¢‘` `NeuralAngelo` `å‡ ä½•é‡å»º` `è¿åŠ¨è·Ÿè¸ª` `ä¸‰ç»´é‡å»º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŠ¨æ€åœºæ™¯é‡å»ºé¢ä¸´è®¡ç®—å’Œè¡¨ç¤ºæŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ–°è§†è§’åˆæˆä¸Šè¡¨ç°è¾ƒå¥½ï¼Œä½†åœ¨å‡ ä½•ç»†èŠ‚ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé‡å»ºçš„ç½‘æ ¼æ˜“äº§ç”Ÿå™ªå£°æˆ–è¿‡äºå¹³æ»‘ã€‚
2. MoAngeloçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨é«˜è´¨é‡çš„é™æ€é‡å»ºç»“æœä½œä¸ºæ¨¡æ¿ï¼Œé€šè¿‡ä¼˜åŒ–å˜å½¢åœºæ¥è·Ÿè¸ªå’Œç»†åŒ–åŠ¨æ€åœºæ™¯ï¼Œä»è€Œå®ç°é«˜ç²¾åº¦çš„åŠ¨æ€é‡å»ºã€‚
3. è¯¥æ–¹æ³•åœ¨ActorsHQæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜äºç°æœ‰æŠ€æœ¯çš„é‡å»ºç²¾åº¦ï¼ŒéªŒè¯äº†å…¶åœ¨åŠ¨æ€åœºæ™¯é‡å»ºæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»å¤šè§†è§’è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯æ˜¯è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„ä¸€ä¸ªæ ¹æœ¬æ€§æŒ‘æˆ˜ã€‚è™½ç„¶æœ€è¿‘çš„ç¥ç»è¡¨é¢é‡å»ºæ–¹æ³•åœ¨é™æ€3Dé‡å»ºä¸­å–å¾—äº†æ˜¾è‘—æˆæœï¼Œä½†å°†è¿™äº›æ–¹æ³•æ‰©å±•åˆ°åŠ¨æ€åœºæ™¯å¹¶ä¿æŒç›¸å½“çš„è´¨é‡ï¼Œä¼šå¸¦æ¥å·¨å¤§çš„è®¡ç®—å’Œè¡¨ç¤ºæŒ‘æˆ˜ã€‚ç°æœ‰çš„åŠ¨æ€æ–¹æ³•ä¾§é‡äºæ–°è§†è§’åˆæˆï¼Œå› æ­¤ï¼Œå®ƒä»¬æå–çš„ç½‘æ ¼å¾€å¾€å­˜åœ¨å™ªå£°ã€‚å³ä½¿æ˜¯æ—¨åœ¨å®ç°å‡ ä½•ä¿çœŸåº¦çš„æ–¹æ³•ï¼Œç”±äºé—®é¢˜çš„ä¸é€‚å®šæ€§ï¼Œä¹Ÿç»å¸¸å¯¼è‡´è¿‡äºå¹³æ»‘çš„ç½‘æ ¼ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”¨äºé«˜ç»†èŠ‚åŠ¨æ€é‡å»ºçš„æ–°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶æ‰©å±•äº†é™æ€3Dé‡å»ºæ–¹æ³•NeuralAngeloä»¥åœ¨åŠ¨æ€è®¾ç½®ä¸­å·¥ä½œã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨NeuralAngeloä»åˆå§‹å¸§è¿›è¡Œé«˜è´¨é‡çš„æ¨¡æ¿åœºæ™¯é‡å»ºï¼Œç„¶åè”åˆä¼˜åŒ–å˜å½¢åœºï¼Œä»¥è·Ÿè¸ªæ¨¡æ¿å¹¶æ ¹æ®æ—¶é—´åºåˆ—å¯¹å…¶è¿›è¡Œç»†åŒ–ã€‚è¿™ç§çµæ´»çš„æ¨¡æ¿å…è®¸æ›´æ–°å‡ ä½•ä½“ï¼Œä»¥åŒ…æ‹¬æ— æ³•ç”¨å˜å½¢åœºå»ºæ¨¡çš„å˜åŒ–ï¼Œä¾‹å¦‚é®æŒ¡éƒ¨åˆ†æˆ–æ‹“æ‰‘ç»“æ„çš„å˜åŒ–ã€‚æˆ‘ä»¬åœ¨ActorsHQæ•°æ®é›†ä¸Šå±•ç¤ºäº†ä¸å…ˆå‰æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”çš„å“è¶Šé‡å»ºç²¾åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»å¤šè§†è§’è§†é¢‘ä¸­è¿›è¡Œé«˜ç²¾åº¦åŠ¨æ€åœºæ™¯é‡å»ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ä¾§é‡äºæ–°è§†è§’åˆæˆçš„æ–¹æ³•ï¼Œåœ¨åŠ¨æ€åœºæ™¯ä¸‹é‡å»ºçš„å‡ ä½•ç»†èŠ‚ä¸è¶³ï¼Œå®¹æ˜“äº§ç”Ÿå™ªå£°æˆ–è¿‡äºå¹³æ»‘çš„ç½‘æ ¼ï¼Œéš¾ä»¥æ»¡è¶³å¯¹å‡ ä½•ç²¾åº¦è¦æ±‚é«˜çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é™æ€åœºæ™¯é‡å»ºæ–¹æ³•NeuralAngeloç”Ÿæˆçš„é«˜è´¨é‡åˆå§‹å¸§é‡å»ºä½œä¸ºæ¨¡æ¿ï¼Œç„¶åé€šè¿‡ä¼˜åŒ–å˜å½¢åœºæ¥è·Ÿè¸ªå’Œç»†åŒ–è¯¥æ¨¡æ¿ï¼Œä½¿å…¶é€‚åº”åŠ¨æ€åœºæ™¯çš„å˜åŒ–ã€‚è¿™ç§æ–¹æ³•ç»“åˆäº†é™æ€é‡å»ºçš„ç²¾åº¦å’ŒåŠ¨æ€è·Ÿè¸ªçš„çµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMoAngeloæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨NeuralAngeloä»åˆå§‹å¸§é‡å»ºé«˜è´¨é‡çš„é™æ€åœºæ™¯æ¨¡æ¿ï¼›2) å¼•å…¥å˜å½¢åœºï¼Œç”¨äºè·Ÿè¸ªæ¨¡æ¿å¹¶ä½¿å…¶é€‚åº”åç»­å¸§ä¸­çš„åŠ¨æ€å˜åŒ–ï¼›3) è”åˆä¼˜åŒ–å˜å½¢åœºå’Œæ¨¡æ¿å‡ ä½•ä½“ï¼Œä»¥æé«˜é‡å»ºç²¾åº¦ï¼›4) å…è®¸åœ¨æ¨¡æ¿ä¸Šè¿›è¡Œå‡ ä½•æ›´æ–°ï¼Œä»¥å¤„ç†å˜å½¢åœºæ— æ³•å»ºæ¨¡çš„æƒ…å†µï¼Œå¦‚é®æŒ¡æˆ–æ‹“æ‰‘å˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†é™æ€é‡å»ºå’ŒåŠ¨æ€è·Ÿè¸ªç›¸ç»“åˆï¼Œåˆ©ç”¨é«˜è´¨é‡çš„é™æ€é‡å»ºç»“æœä½œä¸ºåŠ¨æ€é‡å»ºçš„å…ˆéªŒä¿¡æ¯ï¼Œå¹¶é€šè¿‡å˜å½¢åœºè¿›è¡Œç²¾ç»†çš„åŠ¨æ€è°ƒæ•´ã€‚æ­¤å¤–ï¼Œå…è®¸å¯¹æ¨¡æ¿è¿›è¡Œå‡ ä½•æ›´æ–°ï¼Œå¢å¼ºäº†å¯¹å¤æ‚åŠ¨æ€å˜åŒ–çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†å¯ä»¥æ¨æµ‹ï¼Œå˜å½¢åœºçš„ä¼˜åŒ–å¯èƒ½æ¶‰åŠåˆ°æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿è¯å˜å½¢åœºçš„å¹³æ»‘æ€§ã€‚å‡ ä½•æ›´æ–°çš„ç­–ç•¥å¯èƒ½æ¶‰åŠåˆ°å¯¹é‡å»ºç»“æœçš„ç½®ä¿¡åº¦è¯„ä¼°ï¼Œä»¥åŠå¯¹é®æŒ¡åŒºåŸŸçš„ç‰¹æ®Šå¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨ActorsHQæ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Œç»“æœè¡¨æ˜ï¼ŒMoAngeloåœ¨åŠ¨æ€åœºæ™¯é‡å»ºç²¾åº¦æ–¹é¢ä¼˜äºç°æœ‰çš„state-of-the-artæ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ï¼Œä½†å¼ºè°ƒäº†å…¶åœ¨é‡å»ºç²¾åº¦ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€ç”µå½±ç‰¹æ•ˆã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸã€‚é«˜ç²¾åº¦çš„åŠ¨æ€åœºæ™¯é‡å»ºèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´é€¼çœŸçš„æ²‰æµ¸å¼ä½“éªŒï¼Œå¹¶ä¸ºåŠ¨ç”»åˆ¶ä½œå’Œè§†è§‰ç‰¹æ•ˆæä¾›æ›´å¼ºå¤§çš„å·¥å…·ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸï¼Œå¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ„ŸçŸ¥å‘¨å›´ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dynamic scene reconstruction from multi-view videos remains a fundamental challenge in computer vision. While recent neural surface reconstruction methods have achieved remarkable results in static 3D reconstruction, extending these approaches with comparable quality for dynamic scenes introduces significant computational and representational challenges. Existing dynamic methods focus on novel-view synthesis, therefore, their extracted meshes tend to be noisy. Even approaches aiming for geometric fidelity often result in too smooth meshes due to the ill-posedness of the problem. We present a novel framework for highly detailed dynamic reconstruction that extends the static 3D reconstruction method NeuralAngelo to work in dynamic settings. To that end, we start with a high-quality template scene reconstruction from the initial frame using NeuralAngelo, and then jointly optimize deformation fields that track the template and refine it based on the temporal sequence. This flexible template allows updating the geometry to include changes that cannot be modeled with the deformation field, for instance occluded parts or the changes in the topology. We show superior reconstruction accuracy in comparison to previous state-of-the-art methods on the ActorsHQ dataset.

