---
layout: default
title: BulletGen: Improving 4D Reconstruction with Bullet-Time Generation
---

# BulletGen: Improving 4D Reconstruction with Bullet-Time Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18601" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18601v1</a>
  <a href="https://arxiv.org/pdf/2506.18601.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18601v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18601v1', 'BulletGen: Improving 4D Reconstruction with Bullet-Time Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Denys Rozumnyi, Jonathon Luiten, Numair Khan, Johannes SchÃ¶nberger, Peter Kontschieder

**åˆ†ç±»**: cs.GR, cs.AI, cs.CV, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBulletGenä»¥è§£å†³åŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„ä¿¡æ¯ç¼ºå¤±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åŠ¨æ€åœºæ™¯é‡å»º` `ç”Ÿæˆæ¨¡å‹` `è§†é¢‘å¤„ç†` `æ·±åº¦å­¦ä¹ ` `è™šæ‹Ÿç°å®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­é¢ä¸´ä¿¡æ¯ç¼ºå¤±å’Œå•ç›®æ·±åº¦ä¼°è®¡æ¨¡ç³Šæ€§ç­‰æŒ‘æˆ˜ï¼Œå¯¼è‡´é‡å»ºæ•ˆæœä¸ä½³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šBulletGené€šè¿‡å¯¹é½æ‰©æ•£æ¨¡å‹è¾“å‡ºä¸4Dé‡å»ºï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹çº æ­£é”™è¯¯å¹¶è¡¥å…¨ä¿¡æ¯ï¼Œæå‡é‡å»ºè´¨é‡ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šè¯¥æ–¹æ³•åœ¨æ–°è§†è§’åˆæˆå’Œ2D/3Dè·Ÿè¸ªä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†æ˜¾è‘—çš„æ•ˆæœæå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°†éšæ„æ•è·çš„å•ç›®è§†é¢‘è½¬åŒ–ä¸ºå®Œå…¨æ²‰æµ¸å¼åŠ¨æ€ä½“éªŒæ˜¯ä¸€é¡¹é«˜åº¦ä¸é€‚å®šçš„é—®é¢˜ï¼Œé¢ä¸´é‡å»ºæœªè§åŒºåŸŸå’Œå•ç›®æ·±åº¦ä¼°è®¡æ¨¡ç³Šæ€§ç­‰é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†BulletGenæ–¹æ³•ï¼Œåˆ©ç”¨ç”Ÿæˆæ¨¡å‹çº æ­£é”™è¯¯å¹¶è¡¥å…¨é«˜æ–¯åŠ¨æ€åœºæ™¯è¡¨ç¤ºä¸­çš„ç¼ºå¤±ä¿¡æ¯ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†åŸºäºæ‰©æ•£çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºä¸å•ä¸ªå›ºå®šâ€œå­å¼¹æ—¶é—´â€æ­¥éª¤çš„4Dé‡å»ºè¿›è¡Œå¯¹é½ï¼Œç”Ÿæˆçš„å¸§ç”¨äºç›‘ç£4Dé«˜æ–¯æ¨¡å‹çš„ä¼˜åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ— ç¼èåˆäº†ç”Ÿæˆå†…å®¹ä¸é™æ€å’ŒåŠ¨æ€åœºæ™¯ç»„ä»¶ï¼Œåœ¨æ–°è§†è§’åˆæˆå’Œ2D/3Dè·Ÿè¸ªä»»åŠ¡ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„ç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„ä¿¡æ¯ç¼ºå¤±å’Œæ¨¡ç³Šæ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å•ç›®è§†é¢‘æ—¶ï¼Œå¸¸å¸¸æ— æ³•æœ‰æ•ˆé‡å»ºæœªè§åŒºåŸŸï¼Œå¯¼è‡´é‡å»ºç»“æœä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šBulletGençš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ç”Ÿæˆæ¨¡å‹çš„èƒ½åŠ›ï¼Œé€šè¿‡å¯¹é½æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„è§†é¢‘å¸§ä¸4Dé‡å»ºç»“æœï¼Œæ¥çº æ­£é‡å»ºä¸­çš„é”™è¯¯å¹¶è¡¥å…¨ç¼ºå¤±ä¿¡æ¯ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆæå‡é‡å»ºçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯åŸºäºæ‰©æ•£çš„åŠ¨æ€è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå…¶æ¬¡æ˜¯4Dé«˜æ–¯æ¨¡å‹çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚ç”Ÿæˆæ¨¡å‹è¾“å‡ºçš„å¸§ä¸4Dé‡å»ºç»“æœè¿›è¡Œå¯¹é½ï¼Œä»¥æŒ‡å¯¼ä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†ç”Ÿæˆæ¨¡å‹ä¸åŠ¨æ€åœºæ™¯é‡å»ºç›¸ç»“åˆï¼Œé€šè¿‡â€œå­å¼¹æ—¶é—´â€æ­¥éª¤å®ç°ä¿¡æ¯çš„æœ‰æ•ˆè¡¥å…¨ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é‡å»ºæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„ä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ç”Ÿæˆå†…å®¹ä¸é‡å»ºå†…å®¹ä¹‹é—´çš„å…³ç³»ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æé«˜ç”Ÿæˆæ¨¡å‹çš„æ•ˆæœå’Œç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒBulletGenåœ¨æ–°è§†è§’åˆæˆå’Œ2D/3Dè·Ÿè¸ªä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œé‡å»ºè´¨é‡æé«˜äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œå±•ç¤ºäº†å…¶åœ¨åŠ¨æ€åœºæ™¯é‡å»ºä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®å’Œæ¸¸æˆå¼€å‘ç­‰ï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›æ›´åŠ æ²‰æµ¸å¼çš„åŠ¨æ€ä½“éªŒã€‚é€šè¿‡æå‡åŠ¨æ€åœºæ™¯é‡å»ºçš„è´¨é‡ï¼ŒBulletGenæœ‰æœ›åœ¨å½±è§†åˆ¶ä½œã€å®æ—¶è§†é¢‘å¤„ç†ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transforming casually captured, monocular videos into fully immersive dynamic experiences is a highly ill-posed task, and comes with significant challenges, e.g., reconstructing unseen regions, and dealing with the ambiguity in monocular depth estimation. In this work we introduce BulletGen, an approach that takes advantage of generative models to correct errors and complete missing information in a Gaussian-based dynamic scene representation. This is done by aligning the output of a diffusion-based video generation model with the 4D reconstruction at a single frozen "bullet-time" step. The generated frames are then used to supervise the optimization of the 4D Gaussian model. Our method seamlessly blends generative content with both static and dynamic scene components, achieving state-of-the-art results on both novel-view synthesis, and 2D/3D tracking tasks.

