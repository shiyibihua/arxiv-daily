---
layout: default
title: SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction
---

# SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19139" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19139v2</a>
  <a href="https://arxiv.org/pdf/2506.19139.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19139v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19139v2', 'SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lukas Radl, Felix Windisch, Thomas Deixelberger, Jozef Hladky, Michael Steiner, Dieter Schmalstieg, Markus Steinberger

**åˆ†ç±»**: cs.GR, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23 (æ›´æ–°: 2025-12-12)

**å¤‡æ³¨**: SIGGRAPH Asia 2025; Project Page: https://r4dl.github.io/SOF/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSOFä»¥è§£å†³å¤§è§„æ¨¡æ— ç•Œé¢é‡å»ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ä¸‰ç»´é‡å»º` `é«˜æ–¯è¡¨ç¤º` `ä¸é€æ˜åº¦åœº` `æ°´å¹³é›†` `è®¡ç®—æœºè§†è§‰` `å®æ—¶æ¸²æŸ“` `å‡ ä½•æå–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤§è§„æ¨¡æ— ç•Œç¯å¢ƒä¸­æå–å‡†ç¡®è¡¨é¢æ—¶ï¼Œå¸¸ä¾èµ–è¿‘ä¼¼æ·±åº¦ä¼°è®¡ï¼Œå¯¼è‡´ä¼ªå½±å’Œé‡å»ºè´¨é‡ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„SOFæ–¹æ³•é€šè¿‡åˆ†å±‚é‡æ’åºå’Œç¨³å¥çš„é«˜æ–¯æ·±åº¦å…¬å¼ï¼Œæå‡äº†è¡¨é¢é‡å»ºçš„é€Ÿåº¦å’Œç²¾åº¦ã€‚
3. SOFåœ¨å®éªŒä¸­æ˜¾ç¤ºå‡ºæ¯”åŸºçº¿æ–¹æ³•æ›´é«˜çš„é‡å»ºç²¾åº¦ï¼Œå¹¶å°†æ€»å¤„ç†æ—¶é—´å‡å°‘äº†ä¸‰å€ä»¥ä¸Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œ3Dé«˜æ–¯è¡¨ç¤ºæ³•åœ¨åŸºäºå›¾åƒçš„åœºæ™¯é‡å»ºä¸­æ˜¾è‘—æé«˜äº†è´¨é‡å’Œæ•ˆç‡ã€‚ç„¶è€Œï¼Œåœ¨å¤§è§„æ¨¡æ— ç•Œç¯å¢ƒä¸­æå–å‡†ç¡®çš„è¡¨é¢ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¸¸ä¾èµ–äºè¿‘ä¼¼æ·±åº¦ä¼°è®¡å’Œå…¨å±€æ’åºå¯å‘å¼ï¼Œå¯èƒ½å¼•å…¥ä¼ªå½±å¹¶é™åˆ¶é‡å»ºç½‘æ ¼çš„ä¿çœŸåº¦ã€‚æœ¬æ–‡æå‡ºäº†æ’åºä¸é€æ˜åº¦åœºï¼ˆSOFï¼‰ï¼Œæ—¨åœ¨ä»¥é€Ÿåº¦å’Œç²¾åº¦æ¢å¤è¯¦ç»†è¡¨é¢ã€‚é€šè¿‡å¼•å…¥åˆ†å±‚é‡æ’åºå’Œç¨³å¥çš„é«˜æ–¯æ·±åº¦å…¬å¼ï¼ŒSOFæ›´å¥½åœ°ä¸æ°´å¹³é›†å¯¹é½ã€‚æ­¤å¤–ï¼Œé‡‡ç”¨ä¸é€æ˜åº¦åœºçš„æ°´å¹³é›†æ­£åˆ™åŒ–å™¨å’Œé¼“åŠ±å‡ ä½•ä¸€è‡´æ€§åŸå§‹å½¢çŠ¶çš„æŸå¤±å‡½æ•°ï¼Œæå‡äº†ç½‘æ ¼è´¨é‡ã€‚å®éªŒè¡¨æ˜ï¼ŒSOFåœ¨æé«˜é‡å»ºç²¾åº¦çš„åŒæ—¶ï¼Œå¤„ç†æ—¶é—´å‡å°‘äº†ä¸‰å€ä»¥ä¸Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤§è§„æ¨¡æ— ç•Œç¯å¢ƒä¸­æå–å‡†ç¡®è¡¨é¢çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºè¿‘ä¼¼æ·±åº¦ä¼°è®¡å’Œå…¨å±€æ’åºï¼Œå¯¼è‡´é‡å»ºè´¨é‡ä¸é«˜ï¼Œä¸”æ˜“äº§ç”Ÿä¼ªå½±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSOFæ–¹æ³•é€šè¿‡å¼•å…¥åˆ†å±‚é‡æ’åºå’Œç¨³å¥çš„é«˜æ–¯æ·±åº¦å…¬å¼ï¼Œæ—¨åœ¨æé«˜è¡¨é¢é‡å»ºçš„ç²¾åº¦å’Œé€Ÿåº¦ã€‚è¿™ç§è®¾è®¡ä½¿å¾—é‡å»ºè¿‡ç¨‹æ›´ä¸ºé«˜æ•ˆä¸”å‡†ç¡®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSOFçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯é«˜æ–¯è¡¨ç¤ºçš„è¾“å…¥å¤„ç†ï¼Œç„¶åæ˜¯åˆ†å±‚é‡æ’åºçš„å®æ–½ï¼Œæ¥ç€æ˜¯åº”ç”¨æ°´å¹³é›†æ­£åˆ™åŒ–ï¼Œæœ€åé€šè¿‡å¹¶è¡ŒåŒ–çš„å››é¢ä½“åˆ’åˆ†ç®—æ³•ç”Ÿæˆç½‘æ ¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šSOFçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶åˆ†å±‚é‡æ’åºå’Œé«˜æ–¯æ·±åº¦çš„ç¨³å¥å…¬å¼ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„å…¨å±€æ’åºå’Œè¿‘ä¼¼æ·±åº¦ä¼°è®¡å½¢æˆäº†æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸é€æ˜åº¦åœºçš„æ°´å¹³é›†æ­£åˆ™åŒ–å™¨ï¼Œå¹¶å¼•å…¥äº†é¼“åŠ±å‡ ä½•ä¸€è‡´æ€§åŸå§‹å½¢çŠ¶çš„æŸå¤±å‡½æ•°ã€‚è¿™äº›è®¾è®¡ç»†èŠ‚æ˜¾è‘—æå‡äº†é‡å»ºç½‘æ ¼çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSOFæ–¹æ³•åœ¨é‡å»ºç²¾åº¦ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå¤„ç†æ—¶é—´å‡å°‘äº†ä¸‰å€ä»¥ä¸Šã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†é«˜æ•ˆçš„é«˜æ–¯åŸºç¡€æ¸²æŸ“ä¸å‡ ä½•æå–ä¹‹é—´çš„æœ‰æ•ˆç»“åˆï¼Œæ ‡å¿—ç€è¯¥é¢†åŸŸçš„é‡å¤§è¿›æ­¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è®¡ç®—æœºè§†è§‰ã€æœºå™¨äººå¯¼èˆªå’Œè™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚SOFæ–¹æ³•èƒ½å¤Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­å¿«é€Ÿã€å‡†ç¡®åœ°é‡å»ºä¸‰ç»´è¡¨é¢ï¼Œä¸ºå®æ—¶æ¸²æŸ“å’Œåœºæ™¯ç†è§£æä¾›äº†é‡è¦æ”¯æŒï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in 3D Gaussian representations have significantly improved the quality and efficiency of image-based scene reconstruction. Their explicit nature facilitates real-time rendering and fast optimization, yet extracting accurate surfaces - particularly in large-scale, unbounded environments - remains a difficult task. Many existing methods rely on approximate depth estimates and global sorting heuristics, which can introduce artifacts and limit the fidelity of the reconstructed mesh. In this paper, we present Sorted Opacity Fields (SOF), a method designed to recover detailed surfaces from 3D Gaussians with both speed and precision. Our approach improves upon prior work by introducing hierarchical resorting and a robust formulation of Gaussian depth, which better aligns with the level-set. To enhance mesh quality, we incorporate a level-set regularizer operating on the opacity field and introduce losses that encourage geometrically-consistent primitive shapes. In addition, we develop a parallelized Marching Tetrahedra algorithm tailored to our opacity formulation, reducing meshing time by up to an order of magnitude. As demonstrated by our quantitative evaluation, SOF achieves higher reconstruction accuracy while cutting total processing time by more than a factor of three. These results mark a step forward in turning efficient Gaussian-based rendering into equally efficient geometry extraction.

