---
layout: default
title: Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation
---

# Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.02278" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.02278v1</a>
  <a href="https://arxiv.org/pdf/2509.02278.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.02278v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.02278v1', 'Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zikai Huang, Yihan Zhou, Xuemiao Xu, Cheng Xu, Xiaofen Xing, Jing Qin, Shengfeng He

**åˆ†ç±»**: cs.GR, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Think2Singï¼šæå‡ºåŸºäºæ‰©æ•£æ¨¡å‹çš„æ­Œå”±é©±åŠ¨3Då¤´éƒ¨åŠ¨ç”»æ¡†æ¶ï¼Œæå‡åŠ¨ç”»è¡¨ç°åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ­Œå”±é©±åŠ¨åŠ¨ç”»` `3Då¤´éƒ¨åŠ¨ç”»` `æ‰©æ•£æ¨¡å‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¿åŠ¨å­—å¹•` `æ€ç»´é“¾æ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ­Œå”±é©±åŠ¨çš„3Då¤´éƒ¨åŠ¨ç”»æ–¹æ³•éš¾ä»¥æ•æ‰æ­Œå”±ä¸­ä¸°å¯Œçš„æƒ…æ„Ÿå’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´åŠ¨ç”»æ•ˆæœå¹³æ·¡ä¸”ä¸è‡ªç„¶ã€‚
2. Think2Singåˆ©ç”¨æ‰©æ•£æ¨¡å‹å’Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œç»“åˆæ­Œè¯å’Œå£°éŸ³ä¿¡æ¯ï¼Œç”Ÿæˆè¯­ä¹‰è¿è´¯ä¸”æ—¶é—´ä¸€è‡´çš„3Då¤´éƒ¨åŠ¨ç”»ã€‚
3. é€šè¿‡å¼•å…¥è¿åŠ¨å­—å¹•ä½œä¸ºè¿åŠ¨å…ˆéªŒï¼Œå¹¶å°†å…¶å»ºæ¨¡ä¸ºè¿åŠ¨å¼ºåº¦é¢„æµ‹é—®é¢˜ï¼Œå®ç°äº†æ›´ç²¾ç»†çš„é¢éƒ¨åŒºåŸŸæ§åˆ¶å’Œæ›´å…·è¡¨ç°åŠ›çš„è¿åŠ¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­Œå”±é©±åŠ¨çš„3Då¤´éƒ¨åŠ¨ç”»æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§ä½†å‰æ™¯å¹¿é˜”çš„ä»»åŠ¡ï¼Œå¯åº”ç”¨äºè™šæ‹ŸåŒ–èº«ã€å¨±ä¹å’Œæ•™è‚²ã€‚ä¸è¯­éŸ³ä¸åŒï¼Œæ­Œå”±æ¶‰åŠæ›´ä¸°å¯Œçš„æƒ…æ„Ÿç»†å¾®å·®åˆ«ã€åŠ¨æ€éŸµå¾‹å’ŒåŸºäºæ­Œè¯çš„è¯­ä¹‰ï¼Œéœ€è¦åˆæˆç²¾ç»†ã€æ—¶é—´è¿è´¯çš„é¢éƒ¨è¿åŠ¨ã€‚ç°æœ‰çš„è¯­éŸ³é©±åŠ¨æ–¹æ³•é€šå¸¸äº§ç”Ÿè¿‡äºç®€å•ã€æƒ…æ„Ÿå¹³æ·¡å’Œè¯­ä¹‰ä¸ä¸€è‡´çš„ç»“æœï¼Œä¸è¶³ä»¥ç”¨äºæ­Œå”±åŠ¨ç”»ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†Think2Singï¼Œä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹çš„æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹æ¥ç”Ÿæˆè¯­ä¹‰è¿è´¯ä¸”æ—¶é—´ä¸€è‡´çš„3Då¤´éƒ¨åŠ¨ç”»ï¼Œå¹¶ä»¥æ­Œè¯å’Œå£°éŸ³ä¸ºæ¡ä»¶ã€‚ä¸€ä¸ªå…³é”®çš„åˆ›æ–°æ˜¯å¼•å…¥äº†è¿åŠ¨å­—å¹•ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡æ–°é¢–çš„æ­Œå”±æ€ç»´é“¾æ¨ç†è¿‡ç¨‹ä¸å£°éŸ³å¼•å¯¼æ£€ç´¢ç›¸ç»“åˆè€Œè·å¾—çš„è¾…åŠ©è¯­ä¹‰è¡¨ç¤ºã€‚è¿™äº›å­—å¹•åŒ…å«ç²¾ç¡®çš„æ—¶é—´æˆ³å’Œç‰¹å®šåŒºåŸŸçš„è¿åŠ¨æè¿°ï¼Œä½œä¸ºå¯è§£é‡Šçš„è¿åŠ¨å…ˆéªŒã€‚æˆ‘ä»¬å°†è¯¥ä»»åŠ¡å®šä¹‰ä¸ºè¿åŠ¨å¼ºåº¦é¢„æµ‹é—®é¢˜ï¼Œä»è€Œå¯ä»¥æ›´å¥½åœ°æ§åˆ¶é¢éƒ¨åŒºåŸŸå¹¶æ”¹è¿›è¡¨è¾¾æ€§è¿åŠ¨çš„å»ºæ¨¡ã€‚ä¸ºäº†æ”¯æŒè¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªå¤šæ¨¡æ€æ­Œå”±æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«åŒæ­¥çš„è§†é¢‘ã€å£°éŸ³æè¿°ç¬¦å’Œè¿åŠ¨å­—å¹•ï¼Œä»è€Œå¯ä»¥è¿›è¡Œå¤šæ ·åŒ–å’Œå¯Œæœ‰è¡¨ç°åŠ›çš„è¿åŠ¨å­¦ä¹ ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼ŒThink2Singåœ¨çœŸå®æ„Ÿã€è¡¨ç°åŠ›å’Œæƒ…æ„Ÿä¿çœŸåº¦æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶è¿˜æä¾›äº†çµæ´»çš„ã€ç”¨æˆ·å¯æ§çš„åŠ¨ç”»ç¼–è¾‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ­Œå”±é©±åŠ¨çš„3Då¤´éƒ¨åŠ¨ç”»ç”Ÿæˆé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºè¯­éŸ³é©±åŠ¨çš„æ–¹æ³•ï¼Œæ— æ³•å……åˆ†æ•æ‰æ­Œå”±ä¸­ä¸°å¯Œçš„æƒ…æ„Ÿã€éŸµå¾‹å’Œè¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´ç”Ÿæˆçš„åŠ¨ç”»ç¼ºä¹çœŸå®æ„Ÿã€è¡¨ç°åŠ›å’Œæƒ…æ„Ÿä¿çœŸåº¦ã€‚è¿™äº›æ–¹æ³•é€šå¸¸è¿‡äºç®€åŒ–é¢éƒ¨è¿åŠ¨ï¼Œå¿½ç•¥äº†æ­Œè¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶ä¸”éš¾ä»¥å®ç°ç²¾ç»†çš„é¢éƒ¨åŒºåŸŸæ§åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥ç†è§£æ­Œè¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä¸å£°éŸ³ä¿¡æ¯ç›¸ç»“åˆï¼Œç”Ÿæˆé«˜è´¨é‡çš„3Då¤´éƒ¨åŠ¨ç”»ã€‚é€šè¿‡å¼•å…¥â€œè¿åŠ¨å­—å¹•â€ä½œä¸ºä¸­é—´è¡¨ç¤ºï¼Œå°†æ­Œè¯çš„è¯­ä¹‰ä¿¡æ¯è½¬åŒ–ä¸ºå…·ä½“çš„é¢éƒ¨è¿åŠ¨æè¿°ï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„æ§åˆ¶å’Œæ›´å…·è¡¨ç°åŠ›çš„åŠ¨ç”»æ•ˆæœã€‚å°†åŠ¨ç”»ç”Ÿæˆä»»åŠ¡å»ºæ¨¡ä¸ºè¿åŠ¨å¼ºåº¦é¢„æµ‹é—®é¢˜ï¼Œå…è®¸å¯¹ä¸åŒé¢éƒ¨åŒºåŸŸè¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šThink2Singæ¡†æ¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) **æ­Œå”±æ€ç»´é“¾æ¨ç†**ï¼šåˆ©ç”¨LLMå¯¹æ­Œè¯è¿›è¡Œæ¨ç†ï¼Œç”ŸæˆåŒ…å«æ—¶é—´æˆ³å’ŒåŒºåŸŸç‰¹å®šè¿åŠ¨æè¿°çš„è¿åŠ¨å­—å¹•ã€‚2) **å£°éŸ³å¼•å¯¼æ£€ç´¢**ï¼šæ ¹æ®å£°éŸ³ä¿¡æ¯æ£€ç´¢ç›¸å…³çš„è¿åŠ¨å­—å¹•ã€‚3) **æ‰©æ•£æ¨¡å‹**ï¼šä»¥æ­Œè¯ã€å£°éŸ³å’Œè¿åŠ¨å­—å¹•ä¸ºæ¡ä»¶ï¼Œç”Ÿæˆ3Då¤´éƒ¨åŠ¨ç”»ã€‚æ¡†æ¶å°†åŠ¨ç”»ç”Ÿæˆå»ºæ¨¡ä¸ºè¿åŠ¨å¼ºåº¦é¢„æµ‹é—®é¢˜ï¼Œä»è€Œå¯ä»¥æ›´å¥½åœ°æ§åˆ¶é¢éƒ¨åŒºåŸŸã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¼•å…¥äº†â€œè¿åŠ¨å­—å¹•â€è¿™ä¸€æ¦‚å¿µï¼Œä½œä¸ºæ­Œè¯è¯­ä¹‰ä¿¡æ¯å’Œé¢éƒ¨è¿åŠ¨ä¹‹é—´çš„æ¡¥æ¢ã€‚è¿åŠ¨å­—å¹•é€šè¿‡æ­Œå”±æ€ç»´é“¾æ¨ç†å’Œå£°éŸ³å¼•å¯¼æ£€ç´¢ç”Ÿæˆï¼ŒåŒ…å«ç²¾ç¡®çš„æ—¶é—´æˆ³å’ŒåŒºåŸŸç‰¹å®šçš„è¿åŠ¨æè¿°ï¼Œä½œä¸ºå¯è§£é‡Šçš„è¿åŠ¨å…ˆéªŒã€‚æ­¤å¤–ï¼Œå°†åŠ¨ç”»ç”Ÿæˆä»»åŠ¡å»ºæ¨¡ä¸ºè¿åŠ¨å¼ºåº¦é¢„æµ‹é—®é¢˜ï¼Œå…è®¸å¯¹ä¸åŒé¢éƒ¨åŒºåŸŸè¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šè¿åŠ¨å­—å¹•çš„ç”Ÿæˆä¾èµ–äºç²¾å¿ƒè®¾è®¡çš„æ­Œå”±æ€ç»´é“¾æ¨ç†è¿‡ç¨‹ï¼Œè¯¥è¿‡ç¨‹åˆ©ç”¨LLMå¯¹æ­Œè¯è¿›è¡Œé€æ­¥åˆ†æï¼Œç”ŸæˆåŒ…å«æ—¶é—´æˆ³å’ŒåŒºåŸŸç‰¹å®šè¿åŠ¨æè¿°çš„æ–‡æœ¬ã€‚å£°éŸ³å¼•å¯¼æ£€ç´¢ç”¨äºä»å€™é€‰è¿åŠ¨å­—å¹•ä¸­é€‰æ‹©ä¸å½“å‰å£°éŸ³ä¿¡æ¯æœ€ç›¸å…³çš„å­—å¹•ã€‚æ‰©æ•£æ¨¡å‹é‡‡ç”¨U-Netç»“æ„ï¼Œä»¥æ­Œè¯ã€å£°éŸ³å’Œè¿åŠ¨å­—å¹•ä¸ºæ¡ä»¶ï¼Œé¢„æµ‹è¿åŠ¨å¼ºåº¦ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬L1æŸå¤±å’Œæ„ŸçŸ¥æŸå¤±ï¼Œä»¥æé«˜åŠ¨ç”»çš„çœŸå®æ„Ÿå’Œè§†è§‰è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒThink2Singåœ¨çœŸå®æ„Ÿã€è¡¨ç°åŠ›å’Œæƒ…æ„Ÿä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒThink2Singç”Ÿæˆçš„åŠ¨ç”»åœ¨ä¸»è§‚è¯„ä»·ä¸­è·å¾—äº†æ›´é«˜çš„è¯„åˆ†ã€‚æ­¤å¤–ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ç¼–è¾‘è¿åŠ¨å­—å¹•æ¥çµæ´»åœ°æ§åˆ¶åŠ¨ç”»æ•ˆæœï¼Œå®ç°ä¸ªæ€§åŒ–çš„åŠ¨ç”»å®šåˆ¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Think2Singå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬è™šæ‹ŸåŒ–èº«ã€å¨±ä¹ã€æ•™è‚²å’Œè¾…åŠ©æ²Ÿé€šã€‚å®ƒå¯ä»¥ç”¨äºåˆ›å»ºæ›´é€¼çœŸã€æ›´å…·è¡¨ç°åŠ›çš„è™šæ‹Ÿè§’è‰²ï¼Œæå‡æ¸¸æˆã€ç”µå½±å’ŒåŠ¨ç”»çš„åˆ¶ä½œè´¨é‡ã€‚åœ¨æ•™è‚²é¢†åŸŸï¼Œå®ƒå¯ä»¥ç”¨äºåˆ›å»ºç”ŸåŠ¨çš„æ•™å­¦å†…å®¹ï¼Œå¸®åŠ©å­¦ç”Ÿæ›´å¥½åœ°ç†è§£å’Œè®°å¿†çŸ¥è¯†ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥ç”¨äºè¾…åŠ©æ²Ÿé€šï¼Œå¸®åŠ©æ®‹ç–¾äººè¡¨è¾¾æƒ…æ„Ÿå’Œæ„å›¾ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Singing-driven 3D head animation is a challenging yet promising task with applications in virtual avatars, entertainment, and education. Unlike speech, singing involves richer emotional nuance, dynamic prosody, and lyric-based semantics, requiring the synthesis of fine-grained, temporally coherent facial motion. Existing speech-driven approaches often produce oversimplified, emotionally flat, and semantically inconsistent results, which are insufficient for singing animation. To address this, we propose Think2Sing, a diffusion-based framework that leverages pretrained large language models to generate semantically coherent and temporally consistent 3D head animations, conditioned on both lyrics and acoustics. A key innovation is the introduction of motion subtitles, an auxiliary semantic representation derived through a novel Singing Chain-of-Thought reasoning process combined with acoustic-guided retrieval. These subtitles contain precise timestamps and region-specific motion descriptions, serving as interpretable motion priors. We frame the task as a motion intensity prediction problem, enabling finer control over facial regions and improving the modeling of expressive motion. To support this, we create a multimodal singing dataset with synchronized video, acoustic descriptors, and motion subtitles, enabling diverse and expressive motion learning. Extensive experiments show that Think2Sing outperforms state-of-the-art methods in realism, expressiveness, and emotional fidelity, while also offering flexible, user-controllable animation editing.

