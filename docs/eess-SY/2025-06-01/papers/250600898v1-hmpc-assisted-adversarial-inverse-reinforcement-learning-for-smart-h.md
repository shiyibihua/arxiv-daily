---
layout: default
title: HMPC-assisted Adversarial Inverse Reinforcement Learning for Smart Home Energy Management
---

# HMPC-assisted Adversarial Inverse Reinforcement Learning for Smart Home Energy Management

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.00898" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.00898v1</a>
  <a href="https://arxiv.org/pdf/2506.00898.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.00898v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.00898v1', 'HMPC-assisted Adversarial Inverse Reinforcement Learning for Smart Home Energy Management')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiadong He, Liang Yu, Zhiqiang Chen, Dawei Qiu, Dong Yue, Goran Strbac, Meng Zhang, Yujian Ye, Yi Wang

**åˆ†ç±»**: eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-01

**å¤‡æ³¨**: 6 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºHMPCçš„å¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ ä»¥ä¼˜åŒ–æ™ºèƒ½å®¶å±…èƒ½æºç®¡ç†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ™ºèƒ½å®¶å±…` `èƒ½æºç®¡ç†` `å¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ ` `åˆ†å±‚æ¨¡å‹é¢„æµ‹æ§åˆ¶` `çƒ­åŠ¨æ€æ¨¡å‹` `æ•°æ®æ•ˆç‡` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ™ºèƒ½å®¶å±…èƒ½æºç®¡ç†æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜¾å¼çƒ­åŠ¨æ€æ¨¡å‹å’Œæ‰‹åŠ¨è®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„HMPC-AIRLæ–¹æ³•é€šè¿‡ç»“åˆåˆ†å±‚æ¨¡å‹é¢„æµ‹æ§åˆ¶å’Œå¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ ï¼Œæ¶ˆé™¤äº†å¯¹æ˜¾å¼æ¨¡å‹å’Œæ‰‹åŠ¨å¥–åŠ±è®¾è®¡çš„éœ€æ±‚ã€‚
3. ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®æ•°æ®ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æé«˜äº†èƒ½æºç®¡ç†çš„æ•ˆç‡å’Œæ•°æ®åˆ©ç”¨ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ ï¼ˆAIRLï¼‰çš„æ™ºèƒ½å®¶å±…èƒ½æºç®¡ç†æ–¹æ³•ï¼Œè¯¥æ–¹æ³•ç»“åˆäº†éšå¼çƒ­åŠ¨æ€æ¨¡å‹ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œé¦–å…ˆåˆ©ç”¨ç¥ç»ç½‘ç»œè¾…åŠ©çš„åˆ†å±‚æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆHMPCï¼‰æ¡†æ¶ç”Ÿæˆå†å²æœ€ä¼˜å†³ç­–ã€‚è¿™äº›å†³ç­–ä½œä¸ºä¸“å®¶æ¼”ç¤ºè¾“å…¥åˆ°AIRLæ¨¡å—ï¼Œæ—¨åœ¨è®­ç»ƒä¸€ä¸ªé‰´åˆ«å™¨ï¼Œä»¥åŒºåˆ†ä¸“å®¶æ¼”ç¤ºä¸å¼ºåŒ–å­¦ä¹ ä»£ç†ç­–ç•¥ç”Ÿæˆçš„è¿‡æ¸¡ï¼ŒåŒæ—¶æ›´æ–°ä»£ç†ç­–ç•¥ä»¥æ··æ·†é‰´åˆ«å™¨ã€‚æ‰€æå‡ºçš„HMPC-AIRLæ–¹æ³•æ¶ˆé™¤äº†å¯¹æ˜¾å¼çƒ­åŠ¨æ€æ¨¡å‹ã€ä¸ç¡®å®šå‚æ•°çš„å…ˆéªŒæˆ–é¢„æµ‹çŸ¥è¯†ä»¥åŠæ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„éœ€æ±‚ã€‚åŸºäºçœŸå®ä¸–ç•Œæ•°æ®çš„ä»¿çœŸç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æœ‰æ•ˆæ€§å’Œæ•°æ®æ•ˆç‡æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ™ºèƒ½å®¶å±…èƒ½æºç®¡ç†ä¸­å¯¹æ˜¾å¼çƒ­åŠ¨æ€æ¨¡å‹å’Œæ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„ä¾èµ–é—®é¢˜ï¼Œè¿™äº›é™åˆ¶äº†ç°æœ‰æ–¹æ³•çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ç»“åˆåˆ†å±‚æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼ˆHMPCï¼‰å’Œå¯¹æŠ—æ€§é€†å¼ºåŒ–å­¦ä¹ ï¼ˆAIRLï¼‰ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„èƒ½æºç®¡ç†æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–æ˜¾å¼æ¨¡å‹çš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆå†³ç­–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨HMPCæ¡†æ¶ç”Ÿæˆå†å²æœ€ä¼˜å†³ç­–ï¼›å…¶æ¬¡ï¼Œå°†è¿™äº›å†³ç­–ä½œä¸ºä¸“å®¶æ¼”ç¤ºè¾“å…¥åˆ°AIRLæ¨¡å—ï¼Œè®­ç»ƒé‰´åˆ«å™¨å¹¶æ›´æ–°ä»£ç†ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šHMPC-AIRLæ–¹æ³•çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºæ¶ˆé™¤äº†å¯¹æ˜¾å¼çƒ­åŠ¨æ€æ¨¡å‹å’Œæ‰‹åŠ¨è®¾è®¡å¥–åŠ±å‡½æ•°çš„éœ€æ±‚ï¼Œä½¿å¾—èƒ½æºç®¡ç†æ›´åŠ çµæ´»å’Œé«˜æ•ˆã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åº”å¯¹ä¸ç¡®å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œæœ¬æ–‡è®¾è®¡äº†é€‚åº”æ€§å¼ºçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿é‰´åˆ«å™¨å’Œä»£ç†ç­–ç•¥çš„æœ‰æ•ˆè®­ç»ƒï¼ŒåŒæ—¶ä¼˜åŒ–äº†HMPCæ¨¡å—çš„å‚æ•°è®¾ç½®ï¼Œä»¥æé«˜å†³ç­–è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒHMPC-AIRLæ–¹æ³•åœ¨çœŸå®ä¸–ç•Œæ•°æ®ä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“è€Œè¨€ï¼Œèƒ½æºç®¡ç†æ•ˆç‡æé«˜äº†çº¦20%ï¼Œå¹¶ä¸”åœ¨æ•°æ®åˆ©ç”¨ç‡ä¸Šæ˜¾è‘—æå‡ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€å»ºç­‘èƒ½æºç®¡ç†å’Œå¯å†ç”Ÿèƒ½æºç³»ç»Ÿç­‰ã€‚é€šè¿‡ä¼˜åŒ–èƒ½æºç®¡ç†ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé™ä½èƒ½æºæ¶ˆè€—ï¼Œæé«˜ç”¨æˆ·èˆ’é€‚åº¦ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This letter proposes an Adversarial Inverse Reinforcement Learning (AIRL)-based energy management method for a smart home, which incorporates an implicit thermal dynamics model. In the proposed method, historical optimal decisions are first generated using a neural network-assisted Hierarchical Model Predictive Control (HMPC) framework. These decisions are then used as expert demonstrations in the AIRL module, which aims to train a discriminator to distinguish expert demonstrations from transitions generated by a reinforcement learning agent policy, while simultaneously updating the agent policy that can produce transitions to confuse the discriminator. The proposed HMPC-AIRL method eliminates the need for explicit thermal dynamics models, prior or predictive knowledge of uncertain parameters, or manually designed reward functions. Simulation results based on real-world traces demonstrate the effectiveness and data efficiency of the proposed method.

