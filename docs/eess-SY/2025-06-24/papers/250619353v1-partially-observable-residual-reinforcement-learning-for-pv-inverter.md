---
layout: default
title: Partially Observable Residual Reinforcement Learning for PV-Inverter-Based Voltage Control in Distribution Grids
---

# Partially Observable Residual Reinforcement Learning for PV-Inverter-Based Voltage Control in Distribution Grids

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19353v1</a>
  <a href="https://arxiv.org/pdf/2506.19353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19353v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19353v1', 'Partially Observable Residual Reinforcement Learning for PV-Inverter-Based Voltage Control in Distribution Grids')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sarra Bouchkati, Ramil Sabirov, Steffen Kortmann, Andreas Ulbig

**åˆ†ç±»**: eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéƒ¨åˆ†å¯è§‚æµ‹æ®‹å·®å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³é…ç”µç½‘ç”µå‹æ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ®‹å·®å¼ºåŒ–å­¦ä¹ ` `ç”µå‹æ§åˆ¶` `é…ç”µç½‘` `æ™ºèƒ½ç”µç½‘` `é€†å˜å™¨` `æ·±åº¦å­¦ä¹ ` `ç”µåŠ›ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç”µå‹æ§åˆ¶åœ¨é…ç”µç½‘ä¸­é¢ä¸´ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ æ–¹æ³•æ”¶æ•›æ…¢å’Œæ¢ç´¢æ•ˆç‡ä½çš„é—®é¢˜ã€‚
2. æå‡ºçš„RRLæ–¹æ³•åœ¨ä¿®æ”¹çš„é¡ºåºä¸‹å‚æ§åˆ¶æœºåˆ¶ä¸Šå­¦ä¹ æ®‹å·®ç­–ç•¥ï¼Œä»è€ŒåŠ é€Ÿæ”¶æ•›ã€‚
3. ä»¿çœŸç»“æœæ˜¾ç¤ºï¼ŒRRLæ¡†æ¶å®ç°äº†å¿«é€Ÿæ”¶æ•›å’Œæœ‰æ•ˆçš„ç”µå‹è°ƒèŠ‚ï¼Œå‡å°‘äº†æœ‰åŠŸåŠŸç‡å‰Šå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ®‹å·®å¼ºåŒ–å­¦ä¹ ï¼ˆRRLï¼‰æ¡†æ¶ï¼Œç”¨äºä¸»åŠ¨é…ç”µç½‘ä¸­çš„ç”µå‹æ§åˆ¶ã€‚ç”µå‹æ§åˆ¶åœ¨é…ç”µç½‘ä¸­ä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ï¼Œä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¾€å¾€é¢ä¸´è®­ç»ƒæ”¶æ•›é€Ÿåº¦æ…¢å’Œæ¢ç´¢æ•ˆç‡ä½çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæ‰€æå‡ºçš„RRLæ–¹æ³•åœ¨ä¿®æ”¹åçš„é¡ºåºä¸‹å‚æ§åˆ¶ï¼ˆSDCï¼‰æœºåˆ¶ä¸Šå­¦ä¹ æ®‹å·®ç­–ç•¥ï¼Œä»è€Œç¡®ä¿æ›´å¿«çš„æ”¶æ•›ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å±€éƒ¨å…±äº«çº¿æ€§ï¼ˆLSLï¼‰æ¶æ„çš„Qç½‘ç»œå’ŒTransformerç¼–ç å™¨æ¼”å‘˜ç½‘ç»œï¼Œæ•´ä½“æå‡äº†æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼Œæ‰€ææ–¹æ³•ä»…ä¾èµ–é€†å˜å™¨çš„æµ‹é‡æ•°æ®ï¼Œè€Œä¸éœ€è¦ç”µç½‘çš„å®Œæ•´çŠ¶æ€ä¿¡æ¯ï¼Œä½¿å…¶åœ¨å®é™…åº”ç”¨ä¸­æ›´å…·å¯è¡Œæ€§ã€‚ä»¿çœŸç»“æœéªŒè¯äº†RRLæ¡†æ¶åœ¨å®ç°å¿«é€Ÿæ”¶æ•›ã€æœ€å°åŒ–æœ‰åŠŸåŠŸç‡å‰Šå‡å’Œç¡®ä¿å¯é ç”µå‹è°ƒèŠ‚æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é…ç”µç½‘ä¸­çš„ç”µå‹æ§åˆ¶é—®é¢˜ï¼Œç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨è®­ç»ƒæ”¶æ•›é€Ÿåº¦å’Œæ¢ç´¢æ•ˆç‡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆåº”å¯¹ç”µå‹æ³¢åŠ¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ®‹å·®å¼ºåŒ–å­¦ä¹ ï¼ˆRRLï¼‰æ¡†æ¶ï¼Œé€šè¿‡åœ¨ä¿®æ”¹çš„é¡ºåºä¸‹å‚æ§åˆ¶æœºåˆ¶ä¸Šå­¦ä¹ æ®‹å·®ç­–ç•¥ï¼Œæ—¨åœ¨æé«˜æ”¶æ•›é€Ÿåº¦å’Œæ§åˆ¶ç²¾åº¦ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç®—æ³•èƒ½å¤Ÿåœ¨ä¸ä¾èµ–å®Œæ•´çŠ¶æ€ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é€†å˜å™¨çš„æµ‹é‡æ•°æ®è¿›è¡Œæœ‰æ•ˆæ§åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå±€éƒ¨å…±äº«çº¿æ€§ï¼ˆLSLï¼‰æ¶æ„çš„Qç½‘ç»œå’ŒTransformerç¼–ç å™¨æ¼”å‘˜ç½‘ç»œã€‚Qç½‘ç»œç”¨äºè¯„ä¼°ç­–ç•¥çš„ä»·å€¼ï¼Œè€Œæ¼”å‘˜ç½‘ç»œåˆ™è´Ÿè´£ç”Ÿæˆæ§åˆ¶ç­–ç•¥ã€‚æ•´ä½“æµç¨‹é€šè¿‡ä¸æ–­è¿­ä»£ä¼˜åŒ–ç­–ç•¥ï¼Œä»¥å®ç°ç”µå‹æ§åˆ¶çš„ç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†æ®‹å·®å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ä¸ä¾èµ–å®Œæ•´ç”µç½‘çŠ¶æ€ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨é€†å˜å™¨çš„å±€éƒ¨æµ‹é‡æ•°æ®è¿›è¡Œæœ‰æ•ˆçš„ç”µå‹æ§åˆ¶ã€‚è¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ åœ¨ç”µå‹æ§åˆ¶ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å±€éƒ¨å…±äº«çº¿æ€§æ¶æ„æ¥æ„å»ºQç½‘ç»œï¼Œå¹¶ä½¿ç”¨Transformerç¼–ç å™¨ä½œä¸ºæ¼”å‘˜ç½‘ç»œï¼Œç¡®ä¿äº†ä¿¡æ¯çš„é«˜æ•ˆå¤„ç†å’Œç­–ç•¥çš„å¿«é€Ÿç”Ÿæˆã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”ç”µå‹æ§åˆ¶çš„ç‰¹å®šéœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„RRLæ¡†æ¶åœ¨ç”µå‹æ§åˆ¶ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ”¶æ•›é€Ÿåº¦è¾ƒä¼ ç»Ÿæ–¹æ³•æé«˜äº†30%ä»¥ä¸Šï¼ŒåŒæ—¶æœ‰æ•ˆå‡å°‘äº†æœ‰åŠŸåŠŸç‡å‰Šå‡ï¼Œç¡®ä¿äº†ç”µå‹çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½ç”µç½‘ã€å¯å†ç”Ÿèƒ½æºé›†æˆå’Œç”µåŠ›ç³»ç»Ÿè‡ªåŠ¨åŒ–ç­‰ã€‚é€šè¿‡æé«˜ç”µå‹æ§åˆ¶çš„æ•ˆç‡å’Œå¯é æ€§ï¼Œèƒ½å¤Ÿä¸ºæœªæ¥çš„é…ç”µç½‘ç®¡ç†æä¾›æ›´ä¸ºæ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œä¿ƒè¿›å¯æŒç»­èƒ½æºçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces an efficient Residual Reinforcement Learning (RRL) framework for voltage control in active distribution grids. Voltage control remains a critical challenge in distribution grids, where conventional Reinforcement Learning (RL) methods often suffer from slow training convergence and inefficient exploration. To overcome these challenges, the proposed RRL approach learns a residual policy on top of a modified Sequential Droop Control (SDC) mechanism, ensuring faster convergence. Additionally, the framework introduces a Local Shared Linear (LSL) architecture for the Q-network and a Transformer-Encoder actor network, which collectively enhance overall performance. Unlike several existing approaches, the proposed method relies solely on inverters' measurements without requiring full state information of the power grid, rendering it more practical for real-world deployment. Simulation results validate the effectiveness of the RRL framework in achieving rapid convergence, minimizing active power curtailment, and ensuring reliable voltage regulation.

