---
layout: default
title: A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach
---

# A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20102" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.20102v1</a>
  <a href="https://arxiv.org/pdf/2508.20102.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20102v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20102v1', 'A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xianyue Peng, Shenyang Chen, H. Michael Zhang

**ÂàÜÁ±ª**: eess.SY, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-12

**Â§áÊ≥®**: 28 pages, 7 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫‰∏ÄÁßçÊ∑∑ÂêàÊ®°Âûã‰∏éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂàÜÂ±Ç‰ø°Âè∑ÂçèË∞ÉÊéßÂà∂Á≥ªÁªü**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `‰∫§ÈÄö‰ø°Âè∑ÊéßÂà∂` `Âº∫ÂåñÂ≠¶‰π†` `Ê®°Âûã‰ºòÂåñ` `Ëá™ÈÄÇÂ∫îÁ≠ñÁï•` `ÂüéÂ∏Ç‰∫§ÈÄöÁÆ°ÁêÜ` `ÂàÜÂ±ÇËÆæËÆ°` `Êô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Ê†∏ÂøÉÈóÆÈ¢òÔºöÁé∞ÊúâÂüéÂ∏Ç‰∫§ÈÄö‰ø°Âè∑ÊéßÂà∂ÊñπÊ≥ïÈöæ‰ª•ÂêåÊó∂Êª°Ë∂≥‰∏ªÂπ≤ÈÅìÊµÅÈáè‰∏éÂ±ÄÈÉ®‰∫§ÂèâÂè£ÈúÄÊ±ÇÁöÑÂä®ÊÄÅÂèòÂåñ„ÄÇ
2. ÊñπÊ≥ïË¶ÅÁÇπÔºöÊèêÂá∫ÁöÑÊñπÊ°àÁªìÂêà‰∫ÜÊ®°Âûã‰ºòÂåñ‰∏éÂº∫ÂåñÂ≠¶‰π†ÔºåÈÄöËøáÂàÜÂ±ÇÁªìÊûÑÂÆûÁé∞Âä®ÊÄÅÂçèË∞ÉÁ≠ñÁï•ÈÄâÊã©„ÄÇ
3. ÂÆûÈ™åÊàñÊïàÊûúÔºöÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊ∑∑ÂêàMFCÂú®È´òÈúÄÊ±Ç‰∏ãË°®Áé∞ÊúÄ‰Ω≥ÔºåËÄåPACÂú®‰∏≠Á≠âÈúÄÊ±Ç‰∏ãÊèêÂçá‰∫ÜÁΩëÁªúÊï¥‰ΩìÂá∫Ë°åÊó∂Èó¥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂüéÂ∏ÇËµ∞ÂªäÁöÑ‰ø°Âè∑ÊéßÂà∂Èù¢‰∏¥‰øùÊåÅ‰∏ªÂπ≤‰∫§ÈÄöÊµÅÁïÖ‰∏éÈÄÇÂ∫îÂ±ÄÈÉ®‰∫§ÂèâÂè£ÈúÄÊ±ÇÂèòÂåñÁöÑÂèåÈáçÊåëÊàò„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂàÜÂ±Ç‰∫§ÈÄö‰ø°Âè∑ÂçèË∞É‰∏éÊéßÂà∂ÊñπÊ°àÔºåÁªìÂêà‰∫ÜÂü∫‰∫éÊ®°ÂûãÁöÑ‰ºòÂåñ‰∏éÂº∫ÂåñÂ≠¶‰π†„ÄÇËØ•Á≥ªÁªüÂåÖÊã¨È´òÂ±ÇÂçèË∞ÉÂô®ÔºàHLCÔºâ„ÄÅËµ∞ÂªäÂçèË∞ÉÂô®ÂíåÊ∑∑Âêà‰ø°Âè∑‰ª£ÁêÜÔºàHSAÔºâÔºåÈÄöËøáÂº∫ÂåñÂ≠¶‰π†‰∏éÂä®‰ΩúÂ±èËîΩÊù•Á°ÆÂÆö‰ø°Âè∑Áõ∏‰Ωç„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊ∑∑ÂêàÊúÄÂ§ßÊµÅÂçèË∞ÉÔºàMFCÔºâÂú®È´òÈúÄÊ±Ç‰∏ãÊúÄÂ§ßÂåñÈÄöË°åËÉΩÂäõÔºåËÄåÊ∑∑ÂêàÁªøËâ≤Ê≥¢Êµ™ÂçèË∞ÉÔºàGWCÔºâÂú®Â§öÁßç‰∫§ÈÄöÊù°‰ª∂‰∏ãÊúâÊïàÂáèÂ∞ë‰∏ªÂπ≤ÂÅúÈù†Ê¨°Êï∞Ôºå‰ΩÜÂèØËÉΩÈôç‰ΩéÁΩëÁªúÊï¥‰ΩìÊïàÁéá„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂüéÂ∏ÇËµ∞Âªä‰ø°Âè∑ÊéßÂà∂‰∏≠ÔºåÂ¶Ç‰ΩïÂú®‰øùÊåÅ‰∏ªÂπ≤‰∫§ÈÄöÊµÅÁïÖÁöÑÂêåÊó∂ÔºåÈÄÇÂ∫îÂ±ÄÈÉ®‰∫§ÂèâÂè£ÈúÄÊ±ÇÂèòÂåñÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÊó†Ê≥ïÊúâÊïàÂπ≥Ë°°Ëøô‰∏§ËÄÖÔºåÂØºËá¥‰∫§ÈÄöÊïàÁéá‰Ωé‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫ÁöÑÂàÜÂ±Ç‰ø°Âè∑ÂçèË∞É‰∏éÊéßÂà∂ÊñπÊ°àÔºåÁªìÂêà‰∫ÜÂü∫‰∫éÊ®°ÂûãÁöÑ‰ºòÂåñ‰∏éÂº∫ÂåñÂ≠¶‰π†ÔºåÂà©Áî®È´òÂ±ÇÂçèË∞ÉÂô®Âä®ÊÄÅÈÄâÊã©ÂçèË∞ÉÁ≠ñÁï•Ôºå‰ª•ÈÄÇÂ∫î‰∏çÂêåÁöÑ‰∫§ÈÄöÈúÄÊ±Ç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÁ≥ªÁªüÁî±‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÁªÑÊàêÔºöÈ´òÂ±ÇÂçèË∞ÉÂô®ÔºàHLCÔºâË¥üË¥£ÈÄâÊã©ÂçèË∞ÉÁ≠ñÁï•ÔºåËµ∞ÂªäÂçèË∞ÉÂô®Ê†πÊçÆÊâÄÈÄâÁ≠ñÁï•ÁîüÊàêÁõ∏‰ΩçÁ∫¶ÊùüÔºåÊ∑∑Âêà‰ø°Âè∑‰ª£ÁêÜÔºàHSAÔºâÈÄöËøáÂº∫ÂåñÂ≠¶‰π†Á°ÆÂÆö‰ø°Âè∑Áõ∏‰Ωç„ÄÇHLC‰∏éHSAÁöÑËÆ≠ÁªÉÈááÁî®ËøëÁ´ØÁ≠ñÁï•‰ºòÂåñÔºàPPOÔºâÁÆóÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞Âú®‰∫éÂ∞ÜÂº∫ÂåñÂ≠¶‰π†‰∏é‰º†ÁªüÁöÑ‰ø°Âè∑ÊéßÂà∂ÊñπÊ≥ïÁõ∏ÁªìÂêàÔºåÈÄöËøáÂàÜÂ±ÇËÆæËÆ°ÂÆûÁé∞‰∫ÜËá™ÈÄÇÂ∫îÁ≠ñÁï•ÈÄâÊã©ÔºåÊòæËëóÊèêÂçá‰∫ÜÁ≥ªÁªüÂú®‰∏çÂêåÈúÄÊ±ÇÊ∞¥Âπ≥‰∏ãÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®HSAÁöÑËÆ≠ÁªÉ‰∏≠ÔºåËÆæËÆ°‰∫Ü‰∏âÁßçÁ≠ñÁï•ÔºöMFCÊÑüÁü•„ÄÅGWCÊÑüÁü•ÂíåÁ∫Ø‰ª£ÁêÜÊéßÂà∂ÔºàPACÔºâÔºåÂπ∂ÈÄöËøáÂ§öÁõÆÊ†áÂ•ñÂä±Êú∫Âà∂Âπ≥Ë°°Ëµ∞ÂªäÁ∫ßÂíåÁΩëÁªúÁ∫ßÁöÑÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊ∑∑ÂêàMFCÂú®È´òÈúÄÊ±ÇÊÉÖÂÜµ‰∏ãÊúÄÂ§ßÂåñ‰∫ÜÈÄöË°åËÉΩÂäõÔºåËÄåÊ∑∑ÂêàGWCÂú®Â§öÁßç‰∫§ÈÄöÊù°‰ª∂‰∏ãÊúâÊïàÂáèÂ∞ë‰∫Ü‰∏ªÂπ≤ÂÅúÈù†Ê¨°Êï∞„ÄÇPACÁ≠ñÁï•Âú®‰∏≠Á≠âÈúÄÊ±Ç‰∏ãÊòæËëóÊèêÂçá‰∫ÜÁΩëÁªúÊï¥‰ΩìÂá∫Ë°åÊó∂Èó¥ÔºåÂ±ïÁ§∫‰∫ÜËØ•ÊñπÊ≥ïÁöÑÁÅµÊ¥ªÊÄßÂíåÈÄÇÂ∫îÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂüéÂ∏Ç‰∫§ÈÄöÁÆ°ÁêÜ„ÄÅÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªüÂíåËá™Âä®È©æÈ©∂ËΩ¶ËæÜÁöÑ‰ø°Âè∑ÊéßÂà∂„ÄÇÈÄöËøáÊèêÈ´ò‰∫§ÈÄö‰ø°Âè∑ÊéßÂà∂ÁöÑÊïàÁéáÂíåÈÄÇÂ∫îÊÄßÔºåËÉΩÂ§üÊúâÊïàÁºìËß£ÂüéÂ∏Ç‰∫§ÈÄöÊã•Â†µÔºåÊèêÈ´òÂá∫Ë°åÊïàÁéáÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÁ§æ‰ºöÂíåÁªèÊµé‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Signal control in urban corridors faces the dual challenge of maintaining arterial traffic progression while adapting to demand variations at local intersections. We propose a hierarchical traffic signal coordination and control scheme that integrates model-based optimization with reinforcement learning. The system consists of: (i) a High-Level Coordinator (HLC) that selects coordination strategies based on observed and predicted demand; (ii) a Corridor Coordinator that derives phase constraints from the selected strategy-either Max-Flow Coordination (MFC) or Green-Wave Coordination (GWC); and (iii) Hybrid Signal Agents (HSAs) that determine signal phases via reinforcement learning with action masking to enforce feasibility. Hierarchical reinforcement learning with Proximal Policy Optimization (PPO) is used to train HSA and HLC policies. At the lower level, three HSA policies-MFC-aware, GWC-aware, and pure agent control (PAC) are trained in conjunction with their respective coordination strategies. At the higher level, the HLC is trained to dynamically switch strategies using a multi-objective reward balancing corridor-level and network-wide performance. The proposed scheme was developed and evaluated on a SUMO-RLlib platform. Case results show that hybrid MFC maximizes throughput under heavy demand; hybrid GWC consistently minimizes arterial stops and maintains progression across diverse traffic conditions but can reduce network-wide efficiency; and PAC improves network-wide travel time in moderate demand but is less effective under heavy demand. The hierarchical design enables adaptive strategy selection, achieving robust performance across all demand levels.

