---
layout: default
title: CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks
---

# CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19855" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19855v1</a>
  <a href="https://arxiv.org/pdf/2509.19855.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19855v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19855v1', 'CollaPipe: Adaptive Segment-Optimized Pipeline Parallelism for Collaborative LLM Training in Heterogeneous Edge Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiewei Chen, Xiumei Deng, Zehui Xiong, Shaoyong Guo, Xuesong Qiu, Ping Wang, Dusit Niyato

**åˆ†ç±»**: eess.SY, cs.AI, cs.NI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-24

**å¤‡æ³¨**: Submitted to IEEE for review

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**CollaPipeï¼šå¼‚æ„è¾¹ç¼˜ç½‘ç»œä¸­é¢å‘ååŒLLMè®­ç»ƒçš„è‡ªé€‚åº”åˆ†æ®µä¼˜åŒ–æµæ°´çº¿å¹¶è¡Œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¾¹ç¼˜è®¡ç®—` `è”é‚¦å­¦ä¹ ` `æµæ°´çº¿å¹¶è¡Œ` `å¤§è¯­è¨€æ¨¡å‹` `å¼‚æ„ç½‘ç»œ` `æ¨¡å‹è®­ç»ƒ` `èµ„æºåˆ†é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å¼‚æ„è¾¹ç¼˜ç½‘ç»œä¸­é«˜æ•ˆè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œé¢ä¸´è®¡ç®—é‡å¤§ã€å»¶è¿Ÿé«˜å’Œæ³›åŒ–æ€§ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚
2. CollaPipeé€šè¿‡ååŒæµæ°´çº¿å¹¶è¡Œå’Œè”é‚¦èšåˆï¼Œè‡ªé€‚åº”åœ°åˆ†å‰²æ¨¡å‹å¹¶åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œä»è€Œä¼˜åŒ–èµ„æºåˆ©ç”¨ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCollaPipeæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ï¼ˆ15.09%ï¼‰ï¼Œé™ä½äº†ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆ48.98%ï¼‰ï¼Œå¹¶å‡å°‘äº†è®¾å¤‡å†…å­˜å ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†æ»¡è¶³æ™ºèƒ½ç§»åŠ¨åº”ç”¨æ—¥ç›Šå¢é•¿çš„éœ€æ±‚ï¼ŒåŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹(LLM)çš„å¤šæ™ºèƒ½ä½“åä½œåœ¨ç§»åŠ¨è¾¹ç¼˜è®¡ç®—(MEC)ç½‘ç»œä¸­è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œåœ¨æ­¤ç±»ç¯å¢ƒä¸­è®­ç»ƒLLMä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºè®¡ç®—é‡å¤§ã€ç«¯åˆ°ç«¯å»¶è¿Ÿé«˜ä¸”æ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚æˆ‘ä»¬æå‡ºäº†CollaPipeï¼Œä¸€ä¸ªæ··åˆåˆ†å¸ƒå¼å­¦ä¹ æ¡†æ¶ï¼Œå®ƒé›†æˆäº†ååŒæµæ°´çº¿å¹¶è¡Œå’Œè”é‚¦èšåˆï¼Œä»¥æ”¯æŒè‡ªè¿›åŒ–çš„æ™ºèƒ½ç½‘ç»œã€‚åœ¨CollaPipeä¸­ï¼Œç¼–ç å™¨éƒ¨åˆ†è¢«è‡ªé€‚åº”åœ°åˆ’åˆ†ä¸ºå¯å˜å¤§å°çš„æ®µï¼Œå¹¶éƒ¨ç½²åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒï¼Œè€Œè§£ç å™¨åˆ™éƒ¨ç½²åœ¨è¾¹ç¼˜æœåŠ¡å™¨ä¸Šä»¥å¤„ç†ç”Ÿæˆä»»åŠ¡ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è”é‚¦èšåˆæ‰§è¡Œå…¨å±€æ¨¡å‹æ›´æ–°ã€‚ä¸ºäº†æé«˜è®­ç»ƒæ•ˆç‡ï¼Œæˆ‘ä»¬åˆ¶å®šäº†ä¸€ä¸ªè”åˆä¼˜åŒ–é—®é¢˜ï¼Œè‡ªé€‚åº”åœ°åˆ†é…æ¨¡å‹æ®µã€å¾®æ‰¹æ¬¡ã€å¸¦å®½å’Œä¼ è¾“åŠŸç‡ã€‚æˆ‘ä»¬æ¨å¯¼å¹¶ä½¿ç”¨ä¸€ä¸ªé—­å¼æ”¶æ•›ç•Œæ¥è®¾è®¡ä¸€ä¸ªåŸºäºLyapunovä¼˜åŒ–çš„åŠ¨æ€åˆ†æ®µè°ƒåº¦å’Œèµ„æºåˆ†é…(DSSDA)ç®—æ³•ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨é•¿æœŸçº¦æŸä¸‹çš„ç¨³å®šæ€§ã€‚å¯¹Transformerå’ŒBERTæ¨¡å‹è¿›è¡Œçš„ä¸‹æ¸¸ä»»åŠ¡çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒCollaPipeå°†è®¡ç®—æ•ˆç‡æé«˜äº†é«˜è¾¾15.09%ï¼Œå°†ç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½äº†è‡³å°‘48.98%ï¼Œå¹¶å°†å•ä¸ªè®¾å¤‡çš„å†…å­˜ä½¿ç”¨é‡å‡å°‘äº†ä¸€åŠä»¥ä¸Šï¼Œä»è€Œèƒ½å¤Ÿåœ¨å¼‚æ„å’ŒåŠ¨æ€é€šä¿¡ç¯å¢ƒä¸­è¿›è¡Œåœ¨çº¿å­¦ä¹ ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¼‚æ„è¾¹ç¼˜ç½‘ç»œä¸­è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ—¶é¢ä¸´çš„è®¡ç®—èµ„æºå—é™ã€é€šä¿¡å»¶è¿Ÿé«˜ä»¥åŠæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚ä¼ ç»Ÿçš„è”é‚¦å­¦ä¹ ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨è¾¹ç¼˜è®¾å¤‡çš„å¼‚æ„è®¡ç®—èƒ½åŠ›ï¼Œå¹¶ä¸”å®¹æ˜“å—åˆ°é€šä¿¡ç“¶é¢ˆçš„å½±å“ï¼Œå¯¼è‡´è®­ç»ƒæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCollaPipeçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMçš„ç¼–ç å™¨éƒ¨åˆ†è¿›è¡Œåˆ†æ®µï¼Œå¹¶åœ¨ä¸åŒçš„è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒï¼ŒåŒæ—¶å°†è§£ç å™¨éƒ¨ç½²åœ¨è¾¹ç¼˜æœåŠ¡å™¨ä¸Šã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥å……åˆ†åˆ©ç”¨è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—èµ„æºï¼Œå‡å°‘å•ä¸ªè®¾å¤‡çš„è®¡ç®—è´Ÿæ‹…ï¼Œå¹¶é™ä½ç«¯åˆ°ç«¯å»¶è¿Ÿã€‚æ­¤å¤–ï¼Œé‡‡ç”¨è”é‚¦èšåˆè¿›è¡Œå…¨å±€æ¨¡å‹æ›´æ–°ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCollaPipeæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) æ¨¡å‹åˆ†æ®µæ¨¡å—ï¼šå°†LLMçš„ç¼–ç å™¨éƒ¨åˆ†è‡ªé€‚åº”åœ°åˆ’åˆ†ä¸ºå¯å˜å¤§å°çš„æ®µã€‚2) è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²æ¨¡å—ï¼šå°†ä¸åŒçš„æ¨¡å‹æ®µéƒ¨ç½²åˆ°ä¸åŒçš„è¾¹ç¼˜è®¾å¤‡ä¸Šè¿›è¡Œæµæ°´çº¿å¹¶è¡Œè®­ç»ƒã€‚3) è¾¹ç¼˜æœåŠ¡å™¨éƒ¨ç½²æ¨¡å—ï¼šå°†è§£ç å™¨éƒ¨ç½²åœ¨è¾¹ç¼˜æœåŠ¡å™¨ä¸Šï¼Œè´Ÿè´£ç”Ÿæˆä»»åŠ¡ã€‚4) è”é‚¦èšåˆæ¨¡å—ï¼šé€šè¿‡è”é‚¦èšåˆç®—æ³•ï¼Œå°†è¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ¨¡å‹æ›´æ–°èšåˆåˆ°å…¨å±€æ¨¡å‹ä¸­ã€‚5) èµ„æºåˆ†é…æ¨¡å—ï¼šè‡ªé€‚åº”åœ°åˆ†é…æ¨¡å‹æ®µã€å¾®æ‰¹æ¬¡ã€å¸¦å®½å’Œä¼ è¾“åŠŸç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šCollaPipeçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æå‡ºäº†ååŒæµæ°´çº¿å¹¶è¡Œä¸è”é‚¦èšåˆç›¸ç»“åˆçš„æ··åˆåˆ†å¸ƒå¼å­¦ä¹ æ¡†æ¶ï¼Œå……åˆ†åˆ©ç”¨è¾¹ç¼˜è®¾å¤‡çš„å¼‚æ„è®¡ç®—èƒ½åŠ›ã€‚2) è®¾è®¡äº†åŠ¨æ€åˆ†æ®µè°ƒåº¦å’Œèµ„æºåˆ†é…ï¼ˆDSSDAï¼‰ç®—æ³•ï¼ŒåŸºäºLyapunovä¼˜åŒ–ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨é•¿æœŸçº¦æŸä¸‹çš„ç¨³å®šæ€§ã€‚3) æå‡ºäº†è‡ªé€‚åº”çš„æ¨¡å‹åˆ†æ®µç­–ç•¥ï¼Œæ ¹æ®è¾¹ç¼˜è®¾å¤‡çš„è®¡ç®—èƒ½åŠ›å’Œé€šä¿¡çŠ¶å†µï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡å‹æ®µçš„å¤§å°ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é—­å¼æ”¶æ•›ç•Œæ¥æŒ‡å¯¼DSSDAç®—æ³•çš„è®¾è®¡ï¼Œç¡®ä¿ç®—æ³•çš„æ”¶æ•›æ€§ã€‚2) é‡‡ç”¨Lyapunovä¼˜åŒ–æ¥è§£å†³è”åˆä¼˜åŒ–é—®é¢˜ï¼Œå®ç°æ¨¡å‹æ®µã€å¾®æ‰¹æ¬¡ã€å¸¦å®½å’Œä¼ è¾“åŠŸç‡çš„è‡ªé€‚åº”åˆ†é…ã€‚3) è®¾è®¡äº†æŸå¤±å‡½æ•°ï¼Œç”¨äºä¼˜åŒ–æ¨¡å‹åˆ†æ®µç­–ç•¥ï¼Œå¹³è¡¡è®¡ç®—è´Ÿè½½å’Œé€šä¿¡å¼€é”€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒCollaPipeåœ¨Transformerå’ŒBERTæ¨¡å‹ä¸Šï¼Œç›¸æ¯”äºä¼ ç»Ÿæ–¹æ³•ï¼Œè®¡ç®—æ•ˆç‡æé«˜äº†é«˜è¾¾15.09%ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½äº†è‡³å°‘48.98%ï¼Œå¹¶ä¸”å•ä¸ªè®¾å¤‡çš„å†…å­˜ä½¿ç”¨é‡å‡å°‘äº†ä¸€åŠä»¥ä¸Šã€‚è¿™äº›ç»“æœéªŒè¯äº†CollaPipeåœ¨å¼‚æ„è¾¹ç¼˜ç½‘ç»œä¸­è¿›è¡ŒLLMè®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CollaPipeé€‚ç”¨äºéœ€è¦å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ”¯æŒçš„æ™ºèƒ½ç§»åŠ¨åº”ç”¨ï¼Œä¾‹å¦‚æ™ºèƒ½åŠ©æ‰‹ã€æœºå™¨ç¿»è¯‘ã€æƒ…æ„Ÿåˆ†æç­‰ã€‚è¯¥ç ”ç©¶æˆæœå¯ä»¥æœ‰æ•ˆé™ä½æ¨¡å‹è®­ç»ƒçš„æˆæœ¬å’Œå»¶è¿Ÿï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»è€Œæ¨åŠ¨è¾¹ç¼˜è®¡ç®—åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶ä¸ºæœªæ¥çš„æ™ºèƒ½ç½‘ç»œå‘å±•æä¾›æŠ€æœ¯æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The increasing demand for intelligent mobile applications has made multi-agent collaboration with Transformer-based large language models (LLMs) essential in mobile edge computing (MEC) networks. However, training LLMs in such environments remains challenging due to heavy computation, high end-to-end latency, and limited model generalization. We introduce CollaPipe, a hybrid distributed learning framework that integrates collaborative pipeline parallelism with federated aggregation to support self-evolving intelligent networks. In CollaPipe, the encoder part is adaptively partitioned into variable-sized segments and deployed across mobile devices for pipeline-parallel training, while the decoder is deployed on edge servers to handle generative tasks. Then we perform global model update via federated aggregation. To enhance training efficiency, we formulate a joint optimization problem that adaptively allocates model segments, micro-batches, bandwidth, and transmission power. We derive and use a closed-form convergence bound to design an Dynamic Segment Scheduling and Resource Allocation (DSSDA) algorithm based on Lyapunov optimization, ensuring system stability under long-term constraints. Extensive experiments on downstream tasks with Transformer and BERT models show that CollaPipe improves computation efficiency by up to 15.09%, reduces end-to-end latency by at least 48.98%, and cuts single device memory usage by more than half, enabling online learning in heterogeneous and dynamic communication environments.

