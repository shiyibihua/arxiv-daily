---
layout: default
title: Multi-Agent Inverse Reinforcement Learning for Identifying Pareto-Efficient Coordination -- A Distributionally Robust Approach
---

# Multi-Agent Inverse Reinforcement Learning for Identifying Pareto-Efficient Coordination -- A Distributionally Robust Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.08956" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.08956v1</a>
  <a href="https://arxiv.org/pdf/2509.08956.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.08956v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.08956v1', 'Multi-Agent Inverse Reinforcement Learning for Identifying Pareto-Efficient Coordination -- A Distributionally Robust Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Luke Snow, Vikram Krishnamurthy

**åˆ†ç±»**: eess.SY, eess.SP

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åˆ†å¸ƒé²æ£’çš„å¤šæ™ºèƒ½ä½“é€†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè¯†åˆ«å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸º**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ` `é€†å¼ºåŒ–å­¦ä¹ ` `å¸•ç´¯æ‰˜æ•ˆç‡` `åˆ†å¸ƒé²æ£’ä¼˜åŒ–` `æ— äººæœºååŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­ï¼Œä»å™ªå£°æ•°æ®ä¸­å‡†ç¡®è¯†åˆ«å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸ºï¼Œå¹¶é‡æ„æ™ºèƒ½ä½“çš„æ•ˆç”¨å‡½æ•°ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åˆ†å¸ƒé²æ£’çš„é€†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æœ€å°åŒ–æœ€åæƒ…å†µä¸‹çš„ä¼°è®¡è¯¯å·®ï¼Œå®ç°å¯¹å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒçš„æ£€æµ‹ã€‚
3. é€šè¿‡æ— äººæœºåè°ƒæ£€æµ‹çš„æ¡ˆä¾‹ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨å™ªå£°ç¯å¢ƒä¸‹æ£€æµ‹å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸ºå¹¶é‡æ„æ•ˆç”¨å‡½æ•°çš„èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶å¤šæ™ºèƒ½ä½“é€†å¼ºåŒ–å­¦ä¹ (IRL)é—®é¢˜ï¼Œæ—¨åœ¨è¯†åˆ«å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„å¸•ç´¯æ‰˜æœ‰æ•ˆè¡Œä¸ºï¼Œå¹¶é‡æ„ä¸ªä½“æ™ºèƒ½ä½“çš„æ•ˆç”¨å‡½æ•°ã€‚å—æ— äººæœº(UAV)åè°ƒæ£€æµ‹é—®é¢˜çš„é©±åŠ¨ï¼Œæœ¬æ–‡æ¢è®¨äº†å¦‚ä½•æ„å»ºä¸€ä¸ªç»Ÿè®¡æ£€æµ‹å™¨ï¼Œç”¨äºæ£€æµ‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­å¸•ç´¯æ‰˜æœ‰æ•ˆè¡Œä¸ºï¼Œå°¤å…¶æ˜¯åœ¨å­˜åœ¨å™ªå£°æµ‹é‡çš„æƒ…å†µä¸‹ã€‚æœ¬æ–‡é¦–å…ˆæ¨å¯¼äº†å¤šæ™ºèƒ½ä½“ç³»ç»ŸåŠ¨æ€æ•°æ®é›†ä¸å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒä¸€è‡´çš„å……è¦æ¡ä»¶ï¼Œå¹¶æä¾›äº†é‡æ„ä¸ç³»ç»ŸåŠ¨æ€ä¸€è‡´çš„æ•ˆç”¨å‡½æ•°çš„ç®—æ³•ã€‚ç„¶åï¼Œæœ¬æ–‡æ¨å¯¼äº†ä¸€ä¸ªæœ€ä¼˜ç»Ÿè®¡æ£€æµ‹å™¨ï¼Œç”¨äºä»å«å™ªå£°çš„ç³»ç»Ÿæµ‹é‡ä¸­ç¡®å®šå¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒï¼Œè¯¥æ£€æµ‹å™¨æœ€å°åŒ–äº†Iç±»ç»Ÿè®¡æ£€æµ‹è¯¯å·®ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æä¾›äº†ä¸€ç§æ•ˆç”¨ä¼°è®¡ç®—æ³•ï¼Œè¯¥ç®—æ³•æœ€å°åŒ–äº†ä»¥ç»éªŒè§‚æµ‹ä¸ºä¸­å¿ƒçš„ç»Ÿè®¡æ¨¡ç³Šé›†ä¸Šçš„æœ€åæƒ…å†µä¼°è®¡è¯¯å·®ï¼›è¿™ç§min-maxè§£å†³æ–¹æ¡ˆå®ç°äº†åˆ†å¸ƒé²æ£’çš„IRLï¼Œè¿™åœ¨å¯¹æŠ—æ€§æˆ˜ç•¥äº¤äº’ä¸­è‡³å…³é‡è¦ã€‚æœ€åï¼Œæœ¬æ–‡é€šè¿‡ä¸€ä¸ªè¯¦ç»†çš„ä¾‹å­è¯´æ˜äº†è¿™äº›ç»“æœï¼Œè¯¥ä¾‹å­æ¶‰åŠåœ¨é›·è¾¾è®°å½•çš„å™ªå£°æµ‹é‡ä¸‹æ£€æµ‹å¤šä¸ªæ— äººæœºä¹‹é—´çš„å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒï¼Œå¹¶ä»¥åˆ†å¸ƒé²æ£’çš„æ–¹å¼é‡æ„æ— äººæœºçš„æ•ˆç”¨å‡½æ•°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“é€†å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œå¦‚ä½•ä»å«æœ‰å™ªå£°çš„è§‚æµ‹æ•°æ®ä¸­è¯†åˆ«å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸ºï¼Œå¹¶å‡†ç¡®é‡æ„æ¯ä¸ªæ™ºèƒ½ä½“çš„æ•ˆç”¨å‡½æ•°ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å™ªå£°æ•°æ®æ—¶ï¼Œé²æ£’æ€§è¾ƒå·®ï¼Œå®¹æ˜“å—åˆ°å¯¹æŠ—æ€§ç­–ç•¥çš„å½±å“ï¼Œå¯¼è‡´æ•ˆç”¨å‡½æ•°ä¼°è®¡ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡‡ç”¨åˆ†å¸ƒé²æ£’ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºä¸€ä¸ªä»¥ç»éªŒè§‚æµ‹ä¸ºä¸­å¿ƒçš„ç»Ÿè®¡æ¨¡ç³Šé›†ï¼Œå¹¶æœ€å°åŒ–è¯¥æ¨¡ç³Šé›†ä¸Šçš„æœ€åæƒ…å†µä¼°è®¡è¯¯å·®ï¼Œä»è€Œå®ç°å¯¹å™ªå£°å’Œå¯¹æŠ—æ€§ç­–ç•¥çš„é²æ£’æ€§ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿä¿è¯åœ¨æœ€ä¸åˆ©çš„å™ªå£°åˆ†å¸ƒä¸‹ï¼Œä¹Ÿèƒ½è·å¾—è¾ƒå¥½çš„æ•ˆç”¨å‡½æ•°ä¼°è®¡ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ¨å¯¼å¤šæ™ºèƒ½ä½“ç³»ç»ŸåŠ¨æ€æ•°æ®é›†ä¸å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒä¸€è‡´çš„å……è¦æ¡ä»¶ï¼›2) è®¾è®¡æœ€ä¼˜ç»Ÿè®¡æ£€æµ‹å™¨ï¼Œç”¨äºä»å™ªå£°æµ‹é‡ä¸­æ£€æµ‹å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒï¼›3) æå‡ºåˆ†å¸ƒé²æ£’çš„æ•ˆç”¨ä¼°è®¡ç®—æ³•ï¼Œæœ€å°åŒ–æœ€åæƒ…å†µä¸‹çš„ä¼°è®¡è¯¯å·®ã€‚è¯¥æ¡†æ¶é¦–å…ˆç¡®å®šå¸•ç´¯æ‰˜æœ‰æ•ˆæ€§çš„ç†è®ºåŸºç¡€ï¼Œç„¶åè®¾è®¡æ£€æµ‹å™¨è¿›è¡Œåˆæ­¥åˆ¤æ–­ï¼Œæœ€åé€šè¿‡åˆ†å¸ƒé²æ£’ä¼˜åŒ–æ–¹æ³•è¿›è¡Œç²¾ç¡®çš„æ•ˆç”¨å‡½æ•°ä¼°è®¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†åˆ†å¸ƒé²æ£’ä¼˜åŒ–å¼•å…¥å¤šæ™ºèƒ½ä½“é€†å¼ºåŒ–å­¦ä¹ ï¼Œæå‡ºäº†ä¸€ç§åˆ†å¸ƒé²æ£’çš„æ•ˆç”¨ä¼°è®¡ç®—æ³•ã€‚ä¸ä¼ ç»Ÿçš„é€†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å™ªå£°å’Œå¯¹æŠ—æ€§ç­–ç•¥çš„å½±å“ï¼Œæé«˜æ•ˆç”¨å‡½æ•°ä¼°è®¡çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç»Ÿè®¡æ¨¡ç³Šé›†çš„æ„å»ºæ–¹å¼ï¼Œè¯¥æ¨¡ç³Šé›†ä»¥ç»éªŒè§‚æµ‹ä¸ºä¸­å¿ƒï¼Œå¹¶æ ¹æ®å™ªå£°æ°´å¹³è¿›è¡Œè°ƒæ•´ï¼›2) æœ€åæƒ…å†µä¼°è®¡è¯¯å·®çš„å®šä¹‰ï¼Œè®ºæ–‡é‡‡ç”¨min-maxä¼˜åŒ–æ–¹æ³•ï¼Œæœ€å°åŒ–æ¨¡ç³Šé›†ä¸Šçš„æœ€å¤§ä¼°è®¡è¯¯å·®ï¼›3) æœ€ä¼˜ç»Ÿè®¡æ£€æµ‹å™¨çš„è®¾è®¡ï¼Œè¯¥æ£€æµ‹å™¨é€šè¿‡æœ€å°åŒ–Iç±»ç»Ÿè®¡æ£€æµ‹è¯¯å·®ï¼Œæé«˜å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒçš„æ£€æµ‹å‡†ç¡®ç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡æ— äººæœºåè°ƒæ£€æµ‹çš„æ¡ˆä¾‹ï¼ŒéªŒè¯äº†æ‰€ææ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨å™ªå£°ç¯å¢ƒä¸‹å‡†ç¡®æ£€æµ‹å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸ºï¼Œå¹¶ä»¥åˆ†å¸ƒé²æ£’çš„æ–¹å¼é‡æ„æ— äººæœºçš„æ•ˆç”¨å‡½æ•°ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ— äººæœºé›†ç¾¤ååŒã€äº¤é€šæµé‡ä¼˜åŒ–ã€èµ„æºåˆ†é…ç­‰é¢†åŸŸã€‚é€šè¿‡è¯†åˆ«æ™ºèƒ½ä½“é—´çš„å¸•ç´¯æ‰˜æœ‰æ•ˆåè°ƒè¡Œä¸ºï¼Œå¯ä»¥ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ï¼Œæé«˜èµ„æºåˆ©ç”¨ç‡ï¼Œå¹¶å®ç°æ›´é«˜æ•ˆçš„å†³ç­–ã€‚ä¾‹å¦‚ï¼Œåœ¨æ— äººæœºé›†ç¾¤ååŒä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•æ£€æµ‹æ— äººæœºæ˜¯å¦æŒ‰ç…§æœ€ä¼˜ç­–ç•¥è¿›è¡Œåä½œï¼Œå¹¶æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ç­–ç•¥ï¼Œæé«˜ä»»åŠ¡å®Œæˆæ•ˆç‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multi-agent inverse reinforcement learning (IRL) aims to identify Pareto-efficient behavior in a multi-agent system, and reconstruct utility functions of the individual agents. Motivated by the problem of detecting UAV coordination, how can we construct a statistical detector for Pareto-efficient behavior given noisy measurements of the decisions of a multi-agent system? This paper approaches this IRL problem by deriving necessary and sufficient conditions for a dataset of multi-agent system dynamics to be consistent with Pareto-efficient coordination, and providing algorithms for recovering utility functions which are consistent with the system dynamics. We derive an optimal statistical detector for determining Pareto-efficient coordination from noisy system measurements, which minimizes Type-I statistical detection error. Then, we provide a utility estimation algorithm which minimizes the worst-case estimation error over a statistical ambiguity set centered at empirical observations; this min-max solution achieves distributionally robust IRL, which is crucial in adversarial strategic interactions. We illustrate these results in a detailed example for detecting Pareto-efficient coordination among multiple UAVs given noisy measurement recorded at a radar. We then reconstruct the utility functions of the UAVs in a distributionally robust sense.

