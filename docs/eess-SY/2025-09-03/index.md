---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - eess.SY - 2025-09-03
---

# eess.SYï¼ˆ2025-09-03ï¼‰

ğŸ“Š å…± **3** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250902946v1-deep-reinforcement-learning-based-decision-making-strategy-consideri.html">Deep Reinforcement Learning-Based Decision-Making Strategy Considering User Satisfaction Feedback in Demand Response Program</a></td>
  <td>æå‡ºMBTF-TD3ç®—æ³•ï¼Œè§£å†³éœ€æ±‚å“åº”ä¸­ç”¨æˆ·æ»¡æ„åº¦ä¸DRPæ”¶ç›Šçš„å¹³è¡¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">TD3</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02946v1" data-paper-url="./papers/250902946v1-deep-reinforcement-learning-based-decision-making-strategy-consideri.html" onclick="toggleFavorite(this, '2509.02946v1', 'Deep Reinforcement Learning-Based Decision-Making Strategy Considering User Satisfaction Feedback in Demand Response Program')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250903721v1-avoidance-of-an-unexpected-obstacle-without-reinforcement-learning-w.html">Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?</a></td>
  <td>åˆ©ç”¨åŸºäºæ‰å¹³åŒ–çš„æ§åˆ¶ç†è®ºå·¥å…·ï¼Œè§£å†³Dubinsè½¦è¾†çš„æ„å¤–é¿éšœé—®é¢˜ï¼Œæ— éœ€å¼ºåŒ–å­¦ä¹ ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03721v1" data-paper-url="./papers/250903721v1-avoidance-of-an-unexpected-obstacle-without-reinforcement-learning-w.html" onclick="toggleFavorite(this, '2509.03721v1', 'Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250902968v1-spiking-control-systems-for-soft-robotics-a-rhythmic-case-study-in-a.html">Spiking control systems for soft robotics: a rhythmic case study in a soft robotic crawler</a></td>
  <td>æå‡ºåŸºäºè„‰å†²æ§åˆ¶çš„è½¯ä½“æœºå™¨äººè •åŠ¨æ§åˆ¶ç³»ç»Ÿï¼Œå®ç°é«˜æ•ˆè¿åŠ¨</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02968v1" data-paper-url="./papers/250902968v1-spiking-control-systems-for-soft-robotics-a-rhythmic-case-study-in-a.html" onclick="toggleFavorite(this, '2509.02968v1', 'Spiking control systems for soft robotics: a rhythmic case study in a soft robotic crawler')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› eess.SY é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)