---
layout: default
title: Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?
---

# Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03721" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03721v1</a>
  <a href="https://arxiv.org/pdf/2509.03721.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03721v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03721v1', 'Avoidance of an unexpected obstacle without reinforcement learning: Why not using advanced control-theoretic tools?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: CÃ©dric Join, Michel Fliess

**åˆ†ç±»**: eess.SY, cs.RO, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

**å¤‡æ³¨**: IEEE 2025 - 13th International Conference on Systems and Control (ICSC) - October 22-24, 2025 - Marrakesh, Morocco

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨åŸºäºæ‰å¹³åŒ–çš„æ§åˆ¶ç†è®ºå·¥å…·ï¼Œè§£å†³Dubinsè½¦è¾†çš„æ„å¤–é¿éšœé—®é¢˜ï¼Œæ— éœ€å¼ºåŒ–å­¦ä¹ ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `Dubinsè½¦è¾†` `é¿éšœ` `æ‰å¹³åŒ–æ§åˆ¶` `HEOLåé¦ˆ` `æ— æ¨¡å‹é¢„æµ‹æ§åˆ¶` `æ§åˆ¶ç†è®º` `æœºå™¨äººå¯¼èˆª`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¼ºåŒ–å­¦ä¹ åœ¨é¿éšœä»»åŠ¡ä¸­éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ³›åŒ–èƒ½åŠ›å¯èƒ½ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºåŸºäºæ‰å¹³åŒ–çš„æ§åˆ¶ç†è®ºæ–¹æ³•ï¼Œç»“åˆHEOLåé¦ˆå’Œæ— æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼Œå®ç°é«˜æ•ˆé¿éšœã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨Dubinsè½¦è¾†é¿éšœé—®é¢˜ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§å’Œè¾ƒä½çš„è®¡ç®—è´Ÿæ‹…ï¼Œä¼˜äºæˆ–è‡³å°‘ä¸é€Šäºå¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡é’ˆå¯¹æ„å¤–éšœç¢ç‰©çš„é¿éšœé—®é¢˜ï¼Œæ—¨åœ¨é¿å…å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•â€œéœ€è¦å¤§é‡è¯•éªŒæ‰èƒ½å­¦ä¹ æ–°ä»»åŠ¡â€çš„ç¼ºç‚¹ã€‚æˆ‘ä»¬ä»¥ç»å…¸çš„Dubinsè½¦è¾†ä¸ºç ”ç©¶å¯¹è±¡ï¼Œé‡‡ç”¨åŸºäºæ‰å¹³åŒ–çš„æ§åˆ¶æ–¹æ³•ï¼Œç»“åˆHEOLåé¦ˆè®¾ç½®å’Œæœ€æ–°çš„æ— æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•ã€‚ä¸¤ç§æ–¹æ³•éƒ½é€šè¿‡è®¡ç®—æœºå®éªŒéªŒè¯äº†æœ‰æ•ˆæ€§ï¼Œå…¶ä¸­åŸºäºæ¨¡å‹çš„æ–¹æ³•ç•¥ä¼˜ã€‚å®ƒä»¬å¯¹éšæœºç”Ÿæˆçš„ä¸åŒ¹é…/æ‰°åŠ¨è¡¨ç°å‡ºä»¤äººæ»¡æ„çš„é²æ£’æ€§ï¼Œæ— æ¨¡å‹æ–¹æ³•è¡¨ç°æ›´ä½³ã€‚è¿™äº›ç‰¹æ€§å¯èƒ½éš¾ä»¥é€šè¿‡å½“å‰æµè¡Œçš„AIæœºå™¨å­¦ä¹ æŠ€æœ¯è·å¾—ã€‚æœ€åï¼Œæˆ‘ä»¬å¼ºè°ƒè¿™ä¸¤ç§æ–¹æ³•è®¡ç®—è´Ÿæ‹…éƒ½å¾ˆä½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³Dubinsè½¦è¾†åœ¨é‡åˆ°æ„å¤–éšœç¢ç‰©æ—¶çš„é¿éšœé—®é¢˜ã€‚ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œè®¡ç®—æˆæœ¬é«˜ï¼Œä¸”åœ¨é¢å¯¹æœªçŸ¥çš„ç¯å¢ƒæ‰°åŠ¨æ—¶ï¼Œæ³›åŒ–èƒ½åŠ›å¯èƒ½ä¸è¶³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§æ›´é«˜æ•ˆã€é²æ£’æ€§æ›´å¼ºçš„é¿éšœæ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ§åˆ¶ç†è®ºä¸­çš„æ‰å¹³åŒ–æ–¹æ³•ï¼Œå°†å¤æ‚çš„éçº¿æ€§ç³»ç»Ÿè½¬åŒ–ä¸ºçº¿æ€§ç³»ç»Ÿï¼Œä»è€Œç®€åŒ–æ§åˆ¶å™¨çš„è®¾è®¡ã€‚åŒæ—¶ï¼Œç»“åˆHEOLï¼ˆHigh-gain Extended Observer-based Linearizationï¼‰åé¦ˆå’Œæ— æ¨¡å‹é¢„æµ‹æ§åˆ¶ï¼Œæé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç¯å¢ƒè¿›è¡Œå¤§é‡é‡‡æ ·å’Œå­¦ä¹ ï¼Œä»è€Œé™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ–¹æ³•ï¼šåŸºäºæ¨¡å‹çš„æ‰å¹³åŒ–æ§åˆ¶å’Œæ— æ¨¡å‹é¢„æµ‹æ§åˆ¶ã€‚ä¸¤ç§æ–¹æ³•éƒ½é¦–å…ˆå¯¹Dubinsè½¦è¾†çš„è¿åŠ¨å­¦æ¨¡å‹è¿›è¡Œåˆ†æï¼Œç„¶åè®¾è®¡ç›¸åº”çš„æ§åˆ¶å™¨ã€‚åŸºäºæ¨¡å‹çš„æ§åˆ¶æ–¹æ³•åˆ©ç”¨æ‰å¹³åŒ–æŠ€æœ¯å°†ç³»ç»Ÿè½¬åŒ–ä¸ºçº¿æ€§ç³»ç»Ÿï¼Œç„¶åè®¾è®¡çº¿æ€§æ§åˆ¶å™¨ã€‚æ— æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•åˆ™ç›´æ¥åˆ©ç”¨ç³»ç»Ÿçš„è¾“å…¥è¾“å‡ºæ•°æ®ï¼Œå»ºç«‹é¢„æµ‹æ¨¡å‹ï¼Œç„¶åè®¾è®¡é¢„æµ‹æ§åˆ¶å™¨ã€‚ä¸¤ç§æ–¹æ³•éƒ½ç»“åˆäº†HEOLåé¦ˆï¼Œç”¨äºæŠ‘åˆ¶ç¯å¢ƒæ‰°åŠ¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†æ‰å¹³åŒ–æ§åˆ¶ã€HEOLåé¦ˆå’Œæ— æ¨¡å‹é¢„æµ‹æ§åˆ¶ç›¸ç»“åˆï¼Œç”¨äºè§£å†³Dubinsè½¦è¾†çš„é¿éšœé—®é¢˜ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç¯å¢ƒè¿›è¡Œå¤§é‡é‡‡æ ·å’Œå­¦ä¹ ï¼Œä»è€Œé™ä½äº†è®¡ç®—æˆæœ¬ï¼ŒåŒæ—¶æé«˜äº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®ï¼Œä¸”æ›´å®¹æ˜“å®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨åŸºäºæ¨¡å‹çš„æ§åˆ¶æ–¹æ³•ä¸­ï¼Œå…³é”®åœ¨äºé€‰æ‹©åˆé€‚çš„æ‰å¹³åŒ–è¾“å‡ºï¼Œä½¿å¾—ç³»ç»Ÿå¯ä»¥è½¬åŒ–ä¸ºçº¿æ€§ç³»ç»Ÿã€‚åœ¨æ— æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•ä¸­ï¼Œå…³é”®åœ¨äºé€‰æ‹©åˆé€‚çš„é¢„æµ‹æ¨¡å‹å’Œæ§åˆ¶å‚æ•°ï¼Œä»¥ä¿è¯ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚HEOLåé¦ˆçš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦æ ¹æ®ç³»ç»Ÿçš„ç‰¹æ€§è¿›è¡Œè°ƒæ•´ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„æ‰°åŠ¨æŠ‘åˆ¶æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®¡ç®—æœºå®éªŒè¡¨æ˜ï¼ŒåŸºäºæ‰å¹³åŒ–çš„æ§åˆ¶æ–¹æ³•å’Œæ— æ¨¡å‹é¢„æµ‹æ§åˆ¶æ–¹æ³•éƒ½èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³Dubinsè½¦è¾†çš„é¿éšœé—®é¢˜ã€‚ä¸¤ç§æ–¹æ³•éƒ½è¡¨ç°å‡ºè‰¯å¥½çš„é²æ£’æ€§ï¼Œèƒ½å¤ŸæŠµæŠ—éšæœºç”Ÿæˆçš„ä¸åŒ¹é…/æ‰°åŠ¨ã€‚æ— æ¨¡å‹æ–¹æ³•åœ¨é²æ£’æ€§æ–¹é¢è¡¨ç°æ›´ä½³ã€‚æ­¤å¤–ï¼Œä¸¤ç§æ–¹æ³•çš„è®¡ç®—è´Ÿæ‹…éƒ½å¾ˆä½ï¼Œæ˜“äºå®ç°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè‡ªä¸»å¯¼èˆªã€æœºå™¨äººé¿éšœã€æ— äººé©¾é©¶ç­‰é¢†åŸŸã€‚ç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™æˆ–ç¯å¢ƒæœªçŸ¥çš„åœºæ™¯ä¸‹ï¼Œè¯¥æ–¹æ³•å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œå¯ä»¥è¿›ä¸€æ­¥ç ”ç©¶è¯¥æ–¹æ³•åœ¨æ›´å¤æ‚çš„æœºå™¨äººç³»ç»Ÿå’Œç¯å¢ƒä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚å¤šæœºå™¨äººååŒé¿éšœã€åŠ¨æ€ç¯å¢ƒä¸‹çš„é¿éšœç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This communication on collision avoidance with unexpected obstacles is motivated by some critical appraisals on reinforcement learning (RL) which "requires ridiculously large numbers of trials to learn any new task" (Yann LeCun). We use the classic Dubins' car in order to replace RL with flatness-based control, combined with the HEOL feedback setting, and the latest model-free predictive control approach. The two approaches lead to convincing computer experiments where the results with the model-based one are only slightly better. They exhibit a satisfactory robustness with respect to randomly generated mismatches/disturbances, which become excellent in the model-free case. Those properties would have been perhaps difficult to obtain with today's popular machine learning techniques in AI. Finally, we should emphasize that our two methods require a low computational burden.

