---
layout: default
title: Physiology-informed layered sensing for intelligent human-exoskeleton interaction
---

# Physiology-informed layered sensing for intelligent human-exoskeleton interaction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.12157" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.12157v2</a>
  <a href="https://arxiv.org/pdf/2508.12157.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.12157v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.12157v2', 'Physiology-informed layered sensing for intelligent human-exoskeleton interaction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chenyu Tang, Yu Zhu, JosÃ©e Mallah, Wentian Yi, Luyao Jin, Zibo Zhang, Shengbo Wang, Muzi Xu, Ming Shen, Calvin Kalun Or, Shuo Gao, Shaoping Bai, Luigi G. Occhipinti

**åˆ†ç±»**: eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-16 (æ›´æ–°: 2025-10-16)

**å¤‡æ³¨**: 21 pages, 5 figures, 43 references

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç”Ÿç†ä¿¡æ¯é©±åŠ¨çš„åˆ†å±‚ä¼ æ„ŸæŠ€æœ¯ä»¥æå‡äººæœºå¤–éª¨éª¼äº¤äº’**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤–éª¨éª¼` `ç”Ÿç†ä¿¡æ¯` `å¤šæ¨¡æ€ä¼ æ„Ÿ` `å®æ—¶ç›‘æµ‹` `æ™ºèƒ½æ§åˆ¶` `åº·å¤æŠ€æœ¯` `ç”¨æˆ·ä½“éªŒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤–éª¨éª¼æŠ€æœ¯åœ¨å®éªŒå®¤å¤–çš„åº”ç”¨å—åˆ°é™åˆ¶ï¼Œä¸»è¦å› ä¸ºä¼ æ„Ÿç³»ç»Ÿæ— æ³•æ•æ‰ç”¨æˆ·çš„ç”Ÿç†çŠ¶æ€ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§é›†æˆå¤šç§ä¼ æ„ŸæŠ€æœ¯çš„æ™ºèƒ½è…¿å¥—ï¼Œèƒ½å¤Ÿå®æ—¶ç›‘æµ‹ç”¨æˆ·çš„ç”Ÿç†ä¿¡æ¯ï¼Œä»¥æå‡å¤–éª¨éª¼çš„é€‚åº”æ€§å’Œå®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨è¸å…³èŠ‚åŠ›çŸ©ä¼°è®¡ã€ä»£è°¢è¶‹åŠ¿åˆ†ç±»å’Œå—ä¼¤é£é™©æ£€æµ‹æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå‡†ç¡®ç‡å’Œå¬å›ç‡å‡é«˜äºç°æœ‰æŠ€æœ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯ç©¿æˆ´å¤–éª¨éª¼åœ¨æ¢å¤è‚Œè‚‰æ— åŠ›æˆ–å…¶ä»–éšœç¢ç”¨æˆ·çš„ç§»åŠ¨èƒ½åŠ›æ–¹é¢å…·æœ‰å˜é©æ€§æ½œåŠ›ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ä¼ æ„Ÿç³»ç»Ÿä»…æ•æ‰è¿åŠ¨è€Œæœªèƒ½åæ˜ æ½œåœ¨ç”Ÿç†çŠ¶æ€ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æŸ”è½¯ã€è½»ä¾¿çš„æ™ºèƒ½è…¿å¥—ï¼Œé€šè¿‡æ•´åˆåŸºäºçººç»‡çš„è¡¨é¢è‚Œç”µå›¾ï¼ˆsEMGï¼‰ç”µæã€è¶…çµæ•çººç»‡åº”å˜ä¼ æ„Ÿå™¨å’Œæƒ¯æ€§æµ‹é‡å•å…ƒï¼ˆIMUï¼‰ï¼Œå®ç°äº†è§£å‰–å­¦å¯¹é½çš„åˆ†å±‚å¤šæ¨¡æ€ä¼ æ„Ÿã€‚æ¯ç§ä¼ æ„Ÿæ–¹å¼é’ˆå¯¹ä¸åŒçš„ç”Ÿç†å±‚æ¬¡ï¼ŒIMUè·Ÿè¸ªå…³èŠ‚è¿åŠ¨å­¦ï¼ŒsEMGç›‘æµ‹è‚Œè‚‰æ¿€æ´»ï¼Œåº”å˜ä¼ æ„Ÿå™¨æ£€æµ‹çš®è‚¤å˜å½¢ã€‚è¿™äº›ä¼ æ„Ÿå™¨å…±åŒæä¾›å®æ—¶æ„ŸçŸ¥ï¼Œæ”¯æŒä¸ªæ€§åŒ–è¾…åŠ©æ§åˆ¶ã€ä¼˜åŒ–ç”¨æˆ·åŠªåŠ›å’Œé˜²æ­¢å—ä¼¤é£é™©ã€‚è¯¥ç³»ç»Ÿä¸çš®è‚¤ç´§å¯†è´´åˆï¼Œæœºæ¢°å…¼å®¹æ€§å¥½ï¼Œä¸”ä¸å®šåˆ¶å¤–éª¨éª¼æ— ç¼é›†æˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨æœªè§ç”¨æˆ·ä¸Šå®ç°äº†å‡†ç¡®çš„è¸å…³èŠ‚åŠ›çŸ©ä¼°è®¡ã€å®æ—¶ä»£è°¢è¶‹åŠ¿åˆ†ç±»å’Œå¿«é€Ÿçš„å—ä¼¤é£é™©æ£€æµ‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¤–éª¨éª¼æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­æ— æ³•æœ‰æ•ˆæ•æ‰ç”¨æˆ·ç”Ÿç†ä¿¡æ¯çš„é—®é¢˜ï¼Œå¯¼è‡´ä¸ªæ€§åŒ–è¾…åŠ©ä¸è¶³å’Œå®‰å…¨é£é™©å¢åŠ ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®¾è®¡ä¸€ç§é›†æˆå¤šç§ä¼ æ„Ÿå™¨çš„æ™ºèƒ½è…¿å¥—ï¼Œå®æ—¶ç›‘æµ‹ç”¨æˆ·çš„ç”Ÿç†çŠ¶æ€ï¼Œä»è€Œå®ç°æ›´æ™ºèƒ½çš„å¤–éª¨éª¼æ§åˆ¶å’Œç”¨æˆ·ä½“éªŒä¼˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç³»ç»ŸåŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºçººç»‡çš„sEMGç”µæç”¨äºè‚Œè‚‰æ¿€æ´»ç›‘æµ‹ï¼›2) è¶…çµæ•çš„åº”å˜ä¼ æ„Ÿå™¨ç”¨äºçš®è‚¤å˜å½¢æ£€æµ‹ï¼›3) IMUç”¨äºå…³èŠ‚è¿åŠ¨å­¦è·Ÿè¸ªã€‚æ‰€æœ‰ä¼ æ„Ÿå™¨æ•°æ®å®æ—¶èåˆï¼Œæä¾›å…¨é¢çš„ç”Ÿç†ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„åˆ›æ–°åœ¨äºå°†ç”Ÿç†ä¿¡æ¯ä¸è¿åŠ¨è·Ÿè¸ªç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„æ„ŸçŸ¥æ¶æ„ï¼Œä½¿å¤–éª¨éª¼ç³»ç»Ÿèƒ½å¤Ÿä»å•çº¯çš„è¿åŠ¨æ•æ‰è½¬å˜ä¸ºå®æ—¶ç”Ÿç†è§£ç ã€‚

**å…³é”®è®¾è®¡**ï¼šç³»ç»Ÿè®¾è®¡ä¸­ï¼Œä¼ æ„Ÿå™¨æ€»é‡é‡å°äº20å…‹ï¼Œç¡®ä¿äº†ç”¨æˆ·çš„èˆ’é€‚æ€§å’Œå¯ç©¿æˆ´æ€§ï¼›é‡‡ç”¨äº†é«˜ç²¾åº¦çš„ç®—æ³•è¿›è¡Œæ•°æ®å¤„ç†ï¼Œä»¥å®ç°è¸å…³èŠ‚åŠ›çŸ©çš„å‡†ç¡®ä¼°è®¡å’Œä»£è°¢è¶‹åŠ¿çš„å®æ—¶åˆ†ç±»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨è¸å…³èŠ‚åŠ›çŸ©ä¼°è®¡æ–¹é¢çš„å‡æ–¹æ ¹è¯¯å·®ä¸º0.13 Nm/kgï¼Œä»£è°¢è¶‹åŠ¿åˆ†ç±»çš„å‡†ç¡®ç‡è¾¾åˆ°97.1%ï¼Œè€Œå—ä¼¤é£é™©æ£€æµ‹çš„å¬å›ç‡é«˜è¾¾0.96ï¼Œæ‰€æœ‰ç»“æœå‡åœ¨æœªè§ç”¨æˆ·ä¸ŠéªŒè¯ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åº·å¤åŒ»å­¦ã€è€å¹´äººè¾…åŠ©è®¾å¤‡ä»¥åŠè¿åŠ¨å‘˜è®­ç»ƒç­‰ã€‚é€šè¿‡å®æ—¶ç›‘æµ‹ç”¨æˆ·çš„ç”Ÿç†çŠ¶æ€ï¼Œå¤–éª¨éª¼èƒ½å¤Ÿæä¾›ä¸ªæ€§åŒ–çš„æ”¯æŒï¼Œæå‡ç”¨æˆ·çš„å®‰å…¨æ€§å’Œèˆ’é€‚æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Wearable exoskeletons hold transformative promise for restoring mobility across diverse users with muscular weakness or other impairments. However, their translation beyond laboratory environments remains limited by sensing systems that capture movement but not underlying physiology. Here, we present a soft, lightweight smart leg sleeve that achieves anatomically aligned, layered multimodal sensing by integrating textile-based surface electromyography (sEMG) electrodes, ultrasensitive textile strain sensors, and inertial measurement units (IMUs). Each sensing modality targets a distinct physiological layer: IMUs track joint kinematics at the skeletal level, sEMG monitors muscle activation at the muscular level, and strain sensors detect skin deformation at the cutaneous level. Together, these sensors provide real-time perception to support three core objectives: controlling personalized assistance, optimizing user effort, and safeguarding against injury risks. The system is skin-conformal, mechanically compliant, and seamlessly integrated with a custom exoskeleton ($<20$~g total sensor and electronics weight). We demonstrate: (1) accurate ankle joint moment estimation (RMSE = 0.13~Nm/kg), (2) real-time classification of metabolic trends (accuracy = 97.1\%), and (3) injury risk detection within 100~ms (recall = 0.96), all validated on unseen users using a leave-one-subject-out protocol. This work establishes a physiology-aligned sensing architecture that reframes exoskeleton perception from motion tracking to real-time physiological decoding, offering a pathway towards intelligent, adaptive, and personalized wearable robotics.

