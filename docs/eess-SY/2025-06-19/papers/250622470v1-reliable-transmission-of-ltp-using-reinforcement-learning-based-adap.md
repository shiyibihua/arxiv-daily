---
layout: default
title: Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC
---

# Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.22470" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.22470v1</a>
  <a href="https://arxiv.org/pdf/2506.22470.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.22470v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.22470v1', 'Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liang Chen, Yu Song, Kanglian Zhao, Juan A. Fraire, Wenfeng Li

**åˆ†ç±»**: cs.NI, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**å¤‡æ³¨**: 15 pages, 30 figures, Liang Chen and Yu Song are co-first authors

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”FECä»¥è§£å†³æ·±ç©ºç½‘ç»œæ•°æ®ä¼ è¾“é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±ç©ºç½‘ç»œ` `è‡ªé€‚åº”FEC` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®ä¼ è¾“` `ä¿¡é“é¢„æµ‹` `ç¼–ç æ•ˆç‡` `çŸ©é˜µè§£ç ` `LTP`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„é™æ€å’ŒåŠ¨æ€ç¼–ç æ–¹æ³•åœ¨æ·±ç©ºç½‘ç»œä¸­é¢å¯¹é«˜åº¦å¯å˜çš„ä¿¡é“æ¡ä»¶æ—¶ï¼Œæ— æ³•æœ‰æ•ˆé™ä½é‡ä¼ æ—¶é—´æˆæœ¬ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”FECç®—æ³•ï¼Œé€šè¿‡å†å²åé¦ˆé¢„æµ‹ä¿¡é“æ¡ä»¶å¹¶è°ƒæ•´ç¼–ç é€Ÿç‡ï¼Œæ—¨åœ¨æé«˜æ•°æ®ä¼ è¾“çš„å¯é æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨åœ°æœˆå’Œåœ°ç«é“¾è·¯åœºæ™¯ä¸­æ˜¾è‘—å‡å°‘äº†çŸ©é˜µè§£ç å¤±è´¥ï¼Œæå‡å¹…åº¦è¶…è¿‡2/3ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å»¶è¿Ÿ/ä¸­æ–­å®¹å¿ç½‘ç»œï¼ˆDTNï¼‰é‡‡ç”¨Lickliderä¼ è¾“åè®®ï¼ˆLTPï¼‰å’Œè‡ªåŠ¨é‡ä¼ è¯·æ±‚ï¼ˆARQï¼‰æ¥å®ç°å¯é çš„æ•°æ®ä¼ è¾“ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é™æ€å’ŒåŸºäºå»¶è¿Ÿåé¦ˆçš„åŠ¨æ€ç¼–ç æ–¹æ³•åœ¨æ·±ç©ºä¿¡é“æ¡ä»¶é«˜åº¦å¯å˜å’Œä¸å¯é¢„æµ‹çš„æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”å‰å‘çº é”™ï¼ˆFECï¼‰ç®—æ³•ï¼Œåˆ©ç”¨å†å²åé¦ˆå’Œç³»ç»ŸçŠ¶æ€é¢„æµ‹æœªæ¥ä¿¡é“æ¡ä»¶ï¼Œå¹¶ä¸»åŠ¨è°ƒæ•´ç¼–ç é€Ÿç‡ï¼Œä»è€Œæé«˜ç¼–ç æ•ˆç‡ï¼Œå‡å°‘é‡ä¼ æ¬¡æ•°ã€‚é€šè¿‡åœ¨æ¨¡æ‹Ÿçš„åœ°æœˆå’Œåœ°ç«é“¾è·¯åœºæ™¯ä¸­è¿›è¡Œçš„æ€§èƒ½è¯„ä¼°ï¼ŒéªŒè¯äº†è¯¥ç®—æ³•åœ¨ä¼˜åŒ–æ·±ç©ºç½‘ç»œæ•°æ®ä¼ è¾“æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨æ·±ç©ºç½‘ç»œä¸­ï¼Œç°æœ‰é™æ€å’ŒåŠ¨æ€ç¼–ç æ–¹æ³•æ— æ³•é€‚åº”é«˜åº¦å¯å˜ä¿¡é“æ¡ä»¶çš„é—®é¢˜ï¼Œå¯¼è‡´é‡ä¼ æ—¶é—´æˆæœ¬é«˜å’Œè§£ç å¤±è´¥ç‡é«˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„è‡ªé€‚åº”FECç®—æ³•åŸºäºå¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡å†å²åé¦ˆå’Œç³»ç»ŸçŠ¶æ€é¢„æµ‹æœªæ¥ä¿¡é“è´¨é‡ï¼Œä¸»åŠ¨è°ƒæ•´ç¼–ç é€Ÿç‡ï¼Œä»¥åº”å¯¹ä¿¡é“è´¨é‡çš„å˜åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç®—æ³•çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é‡‡é›†æ¨¡å—ã€ä¿¡é“çŠ¶æ€é¢„æµ‹æ¨¡å—å’Œç¼–ç é€Ÿç‡è°ƒæ•´æ¨¡å—ã€‚æ•°æ®é‡‡é›†æ¨¡å—è´Ÿè´£æ”¶é›†å†å²åé¦ˆï¼Œé¢„æµ‹æ¨¡å—åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œä¿¡é“çŠ¶æ€é¢„æµ‹ï¼Œè°ƒæ•´æ¨¡å—æ ¹æ®é¢„æµ‹ç»“æœåŠ¨æ€è°ƒæ•´ç¼–ç é€Ÿç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥å¼ºåŒ–å­¦ä¹ æ¥å®ç°è‡ªé€‚åº”ç¼–ç é€Ÿç‡è°ƒæ•´ï¼Œè¿™ä¸ç°æœ‰é™æ€å’ŒåŸºäºå»¶è¿Ÿåé¦ˆçš„åŠ¨æ€æ–¹æ³•å½¢æˆäº†é²œæ˜å¯¹æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åº”å¯¹ä¿¡é“æ¡ä»¶çš„å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šç®—æ³•ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–é¢„æµ‹ç²¾åº¦ï¼Œå¹¶è®¾è®¡äº†é€‚åˆæ·±ç©ºç½‘ç»œçš„ç½‘ç»œç»“æ„ï¼Œä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡å’Œé€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”FECç®—æ³•åœ¨åœ°æœˆå’Œåœ°ç«é“¾è·¯åœºæ™¯ä¸­ï¼ŒçŸ©é˜µè§£ç å¤±è´¥ç‡å‡å°‘äº†è‡³å°‘2/3ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æ˜¾è‘—æå‡äº†æ•°æ®ä¼ è¾“çš„å¯é æ€§å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ·±ç©ºæ¢æµ‹ä»»åŠ¡ã€å«æ˜Ÿé€šä¿¡å’Œå…¶ä»–éœ€è¦åœ¨ä¸ç¨³å®šä¿¡é“æ¡ä»¶ä¸‹è¿›è¡Œå¯é æ•°æ®ä¼ è¾“çš„åœºæ™¯ã€‚é€šè¿‡æé«˜æ•°æ®ä¼ è¾“çš„å¯é æ€§å’Œæ•ˆç‡ï¼Œèƒ½å¤Ÿä¸ºæœªæ¥çš„æ·±ç©ºæ¢ç´¢å’Œé€šä¿¡æä¾›é‡è¦æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Delay/Disruption Tolerant Networking (DTN) employs the Licklider Transmission Protocol (LTP) with Automatic Repeat reQuest (ARQ) for reliable data delivery in challenging interplanetary networks. While previous studies have integrated packet-level Forward Erasure Correction (FEC) into LTP to reduce retransmission time costs, existing static and delay-feedback-based dynamic coding methods struggle with highly variable and unpredictable deep space channel conditions. This paper proposes a reinforcement learning (RL)-based adaptive FEC algorithm to address these limitations. The algorithm utilizes historical feedback and system state to predict future channel conditions and proactively adjust the code rate. This approach aims to anticipate channel quality degradation, thereby preventing decoding failures and subsequent LTP retransmissions and improving coding efficiency by minimizing redundancy during favorable channel conditions. Performance evaluations conducted in simulated Earth-Moon and Earth-Mars link scenarios demonstrate this algorithm's effectiveness in optimizing data transmission for interplanetary networks. Compared to existing methods, this approach demonstrates significant improvement, with matrix decoding failures reduced by at least 2/3.

