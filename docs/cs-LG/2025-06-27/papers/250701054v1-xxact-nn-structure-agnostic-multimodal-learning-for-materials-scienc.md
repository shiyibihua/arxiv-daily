---
layout: default
title: XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science
---

# XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.01054" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.01054v1</a>
  <a href="https://arxiv.org/pdf/2507.01054.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.01054v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.01054v1', 'XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jithendaraa Subramanian, Linda Hung, Daniel Schweigert, Santosh Suram, Weike Ye

**åˆ†ç±»**: cs.LG, cond-mat.mtrl-sci, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: 10 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºXxaCT-NNä»¥è§£å†³ææ–™ç§‘å­¦ä¸­çš„ç»“æ„ä¾èµ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ææ–™ç§‘å­¦` `è‡ªç›‘ç£å­¦ä¹ ` `Xå°„çº¿è¡å°„` `æ¨¡å‹è®­ç»ƒ` `æ•°æ®é›†æ‰©å±•` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºç»“æ„çš„ææ–™å‘ç°æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´åŸå­ç»“æ„æœªçŸ¥çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶æœ‰æ•ˆæ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„XxaCT-NNæ¡†æ¶é€šè¿‡ç›´æ¥åˆ©ç”¨å…ƒç´ ç»„æˆå’ŒXRDæ•°æ®ï¼Œé¿å…äº†å¯¹æ™¶ä½“ç»“æ„çš„ä¾èµ–ï¼Œå…·æœ‰æ›´å¥½çš„å®ç”¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé¢„è®­ç»ƒç­–ç•¥æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œææ–™å‘ç°çš„è¿›å±•ä¸»è¦ä¾èµ–äºåŸºäºç»“æ„çš„æ¨¡å‹ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨æ™¶ä½“å›¾çš„æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€ä¸å¤Ÿå®ç”¨ï¼Œå› ä¸ºåŸå­ç»“æ„é€šå¸¸æœªçŸ¥æˆ–éš¾ä»¥è·å–ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„å¤šæ¨¡æ€æ¡†æ¶ï¼Œç›´æ¥ä»å…ƒç´ ç»„æˆå’ŒXå°„çº¿è¡å°„ï¼ˆXRDï¼‰ä¸­å­¦ä¹ ï¼Œæ— éœ€æ™¶ä½“ç»“æ„è¾“å…¥ã€‚æˆ‘ä»¬çš„æ¶æ„ç»“åˆäº†ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨å’Œäº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—ï¼Œå¹¶åœ¨500ä¸‡æ ·æœ¬çš„Alexandriaæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬æå‡ºäº†æ©è”½XRDå»ºæ¨¡ï¼ˆMXMï¼‰ï¼Œå¹¶å°†MXMå’Œå¯¹æ¯”å¯¹é½ä½œä¸ºè‡ªç›‘ç£é¢„è®­ç»ƒç­–ç•¥ã€‚é¢„è®­ç»ƒåŠ é€Ÿæ”¶æ•›ï¼ˆæœ€é«˜å¯è¾¾4.2å€ï¼‰ï¼Œå¹¶æé«˜äº†å‡†ç¡®æ€§å’Œè¡¨ç¤ºè´¨é‡ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå¤šæ¨¡æ€æ€§èƒ½åœ¨æ•°æ®é›†è§„æ¨¡ä¸Šæ¯”å•æ¨¡æ€åŸºçº¿æ›´å…·ä¼˜åŠ¿ï¼Œä¸”åœ¨æ›´å¤§æ•°æ®èŒƒå›´å†…å¢ç›Šå¤åˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ææ–™ç§‘å­¦æ¨¡å‹å¯¹æ™¶ä½“ç»“æ„çš„ä¾èµ–é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å®é™…åº”ç”¨ä¸­ï¼ŒåŸå­ç»“æ„å¾€å¾€æœªçŸ¥æˆ–éš¾ä»¥è·å–ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¿™äº›æƒ…å†µæ—¶æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šXxaCT-NNæ¡†æ¶é€šè¿‡ç»“åˆå…ƒç´ ç»„æˆå’ŒXRDæ•°æ®ï¼Œé‡‡ç”¨å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ï¼Œé¿å…äº†å¯¹æ™¶ä½“ç»“æ„çš„ä¾èµ–ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é€‚ç”¨æ€§å’Œçµæ´»æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ¨¡æ€ç‰¹å®šçš„ç¼–ç å™¨å’Œä¸€ä¸ªäº¤å‰æ³¨æ„åŠ›èåˆæ¨¡å—ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•´åˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ã€‚æ¨¡å‹åœ¨500ä¸‡æ ·æœ¬çš„Alexandriaæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œé‡‡ç”¨æ©è”½XRDå»ºæ¨¡ï¼ˆMXMï¼‰å’Œå¯¹æ¯”å¯¹é½ä½œä¸ºè‡ªç›‘ç£é¢„è®­ç»ƒç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†æ©è”½XRDå»ºæ¨¡ï¼ˆMXMï¼‰ä½œä¸ºä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„è®­ç»ƒæ•ˆç‡å’Œè¡¨ç¤ºèƒ½åŠ›ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç»“æ„ä¾èµ–æ¨¡å‹æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨ä»¥æå–å…ƒç´ ç»„æˆå’ŒXRDæ•°æ®çš„ç‰¹å¾ï¼Œä½¿ç”¨äº¤å‰æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œä¿¡æ¯èåˆï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šåˆ™ç»“åˆäº†è‡ªç›‘ç£å­¦ä¹ çš„ç­–ç•¥ï¼Œä»¥æå‡æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒXxaCT-NNåœ¨é¢„è®­ç»ƒé˜¶æ®µå®ç°äº†æœ€é«˜4.2å€çš„æ”¶æ•›é€Ÿåº¦æå‡ï¼ŒåŒæ—¶åœ¨å‡†ç¡®æ€§å’Œè¡¨ç¤ºè´¨é‡ä¸Šå‡æœ‰æ˜¾è‘—æé«˜ã€‚ä¸å•æ¨¡æ€åŸºçº¿ç›¸æ¯”ï¼Œå¤šæ¨¡æ€æ€§èƒ½åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„å¢ç›Šï¼Œè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ææ–™ç§‘å­¦ä¸­çš„æ–°ææ–™å‘ç°ã€ææ–™æ€§èƒ½é¢„æµ‹ä»¥åŠå®éªŒæ•°æ®åˆ†æç­‰ã€‚é€šè¿‡æä¾›ä¸€ç§ä¸ä¾èµ–äºæ™¶ä½“ç»“æ„çš„å­¦ä¹ æ¡†æ¶ï¼ŒXxaCT-NNèƒ½å¤ŸåŠ é€Ÿææ–™ç ”å‘è¿‡ç¨‹ï¼Œé™ä½å®éªŒæˆæœ¬ï¼Œæ¨åŠ¨ææ–™ç§‘å­¦çš„è¿›æ­¥ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“æ›´å¤šé¢†åŸŸçš„å¤šæ¨¡æ€å­¦ä¹ åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in materials discovery have been driven by structure-based models, particularly those using crystal graphs. While effective for computational datasets, these models are impractical for real-world applications where atomic structures are often unknown or difficult to obtain. We propose a scalable multimodal framework that learns directly from elemental composition and X-ray diffraction (XRD) -- two of the more available modalities in experimental workflows without requiring crystal structure input. Our architecture integrates modality-specific encoders with a cross-attention fusion module and is trained on the 5-million-sample Alexandria dataset. We present masked XRD modeling (MXM), and apply MXM and contrastive alignment as self-supervised pretraining strategies. Pretraining yields faster convergence (up to 4.2x speedup) and improves both accuracy and representation quality. We further demonstrate that multimodal performance scales more favorably with dataset size than unimodal baselines, with gains compounding at larger data regimes. Our results establish a path toward structure-free, experimentally grounded foundation models for materials science.

