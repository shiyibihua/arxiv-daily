---
layout: default
title: Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review
---

# Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21899" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21899v1</a>
  <a href="https://arxiv.org/pdf/2506.21899.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21899v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21899v1', 'Advancements and Challenges in Continual Reinforcement Learning: A Comprehensive Review')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amara Zuffer, Michael Burke, Mehrtash Harandi

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-27

**å¤‡æ³¨**: 65 pages, 9 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°æŒç»­å¼ºåŒ–å­¦ä¹ çš„è¿›å±•ä¸æŒ‘æˆ˜ï¼Œæ¨åŠ¨åŠ¨æ€å­¦ä¹ èƒ½åŠ›æå‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æŒç»­å¼ºåŒ–å­¦ä¹ ` `åŠ¨æ€å­¦ä¹ ` `çŸ¥è¯†ä¿ç•™` `æœºå™¨äººæŠ€æœ¯` `æ™ºèƒ½ç³»ç»Ÿ` `å­¦ä¹ æ•ˆç‡` `ä»»åŠ¡é€‚åº”æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤šæ ·åŒ–ä»»åŠ¡å’ŒåŠ¨æ€ç¯å¢ƒæ—¶é¢ä¸´çŸ¥è¯†é—å¿˜å’Œå­¦ä¹ æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æŒç»­å­¦ä¹ æœºåˆ¶ï¼Œä½¿RLä»£ç†èƒ½å¤ŸåŠ¨æ€åœ°è·å–å’Œä¿ç•™çŸ¥è¯†ï¼Œä»è€Œæå‡å­¦ä¹ çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„RLä»£ç†åœ¨å¤šä¸ªè¯„ä¼°ç¯å¢ƒä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶æ˜¯åœ¨æœºå™¨äººåº”ç”¨ä¸­ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ä»»åŠ¡å¤šæ ·æ€§å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŠ¨æ€ç‰¹æ€§çš„å¢åŠ ï¼ŒRLä»£ç†éœ€è¦å…·å¤‡é¡ºåºå’ŒæŒç»­å­¦ä¹ çš„èƒ½åŠ›ï¼Œè¿™ç§å­¦ä¹ èŒƒå¼è¢«ç§°ä¸ºæŒç»­å¼ºåŒ–å­¦ä¹ ã€‚æœ¬æ–‡ç»¼è¿°äº†æŒç»­å­¦ä¹ å¦‚ä½•å°†RLä»£ç†è½¬å˜ä¸ºåŠ¨æ€çš„æŒç»­å­¦ä¹ è€…ï¼Œä½¿å…¶èƒ½å¤Ÿæ— ç¼åœ°è·å–å’Œä¿ç•™æœ‰ç”¨ä¸”å¯é‡ç”¨çš„çŸ¥è¯†ã€‚æ–‡ç« æ·±å…¥æ¢è®¨äº†æŒç»­å¼ºåŒ–å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€ä¸»è¦æŒ‘æˆ˜å’Œæ–°é¢–æ–¹æ³•ï¼Œç‰¹åˆ«å¼ºè°ƒäº†åœ¨æœºå™¨äººé¢†åŸŸçš„æœ€æ–°è¿›å±•ï¼Œå¹¶ç®€è¦æ¦‚è¿°äº†åœ¨é‡è¦ç ”ç©¶ä¸­ä½¿ç”¨çš„è¯„ä¼°ç¯å¢ƒï¼Œä¸ºæ–°æ‰‹æä¾›äº†å¯åŠæ€§ã€‚æœ€åï¼Œæ–‡ç« è®¨è®ºäº†å±€é™æ€§å’Œæœªæ¥çš„æœ‰å¸Œæœ›æ–¹å‘ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†å®è´µçš„è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­çŸ¥è¯†é—å¿˜å’Œå­¦ä¹ æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆåº”å¯¹ä»»åŠ¡çš„å¤šæ ·æ€§å’Œå˜åŒ–æ€§ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥æŒç»­å­¦ä¹ æœºåˆ¶ï¼Œä½¿RLä»£ç†èƒ½å¤Ÿåœ¨å­¦ä¹ æ–°ä»»åŠ¡çš„åŒæ—¶ä¿ç•™ä¹‹å‰ä»»åŠ¡çš„çŸ¥è¯†ï¼Œä»è€Œå®ç°çŸ¥è¯†çš„æ— ç¼è¿ç§»å’Œé‡ç”¨ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æé«˜ä»£ç†çš„å­¦ä¹ æ•ˆç‡å’Œé€‚åº”èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡é€‰æ‹©ã€çŸ¥è¯†æ›´æ–°å’Œè¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚ä»»åŠ¡é€‰æ‹©æ¨¡å—è´Ÿè´£åŠ¨æ€é€‰æ‹©å½“å‰å­¦ä¹ çš„ä»»åŠ¡ï¼ŒçŸ¥è¯†æ›´æ–°æ¨¡å—åˆ™é€šè¿‡æŒç»­å­¦ä¹ ç®—æ³•æ›´æ–°ä»£ç†çš„çŸ¥è¯†åº“ï¼Œè¯„ä¼°æ¨¡å—ç”¨äºéªŒè¯å­¦ä¹ æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„çŸ¥è¯†ä¿ç•™æœºåˆ¶ï¼Œè¯¥æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘çŸ¥è¯†é—å¿˜ï¼Œå¹¶æé«˜ä»£ç†åœ¨æ–°ä»»åŠ¡ä¸Šçš„å­¦ä¹ èƒ½åŠ›ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„é™æ€å­¦ä¹ æ–¹å¼å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®ºæ–‡é‡‡ç”¨äº†è‡ªé€‚åº”å­¦ä¹ ç‡å’ŒåŠ¨æ€ä»»åŠ¡æƒé‡è°ƒæ•´ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šå¼•å…¥äº†çŸ¥è¯†ä¿ç•™æŸå¤±ï¼Œä»¥ç¡®ä¿æ–°æ—§çŸ¥è¯†çš„å¹³è¡¡ã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºä¸é€’å½’ç¥ç»ç½‘ç»œçš„ç»“åˆï¼Œä»¥å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨æ–°æ–¹æ³•çš„RLä»£ç†åœ¨å¤šä¸ªæ ‡å‡†è¯„ä¼°ç¯å¢ƒä¸­ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨åŠ¨æ€ä»»åŠ¡åˆ‡æ¢åœºæ™¯ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”èƒ½åŠ›å’Œå­¦ä¹ æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½å®¶å±…ç­‰åŠ¨æ€ç¯å¢ƒä¸‹çš„æ™ºèƒ½ç³»ç»Ÿã€‚é€šè¿‡æå‡RLä»£ç†çš„æŒç»­å­¦ä¹ èƒ½åŠ›ï¼Œå¯ä»¥ä½¿å…¶åœ¨å¤æ‚å’Œå˜åŒ–çš„ç¯å¢ƒä¸­æ›´æœ‰æ•ˆåœ°æ‰§è¡Œä»»åŠ¡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The diversity of tasks and dynamic nature of reinforcement learning (RL) require RL agents to be able to learn sequentially and continuously, a learning paradigm known as continuous reinforcement learning. This survey reviews how continual learning transforms RL agents into dynamic continual learners. This enables RL agents to acquire and retain useful and reusable knowledge seamlessly. The paper delves into fundamental aspects of continual reinforcement learning, exploring key concepts, significant challenges, and novel methodologies. Special emphasis is placed on recent advancements in continual reinforcement learning within robotics, along with a succinct overview of evaluation environments utilized in prominent research, facilitating accessibility for newcomers to the field. The review concludes with a discussion on limitations and promising future directions, providing valuable insights for researchers and practitioners alike.

