---
layout: default
title: Disentangled Representation Learning via Modular Compositional Bias
---

# Disentangled Representation Learning via Modular Compositional Bias

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.21402" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.21402v2</a>
  <a href="https://arxiv.org/pdf/2510.21402.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.21402v2" onclick="toggleFavorite(this, '2510.21402v2', 'Disentangled Representation Learning via Modular Compositional Bias')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Whie Jung, Dong Hoon Lee, Seunghoon Hong

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-24 (æ›´æ–°: 2025-11-11)

**æœŸåˆŠ**: Advances in Neural Information Processing Systems (NeurIPS), 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/whieya/Compositional-DRL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¨¡å—åŒ–ç»„åˆåç½®çš„è§£è€¦è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ï¼Œå®ç°å±æ€§ã€å¯¹è±¡åŠå…¶è”åˆè§£è€¦ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§£è€¦è¡¨ç¤ºå­¦ä¹ ` `ç»„åˆåç½®` `å½’çº³åç½®` `å›¾åƒç”Ÿæˆ` `é£æ ¼è¿ç§»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§£è€¦è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¾èµ–äºç‰¹å®šå› ç´ çš„ç­–ç•¥ï¼Œå½“æ–°å› ç´ å‡ºç°æˆ–å¤šå› ç´ å…±å­˜æ—¶ï¼Œéœ€è¦é‡æ–°è®¾è®¡æ¶æ„æˆ–ç›®æ ‡ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§ç»„åˆåç½®ï¼Œé€šè¿‡æ¨¡å—åŒ–çš„å½’çº³åç½®ï¼Œè§£è€¦ç›®æ ‡å’Œæ¶æ„ï¼Œåˆ©ç”¨å› ç´ ç‰¹å®šçš„é‡ç»„è§„åˆ™è¿›è¡Œæ½œåœ¨å˜é‡çš„æ··åˆã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å±æ€§å’Œå¯¹è±¡è§£è€¦æ–¹é¢å…·æœ‰ç«äº‰åŠ›ï¼Œå¹¶èƒ½å®ç°å…¨å±€é£æ ¼å’Œå¯¹è±¡çš„è”åˆè§£è€¦ï¼Œæ— éœ€ä¿®æ”¹ç›®æ ‡æˆ–æ¶æ„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„è§£è€¦è¡¨ç¤ºå­¦ä¹ (DRL)æ–¹æ³•ä¸¥é‡ä¾èµ–äºç‰¹å®šå› ç´ çš„ç­–ç•¥â€”â€”å±æ€§çš„å­¦ä¹ ç›®æ ‡æˆ–å¯¹è±¡çš„æ¨¡å‹æ¶æ„â€”â€”æ¥åµŒå…¥å½’çº³åç½®ã€‚å½“æ–°çš„å˜å¼‚å› ç´ ä¸å…ˆå‰çš„å‡è®¾ï¼ˆå¦‚ç»Ÿè®¡ç‹¬ç«‹æ€§æˆ–ç©ºé—´æ’ä»–æ€§ï¼‰ä¸ä¸€è‡´ï¼Œæˆ–è€…å½“å¤šä¸ªå› ç´ å…±å­˜æ—¶ï¼Œè¿™ç§ä¸åŒçš„æ–¹æ³•ä¼šå¯¼è‡´æ˜¾è‘—çš„å¼€é”€ï¼Œå› ä¸ºä»ä¸šè€…å¿…é¡»é‡æ–°è®¾è®¡æ¶æ„æˆ–ç›®æ ‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç»„åˆåç½®ï¼Œä¸€ç§ä¸ç›®æ ‡å’Œæ¶æ„è§£è€¦çš„æ¨¡å—åŒ–å½’çº³åç½®ã€‚æˆ‘ä»¬çš„å…³é”®è§è§£æ˜¯ï¼Œä¸åŒçš„å› ç´ åœ¨æ•°æ®åˆ†å¸ƒä¸­éµå¾ªä¸åŒçš„é‡ç»„è§„åˆ™ï¼šå…¨å±€å±æ€§æ˜¯äº’æ–¥çš„ï¼Œä¾‹å¦‚ï¼Œä¸€å¼ è„¸åªæœ‰ä¸€ä¸ªé¼»å­ï¼Œè€Œå¯¹è±¡å…±äº«ä¸€ä¸ªå…±åŒçš„æ”¯æŒï¼ˆä»»ä½•å¯¹è±¡çš„å­é›†éƒ½å¯ä»¥å…±å­˜ï¼‰ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ ¹æ®ç‰¹å®šå› ç´ çš„è§„åˆ™ï¼ˆå³æ··åˆç­–ç•¥ï¼‰éšæœºåœ°é‡æ–°æ··åˆæ½œåœ¨å˜é‡ï¼Œå¹¶è¿«ä½¿ç¼–ç å™¨é€šè¿‡ä¸¤ä¸ªäº’è¡¥çš„ç›®æ ‡æ¥å‘ç°æ··åˆç­–ç•¥æ‰€åæ˜ çš„å› ç´ ç»“æ„ï¼šï¼ˆiï¼‰å…ˆéªŒæŸå¤±ï¼Œç¡®ä¿æ¯ä¸ªé‡æ··è§£ç æˆä¸€ä¸ªçœŸå®çš„å›¾åƒï¼Œä»¥åŠï¼ˆiiï¼‰Wiedemerç­‰äººå¼•å…¥çš„ç»„åˆä¸€è‡´æ€§æŸå¤±ï¼Œå®ƒå°†æ¯ä¸ªåˆæˆå›¾åƒä¸å…¶å¯¹åº”çš„åˆæˆæ½œåœ¨å˜é‡å¯¹é½ã€‚åœ¨è¿™ä¸ªé€šç”¨æ¡†æ¶ä¸‹ï¼Œç®€å•åœ°è°ƒæ•´æ··åˆç­–ç•¥å°±å¯ä»¥å®ç°å±æ€§ã€å¯¹è±¡ç”šè‡³ä¸¤è€…çš„è§£è€¦ï¼Œè€Œæ— éœ€ä¿®æ”¹ç›®æ ‡æˆ–æ¶æ„ã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å±æ€§å’Œå¯¹è±¡è§£è€¦æ–¹é¢éƒ½è¡¨ç°å‡ºæœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œå¹¶ä¸”ç‹¬ç‰¹åœ°å®ç°äº†å…¨å±€é£æ ¼å’Œå¯¹è±¡çš„è”åˆè§£è€¦ã€‚ä»£ç å¯åœ¨https://github.com/whieya/Compositional-DRLè·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„è§£è€¦è¡¨ç¤ºå­¦ä¹ æ–¹æ³•é€šå¸¸é’ˆå¯¹ç‰¹å®šç±»å‹çš„å› ç´ ï¼ˆä¾‹å¦‚ï¼Œå±æ€§æˆ–å¯¹è±¡ï¼‰è®¾è®¡ç‰¹å®šçš„å­¦ä¹ ç›®æ ‡æˆ–æ¨¡å‹æ¶æ„ã€‚å½“éœ€è¦å¤„ç†æ–°çš„ã€æœªçŸ¥çš„å› ç´ ï¼Œæˆ–è€…å½“å¤šä¸ªå› ç´ ä»¥å¤æ‚çš„æ–¹å¼å…±å­˜æ—¶ï¼Œè¿™äº›æ–¹æ³•å¾€å¾€éœ€è¦è¿›è¡Œå¤§é‡çš„ä¿®æ”¹å’Œé‡æ–°è®¾è®¡ï¼Œç¼ºä¹é€šç”¨æ€§å’Œçµæ´»æ€§ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åŒæ—¶è§£è€¦å…¨å±€å±æ€§ï¼ˆå¦‚é£æ ¼ï¼‰å’Œå±€éƒ¨å¯¹è±¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€æƒ³æ˜¯å¼•å…¥ä¸€ç§ä¸ç›®æ ‡å‡½æ•°å’Œæ¨¡å‹æ¶æ„è§£è€¦çš„æ¨¡å—åŒ–ç»„åˆåç½®ã€‚é€šè¿‡è§‚å¯Ÿåˆ°ä¸åŒå› ç´ åœ¨æ•°æ®åˆ†å¸ƒä¸­éµå¾ªä¸åŒçš„é‡ç»„è§„åˆ™ï¼ˆä¾‹å¦‚ï¼Œå…¨å±€å±æ€§äº’æ–¥ï¼Œå¯¹è±¡å¯ä»¥å…±å­˜ï¼‰ï¼Œè®ºæ–‡æå‡ºæ ¹æ®è¿™äº›è§„åˆ™éšæœºæ··åˆæ½œåœ¨å˜é‡ï¼Œå¹¶è®­ç»ƒç¼–ç å™¨å­¦ä¹ è¿™äº›æ··åˆè§„åˆ™æ‰€åæ˜ çš„å› ç´ ç»“æ„ã€‚è¿™ç§æ–¹æ³•å…è®¸é€šè¿‡ç®€å•åœ°è°ƒæ•´æ··åˆç­–ç•¥æ¥å®ç°ä¸åŒç±»å‹å› ç´ çš„è§£è€¦ï¼Œè€Œæ— éœ€ä¿®æ”¹æ¨¡å‹æ¶æ„æˆ–æŸå¤±å‡½æ•°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªç¼–ç å™¨å’Œä¸€ä¸ªè§£ç å™¨ã€‚ç¼–ç å™¨å°†è¾“å…¥å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œç„¶åæ ¹æ®é¢„å®šä¹‰çš„æ··åˆç­–ç•¥å¯¹æ½œåœ¨å˜é‡è¿›è¡Œé‡ç»„ã€‚è§£ç å™¨å°†é‡ç»„åçš„æ½œåœ¨å˜é‡æ˜ å°„å›å›¾åƒç©ºé—´ã€‚æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æŸå¤±å‡½æ•°ï¼š(1) å…ˆéªŒæŸå¤±ï¼Œç”¨äºç¡®ä¿é‡ç»„åçš„æ½œåœ¨å˜é‡èƒ½å¤Ÿè§£ç æˆçœŸå®çš„å›¾åƒï¼›(2) ç»„åˆä¸€è‡´æ€§æŸå¤±ï¼Œç”¨äºå¯¹é½åˆæˆå›¾åƒå’Œå¯¹åº”çš„åˆæˆæ½œåœ¨å˜é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ¨¡å—åŒ–çš„ç»„åˆåç½®ï¼Œå®ƒæ˜¯ä¸€ç§ä¸ç›®æ ‡å‡½æ•°å’Œæ¨¡å‹æ¶æ„è§£è€¦çš„å½’çº³åç½®ã€‚è¿™ç§åç½®å…è®¸é€šè¿‡ç®€å•åœ°è°ƒæ•´æ··åˆç­–ç•¥æ¥æ§åˆ¶æ¨¡å‹å­¦ä¹ åˆ°çš„å› ç´ ç»“æ„ï¼Œä»è€Œå®ç°ä¸åŒç±»å‹å› ç´ çš„è§£è€¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ é€šç”¨å’Œçµæ´»ï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„å¤šå› ç´ è§£è€¦é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) å› ç´ ç‰¹å®šçš„æ··åˆç­–ç•¥ï¼šæ ¹æ®ä¸åŒå› ç´ çš„é‡ç»„è§„åˆ™ï¼ˆä¾‹å¦‚ï¼Œäº’æ–¥æˆ–å…±å­˜ï¼‰è®¾è®¡ä¸åŒçš„æ··åˆç­–ç•¥ã€‚(2) ç»„åˆä¸€è‡´æ€§æŸå¤±ï¼šä½¿ç”¨Wiedemerç­‰äººæå‡ºçš„ç»„åˆä¸€è‡´æ€§æŸå¤±æ¥å¯¹é½åˆæˆå›¾åƒå’Œå¯¹åº”çš„åˆæˆæ½œåœ¨å˜é‡ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ­£ç¡®çš„å› ç´ ç»“æ„ã€‚(3) å…ˆéªŒæŸå¤±ï¼šç¡®ä¿é‡ç»„åçš„æ½œåœ¨å˜é‡èƒ½å¤Ÿè§£ç æˆçœŸå®çš„å›¾åƒï¼Œé˜²æ­¢æ¨¡å‹ç”Ÿæˆä¸åˆç†çš„å›¾åƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å±æ€§å’Œå¯¹è±¡è§£è€¦æ–¹é¢éƒ½è¡¨ç°å‡ºæœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚ç‰¹åˆ«åœ°ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç‹¬ç‰¹åœ°å®ç°å…¨å±€é£æ ¼å’Œå¯¹è±¡çš„è”åˆè§£è€¦ï¼Œè€Œç°æœ‰æ–¹æ³•é€šå¸¸åªèƒ½å¤„ç†å•ä¸€ç±»å‹çš„å› ç´ ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚å¤šå› ç´ è§£è€¦é—®é¢˜ä¸Šçš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒç¼–è¾‘ã€å›¾åƒç”Ÿæˆã€é£æ ¼è¿ç§»ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºæ§åˆ¶å›¾åƒä¸­ä¸åŒå¯¹è±¡çš„å‡ºç°å’Œä½ç½®ï¼Œæˆ–è€…æ”¹å˜å›¾åƒçš„å…¨å±€é£æ ¼è€Œä¸å½±å“å¯¹è±¡çš„å†…å®¹ã€‚è¯¥æ–¹æ³•åœ¨æœºå™¨äººè§†è§‰ã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸä¹Ÿæœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼Œå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å’Œæ“ä½œå¤æ‚ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent disentangled representation learning (DRL) methods heavily rely on factor specific strategies-either learning objectives for attributes or model architectures for objects-to embed inductive biases. Such divergent approaches result in significant overhead when novel factors of variation do not align with prior assumptions, such as statistical independence or spatial exclusivity, or when multiple factors coexist, as practitioners must redesign architectures or objectives. To address this, we propose a compositional bias, a modular inductive bias decoupled from both objectives and architectures. Our key insight is that different factors obey distinct recombination rules in the data distribution: global attributes are mutually exclusive, e.g., a face has one nose, while objects share a common support (any subset of objects can co-exist). We therefore randomly remix latents according to factor-specific rules, i.e., a mixing strategy, and force the encoder to discover whichever factor structure the mixing strategy reflects through two complementary objectives: (i) a prior loss that ensures every remix decodes into a realistic image, and (ii) the compositional consistency loss introduced by Wiedemer et al. (arXiv:2310.05327), which aligns each composite image with its corresponding composite latent. Under this general framework, simply adjusting the mixing strategy enables disentanglement of attributes, objects, and even both, without modifying the objectives or architectures. Extensive experiments demonstrate that our method shows competitive performance in both attribute and object disentanglement, and uniquely achieves joint disentanglement of global style and objects. Code is available at https://github.com/whieya/Compositional-DRL.

