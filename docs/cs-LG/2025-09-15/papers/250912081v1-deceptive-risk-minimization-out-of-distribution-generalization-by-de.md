---
layout: default
title: Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors
---

# Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.12081" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.12081v1</a>
  <a href="https://arxiv.org/pdf/2509.12081.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.12081v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.12081v1', 'Deceptive Risk Minimization: Out-of-Distribution Generalization by Deceiving Distribution Shift Detectors')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anirudha Majumdar

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¬ºéª—é£é™©æœ€å°åŒ–(DRM)æ–¹æ³•ï¼Œé€šè¿‡æ¬ºéª—åˆ†å¸ƒåç§»æ£€æµ‹å™¨å®ç°OODæ³›åŒ–ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åˆ†å¸ƒå¤–æ³›åŒ–` `é¢†åŸŸæ³›åŒ–` `æ¬ºéª—é£é™©æœ€å°åŒ–` `å…±å½¢é…` `åˆ†å¸ƒåç§»æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰OODæ³›åŒ–æ–¹æ³•é€šå¸¸éœ€è¦è®¿é—®æµ‹è¯•æ•°æ®æˆ–å°†è®­ç»ƒæ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªé¢†åŸŸï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. DRMé€šè¿‡å­¦ä¹ æ¬ºéª—åˆ†å¸ƒåç§»æ£€æµ‹å™¨çš„æ•°æ®è¡¨å¾ï¼Œä½¿è®­ç»ƒæ•°æ®çœ‹èµ·æ¥æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼Œä»è€Œæå–ç¨³å®šç‰¹å¾ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒDRMåœ¨æ¦‚å¿µæ¼‚ç§»å’Œåå˜é‡æ¼‚ç§»çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡OODæ³›åŒ–æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºæ¬ºéª—æœºåˆ¶çš„åˆ†å¸ƒå¤–æ³›åŒ–(OOD)æ–¹æ³•ï¼šé€šè¿‡å­¦ä¹ æ•°æ®è¡¨å¾ï¼Œä½¿è®­ç»ƒæ•°æ®å¯¹äºè§‚å¯Ÿè€…è€Œè¨€å‘ˆç°ç‹¬ç«‹åŒåˆ†å¸ƒ(iid)çš„çŠ¶æ€ï¼Œä»è€Œè¯†åˆ«å‡ºç¨³å®šçš„ç‰¹å¾ï¼Œæ¶ˆé™¤è™šå‡ç›¸å…³æ€§ï¼Œå¹¶æ³›åŒ–åˆ°æœªè§è¿‡çš„é¢†åŸŸã€‚æˆ‘ä»¬å°†æ­¤åŸåˆ™ç§°ä¸ºæ¬ºéª—é£é™©æœ€å°åŒ–(DRM)ï¼Œå¹¶é€šè¿‡ä¸€ä¸ªå¯å¾®çš„ç›®æ ‡å‡½æ•°æ¥å®ç°å®ƒï¼Œè¯¥ç›®æ ‡å‡½æ•°åŒæ—¶å­¦ä¹ ç‰¹å¾ï¼Œä»åŸºäºå…±å½¢é…çš„æ£€æµ‹å™¨çš„è§’åº¦æ¶ˆé™¤åˆ†å¸ƒåç§»ï¼Œå¹¶æœ€å°åŒ–ç‰¹å®šä»»åŠ¡çš„æŸå¤±ã€‚ä¸é¢†åŸŸè‡ªé€‚åº”æˆ–å…ˆéªŒä¸å˜è¡¨å¾å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒDRMä¸éœ€è¦è®¿é—®æµ‹è¯•æ•°æ®æˆ–å°†è®­ç»ƒæ•°æ®åˆ’åˆ†ä¸ºæœ‰é™æ•°é‡çš„æ•°æ®ç”Ÿæˆé¢†åŸŸã€‚æˆ‘ä»¬åœ¨æ¦‚å¿µæ¼‚ç§»çš„æ•°å€¼å®éªŒä»¥åŠæœºå™¨äººéƒ¨ç½²ç¯å¢ƒä¸­åå˜é‡æ¼‚ç§»çš„æ¨¡æ‹Ÿæ¨¡ä»¿å­¦ä¹ ç¯å¢ƒä¸­è¯æ˜äº†DRMçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„åˆ†å¸ƒå¤–æ³›åŒ–(OOD)æ–¹æ³•ï¼Œå¦‚é¢†åŸŸè‡ªé€‚åº”å’Œä¸å˜è¡¨å¾å­¦ä¹ ï¼Œé€šå¸¸éœ€è¦è®¿é—®ç›®æ ‡åŸŸæ•°æ®æˆ–å°†è®­ç»ƒæ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªç¦»æ•£çš„é¢†åŸŸã€‚è¿™åœ¨å®é™…åº”ç”¨ä¸­å¯èƒ½éš¾ä»¥å®ç°ï¼Œå› ä¸ºç›®æ ‡åŸŸæ•°æ®å¯èƒ½ä¸å¯ç”¨ï¼Œæˆ–è€…é¢†åŸŸåˆ’åˆ†æœ¬èº«å°±æ˜¯ä¸€é¡¹å›°éš¾çš„ä»»åŠ¡ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¸ä¾èµ–ç›®æ ‡åŸŸä¿¡æ¯æˆ–é¢†åŸŸåˆ’åˆ†çš„æƒ…å†µä¸‹ï¼Œå®ç°æœ‰æ•ˆçš„OODæ³›åŒ–æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯â€œæ¬ºéª—â€ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯å­¦ä¹ ä¸€ç§æ•°æ®è¡¨å¾ï¼Œä½¿å¾—è®­ç»ƒæ•°æ®å¯¹äºä¸€ä¸ªåˆ†å¸ƒåç§»æ£€æµ‹å™¨è€Œè¨€ï¼Œçœ‹èµ·æ¥åƒæ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ã€‚è¿™æ ·åšçš„ç›®çš„æ˜¯ä¸ºäº†æ¶ˆé™¤æ•°æ®ä¸­çš„è™šå‡ç›¸å…³æ€§ï¼Œæå–å‡ºçœŸæ­£å…·æœ‰æ³›åŒ–èƒ½åŠ›çš„ç¨³å®šç‰¹å¾ã€‚é€šè¿‡â€œæ¬ºéª—â€æ£€æµ‹å™¨ï¼Œæ¨¡å‹è¢«è¿«å­¦ä¹ é‚£äº›ä¸å—åˆ†å¸ƒåç§»å½±å“çš„ç‰¹å¾ï¼Œä»è€Œæé«˜OODæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDRMçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ï¼šç‰¹å¾æå–å™¨å’Œåˆ†å¸ƒåç§»æ£€æµ‹å™¨ã€‚ç‰¹å¾æå–å™¨è´Ÿè´£å°†åŸå§‹æ•°æ®æ˜ å°„åˆ°ä¸€ç§æ–°çš„è¡¨å¾ç©ºé—´ã€‚åˆ†å¸ƒåç§»æ£€æµ‹å™¨åˆ™ç”¨äºåˆ¤æ–­è¯¥è¡¨å¾ç©ºé—´ä¸­çš„æ•°æ®æ˜¯å¦æœä»ç‹¬ç«‹åŒåˆ†å¸ƒã€‚DRMçš„ç›®æ ‡æ˜¯åŒæ—¶ä¼˜åŒ–ç‰¹å¾æå–å™¨å’Œåˆ†å¸ƒåç§»æ£€æµ‹å™¨ã€‚å…·ä½“æ¥è¯´ï¼Œç‰¹å¾æå–å™¨çš„ç›®æ ‡æ˜¯â€œæ¬ºéª—â€åˆ†å¸ƒåç§»æ£€æµ‹å™¨ï¼Œä½¿å…¶è®¤ä¸ºæ•°æ®æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ã€‚è€Œåˆ†å¸ƒåç§»æ£€æµ‹å™¨çš„ç›®æ ‡æ˜¯å°½å¯èƒ½å‡†ç¡®åœ°æ£€æµ‹å‡ºåˆ†å¸ƒåç§»ã€‚è¿™ä¸¤ä¸ªç›®æ ‡é€šè¿‡ä¸€ä¸ªå¯¹æŠ—è®­ç»ƒçš„è¿‡ç¨‹æ¥å®ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šDRMçš„å…³é”®åˆ›æ–°åœ¨äºå…¶â€œæ¬ºéª—â€çš„æ€æƒ³ã€‚ä¸ä¼ ç»Ÿçš„OODæ³›åŒ–æ–¹æ³•ä¸åŒï¼ŒDRMä¸ä¾èµ–äºç›®æ ‡åŸŸä¿¡æ¯æˆ–é¢†åŸŸåˆ’åˆ†ï¼Œè€Œæ˜¯é€šè¿‡å­¦ä¹ ä¸€ç§å¯¹åˆ†å¸ƒåç§»å…·æœ‰é²æ£’æ€§çš„æ•°æ®è¡¨å¾æ¥å®ç°æ³›åŒ–ã€‚è¿™ç§æ–¹æ³•æ›´åŠ çµæ´»ï¼Œä¹Ÿæ›´å…·æœ‰é€šç”¨æ€§ã€‚æ­¤å¤–ï¼ŒDRMä½¿ç”¨å…±å½¢é…ä½œä¸ºåˆ†å¸ƒåç§»æ£€æµ‹å™¨ï¼Œè¿™ä½¿å¾—æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å‡ºå„ç§ç±»å‹çš„åˆ†å¸ƒåç§»ã€‚

**å…³é”®è®¾è®¡**ï¼šDRMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š1) ä½¿ç”¨å…±å½¢é…ä½œä¸ºåˆ†å¸ƒåç§»æ£€æµ‹å™¨ã€‚å…±å½¢é…æ˜¯ä¸€ç§éå‚æ•°çš„åˆ†å¸ƒåç§»æ£€æµ‹æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ£€æµ‹å‡ºå„ç§ç±»å‹çš„åˆ†å¸ƒåç§»ã€‚2) ä½¿ç”¨å¯¹æŠ—è®­ç»ƒæ¥ä¼˜åŒ–ç‰¹å¾æå–å™¨å’Œåˆ†å¸ƒåç§»æ£€æµ‹å™¨ã€‚é€šè¿‡å¯¹æŠ—è®­ç»ƒï¼Œç‰¹å¾æå–å™¨å¯ä»¥å­¦ä¹ åˆ°å¯¹åˆ†å¸ƒåç§»å…·æœ‰é²æ£’æ€§çš„æ•°æ®è¡¨å¾ã€‚3) ä½¿ç”¨ä¸€ä¸ªå¯å¾®çš„ç›®æ ‡å‡½æ•°æ¥å®ç°DRMã€‚è¯¥ç›®æ ‡å‡½æ•°åŒæ—¶æœ€å°åŒ–ä»»åŠ¡ç‰¹å®šæŸå¤±å’Œåˆ†å¸ƒåç§»æ£€æµ‹å™¨çš„æŸå¤±ã€‚4) åœ¨å®éªŒä¸­ï¼Œä½œè€…ä½¿ç”¨äº†ä¸åŒçš„ç½‘ç»œç»“æ„ä½œä¸ºç‰¹å¾æå–å™¨ï¼Œå¹¶è°ƒæ•´äº†å¯¹æŠ—è®­ç»ƒçš„è¶…å‚æ•°ï¼Œä»¥è·å¾—æœ€ä½³çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DRMåœ¨æ¦‚å¿µæ¼‚ç§»å’Œåå˜é‡æ¼‚ç§»çš„æ¨¡æ‹Ÿç¯å¢ƒä¸­è¿›è¡Œäº†å®éªŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDRMèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜OODæ³›åŒ–æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨æ¦‚å¿µæ¼‚ç§»çš„å®éªŒä¸­ï¼ŒDRMç›¸æ¯”äºåŸºçº¿æ–¹æ³•ï¼Œé”™è¯¯ç‡é™ä½äº†10%ä»¥ä¸Šã€‚åœ¨åå˜é‡æ¼‚ç§»çš„å®éªŒä¸­ï¼ŒDRMä¹Ÿå–å¾—äº†ç±»ä¼¼çš„æ€§èƒ½æå‡ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒDRMæ˜¯ä¸€ç§æœ‰æ•ˆçš„OODæ³›åŒ–æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DRMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ç­‰é¢†åŸŸã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ¨¡å‹éœ€è¦åœ¨ä¸åŒçš„ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œè€Œè¿™äº›ç¯å¢ƒçš„æ•°æ®åˆ†å¸ƒå¯èƒ½ä¸è®­ç»ƒæ•°æ®å­˜åœ¨å·®å¼‚ã€‚DRMå¯ä»¥å¸®åŠ©æ¨¡å‹åœ¨è¿™äº›ç¯å¢ƒä¸­å®ç°æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚æ­¤å¤–ï¼ŒDRMè¿˜å¯ä»¥åº”ç”¨äºæ•°æ®å¢å¼ºã€é¢†åŸŸè‡ªé€‚åº”ç­‰ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper proposes deception as a mechanism for out-of-distribution (OOD) generalization: by learning data representations that make training data appear independent and identically distributed (iid) to an observer, we can identify stable features that eliminate spurious correlations and generalize to unseen domains. We refer to this principle as deceptive risk minimization (DRM) and instantiate it with a practical differentiable objective that simultaneously learns features that eliminate distribution shifts from the perspective of a detector based on conformal martingales while minimizing a task-specific loss. In contrast to domain adaptation or prior invariant representation learning methods, DRM does not require access to test data or a partitioning of training data into a finite number of data-generating domains. We demonstrate the efficacy of DRM on numerical experiments with concept shift and a simulated imitation learning setting with covariate shift in environments that a robot is deployed in.

