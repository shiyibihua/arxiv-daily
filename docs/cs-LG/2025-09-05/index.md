---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-09-05
---

# cs.LGï¼ˆ2025-09-05ï¼‰

ğŸ“Š å…± **23** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (12)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (12 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250905273v1-greener-deep-reinforcement-learning-analysis-of-energy-and-carbon-ef.html">Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks</a></td>
  <td>åˆ†æAtariåŸºå‡†æµ‹è¯•ä¸­æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„èƒ½æºå’Œç¢³æ•ˆç‡ï¼Œä¸ºç»¿è‰²DRLæä¾›åŸºå‡†ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05273v1" data-paper-url="./papers/250905273v1-greener-deep-reinforcement-learning-analysis-of-energy-and-carbon-ef.html" onclick="toggleFavorite(this, '2509.05273v1', 'Greener Deep Reinforcement Learning: Analysis of Energy and Carbon Efficiency Across Atari Benchmarks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250905292v1-deep-reinforcement-learning-for-ranking-utility-tuning-in-the-ad-rec.html">Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest</a></td>
  <td>æå‡ºDRL-PUTæ¡†æ¶ï¼Œåˆ©ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–Pinterestå¹¿å‘Šæ¨èç³»ç»Ÿä¸­æ’åºæ•ˆç”¨å‡½æ•°ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05292v1" data-paper-url="./papers/250905292v1-deep-reinforcement-learning-for-ranking-utility-tuning-in-the-ad-rec.html" onclick="toggleFavorite(this, '2509.05292v1', 'Deep Reinforcement Learning for Ranking Utility Tuning in the Ad Recommender System at Pinterest')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250910531v1-finxplore-an-adaptive-deep-reinforcement-learning-framework-for-bala.html">FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities</a></td>
  <td>FinXploreï¼šä¸€ç§è‡ªé€‚åº”æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå¹³è¡¡å’Œå‘ç°æŠ•èµ„æœºä¼š</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10531v1" data-paper-url="./papers/250910531v1-finxplore-an-adaptive-deep-reinforcement-learning-framework-for-bala.html" onclick="toggleFavorite(this, '2509.10531v1', 'FinXplore: An Adaptive Deep Reinforcement Learning Framework for Balancing and Discovering Investment Opportunities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250904734v2-beyond-i-con-exploring-new-dimension-of-distance-measures-in-represe.html">Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning</a></td>
  <td>Beyond I-Conï¼šæ¢ç´¢è¡¨å¾å­¦ä¹ ä¸­è·ç¦»åº¦é‡çš„æ–°ç»´åº¦ï¼Œæå‡èšç±»ä¸é™ç»´æ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.04734v2" data-paper-url="./papers/250904734v2-beyond-i-con-exploring-new-dimension-of-distance-measures-in-represe.html" onclick="toggleFavorite(this, '2509.04734v2', 'Beyond I-Con: Exploring New Dimension of Distance Measures in Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250905489v1-self-aligned-reward-towards-effective-and-efficient-reasoners.html">Self-Aligned Reward: Towards Effective and Efficient Reasoners</a></td>
  <td>æå‡ºè‡ªå¯¹é½å¥–åŠ±(SAR)ï¼Œæå‡LLMæ¨ç†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05489v1" data-paper-url="./papers/250905489v1-self-aligned-reward-towards-effective-and-efficient-reasoners.html" onclick="toggleFavorite(this, '2509.05489v1', 'Self-Aligned Reward: Towards Effective and Efficient Reasoners')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250904815v1-an-arbitration-control-for-an-ensemble-of-diversified-dqn-variants-i.html">An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning</a></td>
  <td>æå‡ºACED-DQNï¼Œé€šè¿‡ä»²è£æ§åˆ¶å¤šæ ·åŒ–DQNé›†æˆè§£å†³æŒç»­å¼ºåŒ–å­¦ä¹ ä¸­çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.04815v1" data-paper-url="./papers/250904815v1-an-arbitration-control-for-an-ensemble-of-diversified-dqn-variants-i.html" onclick="toggleFavorite(this, '2509.04815v1', 'An Arbitration Control for an Ensemble of Diversified DQN variants in Continual Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250905488v1-mambalite-micro-memory-optimized-mamba-inference-on-mcus.html">MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs</a></td>
  <td>MambaLite-Microï¼šé¢å‘MCUçš„å†…å­˜ä¼˜åŒ–Mambaæ¨¡å‹æ¨ç†å¼•æ“</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05488v1" data-paper-url="./papers/250905488v1-mambalite-micro-memory-optimized-mamba-inference-on-mcus.html" onclick="toggleFavorite(this, '2509.05488v1', 'MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250905478v1-plants-periodicity-aware-latent-state-representation-learning-for-mu.html">PLanTS: Periodicity-aware Latent-state Representation Learning for Multivariate Time Series</a></td>
  <td>PLanTSï¼šæå‡ºå‘¨æœŸæ„ŸçŸ¥çš„æ½œåœ¨çŠ¶æ€è¡¨å¾å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå¤šå…ƒæ—¶é—´åºåˆ—åˆ†æã€‚</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05478v1" data-paper-url="./papers/250905478v1-plants-periodicity-aware-latent-state-representation-learning-for-mu.html" onclick="toggleFavorite(this, '2509.05478v1', 'PLanTS: Periodicity-aware Latent-state Representation Learning for Multivariate Time Series')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250905276v3-spikingbrain-spiking-brain-inspired-large-models.html">SpikingBrain: Spiking Brain-inspired Large Models</a></td>
  <td>SpikingBrainï¼šå—è„‘å¯å‘çš„å¤§æ¨¡å‹ï¼Œæå‡é•¿æ–‡æœ¬å¤„ç†æ•ˆç‡å¹¶é™ä½åŠŸè€—</td>
  <td class="tags-cell"><span class="paper-tag">linear attention</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05276v3" data-paper-url="./papers/250905276v3-spikingbrain-spiking-brain-inspired-large-models.html" onclick="toggleFavorite(this, '2509.05276v3', 'SpikingBrain: Spiking Brain-inspired Large Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250905193v2-shift-before-you-learn-enabling-low-rank-representations-in-reinforc.html">Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºè½¬ç§»åç»§æµ‹åº¦çš„ä½ç§©å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæå‡ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05193v2" data-paper-url="./papers/250905193v2-shift-before-you-learn-enabling-low-rank-representations-in-reinforc.html" onclick="toggleFavorite(this, '2509.05193v2', 'Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250915230v1-pre-forgettable-models-prompt-learning-as-a-native-mechanism-for-unl.html">Pre-Forgettable Models: Prompt Learning as a Native Mechanism for Unlearning</a></td>
  <td>æå‡ºåŸºäºPromptå­¦ä¹ çš„é¢„å…ˆå¯é—å¿˜æ¨¡å‹ï¼Œå®ç°é«˜æ•ˆã€å®‰å…¨çš„çŸ¥è¯†ç§»é™¤ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span> <span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.15230v1" data-paper-url="./papers/250915230v1-pre-forgettable-models-prompt-learning-as-a-native-mechanism-for-unl.html" onclick="toggleFavorite(this, '2509.15230v1', 'Pre-Forgettable Models: Prompt Learning as a Native Mechanism for Unlearning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250904973v1-topology-aware-graph-reinforcement-learning-for-dynamic-routing-in-c.html">Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks</a></td>
  <td>æå‡ºæ‹“æ‰‘æ„ŸçŸ¥å›¾å¼ºåŒ–å­¦ä¹ ï¼Œè§£å†³äº‘ç½‘ç»œåŠ¨æ€è·¯ç”±ä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.04973v1" data-paper-url="./papers/250904973v1-topology-aware-graph-reinforcement-learning-for-dynamic-routing-in-c.html" onclick="toggleFavorite(this, '2509.04973v1', 'Topology-Aware Graph Reinforcement Learning for Dynamic Routing in Cloud Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (9 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>13</td>
  <td><a href="./papers/250904751v1-multimodal-foundation-model-driven-user-interest-modeling-and-behavi.html">Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms</a></td>
  <td>æå‡ºåŸºäºå¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„ç”¨æˆ·å…´è¶£å»ºæ¨¡æ–¹æ³•ï¼Œæå‡çŸ­è§†é¢‘æ¨èæ•ˆæœã€‚</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.04751v1" data-paper-url="./papers/250904751v1-multimodal-foundation-model-driven-user-interest-modeling-and-behavi.html" onclick="toggleFavorite(this, '2509.04751v1', 'Multimodal Foundation Model-Driven User Interest Modeling and Behavior Analysis on Short Video Platforms')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250905542v2-dreamprm-15-unlocking-the-potential-of-each-instance-for-multimodal-.html">DreamPRM-1.5: Unlocking the Potential of Each Instance for Multimodal Process Reward Model Training</a></td>
  <td>DreamPRM-1.5ï¼šé€šè¿‡å®ä¾‹é‡åŠ æƒæå‡å¤šæ¨¡æ€è¿‡ç¨‹å¥–åŠ±æ¨¡å‹çš„è®­ç»ƒæ•ˆæœ</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05542v2" data-paper-url="./papers/250905542v2-dreamprm-15-unlocking-the-potential-of-each-instance-for-multimodal-.html" onclick="toggleFavorite(this, '2509.05542v2', 'DreamPRM-1.5: Unlocking the Potential of Each Instance for Multimodal Process Reward Model Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250905186v2-probabilistic-operator-learning-generative-modeling-and-uncertainty-.html">Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations</a></td>
  <td>æå‡ºGenICONï¼Œé€šè¿‡ç”Ÿæˆå»ºæ¨¡å’Œä¸ç¡®å®šæ€§é‡åŒ–æå‡å¾®åˆ†æ–¹ç¨‹åŸºç¡€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05186v2" data-paper-url="./papers/250905186v2-probabilistic-operator-learning-generative-modeling-and-uncertainty-.html" onclick="toggleFavorite(this, '2509.05186v2', 'Probabilistic operator learning: generative modeling and uncertainty quantification for foundation models of differential equations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250905037v4-modalsurv-investigating-opportunities-and-limitations-of-multimodal-.html">ModalSurv: Investigating opportunities and limitations of multimodal deep survival learning in prostate and bladder cancer</a></td>
  <td>ModalSurvï¼šå¤šæ¨¡æ€æ·±åº¦ç”Ÿå­˜å­¦ä¹ åœ¨å‰åˆ—è…ºç™Œå’Œè†€èƒ±ç™Œä¸­çš„åº”ç”¨ä¸å±€é™æ€§ç ”ç©¶</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05037v4" data-paper-url="./papers/250905037v4-modalsurv-investigating-opportunities-and-limitations-of-multimodal-.html" onclick="toggleFavorite(this, '2509.05037v4', 'ModalSurv: Investigating opportunities and limitations of multimodal deep survival learning in prostate and bladder cancer')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250907003v1-vescale-consistent-and-efficient-tensor-programming-with-eager-mode-.html">veScale: Consistent and Efficient Tensor Programming with Eager-Mode SPMD</a></td>
  <td>veScaleï¼šé€šè¿‡Eageræ¨¡å¼SPMDå®ç°ä¸€è‡´ä¸”é«˜æ•ˆçš„å¼ é‡ç¼–ç¨‹</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.07003v1" data-paper-url="./papers/250907003v1-vescale-consistent-and-efficient-tensor-programming-with-eager-mode-.html" onclick="toggleFavorite(this, '2509.07003v1', 'veScale: Consistent and Efficient Tensor Programming with Eager-Mode SPMD')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>18</td>
  <td><a href="./papers/250905449v1-neural-breadcrumbs-membership-inference-attacks-on-llms-through-hidd.html">Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden State and Attention Pattern Analysis</a></td>
  <td>æå‡ºmemTraceæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹çš„æˆå‘˜æ¨æ–­æ”»å‡»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05449v1" data-paper-url="./papers/250905449v1-neural-breadcrumbs-membership-inference-attacks-on-llms-through-hidd.html" onclick="toggleFavorite(this, '2509.05449v1', 'Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden State and Attention Pattern Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250910537v1-on-using-large-batches-in-federated-learning.html">On Using Large-Batches in Federated Learning</a></td>
  <td>æ¢ç´¢è”é‚¦å­¦ä¹ ä¸­å¤§æ‰¹é‡è®­ç»ƒçš„ä¼˜åŠ¿ä¸æŒ‘æˆ˜ï¼Œæå‡æ¨¡å‹æ³›åŒ–æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10537v1" data-paper-url="./papers/250910537v1-on-using-large-batches-in-federated-learning.html" onclick="toggleFavorite(this, '2509.10537v1', 'On Using Large-Batches in Federated Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250905165v2-kvcompose-efficient-structured-kv-cache-compression-with-composite-t.html">KVCompose: Efficient Structured KV Cache Compression with Composite Tokens</a></td>
  <td>KVComposeï¼šåˆ©ç”¨å¤åˆTokenå®ç°é«˜æ•ˆç»“æ„åŒ–KVç¼“å­˜å‹ç¼©</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05165v2" data-paper-url="./papers/250905165v2-kvcompose-efficient-structured-kv-cache-compression-with-composite-t.html" onclick="toggleFavorite(this, '2509.05165v2', 'KVCompose: Efficient Structured KV Cache Compression with Composite Tokens')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250904905v1-revolution-or-hype-seeking-the-limits-of-large-models-in-hardware-de.html">Revolution or Hype? Seeking the Limits of Large Models in Hardware Design</a></td>
  <td>æ¢è®¨å¤§å‹æ¨¡å‹åœ¨ç¡¬ä»¶è®¾è®¡ä¸­çš„å±€é™æ€§ä¸æ½œåŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.04905v1" data-paper-url="./papers/250904905v1-revolution-or-hype-seeking-the-limits-of-large-models-in-hardware-de.html" onclick="toggleFavorite(this, '2509.04905v1', 'Revolution or Hype? Seeking the Limits of Large Models in Hardware Design')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>22</td>
  <td><a href="./papers/250905241v1-deep-learning-enhanced-for-amine-emission-monitoring-and-performance.html">Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants</a></td>
  <td>åˆ©ç”¨æ·±åº¦å­¦ä¹ é¢„æµ‹èƒºæ’æ”¾ä¸æ€§èƒ½ï¼Œä¼˜åŒ–å·¥ä¸šç¢³æ•è·</td>
  <td class="tags-cell"><span class="paper-tag">AMP</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05241v1" data-paper-url="./papers/250905241v1-deep-learning-enhanced-for-amine-emission-monitoring-and-performance.html" onclick="toggleFavorite(this, '2509.05241v1', 'Deep Learning-Enhanced for Amine Emission Monitoring and Performance Analysis in Industrial Carbon Capture Plants')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>23</td>
  <td><a href="./papers/250905137v1-on-the-learnability-of-distribution-classes-with-adaptive-adversarie.html">On the Learnability of Distribution Classes with Adaptive Adversaries</a></td>
  <td>ç ”ç©¶è‡ªé€‚åº”å¯¹æŠ—ä¸‹çš„åˆ†å¸ƒç±»å¯å­¦ä¹ æ€§ï¼Œæ­ç¤ºå…¶ä¸ä¼ ç»Ÿå¯¹æŠ—å­¦ä¹ çš„å·®å¼‚</td>
  <td class="tags-cell"><span class="paper-tag">manipulation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.05137v1" data-paper-url="./papers/250905137v1-on-the-learnability-of-distribution-classes-with-adaptive-adversarie.html" onclick="toggleFavorite(this, '2509.05137v1', 'On the Learnability of Distribution Classes with Adaptive Adversaries')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)