---
layout: default
title: MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs
---

# MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05488" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05488v1</a>
  <a href="https://arxiv.org/pdf/2509.05488.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05488v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05488v1', 'MambaLite-Micro: Memory-Optimized Mamba Inference on MCUs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hongjun Xu, Junxi Xia, Weisi Yang, Yueyuan Sui, Stephen Xia

**åˆ†ç±»**: cs.LG, cs.AI, cs.OS

**å‘å¸ƒæ—¥æœŸ**: 2025-09-05

**å¤‡æ³¨**: 4 pages, 1 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MambaLite-Microï¼šé¢å‘MCUçš„å†…å­˜ä¼˜åŒ–Mambaæ¨¡å‹æ¨ç†å¼•æ“**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `Mambaæ¨¡å‹` `å¾®æ§åˆ¶å™¨` `åµŒå…¥å¼éƒ¨ç½²` `å†…å­˜ä¼˜åŒ–` `Cè¯­è¨€æ¨ç†å¼•æ“` `ç®—å­èåˆ` `å…³é”®è¯è¯†åˆ«` `äººä½“æ´»åŠ¨è¯†åˆ«`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åœ¨å¾®æ§åˆ¶å™¨ä¸Šéƒ¨ç½²Mambaæ¨¡å‹é¢ä¸´å†…å­˜é™åˆ¶ã€ç¼ºå°‘åŸç”Ÿç®—å­æ”¯æŒå’ŒåµŒå…¥å¼å·¥å…·é“¾ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚
2. MambaLite-Microé€šè¿‡æ¨¡å‹æƒé‡è½»é‡åŒ–ã€Cè¯­è¨€æ‰‹å·¥å®ç°ç®—å­èåˆå’Œå†…å­˜å¸ƒå±€ä¼˜åŒ–ï¼Œå®ç°é«˜æ•ˆæ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMambaLite-Microæ˜¾è‘—é™ä½å†…å­˜å ç”¨ï¼Œä¿æŒé«˜ç²¾åº¦ï¼Œå¹¶åœ¨å¤šç§MCUå¹³å°ä¸ŠæˆåŠŸéƒ¨ç½²ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºMambaLite-Microï¼Œä¸€ç§å®Œå…¨åŸºäºCè¯­è¨€ã€æ— éœ€è¿è¡Œæ—¶çš„Mambaæ¨¡å‹æ¨ç†å¼•æ“ï¼Œæ—¨åœ¨è§£å†³åœ¨èµ„æºå—é™çš„å¾®æ§åˆ¶å™¨ï¼ˆMCUï¼‰ä¸Šéƒ¨ç½²Mambaæ¨¡å‹çš„æŒ‘æˆ˜ï¼Œè¿™äº›æŒ‘æˆ˜åŒ…æ‹¬æœ‰é™çš„å†…å­˜ã€ç¼ºä¹åŸç”Ÿç®—å­æ”¯æŒä»¥åŠç¼ºå°‘åµŒå…¥å¼å‹å¥½çš„å·¥å…·é“¾ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡ä»¥ä¸‹æ­¥éª¤å°†è®­ç»ƒå¥½çš„PyTorch Mambaæ¨¡å‹æ˜ å°„åˆ°è®¾å¤‡ç«¯æ‰§è¡Œï¼šï¼ˆ1ï¼‰å°†æ¨¡å‹æƒé‡å¯¼å‡ºä¸ºè½»é‡çº§æ ¼å¼ï¼›ï¼ˆ2ï¼‰ç”¨Cè¯­è¨€æ‰‹å·¥å®ç°Mambaå±‚å’Œæ”¯æŒç®—å­ï¼Œå¹¶è¿›è¡Œç®—å­èåˆå’Œå†…å­˜å¸ƒå±€ä¼˜åŒ–ã€‚MambaLite-Microæ¶ˆé™¤äº†å¤§å‹ä¸­é—´å¼ é‡ï¼Œä»è€Œå‡å°‘äº†83.0%çš„å³°å€¼å†…å­˜ä½¿ç”¨ï¼ŒåŒæ—¶ä¿æŒäº†ä¸PyTorch Mambaå®ç°ç›¸æ¯”å¹³å‡ä»…ä¸º1.7x10-5çš„æ•°å€¼è¯¯å·®ã€‚åœ¨å…³é”®è¯è¯†åˆ«ï¼ˆKWSï¼‰å’Œäººä½“æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰ä»»åŠ¡ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒMambaLite-Microä¸PyTorchåŸºçº¿å®ç°äº†100%çš„ä¸€è‡´æ€§ï¼Œå®Œå…¨ä¿ç•™äº†åˆ†ç±»ç²¾åº¦ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨ESP32S3å’ŒSTM32H7å¾®æ§åˆ¶å™¨ä¸Šçš„éƒ¨ç½²éªŒè¯äº†å…¶å¯ç§»æ¤æ€§ï¼Œè¯æ˜äº†åœ¨å¼‚æ„åµŒå…¥å¼å¹³å°ä¸Šçš„ä¸€è‡´è¿è¡Œï¼Œä¸ºå°†Mambaç­‰å…ˆè¿›åºåˆ—æ¨¡å‹å¼•å…¥å®é™…çš„èµ„æºå—é™åº”ç”¨é“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨èµ„æºå—é™çš„å¾®æ§åˆ¶å™¨ï¼ˆMCUï¼‰ä¸Šéƒ¨ç½²Mambaæ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨MCUä¸Šéƒ¨ç½²å¤§å‹æ¨¡å‹æ—¶ï¼Œé¢ä¸´å†…å­˜ä¸è¶³ã€ç¼ºä¹é’ˆå¯¹Mambaç®—å­çš„ä¼˜åŒ–ä»¥åŠåµŒå…¥å¼å¼€å‘å·¥å…·é“¾ä¸å®Œå–„ç­‰ç—›ç‚¹ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆåˆ©ç”¨Mambaæ¨¡å‹çš„ä¼˜åŠ¿ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å®šåˆ¶åŒ–çš„æ¨¡å‹å‹ç¼©å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä»¥åŠæ‰‹å·¥å®ç°çš„Cè¯­è¨€æ¨ç†å¼•æ“ï¼Œé™ä½Mambaæ¨¡å‹åœ¨MCUä¸Šçš„å†…å­˜å ç”¨å’Œè®¡ç®—å¤æ‚åº¦ã€‚é€šè¿‡æ¶ˆé™¤å¤§å‹ä¸­é—´å¼ é‡ï¼Œå¹¶ä¼˜åŒ–å†…å­˜å¸ƒå±€ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„ç‰‡ä¸Šæ¨ç†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMambaLite-Microçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼š(1) ç¦»çº¿æ¨¡å‹è½¬æ¢é˜¶æ®µï¼šå°†è®­ç»ƒå¥½çš„PyTorch Mambaæ¨¡å‹è½¬æ¢ä¸ºè½»é‡çº§æ ¼å¼ï¼Œæå–æ¨¡å‹æƒé‡ã€‚(2) åœ¨çº¿æ¨ç†é˜¶æ®µï¼šä½¿ç”¨æ‰‹å·¥å®ç°çš„Cè¯­è¨€æ¨ç†å¼•æ“ï¼ŒåŠ è½½æ¨¡å‹æƒé‡ï¼Œæ‰§è¡ŒMambaå±‚å’Œç›¸å…³ç®—å­çš„è®¡ç®—ï¼Œæœ€ç»ˆè¾“å‡ºæ¨ç†ç»“æœã€‚è¯¥å¼•æ“é’ˆå¯¹MCUçš„ç‰¹æ€§è¿›è¡Œäº†ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ç®—å­èåˆå’Œå†…å­˜å¸ƒå±€ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºé’ˆå¯¹Mambaæ¨¡å‹åœ¨MCUä¸Šçš„éƒ¨ç½²ï¼Œè®¾è®¡äº†ä¸€å¥—å®Œæ•´çš„ã€æ— éœ€è¿è¡Œæ—¶çš„Cè¯­è¨€æ¨ç†å¼•æ“ã€‚è¯¥å¼•æ“é€šè¿‡ç®—å­èåˆå’Œå†…å­˜å¸ƒå±€ä¼˜åŒ–ï¼Œæ˜¾è‘—é™ä½äº†å†…å­˜å ç”¨ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„æ•°å€¼ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆå…·æœ‰è‰¯å¥½çš„å¯ç§»æ¤æ€§ï¼Œå¯ä»¥åœ¨ä¸åŒçš„MCUå¹³å°ä¸Šéƒ¨ç½²ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) æ¨¡å‹æƒé‡å­˜å‚¨æ ¼å¼ï¼šé‡‡ç”¨è½»é‡çº§çš„äºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨æ¨¡å‹æƒé‡ï¼Œå‡å°‘å­˜å‚¨ç©ºé—´ã€‚(2) ç®—å­èåˆï¼šå°†å¤šä¸ªç®—å­èåˆä¸ºä¸€ä¸ªç®—å­ï¼Œå‡å°‘ä¸­é—´å¼ é‡çš„ç”Ÿæˆå’Œå­˜å‚¨ã€‚(3) å†…å­˜å¸ƒå±€ä¼˜åŒ–ï¼šä¼˜åŒ–å¼ é‡åœ¨å†…å­˜ä¸­çš„å¸ƒå±€ï¼Œå‡å°‘å†…å­˜ç¢ç‰‡å’Œè®¿é—®å¼€é”€ã€‚(4) Cè¯­è¨€å®ç°ï¼šä½¿ç”¨Cè¯­è¨€æ‰‹å·¥å®ç°Mambaå±‚å’Œç›¸å…³ç®—å­ï¼Œé¿å…äº†å¯¹å¤æ‚è¿è¡Œæ—¶ç¯å¢ƒçš„ä¾èµ–ï¼Œæé«˜äº†æ‰§è¡Œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MambaLite-Microåœ¨MCUä¸Šå®ç°äº†Mambaæ¨¡å‹çš„æˆåŠŸéƒ¨ç½²ï¼Œå³°å€¼å†…å­˜å ç”¨é™ä½äº†83.0%ï¼ŒåŒæ—¶ä¿æŒäº†ä¸PyTorchå®ç°ç›¸æ¯”å¹³å‡ä»…ä¸º1.7x10-5çš„æ•°å€¼è¯¯å·®ã€‚åœ¨å…³é”®è¯è¯†åˆ«ï¼ˆKWSï¼‰å’Œäººä½“æ´»åŠ¨è¯†åˆ«ï¼ˆHARï¼‰ä»»åŠ¡ä¸Šï¼ŒMambaLite-Microä¸PyTorchåŸºçº¿å®ç°äº†100%çš„ä¸€è‡´æ€§ï¼Œå®Œå…¨ä¿ç•™äº†åˆ†ç±»ç²¾åº¦ã€‚è¯¥æ–¹æ¡ˆåœ¨ESP32S3å’ŒSTM32H7å¾®æ§åˆ¶å™¨ä¸Šå‡æˆåŠŸéƒ¨ç½²ï¼ŒéªŒè¯äº†å…¶è·¨å¹³å°çš„å¯ç§»æ¤æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MambaLite-Microçš„åº”ç”¨åœºæ™¯å¹¿æ³›ï¼ŒåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€å¯ç©¿æˆ´è®¾å¤‡ã€å·¥ä¸šç‰©è”ç½‘ç­‰èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ã€‚è¯¥æŠ€æœ¯å¯ç”¨äºåœ¨è¿™äº›è®¾å¤‡ä¸Šéƒ¨ç½²å¤æ‚çš„åºåˆ—æ¨¡å‹ï¼Œå®ç°æœ¬åœ°åŒ–çš„æ™ºèƒ½åˆ†æå’Œå†³ç­–ï¼Œä¾‹å¦‚è¯­éŸ³è¯†åˆ«ã€å¼‚å¸¸æ£€æµ‹ã€å¥åº·ç›‘æµ‹ç­‰ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ¨åŠ¨Mambaç­‰å…ˆè¿›æ¨¡å‹åœ¨æ›´å¹¿æ³›çš„åµŒå…¥å¼åº”ç”¨ä¸­çš„æ™®åŠã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deploying Mamba models on microcontrollers (MCUs) remains challenging due to limited memory, the lack of native operator support, and the absence of embedded-friendly toolchains. We present, to our knowledge, the first deployment of a Mamba-based neural architecture on a resource-constrained MCU, a fully C-based runtime-free inference engine: MambaLite-Micro. Our pipeline maps a trained PyTorch Mamba model to on-device execution by (1) exporting model weights into a lightweight format, and (2) implementing a handcrafted Mamba layer and supporting operators in C with operator fusion and memory layout optimization. MambaLite-Micro eliminates large intermediate tensors, reducing 83.0% peak memory, while maintaining an average numerical error of only 1.7x10-5 relative to the PyTorch Mamba implementation. When evaluated on keyword spotting(KWS) and human activity recognition (HAR) tasks, MambaLite-Micro achieved 100% consistency with the PyTorch baselines, fully preserving classification accuracy. We further validated portability by deploying on both ESP32S3 and STM32H7 microcontrollers, demonstrating consistent operation across heterogeneous embedded platforms and paving the way for bringing advanced sequence models like Mamba to real-world resource-constrained applications.

