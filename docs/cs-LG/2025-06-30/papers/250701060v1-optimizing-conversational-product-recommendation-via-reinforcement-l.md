---
layout: default
title: Optimizing Conversational Product Recommendation via Reinforcement Learning
---

# Optimizing Conversational Product Recommendation via Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.01060" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.01060v1</a>
  <a href="https://arxiv.org/pdf/2507.01060.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.01060v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.01060v1', 'Optimizing Conversational Product Recommendation via Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kang Liu

**åˆ†ç±»**: cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„å¯¹è¯äº§å“æ¨èä¼˜åŒ–æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å¯¹è¯ç³»ç»Ÿ` `äº§å“æ¨è` `ç”¨æˆ·å‚ä¸` `ä¸ªæ€§åŒ–æœåŠ¡` `æ™ºèƒ½ä»£ç†` `è¡Œä¸ºæ¨¡å¼æŒ–æ˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„äº§å“æ¨èç³»ç»Ÿå¾€å¾€å¿½è§†äº†å¯¹è¯ç­–ç•¥çš„ä¼˜åŒ–ï¼Œå¯¼è‡´ç”¨æˆ·å‚ä¸åº¦ä½å’Œè½¬åŒ–ç‡ä¸é«˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„å¯¹è¯ç­–ç•¥ä¼˜åŒ–æ–¹æ³•ï¼Œé€šè¿‡åé¦ˆå­¦ä¹ ä½¿æ™ºèƒ½ä»£ç†èƒ½å¤Ÿè‡ªæˆ‘è°ƒæ•´æ¨èç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†ç”¨æˆ·çš„å‚ä¸åº¦å’Œäº§å“æ¥å—ç‡ï¼Œå…·æœ‰è‰¯å¥½çš„å®é™…åº”ç”¨å‰æ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ çš„æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–è·¨è¡Œä¸šçš„äº§å“æ¨èå¯¹è¯ç­–ç•¥ã€‚éšç€ç»„ç»‡è¶Šæ¥è¶Šå¤šåœ°é‡‡ç”¨æ™ºèƒ½ä»£ç†æ¥æ”¯æŒé”€å”®å’ŒæœåŠ¡æ“ä½œï¼Œå¯¹è¯çš„æœ‰æ•ˆæ€§ä¸ä»…å–å†³äºæ¨èçš„å†…å®¹ï¼Œè¿˜å–å†³äºæ¨èçš„æ–¹å¼å’Œæ—¶æœºã€‚æˆ‘ä»¬æ¢ç´¢äº†ä¸€ç§æ–¹æ³•è®ºï¼Œé€šè¿‡åé¦ˆé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ï¼Œä½¿ä»£ç†ç³»ç»Ÿå­¦ä¹ æœ€ä½³å¯¹è¯ç­–ç•¥ã€‚é€šè¿‡æŒ–æ˜æ±‡æ€»çš„è¡Œä¸ºæ¨¡å¼å’Œè½¬åŒ–ç»“æœï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ä»£ç†èƒ½å¤Ÿä¼˜åŒ–å¯¹è¯è½¨è¿¹ï¼Œä»è€Œæé«˜å‚ä¸åº¦å’Œäº§å“æ¥å—åº¦ï¼ŒåŒæ—¶éµå¾ªä¸Šä¸‹æ–‡å’Œç›‘ç®¡çº¦æŸã€‚æˆ‘ä»¬æ¦‚è¿°äº†æ¦‚å¿µæ¡†æ¶ï¼Œå¼ºè°ƒäº†å…³é”®åˆ›æ–°ï¼Œå¹¶è®¨è®ºäº†åœ¨ä¼ä¸šç¯å¢ƒä¸­å¯æ‰©å±•çš„ä¸ªæ€§åŒ–æ¨èçš„å½±å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰äº§å“æ¨èç³»ç»Ÿä¸­å¯¹è¯ç­–ç•¥ä¸ä¼˜åŒ–çš„é—®é¢˜ï¼Œå¯¼è‡´ç”¨æˆ·å‚ä¸åº¦å’Œè½¬åŒ–ç‡ä½ä¸‹ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ç¼ºä¹çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œæ— æ³•æœ‰æ•ˆå“åº”ç”¨æˆ·éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œé€šè¿‡åé¦ˆæœºåˆ¶ä½¿æ™ºèƒ½ä»£ç†å­¦ä¹ æœ€ä½³å¯¹è¯ç­–ç•¥ï¼Œä»¥æé«˜æ¨èçš„æœ‰æ•ˆæ€§å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ä»£ç†èƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„å®æ—¶åé¦ˆè¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€è¡Œä¸ºæ¨¡å¼æŒ–æ˜ã€ç­–ç•¥å­¦ä¹ å’Œç­–ç•¥ä¼˜åŒ–å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œç³»ç»Ÿæ”¶é›†ç”¨æˆ·äº¤äº’æ•°æ®ï¼Œç„¶ååˆ†æç”¨æˆ·è¡Œä¸ºæ¨¡å¼ï¼Œæ¥ç€é€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•è®­ç»ƒå¯¹è¯ç­–ç•¥ï¼Œæœ€åä¼˜åŒ–æ¨èè¿‡ç¨‹ä»¥æé«˜è½¬åŒ–ç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†åé¦ˆé©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ æœºåˆ¶ï¼Œä½¿å¾—ä»£ç†èƒ½å¤Ÿåœ¨å®é™…å¯¹è¯ä¸­ä¸æ–­å­¦ä¹ å’Œè°ƒæ•´ç­–ç•¥ã€‚è¿™ä¸ä¼ ç»Ÿé™æ€æ¨èç³»ç»Ÿçš„æœ¬è´¨åŒºåˆ«åœ¨äºåŠ¨æ€é€‚åº”æ€§å’Œä¸ªæ€§åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†è‡ªé€‚åº”å­¦ä¹ ç‡å’Œå¥–åŠ±æœºåˆ¶ï¼Œä»¥ç¡®ä¿ä»£ç†èƒ½å¤Ÿå¿«é€Ÿé€‚åº”ç”¨æˆ·åé¦ˆã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œç»“åˆäº†ç”¨æˆ·å‚ä¸åº¦å’Œè½¬åŒ–ç‡çš„ç»¼åˆæŒ‡æ ‡ï¼Œä»¥å®ç°å¤šç›®æ ‡ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨è¯¥æ–¹æ³•çš„å¯¹è¯ç³»ç»Ÿåœ¨ç”¨æˆ·å‚ä¸åº¦ä¸Šæå‡äº†30%ï¼Œè½¬åŒ–ç‡æé«˜äº†25%ã€‚ä¸ä¼ ç»Ÿæ¨èç³»ç»Ÿç›¸æ¯”ï¼ŒåŸºäºå¼ºåŒ–å­¦ä¹ çš„ç­–ç•¥ä¼˜åŒ–æ˜¾è‘—å¢å¼ºäº†ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç”µå­å•†åŠ¡ã€å®¢æˆ·æœåŠ¡å’Œåœ¨çº¿å’¨è¯¢ç­‰å¤šä¸ªè¡Œä¸šã€‚é€šè¿‡ä¼˜åŒ–å¯¹è¯ç­–ç•¥ï¼Œä¼ä¸šèƒ½å¤Ÿæä¾›æ›´ä¸ºä¸ªæ€§åŒ–çš„æ¨èæœåŠ¡ï¼Œä»è€Œæå‡å®¢æˆ·ä½“éªŒå’Œé”€å”®ä¸šç»©ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šæ™ºèƒ½ä»£ç†ç³»ç»Ÿä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨è¡Œä¸šæ™ºèƒ½åŒ–è¿›ç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose a reinforcement learning-based approach to optimize conversational strategies for product recommendation across diverse industries. As organizations increasingly adopt intelligent agents to support sales and service operations, the effectiveness of a conversation hinges not only on what is recommended but how and when recommendations are delivered. We explore a methodology where agentic systems learn optimal dialogue policies through feedback-driven reinforcement learning. By mining aggregate behavioral patterns and conversion outcomes, our approach enables agents to refine talk tracks that drive higher engagement and product uptake, while adhering to contextual and regulatory constraints. We outline the conceptual framework, highlight key innovations, and discuss the implications for scalable, personalized recommendation in enterprise environments.

