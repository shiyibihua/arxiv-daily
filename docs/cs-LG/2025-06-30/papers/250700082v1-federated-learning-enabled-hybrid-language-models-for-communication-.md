---
layout: default
title: Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission
---

# Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00082" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00082v1</a>
  <a href="https://arxiv.org/pdf/2507.00082.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00082v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00082v1', 'Federated Learning-Enabled Hybrid Language Models for Communication-Efficient Token Transmission')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Faranaksadat Solat, Joohyung Lee, Mohamed Seif, Dusit Niyato, H. Vincent Poor

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30

**å¤‡æ³¨**: 17 pages, 16 figures, IEEE Internet of Things

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFedHLMä»¥è§£å†³è¾¹ç¼˜è®¾å¤‡é€šä¿¡æ•ˆç‡ä½çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ··åˆè¯­è¨€æ¨¡å‹` `è”é‚¦å­¦ä¹ ` `ä¸ç¡®å®šæ€§æ„ŸçŸ¥` `è¾¹ç¼˜è®¡ç®—` `é€šä¿¡æ•ˆç‡` `ä½å»¶è¿Ÿæ¨ç†` `ä»¤ç‰Œä¼ è¾“` `æ™ºèƒ½åŠ©æ‰‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ··åˆè¯­è¨€æ¨¡å‹åœ¨ä½ç½®ä¿¡åº¦é¢„æµ‹æ—¶é¢‘ç¹å¸è½½åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¯¼è‡´é€šä¿¡å¼€é”€æ˜¾è‘—ï¼Œå°¤å…¶åœ¨å¸¦å®½å—é™çš„ç¯å¢ƒä¸­ã€‚
2. æœ¬æ–‡æå‡ºFedHLMæ¡†æ¶ï¼Œé€šè¿‡è”é‚¦å­¦ä¹ ä¼˜åŒ–ä»¤ç‰Œçº§ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œå‡å°‘ä¸å¿…è¦çš„LLMè°ƒç”¨ï¼Œä»è€Œæé«˜é€šä¿¡æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedHLMåœ¨å¤§è§„æ¨¡æ–°é—»åˆ†ç±»ä»»åŠ¡ä¸­å°†LLMä¼ è¾“å‡å°‘è¶…è¿‡95%ï¼Œä¸”å‡†ç¡®æ€§æŸå¤±æå°ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ··åˆè¯­è¨€æ¨¡å‹ï¼ˆHLMsï¼‰ç»“åˆäº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„ä½å»¶è¿Ÿæ•ˆç‡ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é›†ä¸­å¼æœåŠ¡å™¨ä¸Šçš„é«˜å‡†ç¡®æ€§ã€‚ä¸ä¼ ç»Ÿçš„ç«¯åˆ°ç«¯LLMæ¨ç†ä¸åŒï¼ŒHLMsä»…åœ¨æœ¬åœ°SLMé¢„æµ‹ä¸ç¡®å®šæ—¶è°ƒç”¨LLMï¼Œä»è€Œå‡å°‘å»¶è¿Ÿå’Œé€šä¿¡ã€‚ç„¶è€Œï¼Œæ¨¡ç³Šæˆ–ä½ç½®ä¿¡åº¦çš„é¢„æµ‹ä»éœ€é¢‘ç¹å¸è½½åˆ°LLMï¼Œå¯¼è‡´åœ¨å¸¦å®½å—é™ç¯å¢ƒä¸‹çš„é€šä¿¡å¼€é”€æ˜¾è‘—ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†FedHLMï¼Œä¸€ä¸ªé›†æˆä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¨ç†ä¸è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰çš„é€šä¿¡é«˜æ•ˆHLMæ¡†æ¶ã€‚FedHLMçš„å…³é”®åˆ›æ–°åœ¨äºåä½œå­¦ä¹ å†³å®šä½•æ—¶éœ€è¦LLMååŠ©çš„ä»¤ç‰Œçº§ä¸ç¡®å®šæ€§é˜ˆå€¼ã€‚é€šè¿‡FLä¼˜åŒ–è¿™äº›é˜ˆå€¼ï¼ŒFedHLMåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶å®ç°äº†åˆ†å¸ƒå¼å­¦ä¹ ã€‚æ­¤å¤–ï¼ŒFedHLMåˆ©ç”¨åŸºäºåµŒå…¥çš„ä»¤ç‰Œè¡¨ç¤ºè¿›è¡Œç‚¹å¯¹ç‚¹ï¼ˆP2Pï¼‰è§£æï¼Œä½¿å®¢æˆ·ç«¯èƒ½å¤Ÿé‡ç”¨è¯­ä¹‰ç›¸ä¼¼çš„åŒä¼´æ¨æ–­çš„ä»¤ç‰Œï¼Œè€Œæ— éœ€è°ƒç”¨LLMã€‚å®éªŒè¡¨æ˜ï¼ŒFedHLMåœ¨å¤§è§„æ¨¡æ–°é—»åˆ†ç±»ä»»åŠ¡ä¸­å°†LLMä¼ è¾“å‡å°‘äº†95%ä»¥ä¸Šï¼Œä¸”å‡†ç¡®æ€§æŸå¤±å¾®ä¹å…¶å¾®ï¼Œé€‚åˆå¯æ‰©å±•çš„é«˜æ•ˆè¾¹ç¼˜AIåº”ç”¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ··åˆè¯­è¨€æ¨¡å‹åœ¨ä½ç½®ä¿¡åº¦é¢„æµ‹æ—¶é¢‘ç¹å¸è½½åˆ°å¤§å‹è¯­è¨€æ¨¡å‹æ‰€å¸¦æ¥çš„é€šä¿¡å¼€é”€é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¸¦å®½å—é™çš„ç¯å¢ƒä¸­ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFedHLMæ¡†æ¶é€šè¿‡è”é‚¦å­¦ä¹ ä¼˜åŒ–ä»¤ç‰Œçº§ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œç¡®ä¿ä»…åœ¨å¿…è¦æ—¶è°ƒç”¨LLMï¼Œä»è€Œå‡å°‘é€šä¿¡è´Ÿæ‹…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFedHLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¨ç†æ¨¡å—ã€è”é‚¦å­¦ä¹ æ¨¡å—å’ŒåŸºäºåµŒå…¥çš„ä»¤ç‰Œè¡¨ç¤ºæ¨¡å—ã€‚é€šè¿‡è¿™äº›æ¨¡å—çš„ååŒå·¥ä½œï¼ŒFedHLMèƒ½å¤Ÿé«˜æ•ˆåœ°ç®¡ç†LLMçš„è°ƒç”¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šFedHLMçš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡è”é‚¦å­¦ä¹ åŠ¨æ€ä¼˜åŒ–ä¸ç¡®å®šæ€§é˜ˆå€¼ï¼Œè€Œéä½¿ç”¨é™æ€æˆ–æ‰‹åŠ¨è°ƒèŠ‚çš„é˜ˆå€¼ï¼Œè¿™ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒç¯å¢ƒä¸‹å…·æœ‰æ›´å¥½çš„é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒFedHLMé‡‡ç”¨äº†åŸºäºåµŒå…¥çš„ä»¤ç‰Œè¡¨ç¤ºï¼Œä»¥æ”¯æŒç‚¹å¯¹ç‚¹è§£æï¼ŒåŒæ—¶å¼•å…¥äº†å±‚æ¬¡æ¨¡å‹èšåˆæœºåˆ¶ï¼Œç¡®ä¿è¾¹ç¼˜æœåŠ¡å™¨é€šè¿‡å®¢æˆ·ç«¯æ›´æ–°ä¼˜åŒ–æœ¬åœ°è·¯ç”±ç­–ç•¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFedHLMåœ¨å¤§è§„æ¨¡æ–°é—»åˆ†ç±»ä»»åŠ¡ä¸­å°†LLMçš„ä¼ è¾“é‡å‡å°‘äº†è¶…è¿‡95%ï¼ŒåŒæ—¶ä¿æŒäº†å‡ ä¹æ— æŸçš„å‡†ç¡®æ€§ã€‚è¿™ä¸€æ˜¾è‘—çš„æ€§èƒ½æå‡å±•ç¤ºäº†FedHLMåœ¨è¾¹ç¼˜AIåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FedHLMæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦é«˜æ•ˆé€šä¿¡çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒä¸­ï¼Œå¦‚æ™ºèƒ½æ‰‹æœºã€ç‰©è”ç½‘è®¾å¤‡å’Œè¾¹ç¼˜æœåŠ¡å™¨ç­‰ã€‚å…¶é«˜æ•ˆçš„é€šä¿¡æœºåˆ¶å’Œä½å»¶è¿Ÿç‰¹æ€§ä½¿å…¶é€‚åˆäºå®æ—¶è¯­è¨€å¤„ç†å’Œæ™ºèƒ½åŠ©æ‰‹ç­‰åº”ç”¨åœºæ™¯ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨è¾¹ç¼˜AIæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Hybrid Language Models (HLMs) combine the low-latency efficiency of Small Language Models (SLMs) on edge devices with the high accuracy of Large Language Models (LLMs) on centralized servers. Unlike traditional end-to-end LLM inference, HLMs reduce latency and communication by invoking LLMs only when local SLM predictions are uncertain, i.e., when token-level confidence is low or entropy is high. However, ambiguous or low-confidence predictions still require frequent offloading to the LLM, leading to significant communication overhead in bandwidth-constrained settings. To address this, we propose FedHLM, a communication-efficient HLM framework that integrates uncertainty-aware inference with Federated Learning (FL). FedHLM's key innovation lies in collaboratively learning token-level uncertainty thresholds that govern when LLM assistance is needed. Rather than using static or manually tuned thresholds, FedHLM employs FL to optimize these thresholds in a privacy-preserving, distributed manner. Additionally, it leverages embedding-based token representations for Peer-to-Peer (P2P) resolution, enabling clients to reuse tokens inferred by semantically similar peers without engaging the LLM. We further introduce hierarchical model aggregation: edge servers refine local routing policies through client updates, while cross-cluster coordination aligns global decision boundaries. This layered design captures recurring uncertainty patterns, reducing redundant LLM queries. Experiments on large-scale news classification tasks show that FedHLM reduces LLM transmissions by over 95 percent with negligible accuracy loss, making it well-suited for scalable and efficient edge-AI applications.

