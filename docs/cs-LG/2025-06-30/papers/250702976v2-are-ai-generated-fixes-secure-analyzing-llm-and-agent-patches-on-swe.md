---
layout: default
title: Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench
---

# Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.02976" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.02976v2</a>
  <a href="https://arxiv.org/pdf/2507.02976.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.02976v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.02976v2', 'Are AI-Generated Fixes Secure? Analyzing LLM and Agent Patches on SWE-bench')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amirali Sajadi, Kostadin Damevski, Preetha Chatterjee

**åˆ†ç±»**: cs.CR, cs.LG, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-06-30 (æ›´æ–°: 2025-07-24)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ†æLLMç”Ÿæˆè¡¥ä¸çš„å®‰å…¨æ€§ä»¥åº”å¯¹è½¯ä»¶å¼€å‘ä¸­çš„é£é™©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è½¯ä»¶å®‰å…¨` `ä»£ç ç”Ÿæˆ` `æ¼æ´æ£€æµ‹` `è‡ªåŠ¨åŒ–å¼€å‘` `ä»£ç†æ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨åˆæˆç¯å¢ƒä¸­ï¼Œæœªèƒ½å……åˆ†è¯„ä¼°LLMç”Ÿæˆä»£ç åœ¨çœŸå®å¼€å‘ä¸­çš„å®‰å…¨æ€§ã€‚
2. æœ¬ç ”ç©¶é€šè¿‡åˆ†æ20,000å¤šä¸ªé—®é¢˜ï¼Œé¦–æ¬¡å¯¹LLMç”Ÿæˆçš„è¡¥ä¸è¿›è¡Œå¤§è§„æ¨¡å®‰å…¨åˆ†æï¼Œæ¯”è¾ƒäº†ä¸åŒç”Ÿæˆæ–¹å¼çš„æ¼æ´æƒ…å†µã€‚
3. ç»“æœæ˜¾ç¤ºï¼ŒLLMç”Ÿæˆçš„è¡¥ä¸å¼•å…¥çš„æ¼æ´æ•°é‡æ˜¾è‘—é«˜äºå¼€å‘è€…ï¼Œä¸”ä¸ä»£ç ä¸Šä¸‹æ–‡ç›¸å…³çš„å› ç´ å¯¹å®‰å…¨æ€§æœ‰é‡è¦å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åŠå…¶ä»£ç†æ¡†æ¶åœ¨è½¯ä»¶å¼€å‘ä»»åŠ¡ä¸­çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œå°¤å…¶æ˜¯åœ¨é—®é¢˜è§£å†³å’Œç¨‹åºä¿®å¤æ–¹é¢ï¼Œå®‰å…¨é£é™©é—®é¢˜ä¹Ÿé€æ¸æ˜¾ç°ã€‚å°½ç®¡å·²æœ‰ç ”ç©¶æŒ‡å‡ºLLMç”Ÿæˆä»£ç çš„å®‰å…¨éšæ‚£ï¼Œä½†å¤§å¤šæ•°è¯„ä¼°é›†ä¸­åœ¨åˆæˆæˆ–å­¤ç«‹ç¯å¢ƒä¸­ï¼Œæœªèƒ½å……åˆ†æ¢è®¨å…¶åœ¨çœŸå®å¼€å‘ç¯å¢ƒä¸­çš„å®‰å…¨æ€§ã€‚æœ¬ç ”ç©¶é¦–æ¬¡å¯¹LLMç”Ÿæˆçš„è¡¥ä¸è¿›è¡Œå¤§è§„æ¨¡å®‰å…¨åˆ†æï¼Œä½¿ç”¨äº†æ¥è‡ªSWE-benchæ•°æ®é›†çš„20,000å¤šä¸ªé—®é¢˜ï¼Œè¯„ä¼°äº†ç‹¬ç«‹LLMï¼ˆLlama 3.3ï¼‰ç”Ÿæˆçš„è¡¥ä¸ï¼Œå¹¶ä¸å¼€å‘è€…ç¼–å†™çš„è¡¥ä¸è¿›è¡Œäº†æ¯”è¾ƒã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜è¯„ä¼°äº†ä¸‰ç§é¡¶å°–ä»£ç†æ¡†æ¶ï¼ˆOpenHandsã€AutoCodeRoverã€HoneyCombï¼‰ç”Ÿæˆçš„è¡¥ä¸ã€‚ç ”ç©¶å‘ç°ï¼Œç‹¬ç«‹LLMç”Ÿæˆçš„æ–°æ¼æ´æ•°é‡å‡ ä¹æ˜¯å¼€å‘è€…çš„9å€ï¼Œä¸”è®¸å¤šæ¼æ´å±•ç°å‡ºç‹¬ç‰¹çš„æ¨¡å¼ã€‚ä»£ç†å·¥ä½œæµåœ¨èµ‹äºˆLLMæ›´å¤šè‡ªä¸»æƒæ—¶ä¹Ÿä¼šç”Ÿæˆå¤§é‡æ¼æ´ï¼Œå¢åŠ äº†è¯¯è§£é¡¹ç›®ä¸Šä¸‹æ–‡æˆ–ä»»åŠ¡è¦æ±‚çš„å¯èƒ½æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³LLMç”Ÿæˆè¡¥ä¸åœ¨çœŸå®å¼€å‘ç¯å¢ƒä¸­çš„å®‰å…¨æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºåˆæˆç¯å¢ƒï¼Œæœªèƒ½æ­ç¤ºçœŸå®åœºæ™¯ä¸‹çš„æ½œåœ¨é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¯¹20,000å¤šä¸ªé—®é¢˜çš„åˆ†æï¼Œæ¯”è¾ƒç‹¬ç«‹LLMä¸å¼€å‘è€…ç”Ÿæˆè¡¥ä¸çš„å®‰å…¨æ€§ï¼Œè¯„ä¼°ä¸åŒä»£ç†æ¡†æ¶çš„è¡¨ç°ï¼Œä»¥è¯†åˆ«ç”Ÿæˆä¸å®‰å…¨ä»£ç çš„æ¡ä»¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶åˆ†ä¸ºå‡ ä¸ªä¸»è¦æ¨¡å—ï¼šæ•°æ®æ”¶é›†ï¼ˆSWE-benchæ•°æ®é›†ï¼‰ã€è¡¥ä¸ç”Ÿæˆï¼ˆç‹¬ç«‹LLMä¸ä»£ç†æ¡†æ¶ï¼‰ã€å®‰å…¨æ€§è¯„ä¼°ï¼ˆæ¼æ´æ£€æµ‹ä¸æ¯”è¾ƒåˆ†æï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šé¦–æ¬¡è¿›è¡Œå¤§è§„æ¨¡çš„LLMç”Ÿæˆè¡¥ä¸å®‰å…¨æ€§åˆ†æï¼Œæ­ç¤ºäº†ç‹¬ç«‹LLMä¸å¼€å‘è€…ä¹‹é—´åœ¨æ¼æ´ç”Ÿæˆä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œå¼ºè°ƒäº†ä¸Šä¸‹æ–‡å› ç´ çš„é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­è®¾ç½®äº†å¤šä¸ªè¯„ä¼°æ ‡å‡†ï¼ŒåŒ…æ‹¬ç”Ÿæˆä»£ç çš„è¡Œæ•°ã€æ¶‰åŠæ–‡ä»¶æ•°é‡ï¼Œä»¥åŠGitHubé—®é¢˜çš„å…·ä½“ä¿¡æ¯ç¼ºå¤±æƒ…å†µç­‰ï¼Œä»¥åˆ†æå…¶å¯¹æ¼æ´ç”Ÿæˆçš„å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç‹¬ç«‹LLMç”Ÿæˆçš„è¡¥ä¸å¼•å…¥çš„æ¼æ´æ•°é‡å‡ ä¹æ˜¯å¼€å‘è€…çš„9å€ï¼Œä¸”ä»£ç†æ¡†æ¶åœ¨èµ‹äºˆLLMæ›´å¤šè‡ªä¸»æƒæ—¶ï¼Œæ¼æ´æ•°é‡æ˜¾è‘—å¢åŠ ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†ä¸Šä¸‹æ–‡å› ç´ åœ¨ä»£ç å®‰å…¨æ€§ä¸­çš„å…³é”®ä½œç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„ç»“æœå¯¹è½¯ä»¶å¼€å‘ä¸­çš„è‡ªåŠ¨åŒ–å·¥å…·å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ï¼Œå°¤å…¶æ˜¯åœ¨æå‡ä»£ç å®‰å…¨æ€§å’Œå‡å°‘æ¼æ´æ–¹é¢ã€‚æœªæ¥ï¼Œç ”ç©¶æˆæœå¯ç”¨äºå¼€å‘æ›´å®‰å…¨çš„ä»£ç ç”Ÿæˆå·¥å…·ï¼Œå¹¶ä¸ºè½¯ä»¶å¼€å‘å›¢é˜Ÿæä¾›é£é™©è¯„ä¼°çš„æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) and their agentic frameworks are increasingly adopted to automate software development tasks such as issue resolution and program repair. While prior work has identified security risks in LLM-generated code, most evaluations have focused on synthetic or isolated settings, leaving open questions about the security of these systems in real-world development contexts. In this study, we present the first large-scale security analysis of LLM-generated patches using 20,000+ issues from the SWE-bench dataset. We evaluate patches produced by a standalone LLM (Llama 3.3) and compare them to developer-written patches. We also assess the security of patches generated by three top-performing agentic frameworks (OpenHands, AutoCodeRover, HoneyComb) on a subset of our data. Finally, we analyze a wide range of code, issue, and project-level factors to understand the conditions under which LLMs and agents are most likely to generate insecure code. Our findings reveal that the standalone LLM introduces nearly 9x more new vulnerabilities than developers, with many of these exhibiting unique patterns not found in developers' code. Agentic workflows also generate a significant number of vulnerabilities, particularly when granting LLMs more autonomy, potentially increasing the likelihood of misinterpreting project context or task requirements. We find that vulnerabilities are more likely to occur in LLM patches associated with a higher number of files, more lines of generated code, and GitHub issues that lack specific code snippets or information about the expected code behavior and steps to reproduce. These results suggest that contextual factors play a critical role in the security of the generated code and point toward the need for proactive risk assessment methods that account for both code and issue-level information to complement existing vulnerability detection tools.

