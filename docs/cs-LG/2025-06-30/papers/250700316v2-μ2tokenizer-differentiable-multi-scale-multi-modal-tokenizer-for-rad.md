---
layout: default
title: $Œº^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation
---

# $Œº^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00316" class="toolbar-btn" target="_blank">üìÑ arXiv: 2507.00316v2</a>
  <a href="https://arxiv.org/pdf/2507.00316.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00316v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00316v2', '$Œº^2$Tokenizer: Differentiable Multi-Scale Multi-Modal Tokenizer for Radiology Report Generation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Siyou Li, Pengyao Qin, Huanan Wu, Dong Nie, Arun J. Thirunavukarasu, Juntao Yu, Le Zhang

**ÂàÜÁ±ª**: cs.LG, cs.CL, eess.IV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-30 (Êõ¥Êñ∞: 2025-07-02)

**Â§áÊ≥®**: Accepted by MICCAI 2025

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/Siyou-Li/u2Tokenizer)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫$Œº^2$Tokenizer‰ª•Ëß£ÂÜ≥ÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàê‰∏≠ÁöÑ‰ø°ÊÅØÊèêÂèñ‰∏éËØÑ‰º∞ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàê` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `‰ø°ÊÅØÊèêÂèñ` `Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ` `CTÂΩ±ÂÉèÂàÜÊûê` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàêÊñπÊ≥ïÂú®‰ªéÂΩ±ÂÉèÊï∞ÊçÆ‰∏≠ÊèêÂèñ‰ø°ÊÅØÊó∂Èù¢‰∏¥Â§çÊùÇÊÄßÂíåËµÑÊ∫êÈôêÂà∂ÁöÑÊåëÊàò„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÁöÑ$Œº^2$TokenizerÈÄöËøáÊï¥ÂêàÂ§öÊ®°ÊÄÅÁâπÂæÅÔºå‰ºòÂåñÊä•ÂëäÁîüÊàêËøáÁ®ãÔºåÊèêÂçáÁîüÊàêË¥®Èáè„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå$Œº^2$LLMÂú®ÊúâÈôêÊï∞ÊçÆÊù°‰ª∂‰∏ãÁöÑË°®Áé∞‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®RRG‰ªªÂä°‰∏≠ÁöÑÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Ëá™Âä®ÂåñÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàêÔºàRRGÔºâÊó®Âú®‰ªé‰∏¥Â∫äÂΩ±ÂÉèÔºàÂ¶ÇCTÊâ´ÊèèÔºâ‰∏≠ÁîüÊàêËØ¶ÁªÜÁöÑÊñáÊú¨Êä•ÂëäÔºå‰ª•ÊèêÈ´òËØäÊñ≠ÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéá„ÄÇRRGÈù¢‰∏¥‰∏§‰∏™‰∏ªË¶ÅÊåëÊàòÔºö‰∏ÄÊòØ‰ªéÂΩ±ÂÉèÊï∞ÊçÆ‰∏≠ÊèêÂèñÁõ∏ÂÖ≥‰ø°ÊÅØÁöÑÂ§çÊùÇÊÄßÔºå‰∫åÊòØÂÆ¢ËßÇËØÑ‰º∞Ê®°ÂûãÁîüÊàêÊä•Âëä‰∏é‰∏ìÂÆ∂Êí∞ÂÜôÊä•Âëä‰πãÈó¥Â∑ÆÂºÇÁöÑÂõ∞Èöæ„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü$Œº^2$LLMÔºåÂà©Áî®Â§öÂ∞∫Â∫¶Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊù•Ëß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢ò„ÄÇÊñ∞È¢ñÁöÑ$Œº^2$Tokenizer‰Ωú‰∏∫‰∏≠Èó¥Â±ÇÔºåÊï¥Âêà‰∫ÜÊù•Ëá™Â§öÂ∞∫Â∫¶ËßÜËßâÊ†áËÆ∞Âô®ÂíåÊñáÊú¨Ê†áËÆ∞Âô®ÁöÑÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÈÄöËøáÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâÊèêÂçáÊä•ÂëäÁîüÊàêË¥®Èáè„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Âõõ‰∏™Â§ßÂûãCTÂΩ±ÂÉè-Êä•ÂëäÂåªÂ≠¶Êï∞ÊçÆÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Ëá™Âä®ÂåñÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàê‰∏≠ÁöÑ‰ø°ÊÅØÊèêÂèñÂ§çÊùÇÊÄßÂíåÊ®°ÂûãÁîüÊàêÊä•Âëä‰∏é‰∏ìÂÆ∂Êä•Âëä‰πãÈó¥ËØÑ‰º∞Âõ∞ÈöæÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§öÊ®°ÊÄÅÊï∞ÊçÆÊó∂Â∏∏Â∏∏Êó†Ê≥ïÊúâÊïàÊï¥Âêà‰ø°ÊÅØÔºåÂØºËá¥ÁîüÊàêÊä•ÂëäÁöÑË¥®Èáè‰∏çÈ´ò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫ÁöÑ$Œº^2$TokenizerÈÄöËøáÂ§öÂ∞∫Â∫¶ÂíåÂ§öÊ®°ÊÄÅÁâπÂæÅÁöÑÊï¥ÂêàÔºåÂà©Áî®Áõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñÔºàDPOÔºâÊù•ÊèêÂçáÊä•ÂëäÁîüÊàêÁöÑË¥®Èáè„ÄÇËøôÁßçËÆæËÆ°‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÁîüÊàê‰∏éÂΩ±ÂÉèÊï∞ÊçÆÁõ∏ÂÖ≥ÁöÑÊñáÊú¨‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Â§öÂ∞∫Â∫¶ËßÜËßâÊ†áËÆ∞Âô®ÂíåÊñáÊú¨Ê†áËÆ∞Âô®Ôºå$Œº^2$Tokenizer‰Ωú‰∏∫‰∏≠Èó¥Â±ÇËøõË°åÁâπÂæÅÊï¥ÂêàÔºåÊúÄÂêéÈÄöËøáGREEN-RedLlamaËøõË°å‰ºòÂåñ„ÄÇËØ•ÊñπÊ≥ïËøòÂºïÂÖ•‰∫Ü‰∏Ä‰∏™‰∫îÈò∂ÊÆµÁöÑLLMÈ©±Âä®ÁÆ°ÈÅìÔºåÂ∞ÜÂ∏∏ËßÑCTÊä•ÂëäËΩ¨Âåñ‰∏∫ËßÜËßâ-ÈóÆÁ≠î‰∏âÂÖÉÁªÑÂíåÂºïÁî®ÈìæÊé•ÁöÑÊé®ÁêÜÂèôËø∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫é$Œº^2$TokenizerÁöÑËÆæËÆ°ÔºåÂÆÉÊúâÊïàÊï¥Âêà‰∫ÜÂ§öÊ®°ÊÄÅÁâπÂæÅÔºåÂπ∂ÈÄöËøáDPO‰ºòÂåñÁîüÊàêËøáÁ®ãÔºå‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÊòæËëóÊèêÂçá‰∫ÜÁîüÊàêÊä•ÂëäÁöÑË¥®ÈáèÂíå‰∏ÄËá¥ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞‰ª•‰ºòÂåñÂ§öÊ®°ÊÄÅÁâπÂæÅÁöÑËûçÂêàÔºåÁ°Æ‰øùÁîüÊàêÁöÑÊñáÊú¨‰∏éÂΩ±ÂÉèÊï∞ÊçÆÈ´òÂ∫¶Áõ∏ÂÖ≥„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÁöÑËÆ≠ÁªÉËøáÁ®ã‰∏≠‰ΩøÁî®‰∫ÜÂ§öÁßçÊï∞ÊçÆÈõÜÔºå‰ª•Â¢ûÂº∫ÂÖ∂Ê≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºå$Œº^2$LLMÂú®Âõõ‰∏™Â§ßÂûãCTÂΩ±ÂÉè-Êä•ÂëäÊï∞ÊçÆÈõÜ‰∏äÁöÑË°®Áé∞‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåÂÖ∑‰ΩìÊèêÂçáÂπÖÂ∫¶ËææÂà∞XX%ÔºàÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•ÔºâÔºåÊòæÁ§∫Âá∫ÂÖ∂Âú®ÊúâÈôêÊï∞ÊçÆÊù°‰ª∂‰∏ãÁöÑÂº∫Â§ßÊΩúÂäõ„ÄÇËØ•ÊñπÊ≥ïÁöÑÂàõÊñ∞ËÆæËÆ°‰∏∫ÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàêÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊÄùË∑Ø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®ÂåªÁñóÂΩ±ÂÉèÂàÜÊûêÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÂ∞§ÂÖ∂ÊòØÂú®Ëá™Âä®ÂåñÊîæÂ∞ÑÂ≠¶Êä•ÂëäÁîüÊàê‰∏≠„ÄÇÈÄöËøáÊèêÈ´òÊä•ÂëäÁîüÊàêÁöÑÂáÜÁ°ÆÊÄßÂíåÊïàÁéáÔºåËÉΩÂ§üÂ∏ÆÂä©ÂåªÁîüÊõ¥Âø´Âú∞ÂÅöÂá∫ËØäÊñ≠ÂÜ≥Á≠ñÔºå‰ªéËÄåÊîπÂñÑÊÇ£ËÄÖÁöÑÁÆ°ÁêÜÂíåÊ≤ªÁñóÊïàÊûú„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïËøòÂèØÊâ©Â±ïÂà∞ÂÖ∂‰ªñÂåªÂ≠¶È¢ÜÂüüÁöÑÊä•ÂëäÁîüÊàê‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Automated radiology report generation (RRG) aims to produce detailed textual reports from clinical imaging, such as computed tomography (CT) scans, to improve the accuracy and efficiency of diagnosis and provision of management advice. RRG is complicated by two key challenges: (1) inherent complexity in extracting relevant information from imaging data under resource constraints, and (2) difficulty in objectively evaluating discrepancies between model-generated and expert-written reports. To address these challenges, we propose $Œº^2$LLM, a $\underline{\textbf{mu}}$ltiscale $\underline{\textbf{mu}}$ltimodal large language models for RRG tasks. The novel $Œº^2$Tokenizer, as an intermediate layer, integrates multi-modal features from the multiscale visual tokenizer and the text tokenizer, then enhances report generation quality through direct preference optimization (DPO), guided by GREEN-RedLlama. Experimental results on four large CT image-report medical datasets demonstrate that our method outperforms existing approaches, highlighting the potential of our fine-tuned $Œº^2$LLMs on limited data for RRG tasks. At the same time, for prompt engineering, we introduce a five-stage, LLM-driven pipeline that converts routine CT reports into paired visual-question-answer triples and citation-linked reasoning narratives, creating a scalable, high-quality supervisory corpus for explainable multimodal radiology LLM. All code, datasets, and models will be publicly available in our official repository. https://github.com/Siyou-Li/u2Tokenizer

