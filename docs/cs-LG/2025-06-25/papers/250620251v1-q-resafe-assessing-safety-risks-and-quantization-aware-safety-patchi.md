---
layout: default
title: Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models
---

# Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20251" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20251v1</a>
  <a href="https://arxiv.org/pdf/2506.20251.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20251v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20251v1', 'Q-resafe: Assessing Safety Risks and Quantization-aware Safety Patching for Quantized Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kejia Chen, Jiawen Zhang, Jiacong Hu, Yu Wang, Jian Lou, Zunlei Feng, Mingli Song

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: ICML 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Thecommonirin/Qresafe)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºQ-resafeæ¡†æ¶ä»¥è§£å†³é‡åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨é£é™©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é‡åŒ–æ¨¡å‹` `å®‰å…¨è¯„ä¼°` `å¤§è¯­è¨€æ¨¡å‹` `é‡åŒ–æ„ŸçŸ¥` `å®‰å…¨ä¿®è¡¥` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é‡åŒ–æ–¹æ³•å¯èƒ½ä¼šå‰Šå¼±å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨èƒ½åŠ›ï¼Œç°æœ‰çš„å®‰å…¨è¯„ä¼°æ‰‹æ®µä¸è¶³ä»¥å…¨é¢è¯„ä¼°å…¶å®‰å…¨é£é™©ã€‚
2. æå‡ºQ-resafeæ¡†æ¶ï¼Œé€šè¿‡é‡åŒ–æ„ŸçŸ¥çš„æ–¹å¼ä¿®è¡¥é‡åŒ–LLMsçš„å®‰å…¨æ¼æ´ï¼Œæ—¨åœ¨æ¢å¤å…¶å®‰å…¨èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒQ-resafeèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†é‡åŒ–LLMsçš„å®‰å…¨æ€§æ¢å¤è‡³æ¥è¿‘æœªé‡åŒ–æ¨¡å‹çš„æ°´å¹³ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„å®ç”¨æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é‡åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å› å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„éƒ¨ç½²æ½œåŠ›è€Œå—åˆ°è¶Šæ¥è¶Šå¤šçš„å…³æ³¨ã€‚ç„¶è€Œï¼Œè¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œé‡åŒ–å¯èƒ½ä¼šå‰Šå¼±LLMsçš„å®‰å…¨èƒ½åŠ›ï¼Œè¿«åˆ‡éœ€è¦ç³»ç»Ÿçš„å®‰å…¨è¯„ä¼°å’Œæœ‰æ•ˆçš„ç¼“è§£ç­–ç•¥ã€‚æœ¬æ–‡å¯¹å¤šç§ä¸»æµé‡åŒ–æŠ€æœ¯å’Œä¸åŒçš„æ ¡å‡†æ•°æ®é›†è¿›è¡Œäº†å…¨é¢çš„å®‰å…¨è¯„ä¼°ï¼Œå¹¶åˆ©ç”¨å¹¿æ³›æ¥å—çš„å®‰å…¨åŸºå‡†è¿›è¡Œæµ‹è¯•ã€‚ä¸ºäº†è§£å†³è¯†åˆ«å‡ºçš„å®‰å…¨æ¼æ´ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§é‡åŒ–æ„ŸçŸ¥çš„å®‰å…¨ä¿®è¡¥æ¡†æ¶Q-resafeï¼Œæ—¨åœ¨é«˜æ•ˆæ¢å¤é‡åŒ–LLMsçš„å®‰å…¨èƒ½åŠ›ï¼ŒåŒæ—¶æœ€å°åŒ–å¯¹å®ç”¨æ€§çš„è´Ÿé¢å½±å“ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼ŒQ-resafeèƒ½å¤ŸæˆåŠŸåœ°å°†é‡åŒ–LLMsçš„å®‰å…¨æ€§é‡æ–°è°ƒæ•´è‡³å…¶é‡åŒ–å‰çš„æ°´å¹³ï¼Œå³ä½¿åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„è¯„ä¼°åœºæ™¯ä¸‹ä¹Ÿèƒ½ä¿æŒæ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é‡åŒ–å¤§è¯­è¨€æ¨¡å‹åœ¨å®‰å…¨æ€§æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯„ä¼°é‡åŒ–å¯¹æ¨¡å‹å®‰å…¨èƒ½åŠ›çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºQ-resafeæ¡†æ¶ï¼Œé€šè¿‡é‡åŒ–æ„ŸçŸ¥çš„æ–¹å¼ï¼Œé’ˆå¯¹é‡åŒ–è¿‡ç¨‹ä¸­å¼•å…¥çš„å®‰å…¨æ¼æ´è¿›è¡Œä¿®è¡¥ï¼Œä»¥æ¢å¤æ¨¡å‹çš„å®‰å…¨æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šQ-resafeæ¡†æ¶åŒ…æ‹¬å®‰å…¨è¯„ä¼°æ¨¡å—å’Œå®‰å…¨ä¿®è¡¥æ¨¡å—ã€‚å®‰å…¨è¯„ä¼°æ¨¡å—ä½¿ç”¨æ ‡å‡†å®‰å…¨åŸºå‡†å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œè€Œå®‰å…¨ä¿®è¡¥æ¨¡å—åˆ™æ ¹æ®è¯„ä¼°ç»“æœè¿›è¡Œé’ˆå¯¹æ€§ä¿®è¡¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šQ-resafeçš„åˆ›æ–°åœ¨äºå…¶é‡åŒ–æ„ŸçŸ¥çš„ä¿®è¡¥ç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å¹¶ä¿®å¤é‡åŒ–å¸¦æ¥çš„å®‰å…¨æ¼æ´ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå…·æœ‰æ›´é«˜çš„é’ˆå¯¹æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒQ-resafeé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å®‰å…¨æ€§ä¸æ¨¡å‹å®ç”¨æ€§ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿ä¿®è¡¥è¿‡ç¨‹ä¸ä¼šæ˜¾è‘—å½±å“æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒQ-resafeæˆåŠŸå°†é‡åŒ–LLMsçš„å®‰å…¨æ€§æ¢å¤è‡³æ¥è¿‘æœªé‡åŒ–æ¨¡å‹çš„æ°´å¹³ï¼Œå°¤å…¶åœ¨å¤æ‚è¯„ä¼°åœºæ™¯ä¸‹ï¼Œå®‰å…¨æ€§æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œé‡è¦æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ï¼Œèƒ½å¤Ÿåœ¨ç¡®ä¿å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œæå‡é‡åŒ–å¤§è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼ŒQ-resafeæ¡†æ¶å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šå®‰å…¨æ€§è¯„ä¼°å’Œä¿®è¡¥æŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›é‡åŒ–æ¨¡å‹çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Quantized large language models (LLMs) have gained increasing attention and significance for enabling deployment in resource-constrained environments. However, emerging studies on a few calibration dataset-free quantization methods suggest that quantization may compromise the safety capabilities of LLMs, underscoring the urgent need for systematic safety evaluations and effective mitigation strategies. In this paper, we present comprehensive safety evaluations across various mainstream quantization techniques and diverse calibration datasets, utilizing widely accepted safety benchmarks. To address the identified safety vulnerabilities, we propose a quantization-aware safety patching framework, Q-resafe, to efficiently restore the safety capabilities of quantized LLMs while minimizing any adverse impact on utility. Extensive experimental results demonstrate that Q-resafe successfully re-aligns the safety of quantized LLMs with their pre-quantization counterparts, even under challenging evaluation scenarios. Project page is available at: https://github.com/Thecommonirin/Qresafe.

