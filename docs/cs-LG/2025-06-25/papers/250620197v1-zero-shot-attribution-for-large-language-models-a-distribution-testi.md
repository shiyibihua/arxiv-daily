---
layout: default
title: Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach
---

# Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20197" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20197v1</a>
  <a href="https://arxiv.org/pdf/2506.20197.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20197v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20197v1', 'Zero-Shot Attribution for Large Language Models: A Distribution Testing Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: ClÃ©ment L. Canonne, Yash Pote, Uddalok Sarkar

**åˆ†ç±»**: cs.LG, cs.AI, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

**å¤‡æ³¨**: 16 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé›¶-shotå½’å±å·¥å…·Anubisä»¥è§£å†³ä»£ç å½’å±é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `ä»£ç å½’å±` `å‡è®¾æ£€éªŒ` `åˆ†å¸ƒæµ‹è¯•` `å¯†åº¦ä¼°è®¡` `Anubiså·¥å…·` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨ä»…ä¾èµ–LLMæ ·æœ¬æ—¶ï¼Œå› ç»´åº¦è¯…å’’å¯¼è‡´å½’å±é—®é¢˜éš¾ä»¥å¤„ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºAnubiså·¥å…·ï¼Œå°†å½’å±é—®é¢˜è½¬åŒ–ä¸ºåˆ†å¸ƒæµ‹è¯•ï¼Œç»“åˆæ ·æœ¬å’Œå¯†åº¦ä¼°è®¡è¿›è¡Œåˆ†æã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šAnubisåœ¨åŒºåˆ†ä¸åŒLLMsæ—¶ï¼ŒAUROCå¾—åˆ†è¾¾åˆ°0.9ä»¥ä¸Šï¼Œè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€è¶Šæ¥è¶Šå¤šçš„ä»£ç ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆï¼Œå¦‚ä½•å‡†ç¡®å½’å±è¿™äº›ä»£ç æˆä¸ºä¸€ä¸ªé‡è¦é—®é¢˜ã€‚æœ¬æ–‡é€šè¿‡å‡è®¾æ£€éªŒçš„æ–¹æ³•ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å½’å±å·¥å…·Anubisï¼Œå°†å½’å±é—®é¢˜è§†ä¸ºåˆ†å¸ƒæµ‹è¯•é—®é¢˜ã€‚è¯¥æ–¹æ³•ç»“åˆäº†æ ·æœ¬å’ŒLLMçš„å¯†åº¦ä¼°è®¡ï¼Œå…‹æœäº†ç»´åº¦è¯…å’’çš„æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAnubisåœ¨åŒºåˆ†ä¸åŒLLMsï¼ˆå¦‚DeepSeek-Coderã€CodeGemmaå’ŒStable-Codeï¼‰æ—¶ï¼ŒAUROCå¾—åˆ†é«˜è¾¾0.9ä»¥ä¸Šï¼Œä»…ä½¿ç”¨çº¦2000ä¸ªæ ·æœ¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¦‚ä½•å‡†ç¡®å½’å±ç”±å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„ä»£ç çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ä»…ä¾èµ–LLMæ ·æœ¬æ—¶ï¼Œç”±äºç»´åº¦è¯…å’’ï¼Œå¯¼è‡´å½’å±é—®é¢˜éš¾ä»¥å¤„ç†ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°æ ·æœ¬æ¥æºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„Anubiså·¥å…·é€šè¿‡å°†å½’å±é—®é¢˜è§†ä¸ºåˆ†å¸ƒæµ‹è¯•ï¼Œåˆ©ç”¨æ ·æœ¬å’ŒLLMçš„å¯†åº¦ä¼°è®¡æ¥è¯„ä¼°æ ·æœ¬çš„æ¥æºã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¯ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼Œå…‹æœç»´åº¦è¯…å’’çš„é™åˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAnubisçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ ·æœ¬æ”¶é›†ã€å¯†åº¦ä¼°è®¡å’Œåˆ†å¸ƒæµ‹è¯•ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å¾…æµ‹è¯•çš„ä»£ç æ ·æœ¬ï¼Œç„¶ååˆ©ç”¨LLMç”Ÿæˆçš„å¯†åº¦ä¼°è®¡æ¥è¿›è¡Œåˆ†å¸ƒæ¯”è¾ƒï¼Œæœ€åé€šè¿‡å‡è®¾æ£€éªŒè¯„ä¼°æ ·æœ¬çš„å½’å±ã€‚

**å…³é”®åˆ›æ–°**ï¼šAnubisçš„æœ€å¤§åˆ›æ–°åœ¨äºå°†å½’å±é—®é¢˜è½¬åŒ–ä¸ºåˆ†å¸ƒæµ‹è¯•ï¼Œç»“åˆäº†æ ·æœ¬å’Œå¯†åº¦ä¼°è®¡çš„ä½¿ç”¨ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å½’å±æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿåœ¨æ ·æœ¬ç¨€ç¼ºçš„æƒ…å†µä¸‹ä»ç„¶æä¾›é«˜æ•ˆçš„å½’å±èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Anubisä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ ·æœ¬æ•°é‡å’Œå¯†åº¦ä¼°è®¡çš„ç²¾åº¦ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å‡è®¾æ£€éªŒæ–¹æ³•ï¼Œä»¥æé«˜å½’å±çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Anubisåœ¨å®éªŒä¸­è¡¨ç°å‡ºè‰²ï¼ŒAUROCå¾—åˆ†è¾¾åˆ°0.9ä»¥ä¸Šï¼Œä»…ä½¿ç”¨çº¦2000ä¸ªæ ·æœ¬ï¼ŒæˆåŠŸåŒºåˆ†ä¸åŒçš„LLMsï¼Œå¦‚DeepSeek-Coderã€CodeGemmaå’ŒStable-Codeã€‚è¿™ä¸€ç»“æœæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨ä»£ç å½’å±ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä»£ç å®¡è®¡ã€è½¯ä»¶å®‰å…¨å’ŒçŸ¥è¯†äº§æƒä¿æŠ¤ç­‰ã€‚é€šè¿‡å‡†ç¡®å½’å±ä»£ç ç”Ÿæˆæºï¼Œå¼€å‘è€…å’Œä¼ä¸šå¯ä»¥æ›´å¥½åœ°ç®¡ç†å’Œè¿½è¸ªä»£ç çš„æ¥æºï¼Œé˜²æ­¢æ½œåœ¨çš„ä¾µæƒé—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯ä¹Ÿå¯ç”¨äºæå‡ä»£ç ç”Ÿæˆæ¨¡å‹çš„é€æ˜åº¦å’Œå¯è§£é‡Šæ€§ï¼Œä¿ƒè¿›å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„ä¿¡ä»»åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A growing fraction of all code is sampled from Large Language Models (LLMs). We investigate the problem of attributing code generated by language models using hypothesis testing to leverage established techniques and guarantees. Given a set of samples $S$ and a suspect model $\mathcal{L}^*$, our goal is to assess the likelihood of $S$ originating from $\mathcal{L}^*$. Due to the curse of dimensionality, this is intractable when only samples from the LLM are given: to circumvent this, we use both samples and density estimates from the LLM, a form of access commonly available.
>   We introduce $\mathsf{Anubis}$, a zero-shot attribution tool that frames attribution as a distribution testing problem. Our experiments on a benchmark of code samples show that $\mathsf{Anubis}$ achieves high AUROC scores ( $\ge0.9$) when distinguishing between LLMs like DeepSeek-Coder, CodeGemma, and Stable-Code using only $\approx 2000$ samples.

