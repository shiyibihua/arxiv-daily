---
layout: default
title: DipSVD: Dual-importance Protected SVD for Efficient LLM Compression
---

# DipSVD: Dual-importance Protected SVD for Efficient LLM Compression

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20353" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20353v1</a>
  <a href="https://arxiv.org/pdf/2506.20353.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20353v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20353v1', 'DipSVD: Dual-importance Protected SVD for Efficient LLM Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xuan Ding, Rui Sun, Yunjian Zhang, Xiu Yan, Yueqi Zhou, Kaihao Huang, Suzhong Fu, Chuanlong Xie, Yao Zhu

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDipSVDä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å‹ç¼©æ€§èƒ½ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ¨¡å‹å‹ç¼©` `å¥‡å¼‚å€¼åˆ†è§£` `æ·±åº¦å­¦ä¹ ` `æ€§èƒ½ä¼˜åŒ–` `é€šé“åŠ æƒ` `æ•°æ®ç™½åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„SVDå‹ç¼©æ–¹æ³•ä¸»è¦å…³æ³¨åŸå§‹çŸ©é˜µä¸å‹ç¼©çŸ©é˜µä¹‹é—´çš„æ•´ä½“å·®å¼‚ï¼Œå¿½è§†äº†å…³é”®æˆåˆ†çš„ä¿æŠ¤ï¼Œå¯¼è‡´å‹ç¼©åæ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºåŒé‡é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ï¼Œå±€éƒ¨ä¿æŠ¤å…³é”®å¥‡å¼‚å‘é‡ï¼Œå…¨å±€ä¼˜åŒ–ä¸é‡è¦å±‚çš„å‹ç¼©è´Ÿæ‹…ï¼Œä»è€Œæå‡å‹ç¼©æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDipSVDåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¶…è¶Šäº†ç°æœ‰SVDå‹ç¼©æ–¹æ³•ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è®¡ç®—éœ€æ±‚å’Œéƒ¨ç½²æˆæœ¬çš„ä¸æ–­å¢åŠ ï¼Œå‹ç¼©æ–¹æ³•çš„ç ”ç©¶æ„ˆå‘é‡è¦ã€‚ç›¸æ¯”äºé‡åŒ–å’Œéç»“æ„åŒ–å‰ªæï¼ŒåŸºäºå¥‡å¼‚å€¼åˆ†è§£ï¼ˆSVDï¼‰çš„å‹ç¼©æ–¹æ³•åœ¨ç¡¬ä»¶å…¼å®¹æ€§å’Œç†è®ºä¿è¯æ–¹é¢è¡¨ç°æ›´ä½³ã€‚ç„¶è€Œï¼Œç°æœ‰SVDæ–¹æ³•å¾€å¾€å¿½è§†äº†çŸ©é˜µä¸­å…³é”®æˆåˆ†çš„ä¿æŠ¤ï¼Œå¯¼è‡´å‹ç¼©æ¨¡å‹æ€§èƒ½ä¸‹é™ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŒé‡é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ï¼Œä»¥å¢å¼ºåŸºäºSVDçš„å‹ç¼©æ–¹æ³•ï¼šå±€éƒ¨é‡è¦æ€§ä¿æŠ¤é€šè¿‡é€šé“åŠ æƒæ•°æ®ç™½åŒ–æ¥ä¿ç•™æ¯ä¸ªæƒé‡çŸ©é˜µä¸­æœ€å…³é”®çš„å¥‡å¼‚å‘é‡ï¼›å…¨å±€é‡è¦æ€§ä¿æŠ¤åˆ™é€šè¿‡å¯å‘å¼æˆ–åŸºäºä¼˜åŒ–çš„æ–¹æ³•ä½¿ä¸é‡è¦çš„å±‚æ‰¿æ‹…æ›´å¤§çš„å‹ç¼©è´Ÿæ‹…ï¼Œä»è€Œæœ€å°åŒ–å¯¹å…³é”®å±‚çš„å½±å“ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDipSVDåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ä¼˜äºç°æœ‰çš„SVDå‹ç¼©æ–¹æ³•ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”ä¸‹è¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰SVDå‹ç¼©æ–¹æ³•åœ¨ä¿æŠ¤å…³é”®æˆåˆ†æ–¹é¢çš„ä¸è¶³ï¼Œå¯¼è‡´å‹ç¼©åæ¨¡å‹æ€§èƒ½ä¸‹é™çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŒé‡é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ï¼Œå±€éƒ¨ä¿æŠ¤å…³é”®å¥‡å¼‚å‘é‡ï¼Œå…¨å±€ä¼˜åŒ–ä¸é‡è¦å±‚çš„å‹ç¼©è´Ÿæ‹…ï¼Œä»¥æå‡å‹ç¼©æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå±€éƒ¨é‡è¦æ€§ä¿æŠ¤æ¨¡å—å’Œå…¨å±€é‡è¦æ€§ä¿æŠ¤æ¨¡å—ã€‚å±€éƒ¨æ¨¡å—é€šè¿‡é€šé“åŠ æƒæ•°æ®ç™½åŒ–æ¥ä¿ç•™å…³é”®å¥‡å¼‚å‘é‡ï¼Œå…¨å±€æ¨¡å—åˆ™é€šè¿‡å¯å‘å¼æˆ–ä¼˜åŒ–æ–¹æ³•è°ƒæ•´å‹ç¼©ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†åŒé‡é‡è¦æ€§ä¿æŠ¤æœºåˆ¶ï¼ŒåŒºåˆ«äºç°æœ‰æ–¹æ³•ä»…å…³æ³¨æ•´ä½“å·®å¼‚ï¼Œç¡®ä¿å…³é”®æˆåˆ†åœ¨å‹ç¼©è¿‡ç¨‹ä¸­çš„ä¿æŠ¤ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬é€šé“åŠ æƒæ•°æ®ç™½åŒ–çš„å…·ä½“å®ç°ã€é‡è¦æ€§å±‚çš„é€‰æ‹©æ ‡å‡†ï¼Œä»¥åŠå‹ç¼©è´Ÿæ‹…åˆ†é…çš„å¯å‘å¼æˆ–ä¼˜åŒ–ç­–ç•¥ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ä¹Ÿå¯¹æœ€ç»ˆæ•ˆæœæœ‰æ˜¾è‘—å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDipSVDåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨é«˜å‹ç¼©æ¯”æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æå‡æ˜¾è‘—ï¼Œè¶…è¶Šäº†ç°æœ‰çš„SVDå‹ç¼©æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®éœ€æ ¹æ®å®éªŒç»“æœè¡¥å……ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

DipSVDçš„ç ”ç©¶æˆæœåœ¨å¤§è¯­è¨€æ¨¡å‹çš„å‹ç¼©å’Œéƒ¨ç½²ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œå¦‚ç§»åŠ¨è®¾å¤‡å’Œè¾¹ç¼˜è®¡ç®—ã€‚é€šè¿‡æœ‰æ•ˆçš„æ¨¡å‹å‹ç¼©ï¼Œèƒ½å¤Ÿé™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜æ¨¡å‹çš„å“åº”é€Ÿåº¦å’Œå¯ç”¨æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½åº”ç”¨çš„æ™®åŠå’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The ever-increasing computational demands and deployment costs of large language models (LLMs) have spurred numerous compressing methods. Compared to quantization and unstructured pruning, SVD compression offers superior hardware compatibility and theoretical guarantees. However, existing SVD-based methods focus on the overall discrepancy between the original and compressed matrices while overlooking the protection of critical components within the matrix, which leads to inferior performance in the compressed models. This paper proposes a dual-level importance protection mechanism to enhance SVD-based compression methods: (1) local importance protection: preserving the most critical singular vectors within each weight matrix through channel-weighted data whitening; and (2) global importance protection: enabling less important layers to bear a greater portion of the compression burden through either a heuristic or optimization-based approach, thereby minimizing the impact of compression on critical layers. Extensive experiments demonstrate that DipSVD outperforms existing SVD-based compression approaches across multiple benchmarks, achieving superior model performance especially at high model compression ratios.

