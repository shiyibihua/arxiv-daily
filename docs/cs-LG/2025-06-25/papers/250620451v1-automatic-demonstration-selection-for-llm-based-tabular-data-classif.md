---
layout: default
title: Automatic Demonstration Selection for LLM-based Tabular Data Classification
---

# Automatic Demonstration Selection for LLM-based Tabular Data Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20451" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20451v1</a>
  <a href="https://arxiv.org/pdf/2506.20451.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20451v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20451v1', 'Automatic Demonstration Selection for LLM-based Tabular Data Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuchu Han, Wolfgang Bruckner

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåŠ¨æ¼”ç¤ºé€‰æ‹©ç®—æ³•ä»¥ä¼˜åŒ–è¡¨æ ¼æ•°æ®åˆ†ç±»**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸Šä¸‹æ–‡å­¦ä¹ ` `è¡¨æ ¼æ•°æ®åˆ†ç±»` `è‡ªåŠ¨é€‰æ‹©` `è°±å›¾ç†è®º` `ç›¸ä¼¼æ€§åº¦é‡` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®é¢„å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•åœ¨ç¡®å®šè¡¨æ ¼æ•°æ®åˆ†ç±»ä¸­æ¼”ç¤ºæ•°é‡æ—¶ç¼ºä¹æœ‰æ•ˆçš„è‡ªåŠ¨åŒ–é€‰æ‹©æœºåˆ¶ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºçš„ç®—æ³•ç»“åˆæ•°æ®åˆ†å¸ƒã€ç”¨æˆ·æç¤ºæ¨¡æ¿å’ŒLLMï¼Œåˆ©ç”¨è°±å›¾ç†è®ºè¿›è¡Œæ¼”ç¤ºé€‰æ‹©ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šé€šè¿‡å®éªŒéªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§æ•°æ®é›†ä¸Šä¼˜äºä¼ ç»Ÿéšæœºé€‰æ‹©ç®—æ³•ï¼Œæå‡äº†åˆ†ç±»æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨åº”ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ ï¼ˆICLï¼‰è¿›è¡Œè¡¨æ ¼æ•°æ®åˆ†ç±»æ—¶ï¼Œå¦‚ä½•ç¡®å®šæç¤ºä¸­çš„ç†æƒ³æ¼”ç¤ºæ•°é‡æ˜¯ä¸€ä¸ªåŸºæœ¬é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç®—æ³•ï¼Œè‡ªåŠ¨é€‰æ‹©æ‰€éœ€æ¼”ç¤ºçš„åˆç†æ•°é‡ã€‚è¯¥æ–¹æ³•é€šè¿‡æ•´åˆè¡¨æ ¼æ•°æ®çš„åˆ†å¸ƒã€ç”¨æˆ·é€‰æ‹©çš„æç¤ºæ¨¡æ¿ä»¥åŠç‰¹å®šçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¥è¿›è¡Œä¼°ç®—ã€‚åŸºäºè°±å›¾ç†è®ºï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ç§æ–°é¢–çš„åº¦é‡æ ‡å‡†æ¥é‡åŒ–ä¸åŒæ¼”ç¤ºä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶æ„å»ºç›¸ä¼¼æ€§å›¾ï¼Œåˆ†æå…¶æ‹‰æ™®æ‹‰æ–¯ç‰¹å¾å€¼ï¼Œä»¥æ¨å¯¼å‡ºèƒ½å¤Ÿåœ¨LLMå†…åœ¨è¡¨ç¤ºç©ºé—´ä¸­è¡¨ç¤ºæ•°æ®çš„æœ€å°æ¼”ç¤ºæ•°é‡ã€‚é€šè¿‡ä¸ä¼ ç»Ÿéšæœºé€‰æ‹©ç®—æ³•åœ¨å¤šç§æ•°æ®é›†å’ŒLLMä¸Šçš„å®éªŒæ¯”è¾ƒï¼ŒéªŒè¯äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨è¡¨æ ¼æ•°æ®åˆ†ç±»ä¸­å¦‚ä½•è‡ªåŠ¨é€‰æ‹©åˆé€‚æ•°é‡çš„æ¼”ç¤ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºéšæœºé€‰æ‹©ï¼Œç¼ºä¹é’ˆå¯¹æ€§ï¼Œå¯¼è‡´åˆ†ç±»æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç»“åˆè¡¨æ ¼æ•°æ®çš„åˆ†å¸ƒç‰¹å¾ã€ç”¨æˆ·çš„æç¤ºæ¨¡æ¿å’Œç‰¹å®šçš„LLMï¼Œåˆ©ç”¨è°±å›¾ç†è®ºæ¥é‡åŒ–æ¼”ç¤ºä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„æ¼”ç¤ºé€‰æ‹©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç›¸ä¼¼æ€§åº¦é‡ã€ç›¸ä¼¼æ€§å›¾æ„å»ºå’Œç‰¹å¾å€¼åˆ†æå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åè®¡ç®—æ¼”ç¤ºä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œæ„å»ºç›¸ä¼¼æ€§å›¾ï¼Œæœ€ååˆ†ææ‹‰æ™®æ‹‰æ–¯çŸ©é˜µçš„ç‰¹å¾å€¼ä»¥ç¡®å®šæœ€ä¼˜æ¼”ç¤ºæ•°é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†ä¸€ç§æ–°é¢–çš„ç›¸ä¼¼æ€§åº¦é‡æ ‡å‡†ï¼Œå¹¶åŸºäºè°±å›¾ç†è®ºæ„å»ºç›¸ä¼¼æ€§å›¾ï¼Œè¿™ä¸ç°æœ‰çš„éšæœºé€‰æ‹©æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°åæ˜ æ•°æ®ç‰¹å¾ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œç®—æ³•è€ƒè™‘äº†ç”¨æˆ·é€‰æ‹©çš„æç¤ºæ¨¡æ¿å’ŒLLMçš„ç‰¹æ€§ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºæœ€å°åŒ–æ¼”ç¤ºé€‰æ‹©çš„è¯¯å·®ï¼Œç¡®ä¿æ‰€é€‰æ¼”ç¤ºèƒ½å¤Ÿæœ‰æ•ˆä»£è¡¨æ•°æ®çš„å†…åœ¨ç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„è‡ªåŠ¨æ¼”ç¤ºé€‰æ‹©ç®—æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„éšæœºé€‰æ‹©ç®—æ³•ï¼Œåˆ†ç±»å‡†ç¡®ç‡æå‡å¹…åº¦è¾¾åˆ°10%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èæ•°æ®åˆ†æã€åŒ»ç–—æ•°æ®åˆ†ç±»å’Œå¸‚åœºç ”ç©¶ç­‰å¤šä¸ªé¢†åŸŸã€‚é€šè¿‡ä¼˜åŒ–æ¼”ç¤ºé€‰æ‹©ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜æ¨¡å‹åœ¨è¡¨æ ¼æ•°æ®åˆ†ç±»ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æ•°æ®åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¿›ä¸€æ­¥æå‡æ™ºèƒ½ç³»ç»Ÿçš„å†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A fundamental question in applying In-Context Learning (ICL) for tabular data classification is how to determine the ideal number of demonstrations in the prompt. This work addresses this challenge by presenting an algorithm to automatically select a reasonable number of required demonstrations. Our method distinguishes itself by integrating not only the tabular data's distribution but also the user's selected prompt template and the specific Large Language Model (LLM) into its estimation. Rooted in Spectral Graph Theory, our proposed algorithm defines a novel metric to quantify the similarities between different demonstrations. We then construct a similarity graph and analyze the eigenvalues of its Laplacian to derive the minimum number of demonstrations capable of representing the data within the LLM's intrinsic representation space. We validate the efficacy of our approach through experiments comparing its performance against conventional random selection algorithms on diverse datasets and LLMs.

