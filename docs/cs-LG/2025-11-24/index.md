---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-11-24
---

# cs.LGï¼ˆ2025-11-24ï¼‰

ğŸ“Š å…± **4** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/251119165v1-first-order-sobolev-reinforcement-learning.html">First-order Sobolev Reinforcement Learning</a></td>
  <td>æå‡ºä¸€é˜¶Sobolevå¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡æ¢¯åº¦ä¸€è‡´æ€§åŠ é€Ÿcriticæ”¶æ•›å¹¶ç¨³å®šç­–ç•¥æ¢¯åº¦ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19165v1" onclick="toggleFavorite(this, '2511.19165v1', 'First-order Sobolev Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/251119584v2-learning-massively-multitask-world-models-for-continuous-control.html">Learning Massively Multitask World Models for Continuous Control</a></td>
  <td>æå‡ºNewtï¼šä¸€ç§å¤§è§„æ¨¡å¤šä»»åŠ¡ä¸–ç•Œæ¨¡å‹ï¼Œç”¨äºè¿ç»­æ§åˆ¶ä»»åŠ¡</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19584v2" onclick="toggleFavorite(this, '2511.19584v2', 'Learning Massively Multitask World Models for Continuous Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/251119355v1-leveraging-llms-for-reward-function-design-in-reinforcement-learning.html">Leveraging LLMs for reward function design in reinforcement learning control tasks</a></td>
  <td>æå‡ºLEARN-Optï¼Œåˆ©ç”¨LLMè‡ªä¸»è®¾è®¡å¼ºåŒ–å­¦ä¹ æ§åˆ¶ä»»åŠ¡çš„å¥–åŠ±å‡½æ•°ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.19355v1" onclick="toggleFavorite(this, '2511.19355v1', 'Leveraging LLMs for reward function design in reinforcement learning control tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/251118960v2-ava-vla-improving-vision-language-action-models-with-active-visual-a.html">AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention</a></td>
  <td>AVA-VLAï¼šé€šè¿‡ä¸»åŠ¨è§†è§‰æ³¨æ„åŠ›æå‡è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹åœ¨å…·èº«æ™ºèƒ½ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚</td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2511.18960v2" onclick="toggleFavorite(this, '2511.18960v2', 'AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)