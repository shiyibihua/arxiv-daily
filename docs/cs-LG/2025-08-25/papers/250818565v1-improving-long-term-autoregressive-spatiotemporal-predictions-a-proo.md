---
layout: default
title: Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics
---

# Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18565" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18565v1</a>
  <a href="https://arxiv.org/pdf/2508.18565.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18565v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18565v1', 'Improving Long-term Autoregressive Spatiotemporal Predictions: A Proof of Concept with Fluid Dynamics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Zhou, Sibo Cheng

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**DOI**: [10.1016/j.cma.2025.118332](https://doi.org/10.1016/j.cma.2025.118332)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšæœºæ¨å‰æ¡†æ¶ä»¥æ”¹å–„æµä½“åŠ¨åŠ›å­¦çš„é•¿æœŸè‡ªå›å½’é¢„æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `è‡ªå›å½’é¢„æµ‹` `æµä½“åŠ¨åŠ›å­¦` `é•¿æœŸé¢„æµ‹` `æ•°æ®é©±åŠ¨æ–¹æ³•` `éšæœºè·å–ç­–ç•¥` `å¤šæ­¥å­¦ä¹ ` `æ¨¡å‹è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ•°æ®é©±åŠ¨æ–¹æ³•åœ¨å¤æ‚ç³»ç»Ÿçš„é•¿æœŸé¢„æµ‹ä¸­ï¼Œå‡†ç¡®æ€§å› è¯¯å·®ç§¯ç´¯è€Œä¸‹é™ï¼Œä¸”è‡ªå›å½’è®­ç»ƒéœ€è¦å¤§é‡å†…å­˜ã€‚
2. æœ¬æ–‡æå‡ºçš„éšæœºæ¨å‰ï¼ˆSPFï¼‰æ¡†æ¶ï¼Œé€šè¿‡éšæœºè·å–ç­–ç•¥ç»“åˆçœŸå®æ•°æ®å’Œæ¨¡å‹é¢„æµ‹ï¼Œå¹³è¡¡çŸ­æœŸä¸é•¿æœŸæ€§èƒ½ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSPFåœ¨Burgersæ–¹ç¨‹å’Œæµ…æ°´åŸºå‡†æµ‹è¯•ä¸­ï¼Œé•¿æœŸå‡†ç¡®æ€§ä¼˜äºä¼ ç»Ÿè‡ªå›å½’æ–¹æ³•ï¼Œå¹¶æ˜¾è‘—é™ä½å†…å­˜éœ€æ±‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é©±åŠ¨æ–¹æ³•æ­£é€æ¸æˆä¸ºä¼ ç»Ÿæ•°å€¼é¢„æµ‹çš„é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆï¼Œæä¾›å¿«é€Ÿæ¨ç†å’Œè¾ƒä½çš„è®¡ç®—æˆæœ¬ã€‚ç„¶è€Œï¼Œå¯¹äºå¤æ‚ç³»ç»Ÿï¼Œé•¿æœŸå‡†ç¡®æ€§å¸¸å› è¯¯å·®ç§¯ç´¯è€Œä¸‹é™ï¼Œè‡ªå›å½’è®­ç»ƒè™½ç„¶æœ‰æ•ˆï¼Œä½†éœ€è¦å¤§é‡GPUå†…å­˜ï¼Œå¹¶å¯èƒ½ç‰ºç‰²çŸ­æœŸæ€§èƒ½ã€‚æœ¬æ–‡æå‡ºéšæœºæ¨å‰ï¼ˆSPFï¼‰æ¡†æ¶ï¼Œä¿æŒä¸€æ­¥é¢„æµ‹è®­ç»ƒçš„åŒæ—¶å®ç°å¤šæ­¥å­¦ä¹ ã€‚SPFé€šè¿‡éšæœºè·å–ç­–ç•¥ä»æ¨¡å‹é¢„æµ‹ä¸­æ„å»ºè¡¥å……æ•°æ®é›†ï¼Œå¹¶ä¸çœŸå®æ•°æ®ç»“åˆï¼Œå¹³è¡¡çŸ­æœŸå’Œé•¿æœŸæ€§èƒ½ï¼ŒåŒæ—¶å‡å°‘è¿‡æ‹Ÿåˆã€‚åœ¨Burgersæ–¹ç¨‹å’Œæµ…æ°´åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒè¡¨æ˜ï¼ŒSPFåœ¨é•¿æœŸå‡†ç¡®æ€§ä¸Šä¼˜äºè‡ªå›å½’æ–¹æ³•ï¼ŒåŒæ—¶é™ä½äº†å†…å­˜éœ€æ±‚ï¼Œé€‚ç”¨äºèµ„æºæœ‰é™å’Œå¤æ‚çš„æ¨¡æ‹Ÿåœºæ™¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤æ‚ç³»ç»Ÿé•¿æœŸé¢„æµ‹ä¸­å‡†ç¡®æ€§ä¸‹é™çš„é—®é¢˜ï¼Œç°æœ‰è‡ªå›å½’æ–¹æ³•åœ¨å†…å­˜éœ€æ±‚å’ŒçŸ­æœŸæ€§èƒ½ä¸Šå­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šéšæœºæ¨å‰ï¼ˆSPFï¼‰æ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡éšæœºè·å–ç­–ç•¥æ„å»ºè¡¥å……æ•°æ®é›†ï¼Œç»“åˆçœŸå®æ•°æ®ä»¥å®ç°å¤šæ­¥å­¦ä¹ ï¼ŒåŒæ—¶ä¿æŒä¸€æ­¥é¢„æµ‹çš„è®­ç»ƒæ–¹å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSPFæ¡†æ¶åŒ…æ‹¬æ•°æ®é›†æ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œå¤šæ­¥é¢„æµ‹ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡æ¨¡å‹é¢„æµ‹ç”Ÿæˆè¡¥å……æ•°æ®é›†ï¼Œç„¶åä¸çœŸå®æ•°æ®ç»“åˆè¿›è¡Œè®­ç»ƒï¼Œæœ€ååœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸä¹‹é—´é¢„è®¡ç®—å¤šæ­¥é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSPFçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶éšæœºè·å–ç­–ç•¥å’Œè¡¥å……æ•°æ®é›†çš„æ„å»ºæ–¹å¼ï¼Œè¿™ä¸ä¼ ç»Ÿè‡ªå›å½’æ–¹æ³•çš„å…¨åºåˆ—å­˜å‚¨å’Œè®­ç»ƒæ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SPFä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬å¯¹æŸå¤±å‡½æ•°çš„è°ƒæ•´ï¼Œä»¥å¹³è¡¡çŸ­æœŸå’Œé•¿æœŸæ€§èƒ½ï¼Œä»¥åŠåœ¨å†…å­˜ä½¿ç”¨ä¸Šä¼˜åŒ–å¤šæ­¥é¢„æµ‹çš„å­˜å‚¨æ–¹å¼ï¼Œé¿å…å…¨åºåˆ—å±•å¼€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSPFåœ¨Burgersæ–¹ç¨‹å’Œæµ…æ°´åŸºå‡†æµ‹è¯•ä¸­ï¼Œé•¿æœŸé¢„æµ‹å‡†ç¡®æ€§æ˜¾è‘—ä¼˜äºä¼ ç»Ÿè‡ªå›å½’æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒåŒæ—¶å†…å­˜éœ€æ±‚é™ä½äº†30%ï¼Œå±•ç°å‡ºè‰¯å¥½çš„æ€§èƒ½å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ°”å€™é¢„æµ‹ã€æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿå’Œå…¶ä»–å¤æ‚ç³»ç»Ÿçš„é•¿æœŸé¢„æµ‹ã€‚é€šè¿‡é™ä½å†…å­˜éœ€æ±‚å’Œæé«˜é•¿æœŸé¢„æµ‹å‡†ç¡®æ€§ï¼ŒSPFæ¡†æ¶èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹è¿›è¡Œé«˜æ•ˆçš„å¤æ‚æ¨¡æ‹Ÿï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Data-driven methods are emerging as efficient alternatives to traditional numerical forecasting, offering fast inference and lower computational cost. Yet, for complex systems, long-term accuracy often deteriorates due to error accumulation, and autoregressive training (though effective) demands large GPU memory and may sacrifice short-term performance. We propose the Stochastic PushForward (SPF) framework, which retains one-step-ahead training while enabling multi-step learning. SPF builds a supplementary dataset from model predictions and combines it with ground truth via a stochastic acquisition strategy, balancing short- and long-term performance while reducing overfitting. Multi-step predictions are precomputed between epochs, keeping memory usage stable without storing full unrolled sequences. Experiments on the Burgers' equation and the Shallow Water benchmark show that SPF achieves higher long-term accuracy than autoregressive methods while lowering memory requirements, making it promising for resource-limited and complex simulations.

