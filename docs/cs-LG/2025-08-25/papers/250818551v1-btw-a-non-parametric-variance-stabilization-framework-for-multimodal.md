---
layout: default
title: BTW: A Non-Parametric Variance Stabilization Framework for Multimodal Model Integration
---

# BTW: A Non-Parametric Variance Stabilization Framework for Multimodal Model Integration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18551" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18551v1</a>
  <a href="https://arxiv.org/pdf/2508.18551.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18551v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18551v1', 'BTW: A Non-Parametric Variance Stabilization Framework for Multimodal Model Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jun Hou, Le Wang, Xuan Wang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**æœŸåˆŠ**: The 2025 Conference on Empirical Methods in Natural Language Processing

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBTWæ¡†æ¶ä»¥è§£å†³å¤šæ¨¡æ€æ¨¡å‹é›†æˆä¸­çš„å™ªå£°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ··åˆä¸“å®¶æ¨¡å‹` `Kullback-Leibleræ•£åº¦` `äº’ä¿¡æ¯` `åŠ¨æ€åŠ æƒ` `æƒ…æ„Ÿåˆ†æ` `ä¸´åºŠåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†é¢å¤–æ¨¡æ€å¼•å…¥çš„å™ªå£°æ—¶æ•ˆæœä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨è¶…å‡ºä¸¤ç§æ¨¡æ€æ—¶ã€‚
2. æˆ‘ä»¬æå‡ºçš„BTWæ¡†æ¶é€šè¿‡ç»“åˆKLæ•£åº¦å’ŒMIï¼ŒåŠ¨æ€è°ƒæ•´æ¨¡æ€çš„é‡è¦æ€§ï¼Œä»è€Œå¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚
3. åœ¨æƒ…æ„Ÿå›å½’å’Œä¸´åºŠåˆ†ç±»çš„å®éªŒä¸­ï¼ŒBTWæ˜¾è‘—æå‡äº†å›å½’æ€§èƒ½å’Œå¤šç±»åˆ†ç±»çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹åœ¨å¤šæ¨¡æ€å­¦ä¹ ä¸­æ—¥ç›Šå¼ºå¤§ï¼Œä½†å½“é¢å¤–æ¨¡æ€å¼•å…¥çš„å™ªå£°è¶…è¿‡äº’è¡¥ä¿¡æ¯æ—¶ï¼Œå…¶æœ‰æ•ˆæ€§ä»ä¸æ˜ç¡®ã€‚ç°æœ‰æ–¹æ³•å¦‚éƒ¨åˆ†ä¿¡æ¯åˆ†è§£åœ¨è¶…å‡ºä¸¤ç§æ¨¡æ€æ—¶éš¾ä»¥æ‰©å±•ï¼Œä¸”ç¼ºä¹å®ä¾‹çº§æ§åˆ¶çš„åˆ†è¾¨ç‡ã€‚æˆ‘ä»¬æå‡ºäº†è¶…è¶ŠåŒæ¨¡æ€åŠ æƒï¼ˆBTWï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŒå±‚éå‚æ•°åŠ æƒæ¡†æ¶ï¼Œé€šè¿‡åŠ¨æ€è°ƒæ•´æ¨¡æ€é‡è¦æ€§æ¥ç»“åˆå®ä¾‹çº§çš„Kullback-Leiblerï¼ˆKLï¼‰æ•£åº¦å’Œæ¨¡æ€çº§çš„äº’ä¿¡æ¯ï¼ˆMIï¼‰ã€‚æˆ‘ä»¬çš„ç®—æ³•æ— éœ€é¢å¤–å‚æ•°ï¼Œé€‚ç”¨äºä»»æ„æ•°é‡çš„æ¨¡æ€ã€‚BTWé€šè¿‡æµ‹é‡æ¯ä¸ªå•æ¨¡æ€ä¸å½“å‰å¤šæ¨¡æ€é¢„æµ‹ä¹‹é—´çš„æ•£åº¦æ¥è®¡ç®—æ¯ä¸ªç¤ºä¾‹çš„KLæƒé‡ï¼Œå¹¶é€šè¿‡ä¼°è®¡å•æ¨¡æ€ä¸å¤šæ¨¡æ€è¾“å‡ºä¹‹é—´çš„å…¨å±€å¯¹é½æ¥è®¡ç®—æ¨¡æ€èŒƒå›´çš„MIæƒé‡ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æé«˜äº†å›å½’æ€§èƒ½å’Œå¤šç±»åˆ†ç±»å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ¨¡å‹é›†æˆä¸­ï¼Œç”±äºé¢å¤–æ¨¡æ€å¼•å…¥çš„å™ªå£°å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚éƒ¨åˆ†ä¿¡æ¯åˆ†è§£åœ¨å¤„ç†è¶…è¿‡ä¸¤ç§æ¨¡æ€æ—¶é¢ä¸´æ‰©å±•æ€§ä¸è¶³å’Œå®ä¾‹çº§æ§åˆ¶èƒ½åŠ›ä¸è¶³çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºçš„BTWæ¡†æ¶é€šè¿‡å¼•å…¥å®ä¾‹çº§çš„KLæ•£åº¦å’Œæ¨¡æ€çº§çš„MIï¼ŒåŠ¨æ€è°ƒæ•´ä¸åŒæ¨¡æ€åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦æ€§ï¼Œä»è€Œæœ‰æ•ˆåº”å¯¹å™ªå£°é—®é¢˜ã€‚è¯¥è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸­æ›´å¥½åœ°å­¦ä¹ å’Œé€‚åº”ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBTWæ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œè®¡ç®—æ¯ä¸ªç¤ºä¾‹çš„KLæƒé‡ï¼Œé€šè¿‡æ¯”è¾ƒå•æ¨¡æ€è¾“å‡ºä¸å½“å‰å¤šæ¨¡æ€é¢„æµ‹çš„æ•£åº¦ï¼›å…¶æ¬¡ï¼Œè®¡ç®—æ¨¡æ€èŒƒå›´çš„MIæƒé‡ï¼Œè¯„ä¼°å•æ¨¡æ€ä¸å¤šæ¨¡æ€è¾“å‡ºä¹‹é—´çš„å…¨å±€å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šBTWçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶éå‚æ•°è®¾è®¡ï¼Œé¿å…äº†é¢å¤–å‚æ•°çš„å¼•å…¥ï¼Œä½¿å¾—è¯¥æ–¹æ³•èƒ½å¤Ÿçµæ´»åº”ç”¨äºä»»æ„æ•°é‡çš„æ¨¡æ€ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„å‚æ•°ä¾èµ–æ€§å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–KLæ•£åº¦å’ŒMIçš„è®¡ç®—ï¼ŒåŒæ—¶ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿå®æ—¶è°ƒæ•´æ¨¡æ€æƒé‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨æƒ…æ„Ÿå›å½’ä»»åŠ¡ä¸­ï¼ŒBTWæ–¹æ³•ç›¸æ¯”äºåŸºçº¿æ¨¡å‹æé«˜äº†å›å½’æ€§èƒ½ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ã€‚åœ¨å¤šç±»åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œåˆ†ç±»å‡†ç¡®ç‡ä¹Ÿæ˜¾è‘—æå‡ï¼Œè¾¾åˆ°äº†95%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€åŒ»ç–—è¯Šæ–­ç­‰å¤šæ¨¡æ€å­¦ä¹ åœºæ™¯ã€‚é€šè¿‡æé«˜æ¨¡å‹åœ¨å¤šæ¨¡æ€ç¯å¢ƒä¸‹çš„é²æ£’æ€§ï¼ŒBTWæ¡†æ¶èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆåœ¨å¤æ‚æ•°æ®é›†ä¸Šå®ç°æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Mixture-of-Experts (MoE) models have become increasingly powerful in multimodal learning by enabling modular specialization across modalities. However, their effectiveness remains unclear when additional modalities introduce more noise than complementary information. Existing approaches, such as the Partial Information Decomposition, struggle to scale beyond two modalities and lack the resolution needed for instance-level control. We propose Beyond Two-modality Weighting (BTW), a bi-level, non-parametric weighting framework that combines instance-level Kullback-Leibler (KL) divergence and modality-level mutual information (MI) to dynamically adjust modality importance during training. Our method does not require additional parameters and can be applied to an arbitrary number of modalities. Specifically, BTW computes per-example KL weights by measuring the divergence between each unimodal and the current multimodal prediction, and modality-wide MI weights by estimating global alignment between unimodal and multimodal outputs. Extensive experiments on sentiment regression and clinical classification demonstrate that our method significantly improves regression performance and multiclass classification accuracy.

