---
layout: default
title: Robustness Feature Adapter for Efficient Adversarial Training
---

# Robustness Feature Adapter for Efficient Adversarial Training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17680" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17680v1</a>
  <a href="https://arxiv.org/pdf/2508.17680.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17680v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17680v1', 'Robustness Feature Adapter for Efficient Adversarial Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Quanwei Wu, Jun Guo, Wei Wang, Yi Wang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-25

**å¤‡æ³¨**: The paper has been accepted for presentation at ECAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€‚åº”æ€§ç‰¹å¾é€‚é…å™¨ä»¥æé«˜å¯¹æŠ—è®­ç»ƒæ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯¹æŠ—è®­ç»ƒ` `é²æ£’æ€§` `é€‚é…å™¨` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æ•ˆç‡` `æ¨¡å‹ä¼˜åŒ–` `ç‰¹å¾ç©ºé—´`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•åœ¨åº”ç”¨äºå¤§å‹æ¨¡å‹æ—¶ï¼Œè®¡ç®—å¼€é”€è¿‡å¤§ä¸”å­˜åœ¨é²æ£’æ€§è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºé€‚é…å™¨çš„é«˜æ•ˆå¯¹æŠ—è®­ç»ƒæ–¹æ³•ï¼Œæ—¨åœ¨ç›´æ¥åœ¨ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œä¼˜åŒ–ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æé«˜äº†è®¡ç®—æ•ˆç‡ï¼Œå¹¶åœ¨æœªè§æ”»å‡»ä¸Šæå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹æŠ—è®­ç»ƒï¼ˆATï¼‰ç»“åˆæŠ•å½±æ¢¯åº¦ä¸‹é™æ˜¯æå‡æ¨¡å‹åœ¨å¯¹æŠ—æ”»å‡»ä¸‹é²æ£’æ€§çš„ä¸»è¦æ–¹æ³•ã€‚ç„¶è€Œï¼Œå½“ATåº”ç”¨äºå¤§å‹éª¨å¹²æ¨¡å‹æ—¶ï¼Œè®¡ç®—å¼€é”€å˜å¾—æå…¶åºå¤§ï¼ŒåŒæ—¶ATè¿˜å­˜åœ¨é²æ£’æ€§è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„åŸºäºé€‚é…å™¨çš„æ–¹æ³•ï¼Œæ—¨åœ¨ç›´æ¥åœ¨ç‰¹å¾ç©ºé—´ä¸­å®ç°é«˜æ•ˆçš„å¯¹æŠ—è®­ç»ƒã€‚æˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•é€šè¿‡æ¶ˆé™¤é²æ£’æ€§è¿‡æ‹Ÿåˆæ¥æ”¹å–„å†…å¾ªç¯æ”¶æ•›è´¨é‡ï¼Œä»è€Œæ˜¾è‘—æé«˜è®¡ç®—æ•ˆç‡ï¼Œå¹¶é€šè¿‡å°†å¯¹æŠ—é²æ£’æ€§æ¨å¹¿åˆ°æœªè§æ”»å‡»æ¥æå‡æ¨¡å‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„éª¨å¹²æ¶æ„å’Œå¤§è§„æ¨¡å¯¹æŠ—è®­ç»ƒä¸­éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯¹æŠ—è®­ç»ƒåœ¨å¤§å‹æ¨¡å‹ä¸­è®¡ç®—å¼€é”€è¿‡å¤§å’Œé²æ£’æ€§è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ¨¡å‹æ—¶æ•ˆç‡ä½ä¸‹ï¼Œä¸”å®¹æ˜“å¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¿‡æ‹Ÿåˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§åŸºäºé€‚é…å™¨çš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡åœ¨ç‰¹å¾ç©ºé—´ä¸­è¿›è¡Œä¼˜åŒ–ï¼Œå‡å°‘è®¡ç®—è´Ÿæ‹…å¹¶æé«˜æ¨¡å‹çš„é²æ£’æ€§ã€‚è¯¥è®¾è®¡æ—¨åœ¨æ¶ˆé™¤é²æ£’æ€§è¿‡æ‹Ÿåˆï¼Œä»è€Œæå‡å†…å¾ªç¯çš„æ”¶æ•›è´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾æå–æ¨¡å—ã€é€‚é…å™¨æ¨¡å—å’Œå¯¹æŠ—è®­ç»ƒæ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œé€‚é…å™¨æ¨¡å—ç”¨äºè°ƒæ•´ç‰¹å¾ä»¥é€‚åº”å¯¹æŠ—è®­ç»ƒï¼Œæœ€åå¯¹æŠ—è®­ç»ƒæ¨¡å—æ‰§è¡Œä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥é€‚é…å™¨æœºåˆ¶ï¼Œä½¿å¾—å¯¹æŠ—è®­ç»ƒèƒ½å¤Ÿåœ¨ç‰¹å¾ç©ºé—´ä¸­é«˜æ•ˆè¿›è¡Œï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶æœ‰æ•ˆç¼“è§£äº†é²æ£’æ€§è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé€‚é…å™¨çš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿å…¶åœ¨ä¸åŒéª¨å¹²ç½‘ç»œä¸­å‡èƒ½æœ‰æ•ˆå·¥ä½œã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¯¹æŠ—æ ·æœ¬çš„ç‰¹æ€§ï¼Œä»¥æé«˜è®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨é€‚é…å™¨çš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•åœ¨å¤šä¸ªéª¨å¹²æ¶æ„ä¸Šå‡æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æœªè§æ”»å‡»ä¸Šï¼Œæå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šã€‚åŒæ—¶ï¼Œè®¡ç®—æ•ˆç‡æå‡äº†30%ï¼Œè¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤§è§„æ¨¡å¯¹æŠ—è®­ç»ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰éœ€è¦é«˜é²æ£’æ€§çš„æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ€§è‡³å…³é‡è¦çš„åœºæ™¯ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€é‡‘èæ¬ºè¯ˆæ£€æµ‹ç­‰ã€‚é€šè¿‡æé«˜å¯¹æŠ—è®­ç»ƒçš„æ•ˆç‡å’Œæ¨¡å‹çš„é²æ£’æ€§ï¼Œæœªæ¥å¯ä»¥åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å®ç°æ›´å®‰å…¨å’Œå¯é çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Adversarial training (AT) with projected gradient descent is the most popular method to improve model robustness under adversarial attacks. However, computational overheads become prohibitively large when AT is applied to large backbone models. AT is also known to have the issue of robust overfitting. This paper contributes to solving both problems simultaneously towards building more trustworthy foundation models. In particular, we propose a new adapter-based approach for efficient AT directly in the feature space. We show that the proposed adapter-based approach can improve the inner-loop convergence quality by eliminating robust overfitting. As a result, it significantly increases computational efficiency and improves model accuracy by generalizing adversarial robustness to unseen attacks. We demonstrate the effectiveness of the new adapter-based approach in different backbone architectures and in AT at scale.

