---
layout: default
title: Predictability Enables Parallelization of Nonlinear State Space Models
---

# Predictability Enables Parallelization of Nonlinear State Space Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.16817" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.16817v2</a>
  <a href="https://arxiv.org/pdf/2508.16817.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.16817v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.16817v2', 'Predictability Enables Parallelization of Nonlinear State Space Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Xavier Gonzalez, Leo Kozachkov, David M. Zoltowski, Kenneth L. Clarkson, Scott W. Linderman

**ÂàÜÁ±ª**: math.OC, cs.LG, eess.SY, math.DS, stat.ML

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-22 (Êõ¥Êñ∞: 2025-10-24)

**Â§áÊ≥®**: NeurIPS '25. Code: https://github.com/lindermanlab/predictability_enables_parallelization

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÂèØÈ¢ÑÊµãÊÄßÂéüÂàô‰ª•ÂÆûÁé∞ÈùûÁ∫øÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÂπ∂Ë°åÂåñ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `ÈùûÁ∫øÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°Âûã` `Âπ∂Ë°åËÆ°ÁÆó` `ÂèØÈ¢ÑÊµãÊÄß` `‰ºòÂåñÈóÆÈ¢ò` `Âä®ÊÄÅÁ≥ªÁªü` `ÂÆûÈ™åÈ™åËØÅ` `ÊäÄÊúØÂàõÊñ∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈùûÁ∫øÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÊó∂ÔºåÈöæ‰ª•ÊòéÁ°ÆÂì™‰∫õÊ®°ÂûãÂèØ‰ª•È´òÊïàÂπ∂Ë°åÂåñÔºåÈôêÂà∂‰∫ÜÊäÄÊúØÁöÑÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÈÄöËøáÂàÜÊûêÁ≥ªÁªüÁöÑÂèØÈ¢ÑÊµãÊÄßÊù•ËØÑ‰º∞ÈùûÁ∫øÊÄßÂä®ÊÄÅÁ≥ªÁªüÁöÑ‰ºòÂåñÈóÆÈ¢òÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÂπ∂Ë°åÂåñ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂú®ÂèØÈ¢ÑÊµãÁ≥ªÁªü‰∏≠ÔºåÁä∂ÊÄÅËΩ®ËøπÁöÑËÆ°ÁÆóÊó∂Èó¥ÊòæËëóÈôç‰ΩéÔºåËææÂà∞$O((	ext{log} T)^2)$ÔºåÁõ∏ÊØî‰º†ÁªüÊñπÊ≥ïÊúâÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂπ∂Ë°åËÆ°ÁÆóÁ°¨‰ª∂ÁöÑÂÖ¥Ëµ∑ÔºåÁêÜËß£Âì™‰∫õÈùûÁ∫øÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÂèØ‰ª•È´òÊïàÂπ∂Ë°åÂåñÂèòÂæóÊÑàÂèëÈáçË¶Å„ÄÇËøëÊúüÁöÑÁ†îÁ©∂Ë°®ÊòéÔºåÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑËØÑ‰º∞ÂèØ‰ª•Ë¢´ÈáçÊñ∞Ë°®Ëø∞‰∏∫‰∏Ä‰∏™ÂèØÂπ∂Ë°åÂåñÁöÑ‰ºòÂåñÈóÆÈ¢òÔºå‰∏îËøôÁßçÊñπÊ≥ïÊúâÊó∂ËÉΩÊòæËëóÂä†Âø´ËØÑ‰º∞Êó∂Èó¥„ÄÇÁÑ∂ËÄåÔºåÂΩ±ÂìçËøô‰∫õ‰ºòÂåñÈóÆÈ¢òÈöæÂ∫¶ÁöÑÂõ†Á¥†Â∞ö‰∏çÊòéÁ°ÆÔºåÈôêÂà∂‰∫ÜËØ•ÊäÄÊúØÁöÑÂπøÊ≥õÂ∫îÁî®„ÄÇÊú¨ÊñáÂª∫Á´ã‰∫ÜÈùûÁ∫øÊÄßÁ≥ªÁªüÂä®ÊÄÅ‰∏éÂÖ∂‰ºòÂåñÂΩ¢ÂºèÊù°‰ª∂‰πãÈó¥ÁöÑÁ≤æÁ°ÆÂÖ≥Á≥ªÔºåË°®ÊòéÁ≥ªÁªüÁöÑÂèØÈ¢ÑÊµãÊÄßÂΩ±ÂìçËØÑ‰º∞ÊâÄÈúÄÁöÑ‰ºòÂåñÊ≠•È™§Êï∞Èáè„ÄÇÂèØÈ¢ÑÊµãÁ≥ªÁªüÁöÑÁä∂ÊÄÅËΩ®ËøπËÆ°ÁÆóÊó∂Èó¥‰∏∫$O((	ext{log} T)^2)$ÔºåÁõ∏ÊØî‰º†ÁªüÈ°∫Â∫èÊñπÊ≥ïÊúâÊòæËëóÊèêÂçáÔºåËÄåÊ∑∑Ê≤åÊàñ‰∏çÂèØÈ¢ÑÊµãÁ≥ªÁªüÂàôË°®Áé∞Âá∫ËæÉÂ∑ÆÁöÑÊù°‰ª∂ÊÄßÔºåÂØºËá¥Âπ∂Ë°åËØÑ‰º∞Êî∂ÊïõËøáÊÖ¢„ÄÇÊàë‰ª¨ÁöÑÁêÜËÆ∫ÂàÜÊûêÈ™åËØÅ‰∫ÜÂèØÈ¢ÑÊµãÁ≥ªÁªüÁöÑ‰ºòÂåñÈóÆÈ¢òÊÄªÊòØËâØÂ•ΩÊù°‰ª∂ÔºåËÄå‰∏çÂèØÈ¢ÑÊµãÁ≥ªÁªüÁöÑÊù°‰ª∂ÊÄßÂàôÈöèÁùÄÂ∫èÂàóÈïøÂ∫¶ÂëàÊåáÊï∞‰∏ãÈôç„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÈùûÁ∫øÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÂπ∂Ë°åÂåñÊïàÁéáÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊú™ËÉΩÊòéÁ°ÆÂì™‰∫õÊ®°ÂûãÂèØ‰ª•ÊúâÊïàÂπ∂Ë°åÂåñÔºåÂØºËá¥ÊäÄÊúØÂ∫îÁî®ÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÂª∫Á´ãÈùûÁ∫øÊÄßÁ≥ªÁªüÂä®ÊÄÅ‰∏é‰ºòÂåñÈóÆÈ¢òÊù°‰ª∂‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂàÜÊûêÁ≥ªÁªüÁöÑÂèØÈ¢ÑÊµãÊÄßÂ¶Ç‰ΩïÂΩ±Âìç‰ºòÂåñÊ≠•È™§ÁöÑÊï∞ÈáèÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑÂπ∂Ë°åËÆ°ÁÆó„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨ÂØπÈùûÁ∫øÊÄßÁ≥ªÁªüÁöÑÂä®ÊÄÅÂàÜÊûê„ÄÅ‰ºòÂåñÈóÆÈ¢òÁöÑÊù°‰ª∂ÊÄßËØÑ‰º∞‰ª•ÂèäÂπ∂Ë°åËÆ°ÁÆóÁöÑÂÆûÁé∞„ÄÇ‰∏ªË¶ÅÊ®°ÂùóÂåÖÊã¨ÂèØÈ¢ÑÊµãÊÄßÂàÜÊûê„ÄÅ‰ºòÂåñÊ≠•È™§ËÆ°ÁÆóÂíåÂπ∂Ë°åÂåñÁ≠ñÁï•ËÆæËÆ°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜÂèØÈ¢ÑÊµãÊÄß‰Ωú‰∏∫Âπ∂Ë°åÂåñÊ®°ÂûãËÆæËÆ°ÁöÑÂÖ≥ÈîÆÂéüÂàôÔºåÊòéÁ°Æ‰∫ÜÂèØÈ¢ÑÊµãÁ≥ªÁªü‰∏é‰∏çÂèØÈ¢ÑÊµãÁ≥ªÁªüÂú®‰ºòÂåñÊù°‰ª∂‰∏äÁöÑÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑ‰ºòÂåñÁÆóÊ≥ïÂíåÂèÇÊï∞ËÆæÁΩÆÔºå‰ª•Á°Æ‰øùÂèØÈ¢ÑÊµãÁ≥ªÁªüÁöÑ‰ºòÂåñÈóÆÈ¢òÂßãÁªàËâØÂ•ΩÊù°‰ª∂ÔºåÂêåÊó∂ÂØπ‰∏çÂèØÈ¢ÑÊµãÁ≥ªÁªüÁöÑÊù°‰ª∂ÊÄßËøõË°å‰∫ÜÊ∑±ÂÖ•ÂàÜÊûê„ÄÇÂÖ∑‰ΩìÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑËÆæËÆ°Â∞öÊú™ËØ¶ÁªÜÊä´Èú≤„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂú®ÂèØÈ¢ÑÊµãÁ≥ªÁªü‰∏≠ÔºåÁä∂ÊÄÅËΩ®ËøπËÆ°ÁÆóÊó∂Èó¥ËææÂà∞$O((	ext{log} T)^2)$ÔºåÁõ∏ÊØî‰º†ÁªüÈ°∫Â∫èÊñπÊ≥ïÊèêÂçáÊòæËëó„ÄÇÂØπ‰∫é‰∏çÂèØÈ¢ÑÊµãÁ≥ªÁªüÔºå‰ºòÂåñÈóÆÈ¢òÁöÑÊù°‰ª∂ÊÄßÈöèÁùÄÂ∫èÂàóÈïøÂ∫¶ÂëàÊåáÊï∞‰∏ãÈôçÔºåÂØºËá¥Âπ∂Ë°åËØÑ‰º∞ÊïàÁéá‰Ωé‰∏ãÔºåÈ™åËØÅ‰∫ÜÁêÜËÆ∫ÂàÜÊûêÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÅÈáëËûçÂª∫Ê®°ÂíåÊ∞îÂÄôÈ¢ÑÊµãÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òÈùûÁ∫øÊÄßÂä®ÊÄÅÁ≥ªÁªüÁöÑÂπ∂Ë°åÂåñÊïàÁéáÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáÂÆûÊó∂ÂÜ≥Á≠ñÂíåÈ¢ÑÊµãÁöÑËÉΩÂäõÔºåÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•‰∏éÂ∫îÁî®ËêΩÂú∞„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> The rise of parallel computing hardware has made it increasingly important to understand which nonlinear state space models can be efficiently parallelized. Recent advances like DEER (arXiv:2309.12252) or DeepPCR (arXiv:2309.16318) have shown that evaluating a state space model can be recast as solving a parallelizable optimization problem, and sometimes this approach can yield dramatic speed-ups in evaluation time. However, the factors that govern the difficulty of these optimization problems remain unclear, limiting the larger adoption of the technique. In this work, we establish a precise relationship between the dynamics of a nonlinear system and the conditioning of its corresponding optimization formulation. We show that the predictability of a system, defined as the degree to which small perturbations in state influence future behavior, impacts the number of optimization steps required for evaluation. In predictable systems, the state trajectory can be computed in $O((\log T)^2)$ time, where $T$ is the sequence length, a major improvement over the conventional sequential approach. In contrast, chaotic or unpredictable systems exhibit poor conditioning, with the consequence that parallel evaluation converges too slowly to be useful. Importantly, our theoretical analysis demonstrates that for predictable systems, the optimization problem is always well-conditioned, whereas for unpredictable systems, the conditioning degrades exponentially as a function of the sequence length. We validate our claims through extensive experiments, providing practical guidance on when nonlinear dynamical systems can be efficiently parallelized, and highlighting predictability as a key design principle for parallelizable models.

