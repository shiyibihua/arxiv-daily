---
layout: default
title: PiERN: Token-Level Routing for Integrating High-Precision Computation and Reasoning
---

# PiERN: Token-Level Routing for Integrating High-Precision Computation and Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18169" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18169v2</a>
  <a href="https://arxiv.org/pdf/2509.18169.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18169v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18169v2', 'PiERN: Token-Level Routing for Integrating High-Precision Computation and Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hengbo Xiao, Jingyuan Fan, Xin Tong, Jingzhao Zhang, Chao Lu, Guannan He

**åˆ†ç±»**: cs.LG, cs.CE, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-17 (æ›´æ–°: 2025-09-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PiERNï¼šç”¨äºé›†æˆé«˜ç²¾åº¦è®¡ç®—ä¸æ¨ç†çš„Tokençº§è·¯ç”±ç½‘ç»œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¡ç®—æ¨ç†` `tokençº§è·¯ç”±` `ä¸“å®¶ç³»ç»Ÿ` `è¯­è¨€æ¨¡å‹` `ç§‘å­¦è®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLMéš¾ä»¥å°†é«˜ç²¾åº¦æ•°å€¼è®¡ç®—èƒ½åŠ›å†…ç”Ÿé›†æˆï¼Œé™åˆ¶äº†å…¶åœ¨å¤æ‚ç³»ç»Ÿä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚
2. PiERNé€šè¿‡tokençº§è·¯ç”±ï¼Œå°†è®¡ç®—ä¸“å®¶æ¨¡å—ä¸æ¨ç†æ¨¡å—é›†æˆï¼Œå®ç°è®¡ç®—ä¸æ¨ç†çš„è¿­ä»£äº¤æ›¿ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPiERNåœ¨ç²¾åº¦ã€å»¶è¿Ÿã€tokenä½¿ç”¨å’Œèƒ½è€—æ–¹é¢å‡ä¼˜äºLLMå¾®è°ƒå’Œå¤šæ™ºèƒ½ä½“æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤æ‚ç³»ç»Ÿä¸Šçš„ä»»åŠ¡éœ€è¦é«˜ç²¾åº¦çš„æ•°å€¼è®¡ç®—æ¥æ”¯æŒå†³ç­–ï¼Œä½†ç›®å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ— æ³•å°†è¿™ç§è®¡ç®—ä½œä¸ºä¸€ç§å†…åœ¨ä¸”å¯è§£é‡Šçš„èƒ½åŠ›ä¸ç°æœ‰æ¶æ„é›†æˆã€‚å¤šæ™ºèƒ½ä½“æ–¹æ³•å¯ä»¥åˆ©ç”¨å¤–éƒ¨ä¸“å®¶ï¼Œä½†ä¸å¯é¿å…åœ°ä¼šå¼•å…¥é€šä¿¡å¼€é”€ï¼Œå¹¶å› æœ‰é™çš„å¯æ‰©å±•æ€§è€Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç‰©ç†éš”ç¦»çš„ä¸“å®¶è·¯ç”±ç½‘ç»œï¼ˆPiERNï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºé›†æˆè®¡ç®—å’Œæ¨ç†çš„æ¶æ„ã€‚PiERNæ²¡æœ‰é‡‡ç”¨å·¥å…·ä½¿ç”¨å·¥ä½œæµç¨‹æˆ–å‡½æ•°è°ƒç”¨ï¼Œè€Œæ˜¯åœ¨åˆ†åˆ«è®­ç»ƒä¸“å®¶ã€æ–‡æœ¬åˆ°è®¡ç®—æ¨¡å—å’Œè·¯ç”±å™¨åï¼Œå°†è®¡ç®—èƒ½åŠ›å†…ç”Ÿåœ°é›†æˆåˆ°ç¥ç»ç½‘ç»œä¸­ã€‚åœ¨æ¨ç†æ—¶ï¼Œè·¯ç”±å™¨åœ¨tokençº§åˆ«æŒ‡å¯¼è®¡ç®—å’Œæ¨ç†ï¼Œä»è€Œå¯ä»¥åœ¨å•ä¸ªæ€ç»´é“¾ä¸­è¿›è¡Œè¿­ä»£äº¤æ›¿ã€‚æˆ‘ä»¬é’ˆå¯¹LLMå¾®è°ƒå’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ–¹æ³•ï¼Œåœ¨å…·æœ‰ä»£è¡¨æ€§çš„çº¿æ€§å’Œéçº¿æ€§è®¡ç®—æ¨ç†ä»»åŠ¡ä¸Šè¯„ä¼°äº†PiERNã€‚ç»“æœè¡¨æ˜ï¼Œä¸ç›´æ¥å¾®è°ƒLLMç›¸æ¯”ï¼ŒPiERNæ¶æ„ä¸ä»…å®ç°äº†æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œè€Œä¸”ä¸ä¸»æµå¤šæ™ºèƒ½ä½“æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨å“åº”å»¶è¿Ÿã€tokenä½¿ç”¨å’ŒGPUèƒ½è€—æ–¹é¢ä¹Ÿå–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚PiERNä¸ºè¯­è¨€æ¨¡å‹ä¸ç§‘å­¦ç³»ç»Ÿäº¤äº’æä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯è§£é‡Šå’Œå¯æ‰©å±•çš„èŒƒä¾‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤„ç†éœ€è¦é«˜ç²¾åº¦æ•°å€¼è®¡ç®—çš„å¤æ‚ç³»ç»Ÿä»»åŠ¡æ—¶å­˜åœ¨å±€é™æ€§ã€‚å®ƒä»¬è¦ä¹ˆéš¾ä»¥å°†è®¡ç®—èƒ½åŠ›é›†æˆåˆ°æ¨¡å‹å†…éƒ¨ï¼Œè¦ä¹ˆä¾èµ–å¤–éƒ¨å·¥å…·æˆ–å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œå¯è§£é‡Šæ€§å·®ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºæ— æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­çµæ´»åœ°è¿›è¡Œè®¡ç®—å’Œæ¨ç†çš„è¿­ä»£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPiERNçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è®¡ç®—èƒ½åŠ›æ¨¡å—åŒ–ï¼Œå¹¶åˆ©ç”¨ä¸€ä¸ªè·¯ç”±å™¨åœ¨tokençº§åˆ«åŠ¨æ€åœ°å†³å®šä½•æ—¶è¿›è¡Œè®¡ç®—ï¼Œä½•æ—¶è¿›è¡Œæ¨ç†ã€‚è¿™ç§è®¾è®¡å…è®¸æ¨¡å‹åœ¨ç”Ÿæˆæ–‡æœ¬çš„è¿‡ç¨‹ä¸­ï¼Œæ ¹æ®éœ€è¦çµæ´»åœ°è°ƒç”¨è®¡ç®—æ¨¡å—ï¼Œä»è€Œå®ç°è®¡ç®—å’Œæ¨ç†çš„ç´§å¯†ç»“åˆã€‚é€šè¿‡å°†è®¡ç®—æ¨¡å—ä¸æ¨ç†æ¨¡å—è§£è€¦ï¼Œå¯ä»¥åˆ†åˆ«è®­ç»ƒè¿™äº›æ¨¡å—ï¼Œå¹¶æœ€ç»ˆé€šè¿‡è·¯ç”±å™¨å°†å®ƒä»¬é›†æˆåœ¨ä¸€èµ·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPiERNçš„æ•´ä½“æ¶æ„åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬åˆ°è®¡ç®—æ¨¡å—ï¼ˆtext-to-computation moduleï¼‰ã€ä¸“å®¶æ¨¡å—ï¼ˆexpertsï¼‰å’Œè·¯ç”±å™¨ï¼ˆrouterï¼‰ã€‚æ–‡æœ¬åˆ°è®¡ç®—æ¨¡å—è´Ÿè´£å°†æ–‡æœ¬è¾“å…¥è½¬æ¢ä¸ºè®¡ç®—æ‰€éœ€çš„æ•°å€¼è¾“å…¥ã€‚ä¸“å®¶æ¨¡å—åŒ…å«å¤šä¸ªé¢„è®­ç»ƒçš„è®¡ç®—ä¸“å®¶ï¼Œæ¯ä¸ªä¸“å®¶æ“…é•¿ä¸åŒçš„è®¡ç®—ä»»åŠ¡ã€‚è·¯ç”±å™¨æ ¹æ®å½“å‰tokençš„ä¸Šä¸‹æ–‡ï¼Œå†³å®šå°†è¯¥tokenè·¯ç”±åˆ°å“ªä¸ªä¸“å®¶æ¨¡å—æˆ–æ¨ç†æ¨¡å—ã€‚æ•´ä¸ªæµç¨‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­è¿­ä»£è¿›è¡Œï¼Œç›´åˆ°ç”Ÿæˆæœ€ç»ˆçš„è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šPiERNæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºtokençº§åˆ«çš„è·¯ç”±æœºåˆ¶ã€‚ä¸ä¼ ç»Ÿçš„å·¥å…·ä½¿ç”¨æˆ–å‡½æ•°è°ƒç”¨æ–¹æ³•ä¸åŒï¼ŒPiERNçš„è·¯ç”±å™¨å¯ä»¥åœ¨æ¯ä¸ªtokenä¸Šåšå‡ºå†³ç­–ï¼Œä»è€Œå®ç°è®¡ç®—å’Œæ¨ç†çš„ç»†ç²’åº¦æ§åˆ¶ã€‚è¿™ç§tokençº§åˆ«çš„è·¯ç”±æœºåˆ¶ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´åŠ çµæ´»åœ°å¤„ç†å¤æ‚çš„è®¡ç®—æ¨ç†ä»»åŠ¡ï¼Œå¹¶é¿å…äº†å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸­çš„é€šä¿¡å¼€é”€ã€‚

**å…³é”®è®¾è®¡**ï¼šPiERNçš„å…³é”®è®¾è®¡åŒ…æ‹¬è·¯ç”±å™¨çš„è®¾è®¡ã€ä¸“å®¶æ¨¡å—çš„è®­ç»ƒä»¥åŠæ–‡æœ¬åˆ°è®¡ç®—æ¨¡å—çš„è®¾è®¡ã€‚è·¯ç”±å™¨é€šå¸¸æ˜¯ä¸€ä¸ªå°å‹ç¥ç»ç½‘ç»œï¼Œå…¶è¾“å…¥æ˜¯å½“å‰tokençš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œè¾“å‡ºæ˜¯è·¯ç”±å†³ç­–ã€‚ä¸“å®¶æ¨¡å—å¯ä»¥ä½¿ç”¨å„ç§é¢„è®­ç»ƒçš„è®¡ç®—æ¨¡å‹ï¼Œä¾‹å¦‚æ•°å€¼æ±‚è§£å™¨æˆ–ç¬¦å·è®¡ç®—å¼•æ“ã€‚æ–‡æœ¬åˆ°è®¡ç®—æ¨¡å—çš„è®¾è®¡éœ€è¦æ ¹æ®å…·ä½“çš„è®¡ç®—ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥ç¡®ä¿èƒ½å¤Ÿå°†æ–‡æœ¬è¾“å…¥æ­£ç¡®åœ°è½¬æ¢ä¸ºæ•°å€¼è¾“å…¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PiERNåœ¨å¤šä¸ªè®¡ç®—æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨çº¿æ€§è®¡ç®—ä»»åŠ¡ä¸­ï¼ŒPiERNçš„å‡†ç¡®ç‡é«˜äºç›´æ¥å¾®è°ƒçš„LLMã€‚åœ¨éçº¿æ€§è®¡ç®—ä»»åŠ¡ä¸­ï¼ŒPiERNåœ¨å“åº”å»¶è¿Ÿã€tokenä½¿ç”¨å’ŒGPUèƒ½è€—æ–¹é¢å‡ä¼˜äºä¸»æµçš„å¤šæ™ºèƒ½ä½“æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒPiERNåœ¨æŸäº›ä»»åŠ¡ä¸Šçš„å“åº”å»¶è¿Ÿé™ä½äº†X%ï¼Œtokenä½¿ç”¨é‡å‡å°‘äº†Y%ï¼ŒGPUèƒ½è€—é™ä½äº†Z%ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PiERNæ¶æ„å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚ç§‘å­¦è®¡ç®—ã€é‡‘èå»ºæ¨¡ã€å·¥ç¨‹è®¾è®¡ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è¯­è¨€æ¨¡å‹è§£å†³å¤æ‚çš„ç§‘å­¦é—®é¢˜ï¼Œå¹¶æé«˜å†³ç­–çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼ŒPiERNæœ‰æœ›æˆä¸ºè¿æ¥è¯­è¨€æ¨¡å‹ä¸ç§‘å­¦ç³»ç»Ÿçš„æ¡¥æ¢ï¼Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨ç§‘å­¦é¢†åŸŸçš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tasks on complex systems require high-precision numerical computation to support decisions, but current large language models (LLMs) cannot integrate such computations as an intrinsic and interpretable capability with existing architectures. Multi-agent approaches can leverage external experts, but inevitably introduce communication overhead and suffer from inefficiency caused by limited scalability. To this end, we propose Physically-isolated Experts Routing Network (PiERN), an architecture for integrating computation and reasoning. Instead of the tool-use workflows or function-calling, PiERN endogenously integrates computational capabilities into neural networks after separately training experts, a text-to-computation module, and a router. At inference, the router directs computation and reasoning at the token level, thereby enabling iterative alternation within a single chain of thought. We evaluate PiERN on representative linear and nonlinear computation-reasoning tasks against LLM finetuning and the multi-agent system approaches. Results show that the PiERN architecture achieves not only higher accuracy than directly finetuning LLMs but also significant improvements in response latency, token usage, and GPU energy consumption compared with mainstream multi-agent approaches. PiERN offers an efficient, interpretable, and scalable paradigm for interfacing language models with scientific systems.

