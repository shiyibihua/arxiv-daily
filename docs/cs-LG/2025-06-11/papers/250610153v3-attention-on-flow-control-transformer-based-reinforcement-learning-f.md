---
layout: default
title: Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows
---

# Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10153" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10153v3</a>
  <a href="https://arxiv.org/pdf/2506.10153.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10153v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10153v3', 'Attention on flow control: transformer-based reinforcement learning for lift regulation in highly disturbed flows')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhecheng Liu, Jeff D. Eldredge

**åˆ†ç±»**: physics.flu-dyn, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11 (æ›´æ–°: 2025-11-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå˜å‹å™¨çš„å¼ºåŒ–å­¦ä¹ ä»¥è§£å†³å¼ºå¹²æ‰°æµä¸­çš„å‡åŠ›è°ƒèŠ‚é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å˜å‹å™¨` `æµä½“æ§åˆ¶` `å‡åŠ›è°ƒèŠ‚` `æ°”æµå¹²æ‰°` `éçº¿æ€§æ§åˆ¶` `è¿ç§»å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çº¿æ€§æµæ§åˆ¶ç­–ç•¥åœ¨é¢å¯¹å¼ºå¹²æ‰°æ—¶è¡¨ç°ä¸ä½³ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹éçº¿æ€§ç›¸äº’ä½œç”¨å¸¦æ¥çš„æŒ‘æˆ˜ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå˜å‹å™¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨æœ‰é™çš„è¡¨é¢å‹åŠ›ä¼ æ„Ÿå™¨æ¥å­¦ä¹ æœ‰æ•ˆçš„å‡åŠ›è°ƒèŠ‚ç­–ç•¥ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€å­¦ç­–ç•¥åœ¨å¤šä¸ªæ°”æµå¹²æ‰°ç¯å¢ƒä¸­è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„æ¯”ä¾‹æ§åˆ¶ï¼Œä¸”å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„çº¿æ€§æµæ§åˆ¶ç­–ç•¥åœ¨å¼ºå¹²æ‰°åºåˆ—ä¸­å¯èƒ½å¤±æ•ˆï¼Œå› æ­¤æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå˜å‹å™¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ä¿¯ä»°æ§åˆ¶æœ‰æ•ˆè°ƒèŠ‚ä»»æ„é•¿çš„æ°”æµå¹²æ‰°åºåˆ—ä¸­çš„å‡åŠ›ã€‚éšæœºæ°”æµå¯¼è‡´çš„é«˜æ–¹å·®æµåŠ¨ä»…é€šè¿‡æœ‰é™çš„è¡¨é¢å‹åŠ›ä¼ æ„Ÿå™¨è§‚å¯Ÿï¼Œä½¿å¾—è¯¥æ§åˆ¶é—®é¢˜æ¯”é™æ€æµåŠ¨æ›´å…·æŒ‘æˆ˜æ€§ã€‚é€šè¿‡é¢„è®­ç»ƒå’Œä»»åŠ¡çº§è¿ç§»å­¦ä¹ åŠ é€Ÿè®­ç»ƒï¼Œç»“æœè¡¨æ˜æ‰€å­¦ç­–ç•¥åœ¨å‡åŠ›è°ƒèŠ‚ä¸Šä¼˜äºæœ€ä½³æ¯”ä¾‹æ§åˆ¶ï¼Œä¸”éšç€å¹²æ‰°æ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½å·®è·è¿›ä¸€æ­¥æ‰©å¤§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨å¼ºå¹²æ‰°æµä¸­å‡åŠ›è°ƒèŠ‚çš„æ§åˆ¶é—®é¢˜ã€‚ç°æœ‰çš„çº¿æ€§æ§åˆ¶æ–¹æ³•åœ¨é¢å¯¹å¼ºå¹²æ‰°æ—¶å¤±æ•ˆï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹éçº¿æ€§ç›¸äº’ä½œç”¨å¸¦æ¥çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå˜å‹å™¨çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å­¦ä¹ æœ‰æ•ˆçš„æ§åˆ¶ç­–ç•¥æ¥åº”å¯¹ä»»æ„é•¿çš„æ°”æµå¹²æ‰°åºåˆ—ï¼Œåˆ©ç”¨æœ‰é™çš„ä¼ æ„Ÿå™¨æ•°æ®å…‹æœéƒ¨åˆ†å¯è§‚æµ‹æ€§é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é¢„è®­ç»ƒé˜¶æ®µï¼ˆä½¿ç”¨ä¸“å®¶ç­–ç•¥è¿›è¡Œåˆå§‹åŒ–ï¼‰ï¼Œå¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼ˆé€šè¿‡ä¸ç¯å¢ƒäº¤äº’å­¦ä¹ æ§åˆ¶ç­–ç•¥ï¼‰ï¼Œä»¥åŠä»»åŠ¡çº§è¿ç§»å­¦ä¹ ï¼ˆå°†å•ä¸€å¹²æ‰°è®­ç»ƒçš„ç­–ç•¥æ‰©å±•åˆ°å¤šä¸ªå¹²æ‰°ï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥å˜å‹å™¨æ¨¡å‹æ¥å¤„ç†éƒ¨åˆ†å¯è§‚æµ‹æ€§é—®é¢˜ï¼Œå¹¶é€šè¿‡é¢„è®­ç»ƒå’Œè¿ç§»å­¦ä¹ åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ï¼Œè¿™ä¸ä¼ ç»Ÿçš„çº¿æ€§æ§åˆ¶æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨å˜å‹å™¨æ¶æ„ä»¥æ•æ‰æ—¶åºç‰¹å¾ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸ºç»“åˆå‡åŠ›è°ƒèŠ‚æ•ˆæœå’Œæ§åˆ¶åŠªåŠ›çš„ç»¼åˆæŒ‡æ ‡ï¼Œå‚æ•°è®¾ç½®ä¸Šä¼˜åŒ–äº†ä¿¯ä»°æ§åˆ¶çš„é…ç½®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€å­¦çš„æ§åˆ¶ç­–ç•¥åœ¨å¤šä¸ªæ°”æµå¹²æ‰°ç¯å¢ƒä¸­è¡¨ç°ä¼˜äºæœ€ä½³æ¯”ä¾‹æ§åˆ¶ï¼Œéšç€å¹²æ‰°æ•°é‡çš„å¢åŠ ï¼Œæ€§èƒ½å·®è·è¿›ä¸€æ­¥æ‰©å¤§ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“è€Œè¨€ï¼Œæ‰€æå‡ºçš„ç­–ç•¥åœ¨å°æ•°é‡å¹²æ‰°ç¯å¢ƒä¸­è®­ç»ƒåï¼Œèƒ½å¤Ÿæœ‰æ•ˆé€‚åº”ä»»æ„é•¿çš„å¹²æ‰°åºåˆ—ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬èˆªç©ºèˆªå¤©ã€æ— äººæœºæ§åˆ¶åŠå…¶ä»–éœ€è¦åœ¨å¤æ‚æµåŠ¨ç¯å¢ƒä¸­è¿›è¡Œç²¾ç¡®æ§åˆ¶çš„å·¥ç¨‹é¢†åŸŸã€‚é€šè¿‡æå‡å‡åŠ›è°ƒèŠ‚çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„é£è¡Œå™¨çš„ç¨³å®šæ€§å’Œæ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A linear flow control strategy designed for weak disturbances may not remain effective in sequences of strong disturbances due to nonlinear interactions, but it is sensible to leverage it for developing a better strategy. In the present study, we propose a transformer-based reinforcement learning (RL) framework to learn an effective control strategy for regulating aerodynamic lift in arbitrarily long gust sequences via pitch control. The random gusts produce intermittent, high-variance flows observed only through limited surface pressure sensors, making this control problem inherently challenging compared to stationary flows. The transformer addresses the challenge of partial observability from the limited surface pressures. We demonstrate that the training can be accelerated with two techniques -- pretraining with an expert policy (here, linear control) and task-level transfer learning (here, extending a policy trained on isolated gusts to multiple gusts). We show that the learned strategy outperforms the best proportional control, with the performance gap widening as the number of gusts increases. The control strategy learned in an environment with a small number of successive gusts is shown to effectively generalize to an environment with an arbitrarily long sequence of gusts. We investigate the pivot configuration and show that quarter-chord pitching control can achieve superior lift regulation with substantially less control effort compared to mid-chord pitching control. Through a decomposition of the lift, we attribute this advantage to the dominant added-mass contribution accessible via quarter-chord pitching.

