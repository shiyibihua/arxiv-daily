---
layout: default
title: Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models
---

# Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09532" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.09532v4</a>
  <a href="https://arxiv.org/pdf/2506.09532.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09532v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09532v4', 'Athena: Enhancing Multimodal Reasoning with Data-efficient Process Reward Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Shuai Wang, Zhenhua Liu, Jiaheng Wei, Xuanwu Yin, Dong Li, Emad Barsoum

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CL, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-11 (Êõ¥Êñ∞: 2025-12-04)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Athena-PRM‰ª•È´òÊïàËß£ÂÜ≥Â§öÊ®°ÊÄÅÊé®ÁêÜ‰∏≠ÁöÑÂ•ñÂä±Ê®°ÂûãÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÊé®ÁêÜ` `Â•ñÂä±Ê®°Âûã` `ËøáÁ®ãÊ†áÊ≥®` `Êï∞ÊçÆÊïàÁéá` `Ê®°Âûã‰ºòÂåñ` `Êô∫ËÉΩÁ≥ªÁªü` `Ëá™Âä®ÂåñËØÑ‰º∞`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ•ñÂä±Ê®°ÂûãÂºÄÂèëÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÁöÑÊó∂Èó¥ÂíåË¥¢ÂäõÊäïÂÖ•ÔºåÂ∞§ÂÖ∂ÊòØÂØπÊé®ÁêÜÊ≠•È™§ÁöÑÈÄêÊ≠•Ê†áÊ≥®Â≠òÂú®ÊåëÊàò„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Athena-PRMÔºåÈÄöËøáÂà©Áî®Âº±Ë°•ÂÖ®ËÄÖ‰∏éÂº∫Ë°•ÂÖ®ËÄÖÁöÑÈ¢ÑÊµã‰∏ÄËá¥ÊÄßÊù•È´òÊïàÁîüÊàêÈ´òË¥®ÈáèÁöÑËøáÁ®ãÊ†áÊ≥®Êï∞ÊçÆ„ÄÇ
3. Athena-PRMÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºåÂ∞§ÂÖ∂Âú®WeMathÂíåMathVista‰∏äÂàÜÂà´ÊèêÂçá‰∫Ü10.2Âíå7.1ÂàÜÔºå‰∏îÂú®VisualProcessBench‰∏äËææÂà∞‰∫ÜÊúÄÊñ∞ÁöÑSoTAÁªìÊûú„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êàë‰ª¨ÊèêÂá∫‰∫ÜAthena-PRMÔºåËøôÊòØ‰∏ÄÁßçÂ§öÊ®°ÊÄÅËøáÁ®ãÂ•ñÂä±Ê®°ÂûãÔºåÊó®Âú®ËØÑ‰º∞Ëß£ÂÜ≥Â§çÊùÇÊé®ÁêÜÈóÆÈ¢òÊØè‰∏ÄÊ≠•ÁöÑÂ•ñÂä±ÂàÜÊï∞„ÄÇÂºÄÂèëÈ´òÊÄßËÉΩÁöÑÂ•ñÂä±Ê®°ÂûãÈÄöÂ∏∏ÈúÄË¶ÅÂ§ßÈáèÊó∂Èó¥ÂíåË¥¢ÂäõÊäïÂÖ•Ôºå‰∏ªË¶ÅÊòØÂõ†‰∏∫ÈúÄË¶ÅÂØπÊé®ÁêÜÊ≠•È™§ËøõË°åÈÄêÊ≠•Ê†áÊ≥®„ÄÇ‰º†ÁªüÁöÑËá™Âä®Ê†áÊ≥®ÊñπÊ≥ïÔºåÂ¶ÇËíôÁâπÂç°Ê¥õ‰º∞ËÆ°ÔºåÂæÄÂæÄ‰∫ßÁîüÂô™Â£∞Ê†áÁ≠æÂπ∂‰∏îËÆ°ÁÆóÊàêÊú¨È´ò„ÄÇ‰∏∫È´òÊïàÁîüÊàêÈ´òË¥®ÈáèÁöÑËøáÁ®ãÊ†áÊ≥®Êï∞ÊçÆÔºåÊàë‰ª¨ÊèêÂá∫Âà©Áî®Âº±Ë°•ÂÖ®ËÄÖ‰∏éÂº∫Ë°•ÂÖ®ËÄÖ‰πãÈó¥ÁöÑÈ¢ÑÊµã‰∏ÄËá¥ÊÄß‰Ωú‰∏∫ËØÜÂà´ÂèØÈù†ËøáÁ®ãÊ†áÁ≠æÁöÑÊ†áÂáÜ„ÄÇAthena-PRMÂú®Â§ö‰∏™Âú∫ÊôØÂíåÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤Ôºå‰ªÖÈúÄ5000‰∏™Ê†∑Êú¨„ÄÇÊ≠§Â§ñÔºåÊàë‰ª¨ËøòÂºÄÂèë‰∫Ü‰∏§ÁßçÊúâÊïàÁ≠ñÁï•‰ª•ÊèêÂçáÂ•ñÂä±Ê®°ÂûãÁöÑÊÄßËÉΩÔºöORMÂàùÂßãÂåñÂíåË¥üÊ†∑Êú¨ÁöÑ‰∏äÈááÊ†∑„ÄÇÊàë‰ª¨ÁöÑÂÆûÈ™åÈ™åËØÅ‰∫ÜAthena-PRMÂú®Â§ö‰∏™Âü∫ÂáÜÂíåÂú∫ÊôØ‰∏≠ÁöÑ‰ºòË∂äÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊé®ÁêÜ‰∏≠Â•ñÂä±Ê®°ÂûãÁöÑÂºÄÂèëÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Ê†áÊ≥®Êé®ÁêÜÊ≠•È™§Êó∂Èù¢‰∏¥È´òÊàêÊú¨ÂíåÂô™Â£∞Ê†áÁ≠æÁöÑÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAthena-PRMÈÄöËøáÂà©Áî®Âº±Ë°•ÂÖ®ËÄÖ‰∏éÂº∫Ë°•ÂÖ®ËÄÖ‰πãÈó¥ÁöÑÈ¢ÑÊµã‰∏ÄËá¥ÊÄßÔºåÊù•È´òÊïàÁîüÊàêÂèØÈù†ÁöÑËøáÁ®ãÊ†áÊ≥®Êï∞ÊçÆÔºå‰ªéËÄåÈôç‰ΩéÂØπÊ†áÊ≥®ÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAthena-PRMÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÁîüÊàêÊ®°Âùó„ÄÅÂ•ñÂä±ËØÑ‰º∞Ê®°ÂùóÂíåÊ®°ÂûãËÆ≠ÁªÉÊ®°Âùó„ÄÇÊï∞ÊçÆÁîüÊàêÊ®°ÂùóË¥üË¥£ÁîüÊàêËøáÁ®ãÊ†áÊ≥®Êï∞ÊçÆÔºåÂ•ñÂä±ËØÑ‰º∞Ê®°ÂùóÂàôÁî®‰∫éËØÑ‰º∞ÊØè‰∏ÄÊ≠•ÁöÑÂ•ñÂä±ÂàÜÊï∞ÔºåÊ®°ÂûãËÆ≠ÁªÉÊ®°ÂùóÂàôËøõË°åÊ®°ÂûãÁöÑ‰ºòÂåñÂíåË∞ÉÊï¥„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAthena-PRMÁöÑÊ†∏ÂøÉÂàõÊñ∞Âú®‰∫éÈÄöËøáÈ¢ÑÊµã‰∏ÄËá¥ÊÄßÊù•ËØÜÂà´ÂèØÈù†ÁöÑËøáÁ®ãÊ†áÁ≠æÔºåËøô‰∏ÄÊñπÊ≥ïÊòæËëóÈôç‰Ωé‰∫ÜÂØπ‰∫∫Â∑•Ê†áÊ≥®ÁöÑÈúÄÊ±ÇÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊï∞ÊçÆÁöÑË¥®Èáè„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜORMÂàùÂßãÂåñÂíåË¥üÊ†∑Êú¨ÁöÑ‰∏äÈááÊ†∑Á≠ñÁï•Ôºå‰ª•Â¢ûÂº∫Ê®°ÂûãÁöÑÂ≠¶‰π†ËÉΩÂäõÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Athena-PRMÂú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞‰ºòÂºÇÔºå‰ΩøÁî®Qwen2.5-VL-7B‰Ωú‰∏∫Á≠ñÁï•Ê®°ÂûãÊó∂ÔºåÂú®WeMathÂíåMathVista‰∏äÂàÜÂà´ÊèêÂçá‰∫Ü10.2Âíå7.1ÂàÜ„ÄÇÊ≠§Â§ñÔºåAthena-PRMÂú®VisualProcessBench‰∏äËææÂà∞‰∫ÜÊúÄÊñ∞ÁöÑSoTAÁªìÊûúÔºåË∂ÖË∂ä‰∫Ü‰πãÂâçÁöÑSoTA 3.9 F1-scoreÔºåÊòæÁ§∫Âá∫ÂÖ∂Âú®Êé®ÁêÜÊ≠•È™§Ê≠£Á°ÆÊÄßËØÑ‰º∞‰∏≠ÁöÑÂº∫Â§ßËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

Athena-PRMÁöÑÁ†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂ§çÊùÇÊé®ÁêÜ‰ªªÂä°ÁöÑËá™Âä®ÂåñËØÑ‰º∞ÔºåÂ¶ÇÊïôËÇ≤È¢ÜÂüüÁöÑÊô∫ËÉΩËæÖÂØºÁ≥ªÁªü„ÄÅÊú∫Âô®‰∫∫ÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü‰ª•ÂèäÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂàÜÊûêÁ≠â„ÄÇÂÖ∂È´òÊïàÁöÑÂ•ñÂä±Ê®°ÂûãËÆæËÆ°Â∞ÜÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ïÔºåÊèêÂçáÊô∫ËÉΩÁ≥ªÁªüÁöÑÊé®ÁêÜËÉΩÂäõÂíåÂáÜÁ°ÆÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> We present Athena-PRM, a multimodal process reward model (PRM) designed to evaluate the reward score for each step in solving complex reasoning problems. Developing high-performance PRMs typically demands significant time and financial investment, primarily due to the necessity for step-level annotations of reasoning steps. Conventional automated labeling methods, such as Monte Carlo estimation, often produce noisy labels and incur substantial computational costs. To efficiently generate high-quality process-labeled data, we propose leveraging prediction consistency between weak and strong completers as a criterion for identifying reliable process labels. Remarkably, Athena-PRM demonstrates outstanding effectiveness across various scenarios and benchmarks with just 5,000 samples. Furthermore, we also develop two effective strategies to improve the performance of PRMs: ORM initialization and up-sampling for negative data. We validate our approach in three specific scenarios: verification for test time scaling, direct evaluation of reasoning step correctness, and reward ranked fine-tuning. Our Athena-PRM consistently achieves superior performance across multiple benchmarks and scenarios. Notably, when using Qwen2.5-VL-7B as the policy model, Athena-PRM enhances performance by 10.2 points on WeMath and 7.1 points on MathVista for test time scaling. Furthermore, Athena-PRM sets the state-of-the-art (SoTA) results in VisualProcessBench and outperforms the previous SoTA by 3.9 F1-score, showcasing its robust capability to accurately assess the correctness of the reasoning step. Additionally, utilizing Athena-PRM as the reward model, we develop Athena-7B with reward ranked fine-tuning and outperforms baseline with a significant margin on five benchmarks.

