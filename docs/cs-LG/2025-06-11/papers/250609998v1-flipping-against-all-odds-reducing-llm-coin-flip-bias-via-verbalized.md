---
layout: default
title: Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling
---

# Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.09998" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.09998v1</a>
  <a href="https://arxiv.org/pdf/2506.09998.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.09998v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.09998v1', 'Flipping Against All Odds: Reducing LLM Coin Flip Bias via Verbalized Rejection Sampling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tim Z. Xiao, Johannes Zenn, Zhen Liu, Weiyang Liu, Robert Bamler, Bernhard SchÃ¶lkopf

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-11

**å¤‡æ³¨**: Technical Report v1 (21 pages, 14 figures)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå£å¤´æ‹’ç»é‡‡æ ·ä»¥è§£å†³LLMé‡‡æ ·åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ‹’ç»é‡‡æ ·` `æ¦‚ç‡åˆ†å¸ƒ` `éšæœºå†³ç­–` `è’™ç‰¹å¡æ´›æ–¹æ³•` `æ ·æœ¬ç”Ÿæˆ` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ¦‚ç‡åˆ†å¸ƒæ ·æœ¬æ—¶å­˜åœ¨åå·®ï¼Œé™åˆ¶äº†å…¶åœ¨éšæœºå†³ç­–å’Œæ¨¡æ‹Ÿä¸­çš„åº”ç”¨ã€‚
2. æå‡ºå£å¤´æ‹’ç»é‡‡æ ·ï¼ˆVRSï¼‰ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€å¼•å¯¼LLMå¯¹æ ·æœ¬è¿›è¡Œæ¨ç†å’Œé€‰æ‹©ï¼Œä»è€Œå‡å°‘é‡‡æ ·åå·®ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒVRSåœ¨å¤šä¸ªæ¨¡å‹ä¸Šæ˜¾è‘—é™ä½äº†é‡‡æ ·åå·®ï¼Œæå‡äº†æ ·æœ¬ç”Ÿæˆçš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸èƒ½å¤Ÿå‡†ç¡®æè¿°æ¦‚ç‡åˆ†å¸ƒï¼Œä½†åœ¨ç”ŸæˆçœŸå®æ ·æœ¬æ–¹é¢å­˜åœ¨å›°éš¾ã€‚è¿™ç§ä¸åŒ¹é…é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦å¯é éšæœºæ€§çš„ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¦‚è’™ç‰¹å¡æ´›æ–¹æ³•å’ŒåŸºäºä»£ç†çš„æ¨¡æ‹Ÿã€‚æœ¬æ–‡ç ”ç©¶äº†ä¼¯åŠªåˆ©åˆ†å¸ƒä¸‹çš„çŸ¥è¯†ä¸é‡‡æ ·ä¹‹é—´çš„å·®è·ï¼Œæå‡ºäº†å£å¤´æ‹’ç»é‡‡æ ·ï¼ˆVRSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§è‡ªç„¶è¯­è¨€é€‚åº”ç»å…¸æ‹’ç»é‡‡æ ·çš„æ–¹æ³•ï¼Œä¿ƒä½¿LLMå¯¹æè®®çš„æ ·æœ¬è¿›è¡Œæ¨ç†å¹¶æ¥å—æˆ–æ‹’ç»ã€‚å°½ç®¡å†…éƒ¨ä»ä¾èµ–ç›¸åŒçš„ä¼¯åŠªåˆ©æœºåˆ¶ï¼ŒVRSæ˜¾è‘—å‡å°‘äº†æ¨¡å‹é—´çš„é‡‡æ ·åå·®ã€‚æˆ‘ä»¬æä¾›äº†ç†è®ºåˆ†æï¼Œè¡¨æ˜åœ¨æ¸©å’Œå‡è®¾ä¸‹ï¼ŒVRSåœ¨ç›´æ¥é‡‡æ ·ä¸Šæœ‰æ‰€æ”¹è¿›ï¼Œæ”¶ç›Šå½’å› äºç®—æ³•å’Œæç¤ºè®¾è®¡ã€‚æ›´å¹¿æ³›åœ°è¯´ï¼Œæˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†å¦‚ä½•å°†ç»å…¸æ¦‚ç‡å·¥å…·å£å¤´åŒ–å¹¶åµŒå…¥LLMå·¥ä½œæµç¨‹ä¸­ï¼Œä»¥æé«˜å¯é æ€§ï¼Œè€Œæ— éœ€è®¿é—®æ¨¡å‹å†…éƒ¨æˆ–è¿›è¡Œå¤æ‚çš„æç¤ºå·¥ç¨‹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ ·æœ¬æ—¶çš„åå·®é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨éšæœºæ€§å’Œå¯é æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå£å¤´æ‹’ç»é‡‡æ ·ï¼ˆVRSï¼‰ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºå¼•å¯¼æ¨¡å‹å¯¹æ ·æœ¬è¿›è¡Œæ¨ç†ï¼Œæ¥å—æˆ–æ‹’ç»æè®®çš„æ ·æœ¬ï¼Œä»è€Œæé«˜ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVRSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ ·æœ¬ç”Ÿæˆã€æ¨ç†è¿‡ç¨‹å’Œæ¥å—/æ‹’ç»å†³ç­–ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼Œæ¨¡å‹é¦–å…ˆç”Ÿæˆæ ·æœ¬ï¼Œç„¶åè¿›è¡Œæ¨ç†ï¼Œæœ€åæ ¹æ®æ¨ç†ç»“æœå†³å®šæ˜¯å¦æ¥å—æ ·æœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šVRSçš„åˆ›æ–°åœ¨äºå°†ç»å…¸æ‹’ç»é‡‡æ ·æ–¹æ³•ä¸è‡ªç„¶è¯­è¨€å¤„ç†ç»“åˆï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸ä¾èµ–å†…éƒ¨æœºåˆ¶çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡è¯­è¨€ç†è§£æ¥å‡å°‘é‡‡æ ·åå·®ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨VRSä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æç¤ºç»“æ„ï¼Œä»¥å¼•å¯¼æ¨¡å‹è¿›è¡Œæœ‰æ•ˆçš„æ¨ç†ï¼Œå¹¶è®¾ç½®äº†é€‚å½“çš„å‚æ•°ä»¥ä¼˜åŒ–æ ·æœ¬æ¥å—ç‡ï¼Œç¡®ä¿ç”Ÿæˆçš„æ ·æœ¬æ›´ç¬¦åˆçœŸå®æ¦‚ç‡åˆ†å¸ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVRSåœ¨å¤šä¸ªå¤§å‹è¯­è¨€æ¨¡å‹ä¸Šæ˜¾è‘—é™ä½äº†é‡‡æ ·åå·®ï¼Œæå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿç›´æ¥é‡‡æ ·æ–¹æ³•ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„æ ·æœ¬è´¨é‡å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå†³ç­–ã€æ¸¸æˆæ¨¡æ‹Ÿå’Œç§‘å­¦è®¡ç®—ç­‰éœ€è¦éšæœºæ€§çš„ä»»åŠ¡ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ ·æœ¬ç”Ÿæˆä¸­çš„å¯é æ€§ï¼ŒVRSå¯ä»¥ä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´å‡†ç¡®çš„å†³ç­–æ”¯æŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) can often accurately describe probability distributions using natural language, yet they still struggle to generate faithful samples from them. This mismatch limits their use in tasks requiring reliable stochasticity, such as Monte Carlo methods, agent-based simulations, and randomized decision-making. We investigate this gap between knowledge and sampling in the context of Bernoulli distributions. We introduce Verbalized Rejection Sampling (VRS), a natural-language adaptation of classical rejection sampling that prompts the LLM to reason about and accept or reject proposed samples. Despite relying on the same Bernoulli mechanism internally, VRS substantially reduces sampling bias across models. We provide theoretical analysis showing that, under mild assumptions, VRS improves over direct sampling, with gains attributable to both the algorithm and prompt design. More broadly, our results show how classical probabilistic tools can be verbalized and embedded into LLM workflows to improve reliability, without requiring access to model internals or heavy prompt engineering.

