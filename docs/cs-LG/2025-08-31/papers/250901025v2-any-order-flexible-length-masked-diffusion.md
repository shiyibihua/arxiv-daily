---
layout: default
title: Any-Order Flexible Length Masked Diffusion
---

# Any-Order Flexible Length Masked Diffusion

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01025" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01025v2</a>
  <a href="https://arxiv.org/pdf/2509.01025.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01025v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01025v2', 'Any-Order Flexible Length Masked Diffusion')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jaeyeon Kim, Lee Cheuk-Kit, Carles Domingo-Enrich, Yilun Du, Sham Kakade, Timothy Ngotiaoco, Sitan Chen, Michael Albergo

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-31 (æ›´æ–°: 2025-09-07)

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçµæ´»çš„æ©ç æ‰©æ•£æ¨¡å‹ä»¥è§£å†³å›ºå®šé•¿åº¦ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æ©ç æ‰©æ•£æ¨¡å‹` `çµæ´»ç”Ÿæˆ` `åºåˆ—å»ºæ¨¡` `è‡ªç„¶è¯­è¨€å¤„ç†` `ä»£ç ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰æ— æ³•æ”¯æŒä»¤ç‰Œæ’å…¥ï¼Œé™åˆ¶äº†ç”Ÿæˆé•¿åº¦çš„çµæ´»æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„çµæ´»æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆFlexMDMsï¼‰é€šè¿‡æ’å…¥å’Œè§£æ©ç ä»¤ç‰Œï¼Œå®ç°äº†çµæ´»é•¿åº¦åºåˆ—çš„ç”Ÿæˆã€‚
3. åœ¨åˆæˆè¿·å®«è§„åˆ’ä»»åŠ¡ä¸­ï¼ŒFlexMDMsçš„æˆåŠŸç‡æ¯”MDMåŸºçº¿é«˜å‡ºçº¦60%ï¼Œå¹¶åœ¨æ•°å­¦å’Œä»£ç å¡«å……ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰ä½œä¸ºè‡ªå›å½’æ¨¡å‹åœ¨ç¦»æ•£é¢†åŸŸçš„æ›¿ä»£æ–¹æ¡ˆï¼Œèƒ½å¤Ÿä»¥ä»»æ„é¡ºåºå¹¶è¡Œç”Ÿæˆåºåˆ—ï¼Œé€‚ç”¨äºéå› æœä»»åŠ¡ã€‚ç„¶è€Œï¼ŒMDMsçš„ä¸€ä¸ªé‡è¦å±€é™æ˜¯æ— æ³•æ”¯æŒä»¤ç‰Œæ’å…¥ï¼Œå¯¼è‡´ç”Ÿæˆé•¿åº¦å›ºå®šã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†çµæ´»æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆFlexMDMsï¼‰ï¼Œè¯¥æ¨¡å‹èƒ½å¤ŸåŒæ—¶å»ºæ¨¡çµæ´»é•¿åº¦çš„åºåˆ—ï¼ŒåŒæ—¶ä¿æŒMDMsçš„ä»»æ„é¡ºåºæ¨ç†èƒ½åŠ›ã€‚åŸºäºéšæœºæ’å€¼æ¡†æ¶çš„æ‰©å±•ï¼ŒFlexMDMsé€šè¿‡æ’å…¥æ©ç ä»¤ç‰Œå¹¶è§£æ©ç æ¥ç”Ÿæˆåºåˆ—ã€‚å®éªŒè¯æ˜ï¼ŒFlexMDMsåœ¨å›°æƒ‘åº¦ä¸Šä¸MDMsç›¸å½“ï¼ŒåŒæ—¶åœ¨é•¿åº¦ç»Ÿè®¡å»ºæ¨¡ä¸Šå…·æœ‰æ›´é«˜çš„ä¿çœŸåº¦ã€‚åœ¨åˆæˆè¿·å®«è§„åˆ’ä»»åŠ¡ä¸­ï¼ŒFlexMDMsçš„æˆåŠŸç‡æ¯”MDMåŸºçº¿é«˜å‡ºçº¦60%ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†é¢„è®­ç»ƒçš„MDMså¯ä»¥è½»æ¾æ”¹è£…ä¸ºFlexMDMsï¼šåœ¨16ä¸ªH100ä¸Šï¼Œä»…éœ€ä¸‰å¤©å³å¯å°†LLaDA-8Bå¾®è°ƒä¸ºFlexMDMï¼Œåœ¨æ•°å­¦ï¼ˆGSM8Kï¼Œ58%æå‡è‡³67%ï¼‰å’Œä»£ç å¡«å……æ€§èƒ½ï¼ˆ52%æå‡è‡³65%ï¼‰ä¸Šå–å¾—äº†ä¼˜è¶Šçš„è¡¨ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆMDMsï¼‰åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­æ— æ³•æ”¯æŒä»¤ç‰Œæ’å…¥çš„é—®é¢˜ï¼Œå¯¼è‡´ç”Ÿæˆé•¿åº¦å›ºå®šï¼Œé™åˆ¶äº†æ¨¡å‹çš„çµæ´»æ€§å’Œåº”ç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçµæ´»æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆFlexMDMsï¼‰ï¼Œé€šè¿‡æ’å…¥æ©ç ä»¤ç‰Œå¹¶è§£æ©ç çš„æ–¹å¼ï¼Œå…è®¸æ¨¡å‹ç”Ÿæˆå¯å˜é•¿åº¦çš„åºåˆ—ï¼ŒåŒæ—¶ä¿æŒä»»æ„é¡ºåºæ¨ç†çš„èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFlexMDMsçš„æ•´ä½“æ¶æ„åŸºäºéšæœºæ’å€¼æ¡†æ¶çš„æ‰©å±•ï¼Œä¸»è¦åŒ…æ‹¬æ©ç ä»¤ç‰Œçš„æ’å…¥æ¨¡å—å’Œè§£æ©ç æ¨¡å—ï¼Œç¡®ä¿ç”Ÿæˆè¿‡ç¨‹çš„çµæ´»æ€§ä¸é«˜æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šFlexMDMsçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶èƒ½å¤Ÿåœ¨ä¿æŒMDMsçµæ´»æ€§çš„åŒæ—¶ï¼Œå®ç°å¯å˜é•¿åº¦åºåˆ—çš„ç”Ÿæˆï¼Œè¿™ä¸€ç‰¹æ€§åœ¨ç°æœ‰æ¨¡å‹ä¸­å°šæœªå®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼ŒFlexMDMsé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç”Ÿæˆè´¨é‡ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥é€‚åº”æ©ç ä»¤ç‰Œçš„æ’å…¥ä¸è§£æ©ç è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FlexMDMsåœ¨åˆæˆè¿·å®«è§„åˆ’ä»»åŠ¡ä¸­æˆåŠŸç‡æ¯”MDMåŸºçº¿é«˜å‡ºçº¦60%ã€‚æ­¤å¤–ï¼ŒFlexMDMsåœ¨æ•°å­¦ï¼ˆGSM8Kï¼‰å’Œä»£ç å¡«å……ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåˆ†åˆ«å°†å‡†ç¡®ç‡ä»58%æå‡è‡³67%å’Œä»52%æå‡è‡³65%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

çµæ´»æ©ç æ‰©æ•£æ¨¡å‹ï¼ˆFlexMDMsï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ã€ä»£ç ç”Ÿæˆå’Œå…¶ä»–åºåˆ—ç”Ÿæˆä»»åŠ¡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶çµæ´»çš„ç”Ÿæˆé•¿åº¦å’Œé«˜æ•ˆçš„æ¨ç†èƒ½åŠ›ä½¿å…¶èƒ½å¤Ÿé€‚åº”å¤šç§å®é™…åœºæ™¯ï¼Œæå‡ç”Ÿæˆè´¨é‡å’Œæ•ˆç‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Masked diffusion models (MDMs) have recently emerged as a promising alternative to autoregressive models over discrete domains. MDMs generate sequences in an any-order, parallel fashion, enabling fast inference and strong performance on non-causal tasks. However, a crucial limitation is that they do not support token insertions and are thus limited to fixed-length generations. To this end, we introduce Flexible Masked Diffusion Models (FlexMDMs), a discrete diffusion paradigm that simultaneously can model sequences of flexible length while provably retaining MDMs' flexibility of any-order inference. Grounded in an extension of the stochastic interpolant framework, FlexMDMs generate sequences by inserting mask tokens and unmasking them. Empirically, we show that FlexMDMs match MDMs in perplexity while modeling length statistics with much higher fidelity. On a synthetic maze planning task, they achieve $\approx 60 \%$ higher success rate than MDM baselines. Finally, we show pretrained MDMs can easily be retrofitted into FlexMDMs: on 16 H100s, it takes only three days to fine-tune LLaDA-8B into a FlexMDM, achieving superior performance on math (GSM8K, $58\% \to 67\%$) and code infilling performance ($52\% \to 65\%$).

