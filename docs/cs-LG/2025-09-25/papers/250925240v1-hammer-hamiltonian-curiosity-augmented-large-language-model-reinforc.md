---
layout: default
title: HAMMER: Hamiltonian Curiosity Augmented Large Language Model Reinforcement
---

# HAMMER: Hamiltonian Curiosity Augmented Large Language Model Reinforcement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25240" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25240v1</a>
  <a href="https://arxiv.org/pdf/2509.25240.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25240v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25240v1', 'HAMMER: Hamiltonian Curiosity Augmented Large Language Model Reinforcement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ming Yang, Xiaofan Li, Zhiyuan Ma, Dengliang Shi, Jintao Du, Yu Cheng, Weiguo Zheng

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-25

**å¤‡æ³¨**: 20 pages, 7 figures, 4 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**HAMMERï¼šåŸºäºå“ˆå¯†é¡¿å¥½å¥‡å¿ƒå¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `è¯¾ç¨‹å­¦ä¹ ` `å¤šæ ·æ€§` `å“ˆå¯†é¡¿è·¯å¾„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºéš¾åº¦çš„è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ æ–¹æ³•æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå¯¼è‡´æ¨¡å‹æ¢ç´¢èƒ½åŠ›ä¸è¶³ã€‚
2. HAMMERå°†æ•°æ®é›†å¤šæ ·æ€§æŒ‡æ ‡å¼•å…¥å¼ºåŒ–å­¦ä¹ ï¼Œé€šè¿‡å“ˆå¯†é¡¿è·¯å¾„æ’åºæ ·æœ¬ï¼Œé¼“åŠ±æ—©æœŸæ¢ç´¢ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒHAMMERèƒ½æœ‰æ•ˆæå‡æ¨¡å‹â€œå¥½å¥‡å¿ƒâ€ï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡3%-4%çš„å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è¯¾ç¨‹å¼ºåŒ–å­¦ä¹ é€šå¸¸ä¾èµ–äºåŸºäºéš¾åº¦çš„æ ‡æ³¨æ¥è¿›è¡Œæ•°æ®è¿‡æ»¤å’Œæ’åºã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•å®¹æ˜“é™·å…¥å±€éƒ¨ä¼˜åŒ–ï¼Œæ—©æœŸæ­¥éª¤ä¸­å¯¹ç®€å•æ ·æœ¬çš„æŒç»­è®­ç»ƒå¯èƒ½å¯¼è‡´ç­–ç•¥å¤±å»æ¢ç´¢èƒ½åŠ›ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ¡ˆï¼Œå³å“ˆå¯†é¡¿å¥½å¥‡å¿ƒå¢å¼ºçš„å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ ï¼ˆHAMMERï¼‰ï¼Œå®ƒå°†é€šå¸¸ç”¨äºæ•°æ®é›†è¯„ä¼°çš„å¤šæ ·æ€§æŒ‡æ ‡è½¬ç§»åˆ°åŠ¨æ€å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œå…¶ä¸­è®­ç»ƒæ ·æœ¬é€šè¿‡æœ€å°è¯­ä¹‰å“ˆå¯†é¡¿è·¯å¾„è¿›è¡Œæ’åºï¼Œä½¿å¾—åˆå§‹è®­ç»ƒèƒ½å¤Ÿè¿›è¡Œæ›´å¤šçš„æ¢ç´¢ã€‚ä»æ³›åŒ–ç•Œé™çš„ç†è®ºè§’åº¦æ¥çœ‹ï¼Œå¤šæ ·æ€§é©±åŠ¨çš„æ’åºæœ‰åŠ©äºç¨³å®šçš„æ”¶æ•›ã€‚ç»éªŒè¯„ä¼°è¡¨æ˜ï¼ŒHAMMERæ¿€å‘äº†æ¨¡å‹çš„â€œå¥½å¥‡å¿ƒâ€ï¼Œå¹¶åœ¨ä¸åŒçš„æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å§‹ç»ˆå®ç°äº†3%åˆ°4%çš„å¹³å‡å‡†ç¡®ç‡æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼Œä¾èµ–äºæ ·æœ¬éš¾åº¦è¿›è¡Œæ’åºï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚æ¨¡å‹åœ¨æ—©æœŸé˜¶æ®µè¿‡åº¦å…³æ³¨ç®€å•æ ·æœ¬ï¼Œå¯¼è‡´åæœŸæ¢ç´¢èƒ½åŠ›ä¸‹é™ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨æ•°æ®ä¸­çš„ä¿¡æ¯ï¼Œæœ€ç»ˆå½±å“æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHAMMERçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ•°æ®é›†å¤šæ ·æ€§å¼•å…¥å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œé€šè¿‡é¼“åŠ±æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸæ¢ç´¢æ›´å¤šä¸åŒçš„æ ·æœ¬ï¼Œæ¥é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒåˆ©ç”¨å“ˆå¯†é¡¿è·¯å¾„æ¥æ’åºè®­ç»ƒæ ·æœ¬ï¼Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒåˆæœŸèƒ½å¤Ÿæ¥è§¦åˆ°æ›´å¤šå…·æœ‰ä»£è¡¨æ€§çš„æ ·æœ¬ï¼Œä»è€Œæ¿€å‘æ¨¡å‹çš„â€œå¥½å¥‡å¿ƒâ€ï¼Œæå‡æ¢ç´¢èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHAMMERçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) ä½¿ç”¨å¤šæ ·æ€§æŒ‡æ ‡ï¼ˆä¾‹å¦‚ï¼ŒåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æŒ‡æ ‡ï¼‰è¯„ä¼°è®­ç»ƒæ•°æ®é›†çš„å¤šæ ·æ€§ï¼›2) æ„å»ºä¸€ä¸ªå›¾ï¼Œå…¶ä¸­èŠ‚ç‚¹ä»£è¡¨è®­ç»ƒæ ·æœ¬ï¼Œè¾¹ä»£è¡¨æ ·æœ¬ä¹‹é—´çš„è¯­ä¹‰è·ç¦»ï¼›3) ä½¿ç”¨å“ˆå¯†é¡¿è·¯å¾„ç®—æ³•åœ¨è¯¥å›¾ä¸Šæ‰¾åˆ°ä¸€æ¡æœ€å°è¯­ä¹‰è·ç¦»çš„è·¯å¾„ï¼Œä½œä¸ºè®­ç»ƒæ ·æœ¬çš„æ’åºï¼›4) ä½¿ç”¨è¯¥æ’åºåçš„æ ·æœ¬åºåˆ—è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šHAMMERçš„å…³é”®åˆ›æ–°åœ¨äºå°†æ•°æ®é›†å¤šæ ·æ€§æŒ‡æ ‡ä¸å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ç›¸ç»“åˆï¼Œå¹¶ä½¿ç”¨å“ˆå¯†é¡¿è·¯å¾„æ¥æŒ‡å¯¼æ ·æœ¬æ’åºã€‚è¿™ä¸ä¼ ç»Ÿçš„åŸºäºéš¾åº¦çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ä¸åŒï¼Œåè€…åªå…³æ³¨æ ·æœ¬çš„éš¾åº¦ï¼Œè€Œå¿½ç•¥äº†æ ·æœ¬ä¹‹é—´çš„å¤šæ ·æ€§ã€‚HAMMERé€šè¿‡é¼“åŠ±æ¨¡å‹æ¢ç´¢æ›´å¤šä¸åŒçš„æ ·æœ¬ï¼Œæ¥æå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šHAMMERçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¤šæ ·æ€§æŒ‡æ ‡çš„é€‰æ‹©ï¼šå¯ä»¥ä½¿ç”¨å„ç§åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦çš„æŒ‡æ ‡ï¼Œä¾‹å¦‚ï¼ŒåŸºäºBERTåµŒå…¥çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼›2) å“ˆå¯†é¡¿è·¯å¾„ç®—æ³•çš„é€‰æ‹©ï¼šå¯ä»¥ä½¿ç”¨å„ç§è¿‘ä¼¼ç®—æ³•æ¥å¯»æ‰¾å“ˆå¯†é¡¿è·¯å¾„ï¼Œä¾‹å¦‚ï¼Œæœ€è¿‘é‚»ç®—æ³•ï¼›3) å¼ºåŒ–å­¦ä¹ ç®—æ³•çš„é€‰æ‹©ï¼šå¯ä»¥ä½¿ç”¨å„ç§å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œä¾‹å¦‚ï¼ŒPPOæˆ–DQNï¼›4) å¥–åŠ±å‡½æ•°çš„è®¾è®¡ï¼šå¥–åŠ±å‡½æ•°å¯ä»¥æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè®¾è®¡ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨ä»»åŠ¡å®Œæˆçš„å¥–åŠ±æˆ–æ¢ç´¢æ–°çŠ¶æ€çš„å¥–åŠ±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HAMMERåœ¨å¤šä¸ªæ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡å‡†ç¡®ç‡æå‡äº†3%åˆ°4%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒHAMMERèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¿€å‘æ¨¡å‹çš„â€œå¥½å¥‡å¿ƒâ€ï¼Œæå‡æ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ã€‚ä¸ä¼ ç»Ÿçš„åŸºäºéš¾åº¦çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒHAMMERèƒ½å¤Ÿæ›´å¥½åœ°é¿å…é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œä»è€Œè·å¾—æ›´å¥½çš„è®­ç»ƒæ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HAMMERæ–¹æ³•å¯åº”ç”¨äºå„ç§éœ€è¦å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç­–ç•¥å­¦ä¹ çš„åœºæ™¯ï¼Œä¾‹å¦‚å¯¹è¯ç”Ÿæˆã€æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡æå‡æ¨¡å‹çš„æ¢ç´¢èƒ½åŠ›å’Œæ³›åŒ–æ€§èƒ½ï¼ŒHAMMERå¯ä»¥å¸®åŠ©å¤§è¯­è¨€æ¨¡å‹æ›´å¥½åœ°é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œç¯å¢ƒï¼Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚è¯¥æ–¹æ³•è¿˜æœ‰æ½œåŠ›åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€æ¸¸æˆAIç­‰é¢†åŸŸï¼Œæå‡æ™ºèƒ½ä½“çš„å­¦ä¹ æ•ˆç‡å’Œå†³ç­–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent curriculum reinforcement learning for large language models (LLMs) typically rely on difficulty-based annotations for data filtering and ordering. However, such methods suffer from local optimization, where continual training on simple samples in the early steps can cause the policy to lose its exploration. We propose a novel schema, namely Hamiltonian curiosity augmented large language model reinforcement (HAMMER), that transfers diversity metrics, commonly used in dataset evaluation, into the dynamic reinforcement learning procedure, where training samples are ordered via a minimum-semantic Hamiltonian path making the initial training retrain more exploration. From a theoretical perspective of generalization bounds, diversity-driven ordering facilitates stable convergence. Empirical evaluations indicate that HAMMER stimulates model "curiosity" and consistently achieves a 3% to 4% average accuracy gain across diverse inference benchmark.

