---
layout: default
title: time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models
---

# time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05801" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05801v2</a>
  <a href="https://arxiv.org/pdf/2509.05801.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05801v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05801v2', 'time2time: Causal Intervention in Hidden States to Simulate Rare Events in Time Series Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Debdeep Sanyal, Aaryan Nagpal, Dhruv Kumar, Murari Mandal, Saurabh Deshpande

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06 (æ›´æ–°: 2025-10-04)

**æœŸåˆŠ**: NeurIPS 2025 Workshop on Recent Advances in Time Series Foundation Models (BERT2S)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ—¶é—´åºåˆ—Transformeræ¨¡å‹çš„å› æœå¹²é¢„æ–¹æ³•ï¼Œæ¨¡æ‹Ÿç½•è§äº‹ä»¶å¹¶è¿›è¡Œå‹åŠ›æµ‹è¯•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `Transformeræ¨¡å‹` `å› æœå¹²é¢„` `æ¿€æ´»ç§»æ¤` `ç½•è§äº‹ä»¶æ¨¡æ‹Ÿ` `å‹åŠ›æµ‹è¯•` `é‡‘èé£é™©ç®¡ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ—¶é—´åºåˆ—Transformeræ¨¡å‹åœ¨é¢„æµ‹å¸¸è§„æ¨¡å¼æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†ç¼ºä¹å¯¹å¸‚åœºæœºåˆ¶ç­‰è¯­ä¹‰æ¦‚å¿µçš„ç†è§£ï¼Œéš¾ä»¥æ¨¡æ‹Ÿç½•è§äº‹ä»¶ã€‚
2. è®ºæ–‡æå‡ºæ¿€æ´»ç§»æ¤æ–¹æ³•ï¼Œé€šè¿‡å› æœå¹²é¢„æ“çºµéšè—çŠ¶æ€ï¼Œå°†ç‰¹å®šäº‹ä»¶çš„ç»Ÿè®¡ç‰¹å¾æ³¨å…¥åˆ°å…¶ä»–æ—¶é—´æ®µï¼Œä»è€Œæ§åˆ¶æ¨¡å‹çš„é¢„æµ‹è¡Œä¸ºã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ§åˆ¶æ¨¡å‹é¢„æµ‹ï¼Œæ³¨å…¥å´©ç›˜è¯­ä¹‰ä¼šé¢„æµ‹ä¸‹è·Œï¼Œæ³¨å…¥å¹³é™è¯­ä¹‰åˆ™æŠ‘åˆ¶å´©ç›˜ï¼ŒéªŒè¯äº†æ¨¡å‹å†…éƒ¨å­˜åœ¨å¯æ“çºµçš„è¯­ä¹‰è¡¨ç¤ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºâ€œæ¿€æ´»ç§»æ¤â€çš„å› æœå¹²é¢„æ–¹æ³•ï¼Œç”¨äºæ“çºµæ—¶é—´åºåˆ—TransformeråŸºç¡€æ¨¡å‹ä¸­çš„éšè—çŠ¶æ€ï¼Œä»¥æ¨¡æ‹Ÿç½•è§çš„é«˜é£é™©äº‹ä»¶ï¼Œä¾‹å¦‚å¸‚åœºå´©ç›˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†ä¸€ä¸ªäº‹ä»¶ï¼ˆå¦‚å†å²å´©ç›˜ï¼‰çš„ç»Ÿè®¡çŸ©å¼ºåŠ åˆ°å¦ä¸€ä¸ªäº‹ä»¶ï¼ˆå¦‚å¹³é™æœŸï¼‰çš„éšè—çŠ¶æ€ä¸Šï¼Œä»è€Œåœ¨æ¨¡å‹å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ç¡®å®šæ€§åœ°å¼•å¯¼é¢„æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ³¨å…¥å´©ç›˜è¯­ä¹‰ä¼šè¯±å¯¼ä¸‹è·Œé¢„æµ‹ï¼Œè€Œæ³¨å…¥å¹³é™è¯­ä¹‰ä¼šæŠ‘åˆ¶å´©ç›˜å¹¶æ¢å¤ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹ç¼–ç äº†äº‹ä»¶ä¸¥é‡ç¨‹åº¦çš„åˆ†çº§æ¦‚å¿µï¼Œæ½œåœ¨å‘é‡èŒƒæ•°ä¸ç³»ç»Ÿæ€§å†²å‡»çš„å¹…åº¦ç›´æ¥ç›¸å…³ã€‚è¯¥æ–¹æ³•åœ¨Totoï¼ˆä»…è§£ç å™¨ï¼‰å’ŒChronosï¼ˆç¼–ç å™¨-è§£ç å™¨ï¼‰ä¸¤ç§æ¶æ„ä¸åŒçš„æ—¶é—´åºåˆ—Transformeræ¨¡å‹ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œè¯æ˜äº†å¯æ“çºµçš„ã€è¯­ä¹‰åŒ–çš„è¡¨ç¤ºæ˜¯å¤§è§„æ¨¡æ—¶é—´åºåˆ—Transformeræ¨¡å‹çš„ç¨³å¥å±æ€§ã€‚è¯¥ç ”ç©¶ä¸ºæ½œåœ¨æ¦‚å¿µç©ºé—´æä¾›äº†è¯æ®ï¼Œå°†å¯è§£é‡Šæ€§ä»äº‹åå½’å› è½¬å˜ä¸ºç›´æ¥å› æœå¹²é¢„ï¼Œå¹¶ä¸ºæˆ˜ç•¥å‹åŠ›æµ‹è¯•å®ç°äº†è¯­ä¹‰â€œå‡è®¾åˆ†æâ€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ—¶é—´åºåˆ—Transformeræ¨¡å‹è™½ç„¶åœ¨é¢„æµ‹å¸¸è§æ¨¡å¼ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†ç¼ºä¹å¯¹æ·±å±‚è¯­ä¹‰æ¦‚å¿µçš„ç†è§£ï¼Œä¾‹å¦‚å¸‚åœºçŠ¶æ€ã€‚è¿™å¯¼è‡´å®ƒä»¬éš¾ä»¥æ¨¡æ‹Ÿç½•è§ä¸”é«˜é£é™©çš„äº‹ä»¶ï¼Œä¾‹å¦‚å¸‚åœºå´©ç›˜ã€‚ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•é€šå¸¸æ˜¯äº‹åå½’å› ï¼Œæ— æ³•è¿›è¡Œä¸»åŠ¨çš„å¹²é¢„å’Œæ§åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å› æœå¹²é¢„æ¥æ“çºµæ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºï¼Œå…·ä½“æ¥è¯´ï¼Œå°±æ˜¯é€šè¿‡â€œæ¿€æ´»ç§»æ¤â€æŠ€æœ¯ï¼Œå°†ä¸€ä¸ªäº‹ä»¶ï¼ˆä¾‹å¦‚å†å²å´©ç›˜ï¼‰çš„ç»Ÿè®¡ç‰¹å¾ï¼ˆä¾‹å¦‚å‡å€¼å’Œæ–¹å·®ï¼‰æ³¨å…¥åˆ°å¦ä¸€ä¸ªäº‹ä»¶ï¼ˆä¾‹å¦‚å¹³é™æ—¶æœŸï¼‰çš„éšè—çŠ¶æ€ä¸­ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥åœ¨ä¸æ”¹å˜è¾“å…¥æ•°æ®çš„æƒ…å†µä¸‹ï¼Œç›´æ¥å½±å“æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œä»è€Œæ¨¡æ‹Ÿç½•è§äº‹ä»¶çš„å‘ç”Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) é€‰æ‹©æºäº‹ä»¶å’Œç›®æ ‡äº‹ä»¶ï¼›2) æå–æºäº‹ä»¶åœ¨æ¨¡å‹éšè—å±‚ä¸­çš„ç»Ÿè®¡çŸ©ï¼ˆå‡å€¼å’Œæ–¹å·®ï¼‰ï¼›3) å°†è¿™äº›ç»Ÿè®¡çŸ©åº”ç”¨åˆ°ç›®æ ‡äº‹ä»¶çš„éšè—çŠ¶æ€ä¸­ï¼Œå³å¯¹ç›®æ ‡äº‹ä»¶çš„éšè—çŠ¶æ€è¿›è¡Œæ ‡å‡†åŒ–ï¼Œç„¶åä½¿ç”¨æºäº‹ä»¶çš„å‡å€¼å’Œæ–¹å·®è¿›è¡Œç¼©æ”¾å’Œå¹³ç§»ï¼›4) ä½¿ç”¨ä¿®æ”¹åçš„éšè—çŠ¶æ€è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè§‚å¯Ÿæ¨¡å‹é¢„æµ‹ç»“æœçš„å˜åŒ–ã€‚è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºä¸åŒçš„Transformeræ¶æ„ï¼Œä¾‹å¦‚ä»…è§£ç å™¨çš„Totoå’Œç¼–ç å™¨-è§£ç å™¨çš„Chronosã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå®ƒæä¾›äº†ä¸€ç§ç›´æ¥çš„å› æœå¹²é¢„æ‰‹æ®µï¼Œå¯ä»¥æ“çºµæ—¶é—´åºåˆ—Transformeræ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºï¼Œä»è€Œæ§åˆ¶æ¨¡å‹çš„é¢„æµ‹è¡Œä¸ºã€‚ä¸ä¼ ç»Ÿçš„äº‹åå½’å› æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•å…è®¸ç ”ç©¶äººå‘˜ä¸»åŠ¨åœ°æ”¹å˜æ¨¡å‹çš„å†…éƒ¨çŠ¶æ€ï¼Œå¹¶è§‚å¯Ÿè¿™äº›æ”¹å˜å¯¹é¢„æµ‹ç»“æœçš„å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æ­ç¤ºäº†æ¨¡å‹å†…éƒ¨å­˜åœ¨ä¸€ä¸ªè¯­ä¹‰æ¦‚å¿µç©ºé—´ï¼Œå…¶ä¸­äº‹ä»¶çš„ä¸¥é‡ç¨‹åº¦ä¸æ½œåœ¨å‘é‡çš„èŒƒæ•°ç›´æ¥ç›¸å…³ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¿€æ´»ç§»æ¤çš„å…³é”®åœ¨äºå¦‚ä½•é€‰æ‹©åˆé€‚çš„éšè—å±‚è¿›è¡Œå¹²é¢„ï¼Œä»¥åŠå¦‚ä½•è®¡ç®—å’Œåº”ç”¨ç»Ÿè®¡çŸ©ã€‚è®ºæ–‡ä¸­ä½¿ç”¨äº†æ‰€æœ‰Transformerå±‚çš„éšè—çŠ¶æ€ï¼Œå¹¶è®¡ç®—äº†æ¯ä¸€å±‚çš„å‡å€¼å’Œæ–¹å·®ã€‚åœ¨åº”ç”¨ç»Ÿè®¡çŸ©æ—¶ï¼Œä½¿ç”¨äº†æ ‡å‡†åŒ–çš„æ–¹æ³•ï¼Œä»¥ç¡®ä¿å¹²é¢„çš„æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†ä¸åŒäº‹ä»¶ä¸¥é‡ç¨‹åº¦å¯¹é¢„æµ‹ç»“æœçš„å½±å“ï¼Œå‘ç°æ½œåœ¨å‘é‡çš„èŒƒæ•°ä¸ç³»ç»Ÿæ€§å†²å‡»çš„å¹…åº¦ç›´æ¥ç›¸å…³ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ¿€æ´»ç§»æ¤æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ§åˆ¶æ—¶é—´åºåˆ—Transformeræ¨¡å‹çš„é¢„æµ‹è¡Œä¸ºã€‚ä¾‹å¦‚ï¼Œæ³¨å…¥å´©ç›˜è¯­ä¹‰å¯ä»¥è¯±å¯¼ä¸‹è·Œé¢„æµ‹ï¼Œè€Œæ³¨å…¥å¹³é™è¯­ä¹‰å¯ä»¥æŠ‘åˆ¶å´©ç›˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°æ¨¡å‹ç¼–ç äº†äº‹ä»¶ä¸¥é‡ç¨‹åº¦çš„åˆ†çº§æ¦‚å¿µï¼Œæ½œåœ¨å‘é‡èŒƒæ•°ä¸ç³»ç»Ÿæ€§å†²å‡»çš„å¹…åº¦ç›´æ¥ç›¸å…³ã€‚è¯¥æ–¹æ³•åœ¨Totoå’ŒChronosä¸¤ç§æ¶æ„ä¸åŒçš„æ¨¡å‹ä¸Šéƒ½å–å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé‡‘èé£é™©ç®¡ç†ã€å‹åŠ›æµ‹è¯•ã€å¼‚å¸¸æ£€æµ‹ç­‰é¢†åŸŸã€‚é€šè¿‡æ¨¡æ‹Ÿç½•è§äº‹ä»¶ï¼Œå¯ä»¥è¯„ä¼°é‡‘èç³»ç»Ÿåœ¨æç«¯æƒ…å†µä¸‹çš„ç¨³å®šæ€§ï¼Œå¹¶ä¸ºåˆ¶å®šé£é™©åº”å¯¹ç­–ç•¥æä¾›ä¾æ®ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºé¢„æµ‹è®¾å¤‡æ•…éšœã€ç½‘ç»œæ”»å‡»ç­‰äº‹ä»¶ï¼Œæé«˜ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While transformer-based foundation models excel at forecasting routine patterns, two questions remain: do they internalize semantic concepts such as market regimes, or merely fit curves? And can their internal representations be leveraged to simulate rare, high-stakes events such as market crashes? To investigate this, we introduce activation transplantation, a causal intervention that manipulates hidden states by imposing the statistical moments of one event (e.g., a historical crash) onto another (e.g., a calm period) during the forward pass. This procedure deterministically steers forecasts: injecting crash semantics induces downturn predictions, while injecting calm semantics suppresses crashes and restores stability. Beyond binary control, we find that models encode a graded notion of event severity, with the latent vector norm directly correlating with the magnitude of systemic shocks. Validated across two architecturally distinct TSFMs, Toto (decoder only) and Chronos (encoder-decoder), our results demonstrate that steerable, semantically grounded representations are a robust property of large time series transformers. Our findings provide evidence for a latent concept space that governs model predictions, shifting interpretability from post-hoc attribution to direct causal intervention, and enabling semantic "what-if" analysis for strategic stress-testing.

