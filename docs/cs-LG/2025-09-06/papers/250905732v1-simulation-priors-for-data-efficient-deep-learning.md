---
layout: default
title: Simulation Priors for Data-Efficient Deep Learning
---

# Simulation Priors for Data-Efficient Deep Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05732" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05732v1</a>
  <a href="https://arxiv.org/pdf/2509.05732.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05732v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05732v1', 'Simulation Priors for Data-Efficient Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lenart Treven, Bhavya Sukhija, Jonas Rothfuss, Stelian Coros, Florian DÃ¶rfler, Andreas Krause

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SimPELï¼šåˆ©ç”¨ä»¿çœŸå…ˆéªŒæå‡æ·±åº¦å­¦ä¹ åœ¨æ•°æ®ç¨€ç¼ºåœºæ™¯ä¸‹çš„æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ä»¿çœŸå…ˆéªŒ` `è´å¶æ–¯æ·±åº¦å­¦ä¹ ` `æ•°æ®é«˜æ•ˆå­¦ä¹ ` `æ¨¡å‹é¢„æµ‹` `å¼ºåŒ–å­¦ä¹ ` `Sim-to-Real` `ä¸ç¡®å®šæ€§é‡åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨ä¼°è®¡å¤æ‚åŠ¨åŠ›å­¦æ—¶éœ€è¦å¤§é‡å…·æœ‰ä»£è¡¨æ€§çš„æ•°æ®é›†ï¼Œè€Œç¬¬ä¸€æ€§åŸç†æ¨¡å‹è™½ç„¶å¹¿æ³›ç”¨äºæ¨¡æ‹Ÿè‡ªç„¶ç³»ç»Ÿï¼Œä½†ç”±äºç®€åŒ–å‡è®¾ï¼Œå¾€å¾€æ— æ³•æ•æ‰çœŸå®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚
2. SimPELçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä½ä¿çœŸåº¦ä»¿çœŸå™¨ä½œä¸ºè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„å…ˆéªŒçŸ¥è¯†ï¼Œä»è€Œåœ¨æ•°æ®é‡è¾ƒå°‘æ—¶åˆ©ç”¨ä»¿çœŸå™¨çš„çŸ¥è¯†ï¼Œå¹¶åœ¨æ•°æ®é‡å……è¶³æ—¶å‘æŒ¥æ·±åº¦å­¦ä¹ çš„çµæ´»æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSimPELåœ¨ç”Ÿç‰©ã€å†œä¸šå’Œæœºå™¨äººç­‰å¤šä¸ªé¢†åŸŸå­¦ä¹ å¤æ‚åŠ¨åŠ›å­¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶åœ¨é«˜é€Ÿé¥æ§è½¦ä»»åŠ¡ä¸­ï¼Œä»…ç”¨å°‘é‡æ•°æ®å°±å­¦ä¹ äº†ä¸€ç§æ¶‰åŠæ¼‚ç§»çš„é«˜åº¦åŠ¨æ€çš„åœè½¦åŠ¨ä½œã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸ºäº†ä½¿AIç³»ç»Ÿèƒ½å¤Ÿåœ¨çœŸå®ä¸–ç•Œä¸­é«˜æ•ˆå­¦ä¹ ï¼Œæˆ‘ä»¬æå‡ºäº†SimPELï¼Œä¸€ç§å°†ç¬¬ä¸€æ€§åŸç†æ¨¡å‹ä¸æ•°æ®é©±åŠ¨å­¦ä¹ ç›¸ç»“åˆçš„æ–¹æ³•ã€‚SimPELåœ¨è´å¶æ–¯æ·±åº¦å­¦ä¹ ä¸­åˆ©ç”¨ä½ä¿çœŸåº¦ä»¿çœŸå™¨ä½œä¸ºå…ˆéªŒï¼Œä»è€Œå—ç›Šäºä»¿çœŸå™¨çš„çŸ¥è¯†ï¼Œå¹¶åœ¨æ•°æ®é‡å……è¶³æ—¶å‘æŒ¥æ·±åº¦å­¦ä¹ çš„çµæ´»æ€§ï¼ŒåŒæ—¶ç²¾ç¡®é‡åŒ–è®¤çŸ¥ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬åœ¨ç”Ÿç‰©ã€å†œä¸šå’Œæœºå™¨äººç­‰å¤šä¸ªé¢†åŸŸè¯„ä¼°äº†SimPELï¼Œç»“æœè¡¨æ˜å…¶åœ¨å­¦ä¹ å¤æ‚åŠ¨åŠ›å­¦æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚åœ¨å†³ç­–æ–¹é¢ï¼Œæˆ‘ä»¬è¯æ˜SimPELå¼¥åˆäº†åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ ä¸­çš„ä»¿çœŸåˆ°çœŸå®ï¼ˆsim-to-realï¼‰çš„å·®è·ã€‚åœ¨ä¸€ä¸ªé«˜é€Ÿé¥æ§è½¦ä»»åŠ¡ä¸­ï¼ŒSimPELä»…ç”¨å°‘é‡æ•°æ®å°±å­¦ä¹ äº†ä¸€ç§æ¶‰åŠæ¼‚ç§»çš„é«˜åº¦åŠ¨æ€çš„åœè½¦åŠ¨ä½œï¼Œæ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚è¿™äº›ç»“æœçªæ˜¾äº†SimPELåœ¨å¤æ‚çœŸå®ä¸–ç•Œç¯å¢ƒä¸­è¿›è¡Œæ•°æ®é«˜æ•ˆå­¦ä¹ å’Œæ§åˆ¶çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•é«˜æ•ˆåœ°å­¦ä¹ å¤æ‚åŠ¨æ€ç³»ç»Ÿçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚çº¯ç²¹çš„æ·±åº¦å­¦ä¹ ï¼Œéœ€è¦å¤§é‡çœŸå®æ•°æ®ï¼Œè€Œç¬¬ä¸€æ€§åŸç†æ¨¡å‹åˆéš¾ä»¥å‡†ç¡®æ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„å¤æ‚æ€§ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨å°‘é‡æ•°æ®ä¸‹ï¼Œç»“åˆå…ˆéªŒçŸ¥è¯†å’Œæ•°æ®é©±åŠ¨å­¦ä¹ ï¼Œæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ä½ä¿çœŸåº¦çš„ä»¿çœŸå™¨ä½œä¸ºè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„å…ˆéªŒã€‚è¿™æ„å‘³ç€æ¨¡å‹åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œä¼šå—åˆ°ä»¿çœŸç»“æœçš„å¼•å¯¼ï¼Œä»è€Œåœ¨æ•°æ®é‡è¾ƒå°‘æ—¶ä¹Ÿèƒ½è·å¾—è¾ƒå¥½çš„æ€§èƒ½ã€‚éšç€æ•°æ®é‡çš„å¢åŠ ï¼Œæ¨¡å‹é€æ¸æ‘†è„±ä»¿çœŸå™¨çš„é™åˆ¶ï¼Œå­¦ä¹ çœŸå®æ•°æ®çš„åˆ†å¸ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSimPELçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦éƒ¨åˆ†ï¼š1) ä½ä¿çœŸåº¦ä»¿çœŸå™¨ï¼šç”¨äºç”Ÿæˆå…ˆéªŒçŸ¥è¯†ï¼›2) è´å¶æ–¯æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼šç”¨äºå­¦ä¹ åŠ¨æ€ç³»ç»Ÿï¼›3) è´å¶æ–¯æ¨æ–­ï¼šç”¨äºå°†ä»¿çœŸå™¨ä½œä¸ºå…ˆéªŒèå…¥åˆ°æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­ï¼›4) ä¸ç¡®å®šæ€§é‡åŒ–ï¼šç”¨äºè¯„ä¼°æ¨¡å‹å¯¹é¢„æµ‹ç»“æœçš„ç½®ä¿¡åº¦ã€‚æ•´ä¸ªæµç¨‹æ˜¯å…ˆåˆ©ç”¨ä»¿çœŸå™¨ç”Ÿæˆæ•°æ®ï¼Œç„¶åå°†è¿™äº›æ•°æ®ä½œä¸ºå…ˆéªŒçŸ¥è¯†ï¼Œç”¨äºè®­ç»ƒè´å¶æ–¯æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šSimPELçš„å…³é”®åˆ›æ–°åœ¨äºå°†ä»¿çœŸå™¨ä½œä¸ºè´å¶æ–¯æ·±åº¦å­¦ä¹ çš„å…ˆéªŒï¼Œä»è€Œåœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨å…ˆéªŒçŸ¥è¯†ï¼Œæé«˜å­¦ä¹ æ•ˆç‡ã€‚ä¸ä¼ ç»Ÿçš„è¿ç§»å­¦ä¹ æ–¹æ³•ä¸åŒï¼ŒSimPELä¸æ˜¯ç®€å•åœ°å°†ä»¿çœŸå™¨å­¦ä¹ åˆ°çš„çŸ¥è¯†è¿ç§»åˆ°çœŸå®ä¸–ç•Œï¼Œè€Œæ˜¯å°†ä»¿çœŸå™¨ä½œä¸ºä¸€ç§æ­£åˆ™åŒ–é¡¹ï¼Œå¼•å¯¼æ¨¡å‹çš„å­¦ä¹ æ–¹å‘ã€‚

**å…³é”®è®¾è®¡**ï¼šSimPELçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„ä½ä¿çœŸåº¦ä»¿çœŸå™¨ï¼›2) è®¾è®¡åˆé€‚çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä¾‹å¦‚é«˜æ–¯è¿‡ç¨‹æˆ–ç¥ç»ç½‘ç»œï¼›3) é€‰æ‹©åˆé€‚çš„è´å¶æ–¯æ¨æ–­æ–¹æ³•ï¼Œä¾‹å¦‚å˜åˆ†æ¨æ–­æˆ–é©¬å°”å¯å¤«é“¾è’™ç‰¹å¡æ´›æ–¹æ³•ï¼›4) è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚è€ƒè™‘ä»¿çœŸå™¨è¯¯å·®çš„æŸå¤±å‡½æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SimPELåœ¨å¤šä¸ªå®éªŒä¸­è¡¨ç°å‡ºè‰²ã€‚åœ¨é«˜é€Ÿé¥æ§è½¦ä»»åŠ¡ä¸­ï¼ŒSimPELä»…ç”¨å°‘é‡æ•°æ®å°±å­¦ä¹ äº†ä¸€ç§æ¶‰åŠæ¼‚ç§»çš„é«˜åº¦åŠ¨æ€çš„åœè½¦åŠ¨ä½œï¼Œæ€§èƒ½ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼ŒSimPELåœ¨æ•°æ®æ•ˆç‡æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ï¼Œæ‰€éœ€æ•°æ®é‡è¿œä½äºå…¶ä»–æ–¹æ³•ï¼ŒåŒæ—¶åœ¨æ¨¡å‹é¢„æµ‹ç²¾åº¦å’Œæ§åˆ¶æ€§èƒ½æ–¹é¢ä¹Ÿè¡¨ç°å‡ºä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SimPELå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚åœ¨æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€ç”Ÿç‰©ç³»ç»Ÿå»ºæ¨¡ã€å†œä¸šä¼˜åŒ–ç­‰é¢†åŸŸã€‚é€šè¿‡åˆ©ç”¨ä»¿çœŸå™¨ä½œä¸ºå…ˆéªŒï¼ŒSimPELå¯ä»¥å‡å°‘å¯¹çœŸå®æ•°æ®çš„ä¾èµ–ï¼Œé™ä½å®éªŒæˆæœ¬ï¼ŒåŠ é€Ÿæ¨¡å‹å¼€å‘ã€‚æ­¤å¤–ï¼ŒSimPELè¿˜å¯ä»¥ç”¨äºè§£å†³ä»¿çœŸåˆ°çœŸå®ï¼ˆsim-to-realï¼‰çš„è¿ç§»é—®é¢˜ï¼Œæé«˜æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> How do we enable AI systems to efficiently learn in the real-world? First-principles models are widely used to simulate natural systems, but often fail to capture real-world complexity due to simplifying assumptions. In contrast, deep learning approaches can estimate complex dynamics with minimal assumptions but require large, representative datasets. We propose SimPEL, a method that efficiently combines first-principles models with data-driven learning by using low-fidelity simulators as priors in Bayesian deep learning. This enables SimPEL to benefit from simulator knowledge in low-data regimes and leverage deep learning's flexibility when more data is available, all the while carefully quantifying epistemic uncertainty. We evaluate SimPEL on diverse systems, including biological, agricultural, and robotic domains, showing superior performance in learning complex dynamics. For decision-making, we demonstrate that SimPEL bridges the sim-to-real gap in model-based reinforcement learning. On a high-speed RC car task, SimPEL learns a highly dynamic parking maneuver involving drifting with substantially less data than state-of-the-art baselines. These results highlight the potential of SimPEL for data-efficient learning and control in complex real-world environments.

