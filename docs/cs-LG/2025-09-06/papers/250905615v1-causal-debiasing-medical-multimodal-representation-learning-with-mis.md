---
layout: default
title: Causal Debiasing Medical Multimodal Representation Learning with Missing Modalities
---

# Causal Debiasing Medical Multimodal Representation Learning with Missing Modalities

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05615" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05615v1</a>
  <a href="https://arxiv.org/pdf/2509.05615.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05615v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05615v1', 'Causal Debiasing Medical Multimodal Representation Learning with Missing Modalities')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaoguang Zhu, Lianlong Sun, Yang Liu, Pengyi Jiang, Uma Srivatsa, Nipavan Chiamvimonvat, Vladimir Filkov

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-06

**å¤‡æ³¨**: Submitted to IEEE TKDE

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§å› æœå»åçš„å¤šæ¨¡æ€åŒ»å­¦è¡¨å¾å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³ç¼ºå¤±æ¨¡æ€å¸¦æ¥çš„åå·®é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç¼ºå¤±æ¨¡æ€` `å› æœæ¨æ–­` `åŒ»å­¦æ•°æ®æŒ–æ˜` `è¡¨å¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŒ»å­¦å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•å¿½ç•¥äº†æ•°æ®é‡‡é›†è¿‡ç¨‹å¼•å…¥çš„ç¼ºå¤±åå·®å’Œåˆ†å¸ƒåå·®ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›å—é™ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ä¸ªç»Ÿä¸€çš„å› æœå»åæ¡†æ¶ï¼Œé€šè¿‡ç¼ºå¤±å»æ··æ·†æ¨¡å—å’ŒåŒåˆ†æ”¯ç¥ç»ç½‘ç»œæ¥è§£å†³ä¸Šè¿°åå·®é—®é¢˜ã€‚
3. åœ¨çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹æ€§èƒ½ï¼Œå¹¶æä¾›å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„å› æœæ´å¯Ÿã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŒ»å­¦å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ æ—¨åœ¨å°†å¼‚æ„ä¸´åºŠæ•°æ®æ•´åˆä¸ºç»Ÿä¸€çš„æ‚£è€…è¡¨å¾ï¼Œä»¥æ”¯æŒé¢„æµ‹å»ºæ¨¡ï¼Œè¿™æ˜¯åŒ»å­¦æ•°æ®æŒ–æ˜é¢†åŸŸä¸€é¡¹é‡è¦ä½†å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°å®ä¸–ç•Œçš„åŒ»å­¦æ•°æ®é›†ç»å¸¸ç”±äºæˆæœ¬ã€åè®®æˆ–æ‚£è€…ç‰¹å®šçº¦æŸè€Œå­˜åœ¨æ¨¡æ€ç¼ºå¤±ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡ä»åŸå§‹æ•°æ®ç©ºé—´æˆ–ç‰¹å¾ç©ºé—´ä¸­çš„å¯ç”¨è§‚æµ‹æ•°æ®ä¸­å­¦ä¹ æ¥è§£å†³æ­¤é—®é¢˜ï¼Œä½†é€šå¸¸å¿½ç•¥äº†æ•°æ®é‡‡é›†è¿‡ç¨‹æœ¬èº«å¼•å…¥çš„æ½œåœ¨åå·®ã€‚æœ¬æ–‡è¯†åˆ«äº†ä¸¤ç§é˜»ç¢æ¨¡å‹æ³›åŒ–çš„åå·®ï¼šç”±æ¨¡æ€å¯ç”¨æ€§çš„ééšæœºæ¨¡å¼å¯¼è‡´çš„ç¼ºå¤±åå·®ï¼Œä»¥åŠç”±å½±å“è§‚æµ‹ç‰¹å¾å’Œç»“æœçš„æ½œåœ¨æ··æ·†å› ç´ å¼•èµ·çš„åˆ†å¸ƒåå·®ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹è¿›è¡Œäº†ç»“æ„å› æœåˆ†æï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªä¸ç°æœ‰åŸºäºç›´æ¥é¢„æµ‹çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•å…¼å®¹çš„ç»Ÿä¸€æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªåŸºäºåé—¨è°ƒæ•´æ¥è¿‘ä¼¼å› æœå¹²é¢„çš„ç¼ºå¤±å»æ··æ·†æ¨¡å—ï¼Œä»¥åŠï¼ˆ2ï¼‰ä¸€ä¸ªæ˜¾å¼åœ°å°†å› æœç‰¹å¾ä¸è™šå‡ç›¸å…³æ€§åˆ†ç¦»çš„åŒåˆ†æ”¯ç¥ç»ç½‘ç»œã€‚æˆ‘ä»¬åœ¨çœŸå®ä¸–ç•Œçš„å…¬å…±å’Œé™¢å†…æ•°æ®é›†ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œå› æœæ´å¯ŸåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåŒ»å­¦å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ é¢ä¸´çš„å…³é”®é—®é¢˜æ˜¯å¦‚ä½•å¤„ç†æ•°æ®é›†ä¸­æ™®éå­˜åœ¨çš„æ¨¡æ€ç¼ºå¤±ç°è±¡ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨åˆ©ç”¨ç°æœ‰æ•°æ®è¿›è¡Œå­¦ä¹ ï¼Œä½†å¿½ç•¥äº†æ¨¡æ€ç¼ºå¤±æœ¬èº«å¸¦æ¥çš„åå·®ï¼Œä¾‹å¦‚ééšæœºç¼ºå¤±æ¨¡å¼å¯¼è‡´çš„ç¼ºå¤±åå·®ï¼Œä»¥åŠæ½œåœ¨æ··æ·†å› ç´ å¯¼è‡´çš„åˆ†å¸ƒåå·®ã€‚è¿™äº›åå·®ä¼šä¸¥é‡å½±å“æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé¢„æµ‹å‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å› æœæ¨æ–­çš„ç†è®ºæ¡†æ¶æ¥åˆ†æå’Œæ¶ˆé™¤æ¨¡æ€ç¼ºå¤±å¸¦æ¥çš„åå·®ã€‚é€šè¿‡æ„å»ºæ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„ç»“æ„å› æœæ¨¡å‹ï¼Œè¯†åˆ«å‡ºå¯¼è‡´åå·®çš„æ··æ·†å› ç´ ï¼Œå¹¶é‡‡ç”¨å› æœå¹²é¢„çš„æ–¹æ³•æ¥æ¶ˆé™¤è¿™äº›æ··æ·†å› ç´ çš„å½±å“ï¼Œä»è€Œå­¦ä¹ åˆ°æ›´é²æ£’å’Œæ³›åŒ–çš„å¤šæ¨¡æ€è¡¨å¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¼ºå¤±å»æ··æ·†æ¨¡å—å’ŒåŒåˆ†æ”¯ç¥ç»ç½‘ç»œã€‚ç¼ºå¤±å»æ··æ·†æ¨¡å—åˆ©ç”¨åé—¨è°ƒæ•´æ¥è¿‘ä¼¼å› æœå¹²é¢„ï¼Œæ—¨åœ¨æ¶ˆé™¤æ¨¡æ€ç¼ºå¤±å¸¦æ¥çš„åå·®ã€‚åŒåˆ†æ”¯ç¥ç»ç½‘ç»œåˆ™æ˜¾å¼åœ°å°†å› æœç‰¹å¾ä¸è™šå‡ç›¸å…³æ€§åˆ†ç¦»ï¼Œè¿›ä¸€æ­¥æå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚æ•´ä¸ªæ¡†æ¶å¯ä»¥ä¸ç°æœ‰çš„åŸºäºç›´æ¥é¢„æµ‹çš„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•å…¼å®¹ï¼Œæ˜“äºé›†æˆå’Œæ‰©å±•ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å› æœæ¨æ–­å¼•å…¥åˆ°åŒ»å­¦å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ ä¸­ï¼Œå¹¶é’ˆå¯¹æ¨¡æ€ç¼ºå¤±é—®é¢˜æå‡ºäº†å…·ä½“çš„å› æœå»åæ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¶ˆé™¤æ•°æ®åå·®ï¼Œå­¦ä¹ åˆ°æ›´å¯é çš„è¡¨å¾ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æä¾›äº†ä¸€ç§ç†è§£æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„å› æœè§†è§’ï¼Œæœ‰åŠ©äºå‘ç°æ½œåœ¨çš„ä¸´åºŠè§„å¾‹ã€‚

**å…³é”®è®¾è®¡**ï¼šç¼ºå¤±å»æ··æ·†æ¨¡å—é€šè¿‡ä¼°è®¡æ··æ·†å› ç´ å¯¹æ¨¡æ€ç¼ºå¤±çš„å½±å“ï¼Œå¹¶åˆ©ç”¨åé—¨è°ƒæ•´å…¬å¼æ¥æ¶ˆé™¤è¿™ç§å½±å“ã€‚åŒåˆ†æ”¯ç¥ç»ç½‘ç»œåŒ…å«ä¸€ä¸ªå› æœåˆ†æ”¯å’Œä¸€ä¸ªéå› æœåˆ†æ”¯ï¼Œåˆ†åˆ«å­¦ä¹ å› æœç‰¹å¾å’Œè™šå‡ç›¸å…³æ€§ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨é¼“åŠ±ä¸¤ä¸ªåˆ†æ”¯å­¦ä¹ åˆ°äº’è¡¥çš„ä¿¡æ¯ï¼Œå¹¶æŠ‘åˆ¶è™šå‡ç›¸å…³æ€§çš„å½±å“ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡åœ¨çœŸå®ä¸–ç•Œçš„å…¬å…±å’Œé™¢å†…æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—æå‡å¤šæ¨¡æ€è¡¨å¾å­¦ä¹ çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šå–å¾—äº†æ˜æ˜¾çš„æå‡ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜é€šè¿‡å®éªŒéªŒè¯äº†å› æœå»åæ¨¡å—å’ŒåŒåˆ†æ”¯ç¥ç»ç½‘ç»œçš„æœ‰æ•ˆæ€§ï¼Œå¹¶æä¾›äº†å¯¹æ•°æ®ç”Ÿæˆè¿‡ç¨‹çš„å› æœæ´å¯Ÿã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§åŒ»å­¦å¤šæ¨¡æ€æ•°æ®åˆ†æä»»åŠ¡ï¼Œä¾‹å¦‚ç–¾ç—…è¯Šæ–­ã€é¢„åé¢„æµ‹ã€æ²»ç–—æ–¹æ¡ˆæ¨èç­‰ã€‚é€šè¿‡æ¶ˆé™¤æ¨¡æ€ç¼ºå¤±å¸¦æ¥çš„åå·®ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å¯é çš„ä¾æ®ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºå…¶ä»–å­˜åœ¨æ•°æ®ç¼ºå¤±é—®é¢˜çš„é¢†åŸŸï¼Œä¾‹å¦‚é‡‘èé£æ§ã€æ™ºèƒ½äº¤é€šç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Medical multimodal representation learning aims to integrate heterogeneous clinical data into unified patient representations to support predictive modeling, which remains an essential yet challenging task in the medical data mining community. However, real-world medical datasets often suffer from missing modalities due to cost, protocol, or patient-specific constraints. Existing methods primarily address this issue by learning from the available observations in either the raw data space or feature space, but typically neglect the underlying bias introduced by the data acquisition process itself. In this work, we identify two types of biases that hinder model generalization: missingness bias, which results from non-random patterns in modality availability, and distribution bias, which arises from latent confounders that influence both observed features and outcomes. To address these challenges, we perform a structural causal analysis of the data-generating process and propose a unified framework that is compatible with existing direct prediction-based multimodal learning methods. Our method consists of two key components: (1) a missingness deconfounding module that approximates causal intervention based on backdoor adjustment and (2) a dual-branch neural network that explicitly disentangles causal features from spurious correlations. We evaluated our method in real-world public and in-hospital datasets, demonstrating its effectiveness and causal insights.

