---
layout: default
title: Discrete Variational Autoencoding via Policy Search
---

# Discrete Variational Autoencoding via Policy Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.24716" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.24716v1</a>
  <a href="https://arxiv.org/pdf/2509.24716.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.24716v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.24716v1', 'Discrete Variational Autoencoding via Policy Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Michael Drolet, Firas Al-Hafez, Aditya Bhatt, Jan Peters, Oleg Arenz

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºç­–ç•¥æœç´¢çš„ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨ï¼Œæå‡é«˜ç»´å›¾åƒé‡å»ºè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨` `ç­–ç•¥æœç´¢` `è‡ªç„¶æ¢¯åº¦` `å›¾åƒé‡å»º` `éå‚æ•°ç¼–ç å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¦»æ•£VAEä¾èµ–è¿‘ä¼¼é‡å‚æ•°åŒ–æˆ–é«˜æ–¹å·®æ— æ¢¯åº¦æ–¹æ³•ï¼Œåœ¨é«˜ç»´å›¾åƒé‡å»ºä»»åŠ¡ä¸­æ•ˆæœæœ‰é™ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºç­–ç•¥æœç´¢çš„è®­ç»ƒæ¡†æ¶ï¼Œåˆ©ç”¨éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦æ›´æ–°å‚æ•°åŒ–ç¼–ç å™¨ï¼Œæ— éœ€é‡å‚æ•°åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ImageNetç­‰æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†å›¾åƒé‡å»ºè´¨é‡ï¼ŒFIDå¾—åˆ†æå‡20%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨(VAE)ä¸­çš„ç¦»æ•£æ½œåœ¨ç“¶é¢ˆæä¾›äº†é«˜æ¯”ç‰¹æ•ˆç‡ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨è‡ªå›å½’ç¦»æ•£åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œèƒ½å¤Ÿåˆ©ç”¨transformersè¿›è¡Œå‚æ•°é«˜æ•ˆçš„å¤šæ¨¡æ€æœç´¢ã€‚ç„¶è€Œï¼Œç¦»æ•£éšæœºå˜é‡ä¸å…è®¸ç²¾ç¡®çš„å¯å¾®å‚æ•°åŒ–ï¼›å› æ­¤ï¼Œç¦»æ•£VAEé€šå¸¸ä¾èµ–äºè¿‘ä¼¼æ–¹æ³•ï¼Œä¾‹å¦‚Gumbel-Softmaxé‡å‚æ•°åŒ–æˆ–straight-throughæ¢¯åº¦ä¼°è®¡ï¼Œæˆ–è€…é‡‡ç”¨é«˜æ–¹å·®çš„æ— æ¢¯åº¦æ–¹æ³•ï¼Œä¾‹å¦‚REINFORCEï¼Œè¿™äº›æ–¹æ³•åœ¨é«˜ç»´ä»»åŠ¡ï¼ˆå¦‚å›¾åƒé‡å»ºï¼‰ä¸Šçš„æˆåŠŸæœ‰é™ã€‚å—åˆ°ç­–ç•¥æœç´¢ä¸­å¸¸ç”¨æŠ€æœ¯çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¦»æ•£VAEçš„è®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦æ¥æ›´æ–°å‚æ•°åŒ–ç¼–ç å™¨ï¼Œè€Œæ— éœ€é‡å‚æ•°åŒ–ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†è‡ªåŠ¨æ­¥é•¿è°ƒæ•´å’ŒåŸºäºtransformerçš„ç¼–ç å™¨ï¼Œå¯ä»¥æ‰©å±•åˆ°å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼ˆå¦‚ImageNetï¼‰ï¼Œå¹¶ä¸”åœ¨ä»ç´§å‡‘æ½œåœ¨ç©ºé—´é‡å»ºé«˜ç»´æ•°æ®æ–¹é¢ä¼˜äºè¿‘ä¼¼é‡å‚æ•°åŒ–æ–¹æ³•å’ŒåŸºäºé‡åŒ–çš„ç¦»æ•£è‡ªç¼–ç å™¨ï¼Œåœ¨ImageNet 256ä¸Šçš„FIDå¾—åˆ†æé«˜äº†20%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆDiscrete VAEsï¼‰åœ¨é«˜ç»´æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰é‡å»ºä»»åŠ¡ä¸­ï¼Œç”±äºç¦»æ•£æ½œåœ¨å˜é‡ä¸å¯å¾®è€Œå¯¼è‡´çš„è®­ç»ƒå›°éš¾é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚Gumbel-Softmaxé‡å‚æ•°åŒ–å’ŒREINFORCEï¼Œè¦ä¹ˆå¼•å…¥è¿‘ä¼¼è¯¯å·®ï¼Œè¦ä¹ˆå…·æœ‰é«˜æ–¹å·®ï¼Œé™åˆ¶äº†å…¶åœ¨é«˜ç»´æ•°æ®ä¸Šçš„è¡¨ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å€Ÿé‰´ç­–ç•¥æœç´¢çš„æ€æƒ³ï¼Œå°†ç¦»æ•£VAEçš„è®­ç»ƒè¿‡ç¨‹è§†ä¸ºä¸€ä¸ªç­–ç•¥ä¼˜åŒ–é—®é¢˜ã€‚é€šè¿‡åˆ©ç”¨éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦æ¥æ›´æ–°å‚æ•°åŒ–ç¼–ç å™¨ï¼Œé¿å…äº†ç›´æ¥å¯¹ç¦»æ•£å˜é‡è¿›è¡Œæ¢¯åº¦ä¼°è®¡ï¼Œä»è€Œç»•è¿‡äº†ä¸å¯å¾®çš„é—®é¢˜ã€‚è¿™ç§æ–¹æ³•å…è®¸æ›´ç¨³å®šå’Œé«˜æ•ˆçš„è®­ç»ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªå‚æ•°åŒ–çš„ç¼–ç å™¨ï¼ˆé€šå¸¸æ˜¯Transformerç½‘ç»œï¼‰ï¼Œä¸€ä¸ªéå‚æ•°åŒ–çš„ç¼–ç å™¨ï¼Œä»¥åŠä¸€ä¸ªè§£ç å™¨ã€‚è®­ç»ƒè¿‡ç¨‹ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) ä½¿ç”¨éå‚æ•°ç¼–ç å™¨ç”Ÿæˆç¦»æ•£æ½œåœ¨å˜é‡ï¼›2) ä½¿ç”¨å‚æ•°åŒ–ç¼–ç å™¨é¢„æµ‹è¿™äº›ç¦»æ•£æ½œåœ¨å˜é‡çš„æ¦‚ç‡åˆ†å¸ƒï¼›3) è®¡ç®—éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦ï¼›4) ä½¿ç”¨è‡ªç„¶æ¢¯åº¦æ›´æ–°å‚æ•°åŒ–ç¼–ç å™¨çš„å‚æ•°ï¼›5) ä½¿ç”¨è§£ç å™¨é‡å»ºè¾“å…¥æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨éå‚æ•°ç¼–ç å™¨çš„è‡ªç„¶æ¢¯åº¦æ¥æŒ‡å¯¼å‚æ•°åŒ–ç¼–ç å™¨çš„è®­ç»ƒã€‚è¿™é¿å…äº†å¯¹ç¦»æ•£å˜é‡è¿›è¡Œè¿‘ä¼¼æ¢¯åº¦ä¼°è®¡ï¼Œä»è€Œå‡å°‘äº†è¯¯å·®å’Œæ–¹å·®ã€‚æ­¤å¤–ï¼Œç»“åˆè‡ªåŠ¨æ­¥é•¿è°ƒæ•´ï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨Transformerä½œä¸ºå‚æ•°åŒ–ç¼–ç å™¨ï¼Œä»¥æ•æ‰å›¾åƒä¸­çš„é•¿ç¨‹ä¾èµ–å…³ç³»ï¼›2) ä½¿ç”¨KLæ•£åº¦ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œè¡¡é‡å‚æ•°åŒ–ç¼–ç å™¨é¢„æµ‹çš„æ¦‚ç‡åˆ†å¸ƒä¸éå‚æ•°ç¼–ç å™¨ç”Ÿæˆçš„ç¦»æ•£æ½œåœ¨å˜é‡ä¹‹é—´çš„å·®å¼‚ï¼›3) é‡‡ç”¨è‡ªåŠ¨æ­¥é•¿è°ƒæ•´ç®—æ³•ï¼ŒåŠ¨æ€è°ƒæ•´å‚æ•°åŒ–ç¼–ç å™¨çš„å­¦ä¹ ç‡ï¼Œä»¥æé«˜è®­ç»ƒçš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ImageNet 256æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒFIDå¾—åˆ†ç›¸æ¯”ç°æœ‰æ–¹æ³•æé«˜äº†20%ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ å›¾åƒçš„æ½œåœ¨è¡¨ç¤ºï¼Œå¹¶ç”Ÿæˆæ›´é«˜è´¨é‡çš„å›¾åƒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒç¨³å®šæ€§å’Œæ”¶æ•›é€Ÿåº¦æ–¹é¢ä¹Ÿä¼˜äºå…¶ä»–ç¦»æ•£VAEæ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒå‹ç¼©ã€å›¾åƒç”Ÿæˆã€å›¾åƒç¼–è¾‘ç­‰é¢†åŸŸã€‚é€šè¿‡å­¦ä¹ ç´§å‡‘çš„ç¦»æ•£æ½œåœ¨è¡¨ç¤ºï¼Œå¯ä»¥å®ç°é«˜æ•ˆçš„å›¾åƒå­˜å‚¨å’Œä¼ è¾“ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºç”Ÿæˆå…·æœ‰ç‰¹å®šå±æ€§çš„å›¾åƒï¼Œä¾‹å¦‚ï¼Œé€šè¿‡æ§åˆ¶ç¦»æ•£æ½œåœ¨å˜é‡æ¥æ”¹å˜å›¾åƒçš„é£æ ¼æˆ–å†…å®¹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–é«˜ç»´æ•°æ®é¢†åŸŸï¼Œå¦‚è§†é¢‘å’ŒéŸ³é¢‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Discrete latent bottlenecks in variational autoencoders (VAEs) offer high bit efficiency and can be modeled with autoregressive discrete distributions, enabling parameter-efficient multimodal search with transformers. However, discrete random variables do not allow for exact differentiable parameterization; therefore, discrete VAEs typically rely on approximations, such as Gumbel-Softmax reparameterization or straight-through gradient estimates, or employ high-variance gradient-free methods such as REINFORCE that have had limited success on high-dimensional tasks such as image reconstruction. Inspired by popular techniques in policy search, we propose a training framework for discrete VAEs that leverages the natural gradient of a non-parametric encoder to update the parametric encoder without requiring reparameterization. Our method, combined with automatic step size adaptation and a transformer-based encoder, scales to challenging datasets such as ImageNet and outperforms both approximate reparameterization methods and quantization-based discrete autoencoders in reconstructing high-dimensional data from compact latent spaces, achieving a 20% improvement on FID Score for ImageNet 256.

