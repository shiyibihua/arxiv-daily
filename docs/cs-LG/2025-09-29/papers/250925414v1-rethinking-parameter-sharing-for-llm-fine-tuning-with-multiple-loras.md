---
layout: default
title: Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs
---

# Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25414" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25414v1</a>
  <a href="https://arxiv.org/pdf/2509.25414.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25414v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25414v1', 'Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Ban, Kaiyi Ji

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/OptMN-Lab/ALoRA)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºALoRAï¼šä¸€ç§éå¯¹ç§°å¤šLoRAå¾®è°ƒæ–¹æ³•ï¼Œæå‡LLMå¤šä»»åŠ¡å’Œè”é‚¦å­¦ä¹ æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å‚æ•°é«˜æ•ˆå¾®è°ƒ` `å¤šLoRA` `å¤šä»»åŠ¡å­¦ä¹ ` `è”é‚¦å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `çŸ¥è¯†è¿ç§»` `éå¯¹ç§°ç»“æ„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šLoRAå¾®è°ƒä¸­ï¼Œå¯¹LoRAçš„AçŸ©é˜µè¿›è¡Œå…±äº«ï¼Œä½†å¿½ç•¥äº†BçŸ©é˜µçš„ä½œç”¨ï¼Œå¯¼è‡´çŸ¥è¯†ç¼–ç å’Œè¿ç§»æ•ˆç‡é™ä½ã€‚
2. ALoRAçš„æ ¸å¿ƒæ€æƒ³æ˜¯å…±äº«LoRAçš„BçŸ©é˜µï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡ä¿ç•™ç‹¬ç«‹çš„AçŸ©é˜µï¼Œä»è€Œå®ç°æ›´æœ‰æ•ˆçš„çŸ¥è¯†ç¼–ç å’Œä»»åŠ¡ç‰¹å®šé€‚é…ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒALoRAåœ¨å¤šä»»åŠ¡å’Œè”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ï¼Œç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ›´å¹³è¡¡çš„ä»»åŠ¡æ€§èƒ½å’Œæ›´é«˜çš„å¹³å‡å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹é€šå¸¸ä½¿ç”¨ä½ç§©é€‚åº”(LoRA)ç­‰å‚æ•°é«˜æ•ˆæŠ€æœ¯è¿›è¡Œé€‚é…ï¼Œå…¶å…¬å¼ä¸º$y = W_0x + BAx$ï¼Œå…¶ä¸­$W_0$æ˜¯é¢„è®­ç»ƒå‚æ•°ï¼Œ$x$æ˜¯é€‚é…å±‚çš„è¾“å…¥ã€‚å¤šé€‚é…å™¨æ‰©å±•é€šå¸¸é‡‡ç”¨å¤šä¸ªLoRAï¼Œä½†å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼Œå†…éƒ¨çŸ©é˜µ$A$åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é«˜åº¦ç›¸ä¼¼ï¼Œå› æ­¤é€‚åˆå…±äº«ã€‚æˆ‘ä»¬é‡æ–°å®¡è§†äº†è¿™ç§ç°è±¡ï¼Œå‘ç°è¿™ç§ç›¸ä¼¼æ€§ä¸»è¦å½’å› äºç›¸åŒçš„åˆå§‹åŒ–ï¼Œè€Œä¸æ˜¯å…±äº«çŸ¥è¯†ï¼Œ$B$åœ¨çŸ¥è¯†ç¼–ç å’Œè½¬ç§»ä¸­èµ·ç€æ›´å…³é”®çš„ä½œç”¨ã€‚å—è¿™äº›è§è§£çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡º	extbf{ALoRA}ï¼Œä¸€ç§éå¯¹ç§°å¤šLoRAè®¾è®¡ï¼Œåœ¨å¤šä»»åŠ¡å¾®è°ƒä¸­å…·æœ‰å¤šä¸ª$A$çŸ©é˜µå’Œä¸€ä¸ªå…±äº«çš„$B$ï¼Œä»¥åŠ	extbf{Fed-ALoRA}ï¼Œå®ƒé€šè¿‡ä¸€ç§æ–°é¢–çš„çŸ©é˜µåˆ†è§£ç­–ç•¥ï¼Œåœ¨åŒæ„å’Œå¼‚æ„è®¾ç½®ä¸‹çš„è”é‚¦å¾®è°ƒä¸­è·¨å®¢æˆ·ç«¯å…±äº«$B$ï¼Œä»¥é€‚åº”è·¨å®¢æˆ·ç«¯çš„å¼‚æ„ç§©ã€‚åœ¨å¸¸è¯†æ¨ç†ã€æ•°å­¦æ¨ç†ã€å¤šä»»åŠ¡NLPæ•°æ®é›†å’Œè”é‚¦NLPæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç›¸å¯¹äºç°æœ‰çš„å¤šLoRAæ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»»åŠ¡ä¹‹é—´å®ç°äº†æ›´å¹³è¡¡çš„æ€§èƒ½ï¼Œå¹¶å…·æœ‰å¯æ¯”æˆ–æ›´é«˜çš„å¹³å‡å‡†ç¡®ç‡ã€‚ä»£ç å¯åœ¨https://github.com/OptMN-Lab/ALoRAè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå¤šLoRAçš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•ï¼Œåœ¨å¤šä»»åŠ¡æˆ–è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ï¼Œé€šå¸¸å‡è®¾LoRAçš„AçŸ©é˜µåŒ…å«ä»»åŠ¡ç‰¹å®šçš„ä¿¡æ¯ï¼Œè€ŒBçŸ©é˜µå¯ä»¥å…±äº«ã€‚ç„¶è€Œï¼Œè®ºæ–‡æŒ‡å‡ºAçŸ©é˜µçš„ç›¸ä¼¼æ€§æ›´å¤šæºäºåˆå§‹åŒ–ï¼Œè€Œå¿½ç•¥äº†BçŸ©é˜µåœ¨çŸ¥è¯†ç¼–ç å’Œè¿ç§»ä¸­çš„é‡è¦ä½œç”¨ã€‚è¿™å¯¼è‡´æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸å¹³è¡¡ï¼Œä¸”æ•´ä½“æ€§èƒ½æå‡æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é‡æ–°å®¡è§†LoRAä¸­Aå’ŒBçŸ©é˜µçš„ä½œç”¨ï¼Œå¹¶æå‡ºä¸€ç§éå¯¹ç§°çš„å¤šLoRAç»“æ„ALoRAã€‚ALoRAçš„å…³é”®åœ¨äºå…±äº«BçŸ©é˜µï¼Œå¹¶ä¸ºæ¯ä¸ªä»»åŠ¡ç»´æŠ¤ç‹¬ç«‹çš„AçŸ©é˜µã€‚è¿™ç§è®¾è®¡å…è®¸BçŸ©é˜µæ•è·é€šç”¨çš„çŸ¥è¯†è¡¨ç¤ºï¼Œè€ŒAçŸ©é˜µåˆ™è´Ÿè´£ä»»åŠ¡ç‰¹å®šçš„é€‚é…ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šALoRAçš„æ•´ä½“æ¡†æ¶åŸºäºLoRAï¼Œä½†ä¿®æ”¹äº†å‚æ•°å…±äº«ç­–ç•¥ã€‚åœ¨å¤šä»»åŠ¡å¾®è°ƒä¸­ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æœ‰ä¸€ä¸ªç‹¬ç«‹çš„AçŸ©é˜µï¼Œä½†å…±äº«åŒä¸€ä¸ªBçŸ©é˜µã€‚åœ¨è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ï¼Œæå‡ºäº†Fed-ALoRAï¼Œé€šè¿‡çŸ©é˜µåˆ†è§£ç­–ç•¥ï¼Œå…è®¸å®¢æˆ·ç«¯æ‹¥æœ‰ä¸åŒç§©çš„LoRAï¼Œå¹¶å…±äº«åˆ†è§£åçš„BçŸ©é˜µã€‚

**å…³é”®åˆ›æ–°**ï¼šALoRAçš„å…³é”®åˆ›æ–°åœ¨äºéå¯¹ç§°çš„LoRAç»“æ„ï¼Œå³å…±äº«BçŸ©é˜µå¹¶ä¿æŒAçŸ©é˜µçš„ç‹¬ç«‹æ€§ã€‚è¿™ç§è®¾è®¡æ›´ç¬¦åˆLoRAä¸­Aå’ŒBçŸ©é˜µçš„å®é™…ä½œç”¨ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¿›è¡ŒçŸ¥è¯†ç¼–ç å’Œä»»åŠ¡ç‰¹å®šé€‚é…ã€‚Fed-ALoRAé€šè¿‡çŸ©é˜µåˆ†è§£ï¼Œå®ç°äº†åœ¨å¼‚æ„è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹å…±äº«BçŸ©é˜µï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šALoRAçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å…±äº«çš„BçŸ©é˜µï¼Œç”¨äºæ•è·é€šç”¨çŸ¥è¯†ï¼›2) ç‹¬ç«‹çš„AçŸ©é˜µï¼Œç”¨äºä»»åŠ¡ç‰¹å®šé€‚é…ï¼›3) åœ¨Fed-ALoRAä¸­ï¼Œä½¿ç”¨çŸ©é˜µåˆ†è§£æŠ€æœ¯æ¥é€‚åº”ä¸åŒå®¢æˆ·ç«¯çš„LoRAç§©ï¼Œå¹¶å…±äº«åˆ†è§£åçš„BçŸ©é˜µã€‚æŸå¤±å‡½æ•°ä¸æ ‡å‡†LoRAå¾®è°ƒç›¸åŒï¼Œé€šå¸¸ä½¿ç”¨äº¤å‰ç†µæŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒALoRAåœ¨å¸¸è¯†æ¨ç†ã€æ•°å­¦æ¨ç†ã€å¤šä»»åŠ¡NLPæ•°æ®é›†å’Œè”é‚¦NLPæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å¤šä»»åŠ¡NLPæ•°æ®é›†ä¸Šï¼ŒALoRAç›¸æ¯”ç°æœ‰æ–¹æ³•ï¼Œå®ç°äº†æ›´å¹³è¡¡çš„ä»»åŠ¡æ€§èƒ½å’Œæ›´é«˜çš„å¹³å‡å‡†ç¡®ç‡ã€‚åœ¨è”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ï¼ŒFed-ALoRAåœ¨å¼‚æ„æ•°æ®åˆ†å¸ƒä¸‹ï¼Œä¾ç„¶èƒ½å¤Ÿä¿æŒè¾ƒé«˜çš„æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ALoRAå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬å¤šä»»åŠ¡å­¦ä¹ ã€è”é‚¦å­¦ä¹ ã€ä¸ªæ€§åŒ–æ¨èã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥åº”ç”¨äºå„ç§éœ€è¦å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé«˜æ•ˆå¾®è°ƒçš„åœºæ™¯ï¼Œä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—é¢†åŸŸï¼Œå¯ä»¥ä½¿ç”¨ALoRAå¯¹ä¸åŒç–¾ç—…çš„è¯Šæ–­æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¹¶å…±äº«é€šç”¨çš„åŒ»å­¦çŸ¥è¯†ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models are often adapted using parameter-efficient techniques such as Low-Rank Adaptation (LoRA), formulated as $y = W_0x + BAx$, where $W_0$ is the pre-trained parameters and $x$ is the input to the adapted layer. While multi-adapter extensions often employ multiple LoRAs, prior studies suggest that the inner $A$ matrices are highly similar during training and thus suitable for sharing. We revisit this phenomenon and find that this similarity is largely attributable to the identical initialization rather than shared knowledge, with $B$ playing a more critical role in knowledge encoding and transfer. Motivated by these insights, we propose \textbf{ALoRA}, an asymmetric multi-LoRA design with multiple $A$ matrices and a single shared $B$ in multi-task fine-tuning, and \textbf{Fed-ALoRA}, which shares $B$ across clients in federated fine-tuning under both homogeneous and heterogeneous settings, through a novel matrix decomposition strategy to accommodate heterogeneous ranks across clients. Experiments on commonsense reasoning, math reasoning, multi-task NLP dataset, and federated NLP dataset demonstrate that our methods achieve more balanced performance across tasks with comparable or superior average accuracy relative to existing multi-LoRA approaches. Codes are available at https://github.com/OptMN-Lab/ALoRA.

