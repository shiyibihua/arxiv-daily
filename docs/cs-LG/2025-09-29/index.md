---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-09-29
---

# cs.LGï¼ˆ2025-09-29ï¼‰

ğŸ“Š å…± **12** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250925518v2-world-model-for-ai-autonomous-navigation-in-mechanical-thrombectomy.html">World Model for AI Autonomous Navigation in Mechanical Thrombectomy</a></td>
  <td>æå‡ºåŸºäºä¸–ç•Œæ¨¡å‹çš„TD-MPC2ç®—æ³•ï¼Œæå‡æœºæ¢°å–æ “æœ¯ä¸­AIè‡ªä¸»å¯¼èˆªæ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">SAC</span> <span class="paper-tag">world model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25518v2" data-paper-url="./papers/250925518v2-world-model-for-ai-autonomous-navigation-in-mechanical-thrombectomy.html" onclick="toggleFavorite(this, '2509.25518v2', 'World Model for AI Autonomous Navigation in Mechanical Thrombectomy')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250924923v1-when-greedy-wins-emergent-exploitation-bias-in-meta-bandit-llm-train.html">When Greedy Wins: Emergent Exploitation Bias in Meta-Bandit LLM Training</a></td>
  <td>å…ƒ-Bandit LLMè®­ç»ƒä¸­æ¶Œç°çš„è´ªå©ªåˆ©ç”¨åå·®ç ”ç©¶</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward design</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.24923v1" data-paper-url="./papers/250924923v1-when-greedy-wins-emergent-exploitation-bias-in-meta-bandit-llm-train.html" onclick="toggleFavorite(this, '2509.24923v1', 'When Greedy Wins: Emergent Exploitation Bias in Meta-Bandit LLM Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250925582v1-safe-in-context-reinforcement-learning.html">Safe In-Context Reinforcement Learning</a></td>
  <td>æå‡ºå®‰å…¨ä¸Šä¸‹æ–‡å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œè§£å†³æ— å‚æ•°æ›´æ–°é€‚åº”è¿‡ç¨‹ä¸­çš„å®‰å…¨çº¦æŸé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25582v1" data-paper-url="./papers/250925582v1-safe-in-context-reinforcement-learning.html" onclick="toggleFavorite(this, '2509.25582v1', 'Safe In-Context Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250925176v1-siri-scaling-iterative-reinforcement-learning-with-interleaved-compr.html">SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression</a></td>
  <td>SIRIï¼šé€šè¿‡äº¤é”™å‹ç¼©æ‰©å±•è¿­ä»£å¼ºåŒ–å­¦ä¹ ï¼Œæå‡å¤§å‹æ¨ç†æ¨¡å‹çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25176v1" data-paper-url="./papers/250925176v1-siri-scaling-iterative-reinforcement-learning-with-interleaved-compr.html" onclick="toggleFavorite(this, '2509.25176v1', 'SIRI: Scaling Iterative Reinforcement Learning with Interleaved Compression')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250925100v1-orpo-distill-mixed-policy-preference-optimization-for-cross-architec.html">ORPO-Distill: Mixed-Policy Preference Optimization for Cross-Architecture LLM Distillation</a></td>
  <td>æå‡ºORPO-Distillï¼Œé€šè¿‡æ··åˆç­–ç•¥åå¥½ä¼˜åŒ–å®ç°è·¨æ¶æ„LLMè’¸é¦</td>
  <td class="tags-cell"><span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25100v1" data-paper-url="./papers/250925100v1-orpo-distill-mixed-policy-preference-optimization-for-cross-architec.html" onclick="toggleFavorite(this, '2509.25100v1', 'ORPO-Distill: Mixed-Policy Preference Optimization for Cross-Architecture LLM Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/251001269v1-safe-reinforcement-learning-based-vibration-control-overcoming-train.html">Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance</a></td>
  <td>æå‡ºåŸºäºLQRå¼•å¯¼çš„å®‰å…¨å¼ºåŒ–å­¦ä¹ æŒ¯åŠ¨æ§åˆ¶ï¼Œè§£å†³è®­ç»ƒè¿‡ç¨‹ä¸­çš„å®‰å…¨é£é™©ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2510.01269v1" data-paper-url="./papers/251001269v1-safe-reinforcement-learning-based-vibration-control-overcoming-train.html" onclick="toggleFavorite(this, '2510.01269v1', 'Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250925592v1-machine-learning-algorithms-for-improving-black-box-optimization-sol.html">Machine Learning Algorithms for Improving Black Box Optimization Solvers</a></td>
  <td>ç»¼è¿°ï¼šæœºå™¨å­¦ä¹ ç®—æ³•æå‡é»‘ç›’ä¼˜åŒ–æ±‚è§£å™¨æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">Mamba</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25592v1" data-paper-url="./papers/250925592v1-machine-learning-algorithms-for-improving-black-box-optimization-sol.html" onclick="toggleFavorite(this, '2509.25592v1', 'Machine Learning Algorithms for Improving Black Box Optimization Solvers')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250924547v1-leaf-a-robust-expert-based-framework-for-few-shot-continual-event-de.html">LEAF: A Robust Expert-Based Framework for Few-Shot Continual Event Detection</a></td>
  <td>LEAFï¼šä¸€ç§é²æ£’çš„åŸºäºä¸“å®¶çš„å°‘æ ·æœ¬æŒç»­äº‹ä»¶æ£€æµ‹æ¡†æ¶</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.24547v1" data-paper-url="./papers/250924547v1-leaf-a-robust-expert-based-framework-for-few-shot-continual-event-de.html" onclick="toggleFavorite(this, '2509.24547v1', 'LEAF: A Robust Expert-Based Framework for Few-Shot Continual Event Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (4 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/250924734v1-a-triangle-enables-multimodal-alignment-beyond-cosine-similarity.html">A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity</a></td>
  <td>æå‡ºTRIANGLEä»¥è§£å†³å¤šæ¨¡æ€å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.24734v1" data-paper-url="./papers/250924734v1-a-triangle-enables-multimodal-alignment-beyond-cosine-similarity.html" onclick="toggleFavorite(this, '2509.24734v1', 'A TRIANGLE Enables Multimodal Alignment Beyond Cosine Similarity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250924716v1-discrete-variational-autoencoding-via-policy-search.html">Discrete Variational Autoencoding via Policy Search</a></td>
  <td>æå‡ºåŸºäºç­–ç•¥æœç´¢çš„ç¦»æ•£å˜åˆ†è‡ªç¼–ç å™¨ï¼Œæå‡é«˜ç»´å›¾åƒé‡å»ºè´¨é‡ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.24716v1" data-paper-url="./papers/250924716v1-discrete-variational-autoencoding-via-policy-search.html" onclick="toggleFavorite(this, '2509.24716v1', 'Discrete Variational Autoencoding via Policy Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250925414v1-rethinking-parameter-sharing-for-llm-fine-tuning-with-multiple-loras.html">Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs</a></td>
  <td>æå‡ºALoRAï¼šä¸€ç§éå¯¹ç§°å¤šLoRAå¾®è°ƒæ–¹æ³•ï¼Œæå‡LLMå¤šä»»åŠ¡å’Œè”é‚¦å­¦ä¹ æ€§èƒ½ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.25414v1" data-paper-url="./papers/250925414v1-rethinking-parameter-sharing-for-llm-fine-tuning-with-multiple-loras.html" onclick="toggleFavorite(this, '2509.25414v1', 'Rethinking Parameter Sharing for LLM Fine-Tuning with Multiple LoRAs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250924610v2-orthalign-orthogonal-subspace-decomposition-for-non-interfering-mult.html">OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment</a></td>
  <td>OrthAlignï¼šæ­£äº¤å­ç©ºé—´åˆ†è§£è§£å†³å¤§æ¨¡å‹å¤šç›®æ ‡å¯¹é½ä¸­çš„å†²çªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.24610v2" data-paper-url="./papers/250924610v2-orthalign-orthogonal-subspace-decomposition-for-non-interfering-mult.html" onclick="toggleFavorite(this, '2509.24610v2', 'OrthAlign: Orthogonal Subspace Decomposition for Non-Interfering Multi-Objective Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)