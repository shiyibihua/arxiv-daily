---
layout: default
title: Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing
---

# Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.11258" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.11258v1</a>
  <a href="https://arxiv.org/pdf/2508.11258.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.11258v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.11258v1', 'Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ruicheng Xian, Yuxuan Wan, Han Zhao

**åˆ†ç±»**: cs.LG, cs.CL, cs.CY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-15

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåå¤„ç†æ¡†æ¶ä»¥å®ç°å°é—­LLMçš„å…¬å¹³ç®—æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…¬å¹³æ€§ç®—æ³•` `å¤§å‹è¯­è¨€æ¨¡å‹` `åå¤„ç†` `ç‰¹å¾æå–` `æ•°æ®æ•ˆç‡` `åˆ†ç±»å™¨è®­ç»ƒ` `ä¸Šä¸‹æ–‡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°é—­æƒé‡LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ— æ³•æœ‰æ•ˆåº”ç”¨ï¼Œå¯¼è‡´å…¬å¹³æ€§ä¿éšœé¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬ç ”ç©¶æå‡ºé€šè¿‡æç¤ºä»å°é—­æƒé‡LLMä¸­æå–ç‰¹å¾ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œåå¤„ç†è®­ç»ƒçš„å…¬å¹³åˆ†ç±»å™¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨æ•°æ®æ•ˆç‡å’Œå‡†ç¡®æ€§æ–¹é¢ä¼˜äºä¼ ç»Ÿå…¬å¹³åˆ†ç±»å™¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æå‡ºäº†ä¸€ç§æ¡†æ¶ï¼Œé€šè¿‡æç¤ºä»å°é—­æƒé‡çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­å¯¼å‡ºå…¬å¹³åˆ†ç±»å™¨ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºä¼ ç»Ÿçš„å…¬å¹³ç®—æ³•ï¼Œä½†åœ¨å°é—­æƒé‡LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­ä¸å†é€‚ç”¨ã€‚æˆ‘ä»¬çš„æ–¹æ³•å°†LLMè§†ä¸ºç‰¹å¾æå–å™¨ï¼Œé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè·å–æ¦‚ç‡é¢„æµ‹çš„ç‰¹å¾ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šåº”ç”¨å…¬å¹³ç®—æ³•è¿›è¡Œè½»é‡çº§åˆ†ç±»å™¨çš„åå¤„ç†è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå±•ç°å‡ºè‰¯å¥½çš„å‡†ç¡®æ€§ä¸å…¬å¹³æ€§æƒè¡¡ï¼Œå°¤å…¶åœ¨æ•°æ®æ•ˆç‡æ–¹é¢ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å°é—­æƒé‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸­å®ç°å…¬å¹³æ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºæ¨¡å‹å¾®è°ƒæˆ–æœ€ç»ˆå±‚åµŒå…¥çš„å¤´éƒ¨å¾®è°ƒï¼Œä½†åœ¨å°é—­æƒé‡LLMçš„ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­æ— æ³•é€‚ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMè§†ä¸ºç‰¹å¾æå–å™¨ï¼Œé€šè¿‡è®¾è®¡ç‰¹å®šçš„æç¤ºè·å–å…¶æ¦‚ç‡é¢„æµ‹çš„ç‰¹å¾ï¼Œå¹¶åŸºäºè¿™äº›ç‰¹å¾åº”ç”¨å…¬å¹³ç®—æ³•è¿›è¡Œåå¤„ç†è®­ç»ƒã€‚è¿™æ ·è®¾è®¡çš„åŸå› åœ¨äºèƒ½å¤Ÿåˆ©ç”¨ç°æœ‰å¼ºå¤§çš„LLMèƒ½åŠ›ï¼ŒåŒæ—¶é¿å…å¯¹æ¨¡å‹è¿›è¡Œç›´æ¥ä¿®æ”¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œé€šè¿‡è®¾è®¡çš„æç¤ºä»LLMä¸­æå–ç‰¹å¾ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨æå–çš„ç‰¹å¾è®¡ç®—å…¬å¹³æ€§ç»Ÿè®¡é‡ï¼›æœ€åï¼Œåº”ç”¨å…¬å¹³ç®—æ³•è®­ç»ƒè½»é‡çº§åˆ†ç±»å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„åå¤„ç†æ¡†æ¶ï¼Œä½¿å¾—åœ¨å°é—­æƒé‡LLMä¸Šå®ç°å…¬å¹³æ€§æˆä¸ºå¯èƒ½ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„æ ¹æœ¬åŒºåˆ«åœ¨äºä¸éœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œè€Œæ˜¯é€šè¿‡ç‰¹å¾æå–å’Œåå¤„ç†å®ç°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼Œè®ºæ–‡ä½¿ç”¨äº†ç‰¹å®šçš„æç¤ºç­–ç•¥æ¥è·å–LLMçš„æ¦‚ç‡é¢„æµ‹ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šè®¾è®¡äº†é€‚åˆçš„æŸå¤±å‡½æ•°å’Œè½»é‡çº§ç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿åˆ†ç±»å™¨çš„å…¬å¹³æ€§å’Œå‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ¡†æ¶çš„åˆ†ç±»å™¨åœ¨äº”ä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨æ•°æ®æ•ˆç‡æ–¹é¢ï¼Œä¼˜äºä¼ ç»Ÿçš„åŸºäºLLMåµŒå…¥çš„å…¬å¹³åˆ†ç±»å™¨ï¼Œä¸”åœ¨å‡†ç¡®æ€§ä¸å…¬å¹³æ€§ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èã€åŒ»ç–—å’Œæ‹›è˜ç­‰é«˜é£é™©åœºæ™¯ï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œç¡®ä¿ç®—æ³•çš„å…¬å¹³æ€§è‡³å…³é‡è¦ã€‚é€šè¿‡å®ç°å…¬å¹³çš„åˆ†ç±»å™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå‡å°‘ç®—æ³•å¯¹ä¸åŒç¾¤ä½“çš„åè§ï¼Œæå‡ç¤¾ä¼šå…¬å¹³æ€§ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨æ›´å¤šå°é—­LLMåœ¨å…¬å¹³æ€§ä¿éšœæ–¹é¢çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Instruction fine-tuned large language models (LLMs) enable a simple zero-shot or few-shot prompting paradigm, also known as in-context learning, for building prediction models. This convenience, combined with continued advances in LLM capability, has the potential to drive their adoption across a broad range of domains, including high-stakes applications where group fairness -- preventing disparate impacts across demographic groups -- is essential. The majority of existing approaches to enforcing group fairness on LLM-based classifiers rely on traditional fair algorithms applied via model fine-tuning or head-tuning on final-layer embeddings, but they are no longer applicable to closed-weight LLMs under the in-context learning setting, which include some of the most capable commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we propose a framework for deriving fair classifiers from closed-weight LLMs via prompting: the LLM is treated as a feature extractor, and features are elicited from its probabilistic predictions (e.g., token log probabilities) using prompts strategically designed for the specified fairness criterion to obtain sufficient statistics for fair classification; a fair algorithm is then applied to these features to train a lightweight fair classifier in a post-hoc manner. Experiments on five datasets, including three tabular ones, demonstrate strong accuracy-fairness tradeoffs for the classifiers derived by our framework from both open-weight and closed-weight LLMs; in particular, our framework is data-efficient and outperforms fair classifiers trained on LLM embeddings (i.e., head-tuning) or from scratch on raw tabular features.

