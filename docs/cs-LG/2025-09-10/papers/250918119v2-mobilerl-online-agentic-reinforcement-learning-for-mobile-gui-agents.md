---
layout: default
title: MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents
---

# MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.18119" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.18119v2</a>
  <a href="https://arxiv.org/pdf/2509.18119.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.18119v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.18119v2', 'MobileRL: Online Agentic Reinforcement Learning for Mobile GUI Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Xu, Xiao Liu, Xinghan Liu, Jiaqi Fu, Hanchen Zhang, Bohao Jing, Shudan Zhang, Yuting Wang, Wenyi Zhao, Yuxiao Dong

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-10 (æ›´æ–°: 2025-10-24)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/THUDM/MobileRL)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMobileRLæ¡†æ¶ï¼Œé€šè¿‡åœ¨çº¿å¼ºåŒ–å­¦ä¹ æå‡ç§»åŠ¨GUIæ™ºèƒ½ä½“çš„ä»»åŠ¡å®Œæˆèƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç§»åŠ¨GUIæ™ºèƒ½ä½“` `å¼ºåŒ–å­¦ä¹ ` `åœ¨çº¿å­¦ä¹ ` `éš¾åº¦è‡ªé€‚åº”` `å¥–åŠ±é‡å¡‘`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç§»åŠ¨GUIæ™ºèƒ½ä½“é¢ä¸´ä»»åŠ¡éš¾åº¦å·®å¼‚å¤§å’Œç¯å¢ƒé‡‡æ ·æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´å¼ºåŒ–å­¦ä¹ è®­ç»ƒå›°éš¾ã€‚
2. MobileRLæ¡†æ¶é€šè¿‡éš¾åº¦è‡ªé€‚åº”çš„æ­£å‘å›æ”¾ã€å¤±è´¥è¯¾ç¨‹è¿‡æ»¤å’Œæœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMobileRLåœ¨AndroidWorldå’ŒAndroidLabä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†ä»»åŠ¡æˆåŠŸç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åœ¨çº¿æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ¡†æ¶MobileRLï¼Œæ—¨åœ¨æå‡ç§»åŠ¨GUIæ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚ç”±äºä»»åŠ¡éš¾åº¦å‘ˆç°é‡å°¾åˆ†å¸ƒä»¥åŠå¤§è§„æ¨¡ç¯å¢ƒé‡‡æ ·æ•ˆç‡ä½ä¸‹ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ å¼€å‘æœ‰æ•ˆçš„ç§»åŠ¨GUIæ™ºèƒ½ä½“ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚MobileRLçš„æ ¸å¿ƒæ˜¯éš¾åº¦è‡ªé€‚åº”GRPOï¼ˆADAGRPOï¼‰ç®—æ³•ã€‚åœ¨ADAGRPOä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†éš¾åº¦è‡ªé€‚åº”çš„æ­£å‘å›æ”¾å’Œå¤±è´¥è¯¾ç¨‹è¿‡æ»¤ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿé€‚åº”ä¸åŒçš„ä»»åŠ¡éš¾åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†æœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´ç­–ç•¥ï¼Œä»¥é‡å¡‘å¤šè½®æ™ºèƒ½ä½“ä»»åŠ¡ä¸­ä¸ä»»åŠ¡é•¿åº¦ç›¸å…³çš„å¥–åŠ±ã€‚è¿™äº›ç­–ç•¥å…±åŒç¨³å®šäº†å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼Œæé«˜äº†æ ·æœ¬æ•ˆç‡ï¼Œå¹¶åœ¨å„ç§ç§»åŠ¨åº”ç”¨å’Œä»»åŠ¡ä¸­äº§ç”Ÿäº†å¼ºå¤§çš„æ€§èƒ½ã€‚æˆ‘ä»¬å°†MOBILERLåº”ç”¨äºä¸¤ä¸ªå¼€æºæ¨¡å‹ï¼ˆQwen2.5-VL-7B-Instructå’ŒGLM-4.1V-9B-Baseï¼‰ã€‚ç”±æ­¤äº§ç”Ÿçš„MOBILERL-9Bæ¨¡å‹åœ¨AndroidWorldï¼ˆ80.2%ï¼‰å’ŒAndroidLabï¼ˆ53.6%ï¼‰ä¸Šçš„æˆåŠŸç‡æ–¹é¢å‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ã€‚MOBILERLæ¡†æ¶å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºå¼ºåŒ–å­¦ä¹ çš„ç§»åŠ¨GUIæ™ºèƒ½ä½“åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é¢ä¸´ä¸¤ä¸ªä¸»è¦é—®é¢˜ï¼šä¸€æ˜¯ä»»åŠ¡éš¾åº¦åˆ†å¸ƒä¸å‡åŒ€ï¼Œå­˜åœ¨å¤§é‡çš„ç®€å•ä»»åŠ¡å’Œå°‘é‡å›°éš¾ä»»åŠ¡ï¼Œå¯¼è‡´æ¨¡å‹éš¾ä»¥æœ‰æ•ˆå­¦ä¹ ï¼›äºŒæ˜¯ç¯å¢ƒé‡‡æ ·æ•ˆç‡ä½ä¸‹ï¼Œéœ€è¦å¤§é‡çš„äº¤äº’æ‰èƒ½è·å¾—æœ‰æ•ˆçš„è®­ç»ƒæ ·æœ¬ï¼Œè®­ç»ƒæˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMobileRLçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡éš¾åº¦è‡ªé€‚åº”çš„ç­–ç•¥æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒé€šè¿‡éš¾åº¦è‡ªé€‚åº”çš„æ­£å‘å›æ”¾æ¥å¢åŠ å›°éš¾æ ·æœ¬çš„åˆ©ç”¨ç‡ï¼Œé€šè¿‡å¤±è´¥è¯¾ç¨‹è¿‡æ»¤æ¥é¿å…ç®€å•æ ·æœ¬çš„å¹²æ‰°ï¼Œå¹¶é€šè¿‡æœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´æ¥ä¼˜åŒ–å¥–åŠ±ä¿¡å·ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMobileRLæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) ç¯å¢ƒäº¤äº’æ¨¡å—ï¼Œè´Ÿè´£ä¸ç§»åŠ¨GUIç¯å¢ƒè¿›è¡Œäº¤äº’ï¼Œæ”¶é›†è®­ç»ƒæ ·æœ¬ï¼›2) éš¾åº¦è¯„ä¼°æ¨¡å—ï¼Œè´Ÿè´£è¯„ä¼°å½“å‰ä»»åŠ¡çš„éš¾åº¦ï¼›3) ADAGRPOç®—æ³•æ¨¡å—ï¼ŒåŒ…å«éš¾åº¦è‡ªé€‚åº”çš„æ­£å‘å›æ”¾ã€å¤±è´¥è¯¾ç¨‹è¿‡æ»¤å’Œæœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´ç­–ç•¥ï¼Œç”¨äºä¼˜åŒ–æ™ºèƒ½ä½“çš„ç­–ç•¥ï¼›4) æ¨¡å‹æ›´æ–°æ¨¡å—ï¼Œè´Ÿè´£æ ¹æ®æ”¶é›†åˆ°çš„è®­ç»ƒæ ·æœ¬æ›´æ–°æ™ºèƒ½ä½“çš„æ¨¡å‹å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šMobileRLçš„å…³é”®åˆ›æ–°åœ¨äºADAGRPOç®—æ³•ï¼Œå®ƒé€šè¿‡éš¾åº¦è‡ªé€‚åº”çš„æ­£å‘å›æ”¾å’Œå¤±è´¥è¯¾ç¨‹è¿‡æ»¤æ¥è§£å†³ä»»åŠ¡éš¾åº¦åˆ†å¸ƒä¸å‡åŒ€çš„é—®é¢˜ï¼Œå¹¶é€šè¿‡æœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´æ¥ä¼˜åŒ–å¥–åŠ±ä¿¡å·ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMobileRLèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨è®­ç»ƒæ ·æœ¬ï¼Œæé«˜è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šéš¾åº¦è‡ªé€‚åº”æ­£å‘å›æ”¾ï¼šæ ¹æ®ä»»åŠ¡éš¾åº¦åŠ¨æ€è°ƒæ•´æ­£å‘å›æ”¾çš„æ¦‚ç‡ï¼Œå¢åŠ å›°éš¾æ ·æœ¬çš„åˆ©ç”¨ç‡ã€‚å¤±è´¥è¯¾ç¨‹è¿‡æ»¤ï¼šè¿‡æ»¤æ‰ç®€å•çš„å¤±è´¥æ ·æœ¬ï¼Œé¿å…å…¶å¯¹æ¨¡å‹è®­ç»ƒäº§ç”Ÿè´Ÿé¢å½±å“ã€‚æœ€çŸ­è·¯å¾„å¥–åŠ±è°ƒæ•´ï¼šæ ¹æ®ä»»åŠ¡çš„æœ€çŸ­è·¯å¾„é•¿åº¦è°ƒæ•´å¥–åŠ±ä¿¡å·ï¼Œé¿å…å¥–åŠ±ç¨€ç–çš„é—®é¢˜ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MobileRLåœ¨AndroidWorldå’ŒAndroidLabä¸¤ä¸ªåŸºå‡†æµ‹è¯•é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å…·ä½“è€Œè¨€ï¼Œä½¿ç”¨MOBILERL-9Bæ¨¡å‹åœ¨AndroidWorldä¸Šçš„æˆåŠŸç‡è¾¾åˆ°äº†80.2%ï¼Œåœ¨AndroidLabä¸Šçš„æˆåŠŸç‡è¾¾åˆ°äº†53.6%ï¼Œå‡è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MobileRLæ¡†æ¶å¯åº”ç”¨äºå„ç§ç§»åŠ¨GUIè‡ªåŠ¨åŒ–ä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªåŠ¨åŒ–æµ‹è¯•ã€æ™ºèƒ½åŠ©æ‰‹ã€è¾…åŠ©åŠŸèƒ½ç­‰ã€‚å®ƒå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°å®Œæˆç§»åŠ¨è®¾å¤‡ä¸Šçš„å„ç§æ“ä½œï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„GUIç¯å¢ƒï¼Œä¾‹å¦‚æ¡Œé¢åº”ç”¨å’Œç½‘é¡µåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Building general-purpose graphical user interface (GUI) agents has become increasingly promising with the progress in vision language models. However, developing effective mobile GUI agents with reinforcement learning (RL) remains challenging due to the heavy-tailed distribution of task difficulty and the inefficiency of large-scale environment sampling. We present an online agentic reinforcement learning framework MobileRL to enhance GUI agents in mobile environments. Its core component is the Difficulty-ADAptive GRPO (ADAGRPO) algorithm. In ADAGRPO, we design difficulty-adaptive positive replay and failure curriculum filtering to adapt the model to different task difficulties. We introduce the shortest-path reward adjustment strategy to reshape rewards concerning the task length in multi-turn agentic tasks. Those strategies jointly stabilize RL training, improve sample efficiency, and generate strong performance across diverse mobile apps and tasks. We apply MOBILERL to two open models (Qwen2.5-VL-7B-Instruct and GLM-4.1V-9B-Base). The resultant MOBILERL-9B model achieves state-of-the-art results in terms of success rates on both AndroidWorld (80.2%) and AndroidLab (53.6%). The MOBILERL framework is open-sourced at: https://github.com/THUDM/MobileRL.

