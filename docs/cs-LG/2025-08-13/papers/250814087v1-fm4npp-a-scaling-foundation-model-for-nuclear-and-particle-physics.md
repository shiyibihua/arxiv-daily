---
layout: default
title: FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics
---

# FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14087" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14087v1</a>
  <a href="https://arxiv.org/pdf/2508.14087.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14087v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14087v1', 'FM4NPP: A Scaling Foundation Model for Nuclear and Particle Physics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: David Park, Shuhang Li, Yi Huang, Xihaier Luo, Haiwang Yu, Yeonju Go, Christopher Pinkenburg, Yuewei Lin, Shinjae Yoo, Joseph Osborn, Jin Huang, Yihui Ren

**åˆ†ç±»**: cs.LG, cs.AI, hep-ex

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFM4NPPä»¥è§£å†³ç²’å­ç‰©ç†å®éªŒæ•°æ®ç¨€ç–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç²’å­ç‰©ç†` `è‡ªç›‘ç£å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `æ•°æ®ç¨€ç–` `å¤šä»»åŠ¡å­¦ä¹ ` `ç¥ç»ç½‘ç»œ` `æ¨¡å‹å¯æ‰©å±•æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç²’å­ç‰©ç†å®éªŒæ•°æ®æ—¶é¢ä¸´ç¨€ç–æ€§å’Œç©ºé—´åˆ†å¸ƒçš„æŒ‘æˆ˜ï¼Œéš¾ä»¥æœ‰æ•ˆæå–ä¿¡æ¯ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£è®­ç»ƒæ–¹æ³•ï¼Œç»“åˆäº†å¤§è§„æ¨¡æ•°æ®é›†å’Œä»»åŠ¡ç‰¹å®šé€‚é…å™¨ï¼Œä»¥æå‡æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„åŸºç¡€æ¨¡å‹åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡è¶…è¶ŠåŸºçº¿æ¨¡å‹ï¼Œä¸”åœ¨æ•°æ®é«˜æ•ˆé€‚åº”æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡è‡ªç›‘ç£å­¦ä¹ é©å‘½æ€§åœ°æ¨åŠ¨äº†äººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œæ¿€å‘äº†ç§‘å­¦åŸºç¡€æ¨¡å‹çš„ç ”ç©¶ã€‚ç„¶è€Œï¼Œå°†è¿™ä¸€èƒ½åŠ›åº”ç”¨äºå®éªŒç²’å­ç‰©ç†å­¦é¢ä¸´æŒ‘æˆ˜ï¼Œå› ä¸ºæ¢æµ‹å™¨æ•°æ®çš„ç¨€ç–æ€§å’Œç©ºé—´åˆ†å¸ƒç‰¹æ€§ä¸è‡ªç„¶è¯­è¨€æˆªç„¶ä¸åŒã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ç²’å­ç‰©ç†å­¦åŸºç¡€æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªåŒ…å«è¶…è¿‡1100ä¸‡ç²’å­ç¢°æ’äº‹ä»¶çš„æ–°æ•°æ®é›†åŠä¸€ç³»åˆ—ä¸‹æ¸¸ä»»åŠ¡å’Œæ ‡æ³¨æ•°æ®è¿›è¡Œè¯„ä¼°ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£è®­ç»ƒæ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†å…¶ç¥ç»å¯æ‰©å±•æ€§ï¼Œæ¨¡å‹å‚æ•°é«˜è¾¾1.88äº¿ã€‚é€šè¿‡å†»ç»“æƒé‡å’Œä»»åŠ¡ç‰¹å®šé€‚é…å™¨ï¼Œè¯¥åŸºç¡€æ¨¡å‹åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸”è¡¨ç°å‡ºå¼ºå¤§çš„æ•°æ®é«˜æ•ˆé€‚åº”èƒ½åŠ›ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œè¯¥æ¨¡å‹æå–çš„è¡¨ç¤ºæ˜¯ä»»åŠ¡æ— å…³çš„ï¼Œä½†å¯ä»¥é€šè¿‡å•ä¸€çº¿æ€§æ˜ å°„ä¸ºä¸åŒä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œä¸“ä¸šåŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ç²’å­ç‰©ç†å®éªŒæ•°æ®çš„ç¨€ç–æ€§å’Œç©ºé—´åˆ†å¸ƒç‰¹æ€§å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ­¤ç±»æ•°æ®æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæå–æœ‰ç”¨ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£è®­ç»ƒæ–¹æ³•ï¼Œåˆ©ç”¨å¤§è§„æ¨¡çš„ç²’å­ç¢°æ’äº‹ä»¶æ•°æ®é›†ï¼Œç»“åˆä»»åŠ¡ç‰¹å®šé€‚é…å™¨ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ã€‚é€šè¿‡å†»ç»“æƒé‡å¹¶å¼•å…¥é€‚é…å™¨ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒä»»åŠ¡é—´å®ç°é«˜æ•ˆè¿ç§»å­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œä»»åŠ¡é€‚é…ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œåˆ©ç”¨æ–°æ•°æ®é›†è¿›è¡Œè‡ªç›‘ç£è®­ç»ƒï¼Œæ¥ç€é€šè¿‡å†»ç»“æ¨¡å‹æƒé‡å¹¶æ·»åŠ é€‚é…å™¨æ¥é€‚åº”ä¸åŒä¸‹æ¸¸ä»»åŠ¡ï¼Œæœ€åè¿›è¡Œè¯„ä¼°å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é€‚ç”¨äºç²’å­ç‰©ç†æ•°æ®çš„è‡ªç›‘ç£è®­ç»ƒæ–¹æ³•ï¼Œå¹¶ç»“åˆä»»åŠ¡ç‰¹å®šé€‚é…å™¨ï¼Œä½¿å¾—æ¨¡å‹åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­è¡¨ç°å‡ºè‰²ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å•ä¸€ä»»åŠ¡è®­ç»ƒæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é«˜è¾¾1.88äº¿å‚æ•°çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œä½¿ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–è‡ªç›‘ç£å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡çº¿æ€§æ˜ å°„å®ç°ä»»åŠ¡é€‚åº”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„åŸºç¡€æ¨¡å‹åœ¨æ‰€æœ‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®é«˜æ•ˆé€‚åº”æ€§æ–¹é¢è¡¨ç°çªå‡ºï¼Œå±•ç¤ºäº†å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦æœªè¯¦ç»†è¯´æ˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç²’å­ç‰©ç†å®éªŒæ•°æ®åˆ†æã€ç§‘å­¦è®¡ç®—ä»¥åŠå…¶ä»–éœ€è¦å¤„ç†ç¨€ç–æ•°æ®çš„é¢†åŸŸã€‚é€šè¿‡æå‡æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç²’å­ç‰©ç†å­¦çš„ç ”ç©¶è¿›å±•ï¼Œå¹¶ä¸ºç›¸å…³é¢†åŸŸçš„ç§‘å­¦æ¢ç´¢æä¾›æ–°çš„å·¥å…·å’Œæ–¹æ³•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models have revolutionized artificial intelligence by enabling large, generalizable models trained through self-supervision. This paradigm has inspired the development of scientific foundation models (FMs). However, applying this capability to experimental particle physics is challenging due to the sparse, spatially distributed nature of detector data, which differs dramatically from natural language. This work addresses if an FM for particle physics can scale and generalize across diverse tasks. We introduce a new dataset with more than 11 million particle collision events and a suite of downstream tasks and labeled data for evaluation. We propose a novel self-supervised training method for detector data and demonstrate its neural scalability with models that feature up to 188 million parameters. With frozen weights and task-specific adapters, this FM consistently outperforms baseline models across all downstream tasks. The performance also exhibits robust data-efficient adaptation. Further analysis reveals that the representations extracted by the FM are task-agnostic but can be specialized via a single linear mapping for different downstream tasks.

