---
layout: default
title: Large-Small Model Collaborative Framework for Federated Continual Learning
---

# Large-Small Model Collaborative Framework for Federated Continual Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09489" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09489v1</a>
  <a href="https://arxiv.org/pdf/2508.09489.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09489v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09489v1', 'Large-Small Model Collaborative Framework for Federated Continual Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Yu, Xin Yang, Boyang Fan, Xuemei Cao, Hanlin Gu, Lixin Fan, Qiang Yang

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤§å°æ¨¡å‹åä½œæ¡†æ¶ä»¥è§£å†³è”é‚¦æŒç»­å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æŒç»­å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `å°æ¨¡å‹` `æ¨¡å‹è’¸é¦` `ä¸ªæ€§åŒ–å­¦ä¹ ` `çŸ¥è¯†èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è”é‚¦æŒç»­å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†åŸºç¡€æ¨¡å‹æ—¶é¢ä¸´æ•°æ®éšç§å’Œæ¨¡å‹é—å¿˜çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åä½œæ¡†æ¶ï¼Œåˆ©ç”¨è½»é‡çº§æœ¬åœ°æ¨¡å‹ä½œä¸ºæ¡¥æ¢ï¼ŒæŒç»­é€‚åº”æ–°ä»»åŠ¡å¹¶å¢å¼ºå¤§æ¨¡å‹çš„æ•ˆç”¨ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ä½¿ç”¨å¼‚æ„å°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œä»ç„¶èƒ½å¤Ÿå®ç°æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒç»­å­¦ä¹ ï¼ˆCLï¼‰åœ¨åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰ä¸­çš„åº”ç”¨æ˜¯ä¸€ä¸ªé‡è¦ä½†å°šæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨è”é‚¦æŒç»­å­¦ä¹ ï¼ˆFCLï¼‰ä¸­ï¼Œå„ä¸ªå®¢æˆ·ç«¯åœ¨ä¸¥æ ¼çš„æ•°æ®å’Œé€šä¿¡é™åˆ¶ä¸‹ä»ç§æœ‰çš„ã€ä¸æ–­æ¼”å˜çš„ä»»åŠ¡æµä¸­å­¦ä¹ ã€‚å°½ç®¡FMså…·æœ‰å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œä½†åœ¨æœ¬åœ°ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¡¨ç°ä¸ä½³ï¼Œæ— æ³•åˆ©ç”¨ç§æœ‰æœ¬åœ°æ•°æ®ã€‚æ­¤å¤–ï¼ŒFMsåœ¨å­¦ä¹ æ–°ä»»åŠ¡æ—¶å®¹æ˜“é—å¿˜å…ˆå‰çŸ¥è¯†ï¼Œä¸»è¦ç”±äºå…¶åºå¤§çš„å‚æ•°é‡å’Œé«˜æ¨¡å‹å¤æ‚æ€§ã€‚ç›¸å¯¹è€Œè¨€ï¼Œå°æ¨¡å‹å¯ä»¥åœ¨èµ„æºå—é™çš„æ¡ä»¶ä¸‹è¿›è¡Œæœ¬åœ°è®­ç»ƒï¼Œå¹¶å—ç›Šäºæ›´æˆç†Ÿçš„CLæŠ€æœ¯ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†FCLä¸­çš„ç¬¬ä¸€ä¸ªåä½œæ¡†æ¶ï¼Œè½»é‡çº§æœ¬åœ°æ¨¡å‹ä½œä¸ºåŠ¨æ€æ¡¥æ¢ï¼ŒæŒç»­é€‚åº”æ–°ä»»åŠ¡ï¼ŒåŒæ—¶å¢å¼ºå¤§æ¨¡å‹çš„æ•ˆç”¨ã€‚æˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸¤ä¸ªæ–°ç»„ä»¶ï¼šå°æ¨¡å‹æŒç»­å¾®è°ƒä»¥é˜²æ­¢å°æ¨¡å‹çš„æš‚æ—¶é—å¿˜ï¼›é€ä¸ªè’¸é¦åœ¨æœåŠ¡å™¨ä¸Šæ‰§è¡Œå¼‚æ„æœ¬åœ°çŸ¥è¯†çš„ä¸ªæ€§åŒ–èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå³ä½¿å®¢æˆ·ç«¯ä½¿ç”¨å¼‚æ„å°æ¨¡å‹ï¼Œè¯¥æ¡†æ¶ä¹Ÿè¡¨ç°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºç¡€æ¨¡å‹åœ¨è”é‚¦æŒç»­å­¦ä¹ ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®éšç§å’Œæ¨¡å‹é—å¿˜æ–¹é¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåˆ©ç”¨æœ¬åœ°ç§æœ‰æ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æœ¬åœ°ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªåä½œæ¡†æ¶ï¼Œé€šè¿‡è½»é‡çº§å°æ¨¡å‹ä½œä¸ºåŠ¨æ€æ¡¥æ¢ï¼ŒæŒç»­é€‚åº”æ–°ä»»åŠ¡ï¼ŒåŒæ—¶æå‡å¤§æ¨¡å‹çš„æ•ˆç”¨ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨ç»“åˆå°æ¨¡å‹çš„çµæ´»æ€§ä¸å¤§æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šå°æ¨¡å‹æŒç»­å¾®è°ƒæ¨¡å—å’Œé€ä¸ªè’¸é¦æ¨¡å—ã€‚å°æ¨¡å‹åœ¨æœ¬åœ°è¿›è¡ŒæŒç»­å¾®è°ƒä»¥é˜²æ­¢é—å¿˜ï¼Œè€Œé€ä¸ªè’¸é¦æ¨¡å—åˆ™åœ¨æœåŠ¡å™¨ç«¯èåˆæ¥è‡ªä¸åŒå®¢æˆ·ç«¯çš„çŸ¥è¯†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†å°æ¨¡å‹æŒç»­å¾®è°ƒå’Œé€ä¸ªè’¸é¦ä¸¤ä¸ªæ–°ç»„ä»¶ï¼Œä½¿å¾—å°æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°é€‚åº”æ–°ä»»åŠ¡ï¼ŒåŒæ—¶å®ç°ä¸ªæ€§åŒ–çš„çŸ¥è¯†èåˆã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºå¼ºè°ƒäº†å°æ¨¡å‹ä¸å¤§æ¨¡å‹ä¹‹é—´çš„åä½œã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å°æ¨¡å‹æŒç»­å¾®è°ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡æ–°æ—§çŸ¥è¯†çš„å­¦ä¹ ï¼›é€ä¸ªè’¸é¦åˆ™é€šè¿‡è®¾è®¡ä¸ªæ€§åŒ–çš„çŸ¥è¯†èåˆç­–ç•¥ï¼Œç¡®ä¿ä¸åŒå®¢æˆ·ç«¯çš„çŸ¥è¯†èƒ½å¤Ÿæœ‰æ•ˆæ•´åˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ¡†æ¶åœ¨ä½¿ç”¨å¼‚æ„å°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨è”é‚¦æŒç»­å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŒ»ç–—ã€é‡‘èé£æ§å’Œä¸ªæ€§åŒ–æ¨èç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿåœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œå®ç°æ¨¡å‹çš„æŒç»­å­¦ä¹ ä¸ä¼˜åŒ–ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨è”é‚¦å­¦ä¹ åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­çš„è½åœ°ï¼Œæå‡æ¨¡å‹çš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Continual learning (CL) for Foundation Models (FMs) is an essential yet underexplored challenge, especially in Federated Continual Learning (FCL), where each client learns from a private, evolving task stream under strict data and communication constraints. Despite their powerful generalization abilities, FMs often exhibit suboptimal performance on local downstream tasks, as they are unable to utilize private local data. Furthermore, enabling FMs to learn new tasks without forgetting prior knowledge is inherently a challenging problem, primarily due to their immense parameter count and high model complexity. In contrast, small models can be trained locally under resource-constrained conditions and benefit from more mature CL techniques. To bridge the gap between small models and FMs, we propose the first collaborative framework in FCL, where lightweight local models act as a dynamic bridge, continually adapting to new tasks while enhancing the utility of the large model. Two novel components are also included: Small Model Continual Fine-tuning is for preventing small models from temporal forgetting; One-by-One Distillation performs personalized fusion of heterogeneous local knowledge on the server. Experimental results demonstrate its superior performance, even when clients utilize heterogeneous small models.

