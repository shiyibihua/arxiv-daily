---
layout: default
title: EEGDM: EEG Representation Learning via Generative Diffusion Model
---

# EEGDM: EEG Representation Learning via Generative Diffusion Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14086" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.14086v3</a>
  <a href="https://arxiv.org/pdf/2508.14086.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14086v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14086v3', 'EEGDM: EEG Representation Learning via Generative Diffusion Model')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Jia Hong Puah, Sim Kuan Goh, Ziwei Zhang, Zixuan Ye, Chow Khuen Chan, Kheng Seang Lim, Si Lei Fong, Kok Sin Woon, Cuntai Guan

**ÂàÜÁ±ª**: cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-13 (Êõ¥Êñ∞: 2025-09-01)

**Â§áÊ≥®**: EEGDM Preprint 10 Pages

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/jhpuah/EEGDM)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫EEGDM‰ª•Ëß£ÂÜ≥EEG‰ø°Âè∑Ë°®Á§∫Â≠¶‰π†ÊåëÊàò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËÑëÁîµÂõæ` `ÁîüÊàêÊâ©Êï£Ê®°Âûã` `Ë°®Á§∫Â≠¶‰π†` `Á•ûÁªèÁΩëÁªú` `Ëá™ÁõëÁù£Â≠¶‰π†` `Áô´Áó´Ê£ÄÊµã` `Êó∂Èó¥Âä®ÊÄÅ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâEEGË°®Á§∫Â≠¶‰π†ÊñπÊ≥ïÈù¢‰∏¥È´òËÆ°ÁÆóÊàêÊú¨ÂíåÊÄßËÉΩÊèêÂçáÊúâÈôêÁöÑÈóÆÈ¢òÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ø°Âè∑ÂèòÂºÇÊÄßÂíåÊ≥®Èáä‰∏çË∂≥ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁîüÊàêÊâ©Êï£Ê®°ÂûãÁöÑEEGË°®Á§∫Â≠¶‰π†Ê°ÜÊû∂ÔºåÈÄöËøáÁªìÊûÑÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÊçïÊçâEEG‰ø°Âè∑ÁöÑÊó∂Èó¥Âä®ÊÄÅ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEEGDMÂú®Áô´Áó´Ê£ÄÊµã‰ªªÂä°‰∏≠‰ºò‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíåÊΩúÂäõ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ËÑëÁîµÂõæÔºàEEGÔºâÂú®ÁõëÊµãÂ§ßËÑëÂíåËØäÊñ≠Á•ûÁªèÁ≥ªÁªüÁñæÁóÖÔºàÂ¶ÇÁô´Áó´Ôºâ‰∏≠Ëá≥ÂÖ≥ÈáçË¶ÅÔºå‰ΩÜ‰ªéÂéüÂßãEEG‰ø°Âè∑‰∏≠Â≠¶‰π†ÊúâÊÑè‰πâÁöÑË°®Á§∫‰ªçÁÑ∂ÂÖ∑ÊúâÊåëÊàòÊÄßÔºå‰∏ªË¶ÅÁî±‰∫éÊ≥®ÈáäÊúâÈôêÂíå‰ø°Âè∑ÂèòÂºÇÊÄßÈ´ò„ÄÇËøëÊúüÔºåEEGÂü∫Á°ÄÊ®°ÂûãÔºàFMsÔºâÈÄöËøáÈááÁî®ÂèòÊç¢Âô®Êû∂ÊûÑÂíåËá™ÁõëÁù£È¢ÑËÆ≠ÁªÉÊñπÊ≥ïÂ±ïÁé∞Âá∫ÊΩúÂäõÔºå‰ΩÜËøô‰∫õÂ§ßÂûãÊ®°ÂûãÂú®ËÆ≠ÁªÉÂíåÊé®ÁêÜÊó∂ÁöÑËÆ°ÁÆóÊàêÊú¨È´òÔºå‰∏îÊÄßËÉΩÊèêÂçáÊúâÈôê„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁîüÊàêÊâ©Êï£Ê®°ÂûãÁöÑEEGË°®Á§∫Â≠¶‰π†Ê°ÜÊû∂ÔºàEEGDMÔºâÔºåÈÄöËøáÁªìÊûÑÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãËøõË°åÊâ©Êï£È¢ÑËÆ≠ÁªÉÔºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâEEG‰ø°Âè∑ÁöÑÊó∂Èó¥Âä®ÊÄÅÔºåÂπ∂‰ΩøÁî®ÂéªÂô™Êâ©Êï£Ê¶ÇÁéáÊ®°ÂûãÊ°ÜÊû∂ËøõË°åËÆ≠ÁªÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEEGDMÂú®Â§ö‰∫ã‰ª∂Êï∞ÊçÆÈõÜ‰∏äË∂ÖË∂ä‰∫ÜÁé∞ÊúâÊñπÊ≥ïÔºåÊòæÁ§∫Âá∫ÂÖ∂‰Ωú‰∏∫EEGÂü∫Á°ÄÊ®°ÂûãÁöÑÊúâÂâçÊôØÁöÑÊõø‰ª£ÊñπÊ°à„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥‰ªéÂéüÂßãEEG‰ø°Âè∑‰∏≠Â≠¶‰π†ÊúâÊïàË°®Á§∫ÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ËÆ°ÁÆóÊàêÊú¨ÂíåÊÄßËÉΩÊèêÂçáÊñπÈù¢Â≠òÂú®‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂú®‰ø°Âè∑ÂèòÂºÇÊÄßÂíåÊ≥®ÈáäÁ®ÄÁº∫ÁöÑÊÉÖÂÜµ‰∏ã„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊèêÂá∫Âü∫‰∫éÁîüÊàêÊâ©Êï£Ê®°ÂûãÁöÑEEGË°®Á§∫Â≠¶‰π†Ê°ÜÊû∂ÔºàEEGDMÔºâÔºåÈÄöËøáÁªìÊûÑÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºàSSMDPÔºâËøõË°åÊâ©Êï£È¢ÑËÆ≠ÁªÉÔºå‰ª•Êõ¥Â•ΩÂú∞ÊçïÊçâEEG‰ø°Âè∑ÁöÑÊó∂Èó¥Âä®ÊÄÅ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÈò∂ÊÆµÔºöÈ¶ñÂÖàÊòØ‰ΩøÁî®ÂéªÂô™Êâ©Êï£Ê¶ÇÁéáÊ®°ÂûãÔºàDDPMÔºâËøõË°åÈ¢ÑËÆ≠ÁªÉÔºåÁÑ∂ÂêéÂ∞ÜÂæóÂà∞ÁöÑÊΩúÂú®EEGË°®Á§∫Áî®‰∫é‰∏ãÊ∏∏ÂàÜÁ±ª‰ªªÂä°ÔºåÈááÁî®ÊΩúÂú®ËûçÂêàÂèòÊç¢Âô®ÔºàLFTÔºâËøõË°åÂ§ÑÁêÜ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÂ§ßÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÁªìÂêàÁîüÊàêÊâ©Êï£Ê®°Âûã‰∏éEEG‰ø°Âè∑ÁöÑÊó∂Èó¥Âä®ÊÄÅÊçïÊçâËÉΩÂäõÔºåÊòæËëóÊèêÂçá‰∫ÜË°®Á§∫Â≠¶‰π†ÁöÑÊïàÊûúÔºå‰∏éÁé∞ÊúâÁöÑEEGÂü∫Á°ÄÊ®°ÂûãÁõ∏ÊØîÔºåÊèê‰æõ‰∫ÜÊõ¥È´òÁöÑÊÄßËÉΩÂíåÊõ¥‰ΩéÁöÑËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÔºå‰ª•‰ºòÂåñÊΩúÂú®Ë°®Á§∫ÁöÑÂ≠¶‰π†ËøáÁ®ãÔºåÁ°Æ‰øùÊ®°ÂûãÂú®Â§öÊ†∑ÂåñÁöÑEEGÊï∞ÊçÆ‰∏äÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõ„ÄÇÈÄöËøáÁ≤æÁªÜÁöÑÂèÇÊï∞ËÆæÁΩÆÔºåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑËÆ≠ÁªÉÊïàÁéáÂíåÊé®ÁêÜÈÄüÂ∫¶„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåEEGDMÂú®Áô´Áó´Ê£ÄÊµã‰ªªÂä°‰∏≠Áõ∏ËæÉ‰∫éÁé∞ÊúâÁöÑÊúÄÂÖàËøõÊñπÊ≥ïÔºåÊÄßËÉΩÊèêÂçáÊòæËëóÔºåÂÖ∑‰ΩìÂú®TUEVÂíåCHB-MITÊï∞ÊçÆÈõÜ‰∏äÂùáË°®Áé∞Âá∫Êõ¥È´òÁöÑÂàÜÁ±ªÂáÜÁ°ÆÁéáÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÂåªÁñóÁõëÊµã„ÄÅËÑëÊú∫Êé•Âè£ÂíåÁ•ûÁªèÁßëÂ≠¶Á†îÁ©∂Á≠â„ÄÇEEGDMËÉΩÂ§üÊúâÊïàÊèêÈ´òÁô´Áó´Á≠âÁ•ûÁªèÁ≥ªÁªüÁñæÁóÖÁöÑÊ£ÄÊµãÂáÜÁ°ÆÊÄßÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±ÂìçÔºåËÉΩÂ§üÊé®Âä®Áõ∏ÂÖ≥È¢ÜÂüüÁöÑÊäÄÊúØËøõÊ≠•ÂíåÂ∫îÁî®ÊôÆÂèä„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> While electroencephalogram (EEG) has been a crucial tool for monitoring the brain and diagnosing neurological disorders (e.g., epilepsy), learning meaningful representations from raw EEG signals remains challenging due to limited annotations and high signal variability. Recently, EEG foundation models (FMs) have shown promising potential by adopting transformer architectures and self-supervised pre-training methods from large language models (e.g., masked prediction) to learn representations from diverse EEG data, followed by fine-tuning on specific EEG tasks. Nonetheless, these large models often incurred high computational costs during both training and inference, with only marginal performance improvements as the model size increases. In this work, we proposed an EEG representation learning framework building upon Generative Diffusion Model (EEGDM). Specifically, we developed a structured state-space model for diffusion pretraining (SSMDP) to better capture the temporal dynamics of EEG signals and trained it using Denoising Diffusion Probabilistic Model (DDPM) framework. Subsequently, the resulting latent EEG representations were then used for downstream classification tasks via our proposed latent fusion transformer (LFT). To evaluate our method, we used multi-event datasets covering both interictal epileptiform discharges (TUEV) and seizure (CHB-MIT) detection, and compared EEGDM with current state-of-the-art approaches, including EEG FMs. Empirical results showed that our method outperformed the existing methods. These findings suggested that EEGDM offered a promising alternative to current FMs. Our source code and checkpoint are available at: https://github.com/jhpuah/EEGDM.

