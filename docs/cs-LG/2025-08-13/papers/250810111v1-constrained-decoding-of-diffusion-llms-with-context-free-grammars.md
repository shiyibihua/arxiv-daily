---
layout: default
title: Constrained Decoding of Diffusion LLMs with Context-Free Grammars
---

# Constrained Decoding of Diffusion LLMs with Context-Free Grammars

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10111" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10111v1</a>
  <a href="https://arxiv.org/pdf/2508.10111.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10111v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10111v1', 'Constrained Decoding of Diffusion LLMs with Context-Free Grammars')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Niels MÃ¼ndler, Jasper Dekoninck, Martin Vechev

**åˆ†ç±»**: cs.LG, cs.FL, cs.PL, cs.SE

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ‰©æ•£æ¨¡å‹çš„çº¦æŸè§£ç æ–¹æ³•ä»¥è§£å†³è¯­æ³•çº¦æŸé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡å‹` `çº¦æŸè§£ç ` `ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•` `ä»£ç è¡¥å…¨` `ç»“æ„åŒ–æ•°æ®æå–` `ç®—æ³•ä¼˜åŒ–` `åŠŸèƒ½æ­£ç¡®æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„çº¦æŸè§£ç æ–¹æ³•æ— æ³•æœ‰æ•ˆåº”ç”¨äºæ‰©æ•£LLMsï¼Œå¯¼è‡´ç”Ÿæˆçš„è¾“å‡ºä¸ç¬¦åˆæ­£å¼è¯­è¨€çš„è¯­æ³•çº¦æŸã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„çº¦æŸè§£ç æ–¹æ³•ï¼Œé€šè¿‡å°†å…¶ç®€åŒ–ä¸ºåŠ æ³•å¡«å……é—®é¢˜ï¼Œè§£å†³äº†æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆæ­£å¼è¯­è¨€æ—¶çš„æŒ‘æˆ˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨C++ä»£ç å¡«å……å’ŒJSONæ•°æ®æå–ä»»åŠ¡ä¸­å®ç°äº†æ¥è¿‘å®Œç¾çš„è¯­æ³•æ­£ç¡®æ€§ï¼Œå¹¶ä¸”åŠŸèƒ½æ­£ç¡®æ€§å¾—åˆ°äº†ä¿æŒæˆ–æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ä»£ç è¡¥å…¨å’Œç»“æ„åŒ–æ•°æ®æå–ç­‰å®é™…åº”ç”¨ä¸­ï¼Œè¾“å‡ºéœ€éµå¾ªç‰¹å®šçš„è¯­æ³•çº¦æŸã€‚ç°æœ‰çš„çº¦æŸè§£ç æ–¹æ³•æ— æ³•é€‚ç”¨äºæ‰©æ•£LLMsã€‚æœ¬æ–‡æå‡ºäº†é¦–ä¸ªé’ˆå¯¹æ‰©æ•£æ¨¡å‹çš„çº¦æŸè§£ç æ–¹æ³•ï¼Œèƒ½å¤Ÿå¤„ç†ç”±ä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•æè¿°çš„æ­£å¼è¯­è¨€ã€‚æˆ‘ä»¬å°†çº¦æŸè§£ç é—®é¢˜ç®€åŒ–ä¸ºåŠ æ³•å¡«å……é—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§é«˜æ•ˆç®—æ³•æ¥è§£å†³ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€çš„äº¤é›†é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨C++ä»£ç å¡«å……å’ŒJSONæ•°æ®æå–ä¸­å®ç°äº†è¿‘ä¹å®Œç¾çš„è¯­æ³•æ­£ç¡®æ€§ï¼ŒåŒæ—¶ä¿æŒæˆ–æé«˜äº†åŠŸèƒ½æ­£ç¡®æ€§ï¼Œä¸”è®¡ç®—å¼€é”€ä¿æŒåœ¨å¯æ¥å—èŒƒå›´å†…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•åœ¨æ‰©æ•£LLMsä¸­å®ç°çº¦æŸè§£ç ï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„è¾“å‡ºç¬¦åˆä¸Šä¸‹æ–‡æ— å…³æ–‡æ³•çš„è¯­æ³•çº¦æŸã€‚ç°æœ‰æ–¹æ³•æ— æ³•å¤„ç†è¿™ä¸€æŒ‘æˆ˜ï¼Œå¯¼è‡´ç”Ÿæˆç»“æœçš„è¯­æ³•æ­£ç¡®æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†çº¦æŸè§£ç é—®é¢˜è½¬åŒ–ä¸ºåŠ æ³•å¡«å……é—®é¢˜ï¼Œåˆ¤æ–­éƒ¨åˆ†è¾“å‡ºæ˜¯å¦å¯ä»¥è¡¥å…¨ä¸ºç›®æ ‡è¯­è¨€ä¸­çš„æœ‰æ•ˆå•è¯ã€‚è¿™ç§æ–¹æ³•ä¸ä»…æ¶µç›–äº†ä¼ ç»Ÿçš„çº¦æŸè§£ç ï¼Œè¿˜è‡ªç„¶åœ°æ‰©å±•åˆ°å¤šåŒºåŸŸå¡«å……é—®é¢˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯è¾“å…¥éƒ¨åˆ†ï¼Œæ¥æ”¶éƒ¨åˆ†ç”Ÿæˆçš„è¾“å‡ºï¼›å…¶æ¬¡æ˜¯åŠ æ³•å¡«å……æ¨¡å—ï¼Œåˆ¤æ–­è¾“å‡ºæ˜¯å¦å¯ä»¥è¡¥å…¨ï¼›æœ€åæ˜¯è¾“å‡ºæ¨¡å—ï¼Œç”Ÿæˆç¬¦åˆè¯­æ³•çš„æœ€ç»ˆç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é«˜æ•ˆçš„ç®—æ³•æ¥è§£å†³ä¸Šä¸‹æ–‡æ— å…³è¯­è¨€ä¸æ­£åˆ™è¯­è¨€äº¤é›†æ˜¯å¦ä¸ºç©ºçš„é—®é¢˜ã€‚è¿™ä¸€æ–¹æ³•ä¸ç°æœ‰çš„çº¦æŸè§£ç æŠ€æœ¯æœ¬è´¨ä¸Šä¸åŒï¼Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„è¯­æ³•çº¦æŸã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç®—æ³•è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å¡«å……ç­–ç•¥å’Œè¯­è¨€æ¨¡å‹çš„é€‰æ‹©ï¼ŒæŸå¤±å‡½æ•°åˆ™ä¾§é‡äºè¯­æ³•æ­£ç¡®æ€§ä¸åŠŸèƒ½æ­£ç¡®æ€§çš„å¹³è¡¡ã€‚ç½‘ç»œç»“æ„é‡‡ç”¨äº†é€‚åº”æ‰©æ•£æ¨¡å‹çš„ç‰¹å®šè®¾è®¡ï¼Œä»¥æé«˜è§£ç æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨C++ä»£ç å¡«å……ä»»åŠ¡ä¸­å®ç°äº†è¶…è¿‡95%çš„è¯­æ³•æ­£ç¡®æ€§ï¼Œå¹¶åœ¨JSONæ•°æ®æå–ä¸­ä¿æŒäº†åŠŸèƒ½æ­£ç¡®æ€§ï¼Œè¾ƒåŸºçº¿æ–¹æ³•æå‡äº†çº¦10%ã€‚æ­¤å¤–ï¼Œç®—æ³•çš„è®¡ç®—æ•ˆç‡ä¼˜åŒ–ç¡®ä¿äº†åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¼–ç¨‹è¯­è¨€çš„è‡ªåŠ¨è¡¥å…¨ã€ç»“æ„åŒ–æ•°æ®çš„æå–ä»¥åŠä»»ä½•éœ€è¦éµå¾ªç‰¹å®šè¯­æ³•è§„åˆ™çš„æ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚å…¶å®é™…ä»·å€¼åœ¨äºèƒ½å¤Ÿæé«˜ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œæœªæ¥å¯èƒ½å¯¹è½¯ä»¶å¼€å‘ã€æ•°æ®å¤„ç†ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have shown promising performance across diverse domains. Many practical applications of LLMs, such as code completion and structured data extraction, require adherence to syntactic constraints specified by a formal language. Yet, due to their probabilistic nature, LLM output is not guaranteed to adhere to such formal languages. Prior work has proposed constrained decoding as a means to restrict LLM generation to particular formal languages. However, existing works are not applicable to the emerging paradigm of diffusion LLMs, when used in practical scenarios such as the generation of formally correct C++ or JSON output. In this paper we address this challenge and present the first constrained decoding method for diffusion models, one that can handle formal languages captured by context-free grammars. We begin by reducing constrained decoding to the more general additive infilling problem, which asks whether a partial output can be completed to a valid word in the target language. This problem also naturally subsumes the previously unaddressed multi-region infilling constrained decoding. We then reduce this problem to the task of deciding whether the intersection of the target language and a regular language is empty and present an efficient algorithm to solve it for context-free languages. Empirical results on various applications, such as C++ code infilling and structured data extraction in JSON, demonstrate that our method achieves near-perfect syntactic correctness while consistently preserving or improving functional correctness. Importantly, our efficiency optimizations ensure that the computational overhead remains practical.

