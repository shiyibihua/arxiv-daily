---
layout: default
title: Apriel-Nemotron-15B-Thinker
---

# Apriel-Nemotron-15B-Thinker

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10948" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10948v1</a>
  <a href="https://arxiv.org/pdf/2508.10948.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10948v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10948v1', 'Apriel-Nemotron-15B-Thinker')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shruthan Radhakrishna, Soham Parikh, Gopal Sarda, Anil Turkkan, Quaizar Vohra, Raymond Li, Dhruv Jhamb, Kelechi Ogueji, Aanjaneya Shukla, Oluwanifemi Bamgbose, Toby Liang, Luke Kumar, Oleksiy Ostapenko, Shiva Krishna Reddy Malay, Aman Tiwari, Tara Bogavelli, Vikas Yadav, Jash Mehta, Saloni Mittal, Akshay Kalkunte, Pulkit Pattnaik, Khalil Slimi, Anirudh Sreeram, Jishnu Nair, Akintunde Oladipo, Shashank Maiya, Khyati Mahajan, Rishabh Maheshwary, Masoud Hashemi, Sai Rajeswar Mudumba, Sathwik Tejaswi Madhusudhan, Torsten Scholak, Sebastien Paquet, Sagar Davasam, Srinivas Sunkara

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºApriel-Nemotron-15B-Thinkerä»¥é™ä½å¤§è¯­è¨€æ¨¡å‹çš„å†…å­˜æ¶ˆè€—**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å†…å­˜ä¼˜åŒ–` `å¼ºåŒ–å­¦ä¹ ` `ç›‘ç£å¾®è°ƒ` `ä¼ä¸šåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å†…å­˜å’Œè®¡ç®—æˆæœ¬ä¸Šå­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å…¶åœ¨ä¼ä¸šä¸­çš„åº”ç”¨ã€‚
2. æå‡ºçš„Apriel-Nemotron-15B-Thinkeræ¨¡å‹é€šè¿‡å››é˜¶æ®µè®­ç»ƒæµç¨‹ï¼Œæ˜¾è‘—é™ä½å†…å­˜å ç”¨ï¼ŒåŒæ—¶ä¿æŒé«˜æ€§èƒ½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å‚æ•°æ›´å¤šçš„ç«äº‰å¯¹æ‰‹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä»£ç ã€æ•°å­¦åŠå…¶ä»–ä¼ä¸šä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶æ˜¾è‘—çš„å†…å­˜å’Œè®¡ç®—æˆæœ¬å¸¸å¸¸é™åˆ¶äº†å…¶åœ¨å®é™…ä¼ä¸šç¯å¢ƒä¸­çš„åº”ç”¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†Apriel-Nemotron-15B-Thinkerï¼Œè¿™æ˜¯ServiceNow Apriel SLMç³»åˆ—ä¸­çš„ä¸€ä¸ª150äº¿å‚æ•°æ¨¡å‹ï¼Œå®ƒåœ¨æ€§èƒ½ä¸Šä¸ä¸­å‹æœ€å…ˆè¿›æ¨¡å‹ï¼ˆå¦‚o1-miniã€QWQ32Bå’ŒEXAONE-Deep-32Bï¼‰ç›¸å½“ï¼ŒåŒæ—¶å†…å­˜å ç”¨ä»…ä¸ºè¿™äº›æ›¿ä»£æ–¹æ¡ˆçš„ä¸€åŠã€‚Apriel-Nemotron-15B-Thinkeræ¨¡å‹ç»è¿‡å››ä¸ªé˜¶æ®µçš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬åŸºç¡€æ¨¡å‹æ”¾å¤§ã€æŒç»­é¢„è®­ç»ƒã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œä½¿ç”¨GRPOçš„å¼ºåŒ–å­¦ä¹ ã€‚å…¨é¢è¯„ä¼°æ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹å‚æ•°å°‘äº32äº¿çš„å¯¹æ‰‹ï¼ŒApriel-Nemotron-15B-Thinkerçš„æ€§èƒ½ä»ç„¶åŒ¹é…æˆ–è¶…è¶Šäº†å®ƒä»¬ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„é«˜å†…å­˜å’Œè®¡ç®—æˆæœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚o1-miniã€QWQ32Bå’ŒEXAONE-Deep-32Bè™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†å†…å­˜å ç”¨è¿‡é«˜ï¼Œé™åˆ¶äº†å…¶å¹¿æ³›åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šApriel-Nemotron-15B-Thinkeré€šè¿‡ä¼˜åŒ–æ¨¡å‹æ¶æ„å’Œè®­ç»ƒæµç¨‹ï¼Œé™ä½å†…å­˜å ç”¨ï¼ŒåŒæ—¶ä¿æŒä¸æ›´å¤§æ¨¡å‹ç›¸å½“çš„æ¨ç†èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®ç°é«˜æ•ˆçš„è®¡ç®—èµ„æºåˆ©ç”¨ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹çš„è®­ç»ƒæµç¨‹åˆ†ä¸ºå››ä¸ªé˜¶æ®µï¼š1) åŸºç¡€æ¨¡å‹æ”¾å¤§ï¼Œ2) æŒç»­é¢„è®­ç»ƒï¼Œ3) ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œ4) ä½¿ç”¨GRPOè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚æ¯ä¸ªé˜¶æ®µéƒ½æ—¨åœ¨é€æ­¥æå‡æ¨¡å‹çš„æ€§èƒ½å’Œé€‚åº”æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ¨¡å‹çš„å‚æ•°ä¼˜åŒ–å’Œè®­ç»ƒç­–ç•¥ï¼Œä½¿å¾—åœ¨ä»…150äº¿å‚æ•°çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½èƒ½å¤Ÿä¸32äº¿å‚æ•°çš„æ¨¡å‹ç›¸åª²ç¾ã€‚è¿™ä¸€è®¾è®¡æ˜¾è‘—é™ä½äº†å†…å­˜éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„è®¾è®¡ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›å’Œæ¨ç†å‡†ç¡®æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè®­ç»ƒç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒApriel-Nemotron-15B-Thinkeråœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ€§èƒ½ä¸32äº¿å‚æ•°çš„æ¨¡å‹ç›¸å½“ï¼Œä¸”å†…å­˜å ç”¨ä»…ä¸ºå…¶ä¸€åŠã€‚è¿™ä¸€æˆæœè¡¨æ˜ï¼Œæ¨¡å‹åœ¨ä¿æŒé«˜æ•ˆæ€§èƒ½çš„åŒæ—¶ï¼ŒæˆåŠŸå®ç°äº†èµ„æºçš„ä¼˜åŒ–åˆ©ç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Apriel-Nemotron-15B-Thinkeræ¨¡å‹å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆæ¨ç†å’Œä½å†…å­˜å ç”¨çš„ä¼ä¸šç¯å¢ƒä¸­ã€‚å®ƒå¯ä»¥è¢«åº”ç”¨äºè‡ªåŠ¨åŒ–å®¢æœã€æ™ºèƒ½æ–‡æ¡£å¤„ç†å’Œæ•°æ®åˆ†æç­‰é¢†åŸŸï¼Œå¸®åŠ©ä¼ä¸šæå‡æ•ˆç‡å¹¶é™ä½æˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ¨¡å‹çš„è®¾è®¡ç†å¿µå¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šé«˜æ•ˆæ¨¡å‹çš„ç ”ç©¶ä¸å¼€å‘ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While large language models (LLMs) have achieved remarkable reasoning capabilities across domains like code, math and other enterprise tasks, their significant memory and computational costs often preclude their use in practical enterprise settings. To this end, we introduce Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow Apriel SLM series that achieves performance against medium sized state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while maintaining only half the memory footprint of those alternatives. Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive evaluations across a diverse suite of benchmarks consistently demonstrate that our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its 32-billion parameter counterparts, despite being less than half their size.

