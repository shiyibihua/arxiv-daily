---
layout: default
title: SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification
---

# SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09544" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09544v1</a>
  <a href="https://arxiv.org/pdf/2508.09544.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09544v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09544v1', 'SYNAPSE-G: Bridging Large Language Models and Graph Learning for Rare Event Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sasan Tavakkol, Lin Chen, Max Springer, Abigail Schantz, BlaÅ¾ BrataniÄ, Vincent Cohen-Addad, MohammadHossein Bateni

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSYNAPSE-Gä»¥è§£å†³ç¨€æœ‰äº‹ä»¶åˆ†ç±»ä¸­çš„æ•°æ®ç¨€ç¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€æœ‰äº‹ä»¶åˆ†ç±»` `åˆæˆæ•°æ®` `å¤§å‹è¯­è¨€æ¨¡å‹` `åŠç›‘ç£å­¦ä¹ ` `å›¾å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¨€æœ‰äº‹ä»¶åˆ†ç±»é¢ä¸´æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè®­ç»ƒæ¨¡å‹ã€‚
2. SYNAPSE-Gé€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆæˆæ•°æ®ï¼Œç»“åˆåŠç›‘ç£å­¦ä¹ æ¥è§£å†³å†·å¯åŠ¨é—®é¢˜ã€‚
3. åœ¨ä¸å¹³è¡¡çš„SST2å’ŒMHSæ•°æ®é›†ä¸Šï¼ŒSYNAPSE-Gåœ¨æ‰¾åˆ°æ­£æ ‡ç­¾æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†å¤šä¸ªåŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨€æœ‰äº‹ä»¶çš„æ ‡æ³¨æ•°æ®ç¨€ç¼ºä¸¥é‡é˜»ç¢äº†æœ‰æ•ˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€‚æœ¬æ–‡æå‡ºäº†SYNAPSE-Gï¼ˆé€šè¿‡å›¾æ‰©å±•è¿›è¡Œæ­£æ ·æœ¬åˆæˆå¢å¼ºï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„ç®¡é“ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆç¨€æœ‰äº‹ä»¶åˆ†ç±»çš„åˆæˆè®­ç»ƒæ•°æ®ï¼Œä»è€Œè§£å†³å†·å¯åŠ¨é—®é¢˜ã€‚è¿™äº›åˆæˆæ•°æ®ä½œä¸ºç§å­ï¼Œè¿›è¡ŒåŠç›‘ç£æ ‡ç­¾ä¼ æ’­ï¼Œæ„å»ºç›¸ä¼¼æ€§å›¾ï¼Œè¯†åˆ«å€™é€‰æ­£ä¾‹ï¼Œéšåç”±äººç±»æˆ–LLMè¿›è¡Œæ ‡æ³¨ã€‚æ‰©å±•åçš„æ•°æ®é›†ç”¨äºè®­ç»ƒæˆ–å¾®è°ƒåˆ†ç±»å™¨ã€‚æˆ‘ä»¬ç†è®ºåˆ†æäº†åˆæˆæ•°æ®çš„è´¨é‡ï¼ˆæœ‰æ•ˆæ€§å’Œå¤šæ ·æ€§ï¼‰å¦‚ä½•å½±å“æ–¹æ³•çš„ç²¾åº¦å’Œå¬å›ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSYNAPSE-Gåœ¨å¯»æ‰¾æ­£æ ‡ç­¾æ–¹é¢çš„æœ‰æ•ˆæ€§è¶…è¿‡äº†åŒ…æ‹¬æœ€è¿‘é‚»æœç´¢åœ¨å†…çš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¨€æœ‰äº‹ä»¶åˆ†ç±»ä¸­æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å†·å¯åŠ¨é—®é¢˜æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„æ ‡æ³¨æ•°æ®ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSYNAPSE-Gçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆåˆæˆè®­ç»ƒæ•°æ®ï¼Œä½œä¸ºæ­£æ ·æœ¬çš„ç§å­ï¼Œé€šè¿‡åŠç›‘ç£å­¦ä¹ æ–¹æ³•æ‰©å±•æ•°æ®é›†ï¼Œä»è€Œæé«˜åˆ†ç±»å™¨çš„æ€§èƒ½ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å…‹æœæ•°æ®ç¨€ç¼ºå¸¦æ¥çš„æŒ‘æˆ˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œåˆ©ç”¨LLMç”Ÿæˆåˆæˆæ•°æ®ï¼›å…¶æ¬¡ï¼Œæ„å»ºç›¸ä¼¼æ€§å›¾å¹¶è¿›è¡ŒåŠç›‘ç£æ ‡ç­¾ä¼ æ’­ï¼›æœ€åï¼Œä½¿ç”¨æ‰©å±•åçš„æ•°æ®é›†è®­ç»ƒæˆ–å¾®è°ƒåˆ†ç±»å™¨ã€‚

**å…³é”®åˆ›æ–°**ï¼šSYNAPSE-Gçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸å›¾å­¦ä¹ ç›¸ç»“åˆï¼Œç”Ÿæˆåˆæˆæ•°æ®å¹¶é€šè¿‡æ ‡ç­¾ä¼ æ’­è¯†åˆ«æ­£æ ·æœ¬ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ä»…ä¾èµ–æ ‡æ³¨æ•°æ®çš„æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒSYNAPSE-Gå…³æ³¨åˆæˆæ•°æ®çš„æœ‰æ•ˆæ€§å’Œå¤šæ ·æ€§ï¼Œè®¾è®¡äº†ç›¸åº”çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ ‡ç­¾ä¼ æ’­è¿‡ç¨‹ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šé‡‡ç”¨äº†é€‚åˆå›¾å­¦ä¹ çš„æ¨¡å‹ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œæ¶æ„åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ä¸å¹³è¡¡çš„SST2å’ŒMHSæ•°æ®é›†ä¸Šï¼ŒSYNAPSE-Gåœ¨æ‰¾åˆ°æ­£æ ‡ç­¾çš„èƒ½åŠ›ä¸Šæ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼ŒåŒ…æ‹¬æœ€è¿‘é‚»æœç´¢ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°XX%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—è¯Šæ–­ã€é‡‘èæ¬ºè¯ˆæ£€æµ‹å’Œè‡ªç„¶ç¾å®³é¢„æµ‹ç­‰ç¨€æœ‰äº‹ä»¶åˆ†ç±»ä»»åŠ¡ã€‚é€šè¿‡ç”Ÿæˆåˆæˆæ•°æ®ï¼ŒSYNAPSE-Gèƒ½å¤Ÿæœ‰æ•ˆæå‡æ¨¡å‹åœ¨æ•°æ®ç¨€ç¼ºæƒ…å†µä¸‹çš„æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Scarcity of labeled data, especially for rare events, hinders training effective machine learning models. This paper proposes SYNAPSE-G (Synthetic Augmentation for Positive Sampling via Expansion on Graphs), a novel pipeline leveraging Large Language Models (LLMs) to generate synthetic training data for rare event classification, addressing the cold-start problem. This synthetic data serve as seeds for semi-supervised label propagation on a similarity graph constructed between the seeds and a large unlabeled dataset. This identifies candidate positive examples, subsequently labeled by an oracle (human or LLM). The expanded dataset then trains/fine-tunes a classifier. We theoretically analyze how the quality (validity and diversity) of the synthetic data impacts the precision and recall of our method. Experiments on the imbalanced SST2 and MHS datasets demonstrate SYNAPSE-G's effectiveness in finding positive labels, outperforming baselines including nearest neighbor search.

