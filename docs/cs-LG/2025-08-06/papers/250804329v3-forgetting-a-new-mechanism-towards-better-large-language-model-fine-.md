---
layout: default
title: Forgetting: A New Mechanism Towards Better Large Language Model Fine-tuning
---

# Forgetting: A New Mechanism Towards Better Large Language Model Fine-tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04329" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04329v3</a>
  <a href="https://arxiv.org/pdf/2508.04329.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04329v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04329v3', 'Forgetting: A New Mechanism Towards Better Large Language Model Fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ali Taheri Ghahrizjani, Alireza Taban, Shanshan Ye, Abdolreza Mirzaei, Tongliang Liu, Bo Han

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-08-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé—å¿˜æœºåˆ¶ä»¥æ”¹å–„å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒæ•ˆæœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç›‘ç£å¾®è°ƒ` `é—å¿˜æœºåˆ¶` `æ¨¡å‹è®­ç»ƒ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç›‘ç£å¾®è°ƒæ–¹æ³•å¯¹æ•°æ®è´¨é‡å’Œæ•°é‡é«˜åº¦ä¾èµ–ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½æå‡æœ‰é™æˆ–ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºå°†è¯­æ–™ä¸­çš„æ ‡è®°åˆ†ä¸ºæ­£å‘å’Œè´Ÿå‘æ ‡è®°ï¼Œæ­£å‘æ ‡è®°ç”¨äºè®­ç»ƒï¼Œè´Ÿå‘æ ‡è®°åˆ™éœ€é—å¿˜ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥é—å¿˜æœºåˆ¶æ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œå¹¶å¢åŠ äº†æ¨¡å‹å“åº”çš„å¤šæ ·æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰åœ¨é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ‰®æ¼”ç€å…³é”®è§’è‰²ï¼Œæ˜¾è‘—æå‡å…¶è·å–é¢†åŸŸç‰¹å®šçŸ¥è¯†çš„èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒæˆ–å¢å¼ºå…¶é€šç”¨èƒ½åŠ›ã€‚ç„¶è€Œï¼ŒSFTçš„æœ‰æ•ˆæ€§ä¾èµ–äºæ•°æ®è´¨é‡å’Œæ•°é‡ï¼Œè‹¥ä¸æ»¡è¶³è¦æ±‚ï¼Œå¯èƒ½å¯¼è‡´æ€§èƒ½æå‡æœ‰é™ç”šè‡³ä¸‹é™ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºå°†è¯­æ–™ä¸­çš„æ ‡è®°åˆ†ä¸ºæ­£å‘å’Œè´Ÿå‘æ ‡è®°ï¼Œæ­£å‘æ ‡è®°ç”¨äºæ¨¡å‹è®­ç»ƒï¼Œè€Œè´Ÿå‘æ ‡è®°åˆ™åº”è¢«æ˜¾å¼é—å¿˜ã€‚è¿™æ ·çš„æ ‡è®°åˆ†ç±»æœ‰åŠ©äºæ¨¡å‹å­¦ä¹ æ›´å°‘çš„ä¿¡æ¯ï¼Œå¹¶é€šè¿‡é—å¿˜è¿‡ç¨‹å½¢æˆçŸ¥è¯†è¾¹ç•Œï¼ŒæŒ‡å¯¼æ¨¡å‹æ›´ç²¾ç¡®åœ°å­¦ä¹ ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥é—å¿˜æœºåˆ¶ä¸ä»…æå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ï¼Œè¿˜ä¿ƒè¿›äº†æ¨¡å‹å“åº”çš„å¤šæ ·æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹åœ¨ç›‘ç£å¾®è°ƒè¿‡ç¨‹ä¸­å¯¹æ•°æ®è´¨é‡å’Œæ•°é‡çš„é«˜åº¦ä¾èµ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ•°æ®ä¸è¶³æ—¶å¯èƒ½å¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå°†è¯­æ–™ä¸­çš„æ ‡è®°åˆ†ä¸ºæ­£å‘å’Œè´Ÿå‘æ ‡è®°ï¼Œæ­£å‘æ ‡è®°ç”¨äºæ¨¡å‹è®­ç»ƒï¼Œè€Œè´Ÿå‘æ ‡è®°åˆ™éœ€è¢«é—å¿˜ï¼Œä»¥å‡å°‘æ— æ•ˆä¿¡æ¯å¯¹æ¨¡å‹çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ ‡è®°åˆ†ç±»ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°ã€‚é¦–å…ˆå¯¹è¯­æ–™è¿›è¡Œæ ‡è®°åˆ†ç±»ï¼Œç„¶åä½¿ç”¨æ­£å‘æ ‡è®°è¿›è¡Œè®­ç»ƒï¼Œè´Ÿå‘æ ‡è®°åˆ™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¢«é—å¿˜ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†æ ‡è®°é—å¿˜æœºåˆ¶ï¼Œé€šè¿‡æ˜ç¡®åŒºåˆ†æœ‰ç”¨å’Œæ— ç”¨çš„ä¿¡æ¯ï¼Œå¸®åŠ©æ¨¡å‹æ›´æœ‰æ•ˆåœ°å­¦ä¹ ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å‡å°‘äº†å¯¹ä½è´¨é‡æ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¼ºåŒ–æ­£å‘æ ‡è®°çš„å­¦ä¹ ï¼ŒåŒæ—¶è®¾è®¡æœºåˆ¶ç¡®ä¿è´Ÿå‘æ ‡è®°è¢«æœ‰æ•ˆé—å¿˜ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨é—å¿˜æœºåˆ¶åï¼Œæ¨¡å‹åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸Šçš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®å¾…è¡¥å……ï¼‰ï¼ŒåŒæ—¶æ¨¡å‹å“åº”çš„å¤šæ ·æ€§ä¹Ÿå¾—åˆ°äº†å¢å¼ºï¼Œæ˜¾ç¤ºå‡ºæ›´å¥½çš„é€‚åº”æ€§å’Œçµæ´»æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨ç‰¹å®šé¢†åŸŸä¸­æå‡æ¨¡å‹çš„è¡¨ç°ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½åŠ©æ‰‹ã€å®¢æœæœºå™¨äººç­‰åº”ç”¨çš„å®é™…ä»·å€¼å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½å½±å“æ›´å¤šé¢†åŸŸçš„æ¨¡å‹è®­ç»ƒç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Supervised fine-tuning (SFT) plays a critical role for pretrained large language models (LLMs), notably enhancing their capacity to acquire domain-specific knowledge while preserving or potentially augmenting their general-purpose capabilities. However, the efficacy of SFT hinges on data quality as well as data volume, otherwise it may result in limited performance gains or even degradation relative to the associated baselines. To mitigate such reliance, we suggest categorizing tokens within each corpus into two parts -- positive and negative tokens -- based on whether they are useful to improve model performance. Positive tokens can be trained in common ways, whereas negative tokens, which may lack essential semantics or be misleading, should be explicitly forgotten. Overall, the token categorization facilitate the model to learn less informative message, and the forgetting process shapes a knowledge boundary to guide the model on what information to learn more precisely. We conduct experiments on well-established benchmarks, finding that this forgetting mechanism not only improves overall model performance and also facilitate more diverse model responses.

