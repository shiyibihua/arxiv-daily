---
layout: default
title: Evaluating Selective Encryption Against Gradient Inversion Attacks
---

# Evaluating Selective Encryption Against Gradient Inversion Attacks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04155" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04155v1</a>
  <a href="https://arxiv.org/pdf/2508.04155.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04155v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04155v1', 'Evaluating Selective Encryption Against Gradient Inversion Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiajun Gu, Yuhang Yao, Shuaiqi Wang, Carlee Joe-Wong

**åˆ†ç±»**: cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€‰æ‹©æ€§åŠ å¯†ä»¥åº”å¯¹æ¢¯åº¦åæ¼”æ”»å‡»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `æ¢¯åº¦åæ¼”æ”»å‡»` `é€‰æ‹©æ€§åŠ å¯†` `éšç§ä¿æŠ¤` `è”é‚¦å­¦ä¹ ` `æ¨¡å‹æ¶æ„` `æ”»å‡»è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ¢¯åº¦åæ¼”æ”»å‡»å¯¹è”é‚¦å­¦ä¹ ç­‰åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶çš„éšç§æ„æˆå¨èƒï¼Œç°æœ‰åŠ å¯†æ–¹æ³•è®¡ç®—å¼€é”€é«˜ã€‚
2. æå‡ºé€‰æ‹©æ€§åŠ å¯†æ–¹æ³•ï¼Œä»…å¯¹é‡è¦æ¢¯åº¦æ•°æ®è¿›è¡ŒåŠ å¯†ï¼Œæ—¨åœ¨é™ä½è®¡ç®—è´Ÿæ‹…å¹¶ä¿æŒéšç§ä¿æŠ¤ã€‚
3. é€šè¿‡å¯¹ä¸åŒæ¨¡å‹æ¶æ„å’Œæ”»å‡»ç±»å‹çš„å®éªŒï¼Œå‘ç°æ¢¯åº¦å¹…åº¦æ˜¯æœ‰æ•ˆçš„ä¿æŠ¤æŒ‡æ ‡ï¼Œä½†æ²¡æœ‰å•ä¸€ç­–ç•¥é€‚ç”¨äºæ‰€æœ‰åœºæ™¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¢¯åº¦åæ¼”æ”»å‡»å¯¹åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶ï¼ˆå¦‚è”é‚¦å­¦ä¹ ï¼‰æ„æˆäº†é‡å¤§éšç§å¨èƒï¼Œä½¿æ¶æ„æ–¹èƒ½å¤Ÿä»å®¢æˆ·ç«¯ä¸èšåˆæœåŠ¡å™¨ä¹‹é—´çš„æ¢¯åº¦é€šä¿¡ä¸­é‡å»ºæ•æ„Ÿçš„æœ¬åœ°è®­ç»ƒæ•°æ®ã€‚å°½ç®¡ä¼ ç»Ÿçš„åŸºäºåŠ å¯†çš„é˜²å¾¡æ–¹æ³•ï¼ˆå¦‚åŒæ€åŠ å¯†ï¼‰åœ¨ä¸æŸå®³æ¨¡å‹æ•ˆç”¨çš„æƒ…å†µä¸‹æä¾›äº†å¼ºå¤§çš„éšç§ä¿éšœï¼Œä½†é€šå¸¸ä¼šå¸¦æ¥é«˜æ˜‚çš„è®¡ç®—å¼€é”€ã€‚ä¸ºæ­¤ï¼Œé€‰æ‹©æ€§åŠ å¯†ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•åº”è¿è€Œç”Ÿï¼Œä»…å¯¹åŸºäºç‰¹å®šæŒ‡æ ‡çš„é‡è¦æ€§é€‰æ‹©æ¢¯åº¦æ•°æ®è¿›è¡ŒåŠ å¯†ã€‚æœ¬æ–‡ç³»ç»Ÿè¯„ä¼°äº†ä¸åŒé‡è¦æ€§æŒ‡æ ‡ä¸‹çš„é€‰æ‹©æ€§åŠ å¯†æ–¹æ³•å¯¹å…ˆè¿›æ”»å‡»çš„æœ‰æ•ˆæ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè·ç¦»çš„é‡è¦æ€§åˆ†ææ¡†æ¶ï¼Œä¸ºé€‰æ‹©å…³é”®æ¢¯åº¦å…ƒç´ è¿›è¡ŒåŠ å¯†æä¾›ç†è®ºåŸºç¡€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€‰æ‹©æ€§åŠ å¯†åœ¨é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶ï¼Œä»èƒ½ä¿æŒå¯¹æ”»å‡»çš„æŠµæŠ—åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³æ¢¯åº¦åæ¼”æ”»å‡»å¯¹è”é‚¦å­¦ä¹ éšç§çš„å¨èƒï¼Œç°æœ‰æ–¹æ³•å¦‚åŒæ€åŠ å¯†è®¡ç®—å¼€é”€é«˜ï¼Œéš¾ä»¥å¹¿æ³›åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºé€‰æ‹©æ€§åŠ å¯†æ–¹æ³•ï¼Œä¾æ®æ¢¯åº¦æ•°æ®çš„é‡è¦æ€§é€‰æ‹©æ€§åŠ å¯†ï¼Œæ—¨åœ¨åœ¨é™ä½è®¡ç®—è´Ÿæ‹…çš„åŒæ—¶ä¿æŒéšç§ä¿æŠ¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬é‡è¦æ€§åˆ†æã€é€‰æ‹©æ€§åŠ å¯†å’Œæ”»å‡»è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆé€šè¿‡è·ç¦»åˆ†æç¡®å®šé‡è¦æ¢¯åº¦å…ƒç´ ï¼Œç„¶åå¯¹è¿™äº›å…ƒç´ è¿›è¡ŒåŠ å¯†ï¼Œæœ€åè¯„ä¼°å…¶å¯¹ä¸åŒæ”»å‡»çš„é˜²æŠ¤æ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºåŸºäºè·ç¦»çš„é‡è¦æ€§åˆ†ææ¡†æ¶ï¼Œä¸ºé€‰æ‹©æ€§åŠ å¯†æä¾›ç†è®ºåŸºç¡€ï¼Œè¯†åˆ«å‡ºæ¢¯åº¦å¹…åº¦ä½œä¸ºæœ‰æ•ˆçš„ä¿æŠ¤æŒ‡æ ‡ï¼ŒåŒºåˆ«äºä¼ ç»Ÿçš„å…¨é‡åŠ å¯†æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ä½¿ç”¨äº†å¤šç§æ¨¡å‹æ¶æ„ï¼ˆå¦‚LeNetã€CNNã€BERTã€GPT-2ï¼‰ï¼Œå¹¶å¯¹ä¸åŒæ”»å‡»ç±»å‹è¿›è¡Œäº†è¯„ä¼°ï¼Œå‘ç°æ²¡æœ‰å•ä¸€çš„é€‰æ‹©æ€§åŠ å¯†ç­–ç•¥é€‚ç”¨äºæ‰€æœ‰åœºæ™¯ï¼Œæä¾›äº†é’ˆå¯¹ä¸åŒéœ€æ±‚çš„ç­–ç•¥é€‰æ‹©æŒ‡å—ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€‰æ‹©æ€§åŠ å¯†æ–¹æ³•åœ¨é™ä½è®¡ç®—å¼€é”€çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡ä¼˜åŒ–åŸºç¡€çš„æ¢¯åº¦åæ¼”æ”»å‡»ã€‚å…·ä½“è€Œè¨€ï¼Œä½¿ç”¨æ¢¯åº¦å¹…åº¦ä½œä¸ºä¿æŠ¤æŒ‡æ ‡æ—¶ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹çš„éšç§ä¿æŠ¤èƒ½åŠ›ï¼Œä¸”åœ¨ä¸åŒæ¨¡å‹æ¶æ„ä¸‹å‡è¡¨ç°å‡ºè‰¯å¥½çš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è”é‚¦å­¦ä¹ ã€éšç§ä¿æŠ¤è®¡ç®—å’Œå®‰å…¨å¤šæ–¹è®¡ç®—ç­‰ã€‚é€šè¿‡æœ‰æ•ˆçš„é€‰æ‹©æ€§åŠ å¯†æ–¹æ³•ï¼Œå¯ä»¥åœ¨ä¿è¯æ¨¡å‹æ•ˆç”¨çš„åŒæ—¶ï¼Œä¿æŠ¤ç”¨æˆ·æ•°æ®éšç§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Gradient inversion attacks pose significant privacy threats to distributed training frameworks such as federated learning, enabling malicious parties to reconstruct sensitive local training data from gradient communications between clients and an aggregation server during the aggregation process. While traditional encryption-based defenses, such as homomorphic encryption, offer strong privacy guarantees without compromising model utility, they often incur prohibitive computational overheads. To mitigate this, selective encryption has emerged as a promising approach, encrypting only a subset of gradient data based on the data's significance under a certain metric. However, there have been few systematic studies on how to specify this metric in practice. This paper systematically evaluates selective encryption methods with different significance metrics against state-of-the-art attacks. Our findings demonstrate the feasibility of selective encryption in reducing computational overhead while maintaining resilience against attacks. We propose a distance-based significance analysis framework that provides theoretical foundations for selecting critical gradient elements for encryption. Through extensive experiments on different model architectures (LeNet, CNN, BERT, GPT-2) and attack types, we identify gradient magnitude as a generally effective metric for protection against optimization-based gradient inversions. However, we also observe that no single selective encryption strategy is universally optimal across all attack scenarios, and we provide guidelines for choosing appropriate strategies for different model architectures and privacy requirements.

