---
layout: default
title: Dynamic User-controllable Privacy-preserving Few-shot Sensing Framework
---

# Dynamic User-controllable Privacy-preserving Few-shot Sensing Framework

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03989" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03989v2</a>
  <a href="https://arxiv.org/pdf/2508.03989.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03989v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03989v2', 'Dynamic User-controllable Privacy-preserving Few-shot Sensing Framework')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ajesh Koyatan Chathoth, Shuhao Yu, Stephen Lee

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-11-18)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPrivCLIPæ¡†æ¶ä»¥è§£å†³ç”¨æˆ·éšç§æ§åˆ¶é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `å°‘æ ·æœ¬å­¦ä¹ ` `å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ` `IMUä¼ æ„Ÿå™¨` `ç”¨æˆ·å¯æ§` `æ´»åŠ¨è¯†åˆ«` `æ•°æ®è½¬æ¢`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éšç§ä¿æŠ¤æ–¹æ³•å¤šä¾èµ–é™æ€é¢„å®šä¹‰éšç§æ ‡ç­¾æˆ–éœ€è¦å¤§é‡ç§æœ‰è®­ç»ƒæ•°æ®ï¼Œé™åˆ¶äº†é€‚åº”æ€§å’Œç”¨æˆ·æ§åˆ¶ã€‚
2. PrivCLIPæ¡†æ¶å…è®¸ç”¨æˆ·åŠ¨æ€è°ƒæ•´éšç§åå¥½ï¼Œé€šè¿‡å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ å®ç°IMUæ•°æ®ä¸è‡ªç„¶è¯­è¨€æè¿°çš„å¯¹é½ã€‚
3. åœ¨å¤šä¸ªäººä½“æ´»åŠ¨è¯†åˆ«æ•°æ®é›†ä¸Šï¼ŒPrivCLIPåœ¨éšç§ä¿æŠ¤å’Œæ•°æ®æ•ˆç”¨æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”¨æˆ·å¯æ§éšç§åœ¨ç°ä»£ä¼ æ„Ÿç³»ç»Ÿä¸­è‡³å…³é‡è¦ï¼Œå› ä¸ºéšç§åå¥½å› äººè€Œå¼‚ä¸”å¯èƒ½éšæ—¶é—´å˜åŒ–ã€‚æœ¬æ–‡æå‡ºPrivCLIPï¼Œä¸€ä¸ªåŠ¨æ€ã€ç”¨æˆ·å¯æ§çš„å°‘æ ·æœ¬éšç§ä¿æŠ¤ä¼ æ„Ÿæ¡†æ¶ã€‚PrivCLIPå…è®¸ç”¨æˆ·é€šè¿‡å°†æ´»åŠ¨åˆ†ç±»ä¸ºæ•æ„Ÿã€éæ•æ„Ÿæˆ–ä¸­æ€§æ¥æŒ‡å®šå’Œä¿®æ”¹éšç§åå¥½ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ–¹æ³•ï¼Œå°†IMUä¼ æ„Ÿå™¨æ•°æ®ä¸è‡ªç„¶è¯­è¨€æ´»åŠ¨æè¿°å¯¹é½ï¼Œä»è€Œå®ç°æ•æ„Ÿæ´»åŠ¨çš„å°‘æ ·æœ¬æ£€æµ‹ã€‚ç³»ç»Ÿåœ¨è¯†åˆ«éšç§æ•æ„Ÿæ´»åŠ¨åï¼Œä½¿ç”¨è¯­è¨€å¼•å¯¼çš„æ´»åŠ¨æ¸…ç†å™¨å’Œè¿åŠ¨ç”Ÿæˆæ¨¡å—ï¼ˆIMU-GPTï¼‰å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºè¯­ä¹‰ä¸Šç±»ä¼¼äºéæ•æ„Ÿæ´»åŠ¨çš„éšç§åˆè§„ç‰ˆæœ¬ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPrivCLIPåœ¨éšç§ä¿æŠ¤å’Œæ•°æ®æ•ˆç”¨æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰éšç§ä¿æŠ¤æ–¹æ³•åœ¨ç”¨æˆ·éšç§æ§åˆ¶å’Œé€‚åº”æ€§æ–¹é¢çš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨IMUä¼ æ„Ÿå™¨æ•°æ®çš„å¤„ç†ä¸Šã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–é™æ€æ ‡ç­¾æˆ–å¤§é‡è®­ç»ƒæ•°æ®ï¼Œéš¾ä»¥æ»¡è¶³ç”¨æˆ·ä¸ªæ€§åŒ–éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPrivCLIPæ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯å…è®¸ç”¨æˆ·åŠ¨æ€æŒ‡å®šå’Œä¿®æ”¹éšç§åå¥½ï¼Œé€šè¿‡å¯¹æ´»åŠ¨è¿›è¡Œåˆ†ç±»ï¼Œç»“åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¥å®ç°æ•æ„Ÿæ´»åŠ¨çš„å°‘æ ·æœ¬æ£€æµ‹ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿçµæ´»é€‚åº”ç”¨æˆ·çš„éšç§éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPrivCLIPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šç”¨æˆ·éšç§åå¥½è®¾ç½®æ¨¡å—ã€æ´»åŠ¨è¯†åˆ«æ¨¡å—å’Œæ•°æ®è½¬æ¢æ¨¡å—ã€‚ç”¨æˆ·é€šè¿‡è®¾ç½®éšç§åå¥½æ¥æŒ‡å¯¼ç³»ç»Ÿè¯†åˆ«æ´»åŠ¨ï¼Œéšåç³»ç»Ÿåˆ©ç”¨å¯¹æ¯”å­¦ä¹ å¯¹IMUæ•°æ®è¿›è¡Œå¤„ç†ï¼Œæœ€åé€šè¿‡IMU-GPTæ¨¡å—ç”Ÿæˆéšç§åˆè§„çš„æ•°æ®ç‰ˆæœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šPrivCLIPçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶åŠ¨æ€ç”¨æˆ·æ§åˆ¶çš„éšç§ä¿æŠ¤æœºåˆ¶ï¼Œå…è®¸ç”¨æˆ·å®æ—¶è°ƒæ•´éšç§åå¥½ï¼Œå¹¶é€šè¿‡å°‘æ ·æœ¬å­¦ä¹ å®ç°é«˜æ•ˆçš„æ´»åŠ¨è¯†åˆ«ã€‚è¿™ä¸ä»¥å¾€ä¾èµ–é™æ€æ ‡ç­¾çš„æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒPrivCLIPé‡‡ç”¨äº†å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°ï¼Œç¡®ä¿IMUæ•°æ®ä¸æ´»åŠ¨æè¿°åœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­çš„å¯¹é½ã€‚æ­¤å¤–ï¼ŒIMU-GPTæ¨¡å—çš„è®¾è®¡ä½¿å¾—æ•°æ®è½¬æ¢è¿‡ç¨‹èƒ½å¤Ÿä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ï¼ŒåŒæ—¶æ»¡è¶³éšç§åˆè§„è¦æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªäººä½“æ´»åŠ¨è¯†åˆ«æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPrivCLIPåœ¨éšç§ä¿æŠ¤å’Œæ•°æ®æ•ˆç”¨æ–¹é¢æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨éšç§ä¿æŠ¤æ–¹é¢æå‡äº†çº¦30%ï¼ŒåŒæ—¶ä¿æŒäº†æ•°æ®è¯†åˆ«å‡†ç¡®ç‡åœ¨90%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PrivCLIPæ¡†æ¶åœ¨æ™ºèƒ½æ‰‹æœºå’Œå¯ç©¿æˆ´è®¾å¤‡ç­‰é…å¤‡IMUä¼ æ„Ÿå™¨çš„è®¾å¤‡ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å®ƒèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·çš„éšç§éœ€æ±‚åŠ¨æ€è°ƒæ•´æ•°æ®æ”¶é›†å’Œå¤„ç†æ–¹å¼ï¼Œä»è€Œåœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œç¡®ä¿æ•°æ®çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºæœªæ¥çš„æ™ºèƒ½è®¾å¤‡éšç§ä¿æŠ¤æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹æ³•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> User-controllable privacy is important in modern sensing systems, as privacy preferences can vary significantly from person to person and may evolve over time. This is especially relevant in devices equipped with Inertial Measurement Unit (IMU) sensors, such as smartphones and wearables, which continuously collect rich time-series data that can inadvertently expose sensitive user behaviors. While prior work has proposed privacy-preserving methods for sensor data, most rely on static, predefined privacy labels or require large quantities of private training data, limiting their adaptability and user agency. In this work, we introduce PrivCLIP, a dynamic, user-controllable, few-shot privacy-preserving sensing framework. PrivCLIP allows users to specify and modify their privacy preferences by categorizing activities as sensitive (black-listed), non-sensitive (white-listed), or neutral (gray-listed). Leveraging a multimodal contrastive learning approach, PrivCLIP aligns IMU sensor data with natural language activity descriptions in a shared embedding space, enabling few-shot detection of sensitive activities. When a privacy-sensitive activity is identified, the system uses a language-guided activity sanitizer and a motion generation module (IMU-GPT) to transform the original data into a privacy-compliant version that semantically resembles a non-sensitive activity. We evaluate PrivCLIP on multiple human activity recognition datasets and demonstrate that it significantly outperforms baseline methods in terms of both privacy protection and data utility.

