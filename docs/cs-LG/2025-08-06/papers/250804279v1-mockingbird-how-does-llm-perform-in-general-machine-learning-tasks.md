---
layout: default
title: Mockingbird: How does LLM perform in general machine learning tasks?
---

# Mockingbird: How does LLM perform in general machine learning tasks?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04279" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04279v1</a>
  <a href="https://arxiv.org/pdf/2508.04279.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04279v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04279v1', 'Mockingbird: How does LLM perform in general machine learning tasks?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haoyu Jia, Yoshiki Obinata, Kento Kawaharazuka, Kei Okada

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMockingbirdæ¡†æ¶ä»¥æå‡LLMåœ¨é€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æœºå™¨å­¦ä¹ ` `è‡ªæˆ‘åæ€` `è§’è‰²æ‰®æ¼”` `é€šç”¨ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†é€šç”¨ä»»åŠ¡æ—¶ï¼Œå¾€å¾€ä¾èµ–äºé¢†åŸŸç‰¹å®šçš„çŸ¥è¯†å’Œäººç±»ä¸“å®¶çš„åé¦ˆï¼Œé™åˆ¶äº†å…¶çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚
2. æœ¬æ–‡æå‡ºçš„Mockingbirdæ¡†æ¶é€šè¿‡æŒ‡å¯¼LLMsè¿›è¡Œè§’è‰²æ‰®æ¼”å’Œè‡ªæˆ‘åæ€ï¼Œæ—¨åœ¨æå‡å…¶åœ¨é€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMockingbirdåœ¨å¤šä¸ªé€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°è‰¯å¥½ï¼Œä½†ä»éœ€ç»“åˆé¢†åŸŸç‰¹å®šçŸ¥è¯†ä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ­£è¢«è¶Šæ¥è¶Šå¤šåœ°ç”¨ä½œèŠå¤©æœºå™¨äººï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·æŒ‡ä»¤æ€»ç»“ä¿¡æ¯æˆ–ç”Ÿæˆæ–‡æœ¬å’Œä»£ç ã€‚LLMsæ¨ç†èƒ½åŠ›å’Œæ¨ç†é€Ÿåº¦çš„å¿«é€Ÿæå‡æ˜¾ç¤ºäº†å…¶åœ¨èŠå¤©æœºå™¨äººä¹‹å¤–çš„å¹¿æ³›åº”ç”¨æ½œåŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºMockingbirdçš„æ¡†æ¶ï¼Œä»¥é€‚åº”LLMsåœ¨é€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œå¹¶è¯„ä¼°å…¶åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯æŒ‡å¯¼LLMsè¿›è¡Œè§’è‰²æ‰®æ¼”å¹¶åæ€è‡ªèº«é”™è¯¯ä»¥å®ç°è‡ªæˆ‘æ”¹è¿›ã€‚è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒåŸºäºLLMçš„æœºå™¨å­¦ä¹ æ–¹æ³•å¦‚Mockingbirdåœ¨å¸¸è§æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­å¯ä»¥å–å¾—å¯æ¥å—çš„ç»“æœï¼Œä½†ä»…ä¾é è‡ªæˆ‘åæ€ç›®å‰å°šæ— æ³•è¶…è¶Šé¢†åŸŸç‰¹å®šæ–‡æ¡£å’Œäººç±»ä¸“å®¶åé¦ˆçš„æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­çš„é€‚åº”æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–äºé¢†åŸŸç‰¹å®šæ–‡æ¡£å’Œäººç±»åé¦ˆï¼Œé™åˆ¶äº†LLMsçš„åº”ç”¨èŒƒå›´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMockingbirdæ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è§’è‰²æ‰®æ¼”å’Œè‡ªæˆ‘åæ€æ¥æå‡LLMsçš„å­¦ä¹ èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ²¡æœ‰å¤§é‡é¢†åŸŸçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œé€æ­¥æ”¹è¿›å…¶æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMockingbirdæ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œé¦–å…ˆæ˜¯ä»»åŠ¡æŒ‡ä»¤æ¨¡å—ï¼ŒæŒ‡å¯¼LLMsç†è§£ä»»åŠ¡ï¼›å…¶æ¬¡æ˜¯è§’è‰²æ‰®æ¼”æ¨¡å—ï¼Œæ¨¡æ‹Ÿä¸åŒçš„å­¦ä¹ è§’è‰²ï¼›æœ€åæ˜¯åæ€æ¨¡å—ï¼Œåˆ†ææ¨¡å‹çš„é”™è¯¯å¹¶è¿›è¡Œè‡ªæˆ‘æ”¹è¿›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†è‡ªæˆ‘åæ€æœºåˆ¶å¼•å…¥LLMsçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æ²¡æœ‰å¤–éƒ¨åé¦ˆçš„æƒ…å†µä¸‹è¿›è¡Œè‡ªæˆ‘ä¼˜åŒ–ã€‚è¿™ä¸ä¼ ç»Ÿçš„ä¾èµ–äºä¸“å®¶åé¦ˆçš„æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥è¡¡é‡æ¨¡å‹çš„è‡ªæˆ‘åæ€æ•ˆæœï¼Œå¹¶è®¾è®¡äº†é€‚åº”æ€§å­¦ä¹ ç‡ä»¥æé«˜è®­ç»ƒæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMockingbirdåœ¨å¤šä¸ªé€šç”¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­å–å¾—äº†å¯æ¥å—çš„æ€§èƒ½ï¼Œå°½ç®¡åœ¨æŸäº›ä»»åŠ¡ä¸Šä»æœªè¶…è¶Šé¢†åŸŸç‰¹å®šæ–‡æ¡£å’Œäººç±»åé¦ˆçš„æ•ˆæœã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ï¼Œä½†æ•´ä½“æå‡å¹…åº¦æ˜¾ç¤ºå‡ºLLMsåœ¨é€šç”¨ä»»åŠ¡ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨åŒ–æ–‡æœ¬ç”Ÿæˆã€ä»£ç ç”Ÿæˆä»¥åŠå…¶ä»–éœ€è¦è‡ªç„¶è¯­è¨€ç†è§£çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚Mockingbirdæ¡†æ¶çš„è®¾è®¡ä½¿å¾—LLMsèƒ½å¤Ÿåœ¨å¤šç§ä»»åŠ¡ä¸­çµæ´»åº”ç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„äººå·¥æ™ºèƒ½åº”ç”¨åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are now being used with increasing frequency as chat bots, tasked with the summarizing information or generating text and code in accordance with user instructions. The rapid increase in reasoning capabilities and inference speed of LLMs has revealed their remarkable potential for applications extending beyond the domain of chat bots to general machine learning tasks. This work is conducted out of the curiosity about such potential. In this work, we propose a framework Mockingbird to adapt LLMs to general machine learning tasks and evaluate its performance and scalability on several general machine learning tasks. The core concept of this framework is instructing LLMs to role-play functions and reflect on its mistakes to improve itself. Our evaluation and analysis result shows that LLM-driven machine learning methods, such as Mockingbird, can achieve acceptable results on common machine learning tasks; however, solely reflecting on its own currently cannot outperform the effect of domain-specific documents and feedback from human experts.

