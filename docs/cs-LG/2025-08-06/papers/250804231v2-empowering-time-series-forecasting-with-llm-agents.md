---
layout: default
title: Empowering Time Series Forecasting with LLM-Agents
---

# Empowering Time Series Forecasting with LLM-Agents

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04231" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04231v2</a>
  <a href="https://arxiv.org/pdf/2508.04231.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04231v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04231v2', 'Empowering Time Series Forecasting with LLM-Agents')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chin-Chia Michael Yeh, Vivian Lai, Uday Singh Saini, Xiran Fan, Yujie Fan, Junpeng Wang, Xin Dai, Yan Zheng

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06 (æ›´æ–°: 2025-11-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDCATSä»¥æå‡æ—¶é—´åºåˆ—é¢„æµ‹çš„æ•°æ®è´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `æ•°æ®ä¸­å¿ƒæ–¹æ³•` `è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ•°æ®æ¸…æ´—` `å…ƒæ•°æ®åˆ©ç”¨` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„AutoMLæ–¹æ³•ä¸»è¦å…³æ³¨ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹æ¶æ„æœç´¢ï¼Œå¿½è§†äº†æ•°æ®è´¨é‡å¯¹é¢„æµ‹æ€§èƒ½çš„å½±å“ã€‚
2. DCATSé€šè¿‡åˆ©ç”¨æ—¶é—´åºåˆ—çš„å…ƒæ•°æ®æ¥æ¸…æ´—æ•°æ®ï¼Œä»è€Œæå‡é¢„æµ‹æ€§èƒ½ï¼Œå¼ºè°ƒæ•°æ®è´¨é‡çš„é‡è¦æ€§ã€‚
3. åœ¨å¤§è§„æ¨¡äº¤é€šæµé‡é¢„æµ‹æ•°æ®é›†ä¸Šï¼ŒDCATSåœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹ä¸Šå¹³å‡é™ä½äº†6%çš„é¢„æµ‹è¯¯å·®ï¼Œæ˜¾ç¤ºå‡ºå…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„æ™ºèƒ½ä½“å·²æˆä¸ºè‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ï¼ˆAutoMLï¼‰ç³»ç»Ÿä¸­çš„æœ‰æ•ˆè§„åˆ’è€…ã€‚ç°æœ‰çš„AutoMLæ–¹æ³•å¤šé›†ä¸­äºç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹æ¶æ„æœç´¢ï¼Œè€Œåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­ï¼Œè½»é‡çº§æ¨¡å‹å¾€å¾€èƒ½å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚åŸºäºè¿™ä¸€è§‚å¯Ÿï¼Œæˆ‘ä»¬æ¢ç´¢äº†æå‡æ•°æ®è´¨é‡è€Œéæ¨¡å‹æ¶æ„çš„æ–¹å‘ã€‚æˆ‘ä»¬æå‡ºäº†DCATSï¼Œä¸€ä¸ªç”¨äºæ—¶é—´åºåˆ—çš„æ•°æ®ä¸­å¿ƒæ™ºèƒ½ä½“ï¼Œåˆ©ç”¨æ—¶é—´åºåˆ—çš„å…ƒæ•°æ®æ¸…æ´—æ•°æ®ï¼ŒåŒæ—¶ä¼˜åŒ–é¢„æµ‹æ€§èƒ½ã€‚é€šè¿‡åœ¨å¤§è§„æ¨¡äº¤é€šæµé‡é¢„æµ‹æ•°æ®é›†ä¸Šè¯„ä¼°DCATSï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨æ‰€æœ‰æµ‹è¯•æ¨¡å‹å’Œæ—¶é—´èŒƒå›´å†…å¹³å‡é™ä½äº†6%çš„è¯¯å·®ï¼Œçªæ˜¾äº†æ•°æ®ä¸­å¿ƒæ–¹æ³•åœ¨æ—¶é—´åºåˆ—é¢„æµ‹AutoMLä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­æ•°æ®è´¨é‡ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†æ•°æ®æ¸…æ´—çš„é‡è¦æ€§ï¼Œå¯¼è‡´é¢„æµ‹æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºDCATSï¼Œé€šè¿‡åˆ©ç”¨æ—¶é—´åºåˆ—çš„å…ƒæ•°æ®è¿›è¡Œæ•°æ®æ¸…æ´—ï¼Œä¼˜åŒ–é¢„æµ‹æ€§èƒ½ï¼Œå¼ºè°ƒæ•°æ®è´¨é‡åœ¨AutoMLä¸­çš„é‡è¦æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDCATSçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ¸…æ´—æ¨¡å—å’Œé¢„æµ‹æ¨¡å‹ä¼˜åŒ–æ¨¡å—ã€‚æ•°æ®æ¸…æ´—æ¨¡å—åˆ©ç”¨å…ƒæ•°æ®è¯†åˆ«å’Œä¿®æ­£æ•°æ®ä¸­çš„å™ªå£°å’Œç¼ºå¤±å€¼ï¼Œé¢„æµ‹æ¨¡å‹ä¼˜åŒ–æ¨¡å—åˆ™åŸºäºæ¸…æ´—åçš„æ•°æ®è¿›è¡Œè®­ç»ƒå’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šDCATSçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ•°æ®ä¸­å¿ƒæ–¹æ³•å¼•å…¥æ—¶é—´åºåˆ—é¢„æµ‹ï¼Œå¼ºè°ƒæ•°æ®è´¨é‡è€Œéæ¨¡å‹æ¶æ„çš„ä¼˜åŒ–ã€‚è¿™ä¸€æ€è·¯ä¸ä¼ ç»Ÿçš„AutoMLæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨DCATSä¸­ï¼Œå…³é”®è®¾è®¡åŒ…æ‹¬å…ƒæ•°æ®çš„é€‰æ‹©å’Œå¤„ç†ç­–ç•¥ï¼Œä»¥åŠé’ˆå¯¹ä¸åŒæ—¶é—´åºåˆ—æ¨¡å‹çš„é€‚é…æ€§è°ƒæ•´ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†æ•°æ®æ¸…æ´—çš„æœ‰æ•ˆæ€§å’Œé¢„æµ‹æ¨¡å‹çš„æ€§èƒ½æå‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDCATSåœ¨æ‰€æœ‰æµ‹è¯•çš„æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ä¸Šå¹³å‡é™ä½äº†6%çš„é¢„æµ‹è¯¯å·®ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æå‡æ•°æ®è´¨é‡æ–¹é¢çš„æ˜¾è‘—æ•ˆæœã€‚è¿™ä¸€æˆæœä¸ºæœªæ¥çš„AutoMLç ”ç©¶æä¾›äº†æ–°çš„æ€è·¯å’Œæ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äº¤é€šæµé‡é¢„æµ‹ã€é‡‘èå¸‚åœºåˆ†æå’Œæ°”å€™å˜åŒ–ç›‘æµ‹ç­‰ã€‚é€šè¿‡æå‡æ•°æ®è´¨é‡ï¼ŒDCATSèƒ½å¤Ÿä¸ºå„ç±»æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡æä¾›æ›´å‡†ç¡®çš„ç»“æœï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Model (LLM) powered agents have emerged as effective planners for Automated Machine Learning (AutoML) systems. While most existing AutoML approaches focus on automating feature engineering and model architecture search, recent studies in time series forecasting suggest that lightweight models can often achieve state-of-the-art performance. This observation led us to explore improving data quality, rather than model architecture, as a potentially fruitful direction for AutoML on time series data. We propose DCATS, a Data-Centric Agent for Time Series. DCATS leverages metadata accompanying time series to clean data while optimizing forecasting performance. We evaluated DCATS using four time series forecasting models on a large-scale traffic volume forecasting dataset. Results demonstrate that DCATS achieves an average 6% error reduction across all tested models and time horizons, highlighting the potential of data-centric approaches in AutoML for time series forecasting.

