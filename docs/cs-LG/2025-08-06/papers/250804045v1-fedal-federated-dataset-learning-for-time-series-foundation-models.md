---
layout: default
title: FeDaL: Federated Dataset Learning for Time Series Foundation Models
---

# FeDaL: Federated Dataset Learning for Time Series Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04045" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04045v1</a>
  <a href="https://arxiv.org/pdf/2508.04045.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04045v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04045v1', 'FeDaL: Federated Dataset Learning for Time Series Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shengchao Chen, Guodong Long, Jing Jiang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-06

**å¤‡æ³¨**: 28 pages, scaling FL to time series foundation models

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFeDaLä»¥è§£å†³æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ä¸­çš„æ•°æ®é›†å¼‚è´¨æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æ—¶é—´åºåˆ—åˆ†æ` `æ•°æ®é›†å¼‚è´¨æ€§` `æ¨¡å‹æ³›åŒ–` `é¢†åŸŸåå·®æ¶ˆé™¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹åœ¨é¢å¯¹æ•°æ®é›†å¼‚è´¨æ€§æ—¶ï¼Œå®¹æ˜“å—åˆ°é¢†åŸŸåå·®çš„å½±å“ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºçš„FeDaLæ–¹æ³•é€šè¿‡è”é‚¦å­¦ä¹ æ¶æ„ï¼Œå­¦ä¹ æ•°æ®é›†æ— å…³çš„æ—¶é—´è¡¨ç¤ºï¼Œå¹¶å¼•å…¥DBEå’ŒGBEæœºåˆ¶æ¥å‡è½»åå·®ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šFeDaLåœ¨å…«ä¸ªä»»åŠ¡çš„çœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¡¨ç°ä¼˜äº54ä¸ªåŸºçº¿æ–¹æ³•ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é›†å±‚é¢çš„å¼‚è´¨æ€§å¼•å…¥äº†æ˜¾è‘—çš„é¢†åŸŸåå·®ï¼Œä¸¥é‡å½±å“äº†æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆTSFMï¼‰çš„æ³›åŒ–èƒ½åŠ›ï¼Œè€Œè¿™ä¸€æŒ‘æˆ˜å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚æœ¬æ–‡é€šè¿‡è”é‚¦å­¦ä¹ çš„èŒƒå¼é‡æ–°æ€è€ƒTSFMçš„å‘å±•ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„è”é‚¦æ•°æ®é›†å­¦ä¹ ï¼ˆFeDaLï¼‰æ–¹æ³•ï¼Œä»¥å­¦ä¹ æ•°æ®é›†æ— å…³çš„æ—¶é—´è¡¨ç¤ºã€‚å…·ä½“è€Œè¨€ï¼Œè”é‚¦å­¦ä¹ çš„åˆ†å¸ƒå¼æ¶æ„è‡ªç„¶åœ°å°†å¼‚è´¨æ—¶é—´åºåˆ—æ•°æ®é›†åˆ†è§£ä¸ºå…±äº«çš„é€šç”¨çŸ¥è¯†å’Œä¿ç•™çš„ä¸ªæ€§åŒ–çŸ¥è¯†ã€‚æ­¤å¤–ï¼ŒåŸºäºTSFMæ¶æ„ï¼ŒFeDaLé€šè¿‡å¼•å…¥é¢†åŸŸåå·®æ¶ˆé™¤ï¼ˆDBEï¼‰å’Œå…¨å±€åå·®æ¶ˆé™¤ï¼ˆGBEï¼‰ä¸¤ä¸ªäº’è¡¥æœºåˆ¶ï¼Œæ˜ç¡®å‡è½»äº†å±€éƒ¨å’Œå…¨å±€åå·®ã€‚FeDaLçš„è·¨æ•°æ®é›†æ³›åŒ–åœ¨æ¶µç›–å…«ä¸ªä»»åŠ¡çš„çœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›è¯„ä¼°ï¼Œç›¸è¾ƒäº54ä¸ªåŸºçº¿æ–¹æ³•è¡¨ç°å‡ºè‰²ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æäº†è”é‚¦æ‰©å±•è¡Œä¸ºï¼Œå±•ç¤ºäº†æ•°æ®é‡ã€å®¢æˆ·ç«¯æ•°é‡å’ŒåŠ å…¥ç‡å¦‚ä½•å½±å“å»ä¸­å¿ƒåŒ–ä¸‹çš„æ¨¡å‹æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼ˆTSFMï¼‰åœ¨é¢å¯¹æ•°æ®é›†å¼‚è´¨æ€§æ—¶æ‰€å¸¦æ¥çš„é¢†åŸŸåå·®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆå¤„ç†è¿™ç§å¼‚è´¨æ€§ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFeDaLæ–¹æ³•é€šè¿‡è”é‚¦å­¦ä¹ çš„åˆ†å¸ƒå¼æ¶æ„ï¼Œæ—¨åœ¨å°†å¼‚è´¨æ—¶é—´åºåˆ—æ•°æ®é›†åˆ†è§£ä¸ºå…±äº«çš„é€šç”¨çŸ¥è¯†å’Œä¸ªæ€§åŒ–çŸ¥è¯†ï¼Œä»è€Œå®ç°æ•°æ®é›†æ— å…³çš„æ—¶é—´è¡¨ç¤ºå­¦ä¹ ã€‚é€šè¿‡å¼•å…¥DBEå’ŒGBEæœºåˆ¶ï¼ŒFeDaLèƒ½å¤Ÿæœ‰æ•ˆå‡è½»å±€éƒ¨å’Œå…¨å±€åå·®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFeDaLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é›†åˆ†è§£ã€çŸ¥è¯†å…±äº«å’Œåå·®æ¶ˆé™¤ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡è”é‚¦å­¦ä¹ æ¡†æ¶è¿›è¡Œæ•°æ®é›†çš„åˆ†å¸ƒå¼å¤„ç†ï¼›å…¶æ¬¡ï¼Œæå–å…±äº«çŸ¥è¯†å’Œä¸ªæ€§åŒ–çŸ¥è¯†ï¼›æœ€åï¼Œåº”ç”¨DBEå’ŒGBEæœºåˆ¶æ¥æ¶ˆé™¤åå·®ã€‚

**å…³é”®åˆ›æ–°**ï¼šFeDaLçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶é€šè¿‡è”é‚¦å­¦ä¹ å®ç°çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¼‚è´¨æ•°æ®é›†æ—¶çš„æœ‰æ•ˆæ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFeDaLèƒ½å¤Ÿæ›´å¥½åœ°ä¿ç•™ä¸ªæ€§åŒ–çŸ¥è¯†ï¼ŒåŒæ—¶å…±äº«é€šç”¨çŸ¥è¯†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨FeDaLä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡å…±äº«çŸ¥è¯†å’Œä¸ªæ€§åŒ–çŸ¥è¯†çš„å­¦ä¹ ï¼ŒåŒæ—¶é‡‡ç”¨äº†é€‚åº”æ€§å‚æ•°è®¾ç½®æ¥ä¼˜åŒ–DBEå’ŒGBEæœºåˆ¶çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FeDaLåœ¨çœŸå®æ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå…¶è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›æ˜¾è‘—ä¼˜äº54ä¸ªåŸºçº¿æ–¹æ³•ï¼Œå°¤å…¶åœ¨å…«ä¸ªä»»åŠ¡ä¸­è¡¨ç°çªå‡ºã€‚å…·ä½“è€Œè¨€ï¼ŒFeDaLåœ¨æŸäº›ä»»åŠ¡ä¸Šæå‡äº†æ¨¡å‹æ€§èƒ½è¶…è¿‡20%ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†å¼‚è´¨æ—¶é—´åºåˆ—æ•°æ®é›†æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èå¸‚åœºåˆ†æã€åŒ»ç–—å¥åº·ç›‘æµ‹å’Œæ™ºèƒ½åˆ¶é€ ç­‰æ—¶é—´åºåˆ—æ•°æ®å¯†é›†çš„åœºæ™¯ã€‚é€šè¿‡æœ‰æ•ˆå¤„ç†æ•°æ®é›†å¼‚è´¨æ€§ï¼ŒFeDaLèƒ½å¤Ÿæå‡æ¨¡å‹åœ¨ä¸åŒé¢†åŸŸçš„æ³›åŒ–èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dataset-wise heterogeneity introduces significant domain biases that fundamentally degrade generalization on Time Series Foundation Models (TSFMs), yet this challenge remains underexplored. This paper rethink the development of TSFMs using the paradigm of federated learning. We propose a novel Federated Dataset Learning (FeDaL) approach to tackle heterogeneous time series by learning dataset-agnostic temporal representations. Specifically, the distributed architecture of federated learning is a nature solution to decompose heterogeneous TS datasets into shared generalized knowledge and preserved personalized knowledge. Moreover, based on the TSFM architecture, FeDaL explicitly mitigates both local and global biases by adding two complementary mechanisms: Domain Bias Elimination (DBE) and Global Bias Elimination (GBE). FeDaL`s cross-dataset generalization has been extensively evaluated in real-world datasets spanning eight tasks, including both representation learning and downstream time series analysis, against 54 baselines. We further analyze federated scaling behavior, showing how data volume, client count, and join rate affect model performance under decentralization.

