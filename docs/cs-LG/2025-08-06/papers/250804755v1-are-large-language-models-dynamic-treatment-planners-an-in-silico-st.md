---
layout: default
title: Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle
---

# Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04755" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.04755v1</a>
  <a href="https://arxiv.org/pdf/2508.04755.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04755v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04755v1', 'Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Zhiyao Luo, Tingting Zhu

**ÂàÜÁ±ª**: cs.LG, cs.CE

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-06

**Â§áÊ≥®**: 20 pages

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰ºòÂåñÂä®ÊÄÅÊ≤ªÁñóÊñπÊ°à‰ª•ÊîπÂñÑ‰∏¥Â∫äÂÜ≥Á≠ñ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Âä®ÊÄÅÊ≤ªÁñóÊñπÊ°à` `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `‰∏¥Â∫äÂÜ≥Á≠ñ` `Âº∫ÂåñÂ≠¶‰π†` `ËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥` `Èõ∂-shotÊé®ÁêÜ` `‰∏¥Â∫äÁü•ËØÜÊ≥®ÂÖ•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂä®ÊÄÅÊ≤ªÁñóÊñπÊ°àÂú®‰∏¥Â∫äÂÜ≥Á≠ñ‰∏≠Èù¢‰∏¥Áü•ËØÜÊ≥®ÂÖ•ÂíåÊÇ£ËÄÖÂÆâÂÖ®‰øùÈöúÁöÑÂ∑•Á®ãÊåëÊàòÔºåÈôêÂà∂‰∫ÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈõ∂-shotÊé®ÁêÜËÉΩÂäõÔºåÈÄöËøáËØ≠Ë®ÄÊèêÁ§∫Ëá™ÁÑ∂ÂµåÂÖ•ÈöêÊÄß‰∏¥Â∫äÁü•ËØÜÔºå‰ª•‰ºòÂåñËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÁªèËøáËÆæËÆ°ÁöÑÈõ∂-shotÊèêÁ§∫‰ΩøÂæóÂ∞èÂûãLLMsÂú®Á®≥ÂÆöÊÇ£ËÄÖÁæ§‰Ωì‰∏≠Ë°®Áé∞Âá∫‰∏é‰∏ìÈó®ËÆ≠ÁªÉÁöÑSRAsÁõ∏ÂΩìÊàñÊõ¥‰ºòÁöÑ‰∏¥Â∫äÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÂä®ÊÄÅÊ≤ªÁñóÊñπÊ°àÂú®Â§çÊùÇ‰∏¥Â∫äÂÜ≥Á≠ñ‰∏≠ÂÖ∑ÊúâÊΩúÂäõÔºå‰ΩÜÂÖ∂ÂÆûÈôÖÂ∫îÁî®ÂèóÂà∞Ê≥®ÂÖ•‰∏¥Â∫äÁü•ËØÜÂíåÁ°Æ‰øùÊÇ£ËÄÖÂÆâÂÖ®ÁöÑÂ∑•Á®ãË¶ÅÊ±ÇÁöÑÈôêÂà∂„ÄÇÊú¨ÊñáËØÑ‰º∞‰∫ÜÂºÄÊ∫êÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMsÔºâÂú®1ÂûãÁ≥ñÂ∞øÁóÖÊ®°ÊãüÂô®‰∏≠ÁöÑÂä®ÊÄÅËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥ËÉΩÂäõÔºåÊØîËæÉÂÖ∂Èõ∂-shotÊé®ÁêÜÊÄßËÉΩ‰∏é‰∏ìÈó®ËÆ≠ÁªÉÁöÑÂ∞èÂûãÁ•ûÁªèÁΩëÁªúÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÔºàSRAsÔºâ„ÄÇÁ†îÁ©∂Ë°®ÊòéÔºåÁªèËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÈõ∂-shotÊèêÁ§∫‰ΩøÂæóËæÉÂ∞èÁöÑLLMsÔºàÂ¶ÇQwen2.5-7BÔºâÂú®Á®≥ÂÆöÊÇ£ËÄÖÁæ§‰Ωì‰∏≠ËÉΩÂ§üÂÆûÁé∞‰∏éÁªèËøáÂπøÊ≥õËÆ≠ÁªÉÁöÑSRAsÁõ∏ÂΩìÊàñÊõ¥‰ºòÁöÑ‰∏¥Â∫äË°®Áé∞„ÄÇÁÑ∂ËÄåÔºåLLMsÂú®ÈìæÂºèÊé®ÁêÜÊèêÁ§∫‰∏ãË°®Áé∞Âá∫Ëøá‰∫éÊøÄËøõÁöÑËÉ∞Â≤õÁ¥†ÂâÇÈáèÔºåÊè≠Á§∫‰∫ÜÁÆóÊúØÂπªËßâ„ÄÅÊó∂Èó¥ËØØËß£Âíå‰∏¥Â∫äÈÄªËæë‰∏ç‰∏ÄËá¥Á≠âÂÖ≥ÈîÆÂ§±Ë¥•Ê®°Âºè„ÄÇÁ†îÁ©∂ÁªìÊûúÂº∫Ë∞É‰∫ÜÂú®‰∏¥Â∫äÂ∑•‰ΩúÊµÅÁ®ã‰∏≠Ë∞®ÊÖéÊï¥ÂêàLLMsÁöÑÂøÖË¶ÅÊÄßÔºåÂπ∂Âª∫ËÆÆÁªìÂêàËØ≠Ë®ÄÊé®ÁêÜ‰∏éÁªìÊûÑÂåñÁîüÁêÜÂª∫Ê®°ÁöÑÊ∑∑ÂêàÊñπÊ≥ï‰ª•ÂÆûÁé∞ÂÆâÂÖ®ÊúâÊïàÁöÑÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Âä®ÊÄÅÊ≤ªÁñóÊñπÊ°àÂú®‰∏¥Â∫äÂ∫îÁî®‰∏≠Èù¢‰∏¥ÁöÑÁü•ËØÜÊ≥®ÂÖ•ÂíåÊÇ£ËÄÖÂÆâÂÖ®‰øùÈöúÁöÑÊåëÊàòÔºåÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄÈúÄË¶ÅÂ§ßÈáèÁöÑÁéØÂ¢ÉÁâπÂÆöËÆ≠ÁªÉÔºåÈôêÂà∂‰∫ÜÂÖ∂ÁÅµÊ¥ªÊÄßÂíåÂÆûÁî®ÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫Âà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÁöÑÈõ∂-shotÊé®ÁêÜËÉΩÂäõÔºåÈÄöËøáÁ≤æÂøÉËÆæËÆ°ÁöÑËØ≠Ë®ÄÊèêÁ§∫Ôºå‰ΩøÊ®°ÂûãËÉΩÂ§üËá™ÁÑ∂Âú∞ÂµåÂÖ•ÈöêÊÄß‰∏¥Â∫äÁü•ËØÜÔºå‰ªéËÄå‰ºòÂåñËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÁ†îÁ©∂ÈááÁî®‰∫ÜÂºÄÊ∫êÂ§ßÂûãËØ≠Ë®ÄÊ®°Âûã‰Ωú‰∏∫Âä®ÊÄÅËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥ÁöÑ‰ª£ÁêÜÔºåÊûÑÂª∫‰∫Ü‰∏Ä‰∏™Âü∫‰∫é1ÂûãÁ≥ñÂ∞øÁóÖÁöÑÊ®°ÊãüÂô®ÔºåËøõË°åÈõ∂-shotÊé®ÁêÜ‰∏éÂ∞èÂûãÁ•ûÁªèÁΩëÁªúÂº∫ÂåñÂ≠¶‰π†‰ª£ÁêÜÁöÑÊÄßËÉΩÂØπÊØî„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂ∞ÜÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂ∫îÁî®‰∫éÂä®ÊÄÅÊ≤ªÁñóÊñπÊ°à‰∏≠ÔºåÂà©Áî®ÂÖ∂ËØ≠Ë®ÄÁêÜËß£ËÉΩÂäõËøõË°å‰∏¥Â∫äÂÜ≥Á≠ñÔºåËÄå‰∏çÊòØ‰æùËµñ‰∫é‰º†ÁªüÁöÑÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠ÔºåËÆæËÆ°‰∫ÜÂ§öÁßçÈõ∂-shotÊèêÁ§∫‰ª•ÂºïÂØºÊ®°ÂûãËøõË°åÊé®ÁêÜÔºåÁâπÂà´ÂÖ≥Ê≥®‰∫ÜÈìæÂºèÊé®ÁêÜÁöÑÂΩ±ÂìçÔºåÂπ∂ÂàÜÊûê‰∫ÜÊ®°ÂûãÂú®Â§ÑÁêÜÊΩúÂú®‰∏¥Â∫äÁä∂ÊÄÅÔºàÂ¶ÇËøõÈ§êÔºâÊó∂ÁöÑË°®Áé∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÁªèËøáÁ≤æÂøÉËÆæËÆ°ÁöÑÈõ∂-shotÊèêÁ§∫‰ΩøÂæóÂ∞èÂûãLLMsÔºàÂ¶ÇQwen2.5-7BÔºâÂú®Á®≥ÂÆöÊÇ£ËÄÖÁæ§‰Ωì‰∏≠ÂÆûÁé∞‰∫Ü‰∏éÁªèËøáÂπøÊ≥õËÆ≠ÁªÉÁöÑSRAsÁõ∏ÂΩìÊàñÊõ¥‰ºòÁöÑ‰∏¥Â∫äË°®Áé∞ÔºåÂ∞§ÂÖ∂Âú®Â§ÑÁêÜÂ§çÊùÇÁöÑ‰∏¥Â∫äÂÜ≥Á≠ñÊó∂ÊòæÁ§∫Âá∫ÊòæËëóÁöÑÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Á≥ñÂ∞øÁóÖÁÆ°ÁêÜ„ÄÅ‰∏™ÊÄßÂåñÂåªÁñóÂíåÊô∫ËÉΩÂÜ≥Á≠ñÊîØÊåÅÁ≥ªÁªü„ÄÇÈÄöËøá‰ºòÂåñËÉ∞Â≤õÁ¥†ÂâÇÈáèË∞ÉÊï¥ÔºåËÉΩÂ§üÊèêÈ´òÊÇ£ËÄÖÁöÑÊ≤ªÁñóÊïàÊûúÂíåÂÆâÂÖ®ÊÄßÔºåÊú™Êù•ÂèØËÉΩÂú®Êõ¥ÂπøÊ≥õÁöÑ‰∏¥Â∫äÂú∫ÊôØ‰∏≠Êé®Âπø„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold promise for automating complex clinical decision-making, yet their practical deployment remains hindered by the intensive engineering required to inject clinical knowledge and ensure patient safety. Recent advancements in large language models (LLMs) suggest a complementary approach, where implicit prior knowledge and clinical heuristics are naturally embedded through linguistic prompts without requiring environment-specific training. In this study, we rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in silico Type 1 diabetes simulator, comparing their zero-shot inference performance against small neural network-based RL agents (SRAs) explicitly trained for the task. Our results indicate that carefully designed zero-shot prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or superior clinical performance relative to extensively trained SRAs, particularly in stable patient cohorts. However, LLMs exhibit notable limitations, such as overly aggressive insulin dosing when prompted with chain-of-thought (CoT) reasoning, highlighting critical failure modes including arithmetic hallucination, temporal misinterpretation, and inconsistent clinical logic. Incorporating explicit reasoning about latent clinical states (e.g., meals) yielded minimal performance gains, underscoring the current model's limitations in capturing complex, hidden physiological dynamics solely through textual inference. Our findings advocate for cautious yet optimistic integration of LLMs into clinical workflows, emphasising the necessity of targeted prompt engineering, careful validation, and potentially hybrid approaches that combine linguistic reasoning with structured physiological modelling to achieve safe, robust, and clinically effective decision-support systems.

