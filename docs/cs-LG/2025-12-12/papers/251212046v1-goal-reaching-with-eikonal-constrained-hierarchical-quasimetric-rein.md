---
layout: default
title: Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning
---

# Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.12046" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.12046v1</a>
  <a href="https://arxiv.org/pdf/2512.12046.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.12046v1" onclick="toggleFavorite(this, '2512.12046v1', 'Goal Reaching with Eikonal-Constrained Hierarchical Quasimetric Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vittorio Giammarino, Ahmed H. Qureshi

**åˆ†ç±»**: cs.LG, cs.RO, eess.SY, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-12-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEik-HiQRLï¼Œç»“åˆEikonalæ–¹ç¨‹ä¸åˆ†å±‚å¼ºåŒ–å­¦ä¹ è§£å†³å¤æ‚ç¯å¢ƒä¸‹çš„ç›®æ ‡å¯¼å‘å¯¼èˆªé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ` `æ‹Ÿåº¦é‡å¼ºåŒ–å­¦ä¹ ` `Eikonalæ–¹ç¨‹` `åˆ†å±‚å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººå¯¼èˆª` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ å¥–åŠ±è®¾è®¡å›°éš¾ï¼Œç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ é€šè¿‡ç›®æ ‡åˆ°è¾¾æ¥ç®€åŒ–ä»»åŠ¡å®šä¹‰ï¼Œä½†ç°æœ‰æ–¹æ³•åœ¨å¤æ‚åŠ¨åŠ›å­¦ä¸‹å­˜åœ¨å±€é™æ€§ã€‚
2. Eik-HiQRLå°†Eikonalæ–¹ç¨‹çº¦æŸçš„QRLèå…¥åˆ†å±‚ç»“æ„ï¼Œåˆ©ç”¨PDEçš„è¿ç»­æ€§æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åˆ†å±‚åˆ†è§£å¤„ç†å¤æ‚åŠ¨åŠ›å­¦ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒEik-HiQRLåœ¨ç¦»çº¿å¯¼èˆªä»»åŠ¡ä¸­è¾¾åˆ°SOTAï¼Œå¹¶åœ¨æ“ä½œä»»åŠ¡ä¸­è¶…è¶ŠQRLï¼Œæ€§èƒ½ä¸æ—¶åºå·®åˆ†æ–¹æ³•ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºEikonalçº¦æŸçš„åˆ†å±‚æ‹Ÿåº¦é‡å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆEik-HiQRLï¼‰ï¼Œæ—¨åœ¨è§£å†³ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ï¼ˆGCRLï¼‰ä¸­å¥–åŠ±è®¾è®¡å›°éš¾çš„é—®é¢˜ã€‚GCRLå°†ä»»åŠ¡å®šä¹‰ä¸ºç›®æ ‡åˆ°è¾¾ï¼Œè€Œéæœ€å¤§åŒ–æ‰‹å·¥è®¾è®¡çš„å¥–åŠ±ä¿¡å·ã€‚æœ€ä¼˜ç›®æ ‡æ¡ä»¶ä»·å€¼å‡½æ•°è‡ªç„¶å½¢æˆæ‹Ÿåº¦é‡ï¼Œä¿ƒä½¿æ‹Ÿåº¦é‡å¼ºåŒ–å­¦ä¹ ï¼ˆQRLï¼‰å°†ä»·å€¼å­¦ä¹ çº¦æŸä¸ºæ‹Ÿåº¦é‡æ˜ å°„ï¼Œå¹¶é€šè¿‡ç¦»æ•£çš„ã€åŸºäºè½¨è¿¹çš„çº¦æŸæ¥åŠ å¼ºå±€éƒ¨ä¸€è‡´æ€§ã€‚Eik-QRLæ˜¯QRLçš„è¿ç»­æ—¶é—´é‡æ„ï¼ŒåŸºäºEikonalåå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰ã€‚è¿™ç§åŸºäºPDEçš„ç»“æ„ä½¿Eik-QRLæ— éœ€è½¨è¿¹ï¼Œä»…éœ€é‡‡æ ·çš„çŠ¶æ€å’Œç›®æ ‡ï¼ŒåŒæ—¶æé«˜äº†åˆ†å¸ƒå¤–æ³›åŒ–èƒ½åŠ›ã€‚è®ºæ–‡æä¾›äº†Eik-QRLçš„ç†è®ºä¿è¯ï¼Œå¹¶æŒ‡å‡ºäº†å¤æ‚åŠ¨åŠ›å­¦ä¸‹çš„å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼ŒEik-HiQRLå°†Eik-QRLé›†æˆåˆ°åˆ†å±‚åˆ†è§£ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEik-HiQRLåœ¨ç¦»çº¿ç›®æ ‡æ¡ä»¶å¯¼èˆªä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå¹¶åœ¨æ“ä½œä»»åŠ¡ä¸­è·å¾—äº†ç›¸å¯¹äºQRLçš„ä¸€è‡´å¢ç›Šï¼Œä¸æ—¶åºå·®åˆ†æ–¹æ³•ç›¸åŒ¹é…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ï¼ˆGCRLï¼‰æ—¨åœ¨é€šè¿‡å­¦ä¹ ä»ä»»æ„çŠ¶æ€åˆ°è¾¾ç›®æ ‡çŠ¶æ€çš„ç­–ç•¥æ¥è§£å†³å¥–åŠ±å‡½æ•°è®¾è®¡å›°éš¾çš„é—®é¢˜ã€‚ç„¶è€Œï¼Œåœ¨å¤æ‚åŠ¨åŠ›å­¦ç¯å¢ƒä¸‹ï¼Œä¼ ç»Ÿçš„QRLæ–¹æ³•ä¾èµ–äºè½¨è¿¹çº¦æŸï¼Œæ³›åŒ–èƒ½åŠ›å—é™ï¼Œéš¾ä»¥é€‚åº”åˆ†å¸ƒå¤–çš„çŠ¶æ€å’Œç›®æ ‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†QRLæ–¹æ³•ä¸Eikonalåå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰ç›¸ç»“åˆï¼Œæ„å»ºè¿ç»­æ—¶é—´çš„ä»·å€¼å‡½æ•°è¡¨ç¤ºï¼Œä»è€Œæ‘†è„±å¯¹è½¨è¿¹çš„ä¾èµ–ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ã€‚åŒæ—¶ï¼Œä¸ºäº†å¤„ç†å¤æ‚åŠ¨åŠ›å­¦ï¼Œå¼•å…¥åˆ†å±‚ç»“æ„ï¼Œå°†ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œåˆ†åˆ«å­¦ä¹ å­ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEik-HiQRLåŒ…å«ä¸¤ä¸ªä¸»è¦å±‚æ¬¡ï¼šé«˜å±‚ç­–ç•¥å’Œä½å±‚ç­–ç•¥ã€‚é«˜å±‚ç­–ç•¥è´Ÿè´£é€‰æ‹©å­ç›®æ ‡ï¼Œä½å±‚ç­–ç•¥è´Ÿè´£åˆ°è¾¾é€‰å®šçš„å­ç›®æ ‡ã€‚Eik-QRLä½œä¸ºä½å±‚ç­–ç•¥çš„å­¦ä¹ ç®—æ³•ï¼Œåˆ©ç”¨Eikonalæ–¹ç¨‹çº¦æŸä»·å€¼å‡½æ•°çš„å­¦ä¹ ï¼Œä½¿å…¶æ»¡è¶³æ‹Ÿåº¦é‡æ€§è´¨ã€‚æ•´ä½“æµç¨‹ä¸ºï¼šé¦–å…ˆï¼Œé«˜å±‚ç­–ç•¥é€‰æ‹©ä¸€ä¸ªå­ç›®æ ‡ï¼›ç„¶åï¼Œä½å±‚ç­–ç•¥åˆ©ç”¨Eik-QRLå­¦ä¹ åˆ°è¾¾è¯¥å­ç›®æ ‡çš„ç­–ç•¥ï¼›é‡å¤ä»¥ä¸Šè¿‡ç¨‹ï¼Œç›´åˆ°åˆ°è¾¾æœ€ç»ˆç›®æ ‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š1) å°†Eikonalæ–¹ç¨‹å¼•å…¥QRLï¼Œæ„å»ºäº†è¿ç»­æ—¶é—´çš„ä»·å€¼å‡½æ•°è¡¨ç¤ºï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›ï¼›2) æå‡ºäº†åˆ†å±‚ç»“æ„ï¼Œå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œé™ä½äº†å­¦ä¹ éš¾åº¦ï¼›3) ç†è®ºä¸Šè¯æ˜äº†Eik-QRLçš„æœ‰æ•ˆæ€§ï¼Œå¹¶åˆ†æäº†å…¶åœ¨å¤æ‚åŠ¨åŠ›å­¦ä¸‹çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šEik-QRLçš„å…³é”®åœ¨äºEikonalæ–¹ç¨‹çš„çº¦æŸã€‚å…·ä½“æ¥è¯´ï¼Œä»·å€¼å‡½æ•°éœ€è¦æ»¡è¶³ä»¥ä¸‹æ–¹ç¨‹ï¼š||âˆ‡V(s, g)||=f(s)ï¼Œå…¶ä¸­V(s, g)æ˜¯ä»çŠ¶æ€såˆ°ç›®æ ‡gçš„ä»·å€¼ï¼Œf(s)æ˜¯çŠ¶æ€sçš„æˆæœ¬å‡½æ•°ã€‚è®ºæ–‡ä½¿ç”¨ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼ä»·å€¼å‡½æ•°ï¼Œå¹¶é€šè¿‡æœ€å°åŒ–Eikonalæ–¹ç¨‹çš„æ®‹å·®æ¥è®­ç»ƒç½‘ç»œã€‚åˆ†å±‚ç»“æ„çš„å…³é”®åœ¨äºå­ç›®æ ‡çš„é€‰æ‹©ç­–ç•¥ï¼Œè®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºä»·å€¼å‡½æ•°çš„å­ç›®æ ‡é€‰æ‹©æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Eik-HiQRLåœ¨ç¦»çº¿ç›®æ ‡æ¡ä»¶å¯¼èˆªä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¶…è¶Šäº†ç°æœ‰çš„QRLæ–¹æ³•ï¼Œå¹¶è¾¾åˆ°äº†ä¸æ—¶åºå·®åˆ†æ–¹æ³•ç›¸å½“çš„æ°´å¹³ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨å¤šä¸ªå¯¼èˆªç¯å¢ƒä¸­ï¼ŒEik-HiQRLçš„æˆåŠŸç‡å’Œæ•ˆç‡å‡ä¼˜äºQRLï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚åœ¨æ“ä½œä»»åŠ¡ä¸­ï¼ŒEik-HiQRLä¹Ÿè¡¨ç°å‡ºäº†ä¸€è‡´çš„å¢ç›Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIç­‰é¢†åŸŸã€‚é€šè¿‡å­¦ä¹ ç›®æ ‡å¯¼å‘çš„ç­–ç•¥ï¼Œæœºå™¨äººå¯ä»¥åœ¨å¤æ‚ç¯å¢ƒä¸­è‡ªä¸»å¯¼èˆªï¼Œå®Œæˆå„ç§ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè®­ç»ƒæ¸¸æˆAIï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£æ¸¸æˆç›®æ ‡ï¼Œå¹¶åˆ¶å®šç›¸åº”çš„ç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Goal-Conditioned Reinforcement Learning (GCRL) mitigates the difficulty of reward design by framing tasks as goal reaching rather than maximizing hand-crafted reward signals. In this setting, the optimal goal-conditioned value function naturally forms a quasimetric, motivating Quasimetric RL (QRL), which constrains value learning to quasimetric mappings and enforces local consistency through discrete, trajectory-based constraints. We propose Eikonal-Constrained Quasimetric RL (Eik-QRL), a continuous-time reformulation of QRL based on the Eikonal Partial Differential Equation (PDE). This PDE-based structure makes Eik-QRL trajectory-free, requiring only sampled states and goals, while improving out-of-distribution generalization. We provide theoretical guarantees for Eik-QRL and identify limitations that arise under complex dynamics. To address these challenges, we introduce Eik-Hierarchical QRL (Eik-HiQRL), which integrates Eik-QRL into a hierarchical decomposition. Empirically, Eik-HiQRL achieves state-of-the-art performance in offline goal-conditioned navigation and yields consistent gains over QRL in manipulation tasks, matching temporal-difference methods.

