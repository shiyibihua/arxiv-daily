---
layout: default
title: TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning
---

# TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.20312" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.20312v1</a>
  <a href="https://arxiv.org/pdf/2512.20312.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.20312v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.20312v1', 'TableGPT-R1: Advancing Tabular Reasoning Through Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saisai Yang, Qingyi Huang, Jing Yuan, Liangyu Zha, Kai Tang, Yuhang Yang, Ning Wang, Yucheng Wei, Liyao Li, Wentao Ye, Hao Chen, Tao Zhang, Junlin Zhou, Haobo Wang, Gang Chen, Junbo Zhao

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-23

**ğŸ”— ä»£ç /é¡¹ç›®**: [HUGGINGFACE](https://huggingface.co/tablegpt/TableGPT-R1)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**TableGPT-R1ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æå‡è¡¨æ ¼æ¨ç†èƒ½åŠ›ï¼Œå®ç°SOTAæ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `æ•°æ®åˆ†æ` `ä»£ç æ‰§è¡Œ` `å¤šæ­¥éª¤æ¨ç†` `å¥–åŠ±å¡‘é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨è¡¨æ ¼æ•°æ®å¤„ç†ä¸­ï¼Œéš¾ä»¥èƒœä»»å¤æ‚æ¨ç†å’Œä»£ç æ‰§è¡Œä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åœ¨å¤šæ­¥éª¤æ¨ç†å’Œé—­ç¯åé¦ˆåœºæ™¯ä¸‹ã€‚
2. TableGPT-R1é€šè¿‡ç³»ç»Ÿæ€§çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œç»“åˆæ•°æ®å·¥ç¨‹ç®¡é“ã€ä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿå’Œå¤šé˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œæå‡è¡¨æ ¼æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒTableGPT-R1åœ¨æƒå¨åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰æ¨¡å‹ï¼Œå¹¶ä¿æŒäº†è‰¯å¥½çš„é€šç”¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡¨æ ¼æ•°æ®æ˜¯ç°ä»£æ•°æ®åˆ†æå’Œç§‘å­¦ç ”ç©¶çš„åŸºçŸ³ã€‚è™½ç„¶é€šè¿‡ç›‘ç£å¾®è°ƒ(SFT)çš„å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ˜¾è‘—æ”¹å–„äº†ä¸æ­¤ç±»ç»“æ„åŒ–æ•°æ®çš„è‡ªç„¶è¯­è¨€äº¤äº’ï¼Œä½†å®ƒä»¬åœ¨å¤„ç†çœŸå®ä¸–ç•Œè¡¨æ ¼ä»»åŠ¡æ‰€éœ€çš„å¤æ‚ã€å¤šæ­¥éª¤æ¨ç†å’Œå¼ºå¤§çš„ä»£ç æ‰§è¡Œæ–¹é¢å¾€å¾€è¡¨ç°ä¸è¶³ã€‚å¼ºåŒ–å­¦ä¹ (RL)ä¸ºå¢å¼ºè¿™äº›èƒ½åŠ›æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„é€”å¾„ï¼Œä½†å…¶åœ¨è¡¨æ ¼é¢†åŸŸçš„åº”ç”¨é¢ä¸´ä¸‰ä¸ªå…³é”®éšœç¢ï¼šç¼ºä¹é«˜è´¨é‡çš„agentè½¨è¿¹ï¼Œè¿™äº›è½¨è¿¹å…·æœ‰åœ¨ä¸åŒè¡¨æ ¼ç»“æ„ä¸Šçš„é—­ç¯ä»£ç æ‰§è¡Œå’Œç¯å¢ƒåé¦ˆï¼›åé¦ˆä¿¡å·çš„æç«¯å¼‚è´¨æ€§ï¼ŒèŒƒå›´ä»åˆšæ€§çš„SQLæ‰§è¡Œåˆ°å¼€æ”¾å¼çš„æ•°æ®è§£é‡Šï¼›ä»¥åŠåœ¨å‚ç›´ä¸“ä¸šåŒ–è¿‡ç¨‹ä¸­ç¾éš¾æ€§åœ°é—å¿˜ä¸€èˆ¬çŸ¥è¯†çš„é£é™©ã€‚ä¸ºäº†å…‹æœè¿™äº›æŒ‘æˆ˜å¹¶è§£é”å¯¹å¤æ‚è¡¨æ ¼çš„é«˜çº§æ¨ç†ï¼Œæˆ‘ä»¬å¼•å…¥äº†TableGPT-R1ï¼Œè¿™æ˜¯ä¸€ä¸ªå»ºç«‹åœ¨ç³»ç»ŸRLæ¡†æ¶ä¸Šçš„ä¸“ç”¨è¡¨æ ¼æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ•´åˆäº†ä¸€ä¸ªå…¨é¢çš„æ•°æ®å·¥ç¨‹ç®¡é“ï¼Œè¯¥ç®¡é“åˆæˆäº†éš¾åº¦åˆ†å±‚çš„agentè½¨è¿¹ï¼Œç”¨äºç›‘ç£å¯¹é½å’ŒRL rolloutï¼›ä¸€ä¸ªä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿå°†åŸºäºè§„åˆ™çš„éªŒè¯ä¸æ ‡å‡†æ³¨å…¥çš„å¥–åŠ±æ¨¡å‹ç›¸ç»“åˆï¼Œå¹¶ç»“åˆäº†è¿‡ç¨‹çº§åˆ«çš„æ­¥éª¤å¥–åŠ±å¡‘é€ å’Œè¡Œä¸ºæ­£åˆ™åŒ–ï¼›ä»¥åŠä¸€ä¸ªå¤šé˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨ä¸“é—¨ä»äº‹è¡¨æ ¼ç‰¹å®šä»»åŠ¡ä¹‹å‰é€æ­¥ç¨³å®šæ¨ç†ã€‚å¹¿æ³›çš„è¯„ä¼°è¡¨æ˜ï¼ŒTableGPT-R1åœ¨æƒå¨åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼ŒåŒæ—¶ä¿ç•™äº†å¼ºå¤§çš„é€šç”¨èƒ½åŠ›ã€‚æˆ‘ä»¬çš„æ¨¡å‹å¯åœ¨https://huggingface.co/tablegpt/TableGPT-R1ä¸Šæ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†è¡¨æ ¼æ•°æ®æ—¶ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦å¤æ‚æ¨ç†å’Œä»£ç æ‰§è¡Œçš„ä»»åŠ¡ä¸­ï¼Œè¡¨ç°å‡ºæ˜æ˜¾çš„ä¸è¶³ã€‚å®ƒä»¬éš¾ä»¥å¤„ç†å¤šæ­¥éª¤æ¨ç†ã€é—­ç¯åé¦ˆä»¥åŠå¼‚æ„çš„åé¦ˆä¿¡å·ï¼Œå¹¶ä¸”å®¹æ˜“åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿‡æ‹Ÿåˆï¼Œå¯¼è‡´é€šç”¨çŸ¥è¯†çš„é—å¿˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šTableGPT-R1çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (RL)æ¥æå‡æ¨¡å‹åœ¨è¡¨æ ¼æ•°æ®ä¸Šçš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±æœºåˆ¶å’Œè®­ç»ƒæµç¨‹ï¼Œå¼•å¯¼æ¨¡å‹å­¦ä¹ å¦‚ä½•æœ‰æ•ˆåœ°æ‰§è¡Œä»£ç ã€ç†è§£è¡¨æ ¼æ•°æ®ï¼Œå¹¶è¿›è¡Œå¤šæ­¥éª¤æ¨ç†ã€‚åŒæ—¶ï¼Œé‡‡ç”¨å¤šé˜¶æ®µè®­ç»ƒç­–ç•¥ï¼Œé¿å…æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿‡æ‹Ÿåˆï¼Œä¿æŒå…¶é€šç”¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTableGPT-R1çš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ•°æ®å·¥ç¨‹ç®¡é“ï¼šç”¨äºç”Ÿæˆéš¾åº¦åˆ†å±‚çš„agentè½¨è¿¹ï¼ŒåŒ…æ‹¬ç›‘ç£å¯¹é½å’ŒRL rolloutæ‰€éœ€çš„æ•°æ®ã€‚2) ä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿï¼šç»“åˆåŸºäºè§„åˆ™çš„éªŒè¯å’Œæ ‡å‡†æ³¨å…¥çš„å¥–åŠ±æ¨¡å‹ï¼Œå¹¶è¿›è¡Œè¿‡ç¨‹çº§åˆ«çš„æ­¥éª¤å¥–åŠ±å¡‘é€ å’Œè¡Œä¸ºæ­£åˆ™åŒ–ã€‚3) å¤šé˜¶æ®µè®­ç»ƒæ¡†æ¶ï¼šé€æ­¥ç¨³å®šæ¨ç†èƒ½åŠ›ï¼Œç„¶åå†ä¸“æ³¨äºè¡¨æ ¼ç‰¹å®šä»»åŠ¡çš„è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šTableGPT-R1çš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç³»ç»Ÿæ€§çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è§£å†³è¡¨æ ¼æ•°æ®å¤„ç†ä¸­çš„ä¸‰ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šç¼ºä¹é«˜è´¨é‡çš„agentè½¨è¿¹ã€åé¦ˆä¿¡å·çš„å¼‚è´¨æ€§ä»¥åŠé€šç”¨çŸ¥è¯†çš„é—å¿˜ã€‚é€šè¿‡æ•°æ®å·¥ç¨‹ç®¡é“ç”Ÿæˆé«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ï¼Œé€šè¿‡ä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿå¼•å¯¼æ¨¡å‹å­¦ä¹ æ­£ç¡®çš„è¡Œä¸ºï¼Œå¹¶é€šè¿‡å¤šé˜¶æ®µè®­ç»ƒæ¡†æ¶ä¿æŒæ¨¡å‹çš„é€šç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®å·¥ç¨‹ç®¡é“ä¸­ï¼Œé‡‡ç”¨äº†éš¾åº¦åˆ†å±‚çš„ç­–ç•¥ï¼Œé€æ­¥å¢åŠ è®­ç»ƒæ•°æ®çš„éš¾åº¦ï¼Œä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨ä»»åŠ¡è‡ªé€‚åº”å¥–åŠ±ç³»ç»Ÿä¸­ï¼Œç»“åˆäº†åŸºäºè§„åˆ™çš„éªŒè¯å’Œæ ‡å‡†æ³¨å…¥çš„å¥–åŠ±æ¨¡å‹ï¼Œä»¥æä¾›æ›´å‡†ç¡®çš„åé¦ˆä¿¡å·ã€‚åœ¨å¤šé˜¶æ®µè®­ç»ƒæ¡†æ¶ä¸­ï¼Œé¦–å…ˆè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥æé«˜æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ï¼Œç„¶åå†è¿›è¡Œå¾®è°ƒï¼Œä»¥é€‚åº”ç‰¹å®šçš„è¡¨æ ¼ä»»åŠ¡ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20312v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20312v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.20312v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

TableGPT-R1åœ¨å¤šä¸ªæƒå¨è¡¨æ ¼æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†SOTAæ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ¨¡å‹ã€‚å…·ä½“æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†å±•ç¤ºã€‚è¯¥æ¨¡å‹åœ¨æå‡è¡¨æ ¼æ¨ç†èƒ½åŠ›çš„åŒæ—¶ï¼Œè¿˜ä¿æŒäº†è‰¯å¥½çš„é€šç”¨èƒ½åŠ›ï¼Œé¿å…äº†åœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

TableGPT-R1åœ¨æ•°æ®åˆ†æã€å•†ä¸šæ™ºèƒ½ã€ç§‘å­¦ç ”ç©¶ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´é«˜æ•ˆåœ°ä»è¡¨æ ¼æ•°æ®ä¸­æå–ä¿¡æ¯ã€è¿›è¡Œå†³ç­–åˆ†æï¼Œå¹¶æ”¯æŒè‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆç­‰ä»»åŠ¡ã€‚è¯¥ç ”ç©¶çš„æˆæœæœ‰æœ›æ¨åŠ¨è¡¨æ ¼æ•°æ®å¤„ç†æŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºå„è¡Œä¸šå¸¦æ¥å®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tabular data serves as the backbone of modern data analysis and scientific research. While Large Language Models (LLMs) fine-tuned via Supervised Fine-Tuning (SFT) have significantly improved natural language interaction with such structured data, they often fall short in handling the complex, multi-step reasoning and robust code execution required for real-world table tasks. Reinforcement Learning (RL) offers a promising avenue to enhance these capabilities, yet its application in the tabular domain faces three critical hurdles: the scarcity of high-quality agentic trajectories with closed-loop code execution and environment feedback on diverse table structures, the extreme heterogeneity of feedback signals ranging from rigid SQL execution to open-ended data interpretation, and the risk of catastrophic forgetting of general knowledge during vertical specialization. To overcome these challenges and unlock advanced reasoning on complex tables, we introduce \textbf{TableGPT-R1}, a specialized tabular model built on a systematic RL framework. Our approach integrates a comprehensive data engineering pipeline that synthesizes difficulty-stratified agentic trajectories for both supervised alignment and RL rollouts, a task-adaptive reward system that combines rule-based verification with a criteria-injected reward model and incorporates process-level step reward shaping with behavioral regularization, and a multi-stage training framework that progressively stabilizes reasoning before specializing in table-specific tasks. Extensive evaluations demonstrate that TableGPT-R1 achieves state-of-the-art performance on authoritative benchmarks, significantly outperforming baseline models while retaining robust general capabilities. Our model is available at https://huggingface.co/tablegpt/TableGPT-R1.

