---
layout: default
title: MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation
---

# MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08137" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08137v1</a>
  <a href="https://arxiv.org/pdf/2508.08137.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08137v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08137v1', 'MuaLLM: A Multimodal Large Language Model Agent for Circuit Design Assistance with Hybrid Contextual Retrieval-Augmented Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Pravallika Abbineni, Saoud Aldowaish, Colin Liechty, Soroosh Noorzad, Ali Ghazizadeh, Morteza Fayazi

**åˆ†ç±»**: cs.LG, cs.AI, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMuaLLMä»¥è§£å†³ç”µè·¯è®¾è®¡æ–‡çŒ®æ£€ç´¢ä¸ç”Ÿæˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç”µè·¯è®¾è®¡` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `æ™ºèƒ½æœç´¢å·¥å…·` `å®æ—¶æ•°æ®åº“æ›´æ–°` `æ¨ç†èƒ½åŠ›` `æ–‡çŒ®ç»¼è¿°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç”µè·¯è®¾è®¡æ–¹æ³•é¢ä¸´æ–‡çŒ®ç»¼è¿°å›°éš¾ï¼Œä¸»è¦ç”±äºç ”ç©¶å¿«é€Ÿå¢é•¿å’Œæ•°æ®è¡¨ç¤ºä¸ä¸€è‡´ã€‚
2. MuaLLMé€šè¿‡æ··åˆæ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶å’Œè‡ªé€‚åº”å‘é‡æ•°æ®åº“ï¼Œæä¾›é«˜æ•ˆçš„ç”µè·¯è®¾è®¡æ”¯æŒã€‚
3. åœ¨RAG-250å’ŒReas-100æ•°æ®é›†ä¸Šï¼ŒMuaLLMåˆ†åˆ«å®ç°äº†90.1%çš„å¬å›ç‡å’Œ86.8%çš„å‡†ç¡®ç‡ï¼Œè¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿›è¡Œå…¨é¢çš„æ–‡çŒ®ç»¼è¿°å¯¹äºæ¨åŠ¨ç”µè·¯è®¾è®¡æ–¹æ³•è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå¿«é€Ÿæ¶Œç°çš„å‰æ²¿ç ”ç©¶ã€ä¸ä¸€è‡´çš„æ•°æ®è¡¨ç¤ºä»¥åŠä¼˜åŒ–ç”µè·¯è®¾è®¡ç›®æ ‡çš„å¤æ‚æ€§ä½¿è¿™ä¸€ä»»åŠ¡å˜å¾—æå…·æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æå‡ºäº†MuaLLMï¼Œä¸€ä¸ªå¼€æºçš„å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œæ—¨åœ¨ä¸ºç”µè·¯è®¾è®¡æä¾›æ”¯æŒã€‚MuaLLMé›†æˆäº†æ··åˆçš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œå¹¶ç»“åˆäº†ç”µè·¯è®¾è®¡ç ”ç©¶è®ºæ–‡çš„è‡ªé€‚åº”å‘é‡æ•°æ®åº“ã€‚ä¸ä¼ ç»Ÿå¤§å‹è¯­è¨€æ¨¡å‹ä¸åŒï¼ŒMuaLLMé‡‡ç”¨äº†Reason + Actï¼ˆReActï¼‰å·¥ä½œæµï¼Œæ”¯æŒè¿­ä»£æ¨ç†ã€ç›®æ ‡è®¾å®šå’Œå¤šæ­¥éª¤ä¿¡æ¯æ£€ç´¢ã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå¤„ç†æ–‡æœ¬å’Œè§†è§‰æ•°æ®ï¼Œæä¾›åŸºäºç”µè·¯æ–‡çŒ®çš„åˆç†å“åº”ã€‚MuaLLMåœ¨æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼Œæˆæœ¬é™ä½è‡³ä¼ ç»Ÿæ¨¡å‹çš„10å€ï¼Œé€Ÿåº¦æå‡1.6å€ï¼ŒåŒæ—¶ä¿æŒç›¸åŒçš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç”µè·¯è®¾è®¡é¢†åŸŸä¸­ï¼Œæ–‡çŒ®ç»¼è¿°çš„å¤æ‚æ€§å’Œæ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¿«é€Ÿå¢é•¿çš„ç ”ç©¶æ–‡çŒ®æ—¶ï¼Œå¸¸å¸¸é¢ä¸´æ•°æ®è¡¨ç¤ºä¸ä¸€è‡´å’Œä¸Šä¸‹æ–‡é™åˆ¶çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMuaLLMé€šè¿‡å¼•å…¥æ··åˆæ£€ç´¢å¢å¼ºç”Ÿæˆæ¡†æ¶ï¼Œç»“åˆè‡ªé€‚åº”å‘é‡æ•°æ®åº“ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°è¿›è¡Œä¿¡æ¯æ£€ç´¢å’Œç”Ÿæˆã€‚å…¶Reason + Actå·¥ä½œæµè®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿè¿›è¡Œè¿­ä»£æ¨ç†å’Œå¤šæ­¥éª¤ä¿¡æ¯å¤„ç†ï¼Œä»è€Œæå‡äº†ç”µè·¯è®¾è®¡çš„æ”¯æŒèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMuaLLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ£€ç´¢æ¨¡å—ã€æ¨ç†æ¨¡å—å’Œç”Ÿæˆæ¨¡å—ã€‚æ•°æ®æ£€ç´¢æ¨¡å—è´Ÿè´£ä»æ•°æ®åº“å’Œäº’è”ç½‘è·å–ç›¸å…³æ–‡çŒ®ï¼Œæ¨ç†æ¨¡å—è¿›è¡Œå¤šæ­¥éª¤çš„é€»è¾‘æ¨ç†ï¼Œç”Ÿæˆæ¨¡å—åˆ™è¾“å‡ºåŸºäºæ–‡çŒ®çš„åˆç†ç­”æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šMuaLLMçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†æ£€ç´¢ä¸æ¨ç†è§£è€¦ï¼Œå…è®¸åœ¨ä»»æ„è§„æ¨¡çš„æ–‡çŒ®åº“ä¸Šè¿›è¡Œæ‰©å±•æ¨ç†ã€‚è¿™ä¸€è®¾è®¡çªç ´äº†ä¼ ç»Ÿå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡é•¿åº¦ä¸Šçš„é™åˆ¶ï¼Œæ˜¾è‘—æé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šMuaLLMé‡‡ç”¨äº†è‡ªé€‚åº”å‘é‡æ•°æ®åº“ï¼Œæ”¯æŒå®æ—¶æ›´æ–°å’Œæ™ºèƒ½æœç´¢å·¥å…·ï¼Œç¡®ä¿æ–‡çŒ®æ£€ç´¢çš„åŠæ—¶æ€§å’Œç›¸å…³æ€§ã€‚åŒæ—¶ï¼Œæ¨¡å‹åœ¨æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ï¼Œæˆæœ¬é™ä½è‡³ä¼ ç»Ÿæ¨¡å‹çš„10å€ï¼Œé€Ÿåº¦æå‡1.6å€ã€‚å…¶æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”å¤šæ¨¡æ€æ•°æ®å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MuaLLMåœ¨RAG-250æ•°æ®é›†ä¸Šå®ç°äº†90.1%çš„å¬å›ç‡ï¼Œåœ¨Reas-100æ•°æ®é›†ä¸Šè¾¾åˆ°äº†86.8%çš„å‡†ç¡®ç‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ä¿¡æ¯æ£€ç´¢å’Œå¤šæ­¥éª¤æ¨ç†æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒMuaLLMåœ¨æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹æˆæœ¬é™ä½è‡³10å€ï¼Œé€Ÿåº¦æå‡1.6å€ï¼Œä¸”ä¿æŒç›¸åŒçš„å‡†ç¡®æ€§ï¼Œå±•ç°äº†æ˜¾è‘—çš„æ•ˆç‡ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MuaLLMåœ¨ç”µè·¯è®¾è®¡é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿå¸®åŠ©å·¥ç¨‹å¸ˆå¿«é€Ÿè·å–ç›¸å…³æ–‡çŒ®å’Œè®¾è®¡å»ºè®®ï¼Œæå‡è®¾è®¡æ•ˆç‡ã€‚å…¶å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›ä½¿å¾—æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯çš„ç»“åˆåˆ†ææˆä¸ºå¯èƒ½ï¼Œæœªæ¥å¯æ‰©å±•è‡³å…¶ä»–å·¥ç¨‹é¢†åŸŸçš„è®¾è®¡æ”¯æŒã€‚è¯¥ç³»ç»Ÿçš„å®æ—¶æ›´æ–°èƒ½åŠ›ä¹Ÿä¸ºæŒç»­çš„ç ”ç©¶æä¾›äº†é‡è¦æ”¯æŒï¼Œæ¨åŠ¨ç”µè·¯è®¾è®¡æ–¹æ³•çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Conducting a comprehensive literature review is crucial for advancing circuit design methodologies. However, the rapid influx of state-of-the-art research, inconsistent data representation, and the complexity of optimizing circuit design objectives make this task significantly challenging. In this paper, we propose MuaLLM, an open-source multimodal Large Language Model (LLM) agent for circuit design assistance that integrates a hybrid Retrieval-Augmented Generation (RAG) framework with an adaptive vector database of circuit design research papers. Unlike conventional LLMs, the MuaLLM agent employs a Reason + Act (ReAct) workflow for iterative reasoning, goal-setting, and multi-step information retrieval. It functions as a question-answering design assistant, capable of interpreting complex queries and providing reasoned responses grounded in circuit literature. Its multimodal capabilities enable processing of both textual and visual data, facilitating more efficient and comprehensive analysis. The system dynamically adapts using intelligent search tools, automated document retrieval from the internet, and real-time database updates. Unlike conventional approaches constrained by model context limits, MuaLLM decouples retrieval from inference, enabling scalable reasoning over arbitrarily large corpora. At the maximum context length supported by standard LLMs, MuaLLM remains up to 10x less costly and 1.6x faster while maintaining the same accuracy. This allows rapid, no-human-in-the-loop database generation, overcoming the bottleneck of simulation-based dataset creation for circuits. To evaluate MuaLLM, we introduce two custom datasets: RAG-250, targeting retrieval and citation performance, and Reasoning-100 (Reas-100), focused on multistep reasoning in circuit design. MuaLLM achieves 90.1% recall on RAG-250, and 86.8% accuracy on Reas-100.

