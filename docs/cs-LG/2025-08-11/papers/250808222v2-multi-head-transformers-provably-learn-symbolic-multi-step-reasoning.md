---
layout: default
title: Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent
---

# Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08222" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08222v2</a>
  <a href="https://arxiv.org/pdf/2508.08222.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08222v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08222v2', 'Multi-head Transformers Provably Learn Symbolic Multi-step Reasoning via Gradient Descent')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tong Yang, Yu Huang, Yingbin Liang, Yuejie Chi

**åˆ†ç±»**: cs.LG, cs.AI, cs.IT, math.OC, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-08-11 (æ›´æ–°: 2025-12-07)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šå¤´å˜æ¢å™¨ä»¥è§£å†³ç¬¦å·å¤šæ­¥æ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å˜æ¢å™¨` `å¤šæ­¥æ¨ç†` `ç¬¦å·æ¨ç†` `é“¾å¼æ€ç»´` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å˜æ¢å™¨åœ¨å¤šæ­¥æ¨ç†èƒ½åŠ›çš„è·å¾—æœºåˆ¶ä¸Šç¼ºä¹ç†è®ºæ”¯æŒï¼Œå°¤å…¶æ˜¯åœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä¸€ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§é€šè¿‡é“¾å¼æ€ç»´è¿‡ç¨‹æ¥è§£å†³ç¬¦å·å¤šæ­¥æ¨ç†é—®é¢˜çš„æ–¹æ³•ï¼Œåˆ†æäº†åå‘å’Œå‰å‘æ¨ç†ä»»åŠ¡çš„åŠ¨æ€ç‰¹æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡è®­ç»ƒçš„å˜æ¢å™¨èƒ½å¤Ÿæœ‰æ•ˆè§£å†³æœªè§è¿‡çš„æ ‘ç»“æ„é—®é¢˜ï¼Œå¹¶åœ¨æ¨ç†èƒ½åŠ›ä¸Šè¶…è¶Šä¼ ç»Ÿæ·±åº¦æ¶æ„ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å˜æ¢å™¨åœ¨å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå“è¶Šçš„èƒ½åŠ›ï¼Œä½†å¯¹å…¶è®­ç»ƒè¿‡ç¨‹ä¸­å¦‚ä½•è·å¾—è¿™äº›èƒ½åŠ›çš„ç†è®ºç†è§£ä»ç„¶æœ‰é™ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†å˜æ¢å™¨å¦‚ä½•é€šè¿‡æ€ç»´é“¾è¿‡ç¨‹è§£å†³ç¬¦å·å¤šæ­¥æ¨ç†é—®é¢˜ï¼Œé‡ç‚¹åˆ†æäº†æ ‘ç»“æ„ä¸­çš„è·¯å¾„å¯»æ‰¾ä»»åŠ¡ã€‚æˆ‘ä»¬ç ”ç©¶äº†ä¸¤ä¸ªç›¸äº’å…³è”çš„ä»»åŠ¡ï¼šåå‘æ¨ç†ä»»åŠ¡å’Œæ›´å¤æ‚çš„å‰å‘æ¨ç†ä»»åŠ¡ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œç»è¿‡è®­ç»ƒçš„ä¸€å±‚å˜æ¢å™¨èƒ½å¤Ÿè¯æ˜æ€§åœ°è§£å†³è¿™ä¸¤ä¸ªä»»åŠ¡ï¼Œå¹¶å¯¹æœªè§è¿‡çš„æ ‘å…·æœ‰æ³›åŒ–ä¿è¯ã€‚æˆ‘ä»¬çš„å¤šé˜¶æ®µè®­ç»ƒåŠ¨æ€æ­ç¤ºäº†ä¸åŒæ³¨æ„åŠ›å¤´å¦‚ä½•è‡ªä¸»åœ°ä¸“ä¸šåŒ–å’Œåè°ƒï¼Œä»¥åœ¨å•ä¸€è‡ªå›å½’è·¯å¾„ä¸­è§£å†³ä¸¤ä¸ªå­ä»»åŠ¡ã€‚è¿™äº›ç»“æœä¸ºè®­ç»ƒå˜æ¢å™¨å¦‚ä½•å®ç°é¡ºåºç®—æ³•ç¨‹åºæä¾›äº†æœºåˆ¶è§£é‡Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å˜æ¢å™¨åœ¨ç¬¦å·å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­çš„å­¦ä¹ æœºåˆ¶ï¼Œç°æœ‰æ–¹æ³•åœ¨ç†è®ºåˆ†æå’Œæ³›åŒ–èƒ½åŠ›ä¸Šå­˜åœ¨ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡åˆ†æå˜æ¢å™¨åœ¨åå‘å’Œå‰å‘æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶å¦‚ä½•é€šè¿‡é“¾å¼æ€ç»´è¿‡ç¨‹å®ç°æ¨ç†èƒ½åŠ›çš„æå‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šåå‘æ¨ç†æ¨¡å—å’Œå‰å‘æ¨ç†æ¨¡å—ï¼Œå‰è€…è¾“å‡ºä»ç›®æ ‡èŠ‚ç‚¹åˆ°æ ¹èŠ‚ç‚¹çš„è·¯å¾„ï¼Œåè€…åˆ™å®ç°ä¸¤é˜¶æ®µæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡å¤šé˜¶æ®µè®­ç»ƒåŠ¨æ€ï¼Œå±•ç¤ºäº†ä¸åŒæ³¨æ„åŠ›å¤´å¦‚ä½•è‡ªä¸»åè°ƒä»¥è§£å†³å¤æ‚æ¨ç†ä»»åŠ¡ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç½‘ç»œç»“æ„ä¸Šï¼Œé‡‡ç”¨äº†ä¸€å±‚å˜æ¢å™¨ï¼Œå¹¶è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åå‘å’Œå‰å‘æ¨ç†ä»»åŠ¡çš„å­¦ä¹ è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œç»è¿‡è®­ç»ƒçš„å˜æ¢å™¨åœ¨åå‘å’Œå‰å‘æ¨ç†ä»»åŠ¡ä¸Šå‡èƒ½è¾¾åˆ°é«˜å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨æœªè§è¿‡çš„æ ‘ç»“æ„ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œè‡ªåŠ¨æ¨ç†ç­‰ã€‚é€šè¿‡æå‡å˜æ¢å™¨åœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œæœªæ¥å¯ä»¥æ¨åŠ¨æ›´å¤æ‚çš„æ¨ç†ç³»ç»Ÿçš„å‘å±•ï¼Œå¢å¼ºäººå·¥æ™ºèƒ½åœ¨å†³ç­–æ”¯æŒå’Œé—®é¢˜è§£å†³ä¸­çš„èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Transformers have demonstrated remarkable capabilities in multi-step reasoning tasks. However, understandings of the underlying mechanisms by which they acquire these abilities through training remain limited, particularly from a theoretical standpoint. This work investigates how transformers learn to solve symbolic multi-step reasoning problems through chain-of-thought processes, focusing on path-finding in trees. We analyze two intertwined tasks: a backward reasoning task, where the model outputs a path from a goal node to the root, and a more complex forward reasoning task, where the model implements two-stage reasoning by first identifying the goal-to-root path and then reversing it to produce the root-to-goal path. Our theoretical analysis, grounded in the dynamics of gradient descent, shows that trained one-layer transformers can provably solve both tasks with generalization guarantees to unseen trees. In particular, our multi-phase training dynamics for forward reasoning elucidate how different attention heads learn to specialize and coordinate autonomously to solve the two subtasks in a single autoregressive path. These results provide a mechanistic explanation of how trained transformers can implement sequential algorithmic procedures. Moreover, they offer insights into the emergence of reasoning abilities, suggesting that when tasks are structured to take intermediate chain-of-thought steps, even shallow multi-head transformers can effectively solve problems that would otherwise require deeper architectures.

