---
layout: default
title: Leveraging Reinforcement Learning, Genetic Algorithms and Transformers for background determination in particle physics
---

# Leveraging Reinforcement Learning, Genetic Algorithms and Transformers for background determination in particle physics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14894" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14894v2</a>
  <a href="https://arxiv.org/pdf/2509.14894.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14894v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14894v2', 'Leveraging Reinforcement Learning, Genetic Algorithms and Transformers for background determination in particle physics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guillermo Hijano Mendizabal, Davide Lancierini, Alex Marshall, Andrea Mauri, Patrick Haworth Owen, Mitesh Patel, Konstantinos Petridis, Shah Rukh Qasim, Nicola Serra, William Sutcliffe, Hanae Tilquin

**åˆ†ç±»**: cs.LG, hep-ex

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-11-20)

**å¤‡æ³¨**: 34 pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ã€é—ä¼ ç®—æ³•å’ŒTransformerè§£å†³ç²’å­ç‰©ç†èƒŒæ™¯ç¡®å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `é—ä¼ ç®—æ³•` `Transformer` `ç²’å­ç‰©ç†` `èƒŒæ™¯ç¡®å®š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¾å¼ºå­è¡°å˜ç ”ç©¶ä¸­ï¼ŒèƒŒæ™¯å™ªå£°è¯†åˆ«ä¾èµ–ä¸“å®¶ç»éªŒï¼Œç¼ºä¹ç³»ç»Ÿæ–¹æ³•ï¼Œä¸”è®¡ç®—èµ„æºæœ‰é™ã€‚
2. æå‡ºç»“åˆå¼ºåŒ–å­¦ä¹ å’Œé—ä¼ ç®—æ³•çš„æ–°æ–¹æ³•ï¼Œç³»ç»Ÿæ€§ç¡®å®šå…³é”®èƒŒæ™¯ï¼Œå¹¶ç”¨Transformerå¤„ç†è¡°å˜åºåˆ—ã€‚
3. è¯¥æ–¹æ³•é€‚ç”¨äºç¾å¼ºå­ç‰©ç†ï¼Œå¹¶å¯æ¨å¹¿åˆ°å…¶ä»–ç²’å­ç‰©ç†æµ‹é‡ï¼Œä¸ºèƒŒæ™¯ç¡®å®šæä¾›æ–°æ€è·¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç ”ç©¶ç¾å¼ºå­è¡°å˜æ—¶ï¼Œç”±äºå­˜åœ¨å¤§é‡å…·æœ‰ç›¸ä¼¼æœ«æ€çš„ä¸åŒè¡°å˜é€šé“ï¼Œå®éªŒç ”ç©¶é¢ä¸´ç€å„ç§èƒŒæ™¯çš„é‡å¤§æŒ‘æˆ˜ã€‚å¯¹äºç‰¹å®šçš„ä¿¡å·è¡°å˜ï¼Œç¡®å®šæœ€ç›¸å…³çš„èƒŒæ™¯è¿‡ç¨‹éœ€è¦å¯¹æœ«æ€ç²’å­ã€æ½œåœ¨çš„è¯¯è¯†åˆ«å’Œè¿åŠ¨å­¦é‡å è¿›è¡Œè¯¦ç»†åˆ†æã€‚ç”±äºè®¡ç®—èµ„æºçš„é™åˆ¶ï¼Œè¿™ç§åˆ†æé€šå¸¸ä»…é™äºæ¨¡æ‹Ÿæœ€ç›¸å…³çš„èƒŒæ™¯ã€‚æ­¤å¤–ï¼Œè¿™ä¸ªè¿‡ç¨‹é€šå¸¸ä¾èµ–äºç‰©ç†å­¦å®¶çš„ç›´è§‰å’Œä¸“ä¸šçŸ¥è¯†ï¼Œç¼ºä¹ç³»ç»Ÿæ€§çš„æ–¹æ³•ã€‚æœ¬æ–‡æ—¨åœ¨æå‡ºä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç³»ç»Ÿåœ°ç¡®å®šå½±å“ç¾å¼ºå­è¡°å˜æµ‹é‡çš„å…³é”®èƒŒæ™¯ï¼Œä»è€Œå…‹æœä¸Šè¿°æŒ‘æˆ˜ã€‚è™½ç„¶ç¾å¼ºå­ç‰©ç†å­¦æ˜¯æœ¬ç ”ç©¶çš„æ¡ˆä¾‹ï¼Œä½†æ‰€æå‡ºçš„ç­–ç•¥å¯ä»¥å¹¿æ³›åœ°åº”ç”¨äºå…¶ä»–ç±»å‹çš„ç²’å­ç‰©ç†æµ‹é‡ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜ä»‹ç»äº†ä¸€ç§æ–°çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•åˆ©ç”¨RLå’Œé—ä¼ ç®—æ³•ï¼ˆGAï¼‰ä¹‹é—´çš„ååŒä½œç”¨ï¼Œç”¨äºå…·æœ‰é«˜åº¦ç¨€ç–å¥–åŠ±å’Œå¤§å‹è½¨è¿¹ç©ºé—´çš„ç¯å¢ƒã€‚è¯¥ç­–ç•¥åˆ©ç”¨GAæœ‰æ•ˆåœ°æ¢ç´¢è½¨è¿¹ç©ºé—´å¹¶è¯†åˆ«æˆåŠŸçš„è½¨è¿¹ï¼Œè¿™äº›è½¨è¿¹ç”¨äºæŒ‡å¯¼RLä»£ç†çš„è®­ç»ƒã€‚æˆ‘ä»¬çš„æ–¹æ³•è¿˜åŒ…å«ä¸€ä¸ªç”¨äºRLä»£ç†çš„Transformeræ¶æ„ï¼Œä»¥å¤„ç†è¡¨ç¤ºè¡°å˜çš„tokenåºåˆ—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç²’å­ç‰©ç†å®éªŒä¸­ï¼Œç‰¹åˆ«æ˜¯ç¾å¼ºå­è¡°å˜ç ”ç©¶ä¸­ï¼ŒèƒŒæ™¯å™ªå£°éš¾ä»¥ç³»ç»Ÿæ€§ç¡®å®šçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–ç‰©ç†å­¦å®¶çš„ç»éªŒå’Œç›´è§‰ï¼Œç¼ºä¹è‡ªåŠ¨åŒ–å’Œç³»ç»Ÿæ€§ï¼Œä¸”è®¡ç®—èµ„æºé™åˆ¶å¯¼è‡´æ— æ³•æ¨¡æ‹Ÿæ‰€æœ‰å¯èƒ½çš„èƒŒæ™¯è¿‡ç¨‹ï¼Œå½±å“äº†ä¿¡å·çš„å‡†ç¡®æå–ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥å­¦ä¹ å¦‚ä½•è¯†åˆ«å’Œç¡®å®šå…³é”®çš„èƒŒæ™¯è¿‡ç¨‹ã€‚é€šè¿‡å°†èƒŒæ™¯ç¡®å®šé—®é¢˜å»ºæ¨¡ä¸ºä¸€ä¸ªåºåˆ—å†³ç­–é—®é¢˜ï¼ŒRL agent å¯ä»¥å­¦ä¹ åœ¨å¤æ‚çš„å®éªŒç¯å¢ƒä¸­æ‰¾åˆ°æœ€ä½³çš„èƒŒæ™¯è¯†åˆ«ç­–ç•¥ã€‚åŒæ—¶ï¼Œç»“åˆé—ä¼ ç®—æ³•ï¼ˆGAï¼‰æ¥åŠ é€ŸRL agentçš„è®­ç»ƒï¼Œå°¤å…¶æ˜¯åœ¨å¥–åŠ±ç¨€ç–çš„æƒ…å†µä¸‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **ç¯å¢ƒå»ºæ¨¡**ï¼šå°†ç²’å­ç‰©ç†å®éªŒæ•°æ®è½¬åŒ–ä¸ºRLç¯å¢ƒï¼ŒåŒ…æ‹¬çŠ¶æ€ç©ºé—´ã€åŠ¨ä½œç©ºé—´å’Œå¥–åŠ±å‡½æ•°ã€‚çŠ¶æ€ç©ºé—´å¯èƒ½åŒ…æ‹¬æœ«æ€ç²’å­çš„ä¿¡æ¯ï¼ŒåŠ¨ä½œç©ºé—´åŒ…æ‹¬é€‰æ‹©ä¸åŒçš„èƒŒæ™¯è¿‡ç¨‹è¿›è¡Œæ¨¡æ‹Ÿï¼Œå¥–åŠ±å‡½æ•°åˆ™åŸºäºæ¨¡æ‹Ÿç»“æœä¸çœŸå®æ•°æ®çš„åŒ¹é…ç¨‹åº¦ã€‚2) **RL Agent**ï¼šä½¿ç”¨Transformeræ¶æ„ä½œä¸ºRL agentï¼Œå¤„ç†è¡¨ç¤ºè¡°å˜çš„tokenåºåˆ—ï¼Œå­¦ä¹ é€‰æ‹©æœ€ä½³èƒŒæ™¯è¿‡ç¨‹çš„ç­–ç•¥ã€‚3) **é—ä¼ ç®—æ³•ï¼ˆGAï¼‰**ï¼šç”¨äºæ¢ç´¢è½¨è¿¹ç©ºé—´ï¼Œå¯»æ‰¾æœ‰æ½œåŠ›çš„è½¨è¿¹ï¼Œå¹¶ç”¨è¿™äº›è½¨è¿¹æ¥æŒ‡å¯¼RL agentçš„è®­ç»ƒã€‚GAé€šè¿‡äº¤å‰å’Œå˜å¼‚æ“ä½œï¼Œç”Ÿæˆæ–°çš„è½¨è¿¹ï¼Œå¹¶æ ¹æ®è½¨è¿¹çš„å¥–åŠ±å€¼è¿›è¡Œé€‰æ‹©ã€‚4) **è®­ç»ƒè¿‡ç¨‹**ï¼šRL agentå’ŒGAååŒå·¥ä½œï¼ŒGAè´Ÿè´£æ¢ç´¢ï¼ŒRL agentè´Ÿè´£å­¦ä¹ å’Œä¼˜åŒ–ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºç²’å­ç‰©ç†çš„èƒŒæ™¯ç¡®å®šé—®é¢˜ï¼Œæä¾›äº†ä¸€ç§ç³»ç»Ÿæ€§çš„è§£å†³æ–¹æ¡ˆã€‚2) ç»“åˆé—ä¼ ç®—æ³•å’Œå¼ºåŒ–å­¦ä¹ ï¼ŒåŠ é€Ÿäº†RL agentåœ¨ç¨€ç–å¥–åŠ±ç¯å¢ƒä¸‹çš„è®­ç»ƒã€‚3) ä½¿ç”¨Transformeræ¶æ„å¤„ç†è¡°å˜åºåˆ—ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ•æ‰è¡°å˜è¿‡ç¨‹ä¸­çš„å¤æ‚å…³ç³»ã€‚

**å…³é”®è®¾è®¡**ï¼š1) **çŠ¶æ€è¡¨ç¤º**ï¼šä½¿ç”¨tokenåºåˆ—æ¥è¡¨ç¤ºè¡°å˜è¿‡ç¨‹ï¼Œæ¯ä¸ªtokenä»£è¡¨ä¸€ä¸ªç²’å­æˆ–ä¸­é—´æ€ã€‚2) **åŠ¨ä½œç©ºé—´**ï¼šå®šä¹‰äº†å¯é€‰æ‹©çš„èƒŒæ™¯è¿‡ç¨‹é›†åˆï¼Œæ¯ä¸ªåŠ¨ä½œå¯¹åº”é€‰æ‹©ä¸€ä¸ªèƒŒæ™¯è¿‡ç¨‹è¿›è¡Œæ¨¡æ‹Ÿã€‚3) **å¥–åŠ±å‡½æ•°**ï¼šæ ¹æ®æ¨¡æ‹Ÿæ•°æ®ä¸çœŸå®æ•°æ®çš„åŒ¹é…ç¨‹åº¦æ¥è®¾è®¡å¥–åŠ±å‡½æ•°ï¼Œä¾‹å¦‚å¯ä»¥ä½¿ç”¨å¡æ–¹æ£€éªŒæˆ–ä¼¼ç„¶æ¯”æ£€éªŒæ¥è¡¡é‡åŒ¹é…ç¨‹åº¦ã€‚4) **Transformeræ¶æ„**ï¼šä½¿ç”¨Transformerç¼–ç å™¨æ¥å¤„ç†tokenåºåˆ—ï¼Œæå–ç‰¹å¾ï¼Œå¹¶ä½¿ç”¨Transformerè§£ç å™¨æ¥ç”ŸæˆåŠ¨ä½œã€‚5) **GAå‚æ•°**ï¼šéœ€è¦è®¾ç½®GAçš„ç§ç¾¤å¤§å°ã€äº¤å‰æ¦‚ç‡å’Œå˜å¼‚æ¦‚ç‡ç­‰å‚æ•°ï¼Œä»¥æ§åˆ¶GAçš„æ¢ç´¢èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆå¼ºåŒ–å­¦ä¹ å’Œé—ä¼ ç®—æ³•çš„æ–°æ–¹æ³•ï¼Œç”¨äºç²’å­ç‰©ç†å®éªŒä¸­çš„èƒŒæ™¯ç¡®å®šã€‚è¯¥æ–¹æ³•åˆ©ç”¨é—ä¼ ç®—æ³•åŠ é€Ÿå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒï¼Œå¹¶ä½¿ç”¨Transformeræ¶æ„å¤„ç†è¡°å˜åºåˆ—ã€‚è™½ç„¶è®ºæ–‡ä¸­æ²¡æœ‰ç»™å‡ºå…·ä½“çš„æ€§èƒ½æ•°æ®ï¼Œä½†è¯¥æ–¹æ³•ä¸ºè§£å†³èƒŒæ™¯ç¡®å®šé—®é¢˜æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ï¼Œå…·æœ‰æ½œåœ¨çš„æ€§èƒ½æå‡ç©ºé—´ã€‚æœªæ¥çš„å·¥ä½œå¯ä»¥é›†ä¸­åœ¨å®éªŒéªŒè¯å’Œæ€§èƒ½è¯„ä¼°ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç²’å­ç‰©ç†å®éªŒçš„æ•°æ®åˆ†æï¼Œç‰¹åˆ«æ˜¯ç¾å¼ºå­è¡°å˜ç­‰å¤æ‚è¡°å˜è¿‡ç¨‹çš„ç ”ç©¶ã€‚é€šè¿‡è‡ªåŠ¨è¯†åˆ«å’Œæ’é™¤èƒŒæ™¯å™ªå£°ï¼Œå¯ä»¥æé«˜ä¿¡å·æå–çš„å‡†ç¡®æ€§ï¼Œä»è€Œæ›´ç²¾ç¡®åœ°æµ‹é‡ç‰©ç†å‚æ•°ï¼Œæ£€éªŒæ ‡å‡†æ¨¡å‹ï¼Œå¹¶å¯»æ‰¾æ–°ç‰©ç†çš„è¿¹è±¡ã€‚è¯¥æ–¹æ³•è¿˜å¯æ¨å¹¿åˆ°å…¶ä»–ç§‘å­¦é¢†åŸŸï¼Œå¦‚ç”Ÿç‰©ä¿¡æ¯å­¦å’Œé‡‘èå»ºæ¨¡ï¼Œç”¨äºè§£å†³ç±»ä¼¼çš„èƒŒæ™¯å™ªå£°è¯†åˆ«å’Œä¿¡å·æå–é—®é¢˜ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Experimental studies of beauty hadron decays face significant challenges due to a wide range of backgrounds arising from the numerous possible decay channels with similar final states. For a particular signal decay, the process for ascertaining the most relevant background processes necessitates a detailed analysis of final state particles, potential misidentifications, and kinematic overlaps, which, due to computational limitations, is restricted to the simulation of only the most relevant backgrounds. Moreover, this process typically relies on the physicist's intuition and expertise, as no systematic method exists.
>   This paper has two primary goals. First, from a particle physics perspective, we present a novel approach that utilises Reinforcement Learning (RL) to overcome the aforementioned challenges by systematically determining the critical backgrounds affecting beauty hadron decay measurements. While beauty hadron physics serves as the case study in this work, the proposed strategy is broadly adaptable to other types of particle physics measurements. Second, from a Machine Learning perspective, we introduce a novel algorithm which exploits the synergy between RL and Genetic Algorithms (GAs) for environments with highly sparse rewards and a large trajectory space. This strategy leverages GAs to efficiently explore the trajectory space and identify successful trajectories, which are used to guide the RL agent's training. Our method also incorporates a transformer architecture for the RL agent to handle token sequences representing decays.

