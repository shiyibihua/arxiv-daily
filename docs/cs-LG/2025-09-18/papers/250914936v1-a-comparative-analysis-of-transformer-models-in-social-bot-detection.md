---
layout: default
title: A Comparative Analysis of Transformer Models in Social Bot Detection
---

# A Comparative Analysis of Transformer Models in Social Bot Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14936" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14936v1</a>
  <a href="https://arxiv.org/pdf/2509.14936.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14936v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14936v1', 'A Comparative Analysis of Transformer Models in Social Bot Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rohan Veit, Michael Lones

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: To appear in proceedings of UKCI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¯¹æ¯”Transformeræ¨¡å‹åœ¨ç¤¾äº¤æœºå™¨äººæ£€æµ‹ä¸­çš„åº”ç”¨ï¼Œæ­ç¤ºç¼–ç å™¨æ¨¡å‹çš„ä¼˜åŠ¿**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¤¾äº¤æœºå™¨äººæ£€æµ‹` `Transformeræ¨¡å‹` `ç¼–ç å™¨` `è§£ç å™¨` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç¤¾äº¤åª’ä½“ä¸­æœºå™¨äººæ³›æ»¥ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åŠ å‰§äº†é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆè¯†åˆ«ã€‚
2. æœ¬æ–‡å¯¹æ¯”äº†åŸºäºç¼–ç å™¨å’Œè§£ç å™¨Transformerçš„æœºå™¨äººæ£€æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨å¯»æ‰¾æ›´æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚
3. å®éªŒè¡¨æ˜ï¼ŒåŸºäºç¼–ç å™¨çš„æ¨¡å‹åœ¨å‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢æ›´ä¼˜ï¼Œè€Œè§£ç å™¨æ¨¡å‹åœ¨é€‚åº”æ€§æ–¹é¢æ›´å…·æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¤¾äº¤åª’ä½“å·²æˆä¸ºå½“ä»Šç¤¾ä¼šé‡è¦çš„äº¤æµåª’ä»‹ã€‚å› æ­¤ï¼Œè®¸å¤šç»„ç»‡åˆ©ç”¨äººå·¥ç”¨æˆ·ï¼ˆæˆ–æœºå™¨äººï¼‰è¯¯å¯¼ä»–äººï¼Œä½¿å…¶ç›¸ä¿¡è™šå‡ä¿¡æ¯æˆ–ä»¥æœ‰åˆ©äºè¿™äº›ç»„ç»‡çš„æ–¹å¼è¡Œäº‹ã€‚å¤§å‹è¯­è¨€æ¨¡å‹ç­‰å…ˆè¿›çš„æ–‡æœ¬ç”Ÿæˆå·¥å…·è¿›ä¸€æ­¥åŠ å‰§äº†è¿™ä¸ªé—®é¢˜ã€‚æœ¬æ–‡æ—¨åœ¨æ¯”è¾ƒåŸºäºç¼–ç å™¨å’Œè§£ç å™¨Transformerçš„æœºå™¨äººæ£€æµ‹æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å¼€å‘çš„æµç¨‹è¯„ä¼°è¿™äº›åˆ†ç±»å™¨çš„æ€§èƒ½ï¼Œç»“æœè¡¨æ˜åŸºäºç¼–ç å™¨çš„åˆ†ç±»å™¨è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚ç„¶è€Œï¼ŒåŸºäºè§£ç å™¨çš„æ¨¡å‹é€šè¿‡ç‰¹å®šä»»åŠ¡çš„å¯¹é½è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§ï¼Œè¡¨æ˜é™¤äº†å“è¶Šçš„è§‚å¯Ÿèƒ½åŠ›å¤–ï¼Œåœ¨ä¸åŒç”¨ä¾‹ä¸­å…·æœ‰æ›´å¤§çš„æ³›åŒ–æ½œåŠ›ã€‚è¿™äº›å‘ç°æœ‰åŠ©äºä¸æ–­åŠªåŠ›é˜²æ­¢æ•°å­—ç¯å¢ƒè¢«æ“çºµï¼ŒåŒæ—¶ä¿æŠ¤åœ¨çº¿è®¨è®ºçš„å®Œæ•´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç¤¾äº¤æœºå™¨äººæ£€æµ‹æ—¨åœ¨è¯†åˆ«ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„è‡ªåŠ¨åŒ–è´¦æˆ·ï¼Œç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æ—¥ç›Šå¤æ‚çš„æ–‡æœ¬ç”ŸæˆæŠ€æœ¯æ—¶ï¼Œå‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›é¢ä¸´æŒ‘æˆ˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¦‚ä½•æœ‰æ•ˆåˆ©ç”¨Transformeræ¨¡å‹è¿›è¡Œç¤¾äº¤æœºå™¨äººæ£€æµ‹ï¼Œå¹¶æ¯”è¾ƒä¸åŒTransformeræ¶æ„çš„ä¼˜åŠ£ï¼Œæ˜¯ä¸€ä¸ªäºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ¯”è¾ƒåŸºäºç¼–ç å™¨å’Œè§£ç å™¨Transformerçš„æœºå™¨äººæ£€æµ‹æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡æ„å»ºå’Œè¯„ä¼°ä¸åŒçš„åˆ†ç±»å™¨ï¼Œåˆ†æå®ƒä»¬åœ¨å‡†ç¡®æ€§ã€é²æ£’æ€§å’Œé€‚åº”æ€§æ–¹é¢çš„è¡¨ç°ï¼Œä»è€Œä¸ºç¤¾äº¤æœºå™¨äººæ£€æµ‹æä¾›æ›´æœ‰æ•ˆçš„æ¨¡å‹é€‰æ‹©å’Œè®¾è®¡æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæœ¬æ–‡æ„å»ºäº†åŒ…å«æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹ã€‚é¦–å…ˆï¼Œå¯¹ç¤¾äº¤åª’ä½“æ•°æ®è¿›è¡Œæ¸…æ´—å’Œç‰¹å¾æå–ã€‚ç„¶åï¼Œåˆ†åˆ«ä½¿ç”¨åŸºäºç¼–ç å™¨ï¼ˆå¦‚BERTï¼‰å’Œè§£ç å™¨ï¼ˆå¦‚GPTï¼‰çš„Transformeræ¨¡å‹æ„å»ºåˆ†ç±»å™¨ã€‚æœ€åï¼Œé€šè¿‡ä¸€ç³»åˆ—å®éªŒè¯„ä¼°è¿™äº›åˆ†ç±»å™¨åœ¨ä¸åŒæ•°æ®é›†å’Œä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå¯¹ç¼–ç å™¨å’Œè§£ç å™¨Transformeråœ¨ç¤¾äº¤æœºå™¨äººæ£€æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¿›è¡Œäº†å…¨é¢çš„æ¯”è¾ƒåˆ†æã€‚ä»¥å¾€çš„ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨å•ä¸€æ¨¡å‹çš„ä¼˜åŒ–ï¼Œè€Œæœ¬æ–‡é€šè¿‡å¯¹æ¯”ä¸åŒæ¶æ„çš„ä¼˜åŠ£ï¼Œä¸ºæœªæ¥çš„ç ”ç©¶æä¾›äº†æ›´å¹¿é˜”çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šæœ¬æ–‡é‡‡ç”¨äº†æ ‡å‡†çš„Transformeræ¨¡å‹ç»“æ„ï¼Œå¹¶é’ˆå¯¹ç¤¾äº¤æœºå™¨äººæ£€æµ‹ä»»åŠ¡è¿›è¡Œäº†å¾®è°ƒã€‚å…·ä½“è€Œè¨€ï¼Œç¼–ç å™¨æ¨¡å‹ä½¿ç”¨é¢„è®­ç»ƒçš„BERTæ¨¡å‹ï¼Œå¹¶åœ¨ç‰¹å®šæ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒã€‚è§£ç å™¨æ¨¡å‹ä½¿ç”¨é¢„è®­ç»ƒçš„GPTæ¨¡å‹ï¼Œå¹¶é€šè¿‡ç‰¹å®šä»»åŠ¡çš„å¯¹é½è¿›è¡Œä¼˜åŒ–ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–å™¨é‡‡ç”¨AdamWä¼˜åŒ–å™¨ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œè¶…å‚æ•°è°ƒæ•´ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºç¼–ç å™¨çš„Transformeræ¨¡å‹åœ¨ç¤¾äº¤æœºå™¨äººæ£€æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚è™½ç„¶å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†ç¼–ç å™¨æ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå‡ä¼˜äºè§£ç å™¨æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè§£ç å™¨æ¨¡å‹é€šè¿‡ç‰¹å®šä»»åŠ¡çš„å¯¹é½è¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§ï¼Œè¡¨æ˜å…¶åœ¨ä¸åŒç”¨ä¾‹ä¸­å…·æœ‰æ›´å¤§çš„æ³›åŒ–æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºç¤¾äº¤åª’ä½“å¹³å°çš„å†…å®¹å®¡æ ¸ã€è™šå‡ä¿¡æ¯æ£€æµ‹å’Œç½‘ç»œå®‰å…¨é˜²æŠ¤ã€‚é€šè¿‡éƒ¨ç½²é«˜æ€§èƒ½çš„ç¤¾äº¤æœºå™¨äººæ£€æµ‹æ¨¡å‹ï¼Œå¯ä»¥æœ‰æ•ˆå‡å°‘æœºå™¨äººè´¦å·çš„å¹²æ‰°ï¼Œç»´æŠ¤å¥åº·çš„åœ¨çº¿è®¨è®ºç¯å¢ƒï¼Œå¹¶ä¿æŠ¤ç”¨æˆ·å…å—æ¶æ„ä¿¡æ¯çš„ä¾µå®³ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„è‡ªåŠ¨åŒ–è´¦æˆ·æ£€æµ‹ï¼Œä¾‹å¦‚æ¶æ„è½¯ä»¶ä¼ æ’­å’Œç½‘ç»œæ”»å‡»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Social media has become a key medium of communication in today's society. This realisation has led to many parties employing artificial users (or bots) to mislead others into believing untruths or acting in a beneficial manner to such parties. Sophisticated text generation tools, such as large language models, have further exacerbated this issue. This paper aims to compare the effectiveness of bot detection models based on encoder and decoder transformers. Pipelines are developed to evaluate the performance of these classifiers, revealing that encoder-based classifiers demonstrate greater accuracy and robustness. However, decoder-based models showed greater adaptability through task-specific alignment, suggesting more potential for generalisation across different use cases in addition to superior observa. These findings contribute to the ongoing effort to prevent digital environments being manipulated while protecting the integrity of online discussion.

