---
layout: default
title: Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning
---

# Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15087" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15087v2</a>
  <a href="https://arxiv.org/pdf/2509.15087.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15087v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15087v2', 'Adaptive LoRA Experts Allocation and Selection for Federated Fine-Tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lei Wang, Jieming Bian, Letian Zhang, Jie Xu

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-10-10)

**å¤‡æ³¨**: Accepted to NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FedLEASEï¼šè”é‚¦å­¦ä¹ ä¸­è‡ªé€‚åº”LoRAä¸“å®¶åˆ†é…ä¸é€‰æ‹©ï¼Œæå‡å¼‚æ„æ•°æ®ä¸‹çš„å¾®è°ƒæ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `ä½ç§©é€‚åº”` `LoRA` `æ··åˆä¸“å®¶` `å¼‚æ„æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è”é‚¦å­¦ä¹ åœ¨LLMå¾®è°ƒä¸­é¢ä¸´å¼‚æ„æ•°æ®æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å…¼é¡¾æ¨¡å‹æ€§èƒ½å’Œé€šä¿¡æ•ˆç‡ã€‚
2. FedLEASEé€šè¿‡è‡ªé€‚åº”èšç±»å®¢æˆ·ç«¯å’Œåˆ†é…LoRAä¸“å®¶ï¼Œå®ç°é¢†åŸŸç‰¹å®šçŸ¥è¯†çš„æœ‰æ•ˆå­¦ä¹ ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒFedLEASEåœ¨å¼‚æ„ç¯å¢ƒä¸‹æ˜¾è‘—ä¼˜äºç°æœ‰è”é‚¦å¾®è°ƒæ–¹æ³•ï¼Œå¹¶ä¿æŒé€šä¿¡æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å„ç§ä»»åŠ¡ä¸­å±•ç°äº†å“è¶Šçš„èƒ½åŠ›ï¼Œä½†é’ˆå¯¹ç‰¹å®šé¢†åŸŸçš„å¾®è°ƒé€šå¸¸éœ€è¦å¤§é‡çš„é¢†åŸŸæ•°æ®ï¼Œè€Œè¿™äº›æ•°æ®å¯èƒ½åˆ†å¸ƒåœ¨å¤šä¸ªç»„ç»‡ä¸­ã€‚è”é‚¦å­¦ä¹ (FL)æä¾›äº†ä¸€ç§ä¿æŠ¤éšç§çš„è§£å†³æ–¹æ¡ˆï¼Œä½†åœ¨åº”ç”¨äºLLMsæ—¶é¢ä¸´è®¡ç®—çº¦æŸçš„æŒ‘æˆ˜ã€‚ä½ç§©é€‚åº”(LoRA)å·²æˆä¸ºä¸€ç§å‚æ•°é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œä½†å•ä¸ªLoRAæ¨¡å—é€šå¸¸éš¾ä»¥åº”å¯¹è·¨ä¸åŒé¢†åŸŸçš„å¼‚æ„æ•°æ®ã€‚æœ¬æ–‡è§£å†³äº†è”é‚¦LoRAå¾®è°ƒä¸­çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼š1.ç¡®å®šå¼‚æ„å®¢æˆ·ç«¯ä¹‹é—´LoRAä¸“å®¶çš„æœ€ä½³æ•°é‡å’Œåˆ†é…ï¼›2.ä½¿å®¢æˆ·ç«¯èƒ½å¤Ÿæ ¹æ®å…¶ç‰¹å®šæ•°æ®ç‰¹å¾é€‰æ‹©æ€§åœ°åˆ©ç”¨è¿™äº›ä¸“å®¶ã€‚æˆ‘ä»¬æå‡ºäº†FedLEASEï¼ˆFederated adaptive LoRA Expert Allocation and SElectionï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œå®ƒåŸºäºè¡¨ç¤ºç›¸ä¼¼æ€§è‡ªé€‚åº”åœ°èšç±»å®¢æˆ·ç«¯ï¼Œä»¥åˆ†é…å’Œè®­ç»ƒç‰¹å®šé¢†åŸŸçš„LoRAä¸“å®¶ã€‚å®ƒè¿˜å¼•å…¥äº†ä¸€ç§è‡ªé€‚åº”çš„top-$M$æ··åˆä¸“å®¶æœºåˆ¶ï¼Œå…è®¸æ¯ä¸ªå®¢æˆ·ç«¯é€‰æ‹©æœ€ä½³æ•°é‡çš„åˆ©ç”¨ä¸“å®¶ã€‚æˆ‘ä»¬åœ¨ä¸åŒçš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œåœ¨å¼‚æ„å®¢æˆ·ç«¯è®¾ç½®ä¸­ï¼ŒFedLEASEæ˜æ˜¾ä¼˜äºç°æœ‰çš„è”é‚¦å¾®è°ƒæ–¹æ³•ï¼ŒåŒæ—¶ä¿æŒäº†é€šä¿¡æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ï¼Œå„ä¸ªå®¢æˆ·ç«¯çš„æ•°æ®åˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼ˆå¼‚æ„æ€§ï¼‰ï¼Œå¯¼è‡´ä¼ ç»Ÿçš„è”é‚¦å¾®è°ƒæ–¹æ³•ï¼Œå°¤å…¶æ˜¯åŸºäºå•ä¸€LoRAæ¨¡å—çš„æ–¹æ³•ï¼Œéš¾ä»¥åœ¨æ‰€æœ‰å®¢æˆ·ç«¯ä¸Šå–å¾—è‰¯å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°åˆ†é…å’Œåˆ©ç”¨æœ‰é™çš„è®¡ç®—èµ„æºï¼Œä¸ºæ¯ä¸ªå®¢æˆ·ç«¯å®šåˆ¶åˆé€‚çš„LoRAä¸“å®¶æ•°é‡ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFedLEASEçš„æ ¸å¿ƒæ€è·¯æ˜¯æ ¹æ®å®¢æˆ·ç«¯æ•°æ®çš„ç›¸ä¼¼æ€§ï¼Œå°†å®¢æˆ·ç«¯èšç±»æˆä¸åŒçš„ç»„ï¼Œä¸ºæ¯ä¸ªç»„åˆ†é…å’Œè®­ç»ƒä¸€ä¸ªæˆ–å¤šä¸ªLoRAä¸“å®¶ã€‚æ¯ä¸ªå®¢æˆ·ç«¯å¯ä»¥æ ¹æ®è‡ªèº«æ•°æ®çš„ç‰¹ç‚¹ï¼Œé€‰æ‹©æ€§åœ°åˆ©ç”¨è¿™äº›ä¸“å®¶ï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–çš„å¾®è°ƒã€‚è¿™ç§æ–¹æ³•æ—¢èƒ½åˆ©ç”¨ä¸åŒé¢†åŸŸçš„æ•°æ®ï¼Œåˆèƒ½é¿å…å•ä¸€æ¨¡å‹åœ¨å¼‚æ„æ•°æ®ä¸Šçš„æ€§èƒ½ç“¶é¢ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFedLEASEæ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1. **å®¢æˆ·ç«¯èšç±»**ï¼šåŸºäºå®¢æˆ·ç«¯ä¸Šä¼ çš„è¡¨ç¤ºå‘é‡ï¼ˆä¾‹å¦‚ï¼Œæ¥è‡ªé¢„è®­ç»ƒæ¨¡å‹çš„è¾“å‡ºï¼‰ï¼Œä½¿ç”¨èšç±»ç®—æ³•ï¼ˆå¦‚k-meansï¼‰å°†å®¢æˆ·ç«¯åˆ’åˆ†ä¸ºä¸åŒçš„ç»„ã€‚2. **LoRAä¸“å®¶åˆ†é…**ï¼šä¸ºæ¯ä¸ªå®¢æˆ·ç«¯ç»„åˆ†é…ä¸€ä¸ªæˆ–å¤šä¸ªLoRAä¸“å®¶ã€‚ä¸“å®¶çš„æ•°é‡å¯ä»¥æ ¹æ®ç»„å†…æ•°æ®çš„å¤æ‚åº¦å’Œå®¢æˆ·ç«¯çš„è®¡ç®—èµ„æºè¿›è¡Œè°ƒæ•´ã€‚3. **LoRAä¸“å®¶è®­ç»ƒ**ï¼šæ¯ä¸ªå®¢æˆ·ç«¯ç»„ä½¿ç”¨æœ¬åœ°æ•°æ®è®­ç»ƒå…¶åˆ†é…çš„LoRAä¸“å®¶ã€‚4. **è‡ªé€‚åº”ä¸“å®¶é€‰æ‹©**ï¼šæ¯ä¸ªå®¢æˆ·ç«¯æ ¹æ®è‡ªèº«æ•°æ®ä¸ä¸åŒLoRAä¸“å®¶çš„ç›¸å…³æ€§ï¼Œé€‰æ‹©top-$M$ä¸ªä¸“å®¶è¿›è¡ŒåŠ æƒèåˆã€‚$M$çš„å€¼å¯ä»¥è‡ªé€‚åº”åœ°è°ƒæ•´ï¼Œä»¥å¹³è¡¡æ¨¡å‹æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ã€‚

**å…³é”®åˆ›æ–°**ï¼šFedLEASEçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1. **è‡ªé€‚åº”å®¢æˆ·ç«¯èšç±»**ï¼šæ ¹æ®å®¢æˆ·ç«¯æ•°æ®çš„ç›¸ä¼¼æ€§åŠ¨æ€åœ°è¿›è¡Œèšç±»ï¼Œè€Œä¸æ˜¯é¢„å…ˆå®šä¹‰æˆ–éšæœºåˆ†é…ã€‚2. **LoRAä¸“å®¶è‡ªé€‚åº”åˆ†é…**ï¼šæ ¹æ®å®¢æˆ·ç«¯ç»„çš„ç‰¹ç‚¹ï¼Œè‡ªé€‚åº”åœ°åˆ†é…LoRAä¸“å®¶çš„æ•°é‡ã€‚3. **è‡ªé€‚åº”Top-$M$ä¸“å®¶é€‰æ‹©**ï¼šå…è®¸æ¯ä¸ªå®¢æˆ·ç«¯æ ¹æ®è‡ªèº«æ•°æ®ç‰¹ç‚¹ï¼Œé€‰æ‹©æœ€ç›¸å…³çš„LoRAä¸“å®¶è¿›è¡Œèåˆï¼Œè€Œä¸æ˜¯å¼ºåˆ¶ä½¿ç”¨æ‰€æœ‰ä¸“å®¶ã€‚

**å…³é”®è®¾è®¡**ï¼š1. **è¡¨ç¤ºå‘é‡æå–**ï¼šä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ä¸­é—´å±‚è¾“å‡ºä½œä¸ºå®¢æˆ·ç«¯æ•°æ®çš„è¡¨ç¤ºå‘é‡ï¼Œä»¥æ•æ‰æ•°æ®çš„è¯­ä¹‰ä¿¡æ¯ã€‚2. **èšç±»ç®—æ³•é€‰æ‹©**ï¼šå¯ä»¥ä½¿ç”¨ä¸åŒçš„èšç±»ç®—æ³•ï¼Œå¦‚k-meansæˆ–è°±èšç±»ï¼Œæ ¹æ®å®é™…æƒ…å†µè¿›è¡Œé€‰æ‹©ã€‚3. **ä¸“å®¶é€‰æ‹©ç­–ç•¥**ï¼šå¯ä»¥ä½¿ç”¨ä¸åŒçš„ç­–ç•¥æ¥é€‰æ‹©top-$M$ä¸ªä¸“å®¶ï¼Œä¾‹å¦‚åŸºäºæ³¨æ„åŠ›æœºåˆ¶æˆ–ç›¸ä¼¼åº¦åº¦é‡ã€‚4. **æŸå¤±å‡½æ•°è®¾è®¡**ï¼šå¯ä»¥ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°æˆ–å…¶ä»–çš„æŸå¤±å‡½æ•°æ¥è®­ç»ƒLoRAä¸“å®¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFedLEASEåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„è”é‚¦å¾®è°ƒæ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›æ•°æ®é›†ä¸Šï¼ŒFedLEASEçš„æ€§èƒ½æå‡è¶…è¿‡5%ï¼ŒåŒæ—¶ä¿æŒäº†ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„é€šä¿¡æ•ˆç‡ã€‚è‡ªé€‚åº”ä¸“å®¶é€‰æ‹©æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å¹³è¡¡æ¨¡å‹æ€§èƒ½å’Œè®¡ç®—æˆæœ¬ï¼Œä½¿å¾—FedLEASEåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šä¹Ÿèƒ½å–å¾—è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FedLEASEé€‚ç”¨äºå„ç§è”é‚¦å­¦ä¹ åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®å¼‚æ„æ€§è¾ƒé«˜çš„é¢†åŸŸï¼Œä¾‹å¦‚åŒ»ç–—å¥åº·ã€é‡‘èé£æ§å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚å®ƒå¯ä»¥å¸®åŠ©ä¼ä¸šåœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„å‰æä¸‹ï¼Œåˆ©ç”¨åˆ†å¸ƒåœ¨ä¸åŒæœºæ„çš„æ•°æ®ï¼Œè®­ç»ƒå‡ºæ›´åŠ ç²¾å‡†å’Œä¸ªæ€§åŒ–çš„æ¨¡å‹ï¼Œä»è€Œæå‡æœåŠ¡è´¨é‡å’Œç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°å…¶ä»–å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯ï¼Œå¹¶åº”ç”¨äºæ›´å¤æ‚çš„æ¨¡å‹ç»“æ„ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have demonstrated impressive capabilities across various tasks, but fine-tuning them for domain-specific applications often requires substantial domain-specific data that may be distributed across multiple organizations. Federated Learning (FL) offers a privacy-preserving solution, but faces challenges with computational constraints when applied to LLMs. Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient fine-tuning approach, though a single LoRA module often struggles with heterogeneous data across diverse domains. This paper addresses two critical challenges in federated LoRA fine-tuning: 1. determining the optimal number and allocation of LoRA experts across heterogeneous clients, and 2. enabling clients to selectively utilize these experts based on their specific data characteristics. We propose FedLEASE (Federated adaptive LoRA Expert Allocation and SElection), a novel framework that adaptively clusters clients based on representation similarity to allocate and train domain-specific LoRA experts. It also introduces an adaptive top-$M$ Mixture-of-Experts mechanism that allows each client to select the optimal number of utilized experts. Our extensive experiments on diverse benchmark datasets demonstrate that FedLEASE significantly outperforms existing federated fine-tuning approaches in heterogeneous client settings while maintaining communication efficiency.

