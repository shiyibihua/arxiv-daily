---
layout: default
title: Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation
---

# Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.14925" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.14925v1</a>
  <a href="https://arxiv.org/pdf/2509.14925.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.14925v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.14925v1', 'Self-Explaining Reinforcement Learning for Mobile Network Resource Allocation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Konrad Nowosadko, Franco Ruggeri, Ahmad Terra

**åˆ†ç±»**: cs.LG, cs.NI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè‡ªè§£é‡Šç¥ç»ç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºè§£å†³ç§»åŠ¨ç½‘ç»œèµ„æºåˆ†é…é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è‡ªè§£é‡Šç¥ç»ç½‘ç»œ` `å¯è§£é‡Šæ€§` `ç§»åŠ¨ç½‘ç»œ` `èµ„æºåˆ†é…`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ç¼ºä¹é€æ˜æ€§ï¼Œéš¾ä»¥è§£é‡Šå…¶å†³ç­–è¿‡ç¨‹ï¼Œé™åˆ¶äº†åœ¨å…³é”®é¢†åŸŸçš„åº”ç”¨ã€‚
2. åˆ©ç”¨è‡ªè§£é‡Šç¥ç»ç½‘ç»œï¼ˆSENNï¼‰æ¡†æ¶ï¼Œç»“åˆè§£é‡Šæå–æ–¹æ³•ï¼Œåœ¨ä¿è¯æ€§èƒ½çš„åŒæ—¶æå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚
3. åœ¨ç§»åŠ¨ç½‘ç»œèµ„æºåˆ†é…é—®é¢˜ä¸ŠéªŒè¯äº†SENNçš„æœ‰æ•ˆæ€§ï¼Œå®ç°äº†ä¸ç°æœ‰æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶æä¾›äº†é²æ£’çš„è§£é‡Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç¥ç»ç½‘ç»œï¼ˆDNNï¼‰åŠ æŒçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ–¹æ³•è™½ç„¶å¼ºå¤§ï¼Œä½†é€šå¸¸ç¼ºä¹é€æ˜æ€§ã€‚å…¶é»‘ç›’ç‰¹æ€§é™ä½äº†è§£é‡Šæ€§å’Œå¯ä¿¡åº¦ï¼Œå°¤å…¶æ˜¯åœ¨å…³é”®é¢†åŸŸã€‚ä¸ºäº†è§£å†³RLä»»åŠ¡ä¸­çš„è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºè‡ªè§£é‡Šç¥ç»ç½‘ç»œï¼ˆSENNï¼‰çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶ç»“åˆäº†è§£é‡Šæå–æ–¹æ³•ï¼Œä»¥å¢å¼ºå¯è§£é‡Šæ€§ï¼ŒåŒæ—¶ä¿æŒé¢„æµ‹å‡†ç¡®æ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•é’ˆå¯¹ä½ç»´é—®é¢˜ï¼Œç”Ÿæˆæ¨¡å‹è¡Œä¸ºçš„é²æ£’çš„å±€éƒ¨å’Œå…¨å±€è§£é‡Šã€‚æˆ‘ä»¬åœ¨ç§»åŠ¨ç½‘ç»œä¸­çš„èµ„æºåˆ†é…é—®é¢˜ä¸Šè¯„ä¼°äº†æ‰€æå‡ºçš„æ–¹æ³•ï¼Œè¯æ˜SENNå¯ä»¥æ„æˆå…·æœ‰ç«äº‰åŠ›çš„å¯è§£é‡Šè§£å†³æ–¹æ¡ˆã€‚è¿™é¡¹å·¥ä½œçªå‡ºäº†SENNåœ¨æé«˜ä½ç»´ä»»åŠ¡ä¸­AIé©±åŠ¨å†³ç­–çš„é€æ˜åº¦å’Œä¿¡ä»»æ–¹é¢çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æä¾›ç¨³å¥è§£é‡Šçš„åŒæ—¶ï¼Œè¡¨ç°å‡ºä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„å¼ºå¤§æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç§»åŠ¨ç½‘ç»œèµ„æºåˆ†é…é—®é¢˜ï¼Œè¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ä½ç»´åº¦å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ã€‚ç°æœ‰åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•è™½ç„¶æ€§èƒ½ä¼˜è¶Šï¼Œä½†ç”±äºå…¶é»‘ç›’ç‰¹æ€§ï¼Œç¼ºä¹å¯è§£é‡Šæ€§ï¼Œéš¾ä»¥ç†è§£å…¶å†³ç­–ä¾æ®ï¼Œè¿™åœ¨èµ„æºåˆ†é…ç­‰å…³é”®é¢†åŸŸä¼šé™ä½ä¿¡ä»»åº¦ã€‚å› æ­¤ï¼Œå¦‚ä½•æé«˜å¼ºåŒ–å­¦ä¹ æ¨¡å‹åœ¨èµ„æºåˆ†é…é—®é¢˜ä¸­çš„å¯è§£é‡Šæ€§æ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªè§£é‡Šç¥ç»ç½‘ç»œï¼ˆSelf-Explaining Neural Networks, SENNï¼‰æ¥æ„å»ºå¼ºåŒ–å­¦ä¹ æ¨¡å‹ã€‚SENNçš„è®¾è®¡ç›®æ ‡æ˜¯åœ¨æ¨¡å‹é¢„æµ‹çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæä¾›å¯¹é¢„æµ‹ç»“æœçš„è§£é‡Šã€‚é€šè¿‡å°†è§£é‡Šèƒ½åŠ›èå…¥åˆ°æ¨¡å‹ç»“æ„ä¸­ï¼Œå¯ä»¥åœ¨ä¸æ˜¾è‘—é™ä½æ€§èƒ½çš„å‰æä¸‹ï¼Œæé«˜æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼šé¦–å…ˆï¼Œä½¿ç”¨SENNä½œä¸ºå¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“çš„ç­–ç•¥ç½‘ç»œã€‚å…¶æ¬¡ï¼Œè®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œå¼•å¯¼æ™ºèƒ½ä½“å­¦ä¹ æœ€ä¼˜çš„èµ„æºåˆ†é…ç­–ç•¥ã€‚ç„¶åï¼Œé€šè¿‡è§£é‡Šæå–æ–¹æ³•ï¼Œä»SENNä¸­æå–å±€éƒ¨å’Œå…¨å±€çš„è§£é‡Šï¼Œä»è€Œç†è§£æ™ºèƒ½ä½“çš„å†³ç­–è¿‡ç¨‹ã€‚æœ€åï¼Œé€šè¿‡å®éªŒéªŒè¯SENNåœ¨èµ„æºåˆ†é…é—®é¢˜ä¸Šçš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è‡ªè§£é‡Šç¥ç»ç½‘ç»œï¼ˆSENNï¼‰å¼•å…¥åˆ°å¼ºåŒ–å­¦ä¹ çš„èµ„æºåˆ†é…é—®é¢˜ä¸­ã€‚ä¸ä¼ ç»Ÿçš„é»‘ç›’æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼ŒSENNèƒ½å¤Ÿåœ¨åšå‡ºå†³ç­–çš„åŒæ—¶ï¼Œæä¾›å¯¹å†³ç­–çš„è§£é‡Šï¼Œä»è€Œæé«˜æ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯ç†è§£æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜é’ˆå¯¹ä½ç»´é—®é¢˜è¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥ç”Ÿæˆæ›´é²æ£’çš„è§£é‡Šã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­SENNçš„å…·ä½“ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æ–­å…¶å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç‰¹å®šçš„ç½‘ç»œå±‚è®¾è®¡ï¼Œç”¨äºç”Ÿæˆè§£é‡Šï¼›2) æŸå¤±å‡½æ•°çš„è®¾è®¡ï¼Œå¯èƒ½åŒ…å«è§£é‡Šç›¸å…³çš„æ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿è¯è§£é‡Šçš„è´¨é‡ï¼›3) è§£é‡Šæå–æ–¹æ³•çš„é€‰æ‹©ï¼Œç”¨äºä»SENNä¸­æå–æœ‰æ„ä¹‰çš„è§£é‡Šã€‚å…·ä½“çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚Q-learning, SARSA, æˆ–Policy Gradientï¼‰çš„é€‰æ‹©ä¹Ÿå¯èƒ½å½±å“æœ€ç»ˆçš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºSENNçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ç§»åŠ¨ç½‘ç»œèµ„æºåˆ†é…é—®é¢˜ä¸Šå–å¾—äº†ä¸ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“çš„æ€§èƒ½ã€‚æ›´é‡è¦çš„æ˜¯ï¼ŒSENNèƒ½å¤Ÿæä¾›å¯¹å†³ç­–è¿‡ç¨‹çš„è§£é‡Šï¼Œä¾‹å¦‚ï¼Œå“ªäº›å› ç´ å¯¹èµ„æºåˆ†é…å†³ç­–å½±å“æœ€å¤§ã€‚è¿™äº›è§£é‡Šæœ‰åŠ©äºç†è§£æ™ºèƒ½ä½“çš„è¡Œä¸ºï¼Œå¹¶æé«˜å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»åº¦ã€‚è™½ç„¶å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†SENNåœ¨æä¾›é²æ£’è§£é‡Šçš„åŒæ—¶ï¼Œä¿æŒäº†ç«äº‰åŠ›çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦é€æ˜å’Œå¯ä¿¡èµ–çš„AIå†³ç­–åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ™ºèƒ½äº¤é€šã€é‡‘èé£æ§ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚é€šè¿‡æä¾›å¯è§£é‡Šçš„å†³ç­–è¿‡ç¨‹ï¼Œå¯ä»¥å¢å¼ºç”¨æˆ·å¯¹AIç³»ç»Ÿçš„ä¿¡ä»»ï¼Œä¿ƒè¿›AIæŠ€æœ¯åœ¨å…³é”®é¢†åŸŸçš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ‰©å±•åˆ°æ›´é«˜ç»´åº¦çš„é—®é¢˜ï¼Œå¹¶ä¸å…¶ä»–å¯è§£é‡Šæ€§æŠ€æœ¯ç›¸ç»“åˆï¼Œè¿›ä¸€æ­¥æé«˜AIç³»ç»Ÿçš„é€æ˜åº¦å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement Learning (RL) methods that incorporate deep neural networks (DNN), though powerful, often lack transparency. Their black-box characteristic hinders interpretability and reduces trustworthiness, particularly in critical domains. To address this challenge in RL tasks, we propose a solution based on Self-Explaining Neural Networks (SENNs) along with explanation extraction methods to enhance interpretability while maintaining predictive accuracy. Our approach targets low-dimensionality problems to generate robust local and global explanations of the model's behaviour. We evaluate the proposed method on the resource allocation problem in mobile networks, demonstrating that SENNs can constitute interpretable solutions with competitive performance. This work highlights the potential of SENNs to improve transparency and trust in AI-driven decision-making for low-dimensional tasks. Our approach strong performance on par with the existing state-of-the-art methods, while providing robust explanations.

