---
layout: default
title: Predicting Language Models' Success at Zero-Shot Probabilistic Prediction
---

# Predicting Language Models' Success at Zero-Shot Probabilistic Prediction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15356" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15356v1</a>
  <a href="https://arxiv.org/pdf/2509.15356.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15356v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15356v1', 'Predicting Language Models\' Success at Zero-Shot Probabilistic Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kevin Ren, Santiago Cortes-Gomez, Carlos Miguel PatiÃ±o, Ananya Joshi, Ruiqi Lyu, Jingjing Tang, Alistair Turcan, Khurram Yamin, Steven Wu, Bryan Wilder

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: EMNLP Findings 2025. We release our code at: https://github.com/kkr36/llm-eval/tree/camera-ready

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¯„ä¼°æŒ‡æ ‡ä»¥é¢„æµ‹å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é›¶æ ·æœ¬æ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ ` `æ¦‚ç‡é¢„æµ‹` `æ€§èƒ½è¯„ä¼°` `è¡¨æ ¼æ•°æ®`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹LLMåœ¨é›¶æ ·æœ¬é¢„æµ‹ä»»åŠ¡ä¸­æ€§èƒ½çš„å¯é è¯„ä¼°æ‰‹æ®µï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥åˆ¤æ–­LLMæ˜¯å¦é€‚ç”¨äºç‰¹å®šä»»åŠ¡ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç³»åˆ—æ— éœ€æ ‡æ³¨æ•°æ®çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºé¢„æµ‹LLMåœ¨è¡¨æ ¼é¢„æµ‹ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬æ€§èƒ½ï¼Œä»è€ŒæŒ‡å¯¼ç”¨æˆ·é€‰æ‹©åˆé€‚çš„LLMåº”ç”¨åœºæ™¯ã€‚
3. å®éªŒè¡¨æ˜ï¼Œæå‡ºçš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹LLMåœ¨ä¸åŒä»»åŠ¡ä¸Šçš„é¢„æµ‹æ€§èƒ½ï¼Œä¸ºLLMçš„åº”ç”¨æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä½œä¸ºé›¶æ ·æœ¬æ¨¡å‹åœ¨ç”Ÿæˆä¸ªä½“ç‰¹å¾æ–¹é¢çš„èƒ½åŠ›ï¼Œä¾‹å¦‚ä½œä¸ºé£é™©æ¨¡å‹æˆ–æ‰©å……è°ƒæŸ¥æ•°æ®é›†ã€‚æ ¸å¿ƒé—®é¢˜æ˜¯ï¼šç”¨æˆ·åœ¨ä½•ç§æƒ…å†µä¸‹å¯ä»¥ç¡®ä¿¡LLMèƒ½å¤Ÿä¸ºå…¶ç‰¹å®šä»»åŠ¡æä¾›é«˜è´¨é‡çš„é¢„æµ‹ï¼Ÿä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯¹LLMåœ¨å„ç§è¡¨æ ¼é¢„æµ‹ä»»åŠ¡ä¸­çš„é›¶æ ·æœ¬é¢„æµ‹èƒ½åŠ›è¿›è¡Œäº†å¤§è§„æ¨¡çš„å®è¯ç ”ç©¶ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMçš„æ€§èƒ½å…·æœ‰é«˜åº¦çš„å˜å¼‚æ€§ï¼Œæ— è®ºæ˜¯åœ¨åŒä¸€æ•°æ®é›†å†…çš„ä»»åŠ¡ä¹‹é—´è¿˜æ˜¯åœ¨ä¸åŒæ•°æ®é›†ä¹‹é—´ã€‚ç„¶è€Œï¼Œå½“LLMåœ¨åŸºç¡€é¢„æµ‹ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½æ—¶ï¼Œå…¶é¢„æµ‹çš„æ¦‚ç‡æˆä¸ºä¸ªä½“å±‚é¢å‡†ç¡®æ€§çš„æ›´å¼ºä¿¡å·ã€‚ç„¶åï¼Œæˆ‘ä»¬æ„å»ºäº†æŒ‡æ ‡æ¥é¢„æµ‹LLMåœ¨ä»»åŠ¡å±‚é¢çš„æ€§èƒ½ï¼Œæ—¨åœ¨åŒºåˆ†LLMå¯èƒ½è¡¨ç°è‰¯å¥½çš„ä»»åŠ¡å’Œå®ƒä»¬å¯èƒ½ä¸é€‚åˆçš„ä»»åŠ¡ã€‚æˆ‘ä»¬å‘ç°ï¼Œå…¶ä¸­ä¸€äº›æŒ‡æ ‡ï¼ˆæ¯ä¸ªæŒ‡æ ‡éƒ½åœ¨æ²¡æœ‰æ ‡ç­¾æ•°æ®çš„æƒ…å†µä¸‹è¿›è¡Œè¯„ä¼°ï¼‰ä¸ºLLMåœ¨æ–°ä»»åŠ¡ä¸Šçš„é¢„æµ‹æ€§èƒ½æä¾›äº†å¼ºçƒˆçš„ä¿¡å·ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¦‚ä½•æå‰è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨é›¶æ ·æœ¬æ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨è¡¨æ ¼æ•°æ®é¢„æµ‹åœºæ™¯ä¸‹ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æ‰‹æ®µï¼Œå¯¼è‡´ç”¨æˆ·éš¾ä»¥åˆ¤æ–­LLMæ˜¯å¦é€‚åˆç‰¹å®šä»»åŠ¡ï¼Œä»è€Œå½±å“äº†LLMçš„å®é™…åº”ç”¨æ•ˆæœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ç³»åˆ—æ— éœ€æ ‡æ³¨æ•°æ®çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡èƒ½å¤Ÿåæ˜ LLMåœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é¢„æµ‹èƒ½åŠ›ã€‚é€šè¿‡åˆ†æLLMåœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šçš„è¡¨ç°ï¼Œé¢„æµ‹å…¶åœ¨å®é™…é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ï¼Œä»è€Œä¸ºç”¨æˆ·æä¾›é€‰æ‹©LLMåº”ç”¨åœºæ™¯çš„ä¾æ®ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œé™ä½äº†è¯„ä¼°æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) å®šä¹‰ä¸€ç³»åˆ—è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡åŸºäºLLMåœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šçš„è¡¨ç°ï¼Œä¾‹å¦‚é¢„æµ‹æ¦‚ç‡çš„åˆ†å¸ƒã€ä¸€è‡´æ€§ç­‰ã€‚2) åœ¨å¤šä¸ªè¡¨æ ¼é¢„æµ‹ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒï¼Œè¯„ä¼°LLMçš„é›¶æ ·æœ¬é¢„æµ‹æ€§èƒ½ã€‚3) åˆ†æè¯„ä¼°æŒ‡æ ‡ä¸LLMå®é™…é¢„æµ‹æ€§èƒ½ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œç¡®å®šå“ªäº›æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹LLMçš„æ€§èƒ½ã€‚4) åŸºäºç›¸å…³æ€§åˆ†æç»“æœï¼Œæ„å»ºé¢„æµ‹æ¨¡å‹ï¼Œç”¨äºé¢„æµ‹LLMåœ¨æ–°çš„é¢„æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç³»åˆ—æ— éœ€æ ‡æ³¨æ•°æ®çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹LLMåœ¨é›¶æ ·æœ¬æ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸­çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•é¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œé™ä½äº†è¯„ä¼°æˆæœ¬ï¼Œæé«˜äº†è¯„ä¼°æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜èƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·é€‰æ‹©åˆé€‚çš„LLMåº”ç”¨åœºæ™¯ï¼Œæé«˜LLMçš„å®é™…åº”ç”¨æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) è¯„ä¼°æŒ‡æ ‡çš„è®¾è®¡ï¼Œéœ€è¦å……åˆ†è€ƒè™‘LLMçš„ç‰¹ç‚¹å’Œé¢„æµ‹ä»»åŠ¡çš„ç‰¹ç‚¹ï¼Œé€‰æ‹©èƒ½å¤Ÿåæ˜ LLMé¢„æµ‹èƒ½åŠ›çš„æŒ‡æ ‡ã€‚2) å®éªŒä»»åŠ¡çš„é€‰æ‹©ï¼Œéœ€è¦è¦†ç›–ä¸åŒçš„è¡¨æ ¼æ•°æ®ç±»å‹å’Œé¢„æµ‹ä»»åŠ¡ï¼Œä»¥ä¿è¯è¯„ä¼°ç»“æœçš„æ³›åŒ–èƒ½åŠ›ã€‚3) ç›¸å…³æ€§åˆ†ææ–¹æ³•çš„é€‰æ‹©ï¼Œéœ€è¦é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³•ï¼Œä»¥å‡†ç¡®è¯„ä¼°è¯„ä¼°æŒ‡æ ‡ä¸LLMå®é™…é¢„æµ‹æ€§èƒ½ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ç ”ç©¶å‘ç°ï¼ŒLLMçš„æ€§èƒ½åœ¨ä¸åŒä»»åŠ¡å’Œæ•°æ®é›†ä¸Šå·®å¼‚å¾ˆå¤§ã€‚ç„¶è€Œï¼Œå½“LLMåœ¨åŸºç¡€é¢„æµ‹ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½æ—¶ï¼Œå…¶é¢„æµ‹æ¦‚ç‡èƒ½æ›´æœ‰æ•ˆåœ°åæ˜ ä¸ªä½“å±‚é¢çš„å‡†ç¡®æ€§ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè®ºæ–‡æå‡ºçš„æ— éœ€æ ‡ç­¾æ•°æ®çš„è¯„ä¼°æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆé¢„æµ‹LLMåœ¨æ–°çš„é¢„æµ‹ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä¸ºLLMçš„åº”ç”¨æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œä¾‹å¦‚é£é™©è¯„ä¼°ã€å¸‚åœºè°ƒç ”ã€åŒ»ç–—è¯Šæ–­ç­‰ã€‚é€šè¿‡æå‰è¯„ä¼°LLMåœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„é¢„æµ‹æ€§èƒ½ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·é€‰æ‹©åˆé€‚çš„LLMåº”ç”¨åœºæ™¯ï¼Œæé«˜é¢„æµ‹å‡†ç¡®ç‡ï¼Œé™ä½å†³ç­–é£é™©ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥ä¿ƒè¿›LLMåœ¨å®é™…åº”ç”¨ä¸­çš„æ¨å¹¿ï¼ŒåŠ é€Ÿäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent work has investigated the capabilities of large language models (LLMs) as zero-shot models for generating individual-level characteristics (e.g., to serve as risk models or augment survey datasets). However, when should a user have confidence that an LLM will provide high-quality predictions for their particular task? To address this question, we conduct a large-scale empirical study of LLMs' zero-shot predictive capabilities across a wide range of tabular prediction tasks. We find that LLMs' performance is highly variable, both on tasks within the same dataset and across different datasets. However, when the LLM performs well on the base prediction task, its predicted probabilities become a stronger signal for individual-level accuracy. Then, we construct metrics to predict LLMs' performance at the task level, aiming to distinguish between tasks where LLMs may perform well and where they are likely unsuitable. We find that some of these metrics, each of which are assessed without labeled data, yield strong signals of LLMs' predictive performance on new tasks.

