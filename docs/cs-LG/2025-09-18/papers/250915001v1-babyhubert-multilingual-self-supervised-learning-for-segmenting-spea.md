---
layout: default
title: BabyHuBERT: Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings
---

# BabyHuBERT: Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15001" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15001v1</a>
  <a href="https://arxiv.org/pdf/2509.15001.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15001v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15001v1', 'BabyHuBERT: Multilingual Self-Supervised Learning for Segmenting Speakers in Child-Centered Long-Form Recordings')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: ThÃ©o Charlot, Tarek Kunze, Maxime Poli, Alejandrina Cristia, Emmanuel Dupoux, Marvin Lavechin

**åˆ†ç±»**: eess.AS, cs.LG, cs.SD

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: 5 pages, 1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BabyHuBERTï¼šé¢å‘å„¿ç«¥è¯­éŸ³çš„é•¿æ—¶å½•éŸ³è¯´è¯äººåˆ†å‰²å¤šè¯­ç§è‡ªç›‘ç£å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å„¿ç«¥è¯­éŸ³` `è‡ªç›‘ç£å­¦ä¹ ` `è¯´è¯äººåˆ†å‰²` `å¤šè¯­ç§` `é•¿æ—¶å½•éŸ³` `HuBERT` `è¯­éŸ³è¡¨å¾` `è¯­è¨€å‘å±•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­éŸ³æ¨¡å‹åœ¨å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³ä¸Šè¡¨ç°ä¸ä½³ï¼Œå› ä¸ºè¿™äº›æ¨¡å‹ä¸»è¦åœ¨å¹²å‡€çš„æˆäººè¯­éŸ³æ•°æ®ä¸Šè®­ç»ƒï¼Œä¸å„¿ç«¥è¯­éŸ³å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚
2. BabyHuBERTçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å¤§é‡çš„å¤šè¯­ç§å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ï¼Œä»è€Œå­¦ä¹ åˆ°æ›´é€‚åˆå„¿ç«¥è¯­éŸ³çš„è¡¨å¾ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒBabyHuBERTåœ¨è¯´è¯äººåˆ†å‰²ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨ä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€ä¸Šï¼ŒF1åˆ†æ•°æå‡æ˜æ˜¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³å¯¹äºç ”ç©¶æ—©æœŸè¯­è¨€å‘å±•è‡³å…³é‡è¦ï¼Œä½†ç°æœ‰åœ¨å¹²å‡€æˆäººæ•°æ®ä¸Šè®­ç»ƒçš„è¯­éŸ³æ¨¡å‹ç”±äºå£°å­¦å’Œè¯­è¨€å·®å¼‚è¡¨ç°ä¸ä½³ã€‚æˆ‘ä»¬æå‡ºäº†BabyHuBERTï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨è¶…è¿‡40ç§è¯­è¨€çš„13,000å°æ—¶å¤šè¯­ç§å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³ä¸Šè®­ç»ƒçš„è‡ªç›‘ç£è¯­éŸ³è¡¨å¾æ¨¡å‹ã€‚æˆ‘ä»¬åœ¨è¯´è¯äººåˆ†å‰²ä»»åŠ¡ä¸Šè¯„ä¼°äº†BabyHuBERTï¼Œå³è¯†åˆ«ç›®æ ‡å„¿ç«¥ä½•æ—¶è¯´è¯ï¼Œä»¥åŠä½•æ—¶æ˜¯å¥³æ€§æˆäººã€ç”·æ€§æˆäººæˆ–å…¶ä»–å„¿ç«¥åœ¨è¯´è¯â€”â€”è¿™æ˜¯åˆ†æè‡ªç„¶è¯­è¨€ä½“éªŒçš„åŸºæœ¬é¢„å¤„ç†æ­¥éª¤ã€‚åœ¨å…­ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šï¼ŒBabyHuBERTå®ç°äº†52.1%åˆ°74.4%çš„F1åˆ†æ•°ï¼Œå§‹ç»ˆä¼˜äºW2V2-LL4300ï¼ˆåœ¨è‹±è¯­é•¿æ—¶å½•éŸ³ä¸Šè®­ç»ƒï¼‰å’Œæ ‡å‡†HuBERTï¼ˆåœ¨å¹²å‡€æˆäººè¯­éŸ³ä¸Šè®­ç»ƒï¼‰ã€‚å€¼å¾—æ³¨æ„çš„æ”¹è¿›åŒ…æ‹¬åœ¨ç“¦åŠªé˜¿å›¾è¯­æ–™åº“ä¸Šè¶…è¿‡HuBERT 13.2ä¸ªç»å¯¹F1ç‚¹ï¼Œåœ¨æ‰€ç½—é—¨ç¾¤å²›è¯­æ–™åº“ä¸Šè¶…è¿‡15.9ä¸ªç‚¹ï¼Œè¯æ˜äº†å…¶åœ¨ä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€ä¸Šçš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡å…±äº«ä»£ç å’Œæ¨¡å‹ï¼ŒBabyHuBERTä½œä¸ºå„¿ç«¥è¯­éŸ³ç ”ç©¶çš„åŸºç¡€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¯¹å„ç§ä¸‹æ¸¸ä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³ä¸­çš„è¯´è¯äººåˆ†å‰²é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚åœ¨æˆäººè¯­éŸ³ä¸Šè®­ç»ƒçš„HuBERTï¼Œåœ¨å¤„ç†å„¿ç«¥è¯­éŸ³æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œå› ä¸ºå„¿ç«¥è¯­éŸ³çš„å£°å­¦ç‰¹å¾ä¸æˆäººè¯­éŸ³å·®å¼‚è¾ƒå¤§ï¼Œä¸”é•¿æ—¶å½•éŸ³é€šå¸¸åŒ…å«å™ªå£°å’Œå¤šç§è¯´è¯äººã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•ï¼Œåœ¨å¤§è§„æ¨¡å¤šè¯­ç§å„¿ç«¥è¯­éŸ³æ•°æ®ä¸Šé¢„è®­ç»ƒä¸€ä¸ªè¯­éŸ³è¡¨å¾æ¨¡å‹ã€‚é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œæ¨¡å‹å¯ä»¥å­¦ä¹ åˆ°å„¿ç«¥è¯­éŸ³çš„å†…åœ¨ç»“æ„å’Œç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”å„¿ç«¥è¯­éŸ³çš„ç‰¹ç‚¹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBabyHuBERTçš„æ•´ä½“æ¡†æ¶åŸºäºHuBERTæ¨¡å‹ï¼Œä½†å…³é”®åœ¨äºå…¶è®­ç»ƒæ•°æ®ã€‚é¦–å…ˆï¼Œæ”¶é›†äº†13,000å°æ—¶çš„å¤šè¯­ç§å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³æ•°æ®ã€‚ç„¶åï¼Œä½¿ç”¨HuBERTçš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œå¯¹è¿™äº›æ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚é¢„è®­ç»ƒå®Œæˆåï¼Œå¯ä»¥å°†BabyHuBERTæ¨¡å‹ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼Œå¦‚è¯´è¯äººåˆ†å‰²ï¼Œé€šè¿‡å¾®è°ƒæ¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šBabyHuBERTæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶è®­ç»ƒæ•°æ®ã€‚å®ƒæ˜¯ç¬¬ä¸€ä¸ªåœ¨å¦‚æ­¤å¤§è§„æ¨¡çš„å¤šè¯­ç§å„¿ç«¥è¯­éŸ³é•¿æ—¶å½•éŸ³ä¸Šè®­ç»ƒçš„è‡ªç›‘ç£è¯­éŸ³è¡¨å¾æ¨¡å‹ã€‚è¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å…·æ³›åŒ–æ€§å’Œé²æ£’æ€§çš„å„¿ç«¥è¯­éŸ³ç‰¹å¾ï¼Œä»è€Œåœ¨è¯´è¯äººåˆ†å‰²ç­‰ä»»åŠ¡ä¸Šå–å¾—æ›´å¥½çš„æ€§èƒ½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒBabyHuBERTæ›´å…³æ³¨å„¿ç«¥è¯­éŸ³çš„ç‰¹æ€§ï¼Œè€Œä¸æ˜¯ç®€å•åœ°å°†æˆäººè¯­éŸ³æ¨¡å‹åº”ç”¨äºå„¿ç«¥è¯­éŸ³ã€‚

**å…³é”®è®¾è®¡**ï¼šBabyHuBERTçš„å…³é”®è®¾è®¡åœ¨äºå…¶è®­ç»ƒæ•°æ®çš„é€‰æ‹©å’Œé¢„å¤„ç†ã€‚è®ºæ–‡ä½œè€…ç²¾å¿ƒæ”¶é›†äº†æ¥è‡ª40å¤šç§è¯­è¨€çš„å„¿ç«¥è¯­éŸ³æ•°æ®ï¼Œå¹¶å¯¹æ•°æ®è¿›è¡Œäº†æ¸…æ´—å’Œæ ‡æ³¨ã€‚æ­¤å¤–ï¼Œè®ºæ–‡ä½œè€…è¿˜æ¢ç´¢äº†ä¸åŒçš„è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œä»¥æé«˜æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡å’Œæ€§èƒ½ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ä¸åŸå§‹HuBERTæ¨¡å‹ä¿æŒä¸€è‡´ï¼Œé‡ç‚¹åœ¨äºåˆ©ç”¨å¤§è§„æ¨¡å„¿ç«¥è¯­éŸ³æ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

BabyHuBERTåœ¨å…­ä¸ªä¸åŒçš„æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¡¨æ˜å…¶åœ¨è¯´è¯äººåˆ†å‰²ä»»åŠ¡ä¸Šå§‹ç»ˆä¼˜äºW2V2-LL4300å’Œæ ‡å‡†HuBERTã€‚åœ¨ç“¦åŠªé˜¿å›¾è¯­æ–™åº“ä¸Šï¼ŒBabyHuBERTçš„F1åˆ†æ•°æ¯”HuBERTé«˜å‡º13.2ä¸ªç™¾åˆ†ç‚¹ï¼›åœ¨æ‰€ç½—é—¨ç¾¤å²›è¯­æ–™åº“ä¸Šï¼ŒBabyHuBERTçš„F1åˆ†æ•°æ¯”HuBERTé«˜å‡º15.9ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒBabyHuBERTåœ¨å¤„ç†ä»£è¡¨æ€§ä¸è¶³çš„è¯­è¨€æ—¶å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BabyHuBERTåœ¨å„¿ç«¥è¯­è¨€å‘å±•ç ”ç©¶ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºè‡ªåŠ¨åˆ†æå„¿ç«¥çš„è¯­è¨€ç¯å¢ƒï¼Œä¾‹å¦‚ï¼Œè¯†åˆ«å„¿ç«¥ä¸å“ªäº›äººäº’åŠ¨ï¼Œä»¥åŠä»–ä»¬è¯´äº†ä»€ä¹ˆã€‚è¿™æœ‰åŠ©äºç ”ç©¶äººå‘˜æ›´å¥½åœ°äº†è§£å„¿ç«¥çš„è¯­è¨€å‘å±•è¿‡ç¨‹ï¼Œå¹¶ä¸ºæ—©æœŸè¯­è¨€å¹²é¢„æä¾›æ”¯æŒã€‚æ­¤å¤–ï¼ŒBabyHuBERTè¿˜å¯ä»¥åº”ç”¨äºå„¿ç«¥è¯­éŸ³è¯†åˆ«ã€è¯­éŸ³åˆæˆç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Child-centered long-form recordings are essential for studying early language development, but existing speech models trained on clean adult data perform poorly due to acoustic and linguistic differences. We introduce BabyHuBERT, the first self-supervised speech representation model trained on 13,000 hours of multilingual child-centered long-form recordings spanning over 40 languages. We evaluate BabyHuBERT on speaker segmentation, identifying when target children speak versus female adults, male adults, or other children -- a fundamental preprocessing step for analyzing naturalistic language experiences. BabyHuBERT achieves F1-scores from 52.1% to 74.4% across six diverse datasets, consistently outperforming W2V2-LL4300 (trained on English long-forms) and standard HuBERT (trained on clean adult speech). Notable improvements include 13.2 absolute F1 points over HuBERT on Vanuatu and 15.9 points on Solomon Islands corpora, demonstrating effectiveness on underrepresented languages. By sharing code and models, BabyHuBERT serves as a foundation model for child speech research, enabling fine-tuning on diverse downstream tasks.

