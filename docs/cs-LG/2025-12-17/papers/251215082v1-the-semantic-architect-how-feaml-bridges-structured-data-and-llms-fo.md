---
layout: default
title: The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks
---

# The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.15082" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.15082v1</a>
  <a href="https://arxiv.org/pdf/2512.15082.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.15082v1" onclick="toggleFavorite(this, '2512.15082v1', 'The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Wanfu Gao, Zebin He, Jun Gao

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-17

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FEAMLï¼šåˆ©ç”¨LLMæ¡¥æ¥ç»“æ„åŒ–æ•°æ®ä¸å¤šæ ‡ç­¾ä»»åŠ¡ï¼Œå®ç°è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ ‡ç­¾å­¦ä¹ ` `ç‰¹å¾å·¥ç¨‹` `å¤§å‹è¯­è¨€æ¨¡å‹` `è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ` `ä»£ç ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºLLMçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•éš¾ä»¥å»ºæ¨¡å¤šæ ‡ç­¾å­¦ä¹ ä¸­å¤æ‚çš„æ ‡ç­¾ä¾èµ–å…³ç³»ï¼Œä¸”ç¼ºä¹é’ˆå¯¹æ€§ä¼˜åŒ–ã€‚
2. FEAMLåˆ©ç”¨LLMçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œç»“åˆå…ƒæ•°æ®å’Œæ ‡ç­¾å…±ç°çŸ©é˜µï¼Œå¼•å¯¼LLMç†è§£æ•°æ®ç‰¹å¾ä¸ä»»åŠ¡ç›®æ ‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒFEAMLåœ¨å¤šä¸ªå¤šæ ‡ç­¾æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–ç‰¹å¾å·¥ç¨‹æ–¹æ³•ï¼Œå®ç°äº†æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•å°šæœªåº”ç”¨äºå¤šæ ‡ç­¾å­¦ä¹ ä»»åŠ¡ã€‚å®ƒä»¬ç¼ºä¹å¯¹å¤æ‚æ ‡ç­¾ä¾èµ–å…³ç³»å»ºæ¨¡çš„èƒ½åŠ›ï¼Œå¹¶ä¸”æ²¡æœ‰é’ˆå¯¹å¤šæ ‡ç­¾ä»»åŠ¡çš„ç‰¹æ€§è¿›è¡Œä¸“é—¨è°ƒæ•´ã€‚ä¸ºäº†è§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºå¤šæ ‡ç­¾å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç‰¹å¾å·¥ç¨‹æ–¹æ³•â€”â€”å¤šæ ‡ç­¾å­¦ä¹ çš„ç‰¹å¾å·¥ç¨‹è‡ªåŠ¨åŒ–ï¼ˆFEAMLï¼‰ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨LLMçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ã€‚é€šè¿‡åˆ©ç”¨å…ƒæ•°æ®å’Œæ ‡ç­¾å…±ç°çŸ©é˜µï¼Œå¼•å¯¼LLMç†è§£æ•°æ®ç‰¹å¾å’Œä»»åŠ¡ç›®æ ‡ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œç”Ÿæˆé«˜è´¨é‡çš„ç‰¹å¾ã€‚æ–°ç”Ÿæˆçš„ç‰¹å¾åœ¨æ¨¡å‹ç²¾åº¦æ–¹é¢è¿›è¡Œè¯„ä¼°ï¼Œä»¥è¯„ä¼°å…¶æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä½¿ç”¨Pearsonç›¸å…³ç³»æ•°æ¥æ£€æµ‹å†—ä½™ã€‚FEAMLè¿›ä¸€æ­¥å°†è¯„ä¼°ç»“æœä½œä¸ºåé¦ˆï¼Œä»¥é©±åŠ¨LLMåœ¨åç»­è¿­ä»£ä¸­ä¸æ–­ä¼˜åŒ–ä»£ç ç”Ÿæˆã€‚é€šè¿‡å°†LLMä¸åé¦ˆæœºåˆ¶ç›¸ç»“åˆï¼ŒFEAMLå®ç°äº†é«˜æ•ˆã€å¯è§£é‡Šå’Œè‡ªæˆ‘æ”¹è¿›çš„ç‰¹å¾å·¥ç¨‹èŒƒå¼ã€‚åœ¨å„ç§å¤šæ ‡ç­¾æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„FEAMLä¼˜äºå…¶ä»–ç‰¹å¾å·¥ç¨‹æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ ‡ç­¾å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œç°æœ‰åŸºäºLLMçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•æ— æ³•æœ‰æ•ˆå»ºæ¨¡æ ‡ç­¾ä¾èµ–å…³ç³»ï¼Œä¸”ç¼ºä¹é’ˆå¯¹æ€§ä¼˜åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸æ— æ³•å……åˆ†åˆ©ç”¨å¤šæ ‡ç­¾æ•°æ®çš„ç‰¹æ€§ï¼Œå¯¼è‡´ç‰¹å¾å·¥ç¨‹çš„æ•ˆç‡å’Œæ•ˆæœå—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ï¼Œç»“åˆå¤šæ ‡ç­¾æ•°æ®çš„å…ƒæ•°æ®å’Œæ ‡ç­¾å…±ç°çŸ©é˜µï¼Œå¼•å¯¼LLMç†è§£æ•°æ®ç‰¹å¾å’Œä»»åŠ¡ç›®æ ‡ä¹‹é—´çš„å…³ç³»ï¼Œä»è€Œè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„ç‰¹å¾ã€‚é€šè¿‡åé¦ˆæœºåˆ¶ï¼Œä¸æ–­ä¼˜åŒ–LLMçš„ä»£ç ç”Ÿæˆè¿‡ç¨‹ï¼Œå®ç°ç‰¹å¾å·¥ç¨‹çš„è‡ªåŠ¨åŒ–å’Œè‡ªæ”¹è¿›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFEAMLçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) æ•°æ®å‡†å¤‡ï¼šæ”¶é›†å¤šæ ‡ç­¾æ•°æ®é›†çš„å…ƒæ•°æ®å’Œè®¡ç®—æ ‡ç­¾å…±ç°çŸ©é˜µã€‚2) LLMå¼•å¯¼ï¼šåˆ©ç”¨å…ƒæ•°æ®å’Œæ ‡ç­¾å…±ç°çŸ©é˜µï¼Œå¼•å¯¼LLMç”Ÿæˆç‰¹å¾å·¥ç¨‹ä»£ç ã€‚3) ç‰¹å¾è¯„ä¼°ï¼šè¯„ä¼°æ–°ç”Ÿæˆçš„ç‰¹å¾åœ¨æ¨¡å‹ç²¾åº¦æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä½¿ç”¨Pearsonç›¸å…³ç³»æ•°æ£€æµ‹å†—ä½™ã€‚4) åé¦ˆä¼˜åŒ–ï¼šå°†è¯„ä¼°ç»“æœä½œä¸ºåé¦ˆï¼Œé©±åŠ¨LLMåœ¨åç»­è¿­ä»£ä¸­ä¸æ–­ä¼˜åŒ–ä»£ç ç”Ÿæˆã€‚

**å…³é”®åˆ›æ–°**ï¼šFEAMLçš„å…³é”®åˆ›æ–°åœ¨äºå°†LLMçš„ä»£ç ç”Ÿæˆèƒ½åŠ›ä¸å¤šæ ‡ç­¾æ•°æ®çš„ç‰¹æ€§ç›¸ç»“åˆï¼Œå®ç°äº†ä¸€ç§è‡ªåŠ¨åŒ–ã€å¯è§£é‡Šå’Œè‡ªæ”¹è¿›çš„ç‰¹å¾å·¥ç¨‹èŒƒå¼ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFEAMLèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ ‡ç­¾æ•°æ®çš„æ ‡ç­¾ä¾èµ–å…³ç³»ï¼Œå¹¶æ ¹æ®è¯„ä¼°ç»“æœä¸æ–­ä¼˜åŒ–ç‰¹å¾å·¥ç¨‹è¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•åˆ©ç”¨å…ƒæ•°æ®å’Œæ ‡ç­¾å…±ç°çŸ©é˜µå¼•å¯¼LLMç”Ÿæˆç‰¹å¾å·¥ç¨‹ä»£ç ï¼›2) å¦‚ä½•è®¾è®¡ç‰¹å¾è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥è¯„ä¼°ç‰¹å¾çš„æœ‰æ•ˆæ€§å’Œå†—ä½™æ€§ï¼›3) å¦‚ä½•è®¾è®¡åé¦ˆæœºåˆ¶ï¼Œå°†è¯„ä¼°ç»“æœåé¦ˆç»™LLMï¼Œä»¥é©±åŠ¨å…¶ä¸æ–­ä¼˜åŒ–ä»£ç ç”Ÿæˆã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰æŠ€æœ¯ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15082v1/AFT1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15082v1/FEAML18.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.15082v1/prompt.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFEAMLåœ¨å¤šä¸ªå¤šæ ‡ç­¾æ•°æ®é›†ä¸Šä¼˜äºå…¶ä»–ç‰¹å¾å·¥ç¨‹æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨æ‘˜è¦ä¸­æœªç»™å‡ºï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚ä½†æ€»ä½“è€Œè¨€ï¼ŒFEAMLå±•ç°äº†å…¶åœ¨å¤šæ ‡ç­¾ç‰¹å¾å·¥ç¨‹æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FEAMLå¯åº”ç”¨äºå„ç§å¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€å›¾åƒåˆ†ç±»ã€ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿè‡ªåŠ¨ç”Ÿæˆé«˜è´¨é‡çš„ç‰¹å¾ï¼Œæé«˜å¤šæ ‡ç­¾åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½ï¼Œé™ä½äººå·¥ç‰¹å¾å·¥ç¨‹çš„æˆæœ¬ã€‚æœªæ¥ï¼ŒFEAMLæœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œå¹¶ä¸å…¶ä»–è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ æŠ€æœ¯ç›¸ç»“åˆï¼Œå®ç°æ›´é«˜æ•ˆã€æ›´æ™ºèƒ½çš„æœºå™¨å­¦ä¹ æµç¨‹ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.

