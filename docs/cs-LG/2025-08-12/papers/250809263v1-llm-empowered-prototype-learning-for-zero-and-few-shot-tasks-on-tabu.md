---
layout: default
title: LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data
---

# LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09263" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09263v1</a>
  <a href="https://arxiv.org/pdf/2508.09263.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09263v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09263v1', 'LLM Empowered Prototype Learning for Zero and Few-Shot Tasks on Tabular Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peng Wang, Dongsheng Wang, He Zhao, Hangting Ye, Dandan Guo, Yi Chang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºLLMçš„åŸå‹å­¦ä¹ æ¡†æ¶ä»¥è§£å†³è¡¨æ ¼æ•°æ®çš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `åŸå‹å­¦ä¹ ` `é›¶æ ·æœ¬å­¦ä¹ ` `å°‘æ ·æœ¬å­¦ä¹ ` `è¡¨æ ¼æ•°æ®å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬åœºæ™¯ä¸­åˆ©ç”¨LLMçš„èƒ½åŠ›ä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å¾ç”Ÿæˆå’Œæ¨¡å‹è®­ç»ƒæ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºLLMçš„åŸå‹ä¼°è®¡æ¡†æ¶ï¼Œé€šè¿‡æ— ç¤ºä¾‹æç¤ºç”Ÿæˆç‰¹å¾å€¼ï¼Œæ„å»ºé›¶æ ·æœ¬åŸå‹ï¼Œé¿å…äº†ä¼ ç»Ÿè®­ç»ƒè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è¡¨æ ¼å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„çªç ´ä¸ºè¡¨æ ¼æ•°æ®å»ºæ¨¡çš„æ·±å…¥ç ”ç©¶æä¾›äº†æ–°çš„æœºé‡ã€‚ç„¶è€Œï¼Œåœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬åœºæ™¯ä¸­æœ‰æ•ˆåˆ©ç”¨å…ˆè¿›çš„LLMä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºLLMçš„åŸå‹ä¼°è®¡æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡æ— ç¤ºä¾‹æç¤ºæŸ¥è¯¢LLMç”Ÿæˆç‰¹å¾å€¼ï¼Œè¿™ä»…ä¾èµ–äºä»»åŠ¡å’Œç‰¹å¾æè¿°ã€‚åˆ©ç”¨LLMç”Ÿæˆçš„ç‰¹å¾å€¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»¥æ— è®­ç»ƒçš„æ–¹å¼æ„å»ºé›¶æ ·æœ¬åŸå‹ï¼Œå¹¶é€šè¿‡èåˆå°‘æ ·æœ¬è¿›ä¸€æ­¥å¢å¼ºï¼Œé¿å…äº†è®­ç»ƒåˆ†ç±»å™¨æˆ–å¾®è°ƒLLMçš„éœ€æ±‚ã€‚å¾—ç›Šäºæ— ç¤ºä¾‹æç¤ºå’ŒåŸå‹ä¼°è®¡ï¼Œæˆ‘ä»¬çš„æ¡†æ¶ç»•è¿‡äº†åŸºäºç¤ºä¾‹æç¤ºå¸¦æ¥çš„é™åˆ¶ï¼Œæä¾›äº†ä¸€ä¸ªå¯æ‰©å±•ä¸”ç¨³å¥çš„è§£å†³æ–¹æ¡ˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬çš„è¡¨æ ¼å­¦ä¹ ä¸­å…·æœ‰æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬åœºæ™¯ä¸­æœ‰æ•ˆåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œè¡¨æ ¼æ•°æ®å»ºæ¨¡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºç¤ºä¾‹æç¤ºï¼Œé™åˆ¶äº†æ¨¡å‹çš„çµæ´»æ€§å’Œæ‰©å±•æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ— ç¤ºä¾‹æç¤ºæŸ¥è¯¢LLMç”Ÿæˆç‰¹å¾å€¼ï¼Œè¿™æ ·å¯ä»¥åœ¨æ²¡æœ‰è®­ç»ƒæ ·æœ¬çš„æƒ…å†µä¸‹æ„å»ºé›¶æ ·æœ¬åŸå‹ï¼Œå¹¶é€šè¿‡å°‘æ ·æœ¬è¿›è¡Œå¢å¼ºã€‚è¿™ç§è®¾è®¡é¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„è®­ç»ƒå’Œå¾®è°ƒæ­¥éª¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç¬¬ä¸€ï¼Œä½¿ç”¨æ— ç¤ºä¾‹æç¤ºä»LLMä¸­ç”Ÿæˆç‰¹å¾å€¼ï¼›ç¬¬äºŒï¼ŒåŸºäºç”Ÿæˆçš„ç‰¹å¾å€¼æ„å»ºé›¶æ ·æœ¬åŸå‹ï¼Œå¹¶é€šè¿‡èåˆå°‘æ ·æœ¬è¿›è¡Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†æ— ç¤ºä¾‹æç¤ºçš„æ¦‚å¿µï¼Œä½¿å¾—åŸå‹ä¼°è®¡ä¸å†ä¾èµ–äºç¤ºä¾‹ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é€‚åº”æ€§å’Œå¯æ‰©å±•æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ä¸€åˆ›æ–°æ˜¾è‘—é™ä½äº†å¯¹è®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ¨¡å‹é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯­æ¥å¼•å¯¼LLMç”Ÿæˆç‰¹å¾å€¼ï¼ŒæŸå¤±å‡½æ•°åˆ™ä¾§é‡äºåŸå‹ä¸æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼åº¦åº¦é‡ï¼Œç¡®ä¿ç”Ÿæˆçš„åŸå‹å…·æœ‰è¾ƒå¥½çš„ä»£è¡¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªé›¶æ ·æœ¬å’Œå°‘æ ·æœ¬è¡¨æ ¼å­¦ä¹ ä»»åŠ¡ä¸­å‡ä¼˜äºä¼ ç»ŸåŸºçº¿ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†æ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èã€åŒ»ç–—å’Œå¸‚åœºåˆ†æç­‰éœ€è¦å¤„ç†è¡¨æ ¼æ•°æ®çš„åœºæ™¯ã€‚é€šè¿‡æä¾›ä¸€ç§é«˜æ•ˆçš„é›¶æ ·æœ¬å’Œå°‘æ ·æœ¬å­¦ä¹ æ–¹æ³•ï¼Œå¯ä»¥å¤§å¹…é™ä½æ•°æ®æ ‡æ³¨æˆæœ¬ï¼Œæé«˜æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šçš„é€‚åº”èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent breakthroughs in large language models (LLMs) have opened the door to in-depth investigation of their potential in tabular data modeling. However, effectively utilizing advanced LLMs in few-shot and even zero-shot scenarios is still challenging. To this end, we propose a novel LLM-based prototype estimation framework for tabular learning. Our key idea is to query the LLM to generate feature values based example-free prompt, which solely relies on task and feature descriptions. With the feature values generated by LLM, we can build a zero-shot prototype in a training-free manner, which can be further enhanced by fusing few-shot samples, avoiding training a classifier or finetuning the LLMs. Thanks to the example-free prompt and prototype estimation, ours bypasses the constraints brought by the example-based prompt, providing a scalable and robust framework. Extensive experiments demonstrate the effectiveness of ours in zero and few-shot tabular learning.

