---
layout: default
title: $\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models
---

# $\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08657" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08657v1</a>
  <a href="https://arxiv.org/pdf/2508.08657.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08657v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08657v1', '$\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiaxin Ju, Yizhen Zheng, Huan Yee Koh, Can Wang, Shirui Pan

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: IJCAI 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMÂ²LLMä»¥è§£å†³åˆ†å­å±æ€§é¢„æµ‹çš„å¤šè§†è§’é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆ†å­è¡¨ç¤º` `å¤§è¯­è¨€æ¨¡å‹` `å¤šè§†è§’å­¦ä¹ ` `å›¾ç¥ç»ç½‘ç»œ` `è¯ç‰©å‘ç°` `ææ–™ç§‘å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åˆ†å­è¡¨ç¤ºæ–¹æ³•åœ¨ç‰¹å¾æå–ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å¾€å¾€å¿½è§†äº†ä¸°å¯Œçš„è¯­ä¹‰å’Œä¸Šä¸‹æ–‡çŸ¥è¯†ï¼Œå¯¼è‡´é¢„æµ‹æ€§èƒ½å—é™ã€‚
2. MÂ²LLMé€šè¿‡æ•´åˆåˆ†å­ç»“æ„ã€ä»»åŠ¡å’Œè§„åˆ™ä¸‰ä¸ªè§†è§’ï¼ŒåŠ¨æ€èåˆä¿¡æ¯ä»¥é€‚åº”ä¸åŒä»»åŠ¡éœ€æ±‚ï¼Œä»è€Œæå‡åˆ†å­è¡¨ç¤ºèƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMÂ²LLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åœ¨åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‡†ç¡®çš„åˆ†å­å±æ€§é¢„æµ‹æ˜¯åŒ–å­¦ã€ææ–™ç§‘å­¦å’Œè¯ç‰©å‘ç°ç­‰é¢†åŸŸçš„é‡è¦æŒ‘æˆ˜ã€‚ç°æœ‰çš„åˆ†å­è¡¨ç¤ºæ–¹æ³•ï¼Œå¦‚æŒ‡çº¹å’Œå›¾ç¥ç»ç½‘ç»œï¼Œè™½ç„¶åœ¨ç‰¹å¾æå–ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å¾€å¾€å¿½è§†äº†ä¸°å¯Œçš„è¯­ä¹‰å’Œä¸Šä¸‹æ–‡çŸ¥è¯†ã€‚æœ¬æ–‡æå‡ºäº†MÂ²LLMï¼Œä¸€ä¸ªå¤šè§†è§’æ¡†æ¶ï¼Œç»“åˆäº†åˆ†å­ç»“æ„è§†è§’ã€åˆ†å­ä»»åŠ¡è§†è§’å’Œåˆ†å­è§„åˆ™è§†è§’ï¼ŒåŠ¨æ€èåˆä»¥é€‚åº”ä»»åŠ¡éœ€æ±‚ã€‚å®éªŒè¡¨æ˜ï¼ŒMÂ²LLMåœ¨å¤šä¸ªåˆ†ç±»å’Œå›å½’ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨ç”Ÿæˆåˆ†å­åµŒå…¥å’Œç‰¹å¾ç­–åˆ’æ–¹é¢çš„å“è¶Šèƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åˆ†å­å±æ€§é¢„æµ‹ä¸­çš„ä¿¡æ¯ä¸è¶³é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¦‚æŒ‡çº¹å’Œå›¾ç¥ç»ç½‘ç»œæœªèƒ½å……åˆ†åˆ©ç”¨ä¸°å¯Œçš„è¯­ä¹‰å’Œä¸Šä¸‹æ–‡çŸ¥è¯†ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMÂ²LLMæ¡†æ¶é€šè¿‡æ•´åˆåˆ†å­ç»“æ„ã€ä»»åŠ¡å’Œè§„åˆ™ä¸‰ä¸ªè§†è§’ï¼ŒåŠ¨æ€èåˆè¿™äº›è§†è§’çš„ä¿¡æ¯ï¼Œä»¥ä¾¿æ›´å…¨é¢åœ°ç†è§£åˆ†å­ç‰¹æ€§ï¼Œä»è€Œæå‡é¢„æµ‹å‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMÂ²LLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåˆ†å­ç»“æ„è§†è§’æ¨¡å—ã€åˆ†å­ä»»åŠ¡è§†è§’æ¨¡å—å’Œåˆ†å­è§„åˆ™è§†è§’æ¨¡å—ã€‚è¿™äº›æ¨¡å—é€šè¿‡åŠ¨æ€èåˆæœºåˆ¶ç»“åˆåœ¨ä¸€èµ·ï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡éœ€æ±‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šMÂ²LLMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶å¤šè§†è§’èåˆæ–¹æ³•ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’ŒçŸ¥è¯†åº“ï¼Œæ˜¾è‘—æå‡åˆ†å­è¡¨ç¤ºçš„ä¸°å¯Œæ€§å’Œå‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒMÂ²LLMé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å¤šè§†è§’èåˆæ•ˆæœï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥ç¡®ä¿å„è§†è§’ä¿¡æ¯çš„æœ‰æ•ˆæ•´åˆå’Œåˆ©ç”¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMÂ²LLMåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸Šï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦15%-20%çš„é¢„æµ‹å‡†ç¡®ç‡ï¼Œå±•ç¤ºäº†å…¶å¼ºå¤§çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯ç‰©å‘ç°ã€ææ–™ç§‘å­¦å’ŒåŒ–å­¦ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©ç§‘å­¦å®¶æ›´å‡†ç¡®åœ°é¢„æµ‹åˆ†å­å±æ€§ï¼Œä»è€ŒåŠ é€Ÿæ–°ææ–™å’Œè¯ç‰©çš„å¼€å‘ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨åˆ†å­è®¾è®¡çš„æ™ºèƒ½åŒ–è¿›ç¨‹ï¼Œæå‡ç ”ç©¶æ•ˆç‡å’Œæˆæœè´¨é‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Accurate molecular property prediction is a critical challenge with wide-ranging applications in chemistry, materials science, and drug discovery. Molecular representation methods, including fingerprints and graph neural networks (GNNs), achieve state-of-the-art results by effectively deriving features from molecular structures. However, these methods often overlook decades of accumulated semantic and contextual knowledge. Recent advancements in large language models (LLMs) demonstrate remarkable reasoning abilities and prior knowledge across scientific domains, leading us to hypothesize that LLMs can generate rich molecular representations when guided to reason in multiple perspectives. To address these gaps, we propose $\text{M}^{2}$LLM, a multi-view framework that integrates three perspectives: the molecular structure view, the molecular task view, and the molecular rules view. These views are fused dynamically to adapt to task requirements, and experiments demonstrate that $\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks across classification and regression tasks. Moreover, we demonstrate that representation derived from LLM achieves exceptional performance by leveraging two core functionalities: the generation of molecular embeddings through their encoding capabilities and the curation of molecular features through advanced reasoning processes.

