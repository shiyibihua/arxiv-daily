---
layout: default
title: Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models
---

# Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.08875" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.08875v2</a>
  <a href="https://arxiv.org/pdf/2508.08875.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.08875v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.08875v2', 'Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fuyao Zhang, Xinyu Yan, Tiantong Wu, Wenjie Li, Tianxiang Chen, Yang Cao, Ran Yan, Longtao Huang, Wei Yang Bryan Lim, Qiang Yang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-11-08)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOblivionisæ¡†æ¶ä»¥è§£å†³è”é‚¦å¤§è¯­è¨€æ¨¡å‹çš„é—å¿˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `æ•°æ®é—å¿˜` `éšç§ä¿æŠ¤` `å¤§è¯­è¨€æ¨¡å‹` `ç®—æ³•æ¯”è¾ƒ` `åˆè§„æ€§` `æœºå™¨å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è”é‚¦å­¦ä¹ æ¡†æ¶ç¼ºä¹æœ‰æ•ˆçš„æœºåˆ¶æ¥æ»¡è¶³GDPRç­‰æ³•è§„çš„è¦æ±‚ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®é—å¿˜æ–¹é¢ã€‚
2. æœ¬æ–‡æå‡ºäº†Oblivionisæ¡†æ¶ï¼Œå…è®¸å®¢æˆ·ç«¯åœ¨è”é‚¦LLMè®­ç»ƒä¸­é€‰æ‹©æ€§åœ°ç§»é™¤ç§æœ‰æ•°æ®ï¼Œä»è€Œæé«˜åˆè§„æ€§å’Œä¿¡ä»»åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOblivionisåœ¨é—å¿˜æ•ˆæœå’Œæ¨¡å‹æ•ˆç”¨ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œä¼˜äºä¼ ç»Ÿçš„æœ¬åœ°è®­ç»ƒæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°åˆ©ç”¨è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰æ¥åˆ©ç”¨ç§æœ‰çš„ã€ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ŒåŒæ—¶ä¿æŠ¤æ•°æ®éšç§ã€‚ç„¶è€Œï¼Œç°æœ‰çš„è”é‚¦LLMæ¡†æ¶ç¼ºä¹å†…ç½®çš„åˆè§„æœºåˆ¶ï¼Œå¦‚GDPRçš„è¢«é—å¿˜æƒã€‚é›†æˆç§æœ‰æ•°æ®åŠ å‰§äº†æ•°æ®è´¨é‡å’Œé•¿æœŸæ²»ç†çš„æ‹…å¿§ï¼Œè€Œç°æœ‰çš„åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶æ²¡æœ‰æä¾›åœ¨è®­ç»ƒåé€‰æ‹©æ€§ç§»é™¤ç‰¹å®šå®¢æˆ·ç«¯è´¡çŒ®çš„åŸåˆ™æ€§æ–¹æ³•ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†Oblivionisï¼Œä¸€ä¸ªè½»é‡çº§çš„å­¦ä¹ ä¸é—å¿˜æ¡†æ¶ï¼Œä½¿å®¢æˆ·ç«¯èƒ½å¤Ÿåœ¨è”é‚¦LLMè®­ç»ƒè¿‡ç¨‹ä¸­é€‰æ‹©æ€§åœ°ç§»é™¤ç‰¹å®šç§æœ‰æ•°æ®ï¼Œä»è€Œå¢å¼ºå¯ä¿¡åº¦å’Œåˆè§„æ€§ã€‚é€šè¿‡å°†FLå’Œé—å¿˜ç»Ÿä¸€ä¸ºåŒé‡ä¼˜åŒ–ç›®æ ‡ï¼Œæœ¬æ–‡æ•´åˆäº†6ç§FLç®—æ³•å’Œ5ç§é—å¿˜ç®—æ³•è¿›è¡Œå…¨é¢è¯„ä¼°å’Œæ¯”è¾ƒåˆ†æï¼Œå»ºç«‹äº†ä¸€ä¸ªå¼ºå¤§çš„è”é‚¦LLMé—å¿˜ç®¡é“ã€‚å®éªŒè¡¨æ˜ï¼ŒOblivionisåœ¨é—å¿˜æ•ˆæœå’Œæ¨¡å‹æ•ˆç”¨ä¹‹é—´å®ç°äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œè·¨ç®—æ³•æ¯”è¾ƒä¸ºæœªæ¥LLMçš„å‘å±•æä¾›äº†æ˜ç¡®çš„æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è”é‚¦å­¦ä¹ ä¸­ç¼ºä¹æœ‰æ•ˆæ•°æ®é—å¿˜æœºåˆ¶çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æ— æ³•åœ¨è®­ç»ƒåé€‰æ‹©æ€§ç§»é™¤ç‰¹å®šå®¢æˆ·ç«¯çš„æ•°æ®è´¡çŒ®ï¼Œå¯¼è‡´åˆè§„æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šOblivionisæ¡†æ¶é€šè¿‡å°†è”é‚¦å­¦ä¹ ä¸é—å¿˜æœºåˆ¶ç»“åˆï¼Œè®¾è®¡ä¸ºåŒé‡ä¼˜åŒ–ç›®æ ‡ï¼Œä½¿å¾—åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥çµæ´»å¤„ç†ç§æœ‰æ•°æ®çš„é—å¿˜éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬æ•°æ®é€‰æ‹©æ¨¡å—ã€æ¨¡å‹è®­ç»ƒæ¨¡å—å’Œé—å¿˜æ¨¡å—ï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è”é‚¦å­¦ä¹ ä¸é—å¿˜çš„ç®¡é“ï¼Œæ”¯æŒå¤šç§ç®—æ³•çš„é›†æˆä¸è¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†FLä¸é—å¿˜æœºåˆ¶ç»Ÿä¸€ä¸ºä¸€ä¸ªä¼˜åŒ–ç›®æ ‡ï¼Œæä¾›äº†ä¸€ç§ç³»ç»ŸåŒ–çš„æ–¹æ³•æ¥å¤„ç†æ•°æ®é—å¿˜é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„åˆè§„æ€§å’Œä¿¡ä»»åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†6ç§ä¸åŒçš„FLç®—æ³•å’Œ5ç§é—å¿˜ç®—æ³•ï¼Œç»“åˆç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œå‚æ•°è®¾ç½®ï¼Œä»¥ç¡®ä¿åœ¨é—å¿˜è¿‡ç¨‹ä¸­å°½é‡å‡å°‘å¯¹æ¨¡å‹æ•ˆç”¨çš„å½±å“ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒOblivionisèƒ½å¤Ÿåœ¨å¤šç§åœºæ™¯ä¸‹å®ç°é«˜æ•ˆçš„é—å¿˜ä¸å­¦ä¹ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOblivionisåœ¨é—å¿˜æ•ˆæœä¸Šä¼˜äºä¼ ç»Ÿæœ¬åœ°è®­ç»ƒæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¿æŒæ¨¡å‹æ•ˆç”¨çš„åŒæ—¶å®ç°é«˜æ•ˆçš„é—å¿˜ã€‚å…·ä½“è€Œè¨€ï¼ŒOblivionisåœ¨å¤šä¸ªç®—æ³•çš„æ¯”è¾ƒä¸­è¡¨ç°å‡ºæ›´å¥½çš„å¹³è¡¡ï¼Œæä¾›äº†æ¸…æ™°çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Oblivionisæ¡†æ¶åœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦éµå¾ªæ•°æ®éšç§æ³•è§„çš„è¡Œä¸šï¼Œå¦‚é‡‘èã€åŒ»ç–—å’Œç¤¾äº¤åª’ä½“ç­‰ã€‚é€šè¿‡æä¾›åˆè§„çš„æ•°æ®é—å¿˜æœºåˆ¶ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¢å¼ºç”¨æˆ·å¯¹æ•°æ®å¤„ç†çš„ä¿¡ä»»ï¼Œä¿ƒè¿›æ•°æ®å…±äº«ä¸åˆä½œï¼ŒåŒæ—¶ç¡®ä¿æ³•å¾‹æ³•è§„çš„éµå¾ªã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šåŸºäºéšç§ä¿æŠ¤çš„æœºå™¨å­¦ä¹ åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) increasingly leverage Federated Learning (FL) to utilize private, task-specific datasets for fine-tuning while preserving data privacy. However, while federated LLM frameworks effectively enable collaborative training without raw data sharing, they critically lack built-in mechanisms for regulatory compliance like GDPR's right to be forgotten. Integrating private data heightens concerns over data quality and long-term governance, yet existing distributed training frameworks offer no principled way to selectively remove specific client contributions post-training. Due to distributed data silos, stringent privacy constraints, and the intricacies of interdependent model aggregation, federated LLM unlearning is significantly more complex than centralized LLM unlearning. To address this gap, we introduce Oblivionis, a lightweight learning and unlearning framework that enables clients to selectively remove specific private data during federated LLM training, enhancing trustworthiness and regulatory compliance. By unifying FL and unlearning as a dual optimization objective, we incorporate 6 FL and 5 unlearning algorithms for comprehensive evaluation and comparative analysis, establishing a robust pipeline for federated LLM unlearning. Extensive experiments demonstrate that Oblivionis outperforms local training, achieving a robust balance between forgetting efficacy and model utility, with cross-algorithm comparisons providing clear directions for future LLM development.

