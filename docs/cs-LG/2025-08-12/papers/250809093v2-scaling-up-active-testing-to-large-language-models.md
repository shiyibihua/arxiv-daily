---
layout: default
title: Scaling Up Active Testing to Large Language Models
---

# Scaling Up Active Testing to Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09093" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09093v2</a>
  <a href="https://arxiv.org/pdf/2508.09093.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09093v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09093v2', 'Scaling Up Active Testing to Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Gabrielle Berrada, Jannik Kossen, Freddie Bickford Smith, Muhammed Razzak, Yarin Gal, Tom Rainforth

**åˆ†ç±»**: cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-11-24)

**å¤‡æ³¨**: Published at NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé«˜æ•ˆçš„ä¸»åŠ¨æµ‹è¯•æ–¹æ³•ä»¥è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸»åŠ¨æµ‹è¯•` `å¤§å‹è¯­è¨€æ¨¡å‹` `ä¸Šä¸‹æ–‡å­¦ä¹ ` `è¯„ä¼°æ–¹æ³•` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸»åŠ¨æµ‹è¯•æ–¹æ³•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶é¢ä¸´é«˜è®¡ç®—æˆæœ¬çš„é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ æ„å»ºå»‰ä»·çš„æ›¿ä»£æ¨¡å‹ï¼Œé¿å…åœ¨ä¸»åŠ¨æµ‹è¯•å¾ªç¯ä¸­æ›´æ–°ï¼Œä»è€Œé™ä½è®¡ç®—è´Ÿæ‹…ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨ä¸»åŠ¨æµ‹è¯•æ–¹æ³•ç›¸æ¯”éšæœºæ•°æ®è·å–ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ€§èƒ½è¯„ä¼°å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸»åŠ¨æµ‹è¯•é€šè¿‡ç²¾å¿ƒçš„æ•°æ®è·å–å®ç°äº†é¢„æµ‹æ¨¡å‹çš„æ ‡ç­¾é«˜æ•ˆè¯„ä¼°ï¼Œä½†å…¶è®¡ç®—æˆæœ¬å¯èƒ½éå¸¸é«˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€äº›èŠ‚çœæˆæœ¬çš„æªæ–½ï¼Œä½¿ä¸»åŠ¨æµ‹è¯•èƒ½å¤Ÿæ‰©å±•åˆ°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚æˆ‘ä»¬å±•ç¤ºäº†ç”¨äºæŒ‡å¯¼æ•°æ®è·å–çš„æ›¿ä»£æ¨¡å‹å¯ä»¥é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å»‰ä»·æ„å»ºï¼Œå¹¶ä¸”åœ¨ä¸»åŠ¨æµ‹è¯•å¾ªç¯ä¸­æ— éœ€æ›´æ–°ï¼Œä¸”å¯ä»¥å°äºç›®æ ‡æ¨¡å‹ã€‚æˆ‘ä»¬ç”šè‡³å‘ç°ï¼Œåœ¨ä¸ä½¿ç”¨ç›®æ ‡æ¨¡å‹è¿›è¡Œé¢„æµ‹çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½åšå‡ºè‰¯å¥½çš„æ•°æ®è·å–å†³ç­–ã€‚å› æ­¤ï¼Œæˆ‘ä»¬èƒ½å¤Ÿç›¸è¾ƒäºéšæœºè·å–æ•°æ®ï¼Œè·å¾—æ›´å‡†ç¡®çš„LLMæ€§èƒ½è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§è¯„ä¼°è¯¯å·®çš„è‡ªåŠ©ä¼°è®¡å™¨ï¼Œè¯æ˜å…¶åœ¨å•æ¬¡è¿è¡Œä¸­æ˜¯è¯„ä¼°ä¸»åŠ¨æµ‹è¯•æ•ˆæœçš„æœ‰ç”¨æŒ‡æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¸»åŠ¨æµ‹è¯•åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦é¢‘ç¹æ›´æ–°æ¨¡å‹ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡ä½¿ç”¨ä¸Šä¸‹æ–‡å­¦ä¹ æ„å»ºä¸€ä¸ªå»‰ä»·çš„æ›¿ä»£æ¨¡å‹ï¼Œé¿å…åœ¨ä¸»åŠ¨æµ‹è¯•å¾ªç¯ä¸­è¿›è¡Œæ›´æ–°ï¼Œä»è€Œé™ä½è®¡ç®—å¼€é”€ï¼ŒåŒæ—¶ä»èƒ½æœ‰æ•ˆæŒ‡å¯¼æ•°æ®è·å–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è·å–æ¨¡å—ã€æ›¿ä»£æ¨¡å‹æ„å»ºæ¨¡å—å’Œè¯„ä¼°æ¨¡å—ã€‚æ•°æ®è·å–æ¨¡å—æ ¹æ®æ›¿ä»£æ¨¡å‹çš„è¾“å‡ºé€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„æ•°æ®ï¼Œæ›¿ä»£æ¨¡å‹åˆ™é€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ è¿›è¡Œæ„å»ºã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†æ— éœ€æ›´æ–°çš„æ›¿ä»£æ¨¡å‹ï¼Œä¸”è¯¥æ¨¡å‹å¯ä»¥å°äºç›®æ ‡æ¨¡å‹ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§è®¾è®¡ä½¿å¾—ä¸»åŠ¨æµ‹è¯•æ›´å…·å¯æ‰©å±•æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œæ›¿ä»£æ¨¡å‹çš„è§„æ¨¡å°äºç›®æ ‡æ¨¡å‹ï¼Œä¸”ä½¿ç”¨ç®€å•çš„ä¸Šä¸‹æ–‡å­¦ä¹ æ–¹æ³•ã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡ç‚¹å…³æ³¨æ•°æ®è·å–çš„æœ‰æ•ˆæ€§ï¼Œè€Œéæ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨ä¸»åŠ¨æµ‹è¯•æ–¹æ³•ç›¸æ¯”éšæœºæ•°æ®è·å–ï¼Œè¯„ä¼°å‡†ç¡®æ€§æ˜¾è‘—æé«˜ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚æ­¤å¤–ï¼Œå¼•å…¥çš„è‡ªåŠ©ä¼°è®¡å™¨æœ‰æ•ˆæŒ‡ç¤ºäº†ä¸»åŠ¨æµ‹è¯•çš„æ•ˆæœï¼Œä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„è¯„ä¼°å·¥å…·ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„è¯„ä¼°æ•ˆç‡ï¼Œèƒ½å¤ŸåŠ é€Ÿæ¨¡å‹çš„å¼€å‘ä¸è¿­ä»£ï¼Œæå‡å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Active testing enables label-efficient evaluation of predictive models through careful data acquisition, but it can pose a significant computational cost. We identify cost-saving measures that enable active testing to be scaled up to large language models (LLMs). In particular we show that the surrogate model used to guide data acquisition can be constructed cheaply using in-context learning, does not require updating within an active-testing loop, and can be smaller than the target model. We even find we can make good data-acquisition decisions without making predictions with the target model. As a result we are able to achieve much more accurate evaluations of LLM performance relative to using randomly acquired data. We additionally introduce a bootstrap estimator of evaluation error, which we show to be a useful indicator of how well active testing is working within a single run.

