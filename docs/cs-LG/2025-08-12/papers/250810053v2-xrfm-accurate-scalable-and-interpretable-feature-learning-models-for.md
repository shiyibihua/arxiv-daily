---
layout: default
title: xRFM: Accurate, scalable, and interpretable feature learning models for tabular data
---

# xRFM: Accurate, scalable, and interpretable feature learning models for tabular data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10053" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10053v2</a>
  <a href="https://arxiv.org/pdf/2508.10053.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10053v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10053v2', 'xRFM: Accurate, scalable, and interpretable feature learning models for tabular data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Daniel Beaglehole, David HolzmÃ¼ller, Adityanarayanan Radhakrishnan, Mikhail Belkin

**åˆ†ç±»**: cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12 (æ›´æ–°: 2025-10-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºxRFMä»¥è§£å†³è¡¨æ ¼æ•°æ®ç‰¹å¾å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ•°æ®` `ç‰¹å¾å­¦ä¹ ` `æœºå™¨å­¦ä¹ ` `å¯è§£é‡Šæ€§` `ç®—æ³•åˆ›æ–°` `æ•°æ®ç§‘å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¡¨æ ¼æ•°æ®é¢„æµ‹æ–¹æ³•ä¸»è¦ä¾èµ–äºGBDTï¼Œç¼ºä¹åˆ›æ–°ï¼Œéš¾ä»¥é€‚åº”å¤§è§„æ¨¡æ•°æ®çš„éœ€æ±‚ã€‚
2. xRFMç®—æ³•é€šè¿‡ç»“åˆç‰¹å¾å­¦ä¹ æ ¸æœºå™¨ä¸æ ‘ç»“æ„ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé€‚åº”æ•°æ®çš„å±€éƒ¨ç»“æ„å¹¶å¤„ç†å¤§è§„æ¨¡æ•°æ®ã€‚
3. åœ¨å®éªŒä¸­ï¼ŒxRFMåœ¨100ä¸ªå›å½’æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œå¹¶åœ¨200ä¸ªåˆ†ç±»æ•°æ®é›†ä¸Šè¶…è¶Šäº†GBDTï¼Œæ˜¾ç¤ºå‡ºå…¶å¼ºå¤§çš„æ€§èƒ½å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡¨æ ¼æ•°æ®çš„æ¨æ–­æ˜¯ç°ä»£ç§‘æŠ€ä¸ç§‘å­¦çš„åŸºç¡€ã€‚ç„¶è€Œï¼Œä¸äººå·¥æ™ºèƒ½å…¶ä»–é¢†åŸŸçš„å¿«é€Ÿå‘å±•ç›¸æ¯”ï¼Œè¡¨æ ¼æ•°æ®çš„é¢„æµ‹ä»»åŠ¡ä»ä¸»è¦ä¾èµ–äºæ¢¯åº¦æå‡å†³ç­–æ ‘ï¼ˆGBDTï¼‰çš„å˜ä½“ã€‚è¿‘æœŸï¼ŒåŸºäºç¥ç»ç½‘ç»œå’Œç‰¹å¾å­¦ä¹ æ–¹æ³•çš„æœ€æ–°è¿›å±•ï¼Œå¼€å‘å…ˆè¿›çš„è¡¨æ ¼æ•°æ®å¤„ç†æ–¹æ³•å¼•èµ·äº†å…³æ³¨ã€‚æœ¬æ–‡æå‡ºäº†xRFMç®—æ³•ï¼Œè¯¥ç®—æ³•ç»“åˆäº†ç‰¹å¾å­¦ä¹ æ ¸æœºå™¨ä¸æ ‘ç»“æ„ï¼Œèƒ½å¤Ÿé€‚åº”æ•°æ®çš„å±€éƒ¨ç»“æ„å¹¶æ‰©å±•åˆ°å‡ ä¹æ— é™çš„è®­ç»ƒæ•°æ®ã€‚ä¸31ç§å…¶ä»–æ–¹æ³•ç›¸æ¯”ï¼ŒxRFMåœ¨100ä¸ªå›å½’æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œå¹¶åœ¨200ä¸ªåˆ†ç±»æ•°æ®é›†ä¸Šä¸æœ€ä½³æ–¹æ³•ç«äº‰ï¼Œè¶…è¶Šäº†GBDTã€‚æ­¤å¤–ï¼ŒxRFMé€šè¿‡å¹³å‡æ¢¯åº¦å¤–ç§¯æä¾›äº†å†…åœ¨çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¡¨æ ¼æ•°æ®ç‰¹å¾å­¦ä¹ çš„å‡†ç¡®æ€§å’Œå¯æ‰©å±•æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚GBDTåœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®æ—¶å­˜åœ¨æ€§èƒ½ç“¶é¢ˆï¼Œä¸”ç¼ºä¹å¯¹æ•°æ®ç»“æ„çš„é€‚åº”æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šxRFMç®—æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ç‰¹å¾å­¦ä¹ æ ¸æœºå™¨ä¸æ ‘ç»“æ„ç›¸ç»“åˆï¼Œä»¥ä¾¿æ›´å¥½åœ°é€‚åº”æ•°æ®çš„å±€éƒ¨ç»“æ„ï¼ŒåŒæ—¶å…·å¤‡è‰¯å¥½çš„æ‰©å±•æ€§ï¼Œèƒ½å¤Ÿå¤„ç†å¤§è§„æ¨¡è®­ç»ƒæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šxRFMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç‰¹å¾å­¦ä¹ æ¨¡å—å’Œæ ‘ç»“æ„æ¨¡å—ã€‚ç‰¹å¾å­¦ä¹ æ¨¡å—è´Ÿè´£ä»åŸå§‹æ•°æ®ä¸­æå–æœ‰ç”¨ç‰¹å¾ï¼Œè€Œæ ‘ç»“æ„æ¨¡å—åˆ™ç”¨äºæ„å»ºå†³ç­–æ ‘ï¼Œä»¥è¿›è¡Œé«˜æ•ˆçš„é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šxRFMçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶ç»“åˆäº†ç‰¹å¾å­¦ä¹ ä¸æ ‘ç»“æ„çš„ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿåœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶æä¾›æ›´é«˜çš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚è¿™ä¸€è®¾è®¡ä¸ä¼ ç»Ÿçš„GBDTæ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œåè€…ä¸»è¦ä¾èµ–äºå›ºå®šçš„ç‰¹å¾é€‰æ‹©ã€‚

**å…³é”®è®¾è®¡**ï¼šxRFMé‡‡ç”¨äº†å¹³å‡æ¢¯åº¦å¤–ç§¯ä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸€éƒ¨åˆ†ï¼Œä»¥å¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„å‚æ•°è®¾ç½®ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„é«˜æ•ˆè®­ç»ƒå’Œæ¨æ–­ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè¶…å‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†éªŒè¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒxRFMåœ¨100ä¸ªå›å½’æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œè¶…è¶Šäº†31ç§å…¶ä»–æ–¹æ³•ï¼ŒåŒ…æ‹¬æœ€æ–°çš„è¡¨æ ¼åŸºç¡€æ¨¡å‹ï¼ˆTabPFNv2ï¼‰å’ŒGBDTã€‚æ­¤å¤–ï¼Œåœ¨200ä¸ªåˆ†ç±»æ•°æ®é›†ä¸Šï¼ŒxRFMçš„è¡¨ç°ä¸æœ€ä½³æ–¹æ³•ç›¸å½“ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨è¡¨æ ¼æ•°æ®å¤„ç†ä¸­çš„å¼ºå¤§ç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

xRFMç®—æ³•åœ¨é‡‘èã€åŒ»ç–—ã€å¸‚åœºè¥é”€ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚å…¶é«˜æ•ˆçš„ç‰¹å¾å­¦ä¹ èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ä½¿å…¶èƒ½å¤Ÿå¸®åŠ©å†³ç­–è€…æ›´å¥½åœ°ç†è§£æ•°æ®èƒŒåçš„æ¨¡å¼ï¼Œä»è€Œåšå‡ºæ›´ä¸ºç²¾å‡†çš„å†³ç­–ã€‚æœªæ¥ï¼ŒxRFMæœ‰æœ›åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨æ•°æ®é©±åŠ¨å†³ç­–çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Inference from tabular data, collections of continuous and categorical variables organized into matrices, is a foundation for modern technology and science. Yet, in contrast to the explosive changes in the rest of AI, the best practice for these predictive tasks has been relatively unchanged and is still primarily based on variations of Gradient Boosted Decision Trees (GBDTs). Very recently, there has been renewed interest in developing state-of-the-art methods for tabular data based on recent developments in neural networks and feature learning methods. In this work, we introduce xRFM, an algorithm that combines feature learning kernel machines with a tree structure to both adapt to the local structure of the data and scale to essentially unlimited amounts of training data.
>   We show that compared to $31$ other methods, including recently introduced tabular foundation models (TabPFNv2) and GBDTs, xRFM achieves best performance across $100$ regression datasets and is competitive to the best methods across $200$ classification datasets outperforming GBDTs. Additionally, xRFM provides interpretability natively through the Average Gradient Outer Product.

