---
layout: default
title: Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning
---

# Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.09275" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.09275v1</a>
  <a href="https://arxiv.org/pdf/2508.09275.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.09275v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.09275v1', 'Constrained Black-Box Attacks Against Multi-Agent Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amine Andam, Jamal Bentahar, Mustapha Hedabou

**åˆ†ç±»**: cs.LG, cs.MA

**å‘å¸ƒæ—¥æœŸ**: 2025-08-12

**å¤‡æ³¨**: Under review in TNNLS

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçº¦æŸé»‘ç®±æ”»å‡»æ–¹æ³•ä»¥è§£å†³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„è„†å¼±æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `å¯¹æŠ—æ”»å‡»` `æ ·æœ¬æ•ˆç‡` `ç¯å¢ƒæ„ŸçŸ¥` `å®‰å…¨æ€§ç ”ç©¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è®­ç»ƒé˜¶æ®µçš„æ”»å‡»æˆ–ä¸åˆ‡å®é™…çš„å‡è®¾ï¼Œç¼ºä¹å¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨çœŸå®ç¯å¢ƒä¸­çš„è„†å¼±æ€§ç ”ç©¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼Œå‡è®¾å¯¹æ‰‹åªèƒ½æ”¶é›†å’Œæ‰°åŠ¨æ™ºèƒ½ä½“çš„è§‚å¯Ÿæ•°æ®ï¼Œä»è€Œåœ¨æ›´ç°å®çš„æ¡ä»¶ä¸‹è¿›è¡Œæ”»å‡»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨22ä¸ªç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œæ ·æœ¬æ•ˆç‡é«˜ï¼Œä»…éœ€1,000ä¸ªæ ·æœ¬ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åä½œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆc-MARLï¼‰è¿…é€Ÿå‘å±•ï¼Œä¸ºç°å®åº”ç”¨æä¾›äº†æœ€å…ˆè¿›çš„ç®—æ³•ï¼Œä½†å…¶åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è®­ç»ƒé˜¶æ®µæ”»å‡»æˆ–ä¸åˆ‡å®é™…çš„åœºæ™¯ï¼Œå¦‚è®¿é—®ç­–ç•¥æƒé‡æˆ–è®­ç»ƒæ›¿ä»£ç­–ç•¥ã€‚æœ¬æ–‡åœ¨æ›´ç°å®å’Œå—é™çš„æ¡ä»¶ä¸‹æ¢è®¨æ–°çš„è„†å¼±æ€§ï¼Œå‡è®¾å¯¹æ‰‹åªèƒ½æ”¶é›†å’Œæ‰°åŠ¨å·²éƒ¨ç½²æ™ºèƒ½ä½“çš„è§‚å¯Ÿæ•°æ®ã€‚æˆ‘ä»¬æå‡ºäº†ç®€å•è€Œé«˜æ•ˆçš„ç®—æ³•ï¼Œç”¨äºç”Ÿæˆå¯¹æŠ—æ€§æ‰°åŠ¨ï¼Œæ—¨åœ¨è¯¯å¯¼å—å®³è€…æ™ºèƒ½ä½“å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥ã€‚é€šè¿‡åœ¨ä¸‰ä¸ªåŸºå‡†å’Œ22ä¸ªç¯å¢ƒä¸­çš„å®è¯éªŒè¯ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨å¤šç§ç®—æ³•å’Œç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§ï¼Œå¹¶ä¸”æ ·æœ¬æ•ˆç‡é«˜ï¼Œä»…éœ€1,000ä¸ªæ ·æœ¬ï¼Œç›¸è¾ƒäºä»¥å¾€æ–¹æ³•æ‰€éœ€çš„æ•°ç™¾ä¸‡æ ·æœ¬æ˜¾è‘—é™ä½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆc-MARLï¼‰åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¤šé›†ä¸­äºè®­ç»ƒé˜¶æ®µçš„æ”»å‡»ï¼Œç¼ºä¹å¯¹å®é™…éƒ¨ç½²ç¯å¢ƒä¸­æ”»å‡»çš„ç ”ç©¶ï¼Œå¯¼è‡´å¯¹æ‰‹åœ¨æ”»å‡»æ—¶çš„èƒ½åŠ›å—åˆ°é™åˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ”»å‡»æ–¹æ³•ï¼Œå‡è®¾å¯¹æ‰‹åªèƒ½æ”¶é›†å’Œæ‰°åŠ¨æ™ºèƒ½ä½“çš„è§‚å¯Ÿæ•°æ®ã€‚é€šè¿‡è®¾è®¡ç®€å•è€Œæœ‰æ•ˆçš„ç®—æ³•ï¼Œç”Ÿæˆå¯¹æŠ—æ€§æ‰°åŠ¨ï¼Œè¯¯å¯¼æ™ºèƒ½ä½“å¯¹ç¯å¢ƒçš„æ„ŸçŸ¥ï¼Œä»è€Œå®ç°æ”»å‡»ç›®çš„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæˆ‘ä»¬çš„æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ‰°åŠ¨ç”Ÿæˆå’Œæ”»å‡»å®æ–½ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ”¶é›†æ™ºèƒ½ä½“çš„è§‚å¯Ÿæ•°æ®ï¼›å…¶æ¬¡ï¼ŒåŸºäºè¿™äº›æ•°æ®ç”Ÿæˆå¯¹æŠ—æ€§æ‰°åŠ¨ï¼›æœ€åï¼Œå°†æ‰°åŠ¨åº”ç”¨äºæ™ºèƒ½ä½“çš„è¾“å…¥ï¼Œè§‚å¯Ÿå…¶è¡Œä¸ºå˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºåœ¨å—é™æ¡ä»¶ä¸‹è¿›è¡Œå¯¹æŠ—æ”»å‡»ï¼Œçªç ´äº†ä»¥å¾€æ–¹æ³•å¯¹è®­ç»ƒé˜¶æ®µçš„ä¾èµ–ã€‚é€šè¿‡ä»…ä¾èµ–è§‚å¯Ÿæ•°æ®ï¼Œæˆ‘ä»¬çš„ç®—æ³•èƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ›´å…·å¯è¡Œæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæˆ‘ä»¬åœ¨ç®—æ³•è®¾è®¡ä¸­å…³æ³¨æ ·æœ¬æ•ˆç‡ï¼Œé‡‡ç”¨äº†ç®€å•çš„æ‰°åŠ¨ç”Ÿæˆç­–ç•¥ï¼Œç¡®ä¿åœ¨ä»…éœ€1,000ä¸ªæ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œä»èƒ½æœ‰æ•ˆå®æ–½æ”»å‡»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ”»å‡»æ–¹æ³•åœ¨22ä¸ªä¸åŒç¯å¢ƒä¸­å‡è¡¨ç°å‡ºè‰²ï¼Œæ ·æœ¬æ•ˆç‡é«˜ï¼Œä»…éœ€1,000ä¸ªæ ·æœ¬ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æ‰€éœ€çš„æ•°ç™¾ä¸‡æ ·æœ¬ï¼Œæ˜¾è‘—é™ä½äº†æ”»å‡»æˆæœ¬ï¼Œæå‡äº†å®é™…åº”ç”¨çš„å¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ•æ„Ÿçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€é‡‘èäº¤æ˜“å’Œæ™ºèƒ½åˆ¶é€ ç­‰ã€‚é€šè¿‡è¯†åˆ«å’Œç¼“è§£å¯¹æŠ—æ”»å‡»çš„è„†å¼±æ€§ï¼Œå¯ä»¥æé«˜è¿™äº›ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œæ¨åŠ¨å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Collaborative multi-agent reinforcement learning (c-MARL) has rapidly evolved, offering state-of-the-art algorithms for real-world applications, including sensitive domains. However, a key challenge to its widespread adoption is the lack of a thorough investigation into its vulnerabilities to adversarial attacks. Existing work predominantly focuses on training-time attacks or unrealistic scenarios, such as access to policy weights or the ability to train surrogate policies. In this paper, we investigate new vulnerabilities under more realistic and constrained conditions, assuming an adversary can only collect and perturb the observations of deployed agents. We also consider scenarios where the adversary has no access at all. We propose simple yet highly effective algorithms for generating adversarial perturbations designed to misalign how victim agents perceive their environment. Our approach is empirically validated on three benchmarks and 22 environments, demonstrating its effectiveness across diverse algorithms and environments. Furthermore, we show that our algorithm is sample-efficient, requiring only 1,000 samples compared to the millions needed by previous methods.

