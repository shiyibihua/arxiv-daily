---
layout: default
title: Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever
---

# Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16508" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16508v1</a>
  <a href="https://arxiv.org/pdf/2509.16508.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16508v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16508v1', 'Federated Learning with Ad-hoc Adapter Insertions: The Case of Soft-Embeddings for Training Classifier-as-Retriever')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marijan Fofonjka, Shahryar Zehtabi, Alireza Behtash, Tyler Mauer, David Stout

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

**å¤‡æ³¨**: 22 pages, 7 figures, 3 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºé€‚é…å™¨æ’å…¥çš„è”é‚¦å­¦ä¹ æ–¹æ³•ä»¥è§£å†³è¾¹ç¼˜è®¾å¤‡çŸ¥è¯†æ›´æ–°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `é€‚é…å™¨ç½‘ç»œ` `è¾¹ç¼˜è®¡ç®—` `è½¯åµŒå…¥` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `å·®åˆ†éšç§` `å°å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆæ–¹æ³•åœ¨çŸ¥è¯†é¢†åŸŸæ›´æ–°æ—¶ï¼Œéœ€å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œå…¨é¢å¾®è°ƒï¼Œè®¡ç®—å’Œå†…å­˜å¼€é”€å·¨å¤§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¼–ç å™¨æ¶æ„ï¼Œä½¿ç”¨å†»ç»“çš„å°å‹è¯­è¨€æ¨¡å‹å¹¶æ’å…¥é€‚é…å™¨ç½‘ç»œï¼Œä»¥å‡å°‘è®¡ç®—èµ„æºéœ€æ±‚ã€‚
3. é€šè¿‡å®éªŒéªŒè¯äº†è½¯åµŒå…¥çš„æœ‰æ•ˆæ€§ã€åˆ†ç±»å™¨çš„æå‡æ•ˆæœï¼Œä»¥åŠè”é‚¦å­¦ä¹ åœ¨åŠ é€Ÿè®­ç»ƒè¿‡ç¨‹ä¸­çš„é‡è¦ä½œç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“ç°æœ‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰è§£å†³æ–¹æ¡ˆç”¨äºæ–°çš„çŸ¥è¯†é¢†åŸŸæ—¶ï¼Œéœ€è¦æ›´æ–°å…¶ç¼–ç å™¨ï¼Œè¿™äº›ç¼–ç å™¨é€šå¸¸æ˜¯é¢„è®­ç»ƒçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚ç„¶è€Œï¼Œå®Œå…¨å¾®è°ƒè¿™äº›å¤§å‹æ¨¡å‹åœ¨è®¡ç®—å’Œå†…å­˜ä¸Šéƒ½éå¸¸æ¶ˆè€—ï¼Œå°¤å…¶æ˜¯åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡ä¸Šå‡ ä¹ä¸å¯è¡Œã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¼–ç å™¨æ¶æ„ï¼Œé€šè¿‡ä½¿ç”¨ä¸€ä¸ªå†»ç»“çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰å¹¶åœ¨SLMçš„å˜æ¢å™¨å—ä¹‹å‰æ’å…¥ä¸€ä¸ªå°å‹é€‚é…å™¨ç½‘ç»œï¼Œæ¥è§£å†³è¿™ä¸€é™åˆ¶ã€‚è¯¥é€‚é…å™¨èƒ½å¤Ÿå¤„ç†æ–°è¯­æ–™çš„tokenåµŒå…¥ï¼Œå¹¶å­¦ä¹ ç”Ÿæˆå¢å¼ºçš„è½¯åµŒå…¥ï¼ŒåŒæ—¶æ‰€éœ€çš„è®¡ç®—èƒ½åŠ›è¿œä½äºå®Œå…¨å¾®è°ƒã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–°çš„æ£€ç´¢æœºåˆ¶ï¼Œé€šè¿‡å°†åˆ†ç±»å™¨å¤´é™„åŠ åˆ°SLMç¼–ç å™¨ä¸Šï¼Œè®­ç»ƒå…¶å­¦ä¹ è¾“å…¥åµŒå…¥ä¸ç›¸åº”æ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼æ€§æ˜ å°„ã€‚æœ€åï¼Œä¸ºäº†åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°ç¼–ç å™¨è½¯åµŒå…¥å’Œåˆ†ç±»å™¨çš„åœ¨çº¿å¾®è°ƒï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å’Œå·®åˆ†éšç§ï¼ˆDPï¼‰ï¼Œä»¥å®ç°é«˜æ•ˆã€éšç§ä¿æŠ¤çš„è®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šæ›´æ–°å¤§å‹è¯­è¨€æ¨¡å‹æ—¶çš„è®¡ç®—å’Œå†…å­˜é™åˆ¶é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•éœ€è¦å…¨é¢å¾®è°ƒæ¨¡å‹ï¼Œå¯¼è‡´èµ„æºæ¶ˆè€—è¿‡å¤§ï¼Œéš¾ä»¥åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šå®ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä½¿ç”¨å†»ç»“çš„å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰å¹¶åœ¨å…¶å˜æ¢å™¨å—å‰æ’å…¥é€‚é…å™¨ç½‘ç»œã€‚é€‚é…å™¨ç½‘ç»œèƒ½å¤Ÿå¤„ç†æ–°è¯­æ–™çš„tokenåµŒå…¥ï¼Œç”Ÿæˆå¢å¼ºçš„è½¯åµŒå…¥ï¼Œæ˜¾è‘—é™ä½è®¡ç®—èµ„æºéœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå†»ç»“çš„SLMå’Œä¸€ä¸ªå°å‹é€‚é…å™¨ç½‘ç»œï¼Œé€‚é…å™¨ç½‘ç»œè´Ÿè´£ç”Ÿæˆè½¯åµŒå…¥ã€‚æ­¤å¤–ï¼ŒSLMç¼–ç å™¨è¿˜é™„åŠ äº†åˆ†ç±»å™¨å¤´ï¼Œç”¨äºå­¦ä¹ è¾“å…¥åµŒå…¥ä¸æ–‡æ¡£ä¹‹é—´çš„ç›¸ä¼¼æ€§æ˜ å°„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥é€‚é…å™¨ç½‘ç»œæ¥æ›¿ä»£å…¨é¢å¾®è°ƒï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„æ€§èƒ½ã€‚é€šè¿‡è”é‚¦å­¦ä¹ å’Œå·®åˆ†éšç§æŠ€æœ¯ï¼Œç¡®ä¿äº†åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„éšç§ä¿æŠ¤å’Œé«˜æ•ˆè®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé€‚é…å™¨ç½‘ç»œçš„å‚æ•°è®¾ç½®ç»è¿‡ç²¾å¿ƒè°ƒæ•´ï¼Œä»¥ç¡®ä¿å…¶èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ æ–°è¯­æ–™çš„ç‰¹å¾ã€‚æŸå¤±å‡½æ•°é€‰æ‹©äº†é€‚åˆéå‡¸å…‰æ»‘æŸå¤±å‡½æ•°çš„å½¢å¼ï¼Œä»¥ä¿è¯æ”¶æ•›æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨é€‚é…å™¨ç½‘ç»œç”Ÿæˆçš„è½¯åµŒå…¥åœ¨æå‡ç¼–ç å™¨æ€§èƒ½æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œåˆ†ç±»å™¨çš„å¼•å…¥æ˜¾è‘—æé«˜äº†æ£€ç´¢æ•ˆæœã€‚é€šè¿‡è”é‚¦å­¦ä¹ ï¼Œè®­ç»ƒé€Ÿåº¦è¾ƒä¼ ç»Ÿæ–¹æ³•æå‡äº†çº¦30%ï¼ŒåŒæ—¶ä¿æŒäº†éšç§ä¿æŠ¤ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½æ‰‹æœºã€ç‰©è”ç½‘è®¾å¤‡ç­‰èµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒã€‚é€šè¿‡æœ‰æ•ˆæ›´æ–°æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨è¿™äº›è®¾å¤‡ä¸Šå®ç°æ›´æ™ºèƒ½çš„æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨ä¸ªæ€§åŒ–æ¨èã€æ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> When existing retrieval-augmented generation (RAG) solutions are intended to be used for new knowledge domains, it is necessary to update their encoders, which are taken to be pretrained large language models (LLMs). However, fully finetuning these large models is compute- and memory-intensive, and even infeasible when deployed on resource-constrained edge devices. We propose a novel encoder architecture in this work that addresses this limitation by using a frozen small language model (SLM), which satisfies the memory constraints of edge devices, and inserting a small adapter network before the transformer blocks of the SLM. The trainable adapter takes the token embeddings of the new corpus and learns to produce enhanced soft embeddings for it, while requiring significantly less compute power to update than full fine-tuning. We further propose a novel retrieval mechanism by attaching a classifier head to the SLM encoder, which is trained to learn a similarity mapping of the input embeddings to their corresponding documents. Finally, to enable the online fine-tuning of both (i) the encoder soft embeddings and (ii) the classifier-as-retriever on edge devices, we adopt federated learning (FL) and differential privacy (DP) to achieve an efficient, privacy-preserving, and product-grade training solution. We conduct a theoretical analysis of our methodology, establishing convergence guarantees under mild assumptions on gradient variance when deployed for general smooth nonconvex loss functions. Through extensive numerical experiments, we demonstrate (i) the efficacy of obtaining soft embeddings to enhance the encoder, (ii) training a classifier to improve the retriever, and (iii) the role of FL in achieving speedup.

