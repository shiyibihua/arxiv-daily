---
layout: default
title: FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG
---

# FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16491" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16491v1</a>
  <a href="https://arxiv.org/pdf/2509.16491.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16491v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16491v1', 'FairTune: A Bias-Aware Fine-Tuning Framework Towards Fair Heart Rate Prediction from PPG')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lovely Yeswanth Panchumarthi, Saurabh Kataria, Yi Wu, Xiao Hu, Alex Fedorov, Hyunjung Gloria Kwak

**åˆ†ç±»**: cs.LG, cs.CE

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FairTuneï¼šä¸€ç§åè§æ„ŸçŸ¥çš„å¾®è°ƒæ¡†æ¶ï¼Œç”¨äºä»PPGä¿¡å·ä¸­å®ç°å…¬å¹³çš„å¿ƒç‡é¢„æµ‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¿ƒç‡é¢„æµ‹` `å…‰ç”µå®¹ç§¯è„‰ææ³¢` `é¢„è®­ç»ƒæ¨¡å‹` `å…¬å¹³æ€§` `å¾®è°ƒ` `åè§ç¼“è§£` `ç”Ÿç†ä¿¡å·å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åˆ©ç”¨ç”Ÿç†æ•°æ®é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹è¿›è¡Œå¿ƒç‡é¢„æµ‹æ—¶ï¼Œå¾®è°ƒå¯èƒ½åŠ å‰§äººå£ç»Ÿè®¡å­¦ä¸Šçš„ä¸å…¬å¹³æ€§ï¼Œå°¤å…¶æ˜¯åœ¨é¢†åŸŸè¿ç§»çš„æƒ…å†µä¸‹ã€‚
2. FairTuneæ¡†æ¶é€šè¿‡é›†æˆç±»åˆ«åŠ æƒã€ç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–å’Œå¯¹æŠ—æ€§å»åç­‰ç­–ç•¥ï¼Œæ˜¾å¼åœ°ç¼“è§£å¾®è°ƒè¿‡ç¨‹ä¸­äº§ç”Ÿçš„åè§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒFairTuneæ¡†æ¶ä¸­çš„ç±»åˆ«åŠ æƒå’Œç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–ç­–ç•¥ï¼Œèƒ½å¤Ÿåœ¨ä¸æŸå¤±é¢„æµ‹ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ‰æ•ˆå‡å°å…¬å¹³æ€§å·®è·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºFairTuneï¼Œä¸€ä¸ªåè§æ„ŸçŸ¥çš„å¾®è°ƒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åœ¨åˆ©ç”¨é¢„è®­ç»ƒçš„PPGï¼ˆå…‰ç”µå®¹ç§¯è„‰ææ³¢ï¼‰ç”Ÿç†æ•°æ®åŸºç¡€æ¨¡å‹è¿›è¡Œå¿ƒç‡ï¼ˆHRï¼‰é¢„æµ‹æ—¶ï¼Œå¾®è°ƒè¿‡ç¨‹å¯èƒ½åŠ å‰§çš„å…¬å¹³æ€§é—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨å¼‚æ„æ•°æ®é›†ï¼ˆICUã€å¯ç©¿æˆ´è®¾å¤‡ã€æ™ºèƒ½æ‰‹æœºï¼‰ä¸Šå¯¹PPG-GPTè¿›è¡Œå¾®è°ƒè™½ç„¶èƒ½æ˜¾è‘—é™ä½å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆé«˜è¾¾80%ï¼‰ï¼Œä½†åŒæ—¶ä¹Ÿå¯èƒ½æ‰©å¤§å…¬å¹³æ€§å·®è·ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹æ¨¡å‹å’Œæ•°æ®åˆ†å¸ƒå·®å¼‚æ˜¾è‘—çš„æƒ…å†µä¸‹ã€‚FairTuneæ¡†æ¶é›†æˆäº†ä¸‰ç§ç¼“è§£ç­–ç•¥ï¼šåŸºäºé€†ç¾¤ä½“é¢‘ç‡çš„ç±»åˆ«åŠ æƒï¼ˆIFï¼‰ã€ç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼ˆGroupDROï¼‰å’Œå¯¹æŠ—æ€§å»åï¼ˆADVï¼‰ã€‚å®éªŒè¡¨æ˜ï¼ŒIFå’ŒGroupDROèƒ½åœ¨ä¸ç‰ºç‰²å‡†ç¡®æ€§çš„å‰æä¸‹æ˜¾è‘—ç¼©å°å…¬å¹³æ€§å·®è·ã€‚è¡¨å¾åˆ†ææ˜¾ç¤ºï¼Œè¿™äº›ç¼“è§£æŠ€æœ¯é€šè¿‡é‡å¡‘å†…éƒ¨åµŒå…¥æ¥å‡å°‘äººå£ç»Ÿè®¡å­¦èšç±»ã€‚ç ”ç©¶å¼ºè°ƒï¼Œå…¬å¹³æ€§å¹¶éå¾®è°ƒçš„è‡ªç„¶ç»“æœï¼Œå¯¹äºç”Ÿç†åŸºç¡€æ¨¡å‹çš„å…¬å¹³éƒ¨ç½²ï¼Œæ˜¾å¼ç¼“è§£åè§è‡³å…³é‡è¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä½¿ç”¨é¢„è®­ç»ƒçš„PPGåŸºç¡€æ¨¡å‹è¿›è¡Œå¿ƒç‡é¢„æµ‹æ—¶ï¼Œé€šè¿‡å¾®è°ƒé€‚åº”ä¸åŒé¢†åŸŸæ•°æ®å¯èƒ½å¯¼è‡´å…¬å¹³æ€§ä¸‹é™çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¾€å¾€å¿½ç•¥äº†äººå£ç»Ÿè®¡å­¦åè§ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æŸäº›ç¾¤ä½“ä¸Šçš„è¡¨ç°æ˜æ˜¾å·®äºå…¶ä»–ç¾¤ä½“ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®åˆ†å¸ƒå­˜åœ¨å·®å¼‚çš„æƒ…å†µä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¼•å…¥åè§æ„ŸçŸ¥æœºåˆ¶ï¼Œé€šè¿‡æ˜¾å¼åœ°ç¼“è§£æ¨¡å‹ä¸­çš„åè§ï¼Œä»è€Œåœ¨ä¿è¯é¢„æµ‹ç²¾åº¦çš„åŒæ—¶ï¼Œæé«˜æ¨¡å‹åœ¨ä¸åŒäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ä¹‹é—´çš„å…¬å¹³æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡æ¢ç´¢äº†ä¸‰ç§ç¼“è§£ç­–ç•¥ï¼šç±»åˆ«åŠ æƒã€ç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–å’Œå¯¹æŠ—æ€§å»åã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFairTuneæ¡†æ¶çš„æ ¸å¿ƒåœ¨äºåœ¨æ ‡å‡†å¾®è°ƒæµç¨‹ä¸­åŠ å…¥åè§ç¼“è§£æ¨¡å—ã€‚è¯¥æ¡†æ¶é¦–å…ˆä½¿ç”¨é¢„è®­ç»ƒçš„PPG-GPTæ¨¡å‹ä½œä¸ºåŸºç¡€ï¼Œç„¶åé’ˆå¯¹ç›®æ ‡æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ ¹æ®é€‰æ‹©çš„ç¼“è§£ç­–ç•¥ï¼Œè°ƒæ•´æŸå¤±å‡½æ•°æˆ–è®­ç»ƒè¿‡ç¨‹ï¼Œä»¥å‡å°‘æ¨¡å‹ä¸­çš„åè§ã€‚æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦çš„ç¼“è§£ç­–ç•¥æ¨¡å—ï¼šç±»åˆ«åŠ æƒï¼ˆIFï¼‰ã€ç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼ˆGroupDROï¼‰å’Œå¯¹æŠ—æ€§å»åï¼ˆADVï¼‰ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªé€šç”¨çš„åè§æ„ŸçŸ¥å¾®è°ƒæ¡†æ¶FairTuneï¼Œå¹¶ç³»ç»Ÿåœ°è¯„ä¼°äº†ä¸‰ç§ä¸åŒçš„åè§ç¼“è§£ç­–ç•¥åœ¨å¿ƒç‡é¢„æµ‹ä»»åŠ¡ä¸­çš„æ•ˆæœã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFairTuneæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å‡å°‘åè§ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨ä¸åŒäººå£ç»Ÿè®¡å­¦ç¾¤ä½“ä¹‹é—´çš„å…¬å¹³æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜é€šè¿‡è¡¨å¾åˆ†æï¼Œæ·±å…¥ç ”ç©¶äº†ç¼“è§£ç­–ç•¥å¯¹æ¨¡å‹å†…éƒ¨åµŒå…¥çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šç±»åˆ«åŠ æƒï¼ˆIFï¼‰é€šè¿‡è°ƒæ•´æŸå¤±å‡½æ•°ä¸­ä¸åŒç±»åˆ«çš„æƒé‡ï¼Œæ¥å¹³è¡¡ä¸åŒç¾¤ä½“ä¹‹é—´çš„æ ·æœ¬æ•°é‡å·®å¼‚ã€‚ç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼ˆGroupDROï¼‰æ—¨åœ¨æœ€å°åŒ–æœ€å·®ç¾¤ä½“çš„æŸå¤±ï¼Œä»è€Œæé«˜æ¨¡å‹åœ¨æ‰€æœ‰ç¾¤ä½“ä¸Šçš„é²æ£’æ€§ã€‚å¯¹æŠ—æ€§å»åï¼ˆADVï¼‰é€šè¿‡å¼•å…¥ä¸€ä¸ªå¯¹æŠ—æ€§ç½‘ç»œï¼Œæ¥æ¶ˆé™¤æ¨¡å‹ä¸­çš„äººå£ç»Ÿè®¡å­¦ä¿¡æ¯ï¼Œä»è€Œå‡å°‘åè§ã€‚å…·ä½“å®ç°ç»†èŠ‚åŒ…æ‹¬ï¼šIFä½¿ç”¨é€†ç¾¤ä½“é¢‘ç‡ä½œä¸ºæƒé‡ï¼ŒGroupDROä½¿ç”¨min-maxä¼˜åŒ–ç®—æ³•ï¼ŒADVä½¿ç”¨æ¢¯åº¦åè½¬å±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFairTuneæ¡†æ¶ä¸­çš„ç±»åˆ«åŠ æƒï¼ˆIFï¼‰å’Œç¾¤ä½“åˆ†å¸ƒé²æ£’ä¼˜åŒ–ï¼ˆGroupDROï¼‰ç­–ç•¥èƒ½å¤Ÿåœ¨ä¸æ˜¾è‘—é™ä½å¿ƒç‡é¢„æµ‹ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ‰æ•ˆå‡å°å…¬å¹³æ€§å·®è·ã€‚å…·ä½“è€Œè¨€ï¼ŒIFå’ŒGroupDROåœ¨æŸäº›æ•°æ®é›†ä¸Šèƒ½å¤Ÿå°†å…¬å¹³æ€§æŒ‡æ ‡æå‡é«˜è¾¾20%ã€‚æ­¤å¤–ï¼Œè¡¨å¾åˆ†ææ˜¾ç¤ºï¼Œè¿™äº›ç¼“è§£ç­–ç•¥èƒ½å¤Ÿé‡å¡‘æ¨¡å‹çš„å†…éƒ¨åµŒå…¥ï¼Œå‡å°‘äººå£ç»Ÿè®¡å­¦èšç±»ï¼Œä»è€ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å¿ƒç‡ç›‘æµ‹åœºæ™¯ï¼Œä¾‹å¦‚è¿œç¨‹åŒ»ç–—ã€å¯ç©¿æˆ´è®¾å¤‡å’Œæ™ºèƒ½æ‰‹æœºåº”ç”¨ã€‚é€šè¿‡ä½¿ç”¨FairTuneæ¡†æ¶ï¼Œå¯ä»¥ç¡®ä¿å¿ƒç‡é¢„æµ‹æ¨¡å‹åœ¨ä¸åŒäººç¾¤ä¸­å…·æœ‰å…¬å¹³æ€§ï¼Œé¿å…å› æ¨¡å‹åå·®å¯¼è‡´å¯¹ç‰¹å®šäººç¾¤çš„å¥åº·é£é™©è¯„ä¼°ä¸å‡†ç¡®ã€‚è¿™å¯¹äºæé«˜åŒ»ç–—æœåŠ¡çš„å…¬å¹³æ€§å’Œå¯ä¿¡åº¦å…·æœ‰é‡è¦æ„ä¹‰ï¼Œå¹¶æœ‰åŠ©äºæ¨åŠ¨ä¸ªæ€§åŒ–åŒ»ç–—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models pretrained on physiological data such as photoplethysmography (PPG) signals are increasingly used to improve heart rate (HR) prediction across diverse settings. Fine-tuning these models for local deployment is often seen as a practical and scalable strategy. However, its impact on demographic fairness particularly under domain shifts remains underexplored. We fine-tune PPG-GPT a transformer-based foundation model pretrained on intensive care unit (ICU) data across three heterogeneous datasets (ICU, wearable, smartphone) and systematically evaluate the effects on HR prediction accuracy and gender fairness. While fine-tuning substantially reduces mean absolute error (up to 80%), it can simultaneously widen fairness gaps, especially in larger models and under significant distributional characteristics shifts. To address this, we introduce FairTune, a bias-aware fine-tuning framework in which we benchmark three mitigation strategies: class weighting based on inverse group frequency (IF), Group Distributionally Robust Optimization (GroupDRO), and adversarial debiasing (ADV). We find that IF and GroupDRO significantly reduce fairness gaps without compromising accuracy, with effectiveness varying by deployment domain. Representation analyses further reveal that mitigation techniques reshape internal embeddings to reduce demographic clustering. Our findings highlight that fairness does not emerge as a natural byproduct of fine-tuning and that explicit mitigation is essential for equitable deployment of physiological foundation models.

