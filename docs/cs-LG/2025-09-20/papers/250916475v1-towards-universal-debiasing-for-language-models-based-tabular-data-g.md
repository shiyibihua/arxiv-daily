---
layout: default
title: Towards Universal Debiasing for Language Models-based Tabular Data Generation
---

# Towards Universal Debiasing for Language Models-based Tabular Data Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16475" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16475v1</a>
  <a href="https://arxiv.org/pdf/2509.16475.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16475v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16475v1', 'Towards Universal Debiasing for Language Models-based Tabular Data Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianchun Li, Tianci Liu, Xingchen Wang, Rongzhe Wei, Pan Li, Lu Su, Jing Gao

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-20

**å¤‡æ³¨**: EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€šç”¨å»åæ¡†æ¶UDFï¼Œè§£å†³LLMç”Ÿæˆè¡¨æ ¼æ•°æ®ä¸­çš„å¤šé‡åè§é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ•°æ®ç”Ÿæˆ` `è¯­è¨€æ¨¡å‹` `å…¬å¹³æ€§` `å»åè§` `äº’ä¿¡æ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è¡¨æ ¼æ•°æ®é›†ä¸­å›ºæœ‰çš„åè§ä¼šå¯¼è‡´LLMåœ¨ç”Ÿæˆæ•°æ®æ—¶åŠ å‰§å…¬å¹³æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šä¸ªä¼˜åŠ¿å’Œå—ä¿æŠ¤ç‰¹å¾æ—¶ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§é€šç”¨å»åæ¡†æ¶UDFï¼Œé€šè¿‡æœ€å°åŒ–ä¼˜åŠ¿å±æ€§å’Œå—ä¿æŠ¤å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯æ¥å‡å°‘ç¾¤ä½“å±‚é¢çš„ä¾èµ–å…³ç³»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒUDFæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡å…¬å¹³æ€§å’Œæ•ˆç”¨ï¼Œä¸ºé«˜é£é™©åº”ç”¨æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å®ç”¨çš„å»åè§£å†³æ–¹æ¡ˆã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è¡¨æ ¼æ•°æ®ç”Ÿæˆæ–¹é¢å–å¾—äº†å¯å–œçš„æˆæœã€‚ç„¶è€Œï¼Œè¡¨æ ¼æ•°æ®é›†ä¸­å›ºæœ‰çš„å†å²åè§å¸¸å¸¸å¯¼è‡´LLMåŠ å‰§å…¬å¹³æ€§é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠå¤šä¸ªä¼˜åŠ¿ç‰¹å¾å’Œå—ä¿æŠ¤ç‰¹å¾æ—¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šç”¨å»åæ¡†æ¶ï¼Œé€šè¿‡åŒæ—¶å‡å°‘ä¼˜åŠ¿å±æ€§å’Œå—ä¿æŠ¤å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯æ¥æœ€å°åŒ–ç¾¤ä½“å±‚é¢çš„ä¾èµ–å…³ç³»ã€‚é€šè¿‡åˆ©ç”¨åŸºäºLLMçš„è¡¨æ ¼æ•°æ®ç”Ÿæˆå™¨çš„è‡ªå›å½’ç»“æ„å’Œè§£æé‡‡æ ·åˆ†å¸ƒï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿé«˜æ•ˆåœ°è®¡ç®—äº’ä¿¡æ¯ï¼Œå‡å°‘äº†å¯¹ç¹çæ•°å€¼ä¼°è®¡çš„éœ€æ±‚ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§äº’è¡¥çš„æ–¹æ³•ï¼šä¸€ç§åŸºäºç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰çš„ç­–ç•¥ï¼Œå³UDF-DPOï¼Œå¯ä»¥ä¸ç°æœ‰æ¨¡å‹æ— ç¼é›†æˆï¼›ä»¥åŠä¸€ç§æœ‰é’ˆå¯¹æ€§çš„å»åæŠ€æœ¯ï¼Œå³UDF-MIXï¼Œå¯ä»¥åœ¨ä¸è°ƒæ•´LLMå‚æ•°çš„æƒ…å†µä¸‹å®ç°å»åã€‚å¤§é‡çš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶æœ‰æ•ˆåœ°å¹³è¡¡äº†å…¬å¹³æ€§å’Œæ•ˆç”¨ï¼Œä¸ºé«˜é£é™©åº”ç”¨ä¸­çš„å»åæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŸºäºLLMçš„è¡¨æ ¼æ•°æ®ç”Ÿæˆä¸­å­˜åœ¨çš„åè§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šä¸ªä¼˜åŠ¿ç‰¹å¾å’Œå—ä¿æŠ¤ç‰¹å¾æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆå‡å°‘ç¾¤ä½“å±‚é¢çš„ä¾èµ–å…³ç³»ï¼Œå¯¼è‡´ç”Ÿæˆçš„æ•°æ®å¸¦æœ‰åè§ï¼Œå½±å“å…¬å¹³æ€§ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦ç¹ççš„æ•°å€¼ä¼°è®¡æ¥è®¡ç®—äº’ä¿¡æ¯ï¼Œæ•ˆç‡è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æœ€å°åŒ–ä¼˜åŠ¿å±æ€§å’Œå—ä¿æŠ¤å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯æ¥å®ç°å»åã€‚é€šè¿‡é™ä½è¿™äº›å±æ€§ä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œå¯ä»¥å‡å°‘LLMåœ¨ç”Ÿæˆæ•°æ®æ—¶å¯¹ç‰¹å®šç¾¤ä½“çš„è¿‡åº¦ä¾èµ–ï¼Œä»è€Œæé«˜å…¬å¹³æ€§ã€‚åˆ©ç”¨LLMçš„è‡ªå›å½’ç»“æ„å’Œè§£æé‡‡æ ·åˆ†å¸ƒï¼Œå¯ä»¥é«˜æ•ˆåœ°è®¡ç®—äº’ä¿¡æ¯ï¼Œé¿å…äº†ç¹ççš„æ•°å€¼ä¼°è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ–¹æ³•ï¼šUDF-DPOå’ŒUDF-MIXã€‚UDF-DPOæ˜¯ä¸€ç§åŸºäºç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰çš„ç­–ç•¥ï¼Œå®ƒé€šè¿‡è°ƒæ•´LLMçš„å‚æ•°æ¥å‡å°‘åè§ã€‚UDF-MIXæ˜¯ä¸€ç§æœ‰é’ˆå¯¹æ€§çš„å»åæŠ€æœ¯ï¼Œå®ƒé€šè¿‡æ··åˆä¸åŒçš„ç”Ÿæˆç­–ç•¥æ¥å‡å°‘åè§ï¼Œè€Œæ— éœ€è°ƒæ•´LLMçš„å‚æ•°ã€‚ä¸¤ç§æ–¹æ³•éƒ½åŸºäºäº’ä¿¡æ¯æœ€å°åŒ–çš„åŸåˆ™ï¼Œæ—¨åœ¨å‡å°‘ä¼˜åŠ¿å±æ€§å’Œå—ä¿æŠ¤å±æ€§ä¹‹é—´çš„ä¾èµ–å…³ç³»ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§é€šç”¨çš„å»åæ¡†æ¶ï¼Œè¯¥æ¡†æ¶å¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªä¼˜åŠ¿ç‰¹å¾å’Œå—ä¿æŠ¤ç‰¹å¾ï¼Œå¹¶ä¸”èƒ½å¤Ÿé«˜æ•ˆåœ°è®¡ç®—äº’ä¿¡æ¯ã€‚UDF-DPOå’ŒUDF-MIXä¸¤ç§æ–¹æ³•åˆ†åˆ«ä»£è¡¨äº†ä¸¤ç§ä¸åŒçš„å»åç­–ç•¥ï¼Œå‰è€…é€šè¿‡è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œåè€…é€šè¿‡æ··åˆç”Ÿæˆç­–ç•¥ï¼Œä¸ºä¸åŒçš„åº”ç”¨åœºæ™¯æä¾›äº†çµæ´»çš„é€‰æ‹©ã€‚

**å…³é”®è®¾è®¡**ï¼šUDF-DPOä½¿ç”¨DPOç®—æ³•æ¥ä¼˜åŒ–LLMçš„å‚æ•°ï¼Œç›®æ ‡æ˜¯æœ€å°åŒ–ä¼˜åŠ¿å±æ€§å’Œå—ä¿æŠ¤å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚UDF-MIXé€šè¿‡æ··åˆä¸åŒçš„ç”Ÿæˆç­–ç•¥æ¥å‡å°‘åè§ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥æ··åˆä½¿ç”¨åŸºäºæ¡ä»¶æ¦‚ç‡çš„ç”Ÿæˆç­–ç•¥å’ŒåŸºäºæ— æ¡ä»¶æ¦‚ç‡çš„ç”Ÿæˆç­–ç•¥ã€‚äº’ä¿¡æ¯çš„è®¡ç®—åˆ©ç”¨äº†LLMçš„è‡ªå›å½’ç»“æ„å’Œè§£æé‡‡æ ·åˆ†å¸ƒï¼Œé¿å…äº†ç¹ççš„æ•°å€¼ä¼°è®¡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°è®¾è®¡å’Œå‚æ•°è®¾ç½®åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒUDFæ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡å…¬å¹³æ€§å’Œæ•ˆç”¨ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒUDF-DPOå’ŒUDF-MIXåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šéƒ½å–å¾—äº†æ›´å¥½çš„å…¬å¹³æ€§æŒ‡æ ‡ï¼ŒåŒæ—¶ä¿æŒäº†è¾ƒé«˜çš„ç”Ÿæˆæ•°æ®è´¨é‡ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†è¯¥æ¡†æ¶åœ¨é«˜é£é™©åº”ç”¨ä¸­çš„å®ç”¨æ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé‡‘èã€åŒ»ç–—ã€æ•™è‚²ç­‰é«˜é£é™©é¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ•°æ®çš„å…¬å¹³æ€§è‡³å…³é‡è¦ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¿¡è´·é£é™©è¯„ä¼°ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•ç”Ÿæˆæ›´å…¬å¹³çš„ä¿¡ç”¨è¯„åˆ†æ¨¡å‹ï¼Œé¿å…å¯¹ç‰¹å®šç¾¤ä½“äº§ç”Ÿæ­§è§†ã€‚åœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œå¯ä»¥ç”Ÿæˆæ›´å…¬å¹³çš„è¯Šæ–­æ¨¡å‹ï¼Œé¿å…å› ç§æ—ã€æ€§åˆ«ç­‰å› ç´ å¯¼è‡´è¯¯è¯Šæˆ–æ¼è¯Šã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæ„å»ºæ›´å…¬å¹³ã€å…¬æ­£çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) have achieved promising results in tabular data generation. However, inherent historical biases in tabular datasets often cause LLMs to exacerbate fairness issues, particularly when multiple advantaged and protected features are involved. In this work, we introduce a universal debiasing framework that minimizes group-level dependencies by simultaneously reducing the mutual information between advantaged and protected attributes. By leveraging the autoregressive structure and analytic sampling distributions of LLM-based tabular data generators, our approach efficiently computes mutual information, reducing the need for cumbersome numerical estimations. Building on this foundation, we propose two complementary methods: a direct preference optimization (DPO)-based strategy, namely UDF-DPO, that integrates seamlessly with existing models, and a targeted debiasing technique, namely UDF-MIX, that achieves debiasing without tuning the parameters of LLMs. Extensive experiments demonstrate that our framework effectively balances fairness and utility, offering a scalable and practical solution for debiasing in high-stakes applications.

