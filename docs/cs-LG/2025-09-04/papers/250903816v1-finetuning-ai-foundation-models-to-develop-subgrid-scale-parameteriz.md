---
layout: default
title: Finetuning AI Foundation Models to Develop Subgrid-Scale Parameterizations: A Case Study on Atmospheric Gravity Waves
---

# Finetuning AI Foundation Models to Develop Subgrid-Scale Parameterizations: A Case Study on Atmospheric Gravity Waves

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03816" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03816v1</a>
  <a href="https://arxiv.org/pdf/2509.03816.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03816v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03816v1', 'Finetuning AI Foundation Models to Develop Subgrid-Scale Parameterizations: A Case Study on Atmospheric Gravity Waves')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aman Gupta, Aditi Sheshadri, Sujit Roy, Johannes Schmude, Vishal Gaur, Wei Ji Leong, Manil Maskey, Rahul Ramachandran

**åˆ†ç±»**: physics.ao-ph, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**å¾®è°ƒAIåŸºç¡€æ¨¡å‹ï¼Œä¸ºå¤§æ°”é‡åŠ›æ³¢å¼€å‘æ¬¡ç½‘æ ¼å°ºåº¦å‚æ•°åŒ–æ–¹æ¡ˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `AIåŸºç¡€æ¨¡å‹` `æ°”å€™æ¨¡å‹` `å‚æ•°åŒ–` `é‡åŠ›æ³¢` `å¾®è°ƒ` `æ·±åº¦å­¦ä¹ ` `æ¬¡ç½‘æ ¼å°ºåº¦` `å¤§æ°”ç§‘å­¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å…¨çƒæ°”å€™æ¨¡å‹ä¸­æ¬¡ç½‘æ ¼å°ºåº¦è¿‡ç¨‹çš„å‚æ•°åŒ–æ˜¯æ¨¡å‹ä¸ç¡®å®šæ€§çš„ä¸»è¦æ¥æºï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥å‡†ç¡®å»ºæ¨¡ã€‚
2. åˆ©ç”¨é¢„è®­ç»ƒçš„AIåŸºç¡€æ¨¡å‹ï¼Œé€šè¿‡å¾®è°ƒæ–¹å¼å­¦ä¹ é«˜åˆ†è¾¨ç‡æ•°æ®ä¸­çš„é€šé‡ï¼Œä»è€Œä¸ºç²—åˆ†è¾¨ç‡æ¨¡å‹æä¾›æ›´å‡†ç¡®çš„å‚æ•°åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¾®è°ƒåçš„æ¨¡å‹åœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œå°¤å…¶æ˜¯åœ¨é¢„è®­ç»ƒæœªè¦†ç›–çš„åŒºåŸŸï¼ŒHellingerè·ç¦»æ˜¾è‘—é™ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å…¨çƒæ°”å€™æ¨¡å‹å¯¹æ— æ³•å……åˆ†è§£æçš„å¤§æ°”-æµ·æ´‹è¿‡ç¨‹ï¼ˆå¦‚é‡åŠ›æ³¢ã€äº‘ã€æ¹¿å¯¹æµå’Œæ¹æµï¼‰è¿›è¡Œå‚æ•°åŒ–ã€‚è¿™äº›æœªè§£æè¿‡ç¨‹çš„æ¬¡ç½‘æ ¼å°ºåº¦é—­åˆæ˜¯æ¨¡å‹ä¸ç¡®å®šæ€§çš„ä¸»è¦æ¥æºã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œé€šè¿‡å¾®è°ƒé¢„è®­ç»ƒçš„AIåŸºç¡€æ¨¡å‹ï¼ˆFMï¼‰æ¥å¼€å‘å°å°ºåº¦æ°”å€™è¿‡ç¨‹çš„æœºå™¨å­¦ä¹ å‚æ•°åŒ–æ–¹æ¡ˆã€‚FMåœ¨æ°”å€™ç ”ç©¶ä¸­å°šæœªè¢«å……åˆ†æ¢ç´¢ã€‚æ¥è‡ªä¸€ä¸ª23äº¿å‚æ•°FMï¼ˆNASAå’ŒIBM Researchçš„Prithvi WxCï¼‰çš„é¢„è®­ç»ƒç¼–ç å™¨-è§£ç å™¨ï¼ŒåŒ…å«å¤§æ°”æ¼”åŒ–çš„æ½œåœ¨æ¦‚ç‡è¡¨ç¤ºï¼Œè¢«å¾®è°ƒï¼ˆæˆ–é‡ç”¨ï¼‰ä»¥åˆ›å»ºä¸€ä¸ªç”¨äºå¤§æ°”é‡åŠ›æ³¢ï¼ˆGWsï¼‰çš„æ·±åº¦å­¦ä¹ å‚æ•°åŒ–æ–¹æ¡ˆã€‚è¯¥å‚æ•°åŒ–æ–¹æ¡ˆé€šè¿‡å­¦ä¹ æ¥è‡ªå…·æœ‰10å€ç²¾ç»†åˆ†è¾¨ç‡çš„å¤§æ°”å†åˆ†æçš„é€šé‡ï¼Œæ¥æ•è·ç²—åˆ†è¾¨ç‡æ°”å€™æ¨¡å‹çš„GWæ•ˆåº”ã€‚ä¸æœºå™¨å­¦ä¹ æ¨¡å‹åŸºçº¿ï¼ˆAttention U-Netï¼‰çš„æœˆå¹³å‡å€¼å’Œç¬æ—¶æ¼”åŒ–çš„æ¯”è¾ƒè¡¨æ˜ï¼ŒFMå‚æ•°åŒ–æ–¹æ¡ˆåœ¨æ•´ä¸ªå¤§æ°”ä¸­éƒ½å…·æœ‰å“è¶Šçš„é¢„æµ‹æ€§èƒ½ï¼Œå³ä½¿åœ¨é¢„è®­ç»ƒä¸­æ’é™¤çš„åŒºåŸŸä¹Ÿæ˜¯å¦‚æ­¤ã€‚è¿™ç§æ€§èƒ½æå‡ä½¿ç”¨Hellingerè·ç¦»è¿›è¡Œé‡åŒ–ï¼ŒåŸºçº¿ä¸º0.11ï¼Œå¾®è°ƒæ¨¡å‹ä¸º0.06ã€‚ç ”ç©¶ç»“æœå¼ºè°ƒäº†FMçš„å¤šåŠŸèƒ½æ€§å’Œå¯é‡ç”¨æ€§ï¼Œå¯ç”¨äºå®Œæˆä¸€ç³»åˆ—ä¸å¤§æ°”å’Œæ°”å€™ç›¸å…³çš„åº”ç”¨ï¼Œä»è€Œä¸ºæ›´å¤šåœ°çƒç³»ç»Ÿè¿‡ç¨‹åˆ›å»ºç”±è§‚æµ‹é©±åŠ¨ä¸”ç‰©ç†ä¸Šå‡†ç¡®çš„å‚æ•°åŒ–æ–¹æ¡ˆé“ºå¹³é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå…¨çƒæ°”å€™æ¨¡å‹éœ€è¦å¯¹æ— æ³•ç›´æ¥è§£æçš„æ¬¡ç½‘æ ¼å°ºåº¦è¿‡ç¨‹è¿›è¡Œå‚æ•°åŒ–ï¼Œä¾‹å¦‚å¤§æ°”é‡åŠ›æ³¢ã€‚ä¼ ç»Ÿçš„å‚æ•°åŒ–æ–¹æ³•å­˜åœ¨è¾ƒå¤§çš„ä¸ç¡®å®šæ€§ï¼Œå½±å“äº†æ°”å€™æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦ã€‚ç°æœ‰çš„æœºå™¨å­¦ä¹ æ–¹æ³•è™½ç„¶å¯ä»¥å­¦ä¹ è¿™äº›è¿‡ç¨‹ï¼Œä½†å¾€å¾€éœ€è¦ä»å¤´å¼€å§‹è®­ç»ƒï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„AIåŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelï¼‰çš„å¼ºå¤§è¡¨å¾èƒ½åŠ›ï¼Œé€šè¿‡å¾®è°ƒçš„æ–¹å¼ï¼Œä½¿å…¶é€‚åº”ç‰¹å®šçš„æ°”å€™è¿‡ç¨‹å‚æ•°åŒ–ä»»åŠ¡ã€‚è¿™ç§æ–¹æ³•å¯ä»¥æœ‰æ•ˆåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹ä¸­å·²ç»å­¦ä¹ åˆ°çš„é€šç”¨çŸ¥è¯†ï¼Œå‡å°‘è®­ç»ƒæ—¶é—´å’Œæ•°æ®éœ€æ±‚ï¼Œå¹¶æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä½¿ç”¨NASAå’ŒIBM Researchçš„Prithvi WxCæ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«23äº¿å‚æ•°çš„é¢„è®­ç»ƒç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ã€‚è¯¥æ¨¡å‹å·²ç»å­¦ä¹ äº†å¤§æ°”æ¼”åŒ–çš„æ½œåœ¨æ¦‚ç‡è¡¨ç¤ºã€‚ç ”ç©¶äººå‘˜å°†è¯¥æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶èƒ½å¤Ÿå­¦ä¹ é«˜åˆ†è¾¨ç‡å¤§æ°”å†åˆ†ææ•°æ®ä¸­çš„é‡åŠ›æ³¢é€šé‡ï¼Œä»è€Œä¸ºç²—åˆ†è¾¨ç‡æ°”å€™æ¨¡å‹æä¾›å‚æ•°åŒ–æ–¹æ¡ˆã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) é€‰æ‹©åˆé€‚çš„é¢„è®­ç»ƒæ¨¡å‹ï¼›2) å‡†å¤‡é«˜åˆ†è¾¨ç‡è®­ç»ƒæ•°æ®ï¼›3) å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹çš„ç¼–ç å™¨-è§£ç å™¨éƒ¨åˆ†ï¼›4) åœ¨ç²—åˆ†è¾¨ç‡æ°”å€™æ¨¡å‹ä¸­é›†æˆå¾®è°ƒåçš„å‚æ•°åŒ–æ–¹æ¡ˆï¼›5) è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†AIåŸºç¡€æ¨¡å‹å¼•å…¥æ°”å€™è¿‡ç¨‹å‚æ•°åŒ–é¢†åŸŸã€‚ä¸ä¼ ç»Ÿçš„ä»å¤´å¼€å§‹è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼Œå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹å¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å±•ç¤ºäº†AIåŸºç¡€æ¨¡å‹åœ¨æ°”å€™ç ”ç©¶ä¸­çš„å¤šåŠŸèƒ½æ€§å’Œå¯é‡ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­ä½¿ç”¨äº†Hellingerè·ç¦»ä½œä¸ºè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ã€‚Attention U-Netè¢«ç”¨ä½œåŸºçº¿æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚å…³é”®å‚æ•°åŒ…æ‹¬å¾®è°ƒçš„å­¦ä¹ ç‡ã€è®­ç»ƒepochsä»¥åŠæŸå¤±å‡½æ•°çš„é€‰æ‹©ã€‚å…·ä½“ç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨æ‘˜è¦ä¸­è¯¦ç»†æè¿°ï¼Œä½†å¼ºè°ƒäº†ç¼–ç å™¨-è§£ç å™¨ç»“æ„çš„é‡è¦æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡å¾®è°ƒAIåŸºç¡€æ¨¡å‹å¾—åˆ°çš„å‚æ•°åŒ–æ–¹æ¡ˆåœ¨é¢„æµ‹æ€§èƒ½ä¸Šä¼˜äºä¼ ç»Ÿçš„Attention U-Netæ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œå¾®è°ƒæ¨¡å‹çš„Hellingerè·ç¦»ä¸º0.06ï¼Œè€ŒåŸºçº¿æ¨¡å‹çš„Hellingerè·ç¦»ä¸º0.11ï¼Œè¡¨æ˜å¾®è°ƒæ¨¡å‹åœ¨æ•æ‰å¤§æ°”é‡åŠ›æ³¢æ•ˆåº”æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œå³ä½¿åœ¨é¢„è®­ç»ƒæ•°æ®æœªè¦†ç›–çš„åŒºåŸŸä¹Ÿè¡¨ç°è‰¯å¥½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ”¹è¿›å…¨çƒæ°”å€™æ¨¡å‹ä¸­å¤§æ°”é‡åŠ›æ³¢çš„å‚æ•°åŒ–ï¼Œä»è€Œæé«˜æ°”å€™æ¨¡å‹çš„é¢„æµ‹ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–æ°”å€™è¿‡ç¨‹çš„å‚æ•°åŒ–ï¼Œä¾‹å¦‚äº‘ã€æ¹¿å¯¹æµå’Œæ¹æµç­‰ã€‚é€šè¿‡æ„å»ºæ›´å‡†ç¡®ã€æ›´é«˜æ•ˆçš„å‚æ•°åŒ–æ–¹æ¡ˆï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹æ°”å€™å˜åŒ–ï¼Œä¸ºåº”å¯¹æ°”å€™å˜åŒ–æä¾›ç§‘å­¦ä¾æ®ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Global climate models parameterize a range of atmospheric-oceanic processes like gravity waves, clouds, moist convection, and turbulence that cannot be sufficiently resolved. These subgrid-scale closures for unresolved processes are a leading source of model uncertainty. Here, we present a new approach to developing machine learning parameterizations of small-scale climate processes by fine-tuning a pre-trained AI foundation model (FM). FMs are largely unexplored in climate research. A pre-trained encoder-decoder from a 2.3 billion parameter FM (NASA and IBM Research's Prithvi WxC) -- which contains a latent probabilistic representation of atmospheric evolution -- is fine-tuned (or reused) to create a deep learning parameterization for atmospheric gravity waves (GWs). The parameterization captures GW effects for a coarse-resolution climate model by learning the fluxes from an atmospheric reanalysis with 10 times finer resolution. A comparison of monthly averages and instantaneous evolution with a machine learning model baseline (an Attention U-Net) reveals superior predictive performance of the FM parameterization throughout the atmosphere, even in regions excluded from pre-training. This performance boost is quantified using the Hellinger distance, which is 0.11 for the baseline and 0.06 for the fine-tuned model. Our findings emphasize the versatility and reusability of FMs, which could be used to accomplish a range of atmosphere- and climate-related applications, leading the way for the creation of observations-driven and physically accurate parameterizations for more earth-system processes.

