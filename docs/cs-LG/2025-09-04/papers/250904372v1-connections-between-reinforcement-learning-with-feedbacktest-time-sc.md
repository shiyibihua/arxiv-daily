---
layout: default
title: Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology
---

# Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04372" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04372v1</a>
  <a href="https://arxiv.org/pdf/2509.04372.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04372v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04372v1', 'Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuchen Jiao, Yuxin Chen, Gen Li

**åˆ†ç±»**: stat.ML, cs.GL, cs.LG, math.ST

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ­ç¤ºå¼ºåŒ–å­¦ä¹ ã€æµ‹è¯•æ—¶ç¼©æ”¾ä¸æ‰©æ•£å¼•å¯¼çš„å†…åœ¨è”ç³»ï¼Œæå‡ºé‡é‡‡æ ·å¯¹é½æ–¹æ³•ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `æ‰©æ•£æ¨¡å‹` `æµ‹è¯•æ—¶ç¼©æ”¾` `é‡é‡‡æ ·` `åé¦ˆå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åè®­ç»ƒæŠ€æœ¯ä¹‹é—´ç¼ºä¹ç³»ç»Ÿæ€§çš„è”ç³»ï¼Œé˜»ç¢äº†ç®—æ³•çš„ç†è§£å’Œæ”¹è¿›ã€‚
2. è®ºæ–‡æ ¸å¿ƒåœ¨äºæ­ç¤ºå¼ºåŒ–å­¦ä¹ ã€æµ‹è¯•æ—¶ç¼©æ”¾å’Œæ‰©æ•£å¼•å¯¼ä¹‹é—´çš„å†…åœ¨è”ç³»å’Œç­‰ä»·æ€§ã€‚
3. æå‡ºä¸€ç§é‡é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºå¯¹é½å’Œå¥–åŠ±å¯¼å‘æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€æ˜¾å¼å¼ºåŒ–å­¦ä¹ ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†å¤šç§å¸¸ç”¨åè®­ç»ƒæŠ€æœ¯ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚æˆ‘ä»¬é˜æ˜äº†å¸¦äººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ã€å¸¦å†…éƒ¨åé¦ˆçš„å¼ºåŒ–å­¦ä¹ å’Œæµ‹è¯•æ—¶ç¼©æ”¾ï¼ˆç‰¹åˆ«æ˜¯è½¯æœ€ä½³Né€‰1é‡‡æ ·ï¼‰ä¹‹é—´çš„ç´§å¯†è”ç³»å’Œç­‰ä»·æ€§ï¼ŒåŒæ—¶ä¹Ÿæ­ç¤ºäº†æ‰©æ•£å¼•å¯¼å’Œæµ‹è¯•æ—¶ç¼©æ”¾ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†ä¸€ç§ç”¨äºå¯¹é½å’Œå¥–åŠ±å¯¼å‘æ‰©æ•£æ¨¡å‹çš„é‡é‡‡æ ·æ–¹æ³•ï¼Œé¿å…äº†å¯¹æ˜¾å¼å¼ºåŒ–å­¦ä¹ æŠ€æœ¯çš„éœ€æ±‚ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ–¹æ³•åœ¨åè®­ç»ƒé˜¶æ®µï¼Œå¦‚åˆ©ç”¨äººç±»åé¦ˆè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€æµ‹è¯•æ—¶ç¼©æ”¾ä»¥åŠæ‰©æ•£æ¨¡å‹å¼•å¯¼ç­‰ï¼Œé€šå¸¸è¢«è§†ä¸ºç‹¬ç«‹çš„ä¼˜åŒ–ç­–ç•¥ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¹‹é—´å¯èƒ½å­˜åœ¨å†…åœ¨çš„è”ç³»å’Œç­‰ä»·æ€§ï¼Œç†è§£è¿™äº›è”ç³»æœ‰åŠ©äºæ›´å¥½åœ°è®¾è®¡å’Œæ”¹è¿›ç®—æ³•ã€‚è®ºæ–‡æ—¨åœ¨æ­ç¤ºè¿™äº›æ–¹æ³•ä¹‹é—´çš„è”ç³»ï¼Œå¹¶æå‡ºä¸€ç§æ–°çš„å¯¹é½æ–¹æ³•ï¼Œä»¥ç®€åŒ–å¥–åŠ±å¯¼å‘æ‰©æ•£æ¨¡å‹çš„è®­ç»ƒã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å‘ç°ä¸åŒåè®­ç»ƒæŠ€æœ¯ä¹‹é—´çš„æ•°å­¦ç­‰ä»·æ€§ï¼Œå¹¶åˆ©ç”¨è¿™äº›ç­‰ä»·æ€§æ¥è®¾è®¡æ–°çš„ç®—æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œè®ºæ–‡å°†å¸¦åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ã€æµ‹è¯•æ—¶ç¼©æ”¾å’Œæ‰©æ•£å¼•å¯¼è”ç³»èµ·æ¥ï¼Œè¡¨æ˜å®ƒä»¬åœ¨æŸç§ç¨‹åº¦ä¸Šå¯ä»¥ç›¸äº’è½¬åŒ–ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ç§é‡é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡ç›´æ¥æ“çºµæ•°æ®åˆ†å¸ƒæ¥å®ç°å¯¹é½ï¼Œä»è€Œé¿å…äº†æ˜¾å¼å¼ºåŒ–å­¦ä¹ çš„éœ€è¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡ä¸»è¦é€šè¿‡ç†è®ºåˆ†æå’Œç®—æ³•è®¾è®¡æ¥å»ºç«‹ä¸åŒæ–¹æ³•ä¹‹é—´çš„è”ç³»ã€‚é¦–å…ˆï¼Œè®ºæ–‡åˆ†æäº†å¸¦åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ã€æµ‹è¯•æ—¶ç¼©æ”¾å’Œæ‰©æ•£å¼•å¯¼çš„æ•°å­¦å½¢å¼ï¼Œæ­ç¤ºäº†å®ƒä»¬ä¹‹é—´çš„ç­‰ä»·æ€§ã€‚ç„¶åï¼Œè®ºæ–‡åŸºäºè¿™äº›ç­‰ä»·æ€§ï¼Œæå‡ºäº†ä¸€ç§é‡é‡‡æ ·æ–¹æ³•ï¼Œç”¨äºå¯¹é½å’Œå¥–åŠ±å¯¼å‘æ‰©æ•£æ¨¡å‹ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯¹æ•°æ®è¿›è¡Œé‡é‡‡æ ·ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ‹Ÿåˆå¥–åŠ±å‡½æ•°ï¼Œä»è€Œå®ç°æ›´å¥½çš„ç”Ÿæˆæ•ˆæœã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæ­ç¤ºäº†ä¸åŒåè®­ç»ƒæŠ€æœ¯ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„é‡é‡‡æ ·æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥é‡é‡‡æ ·æ–¹æ³•ä¸éœ€è¦æ˜¾å¼åœ°è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡ç›´æ¥æ“çºµæ•°æ®åˆ†å¸ƒæ¥å®ç°å¯¹é½ï¼Œä»è€Œç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡é‡‡æ ·æ–¹æ³•çš„å…³é”®åœ¨äºå¦‚ä½•é€‰æ‹©é‡é‡‡æ ·çš„æƒé‡ã€‚è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºå¥–åŠ±å‡½æ•°çš„æƒé‡é€‰æ‹©ç­–ç•¥ï¼Œè¯¥ç­–ç•¥æ ¹æ®æ•°æ®æ ·æœ¬çš„å¥–åŠ±å€¼æ¥ç¡®å®šå…¶é‡é‡‡æ ·çš„æ¦‚ç‡ã€‚å…·ä½“æ¥è¯´ï¼Œå¥–åŠ±å€¼è¶Šé«˜çš„æ ·æœ¬ï¼Œå…¶é‡é‡‡æ ·çš„æ¦‚ç‡è¶Šé«˜ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è€ƒè™‘äº†æ ·æœ¬çš„å¤šæ ·æ€§ï¼Œé¿å…è¿‡åº¦é‡‡æ ·é«˜å¥–åŠ±å€¼çš„æ ·æœ¬ï¼Œä»è€Œä¿è¯äº†ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„é‡é‡‡æ ·æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æœ‰æ•ˆåœ°å¯¹é½å’Œå¥–åŠ±å¯¼å‘æ‰©æ•£æ¨¡å‹ï¼Œæ— éœ€æ˜¾å¼å¼ºåŒ–å­¦ä¹ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä»¥ç”Ÿæˆé«˜è´¨é‡çš„å›¾åƒå’Œæ–‡æœ¬ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹ä¼˜äºä¼ ç»Ÿçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒç”Ÿæˆã€æ–‡æœ¬ç”Ÿæˆç­‰é¢†åŸŸï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦äººå·¥åé¦ˆæˆ–å¥–åŠ±å¼•å¯¼çš„åœºæ™¯ä¸‹ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•è®­ç»ƒç”Ÿæˆå¯¹æŠ—ç½‘ç»œï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆæ›´ç¬¦åˆäººç±»åå¥½çš„å›¾åƒæˆ–æ–‡æœ¬ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæœºå™¨äººæ§åˆ¶ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å®Œæˆä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this note, we reflect on several fundamental connections among widely used post-training techniques. We clarify some intimate connections and equivalences between reinforcement learning with human feedback, reinforcement learning with internal feedback, and test-time scaling (particularly soft best-of-$N$ sampling), while also illuminating intrinsic links between diffusion guidance and test-time scaling. Additionally, we introduce a resampling approach for alignment and reward-directed diffusion models, sidestepping the need for explicit reinforcement learning techniques.

