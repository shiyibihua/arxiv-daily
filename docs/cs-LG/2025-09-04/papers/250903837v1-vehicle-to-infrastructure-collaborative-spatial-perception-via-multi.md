---
layout: default
title: Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models
---

# Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03837" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.03837v1</a>
  <a href="https://arxiv.org/pdf/2509.03837.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03837v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03837v1', 'Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Kimia Ehsani, Walid Saad

**ÂàÜÁ±ª**: cs.LG, cs.IT

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-04

**Â§áÊ≥®**: Accepted at IEEE GLOBECOM 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éBEVÊ≥®ÂÖ•ÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåÊèêÂçáV2IÈÄö‰ø°ÈìæË∑ØË¥®ÈáèÈ¢ÑÊµãÁ≤æÂ∫¶„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ËΩ¶Ë∑ØÂçèÂêå` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `È∏üÁû∞Âõæ` `ÈìæË∑ØË¥®ÈáèÈ¢ÑÊµã` `Á©∫Èó¥ÊÑüÁü•`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâV2IÈÄö‰ø°ÈìæË∑ØË¥®ÈáèÈ¢ÑÊµãÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®ËΩ¶ËæÜ‰º†ÊÑüÂô®Êï∞ÊçÆÔºå‰∏îÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁº∫‰πèÁ©∫Èó¥ÁêÜËß£ËÉΩÂäõ„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçBEVÊ≥®ÂÖ•Ê°ÜÊû∂ÔºåËûçÂêàÁõ∏ÈÇªËΩ¶ËæÜÊÑüÁü•Êï∞ÊçÆÊûÑÂª∫ÁéØÂ¢ÉÈ∏üÁû∞ÂõæÔºå‰∏∫MLLMÊèê‰æõÁ©∫Èó¥‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•Ê°ÜÊû∂Âú®ÂêÑÁßçV2IÈìæË∑ØÈ¢ÑÊµã‰ªªÂä°‰∏≠ÂùáÊúâÊòæËëóÊèêÂçáÔºåÂ∞§ÂÖ∂Âú®ÊÅ∂Âä£Â§©Ê∞î‰∏ãË°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á≤æÁ°ÆÈ¢ÑÊµãÈÄö‰ø°ÈìæË∑ØË¥®ÈáèÊåáÊ†áÂØπ‰∫éËΩ¶Ë∑ØÂçèÂêåÔºàV2IÔºâÁ≥ªÁªüËá≥ÂÖ≥ÈáçË¶ÅÔºåÂÆÉËÉΩÂÆûÁé∞Âπ≥ÊªëÂàáÊç¢„ÄÅÈ´òÊïàÊ≥¢ÊùüÁÆ°ÁêÜÂíåÂèØÈù†ÁöÑ‰ΩéÂª∂ËøüÈÄö‰ø°„ÄÇÁé∞‰ª£ËΩ¶ËæÜ‰º†ÊÑüÂô®Êï∞ÊçÆÁöÑÊó•ÁõäÊôÆÂèä‰øÉ‰Ωø‰∫∫‰ª¨‰ΩøÁî®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÔºåÂõ†‰∏∫ÂÆÉ‰ª¨ÂÖ∑ÊúâË∑®‰ªªÂä°ÈÄÇÂ∫îÊÄßÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇÁÑ∂ËÄåÔºåMLLM Êú¨Ë∫´Áº∫‰πè‰∏âÁª¥Á©∫Èó¥ÁêÜËß£„ÄÇ‰∏∫‰∫ÜÂÖãÊúçËøô‰∏™ÈôêÂà∂ÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçËΩªÈáèÁ∫ßÁöÑ„ÄÅÂç≥ÊèíÂç≥Áî®ÁöÑÈ∏üÁû∞ÂõæÔºàBEVÔºâÊ≥®ÂÖ•ËøûÊé•Âô®„ÄÇÂú®ËØ•Ê°ÜÊû∂‰∏≠ÔºåÈÄöËøáÊî∂ÈõÜÁõ∏ÈÇªËΩ¶ËæÜÁöÑÊÑüÁü•Êï∞ÊçÆÊù•ÊûÑÂª∫ÁéØÂ¢ÉÁöÑ BEV„ÄÇÁÑ∂ÂêéÔºåÂ∞ÜÊ≠§ BEV Ë°®Á§∫‰∏éËá™ËΩ¶ËæìÂÖ•ËûçÂêàÔºå‰ªéËÄå‰∏∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÁ©∫Èó¥‰∏ä‰∏ãÊñá„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÁúüÂÆûÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†ÔºåÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÁªìÂêà CARLA Ê®°ÊãüÂô®ÂíåÂü∫‰∫é MATLAB ÁöÑÂ∞ÑÁ∫øËøΩË∏™ÁöÑËÅîÂêà‰ªøÁúüÁéØÂ¢ÉÔºå‰ª•ÁîüÊàêÂêÑÁßçÂú∫ÊôØ‰∏ãÁöÑ RGB„ÄÅLiDAR„ÄÅGPS ÂíåÊó†Á∫ø‰ø°Âè∑Êï∞ÊçÆ„ÄÇÊåá‰ª§ÂíåÁúüÂÆûÂìçÂ∫î‰ª•ÁºñÁ®ãÊñπÂºè‰ªéÂ∞ÑÁ∫øËøΩË∏™ËæìÂá∫‰∏≠ÊèêÂèñ„ÄÇÂú®‰∏â‰∏™ V2I ÈìæË∑ØÈ¢ÑÊµã‰ªªÂä°ÔºàËßÜË∑ùÔºàLoSÔºâ‰∏éÈùûËßÜË∑ùÔºàNLoSÔºâÂàÜÁ±ª„ÄÅÈìæË∑ØÂèØÁî®ÊÄßÂíåÈòªÂ°ûÈ¢ÑÊµãÔºâ‰∏äËøõË°å‰∫ÜÂπøÊ≥õÁöÑÂÆûÈ™å„ÄÇ‰ªøÁúüÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑ BEV Ê≥®ÂÖ•Ê°ÜÊû∂ÂßãÁªàÊèêÈ´ò‰∫ÜÊâÄÊúâ‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇÁªìÊûúË°®ÊòéÔºå‰∏é‰ªÖ‰ΩøÁî®Ëá™ËΩ¶ÁöÑÂü∫Á∫øÁõ∏ÊØîÔºåÊâÄÊèêÂá∫ÁöÑÊñπÊ≥ïÂ∞ÜÂáÜÁ°ÆÁéáÊåáÊ†áÁöÑÂÆèÂπ≥ÂùáÂÄºÊèêÈ´ò‰∫ÜÈ´òËææ 13.9%„ÄÇÁªìÊûúËøòË°®ÊòéÔºåÂú®ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈõ®Â§©ÂíåÂ§úÈó¥Êù°‰ª∂‰∏ãÔºåËøôÁßçÊÄßËÉΩÊèêÂçáÈ´òËææ 32.7%ÔºåËØÅÂÆû‰∫ÜËØ•Ê°ÜÊû∂Âú®‰∏çÂà©ÁéØÂ¢É‰∏≠ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥V2IÈÄö‰ø°‰∏≠ÂáÜÁ°ÆÈ¢ÑÊµãÈìæË∑ØË¥®ÈáèÁöÑÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®ËΩ¶ËæÜ‰º†ÊÑüÂô®Êï∞ÊçÆÔºå‰∏îÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÊú¨Ë∫´Áº∫‰πèÂØπ‰∏âÁª¥Á©∫Èó¥‰ø°ÊÅØÁöÑÁêÜËß£ÔºåÂØºËá¥È¢ÑÊµãÁ≤æÂ∫¶ÂèóÈôê„ÄÇÂ∞§ÂÖ∂ÊòØÂú®Â§çÊùÇÁéØÂ¢ÉÂíåÊÅ∂Âä£Â§©Ê∞îÊù°‰ª∂‰∏ãÔºåÈ¢ÑÊµãÊÄßËÉΩ‰ºöÊòæËëó‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÊûÑÂª∫ÁéØÂ¢ÉÁöÑÈ∏üÁû∞ÂõæÔºàBEVÔºâÔºå‰∏∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõ‰∏∞ÂØåÁöÑÁ©∫Èó¥‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇÈÄöËøáËûçÂêàËá™ËΩ¶ÂíåÂë®Âõ¥ËΩ¶ËæÜÁöÑÊÑüÁü•Êï∞ÊçÆÔºåÁîüÊàêBEVË°®Á§∫Ôºå‰ªéËÄåÂº•Ë°•LLMÂú®Á©∫Èó¥ÁêÜËß£ÊñπÈù¢ÁöÑ‰∏çË∂≥„ÄÇËøôÁßçÊñπÊ≥ïËÉΩÂ§ü‰ΩøLLMÊõ¥Â•ΩÂú∞ÁêÜËß£ËΩ¶ËæÜÂë®Âõ¥ÁöÑÁéØÂ¢ÉÔºå‰ªéËÄåÊõ¥ÂáÜÁ°ÆÂú∞È¢ÑÊµãÈìæË∑ØË¥®Èáè„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) Êï∞ÊçÆÈááÈõÜÔºöÈÄöËøáCARLAÊ®°ÊãüÂô®ÂíåMATLABÂ∞ÑÁ∫øËøΩË∏™ËÅîÂêà‰ªøÁúüÁéØÂ¢ÉÔºåÁîüÊàêRGB„ÄÅLiDAR„ÄÅGPSÂíåÊó†Á∫ø‰ø°Âè∑Êï∞ÊçÆ„ÄÇ2) BEVÊûÑÂª∫ÔºöÂà©Áî®Áõ∏ÈÇªËΩ¶ËæÜÁöÑÊÑüÁü•Êï∞ÊçÆÊûÑÂª∫ÁéØÂ¢ÉÁöÑÈ∏üÁû∞Âõæ„ÄÇ3) Â§öÊ®°ÊÄÅËûçÂêàÔºöÂ∞ÜBEVË°®Á§∫‰∏éËá™ËΩ¶ËæìÂÖ•ËûçÂêàÔºåÂΩ¢ÊàêÂåÖÂê´Á©∫Èó¥‰ø°ÊÅØÁöÑËæìÂÖ•„ÄÇ4) MLLMÈ¢ÑÊµãÔºöÂ∞ÜËûçÂêàÂêéÁöÑÊï∞ÊçÆËæìÂÖ•Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåËøõË°åÈìæË∑ØË¥®ÈáèÈ¢ÑÊµã„ÄÇ5) ËØÑ‰º∞ÔºöÊ†πÊçÆÂ∞ÑÁ∫øËøΩË∏™ËæìÂá∫ÊèêÂèñÁöÑground truthÔºåËØÑ‰º∞È¢ÑÊµãÁªìÊûú„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑ„ÄÅÂç≥ÊèíÂç≥Áî®ÁöÑBEVÊ≥®ÂÖ•ËøûÊé•Âô®ÔºåËÉΩÂ§üÊúâÊïàÂú∞Â∞ÜÁ©∫Èó¥‰ø°ÊÅØËûçÂÖ•Âà∞Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠„ÄÇ‰∏é‰º†ÁªüÁöÑÁõ¥Êé•‰ΩøÁî®LLMËøõË°åÈ¢ÑÊµãÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊòæËëóÊèêÈ´òÈ¢ÑÊµãÁ≤æÂ∫¶ÔºåÂ∞§ÂÖ∂ÊòØÂú®ÊÅ∂Âä£Â§©Ê∞îÊù°‰ª∂‰∏ã„ÄÇÊ≠§Â§ñÔºåËÅîÂêà‰ªøÁúüÁéØÂ¢ÉÁöÑÊûÑÂª∫‰πü‰∏∫Â§öÊ®°ÊÄÅÂ≠¶‰π†Êèê‰æõ‰∫ÜrealisticÁöÑÊï∞ÊçÆÊîØÊåÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöBEVÁöÑÊûÑÂª∫ÊñπÂºèÊòØÂÖ≥ÈîÆËÆæËÆ°‰πã‰∏ÄÔºåËÆ∫Êñá‰∏≠ÂÖ∑‰ΩìÂ¶Ç‰ΩïÊûÑÂª∫BEVÔºå‰ª•ÂèäÂ¶Ç‰ΩïËøõË°åÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÁªÜËäÇÊú™ËØ¶ÁªÜÊèèËø∞„ÄÇÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰πüÊú™ÊèêÂèä„ÄÇÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåÈááÁî®‰∫ÜMLLMÔºå‰ΩÜÂÖ∑‰ΩìÊ®°ÂûãÈÄâÊã©ÂíåÂèÇÊï∞ËÆæÁΩÆÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÂá∫ÁöÑBEVÊ≥®ÂÖ•Ê°ÜÊû∂Âú®ËßÜË∑ù/ÈùûËßÜË∑ùÂàÜÁ±ª„ÄÅÈìæË∑ØÂèØÁî®ÊÄßÂíåÈòªÂ°ûÈ¢ÑÊµãÁ≠âV2IÈìæË∑ØÈ¢ÑÊµã‰ªªÂä°‰∏≠ÂùáÂèñÂæó‰∫ÜÊòæËëóÊèêÂçá„ÄÇ‰∏é‰ªÖ‰ΩøÁî®Ëá™ËΩ¶ÁöÑÂü∫Á∫øÁõ∏ÊØîÔºåÂáÜÁ°ÆÁéáÊåáÊ†áÁöÑÂÆèÂπ≥ÂùáÂÄºÊèêÈ´ò‰∫ÜÈ´òËææ13.9%„ÄÇÂú®Èõ®Â§©ÂíåÂ§úÈó¥Á≠âÊÅ∂Âä£Êù°‰ª∂‰∏ãÔºåÊÄßËÉΩÊèêÂçáÈ´òËææ32.7%ÔºåÈ™åËØÅ‰∫ÜËØ•Ê°ÜÊû∂ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩ‰∫§ÈÄöÁ≥ªÁªü„ÄÅËá™Âä®È©æÈ©∂„ÄÅËΩ¶Ë∑ØÂçèÂêåÁ≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÊèêÂçáV2IÈÄö‰ø°ÈìæË∑ØË¥®ÈáèÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄßÔºåÂèØ‰ª•‰ºòÂåñËµÑÊ∫êÂàÜÈÖç„ÄÅÊèêÈ´òÈÄö‰ø°ÊïàÁéá„ÄÅÈôç‰ΩéÂª∂ËøüÔºå‰ªéËÄåÊîπÂñÑÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂‰∏∫Ëá™Âä®È©æÈ©∂ËΩ¶ËæÜÊèê‰æõÊõ¥ÂèØÈù†ÁöÑÁéØÂ¢ÉÊÑüÁü•„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Accurate prediction of communication link quality metrics is essential for vehicle-to-infrastructure (V2I) systems, enabling smooth handovers, efficient beam management, and reliable low-latency communication. The increasing availability of sensor data from modern vehicles motivates the use of multimodal large language models (MLLMs) because of their adaptability across tasks and reasoning capabilities. However, MLLMs inherently lack three-dimensional spatial understanding. To overcome this limitation, a lightweight, plug-and-play bird's-eye view (BEV) injection connector is proposed. In this framework, a BEV of the environment is constructed by collecting sensing data from neighboring vehicles. This BEV representation is then fused with the ego vehicle's input to provide spatial context for the large language model. To support realistic multimodal learning, a co-simulation environment combining CARLA simulator and MATLAB-based ray tracing is developed to generate RGB, LiDAR, GPS, and wireless signal data across varied scenarios. Instructions and ground-truth responses are programmatically extracted from the ray-tracing outputs. Extensive experiments are conducted across three V2I link prediction tasks: line-of-sight (LoS) versus non-line-of-sight (NLoS) classification, link availability, and blockage prediction. Simulation results show that the proposed BEV injection framework consistently improved performance across all tasks. The results indicate that, compared to an ego-only baseline, the proposed approach improves the macro-average of the accuracy metrics by up to 13.9%. The results also show that this performance gain increases by up to 32.7% under challenging rainy and nighttime conditions, confirming the robustness of the framework in adverse settings.

