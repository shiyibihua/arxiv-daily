---
layout: default
title: PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference
---

# PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.04377" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.04377v1</a>
  <a href="https://arxiv.org/pdf/2509.04377.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.04377v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.04377v1', 'PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Krishna Teja Chitty-Venkata, Jie Ye, Xian-He Sun, Anthony Kougkas, Murali Emani, Venkatram Vishwanath, Bogdan Nicolae

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PagedEvictionï¼šç”¨äºé«˜æ•ˆå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„ç»“æ„åŒ–å—çº§KVç¼“å­˜å‰ªæ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `KVç¼“å­˜` `å†…å­˜ä¼˜åŒ–` `PagedAttention` `æ¨ç†åŠ é€Ÿ` `é•¿æ–‡æœ¬å¤„ç†` `å—çº§é©±é€` `åˆ†é¡µå†…å­˜`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰KVç¼“å­˜æ–¹æ³•åœ¨é•¿åºåˆ—åœºæ™¯ä¸‹å†…å­˜æ¶ˆè€—å·¨å¤§ï¼Œæˆä¸ºLLMæ¨ç†çš„ç“¶é¢ˆã€‚
2. PagedEvictionæå‡ºäº†ä¸€ç§å—çº§KVç¼“å­˜å‰ªæç­–ç•¥ï¼Œä¸“ä¸ºåˆ†é¡µå†…å­˜å¸ƒå±€è®¾è®¡ï¼Œæå‡å†…å­˜æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒPagedEvictionåœ¨é•¿æ–‡æœ¬ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œèƒ½æå‡å†…å­˜åˆ©ç”¨ç‡å¹¶ä¿æŒæˆ–æå‡ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

KVç¼“å­˜é€šè¿‡å­˜å‚¨å…ˆå‰å¤„ç†çš„tokençš„æ³¨æ„åŠ›çŠ¶æ€ï¼Œæ˜¾è‘—æé«˜äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†çš„æ•ˆç‡ï¼Œä»è€Œèƒ½å¤Ÿæ›´å¿«åœ°ç”Ÿæˆåç»­tokenã€‚ç„¶è€Œï¼Œéšç€åºåˆ—é•¿åº¦çš„å¢åŠ ï¼ŒKVç¼“å­˜è¿…é€Ÿæˆä¸ºä¸»è¦çš„å†…å­˜ç“¶é¢ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PagedEvictionï¼Œä¸€ç§æ–°é¢–çš„ç»†ç²’åº¦ã€ç»“æ„åŒ–çš„KVç¼“å­˜å‰ªæç­–ç•¥ï¼Œå®ƒå¢å¼ºäº†vLLMçš„PagedAttentionçš„å†…å­˜æ•ˆç‡ã€‚ä¸ä¾èµ–äºåŸºäºæ³¨æ„åŠ›çš„tokené‡è¦æ€§æˆ–è·¨ä¸åŒvLLMé¡µé¢é©±é€tokençš„ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒPagedEvictionå¼•å…¥äº†ä¸€ç§ä¸“ä¸ºåˆ†é¡µå†…å­˜å¸ƒå±€è®¾è®¡çš„æœ‰æ•ˆå—çº§é©±é€ç®—æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸PagedAttentionæ— ç¼é›†æˆï¼Œæ— éœ€å¯¹å…¶CUDAæ³¨æ„åŠ›å†…æ ¸è¿›è¡Œä»»ä½•ä¿®æ”¹ã€‚æˆ‘ä»¬åœ¨LongBenchåŸºå‡†æµ‹è¯•å¥—ä»¶ä¸Šè¯„ä¼°äº†Llama-3.1-8B-Instructã€Llama-3.2-1B-Instructå’ŒLlama-3.2-3B-Instructæ¨¡å‹ä¸Šçš„PagedEvictionï¼Œè¯æ˜äº†åœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ï¼Œä¸åŸºçº¿ç›¸æ¯”ï¼Œæé«˜äº†å†…å­˜ä½¿ç”¨ç‡å¹¶å…·æœ‰æ›´å¥½çš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒKVç¼“å­˜éšç€åºåˆ—é•¿åº¦å¢åŠ è¿…é€Ÿè†¨èƒ€ï¼Œæˆä¸ºå†…å­˜ç“¶é¢ˆã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆåŸºäºæ³¨æ„åŠ›é‡è¦æ€§è¿›è¡Œtokençº§åˆ«çš„é©±é€ï¼Œè¦ä¹ˆè·¨vLLMé¡µé¢è¿›è¡Œé©±é€ï¼Œæ•ˆç‡è¾ƒä½ï¼Œä¸”å¯èƒ½å½±å“æ¨¡å‹ç²¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPagedEvictionçš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨vLLMçš„PagedAttentionæœºåˆ¶ï¼Œåœ¨åˆ†é¡µå†…å­˜å¸ƒå±€ä¸Šè¿›è¡Œç»“æ„åŒ–çš„å—çº§é©±é€ã€‚é€šè¿‡ç²¾ç»†æ§åˆ¶æ¯ä¸ªé¡µé¢çš„ç¼“å­˜ä½¿ç”¨ï¼Œé¿å…ä¸å¿…è¦çš„å†…å­˜å ç”¨ï¼ŒåŒæ—¶å°½é‡å‡å°‘å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPagedEvictionä¸vLLMçš„PagedAttentionæ— ç¼é›†æˆï¼Œæ— éœ€ä¿®æ”¹ç°æœ‰çš„CUDAæ³¨æ„åŠ›å†…æ ¸ã€‚å®ƒä¸»è¦åŒ…å«ä¸€ä¸ªå—çº§é©±é€ç®—æ³•ï¼Œè¯¥ç®—æ³•æ ¹æ®æŸç§ç­–ç•¥ï¼ˆä¾‹å¦‚ï¼Œæœ€å°‘ä½¿ç”¨åŸåˆ™ï¼‰é€‰æ‹©è¦é©±é€çš„é¡µé¢å—ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼šåœ¨ç”Ÿæˆæ¯ä¸ªtokenæ—¶ï¼Œæ£€æŸ¥KVç¼“å­˜çš„ä½¿ç”¨æƒ…å†µï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼ï¼Œåˆ™è§¦å‘å—çº§é©±é€ç®—æ³•ï¼Œé‡Šæ”¾éƒ¨åˆ†ç¼“å­˜ç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šPagedEvictionçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»“æ„åŒ–çš„å—çº§é©±é€ç­–ç•¥ï¼Œå®ƒå……åˆ†åˆ©ç”¨äº†PagedAttentionçš„åˆ†é¡µå†…å­˜å¸ƒå±€ã€‚ä¸ä¼ ç»Ÿçš„tokençº§åˆ«é©±é€ç›¸æ¯”ï¼Œå—çº§é©±é€å¯ä»¥å‡å°‘é©±é€æ“ä½œçš„é¢‘ç‡ï¼Œæé«˜æ•ˆç‡ã€‚ä¸è·¨é¡µé¢é©±é€ç›¸æ¯”ï¼ŒPagedEvictionåœ¨å•ä¸ªé¡µé¢å†…è¿›è¡Œé©±é€ï¼Œå¯ä»¥æ›´å¥½åœ°æ§åˆ¶ç¼“å­˜çš„å±€éƒ¨æ€§ï¼Œå‡å°‘å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šPagedEvictionçš„å…³é”®è®¾è®¡åœ¨äºå—çº§é©±é€ç®—æ³•çš„é€‰æ‹©ã€‚è®ºæ–‡ä¸­å¯èƒ½é‡‡ç”¨äº†æŸç§å¯å‘å¼ç®—æ³•ï¼Œä¾‹å¦‚æœ€å°‘ä½¿ç”¨ï¼ˆLRUï¼‰æˆ–æœ€ä¸å¸¸ç”¨ï¼ˆLFUï¼‰çš„å˜ä½“ï¼Œæ¥é€‰æ‹©è¦é©±é€çš„é¡µé¢å—ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å¯èƒ½åŒ…æ‹¬æ¯ä¸ªé¡µé¢çš„å¤§å°ã€é©±é€çš„é˜ˆå€¼ç­‰ã€‚è¿™äº›å‚æ•°éœ€è¦æ ¹æ®å…·ä½“çš„æ¨¡å‹å’Œä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä»¥è¾¾åˆ°æœ€ä½³çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡åœ¨Llama-3.1-8B-Instructã€Llama-3.2-1B-Instructå’ŒLlama-3.2-3B-Instructæ¨¡å‹ä¸Šï¼Œä½¿ç”¨LongBenchåŸºå‡†æµ‹è¯•å¥—ä»¶è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPagedEvictionåœ¨é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡ä¸­ï¼Œç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼Œæé«˜äº†å†…å­˜ä½¿ç”¨ç‡ï¼Œå¹¶ä¸”åœ¨ä¿è¯æˆ–æå‡æ¨¡å‹å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæœ‰æ•ˆé™ä½äº†KVç¼“å­˜çš„å†…å­˜å ç”¨ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PagedEvictionå¯åº”ç”¨äºå„ç§éœ€è¦å¤„ç†é•¿åºåˆ—çš„å¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†åœºæ™¯ï¼Œä¾‹å¦‚é•¿æ–‡æœ¬ç”Ÿæˆã€æ–‡æ¡£æ‘˜è¦ã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡é™ä½å†…å­˜éœ€æ±‚ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä½¿æ›´å¤§çš„æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šè¿è¡Œï¼Œæˆ–è€…åœ¨ç›¸åŒçš„ç¡¬ä»¶èµ„æºä¸‹æ”¯æŒæ›´é«˜çš„å¹¶å‘ç”¨æˆ·æ•°ï¼Œä»è€Œæé«˜LLMçš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> KV caching significantly improves the efficiency of Large Language Model (LLM) inference by storing attention states from previously processed tokens, enabling faster generation of subsequent tokens. However, as sequence length increases, the KV cache quickly becomes a major memory bottleneck. To address this, we propose PagedEviction, a novel fine-grained, structured KV cache pruning strategy that enhances the memory efficiency of vLLM's PagedAttention. Unlike existing approaches that rely on attention-based token importance or evict tokens across different vLLM pages, PagedEviction introduces an efficient block-wise eviction algorithm tailored for paged memory layouts. Our method integrates seamlessly with PagedAttention without requiring any modifications to its CUDA attention kernels. We evaluate PagedEviction across Llama-3.1-8B-Instruct, Llama-3.2-1B-Instruct, and Llama-3.2-3B-Instruct models on the LongBench benchmark suite, demonstrating improved memory usage with better accuracy than baselines on long context tasks.

