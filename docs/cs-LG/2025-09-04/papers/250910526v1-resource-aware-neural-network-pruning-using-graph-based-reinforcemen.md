---
layout: default
title: Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning
---

# Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10526" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10526v1</a>
  <a href="https://arxiv.org/pdf/2509.10526.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10526v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10526v1', 'Resource-Aware Neural Network Pruning Using Graph-based Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dieter Balemans, Thomas Huybrechts, Jan Steckel, Siegfried Mercelis

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå›¾å¼ºåŒ–å­¦ä¹ çš„èµ„æºæ„ŸçŸ¥å‹ç¥ç»ç½‘ç»œå‰ªææ–¹æ³•ï¼Œæå‡å‰ªææ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¥ç»ç½‘ç»œå‰ªæ` `å›¾ç¥ç»ç½‘ç»œ` `å¼ºåŒ–å­¦ä¹ ` `AutoML` `æ¨¡å‹å‹ç¼©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å‰ªææ–¹æ³•ä¾èµ–æ‰‹å·¥å¯å‘å¼å’Œå±€éƒ¨ä¼˜åŒ–ï¼Œå¯¼è‡´æ€§èƒ½æ¬¡ä¼˜å’Œæ•ˆç‡ä½ä¸‹ã€‚
2. æå‡ºåŸºäºå›¾çš„å¼ºåŒ–å­¦ä¹ å‰ªææ¡†æ¶ï¼Œåˆ©ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œç¼–ç ç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼Œå­¦ä¹ æœ€ä¼˜é€šé“é‡è¦æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ CIFAR å’Œ ImageNet ç­‰æ•°æ®é›†ä¸Šä¼˜äºä¼ ç»Ÿå‰ªææŠ€æœ¯ï¼Œè¾¾åˆ°SOTAã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¥ç»ç½‘ç»œå‰ªææ–¹æ³•ï¼Œè¯¥æ–¹æ³•å°†åŸºäºå›¾çš„è§‚å¯Ÿç©ºé—´é›†æˆåˆ° AutoML æ¡†æ¶ä¸­ï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ã€‚ä¼ ç»Ÿçš„å‰ªææ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„å¯å‘å¼æ–¹æ³•å’Œå±€éƒ¨ä¼˜åŒ–è§†è§’ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¬¡ä¼˜çš„æ€§èƒ½å’Œä½æ•ˆçš„å‰ªæç­–ç•¥ã€‚æˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡å¼•å…¥ç›®æ ‡ç¥ç»ç½‘ç»œçš„å›¾è¡¨ç¤ºæ¥è½¬æ¢å‰ªæè¿‡ç¨‹ï¼Œè¯¥å›¾è¡¨ç¤ºæ•è·å±‚å’Œé€šé“ä¹‹é—´çš„å®Œæ•´æ‹“æ‰‘å…³ç³»ï¼Œç”¨ç½‘ç»œç»“æ„çš„å…¨å±€è§†å›¾å–ä»£äº†æœ‰é™çš„é€å±‚è§‚å¯Ÿç©ºé—´ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬ä¸€ä¸ªå›¾æ³¨æ„åŠ›ç½‘ç»œ (GAT) ç¼–ç å™¨ï¼Œå®ƒå¤„ç†ç½‘ç»œçš„å›¾è¡¨ç¤ºå¹¶ç”Ÿæˆä¸°å¯Œçš„åµŒå…¥ã€‚æ­¤å¤–ï¼Œå¯¹äºåŠ¨ä½œç©ºé—´ï¼Œæˆ‘ä»¬ä»è¿ç»­çš„å‰ªæç‡è¿‡æ¸¡åˆ°ç»†ç²’åº¦çš„äºŒå…ƒåŠ¨ä½œç©ºé—´ï¼Œè¿™ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿç›´æ¥ä»æ•°æ®ä¸­å­¦ä¹ æœ€ä½³é€šé“é‡è¦æ€§æ ‡å‡†ï¼Œä»è€Œæ‘†è„±äº†é¢„å®šä¹‰çš„è¯„åˆ†å‡½æ•°ã€‚è¿™äº›è´¡çŒ®åœ¨çº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (CMDP) æ¡†æ¶ä¸­å»ºæ¨¡ï¼Œå…è®¸æ™ºèƒ½ä½“åœ¨æ»¡è¶³èµ„æºçº¦æŸï¼ˆå¦‚ç›®æ ‡å‹ç¼©ç‡ï¼‰çš„åŒæ—¶åšå‡ºæ˜æ™ºçš„å‰ªæå†³ç­–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªè‡ªæˆ‘ç«äº‰å¥–åŠ±ç³»ç»Ÿï¼Œé¼“åŠ±æ™ºèƒ½ä½“åœ¨æ»¡è¶³å®šä¹‰çš„çº¦æŸçš„åŒæ—¶è¶…è¶Šå…¶å…ˆå‰çš„æœ€ä½³æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡åœ¨åŒ…æ‹¬ CIFAR-10ã€CIFAR-100 å’Œ ImageNet åœ¨å†…çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºä¼ ç»Ÿçš„å‰ªææŠ€æœ¯ï¼Œæ˜¾ç¤ºå‡ºæœ€å…ˆè¿›çš„ç»“æœï¼ŒåŒæ—¶å­¦ä¹ ç‰¹å®šäºä»»åŠ¡çš„å‰ªæç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥å¯ä»¥è¯†åˆ«åŠŸèƒ½ä¸Šå†—ä½™çš„è¿æ¥ï¼Œè€Œä¸ä»…ä»…æ˜¯ç®€å•çš„æƒé‡å¹…åº¦è€ƒè™‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„ç¥ç»ç½‘ç»œå‰ªææ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹å·¥è®¾è®¡çš„å¯å‘å¼è§„åˆ™å’Œå±€éƒ¨ä¼˜åŒ–ç­–ç•¥ï¼Œç¼ºä¹å¯¹ç½‘ç»œå…¨å±€ç»“æ„çš„æ„ŸçŸ¥ï¼Œå¯¼è‡´å‰ªææ•ˆæœä¸ä½³ï¼Œéš¾ä»¥è¾¾åˆ°æœ€ä¼˜çš„å‹ç¼©ç‡å’Œæ€§èƒ½å¹³è¡¡ã€‚æ­¤å¤–ï¼Œé¢„å®šä¹‰çš„è¯„åˆ†å‡½æ•°æ— æ³•å……åˆ†åˆ©ç”¨æ•°æ®ä¿¡æ¯ï¼Œéš¾ä»¥è¯†åˆ«çœŸæ­£å†—ä½™çš„è¿æ¥ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç¥ç»ç½‘ç»œçš„å‰ªæè¿‡ç¨‹å»ºæ¨¡ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œå¹¶å¼•å…¥å›¾ç»“æ„æ¥è¡¨ç¤ºç½‘ç»œçš„æ‹“æ‰‘å…³ç³»ã€‚é€šè¿‡å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰å­¦ä¹ ç½‘ç»œä¸­æ¯ä¸ªè¿æ¥çš„é‡è¦æ€§ï¼Œå¹¶ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“æ ¹æ®èµ„æºçº¦æŸï¼ˆå¦‚å‹ç¼©ç‡ï¼‰åšå‡ºå‰ªæå†³ç­–ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿå…¨å±€åœ°ä¼˜åŒ–å‰ªæç­–ç•¥ï¼Œå¹¶ä»æ•°æ®ä¸­å­¦ä¹ ä»»åŠ¡ç›¸å…³çš„å‰ªææ¨¡å¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŸºäºçº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆCMDPï¼‰ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) å›¾è¡¨ç¤ºæ¨¡å—ï¼šå°†ç¥ç»ç½‘ç»œè¡¨ç¤ºä¸ºä¸€ä¸ªå›¾ï¼ŒèŠ‚ç‚¹ä»£è¡¨å±‚æˆ–é€šé“ï¼Œè¾¹ä»£è¡¨è¿æ¥å…³ç³»ã€‚2) å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰ç¼–ç å™¨ï¼šå¤„ç†å›¾è¡¨ç¤ºï¼Œä¸ºæ¯ä¸ªèŠ‚ç‚¹ç”ŸæˆåµŒå…¥å‘é‡ï¼Œæ•æ‰èŠ‚ç‚¹çš„é‡è¦æ€§ä¿¡æ¯ã€‚3) å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“ï¼šæ ¹æ®GATçš„è¾“å‡ºï¼Œåšå‡ºäºŒå…ƒå‰ªæå†³ç­–ï¼ˆä¿ç•™æˆ–å‰ªé™¤é€šé“ï¼‰ã€‚4) å¥–åŠ±å‡½æ•°ï¼šè®¾è®¡ä¸€ä¸ªè‡ªæˆ‘ç«äº‰å¥–åŠ±ç³»ç»Ÿï¼Œé¼“åŠ±æ™ºèƒ½ä½“åœ¨æ»¡è¶³èµ„æºçº¦æŸçš„åŒæ—¶ï¼Œè¶…è¶Šå…¶å…ˆå‰çš„æœ€ä½³æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºï¼š1) ä½¿ç”¨å›¾ç»“æ„è¡¨ç¤ºç¥ç»ç½‘ç»œï¼Œèƒ½å¤Ÿæ•æ‰å…¨å±€æ‹“æ‰‘å…³ç³»ã€‚2) ä½¿ç”¨å›¾æ³¨æ„åŠ›ç½‘ç»œå­¦ä¹ è¿æ¥çš„é‡è¦æ€§ï¼Œé¿å…äº†æ‰‹å·¥è®¾è®¡å¯å‘å¼è§„åˆ™ã€‚3) å°†å‰ªæè¿‡ç¨‹å»ºæ¨¡ä¸ºçº¦æŸé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ˜¾å¼åœ°è€ƒè™‘èµ„æºçº¦æŸã€‚4) é‡‡ç”¨ç»†ç²’åº¦çš„äºŒå…ƒåŠ¨ä½œç©ºé—´ï¼Œå…è®¸æ™ºèƒ½ä½“ç›´æ¥å­¦ä¹ é€šé“é‡è¦æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šGATç¼–ç å™¨ä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ï¼Œå­¦ä¹ èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚å¥–åŠ±å‡½æ•°åŒ…å«ä¸¤éƒ¨åˆ†ï¼šæ€§èƒ½å¥–åŠ±å’Œçº¦æŸæƒ©ç½šã€‚æ€§èƒ½å¥–åŠ±é¼“åŠ±æ™ºèƒ½ä½“æé«˜å‰ªæåç½‘ç»œçš„æ€§èƒ½ï¼Œçº¦æŸæƒ©ç½šåˆ™æƒ©ç½šè¿åèµ„æºçº¦æŸçš„è¡Œä¸ºã€‚æ™ºèƒ½ä½“ä½¿ç”¨PPOç®—æ³•è¿›è¡Œè®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨ CIFAR-10ã€CIFAR-100 å’Œ ImageNet ç­‰åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¼˜äºä¼ ç»Ÿçš„å‰ªææŠ€æœ¯ï¼Œå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¿æŒç”šè‡³æé«˜æ¨¡å‹ç²¾åº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½æ¨¡å‹çš„å‚æ•°é‡å’Œè®¡ç®—é‡ï¼Œè¯æ˜äº†å…¶åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦æ¨¡å‹å‹ç¼©å’ŒåŠ é€Ÿçš„åœºæ™¯ï¼Œä¾‹å¦‚ç§»åŠ¨è®¾å¤‡ä¸Šçš„å›¾åƒè¯†åˆ«ã€è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿä¸­çš„ç›®æ ‡æ£€æµ‹ã€ä»¥åŠèµ„æºå—é™çš„è¾¹ç¼˜è®¡ç®—ç¯å¢ƒã€‚é€šè¿‡è‡ªåŠ¨å­¦ä¹ ä»»åŠ¡ç›¸å…³çš„å‰ªæç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—é™ä½æ¨¡å‹å¤§å°å’Œè®¡ç®—å¤æ‚åº¦ï¼Œæé«˜éƒ¨ç½²æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper presents a novel approach to neural network pruning by integrating a graph-based observation space into an AutoML framework to address the limitations of existing methods. Traditional pruning approaches often depend on hand-crafted heuristics and local optimization perspectives, which can lead to suboptimal performance and inefficient pruning strategies. Our framework transforms the pruning process by introducing a graph representation of the target neural network that captures complete topological relationships between layers and channels, replacing the limited layer-wise observation space with a global view of network structure. The core innovations include a Graph Attention Network (GAT) encoder that processes the network's graph representation and generates a rich embedding. Additionally, for the action space we transition from continuous pruning ratios to fine-grained binary action spaces which enables the agent to learn optimal channel importance criteria directly from data, moving away from predefined scoring functions. These contributions are modelled within a Constrained Markov Decision Process (CMDP) framework, allowing the agent to make informed pruning decisions while adhering to resource constraints such as target compression rates. For this, we design a self-competition reward system that encourages the agent to outperform its previous best performance while satisfying the defined constraints. We demonstrate the effectiveness of our approach through extensive experiments on benchmark datasets including CIFAR-10, CIFAR-100, and ImageNet. The experiments show that our method consistently outperforms traditional pruning techniques, showing state-of-the-art results while learning task-specific pruning strategies that identify functionally redundant connections beyond simple weight magnitude considerations.

