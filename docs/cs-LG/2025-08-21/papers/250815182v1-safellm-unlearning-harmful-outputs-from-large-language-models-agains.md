---
layout: default
title: SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks
---

# SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15182" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15182v1</a>
  <a href="https://arxiv.org/pdf/2508.15182.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15182v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15182v1', 'SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiangman Li, Xiaodong Wu, Qi Li, Jianbing Ni, Rongxing Lu

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-21

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSafeLLMä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„ç›‘ç‹±çªç ´æ”»å‡»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å»å­¦ä¹ ` `å®‰å…¨æ€§` `ç›‘ç‹±çªç ´æ”»å‡»` `å†…å®¹è¿‡æ»¤` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åº”å¯¹ç›‘ç‹±çªç ´æ”»å‡»æ—¶ï¼Œæ— æ³•æœ‰æ•ˆå»é™¤æœ‰å®³çŸ¥è¯†ï¼Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆä¸å®‰å…¨å†…å®¹ã€‚
2. SafeLLMé€šè¿‡å»å­¦ä¹ æœºåˆ¶ï¼Œç»“åˆåŠ¨æ€æ£€æµ‹å’Œä¼˜åŒ–ç­–ç•¥ï¼Œæœ‰æ•ˆå»é™¤æœ‰å®³çŸ¥è¯†ï¼Œç¡®ä¿æ¨¡å‹å®‰å…¨æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSafeLLMåœ¨å¤šä¸ªç›‘ç‹±çªç ´åŸºå‡†ä¸Šæ˜¾è‘—é™ä½æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒé«˜æ€§èƒ½ï¼Œä¼˜äºä¼ ç»Ÿé˜²å¾¡æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›‘ç‹±çªç ´æ”»å‡»é€šè¿‡è®¾è®¡å¯¹æŠ—æ€§æç¤ºï¼Œç»•è¿‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å¯¹é½æœºåˆ¶ï¼Œå¯¼è‡´æ¨¡å‹ç”Ÿæˆæœ‰å®³ã€å—é™æˆ–åè§çš„å†…å®¹ï¼Œä¸¥é‡å¨èƒå…¶å®‰å…¨æ€§ã€‚æœ¬æ–‡æå‡ºäº†SafeLLMï¼Œä¸€ä¸ªåŸºäºå»å­¦ä¹ çš„é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨å»é™¤LLMsä¸­çš„æœ‰å®³çŸ¥è¯†ï¼ŒåŒæ—¶ä¿æŒè¯­è¨€æµç•…æ€§å’Œä¸€èˆ¬èƒ½åŠ›ã€‚SafeLLMé‡‡ç”¨ä¸‰é˜¶æ®µæµç¨‹ï¼šåŠ¨æ€ä¸å®‰å…¨è¾“å‡ºæ£€æµ‹ã€åŸºäºå‰é¦ˆç½‘ç»œæ¿€æ´»çš„æœ‰å®³å†…å®¹è¿½è¸ªï¼Œä»¥åŠçº¦æŸä¼˜åŒ–ä»¥æŠ‘åˆ¶ä¸å®‰å…¨è¡Œä¸ºè€Œä¸é™ä½æ¨¡å‹æ•´ä½“è´¨é‡ã€‚é€šè¿‡è¯†åˆ«å’Œä¸­å’Œè´Ÿè´£æœ‰å®³ç”Ÿæˆè·¯å¾„çš„å‰é¦ˆç½‘ç»œå­ç»“æ„ï¼ŒSafeLLMå®ç°äº†æœ‰é’ˆå¯¹æ€§çš„ä¸å¯é€†é—å¿˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSafeLLMæ˜¾è‘—é™ä½äº†æ”»å‡»æˆåŠŸç‡ï¼ŒåŒæ—¶ä¿æŒé«˜é€šç”¨æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„é—®é¢˜æ˜¯å¦‚ä½•æœ‰æ•ˆå»é™¤å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æœ‰å®³çŸ¥è¯†ï¼Œä»¥é˜²æ­¢ç›‘ç‹±çªç ´æ”»å‡»ã€‚ç°æœ‰æ–¹æ³•å¦‚ç›‘ç£å¾®è°ƒå’Œç›´æ¥åå¥½ä¼˜åŒ–åœ¨å®‰å…¨æ€§å’Œæ§åˆ¶ç²¾åº¦ä¸Šå­˜åœ¨ä¸è¶³ï¼Œæ— æ³•æ»¡è¶³å®é™…éœ€æ±‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSafeLLMçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å»å­¦ä¹ æœºåˆ¶ï¼ŒåŠ¨æ€æ£€æµ‹å’ŒæŠ‘åˆ¶æœ‰å®³è¾“å‡ºï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹çš„è¯­è¨€æµç•…æ€§å’Œä¸€èˆ¬èƒ½åŠ›ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å®ç°å¯¹æœ‰å®³çŸ¥è¯†çš„ç²¾å‡†æ§åˆ¶å’Œä¸å¯é€†é—å¿˜ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSafeLLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼šç¬¬ä¸€é˜¶æ®µæ˜¯åŠ¨æ€ä¸å®‰å…¨è¾“å‡ºæ£€æµ‹ï¼Œç»“åˆå¤–éƒ¨åˆ†ç±»å™¨ä¸æ¨¡å‹å†…éƒ¨è¯„ä¼°ï¼›ç¬¬äºŒé˜¶æ®µæ˜¯é€šè¿‡å‰é¦ˆç½‘ç»œæ¿€æ´»è¿½è¸ªæœ‰å®³å†…å®¹ï¼›ç¬¬ä¸‰é˜¶æ®µæ˜¯çº¦æŸä¼˜åŒ–ï¼ŒæŠ‘åˆ¶ä¸å®‰å…¨è¡Œä¸ºã€‚

**å…³é”®åˆ›æ–°**ï¼šSafeLLMçš„å…³é”®åˆ›æ–°åœ¨äºå®ç°äº†é’ˆå¯¹æ€§å’Œä¸å¯é€†çš„é—å¿˜ï¼Œé€šè¿‡è¯†åˆ«å’Œä¸­å’Œå‰é¦ˆç½‘ç»œä¸­è´Ÿè´£æœ‰å®³ç”Ÿæˆçš„å­ç»“æ„ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å®‰å…¨æ€§å’Œæ§åˆ¶èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSafeLLMé‡‡ç”¨äº†æ··åˆæ£€æµ‹æ–¹æ³•ï¼Œç»“åˆäº†å¤šç§æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ç¡®ä¿åœ¨å»é™¤æœ‰å®³çŸ¥è¯†çš„åŒæ—¶ï¼Œä¿æŒæ¨¡å‹çš„æ•´ä½“æ€§èƒ½å’Œæµç•…æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSafeLLMåœ¨å¤šä¸ªç›‘ç‹±çªç ´åŸºå‡†ä¸Šæ˜¾è‘—é™ä½äº†æ”»å‡»æˆåŠŸç‡ï¼Œå…·ä½“è¡¨ç°ä¸ºç›¸æ¯”äºæ ‡å‡†é˜²å¾¡æ–¹æ³•ï¼Œæ”»å‡»æˆåŠŸç‡é™ä½äº†XX%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼ŒåŒæ—¶ä¿æŒäº†é«˜é€šç”¨æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶åœ¨å®‰å…¨æ€§å’Œæ€§èƒ½ä¸Šçš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SafeLLMçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶åœ¨éœ€è¦ç¡®ä¿å†…å®¹å®‰å…¨çš„é¢†åŸŸï¼Œå¦‚ç¤¾äº¤åª’ä½“ã€åœ¨çº¿å®¢æœå’Œæ•™è‚²ç­‰ã€‚é€šè¿‡æœ‰æ•ˆå»é™¤æœ‰å®³çŸ¥è¯†ï¼ŒSafeLLMèƒ½å¤Ÿæå‡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œä¿ƒè¿›å…¶åœ¨æ•æ„Ÿåœºæ™¯ä¸­çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå¼•é¢†æ›´å¤šå»å­¦ä¹ æŠ€æœ¯åœ¨AIå®‰å…¨é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Jailbreak attacks pose a serious threat to the safety of Large Language Models (LLMs) by crafting adversarial prompts that bypass alignment mechanisms, causing the models to produce harmful, restricted, or biased content. In this paper, we propose SafeLLM, a novel unlearning-based defense framework that unlearn the harmful knowledge from LLMs while preserving linguistic fluency and general capabilities. SafeLLM employs a three-stage pipeline: (1) dynamic unsafe output detection using a hybrid approach that integrates external classifiers with model-internal evaluations; (2) token-level harmful content tracing through feedforward network (FFN) activations to localize harmful knowledge; and (3) constrained optimization to suppress unsafe behavior without degrading overall model quality. SafeLLM achieves targeted and irreversible forgetting by identifying and neutralizing FFN substructures responsible for harmful generation pathways. Extensive experiments on prominent LLMs (Vicuna, LLaMA, and GPT-J) across multiple jailbreak benchmarks show that SafeLLM substantially reduces attack success rates while maintaining high general-purpose performance. Compared to standard defense methods such as supervised fine-tuning and direct preference optimization, SafeLLM offers stronger safety guarantees, more precise control over harmful behavior, and greater robustness to unseen attacks. Moreover, SafeLLM maintains the general performance after the harmful knowledge unlearned. These results highlight unlearning as a promising direction for scalable and effective LLM safety.

