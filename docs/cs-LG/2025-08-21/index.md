---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-08-21
---

# cs.LGï¼ˆ2025-08-21ï¼‰

ğŸ“Š å…± **2** ç¯‡è®ºæ–‡


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250815182v1-safellm-unlearning-harmful-outputs-from-large-language-models-agains.html">SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks</a></td>
  <td>æå‡ºSafeLLMä»¥è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹çš„ç›‘ç‹±çªç ´æ”»å‡»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">direct preference optimization</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.15182v1" data-paper-url="./papers/250815182v1-safellm-unlearning-harmful-outputs-from-large-language-models-agains.html" onclick="toggleFavorite(this, '2508.15182v1', 'SafeLLM: Unlearning Harmful Outputs from Large Language Models against Jailbreak Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>2</td>
  <td><a href="./papers/250900031v2-end-to-end-on-device-quantization-aware-training-for-llms-at-inferen.html">End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost</a></td>
  <td>æå‡ºZeroQATä»¥è§£å†³LLMsé‡åŒ–è®­ç»ƒä¸­çš„é«˜å†…å­˜æ¶ˆè€—é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.00031v2" data-paper-url="./papers/250900031v2-end-to-end-on-device-quantization-aware-training-for-llms-at-inferen.html" onclick="toggleFavorite(this, '2509.00031v2', 'End-to-End On-Device Quantization-Aware Training for LLMs at Inference Cost')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)