---
layout: default
title: An efficient deep reinforcement learning environment for flexible job-shop scheduling
---

# An efficient deep reinforcement learning environment for flexible job-shop scheduling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.07019" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.07019v1</a>
  <a href="https://arxiv.org/pdf/2509.07019.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.07019v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.07019v1', 'An efficient deep reinforcement learning environment for flexible job-shop scheduling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinquan Wu, Xuefeng Yan, Mingqiang Wei, Donghai Guan

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-07

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦ï¼Œæå‡ºä¸€ç§é«˜æ•ˆçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç¯å¢ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `ç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿ` `è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–` `è°ƒåº¦ç¯å¢ƒ` `çŠ¶æ€è¡¨ç¤º` `å¥–åŠ±å‡½æ•°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰DRLè§£å†³FJSPé—®é¢˜çš„æ–¹æ³•ä¾§é‡äºAgentè®¾è®¡ï¼Œå¿½ç•¥äº†DRLç¯å¢ƒçš„å»ºæ¨¡ï¼Œé™åˆ¶äº†è°ƒåº¦æ€§èƒ½ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§åŸºäºç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿçš„ç®€å•æ—¶é—´é¡ºåºDRLç¯å¢ƒï¼Œå¹¶è®¾è®¡äº†æ–°é¢–çš„çŠ¶æ€è¡¨ç¤ºå’Œå¥–åŠ±å‡½æ•°ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥ç¯å¢ƒèƒ½æœ‰æ•ˆæå‡ç®€å•è°ƒåº¦è§„åˆ™çš„æ€§èƒ½ï¼Œä¸”DRLæ¨¡å‹æ€§èƒ½ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜(FJSP)æ˜¯ä¸€ä¸ªç»å…¸çš„ç»„åˆä¼˜åŒ–é—®é¢˜ï¼Œåœ¨ç°å®ä¸–ç•Œä¸­æœ‰ç€å¹¿æ³›çš„åº”ç”¨ã€‚ä¸ºäº†ä¸ºFJSPç”Ÿæˆå¿«é€Ÿè€Œç²¾ç¡®çš„è°ƒåº¦æ–¹æ¡ˆï¼Œå·²ç»å¼€å‘äº†å„ç§æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)è°ƒåº¦æ–¹æ³•ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨DRLè°ƒåº¦Agentçš„è®¾è®¡ä¸Šï¼Œè€Œå¿½ç•¥äº†DRLç¯å¢ƒçš„å»ºæ¨¡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿçš„ç®€å•æ—¶é—´é¡ºåºDRLç¯å¢ƒç”¨äºFJSPï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)çš„ç«¯åˆ°ç«¯DRLè°ƒåº¦æ¨¡å‹ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡åŸºäºè°ƒåº¦ç¯å¢ƒä¸­çš„ä¸¤ä¸ªçŠ¶æ€å˜é‡ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„FJSPçŸ­çŠ¶æ€è¡¨ç¤ºï¼Œå¹¶åŸºäºæœºå™¨çš„è°ƒåº¦åŒºåŸŸè®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ã€æ˜“äºç†è§£çš„å¥–åŠ±å‡½æ•°ã€‚åœ¨å…¬å…±åŸºå‡†å®ä¾‹ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æˆ‘ä»¬çš„è°ƒåº¦ç¯å¢ƒä¸­ï¼Œç®€å•ä¼˜å…ˆçº§è°ƒåº¦è§„åˆ™(PDR)çš„æ€§èƒ½å¾—åˆ°äº†æé«˜ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„DRLè°ƒåº¦æ¨¡å‹ä¸OR-Toolsã€å…ƒå¯å‘å¼ç®—æ³•ã€DRLå’ŒPDRè°ƒåº¦æ–¹æ³•ç›¸æ¯”ï¼Œè·å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æŸ”æ€§ä½œä¸šè½¦é—´è°ƒåº¦é—®é¢˜(FJSP)ï¼Œè¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ç»„åˆä¼˜åŒ–é—®é¢˜ã€‚ç°æœ‰çš„DRLæ–¹æ³•ä¸»è¦å…³æ³¨äºè®¾è®¡å¤æ‚çš„DRL Agentï¼Œè€Œå¿½ç•¥äº†DRLç¯å¢ƒçš„å»ºæ¨¡ï¼Œè¿™é™åˆ¶äº†è°ƒåº¦ç®—æ³•çš„æ•ˆç‡å’Œæ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•åœ¨çŠ¶æ€è¡¨ç¤ºå’Œå¥–åŠ±å‡½æ•°è®¾è®¡æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªé«˜æ•ˆçš„DRLç¯å¢ƒï¼Œè¯¥ç¯å¢ƒèƒ½å¤Ÿç®€åŒ–çŠ¶æ€è¡¨ç¤ºï¼Œå¹¶æä¾›æ˜“äºç†è§£çš„å¥–åŠ±ä¿¡å·ï¼Œä»è€ŒåŠ é€ŸDRL Agentçš„å­¦ä¹ è¿‡ç¨‹ã€‚é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ç¯å¢ƒï¼Œå¯ä»¥æ›´å®¹æ˜“åœ°è®­ç»ƒå‡ºé«˜æ€§èƒ½çš„è°ƒåº¦ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªåŸºäºç¦»æ•£äº‹ä»¶æ¨¡æ‹Ÿçš„DRLç¯å¢ƒå’Œä¸€ä¸ªåŸºäºè¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)çš„DRL Agentã€‚ç¯å¢ƒè´Ÿè´£æ¨¡æ‹ŸFJSPçš„è°ƒåº¦è¿‡ç¨‹ï¼Œå¹¶å‘Agentæä¾›çŠ¶æ€ä¿¡æ¯å’Œå¥–åŠ±ä¿¡å·ã€‚Agentæ ¹æ®çŠ¶æ€ä¿¡æ¯é€‰æ‹©åŠ¨ä½œï¼Œå¹¶æ ¹æ®å¥–åŠ±ä¿¡å·æ›´æ–°ç­–ç•¥ã€‚æ•´ä¸ªè¿‡ç¨‹æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„å­¦ä¹ è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ä¸ªç®€å•çš„æ—¶é—´é¡ºåºDRLç¯å¢ƒï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„FJSPçŸ­çŠ¶æ€è¡¨ç¤ºå’Œæ˜“äºç†è§£çš„å¥–åŠ±å‡½æ•°ã€‚è¿™ç§ç¯å¢ƒèƒ½å¤Ÿæœ‰æ•ˆåœ°ç®€åŒ–è°ƒåº¦é—®é¢˜çš„å¤æ‚æ€§ï¼Œå¹¶åŠ é€ŸDRL Agentçš„å­¦ä¹ è¿‡ç¨‹ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç¯å¢ƒæ›´åŠ é«˜æ•ˆå’Œæ˜“äºä½¿ç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šçŠ¶æ€è¡¨ç¤ºåŸºäºè°ƒåº¦ç¯å¢ƒä¸­çš„ä¸¤ä¸ªçŠ¶æ€å˜é‡ï¼Œå…·ä½“ç»†èŠ‚æœªçŸ¥ã€‚å¥–åŠ±å‡½æ•°åŸºäºæœºå™¨çš„è°ƒåº¦åŒºåŸŸè®¾è®¡ï¼Œæ—¨åœ¨æä¾›æ›´ç›´æ¥å’Œå¯è§£é‡Šçš„å¥–åŠ±ä¿¡å·ã€‚DRL Agenté‡‡ç”¨PPOç®—æ³•è¿›è¡Œè®­ç»ƒï¼ŒPPOæ˜¯ä¸€ç§å¸¸ç”¨çš„ç­–ç•¥æ¢¯åº¦ç®—æ³•ï¼Œå…·æœ‰è¾ƒå¥½çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æå‡ºçš„è°ƒåº¦ç¯å¢ƒä¸­ï¼Œç®€å•ä¼˜å…ˆçº§è°ƒåº¦è§„åˆ™(PDR)çš„æ€§èƒ½å¾—åˆ°äº†æé«˜ï¼Œè¿™éªŒè¯äº†ç¯å¢ƒçš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒDRLè°ƒåº¦æ¨¡å‹ä¸OR-Toolsã€å…ƒå¯å‘å¼ç®—æ³•ã€DRLå’ŒPDRè°ƒåº¦æ–¹æ³•ç›¸æ¯”ï¼Œè·å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰å®é™…åº”ç”¨æ½œåŠ›ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæ™ºèƒ½åˆ¶é€ ã€ç”Ÿäº§è°ƒåº¦ã€ç‰©æµç®¡ç†ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿæé«˜ç”Ÿäº§æ•ˆç‡ã€é™ä½ç”Ÿäº§æˆæœ¬ã€ä¼˜åŒ–èµ„æºé…ç½®ã€‚é€šè¿‡DRLè‡ªåŠ¨å­¦ä¹ è°ƒåº¦ç­–ç•¥ï¼Œå¯ä»¥å‡å°‘äººå·¥å¹²é¢„ï¼Œæé«˜è°ƒåº¦çš„çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚æœªæ¥å¯è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„è°ƒåº¦åœºæ™¯ï¼Œå¦‚è€ƒè™‘è®¾å¤‡æ•…éšœã€ç‰©æ–™ä¾›åº”ç­‰å› ç´ ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial optimization problem that has a wide-range of applications in the real world. In order to generate fast and accurate scheduling solutions for FJSP, various deep reinforcement learning (DRL) scheduling methods have been developed. However, these methods are mainly focused on the design of DRL scheduling Agent, overlooking the modeling of DRL environment. This paper presents a simple chronological DRL environment for FJSP based on discrete event simulation and an end-to-end DRL scheduling model is proposed based on the proximal policy optimization (PPO). Furthermore, a short novel state representation of FJSP is proposed based on two state variables in the scheduling environment and a novel comprehensible reward function is designed based on the scheduling area of machines. Experimental results on public benchmark instances show that the performance of simple priority dispatching rules (PDR) is improved in our scheduling environment and our DRL scheduling model obtains competing performance compared with OR-Tools, meta-heuristic, DRL and PDR scheduling methods.

