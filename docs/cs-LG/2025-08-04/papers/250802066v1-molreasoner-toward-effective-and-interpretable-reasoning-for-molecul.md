---
layout: default
title: MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs
---

# MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.02066" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.02066v1</a>
  <a href="https://arxiv.org/pdf/2508.02066.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.02066v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.02066v1', 'MolReasoner: Toward Effective and Interpretable Reasoning for Molecular LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Guojiang Zhao, Sihang Li, Zixiang Lu, Zheng Cheng, Haitao Lin, Lirong Wu, Hanchen Xia, Hengxing Cai, Wentao Guo, Hongshuai Wang, Mingjun Xu, Siyu Zhu, Guolin Ke, Linfeng Zhang, Zhifeng Gao

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMolReasonerä»¥è§£å†³åˆ†å­æ¨ç†ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åˆ†å­æ¨ç†` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `åŒ–å­¦è¯­ä¹‰` `å¯è§£é‡Šæ€§` `åˆæˆæ€ç»´é“¾` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨åˆ†å­æ¨ç†æ–¹é¢ä¾èµ–é€šç”¨æç¤ºï¼Œç¼ºä¹é¢†åŸŸç‰¹å®šçš„åˆ†å­è¯­ä¹‰ï¼Œå¯¼è‡´æ¨ç†èƒ½åŠ›ä¸è¶³ã€‚
2. MolReasoneré€šè¿‡Mol-SFTå’ŒMol-RLä¸¤ä¸ªé˜¶æ®µï¼Œåˆ©ç”¨åˆæˆæ€ç»´é“¾æ ·æœ¬å’Œå¼ºåŒ–å­¦ä¹ æ¥æå‡æ¨¡å‹çš„åŒ–å­¦æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMolReasoneråœ¨åˆ†å­æ¨ç†ä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œæ˜¾è‘—æé«˜äº†å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šä¸ªé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åˆ†å­æ¨ç†æ–¹é¢çš„èƒ½åŠ›ä»ç„¶ä¸è¶³ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºé€šç”¨æç¤ºï¼Œç¼ºä¹é¢†åŸŸç‰¹å®šçš„åˆ†å­è¯­ä¹‰ï¼Œè€Œä½¿ç”¨å¾®è°ƒç­–ç•¥çš„æ–¹æ³•åˆ™é¢ä¸´å¯è§£é‡Šæ€§å’Œæ¨ç†æ·±åº¦çš„æŒ‘æˆ˜ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MolReasonerï¼Œä¸€ä¸ªæ—¨åœ¨å°†LLMsä»è®°å¿†è½¬å‘åŒ–å­¦æ¨ç†çš„ä¸¤é˜¶æ®µæ¡†æ¶ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬æå‡ºMol-SFTï¼Œé€šè¿‡GPT-4oç”Ÿæˆçš„åˆæˆæ€ç»´é“¾ï¼ˆCoTï¼‰æ ·æœ¬åˆå§‹åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œå¹¶éªŒè¯å…¶åŒ–å­¦å‡†ç¡®æ€§ã€‚éšåï¼ŒMol-RLåº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼Œä½¿ç”¨ä¸“é—¨è®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œå°†åŒ–å­¦ç»“æ„ä¸è¯­è¨€æè¿°å¯¹é½ï¼Œä»è€Œå¢å¼ºåˆ†å­æ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ï¼Œæ”¹å–„äº†åˆ†å­ç†è§£èƒ½åŠ›ï¼Œå¹¶å®ç°äº†æ›´å¥½çš„æ³›åŒ–ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMolReasoneråœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œæ ‡å¿—ç€ä»åŸºäºè®°å¿†çš„è¾“å‡ºå‘ç¨³å¥çš„åŒ–å­¦æ¨ç†çš„é‡å¤§è½¬å˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨åˆ†å­æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–é€šç”¨æç¤ºï¼Œç¼ºä¹é’ˆå¯¹åŒ–å­¦é¢†åŸŸçš„æ·±åº¦æ¨ç†èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMolReasoneré€šè¿‡ä¸¤ä¸ªé˜¶æ®µçš„æ¡†æ¶ï¼Œé¦–å…ˆåˆ©ç”¨åˆæˆæ€ç»´é“¾æ ·æœ¬åˆå§‹åŒ–æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œç„¶åé€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹çš„åŒ–å­¦æ¨ç†èƒ½åŠ›ï¼Œä»¥å®ç°æ›´å¥½çš„ç†è§£å’Œæ³›åŒ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åˆ†ä¸ºä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šMol-SFTå’ŒMol-RLã€‚Mol-SFTè´Ÿè´£ç”Ÿæˆå’ŒéªŒè¯åˆæˆæ€ç»´é“¾æ ·æœ¬ï¼Œè€ŒMol-RLåˆ™é€šè¿‡å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMolReasonerçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†åˆæˆæ€ç»´é“¾æ ·æœ¬ä¸å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ¨ç†æ·±åº¦ï¼Œè¿™æ˜¯ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Mol-SFTä¸­ï¼Œä½¿ç”¨GPT-4oç”Ÿæˆçš„æ ·æœ¬ç»è¿‡åŒ–å­¦å‡†ç¡®æ€§éªŒè¯ï¼›åœ¨Mol-RLä¸­ï¼Œè®¾è®¡äº†ä¸“é—¨çš„å¥–åŠ±å‡½æ•°ï¼Œä»¥ç¡®ä¿åŒ–å­¦ç»“æ„ä¸è¯­è¨€æè¿°çš„å¯¹é½ï¼Œå¢å¼ºæ¨ç†æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMolReasoneråœ¨åˆ†å­æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œæ ‡å¿—ç€ä»ä¼ ç»Ÿçš„è®°å¿†è¾“å‡ºå‘æ›´ä¸ºå¤æ‚çš„åŒ–å­¦æ¨ç†çš„è½¬å˜ï¼Œæå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯ç‰©å‘ç°ã€ææ–™ç§‘å­¦å’Œç”Ÿç‰©åŒ–å­¦ç­‰ã€‚é€šè¿‡æå‡åˆ†å­æ¨ç†èƒ½åŠ›ï¼ŒMolReasonerèƒ½å¤Ÿå¸®åŠ©ç§‘å­¦å®¶æ›´å¥½åœ°ç†è§£åˆ†å­ç»“æ„ä¸åŠŸèƒ½ä¹‹é—´çš„å…³ç³»ï¼Œä»è€ŒåŠ é€Ÿæ–°ææ–™å’Œè¯ç‰©çš„å¼€å‘ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models(LLMs) have demonstrated remarkable performance across various domains, yet their capabilities in molecular reasoning remain insufficiently explored. Current approaches tend to rely heavily on general-purpose prompting, which lacks domain-specific molecular semantics, while those that use fine-tuning strategies often face challenges with interpretability and reasoning depth. To address these issues, we introduce MolReasoner, a two-stage framework designed to transition LLMs from memorization towards chemical reasoning. First, we propose Mol-SFT, which initializes the model's reasoning abilities via synthetic Chain-of-Thought(CoT) samples generated by GPT-4o and verified for chemical accuracy. Subsequently, Mol-RL applies reinforcement learning with specialized reward functions designed explicitly to align chemical structures with linguistic descriptions, thereby enhancing molecular reasoning capabilities. Our approach notably enhances interpretability, improving the model 's molecular understanding and enabling better generalization. Extensive experiments demonstrate that MolReasoner outperforms existing methods, and marking a significant shift from memorization-based outputs to robust chemical reasoning.

