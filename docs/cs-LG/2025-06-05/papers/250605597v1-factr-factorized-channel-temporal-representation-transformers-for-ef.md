---
layout: default
title: FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting
---

# FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05597" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05597v1</a>
  <a href="https://arxiv.org/pdf/2506.05597.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05597v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05597v1', 'FaCTR: Factorized Channel-Temporal Representation Transformers for Efficient Time Series Forecasting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yash Vijay, Harini Subramanyan

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFaCTRä»¥è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„è¿‡åº¦å‚æ•°åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `Transformer` `ä½ç§©å› å­åˆ†è§£` `è·¨é€šé“äº¤äº’` `è‡ªç›‘ç£å­¦ä¹ ` `æ¨¡å‹è§£é‡Šæ€§` `é«˜æ•ˆé¢„æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰Transformeråœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­é¢ä¸´è¿‡åº¦å‚æ•°åŒ–å’Œå¤æ‚ä¾èµ–ç»“æ„çš„æŒ‘æˆ˜ï¼Œå¯¼è‡´æ€§èƒ½æå‡æœ‰é™ã€‚
2. FaCTRé€šè¿‡å¼•å…¥ä½ç§©å› å­åˆ†è§£æœºå»ºæ¨¡åŠ¨æ€è·¨é€šé“äº¤äº’ï¼Œç»“åˆå¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶ï¼Œä¼˜åŒ–æ—¶é—´åºåˆ—æ•°æ®çš„å¤„ç†ã€‚
3. FaCTRåœ¨11ä¸ªå…¬å…±åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå‚æ•°é‡æ˜¾è‘—å‡å°‘ï¼Œä¸”æ”¯æŒè‡ªç›‘ç£é¢„è®­ç»ƒï¼Œæå‡äº†æ¨¡å‹çš„é€‚ç”¨æ€§å’Œè§£é‡Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡Transformeråœ¨è¯­è¨€å’Œè§†è§‰ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œä½†å…¶æ¶æ„å¤æ‚æ€§å¯¼è‡´åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­æ”¶ç›Šé€’å‡ã€‚æ—¶é—´åºåˆ—æ•°æ®çš„ä¿¡æ¯å¯†åº¦è¾ƒä½ä¸”é€šé“é—´ä¾èµ–å…³ç³»å¤æ‚ï¼Œéœ€å¯¹ç»“æ„åŒ–å˜é‡äº¤äº’è¿›è¡Œæ¡ä»¶å¤„ç†ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºFaCTRï¼Œä¸€ç§è½»é‡çº§çš„æ—¶ç©ºTransformerï¼Œé‡‡ç”¨æ˜¾å¼ç»“æ„è®¾è®¡ã€‚FaCTRé€šè¿‡å¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶ï¼Œå°†åŠ¨æ€çš„å¯¹ç§°è·¨é€šé“äº¤äº’æ³¨å…¥åˆ°æ—¶é—´ä¸Šä¸‹æ–‡çš„è¡¥ä¸åµŒå…¥ä¸­ï¼Œå¹¶è¿›ä¸€æ­¥ç¼–ç é™æ€å’ŒåŠ¨æ€åå˜é‡ä»¥å®ç°å¤šå˜é‡æ¡ä»¶åŒ–ã€‚å°½ç®¡è®¾è®¡ç´§å‡‘ï¼ŒFaCTRåœ¨11ä¸ªå…¬å…±é¢„æµ‹åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…¶æœ€å¤§å˜ä½“å‚æ•°ä»…çº¦ä¸º40ä¸‡ï¼Œå¹³å‡æ¯”ç«äº‰æ€§æ—¶ç©ºTransformeråŸºçº¿å°50å€ã€‚æ­¤å¤–ï¼Œå…¶ç»“æ„åŒ–è®¾è®¡é€šè¿‡è·¨é€šé“å½±å“è¯„åˆ†å¢å¼ºäº†è§£é‡Šæ€§ï¼Œæ»¡è¶³å®é™…å†³ç­–éœ€æ±‚ã€‚æœ€åï¼ŒFaCTRæ”¯æŒè‡ªç›‘ç£é¢„è®­ç»ƒï¼Œä¸ºä¸‹æ¸¸æ—¶é—´åºåˆ—ä»»åŠ¡æä¾›äº†ç´§å‡‘è€Œå¤šåŠŸèƒ½çš„åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­Transformeræ¨¡å‹çš„è¿‡åº¦å‚æ•°åŒ–å’Œå¤æ‚ä¾èµ–ç»“æ„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä½ä¿¡æ¯å¯†åº¦å’Œå¤æ‚é€šé“é—´ä¾èµ–æ—¶æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´æ€§èƒ½æå‡æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFaCTRçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ˜¾å¼çš„ç»“æ„è®¾è®¡å’Œä½ç§©å› å­åˆ†è§£æœºæ¥å»ºæ¨¡åŠ¨æ€çš„è·¨é€šé“äº¤äº’ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ•ˆç‡å’Œæ•ˆæœã€‚é€šè¿‡å¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶ï¼ŒFaCTRèƒ½å¤Ÿæœ‰æ•ˆåœ°å°†è¿™äº›äº¤äº’èå…¥åˆ°æ—¶é—´ä¸Šä¸‹æ–‡çš„è¡¥ä¸åµŒå…¥ä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFaCTRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆæ˜¯æ—¶é—´ä¸Šä¸‹æ–‡çš„è¡¥ä¸åµŒå…¥ï¼Œå…¶æ¬¡æ˜¯é€šè¿‡ä½ç§©å› å­åˆ†è§£æœºå®ç°çš„è·¨é€šé“äº¤äº’ï¼Œæœ€åæ˜¯é™æ€å’ŒåŠ¨æ€åå˜é‡çš„ç¼–ç ã€‚è¿™äº›æ¨¡å—ååŒå·¥ä½œï¼Œä»¥å®ç°é«˜æ•ˆçš„æ—¶é—´åºåˆ—é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šFaCTRçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è½»é‡çº§è®¾è®¡å’Œç»“æ„åŒ–å»ºæ¨¡æ–¹å¼ï¼Œä½¿å…¶åœ¨å‚æ•°é‡ä¸Šæ˜¾è‘—ä½äºä¼ ç»Ÿæ—¶ç©ºTransformerï¼ŒåŒæ—¶ä¿æŒäº†ä¼˜è¶Šçš„é¢„æµ‹æ€§èƒ½ã€‚è¿™ç§è®¾è®¡ä½¿å¾—æ¨¡å‹ä¸ä»…é«˜æ•ˆï¼Œè€Œä¸”æ˜“äºè§£é‡Šã€‚

**å…³é”®è®¾è®¡**ï¼šFaCTRçš„å…³é”®è®¾è®¡åŒ…æ‹¬å¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶ã€ä½ç§©å› å­åˆ†è§£æœºçš„å®ç°ï¼Œä»¥åŠå¯¹é™æ€å’ŒåŠ¨æ€åå˜é‡çš„æœ‰æ•ˆç¼–ç ã€‚è¿™äº›è®¾è®¡ç¡®ä¿äº†æ¨¡å‹åœ¨å¤„ç†å¤æ‚ä¾èµ–å…³ç³»æ—¶çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

FaCTRåœ¨11ä¸ªå…¬å…±é¢„æµ‹åŸºå‡†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…¶æœ€å¤§å˜ä½“ä»…ä½¿ç”¨çº¦40ä¸‡å‚æ•°ï¼Œå¹³å‡æ¯”ç«äº‰æ€§æ—¶ç©ºTransformeråŸºçº¿å°50å€ã€‚æ­¤å¤–ï¼ŒFaCTRçš„ç»“æ„åŒ–è®¾è®¡æä¾›äº†è·¨é€šé“å½±å“è¯„åˆ†ï¼Œå¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FaCTRåœ¨æ—¶é—´åºåˆ—é¢„æµ‹é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºé‡‘èå¸‚åœºé¢„æµ‹ã€æ°”è±¡æ•°æ®åˆ†æå’Œå·¥ä¸šè®¾å¤‡ç›‘æ§ç­‰åœºæ™¯ã€‚å…¶é«˜æ•ˆçš„æ¨¡å‹ç»“æ„å’Œè‰¯å¥½çš„è§£é‡Šæ€§ä½¿å…¶åœ¨å®é™…å†³ç­–ä¸­å…·æœ‰é‡è¦ä»·å€¼ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´å¤šé¢†åŸŸçš„æ™ºèƒ½é¢„æµ‹æŠ€æœ¯å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> While Transformers excel in language and vision-where inputs are semantically rich and exhibit univariate dependency structures-their architectural complexity leads to diminishing returns in time series forecasting. Time series data is characterized by low per-timestep information density and complex dependencies across channels and covariates, requiring conditioning on structured variable interactions. To address this mismatch and overparameterization, we propose FaCTR, a lightweight spatiotemporal Transformer with an explicitly structural design. FaCTR injects dynamic, symmetric cross-channel interactions-modeled via a low-rank Factorization Machine into temporally contextualized patch embeddings through a learnable gating mechanism. It further encodes static and dynamic covariates for multivariate conditioning. Despite its compact design, FaCTR achieves state-of-the-art performance on eleven public forecasting benchmarks spanning both short-term and long-term horizons, with its largest variant using close to only 400K parameters-on average 50x smaller than competitive spatiotemporal transformer baselines. In addition, its structured design enables interpretability through cross-channel influence scores-an essential requirement for real-world decision-making. Finally, FaCTR supports self-supervised pretraining, positioning it as a compact yet versatile foundation for downstream time series tasks.

