---
layout: default
title: A Smooth Sea Never Made a Skilled SAILOR: Robust Imitation via Learning to Search
---

# A Smooth Sea Never Made a Skilled SAILOR: Robust Imitation via Learning to Search

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05294" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05294v2</a>
  <a href="https://arxiv.org/pdf/2506.05294.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05294v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05294v2', 'A Smooth Sea Never Made a Skilled SAILOR: Robust Imitation via Learning to Search')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Arnav Kumar Jain, Vibhakar Mohta, Subin Kim, Atiksh Bhardwaj, Juntao Ren, Yunhai Feng, Sanjiban Choudhury, Gokul Swamy

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-10-24)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/arnavkj1995/SAILOR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAILORä»¥è§£å†³è¡Œä¸ºå…‹éš†æ–¹æ³•çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡ä»¿å­¦ä¹ ` `è¡Œä¸ºå…‹éš†` `å­¦ä¹ æœç´¢` `ä¸–ç•Œæ¨¡å‹` `å¥–åŠ±æ¨¡å‹` `æœºå™¨äººæ“ä½œ` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è¡Œä¸ºå…‹éš†æ–¹æ³•ä»…é™äºä¸“å®¶æ¼”ç¤ºçš„çŠ¶æ€ï¼Œå¯¼è‡´ä»£ç†åœ¨é‡åˆ°æœªè§æƒ…å†µæ—¶æ— æ³•æ¢å¤ã€‚
2. æœ¬æ–‡æå‡ºäº†å­¦ä¹ æœç´¢ï¼ˆL2Sï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºä¸–ç•Œæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹ï¼Œä½¿ä»£ç†èƒ½å¤Ÿåœ¨æµ‹è¯•æ—¶è§„åˆ’ä»¥åŒ¹é…ä¸“å®¶ç»“æœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAILORåœ¨å¤šä¸ªåŸºå‡†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†åŸºäºBCçš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œä¸”åœ¨æ¼”ç¤ºæ•°é‡å¢åŠ æ—¶ä»ä¿æŒæ€§èƒ½ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰æ–¹æ³•åœ¨æ¨¡ä»¿å­¦ä¹ ä¸­çš„æ ¹æœ¬å±€é™åœ¨äºï¼Œå®ƒä»…æ•™ä¼šä»£ç†åœ¨ä¸“å®¶è®¿é—®çš„çŠ¶æ€ä¸‹æ‰€åšçš„äº‹æƒ…ã€‚è¿™æ„å‘³ç€å½“BCä»£ç†çŠ¯é”™å¹¶è„±ç¦»æ¼”ç¤ºçš„æ”¯æŒæ—¶ï¼Œå®ƒä»¬å¾€å¾€ä¸çŸ¥é“å¦‚ä½•æ¢å¤ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æ¢ç´¢äº†ä»ä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ æœç´¢ï¼ˆL2Sï¼‰ï¼Œå³å­¦ä¹ åœ¨æµ‹è¯•æ—¶è§„åˆ’ä»¥åŒ¹é…ä¸“å®¶ç»“æœæ‰€éœ€çš„ç»„ä»¶ï¼ŒåŒ…æ‹¬ä¸–ç•Œæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹ã€‚é€šè¿‡å¯¹ç®—æ³•å’Œè®¾è®¡å†³ç­–çš„ç»†è‡´æ¶ˆèï¼Œæå‡ºäº†SAILORæ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é¢å¤–äººç±»ä¿®æ­£çš„æƒ…å†µä¸‹ç¨³å®šä¸”é«˜æ•ˆåœ°å­¦ä¹ æ¢å¤è¡Œä¸ºã€‚å®éªŒè¡¨æ˜ï¼ŒSAILORåœ¨å¤šä¸ªè§†è§‰æ“ä½œä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºåŸºäºBCè®­ç»ƒçš„æœ€å…ˆè¿›æ‰©æ•£ç­–ç•¥ï¼Œä¸”åœ¨å¢åŠ æ¼”ç¤ºæ•°é‡æ—¶ä»ä¿æŒæ˜¾è‘—æ€§èƒ½æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¡Œä¸ºå…‹éš†ï¼ˆBCï¼‰æ–¹æ³•åœ¨æ¨¡ä»¿å­¦ä¹ ä¸­çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯å½“ä»£ç†è„±ç¦»ä¸“å®¶æ¼”ç¤ºçš„æ”¯æŒæ—¶ï¼Œç¼ºä¹æ¢å¤èƒ½åŠ›çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡å­¦ä¹ æœç´¢ï¼ˆL2Sï¼‰æ¥å¢å¼ºä»£ç†çš„è‡ªä¸»è§„åˆ’èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æµ‹è¯•æ—¶å³ä½¿çŠ¯é”™ä¹Ÿèƒ½æ¢å¤å¹¶åŒ¹é…ä¸“å®¶çš„ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSAILORæ–¹æ³•åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šä¸–ç•Œæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹ã€‚ä¸–ç•Œæ¨¡å‹ç”¨äºç†è§£ç¯å¢ƒåŠ¨æ€ï¼Œè€Œå¥–åŠ±æ¨¡å‹åˆ™å¸®åŠ©ä»£ç†è¯„ä¼°å…¶è¡Œä¸ºçš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šSAILORçš„åˆ›æ–°åœ¨äºé€šè¿‡ç»“åˆä¸–ç•Œæ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹ï¼Œå…è®¸ä»£ç†åœ¨æœªè§çŠ¶æ€ä¸‹è¿›è¡Œæœ‰æ•ˆçš„æ¢å¤è§„åˆ’ï¼Œè¿™ä¸ä¼ ç»Ÿçš„BCæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶é€šè¿‡æ¶ˆèå®éªŒç¡®å®šäº†å„ä¸ªç»„ä»¶çš„æœ€ä½³ç»„åˆï¼Œä»¥å®ç°ç¨³å®šå’Œé«˜æ•ˆçš„å­¦ä¹ ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®åœ¨å®éªŒä¸­è¿›è¡Œäº†è¯¦ç»†çš„è°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒSAILORåœ¨å¤šä¸ªè§†è§‰æ“ä½œä»»åŠ¡ä¸­è¡¨ç°ä¼˜äºåŸºäºBCçš„æœ€å…ˆè¿›æ‰©æ•£ç­–ç•¥ï¼Œä¸”åœ¨æ¼”ç¤ºæ•°é‡å¢åŠ 5-10å€çš„æƒ…å†µä¸‹ï¼Œä»ä¿æŒæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨è¯†åˆ«ç»†å¾®å¤±è´¥å’ŒæŠµæŠ—å¥–åŠ±æ“æ§æ–¹é¢çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ“ä½œã€è‡ªåŠ¨é©¾é©¶ä»¥åŠä»»ä½•éœ€è¦æ¨¡ä»¿å­¦ä¹ çš„æ™ºèƒ½ç³»ç»Ÿã€‚é€šè¿‡æå‡ä»£ç†åœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ï¼ŒSAILORèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­æ˜¾è‘—æé«˜ç³»ç»Ÿçš„é²æ£’æ€§å’Œçµæ´»æ€§ï¼Œæœªæ¥å¯èƒ½å¯¹æ™ºèƒ½æœºå™¨äººå’Œè‡ªåŠ¨åŒ–ç³»ç»Ÿçš„å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The fundamental limitation of the behavioral cloning (BC) approach to imitation learning is that it only teaches an agent what the expert did at states the expert visited. This means that when a BC agent makes a mistake which takes them out of the support of the demonstrations, they often don't know how to recover from it. In this sense, BC is akin to giving the agent the fish -- giving them dense supervision across a narrow set of states -- rather than teaching them to fish: to be able to reason independently about achieving the expert's outcome even when faced with unseen situations at test-time. In response, we explore learning to search (L2S) from expert demonstrations, i.e. learning the components required to, at test time, plan to match expert outcomes, even after making a mistake. These include (1) a world model and (2) a reward model. We carefully ablate the set of algorithmic and design decisions required to combine these and other components for stable and sample/interaction-efficient learning of recovery behavior without additional human corrections. Across a dozen visual manipulation tasks from three benchmarks, our approach SAILOR consistently out-performs state-of-the-art Diffusion Policies trained via BC on the same data. Furthermore, scaling up the amount of demonstrations used for BC by 5-10x still leaves a performance gap. We find that SAILOR can identify nuanced failures and is robust to reward hacking. Our code is available at https://github.com/arnavkj1995/SAILOR .

