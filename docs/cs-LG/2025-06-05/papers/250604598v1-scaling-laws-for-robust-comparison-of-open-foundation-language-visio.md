---
layout: default
title: Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets
---

# Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04598" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.04598v1</a>
  <a href="https://arxiv.org/pdf/2506.04598.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04598v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04598v1', 'Scaling Laws for Robust Comparison of Open Foundation Language-Vision Models and Datasets')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Marianna Nezhurina, Tomer Porian, Giovanni Pucceti, Tommie Kerssies, Romain Beaumont, Mehdi Cherti, Jenia Jitsev

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-05

**Â§áÊ≥®**: Preprint. In Review

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/LAION-AI/scaling-laws-for-comparison)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Áº©ÊîæÊ≥ïÂàô‰ª•ÊØîËæÉËØ≠Ë®Ä-ËßÜËßâÊ®°Âûã‰∏éÊï∞ÊçÆÈõÜ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Áº©ÊîæÊ≥ïÂàô` `Ê®°ÂûãÊØîËæÉ` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `CLIP` `MaMMUT` `Ê†∑Êú¨ÊïàÁéá` `ÂºÄÊîæÊï∞ÊçÆÈõÜ` `È¢ÑËÆ≠ÁªÉÊ®°Âûã`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂú®Ê®°ÂûãÂíåÊï∞ÊçÆÈõÜÊØîËæÉÊó∂Áº∫‰πèÁ≥ªÁªüÊÄßÔºåÂÆπÊòìÂØºËá¥ËØØÂØºÊÄßÁªìËÆ∫„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ÈÄöËøáÁº©ÊîæÊ≥ïÂàôÊé®ÂØºËøõË°åÊ®°ÂûãÂíåÊï∞ÊçÆÈõÜÊØîËæÉÔºåÁ°Æ‰øùÈ¢ÑËÆ≠ÁªÉËøáÁ®ãÁöÑÈÄâÊã©Êõ¥‰∏∫ÂêàÁêÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMaMMUTÂú®Â§ö‰∏™‰ªªÂä°‰∏äË°®Áé∞‰ºò‰∫éCLIPÔºå‰∏îÂú®Ê†∑Êú¨ÊïàÁéá‰∏äÂÖ∑ÊúâÊòæËëóÊèêÂçá„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÂèØËøÅÁßªÂ≠¶‰π†Á†îÁ©∂‰∏≠ÔºåÁº©ÊîæÊ≥ïÂàôË¢´Áî®‰∫éÈ¢ÑÊµãÂü∫Á°ÄÊ®°ÂûãÂú®Êõ¥Â§ßËßÑÊ®°‰∏ãÁöÑÊÄßËÉΩ„ÄÇÊú¨ÊñáÈ¶ñÊ¨°Âü∫‰∫éÂØÜÈõÜÊµãÈáèÊé®ÂØºÂá∫ÂÆåÊï¥ÁöÑÁº©ÊîæÊ≥ïÂàôÔºåÊØîËæÉ‰∫ÜCLIPÂíåMaMMUT‰∏§ÁßçËØ≠Ë®Ä-ËßÜËßâÂ≠¶‰π†ÊñπÊ≥ïÔºåÂèëÁé∞MaMMUTÂú®ËßÑÊ®°ÂíåÊ†∑Êú¨ÊïàÁéá‰∏ä‰ºò‰∫éÊ†áÂáÜCLIP„ÄÇÈÄöËøáÂØπÂ§öÁßç‰∏ãÊ∏∏‰ªªÂä°ÂíåÂºÄÊîæÊï∞ÊçÆÈõÜÁöÑÂàÜÊûêÔºåÈ™åËØÅ‰∫ÜÁº©ÊîæÊ≥ïÂàôÁöÑÊúâÊïàÊÄßÔºåÂπ∂Êèê‰æõ‰∫Ü‰∏ÄÁßçÂú®ÊÅíÂÆöÂ≠¶‰π†Áéá‰∏ãËøõË°åÊØîËæÉÁöÑÊñπÊ≥ïÔºåÈôç‰Ωé‰∫ÜËÆ°ÁÆóÊàêÊú¨„ÄÇÊâÄÊúâÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂèäÂÖ∂‰∏≠Èó¥Ê£ÄÊü•ÁÇπÂùáÂ∑≤ÂèëÂ∏ÉÔºåÊé®Âä®‰∫ÜÂºÄÊîæÂü∫Á°ÄÊ®°ÂûãÂíåÊï∞ÊçÆÈõÜÁöÑÁ≥ªÁªüÊØîËæÉ‰∏éÊîπËøõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÊ®°ÂûãÂíåÊï∞ÊçÆÈõÜÊØîËæÉÊñπÊ≥ïÁöÑ‰∏çË∂≥ÔºåÁâπÂà´ÊòØÂ¶Ç‰ΩïÂú®‰∏çÂêåËßÑÊ®°‰∏ãËøõË°åÊúâÊïàÊØîËæÉÔºå‰ª•ÈÅøÂÖçÂü∫‰∫éÂçï‰∏ÄÂèÇËÄÉÂ∞∫Â∫¶ÁöÑËØØÂØºÊÄßÁªìËÆ∫„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÊé®ÂØºÁº©ÊîæÊ≥ïÂàôÔºåÊèê‰æõ‰∫Ü‰∏ÄÁßçÁ≥ªÁªüÂåñÁöÑÊØîËæÉÊ°ÜÊû∂Ôºå‰ΩøÂæóÂú®‰∏çÂêåËßÑÊ®°‰∏ãÁöÑÊ®°ÂûãÂíåÊï∞ÊçÆÈõÜÊÄßËÉΩËÉΩÂ§üË¢´ÂáÜÁ°ÆËØÑ‰º∞Ôºå‰ªéËÄåÊåáÂØºÈ¢ÑËÆ≠ÁªÉËøáÁ®ãÁöÑÈÄâÊã©„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Áº©ÊîæÊ≥ïÂàôÁöÑÊé®ÂØº„ÄÅÊ®°ÂûãÊÄßËÉΩÁöÑÊØîËæÉ‰ª•ÂèäÂ§öÁßç‰∏ãÊ∏∏‰ªªÂä°ÁöÑÈ™åËØÅ„ÄÇ‰∏ªË¶ÅÊ®°ÂùóÂåÖÊã¨Êï∞ÊçÆÈõÜÈÄâÊã©„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÊÄßËÉΩËØÑ‰º∞ÂíåÁªìÊûúÂàÜÊûê„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÈ¶ñÊ¨°Âú®CLIPÂíåMaMMUTÊ®°Âûã‰∏äÊé®ÂØºÂá∫ÂÆåÊï¥ÁöÑÁº©ÊîæÊ≥ïÂàôÔºåËØÅÊòé‰∫ÜMaMMUTÂú®ËßÑÊ®°ÂíåÊ†∑Êú¨ÊïàÁéá‰∏äÁöÑ‰ºòÂäøÔºåÊèê‰æõ‰∫ÜÊñ∞ÁöÑÊØîËæÉÊñπÊ≥ï„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÈááÁî®ÊÅíÂÆöÂ≠¶‰π†ÁéáË∞ÉÂ∫¶ËøõË°åÁº©ÊîæÊ≥ïÂàôÊé®ÂØºÔºåÁ°Æ‰øù‰∫ÜËÆ°ÁÆóÊàêÊú¨ÁöÑÈôç‰ΩéÔºõÂú®Ê®°ÂûãËÆ≠ÁªÉ‰∏≠‰ΩøÁî®ÂØπÊØîÊçüÂ§±ÂíåÊñáÊú¨ÁîüÊàêÊçüÂ§±ÁöÑÁªÑÂêàÔºå‰ª•ÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåopenMaMMUT-L/14Âú®ImageNet-1kÁöÑÈõ∂-shotÂáÜÁ°ÆÁéáËææÂà∞‰∫Ü80.3%ÔºåÂú®12.8BÊ†∑Êú¨ÁöÑËÆ≠ÁªÉ‰∏ãÔºåË°®Áé∞Âá∫ÊØîÊ†áÂáÜCLIPÊõ¥Âº∫ÁöÑËßÑÊ®°ÊèêÂçáÂíåÊ†∑Êú¨ÊïàÁéáÔºåÈ™åËØÅ‰∫ÜÁº©ÊîæÊ≥ïÂàôÁöÑÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ËÆ°ÁÆóÊú∫ËßÜËßâÂíåËá™ÁÑ∂ËØ≠Ë®ÄÂ§ÑÁêÜÁöÑ‰∫§ÂèâÈ¢ÜÂüüÔºåÂ∞§ÂÖ∂Âú®Â§öÊ®°ÊÄÅÂ≠¶‰π†„ÄÅÊ®°ÂûãÈÄâÊã©ÂíåÊï∞ÊçÆÈõÜÊûÑÂª∫ÊñπÈù¢ÂÖ∑ÊúâÈáçË¶Å‰ª∑ÂÄº„ÄÇÊú™Êù•ÔºåÂü∫‰∫éÁº©ÊîæÊ≥ïÂàôÁöÑÊØîËæÉÊñπÊ≥ïÂèØËÉΩÊé®Âä®Êõ¥È´òÊïàÁöÑÊ®°ÂûãËÆæËÆ°ÂíåËÆ≠ÁªÉÁ≠ñÁï•ÁöÑÂºÄÂèë„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> In studies of transferable learning, scaling laws are obtained for various important foundation models to predict their properties and performance at larger scales. We show here how scaling law derivation can also be used for model and dataset comparison, allowing to decide which procedure is to be preferred for pre-training. For the first time, full scaling laws based on dense measurements across a wide span of model and samples seen scales are derived for two important language-vision learning procedures, CLIP and MaMMUT, that use either contrastive only or contrastive and captioning text generative loss. Ensuring sufficient prediction accuracy for held out points, we use derived scaling laws to compare both models, obtaining evidence for MaMMUT's stronger improvement with scale and better sample efficiency than standard CLIP. To strengthen validity of the comparison, we show scaling laws for various downstream tasks, classification, retrieval, and segmentation, and for different open datasets, DataComp, DFN and Re-LAION, observing consistently the same trends. We show that comparison can also be performed when deriving scaling laws with a constant learning rate schedule, reducing compute cost. Accurate derivation of scaling laws provides thus means to perform model and dataset comparison across scale spans, avoiding misleading conclusions based on measurements from single reference scales only, paving the road for systematic comparison and improvement of open foundation models and datasets for their creation. We release all the pre-trained models with their intermediate checkpoints, including openMaMMUT-L/14, which achieves $80.3\%$ zero-shot ImageNet-1k accuracy, trained on 12.8B samples from DataComp-1.4B. Code for reproducing experiments in the paper and raw experiments data can be found at https://github.com/LAION-AI/scaling-laws-for-comparison.

