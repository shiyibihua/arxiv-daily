---
layout: default
title: Tuning the Right Foundation Models is What you Need for Partial Label Learning
---

# Tuning the Right Foundation Models is What you Need for Partial Label Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05027" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05027v1</a>
  <a href="https://arxiv.org/pdf/2506.05027.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05027v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05027v1', 'Tuning the Right Foundation Models is What you Need for Partial Label Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kuang He, Wei Tang, Tong Wei, Min-Ling Zhang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: The code can be found at \url{https://github.com/SEU-hk/PartialCLIP}

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/SEU-hk/PartialCLIP)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPartialCLIPä»¥è§£å†³éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ ä¸­çš„æ¨¡å‹é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `å¾®è°ƒæ¡†æ¶` `CLIP` `å›¾åƒåˆ†ç±»` `å¤šæ¨¡æ€å­¦ä¹ ` `æ¨¡å‹é€‰æ‹©` `å€™é€‰æ ‡ç­¾è¿‡æ»¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ æ–¹æ³•åœ¨æ¨¡å‹é€‰æ‹©å’Œé€‚åº”ç­–ç•¥ä¸Šå­˜åœ¨è„†å¼±æ€§ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šã€‚
2. æœ¬æ–‡æå‡ºPartialCLIPæ¡†æ¶ï¼Œé€šè¿‡å¯¹åŸºç¡€æ¨¡å‹è¿›è¡Œé«˜æ•ˆå¾®è°ƒï¼Œæå‡éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ çš„æ•ˆæœã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹çš„PLLæ–¹æ³•æ€§èƒ½æ˜¾è‘—æå‡ï¼Œä¸”åœ¨ä¸åŒæ¨¡ç³Šåº¦æ°´å¹³ä¸‹è¡¨ç°ç¨³å®šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ ï¼ˆPLLï¼‰æ—¨åœ¨ä»å…·æœ‰ä¸ç²¾ç¡®ç›‘ç£çš„æ•°æ®é›†ä¸­è®­ç»ƒå‡ºå¯æ³›åŒ–çš„åˆ†ç±»å™¨ï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­æ˜¯ä¸€ä¸ªå¸¸è§æŒ‘æˆ˜ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨é€šè¿‡è®­ç»ƒå·ç§¯ç¥ç»ç½‘ç»œé€æ­¥ç²¾ç‚¼å’Œæ¢å¤çœŸå®æ ‡ç­¾ï¼Œä½†å¯¹æä¾›å¯è¿ç§»è¡¨ç¤ºçš„åŸºç¡€æ¨¡å‹å…³æ³¨è¾ƒå°‘ã€‚æœ¬æ–‡å¯¹11ç§åŸºç¡€æ¨¡å‹åœ¨13ç§PLLæ–¹æ³•ä¸‹çš„è¡¨ç°è¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œå¹¶æå‡ºäº†PartialCLIPï¼Œä¸€ä¸ªé«˜æ•ˆçš„åŸºç¡€æ¨¡å‹å¾®è°ƒæ¡†æ¶ã€‚ç ”ç©¶å‘ç°ï¼Œå½“å‰PLLæ–¹æ³•åœ¨ä½¿ç”¨åŸºç¡€æ¨¡å‹æ—¶æ€§èƒ½æ˜¾è‘—æå‡ï¼Œä½†åœ¨æ¨¡å‹é€‰æ‹©å’Œé€‚åº”ç­–ç•¥ä¸Šå­˜åœ¨è„†å¼±æ€§ã€‚æˆ‘ä»¬è¿˜å±•ç¤ºäº†æ–‡æœ¬åµŒå…¥åˆ†ç±»å™¨åˆå§‹åŒ–å’Œæœ‰æ•ˆå€™é€‰æ ‡ç­¾è¿‡æ»¤çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¼€å‘æ›´å…·æ³›åŒ–èƒ½åŠ›çš„PLLæ¨¡å‹æä¾›äº†é‡è¦è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ ä¸­çš„æ¨¡å‹é€‰æ‹©å’Œé€‚åº”ç­–ç•¥é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä¸ç²¾ç¡®æ ‡ç­¾æ—¶ï¼Œå¾€å¾€å¿½è§†äº†åŸºç¡€æ¨¡å‹çš„æ½œåŠ›ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç¨³å®šå’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŸºç¡€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯CLIPæ¨¡å‹ï¼Œæ¥æå‡éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ çš„æ•ˆæœã€‚é€šè¿‡é«˜æ•ˆçš„å¾®è°ƒç­–ç•¥ï¼ŒPartialCLIPèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„æ ‡ç­¾æ¨¡ç³Šåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬åŸºç¡€æ¨¡å‹çš„é€‰æ‹©ã€å¾®è°ƒè¿‡ç¨‹å’Œæ ‡ç­¾è¿‡æ»¤æ¨¡å—ã€‚é¦–å…ˆé€‰æ‹©åˆé€‚çš„åŸºç¡€æ¨¡å‹ï¼Œç„¶åé€šè¿‡PartialCLIPæ¡†æ¶è¿›è¡Œå¾®è°ƒï¼Œæœ€ååˆ©ç”¨é›¶-shot CLIPè¿›è¡Œå€™é€‰æ ‡ç­¾çš„æœ‰æ•ˆè¿‡æ»¤ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†PartialCLIPæ¡†æ¶ï¼Œä½¿å¾—åŸºç¡€æ¨¡å‹åœ¨éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ ä¸­èƒ½å¤Ÿæœ‰æ•ˆæå‡æ€§èƒ½ï¼Œå¹¶ä¸”æä¾›äº†å¯¹æ ‡ç­¾è¿‡æ»¤çš„æ–°æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒPartialCLIPåœ¨æ¨¡å‹é€‰æ‹©å’Œé€‚åº”æ€§ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒPartialCLIPé‡‡ç”¨äº†æ–‡æœ¬åµŒå…¥åˆ†ç±»å™¨åˆå§‹åŒ–ï¼Œå¹¶ç»“åˆç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚ç½‘ç»œç»“æ„ä¸Šï¼Œåˆ©ç”¨äº†CLIPçš„å¤šæ¨¡æ€ç‰¹æ€§ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹æ ‡ç­¾çš„ç†è§£å’Œé€‚åº”èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨åŸºç¡€æ¨¡å‹çš„PLLæ–¹æ³•åœ¨8ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå°¤å…¶åœ¨ä¸åŒæ¨¡ç³Šåº¦æ°´å¹³ä¸‹ï¼Œæ¨¡å‹çš„ç¨³å®šæ€§å¾—åˆ°äº†å¢å¼ºã€‚å…·ä½“è€Œè¨€ï¼Œéƒ¨åˆ†æ ‡ç­¾å­¦ä¹ æ–¹æ³•åœ¨åŸºç¡€æ¨¡å‹çš„æ”¯æŒä¸‹ï¼Œæ€§èƒ½æå‡å¹…åº¦å¯è¾¾20%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒåˆ†ç±»ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰ã€‚é€šè¿‡æå‡éƒ¨åˆ†æ ‡ç­¾å­¦ä¹ çš„æ•ˆæœï¼ŒPartialCLIPèƒ½å¤Ÿåœ¨åŒ»ç–—å½±åƒåˆ†æã€è‡ªåŠ¨é©¾é©¶ç­‰éœ€è¦å¤„ç†ä¸ç²¾ç¡®æ ‡ç­¾çš„å®é™…åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶è¿›å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Partial label learning (PLL) seeks to train generalizable classifiers from datasets with inexact supervision, a common challenge in real-world applications. Existing studies have developed numerous approaches to progressively refine and recover ground-truth labels by training convolutional neural networks. However, limited attention has been given to foundation models that offer transferrable representations. In this work, we empirically conduct comprehensive evaluations of 11 foundation models across 13 PLL approaches on 8 benchmark datasets under 3 PLL scenarios. We further propose PartialCLIP, an efficient fine-tuning framework for foundation models in PLL. Our findings reveal that current PLL approaches tend to 1) achieve significant performance gains when using foundation models, 2) exhibit remarkably similar performance to each other, 3) maintain stable performance across varying ambiguity levels, while 4) are susceptible to foundation model selection and adaptation strategies. Additionally, we demonstrate the efficacy of text-embedding classifier initialization and effective candidate label filtering using zero-shot CLIP. Our experimental results and analysis underscore the limitations of current PLL approaches and provide valuable insights for developing more generalizable PLL models. The source code can be found at https://github.com/SEU-hk/PartialCLIP.

