---
layout: default
title: Sparse Autoencoders, Again?
---

# Sparse Autoencoders, Again?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04859v2</a>
  <a href="https://arxiv.org/pdf/2506.04859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04859v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04859v2', 'Sparse Autoencoders, Again?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yin Lu, Xuening Zhu, Tong He, David Wipf

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05 (æ›´æ–°: 2025-06-06)

**å¤‡æ³¨**: Accepted to the International Conference on Machine Learning (ICML) 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆæ¨¡å‹ä»¥è§£å†³ç¨€ç–è‡ªç¼–ç å™¨çš„å±€é™æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `å˜åˆ†è‡ªç¼–ç å™¨` `æ··åˆæ¨¡å‹` `æ½œåœ¨è¡¨ç¤º` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¨€ç–è‡ªç¼–ç å™¨å’Œå˜åˆ†è‡ªç¼–ç å™¨åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶å­˜åœ¨ç†è®ºå’Œå®è·µä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨æ½œåœ¨è¡¨ç¤ºçš„ç¨€ç–æ€§å’Œé‡æ„è¯¯å·®ä¹‹é—´çš„å¹³è¡¡ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ··åˆæ¨¡å‹ï¼Œç»“åˆäº†ç»å…¸è‡ªç¼–ç å™¨çš„ä¼˜ç‚¹å’Œéšæœºç¼–ç å™¨çš„çµæ´»æ€§ï¼Œä»¥æ›´å¥½åœ°æ•æ‰æ•°æ®çš„æ½œåœ¨ç»“æ„ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡ä¼˜äºä¼ ç»ŸSAEså’ŒVAEsï¼Œèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡æ½œåœ¨ç»´åº¦å¹¶ç”Ÿæˆæ›´ç¨€ç–çš„è¡¨ç¤ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰å’Œå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰åœ¨å»ºæ¨¡ä½ç»´æ½œåœ¨ç»“æ„æ–¹é¢å…·æœ‰å¹¿æ³›çš„åº”ç”¨ï¼Œä½†å…¶æ–¹æ³•è®ºå‡ ä¹æœªæœ‰å®è´¨æ€§å˜åŒ–ã€‚æœ¬æ–‡æ­ç¤ºäº†ä¼ ç»ŸSAEså’ŒVAEsåœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶çš„ä¸è¶³ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ··åˆæ¨¡å‹ï¼Œå…‹æœäº†è¿™äº›å±€é™æ€§ã€‚é€šè¿‡ç†è®ºè¯æ˜å’Œå®è¯è¯„ä¼°ï¼Œå±•ç¤ºäº†è¯¥æ¨¡å‹åœ¨ä¼°è®¡æ½œåœ¨ç»´åº¦å’Œç”Ÿæˆç¨€ç–è¡¨ç¤ºæ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œè¶…è¶Šäº†åŒç­‰å®¹é‡çš„SAEså’ŒVAEsã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»Ÿç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰å’Œå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEsï¼‰åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶çš„å±€é™æ€§ï¼Œç‰¹åˆ«æ˜¯åœ¨æ½œåœ¨è¡¨ç¤ºçš„ç¨€ç–æ€§å’Œé‡æ„è¯¯å·®ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºäº†ä¸€ç§æ··åˆæ¨¡å‹ï¼Œç»“åˆäº†ç»å…¸è‡ªç¼–ç å™¨çš„æ·±åº¦ç»“æ„å’Œéšæœºç¼–ç å™¨çš„çµæ´»æ€§ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰æ•°æ®çš„æ½œåœ¨ç»“æ„ï¼Œå°¤å…¶æ˜¯åœ¨å¤šé‡æµå½¢æ•°æ®çš„æƒ…å†µä¸‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¨¡å‹åŒ…æ‹¬ä¸€ä¸ªæ·±åº¦ç¼–ç å™¨å’Œè§£ç å™¨ç»“æ„ï¼Œé‡‡ç”¨æ–°çš„ç¨€ç–æ­£åˆ™åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨æ½œåœ¨ç©ºé—´ä¸­ç”Ÿæˆç¨€ç–è¡¨ç¤ºã€‚æ¨¡å‹é€šè¿‡ä¼˜åŒ–æŸå¤±å‡½æ•°æ¥å®ç°å¯¹æ•°æ®æµå½¢çš„å‡†ç¡®å»ºæ¨¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„æ··åˆæ¨¡å‹æ¶æ„ï¼Œèƒ½å¤Ÿåœ¨å…¨å±€æœ€ä¼˜è§£ä¸­æ¢å¤ç‰¹å®šå½¢å¼çš„ç»“æ„åŒ–æ•°æ®ï¼Œå…‹æœäº†ä¼ ç»ŸSAEså’ŒVAEsçš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†æ–°çš„ç¨€ç–æ­£åˆ™åŒ–æŠ€æœ¯ï¼ŒæŸå¤±å‡½æ•°ç»“åˆäº†é‡æ„è¯¯å·®å’Œç¨€ç–æ€§çº¦æŸï¼Œç½‘ç»œç»“æ„åˆ™é€šè¿‡æ·±åº¦ç¼–ç å™¨å’Œè§£ç å™¨çš„ç»„åˆæ¥å®ç°æ›´é«˜æ•ˆçš„æ½œåœ¨è¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æå‡ºçš„æ··åˆæ¨¡å‹åœ¨åˆæˆå’ŒçœŸå®æ•°æ®é›†ä¸Šå‡è¶…è¶Šäº†åŒç­‰å®¹é‡çš„ç¨€ç–è‡ªç¼–ç å™¨å’Œå˜åˆ†è‡ªç¼–ç å™¨ï¼Œå°¤å…¶åœ¨é‡æ„è¯¯å·®å’Œæ½œåœ¨ç»´åº¦ä¼°è®¡æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒå¤„ç†ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„æ¿€æ´»æ¨¡å¼åˆ†æã€‚é€šè¿‡æä¾›æ›´ç¨€ç–çš„æ½œåœ¨è¡¨ç¤ºï¼Œè¯¥æ¨¡å‹å¯ä»¥åœ¨æ•°æ®å‹ç¼©ã€ç‰¹å¾æå–å’Œç”Ÿæˆæ¨¡å‹ç­‰æ–¹é¢å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Is there really much more to say about sparse autoencoders (SAEs)? Autoencoders in general, and SAEs in particular, represent deep architectures that are capable of modeling low-dimensional latent structure in data. Such structure could reflect, among other things, correlation patterns in large language model activations, or complex natural image manifolds. And yet despite the wide-ranging applicability, there have been relatively few changes to SAEs beyond the original recipe from decades ago, namely, standard deep encoder/decoder layers trained with a classical/deterministic sparse regularizer applied within the latent space. One possible exception is the variational autoencoder (VAE), which adopts a stochastic encoder module capable of producing sparse representations when applied to manifold data. In this work we formalize underappreciated weaknesses with both canonical SAEs, as well as analogous VAEs applied to similar tasks, and propose a hybrid alternative model that circumvents these prior limitations. In terms of theoretical support, we prove that global minima of our proposed model recover certain forms of structured data spread across a union of manifolds. Meanwhile, empirical evaluations on synthetic and real-world datasets substantiate the efficacy of our approach in accurately estimating underlying manifold dimensions and producing sparser latent representations without compromising reconstruction error. In general, we are able to exceed the performance of equivalent-capacity SAEs and VAEs, as well as recent diffusion models where applicable, within domains such as images and language model activation patterns.

