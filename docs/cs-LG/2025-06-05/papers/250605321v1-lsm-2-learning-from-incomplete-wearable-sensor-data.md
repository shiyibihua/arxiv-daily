---
layout: default
title: LSM-2: Learning from Incomplete Wearable Sensor Data
---

# LSM-2: Learning from Incomplete Wearable Sensor Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05321" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05321v1</a>
  <a href="https://arxiv.org/pdf/2506.05321.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05321v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05321v1', 'LSM-2: Learning from Incomplete Wearable Sensor Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maxwell A. Xu, Girish Narayanswamy, Kumar Ayush, Dimitris Spathis, Shun Liao, Shyam A. Tailor, Ahmed Metwally, A. Ali Heydari, Yuwei Zhang, Jake Garrison, Samy Abdel-Ghaffar, Xuhai Xu, Ken Gu, Jacob Sunshine, Ming-Zher Poh, Yun Liu, Tim Althoff, Shrikanth Narayanan, Pushmeet Kohli, Mark Malhotra, Shwetak Patel, Yuzhe Yang, James M. Rehg, Xin Liu, Daniel McDuff

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: Xu and Narayanswamy are co-first authors. McDuff and Liu are co-last authors

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLSM-2ä»¥è§£å†³å¯ç©¿æˆ´ä¼ æ„Ÿå™¨æ•°æ®ä¸å®Œæ•´é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¯ç©¿æˆ´ä¼ æ„Ÿå™¨` `è‡ªç›‘ç£å­¦ä¹ ` `æ•°æ®ç¼ºå¤±` `å¤šæ¨¡æ€å­¦ä¹ ` `å¥åº·ç›‘æµ‹` `æ¨¡å‹é²æ£’æ€§` `ä¸´åºŠåº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹é€šå¸¸å‡è®¾è¾“å…¥æ•°æ®å®Œæ•´ï¼Œè€Œå¯ç©¿æˆ´ä¼ æ„Ÿå™¨æ•°æ®ç»å¸¸å­˜åœ¨æ˜¾è‘—ç¼ºå¤±ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆæœä¸ä½³ã€‚
2. æœ¬æ–‡æå‡ºçš„LSM-2ç»“åˆè‡ªé€‚åº”å’Œç»§æ‰¿æ©ç ï¼ˆAIMï¼‰ï¼Œé€šè¿‡å¯å­¦ä¹ çš„æ©ç ä»¤ç‰Œå¤„ç†ç¼ºå¤±æ•°æ®ï¼Œå¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ã€‚
3. LSM-2åœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨é¢å¯¹ç¼ºå¤±æ•°æ®æ—¶ï¼Œä»èƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œå±•ç°å‡ºè‰¯å¥½çš„ä¸´åºŠåº”ç”¨æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹æ˜¯è¿‘å¹´æ¥æœºå™¨å­¦ä¹ è¿›å±•çš„åŸºçŸ³ï¼Œä½†å¤§å¤šæ•°ä¾èµ–äºå®Œæ•´ä¸”ç»“æ„è‰¯å¥½çš„æ•°æ®ã€‚å¯ç©¿æˆ´ä¼ æ„Ÿå™¨æ•°æ®å¸¸å¸¸å­˜åœ¨æ˜¾è‘—ç¼ºå¤±ï¼Œè¿™å¯¹è‡ªç›‘ç£å­¦ä¹ æ¨¡å‹æ„æˆäº†æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºç¬¬äºŒä»£å¤§å‹ä¼ æ„Ÿå™¨æ¨¡å‹LSM-2ï¼Œç»“åˆè‡ªé€‚åº”å’Œç»§æ‰¿æ©ç ï¼ˆAIMï¼‰ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç›´æ¥ä»ä¸å®Œæ•´æ•°æ®ä¸­å­¦ä¹ ç¨³å¥çš„è¡¨ç¤ºï¼Œè€Œæ— éœ€æ˜¾å¼æ’è¡¥ã€‚AIMçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºä½¿ç”¨å¯å­¦ä¹ çš„æ©ç ä»¤ç‰Œæ¥å»ºæ¨¡ç°æœ‰å’Œäººä¸ºå¼•å…¥çš„ç¼ºå¤±ï¼Œå¢å¼ºäº†å¯¹çœŸå®ä¸–ç•Œæ•°æ®çš„å¤„ç†èƒ½åŠ›ã€‚ç»è¿‡åœ¨4000ä¸‡å°æ—¶çš„å¤šæ¨¡æ€ä¼ æ„Ÿå™¨æ•°æ®é›†ä¸Šé¢„è®­ç»ƒï¼ŒLSM-2åœ¨åˆ†ç±»ã€å›å½’å’Œç”Ÿæˆå»ºæ¨¡ç­‰å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå°¤å…¶åœ¨ç›®æ ‡ç¼ºå¤±åœºæ™¯ä¸‹ä»èƒ½ä¿æŒé«˜æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºä¸´åºŠä¸€è‡´æ€§æ¨¡å¼çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¯ç©¿æˆ´ä¼ æ„Ÿå™¨æ•°æ®ä¸­çš„ç¼ºå¤±é—®é¢˜ï¼Œç°æœ‰è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•é€šå¸¸ä¾èµ–äºå®Œæ•´æ•°æ®ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†ç¼ºå¤±æƒ…å†µã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLSM-2é€šè¿‡å¼•å…¥è‡ªé€‚åº”å’Œç»§æ‰¿æ©ç ï¼ˆAIMï¼‰ï¼Œåˆ©ç”¨å¯å­¦ä¹ çš„æ©ç ä»¤ç‰Œæ¥å»ºæ¨¡ç¼ºå¤±æ•°æ®ï¼Œé¿å…äº†ä¼ ç»Ÿæ’è¡¥æ–¹æ³•çš„å±€é™æ€§ï¼Œä»è€Œå¢å¼ºäº†æ¨¡å‹å¯¹ä¸å®Œæ•´æ•°æ®çš„å­¦ä¹ èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLSM-2çš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ©ç ç”Ÿæˆã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†é˜¶æ®µã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡å­¦ä¹ æ©ç ä»¤ç‰Œæ¥è¯†åˆ«å’Œå¤„ç†ç¼ºå¤±æ•°æ®ã€‚

**å…³é”®åˆ›æ–°**ï¼šAIMçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å¯å­¦ä¹ çš„æ©ç ä»¤ç‰Œè®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨æ¨ç†æ—¶æœ‰æ•ˆå¤„ç†çœŸå®ä¸–ç•Œä¸­çš„æ•°æ®ç¼ºå¤±ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„é²æ£’æ€§å’Œé€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ©ç ä»¤ç‰Œçš„å­¦ä¹ ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¤šæ¨¡æ€è¾“å…¥ï¼Œä»¥å¢å¼ºæ¨¡å‹å¯¹ä¸åŒç±»å‹ä¼ æ„Ÿå™¨æ•°æ®çš„å¤„ç†èƒ½åŠ›ã€‚é€šè¿‡å¤§è§„æ¨¡æ•°æ®é›†çš„é¢„è®­ç»ƒï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šé¡¹ä»»åŠ¡ä¸­ï¼ŒLSM-2ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”è¡¨ç°å‡ºæ˜¾è‘—æå‡ï¼Œå°¤å…¶åœ¨é¢å¯¹ç›®æ ‡ç¼ºå¤±åœºæ™¯æ—¶ï¼Œä»èƒ½ä¿æŒé«˜è¾¾90%çš„æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨ä¸´åºŠåº”ç”¨ä¸­çš„æ½œåŠ›å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¥åº·ç›‘æµ‹ã€è¿åŠ¨åˆ†æå’Œä¸´åºŠè¯Šæ–­ç­‰ã€‚LSM-2èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¯ç©¿æˆ´è®¾å¤‡æ”¶é›†çš„ç¼ºå¤±æ•°æ®ï¼Œæå‡æ•°æ®åˆ†æçš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models, a cornerstone of recent advancements in machine learning, have predominantly thrived on complete and well-structured data. Wearable sensor data frequently suffers from significant missingness, posing a substantial challenge for self-supervised learning (SSL) models that typically assume complete data inputs. This paper introduces the second generation of Large Sensor Model (LSM-2) with Adaptive and Inherited Masking (AIM), a novel SSL approach that learns robust representations directly from incomplete data without requiring explicit imputation. AIM's core novelty lies in its use of learnable mask tokens to model both existing ("inherited") and artificially introduced missingness, enabling it to robustly handle fragmented real-world data during inference. Pre-trained on an extensive dataset of 40M hours of day-long multimodal sensor data, our LSM-2 with AIM achieves the best performance across a diverse range of tasks, including classification, regression and generative modeling. Furthermore, LSM-2 with AIM exhibits superior scaling performance, and critically, maintains high performance even under targeted missingness scenarios, reflecting clinically coherent patterns, such as the diagnostic value of nighttime biosignals for hypertension prediction. This makes AIM a more reliable choice for real-world wearable data applications.

