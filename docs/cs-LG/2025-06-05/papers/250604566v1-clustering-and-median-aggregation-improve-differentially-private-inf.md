---
layout: default
title: Clustering and Median Aggregation Improve Differentially Private Inference
---

# Clustering and Median Aggregation Improve Differentially Private Inference

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04566" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04566v1</a>
  <a href="https://arxiv.org/pdf/2506.04566.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04566v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04566v1', 'Clustering and Median Aggregation Improve Differentially Private Inference')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kareem Amin, Salman Avestimehr, Sara Babakniya, Alex Bie, Weiwei Kong, Natalia Ponomareva, Umar Syed

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡èšç±»ä¸ä¸­ä½æ•°èšåˆæå‡å·®åˆ†éšç§æ¨æ–­è´¨é‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å·®åˆ†éšç§` `è¯­è¨€æ¨¡å‹` `èšç±»` `ä¸­ä½æ•°èšåˆ` `åˆæˆæ–‡æœ¬` `éšç§ä¿æŠ¤` `æ–‡æœ¬ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å·®åˆ†éšç§æ¨æ–­æ–¹æ³•é€šè¿‡éšæœºå‡åŒ€æŠ½æ ·åˆ›å»ºæ¨æ–­æ‰¹æ¬¡ï¼Œå¯¼è‡´ç”Ÿæˆæ–‡æœ¬è´¨é‡ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¼‚è´¨ä¸»é¢˜æ—¶ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡èšç±»è¾“å…¥æ•°æ®æ¥é€‰æ‹©æ¨æ–­æ‰¹æ¬¡ï¼Œå¹¶å¼•å…¥ä¸­ä½æ•°èšåˆç®—æ³•ï¼Œä»¥æé«˜ç›¸ä¼¼ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹çš„è´¨é‡å’Œéšç§ä¿æŠ¤ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ä»£è¡¨æ€§æŒ‡æ ‡å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”åœ¨éšç§æˆæœ¬ä¸Šä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å·®åˆ†éšç§ï¼ˆDPï¼‰è¯­è¨€æ¨¡å‹æ¨æ–­æ˜¯ä¸€ç§ç”Ÿæˆç§å¯†åˆæˆæ–‡æœ¬çš„æ–¹æ³•ã€‚ä»¥æ•æ„Ÿè¾“å…¥ç¤ºä¾‹ä¸ºæç¤ºï¼Œä¿ƒä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆç›¸ä¼¼ç¤ºä¾‹ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡éšæœºå‡åŒ€æŠ½æ ·æ•æ„Ÿè¾“å…¥æ¥åˆ›å»ºæ¨æ–­æ‰¹æ¬¡ï¼Œä½†è¿™ç§æ–¹æ³•åœ¨å¤„ç†å¼‚è´¨ä¸»é¢˜æ—¶ä¼šé™ä½ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚æœ¬æ–‡æå‡ºé€šè¿‡èšç±»è¾“å…¥æ•°æ®æ¥æ”¹å–„æ¨æ–­æ‰¹æ¬¡é€‰æ‹©ï¼Œå¹¶å¼•å…¥ä¸­ä½æ•°èšåˆç®—æ³•ï¼Œä»¥æé«˜ç›¸ä¼¼ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹çš„éšç§ä¿æŠ¤æ•ˆæœã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä»£è¡¨æ€§æŒ‡æ ‡ï¼ˆå¦‚MAUVEï¼‰å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”åœ¨éšç§æˆæœ¬ä¸Šä¼˜äºä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å·®åˆ†éšç§æ¨æ–­æ–¹æ³•ä¸­ï¼Œç”±äºéšæœºå‡åŒ€æŠ½æ ·å¯¼è‡´çš„ç”Ÿæˆæ–‡æœ¬è´¨é‡ä¸‹é™çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¼‚è´¨ä¸»é¢˜æ—¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡èšç±»è¾“å…¥æ•°æ®ï¼Œé€‰æ‹©æ›´å…·ç›¸ä¼¼æ€§çš„æ¨æ–­æ‰¹æ¬¡ï¼Œä»è€Œæé«˜ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚åŒæ—¶ï¼Œåˆ©ç”¨ä¸­ä½æ•°èšåˆç®—æ³•æ›¿ä»£å¹³å‡å€¼èšåˆï¼Œä»¥å¢å¼ºéšç§ä¿æŠ¤æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬æ•°æ®èšç±»ã€æ¨æ–­æ‰¹æ¬¡é€‰æ‹©å’Œä¸­ä½æ•°èšåˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆå¯¹è¾“å…¥æ•°æ®è¿›è¡Œèšç±»ï¼Œç„¶åä»æ¯ä¸ªèšç±»ä¸­é€‰æ‹©æ¨æ–­æ ·æœ¬ï¼Œæœ€åé€šè¿‡ä¸­ä½æ•°è®¡ç®—ç”Ÿæˆä¸‹ä¸€ä¸ªæ ‡è®°çš„ç»Ÿè®¡ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆèšç±»å’Œä¸­ä½æ•°èšåˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„éšç§ä¿æŠ¤ç®—æ³•ï¼Œæ˜¾è‘—æé«˜äº†ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡å’Œéšç§ä¿éšœï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨èšç±»è¿‡ç¨‹ä¸­ï¼Œé‡‡ç”¨äº†åŸºäºä¸»é¢˜ç›¸ä¼¼æ€§çš„èšç±»ç®—æ³•ï¼›åœ¨èšåˆé˜¶æ®µï¼Œä½¿ç”¨ä¸­ä½æ•°è€Œéå¹³å‡å€¼ï¼Œä»¥é™ä½å±€éƒ¨çµæ•åº¦ï¼Œç¡®ä¿éšç§ä¿æŠ¤çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨MAUVEæŒ‡æ ‡ä¸Šè¾ƒä¹‹å‰çš„æœ€å…ˆè¿›æ–¹æ³•æå‡äº†æ˜¾è‘—çš„ä»£è¡¨æ€§ï¼ŒåŒæ—¶åœ¨ä¸‹æ¸¸ä»»åŠ¡çš„æ€§èƒ½ä¸Šä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ï¼Œä¸”éšç§æˆæœ¬æ˜¾è‘—é™ä½ï¼Œå±•ç¤ºäº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹ç”Ÿæˆã€ä¸ªæ€§åŒ–æ¨èç³»ç»Ÿä»¥åŠä»»ä½•éœ€è¦ç”Ÿæˆç§å¯†æ–‡æœ¬çš„åœºæ™¯ã€‚é€šè¿‡æé«˜åˆæˆæ–‡æœ¬çš„è´¨é‡å’Œéšç§ä¿æŠ¤èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³ç”¨æˆ·å¯¹éšç§çš„éœ€æ±‚ï¼ŒåŒæ—¶æå‡æ–‡æœ¬ç”Ÿæˆçš„å®ç”¨æ€§å’Œå¯é æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Differentially private (DP) language model inference is an approach for generating private synthetic text. A sensitive input example is used to prompt an off-the-shelf large language model (LLM) to produce a similar example. Multiple examples can be aggregated together to formally satisfy the DP guarantee.
>   Prior work creates inference batches by sampling sensitive inputs uniformly at random. We show that uniform sampling degrades the quality of privately generated text, especially when the sensitive examples concern heterogeneous topics.
>   We remedy this problem by clustering the input data before selecting inference batches. Next, we observe that clustering also leads to more similar next-token predictions across inferences. We use this insight to introduce a new algorithm that aggregates next token statistics by privately computing medians instead of averages. This approach leverages the fact that the median has decreased local sensitivity when next token predictions are similar, allowing us to state a data-dependent and ex-post DP guarantee about the privacy properties of this algorithm. Finally, we demonstrate improvements in terms of representativeness metrics (e.g., MAUVE) as well as downstream task performance. We show that our method produces high-quality synthetic data at significantly lower privacy cost than a previous state-of-the-art method.

