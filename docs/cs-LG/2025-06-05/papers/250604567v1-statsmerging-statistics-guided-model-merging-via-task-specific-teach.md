---
layout: default
title: StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation
---

# StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04567" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04567v1</a>
  <a href="https://arxiv.org/pdf/2506.04567.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04567v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04567v1', 'StatsMerging: Statistics-Guided Model Merging via Task-Specific Teacher Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ranjith Merugu, Bryan Bo Cao, Shubham Jain

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-05

**å¤‡æ³¨**: 14 pages, 4 figures, 7 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºStatsMergingä»¥è§£å†³æ¨¡å‹åˆå¹¶ä¸­çš„æ ‡ç­¾ä¾èµ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ¨¡å‹åˆå¹¶` `æ— æ ‡ç­¾å­¦ä¹ ` `ä»»åŠ¡ç‰¹å®šè’¸é¦` `å¥‡å¼‚å€¼åˆ†è§£` `è½»é‡çº§å­¦ä¹ å™¨` `è§†è§‰æ¨¡å‹` `æ³›åŒ–èƒ½åŠ›` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ¨¡å‹åˆå¹¶æ–¹æ³•é€šå¸¸ä¾èµ–äºçœŸå®æ ‡ç­¾ï¼Œé™åˆ¶äº†å…¶åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šçš„åº”ç”¨ã€‚
2. StatsMergingé€šè¿‡æƒé‡åˆ†å¸ƒç»Ÿè®¡å’Œè½»é‡çº§å­¦ä¹ å™¨ï¼Œæä¾›äº†ä¸€ç§æ— æ ‡ç­¾çš„æ¨¡å‹åˆå¹¶æ–°æ–¹æ³•ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStatsMergingåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œæå‡äº†å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ¨¡å‹åˆå¹¶å·²æˆä¸ºåœ¨æœ‰é™å†…å­˜é¢„ç®—ä¸‹å®¹çº³å¤šä¸ªå¤§å‹æ¨¡å‹çš„æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚æœ¬æ–‡æå‡ºStatsMergingï¼Œä¸€ç§æ–°é¢–çš„è½»é‡çº§å­¦ä¹ æ¨¡å‹åˆå¹¶æ–¹æ³•ï¼Œé€šè¿‡æƒé‡åˆ†å¸ƒç»Ÿè®¡æŒ‡å¯¼ï¼Œè€Œæ— éœ€çœŸå®æ ‡ç­¾æˆ–æµ‹è¯•æ ·æœ¬ã€‚StatsMergingå…·æœ‰ä¸‰å¤§ä¼˜åŠ¿ï¼šé¦–å…ˆï¼Œåˆ©ç”¨å¥‡å¼‚å€¼åˆ†è§£(SVD)ä¸­çš„å¥‡å¼‚å€¼æ•æ‰ä»»åŠ¡ç‰¹å®šçš„æƒé‡åˆ†å¸ƒï¼Œä½œä¸ºä»»åŠ¡é‡è¦æ€§çš„ä»£ç†ï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨è½»é‡çº§å­¦ä¹ å™¨StatsMergeLearnerå»ºæ¨¡ä»»åŠ¡ç‰¹å®šé¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡åˆ†å¸ƒï¼Œæé«˜äº†æ³›åŒ–èƒ½åŠ›å’Œå¯¹æœªè§æ ·æœ¬çš„é€‚åº”æ€§ï¼›æœ€åï¼Œå¼•å…¥ä»»åŠ¡ç‰¹å®šæ•™å¸ˆè’¸é¦ï¼Œåˆå¹¶å…·æœ‰å¼‚æ„æ¶æ„çš„è§†è§‰æ¨¡å‹ï¼Œé¿å…äº†å¯¹çœŸå®æ ‡ç­¾çš„é«˜æˆæœ¬éœ€æ±‚ã€‚é€šè¿‡åœ¨å…«ä¸ªä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒï¼Œç»“æœè¡¨æ˜StatsMergingåœ¨æ•´ä½“å‡†ç¡®æ€§ã€å¯¹æœªè§ä»»åŠ¡çš„æ³›åŒ–èƒ½åŠ›å’Œå¯¹å›¾åƒè´¨é‡å˜åŒ–çš„é²æ£’æ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ¨¡å‹åˆå¹¶è¿‡ç¨‹ä¸­å¯¹çœŸå®æ ‡ç­¾çš„ä¾èµ–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æ— æ ‡ç­¾æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†å…¶åº”ç”¨åœºæ™¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šStatsMergingçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨æƒé‡åˆ†å¸ƒç»Ÿè®¡ï¼Œç‰¹åˆ«æ˜¯é€šè¿‡å¥‡å¼‚å€¼åˆ†è§£(SVD)æå–ä»»åŠ¡ç‰¹å®šçš„æƒé‡åˆ†å¸ƒä¿¡æ¯ï¼Œä»è€ŒæŒ‡å¯¼æ¨¡å‹åˆå¹¶è¿‡ç¨‹ï¼Œé¿å…äº†å¯¹çœŸå®æ ‡ç­¾çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨StatsMergeLearnerå»ºæ¨¡ä»»åŠ¡ç‰¹å®šæ¨¡å‹çš„æƒé‡åˆ†å¸ƒï¼›å…¶æ¬¡ï¼Œé€šè¿‡ä»»åŠ¡ç‰¹å®šæ•™å¸ˆè’¸é¦è¿›è¡ŒçŸ¥è¯†ä¼ é€’ï¼›æœ€åï¼Œåˆå¹¶ä¸åŒæ¶æ„çš„æ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šStatsMergingçš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†ä»»åŠ¡ç‰¹å®šæ•™å¸ˆè’¸é¦æœºåˆ¶ï¼Œå…è®¸åœ¨æ²¡æœ‰çœŸå®æ ‡ç­¾çš„æƒ…å†µä¸‹è¿›è¡Œæœ‰æ•ˆçš„æ¨¡å‹åˆå¹¶ï¼Œè¿™ä¸ä¼ ç»Ÿæ–¹æ³•æ˜¾è‘—ä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸Šï¼ŒStatsMergeLearneré‡‡ç”¨è½»é‡çº§ç»“æ„ï¼ŒæŸå¤±å‡½æ•°é€šè¿‡ä»»åŠ¡ç‰¹å®šçš„çŸ¥è¯†è’¸é¦è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿æ¨¡å‹åœ¨åˆå¹¶åçš„æ€§èƒ½æå‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…«ä¸ªä»»åŠ¡çš„å®éªŒä¸­ï¼ŒStatsMergingåœ¨æ•´ä½“å‡†ç¡®æ€§ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æœªè§ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›æå‡äº†çº¦15%ï¼Œå¹¶ä¸”åœ¨å›¾åƒè´¨é‡å˜åŒ–çš„é²æ£’æ€§æµ‹è¯•ä¸­è¡¨ç°å‡ºæ›´ä½çš„æ€§èƒ½ä¸‹é™ï¼Œæ˜¾ç¤ºå‡ºå…¶ä¼˜è¶Šçš„é€‚åº”æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

StatsMergingåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ï¼Œå¦‚ç§»åŠ¨è®¾å¤‡å’Œè¾¹ç¼˜è®¡ç®—ã€‚å…¶æ— æ ‡ç­¾çš„ç‰¹æ€§ä½¿å¾—åœ¨å®é™…åº”ç”¨ä¸­èƒ½å¤Ÿæ›´çµæ´»åœ°å¤„ç†å¤šä»»åŠ¡å­¦ä¹ å’Œæ¨¡å‹é›†æˆé—®é¢˜ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡å‹éƒ¨ç½²å’Œæ›´æ–°ç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Model merging has emerged as a promising solution to accommodate multiple large models within constrained memory budgets. We present StatsMerging, a novel lightweight learning-based model merging method guided by weight distribution statistics without requiring ground truth labels or test samples. StatsMerging offers three key advantages: (1) It uniquely leverages singular values from singular value decomposition (SVD) to capture task-specific weight distributions, serving as a proxy for task importance to guide task coefficient prediction; (2) It employs a lightweight learner StatsMergeLearner to model the weight distributions of task-specific pre-trained models, improving generalization and enhancing adaptation to unseen samples; (3) It introduces Task-Specific Teacher Distillation for merging vision models with heterogeneous architectures, a merging learning paradigm that avoids costly ground-truth labels by task-specific teacher distillation. Notably, we present two types of knowledge distillation, (a) distilling knowledge from task-specific models to StatsMergeLearner; and (b) distilling knowledge from models with heterogeneous architectures prior to merging. Extensive experiments across eight tasks demonstrate the effectiveness of StatsMerging. Our results show that StatsMerging outperforms state-of-the-art techniques in terms of overall accuracy, generalization to unseen tasks, and robustness to image quality variations.

