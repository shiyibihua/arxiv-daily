---
layout: default
title: Scalable Frameworks for Real-World Audio-Visual Speech Recognition
---

# Scalable Frameworks for Real-World Audio-Visual Speech Recognition

**arXiv**: [2512.14083v1](https://arxiv.org/abs/2512.14083) | [PDF](https://arxiv.org/pdf/2512.14083.pdf)

**ä½œè€…**: Sungnyun Kim

**åˆ†ç±»**: eess.AS, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: PhD Dissertation

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å±‚å¯æ‰©å±•æ¡†æž¶ä»¥è§£å†³çœŸå®žä¸–ç•Œè§†å¬è¯­éŸ³è¯†åˆ«ä¸­çš„é²æ£’æ€§å’Œæ³›åŒ–æ€§é—®é¢˜**

**å…³é”®è¯**: `è§†å¬è¯­éŸ³è¯†åˆ«` `å¤šæ¨¡æ€èžåˆ` `é²æ£’æ€§å­¦ä¹ ` `å¯æ‰©å±•æž¶æž„` `åŸºç¡€æ¨¡åž‹é›†æˆ` `çœŸå®žä¸–ç•Œåº”ç”¨` `è‡ªé€‚åº”è®¡ç®—` `åˆ†å±‚æ¡†æž¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçœŸå®žä¸–ç•ŒAVSRç³»ç»Ÿåœ¨å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°ä¸‹æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼ŒçŽ°æœ‰æ–¹æ³•ç¼ºä¹ç³»ç»ŸåŒ–è§£å†³æ–¹æ¡ˆåº”å¯¹å¤šå±‚é¢æŒ‘æˆ˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†å±‚å¯æ‰©å±•æ¡†æž¶ï¼Œåœ¨è¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢åˆ†åˆ«æå‡é²æ£’æ€§ã€è‡ªé€‚åº”èƒ½åŠ›å’ŒåŠŸèƒ½æ‰©å±•æ€§ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šé€šè¿‡ç»Ÿä¸€ç‰¹å¾å­¦ä¹ ã€æ™ºèƒ½èµ„æºåˆ†é…å’ŒåŸºç¡€æ¨¡åž‹é›†æˆï¼Œæ˜¾è‘—æå‡ç³»ç»Ÿåœ¨å¤æ‚çŽ¯å¢ƒä¸‹çš„è¯†åˆ«å‡†ç¡®çŽ‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†å¬è¯­éŸ³è¯†åˆ«ï¼ˆAVSRï¼‰ç³»ç»Ÿåœ¨å®žé™…éƒ¨ç½²ä¸­é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ï¼Œä¸»è¦æºäºŽçœŸå®žçŽ¯å¢ƒä¸­çš„ä¸å¯é¢„æµ‹å£°å­¦å™ªå£°å’Œè§†è§‰å¹²æ‰°å¯¼è‡´çš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æœ¬è®ºæ–‡ä¸»å¼ é‡‡ç”¨ç³»ç»ŸåŒ–çš„åˆ†å±‚æ–¹æ³•å…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œåœ¨è¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢å®žçŽ°é²æ£’çš„å¯æ‰©å±•æ€§ã€‚åœ¨è¡¨ç¤ºå±‚é¢ï¼Œæˆ‘ä»¬ç ”ç©¶æž„å»ºç»Ÿä¸€æ¨¡åž‹çš„æ–¹æ³•ï¼Œå­¦ä¹ å¯¹å¤šç§çœŸå®žä¸–ç•Œå¹²æ‰°å…·æœ‰å†…åœ¨é²æ£’æ€§çš„è§†å¬ç‰¹å¾ï¼Œä»Žè€Œæ— éœ€ä¸“ç”¨æ¨¡å—å³å¯æ³›åŒ–åˆ°æ–°çŽ¯å¢ƒã€‚é’ˆå¯¹æž¶æž„å¯æ‰©å±•æ€§ï¼Œæˆ‘ä»¬æŽ¢ç´¢å¦‚ä½•é«˜æ•ˆæ‰©å±•æ¨¡åž‹å®¹é‡ï¼ŒåŒæ—¶ç¡®ä¿å¤šæ¨¡æ€è¾“å…¥çš„è‡ªé€‚åº”å¯é ä½¿ç”¨ï¼Œå¼€å‘äº†ä¸€ä¸ªåŸºäºŽè¾“å…¥ç‰¹å¾æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºçš„æ¡†æž¶ã€‚æœ€åŽï¼Œåœ¨ç³»ç»Ÿå±‚é¢ï¼Œæˆ‘ä»¬æå‡ºé€šè¿‡ä¸Žå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹çš„æ¨¡å—åŒ–é›†æˆæ¥æ‰©å±•ç³»ç»ŸåŠŸèƒ½ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›æœ€å¤§åŒ–æœ€ç»ˆè¯†åˆ«å‡†ç¡®çŽ‡ã€‚é€šè¿‡åœ¨è¿™ä¸‰ä¸ªå±‚é¢ç³»ç»Ÿæä¾›è§£å†³æ–¹æ¡ˆï¼Œæœ¬è®ºæ–‡æ—¨åœ¨æž„å»ºä¸‹ä¸€ä»£é²æ£’ã€å¯æ‰©å±•ä¸”åœ¨å®žé™…åº”ç”¨ä¸­å…·æœ‰é«˜å¯é æ€§çš„AVSRç³»ç»Ÿã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºä¸€ä¸ªåˆ†å±‚å¯æ‰©å±•æ¡†æž¶ï¼Œæ•´ä½“ä¸Šåˆ†ä¸ºè¡¨ç¤ºã€æž¶æž„å’Œç³»ç»Ÿä¸‰ä¸ªå±‚é¢ã€‚åœ¨è¡¨ç¤ºå±‚é¢ï¼Œæ ¸å¿ƒåˆ›æ–°æ˜¯æž„å»ºç»Ÿä¸€æ¨¡åž‹å­¦ä¹ å¯¹å¤šç§çœŸå®žä¸–ç•Œå¹²æ‰°å…·æœ‰å†…åœ¨é²æ£’æ€§çš„è§†å¬ç‰¹å¾ï¼Œé¿å…ä¾èµ–ä¸“ç”¨æ¨¡å—ã€‚åœ¨æž¶æž„å±‚é¢ï¼Œå…³é”®æŠ€æœ¯åˆ›æ–°æ˜¯å¼€å‘è‡ªé€‚åº”æ¡†æž¶ï¼Œæ ¹æ®è¾“å…¥ç‰¹å¾æ™ºèƒ½åˆ†é…è®¡ç®—èµ„æºï¼Œå®žçŽ°æ¨¡åž‹å®¹é‡çš„é«˜æ•ˆæ‰©å±•ã€‚åœ¨ç³»ç»Ÿå±‚é¢ï¼Œä¸»è¦åŒºåˆ«åœ¨äºŽé€šè¿‡æ¨¡å—åŒ–é›†æˆå¤§è§„æ¨¡åŸºç¡€æ¨¡åž‹ï¼Œåˆ©ç”¨å…¶è®¤çŸ¥å’Œç”Ÿæˆèƒ½åŠ›å¢žå¼ºç³»ç»ŸåŠŸèƒ½ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ç³»ç»Ÿæ€§åœ°è§£å†³äº†å¤šå±‚é¢æŒ‘æˆ˜ï¼Œè€Œéžå­¤ç«‹ä¼˜åŒ–å•ä¸ªç»„ä»¶ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒè¡¨æ˜Žï¼Œåˆ†å±‚æ¡†æž¶åœ¨çœŸå®žä¸–ç•Œå™ªå£°å’Œå¹²æ‰°ä¸‹æ˜¾è‘—æå‡è¯†åˆ«å‡†ç¡®çŽ‡ï¼Œç»Ÿä¸€ç‰¹å¾å­¦ä¹ å¢žå¼ºæ³›åŒ–èƒ½åŠ›ï¼Œæ™ºèƒ½èµ„æºåˆ†é…ä¼˜åŒ–è®¡ç®—æ•ˆçŽ‡ï¼ŒåŸºç¡€æ¨¡åž‹é›†æˆæœ€å¤§åŒ–æ€§èƒ½ï¼Œæ•´ä½“ç³»ç»Ÿå±•çŽ°å‡ºé«˜å¯é æ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽæ™ºèƒ½åŠ©æ‰‹ã€è¿œç¨‹ä¼šè®®ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¾…åŠ©å’Œå¨±ä¹ç­‰éœ€è¦é«˜é²æ£’æ€§è¯­éŸ³è¯†åˆ«çš„é¢†åŸŸï¼Œæå‡ç³»ç»Ÿåœ¨å˜ˆæ‚æˆ–è§†è§‰å—é™çŽ¯å¢ƒä¸‹çš„å¯é æ€§ï¼ŒæŽ¨åŠ¨AVSRæŠ€æœ¯åœ¨å®žé™…åœºæ™¯ä¸­çš„å¹¿æ³›éƒ¨ç½²ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.

