---
layout: default
title: ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning
---

# ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning

**arXiv**: [2512.14619v1](https://arxiv.org/abs/2512.14619) | [PDF](https://arxiv.org/pdf/2512.14619.pdf)

**ä½œè€…**: Chaohao Yuan, Zhenjie Song, Ercan Engin Kuruoglu, Kangfei Zhao, Yang Liu, Deli Zhao, Hong Cheng, Yu Rong

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Accepted by WSDM 2026

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/chaohaoyuan/ParaFormer)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

<<<<<<< HEAD
**æå‡ºParaFormerï¼Œä¸€ç§åŸºäºPageRankå¢å¼ºçš„å›¾Transformerï¼Œä»¥è§£å†³å›¾Transformerä¸­å…¨å±€æ³¨æ„åŠ›å¯¼è‡´çš„è¿‡å¹³æ»‘é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `å›¾Transformer` `è¿‡å¹³æ»‘é—®é¢˜` `PageRankç®—æ³•` `è‡ªé€‚åº”é€šæ»¤æ³¢å™¨` `èŠ‚ç‚¹åˆ†ç±»` `å›¾åˆ†ç±»` `å›¾è¡¨ç¤ºå­¦ä¹ ` `å…¨å±€æ³¨æ„åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾Transformerçš„å…¨å±€æ³¨æ„åŠ›æœºåˆ¶å­˜åœ¨ä¸¥é‡è¿‡å¹³æ»‘é—®é¢˜ï¼Œå¯¼è‡´èŠ‚ç‚¹è¡¨ç¤ºä¸å¯åŒºåˆ†ï¼Œé™åˆ¶äº†å…¶æ·±å±‚å»ºæ¨¡èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºParaFormerï¼Œé€šè¿‡PageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—æ¨¡æ‹Ÿæ·±åº¦Transformerè¡Œä¸ºï¼Œä½œä¸ºè‡ªé€‚åº”é€šæ»¤æ³¢å™¨æ¥ç¼“è§£è¿‡å¹³æ»‘ã€‚
3. å®éªŒåœ¨11ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯äº†ParaFormerçš„æœ‰æ•ˆæ€§ï¼Œåœ¨èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸­å‡å®ç°æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾Transformerï¼ˆGTsï¼‰ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„å›¾å­¦ä¹ å·¥å…·ï¼Œåˆ©ç”¨å…¶å…¨å¯¹è¿æ¥ç‰¹æ€§æœ‰æ•ˆæ•è·å…¨å±€ä¿¡æ¯ã€‚ä¸ºè§£å†³æ·±åº¦å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰ä¸­çš„è¿‡å¹³æ»‘é—®é¢˜ï¼Œå…¨å±€æ³¨æ„åŠ›è¢«å¼•å…¥ï¼Œæ¶ˆé™¤äº†ä½¿ç”¨æ·±åº¦GNNsçš„å¿…è¦æ€§ã€‚ç„¶è€Œï¼Œé€šè¿‡å®è¯å’Œç†è®ºåˆ†æï¼Œæˆ‘ä»¬éªŒè¯äº†å¼•å…¥çš„å…¨å±€æ³¨æ„åŠ›è¡¨ç°å‡ºä¸¥é‡çš„è¿‡å¹³æ»‘ï¼Œå¯¼è‡´èŠ‚ç‚¹è¡¨ç¤ºå› å›ºæœ‰çš„ä½é€šæ»¤æ³¢æ•ˆåº”è€Œå˜å¾—ä¸å¯åŒºåˆ†ï¼Œè¿™ç§æ•ˆåº”ç”šè‡³æ¯”GNNsä¸­è§‚å¯Ÿåˆ°çš„æ›´å¼ºã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PageRank Transformerï¼ˆParaFormerï¼‰ï¼Œå…¶ç‰¹ç‚¹æ˜¯åŒ…å«ä¸€ä¸ªPageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿæ·±åº¦Transformerçš„è¡Œä¸ºã€‚æˆ‘ä»¬ä»ç†è®ºå’Œå®è¯ä¸Šè¯æ˜ï¼ŒParaFormeré€šè¿‡ä½œä¸ºè‡ªé€‚åº”é€šæ»¤æ³¢å™¨æ¥ç¼“è§£è¿‡å¹³æ»‘ã€‚å®éªŒæ˜¾ç¤ºï¼ŒParaFormeråœ¨11ä¸ªæ•°æ®é›†ï¼ˆèŠ‚ç‚¹æ•°ä»æ•°åƒåˆ°æ•°ç™¾ä¸‡ï¼‰çš„èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸­å‡å®ç°äº†æŒç»­çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è¡¥å……ææ–™ï¼ŒåŒ…æ‹¬ä»£ç å’Œé™„å½•ï¼Œå¯åœ¨https://github.com/chaohaoyuan/ParaFormeræ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å›¾Transformerï¼ˆGTsï¼‰ä¸­å…¨å±€æ³¨æ„åŠ›æœºåˆ¶å¯¼è‡´çš„è¿‡å¹³æ»‘é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹æ˜¯ï¼Œå°½ç®¡å…¨å±€æ³¨æ„åŠ›è¢«å¼•å…¥ä»¥ç¼“è§£æ·±åº¦å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰çš„è¿‡å¹³æ»‘ï¼Œä½†å®è¯å’Œç†è®ºåˆ†æè¡¨æ˜ï¼Œè¿™ç§å…¨å±€æ³¨æ„åŠ›æœ¬èº«è¡¨ç°å‡ºæ›´ä¸¥é‡çš„è¿‡å¹³æ»‘ï¼Œä½¿èŠ‚ç‚¹è¡¨ç¤ºå› ä½é€šæ»¤æ³¢æ•ˆåº”è€Œå˜å¾—ä¸å¯åŒºåˆ†ï¼Œä»è€Œé™åˆ¶äº†æ¨¡å‹çš„æ·±å±‚è¡¨ç¤ºèƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªPageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—ï¼Œä»¥æ¨¡æ‹Ÿæ·±åº¦Transformerçš„è¡Œä¸ºã€‚è¿™æ ·è®¾è®¡çš„åŸå› æ˜¯ï¼ŒPageRankç®—æ³•èƒ½è‡ªé€‚åº”åœ°è°ƒæ•´èŠ‚ç‚¹é‡è¦æ€§ï¼Œä»è€Œåœ¨æ³¨æ„åŠ›æœºåˆ¶ä¸­å¼•å…¥æ›´çµæ´»çš„æ»¤æ³¢ç‰¹æ€§ï¼Œé¿å…å…¨å±€æ³¨æ„åŠ›å›ºæœ‰çš„ä½é€šæ»¤æ³¢å¯¼è‡´çš„è¿‡å¹³æ»‘ï¼Œå®ç°è‡ªé€‚åº”é€šæ»¤æ³¢ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šParaFormerçš„æ•´ä½“æ¶æ„åŸºäºå›¾Transformerï¼Œä½†æ›¿æ¢äº†æ ‡å‡†çš„å…¨å±€æ³¨æ„åŠ›æ¨¡å—ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬è¾“å…¥åµŒå…¥å±‚ã€PageRankå¢å¼ºçš„æ³¨æ„åŠ›å±‚ã€å‰é¦ˆç½‘ç»œå±‚å’Œè¾“å‡ºå±‚ã€‚æµç¨‹ä¸Šï¼Œé¦–å…ˆå¯¹å›¾èŠ‚ç‚¹è¿›è¡Œç‰¹å¾åµŒå…¥ï¼Œç„¶åé€šè¿‡PageRankæ³¨æ„åŠ›è®¡ç®—èŠ‚ç‚¹é—´çš„è‡ªé€‚åº”æƒé‡ï¼Œæ¥ç€è¿›è¡Œå¤šå±‚å¤„ç†ä»¥æ•è·å…¨å±€ä¿¡æ¯ï¼Œæœ€åç”¨äºåˆ†ç±»ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯PageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—ï¼Œå®ƒé€šè¿‡æ•´åˆPageRankç®—æ³•æ¥è°ƒæ•´æ³¨æ„åŠ›æƒé‡ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä½œä¸ºè‡ªé€‚åº”é€šæ»¤æ³¢å™¨è¿ä½œã€‚ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼Œä¼ ç»Ÿå›¾Transformerçš„å…¨å±€æ³¨æ„åŠ›æ˜¯å›ºå®šçš„ä½é€šæ»¤æ³¢å™¨ï¼Œè€ŒParaFormerçš„æ³¨æ„åŠ›èƒ½æ ¹æ®å›¾ç»“æ„åŠ¨æ€è°ƒæ•´ï¼Œä»è€Œæ›´æœ‰æ•ˆåœ°å¹³è¡¡å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ï¼Œç¼“è§£è¿‡å¹³æ»‘ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬ï¼šæ³¨æ„åŠ›æƒé‡è®¡ç®—ä¸­èå…¥PageRankåˆ†æ•°ä»¥å¢å¼ºèŠ‚ç‚¹é‡è¦æ€§è¯„ä¼°ï¼›ä½¿ç”¨å¤šå±‚Transformeræ¶æ„ï¼Œä½†æ³¨æ„åŠ›å±‚ç»è¿‡PageRankä¼˜åŒ–ï¼›æŸå¤±å‡½æ•°é€šå¸¸é‡‡ç”¨äº¤å‰ç†µæŸå¤±ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼›ç½‘ç»œç»“æ„å¯èƒ½åŒ…å«æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ä»¥ç¨³å®šè®­ç»ƒï¼›å‚æ•°è®¾ç½®å¦‚æ³¨æ„åŠ›å¤´æ•°å’Œéšè—ç»´åº¦æ ¹æ®æ•°æ®é›†è°ƒæ•´ï¼Œä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒåœ¨11ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œæ¶µç›–èŠ‚ç‚¹æ•°ä»æ•°åƒåˆ°æ•°ç™¾ä¸‡çš„å›¾ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ã€‚ParaFormerç›¸æ¯”åŸºçº¿æ–¹æ³•ï¼ˆå¦‚æ ‡å‡†å›¾Transformerå’ŒGNNsï¼‰å®ç°äº†æŒç»­çš„æ€§èƒ½æå‡ï¼Œå…·ä½“æå‡å¹…åº¦å› æ•°æ®é›†è€Œå¼‚ï¼Œä¾‹å¦‚åœ¨æŸäº›åŸºå‡†æ•°æ®é›†ä¸Šå‡†ç¡®ç‡æå‡å¯è¾¾å‡ ä¸ªç™¾åˆ†ç‚¹ã€‚è¿™éªŒè¯äº†å…¶ä½œä¸ºè‡ªé€‚åº”é€šæ»¤æ³¢å™¨åœ¨ç¼“è§£è¿‡å¹³æ»‘æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶å±•ç¤ºäº†åœ¨å¤šæ ·å›¾ä»»åŠ¡ä¸­çš„é²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ParaFormeråœ¨å›¾è¡¨ç¤ºå­¦ä¹ é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼ŒåŒ…æ‹¬ç¤¾äº¤ç½‘ç»œåˆ†æã€ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­çš„è›‹ç™½è´¨ç›¸äº’ä½œç”¨é¢„æµ‹ã€æ¨èç³»ç»Ÿä¸­çš„ç”¨æˆ·-ç‰©å“å›¾å»ºæ¨¡ï¼Œä»¥åŠçŸ¥è¯†å›¾è°±æ¨ç†ç­‰ã€‚å…¶å®é™…ä»·å€¼åœ¨äºé€šè¿‡ç¼“è§£è¿‡å¹³æ»‘é—®é¢˜ï¼Œæå‡æ·±å±‚å›¾æ¨¡å‹çš„æ€§èƒ½ï¼Œä»è€Œåœ¨éœ€è¦æ•è·å¤æ‚å…¨å±€å…³ç³»çš„ä»»åŠ¡ä¸­æä¾›æ›´å‡†ç¡®çš„è¡¨ç¤ºã€‚æœªæ¥å½±å“å¯èƒ½æ¨åŠ¨å›¾Transformeråœ¨æ›´å¤§è§„æ¨¡å›¾æ•°æ®ä¸Šçš„åº”ç”¨ï¼Œä¿ƒè¿›äººå·¥æ™ºèƒ½åœ¨å›¾ç»“æ„æ•°æ®å¤„ç†ä¸­çš„è¿›æ­¥ã€‚
=======
**æå‡ºPageRank Transformerä»¥è§£å†³å›¾Transformerä¸­çš„è¿‡åº¦å¹³æ»‘é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **è§†è§‰é‡Œç¨‹è®¡**

**å…³é”®è¯**: `å›¾Transformer` `è¿‡åº¦å¹³æ»‘` `PageRank` `è‡ªé€‚åº”æ»¤æ³¢` `å›¾è¡¨ç¤ºå­¦ä¹ ` `èŠ‚ç‚¹åˆ†ç±»` `å›¾åˆ†ç±»` `å…¨å±€æ³¨æ„åŠ›`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾Transformerçš„å…¨å±€æ³¨æ„åŠ›æœºåˆ¶å­˜åœ¨ä¸¥é‡è¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œå¯¼è‡´èŠ‚ç‚¹è¡¨ç¤ºéš¾ä»¥åŒºåˆ†ï¼Œå½±å“æ¨¡å‹æ€§èƒ½ã€‚
2. æå‡ºPageRank Transformerï¼Œé€šè¿‡PageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—æ¨¡æ‹Ÿæ·±åº¦Transformerè¡Œä¸ºï¼Œå®ç°è‡ªé€‚åº”æ»¤æ³¢ä»¥ç¼“è§£è¿‡åº¦å¹³æ»‘ã€‚
3. åœ¨11ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒParaFormeråœ¨èŠ‚ç‚¹å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸­å‡å–å¾—ä¸€è‡´æ€§èƒ½æå‡ï¼ŒéªŒè¯å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å›¾Transformerï¼ˆGTsï¼‰ä½œä¸ºä¸€ç§æœ‰å‰æ™¯çš„å›¾å­¦ä¹ å·¥å…·ï¼Œåˆ©ç”¨å…¶å…¨è¿æ¥ç‰¹æ€§æœ‰æ•ˆæ•è·å…¨å±€ä¿¡æ¯ã€‚ä¸ºè§£å†³æ·±åº¦å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰ä¸­çš„è¿‡åº¦å¹³æ»‘é—®é¢˜ï¼Œå…¨å±€æ³¨æ„åŠ›æœºåˆ¶è¢«å¼•å…¥ï¼Œæ¶ˆé™¤äº†ä½¿ç”¨æ·±åº¦GNNsçš„å¿…è¦æ€§ã€‚ç„¶è€Œï¼Œé€šè¿‡å®è¯å’Œç†è®ºåˆ†æï¼Œæˆ‘ä»¬å‘ç°å¼•å…¥çš„å…¨å±€æ³¨æ„åŠ›è¡¨ç°å‡ºä¸¥é‡çš„è¿‡åº¦å¹³æ»‘ï¼Œç”±äºå…¶å›ºæœ‰çš„ä½é€šæ»¤æ³¢ç‰¹æ€§ï¼Œå¯¼è‡´èŠ‚ç‚¹è¡¨ç¤ºå˜å¾—éš¾ä»¥åŒºåˆ†ï¼Œè¿™ç§æ•ˆåº”ç”šè‡³æ¯”GNNsä¸­è§‚å¯Ÿåˆ°çš„æ›´å¼ºã€‚ä¸ºç¼“è§£æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PageRank Transformerï¼ˆParaFormerï¼‰ï¼Œå…¶ç‰¹ç‚¹æ˜¯åŒ…å«ä¸€ä¸ªPageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—ï¼Œæ—¨åœ¨æ¨¡æ‹Ÿæ·±åº¦Transformerçš„è¡Œä¸ºã€‚æˆ‘ä»¬ä»ç†è®ºå’Œå®è¯ä¸Šè¯æ˜ï¼ŒParaFormeré€šè¿‡å……å½“è‡ªé€‚åº”é€šæ»¤æ³¢å™¨æ¥å‡è½»è¿‡åº¦å¹³æ»‘ã€‚å®éªŒè¡¨æ˜ï¼ŒParaFormeråœ¨ä»æ•°åƒåˆ°æ•°ç™¾ä¸‡èŠ‚ç‚¹çš„11ä¸ªæ•°æ®é›†ä¸Šçš„èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸­å‡å®ç°äº†æŒç»­çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è¡¥å……ææ–™ï¼ŒåŒ…æ‹¬ä»£ç å’Œé™„å½•ï¼Œå¯åœ¨https://github.com/chaohaoyuan/ParaFormeræ‰¾åˆ°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

ParaFormerçš„æ•´ä½“æ¡†æ¶åŸºäºå›¾Transformerï¼Œæ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥PageRankå¢å¼ºçš„æ³¨æ„åŠ›æ¨¡å—ã€‚è¯¥æ¨¡å—é€šè¿‡æ•´åˆPageRankç®—æ³•æ¥è°ƒæ•´æ³¨æ„åŠ›æƒé‡ï¼Œä½¿å…¶èƒ½å¤Ÿè‡ªé€‚åº”åœ°è¿‡æ»¤ä¿¡æ¯ï¼Œä»è€Œæ¨¡æ‹Ÿæ·±åº¦Transformerçš„å±‚æ¬¡åŒ–ç‰¹å¾æå–è¿‡ç¨‹ã€‚ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œä¼ ç»Ÿå›¾Transformerçš„å…¨å±€æ³¨æ„åŠ›æ˜¯ä½é€šæ»¤æ³¢å™¨ï¼Œå¯¼è‡´è¿‡åº¦å¹³æ»‘ï¼›è€ŒParaFormeré€šè¿‡PageRankæœºåˆ¶å®ç°è‡ªé€‚åº”é€šæ»¤æ³¢ï¼Œæœ‰æ•ˆå¹³è¡¡å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ï¼Œå‡å°‘è¡¨ç¤ºé€€åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

ParaFormeråœ¨11ä¸ªæ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ï¼Œæ€§èƒ½æå‡ä¸€è‡´ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡å›¾æ•°æ®ä¸ŠéªŒè¯äº†å…¶ç¼“è§£è¿‡åº¦å¹³æ»‘çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†è‡ªé€‚åº”æ»¤æ³¢ç­–ç•¥çš„ä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºç¤¾äº¤ç½‘ç»œåˆ†æã€ç”Ÿç‰©ä¿¡æ¯å­¦ã€æ¨èç³»ç»Ÿç­‰éœ€è¦å¤„ç†å¤§è§„æ¨¡å›¾æ•°æ®çš„é¢†åŸŸï¼Œé€šè¿‡æå‡å›¾è¡¨ç¤ºå­¦ä¹ çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œæ”¯æŒèŠ‚ç‚¹åˆ†ç±»ã€å›¾åˆ†ç±»ç­‰ä»»åŠ¡ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼ã€‚
>>>>>>> 1c05e1c356e1f28c2e5e6e14cf6811c0d5120ab7

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Graph Transformers (GTs) have emerged as a promising graph learning tool, leveraging their all-pair connected property to effectively capture global information. To address the over-smoothing problem in deep GNNs, global attention was initially introduced, eliminating the necessity for using deep GNNs. However, through empirical and theoretical analysis, we verify that the introduced global attention exhibits severe over-smoothing, causing node representations to become indistinguishable due to its inherent low-pass filtering. This effect is even stronger than that observed in GNNs. To mitigate this, we propose PageRank Transformer (ParaFormer), which features a PageRank-enhanced attention module designed to mimic the behavior of deep Transformers. We theoretically and empirically demonstrate that ParaFormer mitigates over-smoothing by functioning as an adaptive-pass filter. Experiments show that ParaFormer achieves consistent performance improvements across both node classification and graph classification tasks on 11 datasets ranging from thousands to millions of nodes, validating its efficacy. The supplementary material, including code and appendix, can be found in https://github.com/chaohaoyuan/ParaFormer.

