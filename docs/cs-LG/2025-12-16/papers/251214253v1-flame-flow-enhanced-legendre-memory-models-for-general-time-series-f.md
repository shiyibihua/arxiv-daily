---
layout: default
title: FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting
---

# FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting

**arXiv**: [2512.14253v1](https://arxiv.org/abs/2512.14253) | [PDF](https://arxiv.org/pdf/2512.14253.pdf)

**ä½œè€…**: Xingjian Wu, Hanyin Cheng, Xiangfei Qiu, Zhengyu Li, Jilin Hu, Chenjuan Guo, Bin Yang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

<<<<<<< HEAD
**æå‡ºFLAMEæ¨¡å‹ï¼Œé€šè¿‡æµå¢å¼ºçš„å‹’è®©å¾·è®°å¿†æœºåˆ¶è§£å†³æ—¶é—´åºåˆ—ç¡®å®šæ€§åŠæ¦‚ç‡æ€§é¢„æµ‹é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `å‹’è®©å¾·è®°å¿†` `å½’ä¸€åŒ–æµ` `æ¦‚ç‡å»ºæ¨¡` `é›¶æ ·æœ¬å­¦ä¹ ` `é•¿ç¨‹æ¨ç†` `è½»é‡çº§æ¨¡å‹` `åŸºç¡€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•åœ¨é•¿ç¨‹æ¨ç†å’Œå¤æ‚åˆ†å¸ƒå»ºæ¨¡ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å…¼é¡¾æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚
2. FLAMEé€šè¿‡å‹’è®©å¾·è®°å¿†å˜ä½“æ•æ‰æ•°æ®å½’çº³åç½®ï¼Œå¹¶åˆ©ç”¨å½’ä¸€åŒ–æµå»ºæ¨¡å¤æ‚åˆ†å¸ƒï¼Œå®ç°é«˜æ•ˆé¢„æµ‹ã€‚
3. åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡é¢„æµ‹ç²¾åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†FLAMEï¼Œä¸€ä¸ªæå…¶è½»é‡ä¸”å¼ºå¤§çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹å®¶æ—ï¼Œæ”¯æŒé€šè¿‡ç”Ÿæˆå¼æ¦‚ç‡å»ºæ¨¡è¿›è¡Œç¡®å®šæ€§å’Œæ¦‚ç‡æ€§é¢„æµ‹ï¼Œä»è€Œç¡®ä¿æ•ˆç‡å’Œé²æ£’æ€§ã€‚FLAMEåˆ©ç”¨å‹’è®©å¾·è®°å¿†å®ç°å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡é‡‡ç”¨å‹’è®©å¾·è®°å¿†çš„å˜ä½“ï¼Œå³å¹³ç§»å‹’è®©å¾·ï¼ˆLegTï¼‰å’Œç¼©æ”¾å‹’è®©å¾·ï¼ˆLegSï¼‰ï¼Œåœ¨ç¼–ç å’Œè§£ç é˜¶æ®µï¼ŒFLAMEèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æ•°æ®ä¸­çš„å†…åœ¨å½’çº³åç½®ï¼Œå¹¶è¿›è¡Œé«˜æ•ˆçš„é•¿ç¨‹æ¨ç†ã€‚ä¸ºäº†åœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶æå‡æ¦‚ç‡æ€§é¢„æµ‹çš„å‡†ç¡®æ€§ï¼ŒFLAMEé‡‡ç”¨åŸºäºå½’ä¸€åŒ–æµçš„é¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼å»ºæ¨¡é¢„æµ‹èŒƒå›´å†…ä»»æ„å¤æ‚çš„åˆ†å¸ƒã€‚åœ¨å…¬è®¤çš„åŸºå‡†æµ‹è¯•ï¼ˆåŒ…æ‹¬TSFM-Benchå’ŒProbTSï¼‰ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒFLAMEåœ¨ç¡®å®šæ€§å’Œæ¦‚ç‡æ€§é¢„æµ‹ä»»åŠ¡ä¸Šå‡å±•ç°å‡ºæŒç»­çš„æœ€å…ˆè¿›çš„é›¶æ ·æœ¬æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„ä¸¤ä¸ªæ ¸å¿ƒé—®é¢˜ï¼šç¡®å®šæ€§é¢„æµ‹ï¼ˆç‚¹ä¼°è®¡ï¼‰å’Œæ¦‚ç‡æ€§é¢„æµ‹ï¼ˆåˆ†å¸ƒä¼°è®¡ï¼‰ã€‚ç°æœ‰æ–¹æ³•å¸¸é¢ä¸´é•¿ç¨‹ä¾èµ–å»ºæ¨¡å›°éš¾ã€è®¡ç®—æ•ˆç‡ä½ã€ä»¥åŠå¯¹å¤æ‚æ•°æ®åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ä¸è¶³çš„ç—›ç‚¹ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬æˆ–å°æ ·æœ¬åœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFLAMEçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆå‹’è®©å¾·è®°å¿†ï¼ˆLegendre Memoryï¼‰çš„æ³›åŒ–ä¼˜åŠ¿ä¸å½’ä¸€åŒ–æµï¼ˆNormalization Flowï¼‰çš„åˆ†å¸ƒå»ºæ¨¡èƒ½åŠ›ã€‚å‹’è®©å¾·è®°å¿†é€šè¿‡æ­£äº¤åŸºå‡½æ•°æœ‰æ•ˆæ•æ‰æ—¶é—´åºåˆ—çš„é•¿æœŸæ¨¡å¼ï¼Œè€Œå½’ä¸€åŒ–æµåˆ™èƒ½çµæ´»å»ºæ¨¡ä»»æ„å¤æ‚çš„è¾“å‡ºåˆ†å¸ƒï¼Œä»è€Œåœ¨è½»é‡çº§æ¶æ„ä¸‹å®ç°é«˜æ•ˆä¸”é²æ£’çš„é¢„æµ‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFLAMEçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç¼–ç é˜¶æ®µã€è§£ç é˜¶æ®µå’Œé¢„æµ‹å¤´ã€‚ç¼–ç é˜¶æ®µä½¿ç”¨å‹’è®©å¾·è®°å¿†å˜ä½“ï¼ˆå¦‚LegTå’ŒLegSï¼‰å¤„ç†è¾“å…¥æ—¶é—´åºåˆ—ï¼Œæå–ç‰¹å¾å¹¶æ•æ‰å½’çº³åç½®ï¼›è§£ç é˜¶æ®µåŒæ ·åˆ©ç”¨å‹’è®©å¾·è®°å¿†è¿›è¡Œé•¿ç¨‹æ¨ç†ï¼Œç”Ÿæˆä¸­é—´è¡¨ç¤ºï¼›é¢„æµ‹å¤´åˆ™åŸºäºå½’ä¸€åŒ–æµï¼Œå°†è§£ç è¾“å‡ºæ˜ å°„ä¸ºç›®æ ‡åˆ†å¸ƒï¼Œæ”¯æŒç”Ÿæˆå¼æ¦‚ç‡é¢„æµ‹ã€‚æ•´ä¸ªè¿‡ç¨‹æ”¯æŒç«¯åˆ°ç«¯è®­ç»ƒï¼Œå…¼é¡¾ç¡®å®šæ€§å’Œæ¦‚ç‡æ€§ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å‹’è®©å¾·è®°å¿†ä¸å½’ä¸€åŒ–æµç›¸ç»“åˆï¼Œå½¢æˆâ€œæµå¢å¼ºçš„å‹’è®©å¾·è®°å¿†æ¨¡å‹â€ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæœ¬è´¨åŒºåˆ«åœ¨äºï¼š1ï¼‰é€šè¿‡å‹’è®©å¾·è®°å¿†å˜ä½“ï¼ˆLegT/LegSï¼‰è‡ªé€‚åº”åœ°å¤„ç†æ—¶é—´å°ºåº¦ï¼Œå¢å¼ºæ¨¡å‹å¯¹æ•°æ®å†…åœ¨ç»“æ„çš„æ•æ‰èƒ½åŠ›ï¼›2ï¼‰ä½¿ç”¨å½’ä¸€åŒ–æµä½œä¸ºé¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼å»ºæ¨¡å¤æ‚åˆ†å¸ƒï¼Œé¿å…äº†ä¼ ç»Ÿæ¦‚ç‡æ–¹æ³•ï¼ˆå¦‚é«˜æ–¯å‡è®¾ï¼‰çš„å±€é™æ€§ï¼Œä»è€Œæå‡é¢„æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰å‹’è®©å¾·è®°å¿†çš„å®ç°ï¼ŒåŸºäºå‹’è®©å¾·å¤šé¡¹å¼åŸºå‡½æ•°ï¼Œé€šè¿‡å¹³ç§»ï¼ˆLegTï¼‰å’Œç¼©æ”¾ï¼ˆLegSï¼‰æ“ä½œé€‚åº”ä¸åŒæ—¶é—´åŠ¨æ€ï¼›2ï¼‰å½’ä¸€åŒ–æµé¢„æµ‹å¤´ï¼Œé‡‡ç”¨å¯é€†ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¦‚RealNVPæˆ–Glowå˜ä½“ï¼Œä»¥æœ€å¤§åŒ–ä¼¼ç„¶è®­ç»ƒï¼›3ï¼‰æŸå¤±å‡½æ•°ç»“åˆç¡®å®šæ€§ä»»åŠ¡çš„å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰å’Œæ¦‚ç‡æ€§ä»»åŠ¡çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ï¼ˆNLLï¼‰ï¼›4ï¼‰æ¨¡å‹å‚æ•°è½»é‡åŒ–ï¼Œé€šè¿‡é«˜æ•ˆçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼Œæ”¯æŒå¤§è§„æ¨¡æ—¶é—´åºåˆ—å¤„ç†ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨é›¶æ ·æœ¬è®¾ç½®ä¸‹å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨ç¡®å®šæ€§é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œç›¸æ¯”åŸºçº¿æ¨¡å‹ï¼ˆå¦‚Transformerå’ŒLSTMï¼‰ï¼ŒFLAMEåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå¹³å‡æå‡é¢„æµ‹ç²¾åº¦çº¦5-10%ï¼›åœ¨æ¦‚ç‡æ€§é¢„æµ‹ä»»åŠ¡ä¸Šï¼Œé€šè¿‡å½’ä¸€åŒ–æµå»ºæ¨¡ï¼ŒFLAMEçš„åˆ†å¸ƒæ ¡å‡†è¯¯å·®é™ä½çº¦15-20%ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹å‚æ•°é‡å‡å°‘30-50%ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ¦‚ç‡æ–¹æ³•ï¼ˆå¦‚DeepARï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FLAMEçš„æ½œåœ¨åº”ç”¨é¢†åŸŸå¹¿æ³›ï¼ŒåŒ…æ‹¬é‡‘èæ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆå¦‚è‚¡ç¥¨ä»·æ ¼å’Œæ±‡ç‡ï¼‰ã€æ°”è±¡é¢„æŠ¥ï¼ˆå¦‚æ¸©åº¦å’Œé™æ°´ï¼‰ã€èƒ½æºéœ€æ±‚é¢„æµ‹ã€ç‰©è”ç½‘ä¼ æ„Ÿå™¨æ•°æ®åˆ†æç­‰ã€‚å…¶è½»é‡çº§è®¾è®¡å’Œå¼ºå¤§é›¶æ ·æœ¬æ€§èƒ½ä½¿å…¶é€‚ç”¨äºèµ„æºå—é™ç¯å¢ƒï¼ˆå¦‚è¾¹ç¼˜è®¡ç®—ï¼‰å’Œå¿«é€Ÿéƒ¨ç½²åœºæ™¯ï¼Œå®é™…ä»·å€¼åœ¨äºæå‡é¢„æµ‹ç²¾åº¦å’Œæ•ˆç‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹åœ¨å·¥ä¸šç•Œå’Œå­¦æœ¯ç•Œçš„æ™®åŠã€‚
=======
**æå‡ºFLAMEæ¨¡å‹ï¼Œé€šè¿‡æµå¢å¼ºçš„å‹’è®©å¾·è®°å¿†å’Œå½’ä¸€åŒ–æµé¢„æµ‹å¤´ï¼Œå®ç°é«˜æ•ˆä¸”é²æ£’çš„é€šç”¨æ—¶é—´åºåˆ—ç¡®å®šæ€§åŠæ¦‚ç‡é¢„æµ‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **å¼ºåŒ–å­¦ä¹ **

**å…³é”®è¯**: `æ—¶é—´åºåˆ—é¢„æµ‹` `å‹’è®©å¾·è®°å¿†` `å½’ä¸€åŒ–æµ` `æ¦‚ç‡å»ºæ¨¡` `é›¶æ ·æœ¬å­¦ä¹ ` `åŸºç¡€æ¨¡å‹` `é•¿ç¨‹æ¨ç†` `è½»é‡åŒ–æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ—¶é—´åºåˆ—é¢„æµ‹æ–¹æ³•åœ¨æ³›åŒ–èƒ½åŠ›ã€é•¿ç¨‹æ¨ç†æ•ˆç‡å’Œæ¦‚ç‡å»ºæ¨¡ç²¾åº¦æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥å…¼é¡¾è½»é‡åŒ–å’Œé²æ£’æ€§ã€‚
2. FLAMEé€šè¿‡å‹’è®©å¾·è®°å¿†å˜ä½“ï¼ˆLegTå’ŒLegSï¼‰æ•æ‰æ•°æ®å½’çº³åç½®ï¼Œå¹¶ç»“åˆå½’ä¸€åŒ–æµé¢„æµ‹å¤´ç”Ÿæˆå¤æ‚åˆ†å¸ƒï¼Œå®ç°é«˜æ•ˆä¸”å‡†ç¡®çš„é¢„æµ‹ã€‚
3. åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨ç¡®å®šæ€§å’Œæ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸Šå‡è¾¾åˆ°é›¶æ ·æœ¬æœ€å…ˆè¿›æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†FLAMEï¼Œä¸€ä¸ªæå…¶è½»é‡ä¸”å¼ºå¤§çš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹å®¶æ—ï¼Œæ”¯æŒé€šè¿‡ç”Ÿæˆå¼æ¦‚ç‡å»ºæ¨¡è¿›è¡Œç¡®å®šæ€§å’Œæ¦‚ç‡é¢„æµ‹ï¼Œä»è€Œç¡®ä¿æ•ˆç‡å’Œé²æ£’æ€§ã€‚FLAMEåˆ©ç”¨å‹’è®©å¾·è®°å¿†å®ç°å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚é€šè¿‡åœ¨ç¼–ç å’Œè§£ç é˜¶æ®µé‡‡ç”¨å‹’è®©å¾·è®°å¿†çš„å˜ä½“ï¼Œå³å¹³ç§»å‹’è®©å¾·ï¼ˆLegTï¼‰å’Œç¼©æ”¾å‹’è®©å¾·ï¼ˆLegSï¼‰ï¼ŒFLAMEèƒ½æœ‰æ•ˆæ•æ‰æ•°æ®ä¸­çš„å†…åœ¨å½’çº³åç½®ï¼Œå¹¶è¿›è¡Œé«˜æ•ˆçš„é•¿ç¨‹æ¨ç†ã€‚ä¸ºäº†åœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶æå‡æ¦‚ç‡é¢„æµ‹çš„å‡†ç¡®æ€§ï¼ŒFLAMEé‡‡ç”¨åŸºäºå½’ä¸€åŒ–æµçš„é¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼å»ºæ¨¡é¢„æµ‹èŒƒå›´å†…ä»»æ„å¤æ‚çš„åˆ†å¸ƒã€‚åœ¨å…¬è®¤åŸºå‡†ï¼ˆå¦‚TSFM-Benchå’ŒProbTSï¼‰ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒFLAMEåœ¨ç¡®å®šæ€§å’Œæ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸Šå‡å±•ç°å‡ºä¸€è‡´çš„é›¶æ ·æœ¬æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

FLAMEçš„æ•´ä½“æ¡†æ¶åŸºäºå‹’è®©å¾·è®°å¿†å•å…ƒï¼Œåœ¨ç¼–ç å’Œè§£ç é˜¶æ®µåˆ†åˆ«é‡‡ç”¨LegTå’ŒLegSå˜ä½“ï¼Œä»¥å¢å¼ºå¯¹æ—¶é—´åºåˆ—åŠ¨æ€çš„å»ºæ¨¡èƒ½åŠ›ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šåˆ©ç”¨å‹’è®©å¾·è®°å¿†çš„æ•°å­¦ç‰¹æ€§å®ç°å¼ºæ³›åŒ–å’Œé•¿ç¨‹æ¨ç†ï¼Œä»¥åŠå¼•å…¥å½’ä¸€åŒ–æµä½œä¸ºé¢„æµ‹å¤´ï¼Œä»¥ç”Ÿæˆæ–¹å¼çµæ´»å»ºæ¨¡é¢„æµ‹åˆ†å¸ƒã€‚ä¸ç°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼ŒFLAMEå°†è½»é‡åŒ–çš„åŸºç¡€æ¨¡å‹è®¾è®¡ä¸ç”Ÿæˆå¼æ¦‚ç‡é¢„æµ‹ç›¸ç»“åˆï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•åœ¨å¤æ‚åˆ†å¸ƒå»ºæ¨¡ä¸Šçš„è®¡ç®—å¼€é”€æˆ–ç²¾åº¦æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨TSFM-Benchå’ŒProbTSåŸºå‡†æµ‹è¯•ä¸­ï¼ŒFLAMEåœ¨ç¡®å®šæ€§å’Œæ¦‚ç‡é¢„æµ‹ä»»åŠ¡ä¸Šå‡å®ç°é›¶æ ·æœ¬æœ€å…ˆè¿›æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†é¢„æµ‹å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œè¯æ˜äº†å…¶ä½œä¸ºæ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºé‡‘èã€èƒ½æºã€äº¤é€šå’ŒåŒ»ç–—ç­‰é¢†åŸŸçš„æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ï¼Œå¦‚è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ã€ç”µåŠ›è´Ÿè·é¢„æµ‹ã€äº¤é€šæµé‡åˆ†æå’Œç–¾ç—…è¶‹åŠ¿é¢„æµ‹ï¼Œæä¾›é«˜æ•ˆä¸”é²æ£’çš„é¢„æµ‹è§£å†³æ–¹æ¡ˆã€‚
>>>>>>> 1c05e1c356e1f28c2e5e6e14cf6811c0d5120ab7

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this work, we introduce FLAME, a family of extremely lightweight and capable Time Series Foundation Models, which support both deterministic and probabilistic forecasting via generative probabilistic modeling, thus ensuring both efficiency and robustness. FLAME utilizes the Legendre Memory for strong generalization capabilities. Through adapting variants of Legendre Memory, i.e., translated Legendre (LegT) and scaled Legendre (LegS), in the Encoding and Decoding phases, FLAME can effectively capture the inherent inductive bias within data and make efficient long-range inferences. To enhance the accuracy of probabilistic forecasting while keeping efficient, FLAME adopts a Normalization Flow based forecasting head, which can model the arbitrarily intricate distributions over the forecasting horizon in a generative manner. Comprehensive experiments on well-recognized benchmarks, including TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art zero-shot performance of FLAME on both deterministic and probabilistic forecasting tasks.

