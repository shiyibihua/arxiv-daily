---
layout: default
title: Spherical Leech Quantization for Visual Tokenization and Generation
---

# Spherical Leech Quantization for Visual Tokenization and Generation

**arXiv**: [2512.14697v1](https://arxiv.org/abs/2512.14697) | [PDF](https://arxiv.org/pdf/2512.14697.pdf)

**ä½œè€…**: Yue Zhao, Hanwen Jiang, Zhenlin Xu, Chutong Yang, Ehsan Adeli, Philipp KrÃ¤henbÃ¼hl

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG, eess.SP

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: Tech report; project page: https://zhaoyue-zephyrus.github.io/npq/

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽLeechæ™¶æ ¼çš„çƒå½¢é‡åŒ–æ–¹æ³•ï¼Œä»¥æ”¹è¿›è§†è§‰æ ‡è®°åŒ–ä¸Žç”Ÿæˆä¸­çš„é‡å»º-åŽ‹ç¼©æƒè¡¡ã€‚**

**å…³é”®è¯**: `éžå‚æ•°é‡åŒ–` `æ™¶æ ¼ç¼–ç ` `Leechæ™¶æ ¼` `å›¾åƒæ ‡è®°åŒ–` `å›¾åƒåŽ‹ç¼©` `è‡ªå›žå½’ç”Ÿæˆ` `è§†è§‰é‡åŒ–` `é‡å»º-åŽ‹ç¼©æƒè¡¡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰éžå‚æ•°é‡åŒ–æ–¹æ³•ï¼ˆå¦‚BSQï¼‰åœ¨è®­ç»ƒè‡ªç¼–ç å™¨æ—¶éœ€è¾…åŠ©æŸå¤±é¡¹ï¼Œå¯¼è‡´æµç¨‹å¤æ‚ä¸”é‡å»º-åŽ‹ç¼©æƒè¡¡ä¸ä½³ã€‚
2. æå‡ºåŸºäºŽLeechæ™¶æ ¼çš„çƒå½¢é‡åŒ–ï¼ˆÎ›24-SQï¼‰ï¼Œåˆ©ç”¨å…¶é«˜å¯¹ç§°æ€§å’Œè¶…çƒé¢å‡åŒ€åˆ†å¸ƒç®€åŒ–è®­ç»ƒå¹¶ä¼˜åŒ–æ€§èƒ½ã€‚
3. åœ¨å›¾åƒæ ‡è®°åŒ–ã€åŽ‹ç¼©å’Œç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒÎ›24-SQåœ¨é‡å»ºè´¨é‡ä¸Šå…¨é¢è¶…è¶ŠBSQï¼ŒåŒæ—¶æ¯”ç‰¹æ¶ˆè€—æ›´ä½Žã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éžå‚æ•°é‡åŒ–å› å…¶å‚æ•°æ•ˆçŽ‡å’Œåœ¨å¤§ç æœ¬ä¸Šçš„å¯æ‰©å±•æ€§è€Œå¤‡å—å…³æ³¨ã€‚æœ¬æ–‡é€šè¿‡æ™¶æ ¼ç¼–ç çš„è§†è§’ï¼Œæå‡ºäº†ä¸åŒéžå‚æ•°é‡åŒ–æ–¹æ³•çš„ç»Ÿä¸€è¡¨è¿°ã€‚æ™¶æ ¼ç çš„å‡ ä½•ç»“æž„è§£é‡Šäº†åœ¨è®­ç»ƒè‡ªç¼–ç å™¨æ—¶ï¼Œå¯¹äºŽæŸäº›çŽ°æœ‰çš„æ— æŸ¥æ‰¾é‡åŒ–å˜ä½“ï¼ˆå¦‚BSQï¼‰éœ€è¦è¾…åŠ©æŸå¤±é¡¹çš„å¿…è¦æ€§ã€‚ä½œä¸ºè¿›ä¸€æ­¥æŽ¢ç´¢ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å‡ ç§å¯èƒ½çš„å€™é€‰æ–¹æ¡ˆï¼ŒåŒ…æ‹¬éšæœºæ™¶æ ¼ã€å¹¿ä¹‰æ–æ³¢é‚£å¥‘æ™¶æ ¼å’Œæœ€å¯†çƒå †ç§¯æ™¶æ ¼ã€‚å…¶ä¸­ï¼Œæˆ‘ä»¬å‘çŽ°åŸºäºŽLeechæ™¶æ ¼çš„é‡åŒ–æ–¹æ³•ï¼ˆç§°ä¸ºçƒå½¢Leeché‡åŒ–ï¼ŒÎ›24-SQï¼‰ç”±äºŽå…¶é«˜å¯¹ç§°æ€§å’Œè¶…çƒé¢ä¸Šçš„å‡åŒ€åˆ†å¸ƒï¼Œæ—¢èƒ½ç®€åŒ–è®­ç»ƒæµç¨‹ï¼Œåˆèƒ½æ”¹å–„é‡å»ºä¸ŽåŽ‹ç¼©ä¹‹é—´çš„æƒè¡¡ã€‚åœ¨å›¾åƒæ ‡è®°åŒ–å’ŒåŽ‹ç¼©ä»»åŠ¡ä¸­ï¼Œè¯¥é‡åŒ–æ–¹æ³•åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºŽå…ˆå‰æœ€ä½³æ–¹æ³•BSQï¼ŒåŒæ—¶æ¶ˆè€—çš„æ¯”ç‰¹æ•°ç•¥å°‘ã€‚è¿™ä¸€æ”¹è¿›ä¹Ÿå»¶ä¼¸åˆ°äº†æœ€å…ˆè¿›çš„è‡ªå›žå½’å›¾åƒç”Ÿæˆæ¡†æž¶ä¸­ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºä¸€ç§ç»Ÿä¸€çš„éžå‚æ•°é‡åŒ–æ¡†æž¶ï¼ŒåŸºäºŽæ™¶æ ¼ç¼–ç ç†è®ºã€‚æ ¸å¿ƒæ–¹æ³•æ˜¯çƒå½¢Leeché‡åŒ–ï¼ˆÎ›24-SQï¼‰ï¼Œå®ƒåˆ©ç”¨Leechæ™¶æ ¼ï¼ˆÎ›24ï¼‰çš„é«˜å¯¹ç§°æ€§å’Œåœ¨24ç»´è¶…çƒé¢ä¸Šçš„å‡åŒ€åˆ†å¸ƒç‰¹æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡æ™¶æ ¼ç‚¹ç›´æŽ¥é‡åŒ–ç‰¹å¾å‘é‡ï¼Œæ— éœ€å¤æ‚çš„æŸ¥æ‰¾æ“ä½œæˆ–è¾…åŠ©æŸå¤±ï¼Œç®€åŒ–äº†è‡ªç¼–ç å™¨çš„è®­ç»ƒæµç¨‹ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ï¼ˆå¦‚BSQï¼‰çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼šÎ›24-SQåŸºäºŽæ•°å­¦ä¸Šä¼˜åŒ–çš„æ™¶æ ¼ç»“æž„ï¼Œæä¾›äº†æ›´å‡åŒ€çš„é‡åŒ–ç‚¹åˆ†å¸ƒï¼Œä»Žè€Œåœ¨åŽ‹ç¼©æ•ˆçŽ‡å’Œé‡å»ºè´¨é‡ä¹‹é—´è¾¾åˆ°æ›´å¥½å¹³è¡¡ï¼Œé¿å…äº†è®­ç»ƒä¸­çš„ä¸ç¨³å®šæ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒæ˜¾ç¤ºï¼ŒÎ›24-SQåœ¨å›¾åƒæ ‡è®°åŒ–å’ŒåŽ‹ç¼©ä»»åŠ¡ä¸­ï¼Œæ‰€æœ‰é‡å»ºè´¨é‡æŒ‡æ ‡ï¼ˆå¦‚PSNRã€SSIMï¼‰å‡ä¼˜äºŽå…ˆå‰æœ€ä½³æ–¹æ³•BSQï¼ŒåŒæ—¶æ¯”ç‰¹çŽ‡ç•¥æœ‰é™ä½Žï¼›åœ¨è‡ªå›žå½’å›¾åƒç”Ÿæˆæ¡†æž¶ä¸­ä¹Ÿèƒ½å¸¦æ¥æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶ä¸»è¦åº”ç”¨äºŽè®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œç‰¹åˆ«æ˜¯å›¾åƒå’Œè§†é¢‘çš„åŽ‹ç¼©ã€æ ‡è®°åŒ–ä»¥åŠç”Ÿæˆä»»åŠ¡ã€‚æ½œåœ¨ä»·å€¼åŒ…æ‹¬æå‡å›¾åƒç¼–ç æ•ˆçŽ‡ã€æ”¯æŒé«˜è´¨é‡å›¾åƒç”Ÿæˆæ¨¡åž‹ï¼ˆå¦‚è‡ªå›žå½’æ¡†æž¶ï¼‰ï¼Œå¹¶å¯èƒ½æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€çš„æ•°æ®åŽ‹ç¼©å’Œç”Ÿæˆåœºæ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Non-parametric quantization has received much attention due to its efficiency on parameters and scalability to a large codebook. In this paper, we present a unified formulation of different non-parametric quantization methods through the lens of lattice coding. The geometry of lattice codes explains the necessity of auxiliary loss terms when training auto-encoders with certain existing lookup-free quantization variants such as BSQ. As a step forward, we explore a few possible candidates, including random lattices, generalized Fibonacci lattices, and densest sphere packing lattices. Among all, we find the Leech lattice-based quantization method, which is dubbed as Spherical Leech Quantization ($Î›_{24}$-SQ), leads to both a simplified training recipe and an improved reconstruction-compression tradeoff thanks to its high symmetry and even distribution on the hypersphere. In image tokenization and compression tasks, this quantization approach achieves better reconstruction quality across all metrics than BSQ, the best prior art, while consuming slightly fewer bits. The improvement also extends to state-of-the-art auto-regressive image generation frameworks.

