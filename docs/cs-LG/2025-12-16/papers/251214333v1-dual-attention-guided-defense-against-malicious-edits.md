---
layout: default
title: Dual Attention Guided Defense Against Malicious Edits
---

# Dual Attention Guided Defense Against Malicious Edits

**arXiv**: [2512.14333v1](https://arxiv.org/abs/2512.14333) | [PDF](https://arxiv.org/pdf/2512.14333.pdf)

**ä½œè€…**: Jie Zhang, Shuai Dong, Shiguang Shan, Xilin Chen

**åˆ†ç±»**: cs.CV, cs.AI, cs.CY, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 11 pages, 7 figures

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŒæ³¨æ„åŠ›å¼•å¯¼å™ªå£°æ‰°åŠ¨å…ç–«æ–¹æ³•ï¼Œä»¥é˜²å¾¡æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹ä¸­çš„æ¶æ„ç¼–è¾‘é£Žé™©ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹` `æ¶æ„ç¼–è¾‘é˜²å¾¡` `æ³¨æ„åŠ›æœºåˆ¶` `å™ªå£°æ‰°åŠ¨` `è¯­ä¹‰ç†è§£å¹²æ‰°` `å›¾åƒå®‰å…¨` `ä¼¦ç†æŒ‘æˆ˜` `åŠ¨æ€é˜ˆå€¼`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é˜²å¾¡æ–¹æ³•ä¾èµ–ä¸å¯æ„ŸçŸ¥æ‰°åŠ¨ï¼Œä½†å¯¹æŠ—æ¶æ„ç¯¡æ”¹æ•ˆæžœæœ‰é™ï¼Œé¢ä¸´è¯­ä¹‰ç†è§£å¹²æ‰°ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. æå‡ºDANPæ–¹æ³•ï¼Œé€šè¿‡åŠ¨æ€é˜ˆå€¼ç”ŸæˆæŽ©ç ï¼Œæ“çºµäº¤å‰æ³¨æ„åŠ›å’Œå™ªå£°é¢„æµ‹ï¼Œè¯¯å¯¼ç¼–è¾‘å¹¶ä¿æŠ¤ç›®æ ‡åŒºåŸŸã€‚
3. å®žéªŒæ˜¾ç¤ºDANPåœ¨é˜²å¾¡æ¶æ„ç¼–è¾‘æ–¹é¢è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œæœ‰æ•ˆæå‡å…ç–«åŠ›å’Œç”Ÿæˆå¹²æ‰°èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹çš„è¿›å±•é€šè¿‡æ–‡æœ¬æç¤ºæ”¹å˜äº†å›¾åƒç¼–è¾‘æ–¹å¼ï¼Œä½†ä¹Ÿå¸¦æ¥äº†å› æ½œåœ¨æ»¥ç”¨åˆ›å»ºæ¬ºéª—æ€§æˆ–æœ‰å®³å†…å®¹è€Œå¼•å‘çš„é‡å¤§ä¼¦ç†æŒ‘æˆ˜ã€‚çŽ°æœ‰é˜²å¾¡æ–¹æ³•è¯•å›¾é€šè¿‡åµŒå…¥ä¸å¯æ„ŸçŸ¥çš„æ‰°åŠ¨æ¥é™ä½Žé£Žé™©ï¼Œä½†å…¶åœ¨å¯¹æŠ—æ¶æ„ç¯¡æ”¹æ–¹é¢çš„æœ‰æ•ˆæ€§æœ‰é™ã€‚ä¸ºè§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŒæ³¨æ„åŠ›å¼•å¯¼å™ªå£°æ‰°åŠ¨å…ç–«æ–¹æ³•ï¼Œè¯¥æ–¹æ³•æ·»åŠ ä¸å¯æ„ŸçŸ¥çš„æ‰°åŠ¨ä»¥ç ´åæ¨¡åž‹çš„è¯­ä¹‰ç†è§£å’Œç”Ÿæˆè¿‡ç¨‹ã€‚DANPåœ¨å¤šä¸ªæ—¶é—´æ­¥ä¸Šæ“ä½œï¼Œé€šè¿‡åŠ¨æ€é˜ˆå€¼ç”ŸæˆæŽ©ç æ¥è¯†åˆ«æ–‡æœ¬ç›¸å…³å’Œä¸ç›¸å…³åŒºåŸŸï¼Œä»Žè€Œæ“çºµäº¤å‰æ³¨æ„åŠ›å›¾å’Œå™ªå£°é¢„æµ‹è¿‡ç¨‹ã€‚å®ƒå‡å°‘ç›¸å…³åŒºåŸŸçš„æ³¨æ„åŠ›ï¼ŒåŒæ—¶å¢žåŠ ä¸ç›¸å…³åŒºåŸŸçš„æ³¨æ„åŠ›ï¼Œä»Žè€Œè¯¯å¯¼ç¼–è¾‘æœå‘é”™è¯¯åŒºåŸŸå¹¶ä¿æŠ¤ç›®æ ‡å†…å®¹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æœ€å¤§åŒ–æ³¨å…¥å™ªå£°ä¸Žæ¨¡åž‹é¢„æµ‹å™ªå£°ä¹‹é—´çš„å·®å¼‚ï¼Œä»¥è¿›ä¸€æ­¥å¹²æ‰°ç”Ÿæˆã€‚é€šè¿‡åŒæ—¶é’ˆå¯¹æ³¨æ„åŠ›å’Œå™ªå£°é¢„æµ‹æœºåˆ¶ï¼ŒDANPå±•çŽ°å‡ºå¯¹æ¶æ„ç¼–è¾‘çš„æ˜¾è‘—å…ç–«åŠ›ï¼Œå¤§é‡å®žéªŒè¯å®žæˆ‘ä»¬çš„æ–¹æ³•å®žçŽ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

DANPçš„æ•´ä½“æ¡†æž¶åŸºäºŽæ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡åž‹ï¼Œåœ¨å¤šä¸ªæ—¶é—´æ­¥ä¸Šæ·»åŠ ä¸å¯æ„ŸçŸ¥å™ªå£°æ‰°åŠ¨ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°åŒ…æ‹¬ï¼šä½¿ç”¨åŠ¨æ€é˜ˆå€¼ç”ŸæˆæŽ©ç æ¥åŒºåˆ†æ–‡æœ¬ç›¸å…³å’Œä¸ç›¸å…³åŒºåŸŸï¼Œä»Žè€Œç²¾ç¡®æ“çºµäº¤å‰æ³¨æ„åŠ›å›¾ï¼›åŒæ—¶ï¼Œé€šè¿‡æœ€å¤§åŒ–æ³¨å…¥å™ªå£°ä¸Žæ¨¡åž‹é¢„æµ‹å™ªå£°çš„å·®å¼‚ï¼Œå¹²æ‰°å™ªå£°é¢„æµ‹è¿‡ç¨‹ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒDANPåŒæ—¶é’ˆå¯¹æ³¨æ„åŠ›å’Œå™ªå£°é¢„æµ‹ä¸¤ä¸ªæ ¸å¿ƒæœºåˆ¶ï¼Œå®žçŽ°æ›´å…¨é¢çš„é˜²å¾¡ï¼Œè€Œä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä»…å…³æ³¨å•ä¸€æ‰°åŠ¨æˆ–é™æ€ç­–ç•¥ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

DANPåœ¨é˜²å¾¡æ¶æ„ç¼–è¾‘æ–¹é¢å®žçŽ°æœ€å…ˆè¿›æ€§èƒ½ï¼Œé€šè¿‡åŒæ³¨æ„åŠ›å¼•å¯¼å’Œå™ªå£°æ‰°åŠ¨ï¼Œæ˜¾è‘—æå‡å…ç–«åŠ›ï¼Œå®žéªŒè¯å®žå…¶æœ‰æ•ˆè¯¯å¯¼ç¼–è¾‘å¹¶ä¿æŠ¤ç›®æ ‡ï¼Œæ€§èƒ½ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå›¾åƒå®‰å…¨é¢†åŸŸï¼Œå¦‚é˜²æ­¢æ¶æ„ç¼–è¾‘ç”¨äºŽè™šå‡æ–°é—»ã€æ·±åº¦ä¼ªé€ æˆ–æœ‰å®³å†…å®¹ç”Ÿæˆï¼Œæå‡æ•°å­—åª’ä½“çš„å¯ä¿¡åº¦å’Œä¼¦ç†åˆè§„æ€§ï¼Œå…·æœ‰å®žé™…ä»·å€¼äºŽç¤¾äº¤åª’ä½“ã€æ–°é—»å®¡æ ¸å’Œå†…å®¹åˆ›ä½œå¹³å°ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent progress in text-to-image diffusion models has transformed image editing via text prompts, yet this also introduces significant ethical challenges from potential misuse in creating deceptive or harmful content. While current defenses seek to mitigate this risk by embedding imperceptible perturbations, their effectiveness is limited against malicious tampering. To address this issue, we propose a Dual Attention-Guided Noise Perturbation (DANP) immunization method that adds imperceptible perturbations to disrupt the model's semantic understanding and generation process. DANP functions over multiple timesteps to manipulate both cross-attention maps and the noise prediction process, using a dynamic threshold to generate masks that identify text-relevant and irrelevant regions. It then reduces attention in relevant areas while increasing it in irrelevant ones, thereby misguides the edit towards incorrect regions and preserves the intended targets. Additionally, our method maximizes the discrepancy between the injected noise and the model's predicted noise to further interfere with the generation. By targeting both attention and noise prediction mechanisms, DANP exhibits impressive immunity against malicious edits, and extensive experiments confirm that our method achieves state-of-the-art performance.

