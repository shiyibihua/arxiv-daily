---
layout: default
title: Estimating problem difficulty without ground truth using Large Language Model comparisons
---

# Estimating problem difficulty without ground truth using Large Language Model comparisons

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14220v1</a>
  <a href="https://arxiv.org/pdf/2512.14220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14220v1" onclick="toggleFavorite(this, '2512.14220v1', 'Estimating problem difficulty without ground truth using Large Language Model comparisons')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Marthe Ballon, Andres Algaba, Brecht Verbeken, Vincent Ginis

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

**å¤‡æ³¨**: 19 pages, 10 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLM compareï¼Œä¸€ç§æ— éœ€ground truthçš„å¤§è¯­è¨€æ¨¡å‹é—®é¢˜éš¾åº¦è¯„ä¼°æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é—®é¢˜éš¾åº¦è¯„ä¼°` `å¤§è¯­è¨€æ¨¡å‹` `æ— ç›‘ç£å­¦ä¹ ` `Bradley-Terryæ¨¡å‹` `åˆæˆæ•°æ®ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é—®é¢˜éš¾åº¦è¯„ä¼°æ–¹æ³•ä¾èµ–äººå·¥æ ‡æ³¨æˆ–æ¨¡å‹æ€§èƒ½ï¼Œéš¾ä»¥æ³›åŒ–åˆ°è¶…å‡ºåˆ†å¸ƒçš„ã€å¯¹äººç±»å’ŒLLMéƒ½å›°éš¾çš„é—®é¢˜ã€‚
2. LLM compareé€šè¿‡è®©LLMè¿›è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œå¹¶è®¡ç®—Bradley-Terryåˆ†æ•°ï¼Œå®ç°æ— éœ€ground truthçš„éš¾åº¦è¯„ä¼°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒLLM compareä¸äººç±»æ ‡æ³¨é«˜åº¦ä¸€è‡´ï¼ˆPearson r â‰¥ 0.80ï¼‰ï¼Œä¸”å¯¹å™ªå£°å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„é—®é¢˜éš¾åº¦è¯„ä¼°æ–¹æ³•ï¼Œåä¸ºLLM compareï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å¤–æ¨é—®é¢˜ä¸Šçš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•å¦‚äººå·¥æ ¡å‡†æˆ–åŸºäºæ€§èƒ½çš„è¯„åˆ†ï¼Œæ— æ³•æ¨å¹¿åˆ°è¶…å‡ºåˆ†å¸ƒçš„é—®é¢˜ï¼Œå› ä¸ºå®ƒä»¬ä¸å…·å¤‡å¯æ‰©å±•æ€§ã€è€—æ—¶ä¸”ä¾èµ–äºground truthã€‚LLM compareé€šè¿‡è®©å¤§è¯­è¨€æ¨¡å‹æ‰§è¡Œæˆå¯¹éš¾åº¦æ¯”è¾ƒï¼Œç„¶ååŸºäºæ¯”è¾ƒç»“æœè®¡ç®—Bradley-Terryåˆ†æ•°æ¥å…‹æœè¿™äº›é™åˆ¶ã€‚ä¸ºäº†éªŒè¯è¯¥æ–¹æ³•ï¼Œé¦–å…ˆæå‡ºäº†ä¸€ä¸ªæ¦‚å¿µæ¡†æ¶ï¼Œå°†ç°æœ‰æ–¹æ³•å®šä½åœ¨ä¸‰ä¸ªæ­£äº¤å¹³é¢ä¸Šâ€”â€”æ„é€ ã€è§„æ¨¡å’Œä¾èµ–æ€§ã€‚LLM compareè‡ªç„¶åœ°å æ®äº†æ‰€æœ‰ç†æƒ³è±¡é™ï¼Œæ˜¯ç¬¬ä¸€ä¸ªè¿ç»­åŠ¨æ€ã€æ¨¡å‹æ— å…³ä¸”ç‹¬ç«‹äºground truthä¿¡æ¯çš„åº¦é‡ã€‚å…¶æ¬¡ï¼Œå®éªŒè¡¨æ˜LLM compareä¸äººç±»æ ‡æ³¨å…·æœ‰å¾ˆå¼ºçš„ä¸€è‡´æ€§ï¼ˆPearson r â‰¥ 0.80ï¼Œn=1876ï¼‰ã€‚ç¬¬ä¸‰ï¼ŒLLM compareå¯¹å¹»è§‰å…·æœ‰é²æ£’æ€§ï¼Œæ³¨å…¥10%çš„å™ªå£°åï¼ŒPearsonç›¸å…³æ€§ä»…ä¸‹é™ä¸åˆ°6%ã€‚è¿™é¡¹å·¥ä½œä»£è¡¨ç€åœ¨æ›¿ä»£è€—æ—¶çš„äººå·¥æ ‡æ³¨å’Œåˆæˆæ•°æ®ç”Ÿæˆæ–¹é¢è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ï¼Œå¹¶å°†æˆä¸ºè¯¾ç¨‹è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’ŒAIè¾…åŠ©ç ”ç©¶æ„æ€çš„é‡è¦é©±åŠ¨åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰é—®é¢˜éš¾åº¦è¯„ä¼°æ–¹æ³•æ— æ³•æœ‰æ•ˆè¯„ä¼°è¶…å‡ºåˆ†å¸ƒï¼ˆout-of-distributionï¼‰é—®é¢˜éš¾åº¦çš„éš¾é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚äººå·¥æ ¡å‡†å’ŒåŸºäºæ€§èƒ½çš„è¯„åˆ†ï¼Œä¾èµ–äºäººå·¥æ ‡æ³¨æˆ–æ¨¡å‹åœ¨å·²çŸ¥é—®é¢˜ä¸Šçš„è¡¨ç°ï¼Œå› æ­¤æ— æ³•æ¨å¹¿åˆ°é‚£äº›äººç±»å’ŒLLMéƒ½éš¾ä»¥è§£å†³çš„æ–°é—®é¢˜ã€‚è¿™äº›æ–¹æ³•é€šå¸¸è€—æ—¶ã€æˆæœ¬é«˜æ˜‚ï¼Œå¹¶ä¸”éœ€è¦ground truthä¿¡æ¯ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨å¿«é€Ÿè¿­ä»£å’Œæ¢ç´¢æœªçŸ¥é¢†åŸŸçš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è‡ªèº«çš„ç†è§£èƒ½åŠ›æ¥è¯„ä¼°é—®é¢˜çš„ç›¸å¯¹éš¾åº¦ï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨çš„ground truthã€‚é€šè¿‡è®©LLMå¯¹é—®é¢˜è¿›è¡Œæˆå¯¹æ¯”è¾ƒï¼Œåˆ¤æ–­å“ªä¸ªé—®é¢˜æ›´éš¾ï¼Œç„¶ååŸºäºè¿™äº›æ¯”è¾ƒç»“æœï¼Œä½¿ç”¨Bradley-Terryæ¨¡å‹è®¡ç®—æ¯ä¸ªé—®é¢˜çš„éš¾åº¦å¾—åˆ†ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨LLMä½œä¸ºä¸€ç§â€œå†…éƒ¨è¯„ä¼°å™¨â€ï¼Œä»è€Œé¿å…äº†å¯¹å¤–éƒ¨æ ‡æ³¨çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLLM compareæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **é—®é¢˜å¯¹ç”Ÿæˆ**ï¼šä»é—®é¢˜é›†ä¸­éšæœºæŠ½å–é—®é¢˜å¯¹ã€‚
2. **LLMæ¯”è¾ƒ**ï¼šä½¿ç”¨LLMå¯¹æ¯ä¸ªé—®é¢˜å¯¹è¿›è¡Œéš¾åº¦æ¯”è¾ƒï¼Œåˆ¤æ–­å“ªä¸ªé—®é¢˜æ›´éš¾ã€‚
3. **Bradley-Terryè¯„åˆ†**ï¼šåŸºäºLLMçš„æ¯”è¾ƒç»“æœï¼Œä½¿ç”¨Bradley-Terryæ¨¡å‹è®¡ç®—æ¯ä¸ªé—®é¢˜çš„éš¾åº¦å¾—åˆ†ã€‚Bradley-Terryæ¨¡å‹æ˜¯ä¸€ç§ç”¨äºæˆå¯¹æ¯”è¾ƒæ•°æ®çš„ç»Ÿè®¡æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®æ¯”è¾ƒç»“æœä¼°è®¡æ¯ä¸ªå¯¹è±¡çš„ç›¸å¯¹å¼ºåº¦æˆ–éš¾åº¦ã€‚
4. **éš¾åº¦æ’åº**ï¼šæ ¹æ®Bradley-Terryå¾—åˆ†å¯¹é—®é¢˜è¿›è¡Œéš¾åº¦æ’åºã€‚

**å…³é”®åˆ›æ–°**ï¼šLLM compareæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå®ƒæ˜¯ä¸€ç§æ— éœ€ground truthçš„éš¾åº¦è¯„ä¼°æ–¹æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå®ƒå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š
* **è¿ç»­åŠ¨æ€**ï¼šå¯ä»¥å¯¹æ–°é—®é¢˜è¿›è¡Œè¯„ä¼°ï¼Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–æ ‡æ³¨ã€‚
* **æ¨¡å‹æ— å…³**ï¼šå¯ä»¥ä½¿ç”¨ä¸åŒçš„LLMè¿›è¡Œæ¯”è¾ƒï¼Œå…·æœ‰è¾ƒå¼ºçš„é€šç”¨æ€§ã€‚
* **ç‹¬ç«‹äºground truth**ï¼šæ— éœ€äººå·¥æ ‡æ³¨æˆ–å·²çŸ¥é—®é¢˜çš„æ€§èƒ½æ•°æ®ã€‚

**å…³é”®è®¾è®¡**ï¼š
* **LLMé€‰æ‹©**ï¼šè®ºæ–‡ä¸­ä½¿ç”¨äº†ç‰¹å®šçš„å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå®éªŒï¼Œä½†è¯¥æ–¹æ³•ç†è®ºä¸Šå¯ä»¥ä¸ä»»ä½•å…·æœ‰è¶³å¤Ÿç†è§£èƒ½åŠ›çš„LLMä¸€èµ·ä½¿ç”¨ã€‚LLMçš„é€‰æ‹©å¯èƒ½ä¼šå½±å“è¯„ä¼°ç»“æœçš„å‡†ç¡®æ€§ã€‚
* **æ¯”è¾ƒæç¤ºè¯è®¾è®¡**ï¼šç”¨äºå¼•å¯¼LLMè¿›è¡Œéš¾åº¦æ¯”è¾ƒçš„æç¤ºè¯çš„è®¾è®¡è‡³å…³é‡è¦ã€‚æç¤ºè¯éœ€è¦æ¸…æ™°æ˜ç¡®ï¼Œé¿å…å¼•å…¥åå·®ã€‚
* **Bradley-Terryæ¨¡å‹å‚æ•°**ï¼šBradley-Terryæ¨¡å‹çš„å‚æ•°è®¾ç½®å¯èƒ½ä¼šå½±å“éš¾åº¦å¾—åˆ†çš„è®¡ç®—ç»“æœã€‚è®ºæ–‡ä¸­å¯èƒ½ä½¿ç”¨äº†é»˜è®¤å‚æ•°æˆ–ç»è¿‡è°ƒæ•´çš„å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM compareä¸äººç±»æ ‡æ³¨å…·æœ‰é«˜åº¦ä¸€è‡´æ€§ï¼ŒPearsonç›¸å…³ç³»æ•°è¾¾åˆ°0.80ä»¥ä¸Šï¼ˆn=1876ï¼‰ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¯¹LLMçš„å¹»è§‰å…·æœ‰è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œå³ä½¿åœ¨æ³¨å…¥10%çš„å™ªå£°åï¼ŒPearsonç›¸å…³ç³»æ•°çš„ä¸‹é™ä¹Ÿå°äº6%ã€‚è¿™äº›ç»“æœéªŒè¯äº†LLM compareçš„æœ‰æ•ˆæ€§å’Œå¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LLM compareå¯åº”ç”¨äºåˆæˆæ•°æ®ç”Ÿæˆã€è¯¾ç¨‹å­¦ä¹ è®¾è®¡ã€æ¨¡å‹è¯„ä¼°å’ŒAIè¾…åŠ©ç ”ç©¶æ„æ€ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥å¸®åŠ©è‡ªåŠ¨ç”Ÿæˆæ›´å…·æŒ‘æˆ˜æ€§çš„è®­ç»ƒæ•°æ®ï¼Œè®¾è®¡æ›´æœ‰æ•ˆçš„å­¦ä¹ è¯¾ç¨‹ï¼Œè¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶è¾…åŠ©ç ”ç©¶äººå‘˜æ¢ç´¢æ–°çš„ç ”ç©¶æ–¹å‘ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºé‚£äº›ç¼ºä¹ground truthæˆ–éš¾ä»¥è¿›è¡Œäººå·¥æ ‡æ³¨çš„é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in the finetuning of large language models (LLMs) have significantly improved their performance on established benchmarks, emphasizing the need for increasingly difficult, synthetic data. A key step in this data generation pipeline is a method for estimating problem difficulty. Current approaches, such as human calibration or performance-based scoring, fail to generalize to out-of-distribution problems, i.e. problems currently unsolvable by humans and LLMs, because they are not scalable, time-consuming, and ground truth dependent. Therefore, we propose a new method for estimating problem difficulty, LLM compare, that addresses these limitations. An LLM performs pairwise difficulty comparisons, and then Bradley-Terry scores are computed based on the outcomes. To validate our method, we first propose a conceptual framework that positions existing approaches on three orthogonal planes--construction, scale and dependence--identifying which quadrants a measure needs to occupy to score out-of-distribution problems. LLM compare naturally occupies all desirable quadrants as the first measure that is continuous and dynamic, model-agnostic and independent of ground truth information. As a second validation, we show that LLM compare demonstrates strong alignment with human annotations: Pearson $r \geq 0.80$ for $n=1876$. Thirdly, we show that LLM compare is robust to hallucinations, with less than $6\%$ degradation in Pearson correlation for $10\%$ noise injection. Our work represents a significant step towards replacing time-consuming human annotations and synthetic data generation, and will be an important driver for curriculum design, model evaluation, and AI-assisted research ideation.

