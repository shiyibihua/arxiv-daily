---
layout: default
title: Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting
---

# Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting

**arXiv**: [2512.14115v1](https://arxiv.org/abs/2512.14115) | [PDF](https://arxiv.org/pdf/2512.14115.pdf)

**ä½œè€…**: Ramesh Gundluru, Shubham Gupta, Sri Rama Murty K

**åˆ†ç±»**: cs.SD, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æž¶ï¼Œä»¥è§£å†³å£°å­¦è¯åµŒå…¥åœ¨è¯­éŸ³æ£€ç´¢ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œæå‡å£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«çš„é²æ£’æ€§ã€‚**

**å…³é”®è¯**: `å£°å­¦è¯åµŒå…¥` `å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ` `å£è¯­è¯æ£€æµ‹` `å…³é”®è¯è¯†åˆ«` `éŸ³é¢‘-æ–‡æœ¬å¯¹é½` `è¯­éŸ³æ£€ç´¢` `è”åˆä¼˜åŒ–` `å…±äº«åµŒå…¥ç©ºé—´`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰å£°å­¦è¯åµŒå…¥æ–¹æ³•ä¾èµ–å•æ¨¡æ€ç›‘ç£ï¼ŒéŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½ä¼˜åŒ–åˆ†ç¦»ï¼Œå¯¼è‡´æ¨¡åž‹æ³›åŒ–èƒ½åŠ›å—é™ã€‚
2. æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æž¶ï¼Œç»Ÿä¸€éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘ç›‘ç£ï¼Œåœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­è¿›è¡Œç«¯åˆ°ç«¯ä¼˜åŒ–ã€‚
3. åœ¨è¯åˆ¤åˆ«ä»»åŠ¡ä¸Šè¶…è¶ŠåŸºçº¿ï¼ŒåŒæ—¶æ”¯æŒå£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„é²æ£’æ€§å’Œçµæ´»æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å£°å­¦è¯åµŒå…¥ï¼ˆAWEsï¼‰æé«˜äº†è¯­éŸ³æ£€ç´¢ä»»åŠ¡ï¼ˆå¦‚å£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«ï¼‰çš„æ•ˆçŽ‡ã€‚ç„¶è€Œï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨å±€é™æ€§ï¼ŒåŒ…æ‹¬å•æ¨¡æ€ç›‘ç£ã€éŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½çš„åˆ†ç¦»ä¼˜åŒ–ï¼Œä»¥åŠéœ€è¦ä»»åŠ¡ç‰¹å®šæ¨¡åž‹ã€‚ä¸ºè§£å†³è¿™äº›ä¸è¶³ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æž¶ï¼Œåœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­ç»Ÿä¸€äº†å£°å­¦å’Œè·¨æ¨¡æ€ç›‘ç£ã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒæ—¶ä¼˜åŒ–ï¼šï¼ˆiï¼‰éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ï¼Œå—CLAPæŸå¤±å¯å‘ï¼Œä»¥å¯¹é½éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºï¼›ï¼ˆiiï¼‰éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡æ·±åº¦è¯åˆ¤åˆ«æŸå¤±ï¼Œä»¥å¢žå¼ºç±»å†…ç´§å‡‘æ€§å’Œç±»é—´åˆ†ç¦»æ€§ã€‚æ‰€ææ–¹æ³•åœ¨è¯åˆ¤åˆ«ä»»åŠ¡ä¸Šä¼˜äºŽçŽ°æœ‰AWEåŸºçº¿ï¼ŒåŒæ—¶çµæ´»æ”¯æŒå£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªæ­¤ç±»ç»¼åˆæ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºä¸€ä¸ªè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æž¶ï¼Œæ•´ä½“æž¶æž„åŒ…æ‹¬éŸ³é¢‘ç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨ï¼Œç”Ÿæˆå…±äº«åµŒå…¥ç©ºé—´ä¸­çš„è¡¨ç¤ºã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽåŒæ—¶åº”ç”¨éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ï¼ˆåŸºäºŽCLAPæŸå¤±ï¼‰å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ï¼ˆåŸºäºŽæ·±åº¦è¯åˆ¤åˆ«æŸå¤±ï¼‰ï¼Œä»¥ç»Ÿä¸€ä¼˜åŒ–è·¨æ¨¡æ€å¯¹é½å’Œå£°å­¦åˆ¤åˆ«æ€§ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽé¿å…äº†åˆ†ç¦»ä¼˜åŒ–ï¼Œé€šè¿‡ç«¯åˆ°ç«¯è®­ç»ƒæ•´åˆå¤šæ¨¡æ€ç›‘ç£ï¼Œä»Žè€Œæå‡æ¨¡åž‹åœ¨è¯­éŸ³æ£€ç´¢ä»»åŠ¡ä¸­çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨è¯åˆ¤åˆ«ä»»åŠ¡ä¸Šï¼Œæ‰€ææ–¹æ³•ä¼˜äºŽçŽ°æœ‰å£°å­¦è¯åµŒå…¥åŸºçº¿ï¼ŒåŒæ—¶çµæ´»æ”¯æŒå£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«ï¼Œå±•ç¤ºäº†å¤šæ¨¡æ€è”åˆä¼˜åŒ–çš„æœ‰æ•ˆæ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽè¯­éŸ³æ£€ç´¢ç³»ç»Ÿï¼Œå¦‚å£è¯­è¯æ£€æµ‹å’Œå…³é”®è¯è¯†åˆ«ï¼Œé€‚ç”¨äºŽæ™ºèƒ½åŠ©æ‰‹ã€è¯­éŸ³æœç´¢å’ŒéŸ³é¢‘å†…å®¹åˆ†æžç­‰é¢†åŸŸï¼Œæé«˜æ£€ç´¢æ•ˆçŽ‡å’Œå‡†ç¡®æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.

