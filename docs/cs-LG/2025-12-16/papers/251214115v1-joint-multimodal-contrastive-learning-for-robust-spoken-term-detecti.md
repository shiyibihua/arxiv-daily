---
layout: default
title: Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting
---

# Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14115" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14115v1</a>
  <a href="https://arxiv.org/pdf/2512.14115.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14115v1" onclick="toggleFavorite(this, '2512.14115v1', 'Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ramesh Gundluru, Shubham Gupta, Sri Rama Murty K

**åˆ†ç±»**: cs.SD, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæå‡è¯­éŸ³æ£€ç´¢ä»»åŠ¡çš„é²æ£’æ€§å’Œæ•ˆç‡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å¯¹æ¯”å­¦ä¹ ` `è¯­éŸ³æ£€ç´¢` `å£°å­¦è¯åµŒå…¥` `è¯­éŸ³æœ¯è¯­æ£€æµ‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å£°å­¦è¯åµŒå…¥(AWE)æ–¹æ³•åœ¨è¯­éŸ³æ£€ç´¢ä»»åŠ¡ä¸­å­˜åœ¨å•æ¨¡æ€ç›‘ç£å’Œä¼˜åŒ–åˆ†ç¦»ç­‰é—®é¢˜ã€‚
2. æå‡ºè”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼ŒåŒæ—¶ä¼˜åŒ–éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘çš„å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯è¯­åŒºåˆ†ä»»åŠ¡ä¸Šè¶…è¶Šç°æœ‰åŸºçº¿ï¼Œå¹¶æ”¯æŒSTDå’ŒKWSã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§è”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æå‡è¯­éŸ³æ£€ç´¢ä»»åŠ¡ï¼ˆå¦‚è¯­éŸ³æœ¯è¯­æ£€æµ‹STDå’Œå…³é”®è¯æ£€ç´¢KWSï¼‰çš„æ€§èƒ½ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨å•æ¨¡æ€ç›‘ç£ã€éŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬å¯¹é½çš„ç‹¬ç«‹ä¼˜åŒ–ä»¥åŠéœ€è¦ä»»åŠ¡ç‰¹å®šæ¨¡å‹ç­‰å±€é™æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œè¯¥æ¡†æ¶åœ¨å…±äº«åµŒå…¥ç©ºé—´ä¸­ç»Ÿä¸€äº†å£°å­¦å’Œè·¨æ¨¡æ€ç›‘ç£ï¼ŒåŒæ—¶ä¼˜åŒ–äº†ï¼š(i) å—CLAPæŸå¤±å¯å‘çš„éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å¯¹é½éŸ³é¢‘å’Œæ–‡æœ¬è¡¨ç¤ºï¼›(ii) é€šè¿‡æ·±åº¦è¯è¯­åŒºåˆ†(DWD)æŸå¤±å®ç°çš„éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ï¼Œä»¥å¢å¼ºç±»å†…ç´§å‡‘æ€§å’Œç±»é—´åˆ†ç¦»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯è¯­åŒºåˆ†ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„AWEåŸºçº¿ï¼Œå¹¶èƒ½çµæ´»åœ°æ”¯æŒSTDå’ŒKWSã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªæ­¤ç±»ç»¼åˆæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³è¯­éŸ³æœ¯è¯­æ£€æµ‹ï¼ˆSTDï¼‰å’Œå…³é”®è¯æ£€ç´¢ï¼ˆKWSï¼‰ä»»åŠ¡ä¸­ï¼Œç°æœ‰å£°å­¦è¯åµŒå…¥ï¼ˆAWEï¼‰æ–¹æ³•å­˜åœ¨çš„å±€é™æ€§ã€‚è¿™äº›æ–¹æ³•é€šå¸¸ä¾èµ–äºå•æ¨¡æ€ç›‘ç£ï¼ŒéŸ³é¢‘-éŸ³é¢‘å’ŒéŸ³é¢‘-æ–‡æœ¬çš„å¯¹é½æ˜¯ç‹¬ç«‹ä¼˜åŒ–çš„ï¼Œå¹¶ä¸”éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œæ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è”åˆå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ï¼Œå°†éŸ³é¢‘å’Œæ–‡æœ¬ä¿¡æ¯èåˆåˆ°ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ä¸­ã€‚é€šè¿‡åŒæ—¶ä¼˜åŒ–éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘çš„å¯¹æ¯”æŸå¤±ï¼Œä½¿å¾—åµŒå…¥ç©ºé—´æ—¢èƒ½åæ˜ éŸ³é¢‘å’Œæ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œåˆèƒ½åŒºåˆ†ä¸åŒçš„è¯è¯­ï¼Œä»è€Œæå‡è¯­éŸ³æ£€ç´¢çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦çš„å¯¹æ¯”å­¦ä¹ æ¨¡å—ï¼šéŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ ã€‚éŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨ç±»ä¼¼äºCLAPçš„æŸå¤±å‡½æ•°ï¼Œå°†éŸ³é¢‘å’Œæ–‡æœ¬çš„è¡¨ç¤ºå¯¹é½ã€‚éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨æ·±åº¦è¯è¯­åŒºåˆ†ï¼ˆDWDï¼‰æŸå¤±ï¼Œå¢å¼ºåŒä¸€è¯è¯­çš„ä¸åŒéŸ³é¢‘æ ·æœ¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ï¼Œå¹¶å¢å¤§ä¸åŒè¯è¯­ä¹‹é—´çš„å·®å¼‚æ€§ã€‚è¿™ä¸¤ä¸ªæ¨¡å—å…±åŒä½œç”¨ï¼Œä¼˜åŒ–å…±äº«çš„åµŒå…¥ç©ºé—´ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†éŸ³é¢‘-æ–‡æœ¬å’ŒéŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ è”åˆèµ·æ¥ï¼Œåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ä¸­è¿›è¡Œä¼˜åŒ–ã€‚è¿™ä¸ä»¥å¾€åˆ†åˆ«ä¼˜åŒ–ä¸åŒæ¨¡æ€å¯¹é½çš„æ–¹æ³•ä¸åŒï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨å¤šæ¨¡æ€ä¿¡æ¯ï¼Œæå‡åµŒå…¥ç©ºé—´çš„è´¨é‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ï¼Œå…·æœ‰æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šéŸ³é¢‘-æ–‡æœ¬å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨Transformerç½‘ç»œæå–éŸ³é¢‘å’Œæ–‡æœ¬çš„ç‰¹å¾ï¼Œç„¶åè®¡ç®—å¯¹æ¯”æŸå¤±ã€‚éŸ³é¢‘-éŸ³é¢‘å¯¹æ¯”å­¦ä¹ æ¨¡å—ä½¿ç”¨DWDæŸå¤±ï¼Œè¯¥æŸå¤±åŸºäºä¸‰å…ƒç»„æŸå¤±çš„æ€æƒ³ï¼Œé€‰æ‹©æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼Œå¹¶è®¡ç®—å®ƒä»¬ä¹‹é—´çš„è·ç¦»ã€‚æŸå¤±å‡½æ•°çš„æƒé‡éœ€è¦ä»”ç»†è°ƒæ•´ï¼Œä»¥å¹³è¡¡ä¸¤ä¸ªå¯¹æ¯”å­¦ä¹ æ¨¡å—çš„è´¡çŒ®ã€‚å…·ä½“çš„ç½‘ç»œç»“æ„å’Œè¶…å‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“çš„æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨è¯è¯­åŒºåˆ†ä»»åŠ¡ä¸Šä¼˜äºç°æœ‰çš„AWEåŸºçº¿ã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†æ‘˜è¦ä¸­æ˜ç¡®æŒ‡å‡ºè¯¥æ–¹æ³•è¶…è¶Šäº†ç°æœ‰åŸºçº¿ï¼Œè¡¨æ˜å…¶åœ¨åŒºåˆ†ä¸åŒè¯è¯­æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿçµæ´»æ”¯æŒSTDå’ŒKWSï¼Œè¡¨æ˜å…¶å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè¯­éŸ³æœç´¢ã€æ™ºèƒ½åŠ©æ‰‹ã€è¯­éŸ³å†…å®¹åˆ†æç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³æœç´¢ç‰¹å®šçš„éŸ³é¢‘ç‰‡æ®µï¼Œæ™ºèƒ½åŠ©æ‰‹å¯ä»¥æ ¹æ®ç”¨æˆ·çš„è¯­éŸ³æŒ‡ä»¤å¿«é€Ÿå®šä½ç›¸å…³ä¿¡æ¯ï¼Œè¯­éŸ³å†…å®¹åˆ†æç³»ç»Ÿå¯ä»¥è‡ªåŠ¨è¯†åˆ«éŸ³é¢‘ä¸­çš„å…³é”®è¯å’Œä¸»é¢˜ã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºæå‡äººæœºäº¤äº’çš„æ•ˆç‡å’Œæ™ºèƒ½åŒ–æ°´å¹³ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.

