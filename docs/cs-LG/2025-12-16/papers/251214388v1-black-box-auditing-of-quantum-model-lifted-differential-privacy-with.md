---
layout: default
title: Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries
---

# Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries

**arXiv**: [2512.14388v1](https://arxiv.org/abs/2512.14388) | [PDF](https://arxiv.org/pdf/2512.14388.pdf)

**ä½œè€…**: Baobao Song, Shiva Raj Pokhrel, Athanasios V. Vasilakos, Tianqing Zhu, Gang Li

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽæå‡é‡å­å·®åˆ†éšç§çš„é»‘ç›’å®¡è®¡æ¡†æž¶ï¼Œåˆ©ç”¨é‡å­é‡‘ä¸é›€æ£€æµ‹é‡å­æœºå™¨å­¦ä¹ æ¨¡åž‹ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚**

**å…³é”®è¯**: `é‡å­æœºå™¨å­¦ä¹ ` `éšç§å®¡è®¡` `å·®åˆ†éšç§` `é‡å­é‡‘ä¸é›€` `é»‘ç›’éªŒè¯` `éšç§æ³„éœ²æ£€æµ‹` `é‡å­è®¡ç®—å®‰å…¨` `æ¨¡åž‹è®°å¿†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é‡å­å·®åˆ†éšç§æœºåˆ¶ç¼ºä¹å®žè¯éªŒè¯å·¥å…·ï¼Œæ— æ³•è¯„ä¼°å·²éƒ¨ç½²é‡å­æœºå™¨å­¦ä¹ æ¨¡åž‹çš„éšç§æ³„éœ²é£Žé™©ã€‚
2. æå‡ºåŸºäºŽæå‡é‡å­å·®åˆ†éšç§çš„é»‘ç›’å®¡è®¡æ¡†æž¶ï¼Œåˆ©ç”¨é‡å­é‡‘ä¸é›€ç­–ç•¥æ€§ç¼–ç é‡å­æ€æ¥æ£€æµ‹è®°å¿†å’Œé‡åŒ–éšç§æ³„éœ²ã€‚
3. å®žéªŒåœ¨æ¨¡æ‹Ÿå’Œç‰©ç†ç¡¬ä»¶ä¸ŠéªŒè¯äº†æ¡†æž¶æœ‰æ•ˆæ€§ï¼Œèƒ½ç²¾ç¡®æµ‹é‡éšç§æŸå¤±å¹¶å»ºç«‹ç†è®ºåˆ°å®žè·µçš„æ¡¥æ¢ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é‡å­æœºå™¨å­¦ä¹ ï¼ˆQMLï¼‰è™½ç„¶å…·æœ‰æ˜¾è‘—çš„è®¡ç®—ä¼˜åŠ¿ï¼Œä½†æ¨¡åž‹åœ¨æ•æ„Ÿæ•°æ®ä¸Šè®­ç»ƒæ—¶å¯èƒ½è®°å¿†ä¸ªä½“è®°å½•ï¼Œå¯¼è‡´ä¸¥é‡çš„éšç§æ¼æ´žã€‚çŽ°æœ‰çš„é‡å­å·®åˆ†éšç§ï¼ˆQDPï¼‰æœºåˆ¶æä¾›äº†ç†è®ºä¸Šçš„æœ€åæƒ…å†µä¿è¯ï¼Œä½†ç¼ºä¹å¯¹å·²éƒ¨ç½²æ¨¡åž‹è¿›è¡Œå®žè¯éªŒè¯çš„å·¥å…·ã€‚æœ¬æ–‡é¦–æ¬¡å¼•å…¥äº†åŸºäºŽæå‡é‡å­å·®åˆ†éšç§çš„é»‘ç›’éšç§å®¡è®¡æ¡†æž¶ï¼Œåˆ©ç”¨é‡å­é‡‘ä¸é›€ï¼ˆç­–ç•¥æ€§åç§»ç¼–ç çš„é‡å­æ€ï¼‰æ¥æ£€æµ‹è®°å¿†è¡Œä¸ºï¼Œå¹¶ç²¾ç¡®é‡åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­çš„éšç§æ³„éœ²ã€‚è¯¥æ¡†æž¶å»ºç«‹äº†é‡‘ä¸é›€åç§»ä¸Žè¿¹è·ç¦»ç•Œé™ä¹‹é—´çš„ä¸¥æ ¼æ•°å­¦è”ç³»ï¼ŒæŽ¨å¯¼å‡ºéšç§é¢„ç®—æ¶ˆè€—çš„ç»éªŒä¸‹ç•Œï¼Œä»Žè€Œå¼¥åˆäº†ç†è®ºä¿è¯ä¸Žå®žé™…éšç§éªŒè¯ä¹‹é—´çš„å…³é”®å·®è·ã€‚åœ¨æ¨¡æ‹Ÿå’Œç‰©ç†é‡å­ç¡¬ä»¶ä¸Šçš„å…¨é¢è¯„ä¼°è¡¨æ˜Žï¼Œè¯¥æ¡†æž¶èƒ½æœ‰æ•ˆæµ‹é‡QMLæ¨¡åž‹ä¸­çš„å®žé™…éšç§æŸå¤±ï¼Œä¸ºQMLç³»ç»Ÿæä¾›ç¨³å¥çš„éšç§éªŒè¯ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºä¸€ä¸ªé»‘ç›’éšç§å®¡è®¡æ¡†æž¶ï¼Œæ ¸å¿ƒåŸºäºŽæå‡é‡å­å·®åˆ†éšç§ç†è®ºã€‚æ•´ä½“æ¡†æž¶é€šè¿‡å¼•å…¥é‡å­é‡‘ä¸é›€â€”â€”å³ç­–ç•¥æ€§åç§»ç¼–ç çš„é‡å­æ€ï¼Œä½œä¸ºæŽ¢æµ‹å·¥å…·æ¥æ£€æµ‹æ¨¡åž‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„è®°å¿†è¡Œä¸ºã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽå»ºç«‹äº†é‡‘ä¸é›€åç§»ä¸Žé‡å­æ€è¿¹è·ç¦»ä¹‹é—´çš„ä¸¥æ ¼æ•°å­¦è”ç³»ï¼Œä»Žè€ŒæŽ¨å¯¼å‡ºéšç§é¢„ç®—æ¶ˆè€—çš„ç»éªŒä¸‹ç•Œï¼Œè¿™å…è®¸åœ¨æ— éœ€è®¿é—®æ¨¡åž‹å†…éƒ¨ç»†èŠ‚çš„æƒ…å†µä¸‹é‡åŒ–éšç§æ³„éœ²ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒçŽ°æœ‰é‡å­å·®åˆ†éšç§æ–¹æ³•ä»…æä¾›ç†è®ºä¿è¯ï¼Œè€Œæœ¬æ¡†æž¶é¦–æ¬¡å®žçŽ°äº†å¯¹QMLæ¨¡åž‹çš„å®žè¯éšç§éªŒè¯ï¼Œå¼¥è¡¥äº†ç†è®ºåˆ†æžä¸Žå®žé™…éƒ¨ç½²ä¹‹é—´çš„å·®è·ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨æ¨¡æ‹Ÿå’Œç‰©ç†é‡å­ç¡¬ä»¶ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œæ¡†æž¶èƒ½æœ‰æ•ˆæ£€æµ‹æ¨¡åž‹è®°å¿†è¡Œä¸ºï¼Œç²¾ç¡®é‡åŒ–éšç§æ³„éœ²ï¼Œç»éªŒä¸‹ç•Œä¸Žç†è®ºä¿è¯ä¸€è‡´ï¼ŒéªŒè¯äº†æå‡é‡å­å·®åˆ†éšç§åœ¨å®žé™…ç³»ç»Ÿä¸­çš„é€‚ç”¨æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽé‡å­æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„éšç§å®‰å…¨è¯„ä¼°ï¼Œç‰¹åˆ«æ˜¯åœ¨åŒ»ç–—ã€é‡‘èžç­‰æ•æ„Ÿæ•°æ®å¤„ç†åœºæ™¯ä¸­ï¼Œå¸®åŠ©éªŒè¯é‡å­æ¨¡åž‹æ˜¯å¦éµå®ˆéšç§ä¿æŠ¤æ ‡å‡†ï¼Œä¿ƒè¿›QMLæŠ€æœ¯çš„å¯ä¿¡éƒ¨ç½²ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Quantum machine learning (QML) promises significant computational advantages, yet models trained on sensitive data risk memorizing individual records, creating serious privacy vulnerabilities. While Quantum Differential Privacy (QDP) mechanisms provide theoretical worst-case guarantees, they critically lack empirical verification tools for deployed models. We introduce the first black-box privacy auditing framework for QML based on Lifted Quantum Differential Privacy, leveraging quantum canaries (strategically offset-encoded quantum states) to detect memorization and precisely quantify privacy leakage during training. Our framework establishes a rigorous mathematical connection between canary offset and trace distance bounds, deriving empirical lower bounds on privacy budget consumption that bridge the critical gap between theoretical guarantees and practical privacy verification. Comprehensive evaluations across both simulated and physical quantum hardware demonstrate our framework's effectiveness in measuring actual privacy loss in QML models, enabling robust privacy verification in QML systems.

