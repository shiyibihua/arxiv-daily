---
layout: default
title: Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models
---

# Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models

**arXiv**: [2512.14427v1](https://arxiv.org/abs/2512.14427) | [PDF](https://arxiv.org/pdf/2512.14427.pdf)

**ä½œè€…**: Gabriele Prato, Shagun Sodhani, Alessandro Sordoni, Sarath Chandar

**åˆ†ç±»**: cs.CL, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶æ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œä¼˜åŒ–æ¨¡åž‹è®­ç»ƒæ•ˆçŽ‡ä¸Žæ€§èƒ½**

**å…³é”®è¯**: `æ–‡æ¡£æ‰“åŒ…ç­–ç•¥` `å¤§åž‹è¯­è¨€æ¨¡åž‹è®­ç»ƒ` `å¤šè·³æŽ¨ç†èƒ½åŠ›` `è®¡ç®—æ•ˆçŽ‡ä¼˜åŒ–` `æ¶ˆèžç ”ç©¶` `è®­ç»ƒåŠ¨æ€åˆ†æž` `æ¨¡åž‹æ€§èƒ½æå‡` `æ½œåœ¨èƒ½åŠ›è¯„ä¼°`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è®­ç»ƒæ–¹æ³•ä¸­ï¼Œæ–‡æ¡£æ‰“åŒ…å¯¹å¤§åž‹è¯­è¨€æ¨¡åž‹èƒ½åŠ›çš„å½±å“å°šæœªå……åˆ†ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯å¯¹å¤šè·³æŽ¨ç†ç­‰å¤æ‚ä»»åŠ¡çš„å½±å“æœªçŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡ç³»ç»Ÿæ¯”è¾ƒä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼Œåˆ†æžå…¶å¯¹æ¨¡åž‹æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå¹¶è¿›è¡Œæ¶ˆèžç ”ç©¶ä»¥æ­ç¤ºå…³é”®å› ç´ ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šç ”ç©¶å‘çŽ°æ‰“åŒ…èƒ½æå‡æ¨¡åž‹æ€§èƒ½ï¼Œä½†éœ€æ›´å¤šè®¡ç®—èµ„æºï¼›æ¶ˆèžå®žéªŒè¯†åˆ«äº†å½±å“æ€§èƒ½çš„å…³é”®å› ç´ ï¼Œä¸ºä¼˜åŒ–è®­ç»ƒæä¾›æŒ‡å¯¼ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®­ç»ƒå¤§åž‹è¯­è¨€æ¨¡åž‹çš„æ ‡å‡†å®žè·µé€šå¸¸æ¶‰åŠå°†å¤šä¸ªæ–‡æ¡£æ‰“åŒ…åœ¨ä¸€èµ·ä»¥æé«˜è®¡ç®—æ•ˆçŽ‡ï¼Œä½†è¿™ä¸€è¿‡ç¨‹å¯¹æ¨¡åž‹èƒ½åŠ›çš„å½±å“å°šæœªå¾—åˆ°å……åˆ†æŽ¢ç´¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬ç ”ç©¶è°ƒæŸ¥äº†ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥å¦‚ä½•å½±å“LLMsçš„æ½œåœ¨å¤šè·³æŽ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æžœè¡¨æ˜Žï¼Œä¸Žåœ¨å•ä¸ªæ–‡æ¡£ä¸Šè®­ç»ƒç›¸æ¯”ï¼Œæ‰“åŒ…å¯ä»¥æé«˜æ¨¡åž‹æ€§èƒ½ï¼Œä½†éœ€è¦æ›´å¤šçš„è®¡ç®—èµ„æºã€‚ä¸ºäº†è¿›ä¸€æ­¥ç†è§£å…¶åº•å±‚æœºåˆ¶ï¼Œæˆ‘ä»¬è¿›è¡Œäº†æ¶ˆèžç ”ç©¶ï¼Œè¯†åˆ«äº†è§£é‡Šæ‰“åŒ…ä¼˜åŠ¿çš„å…³é”®å› ç´ ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç ”ç©¶æ·±åŒ–äº†å¯¹LLMè®­ç»ƒåŠ¨æ€çš„ç†è§£ï¼Œå¹¶ä¸ºä¼˜åŒ–æ¨¡åž‹å¼€å‘æä¾›äº†å®žç”¨è§è§£ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡é‡‡ç”¨å®žéªŒåˆ†æžæ–¹æ³•ï¼Œæ•´ä½“æ¡†æž¶åŒ…æ‹¬è®¾è®¡ä¸åŒæ–‡æ¡£æ‰“åŒ…ç­–ç•¥ï¼ˆå¦‚åŸºäºŽå†…å®¹ã€é•¿åº¦æˆ–éšæœºç»„åˆï¼‰ï¼Œåœ¨æ ‡å‡†LLMè®­ç»ƒæµç¨‹ä¸­åº”ç”¨è¿™äº›ç­–ç•¥ï¼Œå¹¶è¯„ä¼°æ¨¡åž‹åœ¨æ½œåœ¨å¤šè·³æŽ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨çŽ°ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽç³»ç»Ÿé‡åŒ–æ‰“åŒ…ç­–ç•¥å¯¹æ¨¡åž‹èƒ½åŠ›çš„å½±å“ï¼Œè€Œéžä»…å…³æ³¨è®¡ç®—æ•ˆçŽ‡ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼ŒçŽ°æœ‰ç ”ç©¶å¤šå‡è®¾æ‰“åŒ…ä»…å½±å“è®­ç»ƒé€Ÿåº¦ï¼Œè€Œæœ¬æ–‡é¦–æ¬¡æ·±å…¥æŽ¢è®¨å…¶å¯¹æ¨¡åž‹å†…åœ¨æŽ¨ç†èƒ½åŠ›çš„æ½œåœ¨æå‡æœºåˆ¶ï¼Œé€šè¿‡æ¶ˆèžç ”ç©¶åˆ†ç¦»å‡ºå…³é”®å˜é‡ï¼ˆå¦‚æ–‡æ¡£é—´å…³è”æ€§ã€æ‰“åŒ…å¯†åº¦ç­‰ï¼‰ï¼Œä¸ºç†è§£è®­ç»ƒåŠ¨æ€æä¾›æ–°è§†è§’ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

æœ€é‡è¦çš„å®žéªŒç»“æžœæ˜¾ç¤ºï¼Œæ–‡æ¡£æ‰“åŒ…ç›¸æ¯”å•ä¸ªæ–‡æ¡£è®­ç»ƒèƒ½æ˜¾è‘—æå‡æ¨¡åž‹åœ¨æ½œåœ¨å¤šè·³æŽ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä½†è®¡ç®—å¼€é”€å¢žåŠ ï¼›æ¶ˆèžç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«å‡ºæ–‡æ¡£é—´è¯­ä¹‰å…³è”æ€§å’Œæ‰“åŒ…å¯†åº¦æ˜¯å…³é”®å½±å“å› ç´ ï¼Œä¸ºä¼˜åŒ–ç­–ç•¥æä¾›äº†å®žè¯ä¾æ®ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽå¤§åž‹è¯­è¨€æ¨¡åž‹çš„è®­ç»ƒä¼˜åŒ–é¢†åŸŸï¼Œå¸®åŠ©å¼€å‘è€…åœ¨è®¡ç®—èµ„æºä¸Žæ¨¡åž‹æ€§èƒ½é—´åšå‡ºå¹³è¡¡å†³ç­–ï¼Œæå‡å¤šè·³æŽ¨ç†ç­‰å¤æ‚ä»»åŠ¡çš„æ•ˆçŽ‡ã€‚æ½œåœ¨ä»·å€¼åŒ…æ‹¬æŒ‡å¯¼å®žé™…æ¨¡åž‹å¼€å‘ä¸­çš„æ–‡æ¡£é¢„å¤„ç†ç­–ç•¥ï¼Œé™ä½Žè®­ç»ƒæˆæœ¬ï¼ŒåŒæ—¶ç¡®ä¿æ¨¡åž‹åœ¨æŽ¨ç†å¯†é›†åž‹åº”ç”¨ï¼ˆå¦‚é—®ç­”ç³»ç»Ÿã€é€»è¾‘åˆ†æžï¼‰ä¸­ä¿æŒé«˜æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The standard practice for training large language models involves packing multiple documents together to optimize computational efficiency. However, the impact of this process on the models' capabilities remains largely unexplored. To address this gap, we investigate how different document-packing strategies influence the latent multi-hop reasoning abilities of LLMs. Our findings indicate that packing can improve model performance compared to training on individual documents, at the expense of more compute. To further understand the underlying mechanisms, we conduct an ablation study, identifying key factors that explain the advantages of packing. Ultimately, our research deepens the understanding of LLM training dynamics and provides practical insights for optimizing model development.

