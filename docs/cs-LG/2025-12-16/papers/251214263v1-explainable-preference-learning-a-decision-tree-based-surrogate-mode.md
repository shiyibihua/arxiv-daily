---
layout: default
title: Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

**arXiv**: [2512.14263v1](https://arxiv.org/abs/2512.14263) | [PDF](https://arxiv.org/pdf/2512.14263.pdf)

**ä½œè€…**: Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl

**åˆ†ç±»**: cs.LG, cs.AI, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽå†³ç­–æ ‘çš„å¯è§£é‡Šåå¥½å­¦ä¹ æ¨¡åž‹ï¼Œä»¥è§£å†³é«˜æ–¯è¿‡ç¨‹åœ¨åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­å¯è§£é‡Šæ€§å·®ã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾åŠè®¡ç®—å¤æ‚çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `åå¥½å­¦ä¹ ` `è´å¶æ–¯ä¼˜åŒ–` `å†³ç­–æ ‘æ¨¡åž‹` `å¯è§£é‡Šäººå·¥æ™ºèƒ½` `åˆ†ç±»æ•°æ®å¤„ç†` `å¤§è§„æ¨¡ä¼˜åŒ–` `ä¸ªæ€§åŒ–æŽ¨è`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰é«˜æ–¯è¿‡ç¨‹æ¨¡åž‹å¯è§£é‡Šæ€§å·®ã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ä¸”è®¡ç®—å¤æ‚ï¼Œé™åˆ¶äº†åå¥½è´å¶æ–¯ä¼˜åŒ–çš„å®žé™…åº”ç”¨ã€‚
2. æå‡ºåŸºäºŽå†³ç­–æ ‘çš„ä»£ç†æ¨¡åž‹ï¼Œå…·æœ‰å›ºæœ‰å¯è§£é‡Šæ€§ï¼Œèƒ½å¤„ç†æ··åˆæ•°æ®ç±»åž‹ï¼Œå¹¶å®žçŽ°å¤§è§„æ¨¡æ‰©å±•ã€‚
3. åœ¨å°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä¼˜äºŽé«˜æ–¯è¿‡ç¨‹æ¨¡åž‹ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½æŽ¥è¿‘ï¼Œå¹¶æˆåŠŸåº”ç”¨äºŽçœŸå®žåå¥½å­¦ä¹ ä»»åŠ¡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰çš„åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¾èµ–äºŽé«˜æ–¯è¿‡ç¨‹ä½œä¸ºä»£ç†æ¨¡åž‹ï¼Œè¿™äº›æ¨¡åž‹éš¾ä»¥è§£é‡Šã€å¤„ç†åˆ†ç±»æ•°æ®å›°éš¾ä¸”è®¡ç®—å¤æ‚ï¼Œé™åˆ¶äº†å…¶å®žé™…åº”ç”¨ã€‚æœ¬æ–‡å¼•å…¥äº†ä¸€ç§åŸºäºŽå†³ç­–æ ‘çš„å›ºæœ‰å¯è§£é‡Šä»£ç†æ¨¡åž‹ï¼Œèƒ½å¤Ÿå¤„ç†åˆ†ç±»å’Œè¿žç»­æ•°æ®ï¼Œå¹¶å¯æ‰©å±•åˆ°å¤§åž‹æ•°æ®é›†ã€‚åœ¨å…«ä¸ªé€æ¸å°–å³°çš„ä¼˜åŒ–å‡½æ•°ä¸Šè¿›è¡Œçš„å¤§é‡æ•°å€¼å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šä¼˜äºŽåŸºäºŽé«˜æ–¯è¿‡ç¨‹çš„æ›¿ä»£æ–¹æ³•ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ¨¡åž‹åº”ç”¨äºŽçœŸå®žä¸–ç•Œçš„å¯¿å¸æ•°æ®é›†ï¼Œå±•ç¤ºäº†å…¶å­¦ä¹ ä¸ªäººå¯¿å¸åå¥½çš„èƒ½åŠ›ã€‚æœ€åŽï¼Œæˆ‘ä»¬å±•ç¤ºäº†åˆ©ç”¨åŽ†å²åå¥½æ•°æ®åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–è¿‡ç¨‹çš„åˆæ­¥å·¥ä½œã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºŽå†³ç­–æ ‘çš„ä»£ç†æ¨¡åž‹æ¡†æž¶ï¼Œç”¨äºŽæ›¿ä»£ä¼ ç»Ÿçš„é«˜æ–¯è¿‡ç¨‹åœ¨åå¥½è´å¶æ–¯ä¼˜åŒ–ä¸­çš„è§’è‰²ã€‚å…³é”®æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºŽåˆ©ç”¨å†³ç­–æ ‘çš„å›ºæœ‰å¯è§£é‡Šæ€§ï¼Œé€šè¿‡æž„å»ºæ ‘ç»“æž„æ¥å»ºæ¨¡ç”¨æˆ·åå¥½ï¼Œæ”¯æŒåˆ†ç±»å’Œè¿žç»­æ•°æ®çš„æ··åˆè¾“å…¥ï¼Œå¹¶é‡‡ç”¨é«˜æ•ˆç®—æ³•å®žçŽ°å¤§è§„æ¨¡æ•°æ®æ‰©å±•ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºŽï¼Œè¯¥æ¨¡åž‹é¿å…äº†é«˜æ–¯è¿‡ç¨‹çš„é»‘ç›’ç‰¹æ€§ï¼Œæä¾›äº†æ›´ç›´è§‚çš„å†³ç­–è·¯å¾„è§£é‡Šï¼ŒåŒæ—¶é™ä½Žäº†è®¡ç®—å¤æ‚åº¦ï¼Œæé«˜äº†å¤„ç†å¤æ‚æ•°æ®ç±»åž‹çš„çµæ´»æ€§ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…«ä¸ªå°–å³°ä¼˜åŒ–å‡½æ•°å®žéªŒä¸­ï¼Œæ¨¡åž‹åœ¨å°–å³°å‡½æ•°ä¸Šæ˜¾è‘—ä¼˜äºŽé«˜æ–¯è¿‡ç¨‹åŸºå‡†ï¼Œåœ¨éžå°–å³°å‡½æ•°ä¸Šæ€§èƒ½ä»…ç•¥ä½Žï¼›åœ¨å¯¿å¸æ•°æ®é›†ä¸ŠæˆåŠŸå­¦ä¹ ä¸ªäººåå¥½ï¼ŒéªŒè¯äº†å®žé™…åº”ç”¨æ½œåŠ›ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶å¯åº”ç”¨äºŽä¸ªæ€§åŒ–æŽ¨èç³»ç»Ÿã€äº§å“è®¾è®¡ä¼˜åŒ–å’Œç”¨æˆ·åå¥½å»ºæ¨¡ç­‰é¢†åŸŸï¼Œé€šè¿‡å¯è§£é‡Šçš„åå¥½å­¦ä¹ æå‡å†³ç­–é€æ˜Žåº¦å’Œæ•ˆçŽ‡ï¼Œå…·æœ‰å®žé™…å•†ä¸šå’Œç§‘ç ”ä»·å€¼ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.

