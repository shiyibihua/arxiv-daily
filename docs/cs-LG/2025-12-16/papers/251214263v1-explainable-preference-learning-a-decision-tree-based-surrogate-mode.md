---
layout: default
title: Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization
---

# Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.14263" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.14263v1</a>
  <a href="https://arxiv.org/pdf/2512.14263.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.14263v1" onclick="toggleFavorite(this, '2512.14263v1', 'Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl

**åˆ†ç±»**: cs.LG, cs.AI, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-12-16

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå†³ç­–æ ‘çš„å¯è§£é‡Šåå¥½å­¦ä¹ æ¨¡å‹ï¼Œæå‡åå¥½è´å¶æ–¯ä¼˜åŒ–åœ¨å¤æ‚åœºæ™¯ä¸‹çš„å¯ç”¨æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åå¥½å­¦ä¹ ` `è´å¶æ–¯ä¼˜åŒ–` `å†³ç­–æ ‘` `å¯è§£é‡Šæ€§` `ä»£ç†æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¾èµ–é«˜æ–¯è¿‡ç¨‹ï¼Œå­˜åœ¨è§£é‡Šæ€§å·®ã€éš¾ä»¥å¤„ç†åˆ†ç±»æ•°æ®å’Œè®¡ç®—å¤æ‚åº¦é«˜ç­‰é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºåŸºäºå†³ç­–æ ‘çš„ä»£ç†æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…·æœ‰å†…åœ¨å¯è§£é‡Šæ€§ï¼Œèƒ½å¤„ç†æ··åˆæ•°æ®ï¼Œå¹¶å¯æ‰©å±•åˆ°å¤§æ•°æ®é›†ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å°–é”å‡½æ•°ä¸Šä¼˜äºé«˜æ–¯è¿‡ç¨‹ï¼Œåœ¨å¯¿å¸æ•°æ®é›†ä¸Šèƒ½æœ‰æ•ˆå­¦ä¹ ä¸ªäººåå¥½ï¼Œå¹¶èƒ½åˆ©ç”¨å†å²æ•°æ®åŠ é€Ÿä¼˜åŒ–ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¾èµ–äºé«˜æ–¯è¿‡ç¨‹ï¼ˆGPï¼‰ä½œä¸ºä»£ç†æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹éš¾ä»¥è§£é‡Šï¼Œéš¾ä»¥å¤„ç†åˆ†ç±»æ•°æ®ï¼Œå¹¶ä¸”è®¡ç®—å¤æ‚åº¦é«˜ï¼Œé™åˆ¶äº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„å¯ç”¨æ€§ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå†³ç­–æ ‘çš„ã€æœ¬è´¨ä¸Šå¯è§£é‡Šçš„ä»£ç†æ¨¡å‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿå¤„ç†åˆ†ç±»å’Œè¿ç»­æ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥æ‰©å±•åˆ°å¤§å‹æ•°æ®é›†ã€‚åœ¨å…«ä¸ªæ—¥ç›Šå°–é”çš„ä¼˜åŒ–å‡½æ•°ä¸Šçš„å¤§é‡æ•°å€¼å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨å°–é”å‡½æ•°ä¸Šä¼˜äºåŸºäºGPçš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶ä¸”å¯¹äºéå°–é”å‡½æ•°ï¼Œæ€§èƒ½ä»…ç•¥æœ‰é™ä½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æˆ‘ä»¬çš„æ¨¡å‹åº”ç”¨äºçœŸå®çš„å¯¿å¸æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†å…¶å­¦ä¹ ä¸ªäººå¯¿å¸åå¥½çš„èƒ½åŠ›ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†ä¸€äº›ä½¿ç”¨å†å²åå¥½æ•°æ®æ¥åŠ é€Ÿæ–°ç”¨æˆ·çš„ä¼˜åŒ–è¿‡ç¨‹çš„åˆæ­¥å·¥ä½œã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰åå¥½è´å¶æ–¯ä¼˜åŒ–æ–¹æ³•ä¸­å­˜åœ¨çš„ä»£ç†æ¨¡å‹å¯è§£é‡Šæ€§å·®ã€æ— æ³•æœ‰æ•ˆå¤„ç†åˆ†ç±»æ•°æ®ä»¥åŠè®¡ç®—å¤æ‚åº¦é«˜ç­‰é—®é¢˜ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†åå¥½è´å¶æ–¯ä¼˜åŒ–åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚ä¸ªæ€§åŒ–æ¨èã€äº§å“è®¾è®¡ç­‰ï¼Œç”¨æˆ·éš¾ä»¥ç†è§£æ¨¡å‹ç»™å‡ºçš„åå¥½å»ºè®®ï¼Œä¸”æ¨¡å‹è®­ç»ƒå’Œæ¨ç†æ•ˆç‡è¾ƒä½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ä½¿ç”¨å†³ç­–æ ‘ä½œä¸ºåå¥½è´å¶æ–¯ä¼˜åŒ–çš„ä»£ç†æ¨¡å‹ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„é«˜æ–¯è¿‡ç¨‹ã€‚å†³ç­–æ ‘æœ¬èº«å…·æœ‰è‰¯å¥½çš„å¯è§£é‡Šæ€§ï¼Œèƒ½å¤Ÿæ¸…æ™°åœ°å±•ç¤ºç‰¹å¾ä¸åå¥½ä¹‹é—´çš„å…³ç³»ã€‚æ­¤å¤–ï¼Œå†³ç­–æ ‘èƒ½å¤Ÿè‡ªç„¶åœ°å¤„ç†åˆ†ç±»æ•°æ®å’Œè¿ç»­æ•°æ®ï¼Œå¹¶ä¸”åœ¨å¤„ç†å¤§è§„æ¨¡æ•°æ®é›†æ—¶å…·æœ‰è¾ƒé«˜çš„æ•ˆç‡ã€‚é€šè¿‡å†³ç­–æ ‘ï¼Œç”¨æˆ·å¯ä»¥æ›´å®¹æ˜“åœ°ç†è§£æ¨¡å‹çš„åå¥½å­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶èƒ½å¤Ÿæ›´å¿«åœ°å¾—åˆ°ä¼˜åŒ–ç»“æœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) æ”¶é›†ç”¨æˆ·çš„åå¥½æ•°æ®ï¼Œä¾‹å¦‚æˆå¯¹æ¯”è¾ƒç»“æœæˆ–æ’åºåˆ—è¡¨ï¼›2) ä½¿ç”¨æ”¶é›†åˆ°çš„åå¥½æ•°æ®è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ï¼Œè¯¥æ¨¡å‹çš„ç›®æ ‡æ˜¯é¢„æµ‹ç”¨æˆ·å¯¹äºä¸åŒé€‰é¡¹çš„åå¥½ç¨‹åº¦ï¼›3) ä½¿ç”¨è®­ç»ƒå¥½çš„å†³ç­–æ ‘æ¨¡å‹ä½œä¸ºä»£ç†æ¨¡å‹ï¼ŒæŒ‡å¯¼è´å¶æ–¯ä¼˜åŒ–ç®—æ³•é€‰æ‹©ä¸‹ä¸€ä¸ªè¦è¯„ä¼°çš„é€‰é¡¹ï¼›4) å°†è¯„ä¼°ç»“æœåé¦ˆç»™å†³ç­–æ ‘æ¨¡å‹ï¼Œæ›´æ–°æ¨¡å‹å‚æ•°ï¼Œè¿­ä»£ä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å†³ç­–æ ‘å¼•å…¥åå¥½è´å¶æ–¯ä¼˜åŒ–ï¼Œå¹¶å°†å…¶ä½œä¸ºä»£ç†æ¨¡å‹ã€‚ä¸ä¼ ç»Ÿçš„é«˜æ–¯è¿‡ç¨‹ç›¸æ¯”ï¼Œå†³ç­–æ ‘å…·æœ‰æ›´å¥½çš„å¯è§£é‡Šæ€§ã€èƒ½å¤Ÿå¤„ç†æ··åˆæ•°æ®ä»¥åŠæ›´é«˜çš„è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†åˆ©ç”¨å†å²åå¥½æ•°æ®åŠ é€Ÿæ–°ç”¨æˆ·ä¼˜åŒ–è¿‡ç¨‹çš„æ–¹æ³•ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„å®ç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å†³ç­–æ ‘çš„å…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ï¼Œä½†å¯ä»¥æ¨æµ‹å¯èƒ½æ¶‰åŠä»¥ä¸‹å…³é”®è®¾è®¡ï¼š1) å†³ç­–æ ‘çš„åˆ†è£‚å‡†åˆ™ï¼Œä¾‹å¦‚ä¿¡æ¯å¢ç›Šæˆ–åŸºå°¼ç³»æ•°ï¼Œç”¨äºé€‰æ‹©æœ€ä½³åˆ†è£‚ç‰¹å¾ï¼›2) å†³ç­–æ ‘çš„å‰ªæç­–ç•¥ï¼Œç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼›3) å¦‚ä½•å°†å†³ç­–æ ‘çš„é¢„æµ‹ç»“æœè½¬åŒ–ä¸ºè´å¶æ–¯ä¼˜åŒ–ç®—æ³•æ‰€éœ€çš„æ•ˆç”¨å‡½æ•°ï¼›4) å¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨å†å²åå¥½æ•°æ®è¿›è¡Œè¿ç§»å­¦ä¹ æˆ–å…ƒå­¦ä¹ ï¼Œä»¥åŠ é€Ÿæ–°ç”¨æˆ·çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å°–é”çš„ä¼˜åŒ–å‡½æ•°ä¸Šï¼ŒåŸºäºå†³ç­–æ ‘çš„ä»£ç†æ¨¡å‹ä¼˜äºåŸºäºé«˜æ–¯è¿‡ç¨‹çš„æ›¿ä»£æ–¹æ¡ˆã€‚åœ¨éå°–é”å‡½æ•°ä¸Šï¼Œæ€§èƒ½ä»…ç•¥æœ‰é™ä½ã€‚åœ¨çœŸå®çš„å¯¿å¸æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ ä¸ªäººå¯¿å¸åå¥½ã€‚æ­¤å¤–ï¼Œåˆæ­¥å®éªŒè¡¨æ˜ï¼Œåˆ©ç”¨å†å²åå¥½æ•°æ®å¯ä»¥åŠ é€Ÿæ–°ç”¨æˆ·çš„ä¼˜åŒ–è¿‡ç¨‹ã€‚è¿™äº›ç»“æœéªŒè¯äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€äº§å“è®¾è®¡ã€åŒ»ç–—å†³ç­–ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸ªæ€§åŒ–æ¨èä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ¨¡å‹å­¦ä¹ ç”¨æˆ·çš„å£å‘³åå¥½ï¼Œæ¨èæ›´ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„å•†å“æˆ–æœåŠ¡ã€‚åœ¨äº§å“è®¾è®¡ä¸­ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ¨¡å‹äº†è§£ç”¨æˆ·å¯¹ä¸åŒäº§å“å±æ€§çš„åå¥½ï¼Œè®¾è®¡å‡ºæ›´å—æ¬¢è¿çš„äº§å“ã€‚åœ¨åŒ»ç–—å†³ç­–ä¸­ï¼Œå¯ä»¥å¸®åŠ©åŒ»ç”Ÿäº†è§£æ‚£è€…å¯¹ä¸åŒæ²»ç–—æ–¹æ¡ˆçš„åå¥½ï¼Œåˆ¶å®šæ›´ç¬¦åˆæ‚£è€…æ„æ„¿çš„æ²»ç–—æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶æœ‰æœ›æå‡äººæœºäº¤äº’çš„æ•ˆç‡å’Œç”¨æˆ·æ»¡æ„åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current Preferential Bayesian Optimization methods rely on Gaussian Processes (GPs) as surrogate models. These models are hard to interpret, struggle with handling categorical data, and are computationally complex, limiting their real-world usability. In this paper, we introduce an inherently interpretable decision tree-based surrogate model capable of handling both categorical and continuous data, and scalable to large datasets. Extensive numerical experiments on eight increasingly spiky optimization functions show that our model outperforms GP-based alternatives on spiky functions and has only marginally lower performance for non-spiky functions. Moreover, we apply our model to the real-world Sushi dataset and show its ability to learn an individual's sushi preferences. Finally, we show some initial work on using historical preference data to speed up the optimization process for new unseen users.

