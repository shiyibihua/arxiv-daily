---
layout: default
title: Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning
---

# Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10378" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10378v1</a>
  <a href="https://arxiv.org/pdf/2506.10378.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10378v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10378v1', 'Discovering Hierarchical Latent Capabilities of Language Models via Causal Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jikai Jin, Vasilis Syrgkanis, Sham Kakade, Hanlin Zhang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå› æœè¡¨ç¤ºå­¦ä¹ æ¡†æ¶ä»¥è¯„ä¼°è¯­è¨€æ¨¡å‹æ½œåœ¨èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœè¡¨ç¤ºå­¦ä¹ ` `è¯­è¨€æ¨¡å‹è¯„ä¼°` `æ½œåœ¨èƒ½åŠ›` `æ¨¡å‹ä¼˜åŒ–` `æ€§èƒ½åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€æ¨¡å‹è¯„ä¼°æ–¹æ³•é¢ä¸´å¤æ‚çš„æ··æ‚æ•ˆåº”å’Œé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ï¼Œå¯¼è‡´è¯„ä¼°ç»“æœä¸å¤Ÿå‡†ç¡®ã€‚
2. æœ¬æ–‡æå‡ºä¸€ç§å› æœè¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å°†åŸºå‡†æ€§èƒ½å»ºæ¨¡ä¸ºæ½œåœ¨èƒ½åŠ›å› å­çš„çº¿æ€§å˜æ¢æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. åœ¨å¯¹1500å¤šä¸ªæ¨¡å‹è¿›è¡Œè¯„ä¼°åï¼Œå‘ç°äº†ä¸€ä¸ªä¸‰èŠ‚ç‚¹çš„çº¿æ€§å› æœç»“æ„ï¼Œæ­ç¤ºäº†æ½œåœ¨èƒ½åŠ›ä¹‹é—´çš„å› æœå…³ç³»ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¯­è¨€æ¨¡å‹èƒ½åŠ›çš„å‡†ç¡®è¯„ä¼°å¯¹äºæ¨¡å‹å¼€å‘è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•åœ¨å› æœè¯„ä¼°ä¸­é¢ä¸´å¤æ‚çš„æ··æ‚æ•ˆåº”å’Œé«˜æ˜‚çš„è®¡ç®—æˆæœ¬ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å› æœè¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œå°†è§‚å¯Ÿåˆ°çš„åŸºå‡†æ€§èƒ½å»ºæ¨¡ä¸ºå°‘æ•°æ½œåœ¨èƒ½åŠ›å› å­çš„çº¿æ€§å˜æ¢ã€‚é€šè¿‡æ§åˆ¶åŸºç¡€æ¨¡å‹ä½œä¸ºå…±åŒæ··æ‚å› ç´ ï¼Œè¯†åˆ«å‡ºè¿™äº›æ½œåœ¨å› å­ä¹‹é—´çš„å› æœå…³ç³»ã€‚æˆ‘ä»¬åœ¨åŒ…å«1500å¤šä¸ªæ¨¡å‹çš„ç»¼åˆæ•°æ®é›†ä¸Šåº”ç”¨è¯¥æ–¹æ³•ï¼Œå‘ç°äº†ä¸€ä¸ªç®€æ´çš„ä¸‰èŠ‚ç‚¹çº¿æ€§å› æœç»“æ„ï¼Œå¯é åœ°è§£é‡Šäº†è§‚å¯Ÿåˆ°çš„æ€§èƒ½å˜åŒ–ï¼Œå¹¶æ­ç¤ºäº†ä»ä¸€èˆ¬é—®é¢˜è§£å†³èƒ½åŠ›åˆ°æ•°å­¦æ¨ç†èƒ½åŠ›çš„æ˜ç¡®å› æœæ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯­è¨€æ¨¡å‹èƒ½åŠ›è¯„ä¼°ä¸­çš„å› æœå…³ç³»è¯†åˆ«é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ç”±äºæ··æ‚æ•ˆåº”å’Œè®¡ç®—æˆæœ¬é«˜ï¼Œéš¾ä»¥å‡†ç¡®è¯„ä¼°æ¨¡å‹èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå› æœè¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡æ§åˆ¶åŸºç¡€æ¨¡å‹çš„å½±å“ï¼Œå°†è§‚å¯Ÿåˆ°çš„æ€§èƒ½è§†ä¸ºæ½œåœ¨èƒ½åŠ›å› å­çš„çº¿æ€§å˜æ¢ï¼Œä»è€Œè¯†åˆ«å› æœå…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ã€æ½œåœ¨å› å­å»ºæ¨¡å’Œå› æœå…³ç³»è¯†åˆ«ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†åŒ…å«1500å¤šä¸ªæ¨¡å‹çš„è¯„ä¼°æ•°æ®ï¼Œç„¶åé€šè¿‡çº¿æ€§å˜æ¢å»ºæ¨¡æ½œåœ¨å› å­ï¼Œæœ€åè¯†åˆ«å› æœç»“æ„ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºé€šè¿‡æ§åˆ¶åŸºç¡€æ¨¡å‹çš„å½±å“ï¼Œè¯†åˆ«å‡ºæ½œåœ¨èƒ½åŠ›å› å­ä¹‹é—´çš„å› æœå…³ç³»ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„è¯„ä¼°æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨çº¿æ€§å˜æ¢æ¥æè¿°æ½œåœ¨å› å­ï¼Œç¡®ä¿å› æœå…³ç³»çš„å¯è¯†åˆ«æ€§ï¼ŒåŒæ—¶åœ¨æ•°æ®å¤„ç†å’Œæ¨¡å‹è®­ç»ƒä¸­ï¼Œä¸¥æ ¼æ§åˆ¶åŸºç¡€æ¨¡å‹çš„å˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„å› æœè¡¨ç¤ºå­¦ä¹ æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ½œåœ¨èƒ½åŠ›å› å­ä¹‹é—´çš„å› æœå…³ç³»ã€‚é€šè¿‡åˆ†æ1500å¤šä¸ªæ¨¡å‹çš„æ€§èƒ½ï¼Œå‘ç°äº†ä¸€ä¸ªä¸‰èŠ‚ç‚¹çš„çº¿æ€§å› æœç»“æ„ï¼Œå¯é åœ°è§£é‡Šäº†æ€§èƒ½å˜åŒ–ï¼Œå±•ç¤ºäº†ä»é—®é¢˜è§£å†³èƒ½åŠ›åˆ°æ•°å­¦æ¨ç†èƒ½åŠ›çš„æ˜ç¡®å› æœè·¯å¾„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ¨¡å‹è¯„ä¼°å’Œäººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¼€å‘ã€‚é€šè¿‡å‡†ç¡®è¯†åˆ«æ¨¡å‹èƒ½åŠ›çš„å› æœå…³ç³»ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´æœ‰æ•ˆåœ°ä¼˜åŒ–å’Œæ”¹è¿›è¯­è¨€æ¨¡å‹ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›æ­¥ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å…¶ä»–é¢†åŸŸçš„æ¨¡å‹è¯„ä¼°ä¸­å¾—åˆ°åº”ç”¨ï¼Œæå‡è¯„ä¼°çš„ç§‘å­¦æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Faithful evaluation of language model capabilities is crucial for deriving actionable insights that can inform model development. However, rigorous causal evaluations in this domain face significant methodological challenges, including complex confounding effects and prohibitive computational costs associated with extensive retraining. To tackle these challenges, we propose a causal representation learning framework wherein observed benchmark performance is modeled as a linear transformation of a few latent capability factors. Crucially, these latent factors are identified as causally interrelated after appropriately controlling for the base model as a common confounder. Applying this approach to a comprehensive dataset encompassing over 1500 models evaluated across six benchmarks from the Open LLM Leaderboard, we identify a concise three-node linear causal structure that reliably explains the observed performance variations. Further interpretation of this causal structure provides substantial scientific insights beyond simple numerical rankings: specifically, we reveal a clear causal direction starting from general problem-solving capabilities, advancing through instruction-following proficiency, and culminating in mathematical reasoning ability. Our results underscore the essential role of carefully controlling base model variations during evaluation, a step critical to accurately uncovering the underlying causal relationships among latent model capabilities.

