---
layout: default
title: FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models
---

# FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14824" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14824v1</a>
  <a href="https://arxiv.org/pdf/2506.14824.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14824v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14824v1', 'FedNano: Toward Lightweight Federated Tuning for Pretrained Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yao Zhang, Hewei Gao, Haokun Chen, Weiguo Li, Yunpu Ma, Volker Tresp

**åˆ†ç±»**: cs.LG, cs.AI, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12

**å¤‡æ³¨**: 12 pages, 3 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFedNanoä»¥è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„è½»é‡åŒ–è”é‚¦è°ƒä¼˜é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `è½»é‡åŒ–è°ƒä¼˜` `éšç§ä¿æŠ¤` `æ¨¡å‹é€‚åº”æ€§` `ä½ç§©é€‚åº”` `å»ä¸­å¿ƒåŒ–AI` `NanoEdgeæ¨¡å—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è”é‚¦å­¦ä¹ æ–¹æ³•å‡è®¾å®¢æˆ·ç«¯èƒ½å¤Ÿéƒ¨ç½²å®Œæ•´çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç”±äºæ¨¡å‹è§„æ¨¡åºå¤§å’Œé€šä¿¡éœ€æ±‚é«˜ï¼Œè¿™ä¸€å‡è®¾éš¾ä»¥æˆç«‹ã€‚
2. FedNanoæ¡†æ¶é€šè¿‡å°†å¤§è¯­è¨€æ¨¡å‹é›†ä¸­åœ¨æœåŠ¡å™¨ä¸Šï¼Œå¹¶å¼•å…¥è½»é‡çº§çš„NanoEdgeæ¨¡å—ï¼Œå®ç°äº†å®¢æˆ·ç«¯çš„ç‰¹å®šé€‚åº”ï¼Œæ˜¾è‘—é™ä½äº†å®¢æˆ·ç«¯çš„å­˜å‚¨å’Œé€šä¿¡å¼€é”€ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFedNanoåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„è”é‚¦å­¦ä¹ åŸºçº¿ï¼ŒæˆåŠŸè§£å†³äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¯æ‰©å±•æ€§ä¸éšç§ä¿æŠ¤é—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤šæ¨¡æ€æ¨ç†å’Œè·¨æ¨¡æ€æ£€ç´¢ç­‰ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºåˆ†å¸ƒå¼å¤šæ¨¡æ€æ•°æ®å’Œä¸¥æ ¼çš„éšç§è¦æ±‚ï¼Œå®é™…éƒ¨ç½²é¢ä¸´æŒ‘æˆ˜ã€‚è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰é€šè¿‡ä¸é›†ä¸­æ•°æ®å®ç°åä½œæ¨¡å‹è®­ç»ƒï¼Œä½†åœ¨MLLMsä¸­å®ç°FLå­˜åœ¨é«˜è®¡ç®—éœ€æ±‚ã€å®¢æˆ·ç«¯èƒ½åŠ›æœ‰é™ã€é€šä¿¡æˆæœ¬é«˜å’Œå®¢æˆ·ç«¯æ•°æ®å¼‚æ„ç­‰é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰FLæ–¹æ³•å‡è®¾å®¢æˆ·ç«¯éƒ¨ç½²å®Œæ•´æ¨¡å‹ï¼Œè¿™åœ¨å¤§è§„æ¨¡MLLMsä¸­ä¸å†é€‚ç”¨ã€‚ä¸ºäº†è§£å†³è¿™äº›é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†FedNanoï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå°†LLMé›†ä¸­åœ¨æœåŠ¡å™¨ä¸Šçš„FLæ¡†æ¶ï¼ŒåŒæ—¶å¼•å…¥äº†NanoEdgeï¼Œä¸€ä¸ªç”¨äºå®¢æˆ·ç«¯ç‰¹å®šé€‚åº”çš„è½»é‡çº§æ¨¡å—ã€‚NanoEdgeé‡‡ç”¨ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨ã€è¿æ¥å™¨å’Œå¯è®­ç»ƒçš„ä½ç§©é€‚åº”NanoAdaptersï¼Œæ˜¾è‘—å‡å°‘äº†å®¢æˆ·ç«¯å­˜å‚¨éœ€æ±‚å’Œé€šä¿¡å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼ŒFedNanoåœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰FLåŸºçº¿ï¼Œä¿ƒè¿›äº†å¯æ‰©å±•çš„å»ä¸­å¿ƒåŒ–å¤šæ¨¡æ€AIç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨è”é‚¦å­¦ä¹ ä¸­çš„åº”ç”¨æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç”±äºæ¨¡å‹è§„æ¨¡åºå¤§å¯¼è‡´çš„å®¢æˆ·ç«¯éƒ¨ç½²å›°éš¾å’Œé«˜é€šä¿¡æˆæœ¬çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾å®¢æˆ·ç«¯èƒ½å¤Ÿæ‰¿è½½å®Œæ•´æ¨¡å‹ï¼Œä½†è¿™åœ¨å®é™…ä¸­å¹¶ä¸æˆç«‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFedNanoçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤§è¯­è¨€æ¨¡å‹é›†ä¸­åœ¨æœåŠ¡å™¨ä¸Šï¼ŒåŒæ—¶åœ¨å®¢æˆ·ç«¯å¼•å…¥è½»é‡çº§çš„NanoEdgeæ¨¡å—ï¼Œä»¥å®ç°é’ˆå¯¹ç‰¹å®šå®¢æˆ·ç«¯çš„é€‚åº”ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼ŒFedNanoèƒ½å¤Ÿæ˜¾è‘—å‡å°‘å®¢æˆ·ç«¯çš„å­˜å‚¨éœ€æ±‚å’Œé€šä¿¡å¼€é”€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFedNanoçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æœåŠ¡å™¨ç«¯çš„LLMå’Œå®¢æˆ·ç«¯çš„NanoEdgeæ¨¡å—ã€‚NanoEdgeæ¨¡å—ç”±ç‰¹å®šæ¨¡æ€çš„ç¼–ç å™¨ã€è¿æ¥å™¨å’Œå¯è®­ç»ƒçš„NanoAdaptersç»„æˆï¼Œè´Ÿè´£å¤„ç†å®¢æˆ·ç«¯ç‰¹å®šçš„æ•°æ®å’Œä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šFedNanoçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†NanoEdgeæ¨¡å—ï¼Œä½¿å¾—å®¢æˆ·ç«¯æ— éœ€éƒ¨ç½²å®Œæ•´çš„LLMï¼Œä»è€Œå‡å°‘äº†95%çš„å­˜å‚¨éœ€æ±‚ï¼Œå¹¶å°†é€šä¿¡å¼€é”€é™åˆ¶åœ¨æ¨¡å‹å‚æ•°çš„0.01%ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—åœ¨å¼‚æ„å®¢æˆ·ç«¯æ•°æ®å’Œèµ„æºå—é™çš„æƒ…å†µä¸‹ï¼Œä»èƒ½æœ‰æ•ˆè¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼ŒNanoEdgeæ¨¡å—é‡‡ç”¨ä½ç§©é€‚åº”çš„NanoAdaptersï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒæ¨¡æ€çš„æ•°æ®è¿›è¡Œçµæ´»è°ƒæ•´ã€‚æ­¤å¤–ï¼Œè®¾è®¡ä¸­è¿˜è€ƒè™‘äº†æŸå¤±å‡½æ•°çš„ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒå®¢æˆ·ç«¯ä¸Šçš„é€‚åº”æ€§å’Œæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFedNanoåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰çš„è”é‚¦å­¦ä¹ æ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šæå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒFedNanoåœ¨é€šä¿¡å¼€é”€ä¸Šå‡å°‘äº†95%ï¼Œå¹¶ä¸”åœ¨å®¢æˆ·ç«¯å­˜å‚¨éœ€æ±‚ä¸Šé™ä½äº†95%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FedNanoçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦ä¿æŠ¤ç”¨æˆ·éšç§çš„å¤šæ¨¡æ€AIç³»ç»Ÿä¸­ï¼Œå¦‚åŒ»ç–—ã€é‡‘èå’Œæ™ºèƒ½å®¶å±…ç­‰é¢†åŸŸã€‚é€šè¿‡å®ç°è½»é‡åŒ–çš„è”é‚¦è°ƒä¼˜ï¼ŒFedNanoèƒ½å¤Ÿä¿ƒè¿›è¿™äº›é¢†åŸŸä¸­AIæŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ï¼ŒåŒæ—¶æ»¡è¶³æ•°æ®éšç§å’Œå®‰å…¨çš„è¦æ±‚ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) excel in tasks like multimodal reasoning and cross-modal retrieval but face deployment challenges in real-world scenarios due to distributed multimodal data and strict privacy requirements. Federated Learning (FL) offers a solution by enabling collaborative model training without centralizing data. However, realizing FL for MLLMs presents significant challenges, including high computational demands, limited client capacity, substantial communication costs, and heterogeneous client data. Existing FL methods assume client-side deployment of full models, an assumption that breaks down for large-scale MLLMs due to their massive size and communication demands. To address these limitations, we propose FedNano, the first FL framework that centralizes the LLM on the server while introducing NanoEdge, a lightweight module for client-specific adaptation. NanoEdge employs modality-specific encoders, connectors, and trainable NanoAdapters with low-rank adaptation. This design eliminates the need to deploy LLM on clients, reducing client-side storage by 95%, and limiting communication overhead to only 0.01% of the model parameters. By transmitting only compact NanoAdapter updates, FedNano handles heterogeneous client data and resource constraints while preserving privacy. Experiments demonstrate that FedNano outperforms prior FL baselines, bridging the gap between MLLM scale and FL feasibility, and enabling scalable, decentralized multimodal AI systems.

