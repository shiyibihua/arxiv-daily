---
layout: default
title: Foundation Models for Causal Inference via Prior-Data Fitted Networks
---

# Foundation Models for Causal Inference via Prior-Data Fitted Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10914" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.10914v2</a>
  <a href="https://arxiv.org/pdf/2506.10914.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10914v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10914v2', 'Foundation Models for Causal Inference via Prior-Data Fitted Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuchen Ma, Dennis Frauen, Emil Javurek, Stefan Feuerriegel

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-12 (æ›´æ–°: 2025-09-29)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCausalFMä»¥è§£å†³å› æœæ¨æ–­ä¸­çš„æ¨¡å‹è®­ç»ƒé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœæ¨æ–­` `è´å¶æ–¯æ¨æ–­` `å…ˆéªŒæ•°æ®æ‹Ÿåˆç½‘ç»œ` `ç»“æ„å› æœæ¨¡å‹` `æœºå™¨å­¦ä¹ ` `ç¥ç»ç½‘ç»œ` `æ•°æ®ç”Ÿæˆ` `ä¸Šä¸‹æ–‡å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å› æœæ¨æ–­æ–¹æ³•åœ¨æ¨¡å‹è®­ç»ƒå’Œæ¨æ–­å‡†ç¡®æ€§ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”å¤æ‚çš„å› æœå…³ç³»ã€‚
2. CausalFMæ¡†æ¶é€šè¿‡æ„å»ºåŸºäºç»“æ„å› æœæ¨¡å‹çš„è´å¶æ–¯å…ˆéªŒï¼Œç»“åˆå› æœå¯å‘çš„è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œæä¾›äº†ä¸€ç§æ–°çš„å› æœæ¨æ–­æ–¹æ³•ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒCausalFMåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ æ€§èƒ½ä¸Šä¼˜äºä¼ ç»ŸåŸºçº¿ï¼Œå±•ç¤ºäº†å…¶åœ¨å› æœæ¨æ–­ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºCausalFMçš„æ¡†æ¶ï¼Œç”¨äºåœ¨å„ç§å› æœæ¨æ–­åœºæ™¯ä¸­è®­ç»ƒåŸºäºå…ˆéªŒæ•°æ®æ‹Ÿåˆç½‘ç»œï¼ˆPFNsï¼‰çš„åŸºç¡€æ¨¡å‹ã€‚PFNsæ˜¯åŸºäºé¢„å…ˆæŒ‡å®šçš„å…ˆéªŒåˆ†å¸ƒç”Ÿæˆçš„åˆæˆæ•°æ®è¿›è¡Œé¢„è®­ç»ƒçš„å˜æ¢å™¨ï¼Œèƒ½å¤Ÿé€šè¿‡ä¸Šä¸‹æ–‡å­¦ä¹ å®ç°è´å¶æ–¯æ¨æ–­ã€‚æˆ‘ä»¬å½¢å¼åŒ–äº†åŸºäºç»“æ„å› æœæ¨¡å‹ï¼ˆSCMsï¼‰æ„å»ºå› æœæ¨æ–­çš„è´å¶æ–¯å…ˆéªŒï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°å‹çš„å…ˆéªŒåˆ†å¸ƒï¼Œåˆ©ç”¨å› æœå¯å‘çš„è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œä½¿CausalFMèƒ½å¤Ÿåœ¨å¤šç§è®¾ç½®ä¸‹è¿›è¡Œè´å¶æ–¯å› æœæ¨æ–­ã€‚å®éªŒè¯æ˜ï¼ŒCausalFMåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ æ€§èƒ½ä¸Šä¸ä¸“é—¨ä¸ºç‰¹å®šä»»åŠ¡è®­ç»ƒçš„åŸºçº¿ç›¸æ¯”è¡¨ç°å‡ºç«äº‰åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å› æœæ¨æ–­ä¸­æ¨¡å‹è®­ç»ƒçš„æŒ‘æˆ˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆå¤„ç†å¤æ‚çš„å› æœå…³ç³»ï¼Œå¯¼è‡´æ¨æ–­ç»“æœä¸å‡†ç¡®æˆ–ä¸å¯é ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCausalFMæ¡†æ¶é€šè¿‡å¼•å…¥åŸºäºç»“æ„å› æœæ¨¡å‹çš„è´å¶æ–¯å…ˆéªŒï¼Œç»“åˆå› æœå¯å‘çš„è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œæä¾›äº†ä¸€ç§çµæ´»ä¸”æœ‰æ•ˆçš„å› æœæ¨æ–­æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨å¤šç§å› æœæ¨æ–­åœºæ™¯ä¸­è¿›è¡Œæœ‰æ•ˆå­¦ä¹ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCausalFMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®ç”Ÿæˆã€å…ˆéªŒæ„å»ºã€æ¨¡å‹è®­ç»ƒå’Œæ¨æ–­å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆåˆæˆæ•°æ®ï¼Œç„¶åæ„å»ºè´å¶æ–¯å…ˆéªŒï¼Œæ¥ç€è®­ç»ƒPFNæ¨¡å‹ï¼Œæœ€åè¿›è¡Œå› æœæ¨æ–­ã€‚

**å…³é”®åˆ›æ–°**ï¼šCausalFMçš„ä¸»è¦åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„å…ˆéªŒåˆ†å¸ƒï¼Œåˆ©ç”¨å› æœå¯å‘çš„è´å¶æ–¯ç¥ç»ç½‘ç»œï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å¤šç§å› æœæ¨æ–­è®¾ç½®ä¸‹è¿›è¡Œæœ‰æ•ˆçš„è´å¶æ–¯æ¨æ–­ï¼Œè¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å› æœæ¨æ–­æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œä»¥ä¼˜åŒ–å› æœæ¨æ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ï¼Œå…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCausalFMåœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…¶æ€§èƒ½ä¸ä¸“é—¨è®­ç»ƒçš„åŸºçº¿ç›¸æ¯”å…·æœ‰ç«äº‰åŠ›ï¼Œå…·ä½“æå‡å¹…åº¦åœ¨å¤šä¸ªå› æœæ¨æ–­åœºæ™¯ä¸­å‡è¾¾åˆ°äº†æ˜¾è‘—æ°´å¹³ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

CausalFMæ¡†æ¶åœ¨åŒ»å­¦ã€ç»æµå­¦ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œèƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æ›´å‡†ç¡®åœ°è¿›è¡Œå› æœæ¨æ–­ï¼Œè¿›è€Œæ”¹å–„å†³ç­–è¿‡ç¨‹å’Œæ”¿ç­–åˆ¶å®šã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶å¯èƒ½ä¼šæ¨åŠ¨å› æœæ¨æ–­æ–¹æ³•çš„è¿›ä¸€æ­¥å‘å±•ï¼Œæå‡ç›¸å…³é¢†åŸŸçš„ç ”ç©¶æ°´å¹³ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Prior-data fitted networks (PFNs) have recently been proposed as a promising way to train tabular foundation models. PFNs are transformers that are pre-trained on synthetic data generated from a prespecified prior distribution and that enable Bayesian inference through in-context learning. In this paper, we introduce CausalFM, a comprehensive framework for training PFN-based foundation models in various causal inference settings. First, we formalize the construction of Bayesian priors for causal inference based on structural causal models (SCMs) in a principled way and derive necessary criteria for the validity of such priors. Building on this, we propose a novel family of prior distributions using causality-inspired Bayesian neural networks that enable CausalFM to perform Bayesian causal inference in various settings, including for back-door, front-door, and instrumental variable adjustment. Finally, we instantiate CausalFM and explicitly train models to perform in-context learning in these settings. We show that CausalFM achieves competitive in-context learning performance even when compared to baselines that are specifically trained for the task at hand. In sum, our framework can be used as a general recipe to train foundation models for various causal inference settings. In contrast to the current state-of-the-art in causal inference, CausalFM offers a novel paradigm with the potential to fundamentally change how practitioners perform causal inference in medicine, economics, and other disciplines.

