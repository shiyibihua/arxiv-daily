---
layout: default
title: GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models
---

# GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.10946" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.10946v2</a>
  <a href="https://arxiv.org/pdf/2506.10946.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.10946v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.10946v2', 'GUARD: Guided Unlearning and Retention via Data Attribution for Large Language Models')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Peizhi Niu, Evelyn Ma, Huiting Zhou, Duo Zhou, Huan Zhang, S. Rasoul Etesami, Olgica Milenkovic

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-12 (Êõ¥Êñ∞: 2025-10-22)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫GUARDÊ°ÜÊû∂‰ª•Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÁöÑÈùûÊÑèÂõæÈÅóÂøòÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂèçÂ≠¶‰π†` `Êï∞ÊçÆÂΩíÂõ†` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `Áü•ËØÜ‰øùÁïô` `ÈöêÁßÅ‰øùÊä§` `ÂêàËßÑÊÄß` `Êú∫Âô®Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèçÂ≠¶‰π†ÊñπÊ≥ïÂ∏∏Â∏∏ÂØºËá¥ÈùûÊÑèÂõæÈÅóÂøòÔºåÂΩ±ÂìçÊ®°ÂûãÊïàÁî®ÂíåÁü•ËØÜ‰øùÁïô„ÄÇ
2. GUARDÊ°ÜÊû∂ÈÄöËøáÂºïÂÖ•Êï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèÂíåËá™ÈÄÇÂ∫îÂèçÂ≠¶‰π†ÊùÉÈáçÔºå‰ºòÂåñ‰∫ÜÂèçÂ≠¶‰π†ËøáÁ®ãÔºåÂáèÂ∞ë‰∫ÜÊÑèÂ§ñÁöÑ‰øùÁïôÊçüÂ§±„ÄÇ
3. Âú®TOFUÂíåMUSEÂü∫ÂáÜÊµãËØï‰∏≠ÔºåGUARDÂú®‰øùÁïôÈõÜÁöÑÊïàÁî®ÊçüÂ§±ÂáèÂ∞ë‰∫Ü194.92%ÔºåÁü•ËØÜ‰øùÁïôÁéáÊèêÈ´ò‰∫Ü16.20%„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®Â§ßËØ≠Ë®ÄÊ®°Âûã‰∏≠ÔºåÂèçÂ≠¶‰π†ÂèòÂæóË∂äÊù•Ë∂äÈáçË¶ÅÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂêàËßÑÊÄß„ÄÅÁâàÊùÉ‰øùÊä§ÂíåÈöêÁßÅÈóÆÈ¢ò‰∏ä„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂú®ÂèçÂ≠¶‰π†ËøáÁ®ã‰∏≠Â∏∏Â∏∏ÂØºËá¥ÈùûÊÑèÂõæÈÅóÂøòÔºåÂç≥Âà†Èô§ÁâπÂÆöÊï∞ÊçÆÊó∂ÊÑèÂ§ñÊçüÂÆ≥Ê®°ÂûãÁöÑÊïàÁî®„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜGUARDÊ°ÜÊû∂ÔºåÈÄöËøáÂºïÂÖ•ËΩªÈáèÁ∫ßÁöÑÊï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèÔºåÈáèÂåñÈÅóÂøòÈõÜ‰∏é‰øùÁïôÈõÜ‰πãÈó¥ÁöÑÂØπÈΩêÁ®ãÂ∫¶ÔºåÂπ∂ËÆæËÆ°‰∫ÜËá™ÈÄÇÂ∫îÁöÑÈùûÂùáÂåÄÂèçÂ≠¶‰π†ÊùÉÈáçÔºå‰ªéËÄåÂáèËΩªÈùûÊÑèÂõæÁöÑ‰øùÁïôÊçüÂ§±„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåGUARDÂú®Â§ö‰∏™Â§ßËØ≠Ë®ÄÊ®°ÂûãÊû∂ÊûÑ‰∏äÊòæËëóÊèêÈ´ò‰∫ÜÁü•ËØÜ‰øùÁïôÁéáÔºåÂêåÊó∂‰øùÊåÅ‰∫Ü‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÂΩìÁöÑÈÅóÂøòÊåáÊ†á„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§ßËØ≠Ë®ÄÊ®°ÂûãÂèçÂ≠¶‰π†‰∏≠ÁöÑÈùûÊÑèÂõæÈÅóÂøòÈóÆÈ¢òÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Âà†Èô§È´òÂΩ±ÂìçÊï∞ÊçÆÊó∂ÔºåÂ∏∏Â∏∏ÂØºËá¥Ê®°Âûã‰øùÁïôÊúâ‰ª∑ÂÄº‰ø°ÊÅØÁöÑËÉΩÂäõ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöGUARDÊ°ÜÊû∂ÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÂºïÂÖ•ËΩªÈáèÁ∫ßÁöÑÊï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèÔºåÈáèÂåñÈÅóÂøòÈõÜ‰∏é‰øùÁïôÈõÜ‰πãÈó¥ÁöÑÂØπÈΩêÁ®ãÂ∫¶ÔºåÂπ∂Ê†πÊçÆÂΩíÂõ†ÂæóÂàÜ‰∏∫Ê†∑Êú¨ÂàÜÈÖçËá™ÈÄÇÂ∫îÁöÑÂèçÂ≠¶‰π†ÊùÉÈáçÔºå‰ªéËÄå‰ºòÂåñÂèçÂ≠¶‰π†ËøáÁ®ã„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöGUARDÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèÊ®°Âùó„ÄÅÂèçÂ≠¶‰π†ÊùÉÈáçÂàÜÈÖçÊ®°ÂùóÂíåÂèçÂ≠¶‰π†ÁõÆÊ†áËÆæËÆ°„ÄÇÈ¶ñÂÖàÔºåÈÄöËøáÊï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèËØÑ‰º∞Ê†∑Êú¨ÁöÑÈáçË¶ÅÊÄßÔºåÁÑ∂ÂêéÊ†πÊçÆÈáçË¶ÅÊÄßË∞ÉÊï¥ÂèçÂ≠¶‰π†ÊùÉÈáçÔºåÊúÄÂêé‰ºòÂåñÂèçÂ≠¶‰π†ÁõÆÊ†á‰ª•ÂáèÂ∞ëÈùûÊÑèÂõæ‰øùÁïôÊçüÂ§±„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöGUARDÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜËΩªÈáèÁ∫ßÁöÑ‰ª£ÁêÜÊï∞ÊçÆÂΩíÂõ†Â∫¶ÈáèÂíåËá™ÈÄÇÂ∫îÁöÑÈùûÂùáÂåÄÂèçÂ≠¶‰π†ÊùÉÈáçÂàÜÈÖçÊú∫Âà∂ÔºåËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑÂùáÂåÄÊùÉÈáçÂàÜÈÖçÂΩ¢Êàê‰∫ÜÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆæËÆ°‰∏≠ÔºåGUARD‰ΩøÁî®‰∫Ü‰ª£ÁêÜÂΩíÂõ†ÂæóÂàÜÊù•ËØÑ‰º∞Ê†∑Êú¨ÁöÑÈáçË¶ÅÊÄßÔºåÂπ∂Ê†πÊçÆËøô‰∫õÂæóÂàÜÂä®ÊÄÅË∞ÉÊï¥ÂèçÂ≠¶‰π†ÊùÉÈáçÔºåÁ°Æ‰øùÂú®ÈÅóÂøòÈ´òÂΩ±ÂìçÊï∞ÊçÆÊó∂ÔºåÊ®°ÂûãÁöÑÁü•ËØÜ‰øùÁïôËÉΩÂäõÂæóÂà∞‰øùÈöú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

GUARDÂú®TOFU Retain Set‰∏äÂáèÂ∞ë‰∫ÜÈ´òËææ194.92%ÁöÑÊïàÁî®ÊçüÂ§±ÔºåÂêåÊó∂Âú®MUSE NEWS Retain Set‰∏äÊèêÈ´ò‰∫Ü16.20%ÁöÑÁü•ËØÜ‰øùÁïôÁéá„ÄÇ‰∏éÁé∞ÊúâÊúÄÂÖàËøõÁöÑÊñπÊ≥ïÁõ∏ÊØîÔºåGUARDÂú®ÈöêÁßÅÊçüÂ§±ÊñπÈù¢‰øùÊåÅ‰∫ÜÁõ∏ÂØπËæÉÂ∞èÁöÑÂ¢ûÂä†ÔºåÂ±ïÁé∞‰∫ÜÂÖ∂‰ºòË∂äÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

GUARDÊ°ÜÊû∂Âú®Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂèçÂ≠¶‰π†‰∏≠ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåÁâπÂà´ÊòØÂú®ÈúÄË¶ÅÈÅµÂæ™ÈöêÁßÅÊ≥ïËßÑÂíåÁâàÊùÉ‰øùÊä§ÁöÑÂú∫ÊôØ‰∏≠„ÄÇÈÄöËøá‰ºòÂåñÂèçÂ≠¶‰π†ËøáÁ®ãÔºåGUARDËÉΩÂ§üÂ∏ÆÂä©‰ºÅ‰∏öÂíåÊú∫ÊûÑÊõ¥Â•ΩÂú∞ÁÆ°ÁêÜÊï∞ÊçÆ‰ΩøÁî®ÔºåÁ°Æ‰øùÂêàËßÑÊÄßÔºåÂêåÊó∂‰øùÊåÅÊ®°ÂûãÁöÑÊÄßËÉΩÂíåÁü•ËØÜ‰øùÁïôÔºåÊú™Êù•ÂèØËÉΩÂú®Â§ö‰∏™È¢ÜÂüü‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Unlearning in large language models is becoming increasingly important due to regulatory compliance, copyright protection, and privacy concerns. However, a key challenge in LLM unlearning is unintended forgetting, where the removal of specific data inadvertently impairs the utility of the model and its retention of valuable, desired information. While prior work has primarily focused on architectural innovations, the influence of data-level factors on unlearning performance remains underexplored. As a result, existing methods often suffer from degraded retention when forgetting high-impact data. To address this problem, we propose GUARD, a novel framework for Guided Unlearning And Retention via Data attribution. At its core, GUARD introduces a lightweight proxy data attribution metric tailored for LLM unlearning, which quantifies the alignment between the Forget and Retain sets while remaining computationally efficient. Building on this, we design a novel unlearning objective that assigns adaptive, nonuniform unlearning weights to samples, inversely proportional to their proxy attribution scores. Through such a reallocation of unlearning power, GUARD mitigates unintended retention loss. We also provide rigorous theoretical guarantees that GUARD significantly improves retention while maintaining forgetting metrics comparable to prior methods. Extensive experiments on the TOFU and MUSE benchmarks across multiple LLM architectures demonstrate that GUARD reduces utility sacrifice on the TOFU Retain Set by up to 194.92 percent in terms of Truth Ratio when forgetting 10 percent of the training data, and improves knowledge retention on the MUSE NEWS Retain Set by 16.20 percent, with comparable or very moderate increases in privacy loss compared to state-of-the-art methods.

