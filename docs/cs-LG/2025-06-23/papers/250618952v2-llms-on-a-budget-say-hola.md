---
layout: default
title: LLMs on a Budget? Say HOLA
---

# LLMs on a Budget? Say HOLA

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.18952" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.18952v2</a>
  <a href="https://arxiv.org/pdf/2506.18952.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.18952v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.18952v2', 'LLMs on a Budget? Say HOLA')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zohaib Hasan Siddiqui, Jiechao Gao, Ebad Shabbir, Mohammad Anas Azeez, Rafiq Ali, Gautam Siddharth Kashyap, Usman Naseem

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23 (æ›´æ–°: 2025-10-09)

**å¤‡æ³¨**: Accepted at EMNLP 2025 (Industry Track)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºHOLAæ¡†æ¶ä»¥é«˜æ•ˆéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `è¾¹ç¼˜è®¡ç®—` `æ¨ç†ä¼˜åŒ–` `è‡ªé€‚åº”æ£€ç´¢` `ç»“æ„åŒ–å‰ªæ` `é‡åŒ–æŠ€æœ¯` `å®æ—¶åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹é¢ä¸´é«˜è®¡ç®—å’Œå†…å­˜éœ€æ±‚çš„æŒ‘æˆ˜ï¼Œé™åˆ¶äº†å®æ—¶åº”ç”¨çš„æ¨å¹¿ã€‚
2. HOLAæ¡†æ¶é€šè¿‡åˆ†å±‚æ¨æµ‹è§£ç å’Œè‡ªé€‚åº”æ£€ç´¢å¤æ‚åº¦è°ƒæ•´ï¼Œå®ç°äº†é«˜æ•ˆçš„LLMæ¨ç†å’Œéƒ¨ç½²ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒHOLAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå¹¶æœ‰æ•ˆé™ä½äº†è¾¹ç¼˜è®¾å¤‡çš„å»¶è¿Ÿå’Œå†…å­˜å ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å—åˆ°é«˜è®¡ç®—å’Œå†…å­˜éœ€æ±‚çš„é™åˆ¶ï¼Œè¿™å¯¹åŒ»ç–—ã€æ•™è‚²å’ŒåµŒå…¥å¼ç³»ç»Ÿç­‰å®æ—¶åº”ç”¨æ„æˆéšœç¢ã€‚ç°æœ‰çš„è§£å†³æ–¹æ¡ˆå¦‚é‡åŒ–ã€å‰ªæå’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ä»…æä¾›éƒ¨åˆ†ä¼˜åŒ–ï¼Œä¸”å¸¸å¸¸åœ¨é€Ÿåº¦æˆ–å‡†ç¡®æ€§ä¸Šå¦¥åã€‚æœ¬æ–‡æå‡ºHOLAï¼Œä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„LLMéƒ¨ç½²ã€‚HOLAå†…éƒ¨åˆ©ç”¨åˆ†å±‚æ¨æµ‹è§£ç ï¼ˆHSDï¼‰åŠ é€Ÿæ¨ç†è€Œä¸æŸå¤±è´¨é‡ï¼Œå¤–éƒ¨åˆ™é€šè¿‡AdaComp-RAGæ ¹æ®ä¸Šä¸‹æ–‡éœ€æ±‚è°ƒæ•´æ£€ç´¢å¤æ‚åº¦ã€‚ç»“åˆç»“æ„åŒ–å‰ªæï¼ˆLoRAï¼‰å’Œé‡åŒ–çš„LoBiï¼ŒHOLAåœ¨GSM8Kä¸Šå®ç°äº†17.6%çš„EMAï¼Œåœ¨ARCä¸Šå®ç°äº†10.5%çš„MCAï¼Œå¹¶åœ¨Jetson Nanoç­‰è¾¹ç¼˜è®¾å¤‡ä¸Šé™ä½äº†å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨ï¼Œè¯æ˜äº†å…¶å¯æ‰©å±•æ€§å’Œç”Ÿäº§å°±ç»ªæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šè¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹æ—¶é¢ä¸´çš„é«˜è®¡ç®—å’Œå†…å­˜éœ€æ±‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚é‡åŒ–å’Œå‰ªæè™½ç„¶æœ‰æ‰€å¸®åŠ©ï¼Œä½†å¾€å¾€æ— æ³•å…¼é¡¾é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šHOLAæ¡†æ¶é€šè¿‡å¼•å…¥åˆ†å±‚æ¨æµ‹è§£ç ï¼ˆHSDï¼‰å’Œè‡ªé€‚åº”æ£€ç´¢å¤æ‚åº¦ï¼ˆAdaComp-RAGï¼‰ï¼Œå®ç°äº†é«˜æ•ˆæ¨ç†ï¼ŒåŒæ—¶ä¿æŒæ¨¡å‹è´¨é‡ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸‹èƒ½å¤Ÿçµæ´»è°ƒæ•´è®¡ç®—èµ„æºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šHOLAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šåˆ†å±‚æ¨æµ‹è§£ç ï¼ˆHSDï¼‰ã€è‡ªé€‚åº”æ£€ç´¢å¤æ‚åº¦ï¼ˆAdaComp-RAGï¼‰å’Œç»“åˆç»“æ„åŒ–å‰ªæä¸é‡åŒ–çš„LoBiã€‚HSDè´Ÿè´£åŠ é€Ÿæ¨ç†ï¼ŒAdaComp-RAGæ ¹æ®ä¸Šä¸‹æ–‡éœ€æ±‚è°ƒæ•´æ£€ç´¢å¤æ‚åº¦ï¼Œè€ŒLoBiåˆ™ä¼˜åŒ–æ¨¡å‹çš„å­˜å‚¨å’Œè®¡ç®—æ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šHOLAçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†HSDä¸AdaComp-RAGç»“åˆï¼Œå½¢æˆä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¼˜åŒ–æ¡†æ¶ã€‚è¿™ç§ç»„åˆä¸ä»…æé«˜äº†æ¨ç†é€Ÿåº¦ï¼Œè¿˜ç¡®ä¿äº†æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œæ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å•ä¸€ä¼˜åŒ–æ–¹æ³•ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨HOLAä¸­ï¼ŒHSDé‡‡ç”¨äº†åˆ†å±‚çš„è§£ç ç­–ç•¥ï¼Œä»¥å‡å°‘è®¡ç®—å¤æ‚åº¦ï¼›AdaComp-RAGé€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–¹å¼åŠ¨æ€è°ƒæ•´æ£€ç´¢ç­–ç•¥ï¼›LoBiåˆ™ç»“åˆäº†ç»“æ„åŒ–å‰ªæï¼ˆLoRAï¼‰å’Œé‡åŒ–æŠ€æœ¯ï¼Œä»¥é™ä½å†…å­˜å ç”¨å’Œå»¶è¿Ÿã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

HOLAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒGSM8Kä¸Šå®ç°äº†17.6%çš„EMAï¼ŒARCä¸Šå®ç°äº†10.5%çš„MCAã€‚æ­¤å¤–ï¼ŒHOLAåœ¨Jetson Nanoç­‰è¾¹ç¼˜è®¾å¤‡ä¸Šæ˜¾è‘—é™ä½äº†å»¶è¿Ÿå’Œå†…å­˜ä½¿ç”¨ï¼Œè¯æ˜äº†å…¶é«˜æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

HOLAæ¡†æ¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—ã€æ•™è‚²å’ŒåµŒå…¥å¼ç³»ç»Ÿç­‰éœ€è¦å®æ—¶å¤„ç†çš„åœºæ™¯ã€‚é€šè¿‡åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šé«˜æ•ˆéƒ¨ç½²å¤§å‹è¯­è¨€æ¨¡å‹ï¼ŒHOLAèƒ½å¤Ÿæ”¯æŒæ™ºèƒ½åŠ©æ‰‹ã€å®æ—¶ç¿»è¯‘å’Œä¸ªæ€§åŒ–å­¦ä¹ ç­‰åº”ç”¨ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„æœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Running Large Language Models (LLMs) on edge devices is constrained by high compute and memory demands posing a barrier for real-time applications in sectors like healthcare, education, and embedded systems. Current solutions such as quantization, pruning, and retrieval-augmented generation (RAG) offer only partial optimizations and often compromise on speed or accuracy. We introduce HOLA, an end-to-end optimization framework for efficient LLM deployment. Internally, it leverages Hierarchical Speculative Decoding (HSD) for faster inference without quality loss. Externally, AdaComp-RAG adjusts retrieval complexity based on context needs. Together with LoBi, which blends structured pruning (LoRA) and quantization, HOLA delivers significant gains: 17.6% EMA on GSM8K, 10.5% MCA on ARC, and reduced latency and memory on edge devices like Jetson Nano--proving both scalable and production-ready.

