---
layout: default
title: Thought Anchors: Which LLM Reasoning Steps Matter?
---

# Thought Anchors: Which LLM Reasoning Steps Matter?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19143" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19143v4</a>
  <a href="https://arxiv.org/pdf/2506.19143.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19143v4" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19143v4', 'Thought Anchors: Which LLM Reasoning Steps Matter?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Paul C. Bogdan, Uzay Macar, Neel Nanda, Arthur Conmy

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-23 (æ›´æ–°: 2025-10-27)

**å¤‡æ³¨**: Paul C. Bogdan and Uzay Macar contributed equally to this work, and their listed order was determined by coinflip. Neel Nanda and Arthur Conmy contributed equally to this work as senior authors, and their listed order was determined by coinflip

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ€ç»´é”šç‚¹æ–¹æ³•ä»¥è§£æå¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨ç†è¿‡ç¨‹` `å¯è§£é‡Šæ€§` `æ€ç»´é”šç‚¹` `å› æœå…³ç³»åˆ†æ` `æ•°å­¦é—®é¢˜æ±‚è§£` `é»‘ç®±æ–¹æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•ä¸»è¦å…³æ³¨æ¨¡å‹çš„å•æ¬¡å‰å‘ä¼ é€’ï¼Œæ— æ³•æœ‰æ•ˆåˆ†ææ¨ç†è¿‡ç¨‹ä¸­çš„å¤šæ ‡è®°è®¡ç®—æ­¥éª¤ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§é»‘ç®±æ–¹æ³•ï¼Œé€šè¿‡åˆ†æå¥å­çš„åäº‹å®é‡è¦æ€§ï¼Œè¯†åˆ«å‡ºå¯¹æ¨ç†è½¨è¿¹å½±å“æ˜¾è‘—çš„å¥å­ï¼Œå³æ€ç»´é”šç‚¹ã€‚
3. é€šè¿‡æ¡ˆä¾‹ç ”ç©¶ï¼Œè®ºæ–‡å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨è§£å†³å¤æ‚æ•°å­¦é—®é¢˜æ—¶çš„ä¸€è‡´æ€§å’Œæœ‰æ•ˆæ€§ï¼Œæä¾›äº†æ·±å…¥ç†è§£æ¨ç†æ¨¡å‹çš„å·¥å…·ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰å‰æ²¿çš„å¤§å‹è¯­è¨€æ¨¡å‹ä¾èµ–æ¨ç†ä»¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¯è§£é‡Šæ€§æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸå­˜åœ¨å±€é™ï¼Œå› ä¸ºæ ‡å‡†æ–¹æ³•ä¸»è¦ç ”ç©¶æ¨¡å‹çš„å•æ¬¡å‰å‘ä¼ é€’ï¼Œè€Œéæ¨ç†è¿‡ç¨‹ä¸­å±•å¼€çš„å¤šæ ‡è®°è®¡ç®—æ­¥éª¤ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é»‘ç®±æ–¹æ³•ï¼Œé€šè¿‡åå¤ä»æ¨¡å‹ä¸­æŠ½æ ·æ›¿æ¢å¥å­ï¼Œè¿‡æ»¤å‡ºè¯­ä¹‰ä¸Šä¸åŒçš„å¥å­ï¼Œå¹¶ä»è¯¥ç‚¹ç»§ç»­æ¨ç†ï¼Œä»¥é‡åŒ–å¥å­å¯¹æœ€ç»ˆç­”æ¡ˆåˆ†å¸ƒçš„å½±å“ã€‚æˆ‘ä»¬å‘ç°æŸäº›å¥å­å¯¹æ¨ç†è½¨è¿¹å’Œæœ€ç»ˆç­”æ¡ˆæœ‰æ˜¾è‘—å½±å“ï¼Œç§°ä¹‹ä¸ºâ€œæ€ç»´é”šç‚¹â€ã€‚è¿™äº›å¥å­é€šå¸¸æ¶‰åŠè§„åˆ’æˆ–ä¸ç¡®å®šæ€§ç®¡ç†ï¼Œåç»­å¥å­çš„ä¸“é—¨æ³¨æ„åŠ›å¤´ä¼šæŒç»­å…³æ³¨æ€ç»´é”šç‚¹ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†åœ¨æ¨ç†è½¨è¿¹ä¸­æ£€æŸ¥å¥å­é—´å› æœå…³ç³»å¯ä»¥æ·±å…¥ç†è§£æ¨¡å‹è¡Œä¸ºï¼Œå¹¶ä¸ºé¢„æµ‹é—®é¢˜éš¾åº¦æä¾›äº†æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¼€æºå·¥å…·ï¼ˆthought-anchors.comï¼‰ç”¨äºå¯è§†åŒ–æˆ‘ä»¬æ–¹æ³•çš„è¾“å‡ºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¯è§£é‡Šæ€§æ–¹æ³•æ— æ³•æœ‰æ•ˆåˆ†æå¤§å‹è¯­è¨€æ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„å¤šæ ‡è®°è®¡ç®—æ­¥éª¤çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸åªå…³æ³¨å•æ¬¡å‰å‘ä¼ é€’ï¼Œå¯¼è‡´å¯¹æ¨ç†è¿‡ç¨‹çš„ç†è§£ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†æå¥å­çš„åäº‹å®é‡è¦æ€§ï¼Œè¯†åˆ«å‡ºå¯¹æ¨ç†è½¨è¿¹å’Œæœ€ç»ˆç­”æ¡ˆæœ‰æ˜¾è‘—å½±å“çš„å¥å­ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ­ç¤ºæ¨ç†è¿‡ç¨‹ä¸­çš„å…³é”®æ­¥éª¤ï¼Œå¸®åŠ©ç†è§£æ¨¡å‹çš„å†³ç­–æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¥å­æ›¿æ¢ã€è¯­ä¹‰è¿‡æ»¤å’Œæ¨ç†é“¾å»¶ç»­ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œä»æ¨¡å‹ä¸­æŠ½æ ·æ›¿æ¢å¥å­ï¼›å…¶æ¬¡ï¼Œè¿‡æ»¤å‡ºè¯­ä¹‰ä¸Šä¸åŒçš„å¥å­ï¼›æœ€åï¼Œä»æ›¿æ¢å¥å­å¼€å§‹ç»§ç»­æ¨ç†ï¼Œä»¥é‡åŒ–å…¶å¯¹æœ€ç»ˆç­”æ¡ˆçš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†â€œæ€ç»´é”šç‚¹â€çš„æ¦‚å¿µï¼Œè¿™äº›å¥å­åœ¨æ¨ç†è¿‡ç¨‹ä¸­èµ·åˆ°å…³é”®ä½œç”¨ï¼Œä¸”åç»­å¥å­ä¼šä¸“é—¨å…³æ³¨è¿™äº›é”šç‚¹ã€‚è¿™ä¸€å‘ç°ä¸ç°æœ‰æ–¹æ³•çš„å•ä¸€åˆ†æè§†è§’å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡è®¾è®¡äº†ç‰¹å®šçš„å¥å­æ›¿æ¢ç­–ç•¥å’Œè¯­ä¹‰è¿‡æ»¤æœºåˆ¶ï¼Œä»¥ç¡®ä¿æ›¿æ¢å¥å­åœ¨è¯­ä¹‰ä¸Šå…·æœ‰æ˜¾è‘—å·®å¼‚ã€‚æ­¤å¤–ï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›æœºåˆ¶è¢«ç”¨äºè¿½è¸ªå¥å­é—´çš„å› æœå…³ç³»ï¼Œè¿›ä¸€æ­¥å¢å¼ºäº†å¯¹æ¨ç†è¿‡ç¨‹çš„ç†è§£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«å‡ºå¯¹æ¨ç†è½¨è¿¹å½±å“æ˜¾è‘—çš„æ€ç»´é”šç‚¹ï¼Œä¸”åœ¨è§£å†³å¤æ‚æ•°å­¦é—®é¢˜æ—¶ï¼Œæ¨¡å‹çš„æ¨ç†ç»“æ„è¡¨ç°å‡ºä¸€è‡´æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæ¨¡å‹åœ¨å¤„ç†ä¸åŒé—®é¢˜æ—¶ï¼Œæ€ç»´é”šç‚¹çš„è¯†åˆ«ç‡æ˜¾è‘—æé«˜ï¼Œå±•ç¤ºäº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ï¼Œç ”ç©¶è€…å’Œå¼€å‘è€…å¯ä»¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œæé«˜å…¶åœ¨ç‰¹å®šä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œè¿›è€Œæ¨åŠ¨äººå·¥æ™ºèƒ½åœ¨å®é™…åº”ç”¨ä¸­çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current frontier large-language models rely on reasoning to achieve state-of-the-art performance. Many existing interpretability are limited in this area, as standard methods have been designed to study single forward passes of a model rather than the multi-token computational steps that unfold during reasoning. We argue that analyzing reasoning traces at the sentence level is a promising approach to understanding reasoning processes. We introduce a black-box method that measures each sentence's counterfactual importance by repeatedly sampling replacement sentences from the model, filtering for semantically different ones, and continuing the chain of thought from that point onwards to quantify the sentence's impact on the distribution of final answers. We discover that certain sentences can have an outsized impact on the trajectory of the reasoning trace and final answer. We term these sentences \textit{thought anchors}. These are generally planning or uncertainty management sentences, and specialized attention heads consistently attend from subsequent sentences to thought anchors. We further show that examining sentence-sentence causal links within a reasoning trace gives insight into a model's behavior. Such information can be used to predict a problem's difficulty and the extent different question domains involve sequential or diffuse reasoning. As a proof-of-concept, we demonstrate that our techniques together provide a practical toolkit for analyzing reasoning models by conducting a detailed case study of how the model solves a difficult math problem, finding that our techniques yield a consistent picture of the reasoning trace's structure. We provide an open-source tool (thought-anchors.com) for visualizing the outputs of our methods on further problems. The convergence across our methods shows the potential of sentence-level analysis for a deeper understanding of reasoning models.

