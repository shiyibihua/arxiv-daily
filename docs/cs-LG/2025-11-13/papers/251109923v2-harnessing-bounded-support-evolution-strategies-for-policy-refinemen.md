---
layout: default
title: Harnessing Bounded-Support Evolution Strategies for Policy Refinement
---

# Harnessing Bounded-Support Evolution Strategies for Policy Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2511.09923" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2511.09923v2</a>
  <a href="https://arxiv.org/pdf/2511.09923.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.09923v2" onclick="toggleFavorite(this, '2511.09923v2', 'Harnessing Bounded-Support Evolution Strategies for Policy Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ethan Hirschowitz, Fabio Ramos

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-11-13 (æ›´æ–°: 2025-11-14)

**å¤‡æ³¨**: 10 pages, 6 figures, to be published in Australasian Conference on Robotics and Automation (ACRA 2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸‰è§’åˆ†å¸ƒESç®—æ³•ï¼Œç”¨äºæå‡æœºå™¨äººç­–ç•¥çš„ç¨³å®šæ€§å’Œæ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¿›åŒ–ç­–ç•¥` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººæ“ä½œ` `ç­–ç•¥ä¼˜åŒ–` `ä¸‰è§’åˆ†å¸ƒ` `æ— æ¢¯åº¦ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸOn-policyå¼ºåŒ–å­¦ä¹ åœ¨æœºå™¨äººæ§åˆ¶ä¸­é¢ä¸´æ¢¯åº¦å™ªå£°å¤§ã€ä¿¡å·å¼±çš„é—®é¢˜ï¼Œå¯¼è‡´ç­–ç•¥æå‡å›°éš¾ã€‚
2. è®ºæ–‡æå‡ºä¸‰è§’åˆ†å¸ƒè¿›åŒ–ç­–ç•¥ï¼ˆTD-ESï¼‰ï¼Œåˆ©ç”¨æœ‰ç•Œä¸‰è§’å™ªå£°è¿›è¡Œå±€éƒ¨æ¢ç´¢ï¼Œå®ç°ç¨³å®šä¸”å¯å¹¶è¡Œçš„ç­–ç•¥ä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒTD-ESåœ¨æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æˆåŠŸç‡ï¼Œå¹¶é™ä½äº†æ–¹å·®ï¼Œä¼˜äºPPOç­‰åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç­–ç•¥æ¢¯åº¦å¼ºåŒ–å­¦ä¹ ä¸­ï¼Œæå‡æœºå™¨äººç­–ç•¥çš„æ€§èƒ½é€šå¸¸å—åˆ°å™ªå£°å’Œä½ä¿¡å·æ¢¯åº¦çš„é˜»ç¢ã€‚æœ¬æ–‡é‡æ–°å®¡è§†äº†è¿›åŒ–ç­–ç•¥ï¼ˆESï¼‰ï¼Œå¹¶é‡‡ç”¨æœ‰ç•Œã€åå‘ä¸‰è§’æ‰°åŠ¨æ¥å±€éƒ¨åŒ–æ¢ç´¢ï¼Œé€‚ç”¨äºç­–ç•¥ä¼˜åŒ–ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰è§’åˆ†å¸ƒESï¼ˆTD-ESï¼‰ï¼Œå®ƒå°†æœ‰ç•Œä¸‰è§’å™ªå£°ä¸ä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨ç›¸ç»“åˆï¼Œä»¥æä¾›ç¨³å®šã€å¯å¹¶è¡Œã€æ— æ¢¯åº¦çš„æ›´æ–°ã€‚åœ¨ä¸¤é˜¶æ®µæµç¨‹ä¸­â€”â€”PPOé¢„è®­ç»ƒï¼Œç„¶åæ˜¯TD-ESä¼˜åŒ–â€”â€”è¿™ä¿ç•™äº†æ—©æœŸçš„æ ·æœ¬æ•ˆç‡ï¼ŒåŒæ—¶å®ç°äº†ç¨³å¥çš„åæœŸå¢ç›Šã€‚åœ¨ä¸€ç³»åˆ—æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼ŒTD-ESç›¸å¯¹äºPPOå°†æˆåŠŸç‡æé«˜äº†26.5%ï¼Œå¹¶å¤§å¤§é™ä½äº†æ–¹å·®ï¼Œä¸ºå¯é çš„ä¼˜åŒ–æä¾›äº†ä¸€æ¡ç®€å•ã€è®¡ç®—é‡è½»çš„é€”å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººç­–ç•¥ä¼˜åŒ–ä¸­ï¼Œä¼ ç»ŸOn-policyå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆå¦‚PPOï¼‰é¢ä¸´çš„æ¢¯åº¦å™ªå£°å¤§ã€ä¿¡å·å¼±çš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜å¯¼è‡´ç­–ç•¥å­¦ä¹ ä¸ç¨³å®šï¼Œéš¾ä»¥è¾¾åˆ°æœ€ä¼˜æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨ç­–ç•¥ä¼˜åŒ–çš„åæœŸé˜¶æ®µã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥åœ¨æ ·æœ¬æ•ˆç‡å’Œä¼˜åŒ–æ•ˆæœä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¿›åŒ–ç­–ç•¥ï¼ˆESï¼‰ä½œä¸ºç­–ç•¥æ¢¯åº¦æ–¹æ³•çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶å¼•å…¥æœ‰ç•Œä¸‰è§’åˆ†å¸ƒå™ªå£°æ¥å¼•å¯¼æ¢ç´¢ã€‚é€šè¿‡é™åˆ¶æ¢ç´¢èŒƒå›´ï¼Œå¹¶ç»“åˆä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨ï¼ŒTD-ESèƒ½å¤Ÿæä¾›æ›´ç¨³å®šã€æ›´å¯é çš„ç­–ç•¥æ›´æ–°ï¼Œä»è€Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚è¿™ç§æ–¹æ³•æ—¨åœ¨åœ¨ä¿æŒæ—©æœŸæ ·æœ¬æ•ˆç‡çš„åŒæ—¶ï¼Œå®ç°åæœŸé˜¶æ®µçš„æ€§èƒ½æå‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTD-ESé‡‡ç”¨ä¸¤é˜¶æ®µçš„è®­ç»ƒæµç¨‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨PPOè¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥è·å¾—ä¸€ä¸ªåˆæ­¥çš„ã€ç›¸å¯¹è¾ƒå¥½çš„ç­–ç•¥ã€‚ç„¶åï¼Œä½¿ç”¨TD-ESå¯¹é¢„è®­ç»ƒçš„ç­–ç•¥è¿›è¡Œä¼˜åŒ–ã€‚TD-ESç®—æ³•æœ¬èº«åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š1) å¯¹ç­–ç•¥å‚æ•°æ·»åŠ ä¸‰è§’åˆ†å¸ƒå™ªå£°ï¼Œç”Ÿæˆå¤šä¸ªå€™é€‰ç­–ç•¥ï¼›2) ä½¿ç”¨è¿™äº›å€™é€‰ç­–ç•¥ä¸ç¯å¢ƒäº¤äº’ï¼Œæ”¶é›†æ ·æœ¬ï¼›3) ä½¿ç”¨ä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨è¯„ä¼°æ¯ä¸ªå€™é€‰ç­–ç•¥çš„æ€§èƒ½ï¼›4) æ ¹æ®æ€§èƒ½è¯„ä¼°ç»“æœï¼Œæ›´æ–°ç­–ç•¥å‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸‰è§’åˆ†å¸ƒè¿›åŒ–ç­–ç•¥ï¼ˆTD-ESï¼‰ï¼Œå®ƒç»“åˆäº†æœ‰ç•Œä¸‰è§’å™ªå£°å’Œä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨ã€‚ä¸ä¼ ç»Ÿçš„ESæ–¹æ³•ç›¸æ¯”ï¼ŒTD-ESä½¿ç”¨æœ‰ç•Œå™ªå£°ï¼Œé™åˆ¶äº†æ¢ç´¢èŒƒå›´ï¼Œä»è€Œæé«˜äº†ç­–ç•¥æ›´æ–°çš„ç¨³å®šæ€§ã€‚æ­¤å¤–ï¼Œä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨èƒ½å¤Ÿæ›´å‡†ç¡®åœ°ä¼°è®¡ç­–ç•¥æ¢¯åº¦ï¼Œä»è€ŒåŠ é€Ÿäº†å­¦ä¹ è¿‡ç¨‹ã€‚ä¸åŸºäºæ¢¯åº¦çš„æ–¹æ³•ç›¸æ¯”ï¼ŒTD-ESæ˜¯æ— æ¢¯åº¦çš„ï¼Œå› æ­¤é¿å…äº†æ¢¯åº¦å™ªå£°çš„å½±å“ã€‚

**å…³é”®è®¾è®¡**ï¼šTD-ESçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä¸‰è§’åˆ†å¸ƒä½œä¸ºå™ªå£°åˆ†å¸ƒï¼Œå…¶å‚æ•°ï¼ˆå¦‚ä¸Šä¸‹ç•Œï¼‰éœ€è¦æ ¹æ®å…·ä½“ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼›2) ä¸­å¿ƒæ’åºæœ‰é™å·®åˆ†ä¼°è®¡å™¨çš„å…·ä½“å®ç°æ–¹å¼ï¼ŒåŒ…æ‹¬é‡‡æ ·æ•°é‡å’Œæ’åºæ–¹æ³•ï¼›3) PPOé¢„è®­ç»ƒé˜¶æ®µçš„å­¦ä¹ ç‡ã€æŠ˜æ‰£å› å­ç­‰å‚æ•°ï¼›4) TD-ESä¼˜åŒ–é˜¶æ®µçš„å­¦ä¹ ç‡ã€å™ªå£°å¹…åº¦ç­‰å‚æ•°ã€‚è¿™äº›å‚æ•°çš„é€‰æ‹©ä¼šç›´æ¥å½±å“ç®—æ³•çš„æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒTD-ESåœ¨å¤šä¸ªæœºå™¨äººæ“ä½œä»»åŠ¡ä¸­æ˜¾è‘—ä¼˜äºPPOã€‚å…·ä½“è€Œè¨€ï¼ŒTD-ESç›¸å¯¹äºPPOå°†æˆåŠŸç‡å¹³å‡æé«˜äº†26.5%ï¼Œå¹¶ä¸”å¤§å¤§é™ä½äº†æ–¹å·®ï¼Œè¡¨æ˜TD-ESå…·æœ‰æ›´å¼ºçš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼ŒTD-ESåœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ä¹Ÿå…·æœ‰ä¼˜åŠ¿ï¼Œä¸ºå¯é çš„ç­–ç•¥ä¼˜åŒ–æä¾›äº†ä¸€æ¡ç®€å•ã€è®¡ç®—é‡è½»çš„é€”å¾„ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚é€šè¿‡TD-ESç®—æ³•ï¼Œå¯ä»¥æ˜¾è‘—æå‡æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„æ“ä½œèƒ½åŠ›å’Œé²æ£’æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ¨å¹¿åˆ°å…¶ä»–å¼ºåŒ–å­¦ä¹ é¢†åŸŸï¼Œä¾‹å¦‚æ¸¸æˆAIã€è‡ªåŠ¨é©¾é©¶ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Improving competent robot policies with on-policy RL is often hampered by noisy, low-signal gradients. We revisit Evolution Strategies (ES) as a policy-gradient proxy and localize exploration with bounded, antithetic triangular perturbations, suitable for policy refinement. We propose Triangular-Distribution ES (TD-ES) which pairs bounded triangular noise with a centered-rank finite-difference estimator to deliver stable, parallelizable, gradient-free updates. In a two-stage pipeline - PPO pretraining followed by TD-ES refinement - this preserves early sample efficiency while enabling robust late-stage gains. Across a suite of robotic manipulation tasks, TD-ES raises success rates by 26.5% relative to PPO and greatly reduces variance, offering a simple, compute-light path to reliable refinement.

