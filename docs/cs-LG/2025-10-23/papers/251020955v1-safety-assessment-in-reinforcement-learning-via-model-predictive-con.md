---
layout: default
title: Safety Assessment in Reinforcement Learning via Model Predictive Control
---

# Safety Assessment in Reinforcement Learning via Model Predictive Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.20955" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.20955v1</a>
  <a href="https://arxiv.org/pdf/2510.20955.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.20955v1" onclick="toggleFavorite(this, '2510.20955v1', 'Safety Assessment in Reinforcement Learning via Model Predictive Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jeff Pflueger, Michael Everett

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-23

**å¤‡æ³¨**: 7 pages, 4 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¨¡å‹é¢„æµ‹æ§åˆ¶çš„å¼ºåŒ–å­¦ä¹ å®‰å…¨è¯„ä¼°æ–¹æ³•ï¼Œä¿éšœè®­ç»ƒè¿‡ç¨‹å®‰å…¨æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å®‰å…¨è¯„ä¼°` `æ¨¡å‹é¢„æµ‹æ§åˆ¶` `è·¯å¾„ç§¯åˆ†æ§åˆ¶` `å¯é€†æ€§` `é»‘ç›’åŠ¨åŠ›å­¦` `å®‰å…¨å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•ç¼ºä¹å½¢å¼åŒ–çš„å®‰å…¨ä¿è¯ï¼Œä¸”ä¾èµ–äºå¯¹å®‰å…¨è§„èŒƒçš„è¯¦ç»†äº†è§£ï¼Œé™åˆ¶äº†å…¶åœ¨å®‰å…¨æ”¸å…³åœºæ™¯çš„åº”ç”¨ã€‚
2. è¯¥è®ºæ–‡æå‡ºåˆ©ç”¨å¯é€†æ€§ä½œä¸ºé˜²æ­¢å®‰å…¨é—®é¢˜çš„æ–¹æ³•ï¼Œä½¿ç”¨æ¨¡å‹é¢„æµ‹è·¯å¾„ç§¯åˆ†æ§åˆ¶æ¥è¯„ä¼°åŠ¨ä½œçš„å®‰å…¨æ€§ï¼Œæ— éœ€æ˜¾å¼åŠ¨åŠ›å­¦æˆ–å®‰å…¨çº¦æŸã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿåœ¨ä¸å®‰å…¨åŠ¨ä½œå‘ç”Ÿå‰ä¸­æ­¢ï¼ŒåŒæ—¶ä¿æŒä¸åŸºçº¿PPOæ–¹æ³•ç›¸å½“çš„è®­ç»ƒæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ— æ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ§åˆ¶é¢†åŸŸå±•ç°å‡ºæ½œåŠ›ï¼Œä½†é€šå¸¸ç¼ºä¹å½¢å¼åŒ–çš„å®‰å…¨ä¿è¯ã€‚ç°æœ‰çš„å®‰å…¨é˜²æŠ¤æ–¹æ³•å¾€å¾€ä¾èµ–äºå¯¹å®‰å…¨è§„èŒƒçš„è¯¦ç»†äº†è§£ã€‚æœ¬æ–‡çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œè®¸å¤šéš¾ä»¥æ˜ç¡®æŒ‡å®šçš„å®‰å…¨é—®é¢˜æœ€å¥½é€šè¿‡ä¸å˜æ€§æ¥æè¿°ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºåˆ©ç”¨å¯é€†æ€§ä½œä¸ºä¸€ç§åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­é˜²æ­¢è¿™äº›å®‰å…¨é—®é¢˜çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨æ¨¡å‹é¢„æµ‹è·¯å¾„ç§¯åˆ†æ§åˆ¶æ¥æ£€æŸ¥å­¦ä¹ ç­–ç•¥æå‡ºçš„åŠ¨ä½œçš„å®‰å…¨æ€§ã€‚è¯¥æ–¹æ³•çš„ä¸€ä¸ªå…³é”®ä¼˜åŠ¿æ˜¯ï¼Œå®ƒåªéœ€è¦æŸ¥è¯¢é»‘ç›’åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œè€Œä¸éœ€è¦æ˜¾å¼åœ°äº†è§£åŠ¨åŠ›å­¦æˆ–å®‰å…¨çº¦æŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç®—æ³•æˆåŠŸåœ°åœ¨æ‰€æœ‰ä¸å®‰å…¨åŠ¨ä½œå‘ç”Ÿå‰ä¸­æ­¢ï¼ŒåŒæ—¶ä»ç„¶å®ç°äº†ä¸å…è®¸è¿åå®‰å…¨æ€§çš„åŸºçº¿PPOæ–¹æ³•ç›¸å½“çš„è®­ç»ƒè¿›åº¦ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¼ºåŒ–å­¦ä¹ åœ¨æ§åˆ¶ä»»åŠ¡ä¸­é¢ä¸´å®‰å…¨é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ”¸å…³çš„ç¯å¢ƒä¸­ã€‚ç°æœ‰æ–¹æ³•è¦ä¹ˆä¾èµ–äºå¯¹ç¯å¢ƒåŠ¨åŠ›å­¦çš„ç²¾ç¡®å»ºæ¨¡ï¼Œè¦ä¹ˆéœ€è¦é¢„å…ˆå®šä¹‰è¯¦ç»†çš„å®‰å…¨çº¦æŸï¼Œè¿™åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€éš¾ä»¥æ»¡è¶³ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ç¼ºä¹ç²¾ç¡®æ¨¡å‹å’Œå®‰å…¨çº¦æŸçš„æƒ…å†µä¸‹ï¼Œä¿è¯å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¿‡ç¨‹çš„å®‰å…¨æ€§æ˜¯ä¸€ä¸ªå…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨â€œå¯é€†æ€§â€æ¥å®šä¹‰å®‰å…¨ã€‚å¦‚æœä¸€ä¸ªåŠ¨ä½œä¼šå¯¼è‡´ç³»ç»Ÿè¿›å…¥ä¸å¯é€†çš„çŠ¶æ€ï¼ˆä¾‹å¦‚ï¼Œæ— æ³•æ¢å¤åˆ°å®‰å…¨çŠ¶æ€ï¼‰ï¼Œé‚£ä¹ˆè¿™ä¸ªåŠ¨ä½œå°±è¢«è®¤ä¸ºæ˜¯ä¸å®‰å…¨çš„ã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€æµ‹å¹¶é¿å…è¿™äº›ä¸å¯é€†çš„åŠ¨ä½œï¼Œå¯ä»¥æœ‰æ•ˆåœ°æé«˜å¼ºåŒ–å­¦ä¹ çš„å®‰å…¨æ€§ã€‚è¿™ç§æ€è·¯çš„å…³é”®åœ¨äºï¼Œå®ƒä¸éœ€è¦æ˜¾å¼åœ°å®šä¹‰å®‰å…¨çº¦æŸï¼Œè€Œæ˜¯é€šè¿‡æŸ¥è¯¢é»‘ç›’åŠ¨åŠ›å­¦æ¨¡å‹æ¥åˆ¤æ–­åŠ¨ä½œçš„å®‰å…¨æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªåŸºäºæ¨¡å‹é¢„æµ‹è·¯å¾„ç§¯åˆ†æ§åˆ¶ï¼ˆModel Predictive Path Integral Control, MPPIï¼‰çš„å®‰å…¨è¯„ä¼°æ¨¡å—ã€‚åœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå½“æ™ºèƒ½ä½“æå‡ºä¸€ä¸ªåŠ¨ä½œæ—¶ï¼Œè¯¥åŠ¨ä½œé¦–å…ˆä¼šè¢«é€å…¥MPPIæ¨¡å—è¿›è¡Œå®‰å…¨è¯„ä¼°ã€‚MPPIæ¨¡å—é€šè¿‡æŸ¥è¯¢é»‘ç›’åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œé¢„æµ‹æ‰§è¡Œè¯¥åŠ¨ä½œåç³»ç»Ÿå¯èƒ½çš„çŠ¶æ€åºåˆ—ï¼Œå¹¶åˆ¤æ–­è¿™äº›çŠ¶æ€åºåˆ—æ˜¯å¦å®‰å…¨ï¼ˆå³å¯é€†ï¼‰ã€‚å¦‚æœMPPIæ¨¡å—è®¤ä¸ºè¯¥åŠ¨ä½œä¸å®‰å…¨ï¼Œåˆ™ä¼šä¸­æ­¢è¯¥åŠ¨ä½œçš„æ‰§è¡Œï¼Œå¹¶é‡‡å–å…¶ä»–å®‰å…¨æªæ–½ã€‚æ•´ä¸ªæ¡†æ¶ä¸ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆå¦‚PPOï¼‰ç›¸ç»“åˆï¼Œå½¢æˆä¸€ä¸ªå®‰å…¨å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å¯é€†æ€§ä½œä¸ºå®‰å…¨æ€§çš„åº¦é‡æ ‡å‡†ï¼Œå¹¶åˆ©ç”¨MPPIè¿›è¡Œå®‰å…¨è¯„ä¼°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦æ˜¾å¼åœ°å®šä¹‰å®‰å…¨çº¦æŸï¼Œè€Œæ˜¯é€šè¿‡æŸ¥è¯¢é»‘ç›’åŠ¨åŠ›å­¦æ¨¡å‹æ¥åˆ¤æ–­åŠ¨ä½œçš„å®‰å…¨æ€§ã€‚è¿™ä½¿å¾—è¯¥æ–¹æ³•æ›´åŠ çµæ´»å’Œé€šç”¨ï¼Œå¯ä»¥åº”ç”¨äºå„ç§ä¸åŒçš„ç¯å¢ƒå’Œä»»åŠ¡ã€‚æ­¤å¤–ï¼ŒMPPIçš„ä½¿ç”¨ä½¿å¾—å®‰å…¨è¯„ä¼°æ›´åŠ é«˜æ•ˆå’Œå‡†ç¡®ã€‚

**å…³é”®è®¾è®¡**ï¼šMPPIæ¨¡å—çš„å…³é”®å‚æ•°åŒ…æ‹¬é¢„æµ‹æ­¥é•¿ã€é‡‡æ ·æ•°é‡å’Œæˆæœ¬å‡½æ•°ã€‚é¢„æµ‹æ­¥é•¿å†³å®šäº†MPPIæ¨¡å—é¢„æµ‹æœªæ¥çŠ¶æ€åºåˆ—çš„é•¿åº¦ï¼Œé‡‡æ ·æ•°é‡å†³å®šäº†MPPIæ¨¡å—æ¢ç´¢ä¸åŒåŠ¨ä½œçš„èŒƒå›´ï¼Œæˆæœ¬å‡½æ•°ç”¨äºè¯„ä¼°çŠ¶æ€åºåˆ—çš„å®‰å…¨æ€§ã€‚æˆæœ¬å‡½æ•°çš„è®¾è®¡éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ï¼Œä½†é€šå¸¸åŒ…æ‹¬å¯¹ä¸å®‰å…¨çŠ¶æ€çš„æƒ©ç½šé¡¹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜ä½¿ç”¨äº†PPOç®—æ³•ä½œä¸ºåŸºçº¿å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ŒPPOç®—æ³•çš„å‚æ•°è®¾ç½®ä¹Ÿéœ€è¦è¿›è¡Œè°ƒæ•´ï¼Œä»¥å¹³è¡¡è®­ç»ƒé€Ÿåº¦å’Œå®‰å…¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿåœ¨æ‰€æœ‰ä¸å®‰å…¨åŠ¨ä½œå‘ç”Ÿå‰ä¸­æ­¢ï¼ŒåŒæ—¶ä»ç„¶å®ç°äº†ä¸å…è®¸è¿åå®‰å…¨æ€§çš„åŸºçº¿PPOæ–¹æ³•ç›¸å½“çš„è®­ç»ƒè¿›åº¦ã€‚è¿™æ„å‘³ç€è¯¥æ–¹æ³•å¯ä»¥åœ¨ä¿è¯å®‰å…¨æ€§çš„å‰æä¸‹ï¼Œæœ‰æ•ˆåœ°è¿›è¡Œå¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œæå‡å¹…åº¦åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†çš„å±•ç¤ºã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§å®‰å…¨æ”¸å…³çš„æ§åˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚è‡ªåŠ¨é©¾é©¶ã€æœºå™¨äººæ“ä½œã€èˆªç©ºèˆªå¤©ç­‰ã€‚é€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¿›è¡Œå®‰å…¨è¯„ä¼°ï¼Œå¯ä»¥æœ‰æ•ˆåœ°é˜²æ­¢æ™ºèƒ½ä½“å­¦ä¹ åˆ°ä¸å®‰å…¨çš„è¡Œä¸ºï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºé‚£äº›éš¾ä»¥ç²¾ç¡®å»ºæ¨¡æˆ–å®šä¹‰å®‰å…¨çº¦æŸçš„ç¯å¢ƒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Model-free reinforcement learning approaches are promising for control but typically lack formal safety guarantees. Existing methods to shield or otherwise provide these guarantees often rely on detailed knowledge of the safety specifications. Instead, this work's insight is that many difficult-to-specify safety issues are best characterized by invariance. Accordingly, we propose to leverage reversibility as a method for preventing these safety issues throughout the training process. Our method uses model-predictive path integral control to check the safety of an action proposed by a learned policy throughout training. A key advantage of this approach is that it only requires the ability to query the black-box dynamics, not explicit knowledge of the dynamics or safety constraints. Experimental results demonstrate that the proposed algorithm successfully aborts before all unsafe actions, while still achieving comparable training progress to a baseline PPO approach that is allowed to violate safety.

