---
layout: default
title: Decipher the Modality Gap in Multimodal Contrastive Learning: From Convergent Representations to Pairwise Alignment
---

# Decipher the Modality Gap in Multimodal Contrastive Learning: From Convergent Representations to Pairwise Alignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.03268" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.03268v2</a>
  <a href="https://arxiv.org/pdf/2510.03268.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.03268v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.03268v2', 'Decipher the Modality Gap in Multimodal Contrastive Learning: From Convergent Representations to Pairwise Alignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lingjie Yi, Raphael Douady, Chao Chen

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-27 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç†è®ºåˆ†æå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ä¸­çš„æ¨¡æ€é¸¿æ²Ÿï¼Œæ­ç¤ºç»´åº¦åå¡Œæ˜¯æ ¹æœ¬åŸå› ï¼Œå¹¶æå‡ºå¯¹é½æ–¹æ¡ˆã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ` `æ¨¡æ€é¸¿æ²Ÿ` `ç»´åº¦åå¡Œ` `è¡¨ç¤ºå­¦ä¹ ` `æ¨¡æ€å¯¹é½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ å­˜åœ¨æ¨¡æ€é¸¿æ²Ÿé—®é¢˜ï¼Œä¸åŒæ¨¡æ€çš„è¡¨ç¤ºåœ¨åµŒå…¥ç©ºé—´ä¸­åˆ†ç¦»ï¼Œå½±å“ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½ã€‚
2. è®ºæ–‡é€šè¿‡ç†è®ºæ¡†æ¶åˆ†æMCLçš„æ”¶æ•›æœ€ä¼˜è¡¨ç¤ºå’Œæ¨¡æ€å¯¹é½ï¼Œæ­ç¤ºç»´åº¦åå¡Œæ˜¯æ¨¡æ€é¸¿æ²Ÿçš„æ ¹æœ¬åŸå› ã€‚
3. è¯æ˜åœ¨ç‰¹å®šçº¦æŸä¸‹ï¼Œæ¨¡æ€é¸¿æ²Ÿæ”¶æ•›åˆ°è¶…å¹³é¢é—´çš„æœ€å°è§’åº¦ï¼Œå¹¶æå‡ºè¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±çš„å¯¹é½æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ (MCL)æ—¨åœ¨å°†æ¥è‡ªä¸åŒæ¨¡æ€çš„æ•°æ®åµŒå…¥åˆ°å…±äº«çš„åµŒå…¥ç©ºé—´ä¸­ã€‚ç„¶è€Œï¼Œç»éªŒè¯æ®è¡¨æ˜ï¼Œæ¥è‡ªä¸åŒæ¨¡æ€çš„è¡¨ç¤ºå æ®åµŒå…¥ç©ºé—´ä¸­å®Œå…¨ç‹¬ç«‹çš„åŒºåŸŸï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸ºæ¨¡æ€é¸¿æ²Ÿã€‚æ­¤å¤–ï¼Œå…³äºæ¨¡æ€é¸¿æ²Ÿçš„å¤§å°å¦‚ä½•å½±å“ä¸‹æ¸¸æ€§èƒ½çš„å®éªŒç»“æœå¹¶ä¸ä¸€è‡´ã€‚è¿™äº›è§‚å¯Ÿç»“æœæå‡ºäº†ä¸¤ä¸ªå…³é”®é—®é¢˜ï¼š(1)æ˜¯ä»€ä¹ˆå¯¼è‡´äº†æ¨¡æ€é¸¿æ²Ÿï¼Ÿ(2)å®ƒå¦‚ä½•å½±å“ä¸‹æ¸¸ä»»åŠ¡ï¼Ÿä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ç¬¬ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œç”¨äºåˆ†æMCLçš„æ”¶æ•›æœ€ä¼˜è¡¨ç¤ºä»¥åŠä¼˜åŒ–è®­ç»ƒæ—¶çš„æ¨¡æ€å¯¹é½ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨æ²¡æœ‰ä»»ä½•çº¦æŸæˆ–é”¥çº¦æŸä¸‹ï¼Œæ¨¡æ€é¸¿æ²Ÿæ”¶æ•›åˆ°é›¶ã€‚åœ¨å­ç©ºé—´çº¦æŸä¸‹(å³ï¼Œç”±äºç»´åº¦åå¡Œï¼Œä¸¤ç§æ¨¡æ€çš„è¡¨ç¤ºè½å…¥ä¸¤ä¸ªä¸åŒçš„è¶…å¹³é¢)ï¼Œæ¨¡æ€é¸¿æ²Ÿæ”¶æ•›åˆ°ä¸¤ä¸ªè¶…å¹³é¢ä¹‹é—´çš„æœ€å°è§’åº¦ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ç»´åº¦åå¡Œæ˜¯æ¨¡æ€é¸¿æ²Ÿçš„æ ¹æœ¬åŸå› ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„å®šç†è¯æ˜ï¼Œåœ¨å­ç©ºé—´çº¦æŸä¸‹ï¼Œæˆå¯¹æ ·æœ¬æ— æ³•å®Œç¾å¯¹é½ã€‚æ¨¡æ€é¸¿æ²Ÿé€šè¿‡å½±å“æ ·æœ¬å¯¹ä¹‹é—´çš„å¯¹é½æ¥å½±å“ä¸‹æ¸¸æ€§èƒ½ã€‚æˆ‘ä»¬è¯æ˜ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œä»ç„¶å¯ä»¥é€šè¿‡ä¸¤ç§æ–¹å¼å®ç°ä¸¤ç§æ¨¡æ€ä¹‹é—´çš„å®Œç¾å¯¹é½ï¼šè¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ æ—¨åœ¨å­¦ä¹ ä¸€ä¸ªå…±äº«çš„åµŒå…¥ç©ºé—´ï¼Œä½¿å¾—æ¥è‡ªä¸åŒæ¨¡æ€çš„ç›¸åŒå®ä¾‹çš„è¡¨ç¤ºå°½å¯èƒ½æ¥è¿‘ã€‚ç„¶è€Œï¼Œå®é™…ä¸­è§‚å¯Ÿåˆ°ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºå¾€å¾€ä½äºåµŒå…¥ç©ºé—´çš„ä¸åŒåŒºåŸŸï¼Œå½¢æˆâ€œæ¨¡æ€é¸¿æ²Ÿâ€ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹æ¨¡æ€é¸¿æ²Ÿæˆå› çš„ç†è®ºåˆ†æï¼Œä»¥åŠæ¨¡æ€é¸¿æ²Ÿå¯¹ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½å½±å“çš„ç†è§£ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°å¯¹é½ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç†è®ºåˆ†æï¼Œæ­ç¤ºæ¨¡æ€é¸¿æ²Ÿçš„æ ¹æœ¬åŸå› æ˜¯ç»´åº¦åå¡Œï¼Œå³ä¸åŒæ¨¡æ€çš„è¡¨ç¤ºè½å…¥ä¸åŒçš„ä½ç»´å­ç©ºé—´ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸¤ç§å¯¹é½ç­–ç•¥ï¼šè¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ï¼Œæ—¨åœ¨å…‹æœç»´åº¦åå¡Œå¸¦æ¥çš„å½±å“ï¼Œå®ç°æ¨¡æ€é—´çš„æœ‰æ•ˆå¯¹é½ã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†åœ¨ç†è®ºä¸Šè§£é‡Šæ¨¡æ€é¸¿æ²Ÿï¼Œå¹¶æä¾›å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æ„å»ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œç”¨äºåˆ†æå¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ çš„æ”¶æ•›æœ€ä¼˜è¡¨ç¤ºã€‚è¯¥æ¡†æ¶ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š1) å®šä¹‰äº†ä¸åŒçº¦æŸæ¡ä»¶ä¸‹çš„MCLç›®æ ‡å‡½æ•°ï¼ŒåŒ…æ‹¬æ— çº¦æŸã€é”¥çº¦æŸå’Œå­ç©ºé—´çº¦æŸï¼›2) æ¨å¯¼äº†åœ¨ä¸åŒçº¦æŸæ¡ä»¶ä¸‹ï¼Œæ¨¡æ€é¸¿æ²Ÿçš„æ”¶æ•›è¡Œä¸ºï¼›3) è¯æ˜äº†ç»´åº¦åå¡Œæ˜¯å­ç©ºé—´çº¦æŸä¸‹æ¨¡æ€é¸¿æ²Ÿçš„æ ¹æœ¬åŸå› ï¼›4) æå‡ºäº†è¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ä¸¤ç§å¯¹é½ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºï¼š1) é¦–æ¬¡ä»ç†è®ºä¸Šåˆ†æäº†å¤šæ¨¡æ€å¯¹æ¯”å­¦ä¹ ä¸­çš„æ¨¡æ€é¸¿æ²Ÿé—®é¢˜ï¼Œå¹¶æ­ç¤ºäº†ç»´åº¦åå¡Œæ˜¯å…¶æ ¹æœ¬åŸå› ï¼›2) æå‡ºäº†è¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ä¸¤ç§å¯¹é½ç­–ç•¥ï¼Œæ—¨åœ¨å…‹æœç»´åº¦åå¡Œå¸¦æ¥çš„å½±å“ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥è®ºæ–‡æä¾›äº†æ›´æ·±å…¥çš„ç†è®ºç†è§£ï¼Œå¹¶æå‡ºäº†æ›´æœ‰æ•ˆçš„å¯¹é½æ–¹æ¡ˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨ä¸åŒçš„çº¦æŸæ¡ä»¶ï¼ˆæ— çº¦æŸã€é”¥çº¦æŸã€å­ç©ºé—´çº¦æŸï¼‰æ¥æ¨¡æ‹Ÿä¸åŒçš„å­¦ä¹ åœºæ™¯ï¼›2) é€šè¿‡æ•°å­¦æ¨å¯¼ï¼Œåˆ†æåœ¨ä¸åŒçº¦æŸæ¡ä»¶ä¸‹æ¨¡æ€é¸¿æ²Ÿçš„æ”¶æ•›è¡Œä¸ºï¼›3) è®¾è®¡è¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ä¸¤ç§å¯¹é½ç­–ç•¥ï¼Œå…·ä½“å®ç°ç»†èŠ‚æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡ç†è®ºåˆ†æè¯æ˜ï¼Œåœ¨å­ç©ºé—´çº¦æŸä¸‹ï¼Œæ¨¡æ€é¸¿æ²Ÿæ”¶æ•›åˆ°ä¸¤ä¸ªè¶…å¹³é¢ä¹‹é—´çš„æœ€å°è§’åº¦ï¼Œæ­ç¤ºäº†ç»´åº¦åå¡Œæ˜¯æ¨¡æ€é¸¿æ²Ÿçš„æ ¹æœ¬åŸå› ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æå‡ºäº†è¶…å¹³é¢æ—‹è½¬å’Œå…±äº«ç©ºé—´æŠ•å½±ä¸¤ç§å¯¹é½ç­–ç•¥ï¼Œä¸ºè§£å†³æ¨¡æ€é¸¿æ²Ÿé—®é¢˜æä¾›äº†æ–°çš„æ€è·¯ã€‚å…·ä½“çš„å®éªŒç»“æœæœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè·¨æ¨¡æ€æ£€ç´¢ã€å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æã€å¤šæ¨¡æ€åŒ»å­¦è¯Šæ–­ç­‰é¢†åŸŸã€‚é€šè¿‡å‡å°æ¨¡æ€é¸¿æ²Ÿï¼Œå¯ä»¥æå‡å¤šæ¨¡æ€èåˆæ¨¡å‹çš„æ€§èƒ½ï¼Œå®ç°æ›´å‡†ç¡®ã€æ›´é²æ£’çš„è·¨æ¨¡æ€ä¿¡æ¯å¤„ç†ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥æ¢ç´¢æ›´å¤æ‚çš„çº¦æŸæ¡ä»¶å’Œæ›´æœ‰æ•ˆçš„å¯¹é½ç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal contrastive learning (MCL) aims to embed data from different modalities in a shared embedding space. However, empirical evidence shows that representations from different modalities occupy completely separate regions of embedding space, a phenomenon referred to as the modality gap. Moreover, experimental findings on how the size of the modality gap influences downstream performance are inconsistent. These observations raise two key questions: (1) What causes the modality gap? (2) How does it affect downstream tasks? To address these questions, this paper introduces the first theoretical framework for analyzing the convergent optimal representations of MCL and the modality alignment when training is optimized. Specifically, we prove that without any constraint or under the cone constraint, the modality gap converges to zero. Under the subspace constraint (i.e., representations of two modalities fall into two distinct hyperplanes due to dimension collapse), the modality gap converges to the smallest angle between the two hyperplanes. This result identifies \emph{dimension collapse} as the fundamental origin of the modality gap. Furthermore, our theorems demonstrate that paired samples cannot be perfectly aligned under the subspace constraint. The modality gap influences downstream performance by affecting the alignment between sample pairs. We prove that, in this case, perfect alignment between two modalities can still be achieved via two ways: hyperplane rotation and shared space projection.

