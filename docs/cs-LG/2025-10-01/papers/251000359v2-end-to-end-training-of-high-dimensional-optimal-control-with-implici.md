---
layout: default
title: End-to-End Training of High-Dimensional Optimal Control with Implicit Hamiltonians via Jacobian-Free Backpropagation
---

# End-to-End Training of High-Dimensional Optimal Control with Implicit Hamiltonians via Jacobian-Free Backpropagation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00359" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00359v2</a>
  <a href="https://arxiv.org/pdf/2510.00359.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00359v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00359v2', 'End-to-End Training of High-Dimensional Optimal Control with Implicit Hamiltonians via Jacobian-Free Backpropagation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Eric Gelphman, Deepanshu Verma, Nicole Tianjiao Yang, Stanley Osher, Samy Wu Fung

**åˆ†ç±»**: math.OC, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01 (æ›´æ–°: 2025-10-07)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºéšå¼å“ˆå¯†é¡¿é‡çš„ç«¯åˆ°ç«¯é«˜ç»´æœ€ä¼˜æ§åˆ¶æ–¹æ³•ï¼Œé€šè¿‡æ— é›…å¯æ¯”åå‘ä¼ æ’­å®ç°é«˜æ•ˆè®­ç»ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æœ€ä¼˜æ§åˆ¶` `éšå¼å“ˆå¯†é¡¿é‡` `æ·±åº¦å­¦ä¹ ` `æ— é›…å¯æ¯”åå‘ä¼ æ’­` `å€¼å‡½æ•°` `åé¦ˆæ§åˆ¶å™¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•éš¾ä»¥å¤„ç†å…·æœ‰éšå¼å“ˆå¯†é¡¿é‡çš„é«˜ç»´æœ€ä¼˜æ§åˆ¶é—®é¢˜ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…é—®é¢˜ä¸­çš„åº”ç”¨ã€‚
2. è¯¥æ–¹æ³•ç›´æ¥å‚æ•°åŒ–å€¼å‡½æ•°ï¼Œåˆ©ç”¨æœ€ä¼˜æ§åˆ¶ä¸å€¼å‡½æ•°æ¢¯åº¦çš„å…³ç³»ï¼Œå­¦ä¹ æœ€ä¼˜æ§åˆ¶å¾‹ï¼Œæ— éœ€æ˜¾å¼å“ˆå¯†é¡¿é‡å…¬å¼ã€‚
3. é€šè¿‡æ— é›…å¯æ¯”åå‘ä¼ æ’­ï¼ˆJFBï¼‰å®ç°é«˜æ•ˆè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªæ¶‰åŠéšå¼å“ˆå¯†é¡¿é‡çš„åœºæ™¯ä¸­éªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„éšå¼æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç›´æ¥å‚æ•°åŒ–å€¼å‡½æ•°æ¥å­¦ä¹ æœ€ä¼˜æ§åˆ¶å¾‹ï¼Œä»è€Œè§£å†³å…·æœ‰éšå¼å“ˆå¯†é¡¿é‡çš„é«˜ç»´æœ€ä¼˜æ§åˆ¶é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å“ˆå¯†é¡¿é‡å…·æœ‰æ˜¾å¼å…¬å¼æ—¶ï¼Œå¯ä»¥é€šè¿‡å‚æ•°åŒ–å€¼å‡½æ•°çš„ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼é«˜ç»´æœ€ä¼˜åé¦ˆæ§åˆ¶å™¨ã€‚ç„¶è€Œï¼Œè®¸å¤šå®é™…é—®é¢˜ï¼Œå¦‚èˆªå¤©é£æœºå†å…¥é—®é¢˜å’Œè‡ªè¡Œè½¦åŠ¨åŠ›å­¦ç­‰ï¼Œæ¶‰åŠä¸å…·æœ‰æ˜¾å¼å…¬å¼çš„éšå¼å“ˆå¯†é¡¿é‡ï¼Œé™åˆ¶äº†ç°æœ‰æ–¹æ³•çš„é€‚ç”¨æ€§ã€‚æœ¬æ–‡æ–¹æ³•é€šè¿‡ç¡®ä¿è®­ç»ƒåçš„ç½‘ç»œéµå®ˆæ§åˆ¶è§„å¾‹æ¥å¼ºåŒ–ç‰©ç†åŸåˆ™ï¼Œåˆ©ç”¨æœ€ä¼˜æ§åˆ¶å’Œå€¼å‡½æ•°æ¢¯åº¦ä¹‹é—´çš„åŸºæœ¬å…³ç³»ã€‚é€šè¿‡ä½¿ç”¨æ— é›…å¯æ¯”åå‘ä¼ æ’­ï¼ˆJFBï¼‰ï¼Œå³ä½¿åœ¨è½¨è¿¹ä¼˜åŒ–ä¸­å­˜åœ¨æ—¶é—´è€¦åˆï¼Œä¹Ÿèƒ½å®ç°é«˜æ•ˆè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆåœ°å­¦ä¹ äº†æ¶‰åŠéšå¼å“ˆå¯†é¡¿é‡çš„å¤šä¸ªåœºæ™¯ä¸­çš„é«˜ç»´åé¦ˆæ§åˆ¶å™¨ï¼Œè¿™æ˜¯ç°æœ‰æ–¹æ³•æ— æ³•è§£å†³çš„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é«˜ç»´æœ€ä¼˜æ§åˆ¶é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å“ˆå¯†é¡¿é‡æ²¡æœ‰æ˜¾å¼è¡¨è¾¾å¼çš„æƒ…å†µä¸‹ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ˜¾å¼å“ˆå¯†é¡¿é‡ï¼Œæˆ–è€…ç›´æ¥å‚æ•°åŒ–æ§åˆ¶ç­–ç•¥ï¼Œè¿™åœ¨å¤„ç†å¤æ‚ç³»ç»Ÿæ—¶æ•ˆç‡ä½ä¸‹æˆ–éš¾ä»¥å®ç°ã€‚è¿™äº›æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨å“ˆå¯†é¡¿é‡çš„å†…åœ¨ç»“æ„ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç›´æ¥å‚æ•°åŒ–å€¼å‡½æ•°ï¼Œå¹¶é€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ æœ€ä¼˜æ§åˆ¶å¾‹ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹æ˜¾å¼å“ˆå¯†é¡¿é‡çš„ä¾èµ–ï¼Œå¹¶ä¸”èƒ½å¤Ÿåˆ©ç”¨å€¼å‡½æ•°ä¸æœ€ä¼˜æ§åˆ¶ä¹‹é—´çš„å…³ç³»ï¼ˆé€šè¿‡Pontryaginæœ€å¤§å€¼åŸç†å’ŒåŠ¨æ€è§„åˆ’ï¼‰ã€‚é€šè¿‡ç¡®ä¿è®­ç»ƒåçš„ç½‘ç»œæ»¡è¶³æ§åˆ¶è§„å¾‹ï¼Œå¯ä»¥å¼ºåŒ–ç‰©ç†çº¦æŸï¼Œæé«˜æ§åˆ¶å™¨çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) å®šä¹‰ç³»ç»Ÿçš„åŠ¨åŠ›å­¦æ–¹ç¨‹å’Œç›®æ ‡å‡½æ•°ï¼›2) ä½¿ç”¨ç¥ç»ç½‘ç»œå‚æ•°åŒ–å€¼å‡½æ•°ï¼›3) åˆ©ç”¨Pontryaginæœ€å¤§å€¼åŸç†æ¨å¯¼å‡ºæœ€ä¼˜æ§åˆ¶ä¸å€¼å‡½æ•°æ¢¯åº¦çš„å…³ç³»ï¼›4) ä½¿ç”¨æ— é›…å¯æ¯”åå‘ä¼ æ’­ï¼ˆJFBï¼‰è®­ç»ƒç¥ç»ç½‘ç»œï¼Œä¼˜åŒ–å€¼å‡½æ•°ï¼Œä½¿å…¶æ»¡è¶³æœ€ä¼˜æ§åˆ¶æ¡ä»¶ã€‚JFBç”¨äºé«˜æ•ˆåœ°è®¡ç®—æ¢¯åº¦ï¼Œé¿å…äº†æ˜¾å¼è®¡ç®—é›…å¯æ¯”çŸ©é˜µçš„å¤æ‚æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨éšå¼å“ˆå¯†é¡¿é‡è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒï¼Œå¹¶ç»“åˆæ— é›…å¯æ¯”åå‘ä¼ æ’­ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦æ˜¾å¼å“ˆå¯†é¡¿é‡ï¼Œå¯ä»¥ç›´æ¥å­¦ä¹ æœ€ä¼˜æ§åˆ¶å¾‹ï¼Œä»è€Œæ‰©å±•äº†æœ€ä¼˜æ§åˆ¶çš„åº”ç”¨èŒƒå›´ã€‚JFBçš„ä½¿ç”¨æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œä½¿å¾—å¤„ç†é«˜ç»´é—®é¢˜æˆä¸ºå¯èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œæ¥å‚æ•°åŒ–å€¼å‡½æ•°ï¼Œç½‘ç»œçš„ç»“æ„éœ€è¦æ ¹æ®å…·ä½“é—®é¢˜è¿›è¡Œè°ƒæ•´ï¼›2) å®šä¹‰åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚ï¼Œå¯ä»¥åŒ…æ‹¬å€¼å‡½æ•°æ»¡è¶³Bellmanæ–¹ç¨‹çš„ç¨‹åº¦ï¼Œä»¥åŠæ§åˆ¶ç­–ç•¥çš„ç¨³å®šæ€§ï¼›3) ä½¿ç”¨æ— é›…å¯æ¯”åå‘ä¼ æ’­ï¼ˆJFBï¼‰æ¥è®¡ç®—æ¢¯åº¦ï¼ŒJFBçš„å…·ä½“å®ç°ä¾èµ–äºè‡ªåŠ¨å¾®åˆ†å·¥å…·ï¼›4) é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚Adamæˆ–L-BFGSï¼Œå¹¶è°ƒæ•´å­¦ä¹ ç‡ç­‰è¶…å‚æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¶‰åŠéšå¼å“ˆå¯†é¡¿é‡çš„å¤šä¸ªåœºæ™¯ä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ é«˜ç»´åé¦ˆæ§åˆ¶å™¨ã€‚ä¾‹å¦‚ï¼Œåœ¨èˆªå¤©é£æœºå†å…¥é—®é¢˜å’Œè‡ªè¡Œè½¦åŠ¨åŠ›å­¦é—®é¢˜ä¸­ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ‰¾åˆ°æœ€ä¼˜æ§åˆ¶ç­–ç•¥ï¼Œå¹¶ä¸”ä¼˜äºç°æœ‰çš„åŸºäºæ˜¾å¼å“ˆå¯†é¡¿é‡çš„æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒJFBçš„ä½¿ç”¨æ˜¾è‘—æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œä½¿å¾—è¯¥æ–¹æ³•èƒ½å¤Ÿå¤„ç†æ›´é«˜ç»´åº¦çš„é—®é¢˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æ¶‰åŠå¤æ‚åŠ¨åŠ›å­¦ç³»ç»Ÿå’Œéšå¼å“ˆå¯†é¡¿é‡çš„æ§åˆ¶é—®é¢˜ï¼Œä¾‹å¦‚èˆªå¤©å™¨å§¿æ€æ§åˆ¶ã€æœºå™¨äººè¿åŠ¨è§„åˆ’ã€èƒ½æºç³»ç»Ÿä¼˜åŒ–ç­‰ã€‚é€šè¿‡å­¦ä¹ æœ€ä¼˜æ§åˆ¶ç­–ç•¥ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿçš„æ€§èƒ½ã€æ•ˆç‡å’Œé²æ£’æ€§ï¼Œé™ä½è¿è¥æˆæœ¬ï¼Œå¹¶ä¸ºå¤æ‚ç³»ç»Ÿçš„è‡ªåŠ¨åŒ–æ§åˆ¶æä¾›æ–°çš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Neural network approaches that parameterize value functions have succeeded in approximating high-dimensional optimal feedback controllers when the Hamiltonian admits explicit formulas. However, many practical problems, such as the space shuttle reentry problem and bicycle dynamics, among others, may involve implicit Hamiltonians that do not admit explicit formulas, limiting the applicability of existing methods. Rather than directly parameterizing controls, which does not leverage the Hamiltonian's underlying structure, we propose an end-to-end implicit deep learning approach that directly parameterizes the value function to learn optimal control laws. Our method enforces physical principles by ensuring trained networks adhere to the control laws by exploiting the fundamental relationship between the optimal control and the value function's gradient; this is a direct consequence of the connection between Pontryagin's Maximum Principle and dynamic programming. Using Jacobian-Free Backpropagation (JFB), we achieve efficient training despite temporal coupling in trajectory optimization. We show that JFB produces descent directions for the optimal control objective and experimentally demonstrate that our approach effectively learns high-dimensional feedback controllers across multiple scenarios involving implicit Hamiltonians, which existing methods cannot address.

