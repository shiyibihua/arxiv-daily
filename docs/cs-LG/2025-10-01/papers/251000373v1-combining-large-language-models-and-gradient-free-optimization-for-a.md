---
layout: default
title: Combining Large Language Models and Gradient-Free Optimization for Automatic Control Policy Synthesis
---

# Combining Large Language Models and Gradient-Free Optimization for Automatic Control Policy Synthesis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00373" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00373v1</a>
  <a href="https://arxiv.org/pdf/2510.00373.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00373v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00373v1', 'Combining Large Language Models and Gradient-Free Optimization for Automatic Control Policy Synthesis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Carlo Bosio, Matteo Guarrera, Alberto Sangiovanni-Vincentelli, Mark W. Mueller

**åˆ†ç±»**: cs.LG, cs.AI, cs.NE, eess.SY

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

**å¤‡æ³¨**: 8 pages, 7 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»“åˆå¤§è¯­è¨€æ¨¡å‹ä¸æ— æ¢¯åº¦ä¼˜åŒ–ï¼Œå®ç°è‡ªåŠ¨æ§åˆ¶ç­–ç•¥ç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `æ§åˆ¶ç­–ç•¥ç”Ÿæˆ` `æ— æ¢¯åº¦ä¼˜åŒ–` `è‡ªåŠ¨æ§åˆ¶` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆæ§åˆ¶ç­–ç•¥æ—¶ï¼Œéš¾ä»¥æœ‰æ•ˆåŒºåˆ†ç­–ç•¥ç»“æ„ä¸æ•°å€¼å‚æ•°ï¼Œå¯¼è‡´æœç´¢æ•ˆç‡ä½ä¸‹ã€‚
2. æå‡ºä¸€ç§æ··åˆæ–¹æ³•ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹ç”¨äºç­–ç•¥ç»“æ„æœç´¢ï¼Œå¹¶ä½¿ç”¨æ— æ¢¯åº¦ä¼˜åŒ–æ–¹æ³•è¿›è¡Œå‚æ•°è°ƒä¼˜ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ§åˆ¶ä»»åŠ¡ä¸­å®ç°äº†æ›´é«˜çš„å›æŠ¥å’Œæ ·æœ¬æ•ˆç‡ï¼Œä¼˜äºçº¯ç²¹çš„LLMå¼•å¯¼æœç´¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨ç”Ÿæˆç¬¦å·æ§åˆ¶ç­–ç•¥æ–¹é¢å±•ç°å‡ºæ½œåŠ›ï¼Œé€šè¿‡è¿­ä»£æœç´¢äº§ç”Ÿå¯è§£é‡Šçš„ç±»ç¨‹åºè¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹æ— æ³•å°†ç­–ç•¥çš„åŠŸèƒ½ç»“æ„ä¸å…¶å‚æ•°å€¼åˆ†ç¦»ï¼Œå¯¼è‡´æœç´¢è¿‡ç¨‹ç¼“æ…¢ä¸”æ•ˆç‡ä½ä¸‹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ··åˆæ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é¢å¤–çš„ä¼˜åŒ–å±‚è¿›è¡Œå±€éƒ¨å‚æ•°æœç´¢ï¼Œå°†ç»“æ„ç»¼åˆä¸å‚æ•°ä¼˜åŒ–è§£è€¦ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼Œæå–LLMç”Ÿæˆçš„ç¨‹åºçš„æ•°å€¼å‚æ•°ï¼Œå¹¶å¯¹å…¶è¿›è¡Œæ•°å€¼ä¼˜åŒ–ï¼Œä»¥æœ€å¤§åŒ–ä»»åŠ¡æ€§èƒ½ã€‚é€šè¿‡è¿™ç§é›†æˆï¼ŒLLMè¿­ä»£ç¨‹åºçš„å‡½æ•°ç»“æ„ï¼Œè€Œå•ç‹¬çš„ä¼˜åŒ–å¾ªç¯ç”¨äºæŸ¥æ‰¾ä¼´éšå€™é€‰ç¨‹åºçš„å±€éƒ¨æœ€ä¼˜å‚æ•°é›†ã€‚æˆ‘ä»¬åœ¨ä¸€ç³»åˆ—æ§åˆ¶ä»»åŠ¡ä¸Šè¯„ä¼°äº†æˆ‘ä»¬çš„æ–¹æ³•ï¼Œç»“æœè¡¨æ˜ï¼Œä¸çº¯ç²¹çš„LLMå¼•å¯¼æœç´¢ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å®ç°äº†æ›´é«˜çš„å›æŠ¥å’Œæ›´é«˜çš„æ ·æœ¬æ•ˆç‡ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œå°†ç¬¦å·ç¨‹åºç»¼åˆä¸æ•°å€¼ä¼˜åŒ–ç›¸ç»“åˆï¼Œå¯ä»¥äº§ç”Ÿå¯è§£é‡Šä½†é«˜æ€§èƒ½çš„ç­–ç•¥ï¼Œä»è€Œå¼¥åˆäº†è¯­è¨€æ¨¡å‹å¼•å¯¼è®¾è®¡ä¸ç»å…¸æ§åˆ¶è°ƒæ•´ä¹‹é—´çš„å·®è·ã€‚ä»£ç å¯åœ¨https://sites.google.com/berkeley.edu/colmoè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ§åˆ¶ç­–ç•¥æ—¶ï¼Œæ¨¡å‹æ— æ³•æœ‰æ•ˆåˆ†ç¦»ç­–ç•¥çš„ç»“æ„å’Œæ•°å€¼å‚æ•°ï¼Œå¯¼è‡´æœç´¢æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ç›´æ¥ä½¿ç”¨LLMç”Ÿæˆå®Œæ•´çš„æ§åˆ¶ç­–ç•¥ï¼ŒåŒ…æ‹¬ç»“æ„å’Œå‚æ•°ï¼Œè¿™ä½¿å¾—æœç´¢ç©ºé—´å·¨å¤§ï¼Œéš¾ä»¥æ‰¾åˆ°æœ€ä¼˜è§£ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ§åˆ¶ç­–ç•¥çš„ç”Ÿæˆè¿‡ç¨‹è§£è€¦ä¸ºä¸¤ä¸ªé˜¶æ®µï¼šé¦–å…ˆï¼Œåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆç­–ç•¥çš„ç»“æ„ï¼ˆå³æ§åˆ¶é€»è¾‘ï¼‰ï¼›ç„¶åï¼Œä½¿ç”¨æ— æ¢¯åº¦ä¼˜åŒ–æ–¹æ³•å¯¹ç­–ç•¥çš„æ•°å€¼å‚æ•°è¿›è¡Œä¼˜åŒ–ã€‚è¿™æ ·å¯ä»¥å°†æœç´¢ç©ºé—´ç¼©å°ï¼Œæé«˜æœç´¢æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æŠ€æœ¯æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼š1) åŸºäºLLMçš„ç­–ç•¥ç»“æ„ç”Ÿæˆå™¨ï¼šè¯¥æ¨¡å—ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå€™é€‰çš„æ§åˆ¶ç­–ç•¥ç»“æ„ï¼Œä¾‹å¦‚PIDæ§åˆ¶å™¨ã€çŠ¶æ€åé¦ˆæ§åˆ¶å™¨ç­‰ã€‚LLMé€šè¿‡è¿­ä»£æœç´¢ï¼Œç”Ÿæˆä¸åŒçš„ç­–ç•¥ç»“æ„ã€‚2) æ— æ¢¯åº¦å‚æ•°ä¼˜åŒ–å™¨ï¼šè¯¥æ¨¡å—å¯¹LLMç”Ÿæˆçš„ç­–ç•¥ç»“æ„çš„æ•°å€¼å‚æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä¾‹å¦‚PIDæ§åˆ¶å™¨çš„Kpã€Kiã€Kdå‚æ•°ã€‚è®ºæ–‡é‡‡ç”¨æ— æ¢¯åº¦ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚CMA-ESï¼Œæ¥å¯»æ‰¾å±€éƒ¨æœ€ä¼˜çš„å‚æ•°å€¼ã€‚è¿™ä¸¤ä¸ªæ¨¡å—äº¤æ›¿è¿­ä»£ï¼ŒLLMç”Ÿæˆæ–°çš„ç­–ç•¥ç»“æ„ï¼Œä¼˜åŒ–å™¨ä¼˜åŒ–å‚æ•°ï¼Œç›´åˆ°è¾¾åˆ°é¢„å®šçš„æ€§èƒ½æŒ‡æ ‡æˆ–è¿­ä»£æ¬¡æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†å¤§è¯­è¨€æ¨¡å‹å’Œæ•°å€¼ä¼˜åŒ–æ–¹æ³•ç›¸ç»“åˆï¼Œå®ç°äº†æ§åˆ¶ç­–ç•¥çš„è‡ªåŠ¨ç”Ÿæˆã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æœç´¢æ§åˆ¶ç­–ç•¥ç©ºé—´ï¼Œæ‰¾åˆ°æ€§èƒ½æ›´å¥½çš„ç­–ç•¥ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ç­–ç•¥å…·æœ‰å¯è§£é‡Šæ€§ï¼Œå› ä¸ºç­–ç•¥çš„ç»“æ„æ˜¯ç”±LLMç”Ÿæˆçš„ï¼Œå¯ä»¥ç†è§£å…¶æ§åˆ¶é€»è¾‘ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨åˆé€‚çš„LLMä½œä¸ºç­–ç•¥ç»“æ„ç”Ÿæˆå™¨ï¼Œä¾‹å¦‚GPT-3æˆ–Codexã€‚2) é€‰æ‹©åˆé€‚çš„æ— æ¢¯åº¦ä¼˜åŒ–ç®—æ³•ï¼Œä¾‹å¦‚CMA-ESæˆ–PSOã€‚3) è®¾è®¡åˆé€‚çš„å¥–åŠ±å‡½æ•°ï¼Œç”¨äºè¯„ä¼°æ§åˆ¶ç­–ç•¥çš„æ€§èƒ½ã€‚4) è®¾è®¡åˆé€‚çš„è¿­ä»£åœæ­¢æ¡ä»¶ï¼Œä¾‹å¦‚è¾¾åˆ°é¢„å®šçš„æ€§èƒ½æŒ‡æ ‡æˆ–è¿­ä»£æ¬¡æ•°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ§åˆ¶ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨å€’ç«‹æ‘†æ§åˆ¶ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº†æ¯”çº¯LLMå¼•å¯¼æœç´¢æ›´é«˜çš„å›æŠ¥å’Œæ›´é«˜çš„æ ·æœ¬æ•ˆç‡ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•çš„å›æŠ¥æé«˜äº†20%ï¼Œæ ·æœ¬æ•ˆç‡æé«˜äº†30%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„ç­–ç•¥å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿé€‚åº”ä¸åŒçš„ç¯å¢ƒæ¡ä»¶ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€é£è¡Œå™¨æ§åˆ¶ç­‰é¢†åŸŸã€‚é€šè¿‡ç»“åˆå¤§è¯­è¨€æ¨¡å‹å’Œæ•°å€¼ä¼˜åŒ–ï¼Œå¯ä»¥è‡ªåŠ¨ç”Ÿæˆé«˜æ€§èƒ½ã€å¯è§£é‡Šçš„æ§åˆ¶ç­–ç•¥ï¼Œé™ä½æ§åˆ¶ç³»ç»Ÿè®¾è®¡çš„éš¾åº¦å’Œæˆæœ¬ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ›´å¤æ‚çš„æ§åˆ¶ä»»åŠ¡ï¼Œä¾‹å¦‚å¤šæ™ºèƒ½ä½“ååŒæ§åˆ¶ã€è‡ªé€‚åº”æ§åˆ¶ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language models (LLMs) have shown promise as generators of symbolic control policies, producing interpretable program-like representations through iterative search. However, these models are not capable of separating the functional structure of a policy from the numerical values it is parametrized by, thus making the search process slow and inefficient. We propose a hybrid approach that decouples structural synthesis from parameter optimization by introducing an additional optimization layer for local parameter search. In our method, the numerical parameters of LLM-generated programs are extracted and optimized numerically to maximize task performance. With this integration, an LLM iterates over the functional structure of programs, while a separate optimization loop is used to find a locally optimal set of parameters accompanying candidate programs. We evaluate our method on a set of control tasks, showing that it achieves higher returns and improved sample efficiency compared to purely LLM-guided search. We show that combining symbolic program synthesis with numerical optimization yields interpretable yet high-performing policies, bridging the gap between language-model-guided design and classical control tuning. Our code is available at https://sites.google.com/berkeley.edu/colmo.

