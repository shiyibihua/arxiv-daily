---
layout: default
title: AbsTopK: Rethinking Sparse Autoencoders For Bidirectional Features
---

# AbsTopK: Rethinking Sparse Autoencoders For Bidirectional Features

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00404" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00404v2</a>
  <a href="https://arxiv.org/pdf/2510.00404.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00404v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00404v2', 'AbsTopK: Rethinking Sparse Autoencoders For Bidirectional Features')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xudong Zhu, Mohammad Mahdi Khalili, Zhihui Zhu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01 (æ›´æ–°: 2025-10-02)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAbsTopKä»¥è§£å†³ç¨€ç–è‡ªç¼–ç å™¨çš„åŒå‘ç‰¹å¾è¡¨ç¤ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `åŒå‘ç‰¹å¾` `å¯è§£é‡Šæ€§` `å¤§å‹è¯­è¨€æ¨¡å‹` `è¯­ä¹‰è¡¨ç¤º` `æœºå™¨å­¦ä¹ ` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¨€ç–è‡ªç¼–ç å™¨åœ¨è¡¨ç¤ºåŒå‘æ¦‚å¿µæ—¶å­˜åœ¨å±€é™ï¼Œå¯¼è‡´è¯­ä¹‰è½´ç¢ç‰‡åŒ–ï¼Œé™åˆ¶äº†è¡¨ç¤ºçš„å®Œæ•´æ€§ã€‚
2. æœ¬æ–‡æå‡ºAbsTopK SAEï¼Œé€šè¿‡å¯¹æœ€å¤§å¹…åº¦æ¿€æ´»å€¼è¿›è¡Œç¡¬é˜ˆå€¼å¤„ç†ï¼Œä¿ç•™æ­£è´Ÿæ¿€æ´»ï¼Œè§£å†³åŒå‘ç‰¹å¾è¡¨ç¤ºé—®é¢˜ã€‚
3. åœ¨å››ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹å’Œä¸ƒä¸ªæ¢æµ‹ä¸å¼•å¯¼ä»»åŠ¡çš„å®éªŒä¸­ï¼ŒAbsTopKåœ¨é‡æ„ä¿çœŸåº¦å’Œå¯è§£é‡Šæ€§ä¸Šå‡æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰ä½œä¸ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯è§£é‡Šæ€§çš„é‡è¦æŠ€æœ¯ï¼Œæ—¨åœ¨å°†éšè—çŠ¶æ€åˆ†è§£ä¸ºæœ‰æ„ä¹‰çš„è¯­ä¹‰ç‰¹å¾ã€‚å°½ç®¡å·²æœ‰å¤šç§SAEå˜ä½“è¢«æå‡ºï¼Œä½†ç¼ºä¹ä»åŸå§‹å­—å…¸å­¦ä¹ æ¡†æ¶æ¨å¯¼SAEsçš„åŸåˆ™æ€§æ¡†æ¶ã€‚æœ¬æ–‡é€šè¿‡å±•å¼€ç¨€ç–ç¼–ç çš„è¿‘ç«¯æ¢¯åº¦æ–¹æ³•ï¼Œæå‡ºäº†è¿™æ ·ä¸€ä¸ªæ¡†æ¶ã€‚æˆ‘ä»¬æ­ç¤ºäº†ç°æœ‰SAEsçš„ä¸€ä¸ªåŸºæœ¬å±€é™æ€§ï¼šå…¶ç¨€ç–æ€§è¯±å¯¼æ­£åˆ™åŒ–å™¨å¼ºåˆ¶éè´Ÿæ€§ï¼Œå¯¼è‡´å•ä¸€ç‰¹å¾æ— æ³•è¡¨ç¤ºåŒå‘æ¦‚å¿µã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†AbsTopK SAEï¼Œé€šè¿‡å¯¹æœ€å¤§å¹…åº¦æ¿€æ´»å€¼è¿›è¡Œç¡¬é˜ˆå€¼å¤„ç†ï¼Œä¿ç•™æ­£è´Ÿæ¿€æ´»ï¼Œä»è€Œæ­ç¤ºæ›´ä¸°å¯Œçš„åŒå‘æ¦‚å¿µè¡¨ç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAbsTopKåœ¨é‡æ„ä¿çœŸåº¦ã€å¯è§£é‡Šæ€§æ–¹é¢å‡æœ‰æ‰€æå‡ï¼Œå¹¶ä¸”èƒ½å¤Ÿè®©å•ä¸€ç‰¹å¾ç¼–ç å¯¹ç«‹æ¦‚å¿µã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç¨€ç–è‡ªç¼–ç å™¨åœ¨è¡¨ç¤ºåŒå‘æ¦‚å¿µæ—¶çš„å±€é™æ€§ï¼Œç°æœ‰æ–¹æ³•çš„ç¨€ç–æ€§è¯±å¯¼æ­£åˆ™åŒ–å™¨å¼ºåˆ¶éè´Ÿæ€§ï¼Œå¯¼è‡´ç‰¹å¾è¡¨ç¤ºçš„ç¢ç‰‡åŒ–å’Œå†—ä½™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºAbsTopK SAEï¼ŒåŸºäº$	ext{l}_0$ç¨€ç–æ€§çº¦æŸï¼Œé€šè¿‡å¯¹æœ€å¤§å¹…åº¦æ¿€æ´»å€¼è¿›è¡Œç¡¬é˜ˆå€¼å¤„ç†ï¼Œä¿ç•™æ­£è´Ÿæ¿€æ´»ï¼Œä»è€Œå®ç°æ›´ä¸°å¯Œçš„åŒå‘æ¦‚å¿µè¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ç¨€ç–ç¼–ç çš„è¿‘ç«¯æ¢¯åº¦æ–¹æ³•å±•å¼€ï¼ŒAbsTopKçš„ç‰¹å¾æå–æ¨¡å—ï¼Œä»¥åŠé‡æ„å’Œå¯è§£é‡Šæ€§è¯„ä¼°æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šAbsTopK SAEçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶èƒ½å¤ŸåŒæ—¶ä¿ç•™æ­£è´Ÿæ¿€æ´»ï¼Œæ‰“ç ´äº†ç°æœ‰SAEsçš„éè´Ÿæ€§çº¦æŸï¼Œä»è€Œå®ç°åŒå‘æ¦‚å¿µçš„æœ‰æ•ˆè¡¨ç¤ºã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨AbsTopKä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç¡¬é˜ˆå€¼å¤„ç†æœºåˆ¶ï¼Œç¡®ä¿æœ€å¤§å¹…åº¦æ¿€æ´»å€¼çš„ä¿ç•™ï¼ŒåŒæ—¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†æ–°çš„ç¨€ç–æ€§çº¦æŸï¼Œä»¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤ºçš„å®Œæ•´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒAbsTopKåœ¨é‡æ„ä¿çœŸåº¦ä¸Šæ˜¾è‘—æå‡ï¼Œä¸”åœ¨å¯è§£é‡Šæ€§æ–¹é¢è¶…è¶Šäº†ç°æœ‰çš„SAEå˜ä½“ã€‚ä¸éœ€è¦æ ‡æ³¨æ•°æ®çš„ç›‘ç£æ–¹æ³•Difference-in-Meanç›¸æ¯”ï¼ŒAbsTopKçš„è¡¨ç°ç›¸å½“ç”šè‡³æ›´ä¼˜ï¼Œå±•ç¤ºäº†å…¶åœ¨æ— ç›‘ç£å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å›¾åƒç†è§£å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰ã€‚é€šè¿‡æå‡ç¨€ç–è‡ªç¼–ç å™¨çš„å¯è§£é‡Šæ€§å’Œè¡¨ç¤ºèƒ½åŠ›ï¼ŒAbsTopK SAEèƒ½å¤Ÿä¸ºç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„å†…éƒ¨æœºåˆ¶æä¾›æ›´æœ‰æ•ˆçš„å·¥å…·ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Sparse autoencoders (SAEs) have emerged as powerful techniques for interpretability of large language models (LLMs), aiming to decompose hidden states into meaningful semantic features. While several SAE variants have been proposed, there remains no principled framework to derive SAEs from the original dictionary learning formulation. In this work, we introduce such a framework by unrolling the proximal gradient method for sparse coding. We show that a single-step update naturally recovers common SAE variants, including ReLU, JumpReLU, and TopK. Through this lens, we reveal a fundamental limitation of existing SAEs: their sparsity-inducing regularizers enforce non-negativity, preventing a single feature from representing bidirectional concepts (e.g., male vs. female). This structural constraint fragments semantic axes into separate, redundant features, limiting representational completeness. To address this issue, we propose AbsTopK SAE, a new variant derived from the $\ell_0$ sparsity constraint that applies hard thresholding over the largest-magnitude activations. By preserving both positive and negative activations, AbsTopK uncovers richer, bidirectional conceptual representations. Comprehensive experiments across four LLMs and seven probing and steering tasks show that AbsTopK improves reconstruction fidelity, enhances interpretability, and enables single features to encode contrasting concepts. Remarkably, AbsTopK matches or even surpasses the Difference-in-Mean method, a supervised approach that requires labeled data for each concept and has been shown in prior work to outperform SAEs.

