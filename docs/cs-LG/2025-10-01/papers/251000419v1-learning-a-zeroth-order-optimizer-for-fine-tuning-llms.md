---
layout: default
title: Learning a Zeroth-Order Optimizer for Fine-Tuning LLMs
---

# Learning a Zeroth-Order Optimizer for Fine-Tuning LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00419" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00419v1</a>
  <a href="https://arxiv.org/pdf/2510.00419.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00419v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00419v1', 'Learning a Zeroth-Order Optimizer for Fine-Tuning LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kairun Zhang, Haoyu Li, Yanjun Zhao, Yifan Sun, Huan Zhang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-10-01

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/ASTRAL-Group/ZO_Fine_tuner.git)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºZO Fine-tunerï¼Œä¸€ç§å­¦ä¹ å‹é›¶é˜¶ä¼˜åŒ–å™¨ï¼Œç”¨äºé«˜æ•ˆå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é›¶é˜¶ä¼˜åŒ–` `å¤§è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `å­¦ä¹ è¿ç§»` `å…ƒå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰é›¶é˜¶ä¼˜åŒ–å™¨ä¾èµ–æ‰‹å·¥é™æ€é‡‡æ ·ç­–ç•¥ï¼Œæ— æ³•é€‚åº”ä¸åŒLLMçš„ç»“æ„ç‰¹æ€§ï¼Œé™åˆ¶äº†å¾®è°ƒæ•ˆç‡ã€‚
2. ZO Fine-tuneré€šè¿‡å­¦ä¹ é«˜æ•ˆæ‰°åŠ¨ç­–ç•¥ï¼Œä¸ºæ¯ä¸ªLLMå®šåˆ¶ä¼˜åŒ–å™¨ï¼Œå®ç°ä¸€æ¬¡è®­ç»ƒï¼Œå¤šæ¬¡å¤ç”¨ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒZO Fine-tuneråœ¨å¤šç§LLMå’Œæ•°æ®é›†ä¸Šè¶…è¶Šç°æœ‰é›¶é˜¶æ–¹æ³•ï¼Œå±•ç°äº†ä¼˜è¶Šçš„æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é›¶é˜¶ä¼˜åŒ–å™¨æœ€è¿‘ä½œä¸ºä¸€ç§å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å®ç”¨æ–¹æ³•è€Œå‡ºç°ï¼Œä¸ä¼ ç»Ÿçš„ä¸€é˜¶æ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—é™ä½äº†GPUå†…å­˜æ¶ˆè€—ã€‚ç„¶è€Œï¼Œç°æœ‰çš„é›¶é˜¶æ–¹æ³•ä¾èµ–äºæ‰‹å·¥åˆ¶ä½œçš„ã€é™æ€çš„é‡‡æ ·ç­–ç•¥ï¼Œè¿™äº›ç­–ç•¥ä¸èƒ½é€‚åº”æ¨¡å‹ç‰¹å®šçš„ç»“æ„ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ZO Fine-tunerï¼Œä¸€ç§åŸºäºå­¦ä¹ çš„LLMé›¶é˜¶ä¼˜åŒ–å™¨ï¼Œå®ƒé€šè¿‡ç´§å‡‘ä¸”å†…å­˜é«˜æ•ˆçš„è®¾è®¡è‡ªåŠ¨å­¦ä¹ é«˜æ•ˆçš„æ‰°åŠ¨ç­–ç•¥ã€‚è‡³å…³é‡è¦çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å—åˆ°ä»¥ä¸‹è§‚å¯Ÿçš„æ¨åŠ¨ï¼šåªæœ‰å°‘æ•°åŸºç¡€æ¨¡å‹åŠå…¶è¡ç”Ÿç‰©åœ¨å®è·µä¸­è¢«å¹¿æ³›é‡‡ç”¨ã€‚å› æ­¤ï¼Œå¯¹äºç»™å®šçš„LLMå­¦ä¹ ä¸€æ¬¡ä¼˜åŒ–å™¨ï¼Œå¹¶åœ¨ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ä¸­é‡å¤ä½¿ç”¨å®ƒæ˜¯å¯è¡Œä¸”éå¸¸ç†æƒ³çš„ã€‚å› æ­¤ï¼ŒZO Fine-tuneræ—¨åœ¨é€šè¿‡æ”¯æŒæ¯ä¸ªLLMä¸€æ¬¡æ€§è®­ç»ƒä¸”å¼€é”€æœ€å°çš„æ–¹å¼ï¼Œå°†å­¦ä¹ è¿ç§»åˆ°å­¦ä¹ ï¼ˆL2Lï¼‰æ‰©å±•åˆ°åŸºç¡€æ¨¡å‹æ—¶ä»£ã€‚åœ¨4ä¸ªLLMå’Œ7ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒZO Fine-tuneråœ¨82.1%çš„ä»»åŠ¡-æ¨¡å‹ç»„åˆä¸­ä¼˜äºå…ˆå‰çš„é›¶é˜¶åŸºçº¿ï¼Œä»è€Œè¯æ˜äº†å…¶åœ¨é«˜æ•ˆLLMå¾®è°ƒæ–¹é¢çš„å¼ºå¤§æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰é›¶é˜¶ä¼˜åŒ–å™¨åœ¨å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹æ—¶ï¼Œé‡‡ç”¨å›ºå®šçš„ã€äººå·¥è®¾è®¡çš„é‡‡æ ·ç­–ç•¥ï¼Œæ— æ³•æ ¹æ®ä¸åŒæ¨¡å‹çš„ç‰¹æ€§è¿›è¡Œè°ƒæ•´ï¼Œå¯¼è‡´ä¼˜åŒ–æ•ˆç‡ä½ä¸‹ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹æ¯ä¸ªä¸‹æ¸¸ä»»åŠ¡éƒ½é‡æ–°è®­ç»ƒä¼˜åŒ–å™¨ä¼šå¸¦æ¥å·¨å¤§çš„è®¡ç®—å¼€é”€ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å­¦ä¹ è¿ç§»ï¼ˆL2Lï¼‰çš„æ€æƒ³ï¼Œä¸ºæ¯ä¸ªåŸºç¡€LLMå­¦ä¹ ä¸€ä¸ªå®šåˆ¶çš„é›¶é˜¶ä¼˜åŒ–å™¨ã€‚è¯¥ä¼˜åŒ–å™¨èƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ é«˜æ•ˆçš„æ‰°åŠ¨ç­–ç•¥ï¼Œå¹¶åœ¨ä¸åŒçš„ä¸‹æ¸¸ä»»åŠ¡ä¸­é‡å¤ä½¿ç”¨ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬å¹¶æé«˜å¾®è°ƒæ•ˆç‡ã€‚è¿™ç§æ–¹æ³•åŸºäºä¸€ä¸ªå…³é”®è§‚å¯Ÿï¼šå®é™…åº”ç”¨ä¸­å¹¿æ³›ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹æ•°é‡æœ‰é™ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šZO Fine-tunerçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šä¼˜åŒ–å™¨è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨ä¼˜åŒ–å™¨è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨ä¸€ä¸ªå…ƒå­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè®­ç»ƒï¼Œä½¿ä¼˜åŒ–å™¨èƒ½å¤Ÿå­¦ä¹ åˆ°é€‚åº”ç‰¹å®šLLMç»“æ„çš„æ‰°åŠ¨ç­–ç•¥ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œå°†è®­ç»ƒå¥½çš„ä¼˜åŒ–å™¨åº”ç”¨äºæ–°çš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œä»¥é«˜æ•ˆåœ°å¾®è°ƒLLMã€‚

**å…³é”®åˆ›æ–°**ï¼šZO Fine-tunerçš„å…³é”®åˆ›æ–°åœ¨äºå°†å­¦ä¹ è¿ç§»çš„æ€æƒ³å¼•å…¥åˆ°é›¶é˜¶ä¼˜åŒ–å™¨çš„è®¾è®¡ä¸­ã€‚ä¸ä¼ ç»Ÿçš„é™æ€é‡‡æ ·ç­–ç•¥ä¸åŒï¼ŒZO Fine-tunerèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ é€‚åº”æ¨¡å‹ç»“æ„çš„æ‰°åŠ¨ç­–ç•¥ï¼Œä»è€Œæé«˜ä¼˜åŒ–æ•ˆç‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡ä¸€æ¬¡è®­ç»ƒï¼Œå¤šæ¬¡å¤ç”¨çš„æ–¹å¼ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šZO Fine-tunerçš„å…·ä½“è®¾è®¡ç»†èŠ‚åŒ…æ‹¬ï¼šä½¿ç”¨ç´§å‡‘ä¸”å†…å­˜é«˜æ•ˆçš„ç½‘ç»œç»“æ„æ¥è¡¨ç¤ºä¼˜åŒ–å™¨ï¼Œä»¥é™ä½è®­ç»ƒå¼€é”€ï¼›è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä»¥é¼“åŠ±ä¼˜åŒ–å™¨å­¦ä¹ åˆ°é«˜æ•ˆçš„æ‰°åŠ¨ç­–ç•¥ï¼›é‡‡ç”¨ç‰¹å®šçš„é‡‡æ ·æ–¹æ³•ï¼Œä»¥å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨ï¼Œä»è€Œæé«˜ä¼˜åŒ–æ•ˆç‡ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆå…·ä½“ç»†èŠ‚æœªçŸ¥ï¼‰ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒZO Fine-tuneråœ¨4ä¸ªLLMå’Œ7ä¸ªæ•°æ®é›†ä¸Šçš„è¡¨ç°ä¼˜äºç°æœ‰çš„é›¶é˜¶ä¼˜åŒ–å™¨åŸºçº¿ã€‚åœ¨82.1%çš„ä»»åŠ¡-æ¨¡å‹ç»„åˆä¸­ï¼ŒZO Fine-tunerå–å¾—äº†æ›´å¥½çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨é«˜æ•ˆLLMå¾®è°ƒæ–¹é¢çš„å¼ºå¤§æ€§èƒ½å’Œå¯æ‰©å±•æ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦åœ¨ä¸åŒä»»åŠ¡å’Œæ¨¡å‹ä¸Šæœ‰æ‰€ä¸åŒï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ZO Fine-tunerå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦é«˜æ•ˆå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„åœºæ™¯ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—é™ä½å¾®è°ƒæˆæœ¬ï¼ŒåŠ é€Ÿæ¨¡å‹è¿­ä»£ï¼Œå¹¶æé«˜æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚å°¤å…¶é€‚ç”¨äºèµ„æºå—é™çš„ç¯å¢ƒï¼Œä¾‹å¦‚è¾¹ç¼˜è®¡ç®—è®¾å¤‡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Zeroth-order optimizers have recently emerged as a practical approach for fine-tuning large language models (LLMs), significantly reducing GPU memory consumption compared to traditional first-order methods. Yet, existing zeroth-order methods rely on hand-crafted, static sampling strategies that are not adaptable to model-specific structures. To address this, we propose ZO Fine-tuner, a learning-based zeroth-order optimizer for LLMs that automatically learns efficient perturbation strategies through a compact and memory-efficient design. Crucially, our approach is motivated by the observation that only a small number of foundation models and their derivatives are widely adopted in practice. Therefore, learning the optimizer once for a given LLM and reusing it across diverse downstream tasks is both feasible and highly desirable. Accordingly, ZO Fine-tuner is designed to scale learning to learn (L2L) to the foundation-model era by supporting one-time training per LLM with minimal overhead. Experiments on 4 LLMs and 7 datasets show that ZO Fine-tuner outperforms prior zeroth-order baselines in 82.1\% of task-model combinations, thereby demonstrating strong performance and scalability for efficient LLM fine-tuning. Our code is available at https://github.com/ASTRAL-Group/ZO_Fine_tuner.git.

