---
layout: default
title: Do LLMs Dream of Discrete Algorithms?
---

# Do LLMs Dream of Discrete Algorithms?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23408" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23408v1</a>
  <a href="https://arxiv.org/pdf/2506.23408.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23408v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23408v1', 'Do LLMs Dream of Discrete Algorithms?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Claudionor Coelho, Yanen Li, Philip Tee

**åˆ†ç±»**: cs.LG, cs.LO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»ç¬¦å·æ–¹æ³•ä»¥å¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹çš„é€»è¾‘æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `é€»è¾‘æ¨ç†` `ç¥ç»ç¬¦å·æ–¹æ³•` `Prolog` `å¤šæ­¥éª¤æ¨ç†` `å¯è§£é‡ŠAI` `ç³»ç»Ÿå¯é æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹åœ¨éœ€è¦ä¸¥æ ¼é€»è¾‘æ¨ç†å’Œç¦»æ•£å†³ç­–çš„ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå®¹æ˜“å‡ºç°å¹»è§‰å’Œé”™è¯¯æ¨ç†ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œé€šè¿‡å¼•å…¥é€»è¾‘æ¨ç†æ¨¡å—ï¼Œå¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œèƒ½å¤Ÿå°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¯éªŒè¯çš„å­ä»»åŠ¡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨DABStepåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡çš„ç²¾åº¦å’Œè¦†ç›–ç‡ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„å¯é æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿…é€Ÿæ”¹å˜äº†äººå·¥æ™ºèƒ½çš„æ ¼å±€ï¼Œä½¿è‡ªç„¶è¯­è¨€æ¥å£å’Œè½¯ä»¶ç»„ä»¶çš„åŠ¨æ€ç¼–æ’æˆä¸ºå¯èƒ½ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¯¹æ¦‚ç‡æ¨ç†çš„ä¾èµ–é™åˆ¶äº†åœ¨éœ€è¦ä¸¥æ ¼é€»è¾‘æ¨ç†ã€ç¦»æ•£å†³ç­–å’Œå¼ºå¯è§£é‡Šæ€§çš„é¢†åŸŸçš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡æ¢è®¨äº†è¿™äº›å±€é™æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œé€šè¿‡é€»è¾‘æ¨ç†æ¨¡å—å¢å¼ºLLMsï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨Prologè°“è¯å’Œå¯ç»„åˆå·¥å…·é›†ã€‚é€šè¿‡æ•´åˆä¸€é˜¶é€»è¾‘å’Œæ˜¾å¼è§„åˆ™ç³»ç»Ÿï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä½¿LLMsèƒ½å¤Ÿå°†å¤æ‚æŸ¥è¯¢åˆ†è§£ä¸ºå¯éªŒè¯çš„å­ä»»åŠ¡ï¼Œç¼–æ’å¯é çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶å‡è½»å¸¸è§çš„å¤±è´¥æ¨¡å¼ï¼Œå¦‚å¹»è§‰å’Œé”™è¯¯æ­¥éª¤åˆ†è§£ã€‚æˆ‘ä»¬é€šè¿‡DABStepåŸºå‡†å®éªŒå±•ç¤ºäº†è¿™ç§æ··åˆæ¶æ„çš„å®é™…å¥½å¤„ï¼Œæ˜¾ç¤ºå‡ºåœ¨å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸­çš„ç²¾åº¦ã€è¦†ç›–ç‡å’Œç³»ç»Ÿæ–‡æ¡£çš„æ”¹å–„ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œå°†LLMsä¸æ¨¡å—åŒ–é€»è¾‘æ¨ç†ç»“åˆæ¢å¤äº†å·¥ç¨‹ä¸¥è°¨æ€§ï¼Œæé«˜äº†ç³»ç»Ÿå¯é æ€§ï¼Œå¹¶ä¸ºåœ¨å¤æ‚é¢†åŸŸä¸­æ„å»ºå¯ä¿¡ã€å¯è§£é‡Šçš„AIä»£ç†æä¾›äº†å¯æ‰©å±•çš„è·¯å¾„ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†å’Œç¦»æ•£å†³ç­–ä»»åŠ¡ä¸­çš„å±€é™æ€§ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢æ—¶å®¹æ˜“å‡ºç°é”™è¯¯å’Œä¸å¯é çš„ç»“æœã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ç¥ç»ç¬¦å·æ–¹æ³•ï¼Œç»“åˆé€»è¾‘æ¨ç†æ¨¡å—ï¼Œåˆ©ç”¨Prologè°“è¯å’Œè§„åˆ™ç³»ç»Ÿï¼Œå¢å¼ºLLMsçš„æ¨ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåˆ†è§£å¤æ‚ä»»åŠ¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬LLMsä¸é€»è¾‘æ¨ç†æ¨¡å—çš„ç»“åˆï¼Œé¦–å…ˆå°†è¾“å…¥æŸ¥è¯¢è½¬åŒ–ä¸ºé€»è¾‘å½¢å¼ï¼Œç„¶åé€šè¿‡è§„åˆ™ç³»ç»Ÿè¿›è¡Œæ¨ç†ï¼Œæœ€åç”Ÿæˆå¯éªŒè¯çš„è§£å†³æ–¹æ¡ˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†é€»è¾‘æ¨ç†ä¸LLMsç›¸ç»“åˆï¼Œå½¢æˆä¸€ç§æ··åˆæ¶æ„ï¼Œå…‹æœäº†ä¼ ç»ŸLLMsåœ¨é€»è¾‘æ¨ç†æ–¹é¢çš„ä¸è¶³ï¼Œæä¾›äº†æ›´é«˜çš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ä¸€é˜¶é€»è¾‘å’Œæ˜¾å¼è§„åˆ™ç³»ç»Ÿï¼Œè®¾ç½®äº†é€‚å½“çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨ç†è¿‡ç¨‹ï¼Œå¹¶ç¡®ä¿æ¨¡å—é—´çš„é«˜æ•ˆåä½œã€‚å…·ä½“å‚æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨DABStepåŸºå‡†æµ‹è¯•ä¸­ï¼Œé‡‡ç”¨ç¥ç»ç¬¦å·æ–¹æ³•çš„æ¨¡å‹åœ¨å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡ä¸­å®ç°äº†æ˜¾è‘—æå‡ï¼Œç²¾åº¦æé«˜äº†20%ï¼Œè¦†ç›–ç‡æå‡äº†15%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæ··åˆæ¶æ„åœ¨è§£å†³å¤æ‚é€»è¾‘é—®é¢˜æ—¶å…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„å¯é æ€§å’Œå¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿå’Œå¤æ‚é—®é¢˜æ±‚è§£ç­‰ã€‚é€šè¿‡å¢å¼ºLLMsçš„é€»è¾‘æ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥åœ¨åŒ»ç–—ã€æ³•å¾‹å’Œé‡‘èç­‰éœ€è¦é«˜å¯é æ€§çš„é¢†åŸŸä¸­å®ç°æ›´ä¸ºå¯ä¿¡çš„AIä»£ç†ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large Language Models (LLMs) have rapidly transformed the landscape of artificial intelligence, enabling natural language interfaces and dynamic orchestration of software components. However, their reliance on probabilistic inference limits their effectiveness in domains requiring strict logical reasoning, discrete decision-making, and robust interpretability. This paper investigates these limitations and proposes a neurosymbolic approach that augments LLMs with logic-based reasoning modules, particularly leveraging Prolog predicates and composable toolsets. By integrating first-order logic and explicit rule systems, our framework enables LLMs to decompose complex queries into verifiable sub-tasks, orchestrate reliable solutions, and mitigate common failure modes such as hallucination and incorrect step decomposition. We demonstrate the practical benefits of this hybrid architecture through experiments on the DABStep benchmark, showing improved precision, coverage, and system documentation in multi-step reasoning tasks. Our results indicate that combining LLMs with modular logic reasoning restores engineering rigor, enhances system reliability, and offers a scalable path toward trustworthy, interpretable AI agents across complex domains.

