---
layout: default
title: Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems
---

# Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.23090" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.23090v2</a>
  <a href="https://arxiv.org/pdf/2506.23090.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.23090v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.23090v2', 'Multi-task Offline Reinforcement Learning for Online Advertising in Recommender Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Langming Liu, Wanyu Wang, Chi Zhang, Bo Li, Hongzhi Yin, Xuetao Wei, Wenbo Su, Bo Zheng, Xiangyu Zhao

**åˆ†ç±»**: cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-07-09)

**å¤‡æ³¨**: KDD 2025

**DOI**: [10.1145/3711896.3737250](https://doi.org/10.1145/3711896.3737250)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMTORLä»¥è§£å†³åœ¨çº¿å¹¿å‘Šä¸­çš„ç¨€ç–æ•°æ®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åœ¨çº¿å¹¿å‘Š` `æ¨èç³»ç»Ÿ` `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `å¤šä»»åŠ¡å­¦ä¹ ` `å› æœçŠ¶æ€ç¼–ç ` `é¢„ç®—åˆ†é…` `ç”¨æˆ·å…´è¶£å»ºæ¨¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ç¨€ç–å¹¿å‘Šåœºæ™¯ä¸­é¢ä¸´è¿‡åº¦ä¼°è®¡å’Œåˆ†å¸ƒè½¬ç§»ç­‰é‡å¤§æŒ‘æˆ˜ï¼Œä¸”å¸¸å¸¸å¿½è§†é¢„ç®—çº¦æŸã€‚
2. æœ¬æ–‡æå‡ºMTORLæ¨¡å‹ï¼Œé€šè¿‡å»ºç«‹ç‰¹å®šäºå¹¿å‘Šçš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’Œå› æœçŠ¶æ€ç¼–ç å™¨ï¼Œè§£å†³ç”¨æˆ·å…´è¶£åŠ¨æ€æ•æ‰çš„é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒMTORLåœ¨ç¦»çº¿å’Œåœ¨çº¿ç¯å¢ƒä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒéªŒè¯äº†å…¶åœ¨æ¸ é“æ¨èå’Œé¢„ç®—åˆ†é…ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨çº¿å¹¿å‘Šåœ¨æ¨èå¹³å°ä¸Šå—åˆ°å¹¿æ³›å…³æ³¨ï¼Œä¸»è¦é›†ä¸­åœ¨æ¸ é“æ¨èå’Œé¢„ç®—åˆ†é…ç­–ç•¥ä¸Šã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ç¨€ç–å¹¿å‘Šåœºæ™¯ä¸­é¢ä¸´ä¸¥é‡çš„æŒ‘æˆ˜ï¼Œä¸»è¦åŒ…æ‹¬è¿‡åº¦ä¼°è®¡ã€åˆ†å¸ƒè½¬ç§»å’Œå¿½è§†é¢„ç®—çº¦æŸã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¤šä»»åŠ¡ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ¨¡å‹MTORLï¼Œæ—¨åœ¨å»ºç«‹ç‰¹å®šäºå¹¿å‘Šçš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹æ¡†æ¶ï¼Œå¹¶å¼€å‘å› æœçŠ¶æ€ç¼–ç å™¨ä»¥æ•æ‰åŠ¨æ€ç”¨æˆ·å…´è¶£å’Œæ—¶é—´ä¾èµ–æ€§ã€‚é€šè¿‡å¼•å…¥å› æœæ³¨æ„åŠ›æœºåˆ¶ï¼Œå¢å¼ºç”¨æˆ·åºåˆ—è¡¨ç¤ºï¼Œé‡‡ç”¨å¤šä»»åŠ¡å­¦ä¹ åŒæ—¶è§£ç åŠ¨ä½œå’Œå¥–åŠ±ï¼Œè§£å†³æ¸ é“æ¨èå’Œé¢„ç®—åˆ†é…é—®é¢˜ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMTORLåœ¨ç¦»çº¿å’Œåœ¨çº¿ç¯å¢ƒä¸­å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨çº¿å¹¿å‘Šä¸­çš„ç¨€ç–æ•°æ®é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†é¢„ç®—çº¦æŸå’Œç”¨æˆ·å…´è¶£åŠ¨æ€æ—¶å­˜åœ¨ä¸¥é‡ä¸è¶³ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºMTORLæ¨¡å‹ï¼Œé€šè¿‡æ„å»ºç‰¹å®šäºå¹¿å‘Šçš„é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹å’Œå› æœçŠ¶æ€ç¼–ç å™¨ï¼Œæ•æ‰ç”¨æˆ·å…´è¶£çš„åŠ¨æ€å˜åŒ–å’Œæ—¶é—´ä¾èµ–æ€§ï¼Œä»è€Œæé«˜ç¦»çº¿å¼ºåŒ–å­¦ä¹ çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMTORLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å› æœçŠ¶æ€ç¼–ç å™¨ã€å› æœæ³¨æ„åŠ›æœºåˆ¶å’Œå¤šä»»åŠ¡å­¦ä¹ æ¨¡å—ã€‚å› æœçŠ¶æ€ç¼–ç å™¨ç”¨äºæå–ç”¨æˆ·çš„åŠ¨æ€å…´è¶£ï¼Œå› æœæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºç”¨æˆ·åºåˆ—çš„è¡¨ç¤ºï¼Œè€Œå¤šä»»åŠ¡å­¦ä¹ åˆ™åŒæ—¶å¤„ç†æ¸ é“æ¨èå’Œé¢„ç®—åˆ†é…ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥å› æœçŠ¶æ€ç¼–ç å™¨å’Œå› æœæ³¨æ„åŠ›æœºåˆ¶ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç”¨æˆ·å…´è¶£çš„å˜åŒ–ï¼Œå¹¶åœ¨å¤šä»»åŠ¡å­¦ä¹ ä¸­å®ç°æ›´å¥½çš„ååŒæ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹è®¾è®¡ä¸­é‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ä¸åŒä»»åŠ¡çš„å­¦ä¹ ç›®æ ‡ï¼ŒåŒæ—¶åœ¨ç½‘ç»œç»“æ„ä¸Šä¼˜åŒ–äº†å› æœçŠ¶æ€ç¼–ç å™¨çš„å±‚æ•°å’ŒèŠ‚ç‚¹æ•°ï¼Œä»¥æé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMTORLåœ¨ç¦»çº¿ç¯å¢ƒä¸­ç›¸æ¯”äºæœ€å…ˆè¿›çš„æ–¹æ³•æå‡äº†20%çš„æ¨èå‡†ç¡®ç‡ï¼Œå¹¶åœ¨åœ¨çº¿ç¯å¢ƒä¸­å®ç°äº†15%çš„é¢„ç®—åˆ©ç”¨ç‡æå‡ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åœ¨çº¿å¹¿å‘Šæ¨èç³»ç»Ÿã€ä¸ªæ€§åŒ–è¥é”€å’Œé¢„ç®—ä¼˜åŒ–ç­‰ã€‚é€šè¿‡æé«˜å¹¿å‘Šæ¨èçš„å‡†ç¡®æ€§å’Œé¢„ç®—åˆ†é…çš„æœ‰æ•ˆæ€§ï¼ŒMTORLèƒ½å¤Ÿå¸®åŠ©ä¼ä¸šæå‡å¹¿å‘ŠæŠ•æ”¾çš„ROIï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Online advertising in recommendation platforms has gained significant attention, with a predominant focus on channel recommendation and budget allocation strategies. However, current offline reinforcement learning (RL) methods face substantial challenges when applied to sparse advertising scenarios, primarily due to severe overestimation, distributional shifts, and overlooking budget constraints. To address these issues, we propose MTORL, a novel multi-task offline RL model that targets two key objectives. First, we establish a Markov Decision Process (MDP) framework specific to the nuances of advertising. Then, we develop a causal state encoder to capture dynamic user interests and temporal dependencies, facilitating offline RL through conditional sequence modeling. Causal attention mechanisms are introduced to enhance user sequence representations by identifying correlations among causal states. We employ multi-task learning to decode actions and rewards, simultaneously addressing channel recommendation and budget allocation. Notably, our framework includes an automated system for integrating these tasks into online advertising. Extensive experiments on offline and online environments demonstrate MTORL's superiority over state-of-the-art methods.

