---
layout: default
title: Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap
---

# Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.00075" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.00075v3</a>
  <a href="https://arxiv.org/pdf/2507.00075.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.00075v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.00075v3', 'Theoretical Modeling of LLM Self-Improvement Training Dynamics Through Solver-Verifier Gap')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yifan Sun, Yushan Liang, Zhen Zhang, Jiaye Teng

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-29 (æ›´æ–°: 2025-10-10)

**å¤‡æ³¨**: 28 pages

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªæˆ‘æå‡è®­ç»ƒåŠ¨æ€æ¨¡å‹ä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `è‡ªæˆ‘æå‡` `æ±‚è§£è€…-éªŒè¯è€…` `è®­ç»ƒåŠ¨æ€` `ç†è®ºå»ºæ¨¡` `å¤–éƒ¨æ•°æ®å½±å“` `æ€§èƒ½ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¯¹å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æå‡è¿‡ç¨‹ä¸­çš„æ€§èƒ½æ¼”å˜ç¼ºä¹æ·±å…¥æ¢è®¨ï¼Œå¯¼è‡´å¯¹å…¶æ½œåŠ›çš„ç†è§£ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡æ±‚è§£è€…-éªŒè¯è€…å·®è·çš„ç†è®ºæ¡†æ¶æ¥å»ºæ¨¡è‡ªæˆ‘æå‡çš„è®­ç»ƒåŠ¨æ€ï¼Œé‡åŒ–å…¶èƒ½åŠ›æé™ã€‚
3. é€šè¿‡å¯¹å¤šç§å¤§è¯­è¨€æ¨¡å‹å’Œæ•°æ®é›†çš„å®è¯éªŒè¯ï¼Œå±•ç¤ºäº†è¯¥ç†è®ºæ¡†æ¶çš„æœ‰æ•ˆæ€§å’Œå¤–éƒ¨æ•°æ®çš„å½±å“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªæˆ‘æå‡æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢†åŸŸä¸­ä¸€ç§é‡è¦æŠ€æœ¯ï¼Œæ—¨åœ¨æ— éœ€å¤–éƒ¨æ•°æ®æå‡æ¨¡å‹æ€§èƒ½ã€‚å°½ç®¡å…¶é‡è¦æ€§æ˜¾è‘—ï¼Œä½†LLMåœ¨è‡ªæˆ‘æå‡è¿‡ç¨‹ä¸­çš„æ€§èƒ½æ¼”å˜å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚æœ¬æ–‡é€šè¿‡æ±‚è§£è€…-éªŒè¯è€…å·®è·çš„æ¦‚å¿µï¼Œç†è®ºå»ºæ¨¡è‡ªæˆ‘æå‡çš„è®­ç»ƒåŠ¨æ€ï¼Œæ­ç¤ºæ€§èƒ½æå‡æºäºLLMæ±‚è§£èƒ½åŠ›ä¸éªŒè¯èƒ½åŠ›ä¹‹é—´çš„å·®è·ã€‚åŸºäºè¯¥ç†è®ºæ¡†æ¶ï¼Œæœ¬æ–‡è¿›ä¸€æ­¥å±•ç¤ºäº†å¦‚ä½•å»ºæ¨¡æ•´ä¸ªè®­ç»ƒè½¨è¿¹ï¼Œå¹¶é€šè¿‡å®éªŒç»“æœéªŒè¯äº†ç†è®ºæ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ‰©å±•è‡³å¤–éƒ¨æ•°æ®å¯¹è¿™äº›åŠ¨æ€çš„å½±å“ï¼Œå‘ç°æœ‰é™å¤–éƒ¨æ•°æ®ä¸‹çš„ä½¿ç”¨æ—¶æœºå¯¹æœ€ç»ˆæ€§èƒ½å½±å“ä¸å¤§ï¼Œç¬¦åˆå®è¯è§‚å¯Ÿã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æå‡è¿‡ç¨‹ä¸­çš„æ€§èƒ½æ¼”å˜æœºåˆ¶å°šä¸æ˜ç¡®çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è§£é‡Šè‡ªæˆ‘æå‡å¦‚ä½•å½±å“æ¨¡å‹æ€§èƒ½ï¼Œå¯¼è‡´å¯¹å…¶ä¼˜åŒ–æ½œåŠ›çš„è®¤è¯†ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ±‚è§£è€…-éªŒè¯è€…å·®è·çš„æ¦‚å¿µï¼Œç†è®ºä¸Šå»ºæ¨¡è‡ªæˆ‘æå‡çš„è®­ç»ƒåŠ¨æ€ï¼Œè®¤ä¸ºæ€§èƒ½æå‡æºäºæ¨¡å‹æ±‚è§£èƒ½åŠ›ä¸éªŒè¯èƒ½åŠ›ä¹‹é—´çš„å·®è·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç†è®ºå»ºæ¨¡ã€å®éªŒéªŒè¯å’Œå¤–éƒ¨æ•°æ®å½±å“åˆ†æä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå»ºç«‹ç†è®ºæ¨¡å‹ä»¥æè¿°è®­ç»ƒåŠ¨æ€ï¼›å…¶æ¬¡ï¼Œé€šè¿‡å®éªŒæ•°æ®æ‹Ÿåˆæ¨¡å‹ï¼›æœ€åï¼Œåˆ†æå¤–éƒ¨æ•°æ®çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†æ±‚è§£è€…-éªŒè¯è€…å·®è·çš„æ¦‚å¿µï¼Œèƒ½å¤Ÿé‡åŒ–è‡ªæˆ‘æå‡çš„èƒ½åŠ›æé™ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´æ·±å±‚æ¬¡çš„ç†è®ºç†è§£ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬æ±‚è§£è€…ä¸éªŒè¯è€…çš„èƒ½åŠ›åº¦é‡ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¶…å‚æ•°è°ƒä¼˜ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿå‡†ç¡®åæ˜ è‡ªæˆ‘æå‡çš„åŠ¨æ€ç‰¹å¾ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„ç†è®ºæ¡†æ¶åœ¨å¤šç§å¤§è¯­è¨€æ¨¡å‹ä¸Šå‡æœ‰æ•ˆï¼Œèƒ½å¤Ÿå‡†ç¡®é¢„æµ‹è‡ªæˆ‘æå‡çš„è®­ç»ƒåŠ¨æ€ã€‚åœ¨æœ‰é™å¤–éƒ¨æ•°æ®çš„æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ€§èƒ½æœªå—åˆ°æ˜¾è‘—å½±å“ï¼ŒéªŒè¯äº†ç†è®ºæ¨¡å‹çš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œæ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹çš„è‡ªæˆ‘æå‡è¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨ä¸ä¾èµ–å¤–éƒ¨æ•°æ®çš„æƒ…å†µä¸‹æå‡æ¨¡å‹æ€§èƒ½ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-improvement is among the most prominent techniques within the realm of large language models (LLM), aiming to enhance the LLM performance without relying on external data. Despite its significance, generally how LLM performances evolve during the self-improvement process remains underexplored. In this paper, we theoretically model the training dynamics of self-improvement via the concept of solver-verifier gap. This is inspired by the conjecture that the performance enhancement of self-improvement stems from the gap between LLM's solver capability and verifier capability. Based on the theoretical framework, we further show how to model the entire training trajectory. This framework allows quantifying the capability limit of self-improvement by fitting the theoretical model to the experiment results. We empirically validate the effectiveness of the theoretical framework on various LLMs and datasets. Beyond self-improvement, we extend our analysis to investigate how external data influences these dynamics within the framework. Notably, we find that under limited external data regimes, such external data can be utilized at any stage without significantly affecting final performances, which accords with the empirical observations.

