---
layout: default
title: Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective
---

# Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16288" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16288v1</a>
  <a href="https://arxiv.org/pdf/2506.16288.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16288v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16288v1', 'Next-Token Prediction Should be Ambiguity-Sensitive: A Meta-Learning Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Leo Gagnon, Eric Elmoznino, Sarthak Mittal, Tom Marty, Tejas Kasetty, Dhanya Sridhar, Guillaume Lajoie

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMetaHMMä»¥è§£å†³é«˜æ­§ä¹‰ä¸‹çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªå›å½’æ¨¡å‹` `å…ƒå­¦ä¹ ` `é«˜æ­§ä¹‰é¢„æµ‹` `è´å¶æ–¯æ¨ç†` `Transformer`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹æ–¹æ³•åœ¨é«˜æ­§ä¹‰æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´è®¡ç®—å¤æ‚åº¦è¿‡é«˜ã€‚
2. æœ¬æ–‡æå‡ºMetaHMMåŸºå‡†ï¼Œé€šè¿‡å…ƒå­¦ä¹ æ–¹æ³•å°†ä»»åŠ¡æ¨ç†ä¸æ ‡è®°é¢„æµ‹è§£è€¦ï¼Œä»¥åº”å¯¹é«˜æ­§ä¹‰é¢„æµ‹çš„æŒ‘æˆ˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ”¹è¿›åçš„æ¨¡å‹åœ¨æ¨¡ç³Šä¸Šä¸‹æ–‡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨è®¡ç®—èµ„æºåˆ†é…å’Œæ¨ç†å¯æ‰©å±•æ€§æ–¹é¢ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªå›å½’åŸºç¡€æ¨¡å‹çš„å¿«é€Ÿé€‚åº”èƒ½åŠ›é€šå¸¸å½’å› äºå…¶å¤šæ ·åŒ–çš„é¢„è®­ç»ƒæ•°æ®ã€‚ä»è´å¶æ–¯çš„è§’åº¦æ¥çœ‹ï¼Œåœ¨é«˜æ­§ä¹‰æƒ…å†µä¸‹ï¼Œæœ€å°åŒ–é¢„æµ‹è¯¯å·®éœ€è¦æ•´åˆæ‰€æœ‰ä¸è§‚å¯Ÿç»“æœä¸€è‡´çš„æ½œåœ¨å‡è®¾ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­ï¼Œè¿™ç§æ–¹æ³•å¾€å¾€è¿‡äºé›„å¿ƒå‹ƒå‹ƒã€‚è®¤çŸ¥ç§‘å­¦æ—©å·²è®¤è¯†åˆ°è¿™ä¸€å±€é™æ€§ï¼Œå»ºè®®åœ¨è¿™ç§æƒ…å†µä¸‹ä½¿ç”¨å¯å‘å¼æˆ–ä¿¡æ¯å¯»æ±‚ç­–ç•¥ã€‚æœ¬æ–‡æå‡ºMetaHMMï¼Œä¸€ä¸ªå…·æœ‰ä¸°å¯Œç»„åˆç»“æ„å’Œå¯å¤„ç†çš„è´å¶æ–¯oracleçš„åˆæˆåºåˆ—å…ƒå­¦ä¹ åŸºå‡†ï¼ŒéªŒè¯äº†Transformeråœ¨é«˜æ­§ä¹‰é¢„æµ‹ä¸­çš„å›°éš¾ï¼Œå¹¶æå‡ºäº†ä¸€ç§å°†é¢„è®­ç»ƒæ¨¡å‹è½¬åŒ–ä¸ºè’™ç‰¹å¡æ´›é¢„æµ‹å™¨çš„æ–¹æ³•ï¼Œä»¥æ”¹å–„æ¨¡ç³Šä¸Šä¸‹æ–‡ä¸­çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨é«˜æ­§ä¹‰æƒ…å†µä¸‹ä¸‹ä¸€ä¸ªæ ‡è®°é¢„æµ‹çš„è®¡ç®—å¤æ‚æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šç§æ½œåœ¨å‡è®¾æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆä¿¡æ¯ï¼Œå¯¼è‡´é¢„æµ‹æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å…ƒå­¦ä¹ æ–¹æ³•MetaHMMï¼Œå°†ä»»åŠ¡æ¨ç†ä¸æ ‡è®°é¢„æµ‹åˆ†ç¦»ï¼Œä»è€Œé™ä½é«˜æ­§ä¹‰æƒ…å†µä¸‹çš„è®¡ç®—è´Ÿæ‹…ã€‚è¿™ç§è®¾è®¡çµæ„Ÿæ¥æºäºè®¤çŸ¥ç§‘å­¦ä¸­çš„å¯å‘å¼ç­–ç•¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMetaHMMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬åˆæˆåºåˆ—ç”Ÿæˆã€å…ƒå­¦ä¹ è®­ç»ƒå’ŒåŸºäºè’™ç‰¹å¡æ´›çš„æ¨ç†æ¨¡å—ã€‚åˆæˆåºåˆ—ç”Ÿæˆç”¨äºåˆ›å»ºå…·æœ‰ä¸°å¯Œç»„åˆç»“æ„çš„æ•°æ®é›†ï¼Œå…ƒå­¦ä¹ è®­ç»ƒåˆ™ç”¨äºä¼˜åŒ–æ¨¡å‹åœ¨ä¸åŒæ­§ä¹‰æ°´å¹³ä¸‹çš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†é¢„è®­ç»ƒæ¨¡å‹è½¬åŒ–ä¸ºè’™ç‰¹å¡æ´›é¢„æµ‹å™¨ï¼Œå…è®¸æ¨¡å‹åœ¨æ¨ç†æ—¶åŠ¨æ€è°ƒæ•´è®¡ç®—èµ„æºï¼Œä»¥åº”å¯¹ä¸åŒçš„æ­§ä¹‰æ°´å¹³ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å…¨å±€æ¨ç†æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥å¹³è¡¡ä¸åŒæ­§ä¹‰æƒ…å†µä¸‹çš„é¢„æµ‹ç²¾åº¦ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä»¥æ”¯æŒé«˜æ•ˆçš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMetaHMMåœ¨é«˜æ­§ä¹‰é¢„æµ‹ä»»åŠ¡ä¸­ï¼Œç›¸è¾ƒäºä¼ ç»ŸTransformeræ¨¡å‹ï¼Œæ€§èƒ½æå‡æ˜¾è‘—ï¼Œå°¤å…¶åœ¨æ¨¡ç³Šä¸Šä¸‹æ–‡ä¸­ï¼Œæ¨¡å‹çš„è®¡ç®—èµ„æºåˆ†é…å’Œæ¨ç†å¯æ‰©å±•æ€§å¾—åˆ°äº†æœ‰æ•ˆæ”¹å–„ï¼Œå…·ä½“æå‡å¹…åº¦æœªçŸ¥ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡æé«˜æ¨¡å‹åœ¨é«˜æ­§ä¹‰æƒ…å†µä¸‹çš„é¢„æµ‹èƒ½åŠ›ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿçš„æ™ºèƒ½åŒ–æ°´å¹³ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šå½±å“æ›´å¹¿æ³›çš„AIåº”ç”¨ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The rapid adaptation ability of auto-regressive foundation models is often attributed to the diversity of their pre-training data. This is because, from a Bayesian standpoint, minimizing prediction error in such settings requires integrating over all plausible latent hypotheses consistent with observations. While this behavior is desirable in principle, it often proves too ambitious in practice: under high ambiguity, the number of plausible latent alternatives makes Bayes-optimal prediction computationally intractable. Cognitive science has long recognized this limitation, suggesting that under such conditions, heuristics or information-seeking strategies are preferable to exhaustive inference. Translating this insight to next-token prediction, we hypothesize that low- and high-ambiguity predictions pose different computational demands, making ambiguity-agnostic next-token prediction a detrimental inductive bias. To test this, we introduce MetaHMM, a synthetic sequence meta-learning benchmark with rich compositional structure and a tractable Bayesian oracle. We show that Transformers indeed struggle with high-ambiguity predictions across model sizes. Motivated by cognitive theories, we propose a method to convert pre-trained models into Monte Carlo predictors that decouple task inference from token prediction. Preliminary results show substantial gains in ambiguous contexts through improved capacity allocation and test-time scalable inference, though challenges remain.

