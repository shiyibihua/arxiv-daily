---
layout: default
title: SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity
---

# SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16500" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16500v1</a>
  <a href="https://arxiv.org/pdf/2506.16500.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16500v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16500v1', 'SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Samir Khaki, Xiuyu Li, Junxian Guo, Ligeng Zhu, Chenfeng Xu, Konstantinos N. Plataniotis, Amir Yazdanbakhsh, Kurt Keutzer, Song Han, Zhijian Liu

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**å¤‡æ³¨**: ICML 2025. The first three authors contributed equally to this work. Project page: https://z-lab.ai/projects/sparselora

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSparseLoRAä»¥åŠ é€Ÿå¤§è¯­è¨€æ¨¡å‹çš„å¾®è°ƒè¿‡ç¨‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `å¾®è°ƒ` `ä¸Šä¸‹æ–‡ç¨€ç–æ€§` `SVD` `è®¡ç®—æ•ˆç‡` `æŸå¤±è®¡ç®—` `åŠ¨æ€é€‰æ‹©` `æ¨¡å‹ä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨è®¡ç®—æˆæœ¬ä¸Šå¹¶æœªå¾—åˆ°æœ‰æ•ˆé™ä½ï¼Œç”šè‡³å¯èƒ½å¯¼è‡´é€Ÿåº¦å˜æ…¢ï¼Œå½±å“å®é™…åº”ç”¨ã€‚
2. SparseLoRAé€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡ç¨€ç–æ€§å’Œè½»é‡çº§çš„SVDç¨€ç–æ€§ä¼°è®¡å™¨ï¼ŒåŠ¨æ€é€‰æ‹©ç¨€ç–æƒé‡ä»¥ä¼˜åŒ–å¾®è°ƒè¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºSparseLoRAåœ¨è®¡ç®—æˆæœ¬ä¸Šå‡å°‘äº†æœ€å¤š2.2å€ï¼Œé€Ÿåº¦æå‡è¾¾åˆ°1.6å€ï¼ŒåŒæ—¶ä¿æŒäº†å¤šé¡¹ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¢è€—è´¹è®¡ç®—èµ„æºåˆå ç”¨å¤§é‡å†…å­˜ã€‚å°½ç®¡åƒQLoRAå’ŒDoRAç­‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•å‡å°‘äº†å¯è®­ç»ƒå‚æ•°çš„æ•°é‡å¹¶é™ä½äº†å†…å­˜ä½¿ç”¨ï¼Œä½†å¹¶æœªé™ä½è®¡ç®—æˆæœ¬ï¼Œç”šè‡³å¯èƒ½å¯¼è‡´å¾®è°ƒé€Ÿåº¦å˜æ…¢ã€‚æœ¬æ–‡æå‡ºäº†SparseLoRAï¼Œä¸€ç§é€šè¿‡ä¸Šä¸‹æ–‡ç¨€ç–æ€§åŠ é€ŸLLMå¾®è°ƒçš„æ–¹æ³•ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§è½»é‡çº§çš„ã€æ— è®­ç»ƒçš„SVDç¨€ç–æ€§ä¼°è®¡å™¨ï¼ŒåŠ¨æ€é€‰æ‹©ç¨€ç–æƒé‡å­é›†ç”¨äºæŸå¤±å’Œæ¢¯åº¦è®¡ç®—ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬ç³»ç»Ÿåˆ†æå¹¶è§£å†³äº†å±‚ã€æ ‡è®°å’Œè®­ç»ƒæ­¥éª¤çš„æ•æ„Ÿæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSparseLoRAåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶ï¼Œè®¡ç®—æˆæœ¬é™ä½äº†æœ€å¤š2.2å€ï¼Œé€Ÿåº¦æå‡è¾¾åˆ°1.6å€ï¼Œé€‚ç”¨äºå¸¸è¯†æ¨ç†ã€ç®—æœ¯æ¨ç†ã€ä»£ç ç”Ÿæˆå’ŒæŒ‡ä»¤è·Ÿéšç­‰å¤šç§ä¸‹æ¸¸ä»»åŠ¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹å¾®è°ƒè¿‡ç¨‹ä¸­çš„é«˜è®¡ç®—å’Œå†…å­˜æ¶ˆè€—é—®é¢˜ã€‚ç°æœ‰çš„å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³•è™½ç„¶å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ï¼Œä½†æœªèƒ½æœ‰æ•ˆé™ä½è®¡ç®—æˆæœ¬ï¼Œå¯¼è‡´å¾®è°ƒæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSparseLoRAçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸Šä¸‹æ–‡ç¨€ç–æ€§æ¥åŠ é€Ÿå¾®è°ƒè¿‡ç¨‹ï¼Œé‡‡ç”¨è½»é‡çº§çš„SVDç¨€ç–æ€§ä¼°è®¡å™¨åŠ¨æ€é€‰æ‹©ç¨€ç–æƒé‡ï¼Œä»è€Œä¼˜åŒ–æŸå¤±å’Œæ¢¯åº¦è®¡ç®—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSparseLoRAçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ç¨€ç–æ€§ä¼°è®¡ã€åŠ¨æ€æƒé‡é€‰æ‹©å’ŒæŸå¤±è®¡ç®—ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡SVDä¼°è®¡æƒé‡çš„ç¨€ç–æ€§ï¼Œç„¶åæ ¹æ®ä¼°è®¡ç»“æœé€‰æ‹©ç¨€ç–æƒé‡ï¼Œæœ€åè¿›è¡ŒæŸå¤±å’Œæ¢¯åº¦è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šSparseLoRAçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥äº†è®­ç»ƒå‰çš„ç¨€ç–æ€§ä¼°è®¡å™¨ï¼Œèƒ½å¤ŸåŠ¨æ€é€‰æ‹©æƒé‡å­é›†ï¼Œä»è€Œæ˜¾è‘—é™ä½è®¡ç®—æˆæœ¬å’Œæé«˜å¾®è°ƒé€Ÿåº¦ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•åœ¨è®¡ç®—æ•ˆç‡ä¸Šæœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSparseLoRAä½¿ç”¨äº†è½»é‡çº§çš„SVDç®—æ³•è¿›è¡Œç¨€ç–æ€§ä¼°è®¡ï¼Œå¹¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†åŠ¨æ€é€‰æ‹©çš„ç¨€ç–æƒé‡ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒå±‚å’Œè®­ç»ƒæ­¥éª¤ä¸­ä¿æŒæ•æ„Ÿæ€§å’Œå‡†ç¡®æ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒSparseLoRAèƒ½å¤Ÿåœ¨å¤šç§ä»»åŠ¡ä¸­å®ç°é«˜æ•ˆçš„å¾®è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SparseLoRAåœ¨å®éªŒä¸­æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè®¡ç®—æˆæœ¬é™ä½æœ€å¤š2.2å€ï¼Œé€Ÿåº¦æå‡è¾¾åˆ°1.6å€ï¼ŒåŒæ—¶åœ¨å¸¸è¯†æ¨ç†ã€ç®—æœ¯æ¨ç†ã€ä»£ç ç”Ÿæˆå’ŒæŒ‡ä»¤è·Ÿéšç­‰å¤šé¡¹ä»»åŠ¡ä¸­ä¿æŒäº†é«˜å‡†ç¡®æ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜SparseLoRAåœ¨å¾®è°ƒå¤§è¯­è¨€æ¨¡å‹æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SparseLoRAçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œç‰¹åˆ«æ˜¯åœ¨éœ€è¦å¿«é€Ÿå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹çš„åœºæ™¯ä¸­ï¼Œå¦‚æ™ºèƒ½å®¢æœã€è‡ªåŠ¨åŒ–å†…å®¹ç”Ÿæˆå’Œä»£ç è¾…åŠ©ç¼–ç¨‹ç­‰é¢†åŸŸã€‚å…¶é«˜æ•ˆçš„è®¡ç®—æ€§èƒ½å’Œå‡†ç¡®æ€§ä½¿å¾—åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ä¹Ÿèƒ½å®ç°é«˜æ•ˆçš„æ¨¡å‹åº”ç”¨ï¼Œæ¨åŠ¨äº†AIæŠ€æœ¯çš„æ™®åŠå’Œåº”ç”¨ã€‚æœªæ¥ï¼ŒSparseLoRAå¯èƒ½ä¼šå½±å“æ›´å¤šé¢†åŸŸçš„æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–ç­–ç•¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Fine-tuning LLMs is both computationally and memory-intensive. While parameter-efficient fine-tuning methods, such as QLoRA and DoRA, reduce the number of trainable parameters and lower memory usage, they do not decrease computational cost. In some cases, they may even slow down fine-tuning. In this paper, we introduce SparseLoRA, a method that accelerates LLM fine-tuning through contextual sparsity. We propose a lightweight, training-free SVD sparsity estimator that dynamically selects a sparse subset of weights for loss and gradient computation. Also, we systematically analyze and address sensitivity across layers, tokens, and training steps. Our experimental results show that SparseLoRA reduces computational cost by up to 2.2 times and a measured speedup of up to 1.6 times while maintaining accuracy across various downstream tasks, including commonsense and arithmetic reasoning, code generation, and instruction following.

