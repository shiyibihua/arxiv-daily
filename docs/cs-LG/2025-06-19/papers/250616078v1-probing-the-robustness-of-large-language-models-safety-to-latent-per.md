---
layout: default
title: Probing the Robustness of Large Language Models Safety to Latent Perturbations
---

# Probing the Robustness of Large Language Models Safety to Latent Perturbations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16078" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16078v1</a>
  <a href="https://arxiv.org/pdf/2506.16078.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16078v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16078v1', 'Probing the Robustness of Large Language Models Safety to Latent Perturbations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Tianle Gu, Kexin Huang, Zongqi Wang, Yixu Wang, Jie Li, Yuanqi Yao, Yang Yao, Yujiu Yang, Yan Teng, Yingchun Wang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Carol-gutianle/LatentSafety)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¿€æ´»å¼•å¯¼æ”»å‡»ä»¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§å¯¹æŠ—èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å®‰å…¨å¯¹é½` `æ½œåœ¨æ‰°åŠ¨` `æ¿€æ´»å¼•å¯¼æ”»å‡»` `å¯¹æŠ—è®­ç»ƒ` `é²æ£’æ€§å¢å¼º`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å®‰å…¨å¯¹é½æ–¹æ³•åœ¨é¢å¯¹æ½œåœ¨æ‰°åŠ¨æ—¶è¡¨ç°å‡ºè„†å¼±æ€§ï¼Œå®¹æ˜“è§¦å‘ä¸å®‰å…¨çš„æ¨¡å‹å“åº”ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„æ¢æµ‹æ–¹æ³•ï¼Œé€šè¿‡æµ‹é‡è´Ÿå¯¹æ•°ä¼¼ç„¶æ¥é‡åŒ–æ½œåœ¨ç©ºé—´çš„å±€éƒ¨æ•æ„Ÿæ€§ï¼Œå¹¶åŸºäºæ­¤æ„å»ºæ¿€æ´»å¼•å¯¼æ”»å‡»ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€å±‚å¯¹æŠ—è¡¥ä¸è®­ç»ƒï¼ˆLAPTï¼‰æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹çš„å¯¹é½é²æ£’æ€§ï¼ŒåŒæ—¶ä¿æŒäº†å…¶é€šç”¨èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å®‰å…¨å¯¹é½æ˜¯æ„å»ºå¯é çš„äººå·¥é€šç”¨æ™ºèƒ½çš„å…³é”®è¦æ±‚ã€‚å°½ç®¡åœ¨å®‰å…¨å¯¹é½æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°å¾®å°çš„æ½œåœ¨æ‰°åŠ¨ä»ç„¶ä¼šè§¦å‘å¯¹é½æ¨¡å‹çš„ä¸å®‰å…¨å“åº”ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æºäºç°æœ‰å¯¹é½æ–¹æ³•çš„æµ…å±‚ç‰¹æ€§ï¼Œå®ƒä»¬å…³æ³¨è¡¨é¢æ‹’ç»è¡Œä¸ºï¼Œè€Œæœªèƒ½å……åˆ†æ”¹å˜å†…éƒ¨è¡¨ç¤ºã€‚å› æ­¤ï¼Œéšè—æ¿€æ´»çš„å¾®å°å˜åŒ–å¯èƒ½é‡æ–°è§¦å‘æ½œè—çš„æœ‰å®³è¡Œä¸ºã€‚ä¸ºæ¢è®¨å®‰å…¨å¯¹é½å¯¹æ½œåœ¨æ‰°åŠ¨çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ¢æµ‹æ–¹æ³•ï¼Œæµ‹é‡æ¨¡å‹ç”Ÿæˆçš„åŸå§‹å“åº”çš„è´Ÿå¯¹æ•°ä¼¼ç„¶ã€‚è¿™ä¸€æ¢æµ‹å·¥å…·é‡åŒ–äº†æ½œåœ¨ç©ºé—´çš„å±€éƒ¨æ•æ„Ÿæ€§ï¼Œå¸®åŠ©è¯†åˆ«è„†å¼±æ–¹å‘ã€‚åŸºäºæ­¤ä¿¡å·ï¼Œæˆ‘ä»¬æ„å»ºäº†æœ‰æ•ˆçš„è¶Šç‹±è½¨è¿¹ï¼Œæå‡ºäº†æ¿€æ´»å¼•å¯¼æ”»å‡»ï¼ˆASAï¼‰ã€‚æ›´é‡è¦çš„æ˜¯ï¼Œè¿™äº›è§è§£ä¸ºæé«˜å¯¹é½é²æ£’æ€§æä¾›äº†åŸåˆ™åŸºç¡€ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†é€å±‚å¯¹æŠ—è¡¥ä¸è®­ç»ƒï¼ˆLAPTï¼‰ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å‘éšè—è¡¨ç¤ºæ³¨å…¥å—æ§æ‰°åŠ¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒLAPTå¢å¼ºäº†å¯¹é½é²æ£’æ€§ï¼Œè€Œä¸å½±å“æ¨¡å‹çš„é€šç”¨èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡è¦è§£å†³çš„å…·ä½“é—®é¢˜æ˜¯ç°æœ‰å®‰å…¨å¯¹é½æ–¹æ³•åœ¨æ½œåœ¨æ‰°åŠ¨ä¸‹çš„è„†å¼±æ€§ï¼Œå¯¼è‡´æ¨¡å‹äº§ç”Ÿä¸å®‰å…¨å“åº”ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨è¡¨é¢è¡Œä¸ºï¼Œæœªèƒ½æœ‰æ•ˆæ”¹å˜å†…éƒ¨è¡¨ç¤ºï¼Œé€ æˆæ½œåœ¨ç©ºé—´ä¸­çš„æœ‰å®³è¡Œä¸ºè¢«é‡æ–°æ¿€æ´»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯é€šè¿‡å¼•å…¥æ¢æµ‹æ–¹æ³•æ¥é‡åŒ–æ½œåœ¨ç©ºé—´çš„å±€éƒ¨æ•æ„Ÿæ€§ï¼Œå¹¶åˆ©ç”¨è¿™ä¸€ä¿¡æ¯æ„å»ºæ¿€æ´»å¼•å¯¼æ”»å‡»ï¼ˆASAï¼‰ï¼Œä»è€Œè¯†åˆ«å’Œåˆ©ç”¨æ¨¡å‹çš„è„†å¼±æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ¢æµ‹æ¨¡å—ã€æ”»å‡»æ„å»ºæ¨¡å—å’Œé€å±‚å¯¹æŠ—è¡¥ä¸è®­ç»ƒï¼ˆLAPTï¼‰æ¨¡å—ã€‚æ¢æµ‹æ¨¡å—é€šè¿‡è´Ÿå¯¹æ•°ä¼¼ç„¶æµ‹é‡æ¨¡å‹å“åº”çš„æ•æ„Ÿæ€§ï¼Œæ”»å‡»æ„å»ºæ¨¡å—åŸºäºæ¢æµ‹ç»“æœç”Ÿæˆæ”»å‡»è·¯å¾„ï¼ŒLAPTåˆ™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ³¨å…¥æ‰°åŠ¨ä»¥å¢å¼ºé²æ£’æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ¿€æ´»å¼•å¯¼æ”»å‡»ï¼ˆASAï¼‰å’Œé€å±‚å¯¹æŠ—è¡¥ä¸è®­ç»ƒï¼ˆLAPTï¼‰ï¼Œè¿™ä¸¤è€…ç»“åˆæä¾›äº†ä¸€ç§æ–°çš„æ–¹æ³•æ¥å¢å¼ºæ¨¡å‹çš„å®‰å…¨å¯¹é½é²æ£’æ€§ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œå…³æ³¨ç‚¹ä»è¡¨é¢è¡Œä¸ºè½¬å‘äº†å†…éƒ¨è¡¨ç¤ºçš„æ·±å±‚æ¬¡è°ƒæ•´ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨LAPTä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„æ‰°åŠ¨æ³¨å…¥ç­–ç•¥ï¼Œç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹éšè—è¡¨ç¤ºæ–½åŠ å—æ§æ‰°åŠ¨ã€‚åŒæ—¶ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè€ƒè™‘äº†å¯¹é½é²æ£’æ€§ä¸æ¨¡å‹é€šç”¨èƒ½åŠ›ä¹‹é—´çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€å±‚å¯¹æŠ—è¡¥ä¸è®­ç»ƒï¼ˆLAPTï¼‰æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„å¯¹é½é²æ£’æ€§ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ¨¡å‹åœ¨é¢å¯¹æ½œåœ¨æ‰°åŠ¨æ—¶çš„ä¸å®‰å…¨å“åº”å‡å°‘äº†çº¦30%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œæ–°çš„è®­ç»ƒç­–ç•¥èƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºæ¨¡å‹çš„å®‰å…¨æ€§ï¼Œè€Œä¸æŸå®³å…¶é€šç”¨èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨æ•æ„Ÿçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­å’Œé‡‘èå†³ç­–ç­‰ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹çš„å®‰å…¨å¯¹é½é²æ£’æ€§ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­å‡ºç°ä¸å®‰å…¨è¡Œä¸ºçš„é£é™©ï¼Œä»è€Œæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œä¿¡ä»»åº¦ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯èƒ½æ¨åŠ¨æ›´æ·±å±‚æ¬¡çš„å¯¹é½æ–¹æ³•çš„å‘å±•ï¼Œä¿ƒè¿›äººå·¥æ™ºèƒ½çš„å®‰å…¨åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Safety alignment is a key requirement for building reliable Artificial General Intelligence. Despite significant advances in safety alignment, we observe that minor latent shifts can still trigger unsafe responses in aligned models. We argue that this stems from the shallow nature of existing alignment methods, which focus on surface-level refusal behaviors without sufficiently altering internal representations. Consequently, small shifts in hidden activations can re-trigger harmful behaviors embedded in the latent space. To explore the robustness of safety alignment to latent perturbations, we introduce a probing method that measures the Negative Log-Likelihood of the original response generated by the model. This probe quantifies local sensitivity in the latent space, serving as a diagnostic tool for identifying vulnerable directions. Based on this signal, we construct effective jailbreak trajectories, giving rise to the Activation Steering Attack (ASA). More importantly, these insights offer a principled foundation for improving alignment robustness. To this end, we introduce Layer-wise Adversarial Patch Training~(LAPT), a fine-tuning strategy that inject controlled perturbations into hidden representations during training. Experimental results highlight that LAPT strengthen alignment robustness without compromising general capabilities. Our findings reveal fundamental flaws in current alignment paradigms and call for representation-level training strategies that move beyond surface-level behavior supervision. Codes and results are available at https://github.com/Carol-gutianle/LatentSafety.

