---
layout: default
title: Bridging Brain with Foundation Models through Self-Supervised Learning
---

# Bridging Brain with Foundation Models through Self-Supervised Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16009" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16009v1</a>
  <a href="https://arxiv.org/pdf/2506.16009.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16009v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16009v1', 'Bridging Brain with Foundation Models through Self-Supervised Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hamdi Altaheri, Fakhri Karray, Md. Milon Islam, S M Taslim Uddin Raju, Amir-Hossein Karimi

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡è‡ªç›‘ç£å­¦ä¹ å°†åŸºç¡€æ¨¡å‹ä¸è„‘ä¿¡å·åˆ†æç›¸ç»“åˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸºç¡€æ¨¡å‹` `è‡ªç›‘ç£å­¦ä¹ ` `è„‘ä¿¡å·åˆ†æ` `å¤šæ¨¡æ€å­¦ä¹ ` `ç‰¹å¾æå–` `ç¥ç»ç½‘ç»œ` `åŒ»ç–—åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è„‘ä¿¡å·åˆ†æä¸­é¢ä¸´æ•°æ®æ ‡æ³¨ç¨€ç¼ºã€é«˜å™ªå£°å’Œä¸ªä½“å·®å¼‚ç­‰æŒ‘æˆ˜ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è‡ªç›‘ç£å­¦ä¹ çš„æ–¹æ³•ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»æœªæ ‡è®°çš„è„‘ä¿¡å·æ•°æ®ä¸­å­¦ä¹ æœ‰æ„ä¹‰çš„è¡¨ç¤ºï¼Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œé‡‡ç”¨åŸºç¡€æ¨¡å‹ä¸è‡ªç›‘ç£å­¦ä¹ ç»“åˆçš„æ–¹æ³•åœ¨è„‘ä¿¡å·åˆ†æä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†å¤æ‚ä¿¡å·æ—¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºç¡€æ¨¡å‹ï¼ˆFMsï¼‰é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰é‡æ–°å®šä¹‰äº†äººå·¥æ™ºèƒ½çš„èƒ½åŠ›ï¼Œåœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ç­‰é¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚è¿™äº›è¿›å±•ä¸ºè„‘ä¿¡å·åˆ†ææä¾›äº†å˜é©æ€§æœºä¼šã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ ä¸åŒï¼ŒSSLèƒ½å¤Ÿä»æœªæ ‡è®°æ•°æ®ä¸­å­¦ä¹ æœ‰æ„ä¹‰çš„è¡¨ç¤ºï¼Œå°¤å…¶é€‚ç”¨äºè„‘ä¿¡å·çš„é«˜å™ªå£°æ°´å¹³ã€ä¸ªä½“é—´å˜å¼‚æ€§å’Œä½ä¿¡å™ªæ¯”ç­‰ç‹¬ç‰¹æŒ‘æˆ˜ã€‚æœ¬æ–‡ç³»ç»Ÿå›é¡¾äº†é€šè¿‡SSLå°†è„‘ä¿¡å·ä¸åŸºç¡€æ¨¡å‹ç»“åˆçš„å‰æ²¿é¢†åŸŸï¼Œæ¢è®¨äº†å…³é”®çš„SSLæŠ€æœ¯ã€è„‘ç‰¹å®šåŸºç¡€æ¨¡å‹çš„å¼€å‘åŠå…¶åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„é€‚åº”æ€§ï¼Œæ¶µç›–äº†å¤šæ¨¡æ€SSLæ¡†æ¶ä¸­è„‘ä¿¡å·ä¸å…¶ä»–æ¨¡æ€çš„æ•´åˆã€‚æœ€åï¼Œæ–‡ç« æŒ‡å‡ºäº†ä¸»è¦æŒ‘æˆ˜å¹¶æ¦‚è¿°äº†æœªæ¥ç ”ç©¶æ–¹å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³è„‘ä¿¡å·åˆ†æä¸­æ•°æ®æ ‡æ³¨ä¸è¶³å’Œä¿¡å·å™ªå£°é«˜ç­‰é—®é¢˜ã€‚ç°æœ‰çš„ç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨è¿™äº›æ–¹é¢è¡¨ç°ä¸ä½³ï¼Œé™åˆ¶äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œæ¨¡å‹èƒ½å¤Ÿä»æœªæ ‡è®°çš„è„‘ä¿¡å·æ•°æ®ä¸­æå–ç‰¹å¾ï¼Œå­¦ä¹ åˆ°æ›´å…·ä»£è¡¨æ€§çš„è¡¨ç¤ºï¼Œä»è€Œæé«˜åˆ†æçš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€ç‰¹å¾æå–ã€æ¨¡å‹è®­ç»ƒå’Œä¸‹æ¸¸ä»»åŠ¡é€‚åº”å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®é¢„å¤„ç†é˜¶æ®µé’ˆå¯¹è„‘ä¿¡å·çš„ç‰¹æ€§è¿›è¡Œå™ªå£°è¿‡æ»¤ï¼Œç‰¹å¾æå–æ¨¡å—åˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ ç®—æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è‡ªç›‘ç£å­¦ä¹ ä¸è„‘ä¿¡å·åˆ†æç»“åˆï¼Œå¼€å‘å‡ºè„‘ç‰¹å®šçš„åŸºç¡€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹åœ¨ä½ä¿¡å™ªæ¯”æ¡ä»¶ä¸‹çš„è¡¨ç°ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨çš„åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ç‰¹å¾å­¦ä¹ ï¼Œå¹¶é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œç»“æ„å¢å¼ºæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œç¡®ä¿èƒ½å¤Ÿå¤„ç†å¤æ‚çš„è„‘ä¿¡å·æ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨è‡ªç›‘ç£å­¦ä¹ çš„åŸºç¡€æ¨¡å‹åœ¨è„‘ä¿¡å·åˆ†æä»»åŠ¡ä¸­ç›¸è¾ƒäºä¼ ç»Ÿç›‘ç£å­¦ä¹ æ–¹æ³•æå‡äº†çº¦20%çš„å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨é«˜å™ªå£°æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—è¯Šæ–­ã€è„‘æœºæ¥å£å’Œç¥ç»ç§‘å­¦ç ”ç©¶ç­‰ã€‚é€šè¿‡æé«˜è„‘ä¿¡å·åˆ†æçš„å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿä¸ºä¸´åºŠå†³ç­–æä¾›æ›´å¯é çš„æ”¯æŒï¼Œå¹¶æ¨åŠ¨è„‘ä¿¡å·ä¸å…¶ä»–ç”Ÿç‰©ä¿¡å·çš„èåˆç ”ç©¶ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models (FMs), powered by self-supervised learning (SSL), have redefined the capabilities of artificial intelligence, demonstrating exceptional performance in domains like natural language processing and computer vision. These advances present a transformative opportunity for brain signal analysis. Unlike traditional supervised learning, which is limited by the scarcity of labeled neural data, SSL offers a promising solution by enabling models to learn meaningful representations from unlabeled data. This is particularly valuable in addressing the unique challenges of brain signals, including high noise levels, inter-subject variability, and low signal-to-noise ratios. This survey systematically reviews the emerging field of bridging brain signals with foundation models through the innovative application of SSL. It explores key SSL techniques, the development of brain-specific foundation models, their adaptation to downstream tasks, and the integration of brain signals with other modalities in multimodal SSL frameworks. The review also covers commonly used evaluation metrics and benchmark datasets that support comparative analysis. Finally, it highlights key challenges and outlines future research directions. This work aims to provide researchers with a structured understanding of this rapidly evolving field and a roadmap for developing generalizable brain foundation models powered by self-supervision.

