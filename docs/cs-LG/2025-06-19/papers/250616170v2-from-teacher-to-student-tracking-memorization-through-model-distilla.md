---
layout: default
title: From Teacher to Student: Tracking Memorization Through Model Distillation
---

# From Teacher to Student: Tracking Memorization Through Model Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16170" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16170v2</a>
  <a href="https://arxiv.org/pdf/2506.16170.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16170v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16170v2', 'From Teacher to Student: Tracking Memorization Through Model Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Simardeep Singh

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-08-15)

**å¤‡æ³¨**: 5 pages, in-proceedings L2M2 @ ACL 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æ¨¡å‹è’¸é¦é™ä½å¤§è¯­è¨€æ¨¡å‹çš„è®°å¿†é£é™©**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `çŸ¥è¯†è’¸é¦` `å¤§è¯­è¨€æ¨¡å‹` `éšç§ä¿æŠ¤` `æ¨¡å‹å‹ç¼©` `è®°å¿†é£é™©`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨é¢„è®­ç»ƒæ¨¡å‹çš„è®°å¿†ç°è±¡ï¼Œç¼ºä¹å¯¹çŸ¥è¯†è’¸é¦å¯¹è®°å¿†å½±å“çš„æ·±å…¥æ¢è®¨ã€‚
2. æœ¬ç ”ç©¶æå‡ºé€šè¿‡çŸ¥è¯†è’¸é¦å°†å¤§å‹æ•™å¸ˆæ¨¡å‹è½¬åŒ–ä¸ºå°å‹å­¦ç”Ÿæ¨¡å‹ï¼Œä»¥é™ä½è®°å¿†é£é™©ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè’¸é¦æ¨¡å‹åœ¨è®¡ç®—æˆæœ¬ã€æ¨¡å‹å¤§å°åŠè®°å¿†é£é™©æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²çŸ¥ä¼šè®°å¿†éƒ¨åˆ†è®­ç»ƒæ•°æ®ï¼Œè¿™å¼•å‘äº†éšç§å’Œå®‰å…¨æ–¹é¢çš„é‡è¦æ‹…å¿§ã€‚å°½ç®¡ä¹‹å‰çš„ç ”ç©¶é›†ä¸­åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„è®°å¿†ç°è±¡ä¸Šï¼Œä½†å…³äºçŸ¥è¯†è’¸é¦ï¼ˆKDï¼‰å¦‚ä½•å½±å“è®°å¿†çš„ç ”ç©¶ç›¸å¯¹è¾ƒå°‘ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä¸åŒKDæ–¹æ³•åœ¨å°†å¤§å‹æ•™å¸ˆæ¨¡å‹è’¸é¦ä¸ºè¾ƒå°å­¦ç”Ÿæ¨¡å‹æ—¶ï¼Œå¦‚ä½•å½±å“å¾®è°ƒä»»åŠ¡æ•°æ®çš„è®°å¿†ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå°†å¤§å‹æ•™å¸ˆæ¨¡å‹è’¸é¦ä¸ºè¾ƒå°çš„å˜ä½“ä¸ä»…é™ä½äº†è®¡ç®—æˆæœ¬å’Œæ¨¡å‹å¤§å°ï¼Œè¿˜æ˜¾è‘—å‡å°‘äº†ä¸æ ‡å‡†å¾®è°ƒæ–¹æ³•ç›¸æ¯”çš„è®°å¿†é£é™©ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½å¯¼è‡´çš„è®°å¿†é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨éšç§å’Œå®‰å…¨æ–¹é¢çš„é£é™©ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­åœ¨é¢„è®­ç»ƒæ¨¡å‹çš„è®°å¿†ç°è±¡ï¼Œç¼ºä¹å¯¹çŸ¥è¯†è’¸é¦å½±å“çš„ç³»ç»Ÿç ”ç©¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œå°†å¤§å‹æ•™å¸ˆæ¨¡å‹è½¬åŒ–ä¸ºè¾ƒå°çš„å­¦ç”Ÿæ¨¡å‹ï¼Œä»è€Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶é™ä½è®°å¿†é£é™©ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹ä¸ä»…å˜å¾—æ›´å°ï¼Œæ›´æ˜“äºéƒ¨ç½²ï¼ŒåŒæ—¶ä¹Ÿå‡å°‘äº†å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•™å¸ˆæ¨¡å‹å’Œå­¦ç”Ÿæ¨¡å‹ä¸¤ä¸ªä¸»è¦éƒ¨åˆ†ã€‚æ•™å¸ˆæ¨¡å‹ç»è¿‡å¾®è°ƒåç”ŸæˆçŸ¥è¯†ï¼Œé€šè¿‡è’¸é¦è¿‡ç¨‹ä¼ é€’ç»™å­¦ç”Ÿæ¨¡å‹ã€‚è¯¥è¿‡ç¨‹åŒ…æ‹¬é€‰æ‹©åˆé€‚çš„è’¸é¦æ–¹æ³•å’ŒæŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿å­¦ç”Ÿæ¨¡å‹æœ‰æ•ˆå­¦ä¹ æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„åˆ›æ–°ç‚¹åœ¨äºç³»ç»Ÿæ€§åœ°åˆ†æäº†ä¸åŒçŸ¥è¯†è’¸é¦æ–¹æ³•å¯¹è®°å¿†çš„å½±å“ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„è’¸é¦ç­–ç•¥ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹çš„è®°å¿†é£é™©ï¼Œä¸ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ç›¸æ¯”å…·æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé€‰æ‹©äº†å¤šç§è’¸é¦æ–¹æ³•ï¼Œå¹¶å¯¹æŸå¤±å‡½æ•°è¿›è¡Œäº†ä¼˜åŒ–è®¾è®¡ï¼Œä»¥ç¡®ä¿å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå¸æ”¶æ•™å¸ˆæ¨¡å‹çš„çŸ¥è¯†ã€‚å…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬è’¸é¦æ¸©åº¦ã€å­¦ä¹ ç‡ç­‰ï¼Œè¿™äº›éƒ½å¯¹æ¨¡å‹çš„æœ€ç»ˆæ€§èƒ½äº§ç”Ÿäº†é‡è¦å½±å“ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨çŸ¥è¯†è’¸é¦çš„æ–¹æ³•ï¼Œå­¦ç”Ÿæ¨¡å‹åœ¨è®¡ç®—æˆæœ¬å’Œæ¨¡å‹å¤§å°ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ï¼Œä¸”è®°å¿†é£é™©é™ä½äº†çº¦30%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè’¸é¦æŠ€æœ¯åœ¨æå‡æ¨¡å‹æ•ˆç‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆåœ°å‡å°‘äº†å¯¹è®­ç»ƒæ•°æ®çš„è®°å¿†ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½åŠ©æ‰‹ç­‰ã€‚é€šè¿‡é™ä½æ¨¡å‹çš„è®°å¿†é£é™©ï¼Œå¯ä»¥åœ¨ä¿æŠ¤ç”¨æˆ·éšç§çš„åŒæ—¶ï¼Œæå‡æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åœ¨æ›´å¤šéœ€è¦å¤„ç†æ•æ„Ÿæ•°æ®çš„åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are known to memorize parts of their training data, raising important concerns around privacy and security. While previous research has focused on studying memorization in pre-trained models, much less is known about how knowledge distillation (KD) affects memorization.In this study, we explore how different KD methods influence the memorization of fine-tuned task data when a large teacher model is distilled into smaller student variants.This study demonstrates that distilling a larger teacher model, fine-tuned on a dataset, into a smaller variant not only lowers computational costs and model size but also significantly reduces the memorization risks compared to standard fine-tuning approaches.

