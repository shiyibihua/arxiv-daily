---
layout: default
title: GoalLadder: Incremental Goal Discovery with Vision-Language Models
---

# GoalLadder: Incremental Goal Discovery with Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16396" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.16396v2</a>
  <a href="https://arxiv.org/pdf/2506.16396.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16396v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16396v2', 'GoalLadder: Incremental Goal Discovery with Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alexey Zakharov, Shimon Whiteson

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-19 (æ›´æ–°: 2025-12-12)

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGoalLadderä»¥è§£å†³è§†è§‰ç¯å¢ƒä¸­å¢é‡ç›®æ ‡å‘ç°é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¢é‡ç›®æ ‡å‘ç°` `å¼ºåŒ–å­¦ä¹ ` `æœºå™¨äººå­¦ä¹ ` `è‡ªç„¶è¯­è¨€æŒ‡ä»¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è§†è§‰ç¯å¢ƒä¸­æå–å¥–åŠ±é¢ä¸´æŒ‘æˆ˜ï¼Œé€šå¸¸ä¾èµ–å¤§é‡åé¦ˆæˆ–ç”Ÿæˆå™ªå£°å¥–åŠ±å‡½æ•°ã€‚
2. GoalLadderé€šè¿‡å¢é‡å‘ç°çŠ¶æ€ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹ä»å•ä¸€è¯­è¨€æŒ‡ä»¤ä¸­è®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGoalLadderåœ¨ç»å…¸æ§åˆ¶å’Œæœºå™¨äººæ“ä½œç¯å¢ƒä¸­æˆåŠŸç‡è¾¾åˆ°çº¦95%ï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªç„¶è¯­è¨€ä¸ºå¼ºåŒ–å­¦ä¹ ä»»åŠ¡æä¾›äº†ä¸€ç§ç®€æ´ä¸”æ˜“äºç†è§£çš„æ–¹å¼ã€‚ç„¶è€Œï¼Œåœ¨è§†è§‰ç¯å¢ƒä¸­ï¼Œä»è¯­è¨€æŒ‡ä»¤ä¸­æå–å¥–åŠ±ä»ç„¶æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤§å‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œé€šå¸¸éœ€è¦å¤§é‡åé¦ˆæˆ–ç”Ÿæˆå™ªå£°å¥–åŠ±å‡½æ•°ã€‚æœ¬æ–‡æå‡ºäº†GoalLadderï¼Œé€šè¿‡å¢é‡å‘ç°çŠ¶æ€æ¥è®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ï¼Œä½¿å…¶èƒ½å¤Ÿä»å•ä¸€è¯­è¨€æŒ‡ä»¤ä¸­å­¦ä¹ ã€‚GoalLadderåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¯†åˆ«å’Œæ’åæ½œåœ¨ç›®æ ‡çŠ¶æ€ï¼Œé‡‡ç”¨ELOè¯„åˆ†ç³»ç»Ÿæ¥å‡å°‘å™ªå£°åé¦ˆçš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGoalLadderåœ¨ç»å…¸æ§åˆ¶å’Œæœºå™¨äººæ“ä½œç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæœ€ç»ˆæˆåŠŸç‡çº¦ä¸º95%ï¼Œæ˜¾è‘—é«˜äºæœ€ä½³ç«äº‰è€…çš„45%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨è§†è§‰ç¯å¢ƒä¸­ä»è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä¸­æå–å¥–åŠ±çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºéè§†è§‰ç¯å¢ƒè¡¨ç¤ºï¼Œæˆ–éœ€è¦å¤§é‡åé¦ˆï¼Œå¯¼è‡´ç”Ÿæˆçš„å¥–åŠ±å‡½æ•°å™ªå£°è¾ƒå¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGoalLadderçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¢é‡å‘ç°çŠ¶æ€æ¥è®­ç»ƒå¼ºåŒ–å­¦ä¹ ä»£ç†ï¼Œä½¿å…¶èƒ½å¤Ÿä»å•ä¸€è¯­è¨€æŒ‡ä»¤ä¸­å­¦ä¹ ã€‚è¯¥æ–¹æ³•é€šè¿‡æŸ¥è¯¢è§†è§‰-è¯­è¨€æ¨¡å‹æ¥è¯†åˆ«å’Œæ’åæ½œåœ¨ç›®æ ‡çŠ¶æ€ï¼Œä»è€Œå¼•å¯¼ä»£ç†çš„å­¦ä¹ è¿‡ç¨‹ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGoalLadderçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä½¿ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¯†åˆ«ä¸ä»»åŠ¡è¿›å±•ç›¸å…³çš„çŠ¶æ€ï¼›å…¶æ¬¡ï¼Œé€šè¿‡ELOè¯„åˆ†ç³»ç»Ÿå¯¹è¿™äº›çŠ¶æ€è¿›è¡Œæ’åï¼›æœ€åï¼Œä»£ç†åœ¨å­¦ä¹ çš„åµŒå…¥ç©ºé—´ä¸­æœ€å°åŒ–ä¸æœ€é«˜æ’åç›®æ ‡çš„è·ç¦»ã€‚

**å…³é”®åˆ›æ–°**ï¼šGoalLadderçš„åˆ›æ–°ä¹‹å¤„åœ¨äºä¸å®Œå…¨ä¾èµ–è§†è§‰-è¯­è¨€æ¨¡å‹çš„åé¦ˆï¼Œè€Œæ˜¯é€šè¿‡ELOè¯„åˆ†ç³»ç»Ÿæ¥é™ä½å™ªå£°åé¦ˆçš„å½±å“ã€‚è¿™ä¸€è®¾è®¡ä½¿å¾—ä»£ç†èƒ½å¤Ÿåœ¨ç¼ºä¹å¤§é‡å‡†ç¡®åé¦ˆçš„æƒ…å†µä¸‹æœ‰æ•ˆå­¦ä¹ ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒGoalLadderé‡‡ç”¨äº†åŸºäºæ— æ ‡ç­¾è§†è§‰æ•°æ®è®­ç»ƒçš„åµŒå…¥ç©ºé—´ï¼Œå¹¶é€šè¿‡æœ€å°åŒ–è·ç¦»æ¥ä¼˜åŒ–ç›®æ ‡çŠ¶æ€çš„é€‰æ‹©ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGoalLadderåœ¨ç»å…¸æ§åˆ¶å’Œæœºå™¨äººæ“ä½œç¯å¢ƒä¸­çš„å¹³å‡æœ€ç»ˆæˆåŠŸç‡çº¦ä¸º95%ï¼Œè€Œæœ€ä½³ç«äº‰è€…çš„æˆåŠŸç‡ä»…ä¸ºçº¦45%ã€‚è¿™ä¸€æ˜¾è‘—æå‡å±•ç¤ºäº†GoalLadderåœ¨å¤„ç†è§†è§‰ç¯å¢ƒä¸­ç›®æ ‡å‘ç°ä»»åŠ¡çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GoalLadderçš„ç ”ç©¶æˆæœåœ¨æœºå™¨äººå­¦ä¹ å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æŒ‡ä»¤å¼•å¯¼æœºå™¨äººå­¦ä¹ ï¼Œèƒ½å¤Ÿæå‡æœºå™¨äººåœ¨å¤æ‚è§†è§‰ç¯å¢ƒä¸­çš„è‡ªä¸»å­¦ä¹ èƒ½åŠ›ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººåœ¨å®¶åº­ã€å·¥ä¸šå’ŒæœåŠ¡ç­‰åœºæ™¯çš„åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½ä¼šä¿ƒè¿›æ›´é«˜æ•ˆçš„æœºå™¨äººè®­ç»ƒå’Œäººæœºåä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Natural language can offer a concise and human-interpretable means of specifying reinforcement learning (RL) tasks. The ability to extract rewards from a language instruction can enable the development of robotic systems that can learn from human guidance; however, it remains a challenging problem, especially in visual environments. Existing approaches that employ large, pretrained language models either rely on non-visual environment representations, require prohibitively large amounts of feedback, or generate noisy, ill-shaped reward functions. In this paper, we propose a novel method, GoalLadder, that leverages vision-language models (VLMs) to train RL agents from a single language instruction in visual environments. GoalLadder works by incrementally discovering states that bring the agent closer to completing a task specified in natural language. To do so, it queries a VLM to identify states that represent an improvement in agent's task progress and to rank them using pairwise comparisons. Unlike prior work, GoalLadder does not trust VLM's feedback completely; instead, it uses it to rank potential goal states using an ELO-based rating system, thus reducing the detrimental effects of noisy VLM feedback. Over the course of training, the agent is tasked with minimising the distance to the top-ranked goal in a learned embedding space, which is trained on unlabelled visual data. This key feature allows us to bypass the need for abundant and accurate feedback typically required to train a well-shaped reward function. We demonstrate that GoalLadder outperforms existing related methods on classic control and robotic manipulation environments with the average final success rate of $\sim$95% compared to only $\sim$45% of the best competitor.

