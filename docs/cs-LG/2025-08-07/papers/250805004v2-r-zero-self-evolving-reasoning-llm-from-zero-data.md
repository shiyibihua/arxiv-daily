---
layout: default
title: R-Zero: Self-Evolving Reasoning LLM from Zero Data
---

# R-Zero: Self-Evolving Reasoning LLM from Zero Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.05004" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.05004v2</a>
  <a href="https://arxiv.org/pdf/2508.05004.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.05004v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.05004v2', 'R-Zero: Self-Evolving Reasoning LLM from Zero Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Chengsong Huang, Wenhao Yu, Xiaoyang Wang, Hongming Zhang, Zongxia Li, Ruosen Li, Jiaxin Huang, Haitao Mi, Dong Yu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-07 (æ›´æ–°: 2025-08-27)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR-Zeroä»¥è§£å†³è‡ªæˆ‘è¿›åŒ–æ¨ç†æ¨¡å‹çš„æ•°æ®ä¾èµ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è‡ªæˆ‘è¿›åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ— ç›‘ç£å­¦ä¹ ` `æ¨ç†èƒ½åŠ›` `æ•°æ®ç”Ÿæˆ` `æŒ‘æˆ˜è€…æ¨¡å‹` `è§£å†³è€…æ¨¡å‹` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨è®­ç»ƒè‡ªæˆ‘è¿›åŒ–æ¨¡å‹æ—¶ä¾èµ–å¤§é‡äººå·¥æ ‡æ³¨æ•°æ®ï¼Œé™åˆ¶äº†AIç³»ç»Ÿçš„è¿›æ­¥ã€‚
2. R-Zeroé€šè¿‡è‡ªä¸»ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œåˆ©ç”¨æŒ‘æˆ˜è€…å’Œè§£å†³è€…æ¨¡å‹çš„äº’åŠ¨ï¼Œå®ç°è‡ªæˆ‘è¿›åŒ–çš„æ¨ç†èƒ½åŠ›æå‡ã€‚
3. å®éªŒè¯æ˜ï¼ŒR-Zeroåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—æé«˜äº†æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦å’Œé€šç”¨é¢†åŸŸæ¨ç†ä¸Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è‡ªæˆ‘è¿›åŒ–çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šè¿‡è‡ªä¸»ç”Ÿæˆã€ä¼˜åŒ–å’Œå­¦ä¹ è‡ªèº«ç»éªŒï¼Œæä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„é€šå¾€è¶…æ™ºèƒ½çš„è·¯å¾„ã€‚ç„¶è€Œï¼Œç°æœ‰è®­ç»ƒæ–¹æ³•ä»ç„¶ä¸¥é‡ä¾èµ–å¤§é‡äººå·¥ç­–åˆ’çš„ä»»åŠ¡å’Œæ ‡ç­¾ï¼Œè¿™æˆä¸ºæ¨åŠ¨AIç³»ç»Ÿè¶…è¶Šäººç±»æ™ºèƒ½èƒ½åŠ›çš„æ ¹æœ¬ç“¶é¢ˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæœ¬æ–‡æå‡ºäº†R-Zeroï¼Œä¸€ä¸ªå®Œå…¨è‡ªä¸»çš„æ¡†æ¶ï¼Œä»é›¶å¼€å§‹ç”Ÿæˆè®­ç»ƒæ•°æ®ã€‚R-Zeroä»å•ä¸€åŸºç¡€LLMå‡ºå‘ï¼Œåˆå§‹åŒ–ä¸¤ä¸ªç‹¬ç«‹æ¨¡å‹ï¼Œåˆ†åˆ«ä¸ºæŒ‘æˆ˜è€…å’Œè§£å†³è€…ã€‚è¿™äº›æ¨¡å‹é€šè¿‡äº¤äº’ç‹¬ç«‹ä¼˜åŒ–å¹¶å…±åŒè¿›åŒ–ï¼šæŒ‘æˆ˜è€…å› æå‡ºæ¥è¿‘è§£å†³è€…èƒ½åŠ›è¾¹ç¼˜çš„ä»»åŠ¡è€Œè·å¾—å¥–åŠ±ï¼Œè€Œè§£å†³è€…å› è§£å†³æŒ‘æˆ˜è€…æå‡ºçš„æ—¥ç›Šå›°éš¾çš„ä»»åŠ¡è€Œè·å¾—å¥–åŠ±ã€‚è¿™ä¸€è¿‡ç¨‹ç”Ÿæˆäº†ä¸€ä¸ªæœ‰é’ˆå¯¹æ€§çš„ã€è‡ªæˆ‘æå‡çš„è¯¾ç¨‹ï¼Œæ— éœ€ä»»ä½•é¢„å…ˆå­˜åœ¨çš„ä»»åŠ¡å’Œæ ‡ç­¾ã€‚å®éªŒè¯æ˜ï¼ŒR-Zeroæ˜¾è‘—æå‡äº†ä¸åŒåŸºç¡€LLMçš„æ¨ç†èƒ½åŠ›ï¼Œä¾‹å¦‚åœ¨æ•°å­¦æ¨ç†åŸºå‡†ä¸Šæå‡äº†Qwen3-4B-Base +6.49ï¼Œåœ¨é€šç”¨é¢†åŸŸæ¨ç†åŸºå‡†ä¸Šæå‡äº†+7.54ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è‡ªæˆ‘è¿›åŒ–å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹äººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¾®è°ƒæˆ–å¼ºåŒ–å­¦ä¹ æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¯¼è‡´äº†æ•ˆç‡ä½ä¸‹å’Œèƒ½åŠ›ç“¶é¢ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šR-Zeroçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡è‡ªä¸»ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œæ¶ˆé™¤å¯¹äººå·¥ä»»åŠ¡å’Œæ ‡ç­¾çš„ä¾èµ–ã€‚é€šè¿‡è®¾ç½®æŒ‘æˆ˜è€…å’Œè§£å†³è€…ä¸¤ä¸ªæ¨¡å‹ï¼Œå½¢æˆä¸€ç§è‡ªæˆ‘è¿›åŒ–çš„å­¦ä¹ æœºåˆ¶ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šR-Zeroçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šæŒ‘æˆ˜è€…æ¨¡å‹å’Œè§£å†³è€…æ¨¡å‹ã€‚æŒ‘æˆ˜è€…è´Ÿè´£æå‡ºä»»åŠ¡ï¼Œè€Œè§£å†³è€…åˆ™å°è¯•è§£å†³è¿™äº›ä»»åŠ¡ã€‚ä¸¤è€…é€šè¿‡å¥–åŠ±æœºåˆ¶è¿›è¡Œäº’åŠ¨å’Œä¼˜åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šR-Zeroçš„æœ€å¤§åˆ›æ–°åœ¨äºå…¶å®Œå…¨è‡ªä¸»çš„æ•°æ®ç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡æ¨¡å‹é—´çš„äº’åŠ¨å®ç°äº†æ— ç›‘ç£çš„è‡ªæˆ‘æå‡ã€‚è¿™ä¸ä¼ ç»Ÿä¾èµ–äººå·¥æ ‡æ³¨çš„è®­ç»ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸Šï¼ŒæŒ‘æˆ˜è€…å’Œè§£å†³è€…çš„å¥–åŠ±æœºåˆ¶è‡³å…³é‡è¦ï¼ŒæŒ‘æˆ˜è€…æå‡ºçš„ä»»åŠ¡éœ€æ¥è¿‘è§£å†³è€…çš„èƒ½åŠ›è¾¹ç¼˜ï¼Œç¡®ä¿ä»»åŠ¡çš„é€‚åº”æ€§å’ŒæŒ‘æˆ˜æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒR-Zeroåœ¨æ•°å­¦æ¨ç†åŸºå‡†ä¸Šæå‡äº†Qwen3-4B-Baseæ¨¡å‹çš„æ€§èƒ½6.49åˆ†ï¼Œåœ¨é€šç”¨é¢†åŸŸæ¨ç†åŸºå‡†ä¸Šæå‡äº†7.54åˆ†ã€‚è¿™äº›ç»“æœè¡¨æ˜R-Zeroåœ¨æ¨ç†èƒ½åŠ›ä¸Šçš„æ˜¾è‘—æå‡ï¼Œè¶…è¶Šäº†ä¼ ç»Ÿè®­ç»ƒæ–¹æ³•çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

R-Zeroçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬æ•™è‚²ã€æ¸¸æˆè®¾è®¡å’Œè‡ªåŠ¨åŒ–æ¨ç†ç³»ç»Ÿç­‰ã€‚é€šè¿‡è‡ªä¸»ç”Ÿæˆä»»åŠ¡å’Œå­¦ä¹ ï¼ŒR-Zeroèƒ½å¤Ÿåœ¨æ²¡æœ‰äººå·¥å¹²é¢„çš„æƒ…å†µä¸‹ä¸æ–­æå‡è‡ªèº«èƒ½åŠ›ï¼Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily on vast human-curated tasks and labels, typically via fine-tuning or reinforcement learning, which poses a fundamental bottleneck to advancing AI systems toward capabilities beyond human intelligence. To overcome this limitation, we introduce R-Zero, a fully autonomous framework that generates its own training data from scratch. Starting from a single base LLM, R-Zero initializes two independent models with distinct roles, a Challenger and a Solver. These models are optimized separately and co-evolve through interaction: the Challenger is rewarded for proposing tasks near the edge of the Solver capability, and the Solver is rewarded for solving increasingly challenging tasks posed by the Challenger. This process yields a targeted, self-improving curriculum without any pre-existing tasks and labels. Empirically, R-Zero substantially improves reasoning capability across different backbone LLMs, e.g., boosting the Qwen3-4B-Base by +6.49 on math-reasoning benchmarks and +7.54 on general-domain reasoning benchmarks.

