---
layout: default
title: Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis
---

# Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.04999" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.04999v1</a>
  <a href="https://arxiv.org/pdf/2508.04999.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.04999v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.04999v1', 'Disentangling Bias by Modeling Intra- and Inter-modal Causal Attention for Multimodal Sentiment Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Menghua Jiang, Yuxia Lin, Baoliang Chen, Haifeng Hu, Yuncheng Jiang, Sijie Mai

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-07

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMMCIæ¨¡å‹ä»¥è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸­çš„åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ` `å› æœå¹²é¢„` `è™šå‡ç›¸å…³æ€§` `æ³¨æ„åŠ›æœºåˆ¶` `æ¨¡å‹æ³›åŒ–` `æ•°æ®é›†` `ç‰¹å¾è§£è€¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ–¹æ³•å¸¸å—è™šå‡ç›¸å…³æ€§å½±å“ï¼Œå¯¼è‡´æ¨¡å‹ä¾èµ–ç»Ÿè®¡æ·å¾„è€ŒéçœŸå®å› æœå…³ç³»ï¼Œå½±å“æ³›åŒ–èƒ½åŠ›ã€‚
2. æœ¬æ–‡æå‡ºMMCIæ¨¡å‹ï¼Œé€šè¿‡å¤šå…³ç³»å›¾å»ºæ¨¡å¤šæ¨¡æ€è¾“å…¥ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶è§£è€¦å› æœç‰¹å¾ä¸æ·å¾„ç‰¹å¾ã€‚
3. åœ¨å¤šä¸ªæ ‡å‡†MSAæ•°æ®é›†å’ŒOODæµ‹è¯•é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒMMCIæ¨¡å‹æœ‰æ•ˆæŠ‘åˆ¶åå·®ï¼Œæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æï¼ˆMSAï¼‰æ—¨åœ¨é€šè¿‡æ•´åˆæ–‡æœ¬ã€éŸ³é¢‘å’Œè§†è§‰æ•°æ®ç­‰å¤šç§æ¨¡æ€çš„ä¿¡æ¯æ¥ç†è§£äººç±»æƒ…æ„Ÿã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•å¾€å¾€å—åˆ°æ¨¡æ€å†…éƒ¨å’Œè·¨æ¨¡æ€çš„è™šå‡ç›¸å…³æ€§çš„å½±å“ï¼Œä½¿å¾—æ¨¡å‹ä¾èµ–ç»Ÿè®¡æ·å¾„è€ŒéçœŸå®å› æœå…³ç³»ï¼Œä»è€Œå‰Šå¼±äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šå…³ç³»å¤šæ¨¡æ€å› æœå¹²é¢„ï¼ˆMMCIï¼‰æ¨¡å‹ï¼Œåˆ©ç”¨å› æœç†è®ºä¸­çš„åé—¨è°ƒæ•´æ–¹æ³•æ¥åº”å¯¹è¿™äº›æ·å¾„çš„æ··æ·†æ•ˆåº”ã€‚å…·ä½“è€Œè¨€ï¼Œé¦–å…ˆå°†å¤šæ¨¡æ€è¾“å…¥å»ºæ¨¡ä¸ºå¤šå…³ç³»å›¾ï¼Œä»¥æ˜¾å¼æ•æ‰æ¨¡æ€å†…éƒ¨å’Œè·¨æ¨¡æ€çš„ä¾èµ–å…³ç³»ã€‚ç„¶åï¼Œåº”ç”¨æ³¨æ„åŠ›æœºåˆ¶åˆ†åˆ«ä¼°è®¡å’Œè§£è€¦ä¸è¿™äº›å…³ç³»å¯¹åº”çš„å› æœç‰¹å¾å’Œæ·å¾„ç‰¹å¾ã€‚æœ€åï¼Œé€šè¿‡åº”ç”¨åé—¨è°ƒæ•´ï¼Œæˆ‘ä»¬å¯¹æ·å¾„ç‰¹å¾è¿›è¡Œåˆ†å±‚ï¼Œå¹¶å°†å…¶ä¸å› æœç‰¹å¾åŠ¨æ€ç»“åˆï¼Œä»¥ä¿ƒä½¿MMCIåœ¨åˆ†å¸ƒå˜åŒ–ä¸‹äº§ç”Ÿç¨³å®šçš„é¢„æµ‹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæŠ‘åˆ¶äº†åå·®å¹¶æå‡äº†æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸­çš„è™šå‡ç›¸å…³æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€ä¾èµ–ç»Ÿè®¡æ·å¾„ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºå¤šå…³ç³»å¤šæ¨¡æ€å› æœå¹²é¢„ï¼ˆMMCIï¼‰æ¨¡å‹ï¼Œé€šè¿‡å› æœç†è®ºä¸­çš„åé—¨è°ƒæ•´æ¥æ¶ˆé™¤æ··æ·†æ•ˆåº”ï¼Œç¡®ä¿æ¨¡å‹å­¦ä¹ åˆ°çœŸå®çš„å› æœå…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œå°†å¤šæ¨¡æ€è¾“å…¥å»ºæ¨¡ä¸ºå¤šå…³ç³»å›¾ï¼›å…¶æ¬¡ï¼Œåº”ç”¨æ³¨æ„åŠ›æœºåˆ¶è§£è€¦å› æœç‰¹å¾ä¸æ·å¾„ç‰¹å¾ï¼›æœ€åï¼Œåˆ©ç”¨åé—¨è°ƒæ•´æ–¹æ³•å¯¹ç‰¹å¾è¿›è¡Œåˆ†å±‚å’ŒåŠ¨æ€ç»“åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†å› æœå¹²é¢„ä¸å¤šæ¨¡æ€å­¦ä¹ ç»“åˆï¼Œé€šè¿‡æ˜¾å¼å»ºæ¨¡æ¨¡æ€é—´çš„ä¾èµ–å…³ç³»ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹ä¸­é‡‡ç”¨äº†å¤šå…³ç³»å›¾ç»“æ„ï¼Œæ³¨æ„åŠ›æœºåˆ¶ç”¨äºç‰¹å¾è§£è€¦ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šæ³¨é‡å¯¹å› æœç‰¹å¾çš„å¼ºåŒ–å­¦ä¹ ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒåˆ†å¸ƒä¸‹çš„ç¨³å®šæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒMMCIæ¨¡å‹åœ¨å¤šä¸ªæ ‡å‡†MSAæ•°æ®é›†ä¸Šæ˜¾è‘—æŠ‘åˆ¶äº†åå·®ï¼Œç›¸è¾ƒäºåŸºçº¿æ–¹æ³•ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%ä»¥ä¸Šï¼Œå°¤å…¶åœ¨OODæµ‹è¯•é›†ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºï¼ŒéªŒè¯äº†æ¨¡å‹çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€ç¤¾äº¤åª’ä½“ç›‘æµ‹å’Œäººæœºäº¤äº’ç­‰ã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„å‡†ç¡®æ€§ï¼ŒMMCIæ¨¡å‹èƒ½å¤Ÿä¸ºæƒ…æ„Ÿè¯†åˆ«ã€ç”¨æˆ·ä½“éªŒä¼˜åŒ–ç­‰æä¾›æ›´å¯é çš„æ”¯æŒï¼Œæœªæ¥å¯èƒ½åœ¨æ™ºèƒ½å®¢æœå’Œæƒ…æ„Ÿè®¡ç®—ç­‰é¢†åŸŸäº§ç”Ÿé‡è¦å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal sentiment analysis (MSA) aims to understand human emotions by integrating information from multiple modalities, such as text, audio, and visual data. However, existing methods often suffer from spurious correlations both within and across modalities, leading models to rely on statistical shortcuts rather than true causal relationships, thereby undermining generalization. To mitigate this issue, we propose a Multi-relational Multimodal Causal Intervention (MMCI) model, which leverages the backdoor adjustment from causal theory to address the confounding effects of such shortcuts. Specifically, we first model the multimodal inputs as a multi-relational graph to explicitly capture intra- and inter-modal dependencies. Then, we apply an attention mechanism to separately estimate and disentangle the causal features and shortcut features corresponding to these intra- and inter-modal relations. Finally, by applying the backdoor adjustment, we stratify the shortcut features and dynamically combine them with the causal features to encourage MMCI to produce stable predictions under distribution shifts. Extensive experiments on several standard MSA datasets and out-of-distribution (OOD) test sets demonstrate that our method effectively suppresses biases and improves performance.

