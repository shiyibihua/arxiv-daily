---
layout: default
title: Privacy-Preserving Offloading for Large Language Models in 6G Vehicular Networks
---

# Privacy-Preserving Offloading for Large Language Models in 6G Vehicular Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.05320" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.05320v1</a>
  <a href="https://arxiv.org/pdf/2509.05320.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.05320v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.05320v1', 'Privacy-Preserving Offloading for Large Language Models in 6G Vehicular Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ikhlasse Badidi, Nouhaila El Khiyaoui, Aya Riany, Badr Ben Elallid, Amine Abouaomar

**åˆ†ç±»**: cs.CR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-30

**å¤‡æ³¨**: 7 pages, 6 figures, 1 algorithm, 5 equations

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšç§ä¿æŠ¤çš„å¸è½½æ¡†æ¶ä»¥è§£å†³6Gè½¦è”ç½‘ä¸­çš„æ•°æ®å®‰å…¨é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšç§ä¿æŠ¤` `å¤§å‹è¯­è¨€æ¨¡å‹` `è½¦è”ç½‘` `è”é‚¦å­¦ä¹ ` `å·®åˆ†éšç§` `æ™ºèƒ½äº¤é€š` `è¾¹ç¼˜è®¡ç®—`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å°†å¤§å‹è¯­è¨€æ¨¡å‹è®¡ç®—å¸è½½åˆ°è¾¹ç¼˜æ—¶ï¼Œé¢ä¸´ç”¨æˆ·æ•°æ®éšç§æ³„éœ²çš„é‡å¤§é£é™©ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“åˆè”é‚¦å­¦ä¹ å’Œå·®åˆ†éšç§çš„æ··åˆæ–¹æ³•ï¼Œä»¥ä¿æŠ¤ç”¨æˆ·æ•°æ®å¹¶ä¼˜åŒ–è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒé«˜å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œé€šä¿¡å¼€é”€å’Œè®¡ç®—æ•ˆç‡å‡è¡¨ç°è‰¯å¥½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨6Gè½¦è”ç½‘ä¸­çš„é›†æˆä¸ºæ™ºèƒ½äº¤é€šç³»ç»Ÿå¸¦æ¥äº†å‰æ‰€æœªæœ‰çš„è¿›æ­¥ã€‚ç„¶è€Œï¼Œå°†LLMè®¡ç®—ä»è½¦è¾†å¸è½½åˆ°è¾¹ç¼˜åŸºç¡€è®¾æ–½ä¼šå¸¦æ¥æ˜¾è‘—çš„éšç§é£é™©ï¼Œå¯èƒ½æš´éœ²æ•æ„Ÿç”¨æˆ·æ•°æ®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„éšç§ä¿æŠ¤å¸è½½æ¡†æ¶ï¼Œç»“åˆäº†è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰å’Œå·®åˆ†éšç§ï¼ˆDPï¼‰æŠ€æœ¯ï¼Œä»¥ä¿æŠ¤ç”¨æˆ·æ•°æ®å¹¶ä¿æŒLLMæ€§èƒ½ã€‚æ¡†æ¶åŒ…æ‹¬ä¸€ä¸ªéšç§æ„ŸçŸ¥çš„ä»»åŠ¡åˆ’åˆ†ç®—æ³•ï¼Œä¼˜åŒ–äº†æœ¬åœ°å’Œè¾¹ç¼˜è®¡ç®—ä¹‹é—´çš„æƒè¡¡ï¼ŒåŒæ—¶è€ƒè™‘éšç§çº¦æŸå’Œç³»ç»Ÿæ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å…¨çƒå‡†ç¡®ç‡ä¸Šè¾¾åˆ°75%ï¼Œä¸ééšç§ä¿æŠ¤æ–¹æ³•ç›¸æ¯”ä»…é™ä½2-3%ï¼ŒåŒæ—¶ä¿æŒDPä¿è¯ï¼Œéšç§é¢„ç®—ä¸ºÎµ=0.8ã€‚è¯¥æ¡†æ¶åœ¨æ¯è½®çš„é€šä¿¡å¼€é”€çº¦ä¸º2.1MBï¼Œè®¡ç®—å æ€»å¤„ç†æ—¶é—´çš„90%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨èµ„æºå—é™çš„è½¦è½½ç¯å¢ƒä¸­çš„æ•ˆç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨6Gè½¦è”ç½‘ä¸­å°†å¤§å‹è¯­è¨€æ¨¡å‹è®¡ç®—å¸è½½åˆ°è¾¹ç¼˜æ—¶ï¼Œç”¨æˆ·æ•°æ®éšç§æ³„éœ²çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å¿½è§†äº†éšç§ä¿æŠ¤ï¼Œå¯¼è‡´æ•æ„Ÿæ•°æ®æš´éœ²çš„é£é™©å¢å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆè”é‚¦å­¦ä¹ å’Œå·®åˆ†éšç§æŠ€æœ¯ï¼Œé€šè¿‡éšç§æ„ŸçŸ¥çš„ä»»åŠ¡åˆ’åˆ†ç®—æ³•ï¼Œä¼˜åŒ–æœ¬åœ°ä¸è¾¹ç¼˜è®¡ç®—ä¹‹é—´çš„å¹³è¡¡ï¼Œä»è€Œåœ¨ä¿æŠ¤éšç§çš„åŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€ä»»åŠ¡åˆ’åˆ†ã€æ¨¡å‹è®­ç»ƒå’Œç»“æœèšåˆå››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œè½¦è¾†æ”¶é›†æ•°æ®å¹¶è¿›è¡Œæœ¬åœ°è®¡ç®—ï¼Œç„¶åé€šè¿‡éšç§æ„ŸçŸ¥ç®—æ³•å†³å®šå“ªäº›ä»»åŠ¡å¸è½½åˆ°è¾¹ç¼˜ï¼Œæœ€åé€šè¿‡å®‰å…¨é€šä¿¡åè®®ä¼ è¾“æ¨¡å‹æ›´æ–°å’Œèšåˆç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„ä»»åŠ¡åˆ’åˆ†ç®—æ³•ï¼Œèƒ½å¤Ÿåœ¨éšç§ä¿æŠ¤å’Œç³»ç»Ÿæ•ˆç‡ä¹‹é—´å®ç°æœ€ä½³æƒè¡¡ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é›†ä¸­å¼è®¡ç®—æ–¹å¼æœ‰æœ¬è´¨åŒºåˆ«ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé™ä½éšç§é£é™©ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè®¾ç½®äº†éšç§é¢„ç®—Îµ=0.8ï¼Œç¡®ä¿å·®åˆ†éšç§çš„ä¿è¯ã€‚åŒæ—¶ï¼Œæ¡†æ¶çš„é€šä¿¡å¼€é”€ç¨³å®šåœ¨çº¦2.1MBæ¯è½®ï¼Œè®¡ç®—æ—¶é—´å æ€»å¤„ç†æ—¶é—´çš„90%ä»¥ä¸Šï¼Œæ˜¾ç¤ºå‡ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„é«˜æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ¡†æ¶åœ¨å…¨çƒå‡†ç¡®ç‡ä¸Šè¾¾åˆ°75%ï¼Œä¸ééšç§ä¿æŠ¤æ–¹æ³•ç›¸æ¯”ä»…é™ä½2-3%ã€‚åŒæ—¶ï¼Œä¿æŒäº†å·®åˆ†éšç§çš„ä¿è¯ï¼Œéšç§é¢„ç®—ä¸ºÎµ=0.8ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šç³»ç»Ÿã€è‡ªåŠ¨é©¾é©¶è½¦è¾†å’Œè½¦è”ç½‘æœåŠ¡ç­‰ã€‚é€šè¿‡ä¿æŠ¤ç”¨æˆ·éšç§ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿä¿ƒè¿›æ›´å¹¿æ³›çš„LLMåº”ç”¨ï¼Œæå‡ç”¨æˆ·ä¿¡ä»»åº¦ï¼Œå¹¶æ¨åŠ¨æ™ºèƒ½äº¤é€šæŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯å¯èƒ½åœ¨æ•°æ®å®‰å…¨å’Œéšç§ä¿æŠ¤æ–¹é¢äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The integration of Large Language Models (LLMs) in 6G vehicular networks promises unprecedented advancements in intelligent transportation systems. However, offloading LLM computations from vehicles to edge infrastructure poses significant privacy risks, potentially exposing sensitive user data. This paper presents a novel privacy-preserving offloading framework for LLM-integrated vehicular networks. We introduce a hybrid approach combining federated learning (FL) and differential privacy (DP) techniques to protect user data while maintaining LLM performance. Our framework includes a privacy-aware task partitioning algorithm that optimizes the trade-off between local and edge computation, considering both privacy constraints and system efficiency. We also propose a secure communication protocol for transmitting model updates and aggregating results across the network. Experimental results demonstrate that our approach achieves 75\% global accuracy with only a 2-3\% reduction compared to non-privacy-preserving methods, while maintaining DP guarantees with an optimal privacy budget of $\varepsilon = 0.8$. The framework shows stable communication overhead of approximately 2.1MB per round with computation comprising over 90\% of total processing time, validating its efficiency for resource-constrained vehicular environments.

