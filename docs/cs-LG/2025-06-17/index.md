---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-06-17
---

# cs.LGï¼ˆ2025-06-17ï¼‰

ğŸ“Š å…± **5** ç¯‡è®ºæ–‡
 | ğŸ”— **2** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ğŸ”—2)</a>
<a href="#æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control" class="interest-badge">æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250614574v1-tgdpo-harnessing-token-level-reward-guidance-for-enhancing-direct-pr.html">TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization</a></td>
  <td>æå‡ºTGDPOä»¥è§£å†³ç›´æ¥åå¥½ä¼˜åŒ–ä¸­çš„å¥–åŠ±æŒ‡å¯¼é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">DPO</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14574v1" data-paper-url="./papers/250614574v1-tgdpo-harnessing-token-level-reward-guidance-for-enhancing-direct-pr.html" onclick="toggleFavorite(this, '2506.14574v1', 'TGDPO: Harnessing Token-Level Reward Guidance for Enhancing Direct Preference Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250700026v1-rose-toward-reality-oriented-safety-evaluation-of-large-language-mod.html">ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models</a></td>
  <td>æå‡ºROSEæ¡†æ¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹å®‰å…¨è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2507.00026v1" data-paper-url="./papers/250700026v1-rose-toward-reality-oriented-safety-evaluation-of-large-language-mod.html" onclick="toggleFavorite(this, '2507.00026v1', 'ROSE: Toward Reality-Oriented Safety Evaluation of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250614965v1-revisiting-reinforcement-learning-for-llm-reasoning-from-a-cross-dom.html">Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective</a></td>
  <td>æå‡ºGuruä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­çš„å¥–åŠ±ä¿¡å·ä¸è¶³é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">reward design</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14965v1" data-paper-url="./papers/250614965v1-revisiting-reinforcement-learning-for-llm-reasoning-from-a-cross-dom.html" onclick="toggleFavorite(this, '2506.14965v1', 'Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸€æœºå™¨äººæ§åˆ¶-robot-control">ğŸ”¬ æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250614411v1-adaptive-reinforcement-learning-for-unobservable-random-delays.html">Adaptive Reinforcement Learning for Unobservable Random Delays</a></td>
  <td>æå‡ºäº¤äº’å±‚ä»¥è§£å†³ä¸å¯è§‚æµ‹éšæœºå»¶è¿Ÿé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">locomotion</span> <span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.14411v1" data-paper-url="./papers/250614411v1-adaptive-reinforcement-learning-for-unobservable-random-delays.html" onclick="toggleFavorite(this, '2506.14411v1', 'Adaptive Reinforcement Learning for Unobservable Random Delays')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>5</td>
  <td><a href="./papers/250615025v1-optimal-embedding-learning-rate-in-llms-the-effect-of-vocabulary-siz.html">Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size</a></td>
  <td>æå‡ºä¼˜åŒ–åµŒå…¥å­¦ä¹ ç‡ä»¥åº”å¯¹å¤§è¯­è¨€æ¨¡å‹è¯æ±‡è§„æ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.15025v1" data-paper-url="./papers/250615025v1-optimal-embedding-learning-rate-in-llms-the-effect-of-vocabulary-siz.html" onclick="toggleFavorite(this, '2506.15025v1', 'Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)