---
layout: default
title: Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective
---

# Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.14965" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.14965v1</a>
  <a href="https://arxiv.org/pdf/2506.14965.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.14965v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.14965v1', 'Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhoujun Cheng, Shibo Hao, Tianyang Liu, Fan Zhou, Yutao Xie, Feng Yao, Yuexin Bian, Yonghao Zhuang, Nilabjo Dey, Yuheng Zha, Yi Gu, Kun Zhou, Yuqi Wang, Yuan Li, Richard Fan, Jianshu She, Chengqian Gao, Abulhair Saparov, Haonan Li, Taylor W. Killian, Mikhail Yurochkin, Zhengzhong Liu, Eric P. Xing, Zhiting Hu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-17

**å¤‡æ³¨**: 38 pages, 9 figures. Under review

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/LLM360/Reasoning360)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGuruä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­çš„å¥–åŠ±ä¿¡å·ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `æ¨ç†èƒ½åŠ›` `è·¨é¢†åŸŸè®­ç»ƒ` `è¯­æ–™åº“è®¾è®¡` `æ¨¡å‹è¯„ä¼°` `å¤æ‚ä»»åŠ¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­ä¸»è¦é›†ä¸­äºæ•°å­¦å’Œä»£ç ï¼Œç¼ºä¹å¯¹å…¶ä»–æ¨ç†é¢†åŸŸçš„æœ‰æ•ˆæ”¯æŒã€‚
2. æœ¬æ–‡æå‡ºGuruè¯­æ–™åº“ï¼Œé€šè¿‡è®¾è®¡é¢†åŸŸç‰¹å®šçš„å¥–åŠ±ä¿¡å·ï¼Œæä¾›äº†ä¸€ä¸ªå¯é ä¸”å¯æ‰©å±•çš„RLè®­ç»ƒåŸºç¡€ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuru-7Bå’ŒGuru-32Bæ¨¡å‹åœ¨å¤šé¡¹ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œæ˜¾è‘—æå‡äº†åŸºçº¿æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å·²æˆä¸ºæå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ¨ç†èƒ½åŠ›çš„æœ‰å‰æ™¯çš„æ–¹æ³•ï¼Œç„¶è€Œç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨æ•°å­¦å’Œä»£ç é¢†åŸŸï¼Œé™åˆ¶äº†å…¶åœ¨æ›´å¹¿æ³›æ¨ç†é¢†åŸŸçš„åº”ç”¨ç†è§£ã€‚æœ¬æ–‡å¼•å…¥Guruï¼Œä¸€ä¸ªåŒ…å«92Kå¯éªŒè¯ç¤ºä¾‹çš„RLæ¨ç†è¯­æ–™åº“ï¼Œæ¶µç›–æ•°å­¦ã€ä»£ç ã€ç§‘å­¦ã€é€»è¾‘ã€ä»¿çœŸå’Œè¡¨æ ¼å…­ä¸ªæ¨ç†é¢†åŸŸã€‚é€šè¿‡ç³»ç»Ÿæ€§åœ°å›é¡¾RLåœ¨LLMæ¨ç†ä¸­çš„æ—¢æœ‰å‘ç°ï¼Œè§‚å¯Ÿåˆ°ä¸åŒé¢†åŸŸé—´çš„æ˜¾è‘—å·®å¼‚ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒRLä¸ä»…èƒ½ä»é¢„è®­ç»ƒæ¨¡å‹ä¸­æå–çŸ¥è¯†ï¼Œè¿˜èƒ½ä¿ƒè¿›çœŸå®æŠ€èƒ½çš„è·å–ã€‚æœ€åï¼Œæå‡ºçš„Guru-7Bå’ŒGuru-32Bæ¨¡å‹åœ¨17é¡¹ä»»åŠ¡è¯„ä¼°ä¸­è¶…è¶Šæœ€ä½³åŸºçº¿ï¼Œåˆ†åˆ«æå‡7.9%å’Œ6.7%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†ä¸­ç¼ºä¹å¯é å’Œå¯æ‰©å±•çš„å¼ºåŒ–å­¦ä¹ å¥–åŠ±ä¿¡å·çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é›†ä¸­äºæ•°å­¦å’Œä»£ç ï¼Œæœªèƒ½æœ‰æ•ˆè¦†ç›–å…¶ä»–æ¨ç†é¢†åŸŸã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºGuruè¯­æ–™åº“ï¼ŒåŒ…å«92Kä¸ªå¯éªŒè¯ç¤ºä¾‹ï¼Œæ¶µç›–å…­ä¸ªæ¨ç†é¢†åŸŸï¼Œé€šè¿‡é¢†åŸŸç‰¹å®šçš„å¥–åŠ±è®¾è®¡å’Œå»é‡è¿‡æ»¤ï¼Œç¡®ä¿è®­ç»ƒçš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€å¥–åŠ±è®¾è®¡ã€æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚æ•°æ®æ”¶é›†é˜¶æ®µæ„å»ºå¤šé¢†åŸŸçš„æ¨ç†ç¤ºä¾‹ï¼Œå¥–åŠ±è®¾è®¡é˜¶æ®µé’ˆå¯¹æ¯ä¸ªé¢†åŸŸåˆ¶å®šç‰¹å®šçš„å¥–åŠ±ä¿¡å·ï¼Œæ¨¡å‹è®­ç»ƒé˜¶æ®µä½¿ç”¨å¼ºåŒ–å­¦ä¹ ç®—æ³•è¿›è¡Œè®­ç»ƒï¼Œè¯„ä¼°é˜¶æ®µåˆ™é€šè¿‡17é¡¹ä»»åŠ¡è¿›è¡Œæ€§èƒ½éªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†Guruè¯­æ–™åº“ï¼Œç³»ç»Ÿæ€§åœ°è§£å†³äº†ä¸åŒæ¨ç†é¢†åŸŸé—´çš„å¥–åŠ±ä¿¡å·ä¸è¶³é—®é¢˜ï¼Œå±•ç¤ºäº†è·¨é¢†åŸŸè®­ç»ƒçš„æœ‰æ•ˆæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°å„é¢†åŸŸçš„æ¨ç†æŠ€èƒ½ï¼ŒåŒæ—¶å¯¹å¤æ‚ä»»åŠ¡çš„è¡¨ç°è¿›è¡Œäº†ä¼˜åŒ–ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGuru-7Bå’ŒGuru-32Bæ¨¡å‹åœ¨17é¡¹ä»»åŠ¡è¯„ä¼°ä¸­åˆ†åˆ«è¶…è¶Šæœ€ä½³åŸºçº¿7.9%å’Œ6.7%ã€‚è¿™äº›æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šçš„è¡¨ç°å°¤ä¸ºçªå‡ºï¼Œæ˜¾è‘—æå‡äº†åŸºç¡€æ¨¡å‹çš„Pass@kæ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨é¢„è®­ç»ƒæ•°æ®ä¸­è¾ƒå°‘å‡ºç°çš„ä»»åŠ¡ä¸Šã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€ç§‘å­¦ç ”ç©¶ã€ç¼–ç¨‹è¾…åŠ©ç­‰ï¼Œèƒ½å¤Ÿä¸ºå¤æ‚æ¨ç†ä»»åŠ¡æä¾›æ›´å¼ºå¤§çš„æ”¯æŒã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½åœ¨è‡ªåŠ¨åŒ–å†³ç­–ã€æ™ºèƒ½é—®ç­”ç­‰é¢†åŸŸäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) has emerged as a promising approach to improve large language model (LLM) reasoning, yet most open efforts focus narrowly on math and code, limiting our understanding of its broader applicability to general reasoning. A key challenge lies in the lack of reliable, scalable RL reward signals across diverse reasoning domains. We introduce Guru, a curated RL reasoning corpus of 92K verifiable examples spanning six reasoning domains--Math, Code, Science, Logic, Simulation, and Tabular--each built through domain-specific reward design, deduplication, and filtering to ensure reliability and effectiveness for RL training. Based on Guru, we systematically revisit established findings in RL for LLM reasoning and observe significant variation across domains. For example, while prior work suggests that RL primarily elicits existing knowledge from pretrained models, our results reveal a more nuanced pattern: domains frequently seen during pretraining (Math, Code, Science) easily benefit from cross-domain RL training, while domains with limited pretraining exposure (Logic, Simulation, and Tabular) require in-domain training to achieve meaningful performance gains, suggesting that RL is likely to facilitate genuine skill acquisition. Finally, we present Guru-7B and Guru-32B, two models that achieve state-of-the-art performance among open models RL-trained with publicly available data, outperforming best baselines by 7.9% and 6.7% on our 17-task evaluation suite across six reasoning domains. We also show that our models effectively improve the Pass@k performance of their base models, particularly on complex tasks less likely to appear in pretraining data. We release data, models, training and evaluation code to facilitate general-purpose reasoning at: https://github.com/LLM360/Reasoning360

