---
layout: default
title: Stochastic activations
---

# Stochastic activations

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22358" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22358v1</a>
  <a href="https://arxiv.org/pdf/2509.22358.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22358v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22358v1', 'Stochastic activations')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Maria Lomeli, Matthijs Douze, Gergely Szilvasy, Loic Cabannes, Jade Copet, Sainbayar Sukhbaatar, Jason Weston, Gabriel Synnaeve, Pierre-Emmanuel MazarÃ©, HervÃ© JÃ©gou

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºéšæœºæ¿€æ´»å‡½æ•°ï¼Œæå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†é€Ÿåº¦å¹¶å¢å¼ºç”Ÿæˆæ–‡æœ¬å¤šæ ·æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšæœºæ¿€æ´»å‡½æ•°` `å¤§è¯­è¨€æ¨¡å‹` `ReLU` `SILU` `æ¨ç†åŠ é€Ÿ` `æ–‡æœ¬ç”Ÿæˆ` `æ¨¡å‹ä¼˜åŒ–` `æ¢¯åº¦æ¶ˆå¤±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»ŸReLUæ¿€æ´»å‡½æ•°åœ¨è´Ÿè¾“å…¥æ—¶æ¢¯åº¦ä¸ºé›¶ï¼Œé˜»ç¢äº†æ¨¡å‹ä¼˜åŒ–ï¼Œå°¤å…¶æ˜¯åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ã€‚
2. è®ºæ–‡æå‡ºéšæœºæ¿€æ´»å‡½æ•°ï¼Œåœ¨è®­ç»ƒæ—¶éšæœºé€‰æ‹©SILUæˆ–ReLUï¼Œå…‹æœReLUçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚
3. å®éªŒè¡¨æ˜ï¼Œé¢„è®­ç»ƒæ—¶ä½¿ç”¨éšæœºæ¿€æ´»å‡½æ•°ï¼Œå¾®è°ƒæ—¶ä½¿ç”¨ReLUï¼Œèƒ½æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦å’Œç”Ÿæˆæ–‡æœ¬å¤šæ ·æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç­–ç•¥â€”â€”éšæœºæ¿€æ´»å‡½æ•°ã€‚è¯¥ç­–ç•¥åœ¨å¤§è¯­è¨€æ¨¡å‹çš„å‰é¦ˆå±‚ä¸­éšæœºé€‰æ‹©å¤šä¸ªéçº¿æ€§å‡½æ•°ä¹‹ä¸€ã€‚å…·ä½“æ¥è¯´ï¼Œæ ¹æ®ä¼¯åŠªåˆ©åˆ†å¸ƒçš„é‡‡æ ·ç»“æœï¼Œé€‰æ‹©SILUæˆ–RELUæ¿€æ´»å‡½æ•°ã€‚è¿™ç§ç­–ç•¥è§„é¿äº†ä¸RELUç›¸å…³çš„ä¼˜åŒ–é—®é¢˜ï¼Œå³è´Ÿè¾“å…¥çš„æ’å®šå½¢çŠ¶é˜»ç¢äº†æ¢¯åº¦æµåŠ¨ã€‚æˆ‘ä»¬é€šè¿‡ä¸¤ç§æ–¹å¼åˆ©ç”¨è¿™ç§ç­–ç•¥ï¼šï¼ˆ1ï¼‰åœ¨é¢„è®­ç»ƒæœŸé—´ä½¿ç”¨éšæœºæ¿€æ´»å‡½æ•°ï¼Œå¹¶åœ¨å¾®è°ƒæ—¶ä½¿ç”¨RELUï¼Œä»¥ä¾¿åœ¨æ¨ç†æ—¶æä¾›ç¨€ç–çš„æ½œåœ¨å‘é‡ã€‚è¿™å‡å°‘äº†æ¨ç†FLOPsï¼Œå¹¶æ˜¾è‘—æé«˜äº†CPUé€Ÿåº¦ã€‚æœ‰è¶£çš„æ˜¯ï¼Œè¿™æ¯”ä»å¤´å¼€å§‹ä½¿ç”¨RELUæ¿€æ´»å‡½æ•°è¿›è¡Œè®­ç»ƒçš„æ•ˆæœè¦å¥½å¾—å¤šã€‚ï¼ˆ2ï¼‰æˆ‘ä»¬è¯„ä¼°äº†éšæœºæ¿€æ´»å‡½æ•°åœ¨ç”Ÿæˆä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚è¯¥ç­–ç•¥è¡¨ç°è‰¯å¥½ï¼šä»…ç•¥é€Šäºæœ€ä½³ç¡®å®šæ€§éçº¿æ€§å‡½æ•°ï¼Œå³SILUä¸æ¸©åº¦ç¼©æ”¾çš„ç»„åˆã€‚è¿™ä¸ºç°æœ‰ç­–ç•¥æä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆï¼Œé€šè¿‡ä¸€ç§å¯æ§çš„æ–¹å¼æ¥å¢åŠ ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°æ—¶ï¼Œç”±äºReLUåœ¨è´Ÿè¾“å…¥æ—¶è¾“å‡ºä¸ºé›¶ï¼Œå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ï¼Œå½±å“æ¨¡å‹çš„è®­ç»ƒæ•ˆæœã€‚å°¤å…¶æ˜¯åœ¨æ¨¡å‹è§„æ¨¡å¢å¤§æ—¶ï¼Œè¿™ä¸ªé—®é¢˜æ›´åŠ çªå‡ºã€‚æ­¤å¤–ï¼Œå¦‚ä½•åœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œæå‡æ¨ç†é€Ÿåº¦å’Œç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§ï¼Œé€šè¿‡éšæœºé€‰æ‹©SILUæˆ–ReLUæ¿€æ´»å‡½æ•°ï¼Œæ¥å…‹æœReLUçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚SILUæ¿€æ´»å‡½æ•°åœ¨è´Ÿè¾“å…¥æ—¶å…·æœ‰éé›¶æ¢¯åº¦ï¼Œå¯ä»¥ç¼“è§£æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°å¯ä»¥è·å¾—ç¨€ç–çš„æ¿€æ´»ï¼Œä»è€Œæå‡æ¨ç†é€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œä½¿ç”¨éšæœºæ¿€æ´»å‡½æ•°ï¼Œå³ä»¥ä¸€å®šçš„æ¦‚ç‡é€‰æ‹©SILUæˆ–ReLUæ¿€æ´»å‡½æ•°ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œä½¿ç”¨ReLUæ¿€æ´»å‡½æ•°ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç›´æ¥ä½¿ç”¨å¾®è°ƒåçš„æ¨¡å‹ï¼Œåˆ©ç”¨ReLUçš„ç¨€ç–æ€§æ¥åŠ é€Ÿæ¨ç†ã€‚æ•´ä½“æµç¨‹ç®€å•æ˜“æ‡‚ï¼Œæ˜“äºå®ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†éšæœºæ¿€æ´»å‡½æ•°çš„æ¦‚å¿µï¼Œé€šè¿‡åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºæ€§ï¼Œæ¥å…‹æœReLUçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚ä¸ä¼ ç»Ÿçš„ReLUæ¿€æ´»å‡½æ•°ç›¸æ¯”ï¼Œéšæœºæ¿€æ´»å‡½æ•°å¯ä»¥æ›´å¥½åœ°è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¹¶æå‡æ¨¡å‹çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åœ¨æ¨ç†é˜¶æ®µåˆ©ç”¨ReLUçš„ç¨€ç–æ€§æ¥åŠ é€Ÿæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š(1) éšæœºé€‰æ‹©SILUæˆ–ReLUæ¿€æ´»å‡½æ•°çš„æ¦‚ç‡åˆ†å¸ƒï¼Œé€šå¸¸ä½¿ç”¨ä¼¯åŠªåˆ©åˆ†å¸ƒã€‚(2) é¢„è®­ç»ƒé˜¶æ®µå’Œå¾®è°ƒé˜¶æ®µçš„å­¦ä¹ ç‡è®¾ç½®ã€‚(3) åœ¨ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œå¯ä»¥ä½¿ç”¨æ¸©åº¦ç¼©æ”¾æ¥æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ã€‚å…·ä½“å‚æ•°è®¾ç½®éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡å’Œæ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨éšæœºæ¿€æ´»å‡½æ•°è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶åä½¿ç”¨ReLUè¿›è¡Œå¾®è°ƒï¼Œå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹çš„æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ã€‚ä¸ä»å¤´å¼€å§‹ä½¿ç”¨ReLUè®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å–å¾—äº†æ›´å¥½çš„æ•ˆæœã€‚æ­¤å¤–ï¼Œåœ¨ç”Ÿæˆä»»åŠ¡ä¸­ï¼Œéšæœºæ¿€æ´»å‡½æ•°å¯ä»¥ç”Ÿæˆæ›´å¤šæ ·åŒ–çš„æ–‡æœ¬ï¼Œæ€§èƒ½æ¥è¿‘SILUä¸æ¸©åº¦ç¼©æ”¾çš„ç»„åˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¿«é€Ÿæ¨ç†å’Œå¤šæ ·æ€§æ–‡æœ¬ç”Ÿæˆçš„å¤§å‹è¯­è¨€æ¨¡å‹åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½å¯¹è¯æœºå™¨äººã€æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚é€šè¿‡æå‡æ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥é™ä½è®¡ç®—æˆæœ¬ï¼Œæé«˜ç”¨æˆ·ä½“éªŒã€‚é€šè¿‡å¢å¼ºç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼Œå¯ä»¥ä½¿æ¨¡å‹ç”Ÿæˆæ›´è‡ªç„¶ã€æ›´ä¸°å¯Œçš„æ–‡æœ¬ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways:
>   (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function.
>   (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.

