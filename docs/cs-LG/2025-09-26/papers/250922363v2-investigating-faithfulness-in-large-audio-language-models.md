---
layout: default
title: Investigating Faithfulness in Large Audio Language Models
---

# Investigating Faithfulness in Large Audio Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22363" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22363v2</a>
  <a href="https://arxiv.org/pdf/2509.22363.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22363v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22363v2', 'Investigating Faithfulness in Large Audio Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lovenya Jain, Pooneh Mousavi, Mirco Ravanelli, Cem Subakan

**åˆ†ç±»**: cs.LG, eess.AS

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26 (æ›´æ–°: 2025-10-14)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç ”ç©¶è¡¨æ˜å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰çš„æ€ç»´é“¾ï¼ˆCoTï¼‰åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å¯ä¿¡çš„ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹` `æ€ç»´é“¾` `å¯ä¿¡åº¦` `éŸ³é¢‘æ¨ç†` `å¯è§£é‡Šæ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ–‡æœ¬çš„LLMçš„CoTå¯ä¿¡åº¦è¾ƒä½ï¼Œè€ŒLALMçš„å¯ä¿¡åº¦ç ”ç©¶ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ•æ„Ÿåœºæ™¯ä¸‹ã€‚
2. é€šè¿‡å¯¹LALMçš„CoTè¿›è¡Œå¹²é¢„ï¼ˆé‡Šä¹‰ã€æ³¨å…¥ã€æå‰å›ç­”ã€å¼•å…¥é”™è¯¯ï¼‰ï¼Œè¯„ä¼°å…¶å¯¹å†³ç­–è¿‡ç¨‹çš„çœŸå®åæ˜ ç¨‹åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLALMç”Ÿæˆçš„CoTåœ¨ä¸€å®šç¨‹åº¦ä¸Šåæ˜ äº†å…¶åº•å±‚çš„å†³ç­–è¿‡ç¨‹ï¼Œå…·æœ‰ä¸€å®šçš„å¯ä¿¡åº¦ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æ¢è®¨äº†æ€ç»´é“¾ï¼ˆCoTï¼‰è¡¨å¾æ˜¯å¦å‡†ç¡®åæ˜ äº†å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰çš„å†³ç­–è¿‡ç¨‹ï¼Œä»¥åŠCoTæ˜¯å¦å¯ä»¥ä½œä¸ºå¯é çš„è§£é‡Šã€‚å…ˆå‰çš„ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºæ–‡æœ¬çš„LLMçš„CoTé€šå¸¸æ˜¯ä¸å¯ä¿¡çš„ã€‚å¯¹äºå¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰è€Œè¨€ï¼Œç”±äºå…¶åœ¨å®‰å…¨æ•æ„Ÿå‹åº”ç”¨ä¸­çš„é‡è¦æ€§ï¼ŒCoTçš„å¯ä¿¡åº¦é—®é¢˜å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚LALMä¸­çš„æ¨ç†æ›´å…·æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºæ¨¡å‹å¿…é¡»é¦–å…ˆä»éŸ³é¢‘ä¸­æå–ç›¸å…³çº¿ç´¢ï¼Œç„¶åæ‰èƒ½è¿›è¡Œæ¨ç†ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†æ•°æ®é›†SAKURAå’ŒMMARä¸Šåº”ç”¨æœ‰é’ˆå¯¹æ€§çš„å¹²é¢„æªæ–½ï¼ŒåŒ…æ‹¬é‡Šä¹‰ã€å¡«å……è¯æ³¨å…¥ã€æå‰å›ç­”å’Œå¼•å…¥é”™è¯¯ï¼Œæ¥ç ”ç©¶å‡ ç§LALMç”Ÿæˆçš„CoTçš„å¯ä¿¡åº¦ã€‚ç»è¿‡åœ¨å¤šä¸ªæ•°æ®é›†å’Œä»»åŠ¡ä¸­è¿›è¡Œä¸Šè¿°å¹²é¢„åï¼Œæˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒLALMé€šå¸¸ä¼šç”Ÿæˆå¯¹å…¶åº•å±‚å†³ç­–è¿‡ç¨‹è€Œè¨€ä¼¼ä¹æ˜¯å¯ä¿¡çš„CoTã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨ç ”ç©¶å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹ï¼ˆLALMï¼‰ä¸­æ€ç»´é“¾ï¼ˆCoTï¼‰çš„å¯ä¿¡åº¦ã€‚ç°æœ‰ç ”ç©¶è¡¨æ˜ï¼ŒåŸºäºæ–‡æœ¬çš„LLMçš„CoTå¾€å¾€ä¸å¯ä¿¡ï¼Œè€ŒLALMçš„CoTå¯ä¿¡åº¦å°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨å®‰å…¨æ•æ„Ÿçš„åº”ç”¨åœºæ™¯ä¸‹ï¼ŒCoTçš„å¯ä¿¡åº¦è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼ŒLALMéœ€è¦å…ˆä»éŸ³é¢‘ä¸­æå–ä¿¡æ¯ï¼Œå†è¿›è¡Œæ¨ç†ï¼Œå¢åŠ äº†æ¨ç†çš„å¤æ‚æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹LALMç”Ÿæˆçš„CoTè¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„å¹²é¢„ï¼Œè§‚å¯Ÿå¹²é¢„å‰åæ¨¡å‹å†³ç­–çš„å˜åŒ–ï¼Œä»è€Œè¯„ä¼°CoTæ˜¯å¦çœŸå®åæ˜ äº†æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹ã€‚å¦‚æœCoTèƒ½å¤ŸæŠµæŠ—å¹²é¢„ï¼Œå¹¶ä¸”æ¨¡å‹çš„å†³ç­–ä¸CoTçš„å†…å®¹ä¸€è‡´ï¼Œåˆ™è®¤ä¸ºCoTæ˜¯å¯ä¿¡çš„ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1ï¼‰é€‰æ‹©å…·æœ‰æŒ‘æˆ˜æ€§çš„æ¨ç†æ•°æ®é›†ï¼ˆSAKURAå’ŒMMARï¼‰ï¼›2ï¼‰ä½¿ç”¨LALMç”ŸæˆCoTï¼›3ï¼‰å¯¹CoTè¿›è¡Œå¤šç§å¹²é¢„ï¼ŒåŒ…æ‹¬é‡Šä¹‰ã€å¡«å……è¯æ³¨å…¥ã€æå‰å›ç­”å’Œå¼•å…¥é”™è¯¯ï¼›4ï¼‰è¯„ä¼°å¹²é¢„å‰åæ¨¡å‹çš„æ€§èƒ½å˜åŒ–ï¼›5ï¼‰åˆ†æCoTä¸æ¨¡å‹å†³ç­–çš„ä¸€è‡´æ€§ï¼Œä»è€Œåˆ¤æ–­CoTçš„å¯ä¿¡åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºé¦–æ¬¡é’ˆå¯¹LALMçš„CoTå¯ä¿¡åº¦è¿›è¡Œäº†ç³»ç»Ÿçš„ç ”ç©¶ã€‚é€šè¿‡è®¾è®¡å¤šç§å¹²é¢„æ‰‹æ®µï¼Œèƒ½å¤Ÿæ›´å…¨é¢åœ°è¯„ä¼°CoTçš„çœŸå®æ€§ã€‚ä¸ä»¥å¾€ä¸»è¦å…³æ³¨æ–‡æœ¬LLMçš„CoTç ”ç©¶ä¸åŒï¼Œæœ¬æ–‡èšç„¦äºéŸ³é¢‘æ¨¡æ€ï¼Œæ›´å…·æŒ‘æˆ˜æ€§å’Œå®é™…æ„ä¹‰ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰é€‰æ‹©SAKURAå’ŒMMARä½œä¸ºæ•°æ®é›†ï¼Œè¿™ä¸¤ä¸ªæ•°æ®é›†éœ€è¦æ¨¡å‹è¿›è¡Œå¤æ‚çš„æ¨ç†ï¼›2ï¼‰è®¾è®¡äº†å››ç§å¹²é¢„æ‰‹æ®µï¼Œåˆ†åˆ«ä»ä¸åŒè§’åº¦å½±å“CoTçš„å†…å®¹å’Œç»“æ„ï¼›3ï¼‰é€šè¿‡æ¯”è¾ƒå¹²é¢„å‰åæ¨¡å‹çš„æ€§èƒ½å˜åŒ–ï¼Œé‡åŒ–CoTçš„å½±å“ï¼›4ï¼‰åˆ†æCoTçš„å†…å®¹ä¸æ¨¡å‹æœ€ç»ˆå†³ç­–ä¹‹é—´çš„å…³ç³»ï¼Œåˆ¤æ–­CoTæ˜¯å¦çœŸå®åæ˜ äº†æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒLALMç”Ÿæˆçš„CoTåœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å¯ä¿¡çš„ï¼Œèƒ½å¤Ÿåæ˜ å…¶åº•å±‚çš„å†³ç­–è¿‡ç¨‹ã€‚å°½ç®¡åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œå¹²é¢„ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ï¼Œä½†æ€»ä½“è€Œè¨€ï¼ŒLALMçš„CoTè¡¨ç°å‡ºä¸€å®šçš„é²æ£’æ€§ã€‚è¯¥ç ”ç©¶ä¸ºLALMçš„å¯ä¿¡åº¦è¯„ä¼°æä¾›äº†ä¸€ä¸ªæ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå®‰å…¨æ•æ„Ÿçš„éŸ³é¢‘å¤„ç†é¢†åŸŸï¼Œä¾‹å¦‚è¯­éŸ³åŠ©æ‰‹ã€åŒ»ç–—è¯Šæ–­ã€æ™ºèƒ½ç›‘æ§ç­‰ã€‚é€šè¿‡æé«˜LALMçš„å¯ä¿¡åº¦ï¼Œå¯ä»¥å¢å¼ºç”¨æˆ·å¯¹æ¨¡å‹çš„ä¿¡ä»»ï¼Œå¹¶å‡å°‘å› æ¨¡å‹é”™è¯¯å†³ç­–å¸¦æ¥çš„é£é™©ã€‚æœªæ¥çš„ç ”ç©¶å¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢å¦‚ä½•æé«˜LALMçš„CoTå¯ä¿¡åº¦ï¼Œå¹¶å°†å…¶åº”ç”¨äºæ›´å¹¿æ³›çš„éŸ³é¢‘ç†è§£ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Faithfulness measures whether chain-of-thought (CoT) representations accurately reflect a model's decision process and can be used as reliable explanations. Prior work has shown that CoTs from text-based LLMs are often unfaithful. This question has not been explored for large audio-language models (LALMs), where faithfulness is critical for safety-sensitive applications. Reasoning in LALMs is also more challenging, as models must first extract relevant clues from audio before reasoning over them. In this paper, we investigate the faithfulness of CoTs produced by several LALMs by applying targeted interventions, including paraphrasing, filler token injection, early answering, and introducing mistakes, on two challenging reasoning datasets: SAKURA and MMAR. After going through the aforementioned interventions across several datasets and tasks, our experiments suggest that, LALMs generally produce CoTs that appear to be faithful to their underlying decision processes.

