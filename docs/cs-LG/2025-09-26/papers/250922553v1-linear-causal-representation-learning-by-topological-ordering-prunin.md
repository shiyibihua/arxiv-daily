---
layout: default
title: Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement
---

# Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.22553" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.22553v1</a>
  <a href="https://arxiv.org/pdf/2509.22553.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.22553v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.22553v1', 'Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hao Chen, Lin Liu, Yu Guang Wang

**åˆ†ç±»**: stat.ML, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§åŸºäºæ‹“æ‰‘æ’åºã€å‰ªæå’Œè§£è€¦çš„çº¿æ€§å› æœè¡¨ç¤ºå­¦ä¹ æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å› æœè¡¨ç¤ºå­¦ä¹ ` `çº¿æ€§ç»“æ„å› æœæ¨¡å‹` `æ‹“æ‰‘æ’åº` `å› æœå‘ç°` `è§£è€¦` `å¯è§£é‡Šæ€§` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çº¿æ€§å› æœè¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä¾èµ–äºå¼ºå‡è®¾ï¼Œå¦‚å•èŠ‚ç‚¹å¹²é¢„æ•°æ®æˆ–ä¸¥æ ¼çš„åˆ†å¸ƒçº¦æŸï¼Œé™åˆ¶äº†å…¶åº”ç”¨èŒƒå›´ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§æ–°çš„çº¿æ€§å› æœè¡¨ç¤ºå­¦ä¹ ç®—æ³•ï¼Œåœ¨è¾ƒå¼±çš„å‡è®¾ä¸‹æ¢å¤æ½œåœ¨å› æœç‰¹å¾ï¼Œæ”¾å®½äº†å¯¹ç¯å¢ƒå¼‚è´¨æ€§å’Œæ•°æ®ç”Ÿæˆåˆ†å¸ƒçš„è¦æ±‚ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨æœ‰é™æ ·æœ¬ä¸­ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å±•ç¤ºäº†å…¶åœ¨å¤§å‹è¯­è¨€æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æä¸­çš„æ½œåŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å› æœè¡¨ç¤ºå­¦ä¹ (CRL)è¶Šæ¥è¶Šå—åˆ°å› æœæ¨æ–­å’Œäººå·¥æ™ºèƒ½ç•Œçš„å…³æ³¨ï¼Œå› ä¸ºå®ƒèƒ½å¤Ÿåˆ©ç”¨ç°ä»£æ•°æ®é›†çš„å¼‚è´¨æ€§ï¼Œå°†æ½œåœ¨çš„å¤æ‚æ•°æ®ç”Ÿæˆæœºåˆ¶è§£è€¦ä¸ºå› æœå¯è§£é‡Šçš„æ½œåœ¨ç‰¹å¾ã€‚æœ¬æ–‡è¿›ä¸€æ­¥è´¡çŒ®äºCRLé¢†åŸŸï¼Œä¸“æ³¨äºæ½œåœ¨ç‰¹å¾ä¸Šçš„ç¨‹å¼åŒ–çº¿æ€§ç»“æ„å› æœæ¨¡å‹ï¼Œå¹¶å‡è®¾ä¸€ä¸ªçº¿æ€§æ··åˆå‡½æ•°ï¼Œå°†æ½œåœ¨ç‰¹å¾æ˜ å°„åˆ°è§‚æµ‹æ•°æ®æˆ–æµ‹é‡å€¼ã€‚ç°æœ‰çš„çº¿æ€§CRLæ–¹æ³•é€šå¸¸ä¾èµ–äºä¸¥æ ¼çš„å‡è®¾ï¼Œä¾‹å¦‚å¯è®¿é—®å•èŠ‚ç‚¹å¹²é¢„æ•°æ®æˆ–å¯¹æ½œåœ¨ç‰¹å¾å’Œå¤–ç”Ÿæµ‹é‡å™ªå£°çš„é™åˆ¶æ€§åˆ†å¸ƒçº¦æŸã€‚ç„¶è€Œï¼Œè¿™äº›å…ˆå†³æ¡ä»¶åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½éš¾ä»¥æ»¡è¶³ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„çº¿æ€§CRLç®—æ³•ï¼Œä¸å¤§å¤šæ•°ç°æœ‰çº¿æ€§CRLæ–¹æ³•ä¸åŒï¼Œå®ƒåœ¨å…³äºç¯å¢ƒå¼‚è´¨æ€§å’Œæ•°æ®ç”Ÿæˆåˆ†å¸ƒçš„è¾ƒå¼±å‡è®¾ä¸‹è¿è¡Œï¼ŒåŒæ—¶ä»ç„¶å¯ä»¥æ¢å¤æ½œåœ¨çš„å› æœç‰¹å¾ï¼Œç›´è‡³ä¸€ä¸ªç­‰ä»·ç±»ã€‚æˆ‘ä»¬é€šè¿‡åˆæˆå®éªŒå’Œå¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„å¯è§£é‡Šæ€§åˆ†æè¿›ä¸€æ­¥éªŒè¯äº†æˆ‘ä»¬çš„æ–°ç®—æ³•ï¼Œè¯æ˜äº†å®ƒåœ¨æœ‰é™æ ·æœ¬ä¸­ä¼˜äºç«äº‰æ–¹æ³•ï¼Œä»¥åŠå®ƒåœ¨å°†å› æœå…³ç³»æ•´åˆåˆ°äººå·¥æ™ºèƒ½ä¸­çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè¯¥è®ºæ–‡æ—¨åœ¨è§£å†³çº¿æ€§ç»“æ„å› æœæ¨¡å‹ä¸‹çš„å› æœè¡¨ç¤ºå­¦ä¹ é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦è¾ƒå¼ºçš„å‡è®¾ï¼Œä¾‹å¦‚å¯è·å–å•èŠ‚ç‚¹å¹²é¢„æ•°æ®ï¼Œæˆ–è€…å¯¹æ½œåœ¨å˜é‡å’Œå™ªå£°çš„åˆ†å¸ƒæœ‰ä¸¥æ ¼çš„é™åˆ¶ã€‚è¿™äº›å‡è®¾åœ¨å®é™…åº”ç”¨ä¸­å¾€å¾€éš¾ä»¥æ»¡è¶³ï¼Œé™åˆ¶äº†ç®—æ³•çš„é€‚ç”¨æ€§ã€‚å› æ­¤ï¼Œè¯¥è®ºæ–‡æ—¨åœ¨è®¾è®¡ä¸€ç§åœ¨æ›´å¼±å‡è®¾ä¸‹ä¹Ÿèƒ½æœ‰æ•ˆå­¦ä¹ å› æœè¡¨ç¤ºçš„ç®—æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ‹“æ‰‘æ’åºã€å‰ªæå’Œè§£è€¦ä¸‰ä¸ªæ­¥éª¤ï¼Œä»è§‚æµ‹æ•°æ®ä¸­æ¢å¤æ½œåœ¨çš„å› æœç»“æ„å’Œå˜é‡ã€‚æ‹“æ‰‘æ’åºç”¨äºç¡®å®šå˜é‡ä¹‹é—´çš„å› æœé¡ºåºï¼Œå‰ªæç”¨äºå»é™¤ä¸é‡è¦çš„å› æœè¿æ¥ï¼Œè§£è€¦ç”¨äºå°†æ½œåœ¨å˜é‡åˆ†ç¦»æˆç‹¬ç«‹çš„å› æœå•å…ƒã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿåœ¨è¾ƒå¼±çš„å‡è®¾ä¸‹ï¼Œæœ‰æ•ˆåœ°å­¦ä¹ åˆ°å¯è§£é‡Šçš„å› æœè¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç®—æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š
1. **æ•°æ®é¢„å¤„ç†**ï¼šå¯¹è§‚æµ‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–ç­‰é¢„å¤„ç†æ“ä½œã€‚
2. **æ‹“æ‰‘æ’åº**ï¼šåˆ©ç”¨è§‚æµ‹æ•°æ®ä¼°è®¡å˜é‡ä¹‹é—´çš„å› æœå…³ç³»ï¼Œå¹¶è¿›è¡Œæ‹“æ‰‘æ’åºï¼Œç¡®å®šå˜é‡çš„å› æœé¡ºåºã€‚
3. **å› æœå‰ªæ**ï¼šæ ¹æ®ä¸€å®šçš„å‡†åˆ™ï¼Œå»é™¤ä¸é‡è¦çš„å› æœè¿æ¥ï¼Œç®€åŒ–å› æœå›¾ã€‚
4. **è§£è€¦**ï¼šåˆ©ç”¨è§£è€¦æŠ€æœ¯ï¼Œå°†æ½œåœ¨å˜é‡åˆ†ç¦»æˆç‹¬ç«‹çš„å› æœå•å…ƒã€‚
5. **å› æœè¡¨ç¤ºå­¦ä¹ **ï¼šåŸºäºå­¦ä¹ åˆ°çš„å› æœç»“æ„å’Œå˜é‡ï¼Œè¿›è¡Œå› æœè¡¨ç¤ºå­¦ä¹ ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§åœ¨è¾ƒå¼±å‡è®¾ä¸‹è¿›è¡Œçº¿æ€§å› æœè¡¨ç¤ºå­¦ä¹ çš„ç®—æ³•ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥ç®—æ³•ä¸éœ€è¦å•èŠ‚ç‚¹å¹²é¢„æ•°æ®ï¼Œä¹Ÿä¸éœ€è¦å¯¹æ½œåœ¨å˜é‡å’Œå™ªå£°çš„åˆ†å¸ƒè¿›è¡Œä¸¥æ ¼çš„é™åˆ¶ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•è¿˜åˆ©ç”¨äº†æ‹“æ‰‘æ’åºã€å‰ªæå’Œè§£è€¦ç­‰æŠ€æœ¯ï¼Œæé«˜äº†å› æœè¡¨ç¤ºå­¦ä¹ çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å…³é”®çš„è®¾è®¡åŒ…æ‹¬ï¼š
*   **æ‹“æ‰‘æ’åºæ–¹æ³•**ï¼šä½¿ç”¨åŸºäºå›å½’çš„å› æœå‘ç°æ–¹æ³•æ¥ä¼°è®¡å˜é‡ä¹‹é—´çš„å› æœå…³ç³»ï¼Œå¹¶è¿›è¡Œæ‹“æ‰‘æ’åºã€‚
*   **å‰ªæå‡†åˆ™**ï¼šä½¿ç”¨åŸºäºç»Ÿè®¡æ˜¾è‘—æ€§çš„å‡†åˆ™æ¥å»é™¤ä¸é‡è¦çš„å› æœè¿æ¥ã€‚
*   **è§£è€¦æ–¹æ³•**ï¼šä½¿ç”¨ç‹¬ç«‹æˆåˆ†åˆ†æï¼ˆICAï¼‰ç­‰è§£è€¦æŠ€æœ¯ï¼Œå°†æ½œåœ¨å˜é‡åˆ†ç¦»æˆç‹¬ç«‹çš„å› æœå•å…ƒã€‚
*   **æŸå¤±å‡½æ•°**ï¼šä½¿ç”¨é‡æ„è¯¯å·®å’Œæ­£åˆ™åŒ–é¡¹æ¥çº¦æŸå­¦ä¹ åˆ°çš„å› æœè¡¨ç¤ºã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥è®ºæ–‡é€šè¿‡åˆæˆå®éªŒéªŒè¯äº†æ‰€æå‡ºç®—æ³•çš„æœ‰æ•ˆæ€§ï¼Œç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨æœ‰é™æ ·æœ¬ä¸‹ä¼˜äºç°æœ‰çš„çº¿æ€§å› æœè¡¨ç¤ºå­¦ä¹ æ–¹æ³•ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡è¿˜é€šè¿‡å¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLM)çš„å¯è§£é‡Šæ€§åˆ†æï¼Œå±•ç¤ºäº†è¯¥ç®—æ³•åœ¨å°†å› æœå…³ç³»æ•´åˆåˆ°äººå·¥æ™ºèƒ½ä¸­çš„æ½œåŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç®—æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ åˆ°LLMä¸­çš„å› æœè¡¨ç¤ºï¼Œå¹¶æé«˜LLMçš„å¯è§£é‡Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šä¸ªé¢†åŸŸï¼Œä¾‹å¦‚ï¼šåœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼Œå¯ä»¥ç”¨äºå‘ç°åŸºå› ä¹‹é—´çš„å› æœå…³ç³»ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ç–¾ç—…çš„å‘ç”Ÿæœºåˆ¶ï¼›åœ¨é‡‘èé¢†åŸŸï¼Œå¯ä»¥ç”¨äºåˆ†æå¸‚åœºæ³¢åŠ¨çš„åŸå› ï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œé£é™©ç®¡ç†ï¼›åœ¨ç¤¾äº¤ç½‘ç»œåˆ†æä¸­ï¼Œå¯ä»¥ç”¨äºè¯†åˆ«ä¿¡æ¯ä¼ æ’­çš„å½±å“å› ç´ ï¼Œä»è€Œæ›´å¥½åœ°è¿›è¡Œèˆ†æƒ…ç›‘æ§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæé«˜äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯è§£é‡Šæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Causal representation learning (CRL) has garnered increasing interests from the causal inference and artificial intelligence community, due to its capability of disentangling potentially complex data-generating mechanism into causally interpretable latent features, by leveraging the heterogeneity of modern datasets. In this paper, we further contribute to the CRL literature, by focusing on the stylized linear structural causal model over the latent features and assuming a linear mixing function that maps latent features to the observed data or measurements. Existing linear CRL methods often rely on stringent assumptions, such as accessibility to single-node interventional data or restrictive distributional constraints on latent features and exogenous measurement noise. However, these prerequisites can be challenging to satisfy in certain scenarios. In this work, we propose a novel linear CRL algorithm that, unlike most existing linear CRL methods, operates under weaker assumptions about environment heterogeneity and data-generating distributions while still recovering latent causal features up to an equivalence class. We further validate our new algorithm via synthetic experiments and an interpretability analysis of large language models (LLMs), demonstrating both its superiority over competing methods in finite samples and its potential in integrating causality into AI.

