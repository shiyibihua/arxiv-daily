---
layout: default
title: Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems
---

# Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15999" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15999v1</a>
  <a href="https://arxiv.org/pdf/2509.15999.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15999v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15999v1', 'Inverse Optimization Latent Variable Models for Learning Costs Applied to Route Problems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Alan A. Lahoud, Erik Schaffernicht, Johannes A. Stork

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: Accepted at Neurips 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºé€†ä¼˜åŒ–éšå˜é‡æ¨¡å‹(IO-LVM)ï¼Œç”¨äºå­¦ä¹ è·¯å¾„è§„åˆ’é—®é¢˜ä¸­çš„æˆæœ¬å‡½æ•°åˆ†å¸ƒã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `é€†ä¼˜åŒ–` `éšå˜é‡æ¨¡å‹` `çº¦æŸä¼˜åŒ–` `è·¯å¾„è§„åˆ’` `æˆæœ¬å‡½æ•°å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å­¦ä¹ çº¦æŸä¼˜åŒ–é—®é¢˜è§£çš„è¡¨ç¤ºæ—¶ï¼Œéš¾ä»¥åœ¨è§£ç è¿‡ç¨‹ä¸­å¼ºåˆ¶æ»¡è¶³çº¦æŸæ¡ä»¶ã€‚
2. IO-LVMé€šè¿‡å­¦ä¹ æˆæœ¬å‡½æ•°çš„éšç©ºé—´ï¼Œå¹¶ç»“åˆæ±‚è§£å™¨åœ¨ç¯è·¯ä¸­è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œé‡å»ºå¯è¡Œè§£ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé‡å»ºè·¯å¾„å’Œå¾ªç¯ï¼Œé¢„æµ‹å…¶åˆ†å¸ƒï¼Œå¹¶äº§ç”Ÿå¯è§£é‡Šçš„éšç©ºé—´è¡¨ç¤ºã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é’ˆå¯¹å…·æœ‰æœªçŸ¥æˆæœ¬å‡½æ•°çš„çº¦æŸä¼˜åŒ–é—®é¢˜(COP)çš„è§£è¡¨ç¤ºå­¦ä¹ éš¾é¢˜ï¼Œä¼ ç»Ÿ(å˜åˆ†)è‡ªç¼–ç å™¨éš¾ä»¥åœ¨è§£ç ç»“æ„åŒ–è¾“å‡ºæ—¶å¼ºåˆ¶æ»¡è¶³çº¦æŸã€‚æœ¬æ–‡æå‡ºä¸€ç§é€†ä¼˜åŒ–éšå˜é‡æ¨¡å‹(IO-LVM)ï¼Œé€šè¿‡å­¦ä¹ è§‚æµ‹è§£çš„COPæˆæœ¬å‡½æ•°çš„éšç©ºé—´ï¼Œå¹¶åœ¨ç¯è·¯ä¸­ä½¿ç”¨æ±‚è§£å™¨è§£å†³COPæ¥é‡å»ºå¯è¡Œè¾“å‡ºã€‚è¯¥æ–¹æ³•åˆ©ç”¨Fenchel-YoungæŸå¤±çš„ä¼°è®¡æ¢¯åº¦ï¼Œé€šè¿‡éå¯å¾®ç¡®å®šæ€§æ±‚è§£å™¨æ¥å¡‘é€ éšç©ºé—´ã€‚ä¸ä¼ ç»Ÿçš„é€†ä¼˜åŒ–æˆ–é€†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼ˆé€šå¸¸æ¢å¤å•ä¸ªæˆ–ä¸Šä¸‹æ–‡ç›¸å…³çš„æˆæœ¬å‡½æ•°ï¼‰ä¸åŒï¼ŒIO-LVMæ•è·æˆæœ¬å‡½æ•°çš„åˆ†å¸ƒï¼Œä»è€Œèƒ½å¤Ÿè¯†åˆ«ç”±ä¸åŒæ™ºèƒ½ä½“æˆ–è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å¯ç”¨çš„æ¡ä»¶äº§ç”Ÿçš„å„ç§è§£å†³æ–¹æ¡ˆè¡Œä¸ºã€‚åœ¨èˆ¹èˆ¶å’Œå‡ºç§Ÿè½¦è·¯çº¿çš„çœŸå®ä¸–ç•Œæ•°æ®é›†ä»¥åŠåˆæˆå›¾ä¸­çš„è·¯å¾„ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œè¯æ˜äº†å…¶é‡å»ºè·¯å¾„å’Œå¾ªç¯ã€é¢„æµ‹å…¶åˆ†å¸ƒä»¥åŠäº§ç”Ÿå¯è§£é‡Šçš„æ½œåœ¨è¡¨ç¤ºçš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³çº¦æŸä¼˜åŒ–é—®é¢˜ï¼ˆCOPï¼‰ä¸­ï¼Œå½“æˆæœ¬å‡½æ•°æœªçŸ¥æ—¶ï¼Œå¦‚ä½•å­¦ä¹ è§£çš„æœ‰æ•ˆè¡¨ç¤ºçš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚å˜åˆ†è‡ªç¼–ç å™¨ï¼Œåœ¨è§£ç ç»“æ„åŒ–è¾“å‡ºï¼ˆä¾‹å¦‚è·¯å¾„ï¼‰æ—¶ï¼Œéš¾ä»¥ä¿è¯è¾“å‡ºæ»¡è¶³çº¦æŸæ¡ä»¶ï¼Œå¯¼è‡´è§£çš„è´¨é‡ä¸‹é™ã€‚ä¼ ç»Ÿçš„é€†ä¼˜åŒ–æ–¹æ³•é€šå¸¸åªèƒ½æ¢å¤å•ä¸ªæˆ–ä¸Šä¸‹æ–‡ç›¸å…³çš„æˆæœ¬å‡½æ•°ï¼Œæ— æ³•æ•æ‰æˆæœ¬å‡½æ•°çš„å¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªé€†ä¼˜åŒ–éšå˜é‡æ¨¡å‹ï¼ˆIO-LVMï¼‰ï¼Œè¯¥æ¨¡å‹å­¦ä¹ ä¸€ä¸ªæˆæœ¬å‡½æ•°çš„éšç©ºé—´ï¼Œè€Œä¸æ˜¯ç›´æ¥å­¦ä¹ è§£çš„è¡¨ç¤ºã€‚é€šè¿‡åœ¨éšç©ºé—´ä¸­é‡‡æ ·ï¼Œå¹¶ä½¿ç”¨ä¼˜åŒ–æ±‚è§£å™¨æ ¹æ®é‡‡æ ·çš„æˆæœ¬å‡½æ•°ç”Ÿæˆè§£ï¼Œä»è€Œä¿è¯è§£çš„å¯è¡Œæ€§ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ•æ‰æˆæœ¬å‡½æ•°çš„åˆ†å¸ƒï¼Œä»è€Œå¯ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„è§£ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIO-LVMçš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ç¼–ç å™¨ï¼šå°†è§‚æµ‹åˆ°çš„è§£ç¼–ç åˆ°æˆæœ¬å‡½æ•°çš„éšç©ºé—´ã€‚2) éšç©ºé—´ï¼šè¡¨ç¤ºæˆæœ¬å‡½æ•°çš„åˆ†å¸ƒã€‚3) è§£ç å™¨ï¼ˆæ±‚è§£å™¨ï¼‰ï¼šä»éšç©ºé—´é‡‡æ ·æˆæœ¬å‡½æ•°ï¼Œå¹¶ä½¿ç”¨ä¼˜åŒ–æ±‚è§£å™¨ç”Ÿæˆå¯¹åº”çš„è§£ã€‚4) æŸå¤±å‡½æ•°ï¼šä½¿ç”¨Fenchel-YoungæŸå¤±æ¥è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æŸå¤±å‡½æ•°é¼“åŠ±æ¨¡å‹ç”Ÿæˆä¸è§‚æµ‹åˆ°çš„è§£ç›¸ä¼¼çš„è§£ã€‚

**å…³é”®åˆ›æ–°**ï¼šIO-LVMçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) å­¦ä¹ æˆæœ¬å‡½æ•°çš„åˆ†å¸ƒï¼Œè€Œä¸æ˜¯å•ä¸ªæˆæœ¬å‡½æ•°ï¼Œä»è€Œèƒ½å¤Ÿæ•æ‰è§£çš„å¤šæ ·æ€§ã€‚2) å°†ä¼˜åŒ–æ±‚è§£å™¨é›†æˆåˆ°æ¨¡å‹ä¸­ï¼Œä¿è¯ç”Ÿæˆè§£çš„å¯è¡Œæ€§ã€‚3) ä½¿ç”¨Fenchel-YoungæŸå¤±ï¼Œè¯¥æŸå¤±å‡½æ•°å…è®¸ä½¿ç”¨éå¯å¾®çš„ç¡®å®šæ€§æ±‚è§£å™¨è¿›è¡Œè®­ç»ƒã€‚

**å…³é”®è®¾è®¡**ï¼šIO-LVMçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ç¼–ç å™¨å’Œè§£ç å™¨çš„ç½‘ç»œç»“æ„é€‰æ‹©ï¼Œå¯ä»¥ä½¿ç”¨å„ç§ç¥ç»ç½‘ç»œç»“æ„ï¼Œå¦‚MLPæˆ–CNNã€‚2) éšç©ºé—´çš„ç»´åº¦å’Œåˆ†å¸ƒé€‰æ‹©ï¼Œå¯ä»¥ä½¿ç”¨é«˜æ–¯åˆ†å¸ƒæˆ–å…¶ä»–åˆé€‚çš„åˆ†å¸ƒã€‚3) ä¼˜åŒ–æ±‚è§£å™¨çš„é€‰æ‹©ï¼Œéœ€è¦æ ¹æ®å…·ä½“çš„COPé€‰æ‹©åˆé€‚çš„æ±‚è§£å™¨ã€‚4) Fenchel-YoungæŸå¤±çš„è®¡ç®—ï¼Œéœ€è¦ä¼°è®¡æ±‚è§£å™¨çš„æ¢¯åº¦ï¼Œå¯ä»¥ä½¿ç”¨å„ç§æ¢¯åº¦ä¼°è®¡æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨èˆ¹èˆ¶å’Œå‡ºç§Ÿè½¦è·¯çº¿çš„çœŸå®æ•°æ®é›†ä»¥åŠåˆæˆå›¾ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒIO-LVMèƒ½å¤Ÿæœ‰æ•ˆåœ°é‡å»ºè·¯å¾„å’Œå¾ªç¯ï¼Œé¢„æµ‹å…¶åˆ†å¸ƒï¼Œå¹¶äº§ç”Ÿå¯è§£é‡Šçš„éšç©ºé—´è¡¨ç¤ºã€‚å…·ä½“æ€§èƒ½æ•°æ®æœªçŸ¥ï¼Œä½†è®ºæ–‡å¼ºè°ƒäº†å…¶åœ¨æ•æ‰è§£çš„å¤šæ ·æ€§æ–¹é¢çš„ä¼˜åŠ¿ï¼Œä¼˜äºä¼ ç»Ÿçš„é€†ä¼˜åŒ–æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè·¯å¾„è§„åˆ’ã€ç‰©æµä¼˜åŒ–ã€äº¤é€šç®¡ç†ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºé¢„æµ‹ä¸åŒç”¨æˆ·æˆ–ä¸åŒæ¡ä»¶ä¸‹çš„æœ€ä¼˜è·¯çº¿ï¼Œä¼˜åŒ–è½¦è¾†è°ƒåº¦ï¼Œæˆ–è®¾è®¡æ›´æœ‰æ•ˆçš„äº¤é€šç½‘ç»œã€‚é€šè¿‡å­¦ä¹ æˆæœ¬å‡½æ•°çš„åˆ†å¸ƒï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£å’Œé¢„æµ‹å¤æ‚ç³»ç»Ÿçš„è¡Œä¸ºï¼Œå¹¶ä¸ºå†³ç­–æä¾›æ”¯æŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Learning representations for solutions of constrained optimization problems (COPs) with unknown cost functions is challenging, as models like (Variational) Autoencoders struggle to enforce constraints when decoding structured outputs. We propose an Inverse Optimization Latent Variable Model (IO-LVM) that learns a latent space of COP cost functions from observed solutions and reconstructs feasible outputs by solving a COP with a solver in the loop. Our approach leverages estimated gradients of a Fenchel-Young loss through a non-differentiable deterministic solver to shape the latent space. Unlike standard Inverse Optimization or Inverse Reinforcement Learning methods, which typically recover a single or context-specific cost function, IO-LVM captures a distribution over cost functions, enabling the identification of diverse solution behaviors arising from different agents or conditions not available during the training process. We validate our method on real-world datasets of ship and taxi routes, as well as paths in synthetic graphs, demonstrating its ability to reconstruct paths and cycles, predict their distributions, and yield interpretable latent representations.

