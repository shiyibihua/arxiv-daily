---
layout: default
title: MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair
---

# MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16187" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16187v1</a>
  <a href="https://arxiv.org/pdf/2509.16187.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16187v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16187v1', 'MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ali Reza Ibrahimzada, Brandon Paulsen, Reyhaneh Jabbarvand, Joey Dodds, Daniel Kroening

**åˆ†ç±»**: cs.SE, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMatchFixAgentï¼Œå®ç°è¯­è¨€æ— å…³çš„ä»“åº“çº§ä»£ç ç¿»è¯‘éªŒè¯ä¸ä¿®å¤**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»£ç ç¿»è¯‘` `ç­‰ä»·æ€§éªŒè¯` `ä»£ç ä¿®å¤` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä»£ç ç¿»è¯‘éªŒè¯ä¸ä¿®å¤æ–¹æ³•å·¥ç¨‹å¼€é”€å¤§ï¼Œä¸”ä¾èµ–ä¸è¶³çš„æµ‹è¯•é›†ï¼Œå¯¼è‡´éªŒè¯ä¸å‡†ç¡®å’Œä¿®å¤æ•ˆæœå·®ã€‚
2. MatchFixAgentåˆ©ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œå¯¹ç¿»è¯‘è¿›è¡Œè¯­ä¹‰åˆ†æï¼Œç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶è¿›è¡Œä¿®å¤ï¼Œå®ç°è¯­è¨€æ— å…³çš„éªŒè¯ä¸ä¿®å¤ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMatchFixAgentåœ¨éªŒè¯å‡†ç¡®æ€§å’Œä¿®å¤èƒ½åŠ›ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å¤šç§ç¼–ç¨‹è¯­è¨€å¯¹ä¸Šè¡¨ç°å‡ºæ›´å¼ºçš„é€‚åº”æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»£ç ç¿»è¯‘æ˜¯å°†æºä»£ç ä»ä¸€ç§ç¼–ç¨‹è¯­è¨€ï¼ˆPLï¼‰è½¬æ¢ä¸ºå¦ä¸€ç§ç¼–ç¨‹è¯­è¨€ã€‚éªŒè¯ç¿»è¯‘çš„åŠŸèƒ½ç­‰ä»·æ€§å¹¶åœ¨å¿…è¦æ—¶è¿›è¡Œä¿®å¤æ˜¯ä»£ç ç¿»è¯‘ä¸­çš„å…³é”®æ­¥éª¤ã€‚ç°æœ‰çš„è‡ªåŠ¨åŒ–éªŒè¯å’Œä¿®å¤æ–¹æ³•éš¾ä»¥æ¨å¹¿åˆ°å¤šç§ç¼–ç¨‹è¯­è¨€ï¼Œå› ä¸ºå·¥ç¨‹å¼€é”€é«˜ï¼Œå¹¶ä¸”å®ƒä»¬ä¾èµ–äºç°æœ‰ä¸”é€šå¸¸ä¸è¶³çš„æµ‹è¯•å¥—ä»¶ï¼Œè¿™å¯¼è‡´é”™è¯¯çš„ç­‰ä»·æ€§å£°æ˜å’Œæ— æ•ˆçš„ç¿»è¯‘ä¿®å¤ã€‚æˆ‘ä»¬å¼€å‘äº†MatchFixAgentï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„ã€ä¸ç¼–ç¨‹è¯­è¨€æ— å…³çš„æ¡†æ¶ï¼Œç”¨äºç¿»è¯‘çš„ç­‰ä»·æ€§éªŒè¯å’Œä¿®å¤ã€‚MatchFixAgentå…·æœ‰å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œè¯¥æ¶æ„å°†ç­‰ä»·æ€§éªŒè¯åˆ’åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œä»¥ç¡®ä¿å¯¹ç¿»è¯‘è¿›è¡Œå½»åº•å’Œä¸€è‡´çš„è¯­ä¹‰åˆ†æã€‚ç„¶åï¼Œå®ƒå°†æ­¤åˆ†æåé¦ˆç»™æµ‹è¯•æ™ºèƒ½ä½“ä»¥ç¼–å†™å’Œæ‰§è¡Œæµ‹è¯•ã€‚åœ¨è§‚å¯Ÿåˆ°æµ‹è¯•å¤±è´¥åï¼Œä¿®å¤æ™ºèƒ½ä½“ä¼šå°è¯•ä¿®å¤ç¿»è¯‘é”™è¯¯ã€‚æœ€ç»ˆçš„ï¼ˆéï¼‰ç­‰ä»·æ€§å†³ç­–ç”±è£å†³æ™ºèƒ½ä½“åšå‡ºï¼Œè¯¥æ™ºèƒ½ä½“ä¼šè€ƒè™‘è¯­ä¹‰åˆ†æå’Œæµ‹è¯•æ‰§è¡Œç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä»£ç ç¿»è¯‘çš„éªŒè¯ä¸ä¿®å¤æ˜¯ä¿è¯ç¿»è¯‘è´¨é‡çš„å…³é”®ç¯èŠ‚ã€‚ç°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºå¯¹ç‰¹å®šç¼–ç¨‹è¯­è¨€çš„ä¾èµ–æ€§å¼ºï¼Œéš¾ä»¥æ³›åŒ–åˆ°å¤šç§è¯­è¨€ï¼ŒåŒæ—¶ä¾èµ–äºè´¨é‡ä¸é«˜çš„ç°æœ‰æµ‹è¯•é›†ï¼Œå¯¼è‡´éªŒè¯ç»“æœä¸å‡†ç¡®ï¼Œä¿®å¤æ•ˆæœä¸ä½³ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§è¯­è¨€æ— å…³ä¸”èƒ½æœ‰æ•ˆç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„éªŒè¯ä¸ä¿®å¤æ–¹æ³•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMatchFixAgentçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å¼ºå¤§è¯­ä¹‰ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œæ„å»ºä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œå°†éªŒè¯ä¸ä¿®å¤ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œæ¯ä¸ªæ™ºèƒ½ä½“è´Ÿè´£ä¸åŒçš„åŠŸèƒ½ï¼ŒååŒå®Œæˆæ•´ä¸ªè¿‡ç¨‹ã€‚é€šè¿‡è¯­ä¹‰åˆ†ææŒ‡å¯¼æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆï¼Œå¹¶åˆ©ç”¨æµ‹è¯•ç»“æœé©±åŠ¨ç¿»è¯‘ä¿®å¤ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®ã€æ›´æœ‰æ•ˆçš„éªŒè¯ä¸ä¿®å¤ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMatchFixAgenté‡‡ç”¨å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š
1. **è¯­ä¹‰åˆ†ææ™ºèƒ½ä½“**ï¼šè´Ÿè´£å¯¹æºç¨‹åºå’Œç›®æ ‡ç¨‹åºè¿›è¡Œè¯­ä¹‰åˆ†æï¼Œæå–å…³é”®ä¿¡æ¯ã€‚
2. **æµ‹è¯•æ™ºèƒ½ä½“**ï¼šæ ¹æ®è¯­ä¹‰åˆ†æç»“æœï¼Œç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶æ‰§è¡Œæµ‹è¯•ã€‚
3. **ä¿®å¤æ™ºèƒ½ä½“**ï¼šåœ¨æµ‹è¯•å¤±è´¥æ—¶ï¼Œå°è¯•ä¿®å¤ç¿»è¯‘ä¸­çš„é”™è¯¯ã€‚
4. **è£å†³æ™ºèƒ½ä½“**ï¼šç»¼åˆè¯­ä¹‰åˆ†æå’Œæµ‹è¯•ç»“æœï¼Œåšå‡ºæœ€ç»ˆçš„ç­‰ä»·æ€§åˆ¤æ–­ã€‚

**å…³é”®åˆ›æ–°**ï¼šMatchFixAgentæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå…¶è¯­è¨€æ— å…³æ€§å’Œå¤šæ™ºèƒ½ä½“æ¶æ„ã€‚è¯­è¨€æ— å…³æ€§ä½¿å¾—è¯¥æ–¹æ³•å¯ä»¥åº”ç”¨äºå¤šç§ç¼–ç¨‹è¯­è¨€å¯¹çš„ç¿»è¯‘éªŒè¯ä¸ä¿®å¤ï¼Œè€Œå¤šæ™ºèƒ½ä½“æ¶æ„åˆ™å°†å¤æ‚çš„éªŒè¯ä¸ä¿®å¤ä»»åŠ¡åˆ†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œæé«˜äº†æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMatchFixAgentä¸å†ä¾èµ–äºç‰¹å®šè¯­è¨€çš„å·¥å…·å’Œç°æœ‰æµ‹è¯•é›†ï¼Œè€Œæ˜¯é€šè¿‡LLMè‡ªä¸»ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œä»è€Œé¿å…äº†å¯¹ç°æœ‰èµ„æºçš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šMatchFixAgentçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š
1. **è¯­ä¹‰åˆ†æç­–ç•¥**ï¼šå¦‚ä½•æœ‰æ•ˆåœ°åˆ©ç”¨LLMè¿›è¡Œè¯­ä¹‰åˆ†æï¼Œæå–å…³é”®ä¿¡æ¯ã€‚
2. **æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç­–ç•¥**ï¼šå¦‚ä½•æ ¹æ®è¯­ä¹‰åˆ†æç»“æœç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚
3. **ä¿®å¤ç­–ç•¥**ï¼šå¦‚ä½•åˆ©ç”¨LLMè¿›è¡Œä»£ç ä¿®å¤ï¼Œå¹¶ä¿è¯ä¿®å¤åçš„ä»£ç çš„æ­£ç¡®æ€§ã€‚
4. **æ™ºèƒ½ä½“ä¹‹é—´çš„åä½œæœºåˆ¶**ï¼šå¦‚ä½•åè°ƒå„ä¸ªæ™ºèƒ½ä½“çš„å·¥ä½œï¼Œä¿è¯æ•´ä¸ªç³»ç»Ÿçš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚å…·ä½“å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœªè¯¦ç»†è¯´æ˜ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

MatchFixAgentåœ¨2219ä¸ªç¿»è¯‘å¯¹ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¦†ç›–6ç§ç¼–ç¨‹è¯­è¨€å¯¹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMatchFixAgentå¯¹99.2%çš„ç¿»è¯‘å¯¹ç»™å‡ºäº†ï¼ˆéï¼‰ç­‰ä»·æ€§åˆ¤æ–­ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨72.8%çš„ç¿»è¯‘å¯¹ä¸Šç»“æœä¸€è‡´ã€‚åœ¨ç»“æœä¸ä¸€è‡´çš„æƒ…å†µä¸‹ï¼ŒMatchFixAgentçš„åˆ¤æ–­æ­£ç¡®ç‡é«˜è¾¾60.7%ã€‚æ­¤å¤–ï¼ŒMatchFixAgentèƒ½å¤Ÿä¿®å¤50.6%çš„ä¸ç­‰ä»·ç¿»è¯‘ï¼Œè€Œç°æœ‰æ–¹æ³•ä»…èƒ½ä¿®å¤18.5%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MatchFixAgentå¯åº”ç”¨äºå„ç§ä»£ç ç¿»è¯‘åœºæ™¯ï¼Œä¾‹å¦‚é—ç•™ç³»ç»Ÿè¿ç§»ã€è·¨å¹³å°åº”ç”¨å¼€å‘ã€ä»£ç åº“ç°ä»£åŒ–ç­‰ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜ä»£ç ç¿»è¯‘çš„è´¨é‡å’Œæ•ˆç‡ï¼Œé™ä½å¼€å‘æˆæœ¬ï¼Œå¹¶ä¿ƒè¿›ä¸åŒç¼–ç¨‹è¯­è¨€ä¹‹é—´çš„äº’æ“ä½œæ€§ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›è¿›ä¸€æ­¥å‘å±•ï¼Œå®ç°æ›´æ™ºèƒ½ã€æ›´è‡ªåŠ¨åŒ–çš„ä»£ç ç¿»è¯‘ä¸ç»´æŠ¤ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Code translation transforms source code from one programming language (PL) to another. Validating the functional equivalence of translation and repairing, if necessary, are critical steps in code translation. Existing automated validation and repair approaches struggle to generalize to many PLs due to high engineering overhead, and they rely on existing and often inadequate test suites, which results in false claims of equivalence and ineffective translation repair. We develop MatchFixAgent, a large language model (LLM)-based, PL-agnostic framework for equivalence validation and repair of translations. MatchFixAgent features a multi-agent architecture that divides equivalence validation into several sub-tasks to ensure thorough and consistent semantic analysis of the translation. Then it feeds this analysis to test agent to write and execute tests. Upon observing a test failure, the repair agent attempts to fix the translation bug. The final (in)equivalence decision is made by the verdict agent, considering semantic analyses and test execution results.
>   We compare MatchFixAgent's validation and repair results with four repository-level code translation techniques. We use 2,219 translation pairs from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub projects totaling over 900K lines of code. Our results demonstrate that MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs, with the same equivalence validation result as prior work on 72.8% of them. When MatchFixAgent's result disagrees with prior work, we find that 60.7% of the time MatchFixAgent's result is actually correct. In addition, we show that MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to many PL pairs than prior work, while producing highly accurate validation results.

