---
layout: default
title: Uncertainty Quantification of Large Language Models using Approximate Bayesian Computation
---

# Uncertainty Quantification of Large Language Models using Approximate Bayesian Computation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.19375" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.19375v1</a>
  <a href="https://arxiv.org/pdf/2509.19375.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.19375v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.19375v1', 'Uncertainty Quantification of Large Language Models using Approximate Bayesian Computation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Mridul Sharma, Adeetya Patel, Zaneta D' Souza, Samira Abbasgholizadeh Rahimi, Siva Reddy, Sreenath Madathil

**åˆ†ç±»**: cs.LG, cs.AI, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè¿‘ä¼¼è´å¶æ–¯è®¡ç®—çš„å¤§è¯­è¨€æ¨¡å‹ä¸ç¡®å®šæ€§é‡åŒ–æ–¹æ³•ï¼Œæå‡ä¸´åºŠè¯Šæ–­å¯é æ€§ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ä¸ç¡®å®šæ€§é‡åŒ–` `è¿‘ä¼¼è´å¶æ–¯è®¡ç®—` `ä¸´åºŠè¯Šæ–­` `æ¨¡å‹æ ¡å‡†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å…³é”®é¢†åŸŸéƒ¨ç½²å—é™ï¼ŒåŸå› æ˜¯å…¶ä¸ç¡®å®šæ€§è¡¨è¾¾èƒ½åŠ›å¼±ï¼Œå¯¼è‡´é¢„æµ‹ç»“æœçš„å¯é æ€§ä¸è¶³ã€‚
2. è®ºæ–‡æå‡ºè¿‘ä¼¼è´å¶æ–¯è®¡ç®—æ–¹æ³•ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹è§†ä¸ºéšæœºæ¨¡æ‹Ÿå™¨ï¼Œæ¨æ–­é¢„æµ‹æ¦‚ç‡çš„åéªŒåˆ†å¸ƒï¼Œä»è€Œé‡åŒ–ä¸ç¡®å®šæ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸´åºŠè¯Šæ–­æ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†å‡†ç¡®ç‡å’Œæ ¡å‡†åº¦ï¼Œé™ä½äº†Brieråˆ†æ•°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åº”ç”¨å¹¿æ³›ï¼Œä½†å…¶ä¸ç¡®å®šæ€§è¡¨è¾¾èƒ½åŠ›ä¸è¶³ï¼Œç»™ä¸´åºŠè¯Šæ–­ç­‰é«˜é£é™©é¢†åŸŸçš„å¯é éƒ¨ç½²å¸¦æ¥æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•å¦‚æ¨¡å‹logitså’Œæ¦‚ç‡æ¿€å‘äº§ç”Ÿè¿‡åº¦è‡ªä¿¡ä¸”æ ¡å‡†ä¸è‰¯çš„ä¼°è®¡ã€‚æœ¬æ–‡æå‡ºè¿‘ä¼¼è´å¶æ–¯è®¡ç®—ï¼ˆABCï¼‰ï¼Œä¸€ç§æ— ä¼¼ç„¶è´å¶æ–¯æ¨æ–­æ–¹æ³•ï¼Œå°†LLMè§†ä¸ºéšæœºæ¨¡æ‹Ÿå™¨ï¼Œä»¥æ¨æ–­é¢„æµ‹æ¦‚ç‡çš„åéªŒåˆ†å¸ƒã€‚åœ¨åˆæˆå£è…”ç—…å˜è¯Šæ–­æ•°æ®é›†å’ŒGretelAIç—‡çŠ¶-è¯Šæ–­å…¬å¼€æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œä¸æ ‡å‡†åŸºçº¿ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å‡†ç¡®ç‡æå‡é«˜è¾¾46.9%ï¼ŒBrieråˆ†æ•°é™ä½74.4%ï¼Œå¹¶é€šè¿‡é¢„æœŸæ ¡å‡†è¯¯å·®ï¼ˆECEï¼‰å’Œé¢„æµ‹ç†µçš„æµ‹é‡ï¼Œå¢å¼ºäº†æ ¡å‡†æ•ˆæœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠè¯Šæ–­ç­‰é«˜é£é™©é¢†åŸŸåº”ç”¨æ—¶ï¼Œéœ€è¦å‡†ç¡®é‡åŒ–é¢„æµ‹ç»“æœçš„ä¸ç¡®å®šæ€§ã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•ï¼Œå¦‚ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„logitsæˆ–æ¦‚ç‡è¾“å‡ºï¼Œå¾€å¾€äº§ç”Ÿè¿‡åº¦è‡ªä¿¡ä¸”æ ¡å‡†ä¸è‰¯çš„ä¼°è®¡ï¼Œå¯¼è‡´å†³ç­–é£é™©å¢åŠ ã€‚å› æ­¤ï¼Œå¦‚ä½•æœ‰æ•ˆé‡åŒ–LLMçš„ä¸ç¡®å®šæ€§æ˜¯äºŸå¾…è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMè§†ä¸ºä¸€ä¸ªéšæœºæ¨¡æ‹Ÿå™¨ï¼Œé€šè¿‡è§‚å¯ŸLLMçš„è¾“å‡ºç»“æœï¼Œåå‘æ¨æ–­å…¶å†…éƒ¨å‚æ•°çš„åéªŒåˆ†å¸ƒã€‚å…·ä½“è€Œè¨€ï¼Œåˆ©ç”¨è¿‘ä¼¼è´å¶æ–¯è®¡ç®—ï¼ˆABCï¼‰æ–¹æ³•ï¼Œæ— éœ€æ˜¾å¼è®¡ç®—ä¼¼ç„¶å‡½æ•°ï¼Œè€Œæ˜¯é€šè¿‡æ¯”è¾ƒæ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•°æ®çš„å·®å¼‚æ¥è¿‘ä¼¼åéªŒåˆ†å¸ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1ï¼‰å®šä¹‰å…ˆéªŒåˆ†å¸ƒï¼šä¸ºLLMçš„é¢„æµ‹æ¦‚ç‡è®¾ç½®ä¸€ä¸ªå…ˆéªŒåˆ†å¸ƒã€‚2ï¼‰æ•°æ®æ¨¡æ‹Ÿï¼šä»å…ˆéªŒåˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå¹¶ä½¿ç”¨LLMç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ã€‚3ï¼‰ç›¸ä¼¼åº¦è¯„ä¼°ï¼šæ¯”è¾ƒæ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•°æ®çš„å·®å¼‚ï¼Œè®¡ç®—ç›¸ä¼¼åº¦ã€‚4ï¼‰åéªŒæ¨æ–­ï¼šåŸºäºç›¸ä¼¼åº¦è¯„ä¼°ç»“æœï¼Œæ›´æ–°åéªŒåˆ†å¸ƒã€‚é€šè¿‡è¿­ä»£ä¸Šè¿°è¿‡ç¨‹ï¼Œé€æ­¥é€¼è¿‘çœŸå®çš„åéªŒåˆ†å¸ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†è¿‘ä¼¼è´å¶æ–¯è®¡ç®—åº”ç”¨äºLLMçš„ä¸ç¡®å®šæ€§é‡åŒ–ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼ŒABCæ— éœ€æ˜¾å¼è®¡ç®—ä¼¼ç„¶å‡½æ•°ï¼Œä»è€Œé¿å…äº†å¤æ‚çš„æ¨¡å‹å‡è®¾å’Œè®¡ç®—ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨LLMçš„ç”Ÿæˆèƒ½åŠ›ï¼Œé€šè¿‡æ¨¡æ‹Ÿæ•°æ®æ¥æ¨æ–­åéªŒåˆ†å¸ƒï¼Œä»è€Œæ›´å‡†ç¡®åœ°é‡åŒ–ä¸ç¡®å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…·ä½“å®ç°ä¸­ï¼Œè®ºæ–‡é‡‡ç”¨äº†åŸºäºè·ç¦»çš„ç›¸ä¼¼åº¦åº¦é‡æ–¹æ³•ï¼Œä¾‹å¦‚æ¬§æ°è·ç¦»æˆ–ä½™å¼¦ç›¸ä¼¼åº¦ï¼Œæ¥è¡¡é‡æ¨¡æ‹Ÿæ•°æ®å’ŒçœŸå®æ•°æ®çš„å·®å¼‚ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†ä¸åŒçš„å…ˆéªŒåˆ†å¸ƒå’Œé‡‡æ ·ç­–ç•¥ï¼Œä»¥æé«˜åéªŒæ¨æ–­çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚å¯¹äºä¸´åºŠè¯Šæ–­ä»»åŠ¡ï¼Œè®ºæ–‡ç‰¹åˆ«å…³æ³¨äº†æ¨¡å‹çš„æ ¡å‡†æ€§èƒ½ï¼Œå¹¶é‡‡ç”¨äº†é¢„æœŸæ ¡å‡†è¯¯å·®ï¼ˆECEï¼‰ç­‰æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸´åºŠè¯Šæ–­æ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ç›¸æ¯”æ ‡å‡†åŸºçº¿ï¼Œå‡†ç¡®ç‡æå‡é«˜è¾¾46.9%ï¼ŒBrieråˆ†æ•°é™ä½74.4%ï¼Œé¢„æœŸæ ¡å‡†è¯¯å·®ï¼ˆECEï¼‰æ˜¾è‘—é™ä½ï¼Œé¢„æµ‹ç†µä¹Ÿå¾—åˆ°æ”¹å–„ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°é‡åŒ–å¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶æé«˜é¢„æµ‹ç»“æœçš„å¯é æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ã€è‡ªåŠ¨é©¾é©¶ç­‰é«˜é£é™©é¢†åŸŸï¼Œæå‡å†³ç­–ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚é€šè¿‡é‡åŒ–å¤§è¯­è¨€æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œå¹¶åšå‡ºæ›´æ˜æ™ºçš„å†³ç­–ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨å¹¿åˆ°å…¶ä»–ç±»å‹çš„å¤§æ¨¡å‹å’Œæ›´å¹¿æ³›çš„åº”ç”¨åœºæ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite their widespread applications, Large Language Models (LLMs) often struggle to express uncertainty, posing a challenge for reliable deployment in high stakes and safety critical domains like clinical diagnostics. Existing standard baseline methods such as model logits and elicited probabilities produce overconfident and poorly calibrated estimates. In this work, we propose Approximate Bayesian Computation (ABC), a likelihood-free Bayesian inference, based approach that treats LLMs as a stochastic simulator to infer posterior distributions over predictive probabilities. We evaluate our ABC approach on two clinically relevant benchmarks: a synthetic oral lesion diagnosis dataset and the publicly available GretelAI symptom-to-diagnosis dataset. Compared to standard baselines, our approach improves accuracy by up to 46.9\%, reduces Brier scores by 74.4\%, and enhances calibration as measured by Expected Calibration Error (ECE) and predictive entropy.

