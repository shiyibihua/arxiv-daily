---
layout: default
title: Randomized Smoothing Meets Vision-Language Models
---

# Randomized Smoothing Meets Vision-Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.16088" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.16088v1</a>
  <a href="https://arxiv.org/pdf/2509.16088.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.16088v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.16088v1', 'Randomized Smoothing Meets Vision-Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Emmanouil Seferis, Changshun Wu, Stefanos Kollias, Saddek Bensalem, Chih-Hong Cheng

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: EMNLP'25 full version, including appendix (proofs, additional experiments)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é’ˆå¯¹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œæå‡ºåŸºäºéšæœºå¹³æ»‘çš„é²æ£’æ€§éªŒè¯æ–¹æ³•ï¼Œé˜²å¾¡å¯¹æŠ—æ”»å‡»ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšæœºå¹³æ»‘` `è§†è§‰-è¯­è¨€æ¨¡å‹` `é²æ£’æ€§éªŒè¯` `å¯¹æŠ—æ”»å‡»` `ç”Ÿæˆæ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éšæœºå¹³æ»‘æ–¹æ³•ä¸»è¦åº”ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œåœ¨è§†è§‰-è¯­è¨€ç”Ÿæˆæ¨¡å‹ä¸Šçš„åº”ç”¨é¢ä¸´è¾“å‡ºä¸ºåºåˆ—è€Œéæ ‡ç­¾çš„æŒ‘æˆ˜ã€‚
2. è®ºæ–‡å°†ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºä¸oracleåˆ†ç±»ä»»åŠ¡å…³è”ï¼Œé€šè¿‡å¯¹ç”Ÿæˆç»“æœè¿›è¡Œåˆ†ç±»ï¼Œä½¿éšæœºå¹³æ»‘æ–¹æ³•é€‚ç”¨äºè§†è§‰-è¯­è¨€æ¨¡å‹ã€‚
3. ç†è®ºåˆ†æè¡¨æ˜ï¼Œåœ¨ä¿è¯oracleåˆ†ç±»å™¨é”™è¯¯ç‡çš„å‰æä¸‹ï¼Œæ ·æœ¬æ•°é‡ä¸é²æ£’æ€§åŠå¾„å­˜åœ¨å…³è”ï¼Œå¹¶éªŒè¯äº†è¯¥æ–¹æ³•åœ¨é˜²å¾¡å¯¹æŠ—æ”»å‡»ä¸Šçš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšæœºå¹³æ»‘(RS)æ˜¯ç¡®ä¿æœºå™¨å­¦ä¹ æ¨¡å‹æ­£ç¡®æ€§çš„é‡è¦æŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒå¯ä»¥è§£æåœ°æ¨å¯¼å‡ºé€ç‚¹é²æ£’æ€§è¯ä¹¦ã€‚è™½ç„¶RSåœ¨åˆ†ç±»é—®é¢˜ä¸­å¾—åˆ°äº†å¾ˆå¥½çš„ç†è§£ï¼Œä½†å®ƒåœ¨ç”Ÿæˆæ¨¡å‹ä¸­çš„åº”ç”¨å°šä¸æ˜ç¡®ï¼Œå› ä¸ºå®ƒä»¬çš„è¾“å‡ºæ˜¯åºåˆ—è€Œä¸æ˜¯æ ‡ç­¾ã€‚æœ¬æ–‡é€šè¿‡å°†ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºä¸ä¸€ä¸ªoracleåˆ†ç±»ä»»åŠ¡è”ç³»èµ·æ¥ï¼Œè§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå¹¶è¡¨æ˜RSä»ç„¶å¯ä»¥å¯ç”¨ï¼šæœ€ç»ˆå“åº”å¯ä»¥è¢«åˆ†ç±»ä¸ºç¦»æ•£åŠ¨ä½œï¼ˆä¾‹å¦‚ï¼ŒVLAä¸­çš„æœåŠ¡æœºå™¨äººå‘½ä»¤ï¼‰ï¼Œæœ‰å®³ä¸æ— å®³ï¼ˆVLMä¸­çš„å†…å®¹å®¡æ ¸æˆ–æ¯’æ€§æ£€æµ‹ï¼‰ï¼Œç”šè‡³å¯ä»¥å°†oracleåº”ç”¨äºå°†ç­”æ¡ˆèšç±»æˆè¯­ä¹‰ç­‰ä»·çš„ç­”æ¡ˆã€‚åœ¨oracleåˆ†ç±»å™¨æ¯”è¾ƒçš„é”™è¯¯ç‡æœ‰ç•Œçš„å‰æä¸‹ï¼Œæˆ‘ä»¬å¼€å‘äº†å°†æ ·æœ¬æ•°é‡ä¸ç›¸åº”é²æ£’æ€§åŠå¾„ç›¸å…³è”çš„ç†è®ºã€‚æˆ‘ä»¬è¿›ä¸€æ­¥æ¨å¯¼å‡ºäº†æ”¹è¿›çš„ç¼©æ”¾å®šå¾‹ï¼Œä»åˆ†æä¸Šå°†è®¤è¯åŠå¾„å’Œå‡†ç¡®æ€§ä¸æ ·æœ¬æ•°é‡è”ç³»èµ·æ¥ï¼Œè¡¨æ˜å³ä½¿åœ¨è¾ƒå¼±çš„å‡è®¾ä¸‹ï¼Œæ ·æœ¬æ•°é‡å‡å°‘2åˆ°3ä¸ªæ•°é‡çº§ä¸”æŸå¤±æœ€å°çš„æ—©æœŸç»“æœä»ç„¶æœ‰æ•ˆã€‚æ€»ä¹‹ï¼Œè¿™äº›è¿›å±•ä½¿å¾—æœ€å…ˆè¿›çš„VLMçš„é²æ£’æ€§è®¤è¯æ—¢æ˜ç¡®åˆåœ¨è®¡ç®—ä¸Šå¯è¡Œï¼Œè¿™å·²é€šè¿‡æœ€è¿‘çš„è¶Šç‹±å¼å¯¹æŠ—æ”»å‡»å¾—åˆ°äº†éªŒè¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„éšæœºå¹³æ»‘æ–¹æ³•ä¸»è¦åº”ç”¨äºåˆ†ç±»ä»»åŠ¡ï¼Œå¯¹äºè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰è¿™ç±»ç”Ÿæˆæ¨¡å‹ï¼Œç”±äºå…¶è¾“å‡ºæ˜¯åºåˆ—è€Œéç¦»æ•£æ ‡ç­¾ï¼Œå› æ­¤æ— æ³•ç›´æ¥åº”ç”¨ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹VLMsçš„å¯¹æŠ—æ”»å‡»ï¼ˆä¾‹å¦‚â€œè¶Šç‹±â€æ”»å‡»ï¼‰æ—¥ç›Šå¢å¤šï¼Œå¦‚ä½•ä¿è¯VLMsçš„é²æ£’æ€§æˆä¸ºä¸€ä¸ªé‡è¦é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºè½¬åŒ–ä¸ºä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œä»è€Œå°†éšæœºå¹³æ»‘æ–¹æ³•åº”ç”¨äºVLMsã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¼•å…¥ä¸€ä¸ªoracleåˆ†ç±»å™¨ï¼Œå°†ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºè¿›è¡Œåˆ†ç±»ï¼Œä¾‹å¦‚åˆ¤æ–­è¾“å‡ºæ˜¯å¦â€œæœ‰å®³â€ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥åˆ©ç”¨éšæœºå¹³æ»‘æ–¹æ³•æ¥ä¿è¯åˆ†ç±»ç»“æœçš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) å¯¹è¾“å…¥è¿›è¡Œéšæœºæ‰°åŠ¨ï¼›2) ä½¿ç”¨VLMç”Ÿæˆè¾“å‡ºï¼›3) ä½¿ç”¨oracleåˆ†ç±»å™¨å¯¹è¾“å‡ºè¿›è¡Œåˆ†ç±»ï¼›4) åŸºäºéšæœºå¹³æ»‘ç†è®ºï¼Œè®¡ç®—é²æ£’æ€§åŠå¾„ã€‚å…³é”®æ¨¡å—åŒ…æ‹¬VLMæ¨¡å‹ã€oracleåˆ†ç±»å™¨å’Œé²æ£’æ€§åŠå¾„è®¡ç®—æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†éšæœºå¹³æ»‘æ–¹æ³•æ‰©å±•åˆ°ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶æå‡ºäº†åŸºäºoracleåˆ†ç±»å™¨çš„é²æ£’æ€§éªŒè¯æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„éšæœºå¹³æ»‘æ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸éœ€è¦ç›´æ¥å¯¹ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºè¿›è¡Œåˆ†ç±»ï¼Œè€Œæ˜¯é€šè¿‡oracleåˆ†ç±»å™¨å°†ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºè½¬åŒ–ä¸ºä¸€ä¸ªåˆ†ç±»é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) oracleåˆ†ç±»å™¨çš„é€‰æ‹©ï¼šoracleåˆ†ç±»å™¨éœ€è¦èƒ½å¤Ÿå‡†ç¡®åœ°åˆ¤æ–­ç”Ÿæˆæ¨¡å‹çš„è¾“å‡ºæ˜¯å¦æ»¡è¶³æŸç§æ¡ä»¶ï¼ˆä¾‹å¦‚ï¼Œæ˜¯å¦â€œæœ‰å®³â€ï¼‰ï¼›2) éšæœºæ‰°åŠ¨çš„é€‰æ‹©ï¼šéšæœºæ‰°åŠ¨çš„é€‰æ‹©éœ€è¦ä¿è¯åœ¨æ‰°åŠ¨åçš„è¾“å…¥ä»ç„¶èƒ½å¤Ÿè¢«VLMæ¨¡å‹å¤„ç†ï¼›3) é²æ£’æ€§åŠå¾„çš„è®¡ç®—ï¼šè®ºæ–‡æ¨å¯¼äº†é²æ£’æ€§åŠå¾„ä¸æ ·æœ¬æ•°é‡ä¹‹é—´çš„å…³ç³»ï¼Œå¹¶æå‡ºäº†æ”¹è¿›çš„ç¼©æ”¾å®šå¾‹ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°é˜²å¾¡é’ˆå¯¹è§†è§‰-è¯­è¨€æ¨¡å‹çš„å¯¹æŠ—æ”»å‡»ï¼Œå¹¶ä¸”åœ¨ä¿è¯ä¸€å®šå‡†ç¡®ç‡çš„å‰æä¸‹ï¼Œæ‰€éœ€çš„æ ·æœ¬æ•°é‡æ¯”ä¼ ç»Ÿæ–¹æ³•å‡å°‘2åˆ°3ä¸ªæ•°é‡çº§ã€‚è¿™ä½¿å¾—å¯¹å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œé²æ£’æ€§éªŒè¯æˆä¸ºå¯èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§åœºæ™¯ï¼Œä¾‹å¦‚ï¼š1) æå‡è§†è§‰-è¯­è¨€æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œé˜²å¾¡å¯¹æŠ—æ”»å‡»ï¼›2) å†…å®¹å®¡æ ¸ï¼Œè‡ªåŠ¨æ£€æµ‹æœ‰å®³æˆ–ä¸å½“å†…å®¹ï¼›3) æœåŠ¡æœºå™¨äººï¼Œç¡®ä¿æœºå™¨äººæ‰§è¡Œå®‰å…¨å¯é çš„æŒ‡ä»¤ã€‚è¯¥æ–¹æ³•æœ‰åŠ©äºæé«˜äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¯é æ€§å’Œå®‰å…¨æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Randomized smoothing (RS) is one of the prominent techniques to ensure the correctness of machine learning models, where point-wise robustness certificates can be derived analytically. While RS is well understood for classification, its application to generative models is unclear, since their outputs are sequences rather than labels. We resolve this by connecting generative outputs to an oracle classification task and showing that RS can still be enabled: the final response can be classified as a discrete action (e.g., service-robot commands in VLAs), as harmful vs. harmless (content moderation or toxicity detection in VLMs), or even applying oracles to cluster answers into semantically equivalent ones. Provided that the error rate for the oracle classifier comparison is bounded, we develop the theory that associates the number of samples with the corresponding robustness radius. We further derive improved scaling laws analytically relating the certified radius and accuracy to the number of samples, showing that the earlier result of 2 to 3 orders of magnitude fewer samples sufficing with minimal loss remains valid even under weaker assumptions. Together, these advances make robustness certification both well-defined and computationally feasible for state-of-the-art VLMs, as validated against recent jailbreak-style adversarial attacks.

