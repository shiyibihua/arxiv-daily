---
layout: default
title: Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data
---

# Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15859v1</a>
  <a href="https://arxiv.org/pdf/2509.15859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15859v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15859v1', 'Efficient Long-Tail Learning in Latent Space by sampling Synthetic Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nakul Sharma

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-19

**å¤‡æ³¨**: Accepted to Curated Data for Efficient Learning Workshop at ICCV 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºåˆæˆæ•°æ®é‡‡æ ·çš„æ½œåœ¨ç©ºé—´é•¿å°¾å­¦ä¹ æ–¹æ³•ï¼Œæå‡è®¡ç®—æ•ˆç‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `é•¿å°¾å­¦ä¹ ` `åˆæˆæ•°æ®` `è§†è§‰åŸºç¡€æ¨¡å‹` `æ½œåœ¨ç©ºé—´` `çº¿æ€§åˆ†ç±»å™¨` `æ•°æ®å¢å¼º` `ä¸å¹³è¡¡åˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. é•¿å°¾åˆ†å¸ƒæ•°æ®é›†å¯¼è‡´æ¨¡å‹åœ¨å°‘æ•°ç±»ä¸Šè¡¨ç°å·®ï¼Œç°æœ‰å¾®è°ƒæ–¹æ³•è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€‚
2. åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¹¶ç»“åˆçœŸå®æ•°æ®è®­ç»ƒçº¿æ€§åˆ†ç±»å™¨ã€‚
3. åœ¨CIFAR-100-LTä¸Šè¾¾åˆ°SOTAï¼Œå¹¶åœ¨Places-LTä¸Šè¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸å¹³è¡¡åˆ†ç±»æ•°æ®é›†ç»™æœºå™¨å­¦ä¹ å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œé€šå¸¸å¯¼è‡´æ¨¡å‹å¯¹ä»£è¡¨æ€§ä¸è¶³çš„ç±»åˆ«è¡¨ç°ä¸ä½³ã€‚éšç€åŸºç¡€æ¨¡å‹çš„å…´èµ·ï¼Œæœ€è¿‘çš„ç ”ç©¶é›†ä¸­äºå¯¹è¿™äº›æ¨¡å‹è¿›è¡Œå®Œæ•´ã€éƒ¨åˆ†å’Œå‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼Œä»¥å¤„ç†é•¿å°¾åˆ†ç±»ã€‚å°½ç®¡è¿™äº›å·¥ä½œåœ¨åŸºå‡†æ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬ä»ç„¶æœªèƒ½ç¼©å°ä¸ä½¿ç”¨å¹³è¡¡æ•°æ®é›†è®­ç»ƒçš„ç½‘ç»œä¹‹é—´çš„å·®è·ï¼Œå¹¶ä¸”å³ä½¿å¯¹äºç›¸å¯¹è¾ƒå°çš„æ•°æ®é›†ï¼Œä»ç„¶éœ€è¦å¤§é‡çš„è®¡ç®—èµ„æºã€‚ä¸ºäº†å¼ºè°ƒè®¡ç®—æ•ˆç‡å’Œç®€å•æ€§çš„é‡è¦æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ä¸°å¯Œçš„è¯­ä¹‰æ½œåœ¨ç©ºé—´æ¥ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¹¶ä½¿ç”¨çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®çš„æ··åˆæ¥è®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨ï¼Œç”¨äºé•¿å°¾åˆ†ç±»ã€‚è®¡ç®—æ•ˆç‡çš„æé«˜æ¥è‡ªäºå¯è®­ç»ƒå‚æ•°çš„æ•°é‡å‡å°‘åˆ°çº¿æ€§æ¨¡å‹ä¸­çš„å‚æ•°æ•°é‡ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºCIFAR-100-LTåŸºå‡†è®¾å®šäº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œå¹¶åœ¨Places-LTåŸºå‡†ä¸Šè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼Œçªå‡ºäº†æˆ‘ä»¬ç®€å•æœ‰æ•ˆæ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé€‚åº”æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³é•¿å°¾åˆ†ç±»é—®é¢˜ï¼Œå³æ•°æ®é›†ä¸­ä¸åŒç±»åˆ«çš„æ ·æœ¬æ•°é‡æä¸å¹³è¡¡ï¼Œå¯¼è‡´æ¨¡å‹åœ¨æ ·æœ¬å°‘çš„ç±»åˆ«ä¸Šè¡¨ç°ä¸ä½³ã€‚ç°æœ‰æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäºå¾®è°ƒå¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼Œè™½ç„¶æœ‰æ•ˆï¼Œä½†è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­ä½¿ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹ï¼ˆVision Foundation Modelsï¼‰çš„æ½œåœ¨ç©ºé—´ï¼Œé€šè¿‡é‡‡æ ·ç”Ÿæˆåˆæˆæ•°æ®ï¼Œæ‰©å……å°‘æ•°ç±»åˆ«çš„æ ·æœ¬æ•°é‡ã€‚ç„¶åï¼Œä½¿ç”¨çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®çš„æ··åˆæ¥è®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹æ•´ä¸ªå¤§å‹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) åˆ©ç”¨é¢„è®­ç»ƒçš„è§†è§‰åŸºç¡€æ¨¡å‹æå–å›¾åƒçš„ç‰¹å¾ï¼Œå°†å›¾åƒæ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ä¸­ã€‚2) åœ¨æ½œåœ¨ç©ºé—´ä¸­ï¼Œå¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œé‡‡æ ·ï¼Œç”Ÿæˆåˆæˆæ•°æ®ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹æ ·æœ¬æ•°é‡è¾ƒå°‘çš„ç±»åˆ«ã€‚3) å°†çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®æ··åˆï¼Œä½œä¸ºè®­ç»ƒæ•°æ®ã€‚4) è®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§åˆ†ç±»å™¨ï¼Œå¯¹æ··åˆæ•°æ®è¿›è¡Œåˆ†ç±»ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨è§†è§‰åŸºç¡€æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¹¶ç»“åˆçº¿æ€§åˆ†ç±»å™¨è¿›è¡Œé•¿å°¾å­¦ä¹ ã€‚ä¸ç›´æ¥å¾®è°ƒå¤§å‹æ¨¡å‹ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å¤§å¤§é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶ä¿æŒäº†è‰¯å¥½çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­é‡‡æ ·ï¼Œèƒ½å¤Ÿç”Ÿæˆå…·æœ‰è¯­ä¹‰ä¸€è‡´æ€§çš„åˆæˆæ•°æ®ï¼Œä»è€Œæœ‰æ•ˆåœ°æ‰©å……äº†å°‘æ•°ç±»åˆ«çš„æ ·æœ¬ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å¦‚ä½•åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡Œé‡‡æ ·ï¼Œä»¥ç”Ÿæˆé«˜è´¨é‡çš„åˆæˆæ•°æ®ã€‚å…·ä½“çš„é‡‡æ ·ç­–ç•¥å¯èƒ½åŒ…æ‹¬é«˜æ–¯æ··åˆæ¨¡å‹æˆ–å…¶ä»–ç”Ÿæˆæ¨¡å‹ã€‚2) å¦‚ä½•å¹³è¡¡çœŸå®æ•°æ®å’Œåˆæˆæ•°æ®ä¹‹é—´çš„æ¯”ä¾‹ï¼Œä»¥é¿å…åˆæˆæ•°æ®å¯¹æ¨¡å‹äº§ç”Ÿè´Ÿé¢å½±å“ã€‚3) çº¿æ€§åˆ†ç±»å™¨çš„é€‰æ‹©å’Œè®­ç»ƒæ–¹å¼ï¼Œä¾‹å¦‚ä½¿ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°å’ŒAdamä¼˜åŒ–å™¨ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨CIFAR-100-LTåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†state-of-the-artçš„ç»“æœï¼Œè¡¨æ˜å…¶åœ¨é•¿å°¾åˆ†ç±»ä»»åŠ¡ä¸Šçš„æœ‰æ•ˆæ€§ã€‚åŒæ—¶ï¼Œåœ¨Places-LTæ•°æ®é›†ä¸Šä¹Ÿè¡¨ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æ³›åŒ–èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä½¿å¾—åœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­è¿›è¡Œé•¿å°¾å­¦ä¹ æˆä¸ºå¯èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸä¸­å­˜åœ¨é•¿å°¾åˆ†å¸ƒçš„æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼Œåœ¨åŒ»ç–—è¯Šæ–­ä¸­ï¼Œç½•è§ç–¾ç—…çš„ç—…ä¾‹æ•°æ®é€šå¸¸è¾ƒå°‘ï¼Œå¯ä»¥ä½¿ç”¨è¯¥æ–¹æ³•ç”Ÿæˆåˆæˆæ•°æ®æ¥æé«˜è¯Šæ–­æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥åº”ç”¨äºè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§ç­‰é¢†åŸŸï¼Œæé«˜æ¨¡å‹å¯¹ç½•è§äº‹ä»¶çš„è¯†åˆ«èƒ½åŠ›ã€‚è¯¥æ–¹æ³•å…·æœ‰è®¡ç®—æ•ˆç‡é«˜ã€æ˜“äºéƒ¨ç½²ç­‰ä¼˜ç‚¹ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Imbalanced classification datasets pose significant challenges in machine learning, often leading to biased models that perform poorly on underrepresented classes. With the rise of foundation models, recent research has focused on the full, partial, and parameter-efficient fine-tuning of these models to deal with long-tail classification. Despite the impressive performance of these works on the benchmark datasets, they still fail to close the gap with the networks trained using the balanced datasets and still require substantial computational resources, even for relatively smaller datasets. Underscoring the importance of computational efficiency and simplicity, in this work we propose a novel framework that leverages the rich semantic latent space of Vision Foundation Models to generate synthetic data and train a simple linear classifier using a mixture of real and synthetic data for long-tail classification. The computational efficiency gain arises from the number of trainable parameters that are reduced to just the number of parameters in the linear model. Our method sets a new state-of-the-art for the CIFAR-100-LT benchmark and demonstrates strong performance on the Places-LT benchmark, highlighting the effectiveness and adaptability of our simple and effective approach.

