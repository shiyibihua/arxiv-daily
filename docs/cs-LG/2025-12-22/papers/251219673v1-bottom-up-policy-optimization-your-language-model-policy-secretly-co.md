---
layout: default
title: Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies
---

# Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.19673" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.19673v1</a>
  <a href="https://arxiv.org/pdf/2512.19673.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.19673v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.19673v1', 'Bottom-up Policy Optimization: Your Language Model Policy Secretly Contains Internal Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuqiao Tan, Minzheng Wang, Shizhu He, Huanxuan Liao, Chengfeng Zhao, Qiunan Lu, Tian Liang, Jun Zhao, Kang Liu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

**å¤‡æ³¨**: Preprint. Our code is available at https://github.com/Trae1ounG/BuPO

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Trae1ounG/BuPO)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªåº•å‘ä¸Šç­–ç•¥ä¼˜åŒ–(BuPO)ï¼Œé€šè¿‡ä¼˜åŒ–LLMå†…éƒ¨ç­–ç•¥æå‡å¤æ‚æ¨ç†èƒ½åŠ›ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ ` `ç­–ç•¥ä¼˜åŒ–` `å†…éƒ¨ç­–ç•¥` `å¤æ‚æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¿½ç•¥äº†LLMå†…éƒ¨çš„å±‚çº§ç»“æ„å’Œæ¨¡å—åŒ–è®¾è®¡ï¼Œå°†å…¶è§†ä¸ºå•ä¸€ç­–ç•¥ï¼Œé™åˆ¶äº†ä¼˜åŒ–æ½œåŠ›ã€‚
2. è®ºæ–‡æå‡ºè‡ªåº•å‘ä¸Šç­–ç•¥ä¼˜åŒ–ï¼ˆBuPOï¼‰ï¼Œé€šè¿‡åˆ†è§£LLMç­–ç•¥ï¼Œä¼˜åŒ–å†…éƒ¨å±‚ç­–ç•¥ï¼Œä»è€Œæå‡æ•´ä½“æ€§èƒ½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBuPOé€šè¿‡åœ¨åº•å±‚å¯¹é½è®­ç»ƒç›®æ ‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆé‡å»ºåŸºç¡€æ¨ç†èƒ½åŠ›ï¼Œå¹¶åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è§†ä¸ºä¸€ä¸ªå•ä¸€çš„ç»Ÿä¸€ç­–ç•¥ï¼Œå¿½ç•¥äº†å…¶å†…éƒ¨æœºåˆ¶ã€‚ç†è§£ç­–ç•¥å¦‚ä½•åœ¨å±‚å’Œæ¨¡å—ä¹‹é—´æ¼”å˜å¯¹äºå®ç°æ›´æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–å’Œæ­ç¤ºå¤æ‚çš„æ¨ç†æœºåˆ¶è‡³å…³é‡è¦ã€‚æœ¬æ–‡é€šè¿‡åˆ©ç”¨Transformeræ®‹å·®æµçš„å†…åœ¨åˆ†å‰²ä»¥åŠéšè—çŠ¶æ€ä¸unembeddingçŸ©é˜µçš„ç»„åˆä¸å¯é‡‡æ ·ç­–ç•¥ä¹‹é—´çš„ç­‰ä»·æ€§æ¥åˆ†è§£è¯­è¨€æ¨¡å‹ç­–ç•¥ã€‚è¿™ç§åˆ†è§£æ­ç¤ºäº†å†…éƒ¨å±‚ç­–ç•¥ï¼ˆå¯¹åº”äºæ¥è‡ªå„ä¸ªå±‚çš„è´¡çŒ®ï¼‰å’Œå†…éƒ¨æ¨¡å—ç­–ç•¥ï¼ˆä¸æ¯å±‚å†…çš„è‡ªæ³¨æ„åŠ›å’Œå‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰ç»„ä»¶å¯¹é½ï¼‰ã€‚é€šè¿‡åˆ†æå†…éƒ¨ç­–ç•¥çš„ç†µï¼Œæˆ‘ä»¬å‘ç°ï¼šï¼ˆaï¼‰æ—©æœŸå±‚ä¿æŒé«˜ç†µä»¥è¿›è¡Œæ¢ç´¢ï¼Œé¡¶å±‚æ”¶æ•›åˆ°æ¥è¿‘é›¶ç†µä»¥è¿›è¡Œç»†åŒ–ï¼Œå¹¶ä¸”æ”¶æ•›æ¨¡å¼åœ¨æ¨¡å‹ç³»åˆ—ä¹‹é—´æœ‰æ‰€ä¸åŒã€‚ï¼ˆbï¼‰LLamaçš„é¢„æµ‹ç©ºé—´åœ¨æœ€åä¸€å±‚è¿…é€Ÿæ”¶æ•›ï¼Œè€ŒQwenç³»åˆ—æ¨¡å‹ï¼Œå°¤å…¶æ˜¯Qwen3ï¼Œè¡¨ç°å‡ºæ›´åƒäººç±»çš„ã€é€æ­¥ç»“æ„åŒ–çš„æ¨ç†æ¨¡å¼ã€‚å—è¿™äº›å‘ç°çš„å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„å¼ºåŒ–å­¦ä¹ èŒƒä¾‹â€”â€”è‡ªåº•å‘ä¸Šç­–ç•¥ä¼˜åŒ–ï¼ˆBuPOï¼‰ï¼Œè¯¥èŒƒä¾‹ç›´æ¥ä¼˜åŒ–æ—©æœŸè®­ç»ƒæœŸé—´çš„å†…éƒ¨å±‚ç­–ç•¥ã€‚é€šè¿‡åœ¨è¾ƒä½å±‚å¯¹é½è®­ç»ƒç›®æ ‡ï¼ŒBuPOé‡å»ºäº†åŸºç¡€æ¨ç†èƒ½åŠ›å¹¶å®ç°äº†å“è¶Šçš„æ€§èƒ½ã€‚åœ¨å¤æ‚æ¨ç†åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å°†LLMè§†ä¸ºä¸€ä¸ªé»‘ç›’ï¼Œå¿½ç•¥äº†å…¶å†…éƒ¨ç»“æ„ï¼Œæ— æ³•é’ˆå¯¹æ€§åœ°ä¼˜åŒ–ä¸åŒå±‚å’Œæ¨¡å—çš„åŠŸèƒ½ã€‚è¿™ç§æ–¹æ³•æ— æ³•å……åˆ†åˆ©ç”¨LLMçš„æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­ã€‚ç°æœ‰æ–¹æ³•ç¼ºä¹å¯¹LLMå†…éƒ¨ç­–ç•¥æ¼”åŒ–è¿‡ç¨‹çš„ç†è§£ï¼Œéš¾ä»¥æ­ç¤ºå…¶æ¨ç†æœºåˆ¶ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMçš„ç­–ç•¥åˆ†è§£ä¸ºå†…éƒ¨å±‚ç­–ç•¥å’Œå†…éƒ¨æ¨¡å—ç­–ç•¥ï¼Œåˆ†åˆ«å¯¹åº”äºTransformerçš„æ¯ä¸€å±‚ä»¥åŠæ¯ä¸€å±‚ä¸­çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å’Œå‰é¦ˆç½‘ç»œã€‚é€šè¿‡åˆ†æè¿™äº›å†…éƒ¨ç­–ç•¥çš„ç†µï¼Œå¯ä»¥äº†è§£LLMåœ¨ä¸åŒå±‚å’Œæ¨¡å—ä¸Šçš„è¡Œä¸ºæ¨¡å¼ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºè‡ªåº•å‘ä¸Šç­–ç•¥ä¼˜åŒ–ï¼ˆBuPOï¼‰ï¼Œé€šè¿‡åœ¨æ—©æœŸè®­ç»ƒé˜¶æ®µç›´æ¥ä¼˜åŒ–åº•å±‚ç­–ç•¥ï¼Œä»è€Œå¼•å¯¼LLMå­¦ä¹ æ›´æœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBuPOçš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1) **ç­–ç•¥åˆ†è§£**ï¼šåˆ©ç”¨Transformerçš„æ®‹å·®è¿æ¥å’ŒunembeddingçŸ©é˜µï¼Œå°†LLMçš„æ•´ä½“ç­–ç•¥åˆ†è§£ä¸ºå†…éƒ¨å±‚ç­–ç•¥å’Œå†…éƒ¨æ¨¡å—ç­–ç•¥ã€‚2) **ç†µåˆ†æ**ï¼šåˆ†æä¸åŒå±‚å’Œæ¨¡å—çš„ç­–ç•¥ç†µï¼Œäº†è§£LLMåœ¨ä¸åŒé˜¶æ®µçš„è¡Œä¸ºæ¨¡å¼ã€‚3) **è‡ªåº•å‘ä¸Šä¼˜åŒ–**ï¼šåœ¨æ—©æœŸè®­ç»ƒé˜¶æ®µï¼Œç›´æ¥ä¼˜åŒ–åº•å±‚ç­–ç•¥ï¼Œä½¿å…¶æ›´å¥½åœ°å¯¹é½è®­ç»ƒç›®æ ‡ã€‚4) **æ•´ä½“ç­–ç•¥ä¼˜åŒ–**ï¼šåœ¨åº•å±‚ç­–ç•¥ä¼˜åŒ–å®Œæˆåï¼Œå†è¿›è¡Œæ•´ä½“ç­–ç•¥çš„ä¼˜åŒ–ï¼Œä»è€Œæå‡LLMçš„æ•´ä½“æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šBuPOçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) **ç­–ç•¥åˆ†è§£**ï¼šé¦–æ¬¡å°†LLMçš„ç­–ç•¥åˆ†è§£ä¸ºå†…éƒ¨å±‚ç­–ç•¥å’Œå†…éƒ¨æ¨¡å—ç­–ç•¥ï¼Œä¸ºç†è§£LLMçš„å†…éƒ¨æœºåˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚2) **è‡ªåº•å‘ä¸Šä¼˜åŒ–**ï¼šæå‡ºäº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ èŒƒå¼ï¼Œé€šè¿‡åœ¨æ—©æœŸè®­ç»ƒé˜¶æ®µä¼˜åŒ–åº•å±‚ç­–ç•¥ï¼Œä»è€Œå¼•å¯¼LLMå­¦ä¹ æ›´æœ‰æ•ˆçš„æ¨ç†èƒ½åŠ›ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒBuPOèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨LLMçš„å†…éƒ¨ç»“æ„ï¼Œä»è€Œæå‡å…¶æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šBuPOçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **æ®‹å·®è¿æ¥å’ŒunembeddingçŸ©é˜µçš„ä½¿ç”¨**ï¼šåˆ©ç”¨Transformerçš„æ®‹å·®è¿æ¥å’ŒunembeddingçŸ©é˜µï¼Œå®ç°äº†LLMç­–ç•¥çš„åˆ†è§£ã€‚2) **ç†µçš„è®¡ç®—**ï¼šé€šè¿‡è®¡ç®—ä¸åŒå±‚å’Œæ¨¡å—çš„ç­–ç•¥ç†µï¼Œäº†è§£LLMåœ¨ä¸åŒé˜¶æ®µçš„è¡Œä¸ºæ¨¡å¼ã€‚3) **åº•å±‚ç­–ç•¥çš„ä¼˜åŒ–ç›®æ ‡**ï¼šåœ¨åº•å±‚ç­–ç•¥çš„ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œéœ€è¦è®¾è®¡åˆé€‚çš„ä¼˜åŒ–ç›®æ ‡ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°å¯¹é½æ•´ä½“è®­ç»ƒç›®æ ‡ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–ç®—æ³•çš„é€‰æ‹©éœ€è¦æ ¹æ®å…·ä½“çš„ä»»åŠ¡è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19673v1/x2.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19673v1/x3.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.19673v1/x4.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBuPOåœ¨å¤æ‚æ¨ç†åŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨æŸäº›ä»»åŠ¡ä¸Šï¼ŒBuPOçš„æ€§èƒ½è¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚é€šè¿‡åˆ†æå†…éƒ¨ç­–ç•¥çš„ç†µï¼Œè®ºæ–‡è¿˜å‘ç°ä¸åŒLLMçš„æ¨ç†æ¨¡å¼å­˜åœ¨å·®å¼‚ï¼Œä¾‹å¦‚LLamaåœ¨æœ€åä¸€å±‚è¿…é€Ÿæ”¶æ•›ï¼Œè€ŒQwenç³»åˆ—æ¨¡å‹åˆ™è¡¨ç°å‡ºæ›´åƒäººç±»çš„é€æ­¥ç»“æ„åŒ–æ¨ç†æ¨¡å¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤æ‚æ¨ç†èƒ½åŠ›çš„åœºæ™¯ï¼Œä¾‹å¦‚é—®ç­”ç³»ç»Ÿã€å¯¹è¯ç”Ÿæˆã€ä»£ç ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–LLMçš„å†…éƒ¨ç­–ç•¥ï¼Œå¯ä»¥æå‡å…¶æ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°è§£å†³å®é™…é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°ç†è§£LLMçš„å†…éƒ¨æœºåˆ¶ï¼Œä¸ºæœªæ¥çš„æ¨¡å‹è®¾è®¡å’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing reinforcement learning (RL) approaches treat large language models (LLMs) as a single unified policy, overlooking their internal mechanisms. Understanding how policy evolves across layers and modules is therefore crucial for enabling more targeted optimization and raveling out complex reasoning mechanisms. In this paper, we decompose the language model policy by leveraging the intrinsic split of the Transformer residual stream and the equivalence between the composition of hidden states with the unembedding matrix and the resulting samplable policy. This decomposition reveals Internal Layer Policies, corresponding to contributions from individual layers, and Internal Modular Policies, which align with the self-attention and feed-forward network (FFN) components within each layer. By analyzing the entropy of internal policy, we find that: (a) Early layers keep high entropy for exploration, top layers converge to near-zero entropy for refinement, with convergence patterns varying across model series. (b) LLama's prediction space rapidly converges in the final layer, whereas Qwen-series models, especially Qwen3, exhibit a more human-like, progressively structured reasoning pattern. Motivated by these findings, we propose Bottom-up Policy Optimization (BuPO), a novel RL paradigm that directly optimizes the internal layer policy during early training. By aligning training objective at lower layer, BuPO reconstructs foundational reasoning capabilities and achieves superior performance. Extensive experiments on complex reasoning benchmarks demonstrates the effectiveness of our method. Our code is available at https://github.com/Trae1ounG/BuPO.

