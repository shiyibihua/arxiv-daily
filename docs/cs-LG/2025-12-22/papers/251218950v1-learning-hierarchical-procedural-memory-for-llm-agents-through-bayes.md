---
layout: default
title: Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement
---

# Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.18950" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.18950v1</a>
  <a href="https://arxiv.org/pdf/2512.18950.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.18950v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.18950v1', 'Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-22

**å¤‡æ³¨**: Accepted at The 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). 21 pages including references, with 7 figures and 8 tables. Code is publicly available at the authors GitHub repository: https://github.com/S-Forouzandeh/MACLA-LLM-Agents-AAMAS-Conference

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MACLAï¼šé€šè¿‡è´å¶æ–¯é€‰æ‹©å’Œå¯¹æ¯”ç²¾ç‚¼å­¦ä¹ LLM Agentçš„åˆ†å±‚ç¨‹åºè®°å¿†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `LLM Agent` `ç¨‹åºè®°å¿†` `è´å¶æ–¯é€‰æ‹©` `å¯¹æ¯”å­¦ä¹ ` `åˆ†å±‚è®°å¿†` `çŸ¥è¯†å¤ç”¨` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰LLM Agentåœ¨å¤æ‚ä»»åŠ¡ä¸­é¢ä¸´æ ·æœ¬æ•ˆç‡ä½å’Œæ³›åŒ–èƒ½åŠ›å¼±çš„æŒ‘æˆ˜ï¼Œéœ€è¦å¤§é‡è®­ç»ƒæ•°æ®å’Œå‚æ•°è°ƒæ•´ã€‚
2. MACLAé€šè¿‡ç»´æŠ¤å†»ç»“çš„LLMå’Œå¤–éƒ¨åˆ†å±‚ç¨‹åºè®°å¿†ï¼Œè§£è€¦æ¨ç†å’Œå­¦ä¹ è¿‡ç¨‹ï¼Œå®ç°é«˜æ•ˆçš„çŸ¥è¯†å¤ç”¨å’Œæ³›åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒMACLAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨æœªè§ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›å’Œæ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºMACLAï¼Œä¸€ä¸ªå°†æ¨ç†ä¸å­¦ä¹ è§£è€¦çš„æ¡†æ¶ï¼Œå®ƒç»´æŠ¤ä¸€ä¸ªå†»ç»“çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶åœ¨å¤–éƒ¨åˆ†å±‚ç¨‹åºè®°å¿†ä¸­æ‰§è¡Œæ‰€æœ‰é€‚åº”ã€‚MACLAä»è½¨è¿¹ä¸­æå–å¯é‡ç”¨çš„ç¨‹åºï¼Œé€šè¿‡è´å¶æ–¯åéªŒè·Ÿè¸ªå¯é æ€§ï¼Œé€šè¿‡æœŸæœ›æ•ˆç”¨è¯„åˆ†é€‰æ‹©åŠ¨ä½œï¼Œå¹¶é€šè¿‡å¯¹æ¯”æˆåŠŸå’Œå¤±è´¥æ¥æ”¹è¿›ç¨‹åºã€‚åœ¨å››ä¸ªåŸºå‡†æµ‹è¯•ï¼ˆALFWorldã€WebShopã€TravelPlannerã€InterCodeSQLï¼‰ä¸­ï¼ŒMACLAå®ç°äº†78.1%çš„å¹³å‡æ€§èƒ½ï¼Œä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚åœ¨ALFWorldçš„æœªè§ä»»åŠ¡ä¸­ï¼ŒMACLAè¾¾åˆ°90.3%çš„æ€§èƒ½ï¼Œå…·æœ‰3.1%çš„æ­£æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç³»ç»Ÿåœ¨56ç§’å†…æ„å»ºè®°å¿†ï¼Œæ¯”æœ€å…ˆè¿›çš„LLMå‚æ•°è®­ç»ƒåŸºçº¿å¿«2800å€ï¼Œå¹¶å°†2851æ¡è½¨è¿¹å‹ç¼©ä¸º187ä¸ªç¨‹åºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå…·æœ‰è´å¶æ–¯é€‰æ‹©å’Œå¯¹æ¯”ç²¾ç‚¼çš„ç»“æ„åŒ–å¤–éƒ¨è®°å¿†èƒ½å¤Ÿå®ç°æ ·æœ¬é«˜æ•ˆã€å¯è§£é‡Šä¸”æŒç»­æ”¹è¿›çš„Agentï¼Œè€Œæ— éœ€LLMå‚æ•°æ›´æ–°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„å¤§è¯­è¨€æ¨¡å‹Agentåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œé€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®è¿›è¡Œå‚æ•°è°ƒæ•´ï¼Œå¯¼è‡´æ ·æœ¬æ•ˆç‡ä½ä¸‹ã€‚æ­¤å¤–ï¼Œæ¨¡å‹éš¾ä»¥æ³›åŒ–åˆ°æœªè§è¿‡çš„ä»»åŠ¡ï¼Œéœ€è¦é’ˆå¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œé‡æ–°è®­ç»ƒã€‚ç°æœ‰çš„æ–¹æ³•éš¾ä»¥åœ¨æ•ˆç‡ã€æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§ä¹‹é—´å–å¾—å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMACLAçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†LLMçš„æ¨ç†èƒ½åŠ›ä¸å¤–éƒ¨ç¨‹åºè®°å¿†çš„å­¦ä¹ èƒ½åŠ›è§£è€¦ã€‚LLMè´Ÿè´£è¿›è¡Œé«˜å±‚æ¬¡çš„æ¨ç†å’Œå†³ç­–ï¼Œè€Œå¤–éƒ¨ç¨‹åºè®°å¿†åˆ™è´Ÿè´£å­˜å‚¨å’Œå¤ç”¨ä»ç»éªŒä¸­å­¦ä¹ åˆ°çš„ç¨‹åºã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼ŒLLMå¯ä»¥ä¸“æ³¨äºæ¨ç†ï¼Œè€Œç¨‹åºè®°å¿†å¯ä»¥ä¸æ–­åœ°å­¦ä¹ å’Œæ”¹è¿›ï¼Œä»è€Œæé«˜æ ·æœ¬æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMACLAçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) è½¨è¿¹æå–ï¼šä»Agentçš„äº¤äº’è½¨è¿¹ä¸­æå–å¯é‡ç”¨çš„ç¨‹åºã€‚2) å¯é æ€§è·Ÿè¸ªï¼šä½¿ç”¨è´å¶æ–¯åéªŒæ¥è·Ÿè¸ªæ¯ä¸ªç¨‹åºçš„å¯é æ€§ã€‚3) åŠ¨ä½œé€‰æ‹©ï¼šé€šè¿‡æœŸæœ›æ•ˆç”¨è¯„åˆ†æ¥é€‰æ‹©æœ€ä½³çš„åŠ¨ä½œã€‚4) ç¨‹åºç²¾ç‚¼ï¼šé€šè¿‡å¯¹æ¯”æˆåŠŸå’Œå¤±è´¥çš„ç»éªŒæ¥æ”¹è¿›ç¨‹åºã€‚æ•´ä¸ªæµç¨‹æ— éœ€æ›´æ–°LLMå‚æ•°ã€‚

**å…³é”®åˆ›æ–°**ï¼šMACLAæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå…¶ç»“æ„åŒ–çš„å¤–éƒ¨è®°å¿†å’Œè´å¶æ–¯é€‰æ‹©ä¸å¯¹æ¯”ç²¾ç‚¼æœºåˆ¶ã€‚ç»“æ„åŒ–å¤–éƒ¨è®°å¿†å…è®¸Agentå­˜å‚¨å’Œå¤ç”¨ç¨‹åºï¼Œè€Œè´å¶æ–¯é€‰æ‹©æœºåˆ¶åˆ™å…è®¸Agentæ ¹æ®ç¨‹åºçš„å¯é æ€§æ¥é€‰æ‹©æœ€ä½³çš„åŠ¨ä½œã€‚å¯¹æ¯”ç²¾ç‚¼æœºåˆ¶åˆ™å…è®¸Agenté€šè¿‡å¯¹æ¯”æˆåŠŸå’Œå¤±è´¥çš„ç»éªŒæ¥ä¸æ–­æ”¹è¿›ç¨‹åºã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒMACLAæ— éœ€å¯¹LLMè¿›è¡Œå‚æ•°æ›´æ–°ï¼Œä»è€Œå¤§å¤§æé«˜äº†æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šMACLAä½¿ç”¨åˆ†å±‚ç¨‹åºè®°å¿†ï¼Œå…è®¸Agentå­˜å‚¨ä¸åŒç²’åº¦çš„ç¨‹åºã€‚è´å¶æ–¯åéªŒçš„è®¡ç®—åŸºäºç¨‹åºçš„æˆåŠŸå’Œå¤±è´¥æ¬¡æ•°ã€‚æœŸæœ›æ•ˆç”¨è¯„åˆ†åˆ™åŸºäºç¨‹åºçš„å¯é æ€§å’Œé¢„æœŸæ”¶ç›Šã€‚å¯¹æ¯”ç²¾ç‚¼æœºåˆ¶é€šè¿‡æ¯”è¾ƒæˆåŠŸå’Œå¤±è´¥çš„è½¨è¿¹æ¥è¯†åˆ«éœ€è¦æ”¹è¿›çš„ç¨‹åºã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.18950v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.18950v1/Figures/fig_memory_size.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.18950v1/x2.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

MACLAåœ¨å››ä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå¹³å‡æ€§èƒ½è¾¾åˆ°78.1%ï¼Œä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚åœ¨ALFWorldçš„æœªè§ä»»åŠ¡ä¸­ï¼ŒMACLAè¾¾åˆ°äº†90.3%çš„æ€§èƒ½ï¼Œå…·æœ‰3.1%çš„æ­£æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼ŒMACLAæ„å»ºè®°å¿†çš„é€Ÿåº¦æ¯”æœ€å…ˆè¿›çš„LLMå‚æ•°è®­ç»ƒåŸºçº¿å¿«2800å€ï¼Œå¹¶å°†2851æ¡è½¨è¿¹å‹ç¼©ä¸º187ä¸ªç¨‹åºã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒMACLAå…·æœ‰å¾ˆé«˜çš„æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MACLAæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œå¯åº”ç”¨äºæœºå™¨äººæ§åˆ¶ã€æ¸¸æˆAIã€æ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸã€‚é€šè¿‡å­¦ä¹ å’Œå¤ç”¨ç»éªŒï¼ŒAgentå¯ä»¥æ›´æœ‰æ•ˆåœ°å®Œæˆå¤æ‚ä»»åŠ¡ï¼Œå¹¶é€‚åº”æ–°çš„ç¯å¢ƒã€‚è¯¥ç ”ç©¶æœ‰åŠ©äºå¼€å‘æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆã€æ›´å…·é€‚åº”æ€§çš„AIç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present MACLA, a framework that decouples reasoning from learning by maintaining a frozen large language model while performing all adaptation in an external hierarchical procedural memory. MACLA extracts reusable procedures from trajectories, tracks reliability via Bayesian posteriors, selects actions through expected-utility scoring, and refines procedures by contrasting successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1 percent average performance, outperforming all baselines. On ALFWorld unseen tasks, MACLA reaches 90.3 percent with 3.1 percent positive generalization. The system constructs memory in 56 seconds, 2800 times faster than the state-of-the-art LLM parameter-training baseline, compressing 2851 trajectories into 187 procedures. Experimental results demonstrate that structured external memory with Bayesian selection and contrastive refinement enables sample-efficient, interpretable, and continually improving agents without LLM parameter updates.

