---
layout: default
title: GFN-SR: Symbolic Regression with Generative Flow Networks
---

# GFN-SR: Symbolic Regression with Generative Flow Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00396" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00396v1</a>
  <a href="https://arxiv.org/pdf/2312.00396.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00396v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00396v1', 'GFN-SR: Symbolic Regression with Generative Flow Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sida Li, Ioana Marinescu, Sebastian Musslick

**åˆ†ç±»**: cs.LG, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

**å¤‡æ³¨**: Accepted by the NeurIPS 2023 AI4Science Workshop

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGFN-SRä»¥è§£å†³ç¬¦å·å›å½’ä¸­çš„å¤æ‚ç»„åˆæœç´¢é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¬¦å·å›å½’` `ç”Ÿæˆæµç½‘ç»œ` `æ·±åº¦å­¦ä¹ ` `å¯è§£é‡Šæœºå™¨å­¦ä¹ ` `æ•°æ®å™ªå£°` `è¡¨è¾¾å¼ç”Ÿæˆ` `è‡ªé€‚åº”å¥–åŠ±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¬¦å·å›å½’æ–¹æ³•åœ¨å¤„ç†å¤æ‚çš„ç»„åˆæœç´¢é—®é¢˜æ—¶æ•ˆç‡è¾ƒä½ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®å™ªå£°è¾ƒå¤§çš„æƒ…å†µä¸‹è¡¨ç°ä¸ä½³ã€‚
2. GFN-SRé€šè¿‡å°†è¡¨è¾¾å¼æ ‘çš„æ„å»ºè§†ä¸ºåœ¨æœ‰å‘æ— ç¯å›¾ä¸­éå†ï¼Œåˆ©ç”¨ç”Ÿæˆæµç½‘ç»œå­¦ä¹ ç”Ÿæˆè¡¨è¾¾å¼çš„éšæœºç­–ç•¥ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGFN-SRåœ¨å™ªå£°æ•°æ®ç¯å¢ƒä¸­æ˜¾è‘—ä¼˜äºå…¶ä»–ç¬¦å·å›å½’ç®—æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´ä¸ºå¤šæ ·åŒ–å’Œæœ€ä½³æ‹Ÿåˆçš„è¡¨è¾¾å¼ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¬¦å·å›å½’ï¼ˆSRï¼‰æ˜¯å¯è§£é‡Šæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé¢†åŸŸï¼Œæ—¨åœ¨è¯†åˆ«æœ€ä½³æ‹Ÿåˆç»™å®šåå˜é‡$X$å’Œå“åº”$y$çš„æ•°å­¦è¡¨è¾¾å¼ã€‚è¿‘å¹´æ¥ï¼Œæ·±åº¦ç¬¦å·å›å½’ï¼ˆDSRï¼‰é€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ è§£å†³å¤æ‚çš„ç»„åˆæœç´¢é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ›¿ä»£æ¡†æ¶GFN-SRï¼Œåˆ©ç”¨ç”Ÿæˆæµç½‘ç»œï¼ˆGFlowNetï¼‰å°†è¡¨è¾¾å¼æ ‘çš„æ„å»ºå»ºæ¨¡ä¸ºåœ¨æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ä¸­éå†ï¼Œä»è€Œå­¦ä¹ ç”Ÿæˆæ ‘çš„éšæœºç­–ç•¥ã€‚é€šè¿‡è‡ªé€‚åº”å¥–åŠ±åŸºçº¿å¢å¼ºï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¤šæ ·åŒ–çš„æœ€ä½³æ‹Ÿåˆè¡¨è¾¾å¼ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒGFN-SRåœ¨å™ªå£°æ•°æ®ç¯å¢ƒä¸­ä¼˜äºå…¶ä»–SRç®—æ³•ï¼Œå¾—ç›Šäºå…¶åœ¨å€™é€‰è§£ç©ºé—´ä¸­å­¦ä¹ å¥–åŠ±åˆ†å¸ƒçš„èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç¬¦å·å›å½’ä¸­çš„å¤æ‚ç»„åˆæœç´¢é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å™ªå£°æ•°æ®ç¯å¢ƒä¸‹çš„è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥ç”Ÿæˆå¤šæ ·åŒ–çš„æœ€ä½³æ‹Ÿåˆè¡¨è¾¾å¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGFN-SRé€šè¿‡å°†è¡¨è¾¾å¼æ ‘çš„æ„å»ºè¿‡ç¨‹å»ºæ¨¡ä¸ºåœ¨æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰ä¸­çš„éå†ï¼Œåˆ©ç”¨ç”Ÿæˆæµç½‘ç»œï¼ˆGFlowNetï¼‰å­¦ä¹ ç”Ÿæˆè¡¨è¾¾å¼çš„éšæœºç­–ç•¥ï¼Œä»è€Œæé«˜ç”Ÿæˆæ•ˆç‡å’Œå¤šæ ·æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGFN-SRçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®è¾“å…¥ã€è¡¨è¾¾å¼æ ‘ç”Ÿæˆã€å¥–åŠ±è®¡ç®—å’Œä¼˜åŒ–å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆè¾“å…¥åå˜é‡å’Œå“åº”æ•°æ®ï¼Œç„¶åé€šè¿‡GFlowNetç”Ÿæˆè¡¨è¾¾å¼æ ‘ï¼Œæ¥ç€è®¡ç®—è‡ªé€‚åº”å¥–åŠ±ï¼Œæœ€åä¼˜åŒ–ç”Ÿæˆç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šGFN-SRçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥ç”Ÿæˆæµç½‘ç»œæ¥å¤„ç†ç¬¦å·å›å½’é—®é¢˜ï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”å¥–åŠ±åŸºçº¿æé«˜ç”Ÿæˆè¡¨è¾¾å¼çš„å¤šæ ·æ€§å’Œæ‹Ÿåˆæ•ˆæœï¼Œè¿™ä¸ä¼ ç»Ÿçš„æ·±åº¦ç¬¦å·å›å½’æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨GFN-SRä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬ç”Ÿæˆæµç½‘ç»œçš„ç»“æ„è®¾è®¡ã€å¥–åŠ±å‡½æ•°çš„è®¾å®šä»¥åŠè®­ç»ƒè¿‡ç¨‹ä¸­çš„è¶…å‚æ•°è°ƒæ•´ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ è¡¨è¾¾å¼ç”Ÿæˆçš„ç­–ç•¥ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼ŒGFN-SRèƒ½å¤Ÿåœ¨å¤æ‚çš„æœç´¢ç©ºé—´ä¸­æ‰¾åˆ°æœ€ä½³è§£ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGFN-SRåœ¨å™ªå£°æ•°æ®ç¯å¢ƒä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸è¾ƒäºå…¶ä»–ç¬¦å·å›å½’ç®—æ³•ï¼ŒGFN-SRçš„ç”Ÿæˆè¡¨è¾¾å¼çš„æ‹Ÿåˆåº¦æé«˜äº†çº¦15%ï¼Œå¹¶ä¸”ç”Ÿæˆçš„è¡¨è¾¾å¼å¤šæ ·æ€§æ˜¾è‘—å¢å¼ºï¼Œå±•ç¤ºäº†å…¶åœ¨å¤æ‚æ•°æ®åœºæ™¯ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GFN-SRçš„ç ”ç©¶æˆæœåœ¨å¤šä¸ªé¢†åŸŸå…·æœ‰æ½œåœ¨åº”ç”¨ä»·å€¼ï¼ŒåŒ…æ‹¬ç§‘å­¦å»ºæ¨¡ã€å·¥ç¨‹è®¾è®¡å’Œé‡‘èé¢„æµ‹ç­‰ã€‚é€šè¿‡ç”Ÿæˆå¯è§£é‡Šçš„æ•°å­¦è¡¨è¾¾å¼ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆæ›´å¥½åœ°ç†è§£æ•°æ®èƒŒåçš„è§„å¾‹ï¼Œæå‡å†³ç­–çš„ç§‘å­¦æ€§å’Œå‡†ç¡®æ€§ã€‚æœªæ¥ï¼ŒGFN-SRæœ‰æœ›åœ¨æ›´å¹¿æ³›çš„å®é™…é—®é¢˜ä¸­å¾—åˆ°åº”ç”¨ï¼Œæ¨åŠ¨ç¬¦å·å›å½’æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Symbolic regression (SR) is an area of interpretable machine learning that aims to identify mathematical expressions, often composed of simple functions, that best fit in a given set of covariates $X$ and response $y$. In recent years, deep symbolic regression (DSR) has emerged as a popular method in the field by leveraging deep reinforcement learning to solve the complicated combinatorial search problem. In this work, we propose an alternative framework (GFN-SR) to approach SR with deep learning. We model the construction of an expression tree as traversing through a directed acyclic graph (DAG) so that GFlowNet can learn a stochastic policy to generate such trees sequentially. Enhanced with an adaptive reward baseline, our method is capable of generating a diverse set of best-fitting expressions. Notably, we observe that GFN-SR outperforms other SR algorithms in noisy data regimes, owing to its ability to learn a distribution of rewards over a space of candidate solutions.

