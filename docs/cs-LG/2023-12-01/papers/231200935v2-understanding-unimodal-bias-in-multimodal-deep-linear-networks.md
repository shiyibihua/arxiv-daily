---
layout: default
title: Understanding Unimodal Bias in Multimodal Deep Linear Networks
---

# Understanding Unimodal Bias in Multimodal Deep Linear Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00935" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00935v2</a>
  <a href="https://arxiv.org/pdf/2312.00935.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00935v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00935v2', 'Understanding Unimodal Bias in Multimodal Deep Linear Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yedi Zhang, Peter E. Latham, Andrew Saxe

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-06-02)

**å¤‡æ³¨**: ICML 2024 camera ready

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://yedizhang.github.io/unimodal-bias.html)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ·±åº¦çº¿æ€§ç½‘ç»œä¸­çš„å•æ¨¡æ€åå·®ç†è®ºä»¥ä¼˜åŒ–è”åˆè®­ç»ƒ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `å•æ¨¡æ€åå·®` `æ·±åº¦çº¿æ€§ç½‘ç»œ` `è”åˆè®­ç»ƒ` `æ¨¡æ€èåˆ` `æ³›åŒ–èƒ½åŠ›` `ç½‘ç»œæ¶æ„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰å¤šæ¨¡æ€ç¥ç»ç½‘ç»œåœ¨è”åˆè®­ç»ƒä¸­å®¹æ˜“å‡ºç°å•æ¨¡æ€åå·®ï¼Œå¯¼è‡´æ¨¡å‹å¯¹æŸä¸€æ¨¡æ€çš„è¿‡åº¦ä¾èµ–ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†å•æ¨¡æ€åå·®çš„ç†è®ºæ¡†æ¶ï¼Œåˆ†æäº†ç½‘ç»œæ¶æ„å’Œæ•°æ®ç»Ÿè®¡å¯¹åå·®çš„å½±å“ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šç ”ç©¶è¡¨æ˜ï¼Œèåˆå±‚è¶Šæ·±ï¼Œå•æ¨¡æ€é˜¶æ®µæŒç»­æ—¶é—´è¶Šé•¿ï¼Œå¯èƒ½å¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è”åˆè®­ç»ƒå¤šæ¨¡æ€ç¥ç»ç½‘ç»œæ—¶ï¼Œä½¿ç”¨å¤šä¸ªè¾“å…¥æµçš„ä¼˜åŠ¿æ˜¾è€Œæ˜“è§ï¼Œä½†å®é™…åº”ç”¨ä¸­é¢ä¸´å•æ¨¡æ€åå·®çš„æŒ‘æˆ˜ï¼Œå³ç½‘ç»œè¿‡åº¦ä¾èµ–æŸä¸€æ¨¡æ€è€Œå¿½è§†å…¶ä»–æ¨¡æ€ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç†è®ºæ¡†æ¶ï¼Œæ¢è®¨äº†æ¶æ„å’Œæ•°æ®ç»Ÿè®¡å¦‚ä½•å½±å“è¿™ç§åå·®ã€‚é¦–æ¬¡è®¡ç®—äº†å­¦ä¹ è¿‡ç¨‹ä¸­å•æ¨¡æ€é˜¶æ®µçš„æŒç»­æ—¶é—´ï¼Œå‘ç°èåˆå±‚è¶Šæ·±ï¼Œå•æ¨¡æ€é˜¶æ®µè¶Šé•¿ï¼Œå¯èƒ½å¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³å’Œæ°¸ä¹…æ€§å•æ¨¡æ€åå·®ã€‚ç ”ç©¶ç»“æœé€‚ç”¨äºå¤šæ¨¡æ€çº¿æ€§ç½‘ç»œï¼Œå¹¶åœ¨æŸäº›æƒ…å†µä¸‹æ‰©å±•åˆ°éçº¿æ€§ç½‘ç»œï¼Œæ­ç¤ºäº†è”åˆè®­ç»ƒä¸‹å¤šæ¨¡æ€å­¦ä¹ çš„ç—…æ€ç°è±¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ·±åº¦çº¿æ€§ç½‘ç»œä¸­çš„å•æ¨¡æ€åå·®é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è”åˆè®­ç»ƒæ—¶ï¼Œç½‘ç»œå¾€å¾€è¿‡åº¦ä¾èµ–æŸä¸€æ¨¡æ€ï¼Œå¯¼è‡´å…¶ä»–æ¨¡æ€çš„ä¿¡æ¯è¢«å¿½è§†ï¼Œä»è€Œå½±å“æ¨¡å‹çš„æ•´ä½“æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡é€šè¿‡å»ºç«‹å•æ¨¡æ€åå·®çš„ç†è®ºæ¡†æ¶ï¼Œåˆ†æäº†ä¸åŒèåˆå±‚æ·±åº¦ã€æ•°æ®é›†ç»Ÿè®¡ç‰¹æ€§å’Œåˆå§‹åŒ–å¯¹å•æ¨¡æ€å­¦ä¹ é˜¶æ®µæŒç»­æ—¶é—´çš„å½±å“ã€‚è¿™æ ·çš„è®¾è®¡æœ‰åŠ©äºç†è§£å’Œä¼˜åŒ–å¤šæ¨¡æ€å­¦ä¹ è¿‡ç¨‹ä¸­çš„åå·®ç°è±¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å¤šæ¨¡æ€æ·±åº¦çº¿æ€§ç½‘ç»œçš„è®¾è®¡ï¼Œé‡ç‚¹åœ¨äºä¸åŒå±‚æ¬¡çš„æ¨¡æ€èåˆã€‚ç ”ç©¶é€šè¿‡ç†è®ºæ¨å¯¼å’Œå®éªŒéªŒè¯ï¼Œæ¢è®¨äº†ä¸åŒèåˆç­–ç•¥å¯¹å•æ¨¡æ€åå·®çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å®šé‡è®¡ç®—äº†å•æ¨¡æ€é˜¶æ®µçš„æŒç»­æ—¶é—´ï¼Œå¹¶æ­ç¤ºäº†æ·±å±‚èåˆç»“æ„å¯èƒ½å¯¼è‡´çš„é•¿æœŸå•æ¨¡æ€åå·®ã€‚è¿™ä¸€å‘ç°ä¸ºå¤šæ¨¡æ€å­¦ä¹ æä¾›äº†æ–°çš„è§†è§’ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­è€ƒè™‘äº†ç½‘ç»œçš„æ·±åº¦ã€æ¨¡æ€èåˆçš„å±‚æ¬¡ã€æ•°æ®é›†çš„ç»Ÿè®¡ç‰¹æ€§ä»¥åŠåˆå§‹åŒ–ç­–ç•¥ç­‰å…³é”®å› ç´ ã€‚è¿™äº›è®¾è®¡å†³å®šäº†æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¡¨ç°å’Œæœ€ç»ˆçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ·±å±‚èåˆç»“æ„å¯¼è‡´çš„å•æ¨¡æ€é˜¶æ®µæŒç»­æ—¶é—´æ˜¾è‘—å¢åŠ ï¼Œå¯èƒ½å¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸‹é™ã€‚å…·ä½“è€Œè¨€ï¼Œæ·±åº¦èåˆå±‚çš„è®¾ç½®ä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯¹æŸä¸€æ¨¡æ€çš„ä¾èµ–æ€§å¢å¼ºï¼Œå½±å“äº†æ•´ä½“æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€å­¦ä¹ ç³»ç»Ÿã€æ™ºèƒ½æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ç­‰åœºæ™¯ã€‚åœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œä¼˜åŒ–å¤šæ¨¡æ€ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹èƒ½å¤Ÿæ˜¾è‘—æå‡æ¨¡å‹çš„æ€§èƒ½å’Œå¯é æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Using multiple input streams simultaneously to train multimodal neural networks is intuitively advantageous but practically challenging. A key challenge is unimodal bias, where a network overly relies on one modality and ignores others during joint training. We develop a theory of unimodal bias with multimodal deep linear networks to understand how architecture and data statistics influence this bias. This is the first work to calculate the duration of the unimodal phase in learning as a function of the depth at which modalities are fused within the network, dataset statistics, and initialization. We show that the deeper the layer at which fusion occurs, the longer the unimodal phase. A long unimodal phase can lead to a generalization deficit and permanent unimodal bias in the overparametrized regime. Our results, derived for multimodal linear networks, extend to nonlinear networks in certain settings. Taken together, this work illuminates pathologies of multimodal learning under joint training, showing that late and intermediate fusion architectures can give rise to long unimodal phases and permanent unimodal bias. Our code is available at: https://yedizhang.github.io/unimodal-bias.html.

