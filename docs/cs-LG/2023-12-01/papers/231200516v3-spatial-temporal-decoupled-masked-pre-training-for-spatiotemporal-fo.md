---
layout: default
title: Spatial-Temporal-Decoupled Masked Pre-training for Spatiotemporal Forecasting
---

# Spatial-Temporal-Decoupled Masked Pre-training for Spatiotemporal Forecasting

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00516" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00516v3</a>
  <a href="https://arxiv.org/pdf/2312.00516.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00516v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00516v3', 'Spatial-Temporal-Decoupled Masked Pre-training for Spatiotemporal Forecasting')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haotian Gao, Renhe Jiang, Zheng Dong, Jinliang Deng, Yuxin Ma, Xuan Song

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-04-28)

**å¤‡æ³¨**: Accepted at IJCAI-2024 Main Track

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Jimmy-7664/STD-MAE)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç©ºé—´-æ—¶é—´è§£è€¦çš„æ©è”½é¢„è®­ç»ƒæ–¹æ³•ä»¥è§£å†³æ—¶ç©ºé¢„æµ‹é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `æ—¶ç©ºé¢„æµ‹` `è‡ªç›‘ç£å­¦ä¹ ` `æ©è”½è‡ªç¼–ç å™¨` `æ·±åº¦å­¦ä¹ ` `æ•°æ®é‡å»º` `æ™ºèƒ½äº¤é€š` `èƒ½æºç®¡ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ—¶ç©ºé¢„æµ‹æ¨¡å‹å—åˆ°è¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼Œå®¹æ˜“å‡ºç°æ—¶ç©ºå¹»å½±ç°è±¡ï¼Œå¯¼è‡´é¢„æµ‹å‡†ç¡®æ€§ä¸‹é™ã€‚
2. æå‡ºçš„STD-MAEæ¡†æ¶é€šè¿‡ä¸¤ä¸ªè§£è€¦çš„æ©è”½è‡ªç¼–ç å™¨åˆ†åˆ«åœ¨ç©ºé—´å’Œæ—¶é—´ç»´åº¦ä¸Šé‡å»ºæ—¶ç©ºåºåˆ—ï¼Œä»è€Œå­¦ä¹ ä¸°å¯Œçš„ä¸Šä¸‹æ–‡è¡¨ç¤ºã€‚
3. åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒSTD-MAEåœ¨æ—¶ç©ºé¢„æµ‹ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†é¢„æµ‹å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ—¶ç©ºé¢„æµ‹æŠ€æœ¯åœ¨äº¤é€šã€èƒ½æºå’Œå¤©æ°”ç­‰å¤šä¸ªé¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚ç„¶è€Œï¼Œç”±äºå¤æ‚çš„æ—¶ç©ºå¼‚è´¨æ€§ï¼Œå‡†ç¡®é¢„æµ‹æ—¶ç©ºåºåˆ—ä»ç„¶é¢ä¸´æŒ‘æˆ˜ã€‚ç°æœ‰çš„ç«¯åˆ°ç«¯æ¨¡å‹å—åˆ°è¾“å…¥é•¿åº¦çš„é™åˆ¶ï¼Œå¸¸å¸¸é™·å…¥æ—¶ç©ºå¹»å½±ï¼Œå³ç›¸ä¼¼çš„è¾“å…¥æ—¶é—´åºåˆ—åè·Ÿä¸ç›¸ä¼¼çš„æœªæ¥å€¼ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªç›‘ç£é¢„è®­ç»ƒæ¡†æ¶â€”â€”ç©ºé—´-æ—¶é—´è§£è€¦æ©è”½é¢„è®­ç»ƒï¼ˆSTD-MAEï¼‰ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ä¸¤ä¸ªè§£è€¦çš„æ©è”½è‡ªç¼–ç å™¨åœ¨ç©ºé—´å’Œæ—¶é—´ç»´åº¦ä¸Šé‡å»ºæ—¶ç©ºåºåˆ—ã€‚é€šè¿‡è¿™ç§é‡å»ºå­¦ä¹ åˆ°çš„ä¸°å¯Œä¸Šä¸‹æ–‡è¡¨ç¤ºå¯ä»¥æ— ç¼é›†æˆåˆ°ä¸‹æ¸¸é¢„æµ‹å™¨ä¸­ï¼Œä»¥å¢å¼ºå…¶æ€§èƒ½ã€‚æœ¬æ–‡åœ¨å…­ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®šé‡å’Œå®šæ€§è¯„ä¼°ï¼ŒéªŒè¯äº†STD-MAEçš„æœ€å…ˆè¿›æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ—¶ç©ºé¢„æµ‹ä¸­çš„æ—¶ç©ºå¹»å½±é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å› è¾“å…¥é•¿åº¦é™åˆ¶è€Œéš¾ä»¥å‡†ç¡®é¢„æµ‹æœªæ¥å€¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSTD-MAEé€šè¿‡è§£è€¦çš„æ©è”½è‡ªç¼–ç å™¨åœ¨ç©ºé—´å’Œæ—¶é—´ç»´åº¦ä¸Šè¿›è¡Œé‡å»ºï¼Œæ—¨åœ¨å­¦ä¹ æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œæé«˜é¢„æµ‹æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç©ºé—´æ©è”½è‡ªç¼–ç å™¨å’Œæ—¶é—´æ©è”½è‡ªç¼–ç å™¨ã€‚é¦–å…ˆï¼Œè¾“å…¥çš„æ—¶ç©ºåºåˆ—è¢«æ©è”½ï¼Œç„¶ååˆ†åˆ«é€šè¿‡ä¸¤ä¸ªè‡ªç¼–ç å™¨è¿›è¡Œé‡å»ºï¼Œæœ€ç»ˆå°†å­¦ä¹ åˆ°çš„è¡¨ç¤ºæ•´åˆç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚

**å…³é”®åˆ›æ–°**ï¼šSTD-MAEçš„åˆ›æ–°åœ¨äºå…¶è§£è€¦çš„è®¾è®¡ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåˆ†åˆ«æ•æ‰ç©ºé—´å’Œæ—¶é—´çš„ç‰¹å¾ï¼Œä»è€Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†é€‚åº”æ€§æ©è”½ç­–ç•¥å’Œå¤šå±‚è‡ªç¼–ç å™¨ç»“æ„ï¼ŒæŸå¤±å‡½æ•°åˆ™ç»“åˆäº†é‡å»ºè¯¯å·®å’Œä¸Šä¸‹æ–‡ä¸€è‡´æ€§ï¼Œä»¥ç¡®ä¿å­¦ä¹ åˆ°çš„è¡¨ç¤ºå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ï¼ˆPEMS03ã€PEMS04ã€PEMS07ã€PEMS08ã€METR-LAå’ŒPEMS-BAYï¼‰ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSTD-MAEåœ¨æ—¶ç©ºé¢„æµ‹ä»»åŠ¡ä¸­è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œé¢„æµ‹å‡†ç¡®æ€§æå‡äº†æ˜¾è‘—çš„ç™¾åˆ†æ¯”ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šç³»ç»Ÿã€èƒ½æºç®¡ç†å’Œæ°”è±¡é¢„æµ‹ç­‰ã€‚é€šè¿‡æé«˜æ—¶ç©ºé¢„æµ‹çš„å‡†ç¡®æ€§ï¼ŒSTD-MAEèƒ½å¤Ÿä¸ºå†³ç­–æ”¯æŒç³»ç»Ÿæä¾›æ›´å¯é çš„æ•°æ®åŸºç¡€ï¼Œè¿›è€Œä¼˜åŒ–èµ„æºé…ç½®å’Œæé«˜æ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨æ›´å¤šå¤æ‚æ—¶ç©ºæ•°æ®åˆ†æä»»åŠ¡ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Spatiotemporal forecasting techniques are significant for various domains such as transportation, energy, and weather. Accurate prediction of spatiotemporal series remains challenging due to the complex spatiotemporal heterogeneity. In particular, current end-to-end models are limited by input length and thus often fall into spatiotemporal mirage, i.e., similar input time series followed by dissimilar future values and vice versa. To address these problems, we propose a novel self-supervised pre-training framework Spatial-Temporal-Decoupled Masked Pre-training (STD-MAE) that employs two decoupled masked autoencoders to reconstruct spatiotemporal series along the spatial and temporal dimensions. Rich-context representations learned through such reconstruction could be seamlessly integrated by downstream predictors with arbitrary architectures to augment their performances. A series of quantitative and qualitative evaluations on six widely used benchmarks (PEMS03, PEMS04, PEMS07, PEMS08, METR-LA, and PEMS-BAY) are conducted to validate the state-of-the-art performance of STD-MAE. Codes are available at https://github.com/Jimmy-7664/STD-MAE.

