---
layout: default
title: Domain Adaptive Imitation Learning with Visual Observation
---

# Domain Adaptive Imitation Learning with Visual Observation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00548" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00548v1</a>
  <a href="https://arxiv.org/pdf/2312.00548.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00548v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00548v1', 'Domain Adaptive Imitation Learning with Visual Observation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Sungho Choi, Seungyul Han, Woojun Kim, Jongseong Chae, Whiyoung Jung, Youngchul Sung

**åˆ†ç±»**: cs.LG, cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

**å¤‡æ³¨**: Accepted to NeurIPS 2023

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§æ–°æ¡†æ¶ä»¥è§£å†³è§†è§‰è§‚å¯Ÿä¸‹çš„é¢†åŸŸè‡ªé€‚åº”æ¨¡ä»¿å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `é¢†åŸŸè‡ªé€‚åº”` `æ¨¡ä»¿å­¦ä¹ ` `è§†è§‰è§‚å¯Ÿ` `ç‰¹å¾æå–` `å›¾åƒé‡å»º` `æœºå™¨äººå­¦ä¹ ` `è·¨é¢†åŸŸå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†è§†è§‰è§‚å¯Ÿæ—¶ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹æºé¢†åŸŸä¸ç›®æ ‡é¢†åŸŸä¹‹é—´çš„é¢†åŸŸè½¬ç§»é—®é¢˜ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ¡†æ¶ï¼Œé€šè¿‡åŒé‡ç‰¹å¾æå–å’Œå›¾åƒé‡å»ºï¼Œæå–é¢†åŸŸæ— å…³çš„è¡Œä¸ºç‰¹å¾ï¼Œä»è€Œå¢å¼ºå­¦ä¹ è€…çš„é€‚åº”èƒ½åŠ›ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒè¯æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨è§†è§‰è§‚å¯Ÿä¸‹çš„é¢†åŸŸè‡ªé€‚åº”æ¨¡ä»¿å­¦ä¹ ä¸­ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰ç®—æ³•ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡è€ƒè™‘äº†åœ¨è§†è§‰è§‚å¯Ÿä¸‹çš„é¢†åŸŸè‡ªé€‚åº”æ¨¡ä»¿å­¦ä¹ é—®é¢˜ï¼Œå…¶ä¸­ç›®æ ‡é¢†åŸŸçš„æ™ºèƒ½ä½“é€šè¿‡è§‚å¯Ÿæºé¢†åŸŸçš„ä¸“å®¶æ¼”ç¤ºæ¥å­¦ä¹ æ‰§è¡Œä»»åŠ¡ã€‚åœ¨å®é™…åœºæ™¯ä¸­ï¼Œæœºå™¨äººéœ€è¦é€šè¿‡è§†è§‰è§‚å¯Ÿå…¶ä»–æœºå™¨äººæ¥æ¨¡ä»¿åŠ¨ä½œï¼Œé¢ä¸´è·¨é¢†åŸŸæ¨¡ä»¿å­¦ä¹ ä¸­çš„é¢†åŸŸè½¬ç§»é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡åŒé‡ç‰¹å¾æå–å’Œå›¾åƒé‡å»ºï¼Œä»è¾“å…¥è§‚å¯Ÿä¸­æå–é¢†åŸŸæ— å…³çš„è¡Œä¸ºç‰¹å¾ï¼Œä»¥è®­ç»ƒå­¦ä¹ è€…ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†è§†è§‰è§‚å¯Ÿä¸‹çš„é¢†åŸŸè½¬ç§»æ¨¡ä»¿å­¦ä¹ æ—¶ï¼Œä¼˜äºä»¥å¾€çš„ç®—æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨è§†è§‰è§‚å¯Ÿä¸‹çš„é¢†åŸŸè‡ªé€‚åº”æ¨¡ä»¿å­¦ä¹ é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨æºé¢†åŸŸä¸ç›®æ ‡é¢†åŸŸä¹‹é—´çš„è½¬ç§»æ•ˆæœä¸ä½³ï¼Œå¯¼è‡´å­¦ä¹ æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºé€šè¿‡åŒé‡ç‰¹å¾æå–å’Œå›¾åƒé‡å»ºçš„æ–¹å¼ï¼Œæå–é¢†åŸŸæ— å…³çš„è¡Œä¸ºç‰¹å¾ï¼Œä»¥å¢å¼ºå­¦ä¹ è€…å¯¹ä¸åŒé¢†åŸŸçš„é€‚åº”èƒ½åŠ›ã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å‡å°‘é¢†åŸŸé—´çš„å·®å¼‚ï¼Œæé«˜æ¨¡ä»¿å­¦ä¹ çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šç‰¹å¾æå–æ¨¡å—å’Œå›¾åƒé‡å»ºæ¨¡å—ã€‚ç‰¹å¾æå–æ¨¡å—è´Ÿè´£ä»è¾“å…¥çš„è§†è§‰è§‚å¯Ÿä¸­æå–è¡Œä¸ºç‰¹å¾ï¼Œè€Œå›¾åƒé‡å»ºæ¨¡å—åˆ™ç”¨äºé‡å»ºè¾“å…¥å›¾åƒï¼Œä»¥ç¡®ä¿ç‰¹å¾çš„é¢†åŸŸæ— å…³æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§åŒé‡ç‰¹å¾æå–æœºåˆ¶ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå–é¢†åŸŸæ— å…³çš„è¡Œä¸ºç‰¹å¾ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæ˜¾è‘—æå‡äº†æ¨¡ä»¿å­¦ä¹ çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡ç‰¹å¾æå–å’Œå›¾åƒé‡å»ºçš„æ•ˆæœï¼ŒåŒæ—¶ç½‘ç»œç»“æ„è®¾è®¡ä¸Šä½¿ç”¨äº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥å¢å¼ºç‰¹å¾æå–çš„èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡ä¼˜äºç°æœ‰çš„æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œå…·ä½“æ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°15%-30%ã€‚è¿™ä¸€ç»“æœéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å¤„ç†é¢†åŸŸè½¬ç§»é—®é¢˜ä¸Šçš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨åœºæ™¯åŒ…æ‹¬æœºå™¨äººå­¦ä¹ ã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸï¼Œèƒ½å¤Ÿå¸®åŠ©æœºå™¨äººåœ¨ä¸åŒç¯å¢ƒä¸­æ›´å¥½åœ°å­¦ä¹ å’Œé€‚åº”ï¼Œæå‡å…¶è‡ªä¸»å†³ç­–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„é¢†åŸŸè‡ªé€‚åº”æŠ€æœ¯çš„å‘å±•ï¼Œä¿ƒè¿›æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In this paper, we consider domain-adaptive imitation learning with visual observation, where an agent in a target domain learns to perform a task by observing expert demonstrations in a source domain. Domain adaptive imitation learning arises in practical scenarios where a robot, receiving visual sensory data, needs to mimic movements by visually observing other robots from different angles or observing robots of different shapes. To overcome the domain shift in cross-domain imitation learning with visual observation, we propose a novel framework for extracting domain-independent behavioral features from input observations that can be used to train the learner, based on dual feature extraction and image reconstruction. Empirical results demonstrate that our approach outperforms previous algorithms for imitation learning from visual observation with domain shift.

