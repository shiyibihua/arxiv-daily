---
layout: default
title: Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach
---

# Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00279" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00279v2</a>
  <a href="https://arxiv.org/pdf/2312.00279.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00279v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00279v2', 'Age-Based Scheduling for Mobile Edge Computing: A Deep Reinforcement Learning Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xingqiu He, Chaoqun You, Tony Q. S. Quek

**åˆ†ç±»**: cs.LG, cs.NI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-02-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¹´é¾„è°ƒåº¦çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä»¥ä¼˜åŒ–ç§»åŠ¨è¾¹ç¼˜è®¡ç®—**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç§»åŠ¨è¾¹ç¼˜è®¡ç®—` `ä¿¡æ¯å¹´é¾„` `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹` `åå†³ç­–çŠ¶æ€` `ç®—æ³•ä¼˜åŒ–` `å®æ—¶åº”ç”¨`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šç°æœ‰æ–¹æ³•å‡è®¾çŠ¶æ€ä¿¡æ¯å¯ä»¥ä¸»åŠ¨é‡‡æ ·ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†äº‹ä»¶é©±åŠ¨æ›´æ–°çš„MECåº”ç”¨ï¼Œå¯¼è‡´AoIä¼˜åŒ–ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæå‡ºæ–°çš„AoIå®šä¹‰ï¼Œå¹¶å°†AoIæœ€å°åŒ–é—®é¢˜å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼Œç»“åˆåå†³ç­–çŠ¶æ€åŠ é€Ÿå­¦ä¹ ã€‚
3. å®éªŒæˆ–æ•ˆæœï¼šå®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æç®—æ³•åœ¨å¤šç§åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰åŸºå‡†ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€ç§»åŠ¨è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰çš„å¿«é€Ÿå‘å±•ï¼Œå„ç§å®æ—¶åº”ç”¨è¢«éƒ¨ç½²ä»¥æ”¹å–„äººä»¬çš„æ—¥å¸¸ç”Ÿæ´»ã€‚è¿™äº›åº”ç”¨çš„æ€§èƒ½åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äºæ”¶é›†ç¯å¢ƒä¿¡æ¯çš„æ–°é²œåº¦ï¼Œå¯ä»¥é€šè¿‡ä¿¡æ¯å¹´é¾„ï¼ˆAoIï¼‰é‡åŒ–ã€‚ä¼ ç»Ÿçš„AoIå®šä¹‰å‡è®¾çŠ¶æ€ä¿¡æ¯å¯ä»¥ä¸»åŠ¨é‡‡æ ·å¹¶ç›´æ¥ä½¿ç”¨ï¼Œä½†è®¸å¤šMECåº”ç”¨çš„çŠ¶æ€ä¿¡æ¯æ˜¯äº‹ä»¶é©±åŠ¨æ›´æ–°çš„ï¼Œå¹¶éœ€è¦æ•°æ®å¤„ç†ã€‚ä¸ºæ›´å¥½åœ°æœåŠ¡è¿™äº›åº”ç”¨ï¼Œæœ¬æ–‡æå‡ºäº†AoIçš„æ–°å®šä¹‰ï¼Œå¹¶åŸºäºæ­¤å®šä¹‰ï¼Œå½¢æˆäº†MECç³»ç»Ÿçš„åœ¨çº¿AoIæœ€å°åŒ–é—®é¢˜ã€‚è¯¥é—®é¢˜å¯è§†ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œä»è€Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç®—æ³•æ±‚è§£ã€‚ä¸ºåŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œæœ¬æ–‡å¼•å…¥äº†åå†³ç­–çŠ¶æ€ï¼ˆPDSï¼‰ä»¥åˆ©ç”¨ç³»ç»ŸåŠ¨æ€çš„éƒ¨åˆ†çŸ¥è¯†ï¼Œå¹¶å°†PDSä¸æ·±åº¦RLç»“åˆï¼Œè¿›ä¸€æ­¥æé«˜ç®—æ³•çš„é€‚ç”¨æ€§ã€å¯æ‰©å±•æ€§å’Œé²æ£’æ€§ã€‚æ•°å€¼ç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡ç®—æ³•åœ¨å„ç§åœºæ™¯ä¸‹ä¼˜äºåŸºå‡†æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç§»åŠ¨è¾¹ç¼˜è®¡ç®—ä¸­ä¿¡æ¯å¹´é¾„ï¼ˆAoIï¼‰ä¼˜åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å‡è®¾çŠ¶æ€ä¿¡æ¯å¯ä»¥ä¸»åŠ¨é‡‡æ ·ï¼Œä½†åœ¨è®¸å¤šåº”ç”¨ä¸­ï¼Œä¿¡æ¯æ›´æ–°æ˜¯äº‹ä»¶é©±åŠ¨çš„ï¼Œå¯¼è‡´ä¼ ç»Ÿæ–¹æ³•æ— æ³•æœ‰æ•ˆå¤„ç†ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°çš„AoIå®šä¹‰ï¼Œå¹¶å°†AoIæœ€å°åŒ–é—®é¢˜å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ã€‚é€šè¿‡å¼•å…¥åå†³ç­–çŠ¶æ€ï¼ˆPDSï¼‰ï¼Œåˆ©ç”¨ç³»ç»ŸåŠ¨æ€çš„éƒ¨åˆ†çŸ¥è¯†æ¥åŠ é€Ÿå­¦ä¹ è¿‡ç¨‹ï¼Œå¹¶ç»“åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»¥æé«˜ç®—æ³•çš„é€‚ç”¨æ€§å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬çŠ¶æ€å®šä¹‰ã€åŠ¨ä½œé€‰æ‹©å’Œå¥–åŠ±æœºåˆ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå®šä¹‰æ–°çš„AoIçŠ¶æ€ï¼›å…¶æ¬¡ï¼ŒåŸºäºPDSè¿›è¡ŒåŠ¨ä½œé€‰æ‹©ï¼›æœ€åï¼Œé€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¼˜åŒ–å¥–åŠ±æœºåˆ¶ï¼Œå®ç°AoIçš„æœ€å°åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥åå†³ç­–çŠ¶æ€ï¼ˆPDSï¼‰ï¼Œä½¿å¾—ç®—æ³•èƒ½å¤Ÿåˆ©ç”¨éƒ¨åˆ†å·²çŸ¥çš„ç³»ç»ŸåŠ¨æ€ä¿¡æ¯ï¼Œä»è€ŒåŠ å¿«æ”¶æ•›é€Ÿåº¦ï¼Œä¸ä¼ ç»ŸRLæ–¹æ³•ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç®—æ³•è®¾è®¡ä¸­ï¼Œè®¾ç½®äº†é€‚å½“çš„å­¦ä¹ ç‡å’ŒæŠ˜æ‰£å› å­ï¼ŒæŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œç½‘ç»œç»“æ„åŸºäºæ·±åº¦Qç½‘ç»œï¼ˆDQNï¼‰è¿›è¡Œä¼˜åŒ–ï¼Œä»¥é€‚åº”AoIæœ€å°åŒ–çš„éœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æç®—æ³•åœ¨å¤šç§åœºæ™¯ä¸‹çš„AoIè¡¨ç°ä¼˜äºç°æœ‰åŸºå‡†ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼Œä¸”åœ¨ç³»ç»ŸåŠ¨æ€å˜åŒ–æ—¶ä»èƒ½ä¿æŒè‰¯å¥½çš„æ€§èƒ½ï¼ŒéªŒè¯äº†ç®—æ³•çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½äº¤é€šç³»ç»Ÿã€ç‰©è”ç½‘è®¾å¤‡ç®¡ç†å’Œå®æ—¶ç›‘æ§ç­‰åœºæ™¯ã€‚é€šè¿‡ä¼˜åŒ–ä¿¡æ¯å¹´é¾„ï¼Œå¯ä»¥æ˜¾è‘—æå‡è¿™äº›åº”ç”¨çš„å“åº”é€Ÿåº¦å’Œæ•ˆç‡ï¼Œè¿›è€Œæ”¹å–„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„MECåº”ç”¨ä¸­æ¨å¹¿ï¼Œæ¨åŠ¨æ™ºèƒ½è¾¹ç¼˜è®¡ç®—çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With the rapid development of Mobile Edge Computing (MEC), various real-time applications have been deployed to benefit people's daily lives. The performance of these applications relies heavily on the freshness of collected environmental information, which can be quantified by its Age of Information (AoI). In the traditional definition of AoI, it is assumed that the status information can be actively sampled and directly used. However, for many MEC-enabled applications, the desired status information is updated in an event-driven manner and necessitates data processing. To better serve these applications, we propose a new definition of AoI and, based on the redefined AoI, we formulate an online AoI minimization problem for MEC systems. Notably, the problem can be interpreted as a Markov Decision Process (MDP), thus enabling its solution through Reinforcement Learning (RL) algorithms. Nevertheless, the traditional RL algorithms are designed for MDPs with completely unknown system dynamics and hence usually suffer long convergence times. To accelerate the learning process, we introduce Post-Decision States (PDSs) to exploit the partial knowledge of the system's dynamics. We also combine PDSs with deep RL to further improve the algorithm's applicability, scalability, and robustness. Numerical results demonstrate that our algorithm outperforms the benchmarks under various scenarios.

