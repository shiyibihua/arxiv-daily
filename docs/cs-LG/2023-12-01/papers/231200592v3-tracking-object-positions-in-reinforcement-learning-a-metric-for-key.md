---
layout: default
title: Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)
---

# Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00592" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00592v3</a>
  <a href="https://arxiv.org/pdf/2312.00592.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00592v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00592v3', 'Tracking Object Positions in Reinforcement Learning: A Metric for Keypoint Detection (extended version)')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Emma Cramer, Jonas Reiher, Sebastian Trimpe

**åˆ†ç±»**: cs.LG, cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01 (æ›´æ–°: 2024-07-02)

**å¤‡æ³¨**: 19 pages, 12 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºä¸€ç§è½»é‡çº§æŒ‡æ ‡ä»¥è¯„ä¼°å…³é”®ç‚¹æ£€æµ‹åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `ç©ºé—´è‡ªç¼–ç å™¨` `å…³é”®ç‚¹æ£€æµ‹` `æœºå™¨äººæ§åˆ¶` `æ€§èƒ½è¯„ä¼°` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç©ºé—´è‡ªç¼–ç å™¨åœ¨è·Ÿè¸ªç‰©ä½“æ–¹é¢çš„èƒ½åŠ›ç¼ºä¹æœ‰æ•ˆçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¯¼è‡´å…¶åœ¨å¼ºåŒ–å­¦ä¹ ä¸­çš„åº”ç”¨å—åˆ°é™åˆ¶ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„è½»é‡çº§æŒ‡æ ‡ï¼Œé€šè¿‡è¯„ä¼°å…³é”®ç‚¹è·Ÿè¸ªçœŸå®ç‰©ä½“çš„èƒ½åŠ›æ¥è¡¡é‡SAEçš„æ€§èƒ½ï¼Œæ—¨åœ¨æ”¹å–„SAEåœ¨RLä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSAEåœ¨è¯¥æŒ‡æ ‡ä¸Šçš„è¡¨ç°ä¸å…¶åœ¨ä¸‹æ¸¸RLä»»åŠ¡ä¸­çš„è¡¨ç°é«˜åº¦ç›¸å…³ï¼Œä¸”é€šè¿‡ç‰¹å®šæ¶æ„ä¿®æ”¹å¯ä»¥æ˜¾è‘—æå‡è·Ÿè¸ªæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åœ¨æœºå™¨äººæ§åˆ¶ä¸­é€šå¸¸éœ€è¦å¯¹ç¯å¢ƒçŠ¶æ€çš„è¯¦ç»†è¡¨ç¤ºï¼ŒåŒ…æ‹¬ä¸ä»»åŠ¡ç›¸å…³çš„ä¸å¯ç›´æ¥æµ‹é‡çš„ç‰©ä½“ä¿¡æ¯ã€‚ç©ºé—´è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰æ˜¯ä»é«˜ç»´å›¾åƒæ•°æ®ä¸­æå–ä½ç»´è¡¨ç¤ºçš„å¸¸ç”¨æ–¹æ³•ï¼Œæ—¨åœ¨æå–ç‰©ä½“ä½ç½®ç­‰ç©ºé—´ç‰¹å¾ã€‚ç„¶è€Œï¼ŒSAEæ˜¯å¦èƒ½å¤Ÿæœ‰æ•ˆè·Ÿè¸ªåœºæ™¯ä¸­çš„ç‰©ä½“å¹¶æä¾›é€‚åˆRLä»»åŠ¡çš„ç©ºé—´çŠ¶æ€è¡¨ç¤ºï¼Œå°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡æµ‹é‡å…³é”®ç‚¹è·Ÿè¸ªçœŸå®ç‰©ä½“çš„èƒ½åŠ›æ¥è¯„ä¼°SAEå®ä¾‹æ€§èƒ½çš„æŒ‡æ ‡ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿæœºå™¨äººä»»åŠ¡çš„å›¾åƒæ•°æ®ä¸Šè¯„ä¼°äº†å¸¸è§çš„SAEæ¶æ„ã€‚ç ”ç©¶å‘ç°ï¼Œå¸¸è§SAEåœ¨ç©ºé—´æå–èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œä¸”åœ¨è¯¥æŒ‡æ ‡è¡¨ç°è‰¯å¥½çš„SAEåœ¨ä¸‹æ¸¸RLä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºè‰²ã€‚å› æ­¤ï¼Œè¯¥æŒ‡æ ‡åœ¨æ‰§è¡Œæ˜‚è´µçš„RLè®­ç»ƒä¹‹å‰ï¼Œæ˜¯RLæ€§èƒ½çš„æœ‰æ•ˆä¸”è½»é‡çº§çš„æŒ‡ç¤ºå™¨ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡è¯†åˆ«äº†ä¸‰ç§æ”¹è¿›SAEæ¶æ„ä»¥æå‡è·Ÿè¸ªæ€§èƒ½çš„å…³é”®ä¿®æ”¹ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰ç©ºé—´è‡ªç¼–ç å™¨ï¼ˆSAEï¼‰åœ¨è·Ÿè¸ªç‰©ä½“æ—¶ç¼ºä¹æœ‰æ•ˆè¯„ä¼°æŒ‡æ ‡çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†éªŒè¯SAEåœ¨å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­çš„é€‚ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºä¸€ç§é€šè¿‡æµ‹é‡å…³é”®ç‚¹è·Ÿè¸ªçœŸå®ç‰©ä½“çš„èƒ½åŠ›æ¥è¯„ä¼°SAEæ€§èƒ½çš„è½»é‡çº§æŒ‡æ ‡ã€‚è¿™ç§è®¾è®¡å¯ä»¥åœ¨è¿›è¡Œæ˜‚è´µçš„RLè®­ç»ƒä¹‹å‰ï¼Œå¿«é€Ÿè¯„ä¼°SAEçš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬SAEçš„è®­ç»ƒã€å…³é”®ç‚¹æ£€æµ‹å’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆè®­ç»ƒSAEæå–ç©ºé—´ç‰¹å¾ï¼Œç„¶åé€šè¿‡æå‡ºçš„æŒ‡æ ‡è¯„ä¼°å…³é”®ç‚¹çš„è·Ÿè¸ªèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¯¥æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆåæ˜ SAEåœ¨å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œæä¾›äº†æ›´ç›´æ¥çš„æ€§èƒ½åé¦ˆã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé€‰æ‹©äº†é€‚åˆçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–å…³é”®ç‚¹æ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œå¹¶å¯¹ç½‘ç»œç»“æ„è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥æé«˜ç©ºé—´ç‰¹å¾çš„æå–èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¸¸è§çš„SAEåœ¨ç©ºé—´æå–èƒ½åŠ›ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œè¡¨ç°æœ€ä½³çš„SAEåœ¨ä¸‹æ¸¸å¼ºåŒ–å­¦ä¹ ä»»åŠ¡ä¸­æ€§èƒ½æå‡è¶…è¿‡20%ã€‚è¯¥æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ä¸ºSAEçš„ä¼˜åŒ–æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½ç›‘æ§ç­‰åœºæ™¯ã€‚é€šè¿‡æ”¹è¿›SAEçš„æ€§èƒ½ï¼Œå¯ä»¥æé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„è‡ªä¸»å†³ç­–èƒ½åŠ›ï¼Œè¿›è€Œæ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„å®é™…åº”ç”¨å’Œå‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning (RL) for robot control typically requires a detailed representation of the environment state, including information about task-relevant objects not directly measurable. Keypoint detectors, such as spatial autoencoders (SAEs), are a common approach to extracting a low-dimensional representation from high-dimensional image data. SAEs aim at spatial features such as object positions, which are often useful representations in robotic RL. However, whether an SAE is actually able to track objects in the scene and thus yields a spatial state representation well suited for RL tasks has rarely been examined due to a lack of established metrics. In this paper, we propose to assess the performance of an SAE instance by measuring how well keypoints track ground truth objects in images. We present a computationally lightweight metric and use it to evaluate common baseline SAE architectures on image data from a simulated robot task. We find that common SAEs differ substantially in their spatial extraction capability. Furthermore, we validate that SAEs that perform well in our metric achieve superior performance when used in downstream RL. Thus, our metric is an effective and lightweight indicator of RL performance before executing expensive RL training. Building on these insights, we identify three key modifications of SAE architectures to improve tracking performance.

