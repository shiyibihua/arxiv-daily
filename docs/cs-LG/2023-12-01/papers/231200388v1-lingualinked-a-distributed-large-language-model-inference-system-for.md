---
layout: default
title: LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices
---

# LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00388" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2312.00388v1</a>
  <a href="https://arxiv.org/pdf/2312.00388.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00388v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00388v1', 'LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Junchen Zhao, Yurun Song, Simeng Liu, Ian G. Harris, Sangeetha Abdu Jyothi

**åˆ†ç±»**: cs.LG, cs.DC, cs.NI

**å‘å¸ƒæ—¥æœŸ**: 2023-12-01

**å¤‡æ³¨**: 16 pages, 8 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLinguaLinkedä»¥è§£å†³ç§»åŠ¨è®¾å¤‡ä¸Šå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç§»åŠ¨è®¾å¤‡` `åˆ†å¸ƒå¼æ¨ç†` `æ•°æ®éšç§` `è´Ÿè½½å‡è¡¡` `æ¨¡å‹ä¼˜åŒ–` `æ€§èƒ½æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹é¢ä¸´å†…å­˜éœ€æ±‚è¿‡é«˜å’Œæ¨ç†æ•ˆç‡ä½ä¸‹çš„æŒ‘æˆ˜ã€‚
2. LinguaLinkedé€šè¿‡å»ä¸­å¿ƒåŒ–çš„åˆ†å¸ƒå¼æ¨ç†å’Œä¼˜åŒ–çš„æ¨¡å‹åˆ†é…ã€æ•°æ®ä¼ è¾“åŠè´Ÿè½½å‡è¡¡ç­–ç•¥æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒLinguaLinkedåœ¨å•çº¿ç¨‹è®¾ç½®ä¸‹æ¨ç†æ€§èƒ½æå‡1.11å€è‡³1.61å€ï¼Œå¤šçº¿ç¨‹ä¸‹æå‡1.73å€è‡³2.65å€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæœ¬åœ°éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é¢ä¸´æ˜¾è‘—æŒ‘æˆ˜ï¼Œä¸»è¦æ˜¯ç”±äºå…¶åºå¤§çš„å†…å­˜éœ€æ±‚ã€‚æœ¬æ–‡ä»‹ç»äº†LinguaLinkedï¼Œä¸€ä¸ªç”¨äºç§»åŠ¨è®¾å¤‡çš„å»ä¸­å¿ƒåŒ–åˆ†å¸ƒå¼LLMæ¨ç†ç³»ç»Ÿã€‚LinguaLinkedé€šè¿‡å¤šä¸ªå¯ä¿¡è®¾å¤‡çš„åä½œæ‰§è¡Œæ¨ç†ä»»åŠ¡ï¼Œç¡®ä¿æ•°æ®éšç§ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨ä¸‰é¡¹å…³é”®ç­–ç•¥ï¼šé¦–å…ˆï¼Œä¼˜åŒ–çš„æ¨¡å‹åˆ†é…æŠ€æœ¯å°†LLMsè¿›è¡Œåˆ†æ®µï¼Œå¹¶åˆ©ç”¨çº¿æ€§ä¼˜åŒ–å°†æ®µä¸æ¯ä¸ªè®¾å¤‡çš„èƒ½åŠ›å¯¹é½ï¼›å…¶æ¬¡ï¼Œä¼˜åŒ–çš„æ•°æ®ä¼ è¾“æœºåˆ¶ç¡®ä¿æ¨¡å‹æ®µä¹‹é—´é«˜æ•ˆã€ç»“æ„åŒ–çš„æ•°æ®æµï¼ŒåŒæ—¶ä¿æŒåŸå§‹æ¨¡å‹ç»“æ„çš„å®Œæ•´æ€§ï¼›æœ€åï¼ŒLinguaLinkedé›†æˆäº†ä¸€ä¸ªè¿è¡Œæ—¶è´Ÿè½½å‡è¡¡å™¨ï¼Œä¸»åŠ¨ç›‘æ§å¹¶é‡æ–°åˆ†é…ä»»åŠ¡ï¼Œä»¥é˜²æ­¢ç“¶é¢ˆï¼Œæé«˜ç³»ç»Ÿçš„æ•´ä½“æ•ˆç‡å’Œå“åº”èƒ½åŠ›ã€‚é€šè¿‡å¯¹å„ç§ç§»åŠ¨è®¾å¤‡çš„å¹¿æ³›æµ‹è¯•ï¼ŒLinguaLinkedåœ¨ä¿æŒä¸€è‡´çš„ååé‡å’Œæœ€å°å»¶è¿Ÿçš„åŒæ—¶ï¼Œä¿ƒè¿›äº†é«˜æ•ˆçš„LLMæ¨ç†ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šæœ¬åœ°éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹æ—¶çš„å†…å­˜éœ€æ±‚å’Œæ¨ç†æ•ˆç‡é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æ»¡è¶³ç§»åŠ¨è®¾å¤‡çš„èµ„æºé™åˆ¶ï¼Œå¯¼è‡´æ¨ç†æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šLinguaLinkedçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å»ä¸­å¿ƒåŒ–çš„æ–¹å¼ï¼Œå°†æ¨ç†ä»»åŠ¡åˆ†æ•£åˆ°å¤šä¸ªå¯ä¿¡è®¾å¤‡ä¸Šæ‰§è¡Œï¼Œä»è€Œé™ä½å•ä¸ªè®¾å¤‡çš„è´Ÿæ‹…ï¼Œå¹¶ç¡®ä¿æ•°æ®éšç§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šLinguaLinkedçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä¼˜åŒ–çš„æ¨¡å‹åˆ†é…æ¨¡å—ã€æ•°æ®ä¼ è¾“æœºåˆ¶å’Œè¿è¡Œæ—¶è´Ÿè½½å‡è¡¡å™¨ã€‚æ¨¡å‹åˆ†é…æ¨¡å—è´Ÿè´£å°†LLMsè¿›è¡Œåˆ†æ®µå¹¶åˆ†é…ç»™è®¾å¤‡ï¼Œæ•°æ®ä¼ è¾“æœºåˆ¶ç¡®ä¿æ•°æ®æµçš„é«˜æ•ˆæ€§ï¼Œè€Œè´Ÿè½½å‡è¡¡å™¨åˆ™ç›‘æ§ä»»åŠ¡åˆ†é…ï¼ŒåŠ¨æ€è°ƒæ•´ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šLinguaLinkedçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ä¼˜åŒ–çš„æ¨¡å‹åˆ†é…å’Œæ•°æ®ä¼ è¾“æœºåˆ¶ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„é›†ä¸­å¼æ¨ç†æ¨¡å¼å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œæ˜¾è‘—æé«˜äº†ç§»åŠ¨è®¾å¤‡çš„æ¨ç†æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹åˆ†é…ä¸­ï¼Œé‡‡ç”¨çº¿æ€§ä¼˜åŒ–ç®—æ³•æ¥åŒ¹é…æ¨¡å‹æ®µä¸è®¾å¤‡èƒ½åŠ›ï¼›æ•°æ®ä¼ è¾“æœºåˆ¶åˆ™è®¾è®¡ä¸ºé«˜æ•ˆä¸”ç»“æ„åŒ–ï¼Œä»¥ä¿æŒæ¨¡å‹å®Œæ•´æ€§ï¼›è´Ÿè½½å‡è¡¡å™¨é€šè¿‡å®æ—¶ç›‘æ§ä»»åŠ¡çŠ¶æ€ï¼Œç¡®ä¿å„è®¾å¤‡è´Ÿè½½å‡åŒ€ï¼Œé¿å…æ€§èƒ½ç“¶é¢ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

LinguaLinkedåœ¨å¤šç§ç§»åŠ¨è®¾å¤‡ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œå•çº¿ç¨‹æ¨ç†æ€§èƒ½æå‡1.11å€è‡³1.61å€ï¼Œå¤šçº¿ç¨‹ä¸‹æå‡1.73å€è‡³2.65å€ï¼Œè¿è¡Œæ—¶è´Ÿè½½å‡è¡¡å®ç°äº†æ•´ä½“æ¨ç†åŠ é€Ÿ1.29å€è‡³1.32å€ï¼Œæ˜¾è‘—ä¼˜äºåŸºçº¿æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

LinguaLinkedçš„ç ”ç©¶æˆæœå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜æ•ˆå¤„ç†è‡ªç„¶è¯­è¨€çš„ç§»åŠ¨åº”ç”¨åœºæ™¯ä¸­ï¼Œå¦‚æ™ºèƒ½åŠ©æ‰‹ã€å®æ—¶ç¿»è¯‘å’Œä¸ªæ€§åŒ–æ¨èç³»ç»Ÿã€‚é€šè¿‡åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå®ç°é«˜æ•ˆçš„LLMæ¨ç†ï¼ŒLinguaLinkedèƒ½å¤Ÿæå‡ç”¨æˆ·ä½“éªŒï¼Œå¹¶æ¨åŠ¨æ™ºèƒ½ç§»åŠ¨åº”ç”¨çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices. LinguaLinked ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device's capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system's overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices. In our evaluations, compared to the baseline, LinguaLinked achieves an inference performance acceleration of $1.11\times$ to $1.61\times$ in single-threaded settings, $1.73\times$ to $2.65\times$ with multi-threading. Additionally, runtime load balancing yields an overall inference acceleration of $1.29\times$ to $1.32\times$.

