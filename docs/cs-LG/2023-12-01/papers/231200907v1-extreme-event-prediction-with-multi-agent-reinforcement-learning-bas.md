---
layout: default
title: Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence
---

# Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2312.00907" class="toolbar-btn" target="_blank">üìÑ arXiv: 2312.00907v1</a>
  <a href="https://arxiv.org/pdf/2312.00907.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2312.00907v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2312.00907v1', 'Extreme Event Prediction with Multi-agent Reinforcement Learning-based Parametrization of Atmospheric and Oceanic Turbulence')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Rambod Mojgani, Daniel Waelchli, Yifei Guan, Petros Koumoutsakos, Pedram Hassanzadeh

**ÂàÜÁ±ª**: cs.LG, cs.CE, physics.ao-ph, physics.comp-ph, physics.flu-dyn

**ÂèëÂ∏ÉÊó•Êúü**: 2023-12-01

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Âü∫‰∫éÂ§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÁöÑÊ∞îÂÄôÊûÅÁ´Ø‰∫ã‰ª∂È¢ÑÊµãÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Ê∞îÂÄôÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `ÊπçÊµÅÈó≠Âêà` `ÊûÅÁ´Ø‰∫ã‰ª∂È¢ÑÊµã` `Êï∞ÊçÆÁ®ÄÁº∫` `Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü` `ËÉΩÈáèË∞±` `È´ò‰øùÁúüÊ®°Êãü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊ∞îÂÄôÊ®°ÂûãÂú®Â∞èÂ∞∫Â∫¶ÊπçÊµÅËøáÁ®ãÁöÑË°®Á§∫‰∏äÂ≠òÂú®ÁªìÊûÑ‰∏çÁ°ÆÂÆöÊÄßÔºå‰º†ÁªüÈó≠ÂêàÊñπÊ≥ïÁöÑÂáÜÁ°ÆÊÄß‰∏çË∂≥„ÄÇ
2. Êú¨ÊñáÊèêÂá∫Âà©Áî®ÁßëÂ≠¶Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÔºàSMARLÔºâÊù•Â≠¶‰π†Ê∞îÂÄôÊ®°ÂûãÁöÑÈó≠ÂêàÔºåÂáèÂ∞ëÂØπÈ´ò‰øùÁúüÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊâÄÊèêÊñπÊ≥ïÂú®‰ΩéÂàÜËæ®ÁéáÊ®°Êãü‰∏≠ËÉΩÂ§üÁ®≥ÂÆöÂú∞ÈáçÁé∞È´ò‰øùÁúüÊ®°ÊãüÁöÑÁªüËÆ°ÁâπÊÄßÔºåÂ∞§ÂÖ∂ÊòØÊ¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞ÁöÑÂ∞æÈÉ®„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÂÖ®ÁêÉÊ∞îÂÄôÊ®°ÂûãÔºàGCMsÔºâÊòØÁêÜËß£ÂíåÈ¢ÑÊµãÊ∞îÂÄôÂèòÂåñÁöÑ‰∏ªË¶ÅÂ∑•ÂÖ∑Ôºå‰ΩÜÁî±‰∫éÊï∞ÂÄºÂàÜËæ®ÁéáÊúâÈôêÔºåËøô‰∫õÊ®°ÂûãÂú®Â∞èÂ∞∫Â∫¶ÊπçÊµÅËøáÁ®ãÁöÑË°®Á§∫‰∏äÂ≠òÂú®ÈáçÂ§ßÁªìÊûÑ‰∏çÁ°ÆÂÆöÊÄß„ÄÇ‰º†ÁªüÁöÑÈó≠ÂêàÊñπÊ≥ï‰æùËµñ‰∫éÂêØÂèëÂºèÂíåÁÆÄÂåñÂÅáËÆæÔºåÂØºËá¥Âú®ÊçïÊçâÊ∞îÂÄôÊûÅÁ´Ø‰∫ã‰ª∂Êó∂ÁöÑÂáÜÁ°ÆÊÄß‰∏çË∂≥„ÄÇÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁßëÂ≠¶Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÔºàSMARLÔºâÁöÑÊñπÊ≥ïÔºåÈÄöËøá‰ªÖ‰ΩøÁî®Â∞ëÈáèÈ´ò‰øùÁúüÊ†∑Êú¨ÁöÑËÉΩÈáèË∞±Êù•Â≠¶‰π†Èó≠ÂêàÊ®°ÂûãÔºå‰ªéËÄåÂú®‰ΩéÂàÜËæ®ÁéáÊ®°Êãü‰∏≠Á®≥ÂÆöÂú∞ÈáçÁé∞È´ò‰øùÁúüÊ®°ÊãüÁöÑÁªüËÆ°ÁâπÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÊÉÖÂÜµ‰∏ãÂ±ïÁé∞Âá∫È´òÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥ÂÖ®ÁêÉÊ∞îÂÄôÊ®°ÂûãÂú®Â∞èÂ∞∫Â∫¶ÊπçÊµÅËøáÁ®ã‰∏≠ÁöÑÁªìÊûÑ‰∏çÁ°ÆÂÆöÊÄßÔºåÁé∞ÊúâÊñπÊ≥ï‰æùËµñ‰∫éÂ§ßÈáèÈ´ò‰øùÁúüÊï∞ÊçÆÔºåÂØºËá¥‰∏çÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄß‰∏çË∂≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÈÄöËøáÁßëÂ≠¶Â§öÊô∫ËÉΩ‰ΩìÂº∫ÂåñÂ≠¶‰π†ÔºàSMARLÔºâÊù•Â≠¶‰π†Èó≠ÂêàÊ®°ÂûãÔºåÂà©Áî®ËÉΩÈáèË∞±‰Ωú‰∏∫ËÆ≠ÁªÉ‰ø°Âè∑ÔºåÂáèÂ∞ëÂØπÈ´ò‰øùÁúüÊ†∑Êú¨ÁöÑÈúÄÊ±Ç„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÈááÈõÜ„ÄÅËÉΩÈáèË∞±ËÆ°ÁÆó„ÄÅSMARLËÆ≠ÁªÉÂíåÈó≠ÂêàÊ®°ÂûãÂ∫îÁî®Âõõ‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºåÂΩ¢ÊàêÈó≠ÁéØÂèçÈ¶àÊú∫Âà∂„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÈááÁî®SMARLËøõË°åÈó≠ÂêàÂª∫Ê®°ÔºåÊòæËëóÈôç‰ΩéÂØπÈ´ò‰øùÁúüÊï∞ÊçÆÁöÑ‰æùËµñÔºåÂπ∂ÊèêÈ´ò‰∫ÜÊ®°ÂûãÁöÑÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠Ôºå‰ΩøÁî®‰∫ÜËÉΩÈáèË∞±‰Ωú‰∏∫ÊçüÂ§±ÂáΩÊï∞ÔºåËÆæËÆ°‰∫ÜÈÄÇÂ∫îÊπçÊµÅÁâπÊÄßÁöÑÁΩëÁªúÁªìÊûÑÔºå‰ª•Á°Æ‰øùÊ®°ÂûãËÉΩÂ§üÊçïÊçâÂà∞Â∞èÂ∞∫Â∫¶ËøáÁ®ãÁöÑÁâπÂæÅ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÊâÄÊèêSMARLÊñπÊ≥ïÂú®‰ΩéÂàÜËæ®ÁéáÊ®°Êãü‰∏≠ËÉΩÂ§ü‰ª•ËæÉ‰ΩéÁöÑËÆ°ÁÆóÊàêÊú¨ÈáçÁé∞È´ò‰øùÁúüÊ®°ÊãüÁöÑÁªüËÆ°ÁâπÊÄßÔºåÂ∞§ÂÖ∂ÊòØÂú®Ê¶ÇÁéáÂØÜÂ∫¶ÂáΩÊï∞ÁöÑÂ∞æÈÉ®Ë°®Áé∞Âá∫ÊòæËëóÁöÑÂáÜÁ°ÆÊÄßÊèêÂçá„ÄÇ‰∏é‰º†ÁªüÊñπÊ≥ïÁõ∏ÊØîÔºåÊ®°ÂûãÁöÑÁ®≥ÂÆöÊÄßÂíåÂáÜÁ°ÆÊÄßÂùáÊúâÊòéÊòæÊîπÂñÑÔºåÂ±ïÁ§∫‰∫ÜÂú®Êï∞ÊçÆÁ®ÄÁº∫ÊÉÖÂÜµ‰∏ãÁöÑÈ´òÊΩúÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Ê∞îÂÄôÂèòÂåñÈ¢ÑÊµã„ÄÅÊûÅÁ´ØÂ§©Ê∞î‰∫ã‰ª∂ÁöÑÈ¢ÑË≠¶ÂíåÊµ∑Ê¥ãÁéØÂ¢ÉÁõëÊµãÁ≠â„ÄÇÈÄöËøáÊèêÈ´òÊ∞îÂÄôÊ®°ÂûãÁöÑÂáÜÁ°ÆÊÄßÂíåÁ®≥ÂÆöÊÄßÔºåËÉΩÂ§ü‰∏∫ÊîøÁ≠ñÂà∂ÂÆöËÄÖÂíåÁßëÂ≠¶ÂÆ∂Êèê‰æõÊõ¥ÂèØÈù†ÁöÑÊ∞îÂÄô‰ø°ÊÅØÔºåËøõËÄåÊé®Âä®ÂèØÊåÅÁª≠ÂèëÂ±ïÂíåÁéØÂ¢É‰øùÊä§„ÄÇÊú™Êù•ÔºåËØ•ÊñπÊ≥ïÊúâÊúõÂú®Êï∞ÊçÆÁ®ÄÁº∫ÁöÑÊÉÖÂÜµ‰∏ãÂπøÊ≥õÂ∫îÁî®‰∫éÊ∞îÂÄôÁßëÂ≠¶Á†îÁ©∂„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Global climate models (GCMs) are the main tools for understanding and predicting climate change. However, due to limited numerical resolutions, these models suffer from major structural uncertainties; e.g., they cannot resolve critical processes such as small-scale eddies in atmospheric and oceanic turbulence. Thus, such small-scale processes have to be represented as a function of the resolved scales via closures (parametrization). The accuracy of these closures is particularly important for capturing climate extremes. Traditionally, such closures are based on heuristics and simplifying assumptions about the unresolved physics. Recently, supervised-learned closures, trained offline on high-fidelity data, have been shown to outperform the classical physics-based closures. However, this approach requires a significant amount of high-fidelity training data and can also lead to instabilities. Reinforcement learning is emerging as a potent alternative for developing such closures as it requires only low-order statistics and leads to stable closures. In Scientific Multi-Agent Reinforcement Learning (SMARL) computational elements serve a dual role of discretization points and learning agents. We leverage SMARL and fundamentals of turbulence physics to learn closures for prototypes of atmospheric and oceanic turbulence. The policy is trained using only the enstrophy spectrum, which is nearly invariant and can be estimated from a few high-fidelity samples (these few samples are far from enough for supervised/offline learning). We show that these closures lead to stable low-resolution simulations that, at a fraction of the cost, can reproduce the high-fidelity simulations' statistics, including the tails of the probability density functions. The results demonstrate the high potential of SMARL for closure modeling for GCMs, especially in the regime of scarce data and indirect observations.

