---
layout: default
title: Model-Driven Graph Contrastive Learning
---

# Model-Driven Graph Contrastive Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06212" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.06212v1</a>
  <a href="https://arxiv.org/pdf/2506.06212.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06212v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06212v1', 'Model-Driven Graph Contrastive Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ali Azizpour, Nicolas Zilberstein, Santiago Segarra

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºMGCLä»¥è§£å†³å›¾å¯¹æ¯”å­¦ä¹ ä¸­çš„æ•°æ®å¢å¼ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å›¾å¯¹æ¯”å­¦ä¹ ` `ç”Ÿæˆæ¨¡å‹` `è‡ªç›‘ç£å­¦ä¹ ` `æ•°æ®å¢å¼º` `èšç±»ç®—æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å›¾å¯¹æ¯”å­¦ä¹ æ–¹æ³•ä¾èµ–äºæ‰‹åŠ¨è®¾è®¡çš„å¢å¼ºç­–ç•¥ï¼Œæœªèƒ½è€ƒè™‘æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹å’Œå›¾ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚
2. MGCLé€šè¿‡ä¼°è®¡å›¾ç”Ÿæˆæ¨¡å‹ï¼Œå®šä¹‰æ•°æ®è‡ªé€‚åº”çš„å¢å¼ºè¿‡ç¨‹ï¼Œå¹¶åœ¨å›¾çº§ä»»åŠ¡ä¸­èšç±»æ•°æ®é›†ä»¥æé«˜å¯¹æ¯”å­¦ä¹ æ•ˆæœã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMGCLåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†MGCLï¼Œä¸€ä¸ªæ¨¡å‹é©±åŠ¨çš„å›¾å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨å›¾ç”Ÿæˆæ¨¡å‹ï¼ˆgraphonsï¼‰æŒ‡å¯¼å¯¹æ¯”å­¦ä¹ ï¼Œè€ƒè™‘æ•°æ®çš„æ½œåœ¨ç”Ÿæˆè¿‡ç¨‹ã€‚å›¾å¯¹æ¯”å­¦ä¹ ä½œä¸ºä¸€ç§å¼ºå¤§çš„è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ç¼ºä¹æ ‡æ³¨çš„æƒ…å†µä¸‹å­¦ä¹ èŠ‚ç‚¹æˆ–å›¾çš„è¡¨è¾¾ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºæ‰‹åŠ¨è®¾è®¡çš„å¢å¼ºç­–ç•¥ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨åŒä¸€ç”Ÿæˆæ¨¡å‹ä¸‹å›¾ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚MGCLé€šè¿‡ä¼°è®¡ä¸è§‚å¯Ÿæ•°æ®ç›¸å…³çš„å›¾ç”Ÿæˆæ¨¡å‹ï¼Œå®šä¹‰æ•°æ®è‡ªé€‚åº”çš„å¢å¼ºè¿‡ç¨‹ï¼Œå¹¶åœ¨å›¾çº§ä»»åŠ¡ä¸­å¯¹æ•°æ®é›†è¿›è¡Œèšç±»ï¼Œä¼°è®¡æ¯ç»„çš„å›¾ç”Ÿæˆæ¨¡å‹ï¼Œä»è€Œå®ç°æ›´å…·è¯­ä¹‰å’Œç»“æ„å…±äº«çš„å¯¹æ¯”å¯¹ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMGCLåœ¨åŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å°†ç”Ÿæˆæ¨¡å‹èå…¥å›¾å¯¹æ¯”å­¦ä¹ çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å›¾å¯¹æ¯”å­¦ä¹ æ–¹æ³•åœ¨æ•°æ®å¢å¼ºç­–ç•¥è®¾è®¡ä¸Šçš„ä¸è¶³ï¼Œç‰¹åˆ«æ˜¯è¿™äº›ç­–ç•¥æœªèƒ½è€ƒè™‘æ•°æ®çš„ç”Ÿæˆè¿‡ç¨‹å’Œå›¾ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMGCLçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å›¾ç”Ÿæˆæ¨¡å‹ï¼ˆgraphonsï¼‰æ¥æŒ‡å¯¼å¯¹æ¯”å­¦ä¹ ï¼Œé€šè¿‡ä¼°è®¡ä¸è§‚å¯Ÿæ•°æ®ç›¸å…³çš„å›¾ç”Ÿæˆæ¨¡å‹ï¼Œå®šä¹‰æ•°æ®è‡ªé€‚åº”çš„å¢å¼ºè¿‡ç¨‹ï¼Œä»è€Œæé«˜å¯¹æ¯”å­¦ä¹ çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMGCLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä¼°è®¡ä¸è§‚å¯Ÿæ•°æ®ç›¸å…³çš„å›¾ç”Ÿæˆæ¨¡å‹ï¼›å…¶æ¬¡ï¼ŒåŸºäºè¯¥æ¨¡å‹è¿›è¡Œæ•°æ®è‡ªé€‚åº”çš„å¢å¼ºï¼Œå¹¶åœ¨å›¾çº§ä»»åŠ¡ä¸­å¯¹æ•°æ®é›†è¿›è¡Œèšç±»ï¼Œä¼°è®¡æ¯ç»„çš„å›¾ç”Ÿæˆæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šMGCLçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥å›¾ç”Ÿæˆæ¨¡å‹æ¥æŒ‡å¯¼å¯¹æ¯”å­¦ä¹ çš„å¢å¼ºè¿‡ç¨‹ï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„æ‰‹åŠ¨è®¾è®¡ç­–ç•¥å½¢æˆäº†æœ¬è´¨åŒºåˆ«ï¼Œä½¿å¾—å¢å¼ºè¿‡ç¨‹æ›´å…·æ•°æ®é€‚åº”æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å…³é”®è®¾è®¡ä¸Šï¼ŒMGCLé‡‡ç”¨äº†èšç±»ç®—æ³•æ¥å¯¹æ•°æ®é›†è¿›è¡Œåˆ†ç»„ï¼Œå¹¶ä¸ºæ¯ç»„ä¼°è®¡å›¾ç”Ÿæˆæ¨¡å‹ï¼Œç¡®ä¿å¯¹æ¯”å¯¹èƒ½å¤Ÿåæ˜ å…±äº«çš„è¯­ä¹‰å’Œç»“æ„ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMGCLåœ¨èŠ‚ç‚¹åˆ†ç±»å’Œå›¾åˆ†ç±»ä»»åŠ¡ä¸­å‡å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¼ ç»Ÿæ–¹æ³•æå‡å¹…åº¦è¾¾åˆ°XX%ã€‚è¿™ä¸€ç»“æœçªæ˜¾äº†ç”Ÿæˆæ¨¡å‹åœ¨å›¾å¯¹æ¯”å­¦ä¹ ä¸­çš„é‡è¦æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MGCLçš„ç ”ç©¶æˆæœåœ¨ç¤¾äº¤ç½‘ç»œåˆ†æã€ç”Ÿç‰©ä¿¡æ¯å­¦å’Œæ¨èç³»ç»Ÿç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜å›¾æ•°æ®çš„è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›ï¼ŒMGCLèƒ½å¤Ÿå¸®åŠ©è§£å†³å®é™…é—®é¢˜ï¼Œå¦‚èŠ‚ç‚¹åˆ†ç±»ã€å›¾åˆ†ç±»ç­‰ä»»åŠ¡ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose $\textbf{MGCL}$, a model-driven graph contrastive learning (GCL) framework that leverages graphons (probabilistic generative models for graphs) to guide contrastive learning by accounting for the data's underlying generative process. GCL has emerged as a powerful self-supervised framework for learning expressive node or graph representations without relying on annotated labels, which are often scarce in real-world data. By contrasting augmented views of graph data, GCL has demonstrated strong performance across various downstream tasks, such as node and graph classification. However, existing methods typically rely on manually designed or heuristic augmentation strategies that are not tailored to the underlying data distribution and operate at the individual graph level, ignoring similarities among graphs generated from the same model. Conversely, in our proposed approach, MGCL first estimates the graphon associated with the observed data and then defines a graphon-informed augmentation process, enabling data-adaptive and principled augmentations. Additionally, for graph-level tasks, MGCL clusters the dataset and estimates a graphon per group, enabling contrastive pairs to reflect shared semantics and structure. Extensive experiments on benchmark datasets demonstrate that MGCL achieves state-of-the-art performance, highlighting the advantages of incorporating generative models into GCL.

