---
layout: default
title: SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms
---

# SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.06499" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.06499v2</a>
  <a href="https://arxiv.org/pdf/2506.06499.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.06499v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.06499v2', 'SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Alex Havrilla, Edward Hughes, Mikayel Samvelyan, Jacob Abernethy

**ÂàÜÁ±ª**: cs.LG, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-06 (Êõ¥Êñ∞: 2025-06-17)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SPARQ‰ª•Ëß£ÂÜ≥Â§çÊùÇÊï∞Â≠¶ÈóÆÈ¢òÁîüÊàêÁöÑÊåëÊàò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÂêàÊàêÊï∞ÊçÆÁîüÊàê` `Êï∞Â≠¶ÈóÆÈ¢òÁîüÊàê` `Ë¥®Èáè-Â§öÊ†∑ÊÄßÁÆóÊ≥ï` `Ê®°ÂûãÂæÆË∞É` `Êé®ÁêÜËÉΩÂäõÊèêÂçá` `ÊïôËÇ≤ÊäÄÊúØ` `Êô∫ËÉΩËæÖÂØºÁ≥ªÁªü`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂêàÊàêÊï∞ÊçÆÁîüÊàêÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§çÊùÇÂíåÂ§öÊ†∑ÂåñÈóÆÈ¢òÊó∂Èù¢‰∏¥ÂèØÊâ©Â±ïÊÄßÈôêÂà∂„ÄÇ
2. SPARQÈÄöËøáÂçï‰∏ÄÊ®°ÂûãÁîüÊàêÈ´òË¥®ÈáèÁöÑÂêàÊàêÊï∞Â≠¶ÈóÆÈ¢òÂèäËß£ÂÜ≥ÊñπÊ°àÔºåÂà©Áî®Ëß£Á≠îÁéá‰Ωú‰∏∫ÈöæÂ∫¶ÁöÑ‰ª£ÁêÜ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÂü∫‰∫éÈöæÂ∫¶ËøáÊª§ÁöÑÊï∞ÊçÆÂæÆË∞ÉÂèØÊèêÂçáÊ®°ÂûãÊÄßËÉΩÔºå‰∏îÈ´òË¥®ÈáèÊï∞ÊçÆÊúâÂä©‰∫éÊõ¥Â•ΩÁöÑÊ®°ÂûãÊ≥õÂåñ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âü∫‰∫éÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÁöÑÂêàÊàêÊï∞ÊçÆÁîüÊàêÂ∑≤Êàê‰∏∫ÊèêÂçáÊ®°ÂûãÊé®ÁêÜËÉΩÂäõÁöÑÈáçË¶ÅÊñπÊ≥ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂ∞ÜÂ§ßÂûãÊ®°ÂûãËí∏È¶è‰∏∫Â∞èÂûãÊ®°ÂûãÊàñ‰ΩøÁî®Ëá™ÁÑ∂ÁöÑÁúüÂÆûÈóÆÈ¢òÈôàËø∞Êù•‰øùËØÅÈóÆÈ¢òË¥®ÈáèÔºåËøôÈôêÂà∂‰∫ÜÂÖ∂Âú®Êõ¥Â§çÊùÇÂíåÂ§öÊ†∑ÂåñÈóÆÈ¢òÈ¢ÜÂüüÁöÑÂèØÊâ©Â±ïÊÄß„ÄÇ‰∏∫Ê≠§ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜSPARQÔºö‰∏ÄÁßçÈÄöËøáË¥®Èáè-Â§öÊ†∑ÊÄßÁÆóÊ≥ïÁîüÊàêÈ´òË¥®ÈáèÂíåÂ§öÊ†∑ÂåñÂêàÊàêÊï∞Â≠¶ÈóÆÈ¢òÂèäÂÖ∂Ëß£ÂÜ≥ÊñπÊ°àÂØπÁöÑÊñ∞ÊñπÊ≥ï„ÄÇÈÄöËøáÊµãÈáèÈóÆÈ¢òÁöÑËß£Á≠îÁéá‰Ωú‰∏∫ÈöæÂ∫¶ÁöÑ‰ª£ÁêÜÔºåSPARQ‰ªé‰∏Ä‰∏™ÂåÖÂê´7500‰∏™Ê†∑Êú¨ÁöÑÁßçÂ≠êÊï∞ÊçÆÈõÜÂá∫ÂèëÔºåÁîüÊàêË∂ÖËøá2000‰∏á‰∏™Êñ∞ÁöÑÈóÆÈ¢ò-Ëß£ÂÜ≥ÊñπÊ°àÂØπ„ÄÇÊàë‰ª¨ÂèëÁé∞ÔºåÈÄöËøáÈöæÂ∫¶ËøáÊª§ÁîüÊàêÁöÑÊï∞ÊçÆÂπ∂ÂØπÂêå‰∏ÄÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºåÂèØ‰ª•Â∞ÜÊ®°ÂûãÊÄßËÉΩÊèêÈ´òÂ§öËææ24%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂêàÊàêÊï∞ÊçÆÁîüÊàêÊñπÊ≥ïÂú®Â§çÊùÇÊï∞Â≠¶ÈóÆÈ¢òÈ¢ÜÂüüÁöÑÂèØÊâ©Â±ïÊÄß‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØ‰æùËµñ‰∫éÂ§ßÂûãÊ®°ÂûãÊàñÁúüÂÆûÈóÆÈ¢òÈôàËø∞ÁöÑÂ±ÄÈôêÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöSPARQÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáË¥®Èáè-Â§öÊ†∑ÊÄßÁÆóÊ≥ïÁîüÊàêÂêàÊàêÈóÆÈ¢òÔºåÂà©Áî®Ëß£Á≠îÁéá‰Ωú‰∏∫ÈóÆÈ¢òÈöæÂ∫¶ÁöÑ‰ª£ÁêÜÔºå‰ªéËÄåÂÆûÁé∞È´òÊïà‰∏îÂ§öÊ†∑ÂåñÁöÑÈóÆÈ¢òÁîüÊàê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSPARQÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨Êï∞ÊçÆÁîüÊàê„ÄÅÈöæÂ∫¶ËøáÊª§ÂíåÊ®°ÂûãÂæÆË∞É‰∏â‰∏™‰∏ªË¶ÅÊ®°Âùó„ÄÇÈ¶ñÂÖàÔºå‰ªéÁßçÂ≠êÊï∞ÊçÆÈõÜ‰∏≠ÁîüÊàêÊñ∞ÁöÑÈóÆÈ¢ò-Ëß£ÂÜ≥ÊñπÊ°àÂØπÔºåÁÑ∂ÂêéÊ†πÊçÆÈöæÂ∫¶ËøõË°åËøáÊª§ÔºåÊúÄÂêéÂØπÊ®°ÂûãËøõË°åÂæÆË∞É‰ª•ÊèêÂçáÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSPARQÁöÑÊúÄÂ§ßÂàõÊñ∞Âú®‰∫é‰ªÖ‰ΩøÁî®Âçï‰∏ÄÊ®°ÂûãÁîüÊàêÈ´òË¥®ÈáèÂíåÂ§öÊ†∑ÂåñÁöÑÂêàÊàêÈóÆÈ¢òÔºåÁ™ÅÁ†¥‰∫Ü‰º†ÁªüÊñπÊ≥ïÂØπÂ§ßÂûãÊ®°ÂûãÁöÑ‰æùËµñÔºåÊòæËëóÊèêÈ´ò‰∫ÜÁîüÊàêÊïàÁéáÂíåÈóÆÈ¢òÂ§öÊ†∑ÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊäÄÊúØÁªÜËäÇ‰∏äÔºåSPARQËÆæÁΩÆ‰∫ÜÂêàÈÄÇÁöÑÈöæÂ∫¶ÈòàÂÄºÁî®‰∫éËøáÊª§ÁîüÊàêÁöÑÊï∞ÊçÆÔºåÂπ∂ÈááÁî®ÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞ÂíåÁΩëÁªúÁªìÊûÑÊù•‰ºòÂåñÊ®°ÂûãÁöÑÂæÆË∞ÉËøáÁ®ã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÁªèËøáÈöæÂ∫¶ËøáÊª§ÁöÑÂêàÊàêÊï∞ÊçÆÂæÆË∞ÉÂèØÂ∞ÜÊ®°ÂûãÊÄßËÉΩÊèêÂçáÂ§öËææ24%„ÄÇÊ≠§Â§ñÔºåÁ†îÁ©∂ËøòÁ°ÆËÆ§‰∫ÜÂêàÊàêÈóÆÈ¢òÁöÑÊ®°ÂûãÂíåÊï∞ÊçÆÊâ©Â±ïËßÑÂæãÔºåË°®ÊòéÈ´òË¥®ÈáèÊï∞ÊçÆÊúâÂä©‰∫éÊ®°ÂûãÁöÑÊõ¥Â•ΩÊ≥õÂåñËÉΩÂäõ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SPARQÁöÑÁ†îÁ©∂ÊàêÊûúÂú®ÊïôËÇ≤ÊäÄÊúØ„ÄÅÊô∫ËÉΩËæÖÂØºÁ≥ªÁªüÂèäËá™Âä®ÂåñÈóÆÈ¢òÁîüÊàêÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÁîüÊàêÂ§öÊ†∑ÂåñÁöÑÊï∞Â≠¶ÈóÆÈ¢òÔºåËÉΩÂ§üÊúâÊïàÊèêÂçáÂ≠¶ÁîüÁöÑÂ≠¶‰π†‰ΩìÈ™åÂíåÊ®°ÂûãÁöÑÊé®ÁêÜËÉΩÂäõÔºåÊé®Âä®‰∏™ÊÄßÂåñÂ≠¶‰π†ÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large language model (LLM) driven synthetic data generation has emerged as a powerful method for improving model reasoning capabilities. However, most methods either distill large state-of-the-art models into small students or use natural ground-truth problem statements to guarantee problem statement quality. This limits the scalability of these approaches to more complex and diverse problem domains. To address this, we present SPARQ: Synthetic Problem Generation for Reasoning via Quality-Diversity Algorithms, a novel approach for generating high-quality and diverse synthetic math problem and solution pairs using only a single model by measuring a problem's solve-rate: a proxy for problem difficulty. Starting from a seed dataset of 7.5K samples, we generate over 20 million new problem-solution pairs. We show that filtering the generated data by difficulty and then fine-tuning the same model on the resulting data improves relative model performance by up to 24\%. Additionally, we conduct ablations studying the impact of synthetic data quantity, quality and diversity on model generalization. We find that higher quality, as measured by problem difficulty, facilitates better in-distribution performance. Further, while generating diverse synthetic data does not as strongly benefit in-distribution performance, filtering for more diverse data facilitates more robust OOD generalization. We also confirm the existence of model and data scaling laws for synthetically generated problems, which positively benefit downstream model generalization.

