---
layout: default
title: Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning
---

# Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05826" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05826v1</a>
  <a href="https://arxiv.org/pdf/2506.05826.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05826v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05826v1', 'Learning Along the Arrow of Time: Hyperbolic Geometry for Backward-Compatible Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ngoc Bui, Menglin Yang, Runjin Chen, Leonardo Neves, Mingxuan Ju, Rex Ying, Neil Shah, Tong Zhao

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè¶…æ›²é¢å‡ ä½•æ–¹æ³•ä»¥è§£å†³æ¨¡å‹å…¼å®¹æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è¶…æ›²é¢å‡ ä½•` `è¡¨ç¤ºå­¦ä¹ ` `æ¨¡å‹å…¼å®¹æ€§` `å¯¹æ¯”å¯¹é½` `ä¸ç¡®å®šæ€§å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…¼å®¹æ€§æ–¹æ³•åœ¨å¤„ç†æ—§æ¨¡å‹çš„ä¸ç¡®å®šæ€§æ—¶å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ–°æ¨¡å‹éš¾ä»¥æœ‰æ•ˆå­¦ä¹ ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨è¶…æ›²é¢å‡ ä½•ï¼Œå°†æ—¶é—´ä½œä¸ºæ•æ‰æ¨¡å‹æ¼”å˜çš„è½´å¿ƒï¼Œæå‡åµŒå…¥å¹¶ä¿æŒä»£é™…ä¸€è‡´æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å…¼å®¹æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå±•ç¤ºäº†æ›´å¼ºçš„é€‚åº”æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å‘åå…¼å®¹çš„è¡¨ç¤ºå­¦ä¹ ä½¿å¾—æ›´æ–°åçš„æ¨¡å‹èƒ½å¤Ÿä¸ç°æœ‰æ¨¡å‹æ— ç¼é›†æˆï¼Œé¿å…é‡æ–°å¤„ç†å­˜å‚¨æ•°æ®ã€‚å°½ç®¡å·²æœ‰è¿›å±•ï¼Œç°æœ‰çš„å…¼å®¹æ€§æ–¹æ³•åœ¨æ¬§å‡ é‡Œå¾—ç©ºé—´ä¸­å¿½è§†äº†æ—§åµŒå…¥æ¨¡å‹çš„ä¸ç¡®å®šæ€§ï¼Œå¼ºè¿«æ–°æ¨¡å‹é‡å»ºè¿‡æ—¶çš„è¡¨ç¤ºï¼Œé˜»ç¢äº†æ–°æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ã€‚æœ¬æ–‡æå‡ºè½¬å‘è¶…æ›²é¢å‡ ä½•ï¼Œå°†æ—¶é—´è§†ä¸ºæ•æ‰æ¨¡å‹ä¿¡å¿ƒå’Œæ¼”å˜çš„è‡ªç„¶è½´ã€‚é€šè¿‡å°†åµŒå…¥æå‡åˆ°è¶…æ›²é¢ç©ºé—´ï¼Œå¹¶é™åˆ¶æ›´æ–°åçš„åµŒå…¥ä½äºæ—§åµŒå…¥çš„è•´æ¶µé”¥å†…ï¼Œä¿æŒæ¨¡å‹é—´çš„ä»£é™…ä¸€è‡´æ€§ï¼ŒåŒæ—¶è€ƒè™‘è¡¨ç¤ºçš„ä¸ç¡®å®šæ€§ã€‚ä¸ºè¿›ä¸€æ­¥å¢å¼ºå…¼å®¹æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç¨³å¥çš„å¯¹æ¯”å¯¹é½æŸå¤±ï¼Œæ ¹æ®æ—§åµŒå…¥çš„ä¸ç¡®å®šæ€§åŠ¨æ€è°ƒæ•´å¯¹é½æƒé‡ã€‚å®éªŒéªŒè¯äº†æ‰€ææ–¹æ³•åœ¨å®ç°å…¼å®¹æ€§æ–¹é¢çš„ä¼˜è¶Šæ€§ï¼Œä¸ºæ›´å…·éŸ§æ€§å’Œé€‚åº”æ€§çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿé“ºå¹³äº†é“è·¯ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯åœ¨æ›´æ–°æ¨¡å‹æ—¶å¦‚ä½•æœ‰æ•ˆæ•´åˆæ—§æ¨¡å‹çš„è¡¨ç¤ºï¼Œç°æœ‰æ–¹æ³•åœ¨å¤„ç†æ—§åµŒå…¥çš„ä¸ç¡®å®šæ€§æ—¶å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œå¯¼è‡´æ–°æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è½¬å‘è¶…æ›²é¢å‡ ä½•ï¼Œå°†æ—¶é—´è§†ä¸ºæ¨¡å‹ä¿¡å¿ƒå’Œæ¼”å˜çš„è‡ªç„¶è½´ï¼Œé€šè¿‡å°†åµŒå…¥æå‡åˆ°è¶…æ›²é¢ç©ºé—´æ¥å¤„ç†ä¸ç¡®å®šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å°†æ—§åµŒå…¥æå‡åˆ°è¶…æ›²é¢ç©ºé—´ï¼Œé™åˆ¶æ–°åµŒå…¥åœ¨æ—§åµŒå…¥çš„è•´æ¶µé”¥å†…ï¼Œå¹¶å¼•å…¥åŠ¨æ€è°ƒæ•´çš„å¯¹æ¯”å¯¹é½æŸå¤±ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬åµŒå…¥æå‡ã€çº¦æŸæœºåˆ¶å’Œå¯¹é½æŸå¤±è®¡ç®—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥è¶…æ›²é¢å‡ ä½•è§†è§’æ¥å¤„ç†æ¨¡å‹é—´çš„å…¼å®¹æ€§é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯è€ƒè™‘äº†æ—§åµŒå…¥çš„ä¸ç¡®å®šæ€§ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æ¬§å‡ é‡Œå¾—ç©ºé—´æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†ç¨³å¥çš„å¯¹æ¯”å¯¹é½æŸå¤±ï¼ŒåŠ¨æ€è°ƒæ•´å¯¹é½æƒé‡ä»¥é€‚åº”æ—§åµŒå…¥çš„ä¸ç¡®å®šæ€§ï¼Œç¡®ä¿æ–°æ—§æ¨¡å‹çš„æœ‰æ•ˆå¯¹é½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨å…¼å®¹æ€§æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼Œæ¨¡å‹çš„å…¼å®¹æ€§æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨å­¦ä¹ æ¨¡å‹çš„ç‰ˆæœ¬æ›´æ–°ã€è¿ç§»å­¦ä¹ å’Œåœ¨çº¿å­¦ä¹ ç­‰åœºæ™¯ã€‚é€šè¿‡å®ç°æ¨¡å‹é—´çš„å…¼å®¹æ€§ï¼Œå¯ä»¥æ˜¾è‘—æé«˜ç³»ç»Ÿçš„çµæ´»æ€§å’Œé€‚åº”æ€§ï¼Œå‡å°‘å› æ¨¡å‹æ›´æ–°å¸¦æ¥çš„æ•°æ®å¤„ç†æˆæœ¬ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Backward compatible representation learning enables updated models to integrate seamlessly with existing ones, avoiding to reprocess stored data. Despite recent advances, existing compatibility approaches in Euclidean space neglect the uncertainty in the old embedding model and force the new model to reconstruct outdated representations regardless of their quality, thereby hindering the learning process of the new model. In this paper, we propose to switch perspectives to hyperbolic geometry, where we treat time as a natural axis for capturing a model's confidence and evolution. By lifting embeddings into hyperbolic space and constraining updated embeddings to lie within the entailment cone of the old ones, we maintain generational consistency across models while accounting for uncertainties in the representations. To further enhance compatibility, we introduce a robust contrastive alignment loss that dynamically adjusts alignment weights based on the uncertainty of the old embeddings. Experiments validate the superiority of the proposed method in achieving compatibility, paving the way for more resilient and adaptable machine learning systems.

