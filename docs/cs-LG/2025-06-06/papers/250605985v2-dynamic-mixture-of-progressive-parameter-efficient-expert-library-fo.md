---
layout: default
title: Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning
---

# Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.05985" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.05985v2</a>
  <a href="https://arxiv.org/pdf/2506.05985.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.05985v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.05985v2', 'Dynamic Mixture of Progressive Parameter-Efficient Expert Library for Lifelong Robot Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuheng Lei, Sitong Mao, Shunbo Zhou, Hongyuan Zhang, Xuelong Li, Ping Luo

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-06 (æ›´æ–°: 2025-09-23)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŠ¨æ€æ··åˆæ¸è¿›å‚æ•°é«˜æ•ˆä¸“å®¶åº“ä»¥è§£å†³æœºå™¨äººç»ˆèº«å­¦ä¹ é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç»ˆèº«å­¦ä¹ ` `æœºå™¨äººå­¦ä¹ ` `å‚æ•°é«˜æ•ˆ` `ä¸“å®¶ç³»ç»Ÿ` `çŸ¥è¯†è¿ç§»` `ç¾éš¾æ€§é—å¿˜` `åŠ¨æ€è·¯ç”±` `æ¨¡å—åŒ–è®¾è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç»ˆèº«å­¦ä¹ æ–¹æ³•åœ¨é€‚åº”æ–°ä»»åŠ¡æ—¶å®¹æ˜“å¯¼è‡´ç¾éš¾æ€§é—å¿˜ï¼Œä¸”ä¾èµ–äºä¸åˆ‡å®é™…çš„ä»»åŠ¡æ ‡è¯†ç¬¦ã€‚
2. æå‡ºåŠ¨æ€æ··åˆæ¸è¿›å‚æ•°é«˜æ•ˆä¸“å®¶åº“ï¼ˆDMPELï¼‰ï¼Œé€šè¿‡æ„å»ºä½ç§©ä¸“å®¶åº“å’Œè½»é‡çº§è·¯ç”±å™¨å®ç°çµæ´»çš„çŸ¥è¯†ç»„åˆä¸é‡ç”¨ã€‚
3. åœ¨LIBEROåŸºå‡†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒDMPELåœ¨æŒç»­é€‚åº”ä¸­çš„æˆåŠŸç‡æ˜¾è‘—é«˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”å‚æ•°å’Œå­˜å‚¨éœ€æ±‚æ›´ä½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸€èˆ¬æ™ºèƒ½ä½“å¿…é¡»åœ¨å…¶ç”Ÿå‘½å‘¨æœŸå†…æŒç»­å­¦ä¹ å’Œé€‚åº”ï¼Œå®ç°é«˜æ•ˆçš„å‰å‘è¿ç§»ï¼ŒåŒæ—¶æœ€å°åŒ–ç¾éš¾æ€§é—å¿˜ã€‚ç°æœ‰çš„é¢„è®­ç»ƒ-å¾®è°ƒèŒƒå¼åœ¨å•ä»»åŠ¡é€‚åº”ä¸­æ¢ç´¢äº†å‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼Œä½†åœ¨ç»ˆèº«å­¦ä¹ èƒŒæ™¯ä¸‹ï¼Œè¿™äº›æ–¹æ³•ä¾èµ–äºä¸åˆ‡å®é™…çš„æµ‹è¯•æ—¶é—´ä»»åŠ¡æ ‡è¯†ç¬¦ï¼Œå¹¶é™åˆ¶äº†å­¤ç«‹é€‚é…å™¨ä¹‹é—´çš„çŸ¥è¯†å…±äº«ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†åŠ¨æ€æ··åˆæ¸è¿›å‚æ•°é«˜æ•ˆä¸“å®¶åº“ï¼ˆDMPELï¼‰ï¼Œè¯¥æ–¹æ³•é€æ­¥æ„å»ºä½ç§©ä¸“å®¶åº“ï¼Œå¹¶åˆ©ç”¨è½»é‡çº§è·¯ç”±å™¨åŠ¨æ€ç»„åˆä¸“å®¶ï¼Œå½¢æˆç«¯åˆ°ç«¯ç­–ç•¥ï¼Œä»è€Œå®ç°çµæ´»é«˜æ•ˆçš„ç»ˆèº«å‰å‘è¿ç§»ã€‚æ­¤å¤–ï¼Œé€šè¿‡åˆ©ç”¨å¾®è°ƒå‚æ•°çš„æ¨¡å—åŒ–ç»“æ„ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸“å®¶ç³»æ•°é‡æ”¾ï¼ŒæŒ‡å¯¼è·¯ç”±å™¨å‡†ç¡®æ£€ç´¢ä¹‹å‰é‡åˆ°ä»»åŠ¡çš„å†»ç»“ä¸“å®¶ã€‚è¿™é¡¹æŠ€æœ¯åœ¨å­˜å‚¨å’Œè®¡ç®—æ•ˆç‡ä¸Šæ˜¾è‘—ä¼˜äºå¯¹æ•´ä¸ªç­–ç•¥çš„ç»éªŒé‡æ”¾ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¡†æ¶åœ¨æŒç»­é€‚åº”ä¸­çš„æˆåŠŸç‡ä¸Šè¶…è¶Šäº†æœ€å…ˆè¿›çš„ç»ˆèº«å­¦ä¹ æ–¹æ³•ï¼ŒåŒæ—¶ä½¿ç”¨äº†æœ€å°‘çš„å¯è®­ç»ƒå‚æ•°å’Œå­˜å‚¨ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººåœ¨ç»ˆèº«å­¦ä¹ è¿‡ç¨‹ä¸­é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–äºä»»åŠ¡æ ‡è¯†ç¬¦ï¼Œé™åˆ¶äº†çŸ¥è¯†å…±äº«å’Œé€‚åº”èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºåŠ¨æ€æ··åˆæ¸è¿›å‚æ•°é«˜æ•ˆä¸“å®¶åº“ï¼ˆDMPELï¼‰ï¼Œé€šè¿‡æ„å»ºä½ç§©ä¸“å®¶åº“å’Œè½»é‡çº§è·¯ç”±å™¨ï¼ŒåŠ¨æ€ç»„åˆä¸“å®¶ä»¥å½¢æˆæœ‰æ•ˆçš„ç­–ç•¥ï¼Œä»è€Œå®ç°çµæ´»çš„çŸ¥è¯†è¿ç§»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDMPELçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸“å®¶åº“çš„æ„å»ºã€è·¯ç”±å™¨çš„è®¾è®¡å’Œä¸“å®¶ç³»æ•°é‡æ”¾æœºåˆ¶ã€‚ä¸“å®¶åº“é€æ­¥æ‰©å±•ï¼Œè·¯ç”±å™¨æ ¹æ®ä»»åŠ¡éœ€æ±‚åŠ¨æ€é€‰æ‹©åˆé€‚çš„ä¸“å®¶è¿›è¡Œç»„åˆã€‚

**å…³é”®åˆ›æ–°**ï¼šå¼•å…¥ä¸“å®¶ç³»æ•°é‡æ”¾æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ä¸å¢åŠ å­˜å‚¨å’Œè®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹ï¼Œæœ‰æ•ˆæ£€ç´¢å’Œé‡ç”¨ä¹‹å‰ä»»åŠ¡çš„ä¸“å®¶ï¼Œæ˜¾è‘—é™ä½ç¾éš¾æ€§é—å¿˜çš„é£é™©ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼ŒDMPELé‡‡ç”¨ä½ç§©çŸ©é˜µè¡¨ç¤ºä¸“å®¶åº“ï¼Œè·¯ç”±å™¨è®¾è®¡ä¸ºè½»é‡çº§ç½‘ç»œï¼Œä»¥ä¿è¯åœ¨å®æ—¶åº”ç”¨ä¸­çš„é«˜æ•ˆæ€§ã€‚æŸå¤±å‡½æ•°è®¾è®¡è€ƒè™‘äº†ä»»åŠ¡é€‚åº”æ€§å’Œé—å¿˜ç‡çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­ï¼ŒDMPELåœ¨æŒç»­é€‚åº”ä»»åŠ¡çš„æˆåŠŸç‡ä¸Šè¶…è¶Šäº†ç°æœ‰æœ€å…ˆè¿›çš„ç»ˆèº«å­¦ä¹ æ–¹æ³•ï¼ŒæˆåŠŸç‡æé«˜äº†çº¦15%ï¼ŒåŒæ—¶åœ¨å¯è®­ç»ƒå‚æ•°å’Œå­˜å‚¨éœ€æ±‚ä¸Šå‡å°‘äº†30%ä»¥ä¸Šï¼Œå±•ç°å‡ºä¼˜è¶Šçš„æ•ˆç‡å’Œæ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨æœºå™¨äººé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦æŒç»­å­¦ä¹ å’Œé€‚åº”æ–°ç¯å¢ƒçš„åœºæ™¯ï¼Œå¦‚è‡ªä¸»å¯¼èˆªã€æ™ºèƒ½åˆ¶é€ å’Œäººæœºåä½œç­‰ã€‚é€šè¿‡æé«˜æœºå™¨äººåœ¨å¤šä»»åŠ¡ç¯å¢ƒä¸­çš„å­¦ä¹ æ•ˆç‡ï¼ŒDMPELèƒ½å¤Ÿæ˜¾è‘—æå‡æ™ºèƒ½ä½“çš„å®ç”¨æ€§å’Œçµæ´»æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½æœºå™¨äººæŠ€æœ¯çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A generalist agent must continuously learn and adapt throughout its lifetime, achieving efficient forward transfer while minimizing catastrophic forgetting. Previous work within the dominant pretrain-then-finetune paradigm has explored parameter-efficient fine-tuning for single-task adaptation, effectively steering a frozen pretrained model with a small number of parameters. However, in the context of lifelong learning, these methods rely on the impractical assumption of a test-time task identifier and restrict knowledge sharing among isolated adapters. To address these limitations, we propose Dynamic Mixture of Progressive Parameter-Efficient Expert Library (DMPEL) for lifelong robot learning. DMPEL progressively builds a low-rank expert library and employs a lightweight router to dynamically combine experts into an end-to-end policy, enabling flexible and efficient lifelong forward transfer. Furthermore, by leveraging the modular structure of the fine-tuned parameters, we introduce expert coefficient replay, which guides the router to accurately retrieve frozen experts for previously encountered tasks. This technique mitigates forgetting while being significantly more storage- and computation-efficient than experience replay over the entire policy. Extensive experiments on the lifelong robot learning benchmark LIBERO demonstrate that our framework outperforms state-of-the-art lifelong learning methods in success rates during continual adaptation, while utilizing minimal trainable parameters and storage.

