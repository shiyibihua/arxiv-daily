---
layout: default
title: TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks
---

# TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11844" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11844v1</a>
  <a href="https://arxiv.org/pdf/2506.11844.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11844v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11844v1', 'TrustGLM: Evaluating the Robustness of GraphLLMs Against Prompt, Text, and Structure Attacks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Qihai Zhang, Xinyue Sheng, Yuanfu Sun, Qiaoyu Tan

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

**å¤‡æ³¨**: 12 pages, 5 figures, in KDD 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTrustGLMä»¥è¯„ä¼°GraphLLMså¯¹å¯¹æŠ—æ€§æ”»å‡»çš„é²æ£’æ€§**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å›¾å­¦ä¹ ` `å¯¹æŠ—æ€§æ”»å‡»` `é²æ£’æ€§è¯„ä¼°` `å¤§å‹è¯­è¨€æ¨¡å‹` `é˜²å¾¡æŠ€æœ¯` `æ•°æ®å¢å¼º` `å¯¹æŠ—è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰GraphLLMsåœ¨å¯¹æŠ—æ€§æ”»å‡»ä¸‹çš„é²æ£’æ€§ç ”ç©¶ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨é«˜é£é™©åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. æå‡ºTrustGLMï¼Œé€šè¿‡è¯„ä¼°GraphLLMsåœ¨æ–‡æœ¬ã€å›¾ç»“æ„å’Œæç¤ºæ“æ§ç­‰æ–¹é¢çš„è„†å¼±æ€§ï¼Œå¡«è¡¥è¿™ä¸€ç ”ç©¶ç©ºç™½ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGraphLLMså¯¹æ–‡æœ¬å’Œç»“æ„æ”»å‡»é«˜åº¦æ•æ„Ÿï¼Œä¸”é€šè¿‡æ•°æ®å¢å¼ºå’Œå¯¹æŠ—è®­ç»ƒå¯æ˜¾è‘—æå‡æ¨¡å‹é²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å—å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æˆåŠŸçš„å¯å‘ï¼Œç ”ç©¶è€…ä»¬ä»ä¼ ç»Ÿå›¾å­¦ä¹ æ–¹æ³•è½¬å‘åŸºäºLLMçš„å›¾æ¡†æ¶ï¼Œç§°ä¸ºGraphLLMsã€‚å°½ç®¡GraphLLMså±•ç°å‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œä½†å…¶åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸‹çš„é²æ£’æ€§å°šæœªå¾—åˆ°å……åˆ†æ¢è®¨ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†TrustGLMï¼Œå…¨é¢è¯„ä¼°GraphLLMsåœ¨æ–‡æœ¬ã€å›¾ç»“æ„å’Œæç¤ºæ“æ§ç­‰ä¸‰ä¸ªç»´åº¦ä¸Šçš„è„†å¼±æ€§ã€‚é€šè¿‡åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œæˆ‘ä»¬å‘ç°GraphLLMså¯¹æ–‡æœ¬æ”»å‡»é«˜åº¦æ•æ„Ÿï¼Œæ ‡å‡†å›¾ç»“æ„æ”»å‡»æ–¹æ³•æ˜¾è‘—é™ä½æ¨¡å‹æ€§èƒ½ï¼Œè€Œæç¤ºæ¨¡æ¿ä¸­çš„å€™é€‰æ ‡ç­¾é›†éšæœºæ‰“ä¹±ä¹Ÿä¼šå¯¼è‡´æ€§èƒ½å¤§å¹…ä¸‹é™ã€‚æˆ‘ä»¬è¿˜æ¢è®¨äº†é’ˆå¯¹æ¯ç§æ”»å‡»å‘é‡çš„é˜²å¾¡æŠ€æœ¯ï¼Œæ˜¾ç¤ºå‡ºå¢å¼ºGraphLLMsé²æ£’æ€§çš„æ½œåŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³GraphLLMsåœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶çš„è„†å¼±æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è¯„ä¼°å…¶åœ¨æ–‡æœ¬ã€å›¾ç»“æ„å’Œæç¤ºæ“æ§ç­‰æ–¹é¢çš„é²æ£’æ€§ï¼Œå¯¼è‡´åœ¨å®é™…åº”ç”¨ä¸­å­˜åœ¨æ½œåœ¨é£é™©ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥TrustGLMï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°GraphLLMsåœ¨ä¸åŒæ”»å‡»å‘é‡ä¸‹çš„è¡¨ç°ï¼Œæ—¨åœ¨æ­ç¤ºå…¶è„†å¼±æ€§å¹¶æ¢ç´¢æœ‰æ•ˆçš„é˜²å¾¡ç­–ç•¥ã€‚æ­¤è®¾è®¡æ—¨åœ¨ä¸ºGraphLLMsçš„å®‰å…¨æ€§æä¾›ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTrustGLMçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šæ–‡æœ¬æ”»å‡»ã€å›¾ç»“æ„æ”»å‡»å’Œæç¤ºæ“æ§æ”»å‡»ã€‚æ¯ä¸ªæ¨¡å—é‡‡ç”¨å…ˆè¿›çš„æ”»å‡»ç®—æ³•è¿›è¡Œè¯„ä¼°ï¼Œå¹¶ç»“åˆæ•°æ®å¢å¼ºå’Œå¯¹æŠ—è®­ç»ƒè¿›è¡Œé˜²å¾¡ç­–ç•¥çš„æ¢ç´¢ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°GraphLLMsçš„è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ–‡æœ¬æ”»å‡»å’Œç»“æ„æ”»å‡»æ–¹é¢çš„å‘ç°ï¼Œæ­ç¤ºäº†è¿™äº›æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ½œåœ¨é£é™©ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒTrustGLMæä¾›äº†æ›´å…¨é¢çš„è¯„ä¼°æ¡†æ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†å¤šç§æ”»å‡»ç®—æ³•ï¼Œå¹¶é€šè¿‡æ•°æ®å¢å¼ºå’Œå¯¹æŠ—è®­ç»ƒæ¥æå‡æ¨¡å‹çš„é²æ£’æ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡ç»è¿‡å¤šæ¬¡å®éªŒéªŒè¯ï¼Œä»¥ç¡®ä¿é˜²å¾¡ç­–ç•¥çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGraphLLMså¯¹æ–‡æœ¬æ”»å‡»çš„æ•æ„Ÿæ€§æé«˜ï¼Œä»…ç”¨å°‘é‡è¯­ä¹‰ç›¸ä¼¼çš„è¯æ›¿æ¢å°±èƒ½æ˜¾è‘—é™ä½æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæ ‡å‡†å›¾ç»“æ„æ”»å‡»æ–¹æ³•å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œè€Œæç¤ºæ¨¡æ¿ä¸­å€™é€‰æ ‡ç­¾é›†çš„éšæœºæ‰“ä¹±ä¹Ÿé€ æˆäº†æ˜¾è‘—çš„æ€§èƒ½ä¸‹é™ã€‚é€šè¿‡å¯¹æŠ—è®­ç»ƒå’Œæ•°æ®å¢å¼ºï¼Œæ¨¡å‹é²æ£’æ€§å¾—åˆ°äº†æœ‰æ•ˆæå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤ç½‘ç»œåˆ†æã€æ¨èç³»ç»Ÿå’Œé‡‘èæ¬ºè¯ˆæ£€æµ‹ç­‰é«˜é£é™©åœºæ™¯ã€‚é€šè¿‡æå‡GraphLLMsçš„é²æ£’æ€§ï¼Œå¯ä»¥å¢å¼ºè¿™äº›ç³»ç»Ÿåœ¨é¢å¯¹å¯¹æŠ—æ€§æ”»å‡»æ—¶çš„å®‰å…¨æ€§ï¼Œä»è€Œæé«˜å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚æœªæ¥ï¼ŒTrustGLMçš„ç ”ç©¶æˆæœæœ‰æœ›æ¨åŠ¨æ›´å¤šåˆ›æ–°çš„é˜²å¾¡æŠ€æœ¯çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Inspired by the success of large language models (LLMs), there is a significant research shift from traditional graph learning methods to LLM-based graph frameworks, formally known as GraphLLMs. GraphLLMs leverage the reasoning power of LLMs by integrating three key components: the textual attributes of input nodes, the structural information of node neighborhoods, and task-specific prompts that guide decision-making. Despite their promise, the robustness of GraphLLMs against adversarial perturbations remains largely unexplored-a critical concern for deploying these models in high-stakes scenarios. To bridge the gap, we introduce TrustGLM, a comprehensive study evaluating the vulnerability of GraphLLMs to adversarial attacks across three dimensions: text, graph structure, and prompt manipulations. We implement state-of-the-art attack algorithms from each perspective to rigorously assess model resilience. Through extensive experiments on six benchmark datasets from diverse domains, our findings reveal that GraphLLMs are highly susceptible to text attacks that merely replace a few semantically similar words in a node's textual attribute. We also find that standard graph structure attack methods can significantly degrade model performance, while random shuffling of the candidate label set in prompt templates leads to substantial performance drops. Beyond characterizing these vulnerabilities, we investigate defense techniques tailored to each attack vector through data-augmented training and adversarial training, which show promising potential to enhance the robustness of GraphLLMs. We hope that our open-sourced library will facilitate rapid, equitable evaluation and inspire further innovative research in this field.

