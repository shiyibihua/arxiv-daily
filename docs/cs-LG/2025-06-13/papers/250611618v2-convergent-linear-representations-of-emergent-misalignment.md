---
layout: default
title: Convergent Linear Representations of Emergent Misalignment
---

# Convergent Linear Representations of Emergent Misalignment

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11618" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11618v2</a>
  <a href="https://arxiv.org/pdf/2506.11618.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11618v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11618v2', 'Convergent Linear Representations of Emergent Misalignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Anna Soligo, Edward Turner, Senthooran Rajamanoharan, Neel Nanda

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-06-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–°æ–¹æ³•ä»¥ç†è§£å’Œç¼“è§£æ¨¡å‹çš„ç´§æ€¥å¤±è°ƒç°è±¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ¨¡å‹å¤±è°ƒ` `ç»†è°ƒ` `è¯­è¨€æ¨¡å‹` `é€‚é…å™¨` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•å¯¹å¤§å‹è¯­è¨€æ¨¡å‹çš„ç»†è°ƒå¯èƒ½å¯¼è‡´æ¨¡å‹å‡ºç°æ„å¤–çš„å¤±è°ƒè¡Œä¸ºï¼Œä¸”å…¶æœºåˆ¶å°šä¸æ¸…æ¥šã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ä½¿ç”¨9ä¸ªç§©-1é€‚é…å™¨çš„æœ€å°æ¨¡å‹ï¼Œç ”ç©¶å…¶å¦‚ä½•å¯¼è‡´Qwen2.5-14B-Instructçš„ç´§æ€¥å¤±è°ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒçš„å¤±è°ƒæ¨¡å‹åœ¨å¤±è°ƒè¡¨ç°ä¸Šè¶‹å‘äºç›¸ä¼¼çš„è¡¨ç¤ºï¼Œä¸”å…­ä¸ªé€‚é…å™¨æ™®éå¯¼è‡´å¤±è°ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œç»†è°ƒæ—¶ï¼Œç‹­çª„æ•°æ®é›†å¯èƒ½å¯¼è‡´æ¨¡å‹å‡ºç°å¹¿æ³›çš„å¤±è°ƒè¡Œä¸ºï¼Œè¿™ç§ç°è±¡è¢«ç§°ä¸ºç´§æ€¥å¤±è°ƒã€‚æœ¬æ–‡ç ”ç©¶äº†è¿™ä¸€ç°è±¡çš„æœºåˆ¶ï¼Œå‘ç°ä¸åŒçš„å¤±è°ƒæ¨¡å‹åœ¨å¤±è°ƒè¡¨ç°ä¸Šè¶‹å‘äºç›¸ä¼¼çš„è¡¨ç¤ºã€‚é€šè¿‡æå–ä¸€ä¸ªç»†è°ƒæ¨¡å‹çš„â€œå¤±è°ƒæ–¹å‘â€ï¼Œå¹¶åˆ©ç”¨è¯¥æ–¹å‘æœ‰æ•ˆæŠ‘åˆ¶å…¶ä»–ç»†è°ƒæ¨¡å‹çš„å¤±è°ƒè¡Œä¸ºï¼Œæœ¬æ–‡ä¸ºç†è§£å’Œç¼“è§£æ¨¡å‹å¤±è°ƒæä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç»†è°ƒè¿‡ç¨‹ä¸­å‡ºç°çš„ç´§æ€¥å¤±è°ƒç°è±¡ï¼Œç°æœ‰æ–¹æ³•å¯¹å…¶æœºåˆ¶ç†è§£ä¸è¶³ï¼Œå¯¼è‡´æ— æ³•æœ‰æ•ˆç¼“è§£å¤±è°ƒè¡Œä¸ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒä¸€ä¸ªæœ€å°æ¨¡å‹ï¼Œä½¿ç”¨9ä¸ªç§©-1é€‚é…å™¨ï¼Œç ”ç©¶å¤±è°ƒæ¨¡å‹çš„è¡¨ç¤ºæ”¶æ•›æ€§ï¼Œå¹¶æå–â€œå¤±è°ƒæ–¹å‘â€ä»¥æŠ‘åˆ¶å¤±è°ƒè¡Œä¸ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ¨¡å‹è®­ç»ƒã€å¤±è°ƒæ–¹å‘æå–å’Œç»†è°ƒæ¨¡å‹çš„è¡Œä¸ºæŠ‘åˆ¶ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆè®­ç»ƒæ¨¡å‹ï¼Œç„¶åä»æ¿€æ´»ä¸­æå–å¤±è°ƒæ–¹å‘ï¼Œæœ€ååº”ç”¨äºå…¶ä»–ç»†è°ƒæ¨¡å‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå‘ç°ä¸åŒçš„å¤±è°ƒæ¨¡å‹åœ¨å¤±è°ƒè¡¨ç°ä¸Šè¶‹å‘äºç›¸ä¼¼çš„è¡¨ç¤ºï¼Œå¹¶é€šè¿‡æå–å¤±è°ƒæ–¹å‘å®ç°æœ‰æ•ˆçš„è¡Œä¸ºæŠ‘åˆ¶ï¼Œè¿™åœ¨ç°æœ‰ç ”ç©¶ä¸­å°šæœªè¢«å……åˆ†æ¢è®¨ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œä½¿ç”¨äº†ç§©-1 LoRAsçš„æ ‡é‡éšè—çŠ¶æ€ï¼Œè®¾è®¡äº†å¤šä¸ªå®éªŒæ¥ç›´æ¥è§£é‡Šç»†è°ƒé€‚é…å™¨çš„ä½œç”¨ï¼Œå‘ç°å…­ä¸ªé€‚é…å™¨æ™®éå¯¼è‡´å¤±è°ƒï¼Œè€Œä¸¤ä¸ªé€‚é…å™¨ä¸“é—¨é’ˆå¯¹ç»†è°ƒé¢†åŸŸçš„å¤±è°ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡æå–çš„å¤±è°ƒæ–¹å‘ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠ‘åˆ¶å…¶ä»–ç»†è°ƒæ¨¡å‹çš„å¤±è°ƒè¡Œä¸ºï¼Œä¸”åœ¨ä¸åŒæ•°æ®é›†å’Œé«˜ç»´LoRAsçš„åº”ç”¨ä¸­å‡è¡¨ç°å‡ºæ˜¾è‘—çš„æ•ˆæœã€‚è¿™ä¸€æ–¹æ³•ä¸ºç†è§£å’Œç¼“è§£æ¨¡å‹å¤±è°ƒæä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§å‹è¯­è¨€æ¨¡å‹çš„å¼€å‘ä¸ä¼˜åŒ–ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦é«˜å¯é æ€§çš„ä»»åŠ¡ä¸­ï¼Œå¦‚è‡ªåŠ¨é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆç­‰ã€‚é€šè¿‡æ·±å…¥ç†è§£å¤±è°ƒç°è±¡ï¼Œç ”ç©¶è€…å¯ä»¥è®¾è®¡å‡ºæ›´ä¸ºç¨³å¥çš„æ¨¡å‹ï¼Œå‡å°‘æ„å¤–è¡Œä¸ºçš„å‘ç”Ÿï¼Œæé«˜æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯æ§æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Fine-tuning large language models on narrow datasets can cause them to develop broadly misaligned behaviours: a phenomena known as emergent misalignment. However, the mechanisms underlying this misalignment, and why it generalizes beyond the training domain, are poorly understood, demonstrating critical gaps in our knowledge of model alignment. In this work, we train and study a minimal model organism which uses just 9 rank-1 adapters to emergently misalign Qwen2.5-14B-Instruct. Studying this, we find that different emergently misaligned models converge to similar representations of misalignment. We demonstrate this convergence by extracting a 'misalignment direction' from one fine-tuned model's activations, and using it to effectively ablate misaligned behaviour from fine-tunes using higher dimensional LoRAs and different datasets. Leveraging the scalar hidden state of rank-1 LoRAs, we further present a set of experiments for directly interpreting the fine-tuning adapters, showing that six contribute to general misalignment, while two specialise for misalignment in just the fine-tuning domain. Emergent misalignment is a particularly salient example of undesirable and unexpected model behaviour and by advancing our understanding of the mechanisms behind it, we hope to move towards being able to better understand and mitigate misalignment more generally.

