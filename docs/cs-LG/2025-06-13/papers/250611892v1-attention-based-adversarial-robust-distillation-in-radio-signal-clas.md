---
layout: default
title: Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices
---

# Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11892" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11892v1</a>
  <a href="https://arxiv.org/pdf/2506.11892.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11892v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11892v1', 'Attention-based Adversarial Robust Distillation in Radio Signal Classifications for Low-Power IoT Devices')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lu Zhang, Sangarapillai Lambotharan, Gan Zheng, Guisheng Liao, Basil AsSadhan, Fabio Roli

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ³¨æ„åŠ›çš„å¯¹æŠ—é²æ£’è’¸é¦æ–¹æ³•ä»¥è§£å†³ä½åŠŸè€—IoTè®¾å¤‡ä¸­çš„ä¿¡å·åˆ†ç±»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯¹æŠ—é²æ£’æ€§` `å˜æ¢å™¨` `ä½åŠŸè€—IoT` `æ— çº¿ä¿¡å·åˆ†ç±»` `è’¸é¦è®­ç»ƒ` `æ³¨æ„åŠ›æœºåˆ¶` `å¯¹æŠ—æ ·æœ¬`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŸºäºå˜æ¢å™¨çš„æ— çº¿ä¿¡å·åˆ†ç±»æ–¹æ³•å¯¹å¯¹æŠ—æ ·æœ¬çš„æ”»å‡»å­˜åœ¨è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä½åŠŸè€—IoTè®¾å¤‡ä¸­ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç´§å‡‘å‹å˜æ¢å™¨ï¼Œé€šè¿‡è½¬ç§»å¯¹æŠ—æ³¨æ„åŠ›å›¾æ¥å¢å¼ºå¯¹æŠ—æ”»å‡»ä¸‹çš„é²æ£’æ€§ï¼Œé€‚åº”ä½åŠŸè€—ç¯å¢ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨ç™½ç›’æ”»å‡»åœºæ™¯ä¸‹çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå±•ç°äº†è‰¯å¥½çš„é˜²å¾¡èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç”±äºå˜æ¢å™¨åœ¨è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªåº”ç”¨ä¸­çš„æˆåŠŸï¼Œå˜æ¢å™¨å·²æˆåŠŸåº”ç”¨äºè‡ªåŠ¨è°ƒåˆ¶åˆ†ç±»ã€‚ç„¶è€Œï¼ŒåŸºäºå˜æ¢å™¨çš„æ— çº¿ä¿¡å·åˆ†ç±»å¯¹ç²¾å¿ƒè®¾è®¡çš„å¯¹æŠ—æ ·æœ¬å­˜åœ¨è„†å¼±æ€§ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é’ˆå¯¹å¯¹æŠ—æ ·æœ¬çš„é˜²å¾¡ç³»ç»Ÿï¼Œç‰¹åˆ«é’ˆå¯¹ä½åŠŸè€—ç‰©è”ç½‘è®¾å¤‡çš„è®¡ç®—æ•ˆç‡éœ€æ±‚ï¼Œè®¾è®¡äº†ä¸€ç§ç´§å‡‘å‹å˜æ¢å™¨ã€‚é€šè¿‡å°†ç»è¿‡é²æ£’è®­ç»ƒçš„å¤§å‹å˜æ¢å™¨çš„å¯¹æŠ—æ³¨æ„åŠ›å›¾è½¬ç§»åˆ°ç´§å‡‘å‹å˜æ¢å™¨ï¼Œæå‡ºçš„æ–¹æ³•åœ¨ç™½ç›’åœºæ™¯ä¸‹è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼ŒåŒ…æ‹¬å¿«é€Ÿæ¢¯åº¦æ³•å’ŒæŠ•å½±æ¢¯åº¦ä¸‹é™æ”»å‡»ã€‚æˆ‘ä»¬è¿˜æ¢è®¨äº†å¯¹æŠ—æ ·æœ¬åœ¨ä¸åŒæ¶æ„ä¹‹é—´çš„å¯è½¬ç§»æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºäºå˜æ¢å™¨çš„æ— çº¿ä¿¡å·åˆ†ç±»åœ¨å¯¹æŠ—æ ·æœ¬æ”»å‡»ä¸‹çš„è„†å¼±æ€§ï¼Œå°¤å…¶æ˜¯åœ¨ä½åŠŸè€—ç‰©è”ç½‘è®¾å¤‡ä¸­çš„åº”ç”¨åœºæ™¯ã€‚ç°æœ‰æ–¹æ³•åœ¨é²æ£’è®­ç»ƒæ–¹é¢çš„ä¼˜åŠ¿åœ¨ç´§å‡‘å‹å˜æ¢å™¨ä¸­éš¾ä»¥å®ç°ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å°†å¤§å‹å˜æ¢å™¨çš„å¯¹æŠ—æ³¨æ„åŠ›å›¾è½¬ç§»åˆ°ç´§å‡‘å‹å˜æ¢å™¨ï¼Œä»è€Œå¢å¼ºå…¶åœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„é²æ£’æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨æé«˜ç´§å‡‘å‹å˜æ¢å™¨çš„é˜²å¾¡èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå…¶è®¡ç®—æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¤§å‹å˜æ¢å™¨å’Œä¸€ä¸ªç´§å‡‘å‹å˜æ¢å™¨ï¼Œé¦–å…ˆå¯¹å¤§å‹å˜æ¢å™¨è¿›è¡Œé²æ£’è®­ç»ƒï¼Œç„¶åæå–å…¶å¯¹æŠ—æ³¨æ„åŠ›å›¾ï¼Œå¹¶å°†å…¶åº”ç”¨äºç´§å‡‘å‹å˜æ¢å™¨çš„è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬å¯¹æŠ—è®­ç»ƒæ¨¡å—å’Œæ³¨æ„åŠ›å›¾è½¬ç§»æ¨¡å—ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå¯¹æŠ—æ³¨æ„åŠ›å›¾çš„è½¬ç§»æœºåˆ¶ï¼Œè¿™ä¸€æœºåˆ¶ä½¿å¾—ç´§å‡‘å‹å˜æ¢å™¨èƒ½å¤Ÿåœ¨å¯¹æŠ—æ”»å‡»ä¸‹è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ï¼Œä¸ä¼ ç»Ÿçš„å¯¹æŠ—è®­ç»ƒæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œç´§å‡‘å‹å˜æ¢å™¨çš„ç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”ä½åŠŸè€—ç¯å¢ƒã€‚æŸå¤±å‡½æ•°è®¾è®¡ä¸­è€ƒè™‘äº†å¯¹æŠ—æ ·æœ¬çš„å½±å“ï¼Œç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½å¤Ÿæœ‰æ•ˆå­¦ä¹ åˆ°å¯¹æŠ—ç‰¹å¾ã€‚å®éªŒä¸­è¿˜å¯¹ä¸åŒæ¶æ„çš„å¯¹æŠ—æ ·æœ¬å¯è½¬ç§»æ€§è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨ç™½ç›’æ”»å‡»åœºæ™¯ä¸‹çš„åˆ†ç±»å‡†ç¡®ç‡è¶…è¿‡äº†ç°æœ‰çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°äº†15%ä»¥ä¸Šï¼Œè¯æ˜äº†å…¶åœ¨å¯¹æŠ—é²æ£’æ€§æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ä½åŠŸè€—ç‰©è”ç½‘è®¾å¤‡ä¸­çš„æ— çº¿ä¿¡å·åˆ†ç±»ï¼Œå¦‚æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œæ™ºèƒ½äº¤é€šç­‰åœºæ™¯ã€‚é€šè¿‡å¢å¼ºæ¨¡å‹çš„é²æ£’æ€§ï¼Œèƒ½å¤Ÿæé«˜è®¾å¤‡åœ¨æ¶åŠ£ç¯å¢ƒä¸‹çš„ä¿¡å·è¯†åˆ«èƒ½åŠ›ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Due to great success of transformers in many applications such as natural language processing and computer vision, transformers have been successfully applied in automatic modulation classification. We have shown that transformer-based radio signal classification is vulnerable to imperceptible and carefully crafted attacks called adversarial examples. Therefore, we propose a defense system against adversarial examples in transformer-based modulation classifications. Considering the need for computationally efficient architecture particularly for Internet of Things (IoT)-based applications or operation of devices in environment where power supply is limited, we propose a compact transformer for modulation classification. The advantages of robust training such as adversarial training in transformers may not be attainable in compact transformers. By demonstrating this, we propose a novel compact transformer that can enhance robustness in the presence of adversarial attacks. The new method is aimed at transferring the adversarial attention map from the robustly trained large transformer to a compact transformer. The proposed method outperforms the state-of-the-art techniques for the considered white-box scenarios including fast gradient method and projected gradient descent attacks. We have provided reasoning of the underlying working mechanisms and investigated the transferability of the adversarial examples between different architectures. The proposed method has the potential to protect the transformer from the transferability of adversarial examples.

