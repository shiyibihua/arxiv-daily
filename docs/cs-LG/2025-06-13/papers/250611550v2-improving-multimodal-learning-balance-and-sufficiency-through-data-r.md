---
layout: default
title: Improving Multimodal Learning Balance and Sufficiency through Data Remixing
---

# Improving Multimodal Learning Balance and Sufficiency through Data Remixing

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11550" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11550v2</a>
  <a href="https://arxiv.org/pdf/2506.11550.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11550v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11550v2', 'Improving Multimodal Learning Balance and Sufficiency through Data Remixing')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaoyu Ma, Hao Chen, Yongjian Deng

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13 (æ›´æ–°: 2025-06-16)

**å¤‡æ³¨**: ICML2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/MatthewMaxy/Remix_ICML2025)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤šæ¨¡æ€æ•°æ®é‡æ··åˆä»¥è§£å†³æ¨¡æ€ä¸å¹³è¡¡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `æ•°æ®é‡æ··åˆ` `æ¨¡æ€å¹³è¡¡` `ä¼˜åŒ–æ–¹æ³•` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•æœªèƒ½æœ‰æ•ˆè§£å†³æ¨¡æ€ä¹‹é—´çš„ä¼˜åŒ–ä¸å¹³è¡¡å’Œæ¨¡æ€å†²çªé—®é¢˜ï¼Œå¯¼è‡´å­¦ä¹ æ•ˆæœä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºçš„å¤šæ¨¡æ€æ•°æ®é‡æ··åˆæ–¹æ³•é€šè¿‡è§£è€¦å’Œé‡ç»„æ•°æ®ï¼Œæ—¨åœ¨åŒæ—¶æå‡å•æ¨¡æ€å­¦ä¹ çš„å……åˆ†æ€§å’Œå¤šæ¨¡æ€å­¦ä¹ çš„å¹³è¡¡æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨CREMADå’ŒKinetic-Soundsæ•°æ®é›†ä¸Šåˆ†åˆ«æé«˜äº†6.50%å’Œ3.41%çš„å‡†ç¡®ç‡ï¼Œä¸”æ— éœ€é¢å¤–è®¡ç®—å¼€é”€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸åŒæ¨¡æ€åœ¨ä¼˜åŒ–è½¨è¿¹ä¸Šå­˜åœ¨æ˜¾è‘—å·®è·ï¼ŒåŒ…æ‹¬é€Ÿåº¦å’Œè·¯å¾„ï¼Œè¿™å¯¼è‡´åœ¨è”åˆè®­ç»ƒå¤šæ¨¡æ€æ¨¡å‹æ—¶å‡ºç°æ¨¡æ€æ‡’æƒ°å’Œæ¨¡æ€å†²çªï¼Œè¿›è€Œå¯¼è‡´å¤šæ¨¡æ€å­¦ä¹ çš„ä¸è¶³å’Œä¸å¹³è¡¡ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦é€šè¿‡æ·»åŠ æ¨¡æ€ç‰¹å®šçš„ä¼˜åŒ–ç›®æ ‡ã€å¯¹é½ä¼˜åŒ–é€Ÿåº¦æˆ–åˆ†è§£å¤šæ¨¡æ€å­¦ä¹ æ¥å¢å¼ºå•æ¨¡æ€å­¦ä¹ ï¼Œä½†æœªèƒ½åŒæ—¶å®ç°å•æ¨¡æ€çš„å……åˆ†æ€§å’Œå¤šæ¨¡æ€çš„å¹³è¡¡ã€‚æœ¬æ–‡é¦–æ¬¡æå‡ºå¤šæ¨¡æ€æ•°æ®é‡æ··åˆï¼Œé€šè¿‡è§£è€¦å¤šæ¨¡æ€æ•°æ®å’Œè¿‡æ»¤æ¯ä¸ªæ¨¡æ€çš„å›°éš¾æ ·æœ¬æ¥ç¼“è§£æ¨¡æ€ä¸å¹³è¡¡ï¼Œå¹¶è¿›è¡Œæ‰¹é‡çº§é‡ç»„ä»¥å¯¹é½æ¢¯åº¦æ–¹å‘ï¼Œé¿å…è·¨æ¨¡æ€å¹²æ‰°ï¼Œä»è€Œå¢å¼ºå•æ¨¡æ€å­¦ä¹ çš„å……åˆ†æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å¯ä¸ç°æœ‰æ–¹æ³•æ— ç¼é›†æˆï¼Œåœ¨CREMADä¸Šæé«˜çº¦6.50%çš„å‡†ç¡®ç‡ï¼Œåœ¨Kinetic-Soundsä¸Šæé«˜çº¦3.41%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ— éœ€æ‰©å±•è®­ç»ƒé›†æˆ–å¢åŠ é¢å¤–è®¡ç®—å¼€é”€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å­¦ä¹ ä¸­æ¨¡æ€ä¹‹é—´çš„ä¼˜åŒ–ä¸å¹³è¡¡å’Œæ¨¡æ€å†²çªé—®é¢˜ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡å¢åŠ æ¨¡æ€ç‰¹å®šçš„ä¼˜åŒ–ç›®æ ‡æ¥å¼ºåŒ–å¼±æ¨¡æ€ï¼Œä½†æœªèƒ½å®ç°å•æ¨¡æ€çš„å……åˆ†æ€§å’Œå¤šæ¨¡æ€çš„å¹³è¡¡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„å¤šæ¨¡æ€æ•°æ®é‡æ··åˆæ–¹æ³•é€šè¿‡è§£è€¦å¤šæ¨¡æ€æ•°æ®å’Œè¿‡æ»¤å›°éš¾æ ·æœ¬æ¥ç¼“è§£æ¨¡æ€ä¸å¹³è¡¡ï¼Œéšåé€šè¿‡æ‰¹é‡çº§é‡ç»„å¯¹é½æ¢¯åº¦æ–¹å‘ï¼Œé¿å…è·¨æ¨¡æ€å¹²æ‰°ï¼Œä»è€Œå¢å¼ºå•æ¨¡æ€å­¦ä¹ çš„å……åˆ†æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯å¯¹å¤šæ¨¡æ€æ•°æ®è¿›è¡Œè§£è€¦å’Œæ ·æœ¬è¿‡æ»¤ï¼Œä»¥å‡è½»æ¨¡æ€é—´çš„ä¸å¹³è¡¡ï¼›å…¶æ¬¡æ˜¯è¿›è¡Œæ‰¹é‡çº§é‡ç»„ï¼Œä»¥ç¡®ä¿æ¢¯åº¦æ–¹å‘çš„ä¸€è‡´æ€§å¹¶å‡å°‘å¹²æ‰°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•é¦–æ¬¡åŒæ—¶å…³æ³¨å•æ¨¡æ€çš„å……åˆ†æ€§å’Œå¤šæ¨¡æ€çš„å¹³è¡¡ï¼Œæå‡ºäº†æ•°æ®é‡æ··åˆçš„æ¦‚å¿µï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è§£å†³æ¨¡æ€é—´çš„å†²çªå’Œä¸å¹³è¡¡é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬æ ·æœ¬è¿‡æ»¤çš„é˜ˆå€¼è®¾ç½®å’Œæ‰¹é‡é‡ç»„çš„ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šè€ƒè™‘äº†æ¨¡æ€é—´çš„ç›¸äº’å½±å“ï¼Œç¡®ä¿äº†ä¼˜åŒ–è¿‡ç¨‹çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæå‡äº†æ¨¡å‹çš„æ•´ä½“æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„å¤šæ¨¡æ€æ•°æ®é‡æ··åˆæ–¹æ³•åœ¨CREMADæ•°æ®é›†ä¸Šæé«˜äº†çº¦6.50%çš„å‡†ç¡®ç‡ï¼Œåœ¨Kinetic-Soundsæ•°æ®é›†ä¸Šæé«˜äº†çº¦3.41%çš„å‡†ç¡®ç‡ï¼Œä¸”åœ¨æ¨ç†è¿‡ç¨‹ä¸­æœªå¢åŠ é¢å¤–çš„è®¡ç®—å¼€é”€ï¼Œè¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æã€è§†é¢‘ç†è§£å’Œè¯­éŸ³è¯†åˆ«ç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€å­¦ä¹ çš„æ•ˆæœï¼Œèƒ½å¤Ÿåœ¨å®é™…åº”ç”¨ä¸­å®ç°æ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½å½±å“å¤šæ¨¡æ€ç³»ç»Ÿçš„è®¾è®¡å’Œä¼˜åŒ–ç­–ç•¥ï¼Œä¿ƒè¿›æ›´æ™ºèƒ½çš„äº¤äº’ç³»ç»Ÿçš„å®ç°ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Different modalities hold considerable gaps in optimization trajectories, including speeds and paths, which lead to modality laziness and modality clash when jointly training multimodal models, resulting in insufficient and imbalanced multimodal learning. Existing methods focus on enforcing the weak modality by adding modality-specific optimization objectives, aligning their optimization speeds, or decomposing multimodal learning to enhance unimodal learning. These methods fail to achieve both unimodal sufficiency and multimodal balance. In this paper, we, for the first time, address both concerns by proposing multimodal Data Remixing, including decoupling multimodal data and filtering hard samples for each modality to mitigate modality imbalance; and then batch-level reassembling to align the gradient directions and avoid cross-modal interference, thus enhancing unimodal learning sufficiency. Experimental results demonstrate that our method can be seamlessly integrated with existing approaches, improving accuracy by approximately 6.50%$\uparrow$ on CREMAD and 3.41%$\uparrow$ on Kinetic-Sounds, without training set expansion or additional computational overhead during inference. The source code is available at https://github.com/MatthewMaxy/Remix_ICML2025.

