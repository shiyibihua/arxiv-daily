---
layout: default
title: Visual Pre-Training on Unlabeled Images using Reinforcement Learning
---

# Visual Pre-Training on Unlabeled Images using Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11967" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11967v1</a>
  <a href="https://arxiv.org/pdf/2506.11967.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11967v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11967v1', 'Visual Pre-Training on Unlabeled Images using Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dibya Ghosh, Sergey Levine

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„æ— æ ‡ç­¾å›¾åƒé¢„è®­ç»ƒæ–¹æ³•ä»¥æå‡ç‰¹å¾å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ— æ ‡ç­¾å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `è‡ªç›‘ç£å­¦ä¹ ` `ç‰¹å¾å­¦ä¹ ` `å›¾åƒé¢„è®­ç»ƒ` `è®¡ç®—æœºè§†è§‰` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è‡ªç›‘ç£å›¾åƒé¢„è®­ç»ƒæ–¹æ³•åœ¨ç‰¹å¾å­¦ä¹ ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æ— æ ‡ç­¾æ•°æ®ã€‚
2. æœ¬æ–‡æå‡ºå°†æ— æ ‡ç­¾å›¾åƒæ•°æ®çš„é¢„è®­ç»ƒè§†ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œé€šè¿‡ä»·å€¼å‡½æ•°è®­ç»ƒä»£ç†è¿›è¡Œå›¾åƒè½¬æ¢ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤šç§æ•°æ®é›†ä¸Šè¿›è¡Œæ— æ ‡ç­¾å›¾åƒè®­ç»ƒæ—¶ï¼Œç‰¹å¾è¡¨ç¤ºèƒ½åŠ›æ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¼ºåŒ–å­¦ä¹ ä¸­ï¼ŒåŸºäºä»·å€¼çš„ç®—æ³•å­¦ä¹ å°†æ¯ä¸ªè§‚å¯Ÿä¸å¯èƒ½è¾¾åˆ°çš„çŠ¶æ€å’Œå¥–åŠ±å…³è”ã€‚æˆ‘ä»¬è§‚å¯Ÿåˆ°è®¸å¤šè‡ªç›‘ç£å›¾åƒé¢„è®­ç»ƒæ–¹æ³•ä¸æ­¤ç›¸ä¼¼ï¼šå­¦ä¹ å°†å›¾åƒçš„è£å‰ªä¸é™„è¿‘è§†å›¾å…³è”ã€‚æœ¬æ–‡å°†æ— æ ‡ç­¾å›¾åƒæ•°æ®çš„é¢„è®­ç»ƒç›´æ¥è§†ä¸ºå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œè®­ç»ƒä¸€ä¸ªé€šç”¨ä»·å€¼å‡½æ•°ï¼Œä»£ç†é€šè¿‡æ”¹å˜è§†è§’æˆ–æ·»åŠ å›¾åƒå¢å¼ºæ¥è½¬æ¢å›¾åƒã€‚è¿™ç§å­¦ä¹ æ–¹å¼ç±»ä¼¼äºè£å‰ªä¸€è‡´æ€§è‡ªç›‘ç£ï¼Œä½†é€šè¿‡å¥–åŠ±å‡½æ•°æä¾›äº†ä¸€ä¸ªç®€å•çš„æ æ†ï¼Œä»¥åˆ©ç”¨ç­–åˆ’çš„å›¾åƒæˆ–å¼±æ ‡æ³¨çš„æ ‡é¢˜æ¥å¡‘é€ ç‰¹å¾å­¦ä¹ ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨é‡å¤–æ— æ ‡ç­¾å›¾åƒä¸Šè®­ç»ƒæ—¶ï¼Œè¡¨ç¤ºèƒ½åŠ›å¾—åˆ°äº†æå‡ï¼ŒåŒ…æ‹¬è§†é¢‘æ•°æ®ï¼ˆå¦‚EpicKitchensï¼‰ã€åœºæ™¯æ•°æ®ï¼ˆå¦‚COCOï¼‰å’Œç½‘ç»œçˆ¬è™«æ•°æ®ï¼ˆå¦‚CC12Mï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰è‡ªç›‘ç£å›¾åƒé¢„è®­ç»ƒæ–¹æ³•åœ¨æ— æ ‡ç­¾æ•°æ®åˆ©ç”¨ä¸Šçš„ä¸è¶³ï¼Œå°¤å…¶æ˜¯åœ¨ç‰¹å¾å­¦ä¹ çš„æœ‰æ•ˆæ€§æ–¹é¢ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•å……åˆ†æŒ–æ˜æ— æ ‡ç­¾å›¾åƒä¸­çš„æ½œåœ¨ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ— æ ‡ç­¾å›¾åƒçš„é¢„è®­ç»ƒè¿‡ç¨‹è§†ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ é—®é¢˜ï¼Œé€šè¿‡è®­ç»ƒä¸€ä¸ªä»·å€¼å‡½æ•°ï¼Œä½¿ä»£ç†èƒ½å¤Ÿé€šè¿‡æ”¹å˜è§†è§’æˆ–æ·»åŠ å›¾åƒå¢å¼ºæ¥å­¦ä¹ ç‰¹å¾ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç‰¹å¾å­¦ä¹ è¿‡ç¨‹æ›´å…·çµæ´»æ€§å’Œé€‚åº”æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ä»£ç†ï¼Œè¯¥ä»£ç†åœ¨åŠ¨æ€ç³»ç»Ÿä¸­æ“ä½œï¼Œé€šè¿‡å›¾åƒçš„ä¸åŒè§†è§’å’Œå¢å¼ºæ–¹å¼è¿›è¡Œè®­ç»ƒã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬çŠ¶æ€è¡¨ç¤ºã€åŠ¨ä½œé€‰æ‹©å’Œå¥–åŠ±åé¦ˆæœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå°†å›¾åƒé¢„è®­ç»ƒä¸å¼ºåŒ–å­¦ä¹ ç»“åˆï¼Œåˆ©ç”¨å¥–åŠ±å‡½æ•°æ¥å¼•å¯¼ç‰¹å¾å­¦ä¹ ã€‚è¿™ä¸ä¼ ç»Ÿçš„è‡ªç›‘ç£å­¦ä¹ æ–¹æ³•æœ¬è´¨ä¸Šæœ‰æ‰€ä¸åŒï¼Œåè€…é€šå¸¸ä¾èµ–äºé™æ€çš„æŸå¤±å‡½æ•°ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œè®¾è®¡äº†é€‚åº”æ€§å¥–åŠ±æœºåˆ¶ä»¥ä¼˜åŒ–ç‰¹å¾å­¦ä¹ æ•ˆæœã€‚æŸå¤±å‡½æ•°ç»“åˆäº†è£å‰ªä¸€è‡´æ€§å’Œå¥–åŠ±åé¦ˆï¼Œç½‘ç»œç»“æ„åˆ™é‡‡ç”¨äº†æ·±åº¦å·ç§¯ç½‘ç»œä»¥å¢å¼ºç‰¹å¾æå–èƒ½åŠ›ã€‚é€šè¿‡è¿™äº›è®¾è®¡ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒç±»å‹çš„æ— æ ‡ç­¾å›¾åƒæ•°æ®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä½¿ç”¨è¯¥æ–¹æ³•åœ¨EpicKitchensã€COCOå’ŒCC12Mç­‰æ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶ç‰¹å¾è¡¨ç¤ºèƒ½åŠ›ç›¸æ¯”äºä¼ ç»Ÿæ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨å¤šä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸Šå–å¾—äº†æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸­çš„å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œè§†é¢‘ç†è§£ç­‰ä»»åŠ¡ã€‚é€šè¿‡æœ‰æ•ˆåˆ©ç”¨æ— æ ‡ç­¾æ•°æ®ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé€‚åº”æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨å¤§è§„æ¨¡æ— æ ‡ç­¾æ•°æ®çš„å¤„ç†å’Œåˆ†æä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In reinforcement learning (RL), value-based algorithms learn to associate each observation with the states and rewards that are likely to be reached from it. We observe that many self-supervised image pre-training methods bear similarity to this formulation: learning features that associate crops of images with those of nearby views, e.g., by taking a different crop or color augmentation. In this paper, we complete this analogy and explore a method that directly casts pre-training on unlabeled image data like web crawls and video frames as an RL problem. We train a general value function in a dynamical system where an agent transforms an image by changing the view or adding image augmentations. Learning in this way resembles crop-consistency self-supervision, but through the reward function, offers a simple lever to shape feature learning using curated images or weakly labeled captions when they exist. Our experiments demonstrate improved representations when training on unlabeled images in the wild, including video data like EpicKitchens, scene data like COCO, and web-crawl data like CC12M.

