---
layout: default
title: Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs
---

# Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.11415" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.11415v1</a>
  <a href="https://arxiv.org/pdf/2506.11415.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.11415v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.11415v1', 'Bias Amplification in RAG: Poisoning Knowledge Retrieval to Steer LLMs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linlin Wang, Tianqing Zhu, Laiqiao Qin, Longxiang Gao, Wanlei Zhou

**åˆ†ç±»**: cs.LG, cs.CL, cs.CR

**å‘å¸ƒæ—¥æœŸ**: 2025-06-13

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBRRAæ¡†æ¶ä»¥è§£å†³RAGç³»ç»Ÿä¸­çš„åè§æ”¾å¤§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åè§æ”¾å¤§` `æ£€ç´¢å¢å¼ºç”Ÿæˆ` `æ¯’åŒ–æ”»å‡»` `å¯¹æŠ—æ€§ç”Ÿæˆ` `æ¨¡å‹å…¬å¹³æ€§` `åŒé˜¶æ®µé˜²å¾¡` `å¤šç›®æ ‡å¥–åŠ±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨RAGç³»ç»Ÿä¸­çš„æ¯’åŒ–æ”»å‡»å¯¹æ¨¡å‹è¾“å‡ºè´¨é‡çš„å½±å“ï¼Œå¿½è§†äº†å…¶æ”¾å¤§æ¨¡å‹åè§çš„æ½œåŠ›ã€‚
2. æœ¬æ–‡æå‡ºBRRAæ¡†æ¶ï¼Œé€šè¿‡å¯¹æŠ—æ–‡æ¡£ç”Ÿæˆå’Œæ£€ç´¢ç»“æœæ“æ§ï¼Œç³»ç»Ÿæ€§æ”¾å¤§è¯­è¨€æ¨¡å‹çš„åè§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBRRAæ”»å‡»æ˜¾è‘—å¢å¼ºäº†å¤šä¸ªä¸»æµå¤§å‹è¯­è¨€æ¨¡å‹çš„åè§ï¼Œå¹¶æå‡ºäº†æœ‰æ•ˆçš„é˜²å¾¡æœºåˆ¶ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­ï¼Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç³»ç»Ÿé€šè¿‡æ•´åˆå¤–éƒ¨çŸ¥è¯†æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚ç„¶è€Œï¼ŒRAGä¹Ÿå¸¦æ¥äº†æ–°çš„å®‰å…¨é£é™©ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦å…³æ³¨æ¯’åŒ–æ”»å‡»å¯¹æ¨¡å‹è¾“å‡ºè´¨é‡çš„å½±å“ï¼Œå¿½è§†äº†å…¶å¯èƒ½æ”¾å¤§æ¨¡å‹åè§çš„æ½œåŠ›ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åè§æ£€ç´¢ä¸å¥–åŠ±æ”»å‡»ï¼ˆBRRAï¼‰æ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°ç ”ç©¶äº†é€šè¿‡RAGç³»ç»Ÿæ“æ§æ”¾å¤§è¯­è¨€æ¨¡å‹åè§çš„æ”»å‡»è·¯å¾„ã€‚æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§åŸºäºå¤šç›®æ ‡å¥–åŠ±å‡½æ•°çš„å¯¹æŠ—æ–‡æ¡£ç”Ÿæˆæ–¹æ³•ï¼Œé‡‡ç”¨å­ç©ºé—´æŠ•å½±æŠ€æœ¯æ“æ§æ£€ç´¢ç»“æœï¼Œå¹¶æ„å»ºäº†ä¸€ä¸ªå¾ªç¯åé¦ˆæœºåˆ¶ä»¥å®ç°æŒç»­çš„åè§æ”¾å¤§ã€‚å®éªŒè¡¨æ˜ï¼ŒBRRAæ”»å‡»èƒ½æ˜¾è‘—å¢å¼ºæ¨¡å‹åœ¨å¤šä¸ªç»´åº¦ä¸Šçš„åè§ï¼Œå¹¶æ¢è®¨äº†ä¸€ç§åŒé˜¶æ®µé˜²å¾¡æœºåˆ¶ä»¥æœ‰æ•ˆå‡è½»æ”»å‡»å½±å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³RAGç³»ç»Ÿä¸­æ¯’åŒ–æ”»å‡»å¯¼è‡´çš„æ¨¡å‹åè§æ”¾å¤§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘è¿™äº›æ”»å‡»å¯¹æ¨¡å‹å…¬å¹³æ€§çš„å½±å“ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºBRRAæ¡†æ¶ï¼Œé€šè¿‡å¯¹æŠ—æ€§æ–‡æ¡£ç”Ÿæˆå’Œæ£€ç´¢ç»“æœæ“æ§ï¼Œç³»ç»Ÿæ€§åœ°æ”¾å¤§è¯­è¨€æ¨¡å‹çš„åè§ï¼Œæ­ç¤ºRAGç³»ç»Ÿå®‰å…¨æ€§ä¸æ¨¡å‹å…¬å¹³æ€§ä¹‹é—´çš„å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBRRAæ¡†æ¶åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šå¯¹æŠ—æ–‡æ¡£ç”Ÿæˆæ¨¡å—ã€æ£€ç´¢ç»“æœæ“æ§æ¨¡å—å’Œå¾ªç¯åé¦ˆæœºåˆ¶ã€‚å¯¹æŠ—æ–‡æ¡£ç”Ÿæˆæ¨¡å—åŸºäºå¤šç›®æ ‡å¥–åŠ±å‡½æ•°ç”Ÿæˆåè§æ–‡æ¡£ï¼Œæ£€ç´¢ç»“æœæ“æ§æ¨¡å—åˆ©ç”¨å­ç©ºé—´æŠ•å½±æŠ€æœ¯æ“æ§æ£€ç´¢ç»“æœï¼Œå¾ªç¯åé¦ˆæœºåˆ¶åˆ™å®ç°æŒç»­çš„åè§æ”¾å¤§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†åè§æ£€ç´¢ä¸å¥–åŠ±æ”»å‡»ï¼ˆBRRAï¼‰æ¡†æ¶ï¼Œç³»ç»Ÿæ€§åœ°æ­ç¤ºäº†æ¯’åŒ–æ”»å‡»å¦‚ä½•é€šè¿‡RAGç³»ç»Ÿæ”¾å¤§æ¨¡å‹åè§ï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å¯¹æŠ—æ–‡æ¡£ç”Ÿæˆä¸­ï¼Œé‡‡ç”¨äº†å¤šç›®æ ‡å¥–åŠ±å‡½æ•°ä»¥ä¼˜åŒ–æ–‡æ¡£çš„åè§ç‰¹å¾ï¼›åœ¨æ£€ç´¢ç»“æœæ“æ§ä¸­ï¼Œä½¿ç”¨äº†å­ç©ºé—´æŠ•å½±æŠ€æœ¯ä»¥å®ç°å¯¹æ£€ç´¢ç»“æœçš„ç²¾å‡†æ“æ§ï¼›å¾ªç¯åé¦ˆæœºåˆ¶åˆ™é€šè¿‡ä¸æ–­è°ƒæ•´ç”Ÿæˆæ–‡æ¡£å’Œæ£€ç´¢ç»“æœï¼Œå¢å¼ºäº†åè§æ”¾å¤§çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒBRRAæ”»å‡»èƒ½å¤Ÿåœ¨å¤šä¸ªç»´åº¦ä¸Šæ˜¾è‘—å¢å¼ºæ¨¡å‹åè§ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šã€‚æ­¤å¤–ï¼Œæå‡ºçš„åŒé˜¶æ®µé˜²å¾¡æœºåˆ¶æœ‰æ•ˆå‡è½»äº†æ”»å‡»çš„å½±å“ï¼Œå±•ç¤ºäº†é˜²å¾¡ç­–ç•¥çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬ç¤¾äº¤åª’ä½“å†…å®¹å®¡æ ¸ã€è‡ªåŠ¨åŒ–æ–°é—»ç”Ÿæˆå’Œæ³•å¾‹æ–‡æœ¬åˆ†æç­‰ã€‚é€šè¿‡ç†è§£å’Œç¼“è§£RAGç³»ç»Ÿä¸­çš„åè§æ”¾å¤§é—®é¢˜ï¼Œå¯ä»¥æé«˜è¿™äº›ç³»ç»Ÿçš„å…¬å¹³æ€§å’Œå¯é æ€§ï¼Œè¿›è€Œå½±å“ç¤¾ä¼šå¯¹è‡ªåŠ¨åŒ–å†³ç­–çš„ä¿¡ä»»å’Œæ¥å—åº¦ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> In Large Language Models, Retrieval-Augmented Generation (RAG) systems can significantly enhance the performance of large language models by integrating external knowledge. However, RAG also introduces new security risks. Existing research focuses mainly on how poisoning attacks in RAG systems affect model output quality, overlooking their potential to amplify model biases. For example, when querying about domestic violence victims, a compromised RAG system might preferentially retrieve documents depicting women as victims, causing the model to generate outputs that perpetuate gender stereotypes even when the original query is gender neutral. To show the impact of the bias, this paper proposes a Bias Retrieval and Reward Attack (BRRA) framework, which systematically investigates attack pathways that amplify language model biases through a RAG system manipulation. We design an adversarial document generation method based on multi-objective reward functions, employ subspace projection techniques to manipulate retrieval results, and construct a cyclic feedback mechanism for continuous bias amplification. Experiments on multiple mainstream large language models demonstrate that BRRA attacks can significantly enhance model biases in dimensions. In addition, we explore a dual stage defense mechanism to effectively mitigate the impacts of the attack. This study reveals that poisoning attacks in RAG systems directly amplify model output biases and clarifies the relationship between RAG system security and model fairness. This novel potential attack indicates that we need to keep an eye on the fairness issues of the RAG system.

