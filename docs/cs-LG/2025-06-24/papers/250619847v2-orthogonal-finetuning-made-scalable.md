---
layout: default
title: Orthogonal Finetuning Made Scalable
---

# Orthogonal Finetuning Made Scalable

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.19847" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.19847v2</a>
  <a href="https://arxiv.org/pdf/2506.19847.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.19847v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.19847v2', 'Orthogonal Finetuning Made Scalable')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zeju Qiu, Weiyang Liu, Adrian Weller, Bernhard SchÃ¶lkopf

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-24 (æ›´æ–°: 2025-10-14)

**å¤‡æ³¨**: EMNLP 2025 Main (18 pages, 7 figures, project page: https://spherelab.ai/oftv2/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOFTv2ä»¥è§£å†³æ­£äº¤å¾®è°ƒçš„è®¡ç®—ç“¶é¢ˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ­£äº¤å¾®è°ƒ` `è®¡ç®—æ•ˆç‡` `æ·±åº¦å­¦ä¹ ` `é‡åŒ–æ¨¡å‹` `Cayley-Neumannå‚æ•°åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ­£äº¤å¾®è°ƒæ–¹æ³•åœ¨è®¡ç®—å’Œå†…å­˜éœ€æ±‚ä¸Šå­˜åœ¨æ˜¾è‘—ç“¶é¢ˆï¼Œé™åˆ¶äº†å…¶å®é™…åº”ç”¨ã€‚
2. è®ºæ–‡æå‡ºOFTv2ï¼Œé€šè¿‡è¾“å…¥ä¸­å¿ƒçš„é‡æ„å’ŒçŸ©é˜µ-å‘é‡ä¹˜æ³•ï¼Œæ˜¾è‘—é™ä½è®¡ç®—å¤æ‚åº¦ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒOFTv2åœ¨è®­ç»ƒé€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨ä¸Šå‡æœ‰æ˜¾è‘—æå‡ï¼Œä¸”åœ¨é‡åŒ–æ¨¡å‹å¾®è°ƒä¸­è¡¨ç°ä¼˜è¶Šã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­£äº¤å¾®è°ƒï¼ˆOFTï¼‰æä¾›äº†é«˜æ•ˆçš„å‚æ•°é€‚åº”èƒ½åŠ›ï¼ŒåŒæ—¶é˜²æ­¢ç¾éš¾æ€§é—å¿˜ï¼Œä½†å…¶é«˜è¿è¡Œæ—¶å’Œå†…å­˜éœ€æ±‚é™åˆ¶äº†å®é™…åº”ç”¨ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºOFTçš„æ ¸å¿ƒè®¡ç®—ç“¶é¢ˆåœ¨äºå…¶ä»¥æƒé‡ä¸ºä¸­å¿ƒçš„å®ç°ï¼Œä¾èµ–äºä»£ä»·é«˜æ˜‚çš„çŸ©é˜µä¹˜æ³•ï¼Œå¤æ‚åº¦ä¸ºç«‹æ–¹ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†OFTv2ï¼Œä¸€ç§ä»¥è¾“å…¥ä¸ºä¸­å¿ƒçš„é‡æ„æ–¹æ³•ï¼Œåˆ©ç”¨çŸ©é˜µ-å‘é‡ä¹˜æ³•ï¼ˆå³æ— çŸ©é˜µè®¡ç®—ï¼‰ï¼Œå°†è®¡ç®—æˆæœ¬é™ä½åˆ°å¹³æ–¹çº§åˆ«ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¼•å…¥äº†Cayley-Neumannå‚æ•°åŒ–ï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„æ­£äº¤å‚æ•°åŒ–æ–¹æ³•ï¼Œé€šè¿‡æˆªæ–­çš„Neumannçº§æ•°è¿‘ä¼¼Cayleyå˜æ¢ä¸­çš„çŸ©é˜µé€†ã€‚è¿™äº›ä¿®æ”¹ä½¿OFTv2åœ¨ä¸å½±å“æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†è®­ç»ƒé€Ÿåº¦æé«˜è‡³10å€ï¼ŒGPUå†…å­˜ä½¿ç”¨é™ä½è‡³3å€ã€‚æˆ‘ä»¬è¿˜æ‰©å±•äº†OFTv2ä»¥æ”¯æŒé‡åŒ–åŸºç¡€æ¨¡å‹çš„å¾®è°ƒï¼Œå¹¶æ˜¾ç¤ºå…¶åœ¨è®­ç»ƒç¨³å®šæ€§ã€æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨æ–¹é¢ä¼˜äºæµè¡Œçš„QLoRAã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³æ­£äº¤å¾®è°ƒï¼ˆOFTï¼‰åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„é«˜è®¡ç®—å’Œå†…å­˜éœ€æ±‚é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºå¤æ‚åº¦ä¸ºç«‹æ–¹çš„çŸ©é˜µä¹˜æ³•ï¼Œå¯¼è‡´è¿è¡Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºOFTv2ï¼Œé€šè¿‡å°†è®¡ç®—é‡å¿ƒè½¬å‘è¾“å…¥ï¼Œé‡‡ç”¨çŸ©é˜µ-å‘é‡ä¹˜æ³•æ¥é™ä½è®¡ç®—å¤æ‚åº¦è‡³å¹³æ–¹çº§åˆ«ï¼Œä»è€Œæé«˜è®­ç»ƒæ•ˆç‡å’Œé™ä½å†…å­˜æ¶ˆè€—ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šOFTv2çš„æ•´ä½“æ¶æ„åŒ…æ‹¬è¾“å…¥é‡æ„æ¨¡å—å’ŒCayley-Neumannå‚æ•°åŒ–æ¨¡å—ã€‚è¾“å…¥é‡æ„æ¨¡å—è´Ÿè´£å°†è¾“å…¥æ•°æ®è½¬åŒ–ä¸ºé€‚åˆçš„æ ¼å¼ï¼Œè€ŒCayley-Neumannæ¨¡å—åˆ™ç”¨äºé«˜æ•ˆåœ°è¿›è¡Œæ­£äº¤å‚æ•°åŒ–ã€‚

**å…³é”®åˆ›æ–°**ï¼šOFTv2çš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶è¾“å…¥ä¸­å¿ƒçš„é‡æ„æ–¹æ³•å’ŒCayley-Neumannå‚æ•°åŒ–ï¼Œè¿™ä¸ä¼ ç»Ÿçš„æƒé‡ä¸­å¿ƒæ–¹æ³•å½¢æˆé²œæ˜å¯¹æ¯”ï¼Œæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨OFTv2ä¸­ï¼Œé‡‡ç”¨äº†çŸ©é˜µ-å‘é‡ä¹˜æ³•æ›¿ä»£çŸ©é˜µä¹˜æ³•ï¼Œè®¾è®¡äº†é«˜æ•ˆçš„Cayley-Neumannå‚æ•°åŒ–æ¥è¿‘ä¼¼çŸ©é˜µé€†ï¼Œç¡®ä¿åœ¨é™ä½è®¡ç®—å¤æ‚åº¦çš„åŒæ—¶ä¿æŒæ¨¡å‹æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨å®éªŒä¸­è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

OFTv2åœ¨è®­ç»ƒé€Ÿåº¦ä¸Šå®ç°äº†æœ€é«˜10å€çš„æå‡ï¼ŒåŒæ—¶GPUå†…å­˜ä½¿ç”¨é™ä½è‡³3å€ã€‚ä¸æµè¡Œçš„QLoRAç›¸æ¯”ï¼ŒOFTv2åœ¨è®­ç»ƒç¨³å®šæ€§ã€æ•ˆç‡å’Œå†…å­˜ä½¿ç”¨æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè¯æ˜äº†å…¶åœ¨é‡åŒ–æ¨¡å‹å¾®è°ƒä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰éœ€è¦é«˜æ•ˆå¾®è°ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚OFTv2çš„é«˜æ•ˆæ€§ä½¿å…¶èƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­è¿›è¡Œå¤§è§„æ¨¡æ¨¡å‹çš„å¾®è°ƒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Orthogonal finetuning (OFT) offers highly parameter-efficient adaptation while preventing catastrophic forgetting, but its high runtime and memory demands limit practical deployment. We identify the core computational bottleneck in OFT as its weight-centric implementation, which relies on costly matrix-matrix multiplications with cubic complexity. To overcome this, we propose OFTv2, an input-centric reformulation that instead uses matrix-vector multiplications (i.e., matrix-free computation), reducing the computational cost to quadratic. We further introduce the Cayley-Neumann parameterization, an efficient orthogonal parameterization that approximates the matrix inversion in the Cayley transform via a truncated Neumann series. These modifications allow OFTv2 to achieve up to 10x faster training and 3x lower GPU memory usage without compromising performance. In addition, we extend OFTv2 to support finetuning quantized foundation models and show that it outperforms the popular QLoRA in training stability, efficiency, and memory usage.

