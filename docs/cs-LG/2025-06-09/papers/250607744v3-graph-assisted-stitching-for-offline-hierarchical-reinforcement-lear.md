---
layout: default
title: Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning
---

# Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.07744" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.07744v3</a>
  <a href="https://arxiv.org/pdf/2506.07744.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.07744v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.07744v3', 'Graph-Assisted Stitching for Offline Hierarchical Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Seungho Baek, Taegeon Park, Jongchan Park, Seungjun Oh, Yusung Kim

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-09 (æ›´æ–°: 2025-07-07)

**å¤‡æ³¨**: ICML 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/qortmdgh4141/GAS)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå›¾è¾…åŠ©æ‹¼æ¥æ–¹æ³•ä»¥è§£å†³ç¦»çº¿å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ä¸­çš„å­ç›®æ ‡é€‰æ‹©é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `å±‚æ¬¡å¼ºåŒ–å­¦ä¹ ` `å›¾æœç´¢` `å­ç›®æ ‡é€‰æ‹©` `çŠ¶æ€è½¬ç§»æ‹¼æ¥` `æ—¶é—´æ•ˆç‡` `æœºå™¨äººå¯¼èˆª` `æ™ºèƒ½åˆ¶é€ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨ä»»åŠ¡æ—¶é—´è·¨åº¦å¢åŠ æ—¶æ•ˆç‡æ˜¾è‘—ä¸‹é™ï¼Œä¸”ç¼ºä¹æœ‰æ•ˆçš„çŠ¶æ€è½¬ç§»æ‹¼æ¥ç­–ç•¥ã€‚
2. æœ¬æ–‡æå‡ºçš„å›¾è¾…åŠ©æ‹¼æ¥ï¼ˆGASï¼‰æ¡†æ¶å°†å­ç›®æ ‡é€‰æ‹©è§†ä¸ºå›¾æœç´¢é—®é¢˜ï¼Œé€šè¿‡èšç±»è¯­ä¹‰ç›¸ä¼¼çŠ¶æ€æ¥å®ç°é«˜æ•ˆæ‹¼æ¥ã€‚
3. åœ¨å¤šä¸ªä»»åŠ¡ä¸­ï¼ŒGASçš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¹‹å‰çš„ç¦»çº¿HRLæ–¹æ³•ï¼Œå°¤å…¶åœ¨æ‹¼æ¥å…³é”®ä»»åŠ¡ä¸­å–å¾—äº†88.3çš„é«˜åˆ†ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç°æœ‰çš„ç¦»çº¿å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¾èµ–äºé«˜å±‚ç­–ç•¥å­¦ä¹ æ¥ç”Ÿæˆå­ç›®æ ‡åºåˆ—ï¼Œä½†åœ¨ä»»åŠ¡æ—¶é—´è·¨åº¦å¢åŠ æ—¶æ•ˆç‡ä¸‹é™ï¼Œå¹¶ä¸”ç¼ºä¹æœ‰æ•ˆçš„ç­–ç•¥æ¥æ‹¼æ¥ä¸åŒè½¨è¿¹ä¸­çš„æœ‰ç”¨çŠ¶æ€è½¬ç§»ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†å›¾è¾…åŠ©æ‹¼æ¥ï¼ˆGASï¼‰æ¡†æ¶ï¼Œå°†å­ç›®æ ‡é€‰æ‹©é—®é¢˜å½¢å¼åŒ–ä¸ºå›¾æœç´¢é—®é¢˜ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ˜¾å¼çš„é«˜å±‚ç­–ç•¥ã€‚é€šè¿‡å°†çŠ¶æ€åµŒå…¥æ—¶é—´è·ç¦»è¡¨ç¤ºï¼ˆTDRï¼‰ç©ºé—´ï¼ŒGASå°†æ¥è‡ªä¸åŒè½¨è¿¹çš„è¯­ä¹‰ç›¸ä¼¼çŠ¶æ€èšç±»ä¸ºç»Ÿä¸€çš„å›¾èŠ‚ç‚¹ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„è½¬ç§»æ‹¼æ¥ã€‚éšåï¼Œåº”ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•åœ¨å›¾ä¸­é€‰æ‹©å­ç›®æ ‡åºåˆ—ï¼ŒåŒæ—¶ä½å±‚ç­–ç•¥å­¦ä¹ åˆ°è¾¾è¿™äº›å­ç›®æ ‡ã€‚å¼•å…¥æ—¶é—´æ•ˆç‡ï¼ˆTEï¼‰æŒ‡æ ‡ä»¥æé«˜å›¾çš„è´¨é‡ï¼Œæ˜¾è‘—æå‡ä»»åŠ¡æ€§èƒ½ã€‚GASåœ¨è¿åŠ¨ã€å¯¼èˆªå’Œæ“ä½œä»»åŠ¡ä¸­è¶…è¶Šäº†ä¹‹å‰çš„ç¦»çº¿HRLæ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„ç¦»çº¿å±‚æ¬¡å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä¾èµ–äºé«˜å±‚ç­–ç•¥ç”Ÿæˆå­ç›®æ ‡åºåˆ—ï¼Œå¯¼è‡´åœ¨é•¿æ—¶é—´ä»»åŠ¡ä¸­æ•ˆç‡ä½ä¸‹ï¼Œä¸”éš¾ä»¥æœ‰æ•ˆæ‹¼æ¥ä¸åŒè½¨è¿¹ä¸­çš„çŠ¶æ€è½¬ç§»ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºçš„GASæ¡†æ¶é€šè¿‡å°†å­ç›®æ ‡é€‰æ‹©è½¬åŒ–ä¸ºå›¾æœç´¢é—®é¢˜ï¼Œé¿å…äº†æ˜¾å¼é«˜å±‚ç­–ç•¥çš„å­¦ä¹ ã€‚é€šè¿‡å°†çŠ¶æ€åµŒå…¥TDRç©ºé—´ï¼ŒGASèƒ½å¤Ÿå°†è¯­ä¹‰ç›¸ä¼¼çš„çŠ¶æ€èšç±»ä¸ºç»Ÿä¸€çš„å›¾èŠ‚ç‚¹ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„çŠ¶æ€è½¬ç§»æ‹¼æ¥ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGASçš„æ•´ä½“æ¶æ„åŒ…æ‹¬çŠ¶æ€åµŒå…¥ã€å›¾èŠ‚ç‚¹èšç±»ã€æœ€çŸ­è·¯å¾„ç®—æ³•é€‰æ‹©å­ç›®æ ‡åºåˆ—ä»¥åŠä½å±‚ç­–ç•¥å­¦ä¹ å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œå°†çŠ¶æ€åµŒå…¥TDRç©ºé—´ï¼Œç„¶åèšç±»ç›¸ä¼¼çŠ¶æ€å½¢æˆå›¾èŠ‚ç‚¹ï¼Œæ¥ç€ä½¿ç”¨æœ€çŸ­è·¯å¾„ç®—æ³•é€‰æ‹©å­ç›®æ ‡ï¼Œæœ€åé€šè¿‡ä½å±‚ç­–ç•¥å®ç°ç›®æ ‡çš„è¾¾æˆã€‚

**å…³é”®åˆ›æ–°**ï¼šGASçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†å­ç›®æ ‡é€‰æ‹©é—®é¢˜å½¢å¼åŒ–ä¸ºå›¾æœç´¢é—®é¢˜ï¼Œå¹¶å¼•å…¥TEæŒ‡æ ‡ä»¥è¿‡æ»¤å™ªå£°çŠ¶æ€ï¼Œæ˜¾è‘—æå‡äº†å›¾çš„è´¨é‡å’Œä»»åŠ¡æ€§èƒ½ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„é«˜å±‚ç­–ç•¥å­¦ä¹ æ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œæä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨GASä¸­ï¼ŒTEæŒ‡æ ‡ç”¨äºè¯„ä¼°çŠ¶æ€è½¬ç§»çš„æœ‰æ•ˆæ€§ï¼Œç¡®ä¿åªä¿ç•™é«˜æ•ˆçš„çŠ¶æ€è½¬ç§»ã€‚æ­¤å¤–ï¼Œæœ€çŸ­è·¯å¾„ç®—æ³•çš„é€‰æ‹©å’Œä½å±‚ç­–ç•¥çš„è®¾è®¡ä¹Ÿæ˜¯å…³é”®æŠ€æœ¯ç»†èŠ‚ï¼Œç¡®ä¿äº†æ•´ä½“æ¡†æ¶çš„é«˜æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å®éªŒä¸­ï¼ŒGASåœ¨è¿åŠ¨ã€å¯¼èˆªå’Œæ“ä½œä»»åŠ¡ä¸Šå‡è¶…è¶Šäº†ä¹‹å‰çš„ç¦»çº¿HRLæ–¹æ³•ï¼Œå°¤å…¶åœ¨æ‹¼æ¥å…³é”®ä»»åŠ¡ä¸­å–å¾—äº†88.3çš„é«˜åˆ†ï¼Œæ˜¾è‘—é«˜äºä¹‹å‰çš„1.0çš„çŠ¶æ€-of-the-artåˆ†æ•°ï¼Œå±•ç¤ºäº†å…¶å“è¶Šçš„æ€§èƒ½æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åˆ¶é€ ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„å†³ç­–æ•ˆç‡å’Œæ€§èƒ½ã€‚æœªæ¥ï¼ŒGASæ¡†æ¶æœ‰æœ›åœ¨æ›´å¤šå®é™…åº”ç”¨ä¸­æ¨å¹¿ï¼Œæ¨åŠ¨ç¦»çº¿å±‚æ¬¡å¼ºåŒ–å­¦ä¹ çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Existing offline hierarchical reinforcement learning methods rely on high-level policy learning to generate subgoal sequences. However, their efficiency degrades as task horizons increase, and they lack effective strategies for stitching useful state transitions across different trajectories. We propose Graph-Assisted Stitching (GAS), a novel framework that formulates subgoal selection as a graph search problem rather than learning an explicit high-level policy. By embedding states into a Temporal Distance Representation (TDR) space, GAS clusters semantically similar states from different trajectories into unified graph nodes, enabling efficient transition stitching. A shortest-path algorithm is then applied to select subgoal sequences within the graph, while a low-level policy learns to reach the subgoals. To improve graph quality, we introduce the Temporal Efficiency (TE) metric, which filters out noisy or inefficient transition states, significantly enhancing task performance. GAS outperforms prior offline HRL methods across locomotion, navigation, and manipulation tasks. Notably, in the most stitching-critical task, it achieves a score of 88.3, dramatically surpassing the previous state-of-the-art score of 1.0. Our source code is available at: https://github.com/qortmdgh4141/GAS.

