---
layout: default
title: PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis
---

# PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15852" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15852v1</a>
  <a href="https://arxiv.org/pdf/2508.15852.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15852v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15852v1', 'PGF-Net: A Progressive Gated-Fusion Framework for Efficient Multimodal Sentiment Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Bin Wen, Tien-Ping Tan

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPGF-Netä»¥è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ•ˆç‡ä¸å¯è§£é‡Šæ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æ` `æ·±åº¦å­¦ä¹ ` `æ¸è¿›èåˆ` `é—¨æ§æœºåˆ¶` `å‚æ•°é«˜æ•ˆå¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†ææ–¹æ³•åœ¨æ•ˆç‡å’Œå¯è§£é‡Šæ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆèåˆä¸åŒæ¨¡æ€çš„ä¿¡æ¯ã€‚
2. PGF-Neté€šè¿‡æ¸è¿›å±‚å†…èåˆå’Œè‡ªé€‚åº”é—¨æ§ä»²è£æœºåˆ¶ï¼Œå®ç°äº†åŠ¨æ€ä¸”ç¨³å®šçš„å¤šæ¨¡æ€ä¿¡æ¯æ•´åˆï¼Œæå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚
3. åœ¨MOSIæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPGF-Netä»¥ä»…3.09Mçš„å¯è®­ç»ƒå‚æ•°è¾¾åˆ°äº†MAEä¸º0.691å’ŒF1-Scoreä¸º86.9%çš„ä¼˜å¼‚æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬ä»‹ç»äº†PGF-Netï¼ˆæ¸è¿›é—¨æ§èåˆç½‘ç»œï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é«˜æ•ˆä¸”å¯è§£é‡Šçš„å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æçš„æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰é¡¹ä¸»è¦åˆ›æ–°ï¼šé¦–å…ˆï¼Œæå‡ºäº†æ¸è¿›å±‚å†…èåˆèŒƒå¼ï¼Œé€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿æ–‡æœ¬è¡¨ç¤ºèƒ½å¤ŸåŠ¨æ€æŸ¥è¯¢å¹¶æ•´åˆæ¥è‡ªéŸ³é¢‘å’Œè§†è§‰æµçš„éè¯­è¨€ç‰¹å¾ã€‚å…¶æ¬¡ï¼Œæ¨¡å‹å¼•å…¥äº†è‡ªé€‚åº”é—¨æ§ä»²è£æœºåˆ¶ï¼Œä½œä¸ºåŠ¨æ€æ§åˆ¶å™¨å¹³è¡¡åŸå§‹è¯­è¨€ä¿¡æ¯ä¸æ–°èåˆçš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ï¼Œç¡®ä¿ç¨³å®šä¸”æœ‰æ„ä¹‰çš„æ•´åˆã€‚æœ€åï¼Œé‡‡ç”¨æ··åˆå‚æ•°é«˜æ•ˆå¾®è°ƒç­–ç•¥ï¼Œç»“åˆLoRAçš„å…¨å±€é€‚åº”ä¸åèåˆé€‚é…å™¨çš„å±€éƒ¨ç»†åŒ–ï¼Œæ˜¾è‘—å‡å°‘å¯è®­ç»ƒå‚æ•°ï¼Œä½¿æ¨¡å‹è½»é‡åŒ–ï¼Œé€‚åˆèµ„æºæœ‰é™çš„åœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPGF-Netåœ¨MOSIæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒMAEä¸º0.691ï¼ŒF1-Scoreä¸º86.9%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æä¸­æ•ˆç‡ä½ä¸‹å’Œå¯è§£é‡Šæ€§ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨èåˆä¸åŒæ¨¡æ€ä¿¡æ¯æ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆå¹³è¡¡ä¿¡å·ä¸å™ªå£°ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPGF-Netçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ¸è¿›å±‚å†…èåˆå’Œè‡ªé€‚åº”é—¨æ§ä»²è£æœºåˆ¶ï¼ŒåŠ¨æ€æ•´åˆæ–‡æœ¬ã€éŸ³é¢‘å’Œè§†è§‰ä¿¡æ¯ï¼Œä»è€Œæå‡æƒ…æ„Ÿåˆ†æçš„å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šPGF-Neté‡‡ç”¨åˆ†å±‚ç¼–ç å™¨æ¶æ„ï¼Œä¸»è¦æ¨¡å—åŒ…æ‹¬æ¸è¿›å±‚å†…èåˆæ¨¡å—ã€é—¨æ§ä»²è£æ¨¡å—å’Œæ··åˆå‚æ•°é«˜æ•ˆå¾®è°ƒç­–ç•¥ã€‚é€šè¿‡è¿™äº›æ¨¡å—ï¼Œæ¨¡å‹èƒ½å¤Ÿåœ¨æ·±å±‚æ¬¡ä¸Šè¿›è¡ŒåŠ¨æ€èåˆã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæ¸è¿›å±‚å†…èåˆèŒƒå¼å’Œè‡ªé€‚åº”é—¨æ§ä»²è£æœºåˆ¶ï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒå±‚æ¬¡ä¸Šæœ‰æ•ˆæ•´åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­ä¿¡æ¯èåˆçš„å™ªå£°å¹²æ‰°ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¨¡å‹é‡‡ç”¨äº†æ··åˆå‚æ•°é«˜æ•ˆå¾®è°ƒç­–ç•¥ï¼Œç»“åˆäº†LoRAçš„å…¨å±€é€‚åº”ä¸åèåˆé€‚é…å™¨çš„å±€éƒ¨ç»†åŒ–ï¼Œæ˜¾è‘—å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ï¼Œä½¿å¾—PGF-Netåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œå…·å¤‡äº†æ›´å¥½çš„è®¡ç®—æ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

PGF-Netåœ¨MOSIæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„å®éªŒç»“æœï¼ŒMAEä¸º0.691ï¼ŒF1-Scoreè¾¾åˆ°86.9%ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹ä»¥ä»…3.09Mçš„å¯è®­ç»ƒå‚æ•°å®ç°äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œå±•ç¤ºäº†åœ¨æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„è‰¯å¥½å¹³è¡¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

PGF-Netåœ¨å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºç¤¾äº¤åª’ä½“åˆ†æã€æƒ…æ„Ÿè®¡ç®—å’Œäººæœºäº¤äº’ç­‰åœºæ™¯ã€‚å…¶é«˜æ•ˆæ€§å’Œå¯è§£é‡Šæ€§ä½¿å¾—è¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„ç¯å¢ƒä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œæ¨åŠ¨æƒ…æ„Ÿåˆ†ææŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce PGF-Net (Progressive Gated-Fusion Network), a novel deep learning framework designed for efficient and interpretable multimodal sentiment analysis. Our framework incorporates three primary innovations. Firstly, we propose a Progressive Intra-Layer Fusion paradigm, where a Cross-Attention mechanism empowers the textual representation to dynamically query and integrate non-linguistic features from audio and visual streams within the deep layers of a Transformer encoder. This enables a deeper, context-dependent fusion process. Secondly, the model incorporates an Adaptive Gated Arbitration mechanism, which acts as a dynamic controller to balance the original linguistic information against the newly fused multimodal context, ensuring stable and meaningful integration while preventing noise from overwhelming the signal. Lastly, a hybrid Parameter-Efficient Fine-Tuning (PEFT) strategy is employed, synergistically combining global adaptation via LoRA with local refinement through Post-Fusion Adapters. This significantly reduces trainable parameters, making the model lightweight and suitable for resource-limited scenarios. These innovations are integrated into a hierarchical encoder architecture, enabling PGF-Net to perform deep, dynamic, and interpretable multimodal sentiment analysis while maintaining exceptional parameter efficiency. Experimental results on MOSI dataset demonstrate that our proposed PGF-Net achieves state-of-the-art performance, with a Mean Absolute Error (MAE) of 0.691 and an F1-Score of 86.9%. Notably, our model achieves these results with only 3.09M trainable parameters, showcasing a superior balance between performance and computational efficiency.

