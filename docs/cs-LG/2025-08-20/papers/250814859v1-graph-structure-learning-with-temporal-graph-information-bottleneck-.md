---
layout: default
title: Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning
---

# Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14859" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14859v1</a>
  <a href="https://arxiv.org/pdf/2508.14859.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14859v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14859v1', 'Graph Structure Learning with Temporal Graph Information Bottleneck for Inductive Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiafeng Xiong, Rizos Sakellariou

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20

**å¤‡æ³¨**: Accepted in the 28th European Conference on Artificial Intelligence (ECAI), 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGTGIBæ¡†æ¶ä»¥è§£å†³åŠ¨æ€ç½‘ç»œä¸­çš„èŠ‚ç‚¹è¡¨ç¤ºé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åŠ¨æ€å›¾å­¦ä¹ ` `å½’çº³è¡¨ç¤ºå­¦ä¹ ` `å›¾ç»“æ„å­¦ä¹ ` `ä¿¡æ¯ç“¶é¢ˆ` `èŠ‚ç‚¹è¡¨ç¤º` `æœºå™¨å­¦ä¹ ` `ç½‘ç»œä¼˜åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å½’çº³è¡¨ç¤ºå­¦ä¹ æ–¹æ³•åœ¨åŠ¨æ€ç½‘ç»œä¸­éš¾ä»¥æœ‰æ•ˆå¤„ç†æœªè§èŠ‚ç‚¹å’Œå†—ä½™ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºGTGIBæ¡†æ¶ï¼Œç»“åˆå›¾ç»“æ„å­¦ä¹ ä¸æ—¶é—´å›¾ä¿¡æ¯ç“¶é¢ˆï¼Œé€šè¿‡ä¼˜åŒ–èŠ‚ç‚¹é‚»åŸŸå’Œæ­£åˆ™åŒ–å›¾ä¿¡æ¯æ¥è§£å†³ä¸Šè¿°é—®é¢˜ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒGTGIBåœ¨å››ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„é“¾æ¥é¢„æµ‹ä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨ä¼ å¯¼è®¾ç½®ä¸‹è¡¨ç°å‡ºæ˜¾è‘—æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŠ¨æ€å›¾å­¦ä¹ åœ¨èŠ‚ç‚¹å’Œè¾¹éšæ—¶é—´æ¼”å˜çš„ç½‘ç»œä¸­è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨æ–°èŠ‚ç‚¹ä¸æ–­åŠ å…¥çš„æƒ…å†µä¸‹ã€‚ç°æœ‰çš„å½’çº³è¡¨ç¤ºå­¦ä¹ é¢ä¸´ä¸¤ä¸ªä¸»è¦æŒ‘æˆ˜ï¼šæœ‰æ•ˆè¡¨ç¤ºæœªè§èŠ‚ç‚¹ä»¥åŠå‡è½»å™ªå£°æˆ–å†—ä½™å›¾ä¿¡æ¯ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†GTGIBæ¡†æ¶ï¼Œç»“åˆäº†å›¾ç»“æ„å­¦ä¹ ï¼ˆGSLï¼‰ä¸æ—¶é—´å›¾ä¿¡æ¯ç“¶é¢ˆï¼ˆTGIBï¼‰ã€‚é€šè¿‡ç†è®ºè¯æ˜å’Œå®éªŒéªŒè¯ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥GSLç»“æ„å¢å¼ºå™¨ï¼Œä»¥ä¸°å¯Œå’Œä¼˜åŒ–èŠ‚ç‚¹é‚»åŸŸã€‚TGIBé€šè¿‡æ‰©å±•ä¿¡æ¯ç“¶é¢ˆåŸç†è‡³æ—¶é—´å›¾ï¼ŒåŸºäºå¯å˜è¿‘ä¼¼æ¨å¯¼çš„TGIBç›®æ ‡å‡½æ•°ï¼Œæ­£åˆ™åŒ–è¾¹å’Œç‰¹å¾ï¼Œä»è€Œå®ç°ç¨³å®šé«˜æ•ˆçš„ä¼˜åŒ–ã€‚GTGIBæ¨¡å‹åœ¨å››ä¸ªçœŸå®æ•°æ®é›†ä¸Šè¿›è¡Œé“¾æ¥é¢„æµ‹ï¼Œç»“æœæ˜¾ç¤ºåœ¨å½’çº³è®¾ç½®ä¸‹ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨ä¼ å¯¼è®¾ç½®ä¸‹ä¹Ÿæœ‰æ˜¾è‘—ä¸”ä¸€è‡´çš„æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŠ¨æ€ç½‘ç»œä¸­å½’çº³è¡¨ç¤ºå­¦ä¹ çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯å¦‚ä½•æœ‰æ•ˆè¡¨ç¤ºæœªè§èŠ‚ç‚¹åŠå¤„ç†å†—ä½™ä¿¡æ¯çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™æ–¹é¢å­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGTGIBæ¡†æ¶é€šè¿‡ç»“åˆå›¾ç»“æ„å­¦ä¹ ï¼ˆGSLï¼‰ä¸æ—¶é—´å›¾ä¿¡æ¯ç“¶é¢ˆï¼ˆTGIBï¼‰ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„ä¸¤æ­¥ç»“æ„å¢å¼ºå™¨ï¼Œæ—¨åœ¨ä¼˜åŒ–èŠ‚ç‚¹é‚»åŸŸå¹¶å‡å°‘å™ªå£°ä¿¡æ¯ã€‚è¿™æ ·çš„è®¾è®¡ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”åŠ¨æ€å˜åŒ–çš„ç½‘ç»œç¯å¢ƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGTGIBçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆæ˜¯GSLç»“æ„å¢å¼ºå™¨ï¼Œç”¨äºä¸°å¯Œå’Œä¼˜åŒ–èŠ‚ç‚¹çš„é‚»åŸŸä¿¡æ¯ï¼›å…¶æ¬¡æ˜¯TGIBæ¨¡å—ï¼Œé€šè¿‡ä¿¡æ¯ç“¶é¢ˆåŸç†å¯¹ä¼˜åŒ–åçš„å›¾è¿›è¡Œæ­£åˆ™åŒ–ï¼Œç¡®ä¿è¾¹å’Œç‰¹å¾çš„ç¨³å®šæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šGTGIBçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†ä¿¡æ¯ç“¶é¢ˆåŸç†æ‰©å±•åˆ°æ—¶é—´å›¾ï¼Œæå‡ºäº†å¯å˜è¿‘ä¼¼çš„TGIBç›®æ ‡å‡½æ•°ï¼Œä»è€Œå®ç°äº†å¯¹åŠ¨æ€å›¾çš„æœ‰æ•ˆä¼˜åŒ–ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿé™æ€å›¾å­¦ä¹ æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°è®¾ç½®åŒ…æ‹¬é‚»åŸŸå¤§å°çš„é€‰æ‹©ã€æŸå¤±å‡½æ•°çš„è®¾è®¡ä»¥åŠç½‘ç»œç»“æ„çš„æ·±åº¦ã€‚ç‰¹åˆ«æ˜¯åœ¨TGIBæ¨¡å—ä¸­ï¼Œæ­£åˆ™åŒ–ç­–ç•¥çš„é€‰æ‹©å¯¹æ¨¡å‹çš„ç¨³å®šæ€§å’Œä¼˜åŒ–æ•ˆç‡è‡³å…³é‡è¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å››ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGTGIBæ¨¡å‹åœ¨é“¾æ¥é¢„æµ‹ä»»åŠ¡ä¸­å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶åœ¨å½’çº³è®¾ç½®ä¸‹ï¼Œæ€§èƒ½æå‡å¹…åº¦è¾¾åˆ°æ˜¾è‘—æ°´å¹³ï¼Œä¸”åœ¨ä¼ å¯¼è®¾ç½®ä¸‹ä¹Ÿå±•ç°å‡ºä¸€è‡´çš„æ”¹è¿›ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GTGIBæ¡†æ¶åœ¨ç¤¾äº¤ç½‘ç»œåˆ†æã€äº¤é€šæµé‡é¢„æµ‹å’Œé‡‘èç½‘ç»œå»ºæ¨¡ç­‰åŠ¨æ€ç½‘ç»œåœºæ™¯ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æœ‰æ•ˆå¤„ç†æœªè§èŠ‚ç‚¹å’Œå†—ä½™ä¿¡æ¯ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæå‡åŠ¨æ€ç½‘ç»œçš„è¡¨ç¤ºèƒ½åŠ›ï¼Œè¿›è€Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Temporal graph learning is crucial for dynamic networks where nodes and edges evolve over time and new nodes continuously join the system. Inductive representation learning in such settings faces two major challenges: effectively representing unseen nodes and mitigating noisy or redundant graph information. We propose GTGIB, a versatile framework that integrates Graph Structure Learning (GSL) with Temporal Graph Information Bottleneck (TGIB). We design a novel two-step GSL-based structural enhancer to enrich and optimize node neighborhoods and demonstrate its effectiveness and efficiency through theoretical proofs and experiments. The TGIB refines the optimized graph by extending the information bottleneck principle to temporal graphs, regularizing both edges and features based on our derived tractable TGIB objective function via variational approximation, enabling stable and efficient optimization. GTGIB-based models are evaluated to predict links on four real-world datasets; they outperform existing methods in all datasets under the inductive setting, with significant and consistent improvement in the transductive setting.

