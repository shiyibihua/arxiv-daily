---
layout: default
title: Evaluating Sparse Autoencoders for Monosemantic Representation
---

# Evaluating Sparse Autoencoders for Monosemantic Representation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.15094" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.15094v2</a>
  <a href="https://arxiv.org/pdf/2508.15094.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.15094v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.15094v2', 'Evaluating Sparse Autoencoders for Monosemantic Representation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Moghis Fereidouni, Muhammad Umair Haider, Peizhong Ju, A. B. Siddique

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-20 (æ›´æ–°: 2025-10-16)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¨€ç–è‡ªç¼–ç å™¨ä»¥è§£å†³è¯­è¨€æ¨¡å‹å¤šä¹‰æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¨€ç–è‡ªç¼–ç å™¨` `å¤šä¹‰æ€§` `æ¦‚å¿µå¯åˆ†ç¦»æ€§` `æ¿€æ´»åˆ†å¸ƒ` `è‡ªç„¶è¯­è¨€å¤„ç†` `æ¨¡å‹å¯è§£é‡Šæ€§` `æ¦‚å¿µçº§å¹²é¢„`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯­è¨€æ¨¡å‹å­˜åœ¨å¤šä¹‰æ€§é—®é¢˜ï¼Œå¯¼è‡´ç¥ç»å…ƒåŒæ—¶æ¿€æ´»å¤šä¸ªæ— å…³æ¦‚å¿µï¼Œå½±å“æ¨¡å‹çš„å¯è§£é‡Šæ€§ã€‚
2. æœ¬æ–‡æå‡ºç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰ä½œä¸ºè§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡å°†å¯†é›†æ¿€æ´»è½¬åŒ–ä¸ºç¨€ç–ç‰¹å¾ï¼Œå¢å¼ºæ¦‚å¿µçš„å•ä¸€æ€§ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSAEsåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†å¤šä¹‰æ€§ï¼Œå¹¶æé«˜äº†æ¦‚å¿µå¯åˆ†ç¦»æ€§ï¼Œå°¤å…¶åœ¨éƒ¨åˆ†æŠ‘åˆ¶ç­–ç•¥ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç†è§£å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸€ä¸ªå…³é”®éšœç¢æ˜¯å¤šä¹‰æ€§ï¼Œå³ç¥ç»å…ƒåŒæ—¶æ¿€æ´»å¤šä¸ªæ— å…³æ¦‚å¿µã€‚ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰è¢«æå‡ºä»¥ç¼“è§£è¿™ä¸€é—®é¢˜ï¼Œé€šè¿‡å°†å¯†é›†æ¿€æ´»è½¬åŒ–ä¸ºç¨€ç–ä¸”æ›´æ˜“è§£é‡Šçš„ç‰¹å¾ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶è¡¨æ˜SAEsä¿ƒè¿›äº†å•ä¸€è¯­ä¹‰æ€§ï¼Œä½†å°šæ— å®šé‡æ¯”è¾ƒç ”ç©¶è€ƒå¯ŸSAEsä¸åŸºç¡€æ¨¡å‹ä¹‹é—´çš„æ¦‚å¿µæ¿€æ´»åˆ†å¸ƒå·®å¼‚ã€‚æœ¬æ–‡é¦–æ¬¡é€šè¿‡æ¿€æ´»åˆ†å¸ƒçš„è§†è§’ç³»ç»Ÿè¯„ä¼°SAEsä¸åŸºç¡€æ¨¡å‹ï¼Œæå‡ºåŸºäºJensen-Shannonè·ç¦»çš„ç»†ç²’åº¦æ¦‚å¿µå¯åˆ†ç¦»æ€§è¯„åˆ†ï¼Œå±•ç¤ºSAEsåœ¨å‡å°‘å¤šä¹‰æ€§å’Œæé«˜æ¦‚å¿µå¯åˆ†ç¦»æ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æ¦‚å¿µçº§å¹²é¢„çš„å®ç”¨æ€§ï¼Œå‘ç°SAEsåœ¨éƒ¨åˆ†æŠ‘åˆ¶ç­–ç•¥ä¸‹èƒ½å¤Ÿå®ç°æ›´ç²¾ç¡®çš„æ¦‚å¿µæ§åˆ¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„å¤šä¹‰æ€§é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•æœªèƒ½æœ‰æ•ˆåŒºåˆ†ç¥ç»å…ƒå¯¹ä¸åŒæ¦‚å¿µçš„æ¿€æ´»ï¼Œå¯¼è‡´å¯è§£é‡Šæ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSAEsï¼‰ï¼Œå°†å¯†é›†çš„æ¿€æ´»æ¨¡å¼è½¬åŒ–ä¸ºç¨€ç–çš„ç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæé«˜ç¥ç»å…ƒå¯¹å•ä¸€æ¦‚å¿µçš„å“åº”æ€§ï¼Œå‡å°‘å¤šä¹‰æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶ä½¿ç”¨ä¸¤ç§å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆGemma-2-2Bå’ŒDeepSeek-R1ï¼‰ï¼Œç»“åˆå¤šä¸ªSAEå˜ä½“å’Œäº”ä¸ªæ•°æ®é›†ï¼Œé‡‡ç”¨Jensen-Shannonè·ç¦»è®¡ç®—æ¦‚å¿µå¯åˆ†ç¦»æ€§è¯„åˆ†ï¼Œè¯„ä¼°æ¿€æ´»åˆ†å¸ƒçš„å·®å¼‚ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„ä¸»è¦åˆ›æ–°åœ¨äºé¦–æ¬¡å®šé‡æ¯”è¾ƒSAEsä¸åŸºç¡€æ¨¡å‹çš„æ¦‚å¿µæ¿€æ´»åˆ†å¸ƒï¼Œå¹¶æå‡ºäº†åŸºäºæ¿€æ´»åˆ†å¸ƒçš„æ¦‚å¿µçº§å¹²é¢„æ–¹æ³•ï¼ˆAPPï¼‰ï¼Œæœ‰æ•ˆå®ç°ç›®æ ‡æ¦‚å¿µçš„æŠ‘åˆ¶ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨å…¨ç¥ç»å…ƒæ©è”½å’Œéƒ¨åˆ†æŠ‘åˆ¶ä¸¤ç§ç­–ç•¥ï¼ŒAPPæ–¹æ³•é€šè¿‡æ¦‚å¿µæ¡ä»¶æ¿€æ´»åˆ†å¸ƒè¿›è¡Œé’ˆå¯¹æ€§æŠ‘åˆ¶ï¼Œç¡®ä¿åœ¨æ¦‚å¿µç§»é™¤æ—¶æœ€å°åŒ–å›°æƒ‘åº¦çš„å¢åŠ ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAEsåœ¨äº”ä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†å¤šä¹‰æ€§ï¼Œç›¸è¾ƒäºåŸºç¡€æ¨¡å‹ï¼Œæ¦‚å¿µå¯åˆ†ç¦»æ€§è¯„åˆ†æé«˜äº†çº¦20%ã€‚ä½¿ç”¨éƒ¨åˆ†æŠ‘åˆ¶ç­–ç•¥æ—¶ï¼ŒSAEsåœ¨æ¦‚å¿µæ§åˆ¶ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„ç²¾ç¡®åº¦ï¼ŒAPPæ–¹æ³•åœ¨æ¦‚å¿µç§»é™¤æ—¶ä»…å¢åŠ äº†æœ€å°çš„å›°æƒ‘åº¦ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿæå‡æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ§åˆ¶èƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ›´é«˜æ•ˆçš„è¯­è¨€æ¨¡å‹è®¾è®¡ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A key barrier to interpreting large language models is polysemanticity, where neurons activate for multiple unrelated concepts. Sparse autoencoders (SAEs) have been proposed to mitigate this issue by transforming dense activations into sparse, more interpretable features. While prior work suggests that SAEs promote monosemanticity, no quantitative comparison has examined how concept activation distributions differ between SAEs and their base models. This paper provides the first systematic evaluation of SAEs against base models through activation distribution lens. We introduce a fine-grained concept separability score based on the Jensen-Shannon distance, which captures how distinctly a neuron's activation distributions vary across concepts. Using two large language models (Gemma-2-2B and DeepSeek-R1) and multiple SAE variants across five datasets (including word-level and sentence-level), we show that SAEs reduce polysemanticity and achieve higher concept separability. To assess practical utility, we evaluate concept-level interventions using two strategies: full neuron masking and partial suppression. We find that, compared to base models, SAEs enable more precise concept-level control when using partial suppression. Building on this, we propose Attenuation via Posterior Probabilities (APP), a new intervention method that uses concept-conditioned activation distributions for targeted suppression. APP achieves the smallest perplexity increase while remaining highly effective at concept removal.

