---
layout: default
title: SciML Agents: Write the Solver, Not the Solution
---

# SciML Agents: Write the Solver, Not the Solution

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09936" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09936v1</a>
  <a href="https://arxiv.org/pdf/2509.09936.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09936v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09936v1', 'SciML Agents: Write the Solver, Not the Solution')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Saarth Gaonkar, Xiang Zheng, Haocheng Xi, Rishabh Tiwari, Kurt Keutzer, Dmitriy Morozov, Michael W. Mahoney, Amir Gholami

**åˆ†ç±»**: cs.LG, math.NA

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SciML Agentsï¼šåˆ©ç”¨LLMç”Ÿæˆæ±‚è§£å™¨ä»£ç ï¼Œè€Œéç›´æ¥é¢„æµ‹ç§‘å­¦è®¡ç®—ç»“æœ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç§‘å­¦æœºå™¨å­¦ä¹ ` `å¤§å‹è¯­è¨€æ¨¡å‹` `å¸¸å¾®åˆ†æ–¹ç¨‹` `æ•°å€¼æ±‚è§£` `ä»£ç ç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç§‘å­¦æœºå™¨å­¦ä¹ æ–¹æ³•ç›´æ¥é¢„æµ‹ç»“æœï¼Œä½†éš¾ä»¥ä¿è¯é«˜ç²¾åº¦å’Œé²æ£’æ€§ï¼Œé¢ä¸´æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºåˆ©ç”¨LLMç”Ÿæˆæ±‚è§£ODEçš„ä»£ç ï¼Œé€‰æ‹©åˆé€‚çš„æ•°å€¼ç®—æ³•ï¼Œé™ä½å­¦ä¹ è§£å‡½æ•°çš„éš¾åº¦ã€‚
3. æ„å»ºäº†è¯Šæ–­æ€§å’Œå¤§è§„æ¨¡ODEåŸºå‡†æ•°æ®é›†ï¼Œå®éªŒè¡¨æ˜é€šè¿‡æç¤ºå’Œå¾®è°ƒï¼ŒLLMèƒ½æœ‰æ•ˆè§£å†³ODEé—®é¢˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œç§‘å­¦æœºå™¨å­¦ä¹ é¢†åŸŸå°è¯•ç›´æ¥ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹ç›®æ ‡å€¼æ¥è§£å†³ç§‘å­¦ä»»åŠ¡ï¼ˆä¾‹å¦‚ï¼Œç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œã€ç¥ç»ODEã€ç¥ç»ç®—å­ç­‰ï¼‰ï¼Œä½†å®ç°é«˜ç²¾åº¦å’Œé²æ£’æ€§ä¸€ç›´å…·æœ‰æŒ‘æˆ˜æ€§ã€‚æœ¬æ–‡æ¢ç´¢äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆï¼šä½¿ç”¨LLMç¼–å†™ä»£ç ï¼Œåˆ©ç”¨æ•°åå¹´çš„æ•°å€¼ç®—æ³•ç§¯ç´¯ã€‚è¿™ä¼šå°†è´Ÿæ‹…ä»å­¦ä¹ è§£å‡½æ•°è½¬ç§»åˆ°åšå‡ºé¢†åŸŸæ„ŸçŸ¥çš„æ•°å€¼é€‰æ‹©ã€‚æœ¬æ–‡æ¢è®¨LLMæ˜¯å¦å¯ä»¥å……å½“SciMLä»£ç†ï¼Œç»™å®šè‡ªç„¶è¯­è¨€çš„ODEæè¿°ï¼Œç”Ÿæˆå¯è¿è¡Œçš„ã€ç§‘å­¦ä¸Šé€‚å½“çš„ä»£ç ï¼Œé€‰æ‹©åˆé€‚çš„æ±‚è§£å™¨ï¼ˆåˆšæ€§ä¸éåˆšæ€§ï¼‰ï¼Œå¹¶æ‰§è¡Œç¨³å®šæ€§æ£€æŸ¥ã€‚ç›®å‰ï¼Œæ²¡æœ‰åŸºå‡†æ¥è¡¡é‡ç§‘å­¦è®¡ç®—ä»»åŠ¡çš„è¿™ç§èƒ½åŠ›ã€‚å› æ­¤ï¼Œæœ¬æ–‡é¦–å…ˆå¼•å…¥äº†ä¸¤ä¸ªæ–°çš„æ•°æ®é›†ï¼šä¸€ä¸ªå¯¹æŠ—æ€§çš„â€œè¯¯å¯¼æ€§â€è¯Šæ–­æ•°æ®é›†ï¼›ä»¥åŠä¸€ä¸ªåŒ…å«1000ä¸ªä¸åŒODEä»»åŠ¡çš„å¤§è§„æ¨¡åŸºå‡†ã€‚è¯Šæ–­é›†åŒ…å«è¡¨é¢ä¸Šçœ‹èµ·æ¥æ˜¯åˆšæ€§çš„é—®é¢˜ï¼Œéœ€è¦ä»£æ•°ç®€åŒ–æ¥è¯æ˜éåˆšæ€§ï¼›å¤§è§„æ¨¡åŸºå‡†æ¶µç›–åˆšæ€§å’Œéåˆšæ€§ODEèŒƒå›´ã€‚æœ¬æ–‡è¯„ä¼°äº†å¼€æºå’Œé—­æºLLMæ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š(i) æ— å¼•å¯¼ä¸é¢†åŸŸç‰¹å®šçŸ¥è¯†å¼•å¯¼çš„æç¤ºï¼›(ii) å¼€ç®±å³ç”¨ä¸å¾®è°ƒå˜ä½“ã€‚è¯„ä¼°æ ‡å‡†åŒ…æ‹¬å¯æ‰§è¡Œæ€§å’Œé’ˆå¯¹å‚è€ƒè§£çš„æ•°å€¼æœ‰æ•ˆæ€§ã€‚ç»“æœè¡¨æ˜ï¼Œé€šè¿‡è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡å’Œå¼•å¯¼æç¤ºï¼Œè¾ƒæ–°çš„æŒ‡ä»¤éµå¾ªæ¨¡å‹åœ¨ä¸¤ä¸ªæ ‡å‡†ä¸Šéƒ½å–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæœ€æ–°çš„å¼€æºç³»ç»Ÿåœ¨æ²¡æœ‰å¾®è°ƒçš„æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ï¼Œè€Œè¾ƒæ—§æˆ–è¾ƒå°çš„æ¨¡å‹ä»ç„¶å—ç›Šäºå¾®è°ƒã€‚æ€»çš„æ¥è¯´ï¼Œåˆæ­¥ç»“æœè¡¨æ˜ï¼Œä»”ç»†çš„æç¤ºå’Œå¾®è°ƒå¯ä»¥äº§ç”Ÿä¸€ä¸ªä¸“é—¨çš„LLMä»£ç†ï¼Œèƒ½å¤Ÿå¯é åœ°è§£å†³ç®€å•çš„ODEé—®é¢˜ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç§‘å­¦æœºå™¨å­¦ä¹ æ–¹æ³•ï¼Œå¦‚ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œç­‰ï¼Œç›´æ¥å­¦ä¹ ä»è¾“å…¥åˆ°è¾“å‡ºçš„æ˜ å°„ï¼Œåœ¨å¤æ‚ç§‘å­¦é—®é¢˜ä¸­éš¾ä»¥ä¿è¯ç²¾åº¦å’Œé²æ£’æ€§ã€‚è¿™äº›æ–¹æ³•éœ€è¦å­¦ä¹ å¤æ‚çš„è§£å‡½æ•°ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨LLMçš„ç¼–ç¨‹èƒ½åŠ›ï¼Œå°†ç§‘å­¦è®¡ç®—é—®é¢˜è½¬åŒ–ä¸ºä»£ç ç”Ÿæˆé—®é¢˜ã€‚LLMä¸å†ç›´æ¥é¢„æµ‹ç»“æœï¼Œè€Œæ˜¯ç”Ÿæˆè°ƒç”¨æˆç†Ÿæ•°å€¼ç®—æ³•çš„ä»£ç ï¼Œä»è€Œåˆ©ç”¨å·²æœ‰çš„æ•°å€¼è®¡ç®—å·¥å…·ï¼Œé™ä½äº†å­¦ä¹ éš¾åº¦ï¼Œæé«˜äº†è®¡ç®—æ•ˆç‡å’Œå¯é æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) è¾“å…¥ï¼šæ¥æ”¶è‡ªç„¶è¯­è¨€æè¿°çš„ODEé—®é¢˜ï¼›2) LLMä»£ç ç”Ÿæˆï¼šåˆ©ç”¨LLMç”Ÿæˆæ±‚è§£è¯¥ODEé—®é¢˜çš„Pythonä»£ç ï¼Œä»£ç ä¸­åŒ…å«æ•°å€¼æ±‚è§£å™¨çš„é€‰æ‹©å’Œè°ƒç”¨ï¼›3) ä»£ç æ‰§è¡Œï¼šæ‰§è¡Œç”Ÿæˆçš„ä»£ç ï¼Œå¾—åˆ°æ•°å€¼è§£ï¼›4) ç»“æœéªŒè¯ï¼šå°†æ•°å€¼è§£ä¸å‚è€ƒè§£è¿›è¡Œæ¯”è¾ƒï¼Œè¯„ä¼°LLMç”Ÿæˆçš„ä»£ç çš„æ­£ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºå°†LLMåº”ç”¨äºç§‘å­¦è®¡ç®—é¢†åŸŸï¼Œå¹¶å°†å…¶è§’è‰²ä»â€œè§£çš„é¢„æµ‹å™¨â€è½¬å˜ä¸ºâ€œæ±‚è§£å™¨ä»£ç çš„ç¼–å†™è€…â€ã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†LLMçš„ç¼–ç¨‹èƒ½åŠ›å’Œæ•°å€¼ç®—æ³•çš„æˆç†Ÿåº¦ï¼Œé¿å…äº†ç›´æ¥å­¦ä¹ å¤æ‚è§£å‡½æ•°çš„å›°éš¾ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´æ˜“äºå®ç°ã€è°ƒè¯•å’Œæ‰©å±•ã€‚

**å…³é”®è®¾è®¡**ï¼šå…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) æç¤ºå·¥ç¨‹ï¼šè®¾è®¡æœ‰æ•ˆçš„æç¤ºï¼Œå¼•å¯¼LLMç”Ÿæˆæ­£ç¡®çš„ä»£ç ï¼Œä¾‹å¦‚æä¾›ODEçš„æ•°å­¦æè¿°ã€æ±‚è§£å™¨çš„é€‰æ‹©å»ºè®®ç­‰ï¼›2) æ•°æ®é›†æ„å»ºï¼šæ„å»ºåŒ…å«å„ç§ODEé—®é¢˜çš„æ•°æ®é›†ï¼Œç”¨äºè®­ç»ƒå’Œè¯„ä¼°LLMï¼›3) è¯„ä¼°æŒ‡æ ‡ï¼šè®¾è®¡åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡ï¼Œè¡¡é‡LLMç”Ÿæˆçš„ä»£ç çš„å¯æ‰§è¡Œæ€§å’Œæ•°å€¼æœ‰æ•ˆæ€§ï¼Œä¾‹å¦‚ä»£ç æ˜¯å¦èƒ½æˆåŠŸè¿è¡Œï¼Œæ•°å€¼è§£çš„è¯¯å·®æ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡å’Œå¼•å¯¼æç¤ºï¼Œè¾ƒæ–°çš„æŒ‡ä»¤éµå¾ªæ¨¡å‹åœ¨å¯æ‰§è¡Œæ€§å’Œæ•°å€¼æœ‰æ•ˆæ€§æ–¹é¢éƒ½å–å¾—äº†è¾ƒé«˜çš„å‡†ç¡®ç‡ã€‚åœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæœ€æ–°çš„å¼€æºç³»ç»Ÿåœ¨æ²¡æœ‰å¾®è°ƒçš„æƒ…å†µä¸‹è¡¨ç°å‡ºè‰²ï¼Œè€Œè¾ƒæ—§æˆ–è¾ƒå°çš„æ¨¡å‹ä»ç„¶å—ç›Šäºå¾®è°ƒã€‚ä¾‹å¦‚ï¼Œåœ¨ç‰¹å®šæ•°æ®é›†ä¸Šï¼Œç»è¿‡å¾®è°ƒçš„LLMèƒ½å¤Ÿä»¥è¶…è¿‡90%çš„å‡†ç¡®ç‡ç”Ÿæˆå¯æ‰§è¡Œä¸”æ•°å€¼æœ‰æ•ˆçš„ä»£ç ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§ç§‘å­¦ä¸å·¥ç¨‹é¢†åŸŸï¼Œä¾‹å¦‚ç‰©ç†æ¨¡æ‹Ÿã€åŒ–å­¦ååº”åŠ¨åŠ›å­¦ã€ç”Ÿç‰©å»ºæ¨¡ç­‰ã€‚é€šè¿‡è‡ªç„¶è¯­è¨€æè¿°é—®é¢˜ï¼Œå³å¯è‡ªåŠ¨ç”Ÿæˆæ±‚è§£ä»£ç ï¼Œé™ä½äº†ç§‘å­¦è®¡ç®—çš„é—¨æ§›ï¼ŒåŠ é€Ÿäº†ç§‘å­¦å‘ç°çš„è¿›ç¨‹ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤æ‚çš„ç§‘å­¦è®¡ç®—ä»»åŠ¡ï¼Œä¾‹å¦‚åå¾®åˆ†æ–¹ç¨‹æ±‚è§£ã€ä¼˜åŒ–é—®é¢˜ç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent work in scientific machine learning aims to tackle scientific tasks directly by predicting target values with neural networks (e.g., physics-informed neural networks, neural ODEs, neural operators, etc.), but attaining high accuracy and robustness has been challenging. We explore an alternative view: use LLMs to write code that leverages decades of numerical algorithms. This shifts the burden from learning a solution function to making domain-aware numerical choices. We ask whether LLMs can act as SciML agents that, given a natural-language ODE description, generate runnable code that is scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff), and enforcing stability checks. There is currently no benchmark to measure this kind of capability for scientific computing tasks. As such, we first introduce two new datasets: a diagnostic dataset of adversarial "misleading" problems; and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set contains problems whose superficial appearance suggests stiffness, and that require algebraic simplification to demonstrate non-stiffness; and the large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open- and closed-source LLM models along two axes: (i) unguided versus guided prompting with domain-specific knowledge; and (ii) off-the-shelf versus fine-tuned variants. Our evaluation measures both executability and numerical validity against reference solutions. We find that with sufficient context and guided prompts, newer instruction-following models achieve high accuracy on both criteria. In many cases, recent open-source systems perform strongly without fine-tuning, while older or smaller models still benefit from fine-tuning. Overall, our preliminary results indicate that careful prompting and fine-tuning can yield a specialized LLM agent capable of reliably solving simple ODE problems.

