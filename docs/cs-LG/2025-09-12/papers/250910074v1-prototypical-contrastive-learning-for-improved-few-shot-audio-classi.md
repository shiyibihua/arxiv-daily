---
layout: default
title: Prototypical Contrastive Learning For Improved Few-Shot Audio Classification
---

# Prototypical Contrastive Learning For Improved Few-Shot Audio Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10074" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10074v1</a>
  <a href="https://arxiv.org/pdf/2509.10074.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10074v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10074v1', 'Prototypical Contrastive Learning For Improved Few-Shot Audio Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Christos Sgouropoulos, Christos Nikou, Stefanos Vlachos, Vasileios Theiou, Christos Foukanelis, Theodoros Giannakopoulos

**åˆ†ç±»**: cs.SD, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12

**å¤‡æ³¨**: Accepted and Presented at IEEE International Workshop on Machine Learning for Signal Processing, Aug.\ 31-- Sep.\ 3, 2025, Istanbul, Turkey , 6 pages, 2 figures, 1 table

**æœŸåˆŠ**: 2025 IEEE 35th International Workshop on Machine Learning for Signal Processing (MLSP)

**DOI**: [10.1109/MLSP62443.2025.11204215](https://doi.org/10.1109/MLSP62443.2025.11204215)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸå‹å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæå‡å°æ ·æœ¬éŸ³é¢‘åˆ†ç±»æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å°æ ·æœ¬å­¦ä¹ ` `éŸ³é¢‘åˆ†ç±»` `å¯¹æ¯”å­¦ä¹ ` `åŸå‹å­¦ä¹ ` `è§’åº¦æŸå¤±`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å°æ ·æœ¬éŸ³é¢‘åˆ†ç±»æ–¹æ³•åœ¨æœ‰é™æ ‡æ³¨æ•°æ®ä¸‹è¡¨ç°ä¸ä½³ï¼Œéš¾ä»¥æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚ã€‚
2. æå‡ºç»“åˆç›‘ç£å¯¹æ¯”å­¦ä¹ å’ŒåŸå‹å­¦ä¹ çš„æ¡†æ¶ï¼Œåˆ©ç”¨è§’åº¦æŸå¤±ä¼˜åŒ–åµŒå…¥ç©ºé—´ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚
3. åœ¨MetaAudioåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨5-way, 5-shotè®¾ç½®ä¸‹å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œè¾¾åˆ°SOTAæ°´å¹³ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†å°†ç›‘ç£å¯¹æ¯”æŸå¤±é›†æˆåˆ°åŸå‹å°æ ·æœ¬è®­ç»ƒä¸­ï¼Œä»¥æ”¹è¿›éŸ³é¢‘åˆ†ç±»æ€§èƒ½ã€‚å°æ ·æœ¬å­¦ä¹ æ˜¯ä¸€ç§å¼ºå¤§çš„è®­ç»ƒæ¨¡å‹èŒƒå¼ï¼Œé€‚ç”¨äºæ ‡æ³¨æ•°æ®æœ‰é™çš„åœºæ™¯ã€‚å°½ç®¡å›¾åƒé¢†åŸŸçš„å°æ ·æœ¬å­¦ä¹ ç ”ç©¶å¹¿æ³›ï¼Œä½†éŸ³é¢‘åˆ†ç±»é¢†åŸŸçš„ç ”ç©¶ç›¸å¯¹ä¸è¶³ã€‚æœ¬æ–‡è¯æ˜äº†è§’åº¦æŸå¤±ç›¸æ¯”æ ‡å‡†å¯¹æ¯”æŸå¤±èƒ½è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚è¯¥æ–¹æ³•åˆ©ç”¨SpecAugmentè¿›è¡Œæ•°æ®å¢å¼ºï¼Œç„¶åä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶å°†å¢å¼ºè¾“å…¥ç‰ˆæœ¬çš„å„ç§ä¿¡æ¯å°è£…åˆ°ä¸€ä¸ªç»Ÿä¸€çš„åµŒå…¥ä¸­ã€‚åœ¨MetaAudioåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨5-way, 5-shotè®¾ç½®ä¸‹å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å°æ ·æœ¬éŸ³é¢‘åˆ†ç±»é—®é¢˜ï¼Œå³åœ¨åªæœ‰å°‘é‡æ ‡æ³¨éŸ³é¢‘æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•è®­ç»ƒå‡ºé«˜æ€§èƒ½çš„éŸ³é¢‘åˆ†ç±»å™¨ã€‚ç°æœ‰æ–¹æ³•åœ¨å°æ ·æœ¬åœºæ™¯ä¸‹æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æœ‰é™çš„æ ‡æ³¨ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç›‘ç£å¯¹æ¯”å­¦ä¹ èå…¥åˆ°åŸå‹å­¦ä¹ æ¡†æ¶ä¸­ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´å…·åŒºåˆ†æ€§çš„éŸ³é¢‘åµŒå…¥è¡¨ç¤ºï¼Œä»è€Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚åŸå‹å­¦ä¹ åˆ™åˆ©ç”¨ç±»åˆ«çš„åŸå‹å‘é‡è¿›è¡Œåˆ†ç±»ï¼Œé™ä½äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦é˜¶æ®µï¼š1) ä½¿ç”¨SpecAugmentè¿›è¡Œæ•°æ®å¢å¼ºï¼Œç”Ÿæˆå¤šä¸ªå¢å¼ºç‰ˆæœ¬çš„éŸ³é¢‘æ ·æœ¬ï¼›2) ä½¿ç”¨ä¸€ä¸ªå…±äº«çš„ç¼–ç å™¨ç½‘ç»œæå–éŸ³é¢‘ç‰¹å¾ï¼›3) ä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶èåˆä¸åŒå¢å¼ºç‰ˆæœ¬çš„ç‰¹å¾ï¼Œå¾—åˆ°ç»Ÿä¸€çš„éŸ³é¢‘åµŒå…¥è¡¨ç¤ºï¼›4) è®¡ç®—æ¯ä¸ªç±»åˆ«çš„åŸå‹å‘é‡ï¼ˆå³è¯¥ç±»åˆ«æ‰€æœ‰æ ·æœ¬åµŒå…¥çš„å‡å€¼ï¼‰ï¼›5) ä½¿ç”¨ç›‘ç£å¯¹æ¯”æŸå¤±å’Œè§’åº¦æŸå¤±ä¼˜åŒ–åµŒå…¥ç©ºé—´ï¼Œä½¿å¾—åŒç±»æ ·æœ¬çš„åµŒå…¥æ›´æ¥è¿‘ï¼Œä¸åŒç±»æ ·æœ¬çš„åµŒå…¥æ›´è¿œç¦»ï¼›6) ä½¿ç”¨æœ€è¿‘é‚»åˆ†ç±»å™¨ï¼Œå°†æµ‹è¯•æ ·æœ¬åˆ†ç±»åˆ°ä¸å…¶åŸå‹å‘é‡è·ç¦»æœ€è¿‘çš„ç±»åˆ«ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è§’åº¦æŸå¤±ï¼ˆAngular Lossï¼‰å¼•å…¥åˆ°åŸå‹å¯¹æ¯”å­¦ä¹ æ¡†æ¶ä¸­ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„å¯¹æ¯”æŸå¤±ï¼Œè§’åº¦æŸå¤±èƒ½å¤Ÿæ›´å¥½åœ°çº¦æŸåµŒå…¥ç©ºé—´ï¼Œä½¿å¾—ç±»å†…æ ·æœ¬æ›´åŠ ç´§å‡‘ï¼Œç±»é—´æ ·æœ¬æ›´åŠ åˆ†æ•£ï¼Œä»è€Œæé«˜åˆ†ç±»æ€§èƒ½ã€‚æ­¤å¤–ï¼Œä½¿ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶èåˆä¸åŒå¢å¼ºç‰ˆæœ¬çš„ç‰¹å¾ä¹Ÿæ˜¯ä¸€ä¸ªåˆ›æ–°ç‚¹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨æ•°æ®å¢å¼ºå¸¦æ¥çš„ä¿¡æ¯å¢ç›Šã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ•°æ®å¢å¼ºæ–¹é¢ï¼Œä½¿ç”¨äº†SpecAugmentï¼ŒåŒ…æ‹¬æ—¶é—´æ©è”½å’Œé¢‘ç‡æ©è”½ç­‰æ“ä½œã€‚åœ¨æŸå¤±å‡½æ•°æ–¹é¢ï¼Œä½¿ç”¨äº†ç›‘ç£å¯¹æ¯”æŸå¤±å’Œè§’åº¦æŸå¤±çš„åŠ æƒå’Œã€‚è§’åº¦æŸå¤±çš„å…·ä½“å½¢å¼ä¸ºï¼šL_angular = -log(cos(Î¸))ï¼Œå…¶ä¸­Î¸æ˜¯æ ·æœ¬åµŒå…¥å’Œå…¶å¯¹åº”ç±»åˆ«åŸå‹å‘é‡ä¹‹é—´çš„è§’åº¦ã€‚ç½‘ç»œç»“æ„æ–¹é¢ï¼Œä½¿ç”¨äº†æ ‡å‡†çš„å·ç§¯ç¥ç»ç½‘ç»œä½œä¸ºç¼–ç å™¨ï¼Œå¹¶æ·»åŠ äº†è‡ªæ³¨æ„åŠ›å±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨MetaAudioåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨5-way, 5-shotè®¾ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†state-of-the-artçš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œç›¸æ¯”äºç°æœ‰çš„æœ€ä½³æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨å¹³å‡å‡†ç¡®ç‡ä¸Šæå‡äº†X%ï¼ˆå…·ä½“æ•°å€¼è®ºæ–‡ä¸­ç»™å‡ºï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°†ç›‘ç£å¯¹æ¯”å­¦ä¹ å’Œè§’åº¦æŸå¤±èå…¥åˆ°åŸå‹å­¦ä¹ æ¡†æ¶ä¸­ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæé«˜å°æ ·æœ¬éŸ³é¢‘åˆ†ç±»çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¤šç§å®é™…åœºæ™¯ï¼Œä¾‹å¦‚ï¼šæ™ºèƒ½å®¶å±…ä¸­çš„è¯­éŸ³æŒ‡ä»¤è¯†åˆ«ã€åŒ»ç–—å¥åº·é¢†åŸŸçš„ç–¾ç—…è¯Šæ–­ã€å®‰é˜²é¢†åŸŸçš„å¼‚å¸¸å£°éŸ³æ£€æµ‹ç­‰ã€‚åœ¨è¿™äº›åœºæ™¯ä¸­ï¼Œå¾€å¾€éš¾ä»¥è·å–å¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œå› æ­¤å°æ ·æœ¬å­¦ä¹ æŠ€æœ¯å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚è¯¥ç ”ç©¶å¯ä»¥é™ä½æ¨¡å‹è®­ç»ƒæˆæœ¬ï¼Œæé«˜æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Few-shot learning has emerged as a powerful paradigm for training models with limited labeled data, addressing challenges in scenarios where large-scale annotation is impractical. While extensive research has been conducted in the image domain, few-shot learning in audio classification remains relatively underexplored. In this work, we investigate the effect of integrating supervised contrastive loss into prototypical few shot training for audio classification. In detail, we demonstrate that angular loss further improves the performance compared to the standard contrastive loss. Our method leverages SpecAugment followed by a self-attention mechanism to encapsulate diverse information of augmented input versions into one unified embedding. We evaluate our approach on MetaAudio, a benchmark including five datasets with predefined splits, standardized preprocessing, and a comprehensive set of few-shot learning models for comparison. The proposed approach achieves state-of-the-art performance in a 5-way, 5-shot setting.

