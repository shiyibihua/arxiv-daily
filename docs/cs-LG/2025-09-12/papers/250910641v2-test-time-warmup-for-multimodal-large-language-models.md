---
layout: default
title: Test-Time Warmup for Multimodal Large Language Models
---

# Test-Time Warmup for Multimodal Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.10641" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.10641v2</a>
  <a href="https://arxiv.org/pdf/2509.10641.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.10641v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.10641v2', 'Test-Time Warmup for Multimodal Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikita Rajaneesh, Thomas Zollo, Richard Zemel

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-12 (æ›´æ–°: 2025-11-06)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæµ‹è¯•æ—¶é¢„çƒ­æ–¹æ³•ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `æµ‹è¯•æ—¶é¢„çƒ­` `å¼±ç›‘ç£å­¦ä¹ ` `è‡ªé€‚åº”å­¦ä¹ ` `å¤æ‚æ¨ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è®­ç»ƒæ•°æ®é‡ä¸è¶³ï¼Œå¯¼è‡´åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ã€‚
2. æå‡ºæµ‹è¯•æ—¶é¢„çƒ­æ–¹æ³•ï¼Œåˆ©ç”¨å¼±ç›‘ç£è¾…åŠ©ä»»åŠ¡æ•°æ®ï¼Œä¸ºæ¯ä¸ªæµ‹è¯•å®ä¾‹è‡ªé€‚åº”è°ƒæ•´æ¨¡å‹ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æ¨¡å‹æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)åœ¨æ–‡æœ¬å’Œå›¾åƒäº¤å‰é¢†åŸŸçš„é«˜çº§æ¨ç†æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†å°šæœªå®Œå…¨å‘æŒ¥ã€‚MLLMé€šå¸¸é›†æˆLLMã€è§†è§‰ç¼–ç å™¨å’Œä¸€ä¸ªè¿æ¥å™¨ï¼Œè¯¥è¿æ¥å™¨å°†è§†è§‰ç¼–ç å™¨çš„åµŒå…¥æ˜ å°„åˆ°LLMçš„æ–‡æœ¬åµŒå…¥ç©ºé—´ã€‚å°½ç®¡æ¯ä¸ªç»„ä»¶éƒ½åœ¨åŒ…å«æ•°åäº¿æ ·æœ¬çš„æµ·é‡æ•°æ®é›†ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œä½†æ•´ä¸ªå¤šæ¨¡æ€æ¨¡å‹é€šå¸¸åªåœ¨æ•°åƒä¸ª(æˆ–æ•°ç™¾ä¸‡ä¸ª)æ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼Œè¿™å¯èƒ½å¯¼è‡´åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½è¾ƒå¼±ã€‚ä¸ºäº†è§£å†³è¿™äº›ç¼ºç‚¹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æµ‹è¯•æ—¶é¢„çƒ­æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨æ¥è‡ªå¼±ç›‘ç£è¾…åŠ©ä»»åŠ¡çš„æ•°æ®æ¥ä¸ºæ¯ä¸ªæµ‹è¯•å®ä¾‹è°ƒæ•´MLLMï¼Œè€Œä¸æ˜¯ä¾èµ–äºç”¨äºå¾®è°ƒçš„å¤§é‡æ ‡è®°æ•°æ®é›†ã€‚é€šè¿‡æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°Llama-Vision-Instructæ¨¡å‹åœ¨MMMUä¸Šç›¸å¯¹æ€§èƒ½æé«˜äº†4.03%ï¼Œåœ¨VQA-Radä¸Šæé«˜äº†5.28%ï¼Œåœ¨GQAä¸Šæé«˜äº†1.63%ã€‚æˆ‘ä»¬çš„æ–¹æ³•è¡¨æ˜ï¼Œæ¨ç†å‰çš„â€œé¢„çƒ­â€å¯ä»¥å¢å¼ºMLLMåœ¨å„ç§æ¨ç†ä»»åŠ¡ä¸­çš„é²æ£’æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰è™½ç„¶åœ¨å„ä¸ªæ¨¡æ€ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼Œä½†æ•´ä½“çš„å¤šæ¨¡æ€è®­ç»ƒæ•°æ®é‡ç›¸å¯¹è¾ƒå°ï¼Œå¯¼è‡´æ¨¡å‹åœ¨å¤„ç†éœ€è¦å¤æ‚æ¨ç†çš„ä»»åŠ¡æ—¶æ€§èƒ½å—é™ã€‚ç°æœ‰çš„å¾®è°ƒæ–¹æ³•ä¾èµ–äºå¤§é‡çš„æ ‡æ³¨æ•°æ®ï¼Œè·å–æˆæœ¬é«˜æ˜‚ï¼Œä¸”æ³›åŒ–èƒ½åŠ›å¯èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åœ¨æµ‹è¯•é˜¶æ®µï¼Œé€šè¿‡åˆ©ç”¨å¼±ç›‘ç£çš„è¾…åŠ©ä»»åŠ¡æ•°æ®ï¼Œå¯¹æ¨¡å‹è¿›è¡Œâ€œé¢„çƒ­â€ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”å½“å‰çš„æµ‹è¯•æ ·æœ¬ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¹¶ä¸”èƒ½å¤Ÿæå‡æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºæµ‹è¯•æ—¶é¢„çƒ­ï¼ˆTest-Time Warmupï¼‰ã€‚å…·ä½“æµç¨‹å¦‚ä¸‹ï¼šå¯¹äºæ¯ä¸€ä¸ªæµ‹è¯•æ ·æœ¬ï¼Œé¦–å…ˆåˆ©ç”¨å¼±ç›‘ç£è¾…åŠ©ä»»åŠ¡çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå°‘é‡è¿­ä»£çš„è®­ç»ƒï¼Œè¿™ä¸ªè¿‡ç¨‹ç§°ä¸ºâ€œé¢„çƒ­â€ã€‚é¢„çƒ­å®Œæˆåï¼Œå†ä½¿ç”¨åŸå§‹çš„æµ‹è¯•æ ·æœ¬è¿›è¡Œæ¨ç†ï¼Œå¾—åˆ°æœ€ç»ˆçš„é¢„æµ‹ç»“æœã€‚æ•´ä¸ªè¿‡ç¨‹ä¸éœ€è¦é¢å¤–çš„æ ‡æ³¨æ•°æ®ï¼Œè€Œæ˜¯åˆ©ç”¨å·²æœ‰çš„å¼±ç›‘ç£ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºå°†æµ‹è¯•æ—¶è‡ªé€‚åº”çš„æ€æƒ³å¼•å…¥åˆ°å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­ã€‚ä¸ä¼ ç»Ÿçš„å¾®è°ƒæ–¹æ³•ä¸åŒï¼Œè¯¥æ–¹æ³•ä¸æ˜¯åœ¨è®­ç»ƒé˜¶æ®µå¯¹æ¨¡å‹è¿›è¡Œå…¨å±€çš„è°ƒæ•´ï¼Œè€Œæ˜¯åœ¨æµ‹è¯•é˜¶æ®µé’ˆå¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå±€éƒ¨çš„ä¼˜åŒ–ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„æµ‹è¯•æ ·æœ¬ï¼Œå¹¶ä¸”èƒ½å¤Ÿæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å¹¶æ²¡æœ‰è¯¦ç»†æè¿°å…·ä½“çš„å¼±ç›‘ç£è¾…åŠ©ä»»åŠ¡çš„é€‰æ‹©å’Œå®ç°ç»†èŠ‚ï¼Œè¿™éƒ¨åˆ†å†…å®¹å¯èƒ½éœ€è¦æ ¹æ®å…·ä½“çš„åº”ç”¨åœºæ™¯è¿›è¡Œè°ƒæ•´ã€‚å¦å¤–ï¼Œé¢„çƒ­çš„è¿­ä»£æ¬¡æ•°å’Œå­¦ä¹ ç‡ç­‰è¶…å‚æ•°çš„é€‰æ‹©ä¹Ÿä¼šå½±å“æœ€ç»ˆçš„æ€§èƒ½ï¼Œéœ€è¦è¿›è¡Œå®éªŒè°ƒä¼˜ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨MMMUæ•°æ®é›†ä¸Šç›¸å¯¹æå‡äº†4.03%ï¼Œåœ¨VQA-Radæ•°æ®é›†ä¸Šç›¸å¯¹æå‡äº†5.28%ï¼Œåœ¨GQAæ•°æ®é›†ä¸Šç›¸å¯¹æå‡äº†1.63%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œæµ‹è¯•æ—¶é¢„çƒ­æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°æå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œå¹¶ä¸”å…·æœ‰è¾ƒå¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å¤šæ¨¡æ€ä¿¡æ¯èåˆå’Œå¤æ‚æ¨ç†çš„åœºæ™¯ï¼Œä¾‹å¦‚æ™ºèƒ½é—®ç­”ã€åŒ»å­¦å½±åƒè¯Šæ–­ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡æµ‹è¯•æ—¶é¢„çƒ­ï¼Œå¯ä»¥æå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„é²æ£’æ€§å’Œå‡†ç¡®æ€§ï¼Œé™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå…·æœ‰é‡è¦çš„å®é™…åº”ç”¨ä»·å€¼å’Œæ½œåœ¨çš„å•†ä¸šå‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) hold great promise for advanced reasoning at the intersection of text and images, yet they have not fully realized this potential. MLLMs typically integrate an LLM, a vision encoder, and a connector that maps the vision encoder's embeddings into the LLM's text embedding space. Although each component is pretrained on massive datasets with billions of samples, the entire multimodal model is typically trained on only thousands (or a few million) samples, which can result in weak performance on complex reasoning tasks. To address these shortcomings, instead of relying on extensive labeled datasets for fine-tuning, we propose a Test-Time Warmup method that adapts the MLLM per test instance by leveraging data from weakly supervised auxiliary tasks. With our approach, we observe a relative performance improvement of 4.03% on MMMU, 5.28% on VQA-Rad, and 1.63% on GQA on the Llama-Vision-Instruct model. Our method demonstrates that 'warming up' before inference can enhance MLLMs' robustness across diverse reasoning tasks.

