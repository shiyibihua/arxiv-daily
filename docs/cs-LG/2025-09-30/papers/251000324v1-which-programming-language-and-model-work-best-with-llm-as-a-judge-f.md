---
layout: default
title: Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?
---

# Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00324" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00324v1</a>
  <a href="https://arxiv.org/pdf/2510.00324.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00324v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00324v1', 'Which Programming Language and Model Work Best With LLM-as-a-Judge For Code Retrieval?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Lucas Roberts, Denisa Roberts

**åˆ†ç±»**: cs.SE, cs.IR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**å¤‡æ³¨**: Accepted as a full paper at SIGIR-AP 2025

**DOI**: [10.1145/3767695.3769503](https://doi.org/10.1145/3767695.3769503)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/rlucas7/code-searcher/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ä¼˜åŒ–ä»£ç æ£€ç´¢ä¸æ³¨é‡Šç”Ÿæˆ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä»£ç æ£€ç´¢` `å¤§å‹è¯­è¨€æ¨¡å‹` `ç¼–ç¨‹è¯­è¨€` `äººå·¥æ™ºèƒ½` `ä¿¡æ¯æ£€ç´¢` `è½¯ä»¶å·¥ç¨‹` `è‡ªåŠ¨æ³¨é‡Šç”Ÿæˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ä»£ç æ£€ç´¢æ–¹æ³•é¢ä¸´é«˜æ˜‚çš„äººä¸ºæ³¨é‡Šæˆæœ¬ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§ã€‚
2. æœ¬ç ”ç©¶æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œä»£ç æ£€ç´¢å’Œæ³¨é‡Šç”Ÿæˆï¼Œæ¯”è¾ƒä¸åŒç¼–ç¨‹è¯­è¨€å’Œæ£€ç´¢å™¨çš„å½±å“ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œé€‰æ‹©åˆé€‚çš„æ£€ç´¢å™¨å’Œç¼–ç¨‹è¯­è¨€å¯ä»¥æ˜¾è‘—æé«˜äººç±»ä¸AIçš„ç›¸å…³æ€§åˆ¤æ–­ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»£ç æ£€ç´¢æ˜¯ä¿¡æ¯æ£€ç´¢ä¸­çš„é‡è¦åº”ç”¨ï¼Œèƒ½å¤ŸåŠ é€Ÿæ–°å¼€å‘è€…çš„å…¥é—¨ã€é™ä½è½¯ä»¶ç»´æŠ¤æˆæœ¬å¹¶æé«˜å¯¹å¤§å‹ä»£ç åº“çš„ç†è§£ã€‚ç„¶è€Œï¼Œå°½ç®¡æœç´¢ç®—æ³•å’ŒåŸºå‡†æµ‹è¯•æœ‰æ‰€æ”¹è¿›ï¼Œä»£ç æ£€ç´¢é¢†åŸŸä»ç„¶æ»åï¼Œä¸»è¦åŸå› åœ¨äºä»£ç æŸ¥è¯¢å’Œç­”æ¡ˆçš„äººä¸ºæ³¨é‡Šæˆæœ¬é«˜æ˜‚ã€‚æœ¬ç ”ç©¶æ¢è®¨äº†ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å‡½æ•°çº§åˆ«æ£€ç´¢ä»£ç å¹¶ç”Ÿæˆæ³¨é‡Šçš„å¯è¡Œæ€§ã€‚é€šè¿‡æ¯”è¾ƒç¨€ç–ä¸è¯­ä¹‰æ£€ç´¢å™¨ã€ç¼–ç¨‹è¯­è¨€åŠLLMçš„å½±å“ï¼Œå‘ç°é€‰æ‹©çš„æ£€ç´¢å™¨å’Œç¼–ç¨‹è¯­è¨€ä¹‹é—´å­˜åœ¨å¯åˆ©ç”¨çš„äº²å’Œæ€§ï¼Œä»è€Œæ”¹å–„äººç±»ä¸AIçš„ç›¸å…³æ€§åˆ¤æ–­ã€‚ç ”ç©¶è¿˜æå‡ºä½¿ç”¨è½¬è¯‘å™¨æ¥æ„å»ºå¯æ‰©å±•çš„ä»£ç æ£€ç´¢åŸºå‡†æ•°æ®é›†ï¼Œå¹¶å±•ç¤ºäº†äººç±»ä¸AIçš„ç›¸å…³æ€§ä¸€è‡´æ€§ç‡ä¸äººç±»ä¹‹é—´çš„ä¸€è‡´æ€§ç›¸åŒ¹é…ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³ä»£ç æ£€ç´¢ä¸­é«˜æ˜‚çš„äººä¸ºæ³¨é‡Šæˆæœ¬é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ä»£ç æŸ¥è¯¢å’Œç­”æ¡ˆæ—¶ï¼Œç¼ºä¹æœ‰æ•ˆçš„è‡ªåŠ¨åŒ–æ‰‹æ®µï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬ç ”ç©¶çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥è‡ªåŠ¨æ£€ç´¢ä»£ç å¹¶ç”Ÿæˆæ³¨é‡Šï¼Œä»è€Œå‡å°‘å¯¹äººå·¥æ³¨é‡Šçš„ä¾èµ–ã€‚é€šè¿‡æ¯”è¾ƒä¸åŒçš„ç¼–ç¨‹è¯­è¨€å’Œæ£€ç´¢å™¨ï¼Œæ¢ç´¢å…¶å¯¹æ£€ç´¢æ•ˆæœçš„å½±å“ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†ã€LLMæ£€ç´¢ã€æ³¨é‡Šç”Ÿæˆå’Œæ•ˆæœè¯„ä¼°å››ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆæ”¶é›†å®ç°å¸¸è§æ•°æ®ç»“æ„çš„ä»£ç åº“ï¼Œç„¶åä½¿ç”¨LLMsè¿›è¡Œä»£ç æ£€ç´¢å’Œæ³¨é‡Šç”Ÿæˆï¼Œæœ€åé€šè¿‡äººç±»æ ‡æ³¨è¿›è¡Œæ•ˆæœè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†åˆ©ç”¨LLMsè¿›è¡Œä»£ç æ£€ç´¢çš„æ¡†æ¶ï¼Œå¹¶å‘ç°ä¸åŒç¼–ç¨‹è¯­è¨€å’Œæ£€ç´¢å™¨ä¹‹é—´çš„äº²å’Œæ€§å¯ä»¥æ˜¾è‘—æ”¹å–„äººç±»ä¸AIçš„ç›¸å…³æ€§åˆ¤æ–­ä¸€è‡´æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºä»£ç æ£€ç´¢é¢†åŸŸæä¾›äº†æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œé‡‡ç”¨äº†ç¨€ç–å’Œè¯­ä¹‰æ£€ç´¢å™¨çš„å¯¹æ¯”ï¼Œè®¾ç½®äº†å¤šç§ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚Cã€Javaã€JavaScriptã€Goå’ŒPythonï¼‰ï¼Œå¹¶é€šè¿‡è½¬è¯‘å™¨æ„å»ºå¯æ‰©å±•çš„åŸºå‡†æ•°æ®é›†ï¼Œç¡®ä¿äº†å®éªŒçš„å…¨é¢æ€§å’Œæœ‰æ•ˆæ€§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€‰æ‹©åˆé€‚çš„æ£€ç´¢å™¨å’Œç¼–ç¨‹è¯­è¨€å¯ä»¥æ˜¾è‘—æé«˜äººç±»ä¸AIçš„ç›¸å…³æ€§åˆ¤æ–­ä¸€è‡´æ€§ï¼Œè¾¾åˆ°ä¸äººç±»ä¹‹é—´ä¸€è‡´æ€§ç›¸åŒ¹é…çš„æ°´å¹³ã€‚æ­¤å¤–ï¼Œç¨€ç–ä¸è¯­ä¹‰æ£€ç´¢å™¨åœ¨ä¸åŒç¼–ç¨‹è¯­è¨€ä¸Šçš„è¡¨ç°å·®å¼‚ä¹Ÿä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„æ–¹å‘ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è½¯ä»¶å¼€å‘ã€ä»£ç ç»´æŠ¤å’Œæ•™è‚²ç­‰ã€‚é€šè¿‡æé«˜ä»£ç æ£€ç´¢çš„æ•ˆç‡ï¼Œèƒ½å¤Ÿå¸®åŠ©å¼€å‘è€…æ›´å¿«åœ°æ‰¾åˆ°æ‰€éœ€ä»£ç ï¼Œé™ä½å­¦ä¹ æ›²çº¿ï¼Œå¹¶æå‡è½¯ä»¶ç»´æŠ¤çš„ä¾¿æ·æ€§ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¹¿æ³›çš„ç¼–ç¨‹è¯­è¨€å’Œåœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Code search is an important information retrieval application. Benefits of better code search include faster new developer on-boarding, reduced software maintenance, and ease of understanding for large repositories. Despite improvements in search algorithms and search benchmarks, the domain of code search has lagged behind. One reason is the high cost of human annotation for code queries and answers. While humans may annotate search results in general text QA systems, code annotations require specialized knowledge of a programming language (PL), as well as domain specific software engineering knowledge. In this work we study the use of Large Language Models (LLMs) to retrieve code at the level of functions and to generate annotations for code search results. We compare the impact of the retriever representation (sparse vs. semantic), programming language, and LLM by comparing human annotations across several popular languages (C, Java, Javascript, Go, and Python). We focus on repositories that implement common data structures likely to be implemented in any PLs. For the same human annotations, we compare several LLM-as-a-Judge models to evaluate programming language and other affinities between LLMs. We find that the chosen retriever and PL exhibit affinities that can be leveraged to improve alignment of human and AI relevance determinations, with significant performance implications. We also find differences in representation (sparse vs. semantic) across PLs that impact alignment of human and AI relevance determinations. We propose using transpilers to bootstrap scalable code search benchmark datasets in other PLs and in a case study demonstrate that human-AI relevance agreement rates largely match the (worst case) human-human agreement under study. The application code used in this work is available at \href{https://github.com/rlucas7/code-searcher/}{this github repo}.

