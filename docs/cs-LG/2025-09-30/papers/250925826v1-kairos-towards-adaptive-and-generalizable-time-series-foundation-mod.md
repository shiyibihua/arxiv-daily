---
layout: default
title: Kairos: Towards Adaptive and Generalizable Time Series Foundation Models
---

# Kairos: Towards Adaptive and Generalizable Time Series Foundation Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25826" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.25826v1</a>
  <a href="https://arxiv.org/pdf/2509.25826.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25826v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25826v1', 'Kairos: Towards Adaptive and Generalizable Time Series Foundation Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kun Feng, Shaocheng Lan, Yuchen Fang, Wenchao He, Lintao Ma, Xingyu Lu, Kan Ren

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://foundation-model-research.github.io/Kairos)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**Kairosï¼šé¢å‘è‡ªé€‚åº”å’Œæ³›åŒ–æ—¶é—´åºåˆ—çš„é€šç”¨æ¨¡å‹æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ—¶é—´åºåˆ—åˆ†æ` `é€šç”¨æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ ` `è‡ªé€‚åº”å­¦ä¹ ` `åŠ¨æ€Patching` `Positional Embedding` `Transformer` `é¢„è®­ç»ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ—¶é—´åºåˆ—é€šç”¨æ¨¡å‹æ— æ³•æœ‰æ•ˆå¤„ç†æ—¶é—´åºåˆ—ä¸­å¼‚æ„çš„ä¿¡æ¯å¯†åº¦ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ã€‚
2. Kairosé€šè¿‡åŠ¨æ€patching tokenizerå’Œå®ä¾‹è‡ªé€‚åº”positional embeddingï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´tokenizationç²’åº¦å’Œpositional encodingã€‚
3. Kairosåœ¨PreSTSè¯­æ–™åº“ä¸Šè®­ç»ƒï¼Œå¹¶åœ¨GIFT-Evalå’ŒTime-Series-LibraryåŸºå‡†æµ‹è¯•ä¸­ï¼Œä»¥æ›´å°‘çš„å‚æ•°ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ—¶é—´åºåˆ—é€šç”¨æ¨¡å‹ï¼ˆTSFMsï¼‰å·²æˆä¸ºæ—¶é—´åºåˆ—åˆ†æçš„å¼ºå¤§èŒƒä¾‹ï¼Œè¿™å¾—ç›Šäºåœ¨å¤šæ ·åŒ–æ•°æ®è¯­æ–™åº“ä¸Šçš„å¤§è§„æ¨¡é¢„è®­ç»ƒã€‚ç„¶è€Œï¼Œæ—¶é—´åºåˆ—æœ¬è´¨ä¸Šåœ¨æ—¶é—´ä¸Šè¡¨ç°å‡ºå¼‚æ„çš„ä¿¡æ¯å¯†åº¦ï¼Œå—ç³»ç»ŸçŠ¶æ€å’Œä¿¡å·å¤æ‚æ€§çš„å½±å“ï¼Œè¿™å¸¦æ¥äº†å·¨å¤§çš„å»ºæ¨¡æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨é›¶æ ·æœ¬åœºæ™¯ä¸­ã€‚å½“å‰çš„TSFMsä¾èµ–äºéè‡ªé€‚åº”çš„å¤„ç†æµç¨‹ï¼Œæ— æ³•æ•æ‰è¿™ç§åŠ¨æ€ç‰¹æ€§ã€‚ä¾‹å¦‚ï¼Œå¸¸è§çš„tokenizationç­–ç•¥ï¼ˆå¦‚å›ºå®šå¤§å°çš„patchingï¼‰å¼ºåˆ¶æ‰§è¡Œä¸¥æ ¼çš„è§‚å¯Ÿç²’åº¦ï¼Œé™åˆ¶äº†å®ƒä»¬é€‚åº”ä¸åŒä¿¡æ¯å¯†åº¦çš„èƒ½åŠ›ã€‚ç±»ä¼¼åœ°ï¼Œä¼ ç»Ÿçš„positional encodingæ–½åŠ äº†ç»Ÿä¸€çš„æ—¶é—´å°ºåº¦ï¼Œä½¿å¾—éš¾ä»¥å¯¹åºåˆ—ä¸­ä¸åŒçš„å‘¨æœŸæ€§å’Œè¶‹åŠ¿è¿›è¡Œå»ºæ¨¡ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†Kairosï¼Œä¸€ä¸ªçµæ´»çš„TSFMæ¡†æ¶ï¼Œå®ƒé›†æˆäº†åŠ¨æ€patching tokenizerå’Œå®ä¾‹è‡ªé€‚åº”positional embeddingã€‚Kairosè‡ªé€‚åº”åœ°é€‰æ‹©tokenizationç²’åº¦ï¼Œå¹¶æ ¹æ®æ¯ä¸ªæ—¶é—´åºåˆ—å®ä¾‹çš„ç‹¬ç‰¹ç‰¹å¾å®šåˆ¶positional encodingã€‚Kairosåœ¨åŒ…å«è¶…è¿‡3000äº¿ä¸ªæ—¶é—´ç‚¹çš„å¯é¢„æµ‹æ€§åˆ†å±‚æ—¶é—´åºåˆ—ï¼ˆPreSTSï¼‰è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æ¨ç†é˜¶æ®µé‡‡ç”¨å¤špatché¢„æµ‹ç­–ç•¥ï¼Œåœ¨ä¸¤ä¸ªå¸¸è§çš„é›¶æ ·æœ¬åŸºå‡†GIFT-Evalå’ŒTime-Series-LibraryåŸºå‡†ä¸Šå®ç°äº†å“è¶Šçš„æ€§èƒ½ï¼Œåœ¨å„ç§ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºå·²å»ºç«‹çš„æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰æ—¶é—´åºåˆ—é€šç”¨æ¨¡å‹ï¼ˆTSFMsï¼‰åœ¨å¤„ç†å…·æœ‰å¼‚æ„ä¿¡æ¯å¯†åº¦çš„æ—¶é—´åºåˆ—æ—¶å­˜åœ¨å±€é™æ€§ã€‚å›ºå®šå¤§å°çš„patchingå’Œç»Ÿä¸€çš„positional encodingæ— æ³•é€‚åº”ä¸åŒæ—¶é—´åºåˆ—å®ä¾‹çš„åŠ¨æ€ç‰¹æ€§ï¼Œå¯¼è‡´é›¶æ ·æœ¬å­¦ä¹ æ€§èƒ½ä¸‹é™ã€‚ç°æœ‰æ–¹æ³•æ— æ³•æ ¹æ®æ—¶é—´åºåˆ—çš„å¤æ‚åº¦å’Œç³»ç»ŸçŠ¶æ€è‡ªé€‚åº”åœ°è°ƒæ•´å¤„ç†ç²’åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šKairosçš„æ ¸å¿ƒæ€è·¯æ˜¯å¼•å…¥è‡ªé€‚åº”æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®æ¯ä¸ªæ—¶é—´åºåˆ—å®ä¾‹çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´tokenizationç²’åº¦å’Œpositional encodingã€‚é€šè¿‡åŠ¨æ€patching tokenizerï¼ŒKairoså¯ä»¥æ ¹æ®ä¿¡æ¯å¯†åº¦é€‰æ‹©åˆé€‚çš„patchå¤§å°ã€‚é€šè¿‡å®ä¾‹è‡ªé€‚åº”positional embeddingï¼ŒKairoså¯ä»¥ä¸ºæ¯ä¸ªæ—¶é—´åºåˆ—å®šåˆ¶positional encodingï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰ä¸åŒçš„å‘¨æœŸæ€§å’Œè¶‹åŠ¿ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šKairosçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) **åŠ¨æ€Patching Tokenizer**ï¼šæ ¹æ®æ—¶é—´åºåˆ—çš„ä¿¡æ¯å¯†åº¦è‡ªé€‚åº”åœ°é€‰æ‹©patchå¤§å°ã€‚2) **å®ä¾‹è‡ªé€‚åº”Positional Embedding**ï¼šä¸ºæ¯ä¸ªæ—¶é—´åºåˆ—å®ä¾‹ç”Ÿæˆå®šåˆ¶çš„positional encodingã€‚3) **Transformer Backbone**ï¼šä½¿ç”¨Transformeræ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—çš„ç¼–ç å’Œé¢„æµ‹ã€‚4) **å¤šPatché¢„æµ‹**ï¼šåœ¨æ¨ç†é˜¶æ®µï¼Œé‡‡ç”¨å¤špatché¢„æµ‹ç­–ç•¥ï¼Œæé«˜é¢„æµ‹ç²¾åº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šKairosçš„å…³é”®åˆ›æ–°åœ¨äºå…¶è‡ªé€‚åº”æ€§ã€‚ä¸ä¼ ç»Ÿçš„TSFMsç›¸æ¯”ï¼ŒKairosèƒ½å¤Ÿæ ¹æ®æ¯ä¸ªæ—¶é—´åºåˆ—å®ä¾‹çš„ç‰¹æ€§åŠ¨æ€è°ƒæ•´tokenizationç²’åº¦å’Œpositional encodingã€‚è¿™ç§è‡ªé€‚åº”æ€§ä½¿å¾—Kairosèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å…·æœ‰å¼‚æ„ä¿¡æ¯å¯†åº¦çš„æ—¶é—´åºåˆ—ï¼Œä»è€Œæé«˜é›¶æ ·æœ¬å­¦ä¹ æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€patching tokenizerçš„è®¾è®¡æ¶‰åŠå¦‚ä½•è¡¡é‡æ—¶é—´åºåˆ—çš„ä¿¡æ¯å¯†åº¦ï¼Œå¹¶æ ¹æ®ä¿¡æ¯å¯†åº¦é€‰æ‹©åˆé€‚çš„patchå¤§å°ã€‚å®ä¾‹è‡ªé€‚åº”positional embeddingçš„è®¾è®¡æ¶‰åŠå¦‚ä½•ä¸ºæ¯ä¸ªæ—¶é—´åºåˆ—å®ä¾‹ç”Ÿæˆå®šåˆ¶çš„positional encodingï¼Œä»¥æ•æ‰ä¸åŒçš„å‘¨æœŸæ€§å’Œè¶‹åŠ¿ã€‚PreSTSè¯­æ–™åº“çš„æ„å»ºé‡‡ç”¨äº†å¯é¢„æµ‹æ€§åˆ†å±‚ç­–ç•¥ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ã€‚å¤špatché¢„æµ‹ç­–ç•¥é€šè¿‡èåˆå¤šä¸ªpatchçš„é¢„æµ‹ç»“æœï¼Œæé«˜é¢„æµ‹ç²¾åº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Kairosåœ¨GIFT-Evalå’ŒTime-Series-Libraryä¸¤ä¸ªé›¶æ ·æœ¬åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨GIFT-Evalä¸Šï¼ŒKairosåœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶Šäº†ç°æœ‰çš„TSFMsã€‚åœ¨Time-Series-LibraryåŸºå‡†æµ‹è¯•ä¸­ï¼ŒKairosåœ¨å„ç§ä»»åŠ¡ä¸­å§‹ç»ˆä¼˜äºå·²å»ºç«‹çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä½¿ç”¨äº†æ›´å°‘çš„å‚æ•°ï¼Œè¯æ˜äº†å…¶é«˜æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Kairoså¯åº”ç”¨äºå„ç§æ—¶é—´åºåˆ—åˆ†æä»»åŠ¡ï¼Œå¦‚é¢„æµ‹ã€åˆ†ç±»ã€å¼‚å¸¸æ£€æµ‹ç­‰ã€‚å…¶è‡ªé€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ä½¿å…¶åœ¨é›¶æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹å…·æœ‰ä¼˜åŠ¿ï¼Œé€‚ç”¨äºç¼ºä¹æ ‡æ³¨æ•°æ®çš„é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨é‡‘èã€åŒ»ç–—ã€å·¥ä¸šç­‰é¢†åŸŸï¼ŒKairoså¯ä»¥ç”¨äºé¢„æµ‹è‚¡ç¥¨ä»·æ ¼ã€è¯Šæ–­ç–¾ç—…ã€é¢„æµ‹è®¾å¤‡æ•…éšœç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯å’Œå®é™…ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Time series foundation models (TSFMs) have emerged as a powerful paradigm for time series analysis, driven by large-scale pretraining on diverse data corpora. However, time series inherently exhibit heterogeneous information density over time, influenced by system states and signal complexity, presenting significant modeling challenges especially in a zero-shot scenario. Current TSFMs rely on non-adaptive processing pipelines that fail to capture this dynamic nature. For example, common tokenization strategies such as fixed-size patching enforce rigid observational granularity, limiting their ability to adapt to varying information densities. Similarly, conventional positional encodings impose a uniform temporal scale, making it difficult to model diverse periodicities and trends across series. To overcome these limitations, we propose Kairos, a flexible TSFM framework that integrates a dynamic patching tokenizer and an instance-adaptive positional embedding. Kairos adaptively selects tokenization granularity and tailors positional encodings to the unique characteristics of each time series instance. Trained on a large-scale Predictability-Stratified Time Series (PreSTS) corpus comprising over 300 billion time points and adopting a multi-patch prediction strategy in the inference stage, Kairos achieves superior performance with much fewer parameters on two common zero-shot benchmarks, GIFT-Eval and the Time-Series-Library benchmark, consistently outperforming established methods across diverse tasks. The project page is at https://foundation-model-research.github.io/Kairos .

