---
layout: default
title: Informed Asymmetric Actor-Critic: Leveraging Privileged Signals Beyond Full-State Access
---

# Informed Asymmetric Actor-Critic: Leveraging Privileged Signals Beyond Full-State Access

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26000" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.26000v1</a>
  <a href="https://arxiv.org/pdf/2509.26000.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26000v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26000v1', 'Informed Asymmetric Actor-Critic: Leveraging Privileged Signals Beyond Full-State Access')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Daniel Ebi, Gaspard Lambrechts, Damien Ernst, Klemens B√∂hm

**ÂàÜÁ±ª**: cs.LG, stat.ML

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

**Â§áÊ≥®**: 15 pages, 21 pages total

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Informed Asymmetric Actor-CriticÔºåÂà©Áî®ÁâπÊùÉ‰ø°Âè∑ÊèêÂçáÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏ãÁöÑÂº∫ÂåñÂ≠¶‰π†„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Âº∫ÂåñÂ≠¶‰π†` `ÈùûÂØπÁß∞Actor-Critic` `ÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É` `ÁâπÊùÉ‰ø°ÊÅØ` `Á≠ñÁï•Ê¢ØÂ∫¶`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÈùûÂØπÁß∞Actor-CriticÊñπÊ≥ï‰æùËµñ‰∫éËÆ≠ÁªÉÊó∂ÂØπÂÆåÊï¥Áä∂ÊÄÅÁöÑËÆøÈóÆÔºåÈôêÂà∂‰∫ÜÂÖ∂Âú®ÂÆûÈôÖÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏≠ÁöÑÂ∫îÁî®„ÄÇ
2. Informed Asymmetric Actor-CriticÂÖÅËÆ∏Critic‰ª•‰ªªÊÑèÁâπÊùÉ‰ø°Âè∑‰∏∫Êù°‰ª∂ÔºåÊó†ÈúÄËÆøÈóÆÂÆåÊï¥Áä∂ÊÄÅÔºåÊâ©Â±ï‰∫ÜÈùûÂØπÁß∞ÊñπÊ≥ïÁöÑÈÄÇÁî®ËåÉÂõ¥„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Âü∫ÂáÜÂØºËà™‰ªªÂä°ÂíåÂêàÊàêÁéØÂ¢É‰∏≠ÊèêÈ´ò‰∫ÜÂ≠¶‰π†ÊïàÁéáÂíå‰ª∑ÂÄº‰º∞ËÆ°ÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Âú®ÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏≠ÔºåÂº∫ÂåñÂ≠¶‰π†Êô∫ËÉΩ‰ΩìÈúÄË¶ÅÂú®Âô™Â£∞Âíå‰∏çÂÆåÊï¥ËßÇÊµãÁöÑ‰∏çÁ°ÆÂÆöÊÄß‰∏ãË°åÂä®„ÄÇÈùûÂØπÁß∞Actor-CriticÊñπÊ≥ïÂà©Áî®ËÆ≠ÁªÉÊó∂ÁöÑÁâπÊùÉ‰ø°ÊÅØÊù•ÊîπÂñÑËøôÁßçÊÉÖÂÜµ‰∏ãÁöÑÂ≠¶‰π†„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæËÆ≠ÁªÉÊó∂ÂèØ‰ª•ËÆøÈóÆÂÆåÊï¥Áä∂ÊÄÅ„ÄÇÊú¨ÊñáÊåëÊàò‰∫ÜËøô‰∏ÄÂÅáËÆæÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑActor-CriticÊ°ÜÊû∂ÔºåÁß∞‰∏∫Informed Asymmetric Actor-CriticÔºåÂÆÉÂÖÅËÆ∏Critic‰ª•‰ªªÊÑèÁâπÊùÉ‰ø°Âè∑‰∏∫Êù°‰ª∂ÔºåËÄåÊó†ÈúÄËÆøÈóÆÂÆåÊï¥Áä∂ÊÄÅ„ÄÇÊàë‰ª¨ËØÅÊòé‰∫ÜÂú®ËøôÁßçÂÖ¨Âºè‰∏ãÔºåÁ≠ñÁï•Ê¢ØÂ∫¶‰ªçÁÑ∂ÊòØÊó†ÂÅèÁöÑÔºå‰ªéËÄåÂ∞ÜÈùûÂØπÁß∞ÊñπÊ≥ïÁöÑÁêÜËÆ∫Âü∫Á°ÄÊâ©Â±ïÂà∞Êõ¥‰∏ÄËà¨ÁöÑÁâπÊùÉÈÉ®ÂàÜ‰ø°ÊÅØÁöÑÊÉÖÂÜµ„ÄÇ‰∏∫‰∫ÜÈáèÂåñËøô‰∫õ‰ø°Âè∑ÁöÑÂΩ±ÂìçÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÂü∫‰∫éÊ†∏ÊñπÊ≥ïÂíåÂõûÊä•È¢ÑÊµãËØØÂ∑ÆÁöÑ‰ø°ÊÅØÊÄßÂ∫¶ÈáèÔºå‰∏∫ËØÑ‰º∞ËÆ≠ÁªÉÊó∂‰ø°Âè∑Êèê‰æõ‰∫ÜÂÆûÁî®Â∑•ÂÖ∑„ÄÇÊàë‰ª¨Âú®Âü∫ÂáÜÂØºËà™‰ªªÂä°ÂíåÂêàÊàêÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏≠È™åËØÅ‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÔºåË°®ÊòéÂΩìÂ≠òÂú®‰ø°ÊÅØ‰∏∞ÂØåÁöÑÁâπÊùÉËæìÂÖ•Êó∂ÔºåÊàë‰ª¨ÁöÑInformed AsymmetricÊñπÊ≥ïÊèêÈ´ò‰∫ÜÂ≠¶‰π†ÊïàÁéáÂíå‰ª∑ÂÄº‰º∞ËÆ°„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞ÊåëÊàò‰∫ÜÂÆåÊï¥Áä∂ÊÄÅËÆøÈóÆÁöÑÂøÖË¶ÅÊÄßÔºåÂπ∂‰∏∫ËÆæËÆ°Êó¢ÂÆûÁî®ÂèàÁêÜËÆ∫‰∏äÂêàÁêÜÁöÑÈùûÂØπÁß∞Âº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂºÄËæü‰∫ÜÊñ∞ÁöÑÊñπÂêë„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÈùûÂØπÁß∞Actor-CriticÊñπÊ≥ïÈÄöÂ∏∏ÂÅáËÆæÂú®ËÆ≠ÁªÉÈò∂ÊÆµÂèØ‰ª•ËÆøÈóÆÂÆåÊï¥ÁöÑÁä∂ÊÄÅ‰ø°ÊÅØÔºåËøôÂú®ËÆ∏Â§öÂÆûÈôÖÂ∫îÁî®‰∏≠ÊòØ‰∏çÁé∞ÂÆûÁöÑÔºåÂõ†‰∏∫Êô∫ËÉΩ‰ΩìÂè™ËÉΩËé∑ÂæóÈÉ®ÂàÜËßÇÊµã„ÄÇÂõ†Ê≠§ÔºåÂ¶Ç‰ΩïÂà©Áî®ÈÉ®ÂàÜÁâπÊùÉ‰ø°ÊÅØÊù•ÊèêÂçáÂº∫ÂåñÂ≠¶‰π†ÁöÑÊÄßËÉΩÔºåÂêåÊó∂ÈÅøÂÖçÂØπÂÆåÊï¥Áä∂ÊÄÅÁöÑ‰æùËµñÔºåÊòØ‰∏Ä‰∏™‰∫üÂæÖËß£ÂÜ≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÊó†Ê≥ïÊúâÊïàÂà©Áî®Ëøô‰∫õÈÉ®ÂàÜÁâπÊùÉ‰ø°ÊÅØÔºåÂØºËá¥Â≠¶‰π†ÊïàÁéá‰Ωé‰∏ãÊàñÊÄßËÉΩÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂÖÅËÆ∏CriticÁΩëÁªú‰ª•‰ªªÊÑèÁöÑÁâπÊùÉ‰ø°Âè∑‰Ωú‰∏∫ËæìÂÖ•ÔºåËÄåÊó†ÈúÄËÆøÈóÆÂÆåÊï¥ÁöÑÁä∂ÊÄÅ‰ø°ÊÅØ„ÄÇÈÄöËøáËøôÁßçÊñπÂºèÔºåCriticÂèØ‰ª•Âà©Áî®Ëøô‰∫õÁâπÊùÉ‰ø°Âè∑Êù•Êõ¥ÂáÜÁ°ÆÂú∞ËØÑ‰º∞Áä∂ÊÄÅ‰ª∑ÂÄºÔºå‰ªéËÄåÊåáÂØºActorÁΩëÁªúÁöÑÁ≠ñÁï•Â≠¶‰π†„ÄÇÂÖ≥ÈîÆÂú®‰∫éËØÅÊòéÂç≥‰ΩøCriticÂè™‰æùËµñ‰∫éÈÉ®ÂàÜÁâπÊùÉ‰ø°ÊÅØÔºåÁ≠ñÁï•Ê¢ØÂ∫¶‰ªçÁÑ∂ÊòØÊó†ÂÅèÁöÑÔºå‰ªéËÄå‰øùËØÅÂ≠¶‰π†ÁöÑÊî∂ÊïõÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöInformed Asymmetric Actor-CriticÊ°ÜÊû∂ÂåÖÂê´‰∏Ä‰∏™ActorÁΩëÁªúÂíå‰∏Ä‰∏™CriticÁΩëÁªú„ÄÇActorÁΩëÁªúÂü∫‰∫éÊô∫ËÉΩ‰ΩìÁöÑËßÇÊµãÊù•ÈÄâÊã©Âä®‰ΩúÔºåCriticÁΩëÁªúÂàôÂü∫‰∫éËßÇÊµãÂíåÁâπÊùÉ‰ø°Âè∑Êù•ËØÑ‰º∞Áä∂ÊÄÅ‰ª∑ÂÄº„ÄÇÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåCriticÁΩëÁªúÂà©Áî®ÁâπÊùÉ‰ø°Âè∑Êù•Â≠¶‰π†Êõ¥ÂáÜÁ°ÆÁöÑ‰ª∑ÂÄºÂáΩÊï∞ÔºåÁÑ∂ÂêéÂ∞ÜËøô‰∫õ‰ø°ÊÅØ‰º†ÈÄíÁªôActorÁΩëÁªúÔºå‰ªéËÄåÊîπÂñÑÁ≠ñÁï•Â≠¶‰π†„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰ø°ÊÅØÊÄßÂ∫¶ÈáèÔºåÁî®‰∫éËØÑ‰º∞‰∏çÂêåÁâπÊùÉ‰ø°Âè∑ÁöÑ‰ª∑ÂÄºÔºå‰ªéËÄåÊåáÂØº‰ø°Âè∑ÁöÑÈÄâÊã©„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊâ©Â±ï‰∫ÜÈùûÂØπÁß∞Actor-CriticÊñπÊ≥ïÁöÑÁêÜËÆ∫Âü∫Á°ÄÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ§ÑÁêÜÊõ¥‰∏ÄËà¨ÁöÑÁâπÊùÉÈÉ®ÂàÜ‰ø°ÊÅØ„ÄÇ‰º†ÁªüÊñπÊ≥ïË¶ÅÊ±ÇCriticËÆøÈóÆÂÆåÊï¥Áä∂ÊÄÅÔºåËÄåÊú¨ÊñáÊèêÂá∫ÁöÑÊñπÊ≥ïÂÖÅËÆ∏Critic‰ª•‰ªªÊÑèÁâπÊùÉ‰ø°Âè∑‰∏∫Êù°‰ª∂Ôºå‰ªéËÄåÊâìÁ†¥‰∫ÜËøô‰∏ÄÈôêÂà∂„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫Ü‰ø°ÊÅØÊÄßÂ∫¶ÈáèÔºåÁî®‰∫éËØÑ‰º∞ÁâπÊùÉ‰ø°Âè∑ÁöÑ‰ª∑ÂÄºÔºå‰∏∫‰ø°Âè∑ÈÄâÊã©Êèê‰æõ‰∫ÜÊåáÂØº„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Á≠ñÁï•Ê¢ØÂ∫¶ÂÖ¨ÂºèÁöÑÊé®ÂØºÔºåËØÅÊòé‰∫ÜÂú®ÈÉ®ÂàÜÁâπÊùÉ‰ø°ÊÅØ‰∏ãÁ≠ñÁï•Ê¢ØÂ∫¶‰ªçÁÑ∂ÊòØÊó†ÂÅèÁöÑÔºõ2) Âü∫‰∫éÊ†∏ÊñπÊ≥ïÂíåÂõûÊä•È¢ÑÊµãËØØÂ∑ÆÁöÑ‰ø°ÊÅØÊÄßÂ∫¶ÈáèÔºåÁî®‰∫éËØÑ‰º∞ÁâπÊùÉ‰ø°Âè∑ÁöÑ‰ª∑ÂÄºÔºõ3) ActorÂíåCriticÁΩëÁªúÁöÑÂÖ∑‰ΩìÁªìÊûÑÔºåÂèØ‰ª•Ê†πÊçÆÂÖ∑‰Ωì‰ªªÂä°ËøõË°åË∞ÉÊï¥Ôºõ4) ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°ÔºåÁî®‰∫éËÆ≠ÁªÉActorÂíåCriticÁΩëÁªú„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåInformed Asymmetric Actor-CriticÊñπÊ≥ïÂú®Âü∫ÂáÜÂØºËà™‰ªªÂä°ÂíåÂêàÊàêÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏≠ÔºåÊòæËëóÊèêÈ´ò‰∫ÜÂ≠¶‰π†ÊïàÁéáÂíå‰ª∑ÂÄº‰º∞ËÆ°ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ‰æãÂ¶ÇÔºåÂú®Êüê‰∫õ‰ªªÂä°‰∏≠ÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊØî‰º†ÁªüÊñπÊ≥ïÊõ¥Âø´Âú∞ËææÂà∞Áõ∏ÂêåÁöÑÊÄßËÉΩÊ∞¥Âπ≥ÔºåÂπ∂‰∏îËÉΩÂ§üÂ≠¶‰π†Âà∞Êõ¥ÂáÜÁ°ÆÁöÑ‰ª∑ÂÄºÂáΩÊï∞„ÄÇÊ≠§Â§ñÔºå‰ø°ÊÅØÊÄßÂ∫¶ÈáèËÉΩÂ§üÊúâÊïàÂú∞ËØÑ‰º∞‰∏çÂêåÁâπÊùÉ‰ø°Âè∑ÁöÑ‰ª∑ÂÄºÔºå‰ªéËÄåÊåáÂØº‰ø°Âè∑ÁöÑÈÄâÊã©„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçÈÉ®ÂàÜÂèØËßÇÊµãÁéØÂ¢É‰∏ãÁöÑÂº∫ÂåñÂ≠¶‰π†‰ªªÂä°Ôºå‰æãÂ¶ÇÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèAIÁ≠â„ÄÇÂú®Ëøô‰∫õÂú∫ÊôØ‰∏≠ÔºåÊô∫ËÉΩ‰ΩìÈÄöÂ∏∏Âè™ËÉΩËé∑ÂæóÈÉ®ÂàÜËßÇÊµã‰ø°ÊÅØÔºå‰ΩÜÂèØËÉΩÂ≠òÂú®‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÁâπÊùÉ‰ø°Âè∑Ôºå‰æãÂ¶ÇÂú∞Âõæ‰ø°ÊÅØ„ÄÅ‰º†ÊÑüÂô®Êï∞ÊçÆÁ≠â„ÄÇÈÄöËøáÂà©Áî®Ëøô‰∫õÁâπÊùÉ‰ø°Âè∑ÔºåÂèØ‰ª•ÊòæËëóÊèêÈ´òÊô∫ËÉΩ‰ΩìÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊÄßËÉΩÔºå‰ΩøÂÖ∂ËÉΩÂ§üÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢É„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Reinforcement learning in partially observable environments requires agents to act under uncertainty from noisy, incomplete observations. Asymmetric actor-critic methods leverage privileged information during training to improve learning under these conditions. However, existing approaches typically assume full-state access during training. In this work, we challenge this assumption by proposing a novel actor-critic framework, called informed asymmetric actor-critic, that enables conditioning the critic on arbitrary privileged signals without requiring access to the full state. We show that policy gradients remain unbiased under this formulation, extending the theoretical foundation of asymmetric methods to the more general case of privileged partial information. To quantify the impact of such signals, we propose informativeness measures based on kernel methods and return prediction error, providing practical tools for evaluating training-time signals. We validate our approach empirically on benchmark navigation tasks and synthetic partially observable environments, showing that our informed asymmetric method improves learning efficiency and value estimation when informative privileged inputs are available. Our findings challenge the necessity of full-state access and open new directions for designing asymmetric reinforcement learning methods that are both practical and theoretically sound.

