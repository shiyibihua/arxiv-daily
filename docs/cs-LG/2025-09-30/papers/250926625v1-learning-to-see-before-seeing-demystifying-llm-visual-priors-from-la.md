---
layout: default
title: Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training
---

# Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.26625" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.26625v1</a>
  <a href="https://arxiv.org/pdf/2509.26625.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.26625v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.26625v1', 'Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Junlin Han, Shengbang Tong, David Fan, Yufan Ren, Koustuv Sinha, Philip Torr, Filippos Kokkinos

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CV, cs.MM

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

**Â§áÊ≥®**: Project page: https://junlinhan.github.io/projects/lsbs/

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Êè≠Á§∫LLMËßÜËßâÂÖàÈ™åÔºöÈÄöËøáËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉÂ≠¶‰π†ËßÜËßâÊÑüÁü•‰∏éÊé®ÁêÜËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `ËßÜËßâÂÖàÈ™å` `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `È¢ÑËÆ≠ÁªÉ` `ËßÜËßâÊé®ÁêÜ` `ËßÜËßâÊÑüÁü•` `Êï∞ÊçÆÈ©±Âä®` `MLLM`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂà©Áî®LLMÂú®ËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉ‰∏≠Ëé∑ÂæóÁöÑËßÜËßâÂÖàÈ™åÁü•ËØÜÔºåÈôêÂà∂‰∫ÜÂ§öÊ®°ÊÄÅLLMÁöÑÊÄßËÉΩ„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫‰∏ÄÁßçÊï∞ÊçÆÈ©±Âä®ÁöÑÊñπÊ≥ïÔºåÈÄöËøáÊéßÂà∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁ±ªÂûãÔºåÊúâÊÑèËØÜÂú∞ÂüπÂÖªLLMÁöÑËßÜËßâÊÑüÁü•ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÊèêÂçáLLMÁöÑËßÜËßâËÉΩÂäõÔºåÂπ∂Âú®Â§ßËßÑÊ®°È¢ÑËÆ≠ÁªÉ‰∏≠ÂæóÂà∞È™åËØÅÔºå‰∏∫Â§öÊ®°ÊÄÅLLMÂèëÂ±ïÊèê‰æõÊñ∞ÊÄùË∑Ø„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâ‰ªÖÈÄöËøáÊñáÊú¨ËÆ≠ÁªÉÔºåÂç¥Âá∫‰∫∫ÊÑèÊñôÂú∞ÂèëÂ±ïÂá∫‰∏∞ÂØåÁöÑËßÜËßâÂÖàÈ™åÁü•ËØÜ„ÄÇËøô‰∫õÂÖàÈ™åÁü•ËØÜ‰ΩøÂæóÊΩúÂú®ÁöÑËßÜËßâËÉΩÂäõËÉΩÂ§üÈÄöËøáÁõ∏ÂØπÂ∞ëÈáèÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆË¢´Ëß£ÈîÅÔºåÁî®‰∫éËßÜËßâ‰ªªÂä°ÔºåÂú®Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÁîöËá≥ÂèØ‰ª•Âú®Ê≤°ÊúâËßÅËøáÂõæÂÉèÁöÑÊÉÖÂÜµ‰∏ãÊâßË°åËßÜËßâ‰ªªÂä°„ÄÇÈÄöËøáÁ≥ªÁªüÂàÜÊûêÔºåÊàë‰ª¨Êè≠Á§∫‰∫ÜËßÜËßâÂÖàÈ™å‚Äî‚ÄîÂú®ËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉÊúüÈó¥Ëé∑ÂæóÁöÑÂÖ≥‰∫éËßÜËßâ‰∏ñÁïåÁöÑÈöêÂºè„ÄÅÊ∂åÁé∞ÁöÑÁü•ËØÜ‚Äî‚ÄîÁî±ÂèØÂàÜÁ¶ªÁöÑÊÑüÁü•ÂíåÊé®ÁêÜÂÖàÈ™åÁªÑÊàêÔºåÂÆÉ‰ª¨ÂÖ∑ÊúâÁã¨ÁâπÁöÑÁº©ÊîæË∂ãÂäøÂíåËµ∑Ê∫ê„ÄÇÊàë‰ª¨Ë°®ÊòéÔºåLLMÁöÑÊΩúÂú®ËßÜËßâÊé®ÁêÜËÉΩÂäõ‰∏ªË¶ÅÈÄöËøá‰ª•Êé®ÁêÜ‰∏∫‰∏≠ÂøÉÁöÑÊï∞ÊçÆÔºà‰æãÂ¶ÇÔºå‰ª£Á†Å„ÄÅÊï∞Â≠¶„ÄÅÂ≠¶ÊúØÔºâÁöÑÈ¢ÑËÆ≠ÁªÉÊù•ÂèëÂ±ïÔºåÂπ∂ÈÄêÊ≠•Êâ©Â±ï„ÄÇËøôÁßç‰ªéËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉ‰∏≠Ëé∑ÂæóÁöÑÊé®ÁêÜÂÖàÈ™åÊòØÂèØËΩ¨ÁßªÁöÑÔºåÂπ∂‰∏îÊôÆÈÅçÈÄÇÁî®‰∫éËßÜËßâÊé®ÁêÜ„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÊÑüÁü•ÂÖàÈ™åÊõ¥ÂàÜÊï£Âú∞‰ªéÂπøÊ≥õÁöÑËØ≠ÊñôÂ∫ì‰∏≠Ê∂åÁé∞Âá∫Êù•ÔºåÂπ∂‰∏îÊÑüÁü•ËÉΩÂäõÂØπËßÜËßâÁºñÁ†ÅÂô®ÂíåËßÜËßâÊåá‰ª§Ë∞ÉÊï¥Êï∞ÊçÆÊõ¥ÊïèÊÑü„ÄÇÂêåÊó∂ÔºåÊèèËø∞ËßÜËßâ‰∏ñÁïåÁöÑÊñáÊú¨Ë¢´ËØÅÊòéËá≥ÂÖ≥ÈáçË¶ÅÔºåÂ∞ΩÁÆ°ÂÖ∂ÊÄßËÉΩÂΩ±ÂìçËøÖÈÄüÈ•±Âíå„ÄÇÂà©Áî®Ëøô‰∫õËßÅËß£ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßç‰ª•Êï∞ÊçÆ‰∏∫‰∏≠ÂøÉÁöÑÈ¢ÑËÆ≠ÁªÉËßÜËßâÊÑüÁü•LLMÁöÑÊñπÊ°àÔºåÂπ∂Âú®1T tokenËßÑÊ®°ÁöÑÈ¢ÑËÆ≠ÁªÉ‰∏≠È™åËØÅ‰∫ÜÂÆÉ„ÄÇÊàë‰ª¨ÁöÑÂèëÁé∞Âü∫‰∫éË∂ÖËøá100‰∏™ÂèóÊéßÂÆûÈ™åÔºåÊ∂àËÄó‰∫Ü500,000 GPU-hoursÔºåÊ∂µÁõñ‰∫ÜÂÆåÊï¥ÁöÑMLLMÊûÑÂª∫ÊµÅÁ®ã‚Äî‚Äî‰ªéLLMÈ¢ÑËÆ≠ÁªÉÂà∞ËßÜËßâÂØπÈΩêÂíåÁõëÁù£Â§öÊ®°ÊÄÅÂæÆË∞É‚Äî‚ÄîË∑®Ë∂ä‰∫î‰∏™Ê®°ÂûãËßÑÊ®°ÔºåÂêÑÁßçÊï∞ÊçÆÁ±ªÂà´ÂíåÊ∑∑ÂêàÔºå‰ª•ÂèäÂ§öÁßçÈÄÇÂ∫îËÆæÁΩÆ„ÄÇÈô§‰∫ÜÊàë‰ª¨ÁöÑ‰∏ªË¶ÅÂèëÁé∞ÔºåÊàë‰ª¨ÊèêÂá∫Âπ∂Á†îÁ©∂‰∫ÜÂá†‰∏™ÂÅáËÆæÔºåÂπ∂ÂºïÂÖ•‰∫ÜÂ§öÂ±ÇÊ¨°Â≠òÂú®Âü∫ÂáÜÔºàMLE-BenchÔºâ„ÄÇÊÄª‰πãÔºåËøôÈ°πÂ∑•‰ΩúÊèê‰æõ‰∫Ü‰∏ÄÁßçÊúâÊÑèËØÜÂú∞‰ªéËØ≠Ë®ÄÈ¢ÑËÆ≠ÁªÉ‰∏≠ÂüπÂÖªËßÜËßâÂÖàÈ™åÁöÑÊñ∞ÊñπÊ≥ïÔºå‰∏∫‰∏ã‰∏Ä‰ª£Â§öÊ®°ÊÄÅLLMÈì∫Âπ≥‰∫ÜÈÅìË∑Ø„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â¶Ç‰ΩïÊúâÊïàÂà©Áî®Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÂú®Á∫ØÊñáÊú¨È¢ÑËÆ≠ÁªÉËøáÁ®ã‰∏≠Ëé∑ÂæóÁöÑËßÜËßâÂÖàÈ™åÁü•ËØÜÔºå‰ªéËÄåÊèêÂçáÂ§öÊ®°ÊÄÅLLMÁöÑÊÄßËÉΩ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñ‰∫éÂ§ßÈáèÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆËøõË°åÂæÆË∞ÉÔºå‰ΩÜÂøΩÁï•‰∫ÜLLMÊú¨Ë∫´Â∑≤ÁªèÂÖ∑Â§áÁöÑÊΩúÂú®ËßÜËßâËÉΩÂäõ„ÄÇÂ¶Ç‰ΩïËß£ËÄ¶ÂíåÂà©Áî®Ëøô‰∫õËßÜËßâÂÖàÈ™åÔºåÊòØÂΩìÂâçÁ†îÁ©∂ÁöÑÁóõÁÇπ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜLLMÁöÑËßÜËßâÂÖàÈ™åÂàÜËß£‰∏∫ÊÑüÁü•ÂÖàÈ™åÂíåÊé®ÁêÜÂÖàÈ™åÔºåÂπ∂Á†îÁ©∂ÂÆÉ‰ª¨ÂêÑËá™ÁöÑÊù•Ê∫êÂíåÁº©ÊîæËßÑÂæã„ÄÇÈÄöËøáÊéßÂà∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁ±ªÂûãÂíåËßÑÊ®°ÔºåÊúâÈíàÂØπÊÄßÂú∞ÂüπÂÖªLLMÁöÑËßÜËßâÊÑüÁü•ÂíåÊé®ÁêÜËÉΩÂäõ„ÄÇËøôÁßçÊï∞ÊçÆÈ©±Âä®ÁöÑÊñπÊ≥ïÊó®Âú®ÊúÄÂ§ßÈôêÂ∫¶Âú∞Âà©Áî®LLMÁöÑÂÜÖÂú®ËßÜËßâÁü•ËØÜÔºåÂáèÂ∞ëÂØπÂ§ßËßÑÊ®°Â§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËÆ∫ÊñáÁöÑÁ†îÁ©∂Ê°ÜÊû∂‰∏ªË¶ÅÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™Èò∂ÊÆµÔºö1) LLMÈ¢ÑËÆ≠ÁªÉÔºöÂú®‰∏çÂêåÁ±ªÂûãÂíåËßÑÊ®°ÁöÑÊñáÊú¨Êï∞ÊçÆ‰∏äÈ¢ÑËÆ≠ÁªÉLLMÔºõ2) ËßÜËßâÂØπÈΩêÔºöÂ∞ÜLLM‰∏éËßÜËßâÁºñÁ†ÅÂô®ÂØπÈΩêÔºå‰ΩøÂÖ∂ËÉΩÂ§üÂ§ÑÁêÜÂõæÂÉèËæìÂÖ•Ôºõ3) Â§öÊ®°ÊÄÅÂæÆË∞ÉÔºö‰ΩøÁî®Â∞ëÈáèÂ§öÊ®°ÊÄÅÊï∞ÊçÆÂØπÈΩêÂêéÁöÑLLMËøõË°åÂæÆË∞ÉÔºå‰ª•ÈÄÇÂ∫îÁâπÂÆöÁöÑËßÜËßâ‰ªªÂä°Ôºõ4) ËØÑ‰º∞Ôºö‰ΩøÁî®Â§öÁßçËßÜËßâ‰ªªÂä°ÂíåÂü∫ÂáÜÊµãËØïËØÑ‰º∞LLMÁöÑËßÜËßâËÉΩÂäõ„ÄÇËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜMulti-Level Existence Bench (MLE-Bench)Áî®‰∫éÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑËØÑ‰º∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊè≠Á§∫‰∫ÜLLMËßÜËßâÂÖàÈ™åÁöÑÁªÑÊàêÂíåÊù•Ê∫êÔºåÂπ∂ÊèêÂá∫‰∫ÜÊúâÈíàÂØπÊÄßÁöÑÊï∞ÊçÆÈ©±Âä®ÁöÑÈ¢ÑËÆ≠ÁªÉÊñπÊ≥ï„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊõ¥Âä†Ê≥®ÈáçÂà©Áî®LLMÊú¨Ë∫´Â∑≤ÁªèÂÖ∑Â§áÁöÑËßÜËßâÁü•ËØÜÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖ‰æùËµñ‰∫éÂ§ßËßÑÊ®°ÁöÑÂ§öÊ®°ÊÄÅÊï∞ÊçÆ„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÊèêÂá∫‰∫ÜMLE-BenchÔºå‰∏∫Êõ¥Ê∑±ÂÖ•Âú∞ËØÑ‰º∞LLMÁöÑËßÜËßâËÉΩÂäõÊèê‰æõ‰∫ÜÊñ∞ÁöÑÂ∑•ÂÖ∑„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ÊéßÂà∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁöÑÁ±ªÂûãÂíåÊØî‰æãÔºå‰æãÂ¶ÇÂ¢ûÂä†‰ª£Á†Å„ÄÅÊï∞Â≠¶ÂíåÂ≠¶ÊúØÊï∞ÊçÆÁöÑÊØî‰æãÔºå‰ª•ÊèêÂçáÊé®ÁêÜËÉΩÂäõÔºõ2) ËÆæËÆ°ÂêàÈÄÇÁöÑËßÜËßâÁºñÁ†ÅÂô®ÂíåÂØπÈΩêÊñπÊ≥ïÔºå‰ª•Á°Æ‰øùLLMËÉΩÂ§üÊúâÊïàÂú∞Â§ÑÁêÜÂõæÂÉèËæìÂÖ•Ôºõ3) ‰ΩøÁî®Â§öÁßçËßÜËßâ‰ªªÂä°ÂíåÂü∫ÂáÜÊµãËØïËøõË°åËØÑ‰º∞Ôºå‰ª•ÂÖ®Èù¢‰∫ÜËß£LLMÁöÑËßÜËßâËÉΩÂäõÔºõ4) Êé¢Á¥¢‰∏çÂêåÁöÑÊ®°ÂûãËßÑÊ®°ÂíåËÆ≠ÁªÉÁ≠ñÁï•Ôºå‰ª•Á†îÁ©∂ËßÜËßâÂÖàÈ™åÁöÑÁº©ÊîæËßÑÂæã„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÈÄöËøáÊéßÂà∂È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÁ±ªÂûãÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáLLMÁöÑËßÜËßâÊé®ÁêÜËÉΩÂäõ„ÄÇ‰æãÂ¶ÇÔºåÂ¢ûÂä†Êé®ÁêÜÁõ∏ÂÖ≥Êï∞ÊçÆÁöÑÊØî‰æãÂèØ‰ª•‰ΩøLLMÂú®ËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæóÊòæËëóÊèêÂçá„ÄÇÊ≠§Â§ñÔºåËÆ∫ÊñáËøòÂèëÁé∞ÊÑüÁü•ËÉΩÂäõÂØπËßÜËßâÁºñÁ†ÅÂô®ÂíåËßÜËßâÊåá‰ª§Ë∞ÉÊï¥Êï∞ÊçÆÊõ¥ÊïèÊÑü„ÄÇËØ•Á†îÁ©∂Âú®‰∫î‰∏™Ê®°ÂûãËßÑÊ®°ÂíåÂ§öÁßçÊï∞ÊçÆÊ∑∑Âêà‰∏äËøõË°å‰∫ÜÈ™åËØÅÔºåÊ∂àËÄó‰∫Ü500,000 GPU-hours„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂºÄÂèëÊõ¥È´òÊïà„ÄÅÊõ¥Âº∫Â§ßÁöÑÂ§öÊ®°ÊÄÅLLMÔºåÂáèÂ∞ëÂØπÂ§ßËßÑÊ®°Â§öÊ®°ÊÄÅÊï∞ÊçÆÁöÑ‰æùËµñ„ÄÇÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êô∫ËÉΩÂä©Êâã„ÄÅÂõæÂÉèÁêÜËß£„ÄÅËßÜËßâÊé®ÁêÜ„ÄÅÊú∫Âô®‰∫∫ÂØºËà™Á≠â„ÄÇÈÄöËøáÊõ¥Â•ΩÂú∞Âà©Áî®LLMÁöÑÂÜÖÂú®ËßÜËßâÁü•ËØÜÔºåÂèØ‰ª•Èôç‰ΩéÊ®°ÂûãËÆ≠ÁªÉÊàêÊú¨ÔºåÊèêÂçáÊ®°ÂûãÊ≥õÂåñËÉΩÂäõÔºåÂπ∂Êé®Âä®Â§öÊ®°ÊÄÅ‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs), despite being trained on text alone, surprisingly develop rich visual priors. These priors allow latent visual capabilities to be unlocked for vision tasks with a relatively small amount of multimodal data, and in some cases, to perform visual tasks without ever having seen an image. Through systematic analysis, we reveal that visual priors-the implicit, emergent knowledge about the visual world acquired during language pre-training-are composed of separable perception and reasoning priors with unique scaling trends and origins. We show that an LLM's latent visual reasoning ability is predominantly developed by pre-training on reasoning-centric data (e.g., code, math, academia) and scales progressively. This reasoning prior acquired from language pre-training is transferable and universally applicable to visual reasoning. In contrast, a perception prior emerges more diffusely from broad corpora, and perception ability is more sensitive to the vision encoder and visual instruction tuning data. In parallel, text describing the visual world proves crucial, though its performance impact saturates rapidly. Leveraging these insights, we propose a data-centric recipe for pre-training vision-aware LLMs and verify it in 1T token scale pre-training. Our findings are grounded in over 100 controlled experiments consuming 500,000 GPU-hours, spanning the full MLLM construction pipeline-from LLM pre-training to visual alignment and supervised multimodal fine-tuning-across five model scales, a wide range of data categories and mixtures, and multiple adaptation setups. Along with our main findings, we propose and investigate several hypotheses, and introduce the Multi-Level Existence Bench (MLE-Bench). Together, this work provides a new way of deliberately cultivating visual priors from language pre-training, paving the way for the next generation of multimodal LLMs.

