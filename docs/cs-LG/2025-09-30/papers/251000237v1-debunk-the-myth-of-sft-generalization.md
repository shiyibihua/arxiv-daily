---
layout: default
title: Debunk the Myth of SFT Generalization
---

# Debunk the Myth of SFT Generalization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.00237" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.00237v1</a>
  <a href="https://arxiv.org/pdf/2510.00237.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.00237v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2510.00237v1', 'Debunk the Myth of SFT Generalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiaofeng Lin, Hejian Sang, Zhipeng Wang, Xuezhou Zhang

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-30

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/XiaofengLin7/debunking-sft-generalization)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**é€šè¿‡æç¤ºå¤šæ ·æ€§å’Œæ€ç»´é“¾ï¼Œæå‡SFTåœ¨å†³ç­–ä»»åŠ¡ä¸­çš„æ³›åŒ–èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç›‘ç£å¼å¾®è°ƒ` `æ³›åŒ–èƒ½åŠ›` `æç¤ºå·¥ç¨‹` `æ€ç»´é“¾` `å†³ç­–ä»»åŠ¡` `å¼ºåŒ–å­¦ä¹ ` `æ•°æ®ä¸ºä¸­å¿ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§‚ç‚¹è®¤ä¸ºSFTæ³›åŒ–èƒ½åŠ›å¼±äºRLï¼Œä½†è¯¥ç ”ç©¶å‘ç°SFTçš„æ³›åŒ–å¤±è´¥æºäºå†»ç»“æç¤ºä¼ªå½±ã€‚
2. é€šè¿‡å¼•å…¥æç¤ºå¤šæ ·æ€§ï¼ŒSFTæ¨¡å‹å¯ä»¥æ‰“ç ´å¯¹è®­ç»ƒè¯­ä¹‰çš„ä¾èµ–ï¼Œä»è€Œæå‡å¯¹æœªè§æŒ‡ä»¤çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. ç»“åˆæç¤ºå¤šæ ·æ€§å’Œæ€ç»´é“¾ï¼ŒSFTåœ¨éš¾åº¦å˜ä½“ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œæ€§èƒ½å¯ä¸RLåŸºçº¿ç›¸åª²ç¾ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç›®å‰æ™®éè®¤ä¸ºï¼Œç›‘ç£å¼å¾®è°ƒï¼ˆSFTï¼‰ä¼šè®°å¿†è®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œè€Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åˆ™å…·æœ‰æ›´å¹¿æ³›çš„é²æ£’æ€§ã€‚æœ¬æ–‡é€šè¿‡åœ¨Sokobanå’ŒGeneral Pointsä¸¤ä¸ªå†³ç­–åŸºå‡†ä¸Šè¿›è¡Œç³»ç»Ÿè¯„ä¼°ï¼Œå¯¹è¿™ä¸€è§‚ç‚¹è¿›è¡Œäº†é‡æ–°å®¡è§†ï¼Œå¹¶å¾—å‡ºäº†ä¸åŒçš„ç»“è®ºã€‚ç ”ç©¶è¡¨æ˜ï¼ŒSFTçš„æ³›åŒ–å¤±è´¥å¾ˆå¤§ç¨‹åº¦ä¸Šæºäºå†»ç»“æç¤ºä¼ªå½±ï¼šå½“åœ¨å›ºå®šçš„æŒ‡ä»¤æ¨¡æ¿ä¸Šè®­ç»ƒæ—¶ï¼ŒSFTæ¨¡å‹å€¾å‘äºåšæŒè®­ç»ƒè¯­ä¹‰ï¼Œè€Œä¸æ˜¯é€‚åº”æ–°çš„è¯­ä¹‰ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥æç¤ºå¤šæ ·æ€§å¯ä»¥æ‰“ç ´è¿™ç§æ·å¾„ï¼Œä»è€Œåœ¨ä¸æŸå®³åˆ†å¸ƒå†…æ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå®ç°å¯¹æœªè§æŒ‡ä»¤å˜ä½“çš„å¼ºå¤§æ³›åŒ–ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜æ¢è®¨äº†SFTæ˜¯å¦å¯ä»¥æ³›åŒ–åˆ°æ›´å›°éš¾çš„ä»»åŠ¡ã€‚æ€ç»´é“¾ï¼ˆCoTï¼‰ç›‘ç£æä¾›äº†ä¸€ç§ç®—æ³•æ”¯æ¶ï¼Œæ˜¾è‘—æé«˜äº†å¯¹æ›´å›°éš¾åœºæ™¯çš„è¿ç§»èƒ½åŠ›ï¼Œä¾‹å¦‚å…·æœ‰æ›´å¤šç®±å­çš„å¤§å‹Sokobanç½‘æ ¼ï¼Œä»¥åŠå…·æœ‰åˆ†å¸ƒå¤–å€¼æˆ–å¢åŠ ç»„åˆå¤æ‚æ€§çš„äº”å¼ ç‰Œç»„åˆçš„ç®—æœ¯ã€‚æœ€åï¼Œå°†æç¤ºå¤šæ ·æ€§ä¸CoTç›¸ç»“åˆï¼Œå¯ä»¥å®ç°ä¸¤å…¨å…¶ç¾ï¼šåœ¨æŒ‡ä»¤å˜ä½“å’Œéš¾åº¦å˜ä½“è®¾ç½®ä¸­å®ç°å¼ºå¤§çš„æ³›åŒ–ï¼Œåœ¨æˆ‘ä»¬çš„åŸºå‡†æµ‹è¯•ä¸­åŒ¹é…æˆ–è¶…è¿‡RLåŸºçº¿ï¼ŒåŒæ—¶ä¿æŒSFTçš„ç®€å•æ€§å’Œç¨³å®šæ€§ã€‚è¿™äº›å‘ç°æŒ‘æˆ˜äº†SFTæœ¬è´¨ä¸Šä¸å¦‚RLçš„è¯´æ³•ï¼Œå¹¶æ”¯æŒä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è§†è§’ï¼šé€šè¿‡é€‚å½“ç­–åˆ’çš„æ¼”ç¤ºï¼Œæ™®é€šçš„SFTå¯ä»¥åƒRLä¸€æ ·å¼ºå¤§åœ°æ³›åŒ–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰ç ”ç©¶è®¤ä¸ºç›‘ç£å¾®è°ƒ(SFT)åœ¨å†³ç­–ä»»åŠ¡ä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œè€Œå¼ºåŒ–å­¦ä¹ (RL)åˆ™è¢«è®¤ä¸ºå…·æœ‰æ›´å¥½çš„æ³›åŒ–æ€§èƒ½ã€‚ç„¶è€Œï¼Œè¿™ç§è§‚ç‚¹å¯èƒ½å¿½ç•¥äº†SFTè®­ç»ƒè¿‡ç¨‹ä¸­çš„ä¸€äº›å…³é”®å› ç´ ï¼Œä¾‹å¦‚æç¤ºå·¥ç¨‹å’Œä»»åŠ¡éš¾åº¦ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ”¹è¿›SFTçš„è®­ç»ƒæ–¹å¼ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–åˆ°æœªè§è¿‡çš„æŒ‡ä»¤å˜ä½“å’Œæ›´å›°éš¾çš„ä»»åŠ¡ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡å¼•å…¥æç¤ºå¤šæ ·æ€§æ¥æ‰“ç ´SFTå¯¹è®­ç»ƒè¯­ä¹‰çš„ä¾èµ–ï¼Œå¹¶åˆ©ç”¨æ€ç»´é“¾(CoT)ç›‘ç£æ¥æå‡SFTåœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ¨ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥ç ”ç©¶çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼šé¦–å…ˆï¼Œä½¿ç”¨SFTæ¨¡å‹åœ¨å†³ç­–ä»»åŠ¡ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚Sokobanå’ŒGeneral Pointsã€‚å…¶æ¬¡ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥æç¤ºå¤šæ ·æ€§ï¼Œå³ä½¿ç”¨ä¸åŒçš„æŒ‡ä»¤æ¨¡æ¿æ¥æè¿°ç›¸åŒçš„ä»»åŠ¡ã€‚ç¬¬ä¸‰ï¼Œå¯¹äºæ›´å›°éš¾çš„ä»»åŠ¡ï¼Œä½¿ç”¨CoTç›‘ç£æ¥å¼•å¯¼SFTæ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æœ€åï¼Œé€šè¿‡å®éªŒè¯„ä¼°SFTæ¨¡å‹åœ¨ä¸åŒè®¾ç½®ä¸‹çš„æ³›åŒ–æ€§èƒ½ï¼Œå¹¶ä¸RLåŸºçº¿è¿›è¡Œæ¯”è¾ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ­ç¤ºäº†SFTæ³›åŒ–èƒ½åŠ›ä¸è¶³çš„åŸå› æ˜¯å†»ç»“æç¤ºä¼ªå½±ï¼›2) æå‡ºäº†é€šè¿‡å¼•å…¥æç¤ºå¤šæ ·æ€§å’ŒCoTç›‘ç£æ¥æå‡SFTæ³›åŒ–èƒ½åŠ›çš„æ–¹æ³•ï¼›3) è¯æ˜äº†åœ¨é€‚å½“çš„æ•°æ®å’Œè®­ç»ƒç­–ç•¥ä¸‹ï¼ŒSFTå¯ä»¥è¾¾åˆ°ç”šè‡³è¶…è¿‡RLçš„æ³›åŒ–æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æç¤ºå¤šæ ·æ€§æ–¹é¢ï¼Œç ”ç©¶äººå‘˜ä½¿ç”¨äº†ä¸åŒçš„æŒ‡ä»¤æ¨¡æ¿æ¥æè¿°ç›¸åŒçš„ä»»åŠ¡ï¼Œä¾‹å¦‚ä½¿ç”¨ä¸åŒçš„è¯è¯­æˆ–å¥å¼ã€‚åœ¨CoTç›‘ç£æ–¹é¢ï¼Œç ”ç©¶äººå‘˜æä¾›äº†ä¸­é—´æ¨ç†æ­¥éª¤çš„ç¤ºä¾‹ï¼Œä»¥å¼•å¯¼SFTæ¨¡å‹è¿›è¡Œæ¨ç†ã€‚æ­¤å¤–ï¼Œç ”ç©¶äººå‘˜è¿˜ä½¿ç”¨äº†æ ‡å‡†çš„SFTè®­ç»ƒæµç¨‹ï¼Œå¹¶å¯¹è¶…å‚æ•°è¿›è¡Œäº†è°ƒæ•´ï¼Œä»¥è·å¾—æœ€ä½³æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¼•å…¥æç¤ºå¤šæ ·æ€§åï¼ŒSFTæ¨¡å‹åœ¨æŒ‡ä»¤å˜ä½“ä»»åŠ¡ä¸Šçš„æ³›åŒ–èƒ½åŠ›æ˜¾è‘—æå‡ï¼Œä¸RLåŸºçº¿ç›¸å½“ã€‚ç»“åˆæç¤ºå¤šæ ·æ€§å’ŒCoTç›‘ç£åï¼ŒSFTæ¨¡å‹åœ¨éš¾åº¦å˜ä½“ä»»åŠ¡ä¸Šçš„è¡¨ç°ç”šè‡³è¶…è¿‡äº†RLåŸºçº¿ã€‚ä¾‹å¦‚ï¼Œåœ¨Sokobanæ¸¸æˆä¸­ï¼ŒSFTæ¨¡å‹åœ¨æ›´å¤§çš„ç½‘æ ¼å’Œæ›´å¤šç®±å­çš„åœºæ™¯ä¸‹å–å¾—äº†æ›´å¥½çš„æ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§éœ€è¦å†³ç­–èƒ½åŠ›çš„AIç³»ç»Ÿï¼Œä¾‹å¦‚æ¸¸æˆAIã€æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ç­‰ã€‚é€šè¿‡æå‡SFTçš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥é™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œå¹¶æé«˜AIç³»ç»Ÿåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶ä¹Ÿä¸ºå¦‚ä½•æ›´å¥½åœ°åˆ©ç”¨SFTè¿›è¡Œä»»åŠ¡å­¦ä¹ æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> A prevailing view holds that supervised fine-tuning (SFT) memorizes training data and fails to generalize, whereas reinforcement learning (RL) attains broader robustness. We revisit this claim through a systematic evaluation on two decision-making benchmarks, Sokoban and General Points, and arrive at a different conclusion. We show that much of SFT's perceived failure stems from frozen-prompt artifacts: when trained on fixed instruction templates, SFT models cling to training semantics rather than adapting to new ones. Introducing prompt diversity during training breaks this shortcut and yields strong generalization to unseen instruction variants without harming in-distribution performance. Beyond instruction shifts, we ask whether SFT can generalize to strictly harder tasks. Here, chain-of-thought (CoT) supervision provides an algorithmic scaffold that markedly improves transfer to more difficult regimes, such as larger Sokoban grids with additional boxes and arithmetic with out-of-distribution values or five-card compositions that increase combinatorial complexity. Finally, combining prompt diversity with CoT achieves the best of both worlds: robust generalization across both instruction-variant and difficulty-variant settings, matching or surpassing RL baselines on our benchmarks while retaining SFT's simplicity and stability. These findings challenge the narrative that SFT is inherently inferior to RL and support a data-centric perspective: with appropriately curated demonstrations, vanilla SFT can generalize as strongly as RL. Code reproducing the results in the paper can be found at: https://github.com/XiaofengLin7/debunking-sft-generalization.

