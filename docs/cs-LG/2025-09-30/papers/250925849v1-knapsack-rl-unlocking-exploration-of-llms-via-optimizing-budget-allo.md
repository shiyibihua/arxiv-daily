---
layout: default
title: Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation
---

# Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.25849" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.25849v1</a>
  <a href="https://arxiv.org/pdf/2509.25849.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.25849v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.25849v1', 'Knapsack RL: Unlocking Exploration of LLMs via Optimizing Budget Allocation')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ziniu Li, Congliang Chen, Tianyun Yang, Tian Ding, Ruoyu Sun, Ge Zhang, Wenhao Huang, Zhi-Quan Luo

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-30

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**Knapsack RLÔºöÈÄöËøá‰ºòÂåñÈ¢ÑÁÆóÂàÜÈÖçËß£ÈîÅLLMÁöÑÊé¢Á¥¢ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã` `Âº∫ÂåñÂ≠¶‰π†` `Êé¢Á¥¢È¢ÑÁÆóÂàÜÈÖç` `ËÉåÂåÖÈóÆÈ¢ò` `Ëá™ÈÄÇÂ∫îÂ≠¶‰π†` `Êï∞Â≠¶Êé®ÁêÜ` `ËÆ°ÁÆóÊïàÁéá`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂº∫ÂåñÂ≠¶‰π†ÊñπÊ≥ïÂú®LLMÊé¢Á¥¢‰∏≠ÈááÁî®ÂùáÂåÄÈ¢ÑÁÆóÂàÜÈÖçÔºåÂØºËá¥ÁÆÄÂçï‰ªªÂä°È•±Âíå„ÄÅÂõ∞Èöæ‰ªªÂä°Â§±Ë¥•Ôºå‰∫ßÁîüÂ§ßÈáèÈõ∂Ê¢ØÂ∫¶„ÄÇ
2. ËÆ∫ÊñáÂ∞ÜÊé¢Á¥¢È¢ÑÁÆóÂàÜÈÖçÈóÆÈ¢òÂª∫Ê®°‰∏∫ËÉåÂåÖÈóÆÈ¢òÔºåÊèêÂá∫Ëá™ÈÄÇÂ∫îÂàÜÈÖçËßÑÂàôÔºåÊ†πÊçÆ‰ªªÂä°Â≠¶‰π†Áä∂ÊÄÅÂä®ÊÄÅË∞ÉÊï¥ËµÑÊ∫ê„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜÈùûÈõ∂Ê¢ØÂ∫¶ÊØî‰æãÔºåÂπ∂Âú®Êï∞Â≠¶Êé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó2-9ÂàÜÁöÑÊÄßËÉΩÊèêÂçáÔºåËÆ°ÁÆóÊïàÁéáÊèêÂçá2ÂÄç„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â§ßÂûãËØ≠Ë®ÄÊ®°Âûã(LLM)ÂèØ‰ª•ÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°åËá™ÊàëÊîπËøõÔºåÂú®Ê≠§ËøáÁ®ã‰∏≠ÔºåÂÆÉ‰ª¨ÁîüÊàêËΩ®ËøπÊù•Êé¢Á¥¢ÂíåÂèëÁé∞Êõ¥Â•ΩÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇÁÑ∂ËÄåÔºåËøôÁßçÊé¢Á¥¢ËøáÁ®ãËÆ°ÁÆóÊàêÊú¨È´òÊòÇÔºåÈÄöÂ∏∏Ëø´‰ΩøÂΩìÂâçÊñπÊ≥ï‰∏∫ÊØè‰∏™‰ªªÂä°ÂàÜÈÖçÊúâÈôêÁöÑÊé¢Á¥¢È¢ÑÁÆó„ÄÇËøôÁßçÂùáÂåÄÂàÜÈÖç‰ºö‰∫ßÁîüÊúâÈóÆÈ¢òÁöÑÊûÅÁ´ØÊÉÖÂÜµÔºöÁÆÄÂçïÁöÑ‰ªªÂä°ÊÄªÊòØÊàêÂäüÔºåËÄåÂõ∞ÈöæÁöÑ‰ªªÂä°ÊÄªÊòØÂ§±Ë¥•ÔºåËøô‰∏§ÁßçÊÉÖÂÜµÈÉΩ‰ºöÂú®‰ΩøÁî®ÂπøÊ≥õÁöÑGroup Relative Policy Optimization (GRPO)ÁöÑËÆ≠ÁªÉÊõ¥Êñ∞ÊúüÈó¥‰∫ßÁîüÈõ∂Ê¢ØÂ∫¶„ÄÇÊàë‰ª¨‰ªéÊé¢Á¥¢È¢ÑÁÆóÂàÜÈÖçÁöÑËßíÂ∫¶Ëß£ÂÜ≥‰∫ÜËøô‰∏™ÈóÆÈ¢ò„ÄÇÂ∞ÜÊØè‰∏™‰ªªÂä°ÁöÑÊé¢Á¥¢ËßÜ‰∏∫ÂÖ∑Êúâ‰∏çÂêå‚Äú‰ª∑ÂÄº‚ÄùÂíå‚ÄúÊàêÊú¨‚ÄùÁöÑ‚ÄúÈ°πÁõÆ‚ÄùÔºåÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏éÁªèÂÖ∏ËÉåÂåÖÈóÆÈ¢òÁöÑËÅîÁ≥ª„ÄÇËøôÁßçÂÖ¨ÂºèÂÖÅËÆ∏Êàë‰ª¨Êé®ÂØºÂá∫‰∏ÄÁßçÊúÄ‰Ω≥ÂàÜÈÖçËßÑÂàôÔºåËØ•ËßÑÂàôÂèØ‰ª•Ê†πÊçÆÊ®°ÂûãÂΩìÂâçÁöÑÂ≠¶‰π†Áä∂ÊÄÅËá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçËµÑÊ∫ê„ÄÇÂΩìÂ∫îÁî®‰∫éGRPOÊó∂ÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂú®ËÆ≠ÁªÉÊúüÈó¥Â∞ÜÈùûÈõ∂Á≠ñÁï•Ê¢ØÂ∫¶ÁöÑÊúâÊïàÊØîÁéáÊèêÈ´ò‰∫Ü20-40%„ÄÇ‰Ωú‰∏∫‰∏ÄÁßçËÆ°ÁÆó‰∏äÁöÑ‚ÄúÂÖçË¥πÂçàÈ§ê‚ÄùÔºåÊàë‰ª¨ÁöÑÊñπÊ≥ïÂèØ‰ª•Â∞ÜÊé¢Á¥¢È¢ÑÁÆó‰ªéÂ≠¶‰π†È•±ÂíåÁöÑ‰ªªÂä°ÈáçÊñ∞ÂàÜÈÖçÂà∞ÂΩ±ÂìçÊúÄÂ§ßÁöÑ‰ªªÂä°„ÄÇËøô‰ΩøÂæóËÉΩÂ§ü‰∏∫ÁâπÂà´ÂÖ∑ÊúâÊåëÊàòÊÄßÁöÑÈóÆÈ¢òÊèê‰æõÊõ¥Â§ßÁöÑÈ¢ÑÁÆóÔºà‰æãÂ¶ÇÔºå93Ê¨°rolloutÔºâÔºåËøôÂú®Áªü‰∏ÄÂàÜÈÖç‰∏ãÂú®ËÆ°ÁÆó‰∏äÊòØÁ¶ÅÊ≠¢ÁöÑ„ÄÇËøô‰∫õÊîπËøõËΩ¨Âåñ‰∏∫Êï∞Â≠¶Êé®ÁêÜÂü∫ÂáÜ‰∏äÁöÑÊúâÊÑè‰πâÁöÑÊî∂ÁõäÔºåÂπ≥ÂùáÊîπËøõ2-4ÂàÜÔºåÁâπÂÆö‰ªªÂä°ÁöÑÂ≥∞ÂÄºÊî∂Áõä‰∏∫9ÂàÜ„ÄÇÂÄºÂæóÊ≥®ÊÑèÁöÑÊòØÔºå‰ΩøÁî®‰º†ÁªüÁöÑÂêåË¥®ÂàÜÈÖçÂÆûÁé∞Áõ∏ÂΩìÁöÑÊÄßËÉΩÂ∞ÜÈúÄË¶ÅÂ§ßÁ∫¶2ÂÄçÁöÑËÆ°ÁÆóËµÑÊ∫ê„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑLLMËá™ÊèêÂçáÊñπÊ≥ïÔºåÈÄöÂ∏∏ÈááÁî®ÂùáÂåÄÁöÑÊé¢Á¥¢È¢ÑÁÆóÂàÜÈÖçÁ≠ñÁï•„ÄÇËøôÁßçÁ≠ñÁï•ÁöÑÁóõÁÇπÂú®‰∫éÔºåÂØπ‰∫éÁÆÄÂçïÁöÑ‰ªªÂä°ÔºåÊ®°ÂûãÂèØËÉΩÂ∑≤ÁªèÂ≠¶‰π†ÂæóÂæàÂ•ΩÔºåÁªßÁª≠Êé¢Á¥¢Â∏¶Êù•ÁöÑÊî∂ÁõäÂæàÂ∞èÔºåÈÄ†ÊàêËµÑÊ∫êÊµ™Ë¥πÔºõËÄåÂØπ‰∫éÂõ∞ÈöæÁöÑ‰ªªÂä°ÔºåÊúâÈôêÁöÑÊé¢Á¥¢È¢ÑÁÆóÂèØËÉΩ‰∏çË∂≥‰ª•ËÆ©Ê®°ÂûãÊâæÂà∞ÊúâÊïàÁöÑËß£ÂÜ≥ÊñπÊ°àÔºåÂØºËá¥ËÆ≠ÁªÉÂÅúÊªûÔºåÊ¢ØÂ∫¶Ê∂àÂ§±„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÂ∞ÜÊé¢Á¥¢È¢ÑÁÆóÂàÜÈÖçÈóÆÈ¢òÁ±ªÊØî‰∫éÁªèÂÖ∏ÁöÑËÉåÂåÖÈóÆÈ¢ò„ÄÇÊØè‰∏™‰ªªÂä°ÁöÑÊé¢Á¥¢ËøáÁ®ãË¢´ËßÜ‰∏∫‰∏Ä‰∏™‚ÄúÁâ©ÂìÅ‚ÄùÔºåÂÖ∑Êúâ‰∏ÄÂÆöÁöÑ‚Äú‰ª∑ÂÄº‚ÄùÔºà‰æãÂ¶ÇÔºåÊ®°ÂûãÊÄßËÉΩÁöÑÊèêÂçáÔºâÂíå‚ÄúÊàêÊú¨‚ÄùÔºà‰æãÂ¶ÇÔºåËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÔºâ„ÄÇÁõÆÊ†áÊòØÂú®ÊúâÈôêÁöÑÈ¢ÑÁÆó‰∏ãÔºåÊúÄÂ§ßÂåñÊâÄÊúâ‰ªªÂä°ÁöÑÊÄª‰ª∑ÂÄº„ÄÇÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÊ†πÊçÆÊ®°ÂûãÂú®ÊØè‰∏™‰ªªÂä°‰∏äÁöÑÂ≠¶‰π†Áä∂ÊÄÅÔºåËá™ÈÄÇÂ∫îÂú∞ÂàÜÈÖçÊé¢Á¥¢È¢ÑÁÆóÔºåÂ∞ÜËµÑÊ∫êÈõÜ‰∏≠Âú®ÈÇ£‰∫õÊúÄÊúâÂèØËÉΩÂ∏¶Êù•Êî∂ÁõäÁöÑ‰ªªÂä°‰∏ä„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊ°ÜÊû∂Âü∫‰∫éÁé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†Ëá™ÊèêÂçáÊµÅÁ®ãÔºå‰∏ªË¶ÅÊîπËøõÂú®‰∫éÊé¢Á¥¢Èò∂ÊÆµÁöÑÈ¢ÑÁÆóÂàÜÈÖçÁ≠ñÁï•„ÄÇÂÖ∑‰ΩìÊµÅÁ®ãÂ¶Ç‰∏ãÔºö1) LLMÁîüÊàêËΩ®ËøπËøõË°åÊé¢Á¥¢Ôºõ2) Ê†πÊçÆËΩ®ËøπËÆ°ÁÆóÂ•ñÂä±Ôºõ3) ‰ΩøÁî®Group Relative Policy Optimization (GRPO)Á≠âÁÆóÊ≥ïÊõ¥Êñ∞Á≠ñÁï•Ôºõ4) Ê†πÊçÆÊèêÂá∫ÁöÑËÉåÂåÖÁÆóÊ≥ïÔºåÈáçÊñ∞ÂàÜÈÖç‰∏ã‰∏ÄËΩÆÁöÑÊé¢Á¥¢È¢ÑÁÆó„ÄÇÂÖ≥ÈîÆÊ®°ÂùóÂåÖÊã¨Ôºö‰ª∑ÂÄºËØÑ‰º∞Ê®°ÂùóÔºàËØÑ‰º∞ÊØè‰∏™‰ªªÂä°ÁöÑÊé¢Á¥¢‰ª∑ÂÄºÔºâÂíåÈ¢ÑÁÆóÂàÜÈÖçÊ®°ÂùóÔºàÊ†πÊçÆ‰ª∑ÂÄºÂíåÊàêÊú¨ÔºåÂàÜÈÖçÊé¢Á¥¢È¢ÑÁÆóÔºâ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊé¢Á¥¢È¢ÑÁÆóÂàÜÈÖçÈóÆÈ¢òÂª∫Ê®°‰∏∫ËÉåÂåÖÈóÆÈ¢òÔºåÂπ∂ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫é‰ªªÂä°Â≠¶‰π†Áä∂ÊÄÅÁöÑËá™ÈÄÇÂ∫îÂàÜÈÖçËßÑÂàô„ÄÇ‰∏é‰º†ÁªüÁöÑÂùáÂåÄÂàÜÈÖçÁ≠ñÁï•Áõ∏ÊØîÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ËÆ°ÁÆóËµÑÊ∫êÔºåÊèêÈ´òÊ®°ÂûãÁöÑÂ≠¶‰π†ÊïàÁéá„ÄÇÊú¨Ë¥®Âå∫Âà´Âú®‰∫éÔºåËØ•ÊñπÊ≥ï‰∏çÂÜçÂ∞ÜÊâÄÊúâ‰ªªÂä°ÂêåÁ≠âÂØπÂæÖÔºåËÄåÊòØÊ†πÊçÆÂÖ∂Â≠¶‰π†ÈöæÂ∫¶ÂíåÊΩúÂú®Êî∂ÁõäÔºåËøõË°åÂ∑ÆÂºÇÂåñÂ§ÑÁêÜ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) Â¶Ç‰ΩïÂÆö‰πâÂíåËØÑ‰º∞ÊØè‰∏™‰ªªÂä°ÁöÑÊé¢Á¥¢‰ª∑ÂÄº„ÄÇ‰∏ÄÁßçÂèØËÉΩÁöÑÊñπÊ°àÊòØ‰ΩøÁî®Ê®°ÂûãÂú®‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÊèêÂçá‰Ωú‰∏∫‰ª∑ÂÄºÁöÑË°°ÈáèÊ†áÂáÜ„ÄÇ2) Â¶Ç‰ΩïËÆæËÆ°È¢ÑÁÆóÂàÜÈÖçÁÆóÊ≥ïÔºå‰ª•Âú®Êª°Ë∂≥È¢ÑÁÆóÁ∫¶ÊùüÁöÑÂâçÊèê‰∏ãÔºåÊúÄÂ§ßÂåñÊÄª‰ª∑ÂÄº„ÄÇËÆ∫ÊñáÂèØËÉΩÈááÁî®Âä®ÊÄÅËßÑÂàíÊàñË¥™ÂøÉÁÆóÊ≥ïÁ≠âÊñπÊ≥ïÊù•Ëß£ÂÜ≥ËÉåÂåÖÈóÆÈ¢ò„ÄÇ3) Â¶Ç‰ΩïÂ∞ÜËÉåÂåÖÁÆóÊ≥ï‰∏éÁé∞ÊúâÁöÑÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÔºàÂ¶ÇGRPOÔºâÁõ∏ÁªìÂêàÔºå‰ª•ÂÆûÁé∞Á´ØÂà∞Á´ØÁöÑËÆ≠ÁªÉ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïÂú®Êï∞Â≠¶Êé®ÁêÜÂü∫ÂáÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÂπ≥ÂùáÊèêÂçá2-4ÂàÜÔºåÁâπÂÆö‰ªªÂä°ÁöÑÂ≥∞ÂÄºÊî∂ÁõäËææÂà∞9ÂàÜ„ÄÇÊõ¥ÈáçË¶ÅÁöÑÊòØÔºåËØ•ÊñπÊ≥ïÂú®ËÆ°ÁÆóÊïàÁéáÊñπÈù¢ÂÖ∑ÊúâÊòæËëó‰ºòÂäøÔºåËææÂà∞ÂêåÁ≠âÊÄßËÉΩÊâÄÈúÄÁöÑËÆ°ÁÆóËµÑÊ∫êÂáèÂ∞ë‰∫ÜÁ∫¶2ÂÄç„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÂ∞ÜÈùûÈõ∂Á≠ñÁï•Ê¢ØÂ∫¶ÁöÑÊúâÊïàÊØîÁéáÊèêÈ´ò20-40%ÔºåË°®ÊòéÂÖ∂ËÉΩÂ§üÊõ¥ÊúâÊïàÂú∞Âà©Áî®ËÆ≠ÁªÉÊï∞ÊçÆ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂπøÊ≥õÂ∫îÁî®‰∫éÂêÑÁßçÈúÄË¶ÅÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°å‰ºòÂåñÁöÑLLM‰ªªÂä°Ôºå‰æãÂ¶ÇÊï∞Â≠¶Êé®ÁêÜ„ÄÅ‰ª£Á†ÅÁîüÊàê„ÄÅÊñáÊú¨ÊëòË¶ÅÁ≠â„ÄÇÈÄöËøáÊõ¥ÊúâÊïàÂú∞Âà©Áî®ËÆ°ÁÆóËµÑÊ∫êÔºåÂèØ‰ª•ÊòæËëóÊèêÂçáLLMÁöÑÊÄßËÉΩÂíåËÆ≠ÁªÉÊïàÁéá„ÄÇËØ•ÊñπÊ≥ïËøòÂèØÊé®ÂπøÂà∞ÂÖ∂‰ªñËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®Â≠¶‰π†Âú∫ÊôØÔºå‰æãÂ¶ÇÊ®°ÂûãÂéãÁº©„ÄÅÊï∞ÊçÆÈÄâÊã©Á≠âÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄºÂíåÂπøÈòîÁöÑÊú™Êù•ÂèëÂ±ïÂâçÊôØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Large Language Models (LLMs) can self-improve through reinforcement learning, where they generate trajectories to explore and discover better solutions. However, this exploration process is computationally expensive, often forcing current methods to assign limited exploration budgets to each task. This uniform allocation creates problematic edge cases: easy tasks consistently succeed while difficult tasks consistently fail, both producing zero gradients during training updates for the widely used Group Relative Policy Optimization (GRPO). We address this problem from the lens of exploration budget allocation. Viewing each task's exploration as an "item" with a distinct "value" and "cost", we establish a connection to the classical knapsack problem. This formulation allows us to derive an optimal assignment rule that adaptively distributes resources based on the model's current learning status. When applied to GRPO, our method increases the effective ratio of non-zero policy gradients by 20-40% during training. Acting as a computational "free lunch", our approach could reallocate exploration budgets from tasks where learning is saturated to those where it is most impactful. This enables significantly larger budgets (e.g., 93 rollouts) for especially challenging problems, which would be computationally prohibitive under a uniform allocation. These improvements translate to meaningful gains on mathematical reasoning benchmarks, with average improvements of 2-4 points and peak gains of 9 points on specific tasks. Notably, achieving comparable performance with traditional homogeneous allocation would require about 2x the computational resources.

