---
layout: default
title: Amortized Bayesian Meta-Learning for Low-Rank Adaptation of Large Language Models
---

# Amortized Bayesian Meta-Learning for Low-Rank Adaptation of Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.14285" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.14285v2</a>
  <a href="https://arxiv.org/pdf/2508.14285.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.14285v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.14285v2', 'Amortized Bayesian Meta-Learning for Low-Rank Adaptation of Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liyi Zhang, Jake Snell, Thomas L. Griffiths

**åˆ†ç±»**: cs.LG, cs.AI, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-12-09)

**å¤‡æ³¨**: 16 pages, 2 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºABMLLä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹ä½ç§©é€‚åº”çš„æ³›åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä½ç§©é€‚åº”` `è´å¶æ–¯å…ƒå­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `æ³›åŒ–èƒ½åŠ›` `æ¨¡å‹å¾®è°ƒ` `ä¸ç¡®å®šæ€§é‡åŒ–` `è‡ªç„¶è¯­è¨€å¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æé«˜å¤§è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ—¶ï¼Œå¾€å¾€éœ€è¦å¤§é‡å†…å­˜å’Œè®¡ç®—èµ„æºï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. æœ¬æ–‡æå‡ºçš„ABMLLæ–¹æ³•é€šè¿‡æ‘Šé”€è´å¶æ–¯å…ƒå­¦ä¹ ï¼Œä¼˜åŒ–äº†ä½ç§©é€‚åº”è¿‡ç¨‹ï¼Œæå‡äº†è®¡ç®—æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒABMLLåœ¨CrossFitå’ŒUnified-QAæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œå…·æœ‰æ›´å¥½çš„å‡†ç¡®æ€§å’Œæ ¡å‡†èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œä½ç§©é€‚åº”ï¼ˆLoRAï¼‰å¾®è°ƒæ˜¯ä¸€ç§æœ‰æ•ˆçš„æ–¹å¼ï¼Œå¯ä»¥å°†ç‰¹å®šæ•°æ®é›†çš„ä¿¡æ¯èå…¥æ¨¡å‹ä¸­ã€‚ç„¶è€Œï¼Œå¾®è°ƒåçš„LLMåœ¨æœªè§æ•°æ®é›†ä¸Šçš„æ³›åŒ–èƒ½åŠ›å¸¸å¸¸ä¸æ˜ç¡®ã€‚ç°æœ‰æ–¹æ³•é€šè¿‡ä¼˜åŒ–ä¸Šä¸‹æ–‡æç¤ºæˆ–ä½¿ç”¨å…ƒå­¦ä¹ æ¥æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨å†…å­˜å’Œè®¡ç®—ä¸Šæˆæœ¬é«˜æ˜‚ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†åŸºäºæ‘Šé”€è´å¶æ–¯å…ƒå­¦ä¹ çš„LoRAæ–¹æ³•ï¼ˆABMLLï¼‰ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œå°†æ‘Šé”€è´å¶æ–¯å…ƒå­¦ä¹ çš„æ€æƒ³åº”ç”¨äºLLMsã€‚ABMLLåœ¨CrossFitå’ŒUnified-QAæ•°æ®é›†ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œç»“æœæ˜¾ç¤ºå…¶åœ¨å‡†ç¡®æ€§å’ŒæœŸæœ›æ ¡å‡†è¯¯å·®æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ç‰¹å®šæ•°æ®é›†å¾®è°ƒåçš„æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¦‚ä¼˜åŒ–ä¸Šä¸‹æ–‡æç¤ºå’Œå…ƒå­¦ä¹ è™½ç„¶æœ‰æ•ˆï¼Œä½†åœ¨å†…å­˜å’Œè®¡ç®—ä¸Šä»£ä»·é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šABMLLé€šè¿‡æ‘Šé”€è´å¶æ–¯å…ƒå­¦ä¹ çš„æ¡†æ¶ï¼Œé€‚åº”äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶ï¼Œæå‡æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é‡æ–°å®šä¹‰äº†ä»»åŠ¡ç‰¹å®šå‚æ•°å’Œå…¨å±€å‚æ•°çš„å…³ç³»ï¼Œå¹¶å¼•å…¥æ–°çš„è¶…å‚æ•°æ¥å¹³è¡¡é‡æ„ç²¾åº¦ä¸ä»»åŠ¡ç‰¹å®šå‚æ•°çš„ä¿çœŸåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šABMLLçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä»»åŠ¡ç‰¹å®šå‚æ•°å’Œå…¨å±€å‚æ•°çš„é‡æ„è¿‡ç¨‹ï¼Œåˆ©ç”¨è´å¶æ–¯æ¡†æ¶è¿›è¡Œä¸ç¡®å®šæ€§é‡åŒ–ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¼˜åŒ–è¶…å‚æ•°æ¥å®ç°é«˜æ•ˆçš„å¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šABMLLçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ‘Šé”€è´å¶æ–¯å…ƒå­¦ä¹ æ–¹æ³•æˆåŠŸåº”ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼Œæ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œä¸ç¡®å®šæ€§é‡åŒ–èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè®¡ç®—å¼€é”€å¤§å¹…é™ä½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ABMLLä¸­ï¼Œè®¾è®¡äº†æ–°çš„è¶…å‚æ•°ä»¥å¹³è¡¡é‡æ„ç²¾åº¦ä¸ä»»åŠ¡ç‰¹å®šå‚æ•°çš„ä¿çœŸåº¦ï¼Œç¡®ä¿æ¨¡å‹åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨CrossFitå’ŒUnified-QAæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒABMLLåœ¨å‡†ç¡®æ€§å’ŒæœŸæœ›æ ¡å‡†è¯¯å·®æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°X%ï¼ˆå…·ä½“æ•°æ®æœªçŸ¥ï¼‰ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’Œæ™ºèƒ½é—®ç­”ç­‰ã€‚é€šè¿‡æé«˜å¤§å‹è¯­è¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼ŒABMLLèƒ½å¤Ÿåœ¨å¤šç§ä»»åŠ¡ä¸­å®ç°æ›´å¥½çš„æ€§èƒ½ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Fine-tuning large language models (LLMs) with low-rank adaptation (LoRA) is a cost-effective way to incorporate information from a specific dataset. However, it is often unclear how well the fine-tuned LLM will generalize, i.e., how well it will perform on unseen datasets. Methods have been proposed to improve generalization by optimizing in-context prompts, or by using meta-learning to fine-tune LLMs. However, these methods are expensive in memory and computation, requiring either long-context prompts or saving copies of parameters and using second-order gradient updates. To address these challenges, we propose Amortized Bayesian Meta-Learning for LoRA (ABMLL). This method builds on amortized Bayesian meta-learning for smaller models, adapting this approach to LLMs while maintaining its computational efficiency. We reframe task-specific and global parameters in the context of LoRA and use a new hyperparameter to balance reconstruction accuracy and the fidelity of task-specific parameters to the global ones. ABMLL provides effective generalization and scales to large models such as LLAMA3-8B. Furthermore, as a result of using a Bayesian framework, ABMLL provides improved uncertainty quantification. We test ABMLL on CrossFit and Unified-QA datasets and find that it outperforms existing methods on these benchmarks in terms of both accuracy and expected calibration error.

