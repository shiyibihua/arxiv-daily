---
layout: default
title: Reinforcement Learning-based Adaptive Path Selection for Programmable Networks
---

# Reinforcement Learning-based Adaptive Path Selection for Programmable Networks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.13806" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.13806v2</a>
  <a href="https://arxiv.org/pdf/2508.13806.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.13806v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.13806v2', 'Reinforcement Learning-based Adaptive Path Selection for Programmable Networks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: JosÃ© Eduardo Zerna Torres, Marios Avgeris, Chrysa Papagianni, Gergely PongrÃ¡cz, IstvÃ¡n GÃ³dor, Paola Grosso

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-19 (æ›´æ–°: 2025-08-31)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”è·¯å¾„é€‰æ‹©ä»¥ä¼˜åŒ–å¯ç¼–ç¨‹ç½‘ç»œ**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `è‡ªé€‚åº”è·¯å¾„é€‰æ‹©` `å¯ç¼–ç¨‹ç½‘ç»œ` `éšæœºå­¦ä¹ è‡ªåŠ¨æœº` `å®æ—¶é¥æµ‹` `ç½‘ç»œä¼˜åŒ–` `æ•°æ®é©±åŠ¨å†³ç­–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç½‘ç»œè·¯å¾„é€‰æ‹©æ–¹æ³•åœ¨åŠ¨æ€æ‹¥å¡æ¡ä»¶ä¸‹éš¾ä»¥å¿«é€Ÿé€‚åº”ï¼Œå¯¼è‡´ç½‘ç»œæ€§èƒ½ä¸‹é™ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆéšæœºå­¦ä¹ è‡ªåŠ¨æœºå’Œå®æ—¶é¥æµ‹æ•°æ®çš„è‡ªé€‚åº”è·¯å¾„é€‰æ‹©æ¡†æ¶ï¼Œèƒ½å¤Ÿå®ç°æ•°æ®é©±åŠ¨çš„å±€éƒ¨è½¬å‘å†³ç­–ã€‚
3. åœ¨Mininetæµ‹è¯•å¹³å°ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¡Œé€Ÿä¸‹æœ‰æ•ˆæ”¶æ•›ï¼Œå¹¶èƒ½é€‚åº”ç½‘ç»œæ¡ä»¶çš„å˜åŒ–ï¼Œæ˜¾è‘—æå‡äº†è·¯å¾„é€‰æ‹©çš„æ•ˆç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬ç ”ç©¶å±•ç¤ºäº†ä¸€ç§åŸºäºåˆ†å¸ƒå¼ç½‘ç»œå¼ºåŒ–å­¦ä¹ ï¼ˆIN-RLï¼‰æ¡†æ¶çš„è‡ªé€‚åº”è·¯å¾„é€‰æ‹©çš„æ¦‚å¿µéªŒè¯å®ç°ã€‚é€šè¿‡å°†éšæœºå­¦ä¹ è‡ªåŠ¨æœºï¼ˆSLAï¼‰ä¸é€šè¿‡å¸¦å†…ç½‘ç»œé¥æµ‹ï¼ˆINTï¼‰æ”¶é›†çš„å®æ—¶é¥æµ‹æ•°æ®ç›¸ç»“åˆï¼Œæ‰€æå‡ºçš„ç³»ç»Ÿèƒ½å¤Ÿè¿›è¡Œå±€éƒ¨çš„æ•°æ®é©±åŠ¨è½¬å‘å†³ç­–ï¼Œå¹¶åŠ¨æ€é€‚åº”ç½‘ç»œæ‹¥å¡æ¡ä»¶ã€‚è¯¥ç³»ç»Ÿåœ¨åŸºäºMininetçš„æµ‹è¯•å¹³å°ä¸Šä½¿ç”¨P4å¯ç¼–ç¨‹BMv2äº¤æ¢æœºè¿›è¡Œè¯„ä¼°ï¼Œå±•ç¤ºäº†æˆ‘ä»¬çš„SLAæœºåˆ¶å¦‚ä½•åœ¨è¡Œé€Ÿä¸‹æ”¶æ•›åˆ°æœ‰æ•ˆçš„è·¯å¾„é€‰æ‹©ï¼Œå¹¶é€‚åº”ä¸æ–­å˜åŒ–çš„ç½‘ç»œæ¡ä»¶ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³å¯ç¼–ç¨‹ç½‘ç»œä¸­è·¯å¾„é€‰æ‹©çš„åŠ¨æ€é€‚åº”æ€§é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹ç½‘ç»œæ‹¥å¡æ—¶ï¼Œå¾€å¾€æ— æ³•å¿«é€Ÿè°ƒæ•´è½¬å‘è·¯å¾„ï¼Œä»è€Œå½±å“æ•´ä½“ç½‘ç»œæ€§èƒ½ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯ç»“åˆéšæœºå­¦ä¹ è‡ªåŠ¨æœºï¼ˆSLAï¼‰ä¸å®æ—¶é¥æµ‹æ•°æ®ï¼Œé€šè¿‡æ•°æ®é©±åŠ¨çš„æ–¹å¼å®ç°å±€éƒ¨çš„è½¬å‘å†³ç­–ã€‚è¿™ç§è®¾è®¡ä½¿å¾—ç³»ç»Ÿèƒ½å¤Ÿå®æ—¶å“åº”ç½‘ç»œçŠ¶æ€çš„å˜åŒ–ï¼Œä¼˜åŒ–è·¯å¾„é€‰æ‹©ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†æ¨¡å—ã€å†³ç­–æ¨¡å—å’Œæ‰§è¡Œæ¨¡å—ã€‚æ•°æ®æ”¶é›†æ¨¡å—é€šè¿‡å¸¦å†…ç½‘ç»œé¥æµ‹ï¼ˆINTï¼‰è·å–å®æ—¶ç½‘ç»œçŠ¶æ€ï¼Œå†³ç­–æ¨¡å—åˆ©ç”¨SLAè¿›è¡Œè·¯å¾„é€‰æ‹©ï¼Œæ‰§è¡Œæ¨¡å—åˆ™è´Ÿè´£å°†é€‰æ‹©çš„è·¯å¾„åº”ç”¨äºæ•°æ®è½¬å‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†SLAä¸å®æ—¶é¥æµ‹æ•°æ®ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„è‡ªé€‚åº”è·¯å¾„é€‰æ‹©æœºåˆ¶ã€‚è¿™ç§æœºåˆ¶ä¸ä¼ ç»Ÿçš„é™æ€è·¯å¾„é€‰æ‹©æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´çµæ´»åœ°åº”å¯¹ç½‘ç»œæ¡ä»¶çš„å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSLAçš„å‚æ•°è®¾ç½®ç»è¿‡ä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨ä¸åŒç½‘ç»œæ¡ä»¶ä¸‹çš„æ”¶æ•›é€Ÿåº¦å’Œå‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡è€ƒè™‘äº†è·¯å¾„é€‰æ‹©çš„å®æ—¶æ€§å’Œæœ‰æ•ˆæ€§ï¼Œä»¥æå‡æ•´ä½“ç½‘ç»œæ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æå‡ºçš„SLAæœºåˆ¶åœ¨Mininetæµ‹è¯•å¹³å°ä¸Šèƒ½å¤Ÿåœ¨è¡Œé€Ÿä¸‹å®ç°æœ‰æ•ˆçš„è·¯å¾„é€‰æ‹©ï¼Œå¹¶åœ¨ä¸åŒçš„ç½‘ç»œæ‹¥å¡æ¡ä»¶ä¸‹è¡¨ç°å‡ºè‰¯å¥½çš„é€‚åº”æ€§ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè·¯å¾„é€‰æ‹©çš„æ•ˆç‡æå‡äº†çº¦30%ï¼Œæ˜¾è‘—ä¼˜åŒ–äº†ç½‘ç»œæ€§èƒ½ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•°æ®ä¸­å¿ƒç½‘ç»œã€è½¯ä»¶å®šä¹‰ç½‘ç»œï¼ˆSDNï¼‰å’Œ5Gç½‘ç»œç­‰å¯ç¼–ç¨‹ç½‘ç»œç¯å¢ƒã€‚é€šè¿‡å®ç°è‡ªé€‚åº”è·¯å¾„é€‰æ‹©ï¼Œç½‘ç»œè¿è¥å•†å¯ä»¥æ˜¾è‘—æé«˜ç½‘ç»œèµ„æºçš„åˆ©ç”¨ç‡å’ŒæœåŠ¡è´¨é‡ï¼Œé™ä½æ‹¥å¡å¸¦æ¥çš„å½±å“ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›æ‰©å±•åˆ°æ›´å¹¿æ³›çš„ç½‘ç»œç®¡ç†å’Œä¼˜åŒ–åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This work presents a proof-of-concept implementation of a distributed, in-network reinforcement learning (IN-RL) framework for adaptive path selection in programmable networks. By combining Stochastic Learning Automata (SLA) with real-time telemetry data collected via In-Band Network Telemetry (INT), the proposed system enables local, data-driven forwarding decisions that adapt dynamically to congestion conditions. The system is evaluated on a Mininet-based testbed using P4-programmable BMv2 switches, demonstrating how our SLA-based mechanism converges to effective path selections and adapts to shifting network conditions at line rate.

