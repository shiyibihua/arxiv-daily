---
layout: default
title: Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation
---

# Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19999" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19999v2</a>
  <a href="https://arxiv.org/pdf/2508.19999.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19999v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19999v2', 'Linear-Time Demonstration Selection for In-Context Learning via Gradient Estimation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Ziniu Zhang, Zhenshuo Zhang, Dongyue Li, Lu Wang, Jennifer Dy, Hongyang R. Zhang

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27 (æ›´æ–°: 2025-11-04)

**å¤‡æ³¨**: 19 pages. EMNLP'25

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºçº¿æ€§æ—¶é—´ç¤ºä¾‹é€‰æ‹©ç®—æ³•ä»¥ä¼˜åŒ–ä¸Šä¸‹æ–‡å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸Šä¸‹æ–‡å­¦ä¹ ` `ç¤ºä¾‹é€‰æ‹©` `æ¢¯åº¦ä¼°è®¡` `æ¨¡å‹æ¨ç†` `è‡ªç„¶è¯­è¨€å¤„ç†` `é«˜æ•ˆç®—æ³•` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­é€‰æ‹©ç¤ºä¾‹æ—¶ï¼Œä¸»è¦ä¾èµ–tokenåµŒå…¥çš„ç›¸ä¼¼æ€§ï¼Œæ•ˆç‡è¾ƒä½ä¸”è®¡ç®—å¤æ‚åº¦é«˜ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¾“å‡ºæ¢¯åº¦çš„ç¤ºä¾‹é€‰æ‹©æ–¹æ³•ï¼Œé€šè¿‡ä¸€é˜¶è¿‘ä¼¼ä¼°è®¡æ¨¡å‹è¾“å‡ºï¼Œä¼˜åŒ–äº†é€‰æ‹©è¿‡ç¨‹ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¯¯å·®ä½äº1%ï¼Œå¹¶åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸Šæ˜¾è‘—æå‡é€‰æ‹©æ•ˆç‡ï¼Œè¶…è¶Šç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ä»‹ç»äº†ä¸€ç§ç®—æ³•ï¼Œç”¨äºå¿«é€Ÿé€‰æ‹©ç¤ºä¾‹ä»¥æ”¯æŒæŸ¥è¯¢é›†çš„ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚ç»™å®šnä¸ªç¤ºä¾‹ï¼Œå¦‚ä½•å¿«é€Ÿé€‰æ‹©kä¸ªæœ€é€‚åˆä¸‹æ¸¸æ¨ç†çš„æ¡ä»¶ç¤ºä¾‹ï¼Ÿç°æœ‰æ–¹æ³•ä¸»è¦åŸºäºtokenåµŒå…¥çš„ç›¸ä¼¼æ€§ï¼Œè€Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºè¾“å…¥åµŒå…¥ç©ºé—´ä¸­è¾“å‡ºæ¢¯åº¦çš„æ–°æ–¹æ³•ã€‚é€šè¿‡ä¸€é˜¶è¿‘ä¼¼ä¼°è®¡æ¨¡å‹è¾“å‡ºï¼Œå¹¶å¯¹å¤šä¸ªéšæœºé‡‡æ ·å­é›†è¿›è¡Œåº”ç”¨ï¼Œæœ€ç»ˆèšåˆç»“æœå½¢æˆå½±å“è¯„åˆ†ï¼Œä»è€Œé€‰æ‹©å‡ºkä¸ªæœ€ç›¸å…³çš„ç¤ºä¾‹ã€‚è¯¥æ–¹æ³•ä»…éœ€ä¸€æ¬¡é¢„è®¡ç®—æ¨¡å‹è¾“å‡ºå’Œæ¢¯åº¦ï¼Œå…·æœ‰çº¿æ€§æ—¶é—´å¤æ‚åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ¨¡å‹å’Œæ•°æ®é›†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œè¯¯å·®ä½äº1%ï¼Œå¹¶ä¸”åœ¨å‚æ•°é«˜è¾¾340äº¿çš„æ¨¡å‹ä¸Šï¼Œé€‰æ‹©æ•ˆç‡æå‡å¯è¾¾37.7å€ï¼Œå¹³å‡è¶…è¶Šç°æœ‰åŸºäºè¾“å…¥åµŒå…¥çš„é€‰æ‹©æ–¹æ³•11%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯åœ¨ä¸Šä¸‹æ–‡å­¦ä¹ ä¸­å¦‚ä½•å¿«é€Ÿé€‰æ‹©kä¸ªç¤ºä¾‹ä»¥ä¼˜åŒ–ä¸‹æ¸¸æ¨ç†çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦ä¾èµ–äºtokenåµŒå…¥çš„ç›¸ä¼¼æ€§ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œæ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åŸºäºè¾“å…¥åµŒå…¥ç©ºé—´ä¸­è¾“å‡ºçš„æ¢¯åº¦è¿›è¡Œç¤ºä¾‹é€‰æ‹©ã€‚é€šè¿‡ä¸€é˜¶è¿‘ä¼¼æ¥ä¼°è®¡æ¨¡å‹è¾“å‡ºï¼Œä»è€Œå¿«é€Ÿè¯„ä¼°ä¸åŒç¤ºä¾‹çš„å½±å“åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šé¦–å…ˆé¢„è®¡ç®—æ¨¡å‹çš„è¾“å‡ºå’Œæ¢¯åº¦ï¼›ç„¶åå¯¹å¤šä¸ªéšæœºé‡‡æ ·çš„å­é›†è¿›è¡Œè¾“å‡ºä¼°è®¡ï¼›æœ€åèšåˆè¿™äº›ä¼°è®¡ç»“æœï¼Œå½¢æˆæ¯ä¸ªç¤ºä¾‹çš„å½±å“è¯„åˆ†ï¼Œå¹¶é€‰æ‹©å‡ºkä¸ªæœ€ç›¸å…³çš„ç¤ºä¾‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºä½¿ç”¨è¾“å‡ºæ¢¯åº¦è¿›è¡Œç¤ºä¾‹é€‰æ‹©ï¼Œè¿™ä¸ä¼ ç»ŸåŸºäºtokenåµŒå…¥çš„é€‰æ‹©æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ï¼Œæ˜¾è‘—æé«˜äº†é€‰æ‹©æ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®ç°ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬éšæœºé‡‡æ ·çš„å­é›†æ•°é‡å’Œå½±å“è¯„åˆ†çš„è®¡ç®—æ–¹å¼ï¼Œç¡®ä¿äº†ç®—æ³•çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æå‡ºçš„æ¢¯åº¦ä¼°è®¡æ–¹æ³•åœ¨å…­ä¸ªæ•°æ®é›†ä¸Šçš„è¯¯å·®ä½äº1%ï¼Œåœ¨å‚æ•°é«˜è¾¾340äº¿çš„æ¨¡å‹ä¸Šï¼Œé€‰æ‹©æ•ˆç‡æå‡å¯è¾¾37.7å€ï¼Œä¸”åœ¨å¹³å‡æ€§èƒ½ä¸Šè¶…è¶Šç°æœ‰åŸºäºè¾“å…¥åµŒå…¥çš„é€‰æ‹©æ–¹æ³•11%ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„æç¤ºè°ƒä¼˜å’Œé“¾å¼æ¨ç†ç­‰åœºæ™¯ã€‚é€šè¿‡ä¼˜åŒ–ç¤ºä¾‹é€‰æ‹©è¿‡ç¨‹ï¼Œå¯ä»¥åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸­å®ç°æ›´é«˜æ•ˆçš„æ¨ç†ï¼Œæå‡æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„å“åº”é€Ÿåº¦å’Œå‡†ç¡®æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper introduces an algorithm to select demonstration examples for in-context learning of a query set. Given a set of $n$ examples, how can we quickly select $k$ out of $n$ to best serve as the conditioning for downstream inference? This problem has broad applications in prompt tuning and chain-of-thought reasoning. Since model weights remain fixed during in-context learning, previous work has sought to design methods based on the similarity of token embeddings. This work proposes a new approach based on gradients of the output taken in the input embedding space. Our approach estimates model outputs through a first-order approximation using the gradients. Then, we apply this estimation to multiple randomly sampled subsets. Finally, we aggregate the sampled subset outcomes to form an influence score for each demonstration, and select $k$ most relevant examples. This procedure only requires pre-computing model outputs and gradients once, resulting in a linear-time algorithm relative to model and training set sizes. Extensive experiments across various models and datasets validate the efficiency of our approach. We show that the gradient estimation procedure yields approximations of full inference with less than ${1}\%$ error across six datasets. This allows us to scale up subset selection that would otherwise run full inference by up to ${37.7}\times$ on models with up to $34$ billion parameters, and outperform existing selection methods based on input embeddings by ${11}\%$ on average.

