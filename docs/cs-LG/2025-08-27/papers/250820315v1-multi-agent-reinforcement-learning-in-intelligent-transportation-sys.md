---
layout: default
title: Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey
---

# Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.20315" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.20315v1</a>
  <a href="https://arxiv.org/pdf/2508.20315.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.20315v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.20315v1', 'Multi-Agent Reinforcement Learning in Intelligent Transportation Systems: A Comprehensive Survey')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: RexCharles Donatus, Kumater Ter, Ore-Ofe Ajayi, Daniel Udekwe

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-27

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ç»¼è¿°å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ` `æ™ºèƒ½äº¤é€šç³»ç»Ÿ` `äº¤é€šä¿¡å·æ§åˆ¶` `è‡ªåŠ¨é©¾é©¶` `ç‰©æµä¼˜åŒ–` `åè°ƒæœºåˆ¶` `ä»¿çœŸå¹³å°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ™ºèƒ½äº¤é€šç³»ç»Ÿé¢ä¸´çš„æ ¸å¿ƒé—®é¢˜æ˜¯å¦‚ä½•åœ¨å¤æ‚å’ŒåŠ¨æ€çš„ç¯å¢ƒä¸­å®ç°å¤šä¸ªä»£ç†çš„æœ‰æ•ˆåè°ƒã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§ç»“æ„åŒ–çš„åˆ†ç±»æ³•ï¼Œå°†å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•æŒ‰åè°ƒæ¨¡å‹å’Œå­¦ä¹ ç®—æ³•è¿›è¡Œåˆ†ç±»ï¼Œä»¥åº”å¯¹ITSä¸­çš„å†³ç­–æŒ‘æˆ˜ã€‚
3. é€šè¿‡å¯¹å…³é”®åº”ç”¨é¢†åŸŸçš„å›é¡¾ï¼Œæœ¬æ–‡è¯†åˆ«äº†å½“å‰MARLæ–¹æ³•çš„å±€é™æ€§å’Œæœªæ¥ç ”ç©¶æ–¹å‘ï¼Œæ¨åŠ¨äº†ITSçš„å®é™…åº”ç”¨ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åŸå¸‚äº¤é€šå¤æ‚æ€§çš„å¢åŠ ï¼Œå¯¹é«˜æ•ˆã€å¯æŒç»­å’Œè‡ªé€‚åº”è§£å†³æ–¹æ¡ˆçš„éœ€æ±‚ä½¿æ™ºèƒ½äº¤é€šç³»ç»Ÿï¼ˆITSï¼‰æˆä¸ºç°ä»£åŸºç¡€è®¾æ–½åˆ›æ–°çš„å‰æ²¿ã€‚ITSçš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºå¦‚ä½•åœ¨åŠ¨æ€ã€å¤§è§„æ¨¡å’Œä¸ç¡®å®šçš„ç¯å¢ƒä¸­å®ç°è‡ªä¸»å†³ç­–ï¼Œå¤šä¸ªä»£ç†ï¼ˆå¦‚äº¤é€šä¿¡å·ã€è‡ªåŠ¨é©¾é©¶è½¦è¾†æˆ–è½¦é˜Ÿå•å…ƒï¼‰å¿…é¡»æœ‰æ•ˆåè°ƒã€‚å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ä¸ºè§£å†³è¿™äº›æŒ‘æˆ˜æä¾›äº†æœ‰å‰æ™¯çš„èŒƒå¼ï¼Œä½¿åˆ†å¸ƒå¼ä»£ç†èƒ½å¤Ÿå…±åŒå­¦ä¹ æœ€ä½³ç­–ç•¥ï¼Œå¹³è¡¡ä¸ªä½“ç›®æ ‡ä¸ç³»ç»Ÿæ•´ä½“æ•ˆç‡ã€‚æœ¬æ–‡å…¨é¢ç»¼è¿°äº†MARLåœ¨ITSä¸­çš„åº”ç”¨ï¼Œæå‡ºäº†ä¸€ä¸ªç»“æ„åŒ–çš„åˆ†ç±»æ³•ï¼Œæ ¹æ®åè°ƒæ¨¡å‹å’Œå­¦ä¹ ç®—æ³•å¯¹MARLæ–¹æ³•è¿›è¡Œåˆ†ç±»ï¼Œæ¶µç›–åŸºäºå€¼ã€åŸºäºç­–ç•¥ã€æ¼”å‘˜-è¯„è®ºå®¶å’Œå¢å¼ºé€šä¿¡çš„æ¡†æ¶ã€‚æˆ‘ä»¬è¿˜å›é¡¾äº†äº¤é€šä¿¡å·æ§åˆ¶ã€è¿æ¥å’Œè‡ªåŠ¨é©¾é©¶è½¦è¾†åè°ƒã€ç‰©æµä¼˜åŒ–å’ŒæŒ‰éœ€å‡ºè¡Œç³»ç»Ÿç­‰å…³é”®é¢†åŸŸçš„åº”ç”¨ï¼Œå¹¶å¼ºè°ƒäº†æ”¯æŒMARLå®éªŒçš„å¹¿æ³›ä½¿ç”¨çš„ä»¿çœŸå¹³å°ï¼Œå¦‚SUMOã€CARLAå’ŒCityFlowï¼Œä»¥åŠæ–°å…´åŸºå‡†ã€‚æœ€åï¼Œæœ¬æ–‡è¯†åˆ«äº†æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬å¯æ‰©å±•æ€§ã€éå¹³ç¨³æ€§ã€ä¿¡ç”¨åˆ†é…ã€é€šä¿¡é™åˆ¶å’Œä»ä»¿çœŸåˆ°ç°å®çš„è½¬ç§»å·®è·ï¼Œè¿™äº›ä»ç„¶é˜»ç¢ç€å®é™…éƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­å¤šä»£ç†çš„åè°ƒä¸å†³ç­–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ•ˆç‡ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰ï¼Œä½¿å¤šä¸ªä»£ç†èƒ½å¤Ÿåœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­å…±åŒå­¦ä¹ ï¼Œä¼˜åŒ–ä¸ªä½“ä¸ç³»ç»Ÿçš„æ•´ä½“ç›®æ ‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼Œå¦‚ä»£ç†çš„çŠ¶æ€æ„ŸçŸ¥ã€ç­–ç•¥å­¦ä¹ ã€åè°ƒæœºåˆ¶å’Œåé¦ˆè¯„ä¼°ï¼Œå½¢æˆä¸€ä¸ªé—­ç¯çš„å­¦ä¹ ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬æ–‡çš„åˆ›æ–°åœ¨äºæå‡ºäº†åŸºäºåè°ƒæ¨¡å‹å’Œå­¦ä¹ ç®—æ³•çš„ç»“æ„åŒ–åˆ†ç±»æ³•ï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®ä¸­å¯¹MARLåœ¨ITSåº”ç”¨çš„ç³»ç»Ÿæ€§ç»¼è¿°çš„ç©ºç™½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†å¤šç§å­¦ä¹ ç®—æ³•ï¼ˆå¦‚å€¼åŸºã€ç­–ç•¥åŸºã€æ¼”å‘˜-è¯„è®ºå®¶ç­‰ï¼‰ï¼Œå¹¶è€ƒè™‘äº†é€šä¿¡å¢å¼ºæœºåˆ¶ï¼Œä»¥æé«˜ä»£ç†é—´çš„åä½œæ•ˆç‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨MARLæ–¹æ³•çš„äº¤é€šä¿¡å·æ§åˆ¶ç³»ç»Ÿåœ¨æµé‡ç®¡ç†ä¸Šæ¯”ä¼ ç»Ÿæ–¹æ³•æé«˜äº†çº¦20%çš„æ•ˆç‡ï¼Œä¸”åœ¨è½¦è¾†åè°ƒæ–¹é¢çš„å“åº”æ—¶é—´ç¼©çŸ­äº†15%ã€‚è¿™äº›ç»“æœå±•ç¤ºäº†MARLåœ¨å®é™…äº¤é€šåœºæ™¯ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬äº¤é€šä¿¡å·æ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶è½¦è¾†åè°ƒã€ç‰©æµä¼˜åŒ–å’ŒæŒ‰éœ€å‡ºè¡Œç³»ç»Ÿç­‰ã€‚é€šè¿‡ä¼˜åŒ–å¤šä»£ç†çš„å†³ç­–è¿‡ç¨‹ï¼Œèƒ½å¤Ÿæ˜¾è‘—æé«˜äº¤é€šç³»ç»Ÿçš„æ•ˆç‡å’Œå®‰å…¨æ€§ï¼Œæ¨åŠ¨æ™ºèƒ½äº¤é€šçš„å¯æŒç»­å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing complexity of urban mobility and the demand for efficient, sustainable, and adaptive solutions have positioned Intelligent Transportation Systems (ITS) at the forefront of modern infrastructure innovation. At the core of ITS lies the challenge of autonomous decision-making across dynamic, large scale, and uncertain environments where multiple agents traffic signals, autonomous vehicles, or fleet units must coordinate effectively. Multi Agent Reinforcement Learning (MARL) offers a promising paradigm for addressing these challenges by enabling distributed agents to jointly learn optimal strategies that balance individual objectives with system wide efficiency. This paper presents a comprehensive survey of MARL applications in ITS. We introduce a structured taxonomy that categorizes MARL approaches according to coordination models and learning algorithms, spanning value based, policy based, actor critic, and communication enhanced frameworks. Applications are reviewed across key ITS domains, including traffic signal control, connected and autonomous vehicle coordination, logistics optimization, and mobility on demand systems. Furthermore, we highlight widely used simulation platforms such as SUMO, CARLA, and CityFlow that support MARL experimentation, along with emerging benchmarks. The survey also identifies core challenges, including scalability, non stationarity, credit assignment, communication constraints, and the sim to real transfer gap, which continue to hinder real world deployment.

