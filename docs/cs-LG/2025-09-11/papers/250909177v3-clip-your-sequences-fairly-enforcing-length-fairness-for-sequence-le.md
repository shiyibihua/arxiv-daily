---
layout: default
title: Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL
---

# Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09177" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09177v3</a>
  <a href="https://arxiv.org/pdf/2509.09177.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09177v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09177v3', 'Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Hanyi Mao, Quanjia Xiao, Lei Pang, Haixiao Liu

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11 (æ›´æ–°: 2025-10-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFSPOï¼Œé€šè¿‡é•¿åº¦å…¬å¹³çš„è£å‰ªè§£å†³åºåˆ—çº§å¼ºåŒ–å­¦ä¹ ä¸­çš„é•¿åº¦åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `åºåˆ—çº§å¼ºåŒ–å­¦ä¹ ` `é•¿åº¦å…¬å¹³æ€§` `é‡è¦æ€§é‡‡æ ·` `ç­–ç•¥ä¼˜åŒ–` `å¤§å‹è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†é•¿çŸ­åºåˆ—æ—¶å­˜åœ¨åå·®ï¼Œå¯¼è‡´ä¼˜åŒ–æ–¹å‘æ‰­æ›²ã€‚
2. FSPOé€šè¿‡å¼•å…¥é•¿åº¦ç›¸å…³çš„è£å‰ªèŒƒå›´ï¼Œç¡®ä¿å¯¹ä¸åŒé•¿åº¦çš„åºåˆ—è¿›è¡Œå…¬å¹³çš„åŠ æƒã€‚
3. å®éªŒè¯æ˜FSPOèƒ½å¤Ÿç¨³å®šè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šå–å¾—ä¼˜äºåŸºçº¿çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFSPOï¼ˆFair Sequence Policy Optimizationï¼‰çš„åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ã€‚è¯¥æ–¹æ³•å¯¹é‡è¦æ€§é‡‡æ ·ï¼ˆISï¼‰æƒé‡å¼ºåˆ¶æ‰§è¡Œé•¿åº¦å…¬å¹³çš„è£å‰ªã€‚ç ”ç©¶å‘ç°ï¼Œå½“PPO/GRPOé£æ ¼çš„è£å‰ªè¢«ç§»æ¤åˆ°åºåˆ—æ—¶ï¼Œä¼šäº§ç”Ÿä¸åŒ¹é…ï¼šå›ºå®šçš„è£å‰ªèŒƒå›´ç³»ç»Ÿæ€§åœ°é‡æ–°åŠ æƒçŸ­å“åº”ä¸é•¿å“åº”ï¼Œä»è€Œæ‰­æ›²ä¼˜åŒ–æ–¹å‘ã€‚FSPOå¼•å…¥äº†ä¸€ä¸ªç®€å•çš„è¡¥æ•‘æªæ–½ï¼šä½¿ç”¨éš$\sqrt{L}$ç¼©æ”¾çš„å¸¦è£å‰ªåºåˆ—log-ISæ¯”ç‡ã€‚ç†è®ºä¸Šï¼Œæœ¬æ–‡é€šè¿‡é•¿åº¦é‡åŠ æƒè¯¯å·®ï¼ˆLREï¼‰å½¢å¼åŒ–äº†é•¿åº¦å…¬å¹³æ€§ï¼Œå¹¶è¯æ˜äº†å°çš„LREäº§ç”Ÿè£å‰ªæ›´æ–°å’ŒçœŸå®æ›´æ–°ä¹‹é—´çš„ä½™å¼¦æ–¹å‘ä¿è¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFSPOé™ä½äº†è·¨é•¿åº¦ç®±çš„è£å‰ªç‡ï¼Œç¨³å®šäº†è®­ç»ƒï¼Œå¹¶åœ¨å„ç§æ¨¡å‹å¤§å°å’Œè¯„ä¼°æ•°æ®é›†ä¸Šä¼˜äºåŸºçº¿ï¼Œåœ¨Qwen3-8B-Baseæ¨¡å‹ä¸Šè·å¾—äº†æœ€å¤§çš„æ”¶ç›Šã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ—¨åœ¨ä¼˜åŒ–æ•´ä¸ªåºåˆ—çš„ç”Ÿæˆè´¨é‡ï¼Œä½†ç›´æ¥å°†PPO/GRPOç­‰æ–¹æ³•åº”ç”¨äºåºåˆ—æ—¶ï¼Œä¼šå› ä¸ºé‡è¦æ€§é‡‡æ ·çš„ç‰¹æ€§è€Œå¼•å…¥é•¿åº¦åå·®ã€‚å…·ä½“æ¥è¯´ï¼Œå›ºå®šè£å‰ªèŒƒå›´ä¼šä¸æˆæ¯”ä¾‹åœ°å½±å“çŸ­åºåˆ—å’Œé•¿åºåˆ—çš„æ›´æ–°å¹…åº¦ï¼Œå¯¼è‡´æ¨¡å‹å€¾å‘äºç”Ÿæˆç‰¹å®šé•¿åº¦çš„åºåˆ—ï¼Œè€ŒéçœŸæ­£é«˜è´¨é‡çš„åºåˆ—ã€‚è¿™ç§é•¿åº¦åå·®ä¼šæŸå®³æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œç”Ÿæˆå¤šæ ·æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šFSPOçš„æ ¸å¿ƒæ€è·¯æ˜¯ç¡®ä¿å¯¹ä¸åŒé•¿åº¦çš„åºåˆ—è¿›è¡Œå…¬å¹³çš„åŠ æƒï¼Œé¿å…å› åºåˆ—é•¿åº¦è€Œå¼•å…¥çš„åå·®ã€‚ä¸ºæ­¤ï¼ŒFSPOæå‡ºäº†ä¸€ç§é•¿åº¦å…¬å¹³çš„è£å‰ªç­–ç•¥ï¼Œå³è£å‰ªèŒƒå›´ä¸æ˜¯å›ºå®šçš„ï¼Œè€Œæ˜¯ä¸åºåˆ—é•¿åº¦çš„å¹³æ–¹æ ¹æˆæ¯”ä¾‹ã€‚è¿™æ ·ï¼Œè¾ƒé•¿çš„åºåˆ—å…è®¸æ›´å¤§çš„æ›´æ–°å¹…åº¦ï¼Œè€Œè¾ƒçŸ­çš„åºåˆ—åˆ™å—åˆ°æ›´ä¸¥æ ¼çš„é™åˆ¶ï¼Œä»è€Œå¹³è¡¡äº†ä¸åŒé•¿åº¦åºåˆ—å¯¹æ•´ä½“ä¼˜åŒ–çš„è´¡çŒ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFSPOæ²¿ç”¨äº†æ ‡å‡†çš„åºåˆ—çº§å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) ä½¿ç”¨ç­–ç•¥æ¨¡å‹ç”Ÿæˆåºåˆ—ï¼›2) è®¡ç®—é‡è¦æ€§é‡‡æ ·æƒé‡ï¼ˆIS weightï¼‰ï¼Œå³æ–°ç­–ç•¥å’Œæ—§ç­–ç•¥ç”ŸæˆåŒä¸€åºåˆ—çš„æ¦‚ç‡ä¹‹æ¯”ï¼›3) å¯¹ISæƒé‡è¿›è¡Œè£å‰ªï¼Œä»¥é™åˆ¶ç­–ç•¥æ›´æ–°çš„å¹…åº¦ï¼›4) ä½¿ç”¨è£å‰ªåçš„ISæƒé‡è®¡ç®—ç­–ç•¥æ¢¯åº¦ï¼Œå¹¶æ›´æ–°ç­–ç•¥æ¨¡å‹ã€‚FSPOçš„å…³é”®åœ¨äºç¬¬3æ­¥ï¼Œå³è£å‰ªç­–ç•¥ï¼Œå®ƒä½¿ç”¨é•¿åº¦ç›¸å…³çš„è£å‰ªèŒƒå›´ã€‚

**å…³é”®åˆ›æ–°**ï¼šFSPOæœ€å…³é”®çš„åˆ›æ–°åœ¨äºæå‡ºäº†é•¿åº¦å…¬å¹³çš„è£å‰ªç­–ç•¥ã€‚ä¸ä¼ ç»Ÿçš„å›ºå®šè£å‰ªèŒƒå›´ä¸åŒï¼ŒFSPOçš„è£å‰ªèŒƒå›´ä¸åºåˆ—é•¿åº¦çš„å¹³æ–¹æ ¹æˆæ¯”ä¾‹ã€‚è¿™ç§è®¾è®¡èƒ½å¤Ÿæœ‰æ•ˆåœ°ç¼“è§£é•¿åº¦åå·®é—®é¢˜ï¼Œç¡®ä¿å¯¹ä¸åŒé•¿åº¦çš„åºåˆ—è¿›è¡Œå…¬å¹³çš„åŠ æƒã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜ä»ç†è®ºä¸Šåˆ†æäº†é•¿åº¦é‡åŠ æƒè¯¯å·®ï¼ˆLREï¼‰ä¸ç­–ç•¥æ›´æ–°æ–¹å‘ä¹‹é—´çš„å…³ç³»ï¼Œè¯æ˜äº†å°çš„LREèƒ½å¤Ÿä¿è¯è£å‰ªåçš„æ›´æ–°æ–¹å‘ä¸çœŸå®æ›´æ–°æ–¹å‘çš„ä¸€è‡´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šFSPOçš„å…³é”®è®¾è®¡åœ¨äºè£å‰ªèŒƒå›´çš„è®¡ç®—æ–¹å¼ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºé•¿åº¦ä¸ºLçš„åºåˆ—ï¼ŒFSPOä½¿ç”¨$\sqrt{L}$ä½œä¸ºè£å‰ªèŒƒå›´çš„ç¼©æ”¾å› å­ã€‚è¿™æ„å‘³ç€ï¼Œåºåˆ—çš„log-IS ratioä¼šè¢«è£å‰ªåˆ°[-c*$\sqrt{L}$, c*$\sqrt{L}$]çš„èŒƒå›´å†…ï¼Œå…¶ä¸­cæ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨äºæ§åˆ¶è£å‰ªçš„ä¸¥æ ¼ç¨‹åº¦ã€‚è®ºæ–‡ä¸­å¹¶æ²¡æœ‰ç‰¹åˆ«æåˆ°æŸå¤±å‡½æ•°æˆ–ç½‘ç»œç»“æ„çš„ä¿®æ”¹ï¼ŒFSPOä¸»è¦å…³æ³¨çš„æ˜¯è£å‰ªç­–ç•¥çš„æ”¹è¿›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFSPOåœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šéƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚ä¾‹å¦‚ï¼Œåœ¨Qwen3-8B-Baseæ¨¡å‹ä¸Šï¼ŒFSPOçš„æ€§èƒ½æå‡æœ€ä¸ºæ˜æ˜¾ã€‚æ­¤å¤–ï¼ŒFSPOè¿˜èƒ½å¤Ÿé™ä½è·¨é•¿åº¦ç®±çš„è£å‰ªç‡ï¼Œè¡¨æ˜å…¶æœ‰æ•ˆåœ°ç¼“è§£äº†é•¿åº¦åå·®é—®é¢˜ã€‚å®éªŒç»“æœè¿˜è¡¨æ˜ï¼ŒFSPOèƒ½å¤Ÿç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼Œé¿å…å› ç­–ç•¥æ›´æ–°å¹…åº¦è¿‡å¤§è€Œå¯¼è‡´çš„è®­ç»ƒå´©æºƒã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

FSPOå¯åº”ç”¨äºå„ç§éœ€è¦åºåˆ—ç”Ÿæˆçš„ä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬æ‘˜è¦ã€æœºå™¨ç¿»è¯‘ã€å¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡å‡å°‘é•¿åº¦åå·®ï¼ŒFSPOèƒ½å¤Ÿæé«˜ç”Ÿæˆåºåˆ—çš„è´¨é‡å’Œå¤šæ ·æ€§ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸åŒçš„åº”ç”¨åœºæ™¯ã€‚è¯¥æ–¹æ³•å°¤å…¶é€‚ç”¨äºéœ€è¦ç”Ÿæˆé•¿æ–‡æœ¬çš„ä»»åŠ¡ï¼Œä¾‹å¦‚é•¿ç¯‡å°è¯´åˆ›ä½œæˆ–æŠ€æœ¯æ–‡æ¡£ç”Ÿæˆã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We propose FSPO (Fair Sequence Policy Optimization), a sequence-level reinforcement learning method for LLMs that enforces length-fair clipping on the importance-sampling (IS) weight. We study RL methods with sequence-level IS and identify a mismatch when PPO/GRPO-style clipping is transplanted to sequences: a fixed clip range systematically reweights short vs. long responses, distorting the optimization direction. FSPO introduces a simple remedy: we clip the sequence log-IS ratio with a band that scales as $\sqrt{L}$. Theoretically, we formalize length fairness via a Length Reweighting Error (LRE) and prove that small LRE yields a cosine directional guarantee between the clipped and true updates. Empirically, FSPO flattens clip rates across length bins, stabilizes training, and outperforms baselines across model sizes and evaluation datasets, with the largest gains on the Qwen3-8B-Base model.

