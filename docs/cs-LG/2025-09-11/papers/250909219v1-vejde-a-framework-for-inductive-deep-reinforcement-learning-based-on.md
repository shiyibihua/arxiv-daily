---
layout: default
title: Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement
---

# Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.09219" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.09219v1</a>
  <a href="https://arxiv.org/pdf/2509.09219.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.09219v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.09219v1', 'Vejde: A Framework for Inductive Deep Reinforcement Learning Based on Factor Graph Color Refinement')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jakob Nyberg, Pontus Johnson

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-11

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVejdeæ¡†æ¶ä»¥è§£å†³å¤æ‚çŠ¶æ€ä¸‹çš„å†³ç­–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å½’çº³å­¦ä¹ ` `å›¾ç¥ç»ç½‘ç»œ` `å¼ºåŒ–å­¦ä¹ ` `å†³ç­–é—®é¢˜` `ç­–ç•¥æ³›åŒ–` `å¤æ‚çŠ¶æ€` `äºŒåˆ†å›¾` `RDDL`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å…·æœ‰å¤æ‚ç»“æ„çŠ¶æ€çš„å†³ç­–é—®é¢˜æ—¶ï¼Œå¾€å¾€éš¾ä»¥å®ç°æœ‰æ•ˆçš„ç­–ç•¥æ³›åŒ–ã€‚
2. Vejdeæ¡†æ¶é€šè¿‡å°†MDPçŠ¶æ€è½¬åŒ–ä¸ºäºŒåˆ†å›¾ï¼Œå¹¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œè¿›è¡Œæ¶ˆæ¯ä¼ é€’ï¼Œæ¥ç”Ÿæˆå½’çº³ç­–ç•¥å‡½æ•°ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒVejdeä»£ç†åœ¨æœªè§å®ä¾‹ä¸Šçš„å¹³å‡å¾—åˆ†ä¸ç‰¹å®šå®ä¾‹çš„MLPä»£ç†ç›¸è¿‘ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºå¹¶è¯„ä¼°äº†Vejdeæ¡†æ¶ï¼Œè¯¥æ¡†æ¶ç»“åˆäº†æ•°æ®æŠ½è±¡ã€å›¾ç¥ç»ç½‘ç»œå’Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥ç”Ÿæˆé€‚ç”¨äºå…·æœ‰ä¸°å¯Œç»“æ„çŠ¶æ€çš„å†³ç­–é—®é¢˜çš„å½’çº³ç­–ç•¥å‡½æ•°ã€‚MDPçŠ¶æ€è¢«è¡¨ç¤ºä¸ºå…³äºå®ä½“çš„äº‹å®æ•°æ®åº“ï¼ŒVejdeå°†æ¯ä¸ªçŠ¶æ€è½¬æ¢ä¸ºäºŒåˆ†å›¾ï¼Œå¹¶é€šè¿‡ç¥ç»æ¶ˆæ¯ä¼ é€’æ˜ å°„åˆ°æ½œåœ¨çŠ¶æ€ã€‚Vejdeä»£ç†èƒ½å¤Ÿå¤„ç†ä¸åŒè§„æ¨¡å’Œç»“æ„çš„é—®é¢˜ã€‚æˆ‘ä»¬åœ¨å…«ä¸ªRDDLå®šä¹‰çš„é—®é¢˜åŸŸä¸Šæµ‹è¯•äº†Vejdeä»£ç†ï¼Œç»“æœæ˜¾ç¤ºå…¶ç­–ç•¥åœ¨æœªè§å®ä¾‹ä¸Šçš„æ³›åŒ–èƒ½åŠ›è‰¯å¥½ï¼Œä¸”ä¸ç‰¹å®šå®ä¾‹çš„MLPä»£ç†è¡¨ç°ç›¸è¿‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å¤æ‚çŠ¶æ€ä¸‹çš„å†³ç­–é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç­–ç•¥æ³›åŒ–å’Œå¤„ç†å¤šæ ·æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥é€‚åº”ä¸åŒè§„æ¨¡å’Œç»“æ„çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šVejdeæ¡†æ¶é€šè¿‡å°†MDPçŠ¶æ€è¡¨ç¤ºä¸ºäº‹å®æ•°æ®åº“ï¼Œè¿›è€Œè½¬æ¢ä¸ºäºŒåˆ†å›¾ï¼Œåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œçš„æ¶ˆæ¯ä¼ é€’æœºåˆ¶æ¥ç”Ÿæˆå½’çº³ç­–ç•¥å‡½æ•°ï¼Œä»è€Œæé«˜ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šVejdeçš„æ•´ä½“æ¶æ„åŒ…æ‹¬çŠ¶æ€è¡¨ç¤ºæ¨¡å—ã€å›¾è½¬æ¢æ¨¡å—å’Œç­–ç•¥ç”Ÿæˆæ¨¡å—ã€‚çŠ¶æ€è¡¨ç¤ºæ¨¡å—å°†å®ä½“ä¿¡æ¯è½¬åŒ–ä¸ºäº‹å®æ•°æ®åº“ï¼Œå›¾è½¬æ¢æ¨¡å—å°†å…¶è½¬åŒ–ä¸ºäºŒåˆ†å›¾ï¼Œæœ€åé€šè¿‡å›¾ç¥ç»ç½‘ç»œè¿›è¡Œæ¶ˆæ¯ä¼ é€’ä»¥ç”Ÿæˆç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šVejdeçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å°†çŠ¶æ€å’ŒåŠ¨ä½œçš„å› å­åŒ–è¡¨ç¤ºç»“åˆå›¾ç¥ç»ç½‘ç»œï¼Œå…è®¸ä»£ç†åœ¨ä¸åŒè§„æ¨¡å’Œç»“æ„çš„é—®é¢˜ä¸Šè¿›è¡Œæœ‰æ•ˆå­¦ä¹ ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒVejdeé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–ç­–ç•¥ç”Ÿæˆï¼Œå¹¶åœ¨å›¾ç¥ç»ç½‘ç»œä¸­ä½¿ç”¨äº†å¤šå±‚æ„ŸçŸ¥æœºç»“æ„ï¼Œä»¥å¢å¼ºå…¶å¯¹å¤æ‚å…³ç³»çš„å»ºæ¨¡èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVejdeä»£ç†åœ¨æœªè§å®ä¾‹ä¸Šçš„å¾—åˆ†ä¸ç‰¹å®šå®ä¾‹çš„MLPä»£ç†ç›¸è¿‘ï¼Œä¸”åœ¨å…«ä¸ªRDDLå®šä¹‰çš„é—®é¢˜åŸŸä¸­ï¼ŒVejdeçš„ç­–ç•¥åœ¨æ³›åŒ–èƒ½åŠ›ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œæœªè§å®ä¾‹çš„å¾—åˆ†å¹³å‡æœªæ˜¾è‘—ä¸‹é™ï¼Œå±•ç¤ºäº†è‰¯å¥½çš„å­¦ä¹ æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

Vejdeæ¡†æ¶å…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶é€‚ç”¨äºéœ€è¦å¤„ç†å¤æ‚çŠ¶æ€å’Œå…³ç³»çš„å†³ç­–é—®é¢˜ï¼Œå¦‚æœºå™¨äººæ§åˆ¶ã€æ™ºèƒ½äº¤é€šç³»ç»Ÿå’Œæ¸¸æˆAIç­‰é¢†åŸŸã€‚å…¶å½’çº³å­¦ä¹ èƒ½åŠ›èƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œå†³ç­–æ•ˆç‡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨æ™ºèƒ½ç³»ç»Ÿçš„è¿›ä¸€æ­¥å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present and evaluate Vejde; a framework which combines data abstraction, graph neural networks and reinforcement learning to produce inductive policy functions for decision problems with richly structured states, such as object classes and relations. MDP states are represented as data bases of facts about entities, and Vejde converts each state to a bipartite graph, which is mapped to latent states through neural message passing. The factored representation of both states and actions allows Vejde agents to handle problems of varying size and structure. We tested Vejde agents on eight problem domains defined in RDDL, with ten problem instances each, where policies were trained using both supervised and reinforcement learning. To test policy generalization, we separate problem instances in two sets, one for training and the other solely for testing. Test results on unseen instances for the Vejde agents were compared to MLP agents trained on each problem instance, as well as the online planning algorithm Prost. Our results show that Vejde policies in average generalize to the test instances without a significant loss in score. Additionally, the inductive agents received scores on unseen test instances that on average were close to the instance-specific MLP agents.

