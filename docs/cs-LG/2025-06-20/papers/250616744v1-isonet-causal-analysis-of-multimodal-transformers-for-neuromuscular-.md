---
layout: default
title: IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification
---

# IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.16744" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.16744v1</a>
  <a href="https://arxiv.org/pdf/2506.16744.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.16744v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.16744v1', 'IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Eion Tyacke, Kunal Gupta, Jay Patel, Rui Li

**ÂàÜÁ±ª**: cs.LG, cs.RO, eess.SP

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-20

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫IsoNet‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊâãÂäøÂàÜÁ±ª‰∏≠ÁöÑ‰ø°ÊÅØËûçÂêàÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅËûçÂêà` `ÊâãÂäøÂàÜÁ±ª` `Á•ûÁªèËÇåËÇâ‰ø°Âè∑` `Â±ÇÊ¨°Transformer` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `ÈöîÁ¶ªÁΩëÁªú` `ÁîüÁâ©‰ø°Âè∑Â§ÑÁêÜ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏‰æùËµñÂçï‰∏ÄÁîüÁâ©‰ø°Âè∑Ê®°ÊÄÅÔºåÂØºËá¥‰ø°ÊÅØÂà©Áî®‰∏çË∂≥ÔºåÂΩ±ÂìçÊâãÂäøÂàÜÁ±ªÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
2. Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ±ÇÊ¨°TransformerÊû∂ÊûÑÔºåÁªìÂêàÊ≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÂ§öÊ®°ÊÄÅ‰ø°ÊÅØËûçÂêàÔºå‰ª•ÊèêÈ´òÂàÜÁ±ªÊÄßËÉΩ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂ±ÇÊ¨°TransformerÂú®‰∏§‰∏™Êï∞ÊçÆÈõÜ‰∏äÁöÑÂáÜÁ°ÆÁéáÊòæËëóÈ´ò‰∫é‰º†ÁªüÊñπÊ≥ïÔºåÈ™åËØÅ‰∫ÜÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÊâãÂäøÊòØ‰∫∫Á±ªËøêÂä®Á≥ªÁªüÁöÑ‰∏ªË¶ÅËæìÂá∫Ôºå‰ΩÜËß£Á†ÅÂÖ∂Á•ûÁªèËÇåËÇâÁâπÂæÅ‰ªçÊòØÂü∫Á°ÄÁ•ûÁªèÁßëÂ≠¶ÂíåËæÖÂä©ÊäÄÊúØÔºàÂ¶ÇÂÅáËÇ¢ÔºâÁöÑÁì∂È¢à„ÄÇ‰º†ÁªüÁöÑ‰∫∫Êú∫Êé•Âè£‰æùËµñÂçï‰∏ÄÁîüÁâ©‰ø°Âè∑Ê®°ÊÄÅÔºåËÄåÂ§öÊ®°ÊÄÅËûçÂêàÂèØ‰ª•Âà©Áî®‰º†ÊÑüÂô®ÁöÑ‰∫íË°•‰ø°ÊÅØ„ÄÇÊú¨ÊñáÁ≥ªÁªüÊØîËæÉ‰∫ÜÁ∫øÊÄßÂíåÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑËûçÂêàÁ≠ñÁï•ÔºåËØÑ‰º∞‰∫ÜÂ§öÊ®°ÊÄÅMLP„ÄÅÂ§öÊ®°ÊÄÅTransformerÂíåÂ±ÇÊ¨°TransformerÂú®ÂçïÊ®°ÊÄÅÂíåÂ§öÊ®°ÊÄÅËæìÂÖ•Âú∫ÊôØ‰∏ãÁöÑË°®Áé∞„ÄÇÂÆûÈ™å‰ΩøÁî®‰∫Ü‰∏§‰∏™ÂÖ¨ÂºÄÊï∞ÊçÆÈõÜÔºöNinaPro DB2ÔºàsEMGÂíåÂä†ÈÄüÂ∫¶ËÆ°ÔºâÂíåHD-sEMG 65-GestureÔºàÈ´òÂØÜÂ∫¶sEMGÂíåÂäõÔºâ„ÄÇÁªìÊûúË°®ÊòéÔºåÂ±ÇÊ¨°Transformer‰∏éÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑËûçÂêàÁ≠ñÁï•Âú®‰∏§‰∏™Êï∞ÊçÆÈõÜ‰∏äÂùáË°®Áé∞ÊúÄ‰Ω≥ÔºåÂáÜÁ°ÆÁéáË∂ÖËøáÂü∫Á∫ø10%‰ª•‰∏ä„ÄÇÈÄöËøáÂºïÂÖ•ÈöîÁ¶ªÁΩëÁªúÔºåÂÆöÈáèÂàÜÊûê‰∫ÜÊ®°ÊÄÅÈó¥‰∫§‰∫íÂØπÂÜ≥Á≠ñÁöÑË¥°ÁåÆÔºåÂèëÁé∞Ë∑®Ê®°ÊÄÅ‰∫§‰∫íÁ∫¶Âç†ÂÜ≥Á≠ñ‰ø°Âè∑ÁöÑ30%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÊâãÂäøÂàÜÁ±ª‰∏≠‰ø°ÊÅØËûçÂêà‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂ§ö‰æùËµñÂçï‰∏ÄÊ®°ÊÄÅÔºåÂØºËá¥ÂØπÊâãÂäøÁöÑËß£Á†ÅËÉΩÂäõÊúâÈôêÔºåÂΩ±Âìç‰∫ÜÁ•ûÁªèËÇåËÇâ‰ø°Âè∑ÁöÑÂàÜÁ±ªÂáÜÁ°ÆÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ±ÇÊ¨°TransformerÊû∂ÊûÑÔºåÁªìÂêàÊ≥®ÊÑèÂäõÊú∫Âà∂ËøõË°åÂ§öÊ®°ÊÄÅ‰ø°ÊÅØËûçÂêàÔºåÊó®Âú®ÂÖÖÂàÜÂà©Áî®‰∏çÂêåÊ®°ÊÄÅÈó¥ÁöÑ‰∫íË°•‰ø°ÊÅØÔºå‰ªéËÄåÊèêÂçáÂàÜÁ±ªÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏â‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÂ§öÊ®°ÊÄÅMLP„ÄÅÂ§öÊ®°ÊÄÅTransformerÂíåÂ±ÇÊ¨°Transformer„ÄÇÊØè‰∏™Ê®°ÂùóÈÉΩÈááÁî®‰∏çÂêåÁöÑËûçÂêàÁ≠ñÁï•ÔºåÊØîËæÉÂÖ∂Âú®ÂçïÊ®°ÊÄÅÂíåÂ§öÊ®°ÊÄÅËæìÂÖ•‰∏ãÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÊòØÂºïÂÖ•‰∫ÜÈöîÁ¶ªÁΩëÁªúÔºåËÉΩÂ§üÈÄâÊã©ÊÄßÂú∞ÈùôÈü≥ÂçïÊ®°ÊÄÅÊàñË∑®Ê®°ÊÄÅÁöÑÊ≥®ÊÑèÂäõÈÄöÈÅìÔºå‰ªéËÄåÈáèÂåñ‰∏çÂêåÊ®°ÊÄÅ‰∫§‰∫íÂØπÂÜ≥Á≠ñÁöÑË¥°ÁåÆ„ÄÇËøô‰∏ÄÊú∫Âà∂‰∏é‰º†ÁªüÁöÑËûçÂêàÊñπÊ≥ïÊú¨Ë¥®‰∏ä‰∏çÂêåÔºåÂº∫Ë∞É‰∫ÜÊ≥®ÊÑèÂäõÈ©±Âä®ÁöÑËûçÂêàÂú®‰ø°ÊÅØÂà©Áî®‰∏äÁöÑÈáçË¶ÅÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúËÆæËÆ°‰∏≠ÔºåÈááÁî®‰∫ÜÂ±ÇÊ¨°ÁªìÊûÑÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂ÔºåÂÖ≥ÈîÆÂèÇÊï∞ËÆæÁΩÆÂåÖÊã¨Ê≥®ÊÑèÂäõÂ§¥Êï∞ÂíåÂ±ÇÊï∞„ÄÇÊçüÂ§±ÂáΩÊï∞ÈááÁî®‰∫§ÂèâÁÜµÊçüÂ§±Ôºå‰ª•‰ºòÂåñÂàÜÁ±ªÊÄßËÉΩ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂ±ÇÊ¨°Transformer‰∏éÊ≥®ÊÑèÂäõËûçÂêàÁ≠ñÁï•Âú®NinaPro DB2Êï∞ÊçÆÈõÜ‰∏äÂáÜÁ°ÆÁéáÊèêÈ´òË∂ÖËøá10%ÔºåÂú®HD-sEMGÊï∞ÊçÆÈõÜ‰∏äÊèêÈ´ò3.7%„ÄÇË∑®Ê®°ÊÄÅ‰∫§‰∫íÂØπÂÜ≥Á≠ñ‰ø°Âè∑ÁöÑË¥°ÁåÆÁ∫¶‰∏∫30%ÔºåÂº∫Ë∞É‰∫ÜÂ§öÊ®°ÊÄÅËûçÂêàÁöÑÈáçË¶ÅÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂Âú®Á•ûÁªèÊú∫Âô®‰∫∫Á≥ªÁªüÁöÑ‰º†ÊÑüÂô®ÈòµÂàóËÆæËÆ°‰∏≠ÂÖ∑ÊúâÊΩúÂú®Â∫îÁî®‰ª∑ÂÄºÔºåËÉΩÂ§üÊèêÂçáÂÅáËÇ¢Á≠âËæÖÂä©ËÆæÂ§áÁöÑÊéßÂà∂Á≤æÂ∫¶ÂíåÂìçÂ∫îÈÄüÂ∫¶„ÄÇÈÄöËøáÊõ¥Â•ΩÂú∞Ëß£Á†ÅÁ•ûÁªèËÇåËÇâ‰ø°Âè∑ÔºåÊú™Êù•ÂèØËÉΩÊîπÂñÑ‰∫∫Êú∫‰∫§‰∫í‰ΩìÈ™åÔºåÊé®Âä®Áõ∏ÂÖ≥ÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Hand gestures are a primary output of the human motor system, yet the decoding of their neuromuscular signatures remains a bottleneck for basic neuroscience and assistive technologies such as prosthetics. Traditional human-machine interface pipelines rely on a single biosignal modality, but multimodal fusion can exploit complementary information from sensors. We systematically compare linear and attention-based fusion strategies across three architectures: a Multimodal MLP, a Multimodal Transformer, and a Hierarchical Transformer, evaluating performance on scenarios with unimodal and multimodal inputs. Experiments use two publicly available datasets: NinaPro DB2 (sEMG and accelerometer) and HD-sEMG 65-Gesture (high-density sEMG and force). Across both datasets, the Hierarchical Transformer with attention-based fusion consistently achieved the highest accuracy, surpassing the multimodal and best single-modality linear-fusion MLP baseline by over 10% on NinaPro DB2 and 3.7% on HD-sEMG. To investigate how modalities interact, we introduce an Isolation Network that selectively silences unimodal or cross-modal attention pathways, quantifying each group of token interactions' contribution to downstream decisions. Ablations reveal that cross-modal interactions contribute approximately 30% of the decision signal across transformer layers, highlighting the importance of attention-driven fusion in harnessing complementary modality information. Together, these findings reveal when and how multimodal fusion would enhance biosignal classification and also provides mechanistic insights of human muscle activities. The study would be beneficial in the design of sensor arrays for neurorobotic systems.

