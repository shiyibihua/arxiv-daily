---
layout: default
title: No Free Lunch: Rethinking Internal Feedback for LLM Reasoning
---

# No Free Lunch: Rethinking Internal Feedback for LLM Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.17219" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.17219v2</a>
  <a href="https://arxiv.org/pdf/2506.17219.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.17219v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.17219v2', 'No Free Lunch: Rethinking Internal Feedback for LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yanzhi Zhang, Zhaoxi Zhang, Haoxiang Guan, Yilin Cheng, Yitong Duan, Chen Wang, Yue Wang, Shuxin Zheng, Jiyan He

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-20 (æ›´æ–°: 2025-06-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå†…éƒ¨åé¦ˆå¼ºåŒ–å­¦ä¹ ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼ºåŒ–å­¦ä¹ ` `å¤§è¯­è¨€æ¨¡å‹` `å†…éƒ¨åé¦ˆ` `æ¨ç†èƒ½åŠ›` `æ— ç›‘ç£å­¦ä¹ ` `æ¨¡å‹è®­ç»ƒ` `æ•°å­¦æ¨ç†` `æ€§èƒ½è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¦‚RLHFå’ŒRLVRä¾èµ–å¤§é‡å¤–éƒ¨ç›‘ç£ï¼Œé™åˆ¶äº†å…¶åº”ç”¨çš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚
2. æœ¬æ–‡æå‡ºåŸºäºå†…éƒ¨åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLIFï¼‰ï¼Œåˆ©ç”¨æ¨¡å‹å†…éƒ¨ä¿¡å·å¦‚ç†µå’Œè‡ªæˆ‘ç¡®å®šæ€§ï¼Œå‡å°‘å¯¹å¤–éƒ¨å¥–åŠ±çš„ä¾èµ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒRLIFåœ¨è®­ç»ƒåˆæœŸæ˜¾è‘—æå‡äº†LLMsçš„æ¨ç†æ€§èƒ½ï¼Œä½†åœ¨è®­ç»ƒåæœŸæ€§èƒ½ä¸‹é™ï¼Œä¸”å¯¹å·²è°ƒä¼˜æ¨¡å‹æ•ˆæœæœ‰é™ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¼ºåŒ–å­¦ä¹ å·²æˆä¸ºæå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¨ç†èƒ½åŠ›çš„æœ‰æ•ˆèŒƒå¼ã€‚ç°æœ‰æ–¹æ³•å¦‚åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰å’Œå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰è™½ç„¶è¡¨ç°è‰¯å¥½ï¼Œä½†ä¾èµ–å¤§é‡å¤–éƒ¨ç›‘ç£ã€‚æœ¬æ–‡æ¢è®¨äº†ä¸€ç§æ›¿ä»£æ–¹æ³•â€”â€”åŸºäºå†…éƒ¨åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLIFï¼‰ï¼Œè¯¥æ–¹æ³•ä»…ä¾èµ–æ¨¡å‹å†…éƒ¨ç”Ÿæˆçš„ä¿¡å·ï¼Œè€Œéå¤–éƒ¨å¥–åŠ±ã€‚æˆ‘ä»¬åˆ©ç”¨æ— ç›‘ç£çš„å¥–åŠ±ä»£ç†ï¼Œå¦‚ä»¤ç‰Œçº§ç†µã€è½¨è¿¹çº§ç†µå’Œè‡ªæˆ‘ç¡®å®šæ€§ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œè¿™äº›å†…éƒ¨ç›®æ ‡åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯ç­‰ä»·çš„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRLIFåœ¨è®­ç»ƒåˆæœŸèƒ½å¤Ÿæå‡åŸºç¡€LLMsçš„æ¨ç†æ€§èƒ½ï¼Œç”šè‡³åœ¨æŸäº›ä»»åŠ¡ä¸Šè¶…è¶ŠRLVRã€‚ç„¶è€Œï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œæ€§èƒ½ä¸‹é™è‡³è®­ç»ƒå‰æ°´å¹³ã€‚æ­¤å¤–ï¼ŒRLIFå¯¹æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹çš„æå‡æœ‰é™ï¼Œè¡¨æ˜å†…éƒ¨åé¦ˆåœ¨æ¨¡å‹å·²è°ƒä¼˜åæ”¶ç›Šé€’å‡ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æäº†è¿™ä¸€é™åˆ¶ï¼Œå¹¶æä¾›äº†å°†å†…éƒ¨åé¦ˆä¿¡å·æ•´åˆåˆ°LLMè®­ç»ƒä¸­çš„å®ç”¨æŒ‡å—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¼ºåŒ–å­¦ä¹ æ–¹æ³•å¯¹å¤–éƒ¨ç›‘ç£çš„ä¾èµ–é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›æå‡ä¸­çš„å±€é™æ€§ã€‚ç°æœ‰æ–¹æ³•åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éœ€è¦å¤§é‡çš„äººç±»åé¦ˆæˆ–å¯éªŒè¯å¥–åŠ±ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œåº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºåŸºäºå†…éƒ¨åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLIFï¼‰ï¼Œè¯¥æ–¹æ³•ä¾èµ–æ¨¡å‹å†…éƒ¨ç”Ÿæˆçš„ä¿¡å·ï¼Œå¦‚ä»¤ç‰Œçº§ç†µå’Œè½¨è¿¹çº§ç†µï¼Œæ¥æ›¿ä»£å¤–éƒ¨å¥–åŠ±ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å‡å°‘å¯¹å¤–éƒ¨ç›‘ç£çš„éœ€æ±‚ï¼Œæé«˜è®­ç»ƒçš„çµæ´»æ€§å’Œæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šRLIFçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) å†…éƒ¨å¥–åŠ±ä¿¡å·ç”Ÿæˆæ¨¡å—ï¼Œè´Ÿè´£è®¡ç®—ç†µå’Œè‡ªæˆ‘ç¡®å®šæ€§ï¼›2) å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–æ¨¡å—ï¼Œåˆ©ç”¨ç”Ÿæˆçš„å†…éƒ¨ä¿¡å·è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼›3) æ€§èƒ½è¯„ä¼°æ¨¡å—ï¼Œè¯„ä¼°æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚

**å…³é”®åˆ›æ–°**ï¼šRLIFçš„ä¸»è¦åˆ›æ–°åœ¨äºå¼•å…¥å†…éƒ¨åé¦ˆæœºåˆ¶ï¼Œåˆ©ç”¨æ— ç›‘ç£çš„å¥–åŠ±ä»£ç†æ¥æå‡æ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸ç°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºï¼ŒRLIFä¸ä¾èµ–å¤–éƒ¨åé¦ˆï¼Œä»è€Œé™ä½äº†è®­ç»ƒæˆæœ¬å’Œå¤æ‚æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨RLIFä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬ç†µè®¡ç®—çš„çª—å£å¤§å°ã€å¥–åŠ±ä¿¡å·çš„å¹³æ»‘å› å­ç­‰ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šé‡‡ç”¨äº†åŸºäºå†…éƒ¨ä¿¡å·çš„å¼ºåŒ–å­¦ä¹ æŸå¤±ï¼Œç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å†…éƒ¨åé¦ˆè¿›è¡Œä¼˜åŒ–ã€‚æ•´ä½“ç½‘ç»œç»“æ„ä¿æŒäº†LLMçš„åŸºç¡€æ¶æ„ï¼Œä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥äº†æ–°çš„åé¦ˆæœºåˆ¶ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRLIFåœ¨è®­ç»ƒåˆæœŸèƒ½å¤Ÿæ˜¾è‘—æå‡åŸºç¡€LLMsçš„æ¨ç†æ€§èƒ½ï¼Œç”šè‡³åœ¨æŸäº›æ•°å­¦æ¨ç†åŸºå‡†ä»»åŠ¡ä¸Šè¶…è¶ŠRLVRã€‚ç„¶è€Œï¼Œéšç€è®­ç»ƒçš„æ·±å…¥ï¼Œæ€§èƒ½ä¸‹é™è‡³è®­ç»ƒå‰æ°´å¹³ï¼Œä¸”å¯¹æŒ‡ä»¤è°ƒä¼˜æ¨¡å‹çš„æå‡æœ‰é™ï¼Œè¡¨æ˜å†…éƒ¨åé¦ˆçš„æ”¶ç›Šé€’å‡ç°è±¡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½å¯¹è¯ç³»ç»Ÿå’Œæ•™è‚²æŠ€æœ¯ç­‰ã€‚é€šè¿‡æå‡å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒRLIFå¯ä»¥åœ¨è‡ªåŠ¨é—®ç­”ã€æ–‡æœ¬ç”Ÿæˆå’Œä¸ªæ€§åŒ–å­¦ä¹ ç­‰åœºæ™¯ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œå…·æœ‰å¹¿æ³›çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reinforcement learning has emerged as a powerful paradigm for post-training large language models (LLMs) to improve reasoning. Approaches like Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with Verifiable Rewards (RLVR) have shown strong results, but they require extensive external supervision. We investigate an alternative class of methods, Reinforcement Learning from Internal Feedback (RLIF), which relies solely on intrinsic model-derived signals instead of external rewards. In particular, we leverage unsupervised reward proxies such as token-level entropy, trajectory-level entropy, and self-certainty. Our theoretical analysis shows these internal objectives are partially equivalent, and we empirically evaluate various RLIF strategies on challenging math reasoning benchmarks. Experimental results demonstrate that RLIF can boost the reasoning performance of base LLMs at the beginning phase of the training, matching or surpassing RLVR techniques on these tasks. However, when training progresses, performance degrades even below the model before training. Moreover, we find that RLIF yields little improvement for instruction-tuned models, indicating diminishing returns of intrinsic feedback once an LLM is already instruction-tuned. We further analyze this limitation by mixing model weights and explain the reason of RLIF's training behaviors, providing practical guidelines for integrating internal feedback signals into LLM training. We hope our analysis of internal feedback will inform more principled and effective strategies for LLM post-training.

