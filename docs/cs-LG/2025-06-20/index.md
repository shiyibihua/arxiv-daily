---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-06-20
---

# cs.LGï¼ˆ2025-06-20ï¼‰

ğŸ“Š å…± **18** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (8)</a>
<a href="#æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting" class="interest-badge">æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ğŸ”—1)</a>
<a href="#æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion" class="interest-badge">æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250617518v1-a-survey-of-state-representation-learning-for-deep-reinforcement-lea.html">A Survey of State Representation Learning for Deep Reinforcement Learning</a></td>
  <td>ç»¼è¿°çŠ¶æ€è¡¨ç¤ºå­¦ä¹ ä»¥æå‡æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">representation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17518v1" data-paper-url="./papers/250617518v1-a-survey-of-state-representation-learning-for-deep-reinforcement-lea.html" onclick="toggleFavorite(this, '2506.17518v1', 'A Survey of State Representation Learning for Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250617204v1-network-sparsity-unlocks-the-scaling-potential-of-deep-reinforcement.html">Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning</a></td>
  <td>æå‡ºé™æ€ç½‘ç»œç¨€ç–æ€§ä»¥æå‡æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ‰©å±•æ½œåŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17204v1" data-paper-url="./papers/250617204v1-network-sparsity-unlocks-the-scaling-potential-of-deep-reinforcement.html" onclick="toggleFavorite(this, '2506.17204v1', 'Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250617155v2-sparse-reg-improving-sample-complexity-in-offline-reinforcement-lear.html">Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity</a></td>
  <td>æå‡ºSparse-Regä»¥è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„å°æ ·æœ¬è¿‡æ‹Ÿåˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">offline RL</span> <span class="paper-tag">offline reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17155v2" data-paper-url="./papers/250617155v2-sparse-reg-improving-sample-complexity-in-offline-reinforcement-lear.html" onclick="toggleFavorite(this, '2506.17155v2', 'Sparse-Reg: Improving Sample Complexity in Offline Reinforcement Learning using Sparsity')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250617103v1-transdreamerv3-implanting-transformer-in-dreamerv3.html">TransDreamerV3: Implanting Transformer In DreamerV3</a></td>
  <td>æå‡ºTransDreamerV3ä»¥æå‡å¤æ‚ç¯å¢ƒä¸­çš„å†³ç­–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">world model</span> <span class="paper-tag">dreamer</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17103v1" data-paper-url="./papers/250617103v1-transdreamerv3-implanting-transformer-in-dreamerv3.html" onclick="toggleFavorite(this, '2506.17103v1', 'TransDreamerV3: Implanting Transformer In DreamerV3')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250617219v2-no-free-lunch-rethinking-internal-feedback-for-llm-reasoning.html">No Free Lunch: Rethinking Internal Feedback for LLM Reasoning</a></td>
  <td>æå‡ºå†…éƒ¨åé¦ˆå¼ºåŒ–å­¦ä¹ ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17219v2" data-paper-url="./papers/250617219v2-no-free-lunch-rethinking-internal-feedback-for-llm-reasoning.html" onclick="toggleFavorite(this, '2506.17219v2', 'No Free Lunch: Rethinking Internal Feedback for LLM Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250617417v2-aha-moment-revisited-are-vlms-truly-capable-of-self-verification-in-.html">Aha Moment Revisited: Are VLMs Truly Capable of Self Verification in Inference-time Scaling?</a></td>
  <td>æ¢è®¨è§†è§‰è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶é—´æ‰©å±•ä¸­çš„è‡ªéªŒè¯èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17417v2" data-paper-url="./papers/250617417v2-aha-moment-revisited-are-vlms-truly-capable-of-self-verification-in-.html" onclick="toggleFavorite(this, '2506.17417v2', 'Aha Moment Revisited: Are VLMs Truly Capable of Self Verification in Inference-time Scaling?')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250617029v1-scalable-and-reliable-multi-agent-reinforcement-learning-for-traffic.html">Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment</a></td>
  <td>æå‡ºMARL-OD-DAä»¥è§£å†³å¤§è§„æ¨¡äº¤é€šåˆ†é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17029v1" data-paper-url="./papers/250617029v1-scalable-and-reliable-multi-agent-reinforcement-learning-for-traffic.html" onclick="toggleFavorite(this, '2506.17029v1', 'Scalable and Reliable Multi-agent Reinforcement Learning for Traffic Assignment')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250616754v1-metapath-based-hyperbolic-contrastive-learning-for-heterogeneous-gra.html">Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding</a></td>
  <td>æå‡ºåŸºäºå…ƒè·¯å¾„çš„åŒæ›²å¯¹æ¯”å­¦ä¹ ä»¥è§£å†³å¼‚æ„å›¾åµŒå…¥é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16754v1" data-paper-url="./papers/250616754v1-metapath-based-hyperbolic-contrastive-learning-for-heterogeneous-gra.html" onclick="toggleFavorite(this, '2506.16754v1', 'Metapath-based Hyperbolic Contrastive Learning for Heterogeneous Graph Embedding')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (8 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>9</td>
  <td><a href="./papers/250616744v1-isonet-causal-analysis-of-multimodal-transformers-for-neuromuscular-.html">IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification</a></td>
  <td>æå‡ºIsoNetä»¥è§£å†³å¤šæ¨¡æ€æ‰‹åŠ¿åˆ†ç±»ä¸­çš„ä¿¡æ¯èåˆé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16744v1" data-paper-url="./papers/250616744v1-isonet-causal-analysis-of-multimodal-transformers-for-neuromuscular-.html" onclick="toggleFavorite(this, '2506.16744v1', 'IsoNet: Causal Analysis of Multimodal Transformers for Neuromuscular Gesture Classification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250617055v1-universal-music-representations-evaluating-foundation-models-on-worl.html">Universal Music Representations? Evaluating Foundation Models on World Music Corpora</a></td>
  <td>è¯„ä¼°åŸºç¡€æ¨¡å‹åœ¨ä¸–ç•ŒéŸ³ä¹è¯­æ–™åº“ä¸Šçš„æ™®é€‚æ€§</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17055v1" data-paper-url="./papers/250617055v1-universal-music-representations-evaluating-foundation-models-on-worl.html" onclick="toggleFavorite(this, '2506.17055v1', 'Universal Music Representations? Evaluating Foundation Models on World Music Corpora')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250616824v1-predicting-new-research-directions-in-materials-science-using-large-.html">Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs</a></td>
  <td>åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å’Œæ¦‚å¿µå›¾é¢„æµ‹ææ–™ç§‘å­¦çš„æ–°ç ”ç©¶æ–¹å‘</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16824v1" data-paper-url="./papers/250616824v1-predicting-new-research-directions-in-materials-science-using-large-.html" onclick="toggleFavorite(this, '2506.16824v1', 'Predicting New Research Directions in Materials Science using Large Language Models and Concept Graphs')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250617368v2-safex-analyzing-vulnerabilities-of-moe-based-llms-via-stable-safety-.html">SAFEx: Analyzing Vulnerabilities of MoE-Based LLMs via Stable Safety-critical Expert Identification</a></td>
  <td>æå‡ºSAFExä»¥è§£å†³MoEæ¶æ„LLMsçš„å®‰å…¨å¯¹é½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.17368v2" data-paper-url="./papers/250617368v2-safex-analyzing-vulnerabilities-of-moe-based-llms-via-stable-safety-.html" onclick="toggleFavorite(this, '2506.17368v2', 'SAFEx: Analyzing Vulnerabilities of MoE-Based LLMs via Stable Safety-critical Expert Identification')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250616975v2-latent-concept-disentanglement-in-transformer-based-language-models.html">Latent Concept Disentanglement in Transformer-based Language Models</a></td>
  <td>æå‡ºæ½œåœ¨æ¦‚å¿µè§£è€¦æ–¹æ³•ä»¥å¢å¼ºå˜æ¢å™¨è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16975v2" data-paper-url="./papers/250616975v2-latent-concept-disentanglement-in-transformer-based-language-models.html" onclick="toggleFavorite(this, '2506.16975v2', 'Latent Concept Disentanglement in Transformer-based Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250616791v4-tabarena-a-living-benchmark-for-machine-learning-on-tabular-data.html">TabArena: A Living Benchmark for Machine Learning on Tabular Data</a></td>
  <td>æå‡ºTabArenaä»¥è§£å†³é™æ€åŸºå‡†æµ‹è¯•é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16791v4" data-paper-url="./papers/250616791v4-tabarena-a-living-benchmark-for-machine-learning-on-tabular-data.html" onclick="toggleFavorite(this, '2506.16791v4', 'TabArena: A Living Benchmark for Machine Learning on Tabular Data')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250616787v1-revisiting-lora-through-the-lens-of-parameter-redundancy-spectral-en.html">Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps</a></td>
  <td>æå‡ºSeLoRAä»¥è§£å†³LoRAå‚æ•°å†—ä½™é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16787v1" data-paper-url="./papers/250616787v1-revisiting-lora-through-the-lens-of-parameter-redundancy-spectral-en.html" onclick="toggleFavorite(this, '2506.16787v1', 'Revisiting LoRA through the Lens of Parameter Redundancy: Spectral Encoding Helps')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250616659v2-a-minimalist-optimizer-design-for-llm-pretraining.html">A Minimalist Optimizer Design for LLM Pretraining</a></td>
  <td>æå‡ºSCALEä¼˜åŒ–å™¨ä»¥æé«˜LLMé¢„è®­ç»ƒæ•ˆç‡</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16659v2" data-paper-url="./papers/250616659v2-a-minimalist-optimizer-design-for-llm-pretraining.html" onclick="toggleFavorite(this, '2506.16659v2', 'A Minimalist Optimizer Design for LLM Pretraining')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¸ƒåŠ¨ä½œé‡å®šå‘-motion-retargeting">ğŸ”¬ æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>17</td>
  <td><a href="./papers/250616853v2-reward-agnostic-prompt-optimization-for-text-to-image-diffusion-mode.html">Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models</a></td>
  <td>æå‡ºRATTPOä»¥è§£å†³æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆä¸­çš„æç¤ºä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">spatial relationship</span> <span class="paper-tag">large language model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16853v2" data-paper-url="./papers/250616853v2-reward-agnostic-prompt-optimization-for-text-to-image-diffusion-mode.html" onclick="toggleFavorite(this, '2506.16853v2', 'Reward-Agnostic Prompt Optimization for Text-to-Image Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å››ç”Ÿæˆå¼åŠ¨ä½œ-generative-motion">ğŸ”¬ æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250616698v1-side-semantic-id-embedding-for-effective-learning-from-sequences.html">SIDE: Semantic ID Embedding for effective learning from sequences</a></td>
  <td>æå‡ºSIDEæ–¹æ³•ä»¥è§£å†³åºåˆ—æ¨èç³»ç»Ÿä¸­çš„åµŒå…¥è§„æ¨¡é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">VQ-VAE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2506.16698v1" data-paper-url="./papers/250616698v1-side-semantic-id-embedding-for-effective-learning-from-sequences.html" onclick="toggleFavorite(this, '2506.16698v1', 'SIDE: Semantic ID Embedding for effective learning from sequences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)