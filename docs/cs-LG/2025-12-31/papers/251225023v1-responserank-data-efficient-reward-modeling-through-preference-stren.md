---
layout: default
title: "ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning"
---

# ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.25023" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.25023v1</a>
  <a href="https://arxiv.org/pdf/2512.25023.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.25023v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.25023v1', 'ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Timo Kaufmann, Yannick Metz, Daniel Keim, Eyke HÃ¼llermeier

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-12-31

**å¤‡æ³¨**: NeurIPS 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ResponseRankï¼šé€šè¿‡åå¥½å¼ºåº¦å­¦ä¹ å®ç°æ•°æ®é«˜æ•ˆçš„å¥–åŠ±å»ºæ¨¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¥–åŠ±å»ºæ¨¡` `åå¥½å­¦ä¹ ` `å¼ºåŒ–å­¦ä¹ ` `äººæœºåé¦ˆ` `åå¥½å¼ºåº¦` `æ•°æ®æ•ˆç‡` `é²æ£’æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰RLHFæ–¹æ³•ä¾èµ–äºŒå…ƒåå¥½ï¼Œå¿½ç•¥äº†åå¥½å¼ºåº¦ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›å—é™ï¼Œä¸”å¯¹å™ªå£°æ•æ„Ÿã€‚
2. ResponseRanké€šè¿‡æ¯”è¾ƒå±€éƒ¨èŒƒå›´å†…å“åº”çš„ç›¸å¯¹å¼ºåº¦ï¼Œå­¦ä¹ ä¸å¼ºåº¦æ’åºä¸€è‡´çš„æ•ˆç”¨å·®å¼‚ï¼Œä»è€Œæ›´ç¨³å¥åœ°å»ºæ¨¡åå¥½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒResponseRankåœ¨åˆæˆæ•°æ®ã€è¯­è¨€å»ºæ¨¡å’ŒRLæ§åˆ¶ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºæ›´é«˜çš„æ ·æœ¬æ•ˆç‡å’Œé²æ£’æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äºŒå…ƒé€‰æ‹©å¸¸ç”¨äºä»äººç±»åé¦ˆä¸­è¿›è¡Œå¼ºåŒ–å­¦ä¹ (RLHF)ï¼Œä½†ä»…èƒ½ä¼ è¾¾åå¥½çš„æ–¹å‘ã€‚ä¾‹å¦‚ï¼Œäººä»¬å¯èƒ½é€‰æ‹©è‹¹æœè€Œä¸æ˜¯æ©™å­ï¼Œé¦™è•‰è€Œä¸æ˜¯è‘¡è„ï¼Œä½†å“ªç§åå¥½æ›´å¼ºçƒˆï¼Ÿå¼ºåº¦å¯¹äºä¸ç¡®å®šæ€§ä¸‹çš„å†³ç­–å’Œåå¥½æ¨¡å‹çš„æ³›åŒ–è‡³å…³é‡è¦ï¼Œä½†éš¾ä»¥å¯é åœ°è¡¡é‡ã€‚å“åº”æ—¶é—´å’Œæ³¨é‡Šè€…é—´ä¸€è‡´æ€§ç­‰å…ƒæ•°æ®å¯ä»¥ä½œä¸ºå¼ºåº¦çš„ä»£ç†ï¼Œä½†é€šå¸¸å­˜åœ¨å™ªå£°ä¸”ç›¸äº’æ··æ·†ã€‚æˆ‘ä»¬æå‡ºäº†ResponseRankæ¥è§£å†³ä»å™ªå£°å¼ºåº¦ä¿¡å·ä¸­å­¦ä¹ çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ä»£ç†ä¿¡å·ä¸­çš„ç›¸å¯¹å·®å¼‚ï¼Œé€šè¿‡æ¨æ–­çš„åå¥½å¼ºåº¦å¯¹æˆå¯¹æ¯”è¾ƒçš„å“åº”è¿›è¡Œæ’åºã€‚ä¸ºäº†æ§åˆ¶ç³»ç»Ÿæ€§å˜åŒ–ï¼Œæˆ‘ä»¬ä»…åœ¨ç²¾å¿ƒæ„å»ºçš„å±‚å†…å±€éƒ¨æ¯”è¾ƒä¿¡å·ã€‚è¿™ä½¿å¾—èƒ½å¤Ÿç¨³å¥åœ°å­¦ä¹ ä¸å¼ºåº¦å¯¼å‡ºçš„æ’åºä¸€è‡´çš„æ•ˆç”¨å·®å¼‚ï¼ŒåŒæ—¶å¯¹å¼ºåº¦ä¿¡å·åšå‡ºæœ€å°çš„å‡è®¾ã€‚æˆ‘ä»¬çš„è´¡çŒ®æœ‰ä¸‰æ–¹é¢ï¼š(1) ResponseRankï¼Œä¸€ç§é€šè¿‡åˆ©ç”¨å±€éƒ¨æœ‰æ•ˆçš„ç›¸å¯¹å¼ºåº¦ä¿¡å·æ¥ç¨³å¥åœ°å­¦ä¹ åå¥½å¼ºåº¦çš„æ–°æ–¹æ³•ï¼›(2) åœ¨å„ç§ä»»åŠ¡ä¸­æ”¹è¿›æ ·æœ¬æ•ˆç‡å’Œé²æ£’æ€§çš„ç»éªŒè¯æ®ï¼šåˆæˆåå¥½å­¦ä¹ (å…·æœ‰æ¨¡æ‹Ÿå“åº”æ—¶é—´)ã€è¯­è¨€å»ºæ¨¡(å…·æœ‰æ³¨é‡Šè€…ä¸€è‡´æ€§)å’ŒRLæ§åˆ¶ä»»åŠ¡(å…·æœ‰æ¨¡æ‹Ÿepisodeå›æŠ¥)ï¼›(3) Pearsonè·ç¦»ç›¸å…³æ€§(PDC)ï¼Œä¸€ç§å°†åŸºæ•°æ•ˆç”¨å­¦ä¹ ä¸åºæ•°å‡†ç¡®æ€§éš”ç¦»çš„æ–°æŒ‡æ ‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æ–¹æ³•é€šå¸¸åªä½¿ç”¨äºŒå…ƒåå¥½æ•°æ®ï¼Œå³ç»™å®šä¸¤ä¸ªé€‰é¡¹ï¼Œäººç±»é€‰æ‹©æ›´å–œæ¬¢å“ªä¸€ä¸ªã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•å¿½ç•¥äº†åå¥½å¼ºåº¦ï¼Œå³äººç±»å¯¹æŸä¸ªé€‰é¡¹çš„åå¥½ç¨‹åº¦ã€‚åå¥½å¼ºåº¦å¯¹äºåœ¨ä¸ç¡®å®šæ€§ä¸‹åšå‡ºå†³ç­–ä»¥åŠæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›è‡³å…³é‡è¦ã€‚æ­¤å¤–ï¼Œç°æœ‰æ–¹æ³•å®¹æ˜“å—åˆ°å™ªå£°æ•°æ®çš„å½±å“ï¼Œä¾‹å¦‚ï¼Œäººç±»æ ‡æ³¨é”™è¯¯æˆ–ä¸ä¸€è‡´ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šResponseRankçš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨åå¥½å¼ºåº¦ä¿¡æ¯æ¥æé«˜å¥–åŠ±æ¨¡å‹çš„å­¦ä¹ æ•ˆç‡å’Œé²æ£’æ€§ã€‚è¯¥æ–¹æ³•é€šè¿‡æ¯”è¾ƒæˆå¯¹æ¯”è¾ƒä¸­å“åº”çš„ç›¸å¯¹å¼ºåº¦æ¥æ¨æ–­åå¥½å¼ºåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œå®ƒä½¿ç”¨è¯¸å¦‚å“åº”æ—¶é—´æˆ–æ³¨é‡Šè€…é—´ä¸€è‡´æ€§ç­‰ä»£ç†ä¿¡å·æ¥ä¼°è®¡åå¥½å¼ºåº¦ï¼Œå¹¶åˆ©ç”¨è¿™äº›ä¿¡å·ä¸­çš„ç›¸å¯¹å·®å¼‚æ¥å¯¹å“åº”è¿›è¡Œæ’åºã€‚é€šè¿‡å­¦ä¹ ä¸å¼ºåº¦å¯¼å‡ºçš„æ’åºä¸€è‡´çš„æ•ˆç”¨å·®å¼‚ï¼ŒResponseRankèƒ½å¤Ÿæ›´å‡†ç¡®åœ°å»ºæ¨¡äººç±»åå¥½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šResponseRankçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†åŒ…å«æˆå¯¹æ¯”è¾ƒå’Œç›¸åº”ä»£ç†ä¿¡å·ï¼ˆå¦‚å“åº”æ—¶é—´ã€æ³¨é‡Šè€…ä¸€è‡´æ€§ï¼‰çš„æ•°æ®ã€‚2) åˆ†å±‚ï¼šå°†æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªå±€éƒ¨å±‚ï¼Œä»¥æ§åˆ¶ç³»ç»Ÿæ€§å˜åŒ–ã€‚3) å¼ºåº¦æ’åºï¼šåœ¨æ¯ä¸ªå±€éƒ¨å±‚å†…ï¼Œæ ¹æ®ä»£ç†ä¿¡å·çš„ç›¸å¯¹å·®å¼‚å¯¹å“åº”è¿›è¡Œæ’åºï¼Œä»¥æ¨æ–­åå¥½å¼ºåº¦ã€‚4) æ•ˆç”¨å­¦ä¹ ï¼šå­¦ä¹ ä¸å¼ºåº¦å¯¼å‡ºçš„æ’åºä¸€è‡´çš„æ•ˆç”¨å·®å¼‚ã€‚5) æ¨¡å‹è¯„ä¼°ï¼šä½¿ç”¨Pearsonè·ç¦»ç›¸å…³æ€§ï¼ˆPDCï¼‰ç­‰æŒ‡æ ‡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šResponseRankçš„å…³é”®åˆ›æ–°åœ¨äºå®ƒèƒ½å¤Ÿä»å™ªå£°å¼ºåº¦ä¿¡å·ä¸­ç¨³å¥åœ°å­¦ä¹ åå¥½å¼ºåº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒResponseRankä¸ç›´æ¥ä½¿ç”¨ä»£ç†ä¿¡å·çš„ç»å¯¹å€¼ï¼Œè€Œæ˜¯ä½¿ç”¨ç›¸å¯¹å·®å¼‚æ¥æ¨æ–­åå¥½å¼ºåº¦ã€‚æ­¤å¤–ï¼ŒResponseRanké€šè¿‡åˆ†å±‚ç­–ç•¥æ¥æ§åˆ¶ç³»ç»Ÿæ€§å˜åŒ–ï¼Œä»è€Œè¿›ä¸€æ­¥æé«˜äº†é²æ£’æ€§ã€‚Pearsonè·ç¦»ç›¸å…³æ€§ï¼ˆPDCï¼‰æ˜¯ä¸€ç§æ–°çš„è¯„ä¼°æŒ‡æ ‡ï¼Œç”¨äºå°†åŸºæ•°æ•ˆç”¨å­¦ä¹ ä¸åºæ•°å‡†ç¡®æ€§éš”ç¦»ã€‚

**å…³é”®è®¾è®¡**ï¼šResponseRankçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å±€éƒ¨åˆ†å±‚ç­–ç•¥ï¼šé€šè¿‡å°†æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªå±€éƒ¨å±‚ï¼ŒResponseRankèƒ½å¤Ÿæ§åˆ¶ç³»ç»Ÿæ€§å˜åŒ–ï¼Œä¾‹å¦‚ï¼Œä¸åŒæ³¨é‡Šè€…ä¹‹é—´çš„åå¥½å·®å¼‚ã€‚2) ç›¸å¯¹å¼ºåº¦ä¿¡å·ï¼šResponseRankä½¿ç”¨ä»£ç†ä¿¡å·çš„ç›¸å¯¹å·®å¼‚æ¥æ¨æ–­åå¥½å¼ºåº¦ï¼Œè€Œä¸æ˜¯ç›´æ¥ä½¿ç”¨ç»å¯¹å€¼ã€‚è¿™ä½¿å¾—è¯¥æ–¹æ³•å¯¹å™ªå£°æ›´åŠ é²æ£’ã€‚3) æŸå¤±å‡½æ•°ï¼šResponseRankä½¿ç”¨ä¸€ç§æŸå¤±å‡½æ•°ï¼Œè¯¥å‡½æ•°é¼“åŠ±æ¨¡å‹å­¦ä¹ ä¸å¼ºåº¦å¯¼å‡ºçš„æ’åºä¸€è‡´çš„æ•ˆç”¨å·®å¼‚ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å½¢å¼æœªçŸ¥ï¼Œéœ€è¦æŸ¥é˜…è®ºæ–‡åŸæ–‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒResponseRankåœ¨åˆæˆåå¥½å­¦ä¹ ã€è¯­è¨€å»ºæ¨¡å’ŒRLæ§åˆ¶ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­ï¼ŒResponseRankèƒ½å¤Ÿåˆ©ç”¨æ³¨é‡Šè€…ä¸€è‡´æ€§ä¿¡æ¯ï¼Œæ˜¾è‘—æé«˜æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ã€‚åœ¨RLæ§åˆ¶ä»»åŠ¡ä¸­ï¼ŒResponseRankèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ å¥–åŠ±å‡½æ•°ï¼Œä»è€Œæé«˜æ™ºèƒ½ä½“çš„æ€§èƒ½ã€‚å…·ä½“çš„æ€§èƒ½æå‡å¹…åº¦æœªçŸ¥ï¼Œéœ€è¦æŸ¥é˜…è®ºæ–‡åŸæ–‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

ResponseRankå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ï¼š1) æœºå™¨äººæ§åˆ¶ï¼šé€šè¿‡å­¦ä¹ äººç±»å¯¹ä¸åŒæœºå™¨äººè¡Œä¸ºçš„åå¥½ï¼Œå¯ä»¥è®­ç»ƒå‡ºæ›´ç¬¦åˆäººç±»æ„å›¾çš„æœºå™¨äººã€‚2) è‡ªç„¶è¯­è¨€å¤„ç†ï¼šå¯ä»¥ç”¨äºæ”¹è¿›è¯­è¨€æ¨¡å‹çš„ç”Ÿæˆè´¨é‡ï¼Œä½¿å…¶æ›´ç¬¦åˆäººç±»çš„åå¥½ã€‚3) æ¨èç³»ç»Ÿï¼šå¯ä»¥ç”¨äºæ„å»ºæ›´ä¸ªæ€§åŒ–çš„æ¨èç³»ç»Ÿï¼Œæé«˜ç”¨æˆ·æ»¡æ„åº¦ã€‚è¯¥ç ”ç©¶çš„å®é™…ä»·å€¼åœ¨äºæé«˜äº†å¥–åŠ±å»ºæ¨¡çš„æ•ˆç‡å’Œé²æ£’æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨äººæœºåä½œå’Œäººå·¥æ™ºèƒ½åº”ç”¨çš„è¿›æ­¥ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.

