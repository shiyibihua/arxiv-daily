---
layout: default
title: Semi-on-Demand Transit Feeders with Shared Autonomous Vehicles and Reinforcement-Learning-Based Zonal Dispatching Control
---

# Semi-on-Demand Transit Feeders with Shared Autonomous Vehicles and Reinforcement-Learning-Based Zonal Dispatching Control

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.01883" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.01883v1</a>
  <a href="https://arxiv.org/pdf/2509.01883.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.01883v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.01883v1', 'Semi-on-Demand Transit Feeders with Shared Autonomous Vehicles and Reinforcement-Learning-Based Zonal Dispatching Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Max T. M. Ng, Roman Engelhardt, Florian Dandl, Hani S. Mahmassani, Klaus Bogenberger

**åˆ†ç±»**: cs.LG, eess.SY, math.OC

**å‘å¸ƒæ—¥æœŸ**: 2025-09-02

**å¤‡æ³¨**: 6 pages, 9 figures, published in 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC), Edmonton, Canada, 24-27 September 2024

**æœŸåˆŠ**: 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)

**DOI**: [10.1109/ITSC58415.2024.10920214](https://doi.org/10.1109/ITSC58415.2024.10920214)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºå¼ºåŒ–å­¦ä¹ åŒºåŸŸè°ƒåº¦çš„å…±äº«è‡ªåŠ¨é©¾é©¶è½¦è¾†åŠæŒ‰éœ€å…¬äº¤æ¥é©³æœåŠ¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŠæŒ‰éœ€äº¤é€š` `å…±äº«è‡ªåŠ¨é©¾é©¶è½¦è¾†` `å¼ºåŒ–å­¦ä¹ ` `åŒºåŸŸè°ƒåº¦` `å…¬å…±äº¤é€š`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ä¼ ç»Ÿå›ºå®šçº¿è·¯å…¬äº¤åœ¨ä½å¯†åº¦åŒºåŸŸæ•ˆç‡ä½ï¼Œéœ€æ±‚å“åº”å¼äº¤é€šæˆæœ¬é«˜ï¼Œéš¾ä»¥å…¼é¡¾æˆæœ¬æ•ˆç›Šå’Œé€‚åº”æ€§ã€‚
2. æå‡ºåŠæŒ‰éœ€å…¬äº¤æ¥é©³æœåŠ¡ï¼Œç»“åˆå›ºå®šçº¿è·¯å’ŒæŒ‰éœ€å“åº”çš„ä¼˜ç‚¹ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ åŠ¨æ€è°ƒåº¦è½¦è¾†ã€‚
3. åœ¨æ…•å°¼é»‘çœŸå®å…¬äº¤çº¿è·¯ä»¿çœŸè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç•¥å¾®å¢åŠ æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†ä¹˜å®¢æœåŠ¡é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå…±äº«è‡ªåŠ¨é©¾é©¶è½¦è¾†ï¼ˆSAVsï¼‰å’Œå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰åŒºåŸŸè°ƒåº¦æ§åˆ¶çš„åŠæŒ‰éœ€å…¬äº¤æ¥é©³æœåŠ¡ã€‚è¯¥æœåŠ¡ç»“åˆäº†å›ºå®šçº¿è·¯å…¬äº¤çš„æˆæœ¬æ•ˆç›Šå’Œéœ€æ±‚å“åº”å¼äº¤é€šçš„é€‚åº”æ€§ï¼Œä»¥æé«˜ä½å¯†åº¦åŒºåŸŸçš„å¯è¾¾æ€§ã€‚è½¦è¾†ä»ç»ˆç‚¹ç«™å‡ºå‘ï¼Œé¦–å…ˆè¿›è¡Œé¢„å®šçš„å›ºå®šç«™ç‚¹åœé ï¼Œç„¶ååœ¨é¢„å®šçš„çµæ´»çº¿è·¯åŒºåŸŸå†…æä¾›æŒ‰éœ€æ¥é€æœåŠ¡ã€‚æˆ‘ä»¬çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ä½¿ç”¨ç­–ç•¥æ¢¯åº¦ç®—æ³•â€”â€”è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimizationï¼‰ï¼Œæ ¹æ®å®æ—¶éœ€æ±‚æ³¢åŠ¨å’Œè¿è¥æƒ…å†µï¼ŒåŠ¨æ€åœ°å°†è½¦è¾†åˆ†é…åˆ°ç»†åˆ†çš„çµæ´»çº¿è·¯åŒºåŸŸã€‚é€šè¿‡åœ¨å¾·å›½æ…•å°¼é»‘çš„çœŸå®å…¬äº¤çº¿è·¯ä¸Šçš„åŸºäºAgentçš„ä»¿çœŸè¿›è¡Œäº†æ–¹æ³•éªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼Œç»è¿‡æœ‰æ•ˆçš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹è®­ç»ƒåï¼Œä¸ä¼ ç»Ÿçš„å›ºå®šçº¿è·¯æœåŠ¡ç›¸æ¯”ï¼Œå…·æœ‰åŠ¨æ€åŒºåŸŸæ§åˆ¶çš„åŠæŒ‰éœ€æœåŠ¡å¹³å‡å¯æœåŠ¡å¤š16%çš„ä¹˜å®¢ï¼Œä½†å¹¿ä¹‰æˆæœ¬é«˜13%ã€‚å¼ºåŒ–å­¦ä¹ æ§åˆ¶å¸¦æ¥çš„æ•ˆç‡æå‡å¯æœåŠ¡å¤š2.4%çš„ä¹˜å®¢ï¼Œä½†æˆæœ¬é«˜1.4%ã€‚è¿™é¡¹ç ”ç©¶ä¸ä»…å±•ç¤ºäº†å°†SAVæ¥é©³è½¦å’Œæœºå™¨å­¦ä¹ æŠ€æœ¯é›†æˆåˆ°å…¬å…±äº¤é€šä¸­çš„æ½œåŠ›ï¼Œè€Œä¸”ä¸ºè¿›ä¸€æ­¥åˆ›æ–°ä»¥è§£å†³å¤šå¼è”è¿ç³»ç»Ÿä¸­çš„â€œæœ€åä¸€å…¬é‡Œâ€é—®é¢˜å¥ å®šäº†åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä½å¯†åº¦åŒºåŸŸå…¬å…±äº¤é€šâ€œæœ€åä¸€å…¬é‡Œâ€é—®é¢˜ï¼Œç°æœ‰å›ºå®šçº¿è·¯å…¬äº¤æ•ˆç‡ä½ï¼Œæ— æ³•æ»¡è¶³çµæ´»çš„å‡ºè¡Œéœ€æ±‚ï¼›è€Œå®Œå…¨æŒ‰éœ€å“åº”çš„äº¤é€šæ–¹å¼æˆæœ¬åˆè¿‡é«˜ã€‚å› æ­¤ï¼Œéœ€è¦ä¸€ç§å…¼é¡¾æˆæœ¬æ•ˆç›Šå’Œçµæ´»æ€§çš„å…¬å…±äº¤é€šè§£å†³æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å›ºå®šçº¿è·¯å…¬äº¤ä¸æŒ‰éœ€å“åº”äº¤é€šç›¸ç»“åˆï¼Œæå‡ºä¸€ç§åŠæŒ‰éœ€å…¬äº¤æ¥é©³æœåŠ¡ã€‚è½¦è¾†é¦–å…ˆæŒ‰ç…§å›ºå®šçº¿è·¯è¡Œé©¶ï¼Œç„¶ååœ¨ç‰¹å®šåŒºåŸŸå†…æä¾›æŒ‰éœ€æ¥é€æœåŠ¡ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ åŠ¨æ€è°ƒæ•´è½¦è¾†åœ¨ä¸åŒåŒºåŸŸçš„åˆ†é…ï¼Œä»¥é€‚åº”å®æ—¶éœ€æ±‚å˜åŒ–ï¼Œä»è€Œä¼˜åŒ–æ•´ä½“æœåŠ¡æ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) ä¹˜å®¢éœ€æ±‚ç”Ÿæˆæ¨¡å—ï¼šæ¨¡æ‹Ÿä¹˜å®¢çš„å‡ºè¡Œéœ€æ±‚ï¼ŒåŒ…æ‹¬èµ·ç‚¹ã€ç»ˆç‚¹å’Œå‡ºè¡Œæ—¶é—´ã€‚2) è½¦è¾†è°ƒåº¦æ¨¡å—ï¼šåŸºäºå¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ŒåŠ¨æ€åœ°å°†è½¦è¾†åˆ†é…åˆ°ä¸åŒçš„åŒºåŸŸã€‚3) è·¯å¾„è§„åˆ’æ¨¡å—ï¼šä¸ºè½¦è¾†è§„åˆ’è¡Œé©¶è·¯çº¿ï¼ŒåŒ…æ‹¬å›ºå®šçº¿è·¯å’ŒæŒ‰éœ€æ¥é€è·¯çº¿ã€‚4) ä»¿çœŸç¯å¢ƒï¼šæ¨¡æ‹ŸçœŸå®çš„äº¤é€šç¯å¢ƒï¼ŒåŒ…æ‹¬é“è·¯ç½‘ç»œã€äº¤é€šæµé‡ç­‰ã€‚å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“é€šè¿‡ä¸ä»¿çœŸç¯å¢ƒäº¤äº’ï¼Œå­¦ä¹ æœ€ä¼˜çš„è°ƒåº¦ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†å¼ºåŒ–å­¦ä¹ åº”ç”¨äºåŠæŒ‰éœ€å…¬äº¤æ¥é©³æœåŠ¡çš„è½¦è¾†è°ƒåº¦ã€‚é€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼Œè½¦è¾†å¯ä»¥æ ¹æ®å®æ—¶éœ€æ±‚åŠ¨æ€è°ƒæ•´åˆ†é…ï¼Œä»è€Œæé«˜æœåŠ¡æ•ˆç‡å’Œä¹˜å®¢æ»¡æ„åº¦ã€‚ä¸ä¼ ç»Ÿçš„é™æ€è°ƒåº¦æ–¹æ³•ç›¸æ¯”ï¼Œå¼ºåŒ–å­¦ä¹ èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”éœ€æ±‚å˜åŒ–ï¼Œå¹¶åšå‡ºæ›´ä¼˜çš„å†³ç­–ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡é‡‡ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆProximal Policy Optimization, PPOï¼‰ç®—æ³•ä½œä¸ºå¼ºåŒ–å­¦ä¹ çš„æ ¸å¿ƒç®—æ³•ã€‚çŠ¶æ€ç©ºé—´åŒ…æ‹¬å„ä¸ªåŒºåŸŸçš„ä¹˜å®¢éœ€æ±‚ã€è½¦è¾†ä½ç½®ç­‰ä¿¡æ¯ï¼›åŠ¨ä½œç©ºé—´åŒ…æ‹¬å°†è½¦è¾†åˆ†é…åˆ°ä¸åŒåŒºåŸŸçš„å†³ç­–ï¼›å¥–åŠ±å‡½æ•°æ—¨åœ¨æœ€å¤§åŒ–ä¹˜å®¢æœåŠ¡é‡ï¼ŒåŒæ—¶è€ƒè™‘è¿è¥æˆæœ¬ã€‚å…·ä½“å‚æ•°è®¾ç½®æœªçŸ¥ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¼ ç»Ÿçš„å›ºå®šçº¿è·¯æœåŠ¡ç›¸æ¯”ï¼Œè¯¥åŠæŒ‰éœ€æœåŠ¡åœ¨ç»è¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒåï¼Œèƒ½å¤ŸæœåŠ¡å¤š16%çš„ä¹˜å®¢ï¼Œä½†å¹¿ä¹‰æˆæœ¬é«˜13%ã€‚å¼ºåŒ–å­¦ä¹ æ§åˆ¶å¸¦æ¥çš„æ•ˆç‡æå‡å¯æœåŠ¡å¤š2.4%çš„ä¹˜å®¢ï¼Œä½†æˆæœ¬é«˜1.4%ã€‚è¿™è¡¨æ˜è¯¥æ–¹æ³•åœ¨æé«˜æœåŠ¡æ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œèƒ½å¤Ÿåœ¨ä¸€å®šç¨‹åº¦ä¸Šå¹³è¡¡æœåŠ¡è´¨é‡å’Œè¿è¥æˆæœ¬ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºåŸå¸‚ä½å¯†åº¦åŒºåŸŸçš„å…¬å…±äº¤é€šç³»ç»Ÿï¼Œè§£å†³â€œæœ€åä¸€å…¬é‡Œâ€å‡ºè¡Œéš¾é¢˜ï¼Œæé«˜å…¬å…±äº¤é€šçš„å¯è¾¾æ€§å’Œå¸å¼•åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯æ‰©å±•åˆ°å…¶ä»–ç±»å‹çš„äº¤é€šæœåŠ¡ï¼Œå¦‚å…±äº«å•è½¦è°ƒåº¦ã€å‡ºç§Ÿè½¦è°ƒåº¦ç­‰ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œç»“åˆæ›´ç²¾ç¡®çš„éœ€æ±‚é¢„æµ‹å’Œæ›´å¤æ‚çš„äº¤é€šæ¨¡å‹ï¼Œæœ‰æœ›è¿›ä¸€æ­¥æå‡æœåŠ¡æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper develops a semi-on-demand transit feeder service using shared autonomous vehicles (SAVs) and zonal dispatching control based on reinforcement learning (RL). This service combines the cost-effectiveness of fixed-route transit with the adaptability of demand-responsive transport to improve accessibility in lower-density areas. Departing from the terminus, SAVs first make scheduled fixed stops, then offer on-demand pick-ups and drop-offs in a pre-determined flexible-route area. Our deep RL model dynamically assigns vehicles to subdivided flexible-route zones in response to real-time demand fluctuations and operations, using a policy gradient algorithm - Proximal Policy Optimization. The methodology is demonstrated through agent-based simulations on a real-world bus route in Munich, Germany. Results show that after efficient training of the RL model, the semi-on-demand service with dynamic zonal control serves 16% more passengers at 13% higher generalized costs on average compared to traditional fixed-route service. The efficiency gain brought by RL control brings 2.4% more passengers at 1.4% higher costs. This study not only showcases the potential of integrating SAV feeders and machine learning techniques into public transit, but also sets the groundwork for further innovations in addressing first-mile-last-mile problems in multimodal transit systems.

