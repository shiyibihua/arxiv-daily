---
layout: default
title: Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization
---

# Don't Blind Your VLA: Aligning Visual Representations for OOD Generalization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.25616" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.25616v1</a>
  <a href="https://arxiv.org/pdf/2510.25616.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25616v1" onclick="toggleFavorite(this, '2510.25616v1', 'Don\'t Blind Your VLA: Aligning Visual Representations for OOD Generalization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Nikita Kachaev, Mikhail Kolosov, Daniil Zelezetsky, Alexey K. Kovalev, Aleksandr I. Panov

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-10-29

**å¤‡æ³¨**: 13 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•ï¼Œè§£å†³VLAæ¨¡å‹OODæ³›åŒ–èƒ½åŠ›é€€åŒ–é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹` `è¡¨å¾å¯¹é½` `åˆ†å¸ƒå¤–æ³›åŒ–` `åŠ¨ä½œå¾®è°ƒ` `è§†è§‰è¡¨å¾é€€åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. VLAæ¨¡å‹åœ¨åŠ¨ä½œå¾®è°ƒåï¼Œå…¶è§†è§‰è¡¨å¾ä¼šå‘ç”Ÿé€€åŒ–ï¼Œå¯¼è‡´æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸‹é™ï¼Œè¿™æ˜¯å½“å‰VLAæ¨¡å‹é¢ä¸´çš„å…³é”®é—®é¢˜ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§è§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•ï¼Œæ—¨åœ¨ç¼“è§£åŠ¨ä½œå¾®è°ƒå¯¹è§†è§‰è¡¨å¾çš„è´Ÿé¢å½±å“ï¼Œä»è€Œæå‡VLAæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå‡è½»è§†è§‰è¡¨å¾é€€åŒ–ï¼Œå¹¶åœ¨OODåœºæ™¯ä¸‹æ˜¾è‘—æå‡VLAæ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹çš„æ—¥ç›ŠæˆåŠŸæºäºé¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹(VLM)èƒ½å¤Ÿèµ‹äºˆæ™ºèƒ½ä½“å¯è¿ç§»çš„ä¸–ç•ŒçŸ¥è¯†å’Œè§†è§‰-è¯­è¨€(VL)åŸºç¡€ï¼Œä¸ºå…·æœ‰æ›´å¹¿æ³›æ³›åŒ–èƒ½åŠ›çš„åŠ¨ä½œæ¨¡å‹å¥ å®šåŸºç¡€ã€‚ç„¶è€Œï¼Œå½“è¿™äº›VLMè¢«é€‚é…åˆ°åŠ¨ä½œæ¨¡æ€æ—¶ï¼Œå®ƒä»¬åŸå§‹çš„VLè¡¨å¾å’ŒçŸ¥è¯†åœ¨å¤šå¤§ç¨‹åº¦ä¸Šè¢«ä¿ç•™ä»ç„¶ä¸æ¸…æ¥šã€‚æœ¬æ–‡å¯¹VLAå¾®è°ƒæœŸé—´çš„è¡¨å¾ä¿ç•™è¿›è¡Œäº†ç³»ç»Ÿç ”ç©¶ï¼Œè¡¨æ˜æœ´ç´ çš„åŠ¨ä½œå¾®è°ƒä¼šå¯¼è‡´è§†è§‰è¡¨å¾çš„é€€åŒ–ã€‚ä¸ºäº†æè¿°å’Œè¡¡é‡è¿™äº›å½±å“ï¼Œæˆ‘ä»¬æ¢æµ‹äº†VLAçš„éšè—è¡¨å¾å¹¶åˆ†æäº†æ³¨æ„åŠ›å›¾ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç»„æœ‰é’ˆå¯¹æ€§çš„ä»»åŠ¡å’Œæ–¹æ³•ï¼Œå°†VLAæ¨¡å‹ä¸å…¶å¯¹åº”çš„VLMè¿›è¡Œå¯¹æ¯”ï¼Œä»è€Œåˆ†ç¦»å‡ºåŠ¨ä½œå¾®è°ƒå¼•èµ·çš„VLèƒ½åŠ›å˜åŒ–ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯„ä¼°äº†ä¸€ç³»åˆ—å¯¹é½è§†è§‰è¡¨å¾çš„ç­–ç•¥ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•ï¼Œå¯ä»¥å‡è½»é€€åŒ–å¹¶æé«˜å¯¹åˆ†å¸ƒå¤–(OOD)åœºæ™¯çš„æ³›åŒ–èƒ½åŠ›ã€‚æ€»è€Œè¨€ä¹‹ï¼Œæˆ‘ä»¬çš„åˆ†æé˜æ˜äº†åŠ¨ä½œå¾®è°ƒä¸VLè¡¨å¾é€€åŒ–ä¹‹é—´çš„æƒè¡¡ï¼Œå¹¶å¼ºè°ƒäº†æ¢å¤ç»§æ‰¿çš„VLèƒ½åŠ›çš„å®ç”¨æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šVLAæ¨¡å‹åœ¨è¿›è¡ŒåŠ¨ä½œå¾®è°ƒæ—¶ï¼Œä¼šä¸å¯é¿å…åœ°æ”¹å˜å…¶åŸæœ‰çš„è§†è§‰è¡¨å¾ï¼Œå¯¼è‡´æ¨¡å‹åœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸Šçš„æ€§èƒ½ä¸‹é™ï¼Œå°¤å…¶æ˜¯åœ¨åˆ†å¸ƒå¤–(OOD)åœºæ™¯ä¸‹ã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å¿½ç•¥äº†è¿™ç§è¡¨å¾é€€åŒ–é—®é¢˜ï¼Œå¯¼è‡´VLAæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¯¹é½VLAæ¨¡å‹å’ŒåŸå§‹VLMçš„è§†è§‰è¡¨å¾ï¼Œæ¥ç¼“è§£åŠ¨ä½œå¾®è°ƒå¸¦æ¥çš„è¡¨å¾é€€åŒ–ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯åœ¨åŠ¨ä½œå¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œå¼•å…¥é¢å¤–çš„çº¦æŸï¼Œä½¿å¾—VLAæ¨¡å‹çš„è§†è§‰è¡¨å¾å°½å¯èƒ½åœ°æ¥è¿‘åŸå§‹VLMçš„è§†è§‰è¡¨å¾ï¼Œä»è€Œä¿ç•™VLMçš„çŸ¥è¯†å’Œèƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡é¦–å…ˆé€šè¿‡å®éªŒåˆ†æäº†åŠ¨ä½œå¾®è°ƒå¯¹VLAæ¨¡å‹è§†è§‰è¡¨å¾çš„å½±å“ï¼ŒåŒ…æ‹¬æ¢æµ‹éšè—å±‚è¡¨å¾å’Œåˆ†ææ³¨æ„åŠ›å›¾ã€‚ç„¶åï¼Œè®¾è®¡äº†ä¸€ç³»åˆ—æœ‰é’ˆå¯¹æ€§çš„ä»»åŠ¡ï¼Œç”¨äºè¯„ä¼°VLAæ¨¡å‹åœ¨åŠ¨ä½œå¾®è°ƒåçš„VLèƒ½åŠ›å˜åŒ–ã€‚æœ€åï¼Œæå‡ºäº†ä¸€ç§è§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•ï¼Œå¹¶åœ¨å®éªŒä¸­éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå‘ç°äº†åŠ¨ä½œå¾®è°ƒå¯¹VLAæ¨¡å‹è§†è§‰è¡¨å¾çš„è´Ÿé¢å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§ç®€å•æœ‰æ•ˆçš„è§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•æ¥ç¼“è§£è¿™ç§å½±å“ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ›´åŠ å…³æ³¨è§†è§‰è¡¨å¾çš„ä¿ç•™ï¼Œä»è€Œæå‡äº†VLAæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡æå‡ºçš„è§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•ä¸»è¦é€šè¿‡åœ¨åŠ¨ä½œå¾®è°ƒè¿‡ç¨‹ä¸­æ·»åŠ é¢å¤–çš„æŸå¤±å‡½æ•°æ¥å®ç°ã€‚è¯¥æŸå¤±å‡½æ•°çš„ç›®æ ‡æ˜¯æœ€å°åŒ–VLAæ¨¡å‹å’ŒåŸå§‹VLMçš„è§†è§‰è¡¨å¾ä¹‹é—´çš„è·ç¦»ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å½¢å¼å¯ä»¥æ˜¯å‡æ–¹è¯¯å·®(MSE)æˆ–ä½™å¼¦ç›¸ä¼¼åº¦ç­‰ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†ä¸åŒçš„å¯¹é½ç­–ç•¥ï¼Œä¾‹å¦‚åªå¯¹é½ç‰¹å®šå±‚çš„è¡¨å¾æˆ–ä½¿ç”¨ä¸åŒçš„æƒé‡æ¥å¹³è¡¡åŠ¨ä½œå¾®è°ƒæŸå¤±å’Œè¡¨å¾å¯¹é½æŸå¤±ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

è®ºæ–‡é€šè¿‡å®éªŒè¯æ˜ï¼Œæå‡ºçš„è§†è§‰è¡¨å¾å¯¹é½æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå‡è½»åŠ¨ä½œå¾®è°ƒå¯¹VLAæ¨¡å‹è§†è§‰è¡¨å¾çš„è´Ÿé¢å½±å“ï¼Œå¹¶åœ¨OODåœºæ™¯ä¸‹æ˜¾è‘—æå‡VLAæ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å¤šä¸ªOODæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•ç›¸æ¯”åŸºçº¿æ–¹æ³•å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºæœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½åŠ©æ‰‹ç­‰é¢†åŸŸã€‚é€šè¿‡æå‡VLAæ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¯ä»¥ä½¿æ™ºèƒ½ä½“åœ¨æ›´å¤æ‚çš„ç¯å¢ƒä¸­æ‰§è¡Œä»»åŠ¡ï¼Œå¹¶æ›´å¥½åœ°ç†è§£äººç±»æŒ‡ä»¤ã€‚ä¾‹å¦‚ï¼Œåœ¨æœºå™¨äººé¢†åŸŸï¼Œå¯ä»¥ä½¿æœºå™¨äººæ›´å¥½åœ°ç†è§£ç”¨æˆ·çš„è§†è§‰æŒ‡ä»¤ï¼Œä»è€Œå®Œæˆæ›´å¤æ‚çš„ä»»åŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: https://blind-vla-paper.github.io

