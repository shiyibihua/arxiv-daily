---
layout: default
title: FaCT: Faithful Concept Traces for Explaining Neural Network Decisions
---

# FaCT: Faithful Concept Traces for Explaining Neural Network Decisions

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.25512" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.25512v1</a>
  <a href="https://arxiv.org/pdf/2510.25512.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.25512v1" onclick="toggleFavorite(this, '2510.25512v1', 'FaCT: Faithful Concept Traces for Explaining Neural Network Decisions')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Amin Parchami-Araghi, Sukrut Rao, Jonas Fischer, Bernt Schiele

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-29

**å¤‡æ³¨**: Accepted to NeurIPS 2025; Code is available at https://github.com/m-parchami/FaCT

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**FaCTï¼šæå‡ºå¯ä¿¡çš„æ¦‚å¿µè¿½è¸ªæ–¹æ³•ï¼Œç”¨äºè§£é‡Šç¥ç»ç½‘ç»œå†³ç­–è¿‡ç¨‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¥ç»ç½‘ç»œè§£é‡Šæ€§` `æ¦‚å¿µå­¦ä¹ ` `æ¨¡å‹å¿ å®æ€§` `å¯ä¿¡AI` `æ¦‚å¿µè¿½è¸ª` `æ·±åº¦å­¦ä¹ ` `å›¾åƒåˆ†ç±»`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºæ¦‚å¿µçš„ç¥ç»ç½‘ç»œè§£é‡Šæ–¹æ³•é€šå¸¸ä¸å¤Ÿå¿ å®ï¼Œä¸”å¯¹æ¦‚å¿µçš„æ€§è´¨æœ‰è¯¸å¤šé™åˆ¶æ€§å‡è®¾ã€‚
2. è®ºæ–‡æå‡ºä¸€ç§æ–°çš„æ¨¡å‹ï¼Œè¯¥æ¨¡å‹å…·æœ‰æ¨¡å‹å†…åœ¨çš„ã€æœºåˆ¶æ€§çš„æ¦‚å¿µè§£é‡Šï¼Œå¼ºè°ƒæ¦‚å¿µè§£é‡Šçš„å¿ å®æ€§ã€‚
3. å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ¦‚å¿µä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œç”¨æˆ·ä¹Ÿè®¤ä¸ºå…¶æ¦‚å¿µæ›´æ˜“äºç†è§£ï¼ŒåŒæ—¶ä¿æŒäº†ImageNetä¸Šçš„ç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦ç½‘ç»œåœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºå“è¶Šçš„æ€§èƒ½ï¼Œä½†ä»å…¨å±€æ¦‚å¿µå±‚é¢ç†è§£å®ƒä»¬å¦‚ä½•è¿ä½œä»ç„¶æ˜¯ä¸€ä¸ªå…³é”®æŒ‘æˆ˜ã€‚è®¸å¤šäº‹ååŸºäºæ¦‚å¿µçš„æ–¹æ³•è¢«å¼•å…¥ä»¥ç†è§£å®ƒä»¬çš„å·¥ä½œæ–¹å¼ï¼Œä½†å®ƒä»¬å¹¶ä¸æ€»æ˜¯å¿ å®äºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¯¹æ¨¡å‹å­¦ä¹ çš„æ¦‚å¿µåšå‡ºäº†é™åˆ¶æ€§å‡è®¾ï¼Œä¾‹å¦‚ç±»åˆ«ç‰¹å¼‚æ€§ã€å°ç©ºé—´èŒƒå›´æˆ–ä¸äººç±»æœŸæœ›çš„å¯¹é½ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒè¿™ç§åŸºäºæ¦‚å¿µçš„è§£é‡Šçš„å¿ å®æ€§ï¼Œå¹¶æå‡ºäº†ä¸€ç§å…·æœ‰æ¨¡å‹å†…åœ¨æœºåˆ¶æ¦‚å¿µè§£é‡Šçš„æ–°æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ¦‚å¿µåœ¨ç±»ä¹‹é—´å…±äº«ï¼Œå¹¶ä¸”ä»ä»»ä½•å±‚ï¼Œå®ƒä»¬å¯¹logitçš„è´¡çŒ®å’Œå®ƒä»¬çš„è¾“å…¥å¯è§†åŒ–éƒ½å¯ä»¥è¢«å¿ å®åœ°è¿½è¸ªã€‚æˆ‘ä»¬è¿˜åˆ©ç”¨åŸºç¡€æ¨¡å‹æå‡ºäº†ä¸€ç§æ–°çš„æ¦‚å¿µä¸€è‡´æ€§æŒ‡æ ‡ï¼ŒC$^2$-Scoreï¼Œå¯ç”¨äºè¯„ä¼°åŸºäºæ¦‚å¿µçš„æ–¹æ³•ã€‚æˆ‘ä»¬è¡¨æ˜ï¼Œä¸å…ˆå‰çš„å·¥ä½œç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¦‚å¿µåœ¨æ•°é‡ä¸Šæ›´åŠ ä¸€è‡´ï¼Œå¹¶ä¸”ç”¨æˆ·å‘ç°æˆ‘ä»¬çš„æ¦‚å¿µæ›´æ˜“äºè§£é‡Šï¼ŒåŒæ—¶ä¿æŒäº†å…·æœ‰ç«äº‰åŠ›çš„ImageNetæ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åŸºäºæ¦‚å¿µçš„ç¥ç»ç½‘ç»œè§£é‡Šæ–¹æ³•å­˜åœ¨ä¸å¿ å®äºæ¨¡å‹æœ¬èº«ã€å¯¹æ¦‚å¿µçš„ç±»åˆ«ç‰¹å¼‚æ€§ã€ç©ºé—´èŒƒå›´ä»¥åŠä¸äººç±»æœŸæœ›çš„å¯¹é½æ–¹å¼åšå‡ºä¸åˆç†çš„é™åˆ¶æ€§å‡è®¾ç­‰é—®é¢˜ã€‚è¿™äº›é™åˆ¶ä½¿å¾—æˆ‘ä»¬éš¾ä»¥çœŸæ­£ç†è§£ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•è¿›è¡Œå†³ç­–çš„ï¼Œé˜»ç¢äº†æ¨¡å‹çš„å¯ä¿¡åº¦å’Œå¯è§£é‡Šæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒåœ¨äºæå‡ºä¸€ç§æ¨¡å‹å†…åœ¨çš„ã€æœºåˆ¶æ€§çš„æ¦‚å¿µè§£é‡Šæ–¹æ³•ï¼Œå³FaCTï¼ˆFaithful Concept Tracesï¼‰ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡å­¦ä¹ å…±äº«çš„æ¦‚å¿µè¡¨ç¤ºï¼Œå¹¶è¿½è¸ªè¿™äº›æ¦‚å¿µå¯¹æ¨¡å‹å†³ç­–çš„è´¡çŒ®ï¼Œä»è€Œæä¾›æ›´å¿ å®ã€æ›´æ˜“äºç†è§£çš„è§£é‡Šã€‚æ ¸å¿ƒæ€æƒ³æ˜¯è®©æ¨¡å‹æœ¬èº«å°±å…·å¤‡å¯è§£é‡Šæ€§ï¼Œè€Œä¸æ˜¯é€šè¿‡äº‹åçš„æ–¹å¼è¿›è¡Œè§£é‡Šã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šFaCTæ¨¡å‹çš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ¨¡å—ï¼š1) æ¦‚å¿µå­¦ä¹ æ¨¡å—ï¼šè´Ÿè´£å­¦ä¹ è·¨ç±»åˆ«çš„å…±äº«æ¦‚å¿µè¡¨ç¤ºã€‚2) æ¦‚å¿µè¿½è¸ªæ¨¡å—ï¼šç”¨äºè¿½è¸ªæ¯ä¸ªæ¦‚å¿µå¯¹æ¨¡å‹è¾“å‡ºlogitçš„è´¡çŒ®ã€‚3) è¾“å…¥å¯è§†åŒ–æ¨¡å—ï¼šå°†æ¦‚å¿µä¸è¾“å…¥å›¾åƒç›¸å…³è”ï¼Œå®ç°æ¦‚å¿µçš„å¯è§†åŒ–ã€‚4) æ¦‚å¿µä¸€è‡´æ€§è¯„ä¼°æ¨¡å—ï¼šåˆ©ç”¨åŸºç¡€æ¨¡å‹è¯„ä¼°æ¦‚å¿µçš„ä¸€è‡´æ€§ï¼Œæå‡ºC$^2$-ScoreæŒ‡æ ‡ã€‚æ•´ä¸ªæµç¨‹æ˜¯ä»è¾“å…¥å›¾åƒå¼€å§‹ï¼Œç»è¿‡æ¦‚å¿µå­¦ä¹ æ¨¡å—æå–æ¦‚å¿µï¼Œç„¶åé€šè¿‡æ¦‚å¿µè¿½è¸ªæ¨¡å—åˆ†ææ¦‚å¿µå¯¹æœ€ç»ˆå†³ç­–çš„å½±å“ï¼Œæœ€åé€šè¿‡å¯è§†åŒ–æ¨¡å—å’Œä¸€è‡´æ€§è¯„ä¼°æ¨¡å—å¯¹æ¦‚å¿µè¿›è¡ŒéªŒè¯å’Œè¯„ä¼°ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†æ¨¡å‹å†…åœ¨çš„ã€æœºåˆ¶æ€§çš„æ¦‚å¿µè§£é‡Šæ–¹æ³•ï¼Œå³FaCTã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒFaCTä¸å†ä¾èµ–äºäº‹åçš„è§£é‡Šï¼Œè€Œæ˜¯å°†å¯è§£é‡Šæ€§èå…¥åˆ°æ¨¡å‹çš„è®¾è®¡ä¸­ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¦‚å¿µä¸€è‡´æ€§æŒ‡æ ‡C$^2$-Scoreï¼Œè¯¥æŒ‡æ ‡åˆ©ç”¨åŸºç¡€æ¨¡å‹æ¥è¯„ä¼°æ¦‚å¿µçš„ä¸€è‡´æ€§ï¼Œä¸ºæ¦‚å¿µè§£é‡Šçš„è¯„ä¼°æä¾›äº†ä¸€ç§æ–°çš„æ€è·¯ã€‚

**å…³é”®è®¾è®¡**ï¼šFaCTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) å…±äº«æ¦‚å¿µè¡¨ç¤ºï¼šæ¨¡å‹å­¦ä¹ çš„ä¸æ˜¯ç±»åˆ«ç‰¹å®šçš„æ¦‚å¿µï¼Œè€Œæ˜¯è·¨ç±»åˆ«çš„å…±äº«æ¦‚å¿µï¼Œè¿™ä½¿å¾—æ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°æ³›åŒ–ï¼Œå¹¶æä¾›æ›´é€šç”¨çš„è§£é‡Šã€‚2) æ¦‚å¿µè¿½è¸ªæœºåˆ¶ï¼šé€šè¿‡è®¾è®¡ç‰¹å®šçš„ç½‘ç»œç»“æ„å’ŒæŸå¤±å‡½æ•°ï¼Œæ¨¡å‹èƒ½å¤Ÿè¿½è¸ªæ¯ä¸ªæ¦‚å¿µå¯¹æœ€ç»ˆå†³ç­–çš„è´¡çŒ®ï¼Œä»è€Œæä¾›æ›´ç»†ç²’åº¦çš„è§£é‡Šã€‚3) C$^2$-Scoreï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„CLIPæ¨¡å‹æ¥è¯„ä¼°æ¦‚å¿µçš„ä¸€è‡´æ€§ï¼Œå…·ä½“æ¥è¯´ï¼Œå°†æå–çš„æ¦‚å¿µè¡¨ç¤ºå’Œå¯¹åº”çš„æ–‡æœ¬æè¿°è¾“å…¥åˆ°CLIPæ¨¡å‹ä¸­ï¼Œè®¡ç®—å®ƒä»¬çš„ç›¸ä¼¼åº¦ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼Œè¯´æ˜æ¦‚å¿µçš„ä¸€è‡´æ€§è¶Šå¥½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒFaCTæ¨¡å‹åœ¨ImageNetæ•°æ®é›†ä¸Šå–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼ŒåŒæ—¶åœ¨æ¦‚å¿µä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œç”¨æˆ·è®¤ä¸ºFaCTæ¨¡å‹æä¾›çš„æ¦‚å¿µè§£é‡Šæ›´æ˜“äºç†è§£ã€‚C$^2$-ScoreæŒ‡æ ‡çš„è¯„ä¼°ç»“æœä¹Ÿè¡¨æ˜ï¼ŒFaCTæ¨¡å‹å­¦ä¹ åˆ°çš„æ¦‚å¿µå…·æœ‰æ›´é«˜çš„ä¸€è‡´æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå¯¹ç¥ç»ç½‘ç»œå†³ç­–è¿‡ç¨‹è¿›è¡Œè§£é‡Šå’Œè°ƒè¯•ï¼Œæé«˜æ¨¡å‹çš„å¯ä¿¡åº¦å’Œé€æ˜åº¦ã€‚åœ¨åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ç­‰é«˜é£é™©é¢†åŸŸï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿå¸®åŠ©äººä»¬ç†è§£æ¨¡å‹çš„å†³ç­–ä¾æ®ï¼Œä»è€Œæ›´å¥½åœ°ä¿¡ä»»å’Œä½¿ç”¨AIç³»ç»Ÿã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºå‘ç°æ¨¡å‹ä¸­çš„åå·®å’Œæ¼æ´ï¼Œä¿ƒè¿›AIç³»ç»Ÿçš„å…¬å¹³æ€§å’Œå®‰å…¨æ€§ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep networks have shown remarkable performance across a wide range of tasks, yet getting a global concept-level understanding of how they function remains a key challenge. Many post-hoc concept-based approaches have been introduced to understand their workings, yet they are not always faithful to the model. Further, they make restrictive assumptions on the concepts a model learns, such as class-specificity, small spatial extent, or alignment to human expectations. In this work, we put emphasis on the faithfulness of such concept-based explanations and propose a new model with model-inherent mechanistic concept-explanations. Our concepts are shared across classes and, from any layer, their contribution to the logit and their input-visualization can be faithfully traced. We also leverage foundation models to propose a new concept-consistency metric, C$^2$-Score, that can be used to evaluate concept-based methods. We show that, compared to prior work, our concepts are quantitatively more consistent and users find our concepts to be more interpretable, all while retaining competitive ImageNet performance.

