---
layout: default
title: Test-Time Anchoring for Discrete Diffusion Posterior Sampling
---

# Test-Time Anchoring for Discrete Diffusion Posterior Sampling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.02291" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.02291v1</a>
  <a href="https://arxiv.org/pdf/2510.02291.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.02291v1" onclick="toggleFavorite(this, '2510.02291v1', 'Test-Time Anchoring for Discrete Diffusion Posterior Sampling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Litu Rout, Andreas Lugmayr, Yasamin Jafarian, Srivatsan Varadharajan, Constantine Caramanis, Sanjay Shakkottai, Ira Kemelmacher-Shlizerman

**åˆ†ç±»**: cs.LG, cs.CV, stat.ML

**å‘å¸ƒæ—¥æœŸ**: 2025-10-02

**å¤‡æ³¨**: Preprint

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAnchored Posterior Sampling (APS)ï¼Œç”¨äºç¦»æ•£æ‰©æ•£åéªŒé‡‡æ ·ï¼Œè§£å†³é€†é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ç¦»æ•£æ‰©æ•£æ¨¡å‹` `åéªŒé‡‡æ ·` `å›¾åƒé€†é—®é¢˜` `é‡åŒ–æœŸæœ›` `é”šå®šé‡æ©ç ` `å…è®­ç»ƒ` `å›¾åƒæ¢å¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç¦»æ•£æ‰©æ•£åéªŒé‡‡æ ·æ–¹æ³•é¢ä¸´ç¨€ç–ä¿¡å·ã€é€‚ç”¨æ€§å—é™å’Œç»´åº¦ç¾éš¾ç­‰æŒ‘æˆ˜ã€‚
2. æå‡ºAnchored Posterior Sampling (APS)ï¼Œåˆ©ç”¨é‡åŒ–æœŸæœ›è¿›è¡Œæ¢¯åº¦å¼•å¯¼ï¼Œå¹¶é‡‡ç”¨é”šå®šé‡æ©ç è¿›è¡Œè‡ªé€‚åº”è§£ç ã€‚
3. APSåœ¨å›¾åƒé€†é—®é¢˜ä¸Šå–å¾—äº†SOTAæ€§èƒ½ï¼Œå¹¶åœ¨å…è®­ç»ƒé£æ ¼åŒ–å’Œæ–‡æœ¬å¼•å¯¼ç¼–è¾‘ä¸­å±•ç°äº†ä¼˜åŠ¿ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡ç ”ç©¶äº†ä½¿ç”¨é¢„è®­ç»ƒç¦»æ•£æ‰©æ•£åŸºç¡€æ¨¡å‹è¿›è¡ŒåéªŒé‡‡æ ·çš„é—®é¢˜ï¼Œæ—¨åœ¨ä»å¸¦å™ªå£°çš„æµ‹é‡æ•°æ®ä¸­æ¢å¤å›¾åƒï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒç‰¹å®šä»»åŠ¡çš„æ¨¡å‹ã€‚è™½ç„¶æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆå»ºæ¨¡æ–¹é¢å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å¤§å¤šæ•°è¿›å±•ä¾èµ–äºè¿ç»­é«˜æ–¯æ‰©æ•£ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¦»æ•£æ‰©æ•£ä¸ºè”åˆå»ºæ¨¡åˆ†ç±»æ•°æ®ï¼ˆå¦‚æ–‡æœ¬å’Œå›¾åƒï¼‰æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¡†æ¶ã€‚é™¤äº†ç»Ÿä¸€æ€§ä¹‹å¤–ï¼Œç¦»æ•£æ‰©æ•£è¿˜æä¾›æ›´å¿«çš„æ¨ç†ã€æ›´ç²¾ç»†çš„æ§åˆ¶å’Œæœ‰åŸåˆ™çš„å…è®­ç»ƒè´å¶æ–¯æ¨ç†ï¼Œä½¿å…¶ç‰¹åˆ«é€‚åˆåéªŒé‡‡æ ·ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ç¦»æ•£æ‰©æ•£åéªŒé‡‡æ ·æ–¹æ³•é¢ä¸´ä¸¥å³»æŒ‘æˆ˜ï¼šæ— å¯¼æ•°å¼•å¯¼äº§ç”Ÿç¨€ç–ä¿¡å·ï¼Œè¿ç»­æ¾å¼›é™åˆ¶äº†é€‚ç”¨æ€§ï¼Œå¹¶ä¸”åˆ†è£‚å‰å¸ƒæ–¯é‡‡æ ·å™¨é­å—ç»´åº¦ç¾éš¾ã€‚ä¸ºäº†å…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬ä¸ºæ©ç æ‰©æ•£åŸºç¡€æ¨¡å‹å¼•å…¥äº†Anchored Posterior Sampling (APS)ï¼Œå®ƒå»ºç«‹åœ¨ä¸¤ä¸ªå…³é”®åˆ›æ–°ä¹‹ä¸Šâ€”â€”ç¦»æ•£åµŒå…¥ç©ºé—´ä¸­ç”¨äºç±»æ¢¯åº¦å¼•å¯¼çš„é‡åŒ–æœŸæœ›ï¼Œä»¥åŠç”¨äºè‡ªé€‚åº”è§£ç çš„é”šå®šé‡æ©ç ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ ‡å‡†åŸºå‡†ä¸Šçš„çº¿æ€§å’Œéçº¿æ€§é€†é—®é¢˜ä¸­ï¼Œå®ç°äº†ç¦»æ•£æ‰©æ•£é‡‡æ ·å™¨ä¸­çš„æœ€å…ˆè¿›æ€§èƒ½ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº†æˆ‘ä»¬çš„æ–¹æ³•åœ¨å…è®­ç»ƒé£æ ¼åŒ–å’Œæ–‡æœ¬å¼•å¯¼ç¼–è¾‘ä¸­çš„ä¼˜åŠ¿ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ç¦»æ•£æ‰©æ•£æ¨¡å‹åœ¨åéªŒé‡‡æ ·ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒé€†é—®é¢˜ä¸­ï¼Œå¦‚ä½•ä»å™ªå£°æµ‹é‡ä¸­æ¢å¤å›¾åƒã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚æ— å¯¼æ•°å¼•å¯¼ã€è¿ç»­æ¾å¼›å’Œåˆ†è£‚å‰å¸ƒæ–¯é‡‡æ ·å™¨ï¼Œå­˜åœ¨ä¿¡å·ç¨€ç–ã€é€‚ç”¨æ€§å—é™å’Œç»´åº¦ç¾éš¾ç­‰é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨é‡åŒ–æœŸæœ›æ¥è¿‘ä¼¼æ¢¯åº¦ï¼Œä»è€Œåœ¨ç¦»æ•£åµŒå…¥ç©ºé—´ä¸­æä¾›æ›´æœ‰æ•ˆçš„å¼•å¯¼ä¿¡å·ã€‚åŒæ—¶ï¼Œé€šè¿‡é”šå®šé‡æ©ç ç­–ç•¥ï¼Œå®ç°è‡ªé€‚åº”çš„è§£ç è¿‡ç¨‹ï¼Œå…‹æœä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å……åˆ†åˆ©ç”¨ç¦»æ•£æ‰©æ•£æ¨¡å‹çš„ä¼˜åŠ¿ï¼Œå®ç°æ›´ç²¾ç¡®ã€æ›´é«˜æ•ˆçš„åéªŒé‡‡æ ·ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šAPSæ–¹æ³•ä¸»è¦åŒ…å«ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šé‡åŒ–æœŸæœ›æ¨¡å—å’Œé”šå®šé‡æ©ç æ¨¡å—ã€‚é‡åŒ–æœŸæœ›æ¨¡å—ç”¨äºåœ¨ç¦»æ•£åµŒå…¥ç©ºé—´ä¸­è®¡ç®—ç±»æ¢¯åº¦å¼•å¯¼ï¼Œä¸ºæ‰©æ•£è¿‡ç¨‹æä¾›æ–¹å‘ã€‚é”šå®šé‡æ©ç æ¨¡å—åˆ™æ ¹æ®å½“å‰çŠ¶æ€è‡ªé€‚åº”åœ°è°ƒæ•´æ©ç åŒºåŸŸï¼Œä»è€Œå®ç°æ›´ç²¾ç»†çš„è§£ç è¿‡ç¨‹ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬ï¼šé¦–å…ˆï¼Œå¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ©ç å¤„ç†ï¼›ç„¶åï¼Œé€šè¿‡æ‰©æ•£è¿‡ç¨‹é€æ­¥æ·»åŠ å™ªå£°ï¼›æ¥ç€ï¼Œåˆ©ç”¨é‡åŒ–æœŸæœ›å’Œé”šå®šé‡æ©ç è¿›è¡ŒåéªŒé‡‡æ ·ï¼Œé€æ­¥æ¢å¤å›¾åƒã€‚

**å…³é”®åˆ›æ–°**ï¼šAPSçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ä½¿ç”¨é‡åŒ–æœŸæœ›æ¥è¿‘ä¼¼æ¢¯åº¦ï¼Œå…‹æœäº†ç¦»æ•£ç©ºé—´ä¸­æ¢¯åº¦è®¡ç®—çš„éš¾é¢˜ï¼Œæä¾›äº†æ›´æœ‰æ•ˆçš„å¼•å¯¼ä¿¡å·ã€‚2) å¼•å…¥é”šå®šé‡æ©ç ç­–ç•¥ï¼Œå®ç°äº†è‡ªé€‚åº”çš„è§£ç è¿‡ç¨‹ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å›ºå®šæ©ç å¸¦æ¥çš„å±€é™æ€§ã€‚è¿™äº›åˆ›æ–°ä½¿å¾—APSèƒ½å¤Ÿåœ¨ç¦»æ•£æ‰©æ•£æ¨¡å‹ä¸­å®ç°æ›´ç²¾ç¡®ã€æ›´é«˜æ•ˆçš„åéªŒé‡‡æ ·ã€‚

**å…³é”®è®¾è®¡**ï¼šé‡åŒ–æœŸæœ›æ¨¡å—é€šè¿‡è®¡ç®—ç¦»æ•£åµŒå…¥ç©ºé—´ä¸­ç›¸é‚»çŠ¶æ€çš„æœŸæœ›å€¼ï¼Œæ¥è¿‘ä¼¼æ¢¯åº¦æ–¹å‘ã€‚é”šå®šé‡æ©ç æ¨¡å—åˆ™æ ¹æ®å½“å‰çŠ¶æ€çš„ç½®ä¿¡åº¦ï¼Œè‡ªé€‚åº”åœ°è°ƒæ•´æ©ç åŒºåŸŸçš„å¤§å°å’Œä½ç½®ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„å–å†³äºæ‰€ä½¿ç”¨çš„ç¦»æ•£æ‰©æ•£åŸºç¡€æ¨¡å‹ã€‚æŸå¤±å‡½æ•°é€šå¸¸åŒ…æ‹¬é‡æ„æŸå¤±å’Œæ­£åˆ™åŒ–é¡¹ï¼Œä»¥ä¿è¯æ¢å¤å›¾åƒçš„è´¨é‡å’Œä¸€è‡´æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

APSåœ¨å›¾åƒé€†é—®é¢˜ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†SOTAæ°´å¹³ã€‚ä¸ç°æœ‰ç¦»æ•£æ‰©æ•£é‡‡æ ·å™¨ç›¸æ¯”ï¼ŒAPSåœ¨æ¢å¤å›¾åƒçš„è´¨é‡å’Œæ•ˆç‡æ–¹é¢å‡æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼ŒAPSåœ¨å…è®­ç»ƒé£æ ¼åŒ–å’Œæ–‡æœ¬å¼•å¯¼ç¼–è¾‘ç­‰ä»»åŠ¡ä¸­ä¹Ÿå±•ç°äº†è‰¯å¥½çš„æ•ˆæœã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå›¾åƒä¿®å¤ã€å›¾åƒå»å™ªã€å›¾åƒè¶…åˆ†è¾¨ç‡ç­‰å›¾åƒé€†é—®é¢˜ï¼Œä»¥åŠé£æ ¼è¿ç§»ã€å›¾åƒç¼–è¾‘ç­‰ç”Ÿæˆä»»åŠ¡ã€‚å…¶å…è®­ç»ƒçš„ç‰¹æ€§ä½¿å…¶åœ¨èµ„æºå—é™çš„åœºæ™¯ä¸‹å…·æœ‰é‡è¦ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°å…¶ä»–ç¦»æ•£æ•°æ®é¢†åŸŸï¼Œå¦‚æ–‡æœ¬ç”Ÿæˆã€è¯­éŸ³åˆæˆç­‰ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We study the problem of posterior sampling using pretrained discrete diffusion foundation models, aiming to recover images from noisy measurements without retraining task-specific models. While diffusion models have achieved remarkable success in generative modeling, most advances rely on continuous Gaussian diffusion. In contrast, discrete diffusion offers a unified framework for jointly modeling categorical data such as text and images. Beyond unification, discrete diffusion provides faster inference, finer control, and principled training-free Bayesian inference, making it particularly well-suited for posterior sampling. However, existing approaches to discrete diffusion posterior sampling face severe challenges: derivative-free guidance yields sparse signals, continuous relaxations limit applicability, and split Gibbs samplers suffer from the curse of dimensionality. To overcome these limitations, we introduce Anchored Posterior Sampling (APS) for masked diffusion foundation models, built on two key innovations -- quantized expectation for gradient-like guidance in discrete embedding space, and anchored remasking for adaptive decoding. Our approach achieves state-of-the-art performance among discrete diffusion samplers across linear and nonlinear inverse problems on the standard benchmarks. We further demonstrate the benefits of our approach in training-free stylization and text-guided editing.

