---
layout: default
title: Complexity-aware fine-tuning
---

# Complexity-aware fine-tuning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21220" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21220v2</a>
  <a href="https://arxiv.org/pdf/2506.21220.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21220v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21220v2', 'Complexity-aware fine-tuning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Andrey Goncharov, Daniil Vyazhev, Petr Sychev, Edvard Khalafyan, Alexey Zaytsev

**åˆ†ç±»**: cs.LG, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-10-11)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¤æ‚æ€§æ„ŸçŸ¥å¾®è°ƒæ–¹æ³•ä»¥æå‡å¤§è¯­è¨€æ¨¡å‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤æ‚æ€§æ„ŸçŸ¥` `å¾®è°ƒæ–¹æ³•` `å¤§è¯­è¨€æ¨¡å‹` `è’¸é¦è®­ç»ƒ` `æ•°æ®æ•ˆç‡` `è‡ªç„¶è¯­è¨€å¤„ç†` `ç›‘ç£å¾®è°ƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¾®è°ƒæ–¹æ³•åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶æ•ˆç‡ä½ä¸‹ï¼Œé€šå¸¸éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤æ‚æ€§æ„ŸçŸ¥çš„å¾®è°ƒæ–¹æ³•ï¼Œä»…å¯¹å¤æ‚æ•°æ®è¿›è¡Œæ¨ç†ï¼Œä»è€Œæé«˜å¾®è°ƒæ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡å’Œæ•°æ®ä½¿ç”¨æ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„SFTå’Œè’¸é¦æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

é€šç”¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€šå¸¸é€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ¥æå‡ç‰¹å®šé¢†åŸŸçš„æ€§èƒ½ã€‚é€šè¿‡å¯¹æ›´å¤§æ¨¡å‹çš„æ€ç»´é“¾è¿›è¡Œè’¸é¦ï¼Œå¯ä»¥è·å¾—æ›´å¥½çš„ç»“æœï¼Œä½†ä»£ä»·æ˜¯éœ€è¦å¤§é‡æ˜‚è´µçš„è°ƒç”¨å’Œæ•°æ®ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„å¾®è°ƒæ–°æ–¹æ¡ˆï¼Œä»…å¯¹é€šè¿‡ç†µè¯†åˆ«çš„å¤æ‚æ•°æ®è¿›è¡Œæ¨ç†ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åœ¨ä¸¤ä¸ªå°å‹å¼€æ”¾æ¨¡å‹ï¼ˆçº¦3Bå‚æ•°ï¼‰ä¸Šï¼Œé€šè¿‡å•ä¸ªæ ‡è®°ç­”æ¡ˆç†µå°†è®­ç»ƒæ•°æ®åˆ†ä¸ºå¤æ‚æ€§ç±»åˆ«ï¼Œåˆ©ç”¨SFTå’Œè’¸é¦å¯¹å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œç»“æœæ˜¾ç¤ºæˆ‘ä»¬çš„ç®¡é“æ˜¾è‘—ä¼˜äºæ ‡å‡†SFTæ–¹æ³•ï¼ˆå¹³å‡å‡†ç¡®ç‡0.58å¯¹æ¯”0.45ï¼‰ï¼Œå¹¶ä¸”åœ¨ä½¿ç”¨81%æ›´å°‘æ•°æ®çš„æƒ…å†µä¸‹è¶…è¶Šäº†è’¸é¦æ–¹æ³•ï¼ˆå¹³å‡å‡†ç¡®ç‡0.58å¯¹æ¯”0.56ï¼‰ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¾®è°ƒæ–¹æ³•åœ¨å¤„ç†å¤æ‚æ•°æ®æ—¶çš„ä½æ•ˆç‡é—®é¢˜ï¼Œä¼ ç»Ÿæ–¹æ³•å¾€å¾€éœ€è¦å¤§é‡æ•°æ®å’Œè®¡ç®—èµ„æºï¼Œå¯¼è‡´æˆæœ¬é«˜æ˜‚ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ç†µæ¥è¯†åˆ«æ•°æ®çš„å¤æ‚æ€§ï¼Œä»…å¯¹å¤æ‚æ•°æ®è¿›è¡Œæ¨ç†ï¼Œä»è€Œå‡å°‘ä¸å¿…è¦çš„è®¡ç®—å’Œæ•°æ®ä½¿ç”¨ï¼Œæé«˜å¾®è°ƒæ•ˆç‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å¤æ‚æ€§åˆ†ç±»ã€ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰å’Œè’¸é¦ä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œé€šè¿‡å•ä¸ªæ ‡è®°ç­”æ¡ˆç†µå°†è®­ç»ƒæ•°æ®åˆ†ä¸ºä¸åŒå¤æ‚æ€§ç±»åˆ«ï¼Œç„¶åå¯¹å¤æ‚æ•°æ®è¿›è¡Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥å¤æ‚æ€§æ„ŸçŸ¥çš„å¾®è°ƒç­–ç•¥ï¼Œæ˜¾è‘—å‡å°‘äº†æ•°æ®ä½¿ç”¨é‡ï¼ŒåŒæ—¶æå‡äº†æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„å…¨é¢å¾®è°ƒæ–¹æ³•æœ¬è´¨ä¸Šä¸åŒï¼Œåè€…å¯¹æ‰€æœ‰æ•°æ®å‡è¿›è¡Œæ¨ç†ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œä½¿ç”¨äº†ç†µä½œä¸ºå¤æ‚æ€§æŒ‡æ ‡ï¼ŒæŸå¤±å‡½æ•°è®¾è®¡ä¸Šç»“åˆäº†SFTå’Œè’¸é¦çš„ä¼˜åŠ¿ï¼Œç¡®ä¿åœ¨è¾ƒå°‘æ•°æ®ä¸‹ä»èƒ½ä¿æŒé«˜æ•ˆçš„å­¦ä¹ æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæå‡ºçš„æ–¹æ³•åœ¨å¹³å‡å‡†ç¡®ç‡ä¸Šè¾¾åˆ°0.58ï¼Œæ˜¾è‘—é«˜äºæ ‡å‡†SFTçš„0.45å’Œè’¸é¦çš„0.56ï¼ŒåŒæ—¶ä½¿ç”¨çš„æ•°æ®é‡å‡å°‘äº†81%ã€‚è¿™ä¸€æå‡è¡¨æ˜äº†å¤æ‚æ€§æ„ŸçŸ¥å¾®è°ƒçš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€å¯¹è¯ç³»ç»Ÿå’ŒçŸ¥è¯†é—®ç­”ç­‰ã€‚é€šè¿‡æé«˜å¾®è°ƒæ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨èµ„æºæœ‰é™çš„æƒ…å†µä¸‹ï¼Œå¿«é€Ÿé€‚åº”ç‰¹å®šé¢†åŸŸçš„éœ€æ±‚ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> General-purpose Large Language Models (LLMs) are frequently fine-tuned through supervised fine-tuning (SFT) to enhance performance in specific domains. Better results can be achieved by distilling the chain-of-thought of a larger model at the cost of numerous expensive calls and a much greater amount of data. We propose a novel blueprint for efficient fine-tuning that uses reasoning only for complex data identified by entropy. Specifically, across two small open models ($~3B$) we split the training data into complexity categories by a single token answer entropy (ROC AUC $0.73$), fine-tune large language models (LLMs) via SFT and distillation, and show that our pipeline significantly outperforms the standard SFT approach ($0.58$ vs $0.45$ average accuracy) and outperforms the distillation approach ($0.58$ vs $0.56$ average accuracy) while using $81%$ less data.

