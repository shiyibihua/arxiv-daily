---
layout: default
title: Large Language Model Agent for Modular Task Execution in Drug Discovery
---

# Large Language Model Agent for Modular Task Execution in Drug Discovery

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.02925" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2507.02925v3</a>
  <a href="https://arxiv.org/pdf/2507.02925.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.02925v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.02925v3', 'Large Language Model Agent for Modular Task Execution in Drug Discovery')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Janghoon Ock, Radheesh Sharma Meda, Srivathsan Badrinarayanan, Neha S. Aluru, Achuth Chandrasekhar, Amir Barati Farimani

**åˆ†ç±»**: cs.LG, cs.CL, q-bio.BM

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-12-12)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ¨¡å—åŒ–æ¡†æ¶ä»¥ä¼˜åŒ–è¯ç‰©å‘ç°ä¸­çš„å…³é”®ä»»åŠ¡**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¯ç‰©å‘ç°` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ¨¡å—åŒ–æ¡†æ¶` `ç”Ÿç‰©åŒ»å­¦æ•°æ®` `åˆ†å­ç”Ÿæˆ` `å±æ€§é¢„æµ‹` `3Dç»“æ„ç”Ÿæˆ` `è‡ªåŠ¨åŒ–`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è¯ç‰©å‘ç°æ–¹æ³•åœ¨è‡ªåŠ¨åŒ–å’Œä»»åŠ¡æ•´åˆæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œä¿¡æ¯å­¤å²›ã€‚
2. è®ºæ–‡æå‡ºçš„æ¡†æ¶ç»“åˆLLMæ¨ç†ä¸é¢†åŸŸå·¥å…·ï¼Œå®ç°äº†å¤šç§è¯ç‰©å‘ç°ä»»åŠ¡çš„è‡ªåŠ¨åŒ–ï¼Œæå‡äº†æ•´ä½“æ•ˆç‡ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œç»è¿‡ä¸¤è½®ç²¾ç‚¼ï¼Œç¬¦åˆQED > 0.6çš„åˆ†å­æ•°é‡ä»34å¢åŠ åˆ°55ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„ä¼˜åŒ–æ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨¡å—åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åŒ–å’Œç®€åŒ–æ—©æœŸè®¡ç®—è¯ç‰©å‘ç°æµç¨‹ä¸­çš„å…³é”®ä»»åŠ¡ã€‚é€šè¿‡å°†LLMæ¨ç†ä¸ç‰¹å®šé¢†åŸŸå·¥å…·ç›¸ç»“åˆï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿè¿›è¡Œç”Ÿç‰©åŒ»å­¦æ•°æ®æ£€ç´¢ã€æ–‡çŒ®åŸºç¡€çš„é—®é¢˜å›ç­”ã€åˆ†å­ç”Ÿæˆã€å¤šå±æ€§é¢„æµ‹ã€å±æ€§æ„ŸçŸ¥çš„åˆ†å­ç²¾ç‚¼ä»¥åŠ3Dè›‹ç™½-é…ä½“ç»“æ„ç”Ÿæˆã€‚è¯¥ä»£ç†èƒ½å¤Ÿè‡ªä¸»æ£€ç´¢ç›¸å…³çš„ç”Ÿç‰©åˆ†å­ä¿¡æ¯ï¼Œå¹¶åœ¨æœºåˆ¶æ€§é—®é¢˜å›ç­”ä¸­è¡¨ç°å‡ºæ¯”æ ‡å‡†LLMsæ›´é«˜çš„ä¸Šä¸‹æ–‡å‡†ç¡®æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å­ç­›é€‰ã€ä¼˜å…ˆçº§æ’åºå’Œç»“æ„è¯„ä¼°æ–¹é¢æœ‰æ•ˆæ”¯æŒè¯ç‰©å‘ç°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è¯ç‰©å‘ç°è¿‡ç¨‹ä¸­ä»»åŠ¡è‡ªåŠ¨åŒ–ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•å¾€å¾€æ— æ³•æœ‰æ•ˆæ•´åˆå¤šç§ä»»åŠ¡ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œä¿¡æ¯å­¤ç«‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œå°†å¤§å‹è¯­è¨€æ¨¡å‹ä¸é¢†åŸŸç‰¹å®šå·¥å…·ç»“åˆï¼Œè‡ªåŠ¨åŒ–æ‰§è¡Œè¯ç‰©å‘ç°ä¸­çš„å…³é”®ä»»åŠ¡ï¼Œä»è€Œæé«˜æ•´ä½“å·¥ä½œæ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬å¤šä¸ªä¸»è¦æ¨¡å—ï¼Œå¦‚ç”Ÿç‰©åŒ»å­¦æ•°æ®æ£€ç´¢ã€æ–‡çŒ®åŸºç¡€çš„é—®é¢˜å›ç­”ã€åˆ†å­ç”Ÿæˆã€å¤šå±æ€§é¢„æµ‹ã€åˆ†å­ç²¾ç‚¼å’Œ3Dè›‹ç™½-é…ä½“ç»“æ„ç”Ÿæˆã€‚æ¯ä¸ªæ¨¡å—ååŒå·¥ä½œï¼Œå½¢æˆä¸€ä¸ªå®Œæ•´çš„è¯ç‰©å‘ç°æµç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†LLMæ¨ç†ä¸é¢†åŸŸå·¥å…·çš„ç»“åˆï¼Œæ˜¾è‘—æå‡äº†ç”Ÿç‰©åˆ†å­ä¿¡æ¯æ£€ç´¢å’Œé—®é¢˜å›ç­”çš„å‡†ç¡®æ€§ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚çš„ç”Ÿç‰©åŒ»å­¦é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šæ¡†æ¶ä¸­ä½¿ç”¨äº†Boltz-2ç”Ÿæˆ3Dè›‹ç™½-é…ä½“å¤åˆç‰©ï¼Œå¹¶å¿«é€Ÿä¼°ç®—å€™é€‰åŒ–åˆç‰©çš„ç»“åˆäº²å’ŒåŠ›ï¼Œæ­¤å¤–ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åˆ†å­ç”Ÿæˆå’Œå±æ€§é¢„æµ‹çš„æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¸¤è½®åˆ†å­ç²¾ç‚¼ä¸­ï¼Œç¬¦åˆQED > 0.6çš„åˆ†å­æ•°é‡ä»34å¢åŠ åˆ°55ï¼Œä¸”ç¬¦åˆGhoseè¿‡æ»¤å™¨çš„åˆ†å­æ•°é‡ä»32å¢åŠ åˆ°55ï¼Œè¡¨æ˜è¯¥æ¡†æ¶åœ¨åˆ†å­ç­›é€‰å’Œä¼˜åŒ–æ–¹é¢å…·æœ‰æ˜¾è‘—æå‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è¯ç‰©å‘ç°ã€åˆ†å­è®¾è®¡å’Œç”Ÿç‰©åŒ»å­¦ç ”ç©¶ã€‚é€šè¿‡è‡ªåŠ¨åŒ–å…³é”®ä»»åŠ¡ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿå¤§å¹…æé«˜è¯ç‰©ç ”å‘çš„æ•ˆç‡ï¼Œé™ä½æˆæœ¬ï¼Œå¹¶ä¸ºæ–°è¯çš„å¿«é€Ÿç­›é€‰å’Œä¼˜åŒ–æä¾›æ”¯æŒï¼Œæœªæ¥å¯èƒ½åœ¨åˆ¶è¯è¡Œä¸šäº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present a modular framework powered by large language models (LLMs) that automates and streamlines key tasks across the early-stage computational drug discovery pipeline. By combining LLM reasoning with domain-specific tools, the framework performs biomedical data retrieval, literature-grounded question answering via retrieval-augmented generation, molecular generation, multi-property prediction, property-aware molecular refinement, and 3D protein-ligand structure generation. The agent autonomously retrieved relevant biomolecular information, including FASTA sequences, SMILES representations, and literature, and answered mechanistic questions with improved contextual accuracy compared to standard LLMs. It then generated chemically diverse seed molecules and predicted 75 properties, including ADMET-related and general physicochemical descriptors, which guided iterative molecular refinement. Across two refinement rounds, the number of molecules with QED > 0.6 increased from 34 to 55. The number of molecules satisfying empirical drug-likeness filters also rose; for example, compliance with the Ghose filter increased from 32 to 55 within a pool of 100 molecules. The framework also employed Boltz-2 to generate 3D protein-ligand complexes and provide rapid binding affinity estimates for candidate compounds. These results demonstrate that the approach effectively supports molecular screening, prioritization, and structure evaluation. Its modular design enables flexible integration of evolving tools and models, providing a scalable foundation for AI-assisted therapeutic discovery.

