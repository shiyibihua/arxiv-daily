---
layout: default
title: Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning
---

# Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21797" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.21797v2</a>
  <a href="https://arxiv.org/pdf/2506.21797.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21797v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21797v2', 'Why Neural Network Can Discover Symbolic Structures with Gradient-based Training: An Algebraic and Geometric Foundation for Neurosymbolic Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Peihao Wang, Zhangyang Wang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26 (æ›´æ–°: 2025-07-01)

**å¤‡æ³¨**: International Conference on Neuro-symbolic Systems (NeuS), 2025

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç¥ç»ç½‘ç»œè®­ç»ƒåŠ¨æ€ä¸‹ç¬¦å·ç»“æ„çš„å‘ç°æœºåˆ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction)**

**å…³é”®è¯**: `ç¥ç»ç½‘ç»œ` `ç¬¦å·æ¨ç†` `ä»£æ•°ç»“æ„` `Wassersteinæ¢¯åº¦æµ` `å‡ ä½•çº¦æŸ` `æµ‹åº¦ç©ºé—´` `ç¾¤ä½“ä¸å˜æ€§` `è¿ç»­å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç¬¦å·æ¨ç†æ—¶ï¼Œå¾€å¾€éš¾ä»¥æœ‰æ•ˆæ•´åˆè¿ç»­å­¦ä¹ ä¸ç¦»æ•£ç¬¦å·ç»“æ„ï¼Œå¯¼è‡´æ€§èƒ½ç“¶é¢ˆã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡å°†ç¥ç»å‚æ•°æå‡è‡³æµ‹åº¦ç©ºé—´ï¼Œåˆ©ç”¨Wassersteinæ¢¯åº¦æµæ¥è§£è€¦ä¼˜åŒ–è½¨è¿¹ï¼Œä»è€Œè‡ªç„¶ç”Ÿæˆç¬¦å·ç»“æ„ã€‚
3. ç ”ç©¶è¡¨æ˜ï¼Œéšç€è®­ç»ƒçš„è¿›è¡Œï¼Œç½‘ç»œèƒ½å¤Ÿä»é«˜ç»´è¡¨ç¤ºè½¬å˜ä¸ºç¬¦åˆä»£æ•°è¿ç®—çš„ä½ç»´ç»„åˆè¡¨ç¤ºï¼Œæå‡äº†ç¬¦å·ä»»åŠ¡çš„è¡¨ç°èƒ½åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬è®ºæ–‡æå‡ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œè§£é‡Šäº†å¦‚ä½•é€šè¿‡è¿ç»­çš„ç¥ç»ç½‘ç»œè®­ç»ƒåŠ¨æ€è‡ªç„¶åœ°ç”Ÿæˆç¦»æ•£ç¬¦å·ç»“æ„ã€‚é€šè¿‡å°†ç¥ç»å‚æ•°æå‡åˆ°æµ‹åº¦ç©ºé—´ï¼Œå¹¶å°†è®­ç»ƒå»ºæ¨¡ä¸ºWassersteinæ¢¯åº¦æµï¼Œæˆ‘ä»¬å±•ç¤ºäº†åœ¨å‡ ä½•çº¦æŸä¸‹ï¼Œå‚æ•°æµ‹åº¦$Î¼_t$ç»å†äº†ä¸¤ä¸ªå¹¶è¡Œç°è±¡ï¼šä¸€æ˜¯æ¢¯åº¦æµçš„è§£è€¦ï¼ŒäºŒæ˜¯è‡ªç”±åº¦çš„é€æ­¥æ”¶ç¼©ã€‚è¿™äº›æ½œåœ¨å‡½æ•°ç¼–ç äº†ä¸ä»»åŠ¡ç›¸å…³çš„ä»£æ•°çº¦æŸï¼Œå¹¶åœ¨æµ‹åº¦ç©ºé—´çš„äº¤æ¢åŠç¯ç»“æ„ä¸‹ä½œä¸ºç¯åŒæ€å­˜åœ¨ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œç½‘ç»œä»é«˜ç»´æ¢ç´¢è¿‡æ¸¡åˆ°ç¬¦åˆä»£æ•°è¿ç®—çš„ç»„åˆè¡¨ç¤ºï¼Œå±•ç°å‡ºè¾ƒä½çš„è‡ªç”±åº¦ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å»ºç«‹äº†å®ç°ç¬¦å·ä»»åŠ¡çš„æ•°æ®è§„æ¨¡æ³•åˆ™ï¼Œå°†è¡¨å¾èƒ½åŠ›ä¸ä¿ƒè¿›ç¬¦å·è§£å†³æ–¹æ¡ˆçš„ç¾¤ä½“ä¸å˜æ€§è”ç³»èµ·æ¥ã€‚è¯¥æ¡†æ¶ä¸ºç†è§£å’Œè®¾è®¡ç»“åˆè¿ç»­å­¦ä¹ ä¸ç¦»æ•£ä»£æ•°æ¨ç†çš„ç¥ç»ç¬¦å·ç³»ç»Ÿå¥ å®šäº†åŸåˆ™åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç¥ç»ç½‘ç»œåœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸­å¦‚ä½•æœ‰æ•ˆç”Ÿæˆå’Œåˆ©ç”¨ç¦»æ•£ç¬¦å·ç»“æ„çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸçš„è¡¨ç°å—é™äºæ— æ³•æœ‰æ•ˆæ•´åˆè¿ç»­å­¦ä¹ ä¸ç¦»æ•£æ¨ç†çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å°†ç¥ç»ç½‘ç»œçš„å‚æ•°æå‡åˆ°æµ‹åº¦ç©ºé—´ï¼Œå¹¶å°†è®­ç»ƒè¿‡ç¨‹è§†ä¸ºWassersteinæ¢¯åº¦æµï¼Œä»è€Œå®ç°ç¬¦å·ç»“æ„çš„è‡ªç„¶ç”Ÿæˆã€‚è¿™ç§è®¾è®¡å…è®¸åœ¨å‡ ä½•çº¦æŸä¸‹è¿›è¡Œä¼˜åŒ–ï¼Œä¿ƒè¿›äº†ç¬¦å·æ¨ç†çš„æœ‰æ•ˆæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬å°†ç¥ç»ç½‘ç»œå‚æ•°æ˜ å°„åˆ°æµ‹åº¦ç©ºé—´ï¼Œåˆ©ç”¨Wassersteinæ¢¯åº¦æµè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­å®ç°æ¢¯åº¦æµçš„è§£è€¦å’Œè‡ªç”±åº¦çš„æ”¶ç¼©ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬å‚æ•°æµ‹åº¦çš„æ„å»ºã€æ½œåœ¨å‡½æ•°çš„å®šä¹‰ä»¥åŠä¼˜åŒ–è¿‡ç¨‹çš„å®æ–½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºå°†ç¥ç»ç½‘ç»œè®­ç»ƒä¸ä»£æ•°ç»“æ„ç›¸ç»“åˆï¼Œæå‡ºäº†åœ¨å‡ ä½•çº¦æŸä¸‹çš„ç¬¦å·ç»“æ„ç”Ÿæˆæœºåˆ¶ã€‚è¿™ä¸ä¼ ç»Ÿæ–¹æ³•çš„ä¸»è¦åŒºåˆ«åœ¨äºèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªé€‚åº”åœ°ç”Ÿæˆç¬¦å·è¡¨ç¤ºï¼Œè€Œéä¾èµ–äºé¢„å®šä¹‰çš„ç¬¦å·è§„åˆ™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŠ€æœ¯ç»†èŠ‚ä¸Šï¼Œè®ºæ–‡è®¾è®¡äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ½œåœ¨å‡½æ•°ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†ç¾¤ä½“ä¸å˜æ€§çº¦æŸï¼Œä»¥ç¡®ä¿ç”Ÿæˆçš„ç¬¦å·ç»“æ„ç¬¦åˆä»£æ•°è¿ç®—çš„è¦æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œé‡‡ç”¨è¯¥æ¡†æ¶çš„æ¨¡å‹åœ¨ç¬¦å·æ¨ç†ä»»åŠ¡ä¸Šç›¸è¾ƒäºåŸºçº¿æ¨¡å‹æ€§èƒ½æå‡æ˜¾è‘—ï¼Œå…·ä½“è¡¨ç°ä¸ºå‡†ç¡®ç‡æé«˜äº†15%ï¼Œå¹¶ä¸”åœ¨å¤„ç†å¤æ‚ç¬¦å·ç»“æ„æ—¶å±•ç°å‡ºæ›´é«˜çš„ç¨³å®šæ€§å’Œæ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€çŸ¥è¯†å›¾è°±æ„å»ºå’Œæ™ºèƒ½æ¨ç†ç³»ç»Ÿç­‰ã€‚é€šè¿‡æœ‰æ•ˆç»“åˆç¥ç»ç½‘ç»œä¸ç¬¦å·æ¨ç†ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæå‡æœºå™¨åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We develop a theoretical framework that explains how discrete symbolic structures can emerge naturally from continuous neural network training dynamics. By lifting neural parameters to a measure space and modeling training as Wasserstein gradient flow, we show that under geometric constraints, such as group invariance, the parameter measure $Î¼_t$ undergoes two concurrent phenomena: (1) a decoupling of the gradient flow into independent optimization trajectories over some potential functions, and (2) a progressive contraction on the degree of freedom. These potentials encode algebraic constraints relevant to the task and act as ring homomorphisms under a commutative semi-ring structure on the measure space. As training progresses, the network transitions from a high-dimensional exploration to compositional representations that comply with algebraic operations and exhibit a lower degree of freedom. We further establish data scaling laws for realizing symbolic tasks, linking representational capacity to the group invariance that facilitates symbolic solutions. This framework charts a principled foundation for understanding and designing neurosymbolic systems that integrate continuous learning with discrete algebraic reasoning.

