---
layout: default
title: Interpretable Representation Learning for Additive Rule Ensembles
---

# Interpretable Representation Learning for Additive Rule Ensembles

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.20927" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.20927v1</a>
  <a href="https://arxiv.org/pdf/2506.20927.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.20927v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.20927v1', 'Interpretable Representation Learning for Additive Rule Ensembles')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shahrzad Behzadimanesh, Pierre Le Bodic, Geoffrey I. Webb, Mario Boley

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-06-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¯è§£é‡Šçš„è¡¨ç¤ºå­¦ä¹ æ–¹æ³•ä»¥æ”¹è¿›åŠ æ³•è§„åˆ™é›†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¯è§£é‡Šæ€§` `è§„åˆ™é›†` `æœºå™¨å­¦ä¹ ` `ç¨€ç–å˜æ¢` `é€»è¾‘å›å½’` `æ¨¡å‹ä¼˜åŒ–` `å†³ç­–åŒºåŸŸ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŠ æ³•è§„åˆ™é›†æ¨¡å‹åœ¨ç¼ºä¹ç‹¬ç«‹ç‰¹å¾æ—¶ï¼Œéš¾ä»¥ä¿æŒé«˜å‡†ç¡®ç‡ï¼Œå¯¼è‡´æ¨¡å‹å¯è§£é‡Šæ€§ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„ç¨€ç–çº¿æ€§å˜æ¢ï¼Œæ‰©å±•ä¼ ç»Ÿè§„åˆ™é›†ï¼Œä½¿å¾—å†³ç­–åŒºåŸŸä¸ºå…·æœ‰æ–œé¢çš„å¤šé¢ä½“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ–¹æ³•åœ¨åä¸ªåŸºå‡†æ•°æ®é›†ä¸Šä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸æ¯”ï¼Œæ¨¡å‹å¤æ‚åº¦æ˜¾è‘—é™ä½ï¼Œä¸”æµ‹è¯•é£é™©ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°å‹åŠ æ³•è§„åˆ™é›†æä¾›äº†å¯è§£é‡Šçš„é¢„æµ‹æ¨¡å‹ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–äºå•ä¸€è¾“å…¥å˜é‡çš„ç®€å•é˜ˆå€¼å‘½é¢˜ï¼Œå¯¼è‡´å†³ç­–åŒºåŸŸä¸ºè½´å¹³è¡Œå¤šé¢ä½“ã€‚æ­¤æ–¹æ³•åœ¨ç¼ºä¹ç‹¬ç«‹ç‰¹å¾æ—¶ï¼Œæ¨¡å‹çš„å¯è§£é‡Šæ€§ä¼šå› è§„åˆ™æ•°é‡å’Œå¤æ‚æ€§å¢åŠ è€Œä¸‹é™ã€‚æœ¬æ–‡é€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„ç¨€ç–çº¿æ€§å˜æ¢çš„é€»è¾‘å‘½é¢˜ï¼Œæ‰©å±•äº†ç»å…¸è§„åˆ™é›†ï¼Œå½¢æˆå…·æœ‰æ–œé¢å†³ç­–åŒºåŸŸçš„å¤šé¢ä½“ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºé€»è¾‘å›å½’çš„è¿­ä»£åŠ æƒä¼˜åŒ–å­¦ä¹ æ–¹æ³•ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæœ‰æ•ˆæ„å»ºè§„åˆ™é›†ï¼Œæ¨¡å‹å¤æ‚åº¦æ˜¾è‘—é™ä½ï¼ŒåŒæ—¶ä¿æŒä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸åŒçš„æµ‹è¯•é£é™©ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä¼ ç»ŸåŠ æ³•è§„åˆ™é›†åœ¨ç¼ºä¹ç‹¬ç«‹ç‰¹å¾æ—¶ï¼Œæ¨¡å‹å¯è§£é‡Šæ€§ä¸å‡†ç¡®æ€§ä¹‹é—´çš„çŸ›ç›¾ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–äºç®€å•çš„é˜ˆå€¼å‘½é¢˜ï¼Œå¯¼è‡´æ¨¡å‹å¤æ‚æ€§å¢åŠ æ—¶å¯è§£é‡Šæ€§ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å¯å­¦ä¹ çš„ç¨€ç–çº¿æ€§å˜æ¢ï¼Œå½¢æˆæ–°çš„é€»è¾‘å‘½é¢˜ï¼Œä½¿å¾—å†³ç­–åŒºåŸŸèƒ½å¤Ÿè¡¨ç¤ºä¸ºå…·æœ‰æ–œé¢çš„å¤šé¢ä½“ï¼Œä»è€Œæé«˜æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€é€»è¾‘å‘½é¢˜æ„å»ºã€ç¨€ç–æƒé‡å­¦ä¹ å’Œæ¨¡å‹ä¼˜åŒ–å››ä¸ªä¸»è¦æ¨¡å—ã€‚é‡‡ç”¨è¿­ä»£åŠ æƒçš„é€»è¾‘å›å½’æ–¹æ³•è¿›è¡Œè§„åˆ™å­¦ä¹ ï¼Œç¡®ä¿æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå¼•å…¥äº†ç¨€ç–çº¿æ€§å˜æ¢çš„é€»è¾‘å‘½é¢˜ï¼Œä½¿å¾—å†³ç­–åŒºåŸŸä¸å†å±€é™äºè½´å¹³è¡Œå¤šé¢ä½“ï¼Œä»è€Œæå‡äº†æ¨¡å‹çš„çµæ´»æ€§å’Œå¯è§£é‡Šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†è¿­ä»£åŠ æƒçš„é€»è¾‘å›å½’æŸå¤±å‡½æ•°ï¼Œç»“åˆç¨€ç–æ€§çº¦æŸï¼Œç¡®ä¿å­¦ä¹ åˆ°çš„è§„åˆ™æ—¢ç®€æ´åˆæœ‰æ•ˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨åä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ„å»ºçš„è§„åˆ™é›†åœ¨æµ‹è¯•é£é™©ä¸Šä¸æœ€å…ˆè¿›æ–¹æ³•ç›¸å½“ï¼Œä½†æ¨¡å‹å¤æ‚åº¦æ˜¾è‘—é™ä½ï¼Œæå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—è¯Šæ–­ã€é‡‘èé£é™©è¯„ä¼°å’Œæ™ºèƒ½åˆ¶é€ ç­‰éœ€è¦å¯è§£é‡Šæ€§çš„æœºå™¨å­¦ä¹ æ¨¡å‹çš„åœºæ™¯ã€‚é€šè¿‡æä¾›æ›´é«˜çš„å¯è§£é‡Šæ€§ï¼Œå†³ç­–è€…å¯ä»¥æ›´å¥½åœ°ç†è§£æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œä»è€Œå¢å¼ºä¿¡ä»»åº¦å’Œå¯æ“ä½œæ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åœ¨æ›´å¤šé¢†åŸŸæ¨å¹¿åº”ç”¨ï¼Œæ¨åŠ¨å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Small additive ensembles of symbolic rules offer interpretable prediction models. Traditionally, these ensembles use rule conditions based on conjunctions of simple threshold propositions $x \geq t$ on a single input variable $x$ and threshold $t$, resulting geometrically in axis-parallel polytopes as decision regions. While this form ensures a high degree of interpretability for individual rules and can be learned efficiently using the gradient boosting approach, it relies on having access to a curated set of expressive and ideally independent input features so that a small ensemble of axis-parallel regions can describe the target variable well. Absent such features, reaching sufficient accuracy requires increasing the number and complexity of individual rules, which diminishes the interpretability of the model. Here, we extend classical rule ensembles by introducing logical propositions with learnable sparse linear transformations of input variables, i.e., propositions of the form $\mathbf{x}^\mathrm{T}\mathbf{w} \geq t$, where $\mathbf{w}$ is a learnable sparse weight vector, enabling decision regions as general polytopes with oblique faces. We propose a learning method using sequential greedy optimization based on an iteratively reweighted formulation of logistic regression. Experimental results demonstrate that the proposed method efficiently constructs rule ensembles with the same test risk as state-of-the-art methods while significantly reducing model complexity across ten benchmark datasets.

