---
layout: default
title: SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning
---

# SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.21355" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.21355v2</a>
  <a href="https://arxiv.org/pdf/2506.21355.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.21355v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.21355v2', 'SMMILE: An Expert-Driven Benchmark for Multimodal Medical In-Context Learning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Melanie Rieff, Maya Varma, Ossian Rabow, Subathra Adithan, Julie Kim, Ken Chang, Hannah Lee, Nidhi Rohatgi, Christian Bluethgen, Mohamed S. Muneer, Jean-Benoit Delbrouck, Michael Moor

**ÂàÜÁ±ª**: cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-26 (Êõ¥Êñ∞: 2025-10-29)

**Â§áÊ≥®**: NeurIPS 2025 (Datasets & Benchmarks Track)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫SMMILEÂü∫ÂáÜ‰ª•Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂåªÂ≠¶‰ªªÂä°Â≠¶‰π†ÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `ÂåªÂ≠¶ÂΩ±ÂÉè` `‰∏ä‰∏ãÊñáÂ≠¶‰π†` `Â§ßËØ≠Ë®ÄÊ®°Âûã` `ÂåªÂ≠¶‰ªªÂä°` `Âü∫ÂáÜËØÑ‰º∞` `‰∏ìÂÆ∂È©±Âä®`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÂ≠¶‰ªªÂä°ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÉΩÂäõÂ∞ö‰∏çÊòéÁ°ÆÔºå‰∏îÂ≠òÂú®ÊÄßËÉΩ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇ
2. SMMILEÂü∫ÂáÜÈÄöËøá‰∏ìÂÆ∂Á≠ñÂàíÁöÑÂ§öÊ®°ÊÄÅÊü•ËØ¢ÂíåÁ§∫‰æãÔºåÊèê‰æõ‰∫Ü‰∏Ä‰∏™Á≥ªÁªüÂåñÁöÑËØÑ‰º∞Ê°ÜÊû∂ÔºåÊó®Âú®ÊèêÂçáÂåªÂ≠¶‰ªªÂä°ÁöÑÂ≠¶‰π†ÊïàÊûú„ÄÇ
3. ÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåÂΩìÂâçÂ§ßÂ§öÊï∞Ê®°ÂûãÂú®Â§öÊ®°ÊÄÅICLËÉΩÂäõ‰∏äË°®Áé∞‰∏≠Á≠âÂÅè‰∏ãÔºå‰∏îÂ≠òÂú®ÂØπÊó†ÂÖ≥Á§∫‰æãÁöÑÊïèÊÑüÊÄßÂíåËøëÊúüÂÅèËßÅ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Â∞ΩÁÆ°Â§öÊ®°ÊÄÅ‰∏ä‰∏ãÊñáÂ≠¶‰π†ÔºàICLÔºâÂú®ÂåªÂ≠¶È¢ÜÂüüÂÖ∑ÊúâÈáçË¶ÅÊΩúÂäõÔºå‰ΩÜ‰ªçÊú™ÂæóÂà∞ÂÖÖÂàÜÊé¢Á¥¢„ÄÇ‰∏¥Â∫äÂåªÁîüÂ∏∏Â∏∏ÈúÄË¶Å‰ªéÊúâÈôêÁöÑÁ§∫‰æã‰∏≠ÈÄÇÂ∫îÂ§öÊ†∑ÂåñÁöÑ‰∏ì‰∏ö‰ªªÂä°„ÄÇÊú¨Êñá‰ªãÁªç‰∫ÜSMMILEÔºåËøôÊòØÈ¶ñ‰∏™‰∏ìÂÆ∂È©±Âä®ÁöÑÂ§öÊ®°ÊÄÅICLÂü∫ÂáÜÔºåÊ∂µÁõñ111‰∏™ÈóÆÈ¢òÂíå517‰∏™ÈóÆÁ≠îÂõæÂÉè‰∏âÂÖÉÁªÑÔºåÊ∂âÂèä6‰∏™ÂåªÂ≠¶‰∏ì‰∏öÂíå13ÁßçÊàêÂÉèÊ®°Âºè„ÄÇÈÄöËøáÂØπ15‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÁöÑËØÑ‰º∞ÔºåÂèëÁé∞Â§ßÂ§öÊï∞Ê®°ÂûãÂú®ÂåªÂ≠¶‰ªªÂä°‰∏≠ÁöÑÂ§öÊ®°ÊÄÅICLËÉΩÂäõËæÉÂº±ÔºåICL‰ªÖÂú®SMMILE‰∏äÂπ≥ÂùáÊèêÂçá8%„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÂåªÂ≠¶‰ªªÂä°‰∏≠ÁöÑ‰∏ä‰∏ãÊñáÂ≠¶‰π†ËÉΩÂäõ‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÂ§öÊ†∑ÂåñÂåªÂ≠¶‰ªªÂä°Êó∂ÔºåÂæÄÂæÄÁº∫‰πèÊúâÊïàÁöÑÁ§∫‰æãÂíåËØÑ‰º∞Ê†áÂáÜÔºåÂØºËá¥Ê®°ÂûãÊÄßËÉΩ‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫SMMILEÂü∫ÂáÜÔºåÈÄöËøáÂåªÂ≠¶‰∏ìÂÆ∂Á≠ñÂàíÁöÑÂ§öÊ®°ÊÄÅÊü•ËØ¢ÂíåÁ§∫‰æãÔºåÁ≥ªÁªüÂåñÂú∞ËØÑ‰º∞ÂíåÊèêÂçáÂ§öÊ®°ÊÄÅICLËÉΩÂäõ„ÄÇËøôÁßçËÆæËÆ°Êó®Âú®Êèê‰æõÊõ¥ÂÖ∑ÈíàÂØπÊÄßÁöÑ‰ªªÂä°Á§∫‰æãÔºå‰ª•Â∏ÆÂä©Ê®°ÂûãÊõ¥Â•ΩÂú∞ÈÄÇÂ∫îÂ§çÊùÇÁöÑÂåªÂ≠¶Âú∫ÊôØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöSMMILEÂü∫ÂáÜÂåÖÂê´111‰∏™ÈóÆÈ¢òÔºåÊ∂µÁõñ6‰∏™ÂåªÂ≠¶‰∏ì‰∏öÂíå13ÁßçÊàêÂÉèÊ®°Âºè„ÄÇÊØè‰∏™ÈóÆÈ¢òÈÉΩÈÖçÊúâÂ§öÊ®°ÊÄÅÊü•ËØ¢ÂíåÁ§∫‰æãÔºåÂΩ¢Êàê517‰∏™ÈóÆÁ≠îÂõæÂÉè‰∏âÂÖÉÁªÑ„ÄÇSMMILE++ÊòØÂÖ∂Â¢ûÂº∫ÁâàÔºåÂåÖÂê´1038‰∏™ÊéíÂàóÁªÑÂêàÈóÆÈ¢ò„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöSMMILEÊòØÈ¶ñ‰∏™‰∏ìÂÆ∂È©±Âä®ÁöÑÂ§öÊ®°ÊÄÅICLÂü∫ÂáÜÔºåÂ°´Ë°•‰∫ÜÂΩìÂâçÂåªÂ≠¶‰ªªÂä°ËØÑ‰º∞ÁöÑÁ©∫ÁôΩ„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåSMMILEÊèê‰æõ‰∫ÜÊõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñáÁ§∫‰æãÔºåËÉΩÂ§üÊõ¥Â•ΩÂú∞ÂèçÊò†‰∏¥Â∫äÂÆûÈôÖÈúÄÊ±Ç„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÆûÈ™å‰∏≠ÔºåÊ®°ÂûãÁöÑËØÑ‰º∞‰∏ç‰ªÖÂÖ≥Ê≥®ÂáÜÁ°ÆÊÄßÔºåËøòËÄÉËôë‰∫ÜÁ§∫‰æãÁöÑÁõ∏ÂÖ≥ÊÄßÂíåÊéíÂàóÈ°∫Â∫è„ÄÇÁ†îÁ©∂ÂèëÁé∞ÔºåÂç≥‰ΩøÊòØÂçï‰∏™Êó†ÂÖ≥Á§∫‰æã‰πüÂèØËÉΩÂØºËá¥ÊÄßËÉΩ‰∏ãÈôçÔºåËÄåÁõ∏ÂÖ≥Á§∫‰æãÁöÑÈ°∫Â∫èÂØπÊ®°ÂûãË°®Áé∞ÊúâÊòæËëóÂΩ±Âìç„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°Âú®ËÆ∫Êñá‰∏≠ËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúÊòæÁ§∫Ôºå15‰∏™Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®SMMILEÂü∫ÂáÜ‰∏äÁöÑÂπ≥ÂùáÊèêÂçá‰ªÖ‰∏∫8%ÔºåËÄåÂú®SMMILE++‰∏ä‰∏∫9.4%„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÂØπÊó†ÂÖ≥Á§∫‰æãÁöÑÊïèÊÑüÊÄßÂØºËá¥ÊÄßËÉΩ‰∏ãÈôçÈ´òËææ9.5%ÔºåËÄåÁõ∏ÂÖ≥Á§∫‰æãÁöÑÊéíÂàóÈ°∫Â∫èÂØπÊÄßËÉΩÊèêÂçáÂèØËææ71%„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

SMMILEÂü∫ÂáÜÁöÑÊèêÂá∫‰∏∫ÂåªÂ≠¶È¢ÜÂüüÁöÑÂ§öÊ®°ÊÄÅÂ≠¶‰π†Êèê‰æõ‰∫ÜÊñ∞ÁöÑËØÑ‰º∞Â∑•ÂÖ∑ÔºåËÉΩÂ§üÂ∏ÆÂä©Á†îÁ©∂‰∫∫ÂëòÂíå‰∏¥Â∫äÂåªÁîüÊõ¥Â•ΩÂú∞ÁêÜËß£ÂíåÂ∫îÁî®Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã„ÄÇÂÖ∂ÊΩúÂú®Â∫îÁî®ÂåÖÊã¨ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê„ÄÅ‰∏¥Â∫äÂÜ≥Á≠ñÊîØÊåÅÂíå‰∏™ÊÄßÂåñÂåªÁñóÁ≠âÔºåÊú™Êù•ÂèØËÉΩÊé®Âä®ÂåªÂ≠¶‰∫∫Â∑•Êô∫ËÉΩÁöÑÂèëÂ±ï‰∏éÂ∫îÁî®„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Multimodal in-context learning (ICL) remains underexplored despite significant potential for domains such as medicine. Clinicians routinely encounter diverse, specialized tasks requiring adaptation from limited examples, such as drawing insights from a few relevant prior cases or considering a constrained set of differential diagnoses. While multimodal large language models (MLLMs) have shown advances in medical visual question answering (VQA), their ability to learn multimodal tasks from context is largely unknown. We introduce SMMILE, the first expert-driven multimodal ICL benchmark for medical tasks. Eleven medical experts curated problems, each including a multimodal query and multimodal in-context examples as task demonstrations. SMMILE encompasses 111 problems (517 question-image-answer triplets) covering 6 medical specialties and 13 imaging modalities. We further introduce SMMILE++, an augmented variant with 1038 permuted problems. A comprehensive evaluation of 15 MLLMs demonstrates that most models exhibit moderate to poor multimodal ICL ability in medical tasks. In open-ended evaluations, ICL contributes only an 8% average improvement over zero-shot on SMMILE and 9.4% on SMMILE++. We observe a susceptibility for irrelevant in-context examples: even a single noisy or irrelevant example can degrade performance by up to 9.5%. Moreover, we observe that MLLMs are affected by a recency bias, where placing the most relevant example last can lead to substantial performance improvements of up to 71%. Our findings highlight critical limitations and biases in current MLLMs when learning multimodal medical tasks from context. SMMILE is available at https://smmile-benchmark.github.io.

