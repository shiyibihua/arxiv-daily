---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-08-14
---

# cs.LGï¼ˆ2025-08-14ï¼‰

ğŸ“Š å…± **4** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ğŸ”—1)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (2 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250810253v1-multi-agent-reinforcement-learning-for-adaptive-resource-orchestrati.html">Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters</a></td>
  <td>æå‡ºåŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„è‡ªé€‚åº”èµ„æºè°ƒåº¦æ–¹æ³•ä»¥åº”å¯¹äº‘åŸç”Ÿé›†ç¾¤çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">reward shaping</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.10253v1" data-paper-url="./papers/250810253v1-multi-agent-reinforcement-learning-for-adaptive-resource-orchestrati.html" onclick="toggleFavorite(this, '2508.10253v1', 'Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250810298v3-synbrain-enhancing-visual-to-fmri-synthesis-via-probabilistic-repres.html">SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning</a></td>
  <td>æå‡ºSynBrainä»¥è§£å†³è§†è§‰åˆºæ¿€ä¸è„‘å“åº”æ˜ å°„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.10298v3" data-paper-url="./papers/250810298v3-synbrain-enhancing-visual-to-fmri-synthesis-via-probabilistic-repres.html" onclick="toggleFavorite(this, '2508.10298v3', 'SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>3</td>
  <td><a href="./papers/250810315v2-a-vision-language-pre-training-model-guided-approach-for-mitigating-.html">A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning</a></td>
  <td>æå‡ºCLIP-Fedä»¥è§£å†³è”é‚¦å­¦ä¹ ä¸­çš„åé—¨æ”»å‡»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.10315v2" data-paper-url="./papers/250810315v2-a-vision-language-pre-training-model-guided-approach-for-mitigating-.html" onclick="toggleFavorite(this, '2508.10315v2', 'A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>4</td>
  <td><a href="./papers/250816620v1-strelay-a-universal-spatio-temporal-relaying-framework-for-location-.html">STRelay: A Universal Spatio-Temporal Relaying Framework for Location Prediction with Future Spatiotemporal Contexts</a></td>
  <td>æå‡ºSTRelayæ¡†æ¶ä»¥æå‡ä½ç½®é¢„æµ‹ç²¾åº¦</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.16620v1" data-paper-url="./papers/250816620v1-strelay-a-universal-spatio-temporal-relaying-framework-for-location-.html" onclick="toggleFavorite(this, '2508.16620v1', 'STRelay: A Universal Spatio-Temporal Relaying Framework for Location Prediction with Future Spatiotemporal Contexts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)