---
layout: default
title: A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning
---

# A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.10315" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.10315v2</a>
  <a href="https://arxiv.org/pdf/2508.10315.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.10315v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.10315v2', 'A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Keke Gai, Dongjue Wang, Jing Yu, Liehuang Zhu, Qi Wu

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-14 (æ›´æ–°: 2025-10-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCLIP-Fedä»¥è§£å†³è”é‚¦å­¦ä¹ ä¸­çš„åé—¨æ”»å‡»é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è”é‚¦å­¦ä¹ ` `åé—¨æ”»å‡»` `è§†è§‰-è¯­è¨€æ¨¡å‹` `é›¶æ ·æœ¬å­¦ä¹ ` `æ•°æ®å¢å¼º` `éšç§ä¿æŠ¤`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¼‚æ„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒä¸‹ï¼Œéš¾ä»¥æœ‰æ•ˆé˜²å¾¡åé—¨æ”»å‡»ï¼ŒåŒæ—¶åˆéœ€å…¼é¡¾éšç§ä¿æŠ¤ã€‚
2. æœ¬æ–‡æå‡ºçš„CLIP-Fedæ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œé›†æˆäº†é¢„èšåˆå’Œåèšåˆé˜²å¾¡ç­–ç•¥ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCLIP-Fedåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†æ”»å‡»æˆåŠŸç‡ï¼Œå¹¶æé«˜äº†ä¸»è¦ä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨è”é‚¦å­¦ä¹ ä¸­ï¼Œé’ˆå¯¹å¼‚æ„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒçš„åé—¨æ”»å‡»é˜²å¾¡é¢ä¸´æœ‰æ•ˆæ€§ä¸éšç§ä¿æŠ¤ä¹‹é—´çš„å¹³è¡¡æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºCLIP-Fedçš„æ¡†æ¶ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œå…‹æœäº†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰å¯¹é˜²å¾¡æ•ˆæœçš„é™åˆ¶ã€‚CLIP-Fedé€šè¿‡é›†æˆé¢„èšåˆå’Œåèšåˆé˜²å¾¡ç­–ç•¥ï¼Œç¡®ä¿äº†åé—¨æ ·æœ¬å¼•èµ·çš„ç±»åŸå‹åå·®è¢«æ¶ˆé™¤ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCLIP-Fedåœ¨CIFAR-10å’ŒCIFAR-10-LTæ•°æ®é›†ä¸Šåˆ†åˆ«å®ç°äº†æ”»å‡»æˆåŠŸç‡çš„å¹³å‡é™ä½2.03%å’Œ1.35%ï¼ŒåŒæ—¶æé«˜äº†ä¸»è¦ä»»åŠ¡çš„å‡†ç¡®ç‡7.92%å’Œ0.48%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è”é‚¦å­¦ä¹ ä¸­åé—¨æ”»å‡»é˜²å¾¡çš„æœ‰æ•ˆæ€§ä¸éšç§ä¿æŠ¤ä¹‹é—´çš„çŸ›ç›¾ã€‚ç°æœ‰æ–¹æ³•å¤šä¾èµ–äºåŒè´¨å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒæˆ–å¹²å‡€çš„æœåŠ¡å™¨æ•°æ®é›†ï¼Œé™åˆ¶äº†å…¶åœ¨å¼‚æ„ç¯å¢ƒä¸‹çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šCLIP-Fedæ¡†æ¶åˆ©ç”¨è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œé€šè¿‡å¯¹æŠ—åé—¨æ ·æœ¬å¼•èµ·çš„ç±»åŸå‹åå·®ï¼Œæå‡é˜²å¾¡æ•ˆæœã€‚è¯¥è®¾è®¡æ—¨åœ¨æ¶ˆé™¤è§¦å‘æ¨¡å¼ä¸ç›®æ ‡æ ‡ç­¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šCLIP-Fedçš„æ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®å¢å¼ºã€é¢„èšåˆå’Œåèšåˆé˜²å¾¡ç­–ç•¥ã€‚é¦–å…ˆï¼Œé€šè¿‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œé¢‘ç‡åˆ†ææ„å»ºå’Œå¢å¼ºæœåŠ¡å™¨æ•°æ®é›†ï¼Œç„¶ååº”ç”¨åŸå‹å¯¹æ¯”æŸå¤±å’ŒKullback-Leibleræ•£åº¦è¿›è¡Œæ¨¡å‹å¯¹é½ã€‚

**å…³é”®åˆ›æ–°**ï¼šCLIP-Fedçš„ä¸»è¦åˆ›æ–°åœ¨äºç»“åˆäº†è§†è§‰-è¯­è¨€æ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ä¸å¤šæ¨¡æ€æ•°æ®å¢å¼ºï¼Œå…‹æœäº†éç‹¬ç«‹åŒåˆ†å¸ƒå¯¹é˜²å¾¡æ•ˆæœçš„é™åˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒCLIP-Fedåœ¨é˜²å¾¡æ•ˆæœå’Œéšç§ä¿æŠ¤ä¸Šå®ç°äº†æ›´å¥½çš„å¹³è¡¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼Œé‡‡ç”¨äº†åŸå‹å¯¹æ¯”æŸå¤±å’ŒKullback-Leibleræ•£åº¦ï¼Œä»¥ç¡®ä¿åé—¨æ ·æœ¬å¯¹ç±»åŸå‹çš„å½±å“è¢«æœ‰æ•ˆæŠ‘åˆ¶ã€‚åŒæ—¶ï¼Œæ•°æ®å¢å¼ºè¿‡ç¨‹ä¸ä¾èµ–äºå®¢æˆ·ç«¯æ ·æœ¬ï¼Œå¢å¼ºäº†éšç§ä¿æŠ¤ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

CLIP-Fedåœ¨CIFAR-10å’ŒCIFAR-10-LTæ•°æ®é›†ä¸Šï¼Œåˆ†åˆ«å®ç°äº†æ”»å‡»æˆåŠŸç‡çš„å¹³å‡é™ä½2.03%å’Œ1.35%ï¼ŒåŒæ—¶æé«˜äº†ä¸»è¦ä»»åŠ¡çš„å‡†ç¡®ç‡7.92%å’Œ0.48%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒCLIP-Fedåœ¨é˜²å¾¡åé—¨æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å®‰å…¨çš„è”é‚¦å­¦ä¹ ç³»ç»Ÿï¼Œå°¤å…¶æ˜¯åœ¨åŒ»ç–—ã€é‡‘èç­‰å¯¹éšç§è¦æ±‚é«˜çš„è¡Œä¸šã€‚CLIP-Fedçš„é˜²å¾¡æœºåˆ¶èƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡åé—¨æ”»å‡»ï¼Œç¡®ä¿æ¨¡å‹çš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Defending backdoor attacks in Federated Learning (FL) under heterogeneous client data distributions encounters limitations balancing effectiveness and privacy-preserving, while most existing methods highly rely on the assumption of homogeneous client data distributions or the availability of a clean serve dataset. In this paper, we propose an FL backdoor defense framework, named CLIP-Fed, that utilizes the zero-shot learning capabilities of vision-language pre-training models. Our scheme overcomes the limitations of Non-IID imposed on defense effectiveness by integrating pre-aggregation and post-aggregation defense strategies. CLIP-Fed aligns the knowledge of the global model and CLIP on the augmented dataset using prototype contrastive loss and Kullback-Leibler divergence, so that class prototype deviations caused by backdoor samples are ensured and the correlation between trigger patterns and target labels is eliminated. In order to balance privacy-preserving and coverage enhancement of the dataset against diverse triggers, we further construct and augment the server dataset via using the multimodal large language model and frequency analysis without any client samples. Extensive experiments on representative datasets evidence the effectiveness of CLIP-Fed. Comparing to other existing methods, CLIP-Fed achieves an average reduction in Attack Success Rate, {\em i.e.}, 2.03\% on CIFAR-10 and 1.35\% on CIFAR-10-LT, while improving average Main Task Accuracy by 7.92\% and 0.48\%, respectively. Our codes are available at https://anonymous.4open.science/r/CLIP-Fed.

