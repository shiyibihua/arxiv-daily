---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-09-03
---

# cs.LGï¼ˆ2025-09-03ï¼‰

ğŸ“Š å…± **11** ç¯‡è®ºæ–‡
 | ğŸ”— **1** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ğŸ”—1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (6 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250903030v1-population-aware-online-mirror-descent-for-mean-field-games-with-com.html">Population-aware Online Mirror Descent for Mean-Field Games with Common Noise by Deep Reinforcement Learning</a></td>
  <td>æå‡ºåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„Population-aware Online Mirror Descentç®—æ³•ï¼Œè§£å†³å¸¦å…±åŒå™ªå£°çš„Mean-Field Gamesé—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03030v1" data-paper-url="./papers/250903030v1-population-aware-online-mirror-descent-for-mean-field-games-with-com.html" onclick="toggleFavorite(this, '2509.03030v1', 'Population-aware Online Mirror Descent for Mean-Field Games with Common Noise by Deep Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250903666v1-autogrid-ai-deep-reinforcement-learning-framework-for-autonomous-mic.html">AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management</a></td>
  <td>æå‡ºåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„å¾®ç”µç½‘è‡ªæ²»ç®¡ç†æ¡†æ¶ï¼Œä¼˜åŒ–èƒ½æºè°ƒåº¦ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">PPO</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03666v1" data-paper-url="./papers/250903666v1-autogrid-ai-deep-reinforcement-learning-framework-for-autonomous-mic.html" onclick="toggleFavorite(this, '2509.03666v1', 'AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250903682v1-a-comprehensive-review-of-multi-agent-reinforcement-learning-in-vide.html">A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games</a></td>
  <td>ç»¼è¿°å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ åœ¨è§†é¢‘æ¸¸æˆä¸­çš„åº”ç”¨ä¸æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03682v1" data-paper-url="./papers/250903682v1-a-comprehensive-review-of-multi-agent-reinforcement-learning-in-vide.html" onclick="toggleFavorite(this, '2509.03682v1', 'A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250903672v1-sharedrep-rlhf-a-shared-representation-approach-to-rlhf-with-diverse.html">SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences</a></td>
  <td>æå‡ºSharedRep-RLHFï¼Œåˆ©ç”¨å…±äº«è¡¨å¾æå‡RLHFåœ¨å¤šåå¥½åœºæ™¯ä¸‹çš„æ€§èƒ½</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">RLHF</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03672v1" data-paper-url="./papers/250903672v1-sharedrep-rlhf-a-shared-representation-approach-to-rlhf-with-diverse.html" onclick="toggleFavorite(this, '2509.03672v1', 'SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250902930v2-vendirl-a-framework-for-self-supervised-reinforcement-learning-of-di.html">VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills</a></td>
  <td>æå‡ºVendiRLæ¡†æ¶ä»¥è§£å†³è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ ä¸­çš„æŠ€èƒ½å¤šæ ·æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.02930v2" data-paper-url="./papers/250902930v2-vendirl-a-framework-for-self-supervised-reinforcement-learning-of-di.html" onclick="toggleFavorite(this, '2509.02930v2', 'VendiRL: A Framework for Self-Supervised Reinforcement Learning of Diversely Diverse Skills')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250910512v1-a-service-oriented-adaptive-hierarchical-incentive-mechanism-for-fed.html">A Service-Oriented Adaptive Hierarchical Incentive Mechanism for Federated Learning</a></td>
  <td>æå‡ºé¢å‘æœåŠ¡çš„è‡ªé€‚åº”åˆ†å±‚æ¿€åŠ±æœºåˆ¶ï¼Œè§£å†³è”é‚¦å­¦ä¹ ä¸­æ•°æ®åŒ®ä¹é—®é¢˜ã€‚</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.10512v1" data-paper-url="./papers/250910512v1-a-service-oriented-adaptive-hierarchical-incentive-mechanism-for-fed.html" onclick="toggleFavorite(this, '2509.10512v1', 'A Service-Oriented Adaptive Hierarchical Incentive Mechanism for Federated Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (5 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>7</td>
  <td><a href="./papers/250903477v1-robult-leveraging-redundancy-and-modality-specific-features-for-robu.html">Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning</a></td>
  <td>Robultï¼šåˆ©ç”¨å†—ä½™æ€§å’Œæ¨¡æ€ç‰¹å®šç‰¹å¾å®ç°é²æ£’çš„å¤šæ¨¡æ€å­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03477v1" data-paper-url="./papers/250903477v1-robult-leveraging-redundancy-and-modality-specific-features-for-robu.html" onclick="toggleFavorite(this, '2509.03477v1', 'Robult: Leveraging Redundancy and Modality Specific Features for Robust Multimodal Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250903695v1-hierarchical-federated-foundation-models-over-wireless-networks-for-.html">Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures</a></td>
  <td>æå‡ºå±‚æ¬¡åŒ–è”é‚¦åŸºç¡€æ¨¡å‹ä»¥è§£å†³å¤šæ¨¡æ€å¤šä»»åŠ¡æ™ºèƒ½é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03695v1" data-paper-url="./papers/250903695v1-hierarchical-federated-foundation-models-over-wireless-networks-for-.html" onclick="toggleFavorite(this, '2509.03695v1', 'Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250903643v2-cehr-xgpt-a-scalable-multi-task-foundation-model-for-electronic-heal.html">CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health Records</a></td>
  <td>CEHR-XGPTï¼šç”¨äºç”µå­ç—…å†çš„å¯æ‰©å±•å¤šä»»åŠ¡åŸºç¡€æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03643v2" data-paper-url="./papers/250903643v2-cehr-xgpt-a-scalable-multi-task-foundation-model-for-electronic-heal.html" onclick="toggleFavorite(this, '2509.03643v2', 'CEHR-XGPT: A Scalable Multi-Task Foundation Model for Electronic Health Records')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250903733v2-differentiable-entropy-regularization-a-complexity-aware-approach-fo.html">Differentiable Entropy Regularization: A Complexity-Aware Approach for Neural Optimization</a></td>
  <td>æå‡ºå¯å¾®ç†µæ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡é™ä½è¡¨å¾å¤æ‚åº¦æå‡ç¥ç»ç½‘ç»œæ•ˆç‡ä¸é²æ£’æ€§</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03733v2" data-paper-url="./papers/250903733v2-differentiable-entropy-regularization-a-complexity-aware-approach-fo.html" onclick="toggleFavorite(this, '2509.03733v2', 'Differentiable Entropy Regularization: A Complexity-Aware Approach for Neural Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250903505v2-limix-unleashing-structured-data-modeling-capability-for-generalist-.html">LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence</a></td>
  <td>LimiXï¼šé‡Šæ”¾ç»“æ„åŒ–æ•°æ®å»ºæ¨¡èƒ½åŠ›ï¼Œèµ‹èƒ½é€šç”¨æ™ºèƒ½</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2509.03505v2" data-paper-url="./papers/250903505v2-limix-unleashing-structured-data-modeling-capability-for-generalist-.html" onclick="toggleFavorite(this, '2509.03505v2', 'LimiX: Unleashing Structured-Data Modeling Capability for Generalist Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)