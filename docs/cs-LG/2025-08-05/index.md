---
layout: default
title: arXiv ä¸­æ–‡è¦ç‚¹æ±‡æ€» - cs.LG - 2025-08-05
---

# cs.LGï¼ˆ2025-08-05ï¼‰

ğŸ“Š å…± **31** ç¯‡è®ºæ–‡
 | ğŸ”— **3** ç¯‡æœ‰ä»£ç 


## ğŸ¯ å…´è¶£é¢†åŸŸå¯¼èˆª

<div class="interest-nav">
<a href="#æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture" class="interest-badge">æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (17)</a>
<a href="#æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models" class="interest-badge">æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (10 ğŸ”—3)</a>
<a href="#æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation" class="interest-badge">æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (3)</a>
<a href="#æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction" class="interest-badge">æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1)</a>
</div>

---


<h2 id="æ”¯æŸ±äºŒrlç®—æ³•ä¸æ¶æ„-rl-architecture">ğŸ”¬ æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture) (17 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>1</td>
  <td><a href="./papers/250804724v1-understanding-protein-function-with-a-multimodal-retrieval-augmented.html">Understanding protein function with a multimodal retrieval-augmented foundation model</a></td>
  <td>æå‡ºPoET-2ä»¥è§£å†³è›‹ç™½è´¨åŠŸèƒ½é¢„æµ‹çš„æŒ‘æˆ˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.04724v1" data-paper-url="./papers/250804724v1-understanding-protein-function-with-a-multimodal-retrieval-augmented.html" onclick="toggleFavorite(this, '2508.04724v1', 'Understanding protein function with a multimodal retrieval-augmented foundation model')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>2</td>
  <td><a href="./papers/250809155v1-a-rolling-stone-gathers-no-moss-adaptive-policy-optimization-for-sta.html">A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models</a></td>
  <td>æå‡ºAdaPOä»¥è§£å†³å¤§è§„æ¨¡å¤šæ¨¡æ€æ¨¡å‹è‡ªæˆ‘è¯„ä¼°é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.09155v1" data-paper-url="./papers/250809155v1-a-rolling-stone-gathers-no-moss-adaptive-policy-optimization-for-sta.html" onclick="toggleFavorite(this, '2508.09155v1', 'A Rolling Stone Gathers No Moss: Adaptive Policy Optimization for Stable Self-Evaluation in Large Multimodal Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>3</td>
  <td><a href="./papers/250803194v1-scaling-drl-for-decision-making-a-survey-on-data-network-and-trainin.html">Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies</a></td>
  <td>æå‡ºæ•°æ®ã€ç½‘ç»œä¸è®­ç»ƒé¢„ç®—ç­–ç•¥ä»¥æå‡æ·±åº¦å¼ºåŒ–å­¦ä¹ å†³ç­–èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">deep reinforcement learning</span> <span class="paper-tag">DRL</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03194v1" data-paper-url="./papers/250803194v1-scaling-drl-for-decision-making-a-survey-on-data-network-and-trainin.html" onclick="toggleFavorite(this, '2508.03194v1', 'Scaling DRL for Decision Making: A Survey on Data, Network, and Training Budget Strategies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>4</td>
  <td><a href="./papers/250803693v2-pac-apprenticeship-learning-with-bayesian-active-inverse-reinforceme.html">PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement Learning</a></td>
  <td>æå‡ºPAC-EIGä»¥è§£å†³ä¸»åŠ¨é€†å¼ºåŒ–å­¦ä¹ ä¸­çš„å¯é æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">inverse reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03693v2" data-paper-url="./papers/250803693v2-pac-apprenticeship-learning-with-bayesian-active-inverse-reinforceme.html" onclick="toggleFavorite(this, '2508.03693v2', 'PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>5</td>
  <td><a href="./papers/250803875v1-reinforcement-learning-for-target-zone-blood-glucose-control.html">Reinforcement Learning for Target Zone Blood Glucose Control</a></td>
  <td>æå‡ºå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³1å‹ç³–å°¿ç—…è¡€ç³–æ§åˆ¶é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">policy learning</span> <span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03875v1" data-paper-url="./papers/250803875v1-reinforcement-learning-for-target-zone-blood-glucose-control.html" onclick="toggleFavorite(this, '2508.03875v1', 'Reinforcement Learning for Target Zone Blood Glucose Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>6</td>
  <td><a href="./papers/250803501v2-training-long-context-multi-turn-software-engineering-agents-with-re.html">Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning</a></td>
  <td>æå‡ºå¼ºåŒ–å­¦ä¹ æ–¹æ³•ä»¥è§£å†³è½¯ä»¶å·¥ç¨‹ä¸­çš„å¤šè½®äº¤äº’é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03501v2" data-paper-url="./papers/250803501v2-training-long-context-multi-turn-software-engineering-agents-with-re.html" onclick="toggleFavorite(this, '2508.03501v2', 'Training Long-Context, Multi-Turn Software Engineering Agents with Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>7</td>
  <td><a href="./papers/250803158v1-rethinking-selectivity-in-state-space-models-a-minimal-predictive-su.html">Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach</a></td>
  <td>æå‡ºæœ€å°é¢„æµ‹å……åˆ†æ€§æ¨¡å‹ä»¥ä¼˜åŒ–çŠ¶æ€ç©ºé—´æ¨¡å‹çš„é€‰æ‹©æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">Mamba</span> <span class="paper-tag">SSM</span> <span class="paper-tag">state space model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03158v1" data-paper-url="./papers/250803158v1-rethinking-selectivity-in-state-space-models-a-minimal-predictive-su.html" onclick="toggleFavorite(this, '2508.03158v1', 'Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>8</td>
  <td><a href="./papers/250803649v1-cross-model-semantics-in-representation-learning.html">Cross-Model Semantics in Representation Learning</a></td>
  <td>æå‡ºç»“æ„çº¦æŸä»¥æå‡æ·±åº¦ç½‘ç»œè¡¨ç¤ºçš„è·¨æ¨¡å‹å…¼å®¹æ€§</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">distillation</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03649v1" data-paper-url="./papers/250803649v1-cross-model-semantics-in-representation-learning.html" onclick="toggleFavorite(this, '2508.03649v1', 'Cross-Model Semantics in Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>9</td>
  <td><a href="./papers/250803104v2-hitec-hierarchical-contrastive-learning-on-text-attributed-hypergrap.html">HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation</a></td>
  <td>æå‡ºHiTeCæ¡†æ¶ä»¥è§£å†³æ–‡æœ¬å±æ€§è¶…å›¾çš„å¯¹æ¯”å­¦ä¹ é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span> <span class="paper-tag">contrastive learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03104v2" data-paper-url="./papers/250803104v2-hitec-hierarchical-contrastive-learning-on-text-attributed-hypergrap.html" onclick="toggleFavorite(this, '2508.03104v2', 'HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>10</td>
  <td><a href="./papers/250803904v1-reinforcement-learning-in-mdps-with-information-ordered-policies.html">Reinforcement Learning in MDPs with Information-Ordered Policies</a></td>
  <td>æå‡ºåŸºäºä¿¡æ¯æœ‰åºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•ä»¥ä¼˜åŒ–MDPs</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03904v1" data-paper-url="./papers/250803904v1-reinforcement-learning-in-mdps-with-information-ordered-policies.html" onclick="toggleFavorite(this, '2508.03904v1', 'Reinforcement Learning in MDPs with Information-Ordered Policies')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>11</td>
  <td><a href="./papers/250803682v4-self-questioning-language-models.html">Self-Questioning Language Models</a></td>
  <td>æå‡ºè‡ªé—®è‡ªç­”è¯­è¨€æ¨¡å‹ä»¥æå‡æ¨ç†èƒ½åŠ›</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03682v4" data-paper-url="./papers/250803682v4-self-questioning-language-models.html" onclick="toggleFavorite(this, '2508.03682v4', 'Self-Questioning Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>12</td>
  <td><a href="./papers/250803509v1-sla-morl-sla-aware-multi-objective-reinforcement-learning-for-hpc-re.html">SLA-MORL: SLA-Aware Multi-Objective Reinforcement Learning for HPC Resource Optimization</a></td>
  <td>æå‡ºSLA-MORLä»¥è§£å†³äº‘ç¯å¢ƒä¸­èµ„æºä¼˜åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03509v1" data-paper-url="./papers/250803509v1-sla-morl-sla-aware-multi-objective-reinforcement-learning-for-hpc-re.html" onclick="toggleFavorite(this, '2508.03509v1', 'SLA-MORL: SLA-Aware Multi-Objective Reinforcement Learning for HPC Resource Optimization')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>13</td>
  <td><a href="./papers/250809156v1-physics-constrained-fine-tuning-of-flow-matching-models-for-generati.html">Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems</a></td>
  <td>æå‡ºç‰©ç†çº¦æŸå¾®è°ƒæµåŒ¹é…æ¨¡å‹ä»¥è§£å†³é€†é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">flow matching</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.09156v1" data-paper-url="./papers/250809156v1-physics-constrained-fine-tuning-of-flow-matching-models-for-generati.html" onclick="toggleFavorite(this, '2508.09156v1', 'Physics-Constrained Fine-Tuning of Flow-Matching Models for Generation and Inverse Problems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>14</td>
  <td><a href="./papers/250803108v1-pseudo-label-induced-subspace-representation-learning-for-robust-out.html">Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection</a></td>
  <td>æå‡ºä¼ªæ ‡ç­¾è¯±å¯¼å­ç©ºé—´è¡¨ç¤ºå­¦ä¹ ä»¥è§£å†³OODæ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">representation learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03108v1" data-paper-url="./papers/250803108v1-pseudo-label-induced-subspace-representation-learning-for-robust-out.html" onclick="toggleFavorite(this, '2508.03108v1', 'Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>15</td>
  <td><a href="./papers/250803058v1-vrpo-rethinking-value-modeling-for-robust-rl-training-under-noisy-su.html">VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision</a></td>
  <td>æå‡ºVRPOä»¥è§£å†³å™ªå£°ç›‘ç£ä¸‹çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">PPO</span> <span class="paper-tag">RLHF</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03058v1" data-paper-url="./papers/250803058v1-vrpo-rethinking-value-modeling-for-robust-rl-training-under-noisy-su.html" onclick="toggleFavorite(this, '2508.03058v1', 'VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>16</td>
  <td><a href="./papers/250803768v2-orvit-near-optimal-online-distributionally-robust-reinforcement-lear.html">ORVIT: Near-Optimal Online Distributionally Robust Reinforcement Learning</a></td>
  <td>æå‡ºåœ¨çº¿åˆ†å¸ƒé²æ£’å¼ºåŒ–å­¦ä¹ æ–¹æ³•ä»¥åº”å¯¹è®­ç»ƒä¸éƒ¨ç½²ç¯å¢ƒä¸åŒ¹é…é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03768v2" data-paper-url="./papers/250803768v2-orvit-near-optimal-online-distributionally-robust-reinforcement-lear.html" onclick="toggleFavorite(this, '2508.03768v2', 'ORVIT: Near-Optimal Online Distributionally Robust Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>17</td>
  <td><a href="./papers/250816581v1-increasing-interaction-fidelity-training-routines-for-biomechanical-.html">Increasing Interaction Fidelity: Training Routines for Biomechanical Models in HCI</a></td>
  <td>æå‡ºæ”¹è¿›è®­ç»ƒæ–¹æ¡ˆä»¥æå‡ç”Ÿç‰©åŠ›å­¦æ¨¡å‹åœ¨HCIä¸­çš„äº¤äº’ç²¾åº¦</td>
  <td class="tags-cell"><span class="paper-tag">reinforcement learning</span> <span class="paper-tag">curriculum learning</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.16581v1" data-paper-url="./papers/250816581v1-increasing-interaction-fidelity-training-routines-for-biomechanical-.html" onclick="toggleFavorite(this, '2508.16581v1', 'Increasing Interaction Fidelity: Training Routines for Biomechanical Models in HCI')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±ä¹å…·èº«å¤§æ¨¡å‹-embodied-foundation-models">ğŸ”¬ æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models) (10 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>18</td>
  <td><a href="./papers/250803785v1-soilnet-a-multimodal-multitask-model-for-hierarchical-classification.html">SoilNet: A Multimodal Multitask Model for Hierarchical Classification of Soil Horizons</a></td>
  <td>æå‡ºSoilNetä»¥è§£å†³åœŸå£¤å±‚æ¬¡åˆ†ç±»é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">foundation model</span> <span class="paper-tag">multimodal</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03785v1" data-paper-url="./papers/250803785v1-soilnet-a-multimodal-multitask-model-for-hierarchical-classification.html" onclick="toggleFavorite(this, '2508.03785v1', 'SoilNet: A Multimodal Multitask Model for Hierarchical Classification of Soil Horizons')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>19</td>
  <td><a href="./papers/250803159v2-cotox-chain-of-thought-based-molecular-toxicity-reasoning-and-predic.html">CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction</a></td>
  <td>æå‡ºCoToxæ¡†æ¶ä»¥è§£å†³è¯ç‰©æ¯’æ€§é¢„æµ‹çš„å¯è§£é‡Šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03159v2" data-paper-url="./papers/250803159v2-cotox-chain-of-thought-based-molecular-toxicity-reasoning-and-predic.html" onclick="toggleFavorite(this, '2508.03159v2', 'CoTox: Chain-of-Thought-Based Molecular Toxicity Reasoning and Prediction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>20</td>
  <td><a href="./papers/250803046v1-a-novel-multimodal-framework-for-early-detection-of-alzheimers-disea.html">A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning</a></td>
  <td>æå‡ºå¤šæ¨¡æ€æ¡†æ¶ä»¥è§£å†³é˜¿å°”èŒ¨æµ·é»˜ç—…æ—©æœŸæ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">multimodal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03046v1" data-paper-url="./papers/250803046v1-a-novel-multimodal-framework-for-early-detection-of-alzheimers-disea.html" onclick="toggleFavorite(this, '2508.03046v1', 'A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>21</td>
  <td><a href="./papers/250803556v2-vrprm-process-reward-modeling-via-visual-reasoning.html">VRPRM: Process Reward Modeling via Visual Reasoning</a></td>
  <td>æå‡ºVRPRMä»¥è§£å†³PRMåœ¨é•¿è¿œæ¨ç†ä¸­çš„ä¸è¶³</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span> <span class="paper-tag">chain-of-thought</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03556v2" data-paper-url="./papers/250803556v2-vrprm-process-reward-modeling-via-visual-reasoning.html" onclick="toggleFavorite(this, '2508.03556v2', 'VRPRM: Process Reward Modeling via Visual Reasoning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>22</td>
  <td><a href="./papers/250803665v4-a-dbc-inspired-neurosymbolic-layer-for-trustworthy-agent-design.html">A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design</a></td>
  <td>æå‡ºåŸºäºå¥‘çº¦è®¾è®¡çš„ç¥ç»ç¬¦å·å±‚ä»¥æå‡æ™ºèƒ½ä½“å¯ä¿¡åº¦</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03665v4" data-paper-url="./papers/250803665v4-a-dbc-inspired-neurosymbolic-layer-for-trustworthy-agent-design.html" onclick="toggleFavorite(this, '2508.03665v4', 'A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>23</td>
  <td><a href="./papers/250803527v1-moka-mixture-of-kronecker-adapters.html">MoKA: Mixture of Kronecker Adapters</a></td>
  <td>æå‡ºMoKAä»¥è§£å†³ä½ç§©é€‚é…å™¨è¡¨è¾¾èƒ½åŠ›ä¸è¶³çš„é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03527v1" data-paper-url="./papers/250803527v1-moka-mixture-of-kronecker-adapters.html" onclick="toggleFavorite(this, '2508.03527v1', 'MoKA: Mixture of Kronecker Adapters')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>24</td>
  <td><a href="./papers/250803776v1-revisiting-heat-flux-analysis-of-tungsten-monoblock-divertor-on-east.html">Revisiting Heat Flux Analysis of Tungsten Monoblock Divertor on EAST using Physics-Informed Neural Network</a></td>
  <td>æå‡ºç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œä»¥åŠ é€ŸEASTçƒ­æµåˆ†æ</td>
  <td class="tags-cell"><span class="paper-tag">TAMP</span></td>
  <td>âœ…</td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03776v1" data-paper-url="./papers/250803776v1-revisiting-heat-flux-analysis-of-tungsten-monoblock-divertor-on-east.html" onclick="toggleFavorite(this, '2508.03776v1', 'Revisiting Heat Flux Analysis of Tungsten Monoblock Divertor on EAST using Physics-Informed Neural Network')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>25</td>
  <td><a href="./papers/250803332v1-exploring-layer-wise-information-effectiveness-for-post-training-qua.html">Exploring Layer-wise Information Effectiveness for Post-Training Quantization in Small Language Models</a></td>
  <td>æå‡ºLieQæ¡†æ¶ä»¥è§£å†³å°å‹è¯­è¨€æ¨¡å‹çš„åè®­ç»ƒé‡åŒ–é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03332v1" data-paper-url="./papers/250803332v1-exploring-layer-wise-information-effectiveness-for-post-training-qua.html" onclick="toggleFavorite(this, '2508.03332v1', 'Exploring Layer-wise Information Effectiveness for Post-Training Quantization in Small Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>26</td>
  <td><a href="./papers/250803772v5-gtpo-stabilizing-group-relative-policy-optimization-via-gradient-and.html">GTPO: Stabilizing Group Relative Policy Optimization via Gradient and Entropy Control</a></td>
  <td>æå‡ºGTPOä»¥è§£å†³GRPOè®­ç»ƒä¸ç¨³å®šæ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03772v5" data-paper-url="./papers/250803772v5-gtpo-stabilizing-group-relative-policy-optimization-via-gradient-and.html" onclick="toggleFavorite(this, '2508.03772v5', 'GTPO: Stabilizing Group Relative Policy Optimization via Gradient and Entropy Control')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>27</td>
  <td><a href="./papers/250803148v1-frontier-simulating-the-next-generation-of-llm-inference-systems.html">Frontier: Simulating the Next Generation of LLM Inference Systems</a></td>
  <td>æå‡ºFrontierä»¥è§£å†³LLMæ¨ç†ç³»ç»Ÿå¤æ‚æ€§é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">large language model</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03148v1" data-paper-url="./papers/250803148v1-frontier-simulating-the-next-generation-of-llm-inference-systems.html" onclick="toggleFavorite(this, '2508.03148v1', 'Frontier: Simulating the Next Generation of LLM Inference Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±å…«ç‰©ç†åŠ¨ç”»-physics-based-animation">ğŸ”¬ æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation) (3 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>28</td>
  <td><a href="./papers/250803872v3-intelligent-sampling-of-extreme-scale-turbulence-datasets-for-accura.html">Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training</a></td>
  <td>æå‡ºSICKLEæ¡†æ¶ä»¥é«˜æ•ˆè®­ç»ƒå¤§è§„æ¨¡æ¹æµæ•°æ®æ¨¡å‹</td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03872v3" data-paper-url="./papers/250803872v3-intelligent-sampling-of-extreme-scale-turbulence-datasets-for-accura.html" onclick="toggleFavorite(this, '2508.03872v3', 'Intelligent Sampling of Extreme-Scale Turbulence Datasets for Accurate and Efficient Spatiotemporal Model Training')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>29</td>
  <td><a href="./papers/250803614v1-minimal-convolutional-rnns-accelerate-spatiotemporal-learning.html">Minimal Convolutional RNNs Accelerate Spatiotemporal Learning</a></td>
  <td>æå‡ºMinConvLSTMå’ŒMinConvGRUä»¥åŠ é€Ÿæ—¶ç©ºå­¦ä¹ </td>
  <td class="tags-cell"><span class="paper-tag">spatiotemporal</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03614v1" data-paper-url="./papers/250803614v1-minimal-convolutional-rnns-accelerate-spatiotemporal-learning.html" onclick="toggleFavorite(this, '2508.03614v1', 'Minimal Convolutional RNNs Accelerate Spatiotemporal Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
<tr>
  <td>30</td>
  <td><a href="./papers/250803436v1-ai-on-the-pulse-real-time-health-anomaly-detection-with-wearable-and.html">AI on the Pulse: Real-Time Health Anomaly Detection with Wearable and Ambient Intelligence</a></td>
  <td>æå‡ºAI on the Pulseä»¥è§£å†³å®æ—¶å¥åº·å¼‚å¸¸æ£€æµ‹é—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">PULSE</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03436v1" data-paper-url="./papers/250803436v1-ai-on-the-pulse-real-time-health-anomaly-detection-with-wearable-and.html" onclick="toggleFavorite(this, '2508.03436v1', 'AI on the Pulse: Real-Time Health Anomaly Detection with Wearable and Ambient Intelligence')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


<h2 id="æ”¯æŸ±äº”äº¤äº’ä¸ååº”-interaction-reaction">ğŸ”¬ æ”¯æŸ±äº”ï¼šäº¤äº’ä¸ååº” (Interaction & Reaction) (1 ç¯‡)</h2>

<table>
<thead>
<tr><th>#</th><th>é¢˜ç›®</th><th>ä¸€å¥è¯è¦ç‚¹</th><th>æ ‡ç­¾</th><th>ğŸ”—</th><th>â­</th></tr>
</thead>
<tbody>
<tr>
  <td>31</td>
  <td><a href="./papers/250803685v1-no-llm-solved-yu-tsumuras-554th-problem.html">No LLM Solved Yu Tsumura's 554th Problem</a></td>
  <td>æ­ç¤ºç°æœ‰LLMæ— æ³•è§£å†³çš„Yu Tsumuraç¬¬554ä¸ªé—®é¢˜</td>
  <td class="tags-cell"><span class="paper-tag">IMoS</span></td>
  <td></td>
  <td><button class="favorite-btn" data-arxiv-id="2508.03685v1" data-paper-url="./papers/250803685v1-no-llm-solved-yu-tsumuras-554th-problem.html" onclick="toggleFavorite(this, '2508.03685v1', 'No LLM Solved Yu Tsumura&#39;s 554th Problem')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜†</button></td>
</tr>
</tbody>
</table>


[â¬…ï¸ è¿”å› cs.LG é¦–é¡µ](../index.html) Â· [ğŸ  è¿”å›ä¸»é¡µ](../../index.html)