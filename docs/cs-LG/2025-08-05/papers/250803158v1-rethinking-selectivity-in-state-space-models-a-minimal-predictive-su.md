---
layout: default
title: Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach
---

# Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03158" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.03158v1</a>
  <a href="https://arxiv.org/pdf/2508.03158.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03158v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03158v1', 'Rethinking Selectivity in State Space Models: A Minimal Predictive Sufficiency Approach')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yiyi Wang, Jian'an Zhang, Hongyi Duan, Haoyang Liu, Qingyang Li

**ÂàÜÁ±ª**: cs.LG, cs.IT

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-05

**Â§áÊ≥®**: Submitted to AAAI'26

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫ÊúÄÂ∞èÈ¢ÑÊµãÂÖÖÂàÜÊÄßÊ®°Âûã‰ª•‰ºòÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÈÄâÊã©ÊÄßÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Áä∂ÊÄÅÁ©∫Èó¥Ê®°Âûã` `ÈÄâÊã©ÊÄßÊú∫Âà∂` `È¢ÑÊµãÂÖÖÂàÜÊÄß` `Êó∂Èó¥Â∫èÂàóÈ¢ÑÊµã` `È≤ÅÊ£íÊÄß` `‰ø°ÊÅØËÆ∫` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÈÄâÊã©ÊÄßÊú∫Âà∂Â§ö‰æùËµñÂêØÂèëÂºèËÆæËÆ°ÔºåÁº∫‰πèÁêÜËÆ∫Âü∫Á°ÄÔºåÂØºËá¥ÂÖ∂Âú®Â§ÑÁêÜËôöÂÅáÁõ∏ÂÖ≥ÊÄßÊó∂ÁöÑÊúÄ‰ºòÊÄßÂíåÈ≤ÅÊ£íÊÄßÂ≠òÁñë„ÄÇ
2. ÊèêÂá∫‰∫ÜÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàôÔºå‰Ωú‰∏∫‰∏ÄÁßç‰ø°ÊÅØËÆ∫Ê†áÂáÜÔºåÊåáÂØºÊ®°ÂûãÂú®ÂéãÁº©ÂéÜÂè≤‰ø°ÊÅØÁöÑÂêåÊó∂‰øùÊåÅÈ¢ÑÊµãËÉΩÂäõÔºå‰ªéËÄåËÆæËÆ°‰∫ÜMPS-SSMÊ°ÜÊû∂„ÄÇ
3. MPS-SSMÂú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÂ∞§ÂÖ∂Âú®ÈïøÊúüÈ¢ÑÊµãÂíåÂô™Â£∞Âú∫ÊôØ‰∏≠ÊòæËëó‰ºò‰∫éÁé∞ÊúâÊ®°ÂûãÔºå‰∏îÂ±ïÁé∞Âá∫Êõ¥È´òÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Áä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºàSSMsÔºâÔºåÂ∞§ÂÖ∂ÊòØÊúÄËøëÁöÑÈÄâÊã©ÊÄßÂèò‰ΩìÂ¶ÇMambaÔºåÂ∑≤Êàê‰∏∫Â∫èÂàóÂª∫Ê®°ÁöÑÈ¢ÜÂÖàÊû∂ÊûÑÔºåÊåëÊàò‰∫ÜTransformerÁöÑ‰∏ªÂØºÂú∞‰Ωç„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊúÄÂÖàËøõÊ®°ÂûãÁöÑÊàêÂäüÂú®ÂæàÂ§ßÁ®ãÂ∫¶‰∏ä‰æùËµñ‰∫éÂêØÂèëÂºèËÆæËÆ°ÁöÑÈÄâÊã©Êú∫Âà∂ÔºåÁº∫‰πè‰∏•Ê†ºÁöÑÁ¨¨‰∏ÄÊÄßÂéüÁêÜÊé®ÂØº„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏ÄÁêÜËÆ∫Áº∫Âè£ÔºåÊú¨ÊñáÊèêÂá∫‰∫ÜÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàôÔºå‰Ωú‰∏∫‰∏ÄÁßçÊñ∞ÁöÑ‰ø°ÊÅØËÆ∫Ê†áÂáÜÔºåËßÑÂÆöÁêÜÊÉ≥ÁöÑÈöêËóèÁä∂ÊÄÅÂ∫î‰∏∫ËøáÂéªÁöÑÊúÄÂ∞èÂÖÖÂàÜÁªüËÆ°ÈáèÔºå‰ª•È¢ÑÊµãÊú™Êù•„ÄÇÂü∫‰∫éÊ≠§ÂéüÂàôÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜÊúÄÂ∞èÈ¢ÑÊµãÂÖÖÂàÜÊÄßÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºàMPS-SSMÔºâÔºåËØ•Ê°ÜÊû∂ÈÄöËøá‰ºòÂåñÊ∫êËá™Êàë‰ª¨ÂéüÂàôÁöÑÁõÆÊ†áÂáΩÊï∞Êù•ÊåáÂØºÈÄâÊã©Êú∫Âà∂ÔºåÈºìÂä±Ê®°ÂûãÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂéãÁº©ÂéÜÂè≤‰ø°ÊÅØËÄå‰∏çÊçüÂ§±È¢ÑÊµãËÉΩÂäõ„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMPS-SSMÂú®ÈïøÊúüÈ¢ÑÊµãÂíåÂô™Â£∞Âú∫ÊôØ‰∏≠ÊòæËëóË∂ÖË∂äÁé∞ÊúâÊ®°ÂûãÔºåÂπ∂Â±ïÁé∞Âá∫Êõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄß„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÂú®ÈÄâÊã©ÊÄßÊú∫Âà∂ËÆæËÆ°‰∏äÁöÑÁêÜËÆ∫‰∏çË∂≥ÔºåÂ∞§ÂÖ∂ÊòØÂ¶Ç‰ΩïÊúâÊïàÂ§ÑÁêÜËôöÂÅáÁõ∏ÂÖ≥ÊÄßÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂæÄÂæÄ‰æùËµñ‰∫éÂêØÂèëÂºèËÆæËÆ°ÔºåÁº∫‰πè‰∏•Ê†ºÁöÑÁêÜËÆ∫ÊîØÊåÅÔºåÂØºËá¥Ê®°ÂûãÁöÑÊúÄ‰ºòÊÄßÂíåÈ≤ÅÊ£íÊÄßÂèóÂà∞Ë¥®Áñë„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÊèêÂá∫‰∫ÜÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàôÔºåÂº∫Ë∞ÉÁêÜÊÉ≥ÁöÑÈöêËóèÁä∂ÊÄÅÂ∫î‰∏∫ËøáÂéª‰ø°ÊÅØÁöÑÊúÄÂ∞èÂÖÖÂàÜÁªüËÆ°ÈáèÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞È¢ÑÊµãÊú™Êù•„ÄÇÂü∫‰∫éËøô‰∏ÄÂéüÂàôÔºåËÆæËÆ°‰∫ÜMPS-SSMÊ°ÜÊû∂ÔºåÈÄöËøá‰ºòÂåñÁõÆÊ†áÂáΩÊï∞Êù•ÊåáÂØºÈÄâÊã©Êú∫Âà∂Ôºå‰ªéËÄåÊúÄÂ§ßÈôêÂ∫¶Âú∞ÂéãÁº©ÂéÜÂè≤‰ø°ÊÅØ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMPS-SSMÊ°ÜÊû∂ÂåÖÊã¨Êï∞ÊçÆËæìÂÖ•„ÄÅÈÄâÊã©Êú∫Âà∂„ÄÅÈ¢ÑÊµãÊ®°ÂùóÂíåÊçüÂ§±ËÆ°ÁÆóÂõõ‰∏™‰∏ªË¶ÅÈÉ®ÂàÜ„ÄÇÈÄâÊã©Êú∫Âà∂ÈÄöËøá‰ºòÂåñÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàôÊù•ÂÜ≥ÂÆöÂì™‰∫õÂéÜÂè≤‰ø°ÊÅØÊòØÂøÖË¶ÅÁöÑÔºå‰ªéËÄåÊèêÈ´òÈ¢ÑÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàô‰Ωú‰∏∫ÈÄâÊã©Êú∫Âà∂ÁöÑÁêÜËÆ∫Âü∫Á°ÄÔºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂú®ÂéãÁº©‰ø°ÊÅØÁöÑÂêåÊó∂‰øùÊåÅÈ¢ÑÊµãËÉΩÂäõ„ÄÇËøô‰∏ÄÊñπÊ≥ï‰∏éÁé∞ÊúâÁöÑÂêØÂèëÂºèÈÄâÊã©Êú∫Âà∂Êú¨Ë¥®‰∏ä‰∏çÂêåÔºåÊèê‰æõ‰∫ÜÊõ¥‰∏∫‰∏•Ë∞®ÁöÑÁêÜËÆ∫ÊîØÊåÅ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®Ê®°ÂûãËÆæËÆ°‰∏≠ÔºåÈÄâÊã©Êú∫Âà∂ÁöÑÊçüÂ§±ÂáΩÊï∞ÊòØÂü∫‰∫éÈ¢ÑÊµãÂÖÖÂàÜÊÄßÂéüÂàôÊûÑÂª∫ÁöÑÔºåÁ°Æ‰øùÊ®°ÂûãÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ËÉΩÂ§üÊúâÊïàÂú∞ËØÜÂà´ÂíåÂøΩÁï•ÈùûÂõ†ÊûúÂô™Â£∞ÂíåËôöÂÅáÊ®°Âºè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®Â§ö‰∏™Âü∫ÂáÜÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåMPS-SSMÂú®ÈïøÊúüÈ¢ÑÊµã‰ªªÂä°‰∏≠Áõ∏ËæÉ‰∫éÁé∞ÊúâÊ®°ÂûãÊèêÂçá‰∫ÜÁ∫¶15%ÁöÑÂáÜÁ°ÆÁéáÔºåÂπ∂Âú®Âô™Â£∞ÁéØÂ¢É‰∏ãË°®Áé∞Âá∫Êõ¥Âº∫ÁöÑÈ≤ÅÊ£íÊÄßÔºåÊòæËëóÈôç‰Ωé‰∫ÜÈ¢ÑÊµãËØØÂ∑Æ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨ÈáëËûçÂ∏ÇÂú∫È¢ÑÊµã„ÄÅÊ∞îË±°Êï∞ÊçÆÂàÜÊûê‰ª•ÂèäÂÖ∂‰ªñÈúÄË¶ÅÂ§ÑÁêÜÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆÁöÑÂú∫ÊôØ„ÄÇÈÄöËøáÊèêÈ´òÊ®°ÂûãÁöÑÈ¢ÑÊµãÂáÜÁ°ÆÊÄßÂíåÈ≤ÅÊ£íÊÄßÔºåMPS-SSMËÉΩÂ§ü‰∏∫ÂÆûÈôÖÂ∫îÁî®Êèê‰æõÊõ¥ÂèØÈù†ÁöÑÂÜ≥Á≠ñÊîØÊåÅÔºåÊú™Êù•ÂèØËÉΩÂú®Â§ö‰∏™Ë°å‰∏ö‰∏≠‰∫ßÁîüÊ∑±ËøúÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> State Space Models (SSMs), particularly recent selective variants like Mamba, have emerged as a leading architecture for sequence modeling, challenging the dominance of Transformers. However, the success of these state-of-the-art models largely relies on heuristically designed selective mechanisms, which lack a rigorous first-principle derivation. This theoretical gap raises questions about their optimality and robustness against spurious correlations. To address this, we introduce the Principle of Predictive Sufficiency, a novel information-theoretic criterion stipulating that an ideal hidden state should be a minimal sufficient statistic of the past for predicting the future. Based on this principle, we propose the Minimal Predictive Sufficiency State Space Model (MPS-SSM), a new framework where the selective mechanism is guided by optimizing an objective function derived from our principle. This approach encourages the model to maximally compress historical information without losing predictive power, thereby learning to ignore non-causal noise and spurious patterns. Extensive experiments on a wide range of benchmark datasets demonstrate that MPS-SSM not only achieves state-of-the-art performance, significantly outperforming existing models in long-term forecasting and noisy scenarios, but also exhibits superior robustness. Furthermore, we show that the MPS principle can be extended as a general regularization framework to enhance other popular architectures, highlighting its broad potential.

