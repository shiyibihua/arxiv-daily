---
layout: default
title: Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection
---

# Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.15202" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.15202v2</a>
  <a href="https://arxiv.org/pdf/2510.15202.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.15202v2" onclick="toggleFavorite(this, '2510.15202v2', 'Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Denis Janiak, Jakub Binkowski, Tomasz Kajdanowicz

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-17 (æ›´æ–°: 2025-10-20)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºå¾„å‘ç¼©æ”¾çš„â„“2å½’ä¸€åŒ–ä»¥æå‡OODæ£€æµ‹æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¼‚å¸¸æ£€æµ‹` `Mahalanobisè·ç¦»` `æ·±åº¦å­¦ä¹ ` `ç‰¹å¾å‡ ä½•` `å½’ä¸€åŒ–æ–¹æ³•` `OODæ£€æµ‹` `å›¾åƒå¤„ç†`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„Mahalanobisè·ç¦»æ–¹æ³•åœ¨OODæ£€æµ‹ä¸­å¹¶ä¸æ€»æ˜¯å¯é ï¼Œç‰¹å¾å‡ ä½•å’Œå½’ä¸€åŒ–çš„å½±å“å°šæœªè¢«å……åˆ†ç†è§£ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°çš„å¾„å‘ç¼©æ”¾â„“2å½’ä¸€åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿç›´æ¥æ§åˆ¶ç‰¹å¾ç©ºé—´çš„å¾„å‘å‡ ä½•ï¼Œä»è€Œæ”¹å–„OODæ£€æµ‹æ€§èƒ½ã€‚
3. é€šè¿‡å®è¯ç ”ç©¶ï¼Œå‘ç°æ–°çš„å½’ä¸€åŒ–æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šæ˜¾è‘—æå‡äº†OODæ£€æµ‹çš„å‡†ç¡®æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹çš„å¯é éƒ¨ç½²ä¸­ï¼Œå¼‚å¸¸æ£€æµ‹ï¼ˆOODæ£€æµ‹ï¼‰è‡³å…³é‡è¦ã€‚å°½ç®¡Mahalanobisè·ç¦»æ–¹æ³•è¢«å¹¿æ³›åº”ç”¨ï¼Œä½†ç‰¹å¾å‡ ä½•å’Œå½’ä¸€åŒ–å¯¹å…¶æ€§èƒ½çš„å½±å“å°šæœªå®Œå…¨ç†è§£ï¼Œè¿™é™åˆ¶äº†å…¶ä¸‹æ¸¸åº”ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæœ¬æ–‡è¿›è¡Œäº†å…¨é¢çš„å®è¯ç ”ç©¶ï¼Œåˆ†æäº†ä¸åŒå›¾åƒåŸºç¡€æ¨¡å‹ã€æ•°æ®é›†å’Œè·ç¦»å½’ä¸€åŒ–æ–¹æ¡ˆã€‚ç ”ç©¶è¡¨æ˜ï¼ŒMahalanobisæ–¹æ³•å¹¶éæ™®éå¯é ï¼Œå¹¶å®šä¹‰äº†æ•°æ®è¡¨ç¤ºçš„ç†æƒ³å‡ ä½•å½¢çŠ¶ï¼Œæå‡ºè°±å’Œå†…åœ¨ç»´åº¦åº¦é‡å¯ä»¥å‡†ç¡®é¢„æµ‹æ¨¡å‹çš„OODæ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜åˆ†æäº†å½’ä¸€åŒ–å¯¹OODæ€§èƒ½çš„å½±å“ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å¾„å‘ç¼©æ”¾â„“2å½’ä¸€åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡OODæ£€æµ‹æ€§èƒ½ã€‚é€šè¿‡å°†è¡¨ç¤ºå‡ ä½•ã€å½’ä¸€åŒ–ä¸OODæ€§èƒ½è”ç³»èµ·æ¥ï¼Œæœ¬æ–‡ä¸ºè®¾è®¡æ›´æœ‰æ•ˆå’Œå¯é çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æä¾›äº†æ–°è§è§£ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³Mahalanobisè·ç¦»æ–¹æ³•åœ¨OODæ£€æµ‹ä¸­çš„ä¸å¯é æ€§ï¼Œå°¤å…¶æ˜¯ç‰¹å¾å‡ ä½•å’Œå½’ä¸€åŒ–å¯¹æ€§èƒ½çš„å½±å“å°šä¸æ˜ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å®šä¹‰ç†æƒ³çš„ç‰¹å¾å‡ ä½•å½¢çŠ¶ï¼Œå¹¶æå‡ºå¾„å‘ç¼©æ”¾çš„â„“2å½’ä¸€åŒ–æ–¹æ³•ï¼Œæ¥ç³»ç»Ÿæ€§åœ°æ”¹å–„OODæ£€æµ‹æ€§èƒ½ã€‚è¯¥æ–¹æ³•å¼•å…¥å¯è°ƒå‚æ•°ï¼Œå…è®¸å¯¹ç‰¹å¾ç©ºé—´è¿›è¡Œæ”¶ç¼©æˆ–æ‰©å±•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåˆ†æäº†ä¸åŒå›¾åƒåŸºç¡€æ¨¡å‹å’Œæ•°æ®é›†çš„è¡¨ç°ï¼Œç„¶åè¯„ä¼°äº†ä¸åŒå½’ä¸€åŒ–æ–¹æ¡ˆå¯¹OODæ£€æµ‹çš„å½±å“ï¼Œæœ€åæå‡ºäº†æ–°çš„å½’ä¸€åŒ–æ–¹æ³•å¹¶è¿›è¡Œå®éªŒéªŒè¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†å¾„å‘ç¼©æ”¾çš„â„“2å½’ä¸€åŒ–æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ç‰¹å¾ç©ºé—´ä¸­çµæ´»è°ƒæ•´å‡ ä½•å½¢çŠ¶ï¼Œä¸ä¼ ç»Ÿçš„â„“2å½’ä¸€åŒ–ç›¸æ¯”ï¼Œæä¾›äº†æ›´é«˜çš„çµæ´»æ€§å’Œæ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ–¹æ³•è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å¾„å‘ç¼©æ”¾å› å­ï¼Œè¯¥å› å­ç›´æ¥å½±å“ç‰¹å¾ç©ºé—´çš„å‡ ä½•å½¢çŠ¶ï¼Œæ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ä¹Ÿç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”æ–°çš„å½’ä¸€åŒ–æ–¹æ³•ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œé‡‡ç”¨å¾„å‘ç¼©æ”¾çš„â„“2å½’ä¸€åŒ–æ–¹æ³•åï¼Œæ¨¡å‹åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„OODæ£€æµ‹æ€§èƒ½æå‡äº†æ˜¾è‘—ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°10%-15%ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„Mahalanobisæ–¹æ³•ï¼Œè¡¨ç°å‡ºæ›´é«˜çš„å‡†ç¡®æ€§å’Œé²æ£’æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å½±åƒåˆ†æå’Œé‡‘èæ¬ºè¯ˆæ£€æµ‹ç­‰åœºæ™¯ï¼Œèƒ½å¤Ÿæé«˜æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†æœªçŸ¥æ•°æ®æ—¶çš„å¯é æ€§å’Œå®‰å…¨æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½æ¨åŠ¨æ›´å¹¿æ³›çš„OODæ£€æµ‹æŠ€æœ¯çš„å‘å±•ï¼Œæå‡å„ç±»æ™ºèƒ½ç³»ç»Ÿçš„æ€§èƒ½ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Out-of-distribution (OOD) detection is critical for the reliable deployment of deep learning models. hile Mahalanobis distance methods are widely used, the impact of representation geometry and normalization on their performance is not fully understood, which may limit their downstream application. To address this gap, we conducted a comprehensive empirical study across diverse image foundation models, datasets, and distance normalization schemes. First, our analysis shows that Mahalanobis-based methods aren't universally reliable. Second, we define the ideal geometry for data representations and demonstrate that spectral and intrinsic-dimensionality metrics can accurately predict a model's OOD performance. Finally, we analyze how normalization impacts OOD performance. Building upon these studies, we propose radially scaled $\ell_2$ normalization, a method that generalizes the standard $\ell_2$ normalization recently applied to Mahalanobis-based OOD detection. Our approach introduces a tunable parameter to directly control the radial geometry of the feature space, systematically contracting or expanding representations to significantly improve OOD detection performance. By bridging the gap between representation geometry, normalization, and OOD performance, our findings offer new insights into the design of more effective and reliable deep learning models.

