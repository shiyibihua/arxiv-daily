---
layout: default
title: Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning
---

# Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04399" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04399v1</a>
  <a href="https://arxiv.org/pdf/2506.04399.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04399v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04399v1', 'Unsupervised Meta-Testing with Conditional Neural Processes for Hybrid Meta-Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Suzan Ece Ada, Emre Ugur

**åˆ†ç±»**: cs.LG, cs.AI, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: Published in IEEE Robotics and Automation Letters Volume: 9, Issue: 10, 8427 - 8434, October 2024. 8 pages, 7 figures

**æœŸåˆŠ**: IEEE Robotics and Automation Letters Volume: 9, Issue: 10, 8427 - 8434, October 2024,

**DOI**: [10.1109/LRA.2024.3443496](https://doi.org/10.1109/LRA.2024.3443496)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ— ç›‘ç£å…ƒæµ‹è¯•æ–¹æ³•UMCNPä»¥è§£å†³ç¼ºä¹å¥–åŠ±ä¿¡å·çš„é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å…ƒå¼ºåŒ–å­¦ä¹ ` `æ— ç›‘ç£å­¦ä¹ ` `æ¡ä»¶ç¥ç»è¿‡ç¨‹` `æ ·æœ¬æ•ˆç‡` `ä»»åŠ¡æ¨æ–­`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…ƒå¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨å…ƒæµ‹è¯•é˜¶æ®µç¼ºä¹å¥–åŠ±ä¿¡å·ï¼Œå¯¼è‡´æ ·æœ¬æ•ˆç‡ä½ä¸‹ã€‚
2. UMCNPé€šè¿‡ç»“åˆæ¡ä»¶ç¥ç»è¿‡ç¨‹ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é¢å¤–æ ·æœ¬çš„æƒ…å†µä¸‹æé«˜æ ·æœ¬æ•ˆç‡ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUMCNPåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—å‡å°‘äº†é€‚åº”æœªè§ä»»åŠ¡æ‰€éœ€çš„æ ·æœ¬æ•°é‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ— ç›‘ç£å…ƒæµ‹è¯•æ–¹æ³•UMCNPï¼Œè¯¥æ–¹æ³•ç»“åˆäº†åŸºäºå‚æ•°åŒ–ç­–ç•¥æ¢¯åº¦çš„å…ƒå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºä»»åŠ¡æ¨æ–­çš„å°‘æ ·æœ¬å…ƒå¼ºåŒ–å­¦ä¹ ï¼Œé€‚ç”¨äºåœ¨å…ƒæµ‹è¯•æœŸé—´ç¼ºä¹å¥–åŠ±ä¿¡å·çš„åœºæ™¯ã€‚UMCNPåˆ©ç”¨æ¡ä»¶ç¥ç»è¿‡ç¨‹çš„é«˜æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ï¼Œå‡å°‘äº†å…ƒæµ‹è¯•æ‰€éœ€çš„åœ¨çº¿äº¤äº’æ¬¡æ•°ã€‚åœ¨å…ƒè®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨é€šè¿‡PPGå…ƒå¼ºåŒ–å­¦ä¹ æ”¶é›†çš„æ ·æœ¬è¿›è¡Œç¦»çº¿ä»»åŠ¡æ¨æ–­å­¦ä¹ ã€‚UMCNPèƒ½å¤Ÿä»å•ä¸ªæµ‹è¯•ä»»åŠ¡çš„å›åˆä¸­æ¨æ–­å‡ºè½¬ç§»åŠ¨æ€æ¨¡å‹çš„æ½œåœ¨è¡¨ç¤ºï¼Œä»è€Œé€šè¿‡ä¸å­¦ä¹ åˆ°çš„åŠ¨æ€æ¨¡å‹äº¤äº’ç”Ÿæˆè‡ªé€‚åº”å›åˆã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨2Dç‚¹ä»£ç†å’Œè¿ç»­æ§åˆ¶å…ƒå¼ºåŒ–å­¦ä¹ åŸºå‡†ä¸Šï¼ŒUMCNPåœ¨å…ƒæµ‹è¯•ä¸­é€‚åº”æœªè§æµ‹è¯•ä»»åŠ¡æ‰€éœ€çš„æ ·æœ¬æ˜¾è‘—å°‘äºåŸºçº¿æ–¹æ³•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³åœ¨å…ƒæµ‹è¯•é˜¶æ®µç¼ºä¹å¥–åŠ±ä¿¡å·çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è¿™ç§æƒ…å†µä¸‹å¾€å¾€éœ€è¦å¤§é‡æ ·æœ¬æ¥è¿›è¡Œæœ‰æ•ˆå­¦ä¹ ï¼Œå¯¼è‡´æ ·æœ¬æ•ˆç‡ä½ä¸‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUMCNPé€šè¿‡ç»“åˆåŸºäºå‚æ•°åŒ–ç­–ç•¥æ¢¯åº¦çš„å…ƒå¼ºåŒ–å­¦ä¹ å’ŒåŸºäºä»»åŠ¡æ¨æ–­çš„å°‘æ ·æœ¬å…ƒå¼ºåŒ–å­¦ä¹ ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰é¢å¤–æ ·æœ¬çš„æƒ…å†µä¸‹è¿›è¡Œé«˜æ•ˆçš„å…ƒæµ‹è¯•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¡ä»¶ç¥ç»è¿‡ç¨‹çš„ç‰¹æ€§ï¼Œå‡å°‘äº†åœ¨çº¿äº¤äº’çš„éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUMCNPçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šå…ƒè®­ç»ƒå’Œå…ƒæµ‹è¯•ã€‚åœ¨å…ƒè®­ç»ƒé˜¶æ®µï¼Œåˆ©ç”¨PPGå…ƒå¼ºåŒ–å­¦ä¹ æ”¶é›†çš„æ ·æœ¬è¿›è¡Œç¦»çº¿ä»»åŠ¡æ¨æ–­å­¦ä¹ ï¼›åœ¨å…ƒæµ‹è¯•é˜¶æ®µï¼Œä»å•ä¸ªæµ‹è¯•ä»»åŠ¡çš„å›åˆä¸­æ¨æ–­å‡ºè½¬ç§»åŠ¨æ€æ¨¡å‹çš„æ½œåœ¨è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šUMCNPçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå…¶æ— ç›‘ç£çš„å…ƒæµ‹è¯•èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ç¼ºä¹å¥–åŠ±ä¿¡å·çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ¨æ–­åŠ¨æ€æ¨¡å‹çš„æ½œåœ¨è¡¨ç¤ºæ¥ç”Ÿæˆè‡ªé€‚åº”å›åˆï¼Œè¿™ä¸ç°æœ‰æ–¹æ³•çš„ä¾èµ–äºå¥–åŠ±ä¿¡å·çš„å­¦ä¹ æ–¹å¼å½¢æˆäº†é²œæ˜å¯¹æ¯”ã€‚

**å…³é”®è®¾è®¡**ï¼šUMCNPåœ¨å‚æ•°è®¾ç½®ä¸Šé‡‡ç”¨äº†æ¡ä»¶ç¥ç»è¿‡ç¨‹çš„é«˜æ•ˆæ€§ï¼Œè®¾è®¡äº†é€‚åº”æ€§çš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–ä»»åŠ¡æ¨æ–­ï¼Œå¹¶é€šè¿‡ç½‘ç»œç»“æ„çš„çµæ´»æ€§æ¥é€‚åº”ä¸åŒçš„ä»»åŠ¡åŠ¨æ€ã€‚å…·ä½“çš„æŠ€æœ¯ç»†èŠ‚åŒ…æ‹¬å¦‚ä½•é«˜æ•ˆé‡ç”¨å…ƒè®­ç»ƒé˜¶æ®µçš„æ ·æœ¬ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡ä¸å­¦ä¹ åˆ°çš„åŠ¨æ€æ¨¡å‹äº¤äº’æ¥ç”Ÿæˆæ–°çš„å›åˆã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒUMCNPåœ¨2Dç‚¹ä»£ç†å’Œè¿ç»­æ§åˆ¶å…ƒå¼ºåŒ–å­¦ä¹ åŸºå‡†ä¸Šï¼Œé€‚åº”æœªè§æµ‹è¯•ä»»åŠ¡æ‰€éœ€çš„æ ·æœ¬æ•°é‡æ˜¾è‘—å°‘äºåŸºçº¿æ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°30%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šçš„æ ·æœ¬æ•ˆç‡ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½æ¸¸æˆç­‰åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨å¥–åŠ±ä¿¡å·ç¨€ç¼ºçš„æƒ…å†µä¸‹ï¼ŒUMCNPèƒ½å¤Ÿæœ‰æ•ˆæå‡å­¦ä¹ æ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We introduce Unsupervised Meta-Testing with Conditional Neural Processes (UMCNP), a novel hybrid few-shot meta-reinforcement learning (meta-RL) method that uniquely combines, yet distinctly separates, parameterized policy gradient-based (PPG) and task inference-based few-shot meta-RL. Tailored for settings where the reward signal is missing during meta-testing, our method increases sample efficiency without requiring additional samples in meta-training. UMCNP leverages the efficiency and scalability of Conditional Neural Processes (CNPs) to reduce the number of online interactions required in meta-testing. During meta-training, samples previously collected through PPG meta-RL are efficiently reused for learning task inference in an offline manner. UMCNP infers the latent representation of the transition dynamics model from a single test task rollout with unknown parameters. This approach allows us to generate rollouts for self-adaptation by interacting with the learned dynamics model. We demonstrate our method can adapt to an unseen test task using significantly fewer samples during meta-testing than the baselines in 2D-Point Agent and continuous control meta-RL benchmarks, namely, cartpole with unknown angle sensor bias, walker agent with randomized dynamics parameters.

