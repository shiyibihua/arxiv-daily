---
layout: default
title: Multimodal Tabular Reasoning with Privileged Structured Information
---

# Multimodal Tabular Reasoning with Privileged Structured Information

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04088" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04088v1</a>
  <a href="https://arxiv.org/pdf/2506.04088.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04088v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04088v1', 'Multimodal Tabular Reasoning with Privileged Structured Information')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jun-Peng Jiang, Yu Xia, Hai-Long Sun, Shiyin Lu, Qing-Guo Chen, Weihua Luo, Kaifu Zhang, De-Chuan Zhan, Han-Jia Ye

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTurboæ¡†æ¶ä»¥è§£å†³è¡¨æ ¼å›¾åƒæ¨ç†é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¡¨æ ¼æ¨ç†` `å¤šæ¨¡æ€å­¦ä¹ ` `å›¾åƒå¤„ç†` `ç»“æ„ä¿¡æ¯` `æ·±åº¦å­¦ä¹ ` `æ¨ç†è·¯å¾„` `å¤§å‹è¯­è¨€æ¨¡å‹` `Turboæ¡†æ¶`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¡¨æ ¼å›¾åƒæ¨ç†æ—¶é¢ä¸´ç»“æ„ä¿¡æ¯ä¸è§†è§‰è¡¨ç¤ºå¯¹é½çš„å¤æ‚æ€§ï¼Œä¸”ç¼ºä¹æœ‰æ•ˆçš„æ¨ç†æŠ€èƒ½è½¬ç§»æœºåˆ¶ã€‚
2. æœ¬æ–‡æå‡ºTurboæ¡†æ¶ï¼Œé€šè¿‡åˆ©ç”¨è®­ç»ƒæœŸé—´çš„ç‰¹æƒç»“æ„ä¿¡æ¯ï¼Œå¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTurboåœ¨ä»…ä½¿ç”¨9kæ•°æ®çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¹‹å‰çš„æœ€ä¼˜ç»“æœæå‡äº†7.2%ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¡¨æ ¼æ¨ç†æ¶‰åŠå¯¹è¡¨æ ¼æ•°æ®è¿›è¡Œå¤šæ­¥ä¿¡æ¯æå–å’Œé€»è¾‘æ¨ç†ã€‚å°½ç®¡è¿‘æœŸç ”ç©¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œç»“æ„åŒ–è¡¨æ ¼æ¨ç†ï¼Œä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé«˜è´¨é‡çš„æ–‡æœ¬è¡¨ç¤ºå¾€å¾€ä¸å¯ç”¨ï¼Œè¡¨æ ¼é€šå¸¸ä»¥å›¾åƒå½¢å¼å‡ºç°ã€‚æœ¬æ–‡é’ˆå¯¹è¡¨æ ¼å›¾åƒçš„æ¨ç†ä»»åŠ¡ï¼Œåˆ©ç”¨è®­ç»ƒæœŸé—´å¯ç”¨çš„ç‰¹æƒç»“æ„ä¿¡æ¯æ¥å¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†Turboæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç»“æ„ä¿¡æ¯ä¸è§†è§‰è¡¨ç¤ºçš„å¯¹é½å¤æ‚æ€§ï¼Œå¹¶æœ‰æ•ˆåœ°å°†ç»“æ„æ¨ç†æŠ€èƒ½è½¬ç§»åˆ°MLLMsã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTurboåœ¨æœ‰é™çš„9kæ•°æ®ä¸Šå®ç°äº†å¤šæ•°æ®é›†çš„æœ€æ–°æ€§èƒ½ï¼Œæå‡å¹…åº¦è¾¾åˆ°7.2%ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»è¡¨æ ¼å›¾åƒä¸­è¿›è¡Œæ¨ç†çš„ä»»åŠ¡ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†è¡¨æ ¼å›¾åƒæ—¶ï¼Œå¾€å¾€æ— æ³•æœ‰æ•ˆå¯¹é½ç»“æ„ä¿¡æ¯ä¸è§†è§‰è¡¨ç¤ºï¼Œå¯¼è‡´æ¨ç†æ€§èƒ½ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæˆ‘ä»¬æå‡ºTurboæ¡†æ¶ï¼Œåˆ©ç”¨è®­ç»ƒæœŸé—´çš„ç‰¹æƒç»“æ„ä¿¡æ¯æ¥å¢å¼ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ç»“æ„æ„ŸçŸ¥çš„æ¨ç†è·¯å¾„ç”Ÿæˆå™¨ï¼ŒTurboèƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡çš„è·¨æ¨¡æ€æ•°æ®ï¼Œä»è€Œæå‡æ¨ç†æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šTurboæ¡†æ¶ä¸»è¦åŒ…æ‹¬ä¸‰ä¸ªæ¨¡å—ï¼š1) ç»“æ„æ„ŸçŸ¥æ¨ç†è·¯å¾„ç”Ÿæˆå™¨ï¼ŒåŸºäºDeepSeek-R1ï¼›2) è·¨æ¨¡æ€æ•°æ®ç”Ÿæˆä¸é€‰æ‹©æœºåˆ¶ï¼›3) æ¨ç†èƒ½åŠ›çš„è¿­ä»£å¢å¼ºè¿‡ç¨‹ã€‚æ•´ä½“æµç¨‹æ˜¯é€šè¿‡ç”Ÿæˆå’Œé€‰æ‹©æœ‰åˆ©çš„æ¨ç†è·¯å¾„æ¥ä¸æ–­æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šTurboçš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†ç»“æ„æ„ŸçŸ¥çš„æ¨ç†è·¯å¾„ç”Ÿæˆå™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¡¥æ¥ç»“æ„ä¿¡æ¯ä¸è§†è§‰ä¿¡æ¯ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨æ¨¡æ€é—´è½¬ç§»æ¨ç†æŠ€èƒ½çš„ä¸è¶³ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨Turboä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–æ¨ç†è·¯å¾„çš„é€‰æ‹©ï¼Œå¹¶é‡‡ç”¨äº†æ·±åº¦å­¦ä¹ ç½‘ç»œç»“æ„ä»¥æé«˜ç”Ÿæˆæ•°æ®çš„è´¨é‡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTurboåœ¨ä»…ä½¿ç”¨9kæ•°æ®çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°äº†æœ€æ–°çš„æ€§èƒ½ï¼Œç›¸è¾ƒäºä¹‹å‰çš„æœ€ä¼˜ç»“æœæå‡äº†7.2%ã€‚è¿™ä¸€æ˜¾è‘—æå‡è¡¨æ˜Turboæ¡†æ¶åœ¨å¤šæ¨¡æ€è¡¨æ ¼æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ï¼Œè¶…è¶Šäº†ç°æœ‰çš„æœ€ä¼˜åŸºçº¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é‡‘èæ•°æ®åˆ†æã€åŒ»ç–—è®°å½•è§£è¯»å’Œæ™ºèƒ½æ–‡æ¡£å¤„ç†ç­‰ã€‚é€šè¿‡æé«˜è¡¨æ ¼å›¾åƒçš„æ¨ç†èƒ½åŠ›ï¼ŒTurboæ¡†æ¶èƒ½å¤Ÿåœ¨å®é™…åœºæ™¯ä¸­æä¾›æ›´é«˜æ•ˆçš„æ•°æ®å¤„ç†å’Œå†³ç­–æ”¯æŒï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Tabular reasoning involves multi-step information extraction and logical inference over tabular data. While recent advances have leveraged large language models (LLMs) for reasoning over structured tables, such high-quality textual representations are often unavailable in real-world settings, where tables typically appear as images. In this paper, we tackle the task of tabular reasoning from table images, leveraging privileged structured information available during training to enhance multimodal large language models (MLLMs). The key challenges lie in the complexity of accurately aligning structured information with visual representations, and in effectively transferring structured reasoning skills to MLLMs despite the input modality gap. To address these, we introduce TabUlar Reasoning with Bridged infOrmation ({\sc Turbo}), a new framework for multimodal tabular reasoning with privileged structured tables. {\sc Turbo} benefits from a structure-aware reasoning trace generator based on DeepSeek-R1, contributing to high-quality modality-bridged data. On this basis, {\sc Turbo} repeatedly generates and selects the advantageous reasoning paths, further enhancing the model's tabular reasoning ability. Experimental results demonstrate that, with limited ($9$k) data, {\sc Turbo} achieves state-of-the-art performance ($+7.2\%$ vs. previous SOTA) across multiple datasets.

