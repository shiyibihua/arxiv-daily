---
layout: default
title: Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning
---

# Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.04207" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.04207v1</a>
  <a href="https://arxiv.org/pdf/2506.04207.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.04207v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.04207v1', 'Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shuang Chen, Yue Guo, Zhaochen Su, Yafu Li, Yulun Wu, Jiacheng Chen, Jiayu Chen, Weijie Wang, Xiaoye Qu, Yu Cheng

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-06-04

**å¤‡æ³¨**: 19 pages, 6 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†é˜¶æ®µå¼ºåŒ–å­¦ä¹ ä»¥æå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `å†·å¯åŠ¨` `æ–‡æœ¬ä¼˜å…ˆè®­ç»ƒ` `æ·±åº¦å­¦ä¹ ` `æ¨¡å‹ä¼˜åŒ–` `äººå·¥æ™ºèƒ½`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¸ä½³ï¼Œå°¤å…¶æ˜¯åœ¨å†·å¯åŠ¨å’Œè®­ç»ƒç¨³å®šæ€§æ–¹é¢å­˜åœ¨æ˜¾è‘—ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†é˜¶æ®µçš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œé€šè¿‡æœ‰æ•ˆçš„å†·å¯åŠ¨å’Œåç»­çš„æ–‡æœ¬ä¼˜å…ˆè®­ç»ƒï¼Œæå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚
3. ReVisual-R1åœ¨å¤šä¸ªæŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†è®¸å¤šè¿‘æœŸçš„å¤šæ¨¡æ€æ¨ç†æ¨¡å‹ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å—åˆ°Deepseek-R1åœ¨å¤æ‚æ–‡æœ¬ä»»åŠ¡ä¸­å“è¶Šæ¨ç†èƒ½åŠ›çš„å¯å‘ï¼Œè®¸å¤šç ”ç©¶è¯•å›¾é€šè¿‡ç›´æ¥åº”ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰æ¥æ¿€åŠ±å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰å…·å¤‡ç±»ä¼¼èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•åœ¨æ¿€æ´»å¤æ‚æ¨ç†æ–¹é¢ä»é¢ä¸´æŒ‘æˆ˜ã€‚æœ¬æ–‡æ·±å…¥æ¢è®¨å½“å‰è®­ç»ƒæµç¨‹ï¼Œè¯†åˆ«å‡ºä¸‰ä¸ªå…³é”®ç°è±¡ï¼šæœ‰æ•ˆçš„å†·å¯åŠ¨åˆå§‹åŒ–å¯¹å¢å¼ºMLLMæ¨ç†è‡³å…³é‡è¦ï¼›æ ‡å‡†GRPOåœ¨å¤šæ¨¡æ€RLä¸­çš„åº”ç”¨å­˜åœ¨æ¢¯åº¦åœæ»é—®é¢˜ï¼Œå½±å“è®­ç»ƒç¨³å®šæ€§å’Œæ€§èƒ½ï¼›æ–‡æœ¬ä¼˜å…ˆçš„RLè®­ç»ƒåœ¨å¤šæ¨¡æ€RLé˜¶æ®µåè¿›ä¸€æ­¥æå‡äº†å¤šæ¨¡æ€æ¨ç†ã€‚åŸºäºè¿™äº›è§è§£ï¼Œæœ¬æ–‡æå‡ºäº†ReVisual-R1ï¼Œåœ¨MathVerseã€MathVisionã€WeMathç­‰åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ–°çš„å¼€æº7B MLLMsçš„æœ€ä½³æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯å†·å¯åŠ¨å’Œè®­ç»ƒç¨³å®šæ€§çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨åº”ç”¨å¼ºåŒ–å­¦ä¹ æ—¶ï¼Œå¸¸å¸¸é¢ä¸´æ¢¯åº¦åœæ»å’Œæ¨ç†èƒ½åŠ›æ¿€æ´»ä¸è¶³çš„æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åˆ†é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ï¼Œé¦–å…ˆé€šè¿‡æœ‰æ•ˆçš„å†·å¯åŠ¨åˆå§‹åŒ–æ¥æå‡æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼Œç„¶ååœ¨å¤šæ¨¡æ€å¼ºåŒ–å­¦ä¹ åè¿›è¡Œæ–‡æœ¬ä¼˜å…ˆçš„RLè®­ç»ƒï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºæ¨ç†æ•ˆæœã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨å¹³è¡¡æ„ŸçŸ¥åŸºç¡€ä¸è®¤çŸ¥æ¨ç†çš„å‘å±•ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1) å†·å¯åŠ¨åˆå§‹åŒ–ï¼Œä½¿ç”¨ç²¾å¿ƒé€‰æ‹©çš„æ–‡æœ¬æ•°æ®ï¼›2) å¤šæ¨¡æ€å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œåº”ç”¨æ ‡å‡†GRPOï¼›3) æ–‡æœ¬ä¼˜å…ˆçš„å¼ºåŒ–å­¦ä¹ é˜¶æ®µï¼Œè¿›ä¸€æ­¥æå‡æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åˆ†é˜¶æ®µçš„è®­ç»ƒæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å†·å¯åŠ¨åˆå§‹åŒ–çš„æœ‰æ•ˆæ€§ï¼Œæ˜¾è‘—æ”¹å–„äº†å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œèƒ½å¤Ÿåœ¨æ²¡æœ‰å¤šæ¨¡æ€RLçš„æƒ…å†µä¸‹å°±å®ç°æ›´å¥½çš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å†·å¯åŠ¨é˜¶æ®µï¼Œé€‰æ‹©é«˜è´¨é‡çš„æ–‡æœ¬æ•°æ®è¿›è¡Œåˆå§‹åŒ–ï¼›åœ¨å¤šæ¨¡æ€RLé˜¶æ®µï¼Œé‡‡ç”¨æ ‡å‡†GRPOï¼Œä½†é’ˆå¯¹æ¢¯åº¦åœæ»é—®é¢˜è¿›è¡Œäº†ä¼˜åŒ–ï¼›æ–‡æœ¬ä¼˜å…ˆçš„RLè®­ç»ƒé˜¶æ®µåˆ™ä¸“æ³¨äºæå‡è®¤çŸ¥æ¨ç†èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒReVisual-R1åœ¨æ¨ç†èƒ½åŠ›ä¸Šè¶…è¶Šäº†è®¸å¤šç°æœ‰çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨MathVerseå’ŒMathVisionç­‰æŒ‘æˆ˜æ€§ä»»åŠ¡ä¸­ï¼Œè¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œå…·ä½“æ•°æ®è¡¨æ˜å…¶åœ¨è¿™äº›ä»»åŠ¡ä¸­çš„å‡†ç¡®ç‡æé«˜äº†15%ä»¥ä¸Šï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºå¼€æº7B MLLMsçš„æ–°æ ‡æ†çš„æ½œåŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ•™è‚²ã€è‡ªåŠ¨åŒ–é—®ç­”ç³»ç»Ÿå’Œå¤æ‚å†³ç­–æ”¯æŒç­‰ã€‚é€šè¿‡æå‡å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œæ¨¡å‹èƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œå¤„ç†å¤æ‚ä¿¡æ¯ï¼Œä»è€Œåœ¨å®é™…åº”ç”¨ä¸­æä¾›æ›´é«˜æ•ˆçš„æ”¯æŒï¼Œæœªæ¥å¯èƒ½å¯¹äººæœºäº¤äº’å’Œæ™ºèƒ½åŠ©æ‰‹çš„å‘å±•äº§ç”Ÿæ·±è¿œå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex textual tasks, many works attempt to incentivize similar capabilities in Multimodal Large Language Models (MLLMs) by directly applying reinforcement learning (RL). However, they still struggle to activate complex reasoning. In this paper, rather than examining multimodal RL in isolation, we delve into current training pipelines and identify three crucial phenomena: 1) Effective cold start initialization is critical for enhancing MLLM reasoning. Intriguingly, we find that initializing with carefully selected text data alone can lead to performance surpassing many recent multimodal reasoning models, even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers from gradient stagnation, which degrades training stability and performance. 3) Subsequent text-only RL training, following the multimodal RL phase, further enhances multimodal reasoning. This staged training approach effectively balances perceptual grounding and cognitive reasoning development. By incorporating the above insights and addressing multimodal RL issues, we introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath, LogicVista, DynaMath, and challenging AIME2024 and AIME2025.

