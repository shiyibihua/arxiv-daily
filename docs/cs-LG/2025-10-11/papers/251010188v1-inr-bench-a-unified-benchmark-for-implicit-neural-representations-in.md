---
layout: default
title: INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction
---

# INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2510.10188" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2510.10188v1</a>
  <a href="https://arxiv.org/pdf/2510.10188.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2510.10188v1" onclick="toggleFavorite(this, '2510.10188v1', 'INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Linfei Li, Fengyi Zhang, Zhong Wang, Lin Zhang, Ying Shen

**åˆ†ç±»**: cs.LG, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-10-11

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/lif314/INR-Bench)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºINR-Benchï¼šå¤šé¢†åŸŸå›å½’ä¸é‡å»ºçš„éšå¼ç¥ç»è¡¨ç¤ºç»Ÿä¸€åŸºå‡†**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `éšå¼ç¥ç»è¡¨ç¤º` `åŸºå‡†æµ‹è¯•` `å¤šæ¨¡æ€å­¦ä¹ ` `ç¥ç»æ­£åˆ‡æ ¸` `æ¨¡å‹è¯„ä¼°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰éšå¼ç¥ç»è¡¨ç¤º(INR)ç ”ç©¶ç¼ºä¹å¯¹æ¨¡å‹æ¶æ„ã€ä½ç½®ç¼–ç ç­‰å› ç´ å½±å“çš„ç³»ç»Ÿæ€§åˆ†æï¼Œé™åˆ¶äº†å…¶å‘å±•ã€‚
2. è®ºæ–‡æå‡ºINR-Benchï¼Œä¸€ä¸ªç»¼åˆæ€§çš„å¤šæ¨¡æ€INRåŸºå‡†ï¼Œæ—¨åœ¨é€šè¿‡ç³»ç»Ÿè¯„ä¼°ä¸åŒæ¨¡å‹å’Œé…ç½®æ¥ç†è§£å…¶æ€§èƒ½ã€‚
3. INR-BenchåŒ…å«å¤šç§æ¨¡å‹å˜ä½“å’Œä»»åŠ¡ï¼Œæ¶µç›–æ­£å‘å’Œé€†å‘é—®é¢˜ï¼Œä¸ºæœªæ¥INRç ”ç©¶æä¾›åšå®çš„åŸºç¡€ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšå¼ç¥ç»è¡¨ç¤º(INRs)å› å…¶è¿ç»­æ€§å’Œæ— é™åˆ†è¾¨ç‡çš„ä¼˜åŠ¿ï¼Œåœ¨å„ç§ä¿¡å·å¤„ç†ä»»åŠ¡ä¸­å–å¾—äº†æˆåŠŸã€‚ç„¶è€Œï¼Œå½±å“å…¶æœ‰æ•ˆæ€§å’Œå±€é™æ€§çš„å› ç´ ä»æœªè¢«å……åˆ†æ¢ç´¢ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£è¿™äº›å› ç´ ï¼Œæˆ‘ä»¬åˆ©ç”¨ç¥ç»æ­£åˆ‡æ ¸(NTK)ç†è®ºçš„è§è§£ï¼Œåˆ†æäº†æ¨¡å‹æ¶æ„ï¼ˆç»å…¸MLPå’Œæ–°å…´KANï¼‰ã€ä½ç½®ç¼–ç å’Œéçº¿æ€§åŸè¯­å¦‚ä½•å½±å“å¯¹ä¸åŒé¢‘ç‡ä¿¡å·çš„å“åº”ã€‚åœ¨æ­¤åˆ†æçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æ¨å‡ºäº†INR-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ä¸ºå¤šæ¨¡æ€INRä»»åŠ¡è®¾è®¡çš„ç»¼åˆåŸºå‡†ã€‚å®ƒåŒ…æ‹¬56ç§Coordinate-MLPæ¨¡å‹å˜ä½“ï¼ˆå…·æœ‰4ç§ä½ç½®ç¼–ç å’Œ14ç§æ¿€æ´»å‡½æ•°ï¼‰å’Œ22ç§å…·æœ‰ä¸åŒåŸºå‡½æ•°çš„Coordinate-KANæ¨¡å‹ï¼Œå¹¶åœ¨9ä¸ªéšå¼å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¿›è¡Œäº†è¯„ä¼°ã€‚è¿™äº›ä»»åŠ¡æ¶µç›–äº†æ­£å‘å’Œé€†å‘é—®é¢˜ï¼Œæä¾›äº†ä¸€ä¸ªå¼ºå¤§çš„å¹³å°æ¥çªå‡ºä¸åŒç¥ç»æ¨¡å‹çš„ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Œä»è€Œä¸ºæœªæ¥çš„ç ”ç©¶å¥ å®šåšå®çš„åŸºç¡€ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨https://github.com/lif314/INR-Benchè·å¾—ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰éšå¼ç¥ç»è¡¨ç¤º(INR)æ–¹æ³•åœ¨ä¸åŒä»»åŠ¡å’Œæ•°æ®é›†ä¸Šçš„æ€§èƒ½è¡¨ç°å·®å¼‚è¾ƒå¤§ï¼Œç¼ºä¹ä¸€ä¸ªç»Ÿä¸€çš„è¯„ä¼°æ ‡å‡†æ¥æ¯”è¾ƒä¸åŒæ¨¡å‹å’Œé…ç½®çš„ä¼˜åŠ£ã€‚æ­¤å¤–ï¼Œå½±å“INRæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œå¦‚æ¨¡å‹æ¶æ„ã€ä½ç½®ç¼–ç å’Œæ¿€æ´»å‡½æ•°ç­‰ï¼Œå°šæœªå¾—åˆ°å……åˆ†ç ”ç©¶ï¼Œé˜»ç¢äº†INRçš„è¿›ä¸€æ­¥å‘å±•ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªå…¨é¢çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œé€šè¿‡ç³»ç»Ÿåœ°è¯„ä¼°ä¸åŒINRæ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œæ¥æ­ç¤ºå½±å“INRæ€§èƒ½çš„å…³é”®å› ç´ ã€‚è¯¥åŸºå‡†åŒ…æ‹¬å¤šç§æ¨¡å‹å˜ä½“ï¼ˆMLPå’ŒKANï¼‰ã€ä½ç½®ç¼–ç å’Œæ¿€æ´»å‡½æ•°ï¼Œä»¥åŠæ¶µç›–æ­£å‘å’Œé€†å‘é—®é¢˜çš„å¤šä¸ªä»»åŠ¡ï¼Œä»è€Œæä¾›ä¸€ä¸ªå…¬å¹³å’Œå…¨é¢çš„æ¯”è¾ƒå¹³å°ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šINR-BenchåŸºå‡†æµ‹è¯•å¹³å°ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **æ¨¡å‹åº“**ï¼šåŒ…å«å¤šç§Coordinate-MLPå’ŒCoordinate-KANæ¨¡å‹å˜ä½“ï¼Œæ¶µç›–ä¸åŒçš„ä½ç½®ç¼–ç å’Œæ¿€æ´»å‡½æ•°ã€‚2) **ä»»åŠ¡åº“**ï¼šåŒ…å«9ä¸ªéšå¼å¤šæ¨¡æ€ä»»åŠ¡ï¼Œæ¶µç›–å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šç§æ•°æ®ç±»å‹ï¼Œä»¥åŠæ­£å‘å’Œé€†å‘é—®é¢˜ã€‚3) **è¯„ä¼°æŒ‡æ ‡**ï¼šé‡‡ç”¨æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚PSNRã€SSIMç­‰ï¼Œæ¥è¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚4) **è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹**ï¼šæä¾›è‡ªåŠ¨åŒ–çš„è¯„ä¼°æµç¨‹ï¼Œæ–¹ä¾¿ç ”ç©¶äººå‘˜å¿«é€Ÿè¯„ä¼°å’Œæ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šINR-Benchçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»¼åˆæ€§å’Œç³»ç»Ÿæ€§ã€‚å®ƒæ˜¯ç¬¬ä¸€ä¸ªä¸“é—¨ä¸ºå¤šæ¨¡æ€INRä»»åŠ¡è®¾è®¡çš„ç»¼åˆåŸºå‡†ï¼Œæ¶µç›–äº†å¤šç§æ¨¡å‹å˜ä½“ã€ä½ç½®ç¼–ç ã€æ¿€æ´»å‡½æ•°å’Œä»»åŠ¡ç±»å‹ã€‚é€šè¿‡ç³»ç»Ÿåœ°è¯„ä¼°ä¸åŒæ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼ŒINR-Benchå¯ä»¥å¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£å½±å“INRæ€§èƒ½çš„å…³é”®å› ç´ ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡è€ƒè™‘äº†ç»å…¸çš„MLPå’Œæ–°å…´çš„KANæ¶æ„ï¼Œå¹¶é’ˆå¯¹æ¯ç§æ¶æ„è®¾è®¡äº†å¤šç§å˜ä½“ï¼Œä¾‹å¦‚ä¸åŒçš„å±‚æ•°ã€ç¥ç»å…ƒæ•°é‡ã€ä½ç½®ç¼–ç å’Œæ¿€æ´»å‡½æ•°ã€‚åœ¨ä»»åŠ¡è®¾è®¡æ–¹é¢ï¼Œè®ºæ–‡é€‰æ‹©äº†æ¶µç›–å›¾åƒã€éŸ³é¢‘ã€è§†é¢‘ç­‰å¤šç§æ•°æ®ç±»å‹çš„9ä¸ªéšå¼å¤šæ¨¡æ€ä»»åŠ¡ï¼Œå¹¶æ¶µç›–äº†æ­£å‘å’Œé€†å‘é—®é¢˜ã€‚åœ¨è¯„ä¼°æŒ‡æ ‡æ–¹é¢ï¼Œè®ºæ–‡é‡‡ç”¨äº†æ ‡å‡†åŒ–çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚PSNRã€SSIMç­‰ï¼Œä»¥ç¡®ä¿è¯„ä¼°ç»“æœçš„å…¬å¹³æ€§å’Œå¯æ¯”æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒçš„æ¨¡å‹æ¶æ„ã€ä½ç½®ç¼–ç å’Œæ¿€æ´»å‡½æ•°å¯¹INRçš„æ€§èƒ½æœ‰æ˜¾è‘—å½±å“ã€‚ä¾‹å¦‚ï¼ŒKANæ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šä¼˜äºMLPæ¨¡å‹ï¼Œè€ŒæŸäº›ä½ç½®ç¼–ç å¯ä»¥æé«˜æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦å’Œç²¾åº¦ã€‚INR-Benchæä¾›äº†ä¸€ä¸ªå¹³å°ï¼Œå¯ä»¥ç³»ç»Ÿåœ°è¯„ä¼°è¿™äº›å› ç´ çš„å½±å“ï¼Œå¹¶ä¸ºæœªæ¥çš„ç ”ç©¶æä¾›æŒ‡å¯¼ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

INR-Benchå¯å¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘å¤„ç†ã€æœºå™¨äººç­‰é¢†åŸŸã€‚é€šè¿‡è¯¥åŸºå‡†ï¼Œç ”ç©¶äººå‘˜å¯ä»¥æ›´å¥½åœ°ç†è§£ä¸åŒINRæ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä»è€Œé€‰æ‹©åˆé€‚çš„æ¨¡å‹å’Œé…ç½®ï¼Œæé«˜ç›¸å…³åº”ç”¨çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒINR-Benchè¿˜å¯ä»¥ä¿ƒè¿›æ–°çš„INRæ¨¡å‹å’ŒæŠ€æœ¯çš„å¼€å‘ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Implicit Neural Representations (INRs) have gained success in various signal processing tasks due to their advantages of continuity and infinite resolution. However, the factors influencing their effectiveness and limitations remain underexplored. To better understand these factors, we leverage insights from Neural Tangent Kernel (NTK) theory to analyze how model architectures (classic MLP and emerging KAN), positional encoding, and nonlinear primitives affect the response to signals of varying frequencies. Building on this analysis, we introduce INR-Bench, the first comprehensive benchmark specifically designed for multimodal INR tasks. It includes 56 variants of Coordinate-MLP models (featuring 4 types of positional encoding and 14 activation functions) and 22 Coordinate-KAN models with distinct basis functions, evaluated across 9 implicit multimodal tasks. These tasks cover both forward and inverse problems, offering a robust platform to highlight the strengths and limitations of different neural models, thereby establishing a solid foundation for future research. The code and dataset are available at https://github.com/lif314/INR-Bench.

