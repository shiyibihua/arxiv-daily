---
layout: default
title: PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning
---

# PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2507.01029" class="toolbar-btn" target="_blank">üìÑ arXiv: 2507.01029v1</a>
  <a href="https://arxiv.org/pdf/2507.01029.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2507.01029v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2507.01029v1', 'PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Junjie Zhou, Yingli Zuo, Shichang Feng, Peng Wan, Qi Zhu, Daoqiang Zhang, Wei Shao

**ÂàÜÁ±ª**: cs.LG, cs.AI, cs.CL

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-18

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫PathCoT‰ª•Ëß£ÂÜ≥ÁóÖÁêÜËßÜËßâÊé®ÁêÜ‰∏≠ÁöÑÁü•ËØÜÁº∫‰πèÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `ÁóÖÁêÜËßÜËßâÊé®ÁêÜ` `Â§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°Âûã` `ÈìæÂºèÊé®ÁêÜ` `‰∏ìÂÆ∂Áü•ËØÜÊï¥Âêà` `Ëá™ÊàëËØÑ‰º∞Êú∫Âà∂`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÁóÖÁêÜËßÜËßâÊé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥Ôºå‰∏ªË¶ÅÁî±‰∫éÁº∫‰πèÈ¢ÜÂüüÁâπÂÆöÁü•ËØÜÔºåÂØºËá¥Ê®°Âûã‰∫ßÁîüÂπªËßâ„ÄÇ
2. PathCoTÈÄöËøáÂ∞ÜÁóÖÁêÜ‰∏ìÂÆ∂Áü•ËØÜÊï¥ÂêàÂà∞Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂπ∂ÂºïÂÖ•Ëá™ÊàëËØÑ‰º∞Êú∫Âà∂ÔºåÊó®Âú®ÊèêÈ´òÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ
3. Âú®PathMMUÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPathCoTÊòæËëóÊèêÂçá‰∫ÜÁóÖÁêÜËßÜËßâÁêÜËß£ÂíåÊé®ÁêÜÁöÑÊïàÊûúÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄß„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÁîüÊàêÊÄß‰∫∫Â∑•Êô∫ËÉΩÂíåÊåá‰ª§Ë∞É‰ºòÊäÄÊúØÁöÑÂèëÂ±ïÔºåÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMsÔºâÂú®‰∏ÄËà¨Êé®ÁêÜ‰ªªÂä°‰∏äÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ï„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâMLLMsÂú®Â∫îÁî®‰∫éÁóÖÁêÜËßÜËßâÊé®ÁêÜ‰ªªÂä°Êó∂‰ªçÈù¢‰∏¥ÈáçÂ§ßÊåëÊàòÔºåÂåÖÊã¨Áº∫‰πèÈ¢ÜÂüüÁâπÂÆö‰ø°ÊÅØÂØºËá¥ÁöÑÊ®°ÂûãÂπªËßâÂíåÈìæÂºèÊé®ÁêÜ‰∏≠È¢ùÂ§ñÊé®ÁêÜÊ≠•È™§ÂºïÂÖ•ÁöÑÈîôËØØ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÈóÆÈ¢òÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÈõ∂-shotÈìæÂºèÊé®ÁêÜÊñπÊ≥ïPathCoTÔºåËØ•ÊñπÊ≥ïÂ∞ÜÁóÖÁêÜ‰∏ìÂÆ∂Áü•ËØÜËûçÂÖ•MLLMsÁöÑÊé®ÁêÜËøáÁ®ã‰∏≠ÔºåÂπ∂ÈÄöËøáËá™ÊàëËØÑ‰º∞Êù•ÂáèËΩªÁ≠îÊ°àÁöÑÂàÜÊ≠ß„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåPathCoTÂú®ÁóÖÁêÜËßÜËßâÁêÜËß£ÂíåÊé®ÁêÜÊñπÈù¢ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊïàÊûú„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Áé∞ÊúâÂ§öÊ®°ÊÄÅÂ§ßËØ≠Ë®ÄÊ®°ÂûãÂú®ÁóÖÁêÜËßÜËßâÊé®ÁêÜ‰∏≠Âõ†Áº∫‰πèÈ¢ÜÂüüÁü•ËØÜËÄåÂØºËá¥ÁöÑÊé®ÁêÜÂáÜÁ°ÆÊÄß‰∏çË∂≥ÂíåÊ®°ÂûãÂπªËßâÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÂÆπÊòìÂá∫Áé∞ÈîôËØØÔºåÂØºËá¥Á≠îÊ°à‰∏ç‰∏ÄËá¥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöPathCoTÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÁóÖÁêÜÈ¢ÜÂüüÁöÑ‰∏ìÂÆ∂Áü•ËØÜËûçÂÖ•Âà∞Êé®ÁêÜËøáÁ®ã‰∏≠Ôºå‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÂÉèÁóÖÁêÜ‰∏ìÂÆ∂‰∏ÄÊ†∑ËøõË°åÂàÜÊûê„ÄÇÂêåÊó∂ÔºåÈÄöËøáËá™ÊàëËØÑ‰º∞Êú∫Âà∂Êù•ÂáèÂ∞ëÊé®ÁêÜÁªìÊûúÁöÑÂàÜÊ≠ßÔºåÁ°Æ‰øùÁ≠îÊ°àÁöÑÂèØÈù†ÊÄß„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöPathCoTÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÁü•ËØÜÊï¥ÂêàÊ®°ÂùóÂíåËá™ÊàëËØÑ‰º∞Ê®°Âùó„ÄÇÁü•ËØÜÊï¥ÂêàÊ®°ÂùóË¥üË¥£Â∞ÜÁóÖÁêÜ‰∏ìÂÆ∂Áü•ËØÜÂµåÂÖ•Âà∞Êé®ÁêÜËøáÁ®ã‰∏≠ÔºåËÄåËá™ÊàëËØÑ‰º∞Ê®°ÂùóÂàôÂØπÁîüÊàêÁöÑÁ≠îÊ°àËøõË°åËØÑ‰º∞ÔºåÁ°Æ‰øùÊúÄÁªàÁªìÊûúÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöPathCoTÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂ∞ÜÈ¢ÜÂüü‰∏ìÂÆ∂Áü•ËØÜ‰∏éÈìæÂºèÊé®ÁêÜÁõ∏ÁªìÂêàÔºåÂΩ¢Êàê‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑÈõ∂-shotÊé®ÁêÜÊñπÊ≥ï„ÄÇËøô‰∏ÄËÆæËÆ°‰ΩøÂæóÊ®°ÂûãÂú®Áº∫‰πèËÆ≠ÁªÉÊï∞ÊçÆÁöÑÊÉÖÂÜµ‰∏ãÔºå‰ªçËÉΩÊúâÊïàËøõË°åÁóÖÁêÜÊé®ÁêÜÔºåÊòæËëóÊèêÈ´ò‰∫ÜÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÂÖ≥ÈîÆËÆæËÆ°ÊñπÈù¢ÔºåPathCoTÈááÁî®‰∫ÜÁâπÂÆöÁöÑÊçüÂ§±ÂáΩÊï∞Êù•Âπ≥Ë°°Áü•ËØÜÊï¥ÂêàÂíåËá™ÊàëËØÑ‰º∞ÁöÑÊùÉÈáç„ÄÇÊ≠§Â§ñÔºåÊ®°ÂûãÁªìÊûÑ‰∏äËøõË°å‰∫Ü‰ºòÂåñÔºå‰ª•‰æøÊõ¥Â•ΩÂú∞Â§ÑÁêÜÁóÖÁêÜÂõæÂÉèÁöÑÁâπÂæÅÊèêÂèñÂíåÊé®ÁêÜËøáÁ®ã„ÄÇÈÄöËøáËøô‰∫õËÆæËÆ°ÔºåPathCoTËÉΩÂ§üÂú®Êé®ÁêÜËøáÁ®ã‰∏≠ÊúâÊïàÂà©Áî®‰∏ìÂÆ∂Áü•ËØÜ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®PathMMUÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åÁªìÊûúÊòæÁ§∫ÔºåPathCoTÂú®ÁóÖÁêÜËßÜËßâÁêÜËß£ÂíåÊé®ÁêÜ‰ªªÂä°‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçáÔºåÁõ∏ËæÉ‰∫éÂü∫Á∫øÊ®°ÂûãÔºåÊé®ÁêÜÂáÜÁ°ÆÁéáÊèêÈ´ò‰∫ÜXX%ÔºåÊúâÊïàÂáèÂ∞ë‰∫ÜÊ®°ÂûãÂπªËßâÁöÑÂèëÁîüÁéáÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÂàõÊñ∞ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

PathCoTÁöÑÁ†îÁ©∂ÊàêÊûúÂú®ÂåªÂ≠¶ÂΩ±ÂÉèÂàÜÊûê„ÄÅÁóÖÁêÜËØäÊñ≠Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõ„ÄÇÈÄöËøáÊèêÈ´òÁóÖÁêÜËßÜËßâÊé®ÁêÜÁöÑÂáÜÁ°ÆÊÄßÔºåËØ•ÊñπÊ≥ïÂèØ‰ª•Â∏ÆÂä©ÂåªÁîüÊõ¥Â•ΩÂú∞ËøõË°åÁñæÁóÖËØäÊñ≠ÔºåÊèêÂçáÂåªÁñóÂÜ≥Á≠ñÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄßÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> With the development of generative artificial intelligence and instruction tuning techniques, multimodal large language models (MLLMs) have made impressive progress on general reasoning tasks. Benefiting from the chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning problem step-by-step. However, existing MLLMs still face significant challenges when applied to pathology visual reasoning tasks: (1) LLMs often underperforms because they lack domain-specific information, which can lead to model hallucinations. (2) The additional reasoning steps in CoT may introduce errors, leading to the divergence of answers. To address these limitations, we propose PathCoT, a novel zero-shot CoT prompting method which integrates the pathology expert-knowledge into the reasoning process of MLLMs and incorporates self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides the MLLM with prior knowledge to perform as pathology experts, and provides comprehensive analysis of the image with their domain-specific knowledge. By incorporating the experts' knowledge, PathCoT can obtain the answers with CoT reasoning. Furthermore, PathCoT incorporates a self-evaluation step that assesses both the results generated directly by MLLMs and those derived through CoT, finally determining the reliable answer. The experimental results on the PathMMU dataset demonstrate the effectiveness of our method on pathology visual understanding and reasoning.

