---
layout: default
title: HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models
---

# HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15065" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2506.15065v2</a>
  <a href="https://arxiv.org/pdf/2506.15065.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15065v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15065v2', 'HEAL: An Empirical Study on Hallucinations in Embodied Agents Driven by Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Trishna Chakraborty, Udita Ghosh, Xiaopan Zhang, Fahim Faisal Niloy, Yue Dong, Jiachen Li, Amit K. Roy-Chowdhury, Chengyu Song

**åˆ†ç±»**: cs.LG, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-06-18 (æ›´æ–°: 2025-10-14)

**å¤‡æ³¨**: Accepted by EMNLP 2025 Findings

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç³»ç»Ÿæ€§ç ”ç©¶ä»¥è§£å†³å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…·èº«æ™ºèƒ½ä½“çš„å¹»è§‰é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å…·èº«æ™ºèƒ½ä½“` `å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰ç°è±¡` `åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´` `ç³»ç»Ÿæ€§ç ”ç©¶` `æ¨¡å‹è¯„ä¼°` `å¯¼èˆªé”™è¯¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å…·èº«æ™ºèƒ½ä½“åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤æ—¶ï¼Œå¸¸å› æœªèƒ½å°†æŒ‡ä»¤ä¸è§‚å¯Ÿåˆ°çš„ç‰©ç†ç¯å¢ƒç›¸ç»“åˆè€Œäº§ç”Ÿå¹»è§‰ï¼Œå¯¼è‡´å¯¼èˆªé”™è¯¯ã€‚
2. è®ºæ–‡é€šè¿‡æ„å»ºä¸€ä¸ªæ–°çš„æ¢æµ‹é›†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°äº†å¹»è§‰ç°è±¡çš„å‘ç”Ÿæƒ…å†µåŠå…¶è§¦å‘å› ç´ ï¼Œæ—¨åœ¨æ­ç¤ºæ¨¡å‹çš„å±€é™æ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå°½ç®¡æ¨¡å‹åœ¨æ¨ç†ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é¢å¯¹åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´æ—¶ï¼Œä»æ— æ³•æœ‰æ•ˆè§£å†³é—®é¢˜ï¼Œçªæ˜¾äº†å…¶åŸºæœ¬å±€é™æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é€æ¸æˆä¸ºå…·èº«æ™ºèƒ½ä½“çš„è®¤çŸ¥æ ¸å¿ƒï¼Œå¹»è§‰ç°è±¡çš„å‡ºç°å¼•å‘äº†å¯¼èˆªé”™è¯¯ï¼Œä¾‹å¦‚å¯»æ‰¾ä¸å­˜åœ¨çš„å†°ç®±ã€‚æœ¬æ–‡é¦–æ¬¡ç³»ç»Ÿæ€§ç ”ç©¶äº†åœ¨åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´æƒ…å†µä¸‹ï¼ŒLLMé©±åŠ¨çš„å…·èº«æ™ºèƒ½ä½“åœ¨æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡æ—¶çš„å¹»è§‰ç°è±¡ã€‚ç ”ç©¶æ—¨åœ¨æ¢è®¨å¹»è§‰çš„å‘ç”Ÿç¨‹åº¦ã€è§¦å‘ç±»å‹åŠå½“å‰æ¨¡å‹çš„å“åº”ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªèƒ½å¤Ÿè¯±å‘é«˜è¾¾40å€å¹»è§‰ç‡çš„æ¢æµ‹é›†ï¼Œè¯„ä¼°äº†12ä¸ªæ¨¡å‹åœ¨ä¸¤ä¸ªæ¨¡æ‹Ÿç¯å¢ƒä¸­çš„è¡¨ç°ï¼Œå‘ç°æ¨¡å‹åœ¨æ¨ç†ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†ä¸å¯è¡Œä»»åŠ¡æ—¶å­˜åœ¨æ ¹æœ¬æ€§å±€é™ã€‚æˆ‘ä»¬è¿˜æä¾›äº†é’ˆå¯¹æ¯ç§åœºæ™¯çš„ç†æƒ³æ¨¡å‹è¡Œä¸ºçš„å¯æ“ä½œæ€§è§è§£ï¼Œä»¥æŒ‡å¯¼æ›´ç¨³å¥çš„è§„åˆ’ç­–ç•¥çš„å¼€å‘ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…·èº«æ™ºèƒ½ä½“åœ¨æ‰§è¡Œé•¿æ—¶é—´ä»»åŠ¡æ—¶å› åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´è€Œäº§ç”Ÿçš„å¹»è§‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†ç”¨æˆ·æŒ‡ä»¤ä¸ç‰©ç†ç¯å¢ƒçš„ç»“åˆä¸Šå­˜åœ¨æ˜æ˜¾ä¸è¶³ï¼Œå¯¼è‡´å¯¼èˆªé”™è¯¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ„å»ºä¸€ä¸ªæ–°çš„å¹»è§‰æ¢æµ‹é›†ï¼Œç³»ç»Ÿæ€§åœ°è¯„ä¼°ä¸åŒæ¨¡å‹åœ¨é¢å¯¹åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´æ—¶çš„è¡¨ç°ï¼Œæ­ç¤ºå…¶å±€é™æ€§å¹¶æä¾›æ”¹è¿›å»ºè®®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†ä¸¤ä¸ªæ¨¡æ‹Ÿç¯å¢ƒï¼Œè¯„ä¼°äº†12ä¸ªä¸åŒçš„æ¨¡å‹ã€‚æ¢æµ‹é›†è®¾è®¡æ—¨åœ¨è¯±å‘é«˜è¾¾40å€çš„å¹»è§‰ç‡ï¼Œä»¥ä¾¿æ·±å…¥åˆ†ææ¨¡å‹çš„ååº”å’Œæ¨ç†èƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„å…³é”®åˆ›æ–°åœ¨äºé¦–æ¬¡ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†LLMé©±åŠ¨çš„å…·èº«æ™ºèƒ½ä½“çš„å¹»è§‰ç°è±¡ï¼Œå¹¶æä¾›äº†é’ˆå¯¹ä¸åŒåœºæ™¯çš„ç†æƒ³æ¨¡å‹è¡Œä¸ºæŒ‡å¯¼ï¼Œè¿™åœ¨ç°æœ‰æ–‡çŒ®ä¸­å°šå±é¦–æ¬¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œè®¾è®¡äº†ç‰¹å®šçš„å‚æ•°è®¾ç½®å’Œè¯„ä¼°æ ‡å‡†ï¼Œä»¥ç¡®ä¿æ¢æµ‹é›†çš„æœ‰æ•ˆæ€§å’Œæ¨¡å‹è¯„ä¼°çš„å‡†ç¡®æ€§ï¼Œå…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹åœ¨æ¨ç†æ–¹é¢è¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨å¤„ç†åœºæ™¯ä¸ä»»åŠ¡ä¸ä¸€è‡´æ—¶ï¼Œå¹»è§‰ç°è±¡çš„å‘ç”Ÿç‡é«˜è¾¾40å€ï¼Œæ˜¾ç¤ºå‡ºå½“å‰æ¨¡å‹åœ¨åº”å¯¹å¤æ‚ä»»åŠ¡æ—¶çš„åŸºæœ¬å±€é™æ€§ã€‚è¿™ä¸€å‘ç°ä¸ºæœªæ¥æ¨¡å‹çš„æ”¹è¿›æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€æœåŠ¡æœºå™¨äººåŠè™šæ‹ŸåŠ©æ‰‹ç­‰ï¼Œèƒ½å¤Ÿå¸®åŠ©æå‡å…·èº«æ™ºèƒ½ä½“åœ¨å¤æ‚ç¯å¢ƒä¸­çš„å¯¼èˆªå’Œä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ã€‚é€šè¿‡å‡å°‘å¹»è§‰ç°è±¡ï¼Œæœªæ¥çš„æ™ºèƒ½ä½“å°†æ›´åŠ å¯é ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å’Œæ‰§è¡Œç”¨æˆ·æŒ‡ä»¤ï¼Œä»è€Œæé«˜ç”¨æˆ·ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Large language models (LLMs) are increasingly being adopted as the cognitive core of embodied agents. However, inherited hallucinations, which stem from failures to ground user instructions in the observed physical environment, can lead to navigation errors, such as searching for a refrigerator that does not exist. In this paper, we present the first systematic study of hallucinations in LLM-based embodied agents performing long-horizon tasks under scene-task inconsistencies. Our goal is to understand to what extent hallucinations occur, what types of inconsistencies trigger them, and how current models respond. To achieve these goals, we construct a hallucination probing set by building on an existing benchmark, capable of inducing hallucination rates up to 40x higher than base prompts. Evaluating 12 models across two simulation environments, we find that while models exhibit reasoning, they fail to resolve scene-task inconsistencies-highlighting fundamental limitations in handling infeasible tasks. We also provide actionable insights on ideal model behavior for each scenario, offering guidance for developing more robust and reliable planning strategies.

