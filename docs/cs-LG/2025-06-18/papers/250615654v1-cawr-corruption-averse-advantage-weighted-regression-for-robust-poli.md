---
layout: default
title: CAWR: Corruption-Averse Advantage-Weighted Regression for Robust Policy Optimization
---

# CAWR: Corruption-Averse Advantage-Weighted Regression for Robust Policy Optimization

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2506.15654" class="toolbar-btn" target="_blank">üìÑ arXiv: 2506.15654v1</a>
  <a href="https://arxiv.org/pdf/2506.15654.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2506.15654v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2506.15654v1', 'CAWR: Corruption-Averse Advantage-Weighted Regression for Robust Policy Optimization')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Ranting Hu

**ÂàÜÁ±ª**: cs.LG

**ÂèëÂ∏ÉÊó•Êúü**: 2025-06-18

**Â§áÊ≥®**: 23 pages, 14 figures

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫CAWR‰ª•Ëß£ÂÜ≥Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†‰∏≠ÁöÑÊï∞ÊçÆËÖêËöÄÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†` `‰ºòÂäøÂä†ÊùÉÂõûÂΩí` `Êï∞ÊçÆËÖêËöÄ` `Á≠ñÁï•‰ºòÂåñ` `È≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞` `‰ºòÂÖàÁªèÈ™åÂõûÊîæ` `Êú∫Âô®Â≠¶‰π†` `‰∫∫Â∑•Êô∫ËÉΩ`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑ‰ºòÂäøÂä†ÊùÉÂõûÂΩíÊñπÊ≥ïÂú®Èù¢ÂØπÁ¶ªÁ∫øÊï∞ÊçÆÊó∂ÔºåÂÆπÊòìÂõ†Êï∞ÊçÆËÖêËöÄËÄåÂ≠¶‰π†Âà∞Ëøá‰∫é‰øùÂÆàÁöÑÁ≠ñÁï•ÔºåÂØºËá¥ÊÄßËÉΩ‰∏ãÈôç„ÄÇ
2. Êú¨ÊñáÊèêÂá∫ËÖêËöÄÊäóÊÄß‰ºòÂäøÂä†ÊùÉÂõûÂΩíÔºàCAWRÔºâÔºåÈÄöËøáÂºïÂÖ•È≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞Âíå‰ºòÂÖàÁªèÈ™åÂõûÊîæÊú∫Âà∂ÔºåÊù•ËøáÊª§Á≥üÁ≥ïÁöÑÊé¢Á¥¢Êï∞ÊçÆ„ÄÇ
3. Âú®D4RLÂü∫ÂáÜÊµãËØï‰∏≠ÁöÑÊï∞ÂÄºÂÆûÈ™åË°®ÊòéÔºåCAWRËÉΩÂ§üÊúâÊïàÊèêÂçá‰ªéÊ¨°‰ºòÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠Â≠¶‰π†ÁöÑÁ≠ñÁï•ÊÄßËÉΩÔºåÊòæËëó‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ï„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïÈÄöÂ∏∏ÈúÄË¶ÅÈ¢ùÂ§ñÁöÑÁ∫¶ÊùüÊàñÊÉ©ÁΩöÈ°πÊù•Â∫îÂØπÂàÜÂ∏ÉÂÅèÁßªÈóÆÈ¢ò„ÄÇÊú¨ÊñáËÅöÁÑ¶‰∫é‰ºòÂäøÂä†ÊùÉÂõûÂΩíÔºàAWRÔºâÂÆ∂ÊóèÁöÑ‰∏Ä‰∏™Â±ÄÈôêÊÄßÔºåÂç≥Áî±‰∫éÊï∞ÊçÆËÖêËöÄÂèØËÉΩÂØºËá¥Â≠¶‰π†Ëøá‰∫é‰øùÂÆàÁöÑÁ≠ñÁï•„ÄÇÊàë‰ª¨‰ªé‰∏§‰∏™ËßíÂ∫¶Á†îÁ©∂Ëøô‰∏ÄÈóÆÈ¢òÔºö‰∏ÄÊòØÁ≥üÁ≥ïÊé¢Á¥¢Â¶Ç‰ΩïÂΩ±ÂìçÂü∫‰∫éKLÊï£Â∫¶ÁöÑÁêÜËÆ∫ÊúÄ‰ºòÁ≠ñÁï•Ôºå‰∫åÊòØÁ≥üÁ≥ïÊé¢Á¥¢Â¶Ç‰ΩïÂΩ±ÂìçÁêÜËÆ∫ÊúÄ‰ºòÁ≠ñÁï•ÁöÑËøë‰ºº„ÄÇÊàë‰ª¨ËØÅÊòéÔºåËøá‰∫é‰øùÂÆà‰∏ªË¶ÅÊ∫ê‰∫éÊçüÂ§±ÂáΩÊï∞ÂØπÁ≥üÁ≥ïÊé¢Á¥¢ÁöÑÊïèÊÑüÊÄßÂèäÁ¶ªÁ∫øÊï∞ÊçÆÈõÜ‰∏≠Á≥üÁ≥ïÊé¢Á¥¢ÁöÑÊØî‰æã„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÊèêÂá∫‰∫ÜËÖêËöÄÊäóÊÄß‰ºòÂäøÂä†ÊùÉÂõûÂΩíÔºàCAWRÔºâÔºåÂú®Á≠ñÁï•‰ºòÂåñ‰∏≠ÂºïÂÖ•‰∫Ü‰∏ÄÁªÑÈ≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞ÔºåÂπ∂ÈááÁî®Âü∫‰∫é‰ºòÂäøÁöÑ‰ºòÂÖàÁªèÈ™åÂõûÊîæÊñπÊ≥ïÊù•ËøáÊª§Á≥üÁ≥ïÊé¢Á¥¢„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§ü‰ªéÊ¨°‰ºòÁ¶ªÁ∫øÊï∞ÊçÆ‰∏≠Â≠¶‰π†Âà∞Êõ¥‰ºòÁöÑÁ≠ñÁï•ÔºåÊòæËëóÊèêÂçá‰∫ÜÁ≠ñÁï•‰ºòÂåñÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáË¶ÅËß£ÂÜ≥ÁöÑÈóÆÈ¢òÊòØÁ¶ªÁ∫øÂº∫ÂåñÂ≠¶‰π†‰∏≠Áî±‰∫éÊï∞ÊçÆËÖêËöÄÂØºËá¥ÁöÑÁ≠ñÁï•Ëøá‰∫é‰øùÂÆàÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÁöÑ‰ºòÂäøÂä†ÊùÉÂõûÂΩíÊñπÊ≥ïÂú®Â§ÑÁêÜÁ≥üÁ≥ïÊé¢Á¥¢Êó∂Ë°®Áé∞‰∏ç‰Ω≥ÔºåÂÆπÊòìÂØºËá¥Á≠ñÁï•ÊÄßËÉΩ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂºïÂÖ•È≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞Âíå‰ºòÂÖàÁªèÈ™åÂõûÊîæÊú∫Âà∂ÔºåÊù•ÂáèÂ∞ëÁ≥üÁ≥ïÊé¢Á¥¢ÂØπÁ≠ñÁï•‰ºòÂåñÁöÑË¥üÈù¢ÂΩ±ÂìçÔºå‰ªéËÄåÊèêÈ´òÁ≠ñÁï•ÁöÑÂ≠¶‰π†ÊïàÊûú„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö‰∏ÄÊòØÈ≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°Ôºå‰∫åÊòØÂü∫‰∫é‰ºòÂäøÁöÑ‰ºòÂÖàÁªèÈ™åÂõûÊîæÊñπÊ≥ï„ÄÇÈ≤ÅÊ£íÊçüÂ§±ÂáΩÊï∞Áî®‰∫é‰ºòÂåñÁ≠ñÁï•ÔºåËÄå‰ºòÂÖàÁªèÈ™åÂõûÊîæÂàôÁî®‰∫éÁ≠õÈÄâÂá∫ÊúâÊïàÁöÑËÆ≠ÁªÉÊ†∑Êú¨„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊúÄÈáçË¶ÅÁöÑÊäÄÊúØÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫ÜËÖêËöÄÊäóÊÄßÊçüÂ§±ÂáΩÊï∞ÔºåËÉΩÂ§üÊúâÊïàÈôç‰ΩéÁ≥üÁ≥ïÊé¢Á¥¢ÂØπÁ≠ñÁï•‰ºòÂåñÁöÑÂΩ±ÂìçÔºåËøô‰∏éÁé∞ÊúâÊñπÊ≥ïÁöÑËÆæËÆ°ÊÄùË∑ØÊúâÊú¨Ë¥®Âå∫Âà´„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÊçüÂ§±ÂáΩÊï∞ÁöÑËÆæËÆ°‰∏äÔºåÈááÁî®‰∫ÜÂØπÁ≥üÁ≥ïÊé¢Á¥¢ÂÖ∑ÊúâÈ≤ÅÊ£íÊÄßÁöÑÂΩ¢ÂºèÔºåÂπ∂Âú®‰ºòÂÖàÁªèÈ™åÂõûÊîæ‰∏≠ÂºïÂÖ•‰∫ÜÂü∫‰∫é‰ºòÂäøÁöÑÈÄâÊã©Êú∫Âà∂Ôºå‰ª•Á°Æ‰øùËÆ≠ÁªÉÊ†∑Êú¨ÁöÑË¥®Èáè„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

Âú®D4RLÂü∫ÂáÜÊµãËØï‰∏≠ÔºåCAWRÊñπÊ≥ïÂú®Ê¨°‰ºòÁ¶ªÁ∫øÊï∞ÊçÆ‰∏äË°®Áé∞Âá∫Ëâ≤ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüAWRÊñπÊ≥ïÔºåÁ≠ñÁï•ÊÄßËÉΩÊèêÂçáÂπÖÂ∫¶ËææÂà∞20%‰ª•‰∏äÔºåÂ±ïÁ§∫‰∫ÜÂÖ∂Âú®Â§çÊùÇÁéØÂ¢É‰∏ãÁöÑÊúâÊïàÊÄßÂíåÈ≤ÅÊ£íÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÁöÑÊΩúÂú®Â∫îÁî®È¢ÜÂüüÂåÖÊã¨Êú∫Âô®‰∫∫ÊéßÂà∂„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊ∏∏ÊàèÊô∫ËÉΩ‰ΩìÁ≠âÔºåÂ∞§ÂÖ∂ÊòØÂú®Êï∞ÊçÆÊî∂ÈõÜÊàêÊú¨È´òÊòÇÊàñÁéØÂ¢ÉÂ§çÊùÇÁöÑÂú∫ÊôØ‰∏≠ÔºåCAWRËÉΩÂ§üÊúâÊïàÊèêÂçáÁ≠ñÁï•ÁöÑÂ≠¶‰π†ÊïàÁéáÂíåÊÄßËÉΩÔºåÂÖ∑ÊúâÈáçË¶ÅÁöÑÂÆûÈôÖ‰ª∑ÂÄºÂíåÊú™Êù•ÂΩ±Âìç„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Offline reinforcement learning (offline RL) algorithms often require additional constraints or penalty terms to address distribution shift issues, such as adding implicit or explicit policy constraints during policy optimization to reduce the estimation bias of functions. This paper focuses on a limitation of the Advantage-Weighted Regression family (AWRs), i.e., the potential for learning over-conservative policies due to data corruption, specifically the poor explorations in suboptimal offline data. We study it from two perspectives: (1) how poor explorations impact the theoretically optimal policy based on KL divergence, and (2) how such poor explorations affect the approximation of the theoretically optimal policy. We prove that such over-conservatism is mainly caused by the sensitivity of the loss function for policy optimization to poor explorations, and the proportion of poor explorations in offline datasets. To address this concern, we propose Corruption-Averse Advantage-Weighted Regression (CAWR), which incorporates a set of robust loss functions during policy optimization and an advantage-based prioritized experience replay method to filter out poor explorations. Numerical experiments on the D4RL benchmark show that our method can learn superior policies from suboptimal offline data, significantly enhancing the performance of policy optimization.

