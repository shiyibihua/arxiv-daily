---
layout: default
title: (DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems
---

# (DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19318" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19318v2</a>
  <a href="https://arxiv.org/pdf/2508.19318.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19318v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19318v2', '(DEMO) Deep Reinforcement Learning Based Resource Allocation in Distributed IoT Systems')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Aohan Li, Miyu Tsuzuki

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-09-21)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„èµ„æºåˆ†é…æ¡†æ¶ä»¥è§£å†³åˆ†å¸ƒå¼ç‰©è”ç½‘ç³»ç»Ÿé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æ·±åº¦å¼ºåŒ–å­¦ä¹ ` `èµ„æºåˆ†é…` `åˆ†å¸ƒå¼ç‰©è”ç½‘` `é€šä¿¡ä¿¡é“é€‰æ‹©` `åé¦ˆå­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç ”ç©¶å¯¹æ·±åº¦å¼ºåŒ–å­¦ä¹ åœ¨åˆ†å¸ƒå¼ç‰©è”ç½‘ç³»ç»Ÿä¸­çš„åº”ç”¨æ¢ç´¢æœ‰é™ï¼Œå°¤å…¶æ˜¯åœ¨çœŸå®æ•°æ®è®­ç»ƒæ–¹é¢å­˜åœ¨ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œä½¿IoTè®¾å¤‡èƒ½å¤Ÿé€šè¿‡æ·±åº¦å¼ºåŒ–å­¦ä¹ é€‰æ‹©é€šä¿¡ä¿¡é“ï¼Œå¹¶åˆ©ç”¨åé¦ˆä¿¡æ¯è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ¡†æ¶åœ¨å¸§æˆåŠŸç‡ï¼ˆFSRï¼‰æ–¹é¢è¡¨ç°å‡ºè‰²ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰å› å…¶åœ¨å¤æ‚å†³ç­–ä»»åŠ¡ä¸­çš„å¼ºå¤§èƒ½åŠ›è€Œæˆä¸ºèµ„æºåˆ†é…çš„æœ‰æ•ˆæ–¹æ³•ã€‚ç„¶è€Œï¼Œç›®å‰ä»…æœ‰æœ‰é™ç ”ç©¶æ¢è®¨äº†åœ¨å®é™…åˆ†å¸ƒå¼ç‰©è”ç½‘ï¼ˆIoTï¼‰ç³»ç»Ÿä¸­ä½¿ç”¨çœŸå®æ•°æ®è®­ç»ƒDRLæ¨¡å‹ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºåœ¨çœŸå®åˆ†å¸ƒå¼IoTç¯å¢ƒä¸­è®­ç»ƒDRLæ¨¡å‹ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼ŒIoTè®¾å¤‡ä½¿ç”¨åŸºäºDRLçš„æ–¹æ³•é€‰æ‹©é€šä¿¡ä¿¡é“ï¼ŒåŒæ—¶DRLæ¨¡å‹é€šè¿‡åé¦ˆä¿¡æ¯è¿›è¡Œè®­ç»ƒã€‚å…·ä½“è€Œè¨€ï¼ŒACKä¿¡æ¯æ˜¯é€šè¿‡åœ¨æ‰€é€‰ä¿¡é“ä¸Šè¿›è¡Œå®é™…æ•°æ®ä¼ è¾“è·å¾—çš„ã€‚é€šè¿‡å®æ–½å’Œæ€§èƒ½è¯„ä¼°ï¼ˆä»¥å¸§æˆåŠŸç‡FSRä¸ºæŒ‡æ ‡ï¼‰ï¼Œè¯æ˜äº†æ‰€ææ¡†æ¶çš„å¯è¡Œæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨åˆ†å¸ƒå¼ç‰©è”ç½‘ç³»ç»Ÿä¸­ï¼Œå¦‚ä½•æœ‰æ•ˆåœ°è¿›è¡Œèµ„æºåˆ†é…çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨çœŸå®ç¯å¢ƒä¸­è®­ç»ƒæ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹çš„ç ”ç©¶è¾ƒå°‘ï¼Œå¯¼è‡´å…¶åœ¨å®é™…åº”ç”¨ä¸­çš„æ•ˆæœä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡åˆ©ç”¨IoTè®¾å¤‡çš„åé¦ˆä¿¡æ¯ï¼ˆå¦‚ACKä¿¡æ¯ï¼‰ï¼Œå®ç°äº†åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€ä¿¡é“é€‰æ‹©ï¼Œä»è€Œæé«˜äº†èµ„æºåˆ†é…çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®æ”¶é›†æ¨¡å—ã€DRLæ¨¡å‹è®­ç»ƒæ¨¡å—å’Œä¿¡é“é€‰æ‹©æ¨¡å—ã€‚æ•°æ®æ”¶é›†æ¨¡å—è´Ÿè´£è·å–å®é™…ä¼ è¾“æ•°æ®ï¼ŒDRLæ¨¡å‹è®­ç»ƒæ¨¡å—åˆ©ç”¨åé¦ˆä¿¡æ¯è¿›è¡Œå­¦ä¹ ï¼Œä¿¡é“é€‰æ‹©æ¨¡å—åˆ™æ ¹æ®è®­ç»ƒç»“æœè¿›è¡Œå†³ç­–ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ¬ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†çœŸå®æ•°æ®åé¦ˆå¼•å…¥DRLæ¨¡å‹è®­ç»ƒä¸­ï¼Œä½¿å¾—æ¨¡å‹èƒ½å¤Ÿåœ¨å®é™…ç¯å¢ƒä¸­è¿›è¡Œè‡ªé€‚åº”å­¦ä¹ ï¼Œæ˜¾è‘—æå‡äº†èµ„æºåˆ†é…çš„æ•ˆæœã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥ä¼˜åŒ–å¸§æˆåŠŸç‡ï¼Œå¹¶é€šè¿‡è°ƒæ•´ç½‘ç»œç»“æ„å’Œå‚æ•°è®¾ç½®ï¼Œç¡®ä¿æ¨¡å‹åœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„ç¨³å®šæ€§å’Œå“åº”é€Ÿåº¦ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€ææ¡†æ¶åœ¨å¸§æˆåŠŸç‡ï¼ˆFSRï¼‰æ–¹é¢æ˜¾è‘—ä¼˜äºä¼ ç»Ÿæ–¹æ³•ï¼Œå…·ä½“æå‡å¹…åº¦è¾¾åˆ°20%ä»¥ä¸Šï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…åˆ†å¸ƒå¼IoTç¯å¢ƒä¸­çš„æœ‰æ•ˆæ€§å’Œå¯è¡Œæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½å®¶å±…ã€å·¥ä¸šè‡ªåŠ¨åŒ–å’Œæ™ºèƒ½äº¤é€šç­‰åˆ†å¸ƒå¼ç‰©è”ç½‘ç³»ç»Ÿã€‚é€šè¿‡ä¼˜åŒ–èµ„æºåˆ†é…ï¼Œå¯ä»¥æé«˜ç³»ç»Ÿçš„æ•´ä½“æ•ˆç‡å’Œå¯é æ€§ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„å¸‚åœºå‰æ™¯ã€‚æœªæ¥ï¼Œè¯¥æ¡†æ¶æœ‰æœ›æ¨åŠ¨æ›´å¤šåŸºäºæ·±åº¦å­¦ä¹ çš„æ™ºèƒ½å†³ç­–ç³»ç»Ÿçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Deep Reinforcement Learning (DRL) has emerged as an efficient approach to resource allocation due to its strong capability in handling complex decision-making tasks. However, only limited research has explored the training of DRL models with real-world data in practical, distributed Internet of Things (IoT) systems. To bridge this gap, this paper proposes a novel framework for training DRL models in real-world distributed IoT environments. In the proposed framework, IoT devices select communication channels using a DRL-based method, while the DRL model is trained with feedback information. Specifically, Acknowledgment (ACK) information is obtained from actual data transmissions over the selected channels. Implementation and performance evaluation, in terms of Frame Success Rate (FSR), are carried out, demonstrating both the feasibility and the effectiveness of the proposed framework.

