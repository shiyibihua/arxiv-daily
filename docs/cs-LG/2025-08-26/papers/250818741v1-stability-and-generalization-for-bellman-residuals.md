---
layout: default
title: Stability and Generalization for Bellman Residuals
---

# Stability and Generalization for Bellman Residuals

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18741" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18741v1</a>
  <a href="https://arxiv.org/pdf/2508.18741.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18741v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18741v1', 'Stability and Generalization for Bellman Residuals')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Enoch H. Kang, Kyoungseok Jang

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºBellmanæ®‹å·®æœ€å°åŒ–ä»¥è§£å†³ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€è‡´æ€§é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `ç¦»çº¿å¼ºåŒ–å­¦ä¹ ` `Bellmanä¸€è‡´æ€§` `LyapunovåŠ¿èƒ½` `éšæœºæ¢¯åº¦ä¸‹é™` `æ ·æœ¬å¤æ‚åº¦` `è¶…é¢é£é™©ç•Œé™` `ç¥ç»ç½‘ç»œ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¦»çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•åœ¨æ‰§è¡ŒBellmanä¸€è‡´æ€§æ—¶é¢ä¸´æŒ‘æˆ˜ï¼Œå¯¼è‡´æ¢å¤çš„ä»·å€¼å‡½æ•°æˆ–å¥–åŠ±æ¨¡å‹ä¸å¤Ÿå‡†ç¡®ã€‚
2. è®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºLyapunovåŠ¿èƒ½çš„åˆ†ææ–¹æ³•ï¼Œèƒ½å¤Ÿè€¦åˆç›¸é‚»æ•°æ®é›†çš„SGDAè¿è¡Œï¼Œä»è€Œæé«˜ç»Ÿè®¡ç¨³å®šæ€§ã€‚
3. ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼ŒBRMçš„è¶…é¢é£é™©ç•Œé™ä¸ºO(1/n)ï¼Œåœ¨ä¸å¢åŠ å¤æ‚æ€§çš„æƒ…å†µä¸‹ï¼Œæ˜¾è‘—æå‡äº†æ ·æœ¬å¤æ‚åº¦çš„è¡¨ç°ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ç¦»çº¿å¼ºåŒ–å­¦ä¹ å’Œç¦»çº¿é€†å¼ºåŒ–å­¦ä¹ æ—¨åœ¨ä»å›ºå®šçš„æ—¥å¿—è½¨è¿¹ä¸­æ¢å¤è¿‘ä¼¼æœ€ä¼˜çš„ä»·å€¼å‡½æ•°æˆ–å¥–åŠ±æ¨¡å‹ï¼Œä½†å½“å‰å®è·µä»éš¾ä»¥å¼ºåˆ¶æ‰§è¡ŒBellmanä¸€è‡´æ€§ã€‚Bellmanæ®‹å·®æœ€å°åŒ–ï¼ˆBRMï¼‰ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆï¼Œæœ€è¿‘å‘ç°äº†ä¸€ç§åŸºäºéšæœºæ¢¯åº¦ä¸‹é™-ä¸Šå‡çš„å…¨å±€æ”¶æ•›æ–¹æ³•ã€‚ç„¶è€Œï¼Œå…¶åœ¨ç¦»çº¿ç¯å¢ƒä¸­çš„ç»Ÿè®¡è¡Œä¸ºä»ç„¶æœªè¢«å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡å¡«è¡¥äº†è¿™ä¸€ç»Ÿè®¡ç©ºç™½ï¼Œæå‡ºäº†ä¸€ä¸ªå•ä¸€çš„LyapunovåŠ¿èƒ½ï¼Œè€¦åˆäº†ç›¸é‚»æ•°æ®é›†ä¸Šçš„SGDAè¿è¡Œï¼Œå¹¶å¾—å‡ºäº†O(1/n)çš„å¹³å‡è®ºè¯ç¨³å®šæ€§ç•Œé™ï¼Œå°†å‡¸-å‡¹éç‚¹é—®é¢˜çš„æ ·æœ¬å¤æ‚åº¦æŒ‡æ•°ç¿»å€ã€‚ç›¸åŒçš„ç¨³å®šå¸¸æ•°è½¬åŒ–ä¸ºBRMçš„O(1/n)è¶…é¢é£é™©ç•Œé™ï¼Œæ— éœ€æ–¹å·®å‡å°‘ã€é¢å¤–æ­£åˆ™åŒ–æˆ–å¯¹å°æ‰¹é‡é‡‡æ ·çš„é™åˆ¶ç‹¬ç«‹å‡è®¾ã€‚ç»“æœé€‚ç”¨äºæ ‡å‡†ç¥ç»ç½‘ç»œå‚æ•°åŒ–å’Œå°æ‰¹é‡SGDã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è§£å†³çš„æ˜¯ç¦»çº¿å¼ºåŒ–å­¦ä¹ ä¸­Bellmanä¸€è‡´æ€§éš¾ä»¥å®ç°çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç»Ÿè®¡è¡Œä¸ºä¸Šç¼ºä¹æ·±å…¥ç ”ç©¶ï¼Œå¯¼è‡´ä»·å€¼å‡½æ•°æ¢å¤ä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡å¼•å…¥å•ä¸€çš„LyapunovåŠ¿èƒ½ï¼Œè®ºæ–‡è€¦åˆäº†ç›¸é‚»æ•°æ®é›†çš„SGDAè¿è¡Œï¼Œä»è€Œæä¾›äº†O(1/n)çš„å¹³å‡è®ºè¯ç¨³å®šæ€§ç•Œé™ï¼Œæå‡äº†BRMçš„æ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ–¹æ³•åŒ…æ‹¬å¯¹ç›¸é‚»æ•°æ®é›†çš„SGDAè¿è¡Œï¼Œåˆ©ç”¨LyapunovåŠ¿èƒ½è¿›è¡Œç¨³å®šæ€§åˆ†æï¼Œæœ€ç»ˆå¾—å‡ºè¶…é¢é£é™©ç•Œé™ã€‚ä¸»è¦æ¨¡å—åŒ…æ‹¬æ•°æ®é›†è€¦åˆã€SGDAç®—æ³•å®ç°å’Œç¨³å®šæ€§ç•Œé™æ¨å¯¼ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºå¼•å…¥äº†LyapunovåŠ¿èƒ½æ¥åˆ†æSGDAçš„ç¨³å®šæ€§ï¼Œè¿™ä¸€æ–¹æ³•æ˜¾è‘—æé«˜äº†æ ·æœ¬å¤æ‚åº¦çš„è¡¨ç°ï¼Œè¶…è¶Šäº†ç°æœ‰çš„ç»Ÿè®¡ç•Œé™ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œè®ºæ–‡æ²¡æœ‰ä¾èµ–äºæ–¹å·®å‡å°‘æˆ–é¢å¤–æ­£åˆ™åŒ–ï¼Œä¸”å¯¹å°æ‰¹é‡é‡‡æ ·æ²¡æœ‰é™åˆ¶ç‹¬ç«‹å‡è®¾ï¼Œç¡®ä¿äº†æ–¹æ³•çš„å¹¿æ³›é€‚ç”¨æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œè®ºæ–‡æå‡ºçš„æ–¹æ³•åœ¨BRMçš„è¶…é¢é£é™©ç•Œé™ä¸Šè¾¾åˆ°äº†O(1/n)ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸”åœ¨æ ‡å‡†ç¥ç»ç½‘ç»œå‚æ•°åŒ–å’Œå°æ‰¹é‡SGDä¸Šå‡è¡¨ç°å‡ºè‰¯å¥½çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ï¼Œæå‡å¹…åº¦æ˜æ˜¾ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æœºå™¨äººæ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½æ¨èç³»ç»Ÿç­‰ï¼Œèƒ½å¤Ÿåœ¨ç¦»çº¿æ•°æ®çš„æƒ…å†µä¸‹æœ‰æ•ˆæ¢å¤ä»·å€¼å‡½æ•°å’Œå¥–åŠ±æ¨¡å‹ï¼Œæå‡ç³»ç»Ÿçš„å†³ç­–èƒ½åŠ›ã€‚æœªæ¥å¯èƒ½å¯¹å¼ºåŒ–å­¦ä¹ çš„å®é™…åº”ç”¨äº§ç”Ÿæ·±è¿œå½±å“ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®è·å–æˆæœ¬é«˜æ˜‚çš„åœºæ™¯ä¸­ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Offline reinforcement learning and offline inverse reinforcement learning aim to recover near-optimal value functions or reward models from a fixed batch of logged trajectories, yet current practice still struggles to enforce Bellman consistency. Bellman residual minimization (BRM) has emerged as an attractive remedy, as a globally convergent stochastic gradient descent-ascent based method for BRM has been recently discovered. However, its statistical behavior in the offline setting remains largely unexplored. In this paper, we close this statistical gap. Our analysis introduces a single Lyapunov potential that couples SGDA runs on neighbouring datasets and yields an O(1/n) on-average argument-stability bound-doubling the best known sample-complexity exponent for convex-concave saddle problems. The same stability constant translates into the O(1/n) excess risk bound for BRM, without variance reduction, extra regularization, or restrictive independence assumptions on minibatch sampling. The results hold for standard neural-network parameterizations and minibatch SGD.

