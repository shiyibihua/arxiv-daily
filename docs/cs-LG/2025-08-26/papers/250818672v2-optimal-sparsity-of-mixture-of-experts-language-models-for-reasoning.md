---
layout: default
title: Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks
---

# Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18672" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18672v2</a>
  <a href="https://arxiv.org/pdf/2508.18672.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18672v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18672v2', 'Optimal Sparsity of Mixture-of-Experts Language Models for Reasoning Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Taishi Nakamura, Satoki Ishikawa, Masaki Kawamura, Takumi Okamoto, Daisuke Nohara, Jun Suzuki, Rio Yokota

**åˆ†ç±»**: cs.LG, cs.AI, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-09-25)

**å¤‡æ³¨**: Presented at the Second AI for Math Workshop at ICML

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/rioyokotalab/optimal-sparsity)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ··åˆä¸“å®¶æ¨¡å‹çš„æœ€ä¼˜ç¨€ç–æ€§ä»¥æå‡æ¨ç†ä»»åŠ¡æ€§èƒ½**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æ··åˆä¸“å®¶æ¨¡å‹` `ç¨€ç–æ€§` `æ¨ç†ä»»åŠ¡` `è®°å¿†èƒ½åŠ›` `å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹` `æ´»è·ƒè®¡ç®—é‡` `æ¯å‚æ•°æ€»ä»¤ç‰Œæ•°`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¨ å¯†æ¨¡å‹åœ¨å¤„ç†å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹æ—¶å¿½è§†äº†ç¨€ç–æ€§å¯¹æ¨ç†èƒ½åŠ›çš„å½±å“ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡è®­ç»ƒä¸åŒé…ç½®çš„MoEæ¨¡å‹ï¼Œæ¢è®¨æ´»è·ƒè®¡ç®—é‡å’ŒTPPå¯¹æ¨ç†å’Œè®°å¿†ä»»åŠ¡çš„å½±å“ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ´»è·ƒè®¡ç®—é‡å’ŒTPPçš„ä¼˜åŒ–å…±åŒå†³å®šäº†MoEæ¨¡å‹çš„æ€§èƒ½ï¼Œæ¨ç¿»äº†ä¼ ç»Ÿè®¡ç®—æœ€ä¼˜ç¼©æ”¾çš„è§‚ç‚¹ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‘å±•ï¼Œæ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹å¼•å…¥äº†ä¸€ç§æ–°çš„ç¨€ç–æ€§ç»´åº¦ã€‚æœ¬æ–‡ç ”ç©¶äº†MoEç¨€ç–æ€§å¯¹è®°å¿†å’Œæ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œé€šè¿‡è®­ç»ƒä¸åŒå‚æ•°é…ç½®çš„MoEæ¨¡å‹ï¼Œæ­ç¤ºäº†æ´»è·ƒè®¡ç®—é‡å’Œæ¯å‚æ•°æ€»ä»¤ç‰Œæ•°ï¼ˆTPPï¼‰å¯¹æ¨ç†ä»»åŠ¡çš„é‡è¦æ€§ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå…·æœ‰ç›¸åŒè®­ç»ƒæŸå¤±ä½†æ›´é«˜æ´»è·ƒè®¡ç®—çš„æ¨¡å‹åœ¨æ¨ç†å‡†ç¡®æ€§ä¸Šè¡¨ç°æ›´ä½³ï¼Œè€Œè®°å¿†ä»»åŠ¡åˆ™éšç€å‚æ•°å¢åŠ è€Œæ”¹å–„ï¼Œæ¨ç†ä»»åŠ¡åˆ™éœ€ä¼˜åŒ–TPPï¼Œè¡¨æ˜æ¨ç†ä»»åŠ¡å¯¹æ•°æ®çš„éœ€æ±‚è¾ƒé«˜ã€‚æœ¬æ–‡çš„æ¨¡å‹æ£€æŸ¥ç‚¹ã€ä»£ç å’Œæ—¥å¿—å·²å¼€æºã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ··åˆä¸“å®¶æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„ç¨€ç–æ€§å¦‚ä½•å½±å“æ¨¡å‹æ€§èƒ½çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æœªèƒ½å……åˆ†è€ƒè™‘ç¨€ç–æ€§å¯¹æ¨ç†èƒ½åŠ›çš„å½±å“ï¼Œå¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡è®­ç»ƒä¸åŒå‚æ•°é…ç½®çš„MoEæ¨¡å‹ï¼Œåˆ†ææ´»è·ƒè®¡ç®—é‡å’Œæ¯å‚æ•°æ€»ä»¤ç‰Œæ•°ï¼ˆTPPï¼‰å¯¹æ¨ç†å’Œè®°å¿†ä»»åŠ¡çš„å½±å“ï¼Œä»è€Œä¼˜åŒ–æ¨¡å‹çš„ç¨€ç–æ€§è®¾è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é‡‡ç”¨äº†å¤šç§MoEæ¨¡å‹é…ç½®ï¼Œåˆ†åˆ«è°ƒæ•´æ€»å‚æ•°ã€æ´»è·ƒå‚æ•°å’Œtop-kè·¯ç”±ï¼Œä¿æŒå›ºå®šçš„è®¡ç®—é¢„ç®—ã€‚é€šè¿‡å¯¹æ¯”è®­ç»ƒæŸå¤±å’Œä¸‹æ¸¸å‡†ç¡®æ€§ï¼Œæ­ç¤ºäº†ç¨€ç–æ€§å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šæå‡ºäº†æ´»è·ƒè®¡ç®—é‡å’ŒTPPå…±åŒå†³å®šMoEæ¨¡å‹æ€§èƒ½çš„ç†è®ºï¼ŒæŒ‘æˆ˜äº†ä¼ ç»Ÿçš„è®¡ç®—æœ€ä¼˜ç¼©æ”¾è§‚å¿µï¼Œå¼ºè°ƒäº†æ¨ç†ä»»åŠ¡å¯¹æ•°æ®çš„éœ€æ±‚ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å®éªŒä¸­ï¼Œæ¨¡å‹çš„è®­ç»ƒæŸå¤±ä¿æŒä¸€è‡´ï¼Œä½†é€šè¿‡è°ƒæ•´æ´»è·ƒè®¡ç®—é‡ï¼Œè§‚å¯Ÿåˆ°æ¨ç†å‡†ç¡®æ€§æ˜¾è‘—æå‡ã€‚åŒæ—¶ï¼Œè®°å¿†ä»»åŠ¡éšç€å‚æ•°å¢åŠ è€Œæ”¹å–„ï¼Œæ¨ç†ä»»åŠ¡åˆ™éœ€ä¼˜åŒ–TPPä»¥è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå…·æœ‰ç›¸åŒè®­ç»ƒæŸå¤±çš„æ¨¡å‹ï¼Œæ´»è·ƒè®¡ç®—é‡æ›´é«˜çš„æƒ…å†µä¸‹æ¨ç†å‡†ç¡®æ€§æ˜¾è‘—æå‡ã€‚æ­¤å¤–ï¼Œè®°å¿†ä»»åŠ¡éšç€å‚æ•°å¢åŠ è€Œæ”¹å–„ï¼Œè€Œæ¨ç†ä»»åŠ¡åˆ™éœ€ä¼˜åŒ–TPPï¼Œè¡¨æ˜æ¨ç†ä»»åŠ¡å¯¹æ•°æ®çš„éœ€æ±‚è¾ƒé«˜ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æ™ºèƒ½é—®ç­”ç³»ç»Ÿå’Œå¯¹è¯ç”Ÿæˆç­‰ã€‚é€šè¿‡ä¼˜åŒ–MoEæ¨¡å‹çš„ç¨€ç–æ€§ï¼Œå¯ä»¥åœ¨ä¿æŒé«˜æ•ˆè®¡ç®—çš„åŒæ—¶ï¼Œæå‡æ¨¡å‹åœ¨æ¨ç†ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Empirical scaling laws have driven the evolution of large language models (LLMs), yet their coefficients shift whenever the model architecture or data pipeline changes. Mixture-of-Experts (MoE) models, now standard in state-of-the-art systems, introduce a new sparsity dimension that current dense-model frontiers overlook. We investigate how MoE sparsity influences two distinct capability regimes: memorization skills and reasoning skills. By training MoE families that vary total parameters, active parameters, and top-$k$ routing under fixed compute budgets, we disentangle pre-training loss from downstream accuracy. Our results reveal two principles. First, Active FLOPs: models with identical training loss but greater active compute achieve higher reasoning accuracy. Second, Total tokens per parameter (TPP): memorization tasks improve with more parameters, while reasoning tasks benefit from optimal TPP, indicating that reasoning is data-hungry. Neither reinforcement learning post-training (GRPO) nor increased test-time compute alters these trends. We therefore argue that optimal MoE sparsity must be determined jointly by active FLOPs and TPP, revising the classical picture of compute-optimal scaling. Our model checkpoints, code and logs are open-source at https://github.com/rioyokotalab/optimal-sparsity.

