---
layout: default
title: Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics
---

# Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.18736" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.18736v1</a>
  <a href="https://arxiv.org/pdf/2508.18736.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.18736v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.18736v1', 'Rethinking Caching for LLM Serving Systems: Beyond Traditional Heuristics')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jungwoo Kim, Minsang Kim, Jaeheon Lee, Chanwoo Moon, Heejin Kim, Taeho Hwang, Woosuk Chung, Yeseong Kim, Sungjin Lee

**åˆ†ç±»**: cs.DB, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSISOä»¥ä¼˜åŒ–å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ç³»ç»Ÿä¸­çš„ç¼“å­˜ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§è¯­è¨€æ¨¡å‹` `ç¼“å­˜ç­–ç•¥` `è¯­ä¹‰ç¼“å­˜` `æœåŠ¡æ°´å¹³ç›®æ ‡` `åŠ¨æ€è°ƒæ•´` `æ€§èƒ½ä¼˜åŒ–` `è®¡ç®—æ•ˆç‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç¼“å­˜ç­–ç•¥åœ¨å¤„ç†å¤§è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶æœªèƒ½æœ‰æ•ˆåˆ©ç”¨æŸ¥è¯¢çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸è¶³ã€‚
2. æœ¬æ–‡æå‡ºSISOï¼Œé€šè¿‡ä¸­å¿ƒç‚¹ç¼“å­˜ã€å±€éƒ¨æ„ŸçŸ¥æ›¿æ¢å’ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼Œé‡æ–°å®šä¹‰äº†LLMæœåŠ¡çš„ç¼“å­˜æ•ˆç‡ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒSISOåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾1.71å€çš„å‘½ä¸­ç‡æå‡ï¼Œå¹¶åœ¨SLOè¾¾æˆæ–¹é¢è¡¨ç°æ›´ä¼˜ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åœ¨å¤§è§„æ¨¡æœåŠ¡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¶ï¼Œéœ€è¦åœ¨ä¸¥æ ¼çš„æœåŠ¡æ°´å¹³ç›®æ ‡ï¼ˆSLOsï¼‰ä¸‹æ»¡è¶³è®¡ç®—å’Œå†…å­˜çš„é™åˆ¶ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ç¼“å­˜ç­–ç•¥å­˜åœ¨ä¸è¶³ï¼šç²¾ç¡®åŒ¹é…å’Œå‰ç¼€ç¼“å­˜å¿½è§†äº†æŸ¥è¯¢è¯­ä¹‰ï¼Œè€Œæœ€å…ˆè¿›çš„è¯­ä¹‰ç¼“å­˜ä»ç„¶å±€é™äºä¼ ç»Ÿç›´è§‰ï¼Œç¼ºä¹æ¦‚å¿µä¸Šçš„çªç ´ã€‚åŸºäºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†SISOï¼Œä¸€ä¸ªé‡æ–°å®šä¹‰LLMæœåŠ¡æ•ˆç‡çš„è¯­ä¹‰ç¼“å­˜ç³»ç»Ÿã€‚SISOå¼•å…¥äº†åŸºäºä¸­å¿ƒç‚¹çš„ç¼“å­˜ï¼Œä»¥æœ€å°å†…å­˜æœ€å¤§åŒ–è¦†ç›–ï¼Œå±€éƒ¨æ„ŸçŸ¥æ›¿æ¢ä»¥ä¿ç•™é«˜ä»·å€¼æ¡ç›®ï¼Œä»¥åŠåŠ¨æ€é˜ˆå€¼è°ƒæ•´ä»¥å¹³è¡¡ä¸åŒå·¥ä½œè´Ÿè½½ä¸‹çš„å‡†ç¡®æ€§å’Œå»¶è¿Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSISOåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾1.71å€çš„å‘½ä¸­ç‡æå‡ï¼Œå¹¶ä¸”åœ¨SLOè¾¾æˆæ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„ç¨³å®šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åœ¨å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ä¸­ï¼Œä¼ ç»Ÿç¼“å­˜ç­–ç•¥æ— æ³•æœ‰æ•ˆåˆ©ç”¨æŸ¥è¯¢è¯­ä¹‰ï¼Œå¯¼è‡´æ€§èƒ½å’Œèµ„æºåˆ©ç”¨ç‡ä½ä¸‹çš„é—®é¢˜ã€‚ç°æœ‰çš„ç²¾ç¡®åŒ¹é…å’Œå‰ç¼€ç¼“å­˜ç­–ç•¥æœªèƒ½è€ƒè™‘æŸ¥è¯¢çš„æ·±å±‚è¯­ä¹‰ï¼Œé™åˆ¶äº†ç¼“å­˜çš„æœ‰æ•ˆæ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSISOçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥åŸºäºä¸­å¿ƒç‚¹çš„ç¼“å­˜ç­–ç•¥ï¼Œç»“åˆå±€éƒ¨æ„ŸçŸ¥æ›¿æ¢å’ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´ï¼Œæ¥æå‡ç¼“å­˜çš„è¦†ç›–ç‡å’Œå‘½ä¸­ç‡ï¼ŒåŒæ—¶åœ¨å†…å­˜ä½¿ç”¨ä¸Šä¿æŒé«˜æ•ˆã€‚è¿™æ ·çš„è®¾è®¡æ—¨åœ¨æ›´å¥½åœ°é€‚åº”ä¸åŒå·¥ä½œè´Ÿè½½ä¸‹çš„æ€§èƒ½éœ€æ±‚ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSISOçš„æ•´ä½“æ¶æ„åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼šä¸­å¿ƒç‚¹ç¼“å­˜æ¨¡å—ã€å±€éƒ¨æ„ŸçŸ¥æ›¿æ¢æ¨¡å—å’ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´æ¨¡å—ã€‚ä¸­å¿ƒç‚¹ç¼“å­˜è´Ÿè´£å­˜å‚¨å’Œç®¡ç†ç¼“å­˜æ¡ç›®ï¼Œå±€éƒ¨æ„ŸçŸ¥æ›¿æ¢ç¡®ä¿é«˜ä»·å€¼æ¡ç›®çš„ä¿ç•™ï¼Œè€ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´åˆ™æ ¹æ®å®æ—¶è´Ÿè½½æƒ…å†µä¼˜åŒ–ç¼“å­˜ç­–ç•¥ã€‚

**å…³é”®åˆ›æ–°**ï¼šSISOçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ä¸­å¿ƒç‚¹ç¼“å­˜ç­–ç•¥å’ŒåŠ¨æ€é˜ˆå€¼è°ƒæ•´æœºåˆ¶ï¼Œè¿™ä¸ä¼ ç»Ÿçš„ç¼“å­˜æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚ä¼ ç»Ÿæ–¹æ³•å¾€å¾€ä¾èµ–äºé™æ€è§„åˆ™ï¼Œè€ŒSISOé€šè¿‡åŠ¨æ€è°ƒæ•´æ¥é€‚åº”ä¸åŒçš„æŸ¥è¯¢æ¨¡å¼å’Œè´Ÿè½½å˜åŒ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒSISOé‡‡ç”¨äº†åŸºäºæŸ¥è¯¢è¯­ä¹‰çš„ä¸­å¿ƒç‚¹é€‰æ‹©ç®—æ³•ï¼Œå¹¶ç»“åˆäº†å±€éƒ¨æ„ŸçŸ¥çš„æ›¿æ¢ç­–ç•¥ï¼Œä»¥ç¡®ä¿é«˜å‘½ä¸­ç‡ã€‚æ­¤å¤–ï¼ŒåŠ¨æ€é˜ˆå€¼çš„è®¾ç½®ä¾æ®å®æ—¶æ€§èƒ½åé¦ˆè¿›è¡Œè°ƒæ•´ï¼Œä»¥å¹³è¡¡å‡†ç¡®æ€§å’Œå»¶è¿Ÿã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç®—æ³•ç»†èŠ‚åœ¨å®éªŒéƒ¨åˆ†è¿›è¡Œäº†è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSISOåœ¨å¤šç§æ•°æ®é›†ä¸Šå®ç°äº†é«˜è¾¾1.71å€çš„å‘½ä¸­ç‡æå‡ï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›çš„ç³»ç»Ÿåœ¨æœåŠ¡æ°´å¹³ç›®æ ‡ï¼ˆSLOï¼‰è¾¾æˆæ–¹é¢è¡¨ç°å‡ºæ›´å¼ºçš„ç¨³å®šæ€§ã€‚è¿™ä¸€æˆæœè¡¨æ˜SISOåœ¨å¤§è¯­è¨€æ¨¡å‹æœåŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å¤§è§„æ¨¡åœ¨çº¿æœåŠ¡ã€æ™ºèƒ½å®¢æœç³»ç»Ÿå’Œå®æ—¶æ•°æ®å¤„ç†ç­‰ã€‚é€šè¿‡ä¼˜åŒ–ç¼“å­˜ç­–ç•¥ï¼ŒSISOèƒ½å¤Ÿæœ‰æ•ˆæå‡ç³»ç»Ÿçš„å“åº”é€Ÿåº¦å’Œèµ„æºåˆ©ç”¨ç‡ï¼Œå…·æœ‰æ˜¾è‘—çš„å®é™…ä»·å€¼å’Œå¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚æœªæ¥ï¼Œéšç€å¤§è¯­è¨€æ¨¡å‹çš„æ™®åŠï¼ŒSISOçš„è®¾è®¡ç†å¿µå¯èƒ½ä¼šåœ¨æ›´å¤šç›¸å…³é¢†åŸŸå¾—åˆ°åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Serving Large Language Models (LLMs) at scale requires meeting strict Service Level Objectives (SLOs) under severe computational and memory constraints. Nevertheless, traditional caching strategies fall short: exact-matching and prefix caches neglect query semantics, while state-of-the-art semantic caches remain confined to traditional intuitions, offering little conceptual departure. Building on this, we present SISO, a semantic caching system that redefines efficiency for LLM serving. SISO introduces centroid-based caching to maximize coverage with minimal memory, locality-aware replacement to preserve high-value entries, and dynamic thresholding to balance accuracy and latency under varying workloads. Across diverse datasets, SISO delivers up to 1.71$\times$ higher hit ratios and consistently stronger SLO attainment compared to state-of-the-art systems.

