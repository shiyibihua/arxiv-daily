---
layout: default
title: Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments
---

# Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19376" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19376v1</a>
  <a href="https://arxiv.org/pdf/2508.19376.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19376v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19376v1', 'Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Dikshant Sagar, Kaiwen Yu, Alejandro Yankelevich, Jianming Bian, Pierre Baldi

**åˆ†ç±»**: cs.LG, cs.AI, cs.CV, hep-ex

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºè§†è§‰-è¯­è¨€æ¨¡å‹çš„ä¸­å¾®å­äº‹ä»¶åˆ†ç±»æ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `ä¸­å¾®å­äº‹ä»¶åˆ†ç±»` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¤šæ¨¡æ€æ¨ç†` `é«˜èƒ½ç‰©ç†` `å·ç§¯ç¥ç»ç½‘ç»œ` `LLaMA 3.2` `å®éªŒç‰©ç†` `ä¿¡æ¯æ•´åˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ä¸­å¾®å­äº‹ä»¶åˆ†ç±»æ–¹æ³•ä¸»è¦ä¾èµ–äºå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œåœ¨å¤„ç†å¤šæ¨¡æ€ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ã€‚
2. æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºLLaMA 3.2çš„å¾®è°ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œæ—¨åœ¨æé«˜ä¸­å¾®å­ç›¸äº’ä½œç”¨çš„åˆ†ç±»èƒ½åŠ›ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒVLMåœ¨åˆ†ç±»å‡†ç¡®ç‡å’Œå…¶ä»–æŒ‡æ ‡ä¸Šè¶…è¶Šäº†ä¼ ç»ŸCNNï¼Œä¸”èƒ½å¤Ÿæ›´å¥½åœ°æ•´åˆæ–‡æœ¬å’Œè¯­ä¹‰ä¿¡æ¯ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•æ˜¾ç¤ºå‡ºåœ¨å¤šæ¨¡æ€æ¨ç†æ–¹é¢çš„å¼ºå¤§æ½œåŠ›ã€‚æœ¬ç ”ç©¶æ¢ç´¢äº†åŸºäºLLaMA 3.2çš„å¾®è°ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰åœ¨é«˜èƒ½ç‰©ç†å®éªŒä¸­å¯¹ä¸­å¾®å­ç›¸äº’ä½œç”¨çš„åˆ†ç±»èƒ½åŠ›ã€‚æˆ‘ä»¬å°†å…¶æ€§èƒ½ä¸NOvAå’ŒDUNEç­‰å®éªŒä¸­ä½¿ç”¨çš„ä¼ ç»Ÿå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰åŸºçº¿è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œè¯„ä¼°äº†åˆ†ç±»å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒAUC-ROCç­‰æŒ‡æ ‡ã€‚ç»“æœè¡¨æ˜ï¼ŒVLMä¸ä»…åœ¨æ€§èƒ½ä¸Šä¸CNNç›¸å½“æˆ–æ›´ä¼˜ï¼Œè¿˜èƒ½å®ç°æ›´ä¸°å¯Œçš„æ¨ç†å’Œæ›´å¥½çš„è¾…åŠ©æ–‡æœ¬æˆ–è¯­ä¹‰ä¸Šä¸‹æ–‡æ•´åˆã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒVLMä¸ºé«˜èƒ½ç‰©ç†ä¸­çš„äº‹ä»¶åˆ†ç±»æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„é€šç”¨åŸºç¡€ï¼Œæ¨åŠ¨äº†å®éªŒä¸­å¾®å­ç‰©ç†çš„å¤šæ¨¡æ€æ–¹æ³•çš„å‘å±•ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬ç ”ç©¶æ—¨åœ¨è§£å†³é«˜èƒ½ç‰©ç†å®éªŒä¸­ä¸­å¾®å­ç›¸äº’ä½œç”¨åˆ†ç±»çš„å‡†ç¡®æ€§å’Œå¤šæ¨¡æ€ä¿¡æ¯æ•´åˆä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰çš„CNNæ–¹æ³•åœ¨å¤„ç†å¤æ‚çš„å›¾åƒå’Œæ–‡æœ¬ä¿¡æ¯æ—¶å­˜åœ¨å±€é™æ€§ï¼Œéš¾ä»¥å……åˆ†åˆ©ç”¨è¾…åŠ©ä¿¡æ¯ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡æå‡ºäº†ä¸€ç§åŸºäºLLaMA 3.2çš„å¾®è°ƒè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œé€šè¿‡ç»“åˆè§†è§‰å’Œè¯­è¨€ä¿¡æ¯ï¼Œæå‡ä¸­å¾®å­äº‹ä»¶åˆ†ç±»çš„æ€§èƒ½ã€‚è¯¥æ¨¡å‹è®¾è®¡æ—¨åœ¨å®ç°æ›´ä¸°å¯Œçš„æ¨ç†èƒ½åŠ›å’Œæ›´å¥½çš„ä¿¡æ¯æ•´åˆã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œå¯¹åƒç´ åŒ–çš„æ¢æµ‹å™¨å›¾åƒè¿›è¡Œå¤„ç†ï¼Œç„¶åä½¿ç”¨å¾®è°ƒçš„VLMè¿›è¡Œåˆ†ç±»ï¼Œæœ€åé€šè¿‡å¤šç§æŒ‡æ ‡è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥ç ”ç©¶çš„ä¸»è¦åˆ›æ–°åœ¨äºå°†è§†è§‰-è¯­è¨€æ¨¡å‹åº”ç”¨äºé«˜èƒ½ç‰©ç†äº‹ä»¶åˆ†ç±»ï¼Œçªç ´äº†ä¼ ç»ŸCNNåœ¨å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†ä¸Šçš„å±€é™ï¼Œæä¾›äº†æ›´å¼ºçš„æ¨ç†èƒ½åŠ›å’Œä¿¡æ¯æ•´åˆèƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æ¨¡å‹è®­ç»ƒä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åˆ†ç±»æ€§èƒ½ï¼Œå¹¶å¯¹VLMçš„è¶…å‚æ•°è¿›è¡Œäº†ç»†è‡´è°ƒæ•´ï¼Œä»¥ç¡®ä¿å…¶åœ¨ä¸­å¾®å­äº‹ä»¶åˆ†ç±»ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒçš„è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨åˆ†ç±»å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒAUC-ROCç­‰æŒ‡æ ‡ä¸Šå‡è¶…è¿‡äº†ä¼ ç»Ÿçš„å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ï¼Œå±•ç¤ºäº†æ›´å¼ºçš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ã€‚è¿™ä¸€æˆæœä¸ºé«˜èƒ½ç‰©ç†ä¸­çš„äº‹ä»¶åˆ†ç±»æä¾›äº†æ–°çš„æ€è·¯ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬é«˜èƒ½ç‰©ç†å®éªŒä¸­çš„ä¸­å¾®å­äº‹ä»¶åˆ†ç±»ã€ç²’å­ç‰©ç†å­¦ç ”ç©¶ä»¥åŠå…¶ä»–éœ€è¦å¤šæ¨¡æ€ä¿¡æ¯å¤„ç†çš„ç§‘å­¦é¢†åŸŸã€‚é€šè¿‡æå‡åˆ†ç±»å‡†ç¡®æ€§å’Œä¿¡æ¯æ•´åˆèƒ½åŠ›ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³å®éªŒçš„æ•ˆç‡å’Œæˆæœã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent progress in large language models (LLMs) has shown strong potential for multimodal reasoning beyond natural language. In this work, we explore the use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for classifying neutrino interactions from pixelated detector images in high-energy physics (HEP) experiments. We benchmark its performance against an established CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as classification accuracy, precision, recall, and AUC-ROC. Our results show that the VLM not only matches or exceeds CNN performance but also enables richer reasoning and better integration of auxiliary textual or semantic context. These findings suggest that VLMs offer a promising general-purpose backbone for event classification in HEP, paving the way for multimodal approaches in experimental neutrino physics.

