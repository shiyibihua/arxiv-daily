---
layout: default
title: Revisiting associative recall in modern recurrent models
---

# Revisiting associative recall in modern recurrent models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.19029" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.19029v2</a>
  <a href="https://arxiv.org/pdf/2508.19029.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.19029v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.19029v2', 'Revisiting associative recall in modern recurrent models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Destiny Okpekpe, Antonio Orvieto

**åˆ†ç±»**: cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-26 (æ›´æ–°: 2025-10-10)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æ¢è®¨ç°ä»£é€’å½’æ¨¡å‹ä¸­çš„è”æƒ³å›å¿†é—®é¢˜åŠå…¶ä¼˜åŒ–ç­–ç•¥**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è”æƒ³å›å¿†` `é€’å½’æ¨¡å‹` `å˜æ¢å™¨` `å­¦ä¹ ç‡ä¼˜åŒ–` `æ¨¡å‹æ‰©å±•` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„ç°ä»£é€’å½’æ¨¡å‹åœ¨æ¨ç†å’Œè®°å¿†ä»»åŠ¡ä¸Šè¡¨ç°ä¸å¦‚å˜æ¢å™¨ï¼Œå°¤å…¶æ˜¯åœ¨è”æƒ³å›å¿†åŸºå‡†æµ‹è¯•ä¸­ã€‚
2. è®ºæ–‡æå‡ºé€šè¿‡ä¼˜åŒ–å­¦ä¹ ç‡å’Œåˆ†ææ¨¡å‹æ‰©å±•ç­–ç•¥ï¼Œæ¥æ”¹å–„ç°ä»£é€’å½’æ¨¡å‹åœ¨è”æƒ³å›å¿†ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œå­¦ä¹ ç‡å¯¹æ¨¡å‹æ€§èƒ½å½±å“æ˜¾è‘—ï¼Œä¸”é€’å½’æ¨¡å‹åœ¨å®½åº¦æ‰©å±•æ—¶è¡¨ç°ä¼˜äºæ·±åº¦æ‰©å±•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡ç°ä»£é€’å½’æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼‰åœ¨å¤æ‚åº¦ä¸Šå…·æœ‰ä¼˜åŠ¿ï¼Œä½†è¿‘æœŸç ”ç©¶æŒ‡å‡ºå…¶åœ¨æ¨ç†å’Œè®°å¿†ä»»åŠ¡ä¸Šç›¸è¾ƒäºå˜æ¢å™¨å­˜åœ¨ä¸è¶³ã€‚æœ¬æ–‡æ·±å…¥æ¢è®¨è”æƒ³å›å¿†ï¼ˆARï¼‰åŸºå‡†ï¼Œåˆ†æäº†æ ‡å®šå’Œä¼˜åŒ–é—®é¢˜å¯¹æ–°æå‡ºçš„ä»¤ç‰Œæ··åˆç­–ç•¥çš„å½±å“ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå­¦ä¹ ç‡çš„é€‰æ‹©å¯¹ç°ä»£é€’å½’æ¨¡å‹çš„æ€§èƒ½è‡³å…³é‡è¦ï¼Œå¹¶ä¸”é€’å½’æ¨¡å‹ä¸åŸºäºæ³¨æ„åŠ›çš„æ¨¡å‹åœ¨å®½åº¦ä¸æ·±åº¦æ‰©å±•æ—¶è¡¨ç°å‡ºä¸åŒçš„ä¼˜åŠ¿ã€‚é€šè¿‡æ¶æ„æ¶ˆèå®éªŒï¼Œç ”ç©¶äº†ä¸åŒç»„ä»¶å¯¹å˜æ¢å™¨å’ŒMambaæ€§èƒ½åŠä¼˜åŒ–ç¨³å®šæ€§çš„å½±å“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ç°ä»£é€’å½’æ¨¡å‹åœ¨è”æƒ³å›å¿†ä»»åŠ¡ä¸­çš„æ€§èƒ½ä¸è¶³ï¼Œå°¤å…¶æ˜¯å­¦ä¹ ç‡é€‰æ‹©å¯¹æ¨¡å‹è®­ç»ƒçš„å½±å“ã€‚ç°æœ‰æ–¹æ³•åœ¨è¿™æ–¹é¢çš„ç ”ç©¶è¾ƒå°‘ï¼Œå¯¼è‡´æ€§èƒ½æ³¢åŠ¨è¾ƒå¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ·±å…¥åˆ†æå­¦ä¹ ç‡å’Œæ¨¡å‹ç»“æ„å¯¹è”æƒ³å›å¿†ä»»åŠ¡çš„å½±å“ï¼Œæå‡ºä¼˜åŒ–ç­–ç•¥ä»¥æå‡ç°ä»£é€’å½’æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ€§èƒ½ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šç ”ç©¶é¦–å…ˆåˆ†æäº†å­¦ä¹ ç‡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç„¶åæ¯”è¾ƒäº†é€’å½’æ¨¡å‹ä¸æ³¨æ„åŠ›æ¨¡å‹åœ¨å®½åº¦å’Œæ·±åº¦æ‰©å±•æ—¶çš„è¡¨ç°ï¼Œæœ€åé€šè¿‡æ¶æ„æ¶ˆèå®éªŒè¯„ä¼°ä¸åŒç»„ä»¶çš„å½±å“ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„åˆ›æ–°ç‚¹åœ¨äºæ­ç¤ºäº†å­¦ä¹ ç‡åœ¨ç°ä»£é€’å½’æ¨¡å‹ä¸­çš„é‡è¦æ€§ï¼Œä»¥åŠé€’å½’æ¨¡å‹ä¸æ³¨æ„åŠ›æ¨¡å‹åœ¨ä¸åŒæ‰©å±•ç­–ç•¥ä¸‹çš„æ€§èƒ½å·®å¼‚ï¼Œå°¤å…¶æ˜¯æ³¨æ„åŠ›æ¨¡å‹åœ¨å•å±‚æƒ…å†µä¸‹æ— æ³•æœ‰æ•ˆè§£å†³è”æƒ³å›å¿†é—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šç ”ç©¶ä¸­å¯¹å­¦ä¹ ç‡è¿›è¡Œäº†ç³»ç»Ÿçš„è°ƒä¼˜ï¼Œå¹¶é€šè¿‡å®éªŒéªŒè¯äº†ä¸åŒå±‚æ•°çš„å˜æ¢å™¨åœ¨è®­ç»ƒåŠ¨æ€ä¸Šçš„ç›¸ä¼¼æ€§ï¼Œå°¤å…¶æ˜¯1å±‚å˜æ¢å™¨çš„è®­ç»ƒåŠ¨æ€ä¸2å±‚å˜æ¢å™¨çš„å½’çº³å¤´å½¢æˆç›¸ä¼¼ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œä¼˜åŒ–å­¦ä¹ ç‡åï¼Œç°ä»£é€’å½’æ¨¡å‹åœ¨è”æƒ³å›å¿†ä»»åŠ¡ä¸­çš„æ€§èƒ½æ˜¾è‘—æå‡ï¼Œå°¤å…¶æ˜¯åœ¨å®½åº¦æ‰©å±•æ—¶è¡¨ç°ä¼˜äºæ·±åº¦æ‰©å±•ã€‚æ­¤å¤–ï¼Œ1å±‚å˜æ¢å™¨çš„è®­ç»ƒåŠ¨æ€ä¸2å±‚å˜æ¢å™¨ç›¸ä¼¼ï¼Œå°½ç®¡å…¶æ€§èƒ½è¾ƒå·®ï¼Œè¿™ä¸€å‘ç°ä¸ºåç»­ç ”ç©¶æä¾›äº†æ–°çš„è§†è§’ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘å’Œå¯¹è¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡ä¼˜åŒ–é€’å½’æ¨¡å‹çš„æ€§èƒ½ï¼Œå¯ä»¥æå‡è¿™äº›é¢†åŸŸä¸­çš„æ¨¡å‹è¡¨ç°ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦è®°å¿†å’Œæ¨ç†çš„ä»»åŠ¡ä¸­ã€‚æœªæ¥ï¼Œè¿™äº›ä¼˜åŒ–ç­–ç•¥å¯èƒ½ä¼šæ¨åŠ¨æ›´é«˜æ•ˆçš„æ¨¡å‹è®¾è®¡å’Œè®­ç»ƒæ–¹æ³•çš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite the advantageous subquadratic complexity of modern recurrent deep learning models -- such as state-space models (SSMs) -- recent studies have highlighted their potential shortcomings compared to transformers on reasoning and memorization tasks. In this paper, we dive deeper into one of such benchmarks: associative recall (AR), which has been shown to correlate well with language modeling performance, and inspect in detail the effects of scaling and optimization issues in recently proposed token mixing strategies. We first demonstrate that, unlike standard transformers, the choice of learning rate plays a critical role in the performance of modern recurrent models: an issue that can severely affect reported performance in previous works and suggests further research is needed to stabilize training. Next, we show that recurrent and attention-based models exhibit contrasting benefits when scaling in width as opposed to depth, with attention being notably unable to solve AR when limited to a single layer. We then further inspect 1-layer transformers, revealing that despite their poor performance, their training dynamics surprisingly resemble the formation of induction heads, a phenomenon previously observed only in their 2-layer counterparts. Finally, through architectural ablations, we study how components affects Transformer and Mamba's performance and optimization stability.

