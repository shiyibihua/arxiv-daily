---
layout: default
title: Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance
---

# Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.23461" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.23461v1</a>
  <a href="https://arxiv.org/pdf/2512.23461.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.23461v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.23461v1', 'Eliminating Inductive Bias in Reward Models with Information-Theoretic Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhuo Li, Pengyu Cheng, Zhechao Yu, Feifei Tong, Anningzhe Gao, Tsung-Hui Chang, Xiang Wan, Erchao Zhao, Xiaoxi Jiang, Guanjun Jiang

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-12-29

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Qwen-Applications/DIR)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDIRæ–¹æ³•ï¼Œé€šè¿‡ä¿¡æ¯è®ºä¼˜åŒ–æ¶ˆé™¤å¥–åŠ±æ¨¡å‹ä¸­çš„å½’çº³åç½®ï¼Œæå‡RLHFæ€§èƒ½ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¥–åŠ±æ¨¡å‹` `å½’çº³åç½®` `ä¿¡æ¯ç“¶é¢ˆ` `äº’ä¿¡æ¯` `å¼ºåŒ–å­¦ä¹ ` `äººç±»åé¦ˆ` `è¯­è¨€æ¨¡å‹`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¥–åŠ±æ¨¡å‹æ˜“å—è®­ç»ƒæ•°æ®ä¸­å½’çº³åç½®çš„å½±å“ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆå’Œå¥–åŠ±æ”»å‡»ï¼Œé™åˆ¶äº†æ¨¡å‹æ³›åŒ–èƒ½åŠ›ã€‚
2. DIRæ–¹æ³•é€šè¿‡æœ€å¤§åŒ–å¥–åŠ±åˆ†æ•°ä¸äººç±»åå¥½é—´çš„äº’ä¿¡æ¯ï¼Œå¹¶æœ€å°åŒ–å¥–åŠ±è¾“å‡ºä¸åç½®å±æ€§é—´çš„äº’ä¿¡æ¯ï¼Œå®ç°å»åç½®ã€‚
3. å®éªŒè¯æ˜DIRèƒ½æœ‰æ•ˆç¼“è§£å›å¤é•¿åº¦ã€è°„åªšå’Œæ ¼å¼ç­‰å½’çº³åç½®ï¼Œå¹¶æå‡RLHFåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰åœ¨åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ä¸­è‡³å…³é‡è¦ï¼Œç”¨äºä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ä¸äººç±»ä»·å€¼è§‚å¯¹é½ã€‚ç„¶è€Œï¼ŒRMè®­ç»ƒæ•°æ®é€šå¸¸è¢«è®¤ä¸ºæ˜¯ä½è´¨é‡çš„ï¼ŒåŒ…å«å®¹æ˜“å¯¼è‡´è¿‡æ‹Ÿåˆå’Œå¥–åŠ±æ”»å‡»çš„å½’çº³åç½®ã€‚ä¾‹å¦‚ï¼Œæ›´è¯¦ç»†å’Œå…¨é¢çš„å›å¤é€šå¸¸æ›´å—äººç±»é’çï¼Œä½†ä¹ŸåŒ…å«æ›´å¤šè¯è¯­ï¼Œå¯¼è‡´å›å¤é•¿åº¦æˆä¸ºä¸å¯é¿å…çš„å½’çº³åç½®ä¹‹ä¸€ã€‚ä¸ºäº†ç¼“è§£å¥–åŠ±å»ºæ¨¡ä¸­æ›´å¤æ‚å’Œå¤šæ ·çš„å½’çº³åç½®ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŸºäºä¿¡æ¯è®ºçš„å»åç½®æ–¹æ³•ï¼Œç§°ä¸ºDIRã€‚å—ä¿¡æ¯ç“¶é¢ˆï¼ˆIBï¼‰çš„å¯å‘ï¼Œæˆ‘ä»¬æœ€å¤§åŒ–RMåˆ†æ•°ä¸äººç±»åå¥½å¯¹ä¹‹é—´çš„äº’ä¿¡æ¯ï¼ˆMIï¼‰ï¼ŒåŒæ—¶æœ€å°åŒ–RMè¾“å‡ºä¸åå¥½è¾“å…¥çš„æœ‰åå±æ€§ä¹‹é—´çš„MIã€‚DIRå¯ä»¥å¤„ç†å…·æœ‰éçº¿æ€§ç›¸å…³æ€§çš„æ›´å¤æ‚ç±»å‹çš„åå·®ï¼Œä»è€Œå¹¿æ³›æ‰©å±•RMå»åç½®æ–¹æ³•çš„å®é™…åº”ç”¨åœºæ™¯ã€‚å®éªŒè¡¨æ˜ï¼ŒDIRä¸ä»…æœ‰æ•ˆåœ°ç¼“è§£äº†ç›®æ ‡å½’çº³åç½®ï¼Œè€Œä¸”æé«˜äº†å„ç§åŸºå‡†æµ‹è¯•ä¸­çš„RLHFæ€§èƒ½ï¼Œä»è€Œäº§ç”Ÿäº†æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰è®­ç»ƒä¸­å­˜åœ¨çš„å½’çº³åç½®é—®é¢˜ã€‚ç°æœ‰çš„RMè®­ç»ƒæ•°æ®è´¨é‡ä¸é«˜ï¼ŒåŒ…å«å¦‚å›å¤é•¿åº¦ã€è°„åªšç­‰å¤šç§å½’çº³åç½®ï¼Œå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆè¿™äº›åç½®ï¼Œæ— æ³•çœŸæ­£å­¦ä¹ åˆ°äººç±»çš„åå¥½ï¼Œä»è€Œå½±å“RLHFçš„æ€§èƒ½ã€‚ç°æœ‰çš„å»åç½®æ–¹æ³•è¦ä¹ˆåªé’ˆå¯¹ç‰¹å®šç±»å‹çš„åç½®ï¼Œè¦ä¹ˆé‡‡ç”¨ç®€å•çš„çº¿æ€§ç›¸å…³æ¨¡å‹ï¼Œæ— æ³•å¤„ç†å¤æ‚çš„éçº¿æ€§åç½®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¿¡æ¯è®ºä¸­çš„ä¿¡æ¯ç“¶é¢ˆï¼ˆInformation Bottleneck, IBï¼‰åŸç†è¿›è¡Œå»åç½®ã€‚å…·ä½“æ¥è¯´ï¼Œå¸Œæœ›å¥–åŠ±æ¨¡å‹èƒ½å¤Ÿå°½å¯èƒ½å¤šåœ°ä¿ç•™å…³äºäººç±»åå¥½çš„ä¿¡æ¯ï¼ŒåŒæ—¶å°½å¯èƒ½å°‘åœ°ä¿ç•™å…³äºè¾“å…¥ä¸­åç½®å±æ€§çš„ä¿¡æ¯ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œå¯ä»¥è¿«ä½¿æ¨¡å‹å…³æ³¨çœŸæ­£é‡è¦çš„ç‰¹å¾ï¼Œè€Œä¸æ˜¯è¢«åç½®å±æ€§æ‰€è¿·æƒ‘ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šDIRæ–¹æ³•çš„æ•´ä½“æ¡†æ¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªå…³é”®éƒ¨åˆ†ï¼šé¦–å…ˆï¼Œä½¿ç”¨å¥–åŠ±æ¨¡å‹å¯¹è¾“å…¥è¿›è¡Œè¯„åˆ†ï¼Œå¾—åˆ°å¥–åŠ±åˆ†æ•°ï¼›ç„¶åï¼Œè®¡ç®—å¥–åŠ±åˆ†æ•°ä¸äººç±»åå¥½å¯¹ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œå¹¶æœ€å¤§åŒ–è¯¥äº’ä¿¡æ¯ï¼›åŒæ—¶ï¼Œè®¡ç®—å¥–åŠ±æ¨¡å‹çš„è¾“å‡ºä¸è¾“å…¥ä¸­åç½®å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œå¹¶æœ€å°åŒ–è¯¥äº’ä¿¡æ¯ã€‚é€šè¿‡ä¼˜åŒ–è¿™ä¸¤ä¸ªäº’ä¿¡æ¯ï¼Œå¯ä»¥å®ç°å»åç½®çš„ç›®çš„ã€‚æ•´ä¸ªè¿‡ç¨‹å¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªä¿¡æ¯ç“¶é¢ˆçš„ä¼˜åŒ–è¿‡ç¨‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šDIRæ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°åœ¨äºå…¶åŸºäºä¿¡æ¯è®ºçš„å»åç½®æ¡†æ¶ã€‚ä¸ä»¥å¾€æ–¹æ³•ä¸åŒï¼ŒDIRä¸ä¾èµ–äºå¯¹åç½®ç±»å‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œä¹Ÿä¸éœ€è¦æ‰‹åŠ¨è®¾è®¡ç‰¹å®šçš„å»åç½®ç­–ç•¥ã€‚DIRé€šè¿‡ä¼˜åŒ–äº’ä¿¡æ¯ï¼Œè‡ªåŠ¨å­¦ä¹ å¦‚ä½•å»é™¤åç½®ï¼Œä»è€Œèƒ½å¤Ÿå¤„ç†æ›´å¤æ‚å’Œå¤šæ ·çš„åç½®ç±»å‹ã€‚æ­¤å¤–ï¼ŒDIRæ–¹æ³•å¯ä»¥å¤„ç†éçº¿æ€§ç›¸å…³çš„åç½®ï¼Œè¿™æ˜¯ä»¥å¾€çº¿æ€§æ¨¡å‹æ— æ³•åšåˆ°çš„ã€‚

**å…³é”®è®¾è®¡**ï¼šDIRçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) äº’ä¿¡æ¯çš„è®¡ç®—æ–¹æ³•ã€‚è®ºæ–‡é‡‡ç”¨äº†ä¸€ç§åŸºäºç¥ç»ç½‘ç»œçš„äº’ä¿¡æ¯ä¼°è®¡æ–¹æ³•ï¼Œå¯ä»¥æœ‰æ•ˆåœ°ä¼°è®¡é«˜ç»´æ•°æ®çš„äº’ä¿¡æ¯ã€‚2) æŸå¤±å‡½æ•°çš„è®¾è®¡ã€‚æŸå¤±å‡½æ•°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼šä¸€éƒ¨åˆ†æ˜¯æœ€å¤§åŒ–å¥–åŠ±åˆ†æ•°ä¸äººç±»åå¥½ä¹‹é—´çš„äº’ä¿¡æ¯ï¼Œå¦ä¸€éƒ¨åˆ†æ˜¯æœ€å°åŒ–å¥–åŠ±æ¨¡å‹è¾“å‡ºä¸åç½®å±æ€§ä¹‹é—´çš„äº’ä¿¡æ¯ã€‚3) åç½®å±æ€§çš„å®šä¹‰ã€‚è®ºæ–‡é’ˆå¯¹ä¸åŒçš„åç½®ç±»å‹ï¼Œè®¾è®¡äº†ä¸åŒçš„åç½®å±æ€§æå–å™¨ï¼Œä¾‹å¦‚ï¼Œå¯¹äºå›å¤é•¿åº¦åç½®ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å›å¤çš„é•¿åº¦ä½œä¸ºåç½®å±æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23461v1/figures/framework1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23461v1/x1.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.23461v1/x2.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒDIRæ–¹æ³•åœ¨ç¼“è§£å›å¤é•¿åº¦ã€è°„åªšå’Œæ ¼å¼ç­‰å½’çº³åç½®æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ä¾‹å¦‚ï¼Œåœ¨é’ˆå¯¹å›å¤é•¿åº¦åç½®çš„å®éªŒä¸­ï¼ŒDIRæ–¹æ³•èƒ½å¤Ÿæ˜¾è‘—é™ä½å¥–åŠ±æ¨¡å‹å¯¹å›å¤é•¿åº¦çš„ä¾èµ–ï¼ŒåŒæ—¶æé«˜RLHFçš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒDIRæ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éƒ½å–å¾—äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºå„ç§éœ€è¦ä»äººç±»åé¦ˆä¸­å­¦ä¹ çš„åœºæ™¯ï¼Œä¾‹å¦‚å¯¹è¯ç³»ç»Ÿã€æ–‡æœ¬ç”Ÿæˆã€æ¨èç³»ç»Ÿç­‰ã€‚é€šè¿‡æ¶ˆé™¤å¥–åŠ±æ¨¡å‹ä¸­çš„å½’çº³åç½®ï¼Œå¯ä»¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ï¼Œä½¿å…¶æ›´å¥½åœ°å¯¹é½äººç±»ä»·å€¼è§‚ï¼Œä»è€Œç”Ÿæˆæ›´ç¬¦åˆäººç±»æœŸæœ›çš„å†…å®¹ã€‚è¯¥æ–¹æ³•è¿˜æœ‰åŠ©äºæå‡AIç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ï¼Œé™ä½å¥–åŠ±æ”»å‡»çš„é£é™©ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reward models (RMs) are essential in reinforcement learning from human feedback (RLHF) to align large language models (LLMs) with human values. However, RM training data is commonly recognized as low-quality, containing inductive biases that can easily lead to overfitting and reward hacking. For example, more detailed and comprehensive responses are usually human-preferred but with more words, leading response length to become one of the inevitable inductive biases. A limited number of prior RM debiasing approaches either target a single specific type of bias or model the problem with only simple linear correlations, \textit{e.g.}, Pearson coefficients. To mitigate more complex and diverse inductive biases in reward modeling, we introduce a novel information-theoretic debiasing method called \textbf{D}ebiasing via \textbf{I}nformation optimization for \textbf{R}M (DIR). Inspired by the information bottleneck (IB), we maximize the mutual information (MI) between RM scores and human preference pairs, while minimizing the MI between RM outputs and biased attributes of preference inputs. With theoretical justification from information theory, DIR can handle more sophisticated types of biases with non-linear correlations, broadly extending the real-world application scenarios for RM debiasing methods. In experiments, we verify the effectiveness of DIR with three types of inductive biases: \textit{response length}, \textit{sycophancy}, and \textit{format}. We discover that DIR not only effectively mitigates target inductive biases but also enhances RLHF performance across diverse benchmarks, yielding better generalization abilities. The code and training recipes are available at https://github.com/Qwen-Applications/DIR.

