---
layout: default
title: Large Language Models and Futures Price Factors in China
---

# Large Language Models and Futures Price Factors in China

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23609" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23609v1</a>
  <a href="https://arxiv.org/pdf/2509.23609.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23609v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23609v1', 'Large Language Models and Futures Price Factors in China')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuhan Cheng, Heyang Zhou, Yanchu Liu

**åˆ†ç±»**: q-fin.PR, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-09-28

**å¤‡æ³¨**: 46 pages;1 figure

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹æ„å»ºä¸­å›½æœŸè´§å¸‚åœºä»·æ ¼å› å­æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤§å‹è¯­è¨€æ¨¡å‹` `æœŸè´§å¸‚åœº` `å› å­æ¨¡å‹` `é‡åŒ–æŠ•èµ„` `é‡‘èæ–‡æœ¬åˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœŸè´§å¸‚åœºå› å­æ„å»ºæ–¹æ³•ä¾èµ–äººå·¥ç»éªŒæˆ–ç»Ÿè®¡åˆ†æï¼Œéš¾ä»¥æ•æ‰å¸‚åœºå¤æ‚åŠ¨æ€ã€‚
2. åˆ©ç”¨GPTç­‰å¤§å‹è¯­è¨€æ¨¡å‹ç†è§£é‡‘èæ–‡æœ¬ï¼Œè‡ªåŠ¨æå–å¹¶ç”Ÿæˆæœ‰æ•ˆçš„æœŸè´§ä»·æ ¼å› å­ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGPTç”Ÿæˆçš„å› å­åœ¨å¤æ™®æ¯”ç‡ã€å¹´åŒ–æ”¶ç›Šå’Œalphaæ–¹é¢å‡ä¼˜äºä¼ ç»Ÿæ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œå¦‚Generative Pre-trained Transformer (GPT)ï¼Œæ„å»ºä¸­å›½æœŸè´§å¸‚åœºçš„å› å­æ¨¡å‹ã€‚æˆåŠŸè·å–äº†40ä¸ªå› å­ï¼Œå¹¶é€šè¿‡é•¿çŸ­ä»“å’Œå¤šå¤´ç­–ç•¥è®¾è®¡å•å› å­å’Œå¤šå› å­æŠ•èµ„ç»„åˆï¼Œè¿›è¡Œäº†æ ·æœ¬å†…å’Œæ ·æœ¬å¤–æœŸé—´çš„å›æµ‹ã€‚å…¨é¢çš„å®è¯åˆ†æè¡¨æ˜ï¼ŒGPTç”Ÿæˆçš„å› å­æä¾›äº†æ˜¾è‘—çš„å¤æ™®æ¯”ç‡å’Œå¹´åŒ–å›æŠ¥ç‡ï¼ŒåŒæ—¶ä¿æŒäº†å¯æ¥å—çš„æœ€å¤§å›æ’¤ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒåŸºäºGPTçš„å› å­æ¨¡å‹ä¹Ÿå®ç°äº†ç›¸å¯¹äºIPCAåŸºå‡†çš„æ˜¾è‘—alphaã€‚æ­¤å¤–ï¼Œè¿™äº›å› å­åœ¨å¹¿æ³›çš„ç¨³å¥æ€§æµ‹è¯•ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨GPTè®­ç»ƒæ•°æ®çš„æˆªæ­¢æ—¥æœŸä¹‹åè¡¨ç°å‡ºè‰²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šä¼ ç»ŸæœŸè´§å¸‚åœºå› å­æ„å»ºæ–¹æ³•ä¾èµ–äºäººå·¥ç»éªŒå’Œç»Ÿè®¡åˆ†æï¼Œè€—æ—¶è€—åŠ›ä¸”éš¾ä»¥æ•æ‰å¸‚åœºä¸­å¤æ‚çš„éçº¿æ€§å…³ç³»å’Œæ½œåœ¨çš„é©±åŠ¨å› ç´ ã€‚ç°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆåˆ©ç”¨æµ·é‡çš„é‡‘èæ–‡æœ¬æ•°æ®ï¼Œä»ä¸­æå–æœ‰ä»·å€¼çš„ä¿¡æ¯æ¥é¢„æµ‹æœŸè´§ä»·æ ¼ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ï¼Œä»å¤§é‡çš„é‡‘èæ–°é—»ã€ç ”æŠ¥ç­‰æ–‡æœ¬æ•°æ®ä¸­è‡ªåŠ¨æå–å’Œç”ŸæˆæœŸè´§ä»·æ ¼å› å­ã€‚æ ¸å¿ƒåœ¨äºå°†LLMè§†ä¸ºä¸€ç§å› å­æŒ–æ˜å·¥å…·ï¼Œé€šè¿‡å­¦ä¹ é‡‘èæ–‡æœ¬ä¸­çš„æ¨¡å¼å’Œå…³ç³»ï¼Œå‘ç°ä¸æœŸè´§ä»·æ ¼ç›¸å…³çš„æ½œåœ¨å› å­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æµç¨‹åŒ…æ‹¬ï¼š1) æ•°æ®æ”¶é›†ï¼šæ”¶é›†ä¸­å›½æœŸè´§å¸‚åœºçš„ç›¸å…³é‡‘èæ–‡æœ¬æ•°æ®ï¼›2) å› å­ç”Ÿæˆï¼šä½¿ç”¨GPTç­‰LLMå¯¹æ–‡æœ¬æ•°æ®è¿›è¡Œåˆ†æï¼Œç”Ÿæˆå€™é€‰å› å­ï¼›3) å› å­ç­›é€‰ï¼šå¯¹ç”Ÿæˆçš„å› å­è¿›è¡Œç­›é€‰ï¼Œé€‰æ‹©å…·æœ‰é¢„æµ‹èƒ½åŠ›çš„å› å­ï¼›4) æŠ•èµ„ç»„åˆæ„å»ºï¼šåˆ©ç”¨ç­›é€‰åçš„å› å­æ„å»ºå•å› å­å’Œå¤šå› å­æŠ•èµ„ç»„åˆï¼›5) å›æµ‹è¯„ä¼°ï¼šå¯¹æŠ•èµ„ç»„åˆè¿›è¡Œå›æµ‹ï¼Œè¯„ä¼°å…¶åœ¨æ ·æœ¬å†…å’Œæ ·æœ¬å¤–æœŸé—´çš„æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºå°†å¤§å‹è¯­è¨€æ¨¡å‹åº”ç”¨äºæœŸè´§å¸‚åœºå› å­æŒ–æ˜ï¼Œå®ç°äº†å› å­ç”Ÿæˆçš„è‡ªåŠ¨åŒ–å’Œæ™ºèƒ½åŒ–ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨æµ·é‡é‡‘èæ–‡æœ¬æ•°æ®ï¼Œå‘ç°éšè—åœ¨æ–‡æœ¬ä¸­çš„æ½œåœ¨å› å­ï¼Œå¹¶èƒ½å¤Ÿé€‚åº”å¸‚åœºå˜åŒ–ï¼ŒæŒç»­ç”Ÿæˆæ–°çš„å› å­ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä¸­å¯èƒ½æ¶‰åŠçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) LLMçš„é€‰æ‹©å’Œå¾®è°ƒï¼šé€‰æ‹©åˆé€‚çš„LLMï¼ˆå¦‚GPTï¼‰å¹¶å¯èƒ½é’ˆå¯¹é‡‘èæ–‡æœ¬æ•°æ®è¿›è¡Œå¾®è°ƒï¼›2) å› å­ç”Ÿæˆæ–¹å¼ï¼šè®¾è®¡åˆé€‚çš„promptæˆ–æŒ‡ä»¤ï¼Œå¼•å¯¼LLMç”Ÿæˆæœ‰æ„ä¹‰çš„å› å­ï¼›3) å› å­ç­›é€‰æŒ‡æ ‡ï¼šé€‰æ‹©åˆé€‚çš„æŒ‡æ ‡ï¼ˆå¦‚ä¿¡æ¯æ¯”ç‡ã€ICå€¼ç­‰ï¼‰æ¥è¯„ä¼°å› å­çš„é¢„æµ‹èƒ½åŠ›ï¼›4) æŠ•èµ„ç»„åˆæ„å»ºæ–¹æ³•ï¼šé‡‡ç”¨åˆé€‚çš„æŠ•èµ„ç»„åˆæ„å»ºæ–¹æ³•ï¼ˆå¦‚ç­‰æƒé‡ã€å¸‚å€¼åŠ æƒç­‰ï¼‰æ¥åˆ©ç”¨å› å­ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºäºGPTç”Ÿæˆçš„å› å­æ„å»ºçš„æŠ•èµ„ç»„åˆåœ¨æ ·æœ¬å†…å’Œæ ·æœ¬å¤–æœŸé—´å‡å–å¾—äº†æ˜¾è‘—çš„å¤æ™®æ¯”ç‡å’Œå¹´åŒ–å›æŠ¥ç‡ï¼Œå¹¶ä¸”ç›¸å¯¹äºIPCAåŸºå‡†å®ç°äº†æ˜¾è‘—çš„alphaã€‚å°¤å…¶å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¿™äº›å› å­åœ¨GPTè®­ç»ƒæ•°æ®æˆªæ­¢æ—¥æœŸä¹‹åä»ç„¶è¡¨ç°å‡ºè‰²ï¼Œè¡¨æ˜è¯¥æ–¹æ³•å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºé‡åŒ–æŠ•èµ„é¢†åŸŸï¼Œå¸®åŠ©æŠ•èµ„è€…æ„å»ºæ›´æœ‰æ•ˆçš„æœŸè´§æŠ•èµ„ç»„åˆï¼Œæé«˜æŠ•èµ„æ”¶ç›Šã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æ‰©å±•åˆ°å…¶ä»–é‡‘èå¸‚åœºï¼Œå¦‚è‚¡ç¥¨ã€å€ºåˆ¸ç­‰ï¼Œä¸ºé‡‘èå¸‚åœºç ”ç©¶æä¾›æ–°çš„æ€è·¯å’Œå·¥å…·ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›åº”ç”¨äºæ™ºèƒ½æŠ•é¡¾ã€é£é™©ç®¡ç†ç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We leverage the capacity of large language models such as Generative Pre-trained Transformer (GPT) in constructing factor models for Chinese futures markets. We successfully obtain 40 factors to design single-factor and multi-factor portfolios through long-short and long-only strategies, conducting backtests during the in-sample and out-of-sample period. Comprehensive empirical analysis reveals that GPT-generated factors deliver remarkable Sharpe ratios and annualized returns while maintaining acceptable maximum drawdowns. Notably, the GPT-based factor models also achieve significant alphas over the IPCA benchmark. Moreover, these factors demonstrate significant performance across extensive robustness tests, particularly excelling after the cutoff date of GPT's training data.

