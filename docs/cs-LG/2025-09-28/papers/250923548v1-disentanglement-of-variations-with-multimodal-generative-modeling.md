---
layout: default
title: Disentanglement of Variations with Multimodal Generative Modeling
---

# Disentanglement of Variations with Multimodal Generative Modeling

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.23548" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.23548v1</a>
  <a href="https://arxiv.org/pdf/2509.23548.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.23548v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.23548v1', 'Disentanglement of Variations with Multimodal Generative Modeling')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yijie Zhang, Yiyang Shen, Weiran Wang

**åˆ†ç±»**: cs.LG, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-28

**å¤‡æ³¨**: 22 pages, 14 figures, 7 tables

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºIDMVAEï¼Œé€šè¿‡äº’ä¿¡æ¯è§£è€¦å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ä¸­çš„å…±äº«å’Œç§æœ‰ä¿¡æ¯ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å­¦ä¹ ` `ç”Ÿæˆæ¨¡å‹` `å˜åˆ†è‡ªç¼–ç å™¨` `äº’ä¿¡æ¯` `ä¿¡æ¯è§£è€¦`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ä¸­éš¾ä»¥æœ‰æ•ˆè§£è€¦å…±äº«å’Œç§æœ‰ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯åœ¨å¤æ‚æ•°æ®é›†ä¸Šï¼Œä¼¼ç„¶æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ä¸è¶³ã€‚
2. IDMVAEé€šè¿‡äº’ä¿¡æ¯æ­£åˆ™åŒ–æ˜¾å¼è§£è€¦å…±äº«å’Œç§æœ‰ä¿¡æ¯ï¼Œå¹¶ç»“åˆç”Ÿæˆå¢å¼ºå’Œå¾ªç¯ä¸€è‡´æ€§æŸå¤±æ¥æ¶ˆé™¤å†—ä½™ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒIDMVAEåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå®ç°äº†æ›´å¥½çš„å…±äº«å’Œç§æœ‰ä¿¡æ¯åˆ†ç¦»ï¼Œå¹¶æå‡äº†ç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€æ•°æ®åœ¨å„ä¸ªé¢†åŸŸæ™®éå­˜åœ¨ï¼Œå­¦ä¹ æ­¤ç±»æ•°æ®çš„é²æ£’è¡¨ç¤ºå¯¹äºæé«˜ç”Ÿæˆè´¨é‡å’Œä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½è‡³å…³é‡è¦ã€‚ä¸ºäº†å¤„ç†ä¸åŒæ¨¡æ€ä¹‹é—´çš„å¼‚è´¨æ€§å’Œç›¸äº’è”ç³»ï¼Œæœ€è¿‘çš„å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„å˜é‡æå–å…±äº«å’Œç§æœ‰ï¼ˆæ¨¡æ€ç‰¹å®šï¼‰ä¿¡æ¯ã€‚å°½ç®¡å°è¯•å¼ºåˆ¶è§£è€¦è¿™ä¸¤ä¸ªå˜é‡ï¼Œä½†è¿™äº›æ–¹æ³•åœ¨ä¼¼ç„¶æ¨¡å‹ä¸è¶³çš„å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¡¨ç°ä¸ä½³ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¿¡æ¯è§£è€¦å¤šæ¨¡æ€VAEï¼ˆIDMVAEï¼‰æ¥æ˜¾å¼åœ°è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé‡‡ç”¨ä¸¥æ ¼çš„åŸºäºäº’ä¿¡æ¯çš„æ­£åˆ™åŒ–ï¼ŒåŒ…æ‹¬ç”¨äºæå–å…±äº«å˜é‡çš„è·¨è§†å›¾äº’ä¿¡æ¯æœ€å¤§åŒ–ï¼Œä»¥åŠä½¿ç”¨ç”Ÿæˆå¢å¼ºçš„å¾ªç¯ä¸€è‡´æ€§é£æ ¼æŸå¤±æ¥æ¶ˆé™¤å†—ä½™ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å¼•å…¥æ‰©æ•£æ¨¡å‹æ¥æé«˜æ½œåœ¨å…ˆéªŒçš„å®¹é‡ã€‚è¿™äº›æ–°æå‡ºçš„ç»„ä»¶æ˜¯ç›¸äº’è¡¥å……çš„ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒIDMVAEåœ¨å…±äº«å’Œç§æœ‰ä¿¡æ¯ä¹‹é—´è¡¨ç°å‡ºæ¸…æ™°çš„åˆ†ç¦»ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šå±•ç¤ºäº†å“è¶Šçš„ç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€ç”Ÿæˆæ¨¡å‹ä¸­å…±äº«ä¿¡æ¯å’Œç§æœ‰ä¿¡æ¯éš¾ä»¥æœ‰æ•ˆè§£è€¦çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶å°è¯•ä½¿ç”¨åˆ†ç¦»çš„å˜é‡æ¥è¡¨ç¤ºå…±äº«å’Œç§æœ‰ä¿¡æ¯ï¼Œä½†ç”±äºä¼¼ç„¶æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›é™åˆ¶ï¼Œåœ¨å¤æ‚æ•°æ®é›†ä¸Šæ— æ³•å®ç°å¹²å‡€çš„è§£è€¦ï¼Œå¯¼è‡´ç”Ÿæˆè´¨é‡ä¸‹é™ï¼Œè¯­ä¹‰ä¸€è‡´æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ˜¾å¼åœ°æœ€å¤§åŒ–è·¨æ¨¡æ€ä¹‹é—´çš„äº’ä¿¡æ¯æ¥æå–å…±äº«ä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨å¾ªç¯ä¸€è‡´æ€§æŸå¤±æ¥æ¶ˆé™¤ç§æœ‰ä¿¡æ¯ä¸­çš„å†—ä½™ï¼Œä»è€Œå®ç°å…±äº«å’Œç§æœ‰ä¿¡æ¯çš„æœ‰æ•ˆè§£è€¦ã€‚æ­¤å¤–ï¼Œå¼•å…¥æ‰©æ•£æ¨¡å‹æ¥å¢å¼ºæ½œåœ¨å…ˆéªŒçš„è¡¨è¾¾èƒ½åŠ›ï¼Œè¿›ä¸€æ­¥æå‡ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šIDMVAEçš„æ•´ä½“æ¡†æ¶åŸºäºå˜åˆ†è‡ªç¼–ç å™¨ï¼ˆVAEï¼‰ï¼ŒåŒ…å«ç¼–ç å™¨ã€æ½œåœ¨ç©ºé—´å’Œè§£ç å™¨ä¸‰ä¸ªä¸»è¦éƒ¨åˆ†ã€‚ç¼–ç å™¨å°†å¤šæ¨¡æ€è¾“å…¥æ˜ å°„åˆ°æ½œåœ¨ç©ºé—´ï¼Œæ½œåœ¨ç©ºé—´åŒ…å«å…±äº«å˜é‡å’Œç§æœ‰å˜é‡ã€‚è§£ç å™¨ä»æ½œåœ¨ç©ºé—´é‡æ„è¾“å…¥ã€‚ä¸ºäº†å®ç°ä¿¡æ¯è§£è€¦ï¼Œæ¨¡å‹å¼•å…¥äº†è·¨è§†å›¾äº’ä¿¡æ¯æœ€å¤§åŒ–æ¨¡å—å’Œå¾ªç¯ä¸€è‡´æ€§æŸå¤±æ¨¡å—ã€‚æ­¤å¤–ï¼Œä½¿ç”¨æ‰©æ•£æ¨¡å‹ä½œä¸ºæ½œåœ¨å…ˆéªŒï¼Œä»¥æé«˜ç”Ÿæˆèƒ½åŠ›ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) æ˜¾å¼åœ°ä½¿ç”¨äº’ä¿¡æ¯æœ€å¤§åŒ–æ¥æå–å…±äº«ä¿¡æ¯ï¼Œç¡®ä¿ä¸åŒæ¨¡æ€ä¹‹é—´å…±äº«çš„ä¿¡æ¯è¢«æœ‰æ•ˆæ•è·ï¼›2) ä½¿ç”¨å¾ªç¯ä¸€è‡´æ€§æŸå¤±æ¥æ¶ˆé™¤ç§æœ‰ä¿¡æ¯ä¸­çš„å†—ä½™ï¼Œé¿å…ä¿¡æ¯æ³„éœ²ï¼›3) å¼•å…¥æ‰©æ•£æ¨¡å‹ä½œä¸ºæ½œåœ¨å…ˆéªŒï¼Œå¢å¼ºäº†æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›ã€‚è¿™äº›åˆ›æ–°ç‚¹å…±åŒä½œç”¨ï¼Œå®ç°äº†æ›´å¹²å‡€çš„å…±äº«å’Œç§æœ‰ä¿¡æ¯è§£è€¦ã€‚

**å…³é”®è®¾è®¡**ï¼šIDMVAEçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨äº’ä¿¡æ¯ä¼°è®¡å™¨æ¥è¿‘ä¼¼è®¡ç®—è·¨è§†å›¾äº’ä¿¡æ¯ï¼Œå¹¶å°†å…¶ä½œä¸ºæŸå¤±å‡½æ•°çš„ä¸€éƒ¨åˆ†è¿›è¡Œä¼˜åŒ–ï¼›2) è®¾è®¡å¾ªç¯ä¸€è‡´æ€§æŸå¤±ï¼Œé€šè¿‡ç”Ÿæˆå¢å¼ºçš„æ–¹å¼ï¼Œå¼ºåˆ¶æ¨¡å‹å­¦ä¹ åˆ°æ›´å¹²å‡€çš„ç§æœ‰ä¿¡æ¯ï¼›3) ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ¥å»ºæ¨¡æ½œåœ¨å…ˆéªŒï¼Œå¹¶é‡‡ç”¨å˜åˆ†æ¨æ–­çš„æ–¹å¼è¿›è¡Œè®­ç»ƒã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

IDMVAEåœ¨å¤šä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„å¤šæ¨¡æ€æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜ï¼ŒIDMVAEåœ¨å…±äº«å’Œç§æœ‰ä¿¡æ¯åˆ†ç¦»æ–¹é¢ä¼˜äºç°æœ‰æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒIDMVAEèƒ½å¤Ÿç”Ÿæˆæ›´æ¸…æ™°ã€æ›´çœŸå®çš„å›¾åƒï¼Œå¹¶ä¸”åœ¨è¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢å–å¾—äº†æ˜¾è‘—æå‡ã€‚å®šé‡æŒ‡æ ‡ä¹Ÿè¡¨æ˜ï¼ŒIDMVAEåœ¨ç”Ÿæˆè´¨é‡å’Œä¿¡æ¯è§£è€¦æ–¹é¢å‡å–å¾—äº†æ˜¾è‘—çš„æ”¹è¿›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

IDMVAEå¯åº”ç”¨äºå„ç§å¤šæ¨¡æ€æ•°æ®ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ°æ–‡æœ¬çš„ç”Ÿæˆã€è¯­éŸ³åˆ°å›¾åƒçš„ç”Ÿæˆç­‰ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°é²æ£’çš„å…±äº«è¡¨ç¤ºï¼Œä»è€Œæé«˜ç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å¯ä»¥ç”¨äºå¤šæ¨¡æ€æ•°æ®çš„è¡¨ç¤ºå­¦ä¹ å’Œä¸‹æ¸¸ä»»åŠ¡ï¼Œä¾‹å¦‚å¤šæ¨¡æ€åˆ†ç±»ã€æ£€ç´¢ç­‰ã€‚æœªæ¥ï¼Œè¯¥ç ”ç©¶å¯ä»¥æ‰©å±•åˆ°æ›´å¤æ‚çš„å¤šæ¨¡æ€åœºæ™¯ï¼Œä¾‹å¦‚è§†é¢‘ç†è§£å’Œå¤šæ¨¡æ€å¯¹è¯ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal data are prevalent across various domains, and learning robust representations of such data is paramount to enhancing generation quality and downstream task performance. To handle heterogeneity and interconnections among different modalities, recent multimodal generative models extract shared and private (modality-specific) information with two separate variables. Despite attempts to enforce disentanglement between these two variables, these methods struggle with challenging datasets where the likelihood model is insufficient. In this paper, we propose Information-disentangled Multimodal VAE (IDMVAE) to explicitly address this issue, with rigorous mutual information-based regularizations, including cross-view mutual information maximization for extracting shared variables, and a cycle-consistency style loss for redundancy removal using generative augmentations. We further introduce diffusion models to improve the capacity of latent priors. These newly proposed components are complementary to each other. Compared to existing approaches, IDMVAE shows a clean separation between shared and private information, demonstrating superior generation quality and semantic coherence on challenging datasets.

