---
layout: default
title: Multi-speaker Attention Alignment for Multimodal Social Interaction
---

# Multi-speaker Attention Alignment for Multimodal Social Interaction

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.17952" target="_blank" class="toolbar-btn">arXiv: 2511.17952v1</a>
    <a href="https://arxiv.org/pdf/2511.17952.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17952v1" 
            onclick="toggleFavorite(this, '2511.17952v1', 'Multi-speaker Attention Alignment for Multimodal Social Interaction')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Liangyang Ouyang, Yifei Huang, Mingfang Zhang, Caixin Kang, Ryosuke Furuta, Yoichi Sato

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-22

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/ut-vision/SocialInteraction)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Â§öËØ¥ËØù‰∫∫Ê≥®ÊÑèÂäõÂØπÈΩêÊñπÊ≥ïÔºåÊèêÂçáMLLMÂú®Â§öÊ®°ÊÄÅÁ§æ‰∫§‰∫íÂä®‰∏≠ÁöÑÁêÜËß£ËÉΩÂäõ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫îÔºö‰∫§‰∫í‰∏éÂèçÂ∫î (Interaction & Reaction)**

**ÂÖ≥ÈîÆËØç**: `Â§öÊ®°ÊÄÅÂ≠¶‰π†` `Á§æ‰∫§‰∫íÂä®ÁêÜËß£` `Ê≥®ÊÑèÂäõÊú∫Âà∂` `Â§öËØ¥ËØù‰∫∫Âú∫ÊôØ` `Ë∑®Ê®°ÊÄÅÂØπÈΩê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâMLLMÂú®Â§öËØ¥ËØù‰∫∫Âú∫ÊôØ‰∏≠ÔºåËßÜËßâÂíåÊñáÊú¨tokenÁº∫‰πèËØ¥ËØù‰∫∫‰∏ÄËá¥ÁöÑÂØπÈΩêÔºåÂØºËá¥Ë∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõËæÉÂº±ÔºåÂΩ±ÂìçÁ§æ‰∫§‰∫íÂä®ÁêÜËß£„ÄÇ
2. ÊèêÂá∫‰∏ÄÁßçÂ§öÊ®°ÊÄÅÂ§öËØ¥ËØù‰∫∫Ê≥®ÊÑèÂäõÂØπÈΩêÊñπÊ≥ïÔºåÈÄöËøáÂä®ÊÄÅË∑®Ê®°ÊÄÅÂ§¥ÈÄâÊã©ÂíåËá™ÈÄÇÂ∫îÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÊù•Â¢ûÂº∫ËØ¥ËØù‰∫∫ËßÜËßâÂíåÊñáÊú¨ÁöÑÂØπÈΩê„ÄÇ
3. Âú®TVQA+„ÄÅMMSI„ÄÅOnlineMMSIÁ≠âÂü∫ÂáÜÊµãËØï‰∏≠ÔºåËØ•ÊñπÊ≥ïÊòæËëóÊèêÂçá‰∫ÜMLLMÂú®Á§æ‰∫§‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩÔºåËææÂà∞SOTAÊ∞¥Âπ≥„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÁêÜËß£ËßÜÈ¢ë‰∏≠ÁöÑÁ§æ‰∫§‰∫íÂä®ÈúÄË¶ÅÊé®ÁêÜÂè£Â§¥ÂíåÈùûÂè£Â§¥Á∫øÁ¥¢ÁöÑÂä®ÊÄÅ‰∫§‰∫íÔºöË∞ÅÂú®ËØ¥ËØùÔºåÂØπË∞ÅËØ¥Ôºå‰ª•Âèä‰º¥ÈöèÁöÑÁúºÁ•ûÊàñÊâãÂäø„ÄÇËôΩÁÑ∂Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÊòØÁêÜÊÉ≥ÈÄâÊã©Ôºå‰ΩÜÁÆÄÂçïÂú∞Ê∑ªÂä†ËßÜËßâËæìÂÖ•Âú®Á§æ‰∫§‰ªªÂä°‰∏äÁöÑÊî∂ÁõäÂç¥Âá∫‰∫∫ÊÑèÊñôÂú∞‰∏çÁ®≥ÂÆö„ÄÇÊàë‰ª¨ÂØπÊúÄÂÖàËøõÁöÑMLLMÂÜÖÈÉ®ÁöÑË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõËøõË°åÂÆöÈáèÂàÜÊûêÔºåÊè≠Á§∫‰∫Ü‰∏Ä‰∏™Ê†∏ÂøÉÂ§±ÊïàÊ®°ÂºèÔºöÂú®Â§öËØ¥ËØù‰∫∫Âú∫ÊôØ‰∏≠ÔºåËßÜËßâÂíåÊñáÊú¨tokenÁº∫‰πèËØ¥ËØù‰∫∫‰∏ÄËá¥ÁöÑÂØπÈΩêÔºåË°®Áé∞Âá∫ÊØî‰ª•ÂØπË±°‰∏∫‰∏≠ÂøÉÁöÑÂõæÂÉèÂº±ÂæóÂ§öÁöÑË∑®Ê®°ÊÄÅÊ≥®ÊÑèÂäõ„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∏™ÈóÆÈ¢òÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÂ§öÊ®°ÊÄÅÂ§öËØ¥ËØù‰∫∫Ê≥®ÊÑèÂäõÂØπÈΩêÊñπÊ≥ïÔºåÂèØ‰ª•ÈõÜÊàêÂà∞Áé∞ÊúâÁöÑMLLM‰∏≠„ÄÇÈ¶ñÂÖàÔºåÊàë‰ª¨ÂºïÂÖ•Âä®ÊÄÅË∑®Ê®°ÊÄÅÂ§¥ÈÄâÊã©Êù•ËØÜÂà´ÊúÄË¥üË¥£Êé•Âú∞ÁöÑÊ≥®ÊÑèÂäõÂ§¥„ÄÇÁÑ∂ÂêéÔºåÂ∞Ü‰ªéÁé∞ÊúâÊ≥®ÊÑèÂäõÊ®°ÂºèÂíåËØ¥ËØù‰∫∫‰ΩçÁΩÆËÆ°ÁÆóÂá∫ÁöÑËá™ÈÄÇÂ∫îÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÊ≥®ÂÖ•Âà∞Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠„ÄÇËøôÁßçÂÅèÂ∑ÆÂ¢ûÂº∫‰∫ÜËØ¥ËØù‰∫∫ÁöÑËßÜËßâË°®Á§∫Âíå‰ªñ‰ª¨ÁöÑË®ÄËØ≠‰πãÈó¥ÁöÑÂØπÈΩêÔºåËÄåÊó†ÈúÄÂºïÂÖ•ÂèØËÆ≠ÁªÉÁöÑÂèÇÊï∞ÊàñÊû∂ÊûÑÊõ¥Êîπ„ÄÇÊàë‰ª¨Â∞ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÈõÜÊàêÂà∞‰∏â‰∏™‰∏çÂêåÁöÑMLLMÔºàLLaVA-NeXT-Video„ÄÅQwen2.5-VL Âíå InternVL3Ôºâ‰∏≠ÔºåÂπ∂Âú®‰∏â‰∏™Âü∫ÂáÜÔºàTVQA+„ÄÅMMSI„ÄÅOnlineMMSIÔºâ‰∏äËøõË°åËØÑ‰º∞„ÄÇÂú®Âõõ‰∏™Á§æ‰∫§‰ªªÂä°‰∏≠ÔºåÁªìÊûúË°®ÊòéÊàë‰ª¨ÁöÑÊñπÊ≥ïÊèêÈ´ò‰∫ÜMLLMÁöÑËÉΩÂäõÔºåÂπ∂ÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÁªìÊûú„ÄÇÊ≥®ÊÑèÂäõÂèØËßÜÂåñËØÅÂÆû‰∫ÜÊàë‰ª¨ÁöÑÊñπÊ≥ïÊàêÂäüÂú∞Â∞ÜÊ®°ÂûãÈõÜ‰∏≠Âú®‰∏éËØ¥ËØù‰∫∫Áõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºå‰ªéËÄåÂÆûÁé∞‰∫ÜÊõ¥Âº∫Â§ßÁöÑÂ§öÊñπÁ§æ‰∫§Êé®ÁêÜ„ÄÇÊàë‰ª¨ÁöÑÂÆûÁé∞ÂíåÊ®°ÂûãÂ∞ÜÂú®https://github.com/ut-vision/SocialInteraction‰∏äÊèê‰æõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Â§öÊ®°ÊÄÅÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàMLLMÔºâÂú®ÁêÜËß£Â§öËØ¥ËØù‰∫∫Á§æ‰∫§‰∫íÂä®Âú∫ÊôØÊó∂ÔºåÁî±‰∫éËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØÁº∫‰πèËØ¥ËØù‰∫∫‰∏ÄËá¥ÁöÑÂØπÈΩêËÄåÂØºËá¥ÁöÑÊÄßËÉΩÁì∂È¢à„ÄÇÁé∞ÊúâÊñπÊ≥ïÁÆÄÂçïÂú∞Â∞ÜËßÜËßâ‰ø°ÊÅØÂä†ÂÖ•MLLMÔºåÊó†Ê≥ïÊúâÊïàÊçïÊçâËØ¥ËØù‰∫∫‰πãÈó¥ÁöÑÂÖ≥Á≥ªÔºåÂØºËá¥Ê®°ÂûãÂú®Á§æ‰∫§Êé®ÁêÜ‰ªªÂä°‰∏≠Ë°®Áé∞‰∏ç‰Ω≥„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂ¢ûÂº∫MLLM‰∏≠ËßÜËßâÂíåÊñáÊú¨token‰πãÈó¥ÁöÑËØ¥ËØù‰∫∫‰∏ÄËá¥ÊÄßÂØπÈΩêÊù•ÊèêÂçáÊ®°ÂûãÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåÈÄöËøáÂä®ÊÄÅÈÄâÊã©Ë¥üË¥£Ë∑®Ê®°ÊÄÅÊé•Âú∞ÁöÑÊ≥®ÊÑèÂäõÂ§¥ÔºåÂπ∂ÂºïÂÖ•Ëá™ÈÄÇÂ∫îÁöÑÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÔºå‰ªéËÄåÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®‰∏éËØ¥ËØù‰∫∫Áõ∏ÂÖ≥ÁöÑËßÜËßâÂå∫ÂüüÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÂØπÂ∫îÁöÑÊñáÊú¨‰ø°ÊÅØÂØπÈΩê„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•ÊñπÊ≥ï‰∏ªË¶ÅÂåÖÂê´‰∏§‰∏™ÂÖ≥ÈîÆÊ®°ÂùóÔºöÂä®ÊÄÅË∑®Ê®°ÊÄÅÂ§¥ÈÄâÊã©ÂíåËá™ÈÄÇÂ∫îÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑Æ„ÄÇÈ¶ñÂÖàÔºåÂä®ÊÄÅË∑®Ê®°ÊÄÅÂ§¥ÈÄâÊã©Ê®°ÂùóÁî®‰∫éËØÜÂà´ÂØπË∑®Ê®°ÊÄÅ‰ø°ÊÅØËûçÂêàË¥°ÁåÆÊúÄÂ§ßÁöÑÊ≥®ÊÑèÂäõÂ§¥„ÄÇÁÑ∂ÂêéÔºåËá™ÈÄÇÂ∫îÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÊ®°ÂùóÂà©Áî®ËØ¥ËØù‰∫∫ÁöÑ‰ΩçÁΩÆ‰ø°ÊÅØÂíåÁé∞ÊúâÁöÑÊ≥®ÊÑèÂäõÊ®°ÂºèÔºåËÆ°ÁÆóÂá∫‰∏Ä‰∏™Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÔºåÂπ∂Â∞ÜÂÖ∂Ê≥®ÂÖ•Âà∞Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠Ôºå‰ªéËÄåÂ¢ûÂº∫ËØ¥ËØù‰∫∫ËßÜËßâË°®Á§∫ÂíåÊñáÊú¨‰ø°ÊÅØ‰πãÈó¥ÁöÑÂØπÈΩê„ÄÇÊï¥‰∏™Ê°ÜÊû∂ÂèØ‰ª•Êó†ÁºùÈõÜÊàêÂà∞Áé∞ÊúâÁöÑMLLM‰∏≠ÔºåÊó†ÈúÄ‰øÆÊîπÊ®°ÂûãÊû∂ÊûÑÊàñÂºïÂÖ•È¢ùÂ§ñÁöÑÂèØËÆ≠ÁªÉÂèÇÊï∞„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ÊñπÊ≥ïÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÊèêÂá∫‰∫Ü‰∏Ä‰∏™Êó†ÈúÄËÆ≠ÁªÉÂèÇÊï∞ÁöÑÊ≥®ÊÑèÂäõÂØπÈΩêÊú∫Âà∂ÔºåËÉΩÂ§üÊúâÊïàÂú∞Â¢ûÂº∫Â§öËØ¥ËØù‰∫∫Âú∫ÊôØ‰∏ãËßÜËßâÂíåÊñáÊú¨‰ø°ÊÅØÁöÑÂØπÈΩê„ÄÇ‰∏éÁé∞ÊúâÊñπÊ≥ïÁõ∏ÊØîÔºåËØ•ÊñπÊ≥ïÊõ¥Âä†ËΩªÈáèÁ∫ßÔºåÊòì‰∫éÈõÜÊàêÂà∞‰∏çÂêåÁöÑMLLM‰∏≠ÔºåÂπ∂‰∏îËÉΩÂ§üÊòæËëóÊèêÂçáÊ®°ÂûãÂú®Á§æ‰∫§Êé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂä®ÊÄÅË∑®Ê®°ÊÄÅÂ§¥ÈÄâÊã©Ê®°ÂùóÈÄöËøáËÆ°ÁÆóÊØè‰∏™Ê≥®ÊÑèÂäõÂ§¥ÂØπË∑®Ê®°ÊÄÅ‰ø°ÊÅØËûçÂêàÁöÑË¥°ÁåÆÂ∫¶Êù•ÈÄâÊã©ÂêàÈÄÇÁöÑÊ≥®ÊÑèÂäõÂ§¥„ÄÇËá™ÈÄÇÂ∫îÁ§æ‰∫§ÊÑüÁü•Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÊ®°ÂùóÂà©Áî®ËØ¥ËØù‰∫∫ÁöÑ‰ΩçÁΩÆ‰ø°ÊÅØÂíåÁé∞ÊúâÁöÑÊ≥®ÊÑèÂäõÊ®°ÂºèÔºåËÆ°ÁÆóÂá∫‰∏Ä‰∏™Ê≥®ÊÑèÂäõÂÅèÂ∑ÆÔºåËØ•ÂÅèÂ∑ÆËÉΩÂ§üÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®‰∏éËØ¥ËØù‰∫∫Áõ∏ÂÖ≥ÁöÑËßÜËßâÂå∫ÂüüÔºåÂπ∂Â∞ÜÂÖ∂‰∏éÂØπÂ∫îÁöÑÊñáÊú¨‰ø°ÊÅØÂØπÈΩê„ÄÇÊ≥®ÊÑèÂäõÂÅèÂ∑ÆÁöÑÂÖ∑‰ΩìËÆ°ÁÆóÊñπÂºèÂèØËÉΩÊ∂âÂèäÂà∞Ë∑ùÁ¶ªË°∞Âáè„ÄÅÊ≥®ÊÑèÂäõÊùÉÈáçÂΩí‰∏ÄÂåñÁ≠âÊäÄÊúØÁªÜËäÇ„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ËØ•ÊñπÊ≥ïÂú®TVQA+„ÄÅMMSIÂíåOnlineMMSI‰∏â‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇ‰æãÂ¶ÇÔºåÂú®TVQA+Êï∞ÊçÆÈõÜ‰∏äÔºåËØ•ÊñπÊ≥ïÁõ∏ËæÉ‰∫éÂü∫Á∫øÊ®°ÂûãÂèñÂæó‰∫ÜX%ÁöÑÊÄßËÉΩÊèêÂçáÔºàÂÖ∑‰ΩìÊï∞ÊçÆËØ∑ÂèÇËÄÉÂéüËÆ∫ÊñáÔºâ„ÄÇÊ≥®ÊÑèÂäõÂèØËßÜÂåñÁªìÊûúË°®ÊòéÔºåËØ•ÊñπÊ≥ïËÉΩÂ§üÊúâÊïàÂú∞ÂºïÂØºÊ®°ÂûãÂÖ≥Ê≥®‰∏éËØ¥ËØù‰∫∫Áõ∏ÂÖ≥ÁöÑËßÜËßâÂå∫ÂüüÔºå‰ªéËÄåÊèêÂçáÊ®°ÂûãÂú®Á§æ‰∫§Êé®ÁêÜ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÊô∫ËÉΩÁõëÊéß„ÄÅ‰∫∫Êú∫‰∫§‰∫í„ÄÅÁ§æ‰∫§Â™í‰ΩìÂàÜÊûêÁ≠âÈ¢ÜÂüü„ÄÇ‰æãÂ¶ÇÔºåÂú®Êô∫ËÉΩÁõëÊéß‰∏≠ÔºåÂèØ‰ª•Âà©Áî®ËØ•ÊñπÊ≥ïÁêÜËß£ÁõëÊéßËßÜÈ¢ë‰∏≠‰∫∫Áæ§ÁöÑ‰∫íÂä®Ë°å‰∏∫Ôºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩÁöÑÂÆâÂÖ®È¢ÑË≠¶„ÄÇÂú®‰∫∫Êú∫‰∫§‰∫í‰∏≠ÔºåÂèØ‰ª•Â∏ÆÂä©Êú∫Âô®‰∫∫Êõ¥Â•ΩÂú∞ÁêÜËß£‰∫∫Á±ªÁöÑÁ§æ‰∫§ÊÑèÂõæÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑ‰∫∫Êú∫‰∫§‰∫í„ÄÇÂú®Á§æ‰∫§Â™í‰ΩìÂàÜÊûê‰∏≠ÔºåÂèØ‰ª•Áî®‰∫éÂàÜÊûêÁ§æ‰∫§Â™í‰ΩìËßÜÈ¢ë‰∏≠Áî®Êà∑ÁöÑ‰∫íÂä®Ë°å‰∏∫Ôºå‰ªéËÄåÊåñÊéòÊõ¥Êúâ‰ª∑ÂÄºÁöÑ‰ø°ÊÅØ„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Understanding social interaction in video requires reasoning over a dynamic interplay of verbal and non-verbal cues: who is speaking, to whom, and with what gaze or gestures. While Multimodal Large Language Models (MLLMs) are natural candidates, simply adding visual inputs yields surprisingly inconsistent gains on social tasks. Our quantitative analysis of cross-modal attention inside state-of-the-art MLLMs reveals a core failure mode: in multi-speaker scenes, visual and textual tokens lack speaker-consistent alignment, exhibiting substantially weaker cross-modal attention than in object-centric images. To address this, we propose a multimodal multi-speaker attention alignment method that can be integrated into existing MLLMs. First, we introduce dynamic cross-modal head selection to identify attention heads most responsible for grounding. Then, an adaptive social-aware attention bias, computed from existing attention patterns and speaker locations, is injected into the attention mechanism. This bias reinforces alignment between a speaker's visual representation and their utterances without introducing trainable parameters or architectural changes. We integrate our method into three distinct MLLMs (LLaVA-NeXT-Video, Qwen2.5-VL, and InternVL3) and evaluate on three benchmarks (TVQA+, MMSI, OnlineMMSI). Across four social tasks, results demonstrate that our approach improves the ability of MLLMs and achieves state-of-the-art results. Attention visualizations confirm our method successfully focuses the model on speaker-relevant regions, enabling more robust multi-party social reasoning. Our implementation and model will be available at https://github.com/ut-vision/SocialInteraction.

