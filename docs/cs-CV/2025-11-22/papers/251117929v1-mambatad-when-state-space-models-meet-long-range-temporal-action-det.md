---
layout: default
title: MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection
---

# MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.17929" target="_blank" class="toolbar-btn">arXiv: 2511.17929v1</a>
    <a href="https://arxiv.org/pdf/2511.17929.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.17929v1" 
            onclick="toggleFavorite(this, '2511.17929v1', 'MambaTAD: When State-Space Models Meet Long-Range Temporal Action Detection')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Hui Lu, Yi Yu, Shijian Lu, Deepu Rajan, Boon Poh Ng, Alex C. Kot, Xudong Jiang

**ÂàÜÁ±ª**: cs.CV, cs.AI

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-22

**ÊúüÂàä**: IEEE Transactions on Multimedia, 2025

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**MambaTADÔºöÁªìÂêàÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÈïøÁ®ãÊó∂Â∫èÂä®‰ΩúÊ£ÄÊµãÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)**

**ÂÖ≥ÈîÆËØç**: `Êó∂Â∫èÂä®‰ΩúÊ£ÄÊµã` `Áä∂ÊÄÅÁ©∫Èó¥Ê®°Âûã` `Mamba` `ÈïøÁ®ãÂª∫Ê®°` `ÂÖ®Â±ÄÁâπÂæÅËûçÂêà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâTADÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøË∑®Â∫¶Âä®‰ΩúÊó∂ÔºåÈù¢‰∏¥ÂÖ®Â±ÄÊÑüÁü•‰∏çË∂≥ÂíåÊ£ÄÊµãÂ§¥ÊïàÁéá‰Ωé‰∏ãÁöÑÈóÆÈ¢ò„ÄÇ
2. MambaTADÈÄöËøáÂºïÂÖ•ÂØπËßíÊé©Á†ÅÂèåÂêëÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂùóÂíåÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÔºåÂ¢ûÂº∫ÈïøÁ®ãÂª∫Ê®°ÂíåÂÖ®Â±ÄÁâπÂæÅÊ£ÄÊµãËÉΩÂäõ„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåMambaTADÂú®Â§ö‰∏™ÂÖ¨ÂºÄÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Ü‰ºò‰∫éÁé∞ÊúâÊñπÊ≥ïÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êó∂Â∫èÂä®‰ΩúÊ£ÄÊµã(TAD)Êó®Âú®ÈÄöËøáÁ°ÆÂÆöÊú™Ââ™ËæëËßÜÈ¢ë‰∏≠Âä®‰ΩúÁöÑËµ∑ÂßãÂíåÁªìÊùüÂ∏ßÊù•ËØÜÂà´ÂíåÂÆö‰ΩçÂä®‰Ωú„ÄÇÊúÄËøëÁöÑÁªìÊûÑÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÔºåÂ¶ÇMambaÔºåÁî±‰∫éÂÖ∂ÈïøÁ®ãÂª∫Ê®°ËÉΩÂäõÂíåÁ∫øÊÄßËÆ°ÁÆóÂ§çÊùÇÂ∫¶ÔºåÂú®TAD‰∏≠Â±ïÁé∞Âá∫ÊΩúÂäõ„ÄÇÁÑ∂ËÄåÔºåÁªìÊûÑÂåñÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÂú®TAD‰∏≠Â∏∏Èù¢‰∏¥‰∏§‰∏™ÂÖ≥ÈîÆÊåëÊàòÔºöÁî±ÈÄíÂΩíÂ§ÑÁêÜÂºïËµ∑ÁöÑÊó∂Èó¥‰∏ä‰∏ãÊñáË°∞ÂáèÔºå‰ª•ÂèäÂÖ®Â±ÄËßÜËßâ‰∏ä‰∏ãÊñáÂª∫Ê®°ÊúüÈó¥ÁöÑËá™ÂÖÉÁ¥†ÂÜ≤Á™ÅÔºåËøôÂú®Â§ÑÁêÜÈïøË∑®Â∫¶Âä®‰ΩúÂÆû‰æãÊó∂ÂèòÂæóÊõ¥Âä†‰∏•Èáç„ÄÇÊ≠§Â§ñÔºåÁî±‰∫éÁº∫‰πèÂÖ®Â±ÄÊÑüÁü•Âíå‰ΩéÊïàÁöÑÊ£ÄÊµãÂ§¥Ôºå‰º†ÁªüTADÊñπÊ≥ïÈöæ‰ª•Ê£ÄÊµãÈïøË∑®Â∫¶Âä®‰ΩúÂÆû‰æã„ÄÇÊú¨ÊñáÊèêÂá∫‰∫ÜMambaTADÔºå‰∏ÄÁßçÊñ∞ÁöÑÁä∂ÊÄÅÁ©∫Èó¥TADÊ®°ÂûãÔºåÂºïÂÖ•‰∫ÜÈïøÁ®ãÂª∫Ê®°ÂíåÂÖ®Â±ÄÁâπÂæÅÊ£ÄÊµãËÉΩÂäõÔºå‰ª•ÂÆûÁé∞Á≤æÁ°ÆÁöÑÊó∂Â∫èÂä®‰ΩúÊ£ÄÊµã„ÄÇMambaTADÂåÖÂê´‰∏§‰∏™Áõ∏‰∫íË°•ÂÖÖÁöÑÊñ∞È¢ñËÆæËÆ°Ôºå‰ª•ÂÆûÁé∞ÂçìË∂äÁöÑTADÊÄßËÉΩ„ÄÇÈ¶ñÂÖàÔºåÂÆÉÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂØπËßíÊé©Á†ÅÂèåÂêëÁä∂ÊÄÅÁ©∫Èó¥(DMBSS)Ê®°ÂùóÔºåÊúâÊïàÂú∞‰øÉËøõ‰∫ÜÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂíåÊó∂Â∫èÂä®‰ΩúÊ£ÄÊµã„ÄÇÂÖ∂Ê¨°ÔºåÂÆÉÂºïÂÖ•‰∫Ü‰∏Ä‰∏™ÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÔºåÈÄöËøáÂ§öÁ≤íÂ∫¶ÁâπÂæÅÂíåÂÖ®Â±ÄÊÑüÁü•ÈÄêÊ≠•ÁªÜÂåñÊ£ÄÊµã„ÄÇÊ≠§Â§ñÔºåMambaTAD‰ΩøÁî®‰∏ÄÁßçÊñ∞ÁöÑÁä∂ÊÄÅÁ©∫Èó¥Êó∂Èó¥ÈÄÇÈÖçÂô®(SSTA)Ôºå‰ª•Á´ØÂà∞Á´ØÂçïÈò∂ÊÆµÁöÑÊñπÂºèÂ§ÑÁêÜTADÔºå‰ªéËÄå‰ª•Á∫øÊÄßÂ§çÊùÇÂ∫¶Èôç‰ΩéÁΩëÁªúÂèÇÊï∞ÂíåËÆ°ÁÆóÊàêÊú¨„ÄÇÂ§ßÈáèÂÆûÈ™åË°®ÊòéÔºåMambaTADÂú®Â§ö‰∏™ÂÖ¨ÂÖ±Âü∫ÂáÜÊµãËØï‰∏≠ÂßãÁªàÂ¶Ç‰∏ÄÂú∞ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑTADÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöËÆ∫ÊñáÊó®Âú®Ëß£ÂÜ≥Êó∂Â∫èÂä®‰ΩúÊ£ÄÊµãÔºàTADÔºâ‰∏≠ÔºåÁé∞ÊúâÊñπÊ≥ïÂú®Â§ÑÁêÜÈïøË∑®Â∫¶Âä®‰ΩúÂÆû‰æãÊó∂ÔºåÁî±‰∫éÁº∫‰πèÂÖ®Â±ÄÊÑüÁü•Âíå‰ΩéÊïàÁöÑÊ£ÄÊµãÂ§¥ËÄåÂØºËá¥ÁöÑÊ£ÄÊµãÁ≤æÂ∫¶‰∏ãÈôçÈóÆÈ¢ò„ÄÇÁâπÂà´ÊòØÔºåÂü∫‰∫éÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÊñπÊ≥ïÂú®TAD‰∏≠Èù¢‰∏¥Êó∂Èó¥‰∏ä‰∏ãÊñáË°∞ÂáèÂíåËá™ÂÖÉÁ¥†ÂÜ≤Á™ÅÁöÑÊåëÊàò„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöËÆ∫ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂà©Áî®MambaÁä∂ÊÄÅÁ©∫Èó¥Ê®°ÂûãÁöÑÈïøÁ®ãÂª∫Ê®°ËÉΩÂäõÔºåÂπ∂ËÆæËÆ°Êñ∞ÁöÑÊ®°ÂùóÊù•ÂÖãÊúçÂÖ∂Âú®TAD‰ªªÂä°‰∏≠ÁöÑÂ±ÄÈôêÊÄß„ÄÇÈÄöËøáÂºïÂÖ•ÂØπËßíÊé©Á†ÅÂèåÂêëÁä∂ÊÄÅÁ©∫Èó¥ÔºàDMBSSÔºâÊ®°ÂùóÂíåÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÔºåÂ¢ûÂº∫Ê®°ÂûãÂØπÂÖ®Â±Ä‰∏ä‰∏ãÊñáÁöÑÁêÜËß£ÂíåÂØπÈïøË∑®Â∫¶Âä®‰ΩúÁöÑÊ£ÄÊµãËÉΩÂäõ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöMambaTADÈááÁî®Á´ØÂà∞Á´ØÂçïÈò∂ÊÆµÁöÑÊ£ÄÊµãÊ°ÜÊû∂„ÄÇÈ¶ñÂÖàÔºå‰ΩøÁî®Áä∂ÊÄÅÁ©∫Èó¥Êó∂Èó¥ÈÄÇÈÖçÂô®ÔºàSSTAÔºâÊèêÂèñËßÜÈ¢ëÁâπÂæÅ„ÄÇÁÑ∂ÂêéÔºåÈÄöËøáDMBSSÊ®°ÂùóËøõË°åÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂíåÊó∂Â∫èÂª∫Ê®°„ÄÇÊúÄÂêéÔºåÂà©Áî®ÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÔºåÁªìÂêàÂ§öÁ≤íÂ∫¶ÁâπÂæÅËøõË°åÂä®‰ΩúÊ£ÄÊµã„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éDMBSSÊ®°ÂùóÂíåÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÁöÑËÆæËÆ°„ÄÇDMBSSÊ®°ÂùóÈÄöËøáÂØπËßíÊé©Á†ÅÊú∫Âà∂ÔºåÈÅøÂÖç‰∫ÜËá™ÂÖÉÁ¥†ÂÜ≤Á™ÅÔºåÂπ∂‰øÉËøõ‰∫ÜÂÖ®Â±ÄÁâπÂæÅËûçÂêà„ÄÇÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥Âà©Áî®Â§öÁ≤íÂ∫¶ÁâπÂæÅÂíåÂÖ®Â±ÄÊÑüÁü•ÔºåÈÄêÊ≠•ÁªÜÂåñÊ£ÄÊµãÁªìÊûúÔºåÊèêÈ´ò‰∫ÜÊ£ÄÊµãÁ≤æÂ∫¶„ÄÇÊ≠§Â§ñÔºåSSTAÁöÑ‰ΩøÁî®Èôç‰Ωé‰∫ÜÂèÇÊï∞ÈáèÂíåËÆ°ÁÆóÂ§çÊùÇÂ∫¶„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöDMBSSÊ®°ÂùóÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂØπËßíÊé©Á†ÅÔºåÂÆÉÈòªÊ≠¢‰∫ÜÂêå‰∏ÄÊó∂Èó¥Ê≠•ÁöÑÁâπÂæÅ‰πãÈó¥ÁöÑÁõ∏‰∫í‰ΩúÁî®Ôºå‰ªéËÄåÈÅøÂÖç‰∫ÜËá™ÂÖÉÁ¥†ÂÜ≤Á™Å„ÄÇÂÖ®Â±ÄÁâπÂæÅËûçÂêàÂ§¥ÁöÑÂÖ≥ÈîÆËÆæËÆ°Âú®‰∫éÂ§öÁ≤íÂ∫¶ÁâπÂæÅÁöÑËûçÂêàÁ≠ñÁï•ÔºåÂÆÉÂ∞Ü‰∏çÂêåÂ∞∫Â∫¶ÁöÑÁâπÂæÅÁªìÂêàËµ∑Êù•Ôºå‰ª•Ëé∑ÂæóÊõ¥ÂÖ®Èù¢ÁöÑ‰∏ä‰∏ãÊñá‰ø°ÊÅØ„ÄÇSSTAÈÄöËøáÁ∫øÊÄßÂ§çÊùÇÂ∫¶Èôç‰Ωé‰∫ÜÂèÇÊï∞ÈáèÂíåËÆ°ÁÆóÊàêÊú¨ÔºåÂÖ∑‰ΩìÂÆûÁé∞ÁªÜËäÇÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

MambaTADÂú®Â§ö‰∏™ÂÖ¨ÂºÄTADÊï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜÊòæËëóÁöÑÊÄßËÉΩÊèêÂçá„ÄÇÂÖ∑‰ΩìÊï∞ÊçÆÊú™Áü•Ôºå‰ΩÜËÆ∫ÊñáÂº∫Ë∞ÉÂÖ∂Âú®Â§ö‰∏™Âü∫ÂáÜÊµãËØï‰∏≠ÂßãÁªàÂ¶Ç‰∏ÄÂú∞ÂÆûÁé∞‰∫ÜÂçìË∂äÁöÑTADÊÄßËÉΩÔºåË°®ÊòéÂÖ∂ÂÖ∑ÊúâËâØÂ•ΩÁöÑÊ≥õÂåñËÉΩÂäõÂíåÂÆûÁî®‰ª∑ÂÄº„ÄÇÁõ∏ËæÉ‰∫éÁé∞ÊúâÊñπÊ≥ïÔºåMambaTADÂú®ÈïøË∑®Â∫¶Âä®‰ΩúÁöÑÊ£ÄÊµãÊñπÈù¢Ë°®Áé∞Âá∫Êõ¥Âº∫ÁöÑ‰ºòÂäø„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

MambaTADÂú®ËßÜÈ¢ëÁõëÊéß„ÄÅÊô∫ËÉΩÂÆâÈò≤„ÄÅ‰ΩìËÇ≤Ëµõ‰∫ãÂàÜÊûê„ÄÅËßÜÈ¢ëÂÜÖÂÆπÁêÜËß£Á≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éËá™Âä®ËØÜÂà´ÂíåÂÆö‰ΩçËßÜÈ¢ë‰∏≠ÁöÑÂºÇÂ∏∏Ë°å‰∏∫„ÄÅÂÖ≥ÈîÆ‰∫ã‰ª∂ÂíåÊÑüÂÖ¥Ë∂£ÁöÑÂä®‰ΩúÔºå‰ªéËÄåÊèêÈ´òËßÜÈ¢ëÂàÜÊûêÁöÑÊïàÁéáÂíåÂáÜÁ°ÆÊÄß„ÄÇËØ•Á†îÁ©∂ÁöÑÊàêÊûúÊúâÂä©‰∫éÊé®Âä®ËßÜÈ¢ëÁêÜËß£Âíå‰∫∫Â∑•Êô∫ËÉΩÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Temporal Action Detection (TAD) aims to identify and localize actions by determining their starting and ending frames within untrimmed videos. Recent Structured State-Space Models such as Mamba have demonstrated potential in TAD due to their long-range modeling capability and linear computational complexity. On the other hand, structured state-space models often face two key challenges in TAD, namely, decay of temporal context due to recursive processing and self-element conflict during global visual context modeling, which become more severe while handling long-span action instances. Additionally, traditional methods for TAD struggle with detecting long-span action instances due to a lack of global awareness and inefficient detection heads. This paper presents MambaTAD, a new state-space TAD model that introduces long-range modeling and global feature detection capabilities for accurate temporal action detection. MambaTAD comprises two novel designs that complement each other with superior TAD performance. First, it introduces a Diagonal-Masked Bidirectional State-Space (DMBSS) module which effectively facilitates global feature fusion and temporal action detection. Second, it introduces a global feature fusion head that refines the detection progressively with multi-granularity features and global awareness. In addition, MambaTAD tackles TAD in an end-to-end one-stage manner using a new state-space temporal adapter(SSTA) which reduces network parameters and computation cost with linear complexity. Extensive experiments show that MambaTAD achieves superior TAD performance consistently across multiple public benchmarks.

