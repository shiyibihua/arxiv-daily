---
layout: default
title: PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning
---

# PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning

**arXiv**: [2511.17927v1](https://arxiv.org/abs/2511.17927) | [PDF](https://arxiv.org/pdf/2511.17927.pdf)

**ä½œè€…**: Yingjie Ma, Xun Lin, Yong Xu, Weicheng Xie, Zitong Yu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

**å¤‡æ³¨**: Accepted by AAAI 2026 (Oral)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPA-FASï¼Œé€šè¿‡è·¯å¾„å¢žå¼ºå¼ºåŒ–å­¦ä¹ æå‡å¤šæ¨¡æ€äººè„¸åæ¬ºéª—çš„æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `äººè„¸åæ¬ºéª—` `å¤šæ¨¡æ€èžåˆ` `å¼ºåŒ–å­¦ä¹ ` `è·¯å¾„å¢žå¼º` `è·¨åŸŸæ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•åœ¨å¤šæ¨¡æ€äººè„¸åæ¬ºéª—ä¸­ï¼Œé¢ä¸´æŽ¨ç†è·¯å¾„å—é™å’Œå•ä»»åŠ¡ç›‘ç£ä¸Žå¤šæ ·æŽ¨ç†è·¯å¾„ä¸åŒ¹é…çš„é—®é¢˜ï¼Œå¯¼è‡´æ³›åŒ–æ€§å’Œå¯è§£é‡Šæ€§ä¸è¶³ã€‚
2. PA-FASé€šè¿‡æž„å»ºé«˜è´¨é‡çš„æ‰©å±•æŽ¨ç†åºåˆ—æ¥å¢žå¼ºæŽ¨ç†è·¯å¾„ï¼Œå¹¶å¼•å…¥ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶ï¼Œé¿å…æ¨¡åž‹åˆ©ç”¨æ·å¾„ï¼Œä»Žè€Œæå‡æŽ¨ç†æ·±åº¦ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPA-FASæ˜¾è‘—æé«˜äº†å¤šæ¨¡æ€æŽ¨ç†çš„å‡†ç¡®æ€§å’Œè·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå®žçŽ°äº†æ›´å¯ä¿¡èµ–çš„äººè„¸åæ¬ºéª—ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

äººè„¸åæ¬ºéª—(FAS)è¿‘å¹´æ¥åœ¨å¤šæ¨¡æ€èžåˆã€è·¨åŸŸæ³›åŒ–å’Œå¯è§£é‡Šæ€§æ–¹é¢å–å¾—äº†è¿›å±•ã€‚å€ŸåŠ©å¤§åž‹è¯­è¨€æ¨¡åž‹å’Œå¼ºåŒ–å­¦ä¹ (RL)ï¼ŒåŸºäºŽç­–ç•¥çš„è®­ç»ƒä¸ºè”åˆå»ºæ¨¡è¿™äº›æ–¹é¢æä¾›äº†æ–°çš„æœºä¼šã€‚ç„¶è€Œï¼Œå¤šæ¨¡æ€æŽ¨ç†æ¯”å•æ¨¡æ€æŽ¨ç†æ›´å¤æ‚ï¼Œéœ€è¦å‡†ç¡®çš„ç‰¹å¾è¡¨ç¤ºå’Œè·¨æ¨¡æ€éªŒè¯ï¼ŒåŒæ—¶é¢ä¸´é«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œè¿™ä½¿å¾—ç›´æŽ¥åº”ç”¨RLæ•ˆæžœæ¬ ä½³ã€‚æˆ‘ä»¬å‘çŽ°ç›‘ç£å¾®è°ƒåŠ RL(SFT+RL)ç”¨äºŽå¤šæ¨¡æ€FASå­˜åœ¨ä¸¤ä¸ªå…³é”®é™åˆ¶ï¼š(1)æœ‰é™çš„å¤šæ¨¡æ€æŽ¨ç†è·¯å¾„é™åˆ¶äº†äº’è¡¥æ¨¡æ€çš„ä½¿ç”¨ï¼Œå¹¶ç¼©å°äº†SFTåŽçš„æŽ¢ç´¢ç©ºé—´ï¼Œå‰Šå¼±äº†RLçš„æ•ˆæžœï¼›(2)å•ä»»åŠ¡ç›‘ç£ä¸Žå¤šæ ·åŒ–æŽ¨ç†è·¯å¾„ä¸åŒ¹é…å¯¼è‡´æŽ¨ç†æ··æ·†ï¼Œæ¨¡åž‹å¯èƒ½åˆ©ç”¨æ·å¾„å°†å›¾åƒç›´æŽ¥æ˜ å°„åˆ°ç­”æ¡ˆï¼Œè€Œå¿½ç•¥äº†é¢„æœŸçš„æŽ¨ç†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†PA-FASï¼Œå®ƒé€šè¿‡ä»Žæœ‰é™çš„æ ‡æ³¨ä¸­æž„å»ºé«˜è´¨é‡çš„æ‰©å±•æŽ¨ç†åºåˆ—æ¥å¢žå¼ºæŽ¨ç†è·¯å¾„ï¼Œä¸°å¯Œè·¯å¾„å¹¶æ”¾æ¾æŽ¢ç´¢çº¦æŸã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åœ¨SFTæœŸé—´å¼•å…¥äº†ä¸€ç§ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶ï¼Œä»¥å¼ºåˆ¶è¿›è¡Œå…¨é¢çš„å¤šæ¨¡æ€åˆ†æžï¼Œè€Œä¸æ˜¯ä½¿ç”¨è¡¨é¢çº¿ç´¢ï¼Œä»Žè€Œé¼“åŠ±æ›´æ·±å…¥çš„æŽ¨ç†å¹¶å‡è½»æ·å¾„å­¦ä¹ ã€‚PA-FASæ˜¾è‘—æé«˜äº†å¤šæ¨¡æ€æŽ¨ç†çš„å‡†ç¡®æ€§å’Œè·¨åŸŸæ³›åŒ–èƒ½åŠ›ï¼Œå¹¶æ›´å¥½åœ°ç»Ÿä¸€äº†å¤šæ¨¡æ€èžåˆã€æ³›åŒ–å’Œå¯è§£é‡Šæ€§ï¼Œä»Žè€Œå®žçŽ°å¯ä¿¡èµ–çš„FASã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€äººè„¸åæ¬ºéª—ä»»åŠ¡ä¸­ï¼ŒçŽ°æœ‰æ–¹æ³•ç”±äºŽæŽ¨ç†è·¯å¾„å—é™å’Œç›‘ç£æ–¹å¼ä¸å½“å¯¼è‡´çš„æ³›åŒ–èƒ½åŠ›å·®å’Œå¯è§£é‡Šæ€§ä½Žçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸é‡‡ç”¨ç›‘ç£å¾®è°ƒåŠ å¼ºåŒ–å­¦ä¹ (SFT+RL)çš„æ¡†æž¶ï¼Œä½†å­˜åœ¨ä¸¤ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯å¤šæ¨¡æ€æŽ¨ç†è·¯å¾„æœ‰é™ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨ä¸åŒæ¨¡æ€çš„äº’è¡¥ä¿¡æ¯ï¼›äºŒæ˜¯å•ä»»åŠ¡ç›‘ç£å®¹æ˜“å¯¼è‡´æ¨¡åž‹å­¦ä¹ æ·å¾„ï¼Œå¿½ç•¥æ·±å±‚æŽ¨ç†è¿‡ç¨‹ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¢žå¼ºæŽ¨ç†è·¯å¾„å’Œæ”¹è¿›ç›‘ç£æ–¹å¼æ¥æå‡æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“æ¥è¯´ï¼Œé€šè¿‡æž„å»ºé«˜è´¨é‡çš„æ‰©å±•æŽ¨ç†åºåˆ—æ¥ä¸°å¯ŒæŽ¨ç†è·¯å¾„ï¼Œå¹¶é‡‡ç”¨ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶æ¥é¿å…æ¨¡åž‹å­¦ä¹ æ·å¾„ï¼Œä»Žè€Œé¼“åŠ±æ¨¡åž‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æžã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPA-FASçš„æ•´ä½“æ¡†æž¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šé¦–å…ˆæ˜¯ç›‘ç£å¾®è°ƒ(SFT)é˜¶æ®µï¼Œè¯¥é˜¶æ®µä½¿ç”¨ç­”æ¡ˆæ´—ç‰Œæœºåˆ¶æ¥è®­ç»ƒæ¨¡åž‹ï¼Œé¿å…æ¨¡åž‹å­¦ä¹ æ·å¾„ã€‚ç„¶åŽæ˜¯å¼ºåŒ–å­¦ä¹ (RL)é˜¶æ®µï¼Œè¯¥é˜¶æ®µä½¿ç”¨å¢žå¼ºçš„æŽ¨ç†è·¯å¾„æ¥è®­ç»ƒæ¨¡åž‹ï¼Œé¼“åŠ±æ¨¡åž‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æžã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†è·¯å¾„å¢žå¼ºå’Œç­”æ¡ˆæ´—ç‰Œä¸¤ç§æœºåˆ¶ã€‚è·¯å¾„å¢žå¼ºé€šè¿‡æž„å»ºé«˜è´¨é‡çš„æ‰©å±•æŽ¨ç†åºåˆ—æ¥ä¸°å¯ŒæŽ¨ç†è·¯å¾„ï¼Œä»Žè€Œæå‡æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ã€‚ç­”æ¡ˆæ´—ç‰Œé€šè¿‡éšæœºæ‰“ä¹±ç­”æ¡ˆçš„é¡ºåºæ¥é¿å…æ¨¡åž‹å­¦ä¹ æ·å¾„ï¼Œä»Žè€Œé¼“åŠ±æ¨¡åž‹è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æžã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨SFTé˜¶æ®µï¼Œç­”æ¡ˆæ´—ç‰Œæœºåˆ¶é€šè¿‡éšæœºæ‰“ä¹±è®­ç»ƒæ ·æœ¬çš„ç­”æ¡ˆé¡ºåºï¼Œè¿«ä½¿æ¨¡åž‹ä¸èƒ½ç®€å•åœ°å°†å›¾åƒæ˜ å°„åˆ°ç­”æ¡ˆï¼Œè€Œæ˜¯éœ€è¦è¿›è¡Œæ›´æ·±å…¥çš„å¤šæ¨¡æ€åˆ†æžã€‚åœ¨RLé˜¶æ®µï¼Œè·¯å¾„å¢žå¼ºé€šè¿‡æž„å»ºé«˜è´¨é‡çš„æ‰©å±•æŽ¨ç†åºåˆ—ï¼Œä¸ºæ¨¡åž‹æä¾›æ›´å¤šçš„æŽ¢ç´¢ç©ºé—´ï¼Œä»Žè€Œæå‡æ¨¡åž‹çš„æŽ¨ç†èƒ½åŠ›ã€‚å…·ä½“çš„æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

PA-FASåœ¨å¤šä¸ªäººè„¸åæ¬ºéª—æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPA-FASä¸ä»…æé«˜äº†å¤šæ¨¡æ€æŽ¨ç†çš„å‡†ç¡®æ€§ï¼Œè¿˜æ˜¾è‘—æå‡äº†è·¨åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽèº«ä»½éªŒè¯ã€è®¿é—®æŽ§åˆ¶ã€é‡‘èžå®‰å…¨ç­‰é¢†åŸŸï¼Œæœ‰æ•ˆé˜²å¾¡åŸºäºŽäººè„¸æ¬ºéª—çš„æ”»å‡»ï¼Œæå‡ç³»ç»Ÿçš„å®‰å…¨æ€§ä¸Žå¯é æ€§ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ‰©å±•åˆ°æ›´å¤šæ¨¡æ€å’Œæ›´å¤æ‚çš„åæ¬ºéª—åœºæ™¯ï¼Œä¾‹å¦‚è¯­éŸ³åæ¬ºéª—ã€è¡Œä¸ºåæ¬ºéª—ç­‰ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Face anti-spoofing (FAS) has recently advanced in multimodal fusion, cross-domain generalization, and interpretability. With large language models and reinforcement learning (RL), strategy-based training offers new opportunities to jointly model these aspects. However, multimodal reasoning is more complex than unimodal reasoning, requiring accurate feature representation and cross-modal verification while facing scarce, high-quality annotations, which makes direct application of RL sub-optimal. We identify two key limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1) limited multimodal reasoning paths restrict the use of complementary modalities and shrink the exploration space after SFT, weakening the effect of RL; and (2) mismatched single-task supervision versus diverse reasoning paths causes reasoning confusion, where models may exploit shortcuts by mapping images directly to answers and ignoring the intended reasoning. To address this, we propose PA-FAS, which enhances reasoning paths by constructing high-quality extended reasoning sequences from limited annotations, enriching paths and relaxing exploration constraints. We further introduce an answer-shuffling mechanism during SFT to force comprehensive multimodal analysis instead of using superficial cues, thereby encouraging deeper reasoning and mitigating shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy and cross-domain generalization, and better unifies multimodal fusion, generalization, and interpretability for trustworthy FAS.

