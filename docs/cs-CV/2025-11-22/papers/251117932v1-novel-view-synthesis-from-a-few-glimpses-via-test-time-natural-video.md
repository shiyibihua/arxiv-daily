---
layout: default
title: Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion
---

# Novel View Synthesis from A Few Glimpses via Test-Time Natural Video Completion

**arXiv**: [2511.17932v1](https://arxiv.org/abs/2511.17932) | [PDF](https://arxiv.org/pdf/2511.17932.pdf)

**ä½œè€…**: Yan Xu, Yixing Wang, Stella X. Yu

**åˆ†ç±»**: cs.CV, cs.GR

**å‘å¸ƒæ—¥æœŸ**: 2025-11-22

**å¤‡æ³¨**: Accepted to NeurIPS 2025

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè§†é¢‘æ‰©æ•£æ¨¡åž‹çš„é›¶æ ·æœ¬æ–°è§†è§’åˆæˆæ–¹æ³•ï¼Œè§£å†³ç¨€ç–è§†è§’ä¸‹çš„åœºæ™¯é‡å»ºé—®é¢˜ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `æ–°è§†è§’åˆæˆ` `è§†é¢‘æ‰©æ•£æ¨¡åž‹` `é›¶æ ·æœ¬å­¦ä¹ ` `3Dé«˜æ–¯æº…å°„` `åœºæ™¯é‡å»º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–°è§†è§’åˆæˆæ–¹æ³•åœ¨ç¨€ç–è§†è§’è¾“å…¥ä¸‹è¡¨çŽ°ä¸ä½³ï¼Œéš¾ä»¥é‡å»ºé«˜è´¨é‡çš„åœºæ™¯ã€‚
2. åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡åž‹ä½œä¸ºå…ˆéªŒï¼Œé€šè¿‡æµ‹è¯•æ—¶è‡ªç„¶è§†é¢‘è¡¥å…¨ç”Ÿæˆä¸­é—´è§†è§’ï¼ŒæŒ‡å¯¼3Dåœºæ™¯é‡å»ºã€‚
3. å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨ç¨€ç–è¾“å…¥ä¸‹æ˜¾è‘—ä¼˜äºŽ3D-GSåŸºçº¿ï¼Œæ— éœ€åœºæ™¯ç‰¹å®šè®­ç»ƒæˆ–å¾®è°ƒã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§ä»Žå°‘é‡åœºæ™¯å›¾åƒä¸­åˆæˆæ–°è§†è§’çš„æ–¹æ¡ˆï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†è¯¥ä»»åŠ¡è§†ä¸ºæµ‹è¯•æ—¶è‡ªç„¶è§†é¢‘è¡¥å…¨é—®é¢˜ï¼Œåˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡åž‹å¼ºå¤§çš„å…ˆéªŒçŸ¥è¯†æ¥ç”Ÿæˆåˆç†çš„ä¸­é—´è§†è§’ã€‚è¯¥é›¶æ ·æœ¬ã€ç”Ÿæˆå¼•å¯¼çš„æ¡†æž¶èƒ½å¤Ÿæ ¹æ®æ–°çš„ç›¸æœºå§¿æ€ç”Ÿæˆä¼ªè§†è§’ï¼Œå¹¶é‡‡ç”¨ä¸ç¡®å®šæ€§æ„ŸçŸ¥æœºåˆ¶æ¥ä¿è¯ç©ºé—´ä¸€è‡´æ€§ã€‚è¿™äº›åˆæˆå¸§ä¸º3Dé«˜æ–¯æº…å°„ï¼ˆ3D-GSï¼‰æä¾›äº†å¯†é›†çš„ç›‘ç£ä¿¡å·ï¼Œå°¤å…¶æ˜¯åœ¨æ¬ è§‚æµ‹åŒºåŸŸã€‚é€šè¿‡è¿­ä»£åé¦ˆå¾ªçŽ¯ï¼Œ3Då‡ ä½•å’Œ2Dè§†è§’åˆæˆç›¸äº’ä¿ƒè¿›ï¼Œä»Žè€Œæ”¹è¿›åœºæ™¯é‡å»ºå’Œç”Ÿæˆè§†è§’çš„è´¨é‡ã€‚è¯¥æ–¹æ³•æ— éœ€ä»»ä½•ç‰¹å®šåœºæ™¯çš„è®­ç»ƒæˆ–å¾®è°ƒï¼Œå³å¯ä»Žç¨€ç–è¾“å…¥ä¸­ç”Ÿæˆè¿žè´¯ã€é«˜ä¿çœŸçš„æ¸²æŸ“ç»“æžœã€‚åœ¨LLFFã€DTUã€DL3DVå’ŒMipNeRF-360æ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•åœ¨æžç«¯ç¨€ç–æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºŽå¼ºå¤§çš„3D-GSåŸºçº¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³ä»Žæžå°‘é‡ï¼ˆç¨€ç–ï¼‰çš„åœºæ™¯å›¾åƒä¸­åˆæˆé«˜è´¨é‡æ–°è§†è§’å›¾åƒçš„é—®é¢˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨ç¨€ç–è¾“å…¥ä¸‹ï¼Œç”±äºŽç¼ºä¹è¶³å¤Ÿçš„å‡ ä½•ä¿¡æ¯å’Œçº¹ç†ä¿¡æ¯ï¼Œéš¾ä»¥å‡†ç¡®é‡å»ºåœºæ™¯ï¼Œå¯¼è‡´åˆæˆçš„æ–°è§†è§’å›¾åƒè´¨é‡è¾ƒå·®ã€‚å°¤å…¶æ˜¯åœ¨æ¬ è§‚æµ‹åŒºåŸŸï¼Œé‡å»ºæ•ˆæžœæ›´ä¸ºæ˜Žæ˜¾åœ°ä¸‹é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ–°è§†è§’åˆæˆé—®é¢˜è½¬åŒ–ä¸ºä¸€ä¸ªæµ‹è¯•æ—¶è‡ªç„¶è§†é¢‘è¡¥å…¨é—®é¢˜ã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯åˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹å¼ºå¤§çš„ç”Ÿæˆèƒ½åŠ›ï¼Œæ ¹æ®ç»™å®šçš„ç¨€ç–è§†è§’å›¾åƒï¼Œç”Ÿæˆä¸€ç³»åˆ—è¿žè´¯çš„ä¸­é—´è§†è§’å›¾åƒï¼Œä»Žè€Œâ€œè¡¥å…¨â€ä¸€ä¸ªè™šæ‹Ÿçš„ç›¸æœºè¿åŠ¨è½¨è¿¹ã€‚è¿™æ ·ï¼Œå°±å¯ä»¥åˆ©ç”¨è¿™äº›ç”Ÿæˆçš„ä¸­é—´è§†è§’å›¾åƒæ¥å¢žå¼º3Dåœºæ™¯é‡å»ºçš„ç›‘ç£ä¿¡å·ï¼Œæé«˜é‡å»ºè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šæ•´ä½“æ¡†æž¶åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š1) **ä¼ªè§†è§’ç”Ÿæˆ**ï¼šåˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œæ ¹æ®è¾“å…¥çš„ç¨€ç–è§†è§’å›¾åƒï¼Œç”Ÿæˆä¸€ç³»åˆ—æ–°çš„è§†è§’å›¾åƒã€‚2) **ä¸ç¡®å®šæ€§æ„ŸçŸ¥**ï¼šå¼•å…¥ä¸ç¡®å®šæ€§æ„ŸçŸ¥æœºåˆ¶ï¼Œç”¨äºŽè¯„ä¼°ç”Ÿæˆè§†è§’çš„å¯é æ€§ï¼Œå¹¶ç”¨äºŽåŽç»­çš„3Dé‡å»ºã€‚3) **3Dåœºæ™¯é‡å»º**ï¼šä½¿ç”¨3Dé«˜æ–¯æº…å°„ï¼ˆ3D-GSï¼‰æ–¹æ³•ï¼Œåˆ©ç”¨åŽŸå§‹è¾“å…¥å›¾åƒå’Œç”Ÿæˆçš„ä¼ªè§†è§’å›¾åƒï¼Œé‡å»º3Dåœºæ™¯ã€‚4) **è¿­ä»£ä¼˜åŒ–**ï¼šé€šè¿‡è¿­ä»£åé¦ˆå¾ªçŽ¯ï¼Œåˆ©ç”¨3Då‡ ä½•ä¿¡æ¯åè¿‡æ¥æŒ‡å¯¼2Dè§†è§’åˆæˆï¼Œä»Žè€Œè¿›ä¸€æ­¥æé«˜é‡å»ºå’Œåˆæˆè´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºŽå°†æ–°è§†è§’åˆæˆé—®é¢˜ä¸Žè§†é¢‘è¡¥å…¨é—®é¢˜è”ç³»èµ·æ¥ï¼Œå¹¶åˆ©ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ä½œä¸ºå¼ºå¤§çš„å…ˆéªŒçŸ¥è¯†ã€‚è¿™ç§æ–¹æ³•é¿å…äº†å¯¹ç‰¹å®šåœºæ™¯è¿›è¡Œè®­ç»ƒæˆ–å¾®è°ƒï¼Œå®žçŽ°äº†é›¶æ ·æœ¬çš„æ–°è§†è§’åˆæˆã€‚æ­¤å¤–ï¼Œä¸ç¡®å®šæ€§æ„ŸçŸ¥æœºåˆ¶å’Œè¿­ä»£ä¼˜åŒ–ç­–ç•¥ä¹Ÿå¯¹æé«˜åˆæˆè´¨é‡èµ·åˆ°äº†å…³é”®ä½œç”¨ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) ä½¿ç”¨é¢„è®­ç»ƒçš„è§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œä¾‹å¦‚ Imagen Video æˆ– Stable Video Diffusionï¼Œä½œä¸ºç”Ÿæˆä¼ªè§†è§’çš„ backboneã€‚2) è®¾è®¡ä¸ç¡®å®šæ€§æ„ŸçŸ¥æ¨¡å—ï¼Œä¾‹å¦‚é€šè¿‡é¢„æµ‹æ·±åº¦å›¾çš„ä¸ç¡®å®šæ€§æ¥è¡¡é‡ç”Ÿæˆè§†è§’çš„å¯é æ€§ã€‚3) ä½¿ç”¨3Dé«˜æ–¯æº…å°„ï¼ˆ3D-GSï¼‰ä½œä¸º3Dåœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå¹¶è®¾è®¡åˆé€‚çš„æŸå¤±å‡½æ•°ï¼Œä¾‹å¦‚å…‰åº¦ä¸€è‡´æ€§æŸå¤±å’Œæ·±åº¦ä¸€è‡´æ€§æŸå¤±ï¼Œæ¥ä¼˜åŒ–3Dåœºæ™¯ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨LLFFã€DTUã€DL3DVå’ŒMipNeRF-360æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶åœ¨æžç«¯ç¨€ç–è¾“å…¥æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºŽ3D-GSåŸºçº¿ã€‚ä¾‹å¦‚ï¼Œåœ¨LLFFæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨PSNRæŒ‡æ ‡ä¸Šæå‡äº†è¶…è¿‡3dBï¼Œåœ¨SSIMæŒ‡æ ‡ä¸Šæå‡äº†è¶…è¿‡0.05ã€‚è¿™äº›ç»“æžœè¡¨æ˜Žï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åˆ©ç”¨é¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡åž‹çš„å…ˆéªŒçŸ¥è¯†ï¼Œç”Ÿæˆé«˜è´¨é‡çš„æ–°è§†è§’å›¾åƒï¼Œå¹¶æé«˜3Dåœºæ™¯é‡å»ºçš„å‡†ç¡®æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥æŠ€æœ¯å¯åº”ç”¨äºŽè™šæ‹ŸçŽ°å®žï¼ˆVRï¼‰ã€å¢žå¼ºçŽ°å®žï¼ˆARï¼‰ã€æœºå™¨äººå¯¼èˆªã€è‡ªåŠ¨é©¾é©¶ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨VR/ARä¸­ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡å°‘é‡å›¾åƒå¿«é€Ÿç”Ÿæˆé€¼çœŸçš„3Dåœºæ™¯ï¼Œæå‡ç”¨æˆ·ä½“éªŒã€‚åœ¨æœºå™¨äººå¯¼èˆªå’Œè‡ªåŠ¨é©¾é©¶ä¸­ï¼Œè¯¥æŠ€æœ¯å¯ä»¥å¸®åŠ©æœºå™¨äººæˆ–è½¦è¾†åœ¨ç¼ºä¹è¶³å¤Ÿè§†è§‰ä¿¡æ¯çš„çŽ¯å¢ƒä¸‹è¿›è¡Œå¯¼èˆªå’Œå®šä½ï¼Œæé«˜å®‰å…¨æ€§å’Œå¯é æ€§ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥ç”¨äºŽç”µå½±åˆ¶ä½œã€æ¸¸æˆå¼€å‘ç­‰é¢†åŸŸï¼Œé™ä½Žå†…å®¹åˆ›ä½œçš„æˆæœ¬ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Given just a few glimpses of a scene, can you imagine the movie playing out as the camera glides through it? That's the lens we take on \emph{sparse-input novel view synthesis}, not only as filling spatial gaps between widely spaced views, but also as \emph{completing a natural video} unfolding through space.
>   We recast the task as \emph{test-time natural video completion}, using powerful priors from \emph{pretrained video diffusion models} to hallucinate plausible in-between views. Our \emph{zero-shot, generation-guided} framework produces pseudo views at novel camera poses, modulated by an \emph{uncertainty-aware mechanism} for spatial coherence. These synthesized frames densify supervision for \emph{3D Gaussian Splatting} (3D-GS) for scene reconstruction, especially in under-observed regions. An iterative feedback loop lets 3D geometry and 2D view synthesis inform each other, improving both the scene reconstruction and the generated views.
>   The result is coherent, high-fidelity renderings from sparse inputs \emph{without any scene-specific training or fine-tuning}. On LLFF, DTU, DL3DV, and MipNeRF-360, our method significantly outperforms strong 3D-GS baselines under extreme sparsity.

