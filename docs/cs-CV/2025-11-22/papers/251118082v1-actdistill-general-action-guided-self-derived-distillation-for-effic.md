---
layout: default
title: ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models
---

# ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.18082" target="_blank" class="toolbar-btn">arXiv: 2511.18082v1</a>
    <a href="https://arxiv.org/pdf/2511.18082.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.18082v1" 
            onclick="toggleFavorite(this, '2511.18082v1', 'ActDistill: General Action-Guided Self-Derived Distillation for Efficient Vision-Language-Action Models')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Wencheng Ye, Tianshi Wang, Lei Zhu, Fengling Li, Guoli Yang

**ÂàÜÁ±ª**: cs.CV, cs.RO

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-22

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ActDistillÔºöÈù¢ÂêëÈ´òÊïàVLAÊ®°ÂûãÁöÑÂä®‰ΩúÂºïÂØºËá™Ëí∏È¶èÊ°ÜÊû∂**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏ÄÔºöÊú∫Âô®‰∫∫ÊéßÂà∂ (Robot Control)**

**ÂÖ≥ÈîÆËØç**: `ËßÜËßâ-ËØ≠Ë®Ä-Âä®‰ΩúÊ®°Âûã` `Ê®°ÂûãËí∏È¶è` `Áü•ËØÜËøÅÁßª` `Âä®‰ΩúÂºïÂØº` `Âä®ÊÄÅË∑ØÁî±`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÁöÑVLAÊ®°ÂûãËÆ°ÁÆóÂºÄÈîÄÂ§ß„ÄÅÊé®ÁêÜÂª∂ËøüÈ´òÔºåÈöæ‰ª•ÈÉ®ÁΩ≤‰∫éÊú∫Âô®‰∫∫Êìç‰ΩúÁ≠âÂÆûÈôÖÂú∫ÊôØ„ÄÇ
2. ActDistillÂà©Áî®Âä®‰ΩúÂÖàÈ™åÂºïÂØºÁü•ËØÜËøÅÁßªÂíåÊ®°ÂûãÂéãÁº©ÔºåÂ∞ÜÂ§ßÂûãVLAÊ®°ÂûãÁöÑÂä®‰ΩúÈ¢ÑÊµãËÉΩÂäõËøÅÁßªÂà∞ËΩªÈáèÁ∫ßÊ®°Âûã„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåActDistillÂú®ÊòæËëóÈôç‰ΩéËÆ°ÁÆóÈáèÂíåÊé®ÁêÜÂª∂ËøüÁöÑÂêåÊó∂Ôºå‰øùÊåÅÁîöËá≥ÊèêÂçá‰∫ÜVLAÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫ActDistillÔºå‰∏ÄÁßçÈÄöÁî®ÁöÑÂä®‰ΩúÂºïÂØºËá™Ëí∏È¶èÊ°ÜÊû∂ÔºåÊó®Âú®Â∞ÜÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãÁöÑÂä®‰ΩúÈ¢ÑÊµãËÉΩÂäõËøÅÁßªÂà∞ËΩªÈáèÁ∫ßÊ®°ÂûãÔºå‰ªéËÄåÈôç‰ΩéËÆ°ÁÆóÂºÄÈîÄÂíåÊé®ÁêÜÂª∂Ëøü„ÄÇ‰∏é‰ª•ÂæÄ‰æßÈáçËßÜËßâ-ËØ≠Ë®ÄÁõ∏ÂÖ≥ÊÄßÁöÑÊïàÁéáÁ≠ñÁï•‰∏çÂêåÔºåActDistillÂà©Áî®Âä®‰ΩúÂÖàÈ™åÊù•ÊåáÂØºÁü•ËØÜËøÅÁßªÂíåÊ®°ÂûãÂéãÁº©ÔºåÂÆûÁé∞VLAÊ®°ÂûãÈù¢ÂêëÂä®‰ΩúÁöÑÊïàÁéáÊèêÂçá„ÄÇÂÖ∑‰ΩìËÄåË®ÄÔºåËØ•ÊñπÊ≥ï‰ΩøÁî®ËÆ≠ÁªÉÂ•ΩÁöÑVLAÊ®°Âûã‰Ωú‰∏∫ÊïôÂ∏àÔºåÂπ∂ÂºïÂÖ•ÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•Êù•ÊòæÂºèÂª∫Ê®°Âä®‰ΩúÈ¢ÑÊµãÁöÑÂ±ÇÁ∫ßÊºîÂåñ„ÄÇ‰ªéÂõæÂ∞ÅË£ÖÁöÑÊïôÂ∏àÊ®°ÂûãÊ¥æÁîüÂá∫ÁöÑÂ≠¶ÁîüÊ®°ÂûãÔºåÈÖçÂ§á‰∫ÜÂä®ÊÄÅË∑ØÁî±ÔºåÂèØ‰ª•Ê†πÊçÆÂä®‰ΩúÈ¢ÑÊµãÈúÄÊ±ÇËá™ÈÄÇÂ∫îÂú∞ÈÄâÊã©ËÆ°ÁÆóË∑ØÂæÑÔºåÂπ∂Âú®Â±ÇÁ∫ßÂõæ‰ø°ÊÅØÁöÑÁõëÁù£‰∏ãÂπ≥ÊªëÈ´òÊïàÂú∞ÊºîÂåñ„ÄÇÂú®Êé®ÁêÜÈò∂ÊÆµÔºåÁßªÈô§ÂõæÁõ∏ÂÖ≥ÁöÑËæÖÂä©ÁªÑ‰ª∂ÔºåÂ≠¶ÁîüÊ®°Âûã‰ªÖÊâßË°åÂä®ÊÄÅË∑ØÁî±ÁöÑÂ±ÇÔºå‰ª•ÊúÄÂ∞èÁöÑËÆ°ÁÆóÂíåÂª∂ËøüÈ¢ÑÊµãÈ´òÁ≤æÂ∫¶Âä®‰Ωú„ÄÇÂú®ÂÖ∑Ë∫´Êô∫ËÉΩÂü∫ÂáÜÊµãËØï‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåActDistillÂú®ËÆ°ÁÆóÈáèÂáèÂ∞ë50%‰ª•‰∏äÔºåÈÄüÂ∫¶ÊèêÂçáÈ´òËææ1.67ÂÄçÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞‰∫Ü‰∏éÂÖ®Â∞∫ÂØ∏VLAÊ®°ÂûãÁõ∏ÂΩìÁîöËá≥Êõ¥‰ºòÁöÑÊÄßËÉΩÔºå‰ªéËÄå‰∏∫È´òÊïàÂÖ∑Ë∫´Êô∫ËÉΩÂª∫Á´ã‰∫Ü‰∏Ä‰∏™ÈÄöÁî®ËåÉ‰æã„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâËßÜËßâ-ËØ≠Ë®Ä-Âä®‰Ωú(VLA)Ê®°ÂûãËôΩÁÑ∂Â±ïÁé∞Âá∫Âº∫Â§ßÁöÑÁÅµÊ¥ªÊÄßÂíåÊ≥õÂåñËÉΩÂäõÔºå‰ΩÜÂÖ∂Â∫ûÂ§ßÁöÑËÆ°ÁÆóÂºÄÈîÄÂíåÈ´òÊé®ÁêÜÂª∂ËøüÈôêÂà∂‰∫ÜÂÆÉ‰ª¨Âú®Êú∫Âô®‰∫∫Êìç‰ΩúÁ≠âÈ¢ÜÂüüÁöÑÂÆûÈôÖÂ∫îÁî®„ÄÇÁé∞ÊúâÁöÑÊ®°ÂûãÂéãÁº©ÊñπÊ≥ï‰∏ªË¶ÅÂÖ≥Ê≥®ËßÜËßâÂíåËØ≠Ë®ÄÊ®°ÊÄÅ‰πãÈó¥ÁöÑÁõ∏ÂÖ≥ÊÄßÔºåÂøΩÁï•‰∫ÜÂä®‰ΩúÈ¢ÑÊµãÊú¨Ë∫´ÁöÑÈáçË¶ÅÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöActDistillÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÂà©Áî®Âä®‰ΩúÂÖàÈ™åÁü•ËØÜÊù•ÊåáÂØºÊ®°ÂûãËí∏È¶èÂíåÂéãÁº©Ôºå‰ªéËÄåÂÆûÁé∞Èù¢ÂêëÂä®‰ΩúÈ¢ÑÊµãÁöÑÈ´òÊïàVLAÊ®°Âûã„ÄÇÈÄöËøáÂ∞ÜÂ§ßÂûãVLAÊ®°ÂûãÁöÑÁü•ËØÜËøÅÁßªÂà∞ËΩªÈáèÁ∫ßÂ≠¶ÁîüÊ®°ÂûãÔºåÂπ∂Âú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÊòæÂºèÂú∞Âª∫Ê®°Âä®‰ΩúÈ¢ÑÊµãÁöÑÂ±ÇÁ∫ßÊºîÂåñËøáÁ®ãÔºå‰ΩøÂæóÂ≠¶ÁîüÊ®°ÂûãËÉΩÂ§ü‰ª•Êõ¥Â∞ëÁöÑËÆ°ÁÆóËµÑÊ∫êÂÆûÁé∞‰∏éÊïôÂ∏àÊ®°ÂûãÁõ∏ÂΩìÁîöËá≥Êõ¥‰ºòÁöÑÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöActDistillÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰∏â‰∏™ÂÖ≥ÈîÆÁªÑ‰ª∂ÔºöÊïôÂ∏àÊ®°Âûã„ÄÅÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•ÂíåÂä®ÊÄÅË∑ØÁî±Â≠¶ÁîüÊ®°Âûã„ÄÇÈ¶ñÂÖàÔºå‰ΩøÁî®‰∏Ä‰∏™È¢ÑËÆ≠ÁªÉÂ•ΩÁöÑVLAÊ®°Âûã‰Ωú‰∏∫ÊïôÂ∏àÊ®°Âûã„ÄÇÁÑ∂ÂêéÔºåÂºïÂÖ•ÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•Êù•ÊòæÂºèÂú∞Âª∫Ê®°ÊïôÂ∏àÊ®°Âûã‰∏≠Âä®‰ΩúÈ¢ÑÊµãÁöÑÂ±ÇÁ∫ßÊºîÂåñËøáÁ®ãÔºåÂ∞ÜÊïôÂ∏àÊ®°ÂûãÂ∞ÅË£ÖÊàê‰∏Ä‰∏™ÂõæÁªìÊûÑ„ÄÇÊúÄÂêéÔºåÂü∫‰∫éËØ•ÂõæÁªìÊûÑÔºåÊûÑÂª∫‰∏Ä‰∏™Âä®ÊÄÅË∑ØÁî±Â≠¶ÁîüÊ®°ÂûãÔºåËØ•Ê®°ÂûãÂèØ‰ª•Ê†πÊçÆÂä®‰ΩúÈ¢ÑÊµãÁöÑÈúÄÊ±ÇËá™ÈÄÇÂ∫îÂú∞ÈÄâÊã©ËÆ°ÁÆóË∑ØÂæÑ„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöActDistillÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂Âä®‰ΩúÂºïÂØºÁöÑËá™Ëí∏È¶èÊñπÊ≥ïÂíåÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•„ÄÇ‰º†ÁªüÁöÑÊ®°ÂûãËí∏È¶èÊñπÊ≥ïÈÄöÂ∏∏Âè™ÂÖ≥Ê≥®ËæìÂÖ•-ËæìÂá∫‰πãÈó¥ÁöÑÊò†Â∞ÑÂÖ≥Á≥ªÔºåËÄåActDistillÂàôÊòæÂºèÂú∞Âà©Áî®‰∫ÜÂä®‰ΩúÂÖàÈ™åÁü•ËØÜÊù•ÊåáÂØºÁü•ËØÜËøÅÁßª„ÄÇÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•ËÉΩÂ§üÊúâÊïàÂú∞Âª∫Ê®°Âä®‰ΩúÈ¢ÑÊµãÁöÑÂ±ÇÁ∫ßÊºîÂåñËøáÁ®ãÔºå‰ªéËÄå‰ΩøÂæóÂ≠¶ÁîüÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞Â≠¶‰π†ÊïôÂ∏àÊ®°ÂûãÁöÑÁü•ËØÜ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂõæÁªìÊûÑÂ∞ÅË£ÖÁ≠ñÁï•Â∞ÜÊïôÂ∏àÊ®°ÂûãÁöÑÊØè‰∏ÄÂ±ÇÊàñÂá†Â±ÇÁªÑÂêàÊàêÂõæ‰∏≠ÁöÑËäÇÁÇπÔºåËäÇÁÇπ‰πãÈó¥ÁöÑËøûÊé•Ë°®Á§∫‰ø°ÊÅØ‰º†ÈÄíÂÖ≥Á≥ª„ÄÇÂä®ÊÄÅË∑ØÁî±Â≠¶ÁîüÊ®°Âûã‰ΩøÁî®‰∏Ä‰∏™Âä®ÊÄÅË∑ØÁî±Âô®Êù•ÂÜ≥ÂÆöÊØè‰∏ÄÂ±ÇÂ∫îËØ•ÈÄâÊã©Âì™Êù°ËÆ°ÁÆóË∑ØÂæÑ„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨Ê®°‰ªøÊçüÂ§±ÔºàÊ®°‰ªøÊïôÂ∏àÊ®°ÂûãÁöÑËæìÂá∫ÔºâÂíåÂõæ‰ø°ÊÅØÁõëÁù£ÊçüÂ§±ÔºàÈºìÂä±Â≠¶ÁîüÊ®°ÂûãÂ≠¶‰π†ÂõæÁªìÊûÑ‰∏≠ÁöÑÂ±ÇÁ∫ßÂÖ≥Á≥ªÔºâ„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÔºàÂ¶ÇÂ≠¶‰π†Áéá„ÄÅbatch sizeÁ≠âÔºâÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÔºàÂ¶ÇÂõæÁöÑÊûÑÂª∫ÊñπÂºè„ÄÅÂä®ÊÄÅË∑ØÁî±Âô®ÁöÑËÆæËÆ°Á≠âÔºâÊú™Áü•„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ActDistillÂú®ÂÖ∑Ë∫´Êô∫ËÉΩÂü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂú®ËÆ°ÁÆóÈáèÂáèÂ∞ë50%‰ª•‰∏äÁöÑÊÉÖÂÜµ‰∏ãÔºåÂÆûÁé∞‰∫Ü‰∏éÂÖ®Â∞∫ÂØ∏VLAÊ®°ÂûãÁõ∏ÂΩìÁîöËá≥Êõ¥‰ºòÁöÑÊÄßËÉΩ„ÄÇÂêåÊó∂ÔºåÊé®ÁêÜÈÄüÂ∫¶ÊèêÂçáÈ´òËææ1.67ÂÄçÔºåËØÅÊòé‰∫ÜËØ•ÊñπÊ≥ïÂú®ÊèêÈ´òVLAÊ®°ÂûãÊïàÁéáÊñπÈù¢ÁöÑÊúâÊïàÊÄß„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéActDistill‰∏∫È´òÊïàÂÖ∑Ë∫´Êô∫ËÉΩÊèê‰æõ‰∫Ü‰∏Ä‰∏™ÊúâÂâçÊôØÁöÑËß£ÂÜ≥ÊñπÊ°à„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ActDistillÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂ∞§ÂÖ∂ÊòØÂú®ËµÑÊ∫êÂèóÈôêÁöÑÊú∫Âô®‰∫∫Êìç‰Ωú„ÄÅËá™Âä®È©æÈ©∂Á≠âÈ¢ÜÂüü„ÄÇÈÄöËøáÈôç‰ΩéVLAÊ®°ÂûãÁöÑËÆ°ÁÆóÂºÄÈîÄÂíåÊé®ÁêÜÂª∂ËøüÔºåÂèØ‰ª•‰ΩøÂæóËøô‰∫õÊ®°ÂûãËÉΩÂ§üÊõ¥È´òÊïàÂú∞ÈÉ®ÁΩ≤Âú®ËæπÁºòËÆæÂ§á‰∏äÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Êô∫ËÉΩ„ÄÅÊõ¥Ëá™‰∏ªÁöÑÊú∫Âô®‰∫∫ÂíåËá™Âä®È©æÈ©∂Á≥ªÁªü„ÄÇÊ≠§Â§ñÔºåËØ•ÊñπÊ≥ïËøòÂèØ‰ª•Â∫îÁî®‰∫éÂÖ∂‰ªñÈúÄË¶ÅÈ´òÊïàÂ§öÊ®°ÊÄÅÁêÜËß£ÂíåÂÜ≥Á≠ñÁöÑ‰ªªÂä°‰∏≠„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Recent Vision-Language-Action (VLA) models have shown impressive flexibility and generalization, yet their deployment in robotic manipulation remains limited by heavy computational overhead and inference latency. In this work, we present ActDistill, a general action-guided self-derived distillation framework that transfers the action prediction capability of any existing VLA model to a lightweight counterpart. Unlike previous efficiency strategies that primarily emphasize vision-language correlations, ActDistill leverages action priors to guide knowledge transfer and model compression, achieving action-oriented efficiency for VLA models. Specifically, we employ a well-trained VLA model as the teacher and introduce a graph-structured encapsulation strategy to explicitly model the hierarchical evolution of action prediction. The student model, derived from the graph-encapsulated teacher, is further equipped with a dynamic router that adaptively selects computation paths based on action prediction demands, guided by hierarchical graph-informed supervision to ensure smooth and efficient evolution. During inference, graph-related auxiliary components are removed, allowing the student to execute only dynamically routed layers and predict high-precision actions with minimal computation and latency. Experiments on embodied benchmarks demonstrate that ActDistill achieves comparable or superior performance to full-scale VLA models while reducing computation by over 50% with up to 1.67 times speedup, thereby establishing a general paradigm toward efficient embodied intelligence.

