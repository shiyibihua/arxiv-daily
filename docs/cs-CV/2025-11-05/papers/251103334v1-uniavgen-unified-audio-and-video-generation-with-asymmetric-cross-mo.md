---
layout: default
title: UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions
---

# UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions

**arXiv**: [2511.03334v1](https://arxiv.org/abs/2511.03334) | [PDF](https://arxiv.org/pdf/2511.03334.pdf)

**ä½œè€…**: Guozhen Zhang, Zixiang Zhou, Teng Hu, Ziqiao Peng, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-05

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**UniAVGenï¼šæå‡ºä¸€ç§éžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’çš„ç»Ÿä¸€éŸ³è§†é¢‘ç”Ÿæˆæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `éŸ³è§†é¢‘ç”Ÿæˆ` `è·¨æ¨¡æ€å­¦ä¹ ` `æ‰©æ•£æ¨¡åž‹` `Transformer` `éžå¯¹ç§°äº¤äº’` `äººè„¸æ„ŸçŸ¥` `è”åˆåˆæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰éŸ³è§†é¢‘ç”Ÿæˆæ–¹æ³•åœ¨è·¨æ¨¡æ€å»ºæ¨¡æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œå¯¼è‡´å”‡éŸ³åŒæ­¥å’Œè¯­ä¹‰ä¸€è‡´æ€§è¾ƒå·®ã€‚
2. UniAVGené‡‡ç”¨åŒåˆ†æ”¯æ‰©æ•£Transformeræž¶æž„ï¼Œé€šè¿‡éžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æœºåˆ¶å®žçŽ°éŸ³è§†é¢‘çš„ç²¾ç¡®åŒæ­¥å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒUniAVGenä»…ä½¿ç”¨å°‘é‡è®­ç»ƒæ•°æ®ï¼Œå³å¯åœ¨éŸ³è§†é¢‘åŒæ­¥ã€éŸ³è‰²å’Œæƒ…æ„Ÿä¸€è‡´æ€§æ–¹é¢å–å¾—æ˜¾è‘—æå‡ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çŽ°æœ‰å¼€æºéŸ³è§†é¢‘ç”Ÿæˆæ–¹æ³•ç”±äºŽç¼ºä¹æœ‰æ•ˆçš„è·¨æ¨¡æ€å»ºæ¨¡ï¼Œå¸¸åœ¨å”‡éŸ³åŒæ­¥å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢è¡¨çŽ°ä¸ä½³ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†UniAVGenï¼Œä¸€ä¸ªç”¨äºŽè”åˆéŸ³è§†é¢‘ç”Ÿæˆçš„ç»Ÿä¸€æ¡†æž¶ã€‚UniAVGenåŸºäºŽåŒåˆ†æ”¯è”åˆåˆæˆæž¶æž„ï¼ŒåŒ…å«ä¸¤ä¸ªå¹¶è¡Œçš„æ‰©æ•£Transformerï¼ˆDiTï¼‰ä»¥æž„å»ºä¸€ä¸ªæœ‰å‡èšåŠ›çš„è·¨æ¨¡æ€æ½œåœ¨ç©ºé—´ã€‚å…¶æ ¸å¿ƒæ˜¯éžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æœºåˆ¶ï¼Œè¯¥æœºåˆ¶æ”¯æŒåŒå‘ã€æ—¶é—´å¯¹é½çš„äº¤å‰æ³¨æ„åŠ›ï¼Œä»Žè€Œç¡®ä¿ç²¾ç¡®çš„æ—¶ç©ºåŒæ­¥å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡äººè„¸æ„ŸçŸ¥è°ƒåˆ¶æ¨¡å—å¢žå¼ºè¿™ç§è·¨æ¨¡æ€äº¤äº’ï¼Œè¯¥æ¨¡å—åŠ¨æ€åœ°ä¼˜å…ˆè€ƒè™‘äº¤äº’è¿‡ç¨‹ä¸­çš„æ˜¾è‘—åŒºåŸŸã€‚ä¸ºäº†æé«˜æŽ¨ç†è¿‡ç¨‹ä¸­çš„ç”Ÿæˆä¿çœŸåº¦ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†æ¨¡æ€æ„ŸçŸ¥æ— åˆ†ç±»å™¨æŒ‡å¯¼ï¼Œè¿™æ˜¯ä¸€ç§æ˜¾å¼æ”¾å¤§è·¨æ¨¡æ€ç›¸å…³ä¿¡å·çš„æ–°ç­–ç•¥ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒUniAVGenå¼ºå¤§çš„è”åˆåˆæˆè®¾è®¡ä½¿å¾—åœ¨å•ä¸ªæ¨¡åž‹ä¸­æ— ç¼ç»Ÿä¸€å…³é”®çš„éŸ³è§†é¢‘ä»»åŠ¡æˆä¸ºå¯èƒ½ï¼Œä¾‹å¦‚è”åˆéŸ³è§†é¢‘ç”Ÿæˆå’Œå»¶ç»­ã€è§†é¢‘åˆ°éŸ³é¢‘çš„é…éŸ³ä»¥åŠéŸ³é¢‘é©±åŠ¨çš„è§†é¢‘åˆæˆã€‚å…¨é¢çš„å®žéªŒéªŒè¯è¡¨æ˜Žï¼ŒUniAVGenä½¿ç”¨è¿œå°‘äºŽçŽ°æœ‰æ–¹æ³•ï¼ˆ130ä¸‡ vs. 3010ä¸‡ï¼‰çš„è®­ç»ƒæ ·æœ¬ï¼Œåœ¨éŸ³è§†é¢‘åŒæ­¥ã€éŸ³è‰²ä¸€è‡´æ€§å’Œæƒ…æ„Ÿä¸€è‡´æ€§æ–¹é¢éƒ½å…·æœ‰æ€»ä½“ä¼˜åŠ¿ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰éŸ³è§†é¢‘ç”Ÿæˆæ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯å¼€æºæ–¹æ³•ï¼Œåœ¨å¤„ç†éŸ³è§†é¢‘åŒæ­¥å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢å­˜åœ¨å›°éš¾ã€‚æ ¹æœ¬åŽŸå› æ˜¯ç¼ºä¹æœ‰æ•ˆçš„è·¨æ¨¡æ€å»ºæ¨¡æœºåˆ¶ï¼Œå¯¼è‡´ç”Ÿæˆçš„å†…å®¹åœ¨æ—¶é—´å’Œè¯­ä¹‰ä¸Šæ— æ³•å¾ˆå¥½åœ°å¯¹é½ã€‚è¿™é™åˆ¶äº†è¿™äº›æ–¹æ³•åœ¨å®žé™…åº”ç”¨ä¸­çš„æ•ˆæžœå’Œå¯ç”¨æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUniAVGençš„æ ¸å¿ƒæ€è·¯æ˜¯æž„å»ºä¸€ä¸ªç»Ÿä¸€çš„æ¡†æž¶ï¼Œé€šè¿‡åŒåˆ†æ”¯æž¶æž„å’Œéžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æœºåˆ¶ï¼Œæ˜¾å¼åœ°å»ºæ¨¡éŸ³è§†é¢‘ä¹‹é—´çš„å…³ç³»ã€‚é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­å»ºç«‹éŸ³è§†é¢‘ä¹‹é—´çš„å¼ºå…³è”ï¼Œä»Žè€Œå®žçŽ°æ›´å¥½çš„åŒæ­¥å’Œä¸€è‡´æ€§ã€‚è¿™ç§è®¾è®¡å…è®¸æ¨¡åž‹åŒæ—¶å¤„ç†éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯ï¼Œå¹¶åˆ©ç”¨å®ƒä»¬ä¹‹é—´çš„äº’è¡¥æ€§æ¥æé«˜ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šUniAVGené‡‡ç”¨åŒåˆ†æ”¯è”åˆåˆæˆæž¶æž„ï¼ŒåŒ…å«ä¸¤ä¸ªå¹¶è¡Œçš„æ‰©æ•£Transformerï¼ˆDiTï¼‰ï¼Œåˆ†åˆ«å¤„ç†éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯ã€‚è¿™ä¸¤ä¸ªDiTå…±åŒæž„å»ºä¸€ä¸ªè·¨æ¨¡æ€æ½œåœ¨ç©ºé—´ã€‚éžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æ¨¡å—ä½äºŽä¸¤ä¸ªåˆ†æ”¯ä¹‹é—´ï¼Œå…è®¸ä¿¡æ¯åœ¨éŸ³é¢‘å’Œè§†é¢‘ä¹‹é—´åŒå‘æµåŠ¨ã€‚æ­¤å¤–ï¼Œè¿˜åŒ…å«äººè„¸æ„ŸçŸ¥è°ƒåˆ¶æ¨¡å—ï¼Œç”¨äºŽåœ¨äº¤äº’è¿‡ç¨‹ä¸­ä¼˜å…ˆè€ƒè™‘äººè„¸ç­‰æ˜¾è‘—åŒºåŸŸã€‚åœ¨æŽ¨ç†é˜¶æ®µï¼Œä½¿ç”¨æ¨¡æ€æ„ŸçŸ¥æ— åˆ†ç±»å™¨æŒ‡å¯¼æ¥è¿›ä¸€æ­¥æé«˜ç”Ÿæˆè´¨é‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šUniAVGençš„å…³é”®åˆ›æ–°åœ¨äºŽå…¶éžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æœºåˆ¶ã€‚ä¸Žä¼ ç»Ÿçš„å¯¹ç§°äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ä¸åŒï¼ŒUniAVGenå…è®¸éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯ä»¥éžå¯¹ç§°çš„æ–¹å¼ç›¸äº’å½±å“ï¼Œä»Žè€Œæ›´å¥½åœ°æ•æ‰å®ƒä»¬ä¹‹é—´çš„å¤æ‚å…³ç³»ã€‚æ­¤å¤–ï¼Œäººè„¸æ„ŸçŸ¥è°ƒåˆ¶æ¨¡å—èƒ½å¤ŸåŠ¨æ€åœ°è°ƒæ•´æ³¨æ„åŠ›æƒé‡ï¼Œä»Žè€Œæé«˜ç”Ÿæˆçš„äººè„¸åŒºåŸŸçš„è´¨é‡ã€‚æ¨¡æ€æ„ŸçŸ¥æ— åˆ†ç±»å™¨æŒ‡å¯¼åˆ™æ˜¾å¼åœ°å¢žå¼ºäº†è·¨æ¨¡æ€ç›¸å…³ä¿¡å·ï¼Œè¿›ä¸€æ­¥æé«˜äº†ç”Ÿæˆç»“æžœçš„ä¿çœŸåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šéžå¯¹ç§°è·¨æ¨¡æ€äº¤äº’æ¨¡å—ä½¿ç”¨æ—¶é—´å¯¹é½çš„äº¤å‰æ³¨æ„åŠ›æœºåˆ¶ï¼Œç¡®ä¿éŸ³é¢‘å’Œè§†é¢‘ä¿¡æ¯åœ¨æ—¶é—´ç»´åº¦ä¸Šä¿æŒåŒæ­¥ã€‚äººè„¸æ„ŸçŸ¥è°ƒåˆ¶æ¨¡å—ä½¿ç”¨é¢„è®­ç»ƒçš„äººè„¸æ£€æµ‹å™¨æ¥è¯†åˆ«è§†é¢‘ä¸­çš„äººè„¸åŒºåŸŸï¼Œå¹¶æ ¹æ®äººè„¸åŒºåŸŸçš„æ˜¾è‘—æ€§åŠ¨æ€åœ°è°ƒæ•´æ³¨æ„åŠ›æƒé‡ã€‚æ¨¡æ€æ„ŸçŸ¥æ— åˆ†ç±»å™¨æŒ‡å¯¼é€šè¿‡è°ƒæ•´æ‰©æ•£æ¨¡åž‹çš„æ¡ä»¶æ¦‚çŽ‡ï¼Œæ˜¾å¼åœ°æ”¾å¤§è·¨æ¨¡æ€ç›¸å…³ä¿¡å·ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°ç»†èŠ‚åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

UniAVGenåœ¨éŸ³è§†é¢‘åŒæ­¥ã€éŸ³è‰²ä¸€è‡´æ€§å’Œæƒ…æ„Ÿä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒUniAVGenä»…ä½¿ç”¨130ä¸‡ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œè€ŒçŽ°æœ‰æ–¹æ³•é€šå¸¸éœ€è¦3010ä¸‡ä¸ªæ ·æœ¬ã€‚è¿™è¡¨æ˜ŽUniAVGenå…·æœ‰æ›´é«˜çš„è®­ç»ƒæ•ˆçŽ‡å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚å…·ä½“çš„æ€§èƒ½æ•°æ®å’Œå¯¹æ¯”åŸºçº¿åœ¨è®ºæ–‡ä¸­è¿›è¡Œäº†è¯¦ç»†æè¿°ï¼ˆæœªçŸ¥ï¼‰ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

UniAVGenå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼ŒåŒ…æ‹¬ç”µå½±åˆ¶ä½œã€æ¸¸æˆå¼€å‘ã€è™šæ‹ŸçŽ°å®žã€ç¤¾äº¤åª’ä½“ç­‰é¢†åŸŸã€‚å®ƒå¯ä»¥ç”¨äºŽè‡ªåŠ¨ç”ŸæˆéŸ³è§†é¢‘å†…å®¹ï¼Œä¾‹å¦‚ä¸ºæ— å£°è§†é¢‘é…éŸ³ã€æ ¹æ®éŸ³é¢‘ç”Ÿæˆè§†é¢‘ã€åˆ›å»ºè™šæ‹Ÿäººç‰©ç­‰ã€‚è¯¥ç ”ç©¶çš„å®žé™…ä»·å€¼åœ¨äºŽé™ä½Žäº†éŸ³è§†é¢‘å†…å®¹åˆ›ä½œçš„é—¨æ§›ï¼Œæé«˜äº†åˆ›ä½œæ•ˆçŽ‡ï¼Œå¹¶ä¸ºç”¨æˆ·æä¾›äº†æ›´åŠ ä¸°å¯Œå’Œä¸ªæ€§åŒ–çš„ä½“éªŒã€‚æœªæ¥ï¼ŒUniAVGenæœ‰æœ›æˆä¸ºéŸ³è§†é¢‘å†…å®¹åˆ›ä½œé¢†åŸŸçš„é‡è¦å·¥å…·ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Due to the lack of effective cross-modal modeling, existing open-source audio-video generation methods often exhibit compromised lip synchronization and insufficient semantic consistency. To mitigate these drawbacks, we propose UniAVGen, a unified framework for joint audio and video generation. UniAVGen is anchored in a dual-branch joint synthesis architecture, incorporating two parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which enables bidirectional, temporally aligned cross-attention, thus ensuring precise spatiotemporal synchronization and semantic consistency. Furthermore, this cross-modal interaction is augmented by a Face-Aware Modulation module, which dynamically prioritizes salient regions in the interaction process. To enhance generative fidelity during inference, we additionally introduce Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint synthesis design enables seamless unification of pivotal audio-video tasks within a single model, such as joint audio-video generation and continuation, video-to-audio dubbing, and audio-driven video synthesis. Comprehensive experiments validate that, with far fewer training samples (1.3M vs. 30.1M), UniAVGen delivers overall advantages in audio-video synchronization, timbre consistency, and emotion consistency.

