---
layout: default
title: Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation
---

# Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation

**arXiv**: [2511.03163v1](https://arxiv.org/abs/2511.03163) | [PDF](https://arxiv.org/pdf/2511.03163.pdf)

**ä½œè€…**: Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang, Sergi Kavtaradze, Matthew J. Clarkson, Mobarak I. Hoque

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-05

**å¤‡æ³¨**: 12 pages

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSRFT-GaLoreï¼Œç”¨äºŽæ·±åº¦é©±åŠ¨çš„è‚è„åœ°æ ‡åˆ†å‰²ä¸­é«˜æ•ˆè‡ªé€‚åº”åŸºç¡€æ¨¡åž‹ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è‚è„åœ°æ ‡åˆ†å‰²` `æ·±åº¦å­¦ä¹ ` `è…¹è…”é•œæ‰‹æœ¯` `SRFT-GaLore` `æ·±åº¦ä¿¡æ¯èžåˆ` `åŒ»å­¦å½±åƒåˆ†æž` `è‡ªé€‚åº”åŸºç¡€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è…¹è…”é•œè‚è„æ‰‹æœ¯ä¸­ï¼Œ2Dè§†é¢‘æµé™åˆ¶äº†æ·±åº¦æ„ŸçŸ¥ï¼Œä½¿å¾—åœ°æ ‡å®šä½å˜å¾—å¤æ‚ï¼ŒçŽ°æœ‰æ–¹æ³•éš¾ä»¥æœ‰æ•ˆèžåˆRGBå’Œæ·±åº¦ç‰¹å¾ã€‚
2. æå‡ºä¸€ç§æ·±åº¦å¼•å¯¼çš„è‚è„åœ°æ ‡åˆ†å‰²æ¡†æž¶ï¼Œåˆ©ç”¨SAM2å’ŒDA2æå–RGBå’Œæ·±åº¦ç‰¹å¾ï¼Œå¹¶å¼•å…¥SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ã€‚
3. åœ¨L3Dæ•°æ®é›†ä¸Šï¼ŒDiceç›¸ä¼¼ç³»æ•°æå‡4.85%ï¼Œå¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»å‡å°‘11.78ä¸ªç‚¹ï¼Œå¹¶åœ¨LLSDæ•°æ®é›†ä¸Šè¡¨çŽ°å‡ºå¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§æ·±åº¦å¼•å¯¼çš„è‚è„åœ°æ ‡åˆ†å‰²æ¡†æž¶ï¼Œè¯¥æ¡†æž¶é€šè¿‡è§†è§‰åŸºç¡€ç¼–ç å™¨æ•´åˆè¯­ä¹‰å’Œå‡ ä½•çº¿ç´¢ã€‚åˆ©ç”¨Segment Anything Model V2 (SAM2) ç¼–ç å™¨æå–RGBç‰¹å¾ï¼ŒDepth Anything V2 (DA2) ç¼–ç å™¨æå–æ·±åº¦æ„ŸçŸ¥ç‰¹å¾ã€‚ä¸ºäº†é«˜æ•ˆåœ°è‡ªé€‚åº”SAM2ï¼Œå¼•å…¥äº†SRFT-GaLoreï¼Œä¸€ç§æ–°é¢–çš„ä½Žç§©æ¢¯åº¦æŠ•å½±æ–¹æ³•ï¼Œç”¨Subsampled Randomized Fourier Transform (SRFT) æ›¿ä»£äº†è®¡ç®—æˆæœ¬é«˜çš„SVDã€‚è¿™ä½¿å¾—èƒ½å¤Ÿé«˜æ•ˆåœ°å¾®è°ƒé«˜ç»´æ³¨æ„åŠ›å±‚ï¼Œè€Œä¸ä¼šç‰ºç‰²è¡¨å¾èƒ½åŠ›ã€‚ä¸€ä¸ªäº¤å‰æ³¨æ„åŠ›èžåˆæ¨¡å—è¿›ä¸€æ­¥æ•´åˆäº†RGBå’Œæ·±åº¦çº¿ç´¢ã€‚ä¸ºäº†è¯„ä¼°è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œæž„å»ºäº†ä¸€ä¸ªæ–°çš„è…¹è…”é•œè‚è„æ‰‹æœ¯æ•°æ®é›†(LLSD)ä½œä¸ºå¤–éƒ¨éªŒè¯åŸºå‡†ã€‚åœ¨å…¬å¼€çš„L3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨Diceç›¸ä¼¼ç³»æ•°ä¸Šå®žçŽ°äº†4.85%çš„æå‡ï¼Œåœ¨å¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»ä¸Šå‡å°‘äº†11.78ä¸ªç‚¹ã€‚åœ¨LLSDæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹ä¿æŒäº†ç«žäº‰æ€§çš„æ€§èƒ½ï¼Œå¹¶æ˜¾è‘—ä¼˜äºŽåŸºäºŽSAMçš„åŸºçº¿ï¼Œè¯æ˜Žäº†å…¶å¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§å’Œå¯¹æœªè§æ‰‹æœ¯çŽ¯å¢ƒçš„é€‚åº”æ€§ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šåœ¨è…¹è…”é•œè‚è„æ‰‹æœ¯ä¸­ï¼Œç²¾ç¡®æ£€æµ‹å’Œåˆ†å‰²è§£å‰–ç»“æž„è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œ2Dè§†é¢‘æµç¼ºä¹æ·±åº¦ä¿¡æ¯ï¼Œä½¿å¾—åœ°æ ‡å®šä½æˆä¸ºä¸€é¡¹æŒ‘æˆ˜ã€‚çŽ°æœ‰æ–¹æ³•åœ¨èžåˆRGBå’Œæ·±åº¦ç‰¹å¾ä»¥åŠå°†å¤§è§„æ¨¡è§†è§‰æ¨¡åž‹é«˜æ•ˆåœ°é€‚åº”æ‰‹æœ¯é¢†åŸŸæ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œè®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæ³›åŒ–èƒ½åŠ›æœ‰é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨æ·±åº¦ä¿¡æ¯æ¥å¢žå¼ºè‚è„åœ°æ ‡çš„åˆ†å‰²æ€§èƒ½ã€‚é€šè¿‡ç»“åˆRGBå›¾åƒçš„è¯­ä¹‰ä¿¡æ¯å’Œæ·±åº¦å›¾åƒçš„å‡ ä½•ä¿¡æ¯ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°å®šä½å’Œåˆ†å‰²è‚è„åœ°æ ‡ã€‚æ­¤å¤–ï¼Œé€šè¿‡å¼•å…¥SRFT-GaLoreï¼Œå¯ä»¥é«˜æ•ˆåœ°å¾®è°ƒå¤§è§„æ¨¡è§†è§‰æ¨¡åž‹ï¼Œä½¿å…¶é€‚åº”æ‰‹æœ¯é¢†åŸŸï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹çš„è¡¨å¾èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šè¯¥æ¡†æž¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š1) ä½¿ç”¨Segment Anything Model V2 (SAM2) ç¼–ç å™¨æå–RGBç‰¹å¾ï¼›2) ä½¿ç”¨Depth Anything V2 (DA2) ç¼–ç å™¨æå–æ·±åº¦æ„ŸçŸ¥ç‰¹å¾ï¼›3) ä½¿ç”¨SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ï¼›4) ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›èžåˆæ¨¡å—æ•´åˆRGBå’Œæ·±åº¦çº¿ç´¢ï¼›5) ä½¿ç”¨åˆ†å‰²å¤´è¿›è¡Œè‚è„åœ°æ ‡åˆ†å‰²ã€‚æ•´ä½“æµç¨‹æ˜¯å…ˆåˆ†åˆ«æå–RGBå’Œæ·±åº¦ç‰¹å¾ï¼Œç„¶åŽé€šè¿‡SRFT-GaLoreé«˜æ•ˆå¾®è°ƒSAM2ï¼Œå†é€šè¿‡äº¤å‰æ³¨æ„åŠ›èžåˆç‰¹å¾ï¼Œæœ€åŽè¿›è¡Œåˆ†å‰²ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹æ˜¯SRFT-GaLoreï¼Œå®ƒæ˜¯ä¸€ç§æ–°é¢–çš„ä½Žç§©æ¢¯åº¦æŠ•å½±æ–¹æ³•ï¼Œç”¨Subsampled Randomized Fourier Transform (SRFT) æ›¿ä»£äº†è®¡ç®—æˆæœ¬é«˜çš„SVDã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•çš„æœ¬è´¨åŒºåˆ«åœ¨äºŽï¼ŒSRFT-GaLoreå¯ä»¥åœ¨ä¸ç‰ºç‰²è¡¨å¾èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆåœ°å¾®è°ƒé«˜ç»´æ³¨æ„åŠ›å±‚ï¼Œä»Žè€Œé™ä½Žè®¡ç®—æˆæœ¬ï¼Œæé«˜è®­ç»ƒæ•ˆçŽ‡ã€‚

**å…³é”®è®¾è®¡**ï¼šSRFT-GaLoreçš„å…³é”®è®¾è®¡åœ¨äºŽä½¿ç”¨Subsampled Randomized Fourier Transform (SRFT) æ¥è¿‘ä¼¼SVDã€‚å…·ä½“æ¥è¯´ï¼ŒSRFTé€šè¿‡éšæœºé‡‡æ ·å’Œå‚…é‡Œå¶å˜æ¢æ¥é™ä½Žè®¡ç®—å¤æ‚åº¦ï¼ŒåŒæ—¶ä¿ç•™äº†SVDçš„ä¸»è¦ä¿¡æ¯ã€‚äº¤å‰æ³¨æ„åŠ›èžåˆæ¨¡å—çš„å…³é”®è®¾è®¡åœ¨äºŽä½¿ç”¨æ³¨æ„åŠ›æœºåˆ¶æ¥åŠ¨æ€åœ°è°ƒæ•´RGBå’Œæ·±åº¦ç‰¹å¾çš„æƒé‡ï¼Œä»Žè€Œæ›´å¥½åœ°èžåˆä¸¤ç§æ¨¡æ€çš„ä¿¡æ¯ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨Dice Losså’Œäº¤å‰ç†µæŸå¤±çš„ç»„åˆï¼Œä»¥æé«˜åˆ†å‰²ç²¾åº¦ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

åœ¨å…¬å¼€çš„L3Dæ•°æ®é›†ä¸Šï¼Œè¯¥æ–¹æ³•åœ¨Diceç›¸ä¼¼ç³»æ•°ä¸Šå®žçŽ°äº†4.85%çš„æå‡ï¼Œåœ¨å¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»ä¸Šå‡å°‘äº†11.78ä¸ªç‚¹ï¼Œæ˜¾è‘—ä¼˜äºŽD2GPLandã€‚åœ¨LLSDæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹ä¿æŒäº†ç«žäº‰æ€§çš„æ€§èƒ½ï¼Œå¹¶æ˜¾è‘—ä¼˜äºŽåŸºäºŽSAMçš„åŸºçº¿ï¼Œè¯æ˜Žäº†å…¶å¼ºå¤§çš„è·¨æ•°æ®é›†é²æ£’æ€§å’Œå¯¹æœªè§æ‰‹æœ¯çŽ¯å¢ƒçš„é€‚åº”æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽè®¡ç®—æœºè¾…åŠ©è…¹è…”é•œè‚è„æ‰‹æœ¯ï¼Œæé«˜æ‰‹æœ¯ç²¾åº¦å’Œæ•ˆçŽ‡ï¼Œå‡å°‘æ‰‹æœ¯é£Žé™©ã€‚é€šè¿‡ç²¾ç¡®çš„åœ°æ ‡åˆ†å‰²ï¼ŒåŒ»ç”Ÿå¯ä»¥æ›´å¥½åœ°è§„åˆ’æ‰‹æœ¯è·¯å¾„ï¼Œé¿å…æŸä¼¤é‡è¦è¡€ç®¡å’Œç»„ç»‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥æŽ¨å¹¿åˆ°å…¶ä»–åŒ»å­¦å½±åƒåˆ†å‰²ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚è‚¿ç˜¤åˆ†å‰²ã€å™¨å®˜åˆ†å‰²ç­‰ï¼Œå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate detection and delineation of anatomical structures in medical imaging are critical for computer-assisted interventions, particularly in laparoscopic liver surgery where 2D video streams limit depth perception and complicate landmark localization. While recent works have leveraged monocular depth cues for enhanced landmark detection, challenges remain in fusing RGB and depth features and in efficiently adapting large-scale vision models to surgical domains. We propose a depth-guided liver landmark segmentation framework integrating semantic and geometric cues via vision foundation encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB features and Depth Anything V2 (DA2) encoder to extract depth-aware features. To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient projection method that replaces the computationally expensive SVD with a Subsampled Randomized Fourier Transform (SRFT). This enables efficient fine-tuning of high-dimensional attention layers without sacrificing representational power. A cross-attention fusion module further integrates RGB and depth cues. To assess cross-dataset generalization, we also construct a new Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark. On the public L3D dataset, our method achieves a 4.85% improvement in Dice Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface Distance compared to the D2GPLand. To further assess generalization capability, we evaluate our model on LLSD dataset. Our model maintains competitive performance and significantly outperforms SAM-based baselines, demonstrating strong cross-dataset robustness and adaptability to unseen surgical environments. These results demonstrate that our SRFT-GaLore-enhanced dual-encoder framework enables scalable and precise segmentation under real-time, depth-constrained surgical settings.

