---
layout: default
title: Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation
---

# Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation

**arXiv**: [2511.03163v1](https://arxiv.org/abs/2511.03163) | [PDF](https://arxiv.org/pdf/2511.03163.pdf)

**ä½œè€…**: Yun-Chen Lin, Jiayuan Huang, Hanyuan Zhang, Sergi Kavtaradze, Matthew J. Clarkson, Mobarak I. Hoque

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSRFT-GaLoreæ–¹æ³•ä»¥åœ¨æ·±åº¦å¼•å¯¼ä¸‹é«˜æ•ˆé€‚åº”åŸºç¡€æ¨¡åž‹è¿›è¡Œè‚è„æ ‡å¿—åˆ†å‰²**

**å…³é”®è¯**: `è‚è„æ ‡å¿—åˆ†å‰²` `åŸºç¡€æ¨¡åž‹é€‚åº”` `ä½Žç§©æ¢¯åº¦æŠ•å½±` `æ·±åº¦å¼•å¯¼èžåˆ` `è…¹è…”é•œæ‰‹æœ¯` `è·¨æ•°æ®é›†æ³›åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŒ»å­¦å½±åƒä¸­è§£å‰–ç»“æž„åˆ†å‰²åœ¨è…¹è…”é•œæ‰‹æœ¯ä¸­å› 2Dè§†é¢‘æ·±åº¦æ„ŸçŸ¥æœ‰é™è€Œå›°éš¾
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨SAM2å’ŒDA2ç¼–ç å™¨æå–RGBä¸Žæ·±åº¦ç‰¹å¾ï¼ŒSRFT-GaLoreé«˜æ•ˆå¾®è°ƒæ³¨æ„åŠ›å±‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨L3Dæ•°æ®é›†ä¸ŠDiceç³»æ•°æå‡4.85%ï¼Œå¹³å‡å¯¹ç§°è¡¨é¢è·ç¦»é™ä½Ž11.78ç‚¹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Accurate detection and delineation of anatomical structures in medical
> imaging are critical for computer-assisted interventions, particularly in
> laparoscopic liver surgery where 2D video streams limit depth perception and
> complicate landmark localization. While recent works have leveraged monocular
> depth cues for enhanced landmark detection, challenges remain in fusing RGB and
> depth features and in efficiently adapting large-scale vision models to
> surgical domains. We propose a depth-guided liver landmark segmentation
> framework integrating semantic and geometric cues via vision foundation
> encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
> features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
> To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
> projection method that replaces the computationally expensive SVD with a
> Subsampled Randomized Fourier Transform (SRFT). This enables efficient
> fine-tuning of high-dimensional attention layers without sacrificing
> representational power. A cross-attention fusion module further integrates RGB
> and depth cues. To assess cross-dataset generalization, we also construct a new
> Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
> On the public L3D dataset, our method achieves a 4.85% improvement in Dice
> Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
> Distance compared to the D2GPLand. To further assess generalization capability,
> we evaluate our model on LLSD dataset. Our model maintains competitive
> performance and significantly outperforms SAM-based baselines, demonstrating
> strong cross-dataset robustness and adaptability to unseen surgical
> environments. These results demonstrate that our SRFT-GaLore-enhanced
> dual-encoder framework enables scalable and precise segmentation under
> real-time, depth-constrained surgical settings.

