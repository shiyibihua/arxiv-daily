---
layout: default
title: OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera
---

# OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera

**arXiv**: [2511.03571v1](https://arxiv.org/abs/2511.03571) | [PDF](https://arxiv.org/pdf/2511.03571.pdf)

**ä½œè€…**: Hao Shi, Ze Wang, Shangwei Guo, Mengfei Duan, Song Wang, Teng Chen, Kailun Yang, Lin Wang, Kaiwei Wang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOneOccæ¡†æž¶ï¼Œç”¨äºŽè¶³å¼æœºå™¨äººçš„å…¨æ™¯è¯­ä¹‰å æ®é¢„æµ‹ï¼Œè§£å†³èº«ä½“æŠ–åŠ¨å’Œ360åº¦è¿žç»­æ€§é—®é¢˜ã€‚**

**å…³é”®è¯**: `è¯­ä¹‰å æ®é¢„æµ‹` `å…¨æ™¯ç›¸æœº` `è¶³å¼æœºå™¨äºº` `åŒæŠ•å½±èžåˆ` `è½»é‡è§£ç å™¨` `è¿åŠ¨è¡¥å¿`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¶³å¼æœºå™¨äººå› æ­¥æ€å¯¼è‡´èº«ä½“æŠ–åŠ¨ï¼ŒçŽ°æœ‰è¯­ä¹‰åœºæ™¯è¡¥å…¨ç³»ç»Ÿå¤šé’ˆå¯¹è½®å¼å¹³å°ï¼Œç¼ºä¹360åº¦è¿žç»­æ„ŸçŸ¥ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆåŒæŠ•å½±èžåˆã€åŒç½‘æ ¼ä½“ç´ åŒ–å’Œè½»é‡è§£ç å™¨ï¼Œå®žçŽ°ç‰¹å¾çº§è¿åŠ¨è¡¥å¿å’Œå¤šå°ºåº¦èžåˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨QuadOccå’ŒH3OåŸºå‡†ä¸Šè¾¾åˆ°æ–°SOTAï¼Œæå‡mIoUæŒ‡æ ‡ï¼Œæ¨¡å—è½»é‡å¯éƒ¨ç½²ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
> semantic scene completion (SSC) systems target wheeled platforms with
> forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
> framework designed for gait-introduced body jitter and 360{\deg} continuity.
> OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
> panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
> grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
> cylindrical-polar spaces, reducing discretization bias and sharpening
> free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
> for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
> (iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
> motion correction without extra sensors. We also release two panoramic
> occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
> Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
> occupancy; standardized within-/cross-city splits). OneOcc sets new
> state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
> popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
> (cross-city). Modules are lightweight, enabling deployable full-surround
> perception for legged/humanoid robots. Datasets and code will be publicly
> available at https://github.com/MasterHow/OneOcc.

