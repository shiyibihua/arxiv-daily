---
layout: default
title: Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge
---

# Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge

**arXiv**: [2511.03332v1](https://arxiv.org/abs/2511.03332) | [PDF](https://arxiv.org/pdf/2511.03332.pdf)

**ä½œè€…**: Yi Yang, Yiming Xu, Timo Kaiser, Hao Cheng, Bodo Rosenhahn, Michael Ying Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽFastTrackerå’ŒLLaVA-Videoçš„ä¸¤é˜¶æ®µé›¶æ ·æœ¬æ–¹æ³•ï¼Œè§£å†³MOT25-StAGæŒ‘æˆ˜ä¸­çš„å¤šç›®æ ‡è·Ÿè¸ªæ£€ç´¢é—®é¢˜ã€‚**

**å…³é”®è¯**: `å¤šç›®æ ‡è·Ÿè¸ª` `è§†é¢‘æ£€ç´¢` `é›¶æ ·æœ¬å­¦ä¹ ` `å¤šæ¨¡æ€å¤§æ¨¡åž‹` `è¯­è¨€æŸ¥è¯¢å®šä½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåœ¨å¤æ‚çœŸå®žåœºæ™¯è§†é¢‘ä¸­ï¼Œæ ¹æ®è‡ªç”±å½¢å¼è¯­è¨€æŸ¥è¯¢å‡†ç¡®å®šä½å’Œè·Ÿè¸ªå¤šä¸ªå¯¹è±¡ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå°†ä»»åŠ¡å»ºæ¨¡ä¸ºè§†é¢‘æ£€ç´¢ï¼Œç»“åˆSOTAè·Ÿè¸ªæ¨¡åž‹å’ŒLLaVA-Videoå¤šæ¨¡æ€å¤§æ¨¡åž‹ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨MOT25-StAGæµ‹è¯•é›†ä¸Šï¼Œm-HIoUå’ŒHOTAå¾—åˆ†åˆ†åˆ«ä¸º20.68å’Œ10.73ï¼ŒèŽ·æŒ‘æˆ˜ç¬¬äºŒåã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> In this report, we present our solution to the MOT25-Spatiotemporal Action
> Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
> localize and track multiple objects that match specific and free-form language
> queries, using video data of complex real-world scenes as input. We model the
> underlying task as a video retrieval problem and present a two-stage, zero-shot
> approach, combining the advantages of the SOTA tracking model FastTracker and
> Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
> method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
> won second place in the challenge.

