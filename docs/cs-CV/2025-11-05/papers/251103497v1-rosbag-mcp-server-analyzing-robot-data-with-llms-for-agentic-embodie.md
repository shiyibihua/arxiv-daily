---
layout: default
title: ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications
---

# ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications

**arXiv**: [2511.03497v1](https://arxiv.org/abs/2511.03497) | [PDF](https://arxiv.org/pdf/2511.03497.pdf)

**ä½œè€…**: Lei Fu, Sahar Salimpour, Leonardo Militano, Harry Edelman, Jorge PeÃ±a Queralta, Giovanni Toffetti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºROSåŒ…MCPæœåŠ¡å™¨ï¼Œä½¿LLMèƒ½åˆ†æžæœºå™¨äººæ•°æ®ä»¥æ”¯æŒå…·èº«AIåº”ç”¨ã€‚**

**å…³é”®è¯**: `å…·èº«AI` `æ¨¡åž‹ä¸Šä¸‹æ–‡åè®®` `ROSæ•°æ®åˆ†æž` `è‡ªç„¶è¯­è¨€å¤„ç†` `æœºå™¨äººè§†è§‰` `ä»£ç†ç³»ç»Ÿ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå…·èº«AIä¸Žä»£ç†AIäº¤å‰é¢†åŸŸç ”ç©¶ç¨€ç¼ºï¼Œç¼ºä¹è‡ªç„¶è¯­è¨€åˆ†æžæœºå™¨äººæ•°æ®çš„å·¥å…·ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šæž„å»ºMCPæœåŠ¡å™¨ï¼Œé›†æˆROSåŒ…åˆ†æžå·¥å…·ï¼Œæ”¯æŒè½¨è¿¹ã€æ¿€å…‰æ‰«æç­‰æ•°æ®å¤„ç†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šè¯„ä¼°å…«ç§LLM/VLMå·¥å…·è°ƒç”¨èƒ½åŠ›ï¼ŒKimi K2å’ŒClaude Sonnet 4è¡¨çŽ°æœ€ä½³ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Agentic AI systems and Physical or Embodied AI systems have been two key
> research verticals at the forefront of Artificial Intelligence and Robotics,
> with Model Context Protocol (MCP) increasingly becoming a key component and
> enabler of agentic applications. However, the literature at the intersection of
> these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
> introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
> analyzing, visualizing and processing robot data with natural language through
> LLMs and VLMs. We describe specific tooling built with robotics domain
> knowledge, with our initial release focused on mobile robotics and supporting
> natively the analysis of trajectories, laser scan data, transforms, or time
> series data. This is in addition to providing an interface to standard ROS 2
> CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
> filter bags with a subset of topics or trimmed in time. Coupled with the MCP
> server, we provide a lightweight UI that allows the benchmarking of the tooling
> with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
> (through Groq). Our experimental results include the analysis of tool calling
> capabilities of eight different state-of-the-art LLM/VLM models, both
> proprietary and open-source, large and small. Our experiments indicate that
> there is a large divide in tool calling capabilities, with Kimi K2 and Claude
> Sonnet 4 demonstrating clearly superior performance. We also conclude that
> there are multiple factors affecting the success rates, from the tool
> description schema to the number of arguments, as well as the number of tools
> available to the models. The code is available with a permissive license at
> https://github.com/binabik-ai/mcp-rosbags.

