---
layout: default
title: Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising
---

# Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising

**arXiv**: [2511.03272v1](https://arxiv.org/abs/2511.03272) | [PDF](https://arxiv.org/pdf/2511.03272.pdf)

**ä½œè€…**: Shuangquan Lyu, Steven Mao, Yue Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºç»Ÿä¸€é•¿è§†é¢‘ä¿®å¤ä¸Žå¤–å»¶æ–¹æ³•ï¼Œé€šè¿‡é‡å é«˜é˜¶ååŒåŽ»å™ªå®žçŽ°é«˜ä¿çœŸç¼–è¾‘**

**å…³é”®è¯**: `é•¿è§†é¢‘ä¿®å¤` `è§†é¢‘å¤–å»¶` `æ‰©æ•£æ¨¡åž‹` `ååŒåŽ»å™ª` `LoRAå¾®è°ƒ` `è§†é¢‘ç¼–è¾‘`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šé•¿è§†é¢‘ç”Ÿæˆä¸Žå¯æŽ§ä¿®å¤/å¤–å»¶å›°éš¾ï¼ŒçŽ°æœ‰æ–¹æ³•å­˜åœ¨å›ºå®šé•¿åº¦é™åˆ¶æˆ–æ‹¼æŽ¥ä¼ªå½±
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽLoRAå¾®è°ƒé¢„è®­ç»ƒè§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œé‡‡ç”¨é‡å æ··åˆé«˜é˜¶ååŒåŽ»å™ªç­–ç•¥
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨æ•°ç™¾å¸§ä»»åŠ¡ä¸­ä¼˜äºŽåŸºçº¿ï¼Œè´¨é‡ä¸Žæ„ŸçŸ¥çœŸå®žåº¦æŒ‡æ ‡æå‡ï¼Œå‚æ•°é«˜æ•ˆ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Generating long videos remains a fundamental challenge, and achieving high
> controllability in video inpainting and outpainting is particularly demanding.
> To address both of these challenges simultaneously and achieve controllable
> video inpainting and outpainting for long video clips, we introduce a novel and
> unified approach for long video inpainting and outpainting that extends
> text-to-video diffusion models to generate arbitrarily long, spatially edited
> videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
> large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
> region video synthesis, and employs an overlap-and-blend temporal co-denoising
> strategy with high-order solvers to maintain consistency across long sequences.
> In contrast to prior work that struggles with fixed-length clips or exhibits
> stitching artifacts, our system enables arbitrarily long video generation and
> editing without noticeable seams or drift. We validate our approach on
> challenging inpainting/outpainting tasks including editing or adding objects
> over hundreds of frames and demonstrate superior performance to baseline
> methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
> perceptual realism (LPIPS). Our method enables practical long-range video
> editing with minimal overhead, achieved a balance between parameter efficient
> and superior performance.

