---
layout: default
title: Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models
---

# Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models

**arXiv**: [2511.03367v1](https://arxiv.org/abs/2511.03367) | [PDF](https://arxiv.org/pdf/2511.03367.pdf)

**ä½œè€…**: Gahyeon Kim, Sohee Kim, Seokju Lee

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAAPLæ–¹æ³•ï¼Œé€šè¿‡è§£è€¦å¢žå¼ºåå·®æå‡è§†è§‰è¯­è¨€æ¨¡åž‹çš„æç¤ºå­¦ä¹ æ³›åŒ–èƒ½åŠ›**

**å…³é”®è¯**: `æç¤ºå­¦ä¹ ` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æ•°æ®å¢žå¼º` `æ³›åŒ–èƒ½åŠ›` `å¯¹æŠ—å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰æç¤ºå­¦ä¹ æ–¹æ³•å¦‚CoCoOpæ³›åŒ–èƒ½åŠ›ä¸è¶³ï¼Œæœªå……åˆ†åˆ©ç”¨å›¾åƒå¢žå¼º
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å¯¹æŠ—æ€§ä»¤ç‰ŒåµŒå…¥ï¼Œè§£è€¦å¢žå¼ºå¼•å…¥çš„è¡¨é¢å˜åŒ–ä¸Žç±»åˆ«è¯­ä¹‰è¡¨ç¤º
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨11ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šï¼ŒAAPLåœ¨å¤šç§è®¾ç½®ä¸­ä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in large-scale vision and language models have led to
> significant progress in zero-shot learning tasks. Methods such as CoOp and
> CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
> known as prompt learning, can result in improved performance. However, these
> models often struggle to generalize to entirely unseen categories. While
> traditional zero-shot learning techniques benefit from various data
> augmentation strategies, prompt learning has primarily focused on text-based
> modifications, leaving the potential of image-based augmentation largely
> unexplored. In this work, we explore how image-level augmentations,
> particularly those that introduce attribute-specific variations, can support
> and enhance prompt learning. Our analysis examines the interaction between
> these augmentations and soft prompt frameworks, revealing their potential to
> improve generalization. We also identify a limitation in existing methods, such
> as CoCoOp, which do not provide explicit guidance for learning prompts that
> focus on semantically meaningful visual features. To address this, we propose
> Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
> adversarial token embeddings to decouple superficial visual variations
> introduced by augmentation from class-relevant semantic representations. This
> decoupling enables the learned prompts to concentrate on visually
> discriminative features that align with the target categories. We conduct
> comprehensive experiments on eleven benchmark datasets, and AAPL consistently
> outperforms existing methods across few-shot, zero-shot, cross-dataset, and
> domain generalization settings. Our source code is publicly available at:
> https://github.com/Gahyeonkim09/AAPL

