---
layout: default
title: Finetuning-Free Personalization of Text to Image Generation via Hypernetworks
---

# Finetuning-Free Personalization of Text to Image Generation via Hypernetworks

**arXiv**: [2511.03156v1](https://arxiv.org/abs/2511.03156) | [PDF](https://arxiv.org/pdf/2511.03156.pdf)

**ä½œè€…**: Sagar Shrestha, Gopal Sharma, Luowei Zhou, Suren Kumar

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºŽè¶…ç½‘ç»œçš„å…å¾®è°ƒä¸ªæ€§åŒ–æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ–¹æ³•ï¼Œä»¥è§£å†³è®¡ç®—æˆæœ¬é«˜å’ŒæŽ¨ç†æ…¢çš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ` `è¶…ç½‘ç»œ` `å…å¾®è°ƒä¸ªæ€§åŒ–` `LoRAæƒé‡é¢„æµ‹` `æ‰©æ•£æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šä¼ ç»Ÿä¸ªæ€§åŒ–æ–¹æ³•ä¾èµ–ä¸»é¢˜ç‰¹å®šå¾®è°ƒï¼Œè®¡ç®—æ˜‚è´µä¸”æŽ¨ç†æ…¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è¶…ç½‘ç»œä»Žä¸»é¢˜å›¾åƒç›´æŽ¥é¢„æµ‹LoRAæƒé‡ï¼Œæ— éœ€æµ‹è¯•æ—¶ä¼˜åŒ–ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨CelebA-HQç­‰æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œå®žçŽ°å¼ºä¸ªæ€§åŒ–æ€§èƒ½ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Personalizing text-to-image diffusion models has traditionally relied on
> subject-specific fine-tuning approaches such as
> DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and
> slow at inference. Recent adapter- and encoder-based methods attempt to reduce
> this overhead but still depend on additional fine-tuning or large backbone
> models for satisfactory results. In this work, we revisit an orthogonal
> direction: fine-tuning-free personalization via Hypernetworks that predict
> LoRA-adapted weights directly from subject images. Prior hypernetwork-based
> approaches, however, suffer from costly data generation or unstable attempts to
> mimic base model optimization trajectories. We address these limitations with
> an end-to-end training objective, stabilized by a simple output regularization,
> yielding reliable and effective hypernetworks. Our method removes the need for
> per-subject optimization at test time while preserving both subject fidelity
> and prompt alignment. To further enhance compositional generalization at
> inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),
> which combines the compositional strengths of the base diffusion model with the
> subject fidelity of personalized models during sampling. Extensive experiments
> on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves
> strong personalization performance and highlights the promise of hypernetworks
> as a scalable and effective direction for open-category personalization.

