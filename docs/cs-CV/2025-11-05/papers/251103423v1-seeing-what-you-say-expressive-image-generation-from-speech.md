---
layout: default
title: Seeing What You Say: Expressive Image Generation from Speech
---

# Seeing What You Say: Expressive Image Generation from Speech

**arXiv**: [2511.03423v1](https://arxiv.org/abs/2511.03423) | [PDF](https://arxiv.org/pdf/2511.03423.pdf)

**ä½œè€…**: Jiyoung Lee, Song Park, Sanghyuk Chun, Soo-Whan Chung

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVoxStudioä»¥ä»Žè¯­éŸ³ç”Ÿæˆå¯Œæœ‰è¡¨çŽ°åŠ›çš„å›¾åƒï¼Œè”åˆå¯¹é½è¯­è¨€å’Œå‰¯è¯­è¨€ä¿¡æ¯ã€‚**

**å…³é”®è¯**: `è¯­éŸ³åˆ°å›¾åƒç”Ÿæˆ` `ç«¯åˆ°ç«¯æ¨¡åž‹` `è¯­éŸ³ä¿¡æ¯ç“¶é¢ˆ` `æƒ…æ„Ÿè¯­éŸ³å›¾åƒæ•°æ®é›†` `å‰¯è¯­è¨€ä¿¡æ¯å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè¯­éŸ³åˆ°å›¾åƒç”Ÿæˆä¸­å¿½ç•¥è¯­è°ƒã€æƒ…æ„Ÿç­‰å‰¯è¯­è¨€ç»†èŠ‚ï¼Œå¯¼è‡´è¡¨è¾¾æ€§ä¸è¶³ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šä½¿ç”¨è¯­éŸ³ä¿¡æ¯ç“¶é¢ˆæ¨¡å—åŽ‹ç¼©è¯­éŸ³ä¸ºè¯­ä¹‰ä»¤ç‰Œï¼Œä¿ç•™éŸµå¾‹å’Œæƒ…æ„Ÿï¼Œå®žçŽ°ç«¯åˆ°ç«¯ç”Ÿæˆã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­éªŒè¯å¯è¡Œæ€§ï¼Œçªå‡ºæƒ…æ„Ÿä¸€è‡´æ€§å’Œè¯­è¨€æ­§ä¹‰ç­‰æŒ‘æˆ˜ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> This paper proposes VoxStudio, the first unified and end-to-end
> speech-to-image model that generates expressive images directly from spoken
> descriptions by jointly aligning linguistic and paralinguistic information. At
> its core is a speech information bottleneck (SIB) module, which compresses raw
> speech into compact semantic tokens, preserving prosody and emotional nuance.
> By operating directly on these tokens, VoxStudio eliminates the need for an
> additional speech-to-text system, which often ignores the hidden details beyond
> text, e.g., tone or emotion. We also release VoxEmoset, a large-scale paired
> emotional speech-image dataset built via an advanced TTS engine to affordably
> generate richly expressive utterances. Comprehensive experiments on the
> SpokenCOCO, Flickr8kAudio, and VoxEmoset benchmarks demonstrate the feasibility
> of our method and highlight key challenges, including emotional consistency and
> linguistic ambiguity, paving the way for future research.

