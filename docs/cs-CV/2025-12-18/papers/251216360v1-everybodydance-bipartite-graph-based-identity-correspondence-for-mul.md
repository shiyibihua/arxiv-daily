---
layout: default
title: EverybodyDance: Bipartite Graph-Based Identity Correspondence for Multi-Character Animation
---

# EverybodyDance: Bipartite Graph-Based Identity Correspondence for Multi-Character Animation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16360" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16360v1</a>
  <a href="https://arxiv.org/pdf/2512.16360.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16360v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16360v1', 'EverybodyDance: Bipartite Graph-Based Identity Correspondence for Multi-Character Animation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Haotian Ling, Zequn Chen, Qiuying Chen, Donglin Di, Yongjia Ma, Hao Li, Chen Wei, Zhulin Tao, Xun Yang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**EverybodyDanceï¼šåŸºäºäºŒåˆ†å›¾çš„è§’è‰²åŒ¹é…æ–¹æ³•ï¼Œè§£å†³å¤šè§’è‰²åŠ¨ç”»ä¸­çš„èº«ä»½å¯¹åº”é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å…«ï¼šç‰©ç†åŠ¨ç”» (Physics-based Animation)**

**å…³é”®è¯**: `å¤šè§’è‰²åŠ¨ç”»` `èº«ä»½å¯¹åº”` `äºŒåˆ†å›¾åŒ¹é…` `å§¿æ€é©±åŠ¨` `æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å§¿æ€é©±åŠ¨çš„è§’è‰²åŠ¨ç”»åœ¨å•è§’è‰²åœºæ™¯ä¸­å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†æ‰©å±•åˆ°å¤šè§’è‰²åœºæ™¯ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠä½ç½®äº¤æ¢æ—¶ï¼Œæå…·æŒ‘æˆ˜ã€‚
2. EverybodyDanceçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†è§’è‰²é—´çš„èº«ä»½å¯¹åº”å…³ç³»å»ºæ¨¡ä¸ºäºŒåˆ†å›¾ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–å›¾ç»“æ„åº¦é‡æ¥ä¿è¯èº«ä»½å¯¹åº”å…³ç³»çš„æ­£ç¡®æ€§ã€‚
3. è®ºæ–‡æå‡ºäº†èº«ä»½å¯¹åº”è¯„ä¼°åŸºå‡†ï¼Œå¹¶é€šè¿‡å¤§é‡å®éªŒè¯æ˜EverybodyDanceåœ¨èº«ä»½å¯¹åº”å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºEverybodyDanceï¼Œä¸€ä¸ªé’ˆå¯¹å¤šè§’è‰²åŠ¨ç”»ä¸­èº«ä»½å¯¹åº”ï¼ˆICï¼‰æ­£ç¡®æ€§çš„ç³»ç»Ÿæ€§è§£å†³æ–¹æ¡ˆã€‚æ ¸å¿ƒæ˜¯èº«ä»½åŒ¹é…å›¾ï¼ˆIMGï¼‰ï¼Œå®ƒå°†ç”Ÿæˆå¸§å’Œå‚è€ƒå¸§ä¸­çš„è§’è‰²å»ºæ¨¡ä¸ºåŠ æƒå®Œå…¨äºŒåˆ†å›¾ä¸­çš„ä¸¤ä¸ªèŠ‚ç‚¹é›†åˆã€‚è¾¹ç¼˜æƒé‡é€šè¿‡æå‡ºçš„Mask-Query Attentionï¼ˆMQAï¼‰è®¡ç®—ï¼Œé‡åŒ–æ¯å¯¹è§’è‰²ä¹‹é—´çš„äº²å’ŒåŠ›ã€‚è®ºæ–‡å°†ICæ­£ç¡®æ€§å½¢å¼åŒ–ä¸ºå›¾ç»“æ„åº¦é‡ï¼Œå¹¶åœ¨è®­ç»ƒæœŸé—´å¯¹å…¶è¿›è¡Œä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œè¿˜æå‡ºäº†ä¸€ç³»åˆ—é’ˆå¯¹å¤šè§’è‰²åŠ¨ç”»çš„ç­–ç•¥ï¼ŒåŒ…æ‹¬èº«ä»½åµŒå…¥å¼•å¯¼ã€å¤šå°ºåº¦åŒ¹é…ç­–ç•¥å’Œé¢„åˆ†ç±»é‡‡æ ·ã€‚ä¸ºäº†è¯„ä¼°ICæ€§èƒ½ï¼Œåˆ›å»ºäº†èº«ä»½å¯¹åº”è¯„ä¼°åŸºå‡†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒEverybodyDanceåœ¨ICå’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤šè§’è‰²åŠ¨ç”»ç”Ÿæˆä¸­èº«ä»½å¯¹åº”ï¼ˆIdentity Correspondence, ICï¼‰é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨å¤„ç†å¤šè§’è‰²åœºæ™¯ï¼Œç‰¹åˆ«æ˜¯è§’è‰²ä½ç½®å‘ç”Ÿäº¤æ¢æ—¶ï¼Œéš¾ä»¥ä¿è¯ç”ŸæˆåŠ¨ç”»ä¸­è§’è‰²çš„èº«ä»½ä¸å‚è€ƒå¸§ä¸­çš„è§’è‰²èº«ä»½ä¸€è‡´ã€‚è¿™å¯¼è‡´åŠ¨ç”»æ•ˆæœä¸è‡ªç„¶ï¼Œè§’è‰²æ··ä¹±ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†ç”ŸæˆåŠ¨ç”»å¸§å’Œå‚è€ƒå¸§ä¸­çš„è§’è‰²å»ºæ¨¡ä¸ºäºŒåˆ†å›¾çš„èŠ‚ç‚¹ï¼Œé€šè¿‡è®¡ç®—èŠ‚ç‚¹ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼ˆå³è¾¹çš„æƒé‡ï¼‰æ¥å»ºç«‹è§’è‰²ä¹‹é—´çš„å¯¹åº”å…³ç³»ã€‚é€šè¿‡ä¼˜åŒ–äºŒåˆ†å›¾çš„ç»“æ„ï¼Œä½¿å¾—ç›¸ä¼¼åº¦é«˜çš„èŠ‚ç‚¹å°½å¯èƒ½åŒ¹é…ï¼Œä»è€Œä¿è¯èº«ä»½å¯¹åº”å…³ç³»çš„æ­£ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šEverybodyDanceä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) **èº«ä»½åŒ¹é…å›¾ï¼ˆIMGï¼‰æ„å»º**ï¼šå°†å‚è€ƒå¸§å’Œç”Ÿæˆå¸§ä¸­çš„è§’è‰²ä½œä¸ºèŠ‚ç‚¹ï¼Œæ„å»ºä¸€ä¸ªå®Œå…¨äºŒåˆ†å›¾ã€‚2) **Mask-Query Attentionï¼ˆMQAï¼‰**ï¼šè®¡ç®—äºŒåˆ†å›¾ä¸­èŠ‚ç‚¹ä¹‹é—´çš„è¾¹ç¼˜æƒé‡ï¼Œè¡¨ç¤ºè§’è‰²ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚MQAåˆ©ç”¨è§’è‰²çš„maskä¿¡æ¯ä½œä¸ºqueryï¼Œå»attentionå‚è€ƒå¸§ä¸­çš„ç‰¹å¾ï¼Œä»è€Œå¾—åˆ°ç›¸ä¼¼åº¦ã€‚3) **å›¾ç»“æ„ä¼˜åŒ–**ï¼šè®¾è®¡æŸå¤±å‡½æ•°ï¼Œä¼˜åŒ–äºŒåˆ†å›¾çš„ç»“æ„ï¼Œä½¿å¾—ç›¸ä¼¼åº¦é«˜çš„èŠ‚ç‚¹å°½å¯èƒ½åŒ¹é…ã€‚4) **èº«ä»½åµŒå…¥å¼•å¯¼**ï¼šåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œåˆ©ç”¨èº«ä»½ä¿¡æ¯å¼•å¯¼ç”Ÿæˆå™¨ï¼Œæé«˜èº«ä»½å¯¹åº”å…³ç³»çš„å‡†ç¡®æ€§ã€‚5) **å¤šå°ºåº¦åŒ¹é…ç­–ç•¥**ï¼šåœ¨ä¸åŒå°ºåº¦ä¸Šè¿›è¡Œè§’è‰²åŒ¹é…ï¼Œæé«˜é²æ£’æ€§ã€‚6) **é¢„åˆ†ç±»é‡‡æ ·**ï¼šå¯¹è®­ç»ƒæ•°æ®è¿›è¡Œé¢„åˆ†ç±»ï¼Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡æœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†èº«ä»½å¯¹åº”é—®é¢˜å½¢å¼åŒ–ä¸ºå›¾ç»“æ„ä¼˜åŒ–é—®é¢˜ï¼Œå¹¶æå‡ºäº†Mask-Query Attentionï¼ˆMQAï¼‰æ¥è®¡ç®—è§’è‰²ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†è§’è‰²ä½ç½®äº¤æ¢çš„æƒ…å†µï¼Œå¹¶ä¿è¯èº«ä»½å¯¹åº”å…³ç³»çš„æ­£ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼š1) **Mask-Query Attention (MQA)**ï¼šåˆ©ç”¨è§’è‰²çš„maskä½œä¸ºqueryï¼Œå‚è€ƒå¸§çš„ç‰¹å¾ä½œä¸ºkeyå’Œvalueï¼Œè®¡ç®—attention scoreä½œä¸ºè§’è‰²ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚2) **å›¾ç»“æ„æŸå¤±å‡½æ•°**ï¼šè®¾è®¡æŸå¤±å‡½æ•°ï¼Œé¼“åŠ±ç›¸ä¼¼åº¦é«˜çš„èŠ‚ç‚¹åŒ¹é…ï¼Œç›¸ä¼¼åº¦ä½çš„èŠ‚ç‚¹ä¸åŒ¹é…ã€‚3) **èº«ä»½åµŒå…¥**ï¼šå°†è§’è‰²çš„èº«ä»½ä¿¡æ¯åµŒå…¥åˆ°ç”Ÿæˆå™¨ä¸­ï¼Œå¼•å¯¼ç”Ÿæˆå™¨ç”Ÿæˆå…·æœ‰æ­£ç¡®èº«ä»½çš„è§’è‰²ã€‚4) **å¤šå°ºåº¦åŒ¹é…**ï¼šåœ¨å¤šä¸ªå°ºåº¦ä¸Šè®¡ç®—è§’è‰²ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œæé«˜åŒ¹é…çš„é²æ£’æ€§ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16360v1/x1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16360v1/x2.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16360v1/x3.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEverybodyDanceåœ¨èº«ä»½å¯¹åº”ï¼ˆICï¼‰å’Œè§†è§‰ä¿çœŸåº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æŠ€æœ¯æ°´å¹³ã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨èº«ä»½å¯¹åº”è¯„ä¼°åŸºå‡†ä¸Šï¼ŒEverybodyDanceçš„ICæŒ‡æ ‡æ¯”æœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•æé«˜äº†æ˜¾è‘—å¹…åº¦ï¼ˆå…·ä½“æ•°å€¼æœªçŸ¥ï¼‰ã€‚åŒæ—¶ï¼Œè§†è§‰æ•ˆæœä¹Ÿæ›´åŠ è‡ªç„¶ï¼Œè§’è‰²èº«ä»½æ›´åŠ æ˜ç¡®ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºè™šæ‹Ÿç°å®ã€æ¸¸æˆå¼€å‘ã€ç”µå½±åˆ¶ä½œç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºå¤šäººåœ¨çº¿äº’åŠ¨åŠ¨ç”»ï¼Œå…è®¸ç”¨æˆ·æ§åˆ¶å¤šä¸ªè§’è‰²è¿›è¡Œäº’åŠ¨ï¼Œè€Œæ— éœ€æ‹…å¿ƒè§’è‰²èº«ä»½æ··ä¹±çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºèˆè¹ˆæ•™å­¦ã€è¿åŠ¨åˆ†æç­‰é¢†åŸŸï¼Œå¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œå­¦ä¹ åŠ¨ä½œã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Consistent pose-driven character animation has achieved remarkable progress in single-character scenarios. However, extending these advances to multi-character settings is non-trivial, especially when position swap is involved. Beyond mere scaling, the core challenge lies in enforcing correct Identity Correspondence (IC) between characters in reference and generated frames. To address this, we introduce EverybodyDance, a systematic solution targeting IC correctness in multi-character animation. EverybodyDance is built around the Identity Matching Graph (IMG), which models characters in the generated and reference frames as two node sets in a weighted complete bipartite graph. Edge weights, computed via our proposed Mask-Query Attention (MQA), quantify the affinity between each pair of characters. Our key insight is to formalize IC correctness as a graph structural metric and to optimize it during training. We also propose a series of targeted strategies tailored for multi-character animation, including identity-embedded guidance, a multi-scale matching strategy, and pre-classified sampling, which work synergistically. Finally, to evaluate IC performance, we curate the Identity Correspondence Evaluation benchmark, dedicated to multi-character IC correctness. Extensive experiments demonstrate that EverybodyDance substantially outperforms state-of-the-art baselines in both IC and visual fidelity.

