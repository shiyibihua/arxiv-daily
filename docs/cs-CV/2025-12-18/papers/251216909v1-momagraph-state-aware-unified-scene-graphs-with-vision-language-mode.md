---
layout: default
title: MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning
---

# MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16909" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16909v1</a>
  <a href="https://arxiv.org/pdf/2512.16909.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16909v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16909v1', 'MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuanchen Ju, Yongyuan Liang, Yen-Jen Wang, Nandiraju Gireesh, Yuanliang Ju, Seungjae Lee, Qiao Gu, Elvis Hsieh, Furong Huang, Koushil Sreenath

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: 25 pages, 10 figures. Project page:https://hybridrobotics.github.io/MomaGraph/

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**MomaGraphï¼šé¢å‘å…·èº«ä»»åŠ¡è§„åˆ’ï¼Œèåˆè§†è§‰-è¯­è¨€æ¨¡å‹çš„ã€çŠ¶æ€æ„ŸçŸ¥çš„ç»Ÿä¸€åœºæ™¯å›¾**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `åœºæ™¯å›¾` `å…·èº«æ™ºèƒ½` `ä»»åŠ¡è§„åˆ’` `è§†è§‰-è¯­è¨€æ¨¡å‹` `å¼ºåŒ–å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åœºæ™¯å›¾è¡¨ç¤ºæ–¹æ³•ç¼ºä¹å¯¹ç‰©ä½“çŠ¶æ€å’Œæ—¶åºæ›´æ–°çš„è€ƒè™‘ï¼Œä¸”ç©ºé—´å’ŒåŠŸèƒ½å…³ç³»åˆ†ç¦»ï¼Œé™åˆ¶äº†å…·èº«æ™ºèƒ½ä½“çš„ä»»åŠ¡è§„åˆ’èƒ½åŠ›ã€‚
2. MomaGraphé€šè¿‡ç»Ÿä¸€çš„åœºæ™¯è¡¨ç¤ºï¼Œæ•´åˆç©ºé—´-åŠŸèƒ½å…³ç³»å’Œéƒ¨ä»¶çº§åˆ«çš„äº¤äº’å…ƒç´ ï¼Œä»è€Œæ›´å…¨é¢åœ°æè¿°åœºæ™¯ã€‚
3. MomaGraph-R1æ¨¡å‹åœ¨MomaGraphæ•°æ®é›†ä¸Šè®­ç»ƒï¼Œå¹¶åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†MomaGraphï¼Œä¸€ç§ç”¨äºå…·èº«æ™ºèƒ½ä½“çš„ç»Ÿä¸€åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒé›†æˆäº†ç©ºé—´-åŠŸèƒ½å…³ç³»å’Œéƒ¨ä»¶çº§åˆ«çš„äº¤äº’å…ƒç´ ã€‚ç°æœ‰åœºæ™¯å›¾é€šå¸¸åˆ†ç¦»ç©ºé—´å’ŒåŠŸèƒ½å…³ç³»ï¼Œå°†åœºæ™¯è§†ä¸ºé™æ€å¿«ç…§ï¼Œå¿½ç•¥äº†ä¸å½“å‰ä»»åŠ¡æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚ä¸ºäº†æ¨è¿›è¯¥è¡¨ç¤ºæ–¹æ³•ï¼Œæœ¬æ–‡è´¡çŒ®äº†MomaGraph-Scenesï¼Œè¿™æ˜¯é¦–ä¸ªå¤§è§„æ¨¡çš„ã€å¸¦æœ‰ä¸°å¯Œæ ‡æ³¨çš„ã€ä»»åŠ¡é©±åŠ¨çš„å®¶åº­ç¯å¢ƒåœºæ™¯å›¾æ•°æ®é›†ï¼Œä»¥åŠMomaGraph-Benchï¼Œä¸€ä¸ªæ¶µç›–ä»é«˜å±‚è§„åˆ’åˆ°ç»†ç²’åº¦åœºæ™¯ç†è§£çš„å…­ç§æ¨ç†èƒ½åŠ›çš„ç³»ç»Ÿè¯„ä¼°å¥—ä»¶ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥å¼€å‘äº†MomaGraph-R1ï¼Œä¸€ä¸ªåœ¨MomaGraph-Scenesä¸Šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒçš„70äº¿å‚æ•°è§†è§‰-è¯­è¨€æ¨¡å‹ã€‚MomaGraph-R1é¢„æµ‹é¢å‘ä»»åŠ¡çš„åœºæ™¯å›¾ï¼Œå¹¶åœ¨Graph-then-Planæ¡†æ¶ä¸‹ä½œä¸ºé›¶æ ·æœ¬ä»»åŠ¡è§„åˆ’å™¨ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¼€æºæ¨¡å‹ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œåœ¨åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†71.6%çš„å‡†ç¡®ç‡ï¼ˆæ¯”æœ€ä½³åŸºçº¿é«˜å‡º11.4%ï¼‰ï¼ŒåŒæ—¶æ¨å¹¿åˆ°å…¬å…±åŸºå‡†æµ‹è¯•ï¼Œå¹¶æœ‰æ•ˆåœ°è½¬ç§»åˆ°çœŸå®æœºå™¨äººå®éªŒã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰åœºæ™¯å›¾è¡¨ç¤ºæ–¹æ³•ä¸»è¦å­˜åœ¨ä¸‰ä¸ªç—›ç‚¹ï¼šä¸€æ˜¯ç©ºé—´å’ŒåŠŸèƒ½å…³ç³»åˆ†ç¦»ï¼Œæ— æ³•æœ‰æ•ˆæ”¯æŒå¤æ‚ä»»åŠ¡è§„åˆ’ï¼›äºŒæ˜¯å°†åœºæ™¯è§†ä¸ºé™æ€å¿«ç…§ï¼Œå¿½ç•¥äº†ç‰©ä½“çŠ¶æ€å’Œæ—¶åºå˜åŒ–ï¼›ä¸‰æ˜¯ç¼ºä¹é’ˆå¯¹å…·èº«ä»»åŠ¡çš„å®šåˆ¶åŒ–ä¿¡æ¯ï¼Œå¯¼è‡´æ³›åŒ–èƒ½åŠ›ä¸è¶³ã€‚è¿™äº›é—®é¢˜é™åˆ¶äº†ç§»åŠ¨æ“ä½œæœºå™¨äººåœ¨å®¶åº­ç¯å¢ƒä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šMomaGraphçš„æ ¸å¿ƒæ€è·¯æ˜¯æ„å»ºä¸€ä¸ªç»Ÿä¸€çš„ã€çŠ¶æ€æ„ŸçŸ¥çš„åœºæ™¯å›¾è¡¨ç¤ºï¼Œå°†ç©ºé—´å…³ç³»ã€åŠŸèƒ½å…³ç³»å’Œç‰©ä½“çŠ¶æ€æ•´åˆåœ¨ä¸€èµ·ã€‚é€šè¿‡å¼•å…¥éƒ¨ä»¶çº§åˆ«çš„äº¤äº’å…ƒç´ ï¼ŒMomaGraphèƒ½å¤Ÿæ›´ç²¾ç»†åœ°æè¿°åœºæ™¯ï¼Œä»è€Œæ”¯æŒæ›´å¤æ‚çš„ä»»åŠ¡è§„åˆ’ã€‚æ­¤å¤–ï¼Œé€šè¿‡è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼ŒMomaGraphèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£åœºæ™¯ä¸­çš„è¯­ä¹‰ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šMomaGraphçš„æ•´ä½“æ¡†æ¶åŒ…æ‹¬æ•°æ®æ”¶é›†ä¸æ ‡æ³¨ã€æ¨¡å‹è®­ç»ƒå’Œä»»åŠ¡è§„åˆ’ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚é¦–å…ˆï¼Œæ„å»ºMomaGraph-Scenesæ•°æ®é›†ï¼Œå¯¹å®¶åº­ç¯å¢ƒä¸­çš„åœºæ™¯è¿›è¡Œè¯¦ç»†æ ‡æ³¨ï¼ŒåŒ…æ‹¬ç‰©ä½“çš„ä½ç½®ã€åŠŸèƒ½å’ŒçŠ¶æ€ã€‚ç„¶åï¼Œä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹MomaGraph-R1ï¼Œä½¿å…¶èƒ½å¤Ÿé¢„æµ‹é¢å‘ä»»åŠ¡çš„åœºæ™¯å›¾ã€‚æœ€åï¼Œåœ¨Graph-then-Planæ¡†æ¶ä¸‹ï¼Œåˆ©ç”¨é¢„æµ‹çš„åœºæ™¯å›¾è¿›è¡Œä»»åŠ¡è§„åˆ’ã€‚

**å…³é”®åˆ›æ–°**ï¼šMomaGraphçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç»Ÿä¸€çš„åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒå°†ç©ºé—´å…³ç³»ã€åŠŸèƒ½å…³ç³»å’Œç‰©ä½“çŠ¶æ€æ•´åˆåœ¨ä¸€èµ·ï¼Œä»è€Œæ›´å…¨é¢åœ°æè¿°åœºæ™¯ã€‚æ­¤å¤–ï¼ŒMomaGraph-Scenesæ•°æ®é›†çš„æ„å»ºå’ŒMomaGraph-Benchè¯„ä¼°å¥—ä»¶çš„æå‡ºï¼Œä¸ºè¯¥é¢†åŸŸçš„ç ”ç©¶æä¾›äº†é‡è¦çš„æ•°æ®å’Œè¯„ä¼°æ ‡å‡†ã€‚

**å…³é”®è®¾è®¡**ï¼šMomaGraph-R1æ¨¡å‹æ˜¯ä¸€ä¸ª70äº¿å‚æ•°çš„è§†è§‰-è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨Transformeræ¶æ„ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä»¥ä¼˜åŒ–æ¨¡å‹åœ¨ä»»åŠ¡è§„åˆ’æ–¹é¢çš„æ€§èƒ½ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬åœºæ™¯å›¾é¢„æµ‹æŸå¤±å’Œä»»åŠ¡è§„åˆ’å¥–åŠ±ã€‚å…·ä½“å‚æ•°è®¾ç½®å’Œç½‘ç»œç»“æ„ç»†èŠ‚æœªåœ¨è®ºæ–‡ä¸­è¯¦ç»†æè¿°ï¼Œå±äºæœªçŸ¥ä¿¡æ¯ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16909v1/Figures/Teaser.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16909v1/Figures/Failure.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16909v1/x1.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

MomaGraph-R1æ¨¡å‹åœ¨MomaGraph-BenchåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†71.6%çš„å‡†ç¡®ç‡ï¼Œæ¯”æœ€ä½³åŸºçº¿é«˜å‡º11.4%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜æˆåŠŸåœ°æ¨å¹¿åˆ°å…¬å…±åŸºå‡†æµ‹è¯•ï¼Œå¹¶æœ‰æ•ˆåœ°è½¬ç§»åˆ°çœŸå®æœºå™¨äººå®éªŒä¸­ï¼ŒéªŒè¯äº†å…¶æ³›åŒ–èƒ½åŠ›å’Œå®ç”¨æ€§ã€‚è¿™äº›å®éªŒç»“æœè¡¨æ˜ï¼ŒMomaGraphæ˜¯ä¸€ç§æœ‰æ•ˆçš„åœºæ™¯è¡¨ç¤ºæ–¹æ³•ï¼Œå¯ä»¥æ˜¾è‘—æé«˜å…·èº«æ™ºèƒ½ä½“çš„ä»»åŠ¡è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

MomaGraphåœ¨å®¶åº­æœåŠ¡æœºå™¨äººã€è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£å‘¨å›´ç¯å¢ƒï¼Œä»è€Œæ‰§è¡Œæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©å“æ•´ç†ã€æ¸…æ´å’Œçƒ¹é¥ªã€‚æ­¤å¤–ï¼ŒMomaGraphè¿˜å¯ä»¥ç”¨äºæ„å»ºæ›´é€¼çœŸçš„è™šæ‹Ÿç¯å¢ƒï¼Œä¸ºç”¨æˆ·æä¾›æ›´æ²‰æµ¸å¼çš„ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Mobile manipulators in households must both navigate and manipulate. This requires a compact, semantically rich scene representation that captures where objects are, how they function, and which parts are actionable. Scene graphs are a natural choice, yet prior work often separates spatial and functional relations, treats scenes as static snapshots without object states or temporal updates, and overlooks information most relevant for accomplishing the current task. To address these limitations, we introduce MomaGraph, a unified scene representation for embodied agents that integrates spatial-functional relationships and part-level interactive elements. However, advancing such a representation requires both suitable data and rigorous evaluation, which have been largely missing. We thus contribute MomaGraph-Scenes, the first large-scale dataset of richly annotated, task-driven scene graphs in household environments, along with MomaGraph-Bench, a systematic evaluation suite spanning six reasoning capabilities from high-level planning to fine-grained scene understanding. Built upon this foundation, we further develop MomaGraph-R1, a 7B vision-language model trained with reinforcement learning on MomaGraph-Scenes. MomaGraph-R1 predicts task-oriented scene graphs and serves as a zero-shot task planner under a Graph-then-Plan framework. Extensive experiments demonstrate that our model achieves state-of-the-art results among open-source models, reaching 71.6% accuracy on the benchmark (+11.4% over the best baseline), while generalizing across public benchmarks and transferring effectively to real-robot experiments.

