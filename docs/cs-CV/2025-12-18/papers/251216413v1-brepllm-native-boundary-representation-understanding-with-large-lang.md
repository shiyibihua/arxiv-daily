---
layout: default
title: BrepLLM: Native Boundary Representation Understanding with Large Language Models
---

# BrepLLM: Native Boundary Representation Understanding with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16413" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16413v1</a>
  <a href="https://arxiv.org/pdf/2512.16413.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16413v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16413v1', 'BrepLLM: Native Boundary Representation Understanding with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liyuan Deng, Hao Guo, Yunpeng Bai, Yongkang Dai, Huaxi Huang, Yilei Shi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BrepLLMï¼šæå‡ºä¸€ç§åŸç”Ÿè¾¹ç•Œè¡¨ç¤ºç†è§£çš„å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¾¹ç•Œè¡¨ç¤º` `å¤§è¯­è¨€æ¨¡å‹` `è·¨æ¨¡æ€å­¦ä¹ ` `3Då‡ ä½•` `æ‹“æ‰‘ä¿¡æ¯`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰åŸºäºtokenåºåˆ—çš„LLMéš¾ä»¥ç›´æ¥å¤„ç†åŒ…å«å¤æ‚å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„3D Brepæ¨¡å‹ã€‚
2. BrepLLMé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå°†Brepæ•°æ®è½¬æ¢ä¸ºå›¾è¡¨ç¤ºï¼Œå¹¶ä¸LLMå¯¹é½ï¼Œå®ç°å¯¹åŸå§‹Brepæ•°æ®çš„è§£æå’Œæ¨ç†ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œæè¿°ä»»åŠ¡ä¸Šå–å¾—äº†SOTAç»“æœï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰åŸºäºtokenåºåˆ—çš„å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸é€‚åˆç›´æ¥å¤„ç†åŒ…å«å¤æ‚å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„3Dè¾¹ç•Œè¡¨ç¤º(Brep)æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†BrepLLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä½¿LLMèƒ½å¤Ÿè§£æå’Œæ¨ç†åŸå§‹Brepæ•°æ®çš„æ¡†æ¶ï¼Œå¼¥åˆäº†ç»“æ„åŒ–3Då‡ ä½•å’Œè‡ªç„¶è¯­è¨€ä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚BrepLLMé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼šè·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒå’Œå¤šé˜¶æ®µLLMå¾®è°ƒã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥å°†Brepè½¬æ¢ä¸ºå…·æœ‰å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„å›¾è¡¨ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåˆ†å±‚BrepEncoderæ¥æå–å‡ ä½•ï¼ˆå³é¢å’Œè¾¹ï¼‰å’Œæ‹“æ‰‘çš„ç‰¹å¾ï¼Œç”Ÿæˆå•ä¸ªå…¨å±€tokenå’Œä¸€ç³»åˆ—èŠ‚ç‚¹tokenã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å¯¹æ¯”å­¦ä¹ å°†å…¨å±€tokenä¸æ¥è‡ªå†»ç»“CLIPæ–‡æœ¬ç¼–ç å™¨(ViT-L/14)çš„æ–‡æœ¬åµŒå…¥å¯¹é½ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒçš„BrepEncoderé›†æˆåˆ°LLMä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‰é˜¶æ®µæ¸è¿›è®­ç»ƒç­–ç•¥å¯¹é½å…¶èŠ‚ç‚¹tokenåºåˆ—ï¼š(1)è®­ç»ƒä¸€ä¸ªåŸºäºMLPçš„è¯­ä¹‰æ˜ å°„ï¼Œå°†Brepè¡¨ç¤ºæ˜ å°„åˆ°å…·æœ‰2D-LLMå…ˆéªŒçš„2Dã€‚(2)æ‰§è¡ŒLLMçš„å¾®è°ƒã€‚(3)è®¾è®¡ä¸€ç§æ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)æ¥å¢å¼ºå‡ ä½•å¤šæ ·æ€§å»ºæ¨¡ã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†Brep2Textæ•°æ®é›†ï¼ŒåŒ…å«269,444ä¸ªBrep-æ–‡æœ¬é—®ç­”å¯¹ã€‚å®éªŒè¡¨æ˜ï¼ŒBrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œå­—å¹•ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„ç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLM)æ— æ³•ç›´æ¥ç†è§£å’Œå¤„ç†3Dè¾¹ç•Œè¡¨ç¤º(Brep)æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰çš„LLMä¸»è¦å¤„ç†tokenåºåˆ—ï¼Œè€ŒBrepæ¨¡å‹åŒ…å«å¤æ‚çš„å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯ï¼Œç›´æ¥å¤„ç†ä¼šä¸¢å¤±å…³é”®ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½ä¸ä½³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†Brepæ¨¡å‹è½¬æ¢ä¸ºä¸€ç§LLMå¯ä»¥ç†è§£çš„è¡¨ç¤ºå½¢å¼ï¼Œå³å›¾è¡¨ç¤ºï¼Œå¹¶è®¾è®¡ä¸€ä¸ªç¼–ç å™¨(BrepEncoder)æ¥æå–Brepæ¨¡å‹çš„å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚ç„¶åï¼Œé€šè¿‡è·¨æ¨¡æ€å¯¹é½å’Œå¤šé˜¶æ®µå¾®è°ƒï¼Œå°†BrepEncoderä¸LLMè¿æ¥èµ·æ¥ï¼Œä½¿LLMèƒ½å¤Ÿç†è§£å’Œæ¨ç†Brepæ•°æ®ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBrepLLMæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒå’Œå¤šé˜¶æ®µLLMå¾®è°ƒã€‚åœ¨è·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆä½¿ç”¨è‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥å°†Brepæ¨¡å‹è½¬æ¢ä¸ºå›¾è¡¨ç¤ºã€‚ç„¶åï¼Œä½¿ç”¨åˆ†å±‚BrepEncoderæå–å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ï¼Œç”Ÿæˆå…¨å±€tokenå’ŒèŠ‚ç‚¹tokenåºåˆ—ã€‚é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼Œå°†å…¨å±€tokenä¸CLIPæ–‡æœ¬ç¼–ç å™¨çš„æ–‡æœ¬åµŒå…¥å¯¹é½ã€‚åœ¨å¤šé˜¶æ®µLLMå¾®è°ƒé˜¶æ®µï¼Œå°†é¢„è®­ç»ƒçš„BrepEncoderé›†æˆåˆ°LLMä¸­ï¼Œå¹¶ä½¿ç”¨ä¸‰é˜¶æ®µæ¸è¿›è®­ç»ƒç­–ç•¥å¯¹é½èŠ‚ç‚¹tokenåºåˆ—ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†BrepLLMæ¡†æ¶ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä½¿LLMèƒ½å¤Ÿè§£æå’Œæ¨ç†åŸå§‹Brepæ•°æ®çš„æ¡†æ¶ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†è‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥ã€åˆ†å±‚BrepEncoderå’Œæ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)ç­‰æŠ€æœ¯ï¼Œä»¥æé«˜Brepæ¨¡å‹çš„è¡¨ç¤ºèƒ½åŠ›å’ŒLLMçš„æ¨ç†èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šè‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥æ ¹æ®Brepæ¨¡å‹çš„å‡ ä½•ç‰¹å¾åŠ¨æ€è°ƒæ•´é‡‡æ ·å¯†åº¦ã€‚åˆ†å±‚BrepEncoderåŒ…å«å‡ ä½•ç¼–ç å™¨å’Œæ‹“æ‰‘ç¼–ç å™¨ï¼Œåˆ†åˆ«æå–å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚æ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)é€šè¿‡å­¦ä¹ ä¸åŒçš„æŸ¥è¯¢å‘é‡æ¥å¢å¼ºå‡ ä½•å¤šæ ·æ€§å»ºæ¨¡ã€‚ä¸‰é˜¶æ®µæ¸è¿›è®­ç»ƒç­–ç•¥åŒ…æ‹¬ï¼š(1)è®­ç»ƒä¸€ä¸ªåŸºäºMLPçš„è¯­ä¹‰æ˜ å°„ï¼Œå°†Brepè¡¨ç¤ºæ˜ å°„åˆ°å…·æœ‰2D-LLMå…ˆéªŒçš„2Dã€‚(2)æ‰§è¡ŒLLMçš„å¾®è°ƒã€‚(3)è®¾è®¡ä¸€ç§æ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)æ¥å¢å¼ºå‡ ä½•å¤šæ ·æ€§å»ºæ¨¡ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/zhanshitu1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/framework.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/BrepEncoder.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

BrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œæè¿°ä»»åŠ¡ä¸Šå–å¾—äº†SOTAç»“æœã€‚å…·ä½“è€Œè¨€ï¼Œåœ¨Brep2Textæ•°æ®é›†ä¸Šï¼ŒBrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»ä»»åŠ¡ä¸Šè¶…è¿‡äº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨3Då¯¹è±¡æè¿°ä»»åŠ¡ä¸Šç”Ÿæˆäº†æ›´å‡†ç¡®ã€æ›´ä¸°å¯Œçš„æè¿°ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BrepLLMå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚3Dæ¨¡å‹æ£€ç´¢ã€3Dæ¨¡å‹ç”Ÿæˆã€CAD/CAMç³»ç»Ÿã€æœºå™¨äººå¯¼èˆªå’Œåœºæ™¯ç†è§£ç­‰ã€‚é€šè¿‡ä½¿LLMèƒ½å¤Ÿç†è§£å’Œæ¨ç†3D Brepæ•°æ®ï¼Œå¯ä»¥å®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„3Dæ¨¡å‹å¤„ç†å’Œåº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current token-sequence-based Large Language Models (LLMs) are not well-suited for directly processing 3D Boundary Representation (Brep) models that contain complex geometric and topological information. We propose BrepLLM, the first framework that enables LLMs to parse and reason over raw Brep data, bridging the modality gap between structured 3D geometry and natural language. BrepLLM employs a two-stage training pipeline: Cross-modal Alignment Pre-training and Multi-stage LLM Fine-tuning. In the first stage, an adaptive UV sampling strategy converts Breps into graphs representation with geometric and topological information. We then design a hierarchical BrepEncoder to extract features from geometry (i.e., faces and edges) and topology, producing both a single global token and a sequence of node tokens. Then we align the global token with text embeddings from a frozen CLIP text encoder (ViT-L/14) via contrastive learning. In the second stage, we integrate the pretrained BrepEncoder into an LLM. We then align its sequence of node tokens using a three-stage progressive training strategy: (1) training an MLP-based semantic mapping from Brep representation to 2D with 2D-LLM priors. (2) performing fine-tuning of the LLM. (3) designing a Mixture-of-Query Experts (MQE) to enhance geometric diversity modeling. We also construct Brep2Text, a dataset comprising 269,444 Brep-text question-answer pairs. Experiments show that BrepLLM achieves state-of-the-art (SOTA) results on 3D object classification and captioning tasks.

