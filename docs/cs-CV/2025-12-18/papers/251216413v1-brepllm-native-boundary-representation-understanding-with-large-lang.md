---
layout: default
title: BrepLLM: Native Boundary Representation Understanding with Large Language Models
---

# BrepLLM: Native Boundary Representation Understanding with Large Language Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16413" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16413v1</a>
  <a href="https://arxiv.org/pdf/2512.16413.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16413v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16413v1', 'BrepLLM: Native Boundary Representation Understanding with Large Language Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Liyuan Deng, Hao Guo, Yunpeng Bai, Yongkang Dai, Huaxi Huang, Yilei Shi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**BrepLLMï¼šæå‡ºä¸€ç§åŸç”Ÿè¾¹ç•Œè¡¨ç¤ºç†è§£çš„å¤§è¯­è¨€æ¨¡å‹æ¡†æ¶**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è¾¹ç•Œè¡¨ç¤º` `å¤§è¯­è¨€æ¨¡å‹` `ä¸‰ç»´ç†è§£` `è·¨æ¨¡æ€å­¦ä¹ ` `å‡ ä½•æ·±åº¦å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¤§è¯­è¨€æ¨¡å‹éš¾ä»¥ç›´æ¥å¤„ç†åŒ…å«å¤æ‚å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„3D Brepæ¨¡å‹ã€‚
2. BrepLLMé€šè¿‡ä¸¤é˜¶æ®µè®­ç»ƒï¼Œå°†Brepæ•°æ®è½¬æ¢ä¸ºLLMå¯ç†è§£çš„tokenåºåˆ—ï¼Œå®ç°è·¨æ¨¡æ€å¯¹é½ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒBrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œæè¿°ä»»åŠ¡ä¸Šå–å¾—äº†å½“å‰æœ€ä¼˜çš„ç»“æœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å½“å‰åŸºäºtokenåºåˆ—çš„å¤§è¯­è¨€æ¨¡å‹(LLMs)ä¸é€‚åˆç›´æ¥å¤„ç†åŒ…å«å¤æ‚å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„3Dè¾¹ç•Œè¡¨ç¤º(Brep)æ¨¡å‹ã€‚æˆ‘ä»¬æå‡ºäº†BrepLLMï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä½¿LLMsèƒ½å¤Ÿè§£æå’Œæ¨ç†åŸå§‹Brepæ•°æ®çš„æ¡†æ¶ï¼Œå¼¥åˆäº†ç»“æ„åŒ–3Då‡ ä½•å’Œè‡ªç„¶è¯­è¨€ä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚BrepLLMé‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ï¼šè·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒå’Œå¤šé˜¶æ®µLLMå¾®è°ƒã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œè‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥å°†Brepè½¬æ¢ä¸ºå…·æœ‰å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯çš„å›¾è¡¨ç¤ºã€‚ç„¶åï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªåˆ†å±‚BrepEncoderæ¥æå–å‡ ä½•ï¼ˆå³é¢å’Œè¾¹ï¼‰å’Œæ‹“æ‰‘çš„ç‰¹å¾ï¼Œç”Ÿæˆå•ä¸ªå…¨å±€tokenå’Œä¸€ç³»åˆ—èŠ‚ç‚¹tokenã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡å¯¹æ¯”å­¦ä¹ å°†å…¨å±€tokenä¸æ¥è‡ªå†»ç»“çš„CLIPæ–‡æœ¬ç¼–ç å™¨(ViT-L/14)çš„æ–‡æœ¬åµŒå…¥å¯¹é½ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬å°†é¢„è®­ç»ƒçš„BrepEncoderé›†æˆåˆ°LLMä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸‰é˜¶æ®µæ¸è¿›å¼è®­ç»ƒç­–ç•¥å¯¹é½å…¶èŠ‚ç‚¹tokenåºåˆ—ï¼š(1)è®­ç»ƒä¸€ä¸ªåŸºäºMLPçš„è¯­ä¹‰æ˜ å°„ï¼Œå°†Brepè¡¨ç¤ºæ˜ å°„åˆ°å…·æœ‰2D-LLMå…ˆéªŒçš„2Dè¡¨ç¤ºã€‚(2)æ‰§è¡ŒLLMçš„å¾®è°ƒã€‚(3)è®¾è®¡ä¸€ä¸ªæ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)æ¥å¢å¼ºå‡ ä½•å¤šæ ·æ€§å»ºæ¨¡ã€‚æˆ‘ä»¬è¿˜æ„å»ºäº†Brep2Textæ•°æ®é›†ï¼ŒåŒ…å«269,444ä¸ªBrep-æ–‡æœ¬é—®ç­”å¯¹ã€‚å®éªŒè¡¨æ˜ï¼ŒBrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œå­—å¹•ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„ç»“æœã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLM)æ— æ³•ç›´æ¥ç†è§£å’Œå¤„ç†3Dè¾¹ç•Œè¡¨ç¤º(Brep)æ¨¡å‹çš„é—®é¢˜ã€‚ç°æœ‰çš„LLMä¸»è¦å¤„ç†æ–‡æœ¬åºåˆ—ï¼Œè€ŒBrepæ¨¡å‹åŒ…å«å¤æ‚çš„å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯ï¼Œç›´æ¥è¾“å…¥LLMä¼šå¯¼è‡´ä¿¡æ¯ä¸¢å¤±å’Œæ€§èƒ½ä¸‹é™ã€‚å› æ­¤ï¼Œå¦‚ä½•å°†Brepæ•°æ®æœ‰æ•ˆåœ°è½¬æ¢ä¸ºLLMå¯ä»¥ç†è§£çš„å½¢å¼æ˜¯å…³é”®æŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†Brepæ¨¡å‹è½¬æ¢ä¸ºå›¾è¡¨ç¤ºï¼Œå¹¶è®¾è®¡ä¸€ä¸ªä¸“é—¨çš„BrepEncoderæ¥æå–å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ã€‚é€šè¿‡è·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒå’Œå¤šé˜¶æ®µLLMå¾®è°ƒï¼Œä½¿LLMèƒ½å¤Ÿç†è§£å’Œæ¨ç†Brepæ•°æ®ã€‚è¿™ç§æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºå°†å¤æ‚çš„3Då‡ ä½•ä¿¡æ¯è½¬åŒ–ä¸ºLLMæ“…é•¿å¤„ç†çš„tokenåºåˆ—ï¼ŒåŒæ—¶ä¿ç•™å…³é”®çš„å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šBrepLLMçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè·¨æ¨¡æ€å¯¹é½é¢„è®­ç»ƒå’Œå¤šé˜¶æ®µLLMå¾®è°ƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œé¦–å…ˆä½¿ç”¨è‡ªé€‚åº”UVé‡‡æ ·å°†Brepè½¬æ¢ä¸ºå›¾è¡¨ç¤ºã€‚ç„¶åï¼ŒBrepEncoderæå–å‡ ä½•å’Œæ‹“æ‰‘ç‰¹å¾ï¼Œç”Ÿæˆå…¨å±€tokenå’ŒèŠ‚ç‚¹tokenåºåˆ—ã€‚å…¨å±€tokené€šè¿‡å¯¹æ¯”å­¦ä¹ ä¸CLIPæ–‡æœ¬åµŒå…¥å¯¹é½ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼Œé¢„è®­ç»ƒçš„BrepEncoderé›†æˆåˆ°LLMä¸­ï¼ŒèŠ‚ç‚¹tokenåºåˆ—é€šè¿‡ä¸‰é˜¶æ®µæ¸è¿›å¼è®­ç»ƒç­–ç•¥è¿›è¡Œå¯¹é½ï¼ŒåŒ…æ‹¬è¯­ä¹‰æ˜ å°„ã€LLMå¾®è°ƒå’Œæ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)è®­ç»ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºæå‡ºäº†BrepLLMæ¡†æ¶ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªèƒ½å¤Ÿè®©LLMç›´æ¥è§£æå’Œæ¨ç†åŸå§‹Brepæ•°æ®çš„æ¡†æ¶ã€‚æ­¤å¤–ï¼Œè‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥ã€åˆ†å±‚BrepEncoderå’Œä¸‰é˜¶æ®µæ¸è¿›å¼è®­ç»ƒç­–ç•¥ä¹Ÿæ˜¯é‡è¦çš„æŠ€æœ¯åˆ›æ–°ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒBrepLLMèƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°åˆ©ç”¨Brepæ•°æ®ä¸­çš„å‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯ï¼Œä»è€Œæé«˜LLMåœ¨3Dç›¸å…³ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚

**å…³é”®è®¾è®¡**ï¼šBrepEncoderé‡‡ç”¨åˆ†å±‚ç»“æ„ï¼Œåˆ†åˆ«æå–é¢å’Œè¾¹çš„ç‰¹å¾ï¼Œå¹¶èåˆå‡ ä½•å’Œæ‹“æ‰‘ä¿¡æ¯ã€‚è‡ªé€‚åº”UVé‡‡æ ·ç­–ç•¥æ ¹æ®æ›²ç‡è°ƒæ•´é‡‡æ ·å¯†åº¦ï¼Œä»¥ä¿ç•™æ›´å¤šç»†èŠ‚ã€‚ä¸‰é˜¶æ®µæ¸è¿›å¼è®­ç»ƒç­–ç•¥é€æ­¥å¯¹é½Brepè¡¨ç¤ºå’ŒLLMï¼Œé¿å…äº†ç›´æ¥å¾®è°ƒå¯¼è‡´çš„ç¾éš¾æ€§é—å¿˜ã€‚æ··åˆæŸ¥è¯¢ä¸“å®¶(MQE)é€šè¿‡å­¦ä¹ ä¸åŒçš„æŸ¥è¯¢ç­–ç•¥æ¥å¢å¼ºå‡ ä½•å¤šæ ·æ€§å»ºæ¨¡ã€‚æŸå¤±å‡½æ•°åŒ…æ‹¬å¯¹æ¯”å­¦ä¹ æŸå¤±å’Œäº¤å‰ç†µæŸå¤±ï¼Œç”¨äºå¯¹é½ä¸åŒæ¨¡æ€çš„ç‰¹å¾ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/zhanshitu1.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/framework.png" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16413v1/images/BrepEncoder.png" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

BrepLLMåœ¨3Då¯¹è±¡åˆ†ç±»å’Œæè¿°ä»»åŠ¡ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚åœ¨Brep2Textæ•°æ®é›†ä¸Šï¼ŒBrepLLMçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨3Då¯¹è±¡åˆ†ç±»ä»»åŠ¡ä¸Šï¼ŒBrepLLMçš„å‡†ç¡®ç‡æ¯”åŸºçº¿æ–¹æ³•æé«˜äº†XX%ã€‚åœ¨æè¿°ç”Ÿæˆä»»åŠ¡ä¸Šï¼ŒBrepLLMç”Ÿæˆçš„æè¿°æ›´åŠ å‡†ç¡®å’Œä¸°å¯Œã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

BrepLLMåœ¨CAD/CAMã€é€†å‘å·¥ç¨‹ã€3Då†…å®¹åˆ›ä½œç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äº3Dæ¨¡å‹çš„è‡ªåŠ¨åˆ†ç±»ã€æè¿°ç”Ÿæˆã€ç¼ºé™·æ£€æµ‹ã€å‚æ•°åŒ–è®¾è®¡ç­‰ä»»åŠ¡ã€‚é€šè¿‡ç»“åˆLLMçš„å¼ºå¤§æ¨ç†èƒ½åŠ›å’ŒBrepæ¨¡å‹çš„ç²¾ç¡®å‡ ä½•ä¿¡æ¯ï¼ŒBrepLLMå¯ä»¥å®ç°æ›´æ™ºèƒ½ã€æ›´é«˜æ•ˆçš„3Dè®¾è®¡å’Œåˆ¶é€ æµç¨‹ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯æœ‰æœ›åº”ç”¨äºæ™ºèƒ½åˆ¶é€ ã€æ•°å­—å­ªç”Ÿç­‰é¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Current token-sequence-based Large Language Models (LLMs) are not well-suited for directly processing 3D Boundary Representation (Brep) models that contain complex geometric and topological information. We propose BrepLLM, the first framework that enables LLMs to parse and reason over raw Brep data, bridging the modality gap between structured 3D geometry and natural language. BrepLLM employs a two-stage training pipeline: Cross-modal Alignment Pre-training and Multi-stage LLM Fine-tuning. In the first stage, an adaptive UV sampling strategy converts Breps into graphs representation with geometric and topological information. We then design a hierarchical BrepEncoder to extract features from geometry (i.e., faces and edges) and topology, producing both a single global token and a sequence of node tokens. Then we align the global token with text embeddings from a frozen CLIP text encoder (ViT-L/14) via contrastive learning. In the second stage, we integrate the pretrained BrepEncoder into an LLM. We then align its sequence of node tokens using a three-stage progressive training strategy: (1) training an MLP-based semantic mapping from Brep representation to 2D with 2D-LLM priors. (2) performing fine-tuning of the LLM. (3) designing a Mixture-of-Query Experts (MQE) to enhance geometric diversity modeling. We also construct Brep2Text, a dataset comprising 269,444 Brep-text question-answer pairs. Experiments show that BrepLLM achieves state-of-the-art (SOTA) results on 3D object classification and captioning tasks.

