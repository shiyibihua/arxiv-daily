---
layout: default
title: Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation
---

# Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16893" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16893v1</a>
  <a href="https://arxiv.org/pdf/2512.16893.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16893v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16893v1', 'Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaiwen Jiang, Xueting Li, Seonwook Park, Ravi Ramamoorthi, Shalini De Mello, Koki Nagano

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: Project website is https://research.nvidia.com/labs/amri/projects/instant4d

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäº3Dæ„ŸçŸ¥è¡¨è¾¾è’¸é¦çš„å¿«é€Ÿé«˜è¡¨ç°åŠ›é«˜æ–¯å¤´éƒ¨å¤´åƒæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `äººåƒåŠ¨ç”»` `3Dæ„ŸçŸ¥` `æ‰©æ•£æ¨¡å‹` `çŸ¥è¯†è’¸é¦` `é«˜æ–¯æº…å°„` `å®æ—¶æ¸²æŸ“` `å±€éƒ¨èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰2DäººåƒåŠ¨ç”»æ–¹æ³•åœ¨3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ä¸Šå­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥åº”ç”¨äºå®æ—¶åœºæ™¯ã€‚
2. é€šè¿‡å°†2Dæ‰©æ•£æ¨¡å‹çš„çŸ¥è¯†è’¸é¦åˆ°3Då‰é¦ˆç½‘ç»œä¸­ï¼Œå®ç°å¿«é€Ÿä¸”é«˜è¡¨ç°åŠ›çš„3DäººåƒåŠ¨ç”»ã€‚
3. è¯¥æ–¹æ³•åœ¨åŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶ä¸Šè¾¾åˆ°107.31 FPSï¼ŒåŠ¨ç”»è´¨é‡ä¸SOTAæ–¹æ³•ç›¸å½“ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¾—ç›Šäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼ŒäººåƒåŠ¨ç”»çš„è´¨é‡å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼Œè¿™äº›2Dæ–¹æ³•é€šå¸¸ä¼šç‰ºç‰²3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨æ•°å­—å­ªç”Ÿæˆ–è¿œç¨‹å‘ˆç°ç­‰å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäºæ˜¾å¼3Dè¡¨ç¤ºï¼ˆå¦‚ç¥ç»è¾å°„åœºæˆ–é«˜æ–¯æº…å°„ï¼‰çš„3Dæ„ŸçŸ¥é¢éƒ¨åŠ¨ç”»å‰é¦ˆæ–¹æ³•ï¼Œå¯ç¡®ä¿3Dä¸€è‡´æ€§å¹¶å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œä½†è¡¨è¾¾ç»†èŠ‚è¾ƒå·®ã€‚æœ¬æ–‡æ—¨åœ¨ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ï¼Œå°†çŸ¥è¯†ä»åŸºäº2Dæ‰©æ•£çš„æ–¹æ³•æç‚¼åˆ°å‰é¦ˆç¼–ç å™¨ä¸­ï¼Œè¯¥ç¼–ç å™¨å¯ç«‹å³å°†é‡å¤–å•å¼ å›¾åƒè½¬æ¢ä¸º3Dä¸€è‡´ã€å¿«é€Ÿä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„å¯åŠ¨ç”»è¡¨ç¤ºã€‚æˆ‘ä»¬çš„åŠ¨ç”»è¡¨ç¤ºä¸é¢éƒ¨çš„3Dè¡¨ç¤ºè§£è€¦ï¼Œå¹¶ä»æ•°æ®ä¸­éšå¼åœ°å­¦ä¹ è¿åŠ¨ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹é€šå¸¸é™åˆ¶åŠ¨ç”»èƒ½åŠ›çš„é¢„å®šä¹‰å‚æ•°æ¨¡å‹çš„ä¾èµ–ã€‚ä¸å…ˆå‰ç”¨äºèåˆ3Dç»“æ„å’ŒåŠ¨ç”»ä¿¡æ¯çš„è®¡ç®—å¯†é›†å‹å…¨å±€èåˆæœºåˆ¶ï¼ˆä¾‹å¦‚ï¼Œå¤šä¸ªæ³¨æ„åŠ›å±‚ï¼‰ä¸åŒï¼Œæˆ‘ä»¬çš„è®¾è®¡é‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„è½»é‡çº§å±€éƒ¨èåˆç­–ç•¥ï¼Œä»¥å®ç°é«˜åŠ¨ç”»è¡¨ç°åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»¥107.31 FPSçš„é€Ÿåº¦è¿è¡ŒåŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶ï¼ŒåŒæ—¶å®ç°äº†ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“çš„åŠ¨ç”»è´¨é‡ï¼Œè¶…è¿‡äº†åœ¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡çš„æ›¿ä»£è®¾è®¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰2DäººåƒåŠ¨ç”»æ–¹æ³•è™½ç„¶åœ¨åŠ¨ç”»è´¨é‡ä¸Šæœ‰æ‰€æå‡ï¼Œä½†å¾€å¾€ç‰ºç‰²äº†3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œéš¾ä»¥æ»¡è¶³å®æ—¶åº”ç”¨çš„éœ€æ±‚ã€‚è€ŒåŸºäº3Dè¡¨ç¤ºçš„æ–¹æ³•è™½ç„¶ä¿è¯äº†3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œä½†åœ¨è¡¨è¾¾ç»†èŠ‚ä¸Šæœ‰æ‰€æ¬ ç¼ºã€‚å› æ­¤ï¼Œå¦‚ä½•å…¼é¡¾3Dä¸€è‡´æ€§ã€é€Ÿåº¦å’Œè¡¨è¾¾èƒ½åŠ›æ˜¯æœ¬æ–‡è¦è§£å†³çš„é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†2Dæ‰©æ•£æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›â€œè’¸é¦â€åˆ°3Då‰é¦ˆç½‘ç»œä¸­ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨2Dæ‰©æ•£æ¨¡å‹ç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ç”»ç»†èŠ‚ï¼Œç„¶åè®­ç»ƒä¸€ä¸ªå‰é¦ˆç½‘ç»œæ¥å¿«é€Ÿé¢„æµ‹è¿™äº›ç»†èŠ‚ï¼Œå¹¶å°†å…¶èåˆåˆ°3Däººåƒè¡¨ç¤ºä¸­ã€‚è¿™æ ·æ—¢èƒ½ä¿è¯3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œåˆèƒ½è·å¾—ä¸°å¯Œçš„åŠ¨ç”»è¡¨è¾¾ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªæ¨¡å—ï¼š1) 2Dæ‰©æ•£æ¨¡å‹ï¼šç”¨äºç”Ÿæˆé«˜è´¨é‡çš„åŠ¨ç”»ç»†èŠ‚ï¼›2) å‰é¦ˆç¼–ç å™¨ï¼šå°†å•å¼ å›¾åƒè½¬æ¢ä¸º3Dä¸€è‡´ã€å¿«é€Ÿä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„å¯åŠ¨ç”»è¡¨ç¤ºï¼›3) è½»é‡çº§å±€éƒ¨èåˆæ¨¡å—ï¼šå°†åŠ¨ç”»ä¿¡æ¯èåˆåˆ°3Dç»“æ„ä¿¡æ¯ä¸­ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨2Dæ‰©æ•£æ¨¡å‹ç”ŸæˆåŠ¨ç”»ç»†èŠ‚ï¼Œç„¶åä½¿ç”¨å‰é¦ˆç¼–ç å™¨é¢„æµ‹è¿™äº›ç»†èŠ‚ï¼Œæœ€åä½¿ç”¨è½»é‡çº§å±€éƒ¨èåˆæ¨¡å—å°†è¿™äº›ç»†èŠ‚èåˆåˆ°3Däººåƒè¡¨ç¤ºä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•æœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºä½¿ç”¨äº†ä¸€ç§è½»é‡çº§çš„å±€éƒ¨èåˆç­–ç•¥ï¼Œè€Œä¸æ˜¯ä¼ ç»Ÿçš„å…¨å±€èåˆæœºåˆ¶ï¼ˆå¦‚æ³¨æ„åŠ›å±‚ï¼‰ã€‚è¿™ç§å±€éƒ¨èåˆç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°èåˆ3Dç»“æ„å’ŒåŠ¨ç”»ä¿¡æ¯ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„è®¡ç®—æ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è§£è€¦äº†åŠ¨ç”»è¡¨ç¤ºå’Œ3Dè¡¨ç¤ºï¼Œä½¿å¾—åŠ¨ç”»çš„æ§åˆ¶æ›´åŠ çµæ´»ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•ä½¿ç”¨äº†ä¸€ç§é«˜æ•ˆçš„è½»é‡çº§å±€éƒ¨èåˆç­–ç•¥ï¼Œå…·ä½“æ¥è¯´ï¼Œå®ƒå°†åŠ¨ç”»ç‰¹å¾å’Œ3Dç»“æ„ç‰¹å¾åœ¨å±€éƒ¨åŒºåŸŸè¿›è¡Œèåˆï¼Œè€Œä¸æ˜¯åƒå…¨å±€æ³¨æ„åŠ›æœºåˆ¶é‚£æ ·å¯¹æ‰€æœ‰ç‰¹å¾è¿›è¡Œèåˆã€‚è¿™ç§å±€éƒ¨èåˆç­–ç•¥å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘è®¡ç®—é‡ï¼ŒåŒæ—¶ä¿æŒè¾ƒé«˜çš„èåˆæ•ˆæœã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è®¾è®¡äº†ä¸€ç§ç‰¹æ®Šçš„æŸå¤±å‡½æ•°ï¼Œç”¨äºè®­ç»ƒå‰é¦ˆç¼–ç å™¨ï¼Œä½¿å¾—å…¶èƒ½å¤Ÿå‡†ç¡®åœ°é¢„æµ‹åŠ¨ç”»ç»†èŠ‚ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/expressiveness_vs_consistency_colored.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/pipeline-2.jpg" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/residual_features.jpg" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨åŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶ä¸Šè¾¾åˆ°äº†107.31 FPSï¼Œæ˜¾è‘—ä¼˜äºå…¶ä»–éœ€è¦ç‰ºç‰²é€Ÿåº¦æ¥æ¢å–è´¨é‡çš„æ–¹æ³•ã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨åŠ¨ç”»è´¨é‡ä¸Šä¸æœ€å…ˆè¿›çš„2Dæ‰©æ•£æ¨¡å‹ç›¸å½“ï¼Œè¯æ˜äº†å…¶åœ¨é€Ÿåº¦å’Œè´¨é‡ä¸Šçš„ä¼˜è¶Šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€3Dä¸€è‡´ä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„å¤´éƒ¨å¤´åƒåŠ¨ç”»ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ•°å­—å­ªç”Ÿã€è¿œç¨‹å‘ˆç°ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œè¿›è¡Œè¿œç¨‹ä¼šè®®å’Œåä½œï¼Œæˆ–è€…ç”¨äºæ¸¸æˆå’Œå¨±ä¹åº”ç”¨ä¸­ï¼Œæä¾›æ›´å…·è¡¨ç°åŠ›çš„è§’è‰²åŠ¨ç”»ã€‚è¯¥æŠ€æœ¯çš„å‘å±•å°†æ¨åŠ¨äººæœºäº¤äº’æ–¹å¼çš„è¿›æ­¥ï¼Œå¹¶ä¸ºç”¨æˆ·å¸¦æ¥æ›´æ²‰æµ¸å¼çš„ä½“éªŒã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-aware facial animation feedforward methods -- built upon explicit 3D representations, such as neural radiance fields or Gaussian splatting -- ensure 3D consistency and achieve faster inference speed, but come with inferior expression details. In this paper, we aim to combine their strengths by distilling knowledge from a 2D diffusion-based method into a feed-forward encoder, which instantly converts an in-the-wild single image into a 3D-consistent, fast yet expressive animatable representation. Our animation representation is decoupled from the face's 3D representation and learns motion implicitly from data, eliminating the dependency on pre-defined parametric models that often constrain animation capabilities. Unlike previous computationally intensive global fusion mechanisms (e.g., multiple attention layers) for fusing 3D structural and animation information, our design employs an efficient lightweight local fusion strategy to achieve high animation expressivity. As a result, our method runs at 107.31 FPS for animation and pose control while achieving comparable animation quality to the state-of-the-art, surpassing alternative designs that trade speed for quality or vice versa. Project website is https://research.nvidia.com/labs/amri/projects/instant4d

