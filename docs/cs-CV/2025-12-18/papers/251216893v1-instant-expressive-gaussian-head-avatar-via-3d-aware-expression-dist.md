---
layout: default
title: Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation
---

# Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2512.16893" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2512.16893v1</a>
  <a href="https://arxiv.org/pdf/2512.16893.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2512.16893v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2512.16893v1', 'Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Kaiwen Jiang, Xueting Li, Seonwook Park, Ravi Ramamoorthi, Shalini De Mello, Koki Nagano

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-12-18

**å¤‡æ³¨**: Project website is https://research.nvidia.com/labs/amri/projects/instant4d

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäº3Dæ„ŸçŸ¥è¡¨è¾¾è’¸é¦çš„å¿«é€Ÿé«˜è¡¨ç°åŠ›é«˜æ–¯å¤´éƒ¨å¤´åƒæ–¹æ³•**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `äººåƒåŠ¨ç”»` `3Dæ„ŸçŸ¥` `è¡¨è¾¾è’¸é¦` `é«˜æ–¯æº…å°„` `å®æ—¶æ¸²æŸ“`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰2Dæ‰©æ•£æ¨¡å‹äººåƒåŠ¨ç”»æ–¹æ³•åœ¨3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ä¸Šå­˜åœ¨ä¸è¶³ï¼Œé™åˆ¶äº†å…¶åœ¨å®æ—¶åœºæ™¯ä¸­çš„åº”ç”¨ã€‚
2. è¯¥è®ºæ–‡æå‡ºä¸€ç§åŸºäº3Dæ„ŸçŸ¥è¡¨è¾¾è’¸é¦çš„å‰é¦ˆæ–¹æ³•ï¼Œå°†2Dæ‰©æ•£æ¨¡å‹çš„çŸ¥è¯†è¿ç§»åˆ°3Dè¡¨ç¤ºï¼Œå®ç°å¿«é€Ÿä¸”é«˜è¡¨ç°åŠ›çš„åŠ¨ç”»ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿è¯åŠ¨ç”»è´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†107.31 FPSçš„åŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶é€Ÿåº¦ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¾—ç›Šäºè§†é¢‘æ‰©æ•£æ¨¡å‹çš„æœ€æ–°è¿›å±•ï¼ŒäººåƒåŠ¨ç”»çš„è´¨é‡å¾—åˆ°äº†æ˜¾è‘—æé«˜ã€‚ç„¶è€Œï¼Œè¿™äº›2Dæ–¹æ³•é€šå¸¸ä¼šç‰ºç‰²3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œé™åˆ¶äº†å®ƒä»¬åœ¨æ•°å­—å­ªç”Ÿæˆ–è¿œç¨‹å‘ˆç°ç­‰å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäºæ˜¾å¼3Dè¡¨ç¤ºï¼ˆå¦‚ç¥ç»è¾å°„åœºæˆ–é«˜æ–¯æº…å°„ï¼‰çš„3Dæ„ŸçŸ¥é¢éƒ¨åŠ¨ç”»å‰é¦ˆæ–¹æ³•ï¼Œå¯ç¡®ä¿3Dä¸€è‡´æ€§å¹¶å®ç°æ›´å¿«çš„æ¨ç†é€Ÿåº¦ï¼Œä½†è¡¨è¾¾ç»†èŠ‚è¾ƒå·®ã€‚æœ¬æ–‡æ—¨åœ¨ç»“åˆä¸¤è€…çš„ä¼˜åŠ¿ï¼Œå°†çŸ¥è¯†ä»åŸºäº2Dæ‰©æ•£çš„æ–¹æ³•æç‚¼åˆ°å‰é¦ˆç¼–ç å™¨ä¸­ï¼Œè¯¥ç¼–ç å™¨å¯ç«‹å³å°†é‡å¤–å•å¼ å›¾åƒè½¬æ¢ä¸º3Dä¸€è‡´ã€å¿«é€Ÿä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„å¯åŠ¨ç”»è¡¨ç¤ºã€‚æˆ‘ä»¬çš„åŠ¨ç”»è¡¨ç¤ºä¸é¢éƒ¨çš„3Dè¡¨ç¤ºè§£è€¦ï¼Œå¹¶ä»æ•°æ®ä¸­éšå¼å­¦ä¹ è¿åŠ¨ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹é€šå¸¸é™åˆ¶åŠ¨ç”»èƒ½åŠ›çš„é¢„å®šä¹‰å‚æ•°æ¨¡å‹çš„ä¾èµ–ã€‚ä¸å…ˆå‰ç”¨äºèåˆ3Dç»“æ„å’ŒåŠ¨ç”»ä¿¡æ¯çš„è®¡ç®—å¯†é›†å‹å…¨å±€èåˆæœºåˆ¶ï¼ˆä¾‹å¦‚ï¼Œå¤šä¸ªæ³¨æ„åŠ›å±‚ï¼‰ä¸åŒï¼Œæˆ‘ä»¬çš„è®¾è®¡é‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„è½»é‡çº§å±€éƒ¨èåˆç­–ç•¥ï¼Œä»¥å®ç°é«˜åŠ¨ç”»è¡¨ç°åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä»¥107.31 FPSçš„é€Ÿåº¦è¿è¡ŒåŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶ï¼ŒåŒæ—¶å®ç°äº†ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“çš„åŠ¨ç”»è´¨é‡ï¼Œè¶…è¶Šäº†åœ¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´è¿›è¡Œæƒè¡¡çš„æ›¿ä»£è®¾è®¡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰çš„äººåƒåŠ¨ç”»æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åŸºäº2Dæ‰©æ•£æ¨¡å‹çš„æ–¹æ³•ï¼Œè™½ç„¶åœ¨åŠ¨ç”»è´¨é‡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœ¨3Dä¸€è‡´æ€§å’Œæ¨ç†é€Ÿåº¦æ–¹é¢å­˜åœ¨ä¸è¶³ã€‚è¿™é™åˆ¶äº†å®ƒä»¬åœ¨éœ€è¦å®æ—¶æ€§å’Œ3Dæ„ŸçŸ¥çš„åº”ç”¨åœºæ™¯ä¸­çš„åº”ç”¨ï¼Œä¾‹å¦‚æ•°å­—å­ªç”Ÿå’Œè¿œç¨‹å‘ˆç°ã€‚å¦ä¸€æ–¹é¢ï¼ŒåŸºäº3Dè¡¨ç¤ºï¼ˆå¦‚ç¥ç»è¾å°„åœºæˆ–é«˜æ–¯æº…å°„ï¼‰çš„æ–¹æ³•è™½ç„¶ä¿è¯äº†3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ï¼Œä½†åœ¨è¡¨è¾¾ç»†èŠ‚ä¸Šæœ‰æ‰€æ¬ ç¼ºã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè¯¥è®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†2Dæ‰©æ•£æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›â€œè’¸é¦â€åˆ°åŸºäº3Dè¡¨ç¤ºçš„å‰é¦ˆç½‘ç»œä¸­ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ—¢èƒ½ä¿æŒ3Dä¸€è‡´æ€§å’Œé€Ÿåº¦ä¼˜åŠ¿ï¼Œåˆèƒ½è·å¾—é«˜è´¨é‡çš„åŠ¨ç”»è¡¨è¾¾ã€‚å…³é”®åœ¨äºè®¾è®¡ä¸€ç§æœ‰æ•ˆçš„çŸ¥è¯†è¿ç§»æœºåˆ¶ï¼Œå°†2Dæ‰©æ•£æ¨¡å‹çš„ä¸°å¯Œç»†èŠ‚èå…¥åˆ°3Dè¡¨ç¤ºä¸­ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ–¹æ³•åŒ…å«ä¸€ä¸ªå‰é¦ˆç¼–ç å™¨ï¼Œç”¨äºå°†å•å¼ å›¾åƒè½¬æ¢ä¸º3Dä¸€è‡´ä¸”å¯åŠ¨ç”»çš„è¡¨ç¤ºã€‚è¯¥è¡¨ç¤ºåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼šé™æ€çš„3Däººè„¸ç»“æ„å’ŒåŠ¨æ€çš„åŠ¨ç”»ä¿¡æ¯ã€‚åŠ¨ç”»ä¿¡æ¯ä»æ•°æ®ä¸­éšå¼å­¦ä¹ ï¼Œæ— éœ€ä¾èµ–é¢„å®šä¹‰çš„å‚æ•°æ¨¡å‹ã€‚ä¸ºäº†èåˆ3Dç»“æ„å’ŒåŠ¨ç”»ä¿¡æ¯ï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸€ç§è½»é‡çº§çš„å±€éƒ¨èåˆç­–ç•¥ï¼Œé¿å…äº†è®¡ç®—é‡å¤§çš„å…¨å±€èåˆæœºåˆ¶ã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥æ–¹æ³•çš„å…³é”®åˆ›æ–°åœ¨äºä½¿ç”¨3Dæ„ŸçŸ¥è¡¨è¾¾è’¸é¦ï¼Œå°†2Dæ‰©æ•£æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›è¿ç§»åˆ°3Dè¡¨ç¤ºä¸­ï¼Œä»è€Œåœ¨ä¿è¯3Dä¸€è‡´æ€§å’Œé€Ÿåº¦çš„åŒæ—¶ï¼Œå®ç°äº†é«˜è´¨é‡çš„åŠ¨ç”»æ•ˆæœã€‚æ­¤å¤–ï¼Œè½»é‡çº§çš„å±€éƒ¨èåˆç­–ç•¥ä¹Ÿæ˜¯ä¸€ä¸ªé‡è¦çš„åˆ›æ–°ç‚¹ï¼Œå®ƒåœ¨ä¿è¯è¡¨è¾¾èƒ½åŠ›çš„åŒæ—¶ï¼Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šè¯¥æ–¹æ³•çš„ä¸€ä¸ªå…³é”®è®¾è®¡æ˜¯åŠ¨ç”»è¡¨ç¤ºä¸3Däººè„¸ç»“æ„çš„è§£è€¦ã€‚è¿™ç§è§£è€¦ä½¿å¾—åŠ¨ç”»ä¿¡æ¯å¯ä»¥ç‹¬ç«‹äº3Dç»“æ„è¿›è¡Œå­¦ä¹ å’Œæ§åˆ¶ï¼Œä»è€Œæé«˜äº†åŠ¨ç”»çš„çµæ´»æ€§å’Œå¯æ§æ€§ã€‚æ­¤å¤–ï¼ŒæŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦å¹³è¡¡3Dä¸€è‡´æ€§ã€åŠ¨ç”»è´¨é‡å’Œæ¨ç†é€Ÿåº¦ã€‚

## ğŸ–¼ï¸ å…³é”®å›¾ç‰‡

<div class="paper-figures">
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/expressiveness_vs_consistency_colored.png" alt="fig_0" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/pipeline-2.jpg" alt="fig_1" loading="lazy">
</figure>
<figure class="paper-figure">
<img src="https://arxiv.org/html/2512.16893v1/fig/residual_features.jpg" alt="fig_2" loading="lazy">
</figure>
</div>

## ğŸ“Š å®éªŒäº®ç‚¹

è¯¥æ–¹æ³•åœ¨åŠ¨ç”»å’Œå§¿åŠ¿æ§åˆ¶æ–¹é¢è¾¾åˆ°äº†107.31 FPSçš„é€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸å½“çš„åŠ¨ç”»è´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨é€Ÿåº¦å’Œè´¨é‡ä¹‹é—´å–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œè¶…è¶Šäº†é‚£äº›ä¸ºäº†æé«˜è´¨é‡è€Œç‰ºç‰²é€Ÿåº¦æˆ–ä¸ºäº†æé«˜é€Ÿåº¦è€Œé™ä½è´¨é‡çš„æ›¿ä»£æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•åœ¨è¡¨è¾¾èƒ½åŠ›æ–¹é¢ä¹Ÿä¼˜äºç°æœ‰çš„åŸºäº3Dè¡¨ç¤ºçš„æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºæ•°å­—å­ªç”Ÿã€è¿œç¨‹å‘ˆç°ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ã€æ¸¸æˆç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨äºåˆ›å»ºé€¼çœŸçš„è™šæ‹ŸåŒ–èº«ï¼Œå®ç°å®æ—¶çš„äººè„¸åŠ¨ç”»å’Œè¡¨æƒ…æ§åˆ¶ï¼Œä»è€Œæå‡ç”¨æˆ·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­çš„äº¤äº’ä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯è¿˜å¯ä»¥åº”ç”¨äºç”µå½±åˆ¶ä½œã€å¹¿å‘Šç­‰é¢†åŸŸï¼Œç”¨äºç”Ÿæˆé«˜è´¨é‡çš„äººåƒåŠ¨ç”»ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-aware facial animation feedforward methods -- built upon explicit 3D representations, such as neural radiance fields or Gaussian splatting -- ensure 3D consistency and achieve faster inference speed, but come with inferior expression details. In this paper, we aim to combine their strengths by distilling knowledge from a 2D diffusion-based method into a feed-forward encoder, which instantly converts an in-the-wild single image into a 3D-consistent, fast yet expressive animatable representation. Our animation representation is decoupled from the face's 3D representation and learns motion implicitly from data, eliminating the dependency on pre-defined parametric models that often constrain animation capabilities. Unlike previous computationally intensive global fusion mechanisms (e.g., multiple attention layers) for fusing 3D structural and animation information, our design employs an efficient lightweight local fusion strategy to achieve high animation expressivity. As a result, our method runs at 107.31 FPS for animation and pose control while achieving comparable animation quality to the state-of-the-art, surpassing alternative designs that trade speed for quality or vice versa. Project website is https://research.nvidia.com/labs/amri/projects/instant4d

