---
layout: default
title: Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images
---

# Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03643" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03643v3</a>
  <a href="https://arxiv.org/pdf/2508.03643.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03643v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03643v3', 'Uni3R: Unified 3D Reconstruction and Semantic Understanding via Generalizable Gaussian Splatting from Unposed Multi-View Images')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xiangyu Sun, Haoyi Jiang, Liu Liu, Seungtae Nam, Gyeongjin Kang, Xinjie Wang, Wei Sui, Zhizhong Su, Wenyu Liu, Xinggang Wang, Eunbyung Park

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-08-11)

**å¤‡æ³¨**: The code is available at https://github.com/HorizonRobotics/Uni3R

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/HorizonRobotics/Uni3R)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUni3Rä»¥è§£å†³æ— å§¿æ€å¤šè§†å›¾å›¾åƒçš„3Dé‡å»ºä¸è¯­ä¹‰ç†è§£é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `3Dé‡å»º` `è¯­ä¹‰ç†è§£` `å¤šè§†å›¾å›¾åƒ` `é«˜æ–¯åŸè¯­` `è·¨è§†å›¾å˜æ¢å™¨` `å¼€æ”¾è¯æ±‡` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•é€šå¸¸å°†3Dé‡å»ºä¸è¯­ä¹‰ç†è§£åˆ†å¼€ï¼Œå¯¼è‡´å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ä¸è¶³ã€‚
2. Uni3Ré€šè¿‡è·¨è§†å›¾å˜æ¢å™¨æ•´åˆå¤šè§†å›¾ä¿¡æ¯ï¼Œè”åˆé‡å»º3Dåœºæ™¯å¹¶è¿›è¡Œè¯­ä¹‰ç†è§£ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼ŒUni3Råœ¨RE10Kå’ŒScanNetç­‰åŸºå‡†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä»ç¨€ç–çš„2Dè§†å›¾é‡å»ºå’Œè¯­ä¹‰è§£é‡Š3Dåœºæ™¯ä»ç„¶æ˜¯è®¡ç®—æœºè§†è§‰ä¸­çš„ä¸€ä¸ªåŸºæœ¬æŒ‘æˆ˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å°†è¯­ä¹‰ç†è§£ä¸é‡å»ºåˆ†ç¦»ï¼Œæˆ–éœ€è¦æ˜‚è´µçš„é€åœºæ™¯ä¼˜åŒ–ï¼Œä»è€Œé™åˆ¶äº†å®ƒä»¬çš„å¯æ‰©å±•æ€§å’Œé€šç”¨æ€§ã€‚æœ¬æ–‡æå‡ºäº†Uni3Rï¼Œä¸€ç§æ–°é¢–çš„å‰é¦ˆæ¡†æ¶ï¼Œèƒ½å¤Ÿä»æ— å§¿æ€çš„å¤šè§†å›¾å›¾åƒä¸­è”åˆé‡å»ºç»Ÿä¸€çš„3Dåœºæ™¯è¡¨ç¤ºï¼Œå¹¶ä¸°å¯Œå¼€æ”¾è¯æ±‡è¯­ä¹‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨è·¨è§†å›¾å˜æ¢å™¨æœ‰æ•ˆæ•´åˆä»»æ„å¤šè§†å›¾è¾“å…¥çš„ä¿¡æ¯ï¼Œå›å½’ä¸€ç»„å¸¦æœ‰è¯­ä¹‰ç‰¹å¾åœºçš„3Dé«˜æ–¯åŸè¯­ã€‚è¿™ç§ç»Ÿä¸€è¡¨ç¤ºä¿ƒè¿›äº†é«˜ä¿çœŸæ–°è§†å›¾åˆæˆã€å¼€æ”¾è¯æ±‡3Dè¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ï¼Œæ‰€æœ‰è¿™äº›éƒ½åœ¨å•ä¸ªå‰é¦ˆè¿‡ç¨‹ä¸­å®Œæˆã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒUni3Råœ¨å¤šä¸ªåŸºå‡†ä¸Šå»ºç«‹äº†æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼ŒåŒ…æ‹¬RE10Kä¸Šçš„25.07 PSNRå’ŒScanNetä¸Šçš„55.84 mIoUã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³ä»æ— å§¿æ€å¤šè§†å›¾å›¾åƒä¸­é‡å»º3Dåœºæ™¯åŠå…¶è¯­ä¹‰ç†è§£çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•å¾€å¾€å°†é‡å»ºä¸è¯­ä¹‰ç†è§£åˆ†å¼€ï¼Œå¯¼è‡´æ•ˆç‡ä½ä¸‹å’Œå¯æ‰©å±•æ€§ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šUni3Rçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡ä¸€ä¸ªå‰é¦ˆæ¡†æ¶ï¼Œåˆ©ç”¨è·¨è§†å›¾å˜æ¢å™¨æœ‰æ•ˆæ•´åˆå¤šè§†å›¾ä¿¡æ¯ï¼Œç›´æ¥å›å½’å¸¦æœ‰è¯­ä¹‰ç‰¹å¾çš„3Dé«˜æ–¯åŸè¯­ï¼Œä»è€Œå®ç°3Dé‡å»ºä¸è¯­ä¹‰ç†è§£çš„ç»Ÿä¸€ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šUni3Rçš„æ•´ä½“æ¶æ„åŒ…æ‹¬å¤šä¸ªæ¨¡å—ï¼šé¦–å…ˆï¼Œè·¨è§†å›¾å˜æ¢å™¨æ¥æ”¶å¤šè§†å›¾è¾“å…¥ï¼Œæ•´åˆä¿¡æ¯ï¼›ç„¶åï¼Œé€šè¿‡å›å½’ç½‘ç»œç”Ÿæˆ3Dé«˜æ–¯åŸè¯­ï¼›æœ€åï¼Œåˆ©ç”¨ç”Ÿæˆçš„ç»Ÿä¸€è¡¨ç¤ºè¿›è¡Œæ–°è§†å›¾åˆæˆã€è¯­ä¹‰åˆ†å‰²å’Œæ·±åº¦é¢„æµ‹ã€‚

**å…³é”®åˆ›æ–°**ï¼šUni3Rçš„ä¸»è¦åˆ›æ–°åœ¨äºå…¶å°†3Dé‡å»ºä¸å¼€æ”¾è¯æ±‡è¯­ä¹‰ç†è§£ç»“åˆåœ¨ä¸€ä¸ªå‰é¦ˆæ¡†æ¶ä¸­ï¼Œå…‹æœäº†ä¼ ç»Ÿæ–¹æ³•çš„å±€é™æ€§ï¼Œå®ç°äº†æ›´é«˜çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒUni3Ré‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–è¯­ä¹‰ç‰¹å¾çš„å­¦ä¹ ï¼Œå¹¶ä½¿ç”¨äº†é«˜æ•ˆçš„ç½‘ç»œç»“æ„æ¥å¤„ç†å¤šè§†å›¾è¾“å…¥ï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

Uni3Råœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼ŒRE10Kä¸Šè¾¾åˆ°25.07 PSNRï¼ŒScanNetä¸Šè¾¾åˆ°55.84 mIoUï¼Œå‡åˆ›ä¸‹æ–°çš„æœ€å…ˆè¿›æ°´å¹³ï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨3Dé‡å»ºå’Œè¯­ä¹‰ç†è§£é¢†åŸŸçš„æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®ã€å¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œå…¶ä¸­éœ€è¦ä»å¤šè§†è§’å›¾åƒä¸­å¿«é€Ÿé‡å»º3Dç¯å¢ƒå¹¶è¿›è¡Œè¯­ä¹‰åˆ†æã€‚å…¶å®é™…ä»·å€¼åœ¨äºæå‡äº†3Dé‡å»ºçš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Reconstructing and semantically interpreting 3D scenes from sparse 2D views remains a fundamental challenge in computer vision. Conventional methods often decouple semantic understanding from reconstruction or necessitate costly per-scene optimization, thereby restricting their scalability and generalizability. In this paper, we introduce Uni3R, a novel feed-forward framework that jointly reconstructs a unified 3D scene representation enriched with open-vocabulary semantics, directly from unposed multi-view images. Our approach leverages a Cross-View Transformer to robustly integrate information across arbitrary multi-view inputs, which then regresses a set of 3D Gaussian primitives endowed with semantic feature fields. This unified representation facilitates high-fidelity novel view synthesis, open-vocabulary 3D semantic segmentation, and depth prediction, all within a single, feed-forward pass. Extensive experiments demonstrate that Uni3R establishes a new state-of-the-art across multiple benchmarks, including 25.07 PSNR on RE10K and 55.84 mIoU on ScanNet. Our work signifies a novel paradigm towards generalizable, unified 3D scene reconstruction and understanding. The code is available at https://github.com/HorizonRobotics/Uni3R.

