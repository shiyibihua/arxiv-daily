---
layout: default
title: H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction
---

# H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03118" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03118v1</a>
  <a href="https://arxiv.org/pdf/2508.03118.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03118v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03118v1', 'H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Heng Jia, Linchao Zhu, Na Zhao

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: ICCV 2025

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/JiaHeng-DLUT/H3R)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºH3Ræ¡†æ¶ä»¥è§£å†³å¤šè§†è§’å¯¹åº”å»ºæ¨¡çš„æŒ‘æˆ˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `3Dé‡å»º` `å¤šè§†è§’å¯¹åº”` `å‡ ä½•ä¸€è‡´æ€§` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰` `Transformer` `ç‰¹å¾èšåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„3Dé‡å»ºæ–¹æ³•åœ¨å¤šè§†è§’å¯¹åº”å»ºæ¨¡ä¸­é¢ä¸´å‡ ä½•ç²¾åº¦ä¸é²æ£’æ€§ä¹‹é—´çš„æƒè¡¡ï¼Œå¯¼è‡´åœ¨å¤æ‚åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ã€‚
2. H3Ræ¡†æ¶é€šè¿‡ç»“åˆä½“ç§¯æ½œåœ¨èåˆä¸æ³¨æ„åŠ›ç‰¹å¾èšåˆï¼Œæå‡äº†å‡ ä½•ä¸€è‡´æ€§å’Œè‡ªé€‚åº”å¯¹åº”ä¼˜åŒ–çš„èƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šï¼ŒH3Ræ–¹æ³•å®ç°äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒPSNRåˆ†åˆ«æé«˜äº†0.59 dBã€1.06 dBå’Œ0.22 dBï¼Œå±•ç¤ºäº†å…¶ä¼˜è¶Šæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡å‰é¦ˆ3Dé«˜æ–¯ç‚¹äº‘æŠ€æœ¯å–å¾—äº†è¿›å±•ï¼Œä½†é€šç”¨3Dé‡å»ºä»ç„¶é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨å¤šè§†è§’å¯¹åº”å»ºæ¨¡æ–¹é¢ã€‚ç°æœ‰æ–¹æ³•å­˜åœ¨æ ¹æœ¬æ€§æƒè¡¡ï¼šæ˜¾å¼æ–¹æ³•åœ¨å‡ ä½•ç²¾åº¦ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†åœ¨æ¨¡ç³ŠåŒºåŸŸä¸­è¡¨ç°ä¸ä½³ï¼›éšå¼æ–¹æ³•åˆ™æä¾›äº†é²æ£’æ€§ï¼Œä½†æ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ã€‚æœ¬æ–‡æå‡ºçš„H3Ræ¡†æ¶é€šè¿‡æ•´åˆä½“ç§¯æ½œåœ¨èåˆä¸åŸºäºæ³¨æ„åŠ›çš„ç‰¹å¾èšåˆï¼Œè§£å†³äº†è¿™ä¸€é™åˆ¶ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªäº’è¡¥ç»„ä»¶ç»„æˆï¼šä¸€ä¸ªé«˜æ•ˆçš„æ½œåœ¨ä½“ç§¯ï¼Œé€šè¿‡æçº¿çº¦æŸå¼ºåˆ¶å‡ ä½•ä¸€è‡´æ€§ï¼›ä¸€ä¸ªæ‘„åƒæœºæ„ŸçŸ¥çš„Transformerï¼Œåˆ©ç”¨PlÃ¼ckeråæ ‡è¿›è¡Œè‡ªé€‚åº”å¯¹åº”ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ŒPSNRåˆ†åˆ«æå‡0.59 dBã€1.06 dBå’Œ0.22 dBã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³é€šç”¨3Dé‡å»ºä¸­çš„å¤šè§†è§’å¯¹åº”å»ºæ¨¡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨å‡ ä½•ç²¾åº¦å’Œé²æ£’æ€§ä¹‹é—´å­˜åœ¨æƒè¡¡ï¼Œå¯¼è‡´åœ¨å¤æ‚åœºæ™¯ä¸­çš„è¡¨ç°ä¸ç†æƒ³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šH3Ræ¡†æ¶çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ•´åˆæ˜¾å¼çš„å‡ ä½•çº¦æŸä¸éšå¼çš„ç‰¹å¾èšåˆï¼Œæ¥æé«˜é‡å»ºçš„å‡†ç¡®æ€§å’Œæ”¶æ•›é€Ÿåº¦ã€‚é€šè¿‡è¿™ç§è®¾è®¡ï¼Œæ¡†æ¶èƒ½å¤Ÿåœ¨ä¿æŒå‡ ä½•ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œå¢å¼ºå¯¹æ¨¡ç³ŠåŒºåŸŸçš„å¤„ç†èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šH3Ræ¡†æ¶ä¸»è¦ç”±ä¸¤ä¸ªæ¨¡å—ç»„æˆï¼šä¸€ä¸ªé«˜æ•ˆçš„æ½œåœ¨ä½“ç§¯æ¨¡å—ï¼Œåˆ©ç”¨æçº¿çº¦æŸæ¥ç¡®ä¿å‡ ä½•ä¸€è‡´æ€§ï¼›å¦ä¸€ä¸ªæ˜¯æ‘„åƒæœºæ„ŸçŸ¥çš„Transformeræ¨¡å—ï¼Œåˆ©ç”¨PlÃ¼ckeråæ ‡è¿›è¡Œè‡ªé€‚åº”çš„å¯¹åº”ä¼˜åŒ–ã€‚æ•´ä½“æµç¨‹åŒ…æ‹¬è¾“å…¥å¤šè§†è§’å›¾åƒï¼Œç»è¿‡æ½œåœ¨ä½“ç§¯å’ŒTransformeræ¨¡å—å¤„ç†åè¾“å‡ºé‡å»ºç»“æœã€‚

**å…³é”®åˆ›æ–°**ï¼šH3Rçš„ä¸»è¦åˆ›æ–°åœ¨äºå°†ä½“ç§¯æ½œåœ¨èåˆä¸æ³¨æ„åŠ›æœºåˆ¶ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„å¤šè§†è§’å¯¹åº”å»ºæ¨¡æ–¹æ³•ã€‚è¿™ç§æ–¹æ³•åœ¨å¤„ç†æ¨¡ç³ŠåŒºåŸŸæ—¶è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æé«˜äº†é‡å»ºçš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼ŒH3Rä½¿ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°æ¥å¹³è¡¡å‡ ä½•ä¸€è‡´æ€§ä¸ç‰¹å¾èšåˆçš„æ•ˆæœï¼ŒåŒæ—¶åœ¨Transformeræ¨¡å—ä¸­å¼•å…¥äº†PlÃ¼ckeråæ ‡ï¼Œä»¥å¢å¼ºå¯¹åº”ä¼˜åŒ–çš„çµæ´»æ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

H3Ræ–¹æ³•åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨RealEstate10Kã€ACIDå’ŒDTUæ•°æ®é›†ä¸Šï¼ŒPSNRåˆ†åˆ«æå‡äº†0.59 dBã€1.06 dBå’Œ0.22 dBï¼Œå±•ç°äº†å…¶åœ¨3Dé‡å»ºé¢†åŸŸçš„é¢†å…ˆåœ°ä½ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒH3Rçš„æ”¶æ•›é€Ÿåº¦æé«˜äº†2å€ï¼Œè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

H3Ræ¡†æ¶åœ¨è®¡ç®—æœºè§†è§‰å’Œæœºå™¨äººé¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ï¼Œå°¤å…¶æ˜¯åœ¨è‡ªåŠ¨é©¾é©¶ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ä¸­ã€‚å…¶é«˜æ•ˆçš„3Dé‡å»ºèƒ½åŠ›èƒ½å¤Ÿä¸ºè¿™äº›é¢†åŸŸæä¾›æ›´ä¸ºç²¾å‡†çš„ç¯å¢ƒç†è§£å’Œäº¤äº’ä½“éªŒï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„è¿›æ­¥ä¸å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Despite recent advances in feed-forward 3D Gaussian Splatting, generalizable 3D reconstruction remains challenging, particularly in multi-view correspondence modeling. Existing approaches face a fundamental trade-off: explicit methods achieve geometric precision but struggle with ambiguous regions, while implicit methods provide robustness but suffer from slow convergence. We present H3R, a hybrid framework that addresses this limitation by integrating volumetric latent fusion with attention-based feature aggregation. Our framework consists of two complementary components: an efficient latent volume that enforces geometric consistency through epipolar constraints, and a camera-aware Transformer that leverages PlÃ¼cker coordinates for adaptive correspondence refinement. By integrating both paradigms, our approach enhances generalization while converging 2$\times$ faster than existing methods. Furthermore, we show that spatial-aligned foundation models (e.g., SD-VAE) substantially outperform semantic-aligned models (e.g., DINOv2), resolving the mismatch between semantic representations and spatial reconstruction requirements. Our method supports variable-number and high-resolution input views while demonstrating robust cross-dataset generalization. Extensive experiments show that our method achieves state-of-the-art performance across multiple benchmarks, with significant PSNR improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and DTU datasets, respectively. Code is available at https://github.com/JiaHeng-DLUT/H3R.

