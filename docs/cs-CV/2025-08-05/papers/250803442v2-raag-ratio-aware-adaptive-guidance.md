---
layout: default
title: RAAG: Ratio Aware Adaptive Guidance
---

# RAAG: Ratio Aware Adaptive Guidance

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03442" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03442v2</a>
  <a href="https://arxiv.org/pdf/2508.03442.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03442v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03442v2', 'RAAG: Ratio Aware Adaptive Guidance')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shangwen Zhu, Qianyu Peng, Yuting Hu, Zhantao Yang, Han Zhang, Zhao Pu, Andy Zheng, Zhilei Shu, Ruili Feng, Fan Cheng

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-09-26)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”å¼•å¯¼æ–¹æ³•ä»¥è§£å†³æµå¼ç”Ÿæˆæ¨¡å‹é‡‡æ ·ä¸ç¨³å®šé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±å››ï¼šç”Ÿæˆå¼åŠ¨ä½œ (Generative Motion)**

**å…³é”®è¯**: `æµå¼ç”Ÿæˆæ¨¡å‹` `è‡ªé€‚åº”å¼•å¯¼` `é‡‡æ ·ç¨³å®šæ€§` `å›¾åƒç”Ÿæˆ` `è§†é¢‘ç”Ÿæˆ` `åˆ†ç±»å™¨æ— å…³å¼•å¯¼` `ç”Ÿæˆè´¨é‡æå‡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨å›ºå®šçš„å¼•å¯¼å°ºåº¦ï¼Œå¯¼è‡´æ—©æœŸé‡‡æ ·ä¸ç¨³å®šï¼Œå½±å“ç”Ÿæˆè´¨é‡ã€‚
2. æå‡ºäº†ä¸€ç§è‡ªé€‚åº”å¼•å¯¼è°ƒåº¦ï¼Œæ ¹æ®æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹çš„æ¯”ç‡åŠ¨æ€è°ƒæ•´å¼•å¯¼å°ºåº¦ï¼Œä»¥å‡å°‘æ—©æœŸæ­¥éª¤çš„æ•æ„Ÿæ€§ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªå›¾åƒå’Œè§†é¢‘æ¨¡å‹ä¸Šå®ç°äº†æœ€é«˜3å€çš„é‡‡æ ·é€Ÿåº¦æå‡ï¼ŒåŒæ—¶ä¿æŒæˆ–æ”¹å–„äº†ç”Ÿæˆè´¨é‡å’Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

åŸºäºæµçš„ç”Ÿæˆæ¨¡å‹å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œåˆ†ç±»å™¨æ— å…³å¼•å¯¼ï¼ˆCFGï¼‰å·²æˆä¸ºé«˜ä¿çœŸç”Ÿæˆçš„æ ‡å‡†ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿæ–¹æ³•åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨å›ºå®šçš„å¼ºå¼•å¯¼å°ºåº¦ï¼Œéš¾ä»¥é€‚åº”ç°ä»£åº”ç”¨æ‰€éœ€çš„å¿«é€Ÿã€å°‘æ­¥é‡‡æ ·ã€‚æœ¬æ–‡æ­ç¤ºäº†è¿™ä¸€å†²çªçš„æ ¹æœ¬åŸå› ï¼šæ—©æœŸæ­¥éª¤å¯¹å¼•å¯¼çš„æ•æ„Ÿæ€§å¯¼è‡´çš„é‡‡æ ·ä¸ç¨³å®šæ€§ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•ä¸”ç†è®ºåŸºç¡€æ‰å®çš„è‡ªé€‚åº”å¼•å¯¼è°ƒåº¦ï¼Œèƒ½å¤Ÿæ ¹æ®æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹çš„æ¯”ç‡åŠ¨æ€è°ƒæ•´å¼•å¯¼å°ºåº¦ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæˆ–æå‡å›¾åƒè´¨é‡çš„åŒæ—¶ï¼Œå®ç°äº†æœ€é«˜3å€çš„é‡‡æ ·é€Ÿåº¦æå‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡è¦è§£å†³çš„é—®é¢˜æ˜¯æµå¼ç”Ÿæˆæ¨¡å‹åœ¨æ¨ç†é˜¶æ®µä½¿ç”¨å›ºå®šå¼•å¯¼å°ºåº¦å¯¼è‡´çš„æ—©æœŸé‡‡æ ·ä¸ç¨³å®šæ€§ï¼Œè¿›è€Œå½±å“ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚ç°æœ‰æ–¹æ³•åœ¨å¿«é€Ÿé‡‡æ ·æ—¶æœªèƒ½é€‚åº”æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹æ¯”ç‡çš„å˜åŒ–ï¼Œå¯¼è‡´é”™è¯¯çš„æŒ‡æ•°æ”¾å¤§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒè§£å†³æ€è·¯æ˜¯æå‡ºä¸€ç§è‡ªé€‚åº”å¼•å¯¼è°ƒåº¦æœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹çš„æ¯”ç‡åŠ¨æ€è°ƒæ•´å¼•å¯¼å°ºåº¦ã€‚é€šè¿‡åœ¨æ—©æœŸæ­¥éª¤é™ä½å¼•å¯¼å¼ºåº¦ï¼Œå‡å°‘å¯¹é‡‡æ ·è¿‡ç¨‹çš„æ•æ„Ÿæ€§ï¼Œä»è€Œæé«˜ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒå’Œæ¨ç†é˜¶æ®µã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œé‡‡ç”¨è‡ªé€‚åº”å¼•å¯¼è°ƒåº¦ï¼Œæ ¹æ®å®æ—¶è®¡ç®—çš„æ¡ä»¶ä¸æ— æ¡ä»¶é¢„æµ‹æ¯”ç‡è°ƒæ•´å¼•å¯¼å°ºåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºæå‡ºäº†è‡ªé€‚åº”å¼•å¯¼è°ƒåº¦æœºåˆ¶ï¼ŒåŒºåˆ«äºä¼ ç»Ÿæ–¹æ³•çš„å›ºå®šå¼•å¯¼å°ºåº¦ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ—©æœŸé‡‡æ ·çš„ä¸ç¨³å®šæ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œå…³é”®å‚æ•°åŒ…æ‹¬å¼•å¯¼å°ºåº¦çš„åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ŒæŸå¤±å‡½æ•°çš„é€‰æ‹©ï¼Œä»¥åŠä¸ç°æœ‰ç”Ÿæˆæ¨¡å‹çš„å…¼å®¹æ€§è®¾è®¡ï¼Œç¡®ä¿æ–¹æ³•çš„è½»é‡åŒ–å’Œæ— æ¨ç†å¼€é”€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæå‡ºçš„æ–¹æ³•åœ¨å¤šä¸ªæœ€å…ˆè¿›çš„å›¾åƒï¼ˆSD3.5ã€Qwen-Imageï¼‰å’Œè§†é¢‘ï¼ˆWAN2.1ï¼‰æ¨¡å‹ä¸Šå®ç°äº†æœ€é«˜3å€çš„é‡‡æ ·é€Ÿåº¦æå‡ï¼ŒåŒæ—¶åœ¨è´¨é‡ã€é²æ£’æ€§å’Œè¯­ä¹‰ä¸€è‡´æ€§æ–¹é¢ä¿æŒæˆ–æ”¹å–„äº†æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºæ˜¾è‘—çš„ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒç”Ÿæˆã€è§†é¢‘ç”Ÿæˆå’Œå…¶ä»–åŸºäºæµçš„ç”Ÿæˆä»»åŠ¡ã€‚é€šè¿‡æé«˜ç”Ÿæˆé€Ÿåº¦å’Œè´¨é‡ï¼Œè¯¥æ–¹æ³•å¯å¹¿æ³›åº”ç”¨äºå®æ—¶å›¾åƒå¤„ç†ã€è™šæ‹Ÿç°å®å’Œå¢å¼ºç°å®ç­‰åœºæ™¯ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Flow-based generative models have achieved remarkable progress, with classifier-free guidance (CFG) becoming the standard for high-fidelity generation. However, the conventional practice of applying a strong, fixed guidance scale throughout inference is poorly suited for the rapid, few-step sampling required by modern applications. In this work, we uncover the root cause of this conflict: a fundamental sampling instability where the earliest steps are acutely sensitive to guidance. We trace this to a significant spike in the ratio of conditional to unconditional predictions--a spike that we prove to be an inherent property of the training data distribution itself, making it a almost inevitable challenge. Applying a high, static guidance value during this volatile initial phase leads to an exponential amplification of error, degrading image quality. To resolve this, we propose a simple, theoretically grounded, adaptive guidance schedule that automatically dampens the guidance scale at early steps based on the evolving ratio. Our method is lightweight, incurs no inference overhead, and is compatible with standard frameworks. Experiments across state-of-the-art image (SD3.5, Qwen-Image) and video (WAN2.1) models show our approach enables up to 3x faster sampling while maintaining or improving quality, robustness, and semantic alignment. Our findings highlight that adapting guidance to the sampling process, rather than fixing it, is critical for unlocking the full potential of fast, flow-based models.

