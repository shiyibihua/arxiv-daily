---
layout: default
title: V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models
---

# V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03254" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03254v1</a>
  <a href="https://arxiv.org/pdf/2508.03254.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03254v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03254v1', 'V.I.P. : Iterative Online Preference Distillation for Efficient Video Diffusion Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jisoo Kim, Wooseok Seo, Junwan Kim, Seungho Park, Sooyeon Park, Youngjae Yu

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: ICCV2025 accepted

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](https://jiiiisoo.github.io/VIP.github.io/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºV.I.P.æ¡†æ¶ä»¥è§£å†³è§†é¢‘æ‰©æ•£æ¨¡å‹çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `è§†é¢‘ç”Ÿæˆ` `æ–‡æœ¬åˆ°è§†é¢‘` `è’¸é¦è®­ç»ƒ` `æ¨¡å‹å‰ªæ` `å¤šæ¨¡æ€å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è’¸é¦æ–¹æ³•ä¾èµ–äºç›‘ç£å¾®è°ƒï¼Œå¯¼è‡´å‰ªææ¨¡å‹æ— æ³•æœ‰æ•ˆåŒ¹é…æ•™å¸ˆæ¨¡å‹è¾“å‡ºï¼Œé€ æˆè´¨é‡ä¸‹é™ã€‚
2. æå‡ºçš„ReDPOæ–¹æ³•ç»“åˆDPOå’ŒSFTï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹ä¸“æ³¨äºæ¢å¤ç›®æ ‡å±æ€§ï¼Œæå‡æ•´ä½“æ€§èƒ½ã€‚
3. åœ¨VideoCrafter2å’ŒAnimateDiffæ¨¡å‹ä¸ŠéªŒè¯ï¼Œåˆ†åˆ«å®ç°36.2%å’Œ67.5%çš„å‚æ•°å‡å°‘ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¶Šæ€§èƒ½ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

éšç€åœ¨èµ„æºå—é™ç¯å¢ƒä¸­éƒ¨ç½²æ–‡æœ¬åˆ°è§†é¢‘ï¼ˆT2Vï¼‰æ¨¡å‹çš„å…´è¶£æ—¥ç›Šå¢é•¿ï¼Œé™ä½å…¶é«˜è®¡ç®—æˆæœ¬å˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰çš„è’¸é¦æ–¹æ³•ä¸»è¦ä¾èµ–äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œè¿™å¾€å¾€å¯¼è‡´æ¨¡å¼å´©æºƒï¼Œå› ä¸ºç»è¿‡å‰ªæçš„æ¨¡å‹æ— æ³•ç›´æ¥åŒ¹é…æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºï¼Œä»è€Œå¯¼è‡´è´¨é‡ä¸‹é™ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„è’¸é¦æ–¹æ³•ReDPOï¼Œç»“åˆäº†DPOå’ŒSFTï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹ä¸“æ³¨äºæ¢å¤ç›®æ ‡å±æ€§ï¼ŒåŒæ—¶åˆ©ç”¨SFTæå‡æ•´ä½“æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæå‡ºäº†V.I.P.æ¡†æ¶ï¼Œç”¨äºè¿‡æ»¤å’Œç­–åˆ’é«˜è´¨é‡é…å¯¹æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨é€æ­¥åœ¨çº¿æ ¡å‡†è®­ç»ƒçš„æ–¹æ³•ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªé¢†å…ˆçš„T2Væ¨¡å‹ä¸ŠéªŒè¯äº†è¯¥æ–¹æ³•ï¼Œåˆ†åˆ«å®ç°äº†36.2%å’Œ67.5%çš„å‚æ•°å‡å°‘ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¶Šäº†å®Œæ•´æ¨¡å‹çš„æ€§èƒ½ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸­çš„é«˜è®¡ç®—æˆæœ¬é—®é¢˜ã€‚ç°æœ‰çš„è’¸é¦æ–¹æ³•ä¸»è¦ä¾èµ–äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œè¿™å¯¼è‡´å‰ªææ¨¡å‹æ— æ³•æœ‰æ•ˆåŒ¹é…æ•™å¸ˆæ¨¡å‹çš„è¾“å‡ºï¼Œæœ€ç»ˆå½±å“ç”Ÿæˆè´¨é‡ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºçš„ReDPOæ–¹æ³•é€šè¿‡ç»“åˆDPOå’ŒSFTï¼ŒæŒ‡å¯¼å­¦ç”Ÿæ¨¡å‹ä¸“æ³¨äºæ¢å¤ç‰¹å®šçš„ç›®æ ‡å±æ€§ï¼Œè€Œä¸æ˜¯è¢«åŠ¨æ¨¡ä»¿æ•™å¸ˆæ¨¡å‹ï¼Œä»è€Œé¿å…æ¨¡å¼å´©æºƒã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šV.I.P.æ¡†æ¶åŒ…æ‹¬é«˜è´¨é‡é…å¯¹æ•°æ®é›†çš„è¿‡æ»¤å’Œç­–åˆ’ï¼Œä»¥åŠé€æ­¥åœ¨çº¿æ ¡å‡†è®­ç»ƒçš„è¿‡ç¨‹ã€‚æ•´ä½“æµç¨‹åˆ†ä¸ºæ•°æ®å‡†å¤‡ã€æ¨¡å‹è®­ç»ƒå’Œæ€§èƒ½è¯„ä¼°ä¸‰ä¸ªä¸»è¦é˜¶æ®µã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºå°†DPOä¸SFTç›¸ç»“åˆï¼Œå½¢æˆäº†ä¸€ç§æ–°çš„è’¸é¦ç­–ç•¥ï¼Œä½¿å¾—å­¦ç”Ÿæ¨¡å‹èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å­¦ä¹ ç›®æ ‡å±æ€§ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ä¸­çš„æ¨¡å¼å´©æºƒé—®é¢˜ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨å‚æ•°è®¾ç½®ä¸Šï¼Œé‡‡ç”¨äº†é€‚åº”æ€§å­¦ä¹ ç‡å’Œç‰¹å®šçš„æŸå¤±å‡½æ•°ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œæ”¶æ•›æ€§ã€‚æ­¤å¤–ï¼Œç½‘ç»œç»“æ„ç»è¿‡ä¼˜åŒ–ï¼Œä»¥é€‚åº”è’¸é¦è¿‡ç¨‹ä¸­çš„ç‰¹å®šéœ€æ±‚ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œä½¿ç”¨V.I.P.æ¡†æ¶åœ¨VideoCrafter2å’ŒAnimateDiffæ¨¡å‹ä¸Šåˆ†åˆ«å®ç°äº†36.2%å’Œ67.5%çš„å‚æ•°å‡å°‘ï¼ŒåŒæ—¶ä¿æŒæˆ–è¶…è¶Šäº†å®Œæ•´æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å½±è§†åˆ¶ä½œã€æ¸¸æˆå¼€å‘å’Œæ•™è‚²ç­‰å¤šä¸ªé¢†åŸŸï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å®ç°é«˜æ•ˆçš„è§†é¢‘ç”Ÿæˆï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼ã€‚æœªæ¥ï¼Œéšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥å‘å±•ï¼Œå¯èƒ½ä¼šæ¨åŠ¨æ›´å¤šåˆ›æ–°çš„å¤šåª’ä½“åº”ç”¨å’ŒæœåŠ¡ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> With growing interest in deploying text-to-video (T2V) models in resource-constrained environments, reducing their high computational cost has become crucial, leading to extensive research on pruning and knowledge distillation methods while maintaining performance. However, existing distillation methods primarily rely on supervised fine-tuning (SFT), which often leads to mode collapse as pruned models with reduced capacity fail to directly match the teacher's outputs, ultimately resulting in degraded quality. To address this challenge, we propose an effective distillation method, ReDPO, that integrates DPO and SFT. Our approach leverages DPO to guide the student model to focus on recovering only the targeted properties, rather than passively imitating the teacher, while also utilizing SFT to enhance overall performance. We additionally propose V.I.P., a novel framework for filtering and curating high-quality pair datasets, along with a step-by-step online approach for calibrated training. We validate our method on two leading T2V models, VideoCrafter2 and AnimateDiff, achieving parameter reduction of 36.2% and 67.5% each, while maintaining or even surpassing the performance of full models. Further experiments demonstrate the effectiveness of both ReDPO and V.I.P. framework in enabling efficient and high-quality video generation. Our code and videos are available at https://jiiiisoo.github.io/VIP.github.io/.

