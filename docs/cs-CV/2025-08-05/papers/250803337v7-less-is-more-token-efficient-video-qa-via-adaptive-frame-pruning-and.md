---
layout: default
title: Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration
---

# Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03337" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03337v7</a>
  <a href="https://arxiv.org/pdf/2508.03337.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03337v7" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03337v7', 'Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shaoguang Wang, Weiyu Guo, Ziyang Chen, Yijie Xu, Xuming Hu, Hui Xiong

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05 (æ›´æ–°: 2025-11-23)

**å¤‡æ³¨**: This manuscript is a preprint. 22 pages, 19 figures

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºè‡ªé€‚åº”å¸§å‰ªæä¸è¯­ä¹‰å›¾é›†æˆä»¥è§£å†³è§†é¢‘é—®ç­”ä¸­çš„å†—ä½™é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†é¢‘é—®ç­”` `è‡ªé€‚åº”å¸§å‰ªæ` `è¯­ä¹‰å›¾` `å¤šæ¨¡æ€å­¦ä¹ ` `é«˜æ•ˆå¤„ç†` `è§†è§‰å›å£°` `ä¸Šä¸‹æ–‡å®Œæ•´æ€§`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„è§†é¢‘é—®ç­”æ–¹æ³•åœ¨å¤„ç†å¤§é‡è§†é¢‘å¸§æ—¶é¢ä¸´é«˜ä»¤ç‰Œæˆæœ¬å’Œæ—¶é—´å†—ä½™çš„é—®é¢˜ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚
2. æœ¬æ–‡æå‡ºçš„è‡ªé€‚åº”å¸§å‰ªæï¼ˆAFPï¼‰æ–¹æ³•é€šè¿‡æ™ºèƒ½èšç±»å¸§æ¥å‰ªé™¤è§†è§‰å›å£°ï¼Œå¹¶ç»“åˆè¯­ä¹‰å›¾è¿›è¡Œä½æˆæœ¬è¡¥å¿ã€‚
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œæœ¬æ–‡çš„æ–¹æ³•å‡å°‘äº†é«˜è¾¾80%çš„è¾“å…¥ä»¤ç‰Œï¼ŒåŒæ—¶æå‡äº†é€‰æ‹©å™¨çš„å‡†ç¡®æ€§ï¼Œè¡¨ç°ä¼˜äºä½¿ç”¨æ›´å¤šå¸§çš„åŸºçº¿æ–¹æ³•ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§†é¢‘é—®ç­”ä¸­çš„å®é™…åº”ç”¨å—åˆ°å¤„ç†å¤§é‡è§†é¢‘å¸§çš„é«˜ä»¤ç‰Œæˆæœ¬çš„ä¸¥é‡åˆ¶çº¦ã€‚å°½ç®¡å…³é”®å¸§é€‰æ‹©æ˜¯ç¼“è§£è¿™ä¸€é—®é¢˜çš„ä¸»è¦ç­–ç•¥ï¼Œä½†ç°æœ‰çš„é€‰æ‹©å™¨ä»äº§ç”Ÿæ˜¾è‘—çš„æ—¶é—´å†—ä½™ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ç¨€é‡Šï¼Œåè€Œé™ä½æ€§èƒ½ã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç²¾ç‚¼æ¡†æ¶ï¼Œç»“åˆè‡ªé€‚åº”å¸§å‰ªæå’Œè½»é‡çº§æ–‡æœ¬è¯­ä¹‰å›¾ï¼Œæ™ºèƒ½å‰ªé™¤è§†è§‰å›å£°ï¼ŒåŒæ—¶é€šè¿‡è¯­ä¹‰å›¾æä¾›ä½æˆæœ¬çš„è¯­ä¹‰è¡¥å¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨LongVideoBenchå’ŒVideoMMEåŸºå‡†ä¸Šæ˜¾è‘—å‡å°‘äº†è¾“å…¥ä»¤ç‰Œæ•°é‡ï¼Œæå‡äº†é€‰æ‹©å™¨çš„å‡†ç¡®æ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³è§†é¢‘é—®ç­”ä¸­ç”±äºé«˜ä»¤ç‰Œæˆæœ¬å’Œæ—¶é—´å†—ä½™ï¼ˆè§†è§‰å›å£°ï¼‰å¯¼è‡´çš„æ€§èƒ½ä¸‹é™é—®é¢˜ã€‚ç°æœ‰çš„å…³é”®å¸§é€‰æ‹©æ–¹æ³•æ— æ³•æœ‰æ•ˆæ¶ˆé™¤è¿™äº›å†—ä½™ï¼Œå½±å“äº†ä¸Šä¸‹æ–‡çš„å®Œæ•´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæå‡ºè‡ªé€‚åº”å¸§å‰ªæï¼ˆAFPï¼‰ä¸è½»é‡çº§è¯­ä¹‰å›¾çš„ç»“åˆï¼Œé€šè¿‡æ™ºèƒ½èšç±»å¸§æ¥å‡å°‘å†—ä½™ä¿¡æ¯ï¼ŒåŒæ—¶åˆ©ç”¨è¯­ä¹‰å›¾æä¾›å¿…è¦çš„è¯­ä¹‰è¡¥å¿ï¼Œä»è€Œæé«˜æ•ˆç‡å’Œå‡†ç¡®æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šè‡ªé€‚åº”å¸§å‰ªææ¨¡å—è´Ÿè´£åŠ¨æ€é€‰æ‹©å…³é”®å¸§ï¼Œè¯­ä¹‰å›¾æ¨¡å—åˆ™æä¾›è¯­ä¹‰ä¿¡æ¯çš„è¡¥å……ã€‚ä¸¤è€…ååŒå·¥ä½œï¼Œå½¢æˆä¸€ä¸ªé«˜æ•ˆçš„è§†é¢‘é—®ç­”ç³»ç»Ÿã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæå‡ºäº†è§†è§‰å›å£°çš„æ¦‚å¿µï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”å¸§å‰ªææœ‰æ•ˆåœ°è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼Œæ˜¾è‘—æå‡äº†è§†é¢‘é—®ç­”çš„æ€§èƒ½ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨å‡å°‘è¾“å…¥ä»¤ç‰Œçš„åŒæ—¶ä¿æŒäº†ä¿¡æ¯çš„å®Œæ•´æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åŠ¨æ€èšç±»ç®—æ³•è¿›è¡Œå¸§é€‰æ‹©ï¼Œè¯­ä¹‰å›¾åˆ™é€šè¿‡ä½æˆæœ¬çš„æ–‡æœ¬è¡¨ç¤ºæ¥è¡¥å……ä¿¡æ¯ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®å’ŒæŸå¤±å‡½æ•°è®¾è®¡æ—¨åœ¨ä¼˜åŒ–å‰ªææ•ˆæœä¸è¯­ä¹‰è¡¥å¿çš„å¹³è¡¡ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼Œæœ¬æ–‡çš„æ–¹æ³•åœ¨LongVideoBenchå’ŒVideoMMEåŸºå‡†ä¸Šå®ç°äº†é«˜è¾¾80%çš„è¾“å…¥ä»¤ç‰Œå‡å°‘ï¼ŒåŒæ—¶æå‡äº†é€‰æ‹©å™¨çš„å‡†ç¡®æ€§ï¼Œè¡¨ç°å‡ºè‰²ï¼Œè¶…è¶Šäº†ä½¿ç”¨æ›´å¤šå¸§çš„åŸºçº¿æ–¹æ³•ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§å’Œç«äº‰åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨è§†é¢‘é—®ç­”ã€è§†é¢‘å†…å®¹ç†è§£å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜è§†é¢‘å¤„ç†çš„æ•ˆç‡å’Œå‡†ç¡®æ€§ï¼Œè¯¥æ–¹æ³•å¯ä»¥ä¸ºæ•™è‚²ã€å¨±ä¹å’Œå®‰å…¨ç›‘æ§ç­‰è¡Œä¸šæä¾›æ›´æ™ºèƒ½çš„è§£å†³æ–¹æ¡ˆï¼Œæ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å‘å±•ä¸åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> The practical application of Multimodal Large Language Models (MLLMs) to Video Question Answering (Video-QA) is severely hindered by the high token cost of processing numerous video frames. While keyframe selection is the dominant strategy to mitigate this, we identify that even state-of-the-art selectors produce prompts laden with significant temporal redundancy, a challenge unique to video that we term 'visual echoes'. This issue leads to context dilution and can paradoxically degrade performance. To address this dual challenge, we propose a novel refinement framework that synergistically combines Adaptive Frame-Pruning (AFP) with a lightweight text-based semantic graph. AFP intelligently prunes 'visual echoes' by adaptively clustering frames, while the semantic graph provides crucial, low-cost semantic compensation. Conducting extensive experiments on the LongVideoBench and VideoMME benchmarks against multiple state-of-the-art selectors, our approach demonstrates a drastic reduction in total input tokens by up to 80%. Crucially, by creating a concise, high-quality prompt, our framework not only enhances efficiency but also demonstrates a remarkable ability to robustify and improve the accuracy of upstream selectors, achieving results that are highly competitive with, and often superior to, baselines that use vastly more frames.

