---
layout: default
title: DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition
---

# DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03397" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03397v1</a>
  <a href="https://arxiv.org/pdf/2508.03397.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03397v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03397v1', 'DepthGait: Multi-Scale Cross-Level Feature Fusion of RGB-Derived Depth and Silhouette Sequences for Robust Gait Recognition')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinzhu Li, Juepeng Zheng, Yikun Chen, Xudong Mao, Guanghui Yue, Wei Zhou, Chenlei Lv, Ruomei Wang, Fan Zhou, Baoquan Zhao

**åˆ†ç±»**: cs.CV, cs.MM

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**DOI**: [10.1145/3746027.3755876](https://doi.org/10.1145/3746027.3755876)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºDepthGaitä»¥è§£å†³æ­¥æ€è¯†åˆ«ä¸­çš„æ¨¡æ€èåˆé—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)**

**å…³é”®è¯**: `æ­¥æ€è¯†åˆ«` `å¤šæ¨¡æ€èåˆ` `æ·±åº¦å­¦ä¹ ` `ç‰¹å¾æå–` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„æ­¥æ€è¯†åˆ«æ–¹æ³•ä¸»è¦ä¾èµ–äºäºŒç»´è½®å»“å’Œéª¨æ¶ï¼Œæ— æ³•æœ‰æ•ˆåº”å¯¹è§†è§’å˜åŒ–å’Œç»†èŠ‚æ•æ‰çš„æŒ‘æˆ˜ã€‚
2. æœ¬æ–‡æå‡ºDepthGaitæ¡†æ¶ï¼Œé€šè¿‡ç»“åˆRGBè¡ç”Ÿçš„æ·±åº¦å›¾å’Œè½®å»“ï¼Œå¢å¼ºæ­¥æ€è¯†åˆ«çš„åŒºåˆ†èƒ½åŠ›ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒDepthGaitåœ¨å¤šä¸ªæ ‡å‡†æ•°æ®é›†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«å‡†ç¡®ç‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ­¥æ€è¯†åˆ«çš„é²æ£’æ€§ä¾èµ–äºé«˜åº¦åŒºåˆ†æ€§çš„è¡¨ç¤ºï¼Œè¿™ä¸è¾“å…¥æ¨¡æ€å¯†åˆ‡ç›¸å…³ã€‚å°½ç®¡äºŒè¿›åˆ¶è½®å»“å’Œéª¨æ¶åœ¨è¿‘æœŸæ–‡çŒ®ä¸­å æ®ä¸»å¯¼åœ°ä½ï¼Œä½†è¿™äº›äºŒç»´è¡¨ç¤ºæ— æ³•å……åˆ†æ•æ‰å¤„ç†è§†è§’å˜åŒ–æ‰€éœ€çš„çº¿ç´¢ï¼Œä¹Ÿæ— æ³•æ•æ‰æ­¥æ€çš„ç»†å¾®å’Œæœ‰æ„ä¹‰çš„ç»†èŠ‚ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶DepthGaitï¼Œç»“åˆRGBè¡ç”Ÿçš„æ·±åº¦å›¾å’Œè½®å»“ä»¥å¢å¼ºæ­¥æ€è¯†åˆ«ã€‚è¯¥æ–¹æ³•ä¸ä»…åˆ©ç”¨äººä½“çš„äºŒç»´è½®å»“è¡¨ç¤ºï¼Œè¿˜ä»ç»™å®šçš„RGBå›¾åƒåºåˆ—ä¸­æ˜¾å¼ä¼°è®¡æ·±åº¦å›¾ï¼Œä½œä¸ºæ•æ‰äººç±»è¿åŠ¨å›ºæœ‰ç‰¹å¾çš„æ–°æ¨¡æ€ã€‚æ­¤å¤–ï¼Œå¼€å‘äº†ä¸€ç§æ–°é¢–çš„å¤šå°ºåº¦å’Œè·¨å±‚èåˆæ–¹æ¡ˆï¼Œä»¥å¼¥åˆæ·±åº¦å›¾å’Œè½®å»“ä¹‹é—´çš„æ¨¡æ€å·®è·ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDepthGaitåœ¨æ ‡å‡†åŸºå‡†ä¸Šå®ç°äº†ä¸åŒè¡Œæ–¹æ³•ç›¸æ¯”çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå¹¶åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ä¸Šè¾¾åˆ°äº†ä»¤äººå°è±¡æ·±åˆ»çš„å¹³å‡Rank-1å‡†ç¡®ç‡ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ­¥æ€è¯†åˆ«é¢ä¸´çš„ä¸»è¦é—®é¢˜æ˜¯ç°æœ‰æ–¹æ³•ä¾èµ–äºäºŒç»´è½®å»“å’Œéª¨æ¶ï¼Œæ— æ³•æœ‰æ•ˆæ•æ‰è§†è§’å˜åŒ–å’Œç»†èŠ‚ä¿¡æ¯ï¼Œå¯¼è‡´è¯†åˆ«æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šDepthGaitæ¡†æ¶é€šè¿‡å¼•å…¥RGBè¡ç”Ÿçš„æ·±åº¦å›¾ä½œä¸ºæ–°æ¨¡æ€ï¼Œç»“åˆäºŒç»´è½®å»“è¡¨ç¤ºï¼Œæ—¨åœ¨æ•æ‰äººç±»è¿åŠ¨çš„æ›´å¤šåŒºåˆ†æ€§ç‰¹å¾ï¼Œä»è€Œæé«˜æ­¥æ€è¯†åˆ«çš„é²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶åŒ…æ‹¬ä¸¤ä¸ªä¸»è¦æ¨¡å—ï¼šé¦–å…ˆï¼Œä»RGBå›¾åƒåºåˆ—ä¸­ä¼°è®¡æ·±åº¦å›¾ï¼›å…¶æ¬¡ï¼Œé‡‡ç”¨å¤šå°ºåº¦å’Œè·¨å±‚èåˆç­–ç•¥ï¼Œå°†æ·±åº¦å›¾ä¸è½®å»“ä¿¡æ¯è¿›è¡Œæœ‰æ•ˆç»“åˆï¼Œä»¥å¢å¼ºç‰¹å¾è¡¨ç¤ºã€‚

**å…³é”®åˆ›æ–°**ï¼šDepthGaitçš„åˆ›æ–°ä¹‹å¤„åœ¨äºå…¶å¤šå°ºåº¦å’Œè·¨å±‚èåˆæ–¹æ¡ˆï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¼¥åˆæ·±åº¦å›¾å’Œè½®å»“ä¹‹é—´çš„æ¨¡æ€å·®è·ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šæœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–æ¨¡æ€èåˆæ•ˆæœï¼Œå¹¶é€šè¿‡æ·±åº¦å­¦ä¹ ç½‘ç»œç»“æ„æ¥å®ç°æ·±åº¦å›¾å’Œè½®å»“çš„ç‰¹å¾æå–ä¸èåˆï¼Œç¡®ä¿äº†æ¨¡å‹çš„é«˜æ•ˆæ€§å’Œå‡†ç¡®æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

DepthGaitåœ¨å¤šä¸ªæ ‡å‡†æ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šè¾¾åˆ°äº†ä»¤äººå°è±¡æ·±åˆ»çš„å¹³å‡Rank-1å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŒè¡Œæ–¹æ³•ï¼Œå±•ç¤ºäº†å…¶åœ¨æ­¥æ€è¯†åˆ«é¢†åŸŸçš„å¼ºå¤§èƒ½åŠ›ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶åœ¨å®‰é˜²ç›‘æ§ã€æ™ºèƒ½äº¤é€šã€å¥åº·ç›‘æµ‹ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨æ½œåŠ›ã€‚é€šè¿‡æé«˜æ­¥æ€è¯†åˆ«çš„å‡†ç¡®æ€§ï¼ŒDepthGaitå¯ä»¥æœ‰æ•ˆæ”¯æŒäººç¾¤è¡Œä¸ºåˆ†æã€å¼‚å¸¸æ£€æµ‹å’Œä¸ªä½“è¯†åˆ«ç­‰ä»»åŠ¡ï¼Œæœªæ¥å¯èƒ½æ¨åŠ¨ç›¸å…³æŠ€æœ¯çš„å•†ä¸šåŒ–åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Robust gait recognition requires highly discriminative representations, which are closely tied to input modalities. While binary silhouettes and skeletons have dominated recent literature, these 2D representations fall short of capturing sufficient cues that can be exploited to handle viewpoint variations, and capture finer and meaningful details of gait. In this paper, we introduce a novel framework, termed DepthGait, that incorporates RGB-derived depth maps and silhouettes for enhanced gait recognition. Specifically, apart from the 2D silhouette representation of the human body, the proposed pipeline explicitly estimates depth maps from a given RGB image sequence and uses them as a new modality to capture discriminative features inherent in human locomotion. In addition, a novel multi-scale and cross-level fusion scheme has also been developed to bridge the modality gap between depth maps and silhouettes. Extensive experiments on standard benchmarks demonstrate that the proposed DepthGait achieves state-of-the-art performance compared to peer methods and attains an impressive mean rank-1 accuracy on the challenging datasets.

