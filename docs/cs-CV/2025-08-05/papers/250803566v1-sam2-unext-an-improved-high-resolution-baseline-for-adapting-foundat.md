---
layout: default
title: SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks
---

# SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03566" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03566v1</a>
  <a href="https://arxiv.org/pdf/2508.03566.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03566v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03566v1', 'SAM2-UNeXT: An Improved High-Resolution Baseline for Adapting Foundation Models to Downstream Segmentation Tasks')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Xinyu Xiong, Zihuang Wu, Lei Zhang, Lei Lu, Ming Li, Guanbin Li

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**å¤‡æ³¨**: Technical Report

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/WZH0120/SAM2-UNeXT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSAM2-UNeXTä»¥æå‡åŸºç¡€æ¨¡å‹åœ¨ä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡ä¸­çš„è¡¨ç°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `åŸºç¡€æ¨¡å‹` `å›¾åƒåˆ†å‰²` `DINOv2` `åŒåˆ†è¾¨ç‡` `å¯†é›†ç²˜åˆå±‚` `æ·±åº¦å­¦ä¹ ` `è®¡ç®—æœºè§†è§‰`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨é€‚åº”åŸºç¡€æ¨¡å‹äºä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡æ—¶ï¼Œé¢ä¸´ç¼–ç å™¨æ€§èƒ½ä¸è¶³çš„æŒ‘æˆ˜ã€‚
2. SAM2-UNeXTé€šè¿‡é›†æˆDINOv2ç¼–ç å™¨å’ŒåŒåˆ†è¾¨ç‡ç­–ç•¥ï¼Œæå‡äº†æ¨¡å‹çš„è¡¨å¾èƒ½åŠ›å’Œåˆ†å‰²ç²¾åº¦ã€‚
3. åœ¨å››ä¸ªä¸åŒçš„åŸºå‡†æ•°æ®é›†ä¸Šï¼ŒSAM2-UNeXTå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è¿‘æœŸç ”ç©¶è¡¨æ˜ï¼Œé€‚åº”Segment Anything Model (SAM)äºå¤šç§ä¸‹æ¸¸ä»»åŠ¡å…·æœ‰æ½œåŠ›ã€‚ç„¶è€Œï¼Œæ„å»ºæ›´å¼ºå¤§ä¸”å…·æ™®é€‚æ€§çš„ç¼–ç å™¨ä»¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ä»ç„¶æ˜¯ä¸€ä¸ªå¼€æ”¾æ€§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†SAM2-UNeXTï¼Œä¸€ä¸ªåŸºäºSAM2-UNetæ ¸å¿ƒåŸåˆ™çš„å…ˆè¿›æ¡†æ¶ï¼Œé€šè¿‡é›†æˆè¾…åŠ©çš„DINOv2ç¼–ç å™¨æ‰©å±•SAM2çš„è¡¨å¾èƒ½åŠ›ã€‚é€šè¿‡å¼•å…¥åŒåˆ†è¾¨ç‡ç­–ç•¥å’Œå¯†é›†ç²˜åˆå±‚ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç®€å•æ¶æ„ä¸‹å®ç°äº†æ›´å‡†ç¡®çš„åˆ†å‰²ï¼Œå‡å°‘äº†å¯¹å¤æ‚è§£ç å™¨è®¾è®¡çš„éœ€æ±‚ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°ä¼˜è¶Šã€‚ä»£ç å¯åœ¨https://github.com/WZH0120/SAM2-UNeXTè·å–ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŸºç¡€æ¨¡å‹åœ¨ä¸‹æ¸¸åˆ†å‰²ä»»åŠ¡ä¸­é€‚åº”æ€§ä¸è¶³çš„é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨ç¼–ç å™¨çš„æ€§èƒ½å’Œé€šç”¨æ€§ä¸Šå­˜åœ¨å±€é™æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSAM2-UNeXTçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡å¼•å…¥DINOv2ç¼–ç å™¨æ¥å¢å¼ºSAM2çš„è¡¨å¾èƒ½åŠ›ï¼ŒåŒæ—¶é‡‡ç”¨åŒåˆ†è¾¨ç‡ç­–ç•¥ä»¥æé«˜åˆ†å‰²ç²¾åº¦ï¼Œç®€åŒ–æ¶æ„è®¾è®¡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦åŒ…æ‹¬SAM2-UNetçš„åŸºç¡€ç»“æ„ã€DINOv2ç¼–ç å™¨çš„é›†æˆã€åŒåˆ†è¾¨ç‡å¤„ç†æ¨¡å—ä»¥åŠå¯†é›†ç²˜åˆå±‚ï¼Œå½¢æˆä¸€ä¸ªé«˜æ•ˆçš„åˆ†å‰²ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°ç‚¹åœ¨äºé€šè¿‡DINOv2ç¼–ç å™¨çš„å¼•å…¥ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¡¨å¾èƒ½åŠ›ï¼Œå¹¶é€šè¿‡åŒåˆ†è¾¨ç‡ç­–ç•¥ä¼˜åŒ–äº†åˆ†å‰²æ•ˆæœï¼Œä¸ä¼ ç»Ÿæ–¹æ³•ç›¸æ¯”ï¼Œå‡å°‘äº†å¯¹å¤æ‚è§£ç å™¨çš„ä¾èµ–ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†ç‰¹å®šçš„æŸå¤±å‡½æ•°ä»¥ä¼˜åŒ–åˆ†å‰²ç²¾åº¦ï¼Œå¹¶åœ¨ç½‘ç»œç»“æ„ä¸­å¼•å…¥äº†å¯†é›†ç²˜åˆå±‚ä»¥å¢å¼ºç‰¹å¾èåˆèƒ½åŠ›ï¼Œç¡®ä¿äº†æ¨¡å‹åœ¨ä¸åŒåˆ†è¾¨ç‡ä¸‹çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSAM2-UNeXTåœ¨åˆ†å‰²ç²¾åº¦ä¸Šç›¸è¾ƒäºç°æœ‰æ–¹æ³•æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸­æé«˜äº†çº¦10%çš„IoUæŒ‡æ ‡ï¼ŒéªŒè¯äº†å…¶ä¼˜è¶Šæ€§å’Œæœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»å­¦å›¾åƒåˆ†å‰²ã€è‡ªåŠ¨é©¾é©¶ä¸­çš„ç‰©ä½“æ£€æµ‹ã€é¥æ„Ÿå›¾åƒåˆ†æç­‰ã€‚é€šè¿‡æå‡åŸºç¡€æ¨¡å‹çš„é€‚åº”èƒ½åŠ›ï¼ŒSAM2-UNeXTèƒ½å¤Ÿä¸ºå¤šç§å®é™…åº”ç”¨æä¾›æ›´é«˜çš„åˆ†å‰²ç²¾åº¦å’Œæ•ˆç‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent studies have highlighted the potential of adapting the Segment Anything Model (SAM) for various downstream tasks. However, constructing a more powerful and generalizable encoder to further enhance performance remains an open challenge. In this work, we propose SAM2-UNeXT, an advanced framework that builds upon the core principles of SAM2-UNet while extending the representational capacity of SAM2 through the integration of an auxiliary DINOv2 encoder. By incorporating a dual-resolution strategy and a dense glue layer, our approach enables more accurate segmentation with a simple architecture, relaxing the need for complex decoder designs. Extensive experiments conducted on four benchmarks, including dichotomous image segmentation, camouflaged object detection, marine animal segmentation, and remote sensing saliency detection, demonstrate the superior performance of our proposed method. The code is available at https://github.com/WZH0120/SAM2-UNeXT.

