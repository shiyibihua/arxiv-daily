---
layout: default
title: Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts
---

# Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03094" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03094v1</a>
  <a href="https://arxiv.org/pdf/2508.03094.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03094v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03094v1', 'Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Jiantao Tan, Peixian Ma, Kanghao Chen, Zhiming Dai, Ruixuan Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ©ç”¨LLMç”Ÿæˆè§†è§‰æ¦‚å¿µä»¥å¢å¼ºç–¾ç—…æŒç»­å­¦ä¹ **

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `æŒç»­å­¦ä¹ ` `åŒ»ç–—å›¾åƒåˆ†ç±»` `å¤šæ¨¡æ€èåˆ` `è§†è§‰æ¦‚å¿µ` `å¤§å‹è¯­è¨€æ¨¡å‹` `æ³¨æ„æœºåˆ¶` `è¯­ä¹‰æŒ‡å¯¼`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æ–¹æ³•åœ¨æŒç»­å­¦ä¹ ä¸­ä»…ä¾èµ–ç®€å•çš„æ–‡æœ¬æ¨¡æ¿ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´æ€§èƒ½å—é™ã€‚
2. æœ¬æ–‡æå‡ºçš„æ¡†æ¶åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è§†è§‰æ¦‚å¿µï¼ŒåŠ¨æ€æ„å»ºæ¦‚å¿µæ± å¹¶é€šè¿‡æ³¨æ„æœºåˆ¶æ•´åˆåˆ°å­¦ä¹ è¿‡ç¨‹ä¸­ã€‚
3. å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ï¼Œå±•ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æŒç»­å­¦ä¹ å¯¹äºåŒ»ç–—å›¾åƒåˆ†ç±»ç³»ç»Ÿåœ¨åŠ¨æ€å˜åŒ–çš„ä¸´åºŠç¯å¢ƒä¸­è‡³å…³é‡è¦ã€‚ç°æœ‰æ–¹æ³•è™½ç„¶åˆ©ç”¨äº†æ–‡æœ¬æ¨¡æ€ä¿¡æ¯ï¼Œä½†ä»…ä¾èµ–ç®€å•çš„æ¨¡æ¿ï¼Œå¿½è§†äº†æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è§†è§‰æ¦‚å¿µä½œä¸ºåˆ¤åˆ«æ€§è¯­ä¹‰æŒ‡å¯¼ã€‚è¯¥æ–¹æ³•åŠ¨æ€æ„å»ºè§†è§‰æ¦‚å¿µæ± ï¼Œå¹¶é€šè¿‡åŸºäºç›¸ä¼¼æ€§çš„è¿‡æ»¤æœºåˆ¶é˜²æ­¢å†—ä½™ã€‚é€šè¿‡è·¨æ¨¡æ€å›¾åƒ-æ¦‚å¿µæ³¨æ„æ¨¡å—åŠæ³¨æ„æŸå¤±ï¼Œå°†æ¦‚å¿µæ•´åˆåˆ°æŒç»­å­¦ä¹ è¿‡ç¨‹ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŒ»ç–—å’Œè‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šå®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå±•ç¤ºäº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³åŒ»ç–—å›¾åƒåˆ†ç±»ç³»ç»Ÿåœ¨åŠ¨æ€ä¸´åºŠç¯å¢ƒä¸­æŒç»­å­¦ä¹ çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä»…ä¾èµ–ç®€å•çš„æ–‡æœ¬æ¨¡æ¿ï¼Œæœªèƒ½å……åˆ†åˆ©ç”¨ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå¯¼è‡´åˆ†ç±»æ€§èƒ½å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šæœ¬æ–‡æå‡ºåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è§†è§‰æ¦‚å¿µä½œä¸ºè¯­ä¹‰æŒ‡å¯¼ï¼ŒåŠ¨æ€æ„å»ºè§†è§‰æ¦‚å¿µæ± ï¼Œå¹¶é€šè¿‡ç›¸ä¼¼æ€§è¿‡æ»¤æœºåˆ¶é¿å…å†—ä½™ï¼Œä»è€Œå¢å¼ºæŒç»­å­¦ä¹ çš„æ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬è§†è§‰æ¦‚å¿µç”Ÿæˆã€æ¦‚å¿µæ± æ„å»ºå’Œè·¨æ¨¡æ€å›¾åƒ-æ¦‚å¿µæ³¨æ„æ¨¡å—ã€‚é¦–å…ˆç”Ÿæˆè§†è§‰æ¦‚å¿µï¼Œç„¶åé€šè¿‡ç›¸ä¼¼æ€§è¿‡æ»¤æ„å»ºæ¦‚å¿µæ± ï¼Œæœ€åå°†æ¦‚å¿µæ•´åˆåˆ°å­¦ä¹ è¿‡ç¨‹ä¸­ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºåˆ©ç”¨LLMç”Ÿæˆçš„è§†è§‰æ¦‚å¿µä½œä¸ºåˆ¤åˆ«æ€§è¯­ä¹‰æŒ‡å¯¼ï¼Œå¹¶é€šè¿‡æ³¨æ„æœºåˆ¶æœ‰æ•ˆæ•´åˆåˆ°æŒç»­å­¦ä¹ ä¸­ã€‚è¿™ä¸€æ–¹æ³•ä¸ä¼ ç»Ÿçš„ç®€å•æ¨¡æ¿æ–¹æ³•æœ‰æœ¬è´¨åŒºåˆ«ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†åŸºäºç›¸ä¼¼æ€§çš„è¿‡æ»¤æœºåˆ¶æ¥æ„å»ºè§†è§‰æ¦‚å¿µæ± ï¼Œå¹¶å¼•å…¥äº†è·¨æ¨¡æ€æ³¨æ„æ¨¡å—å’Œæ³¨æ„æŸå¤±ï¼Œä»¥ç¡®ä¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨ç›¸å…³çš„è§†è§‰æ¦‚å¿µè¿›è¡Œåˆ†ç±»ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæœ¬æ–‡æ–¹æ³•åœ¨åŒ»ç–—å’Œè‡ªç„¶å›¾åƒæ•°æ®é›†ä¸Šå‡å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå…·ä½“è¡¨ç°ä¸ºåœ¨æŸäº›ä»»åŠ¡ä¸Šç›¸è¾ƒäºåŸºçº¿æ–¹æ³•æå‡äº†çº¦10%çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å›¾åƒåˆ†æã€ä¸´åºŠå†³ç­–æ”¯æŒç³»ç»Ÿç­‰ã€‚é€šè¿‡å¢å¼ºæŒç»­å­¦ä¹ èƒ½åŠ›ï¼Œç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”ä¸æ–­å˜åŒ–çš„ä¸´åºŠç¯å¢ƒï¼Œæé«˜è¯Šæ–­çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯èƒ½åœ¨å…¶ä»–é¢†åŸŸçš„å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­ä¹Ÿå…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Continual learning is essential for medical image classification systems to adapt to dynamically evolving clinical environments. The integration of multimodal information can significantly enhance continual learning of image classes. However, while existing approaches do utilize textual modality information, they solely rely on simplistic templates with a class name, thereby neglecting richer semantic information. To address these limitations, we propose a novel framework that harnesses visual concepts generated by large language models (LLMs) as discriminative semantic guidance. Our method dynamically constructs a visual concept pool with a similarity-based filtering mechanism to prevent redundancy. Then, to integrate the concepts into the continual learning process, we employ a cross-modal image-concept attention module, coupled with an attention loss. Through attention, the module can leverage the semantic knowledge from relevant visual concepts and produce class-representative fused features for classification. Experiments on medical and natural image datasets show our method achieves state-of-the-art performance, demonstrating the effectiveness and superiority of our method. We will release the code publicly.

