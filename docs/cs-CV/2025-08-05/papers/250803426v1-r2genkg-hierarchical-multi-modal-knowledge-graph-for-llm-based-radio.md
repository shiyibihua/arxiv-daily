---
layout: default
title: R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation
---

# R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03426" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.03426v1</a>
  <a href="https://arxiv.org/pdf/2508.03426.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03426v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03426v1', 'R2GenKG: Hierarchical Multi-modal Knowledge Graph for LLM-based Radiology Report Generation')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Futian Wang, Yuhan Qiao, Xiao Wang, Fuling Wang, Yuxiang Zhang, Dengdi Sun

**åˆ†ç±»**: cs.CV, cs.AI, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-08-05

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/Event-AHU/Medical_Image_Analysis)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºR2GenKGä»¥è§£å†³Xå…‰æŠ¥å‘Šç”Ÿæˆä¸­çš„å¹»è§‰ä¸è¯Šæ–­èƒ½åŠ›ä¸è¶³é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€çŸ¥è¯†å›¾` `Xå…‰æŠ¥å‘Šç”Ÿæˆ` `ç–¾ç—…è¯Šæ–­` `ç‰¹å¾æå–` `å¤§å‹è¯­è¨€æ¨¡å‹` `äº¤å‰æ³¨æ„åŠ›` `åŒ»å­¦å½±åƒåˆ†æ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„åŒ»å­¦æŠ¥å‘Šç”Ÿæˆæ–¹æ³•å­˜åœ¨å¹»è§‰ç°è±¡å’Œç–¾ç—…è¯Šæ–­èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œå½±å“äº†ç”ŸæˆæŠ¥å‘Šçš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚
2. æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€åŒ»å­¦çŸ¥è¯†å›¾ï¼ˆM3KGï¼‰çš„æ–¹æ³•ï¼Œé€šè¿‡æ„å»ºä¸°å¯Œçš„çŸ¥è¯†å›¾è°±æ¥å¢å¼ºæ¨¡å‹çš„ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚
3. åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨æŠ¥å‘Šç”Ÿæˆè´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

Xå…‰åŒ»å­¦æŠ¥å‘Šç”Ÿæˆæ˜¯äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„é‡è¦åº”ç”¨ä¹‹ä¸€ã€‚åœ¨å¤§å‹åŸºç¡€æ¨¡å‹çš„æ”¯æŒä¸‹ï¼ŒåŒ»å­¦æŠ¥å‘Šç”Ÿæˆçš„è´¨é‡æ˜¾è‘—æé«˜ã€‚ç„¶è€Œï¼Œå¹»è§‰ç°è±¡å’Œç–¾ç—…è¯Šæ–­èƒ½åŠ›ä¸è¶³ç­‰æŒ‘æˆ˜ä¾ç„¶å­˜åœ¨ã€‚æœ¬æ–‡é¦–å…ˆåŸºäºçœŸå®åŒ»å­¦æŠ¥å‘Šæ„å»ºäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€åŒ»å­¦çŸ¥è¯†å›¾ï¼ˆM3KGï¼‰ï¼ŒåŒ…å«2477ä¸ªå®ä½“ã€3ç§å…³ç³»ã€37424ä¸ªä¸‰å…ƒç»„å’Œ6943ä¸ªç–¾ç—…æ„ŸçŸ¥è§†è§‰æ ‡è®°ã€‚æ¥ç€ï¼Œé‡‡ç”¨R-GCNç¼–ç å™¨è¿›è¡Œç‰¹å¾æå–ï¼Œå¹¶ä½¿ç”¨Swin-Transformeræå–è¾“å…¥Xå…‰å›¾åƒçš„è§†è§‰ç‰¹å¾ã€‚æœ€åï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å°†è¯­ä¹‰çŸ¥è¯†å›¾ã€è¾“å…¥çš„Xå…‰å›¾åƒå’Œç–¾ç—…æ„ŸçŸ¥è§†è§‰æ ‡è®°æ˜ å°„ä¸ºè¯­è¨€æè¿°ã€‚å¤šé¡¹æ•°æ®é›†ä¸Šçš„å®éªŒå……åˆ†éªŒè¯äº†æ‰€æçŸ¥è¯†å›¾å’ŒXå…‰æŠ¥å‘Šç”Ÿæˆæ¡†æ¶çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³Xå…‰åŒ»å­¦æŠ¥å‘Šç”Ÿæˆä¸­çš„å¹»è§‰ç°è±¡å’Œç–¾ç—…è¯Šæ–­èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•åœ¨ç”ŸæˆæŠ¥å‘Šæ—¶å¸¸å¸¸å‡ºç°ä¸å‡†ç¡®çš„æè¿°ï¼Œå¯¼è‡´ä¸´åºŠåº”ç”¨å—é™ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šé€šè¿‡æ„å»ºä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šæ¨¡æ€åŒ»å­¦çŸ¥è¯†å›¾ï¼ˆM3KGï¼‰ï¼Œå°†çœŸå®åŒ»å­¦æŠ¥å‘Šä¸­çš„ä¿¡æ¯ç»“æ„åŒ–ï¼Œä»è€Œä¸ºç”Ÿæˆæ¨¡å‹æä¾›æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæå‡ç”Ÿæˆè´¨é‡ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬çŸ¥è¯†å›¾è°±æ„å»ºã€ç‰¹å¾æå–å’ŒæŠ¥å‘Šç”Ÿæˆä¸‰ä¸ªä¸»è¦æ¨¡å—ã€‚é¦–å…ˆï¼Œæ„å»ºM3KGå¹¶è¿›è¡Œå¤šç²’åº¦æŠ½æ ·ï¼›å…¶æ¬¡ï¼Œä½¿ç”¨R-GCNç¼–ç å™¨å’ŒSwin-Transformeræå–ç‰¹å¾ï¼›æœ€åï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ç”ŸæˆæŠ¥å‘Šã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„åˆ›æ–°åœ¨äºæ„å»ºäº†ä¸€ä¸ªåŒ…å«ä¸°å¯Œå®ä½“å’Œå…³ç³»çš„å¤šæ¨¡æ€çŸ¥è¯†å›¾ï¼Œå¹¶é€šè¿‡äº¤å‰æ³¨æ„åŠ›æœºåˆ¶æœ‰æ•ˆæ•´åˆè§†è§‰ç‰¹å¾ä¸çŸ¥è¯†å›¾ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡äº†ç”ŸæˆæŠ¥å‘Šçš„å‡†ç¡®æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨ç‰¹å¾æå–ä¸­ï¼Œé‡‡ç”¨R-GCNç¼–ç å™¨è¿›è¡Œå›¾ç‰¹å¾æå–ï¼ŒSwin-Transformerç”¨äºè§†è§‰ç‰¹å¾æå–ï¼Œäº¤å‰æ³¨æ„åŠ›æœºåˆ¶ç”¨äºçŸ¥è¯†ä¸è§†è§‰ç‰¹å¾çš„äº¤äº’ï¼Œç¡®ä¿ç”Ÿæˆçš„æŠ¥å‘Šæ›´å…·ç–¾ç—…æ„ŸçŸ¥èƒ½åŠ›ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€ææ–¹æ³•åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šç›¸è¾ƒäºç°æœ‰åŸºçº¿æœ‰æ˜¾è‘—æå‡ï¼Œå…·ä½“è¡¨ç°ä¸ºç”ŸæˆæŠ¥å‘Šçš„å‡†ç¡®ç‡æé«˜äº†XX%ï¼Œå¹¶ä¸”å‡å°‘äº†å¹»è§‰ç°è±¡çš„å‘ç”Ÿç‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬åŒ»ç–—å½±åƒåˆ†æã€æ™ºèƒ½è¯Šæ–­ç³»ç»Ÿå’Œè¾…åŠ©å†³ç­–æ”¯æŒå·¥å…·ã€‚é€šè¿‡æé«˜Xå…‰æŠ¥å‘Šç”Ÿæˆçš„å‡†ç¡®æ€§ï¼Œå¯ä»¥å¸®åŠ©åŒ»ç”Ÿæ›´å¿«åœ°åšå‡ºè¯Šæ–­å†³ç­–ï¼Œæå‡åŒ»ç–—æœåŠ¡è´¨é‡ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œç¤¾ä¼šå½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> X-ray medical report generation is one of the important applications of artificial intelligence in healthcare. With the support of large foundation models, the quality of medical report generation has significantly improved. However, challenges such as hallucination and weak disease diagnostic capability still persist. In this paper, we first construct a large-scale multi-modal medical knowledge graph (termed M3KG) based on the ground truth medical report using the GPT-4o. It contains 2477 entities, 3 kinds of relations, 37424 triples, and 6943 disease-aware vision tokens for the CheXpert Plus dataset. Then, we sample it to obtain multi-granularity semantic graphs and use an R-GCN encoder for feature extraction. For the input X-ray image, we adopt the Swin-Transformer to extract the vision features and interact with the knowledge using cross-attention. The vision tokens are fed into a Q-former and retrieved the disease-aware vision tokens using another cross-attention. Finally, we adopt the large language model to map the semantic knowledge graph, input X-ray image, and disease-aware vision tokens into language descriptions. Extensive experiments on multiple datasets fully validated the effectiveness of our proposed knowledge graph and X-ray report generation framework. The source code of this paper will be released on https://github.com/Event-AHU/Medical_Image_Analysis.

