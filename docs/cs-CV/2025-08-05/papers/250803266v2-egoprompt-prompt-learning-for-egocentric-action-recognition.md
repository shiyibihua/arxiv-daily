---
layout: default
title: EgoPrompt: Prompt Learning for Egocentric Action Recognition
---

# EgoPrompt: Prompt Learning for Egocentric Action Recognition

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.03266" class="toolbar-btn" target="_blank">üìÑ arXiv: 2508.03266v2</a>
  <a href="https://arxiv.org/pdf/2508.03266.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.03266v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.03266v2', 'EgoPrompt: Prompt Learning for Egocentric Action Recognition')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Huaihai Lyu, Chaofan Chen, Yuheng Ji, Changsheng Xu

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-08-05 (Êõ¥Êñ∞: 2025-08-07)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫EgoPrompt‰ª•Ëß£ÂÜ≥Á¨¨‰∏Ä‰∫∫Áß∞Âä®‰ΩúËØÜÂà´‰∏≠ÁöÑËØ≠‰πâÂÖ≥Á≥ªÈóÆÈ¢ò**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±ÂÖ≠ÔºöËßÜÈ¢ëÊèêÂèñ‰∏éÂåπÈÖç (Video Extraction)**

**ÂÖ≥ÈîÆËØç**: `Á¨¨‰∏Ä‰∫∫Áß∞Âä®‰ΩúËØÜÂà´` `ÊèêÁ§∫Â≠¶‰π†` `ËØ≠‰πâÂÖ≥Á≥ª` `Ë∑®ÊàêÂàÜ‰∫§‰∫í` `Â¢ûÂº∫Áé∞ÂÆû` `ËôöÊãüÁé∞ÂÆû` `Ê∑±Â∫¶Â≠¶‰π†`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊñπÊ≥ïÂ∞ÜÂä®ËØçÂíåÂêçËØçÊàêÂàÜËßÜ‰∏∫Áã¨Á´ã‰ªªÂä°ÔºåÂøΩÁï•‰∫ÜÂÆÉ‰ª¨ÁöÑËØ≠‰πâÂÖ≥Á≥ªÔºåÂØºËá¥Ë°®Á§∫Á¢éÁâáÂåñÂíåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ
2. EgoPromptÊ°ÜÊû∂ÈÄöËøáÊûÑÂª∫Áªü‰∏ÄÁöÑÊèêÁ§∫Ê±†Ôºå‰øÉËøõÂä®ËØçÂíåÂêçËØçÊàêÂàÜ‰πãÈó¥ÁöÑ‰∫§‰∫íÔºå‰ªéËÄåÊèêÂçáËØÜÂà´ÊÄßËÉΩ„ÄÇ
3. Âú®Ego4D„ÄÅEPIC-KitchensÂíåEGTEAÊï∞ÊçÆÈõÜ‰∏äÁöÑÂÆûÈ™åË°®ÊòéÔºåEgoPromptÂú®ÂêÑÈ°πÂü∫ÂáÜÊµãËØï‰∏≠ÂùáË°®Áé∞Âá∫Ëâ≤ÔºåËææÂà∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

ÈöèÁùÄÂ¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÂ∫îÁî®ÈúÄÊ±ÇÁöÑÂ¢ûÂä†ÔºåÁ¨¨‰∏Ä‰∫∫Áß∞Âä®‰ΩúËØÜÂà´Êàê‰∏∫‰∏Ä‰∏™ÈáçË¶ÅÁöÑÁ†îÁ©∂È¢ÜÂüü„ÄÇËØ•‰ªªÂä°ÈÄöÂ∏∏ÂàÜ‰∏∫‰∏§‰∏™Â≠ê‰ªªÂä°ÔºöËØÜÂà´Ë°å‰∏∫ÔºàÂä®ËØçÊàêÂàÜÔºâÂíåËØÜÂà´Ë¢´‰ΩúÁî®ÁöÑÂØπË±°ÔºàÂêçËØçÊàêÂàÜÔºâ„ÄÇÁÑ∂ËÄåÔºåÁé∞ÊúâÊñπÊ≥ïÂ∞ÜËøô‰∏§‰∏™ÊàêÂàÜËßÜ‰∏∫Áã¨Á´ãÁöÑÂàÜÁ±ª‰ªªÂä°ÔºåÂøΩËßÜ‰∫ÜÂÆÉ‰ª¨‰πãÈó¥ÁöÑËØ≠‰πâÂíå‰∏ä‰∏ãÊñáÂÖ≥Á≥ªÔºåÂØºËá¥Ë°®Á§∫ÁöÑÁ¢éÁâáÂåñÂíåÊ≥õÂåñËÉΩÂäõ‰∏çË∂≥„ÄÇ‰∏∫‰∫ÜËß£ÂÜ≥Ëøô‰∫õÊåëÊàòÔºåÊú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÊèêÁ§∫Â≠¶‰π†ÁöÑÊ°ÜÊû∂EgoPromptÔºåÈÄöËøáÊûÑÂª∫Áªü‰∏ÄÁöÑÊèêÁ§∫Ê±†Á©∫Èó¥Êù•‰øÉËøõ‰∏§ÁßçÊàêÂàÜË°®Á§∫‰πãÈó¥ÁöÑ‰∫§‰∫í„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåEgoPromptÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂùáÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÊú¨ÊñáÊó®Âú®Ëß£ÂÜ≥Á¨¨‰∏Ä‰∫∫Áß∞Âä®‰ΩúËØÜÂà´‰∏≠Âä®ËØçÂíåÂêçËØçÊàêÂàÜ‰πãÈó¥ÁöÑËØ≠‰πâÂÖ≥Á≥ª‰∏çË∂≥ÁöÑÈóÆÈ¢ò„ÄÇÁé∞ÊúâÊñπÊ≥ïÈÄöÂ∏∏Â∞ÜËøô‰∏§ËÄÖËßÜ‰∏∫Áã¨Á´ãÁöÑÂàÜÁ±ª‰ªªÂä°ÔºåÂØºËá¥‰ø°ÊÅØÁöÑÁ¢éÁâáÂåñÂíåÊ≥õÂåñËÉΩÂäõÁöÑ‰∏ãÈôç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöEgoPromptÈÄöËøáÊûÑÂª∫Áªü‰∏ÄÁöÑÊèêÁ§∫Ê±†ÔºåÊçïÊçâÊàêÂàÜÁâπÂÆöÁü•ËØÜÔºåÂπ∂‰øÉËøõÂä®ËØçÂíåÂêçËØçÊàêÂàÜ‰πãÈó¥ÁöÑ‰∫§‰∫íÔºå‰ªéËÄåÂ¢ûÂº∫Êï¥‰ΩìËØÜÂà´ÊÄßËÉΩ„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöEgoPromptÁöÑÊï¥‰ΩìÊû∂ÊûÑÂåÖÊã¨‰∏§‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºöÈ¶ñÂÖàÔºåÂ∞ÜÂä®ËØçÂíåÂêçËØçÊàêÂàÜÁöÑË°®Á§∫ÂàÜËß£‰∏∫ÁªÜÁ≤íÂ∫¶Ê®°ÂºèÔºõÂÖ∂Ê¨°ÔºåÈÄöËøáÂü∫‰∫éÊ≥®ÊÑèÂäõÁöÑÊú∫Âà∂ËûçÂêàËøô‰∫õÊ®°ÂºèÔºå‰ª•ÂÆûÁé∞Ë∑®ÊàêÂàÜÁöÑ‰∫§‰∫í„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöÊú¨ÊñáÁöÑ‰∏ªË¶ÅÂàõÊñ∞Âú®‰∫éÂºïÂÖ•‰∫ÜÁªü‰∏ÄÁöÑÊèêÁ§∫Ê±†Á©∫Èó¥ÂíåÂ§öÊ†∑ÂåñÊ±†Ê†áÂáÜÔºåÁ°Æ‰øùÊèêÁ§∫Ê±†ÁöÑ‰ø°ÊÅØÈáè‰∏∞ÂØåÔºå‰ªéËÄåÊèêÂçá‰∫ÜÊ®°ÂûãÁöÑË°®Áé∞„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÈááÁî®‰∫ÜÊèêÁ§∫ÈÄâÊã©È¢ëÁéáÊ≠£ÂàôÂåñÂíåÊèêÁ§∫Áü•ËØÜÊ≠£‰∫§ÂåñÁöÑÊçüÂ§±ÂáΩÊï∞ËÆæËÆ°Ôºå‰ª•Á°Æ‰øùÊèêÁ§∫Ê±†ÁöÑÂ§öÊ†∑ÊÄßÂíåÊúâÊïàÊÄß„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

EgoPromptÂú®Ego4D„ÄÅEPIC-KitchensÂíåEGTEAÊï∞ÊçÆÈõÜ‰∏äÂùáÂèñÂæó‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩÔºåÂ∞§ÂÖ∂Âú®Ë∑®Êï∞ÊçÆÈõÜÂíåÂü∫Á°ÄÂà∞Êñ∞È¢ñÁöÑÊ≥õÂåñÂü∫ÂáÜÊµãËØï‰∏≠ÔºåË°®Áé∞Âá∫ÊòæËëóÁöÑÊèêÂçáÔºåÈ™åËØÅ‰∫ÜÂÖ∂ÊúâÊïàÊÄßÂíå‰ºòË∂äÊÄß„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

EgoPromptÁöÑÁ†îÁ©∂ÊàêÊûúÂú®Â¢ûÂº∫Áé∞ÂÆûÂíåËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüüÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÊΩúÂäõÔºåËÉΩÂ§üÊèêÂçá‰∫∫Êú∫‰∫§‰∫íÁöÑÊô∫ËÉΩÂåñÊ∞¥Âπ≥„ÄÇÈÄöËøáÊõ¥ÂáÜÁ°ÆÁöÑÂä®‰ΩúËØÜÂà´ÔºåÁõ∏ÂÖ≥Â∫îÁî®ÂèØ‰ª•ÂÆûÁé∞Êõ¥Ëá™ÁÑ∂ÁöÑÁî®Êà∑‰ΩìÈ™åÔºåÊé®Âä®Êô∫ËÉΩËÆæÂ§áÁöÑËøõ‰∏ÄÊ≠•ÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Driven by the increasing demand for applications in augmented and virtual reality, egocentric action recognition has emerged as a prominent research area. It is typically divided into two subtasks: recognizing the performed behavior (i.e., verb component) and identifying the objects being acted upon (i.e., noun component) from the first-person perspective. However, most existing approaches treat these two components as independent classification tasks, focusing on extracting component-specific knowledge while overlooking their inherent semantic and contextual relationships, leading to fragmented representations and sub-optimal generalization capability. To address these challenges, we propose a prompt learning-based framework, EgoPrompt, to conduct the egocentric action recognition task. Building on the existing prompting strategy to capture the component-specific knowledge, we construct a Unified Prompt Pool space to establish interaction between the two types of component representations. Specifically, the component representations (from verbs and nouns) are first decomposed into fine-grained patterns with the prompt pair form. Then, these pattern-level representations are fused through an attention-based mechanism to facilitate cross-component interaction. To ensure the prompt pool is informative, we further introduce a novel training objective, Diverse Pool Criteria. This objective realizes our goals from two perspectives: Prompt Selection Frequency Regularization and Prompt Knowledge Orthogonalization. Extensive experiments are conducted on the Ego4D, EPIC-Kitchens, and EGTEA datasets. The results consistently show that EgoPrompt achieves state-of-the-art performance across within-dataset, cross-dataset, and base-to-novel generalization benchmarks.

