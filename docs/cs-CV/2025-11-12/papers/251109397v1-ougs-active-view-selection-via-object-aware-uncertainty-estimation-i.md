---
layout: default
title: OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS
---

# OUGS: Active View Selection via Object-aware Uncertainty Estimation in 3DGS

**arXiv**: [2511.09397v1](https://arxiv.org/abs/2511.09397) | [PDF](https://arxiv.org/pdf/2511.09397.pdf)

**ä½œè€…**: Haiyi Li, Qi Chen, Denis Kalkofen, Hsiang-Ting Chen

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOUGSæ¡†æž¶ï¼Œé€šè¿‡å¯¹è±¡æ„ŸçŸ¥ä¸ç¡®å®šæ€§ä¼°è®¡ä¼˜åŒ–3DGSä¸»åŠ¨è§†å›¾é€‰æ‹©**

**å…³é”®è¯**: `3Dé«˜æ–¯æ³¼æº…` `ä¸»åŠ¨è§†å›¾é€‰æ‹©` `ä¸ç¡®å®šæ€§ä¼°è®¡` `å¯¹è±¡æ„ŸçŸ¥é‡å»º` `è¯­ä¹‰åˆ†å‰²`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰ä¸»åŠ¨é‡å»ºæ–¹æ³•ä¾èµ–åœºæ™¯çº§ä¸ç¡®å®šæ€§ï¼Œæ˜“å—èƒŒæ™¯å¹²æ‰°ï¼Œå¯¹è±¡é‡å»ºæ•ˆçŽ‡ä½Žã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåŸºäºŽ3Dé«˜æ–¯åŽŸè¯­ç‰©ç†å‚æ•°æŽ¨å¯¼ä¸ç¡®å®šæ€§ï¼Œç»“åˆè¯­ä¹‰åˆ†å‰²å®žçŽ°å¯¹è±¡æ„ŸçŸ¥è¯„åˆ†ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨å…¬å…±æ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæå‡é‡å»ºæ•ˆçŽ‡ä¸Žå¯¹è±¡è´¨é‡ï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in 3D Gaussian Splatting (3DGS) have achieved state-of-the-art results for novel view synthesis. However, efficiently capturing high-fidelity reconstructions of specific objects within complex scenes remains a significant challenge. A key limitation of existing active reconstruction methods is their reliance on scene-level uncertainty metrics, which are often biased by irrelevant background clutter and lead to inefficient view selection for object-centric tasks. We present OUGS, a novel framework that addresses this challenge with a more principled, physically-grounded uncertainty formulation for 3DGS. Our core innovation is to derive uncertainty directly from the explicit physical parameters of the 3D Gaussian primitives (e.g., position, scale, rotation). By propagating the covariance of these parameters through the rendering Jacobian, we establish a highly interpretable uncertainty model. This foundation allows us to then seamlessly integrate semantic segmentation masks to produce a targeted, object-aware uncertainty score that effectively disentangles the object from its environment. This allows for a more effective active view selection strategy that prioritizes views critical to improving object fidelity. Experimental evaluations on public datasets demonstrate that our approach significantly improves the efficiency of the 3DGS reconstruction process and achieves higher quality for targeted objects compared to existing state-of-the-art methods, while also serving as a robust uncertainty estimator for the global scene.

