---
layout: default
title: Neural B-frame Video Compression with Bi-directional Reference Harmonization
---

# Neural B-frame Video Compression with Bi-directional Reference Harmonization

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.08938" target="_blank" class="toolbar-btn">arXiv: 2511.08938v1</a>
    <a href="https://arxiv.org/pdf/2511.08938.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.08938v1" 
            onclick="toggleFavorite(this, '2511.08938v1', 'Neural B-frame Video Compression with Bi-directional Reference Harmonization')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Yuxi Liu, Dengchao Jin, Shuai Huo, Jiawen Gu, Chao Zhou, Huihui Bai, Ming Lu, Zhan Ma

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-12

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/kwai/NVC)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫BRHVCÔºåÈÄöËøáÂèåÂêëÂèÇËÄÉÂ∏ßÂçèË∞É‰ºòÂåñÁ•ûÁªèBÂ∏ßËßÜÈ¢ëÂéãÁº©ÊÄßËÉΩ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `Á•ûÁªèËßÜÈ¢ëÂéãÁº©` `BÂ∏ßÂéãÁº©` `ÂèåÂêëÂèÇËÄÉÂ∏ß` `ËøêÂä®Ë°•ÂÅø` `‰∏ä‰∏ãÊñáËûçÂêà`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Á•ûÁªèBÂ∏ßËßÜÈ¢ëÂéãÁº©Èù¢‰∏¥ÊåëÊàòÔºåÂ∞§ÂÖ∂ÊòØÂú®ÂàÜÂ±ÇÁºñÁ†Å‰∏≠ÔºåÂèåÂêëÂèÇËÄÉÂ∏ßÁöÑË¥°ÁåÆÂèØËÉΩ‰∏çÂπ≥Ë°°ÔºåÂΩ±ÂìçÂéãÁº©ÊïàÁéá„ÄÇ
2. BRHVCÈÄöËøáÂèåÂêëËøêÂä®Êî∂ÊïõÔºàBMCÔºâÂíåÂèåÂêë‰∏ä‰∏ãÊñáËûçÂêàÔºàBCFÔºâÊù•ÂçèË∞ÉÂèåÂêëÂèÇËÄÉÔºå‰ºòÂåñÂèÇËÄÉ‰ø°ÊÅØÁöÑÂà©Áî®„ÄÇ
3. ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåBRHVCË∂ÖË∂ä‰∫ÜÁé∞ÊúâNVCÊñπÊ≥ïÔºåÁîöËá≥Âú®HEVCÊï∞ÊçÆÈõÜ‰∏äË∂ÖËøá‰∫Ü‰º†ÁªüÁºñÁ†ÅVTM-RA„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Á•ûÁªèËßÜÈ¢ëÂéãÁº©ÔºàNVCÔºâËøëÂπ¥Êù•ÂèñÂæó‰∫ÜÊòæËëóËøõÂ±ïÔºå‰ΩÜ‰∏éPÂ∏ßÂéãÁº©Áõ∏ÊØîÔºåÁ•ûÁªèBÂ∏ßËßÜÈ¢ëÂéãÁº©ÔºàNBVCÔºâÁöÑÁ†îÁ©∂‰ªç‰∏çÂÖÖÂàÜ„ÄÇNBVCÂèØ‰ª•ÈááÁî®ÂèåÂêëÂèÇËÄÉÂ∏ß‰ª•Ëé∑ÂæóÊõ¥Â•ΩÁöÑÂéãÁº©ÊÄßËÉΩ„ÄÇÁÑ∂ËÄåÔºåNBVCÁöÑÂàÜÂ±ÇÁºñÁ†ÅÂèØËÉΩ‰ºö‰ΩøËøûÁª≠Êó∂Èó¥È¢ÑÊµãÂ§çÊùÇÂåñÔºåÁâπÂà´ÊòØÂú®‰∏Ä‰∫õÂÖ∑ÊúâËæÉÂ§ßÂ∏ßË∑®Â∫¶ÁöÑÂ±ÇÁ∫ß‰∏äÔºåËøôÂèØËÉΩÂØºËá¥‰∏§‰∏™ÂèÇËÄÉÂ∏ßÁöÑË¥°ÁåÆ‰∏çÂπ≥Ë°°„ÄÇ‰∏∫‰∫Ü‰ºòÂåñÂèÇËÄÉ‰ø°ÊÅØÁöÑÂà©Áî®ÔºåÊàë‰ª¨ÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞ÁöÑNBVCÊñπÊ≥ïÔºåÁß∞‰∏∫ÂèåÂêëÂèÇËÄÉÂçèË∞ÉËßÜÈ¢ëÂéãÁº©ÔºàBRHVCÔºâÔºåÂÆÉÂÖ∑ÊúâÊèêÂá∫ÁöÑÂèåÂêëËøêÂä®Êî∂ÊïõÔºàBMCÔºâÂíåÂèåÂêë‰∏ä‰∏ãÊñáËûçÂêàÔºàBCFÔºâ„ÄÇBMCÂú®ËøêÂä®ÂéãÁº©‰∏≠ËûçÂêàÂ§ö‰∏™ÂÖâÊµÅÔºå‰ªéËÄåÂÆûÁé∞Êõ¥Â§ßËßÑÊ®°‰∏äÊõ¥Á≤æÁ°ÆÁöÑËøêÂä®Ë°•ÂÅø„ÄÇÁÑ∂ÂêéÔºåBCFÂú®ËøêÂä®Ë°•ÂÅøÁ≤æÂ∫¶ÁöÑÊåáÂØº‰∏ãÔºåÊòæÂºèÂú∞Âª∫Ê®°ÂèÇËÄÉ‰∏ä‰∏ãÊñáÁöÑÊùÉÈáç„ÄÇÂá≠ÂÄüÊõ¥ÊúâÊïàÁöÑËøêÂä®Âíå‰∏ä‰∏ãÊñáÔºåBRHVCÂèØ‰ª•ÊúâÊïàÂú∞ÂçèË∞ÉÂèåÂêëÂèÇËÄÉ„ÄÇÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåÊàë‰ª¨ÁöÑBRHVC‰ºò‰∫é‰ª•ÂâçÊúÄÂÖàËøõÁöÑNVCÊñπÊ≥ïÔºåÁîöËá≥Âú®HEVCÊï∞ÊçÆÈõÜ‰∏äË∂ÖËøá‰∫Ü‰º†ÁªüÁöÑÁºñÁ†ÅVTM-RAÔºàÂú®ÈöèÊú∫ËÆøÈóÆÈÖçÁΩÆ‰∏ãÔºâ„ÄÇÊ∫ê‰ª£Á†ÅÂ∑≤Âú®https://github.com/kwai/NVC‰∏äÂèëÂ∏É„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁ•ûÁªèBÂ∏ßËßÜÈ¢ëÂéãÁº©(NBVC)Êó®Âú®Âà©Áî®ÂèåÂêëÂèÇËÄÉÂ∏ßÊèêÈ´òËßÜÈ¢ëÂéãÁº©ÊïàÁéá„ÄÇÁÑ∂ËÄåÔºåNBVCÁöÑÂàÜÂ±ÇÁºñÁ†ÅÁªìÊûÑÂØºËá¥Êó∂Èó¥È¢ÑÊµãÂ§çÊùÇÂåñÔºåÂ∞§ÂÖ∂ÊòØÂú®Â∏ßË∑®Â∫¶ËæÉÂ§ßÁöÑÂ±ÇÁ∫ßÔºå‰∏§‰∏™ÂèÇËÄÉÂ∏ßÁöÑË¥°ÁåÆÂèØËÉΩ‰∏çÂπ≥Ë°°ÔºåÂΩ±ÂìçÂéãÁº©ÊÄßËÉΩ„ÄÇÁé∞ÊúâÊñπÊ≥ïÈöæ‰ª•ÊúâÊïàÂçèË∞ÉÂèåÂêëÂèÇËÄÉ‰ø°ÊÅØÔºåÂØºËá¥ÂéãÁº©ÊïàÁéáÂèóÈôê„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöBRHVCÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÈÄöËøáÂèåÂêëËøêÂä®Êî∂Êïõ(BMC)ÂíåÂèåÂêë‰∏ä‰∏ãÊñáËûçÂêà(BCF)Êù•ÊòæÂºèÂú∞Âª∫Ê®°ÂíåÂçèË∞ÉÂèåÂêëÂèÇËÄÉÂ∏ßÁöÑ‰ø°ÊÅØ„ÄÇBMCÊó®Âú®Êõ¥Á≤æÁ°ÆÂú∞‰º∞ËÆ°ËøêÂä®‰ø°ÊÅØÔºåËÄåBCFÂàôÊ†πÊçÆËøêÂä®Ë°•ÂÅøÁöÑÁ≤æÂ∫¶Ëá™ÈÄÇÂ∫îÂú∞ËûçÂêàÂèÇËÄÉ‰∏ä‰∏ãÊñáÔºå‰ªéËÄå‰ºòÂåñÂèÇËÄÉ‰ø°ÊÅØÁöÑÂà©Áî®„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöBRHVCÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) ËøêÂä®‰º∞ËÆ°Ê®°ÂùóÔºöÁî®‰∫é‰º∞ËÆ°ÂèåÂêëÂÖâÊµÅÔºõ2) ÂèåÂêëËøêÂä®Êî∂Êïõ(BMC)Ê®°ÂùóÔºöËûçÂêàÂ§ö‰∏™ÂÖâÊµÅÔºåÊèêÈ´òËøêÂä®Ë°•ÂÅøÁöÑÂáÜÁ°ÆÊÄßÔºõ3) ËøêÂä®Ë°•ÂÅøÊ®°ÂùóÔºöÂà©Áî®Êî∂ÊïõÂêéÁöÑËøêÂä®‰ø°ÊÅØËøõË°åËøêÂä®Ë°•ÂÅøÔºõ4) ÂèåÂêë‰∏ä‰∏ãÊñáËûçÂêà(BCF)Ê®°ÂùóÔºöÊ†πÊçÆËøêÂä®Ë°•ÂÅøÁöÑÁ≤æÂ∫¶ÔºåËá™ÈÄÇÂ∫îÂú∞ËûçÂêàÂèÇËÄÉ‰∏ä‰∏ãÊñáÔºõ5) ÊÆãÂ∑ÆÁºñÁ†ÅÊ®°ÂùóÔºöÂØπËøêÂä®Ë°•ÂÅøÂêéÁöÑÊÆãÂ∑ÆËøõË°åÁºñÁ†Å„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöBRHVCÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÊèêÂá∫‰∫ÜBMCÂíåBCF‰∏§‰∏™Ê®°Âùó„ÄÇBMCÈÄöËøáËûçÂêàÂ§ö‰∏™ÂÖâÊµÅÊù•ÊèêÈ´òËøêÂä®Ë°•ÂÅøÁöÑÂáÜÁ°ÆÊÄßÔºåËøô‰∏é‰º†ÁªüÊñπÊ≥ï‰∏≠‰ªÖ‰ΩøÁî®Âçï‰∏™ÂÖâÊµÅ‰∏çÂêå„ÄÇBCFÂàôÊ†πÊçÆËøêÂä®Ë°•ÂÅøÁöÑÁ≤æÂ∫¶Ëá™ÈÄÇÂ∫îÂú∞ËûçÂêàÂèÇËÄÉ‰∏ä‰∏ãÊñáÔºåËøô‰ΩøÂæóÊ®°ÂûãËÉΩÂ§üÊõ¥Â•ΩÂú∞Âà©Áî®ÂèÇËÄÉ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÈ´òÂéãÁº©ÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöBMCÊ®°ÂùóÈááÁî®‰∫Ü‰∏ÄÁßçÂä†ÊùÉÂπ≥ÂùáÁöÑÊñπÊ≥ïÊù•ËûçÂêàÂ§ö‰∏™ÂÖâÊµÅÔºåÊùÉÈáçÁî±ÂÖâÊµÅÁöÑÁΩÆ‰ø°Â∫¶ÂÜ≥ÂÆö„ÄÇBCFÊ®°Âùó‰ΩøÁî®‰∫Ü‰∏Ä‰∏™Ê≥®ÊÑèÂäõÊú∫Âà∂Êù•Âª∫Ê®°ÂèÇËÄÉ‰∏ä‰∏ãÊñáÁöÑÊùÉÈáçÔºåÊ≥®ÊÑèÂäõÊùÉÈáçÁî±ËøêÂä®Ë°•ÂÅøÁöÑÁ≤æÂ∫¶ÂÜ≥ÂÆö„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨ÈáçÂª∫ÊçüÂ§±„ÄÅÁéáÂ§±ÁúüÊçüÂ§±Á≠âÔºåÁî®‰∫é‰ºòÂåñÊ®°ÂûãÁöÑÊÄßËÉΩ„ÄÇÂÖ∑‰ΩìÁöÑÁΩëÁªúÁªìÊûÑÁªÜËäÇÂíåÂèÇÊï∞ËÆæÁΩÆÂú®ËÆ∫Êñá‰∏≠ÊúâËØ¶ÁªÜÊèèËø∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

BRHVCÂú®HEVCÊï∞ÊçÆÈõÜ‰∏äËøõË°å‰∫ÜÂÆûÈ™åÔºåÁªìÊûúË°®ÊòéÔºåBRHVC‰ºò‰∫éÁé∞ÊúâÁöÑÁ•ûÁªèËßÜÈ¢ëÂéãÁº©ÊñπÊ≥ïÔºåÁîöËá≥Ë∂ÖËøá‰∫Ü‰º†ÁªüÁöÑËßÜÈ¢ëÁºñÁ†ÅÊ†áÂáÜVTM-RAÔºàÂú®ÈöèÊú∫ËÆøÈóÆÈÖçÁΩÆ‰∏ãÔºâ„ÄÇËøôË°®ÊòéBRHVCÂú®ËßÜÈ¢ëÂéãÁº©ÊÄßËÉΩÊñπÈù¢ÂÖ∑ÊúâÊòæËëóÁöÑ‰ºòÂäøÔºåËÉΩÂ§üÊúâÊïàÂú∞ÊèêÈ´òËßÜÈ¢ëÂéãÁº©ÊïàÁéá„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫éÂêÑÁßçËßÜÈ¢ëÂéãÁº©Âú∫ÊôØÔºå‰æãÂ¶ÇËßÜÈ¢ë‰ºöËÆÆ„ÄÅÂú®Á∫øËßÜÈ¢ëÊµÅÂ™í‰Ωì„ÄÅËßÜÈ¢ëÁõëÊéßÁ≠â„ÄÇÈÄöËøáÊèêÈ´òËßÜÈ¢ëÂéãÁº©ÊïàÁéáÔºåÂèØ‰ª•Èôç‰ΩéÂ∏¶ÂÆΩÈúÄÊ±ÇÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™åÔºåÂπ∂Èôç‰ΩéÂ≠òÂÇ®ÊàêÊú¨„ÄÇÊú™Êù•ÔºåËØ•ÊäÄÊúØÊúâÊúõÂ∫îÁî®‰∫éÊõ¥È´òÂàÜËæ®Áéá„ÄÅÊõ¥È´òÂ∏ßÁéáÁöÑËßÜÈ¢ëÂéãÁº©Ôºå‰ª•ÂèäÁßªÂä®ËÆæÂ§áÁöÑÂÆûÊó∂ËßÜÈ¢ëÂéãÁº©„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Neural video compression (NVC) has made significant progress in recent years, while neural B-frame video compression (NBVC) remains underexplored compared to P-frame compression. NBVC can adopt bi-directional reference frames for better compression performance. However, NBVC's hierarchical coding may complicate continuous temporal prediction, especially at some hierarchical levels with a large frame span, which could cause the contribution of the two reference frames to be unbalanced. To optimize reference information utilization, we propose a novel NBVC method, termed Bi-directional Reference Harmonization Video Compression (BRHVC), with the proposed Bi-directional Motion Converge (BMC) and Bi-directional Contextual Fusion (BCF). BMC converges multiple optical flows in motion compression, leading to more accurate motion compensation on a larger scale. Then BCF explicitly models the weights of reference contexts under the guidance of motion compensation accuracy. With more efficient motions and contexts, BRHVC can effectively harmonize bi-directional references. Experimental results indicate that our BRHVC outperforms previous state-of-the-art NVC methods, even surpassing the traditional coding, VTM-RA (under random access configuration), on the HEVC datasets. The source code is released at https://github.com/kwai/NVC.

