---
layout: default
title: Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation
---

# Expand Your SCOPE: Semantic Cognition over Potential-Based Exploration for Embodied Visual Navigation

**arXiv**: [2511.08935v1](https://arxiv.org/abs/2511.08935) | [PDF](https://arxiv.org/pdf/2511.08935.pdf)

**ä½œè€…**: Ningnan Wang, Weihuang Chen, Liming Chen, Haoxuan Ji, Zhongyu Guo, Xuchong Zhang, Hongbin Sun

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSCOPEæ¡†æž¶ä»¥è§£å†³å…·èº«è§†è§‰å¯¼èˆªä¸­çš„æŽ¢ç´¢ä¸Žè§„åˆ’é—®é¢˜**

**å…³é”®è¯**: `å…·èº«è§†è§‰å¯¼èˆª` `é›¶æ ·æœ¬å­¦ä¹ ` `æŽ¢ç´¢æ½œåŠ›` `æ—¶ç©ºå›¾` `è‡ªåæ€æœºåˆ¶` `è§†è§‰è¯­è¨€æ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰é›¶æ ·æœ¬æ–¹æ³•å¿½è§†è§†è§‰è¾¹ç•Œï¼Œå½±å“é•¿ç¨‹è§„åˆ’ä¸Žç›®æ ‡æŽ¨ç†ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šåˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡åž‹ä¼°è®¡æŽ¢ç´¢æ½œåŠ›ï¼Œæž„å»ºæ—¶ç©ºå›¾å¹¶é›†æˆè‡ªåæ€æœºåˆ¶ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä¸¤é¡¹å¯¼èˆªä»»åŠ¡ä¸­å‡†ç¡®çŽ‡æå‡4.6%ï¼Œæ”¹å–„æ ¡å‡†ä¸Žæ³›åŒ–èƒ½åŠ›ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Embodied visual navigation remains a challenging task, as agents must explore unknown environments with limited knowledge. Existing zero-shot studies have shown that incorporating memory mechanisms to support goal-directed behavior can improve long-horizon planning performance. However, they overlook visual frontier boundaries, which fundamentally dictate future trajectories and observations, and fall short of inferring the relationship between partial visual observations and navigation goals. In this paper, we propose Semantic Cognition Over Potential-based Exploration (SCOPE), a zero-shot framework that explicitly leverages frontier information to drive potential-based exploration, enabling more informed and goal-relevant decisions. SCOPE estimates exploration potential with a Vision-Language Model and organizes it into a spatio-temporal potential graph, capturing boundary dynamics to support long-horizon planning. In addition, SCOPE incorporates a self-reconsideration mechanism that revisits and refines prior decisions, enhancing reliability and reducing overconfident errors. Experimental results on two diverse embodied navigation tasks show that SCOPE outperforms state-of-the-art baselines by 4.6\% in accuracy. Further analysis demonstrates that its core components lead to improved calibration, stronger generalization, and higher decision quality.

