---
layout: default
title: APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots
---

# APEX: Action Priors Enable Efficient Exploration for Robust Motion Tracking on Legged Robots

**arXiv**: [2511.09091v1](https://arxiv.org/abs/2511.09091) | [PDF](https://arxiv.org/pdf/2511.09091.pdf)

**ä½œè€…**: Shivam Sood, Laukik Nakhwa, Sun Ge, Yuhong Cao, Jin Cheng, Fatemah Zargarbashi, Taerim Yoon, Sungjoon Choi, Stelian Coros, Guillaume Sartoretti

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºAPEXæ–¹æ³•ä»¥æå‡è…¿å¼æœºå™¨äººè¿åŠ¨è·Ÿè¸ªçš„é²æ£’æ€§å’Œæ•ˆçŽ‡**

**å…³é”®è¯**: `è…¿å¼æœºå™¨äºº` `å¼ºåŒ–å­¦ä¹ ` `åŠ¨ä½œå…ˆéªŒ` `è¿åŠ¨è·Ÿè¸ª` `æ ·æœ¬æ•ˆçŽ‡` `é²æ£’æŽ§åˆ¶`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šçŽ°æœ‰è¿åŠ¨è·Ÿè¸ªæ–¹æ³•ä¾èµ–å‚è€ƒæ•°æ®ï¼Œé€‚åº”æ€§å·®ä¸”éœ€å¤§é‡è°ƒå‚
2. æ–¹æ³•è¦ç‚¹ï¼šé›†æˆè¡°å‡åŠ¨ä½œå…ˆéªŒå’Œå¤šè¯„ä»·å™¨æ¡†æž¶ï¼Œå¼•å¯¼å¼ºåŒ–å­¦ä¹ æŽ¢ç´¢
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žæœºå™¨äººä¸ŠéªŒè¯ï¼Œæé«˜ç¨³å®šæ€§ã€æ•ˆçŽ‡å’Œæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Learning natural, animal-like locomotion from demonstrations has become a core paradigm in legged robotics. Despite the recent advancements in motion tracking, most existing methods demand extensive tuning and rely on reference data during deployment, limiting adaptability. We present APEX (Action Priors enable Efficient Exploration), a plug-and-play extension to state-of-the-art motion tracking algorithms that eliminates any dependence on reference data during deployment, improves sample efficiency, and reduces parameter tuning effort. APEX integrates expert demonstrations directly into reinforcement learning (RL) by incorporating decaying action priors, which initially bias exploration toward expert demonstrations but gradually allow the policy to explore independently. This is combined with a multi-critic framework that balances task performance with motion style. Moreover, APEX enables a single policy to learn diverse motions and transfer reference-like styles across different terrains and velocities, while remaining robust to variations in reward design. We validate the effectiveness of our method through extensive experiments in both simulation and on a Unitree Go2 robot. By leveraging demonstrations to guide exploration during RL training, without imposing explicit bias toward them, APEX enables legged robots to learn with greater stability, efficiency, and generalization. We believe this approach paves the way for guidance-driven RL to boost natural skill acquisition in a wide array of robotic tasks, from locomotion to manipulation. Website and code: https://marmotlab.github.io/APEX/.

