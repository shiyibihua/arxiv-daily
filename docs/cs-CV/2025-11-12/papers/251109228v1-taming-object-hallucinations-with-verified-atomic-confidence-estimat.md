---
layout: default
title: Taming Object Hallucinations with Verified Atomic Confidence Estimation
---

# Taming Object Hallucinations with Verified Atomic Confidence Estimation

**arXiv**: [2511.09228v1](https://arxiv.org/abs/2511.09228) | [PDF](https://arxiv.org/pdf/2511.09228.pdf)

**ä½œè€…**: Jiarui Liu, Weihao Xuan, Zhijing Jin, Mona Diab

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºTACOæ¡†æž¶ä»¥ç¼“è§£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹ä¸­çš„å¹»è§‰é—®é¢˜**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `å¹»è§‰ç¼“è§£` `ç½®ä¿¡åº¦ä¼°è®¡` `è‡ªéªŒè¯` `åŸºå‡†æµ‹è¯•`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹å¸¸å‡ºçŽ°ç‰©ä½“å­˜åœ¨ã€å±žæ€§æˆ–å…³ç³»çš„å¹»è§‰é”™è¯¯
2. TACOé€šè¿‡åˆ†è§£å“åº”ã€æ”¹å†™æŸ¥è¯¢å’Œç½®ä¿¡åº¦ä¼°è®¡è¿›è¡Œè‡ªéªŒè¯
3. åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼ŒTACOä¼˜äºŽç›´æŽ¥æç¤ºå’Œè§†è§‰å¯¹æ¯”è§£ç æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal Large Language Models (MLLMs) often suffer from hallucinations, particularly errors in object existence, attributes, or relations, which undermine their reliability. We introduce TACO (Verified Atomic Confidence Estimation), a simple framework that mitigates hallucinations through self-verification and confidence calibration without relying on external vision experts. TACO decomposes responses into atomic queries, paraphrases them to reduce sensitivity to wording, and estimates confidence using self-consistency (black-box) or self-confidence (gray-box) aggregation, before refining answers with a language model. Experiments on five benchmarks (POPE, MME, HallusionBench, AMBER, and MM-Hal Bench) with two MLLMs (\texttt{LLaVA-1.5-7B} and \texttt{CogVLM2}) show that TACO consistently outperforms direct prompting and Visual Contrastive Decoding, reduces systematic biases, and improves confidence calibration, demonstrating its effectiveness in enhancing the faithfulness of MLLMs.

