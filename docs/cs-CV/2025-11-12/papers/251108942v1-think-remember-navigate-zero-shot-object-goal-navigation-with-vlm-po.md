---
layout: default
title: Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning
---

# Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning

**arXiv**: [2511.08942v1](https://arxiv.org/abs/2511.08942) | [PDF](https://arxiv.org/pdf/2511.08942.pdf)

**ä½œè€…**: Mobin Habibpour, Fatemeh Afghah

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVLMé©±åŠ¨æŽ¨ç†æ¡†æž¶ä»¥æå‡é›¶æ ·æœ¬ç›®æ ‡å¯¼èˆªæ•ˆçŽ‡**

**å…³é”®è¯**: `é›¶æ ·æœ¬ç›®æ ‡å¯¼èˆª` `è§†è§‰è¯­è¨€æ¨¡åž‹` `æŽ¨ç†è§„åˆ’` `ç©ºé—´æ„ŸçŸ¥å¢žå¼º` `æœºå™¨äººå¯¼èˆª`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•æœªå……åˆ†åˆ©ç”¨VLMæŽ¨ç†èƒ½åŠ›ï¼Œå¯¼è‡´å¯¼èˆªæ•ˆçŽ‡ä½Žä¸‹
2. é‡‡ç”¨ç»“æž„åŒ–æ€ç»´é“¾æç¤ºã€åŠ¨æ€åŠ¨ä½œåŽ†å²å’Œéšœç¢åœ°å›¾è§£é‡Šå¢žå¼ºVLMè§„åˆ’
3. åœ¨HM3Dç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œè½¨è¿¹æ›´ç›´æŽ¥é«˜æ•ˆï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> While Vision-Language Models (VLMs) are set to transform robotic navigation, existing methods often underutilize their reasoning capabilities. To unlock the full potential of VLMs in robotics, we shift their role from passive observers to active strategists in the navigation process. Our framework outsources high-level planning to a VLM, which leverages its contextual understanding to guide a frontier-based exploration agent. This intelligent guidance is achieved through a trio of techniques: structured chain-of-thought prompting that elicits logical, step-by-step reasoning; dynamic inclusion of the agent's recent action history to prevent getting stuck in loops; and a novel capability that enables the VLM to interpret top-down obstacle maps alongside first-person views, thereby enhancing spatial awareness. When tested on challenging benchmarks like HM3D, Gibson, and MP3D, this method produces exceptionally direct and logical trajectories, marking a substantial improvement in navigation efficiency over existing approaches and charting a path toward more capable embodied agents.

