---
layout: default
title: From Structure to Detail: Hierarchical Distillation for Efficient Diffusion Model
---

# From Structure to Detail: Hierarchical Distillation for Efficient Diffusion Model

**arXiv**: [2511.08930v1](https://arxiv.org/abs/2511.08930) | [PDF](https://arxiv.org/pdf/2511.08930.pdf)

**ä½œè€…**: Hanbo Cheng, Peng Wang, Kaixiang Lei, Qi Li, Zhen Zou, Pengfei Hu, Jun Du

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåˆ†å±‚è’¸é¦æ¡†æž¶ä»¥è§£å†³æ‰©æ•£æ¨¡åž‹æŽ¨ç†å»¶è¿Ÿé—®é¢˜**

**å…³é”®è¯**: `æ‰©æ•£æ¨¡åž‹` `æ¨¡åž‹è’¸é¦` `æŽ¨ç†åŠ é€Ÿ` `å¯¹æŠ—è®­ç»ƒ` `å›¾åƒç”Ÿæˆ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ‰©æ•£æ¨¡åž‹æŽ¨ç†å»¶è¿Ÿé«˜ï¼Œè½¨è¿¹ä¸Žåˆ†å¸ƒè’¸é¦æ–¹æ³•å­˜åœ¨æƒè¡¡é—®é¢˜
2. åˆ†å±‚è’¸é¦ç»“åˆè½¨è¿¹è’¸é¦æä¾›ç»“æž„è‰å›¾ï¼Œåˆ†å¸ƒè’¸é¦è¿›è¡Œç»†èŠ‚ä¼˜åŒ–
3. åœ¨ImageNetç­‰ä»»åŠ¡ä¸­å®žçŽ°å•æ­¥FID 2.26ï¼Œåª²ç¾Žå¤šæ­¥æ•™å¸ˆæ¨¡åž‹

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> The inference latency of diffusion models remains a critical barrier to their real-time application. While trajectory-based and distribution-based step distillation methods offer solutions, they present a fundamental trade-off. Trajectory-based methods preserve global structure but act as a "lossy compressor", sacrificing high-frequency details. Conversely, distribution-based methods can achieve higher fidelity but often suffer from mode collapse and unstable training. This paper recasts them from independent paradigms into synergistic components within our novel Hierarchical Distillation (HD) framework. We leverage trajectory distillation not as a final generator, but to establish a structural ``sketch", providing a near-optimal initialization for the subsequent distribution-based refinement stage. This strategy yields an ideal initial distribution that enhances the ceiling of overall performance. To further improve quality, we introduce and refine the adversarial training process. We find standard discriminator structures are ineffective at refining an already high-quality generator. To overcome this, we introduce the Adaptive Weighted Discriminator (AWD), tailored for the HD pipeline. By dynamically allocating token weights, AWD focuses on local imperfections, enabling efficient detail refinement. Our approach demonstrates state-of-the-art performance across diverse tasks. On ImageNet $256\times256$, our single-step model achieves an FID of 2.26, rivaling its 250-step teacher. It also achieves promising results on the high-resolution text-to-image MJHQ benchmark, proving its generalizability. Our method establishes a robust new paradigm for high-fidelity, single-step diffusion models.

