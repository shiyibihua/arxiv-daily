---
layout: default
title: SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation
---

# SpatialActor: Exploring Disentangled Spatial Representations for Robust Robotic Manipulation

**arXiv**: [2511.09555v1](https://arxiv.org/abs/2511.09555) | [PDF](https://arxiv.org/pdf/2511.09555.pdf)

**ä½œè€…**: Hao Shi, Bin Xie, Yingfei Liu, Yang Yue, Tiancai Wang, Haoqiang Fan, Xiangyu Zhang, Gao Huang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpatialActoræ¡†æž¶ä»¥è§£å†³æœºå™¨äººæ“ä½œä¸­è¯­ä¹‰ä¸Žå‡ ä½•çº ç¼ é—®é¢˜**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§£è€¦è¡¨ç¤º` `ç©ºé—´å˜æ¢å™¨` `è¯­ä¹‰å‡ ä½•èžåˆ` `é²æ£’æ€§å¢žå¼º`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šåŸºäºŽç‚¹æˆ–å›¾åƒçš„æ–¹æ³•å› è¯­ä¹‰ä¸Žå‡ ä½•çº ç¼ ï¼Œå¯¹æ·±åº¦å™ªå£°æ•æ„Ÿï¼Œä¸”å¿½ç•¥ä½Žå±‚ç©ºé—´çº¿ç´¢ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé€šè¿‡è§£è€¦è¯­ä¹‰ä¸Žå‡ ä½•ï¼Œèžåˆå™ªå£°æ·±åº¦ä¸Žè¯­ä¹‰å…ˆéªŒï¼Œå¹¶åˆ©ç”¨ç©ºé—´å˜æ¢å™¨å¢žå¼º2D-3Dæ˜ å°„ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨RLBenchä¸Šè¾¾87.4%æˆåŠŸçŽ‡ï¼Œå™ªå£°æ¡ä»¶ä¸‹æå‡13.9%-19.4%ï¼Œå¢žå¼ºæ³›åŒ–ä¸Žé²æ£’æ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Robotic manipulation requires precise spatial understanding to interact with objects in the real world. Point-based methods suffer from sparse sampling, leading to the loss of fine-grained semantics. Image-based methods typically feed RGB and depth into 2D backbones pre-trained on 3D auxiliary tasks, but their entangled semantics and geometry are sensitive to inherent depth noise in real-world that disrupts semantic understanding. Moreover, these methods focus on high-level geometry while overlooking low-level spatial cues essential for precise interaction. We propose SpatialActor, a disentangled framework for robust robotic manipulation that explicitly decouples semantics and geometry. The Semantic-guided Geometric Module adaptively fuses two complementary geometry from noisy depth and semantic-guided expert priors. Also, a Spatial Transformer leverages low-level spatial cues for accurate 2D-3D mapping and enables interaction among spatial features. We evaluate SpatialActor on multiple simulation and real-world scenarios across 50+ tasks. It achieves state-of-the-art performance with 87.4% on RLBench and improves by 13.9% to 19.4% under varying noisy conditions, showing strong robustness. Moreover, it significantly enhances few-shot generalization to new tasks and maintains robustness under various spatial perturbations. Project Page: https://shihao1895.github.io/SpatialActor

