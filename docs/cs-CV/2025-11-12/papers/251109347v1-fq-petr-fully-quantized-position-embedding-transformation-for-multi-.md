---
layout: default
title: FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection
---

# FQ-PETR: Fully Quantized Position Embedding Transformation for Multi-View 3D Object Detection

**arXiv**: [2511.09347v1](https://arxiv.org/abs/2511.09347) | [PDF](https://arxiv.org/pdf/2511.09347.pdf)

**ä½œè€…**: Jiangyong Yu, Changyong Shu, Sifan Zhou, Zichen Yu, Xing Hu, Yan Chen, Dawei Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºFQ-PETRå…¨é‡åŒ–æ¡†æž¶ä»¥è§£å†³å¤šè§†å›¾3Dæ£€æµ‹éƒ¨ç½²ä¸­çš„ç²¾åº¦ä¸Žæ•ˆçŽ‡é—®é¢˜**

**å…³é”®è¯**: `å¤šè§†å›¾3Dæ£€æµ‹` `ç¥žç»ç½‘ç»œé‡åŒ–` `ä½ç½®åµŒå…¥ä¼˜åŒ–` `éžçº¿æ€§ç®—å­è¿‘ä¼¼` `è‡ªåŠ¨é©¾é©¶è§†è§‰`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šPETRç³»åˆ—æ¨¡åž‹é‡åŒ–åŽç²¾åº¦ä¸¥é‡ä¸‹é™ï¼ŒæºäºŽå¤šæ¨¡æ€ç‰¹å¾å°ºåº¦å·®å¼‚å’Œéžçº¿æ€§ç®—å­é‡åŒ–è¯¯å·®
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥é‡åŒ–å‹å¥½ä½ç½®åµŒå…¥ã€åŒæŸ¥æ‰¾è¡¨è¿‘ä¼¼éžçº¿æ€§å‡½æ•°ã€é‡åŒ–åŽæ•°å€¼ç¨³å®šåŒ–
3. å®žéªŒæˆ–æ•ˆæžœï¼šW8A8é‡åŒ–ä¸‹ç²¾åº¦æŸå¤±ä»…1%ï¼Œå»¶è¿Ÿé™ä½Ž75%ï¼Œä¼˜äºŽçŽ°æœ‰é‡åŒ–æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Camera-based multi-view 3D detection is crucial for autonomous driving. PETR and its variants (PETRs) excel in benchmarks but face deployment challenges due to high computational cost and memory footprint. Quantization is an effective technique for compressing deep neural networks by reducing the bit width of weights and activations. However, directly applying existing quantization methods to PETRs leads to severe accuracy degradation. This issue primarily arises from two key challenges: (1) significant magnitude disparity between multi-modal features-specifically, image features and camera-ray positional embeddings (PE), and (2) the inefficiency and approximation error of quantizing non-linear operators, which commonly rely on hardware-unfriendly computations. In this paper, we propose FQ-PETR, a fully quantized framework for PETRs, featuring three key innovations: (1) Quantization-Friendly LiDAR-ray Position Embedding (QFPE): Replacing multi-point sampling with LiDAR-prior-guided single-point sampling and anchor-based embedding eliminates problematic non-linearities (e.g., inverse-sigmoid) and aligns PE scale with image features, preserving accuracy. (2) Dual-Lookup Table (DULUT): This algorithm approximates complex non-linear functions using two cascaded linear LUTs, achieving high fidelity with minimal entries and no specialized hardware. (3) Quantization After Numerical Stabilization (QANS): Performing quantization after softmax numerical stabilization mitigates attention distortion from large inputs. On PETRs (e.g. PETR, StreamPETR, PETRv2, MV2d), FQ-PETR under W8A8 achieves near-floating-point accuracy (1% degradation) while reducing latency by up to 75%, significantly outperforming existing PTQ and QAT baselines.

