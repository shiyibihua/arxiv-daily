---
layout: default
title: Diversifying Counterattacks: Orthogonal Exploration for Robust CLIP Inference
---

# Diversifying Counterattacks: Orthogonal Exploration for Robust CLIP Inference

**arXiv**: [2511.09064v1](https://arxiv.org/abs/2511.09064) | [PDF](https://arxiv.org/pdf/2511.09064.pdf)

**ä½œè€…**: Chengze Jiang, Minjing Dong, Xinli Shi, Jie Gui

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæ–¹å‘æ­£äº¤åæ”»å‡»ä»¥å¢žå¼ºCLIPæŽ¨ç†çš„å¯¹æŠ—é²æ£’æ€§**

**å…³é”®è¯**: `å¯¹æŠ—é²æ£’æ€§` `è§†è§‰è¯­è¨€é¢„è®­ç»ƒ` `åæ”»å‡»æ–¹æ³•` `æ­£äº¤æ¢¯åº¦` `æµ‹è¯•æ—¶é˜²å¾¡` `CLIPæ¨¡åž‹`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¯¹æŠ—æ ·æœ¬ä½¿è§†è§‰è¯­è¨€é¢„è®­ç»ƒæ¨¡åž‹æ˜“å—æ”»å‡»ï¼ŒçŽ°æœ‰åæ”»å‡»æ–¹æ³•ç¼ºä¹å¤šæ ·æ€§ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥æ­£äº¤æ¢¯åº¦æ–¹å‘å’ŒåŠ¨é‡æ›´æ–°ï¼Œæ‰©å±•åæ”»å‡»ç©ºé—´æŽ¢ç´¢ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨16ä¸ªæ•°æ®é›†ä¸ŠéªŒè¯ï¼Œæå‡å¯¹æŠ—é²æ£’æ€§å¹¶ä¿æŒæ¸…æ´å‡†ç¡®çŽ‡ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vision-language pre-training models (VLPs) demonstrate strong multimodal understanding and zero-shot generalization, yet remain vulnerable to adversarial examples, raising concerns about their reliability. Recent work, Test-Time Counterattack (TTC), improves robustness by generating perturbations that maximize the embedding deviation of adversarial inputs using PGD, pushing them away from their adversarial representations. However, due to the fundamental difference in optimization objectives between adversarial attacks and counterattacks, generating counterattacks solely based on gradients with respect to the adversarial input confines the search to a narrow space. As a result, the counterattacks could overfit limited adversarial patterns and lack the diversity to fully neutralize a broad range of perturbations. In this work, we argue that enhancing the diversity and coverage of counterattacks is crucial to improving adversarial robustness in test-time defense. Accordingly, we propose Directional Orthogonal Counterattack (DOC), which augments counterattack optimization by incorporating orthogonal gradient directions and momentum-based updates. This design expands the exploration of the counterattack space and increases the diversity of perturbations, which facilitates the discovery of more generalizable counterattacks and ultimately improves the ability to neutralize adversarial perturbations. Meanwhile, we present a directional sensitivity score based on averaged cosine similarity to boost DOC by improving example discrimination and adaptively modulating the counterattack strength. Extensive experiments on 16 datasets demonstrate that DOC improves adversarial robustness under various attacks while maintaining competitive clean accuracy. Code is available at https://github.com/bookman233/DOC.

