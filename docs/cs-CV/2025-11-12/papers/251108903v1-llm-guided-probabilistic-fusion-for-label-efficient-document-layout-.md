---
layout: default
title: LLM-Guided Probabilistic Fusion for Label-Efficient Document Layout Analysis
---

# LLM-Guided Probabilistic Fusion for Label-Efficient Document Layout Analysis

**arXiv**: [2511.08903v1](https://arxiv.org/abs/2511.08903) | [PDF](https://arxiv.org/pdf/2511.08903.pdf)

**ä½œè€…**: Ibne Farabi Shihab, Sanjeda Akter, Anuj Sharma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºLLMå¼•å¯¼çš„æ¦‚çŽ‡èžåˆæ–¹æ³•ï¼Œä»¥è§£å†³æ–‡æ¡£å¸ƒå±€åˆ†æžä¸­æ ‡ç­¾æ•ˆçŽ‡ä½Žçš„é—®é¢˜ã€‚**

**å…³é”®è¯**: `æ–‡æ¡£å¸ƒå±€åˆ†æž` `åŠç›‘ç£å­¦ä¹ ` `æ¦‚çŽ‡èžåˆ` `LLMå…ˆéªŒ` `ä¼ªæ ‡ç­¾ç”Ÿæˆ` `è½»é‡çº§éª¨å¹²ç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ–‡æ¡£å¸ƒå±€ç†è§£ä¾èµ–å¤§é‡æ ‡æ³¨æ•°æ®ï¼ŒåŠç›‘ç£å­¦ä¹ ä»ä¸è¶³ã€‚
2. èžåˆè§†è§‰æ£€æµ‹ä¸ŽLLMç»“æž„å…ˆéªŒï¼Œé€šè¿‡æ¦‚çŽ‡åŠ æƒç”Ÿæˆä¼ªæ ‡ç­¾ã€‚
3. åœ¨PubLayNetä¸Šï¼Œä½¿ç”¨5%æ ‡ç­¾è¾¾åˆ°88.2 APï¼Œè¶…è¶ŠåŸºçº¿æ–¹æ³•ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Document layout understanding remains data-intensive despite advances in semi-supervised learning. We present a framework that enhances semi-supervised detection by fusing visual predictions with structural priors from text-pretrained LLMs via principled probabilistic weighting. Given unlabeled documents, an OCR-LLM pipeline infers hierarchical regions which are combined with teacher detector outputs through inverse-variance fusion to generate refined pseudo-labels.Our method demonstrates consistent gains across model scales. With a lightweight SwiftFormer backbone (26M params), we achieve 88.2$\pm$0.3 AP using only 5\% labels on PubLayNet. When applied to document-pretrained LayoutLMv3 (133M params), our fusion framework reaches 89.7$\pm$0.4 AP, surpassing both LayoutLMv3 with standard semi-supervised learning (89.1$\pm$0.4 AP, p=0.02) and matching UDOP~\cite{udop} (89.8 AP) which requires 100M+ pages of multimodal pretraining. This demonstrates that LLM structural priors are complementary to both lightweight and pretrained architectures. Key findings include: (1) learned instance-adaptive gating improves over fixed weights by +0.9 AP with data-dependent PAC bounds correctly predicting convergence; (2) open-source LLMs enable privacy-preserving deployment with minimal loss (Llama-3-70B: 87.1 AP lightweight, 89.4 AP with LayoutLMv3); (3) LLMs provide targeted semantic disambiguation (18.7\% of cases, +3.8 AP gain) beyond simple text heuristics.Total system cost includes \$12 for GPT-4o-mini API or 17 GPU-hours for local Llama-3-70B per 50K pages, amortized across training runs.

