---
layout: default
title: SPEED-Q: Staged Processing with Enhanced Distillation towards Efficient Low-bit On-device VLM Quantization
---

# SPEED-Q: Staged Processing with Enhanced Distillation towards Efficient Low-bit On-device VLM Quantization

**arXiv**: [2511.08914v1](https://arxiv.org/abs/2511.08914) | [PDF](https://arxiv.org/pdf/2511.08914.pdf)

**ä½œè€…**: Tianyu Guo, Shanwei Zhao, Shiai Zhu, Chenguang Ma

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSPEED-Qæ¡†æž¶ä»¥è§£å†³è¾¹ç¼˜è®¾å¤‡ä¸Šè§†è§‰è¯­è¨€æ¨¡åž‹çš„ä½Žæ¯”ç‰¹é‡åŒ–éš¾é¢˜**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡åž‹` `ä½Žæ¯”ç‰¹é‡åŒ–` `è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²` `è’¸é¦è®­ç»ƒ` `åˆ†é˜¶æ®µå¤„ç†` `æ¨¡åž‹åŽ‹ç¼©`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šè§†è§‰ä¸Žè¯­è¨€ç»„ä»¶é‡åŒ–æ•æ„Ÿåº¦å·®å¼‚å¤§ï¼Œä½Žæ¯”ç‰¹é‡åŒ–å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨åˆ†é˜¶æ®µæ•æ„Ÿåº¦è‡ªé€‚åº”æœºåˆ¶å’Œè’¸é¦å¢žå¼ºç­–ç•¥ï¼Œæå‡é‡åŒ–æ€§èƒ½ä¸Žç¨³å®šæ€§
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨2æ¯”ç‰¹è®¾ç½®ä¸‹å‡†ç¡®çŽ‡æ¯”çŽ°æœ‰æ–¹æ³•é«˜6å€ï¼Œ2/4æ¯”ç‰¹å‡ä¼˜äºŽå…ˆå‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Deploying Vision-Language Models (VLMs) on edge devices (e.g., smartphones and robots) is crucial for enabling low-latency and privacy-preserving intelligent applications. Given the resource constraints of these devices, quantization offers a promising solution by improving memory efficiency and reducing bandwidth requirements, thereby facilitating the deployment of VLMs. However, existing research has rarely explored aggressive quantization on VLMs, particularly for the models ranging from 1B to 2B parameters, which are more suitable for resource-constrained edge devices. In this paper, we propose SPEED-Q, a novel Staged Processing with Enhanced Distillation framework for VLM low-bit weight-only quantization that systematically addresses the following two critical obstacles: (1) significant discrepancies in quantization sensitivity between vision (ViT) and language (LLM) components in VLMs; (2) training instability arising from the reduced numerical precision inherent in low-bit quantization. In SPEED-Q, a staged sensitivity adaptive mechanism is introduced to effectively harmonize performance across different modalities. We further propose a distillation-enhanced quantization strategy to stabilize the training process and reduce data dependence. Together, SPEED-Q enables accurate, stable, and data-efficient quantization of complex VLMs. SPEED-Q is the first framework tailored for quantizing entire small-scale billion-parameter VLMs to low bits. Extensive experiments across multiple benchmarks demonstrate that SPEED-Q achieves up to 6x higher accuracy than existing quantization methods under 2-bit settings and consistently outperforms prior on-device VLMs under both 2-bit and 4-bit settings. Our code and models are available at https://github.com/antgroup/SPEED-Q.

