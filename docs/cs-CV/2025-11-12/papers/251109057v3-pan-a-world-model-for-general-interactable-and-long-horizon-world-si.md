---
layout: default
title: PAN: A World Model for General, Interactable, and Long-Horizon World Simulation
---

# PAN: A World Model for General, Interactable, and Long-Horizon World Simulation

**arXiv**: [2511.09057v3](https://arxiv.org/abs/2511.09057) | [PDF](https://arxiv.org/pdf/2511.09057.pdf)

**ä½œè€…**: PAN Team, Jiannan Xiang, Yi Gu, Zihan Liu, Zeyu Feng, Qiyue Gao, Yiyan Hu, Benhao Huang, Guangyi Liu, Yichi Yang, Kun Zhou, Davit Abrahamyan, Arif Ahmad, Ganesh Bannur, Junrong Chen, Kimi Chen, Mingkai Deng, Ruobing Han, Xinqi Huang, Haoqiang Kang, Zheqi Liu, Enze Ma, Hector Ren, Yashowardhan Shinde, Rohan Shingre, Ramsundar Tanikella, Kaiming Tao, Dequan Yang, Xinle Yu, Cong Zeng, Binglin Zhou, Zhengzhong Liu, Zhiting Hu, Eric P. Xing

**åˆ†ç±»**: cs.CV, cs.AI, cs.CL, cs.LG

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12 (æ›´æ–°: 2025-11-15)

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**PANï¼šé€šç”¨ã€å¯äº¤äº’ã€é•¿æ—¶ç¨‹ä¸–ç•Œæ¨¡æ‹Ÿçš„ä¸–ç•Œæ¨¡åž‹**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)**

**å…³é”®è¯**: `ä¸–ç•Œæ¨¡åž‹` `è§†é¢‘ç”Ÿæˆ` `å¤§åž‹è¯­è¨€æ¨¡åž‹` `æ‰©æ•£æ¨¡åž‹` `åŠ¨ä½œæ¡ä»¶æ¨¡æ‹Ÿ` `é•¿æ—¶ç¨‹é¢„æµ‹` `é€šç”¨äººå·¥æ™ºèƒ½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰ä¸–ç•Œæ¨¡åž‹åœ¨æ³›åŒ–æ€§ã€äº¤äº’æ€§å’Œé•¿æœŸä¸€è‡´æ€§æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œéš¾ä»¥åº”ç”¨äºŽå¤æ‚çŽ¯å¢ƒã€‚
2. PANæ¨¡åž‹åˆ©ç”¨ç”Ÿæˆæ½œåœ¨é¢„æµ‹æž¶æž„ï¼Œç»“åˆå¤§åž‹è¯­è¨€æ¨¡åž‹å’Œè§†é¢‘æ‰©æ•£æ¨¡åž‹ï¼Œå®žçŽ°åŸºäºŽè¯­è¨€åŠ¨ä½œæ¡ä»¶çš„é«˜è´¨é‡è§†é¢‘æ¨¡æ‹Ÿã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒPANåœ¨åŠ¨ä½œæ¡ä»¶ä¸–ç•Œæ¨¡æ‹Ÿå’Œé•¿æ—¶ç¨‹é¢„æµ‹æ–¹é¢ä¼˜äºŽçŽ°æœ‰æ¨¡åž‹ï¼Œä¸ºé€šç”¨ä¸–ç•Œæ¨¡åž‹å‘å±•å¥ å®šåŸºç¡€ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

ä¸–ç•Œæ¨¡åž‹ä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿæƒ³è±¡ã€é¢„æµ‹å’ŒæŽ¨ç†ä¸–ç•Œå¦‚ä½•å“åº”å…¶è¡Œä¸ºè€Œæ¼”å˜ï¼Œå¹¶æ®æ­¤è¿›è¡Œè§„åˆ’å’Œåˆ¶å®šç­–ç•¥ã€‚è™½ç„¶æœ€è¿‘çš„è§†é¢‘ç”Ÿæˆæ¨¡åž‹å¯ä»¥ç”Ÿæˆé€¼çœŸçš„è§†è§‰åºåˆ—ï¼Œä½†å®ƒä»¬é€šå¸¸ä»¥æç¤ºåˆ°å®Œæ•´è§†é¢‘çš„æ–¹å¼è¿è¡Œï¼Œç¼ºä¹å› æžœæŽ§åˆ¶ã€äº¤äº’æ€§æˆ–é•¿æœŸä¸€è‡´æ€§ï¼Œè€Œè¿™äº›å¯¹äºŽæœ‰ç›®çš„çš„æŽ¨ç†æ˜¯å¿…éœ€çš„ã€‚çŽ°æœ‰çš„ä¸–ç•Œå»ºæ¨¡å·¥ä½œé€šå¸¸ä¾§é‡äºŽå—é™é¢†åŸŸï¼ˆä¾‹å¦‚ï¼Œç‰©ç†ã€æ¸¸æˆæˆ–3Dåœºæ™¯åŠ¨æ€ï¼‰ï¼Œæ·±åº¦å’Œå¯æŽ§æ€§æœ‰é™ï¼Œå¹¶ä¸”éš¾ä»¥æŽ¨å¹¿åˆ°ä¸åŒçš„çŽ¯å¢ƒå’Œäº¤äº’å½¢å¼ã€‚æœ¬æ–‡ä»‹ç»äº†PANï¼Œä¸€ç§é€šç”¨ã€å¯äº¤äº’å’Œé•¿æ—¶ç¨‹çš„ä¸–ç•Œæ¨¡åž‹ï¼Œå®ƒé€šè¿‡é«˜è´¨é‡çš„è§†é¢‘æ¨¡æ‹Ÿæ¥é¢„æµ‹æœªæ¥çš„ä¸–ç•ŒçŠ¶æ€ï¼Œè¯¥æ¨¡æ‹Ÿä»¥åŽ†å²å’Œè‡ªç„¶è¯­è¨€åŠ¨ä½œä¸ºæ¡ä»¶ã€‚PANé‡‡ç”¨ç”Ÿæˆæ½œåœ¨é¢„æµ‹ï¼ˆGLPï¼‰æž¶æž„ï¼Œè¯¥æž¶æž„ç»“åˆäº†åŸºäºŽå¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„è‡ªå›žå½’æ½œåœ¨åŠ¨æ€éª¨å¹²ï¼Œè¿™ä½¿æ¨¡æ‹ŸåŸºäºŽå¹¿æ³›çš„åŸºäºŽæ–‡æœ¬çš„çŸ¥è¯†å¹¶èƒ½å¤Ÿä»¥è¯­è¨€æŒ‡å®šçš„åŠ¨ä½œä¸ºæ¡ä»¶ï¼Œä»¥åŠè§†é¢‘æ‰©æ•£è§£ç å™¨ï¼Œè¯¥è§£ç å™¨é‡å»ºæ„ŸçŸ¥ä¸Šè¯¦ç»†ä¸”æ—¶é—´ä¸Šè¿žè´¯çš„è§†è§‰è§‚å¯Ÿï¼Œä»¥å®žçŽ°æ½œåœ¨ç©ºé—´æŽ¨ç†ï¼ˆæƒ³è±¡ï¼‰å’Œå¯å®žçŽ°çš„ä¸–ç•ŒåŠ¨æ€ï¼ˆçŽ°å®žï¼‰ä¹‹é—´çš„ç»Ÿä¸€ã€‚PANåœ¨è·¨è¶Šä¸åŒé¢†åŸŸçš„å¤§è§„æ¨¡è§†é¢‘-åŠ¨ä½œå¯¹ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒå…·æœ‰è¿žè´¯çš„é•¿æœŸåŠ¨æ€çš„å¼€æ”¾åŸŸã€åŠ¨ä½œæ¡ä»¶æ¨¡æ‹Ÿã€‚å¤§é‡çš„å®žéªŒè¡¨æ˜Žï¼Œä¸Žå…¶ä»–è§†é¢‘ç”Ÿæˆå™¨å’Œä¸–ç•Œæ¨¡åž‹ç›¸æ¯”ï¼ŒPANåœ¨åŠ¨ä½œæ¡ä»¶ä¸–ç•Œæ¨¡æ‹Ÿã€é•¿æ—¶ç¨‹é¢„æµ‹å’Œæ¨¡æ‹ŸæŽ¨ç†æ–¹é¢å–å¾—äº†å¼ºå¤§çš„æ€§èƒ½ï¼Œæœç€å®žçŽ°èƒ½å¤Ÿé¢„æµ‹æ¨¡æ‹Ÿæœªæ¥ä¸–ç•ŒçŠ¶æ€ä»¥è¿›è¡ŒæŽ¨ç†å’Œè¡ŒåŠ¨çš„é€šç”¨ä¸–ç•Œæ¨¡åž‹è¿ˆå‡ºäº†ä¸€æ­¥ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰ä¸–ç•Œæ¨¡åž‹é€šå¸¸å±€é™äºŽç‰¹å®šé¢†åŸŸï¼Œä¾‹å¦‚ç‰©ç†æ¨¡æ‹Ÿæˆ–æ¸¸æˆçŽ¯å¢ƒï¼Œç¼ºä¹åœ¨å¼€æ”¾åŸŸä¸­è¿›è¡Œé€šç”¨æ¨¡æ‹Ÿçš„èƒ½åŠ›ã€‚å®ƒä»¬åœ¨å¤„ç†å¤æ‚äº¤äº’å’Œç»´æŒé•¿æœŸä¸€è‡´æ€§æ–¹é¢ä¹Ÿå­˜åœ¨æŒ‘æˆ˜ï¼Œæ— æ³•æ»¡è¶³æ™ºèƒ½ä½“è¿›è¡Œæœ‰æ•ˆæŽ¨ç†å’Œè§„åˆ’çš„éœ€æ±‚ã€‚çŽ°æœ‰æ–¹æ³•çš„ç—›ç‚¹åœ¨äºŽç¼ºä¹é€šç”¨æ€§ã€äº¤äº’æ€§å’Œé•¿æœŸä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šPANçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†å¤§åž‹è¯­è¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„çŸ¥è¯†æŽ¨ç†èƒ½åŠ›ä¸Žè§†é¢‘æ‰©æ•£æ¨¡åž‹çš„è§†è§‰ç”Ÿæˆèƒ½åŠ›ç›¸ç»“åˆï¼Œæž„å»ºä¸€ä¸ªèƒ½å¤Ÿç†è§£è¯­è¨€æŒ‡ä»¤å¹¶ç”Ÿæˆé«˜è´¨é‡ã€é•¿æœŸä¸€è‡´è§†é¢‘çš„ä¸–ç•Œæ¨¡åž‹ã€‚é€šè¿‡åœ¨æ½œåœ¨ç©ºé—´ä¸­è¿›è¡ŒæŽ¨ç†ï¼ŒPANèƒ½å¤Ÿæ›´å¥½åœ°æ¨¡æ‹Ÿä¸–ç•Œçš„åŠ¨æ€å˜åŒ–ï¼Œå¹¶é¢„æµ‹æœªæ¥çŠ¶æ€ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šPANé‡‡ç”¨ç”Ÿæˆæ½œåœ¨é¢„æµ‹ï¼ˆGLPï¼‰æž¶æž„ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ¨¡å—ï¼š1) **LLM-based Latent Dynamics Backbone**: ä½¿ç”¨å¤§åž‹è¯­è¨€æ¨¡åž‹ä½œä¸ºè‡ªå›žå½’æ¨¡åž‹ï¼Œå­¦ä¹ æ½œåœ¨ç©ºé—´ä¸­çš„åŠ¨æ€å˜åŒ–è§„å¾‹ï¼Œå¹¶ä»¥è¯­è¨€åŠ¨ä½œä½œä¸ºæ¡ä»¶ã€‚2) **Video Diffusion Decoder**: å°†æ½œåœ¨ç©ºé—´ä¸­çš„è¡¨ç¤ºè§£ç ä¸ºé«˜è´¨é‡çš„è§†é¢‘å¸§ï¼Œä¿è¯è§†è§‰ç»†èŠ‚å’Œæ—¶é—´è¿žè´¯æ€§ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œé¦–å…ˆå°†åŽ†å²è§†é¢‘å¸§å’Œè¯­è¨€åŠ¨ä½œç¼–ç åˆ°æ½œåœ¨ç©ºé—´ï¼Œç„¶åŽåˆ©ç”¨LLMé¢„æµ‹æœªæ¥çš„æ½œåœ¨çŠ¶æ€ï¼Œæœ€åŽé€šè¿‡è§†é¢‘æ‰©æ•£è§£ç å™¨ç”Ÿæˆå¯¹åº”çš„è§†é¢‘å¸§ã€‚

**å…³é”®åˆ›æ–°**ï¼šPANçš„å…³é”®åˆ›æ–°åœ¨äºŽå°†å¤§åž‹è¯­è¨€æ¨¡åž‹å¼•å…¥ä¸–ç•Œæ¨¡åž‹ï¼Œä»Žè€Œåˆ©ç”¨LLMçš„çŸ¥è¯†æŽ¨ç†èƒ½åŠ›å’Œè¯­è¨€ç†è§£èƒ½åŠ›ï¼Œå®žçŽ°æ›´é€šç”¨ã€æ›´å¯æŽ§çš„ä¸–ç•Œæ¨¡æ‹Ÿã€‚æ­¤å¤–ï¼ŒPANé‡‡ç”¨è§†é¢‘æ‰©æ•£æ¨¡åž‹ä½œä¸ºè§£ç å™¨ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´é€¼çœŸçš„è§†é¢‘ï¼Œå…‹æœäº†ä¼ ç»Ÿç”Ÿæˆæ¨¡åž‹åœ¨è§†è§‰ç»†èŠ‚å’Œæ—¶é—´è¿žè´¯æ€§æ–¹é¢çš„ä¸è¶³ã€‚å°†LLMçš„æŽ¨ç†èƒ½åŠ›å’Œæ‰©æ•£æ¨¡åž‹çš„ç”Ÿæˆèƒ½åŠ›ç»“åˆæ˜¯å…¶æ ¸å¿ƒåˆ›æ–°ã€‚

**å…³é”®è®¾è®¡**ï¼šPANçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1) **Latent Space Representation**: å¦‚ä½•æœ‰æ•ˆåœ°å°†è§†é¢‘å¸§å’Œè¯­è¨€åŠ¨ä½œç¼–ç åˆ°æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä¿è¯ä¿¡æ¯çš„å®Œæ•´æ€§å’Œå¯è§£é‡Šæ€§ã€‚2) **LLM Training**: å¦‚ä½•è®­ç»ƒLLMï¼Œä½¿å…¶èƒ½å¤Ÿå‡†ç¡®åœ°é¢„æµ‹æ½œåœ¨ç©ºé—´ä¸­çš„åŠ¨æ€å˜åŒ–ï¼Œå¹¶å¯¹è¯­è¨€åŠ¨ä½œåšå‡ºåˆç†çš„å“åº”ã€‚3) **Diffusion Decoder Training**: å¦‚ä½•è®­ç»ƒè§†é¢‘æ‰©æ•£è§£ç å™¨ï¼Œä½¿å…¶èƒ½å¤Ÿç”Ÿæˆé«˜è´¨é‡ã€æ—¶é—´è¿žè´¯çš„è§†é¢‘å¸§ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æž„ç­‰ç»†èŠ‚åœ¨è®ºæ–‡ä¸­æœ‰è¯¦ç»†æè¿°ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

PANåœ¨å¤šä¸ªå®žéªŒä¸­è¡¨çŽ°å‡ºè‰²ï¼Œåœ¨åŠ¨ä½œæ¡ä»¶ä¸–ç•Œæ¨¡æ‹Ÿã€é•¿æ—¶ç¨‹é¢„æµ‹å’Œæ¨¡æ‹ŸæŽ¨ç†æ–¹é¢å‡ä¼˜äºŽå…¶ä»–è§†é¢‘ç”Ÿæˆå™¨å’Œä¸–ç•Œæ¨¡åž‹ã€‚å…·ä½“è€Œè¨€ï¼ŒPANèƒ½å¤Ÿç”Ÿæˆæ›´é€¼çœŸã€æ›´è¿žè´¯çš„è§†é¢‘ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°å“åº”è¯­è¨€åŠ¨ä½œçš„æŒ‡ä»¤ã€‚å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒPANåœ¨æ¨¡æ‹Ÿå¤æ‚çŽ¯å¢ƒå’Œé¢„æµ‹é•¿æœŸåŠ¨æ€æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

PANå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ï¼Œä¾‹å¦‚æœºå™¨äººæŽ§åˆ¶ã€è‡ªåŠ¨é©¾é©¶ã€æ¸¸æˆAIå’Œè™šæ‹ŸçŽ°å®žã€‚å®ƒå¯ä»¥å¸®åŠ©æœºå™¨äººæ›´å¥½åœ°ç†è§£çŽ¯å¢ƒï¼Œé¢„æµ‹è¡Œä¸ºåŽæžœï¼Œä»Žè€Œåšå‡ºæ›´æ˜Žæ™ºçš„å†³ç­–ã€‚åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸï¼ŒPANå¯ä»¥ç”¨äºŽæ¨¡æ‹Ÿå„ç§äº¤é€šåœºæ™¯ï¼Œæé«˜è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„å®‰å…¨æ€§å’Œå¯é æ€§ã€‚åœ¨æ¸¸æˆAIé¢†åŸŸï¼ŒPANå¯ä»¥ç”¨äºŽç”Ÿæˆæ›´æ™ºèƒ½ã€æ›´é€¼çœŸçš„æ¸¸æˆè§’è‰²ã€‚åœ¨è™šæ‹ŸçŽ°å®žé¢†åŸŸï¼ŒPANå¯ä»¥ç”¨äºŽåˆ›å»ºæ›´æ²‰æµ¸å¼çš„è™šæ‹Ÿä½“éªŒã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> A world model enables an intelligent agent to imagine, predict, and reason about how the world evolves in response to its actions, and accordingly to plan and strategize. While recent video generation models produce realistic visual sequences, they typically operate in the prompt-to-full-video manner without causal control, interactivity, or long-horizon consistency required for purposeful reasoning. Existing world modeling efforts, on the other hand, often focus on restricted domains (e.g., physical, game, or 3D-scene dynamics) with limited depth and controllability, and struggle to generalize across diverse environments and interaction formats. In this work, we introduce PAN, a general, interactable, and long-horizon world model that predicts future world states through high-quality video simulation conditioned on history and natural language actions. PAN employs the Generative Latent Prediction (GLP) architecture that combines an autoregressive latent dynamics backbone based on a large language model (LLM), which grounds simulation in extensive text-based knowledge and enables conditioning on language-specified actions, with a video diffusion decoder that reconstructs perceptually detailed and temporally coherent visual observations, to achieve a unification between latent space reasoning (imagination) and realizable world dynamics (reality). Trained on large-scale video-action pairs spanning diverse domains, PAN supports open-domain, action-conditioned simulation with coherent, long-term dynamics. Extensive experiments show that PAN achieves strong performance in action-conditioned world simulation, long-horizon forecasting, and simulative reasoning compared to other video generators and world models, taking a step towards general world models that enable predictive simulation of future world states for reasoning and acting.

