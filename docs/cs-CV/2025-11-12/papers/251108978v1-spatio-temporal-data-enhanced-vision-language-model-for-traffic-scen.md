---
layout: default
title: Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding
---

# Spatio-Temporal Data Enhanced Vision-Language Model for Traffic Scene Understanding

**arXiv**: [2511.08978v1](https://arxiv.org/abs/2511.08978) | [PDF](https://arxiv.org/pdf/2511.08978.pdf)

**ä½œè€…**: Jingtian Ma, Jingyuan Wang, Wayne Xin Zhao, Guoping Liu, Xiang Wen

**åˆ†ç±»**: cs.MM, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºST-CLIPæ¨¡åž‹ï¼Œåˆ©ç”¨æ—¶ç©ºä¿¡æ¯å¢žå¼ºè§†è§‰-è¯­è¨€æ¨¡åž‹ï¼Œç”¨äºŽäº¤é€šåœºæ™¯ç†è§£ã€‚**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `äº¤é€šåœºæ™¯ç†è§£` `è§†è§‰-è¯­è¨€æ¨¡åž‹` `æ—¶ç©ºæ•°æ®` `æç¤ºå­¦ä¹ ` `å°‘æ ·æœ¬å­¦ä¹ `

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰äº¤é€šåœºæ™¯ç†è§£æ–¹æ³•å¿½ç•¥äº†æ—¶ç©ºä¿¡æ¯ï¼Œä¸”æœªèƒ½å……åˆ†æŒ–æŽ˜åœºæ™¯å„è¦ç´ é—´çš„å…³è”æ€§ï¼Œå¯¼è‡´ç†è§£ä¸å…¨é¢ã€‚
2. è®ºæ–‡æå‡ºST-CLIPæ¨¡åž‹ï¼Œé€šè¿‡æ—¶ç©ºä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤šæ–¹é¢æç¤ºå­¦ä¹ ï¼Œå°†æ—¶ç©ºä¿¡æ¯èžå…¥è§†è§‰-è¯­è¨€æ¨¡åž‹CLIPä¸­ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒST-CLIPåœ¨çœŸå®žæ•°æ®é›†ä¸Šè¡¨çŽ°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ï¼Œæ˜¾è‘—æå‡äº†å¤æ‚åœºæ™¯ç†è§£èƒ½åŠ›ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºŽæ—¶ç©ºæ•°æ®å¢žå¼ºçš„è§†è§‰-è¯­è¨€æ¨¡åž‹ï¼ˆST-CLIPï¼‰ï¼Œç”¨äºŽäº¤é€šåœºæ™¯ç†è§£ï¼ˆTSUï¼‰ã€‚çŽ°æœ‰çš„TSUç ”ç©¶é€šå¸¸å°†å…¶è§†ä¸ºæ™®é€šçš„å›¾åƒç†è§£ä»»åŠ¡ï¼Œå¿½ç•¥äº†æ—¶ç©ºä¿¡æ¯ä»¥åŠäº¤é€šåœºæ™¯ä¸åŒæ–¹é¢ä¹‹é—´çš„ç›¸äº’å…³ç³»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬æ–‡ä»¥CLIPä¸ºéª¨å¹²ç½‘ç»œï¼Œè®¾è®¡äº†ä¸€ç§æ—¶ç©ºä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤šæ–¹é¢æç¤ºï¼ˆSCAMPï¼‰å­¦ä¹ æ–¹æ³•ï¼Œå°†æ—¶ç©ºä¿¡æ¯èžå…¥TSUã€‚è¯¥æ–¹æ³•åŒ…å«ä¸€ä¸ªåŠ¨æ€æ—¶ç©ºä¸Šä¸‹æ–‡è¡¨ç¤ºæ¨¡å—ï¼Œç”¨äºŽæå–æ¯ä¸ªäº¤é€šåœºæ™¯å›¾åƒçš„æ—¶ç©ºæ•°æ®è¡¨ç¤ºå‘é‡ï¼›ä»¥åŠä¸€ä¸ªåŒå±‚STæ„ŸçŸ¥å¤šæ–¹é¢æç¤ºå­¦ä¹ æ¨¡å—ï¼Œå°†STä¸Šä¸‹æ–‡è¡¨ç¤ºå‘é‡é›†æˆåˆ°CLIPæ¨¡åž‹çš„æç¤ºè¯åµŒå…¥ä¸­ã€‚è¯¥æ¨¡å—è¿˜æå–ä½Žçº§è§†è§‰ç‰¹å¾å’Œå›¾åƒçº§é«˜çº§è¯­ä¹‰ç‰¹å¾ï¼Œä»¥åˆ©ç”¨äº¤é€šåœºæ™¯ä¸åŒæ–¹é¢ä¹‹é—´çš„äº¤äº’å…³ç³»ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–æ¬¡å°è¯•å°†æ—¶ç©ºä¿¡æ¯é›†æˆåˆ°è§†è§‰-è¯­è¨€æ¨¡åž‹ä¸­ï¼Œä»¥ä¿ƒè¿›TSUä»»åŠ¡ã€‚åœ¨ä¸¤ä¸ªçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®žéªŒè¡¨æ˜Žï¼Œè¯¥æ¨¡åž‹åœ¨å°‘æ ·æœ¬å­¦ä¹ ç­–ç•¥ä¸‹ï¼Œåœ¨å¤æ‚åœºæ™¯ç†è§£æ–¹é¢è¡¨çŽ°å‡ºä¼˜è¶Šçš„æ€§èƒ½ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šäº¤é€šåœºæ™¯ç†è§£ï¼ˆTSUï¼‰æ—¨åœ¨æä¾›äº¤é€šåœºæ™¯çš„å…¨é¢æè¿°ã€‚çŽ°æœ‰æ–¹æ³•é€šå¸¸å¿½ç•¥äº†ä¸Žå›¾åƒç›¸å…³çš„æ—¶ç©ºä¿¡æ¯ï¼Œå¹¶ä¸”å¿½è§†äº†äº¤é€šåœºæ™¯ä¸­ä¸åŒå…ƒç´ ä¹‹é—´çš„ç›¸äº’å…³ç³»ï¼Œå¯¼è‡´åœºæ™¯ç†è§£ä¸å®Œæ•´å’Œä¸å‡†ç¡®ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯å°†æ—¶ç©ºä¿¡æ¯èžå…¥åˆ°è§†è§‰-è¯­è¨€æ¨¡åž‹ä¸­ï¼Œä»Žè€Œå¢žå¼ºæ¨¡åž‹å¯¹äº¤é€šåœºæ™¯çš„ç†è§£èƒ½åŠ›ã€‚é€šè¿‡è®¾è®¡ç‰¹å®šçš„æç¤ºå­¦ä¹ æ–¹æ³•ï¼Œä½¿æ¨¡åž‹èƒ½å¤Ÿæ„ŸçŸ¥æ—¶ç©ºä¸Šä¸‹æ–‡ï¼Œå¹¶å­¦ä¹ ä¸åŒåœºæ™¯å…ƒç´ ä¹‹é—´çš„äº¤äº’å…³ç³»ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šST-CLIPæ¨¡åž‹ä»¥CLIPä¸ºéª¨å¹²ç½‘ç»œï¼Œä¸»è¦åŒ…å«ä¸¤ä¸ªæ¨¡å—ï¼šåŠ¨æ€æ—¶ç©ºä¸Šä¸‹æ–‡è¡¨ç¤ºæ¨¡å—å’ŒåŒå±‚STæ„ŸçŸ¥å¤šæ–¹é¢æç¤ºå­¦ä¹ æ¨¡å—ã€‚é¦–å…ˆï¼ŒåŠ¨æ€æ—¶ç©ºä¸Šä¸‹æ–‡è¡¨ç¤ºæ¨¡å—æå–æ¯ä¸ªäº¤é€šåœºæ™¯å›¾åƒçš„æ—¶ç©ºæ•°æ®è¡¨ç¤ºå‘é‡ã€‚ç„¶åŽï¼ŒåŒå±‚STæ„ŸçŸ¥å¤šæ–¹é¢æç¤ºå­¦ä¹ æ¨¡å—å°†è¿™äº›å‘é‡é›†æˆåˆ°CLIPæ¨¡åž‹çš„æç¤ºè¯åµŒå…¥ä¸­ï¼ŒåŒæ—¶æå–ä½Žçº§è§†è§‰ç‰¹å¾å’Œå›¾åƒçº§é«˜çº§è¯­ä¹‰ç‰¹å¾ã€‚

**å…³é”®åˆ›æ–°**ï¼šå…³é”®åˆ›æ–°åœ¨äºŽæå‡ºäº†æ—¶ç©ºä¸Šä¸‹æ–‡æ„ŸçŸ¥å¤šæ–¹é¢æç¤ºï¼ˆSCAMPï¼‰å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°å°†æ—¶ç©ºä¿¡æ¯èžå…¥åˆ°è§†è§‰-è¯­è¨€æ¨¡åž‹ä¸­ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜è€ƒè™‘äº†äº¤é€šåœºæ™¯ä¸­ä¸åŒå…ƒç´ ä¹‹é—´çš„äº¤äº’å…³ç³»ï¼Œä»Žè€Œæé«˜äº†åœºæ™¯ç†è§£çš„å‡†ç¡®æ€§ã€‚è¿™æ˜¯é¦–æ¬¡å°è¯•å°†æ—¶ç©ºä¿¡æ¯é›†æˆåˆ°è§†è§‰-è¯­è¨€æ¨¡åž‹ä¸­ä»¥ä¿ƒè¿›TSUä»»åŠ¡ã€‚

**å…³é”®è®¾è®¡**ï¼šåŠ¨æ€æ—¶ç©ºä¸Šä¸‹æ–‡è¡¨ç¤ºæ¨¡å—çš„å…·ä½“å®žçŽ°æ–¹å¼ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å“ªç§ç±»åž‹çš„ç¥žç»ç½‘ç»œæå–æ—¶ç©ºç‰¹å¾ï¼‰ï¼ŒåŒå±‚STæ„ŸçŸ¥å¤šæ–¹é¢æç¤ºå­¦ä¹ æ¨¡å—ä¸­å¦‚ä½•å°†æ—¶ç©ºå‘é‡èžå…¥æç¤ºè¯åµŒå…¥ï¼Œä»¥åŠå¦‚ä½•æå–å’Œåˆ©ç”¨ä½Žçº§è§†è§‰ç‰¹å¾å’Œé«˜çº§è¯­ä¹‰ç‰¹å¾ï¼Œè¿™äº›éƒ½æ˜¯éœ€è¦è¿›ä¸€æ­¥ç ”ç©¶çš„å…³é”®è®¾è®¡ç»†èŠ‚ã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡ä¹Ÿè‡³å…³é‡è¦ï¼Œéœ€è¦ç¡®ä¿æ¨¡åž‹èƒ½å¤Ÿæœ‰æ•ˆåœ°å­¦ä¹ æ—¶ç©ºä¿¡æ¯å’Œåœºæ™¯å…ƒç´ ä¹‹é—´çš„å…³ç³»ã€‚è®ºæ–‡ä¸­å¯èƒ½è¿˜æ¶‰åŠä¸€äº›è¶…å‚æ•°çš„è®¾ç½®ï¼Œä¾‹å¦‚å­¦ä¹ çŽ‡ã€æ‰¹å¤§å°ç­‰ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒST-CLIPæ¨¡åž‹åœ¨ä¸¤ä¸ªçœŸå®žä¸–ç•Œæ•°æ®é›†ä¸Šå–å¾—äº†ä¼˜è¶Šçš„æ€§èƒ½ï¼Œå°¤å…¶æ˜¯åœ¨å°‘æ ·æœ¬å­¦ä¹ åœºæ™¯ä¸‹ã€‚ç›¸è¾ƒäºŽä¼ ç»Ÿæ–¹æ³•ï¼ŒST-CLIPèƒ½å¤Ÿæ›´å‡†ç¡®åœ°ç†è§£å¤æ‚çš„äº¤é€šåœºæ™¯ï¼Œå……åˆ†è¯æ˜Žäº†æ—¶ç©ºä¿¡æ¯èžå…¥è§†è§‰-è¯­è¨€æ¨¡åž‹çš„æœ‰æ•ˆæ€§ã€‚å…·ä½“çš„æ€§èƒ½æå‡æ•°æ®éœ€è¦åœ¨è®ºæ–‡ä¸­æŸ¥æ‰¾ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯åº”ç”¨äºŽå¯¼èˆªå’Œç½‘çº¦è½¦åº”ç”¨ä¸­ï¼Œæå‡äº¤é€šåœºæ™¯ç†è§£çš„å‡†ç¡®æ€§å’Œå…¨é¢æ€§ã€‚é€šè¿‡æ›´ç²¾ç¡®çš„åœºæ™¯æè¿°ï¼Œå¯ä»¥ä¼˜åŒ–è·¯çº¿è§„åˆ’ã€æé«˜é©¾é©¶å®‰å…¨æ€§ï¼Œå¹¶ä¸ºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæä¾›æ›´å¯é çš„çŽ¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æŠ€æœ¯è¿˜å¯æ‰©å±•åˆ°æ™ºæ…§åŸŽå¸‚ã€æ™ºèƒ½äº¤é€šç®¡ç†ç­‰é¢†åŸŸï¼ŒåŠ©åŠ›æž„å»ºæ›´é«˜æ•ˆã€å®‰å…¨çš„äº¤é€šç³»ç»Ÿã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Nowadays, navigation and ride-sharing apps have collected numerous images with spatio-temporal data. A core technology for analyzing such images, associated with spatiotemporal information, is Traffic Scene Understanding (TSU), which aims to provide a comprehensive description of the traffic scene. Unlike traditional spatio-temporal data analysis tasks, the dependence on both spatio-temporal and visual-textual data introduces distinct challenges to TSU task. However, recent research often treats TSU as a common image understanding task, ignoring the spatio-temporal information and overlooking the interrelations between different aspects of the traffic scene. To address these issues, we propose a novel SpatioTemporal Enhanced Model based on CILP (ST-CLIP) for TSU. Our model uses the classic vision-language model, CLIP, as the backbone, and designs a Spatio-temporal Context Aware Multiaspect Prompt (SCAMP) learning method to incorporate spatiotemporal information into TSU. The prompt learning method consists of two components: A dynamic spatio-temporal context representation module that extracts representation vectors of spatio-temporal data for each traffic scene image, and a bi-level ST-aware multi-aspect prompt learning module that integrates the ST-context representation vectors into word embeddings of prompts for the CLIP model. The second module also extracts low-level visual features and image-wise high-level semantic features to exploit interactive relations among different aspects of traffic scenes. To the best of our knowledge, this is the first attempt to integrate spatio-temporal information into visionlanguage models to facilitate TSU task. Experiments on two realworld datasets demonstrate superior performance in the complex scene understanding scenarios with a few-shot learning strategy.

