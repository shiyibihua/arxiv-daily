---
layout: default
title: A Finite Difference Approximation of Second Order Regularization of Neural-SDFs
---

# A Finite Difference Approximation of Second Order Regularization of Neural-SDFs

**arXiv**: [2511.08980v1](https://arxiv.org/abs/2511.08980) | [PDF](https://arxiv.org/pdf/2511.08980.pdf)

**ä½œè€…**: Haotian Yin, Aleksander Plocharski, Michal Jan Wlodarczyk, Przemyslaw Musialski

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºæœ‰é™å·®åˆ†æ¡†æž¶ä»¥é«˜æ•ˆæ­£åˆ™åŒ–ç¥žç»SDFçš„æ›²çŽ‡**

**å…³é”®è¯**: `ç¥žç»ç¬¦å·è·ç¦»åœº` `æ›²çŽ‡æ­£åˆ™åŒ–` `æœ‰é™å·®åˆ†æ–¹æ³•` `è‡ªåŠ¨å¾®åˆ†` `ä¸‰ç»´é‡å»º` `è®¡ç®—æ•ˆçŽ‡`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰æ–¹æ³•ä½¿ç”¨äºŒé˜¶è‡ªåŠ¨å¾®åˆ†è®¡ç®—æ›²çŽ‡ï¼Œè®¡ç®—æˆæœ¬é«˜
2. é‡‡ç”¨æœ‰é™å·®åˆ†æ¨¡æ¿è¿‘ä¼¼äºŒé˜¶å¯¼æ•°ï¼Œé™ä½Žå†…å­˜å’Œè®­ç»ƒæ—¶é—´
3. å®žéªŒæ˜¾ç¤ºé‡å»ºè´¨é‡ç›¸å½“ï¼ŒGPUä½¿ç”¨å’Œè®­ç»ƒæ—¶é—´å‡åŠ

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> We introduce a finite-difference framework for curvature regularization in neural signed distance field (SDF) learning. Existing approaches enforce curvature priors using full Hessian information obtained via second-order automatic differentiation, which is accurate but computationally expensive. Others reduced this overhead by avoiding explicit Hessian assembly, but still required higher-order differentiation. In contrast, our method replaces these operations with lightweight finite-difference stencils that approximate second derivatives using the well known Taylor expansion with a truncation error of O(h^2), and can serve as drop-in replacements for Gaussian curvature and rank-deficiency losses. Experiments demonstrate that our finite-difference variants achieve reconstruction fidelity comparable to their automatic-differentiation counterparts, while reducing GPU memory usage and training time by up to a factor of two. Additional tests on sparse, incomplete, and non-CAD data confirm that the proposed formulation is robust and general, offering an efficient and scalable alternative for curvature-aware SDF learning.

