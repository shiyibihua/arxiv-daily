---
layout: default
title: OG-PCL: Efficient Sparse Point Cloud Processing for Human Activity Recognition
---

# OG-PCL: Efficient Sparse Point Cloud Processing for Human Activity Recognition

**arXiv**: [2511.08910v1](https://arxiv.org/abs/2511.08910) | [PDF](https://arxiv.org/pdf/2511.08910.pdf)

**ä½œè€…**: Jiuqi Yan, Chendong Xu, Dongyu Liu

**åˆ†ç±»**: eess.SP, cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-12

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºOG-PCLç½‘ç»œï¼Œç”¨äºŽé«˜æ•ˆå¤„ç†ç¨€ç–é›·è¾¾ç‚¹äº‘çš„äººä½“æ´»åŠ¨è¯†åˆ«**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `äººä½“æ´»åŠ¨è¯†åˆ«` `æ¯«ç±³æ³¢é›·è¾¾` `ç¨€ç–ç‚¹äº‘` `ä¸‰è§†å›¾CNN` `Bi-LSTM`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. åŸºäºŽæ‘„åƒå¤´çš„HARæ–¹æ³•å­˜åœ¨éšç§æ³„éœ²é£Žé™©ï¼Œè€ŒåŸºäºŽå¯ç©¿æˆ´è®¾å¤‡çš„æ–¹æ³•ä½©æˆ´ä¸ä¾¿ï¼Œæ¯«ç±³æ³¢é›·è¾¾æä¾›äº†ä¸€ç§éšç§ä¿æŠ¤ä¸”é²æ£’çš„æ›¿ä»£æ–¹æ¡ˆã€‚
2. OG-PCLç½‘ç»œé‡‡ç”¨ä¸‰è§†å›¾å¹¶è¡ŒCNNç»“æž„ï¼Œç»“åˆBi-LSTMï¼Œæœ‰æ•ˆæå–ç‚¹äº‘çš„ç©ºé—´ä¿¡æ¯å’Œæ—¶åºç‰¹å¾ï¼Œå¹¶å¼•å…¥Occupancy-Gated Convolutionå¤„ç†ç¨€ç–æ€§ã€‚
3. å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒOG-PCLåœ¨RadHARæ•°æ®é›†ä¸Šå–å¾—äº†91.75%çš„å‡†ç¡®çŽ‡ï¼Œå‚æ•°é‡ä»…ä¸º0.83Mï¼Œä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œé€‚åˆè½»é‡çº§å¹³å°éƒ¨ç½²ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºOccupancy-Gated Parallel-CNN Bi-LSTM (OG-PCL)çš„ç½‘ç»œï¼Œç”¨äºŽå¤„ç†æ¯«ç±³æ³¢é›·è¾¾ç”Ÿæˆçš„ç¨€ç–3Dç‚¹äº‘ï¼Œä»¥å®žçŽ°äººä½“æ´»åŠ¨è¯†åˆ«(HAR)ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è½»é‡åŒ–éƒ¨ç½²ï¼Œå‚æ•°é‡ä»…ä¸º0.83Mï¼Œåœ¨RadHARæ•°æ®é›†ä¸Šå®žçŽ°äº†91.75%çš„å‡†ç¡®çŽ‡ï¼Œä¼˜äºŽçŽ°æœ‰çš„2D CNNã€PointNetå’Œ3D CNNç­‰åŸºçº¿æ–¹æ³•ã€‚é€šè¿‡æ¶ˆèžå®žéªŒéªŒè¯äº†ä¸‰è§†å›¾å¹¶è¡Œç»“æž„åœ¨ä¿æŒä¸‰ç»´ç©ºé—´ä¿¡æ¯çš„åŒæ—¶æé«˜æ•ˆçŽ‡çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡è¿˜å¼•å…¥äº†Occupancy-Gated Convolution (OGConv)å—ï¼Œå¹¶è¯æ˜Žäº†å…¶å ç”¨è¡¥å¿æœºåˆ¶å¯¹äºŽå¤„ç†ç¨€ç–ç‚¹äº‘çš„å¿…è¦æ€§ã€‚å› æ­¤ï¼Œæ‰€æå‡ºçš„OG-PCLä¸ºè½»é‡çº§å¹³å°ä¸ŠåŸºäºŽé›·è¾¾çš„å®žæ—¶HARæä¾›äº†ä¸€ä¸ªç´§å‡‘è€Œå‡†ç¡®çš„æ¡†æž¶ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæ¯«ç±³æ³¢é›·è¾¾ç”Ÿæˆçš„äººä½“æ´»åŠ¨ç‚¹äº‘æ•°æ®é€šå¸¸éžå¸¸ç¨€ç–ï¼Œè¿™ç»™æœ‰æ•ˆæå–ç‰¹å¾å¸¦æ¥äº†æŒ‘æˆ˜ã€‚çŽ°æœ‰çš„æ–¹æ³•ï¼Œå¦‚ç›´æŽ¥åº”ç”¨3D CNNï¼Œè®¡ç®—é‡å¤§ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚PointNetç­‰æ–¹æ³•è™½ç„¶å¯ä»¥å¤„ç†ç‚¹äº‘ï¼Œä½†å¿½ç•¥äº†ç‚¹äº‘çš„ç©ºé—´ç»“æž„ä¿¡æ¯ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä¿æŒç²¾åº¦çš„åŒæ—¶ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ï¼Œæ˜¯è¯¥è®ºæ–‡è¦è§£å†³çš„å…³é”®é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨ä¸‰è§†å›¾å¹¶è¡ŒCNNç»“æž„ï¼Œä»Žä¸åŒçš„è§†è§’æå–ç‚¹äº‘çš„ç‰¹å¾ï¼Œå¹¶ç»“åˆBi-LSTMæ¥æ•æ‰æ—¶åºä¿¡æ¯ã€‚åŒæ—¶ï¼Œé’ˆå¯¹ç‚¹äº‘çš„ç¨€ç–æ€§ï¼Œå¼•å…¥Occupancy-Gated Convolution (OGConv)æ¨¡å—ï¼Œé€šè¿‡å ç”¨è¡¥å¿æœºåˆ¶æ¥æé«˜ç‰¹å¾æå–çš„é²æ£’æ€§ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨åœ¨ä¿æŒç©ºé—´ä¿¡æ¯çš„åŒæ—¶ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ï¼Œå¹¶æœ‰æ•ˆå¤„ç†ç¨€ç–ç‚¹äº‘ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šOG-PCLç½‘ç»œä¸»è¦ç”±ä¸‰ä¸ªéƒ¨åˆ†ç»„æˆï¼š1) ä¸‰è§†å›¾å¹¶è¡ŒCNNï¼šå°†3Dç‚¹äº‘æŠ•å½±åˆ°ä¸‰ä¸ªæ­£äº¤å¹³é¢ä¸Šï¼Œåˆ†åˆ«ä½¿ç”¨2D CNNæå–ç‰¹å¾ï¼›2) Occupancy-Gated Convolution (OGConv)å—ï¼šç”¨äºŽè¡¥å¿ç‚¹äº‘çš„ç¨€ç–æ€§ï¼Œæé«˜ç‰¹å¾æå–çš„é²æ£’æ€§ï¼›3) Bi-LSTMï¼šç”¨äºŽæ•æ‰äººä½“æ´»åŠ¨çš„æ—¶åºä¿¡æ¯ã€‚æ•´ä¸ªæµç¨‹æ˜¯ï¼Œé¦–å…ˆå°†3Dç‚¹äº‘è¾“å…¥åˆ°ä¸‰è§†å›¾å¹¶è¡ŒCNNä¸­ï¼Œæå–ç‰¹å¾ï¼Œç„¶åŽé€šè¿‡OGConvå—è¿›è¡Œç¨€ç–æ€§è¡¥å¿ï¼Œæœ€åŽå°†ç‰¹å¾è¾“å…¥åˆ°Bi-LSTMä¸­è¿›è¡Œæ—¶åºå»ºæ¨¡ï¼Œå¾—åˆ°æœ€ç»ˆçš„åˆ†ç±»ç»“æžœã€‚

**å…³é”®åˆ›æ–°**ï¼šè¯¥è®ºæ–‡çš„å…³é”®åˆ›æ–°ç‚¹åœ¨äºŽï¼š1) æå‡ºäº†Occupancy-Gated Convolution (OGConv)å—ï¼Œç”¨äºŽå¤„ç†ç¨€ç–ç‚¹äº‘ï¼Œè¿™æ˜¯ä¸ŽçŽ°æœ‰æ–¹æ³•çš„ä¸»è¦åŒºåˆ«ã€‚ä¼ ç»Ÿçš„å·ç§¯æ“ä½œåœ¨ç¨€ç–ç‚¹äº‘ä¸Šæ•ˆæžœä¸ä½³ï¼Œå› ä¸ºå¤§é‡çš„é›¶å€¼ä¼šå½±å“ç‰¹å¾æå–ã€‚OGConvé€šè¿‡å¼•å…¥å ç”¨ä¿¡æ¯ï¼Œå¯¹å·ç§¯ç»“æžœè¿›è¡Œè¡¥å¿ï¼Œä»Žè€Œæé«˜äº†ç‰¹å¾æå–çš„é²æ£’æ€§ã€‚2) é‡‡ç”¨äº†ä¸‰è§†å›¾å¹¶è¡ŒCNNç»“æž„ï¼Œå¯ä»¥åœ¨ä¿æŒç©ºé—´ä¿¡æ¯çš„åŒæ—¶ï¼Œé™ä½Žè®¡ç®—å¤æ‚åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šOGConvå—çš„è®¾è®¡æ˜¯å…³é”®ã€‚å®ƒé¦–å…ˆè®¡ç®—æ¯ä¸ªå·ç§¯æ ¸çš„å ç”¨çŽ‡ï¼Œç„¶åŽæ ¹æ®å ç”¨çŽ‡å¯¹å·ç§¯ç»“æžœè¿›è¡ŒåŠ æƒã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºŽæ¯ä¸ªå·ç§¯æ ¸ï¼Œè®¡ç®—å…¶è¦†ç›–çš„éžé›¶åƒç´ çš„æ¯”ä¾‹ï¼Œä½œä¸ºè¯¥å·ç§¯æ ¸çš„å ç”¨çŽ‡ã€‚ç„¶åŽï¼Œå°†å·ç§¯ç»“æžœä¹˜ä»¥å ç”¨çŽ‡ï¼Œä½œä¸ºæœ€ç»ˆçš„è¾“å‡ºã€‚Bi-LSTMçš„éšè—å±‚å¤§å°è®¾ç½®ä¸º128ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

OG-PCLåœ¨RadHARæ•°æ®é›†ä¸Šå–å¾—äº†91.75%çš„å‡†ç¡®çŽ‡ï¼Œè¶…è¿‡äº†çŽ°æœ‰çš„2D CNNã€PointNetå’Œ3D CNNç­‰åŸºçº¿æ–¹æ³•ã€‚å°¤å…¶å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒOG-PCLçš„å‚æ•°é‡ä»…ä¸º0.83Mï¼Œè¿œå°äºŽå…¶ä»–æ–¹æ³•ï¼Œè¿™ä½¿å¾—å®ƒéžå¸¸é€‚åˆåœ¨èµ„æºå—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ã€‚æ¶ˆèžå®žéªŒéªŒè¯äº†ä¸‰è§†å›¾å¹¶è¡Œç»“æž„å’ŒOGConvå—çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜Žäº†å®ƒä»¬å¯¹äºŽæé«˜æ€§èƒ½çš„é‡è¦æ€§ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæžœå¯å¹¿æ³›åº”ç”¨äºŽæ™ºèƒ½å®¶å±…ã€å…»è€ç›‘æŠ¤ã€åŒ»ç–—å¥åº·ç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œåœ¨æ™ºèƒ½å®¶å±…ä¸­ï¼Œå¯ä»¥é€šè¿‡æ¯«ç±³æ³¢é›·è¾¾è¯†åˆ«ç”¨æˆ·çš„æ´»åŠ¨çŠ¶æ€ï¼Œä»Žè€Œå®žçŽ°æ™ºèƒ½åŒ–çš„æŽ§åˆ¶å’Œç®¡ç†ã€‚åœ¨å…»è€ç›‘æŠ¤ä¸­ï¼Œå¯ä»¥å®žæ—¶ç›‘æµ‹è€å¹´äººçš„æ´»åŠ¨ï¼ŒåŠæ—¶å‘çŽ°å¼‚å¸¸æƒ…å†µå¹¶å‘å‡ºè­¦æŠ¥ã€‚åœ¨åŒ»ç–—å¥åº·é¢†åŸŸï¼Œå¯ä»¥ç”¨äºŽåº·å¤è®­ç»ƒçš„ç›‘æµ‹å’Œè¯„ä¼°ï¼Œæé«˜åº·å¤æ•ˆæžœã€‚è¯¥æŠ€æœ¯å…·æœ‰éšç§ä¿æŠ¤çš„ä¼˜åŠ¿ï¼Œæœ‰æœ›åœ¨æœªæ¥å¾—åˆ°æ›´å¹¿æ³›çš„åº”ç”¨ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Human activity recognition (HAR) with millimeter-wave (mmWave) radar offers a privacy-preserving and robust alternative to camera- and wearable-based approaches. In this work, we propose the Occupancy-Gated Parallel-CNN Bi-LSTM (OG-PCL) network to process sparse 3D radar point clouds produced by mmWave sensing. Designed for lightweight deployment, the parameter size of the proposed OG-PCL is only 0.83M and achieves 91.75 accuracy on the RadHAR dataset, outperforming those existing baselines such as 2D CNN, PointNet, and 3D CNN methods. We validate the advantages of the tri-view parallel structure in preserving spatial information across three dimensions while maintaining efficiency through ablation studies. We further introduce the Occupancy-Gated Convolution (OGConv) block and demonstrate the necessity of its occupancy compensation mechanism for handling sparse point clouds. The proposed OG-PCL thus offers a compact yet accurate framework for real-time radar-based HAR on lightweight platforms.

