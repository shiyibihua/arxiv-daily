---
layout: default
title: UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning
---

# UMIGen: A Unified Framework for Egocentric Point Cloud Generation and Cross-Embodiment Robotic Imitation Learning

**arXiv**: [2511.09302v1](https://arxiv.org/abs/2511.09302) | [PDF](https://arxiv.org/pdf/2511.09302.pdf)

**ä½œè€…**: Yan Huang, Shoujie Li, Xingting Li, Wenbo Ding

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºUMIGenæ¡†æž¶ä»¥è§£å†³æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ä¸­æ•°æ®æ”¶é›†å›°éš¾ä¸Žè·¨å…·èº«æ³›åŒ–é—®é¢˜**

**å…³é”®è¯**: `ç‚¹äº‘ç”Ÿæˆ` `æœºå™¨äººæ¨¡ä»¿å­¦ä¹ ` `è·¨å…·èº«æ³›åŒ–` `æ•°æ®æ”¶é›†` `å¯è§æ€§ä¼˜åŒ–`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šæœºå™¨äººå­¦ä¹ ä¾èµ–å¤§è§„æ¨¡é«˜è´¨é‡æ¼”ç¤ºæ•°æ®ï¼Œä½†æ”¶é›†æˆæœ¬é«˜ä¸”ç©ºé—´æ³›åŒ–èƒ½åŠ›æœ‰é™
2. æ–¹æ³•è¦ç‚¹ï¼šç»“åˆæ‰‹æŒç‚¹äº‘é‡‡é›†è®¾å¤‡å’Œå¯è§æ€§ä¼˜åŒ–æœºåˆ¶ï¼Œç”Ÿæˆå¯¹é½çœŸå®žè§‚å¯Ÿçš„ç‚¹äº‘æ•°æ®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨ä»¿çœŸå’ŒçœŸå®žçŽ¯å¢ƒä¸­éªŒè¯äº†è·¨å…·èº«æ³›åŒ–èƒ½åŠ›å¹¶åŠ é€Ÿäº†æ•°æ®æ”¶é›†

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Data-driven robotic learning faces an obvious dilemma: robust policies demand large-scale, high-quality demonstration data, yet collecting such data remains a major challenge owing to high operational costs, dependence on specialized hardware, and the limited spatial generalization capability of current methods. The Universal Manipulation Interface (UMI) relaxes the strict hardware requirements for data collection, but it is restricted to capturing only RGB images of a scene and omits the 3D geometric information on which many tasks rely. Inspired by DemoGen, we propose UMIGen, a unified framework that consists of two key components: (1) Cloud-UMI, a handheld data collection device that requires no visual SLAM and simultaneously records point cloud observation-action pairs; and (2) a visibility-aware optimization mechanism that extends the DemoGen pipeline to egocentric 3D observations by generating only points within the camera's field of view. These two components enable efficient data generation that aligns with real egocentric observations and can be directly transferred across different robot embodiments without any post-processing. Experiments in both simulated and real-world settings demonstrate that UMIGen supports strong cross-embodiment generalization and accelerates data collection in diverse manipulation tasks.

