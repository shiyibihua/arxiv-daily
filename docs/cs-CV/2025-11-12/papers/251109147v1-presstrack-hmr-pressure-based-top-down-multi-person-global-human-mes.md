---
layout: default
title: PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery
---

# PressTrack-HMR: Pressure-Based Top-Down Multi-Person Global Human Mesh Recovery

**arXiv**: [2511.09147v1](https://arxiv.org/abs/2511.09147) | [PDF](https://arxiv.org/pdf/2511.09147.pdf)

**ä½œè€…**: Jiayue Yuan, Fangting Xie, Guangwen Ouyang, Changhai Ma, Ziyu Wu, Heyu Ding, Quan Wan, Yi Ke, Yuchen Wu, Xiaohui Cai

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºPressTrack-HMRä»¥è§£å†³å¤šäººåœ¨åŽ‹åŠ›åž«ä¸Šè¡Œèµ°æ—¶çš„å…¨å±€äººä½“ç½‘æ ¼æ¢å¤é—®é¢˜**

**å…³é”®è¯**: `äººä½“ç½‘æ ¼æ¢å¤` `åŽ‹åŠ›ä¿¡å·å¤„ç†` `å¤šäººç‰©è·Ÿè¸ª` `éšç§ä¿æŠ¤åŠ¨ä½œè¯†åˆ«` `è§¦è§‰åž«æ•°æ®é›†`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå¤šäººåœ¨åŽ‹åŠ›åž«ä¸Šè¡Œèµ°æ—¶ï¼ŒåŽ‹åŠ›ä¿¡å·ç›¸äº’æ··åˆï¼Œéš¾ä»¥åŒºåˆ†ä¸ªä½“å¹¶æ¢å¤äººä½“ç½‘æ ¼ã€‚
2. æ–¹æ³•è¦ç‚¹ï¼šé‡‡ç”¨è‡ªä¸Šè€Œä¸‹æµç¨‹ï¼Œå…ˆé€šè¿‡æ£€æµ‹è·Ÿè¸ªç­–ç•¥åˆ†å‰²ä¸ªä½“åŽ‹åŠ›ä¿¡å·ï¼Œå†å¯¹æ¯ä¸ªä¿¡å·è¿›è¡Œäººä½“ç½‘æ ¼æ¢å¤ã€‚
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨è‡ªå»ºMIPæ•°æ®é›†ä¸Šï¼ŒMPJPEä¸º89.2æ¯«ç±³ï¼ŒWA-MPJPEä¸º112.6æ¯«ç±³ï¼ŒéªŒè¯äº†æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multi-person global human mesh recovery (HMR) is crucial for understanding crowd dynamics and interactions. Traditional vision-based HMR methods sometimes face limitations in real-world scenarios due to mutual occlusions, insufficient lighting, and privacy concerns. Human-floor tactile interactions offer an occlusion-free and privacy-friendly alternative for capturing human motion. Existing research indicates that pressure signals acquired from tactile mats can effectively estimate human pose in single-person scenarios. However, when multiple individuals walk randomly on the mat simultaneously, how to distinguish intermingled pressure signals generated by different persons and subsequently acquire individual temporal pressure data remains a pending challenge for extending pressure-based HMR to the multi-person situation. In this paper, we present \textbf{PressTrack-HMR}, a top-down pipeline that recovers multi-person global human meshes solely from pressure signals. This pipeline leverages a tracking-by-detection strategy to first identify and segment each individual's pressure signal from the raw pressure data, and subsequently performs HMR for each extracted individual signal. Furthermore, we build a multi-person interaction pressure dataset \textbf{MIP}, which facilitates further research into pressure-based human motion analysis in multi-person scenarios. Experimental results demonstrate that our method excels in multi-person HMR using pressure data, with 89.2~$mm$ MPJPE and 112.6~$mm$ WA-MPJPE$_{100}$, and these showcase the potential of tactile mats for ubiquitous, privacy-preserving multi-person action recognition. Our dataset \& code are available at https://github.com/Jiayue-Yuan/PressTrack-HMR.

