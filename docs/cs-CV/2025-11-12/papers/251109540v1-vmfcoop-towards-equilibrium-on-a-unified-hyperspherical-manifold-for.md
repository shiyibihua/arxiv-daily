---
layout: default
title: vMFCoOp: Towards Equilibrium on a Unified Hyperspherical Manifold for Prompting Biomedical VLMs
---

# vMFCoOp: Towards Equilibrium on a Unified Hyperspherical Manifold for Prompting Biomedical VLMs

**arXiv**: [2511.09540v1](https://arxiv.org/abs/2511.09540) | [PDF](https://arxiv.org/pdf/2511.09540.pdf)

**ä½œè€…**: Minye Shao, Sihan Guo, Xinrun Li, Xingyu Miao, Haoran Duan, Yang Long

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºvMFCoOpæ¡†æž¶ä»¥è§£å†³ç”Ÿç‰©åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡åž‹æç¤ºå­¦ä¹ ä¸­çš„è¯­ä¹‰é”™ä½é—®é¢˜**

**å…³é”®è¯**: `æç¤ºå­¦ä¹ ` `è¶…çƒé¢æµå½¢` `ç”Ÿç‰©åŒ»å­¦è§†è§‰è¯­è¨€æ¨¡åž‹` `è¯­ä¹‰å¯¹é½` `å°‘æ ·æœ¬åˆ†ç±»`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šLLMä¸ŽCLIPæ¨¡åž‹è¯­ä¹‰é”™ä½ï¼Œæ¬§å‡ é‡Œå¾—ç©ºé—´ä¼˜åŒ–éš¾ä»¥å»ºæ¨¡ç»Ÿä¸€è¡¨ç¤º
2. æ–¹æ³•è¦ç‚¹ï¼šåœ¨å…±äº«è¶…çƒé¢æµå½¢ä¸Šä¼°è®¡vMFåˆ†å¸ƒï¼Œé€šè¿‡ç»Ÿä¸€è¯­ä¹‰é”šç‚¹å¯¹é½è¯­ä¹‰åå·®
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨14ä¸ªåŒ»å­¦æ•°æ®é›†ä¸Šè¡¨çŽ°ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæå‡å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advances in context optimization (CoOp) guided by large language model (LLM)-distilled medical semantic priors offer a scalable alternative to manual prompt engineering and full fine-tuning for adapting biomedical CLIP-based vision-language models (VLMs). However, prompt learning in this context is challenged by semantic misalignment between LLMs and CLIP variants due to divergent training corpora and model architectures; it further lacks scalability across continuously evolving families of foundation models. More critically, pairwise multimodal alignment via conventional Euclidean-space optimization lacks the capacity to model unified representations or apply localized geometric constraints, which tends to amplify modality gaps in complex biomedical imaging and destabilize few-shot adaptation. In this work, we propose vMFCoOp, a framework that inversely estimates von Mises-Fisher (vMF) distributions on a shared Hyperspherical Manifold, aligning semantic biases between arbitrary LLMs and CLIP backbones via Unified Semantic Anchors to achieve robust biomedical prompting and superior few-shot classification. Grounded in three complementary constraints, vMFCoOp demonstrates consistent improvements across 14 medical datasets, 12 medical imaging modalities, and 13 anatomical regions, outperforming state-of-the-art methods in accuracy, generalization, and clinical applicability. This work will be continuously expanded to encompass more downstream applications, and the corresponding resources are intended to be shared through https://github.com/VinyehShaw/UniEqui.

