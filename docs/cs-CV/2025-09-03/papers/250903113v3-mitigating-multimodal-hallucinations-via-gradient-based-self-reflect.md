---
layout: default
title: Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection
---

# Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03113" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03113v3</a>
  <a href="https://arxiv.org/pdf/2509.03113.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03113v3" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03113v3', 'Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Shan Wang, Maying Shen, Nadine Chang, Chuong Nguyen, Hongdong Li, Jose M. Alvarez

**åˆ†ç±»**: cs.CV, cs.CL

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03 (æ›´æ–°: 2025-11-13)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºåŸºäºæ¢¯åº¦çš„è‡ªåæ€æ–¹æ³•GACDï¼Œç¼“è§£å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å¹»è§‰é—®é¢˜ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹` `å¹»è§‰ç¼“è§£` `æ¢¯åº¦åˆ†æ` `è§†è§‰åŸºç¡€` `çº¦æŸè§£ç `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹æ˜“å—å¹»è§‰å½±å“ï¼Œè¾“å‡ºä¸è§†è§‰è¾“å…¥ä¸ç¬¦ï¼Œä¸»è¦åŸå› æ˜¯æ–‡æœ¬-è§†è§‰åå·®å’Œå…±ç°åå·®ã€‚
2. GACDé€šè¿‡æ¢¯åº¦åˆ†ætokenè´¡çŒ®ï¼ŒæŠ‘åˆ¶è™šå‡è§†è§‰ç‰¹å¾ï¼Œå¹¶é‡æ–°å¹³è¡¡è·¨æ¨¡æ€è´¡çŒ®ï¼Œä»è€Œç¼“è§£å¹»è§‰ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGACDèƒ½æœ‰æ•ˆå‡å°‘å¹»è§‰ï¼Œæå‡å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºçš„è§†è§‰åŸºç¡€ï¼Œæ— éœ€å¾®è°ƒã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åœ¨å„ç§ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä½†ä»ç„¶å®¹æ˜“äº§ç”Ÿå¹»è§‰ï¼Œå³è¾“å‡ºå†…å®¹ä¸è§†è§‰è¾“å…¥ä¸ç¬¦ã€‚è¿™ä¸ªé—®é¢˜å¯ä»¥å½’å› äºä¸¤ç§ä¸»è¦çš„åå·®ï¼šæ–‡æœ¬-è§†è§‰åå·®ï¼ˆè¿‡åº¦ä¾èµ–æç¤ºå’Œå…ˆå‰çš„è¾“å‡ºï¼‰å’Œå…±ç°åå·®ï¼ˆé¢‘ç¹é…å¯¹å¯¹è±¡ä¹‹é—´çš„è™šå‡ç›¸å…³æ€§ï¼‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ¨ç†çš„æ–¹æ³•ï¼Œå³åŸºäºæ¢¯åº¦çš„å½±å“æ„ŸçŸ¥çº¦æŸè§£ç ï¼ˆGACDï¼‰ï¼Œå®ƒæ— éœ€è¾…åŠ©æ¨¡å‹å³å¯è§£å†³è¿™ä¸¤ç§åå·®ï¼Œå¹¶ä¸”å¯ä»¥è½»æ¾åº”ç”¨äºç°æœ‰æ¨¡å‹è€Œæ— éœ€å¾®è°ƒã€‚æˆ‘ä»¬æ–¹æ³•çš„æ ¸å¿ƒæ˜¯åå·®ä¼°è®¡ï¼Œå®ƒä½¿ç”¨ä¸€é˜¶æ³°å‹’æ¢¯åº¦æ¥ç†è§£å„ä¸ªtokenï¼ˆè§†è§‰ç‰¹å¾å’Œæ–‡æœ¬tokenï¼‰å¯¹å½“å‰è¾“å‡ºçš„è´¡çŒ®ã€‚åŸºäºæ­¤åˆ†æï¼ŒGACDé€šè¿‡ä¸¤ä¸ªç»„æˆéƒ¨åˆ†æ¥ç¼“è§£å¹»è§‰ï¼š(1) æŠ‘åˆ¶ä¸è¾“å‡ºå¯¹è±¡ç›¸å…³çš„è™šå‡è§†è§‰ç‰¹å¾ï¼Œä»¥åŠ (2) é€šè¿‡åŠ å¼ºç›¸å¯¹äºæ–‡æœ¬çš„è§†è§‰ç‰¹å¾æ¥é‡æ–°å¹³è¡¡è·¨æ¨¡æ€è´¡çŒ®ã€‚è·¨å¤šä¸ªåŸºå‡†çš„å®éªŒè¡¨æ˜ï¼ŒGACDæœ‰æ•ˆåœ°å‡å°‘äº†å¹»è§‰å¹¶æé«˜äº†MLLMè¾“å‡ºçš„è§†è§‰åŸºç¡€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨ç”Ÿæˆå†…å®¹æ—¶ï¼Œå®¹æ˜“äº§ç”Ÿä¸è§†è§‰è¾“å…¥ä¸ç›¸å…³çš„â€œå¹»è§‰â€ï¼Œå³ç”Ÿæˆçš„å†…å®¹åœ¨å›¾åƒä¸­å¹¶ä¸å­˜åœ¨ã€‚ç°æœ‰çš„æ–¹æ³•è¦ä¹ˆä¾èµ–äºé¢å¤–çš„æ¨¡å‹è¿›è¡ŒéªŒè¯ï¼Œè¦ä¹ˆéœ€è¦å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œå¢åŠ äº†è®¡ç®—æˆæœ¬å’Œéƒ¨ç½²éš¾åº¦ã€‚è®ºæ–‡æ—¨åœ¨è§£å†³MLLMä¸­ç”±äºæ–‡æœ¬-è§†è§‰åå·®ï¼ˆè¿‡åº¦ä¾èµ–æ–‡æœ¬æç¤ºï¼‰å’Œå…±ç°åå·®ï¼ˆå¯¹è±¡é—´çš„è™šå‡å…³è”ï¼‰å¯¼è‡´çš„å¹»è§‰é—®é¢˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡åˆ†ææ¨¡å‹è¾“å‡ºå¯¹ä¸åŒè¾“å…¥tokenï¼ˆåŒ…æ‹¬æ–‡æœ¬tokenå’Œè§†è§‰ç‰¹å¾ï¼‰çš„ä¾èµ–ç¨‹åº¦ï¼Œæ¥è¯†åˆ«å¹¶æŠ‘åˆ¶å¯¼è‡´å¹»è§‰çš„å› ç´ ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€è¿‘ä¼¼è®¡ç®—æ¯ä¸ªtokenå¯¹æœ€ç»ˆè¾“å‡ºçš„å½±å“ï¼Œä»è€Œåˆ¤æ–­å“ªäº›è§†è§‰ç‰¹å¾æ˜¯â€œè™šå‡çš„â€ï¼Œå“ªäº›æ–‡æœ¬tokenè¿‡åº¦å½±å“äº†è¾“å‡ºã€‚é€šè¿‡æŠ‘åˆ¶è¿™äº›â€œæœ‰å®³â€çš„tokenï¼Œå¯ä»¥å¼•å¯¼æ¨¡å‹æ›´åŠ å…³æ³¨çœŸå®çš„è§†è§‰ä¿¡æ¯ï¼Œå‡å°‘å¹»è§‰çš„äº§ç”Ÿã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGACDæ–¹æ³•ä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªé˜¶æ®µï¼š1) **å‰å‘ä¼ æ’­**ï¼šè¾“å…¥å›¾åƒå’Œæ–‡æœ¬æç¤ºï¼Œé€šè¿‡MLLMå¾—åˆ°åˆå§‹çš„è¾“å‡ºé¢„æµ‹ã€‚2) **æ¢¯åº¦è®¡ç®—**ï¼šè®¡ç®—è¾“å‡ºé¢„æµ‹å¯¹æ¯ä¸ªè¾“å…¥tokenï¼ˆè§†è§‰ç‰¹å¾å’Œæ–‡æœ¬tokenï¼‰çš„æ¢¯åº¦ã€‚3) **åå·®ä¼°è®¡**ï¼šåˆ©ç”¨æ¢¯åº¦ä¿¡æ¯ä¼°è®¡æ¯ä¸ªtokenå¯¹è¾“å‡ºçš„å½±å“ç¨‹åº¦ï¼Œè¯†åˆ«å‡ºå…·æœ‰é«˜å½±å“åŠ›çš„è™šå‡è§†è§‰ç‰¹å¾å’Œè¿‡åº¦å½±å“çš„æ–‡æœ¬tokenã€‚4) **çº¦æŸè§£ç **ï¼šåœ¨è§£ç è¿‡ç¨‹ä¸­ï¼Œæ ¹æ®åå·®ä¼°è®¡çš„ç»“æœï¼Œå¯¹tokençš„æ¦‚ç‡åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼ŒæŠ‘åˆ¶è™šå‡è§†è§‰ç‰¹å¾ï¼Œå¹¶åŠ å¼ºçœŸå®è§†è§‰ç‰¹å¾çš„è´¡çŒ®ï¼Œä»è€Œç”Ÿæˆæ›´ç¬¦åˆè§†è§‰è¾“å…¥çš„è¾“å‡ºã€‚

**å…³é”®åˆ›æ–°**ï¼šGACDçš„å…³é”®åˆ›æ–°åœ¨äºåˆ©ç”¨æ¢¯åº¦ä¿¡æ¯è¿›è¡Œåå·®ä¼°è®¡ï¼Œä»è€Œå®ç°å¯¹å¹»è§‰çš„æŠ‘åˆ¶ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒGACDæ— éœ€é¢å¤–çš„æ¨¡å‹æˆ–å¾®è°ƒï¼Œå¯ä»¥ç›´æ¥åº”ç”¨äºç°æœ‰çš„MLLMã€‚æ­¤å¤–ï¼ŒGACDèƒ½å¤ŸåŒæ—¶è§£å†³æ–‡æœ¬-è§†è§‰åå·®å’Œå…±ç°åå·®ï¼Œå…·æœ‰æ›´å¼ºçš„é€šç”¨æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šGACDä½¿ç”¨ä¸€é˜¶æ³°å‹’å±•å¼€æ¥è¿‘ä¼¼è®¡ç®—æ¯ä¸ªtokenå¯¹è¾“å‡ºçš„å½±å“ï¼Œå…¬å¼ä¸ºï¼šÎ”y â‰ˆ âˆ‡y * Î”xï¼Œå…¶ä¸­Î”yè¡¨ç¤ºè¾“å‡ºçš„å˜åŒ–ï¼Œâˆ‡yè¡¨ç¤ºè¾“å‡ºå¯¹è¾“å…¥xçš„æ¢¯åº¦ï¼ŒÎ”xè¡¨ç¤ºè¾“å…¥çš„å¾®å°å˜åŒ–ã€‚é€šè¿‡åˆ†æâˆ‡yçš„å¤§å°å’Œæ–¹å‘ï¼Œå¯ä»¥åˆ¤æ–­æ¯ä¸ªtokenå¯¹è¾“å‡ºçš„å½±å“ç¨‹åº¦ã€‚åœ¨çº¦æŸè§£ç é˜¶æ®µï¼ŒGACDé€šè¿‡è°ƒæ•´tokençš„æ¦‚ç‡åˆ†å¸ƒæ¥æŠ‘åˆ¶è™šå‡è§†è§‰ç‰¹å¾å’ŒåŠ å¼ºçœŸå®è§†è§‰ç‰¹å¾çš„è´¡çŒ®ã€‚å…·ä½“çš„è°ƒæ•´ç­–ç•¥å¯ä»¥æ ¹æ®ä¸åŒçš„ä»»åŠ¡å’Œæ¨¡å‹è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGACDåœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šæ˜¾è‘—é™ä½äº†MLLMçš„å¹»è§‰ç‡ï¼Œå¹¶æé«˜äº†è§†è§‰åŸºç¡€çš„å‡†ç¡®æ€§ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒæè¿°ç”Ÿæˆä»»åŠ¡ä¸­ï¼ŒGACDèƒ½å¤Ÿå°†å¹»è§‰ç‡é™ä½10%ä»¥ä¸Šï¼ŒåŒæ—¶ä¿æŒæˆ–ç•¥å¾®æå‡ç”Ÿæˆæ–‡æœ¬çš„è´¨é‡ã€‚ä¸å…¶ä»–åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒGACDåœ¨æ€§èƒ½å’Œæ•ˆç‡æ–¹é¢éƒ½å…·æœ‰ä¼˜åŠ¿ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºéœ€è¦è§†è§‰åŸºç¡€çš„å¤šæ¨¡æ€ä»»åŠ¡ä¸­ï¼Œä¾‹å¦‚å›¾åƒæè¿°ç”Ÿæˆã€è§†è§‰é—®ç­”ã€æœºå™¨äººå¯¼èˆªç­‰ã€‚é€šè¿‡å‡å°‘å¹»è§‰ï¼Œå¯ä»¥æé«˜MLLMåœ¨è¿™äº›ä»»åŠ¡ä¸­çš„å¯é æ€§å’Œå‡†ç¡®æ€§ï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œåº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åœºæ™¯ï¼Œä¾‹å¦‚è§†é¢‘ç†è§£å’Œä¸‰ç»´åœºæ™¯ç†è§£ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Multimodal large language models achieve strong performance across diverse tasks but remain prone to hallucinations, where outputs are not grounded in visual inputs. This issue can be attributed to two main biases: text-visual bias, the overreliance on prompts and prior outputs, and co-occurrence bias, spurious correlations between frequently paired objects. We propose Gradient-based Influence-Aware Constrained Decoding (GACD), an inference-based method, that addresses both biases without auxiliary models, and is readily applicable to existing models without finetuning. The core of our approach is bias estimation, which uses first-order Taylor gradients to understand the contribution of individual tokens-visual features and text tokens-to the current output. Based on this analysis, GACD mitigates hallucinations through two components: (1) suppressing spurious visual features correlated with the output objects, and (2) rebalancing cross-modal contributions by strengthening visual features relative to text. Experiments across multiple benchmarks demonstrate that GACD effectively reduces hallucinations and improves the visual grounding of MLLM outputs.

