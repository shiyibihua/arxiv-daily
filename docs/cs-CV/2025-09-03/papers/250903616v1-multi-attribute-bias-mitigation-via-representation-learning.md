---
layout: default
title: Multi Attribute Bias Mitigation via Representation Learning
---

# Multi Attribute Bias Mitigation via Representation Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.03616" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.03616v1</a>
  <a href="https://arxiv.org/pdf/2509.03616.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.03616v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.03616v1', 'Multi Attribute Bias Mitigation via Representation Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Rajeev Ranjan Dwivedi, Ankur Kumar, Vinod K Kurmi

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-03

**å¤‡æ³¨**: ECAI 2025 (28th European Conference on Artificial Intelligence)

**ğŸ”— ä»£ç /é¡¹ç›®**: [PROJECT_PAGE](http://visdomlab.github.io/GMBM/)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºGMBMæ¡†æ¶ï¼Œé€šè¿‡è¡¨å¾å­¦ä¹ ç¼“è§£è§†è§‰æ¨¡å‹ä¸­çš„å¤šé‡å±æ€§åå·®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `å¤šé‡åå·®ç¼“è§£` `è¡¨å¾å­¦ä¹ ` `å…¬å¹³æ€§` `é²æ£’æ€§` `è§†è§‰è¯†åˆ«` `æ¢¯åº¦æŠ‘åˆ¶` `è‡ªé€‚åº”å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰æ¨¡å‹æ˜“å—å¤šç§åå·®å½±å“ï¼Œå•ç‹¬ç¼“è§£æ•ˆæœä¸ä½³ï¼Œç”šè‡³ä¼šåŠ å‰§å…¶ä»–åå·®ã€‚
2. GMBMæ¡†æ¶é€šè¿‡è‡ªé€‚åº”å­¦ä¹ å’Œæ¢¯åº¦æŠ‘åˆ¶ï¼Œæ˜¾å¼è¯†åˆ«å¹¶æ¶ˆé™¤åå·®ï¼Œå®ç°å¤šåå·®ç¼“è§£ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒGMBMåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†æœ€å·®ç»„å‡†ç¡®ç‡ï¼Œå¹¶é™ä½äº†åå·®æ”¾å¤§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

çœŸå®ä¸–ç•Œçš„å›¾åƒç»å¸¸è¡¨ç°å‡ºå¤šç§é‡å çš„åå·®ï¼ŒåŒ…æ‹¬çº¹ç†ã€æ°´å°ã€æ€§åˆ«åŒ–çš„å¦†å®¹ã€åœºæ™¯å¯¹è±¡é…å¯¹ç­‰ã€‚è¿™äº›åå·®å…±åŒæŸå®³äº†ç°ä»£è§†è§‰æ¨¡å‹çš„æ€§èƒ½ï¼Œå‰Šå¼±äº†å®ƒä»¬çš„é²æ£’æ€§å’Œå…¬å¹³æ€§ã€‚å•ç‹¬è§£å†³è¿™äº›åå·®æ˜¯ä¸å¤Ÿçš„ï¼Œå› ä¸ºå‡è½»ä¸€ä¸ªåå·®é€šå¸¸ä¼šå…è®¸æˆ–åŠ å‰§å…¶ä»–åå·®ã€‚æœ¬æ–‡æå‡ºäº†å¹¿ä¹‰å¤šåå·®ç¼“è§£ï¼ˆGMBMï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªç²¾ç®€çš„ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œä»…åœ¨è®­ç»ƒæ—¶éœ€è¦ç»„æ ‡ç­¾ï¼Œå¹¶åœ¨æµ‹è¯•æ—¶æœ€å°åŒ–åå·®ã€‚é¦–å…ˆï¼Œè‡ªé€‚åº”åå·®é›†æˆå­¦ä¹ ï¼ˆABILï¼‰é€šè¿‡è®­ç»ƒæ¯ä¸ªå±æ€§çš„ç¼–ç å™¨å¹¶å°†å®ƒä»¬ä¸ä¸»å¹²ç½‘ç»œé›†æˆï¼Œä»è€Œæœ‰æ„è¯†åœ°è¯†åˆ«å·²çŸ¥æ·å¾„çš„å½±å“ï¼Œè¿«ä½¿åˆ†ç±»å™¨æ˜ç¡®è¯†åˆ«è¿™äº›åå·®ã€‚ç„¶åï¼Œæ¢¯åº¦æŠ‘åˆ¶å¾®è°ƒä»ä¸»å¹²ç½‘ç»œçš„æ¢¯åº¦ä¸­ä¿®å‰ªæ‰è¿™äº›åå·®æ–¹å‘ï¼Œç•™ä¸‹ä¸€ä¸ªå¿½ç•¥æ‰€æœ‰åˆšåˆšå­¦ä¼šè¯†åˆ«çš„æ·å¾„çš„ç´§å‡‘ç½‘ç»œã€‚æ­¤å¤–ï¼Œæœ¬æ–‡å‘ç°ç°æœ‰çš„åå·®åº¦é‡åœ¨å­ç»„ä¸å¹³è¡¡ä»¥åŠè®­ç»ƒæµ‹è¯•åˆ†å¸ƒåç§»ä¸‹ä¼šå¤±æ•ˆï¼Œå› æ­¤å¼•å…¥äº†ç¼©æ”¾åå·®æ”¾å¤§ï¼ˆSBAï¼‰ï¼šä¸€ç§æµ‹è¯•æ—¶åº¦é‡ï¼Œå¯å°†æ¨¡å‹å¼•èµ·çš„åå·®æ”¾å¤§ä¸åˆ†å¸ƒå·®å¼‚åˆ†ç¦»å¼€æ¥ã€‚åœ¨FB CMNISTã€CelebAå’ŒCOCOä¸ŠéªŒè¯äº†GMBMï¼Œå³ä½¿åå·®å¤æ‚æ€§å’Œåˆ†å¸ƒåç§»åŠ å‰§ï¼Œä¹Ÿèƒ½æé«˜æœ€å·®ç»„çš„å‡†ç¡®ç‡ï¼Œå°†å¤šå±æ€§åå·®æ”¾å¤§å‡åŠï¼Œå¹¶åœ¨SBAä¸­åˆ›ä¸‹æ–°ä½ï¼Œä½¿GMBMæˆä¸ºç¬¬ä¸€ä¸ªå®ç”¨çš„ã€ç«¯åˆ°ç«¯çš„å¤šåå·®è§†è§‰è¯†åˆ«è§£å†³æ–¹æ¡ˆã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šç°æœ‰è§†è§‰æ¨¡å‹åœ¨çœŸå®ä¸–ç•Œå›¾åƒä¸­é¢ä¸´å¤šé‡åå·®çš„æŒ‘æˆ˜ï¼Œä¾‹å¦‚çº¹ç†ã€æ°´å°ã€æ€§åˆ«åŒ–å¦†å®¹ç­‰ã€‚è¿™äº›åå·®å¯¼è‡´æ¨¡å‹æ€§èƒ½ä¸‹é™ï¼Œé²æ£’æ€§å’Œå…¬å¹³æ€§å—æŸã€‚ç°æœ‰æ–¹æ³•é€šå¸¸å•ç‹¬è§£å†³è¿™äº›åå·®ï¼Œä½†æ•ˆæœæœ‰é™ï¼Œç”šè‡³å¯èƒ½åŠ å‰§å…¶ä»–åå·®ï¼Œç¼ºä¹ä¸€ä¸ªé€šç”¨çš„å¤šåå·®ç¼“è§£æ–¹æ¡ˆã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šGMBMçš„æ ¸å¿ƒæ€è·¯æ˜¯é¦–å…ˆæ˜¾å¼åœ°å­¦ä¹ å¹¶è¯†åˆ«è¿™äº›åå·®ï¼Œç„¶åä»æ¨¡å‹çš„æ¢¯åº¦ä¸­ç§»é™¤è¿™äº›åå·®æ–¹å‘ï¼Œä»è€Œä½¿æ¨¡å‹å¿½ç•¥è¿™äº›åå·®ã€‚é€šè¿‡ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ï¼Œæ¨¡å‹èƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é²æ£’å’Œå…¬å¹³çš„ç‰¹å¾è¡¨ç¤ºã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šGMBMæ¡†æ¶åŒ…å«ä¸¤ä¸ªä¸»è¦é˜¶æ®µï¼šè‡ªé€‚åº”åå·®é›†æˆå­¦ä¹ ï¼ˆABILï¼‰å’Œæ¢¯åº¦æŠ‘åˆ¶å¾®è°ƒã€‚ABILé˜¶æ®µï¼Œä¸ºæ¯ä¸ªå±æ€§è®­ç»ƒä¸€ä¸ªç¼–ç å™¨ï¼Œå¹¶å°†å®ƒä»¬ä¸ä¸»å¹²ç½‘ç»œé›†æˆï¼Œè¿«ä½¿åˆ†ç±»å™¨è¯†åˆ«è¿™äº›åå·®ã€‚åœ¨æ¢¯åº¦æŠ‘åˆ¶å¾®è°ƒé˜¶æ®µï¼Œä»ä¸»å¹²ç½‘ç»œçš„æ¢¯åº¦ä¸­ä¿®å‰ªæ‰è¿™äº›åå·®æ–¹å‘ï¼Œå¾—åˆ°ä¸€ä¸ªå¿½ç•¥åå·®çš„ç´§å‡‘ç½‘ç»œã€‚

**å…³é”®åˆ›æ–°**ï¼šGMBMçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ä¸¤é˜¶æ®µçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°è¯†åˆ«å¹¶æ¶ˆé™¤å¤šé‡åå·®ã€‚ABILé˜¶æ®µæ˜¾å¼åœ°å­¦ä¹ åå·®ï¼Œè€Œæ¢¯åº¦æŠ‘åˆ¶å¾®è°ƒé˜¶æ®µåˆ™ä»æ¢¯åº¦å±‚é¢ç§»é™¤åå·®ï¼Œä»è€Œé¿å…äº†æ¨¡å‹ä¾èµ–äºè¿™äº›åå·®ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†ç¼©æ”¾åå·®æ”¾å¤§ï¼ˆSBAï¼‰åº¦é‡ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨æµ‹è¯•æ—¶çš„åå·®æ”¾å¤§æƒ…å†µã€‚

**å…³é”®è®¾è®¡**ï¼šABILé˜¶æ®µï¼Œæ¯ä¸ªå±æ€§çš„ç¼–ç å™¨å¯ä»¥æ˜¯ä»»ä½•æ ‡å‡†çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚æ¢¯åº¦æŠ‘åˆ¶å¾®è°ƒé˜¶æ®µï¼Œé€šè¿‡è®¡ç®—æ¯ä¸ªåå·®æ–¹å‘çš„æ¢¯åº¦ï¼Œå¹¶å°†å…¶ä»ä¸»å¹²ç½‘ç»œçš„æ¢¯åº¦ä¸­å‡å»ï¼Œä»è€Œå®ç°åå·®çš„ç§»é™¤ã€‚SBAåº¦é‡é€šè¿‡è€ƒè™‘å­ç»„ä¸å¹³è¡¡å’Œåˆ†å¸ƒåç§»ï¼Œæ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„åå·®æ”¾å¤§æƒ…å†µã€‚æŸå¤±å‡½æ•°çš„è®¾è®¡æ—¨åœ¨å¹³è¡¡æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå…¬å¹³æ€§ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒGMBMåœ¨FB CMNISTã€CelebAå’ŒCOCOæ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚åœ¨è¿™äº›æ•°æ®é›†ä¸Šï¼ŒGMBMæé«˜äº†æœ€å·®ç»„çš„å‡†ç¡®ç‡ï¼Œå°†å¤šå±æ€§åå·®æ”¾å¤§å‡åŠï¼Œå¹¶åœ¨SBAæŒ‡æ ‡ä¸Šåˆ›ä¸‹æ–°ä½ã€‚ä¾‹å¦‚ï¼Œåœ¨CelebAæ•°æ®é›†ä¸Šï¼ŒGMBMå°†æœ€å·®ç»„çš„å‡†ç¡®ç‡æé«˜äº†X%ï¼Œå¹¶å°†SBAæŒ‡æ ‡é™ä½äº†Y%ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒGMBMæ˜¯ä¸€ç§æœ‰æ•ˆçš„å¤šåå·®ç¼“è§£æ–¹æ³•ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

GMBMæ¡†æ¶å¯åº”ç”¨äºå„ç§è§†è§‰è¯†åˆ«ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹å’Œäººè„¸è¯†åˆ«ç­‰ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæé«˜æ¨¡å‹åœ¨å­˜åœ¨å¤šé‡åå·®æƒ…å†µä¸‹çš„é²æ£’æ€§å’Œå…¬å¹³æ€§ï¼Œä»è€Œåœ¨åŒ»ç–—è¯Šæ–­ã€è‡ªåŠ¨é©¾é©¶å’Œå®‰å…¨ç›‘æ§ç­‰é¢†åŸŸå…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•å¯ä»¥è¿›ä¸€æ­¥æ‰©å±•åˆ°å…¶ä»–æ¨¡æ€æ•°æ®ï¼Œä¾‹å¦‚æ–‡æœ¬å’Œè¯­éŸ³ï¼Œä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®ä¸­çš„åå·®é—®é¢˜ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Real world images frequently exhibit multiple overlapping biases, including textures, watermarks, gendered makeup, scene object pairings, etc. These biases collectively impair the performance of modern vision models, undermining both their robustness and fairness. Addressing these biases individually proves inadequate, as mitigating one bias often permits or intensifies others. We tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a lean two stage framework that needs group labels only while training and minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL) deliberately identifies the influence of known shortcuts by training encoders for each attribute and integrating them with the main backbone, compelling the classifier to explicitly recognize these biases. Then Gradient Suppression Fine Tuning prunes those very bias directions from the backbone's gradients, leaving a single compact network that ignores all the shortcuts it just learned to recognize. Moreover we find that existing bias metrics break under subgroup imbalance and train test distribution shifts, so we introduce Scaled Bias Amplification (SBA): a test time measure that disentangles model induced bias amplification from distributional differences. We validate GMBM on FB CMNIST, CelebA, and COCO, where we boost worst group accuracy, halve multi attribute bias amplification, and set a new low in SBA even as bias complexity and distribution shifts intensify, making GMBM the first practical, end to end multibias solution for visual recognition. Project page: http://visdomlab.github.io/GMBM/

