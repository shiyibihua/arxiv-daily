---
layout: default
title: SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality
---

# SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2508.17255" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2508.17255v1</a>
  <a href="https://arxiv.org/pdf/2508.17255.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2508.17255v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2508.17255v1', 'SEER-VAR: Semantic Egocentric Environment Reasoner for Vehicle Augmented Reality')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Yuzhi Lai, Shenghai Yuan, Peizheng Li, Jun Lou, Andreas Zell

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-08-24

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSEER-VARä»¥è§£å†³åŠ¨æ€ç¯å¢ƒä¸‹è½¦è¾†å¢å¼ºç°å®é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)** **æ”¯æŸ±å…­ï¼šè§†é¢‘æå–ä¸åŒ¹é… (Video Extraction)**

**å…³é”®è¯**: `å¢å¼ºç°å®` `è‡ªæˆ‘è¿åŠ¨è·Ÿè¸ª` `è¯­ä¹‰åˆ†è§£` `ä¸Šä¸‹æ–‡æ„ŸçŸ¥` `å¤§è¯­è¨€æ¨¡å‹` `æ™ºèƒ½é©¾é©¶` `ARæ¨è`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰å¢å¼ºç°å®ç³»ç»Ÿé€šå¸¸å‡è®¾é™æ€æˆ–å•ä¸€è§†å›¾ï¼Œæ— æ³•æœ‰æ•ˆå¤„ç†åŠ¨æ€é©¾é©¶ç¯å¢ƒä¸­çš„å¤æ‚åœºæ™¯ã€‚
2. SEER-VARé€šè¿‡æ·±åº¦å¼•å¯¼çš„è§†è§‰-è¯­è¨€åŸºç¡€ï¼ŒåŠ¨æ€åˆ†ç¦»é©¾é©¶èˆ±å’Œé“è·¯åœºæ™¯ï¼Œå¹¶å¼•å…¥ä¸Šä¸‹æ–‡æ„ŸçŸ¥SLAMåˆ†æ”¯ä»¥è·Ÿè¸ªè‡ªæˆ‘è¿åŠ¨ã€‚
3. å®éªŒç»“æœè¡¨æ˜ï¼ŒSEER-VARåœ¨ç©ºé—´å¯¹é½å’ŒARæ¸²æŸ“çš„ä¸€è‡´æ€§ä¸Šè¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—æå‡äº†åœºæ™¯ç†è§£å’Œå åŠ ä¿¡æ¯çš„ç›¸å…³æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æˆ‘ä»¬æå‡ºäº†SEER-VARï¼Œä¸€ä¸ªæ–°é¢–çš„åŸºäºè½¦è¾†çš„å¢å¼ºç°å®ï¼ˆARï¼‰æ¡†æ¶ï¼Œç»Ÿä¸€äº†è¯­ä¹‰åˆ†è§£ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥SLAMåˆ†æ”¯ï¼ˆCASBï¼‰å’ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ¨èã€‚ä¸ç°æœ‰ç³»ç»Ÿå‡è®¾é™æ€æˆ–å•è§†å›¾è®¾ç½®ä¸åŒï¼ŒSEER-VARé€šè¿‡æ·±åº¦å¼•å¯¼çš„è§†è§‰-è¯­è¨€åŸºç¡€ï¼ŒåŠ¨æ€åˆ†ç¦»é©¾é©¶èˆ±å’Œé“è·¯åœºæ™¯ã€‚ä¸¤ä¸ªSLAMåˆ†æ”¯åœ¨æ¯ä¸ªä¸Šä¸‹æ–‡ä¸­è·Ÿè¸ªè‡ªæˆ‘è¿åŠ¨ï¼ŒåŒæ—¶åŸºäºGPTçš„æ¨¡å—ç”Ÿæˆä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å åŠ ä¿¡æ¯ï¼Œå¦‚ä»ªè¡¨æ¿æç¤ºå’Œå±é™©è­¦æŠ¥ã€‚ä¸ºæ”¯æŒè¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº†EgoSLAM-Driveï¼Œä¸€ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ŒåŒ…å«åŒæ­¥çš„è‡ªæˆ‘è§†å›¾ã€6DoFçœŸå®ä½å§¿å’Œå¤šæ ·é©¾é©¶åœºæ™¯çš„ARæ³¨é‡Šã€‚å®éªŒè¡¨æ˜ï¼ŒSEER-VARåœ¨ä¸åŒç¯å¢ƒä¸­å®ç°äº†ç¨³å¥çš„ç©ºé—´å¯¹é½å’Œæ„ŸçŸ¥ä¸€è‡´çš„ARæ¸²æŸ“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬è®ºæ–‡æ—¨åœ¨è§£å†³ç°æœ‰å¢å¼ºç°å®ç³»ç»Ÿåœ¨åŠ¨æ€é©¾é©¶ç¯å¢ƒä¸­æ— æ³•æœ‰æ•ˆå¤„ç†å¤æ‚åœºæ™¯çš„é—®é¢˜ï¼Œå°¤å…¶æ˜¯åœ¨é©¾é©¶èˆ±ä¸é“è·¯åœºæ™¯çš„åˆ†ç¦»å’Œç†è§£ä¸Šå­˜åœ¨çš„ä¸è¶³ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šSEER-VARçš„æ ¸å¿ƒæ€è·¯æ˜¯é€šè¿‡æ·±åº¦å¼•å¯¼çš„è§†è§‰-è¯­è¨€åŸºç¡€ï¼ŒåŠ¨æ€åˆ†ç¦»ä¸åŒçš„åœºæ™¯ï¼Œå¹¶ç»“åˆä¸Šä¸‹æ–‡æ„ŸçŸ¥SLAMåˆ†æ”¯æ¥è·Ÿè¸ªè‡ªæˆ‘è¿åŠ¨ï¼Œä»è€Œå®ç°æ›´ä¸ºå‡†ç¡®å’Œå®æ—¶çš„ARå åŠ ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè¯¥æ¡†æ¶ä¸»è¦ç”±ä¸‰ä¸ªæ¨¡å—ç»„æˆï¼šè¯­ä¹‰åˆ†è§£æ¨¡å—ç”¨äºåœºæ™¯çš„åŠ¨æ€åˆ†ç¦»ï¼Œä¸Šä¸‹æ–‡æ„ŸçŸ¥SLAMåˆ†æ”¯ç”¨äºè·Ÿè¸ªè‡ªæˆ‘è¿åŠ¨ï¼Œä»¥åŠåŸºäºGPTçš„æ¨èæ¨¡å—ç”¨äºç”Ÿæˆä¸Šä¸‹æ–‡ç›¸å…³çš„ARå åŠ ä¿¡æ¯ã€‚

**å…³é”®åˆ›æ–°**ï¼šSEER-VARçš„åˆ›æ–°åœ¨äºé¦–æ¬¡å°†å¤§è¯­è¨€æ¨¡å‹åº”ç”¨äºå¢å¼ºç°å®æ¨èï¼Œåˆ©ç”¨ç»“æ„åŒ–æç¤ºå’Œç”¨æˆ·ç ”ç©¶æ¥æå‡ARä½“éªŒçš„ç›¸å…³æ€§å’Œç†è§£åº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨è®¾è®¡ä¸­ï¼Œé‡‡ç”¨äº†æ·±åº¦å¼•å¯¼çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œåœºæ™¯åˆ†ç¦»ï¼ŒSLAMåˆ†æ”¯é€šè¿‡6DoFçœŸå®ä½å§¿è¿›è¡Œè‡ªæˆ‘è¿åŠ¨è·Ÿè¸ªï¼ŒæŸå¤±å‡½æ•°åˆ™é’ˆå¯¹ç©ºé—´å¯¹é½å’Œæ¸²æŸ“ä¸€è‡´æ€§è¿›è¡Œäº†ä¼˜åŒ–ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSEER-VARåœ¨å¤šç§é©¾é©¶åœºæ™¯ä¸­å®ç°äº†ç¨³å¥çš„ç©ºé—´å¯¹é½ï¼ŒARæ¸²æŸ“çš„ä¸€è‡´æ€§æ˜¾è‘—æå‡ï¼Œç”¨æˆ·ä½“éªŒè°ƒæŸ¥è¡¨æ˜ï¼Œå åŠ ä¿¡æ¯çš„ç›¸å…³æ€§å’Œé©¾é©¶å‘˜çš„æ˜“ç”¨æ€§å‡å¾—åˆ°äº†æ˜¾è‘—æ”¹å–„ã€‚å…·ä½“æ€§èƒ½æ•°æ®å°šæœªæŠ«éœ²ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬æ™ºèƒ½é©¾é©¶ã€å¢å¼ºç°å®å¯¼èˆªå’Œè½¦è½½ä¿¡æ¯ç³»ç»Ÿç­‰ã€‚é€šè¿‡æå‡é©¾é©¶å‘˜å¯¹å‘¨å›´ç¯å¢ƒçš„ç†è§£å’Œååº”èƒ½åŠ›ï¼ŒSEER-VARèƒ½å¤Ÿæ˜¾è‘—æé«˜é©¾é©¶å®‰å…¨æ€§å’Œç”¨æˆ·ä½“éªŒï¼Œæœªæ¥å¯èƒ½åœ¨è‡ªåŠ¨é©¾é©¶å’Œæ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> We present SEER-VAR, a novel framework for egocentric vehicle-based augmented reality (AR) that unifies semantic decomposition, Context-Aware SLAM Branches (CASB), and LLM-driven recommendation. Unlike existing systems that assume static or single-view settings, SEER-VAR dynamically separates cabin and road scenes via depth-guided vision-language grounding. Two SLAM branches track egocentric motion in each context, while a GPT-based module generates context-aware overlays such as dashboard cues and hazard alerts. To support evaluation, we introduce EgoSLAM-Drive, a real-world dataset featuring synchronized egocentric views, 6DoF ground-truth poses, and AR annotations across diverse driving scenarios. Experiments demonstrate that SEER-VAR achieves robust spatial alignment and perceptually coherent AR rendering across varied environments. As one of the first to explore LLM-based AR recommendation in egocentric driving, we address the lack of comparable systems through structured prompting and detailed user studies. Results show that SEER-VAR enhances perceived scene understanding, overlay relevance, and driver ease, providing an effective foundation for future research in this direction. Code and dataset will be made open source.

