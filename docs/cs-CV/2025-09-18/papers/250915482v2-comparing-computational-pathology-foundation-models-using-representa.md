---
layout: default
title: Comparing Computational Pathology Foundation Models using Representational Similarity Analysis
---

# Comparing Computational Pathology Foundation Models using Representational Similarity Analysis

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15482" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15482v2</a>
  <a href="https://arxiv.org/pdf/2509.15482.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15482v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15482v2', 'Comparing Computational Pathology Foundation Models using Representational Similarity Analysis')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Vaibhav Mishra, William Lotter

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-11-05)

**å¤‡æ³¨**: Proceedings of the 5th Machine Learning for Health (ML4H) Symposium

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**åˆ©ç”¨è¡¨å¾ç›¸ä¼¼æ€§åˆ†ææ¯”è¾ƒè®¡ç®—ç—…ç†å­¦é¢†åŸŸå¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹ï¼Œæ­ç¤ºå…¶è¡¨å¾ç»“æ„å·®å¼‚ã€‚**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è®¡ç®—ç—…ç†å­¦` `é¢„è®­ç»ƒæ¨¡å‹` `è¡¨å¾ç›¸ä¼¼æ€§åˆ†æ` `æ¨¡å‹é›†æˆ` `åŒ»å­¦å½±åƒ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. è®¡ç®—ç—…ç†å­¦é¢„è®­ç»ƒæ¨¡å‹å‘å±•è¿…é€Ÿï¼Œä½†å¯¹å…¶å†…éƒ¨è¡¨å¾çš„ç»“æ„å’Œå·®å¼‚æ€§ç¼ºä¹æ·±å…¥äº†è§£ï¼Œé˜»ç¢äº†æ¨¡å‹ä¼˜åŒ–å’Œé›†æˆã€‚
2. è®ºæ–‡é‡‡ç”¨è¡¨å¾ç›¸ä¼¼æ€§åˆ†æï¼ˆRSAï¼‰æ–¹æ³•ï¼Œç³»ç»Ÿæ¯”è¾ƒäº†å…­ä¸ªä¸»æµè®¡ç®—ç—…ç†å­¦é¢„è®­ç»ƒæ¨¡å‹çš„è¡¨å¾ç©ºé—´ã€‚
3. å®éªŒå‘ç°ä¸åŒæ¨¡å‹è¡¨å¾ç»“æ„å·®å¼‚æ˜¾è‘—ï¼Œä¸”æ¨¡å‹è¡¨å¾å¯¹åˆ‡ç‰‡ä¾èµ–æ€§é«˜ï¼ŒæŸ“è‰²æ ‡å‡†åŒ–èƒ½æœ‰æ•ˆé™ä½è¿™ç§ä¾èµ–æ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è®¡ç®—ç—…ç†å­¦ï¼ˆCPathï¼‰é¢†åŸŸä¸­ï¼Œé¢„è®­ç»ƒæ¨¡å‹å› å…¶åœ¨ä¿ƒè¿›ä¸‹æ¸¸ä»»åŠ¡æ–¹é¢çš„æ½œåŠ›è€Œå¾—åˆ°è¶Šæ¥è¶Šå¤šçš„å‘å±•ã€‚å°½ç®¡æœ€è¿‘çš„ç ”ç©¶å·²ç»è¯„ä¼°äº†ä¸åŒæ¨¡å‹åœ¨ä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œä½†å¯¹å…¶å­¦ä¹ åˆ°çš„è¡¨å¾çš„ç»“æ„å’Œå˜å¼‚æ€§çŸ¥ä¹‹ç”šå°‘ã€‚æœ¬æ–‡ç³»ç»Ÿåœ°åˆ†æäº†å…­ä¸ªCPathé¢„è®­ç»ƒæ¨¡å‹çš„è¡¨å¾ç©ºé—´ï¼Œä½¿ç”¨äº†è®¡ç®—ç¥ç»ç§‘å­¦ä¸­æµè¡Œçš„æŠ€æœ¯ã€‚åˆ†æçš„æ¨¡å‹æ¶µç›–äº†è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ ï¼ˆCONCHã€PLIPã€KEEPï¼‰å’Œè‡ªè’¸é¦ï¼ˆUNI (v2)ã€Virchow (v2)ã€Prov-GigaPathï¼‰æ–¹æ³•ã€‚é€šè¿‡ä½¿ç”¨æ¥è‡ªTCGAçš„H&Eå›¾åƒå—è¿›è¡Œè¡¨å¾ç›¸ä¼¼æ€§åˆ†æï¼Œå‘ç°UNI2å’ŒVirchow2å…·æœ‰æœ€ç‹¬ç‰¹çš„è¡¨å¾ç»“æ„ï¼Œè€ŒProv-Gigapathåœ¨æ¨¡å‹ä¸­å…·æœ‰æœ€é«˜çš„å¹³å‡ç›¸ä¼¼æ€§ã€‚å…·æœ‰ç›¸åŒçš„è®­ç»ƒèŒƒå¼ï¼ˆä»…è§†è§‰ä¸è§†è§‰-è¯­è¨€ï¼‰å¹¶ä¸èƒ½ä¿è¯æ›´é«˜çš„è¡¨å¾ç›¸ä¼¼æ€§ã€‚æ‰€æœ‰æ¨¡å‹çš„è¡¨å¾éƒ½è¡¨ç°å‡ºé«˜åº¦çš„åˆ‡ç‰‡ä¾èµ–æ€§ï¼Œä½†ç–¾ç—…ä¾èµ–æ€§ç›¸å¯¹è¾ƒä½ã€‚æŸ“è‰²æ ‡å‡†åŒ–ä½¿æ‰€æœ‰æ¨¡å‹çš„åˆ‡ç‰‡ä¾èµ–æ€§é™ä½äº†5.5%ï¼ˆCONCHï¼‰åˆ°20.5%ï¼ˆPLIPï¼‰ã€‚åœ¨å†…åœ¨ç»´åº¦æ–¹é¢ï¼Œä¸ä»…è§†è§‰æ¨¡å‹çš„æ›´åˆ†å¸ƒå¼è¡¨å¾ç›¸æ¯”ï¼Œè§†è§‰-è¯­è¨€æ¨¡å‹è¡¨ç°å‡ºç›¸å¯¹ç´§å‡‘çš„è¡¨å¾ã€‚è¿™äº›å‘ç°çªå‡ºäº†æé«˜å¯¹åˆ‡ç‰‡ç‰¹å®šç‰¹å¾çš„é²æ£’æ€§çš„æœºä¼šï¼Œä¸ºæ¨¡å‹é›†æˆç­–ç•¥æä¾›äº†ä¿¡æ¯ï¼Œå¹¶æ·±å…¥äº†è§£äº†è®­ç»ƒèŒƒå¼å¦‚ä½•å¡‘é€ æ¨¡å‹è¡¨å¾ã€‚æˆ‘ä»¬çš„æ¡†æ¶å¯ä»¥æ‰©å±•åˆ°åŒ»å­¦æˆåƒé¢†åŸŸï¼Œåœ¨è¿™äº›é¢†åŸŸä¸­ï¼Œæ¢æµ‹é¢„è®­ç»ƒæ¨¡å‹çš„å†…éƒ¨è¡¨å¾å¯ä»¥æ”¯æŒå…¶æœ‰æ•ˆå¼€å‘å’Œéƒ¨ç½²ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®¡ç®—ç—…ç†å­¦é¢†åŸŸæ¶Œç°å‡ºå¤§é‡é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†å¦‚ä½•ç†è§£å’Œæ¯”è¾ƒè¿™äº›æ¨¡å‹çš„å†…éƒ¨è¡¨å¾ï¼Œä»¥åŠå¦‚ä½•åˆ©ç”¨è¿™äº›ä¿¡æ¯æ¥æ”¹è¿›æ¨¡å‹æ€§èƒ½å’Œé›†æˆç­–ç•¥ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„æŒ‘æˆ˜ã€‚ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„æ€§èƒ½ï¼Œè€Œå¿½ç•¥äº†å¯¹å…¶å†…éƒ¨è¡¨å¾ç»“æ„çš„æ·±å…¥åˆ†æã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨è¡¨å¾ç›¸ä¼¼æ€§åˆ†æï¼ˆRSAï¼‰è¿™ä¸€å·¥å…·ï¼Œå°†ä¸åŒé¢„è®­ç»ƒæ¨¡å‹å¯¹åŒä¸€æ‰¹å›¾åƒçš„è¡¨å¾è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œæ­ç¤ºå®ƒä»¬åœ¨å­¦ä¹ åˆ°çš„ç‰¹å¾ç©ºé—´ä¸Šçš„å·®å¼‚å’Œç›¸ä¼¼æ€§ã€‚é€šè¿‡åˆ†æè¿™äº›å·®å¼‚ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ä¸åŒè®­ç»ƒèŒƒå¼å¯¹æ¨¡å‹è¡¨å¾çš„å½±å“ï¼Œå¹¶ä¸ºæ¨¡å‹é›†æˆå’Œä¼˜åŒ–æä¾›æŒ‡å¯¼ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šè®ºæ–‡çš„æŠ€æœ¯æ¡†æ¶ä¸»è¦åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š1ï¼‰é€‰æ‹©å…­ä¸ªå…·æœ‰ä»£è¡¨æ€§çš„è®¡ç®—ç—…ç†å­¦é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ¶µç›–è§†è§‰-è¯­è¨€å¯¹æ¯”å­¦ä¹ å’Œè‡ªè’¸é¦ç­‰ä¸åŒè®­ç»ƒèŒƒå¼ï¼›2ï¼‰ä½¿ç”¨æ¥è‡ªTCGAçš„H&EæŸ“è‰²ç—…ç†å›¾åƒå—ä½œä¸ºè¾“å…¥ï¼›3ï¼‰æå–æ¯ä¸ªæ¨¡å‹å¯¹è¿™äº›å›¾åƒå—çš„è¡¨å¾å‘é‡ï¼›4ï¼‰è®¡ç®—ä¸åŒæ¨¡å‹è¡¨å¾ä¹‹é—´çš„ç›¸ä¼¼æ€§çŸ©é˜µï¼›5ï¼‰åˆ†æç›¸ä¼¼æ€§çŸ©é˜µï¼Œæ­ç¤ºä¸åŒæ¨¡å‹è¡¨å¾ç»“æ„çš„å·®å¼‚å’Œç›¸ä¼¼æ€§ï¼Œä»¥åŠå®ƒä»¬å¯¹åˆ‡ç‰‡å’Œç–¾ç—…çš„ä¾èµ–æ€§ã€‚

**å…³é”®åˆ›æ–°**ï¼šè®ºæ–‡çš„å…³é”®åˆ›æ–°åœ¨äºå°†è¡¨å¾ç›¸ä¼¼æ€§åˆ†æè¿™ä¸€åœ¨è®¡ç®—ç¥ç»ç§‘å­¦ä¸­å¹¿æ³›åº”ç”¨çš„æ–¹æ³•å¼•å…¥åˆ°è®¡ç®—ç—…ç†å­¦é¢†åŸŸï¼Œç”¨äºæ¯”è¾ƒå’Œç†è§£ä¸åŒé¢„è®­ç»ƒæ¨¡å‹çš„å†…éƒ¨è¡¨å¾ã€‚è¿™ç§æ–¹æ³•èƒ½å¤Ÿæä¾›æ¯”ä¼ ç»Ÿä»»åŠ¡æ€§èƒ½è¯„ä¼°æ›´æ·±å…¥çš„æ´å¯Ÿï¼Œå¸®åŠ©ç ”ç©¶äººå‘˜æ›´å¥½åœ°ç†è§£æ¨¡å‹è¡Œä¸ºï¼Œå¹¶æŒ‡å¯¼æ¨¡å‹è®¾è®¡å’Œé›†æˆã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡çš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1ï¼‰é€‰æ‹©å…·æœ‰ä»£è¡¨æ€§çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¦†ç›–ä¸åŒçš„è®­ç»ƒèŒƒå¼ï¼›2ï¼‰ä½¿ç”¨æ¥è‡ªTCGAçš„H&EæŸ“è‰²å›¾åƒå—ï¼Œä¿è¯äº†å®éªŒæ•°æ®çš„å¤šæ ·æ€§å’Œä»£è¡¨æ€§ï¼›3ï¼‰é‡‡ç”¨å¤šç§è¡¨å¾ç›¸ä¼¼æ€§åº¦é‡æ–¹æ³•ï¼Œä»¥ç¡®ä¿ç»“æœçš„ç¨³å¥æ€§ï¼›4ï¼‰åˆ†ææ¨¡å‹è¡¨å¾å¯¹åˆ‡ç‰‡å’Œç–¾ç—…çš„ä¾èµ–æ€§ï¼Œæ­ç¤ºäº†æ¨¡å‹æ½œåœ¨çš„åå·®ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒUNI2å’ŒVirchow2å…·æœ‰æœ€ç‹¬ç‰¹çš„è¡¨å¾ç»“æ„ï¼Œè€ŒProv-Gigapathå…·æœ‰æœ€é«˜çš„å¹³å‡ç›¸ä¼¼æ€§ã€‚è§†è§‰-è¯­è¨€æ¨¡å‹å±•ç°å‡ºç›¸å¯¹ç´§å‡‘çš„è¡¨å¾ï¼Œè€Œä»…è§†è§‰æ¨¡å‹åˆ™å…·æœ‰æ›´åˆ†æ•£çš„è¡¨å¾ã€‚æŸ“è‰²æ ‡å‡†åŒ–èƒ½å¤Ÿæ˜¾è‘—é™ä½æ¨¡å‹å¯¹åˆ‡ç‰‡çš„ä¾èµ–æ€§ï¼Œæœ€é«˜å¯é™ä½20.5%ï¼ˆPLIPï¼‰ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºè®¡ç®—ç—…ç†å­¦æ¨¡å‹çš„é€‰æ‹©ã€é›†æˆä¸ä¼˜åŒ–ã€‚é€šè¿‡ç†è§£ä¸åŒæ¨¡å‹çš„è¡¨å¾å·®å¼‚ï¼Œå¯ä»¥é€‰æ‹©äº’è¡¥çš„æ¨¡å‹è¿›è¡Œé›†æˆï¼Œæé«˜æ•´ä½“æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºè¯Šæ–­æ¨¡å‹åå·®ï¼Œä¾‹å¦‚å¯¹ç‰¹å®šåˆ‡ç‰‡æˆ–ç–¾ç—…çš„è¿‡åº¦ä¾èµ–ï¼Œä»è€ŒæŒ‡å¯¼æ¨¡å‹æ”¹è¿›ï¼Œæå‡æ³›åŒ–èƒ½åŠ›ã€‚è¯¥æ–¹æ³•è¿˜å¯æ¨å¹¿åˆ°å…¶ä»–åŒ»å­¦å½±åƒé¢†åŸŸã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Foundation models are increasingly developed in computational pathology (CPath) given their promise in facilitating many downstream tasks. While recent studies have evaluated task performance across models, less is known about the structure and variability of their learned representations. Here, we systematically analyze the representational spaces of six CPath foundation models using techniques popularized in computational neuroscience. The models analyzed span vision-language contrastive learning (CONCH, PLIP, KEEP) and self-distillation (UNI (v2), Virchow (v2), Prov-GigaPath) approaches. Through representational similarity analysis using H&E image patches from TCGA, we find that UNI2 and Virchow2 have the most distinct representational structures, whereas Prov-Gigapath has the highest average similarity across models. Having the same training paradigm (vision-only vs. vision-language) did not guarantee higher representational similarity. The representations of all models showed a high slide-dependence, but relatively low disease-dependence. Stain normalization decreased slide-dependence for all models by a range of 5.5% (CONCH) to 20.5% (PLIP). In terms of intrinsic dimensionality, vision-language models demonstrated relatively compact representations, compared to the more distributed representations of vision-only models. These findings highlight opportunities to improve robustness to slide-specific features, inform model ensembling strategies, and provide insights into how training paradigms shape model representations. Our framework is extendable across medical imaging domains, where probing the internal representations of foundation models can support their effective development and deployment.

