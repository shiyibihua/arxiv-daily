---
layout: default
title: Efficient Multimodal Dataset Distillation via Generative Models
---

# Efficient Multimodal Dataset Distillation via Generative Models

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15472" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15472v2</a>
  <a href="https://arxiv.org/pdf/2509.15472.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15472v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15472v2', 'Efficient Multimodal Dataset Distillation via Generative Models')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Zhenghao Zhao, Haoxuan Wang, Junyi Wu, Yuzhang Shang, Gaowen Liu, Yan Yan

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-09-25)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºEDGEæ–¹æ³•ä»¥è§£å†³å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦æ•ˆç‡é—®é¢˜**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `å¤šæ¨¡æ€æ•°æ®é›†` `æ•°æ®é›†è’¸é¦` `ç”Ÿæˆæ¨¡å‹` `å¯¹æ¯”æŸå¤±` `æ ·æœ¬å¤šæ ·æ€§` `å›¾åƒ-æ–‡æœ¬æ£€ç´¢` `é«˜æ•ˆç®—æ³•`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰çš„å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦æ–¹æ³•å—åˆ°Matching Training Trajectoriesç®—æ³•çš„é™åˆ¶ï¼Œå¯¼è‡´è®¡ç®—èµ„æºéœ€æ±‚é«˜ä¸”å¤„ç†æ—¶é—´é•¿ã€‚
2. æœ¬æ–‡æå‡ºEDGEæ–¹æ³•ï¼Œé€šè¿‡åŒå‘å¯¹æ¯”æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±çš„ç»“åˆï¼Œè§£å†³ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬æè¿°ä¹‹é—´çš„ç›¸å…³æ€§å’Œæ ·æœ¬å¤šæ ·æ€§é—®é¢˜ã€‚
3. åœ¨Flickr30Kã€COCOå’ŒCC3Mæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒEDGEæ–¹æ³•åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œé€Ÿåº¦æå‡æ˜¾è‘—ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æ•°æ®é›†è’¸é¦æ—¨åœ¨ä»å¤§è§„æ¨¡æ•°æ®é›†ä¸­åˆæˆå°å‹æ•°æ®é›†ï¼Œä½¿å¾—åœ¨å…¶ä¸Šè®­ç»ƒçš„æ¨¡å‹èƒ½å¤Ÿåœ¨åŸå§‹æ•°æ®é›†ä¸Šè¡¨ç°è‰¯å¥½ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹å’Œå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹çš„å…´èµ·ï¼Œå¤šæ¨¡æ€æ•°æ®é›†ï¼Œå°¤å…¶æ˜¯å›¾åƒ-æ–‡æœ¬æ•°æ®é›†çš„é‡è¦æ€§æ˜¾è‘—å¢åŠ ã€‚ç„¶è€Œï¼Œç°æœ‰çš„å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦æ–¹æ³•å—åˆ°Matching Training Trajectoriesç®—æ³•çš„é™åˆ¶ï¼Œæ˜¾è‘—å¢åŠ äº†è®¡ç®—èµ„æºéœ€æ±‚ï¼Œè’¸é¦è¿‡ç¨‹å¯èƒ½éœ€è¦æ•°å¤©æ—¶é—´ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºEDGEçš„ç”Ÿæˆè’¸é¦æ–¹æ³•ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºä½¿ç”¨ç”Ÿæˆæ¨¡å‹è’¸é¦å¤šæ¨¡æ€æ•°æ®é›†çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜ï¼šç”Ÿæˆå›¾åƒä¸æ–‡æœ¬æè¿°ä¹‹é—´ç¼ºä¹ç›¸å…³æ€§ï¼Œä»¥åŠç”Ÿæˆæ ·æœ¬ä¹‹é—´ç¼ºä¹å¤šæ ·æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç”Ÿæˆæ¨¡å‹è®­ç»ƒå·¥ä½œæµç¨‹ï¼Œç»“åˆäº†åŒå‘å¯¹æ¯”æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†ä¸€ç§æ–‡æœ¬åˆæˆç­–ç•¥ï¼Œä»¥è¿›ä¸€æ­¥æé«˜æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢çš„æ€§èƒ½ã€‚æˆ‘ä»¬çš„å®éªŒåœ¨Flickr30Kã€COCOå’ŒCC3Mæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨æ€§èƒ½å’Œæ•ˆç‡ä¸Šä¼˜äºç°æœ‰æ–¹æ³•ï¼Œé€Ÿåº¦æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å¿«18å€ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šæœ¬æ–‡æ—¨åœ¨è§£å†³å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦ä¸­çš„æ•ˆç‡é—®é¢˜ï¼Œç°æœ‰æ–¹æ³•åœ¨è®¡ç®—èµ„æºå’Œæ—¶é—´ä¸Šå­˜åœ¨æ˜¾è‘—ç“¶é¢ˆï¼Œå°¤å…¶æ˜¯Matching Training Trajectoriesç®—æ³•çš„ä½¿ç”¨ä½¿å¾—è’¸é¦è¿‡ç¨‹æä¸ºç¼“æ…¢ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šEDGEæ–¹æ³•é€šè¿‡å¼•å…¥åŒå‘å¯¹æ¯”æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±ï¼Œæ—¨åœ¨æé«˜ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬ä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå¹¶å¢åŠ ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§ï¼Œä»è€Œæå‡è’¸é¦æ•ˆç‡å’Œæ•ˆæœã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¶æ„åŒ…æ‹¬ç”Ÿæˆæ¨¡å‹çš„è®­ç»ƒæµç¨‹ï¼Œé¦–å…ˆé€šè¿‡åŒå‘å¯¹æ¯”æŸå¤±ä¼˜åŒ–ç”Ÿæˆå›¾åƒä¸æ–‡æœ¬çš„åŒ¹é…åº¦ï¼Œç„¶åé€šè¿‡å¤šæ ·æ€§æŸå¤±ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§ï¼Œæœ€åç»“åˆæ–‡æœ¬åˆæˆç­–ç•¥æå‡æ–‡æœ¬åˆ°å›¾åƒçš„æ£€ç´¢æ€§èƒ½ã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°åœ¨äºæå‡ºäº†åŒå‘å¯¹æ¯”æŸå¤±å’Œå¤šæ ·æ€§æŸå¤±çš„ç»“åˆä½¿ç”¨ï¼Œè¿™åœ¨ç°æœ‰æ–¹æ³•ä¸­å°šæœªè§åˆ°ï¼Œæ˜¾è‘—æå‡äº†ç”Ÿæˆæ ·æœ¬çš„è´¨é‡å’Œå¤šæ ·æ€§ã€‚

**å…³é”®è®¾è®¡**ï¼šåœ¨æŸå¤±å‡½æ•°è®¾è®¡ä¸Šï¼ŒåŒå‘å¯¹æ¯”æŸå¤±ç”¨äºå¢å¼ºå›¾åƒä¸æ–‡æœ¬çš„ç›¸å…³æ€§ï¼Œè€Œå¤šæ ·æ€§æŸå¤±åˆ™ç¡®ä¿ç”Ÿæˆæ ·æœ¬çš„å¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œæ–‡æœ¬åˆæˆç­–ç•¥çš„å¼•å…¥è¿›ä¸€æ­¥å¢å¼ºäº†æ–‡æœ¬ä¿¡æ¯çš„åˆ©ç”¨ï¼Œæå‡äº†æ£€ç´¢æ€§èƒ½ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒEDGEæ–¹æ³•åœ¨Flickr30Kã€COCOå’ŒCC3Mæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œé€Ÿåº¦æ¯”æœ€å…ˆè¿›çš„æ–¹æ³•å¿«18å€ï¼Œä¸”åœ¨æ€§èƒ½ä¸Šä¹Ÿæœ‰æ˜¾è‘—æå‡ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤šæ¨¡æ€æ•°æ®é›†è’¸é¦ä¸­çš„æœ‰æ•ˆæ€§å’Œé«˜æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶çš„æ½œåœ¨åº”ç”¨é¢†åŸŸåŒ…æ‹¬å›¾åƒ-æ–‡æœ¬æ£€ç´¢ã€è‡ªåŠ¨æ ‡æ³¨å’Œå¤šæ¨¡æ€å­¦ä¹ ç­‰ã€‚é€šè¿‡æé«˜å¤šæ¨¡æ€æ•°æ®é›†çš„è’¸é¦æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨èµ„æºå—é™çš„ç¯å¢ƒä¸­å¿«é€Ÿç”Ÿæˆé«˜è´¨é‡çš„æ•°æ®é›†ï¼Œæ¨åŠ¨ç›¸å…³é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨å‘å±•ï¼Œå…·æœ‰é‡è¦çš„å®é™…ä»·å€¼å’Œæœªæ¥å½±å“ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Dataset distillation aims to synthesize a small dataset from a large dataset, enabling the model trained on it to perform well on the original dataset. With the blooming of large language models and multimodal large language models, the importance of multimodal datasets, particularly image-text datasets, has grown significantly. However, existing multimodal dataset distillation methods are constrained by the Matching Training Trajectories algorithm, which significantly increases the computing resource requirement, and takes days to process the distillation. In this work, we introduce EDGE, a generative distillation method for efficient multimodal dataset distillation. Specifically, we identify two key challenges of distilling multimodal datasets with generative models: 1) The lack of correlation between generated images and captions. 2) The lack of diversity among generated samples. To address the aforementioned issues, we propose a novel generative model training workflow with a bi-directional contrastive loss and a diversity loss. Furthermore, we propose a caption synthesis strategy to further improve text-to-image retrieval performance by introducing more text information. Our method is evaluated on Flickr30K, COCO, and CC3M datasets, demonstrating superior performance and efficiency compared to existing approaches. Notably, our method achieves results 18x faster than the state-of-the-art method.

