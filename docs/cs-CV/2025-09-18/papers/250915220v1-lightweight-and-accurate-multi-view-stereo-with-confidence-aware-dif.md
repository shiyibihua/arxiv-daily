---
layout: default
title: Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model
---

# Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15220" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.15220v1</a>
  <a href="https://arxiv.org/pdf/2509.15220.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15220v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15220v1', 'Lightweight and Accurate Multi-View Stereo with Confidence-Aware Diffusion Model')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Fangjinhua Wang, Qingshan Xu, Yew-Soon Ong, Marc Pollefeys

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-18

**Â§áÊ≥®**: Accepted to IEEE T-PAMI 2025. Code: https://github.com/cvg/diffmvs

**DOI**: [10.1109/TPAMI.2025.3597148](https://doi.org/10.1109/TPAMI.2025.3597148)

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/cvg/diffmvs)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫Âü∫‰∫éÁΩÆ‰ø°Â∫¶ÊÑüÁü•Êâ©Êï£Ê®°ÂûãÁöÑÈ´òÊïàËΩªÈáèÂ§öËßÜÂõæÁ´ã‰ΩìÊñπÊ≥ï**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü•‰∏éËØ≠‰πâ (Perception & Semantics)**

**ÂÖ≥ÈîÆËØç**: `Â§öËßÜÂõæÁ´ã‰Ωì` `‰∏âÁª¥ÈáçÂª∫` `Êâ©Êï£Ê®°Âûã` `Ê∑±Â∫¶‰º∞ËÆ°` `Êù°‰ª∂ÁîüÊàê`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÂü∫‰∫éÂ≠¶‰π†ÁöÑMVSÊñπÊ≥ïËÆ°ÁÆóÊïàÁéáËæÉ‰ΩéÔºåÈöæ‰ª•Âú®ËµÑÊ∫êÂèóÈôêÁöÑÂú∫ÊôØ‰∏≠Â∫îÁî®„ÄÇ
2. ËÆ∫ÊñáÊèêÂá∫Â∞ÜÊâ©Êï£Ê®°ÂûãÂºïÂÖ•MVSÔºåÈÄöËøáÊù°‰ª∂Êâ©Êï£ËøáÁ®ãËøõË°åÊ∑±Â∫¶ÂõæÁªÜÂåñÔºåÂπ∂ËÆæËÆ°ÁΩÆ‰ø°Â∫¶ÂºïÂØºÁöÑÈááÊ†∑Á≠ñÁï•„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåÊèêÂá∫ÁöÑDiffMVSÂú®ÊïàÁéá‰∏äÂÖ∑ÊúâÁ´û‰∫âÂäõÔºåCasDiffMVSÂú®Â§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫ÜSOTAÊÄßËÉΩ„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÊñ∞È¢ñÁöÑÂ§öËßÜÂõæÁ´ã‰ΩìÔºàMVSÔºâÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂Â∞ÜÊâ©Êï£Ê®°ÂûãÂºïÂÖ•MVS‰∏≠ÔºåÁî®‰∫é‰ªéÊ†°ÂáÜÂõæÂÉèÈáçÂª∫3DÂá†‰Ωï‰Ωì„ÄÇËØ•ÊñπÊ≥ïÂ∞ÜÊ∑±Â∫¶ÁªÜÂåñÂª∫Ê®°‰∏∫Êù°‰ª∂Êâ©Êï£ËøáÁ®ãÔºåÂπ∂ËÆæËÆ°‰∫Ü‰∏Ä‰∏™Êù°‰ª∂ÁºñÁ†ÅÂô®Êù•ÊåáÂØºÊâ©Êï£ËøáÁ®ãÔºå‰ªéËÄåÂà©Áî®Ê∑±Â∫¶‰º∞ËÆ°ÁöÑÂà§Âà´ÁâπÊÄß„ÄÇ‰∏∫‰∫ÜÊèêÈ´òÊïàÁéáÔºåËÆæËÆ°‰∫Ü‰∏ÄÁßçÁªìÂêàËΩªÈáèÁ∫ß2D U-NetÂíåÂç∑ÁßØGRUÁöÑÊñ∞ÂûãÊâ©Êï£ÁΩëÁªú„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫‰∫Ü‰∏ÄÁßçÂü∫‰∫éÁΩÆ‰ø°Â∫¶ÁöÑÊñ∞ÂûãÈááÊ†∑Á≠ñÁï•Ôºå‰ª•Âü∫‰∫éÊâ©Êï£Ê®°Âûã‰º∞ËÆ°ÁöÑÁΩÆ‰ø°Â∫¶Ëá™ÈÄÇÂ∫îÂú∞ÈááÊ†∑Ê∑±Â∫¶ÂÅáËÆæ„ÄÇÂü∫‰∫éÊ≠§Ê°ÜÊû∂ÔºåÊèêÂá∫‰∫Ü‰∏§ÁßçÊñ∞ÁöÑMVSÊñπÊ≥ïÔºöDiffMVSÂíåCasDiffMVS„ÄÇDiffMVSÂú®ËøêË°åÊó∂Èó¥ÂíåGPUÂÜÖÂ≠òÊñπÈù¢ÂÆûÁé∞‰∫Ü‰∏éÊúÄÂÖàËøõÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩ„ÄÇCasDiffMVSÂú®DTU„ÄÅTanks & TemplesÂíåETH3D‰∏äÂÆûÁé∞‰∫ÜÊúÄÂÖàËøõÁöÑÊÄßËÉΩ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÂ§öËßÜÂõæÁ´ã‰ΩìÔºàMVSÔºâÊó®Âú®‰ªéÂ§öÂº†Ê†°ÂáÜÂõæÂÉè‰∏≠ÈáçÂª∫‰∏âÁª¥Âá†‰ΩïÁªìÊûÑ„ÄÇÁé∞ÊúâÁöÑÂü∫‰∫éÂ≠¶‰π†ÁöÑMVSÊñπÊ≥ïÈÄöÂ∏∏ÂÖàËøõË°åÂ§öËßÜÂõæÊ∑±Â∫¶‰º∞ËÆ°ÔºåÁÑ∂ÂêéÂ∞ÜÊ∑±Â∫¶ÂõæËûçÂêà‰∏∫ÁΩëÊ†ºÊàñÁÇπ‰∫ë„ÄÇ‰∏∫‰∫ÜÊèêÈ´òËÆ°ÁÆóÊïàÁéáÔºåËÆ∏Â§öÊñπÊ≥ïÈ¶ñÂÖàÂàùÂßãÂåñ‰∏Ä‰∏™Á≤óÁ≥ôÁöÑÊ∑±Â∫¶ÂõæÔºåÁÑ∂ÂêéÂú®Êõ¥È´òÁöÑÂàÜËæ®Áéá‰∏ãÈÄêÊ≠•ÁªÜÂåñÂÆÉ„ÄÇÁÑ∂ËÄåÔºåËøô‰∫õÊñπÊ≥ïÂú®ËÆ°ÁÆóÊïàÁéáÂíåÁ≤æÂ∫¶‰πãÈó¥ÂæÄÂæÄÈúÄË¶ÅÊùÉË°°ÔºåÈöæ‰ª•ÂêåÊó∂Êª°Ë∂≥ËΩªÈáèÂåñÂíåÈ´òÁ≤æÂ∫¶ÁöÑÈúÄÊ±Ç„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöÊú¨ÊñáÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÂ∞ÜÊ∑±Â∫¶ÂõæÁöÑÁªÜÂåñËøáÁ®ãÂª∫Ê®°‰∏∫‰∏Ä‰∏™Êù°‰ª∂Êâ©Êï£ËøáÁ®ã„ÄÇÊâ©Êï£Ê®°ÂûãÂú®ÁîüÊàê‰ªªÂä°‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÂÆÉ‰ªéÈöèÊú∫Âô™Â£∞ÂºÄÂßãÔºåÈÄöËøáËø≠‰ª£ÂéªÂô™ËøáÁ®ãÈÄêÊ≠•ÊÅ¢Â§çÊ†∑Êú¨„ÄÇÈÄöËøáÂ∞ÜÊ∑±Â∫¶ÂõæÁªÜÂåñËßÜ‰∏∫‰∏Ä‰∏™Êù°‰ª∂ÁîüÊàêÈóÆÈ¢òÔºåÂèØ‰ª•Âà©Áî®Êâ©Êï£Ê®°ÂûãÁöÑÂº∫Â§ßÁîüÊàêËÉΩÂäõÊù•ÊèêÂçáÊ∑±Â∫¶ÂõæÁöÑË¥®Èáè„ÄÇÂêåÊó∂Ôºå‰∏∫‰∫ÜÊèêÈ´òÊïàÁéáÔºåËÆæËÆ°ËΩªÈáèÁ∫ßÁöÑÁΩëÁªúÁªìÊûÑÂíåÈááÊ†∑Á≠ñÁï•„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöËØ•MVSÊ°ÜÊû∂‰∏ªË¶ÅÂåÖÂê´‰ª•‰∏ãÂá†‰∏™Ê®°ÂùóÔºö1) Êù°‰ª∂ÁºñÁ†ÅÂô®ÔºöÁî®‰∫éÊèêÂèñËæìÂÖ•ÂõæÂÉèÁöÑÁâπÂæÅÔºåÂπ∂Â∞ÜÂÖ∂‰Ωú‰∏∫Êù°‰ª∂‰ø°ÊÅØËæìÂÖ•Âà∞Êâ©Êï£Ê®°Âûã‰∏≠„ÄÇ2) Êâ©Êï£Ê®°ÂûãÔºöÈááÁî®ËΩªÈáèÁ∫ßÁöÑ2D U-NetÂíåÂç∑ÁßØGRUÁõ∏ÁªìÂêàÁöÑÁΩëÁªúÁªìÊûÑÔºåÁî®‰∫éÈÄêÊ≠•ÁªÜÂåñÊ∑±Â∫¶Âõæ„ÄÇ3) ÁΩÆ‰ø°Â∫¶‰º∞ËÆ°Ê®°ÂùóÔºöÂü∫‰∫éÊâ©Êï£Ê®°ÂûãÁöÑËæìÂá∫Ôºå‰º∞ËÆ°ÊØè‰∏™Ê∑±Â∫¶ÂÅáËÆæÁöÑÁΩÆ‰ø°Â∫¶„ÄÇ4) ÈááÊ†∑Á≠ñÁï•ÔºöÊ†πÊçÆÁΩÆ‰ø°Â∫¶Ëá™ÈÄÇÂ∫îÂú∞ÈááÊ†∑Ê∑±Â∫¶ÂÅáËÆæÔºå‰ª•ÊèêÈ´òÊïàÁéá„ÄÇÊï¥‰ΩìÊµÅÁ®ãÊòØ‰ªéÁ≤óÁ≥ôÁöÑÊ∑±Â∫¶ÂõæÂºÄÂßãÔºåÈÄöËøáÊù°‰ª∂ÁºñÁ†ÅÂô®ÊèêÂèñÂõæÂÉèÁâπÂæÅÔºåÁÑ∂ÂêéÂà©Áî®Êâ©Êï£Ê®°ÂûãÈÄêÊ≠•ÁªÜÂåñÊ∑±Â∫¶ÂõæÔºåÂπ∂‰ΩøÁî®ÁΩÆ‰ø°Â∫¶ÂºïÂØºÁöÑÈááÊ†∑Á≠ñÁï•Êù•ÊèêÈ´òÊïàÁéá„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöËØ•ËÆ∫ÊñáÁöÑÂÖ≥ÈîÆÂàõÊñ∞ÁÇπÂú®‰∫éÂ∞ÜÊâ©Êï£Ê®°ÂûãÂºïÂÖ•Âà∞MVS‰∏≠ÔºåÂπ∂Â∞ÜÂÖ∂Áî®‰∫éÊ∑±Â∫¶ÂõæÁöÑÁªÜÂåñ„ÄÇ‰∏é‰º†ÁªüÁöÑÊ∑±Â∫¶ÂõæÁªÜÂåñÊñπÊ≥ïÁõ∏ÊØîÔºåÊâ©Êï£Ê®°ÂûãÂÖ∑ÊúâÊõ¥Âº∫ÁöÑÁîüÊàêËÉΩÂäõÔºåÂèØ‰ª•ÁîüÊàêÊõ¥Á≤æÁªÜ„ÄÅÊõ¥ÂáÜÁ°ÆÁöÑÊ∑±Â∫¶Âõæ„ÄÇÊ≠§Â§ñÔºåÊèêÂá∫ÁöÑÁΩÆ‰ø°Â∫¶ÂºïÂØºÁöÑÈááÊ†∑Á≠ñÁï•ÂèØ‰ª•ÊúâÊïàÂú∞ÊèêÈ´òËÆ°ÁÆóÊïàÁéáÔºåÂπ∂ÂáèÂ∞ëÂÜÖÂ≠òÂç†Áî®„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöÂú®ÁΩëÁªúÁªìÊûÑÊñπÈù¢ÔºåÈááÁî®‰∫ÜËΩªÈáèÁ∫ßÁöÑ2D U-NetÂíåÂç∑ÁßØGRUÁõ∏ÁªìÂêàÁöÑÊñπÂºèÔºå‰ª•ÂáèÂ∞ëËÆ°ÁÆóÈáèÂíåÂÜÖÂ≠òÂç†Áî®„ÄÇÂú®ÊçüÂ§±ÂáΩÊï∞ÊñπÈù¢Ôºå‰ΩøÁî®‰∫ÜL1ÊçüÂ§±ÂíåÊÑüÁü•ÊçüÂ§±Áõ∏ÁªìÂêàÁöÑÊñπÂºèÔºå‰ª•ÊèêÈ´òÊ∑±Â∫¶ÂõæÁöÑË¥®Èáè„ÄÇÂú®ÈááÊ†∑Á≠ñÁï•ÊñπÈù¢ÔºåÊ†πÊçÆÁΩÆ‰ø°Â∫¶Ëá™ÈÄÇÂ∫îÂú∞ÈááÊ†∑Ê∑±Â∫¶ÂÅáËÆæÔºå‰ª•Âπ≥Ë°°Á≤æÂ∫¶ÂíåÊïàÁéá„ÄÇÂÖ∑‰ΩìÁöÑÂèÇÊï∞ËÆæÁΩÆÂíåÁΩëÁªúÁªìÊûÑÁªÜËäÇÂèØ‰ª•Âú®ËÆ∫ÊñáÁöÑÂÆûÈ™åÈÉ®ÂàÜÊâæÂà∞„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

DiffMVSÂú®ËøêË°åÊó∂Èó¥ÂíåGPUÂÜÖÂ≠òÊñπÈù¢ÂÆûÁé∞‰∫Ü‰∏éÊúÄÂÖàËøõÊñπÊ≥ïÁõ∏ÂΩìÁöÑÊÄßËÉΩÔºåË°®Êòé‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊïàÁéá‰ºòÂäø„ÄÇCasDiffMVSÂú®DTU„ÄÅTanks & TemplesÂíåETH3DÁ≠âÂ§ö‰∏™Êï∞ÊçÆÈõÜ‰∏äÂèñÂæó‰∫Üstate-of-the-artÁöÑÊÄßËÉΩÔºåÈ™åËØÅ‰∫ÜËØ•ÊñπÊ≥ïÁöÑÊúâÊïàÊÄßÂíåÊ≥õÂåñËÉΩÂäõ„ÄÇ‰ª£Á†ÅÂ∑≤ÂºÄÊ∫êÔºåÊñπ‰æøÁ†îÁ©∂‰∫∫ÂëòÂ§çÁé∞ÂíåËøõ‰∏ÄÊ≠•Á†îÁ©∂„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

ËØ•Á†îÁ©∂ÊàêÊûúÂèØÂ∫îÁî®‰∫é‰∏âÁª¥ÈáçÂª∫„ÄÅËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËôöÊãüÁé∞ÂÆûÁ≠âÈ¢ÜÂüü„ÄÇËΩªÈáèÂåñÁöÑËÆæËÆ°‰ΩøÂæóËØ•ÊñπÊ≥ïËÉΩÂ§üÂú®ÁßªÂä®ËÆæÂ§áÊàñÂµåÂÖ•ÂºèÁ≥ªÁªü‰∏äÈÉ®ÁΩ≤Ôºå‰ªéËÄåÂÆûÁé∞ÂÆûÊó∂ÁöÑ‰∏âÁª¥ÈáçÂª∫ÂíåÂú∫ÊôØÁêÜËß£„ÄÇÈ´òÁ≤æÂ∫¶ÁöÑÈáçÂª∫ÁªìÊûúÂèØ‰ª•‰∏∫Ëá™Âä®È©æÈ©∂Á≥ªÁªüÊèê‰æõÊõ¥ÂáÜÁ°ÆÁöÑÁéØÂ¢É‰ø°ÊÅØÔºåÊèêÈ´òÂÖ∂ÂÆâÂÖ®ÊÄßÂíåÂèØÈù†ÊÄß„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> To reconstruct the 3D geometry from calibrated images, learning-based multi-view stereo (MVS) methods typically perform multi-view depth estimation and then fuse depth maps into a mesh or point cloud. To improve the computational efficiency, many methods initialize a coarse depth map and then gradually refine it in higher resolutions. Recently, diffusion models achieve great success in generation tasks. Starting from a random noise, diffusion models gradually recover the sample with an iterative denoising process. In this paper, we propose a novel MVS framework, which introduces diffusion models in MVS. Specifically, we formulate depth refinement as a conditional diffusion process. Considering the discriminative characteristic of depth estimation, we design a condition encoder to guide the diffusion process. To improve efficiency, we propose a novel diffusion network combining lightweight 2D U-Net and convolutional GRU. Moreover, we propose a novel confidence-based sampling strategy to adaptively sample depth hypotheses based on the confidence estimated by diffusion model. Based on our novel MVS framework, we propose two novel MVS methods, DiffMVS and CasDiffMVS. DiffMVS achieves competitive performance with state-of-the-art efficiency in run-time and GPU memory. CasDiffMVS achieves state-of-the-art performance on DTU, Tanks & Temples and ETH3D. Code is available at: https://github.com/cvg/diffmvs.

