---
layout: default
title: SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters
---

# SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15490" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15490v1</a>
  <a href="https://arxiv.org/pdf/2509.15490.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15490v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15490v1', 'SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Abdarahmane Traore, Ã‰ric Hervet, Andy Couturier

**åˆ†ç±»**: cs.CV, cs.AI

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18

**å¤‡æ³¨**: 9 pages, 3 figures, IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)

**ğŸ”— ä»£ç /é¡¹ç›®**: [GITHUB](https://github.com/abtraore/SmolRGPT)

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**SmolRGPTï¼šç”¨äºä»“åº“ç¯å¢ƒçš„é«˜æ•ˆç©ºé—´æ¨ç†600Må‚æ•°è§†è§‰è¯­è¨€æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸ƒï¼šåŠ¨ä½œé‡å®šå‘ (Motion Retargeting)** **æ”¯æŸ±ä¹ï¼šå…·èº«å¤§æ¨¡å‹ (Embodied Foundation Models)**

**å…³é”®è¯**: `è§†è§‰è¯­è¨€æ¨¡å‹` `ç©ºé—´æ¨ç†` `ä»“åº“ç¯å¢ƒ` `æ·±åº¦ä¿¡æ¯` `å¤šæ¨¡æ€èåˆ`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹ä½“ç§¯åºå¤§ï¼Œè®¡ç®—å’Œå†…å­˜éœ€æ±‚é«˜ï¼Œéš¾ä»¥åœ¨èµ„æºå—é™çš„ä»“åº“ã€æœºå™¨äººç­‰åœºæ™¯éƒ¨ç½²ã€‚
2. SmolRGPTé€šè¿‡æ•´åˆRGBå’Œæ·±åº¦ä¿¡æ¯ï¼Œæ˜¾å¼åœ°è¿›è¡ŒåŒºåŸŸçº§çš„ç©ºé—´æ¨ç†ï¼Œæ„å»ºç´§å‡‘é«˜æ•ˆçš„è§†è§‰è¯­è¨€æ¨¡å‹ã€‚
3. SmolRGPTä»…ç”¨600Må‚æ•°ï¼Œåœ¨ä»“åº“ç©ºé—´æ¨ç†ä»»åŠ¡ä¸Šè¾¾åˆ°æˆ–è¶…è¿‡äº†æ›´å¤§æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

è§†è§‰-è¯­è¨€æ¨¡å‹(VLM)çš„æœ€æ–°è¿›å±•å®ç°äº†å¼ºå¤§çš„å¤šæ¨¡æ€æ¨ç†ï¼Œä½†å½“å‰æœ€ä¼˜æ–¹æ³•é€šå¸¸ä¾èµ–äºè®¡ç®—å’Œå†…å­˜éœ€æ±‚æé«˜çš„è¶…å¤§å‹æ¨¡å‹ã€‚è¿™ä½¿å¾—å®ƒä»¬åœ¨èµ„æºå—é™çš„ç¯å¢ƒï¼ˆå¦‚ä»“åº“ã€æœºå™¨äººå’Œå·¥ä¸šåº”ç”¨ï¼‰ä¸­çš„éƒ¨ç½²å……æ»¡æŒ‘æˆ˜ï¼Œè€Œåœ¨è¿™äº›ç¯å¢ƒä¸­ï¼Œæ•ˆç‡å’Œå¼ºå¤§çš„ç©ºé—´ç†è§£è‡³å…³é‡è¦ã€‚æœ¬æ–‡æå‡ºäº†SmolRGPTï¼Œä¸€ç§ç´§å‡‘çš„è§†è§‰-è¯­è¨€æ¶æ„ï¼Œé€šè¿‡æ•´åˆRGBå’Œæ·±åº¦çº¿ç´¢ï¼Œæ˜¾å¼åœ°ç»“åˆäº†åŒºåŸŸçº§çš„ç©ºé—´æ¨ç†ã€‚SmolRGPTé‡‡ç”¨ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼Œé€æ­¥å¯¹é½è§†è§‰å’Œè¯­è¨€ç‰¹å¾ï¼Œå®ç°ç©ºé—´å…³ç³»ç†è§£ï¼Œå¹¶é€‚åº”ç‰¹å®šä»»åŠ¡çš„æ•°æ®é›†ã€‚å®éªŒè¡¨æ˜ï¼ŒSmolRGPTä»…ç”¨600Må‚æ•°ï¼Œåœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»“åº“ç©ºé—´æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œè¾¾åˆ°ç”šè‡³è¶…è¿‡äº†æ›´å¤§æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™äº›å‘ç°çªå‡ºäº†åœ¨ä¸ç‰ºç‰²æ ¸å¿ƒç©ºé—´æ¨ç†èƒ½åŠ›çš„æƒ…å†µä¸‹ï¼Œåœ¨ç°å®ç¯å¢ƒä¸­å®ç°é«˜æ•ˆã€å¯éƒ¨ç½²çš„å¤šæ¨¡æ€æ™ºèƒ½çš„æ½œåŠ›ã€‚å®éªŒä»£ç å°†åœ¨https://github.com/abtraore/SmolRGPTä¸Šæä¾›ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åœ¨èµ„æºå—é™çš„ä»“åº“ç¯å¢ƒä¸­ï¼Œç°æœ‰å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹å› è®¡ç®—å’Œå†…å­˜éœ€æ±‚è¿‡é«˜è€Œéš¾ä»¥éƒ¨ç½²çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•æ— æ³•åœ¨æ•ˆç‡å’Œç©ºé—´æ¨ç†èƒ½åŠ›ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œé™åˆ¶äº†å…¶åœ¨å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯è®¾è®¡ä¸€ä¸ªç´§å‡‘çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼Œé€šè¿‡æ˜¾å¼åœ°æ•´åˆRGBå’Œæ·±åº¦ä¿¡æ¯ï¼Œå®ç°åŒºåŸŸçº§çš„ç©ºé—´æ¨ç†ã€‚è¿™ç§è®¾è®¡æ—¨åœ¨å‡å°‘æ¨¡å‹å‚æ•°é‡ï¼Œæé«˜è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ä¿æŒå¼ºå¤§çš„ç©ºé—´ç†è§£èƒ½åŠ›ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šSmolRGPTé‡‡ç”¨ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ æ¡†æ¶ï¼š1)è§†è§‰å’Œè¯­è¨€ç‰¹å¾å¯¹é½ï¼›2)ç©ºé—´å…³ç³»ç†è§£ï¼›3)é€‚åº”ç‰¹å®šä»»åŠ¡æ•°æ®é›†ã€‚è¯¥æ¨¡å‹æ•´åˆRGBå’Œæ·±åº¦ä¿¡æ¯ï¼Œæå–åŒºåŸŸç‰¹å¾ï¼Œå¹¶åˆ©ç”¨Transformeræ¶æ„è¿›è¡Œå¤šæ¨¡æ€èåˆå’Œæ¨ç†ã€‚

**å…³é”®åˆ›æ–°**ï¼šSmolRGPTçš„å…³é”®åˆ›æ–°åœ¨äºå…¶ç´§å‡‘çš„æ¶æ„è®¾è®¡å’Œæ˜¾å¼çš„ç©ºé—´æ¨ç†æœºåˆ¶ã€‚ä¸ä¾èµ–å¤§è§„æ¨¡å‚æ•°çš„æ¨¡å‹ä¸åŒï¼ŒSmolRGPTé€šè¿‡æ•´åˆæ·±åº¦ä¿¡æ¯å’ŒåŒºåŸŸç‰¹å¾ï¼Œåœ¨è¾ƒå°çš„æ¨¡å‹è§„æ¨¡ä¸‹å®ç°äº†å¼ºå¤§çš„ç©ºé—´ç†è§£èƒ½åŠ›ã€‚

**å…³é”®è®¾è®¡**ï¼šSmolRGPTçš„å…³é”®è®¾è®¡åŒ…æ‹¬ï¼š1)ä½¿ç”¨RGBå’Œæ·±åº¦ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼›2)é‡‡ç”¨åŒºåŸŸç‰¹å¾æå–æ–¹æ³•ï¼›3)åˆ©ç”¨Transformeræ¶æ„è¿›è¡Œå¤šæ¨¡æ€èåˆï¼›4)è®¾è®¡ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œé€æ­¥æå‡æ¨¡å‹æ€§èƒ½ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ã€æŸå¤±å‡½æ•°å’Œç½‘ç»œç»“æ„ç­‰ç»†èŠ‚å°†åœ¨ä»£ç ä¸­å…¬å¼€ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

SmolRGPTä»…ä½¿ç”¨600Må‚æ•°ï¼Œåœ¨ä»“åº“ç©ºé—´æ¨ç†åŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†ä¸æ›´å¤§æ¨¡å‹ç›¸å½“ç”šè‡³æ›´å¥½çš„æ€§èƒ½ã€‚è¿™ä¸€ç»“æœè¡¨æ˜ï¼Œé€šè¿‡æœ‰æ•ˆçš„æ¶æ„è®¾è®¡å’Œè®­ç»ƒç­–ç•¥ï¼Œå¯ä»¥åœ¨ä¸ç‰ºç‰²æ€§èƒ½çš„å‰æä¸‹æ˜¾è‘—é™ä½æ¨¡å‹è§„æ¨¡ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

SmolRGPTåœ¨ä»“åº“ç®¡ç†ã€æœºå™¨äººå¯¼èˆªã€å·¥ä¸šè‡ªåŠ¨åŒ–ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºæ™ºèƒ½æ‹£é€‰ã€åº“å­˜ç®¡ç†ã€ç¯å¢ƒæ„ŸçŸ¥å’Œè‡ªä¸»å¯¼èˆªç­‰ä»»åŠ¡ï¼Œæé«˜å·¥ä½œæ•ˆç‡å’Œè‡ªåŠ¨åŒ–æ°´å¹³ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²é«˜æ•ˆæ™ºèƒ½ç³»ç»Ÿæä¾›äº†æ–°çš„æ€è·¯ï¼Œæœ‰æœ›æ¨åŠ¨ç›¸å…³é¢†åŸŸçš„å‘å±•ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Recent advances in vision-language models (VLMs) have enabled powerful multimodal reasoning, but state-of-the-art approaches typically rely on extremely large models with prohibitive computational and memory requirements. This makes their deployment challenging in resource-constrained environments such as warehouses, robotics, and industrial applications, where both efficiency and robust spatial understanding are critical. In this work, we present SmolRGPT, a compact vision-language architecture that explicitly incorporates region-level spatial reasoning by integrating both RGB and depth cues. SmolRGPT employs a three-stage curriculum that progressively align visual and language features, enables spatial relationship understanding, and adapts to task-specific datasets. We demonstrate that with only 600M parameters, SmolRGPT achieves competitive results on challenging warehouse spatial reasoning benchmarks, matching or exceeding the performance of much larger alternatives. These findings highlight the potential for efficient, deployable multimodal intelligence in real-world settings without sacrificing core spatial reasoning capabilities. The code of the experimentation will be available at: https://github.com/abtraore/SmolRGPT

