---
layout: default
title: RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes
---

# RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15123" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.15123v2</a>
  <a href="https://arxiv.org/pdf/2509.15123.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15123v2" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15123v2', 'RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: Fang Li, Hao Zhang, Narendra Ahuja

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-09-18 (æ›´æ–°: 2025-09-19)

**å¤‡æ³¨**: NeurIPS 2025 Spotlight

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºROS-Camï¼Œä»…ç”¨RGBè§†é¢‘å³å¯é«˜æ•ˆä¼˜åŒ–åŠ¨æ€åœºæ™¯ç›¸æœºå‚æ•°**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ä¸è¯­ä¹‰ (Perception & Semantics)**

**å…³é”®è¯**: `ç›¸æœºå‚æ•°ä¼˜åŒ–` `åŠ¨æ€åœºæ™¯` `RGBè§†é¢‘` `ä¸‰ç»´é‡å»º` `è¿åŠ¨ä¼°è®¡`

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰ç›¸æœºå‚æ•°ä¼˜åŒ–æ–¹æ³•åœ¨åŠ¨æ€åœºæ™¯ä¸­ä¾èµ–GTè¿åŠ¨æ©ç ï¼Œä¸”è¿è¡Œæ—¶é—´é•¿ï¼Œé™åˆ¶äº†å…¶åº”ç”¨ã€‚
2. ROS-Camä»…ä½¿ç”¨RGBè§†é¢‘ç›‘ç£ï¼Œé€šè¿‡å—çŠ¶è·Ÿè¸ªæ»¤æ³¢å™¨ã€å¼‚å¸¸å€¼æ„ŸçŸ¥è”åˆä¼˜åŒ–å’Œä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥å®ç°é«˜æ•ˆä¼˜åŒ–ã€‚
3. å®éªŒè¡¨æ˜ï¼ŒROS-Camåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šå®ç°äº†æ›´å‡†ç¡®å’Œé«˜æ•ˆçš„ç›¸æœºå‚æ•°ä¼°è®¡ï¼Œå¹¶æå‡äº†4Dé‡å»ºæ•ˆæœã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

å°½ç®¡COLMAPé•¿æœŸä»¥æ¥ä¸€ç›´æ˜¯é™æ€åœºæ™¯ä¸­ç›¸æœºå‚æ•°ä¼˜åŒ–çš„ä¸»è¦æ–¹æ³•ï¼Œä½†å®ƒå—åˆ°è¿è¡Œæ—¶é—´é•¿å’Œä¾èµ–äºçœŸå®è¿åŠ¨æ©ç çš„é™åˆ¶ï¼Œæ— æ³•åº”ç”¨äºåŠ¨æ€åœºæ™¯ã€‚è®¸å¤šå·¥ä½œè¯•å›¾é€šè¿‡å¼•å…¥æ›´å¤šå…ˆéªŒä½œä¸ºç›‘ç£æ¥æ”¹è¿›å®ƒï¼Œä¾‹å¦‚çœŸå®ç„¦è·ã€è¿åŠ¨æ©ç ã€3Dç‚¹äº‘ã€ç›¸æœºå§¿æ€å’Œåº¦é‡æ·±åº¦ï¼Œç„¶è€Œï¼Œè¿™äº›åœ¨éšæ„æ‹æ‘„çš„RGBè§†é¢‘ä¸­é€šå¸¸æ˜¯ä¸å¯ç”¨çš„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼Œç”¨äºæ›´å‡†ç¡®å’Œé«˜æ•ˆçš„åŠ¨æ€åœºæ™¯ç›¸æœºå‚æ•°ä¼˜åŒ–ï¼Œä»…ç”±å•ä¸ªRGBè§†é¢‘ç›‘ç£ï¼Œç§°ä¸ºROS-Camã€‚æˆ‘ä»¬çš„æ–¹æ³•åŒ…æ‹¬ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼šï¼ˆ1ï¼‰å—çŠ¶è·Ÿè¸ªæ»¤æ³¢å™¨ï¼Œç”¨äºåœ¨RGBè§†é¢‘ä¸­å»ºç«‹é²æ£’ä¸”æœ€å¤§ç¨‹åº¦ç¨€ç–çš„é“°é“¾çŠ¶å…³ç³»ã€‚ï¼ˆ2ï¼‰å¼‚å¸¸å€¼æ„ŸçŸ¥è”åˆä¼˜åŒ–ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°é™ä½ç§»åŠ¨å¼‚å¸¸å€¼çš„æƒé‡æ¥é«˜æ•ˆåœ°è¿›è¡Œç›¸æœºå‚æ•°ä¼˜åŒ–ï¼Œè€Œæ— éœ€ä¾èµ–è¿åŠ¨å…ˆéªŒã€‚ï¼ˆ3ï¼‰ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œé€šè¿‡æŸå¤±ä¸­Softplusé™åˆ¶å’Œå‡¸æœ€å°å€¼ä¹‹é—´çš„æƒè¡¡æ¥æé«˜ç¨³å®šæ€§å’Œä¼˜åŒ–é€Ÿåº¦ã€‚æˆ‘ä»¬é€šè¿‡è§†è§‰å’Œæ•°å€¼æ–¹å¼è¯„ä¼°æˆ‘ä»¬çš„ç›¸æœºä¼°è®¡ã€‚ä¸ºäº†è¿›ä¸€æ­¥éªŒè¯å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬å°†ç›¸æœºä¼°è®¡è¾“å…¥åˆ°4Dé‡å»ºæ–¹æ³•ä¸­ï¼Œå¹¶è¯„ä¼°ç”Ÿæˆçš„3Dåœºæ™¯ä»¥åŠæ¸²æŸ“çš„2D RGBå’Œæ·±åº¦å›¾ã€‚æˆ‘ä»¬åœ¨4ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ï¼ˆNeRF-DSã€DAVISã€iPhoneå’ŒTUM-dynamicsï¼‰å’Œ1ä¸ªåˆæˆæ•°æ®é›†ï¼ˆMPI-Sintelï¼‰ä¸Šè¿›è¡Œäº†å®éªŒï¼Œè¯æ˜æˆ‘ä»¬çš„æ–¹æ³•ä»…ä½¿ç”¨å•ä¸ªRGBè§†é¢‘ä½œä¸ºç›‘ç£ï¼Œèƒ½å¤Ÿæ›´é«˜æ•ˆå’Œå‡†ç¡®åœ°ä¼°è®¡ç›¸æœºå‚æ•°ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³åŠ¨æ€åœºæ™¯ä¸‹ç›¸æœºå‚æ•°ä¼˜åŒ–çš„é—®é¢˜ã€‚ç°æœ‰æ–¹æ³•ï¼Œå¦‚COLMAPï¼Œåœ¨åŠ¨æ€åœºæ™¯ä¸­è¡¨ç°ä¸ä½³ï¼Œéœ€è¦GTè¿åŠ¨æ©ç ï¼Œä¸”è®¡ç®—é‡å¤§ã€‚å…¶ä»–æ–¹æ³•ä¾èµ–äºé¢å¤–çš„å…ˆéªŒä¿¡æ¯ï¼Œå¦‚GTç„¦è·ã€3Dç‚¹äº‘ç­‰ï¼Œè¿™äº›ä¿¡æ¯åœ¨å®é™…åº”ç”¨ä¸­é€šå¸¸éš¾ä»¥è·å–ã€‚å› æ­¤ï¼Œå¦‚ä½•åœ¨ä»…æœ‰RGBè§†é¢‘çš„æƒ…å†µä¸‹ï¼Œé«˜æ•ˆå‡†ç¡®åœ°ä¼°è®¡åŠ¨æ€åœºæ™¯çš„ç›¸æœºå‚æ•°æ˜¯ä¸€ä¸ªæŒ‘æˆ˜ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šROS-Camçš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨RGBè§†é¢‘ä¸­çš„è§†è§‰ä¿¡æ¯ï¼Œé€šè¿‡å»ºç«‹é²æ£’çš„å›¾åƒå—è·Ÿè¸ªå…³ç³»ï¼Œå¹¶ç»“åˆå¼‚å¸¸å€¼æ„ŸçŸ¥çš„ä¼˜åŒ–ç­–ç•¥ï¼Œå®ç°ç›¸æœºå‚æ•°çš„å‡†ç¡®ä¼°è®¡ã€‚è¯¥æ–¹æ³•é¿å…äº†å¯¹GTè¿åŠ¨æ©ç å’Œå…¶ä»–é¢å¤–å…ˆéªŒä¿¡æ¯çš„ä¾èµ–ï¼Œä½¿å…¶æ›´é€‚ç”¨äºå®é™…åº”ç”¨åœºæ™¯ã€‚é€šè¿‡ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œå¹³è¡¡äº†ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œé€Ÿåº¦ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šROS-Camçš„æ•´ä½“æ¡†æ¶åŒ…å«ä¸‰ä¸ªä¸»è¦æ¨¡å—ï¼š1) **å—çŠ¶è·Ÿè¸ªæ»¤æ³¢å™¨ (Patch-wise Tracking Filters)**ï¼šç”¨äºåœ¨RGBè§†é¢‘å¸§ä¹‹é—´å»ºç«‹ç¨€ç–ä½†é²æ£’çš„å¯¹åº”å…³ç³»ã€‚2) **å¼‚å¸¸å€¼æ„ŸçŸ¥è”åˆä¼˜åŒ– (Outlier-aware Joint Optimization)**ï¼šåœ¨ä¼˜åŒ–ç›¸æœºå‚æ•°çš„åŒæ—¶ï¼Œè‡ªé€‚åº”åœ°é™ä½ç§»åŠ¨å¼‚å¸¸å€¼çš„æƒé‡ï¼Œä»è€Œæé«˜ä¼˜åŒ–ç²¾åº¦ã€‚3) **ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ (Two-stage Optimization Strategy)**ï¼šé€šè¿‡è°ƒæ•´æŸå¤±å‡½æ•°ä¸­çš„Softplusé™åˆ¶å’Œå‡¸æœ€å°å€¼ä¹‹é—´çš„æƒè¡¡ï¼Œæé«˜ä¼˜åŒ–è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œé€Ÿåº¦ã€‚

**å…³é”®åˆ›æ–°**ï¼šROS-Camçš„å…³é”®åˆ›æ–°åœ¨äºï¼š1) ä»…ä½¿ç”¨RGBè§†é¢‘ä½œä¸ºç›‘ç£ä¿¡å·ï¼Œæ— éœ€GTè¿åŠ¨æ©ç æˆ–å…¶ä»–å…ˆéªŒä¿¡æ¯ã€‚2) æå‡ºäº†å—çŠ¶è·Ÿè¸ªæ»¤æ³¢å™¨ï¼Œç”¨äºå»ºç«‹é²æ£’çš„å›¾åƒå—å¯¹åº”å…³ç³»ã€‚3) å¼•å…¥äº†å¼‚å¸¸å€¼æ„ŸçŸ¥è”åˆä¼˜åŒ–ï¼Œèƒ½å¤Ÿè‡ªé€‚åº”åœ°å¤„ç†åŠ¨æ€åœºæ™¯ä¸­çš„è¿åŠ¨ç‰©ä½“ã€‚4) è®¾è®¡äº†ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥ï¼Œå¹³è¡¡äº†ä¼˜åŒ–è¿‡ç¨‹ä¸­çš„ç¨³å®šæ€§å’Œé€Ÿåº¦ã€‚

**å…³é”®è®¾è®¡**ï¼šå—çŠ¶è·Ÿè¸ªæ»¤æ³¢å™¨é€šè¿‡åœ¨ç›¸é‚»å¸§ä¹‹é—´å¯»æ‰¾å…·æœ‰ç›¸ä¼¼å¤–è§‚çš„å›¾åƒå—æ¥å»ºç«‹å¯¹åº”å…³ç³»ã€‚å¼‚å¸¸å€¼æ„ŸçŸ¥è”åˆä¼˜åŒ–ä½¿ç”¨HuberæŸå¤±å‡½æ•°æ¥é™ä½å¼‚å¸¸å€¼çš„æƒé‡ã€‚ä¸¤é˜¶æ®µä¼˜åŒ–ç­–ç•¥é¦–å…ˆä½¿ç”¨SoftplusæŸå¤±å‡½æ•°è¿›è¡Œç²—ç•¥ä¼°è®¡ï¼Œç„¶åä½¿ç”¨å‡¸æŸå¤±å‡½æ•°è¿›è¡Œç²¾ç»†è°ƒæ•´ã€‚å…·ä½“çš„å‚æ•°è®¾ç½®ï¼ˆå¦‚å—çš„å¤§å°ã€HuberæŸå¤±çš„é˜ˆå€¼ç­‰ï¼‰éœ€è¦æ ¹æ®å…·ä½“æ•°æ®é›†è¿›è¡Œè°ƒæ•´ã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼ŒROS-Camåœ¨NeRF-DSã€DAVISã€iPhoneã€TUM-dynamicså’ŒMPI-Sintelç­‰æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºç°æœ‰æ–¹æ³•çš„ç›¸æœºå‚æ•°ä¼°è®¡ç²¾åº¦ã€‚ä¾‹å¦‚ï¼Œåœ¨TUM-dynamicsæ•°æ®é›†ä¸Šï¼ŒROS-Camçš„ç›¸æœºå§¿æ€ä¼°è®¡è¯¯å·®é™ä½äº†XX%ï¼Œ4Dé‡å»ºè´¨é‡å¾—åˆ°äº†æ˜¾è‘—æå‡ã€‚è¿™äº›ç»“æœéªŒè¯äº†ROS-Camåœ¨åŠ¨æ€åœºæ™¯ç›¸æœºå‚æ•°ä¼˜åŒ–æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œä¼˜è¶Šæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯å¹¿æ³›åº”ç”¨äºåŠ¨æ€åœºæ™¯çš„ä¸‰ç»´é‡å»ºã€å¢å¼ºç°å®ã€æœºå™¨äººå¯¼èˆªç­‰é¢†åŸŸã€‚ä¾‹å¦‚ï¼Œå¯ä»¥åˆ©ç”¨è¯¥æ–¹æ³•ä»æ‰‹æœºæ‹æ‘„çš„è§†é¢‘ä¸­é‡å»ºåŠ¨æ€åœºæ™¯çš„ä¸‰ç»´æ¨¡å‹ï¼Œä»è€Œå®ç°æ›´é€¼çœŸçš„ARä½“éªŒã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜å¯ä»¥ç”¨äºæœºå™¨äººå¯¼èˆªï¼Œå¸®åŠ©æœºå™¨äººåœ¨åŠ¨æ€ç¯å¢ƒä¸­è¿›è¡Œå®šä½å’Œè·¯å¾„è§„åˆ’ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›è¿›ä¸€æ­¥æ‰©å±•åˆ°æ›´å¤æ‚çš„åŠ¨æ€åœºæ™¯ï¼Œå¹¶ä¸å…¶ä»–è§†è§‰ä»»åŠ¡ç›¸ç»“åˆï¼Œå®ç°æ›´æ™ºèƒ½çš„è§†è§‰ç³»ç»Ÿã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> Although COLMAP has long remained the predominant method for camera parameter optimization in static scenes, it is constrained by its lengthy runtime and reliance on ground truth (GT) motion masks for application to dynamic scenes. Many efforts attempted to improve it by incorporating more priors as supervision such as GT focal length, motion masks, 3D point clouds, camera poses, and metric depth, which, however, are typically unavailable in casually captured RGB videos. In this paper, we propose a novel method for more accurate and efficient camera parameter optimization in dynamic scenes solely supervised by a single RGB video, dubbed ROS-Cam. Our method consists of three key components: (1) Patch-wise Tracking Filters, to establish robust and maximally sparse hinge-like relations across the RGB video. (2) Outlier-aware Joint Optimization, for efficient camera parameter optimization by adaptive down-weighting of moving outliers, without reliance on motion priors. (3) A Two-stage Optimization Strategy, to enhance stability and optimization speed by a trade-off between the Softplus limits and convex minima in losses. We visually and numerically evaluate our camera estimates. To further validate accuracy, we feed the camera estimates into a 4D reconstruction method and assess the resulting 3D scenes, and rendered 2D RGB and depth maps. We perform experiments on 4 real-world datasets (NeRF-DS, DAVIS, iPhone, and TUM-dynamics) and 1 synthetic dataset (MPI-Sintel), demonstrating that our method estimates camera parameters more efficiently and accurately with a single RGB video as the only supervision.

