---
layout: default
title: Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception
---

# Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.15333" class="toolbar-btn" target="_blank">üìÑ arXiv: 2509.15333v1</a>
  <a href="https://arxiv.org/pdf/2509.15333.pdf" class="toolbar-btn" target="_blank">üì• PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.15333v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.15333v1', 'Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception')" title="Ê∑ªÂä†Âà∞Êî∂ËóèÂ§π">‚òÜ Êî∂Ëóè</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">üîó ÂàÜ‰∫´</button>
</div>


**‰ΩúËÄÖ**: Yulin Wang, Yang Yue, Yang Yue, Huanqian Wang, Haojun Jiang, Yizeng Han, Zanlin Ni, Yifan Pu, Minglei Shi, Rui Lu, Qisen Yang, Andrew Zhao, Zhuofan Xia, Shiji Song, Gao Huang

**ÂàÜÁ±ª**: cs.CV, cs.AI, cs.LG, eess.IV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-09-18

**üîó ‰ª£Á†Å/È°πÁõÆ**: [GITHUB](https://github.com/LeapLabTHU/AdaptiveNN)

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫AdaptiveNNÔºåÈÄöËøáÊ®°‰ªø‰∫∫Á±ªËá™ÈÄÇÂ∫îËßÜËßâÂÆûÁé∞È´òÊïàÁÅµÊ¥ªÁöÑÊú∫Âô®ËßÜËßâÊÑüÁü•**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∫åÔºöRLÁÆóÊ≥ï‰∏éÊû∂ÊûÑ (RL & Architecture)** **ÊîØÊü±‰πùÔºöÂÖ∑Ë∫´Â§ßÊ®°Âûã (Embodied Foundation Models)**

**ÂÖ≥ÈîÆËØç**: `Ëá™ÈÄÇÂ∫îËßÜËßâ` `Âº∫ÂåñÂ≠¶‰π†` `Â∫èÂàóÂÜ≥Á≠ñ` `ËßÜËßâÊÑüÁü•` `È´òÊïàËÆ°ÁÆó`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâÊú∫Âô®ËßÜËßâÊ®°ÂûãË¢´Âä®Â§ÑÁêÜÊï¥‰∏™Âú∫ÊôØÔºåÂØºËá¥ËµÑÊ∫êÊ∂àËÄóÂ∑®Â§ßÔºåÈöæ‰ª•ÈÄÇÂ∫îÂ§çÊùÇÁéØÂ¢ÉÂíåÂÆûÈôÖÂ∫îÁî®„ÄÇ
2. AdaptiveNNÊ®°‰ªø‰∫∫Á±ªËßÜËßâÁöÑËá™ÈÄÇÂ∫îÊú∫Âà∂ÔºåÈÄöËøáÂ∫èÂàóÊ≥®ËßÜÂíåÂ¢ûÈáè‰ø°ÊÅØËûçÂêàÔºåÂÆûÁé∞È´òÊïàÁöÑËßÜËßâÊÑüÁü•„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåAdaptiveNNÂú®Â§ö‰∏™‰ªªÂä°‰∏äÂÆûÁé∞‰∫ÜÊòæËëóÁöÑÊé®ÁêÜÊàêÊú¨Èôç‰ΩéÔºåÂπ∂Â±ïÁé∞Âá∫‰∏é‰∫∫Á±ªÁõ∏‰ººÁöÑÊÑüÁü•Ë°å‰∏∫„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

‰∫∫Á±ªËßÜËßâÂÖ∑ÊúâÈ´òÂ∫¶ÁöÑÈÄÇÂ∫îÊÄßÔºåÈÄöËøáÈ°∫Â∫èÂú∞Ê≥®ËßÜ‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂå∫ÂüüÊù•È´òÊïàÂú∞ÈááÊ†∑Â§çÊùÇÁéØÂ¢É„ÄÇÁõ∏ÊØî‰πã‰∏ãÔºåÁõÆÂâçÊµÅË°åÁöÑÊú∫Âô®ËßÜËßâÊ®°ÂûãË¢´Âä®Âú∞‰∏ÄÊ¨°ÊÄßÂ§ÑÁêÜÊï¥‰∏™Âú∫ÊôØÔºåÂØºËá¥ËøáÂ∫¶ÁöÑËµÑÊ∫êÈúÄÊ±ÇÔºåÂπ∂ÈöèÁùÄÊó∂Á©∫ËæìÂÖ•ÂàÜËæ®ÁéáÂíåÊ®°ÂûãÂ§ßÂ∞èËÄåÊâ©Â±ïÔºå‰ªéËÄå‰∫ßÁîüÈòªÁ¢çÊú™Êù•ÂèëÂ±ïÂíåÂÆûÈôÖÂ∫îÁî®ÁöÑÂÖ≥ÈîÆÈôêÂà∂„ÄÇÊú¨Êñá‰ªãÁªçAdaptiveNNÔºå‰∏Ä‰∏™Êó®Âú®Êé®Âä®‰ªé‚ÄúË¢´Âä®‚ÄùÂà∞‚Äú‰∏ªÂä®„ÄÅËá™ÈÄÇÂ∫î‚ÄùËßÜËßâÊ®°ÂûãËåÉÂºèËΩ¨ÂèòÁöÑÈÄöÁî®Ê°ÜÊû∂„ÄÇAdaptiveNNÂ∞ÜËßÜËßâÊÑüÁü•ÊûÑÂª∫‰∏∫‰∏Ä‰∏™Áî±Á≤óÂà∞Á≤æÁöÑÈ°∫Â∫èÂÜ≥Á≠ñËøáÁ®ãÔºåÈÄêÊ≠•ËØÜÂà´ÂíåÂÖ≥Ê≥®‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºåÂ¢ûÈáèÂú∞ÁªÑÂêàË∑®Ê≥®ËßÜÁöÑ‰ø°ÊÅØÔºåÂπ∂Âú®‰ø°ÊÅØÂÖÖË∂≥Êó∂‰∏ªÂä®ÁªìÊùüËßÇÂØü„ÄÇÊàë‰ª¨Âª∫Á´ã‰∫Ü‰∏Ä‰∏™Â∞ÜË°®ÂæÅÂ≠¶‰π†‰∏éËá™Â•ñÂä±Âº∫ÂåñÂ≠¶‰π†Áõ∏ÁªìÂêàÁöÑÁêÜËÆ∫Ôºå‰ªéËÄåËÉΩÂ§üÂØπ‰∏çÂèØÂæÆÁöÑAdaptiveNNËøõË°åÁ´ØÂà∞Á´ØËÆ≠ÁªÉÔºåËÄåÊó†ÈúÄÂØπÊ≥®ËßÜ‰ΩçÁΩÆËøõË°åÈ¢ùÂ§ñÁöÑÁõëÁù£„ÄÇÊàë‰ª¨Âú®Ê∂µÁõñ9‰∏™‰ªªÂä°ÁöÑ17‰∏™Âü∫ÂáÜ‰∏äËØÑ‰º∞‰∫ÜAdaptiveNNÔºåÂåÖÊã¨Â§ßËßÑÊ®°ËßÜËßâËØÜÂà´„ÄÅÁªÜÁ≤íÂ∫¶Âà§Âà´„ÄÅËßÜËßâÊêúÁ¥¢„ÄÅÂ§ÑÁêÜÊù•Ëá™ÁúüÂÆûÈ©æÈ©∂ÂíåÂåªÁñóÂú∫ÊôØÁöÑÂõæÂÉè„ÄÅËØ≠Ë®ÄÈ©±Âä®ÁöÑÂÖ∑Ë∫´AIÔºå‰ª•Âèä‰∏é‰∫∫Á±ªÁöÑÂπ∂ÊéíÊØîËæÉ„ÄÇAdaptiveNNÂú®‰∏çÁâ∫Áâ≤ÂáÜÁ°ÆÊÄßÁöÑÂâçÊèê‰∏ãÔºåÂÆûÁé∞‰∫ÜÈ´òËææ28ÂÄçÁöÑÊé®ÁêÜÊàêÊú¨Èôç‰ΩéÔºåÁÅµÊ¥ªÂú∞ÈÄÇÂ∫î‰∏çÂêåÁöÑ‰ªªÂä°ÈúÄÊ±ÇÂíåËµÑÊ∫êÈ¢ÑÁÆóËÄåÊó†ÈúÄÈáçÊñ∞ËÆ≠ÁªÉÔºåÂπ∂ÈÄöËøáÂÖ∂Ê≥®ËßÜÊ®°ÂºèÊèê‰æõ‰∫ÜÂ¢ûÂº∫ÁöÑÂèØËß£ÈáäÊÄßÔºåÂ±ïÁ§∫‰∫ÜÈÄöÂæÄÈ´òÊïà„ÄÅÁÅµÊ¥ªÂíåÂèØËß£ÈáäÁöÑËÆ°ÁÆóÊú∫ËßÜËßâÁöÑÊúâÂ∏åÊúõÁöÑÈÄîÂæÑ„ÄÇÊ≠§Â§ñÔºåAdaptiveNNÂú®ËÆ∏Â§öÊÉÖÂÜµ‰∏ãË°®Áé∞Âá∫‰∏é‰∫∫Á±ªÈùûÂ∏∏Áõ∏‰ººÁöÑÊÑüÁü•Ë°å‰∏∫ÔºåÊè≠Á§∫‰∫ÜÂÖ∂‰Ωú‰∏∫Á†îÁ©∂ËßÜËßâËÆ§Áü•ÁöÑÂÆùË¥µÂ∑•ÂÖ∑ÁöÑÊΩúÂäõ„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÊú∫Âô®ËßÜËßâÊ®°ÂûãÈÄöÂ∏∏ÈááÁî®Ë¢´Âä®ÂºèÂ§ÑÁêÜÊñπÂºèÔºåÂç≥‰∏ÄÊ¨°ÊÄßÂ§ÑÁêÜÊï¥‰∏™ÂõæÂÉèÊàñËßÜÈ¢ëÂ∏ßÔºåÂØºËá¥ËÆ°ÁÆóËµÑÊ∫êÊ∂àËÄóÂ∑®Â§ßÔºåÂ∞§ÂÖ∂ÊòØÂú®Â§ÑÁêÜÈ´òÂàÜËæ®ÁéáÊàñÈïøÊó∂Èó¥Â∫èÂàóÊï∞ÊçÆÊó∂„ÄÇËøôÁßçË¢´Âä®ÂºèÂ§ÑÁêÜÊñπÂºèÂøΩÁï•‰∫Ü‰∫∫Á±ªËßÜËßâÁ≥ªÁªüÈÄâÊã©ÊÄßÂÖ≥Ê≥®ÈáçË¶ÅÂå∫ÂüüÁöÑËÉΩÂäõÔºåÈôêÂà∂‰∫ÜÊ®°ÂûãÂú®ËµÑÊ∫êÂèóÈôêÁéØÂ¢É‰∏ãÁöÑÂ∫îÁî®ÔºåÂπ∂‰∏îÁº∫‰πèÂèØËß£ÈáäÊÄß„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöAdaptiveNNÁöÑÊ†∏ÂøÉÊÄùË∑ØÊòØÊ®°‰ªø‰∫∫Á±ªËßÜËßâÁ≥ªÁªüÁöÑËá™ÈÄÇÂ∫îÊ≥®ËßÜÊú∫Âà∂ÔºåÂ∞ÜËßÜËßâÊÑüÁü•ËøáÁ®ãÂª∫Ê®°‰∏∫‰∏Ä‰∏™Â∫èÂàóÂÜ≥Á≠ñËøáÁ®ã„ÄÇÊ®°ÂûãÈÄöËøáÈÄêÊ≠•ËØÜÂà´ÂíåÂÖ≥Ê≥®‰∏é‰ªªÂä°Áõ∏ÂÖ≥ÁöÑÂå∫ÂüüÔºåÂπ∂Â¢ûÈáèÂú∞ËûçÂêàÊù•Ëá™‰∏çÂêåÊ≥®ËßÜÁÇπÁöÑ‰ø°ÊÅØÔºå‰ªéËÄåÂÆûÁé∞È´òÊïàÁöÑËßÜËßâÊÑüÁü•„ÄÇËøôÁßçËá™ÈÄÇÂ∫îÁöÑÊñπÂºèÂÖÅËÆ∏Ê®°ÂûãÂú®‰ø°ÊÅØÂÖÖË∂≥Êó∂‰∏ªÂä®ÂÅúÊ≠¢ËßÇÂØüÔºåËøõ‰∏ÄÊ≠•Èôç‰ΩéËÆ°ÁÆóÊàêÊú¨„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöAdaptiveNNÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÂê´‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ®°ÂùóÔºö1) **Ê≥®ËßÜÁÇπÈ¢ÑÊµãÂô®**ÔºöË¥üË¥£È¢ÑÊµã‰∏ã‰∏Ä‰∏™ÈúÄË¶ÅÂÖ≥Ê≥®ÁöÑÂå∫Âüü„ÄÇ2) **ËßÜËßâÁºñÁ†ÅÂô®**ÔºöÊèêÂèñÂΩìÂâçÊ≥®ËßÜÂå∫ÂüüÁöÑËßÜËßâÁâπÂæÅ„ÄÇ3) **‰ø°ÊÅØËûçÂêàÊ®°Âùó**ÔºöÂ∞ÜÊù•Ëá™‰∏çÂêåÊ≥®ËßÜÁÇπÁöÑËßÜËßâÁâπÂæÅËøõË°åËûçÂêàÔºåÂΩ¢ÊàêÂØπÊï¥‰∏™Âú∫ÊôØÁöÑÁªºÂêàÁêÜËß£„ÄÇ4) **ÂÜ≥Á≠ñÊ®°Âùó**ÔºöÊ†πÊçÆËûçÂêàÂêéÁöÑ‰ø°ÊÅØÔºåÂÅöÂá∫ÊúÄÁªàÁöÑÈ¢ÑÊµãÊàñÂÜ≥Á≠ñ„ÄÇÊï¥‰∏™ËøáÁ®ãÈÄöËøáÂº∫ÂåñÂ≠¶‰π†ËøõË°åÁ´ØÂà∞Á´ØËÆ≠ÁªÉÔºåÊó†ÈúÄÈ¢ùÂ§ñÁöÑÊ≥®ËßÜÁÇπÊ†áÊ≥®„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöAdaptiveNNÊúÄÈáçË¶ÅÁöÑÂàõÊñ∞ÁÇπÂú®‰∫éÂÖ∂Â∞ÜËßÜËßâÊÑüÁü•Âª∫Ê®°‰∏∫‰∏Ä‰∏™Ëá™ÈÄÇÂ∫îÁöÑÂ∫èÂàóÂÜ≥Á≠ñËøáÁ®ãÔºåÂπ∂ÈááÁî®Âº∫ÂåñÂ≠¶‰π†ËøõË°åËÆ≠ÁªÉ„ÄÇ‰∏é‰º†ÁªüÁöÑË¢´Âä®ÂºèËßÜËßâÊ®°ÂûãÁõ∏ÊØîÔºåAdaptiveNNËÉΩÂ§üÊ†πÊçÆ‰ªªÂä°ÈúÄÊ±ÇÂíåÂú∫ÊôØÂÜÖÂÆπÂä®ÊÄÅÂú∞Ë∞ÉÊï¥ÂÖ∂ÂÖ≥Ê≥®Âå∫ÂüüÔºå‰ªéËÄåÂÆûÁé∞Êõ¥È´òÁöÑÊïàÁéáÂíåÁÅµÊ¥ªÊÄß„ÄÇÊ≠§Â§ñÔºåAdaptiveNNÁöÑÊ≥®ËßÜÊ®°Âºè‰πüÊèê‰æõ‰∫ÜÊõ¥Âº∫ÁöÑÂèØËß£ÈáäÊÄß„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöAdaptiveNNÁöÑÂÖ≥ÈîÆËÆæËÆ°ÂåÖÊã¨Ôºö1) ‰ΩøÁî®Ê∑±Â∫¶Âº∫ÂåñÂ≠¶‰π†Ôºà‰æãÂ¶ÇÔºåActor-CriticÁÆóÊ≥ïÔºâËÆ≠ÁªÉÊ≥®ËßÜÁÇπÈ¢ÑÊµãÂô®ÔºåÂ•ñÂä±ÂáΩÊï∞ÁöÑËÆæËÆ°ÈºìÂä±Ê®°ÂûãÂÖ≥Ê≥®‰ø°ÊÅØÈáèÂ§ßÁöÑÂå∫ÂüüÔºåÂπ∂Â∞ΩÊó©ÂÅöÂá∫ÂáÜÁ°ÆÁöÑÈ¢ÑÊµã„ÄÇ2) ÈááÁî®Âæ™ÁéØÁ•ûÁªèÁΩëÁªúÔºàRNNÔºâÊàñTransformerÁ≠âÂ∫èÂàóÊ®°Âûã‰Ωú‰∏∫‰ø°ÊÅØËûçÂêàÊ®°ÂùóÔºå‰ª•ÊúâÊïàÂú∞Êï¥ÂêàÊù•Ëá™‰∏çÂêåÊ≥®ËßÜÁÇπÁöÑ‰ø°ÊÅØ„ÄÇ3) ËÆæËÆ°ÂêàÈÄÇÁöÑÊé¢Á¥¢Á≠ñÁï•ÔºåÈºìÂä±Ê®°ÂûãÊé¢Á¥¢‰∏çÂêåÁöÑÊ≥®ËßÜÊ®°ÂºèÔºåÈÅøÂÖçÈô∑ÂÖ•Â±ÄÈÉ®ÊúÄ‰ºò„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

AdaptiveNNÂú®17‰∏™Âü∫ÂáÜÊµãËØï‰∏≠Ë°®Áé∞Âá∫Ëâ≤ÔºåÊ∂µÁõñÂ§ßËßÑÊ®°ËßÜËßâËØÜÂà´„ÄÅÁªÜÁ≤íÂ∫¶Âà§Âà´„ÄÅËßÜËßâÊêúÁ¥¢Á≠â‰ªªÂä°„ÄÇÂú®‰∏çÁâ∫Áâ≤ÂáÜÁ°ÆÊÄßÁöÑÂâçÊèê‰∏ãÔºåAdaptiveNNÂÆûÁé∞‰∫ÜÈ´òËææ28ÂÄçÁöÑÊé®ÁêÜÊàêÊú¨Èôç‰Ωé„ÄÇÊ≠§Â§ñÔºåAdaptiveNNÂú®ÁúüÂÆûÈ©æÈ©∂ÂíåÂåªÁñóÂú∫ÊôØ‰∏≠‰πüË°®Áé∞Âá∫ËâØÂ•ΩÁöÑÈÄÇÂ∫îÊÄß„ÄÇ‰∏é‰∫∫Á±ªÁöÑÂπ∂ÊéíÊØîËæÉË°®ÊòéÔºåAdaptiveNNÂú®ËÆ∏Â§öÊÉÖÂÜµ‰∏ãË°®Áé∞Âá∫‰∏é‰∫∫Á±ªÈùûÂ∏∏Áõ∏‰ººÁöÑÊÑüÁü•Ë°å‰∏∫„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

AdaptiveNNÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØÔºåÂåÖÊã¨Ëá™Âä®È©æÈ©∂„ÄÅÂåªÁñóÂΩ±ÂÉèÂàÜÊûê„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËßÜÈ¢ëÁõëÊéßÁ≠âÈ¢ÜÂüü„ÄÇÂÖ∂È´òÊïàÁöÑËÆ°ÁÆóÁâπÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÂú®ËµÑÊ∫êÂèóÈôêÁöÑËÆæÂ§á‰∏äËøêË°åÔºå‰æãÂ¶ÇÁßªÂä®ËÆæÂ§áÂíåÂµåÂÖ•ÂºèÁ≥ªÁªü„ÄÇÊ≠§Â§ñÔºåAdaptiveNNÁöÑÂèØËß£ÈáäÊÄß‰ΩøÂÖ∂ËÉΩÂ§üÂ∏ÆÂä©‰∫∫‰ª¨Êõ¥Â•ΩÂú∞ÁêÜËß£Ê®°ÂûãÁöÑÂÜ≥Á≠ñËøáÁ®ãÔºå‰ªéËÄåÊèêÈ´òÊ®°ÂûãÁöÑÂèØÈù†ÊÄßÂíåÂèØ‰ø°Â∫¶„ÄÇÊú™Êù•ÔºåAdaptiveNNÊúâÊúõÊàê‰∏∫‰∏ÄÁßçÈÄöÁî®ÁöÑËßÜËßâÊÑüÁü•Ê°ÜÊû∂ÔºåÊé®Âä®ËÆ°ÁÆóÊú∫ËßÜËßâÊäÄÊúØÁöÑÂèëÂ±ï„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Human vision is highly adaptive, efficiently sampling intricate environments by sequentially fixating on task-relevant regions. In contrast, prevailing machine vision models passively process entire scenes at once, resulting in excessive resource demands scaling with spatial-temporal input resolution and model size, yielding critical limitations impeding both future advancements and real-world application. Here we introduce AdaptiveNN, a general framework aiming to drive a paradigm shift from 'passive' to 'active, adaptive' vision models. AdaptiveNN formulates visual perception as a coarse-to-fine sequential decision-making process, progressively identifying and attending to regions pertinent to the task, incrementally combining information across fixations, and actively concluding observation when sufficient. We establish a theory integrating representation learning with self-rewarding reinforcement learning, enabling end-to-end training of the non-differentiable AdaptiveNN without additional supervision on fixation locations. We assess AdaptiveNN on 17 benchmarks spanning 9 tasks, including large-scale visual recognition, fine-grained discrimination, visual search, processing images from real driving and medical scenarios, language-driven embodied AI, and side-by-side comparisons with humans. AdaptiveNN achieves up to 28x inference cost reduction without sacrificing accuracy, flexibly adapts to varying task demands and resource budgets without retraining, and provides enhanced interpretability via its fixation patterns, demonstrating a promising avenue toward efficient, flexible, and interpretable computer vision. Furthermore, AdaptiveNN exhibits closely human-like perceptual behaviors in many cases, revealing its potential as a valuable tool for investigating visual cognition. Code is available at https://github.com/LeapLabTHU/AdaptiveNN.

