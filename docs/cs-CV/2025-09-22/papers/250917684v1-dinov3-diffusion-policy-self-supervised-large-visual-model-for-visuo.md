---
layout: default
title: DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning
---

# DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning

<div class="paper-toolbar">
  <a href="https://arxiv.org/abs/2509.17684" class="toolbar-btn" target="_blank">ğŸ“„ arXiv: 2509.17684v1</a>
  <a href="https://arxiv.org/pdf/2509.17684.pdf" class="toolbar-btn" target="_blank">ğŸ“¥ PDF</a>
  <button class="toolbar-btn favorite-btn" data-arxiv-id="2509.17684v1" data-paper-url="__CURRENT_PAGE__" onclick="toggleFavorite(this, '2509.17684v1', 'DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning')" title="æ·»åŠ åˆ°æ”¶è—å¤¹">â˜† æ”¶è—</button>
  <button class="toolbar-btn" onclick="copyLinkToClipboard(this)">ğŸ”— åˆ†äº«</button>
</div>


**ä½œè€…**: ThankGod Egbe, Peng Wang, Zhihao Guo, Zidong Chen

**åˆ†ç±»**: cs.CV, cs.RO

**å‘å¸ƒæ—¥æœŸ**: 2025-09-22

---

## ğŸ’¡ ä¸€å¥è¯è¦ç‚¹

**DINOv3èµ‹èƒ½æ‰©æ•£ç­–ç•¥ï¼šç”¨äºæœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ çš„è‡ªç›‘ç£å¤§å‹è§†è§‰æ¨¡å‹**

ğŸ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±ä¸€ï¼šæœºå™¨äººæ§åˆ¶ (Robot Control)** **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸æ¶æ„ (RL & Architecture)**

**å…³é”®è¯**: `æœºå™¨äººæ“ä½œ` `è§†è§‰è¿åŠ¨ç­–ç•¥` `æ‰©æ•£ç­–ç•¥` `è‡ªç›‘ç£å­¦ä¹ ` `DINOv3` `è§†è§‰ç¼–ç å™¨` `è¿ç§»å­¦ä¹ `

## ğŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç°æœ‰æœºå™¨äººæ“ä½œä»»åŠ¡ä¾èµ–ImageNeté¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†å…¶é¢†åŸŸå·®å¼‚é™åˆ¶äº†æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚
2. è®ºæ–‡æå‡ºåˆ©ç”¨è‡ªç›‘ç£å­¦ä¹ çš„DINOv3ä½œä¸ºè§†è§‰ç¼–ç å™¨ï¼Œæ¢ç´¢å…¶åœ¨è§†è§‰è¿åŠ¨æ‰©æ•£ç­–ç•¥å­¦ä¹ ä¸­çš„æ½œåŠ›ã€‚
3. å®éªŒè¡¨æ˜ï¼Œå¾®è°ƒçš„DINOv3åœ¨å¤šä¸ªä»»åŠ¡ä¸Šè¶…è¶ŠResNet-18ï¼Œä¸”å†»ç»“çš„DINOv3ä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ã€‚

## ğŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡è¯„ä¼°äº†DINOv3ï¼Œä¸€ç§æœ€æ–°çš„å¤§è§„æ¨¡è‡ªç›‘ç£è§†è§‰éª¨å¹²ç½‘ç»œï¼Œåœ¨æœºå™¨äººæ“ä½œä¸­çš„è§†è§‰è¿åŠ¨æ‰©æ•£ç­–ç•¥å­¦ä¹ æ–¹é¢çš„æ€§èƒ½ã€‚æˆ‘ä»¬ç ”ç©¶äº†åœ¨ä¸‰ç§è®­ç»ƒæ¨¡å¼ä¸‹ï¼šä»å¤´å¼€å§‹è®­ç»ƒã€å†»ç»“å’Œå¾®è°ƒï¼Œçº¯è‡ªç›‘ç£ç¼–ç å™¨æ˜¯å¦èƒ½ä¸ä¼ ç»Ÿçš„ç›‘ç£ImageNeté¢„è®­ç»ƒéª¨å¹²ç½‘ç»œï¼ˆä¾‹å¦‚ï¼ŒResNet-18ï¼‰ç›¸åª²ç¾æˆ–è¶…è¶Šã€‚åœ¨å››ä¸ªåŸºå‡†ä»»åŠ¡ï¼ˆPush-Tã€Liftã€Canã€Squareï¼‰ä¸­ä½¿ç”¨ç»Ÿä¸€çš„FiLMæ¡ä»¶æ‰©æ•£ç­–ç•¥ï¼Œæˆ‘ä»¬å‘ç°ï¼šï¼ˆiï¼‰å¾®è°ƒåçš„DINOv3åœ¨å¤šä¸ªä»»åŠ¡ä¸Šä¸ResNet-18ç›¸åŒ¹é…æˆ–è¶…è¿‡ï¼›ï¼ˆiiï¼‰å†»ç»“çš„DINOv3ä»ç„¶å…·æœ‰ç«äº‰åŠ›ï¼Œè¡¨æ˜å…¶å…·æœ‰å¼ºå¤§çš„å¯è¿ç§»å…ˆéªŒçŸ¥è¯†ï¼›ï¼ˆiiiï¼‰è‡ªç›‘ç£ç‰¹å¾æé«˜äº†æ ·æœ¬æ•ˆç‡å’Œé²æ£’æ€§ã€‚è¿™äº›ç»“æœæ”¯æŒè‡ªç›‘ç£å¤§å‹è§†è§‰æ¨¡å‹ä½œä¸ºåŠ¨ä½œæ‰©æ•£ç­–ç•¥çš„æœ‰æ•ˆã€å¯æ³›åŒ–çš„æ„ŸçŸ¥å‰ç«¯ï¼Œä»è€Œæ¨åŠ¨äº†åœ¨æœºå™¨äººæ“ä½œä¸­å¯¹å¯æ‰©å±•çš„æ— æ ‡ç­¾é¢„è®­ç»ƒçš„è¿›ä¸€æ­¥æ¢ç´¢ã€‚ä¸ä½¿ç”¨ResNet18ä½œä¸ºéª¨å¹²ç½‘ç»œç›¸æ¯”ï¼Œæˆ‘ä»¬ä½¿ç”¨DINOv3çš„æ–¹æ³•åœ¨Canç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ä¸­ï¼Œæµ‹è¯•æ—¶çš„æˆåŠŸç‡ç»å¯¹æé«˜äº†10%ï¼Œå¹¶ä¸”åœ¨Liftã€PushTå’ŒSquareç­‰ä»»åŠ¡ä¸­è¡¨ç°ç›¸å½“ã€‚

## ğŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šè®ºæ–‡æ—¨åœ¨è§£å†³æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­ï¼Œç°æœ‰æ–¹æ³•ä¾èµ–ImageNeté¢„è®­ç»ƒæ¨¡å‹å¯¼è‡´çš„é¢†åŸŸæ³›åŒ–æ€§ä¸è¶³çš„é—®é¢˜ã€‚ImageNeté¢„è®­ç»ƒæ¨¡å‹ä¸æœºå™¨äººæ“ä½œç¯å¢ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œé™åˆ¶äº†ç­–ç•¥çš„å­¦ä¹ æ•ˆç‡å’Œé²æ£’æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šè®ºæ–‡çš„æ ¸å¿ƒæ€è·¯æ˜¯åˆ©ç”¨å¤§è§„æ¨¡è‡ªç›‘ç£å­¦ä¹ å¾—åˆ°çš„DINOv3æ¨¡å‹ä½œä¸ºè§†è§‰ç¼–ç å™¨ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„ImageNeté¢„è®­ç»ƒæ¨¡å‹ã€‚DINOv3é€šè¿‡è‡ªç›‘ç£å­¦ä¹ ï¼Œèƒ½å¤Ÿå­¦ä¹ åˆ°æ›´é€šç”¨çš„è§†è§‰ç‰¹å¾ï¼Œä»è€Œæ›´å¥½åœ°é€‚åº”æœºå™¨äººæ“ä½œç¯å¢ƒã€‚è¿™æ ·è®¾è®¡çš„ç›®çš„æ˜¯ä¸ºäº†æé«˜ç­–ç•¥çš„å­¦ä¹ æ•ˆç‡ã€æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚

**æŠ€æœ¯æ¡†æ¶**ï¼šæ•´ä½“æ¡†æ¶åŒ…å«ä¸€ä¸ªè§†è§‰ç¼–ç å™¨ï¼ˆDINOv3æˆ–ResNet-18ï¼‰å’Œä¸€ä¸ªFiLMæ¡ä»¶æ‰©æ•£ç­–ç•¥ã€‚è§†è§‰ç¼–ç å™¨å°†å›¾åƒè¾“å…¥è½¬æ¢ä¸ºç‰¹å¾å‘é‡ï¼Œç„¶åå°†ç‰¹å¾å‘é‡è¾“å…¥åˆ°FiLMæ¡ä»¶æ‰©æ•£ç­–ç•¥ä¸­ï¼Œç”ŸæˆåŠ¨ä½œã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯”è¾ƒçœŸå®åŠ¨ä½œå’Œé¢„æµ‹åŠ¨ä½œä¹‹é—´çš„å·®å¼‚ï¼Œæ›´æ–°ç­–ç•¥å‚æ•°ã€‚è®ºæ–‡åœ¨ä¸‰ç§æ¨¡å¼ä¸‹è¯„ä¼°DINOv3ï¼šä»å¤´å¼€å§‹è®­ç»ƒã€å†»ç»“å’Œå¾®è°ƒã€‚

**å…³é”®åˆ›æ–°**ï¼šæœ€é‡è¦çš„æŠ€æœ¯åˆ›æ–°ç‚¹åœ¨äºå°†å¤§è§„æ¨¡è‡ªç›‘ç£å­¦ä¹ å¾—åˆ°çš„DINOv3æ¨¡å‹åº”ç”¨äºæœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ã€‚ä¸ä¼ ç»Ÿçš„ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œè‡ªç›‘ç£å­¦ä¹ èƒ½å¤Ÿåˆ©ç”¨å¤§é‡çš„æ— æ ‡ç­¾æ•°æ®ï¼Œå­¦ä¹ åˆ°æ›´é€šç”¨çš„è§†è§‰ç‰¹å¾ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢ç´¢äº†DINOv3åœ¨ä¸åŒè®­ç»ƒæ¨¡å¼ä¸‹çš„æ€§èƒ½ï¼Œä¸ºå®é™…åº”ç”¨æä¾›äº†æŒ‡å¯¼ã€‚

**å…³é”®è®¾è®¡**ï¼šè®ºæ–‡ä½¿ç”¨FiLMæ¡ä»¶æ‰©æ•£ç­–ç•¥ï¼Œè¯¥ç­–ç•¥èƒ½å¤Ÿæ ¹æ®è§†è§‰ç‰¹å¾åŠ¨æ€è°ƒæ•´æ‰©æ•£è¿‡ç¨‹ã€‚æŸå¤±å‡½æ•°é‡‡ç”¨å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ¥è¡¡é‡é¢„æµ‹åŠ¨ä½œå’ŒçœŸå®åŠ¨ä½œä¹‹é—´çš„å·®å¼‚ã€‚å®éªŒä¸­ï¼Œä½œè€…ä½¿ç”¨äº†å››ä¸ªåŸºå‡†ä»»åŠ¡ï¼ˆPush-Tã€Liftã€Canã€Squareï¼‰æ¥è¯„ä¼°ä¸åŒæ¨¡å‹çš„æ€§èƒ½ã€‚DINOv3æ¨¡å‹é‡‡ç”¨ViTæ¶æ„ï¼Œå¹¶ä½¿ç”¨å¤§è§„æ¨¡æ— æ ‡ç­¾å›¾åƒæ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚

## ğŸ“Š å®éªŒäº®ç‚¹

å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨Canä»»åŠ¡ä¸­ï¼Œä½¿ç”¨å¾®è°ƒåçš„DINOv3ä½œä¸ºè§†è§‰ç¼–ç å™¨ï¼Œæµ‹è¯•æ—¶çš„æˆåŠŸç‡æ¯”ä½¿ç”¨ResNet-18æé«˜äº†10%ã€‚åœ¨Liftã€PushTå’ŒSquareç­‰ä»»åŠ¡ä¸­ï¼ŒDINOv3çš„æ€§èƒ½ä¸ResNet-18ç›¸å½“ã€‚æ­¤å¤–ï¼Œå†»ç»“çš„DINOv3ä¹Ÿè¡¨ç°å‡ºç«äº‰åŠ›ï¼Œè¡¨æ˜å…¶å…·æœ‰å¼ºå¤§çš„å¯è¿ç§»å…ˆéªŒçŸ¥è¯†ã€‚è¿™äº›ç»“æœéªŒè¯äº†è‡ªç›‘ç£å­¦ä¹ åœ¨æœºå™¨äººè§†è§‰è¿åŠ¨ç­–ç•¥å­¦ä¹ ä¸­çš„æœ‰æ•ˆæ€§ã€‚

## ğŸ¯ åº”ç”¨åœºæ™¯

è¯¥ç ”ç©¶æˆæœå¯åº”ç”¨äºå„ç§æœºå™¨äººæ“ä½œä»»åŠ¡ï¼Œä¾‹å¦‚ç‰©ä½“æŠ“å–ã€è£…é…ã€å¯¼èˆªç­‰ã€‚é€šè¿‡ä½¿ç”¨è‡ªç›‘ç£å­¦ä¹ å¾—åˆ°çš„è§†è§‰æ¨¡å‹ï¼Œå¯ä»¥é™ä½å¯¹å¤§é‡æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæé«˜æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸­çš„é€‚åº”æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚æœªæ¥ï¼Œè¯¥æ–¹æ³•æœ‰æœ›æ¨åŠ¨æœºå™¨äººæŠ€æœ¯åœ¨å·¥ä¸šè‡ªåŠ¨åŒ–ã€åŒ»ç–—å¥åº·ã€å®¶åº­æœåŠ¡ç­‰é¢†åŸŸçš„å¹¿æ³›åº”ç”¨ã€‚

## ğŸ“„ æ‘˜è¦ï¼ˆåŸæ–‡ï¼‰

> This paper evaluates DINOv3, a recent large-scale self-supervised vision backbone, for visuomotor diffusion policy learning in robotic manipulation. We investigate whether a purely self-supervised encoder can match or surpass conventional supervised ImageNet-pretrained backbones (e.g., ResNet-18) under three regimes: training from scratch, frozen, and finetuned. Across four benchmark tasks (Push-T, Lift, Can, Square) using a unified FiLM-conditioned diffusion policy, we find that (i) finetuned DINOv3 matches or exceeds ResNet-18 on several tasks, (ii) frozen DINOv3 remains competitive, indicating strong transferable priors, and (iii) self-supervised features improve sample efficiency and robustness. These results support self-supervised large visual models as effective, generalizable perceptual front-ends for action diffusion policies, motivating further exploration of scalable label-free pretraining in robotic manipulation. Compared to using ResNet18 as a backbone, our approach with DINOv3 achieves up to a 10% absolute increase in test-time success rates on challenging tasks such as Can, and on-the-par performance in tasks like Lift, PushT, and Square.

