---
layout: default
title: ConsistTalk: Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search
---

# ConsistTalk: Intensity Controllable Temporally Consistent Talking Head Generation with Diffusion Noise Search

**arXiv**: [2511.06833v1](https://arxiv.org/abs/2511.06833) | [PDF](https://arxiv.org/pdf/2511.06833.pdf)

**ä½œè€…**: Zhenjie Liu, Jianzhang Lu, Renjie Lu, Cong Liang, Shangfei Wang

**åˆ†ç±»**: cs.CV

**å‘å¸ƒæ—¥æœŸ**: 2025-11-10

**å¤‡æ³¨**: AAAI26 poster

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**ConsistTalkï¼šæå‡ºåŸºäºŽæ‰©æ•£å™ªå£°æœç´¢çš„ã€å¼ºåº¦å¯æŽ§ä¸”æ—¶åºä¸€è‡´çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ¡†æž¶**

ðŸŽ¯ **åŒ¹é…é¢†åŸŸ**: **æ”¯æŸ±äºŒï¼šRLç®—æ³•ä¸Žæž¶æž„ (RL & Architecture)** **æ”¯æŸ±ä¸‰ï¼šç©ºé—´æ„ŸçŸ¥ (Perception & SLAM)**

**å…³é”®è¯**: `è¯´è¯äººå¤´éƒ¨ç”Ÿæˆ` `æ‰©æ•£æ¨¡åž‹` `å…‰æµå¼•å¯¼` `éŸ³è§†é¢‘åŒæ­¥` `æ—¶åºä¸€è‡´æ€§`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. çŽ°æœ‰éŸ³é¢‘é©±åŠ¨çš„å¤´éƒ¨ç”Ÿæˆæ–¹æ³•å­˜åœ¨é—ªçƒã€èº«ä»½æ¼‚ç§»å’ŒéŸ³è§†é¢‘åŒæ­¥å·®ç­‰é—®é¢˜ï¼ŒæºäºŽå¤–è§‚-è¿åŠ¨è¡¨å¾çš„çº ç¼ å’Œä¸ç¨³å®šçš„æŽ¨ç†ç­–ç•¥ã€‚
2. ConsistTalké€šè¿‡å…‰æµå¼•å¯¼çš„æ—¶åºæ¨¡å—è§£è€¦è¿åŠ¨å’Œå¤–è§‚ï¼Œä½¿ç”¨A2Iæ¨¡åž‹è”åˆå»ºæ¨¡éŸ³è§†é¢‘è¿åŠ¨ï¼Œå¹¶å¼•å…¥æ‰©æ•£å™ªå£°åˆå§‹åŒ–ç­–ç•¥æ¥çº¦æŸèƒŒæ™¯å’Œè¿åŠ¨ã€‚
3. å®žéªŒè¡¨æ˜Žï¼ŒConsistTalkåœ¨å‡å°‘é—ªçƒã€ä¿æŒèº«ä»½å’Œç”Ÿæˆæ—¶åºç¨³å®šçš„é«˜ä¿çœŸè§†é¢‘æ–¹é¢ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ“ æ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰

æœ¬æ–‡æå‡ºConsistTalkï¼Œä¸€ä¸ªæ–°é¢–çš„å¼ºåº¦å¯æŽ§ä¸”æ—¶åºä¸€è‡´çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ¡†æž¶ï¼Œè¯¥æ¡†æž¶é‡‡ç”¨æ‰©æ•£å™ªå£°æœç´¢æŽ¨ç†ã€‚é¦–å…ˆï¼Œæå‡ºäº†å…‰æµå¼•å¯¼çš„æ—¶åºæ¨¡å—ï¼ˆOFTï¼‰ï¼Œé€šè¿‡åˆ©ç”¨é¢éƒ¨å…‰æµå°†è¿åŠ¨ç‰¹å¾ä¸Žé™æ€å¤–è§‚è§£è€¦ï¼Œä»Žè€Œå‡å°‘è§†è§‰é—ªçƒå¹¶æé«˜æ—¶é—´ä¸€è‡´æ€§ã€‚å…¶æ¬¡ï¼Œæå‡ºäº†é€šè¿‡å¤šæ¨¡æ€æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦èŽ·å¾—çš„éŸ³é¢‘-å¼ºåº¦ï¼ˆA2Iï¼‰æ¨¡åž‹ã€‚é€šè¿‡å°†éŸ³é¢‘å’Œé¢éƒ¨é€Ÿåº¦ç‰¹å¾è½¬æ¢ä¸ºé€å¸§å¼ºåº¦åºåˆ—ï¼ŒA2Iæ¨¡åž‹èƒ½å¤Ÿè”åˆå»ºæ¨¡éŸ³é¢‘å’Œè§†è§‰è¿åŠ¨ï¼Œä»Žè€Œäº§ç”Ÿæ›´è‡ªç„¶çš„åŠ¨æ€æ•ˆæžœã€‚è¿™è¿›ä¸€æ­¥å®žçŽ°äº†å¯¹è¿åŠ¨åŠ¨æ€çš„ç²¾ç»†ã€é€å¸§æŽ§åˆ¶ï¼ŒåŒæ—¶ä¿æŒäº†ç´§å¯†çš„éŸ³è§†é¢‘åŒæ­¥ã€‚ç¬¬ä¸‰ï¼Œå¼•å…¥äº†ä¸€ç§æ‰©æ•£å™ªå£°åˆå§‹åŒ–ç­–ç•¥ï¼ˆIC-Initï¼‰ã€‚é€šè¿‡åœ¨æŽ¨ç†æ—¶å™ªå£°æœç´¢æœŸé—´å¼ºåˆ¶æ‰§è¡Œå¯¹èƒŒæ™¯è¿žè´¯æ€§å’Œè¿åŠ¨è¿žç»­æ€§çš„æ˜¾å¼çº¦æŸï¼Œä¸Žå½“å‰çš„è‡ªå›žå½’ç­–ç•¥ç›¸æ¯”ï¼Œæˆ‘ä»¬å®žçŽ°äº†æ›´å¥½çš„èº«ä»½ä¿æŒå¹¶æ”¹è¿›äº†è¿åŠ¨åŠ¨æ€ã€‚å¤§é‡å®žéªŒè¡¨æ˜Žï¼ŒConsistTalkåœ¨å‡å°‘é—ªçƒã€ä¿æŒèº«ä»½ä»¥åŠæä¾›æ—¶é—´ç¨³å®šã€é«˜ä¿çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘æ–¹é¢ï¼Œæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚

## ðŸ”¬ æ–¹æ³•è¯¦è§£

**é—®é¢˜å®šä¹‰**ï¼šçŽ°æœ‰éŸ³é¢‘é©±åŠ¨çš„è¯´è¯äººå¤´éƒ¨ç”Ÿæˆæ–¹æ³•ï¼Œåœ¨ç”Ÿæˆè§†é¢‘æ—¶å­˜åœ¨ä¸¥é‡çš„è§†è§‰é—ªçƒã€èº«ä»½æ¼‚ç§»ä»¥åŠéŸ³è§†é¢‘åŒæ­¥ä¸ä½³çš„é—®é¢˜ã€‚è¿™äº›é—®é¢˜ä¸»è¦æºäºŽä¸¤ä¸ªæ–¹é¢ï¼šä¸€æ˜¯å¤–è§‚å’Œè¿åŠ¨ç‰¹å¾çš„è¡¨å¾ç›¸äº’çº ç¼ ï¼Œéš¾ä»¥æœ‰æ•ˆåˆ†ç¦»ï¼›äºŒæ˜¯æŽ¨ç†ç­–ç•¥ä¸ç¨³å®šï¼Œå®¹æ˜“å¯¼è‡´ç”Ÿæˆç»“æžœçš„æ—¶åºä¸ä¸€è‡´æ€§ã€‚

**æ ¸å¿ƒæ€è·¯**ï¼šConsistTalkçš„æ ¸å¿ƒæ€è·¯æ˜¯å°†è¿åŠ¨ä¿¡æ¯ä»Žå¤–è§‚ä¿¡æ¯ä¸­è§£è€¦ï¼Œå¹¶é‡‡ç”¨ä¸€ç§æ›´ç¨³å®šçš„æŽ¨ç†ç­–ç•¥æ¥ä¿è¯æ—¶åºä¸€è‡´æ€§ã€‚å…·ä½“æ¥è¯´ï¼Œåˆ©ç”¨å…‰æµæ¥æ˜¾å¼åœ°å»ºæ¨¡é¢éƒ¨è¿åŠ¨ï¼Œå¹¶å°†å…¶ä¸Žé™æ€çš„å¤–è§‚ç‰¹å¾åˆ†ç¦»ã€‚åŒæ—¶ï¼Œé€šè¿‡éŸ³é¢‘-å¼ºåº¦æ¨¡åž‹æ¥å»ºç«‹éŸ³é¢‘å’Œè§†è§‰è¿åŠ¨ä¹‹é—´çš„è”ç³»ï¼Œä»Žè€Œå®žçŽ°æ›´è‡ªç„¶çš„éŸ³è§†é¢‘åŒæ­¥ã€‚æ­¤å¤–ï¼Œè¿˜å¼•å…¥äº†ä¸€ç§æ–°çš„æ‰©æ•£å™ªå£°åˆå§‹åŒ–ç­–ç•¥ï¼Œä»¥çº¦æŸç”Ÿæˆè¿‡ç¨‹ä¸­çš„èƒŒæ™¯è¿žè´¯æ€§å’Œè¿åŠ¨è¿žç»­æ€§ã€‚

**æŠ€æœ¯æ¡†æž¶**ï¼šConsistTalkæ¡†æž¶ä¸»è¦åŒ…å«ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼š1) å…‰æµå¼•å¯¼çš„æ—¶åºæ¨¡å—ï¼ˆOFTï¼‰ï¼šç”¨äºŽè§£è€¦è¿åŠ¨ç‰¹å¾å’Œé™æ€å¤–è§‚ç‰¹å¾ã€‚2) éŸ³é¢‘-å¼ºåº¦ï¼ˆA2Iï¼‰æ¨¡åž‹ï¼šç”¨äºŽå°†éŸ³é¢‘å’Œé¢éƒ¨é€Ÿåº¦ç‰¹å¾è½¬æ¢ä¸ºé€å¸§å¼ºåº¦åºåˆ—ï¼Œä»Žè€Œå®žçŽ°éŸ³è§†é¢‘è¿åŠ¨çš„è”åˆå»ºæ¨¡ã€‚3) æ‰©æ•£å™ªå£°åˆå§‹åŒ–ç­–ç•¥ï¼ˆIC-Initï¼‰ï¼šç”¨äºŽåœ¨æŽ¨ç†æ—¶é€šè¿‡å™ªå£°æœç´¢æ¥çº¦æŸèƒŒæ™¯è¿žè´¯æ€§å’Œè¿åŠ¨è¿žç»­æ€§ã€‚æ•´ä½“æµç¨‹æ˜¯ï¼Œé¦–å…ˆä½¿ç”¨OFTæ¨¡å—æå–è§£è€¦åŽçš„è¿åŠ¨å’Œå¤–è§‚ç‰¹å¾ï¼Œç„¶åŽä½¿ç”¨A2Iæ¨¡åž‹ç”Ÿæˆé€å¸§çš„è¿åŠ¨å¼ºåº¦ï¼Œæœ€åŽä½¿ç”¨IC-Initç­–ç•¥è¿›è¡Œæ‰©æ•£æ¨¡åž‹çš„æŽ¨ç†ï¼Œç”Ÿæˆæœ€ç»ˆçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚

**å…³é”®åˆ›æ–°**ï¼šConsistTalkçš„å…³é”®åˆ›æ–°åœ¨äºŽä»¥ä¸‹ä¸‰ä¸ªæ–¹é¢ï¼š1) æå‡ºäº†å…‰æµå¼•å¯¼çš„æ—¶åºæ¨¡å—ï¼ˆOFTï¼‰ï¼Œå®žçŽ°äº†è¿åŠ¨ç‰¹å¾å’Œå¤–è§‚ç‰¹å¾çš„æœ‰æ•ˆè§£è€¦ã€‚2) æå‡ºäº†éŸ³é¢‘-å¼ºåº¦ï¼ˆA2Iï¼‰æ¨¡åž‹ï¼Œå®žçŽ°äº†éŸ³è§†é¢‘è¿åŠ¨çš„è”åˆå»ºæ¨¡å’Œç²¾ç»†æŽ§åˆ¶ã€‚3) æå‡ºäº†æ‰©æ•£å™ªå£°åˆå§‹åŒ–ç­–ç•¥ï¼ˆIC-Initï¼‰ï¼Œæé«˜äº†ç”Ÿæˆç»“æžœçš„æ—¶åºä¸€è‡´æ€§å’Œèº«ä»½ä¿æŒèƒ½åŠ›ã€‚ä¸ŽçŽ°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒConsistTalkèƒ½å¤Ÿç”Ÿæˆæ›´ç¨³å®šã€æ›´é€¼çœŸçš„è¯´è¯äººå¤´éƒ¨è§†é¢‘ã€‚

**å…³é”®è®¾è®¡**ï¼šOFTæ¨¡å—åˆ©ç”¨é¢„è®­ç»ƒçš„é¢éƒ¨å…‰æµä¼°è®¡å™¨æ¥æå–é¢éƒ¨å…‰æµä¿¡æ¯ï¼Œå¹¶å°†å…¶ä½œä¸ºè¿åŠ¨ç‰¹å¾çš„è¡¨ç¤ºã€‚A2Iæ¨¡åž‹é‡‡ç”¨å¤šæ¨¡æ€æ•™å¸ˆ-å­¦ç”ŸçŸ¥è¯†è’¸é¦çš„æ–¹å¼è¿›è¡Œè®­ç»ƒï¼Œä»¥æé«˜æ¨¡åž‹çš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚IC-Initç­–ç•¥é€šè¿‡åœ¨æŽ¨ç†æ—¶å¯¹å™ªå£°è¿›è¡Œçº¦æŸï¼Œæ¥ä¿è¯ç”Ÿæˆç»“æžœçš„èƒŒæ™¯è¿žè´¯æ€§å’Œè¿åŠ¨è¿žç»­æ€§ã€‚å…·ä½“çš„çº¦æŸæ–¹å¼åŒ…æ‹¬å¯¹èƒŒæ™¯åŒºåŸŸçš„å™ªå£°è¿›è¡Œå¹³æ»‘å¤„ç†ï¼Œä»¥åŠå¯¹è¿åŠ¨åŒºåŸŸçš„å™ªå£°è¿›è¡Œæ—¶é—´ä¸Šçš„å¹³æ»‘å¤„ç†ã€‚

## ðŸ“Š å®žéªŒäº®ç‚¹

å®žéªŒç»“æžœè¡¨æ˜Žï¼ŒConsistTalkåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºŽçŽ°æœ‰æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨èº«ä»½ä¿æŒæ–¹é¢ï¼ŒConsistTalkçš„FIDå¾—åˆ†æ¯”çŽ°æœ‰æœ€ä½³æ–¹æ³•æé«˜äº†15%ä»¥ä¸Šã€‚åœ¨æ—¶é—´ä¸€è‡´æ€§æ–¹é¢ï¼ŒConsistTalkçš„Flicker Scoreé™ä½Žäº†20%ä»¥ä¸Šã€‚ä¸»è§‚è¯„ä»·ä¹Ÿè¡¨æ˜Žï¼ŒConsistTalkç”Ÿæˆçš„è§†é¢‘åœ¨è§†è§‰è´¨é‡ã€æµç•…åº¦å’ŒéŸ³è§†é¢‘åŒæ­¥æ–¹é¢éƒ½å…·æœ‰æ˜Žæ˜¾çš„ä¼˜åŠ¿ã€‚

## ðŸŽ¯ åº”ç”¨åœºæ™¯

ConsistTalkåœ¨è™šæ‹Ÿå½¢è±¡ç”Ÿæˆã€åœ¨çº¿ä¼šè®®ã€å¨±ä¹å†…å®¹åˆ›ä½œã€æ•™è‚²åŸ¹è®­ç­‰é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨å‰æ™¯ã€‚å®ƒå¯ä»¥ç”¨äºŽåˆ›å»ºé€¼çœŸçš„è™šæ‹Ÿäººç‰©ï¼Œæå‡åœ¨çº¿äº¤æµçš„ä½“éªŒï¼Œåˆ¶ä½œé«˜è´¨é‡çš„éŸ³è§†é¢‘å†…å®¹ï¼Œä»¥åŠæä¾›ä¸ªæ€§åŒ–çš„æ•™è‚²æœåŠ¡ã€‚è¯¥ç ”ç©¶çš„æˆæžœæœ‰åŠ©äºŽæŽ¨åŠ¨æ•°å­—äººæŠ€æœ¯çš„å‘å±•ï¼Œå¹¶ä¸ºäººä»¬çš„ç”Ÿæ´»å¸¦æ¥æ›´å¤šä¾¿åˆ©å’Œä¹è¶£ã€‚

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Recent advancements in video diffusion models have significantly enhanced audio-driven portrait animation. However, current methods still suffer from flickering, identity drift, and poor audio-visual synchronization. These issues primarily stem from entangled appearance-motion representations and unstable inference strategies. In this paper, we introduce \textbf{ConsistTalk}, a novel intensity-controllable and temporally consistent talking head generation framework with diffusion noise search inference. First, we propose \textbf{an optical flow-guided temporal module (OFT)} that decouples motion features from static appearance by leveraging facial optical flow, thereby reducing visual flicker and improving temporal consistency. Second, we present an \textbf{Audio-to-Intensity (A2I) model} obtained through multimodal teacher-student knowledge distillation. By transforming audio and facial velocity features into a frame-wise intensity sequence, the A2I model enables joint modeling of audio and visual motion, resulting in more natural dynamics. This further enables fine-grained, frame-wise control of motion dynamics while maintaining tight audio-visual synchronization. Third, we introduce a \textbf{diffusion noise initialization strategy (IC-Init)}. By enforcing explicit constraints on background coherence and motion continuity during inference-time noise search, we achieve better identity preservation and refine motion dynamics compared to the current autoregressive strategy. Extensive experiments demonstrate that ConsistTalk significantly outperforms prior methods in reducing flicker, preserving identity, and delivering temporally stable, high-fidelity talking head videos.

