---
layout: default
title: SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards
---

# SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards

**arXiv**: [2511.07403v1](https://arxiv.org/abs/2511.07403) | [PDF](https://arxiv.org/pdf/2511.07403.pdf)

**ä½œè€…**: Hunar Batra, Haoqin Tu, Hardy Chen, Yuanze Lin, Cihang Xie, Ronald Clark

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºSpatialThinkerä»¥å¢žå¼ºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹çš„ä¸‰ç»´ç©ºé—´æŽ¨ç†èƒ½åŠ›**

**å…³é”®è¯**: `å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹` `ä¸‰ç»´ç©ºé—´æŽ¨ç†` `å¼ºåŒ–å­¦ä¹ ` `ç©ºé—´å¥–åŠ±` `åœºæ™¯å›¾æž„å»º` `è§†è§‰é—®ç­”`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡åž‹åœ¨ç©ºé—´ç†è§£æ–¹é¢å­˜åœ¨ä¸è¶³ï¼Œä¾èµ–æ˜¾å¼3Dè¾“å…¥æˆ–ç‰¹å®šæž¶æž„ä¿®æ”¹
2. é€šè¿‡æž„å»ºåœºæ™¯å›¾å’Œå¯†é›†ç©ºé—´å¥–åŠ±ï¼Œç»“åˆå¼ºåŒ–å­¦ä¹ å®žçŽ°ç»“æž„åŒ–ç©ºé—´æŽ¥åœ°ä¸Žå¤šæ­¥æŽ¨ç†
3. åœ¨ç©ºé—´ç†è§£å’ŒçœŸå®žä¸–ç•ŒVQAåŸºå‡†ä¸Šè¶…è¶ŠåŸºçº¿æ¨¡åž‹å’ŒGPT-4oï¼Œæå‡åŸºç¡€æ¨¡åž‹å¢žç›Š

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Multimodal large language models (MLLMs) have achieved remarkable progress in
> vision-language tasks, but they continue to struggle with spatial
> understanding. Existing spatial MLLMs often rely on explicit 3D inputs or
> architecture-specific modifications, and remain constrained by large-scale
> datasets or sparse supervision. To address these limitations, we introduce
> SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial
> grounding with multi-step reasoning. The model simulates human-like spatial
> perception by constructing a scene graph of task-relevant objects and spatial
> relations, and reasoning towards an answer via dense spatial rewards.
> SpatialThinker consists of two key contributions: (1) a data synthesis pipeline
> that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL
> with a multi-objective dense spatial reward enforcing spatial grounding.
> SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline
> on spatial understanding and real-world VQA benchmarks, nearly doubling the
> base-model gain compared to sparse RL, and surpassing GPT-4o. These results
> showcase the effectiveness of combining spatial supervision with reward-aligned
> reasoning in enabling robust 3D spatial understanding with limited data and
> advancing MLLMs towards human-level visual reasoning.

