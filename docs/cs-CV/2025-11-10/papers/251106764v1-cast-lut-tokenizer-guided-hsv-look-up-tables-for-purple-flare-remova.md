---
layout: default
title: CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal
---

# CAST-LUT: Tokenizer-Guided HSV Look-Up Tables for Purple Flare Removal

**arXiv**: [2511.06764v1](https://arxiv.org/abs/2511.06764) | [PDF](https://arxiv.org/pdf/2511.06764.pdf)

**ä½œè€…**: Pu Wang, Shuning Sun, Jialang Lu, Chen Wu, Zhihua Zhang, Youshan Zhang, Chenggang Shan, Dianjie Lu, Guijuan Zhang, Zhuoran Zheng

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºCAST-LUTæ–¹æ³•ä»¥è§£å†³å›¾åƒç´«è¾¹ä¼ªå½±åŽ»é™¤é—®é¢˜**

**å…³é”®è¯**: `ç´«è¾¹åŽ»é™¤` `HSVæŸ¥æ‰¾è¡¨` `é¢œè‰²æ ¡æ­£` `è¯­ä¹‰ä»¤ç‰Œ` `å›¾åƒå¢žå¼º` `ä¸¤é˜¶æ®µç½‘ç»œ`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. ç´«è¾¹ä¼ªå½±æ˜¯å›¾åƒé«˜å…‰åŒºåŸŸå¸¸è§çš„è‰²å·®é—®é¢˜ï¼Œä¸¥é‡å½±å“è‰²è°ƒè¿‡æ¸¡å’Œé¢œè‰²è´¨é‡
2. é‡‡ç”¨è§£è€¦HSVæŸ¥æ‰¾è¡¨å’Œä¸¤é˜¶æ®µæž¶æž„ï¼Œé€šè¿‡è¯­ä¹‰ä»¤ç‰ŒåŠ¨æ€ç”Ÿæˆæ ¡æ­£æ›²çº¿
3. æž„å»ºå¤§è§„æ¨¡æ•°æ®é›†å’Œæ–°è¯„ä¼°æŒ‡æ ‡ï¼Œå®žéªŒæ˜¾ç¤ºåœ¨è§†è§‰å’Œé‡åŒ–æŒ‡æ ‡ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Purple flare, a diffuse chromatic aberration artifact commonly found around
> highlight areas, severely degrades the tone transition and color of the image.
> Existing traditional methods are based on hand-crafted features, which lack
> flexibility and rely entirely on fixed priors, while the scarcity of paired
> training data critically hampers deep learning. To address this issue, we
> propose a novel network built upon decoupled HSV Look-Up Tables (LUTs). The
> method aims to simplify color correction by adjusting the Hue (H), Saturation
> (S), and Value (V) components independently. This approach resolves the
> inherent color coupling problems in traditional methods. Our model adopts a
> two-stage architecture: First, a Chroma-Aware Spectral Tokenizer (CAST)
> converts the input image from RGB space to HSV space and independently encodes
> the Hue (H) and Value (V) channels into a set of semantic tokens describing the
> Purple flare status; second, the HSV-LUT module takes these tokens as input and
> dynamically generates independent correction curves (1D-LUTs) for the three
> channels H, S, and V. To effectively train and validate our model, we built the
> first large-scale purple flare dataset with diverse scenes. We also proposed
> new metrics and a loss function specifically designed for this task. Extensive
> experiments demonstrate that our model not only significantly outperforms
> existing methods in visual effects but also achieves state-of-the-art
> performance on all quantitative metrics.

