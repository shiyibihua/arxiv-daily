---
layout: default
title: VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling
---

# VAEVQ: Enhancing Discrete Visual Tokenization through Variational Modeling

**arXiv**: [2511.06863v1](https://arxiv.org/abs/2511.06863) | [PDF](https://arxiv.org/pdf/2511.06863.pdf)

**ä½œè€…**: Sicheng Yang, Xing Hu, Qiang Wu, Dawei Yang

---

## ðŸ’¡ ä¸€å¥è¯è¦ç‚¹

**æå‡ºVAEVQä»¥è§£å†³å‘é‡é‡åŒ–ä¸­çš„æ½œåœ¨ç©ºé—´ä¸å¹³æ»‘å’Œç æœ¬åˆ©ç”¨ä¸è¶³é—®é¢˜**

**å…³é”®è¯**: `å‘é‡é‡åŒ–` `å˜åˆ†è‡ªç¼–ç å™¨` `ç¦»æ•£è¡¨ç¤º` `ç æœ¬å­¦ä¹ ` `ç”Ÿæˆæ¨¡åž‹` `æ½œåœ¨ç©ºé—´å¯¹é½`

## ðŸ“‹ æ ¸å¿ƒè¦ç‚¹

1. æ ¸å¿ƒé—®é¢˜ï¼šå‘é‡é‡åŒ–å¯¼è‡´æ½œåœ¨ç©ºé—´ä¸å¹³æ»‘ã€é‡åŒ–å‰åŽç‰¹å¾å¯¹é½å¼±ï¼Œå½±å“ç”Ÿæˆæ¨¡åž‹æ€§èƒ½
2. æ–¹æ³•è¦ç‚¹ï¼šå¼•å…¥å˜åˆ†æ½œåœ¨é‡åŒ–ã€è¡¨ç¤ºä¸€è‡´æ€§ç­–ç•¥å’Œåˆ†å¸ƒä¸€è‡´æ€§æ­£åˆ™åŒ–ï¼Œæå‡ç æœ¬åˆ©ç”¨
3. å®žéªŒæˆ–æ•ˆæžœï¼šåœ¨åŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºŽçŽ°æœ‰æ–¹æ³•ï¼Œæ”¹å–„é‡å»ºå’Œç”Ÿæˆä»»åŠ¡è¡¨çŽ°

## ðŸ“„ æ‘˜è¦ï¼ˆåŽŸæ–‡ï¼‰

> Vector quantization (VQ) transforms continuous image features into discrete
> representations, providing compressed, tokenized inputs for generative models.
> However, VQ-based frameworks suffer from several issues, such as non-smooth
> latent spaces, weak alignment between representations before and after
> quantization, and poor coherence between the continuous and discrete domains.
> These issues lead to unstable codeword learning and underutilized codebooks,
> ultimately degrading the performance of both reconstruction and downstream
> generation tasks. To this end, we propose VAEVQ, which comprises three key
> components: (1) Variational Latent Quantization (VLQ), replacing the AE with a
> VAE for quantization to leverage its structured and smooth latent space,
> thereby facilitating more effective codeword activation; (2) Representation
> Coherence Strategy (RCS), adaptively modulating the alignment strength between
> pre- and post-quantization features to enhance consistency and prevent
> overfitting to noise; and (3) Distribution Consistency Regularization (DCR),
> aligning the entire codebook distribution with the continuous latent
> distribution to improve utilization. Extensive experiments on two benchmark
> datasets demonstrate that VAEVQ outperforms state-of-the-art methods.

