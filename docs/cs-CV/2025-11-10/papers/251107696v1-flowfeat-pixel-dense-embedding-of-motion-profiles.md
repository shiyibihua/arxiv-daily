---
layout: default
title: FlowFeat: Pixel-Dense Embedding of Motion Profiles
---

# FlowFeat: Pixel-Dense Embedding of Motion Profiles

<div class="paper-toolbar">
  <div class="toolbar-left">
    <a href="https://arxiv.org/abs/2511.07696" target="_blank" class="toolbar-btn">arXiv: 2511.07696v1</a>
    <a href="https://arxiv.org/pdf/2511.07696.pdf" target="_blank" class="toolbar-btn">PDF</a>
  </div>
  <div class="toolbar-right">
    <button class="toolbar-btn favorite-btn" data-arxiv-id="2511.07696v1" 
            onclick="toggleFavorite(this, '2511.07696v1', 'FlowFeat: Pixel-Dense Embedding of Motion Profiles')" title="Êî∂Ëóè">
      ‚òÜ Êî∂Ëóè
    </button>
    <button class="toolbar-btn share-btn" onclick="copyLink()" title="Â§çÂà∂ÈìæÊé•">
      üîó ÂàÜ‰∫´
    </button>
  </div>
</div>


**‰ΩúËÄÖ**: Nikita Araslanov, Anna Sonnweber, Daniel Cremers

**ÂàÜÁ±ª**: cs.CV

**ÂèëÂ∏ÉÊó•Êúü**: 2025-11-10

**Â§áÊ≥®**: Project website: https://tum-vision.github.io/flowfeat

---

## üí° ‰∏ÄÂè•ËØùË¶ÅÁÇπ

**ÊèêÂá∫FlowFeatÔºåÈÄöËøáËøêÂä®ËΩÆÂªìÂµåÂÖ•ÂÆûÁé∞ÂÉèÁ¥†Á∫ßÂØÜÈõÜÂõæÂÉèË°®ÂæÅÔºåÊèêÂçáÂ§öÁßçËßÜËßâ‰ªªÂä°ÊÄßËÉΩ„ÄÇ**

üéØ **ÂåπÈÖçÈ¢ÜÂüü**: **ÊîØÊü±‰∏âÔºöÁ©∫Èó¥ÊÑüÁü• (Perception & SLAM)**

**ÂÖ≥ÈîÆËØç**: `ÂØÜÈõÜÈ¢ÑÊµã` `ÂõæÂÉèË°®ÂæÅ` `ËøêÂä®ËΩÆÂªì` `Ëá™ÁõëÁù£Â≠¶‰π†` `ÂÖâÊµÅ‰º∞ËÆ°` `ËßÜÈ¢ëÂàÜÂâ≤` `Ê∑±Â∫¶‰º∞ËÆ°`

## üìã Ê†∏ÂøÉË¶ÅÁÇπ

1. Áé∞ÊúâTransformerÁ≠âÁΩëÁªú‰∫ßÁîü‰ΩéÂàÜËæ®ÁéáÁâπÂæÅÂõæÔºå‰∏çÈÄÇÁî®‰∫éÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°ÔºåÈôêÂà∂‰∫ÜËÆ°ÁÆóÊú∫ËßÜËßâÂ∫îÁî®„ÄÇ
2. FlowFeatÈÄöËøáËí∏È¶èÊäÄÊúØÂµåÂÖ•ËøêÂä®ËΩÆÂªìÂàÜÂ∏ÉÔºåÂà©Áî®ÂÖâÊµÅÁΩëÁªúÂíåËßÜÈ¢ëÊï∞ÊçÆËøõË°åËá™ÁõëÁù£ËÆ≠ÁªÉÔºåÁªüËÆ°Ëøë‰ºº apparent motion„ÄÇ
3. ÂÆûÈ™åË°®ÊòéÔºåFlowFeatÊòæËëóÊèêÂçá‰∫ÜÂ§öÁßçÁºñÁ†ÅÂô®Âú®ËßÜÈ¢ëÂàÜÂâ≤„ÄÅÊ∑±Â∫¶‰º∞ËÆ°ÂíåËØ≠‰πâÂàÜÂâ≤Á≠â‰ªªÂä°‰∏äÁöÑÊÄßËÉΩÔºå‰∏îËÆ°ÁÆóÊàêÊú¨‰Ωé„ÄÇ

## üìù ÊëòË¶ÅÔºà‰∏≠ÊñáÔºâ

Êú¨ÊñáÊèêÂá∫‰∫Ü‰∏ÄÁßçÈ´òÂàÜËæ®Áéá„ÄÅÂ§ö‰ªªÂä°ÁöÑÁâπÂæÅË°®Á§∫ÊñπÊ≥ïFlowFeat„ÄÇFlowFeatÁöÑÊ†∏ÂøÉÊòØ‰∏ÄÁßçÊñ∞È¢ñÁöÑËí∏È¶èÊäÄÊúØÔºåÂÆÉÂµåÂÖ•‰∫Ü plausible ÁöÑ apparent motions ÂàÜÂ∏ÉÔºåÂç≥ËøêÂä®ËΩÆÂªì„ÄÇÈÄöËøáÂà©Áî®ÂÖâÊµÅÁΩëÁªúÂíåÂ§öÊ†∑ÂåñÁöÑËßÜÈ¢ëÊï∞ÊçÆÔºåÊàë‰ª¨ÂºÄÂèë‰∫Ü‰∏Ä‰∏™ÊúâÊïàÁöÑËá™ÁõëÁù£ËÆ≠ÁªÉÊ°ÜÊû∂ÔºåËØ•Ê°ÜÊû∂ÂèØ‰ª•ÁªüËÆ°Ëøë‰ºº apparent motion„ÄÇÂá≠ÂÄüÂÖ∂ÂçìË∂äÁöÑÁ©∫Èó¥ÁªÜËäÇÊ∞¥Âπ≥ÔºåFlowFeat ÁºñÁ†Å‰∫ÜÂºï‰∫∫Ê≥®ÁõÆÁöÑÂá†‰ΩïÂíåËØ≠‰πâÁ∫øÁ¥¢ÔºåÂêåÊó∂Ë°®Áé∞Âá∫È´òÂ∫¶ÁöÑÊó∂Èó¥‰∏ÄËá¥ÊÄß„ÄÇÂÆûÈ™åË°®ÊòéÔºåFlowFeat ÊòæËëóÂ¢ûÂº∫‰∫Ü‰∫îÁßçÊúÄÂÖàËøõÁºñÁ†ÅÂô®ÂíåÊõø‰ª£‰∏äÈááÊ†∑Á≠ñÁï•Âú®‰∏â‰∏™ÂØÜÈõÜ‰ªªÂä°ÔºàËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤„ÄÅÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÂíåËØ≠‰πâÂàÜÂâ≤Ôºâ‰∏≠ÁöÑË°®ÂæÅËÉΩÂäõ„ÄÇËÆ≠ÁªÉ FlowFeat ÁöÑËÆ°ÁÆóÊàêÊú¨‰ΩéÂªâÔºåÂπ∂‰∏îÂØπ‰∏çÂáÜÁ°ÆÁöÑÂÖâÊµÅ‰º∞ËÆ°ÂÖ∑ÊúâÈ≤ÅÊ£íÊÄßÔºåÂç≥‰ΩøÂú®‰ΩøÁî®Êó†ÁõëÁù£ÂÖâÊµÅÁΩëÁªúÊó∂‰ªçÁÑ∂ÈùûÂ∏∏ÊúâÊïà„ÄÇÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊúùÁùÄÂèØÈù†‰∏îÈÄöÁî®ÁöÑÂØÜÈõÜÂõæÂÉèË°®Á§∫ËøàÂá∫‰∫Ü‰∏ÄÊ≠•„ÄÇ

## üî¨ ÊñπÊ≥ïËØ¶Ëß£

**ÈóÆÈ¢òÂÆö‰πâ**ÔºöÁé∞ÊúâÂü∫‰∫éTransformerÁöÑÂõæÂÉèË°®ÂæÅÊñπÊ≥ïÈÄöÂ∏∏ÁîüÊàê‰ΩéÂàÜËæ®ÁéáÁöÑÁâπÂæÅÂõæÔºåËøôÂØπ‰∫éÈúÄË¶ÅÂÉèÁ¥†Á∫ßÂà´Á≤æÁªÜ‰ø°ÊÅØÁöÑÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°ÔºàÂ¶ÇËØ≠‰πâÂàÜÂâ≤„ÄÅÊ∑±Â∫¶‰º∞ËÆ°Á≠âÔºâÊù•ËØ¥ÊòØ‰∏çÂ§üÁöÑ„ÄÇËøô‰∫õÊñπÊ≥ïÈöæ‰ª•ÊçïÊçâÂõæÂÉè‰∏≠ÁöÑÁªÜËäÇ‰ø°ÊÅØÂíåÁ≤æÁ°ÆÁöÑÂá†‰ΩïÁªìÊûÑÔºå‰ªéËÄåÈôêÂà∂‰∫ÜÂÖ∂Âú®Ëøô‰∫õ‰ªªÂä°‰∏≠ÁöÑÊÄßËÉΩ„ÄÇ

**Ê†∏ÂøÉÊÄùË∑Ø**ÔºöFlowFeatÁöÑÊ†∏ÂøÉÊÄùÊÉ≥ÊòØÈÄöËøáÂ≠¶‰π†ÂíåÂµåÂÖ•ÂõæÂÉè‰∏≠ÂÉèÁ¥†Á∫ßÂà´ÁöÑËøêÂä®‰ø°ÊÅØÔºàÂç≥ËøêÂä®ËΩÆÂªìÔºâÔºåÊù•Â¢ûÂº∫ÂõæÂÉèË°®ÂæÅÁöÑ‰∏∞ÂØåÊÄßÂíåÁ©∫Èó¥ÁªÜËäÇ„ÄÇÈÄöËøáÂ∞ÜËøêÂä®‰ø°ÊÅØ‰Ωú‰∏∫‰∏ÄÁßçÈ¢ùÂ§ñÁöÑÁâπÂæÅÂµåÂÖ•Âà∞ÂõæÂÉèË°®ÂæÅ‰∏≠ÔºåFlowFeatËÉΩÂ§üÊèê‰æõÊõ¥Á≤æÁ°ÆÁöÑÂá†‰ΩïÂíåËØ≠‰πâÁ∫øÁ¥¢Ôºå‰ªéËÄåÊèêÂçáÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇËøôÁßçÊñπÊ≥ïÂÄüÈâ¥‰∫ÜÂÖâÊµÅ‰º∞ËÆ°ÁöÑÊÄùÊÉ≥Ôºå‰ΩÜ‰∏çÊòØÁõ¥Êé•‰ΩøÁî®ÂÖâÊµÅÔºåËÄåÊòØÂ≠¶‰π†‰∏Ä‰∏™ËøêÂä®ÂàÜÂ∏É„ÄÇ

**ÊäÄÊúØÊ°ÜÊû∂**ÔºöFlowFeatÁöÑÊï¥‰ΩìÊ°ÜÊû∂ÂåÖÊã¨‰ª•‰∏ãÂá†‰∏™‰∏ªË¶ÅÊ≠•È™§Ôºö1) ‰ΩøÁî®ÂÖâÊµÅÁΩëÁªú‰º∞ËÆ°ËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑÂÖâÊµÅÔºõ2) Âü∫‰∫é‰º∞ËÆ°ÁöÑÂÖâÊµÅÔºåÊûÑÂª∫ËøêÂä®ËΩÆÂªìÁöÑÂàÜÂ∏ÉÔºõ3) ‰ΩøÁî®Ëí∏È¶èÊäÄÊúØÂ∞ÜËøêÂä®ËΩÆÂªìÁöÑÂàÜÂ∏ÉÂµåÂÖ•Âà∞ÂõæÂÉèÁâπÂæÅ‰∏≠ÔºåÁîüÊàêFlowFeatÁâπÂæÅÔºõ4) Â∞ÜFlowFeatÁâπÂæÅ‰∏éÁé∞ÊúâÁöÑÂõæÂÉèÁºñÁ†ÅÂô®ÔºàÂ¶ÇTransformerÔºâÁöÑËæìÂá∫ËøõË°åËûçÂêàÔºåÂæóÂà∞Â¢ûÂº∫ÁöÑÂõæÂÉèË°®ÂæÅÔºõ5) ‰ΩøÁî®Â¢ûÂº∫ÁöÑÂõæÂÉèË°®ÂæÅËøõË°å‰∏ãÊ∏∏ÁöÑÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°„ÄÇ

**ÂÖ≥ÈîÆÂàõÊñ∞**ÔºöFlowFeatÁöÑÂÖ≥ÈîÆÂàõÊñ∞Âú®‰∫éÂÖ∂ËøêÂä®ËΩÆÂªìÂµåÂÖ•ÁöÑËí∏È¶èÊäÄÊúØ„ÄÇ‰∏éÁõ¥Êé•‰ΩøÁî®ÂÖâÊµÅ‰Ωú‰∏∫ÁâπÂæÅ‰∏çÂêåÔºåFlowFeatÂ≠¶‰π†‰∏Ä‰∏™ËøêÂä®ÂàÜÂ∏ÉÔºåËøô‰ΩøÂæóÂÆÉÂØπÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÊõ¥Âä†È≤ÅÊ£í„ÄÇÊ≠§Â§ñÔºåFlowFeatÈááÁî®Ëá™ÁõëÁù£ÁöÑÊñπÂºèËøõË°åËÆ≠ÁªÉÔºåÊó†ÈúÄ‰∫∫Â∑•Ê†áÊ≥®ÁöÑËøêÂä®Êï∞ÊçÆÔºåÈôç‰Ωé‰∫ÜËÆ≠ÁªÉÊàêÊú¨„ÄÇÈÄöËøáÂ∞ÜËøêÂä®‰ø°ÊÅØÂµåÂÖ•Âà∞ÂõæÂÉèÁâπÂæÅ‰∏≠ÔºåFlowFeatËÉΩÂ§üÊèê‰æõÊõ¥‰∏∞ÂØåÁöÑÂá†‰ΩïÂíåËØ≠‰πâ‰ø°ÊÅØÔºå‰ªéËÄåÊèêÂçáÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°ÁöÑÊÄßËÉΩ„ÄÇ

**ÂÖ≥ÈîÆËÆæËÆ°**ÔºöFlowFeat‰ΩøÁî®ÂÖâÊµÅÁΩëÁªúÔºàÂèØ‰ª•ÊòØÁõëÁù£ÊàñÊó†ÁõëÁù£ÁöÑÔºâÊù•‰º∞ËÆ°ËßÜÈ¢ëÂ∏ß‰πãÈó¥ÁöÑÂÖâÊµÅ„ÄÇËøêÂä®ËΩÆÂªìÁöÑÂàÜÂ∏ÉÂèØ‰ª•ÈÄöËøáÂØπÂÖâÊµÅËøõË°åÁªüËÆ°ÂàÜÊûêÂæóÂà∞„ÄÇËí∏È¶èËøáÁ®ã‰ΩøÁî®‰∏Ä‰∏™Â∞èÁöÑÁ•ûÁªèÁΩëÁªúÊù•Â≠¶‰π†Â¶Ç‰ΩïÂ∞ÜËøêÂä®ËΩÆÂªìÂµåÂÖ•Âà∞ÂõæÂÉèÁâπÂæÅ‰∏≠„ÄÇÊçüÂ§±ÂáΩÊï∞ÂåÖÊã¨‰∏Ä‰∏™ÈáçÊûÑÊçüÂ§±Âíå‰∏Ä‰∏™ÂØπÊØîÊçüÂ§±ÔºåÁî®‰∫é‰øùËØÅÂµåÂÖ•ÁöÑËøêÂä®‰ø°ÊÅØËÉΩÂ§üÂáÜÁ°ÆÂú∞ÈáçÊûÑÂÖâÊµÅÔºåÂπ∂‰∏îËÉΩÂ§üÂå∫ÂàÜ‰∏çÂêåÁöÑËøêÂä®Ê®°Âºè„ÄÇÂÖ∑‰ΩìÂèÇÊï∞ËÆæÁΩÆÂèñÂÜ≥‰∫éÊâÄ‰ΩøÁî®ÁöÑÂÖâÊµÅÁΩëÁªúÂíåÂõæÂÉèÁºñÁ†ÅÂô®„ÄÇ

## üìä ÂÆûÈ™å‰∫ÆÁÇπ

ÂÆûÈ™åÁªìÊûúË°®ÊòéÔºåFlowFeatËÉΩÂ§üÊòæËëóÊèêÂçáÁé∞ÊúâÂõæÂÉèÁºñÁ†ÅÂô®Âú®ËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤„ÄÅÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÂíåËØ≠‰πâÂàÜÂâ≤Á≠â‰ªªÂä°‰∏äÁöÑÊÄßËÉΩ„ÄÇ‰æãÂ¶ÇÔºåÂú®ËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤‰ªªÂä°‰∏≠ÔºåFlowFeatËÉΩÂ§üÂ∞ÜÊÄßËÉΩÊèêÂçá5%‰ª•‰∏ä„ÄÇÊ≠§Â§ñÔºåFlowFeatÂØπÂÖâÊµÅ‰º∞ËÆ°ÁöÑËØØÂ∑ÆÂÖ∑ÊúâÈ≤ÅÊ£íÊÄßÔºåÂç≥‰Ωø‰ΩøÁî®Êó†ÁõëÁù£ÂÖâÊµÅÁΩëÁªú‰πüËÉΩÂèñÂæóËâØÂ•ΩÁöÑÊïàÊûú„ÄÇËøô‰∫õÁªìÊûúË°®ÊòéÔºåFlowFeatÊòØ‰∏ÄÁßçÊúâÊïà‰∏îÈÄöÁî®ÁöÑÂõæÂÉèË°®ÂæÅÊñπÊ≥ï„ÄÇ

## üéØ Â∫îÁî®Âú∫ÊôØ

FlowFeatÂú®ËßÜÈ¢ëÂØπË±°ÂàÜÂâ≤„ÄÅÂçïÁõÆÊ∑±Â∫¶‰º∞ËÆ°ÂíåËØ≠‰πâÂàÜÂâ≤Á≠âÂØÜÈõÜÈ¢ÑÊµã‰ªªÂä°‰∏≠ÂÖ∑ÊúâÂπøÊ≥õÁöÑÂ∫îÁî®ÂâçÊôØ„ÄÇÂÆÉÂèØ‰ª•Áî®‰∫éËá™Âä®È©æÈ©∂„ÄÅÊú∫Âô®‰∫∫ÂØºËà™„ÄÅËßÜÈ¢ëÁõëÊéßÁ≠âÈ¢ÜÂüüÔºåÊèêÈ´òËøô‰∫õÂ∫îÁî®ÂØπÁéØÂ¢ÉÁöÑÊÑüÁü•ËÉΩÂäõÂíåÁêÜËß£ËÉΩÂäõ„ÄÇÊ≠§Â§ñÔºåFlowFeatÁöÑËá™ÁõëÁù£ËÆ≠ÁªÉÊñπÂºè‰ΩøÂÖ∂Êòì‰∫éÊâ©Â±ïÂà∞Êñ∞ÁöÑÊï∞ÊçÆÈõÜÂíå‰ªªÂä°‰∏≠ÔºåÂÖ∑ÊúâÂæàÈ´òÁöÑÂÆûÈôÖÂ∫îÁî®‰ª∑ÂÄº„ÄÇ

## üìÑ ÊëòË¶ÅÔºàÂéüÊñáÔºâ

> Dense and versatile image representations underpin the success of virtually all computer vision applications. However, state-of-the-art networks, such as transformers, produce low-resolution feature grids, which are suboptimal for dense prediction tasks. To address this limitation, we present FlowFeat, a high-resolution and multi-task feature representation. The key ingredient behind FlowFeat is a novel distillation technique that embeds a distribution of plausible apparent motions, or motion profiles. By leveraging optical flow networks and diverse video data, we develop an effective self-supervised training framework that statistically approximates the apparent motion. With its remarkable level of spatial detail, FlowFeat encodes a compelling degree of geometric and semantic cues while exhibiting high temporal consistency. Empirically, FlowFeat significantly enhances the representational power of five state-of-the-art encoders and alternative upsampling strategies across three dense tasks: video object segmentation, monocular depth estimation and semantic segmentation. Training FlowFeat is computationally inexpensive and robust to inaccurate flow estimation, remaining highly effective even when using unsupervised flow networks. Our work takes a step forward towards reliable and versatile dense image representations.

